Epoch: 1| Step: 0
Training loss: 5.619876477930566
Validation loss: 5.332862688391961

Epoch: 6| Step: 1
Training loss: 5.355659642841481
Validation loss: 5.3252186563690325

Epoch: 6| Step: 2
Training loss: 5.455345423152698
Validation loss: 5.3216822469779785

Epoch: 6| Step: 3
Training loss: 4.196729821984073
Validation loss: 5.318815654553161

Epoch: 6| Step: 4
Training loss: 5.531303448607405
Validation loss: 5.313892552118267

Epoch: 6| Step: 5
Training loss: 4.89062734000543
Validation loss: 5.310866960131762

Epoch: 6| Step: 6
Training loss: 5.057654239793559
Validation loss: 5.304851493141231

Epoch: 6| Step: 7
Training loss: 5.472659038186299
Validation loss: 5.302594377728173

Epoch: 6| Step: 8
Training loss: 4.627382231975308
Validation loss: 5.298122837755478

Epoch: 6| Step: 9
Training loss: 5.311914568788583
Validation loss: 5.2936036770946355

Epoch: 6| Step: 10
Training loss: 6.252398221523307
Validation loss: 5.290963631106862

Epoch: 6| Step: 11
Training loss: 5.593549160042356
Validation loss: 5.287594247578904

Epoch: 6| Step: 12
Training loss: 5.703683486139338
Validation loss: 5.282655994187237

Epoch: 6| Step: 13
Training loss: 5.89993836968771
Validation loss: 5.276844895922006

Epoch: 2| Step: 0
Training loss: 6.40815847858571
Validation loss: 5.272248888316603

Epoch: 6| Step: 1
Training loss: 3.518280111753921
Validation loss: 5.269224203427774

Epoch: 6| Step: 2
Training loss: 5.1250591739867
Validation loss: 5.265768564352804

Epoch: 6| Step: 3
Training loss: 5.627969932643932
Validation loss: 5.263679248843385

Epoch: 6| Step: 4
Training loss: 4.971687264437607
Validation loss: 5.258965428908193

Epoch: 6| Step: 5
Training loss: 4.40993329575104
Validation loss: 5.2542198925892825

Epoch: 6| Step: 6
Training loss: 5.140537620659822
Validation loss: 5.249153561191876

Epoch: 6| Step: 7
Training loss: 5.223494331947597
Validation loss: 5.2488319906400385

Epoch: 6| Step: 8
Training loss: 5.494696053732216
Validation loss: 5.241320434280804

Epoch: 6| Step: 9
Training loss: 5.6803141042334895
Validation loss: 5.2376847469345265

Epoch: 6| Step: 10
Training loss: 5.317747508872082
Validation loss: 5.235643558635763

Epoch: 6| Step: 11
Training loss: 5.763717873524513
Validation loss: 5.2293508618397535

Epoch: 6| Step: 12
Training loss: 5.530765490675029
Validation loss: 5.2272679319614666

Epoch: 6| Step: 13
Training loss: 5.732935587075494
Validation loss: 5.221573578967096

Epoch: 3| Step: 0
Training loss: 5.550003931542456
Validation loss: 5.216130312970961

Epoch: 6| Step: 1
Training loss: 4.908182917536993
Validation loss: 5.214503574156715

Epoch: 6| Step: 2
Training loss: 4.536524156457137
Validation loss: 5.2101368271845265

Epoch: 6| Step: 3
Training loss: 4.3231637661949405
Validation loss: 5.205113949308319

Epoch: 6| Step: 4
Training loss: 6.333744671497321
Validation loss: 5.201590660666431

Epoch: 6| Step: 5
Training loss: 5.523354622786998
Validation loss: 5.198270484791029

Epoch: 6| Step: 6
Training loss: 4.977786501997917
Validation loss: 5.193917122661999

Epoch: 6| Step: 7
Training loss: 6.364495093134045
Validation loss: 5.187293182848314

Epoch: 6| Step: 8
Training loss: 3.982363922610461
Validation loss: 5.18383033020238

Epoch: 6| Step: 9
Training loss: 5.778841083855909
Validation loss: 5.1788519263598305

Epoch: 6| Step: 10
Training loss: 5.183199283219806
Validation loss: 5.173698585359694

Epoch: 6| Step: 11
Training loss: 4.522779453093334
Validation loss: 5.1677969484508255

Epoch: 6| Step: 12
Training loss: 5.975610116110792
Validation loss: 5.1654419984085935

Epoch: 6| Step: 13
Training loss: 4.562844668394433
Validation loss: 5.160966327967933

Epoch: 4| Step: 0
Training loss: 6.246598195311739
Validation loss: 5.157204840319859

Epoch: 6| Step: 1
Training loss: 5.129430019250452
Validation loss: 5.14999140081535

Epoch: 6| Step: 2
Training loss: 4.098634092245749
Validation loss: 5.143825751009635

Epoch: 6| Step: 3
Training loss: 4.746051150786188
Validation loss: 5.1403267156074515

Epoch: 6| Step: 4
Training loss: 6.436621152274705
Validation loss: 5.132344939078612

Epoch: 6| Step: 5
Training loss: 6.546947833910196
Validation loss: 5.129963361997114

Epoch: 6| Step: 6
Training loss: 5.18990646983637
Validation loss: 5.1243278068597595

Epoch: 6| Step: 7
Training loss: 5.146842744282654
Validation loss: 5.120041414065812

Epoch: 6| Step: 8
Training loss: 5.388207111730789
Validation loss: 5.1109855516647835

Epoch: 6| Step: 9
Training loss: 4.568350398465422
Validation loss: 5.107821306551745

Epoch: 6| Step: 10
Training loss: 5.009352900884076
Validation loss: 5.10339664613633

Epoch: 6| Step: 11
Training loss: 3.550177293030685
Validation loss: 5.0981586441799545

Epoch: 6| Step: 12
Training loss: 5.138924268079521
Validation loss: 5.091410554838673

Epoch: 6| Step: 13
Training loss: 3.927319641828482
Validation loss: 5.086160063810113

Epoch: 5| Step: 0
Training loss: 5.431429401064246
Validation loss: 5.079234943107481

Epoch: 6| Step: 1
Training loss: 3.6191827861143793
Validation loss: 5.075256793693753

Epoch: 6| Step: 2
Training loss: 5.220202580755929
Validation loss: 5.070108901795951

Epoch: 6| Step: 3
Training loss: 5.653898983463532
Validation loss: 5.063423922165027

Epoch: 6| Step: 4
Training loss: 5.759026449898869
Validation loss: 5.05707566020172

Epoch: 6| Step: 5
Training loss: 4.715761564690243
Validation loss: 5.053925383051803

Epoch: 6| Step: 6
Training loss: 4.118250092658725
Validation loss: 5.048116527379329

Epoch: 6| Step: 7
Training loss: 5.8351308323853965
Validation loss: 5.041663223844427

Epoch: 6| Step: 8
Training loss: 6.168975226127608
Validation loss: 5.035044704581401

Epoch: 6| Step: 9
Training loss: 5.477341187062587
Validation loss: 5.028857660625576

Epoch: 6| Step: 10
Training loss: 4.81998564911918
Validation loss: 5.021330771221591

Epoch: 6| Step: 11
Training loss: 5.134800170457205
Validation loss: 5.016503027534864

Epoch: 6| Step: 12
Training loss: 3.366633181515598
Validation loss: 5.01087460452527

Epoch: 6| Step: 13
Training loss: 5.538655469221594
Validation loss: 5.003774155786163

Epoch: 6| Step: 0
Training loss: 5.088218259604539
Validation loss: 4.996953187694402

Epoch: 6| Step: 1
Training loss: 3.504660092577018
Validation loss: 4.992047131648775

Epoch: 6| Step: 2
Training loss: 5.135892875623752
Validation loss: 4.986123032744681

Epoch: 6| Step: 3
Training loss: 4.764104681932394
Validation loss: 4.977777161655545

Epoch: 6| Step: 4
Training loss: 5.931051828593056
Validation loss: 4.973434096765006

Epoch: 6| Step: 5
Training loss: 5.225056931765007
Validation loss: 4.966578005698389

Epoch: 6| Step: 6
Training loss: 4.7673604838176455
Validation loss: 4.958673778637088

Epoch: 6| Step: 7
Training loss: 4.582226058838311
Validation loss: 4.953196274454937

Epoch: 6| Step: 8
Training loss: 5.525242878680375
Validation loss: 4.945193470215112

Epoch: 6| Step: 9
Training loss: 4.948877673601509
Validation loss: 4.939645953268975

Epoch: 6| Step: 10
Training loss: 4.930439210095117
Validation loss: 4.932689414173432

Epoch: 6| Step: 11
Training loss: 4.438868566813213
Validation loss: 4.926391473205268

Epoch: 6| Step: 12
Training loss: 5.412624239651961
Validation loss: 4.9188004826057385

Epoch: 6| Step: 13
Training loss: 6.043160966258579
Validation loss: 4.912473517711334

Epoch: 7| Step: 0
Training loss: 4.438620842161307
Validation loss: 4.903870450139079

Epoch: 6| Step: 1
Training loss: 4.632153314586423
Validation loss: 4.897174153970053

Epoch: 6| Step: 2
Training loss: 4.7098506856847715
Validation loss: 4.888120638349039

Epoch: 6| Step: 3
Training loss: 4.34087161193675
Validation loss: 4.878377112283299

Epoch: 6| Step: 4
Training loss: 4.742537408579646
Validation loss: 4.873220370790982

Epoch: 6| Step: 5
Training loss: 4.655380270204044
Validation loss: 4.8658052834031

Epoch: 6| Step: 6
Training loss: 4.27628946767266
Validation loss: 4.860324648255717

Epoch: 6| Step: 7
Training loss: 6.253848912526039
Validation loss: 4.852529471566782

Epoch: 6| Step: 8
Training loss: 4.554147887940124
Validation loss: 4.841628833798237

Epoch: 6| Step: 9
Training loss: 5.300942448728015
Validation loss: 4.834449218461983

Epoch: 6| Step: 10
Training loss: 4.917418190799721
Validation loss: 4.82716394205833

Epoch: 6| Step: 11
Training loss: 5.671143876130241
Validation loss: 4.817542932847827

Epoch: 6| Step: 12
Training loss: 5.58111201646518
Validation loss: 4.81015894415413

Epoch: 6| Step: 13
Training loss: 3.9719519727017985
Validation loss: 4.799401531288529

Epoch: 8| Step: 0
Training loss: 5.007809833877021
Validation loss: 4.791583723480154

Epoch: 6| Step: 1
Training loss: 4.500555216128113
Validation loss: 4.781402564009106

Epoch: 6| Step: 2
Training loss: 4.0982778421383665
Validation loss: 4.775704288454875

Epoch: 6| Step: 3
Training loss: 4.500806736157988
Validation loss: 4.766061945639613

Epoch: 6| Step: 4
Training loss: 4.531540854754655
Validation loss: 4.753483264198499

Epoch: 6| Step: 5
Training loss: 5.460409026981711
Validation loss: 4.74940315128004

Epoch: 6| Step: 6
Training loss: 3.768964750583069
Validation loss: 4.737277422689585

Epoch: 6| Step: 7
Training loss: 5.242284645965552
Validation loss: 4.730903567094283

Epoch: 6| Step: 8
Training loss: 4.09151531698359
Validation loss: 4.719132290904504

Epoch: 6| Step: 9
Training loss: 5.381177324431212
Validation loss: 4.711833237100325

Epoch: 6| Step: 10
Training loss: 5.373267493369174
Validation loss: 4.705551180686753

Epoch: 6| Step: 11
Training loss: 4.2564916959412935
Validation loss: 4.693152935899724

Epoch: 6| Step: 12
Training loss: 5.305215486254147
Validation loss: 4.6817031138763925

Epoch: 6| Step: 13
Training loss: 5.765153570983299
Validation loss: 4.674143904601514

Epoch: 9| Step: 0
Training loss: 4.021044210066166
Validation loss: 4.663723062658822

Epoch: 6| Step: 1
Training loss: 5.387735228038881
Validation loss: 4.6518655480946665

Epoch: 6| Step: 2
Training loss: 3.0333785616119324
Validation loss: 4.643068441175772

Epoch: 6| Step: 3
Training loss: 5.988606761986216
Validation loss: 4.633909365002407

Epoch: 6| Step: 4
Training loss: 5.241150618451816
Validation loss: 4.621656628964242

Epoch: 6| Step: 5
Training loss: 4.627737523871006
Validation loss: 4.610651789425435

Epoch: 6| Step: 6
Training loss: 4.203355747398092
Validation loss: 4.599608210116383

Epoch: 6| Step: 7
Training loss: 4.671119246067941
Validation loss: 4.586145015506997

Epoch: 6| Step: 8
Training loss: 4.820491744160297
Validation loss: 4.574506112802639

Epoch: 6| Step: 9
Training loss: 4.844115409603956
Validation loss: 4.565360338738218

Epoch: 6| Step: 10
Training loss: 4.922580632081683
Validation loss: 4.556913617417017

Epoch: 6| Step: 11
Training loss: 3.585217239416406
Validation loss: 4.537571308729711

Epoch: 6| Step: 12
Training loss: 3.851267093371648
Validation loss: 4.530547980218639

Epoch: 6| Step: 13
Training loss: 5.855491225878311
Validation loss: 4.51737470338063

Epoch: 10| Step: 0
Training loss: 3.303126766958639
Validation loss: 4.51063352048998

Epoch: 6| Step: 1
Training loss: 5.363753507066699
Validation loss: 4.498338413086493

Epoch: 6| Step: 2
Training loss: 4.381430559342221
Validation loss: 4.4842385006196555

Epoch: 6| Step: 3
Training loss: 4.328559054977954
Validation loss: 4.467794701597188

Epoch: 6| Step: 4
Training loss: 4.417458853063134
Validation loss: 4.453991601079558

Epoch: 6| Step: 5
Training loss: 4.549116178755221
Validation loss: 4.443604774698727

Epoch: 6| Step: 6
Training loss: 4.469318060348866
Validation loss: 4.432860367741655

Epoch: 6| Step: 7
Training loss: 6.006056589749829
Validation loss: 4.420571678700665

Epoch: 6| Step: 8
Training loss: 4.484214434257937
Validation loss: 4.4012168240215885

Epoch: 6| Step: 9
Training loss: 4.372121681523385
Validation loss: 4.390194523745661

Epoch: 6| Step: 10
Training loss: 4.123598958996109
Validation loss: 4.3762581090097505

Epoch: 6| Step: 11
Training loss: 4.580535982911505
Validation loss: 4.361761861600368

Epoch: 6| Step: 12
Training loss: 4.0736339877272725
Validation loss: 4.35143878071832

Epoch: 6| Step: 13
Training loss: 3.982461148040781
Validation loss: 4.332241871412238

Epoch: 11| Step: 0
Training loss: 4.794981144618411
Validation loss: 4.318579684023144

Epoch: 6| Step: 1
Training loss: 3.066706201740788
Validation loss: 4.306977859570637

Epoch: 6| Step: 2
Training loss: 4.110237756242551
Validation loss: 4.295095946733337

Epoch: 6| Step: 3
Training loss: 5.410944493570415
Validation loss: 4.274646382056117

Epoch: 6| Step: 4
Training loss: 4.967249229793958
Validation loss: 4.265280575831475

Epoch: 6| Step: 5
Training loss: 4.1417778281652025
Validation loss: 4.251976189516471

Epoch: 6| Step: 6
Training loss: 5.42412931425395
Validation loss: 4.234787990955887

Epoch: 6| Step: 7
Training loss: 4.104413304284511
Validation loss: 4.216052280485047

Epoch: 6| Step: 8
Training loss: 4.13591754996428
Validation loss: 4.202761483901937

Epoch: 6| Step: 9
Training loss: 3.7850741130471626
Validation loss: 4.185772393274075

Epoch: 6| Step: 10
Training loss: 3.8734679115889645
Validation loss: 4.168337920352688

Epoch: 6| Step: 11
Training loss: 4.2192843628591765
Validation loss: 4.154659155838919

Epoch: 6| Step: 12
Training loss: 4.255666433427618
Validation loss: 4.142260644496628

Epoch: 6| Step: 13
Training loss: 3.1410915350876545
Validation loss: 4.12107347021618

Epoch: 12| Step: 0
Training loss: 3.9134549032907398
Validation loss: 4.110993323254983

Epoch: 6| Step: 1
Training loss: 4.5227547823791205
Validation loss: 4.097419022040472

Epoch: 6| Step: 2
Training loss: 3.932710186578855
Validation loss: 4.076239991691651

Epoch: 6| Step: 3
Training loss: 4.915701345734806
Validation loss: 4.0557059473987485

Epoch: 6| Step: 4
Training loss: 2.899966101612729
Validation loss: 4.042789085596661

Epoch: 6| Step: 5
Training loss: 3.808180316101942
Validation loss: 4.023738358492531

Epoch: 6| Step: 6
Training loss: 4.17605278766636
Validation loss: 4.008082627337462

Epoch: 6| Step: 7
Training loss: 3.8886137516845305
Validation loss: 3.9932545061857003

Epoch: 6| Step: 8
Training loss: 4.15617772089701
Validation loss: 3.975101913721402

Epoch: 6| Step: 9
Training loss: 4.892403471184027
Validation loss: 3.961492734602555

Epoch: 6| Step: 10
Training loss: 4.476108494716111
Validation loss: 3.9371845218594275

Epoch: 6| Step: 11
Training loss: 3.802498753815195
Validation loss: 3.9181708447735675

Epoch: 6| Step: 12
Training loss: 4.0925011513533045
Validation loss: 3.9042712063143514

Epoch: 6| Step: 13
Training loss: 3.4826582027739432
Validation loss: 3.886274939349609

Epoch: 13| Step: 0
Training loss: 4.537013525408132
Validation loss: 3.8697494756055675

Epoch: 6| Step: 1
Training loss: 4.343838697666806
Validation loss: 3.8507160858442027

Epoch: 6| Step: 2
Training loss: 4.646021315986778
Validation loss: 3.831333685256086

Epoch: 6| Step: 3
Training loss: 3.181017248486474
Validation loss: 3.811909520097137

Epoch: 6| Step: 4
Training loss: 3.1811277234873248
Validation loss: 3.7888862429321617

Epoch: 6| Step: 5
Training loss: 3.719933970490876
Validation loss: 3.779233919283717

Epoch: 6| Step: 6
Training loss: 4.125695834569578
Validation loss: 3.759375897586952

Epoch: 6| Step: 7
Training loss: 3.8550280596433026
Validation loss: 3.737196415414665

Epoch: 6| Step: 8
Training loss: 4.549835604537851
Validation loss: 3.7248145619508732

Epoch: 6| Step: 9
Training loss: 3.528135022942334
Validation loss: 3.6959655027965908

Epoch: 6| Step: 10
Training loss: 3.2132485790340066
Validation loss: 3.686481387284211

Epoch: 6| Step: 11
Training loss: 3.701293878884606
Validation loss: 3.660053193194265

Epoch: 6| Step: 12
Training loss: 3.650615426005104
Validation loss: 3.6342398254860995

Epoch: 6| Step: 13
Training loss: 3.7187914164825377
Validation loss: 3.6212456327490155

Epoch: 14| Step: 0
Training loss: 3.8302446997337998
Validation loss: 3.5946458011266387

Epoch: 6| Step: 1
Training loss: 3.083837948995781
Validation loss: 3.583104582513318

Epoch: 6| Step: 2
Training loss: 4.232076661625241
Validation loss: 3.560483199346092

Epoch: 6| Step: 3
Training loss: 3.810836679298794
Validation loss: 3.542536546309335

Epoch: 6| Step: 4
Training loss: 4.410809045394793
Validation loss: 3.5222700119421115

Epoch: 6| Step: 5
Training loss: 4.176740345306298
Validation loss: 3.5064058514390877

Epoch: 6| Step: 6
Training loss: 3.720240959239039
Validation loss: 3.4854129558786915

Epoch: 6| Step: 7
Training loss: 3.279344568593021
Validation loss: 3.4684959125664387

Epoch: 6| Step: 8
Training loss: 3.0764065510683167
Validation loss: 3.444016825246657

Epoch: 6| Step: 9
Training loss: 3.73741709129209
Validation loss: 3.411160191396889

Epoch: 6| Step: 10
Training loss: 3.7692373843112548
Validation loss: 3.4076988418106744

Epoch: 6| Step: 11
Training loss: 2.3571070197712767
Validation loss: 3.3773452361374647

Epoch: 6| Step: 12
Training loss: 3.4113538109683668
Validation loss: 3.3566561793517384

Epoch: 6| Step: 13
Training loss: 3.45894219121299
Validation loss: 3.3371139826076375

Epoch: 15| Step: 0
Training loss: 3.6747858724687745
Validation loss: 3.3236443052765487

Epoch: 6| Step: 1
Training loss: 3.273782570798161
Validation loss: 3.2972979390706487

Epoch: 6| Step: 2
Training loss: 3.263126275179763
Validation loss: 3.2890311435904644

Epoch: 6| Step: 3
Training loss: 3.425207875201487
Validation loss: 3.2656363061017473

Epoch: 6| Step: 4
Training loss: 3.921025887172072
Validation loss: 3.24800033515768

Epoch: 6| Step: 5
Training loss: 3.7040025661121816
Validation loss: 3.2242231452928416

Epoch: 6| Step: 6
Training loss: 3.8029272249025845
Validation loss: 3.202049313656729

Epoch: 6| Step: 7
Training loss: 3.4322925310997268
Validation loss: 3.18273896912254

Epoch: 6| Step: 8
Training loss: 3.2502429577906895
Validation loss: 3.175919890072055

Epoch: 6| Step: 9
Training loss: 3.379998920147063
Validation loss: 3.1516597381980875

Epoch: 6| Step: 10
Training loss: 3.39938909427774
Validation loss: 3.132794847168367

Epoch: 6| Step: 11
Training loss: 2.600544498355536
Validation loss: 3.1102395049582334

Epoch: 6| Step: 12
Training loss: 3.412089810154269
Validation loss: 3.0802910725328907

Epoch: 6| Step: 13
Training loss: 2.563283288845006
Validation loss: 3.070296142754987

Epoch: 16| Step: 0
Training loss: 3.5446131548163846
Validation loss: 3.056045856708612

Epoch: 6| Step: 1
Training loss: 3.713071189635577
Validation loss: 3.034978605053979

Epoch: 6| Step: 2
Training loss: 2.8230504828873793
Validation loss: 3.0136010133453532

Epoch: 6| Step: 3
Training loss: 3.8536088007060854
Validation loss: 3.0045358351789226

Epoch: 6| Step: 4
Training loss: 2.5220627952338988
Validation loss: 2.9838333398563326

Epoch: 6| Step: 5
Training loss: 3.044301359460314
Validation loss: 2.968037168352335

Epoch: 6| Step: 6
Training loss: 3.2581502981720343
Validation loss: 2.9508769484371524

Epoch: 6| Step: 7
Training loss: 2.773980745651652
Validation loss: 2.943215901803575

Epoch: 6| Step: 8
Training loss: 3.4273867178128503
Validation loss: 2.938334489404684

Epoch: 6| Step: 9
Training loss: 3.286504407621185
Validation loss: 2.9185888308576855

Epoch: 6| Step: 10
Training loss: 2.850245843289224
Validation loss: 2.9097773836426097

Epoch: 6| Step: 11
Training loss: 3.47617267609062
Validation loss: 2.8988555579289694

Epoch: 6| Step: 12
Training loss: 2.8764861868081253
Validation loss: 2.8856816631948257

Epoch: 6| Step: 13
Training loss: 3.234855431889062
Validation loss: 2.8709508087222955

Epoch: 17| Step: 0
Training loss: 3.569615803195335
Validation loss: 2.854946512873113

Epoch: 6| Step: 1
Training loss: 3.8911810175059367
Validation loss: 2.8366295396621704

Epoch: 6| Step: 2
Training loss: 2.983167473926034
Validation loss: 2.8424429627550567

Epoch: 6| Step: 3
Training loss: 2.5421762007806286
Validation loss: 2.827722055142008

Epoch: 6| Step: 4
Training loss: 3.541320215371359
Validation loss: 2.812045619634403

Epoch: 6| Step: 5
Training loss: 2.65119965587768
Validation loss: 2.7973007764423334

Epoch: 6| Step: 6
Training loss: 2.4363966180673016
Validation loss: 2.799325300120098

Epoch: 6| Step: 7
Training loss: 3.255607462510057
Validation loss: 2.783135588279338

Epoch: 6| Step: 8
Training loss: 2.6473303537165482
Validation loss: 2.783039983988448

Epoch: 6| Step: 9
Training loss: 2.5773433540762523
Validation loss: 2.7705596028701986

Epoch: 6| Step: 10
Training loss: 2.6250510437861796
Validation loss: 2.7550082891371654

Epoch: 6| Step: 11
Training loss: 3.1252061394412793
Validation loss: 2.7469061230719696

Epoch: 6| Step: 12
Training loss: 3.6605345572236994
Validation loss: 2.744418812378643

Epoch: 6| Step: 13
Training loss: 3.55667534884031
Validation loss: 2.7402882456124553

Epoch: 18| Step: 0
Training loss: 2.997394383902687
Validation loss: 2.7346365011075826

Epoch: 6| Step: 1
Training loss: 3.3422100763686413
Validation loss: 2.7329121463489483

Epoch: 6| Step: 2
Training loss: 2.733952778506787
Validation loss: 2.726767811060479

Epoch: 6| Step: 3
Training loss: 2.642002446187206
Validation loss: 2.7231514737914444

Epoch: 6| Step: 4
Training loss: 3.230570301457043
Validation loss: 2.709347775515975

Epoch: 6| Step: 5
Training loss: 3.3436180873056247
Validation loss: 2.728968837556463

Epoch: 6| Step: 6
Training loss: 3.3586701829212173
Validation loss: 2.7020277311537697

Epoch: 6| Step: 7
Training loss: 2.7960831357632427
Validation loss: 2.710519226267167

Epoch: 6| Step: 8
Training loss: 2.5547149376751923
Validation loss: 2.708805512253651

Epoch: 6| Step: 9
Training loss: 2.940586335498585
Validation loss: 2.707449808825174

Epoch: 6| Step: 10
Training loss: 3.4564389168567575
Validation loss: 2.7051495684304427

Epoch: 6| Step: 11
Training loss: 2.409582431438378
Validation loss: 2.688716139171311

Epoch: 6| Step: 12
Training loss: 3.1820746231775745
Validation loss: 2.6961687061767043

Epoch: 6| Step: 13
Training loss: 3.598265887204492
Validation loss: 2.694652153209781

Epoch: 19| Step: 0
Training loss: 2.6494370996280048
Validation loss: 2.6941567673940647

Epoch: 6| Step: 1
Training loss: 3.1651163489001783
Validation loss: 2.6833596250494005

Epoch: 6| Step: 2
Training loss: 3.2731489177221142
Validation loss: 2.6682747153897206

Epoch: 6| Step: 3
Training loss: 2.81686909717511
Validation loss: 2.673783535123632

Epoch: 6| Step: 4
Training loss: 2.358516208401322
Validation loss: 2.670871857421652

Epoch: 6| Step: 5
Training loss: 2.6758379185377015
Validation loss: 2.6737221871130634

Epoch: 6| Step: 6
Training loss: 4.0114933830928425
Validation loss: 2.668627998906561

Epoch: 6| Step: 7
Training loss: 3.1500850181611075
Validation loss: 2.661405379610169

Epoch: 6| Step: 8
Training loss: 3.2287277087403172
Validation loss: 2.676414672139988

Epoch: 6| Step: 9
Training loss: 3.207540752719891
Validation loss: 2.6640909051672406

Epoch: 6| Step: 10
Training loss: 2.560117404748976
Validation loss: 2.664572672954218

Epoch: 6| Step: 11
Training loss: 3.0283853424874407
Validation loss: 2.670477816950272

Epoch: 6| Step: 12
Training loss: 3.3513042643905036
Validation loss: 2.6609306389457648

Epoch: 6| Step: 13
Training loss: 2.104927403881272
Validation loss: 2.6542591932370243

Epoch: 20| Step: 0
Training loss: 2.683819934802603
Validation loss: 2.6636176643247067

Epoch: 6| Step: 1
Training loss: 3.866440456175093
Validation loss: 2.6562499584991817

Epoch: 6| Step: 2
Training loss: 2.7615662873956466
Validation loss: 2.6537656976267057

Epoch: 6| Step: 3
Training loss: 2.4309271198428193
Validation loss: 2.6495253206480474

Epoch: 6| Step: 4
Training loss: 3.348264124908082
Validation loss: 2.6458849551050303

Epoch: 6| Step: 5
Training loss: 2.466814078832032
Validation loss: 2.6383421713848576

Epoch: 6| Step: 6
Training loss: 3.478865026010877
Validation loss: 2.6527765948340862

Epoch: 6| Step: 7
Training loss: 3.1208598367934828
Validation loss: 2.64042424953819

Epoch: 6| Step: 8
Training loss: 3.602067427915394
Validation loss: 2.647657133215127

Epoch: 6| Step: 9
Training loss: 2.7018746367257283
Validation loss: 2.6419616469568328

Epoch: 6| Step: 10
Training loss: 3.0578991331401815
Validation loss: 2.649511161940689

Epoch: 6| Step: 11
Training loss: 3.0595135822022717
Validation loss: 2.6401940936082933

Epoch: 6| Step: 12
Training loss: 2.4962563140896257
Validation loss: 2.6407480577082296

Epoch: 6| Step: 13
Training loss: 2.3687851553449537
Validation loss: 2.6442088290800974

Epoch: 21| Step: 0
Training loss: 2.356000293077538
Validation loss: 2.629570419423816

Epoch: 6| Step: 1
Training loss: 3.4453364434134715
Validation loss: 2.639863145756126

Epoch: 6| Step: 2
Training loss: 2.2568516782296695
Validation loss: 2.6363212987763918

Epoch: 6| Step: 3
Training loss: 3.0290758653662886
Validation loss: 2.6393510765266264

Epoch: 6| Step: 4
Training loss: 2.9499362098133197
Validation loss: 2.6380868387680105

Epoch: 6| Step: 5
Training loss: 2.5914445305550817
Validation loss: 2.6465352155883677

Epoch: 6| Step: 6
Training loss: 2.295084352626052
Validation loss: 2.6266112243880873

Epoch: 6| Step: 7
Training loss: 2.6793051577577818
Validation loss: 2.649410284887313

Epoch: 6| Step: 8
Training loss: 3.290274860993937
Validation loss: 2.6424296174204294

Epoch: 6| Step: 9
Training loss: 3.9267327972655086
Validation loss: 2.6430527488423974

Epoch: 6| Step: 10
Training loss: 2.8765077369197325
Validation loss: 2.6481651165841487

Epoch: 6| Step: 11
Training loss: 3.759160107490118
Validation loss: 2.6379269410902553

Epoch: 6| Step: 12
Training loss: 2.929005780059019
Validation loss: 2.6334232091721033

Epoch: 6| Step: 13
Training loss: 3.129182229509185
Validation loss: 2.642644956314653

Epoch: 22| Step: 0
Training loss: 3.0181232441486077
Validation loss: 2.6329772153766275

Epoch: 6| Step: 1
Training loss: 3.1912290414195916
Validation loss: 2.639622133243743

Epoch: 6| Step: 2
Training loss: 2.2508462797845006
Validation loss: 2.631630353976019

Epoch: 6| Step: 3
Training loss: 3.0170262693197794
Validation loss: 2.6383455518789245

Epoch: 6| Step: 4
Training loss: 2.8158962512844905
Validation loss: 2.636988290418934

Epoch: 6| Step: 5
Training loss: 2.548812784316861
Validation loss: 2.6474300763446563

Epoch: 6| Step: 6
Training loss: 3.0628060946958517
Validation loss: 2.631742678580522

Epoch: 6| Step: 7
Training loss: 3.397701350316473
Validation loss: 2.6365049739027686

Epoch: 6| Step: 8
Training loss: 2.483522472816753
Validation loss: 2.6345144005961574

Epoch: 6| Step: 9
Training loss: 3.293041441127548
Validation loss: 2.6266168536115457

Epoch: 6| Step: 10
Training loss: 3.4248841871743108
Validation loss: 2.629544572017688

Epoch: 6| Step: 11
Training loss: 3.167309712487766
Validation loss: 2.6358604526048324

Epoch: 6| Step: 12
Training loss: 2.851946410372523
Validation loss: 2.636985138593066

Epoch: 6| Step: 13
Training loss: 3.113077384371681
Validation loss: 2.6283939632028592

Epoch: 23| Step: 0
Training loss: 2.778991296392856
Validation loss: 2.6293396273718836

Epoch: 6| Step: 1
Training loss: 2.6545449562713612
Validation loss: 2.6409181375225828

Epoch: 6| Step: 2
Training loss: 3.4007151019978217
Validation loss: 2.6255963512902194

Epoch: 6| Step: 3
Training loss: 3.263124667761113
Validation loss: 2.620621214330317

Epoch: 6| Step: 4
Training loss: 2.2329690417865513
Validation loss: 2.6288712166459205

Epoch: 6| Step: 5
Training loss: 3.681718334723643
Validation loss: 2.625684408687476

Epoch: 6| Step: 6
Training loss: 2.7638331928956665
Validation loss: 2.6223385010054865

Epoch: 6| Step: 7
Training loss: 3.1329549628611653
Validation loss: 2.604452928786067

Epoch: 6| Step: 8
Training loss: 3.228315639128976
Validation loss: 2.6176537989869915

Epoch: 6| Step: 9
Training loss: 2.64746850215629
Validation loss: 2.615713146920553

Epoch: 6| Step: 10
Training loss: 2.783184278993211
Validation loss: 2.6094612557789527

Epoch: 6| Step: 11
Training loss: 2.99103095509164
Validation loss: 2.613514804959944

Epoch: 6| Step: 12
Training loss: 2.6851263875357927
Validation loss: 2.6134820362471736

Epoch: 6| Step: 13
Training loss: 3.178048576103769
Validation loss: 2.6117077571741634

Epoch: 24| Step: 0
Training loss: 2.980188759067595
Validation loss: 2.619784872796112

Epoch: 6| Step: 1
Training loss: 3.0053932666347993
Validation loss: 2.6208452089441265

Epoch: 6| Step: 2
Training loss: 2.6266568722356736
Validation loss: 2.6041821649561925

Epoch: 6| Step: 3
Training loss: 2.248657885918361
Validation loss: 2.619227546766157

Epoch: 6| Step: 4
Training loss: 3.48300540846767
Validation loss: 2.615234188748342

Epoch: 6| Step: 5
Training loss: 2.7005965033106754
Validation loss: 2.608048880475661

Epoch: 6| Step: 6
Training loss: 3.599285870823159
Validation loss: 2.626558360828277

Epoch: 6| Step: 7
Training loss: 3.090839596849398
Validation loss: 2.6231803652082766

Epoch: 6| Step: 8
Training loss: 3.4744776271396742
Validation loss: 2.614205171320464

Epoch: 6| Step: 9
Training loss: 2.8909750236770315
Validation loss: 2.6094506434342035

Epoch: 6| Step: 10
Training loss: 2.8116670010726117
Validation loss: 2.6243580249485436

Epoch: 6| Step: 11
Training loss: 2.6601648540609752
Validation loss: 2.6214250968547606

Epoch: 6| Step: 12
Training loss: 1.973657335131855
Validation loss: 2.624955807346571

Epoch: 6| Step: 13
Training loss: 3.831681075122275
Validation loss: 2.6110669283364065

Epoch: 25| Step: 0
Training loss: 3.004403220786739
Validation loss: 2.6010850579559484

Epoch: 6| Step: 1
Training loss: 2.8637192041214012
Validation loss: 2.6062303978848833

Epoch: 6| Step: 2
Training loss: 3.025358787255815
Validation loss: 2.602651740349248

Epoch: 6| Step: 3
Training loss: 2.6999369437307363
Validation loss: 2.601214714913405

Epoch: 6| Step: 4
Training loss: 3.0765559656045705
Validation loss: 2.606068074917442

Epoch: 6| Step: 5
Training loss: 3.243132157184601
Validation loss: 2.6112262460736644

Epoch: 6| Step: 6
Training loss: 3.0028895131967137
Validation loss: 2.601547115523962

Epoch: 6| Step: 7
Training loss: 3.254388633774195
Validation loss: 2.605131293694712

Epoch: 6| Step: 8
Training loss: 2.6556746813480516
Validation loss: 2.6108752972698133

Epoch: 6| Step: 9
Training loss: 2.9281915125829445
Validation loss: 2.6073990939481178

Epoch: 6| Step: 10
Training loss: 2.150873086772065
Validation loss: 2.5981547028310814

Epoch: 6| Step: 11
Training loss: 3.4299237076529594
Validation loss: 2.6040207450756068

Epoch: 6| Step: 12
Training loss: 3.1351931841889837
Validation loss: 2.6097022795676024

Epoch: 6| Step: 13
Training loss: 2.2268042717557086
Validation loss: 2.597597474191867

Epoch: 26| Step: 0
Training loss: 1.8835788291109172
Validation loss: 2.592791919407935

Epoch: 6| Step: 1
Training loss: 3.0071310485152347
Validation loss: 2.601983625048663

Epoch: 6| Step: 2
Training loss: 2.8097972174949533
Validation loss: 2.594668256339731

Epoch: 6| Step: 3
Training loss: 2.798559267769708
Validation loss: 2.593959930815888

Epoch: 6| Step: 4
Training loss: 2.3163014688964845
Validation loss: 2.594150077959398

Epoch: 6| Step: 5
Training loss: 2.6269536695515234
Validation loss: 2.592471113238334

Epoch: 6| Step: 6
Training loss: 2.4110783276865955
Validation loss: 2.5886003057589466

Epoch: 6| Step: 7
Training loss: 3.0809314926836433
Validation loss: 2.592307747232917

Epoch: 6| Step: 8
Training loss: 2.7877740528545867
Validation loss: 2.586681059178961

Epoch: 6| Step: 9
Training loss: 3.823359048940376
Validation loss: 2.592349246840606

Epoch: 6| Step: 10
Training loss: 3.397921117377782
Validation loss: 2.5921821644473377

Epoch: 6| Step: 11
Training loss: 3.3374008792631207
Validation loss: 2.5903933169402706

Epoch: 6| Step: 12
Training loss: 3.140301891805896
Validation loss: 2.587281589644014

Epoch: 6| Step: 13
Training loss: 3.3955198896103886
Validation loss: 2.5945455826188946

Epoch: 27| Step: 0
Training loss: 2.907129626312623
Validation loss: 2.6017562871391866

Epoch: 6| Step: 1
Training loss: 2.3956561036831348
Validation loss: 2.6107160916637686

Epoch: 6| Step: 2
Training loss: 2.8153572827415854
Validation loss: 2.599094632336018

Epoch: 6| Step: 3
Training loss: 2.5513274234609917
Validation loss: 2.5903685690753266

Epoch: 6| Step: 4
Training loss: 2.7935385809658557
Validation loss: 2.6008880774765553

Epoch: 6| Step: 5
Training loss: 2.5849657336090752
Validation loss: 2.5853316596160307

Epoch: 6| Step: 6
Training loss: 3.300452149366627
Validation loss: 2.591687617635848

Epoch: 6| Step: 7
Training loss: 2.9580792241813274
Validation loss: 2.579929115584472

Epoch: 6| Step: 8
Training loss: 3.18288806044675
Validation loss: 2.6070418085113474

Epoch: 6| Step: 9
Training loss: 3.30681799352634
Validation loss: 2.60256638479002

Epoch: 6| Step: 10
Training loss: 3.8143548674460757
Validation loss: 2.5838115903081627

Epoch: 6| Step: 11
Training loss: 2.8443012751205425
Validation loss: 2.5805558871778578

Epoch: 6| Step: 12
Training loss: 2.673323210921431
Validation loss: 2.5970830010508705

Epoch: 6| Step: 13
Training loss: 2.567148504814294
Validation loss: 2.5961781174446887

Epoch: 28| Step: 0
Training loss: 3.13110381068773
Validation loss: 2.5971649990855985

Epoch: 6| Step: 1
Training loss: 2.857532845856531
Validation loss: 2.5934050234585446

Epoch: 6| Step: 2
Training loss: 2.8953821576339656
Validation loss: 2.6054743358556305

Epoch: 6| Step: 3
Training loss: 3.090348656992823
Validation loss: 2.574725659271264

Epoch: 6| Step: 4
Training loss: 3.0794346535759662
Validation loss: 2.575094678097761

Epoch: 6| Step: 5
Training loss: 2.5849479326209983
Validation loss: 2.5848295627013007

Epoch: 6| Step: 6
Training loss: 2.7508649332827213
Validation loss: 2.588780586205105

Epoch: 6| Step: 7
Training loss: 2.521983764269463
Validation loss: 2.588297650552462

Epoch: 6| Step: 8
Training loss: 3.294225125001984
Validation loss: 2.5965262424390247

Epoch: 6| Step: 9
Training loss: 3.736944360161112
Validation loss: 2.5854264032373035

Epoch: 6| Step: 10
Training loss: 2.7302676496547407
Validation loss: 2.585677204663736

Epoch: 6| Step: 11
Training loss: 2.687536727299461
Validation loss: 2.5867622145201805

Epoch: 6| Step: 12
Training loss: 2.4848877959373614
Validation loss: 2.585509201284063

Epoch: 6| Step: 13
Training loss: 2.646828762042409
Validation loss: 2.576964526926647

Epoch: 29| Step: 0
Training loss: 3.0375141033583013
Validation loss: 2.5864573083493374

Epoch: 6| Step: 1
Training loss: 3.6407711670966236
Validation loss: 2.5863024935429624

Epoch: 6| Step: 2
Training loss: 3.1434642806004085
Validation loss: 2.5720871871179116

Epoch: 6| Step: 3
Training loss: 3.329015764835669
Validation loss: 2.568598399898288

Epoch: 6| Step: 4
Training loss: 2.6705622431806657
Validation loss: 2.570841996306693

Epoch: 6| Step: 5
Training loss: 2.893400602071442
Validation loss: 2.5727959658906965

Epoch: 6| Step: 6
Training loss: 3.1615559009325898
Validation loss: 2.5861814417486277

Epoch: 6| Step: 7
Training loss: 2.2833367823368205
Validation loss: 2.5870287012154014

Epoch: 6| Step: 8
Training loss: 2.911710470037865
Validation loss: 2.596377827959088

Epoch: 6| Step: 9
Training loss: 2.6772789988773282
Validation loss: 2.584394009622372

Epoch: 6| Step: 10
Training loss: 2.327756916621325
Validation loss: 2.5755782444741664

Epoch: 6| Step: 11
Training loss: 2.823299189664739
Validation loss: 2.569123752602223

Epoch: 6| Step: 12
Training loss: 2.830652108967033
Validation loss: 2.5690607021791956

Epoch: 6| Step: 13
Training loss: 2.687539920953955
Validation loss: 2.5811232960444097

Epoch: 30| Step: 0
Training loss: 3.173076383328336
Validation loss: 2.5787172822347726

Epoch: 6| Step: 1
Training loss: 3.585509031540541
Validation loss: 2.5748640800116003

Epoch: 6| Step: 2
Training loss: 2.885569177078936
Validation loss: 2.573933783493075

Epoch: 6| Step: 3
Training loss: 2.959799354041845
Validation loss: 2.5752327504885324

Epoch: 6| Step: 4
Training loss: 2.7519306861498696
Validation loss: 2.57049059631886

Epoch: 6| Step: 5
Training loss: 2.8273285645337745
Validation loss: 2.5727557641448526

Epoch: 6| Step: 6
Training loss: 3.1319813374904824
Validation loss: 2.571454826596293

Epoch: 6| Step: 7
Training loss: 2.7874871086883104
Validation loss: 2.5680399580327578

Epoch: 6| Step: 8
Training loss: 2.3092429447229423
Validation loss: 2.551996390238996

Epoch: 6| Step: 9
Training loss: 2.9667595866649457
Validation loss: 2.5626394362471263

Epoch: 6| Step: 10
Training loss: 2.649867029272818
Validation loss: 2.5730521372469184

Epoch: 6| Step: 11
Training loss: 3.013599090785048
Validation loss: 2.561607772761607

Epoch: 6| Step: 12
Training loss: 2.7179681815782497
Validation loss: 2.580410394032981

Epoch: 6| Step: 13
Training loss: 2.6473942054885122
Validation loss: 2.5665646784446303

Epoch: 31| Step: 0
Training loss: 2.7581512848245375
Validation loss: 2.574252655873101

Epoch: 6| Step: 1
Training loss: 2.6158288873944797
Validation loss: 2.5845229188259977

Epoch: 6| Step: 2
Training loss: 2.6947275605088934
Validation loss: 2.5709303236702707

Epoch: 6| Step: 3
Training loss: 2.783939218723599
Validation loss: 2.56737779981218

Epoch: 6| Step: 4
Training loss: 2.9979980464773703
Validation loss: 2.5689509947759555

Epoch: 6| Step: 5
Training loss: 2.8270635140796503
Validation loss: 2.5760145372488696

Epoch: 6| Step: 6
Training loss: 2.5104119919433967
Validation loss: 2.5601074250143268

Epoch: 6| Step: 7
Training loss: 3.4797441989234503
Validation loss: 2.5601258363226864

Epoch: 6| Step: 8
Training loss: 2.7492240331175704
Validation loss: 2.5633527045811015

Epoch: 6| Step: 9
Training loss: 3.1897214740428694
Validation loss: 2.5555855429900594

Epoch: 6| Step: 10
Training loss: 2.617093485951349
Validation loss: 2.5521919972379905

Epoch: 6| Step: 11
Training loss: 3.156085774898722
Validation loss: 2.5726298557254847

Epoch: 6| Step: 12
Training loss: 2.7197935359796954
Validation loss: 2.5616486098184783

Epoch: 6| Step: 13
Training loss: 3.610709996239094
Validation loss: 2.5660069576548876

Epoch: 32| Step: 0
Training loss: 2.8779315100626226
Validation loss: 2.5617232297143953

Epoch: 6| Step: 1
Training loss: 2.8483967805882537
Validation loss: 2.5712641596747354

Epoch: 6| Step: 2
Training loss: 2.5177232983078266
Validation loss: 2.5634693310269867

Epoch: 6| Step: 3
Training loss: 2.8374713711407655
Validation loss: 2.562010163261183

Epoch: 6| Step: 4
Training loss: 3.245834468764636
Validation loss: 2.5543175151846715

Epoch: 6| Step: 5
Training loss: 2.760447164882868
Validation loss: 2.5693768482874746

Epoch: 6| Step: 6
Training loss: 2.2914966751397468
Validation loss: 2.5570166431400794

Epoch: 6| Step: 7
Training loss: 3.2490480936282666
Validation loss: 2.5647479166233174

Epoch: 6| Step: 8
Training loss: 2.8883717595747243
Validation loss: 2.568697234858509

Epoch: 6| Step: 9
Training loss: 3.826803921443301
Validation loss: 2.560286160116473

Epoch: 6| Step: 10
Training loss: 2.8300208381451784
Validation loss: 2.5515082365330706

Epoch: 6| Step: 11
Training loss: 2.788251999487579
Validation loss: 2.5574543036187367

Epoch: 6| Step: 12
Training loss: 2.7601388083672673
Validation loss: 2.5645577986890586

Epoch: 6| Step: 13
Training loss: 2.182847443111841
Validation loss: 2.5395909074916707

Epoch: 33| Step: 0
Training loss: 3.180718781911487
Validation loss: 2.549071907967519

Epoch: 6| Step: 1
Training loss: 2.3345742218513346
Validation loss: 2.568287821705301

Epoch: 6| Step: 2
Training loss: 2.8355287199467876
Validation loss: 2.553050994412986

Epoch: 6| Step: 3
Training loss: 2.4657359012470264
Validation loss: 2.5538674409044493

Epoch: 6| Step: 4
Training loss: 2.959073489014951
Validation loss: 2.551417627123863

Epoch: 6| Step: 5
Training loss: 3.3965691703403085
Validation loss: 2.5555691835356034

Epoch: 6| Step: 6
Training loss: 3.1883981972567383
Validation loss: 2.5576032457048945

Epoch: 6| Step: 7
Training loss: 3.5529158316771903
Validation loss: 2.559870880095132

Epoch: 6| Step: 8
Training loss: 2.477855838045907
Validation loss: 2.54879871791958

Epoch: 6| Step: 9
Training loss: 3.312334308438962
Validation loss: 2.551187883450202

Epoch: 6| Step: 10
Training loss: 2.7622908845351772
Validation loss: 2.557358561795957

Epoch: 6| Step: 11
Training loss: 1.9785205053964054
Validation loss: 2.5448838188455007

Epoch: 6| Step: 12
Training loss: 3.2854841252385962
Validation loss: 2.553871845692743

Epoch: 6| Step: 13
Training loss: 1.7847574736020149
Validation loss: 2.5530628152139654

Epoch: 34| Step: 0
Training loss: 2.577637042482576
Validation loss: 2.5505077836900143

Epoch: 6| Step: 1
Training loss: 2.995883501576303
Validation loss: 2.544499866918319

Epoch: 6| Step: 2
Training loss: 3.216702300617186
Validation loss: 2.547275703193693

Epoch: 6| Step: 3
Training loss: 2.318716611390445
Validation loss: 2.5427767909538264

Epoch: 6| Step: 4
Training loss: 3.0749470527866665
Validation loss: 2.548860553162231

Epoch: 6| Step: 5
Training loss: 2.6446459250893675
Validation loss: 2.550645661292783

Epoch: 6| Step: 6
Training loss: 2.6715573127563252
Validation loss: 2.5454204690654203

Epoch: 6| Step: 7
Training loss: 2.508254443054918
Validation loss: 2.54504562055796

Epoch: 6| Step: 8
Training loss: 2.7665942374097785
Validation loss: 2.559814952244878

Epoch: 6| Step: 9
Training loss: 3.0215604411280026
Validation loss: 2.5340582349093497

Epoch: 6| Step: 10
Training loss: 2.955161063876578
Validation loss: 2.553056018661748

Epoch: 6| Step: 11
Training loss: 3.3720670601182547
Validation loss: 2.5539174601013035

Epoch: 6| Step: 12
Training loss: 2.8273412134728884
Validation loss: 2.5507584535501935

Epoch: 6| Step: 13
Training loss: 3.221430874987731
Validation loss: 2.545834163875561

Epoch: 35| Step: 0
Training loss: 3.3447071737576723
Validation loss: 2.54636757735234

Epoch: 6| Step: 1
Training loss: 2.658313443419409
Validation loss: 2.546804169807935

Epoch: 6| Step: 2
Training loss: 2.795737178947402
Validation loss: 2.545567278256086

Epoch: 6| Step: 3
Training loss: 2.707405537853339
Validation loss: 2.547900042623315

Epoch: 6| Step: 4
Training loss: 3.2459502297450484
Validation loss: 2.5618153824813046

Epoch: 6| Step: 5
Training loss: 3.3005538591238803
Validation loss: 2.539393488889875

Epoch: 6| Step: 6
Training loss: 2.522747689554262
Validation loss: 2.549007016378535

Epoch: 6| Step: 7
Training loss: 2.422127987353596
Validation loss: 2.551733919642014

Epoch: 6| Step: 8
Training loss: 2.9515841869488466
Validation loss: 2.5380775226054433

Epoch: 6| Step: 9
Training loss: 2.587153215251426
Validation loss: 2.545600155828183

Epoch: 6| Step: 10
Training loss: 2.5291665062021855
Validation loss: 2.540944393366735

Epoch: 6| Step: 11
Training loss: 2.9193994163124257
Validation loss: 2.5520265249359055

Epoch: 6| Step: 12
Training loss: 2.980269079157063
Validation loss: 2.552148029511049

Epoch: 6| Step: 13
Training loss: 3.218656964485233
Validation loss: 2.546886755853696

Epoch: 36| Step: 0
Training loss: 3.7112962408837236
Validation loss: 2.54825537169667

Epoch: 6| Step: 1
Training loss: 3.0378205181291094
Validation loss: 2.548820774518971

Epoch: 6| Step: 2
Training loss: 2.633062424385888
Validation loss: 2.5341383824967614

Epoch: 6| Step: 3
Training loss: 3.4354294523175097
Validation loss: 2.5351473672895977

Epoch: 6| Step: 4
Training loss: 2.4649947372597
Validation loss: 2.5393664782787626

Epoch: 6| Step: 5
Training loss: 2.0288174662298473
Validation loss: 2.550960249624478

Epoch: 6| Step: 6
Training loss: 2.7832219708791768
Validation loss: 2.5399556209565244

Epoch: 6| Step: 7
Training loss: 2.4883928738024608
Validation loss: 2.532394804566592

Epoch: 6| Step: 8
Training loss: 3.3514372973409206
Validation loss: 2.53464799544638

Epoch: 6| Step: 9
Training loss: 2.1781894362344363
Validation loss: 2.5296588101074056

Epoch: 6| Step: 10
Training loss: 3.230373985441226
Validation loss: 2.5479646806820737

Epoch: 6| Step: 11
Training loss: 3.1154535581200267
Validation loss: 2.5428592113966166

Epoch: 6| Step: 12
Training loss: 2.5720571608710103
Validation loss: 2.5368016064116223

Epoch: 6| Step: 13
Training loss: 2.275298729870464
Validation loss: 2.547167748796681

Epoch: 37| Step: 0
Training loss: 2.2545565984190445
Validation loss: 2.5447191014025266

Epoch: 6| Step: 1
Training loss: 2.930792109467339
Validation loss: 2.536940247107133

Epoch: 6| Step: 2
Training loss: 2.5620680654330052
Validation loss: 2.531212708565521

Epoch: 6| Step: 3
Training loss: 2.7454040442604173
Validation loss: 2.5234079514478993

Epoch: 6| Step: 4
Training loss: 2.0058829093525663
Validation loss: 2.535525507190943

Epoch: 6| Step: 5
Training loss: 2.605766405206383
Validation loss: 2.542121917713463

Epoch: 6| Step: 6
Training loss: 2.6180555128327447
Validation loss: 2.546107801899977

Epoch: 6| Step: 7
Training loss: 3.481902335666822
Validation loss: 2.5259047279668234

Epoch: 6| Step: 8
Training loss: 3.1995682484709613
Validation loss: 2.535381005385109

Epoch: 6| Step: 9
Training loss: 3.269059852516613
Validation loss: 2.5365119319125324

Epoch: 6| Step: 10
Training loss: 2.6212210020281366
Validation loss: 2.529139495842596

Epoch: 6| Step: 11
Training loss: 3.000164027498252
Validation loss: 2.538730622744718

Epoch: 6| Step: 12
Training loss: 3.2404662929359866
Validation loss: 2.5302582092507007

Epoch: 6| Step: 13
Training loss: 3.407026289927741
Validation loss: 2.52052741625493

Epoch: 38| Step: 0
Training loss: 2.9819271574174233
Validation loss: 2.5247917527622765

Epoch: 6| Step: 1
Training loss: 2.2654566208982847
Validation loss: 2.534655029991575

Epoch: 6| Step: 2
Training loss: 3.411816449575754
Validation loss: 2.538601704852529

Epoch: 6| Step: 3
Training loss: 2.932722223809955
Validation loss: 2.5383681056598575

Epoch: 6| Step: 4
Training loss: 3.028707952455484
Validation loss: 2.5418570749933447

Epoch: 6| Step: 5
Training loss: 2.8286916259999852
Validation loss: 2.545223474427201

Epoch: 6| Step: 6
Training loss: 2.085176021729451
Validation loss: 2.5441209296743237

Epoch: 6| Step: 7
Training loss: 2.6268680828184023
Validation loss: 2.527387850003359

Epoch: 6| Step: 8
Training loss: 2.642441344968073
Validation loss: 2.536867572670768

Epoch: 6| Step: 9
Training loss: 3.2444846965812766
Validation loss: 2.540878946118378

Epoch: 6| Step: 10
Training loss: 2.813054771809543
Validation loss: 2.529109596283896

Epoch: 6| Step: 11
Training loss: 3.3054671574018264
Validation loss: 2.546014199037723

Epoch: 6| Step: 12
Training loss: 2.2804173034113195
Validation loss: 2.5326096906066975

Epoch: 6| Step: 13
Training loss: 3.363978155330533
Validation loss: 2.5313376276447457

Epoch: 39| Step: 0
Training loss: 3.198933161283825
Validation loss: 2.523851547679644

Epoch: 6| Step: 1
Training loss: 2.6430383973581746
Validation loss: 2.5477910189063024

Epoch: 6| Step: 2
Training loss: 2.494474025778421
Validation loss: 2.5384502582085244

Epoch: 6| Step: 3
Training loss: 2.3756859441304865
Validation loss: 2.541813603240092

Epoch: 6| Step: 4
Training loss: 2.955401799338328
Validation loss: 2.530316309139584

Epoch: 6| Step: 5
Training loss: 2.955299827997873
Validation loss: 2.522677228655533

Epoch: 6| Step: 6
Training loss: 3.2093825833269096
Validation loss: 2.5395170899402717

Epoch: 6| Step: 7
Training loss: 2.648689190543237
Validation loss: 2.537208293807877

Epoch: 6| Step: 8
Training loss: 3.2861109014406957
Validation loss: 2.5373562904510765

Epoch: 6| Step: 9
Training loss: 2.716059087512256
Validation loss: 2.5405762789735378

Epoch: 6| Step: 10
Training loss: 2.7360261999682756
Validation loss: 2.538984377836884

Epoch: 6| Step: 11
Training loss: 2.7276997203064997
Validation loss: 2.5328990750552554

Epoch: 6| Step: 12
Training loss: 2.592614166482849
Validation loss: 2.541015896395141

Epoch: 6| Step: 13
Training loss: 3.5661257312836354
Validation loss: 2.531941092543924

Epoch: 40| Step: 0
Training loss: 2.785830722373616
Validation loss: 2.5119066945870445

Epoch: 6| Step: 1
Training loss: 3.057260507731356
Validation loss: 2.538317312433876

Epoch: 6| Step: 2
Training loss: 2.3333261239984946
Validation loss: 2.5182797291481887

Epoch: 6| Step: 3
Training loss: 2.5224520527693897
Validation loss: 2.514405451423575

Epoch: 6| Step: 4
Training loss: 2.757604834326747
Validation loss: 2.538263907348833

Epoch: 6| Step: 5
Training loss: 2.822089567929931
Validation loss: 2.5291595324138463

Epoch: 6| Step: 6
Training loss: 3.0820560043365837
Validation loss: 2.53417291162376

Epoch: 6| Step: 7
Training loss: 3.3833127257623077
Validation loss: 2.528604289235166

Epoch: 6| Step: 8
Training loss: 2.695313207653893
Validation loss: 2.542352793243221

Epoch: 6| Step: 9
Training loss: 3.0163842070751503
Validation loss: 2.5361048907479935

Epoch: 6| Step: 10
Training loss: 2.321319977871803
Validation loss: 2.540135564103736

Epoch: 6| Step: 11
Training loss: 2.4742056525570018
Validation loss: 2.5455507164438105

Epoch: 6| Step: 12
Training loss: 2.9796581440896284
Validation loss: 2.5326993523265595

Epoch: 6| Step: 13
Training loss: 3.7898856930366884
Validation loss: 2.5333040856949025

Epoch: 41| Step: 0
Training loss: 2.713599928647166
Validation loss: 2.53012241744241

Epoch: 6| Step: 1
Training loss: 2.9002350942095316
Validation loss: 2.5332052502314997

Epoch: 6| Step: 2
Training loss: 2.5091477876745016
Validation loss: 2.526199299027815

Epoch: 6| Step: 3
Training loss: 3.213356907179008
Validation loss: 2.5128658487682474

Epoch: 6| Step: 4
Training loss: 2.821868889718606
Validation loss: 2.531756531797774

Epoch: 6| Step: 5
Training loss: 3.167520775971475
Validation loss: 2.524375904353644

Epoch: 6| Step: 6
Training loss: 2.4573865673006967
Validation loss: 2.518068392051119

Epoch: 6| Step: 7
Training loss: 3.1574831527055123
Validation loss: 2.5202725891147586

Epoch: 6| Step: 8
Training loss: 2.438536105882208
Validation loss: 2.526387069492441

Epoch: 6| Step: 9
Training loss: 2.824064596145188
Validation loss: 2.5168966000318838

Epoch: 6| Step: 10
Training loss: 2.847001784146885
Validation loss: 2.5205631590998028

Epoch: 6| Step: 11
Training loss: 2.8841139587447593
Validation loss: 2.535136331611156

Epoch: 6| Step: 12
Training loss: 2.9635186934739965
Validation loss: 2.5302754547548925

Epoch: 6| Step: 13
Training loss: 2.6478678673049942
Validation loss: 2.515990599415039

Epoch: 42| Step: 0
Training loss: 1.6762760027775239
Validation loss: 2.521377741308113

Epoch: 6| Step: 1
Training loss: 2.867982011108166
Validation loss: 2.5193728456387676

Epoch: 6| Step: 2
Training loss: 2.638297053666207
Validation loss: 2.52102841163387

Epoch: 6| Step: 3
Training loss: 3.4436521097383332
Validation loss: 2.5290726493598883

Epoch: 6| Step: 4
Training loss: 3.0559958073352593
Validation loss: 2.524776778806298

Epoch: 6| Step: 5
Training loss: 2.5981468712549365
Validation loss: 2.5205100496385033

Epoch: 6| Step: 6
Training loss: 2.8009188098192386
Validation loss: 2.5032771626980623

Epoch: 6| Step: 7
Training loss: 3.1785277705003296
Validation loss: 2.5088856073526737

Epoch: 6| Step: 8
Training loss: 2.3956804862539616
Validation loss: 2.530262121186963

Epoch: 6| Step: 9
Training loss: 3.0463138943977333
Validation loss: 2.510028777657574

Epoch: 6| Step: 10
Training loss: 2.842345341456611
Validation loss: 2.520179869946318

Epoch: 6| Step: 11
Training loss: 3.234399178087468
Validation loss: 2.5181597036137533

Epoch: 6| Step: 12
Training loss: 2.971962886758271
Validation loss: 2.5273856387325284

Epoch: 6| Step: 13
Training loss: 2.3350180152671873
Validation loss: 2.517468932750192

Epoch: 43| Step: 0
Training loss: 2.5806760246792404
Validation loss: 2.531588494402678

Epoch: 6| Step: 1
Training loss: 2.8335732938092777
Validation loss: 2.5140400416199875

Epoch: 6| Step: 2
Training loss: 3.0317976938558626
Validation loss: 2.5155167028644065

Epoch: 6| Step: 3
Training loss: 3.194081412064278
Validation loss: 2.521157098404881

Epoch: 6| Step: 4
Training loss: 2.6808396245447614
Validation loss: 2.518017448961375

Epoch: 6| Step: 5
Training loss: 3.1281836505158997
Validation loss: 2.5279125136546017

Epoch: 6| Step: 6
Training loss: 2.226328733787958
Validation loss: 2.5269526153464468

Epoch: 6| Step: 7
Training loss: 2.609572534451004
Validation loss: 2.5254920421574387

Epoch: 6| Step: 8
Training loss: 2.907367122431346
Validation loss: 2.5306417062702966

Epoch: 6| Step: 9
Training loss: 3.0326074136829684
Validation loss: 2.518455295598943

Epoch: 6| Step: 10
Training loss: 2.572669157614997
Validation loss: 2.532290001072067

Epoch: 6| Step: 11
Training loss: 3.1755301926441404
Validation loss: 2.5211820040087325

Epoch: 6| Step: 12
Training loss: 2.5354166470237445
Validation loss: 2.5399884308714715

Epoch: 6| Step: 13
Training loss: 2.9496510574089325
Validation loss: 2.5238470336149468

Epoch: 44| Step: 0
Training loss: 2.614814616355292
Validation loss: 2.5229213487313027

Epoch: 6| Step: 1
Training loss: 3.9545222892600926
Validation loss: 2.5345753599706673

Epoch: 6| Step: 2
Training loss: 2.7077318746336805
Validation loss: 2.5210636989280095

Epoch: 6| Step: 3
Training loss: 2.4480155654300173
Validation loss: 2.508606326166533

Epoch: 6| Step: 4
Training loss: 3.04534372829438
Validation loss: 2.5252837095718554

Epoch: 6| Step: 5
Training loss: 2.3181245808666566
Validation loss: 2.5194672520681314

Epoch: 6| Step: 6
Training loss: 3.0064968650163313
Validation loss: 2.5271929332495637

Epoch: 6| Step: 7
Training loss: 2.6990919952883305
Validation loss: 2.5193688007909696

Epoch: 6| Step: 8
Training loss: 2.728848611095722
Validation loss: 2.522750523761482

Epoch: 6| Step: 9
Training loss: 3.059764964233779
Validation loss: 2.5222084300433405

Epoch: 6| Step: 10
Training loss: 2.44303285656764
Validation loss: 2.5162122052950555

Epoch: 6| Step: 11
Training loss: 2.8184901555437394
Validation loss: 2.5252269111302534

Epoch: 6| Step: 12
Training loss: 2.7818385155195875
Validation loss: 2.515922769777562

Epoch: 6| Step: 13
Training loss: 2.1607804181315737
Validation loss: 2.5170667579522936

Epoch: 45| Step: 0
Training loss: 1.95803039994375
Validation loss: 2.5100110611007773

Epoch: 6| Step: 1
Training loss: 3.28200994501461
Validation loss: 2.5176076187629497

Epoch: 6| Step: 2
Training loss: 2.7993676357082995
Validation loss: 2.518871805949699

Epoch: 6| Step: 3
Training loss: 3.3926862085636262
Validation loss: 2.5168444985115315

Epoch: 6| Step: 4
Training loss: 2.1020866789726598
Validation loss: 2.5097329603428244

Epoch: 6| Step: 5
Training loss: 2.484296497568193
Validation loss: 2.5180158576413545

Epoch: 6| Step: 6
Training loss: 2.139625928752555
Validation loss: 2.502742505919221

Epoch: 6| Step: 7
Training loss: 3.0221581721842745
Validation loss: 2.5155964460403952

Epoch: 6| Step: 8
Training loss: 2.823332630399086
Validation loss: 2.510285231902034

Epoch: 6| Step: 9
Training loss: 2.837200965752754
Validation loss: 2.503923913509664

Epoch: 6| Step: 10
Training loss: 3.1640121644337227
Validation loss: 2.5204575198411514

Epoch: 6| Step: 11
Training loss: 2.27012555585978
Validation loss: 2.5199070025715558

Epoch: 6| Step: 12
Training loss: 2.714119838005712
Validation loss: 2.5077207707812694

Epoch: 6| Step: 13
Training loss: 4.408287713452378
Validation loss: 2.508344234379771

Epoch: 46| Step: 0
Training loss: 2.4178528888904043
Validation loss: 2.5259977789566483

Epoch: 6| Step: 1
Training loss: 2.7479811106758625
Validation loss: 2.5103152749935376

Epoch: 6| Step: 2
Training loss: 3.0949051367006035
Validation loss: 2.5245931575998517

Epoch: 6| Step: 3
Training loss: 2.4567201353730472
Validation loss: 2.5089012769815566

Epoch: 6| Step: 4
Training loss: 2.578913065367727
Validation loss: 2.511810145419087

Epoch: 6| Step: 5
Training loss: 3.3984508294907414
Validation loss: 2.5132561303745677

Epoch: 6| Step: 6
Training loss: 2.8199072042036817
Validation loss: 2.5118159681333956

Epoch: 6| Step: 7
Training loss: 2.724865579351963
Validation loss: 2.508118976794004

Epoch: 6| Step: 8
Training loss: 2.8044380778391385
Validation loss: 2.5128624157729544

Epoch: 6| Step: 9
Training loss: 2.8372379400427397
Validation loss: 2.5244428498165576

Epoch: 6| Step: 10
Training loss: 2.5917306415802277
Validation loss: 2.4998578461870453

Epoch: 6| Step: 11
Training loss: 2.9039093764695973
Validation loss: 2.504980460705939

Epoch: 6| Step: 12
Training loss: 2.7337267297941317
Validation loss: 2.5190769796862598

Epoch: 6| Step: 13
Training loss: 3.4151451785950986
Validation loss: 2.510353732648844

Epoch: 47| Step: 0
Training loss: 2.9947820425569995
Validation loss: 2.5247439296140723

Epoch: 6| Step: 1
Training loss: 2.3342088918556265
Validation loss: 2.5198009156190553

Epoch: 6| Step: 2
Training loss: 3.0365181988441337
Validation loss: 2.5101223834701094

Epoch: 6| Step: 3
Training loss: 2.5560291745187906
Validation loss: 2.5154905589652627

Epoch: 6| Step: 4
Training loss: 2.738045109513084
Validation loss: 2.5029513790986044

Epoch: 6| Step: 5
Training loss: 2.5676675191012293
Validation loss: 2.515713834280035

Epoch: 6| Step: 6
Training loss: 2.5418965178405015
Validation loss: 2.5207402913770984

Epoch: 6| Step: 7
Training loss: 3.3035826222587263
Validation loss: 2.5150751822447104

Epoch: 6| Step: 8
Training loss: 3.0443389510775325
Validation loss: 2.5105500221361954

Epoch: 6| Step: 9
Training loss: 2.445788059974528
Validation loss: 2.5131734087711326

Epoch: 6| Step: 10
Training loss: 2.2695745309717728
Validation loss: 2.503054367071951

Epoch: 6| Step: 11
Training loss: 2.749200964932749
Validation loss: 2.5118497906411417

Epoch: 6| Step: 12
Training loss: 3.70925768929456
Validation loss: 2.505200793809444

Epoch: 6| Step: 13
Training loss: 2.714787983493113
Validation loss: 2.529559369057865

Epoch: 48| Step: 0
Training loss: 3.020342679571074
Validation loss: 2.5129464774098267

Epoch: 6| Step: 1
Training loss: 2.4780621245250027
Validation loss: 2.5089246570916486

Epoch: 6| Step: 2
Training loss: 3.0738605838350868
Validation loss: 2.5064331775788196

Epoch: 6| Step: 3
Training loss: 2.7565494919597464
Validation loss: 2.5045057107125857

Epoch: 6| Step: 4
Training loss: 3.1998406668573245
Validation loss: 2.5114014367589044

Epoch: 6| Step: 5
Training loss: 3.012113117368558
Validation loss: 2.5014457224307103

Epoch: 6| Step: 6
Training loss: 3.321834583341632
Validation loss: 2.50117963729366

Epoch: 6| Step: 7
Training loss: 2.3731239337732886
Validation loss: 2.5081712442353843

Epoch: 6| Step: 8
Training loss: 2.153672820494519
Validation loss: 2.511315165358565

Epoch: 6| Step: 9
Training loss: 2.6991967560552474
Validation loss: 2.507703228067706

Epoch: 6| Step: 10
Training loss: 2.5091615654994768
Validation loss: 2.494733791042658

Epoch: 6| Step: 11
Training loss: 2.782755412180703
Validation loss: 2.5134695841005765

Epoch: 6| Step: 12
Training loss: 2.550315826155825
Validation loss: 2.503437553235759

Epoch: 6| Step: 13
Training loss: 3.3267151617925146
Validation loss: 2.495948411496682

Epoch: 49| Step: 0
Training loss: 2.0682422579566584
Validation loss: 2.49449302634009

Epoch: 6| Step: 1
Training loss: 3.2539000951885066
Validation loss: 2.5141931636080406

Epoch: 6| Step: 2
Training loss: 2.5000925046972675
Validation loss: 2.51337957706158

Epoch: 6| Step: 3
Training loss: 2.908743660153118
Validation loss: 2.5089610229939567

Epoch: 6| Step: 4
Training loss: 2.5455865701893003
Validation loss: 2.5101754338954803

Epoch: 6| Step: 5
Training loss: 2.4934397454257047
Validation loss: 2.513125201317278

Epoch: 6| Step: 6
Training loss: 3.0937512330332138
Validation loss: 2.513901926690969

Epoch: 6| Step: 7
Training loss: 3.0017064327618526
Validation loss: 2.5004611359119355

Epoch: 6| Step: 8
Training loss: 2.8518658202335208
Validation loss: 2.5291868111694304

Epoch: 6| Step: 9
Training loss: 2.976960243223595
Validation loss: 2.500498305670533

Epoch: 6| Step: 10
Training loss: 2.8193405040337973
Validation loss: 2.5110246166168158

Epoch: 6| Step: 11
Training loss: 2.234205866461112
Validation loss: 2.515978139799602

Epoch: 6| Step: 12
Training loss: 2.649267286093973
Validation loss: 2.518019008718731

Epoch: 6| Step: 13
Training loss: 3.957498295025148
Validation loss: 2.504393312074386

Epoch: 50| Step: 0
Training loss: 2.5486963230708963
Validation loss: 2.5115381294969366

Epoch: 6| Step: 1
Training loss: 3.0019976005163396
Validation loss: 2.4909042710103035

Epoch: 6| Step: 2
Training loss: 2.8484793102818062
Validation loss: 2.492297312308677

Epoch: 6| Step: 3
Training loss: 2.9784858476995133
Validation loss: 2.4999424932900447

Epoch: 6| Step: 4
Training loss: 3.356482675681261
Validation loss: 2.505888339663748

Epoch: 6| Step: 5
Training loss: 2.798761339049649
Validation loss: 2.522947085387287

Epoch: 6| Step: 6
Training loss: 2.460887121260133
Validation loss: 2.5070859449302167

Epoch: 6| Step: 7
Training loss: 3.238894341276831
Validation loss: 2.506610505505947

Epoch: 6| Step: 8
Training loss: 2.634342009676058
Validation loss: 2.507342285055376

Epoch: 6| Step: 9
Training loss: 2.2661134390655246
Validation loss: 2.499179233646532

Epoch: 6| Step: 10
Training loss: 2.9008431951729063
Validation loss: 2.51049827191492

Epoch: 6| Step: 11
Training loss: 1.9238830248749792
Validation loss: 2.5008644762823553

Epoch: 6| Step: 12
Training loss: 3.089504218465799
Validation loss: 2.507931637680593

Epoch: 6| Step: 13
Training loss: 2.6791094720963833
Validation loss: 2.5077548979592232

Epoch: 51| Step: 0
Training loss: 2.9058611209708762
Validation loss: 2.5060704230730626

Epoch: 6| Step: 1
Training loss: 2.7232347527835916
Validation loss: 2.503817166758547

Epoch: 6| Step: 2
Training loss: 3.0385609975432475
Validation loss: 2.513121156614971

Epoch: 6| Step: 3
Training loss: 3.222728751551874
Validation loss: 2.498524468299611

Epoch: 6| Step: 4
Training loss: 3.3346384990081583
Validation loss: 2.5144170470943137

Epoch: 6| Step: 5
Training loss: 2.4172928316805637
Validation loss: 2.505161785288267

Epoch: 6| Step: 6
Training loss: 3.0190032852726105
Validation loss: 2.5016868120211337

Epoch: 6| Step: 7
Training loss: 3.390500677264244
Validation loss: 2.529185564413459

Epoch: 6| Step: 8
Training loss: 2.7663133702041804
Validation loss: 2.498277807272603

Epoch: 6| Step: 9
Training loss: 2.318986507394614
Validation loss: 2.5196257909048994

Epoch: 6| Step: 10
Training loss: 2.3452410214972734
Validation loss: 2.5140564337172426

Epoch: 6| Step: 11
Training loss: 2.6068671504368717
Validation loss: 2.493646064311426

Epoch: 6| Step: 12
Training loss: 2.202573125450168
Validation loss: 2.5153507385575793

Epoch: 6| Step: 13
Training loss: 2.1641714571298905
Validation loss: 2.5072727654402778

Epoch: 52| Step: 0
Training loss: 2.404771623137682
Validation loss: 2.5070716311233325

Epoch: 6| Step: 1
Training loss: 2.8896317708732777
Validation loss: 2.507248619928818

Epoch: 6| Step: 2
Training loss: 2.89323991601265
Validation loss: 2.499043831453539

Epoch: 6| Step: 3
Training loss: 3.022520729669078
Validation loss: 2.4983023324516154

Epoch: 6| Step: 4
Training loss: 2.770741358404082
Validation loss: 2.5084396292222766

Epoch: 6| Step: 5
Training loss: 3.1139832666005076
Validation loss: 2.503805587526896

Epoch: 6| Step: 6
Training loss: 2.6569636564285237
Validation loss: 2.491482478888934

Epoch: 6| Step: 7
Training loss: 2.086682590184174
Validation loss: 2.5182254440562266

Epoch: 6| Step: 8
Training loss: 2.8398654102617042
Validation loss: 2.4995770691430343

Epoch: 6| Step: 9
Training loss: 3.0677404914729114
Validation loss: 2.4964019879324995

Epoch: 6| Step: 10
Training loss: 2.6464076182365317
Validation loss: 2.50309325378286

Epoch: 6| Step: 11
Training loss: 2.8707687090136425
Validation loss: 2.4961894158211657

Epoch: 6| Step: 12
Training loss: 2.6336929252824097
Validation loss: 2.5028723807475717

Epoch: 6| Step: 13
Training loss: 3.0651713028747345
Validation loss: 2.500974493936456

Epoch: 53| Step: 0
Training loss: 2.793770713644024
Validation loss: 2.498445436687885

Epoch: 6| Step: 1
Training loss: 2.3396100929022987
Validation loss: 2.495182117180594

Epoch: 6| Step: 2
Training loss: 2.5181818697622336
Validation loss: 2.5176950858394003

Epoch: 6| Step: 3
Training loss: 2.789455354094299
Validation loss: 2.4877120406400586

Epoch: 6| Step: 4
Training loss: 3.428898679351619
Validation loss: 2.496188385718213

Epoch: 6| Step: 5
Training loss: 2.3528309186178262
Validation loss: 2.5093690176011227

Epoch: 6| Step: 6
Training loss: 2.496115336675534
Validation loss: 2.5188081261185844

Epoch: 6| Step: 7
Training loss: 3.438592494406735
Validation loss: 2.5058641363095537

Epoch: 6| Step: 8
Training loss: 3.0092329362114665
Validation loss: 2.5010412211616204

Epoch: 6| Step: 9
Training loss: 3.2441484151490605
Validation loss: 2.511855348923928

Epoch: 6| Step: 10
Training loss: 2.9111925980840994
Validation loss: 2.506900418957866

Epoch: 6| Step: 11
Training loss: 2.435457988178531
Validation loss: 2.4988832153306144

Epoch: 6| Step: 12
Training loss: 2.1397547379887065
Validation loss: 2.4966776162389106

Epoch: 6| Step: 13
Training loss: 2.534113077159263
Validation loss: 2.5146335795149057

Epoch: 54| Step: 0
Training loss: 2.596063891642921
Validation loss: 2.4933502018654967

Epoch: 6| Step: 1
Training loss: 1.9490654833515302
Validation loss: 2.507679644885525

Epoch: 6| Step: 2
Training loss: 2.219160444953076
Validation loss: 2.505888803103831

Epoch: 6| Step: 3
Training loss: 3.236315601165795
Validation loss: 2.5045385694470816

Epoch: 6| Step: 4
Training loss: 2.8835539239134578
Validation loss: 2.5098766732789044

Epoch: 6| Step: 5
Training loss: 3.140845447603626
Validation loss: 2.5076406232972697

Epoch: 6| Step: 6
Training loss: 3.014489469053293
Validation loss: 2.5077783991628153

Epoch: 6| Step: 7
Training loss: 2.837453053628019
Validation loss: 2.496204652668236

Epoch: 6| Step: 8
Training loss: 3.0094042244796424
Validation loss: 2.497756835593793

Epoch: 6| Step: 9
Training loss: 2.2791192542054786
Validation loss: 2.5099924588879667

Epoch: 6| Step: 10
Training loss: 3.4259474397581395
Validation loss: 2.5099240208008085

Epoch: 6| Step: 11
Training loss: 2.967933462183697
Validation loss: 2.491175293205648

Epoch: 6| Step: 12
Training loss: 2.6158583269224542
Validation loss: 2.481219618371001

Epoch: 6| Step: 13
Training loss: 2.1545210831452275
Validation loss: 2.498808844652679

Epoch: 55| Step: 0
Training loss: 2.287500050028816
Validation loss: 2.4848837310647416

Epoch: 6| Step: 1
Training loss: 1.6292885164838944
Validation loss: 2.5092775353121652

Epoch: 6| Step: 2
Training loss: 2.539681602706812
Validation loss: 2.4856638574156764

Epoch: 6| Step: 3
Training loss: 3.0837221330080173
Validation loss: 2.5027063436456367

Epoch: 6| Step: 4
Training loss: 3.0275365362002393
Validation loss: 2.493214414215268

Epoch: 6| Step: 5
Training loss: 2.620715504854591
Validation loss: 2.4904391090992

Epoch: 6| Step: 6
Training loss: 2.5318541571089503
Validation loss: 2.4827239430284602

Epoch: 6| Step: 7
Training loss: 3.045922859292123
Validation loss: 2.4881934711993594

Epoch: 6| Step: 8
Training loss: 3.5112699533766754
Validation loss: 2.504462743231235

Epoch: 6| Step: 9
Training loss: 2.2454886243281895
Validation loss: 2.510008622076939

Epoch: 6| Step: 10
Training loss: 3.0105057189512014
Validation loss: 2.5000479457728617

Epoch: 6| Step: 11
Training loss: 2.7033193000244204
Validation loss: 2.4877841884620677

Epoch: 6| Step: 12
Training loss: 2.853998183872043
Validation loss: 2.48562223713785

Epoch: 6| Step: 13
Training loss: 3.6797305224064027
Validation loss: 2.4820592944362283

Epoch: 56| Step: 0
Training loss: 2.3673270911425655
Validation loss: 2.493985146274456

Epoch: 6| Step: 1
Training loss: 3.3394713790953316
Validation loss: 2.4966041892537314

Epoch: 6| Step: 2
Training loss: 2.2624606429412544
Validation loss: 2.506471137879172

Epoch: 6| Step: 3
Training loss: 2.6626702303486094
Validation loss: 2.5068907054536647

Epoch: 6| Step: 4
Training loss: 2.9038395884007735
Validation loss: 2.5049004138570474

Epoch: 6| Step: 5
Training loss: 2.6689320915332986
Validation loss: 2.518724582765454

Epoch: 6| Step: 6
Training loss: 2.472567829401246
Validation loss: 2.5012522668236783

Epoch: 6| Step: 7
Training loss: 2.958110818867207
Validation loss: 2.507379694301176

Epoch: 6| Step: 8
Training loss: 3.642509660256378
Validation loss: 2.496106511200765

Epoch: 6| Step: 9
Training loss: 2.266627964456044
Validation loss: 2.501279377440171

Epoch: 6| Step: 10
Training loss: 3.2821289338537483
Validation loss: 2.5174828279683124

Epoch: 6| Step: 11
Training loss: 2.955073606862045
Validation loss: 2.4922276651583735

Epoch: 6| Step: 12
Training loss: 2.1281288897553017
Validation loss: 2.4913024246232625

Epoch: 6| Step: 13
Training loss: 2.2028759754747824
Validation loss: 2.499729234122371

Epoch: 57| Step: 0
Training loss: 2.790791891645955
Validation loss: 2.498742111163972

Epoch: 6| Step: 1
Training loss: 2.540638783547712
Validation loss: 2.4914493090511582

Epoch: 6| Step: 2
Training loss: 1.975403095105674
Validation loss: 2.4999576554762837

Epoch: 6| Step: 3
Training loss: 2.464352711463808
Validation loss: 2.502254865871383

Epoch: 6| Step: 4
Training loss: 2.8866374787697002
Validation loss: 2.4885949594378656

Epoch: 6| Step: 5
Training loss: 2.4952102554193702
Validation loss: 2.506631498423362

Epoch: 6| Step: 6
Training loss: 2.3680391196099726
Validation loss: 2.489531085316959

Epoch: 6| Step: 7
Training loss: 2.416669111140977
Validation loss: 2.4931720891464964

Epoch: 6| Step: 8
Training loss: 3.078756664546145
Validation loss: 2.5035606827832932

Epoch: 6| Step: 9
Training loss: 2.8322550086711944
Validation loss: 2.49425754091126

Epoch: 6| Step: 10
Training loss: 3.3969056634299806
Validation loss: 2.5020584522699543

Epoch: 6| Step: 11
Training loss: 3.385713597505119
Validation loss: 2.4903583220540675

Epoch: 6| Step: 12
Training loss: 2.9105458658022343
Validation loss: 2.520371267517266

Epoch: 6| Step: 13
Training loss: 3.0665550633177716
Validation loss: 2.508259544258839

Epoch: 58| Step: 0
Training loss: 3.1853498799067386
Validation loss: 2.504114872543521

Epoch: 6| Step: 1
Training loss: 2.922043413010753
Validation loss: 2.509324034934919

Epoch: 6| Step: 2
Training loss: 2.3589032440459503
Validation loss: 2.5014628580911906

Epoch: 6| Step: 3
Training loss: 3.304361241605835
Validation loss: 2.5066757807727393

Epoch: 6| Step: 4
Training loss: 2.6042897818391384
Validation loss: 2.494057322320268

Epoch: 6| Step: 5
Training loss: 2.112302204329909
Validation loss: 2.502476637549495

Epoch: 6| Step: 6
Training loss: 2.422127692053024
Validation loss: 2.5194101535840687

Epoch: 6| Step: 7
Training loss: 2.4480368943145634
Validation loss: 2.504570130868518

Epoch: 6| Step: 8
Training loss: 3.073469950548772
Validation loss: 2.5070734379928745

Epoch: 6| Step: 9
Training loss: 2.5952170026596146
Validation loss: 2.4852953332407375

Epoch: 6| Step: 10
Training loss: 3.2589211898690253
Validation loss: 2.5061361839848417

Epoch: 6| Step: 11
Training loss: 2.912371024358076
Validation loss: 2.4979073903259827

Epoch: 6| Step: 12
Training loss: 2.5199172086588226
Validation loss: 2.498168180883726

Epoch: 6| Step: 13
Training loss: 2.763826378052058
Validation loss: 2.50181660639095

Epoch: 59| Step: 0
Training loss: 2.664255084910359
Validation loss: 2.4977138012803604

Epoch: 6| Step: 1
Training loss: 2.6840002648798302
Validation loss: 2.51743850658811

Epoch: 6| Step: 2
Training loss: 2.5111185783605285
Validation loss: 2.4980885366231003

Epoch: 6| Step: 3
Training loss: 2.4171836453526048
Validation loss: 2.483807100106962

Epoch: 6| Step: 4
Training loss: 3.2669944994424474
Validation loss: 2.5006014285063203

Epoch: 6| Step: 5
Training loss: 2.539826545199437
Validation loss: 2.4958459890132625

Epoch: 6| Step: 6
Training loss: 2.409607761485048
Validation loss: 2.4831075894289247

Epoch: 6| Step: 7
Training loss: 2.9023910662361105
Validation loss: 2.4979504561984123

Epoch: 6| Step: 8
Training loss: 3.5933484723887488
Validation loss: 2.4974206806028802

Epoch: 6| Step: 9
Training loss: 2.9043395623544144
Validation loss: 2.501982091850139

Epoch: 6| Step: 10
Training loss: 2.875464028767758
Validation loss: 2.496382904340894

Epoch: 6| Step: 11
Training loss: 2.98391927864589
Validation loss: 2.491262713795857

Epoch: 6| Step: 12
Training loss: 2.297783704307746
Validation loss: 2.494134207000725

Epoch: 6| Step: 13
Training loss: 2.1493308689459845
Validation loss: 2.4961209361576024

Epoch: 60| Step: 0
Training loss: 2.927055132493617
Validation loss: 2.5081659057205923

Epoch: 6| Step: 1
Training loss: 2.708707304346506
Validation loss: 2.5060554733112164

Epoch: 6| Step: 2
Training loss: 2.805007533778989
Validation loss: 2.488092407946515

Epoch: 6| Step: 3
Training loss: 2.64931975216865
Validation loss: 2.4905406010653617

Epoch: 6| Step: 4
Training loss: 2.8585884388188565
Validation loss: 2.4945997604974517

Epoch: 6| Step: 5
Training loss: 3.2711250677219907
Validation loss: 2.5012853261369417

Epoch: 6| Step: 6
Training loss: 3.106083800630319
Validation loss: 2.4912274582007066

Epoch: 6| Step: 7
Training loss: 2.6961470486753973
Validation loss: 2.4950573165116365

Epoch: 6| Step: 8
Training loss: 2.9303545790022065
Validation loss: 2.4909949635618

Epoch: 6| Step: 9
Training loss: 2.48143387889067
Validation loss: 2.499106704923798

Epoch: 6| Step: 10
Training loss: 2.742825947311658
Validation loss: 2.4822671887132666

Epoch: 6| Step: 11
Training loss: 2.3236116016988118
Validation loss: 2.4854260480763317

Epoch: 6| Step: 12
Training loss: 2.2502768664087505
Validation loss: 2.4937981219000664

Epoch: 6| Step: 13
Training loss: 2.8452183212958198
Validation loss: 2.491424953078822

Epoch: 61| Step: 0
Training loss: 2.634825347381882
Validation loss: 2.489047889076163

Epoch: 6| Step: 1
Training loss: 2.698028876328955
Validation loss: 2.4969678015376533

Epoch: 6| Step: 2
Training loss: 3.1651374403775097
Validation loss: 2.500392386704067

Epoch: 6| Step: 3
Training loss: 2.2475398707433545
Validation loss: 2.4947398134077954

Epoch: 6| Step: 4
Training loss: 2.972549095678775
Validation loss: 2.5005872088084873

Epoch: 6| Step: 5
Training loss: 2.3341236025092527
Validation loss: 2.4976730335697632

Epoch: 6| Step: 6
Training loss: 2.6161628197562736
Validation loss: 2.49466885072096

Epoch: 6| Step: 7
Training loss: 3.0023934035869355
Validation loss: 2.5191864116009524

Epoch: 6| Step: 8
Training loss: 2.7623203167368335
Validation loss: 2.492613643442912

Epoch: 6| Step: 9
Training loss: 3.1583119823636636
Validation loss: 2.4955119558528365

Epoch: 6| Step: 10
Training loss: 2.8620542887211124
Validation loss: 2.4865846817236856

Epoch: 6| Step: 11
Training loss: 2.653727511770203
Validation loss: 2.5050736825756554

Epoch: 6| Step: 12
Training loss: 2.2451189928018516
Validation loss: 2.483250155986062

Epoch: 6| Step: 13
Training loss: 3.028483435928269
Validation loss: 2.4769031547478524

Epoch: 62| Step: 0
Training loss: 1.7138140460956452
Validation loss: 2.4880514248842474

Epoch: 6| Step: 1
Training loss: 2.922411374721743
Validation loss: 2.4940313728587413

Epoch: 6| Step: 2
Training loss: 3.124944457514218
Validation loss: 2.4967366741685018

Epoch: 6| Step: 3
Training loss: 2.3816535507634726
Validation loss: 2.484487272927034

Epoch: 6| Step: 4
Training loss: 2.5931316695790683
Validation loss: 2.4930153479009167

Epoch: 6| Step: 5
Training loss: 3.389606797587079
Validation loss: 2.4918995594236493

Epoch: 6| Step: 6
Training loss: 3.3850075029433704
Validation loss: 2.4981278680223187

Epoch: 6| Step: 7
Training loss: 2.332606361311015
Validation loss: 2.4822576654130537

Epoch: 6| Step: 8
Training loss: 2.639098318612388
Validation loss: 2.499289512170399

Epoch: 6| Step: 9
Training loss: 2.5917600788646475
Validation loss: 2.489109004589908

Epoch: 6| Step: 10
Training loss: 2.7217988206120696
Validation loss: 2.5003212204551404

Epoch: 6| Step: 11
Training loss: 2.8414021955308577
Validation loss: 2.4928611595564

Epoch: 6| Step: 12
Training loss: 2.462370343353068
Validation loss: 2.4965520688308924

Epoch: 6| Step: 13
Training loss: 3.127975877985909
Validation loss: 2.4930574267792425

Epoch: 63| Step: 0
Training loss: 2.377729052592049
Validation loss: 2.482889985481864

Epoch: 6| Step: 1
Training loss: 2.283904321193044
Validation loss: 2.4928728317881172

Epoch: 6| Step: 2
Training loss: 2.239184239040184
Validation loss: 2.483750782726352

Epoch: 6| Step: 3
Training loss: 3.349557841713642
Validation loss: 2.489285341080982

Epoch: 6| Step: 4
Training loss: 3.00098466608286
Validation loss: 2.4835569624447245

Epoch: 6| Step: 5
Training loss: 2.6963651066784675
Validation loss: 2.5046390612104927

Epoch: 6| Step: 6
Training loss: 2.7860931062058487
Validation loss: 2.4977900253323893

Epoch: 6| Step: 7
Training loss: 2.576824808272634
Validation loss: 2.494819328741677

Epoch: 6| Step: 8
Training loss: 2.2900773750793
Validation loss: 2.5004220954850345

Epoch: 6| Step: 9
Training loss: 3.1420825214196926
Validation loss: 2.5103803252551753

Epoch: 6| Step: 10
Training loss: 2.5616152096479685
Validation loss: 2.499898323944792

Epoch: 6| Step: 11
Training loss: 2.428646931957171
Validation loss: 2.5081993047255335

Epoch: 6| Step: 12
Training loss: 3.4839714056039437
Validation loss: 2.4997589384780188

Epoch: 6| Step: 13
Training loss: 3.139399502913193
Validation loss: 2.480159859079943

Epoch: 64| Step: 0
Training loss: 2.6707174013143185
Validation loss: 2.50916771109

Epoch: 6| Step: 1
Training loss: 2.4933191677785875
Validation loss: 2.4947617329266363

Epoch: 6| Step: 2
Training loss: 3.3165378072680816
Validation loss: 2.495579211281818

Epoch: 6| Step: 3
Training loss: 2.539126914747819
Validation loss: 2.502571289021366

Epoch: 6| Step: 4
Training loss: 3.5007219932289617
Validation loss: 2.499077074882416

Epoch: 6| Step: 5
Training loss: 2.498304173369564
Validation loss: 2.5128750877361483

Epoch: 6| Step: 6
Training loss: 2.3449407985672903
Validation loss: 2.496883872411427

Epoch: 6| Step: 7
Training loss: 2.7450099233368044
Validation loss: 2.505599068807844

Epoch: 6| Step: 8
Training loss: 2.6253095171874796
Validation loss: 2.488470186924861

Epoch: 6| Step: 9
Training loss: 3.1926786951345747
Validation loss: 2.5082362908205766

Epoch: 6| Step: 10
Training loss: 2.412323853382085
Validation loss: 2.5027784761228737

Epoch: 6| Step: 11
Training loss: 2.4808887516589513
Validation loss: 2.4799357567582865

Epoch: 6| Step: 12
Training loss: 2.2199978610191695
Validation loss: 2.506309156047288

Epoch: 6| Step: 13
Training loss: 3.287119239252876
Validation loss: 2.493388764904916

Epoch: 65| Step: 0
Training loss: 2.82354331480605
Validation loss: 2.484096754789906

Epoch: 6| Step: 1
Training loss: 2.7259526048823632
Validation loss: 2.4897024385582665

Epoch: 6| Step: 2
Training loss: 2.9017423722939317
Validation loss: 2.4886244237808293

Epoch: 6| Step: 3
Training loss: 3.255783510382638
Validation loss: 2.4870324085585955

Epoch: 6| Step: 4
Training loss: 3.092103153753469
Validation loss: 2.4878655702027483

Epoch: 6| Step: 5
Training loss: 2.085245081816287
Validation loss: 2.498632731896075

Epoch: 6| Step: 6
Training loss: 2.9085633289878543
Validation loss: 2.485432129611812

Epoch: 6| Step: 7
Training loss: 2.493142545900837
Validation loss: 2.4954840994174865

Epoch: 6| Step: 8
Training loss: 2.647243174198367
Validation loss: 2.495929230968369

Epoch: 6| Step: 9
Training loss: 2.5127255808211406
Validation loss: 2.49584023792104

Epoch: 6| Step: 10
Training loss: 2.61294539820912
Validation loss: 2.4939467805706568

Epoch: 6| Step: 11
Training loss: 2.888515052897497
Validation loss: 2.5069580922737034

Epoch: 6| Step: 12
Training loss: 2.31645853585067
Validation loss: 2.4969069173952825

Epoch: 6| Step: 13
Training loss: 2.9589108901766306
Validation loss: 2.4937977168654797

Epoch: 66| Step: 0
Training loss: 3.107887257194214
Validation loss: 2.495356127995902

Epoch: 6| Step: 1
Training loss: 3.312413340460626
Validation loss: 2.490320180483943

Epoch: 6| Step: 2
Training loss: 2.687706695414999
Validation loss: 2.487755964168338

Epoch: 6| Step: 3
Training loss: 2.6220954083994563
Validation loss: 2.4833052737736168

Epoch: 6| Step: 4
Training loss: 2.6202208291966738
Validation loss: 2.4875059783100233

Epoch: 6| Step: 5
Training loss: 2.9949399872691522
Validation loss: 2.495835575613118

Epoch: 6| Step: 6
Training loss: 2.8660131226989214
Validation loss: 2.4896350238582774

Epoch: 6| Step: 7
Training loss: 2.4335704330870334
Validation loss: 2.50040169226716

Epoch: 6| Step: 8
Training loss: 2.6729514647250667
Validation loss: 2.5021369291927065

Epoch: 6| Step: 9
Training loss: 2.4343501548821416
Validation loss: 2.493908520156631

Epoch: 6| Step: 10
Training loss: 2.4502801618180166
Validation loss: 2.5101904505261214

Epoch: 6| Step: 11
Training loss: 2.422790157550169
Validation loss: 2.4940744367906316

Epoch: 6| Step: 12
Training loss: 2.6355864177410044
Validation loss: 2.4915376059437517

Epoch: 6| Step: 13
Training loss: 2.9749328477477266
Validation loss: 2.510436569119316

Epoch: 67| Step: 0
Training loss: 2.7531574502822975
Validation loss: 2.48795662082373

Epoch: 6| Step: 1
Training loss: 2.866934034905241
Validation loss: 2.5040979045025114

Epoch: 6| Step: 2
Training loss: 2.773850445159987
Validation loss: 2.4896204516554126

Epoch: 6| Step: 3
Training loss: 2.8256178222511084
Validation loss: 2.4776830586627048

Epoch: 6| Step: 4
Training loss: 2.7000243645027893
Validation loss: 2.4960913220265275

Epoch: 6| Step: 5
Training loss: 2.767268667640757
Validation loss: 2.5030049200176907

Epoch: 6| Step: 6
Training loss: 2.175281296001931
Validation loss: 2.504351320785791

Epoch: 6| Step: 7
Training loss: 2.5968601928729482
Validation loss: 2.4779903340360576

Epoch: 6| Step: 8
Training loss: 3.193876284138725
Validation loss: 2.489565187926054

Epoch: 6| Step: 9
Training loss: 2.8654240894503458
Validation loss: 2.476689965396291

Epoch: 6| Step: 10
Training loss: 2.9066055244466273
Validation loss: 2.48761733185435

Epoch: 6| Step: 11
Training loss: 2.691412628121978
Validation loss: 2.47970889759093

Epoch: 6| Step: 12
Training loss: 2.4669056050673572
Validation loss: 2.4870029408167325

Epoch: 6| Step: 13
Training loss: 2.668652470613424
Validation loss: 2.483250783668821

Epoch: 68| Step: 0
Training loss: 2.3902747203042143
Validation loss: 2.488022938811159

Epoch: 6| Step: 1
Training loss: 3.2558391641356805
Validation loss: 2.4883971874115174

Epoch: 6| Step: 2
Training loss: 2.1791722498786354
Validation loss: 2.4882434814994956

Epoch: 6| Step: 3
Training loss: 2.275899386523518
Validation loss: 2.480334632328266

Epoch: 6| Step: 4
Training loss: 2.3865577156445514
Validation loss: 2.483399748535192

Epoch: 6| Step: 5
Training loss: 2.7135554708079686
Validation loss: 2.4918500072743863

Epoch: 6| Step: 6
Training loss: 2.3879948527601735
Validation loss: 2.4836180871453264

Epoch: 6| Step: 7
Training loss: 2.7898192674624966
Validation loss: 2.469401606773294

Epoch: 6| Step: 8
Training loss: 2.595723699598669
Validation loss: 2.4854781150691334

Epoch: 6| Step: 9
Training loss: 3.486483769722453
Validation loss: 2.4689114435923063

Epoch: 6| Step: 10
Training loss: 3.2829846837653522
Validation loss: 2.485432721673664

Epoch: 6| Step: 11
Training loss: 2.6844730630177898
Validation loss: 2.491372985672314

Epoch: 6| Step: 12
Training loss: 2.9004304106067536
Validation loss: 2.4910251919632898

Epoch: 6| Step: 13
Training loss: 2.298917420240281
Validation loss: 2.5004541143600743

Epoch: 69| Step: 0
Training loss: 2.2463372405384683
Validation loss: 2.4986625293154567

Epoch: 6| Step: 1
Training loss: 2.611562029363908
Validation loss: 2.497976891432912

Epoch: 6| Step: 2
Training loss: 2.21118356797921
Validation loss: 2.4923459750786416

Epoch: 6| Step: 3
Training loss: 3.0219757726014995
Validation loss: 2.476970183192744

Epoch: 6| Step: 4
Training loss: 2.480614365035654
Validation loss: 2.4870489168149317

Epoch: 6| Step: 5
Training loss: 2.5656030986190275
Validation loss: 2.4734174978967327

Epoch: 6| Step: 6
Training loss: 3.136221308236758
Validation loss: 2.5032608894772164

Epoch: 6| Step: 7
Training loss: 2.1562429234485325
Validation loss: 2.4882168820671877

Epoch: 6| Step: 8
Training loss: 3.285609664199099
Validation loss: 2.483211264122479

Epoch: 6| Step: 9
Training loss: 2.825923083571362
Validation loss: 2.4928837429614705

Epoch: 6| Step: 10
Training loss: 3.0454276535316853
Validation loss: 2.4851495958380174

Epoch: 6| Step: 11
Training loss: 3.0318494381020678
Validation loss: 2.4756576641284047

Epoch: 6| Step: 12
Training loss: 2.7547403573922367
Validation loss: 2.48886697009908

Epoch: 6| Step: 13
Training loss: 2.3630742258238375
Validation loss: 2.490201315164737

Epoch: 70| Step: 0
Training loss: 2.6757217289228494
Validation loss: 2.481545845823378

Epoch: 6| Step: 1
Training loss: 3.229645445410992
Validation loss: 2.4914111985890766

Epoch: 6| Step: 2
Training loss: 2.600545231797461
Validation loss: 2.4825483311412073

Epoch: 6| Step: 3
Training loss: 2.938237848344205
Validation loss: 2.4766737503824703

Epoch: 6| Step: 4
Training loss: 2.2382780544398
Validation loss: 2.4798041689354973

Epoch: 6| Step: 5
Training loss: 3.209970296086525
Validation loss: 2.488236502228315

Epoch: 6| Step: 6
Training loss: 2.3859782217331658
Validation loss: 2.4838045837444653

Epoch: 6| Step: 7
Training loss: 2.5290625268485303
Validation loss: 2.4911659274507185

Epoch: 6| Step: 8
Training loss: 3.3735775245769966
Validation loss: 2.4994282530139227

Epoch: 6| Step: 9
Training loss: 2.547189423980754
Validation loss: 2.4963270195816234

Epoch: 6| Step: 10
Training loss: 2.6778791459429008
Validation loss: 2.4947570187640085

Epoch: 6| Step: 11
Training loss: 2.0488483729784748
Validation loss: 2.464308572618692

Epoch: 6| Step: 12
Training loss: 2.3594071341846257
Validation loss: 2.4940508578510245

Epoch: 6| Step: 13
Training loss: 3.3793813735227345
Validation loss: 2.4898601060115

Epoch: 71| Step: 0
Training loss: 3.257041053089259
Validation loss: 2.4959902313985607

Epoch: 6| Step: 1
Training loss: 3.374117841931825
Validation loss: 2.4989546672052763

Epoch: 6| Step: 2
Training loss: 2.7616994120610094
Validation loss: 2.489741645015533

Epoch: 6| Step: 3
Training loss: 2.54801905861139
Validation loss: 2.4844010823106655

Epoch: 6| Step: 4
Training loss: 2.950107223372488
Validation loss: 2.515247224632544

Epoch: 6| Step: 5
Training loss: 2.615700735000663
Validation loss: 2.4935927784030714

Epoch: 6| Step: 6
Training loss: 2.601403858743467
Validation loss: 2.5036378541642277

Epoch: 6| Step: 7
Training loss: 2.0627693231620965
Validation loss: 2.490757172261246

Epoch: 6| Step: 8
Training loss: 2.0325299265254815
Validation loss: 2.4936580027360655

Epoch: 6| Step: 9
Training loss: 2.652361278447925
Validation loss: 2.4908904253909387

Epoch: 6| Step: 10
Training loss: 2.2687591972900267
Validation loss: 2.499388585132043

Epoch: 6| Step: 11
Training loss: 2.997797475375737
Validation loss: 2.482477986041184

Epoch: 6| Step: 12
Training loss: 2.946990893321081
Validation loss: 2.503220497841318

Epoch: 6| Step: 13
Training loss: 2.547495760478946
Validation loss: 2.489561642479228

Epoch: 72| Step: 0
Training loss: 2.2972023659272973
Validation loss: 2.4813829001794545

Epoch: 6| Step: 1
Training loss: 3.0599837573249915
Validation loss: 2.494571925220253

Epoch: 6| Step: 2
Training loss: 2.6868602967198267
Validation loss: 2.4947128685929765

Epoch: 6| Step: 3
Training loss: 2.7281072661882004
Validation loss: 2.495916992699479

Epoch: 6| Step: 4
Training loss: 2.941648759508247
Validation loss: 2.492471276643953

Epoch: 6| Step: 5
Training loss: 2.6737929927727544
Validation loss: 2.4975203470944294

Epoch: 6| Step: 6
Training loss: 3.3072488296417903
Validation loss: 2.4989001572259704

Epoch: 6| Step: 7
Training loss: 2.2661922402446075
Validation loss: 2.505660019013619

Epoch: 6| Step: 8
Training loss: 2.8499490432199304
Validation loss: 2.4861206476450244

Epoch: 6| Step: 9
Training loss: 2.5060325318924574
Validation loss: 2.5020636347551566

Epoch: 6| Step: 10
Training loss: 2.608554551206214
Validation loss: 2.501247926186928

Epoch: 6| Step: 11
Training loss: 2.1363616589181036
Validation loss: 2.492117748968212

Epoch: 6| Step: 12
Training loss: 3.189987109884689
Validation loss: 2.482763245746594

Epoch: 6| Step: 13
Training loss: 2.3954223169682707
Validation loss: 2.4943416879083795

Epoch: 73| Step: 0
Training loss: 2.8686032658700733
Validation loss: 2.497793019233068

Epoch: 6| Step: 1
Training loss: 2.804492146693711
Validation loss: 2.4857728843053186

Epoch: 6| Step: 2
Training loss: 2.9662254441149516
Validation loss: 2.5029351457540288

Epoch: 6| Step: 3
Training loss: 2.6731871121468194
Validation loss: 2.4852797731752165

Epoch: 6| Step: 4
Training loss: 2.0985481738618246
Validation loss: 2.4900323699083944

Epoch: 6| Step: 5
Training loss: 2.551394518843311
Validation loss: 2.4968633992110463

Epoch: 6| Step: 6
Training loss: 2.3580176889210667
Validation loss: 2.4828980546347976

Epoch: 6| Step: 7
Training loss: 2.6914495677811656
Validation loss: 2.4910374038370655

Epoch: 6| Step: 8
Training loss: 2.8077066901494816
Validation loss: 2.492869586193312

Epoch: 6| Step: 9
Training loss: 2.7898392650832053
Validation loss: 2.494554901517067

Epoch: 6| Step: 10
Training loss: 3.523856601191961
Validation loss: 2.48608463441529

Epoch: 6| Step: 11
Training loss: 1.929478375304059
Validation loss: 2.483147421382436

Epoch: 6| Step: 12
Training loss: 3.018939158829531
Validation loss: 2.5038931016005814

Epoch: 6| Step: 13
Training loss: 2.8171530486088057
Validation loss: 2.487245231423583

Epoch: 74| Step: 0
Training loss: 2.38542997087214
Validation loss: 2.4913926694724804

Epoch: 6| Step: 1
Training loss: 2.092828576326818
Validation loss: 2.48267392067508

Epoch: 6| Step: 2
Training loss: 2.663736094058547
Validation loss: 2.498115254149014

Epoch: 6| Step: 3
Training loss: 2.57110982198453
Validation loss: 2.4813661346818967

Epoch: 6| Step: 4
Training loss: 2.2422132324443487
Validation loss: 2.4848941759169176

Epoch: 6| Step: 5
Training loss: 3.0432197751282186
Validation loss: 2.4675336795536476

Epoch: 6| Step: 6
Training loss: 2.378997851081766
Validation loss: 2.4840141617883154

Epoch: 6| Step: 7
Training loss: 3.037454763318951
Validation loss: 2.481895196174581

Epoch: 6| Step: 8
Training loss: 2.5228144109674533
Validation loss: 2.4956720385480127

Epoch: 6| Step: 9
Training loss: 2.858126174789711
Validation loss: 2.46338947506528

Epoch: 6| Step: 10
Training loss: 3.3454670998183196
Validation loss: 2.4821688772896895

Epoch: 6| Step: 11
Training loss: 3.095108196481151
Validation loss: 2.5049668441001827

Epoch: 6| Step: 12
Training loss: 2.855262508850246
Validation loss: 2.493373495427411

Epoch: 6| Step: 13
Training loss: 2.6259852785509867
Validation loss: 2.4883079981340575

Epoch: 75| Step: 0
Training loss: 2.528619129001923
Validation loss: 2.490510072384185

Epoch: 6| Step: 1
Training loss: 2.3070377069441683
Validation loss: 2.496774272095155

Epoch: 6| Step: 2
Training loss: 2.972961971487549
Validation loss: 2.4830219260057267

Epoch: 6| Step: 3
Training loss: 1.994434062354582
Validation loss: 2.4736041520907084

Epoch: 6| Step: 4
Training loss: 2.910431837307697
Validation loss: 2.4847637090929613

Epoch: 6| Step: 5
Training loss: 2.1343173911501006
Validation loss: 2.4920963102611142

Epoch: 6| Step: 6
Training loss: 2.9951143218114753
Validation loss: 2.4869107708220635

Epoch: 6| Step: 7
Training loss: 3.1751115193643815
Validation loss: 2.4912295147907937

Epoch: 6| Step: 8
Training loss: 3.241616660731845
Validation loss: 2.4867227700584644

Epoch: 6| Step: 9
Training loss: 3.0293072639449514
Validation loss: 2.4945277229572596

Epoch: 6| Step: 10
Training loss: 2.769974644816892
Validation loss: 2.48649342981955

Epoch: 6| Step: 11
Training loss: 2.2692877266212514
Validation loss: 2.475704099343147

Epoch: 6| Step: 12
Training loss: 2.8534591429001037
Validation loss: 2.5015583728996225

Epoch: 6| Step: 13
Training loss: 2.343146488053519
Validation loss: 2.4850185781177974

Epoch: 76| Step: 0
Training loss: 2.5051727186646824
Validation loss: 2.4739777166689905

Epoch: 6| Step: 1
Training loss: 2.7412319855243763
Validation loss: 2.4756383678151592

Epoch: 6| Step: 2
Training loss: 3.072198264419684
Validation loss: 2.4851536107598196

Epoch: 6| Step: 3
Training loss: 2.1680283546845756
Validation loss: 2.5029404687949546

Epoch: 6| Step: 4
Training loss: 2.7860226774860526
Validation loss: 2.483385638869695

Epoch: 6| Step: 5
Training loss: 2.8813545654917374
Validation loss: 2.4891852531993073

Epoch: 6| Step: 6
Training loss: 2.650686563767655
Validation loss: 2.4952270907436276

Epoch: 6| Step: 7
Training loss: 2.546845980051789
Validation loss: 2.4792428077786233

Epoch: 6| Step: 8
Training loss: 2.6611593318632742
Validation loss: 2.483345281150053

Epoch: 6| Step: 9
Training loss: 3.022053404219406
Validation loss: 2.489983931672985

Epoch: 6| Step: 10
Training loss: 2.5099592200990157
Validation loss: 2.4814575198628166

Epoch: 6| Step: 11
Training loss: 3.1077717237065405
Validation loss: 2.484371191233272

Epoch: 6| Step: 12
Training loss: 2.314206601948643
Validation loss: 2.4880285225028516

Epoch: 6| Step: 13
Training loss: 3.0398721670578883
Validation loss: 2.4743137369012214

Epoch: 77| Step: 0
Training loss: 3.0576614771425024
Validation loss: 2.4970557297877183

Epoch: 6| Step: 1
Training loss: 2.2368772140794677
Validation loss: 2.4874961349647733

Epoch: 6| Step: 2
Training loss: 2.384979263471429
Validation loss: 2.491369007527465

Epoch: 6| Step: 3
Training loss: 2.8716490746961276
Validation loss: 2.4977180166805395

Epoch: 6| Step: 4
Training loss: 2.0854970631328382
Validation loss: 2.492538280876251

Epoch: 6| Step: 5
Training loss: 2.890658651619998
Validation loss: 2.4957056242704563

Epoch: 6| Step: 6
Training loss: 3.121178693892579
Validation loss: 2.4973312910739645

Epoch: 6| Step: 7
Training loss: 2.4701479080641353
Validation loss: 2.501062338726957

Epoch: 6| Step: 8
Training loss: 3.0443196854316947
Validation loss: 2.484843806234027

Epoch: 6| Step: 9
Training loss: 2.2773327573638533
Validation loss: 2.4804123578562205

Epoch: 6| Step: 10
Training loss: 2.878797759414825
Validation loss: 2.506035846370646

Epoch: 6| Step: 11
Training loss: 3.0018161998091295
Validation loss: 2.4983340855307623

Epoch: 6| Step: 12
Training loss: 2.9449579243010113
Validation loss: 2.4965812205437685

Epoch: 6| Step: 13
Training loss: 2.374264352202982
Validation loss: 2.487747811843677

Epoch: 78| Step: 0
Training loss: 3.0129426876255074
Validation loss: 2.498465155064345

Epoch: 6| Step: 1
Training loss: 2.8832704754043417
Validation loss: 2.500766922618625

Epoch: 6| Step: 2
Training loss: 2.4115386905560077
Validation loss: 2.502004706662985

Epoch: 6| Step: 3
Training loss: 3.096390031243793
Validation loss: 2.4945848658289504

Epoch: 6| Step: 4
Training loss: 2.537761648434529
Validation loss: 2.4874089458156496

Epoch: 6| Step: 5
Training loss: 2.560896394968793
Validation loss: 2.494633777887034

Epoch: 6| Step: 6
Training loss: 2.936046809039012
Validation loss: 2.495508792792647

Epoch: 6| Step: 7
Training loss: 2.5748829194645326
Validation loss: 2.4809223892270076

Epoch: 6| Step: 8
Training loss: 2.19375066077937
Validation loss: 2.489996551217731

Epoch: 6| Step: 9
Training loss: 2.777559897037041
Validation loss: 2.4854733987701416

Epoch: 6| Step: 10
Training loss: 2.414274434783203
Validation loss: 2.4850836334165556

Epoch: 6| Step: 11
Training loss: 3.021227124734815
Validation loss: 2.479706691359563

Epoch: 6| Step: 12
Training loss: 2.8808007806541194
Validation loss: 2.480600627080326

Epoch: 6| Step: 13
Training loss: 2.1427392473032256
Validation loss: 2.4953241875386905

Epoch: 79| Step: 0
Training loss: 3.1650521696832117
Validation loss: 2.508320027127586

Epoch: 6| Step: 1
Training loss: 1.8081143693449915
Validation loss: 2.4916130363324673

Epoch: 6| Step: 2
Training loss: 2.7396492799042513
Validation loss: 2.4724987463077643

Epoch: 6| Step: 3
Training loss: 2.567531948466559
Validation loss: 2.470511926511947

Epoch: 6| Step: 4
Training loss: 3.1006406860323876
Validation loss: 2.471077607446402

Epoch: 6| Step: 5
Training loss: 2.4982973022441484
Validation loss: 2.4898068096088197

Epoch: 6| Step: 6
Training loss: 2.3306287576937184
Validation loss: 2.5085977970558098

Epoch: 6| Step: 7
Training loss: 2.9439418851672645
Validation loss: 2.476138598463094

Epoch: 6| Step: 8
Training loss: 2.846699788200903
Validation loss: 2.4868841994006776

Epoch: 6| Step: 9
Training loss: 3.193258432081954
Validation loss: 2.4923672300908803

Epoch: 6| Step: 10
Training loss: 2.4991597670964114
Validation loss: 2.479803523839411

Epoch: 6| Step: 11
Training loss: 2.9072378797121847
Validation loss: 2.4883330522267046

Epoch: 6| Step: 12
Training loss: 2.666559117850512
Validation loss: 2.4892400325618302

Epoch: 6| Step: 13
Training loss: 1.6445301626750042
Validation loss: 2.5057149415823896

Epoch: 80| Step: 0
Training loss: 2.518570969800024
Validation loss: 2.4950893944705728

Epoch: 6| Step: 1
Training loss: 2.477843329451565
Validation loss: 2.496930755305265

Epoch: 6| Step: 2
Training loss: 2.1942934542296633
Validation loss: 2.4972788809340347

Epoch: 6| Step: 3
Training loss: 2.4890584884582494
Validation loss: 2.4809450069077115

Epoch: 6| Step: 4
Training loss: 3.2507273520338096
Validation loss: 2.5007497355451784

Epoch: 6| Step: 5
Training loss: 2.649544723556571
Validation loss: 2.473684806447811

Epoch: 6| Step: 6
Training loss: 2.7681697194321475
Validation loss: 2.481035944684365

Epoch: 6| Step: 7
Training loss: 2.6979370607368716
Validation loss: 2.4941584460651387

Epoch: 6| Step: 8
Training loss: 3.00000762938483
Validation loss: 2.4996827457486046

Epoch: 6| Step: 9
Training loss: 3.0930366078925857
Validation loss: 2.4769590451173187

Epoch: 6| Step: 10
Training loss: 2.1022659882758474
Validation loss: 2.493840581290359

Epoch: 6| Step: 11
Training loss: 3.3618858712526403
Validation loss: 2.4784137916272195

Epoch: 6| Step: 12
Training loss: 2.31903020188839
Validation loss: 2.4878499731436636

Epoch: 6| Step: 13
Training loss: 2.7295460813384604
Validation loss: 2.4827319073970164

Epoch: 81| Step: 0
Training loss: 2.6191922381135164
Validation loss: 2.5008297712206624

Epoch: 6| Step: 1
Training loss: 2.6903291936199825
Validation loss: 2.480906653449228

Epoch: 6| Step: 2
Training loss: 3.461461012536266
Validation loss: 2.4958750524209248

Epoch: 6| Step: 3
Training loss: 2.701374347018927
Validation loss: 2.4877492998948183

Epoch: 6| Step: 4
Training loss: 2.6168991613263466
Validation loss: 2.49005615883511

Epoch: 6| Step: 5
Training loss: 2.3723424800117416
Validation loss: 2.475307403413838

Epoch: 6| Step: 6
Training loss: 2.288453629793829
Validation loss: 2.4942948020874764

Epoch: 6| Step: 7
Training loss: 2.8264129683468338
Validation loss: 2.5017463921630507

Epoch: 6| Step: 8
Training loss: 2.923126931670054
Validation loss: 2.4716760023048616

Epoch: 6| Step: 9
Training loss: 2.8829301019267213
Validation loss: 2.510027081179601

Epoch: 6| Step: 10
Training loss: 2.457799163801579
Validation loss: 2.491832624437084

Epoch: 6| Step: 11
Training loss: 2.2980368653370733
Validation loss: 2.4891075461900565

Epoch: 6| Step: 12
Training loss: 2.8121724255850142
Validation loss: 2.4870920202163713

Epoch: 6| Step: 13
Training loss: 2.9276309513607965
Validation loss: 2.496040602106691

Epoch: 82| Step: 0
Training loss: 2.275448044474008
Validation loss: 2.4836885434289875

Epoch: 6| Step: 1
Training loss: 3.6161195566785898
Validation loss: 2.473750548431562

Epoch: 6| Step: 2
Training loss: 2.894280509024133
Validation loss: 2.4893687524704493

Epoch: 6| Step: 3
Training loss: 2.4665996989189454
Validation loss: 2.4817558129469868

Epoch: 6| Step: 4
Training loss: 2.5119167504942466
Validation loss: 2.497521621975277

Epoch: 6| Step: 5
Training loss: 2.4656568053772356
Validation loss: 2.4948461943110365

Epoch: 6| Step: 6
Training loss: 2.2977502932688934
Validation loss: 2.479479772978056

Epoch: 6| Step: 7
Training loss: 2.736446794636338
Validation loss: 2.515267118080615

Epoch: 6| Step: 8
Training loss: 1.8114712525123298
Validation loss: 2.486755165836376

Epoch: 6| Step: 9
Training loss: 3.1207617438695174
Validation loss: 2.498372843052469

Epoch: 6| Step: 10
Training loss: 3.0368548614719795
Validation loss: 2.4804565336368904

Epoch: 6| Step: 11
Training loss: 2.702354718307641
Validation loss: 2.4880816674098782

Epoch: 6| Step: 12
Training loss: 2.358049841602369
Validation loss: 2.4770530369373938

Epoch: 6| Step: 13
Training loss: 3.1724492196903125
Validation loss: 2.49958789566736

Epoch: 83| Step: 0
Training loss: 2.91692794356146
Validation loss: 2.4983002945107655

Epoch: 6| Step: 1
Training loss: 3.127473996280722
Validation loss: 2.4888611374723135

Epoch: 6| Step: 2
Training loss: 2.6498837643448767
Validation loss: 2.473522134267193

Epoch: 6| Step: 3
Training loss: 2.2233839402546898
Validation loss: 2.4953851447139215

Epoch: 6| Step: 4
Training loss: 2.7017202089696357
Validation loss: 2.4956961183514124

Epoch: 6| Step: 5
Training loss: 2.638176861009015
Validation loss: 2.4993893739006836

Epoch: 6| Step: 6
Training loss: 2.6546915306882473
Validation loss: 2.486660806184416

Epoch: 6| Step: 7
Training loss: 2.5499230616313224
Validation loss: 2.4890859234581035

Epoch: 6| Step: 8
Training loss: 2.4441682618590423
Validation loss: 2.492523122412742

Epoch: 6| Step: 9
Training loss: 3.162670290738496
Validation loss: 2.490973851216078

Epoch: 6| Step: 10
Training loss: 3.207579107104378
Validation loss: 2.4937183709659636

Epoch: 6| Step: 11
Training loss: 2.6205293641857117
Validation loss: 2.50128675283813

Epoch: 6| Step: 12
Training loss: 2.074172197239778
Validation loss: 2.499553589290605

Epoch: 6| Step: 13
Training loss: 2.3016113441810906
Validation loss: 2.5128098949511593

Epoch: 84| Step: 0
Training loss: 2.727678218232356
Validation loss: 2.4860892562316548

Epoch: 6| Step: 1
Training loss: 2.542202460509337
Validation loss: 2.4986401941094134

Epoch: 6| Step: 2
Training loss: 2.6223312617474344
Validation loss: 2.4759014273824462

Epoch: 6| Step: 3
Training loss: 3.059003429818701
Validation loss: 2.48493806775143

Epoch: 6| Step: 4
Training loss: 2.552049867579262
Validation loss: 2.4854904088636274

Epoch: 6| Step: 5
Training loss: 2.8755331788952194
Validation loss: 2.4923445052010305

Epoch: 6| Step: 6
Training loss: 2.6550303632361363
Validation loss: 2.4860333019775536

Epoch: 6| Step: 7
Training loss: 3.1374530621547345
Validation loss: 2.4820384314395443

Epoch: 6| Step: 8
Training loss: 2.5205111231998307
Validation loss: 2.498014886332755

Epoch: 6| Step: 9
Training loss: 2.293319441379936
Validation loss: 2.4900923627445137

Epoch: 6| Step: 10
Training loss: 2.275398274028184
Validation loss: 2.487759871833638

Epoch: 6| Step: 11
Training loss: 2.824465328020628
Validation loss: 2.4986132964860666

Epoch: 6| Step: 12
Training loss: 2.6646299233338984
Validation loss: 2.4982443582344973

Epoch: 6| Step: 13
Training loss: 3.1294275580568227
Validation loss: 2.4958350291600664

Epoch: 85| Step: 0
Training loss: 2.1916987857955004
Validation loss: 2.477350306040051

Epoch: 6| Step: 1
Training loss: 2.1748281476760014
Validation loss: 2.4952744542529786

Epoch: 6| Step: 2
Training loss: 2.7346367410999814
Validation loss: 2.493502809552699

Epoch: 6| Step: 3
Training loss: 2.9286749552328613
Validation loss: 2.4995534898035814

Epoch: 6| Step: 4
Training loss: 2.4391019398874745
Validation loss: 2.512585075471441

Epoch: 6| Step: 5
Training loss: 3.416891571334084
Validation loss: 2.4971076128096654

Epoch: 6| Step: 6
Training loss: 2.9712876566810418
Validation loss: 2.4860315736566996

Epoch: 6| Step: 7
Training loss: 3.4159145612908794
Validation loss: 2.4899077322322754

Epoch: 6| Step: 8
Training loss: 2.2706741370531636
Validation loss: 2.487752615030483

Epoch: 6| Step: 9
Training loss: 2.1726272707271543
Validation loss: 2.4868065472890586

Epoch: 6| Step: 10
Training loss: 2.2867311446698166
Validation loss: 2.492839063409327

Epoch: 6| Step: 11
Training loss: 3.0960826364375986
Validation loss: 2.495000568749621

Epoch: 6| Step: 12
Training loss: 2.0651518217715985
Validation loss: 2.4708755645050844

Epoch: 6| Step: 13
Training loss: 3.051055231625318
Validation loss: 2.4864221848672368

Epoch: 86| Step: 0
Training loss: 2.3746588612549013
Validation loss: 2.4833561325003943

Epoch: 6| Step: 1
Training loss: 1.8902316354162958
Validation loss: 2.4775252091899533

Epoch: 6| Step: 2
Training loss: 1.908449373784535
Validation loss: 2.4836411550941198

Epoch: 6| Step: 3
Training loss: 2.367658209504423
Validation loss: 2.4769528377260386

Epoch: 6| Step: 4
Training loss: 3.1417422608472756
Validation loss: 2.477724387049533

Epoch: 6| Step: 5
Training loss: 3.0126156986542973
Validation loss: 2.489359018959971

Epoch: 6| Step: 6
Training loss: 2.7728719645125324
Validation loss: 2.483004818984814

Epoch: 6| Step: 7
Training loss: 2.3730432580990954
Validation loss: 2.47798272790676

Epoch: 6| Step: 8
Training loss: 3.1822322625558876
Validation loss: 2.4925197801946677

Epoch: 6| Step: 9
Training loss: 3.340710550895315
Validation loss: 2.4777494860798694

Epoch: 6| Step: 10
Training loss: 2.3267605258551503
Validation loss: 2.491215014688219

Epoch: 6| Step: 11
Training loss: 2.8252516845395657
Validation loss: 2.505698379302669

Epoch: 6| Step: 12
Training loss: 2.784146975375611
Validation loss: 2.5015128705916694

Epoch: 6| Step: 13
Training loss: 2.8670165299417065
Validation loss: 2.4878468580480684

Epoch: 87| Step: 0
Training loss: 3.4020397519094008
Validation loss: 2.505198584444595

Epoch: 6| Step: 1
Training loss: 3.177589868074535
Validation loss: 2.492252935979762

Epoch: 6| Step: 2
Training loss: 2.402156766732348
Validation loss: 2.468670675660395

Epoch: 6| Step: 3
Training loss: 2.432770468876141
Validation loss: 2.492324103745145

Epoch: 6| Step: 4
Training loss: 2.656210416611085
Validation loss: 2.481061815142263

Epoch: 6| Step: 5
Training loss: 3.020555329958843
Validation loss: 2.4562066554969215

Epoch: 6| Step: 6
Training loss: 1.757155096252917
Validation loss: 2.485760498572451

Epoch: 6| Step: 7
Training loss: 2.403975464497304
Validation loss: 2.4672627952034203

Epoch: 6| Step: 8
Training loss: 2.5263179247830383
Validation loss: 2.488278200352404

Epoch: 6| Step: 9
Training loss: 2.718241150690664
Validation loss: 2.478108013979211

Epoch: 6| Step: 10
Training loss: 2.4350559991119374
Validation loss: 2.495780650320044

Epoch: 6| Step: 11
Training loss: 2.867914341571809
Validation loss: 2.4950501682696578

Epoch: 6| Step: 12
Training loss: 2.6874015257780877
Validation loss: 2.5001458443380082

Epoch: 6| Step: 13
Training loss: 2.8271879888479097
Validation loss: 2.508914553428482

Epoch: 88| Step: 0
Training loss: 2.5238573415978376
Validation loss: 2.4751956762907144

Epoch: 6| Step: 1
Training loss: 3.330104758416222
Validation loss: 2.5020109538524484

Epoch: 6| Step: 2
Training loss: 3.031291843400791
Validation loss: 2.4971842136527975

Epoch: 6| Step: 3
Training loss: 2.604837732953965
Validation loss: 2.5098253003860758

Epoch: 6| Step: 4
Training loss: 2.663095606418091
Validation loss: 2.4947326401069616

Epoch: 6| Step: 5
Training loss: 2.3484817551474086
Validation loss: 2.483425676952773

Epoch: 6| Step: 6
Training loss: 2.472807724397431
Validation loss: 2.492660720813606

Epoch: 6| Step: 7
Training loss: 2.258549342317619
Validation loss: 2.477326794034775

Epoch: 6| Step: 8
Training loss: 2.6549632826742884
Validation loss: 2.4933140020765543

Epoch: 6| Step: 9
Training loss: 2.5620922601601905
Validation loss: 2.494861652581975

Epoch: 6| Step: 10
Training loss: 3.054718095474976
Validation loss: 2.4906169252484367

Epoch: 6| Step: 11
Training loss: 2.5302215182161216
Validation loss: 2.476258881122255

Epoch: 6| Step: 12
Training loss: 2.960655339870534
Validation loss: 2.485224684736746

Epoch: 6| Step: 13
Training loss: 1.8046518958076414
Validation loss: 2.4700381852645386

Epoch: 89| Step: 0
Training loss: 2.3004233012224358
Validation loss: 2.480131295804333

Epoch: 6| Step: 1
Training loss: 2.092679789304021
Validation loss: 2.4878318894595557

Epoch: 6| Step: 2
Training loss: 3.6281206576167757
Validation loss: 2.490079870318945

Epoch: 6| Step: 3
Training loss: 2.4819486273490936
Validation loss: 2.483794670510638

Epoch: 6| Step: 4
Training loss: 2.6194188868369292
Validation loss: 2.4927919816935433

Epoch: 6| Step: 5
Training loss: 2.346525456269108
Validation loss: 2.487614793582074

Epoch: 6| Step: 6
Training loss: 2.831492237229293
Validation loss: 2.4756683208397017

Epoch: 6| Step: 7
Training loss: 2.3313039287639574
Validation loss: 2.4810161497839007

Epoch: 6| Step: 8
Training loss: 2.9362923594959973
Validation loss: 2.4780420534408676

Epoch: 6| Step: 9
Training loss: 2.7613864466748654
Validation loss: 2.4886270825801575

Epoch: 6| Step: 10
Training loss: 2.993866690828296
Validation loss: 2.510916795433437

Epoch: 6| Step: 11
Training loss: 2.4443122353587645
Validation loss: 2.485689845756314

Epoch: 6| Step: 12
Training loss: 2.7343651471641683
Validation loss: 2.4905578271959645

Epoch: 6| Step: 13
Training loss: 2.625067028824741
Validation loss: 2.4879482527676156

Epoch: 90| Step: 0
Training loss: 3.269496101728263
Validation loss: 2.5084678742462057

Epoch: 6| Step: 1
Training loss: 3.436873084034987
Validation loss: 2.4998661805300344

Epoch: 6| Step: 2
Training loss: 2.1479764686446345
Validation loss: 2.4811687928265043

Epoch: 6| Step: 3
Training loss: 2.4669837911047834
Validation loss: 2.4879828232397574

Epoch: 6| Step: 4
Training loss: 2.191312464918842
Validation loss: 2.48748684605137

Epoch: 6| Step: 5
Training loss: 3.017965880730095
Validation loss: 2.4951921572677347

Epoch: 6| Step: 6
Training loss: 2.5255637644268725
Validation loss: 2.489476180030705

Epoch: 6| Step: 7
Training loss: 2.7166501409421953
Validation loss: 2.4924975015405137

Epoch: 6| Step: 8
Training loss: 2.098583165820103
Validation loss: 2.4838300950832353

Epoch: 6| Step: 9
Training loss: 2.634691422579106
Validation loss: 2.4915312903071234

Epoch: 6| Step: 10
Training loss: 2.4145495469694773
Validation loss: 2.492196716873778

Epoch: 6| Step: 11
Training loss: 3.069706747854307
Validation loss: 2.4889847625432915

Epoch: 6| Step: 12
Training loss: 2.3903022498380944
Validation loss: 2.481578971380363

Epoch: 6| Step: 13
Training loss: 2.7937198509279253
Validation loss: 2.4832485475482673

Epoch: 91| Step: 0
Training loss: 2.335796849535988
Validation loss: 2.490280863717841

Epoch: 6| Step: 1
Training loss: 3.2444883707925367
Validation loss: 2.482066092766789

Epoch: 6| Step: 2
Training loss: 2.3702746112287283
Validation loss: 2.5144444755928177

Epoch: 6| Step: 3
Training loss: 2.96289126874581
Validation loss: 2.4951619084545418

Epoch: 6| Step: 4
Training loss: 2.4695305857767615
Validation loss: 2.480869070287431

Epoch: 6| Step: 5
Training loss: 2.7417593510352543
Validation loss: 2.47437501430448

Epoch: 6| Step: 6
Training loss: 2.915787500757343
Validation loss: 2.493482081373255

Epoch: 6| Step: 7
Training loss: 1.4661276112085273
Validation loss: 2.4878745671140705

Epoch: 6| Step: 8
Training loss: 2.5439870175624173
Validation loss: 2.4982067557515895

Epoch: 6| Step: 9
Training loss: 3.155592594988985
Validation loss: 2.492224891904912

Epoch: 6| Step: 10
Training loss: 2.7891738826619235
Validation loss: 2.47137180747686

Epoch: 6| Step: 11
Training loss: 2.545856201851666
Validation loss: 2.4855576518214706

Epoch: 6| Step: 12
Training loss: 3.081271659357111
Validation loss: 2.481885392552992

Epoch: 6| Step: 13
Training loss: 2.3475751053533216
Validation loss: 2.4939070573677333

Epoch: 92| Step: 0
Training loss: 3.172166331775526
Validation loss: 2.477361814376687

Epoch: 6| Step: 1
Training loss: 2.682706594626323
Validation loss: 2.5005651942602674

Epoch: 6| Step: 2
Training loss: 2.635766610494943
Validation loss: 2.5047006678318744

Epoch: 6| Step: 3
Training loss: 2.3086063494394975
Validation loss: 2.4721974022924336

Epoch: 6| Step: 4
Training loss: 2.2959091335552104
Validation loss: 2.497156891237111

Epoch: 6| Step: 5
Training loss: 2.451187048633314
Validation loss: 2.505327563471324

Epoch: 6| Step: 6
Training loss: 2.6427452107884912
Validation loss: 2.4831434331569917

Epoch: 6| Step: 7
Training loss: 2.326852335403234
Validation loss: 2.4699356598545203

Epoch: 6| Step: 8
Training loss: 3.0262967569551447
Validation loss: 2.4764736650400097

Epoch: 6| Step: 9
Training loss: 2.0551533334149146
Validation loss: 2.4927912998500577

Epoch: 6| Step: 10
Training loss: 2.6184028195056834
Validation loss: 2.5020733859541457

Epoch: 6| Step: 11
Training loss: 2.1834496192928827
Validation loss: 2.5065283597962615

Epoch: 6| Step: 12
Training loss: 3.568151308204256
Validation loss: 2.4887469656216923

Epoch: 6| Step: 13
Training loss: 3.2590480446611503
Validation loss: 2.4964949884442147

Epoch: 93| Step: 0
Training loss: 2.875046771125163
Validation loss: 2.5066396005828957

Epoch: 6| Step: 1
Training loss: 2.401010630331851
Validation loss: 2.4880091603620276

Epoch: 6| Step: 2
Training loss: 2.6295722015907654
Validation loss: 2.4741192674779153

Epoch: 6| Step: 3
Training loss: 2.495531666589345
Validation loss: 2.4943204810688457

Epoch: 6| Step: 4
Training loss: 2.7975877247982583
Validation loss: 2.4946949358792505

Epoch: 6| Step: 5
Training loss: 2.532974126931394
Validation loss: 2.4857216578464394

Epoch: 6| Step: 6
Training loss: 3.1862817567998944
Validation loss: 2.5020931197973675

Epoch: 6| Step: 7
Training loss: 2.6028815697170895
Validation loss: 2.502562015599285

Epoch: 6| Step: 8
Training loss: 3.0379476586278606
Validation loss: 2.4990129593748436

Epoch: 6| Step: 9
Training loss: 3.2612829225573723
Validation loss: 2.5154693989524066

Epoch: 6| Step: 10
Training loss: 2.699120968318655
Validation loss: 2.49833383515258

Epoch: 6| Step: 11
Training loss: 2.2652362358400056
Validation loss: 2.508006700733639

Epoch: 6| Step: 12
Training loss: 2.1515823928478524
Validation loss: 2.490838014299258

Epoch: 6| Step: 13
Training loss: 2.0826875321486376
Validation loss: 2.5065727953372985

Epoch: 94| Step: 0
Training loss: 2.330558682534211
Validation loss: 2.4960125975070713

Epoch: 6| Step: 1
Training loss: 2.4220718795984166
Validation loss: 2.494066253724289

Epoch: 6| Step: 2
Training loss: 2.2858882416367545
Validation loss: 2.4851452502864912

Epoch: 6| Step: 3
Training loss: 2.9876957338448418
Validation loss: 2.4959461220432737

Epoch: 6| Step: 4
Training loss: 2.610719345904932
Validation loss: 2.4964793590386716

Epoch: 6| Step: 5
Training loss: 2.81445117661821
Validation loss: 2.487429918363592

Epoch: 6| Step: 6
Training loss: 2.693153644585605
Validation loss: 2.483184690280778

Epoch: 6| Step: 7
Training loss: 2.0738160627901348
Validation loss: 2.5074197561748415

Epoch: 6| Step: 8
Training loss: 3.0508709648900556
Validation loss: 2.4964826348551656

Epoch: 6| Step: 9
Training loss: 3.0308427045451936
Validation loss: 2.4812905167734693

Epoch: 6| Step: 10
Training loss: 2.5727535819029734
Validation loss: 2.4819788264855465

Epoch: 6| Step: 11
Training loss: 2.8038594078047763
Validation loss: 2.4725635980809724

Epoch: 6| Step: 12
Training loss: 3.1564971524906595
Validation loss: 2.490914918069688

Epoch: 6| Step: 13
Training loss: 1.922614536817192
Validation loss: 2.473174119022909

Epoch: 95| Step: 0
Training loss: 2.374863168890656
Validation loss: 2.5004402162737174

Epoch: 6| Step: 1
Training loss: 2.2344884243432923
Validation loss: 2.4981218471544815

Epoch: 6| Step: 2
Training loss: 1.8322949575539582
Validation loss: 2.4781426425848885

Epoch: 6| Step: 3
Training loss: 2.5604215426873216
Validation loss: 2.4909640081952578

Epoch: 6| Step: 4
Training loss: 2.4329463777351967
Validation loss: 2.494074452209021

Epoch: 6| Step: 5
Training loss: 3.0987529953745545
Validation loss: 2.487844613692953

Epoch: 6| Step: 6
Training loss: 2.886217210533011
Validation loss: 2.4971001706559655

Epoch: 6| Step: 7
Training loss: 2.4050397925941227
Validation loss: 2.508325702080691

Epoch: 6| Step: 8
Training loss: 3.0618670062404423
Validation loss: 2.5005302482146634

Epoch: 6| Step: 9
Training loss: 2.766958055509864
Validation loss: 2.5031808603546617

Epoch: 6| Step: 10
Training loss: 2.964737600001935
Validation loss: 2.480633002564402

Epoch: 6| Step: 11
Training loss: 2.7544718709365617
Validation loss: 2.503861849046282

Epoch: 6| Step: 12
Training loss: 3.0676994561076105
Validation loss: 2.473961733614404

Epoch: 6| Step: 13
Training loss: 2.6090459559038646
Validation loss: 2.4781286214381426

Epoch: 96| Step: 0
Training loss: 2.9897404716921048
Validation loss: 2.4808410215314654

Epoch: 6| Step: 1
Training loss: 2.2396904734925367
Validation loss: 2.505336174320935

Epoch: 6| Step: 2
Training loss: 3.284665319385824
Validation loss: 2.483958080287975

Epoch: 6| Step: 3
Training loss: 2.5371201818175826
Validation loss: 2.4958256264510297

Epoch: 6| Step: 4
Training loss: 2.5543219161858923
Validation loss: 2.50386056101166

Epoch: 6| Step: 5
Training loss: 1.501699756140612
Validation loss: 2.4868495930386465

Epoch: 6| Step: 6
Training loss: 2.98586503624133
Validation loss: 2.4904897032522113

Epoch: 6| Step: 7
Training loss: 2.720347318913977
Validation loss: 2.478599665153631

Epoch: 6| Step: 8
Training loss: 2.0125206987726316
Validation loss: 2.4901228574248706

Epoch: 6| Step: 9
Training loss: 2.4355549999551225
Validation loss: 2.5012898378716812

Epoch: 6| Step: 10
Training loss: 2.2890849974897005
Validation loss: 2.485162321426031

Epoch: 6| Step: 11
Training loss: 2.667067100341611
Validation loss: 2.509921296721024

Epoch: 6| Step: 12
Training loss: 3.21515729077427
Validation loss: 2.47669627022873

Epoch: 6| Step: 13
Training loss: 3.5501093296892394
Validation loss: 2.4888603453670677

Epoch: 97| Step: 0
Training loss: 2.716812144715805
Validation loss: 2.4954628041772207

Epoch: 6| Step: 1
Training loss: 2.7484037795175063
Validation loss: 2.48255963518229

Epoch: 6| Step: 2
Training loss: 2.8585640846583504
Validation loss: 2.4941191784980266

Epoch: 6| Step: 3
Training loss: 2.996703243803246
Validation loss: 2.4916802426690388

Epoch: 6| Step: 4
Training loss: 2.56063318870898
Validation loss: 2.479091946834043

Epoch: 6| Step: 5
Training loss: 2.1925039551023957
Validation loss: 2.5122756362346363

Epoch: 6| Step: 6
Training loss: 2.774823081760493
Validation loss: 2.508809181894983

Epoch: 6| Step: 7
Training loss: 2.2358809511296687
Validation loss: 2.501404777770451

Epoch: 6| Step: 8
Training loss: 2.5208226878884585
Validation loss: 2.488512836119434

Epoch: 6| Step: 9
Training loss: 2.3710342223787926
Validation loss: 2.4855013937028114

Epoch: 6| Step: 10
Training loss: 2.7373444047020485
Validation loss: 2.471067970474974

Epoch: 6| Step: 11
Training loss: 2.0248417639426415
Validation loss: 2.5090953249887544

Epoch: 6| Step: 12
Training loss: 2.9885260188766853
Validation loss: 2.496982369363015

Epoch: 6| Step: 13
Training loss: 3.687730038466602
Validation loss: 2.481183019455025

Epoch: 98| Step: 0
Training loss: 2.902437888835412
Validation loss: 2.4841383407700626

Epoch: 6| Step: 1
Training loss: 2.2360434538384117
Validation loss: 2.4691365028888903

Epoch: 6| Step: 2
Training loss: 2.93820409250014
Validation loss: 2.4937844360122106

Epoch: 6| Step: 3
Training loss: 3.0396742021252736
Validation loss: 2.4888597242492545

Epoch: 6| Step: 4
Training loss: 1.8608668136944477
Validation loss: 2.48311380466397

Epoch: 6| Step: 5
Training loss: 2.805406313620751
Validation loss: 2.4976554449182387

Epoch: 6| Step: 6
Training loss: 1.9525859851928502
Validation loss: 2.5014219431765263

Epoch: 6| Step: 7
Training loss: 2.297542760407492
Validation loss: 2.5050182429452486

Epoch: 6| Step: 8
Training loss: 2.524535043794681
Validation loss: 2.495841710875731

Epoch: 6| Step: 9
Training loss: 3.028920172973465
Validation loss: 2.499540902099068

Epoch: 6| Step: 10
Training loss: 2.671304385283611
Validation loss: 2.479757921116941

Epoch: 6| Step: 11
Training loss: 3.560701150319241
Validation loss: 2.482297702067102

Epoch: 6| Step: 12
Training loss: 2.369518781327955
Validation loss: 2.483682788958228

Epoch: 6| Step: 13
Training loss: 2.4425181061962835
Validation loss: 2.4736765092947963

Epoch: 99| Step: 0
Training loss: 3.008783515645244
Validation loss: 2.508240901459662

Epoch: 6| Step: 1
Training loss: 2.430844047016243
Validation loss: 2.4723380046215917

Epoch: 6| Step: 2
Training loss: 2.563719575534969
Validation loss: 2.498939587673066

Epoch: 6| Step: 3
Training loss: 2.033454051368833
Validation loss: 2.511219145741392

Epoch: 6| Step: 4
Training loss: 3.3866820019902932
Validation loss: 2.4898795175954604

Epoch: 6| Step: 5
Training loss: 3.1991008508590792
Validation loss: 2.484980874542496

Epoch: 6| Step: 6
Training loss: 2.3331778565332915
Validation loss: 2.488365651635194

Epoch: 6| Step: 7
Training loss: 2.7274567195210175
Validation loss: 2.508411813127669

Epoch: 6| Step: 8
Training loss: 2.092317461189491
Validation loss: 2.4719362332766934

Epoch: 6| Step: 9
Training loss: 2.5736457522726233
Validation loss: 2.4927602886295936

Epoch: 6| Step: 10
Training loss: 2.667779918595475
Validation loss: 2.4644920969732906

Epoch: 6| Step: 11
Training loss: 2.413319099798784
Validation loss: 2.472228061708611

Epoch: 6| Step: 12
Training loss: 2.782062540411298
Validation loss: 2.5020523834821184

Epoch: 6| Step: 13
Training loss: 2.837421964000849
Validation loss: 2.493064816217651

Epoch: 100| Step: 0
Training loss: 2.607295778347243
Validation loss: 2.4936356309296444

Epoch: 6| Step: 1
Training loss: 2.465067180778145
Validation loss: 2.4977038749958362

Epoch: 6| Step: 2
Training loss: 2.485743691438022
Validation loss: 2.504769863251194

Epoch: 6| Step: 3
Training loss: 3.3123669867530743
Validation loss: 2.4971727245487476

Epoch: 6| Step: 4
Training loss: 2.366539995627228
Validation loss: 2.4965097212771825

Epoch: 6| Step: 5
Training loss: 2.527181298814479
Validation loss: 2.465821415590153

Epoch: 6| Step: 6
Training loss: 2.140755531062436
Validation loss: 2.4743358886561175

Epoch: 6| Step: 7
Training loss: 2.571097859808513
Validation loss: 2.487240798314994

Epoch: 6| Step: 8
Training loss: 2.9286526492615774
Validation loss: 2.4702417693480476

Epoch: 6| Step: 9
Training loss: 2.90893299584511
Validation loss: 2.494260771338418

Epoch: 6| Step: 10
Training loss: 3.0400367097143963
Validation loss: 2.4917459553563512

Epoch: 6| Step: 11
Training loss: 2.3945045656394486
Validation loss: 2.495400117307075

Epoch: 6| Step: 12
Training loss: 2.3219519580599273
Validation loss: 2.508081434451521

Epoch: 6| Step: 13
Training loss: 3.1151719233552018
Validation loss: 2.492881129837498

Epoch: 101| Step: 0
Training loss: 2.9133291676867605
Validation loss: 2.5136513916708836

Epoch: 6| Step: 1
Training loss: 2.5071395969486114
Validation loss: 2.498143023263389

Epoch: 6| Step: 2
Training loss: 2.7776275361014626
Validation loss: 2.4775093607758127

Epoch: 6| Step: 3
Training loss: 2.343594355183497
Validation loss: 2.4797995333374536

Epoch: 6| Step: 4
Training loss: 2.9486340479997577
Validation loss: 2.5088500874618105

Epoch: 6| Step: 5
Training loss: 1.9109669468654682
Validation loss: 2.4960762801441554

Epoch: 6| Step: 6
Training loss: 2.398932589151112
Validation loss: 2.50533306612997

Epoch: 6| Step: 7
Training loss: 2.756249522514042
Validation loss: 2.4881548003359466

Epoch: 6| Step: 8
Training loss: 3.0614712602710843
Validation loss: 2.4749835056779936

Epoch: 6| Step: 9
Training loss: 2.9342350773057704
Validation loss: 2.4950136479034

Epoch: 6| Step: 10
Training loss: 2.972655768776653
Validation loss: 2.485519616567222

Epoch: 6| Step: 11
Training loss: 2.6382332528323
Validation loss: 2.4966423067006103

Epoch: 6| Step: 12
Training loss: 2.481084215597628
Validation loss: 2.5127359665656552

Epoch: 6| Step: 13
Training loss: 2.029243769607106
Validation loss: 2.499603865628202

Epoch: 102| Step: 0
Training loss: 1.9410833631377469
Validation loss: 2.5048801136416086

Epoch: 6| Step: 1
Training loss: 2.8988244140338058
Validation loss: 2.505696076249049

Epoch: 6| Step: 2
Training loss: 2.5031009515757243
Validation loss: 2.487597539857552

Epoch: 6| Step: 3
Training loss: 2.8561980729005167
Validation loss: 2.4824433430395905

Epoch: 6| Step: 4
Training loss: 2.63115551704159
Validation loss: 2.498185682803018

Epoch: 6| Step: 5
Training loss: 2.782173432056758
Validation loss: 2.4877190347793516

Epoch: 6| Step: 6
Training loss: 3.1080819513226636
Validation loss: 2.5035874202471176

Epoch: 6| Step: 7
Training loss: 2.7737026034169827
Validation loss: 2.5049216135131767

Epoch: 6| Step: 8
Training loss: 2.700745963433563
Validation loss: 2.5032622146887107

Epoch: 6| Step: 9
Training loss: 2.1904807354798956
Validation loss: 2.5071609944468114

Epoch: 6| Step: 10
Training loss: 2.9801037966169632
Validation loss: 2.504760363585764

Epoch: 6| Step: 11
Training loss: 2.805533873806844
Validation loss: 2.5032138737146843

Epoch: 6| Step: 12
Training loss: 2.476874780070131
Validation loss: 2.5186861949067563

Epoch: 6| Step: 13
Training loss: 2.0258035266503183
Validation loss: 2.508131186188032

Epoch: 103| Step: 0
Training loss: 2.202906063374913
Validation loss: 2.518109208291083

Epoch: 6| Step: 1
Training loss: 2.919142807334759
Validation loss: 2.509304872871079

Epoch: 6| Step: 2
Training loss: 3.253299652013853
Validation loss: 2.5054003838230754

Epoch: 6| Step: 3
Training loss: 2.3121029280946295
Validation loss: 2.4742085786342525

Epoch: 6| Step: 4
Training loss: 2.6575259566093594
Validation loss: 2.497575164843556

Epoch: 6| Step: 5
Training loss: 2.7081135489465793
Validation loss: 2.4788094867599524

Epoch: 6| Step: 6
Training loss: 2.3008933695755522
Validation loss: 2.4945062427856315

Epoch: 6| Step: 7
Training loss: 2.5913289732245777
Validation loss: 2.4922458156969154

Epoch: 6| Step: 8
Training loss: 2.4608202709553626
Validation loss: 2.481268559355956

Epoch: 6| Step: 9
Training loss: 2.83198477871355
Validation loss: 2.4754036830326145

Epoch: 6| Step: 10
Training loss: 2.9630887311716445
Validation loss: 2.4860926498892044

Epoch: 6| Step: 11
Training loss: 2.470452313263827
Validation loss: 2.4719008762717563

Epoch: 6| Step: 12
Training loss: 2.18187229493978
Validation loss: 2.4753268379808766

Epoch: 6| Step: 13
Training loss: 3.5631801558265304
Validation loss: 2.489149863127141

Epoch: 104| Step: 0
Training loss: 2.8415048980160527
Validation loss: 2.517038699050282

Epoch: 6| Step: 1
Training loss: 3.0452729537220304
Validation loss: 2.494314707445109

Epoch: 6| Step: 2
Training loss: 2.8394142046402275
Validation loss: 2.4825405396719717

Epoch: 6| Step: 3
Training loss: 2.0037935756959206
Validation loss: 2.499192172453407

Epoch: 6| Step: 4
Training loss: 2.479884954522043
Validation loss: 2.4772587952172502

Epoch: 6| Step: 5
Training loss: 2.6460962440246956
Validation loss: 2.5050065372460257

Epoch: 6| Step: 6
Training loss: 2.1304782488128224
Validation loss: 2.519015534857066

Epoch: 6| Step: 7
Training loss: 2.707049921585138
Validation loss: 2.4851716520382885

Epoch: 6| Step: 8
Training loss: 2.7920776652980837
Validation loss: 2.5050968614986333

Epoch: 6| Step: 9
Training loss: 2.912513136936407
Validation loss: 2.4882152273849694

Epoch: 6| Step: 10
Training loss: 2.110970804783302
Validation loss: 2.507479918841826

Epoch: 6| Step: 11
Training loss: 2.913049598541366
Validation loss: 2.503825890310911

Epoch: 6| Step: 12
Training loss: 2.8326797479495207
Validation loss: 2.4910430085586857

Epoch: 6| Step: 13
Training loss: 2.329933743987861
Validation loss: 2.4857988529424473

Epoch: 105| Step: 0
Training loss: 3.077296421435683
Validation loss: 2.4805633679321564

Epoch: 6| Step: 1
Training loss: 2.316675386023636
Validation loss: 2.467492159182373

Epoch: 6| Step: 2
Training loss: 2.439758037389335
Validation loss: 2.5011288955096105

Epoch: 6| Step: 3
Training loss: 2.5851625508715523
Validation loss: 2.48379845074529

Epoch: 6| Step: 4
Training loss: 2.540654173586154
Validation loss: 2.504211981499549

Epoch: 6| Step: 5
Training loss: 2.7734601087051636
Validation loss: 2.494418998562469

Epoch: 6| Step: 6
Training loss: 2.428646539279923
Validation loss: 2.4745601085803206

Epoch: 6| Step: 7
Training loss: 2.2311827791063013
Validation loss: 2.4844753105564634

Epoch: 6| Step: 8
Training loss: 3.1592664750926804
Validation loss: 2.490123144661982

Epoch: 6| Step: 9
Training loss: 2.1847872671101998
Validation loss: 2.5008266579414036

Epoch: 6| Step: 10
Training loss: 2.775656572629202
Validation loss: 2.503813357874039

Epoch: 6| Step: 11
Training loss: 2.0471625672057905
Validation loss: 2.4902522631394204

Epoch: 6| Step: 12
Training loss: 3.4179949775779437
Validation loss: 2.467818314271574

Epoch: 6| Step: 13
Training loss: 2.798105746934274
Validation loss: 2.503815562317849

Epoch: 106| Step: 0
Training loss: 2.7525294548489017
Validation loss: 2.4855666519296227

Epoch: 6| Step: 1
Training loss: 2.5632225506591824
Validation loss: 2.4977526089689595

Epoch: 6| Step: 2
Training loss: 1.8852563723153062
Validation loss: 2.480257042352704

Epoch: 6| Step: 3
Training loss: 3.1052169217862473
Validation loss: 2.483792737815068

Epoch: 6| Step: 4
Training loss: 2.6361302149886257
Validation loss: 2.4929988945784136

Epoch: 6| Step: 5
Training loss: 1.9258305231874708
Validation loss: 2.498350581703565

Epoch: 6| Step: 6
Training loss: 3.44234319569402
Validation loss: 2.4777598316734584

Epoch: 6| Step: 7
Training loss: 2.5149481200371255
Validation loss: 2.483561712834226

Epoch: 6| Step: 8
Training loss: 2.534877861737283
Validation loss: 2.472967671529593

Epoch: 6| Step: 9
Training loss: 3.1614034146226566
Validation loss: 2.474544081631157

Epoch: 6| Step: 10
Training loss: 2.8045505500871943
Validation loss: 2.4907490421108425

Epoch: 6| Step: 11
Training loss: 1.7954488651023357
Validation loss: 2.4850342326656683

Epoch: 6| Step: 12
Training loss: 2.594645150385867
Validation loss: 2.4887592515096557

Epoch: 6| Step: 13
Training loss: 2.7152168731059527
Validation loss: 2.5016480663880136

Epoch: 107| Step: 0
Training loss: 2.8483845599638453
Validation loss: 2.480554417881437

Epoch: 6| Step: 1
Training loss: 2.315538626641699
Validation loss: 2.4940460195101632

Epoch: 6| Step: 2
Training loss: 2.734100502404946
Validation loss: 2.5152725617926244

Epoch: 6| Step: 3
Training loss: 3.3520412147646628
Validation loss: 2.480783620985072

Epoch: 6| Step: 4
Training loss: 2.3279032761645166
Validation loss: 2.4664478183162

Epoch: 6| Step: 5
Training loss: 2.7716309587293035
Validation loss: 2.4876386035666176

Epoch: 6| Step: 6
Training loss: 2.5760000083342844
Validation loss: 2.513090586003744

Epoch: 6| Step: 7
Training loss: 1.9975215336828926
Validation loss: 2.467545844572693

Epoch: 6| Step: 8
Training loss: 2.9217976442592706
Validation loss: 2.4862594551832133

Epoch: 6| Step: 9
Training loss: 2.4380528727768236
Validation loss: 2.4867084823388743

Epoch: 6| Step: 10
Training loss: 2.735660795622969
Validation loss: 2.5022793787082813

Epoch: 6| Step: 11
Training loss: 2.4027712557881165
Validation loss: 2.4700606618194905

Epoch: 6| Step: 12
Training loss: 2.5475281422027396
Validation loss: 2.485507087234159

Epoch: 6| Step: 13
Training loss: 3.100777091794579
Validation loss: 2.4797223432570417

Epoch: 108| Step: 0
Training loss: 2.4941509488578424
Validation loss: 2.4853696260658715

Epoch: 6| Step: 1
Training loss: 1.7493185351364189
Validation loss: 2.468823131860764

Epoch: 6| Step: 2
Training loss: 2.639293989798674
Validation loss: 2.4900846195894863

Epoch: 6| Step: 3
Training loss: 2.809967766030488
Validation loss: 2.494354171322898

Epoch: 6| Step: 4
Training loss: 3.0708662703329423
Validation loss: 2.501272255179339

Epoch: 6| Step: 5
Training loss: 3.1715382364329536
Validation loss: 2.5015046001508607

Epoch: 6| Step: 6
Training loss: 1.805423272821645
Validation loss: 2.4980081047237235

Epoch: 6| Step: 7
Training loss: 2.7039269817696074
Validation loss: 2.473186763182612

Epoch: 6| Step: 8
Training loss: 2.953768382554035
Validation loss: 2.4740080421173065

Epoch: 6| Step: 9
Training loss: 2.939165657662663
Validation loss: 2.504369012890022

Epoch: 6| Step: 10
Training loss: 3.3099810541538486
Validation loss: 2.4917532684336967

Epoch: 6| Step: 11
Training loss: 2.3779892430298797
Validation loss: 2.504116355475635

Epoch: 6| Step: 12
Training loss: 1.9819936806648282
Validation loss: 2.524051897386636

Epoch: 6| Step: 13
Training loss: 1.8742234211299387
Validation loss: 2.498946139006967

Epoch: 109| Step: 0
Training loss: 2.4894403605460846
Validation loss: 2.5005861743658864

Epoch: 6| Step: 1
Training loss: 2.100010522180263
Validation loss: 2.506356556643098

Epoch: 6| Step: 2
Training loss: 2.0924582980613917
Validation loss: 2.4773005942959445

Epoch: 6| Step: 3
Training loss: 2.414299913108264
Validation loss: 2.4893111608212832

Epoch: 6| Step: 4
Training loss: 2.7443400137471063
Validation loss: 2.496130925224466

Epoch: 6| Step: 5
Training loss: 2.386753512814555
Validation loss: 2.5037388766351523

Epoch: 6| Step: 6
Training loss: 2.8493673994461237
Validation loss: 2.503714188659626

Epoch: 6| Step: 7
Training loss: 2.644370227684091
Validation loss: 2.5010592708381605

Epoch: 6| Step: 8
Training loss: 3.340356834218049
Validation loss: 2.471248164936171

Epoch: 6| Step: 9
Training loss: 2.9621859613393053
Validation loss: 2.4829810399370467

Epoch: 6| Step: 10
Training loss: 2.7155779168335052
Validation loss: 2.479921878587556

Epoch: 6| Step: 11
Training loss: 2.761373409278207
Validation loss: 2.503997293758283

Epoch: 6| Step: 12
Training loss: 2.728348373934007
Validation loss: 2.504006734377806

Epoch: 6| Step: 13
Training loss: 2.336925489028688
Validation loss: 2.534031585760582

Epoch: 110| Step: 0
Training loss: 2.648205142110582
Validation loss: 2.5177909501261158

Epoch: 6| Step: 1
Training loss: 2.9404989314850045
Validation loss: 2.4893564268522073

Epoch: 6| Step: 2
Training loss: 2.4971495590793427
Validation loss: 2.5001980887658983

Epoch: 6| Step: 3
Training loss: 2.928340999164075
Validation loss: 2.5063971524270077

Epoch: 6| Step: 4
Training loss: 2.767277800229861
Validation loss: 2.4736491531582363

Epoch: 6| Step: 5
Training loss: 2.240964017409793
Validation loss: 2.5005438397685205

Epoch: 6| Step: 6
Training loss: 2.490981428998269
Validation loss: 2.502049547345934

Epoch: 6| Step: 7
Training loss: 2.0672312713856016
Validation loss: 2.4756492617488197

Epoch: 6| Step: 8
Training loss: 3.3849205866504
Validation loss: 2.5176483569384858

Epoch: 6| Step: 9
Training loss: 2.625307428432053
Validation loss: 2.4873559998837216

Epoch: 6| Step: 10
Training loss: 2.5875234667317417
Validation loss: 2.4895720476253493

Epoch: 6| Step: 11
Training loss: 2.557189649319716
Validation loss: 2.4861315100830494

Epoch: 6| Step: 12
Training loss: 2.6743778753120315
Validation loss: 2.485846305336641

Epoch: 6| Step: 13
Training loss: 1.902115700464804
Validation loss: 2.4873832238247973

Epoch: 111| Step: 0
Training loss: 2.3868577982204515
Validation loss: 2.498568637819663

Epoch: 6| Step: 1
Training loss: 2.4846408149978587
Validation loss: 2.495993291138409

Epoch: 6| Step: 2
Training loss: 1.9868998047131405
Validation loss: 2.492669720987

Epoch: 6| Step: 3
Training loss: 2.8401607457190585
Validation loss: 2.4812218563200608

Epoch: 6| Step: 4
Training loss: 2.120992921571912
Validation loss: 2.4805177399055403

Epoch: 6| Step: 5
Training loss: 3.187507479789784
Validation loss: 2.499976312873768

Epoch: 6| Step: 6
Training loss: 2.7603142389451585
Validation loss: 2.4640585353605435

Epoch: 6| Step: 7
Training loss: 2.6023154329049363
Validation loss: 2.485472785573257

Epoch: 6| Step: 8
Training loss: 2.2468111965580277
Validation loss: 2.5030227773198

Epoch: 6| Step: 9
Training loss: 3.0497274495903186
Validation loss: 2.4918962168836263

Epoch: 6| Step: 10
Training loss: 2.7310865410048812
Validation loss: 2.5047069917147535

Epoch: 6| Step: 11
Training loss: 3.1378632354205784
Validation loss: 2.4997167139650567

Epoch: 6| Step: 12
Training loss: 2.6603958089235404
Validation loss: 2.472607496251044

Epoch: 6| Step: 13
Training loss: 2.627594619194255
Validation loss: 2.4687778424081497

Epoch: 112| Step: 0
Training loss: 2.166868518327823
Validation loss: 2.5072599281490904

Epoch: 6| Step: 1
Training loss: 2.6001643642411025
Validation loss: 2.4921420745099194

Epoch: 6| Step: 2
Training loss: 2.9551791358521036
Validation loss: 2.489405235160115

Epoch: 6| Step: 3
Training loss: 2.3459576191566005
Validation loss: 2.5048690183043383

Epoch: 6| Step: 4
Training loss: 2.9716737504561954
Validation loss: 2.505718175654504

Epoch: 6| Step: 5
Training loss: 2.1810571885899512
Validation loss: 2.489928303809141

Epoch: 6| Step: 6
Training loss: 2.761256328970968
Validation loss: 2.5221143041016507

Epoch: 6| Step: 7
Training loss: 3.0002387269721127
Validation loss: 2.4541626854278977

Epoch: 6| Step: 8
Training loss: 2.4113339308967445
Validation loss: 2.4983830452707037

Epoch: 6| Step: 9
Training loss: 2.189502344590609
Validation loss: 2.507036771681835

Epoch: 6| Step: 10
Training loss: 2.293495442663887
Validation loss: 2.476275011889092

Epoch: 6| Step: 11
Training loss: 2.633952542027351
Validation loss: 2.4945752919225597

Epoch: 6| Step: 12
Training loss: 3.376153960572699
Validation loss: 2.491452435077177

Epoch: 6| Step: 13
Training loss: 2.7395488509605586
Validation loss: 2.4838395906798985

Epoch: 113| Step: 0
Training loss: 2.5497267034345135
Validation loss: 2.4921107630591535

Epoch: 6| Step: 1
Training loss: 2.5961038410772415
Validation loss: 2.502478854439673

Epoch: 6| Step: 2
Training loss: 2.4702290800174125
Validation loss: 2.482619729601445

Epoch: 6| Step: 3
Training loss: 2.757043920516498
Validation loss: 2.4879383184336983

Epoch: 6| Step: 4
Training loss: 2.6679276425502603
Validation loss: 2.496772367415487

Epoch: 6| Step: 5
Training loss: 2.004045210216038
Validation loss: 2.5160999475212207

Epoch: 6| Step: 6
Training loss: 2.9553443602185494
Validation loss: 2.494195694331952

Epoch: 6| Step: 7
Training loss: 2.5313199822441543
Validation loss: 2.488078830804157

Epoch: 6| Step: 8
Training loss: 3.300831233441819
Validation loss: 2.492099161325067

Epoch: 6| Step: 9
Training loss: 2.0022041572793614
Validation loss: 2.4808802863942745

Epoch: 6| Step: 10
Training loss: 2.737822011185022
Validation loss: 2.475262344458942

Epoch: 6| Step: 11
Training loss: 2.3126275310920037
Validation loss: 2.464764513167997

Epoch: 6| Step: 12
Training loss: 2.316767080678531
Validation loss: 2.484248111575282

Epoch: 6| Step: 13
Training loss: 3.443151232940957
Validation loss: 2.49755900997895

Epoch: 114| Step: 0
Training loss: 2.3783722076054783
Validation loss: 2.5117130842441435

Epoch: 6| Step: 1
Training loss: 2.7538137866791397
Validation loss: 2.5079004017196262

Epoch: 6| Step: 2
Training loss: 2.7601185955607157
Validation loss: 2.489465380587081

Epoch: 6| Step: 3
Training loss: 2.2302939752357536
Validation loss: 2.506516863661893

Epoch: 6| Step: 4
Training loss: 2.723888408475761
Validation loss: 2.492924003852374

Epoch: 6| Step: 5
Training loss: 2.489542834432679
Validation loss: 2.4878976780320707

Epoch: 6| Step: 6
Training loss: 2.511139086433401
Validation loss: 2.4861754852513744

Epoch: 6| Step: 7
Training loss: 2.6240990318707373
Validation loss: 2.499634956042162

Epoch: 6| Step: 8
Training loss: 2.861672900783152
Validation loss: 2.491286317065947

Epoch: 6| Step: 9
Training loss: 2.585393473859028
Validation loss: 2.494567735334388

Epoch: 6| Step: 10
Training loss: 2.794568352030403
Validation loss: 2.4861197422678494

Epoch: 6| Step: 11
Training loss: 2.4845557956767754
Validation loss: 2.4808362390644736

Epoch: 6| Step: 12
Training loss: 2.394032760931353
Validation loss: 2.5054135232890427

Epoch: 6| Step: 13
Training loss: 3.232684149574945
Validation loss: 2.5019066994669164

Epoch: 115| Step: 0
Training loss: 2.6807844847154745
Validation loss: 2.4755932734615915

Epoch: 6| Step: 1
Training loss: 2.637509827798911
Validation loss: 2.494661782550262

Epoch: 6| Step: 2
Training loss: 2.026458958765279
Validation loss: 2.467446692049729

Epoch: 6| Step: 3
Training loss: 3.0417380825350726
Validation loss: 2.510239638592377

Epoch: 6| Step: 4
Training loss: 3.1016316826548946
Validation loss: 2.4915810833890246

Epoch: 6| Step: 5
Training loss: 2.6967224855936958
Validation loss: 2.487794688118523

Epoch: 6| Step: 6
Training loss: 2.3033442316565744
Validation loss: 2.491143200864175

Epoch: 6| Step: 7
Training loss: 2.933913130968741
Validation loss: 2.4962880213056917

Epoch: 6| Step: 8
Training loss: 2.7303582034019414
Validation loss: 2.503170627507259

Epoch: 6| Step: 9
Training loss: 2.476740304238103
Validation loss: 2.4925027316757284

Epoch: 6| Step: 10
Training loss: 2.797003886913317
Validation loss: 2.4748415858041812

Epoch: 6| Step: 11
Training loss: 1.7399024518391522
Validation loss: 2.5082127908409966

Epoch: 6| Step: 12
Training loss: 2.5103001125604183
Validation loss: 2.49742703369823

Epoch: 6| Step: 13
Training loss: 3.061547890402744
Validation loss: 2.4838439653509945

Epoch: 116| Step: 0
Training loss: 2.1498855427283274
Validation loss: 2.5032248391541345

Epoch: 6| Step: 1
Training loss: 2.433728552646895
Validation loss: 2.4957472078749485

Epoch: 6| Step: 2
Training loss: 2.5164783049401835
Validation loss: 2.5046390914054215

Epoch: 6| Step: 3
Training loss: 3.1575403880528685
Validation loss: 2.470192085789177

Epoch: 6| Step: 4
Training loss: 2.3541936507127343
Validation loss: 2.4774602839600264

Epoch: 6| Step: 5
Training loss: 2.3444682737267377
Validation loss: 2.500406984303707

Epoch: 6| Step: 6
Training loss: 2.6177471416575457
Validation loss: 2.5002819291984526

Epoch: 6| Step: 7
Training loss: 2.2143402334612325
Validation loss: 2.491862304612033

Epoch: 6| Step: 8
Training loss: 3.2450853013875074
Validation loss: 2.4720537300812633

Epoch: 6| Step: 9
Training loss: 2.9839553937467156
Validation loss: 2.4931615452988507

Epoch: 6| Step: 10
Training loss: 2.606438452038789
Validation loss: 2.4858444959290673

Epoch: 6| Step: 11
Training loss: 2.712521400894614
Validation loss: 2.4693176584724106

Epoch: 6| Step: 12
Training loss: 2.617511968284724
Validation loss: 2.473242069996623

Epoch: 6| Step: 13
Training loss: 2.2592409888236924
Validation loss: 2.473967654734712

Epoch: 117| Step: 0
Training loss: 2.192172700120992
Validation loss: 2.5086666913297644

Epoch: 6| Step: 1
Training loss: 2.379188658639932
Validation loss: 2.4775980996211424

Epoch: 6| Step: 2
Training loss: 3.133063632098512
Validation loss: 2.499439542767374

Epoch: 6| Step: 3
Training loss: 2.5106862557886647
Validation loss: 2.460853281710728

Epoch: 6| Step: 4
Training loss: 2.555717050821523
Validation loss: 2.488362718509516

Epoch: 6| Step: 5
Training loss: 2.4511803372301637
Validation loss: 2.4635309391134608

Epoch: 6| Step: 6
Training loss: 2.502809090747147
Validation loss: 2.4848523054545346

Epoch: 6| Step: 7
Training loss: 3.0539072118227253
Validation loss: 2.4837383275600247

Epoch: 6| Step: 8
Training loss: 2.075582684433322
Validation loss: 2.4939470077465367

Epoch: 6| Step: 9
Training loss: 2.9471156421517177
Validation loss: 2.486633879500859

Epoch: 6| Step: 10
Training loss: 2.4291090690715804
Validation loss: 2.4845694415986572

Epoch: 6| Step: 11
Training loss: 2.7531690544214897
Validation loss: 2.502294267019795

Epoch: 6| Step: 12
Training loss: 2.7329134277411407
Validation loss: 2.474999522530949

Epoch: 6| Step: 13
Training loss: 2.8764841975589146
Validation loss: 2.4938546097025185

Epoch: 118| Step: 0
Training loss: 2.5394085926985808
Validation loss: 2.4838367337476766

Epoch: 6| Step: 1
Training loss: 2.4175786457070454
Validation loss: 2.4602310179671028

Epoch: 6| Step: 2
Training loss: 2.615059514143456
Validation loss: 2.494303813837197

Epoch: 6| Step: 3
Training loss: 2.6678190622185327
Validation loss: 2.473744702962584

Epoch: 6| Step: 4
Training loss: 2.635147281996766
Validation loss: 2.4674191089160282

Epoch: 6| Step: 5
Training loss: 2.0082914619776786
Validation loss: 2.4735956473866705

Epoch: 6| Step: 6
Training loss: 3.122445092065881
Validation loss: 2.498660685583513

Epoch: 6| Step: 7
Training loss: 2.0356709420697654
Validation loss: 2.4899360412726703

Epoch: 6| Step: 8
Training loss: 2.713181504102986
Validation loss: 2.5063048118939784

Epoch: 6| Step: 9
Training loss: 2.618099224649414
Validation loss: 2.5018746156699305

Epoch: 6| Step: 10
Training loss: 3.0502607265409183
Validation loss: 2.5161336828950827

Epoch: 6| Step: 11
Training loss: 2.4772769126188607
Validation loss: 2.487396225537515

Epoch: 6| Step: 12
Training loss: 2.4451832112511473
Validation loss: 2.5119670610641194

Epoch: 6| Step: 13
Training loss: 3.2949084161235938
Validation loss: 2.487103778277338

Epoch: 119| Step: 0
Training loss: 2.3365104253378375
Validation loss: 2.4977914776363894

Epoch: 6| Step: 1
Training loss: 3.360928056704539
Validation loss: 2.5133448652903394

Epoch: 6| Step: 2
Training loss: 2.9947855454534364
Validation loss: 2.4973769034460678

Epoch: 6| Step: 3
Training loss: 1.968854023440767
Validation loss: 2.4515691666879196

Epoch: 6| Step: 4
Training loss: 3.1925433781603574
Validation loss: 2.4845675523265323

Epoch: 6| Step: 5
Training loss: 2.9866889650784016
Validation loss: 2.492116261468086

Epoch: 6| Step: 6
Training loss: 2.6168309210797407
Validation loss: 2.4967070714481

Epoch: 6| Step: 7
Training loss: 2.237060746706344
Validation loss: 2.5038215674463906

Epoch: 6| Step: 8
Training loss: 2.671654407697583
Validation loss: 2.4924213511743

Epoch: 6| Step: 9
Training loss: 2.5557601496672087
Validation loss: 2.4516208756629703

Epoch: 6| Step: 10
Training loss: 2.1641940410862297
Validation loss: 2.479831679439509

Epoch: 6| Step: 11
Training loss: 2.4306622969183023
Validation loss: 2.463533105718057

Epoch: 6| Step: 12
Training loss: 2.348561751783614
Validation loss: 2.4667575449722143

Epoch: 6| Step: 13
Training loss: 2.235865595932307
Validation loss: 2.4690577511334517

Epoch: 120| Step: 0
Training loss: 2.894574740310931
Validation loss: 2.4969529800305317

Epoch: 6| Step: 1
Training loss: 2.2380701201825657
Validation loss: 2.4756983232069154

Epoch: 6| Step: 2
Training loss: 2.9252652170300424
Validation loss: 2.486911303773258

Epoch: 6| Step: 3
Training loss: 1.9252814520642108
Validation loss: 2.498919421644421

Epoch: 6| Step: 4
Training loss: 2.4062193831440464
Validation loss: 2.477508939626313

Epoch: 6| Step: 5
Training loss: 2.5084525269062663
Validation loss: 2.4813269281327086

Epoch: 6| Step: 6
Training loss: 2.575909766802592
Validation loss: 2.4741469043998814

Epoch: 6| Step: 7
Training loss: 3.2348123890454263
Validation loss: 2.498988470920223

Epoch: 6| Step: 8
Training loss: 2.484243809337106
Validation loss: 2.494007452242515

Epoch: 6| Step: 9
Training loss: 3.07747011915462
Validation loss: 2.4947097672050993

Epoch: 6| Step: 10
Training loss: 2.4397388837584346
Validation loss: 2.5017234527313263

Epoch: 6| Step: 11
Training loss: 2.6869618076553192
Validation loss: 2.473950004282965

Epoch: 6| Step: 12
Training loss: 2.2516451225501886
Validation loss: 2.460953593685709

Epoch: 6| Step: 13
Training loss: 2.2865934107569155
Validation loss: 2.505238262662297

Epoch: 121| Step: 0
Training loss: 2.5253135864119525
Validation loss: 2.464392978666848

Epoch: 6| Step: 1
Training loss: 2.1305521071283295
Validation loss: 2.503439914689716

Epoch: 6| Step: 2
Training loss: 1.7522656896571531
Validation loss: 2.5226568773898737

Epoch: 6| Step: 3
Training loss: 2.41242110365497
Validation loss: 2.4587223832459246

Epoch: 6| Step: 4
Training loss: 2.7727437615792607
Validation loss: 2.5044614319621723

Epoch: 6| Step: 5
Training loss: 2.5377303634333286
Validation loss: 2.4952330723626734

Epoch: 6| Step: 6
Training loss: 3.04562524449132
Validation loss: 2.4762751889221484

Epoch: 6| Step: 7
Training loss: 3.0768640714269595
Validation loss: 2.5239836231602855

Epoch: 6| Step: 8
Training loss: 2.677694396896817
Validation loss: 2.4661026698017907

Epoch: 6| Step: 9
Training loss: 2.6703345782782972
Validation loss: 2.4989771483526626

Epoch: 6| Step: 10
Training loss: 2.557822074709095
Validation loss: 2.504413684308391

Epoch: 6| Step: 11
Training loss: 2.2970394153526392
Validation loss: 2.47457873990775

Epoch: 6| Step: 12
Training loss: 3.428171574459643
Validation loss: 2.4994845756269477

Epoch: 6| Step: 13
Training loss: 2.0348676890632
Validation loss: 2.4677131077629983

Epoch: 122| Step: 0
Training loss: 2.408132634055509
Validation loss: 2.4860050784301126

Epoch: 6| Step: 1
Training loss: 2.444265708264979
Validation loss: 2.48718349495978

Epoch: 6| Step: 2
Training loss: 2.8993824860397437
Validation loss: 2.4804851841174242

Epoch: 6| Step: 3
Training loss: 2.7175055100035057
Validation loss: 2.4634989362060464

Epoch: 6| Step: 4
Training loss: 2.533824129831577
Validation loss: 2.4788351674067357

Epoch: 6| Step: 5
Training loss: 2.7075112097623473
Validation loss: 2.475544611729175

Epoch: 6| Step: 6
Training loss: 2.145544483286409
Validation loss: 2.4773490683810255

Epoch: 6| Step: 7
Training loss: 3.0738401070721317
Validation loss: 2.470917199733419

Epoch: 6| Step: 8
Training loss: 2.4325294677894074
Validation loss: 2.4726877559625935

Epoch: 6| Step: 9
Training loss: 2.9338809506447516
Validation loss: 2.503381570968717

Epoch: 6| Step: 10
Training loss: 3.0088041181970766
Validation loss: 2.4937217850823377

Epoch: 6| Step: 11
Training loss: 2.557364924379255
Validation loss: 2.4889527377480287

Epoch: 6| Step: 12
Training loss: 2.1363185807721297
Validation loss: 2.526394748062143

Epoch: 6| Step: 13
Training loss: 2.1618611400873498
Validation loss: 2.5076291854235264

Epoch: 123| Step: 0
Training loss: 2.5517983621323697
Validation loss: 2.5002287103776184

Epoch: 6| Step: 1
Training loss: 2.601349784700639
Validation loss: 2.4885788271450933

Epoch: 6| Step: 2
Training loss: 3.1369704814150756
Validation loss: 2.4714360845896377

Epoch: 6| Step: 3
Training loss: 2.8945328973721693
Validation loss: 2.483564266603532

Epoch: 6| Step: 4
Training loss: 2.4406397234170973
Validation loss: 2.4888149261044537

Epoch: 6| Step: 5
Training loss: 2.457356684591225
Validation loss: 2.5046094157560628

Epoch: 6| Step: 6
Training loss: 2.5629541878477555
Validation loss: 2.515372889711047

Epoch: 6| Step: 7
Training loss: 2.5869079797139696
Validation loss: 2.5112696979375566

Epoch: 6| Step: 8
Training loss: 2.549050554530691
Validation loss: 2.5084000650096128

Epoch: 6| Step: 9
Training loss: 2.2387473268562172
Validation loss: 2.4719318940539865

Epoch: 6| Step: 10
Training loss: 2.609615109298066
Validation loss: 2.508463927299934

Epoch: 6| Step: 11
Training loss: 2.788344517890797
Validation loss: 2.485938503454182

Epoch: 6| Step: 12
Training loss: 2.125667467195024
Validation loss: 2.473511405086706

Epoch: 6| Step: 13
Training loss: 3.103216465334814
Validation loss: 2.507536045779248

Epoch: 124| Step: 0
Training loss: 1.3344182527844326
Validation loss: 2.4626569708409494

Epoch: 6| Step: 1
Training loss: 3.323853810020926
Validation loss: 2.490359106476871

Epoch: 6| Step: 2
Training loss: 2.3824136368908846
Validation loss: 2.4653294362370395

Epoch: 6| Step: 3
Training loss: 2.52935116978404
Validation loss: 2.4660141160997058

Epoch: 6| Step: 4
Training loss: 2.5078417814927993
Validation loss: 2.5105209733992933

Epoch: 6| Step: 5
Training loss: 1.7935062176331027
Validation loss: 2.5045434346035838

Epoch: 6| Step: 6
Training loss: 3.3027014569988764
Validation loss: 2.5000983629052196

Epoch: 6| Step: 7
Training loss: 2.8883755566092972
Validation loss: 2.5015080313110354

Epoch: 6| Step: 8
Training loss: 2.3252497590157875
Validation loss: 2.474890336977421

Epoch: 6| Step: 9
Training loss: 3.134604837922828
Validation loss: 2.485228397808498

Epoch: 6| Step: 10
Training loss: 2.7206929597575713
Validation loss: 2.494675547891845

Epoch: 6| Step: 11
Training loss: 2.3079439594532634
Validation loss: 2.4721101319356333

Epoch: 6| Step: 12
Training loss: 2.264500621793042
Validation loss: 2.5043523311523384

Epoch: 6| Step: 13
Training loss: 2.7412175476407654
Validation loss: 2.5207473464276573

Epoch: 125| Step: 0
Training loss: 3.0633406750325034
Validation loss: 2.4763894450729866

Epoch: 6| Step: 1
Training loss: 2.9423755198735546
Validation loss: 2.4991812411226833

Epoch: 6| Step: 2
Training loss: 2.454484987798534
Validation loss: 2.4989842248351657

Epoch: 6| Step: 3
Training loss: 2.4653273408829666
Validation loss: 2.486964690059944

Epoch: 6| Step: 4
Training loss: 2.2512346694822503
Validation loss: 2.4960480772048887

Epoch: 6| Step: 5
Training loss: 2.5794877583227476
Validation loss: 2.514419415569503

Epoch: 6| Step: 6
Training loss: 2.876309967145337
Validation loss: 2.488304870218274

Epoch: 6| Step: 7
Training loss: 2.501195812334209
Validation loss: 2.4961544064607954

Epoch: 6| Step: 8
Training loss: 3.0832945503338878
Validation loss: 2.485895782248742

Epoch: 6| Step: 9
Training loss: 2.886207297807621
Validation loss: 2.448312412616745

Epoch: 6| Step: 10
Training loss: 2.005394336611256
Validation loss: 2.463503627452635

Epoch: 6| Step: 11
Training loss: 2.3812829283192265
Validation loss: 2.4547448360451622

Epoch: 6| Step: 12
Training loss: 2.1036566188529786
Validation loss: 2.4497148146488685

Epoch: 6| Step: 13
Training loss: 2.6030809707856397
Validation loss: 2.4533273992103317

Epoch: 126| Step: 0
Training loss: 2.746052422897596
Validation loss: 2.4820832775248256

Epoch: 6| Step: 1
Training loss: 2.9781472300353267
Validation loss: 2.5085296111586124

Epoch: 6| Step: 2
Training loss: 2.6124396686797295
Validation loss: 2.503420350191508

Epoch: 6| Step: 3
Training loss: 3.1078620948881057
Validation loss: 2.4743705301633696

Epoch: 6| Step: 4
Training loss: 2.266405589364293
Validation loss: 2.500626176944033

Epoch: 6| Step: 5
Training loss: 2.926736143615564
Validation loss: 2.502578606318727

Epoch: 6| Step: 6
Training loss: 2.7845538800082403
Validation loss: 2.4967589955992033

Epoch: 6| Step: 7
Training loss: 1.760579825821482
Validation loss: 2.4974918109438007

Epoch: 6| Step: 8
Training loss: 2.1621641791340727
Validation loss: 2.4957578003764844

Epoch: 6| Step: 9
Training loss: 2.4446457023807064
Validation loss: 2.4812500960467623

Epoch: 6| Step: 10
Training loss: 2.8811983381095776
Validation loss: 2.4965070821687263

Epoch: 6| Step: 11
Training loss: 2.2135841515147785
Validation loss: 2.4990920233047706

Epoch: 6| Step: 12
Training loss: 2.52679012785386
Validation loss: 2.495808496255255

Epoch: 6| Step: 13
Training loss: 2.589032306391486
Validation loss: 2.4971316341112586

Epoch: 127| Step: 0
Training loss: 2.336160604482081
Validation loss: 2.4967759888725656

Epoch: 6| Step: 1
Training loss: 2.882681825565612
Validation loss: 2.5126488691450732

Epoch: 6| Step: 2
Training loss: 2.630526583211139
Validation loss: 2.5142861973538047

Epoch: 6| Step: 3
Training loss: 3.0131647223445874
Validation loss: 2.4958532623438163

Epoch: 6| Step: 4
Training loss: 3.4289271874004763
Validation loss: 2.486242812793677

Epoch: 6| Step: 5
Training loss: 2.7379090060208804
Validation loss: 2.5241788121118005

Epoch: 6| Step: 6
Training loss: 2.8037548161404486
Validation loss: 2.4976382379733253

Epoch: 6| Step: 7
Training loss: 2.8422394817478778
Validation loss: 2.4965517782259616

Epoch: 6| Step: 8
Training loss: 2.4391448511056684
Validation loss: 2.463684031783004

Epoch: 6| Step: 9
Training loss: 2.2592407777629053
Validation loss: 2.4768071523321664

Epoch: 6| Step: 10
Training loss: 1.9304089143650773
Validation loss: 2.497127419774479

Epoch: 6| Step: 11
Training loss: 1.9900570117508998
Validation loss: 2.503683689545385

Epoch: 6| Step: 12
Training loss: 2.2027158966074114
Validation loss: 2.4753644773268517

Epoch: 6| Step: 13
Training loss: 2.5394528132991367
Validation loss: 2.4688524344644374

Epoch: 128| Step: 0
Training loss: 3.083046014819141
Validation loss: 2.4767988987608422

Epoch: 6| Step: 1
Training loss: 2.93424222765632
Validation loss: 2.49774439792407

Epoch: 6| Step: 2
Training loss: 2.04047844493411
Validation loss: 2.483548180084013

Epoch: 6| Step: 3
Training loss: 2.478899025027389
Validation loss: 2.4864462171210273

Epoch: 6| Step: 4
Training loss: 2.2621135992907586
Validation loss: 2.491516390156684

Epoch: 6| Step: 5
Training loss: 2.801954122256244
Validation loss: 2.4707795836510917

Epoch: 6| Step: 6
Training loss: 2.2510260255885974
Validation loss: 2.4537976844063483

Epoch: 6| Step: 7
Training loss: 2.4604970386458622
Validation loss: 2.4880299480475236

Epoch: 6| Step: 8
Training loss: 2.468941210331514
Validation loss: 2.510705469595703

Epoch: 6| Step: 9
Training loss: 2.847801257131907
Validation loss: 2.4848619580906877

Epoch: 6| Step: 10
Training loss: 3.139184725913434
Validation loss: 2.471846288779765

Epoch: 6| Step: 11
Training loss: 2.6443546298168186
Validation loss: 2.4479227904219383

Epoch: 6| Step: 12
Training loss: 2.2520581474860286
Validation loss: 2.4443334245532213

Epoch: 6| Step: 13
Training loss: 2.186328901434224
Validation loss: 2.495317705290139

Epoch: 129| Step: 0
Training loss: 2.347768568249655
Validation loss: 2.457140788849528

Epoch: 6| Step: 1
Training loss: 2.451404138024737
Validation loss: 2.4870614399267432

Epoch: 6| Step: 2
Training loss: 2.129989152621018
Validation loss: 2.488457336083397

Epoch: 6| Step: 3
Training loss: 3.0179851566098828
Validation loss: 2.472060893486256

Epoch: 6| Step: 4
Training loss: 2.7468351011882963
Validation loss: 2.4827942646387724

Epoch: 6| Step: 5
Training loss: 2.5964833759588872
Validation loss: 2.4970645714141995

Epoch: 6| Step: 6
Training loss: 3.2784551434237144
Validation loss: 2.5026144016595193

Epoch: 6| Step: 7
Training loss: 2.0082823207386107
Validation loss: 2.4935194559213416

Epoch: 6| Step: 8
Training loss: 2.6696654882442323
Validation loss: 2.506455168203729

Epoch: 6| Step: 9
Training loss: 2.948987373218947
Validation loss: 2.4722444821656375

Epoch: 6| Step: 10
Training loss: 2.3219067783157703
Validation loss: 2.482191128324582

Epoch: 6| Step: 11
Training loss: 2.594975744880116
Validation loss: 2.496648124743057

Epoch: 6| Step: 12
Training loss: 2.411127077314463
Validation loss: 2.5071586129795302

Epoch: 6| Step: 13
Training loss: 2.2731647131164436
Validation loss: 2.498758108075642

Epoch: 130| Step: 0
Training loss: 2.079819182275982
Validation loss: 2.5055596132182454

Epoch: 6| Step: 1
Training loss: 2.6608620490119494
Validation loss: 2.5145633530909812

Epoch: 6| Step: 2
Training loss: 2.3417480056410485
Validation loss: 2.46986932848361

Epoch: 6| Step: 3
Training loss: 2.3955509074611703
Validation loss: 2.461279900178709

Epoch: 6| Step: 4
Training loss: 2.3064297572433583
Validation loss: 2.464809950210076

Epoch: 6| Step: 5
Training loss: 2.844895352280939
Validation loss: 2.4942848467795757

Epoch: 6| Step: 6
Training loss: 2.3091398003221113
Validation loss: 2.4924323836382074

Epoch: 6| Step: 7
Training loss: 3.535390131679771
Validation loss: 2.4862757249704397

Epoch: 6| Step: 8
Training loss: 2.5514722650460686
Validation loss: 2.469464014097158

Epoch: 6| Step: 9
Training loss: 2.4318831847520523
Validation loss: 2.471708768506592

Epoch: 6| Step: 10
Training loss: 2.975418631967849
Validation loss: 2.4811186440594986

Epoch: 6| Step: 11
Training loss: 2.3457220300679684
Validation loss: 2.477318277791814

Epoch: 6| Step: 12
Training loss: 2.2448905574910114
Validation loss: 2.4820026946677918

Epoch: 6| Step: 13
Training loss: 2.775608040805708
Validation loss: 2.5091568339464594

Epoch: 131| Step: 0
Training loss: 2.4867664079716376
Validation loss: 2.5000055856539767

Epoch: 6| Step: 1
Training loss: 2.0881744848403314
Validation loss: 2.485914708124149

Epoch: 6| Step: 2
Training loss: 2.5161105806827395
Validation loss: 2.459908596157858

Epoch: 6| Step: 3
Training loss: 2.63701116000126
Validation loss: 2.5010597525984277

Epoch: 6| Step: 4
Training loss: 2.4452021272265334
Validation loss: 2.471125167720563

Epoch: 6| Step: 5
Training loss: 3.1236548008022904
Validation loss: 2.471541472844203

Epoch: 6| Step: 6
Training loss: 2.939682332477669
Validation loss: 2.4868731217060938

Epoch: 6| Step: 7
Training loss: 2.185107639550816
Validation loss: 2.503140785944141

Epoch: 6| Step: 8
Training loss: 1.9743539888399677
Validation loss: 2.4773551593959833

Epoch: 6| Step: 9
Training loss: 2.6151200512376587
Validation loss: 2.442788092849488

Epoch: 6| Step: 10
Training loss: 3.023885688780824
Validation loss: 2.484267311086591

Epoch: 6| Step: 11
Training loss: 2.6949799705709436
Validation loss: 2.4802287639279426

Epoch: 6| Step: 12
Training loss: 2.248886680668956
Validation loss: 2.4738496970054134

Epoch: 6| Step: 13
Training loss: 3.044215366890491
Validation loss: 2.4908632050457964

Epoch: 132| Step: 0
Training loss: 2.0610670255805723
Validation loss: 2.506500492830079

Epoch: 6| Step: 1
Training loss: 2.7936476515897475
Validation loss: 2.4853920485531207

Epoch: 6| Step: 2
Training loss: 2.93938028745928
Validation loss: 2.4895053847375217

Epoch: 6| Step: 3
Training loss: 2.0797471907007794
Validation loss: 2.4477152290974775

Epoch: 6| Step: 4
Training loss: 2.419393535632686
Validation loss: 2.4946093564048883

Epoch: 6| Step: 5
Training loss: 2.121056544081203
Validation loss: 2.472163175208268

Epoch: 6| Step: 6
Training loss: 3.313578016378954
Validation loss: 2.487568629140481

Epoch: 6| Step: 7
Training loss: 2.6781572693846987
Validation loss: 2.493247097865204

Epoch: 6| Step: 8
Training loss: 2.44256105500892
Validation loss: 2.5187639715711585

Epoch: 6| Step: 9
Training loss: 2.1220978385309213
Validation loss: 2.5115652301373173

Epoch: 6| Step: 10
Training loss: 2.9896080911034333
Validation loss: 2.4837607792242946

Epoch: 6| Step: 11
Training loss: 2.772369780995256
Validation loss: 2.4776942622902

Epoch: 6| Step: 12
Training loss: 2.3041523974932785
Validation loss: 2.4856724407248714

Epoch: 6| Step: 13
Training loss: 2.8854736616287324
Validation loss: 2.4844269600344706

Epoch: 133| Step: 0
Training loss: 1.9441268555573392
Validation loss: 2.498617776621834

Epoch: 6| Step: 1
Training loss: 2.4230540697186833
Validation loss: 2.472168995899269

Epoch: 6| Step: 2
Training loss: 3.1445248811076807
Validation loss: 2.461414091647488

Epoch: 6| Step: 3
Training loss: 2.1996289373797127
Validation loss: 2.451891569495255

Epoch: 6| Step: 4
Training loss: 2.6436428905099767
Validation loss: 2.492452361469034

Epoch: 6| Step: 5
Training loss: 2.159232909721147
Validation loss: 2.504577262687458

Epoch: 6| Step: 6
Training loss: 2.741983346322291
Validation loss: 2.492471571838857

Epoch: 6| Step: 7
Training loss: 2.4989647629212426
Validation loss: 2.507063571262689

Epoch: 6| Step: 8
Training loss: 2.755851069707542
Validation loss: 2.4834093944295312

Epoch: 6| Step: 9
Training loss: 2.3311328275550043
Validation loss: 2.4762195502259803

Epoch: 6| Step: 10
Training loss: 2.9372665637175337
Validation loss: 2.4832420931391432

Epoch: 6| Step: 11
Training loss: 2.684464092796761
Validation loss: 2.46651026399815

Epoch: 6| Step: 12
Training loss: 2.5719710451457014
Validation loss: 2.4744907526867745

Epoch: 6| Step: 13
Training loss: 2.805182708120799
Validation loss: 2.49947607641697

Epoch: 134| Step: 0
Training loss: 2.4460844826195314
Validation loss: 2.4671372898673387

Epoch: 6| Step: 1
Training loss: 2.6816294226026938
Validation loss: 2.470325073958218

Epoch: 6| Step: 2
Training loss: 2.1949864481375103
Validation loss: 2.479793009990115

Epoch: 6| Step: 3
Training loss: 2.0471122545957905
Validation loss: 2.5214842631609264

Epoch: 6| Step: 4
Training loss: 2.4164945826155
Validation loss: 2.476680266418976

Epoch: 6| Step: 5
Training loss: 2.960476399051068
Validation loss: 2.489049695640056

Epoch: 6| Step: 6
Training loss: 3.1029020630812263
Validation loss: 2.4706810579259266

Epoch: 6| Step: 7
Training loss: 2.257156752031406
Validation loss: 2.482732752054338

Epoch: 6| Step: 8
Training loss: 2.6085591211388257
Validation loss: 2.5025082065361293

Epoch: 6| Step: 9
Training loss: 2.4518460383906002
Validation loss: 2.4672264537193462

Epoch: 6| Step: 10
Training loss: 2.5605782536752475
Validation loss: 2.4810500945780123

Epoch: 6| Step: 11
Training loss: 2.527869616459885
Validation loss: 2.4905678673966305

Epoch: 6| Step: 12
Training loss: 3.07509994964674
Validation loss: 2.4776935131759417

Epoch: 6| Step: 13
Training loss: 2.563307100053478
Validation loss: 2.4840431365792726

Epoch: 135| Step: 0
Training loss: 2.7867080624105136
Validation loss: 2.5061374626663424

Epoch: 6| Step: 1
Training loss: 2.478753790147955
Validation loss: 2.5185752205256886

Epoch: 6| Step: 2
Training loss: 3.4052916412260785
Validation loss: 2.463575601793888

Epoch: 6| Step: 3
Training loss: 2.533797500985621
Validation loss: 2.4815472962702465

Epoch: 6| Step: 4
Training loss: 2.173654719014475
Validation loss: 2.4832774228744015

Epoch: 6| Step: 5
Training loss: 2.4961513458914024
Validation loss: 2.4925586805791085

Epoch: 6| Step: 6
Training loss: 1.94204044537213
Validation loss: 2.497062011945192

Epoch: 6| Step: 7
Training loss: 2.086401269912918
Validation loss: 2.5112899669191973

Epoch: 6| Step: 8
Training loss: 2.391122005883741
Validation loss: 2.496024030068986

Epoch: 6| Step: 9
Training loss: 2.592992832937461
Validation loss: 2.491340479124126

Epoch: 6| Step: 10
Training loss: 3.275983380323273
Validation loss: 2.4640603904177456

Epoch: 6| Step: 11
Training loss: 2.035776581922463
Validation loss: 2.4859957633207244

Epoch: 6| Step: 12
Training loss: 3.0082338508648654
Validation loss: 2.515167300675669

Epoch: 6| Step: 13
Training loss: 2.204346663030892
Validation loss: 2.510293130273594

Epoch: 136| Step: 0
Training loss: 2.6435110358420393
Validation loss: 2.4873933366174463

Epoch: 6| Step: 1
Training loss: 2.5629182799814902
Validation loss: 2.5101288851910044

Epoch: 6| Step: 2
Training loss: 2.756798317274531
Validation loss: 2.485559163874923

Epoch: 6| Step: 3
Training loss: 2.2878202120428597
Validation loss: 2.4749721944835366

Epoch: 6| Step: 4
Training loss: 2.456179327105791
Validation loss: 2.488974962126255

Epoch: 6| Step: 5
Training loss: 2.2728681867436844
Validation loss: 2.476730583721014

Epoch: 6| Step: 6
Training loss: 2.246654566535098
Validation loss: 2.489184888095637

Epoch: 6| Step: 7
Training loss: 2.7435297710346105
Validation loss: 2.5042997342244093

Epoch: 6| Step: 8
Training loss: 2.8035953701201484
Validation loss: 2.5309621651565326

Epoch: 6| Step: 9
Training loss: 2.689829504289444
Validation loss: 2.4531885664911437

Epoch: 6| Step: 10
Training loss: 2.4019983555059974
Validation loss: 2.503852076143823

Epoch: 6| Step: 11
Training loss: 2.6681217356394002
Validation loss: 2.5002412653966117

Epoch: 6| Step: 12
Training loss: 2.904557586440527
Validation loss: 2.5007903469984183

Epoch: 6| Step: 13
Training loss: 2.7025386637445954
Validation loss: 2.5100013734230093

Epoch: 137| Step: 0
Training loss: 2.606740935487939
Validation loss: 2.4950288467207735

Epoch: 6| Step: 1
Training loss: 2.3211194828215835
Validation loss: 2.5088079372745904

Epoch: 6| Step: 2
Training loss: 2.4756685683325004
Validation loss: 2.4972251484658208

Epoch: 6| Step: 3
Training loss: 2.0510380466081153
Validation loss: 2.455643465127842

Epoch: 6| Step: 4
Training loss: 2.232140123638114
Validation loss: 2.5092663838156404

Epoch: 6| Step: 5
Training loss: 2.391848581376018
Validation loss: 2.4849879537426474

Epoch: 6| Step: 6
Training loss: 2.9308807791205798
Validation loss: 2.481039226425321

Epoch: 6| Step: 7
Training loss: 2.9323292126236535
Validation loss: 2.4931901330686452

Epoch: 6| Step: 8
Training loss: 3.033115717309487
Validation loss: 2.4641012101662305

Epoch: 6| Step: 9
Training loss: 2.962724051071144
Validation loss: 2.4826308076876487

Epoch: 6| Step: 10
Training loss: 2.6043371119351155
Validation loss: 2.4653990852089422

Epoch: 6| Step: 11
Training loss: 2.399331786593043
Validation loss: 2.4702956653263226

Epoch: 6| Step: 12
Training loss: 2.3961865924849506
Validation loss: 2.5150731375085367

Epoch: 6| Step: 13
Training loss: 2.0949176550002364
Validation loss: 2.497851048058156

Epoch: 138| Step: 0
Training loss: 3.0754182794684963
Validation loss: 2.495605858595894

Epoch: 6| Step: 1
Training loss: 2.416480769757523
Validation loss: 2.51447445675479

Epoch: 6| Step: 2
Training loss: 2.6180028755516074
Validation loss: 2.4807485161545557

Epoch: 6| Step: 3
Training loss: 2.335799299253693
Validation loss: 2.4426191874170002

Epoch: 6| Step: 4
Training loss: 2.975708846585707
Validation loss: 2.484808460596217

Epoch: 6| Step: 5
Training loss: 2.6752153898138693
Validation loss: 2.487924496237723

Epoch: 6| Step: 6
Training loss: 2.5736331534112242
Validation loss: 2.489129149165415

Epoch: 6| Step: 7
Training loss: 2.45177651049266
Validation loss: 2.4912158472076587

Epoch: 6| Step: 8
Training loss: 2.610625281577064
Validation loss: 2.492404192438169

Epoch: 6| Step: 9
Training loss: 2.7332042694634593
Validation loss: 2.4619663861971306

Epoch: 6| Step: 10
Training loss: 2.100318966211242
Validation loss: 2.514643888563977

Epoch: 6| Step: 11
Training loss: 1.47198074187763
Validation loss: 2.4867597616645254

Epoch: 6| Step: 12
Training loss: 2.864904508214283
Validation loss: 2.4647918951057544

Epoch: 6| Step: 13
Training loss: 3.0354252012434353
Validation loss: 2.513654419713868

Epoch: 139| Step: 0
Training loss: 2.664837229554926
Validation loss: 2.4842866528575693

Epoch: 6| Step: 1
Training loss: 2.044087965899512
Validation loss: 2.499469730581178

Epoch: 6| Step: 2
Training loss: 2.91081977806863
Validation loss: 2.4450395626981942

Epoch: 6| Step: 3
Training loss: 2.137428737590184
Validation loss: 2.5293263517147584

Epoch: 6| Step: 4
Training loss: 2.8605117622751104
Validation loss: 2.465080640267925

Epoch: 6| Step: 5
Training loss: 2.5443121061748557
Validation loss: 2.4883421648974866

Epoch: 6| Step: 6
Training loss: 2.565820078339079
Validation loss: 2.477184858349182

Epoch: 6| Step: 7
Training loss: 2.8746503534414436
Validation loss: 2.4763537033879093

Epoch: 6| Step: 8
Training loss: 1.690300207617013
Validation loss: 2.499050014748373

Epoch: 6| Step: 9
Training loss: 2.5779058189856467
Validation loss: 2.4896014828989412

Epoch: 6| Step: 10
Training loss: 2.4330336904454843
Validation loss: 2.515141140913231

Epoch: 6| Step: 11
Training loss: 1.7973102871627549
Validation loss: 2.495346826219168

Epoch: 6| Step: 12
Training loss: 3.4582623547237015
Validation loss: 2.4727006255165107

Epoch: 6| Step: 13
Training loss: 2.970510502877423
Validation loss: 2.477810134295063

Epoch: 140| Step: 0
Training loss: 2.7424069395594
Validation loss: 2.5035881093901833

Epoch: 6| Step: 1
Training loss: 2.7150767274415606
Validation loss: 2.4669707223403496

Epoch: 6| Step: 2
Training loss: 3.7682904825272647
Validation loss: 2.510556227638874

Epoch: 6| Step: 3
Training loss: 2.217812783460423
Validation loss: 2.49505552919619

Epoch: 6| Step: 4
Training loss: 2.340454836925713
Validation loss: 2.4810980759008023

Epoch: 6| Step: 5
Training loss: 2.5660946452168223
Validation loss: 2.484000799728996

Epoch: 6| Step: 6
Training loss: 2.6524401100868715
Validation loss: 2.4724864356115153

Epoch: 6| Step: 7
Training loss: 2.069942801233507
Validation loss: 2.473215741988664

Epoch: 6| Step: 8
Training loss: 2.5962117473959814
Validation loss: 2.4889988631281628

Epoch: 6| Step: 9
Training loss: 2.1739063231737505
Validation loss: 2.4881109564885824

Epoch: 6| Step: 10
Training loss: 2.162101104637807
Validation loss: 2.5111889286829427

Epoch: 6| Step: 11
Training loss: 2.41861037213565
Validation loss: 2.4843703362979714

Epoch: 6| Step: 12
Training loss: 2.26981088094178
Validation loss: 2.5119540303803016

Epoch: 6| Step: 13
Training loss: 2.790086574236692
Validation loss: 2.488918690608634

Epoch: 141| Step: 0
Training loss: 2.564128358356629
Validation loss: 2.4499356299677952

Epoch: 6| Step: 1
Training loss: 2.3975735080496414
Validation loss: 2.477855798730325

Epoch: 6| Step: 2
Training loss: 2.233665833939522
Validation loss: 2.4782136709116354

Epoch: 6| Step: 3
Training loss: 2.214243220435733
Validation loss: 2.484246363437186

Epoch: 6| Step: 4
Training loss: 2.463999076031846
Validation loss: 2.4619601196578857

Epoch: 6| Step: 5
Training loss: 2.77929859067498
Validation loss: 2.468294846538088

Epoch: 6| Step: 6
Training loss: 2.6770374774097845
Validation loss: 2.496988347803925

Epoch: 6| Step: 7
Training loss: 2.5621435336153446
Validation loss: 2.475223080585545

Epoch: 6| Step: 8
Training loss: 2.2401346518712675
Validation loss: 2.4845656032070345

Epoch: 6| Step: 9
Training loss: 2.716871555379716
Validation loss: 2.4795189632419854

Epoch: 6| Step: 10
Training loss: 2.8706153938237375
Validation loss: 2.4901161861019996

Epoch: 6| Step: 11
Training loss: 2.8989648878978596
Validation loss: 2.4865724969542273

Epoch: 6| Step: 12
Training loss: 2.8159624615139602
Validation loss: 2.4960201959400967

Epoch: 6| Step: 13
Training loss: 1.904408800797297
Validation loss: 2.5025841227047345

Epoch: 142| Step: 0
Training loss: 2.5016817158604936
Validation loss: 2.467648961712998

Epoch: 6| Step: 1
Training loss: 2.255329918759105
Validation loss: 2.4839759878238064

Epoch: 6| Step: 2
Training loss: 2.25897239801938
Validation loss: 2.4817023352674754

Epoch: 6| Step: 3
Training loss: 2.2663517279709056
Validation loss: 2.45634698230406

Epoch: 6| Step: 4
Training loss: 3.0202735294486143
Validation loss: 2.4193935684809427

Epoch: 6| Step: 5
Training loss: 2.410967079915653
Validation loss: 2.4885780091959178

Epoch: 6| Step: 6
Training loss: 2.619393765294243
Validation loss: 2.5077021699805337

Epoch: 6| Step: 7
Training loss: 3.575956395406088
Validation loss: 2.4575987351471036

Epoch: 6| Step: 8
Training loss: 2.712596550554753
Validation loss: 2.4794248927467057

Epoch: 6| Step: 9
Training loss: 2.166401504527912
Validation loss: 2.484693145039187

Epoch: 6| Step: 10
Training loss: 2.815809379747452
Validation loss: 2.4967070930110835

Epoch: 6| Step: 11
Training loss: 1.916888334752167
Validation loss: 2.479210055323077

Epoch: 6| Step: 12
Training loss: 2.2622481864612505
Validation loss: 2.4974146046512002

Epoch: 6| Step: 13
Training loss: 2.82648222194056
Validation loss: 2.4825392116603293

Epoch: 143| Step: 0
Training loss: 2.709823511436633
Validation loss: 2.503042472951781

Epoch: 6| Step: 1
Training loss: 2.6479558366048823
Validation loss: 2.4773966319177463

Epoch: 6| Step: 2
Training loss: 2.4927799871858247
Validation loss: 2.4636908006946054

Epoch: 6| Step: 3
Training loss: 2.7220298889447547
Validation loss: 2.463488341323681

Epoch: 6| Step: 4
Training loss: 2.129457846760619
Validation loss: 2.484472751532422

Epoch: 6| Step: 5
Training loss: 2.676781415922247
Validation loss: 2.482858855755415

Epoch: 6| Step: 6
Training loss: 2.4025449094832214
Validation loss: 2.4682005632624566

Epoch: 6| Step: 7
Training loss: 2.7975451982407633
Validation loss: 2.4596268191916626

Epoch: 6| Step: 8
Training loss: 2.3360781419957366
Validation loss: 2.508815773876602

Epoch: 6| Step: 9
Training loss: 2.3129304021382695
Validation loss: 2.479891280177196

Epoch: 6| Step: 10
Training loss: 2.3919060958304263
Validation loss: 2.469849971377949

Epoch: 6| Step: 11
Training loss: 2.9757107695036886
Validation loss: 2.4485519775166606

Epoch: 6| Step: 12
Training loss: 2.7155599184655026
Validation loss: 2.4743368998821036

Epoch: 6| Step: 13
Training loss: 2.3578511552820904
Validation loss: 2.5199007315859503

Epoch: 144| Step: 0
Training loss: 2.9393179928967705
Validation loss: 2.4670028153028034

Epoch: 6| Step: 1
Training loss: 2.904203288988981
Validation loss: 2.4583460281013703

Epoch: 6| Step: 2
Training loss: 2.1449647892549555
Validation loss: 2.5001464944392633

Epoch: 6| Step: 3
Training loss: 2.8759150500106796
Validation loss: 2.465641112539871

Epoch: 6| Step: 4
Training loss: 2.5097339910153744
Validation loss: 2.504067790911932

Epoch: 6| Step: 5
Training loss: 2.650859973929101
Validation loss: 2.4736041458723146

Epoch: 6| Step: 6
Training loss: 1.7391650064287119
Validation loss: 2.5058562914999016

Epoch: 6| Step: 7
Training loss: 2.567575684706879
Validation loss: 2.502154740436235

Epoch: 6| Step: 8
Training loss: 2.8939631801706795
Validation loss: 2.4880057842594088

Epoch: 6| Step: 9
Training loss: 2.446778659214998
Validation loss: 2.499394992716128

Epoch: 6| Step: 10
Training loss: 2.0195265277386762
Validation loss: 2.4760824410876623

Epoch: 6| Step: 11
Training loss: 2.6890960212493384
Validation loss: 2.465846527652288

Epoch: 6| Step: 12
Training loss: 2.158152418274518
Validation loss: 2.470416618511282

Epoch: 6| Step: 13
Training loss: 2.9388504170826417
Validation loss: 2.4823967354293988

Epoch: 145| Step: 0
Training loss: 2.185022313333579
Validation loss: 2.497268729126815

Epoch: 6| Step: 1
Training loss: 2.1324695129719635
Validation loss: 2.4591024619800668

Epoch: 6| Step: 2
Training loss: 2.8010972189273997
Validation loss: 2.4766581625458346

Epoch: 6| Step: 3
Training loss: 2.046269450995313
Validation loss: 2.5077060455420956

Epoch: 6| Step: 4
Training loss: 2.4680222996055154
Validation loss: 2.48187503110239

Epoch: 6| Step: 5
Training loss: 2.933844706725902
Validation loss: 2.47296197608196

Epoch: 6| Step: 6
Training loss: 2.615976810836672
Validation loss: 2.4820324562383793

Epoch: 6| Step: 7
Training loss: 2.4925204924541653
Validation loss: 2.4943888215666603

Epoch: 6| Step: 8
Training loss: 2.437585291226125
Validation loss: 2.484778341246639

Epoch: 6| Step: 9
Training loss: 2.600935851910926
Validation loss: 2.46715980739779

Epoch: 6| Step: 10
Training loss: 3.399897960926821
Validation loss: 2.477214281957036

Epoch: 6| Step: 11
Training loss: 2.262915945018451
Validation loss: 2.478000235832349

Epoch: 6| Step: 12
Training loss: 2.456050125026826
Validation loss: 2.488211199887973

Epoch: 6| Step: 13
Training loss: 2.3941664052189244
Validation loss: 2.4874635509570835

Epoch: 146| Step: 0
Training loss: 2.5789948816562966
Validation loss: 2.49011675440057

Epoch: 6| Step: 1
Training loss: 2.019566194390615
Validation loss: 2.5083251333083925

Epoch: 6| Step: 2
Training loss: 1.8752734938475761
Validation loss: 2.509400082039138

Epoch: 6| Step: 3
Training loss: 2.694345582762955
Validation loss: 2.5051068915265953

Epoch: 6| Step: 4
Training loss: 2.8868044787570524
Validation loss: 2.4903183336639874

Epoch: 6| Step: 5
Training loss: 2.349787349413427
Validation loss: 2.466912471138792

Epoch: 6| Step: 6
Training loss: 1.4744380624050555
Validation loss: 2.4947286940376845

Epoch: 6| Step: 7
Training loss: 3.394435868059039
Validation loss: 2.445352990574878

Epoch: 6| Step: 8
Training loss: 2.353065188028961
Validation loss: 2.463384482319091

Epoch: 6| Step: 9
Training loss: 2.7830397601452037
Validation loss: 2.474672684871865

Epoch: 6| Step: 10
Training loss: 2.7948759809627335
Validation loss: 2.4922612062625302

Epoch: 6| Step: 11
Training loss: 2.7905721559038583
Validation loss: 2.470445253636702

Epoch: 6| Step: 12
Training loss: 2.7356483328444967
Validation loss: 2.486090526662492

Epoch: 6| Step: 13
Training loss: 2.559396678939874
Validation loss: 2.510605957903692

Epoch: 147| Step: 0
Training loss: 2.700721245259938
Validation loss: 2.4749204782567533

Epoch: 6| Step: 1
Training loss: 2.7946611732011535
Validation loss: 2.473542357070501

Epoch: 6| Step: 2
Training loss: 2.2482284353268263
Validation loss: 2.4660984700103086

Epoch: 6| Step: 3
Training loss: 2.5275409981169177
Validation loss: 2.491524950474293

Epoch: 6| Step: 4
Training loss: 2.5692175298162545
Validation loss: 2.460296076404952

Epoch: 6| Step: 5
Training loss: 2.2814139738331622
Validation loss: 2.501784341087007

Epoch: 6| Step: 6
Training loss: 2.786546272007267
Validation loss: 2.485754287376712

Epoch: 6| Step: 7
Training loss: 2.9869332258731855
Validation loss: 2.497756100707619

Epoch: 6| Step: 8
Training loss: 2.8750754636729043
Validation loss: 2.474793928099865

Epoch: 6| Step: 9
Training loss: 2.2746921498696184
Validation loss: 2.512205059184238

Epoch: 6| Step: 10
Training loss: 2.422677184121804
Validation loss: 2.501284720403648

Epoch: 6| Step: 11
Training loss: 2.17160888797995
Validation loss: 2.4836105901190586

Epoch: 6| Step: 12
Training loss: 2.215405374464359
Validation loss: 2.443389571590124

Epoch: 6| Step: 13
Training loss: 2.4914178407195497
Validation loss: 2.495883678420384

Epoch: 148| Step: 0
Training loss: 2.771902943914335
Validation loss: 2.5185808708446027

Epoch: 6| Step: 1
Training loss: 2.796970898566515
Validation loss: 2.4753483779105276

Epoch: 6| Step: 2
Training loss: 2.5422315334640095
Validation loss: 2.487519173134193

Epoch: 6| Step: 3
Training loss: 1.9154643005374181
Validation loss: 2.471822361419149

Epoch: 6| Step: 4
Training loss: 2.2394438116098527
Validation loss: 2.4891741455784873

Epoch: 6| Step: 5
Training loss: 2.234295290078691
Validation loss: 2.5044869591048684

Epoch: 6| Step: 6
Training loss: 1.965196945571001
Validation loss: 2.4847775566096435

Epoch: 6| Step: 7
Training loss: 3.1310173085263364
Validation loss: 2.4881189757382307

Epoch: 6| Step: 8
Training loss: 2.943959702070834
Validation loss: 2.4406235661570124

Epoch: 6| Step: 9
Training loss: 2.9805780193252227
Validation loss: 2.467528751815568

Epoch: 6| Step: 10
Training loss: 2.557125130155819
Validation loss: 2.495352301059705

Epoch: 6| Step: 11
Training loss: 2.39754317816556
Validation loss: 2.4397110551393806

Epoch: 6| Step: 12
Training loss: 2.785115331319772
Validation loss: 2.480585309888694

Epoch: 6| Step: 13
Training loss: 1.5364767127365577
Validation loss: 2.4914558337771178

Epoch: 149| Step: 0
Training loss: 3.0611137833980737
Validation loss: 2.4521367752862226

Epoch: 6| Step: 1
Training loss: 2.332995344841634
Validation loss: 2.5213013243983347

Epoch: 6| Step: 2
Training loss: 2.5426193911447106
Validation loss: 2.4593723062826074

Epoch: 6| Step: 3
Training loss: 2.434372289066005
Validation loss: 2.487474368367289

Epoch: 6| Step: 4
Training loss: 2.409368104838241
Validation loss: 2.470264927960832

Epoch: 6| Step: 5
Training loss: 2.853214318505825
Validation loss: 2.4919066014792928

Epoch: 6| Step: 6
Training loss: 2.5342493066063305
Validation loss: 2.502326902765708

Epoch: 6| Step: 7
Training loss: 1.8589527067311413
Validation loss: 2.4970178845621955

Epoch: 6| Step: 8
Training loss: 2.6320166587708216
Validation loss: 2.534986206016834

Epoch: 6| Step: 9
Training loss: 2.627119480240336
Validation loss: 2.4981739804925533

Epoch: 6| Step: 10
Training loss: 2.0321135812614455
Validation loss: 2.5046495505998125

Epoch: 6| Step: 11
Training loss: 2.644626272007315
Validation loss: 2.5099592956816794

Epoch: 6| Step: 12
Training loss: 2.77974994797273
Validation loss: 2.49110885949125

Epoch: 6| Step: 13
Training loss: 2.4024179834821413
Validation loss: 2.4683378567957823

Epoch: 150| Step: 0
Training loss: 2.8290948206038067
Validation loss: 2.482417983200864

Epoch: 6| Step: 1
Training loss: 2.6278530238666633
Validation loss: 2.501894025232763

Epoch: 6| Step: 2
Training loss: 2.815616830354581
Validation loss: 2.488987739225639

Epoch: 6| Step: 3
Training loss: 2.5760403614732454
Validation loss: 2.4889833730803126

Epoch: 6| Step: 4
Training loss: 2.665346703083473
Validation loss: 2.493616824310743

Epoch: 6| Step: 5
Training loss: 2.071909853266661
Validation loss: 2.4982439062035344

Epoch: 6| Step: 6
Training loss: 2.5644564719370773
Validation loss: 2.4522058235657824

Epoch: 6| Step: 7
Training loss: 3.201085180815854
Validation loss: 2.4704639990141506

Epoch: 6| Step: 8
Training loss: 2.393935560399693
Validation loss: 2.451402197047797

Epoch: 6| Step: 9
Training loss: 2.6040481743875725
Validation loss: 2.4814527380674325

Epoch: 6| Step: 10
Training loss: 2.200138529837627
Validation loss: 2.4659006361345126

Epoch: 6| Step: 11
Training loss: 2.5362142227379305
Validation loss: 2.465199848495301

Epoch: 6| Step: 12
Training loss: 2.3521790567476875
Validation loss: 2.473895498793631

Epoch: 6| Step: 13
Training loss: 2.099084577400309
Validation loss: 2.5115471079561758

Epoch: 151| Step: 0
Training loss: 2.485463413801872
Validation loss: 2.4551454532665287

Epoch: 6| Step: 1
Training loss: 2.9597661663174244
Validation loss: 2.488852130221662

Epoch: 6| Step: 2
Training loss: 2.389302006074768
Validation loss: 2.479738608119975

Epoch: 6| Step: 3
Training loss: 2.6016647731163993
Validation loss: 2.4779001970060612

Epoch: 6| Step: 4
Training loss: 2.3652386086486676
Validation loss: 2.452719253626091

Epoch: 6| Step: 5
Training loss: 2.6363958316439544
Validation loss: 2.4795379305530956

Epoch: 6| Step: 6
Training loss: 2.5729989619099154
Validation loss: 2.462824508808616

Epoch: 6| Step: 7
Training loss: 2.119404887936708
Validation loss: 2.4787518043952708

Epoch: 6| Step: 8
Training loss: 2.485199701432413
Validation loss: 2.4688052006016603

Epoch: 6| Step: 9
Training loss: 2.226961976739501
Validation loss: 2.5025354326232856

Epoch: 6| Step: 10
Training loss: 2.5013609043071314
Validation loss: 2.4802906114844006

Epoch: 6| Step: 11
Training loss: 2.6748565635372015
Validation loss: 2.482929842608879

Epoch: 6| Step: 12
Training loss: 2.798848143437438
Validation loss: 2.52501219075697

Epoch: 6| Step: 13
Training loss: 2.809308424045166
Validation loss: 2.4870275256396717

Epoch: 152| Step: 0
Training loss: 2.867969208885911
Validation loss: 2.5155465565963446

Epoch: 6| Step: 1
Training loss: 2.382419140975692
Validation loss: 2.48241420396219

Epoch: 6| Step: 2
Training loss: 2.3246146754424113
Validation loss: 2.463426856597461

Epoch: 6| Step: 3
Training loss: 2.258423824772987
Validation loss: 2.4876346472748105

Epoch: 6| Step: 4
Training loss: 2.452555013150428
Validation loss: 2.452058519403788

Epoch: 6| Step: 5
Training loss: 2.230040714593596
Validation loss: 2.4767840942235764

Epoch: 6| Step: 6
Training loss: 2.5448349347198738
Validation loss: 2.4878633629610296

Epoch: 6| Step: 7
Training loss: 2.8145984027119364
Validation loss: 2.465070808254113

Epoch: 6| Step: 8
Training loss: 2.077044901847813
Validation loss: 2.4298047434209775

Epoch: 6| Step: 9
Training loss: 2.5270086476065186
Validation loss: 2.4631767433664757

Epoch: 6| Step: 10
Training loss: 3.02740486329444
Validation loss: 2.498374637229849

Epoch: 6| Step: 11
Training loss: 2.7109647634053258
Validation loss: 2.4948222645522593

Epoch: 6| Step: 12
Training loss: 2.716477770956821
Validation loss: 2.4534015090804915

Epoch: 6| Step: 13
Training loss: 1.7924689633117878
Validation loss: 2.5005567669008917

Epoch: 153| Step: 0
Training loss: 2.422621285912946
Validation loss: 2.4757032874954836

Epoch: 6| Step: 1
Training loss: 1.9443790386946451
Validation loss: 2.473192169945715

Epoch: 6| Step: 2
Training loss: 2.7681579197889667
Validation loss: 2.490811230550752

Epoch: 6| Step: 3
Training loss: 2.530271458744643
Validation loss: 2.458270923273496

Epoch: 6| Step: 4
Training loss: 2.5694347610520274
Validation loss: 2.4673002053317052

Epoch: 6| Step: 5
Training loss: 2.4207635113292674
Validation loss: 2.482684510612101

Epoch: 6| Step: 6
Training loss: 2.7677914167766016
Validation loss: 2.4733346161702063

Epoch: 6| Step: 7
Training loss: 2.790505514117919
Validation loss: 2.467630595969528

Epoch: 6| Step: 8
Training loss: 2.24373273072464
Validation loss: 2.498891213347604

Epoch: 6| Step: 9
Training loss: 2.362310541215877
Validation loss: 2.485284588352575

Epoch: 6| Step: 10
Training loss: 2.822221273845937
Validation loss: 2.4605055448645823

Epoch: 6| Step: 11
Training loss: 3.027677337971504
Validation loss: 2.4759271350857297

Epoch: 6| Step: 12
Training loss: 2.3702602272581537
Validation loss: 2.504134057941921

Epoch: 6| Step: 13
Training loss: 1.7177703146068473
Validation loss: 2.4596363696622277

Epoch: 154| Step: 0
Training loss: 2.2455820578831056
Validation loss: 2.4702766156353846

Epoch: 6| Step: 1
Training loss: 2.9074227212753203
Validation loss: 2.4843169443089774

Epoch: 6| Step: 2
Training loss: 2.5206718287999847
Validation loss: 2.470926644313799

Epoch: 6| Step: 3
Training loss: 2.6996445492492636
Validation loss: 2.479678996475694

Epoch: 6| Step: 4
Training loss: 2.4528373015014098
Validation loss: 2.4735584692779202

Epoch: 6| Step: 5
Training loss: 2.168500735334888
Validation loss: 2.5011571523683203

Epoch: 6| Step: 6
Training loss: 1.8038223636992348
Validation loss: 2.486831221678896

Epoch: 6| Step: 7
Training loss: 2.935111515454617
Validation loss: 2.457228940361469

Epoch: 6| Step: 8
Training loss: 2.5657335674254393
Validation loss: 2.4508097664643085

Epoch: 6| Step: 9
Training loss: 3.0326748674737027
Validation loss: 2.5128405261093145

Epoch: 6| Step: 10
Training loss: 2.4471488127112244
Validation loss: 2.5057521940342777

Epoch: 6| Step: 11
Training loss: 2.5456180396149932
Validation loss: 2.50580400313938

Epoch: 6| Step: 12
Training loss: 2.0638021346773128
Validation loss: 2.501865761326155

Epoch: 6| Step: 13
Training loss: 2.4320554325851105
Validation loss: 2.4956780843298505

Epoch: 155| Step: 0
Training loss: 2.5098353513539013
Validation loss: 2.473094397548147

Epoch: 6| Step: 1
Training loss: 1.8701089644687034
Validation loss: 2.4742784739651493

Epoch: 6| Step: 2
Training loss: 1.6564038043314016
Validation loss: 2.4737711009928987

Epoch: 6| Step: 3
Training loss: 2.7570619939752983
Validation loss: 2.4479937619592875

Epoch: 6| Step: 4
Training loss: 2.8995441473112686
Validation loss: 2.4877670595722146

Epoch: 6| Step: 5
Training loss: 2.9024010879787943
Validation loss: 2.4895246219667198

Epoch: 6| Step: 6
Training loss: 2.1913159465713186
Validation loss: 2.4806395206024305

Epoch: 6| Step: 7
Training loss: 2.121009782846813
Validation loss: 2.4829580639424287

Epoch: 6| Step: 8
Training loss: 2.6081905760612445
Validation loss: 2.481196335728588

Epoch: 6| Step: 9
Training loss: 2.237218794387344
Validation loss: 2.5133768944669845

Epoch: 6| Step: 10
Training loss: 2.289142802525702
Validation loss: 2.5046662569701272

Epoch: 6| Step: 11
Training loss: 2.2883185001049053
Validation loss: 2.487170446782194

Epoch: 6| Step: 12
Training loss: 3.961728229635486
Validation loss: 2.4708088962544736

Epoch: 6| Step: 13
Training loss: 1.9823070774758917
Validation loss: 2.471103095597045

Epoch: 156| Step: 0
Training loss: 3.0123347383494252
Validation loss: 2.4540840021211126

Epoch: 6| Step: 1
Training loss: 2.340731902794354
Validation loss: 2.4443936485626088

Epoch: 6| Step: 2
Training loss: 2.0744702317829753
Validation loss: 2.4661107445045514

Epoch: 6| Step: 3
Training loss: 1.8575264854134519
Validation loss: 2.491558448048399

Epoch: 6| Step: 4
Training loss: 2.1510202870141613
Validation loss: 2.4534761579710596

Epoch: 6| Step: 5
Training loss: 2.903468616135331
Validation loss: 2.491731551370842

Epoch: 6| Step: 6
Training loss: 3.015671171319146
Validation loss: 2.4987702493267205

Epoch: 6| Step: 7
Training loss: 2.829998091572364
Validation loss: 2.478426485600041

Epoch: 6| Step: 8
Training loss: 2.4344415305452114
Validation loss: 2.5062779141856173

Epoch: 6| Step: 9
Training loss: 2.3224722832051414
Validation loss: 2.47174375487513

Epoch: 6| Step: 10
Training loss: 2.049341128465813
Validation loss: 2.442172347039826

Epoch: 6| Step: 11
Training loss: 2.271896836544494
Validation loss: 2.479565836895708

Epoch: 6| Step: 12
Training loss: 2.5725238412654985
Validation loss: 2.492031628860979

Epoch: 6| Step: 13
Training loss: 2.8471382831719674
Validation loss: 2.4583813579353313

Epoch: 157| Step: 0
Training loss: 2.2647342377760635
Validation loss: 2.500591672592564

Epoch: 6| Step: 1
Training loss: 2.618816904747413
Validation loss: 2.491015211238578

Epoch: 6| Step: 2
Training loss: 2.442422249531666
Validation loss: 2.4653941209689583

Epoch: 6| Step: 3
Training loss: 2.1409377266434526
Validation loss: 2.4298653074765038

Epoch: 6| Step: 4
Training loss: 2.188433856538918
Validation loss: 2.465404965543121

Epoch: 6| Step: 5
Training loss: 2.9719725134542445
Validation loss: 2.476770715930014

Epoch: 6| Step: 6
Training loss: 2.2870352559576794
Validation loss: 2.493295564216816

Epoch: 6| Step: 7
Training loss: 2.5454214429870374
Validation loss: 2.4958171389195427

Epoch: 6| Step: 8
Training loss: 2.5779097033683516
Validation loss: 2.487551300893423

Epoch: 6| Step: 9
Training loss: 2.18188322215961
Validation loss: 2.4738921039483404

Epoch: 6| Step: 10
Training loss: 2.538434135738155
Validation loss: 2.4488221835453836

Epoch: 6| Step: 11
Training loss: 2.691963924217245
Validation loss: 2.466128102297165

Epoch: 6| Step: 12
Training loss: 2.6506156853941905
Validation loss: 2.463223986285642

Epoch: 6| Step: 13
Training loss: 2.6876458416778215
Validation loss: 2.462421887978003

Epoch: 158| Step: 0
Training loss: 2.8905341056760876
Validation loss: 2.488620213065117

Epoch: 6| Step: 1
Training loss: 2.153695957349338
Validation loss: 2.496628454652994

Epoch: 6| Step: 2
Training loss: 2.0113802430613994
Validation loss: 2.5018202307934487

Epoch: 6| Step: 3
Training loss: 2.320140279935483
Validation loss: 2.478045098098542

Epoch: 6| Step: 4
Training loss: 2.8643973180312177
Validation loss: 2.471780935387117

Epoch: 6| Step: 5
Training loss: 2.2542751810275683
Validation loss: 2.4837953677256803

Epoch: 6| Step: 6
Training loss: 2.9537101044868397
Validation loss: 2.483074187952475

Epoch: 6| Step: 7
Training loss: 1.4955016077377978
Validation loss: 2.479462393370069

Epoch: 6| Step: 8
Training loss: 2.8344934743663788
Validation loss: 2.4816231449888537

Epoch: 6| Step: 9
Training loss: 2.1701483140528834
Validation loss: 2.447927392130133

Epoch: 6| Step: 10
Training loss: 2.6816920131752324
Validation loss: 2.4775438720266343

Epoch: 6| Step: 11
Training loss: 2.534844942184908
Validation loss: 2.4779583823424796

Epoch: 6| Step: 12
Training loss: 2.7862934289545147
Validation loss: 2.4799701060598225

Epoch: 6| Step: 13
Training loss: 2.4626640923525676
Validation loss: 2.482796601326959

Epoch: 159| Step: 0
Training loss: 2.333569809874166
Validation loss: 2.502410444442771

Epoch: 6| Step: 1
Training loss: 3.1510979933735435
Validation loss: 2.4739760628255487

Epoch: 6| Step: 2
Training loss: 2.5800443036319383
Validation loss: 2.4624056050362775

Epoch: 6| Step: 3
Training loss: 2.4369059107684548
Validation loss: 2.5260263690965234

Epoch: 6| Step: 4
Training loss: 2.3157165426880515
Validation loss: 2.4744416527811617

Epoch: 6| Step: 5
Training loss: 2.0548716415451156
Validation loss: 2.4750374682720477

Epoch: 6| Step: 6
Training loss: 2.409950878228358
Validation loss: 2.4578886455485933

Epoch: 6| Step: 7
Training loss: 3.0671917534913833
Validation loss: 2.4804018238493417

Epoch: 6| Step: 8
Training loss: 1.8746246597992793
Validation loss: 2.464710084344738

Epoch: 6| Step: 9
Training loss: 2.3289670509507134
Validation loss: 2.449291120039821

Epoch: 6| Step: 10
Training loss: 2.770112443425131
Validation loss: 2.5047524861490778

Epoch: 6| Step: 11
Training loss: 2.7318255937516422
Validation loss: 2.4767749224666256

Epoch: 6| Step: 12
Training loss: 2.4361366958850232
Validation loss: 2.5248390754436856

Epoch: 6| Step: 13
Training loss: 2.2428158401351705
Validation loss: 2.454442535914905

Epoch: 160| Step: 0
Training loss: 2.3415378557754085
Validation loss: 2.465828754610003

Epoch: 6| Step: 1
Training loss: 2.6229647057587813
Validation loss: 2.5181161068025113

Epoch: 6| Step: 2
Training loss: 2.5615517327116213
Validation loss: 2.463770674007877

Epoch: 6| Step: 3
Training loss: 2.168243115908887
Validation loss: 2.4746075247427703

Epoch: 6| Step: 4
Training loss: 2.362642766281956
Validation loss: 2.459428282327843

Epoch: 6| Step: 5
Training loss: 2.791896117920231
Validation loss: 2.4386541091749008

Epoch: 6| Step: 6
Training loss: 2.217565300806785
Validation loss: 2.4810228538426276

Epoch: 6| Step: 7
Training loss: 2.0582399009884034
Validation loss: 2.48671270402371

Epoch: 6| Step: 8
Training loss: 2.6664487829205488
Validation loss: 2.4433468534830873

Epoch: 6| Step: 9
Training loss: 3.0861853391379084
Validation loss: 2.495023945543836

Epoch: 6| Step: 10
Training loss: 1.9487107710104452
Validation loss: 2.458212483124212

Epoch: 6| Step: 11
Training loss: 2.905114885379478
Validation loss: 2.4626341216946748

Epoch: 6| Step: 12
Training loss: 2.6020244383019833
Validation loss: 2.5339686971502946

Epoch: 6| Step: 13
Training loss: 2.301471600158618
Validation loss: 2.460838285400437

Epoch: 161| Step: 0
Training loss: 2.790514399781331
Validation loss: 2.4910596116748898

Epoch: 6| Step: 1
Training loss: 2.4531485198041487
Validation loss: 2.4404451369692786

Epoch: 6| Step: 2
Training loss: 2.374301004444169
Validation loss: 2.5077072579956305

Epoch: 6| Step: 3
Training loss: 2.1054132627631668
Validation loss: 2.485491275275242

Epoch: 6| Step: 4
Training loss: 2.499637863633511
Validation loss: 2.464025452058743

Epoch: 6| Step: 5
Training loss: 2.2752684466258977
Validation loss: 2.485918504213348

Epoch: 6| Step: 6
Training loss: 2.8332769350908795
Validation loss: 2.4493449505493685

Epoch: 6| Step: 7
Training loss: 2.200624927714682
Validation loss: 2.451372538394342

Epoch: 6| Step: 8
Training loss: 2.1982254847904983
Validation loss: 2.505418763298264

Epoch: 6| Step: 9
Training loss: 1.9048740236174835
Validation loss: 2.4660680420994843

Epoch: 6| Step: 10
Training loss: 3.6672973668365976
Validation loss: 2.4396105427762067

Epoch: 6| Step: 11
Training loss: 2.0558129770884164
Validation loss: 2.458237285486194

Epoch: 6| Step: 12
Training loss: 2.322690214286651
Validation loss: 2.4788896873518076

Epoch: 6| Step: 13
Training loss: 2.816237869202706
Validation loss: 2.4745657122900258

Epoch: 162| Step: 0
Training loss: 2.043226178436337
Validation loss: 2.4964326715115774

Epoch: 6| Step: 1
Training loss: 2.1962841775109636
Validation loss: 2.4892344011230505

Epoch: 6| Step: 2
Training loss: 2.430526343276058
Validation loss: 2.4708852758922286

Epoch: 6| Step: 3
Training loss: 2.079584398013972
Validation loss: 2.440219753270446

Epoch: 6| Step: 4
Training loss: 3.6847217244598736
Validation loss: 2.461914080202442

Epoch: 6| Step: 5
Training loss: 2.476085917829417
Validation loss: 2.4688609840635665

Epoch: 6| Step: 6
Training loss: 2.5041334313986816
Validation loss: 2.500520795495044

Epoch: 6| Step: 7
Training loss: 2.583438830118655
Validation loss: 2.490040589396414

Epoch: 6| Step: 8
Training loss: 2.3663102844264987
Validation loss: 2.5226256215260436

Epoch: 6| Step: 9
Training loss: 2.918151114406804
Validation loss: 2.4969944371131056

Epoch: 6| Step: 10
Training loss: 2.362906938655145
Validation loss: 2.5040989630888597

Epoch: 6| Step: 11
Training loss: 2.461439196597914
Validation loss: 2.4769623410572286

Epoch: 6| Step: 12
Training loss: 1.963839993129716
Validation loss: 2.4711609098154597

Epoch: 6| Step: 13
Training loss: 2.765249625556106
Validation loss: 2.514282530253266

Epoch: 163| Step: 0
Training loss: 2.1139069651519944
Validation loss: 2.4869087060216755

Epoch: 6| Step: 1
Training loss: 2.804323560643811
Validation loss: 2.5067677916300926

Epoch: 6| Step: 2
Training loss: 2.4846943584045706
Validation loss: 2.452202224103983

Epoch: 6| Step: 3
Training loss: 3.16631005604832
Validation loss: 2.475122265588834

Epoch: 6| Step: 4
Training loss: 2.7796579154607572
Validation loss: 2.4205972688961563

Epoch: 6| Step: 5
Training loss: 2.487570189439425
Validation loss: 2.4865130022342123

Epoch: 6| Step: 6
Training loss: 3.0941175762638093
Validation loss: 2.4833746694474956

Epoch: 6| Step: 7
Training loss: 2.150894812742687
Validation loss: 2.502260751801841

Epoch: 6| Step: 8
Training loss: 2.1802240620528877
Validation loss: 2.474773424951344

Epoch: 6| Step: 9
Training loss: 2.365743568099654
Validation loss: 2.485202095689521

Epoch: 6| Step: 10
Training loss: 1.954113458371306
Validation loss: 2.449788981481544

Epoch: 6| Step: 11
Training loss: 2.4030971927298945
Validation loss: 2.50459525259132

Epoch: 6| Step: 12
Training loss: 2.2594659684098684
Validation loss: 2.464845019940299

Epoch: 6| Step: 13
Training loss: 2.1341492652208456
Validation loss: 2.454307958047415

Epoch: 164| Step: 0
Training loss: 2.155755912453251
Validation loss: 2.480021795031673

Epoch: 6| Step: 1
Training loss: 2.392906645972448
Validation loss: 2.4845414846613987

Epoch: 6| Step: 2
Training loss: 2.3422722799214815
Validation loss: 2.452821079309315

Epoch: 6| Step: 3
Training loss: 2.159304017861481
Validation loss: 2.4685612963760257

Epoch: 6| Step: 4
Training loss: 2.3156820519300796
Validation loss: 2.489732957578497

Epoch: 6| Step: 5
Training loss: 2.4132362112064127
Validation loss: 2.482802951573184

Epoch: 6| Step: 6
Training loss: 2.9944221777275826
Validation loss: 2.485586079510153

Epoch: 6| Step: 7
Training loss: 2.0051920968591506
Validation loss: 2.4908361061095112

Epoch: 6| Step: 8
Training loss: 2.5457077628060216
Validation loss: 2.4813072182081157

Epoch: 6| Step: 9
Training loss: 2.512278445519821
Validation loss: 2.4623642423403687

Epoch: 6| Step: 10
Training loss: 2.248340418497869
Validation loss: 2.5067518018566055

Epoch: 6| Step: 11
Training loss: 1.9961535898335383
Validation loss: 2.4751557495160847

Epoch: 6| Step: 12
Training loss: 2.28386872365583
Validation loss: 2.4933849950974842

Epoch: 6| Step: 13
Training loss: 4.196553932798752
Validation loss: 2.455730997045589

Epoch: 165| Step: 0
Training loss: 2.727998022246553
Validation loss: 2.4855565863698836

Epoch: 6| Step: 1
Training loss: 2.4611420077165835
Validation loss: 2.4589898088207125

Epoch: 6| Step: 2
Training loss: 2.9976088213157306
Validation loss: 2.4494468453351965

Epoch: 6| Step: 3
Training loss: 2.0252241693442707
Validation loss: 2.4430349867838617

Epoch: 6| Step: 4
Training loss: 2.4531327751668184
Validation loss: 2.477837707288593

Epoch: 6| Step: 5
Training loss: 2.1662905684522866
Validation loss: 2.493512765926622

Epoch: 6| Step: 6
Training loss: 2.834674312176925
Validation loss: 2.4726038414696307

Epoch: 6| Step: 7
Training loss: 2.4545628895445413
Validation loss: 2.4791254681453876

Epoch: 6| Step: 8
Training loss: 1.972927686693404
Validation loss: 2.457933954160508

Epoch: 6| Step: 9
Training loss: 2.1959678241964307
Validation loss: 2.4941450396776146

Epoch: 6| Step: 10
Training loss: 2.5063655874182023
Validation loss: 2.4720501289262873

Epoch: 6| Step: 11
Training loss: 2.3776597639409984
Validation loss: 2.4919573880512687

Epoch: 6| Step: 12
Training loss: 2.363233833783108
Validation loss: 2.474676772732718

Epoch: 6| Step: 13
Training loss: 2.647356200811177
Validation loss: 2.490733228434276

Epoch: 166| Step: 0
Training loss: 2.4082178763551148
Validation loss: 2.490504419627072

Epoch: 6| Step: 1
Training loss: 2.8918480837269906
Validation loss: 2.4870199069475727

Epoch: 6| Step: 2
Training loss: 2.1379772434290336
Validation loss: 2.466094513467533

Epoch: 6| Step: 3
Training loss: 1.9511757851562421
Validation loss: 2.482166555502926

Epoch: 6| Step: 4
Training loss: 2.7549394116948154
Validation loss: 2.4686803910481165

Epoch: 6| Step: 5
Training loss: 2.324727286475111
Validation loss: 2.450849094046956

Epoch: 6| Step: 6
Training loss: 2.132947421434997
Validation loss: 2.463840569421992

Epoch: 6| Step: 7
Training loss: 2.843676555649291
Validation loss: 2.467678873542016

Epoch: 6| Step: 8
Training loss: 2.023196879922762
Validation loss: 2.419757018791808

Epoch: 6| Step: 9
Training loss: 2.9234084730883745
Validation loss: 2.498277382441021

Epoch: 6| Step: 10
Training loss: 2.177400763579272
Validation loss: 2.4793635850523437

Epoch: 6| Step: 11
Training loss: 2.503070947870728
Validation loss: 2.477203896828914

Epoch: 6| Step: 12
Training loss: 2.2547368943691835
Validation loss: 2.3989262851240434

Epoch: 6| Step: 13
Training loss: 3.0733472274609634
Validation loss: 2.4718182003859583

Epoch: 167| Step: 0
Training loss: 2.1009102982804615
Validation loss: 2.456708919576811

Epoch: 6| Step: 1
Training loss: 2.134926443507938
Validation loss: 2.4620099776687354

Epoch: 6| Step: 2
Training loss: 2.64123798907429
Validation loss: 2.450677604342623

Epoch: 6| Step: 3
Training loss: 1.9794237739472758
Validation loss: 2.466377888168679

Epoch: 6| Step: 4
Training loss: 1.6626447628926821
Validation loss: 2.4705934341220623

Epoch: 6| Step: 5
Training loss: 2.232674545180023
Validation loss: 2.4357491834753433

Epoch: 6| Step: 6
Training loss: 2.7251340080697823
Validation loss: 2.444865587209982

Epoch: 6| Step: 7
Training loss: 2.7273266440177175
Validation loss: 2.44524711734562

Epoch: 6| Step: 8
Training loss: 2.6252211522994067
Validation loss: 2.4271931963814457

Epoch: 6| Step: 9
Training loss: 2.3841496952345733
Validation loss: 2.4965537816536156

Epoch: 6| Step: 10
Training loss: 2.3243352780662434
Validation loss: 2.4503575611352706

Epoch: 6| Step: 11
Training loss: 2.9719112229571514
Validation loss: 2.4582277175869023

Epoch: 6| Step: 12
Training loss: 3.296865164936456
Validation loss: 2.528855674501216

Epoch: 6| Step: 13
Training loss: 2.6519022645791694
Validation loss: 2.4946526652176284

Epoch: 168| Step: 0
Training loss: 2.0777613959910446
Validation loss: 2.4458628406083944

Epoch: 6| Step: 1
Training loss: 2.658897337281268
Validation loss: 2.473633913660833

Epoch: 6| Step: 2
Training loss: 2.803683810632658
Validation loss: 2.4807789861838367

Epoch: 6| Step: 3
Training loss: 2.5247201405655817
Validation loss: 2.5081321899212554

Epoch: 6| Step: 4
Training loss: 2.50164264119315
Validation loss: 2.493687053606322

Epoch: 6| Step: 5
Training loss: 2.590782950340759
Validation loss: 2.462336162911267

Epoch: 6| Step: 6
Training loss: 2.8341963706459743
Validation loss: 2.479706605033226

Epoch: 6| Step: 7
Training loss: 2.290242590735786
Validation loss: 2.4865026770790952

Epoch: 6| Step: 8
Training loss: 2.2655706991068203
Validation loss: 2.4801224206863437

Epoch: 6| Step: 9
Training loss: 1.9186360427863736
Validation loss: 2.4983968362844995

Epoch: 6| Step: 10
Training loss: 1.7796213836043704
Validation loss: 2.4429696281760487

Epoch: 6| Step: 11
Training loss: 2.934866841039605
Validation loss: 2.4808589774013052

Epoch: 6| Step: 12
Training loss: 2.676800298510191
Validation loss: 2.4666445772977332

Epoch: 6| Step: 13
Training loss: 1.8154168172116407
Validation loss: 2.440786411151149

Epoch: 169| Step: 0
Training loss: 2.366951002135192
Validation loss: 2.481657856257054

Epoch: 6| Step: 1
Training loss: 2.483570856431033
Validation loss: 2.5139185226247824

Epoch: 6| Step: 2
Training loss: 2.569442369843983
Validation loss: 2.448435227121948

Epoch: 6| Step: 3
Training loss: 2.604932189322405
Validation loss: 2.4743462360893864

Epoch: 6| Step: 4
Training loss: 2.428736755209328
Validation loss: 2.4309714413791292

Epoch: 6| Step: 5
Training loss: 2.668663638144738
Validation loss: 2.4644712766654773

Epoch: 6| Step: 6
Training loss: 2.838478988282095
Validation loss: 2.4638147002286366

Epoch: 6| Step: 7
Training loss: 2.5673969278567847
Validation loss: 2.4771475861158296

Epoch: 6| Step: 8
Training loss: 2.0420474132073587
Validation loss: 2.4741670474928377

Epoch: 6| Step: 9
Training loss: 2.0949231177814815
Validation loss: 2.455894657681055

Epoch: 6| Step: 10
Training loss: 2.3651153257289175
Validation loss: 2.454158848575732

Epoch: 6| Step: 11
Training loss: 2.6137409347603193
Validation loss: 2.4397978699032183

Epoch: 6| Step: 12
Training loss: 2.2869384076256707
Validation loss: 2.4446249259287027

Epoch: 6| Step: 13
Training loss: 2.8885614401113817
Validation loss: 2.4708691587038256

Epoch: 170| Step: 0
Training loss: 2.3038612048278515
Validation loss: 2.4244444925595534

Epoch: 6| Step: 1
Training loss: 2.888041893779349
Validation loss: 2.4459197892903726

Epoch: 6| Step: 2
Training loss: 2.237191725651107
Validation loss: 2.4764393034737333

Epoch: 6| Step: 3
Training loss: 2.2966428885961476
Validation loss: 2.4417279210971805

Epoch: 6| Step: 4
Training loss: 2.7591710189129066
Validation loss: 2.4220665767608947

Epoch: 6| Step: 5
Training loss: 2.6748986340862935
Validation loss: 2.464105939801156

Epoch: 6| Step: 6
Training loss: 2.408181938331884
Validation loss: 2.4650018150968385

Epoch: 6| Step: 7
Training loss: 2.9588909071458893
Validation loss: 2.4530835801005852

Epoch: 6| Step: 8
Training loss: 2.989431521363694
Validation loss: 2.469378964341035

Epoch: 6| Step: 9
Training loss: 2.322176200871038
Validation loss: 2.490922930350679

Epoch: 6| Step: 10
Training loss: 2.2270648590358877
Validation loss: 2.4606335940779243

Epoch: 6| Step: 11
Training loss: 2.2239782494778115
Validation loss: 2.461713562725863

Epoch: 6| Step: 12
Training loss: 1.6271937308019089
Validation loss: 2.441110224408651

Epoch: 6| Step: 13
Training loss: 1.5421533675508614
Validation loss: 2.500358734234307

Epoch: 171| Step: 0
Training loss: 2.17649437879226
Validation loss: 2.4562169561433773

Epoch: 6| Step: 1
Training loss: 2.538171699956623
Validation loss: 2.4415983469873144

Epoch: 6| Step: 2
Training loss: 2.316364976280427
Validation loss: 2.468432296844386

Epoch: 6| Step: 3
Training loss: 2.53256643466103
Validation loss: 2.4532145958078697

Epoch: 6| Step: 4
Training loss: 2.709038412796924
Validation loss: 2.468062451885614

Epoch: 6| Step: 5
Training loss: 2.446165478415254
Validation loss: 2.4741449615774607

Epoch: 6| Step: 6
Training loss: 2.610003184466411
Validation loss: 2.4368116070892922

Epoch: 6| Step: 7
Training loss: 3.024280519280868
Validation loss: 2.48556300279504

Epoch: 6| Step: 8
Training loss: 1.8945077167111193
Validation loss: 2.464342584223194

Epoch: 6| Step: 9
Training loss: 2.4044919217632965
Validation loss: 2.4546342435194703

Epoch: 6| Step: 10
Training loss: 2.4288587720763806
Validation loss: 2.4510798888511394

Epoch: 6| Step: 11
Training loss: 2.368974269426091
Validation loss: 2.4666106701885746

Epoch: 6| Step: 12
Training loss: 2.7449782209800473
Validation loss: 2.4707086803888254

Epoch: 6| Step: 13
Training loss: 1.6590489902402556
Validation loss: 2.4770682517772356

Epoch: 172| Step: 0
Training loss: 2.4359916519498053
Validation loss: 2.464919873496412

Epoch: 6| Step: 1
Training loss: 2.3428895515267203
Validation loss: 2.5053121262876425

Epoch: 6| Step: 2
Training loss: 2.87935838810886
Validation loss: 2.5184705076735905

Epoch: 6| Step: 3
Training loss: 2.0860209359044646
Validation loss: 2.445553262392833

Epoch: 6| Step: 4
Training loss: 2.2377647882560385
Validation loss: 2.468722073163518

Epoch: 6| Step: 5
Training loss: 2.66347571032609
Validation loss: 2.51808351178055

Epoch: 6| Step: 6
Training loss: 2.1467882519205252
Validation loss: 2.474020684087466

Epoch: 6| Step: 7
Training loss: 2.0680508910360595
Validation loss: 2.431800479826055

Epoch: 6| Step: 8
Training loss: 2.0999080002023813
Validation loss: 2.4533016856281447

Epoch: 6| Step: 9
Training loss: 2.349572642000375
Validation loss: 2.47651154471627

Epoch: 6| Step: 10
Training loss: 2.7897885870734336
Validation loss: 2.4370030205971513

Epoch: 6| Step: 11
Training loss: 2.5037532289496562
Validation loss: 2.4931975262267505

Epoch: 6| Step: 12
Training loss: 2.5500745276237606
Validation loss: 2.4550191874955476

Epoch: 6| Step: 13
Training loss: 3.187046991208307
Validation loss: 2.455051140651565

Epoch: 173| Step: 0
Training loss: 2.438941333798727
Validation loss: 2.4347891488008435

Epoch: 6| Step: 1
Training loss: 2.6802394287424662
Validation loss: 2.4668422356362885

Epoch: 6| Step: 2
Training loss: 2.6636482878822583
Validation loss: 2.4282697858198095

Epoch: 6| Step: 3
Training loss: 2.6429799430625938
Validation loss: 2.4761448518973306

Epoch: 6| Step: 4
Training loss: 1.7905423236820537
Validation loss: 2.4405170864866106

Epoch: 6| Step: 5
Training loss: 2.131700722027423
Validation loss: 2.4671823496610448

Epoch: 6| Step: 6
Training loss: 2.669874368062166
Validation loss: 2.4714785630280285

Epoch: 6| Step: 7
Training loss: 2.317117874426771
Validation loss: 2.4273474571281333

Epoch: 6| Step: 8
Training loss: 2.523114918973796
Validation loss: 2.4470781592443007

Epoch: 6| Step: 9
Training loss: 2.4051033359462104
Validation loss: 2.4359251582271315

Epoch: 6| Step: 10
Training loss: 2.321603332480859
Validation loss: 2.421934783229438

Epoch: 6| Step: 11
Training loss: 2.581099210680592
Validation loss: 2.4619436274831923

Epoch: 6| Step: 12
Training loss: 2.689900944811074
Validation loss: 2.4606185057861927

Epoch: 6| Step: 13
Training loss: 2.346028250619301
Validation loss: 2.4390406634150286

Epoch: 174| Step: 0
Training loss: 2.114547942167626
Validation loss: 2.453349397709476

Epoch: 6| Step: 1
Training loss: 2.6311647596166483
Validation loss: 2.4808718882692933

Epoch: 6| Step: 2
Training loss: 2.736865495280653
Validation loss: 2.4850241149150207

Epoch: 6| Step: 3
Training loss: 2.735266665442165
Validation loss: 2.470009466538978

Epoch: 6| Step: 4
Training loss: 1.8424244657895457
Validation loss: 2.4447327440634066

Epoch: 6| Step: 5
Training loss: 2.5097211663134216
Validation loss: 2.4731875603077462

Epoch: 6| Step: 6
Training loss: 2.476057705140531
Validation loss: 2.4471548982299542

Epoch: 6| Step: 7
Training loss: 2.40047693679368
Validation loss: 2.4689884737807377

Epoch: 6| Step: 8
Training loss: 2.545524192142114
Validation loss: 2.4570723633763345

Epoch: 6| Step: 9
Training loss: 2.032992510555224
Validation loss: 2.4675995116528333

Epoch: 6| Step: 10
Training loss: 2.0098612385389076
Validation loss: 2.496761831584345

Epoch: 6| Step: 11
Training loss: 2.70848214156369
Validation loss: 2.4331326669822686

Epoch: 6| Step: 12
Training loss: 2.3617753708866673
Validation loss: 2.4495774213353125

Epoch: 6| Step: 13
Training loss: 2.5890091001336692
Validation loss: 2.4611003149304387

Epoch: 175| Step: 0
Training loss: 2.5514299347751352
Validation loss: 2.453501145615536

Epoch: 6| Step: 1
Training loss: 2.816555659422212
Validation loss: 2.423786578874611

Epoch: 6| Step: 2
Training loss: 2.2122680111398783
Validation loss: 2.5029359272594958

Epoch: 6| Step: 3
Training loss: 2.335653842812244
Validation loss: 2.486186843434762

Epoch: 6| Step: 4
Training loss: 2.374078170164272
Validation loss: 2.4556831224444893

Epoch: 6| Step: 5
Training loss: 2.400992756398502
Validation loss: 2.4481681539201765

Epoch: 6| Step: 6
Training loss: 2.32229457673553
Validation loss: 2.445056222366163

Epoch: 6| Step: 7
Training loss: 2.4400123950768493
Validation loss: 2.4883238045574334

Epoch: 6| Step: 8
Training loss: 2.601847406772946
Validation loss: 2.4320311364085643

Epoch: 6| Step: 9
Training loss: 2.29767703630941
Validation loss: 2.4779993057624763

Epoch: 6| Step: 10
Training loss: 2.6306094225755117
Validation loss: 2.4690429515762946

Epoch: 6| Step: 11
Training loss: 2.586510816562172
Validation loss: 2.459215999199674

Epoch: 6| Step: 12
Training loss: 2.170583876361116
Validation loss: 2.4882497117240012

Epoch: 6| Step: 13
Training loss: 1.8781889817293353
Validation loss: 2.5170953604161292

Epoch: 176| Step: 0
Training loss: 2.405884256681745
Validation loss: 2.4841678961560065

Epoch: 6| Step: 1
Training loss: 2.319949137689196
Validation loss: 2.4844764404472883

Epoch: 6| Step: 2
Training loss: 2.1827346121586744
Validation loss: 2.4788765127821577

Epoch: 6| Step: 3
Training loss: 2.184734449159047
Validation loss: 2.461168433111757

Epoch: 6| Step: 4
Training loss: 2.9372113674479454
Validation loss: 2.4621614656457202

Epoch: 6| Step: 5
Training loss: 1.9977574889331846
Validation loss: 2.458100178714236

Epoch: 6| Step: 6
Training loss: 2.918531167038247
Validation loss: 2.4916232821774633

Epoch: 6| Step: 7
Training loss: 2.2571583364483625
Validation loss: 2.4622042509005357

Epoch: 6| Step: 8
Training loss: 2.3130350267237794
Validation loss: 2.4329946459939604

Epoch: 6| Step: 9
Training loss: 2.1617494195624327
Validation loss: 2.4479527003233192

Epoch: 6| Step: 10
Training loss: 2.7044944160955287
Validation loss: 2.4929739223407066

Epoch: 6| Step: 11
Training loss: 2.441675180500624
Validation loss: 2.5000018417187544

Epoch: 6| Step: 12
Training loss: 2.9799461856565763
Validation loss: 2.468528351310133

Epoch: 6| Step: 13
Training loss: 1.6220919925129655
Validation loss: 2.4729842674542764

Epoch: 177| Step: 0
Training loss: 2.5725762969659303
Validation loss: 2.499542837489684

Epoch: 6| Step: 1
Training loss: 2.5738949376667426
Validation loss: 2.49489391801655

Epoch: 6| Step: 2
Training loss: 2.450763513356782
Validation loss: 2.438547991886404

Epoch: 6| Step: 3
Training loss: 2.7367578205844727
Validation loss: 2.409467368306977

Epoch: 6| Step: 4
Training loss: 2.435561558634065
Validation loss: 2.4547443655603285

Epoch: 6| Step: 5
Training loss: 2.85369809799016
Validation loss: 2.412079935739893

Epoch: 6| Step: 6
Training loss: 1.9639161121376636
Validation loss: 2.4852060290332214

Epoch: 6| Step: 7
Training loss: 2.2953712575311
Validation loss: 2.4418062046386253

Epoch: 6| Step: 8
Training loss: 2.2896790178718964
Validation loss: 2.4514919057541706

Epoch: 6| Step: 9
Training loss: 2.259570008616757
Validation loss: 2.441042911261371

Epoch: 6| Step: 10
Training loss: 2.4124312830808585
Validation loss: 2.483267141046229

Epoch: 6| Step: 11
Training loss: 2.4720869086830324
Validation loss: 2.442401542335414

Epoch: 6| Step: 12
Training loss: 2.1715571767862807
Validation loss: 2.470051280352845

Epoch: 6| Step: 13
Training loss: 2.0436604424782487
Validation loss: 2.5024261822781404

Epoch: 178| Step: 0
Training loss: 1.9139673948988687
Validation loss: 2.4529996967573253

Epoch: 6| Step: 1
Training loss: 2.527379974624475
Validation loss: 2.483966428759882

Epoch: 6| Step: 2
Training loss: 2.9543722435389816
Validation loss: 2.4761916848551824

Epoch: 6| Step: 3
Training loss: 2.428535212719582
Validation loss: 2.4810200484318474

Epoch: 6| Step: 4
Training loss: 2.8458793967797766
Validation loss: 2.5114061712286255

Epoch: 6| Step: 5
Training loss: 2.812981458356701
Validation loss: 2.4534981070713733

Epoch: 6| Step: 6
Training loss: 2.4984097191158927
Validation loss: 2.443915127643824

Epoch: 6| Step: 7
Training loss: 1.9751927148980497
Validation loss: 2.478457049341538

Epoch: 6| Step: 8
Training loss: 2.501223932118005
Validation loss: 2.461630894614619

Epoch: 6| Step: 9
Training loss: 3.0969112698214283
Validation loss: 2.4774917086522357

Epoch: 6| Step: 10
Training loss: 1.6344003941621832
Validation loss: 2.478863385715691

Epoch: 6| Step: 11
Training loss: 2.745085920646375
Validation loss: 2.478864453009912

Epoch: 6| Step: 12
Training loss: 1.6965820200076986
Validation loss: 2.4710328531534267

Epoch: 6| Step: 13
Training loss: 1.5670331428250905
Validation loss: 2.4443669039031706

Epoch: 179| Step: 0
Training loss: 2.4001564054387887
Validation loss: 2.461885877968427

Epoch: 6| Step: 1
Training loss: 2.3779422203532663
Validation loss: 2.4675695365257835

Epoch: 6| Step: 2
Training loss: 2.027103358369448
Validation loss: 2.5059524767057053

Epoch: 6| Step: 3
Training loss: 2.3539315390407434
Validation loss: 2.4477412213089482

Epoch: 6| Step: 4
Training loss: 2.081879629944801
Validation loss: 2.440833876327519

Epoch: 6| Step: 5
Training loss: 2.137502355741575
Validation loss: 2.4871245060150264

Epoch: 6| Step: 6
Training loss: 3.1561883599333718
Validation loss: 2.454810573012434

Epoch: 6| Step: 7
Training loss: 1.887890374949064
Validation loss: 2.4966423385325065

Epoch: 6| Step: 8
Training loss: 2.4642907926455786
Validation loss: 2.479577603764088

Epoch: 6| Step: 9
Training loss: 2.3569428495292937
Validation loss: 2.48064926352333

Epoch: 6| Step: 10
Training loss: 3.064084791290106
Validation loss: 2.463295687798932

Epoch: 6| Step: 11
Training loss: 2.332470620840168
Validation loss: 2.4323314036282975

Epoch: 6| Step: 12
Training loss: 2.657389407651371
Validation loss: 2.4109387607565984

Epoch: 6| Step: 13
Training loss: 1.9601920485315885
Validation loss: 2.4411397646271067

Epoch: 180| Step: 0
Training loss: 1.9918166469887628
Validation loss: 2.4891064359105

Epoch: 6| Step: 1
Training loss: 2.34051840199467
Validation loss: 2.4730620405130233

Epoch: 6| Step: 2
Training loss: 2.4095286042050676
Validation loss: 2.4577603156369996

Epoch: 6| Step: 3
Training loss: 1.862752587516932
Validation loss: 2.462771064535513

Epoch: 6| Step: 4
Training loss: 2.260420827085355
Validation loss: 2.479070040263276

Epoch: 6| Step: 5
Training loss: 2.3654875741848755
Validation loss: 2.5016687842934653

Epoch: 6| Step: 6
Training loss: 2.465971723383572
Validation loss: 2.4352367022801045

Epoch: 6| Step: 7
Training loss: 2.9806844050830135
Validation loss: 2.4685939730686526

Epoch: 6| Step: 8
Training loss: 2.2592084852302428
Validation loss: 2.439255876319587

Epoch: 6| Step: 9
Training loss: 2.0943903157429213
Validation loss: 2.449776431085926

Epoch: 6| Step: 10
Training loss: 2.8932390919585793
Validation loss: 2.420373477232672

Epoch: 6| Step: 11
Training loss: 2.49684735833099
Validation loss: 2.4660530754215175

Epoch: 6| Step: 12
Training loss: 2.2978293583579776
Validation loss: 2.4562546910638785

Epoch: 6| Step: 13
Training loss: 3.194105895157896
Validation loss: 2.4746859149718445

Epoch: 181| Step: 0
Training loss: 2.4368459361970864
Validation loss: 2.400226993918176

Epoch: 6| Step: 1
Training loss: 2.243780015834986
Validation loss: 2.431135963679838

Epoch: 6| Step: 2
Training loss: 2.4861902287098867
Validation loss: 2.4841379444805054

Epoch: 6| Step: 3
Training loss: 2.188406620159117
Validation loss: 2.4879052723969086

Epoch: 6| Step: 4
Training loss: 2.7334005308807634
Validation loss: 2.4963981461686156

Epoch: 6| Step: 5
Training loss: 2.182733410636017
Validation loss: 2.4238472076328796

Epoch: 6| Step: 6
Training loss: 2.425466225235784
Validation loss: 2.496732694301852

Epoch: 6| Step: 7
Training loss: 2.118803751665956
Validation loss: 2.442490352800869

Epoch: 6| Step: 8
Training loss: 2.9593279245694823
Validation loss: 2.4588464320009367

Epoch: 6| Step: 9
Training loss: 2.5303753884203113
Validation loss: 2.477506956497548

Epoch: 6| Step: 10
Training loss: 1.8095256472580643
Validation loss: 2.4831137432343975

Epoch: 6| Step: 11
Training loss: 2.493037159697498
Validation loss: 2.4409924107418837

Epoch: 6| Step: 12
Training loss: 2.439947024849069
Validation loss: 2.449489843256959

Epoch: 6| Step: 13
Training loss: 1.7210167242918817
Validation loss: 2.5166555067305394

Epoch: 182| Step: 0
Training loss: 1.8386454638465874
Validation loss: 2.470500002317079

Epoch: 6| Step: 1
Training loss: 2.81702152890993
Validation loss: 2.480146730019895

Epoch: 6| Step: 2
Training loss: 2.466521404044345
Validation loss: 2.4185507192594535

Epoch: 6| Step: 3
Training loss: 2.820088385556356
Validation loss: 2.5017092901364744

Epoch: 6| Step: 4
Training loss: 2.452279497941242
Validation loss: 2.467195975296308

Epoch: 6| Step: 5
Training loss: 2.073786746223207
Validation loss: 2.4676083829822093

Epoch: 6| Step: 6
Training loss: 2.4625665026364723
Validation loss: 2.4863510533550244

Epoch: 6| Step: 7
Training loss: 2.3432812031156227
Validation loss: 2.501720646452395

Epoch: 6| Step: 8
Training loss: 2.9441493644245535
Validation loss: 2.456581303417746

Epoch: 6| Step: 9
Training loss: 2.3453341407463646
Validation loss: 2.4593922571460043

Epoch: 6| Step: 10
Training loss: 2.3055552772409458
Validation loss: 2.5198954036775794

Epoch: 6| Step: 11
Training loss: 2.8361004238776255
Validation loss: 2.4641484275586008

Epoch: 6| Step: 12
Training loss: 1.9340406113416981
Validation loss: 2.443145664177132

Epoch: 6| Step: 13
Training loss: 1.4644910871052836
Validation loss: 2.4657018069691734

Epoch: 183| Step: 0
Training loss: 2.468477934320123
Validation loss: 2.488440861895752

Epoch: 6| Step: 1
Training loss: 2.145835382651921
Validation loss: 2.4434070026589443

Epoch: 6| Step: 2
Training loss: 2.6854476189044156
Validation loss: 2.4585303896233155

Epoch: 6| Step: 3
Training loss: 2.991584896432979
Validation loss: 2.4306750757351416

Epoch: 6| Step: 4
Training loss: 2.225205606968968
Validation loss: 2.4862205794598053

Epoch: 6| Step: 5
Training loss: 2.8953689824959796
Validation loss: 2.4300635494293377

Epoch: 6| Step: 6
Training loss: 2.515451460829314
Validation loss: 2.494896199187532

Epoch: 6| Step: 7
Training loss: 2.1121887654925633
Validation loss: 2.4597367364760268

Epoch: 6| Step: 8
Training loss: 2.6343549517211446
Validation loss: 2.4665533895625935

Epoch: 6| Step: 9
Training loss: 2.093470312767643
Validation loss: 2.436138300700832

Epoch: 6| Step: 10
Training loss: 2.238103356873262
Validation loss: 2.487922822813229

Epoch: 6| Step: 11
Training loss: 2.1424341283796338
Validation loss: 2.55718131232747

Epoch: 6| Step: 12
Training loss: 2.12911913446073
Validation loss: 2.463558440905894

Epoch: 6| Step: 13
Training loss: 2.650786132088462
Validation loss: 2.4807849571703082

Epoch: 184| Step: 0
Training loss: 1.6197092049594493
Validation loss: 2.476822519800078

Epoch: 6| Step: 1
Training loss: 2.467663296414285
Validation loss: 2.4385038495863003

Epoch: 6| Step: 2
Training loss: 2.0190204734425494
Validation loss: 2.4378152153883508

Epoch: 6| Step: 3
Training loss: 2.4964549679338073
Validation loss: 2.483750804401817

Epoch: 6| Step: 4
Training loss: 3.1313273650641684
Validation loss: 2.483745572351949

Epoch: 6| Step: 5
Training loss: 2.6353231622043034
Validation loss: 2.4633069568631547

Epoch: 6| Step: 6
Training loss: 2.3077901354863797
Validation loss: 2.475448412156781

Epoch: 6| Step: 7
Training loss: 2.0448674264853053
Validation loss: 2.4777611291375927

Epoch: 6| Step: 8
Training loss: 2.51544643739813
Validation loss: 2.458576354801103

Epoch: 6| Step: 9
Training loss: 1.9145825983432803
Validation loss: 2.468159392721169

Epoch: 6| Step: 10
Training loss: 2.5822895053630326
Validation loss: 2.4816720666525462

Epoch: 6| Step: 11
Training loss: 2.2679185504988437
Validation loss: 2.5044434631052432

Epoch: 6| Step: 12
Training loss: 2.951434585117802
Validation loss: 2.5136179462906147

Epoch: 6| Step: 13
Training loss: 2.5932923797995597
Validation loss: 2.4894577080827203

Epoch: 185| Step: 0
Training loss: 3.080190517428626
Validation loss: 2.462090851481611

Epoch: 6| Step: 1
Training loss: 2.0514662406983093
Validation loss: 2.494502305607661

Epoch: 6| Step: 2
Training loss: 2.132889183817757
Validation loss: 2.438316049798076

Epoch: 6| Step: 3
Training loss: 1.830295024708291
Validation loss: 2.4567659152845644

Epoch: 6| Step: 4
Training loss: 2.771742611791013
Validation loss: 2.504864954129666

Epoch: 6| Step: 5
Training loss: 2.207634389378814
Validation loss: 2.505583612833516

Epoch: 6| Step: 6
Training loss: 2.16911667683999
Validation loss: 2.4444919207823452

Epoch: 6| Step: 7
Training loss: 2.718144316456624
Validation loss: 2.444911912049774

Epoch: 6| Step: 8
Training loss: 2.424265414006145
Validation loss: 2.4433516626387224

Epoch: 6| Step: 9
Training loss: 2.5401125570574137
Validation loss: 2.410147710743061

Epoch: 6| Step: 10
Training loss: 2.033731441401403
Validation loss: 2.497447471483003

Epoch: 6| Step: 11
Training loss: 2.6523315249626216
Validation loss: 2.4639398431299075

Epoch: 6| Step: 12
Training loss: 2.304128805427759
Validation loss: 2.4511306699747326

Epoch: 6| Step: 13
Training loss: 2.52438856218987
Validation loss: 2.454005187796327

Epoch: 186| Step: 0
Training loss: 2.1336762073273543
Validation loss: 2.453445581876207

Epoch: 6| Step: 1
Training loss: 1.999664814995181
Validation loss: 2.4678627788583456

Epoch: 6| Step: 2
Training loss: 2.2779258651459293
Validation loss: 2.4511527582637407

Epoch: 6| Step: 3
Training loss: 2.477244575028731
Validation loss: 2.446086929835861

Epoch: 6| Step: 4
Training loss: 3.5348433045186036
Validation loss: 2.4806123032620606

Epoch: 6| Step: 5
Training loss: 2.4143406976193122
Validation loss: 2.4776721426304102

Epoch: 6| Step: 6
Training loss: 2.588598720195542
Validation loss: 2.5015867694047604

Epoch: 6| Step: 7
Training loss: 2.48126121537679
Validation loss: 2.424809267531044

Epoch: 6| Step: 8
Training loss: 2.468393517360851
Validation loss: 2.4467441698045067

Epoch: 6| Step: 9
Training loss: 2.418941369975592
Validation loss: 2.5074687000514335

Epoch: 6| Step: 10
Training loss: 1.672641257691488
Validation loss: 2.447729871155697

Epoch: 6| Step: 11
Training loss: 2.445700520208044
Validation loss: 2.54276437084435

Epoch: 6| Step: 12
Training loss: 1.9723487538804068
Validation loss: 2.49684359015181

Epoch: 6| Step: 13
Training loss: 2.003929212412603
Validation loss: 2.4551168798594105

Epoch: 187| Step: 0
Training loss: 2.967149805168016
Validation loss: 2.488669059504686

Epoch: 6| Step: 1
Training loss: 2.841732105683721
Validation loss: 2.4892581503011177

Epoch: 6| Step: 2
Training loss: 2.0797949943017833
Validation loss: 2.4970449513181077

Epoch: 6| Step: 3
Training loss: 2.517960879615085
Validation loss: 2.4661942037279374

Epoch: 6| Step: 4
Training loss: 2.329805727542187
Validation loss: 2.433467188749774

Epoch: 6| Step: 5
Training loss: 2.256663944387367
Validation loss: 2.4624279461626624

Epoch: 6| Step: 6
Training loss: 2.1170530382088577
Validation loss: 2.451352511279759

Epoch: 6| Step: 7
Training loss: 2.9433219517465807
Validation loss: 2.4211409245888924

Epoch: 6| Step: 8
Training loss: 2.681536245294227
Validation loss: 2.5108554939745558

Epoch: 6| Step: 9
Training loss: 2.4165699599636934
Validation loss: 2.420481761321931

Epoch: 6| Step: 10
Training loss: 1.9310927737533186
Validation loss: 2.4733336351115467

Epoch: 6| Step: 11
Training loss: 2.26147343650869
Validation loss: 2.4556817297983673

Epoch: 6| Step: 12
Training loss: 1.6441361412518305
Validation loss: 2.4582211781886714

Epoch: 6| Step: 13
Training loss: 2.125202281524335
Validation loss: 2.491902501760495

Epoch: 188| Step: 0
Training loss: 2.515509466515511
Validation loss: 2.4786805954937603

Epoch: 6| Step: 1
Training loss: 2.438357275816817
Validation loss: 2.4374353144129324

Epoch: 6| Step: 2
Training loss: 1.8317855312295364
Validation loss: 2.478898075645211

Epoch: 6| Step: 3
Training loss: 3.0290294261068498
Validation loss: 2.432501306388339

Epoch: 6| Step: 4
Training loss: 2.203271955634583
Validation loss: 2.428507802012063

Epoch: 6| Step: 5
Training loss: 2.456259892955785
Validation loss: 2.45083341308977

Epoch: 6| Step: 6
Training loss: 2.0415900339289923
Validation loss: 2.473942654122287

Epoch: 6| Step: 7
Training loss: 2.3729240982256345
Validation loss: 2.4394862888015942

Epoch: 6| Step: 8
Training loss: 1.9284486693715757
Validation loss: 2.441377385582058

Epoch: 6| Step: 9
Training loss: 2.7716285501391216
Validation loss: 2.4223789120880737

Epoch: 6| Step: 10
Training loss: 2.658906035083933
Validation loss: 2.4036665185301307

Epoch: 6| Step: 11
Training loss: 2.176054302183152
Validation loss: 2.4224142204036956

Epoch: 6| Step: 12
Training loss: 2.333299863666087
Validation loss: 2.487600041046991

Epoch: 6| Step: 13
Training loss: 2.737644181308475
Validation loss: 2.4314047037281448

Epoch: 189| Step: 0
Training loss: 2.0610901609020376
Validation loss: 2.460330170569956

Epoch: 6| Step: 1
Training loss: 2.6437937667506555
Validation loss: 2.4452411864388583

Epoch: 6| Step: 2
Training loss: 2.118647561086587
Validation loss: 2.463030817680818

Epoch: 6| Step: 3
Training loss: 2.3241063194970604
Validation loss: 2.441226314353767

Epoch: 6| Step: 4
Training loss: 2.457541796308463
Validation loss: 2.4275403329044107

Epoch: 6| Step: 5
Training loss: 2.304580117003103
Validation loss: 2.4647285581810627

Epoch: 6| Step: 6
Training loss: 1.6226441105116216
Validation loss: 2.4603314511759327

Epoch: 6| Step: 7
Training loss: 2.1471407219192975
Validation loss: 2.473680636111079

Epoch: 6| Step: 8
Training loss: 3.292086626778726
Validation loss: 2.44267510919934

Epoch: 6| Step: 9
Training loss: 2.877139415005624
Validation loss: 2.434404084092983

Epoch: 6| Step: 10
Training loss: 2.038035400816902
Validation loss: 2.431954600126567

Epoch: 6| Step: 11
Training loss: 2.5211407392559884
Validation loss: 2.4421733106989394

Epoch: 6| Step: 12
Training loss: 2.2088015317923304
Validation loss: 2.4732893580210233

Epoch: 6| Step: 13
Training loss: 2.0032088049439163
Validation loss: 2.4336806707944607

Epoch: 190| Step: 0
Training loss: 2.2273090382590377
Validation loss: 2.4885200762830832

Epoch: 6| Step: 1
Training loss: 2.2004096430087507
Validation loss: 2.435449290266064

Epoch: 6| Step: 2
Training loss: 2.0453079864708603
Validation loss: 2.443985843704822

Epoch: 6| Step: 3
Training loss: 2.493754501147498
Validation loss: 2.450257712022287

Epoch: 6| Step: 4
Training loss: 2.091805423323745
Validation loss: 2.418184179120562

Epoch: 6| Step: 5
Training loss: 2.2625121732774205
Validation loss: 2.4579844810390896

Epoch: 6| Step: 6
Training loss: 3.3893053149854286
Validation loss: 2.404299182417079

Epoch: 6| Step: 7
Training loss: 2.622110865899153
Validation loss: 2.465477834769882

Epoch: 6| Step: 8
Training loss: 2.314169822125681
Validation loss: 2.466993565614099

Epoch: 6| Step: 9
Training loss: 1.7779944266327397
Validation loss: 2.458156716655783

Epoch: 6| Step: 10
Training loss: 2.17273788326222
Validation loss: 2.4316378179663203

Epoch: 6| Step: 11
Training loss: 2.1942393439117716
Validation loss: 2.47001235918468

Epoch: 6| Step: 12
Training loss: 2.51007035479788
Validation loss: 2.4237514534392677

Epoch: 6| Step: 13
Training loss: 2.656298737920286
Validation loss: 2.4439775270202495

Epoch: 191| Step: 0
Training loss: 2.7191284617823417
Validation loss: 2.4485940619537323

Epoch: 6| Step: 1
Training loss: 1.8530221328360525
Validation loss: 2.4601016003810243

Epoch: 6| Step: 2
Training loss: 2.3645760512274867
Validation loss: 2.4821616526836174

Epoch: 6| Step: 3
Training loss: 2.396975988376809
Validation loss: 2.419601632044773

Epoch: 6| Step: 4
Training loss: 2.6034244140765006
Validation loss: 2.458369072483485

Epoch: 6| Step: 5
Training loss: 2.394423913339077
Validation loss: 2.4752458445937147

Epoch: 6| Step: 6
Training loss: 1.9512454945953963
Validation loss: 2.4423822708819096

Epoch: 6| Step: 7
Training loss: 2.867981346059066
Validation loss: 2.4735668787596508

Epoch: 6| Step: 8
Training loss: 2.450662433831617
Validation loss: 2.3781920259593385

Epoch: 6| Step: 9
Training loss: 2.56201492928794
Validation loss: 2.4679178704951594

Epoch: 6| Step: 10
Training loss: 1.6851821805455984
Validation loss: 2.5008521135242865

Epoch: 6| Step: 11
Training loss: 2.6736517458603486
Validation loss: 2.4172603003955806

Epoch: 6| Step: 12
Training loss: 1.9887948862281661
Validation loss: 2.4468904653925425

Epoch: 6| Step: 13
Training loss: 2.1483866737595894
Validation loss: 2.449538587207174

Epoch: 192| Step: 0
Training loss: 1.483198000417059
Validation loss: 2.49489267261962

Epoch: 6| Step: 1
Training loss: 2.837776701623362
Validation loss: 2.4664191391192483

Epoch: 6| Step: 2
Training loss: 2.4610919237883873
Validation loss: 2.4564091295409454

Epoch: 6| Step: 3
Training loss: 2.3346594947357664
Validation loss: 2.4202554062016053

Epoch: 6| Step: 4
Training loss: 2.513528175070122
Validation loss: 2.4753328873665272

Epoch: 6| Step: 5
Training loss: 2.3739053311581886
Validation loss: 2.445722770745989

Epoch: 6| Step: 6
Training loss: 2.195515361929352
Validation loss: 2.4608832813494463

Epoch: 6| Step: 7
Training loss: 2.459558106407813
Validation loss: 2.4482267170752974

Epoch: 6| Step: 8
Training loss: 1.9729417046714124
Validation loss: 2.444414832856243

Epoch: 6| Step: 9
Training loss: 2.2284039294696947
Validation loss: 2.4152792210552305

Epoch: 6| Step: 10
Training loss: 2.7935240720329997
Validation loss: 2.4468108787187264

Epoch: 6| Step: 11
Training loss: 2.149239796043526
Validation loss: 2.481412650070689

Epoch: 6| Step: 12
Training loss: 2.7700388541405854
Validation loss: 2.459504042885765

Epoch: 6| Step: 13
Training loss: 2.3078330088784362
Validation loss: 2.4135874613930857

Epoch: 193| Step: 0
Training loss: 1.9530982664186034
Validation loss: 2.4352793121054517

Epoch: 6| Step: 1
Training loss: 2.019212354499213
Validation loss: 2.4949323256704417

Epoch: 6| Step: 2
Training loss: 2.497291719230799
Validation loss: 2.4436371344089283

Epoch: 6| Step: 3
Training loss: 2.6506899817123823
Validation loss: 2.4269361536287604

Epoch: 6| Step: 4
Training loss: 2.168149318564183
Validation loss: 2.4576681421442097

Epoch: 6| Step: 5
Training loss: 2.6865919486447787
Validation loss: 2.4272763751460844

Epoch: 6| Step: 6
Training loss: 2.117782565453157
Validation loss: 2.424043284035807

Epoch: 6| Step: 7
Training loss: 2.2631264425261
Validation loss: 2.4554634514647544

Epoch: 6| Step: 8
Training loss: 2.3863068520201445
Validation loss: 2.454702523902507

Epoch: 6| Step: 9
Training loss: 2.233140617804974
Validation loss: 2.4624808627673254

Epoch: 6| Step: 10
Training loss: 2.4405934193774463
Validation loss: 2.419436036664952

Epoch: 6| Step: 11
Training loss: 2.1132599270744388
Validation loss: 2.4441121974999094

Epoch: 6| Step: 12
Training loss: 2.8030681557563724
Validation loss: 2.444730093104092

Epoch: 6| Step: 13
Training loss: 2.849512988859963
Validation loss: 2.419671403211599

Epoch: 194| Step: 0
Training loss: 2.3163745485552063
Validation loss: 2.481704807275862

Epoch: 6| Step: 1
Training loss: 2.259967659744183
Validation loss: 2.4499964581552485

Epoch: 6| Step: 2
Training loss: 2.550989863932954
Validation loss: 2.4780449537799907

Epoch: 6| Step: 3
Training loss: 2.3587124127828343
Validation loss: 2.473522856661077

Epoch: 6| Step: 4
Training loss: 1.5484866599277247
Validation loss: 2.450494034015482

Epoch: 6| Step: 5
Training loss: 1.9931361314684612
Validation loss: 2.455982026158613

Epoch: 6| Step: 6
Training loss: 2.837163318707875
Validation loss: 2.424319217531011

Epoch: 6| Step: 7
Training loss: 2.4854687856073583
Validation loss: 2.4483380414292495

Epoch: 6| Step: 8
Training loss: 2.230952489342745
Validation loss: 2.46832835816881

Epoch: 6| Step: 9
Training loss: 2.145259545902805
Validation loss: 2.4984364388507165

Epoch: 6| Step: 10
Training loss: 2.4543133426825974
Validation loss: 2.473547786894053

Epoch: 6| Step: 11
Training loss: 2.4011185662014944
Validation loss: 2.474683152102686

Epoch: 6| Step: 12
Training loss: 2.185273481490088
Validation loss: 2.427317189820842

Epoch: 6| Step: 13
Training loss: 3.156793830778162
Validation loss: 2.430994862839967

Epoch: 195| Step: 0
Training loss: 2.0565870663877326
Validation loss: 2.4272442153098015

Epoch: 6| Step: 1
Training loss: 2.5958667987688973
Validation loss: 2.4969206457182986

Epoch: 6| Step: 2
Training loss: 1.9865041409114959
Validation loss: 2.4127303184247584

Epoch: 6| Step: 3
Training loss: 2.1520467508265058
Validation loss: 2.427765128131034

Epoch: 6| Step: 4
Training loss: 2.1259057975490094
Validation loss: 2.457364218940797

Epoch: 6| Step: 5
Training loss: 3.148714947840453
Validation loss: 2.473945621960836

Epoch: 6| Step: 6
Training loss: 1.9356977632990808
Validation loss: 2.482594828510239

Epoch: 6| Step: 7
Training loss: 3.0763109157565385
Validation loss: 2.45357594611383

Epoch: 6| Step: 8
Training loss: 2.285396726295835
Validation loss: 2.4277912874685135

Epoch: 6| Step: 9
Training loss: 1.6851526110896762
Validation loss: 2.4790906666120933

Epoch: 6| Step: 10
Training loss: 2.522225954199601
Validation loss: 2.4122510183175967

Epoch: 6| Step: 11
Training loss: 2.5083055813628152
Validation loss: 2.5077561032331457

Epoch: 6| Step: 12
Training loss: 1.9853717373237108
Validation loss: 2.4957018482040754

Epoch: 6| Step: 13
Training loss: 2.4889180612652035
Validation loss: 2.488659204792745

Epoch: 196| Step: 0
Training loss: 2.9709475765938134
Validation loss: 2.444527133080366

Epoch: 6| Step: 1
Training loss: 2.816311436510862
Validation loss: 2.443960576777366

Epoch: 6| Step: 2
Training loss: 2.3809065403385543
Validation loss: 2.4383380144549123

Epoch: 6| Step: 3
Training loss: 1.9085974700679118
Validation loss: 2.4739261433828488

Epoch: 6| Step: 4
Training loss: 1.732906097553538
Validation loss: 2.4785132853101484

Epoch: 6| Step: 5
Training loss: 2.2605044674558146
Validation loss: 2.4734767639846735

Epoch: 6| Step: 6
Training loss: 2.277010492507556
Validation loss: 2.4457302602229296

Epoch: 6| Step: 7
Training loss: 2.1408003018292043
Validation loss: 2.460009998159819

Epoch: 6| Step: 8
Training loss: 2.6959819459904937
Validation loss: 2.461967470448418

Epoch: 6| Step: 9
Training loss: 2.5029847447490146
Validation loss: 2.390991084249384

Epoch: 6| Step: 10
Training loss: 2.211852406701397
Validation loss: 2.4368463107205565

Epoch: 6| Step: 11
Training loss: 1.7157208191842648
Validation loss: 2.458247451436157

Epoch: 6| Step: 12
Training loss: 2.243334752498516
Validation loss: 2.5162691700338002

Epoch: 6| Step: 13
Training loss: 2.4132687149389165
Validation loss: 2.4607566046912868

Epoch: 197| Step: 0
Training loss: 2.077382005078901
Validation loss: 2.4495767180439043

Epoch: 6| Step: 1
Training loss: 2.443712387380882
Validation loss: 2.4701370500636126

Epoch: 6| Step: 2
Training loss: 2.33558881830125
Validation loss: 2.5237186272367014

Epoch: 6| Step: 3
Training loss: 2.079634842180892
Validation loss: 2.4907064301782853

Epoch: 6| Step: 4
Training loss: 2.764477162932441
Validation loss: 2.4649053200297053

Epoch: 6| Step: 5
Training loss: 2.0168766600723456
Validation loss: 2.4462487330894986

Epoch: 6| Step: 6
Training loss: 2.30438458019859
Validation loss: 2.428723686473066

Epoch: 6| Step: 7
Training loss: 1.4549850536509494
Validation loss: 2.4288137148224203

Epoch: 6| Step: 8
Training loss: 1.902821005108226
Validation loss: 2.454743995856311

Epoch: 6| Step: 9
Training loss: 2.003729680482447
Validation loss: 2.4639954084817837

Epoch: 6| Step: 10
Training loss: 2.6677872468973707
Validation loss: 2.4691866530982085

Epoch: 6| Step: 11
Training loss: 3.1478570824333465
Validation loss: 2.4620212973926736

Epoch: 6| Step: 12
Training loss: 2.323628121350701
Validation loss: 2.424132241471824

Epoch: 6| Step: 13
Training loss: 2.977459149212545
Validation loss: 2.4702062760045576

Epoch: 198| Step: 0
Training loss: 2.5055257763987844
Validation loss: 2.4075560555116695

Epoch: 6| Step: 1
Training loss: 2.2199586611842443
Validation loss: 2.4876413396803496

Epoch: 6| Step: 2
Training loss: 2.980321878036683
Validation loss: 2.4125811927084695

Epoch: 6| Step: 3
Training loss: 2.438251281769235
Validation loss: 2.459339023385375

Epoch: 6| Step: 4
Training loss: 2.6975537697963285
Validation loss: 2.4449419846102147

Epoch: 6| Step: 5
Training loss: 2.5695050023362964
Validation loss: 2.5183928532637467

Epoch: 6| Step: 6
Training loss: 2.4691551938296263
Validation loss: 2.462901717402819

Epoch: 6| Step: 7
Training loss: 2.187026381310387
Validation loss: 2.4485546410901886

Epoch: 6| Step: 8
Training loss: 2.0450557165786787
Validation loss: 2.4614962348351033

Epoch: 6| Step: 9
Training loss: 2.3710398534339876
Validation loss: 2.4797156486053646

Epoch: 6| Step: 10
Training loss: 1.666481516408523
Validation loss: 2.451577722706392

Epoch: 6| Step: 11
Training loss: 2.4100670202916272
Validation loss: 2.468933086218535

Epoch: 6| Step: 12
Training loss: 1.8307716578132753
Validation loss: 2.488456303809943

Epoch: 6| Step: 13
Training loss: 1.998522749358325
Validation loss: 2.486496629092743

Epoch: 199| Step: 0
Training loss: 2.7148216191768837
Validation loss: 2.425106104238004

Epoch: 6| Step: 1
Training loss: 2.2500120798422474
Validation loss: 2.4529089857712316

Epoch: 6| Step: 2
Training loss: 2.3910344589730577
Validation loss: 2.4929056865131005

Epoch: 6| Step: 3
Training loss: 1.7478968380093953
Validation loss: 2.487378457543766

Epoch: 6| Step: 4
Training loss: 2.012335880766798
Validation loss: 2.526349015224076

Epoch: 6| Step: 5
Training loss: 2.030762364469271
Validation loss: 2.467584581275818

Epoch: 6| Step: 6
Training loss: 1.8942545580608359
Validation loss: 2.4601987600770756

Epoch: 6| Step: 7
Training loss: 2.6629040120524032
Validation loss: 2.4457978547283505

Epoch: 6| Step: 8
Training loss: 2.299394536144052
Validation loss: 2.4538984801673647

Epoch: 6| Step: 9
Training loss: 2.624435182386925
Validation loss: 2.510026563350153

Epoch: 6| Step: 10
Training loss: 2.8910982311638547
Validation loss: 2.467963557995584

Epoch: 6| Step: 11
Training loss: 2.248425462596448
Validation loss: 2.432243191922278

Epoch: 6| Step: 12
Training loss: 2.464152050144818
Validation loss: 2.452523697515141

Epoch: 6| Step: 13
Training loss: 2.0647072973928946
Validation loss: 2.4502259197380134

Epoch: 200| Step: 0
Training loss: 2.1086243600732995
Validation loss: 2.4634619647493254

Epoch: 6| Step: 1
Training loss: 2.350544148205597
Validation loss: 2.455053911517098

Epoch: 6| Step: 2
Training loss: 1.5490452348471497
Validation loss: 2.4337857231137776

Epoch: 6| Step: 3
Training loss: 2.11236947463347
Validation loss: 2.3979015386820226

Epoch: 6| Step: 4
Training loss: 2.2784603254100726
Validation loss: 2.4454466807749884

Epoch: 6| Step: 5
Training loss: 2.21422577702139
Validation loss: 2.507157075096495

Epoch: 6| Step: 6
Training loss: 2.013211483499665
Validation loss: 2.458747548002437

Epoch: 6| Step: 7
Training loss: 2.812852455942865
Validation loss: 2.4359587652414607

Epoch: 6| Step: 8
Training loss: 2.7849228856147525
Validation loss: 2.4584514561036754

Epoch: 6| Step: 9
Training loss: 2.1905176329592
Validation loss: 2.463814574326098

Epoch: 6| Step: 10
Training loss: 2.3091697426147606
Validation loss: 2.449821465914117

Epoch: 6| Step: 11
Training loss: 2.9813595861610906
Validation loss: 2.4193274503955604

Epoch: 6| Step: 12
Training loss: 2.130450942969105
Validation loss: 2.4598609602331165

Epoch: 6| Step: 13
Training loss: 2.9257354529021677
Validation loss: 2.401002243266792

Epoch: 201| Step: 0
Training loss: 2.5985411549330166
Validation loss: 2.444397342376615

Epoch: 6| Step: 1
Training loss: 2.073557487873818
Validation loss: 2.4729257681123875

Epoch: 6| Step: 2
Training loss: 1.7031728755276445
Validation loss: 2.3985714535805553

Epoch: 6| Step: 3
Training loss: 2.4739034439154843
Validation loss: 2.4640099142606533

Epoch: 6| Step: 4
Training loss: 2.697100679186714
Validation loss: 2.4714328699697874

Epoch: 6| Step: 5
Training loss: 2.483834645749253
Validation loss: 2.490488408301763

Epoch: 6| Step: 6
Training loss: 2.5238412823354026
Validation loss: 2.418664690455906

Epoch: 6| Step: 7
Training loss: 1.5074751876889392
Validation loss: 2.3940209066357228

Epoch: 6| Step: 8
Training loss: 2.8802126194035034
Validation loss: 2.517355173396509

Epoch: 6| Step: 9
Training loss: 2.13843853518026
Validation loss: 2.4669653299999883

Epoch: 6| Step: 10
Training loss: 2.509251737120634
Validation loss: 2.4782314327182493

Epoch: 6| Step: 11
Training loss: 1.7358574245329812
Validation loss: 2.4773269228725416

Epoch: 6| Step: 12
Training loss: 2.549350027386155
Validation loss: 2.4414669221291736

Epoch: 6| Step: 13
Training loss: 1.7813637680396648
Validation loss: 2.4722110282856837

Epoch: 202| Step: 0
Training loss: 2.5087079027233368
Validation loss: 2.4221853797652444

Epoch: 6| Step: 1
Training loss: 2.360921390864756
Validation loss: 2.4851595588566093

Epoch: 6| Step: 2
Training loss: 2.5241156927456774
Validation loss: 2.4503016666398794

Epoch: 6| Step: 3
Training loss: 2.3173869278039736
Validation loss: 2.4705786977228787

Epoch: 6| Step: 4
Training loss: 2.248684392526524
Validation loss: 2.4272365769031956

Epoch: 6| Step: 5
Training loss: 3.021061873286299
Validation loss: 2.422229725783687

Epoch: 6| Step: 6
Training loss: 2.153977343603928
Validation loss: 2.4212225938667578

Epoch: 6| Step: 7
Training loss: 2.1174821824514294
Validation loss: 2.4723708678152625

Epoch: 6| Step: 8
Training loss: 1.8816352424441647
Validation loss: 2.4716277654669105

Epoch: 6| Step: 9
Training loss: 1.839000403328997
Validation loss: 2.4471010740207926

Epoch: 6| Step: 10
Training loss: 2.508615335557533
Validation loss: 2.4216911063505115

Epoch: 6| Step: 11
Training loss: 2.3582627662192635
Validation loss: 2.4709774958539765

Epoch: 6| Step: 12
Training loss: 2.1796457156753286
Validation loss: 2.4446838969500555

Epoch: 6| Step: 13
Training loss: 2.287564878116955
Validation loss: 2.4753006610903414

Epoch: 203| Step: 0
Training loss: 2.6544091521622133
Validation loss: 2.4450172314981478

Epoch: 6| Step: 1
Training loss: 2.225900437821566
Validation loss: 2.4395511906042535

Epoch: 6| Step: 2
Training loss: 1.8074563983813166
Validation loss: 2.4477603275083135

Epoch: 6| Step: 3
Training loss: 2.159910550208018
Validation loss: 2.449928572958976

Epoch: 6| Step: 4
Training loss: 2.952641846223533
Validation loss: 2.4682044322972607

Epoch: 6| Step: 5
Training loss: 1.7488590335734677
Validation loss: 2.4591324840200186

Epoch: 6| Step: 6
Training loss: 2.7020493500591414
Validation loss: 2.446129371618799

Epoch: 6| Step: 7
Training loss: 3.217647178384073
Validation loss: 2.4775062244003028

Epoch: 6| Step: 8
Training loss: 2.195394602696256
Validation loss: 2.4576914119354294

Epoch: 6| Step: 9
Training loss: 1.508222613126003
Validation loss: 2.460990333022556

Epoch: 6| Step: 10
Training loss: 2.161900621379811
Validation loss: 2.4095814749600444

Epoch: 6| Step: 11
Training loss: 2.639193536227967
Validation loss: 2.476005579827615

Epoch: 6| Step: 12
Training loss: 1.8055939482821153
Validation loss: 2.4605608512397703

Epoch: 6| Step: 13
Training loss: 2.373023766927099
Validation loss: 2.439713009095298

Epoch: 204| Step: 0
Training loss: 1.9312827740206144
Validation loss: 2.407269709651634

Epoch: 6| Step: 1
Training loss: 2.4678664739028964
Validation loss: 2.46397661389276

Epoch: 6| Step: 2
Training loss: 1.9393324031694283
Validation loss: 2.4656870574505065

Epoch: 6| Step: 3
Training loss: 2.5494637467746357
Validation loss: 2.5131130049643873

Epoch: 6| Step: 4
Training loss: 2.312272550377443
Validation loss: 2.4815838918799247

Epoch: 6| Step: 5
Training loss: 2.1435520180792036
Validation loss: 2.467747359169658

Epoch: 6| Step: 6
Training loss: 2.5609049601230254
Validation loss: 2.4663789317616605

Epoch: 6| Step: 7
Training loss: 1.791682893842209
Validation loss: 2.4131779048062993

Epoch: 6| Step: 8
Training loss: 3.0865125675609866
Validation loss: 2.386819664308876

Epoch: 6| Step: 9
Training loss: 2.227318779180878
Validation loss: 2.4438336633563553

Epoch: 6| Step: 10
Training loss: 1.791099355023794
Validation loss: 2.4814582275491546

Epoch: 6| Step: 11
Training loss: 2.3754007101825043
Validation loss: 2.439096849602255

Epoch: 6| Step: 12
Training loss: 2.6958123227400783
Validation loss: 2.485553272430906

Epoch: 6| Step: 13
Training loss: 2.0840309373825354
Validation loss: 2.443867673008543

Epoch: 205| Step: 0
Training loss: 2.2487776933017636
Validation loss: 2.455853925964407

Epoch: 6| Step: 1
Training loss: 2.548770877589862
Validation loss: 2.401983796491912

Epoch: 6| Step: 2
Training loss: 1.9283310296328715
Validation loss: 2.4249816414726255

Epoch: 6| Step: 3
Training loss: 1.9725499492746497
Validation loss: 2.4437815572447086

Epoch: 6| Step: 4
Training loss: 2.4883047249493626
Validation loss: 2.4280167557991565

Epoch: 6| Step: 5
Training loss: 2.3224617094860376
Validation loss: 2.435195659247356

Epoch: 6| Step: 6
Training loss: 2.139814014374446
Validation loss: 2.4706187238880433

Epoch: 6| Step: 7
Training loss: 2.8725894275951185
Validation loss: 2.4819901181433868

Epoch: 6| Step: 8
Training loss: 2.332626905678963
Validation loss: 2.462218863021325

Epoch: 6| Step: 9
Training loss: 2.2967998466393325
Validation loss: 2.472077871943567

Epoch: 6| Step: 10
Training loss: 2.194913889036571
Validation loss: 2.446977584378014

Epoch: 6| Step: 11
Training loss: 1.9512936971244856
Validation loss: 2.423594730298059

Epoch: 6| Step: 12
Training loss: 2.6091137601089183
Validation loss: 2.4816890599308423

Epoch: 6| Step: 13
Training loss: 2.2178766385334514
Validation loss: 2.475722138032498

Epoch: 206| Step: 0
Training loss: 2.5036244821534117
Validation loss: 2.4229055635405268

Epoch: 6| Step: 1
Training loss: 2.0081240638614375
Validation loss: 2.457426479200704

Epoch: 6| Step: 2
Training loss: 2.6221744225432433
Validation loss: 2.455789950872375

Epoch: 6| Step: 3
Training loss: 2.065500331238697
Validation loss: 2.4222124069129523

Epoch: 6| Step: 4
Training loss: 2.2270866981626045
Validation loss: 2.4491995447482022

Epoch: 6| Step: 5
Training loss: 2.2392633490446165
Validation loss: 2.453562576063067

Epoch: 6| Step: 6
Training loss: 3.1135365610005308
Validation loss: 2.4587397603537022

Epoch: 6| Step: 7
Training loss: 2.2406088558450707
Validation loss: 2.426392024551689

Epoch: 6| Step: 8
Training loss: 2.281993901444359
Validation loss: 2.5121308471579047

Epoch: 6| Step: 9
Training loss: 2.2020232780397233
Validation loss: 2.4199586101230883

Epoch: 6| Step: 10
Training loss: 1.81167972024229
Validation loss: 2.4009539062941276

Epoch: 6| Step: 11
Training loss: 2.0065473437186148
Validation loss: 2.4708574821325344

Epoch: 6| Step: 12
Training loss: 2.3856894213618323
Validation loss: 2.4411162042090524

Epoch: 6| Step: 13
Training loss: 2.337137481811183
Validation loss: 2.4738658269006337

Epoch: 207| Step: 0
Training loss: 2.778811553808716
Validation loss: 2.433829233664497

Epoch: 6| Step: 1
Training loss: 1.7985171568038685
Validation loss: 2.4486669744564513

Epoch: 6| Step: 2
Training loss: 2.2758144262313706
Validation loss: 2.4720299540650044

Epoch: 6| Step: 3
Training loss: 2.5131362071590235
Validation loss: 2.4493306907605703

Epoch: 6| Step: 4
Training loss: 2.774704248975196
Validation loss: 2.4703008355755602

Epoch: 6| Step: 5
Training loss: 2.457532094782733
Validation loss: 2.3965777452938175

Epoch: 6| Step: 6
Training loss: 1.8927770299486726
Validation loss: 2.4213155512468956

Epoch: 6| Step: 7
Training loss: 2.425837861658253
Validation loss: 2.438318512170965

Epoch: 6| Step: 8
Training loss: 2.107808527507955
Validation loss: 2.4646209844430382

Epoch: 6| Step: 9
Training loss: 2.4786529863680102
Validation loss: 2.4520619591144266

Epoch: 6| Step: 10
Training loss: 2.453706320142117
Validation loss: 2.52756065787841

Epoch: 6| Step: 11
Training loss: 2.5237227240302897
Validation loss: 2.4953608096921482

Epoch: 6| Step: 12
Training loss: 1.6129716109575911
Validation loss: 2.4471277809413956

Epoch: 6| Step: 13
Training loss: 1.9197645928192997
Validation loss: 2.4343981267694166

Epoch: 208| Step: 0
Training loss: 2.386059159510322
Validation loss: 2.4324718683595323

Epoch: 6| Step: 1
Training loss: 1.8482738535293899
Validation loss: 2.4616772080527882

Epoch: 6| Step: 2
Training loss: 1.8242399226722321
Validation loss: 2.441000039711312

Epoch: 6| Step: 3
Training loss: 2.195974229880292
Validation loss: 2.479288591623587

Epoch: 6| Step: 4
Training loss: 1.9480463756547635
Validation loss: 2.436954845407242

Epoch: 6| Step: 5
Training loss: 2.4455451245306685
Validation loss: 2.426014466578082

Epoch: 6| Step: 6
Training loss: 2.2455797220916125
Validation loss: 2.41240433763564

Epoch: 6| Step: 7
Training loss: 2.0477423541010467
Validation loss: 2.4636945446595524

Epoch: 6| Step: 8
Training loss: 2.1554898013849453
Validation loss: 2.466047486674134

Epoch: 6| Step: 9
Training loss: 3.066837586601673
Validation loss: 2.393501174067546

Epoch: 6| Step: 10
Training loss: 2.821008231874806
Validation loss: 2.463518247475928

Epoch: 6| Step: 11
Training loss: 2.2923323155834887
Validation loss: 2.453686069679611

Epoch: 6| Step: 12
Training loss: 2.501651218611435
Validation loss: 2.4325637772329003

Epoch: 6| Step: 13
Training loss: 2.0453557790165378
Validation loss: 2.4186928507908916

Epoch: 209| Step: 0
Training loss: 2.180414987664646
Validation loss: 2.473069223284776

Epoch: 6| Step: 1
Training loss: 1.9093686841994497
Validation loss: 2.431464820947977

Epoch: 6| Step: 2
Training loss: 2.2531476785521063
Validation loss: 2.450051235820957

Epoch: 6| Step: 3
Training loss: 2.696836355911572
Validation loss: 2.406432133847778

Epoch: 6| Step: 4
Training loss: 2.3782306582505353
Validation loss: 2.4515423460639756

Epoch: 6| Step: 5
Training loss: 2.1633093449458243
Validation loss: 2.4295197810057494

Epoch: 6| Step: 6
Training loss: 1.691007853538824
Validation loss: 2.4952731884979995

Epoch: 6| Step: 7
Training loss: 2.7561227090035305
Validation loss: 2.4404262786660085

Epoch: 6| Step: 8
Training loss: 2.309816194958419
Validation loss: 2.437649600536778

Epoch: 6| Step: 9
Training loss: 1.8475010103008724
Validation loss: 2.498192706112761

Epoch: 6| Step: 10
Training loss: 2.4631943783865964
Validation loss: 2.4389312250754287

Epoch: 6| Step: 11
Training loss: 2.057097439510552
Validation loss: 2.504803616632809

Epoch: 6| Step: 12
Training loss: 2.5723294863525243
Validation loss: 2.4851483899159934

Epoch: 6| Step: 13
Training loss: 2.942460923498546
Validation loss: 2.4438818692141466

Epoch: 210| Step: 0
Training loss: 2.590008162261002
Validation loss: 2.456165782828277

Epoch: 6| Step: 1
Training loss: 2.1615888318725585
Validation loss: 2.4641284148065408

Epoch: 6| Step: 2
Training loss: 2.1745015461087953
Validation loss: 2.4500712850821778

Epoch: 6| Step: 3
Training loss: 2.123621774162543
Validation loss: 2.4587445826722343

Epoch: 6| Step: 4
Training loss: 1.711640235426892
Validation loss: 2.470645349875938

Epoch: 6| Step: 5
Training loss: 2.687670591396056
Validation loss: 2.4831350798532745

Epoch: 6| Step: 6
Training loss: 2.9378291818132776
Validation loss: 2.42213529364984

Epoch: 6| Step: 7
Training loss: 2.4005320595028867
Validation loss: 2.498909041569898

Epoch: 6| Step: 8
Training loss: 1.9937566822860808
Validation loss: 2.4162581617972094

Epoch: 6| Step: 9
Training loss: 2.460881598912464
Validation loss: 2.47951854863738

Epoch: 6| Step: 10
Training loss: 2.5541884375220514
Validation loss: 2.4770311876284548

Epoch: 6| Step: 11
Training loss: 2.2902991173637277
Validation loss: 2.486697303860139

Epoch: 6| Step: 12
Training loss: 1.966495858334298
Validation loss: 2.485160240730826

Epoch: 6| Step: 13
Training loss: 2.048668810647889
Validation loss: 2.4526869883991664

Epoch: 211| Step: 0
Training loss: 2.0607838282003925
Validation loss: 2.454639803421318

Epoch: 6| Step: 1
Training loss: 2.2127731844250214
Validation loss: 2.456836601106655

Epoch: 6| Step: 2
Training loss: 2.3410788000663536
Validation loss: 2.4550528411812444

Epoch: 6| Step: 3
Training loss: 2.166751334174443
Validation loss: 2.451512306888691

Epoch: 6| Step: 4
Training loss: 3.086805776780336
Validation loss: 2.49723786795433

Epoch: 6| Step: 5
Training loss: 2.1282272515960403
Validation loss: 2.4624510772760844

Epoch: 6| Step: 6
Training loss: 2.2508363229090773
Validation loss: 2.434762595041242

Epoch: 6| Step: 7
Training loss: 1.8410439757607135
Validation loss: 2.441441215937444

Epoch: 6| Step: 8
Training loss: 2.161624568077313
Validation loss: 2.459345908496591

Epoch: 6| Step: 9
Training loss: 1.6101389432862656
Validation loss: 2.4537973145596985

Epoch: 6| Step: 10
Training loss: 2.8609674740715443
Validation loss: 2.443442431511961

Epoch: 6| Step: 11
Training loss: 2.4880966046152038
Validation loss: 2.4022871353437485

Epoch: 6| Step: 12
Training loss: 2.0815221797541215
Validation loss: 2.4650510109894905

Epoch: 6| Step: 13
Training loss: 2.026494489600659
Validation loss: 2.4573013603502876

Epoch: 212| Step: 0
Training loss: 2.821360131963337
Validation loss: 2.4605705824992814

Epoch: 6| Step: 1
Training loss: 1.5847645448112615
Validation loss: 2.5123048498918306

Epoch: 6| Step: 2
Training loss: 2.0368089170876544
Validation loss: 2.426546555982099

Epoch: 6| Step: 3
Training loss: 1.528137001037279
Validation loss: 2.4270347461135273

Epoch: 6| Step: 4
Training loss: 1.7540510156100217
Validation loss: 2.4279068495923815

Epoch: 6| Step: 5
Training loss: 2.5396761578146663
Validation loss: 2.429341280246056

Epoch: 6| Step: 6
Training loss: 2.9679030967172606
Validation loss: 2.4071670987814286

Epoch: 6| Step: 7
Training loss: 1.992615836975115
Validation loss: 2.52673416430691

Epoch: 6| Step: 8
Training loss: 2.3003866119531136
Validation loss: 2.4029137629536077

Epoch: 6| Step: 9
Training loss: 2.4379189938112673
Validation loss: 2.491678880945632

Epoch: 6| Step: 10
Training loss: 2.493757656152584
Validation loss: 2.42789373204067

Epoch: 6| Step: 11
Training loss: 1.911741632434506
Validation loss: 2.496999593147812

Epoch: 6| Step: 12
Training loss: 2.49293396870813
Validation loss: 2.4345564305551335

Epoch: 6| Step: 13
Training loss: 1.7761100092143907
Validation loss: 2.471558963125437

Epoch: 213| Step: 0
Training loss: 2.251329453086653
Validation loss: 2.4296706136113984

Epoch: 6| Step: 1
Training loss: 2.165122973889804
Validation loss: 2.438003969640995

Epoch: 6| Step: 2
Training loss: 1.8456993789231164
Validation loss: 2.4581883072939954

Epoch: 6| Step: 3
Training loss: 2.4890493887096805
Validation loss: 2.4758927172687395

Epoch: 6| Step: 4
Training loss: 1.9894193079044358
Validation loss: 2.497837451089031

Epoch: 6| Step: 5
Training loss: 2.7095465265908873
Validation loss: 2.4312432738834096

Epoch: 6| Step: 6
Training loss: 2.070933928883071
Validation loss: 2.492106503198355

Epoch: 6| Step: 7
Training loss: 2.3214445595662303
Validation loss: 2.4373652607899166

Epoch: 6| Step: 8
Training loss: 1.972265707202229
Validation loss: 2.4718055595971027

Epoch: 6| Step: 9
Training loss: 2.098161292059101
Validation loss: 2.521350825445399

Epoch: 6| Step: 10
Training loss: 2.684190886359706
Validation loss: 2.4607527791622963

Epoch: 6| Step: 11
Training loss: 1.9309572065798295
Validation loss: 2.439255939379161

Epoch: 6| Step: 12
Training loss: 2.435890253084741
Validation loss: 2.516566800430966

Epoch: 6| Step: 13
Training loss: 2.2112339211974272
Validation loss: 2.461545880407476

Epoch: 214| Step: 0
Training loss: 1.8385456794788635
Validation loss: 2.440490350292372

Epoch: 6| Step: 1
Training loss: 2.5738056412880086
Validation loss: 2.416951138009117

Epoch: 6| Step: 2
Training loss: 1.98668098128792
Validation loss: 2.4306610038451097

Epoch: 6| Step: 3
Training loss: 2.5598316721412107
Validation loss: 2.4317199902300577

Epoch: 6| Step: 4
Training loss: 2.505214974017208
Validation loss: 2.438044898626316

Epoch: 6| Step: 5
Training loss: 1.9976585510503222
Validation loss: 2.428800052244053

Epoch: 6| Step: 6
Training loss: 1.8809281412865606
Validation loss: 2.4650870288719156

Epoch: 6| Step: 7
Training loss: 2.146136685258878
Validation loss: 2.4561216132372716

Epoch: 6| Step: 8
Training loss: 2.1550108071607186
Validation loss: 2.4839521195093397

Epoch: 6| Step: 9
Training loss: 2.768175145528552
Validation loss: 2.4477064312521306

Epoch: 6| Step: 10
Training loss: 2.325489165007522
Validation loss: 2.471154442508304

Epoch: 6| Step: 11
Training loss: 2.2975748254589585
Validation loss: 2.496242410604082

Epoch: 6| Step: 12
Training loss: 1.1307984963272455
Validation loss: 2.436538673422456

Epoch: 6| Step: 13
Training loss: 2.890984755115302
Validation loss: 2.5187507297379748

Epoch: 215| Step: 0
Training loss: 2.0527794394732286
Validation loss: 2.4424766633397614

Epoch: 6| Step: 1
Training loss: 2.5273795972873128
Validation loss: 2.479323666458831

Epoch: 6| Step: 2
Training loss: 1.9590327522184325
Validation loss: 2.413548248937907

Epoch: 6| Step: 3
Training loss: 1.8802101860847398
Validation loss: 2.43768168093888

Epoch: 6| Step: 4
Training loss: 1.858677709285784
Validation loss: 2.3850288894498615

Epoch: 6| Step: 5
Training loss: 2.18122290127161
Validation loss: 2.450164563627305

Epoch: 6| Step: 6
Training loss: 2.733349242590528
Validation loss: 2.397572326511895

Epoch: 6| Step: 7
Training loss: 2.399811292223047
Validation loss: 2.438662528114066

Epoch: 6| Step: 8
Training loss: 1.4646782133028982
Validation loss: 2.375322338125281

Epoch: 6| Step: 9
Training loss: 1.710753409179787
Validation loss: 2.449207126172274

Epoch: 6| Step: 10
Training loss: 1.7581244297887784
Validation loss: 2.41209388114487

Epoch: 6| Step: 11
Training loss: 2.754379253483711
Validation loss: 2.479425397321983

Epoch: 6| Step: 12
Training loss: 3.040721450326643
Validation loss: 2.4105689638307175

Epoch: 6| Step: 13
Training loss: 2.240943909405708
Validation loss: 2.4499857965107457

Epoch: 216| Step: 0
Training loss: 2.4708768157821086
Validation loss: 2.3967945772534045

Epoch: 6| Step: 1
Training loss: 2.142943525843846
Validation loss: 2.4594207720218444

Epoch: 6| Step: 2
Training loss: 1.9823880798766573
Validation loss: 2.4216239066

Epoch: 6| Step: 3
Training loss: 2.011751341324287
Validation loss: 2.442800795640067

Epoch: 6| Step: 4
Training loss: 2.3422858178776167
Validation loss: 2.452550938591674

Epoch: 6| Step: 5
Training loss: 1.7328791310576812
Validation loss: 2.472620708370391

Epoch: 6| Step: 6
Training loss: 2.31125163844181
Validation loss: 2.447928102702646

Epoch: 6| Step: 7
Training loss: 2.0856577939298018
Validation loss: 2.4656605453171787

Epoch: 6| Step: 8
Training loss: 1.9022116487918257
Validation loss: 2.4644813919346698

Epoch: 6| Step: 9
Training loss: 2.781812546662569
Validation loss: 2.4514076881993536

Epoch: 6| Step: 10
Training loss: 2.4840515693926033
Validation loss: 2.4763336474439286

Epoch: 6| Step: 11
Training loss: 2.3326939546955563
Validation loss: 2.4281612936900823

Epoch: 6| Step: 12
Training loss: 2.427639898792745
Validation loss: 2.4594266958362447

Epoch: 6| Step: 13
Training loss: 2.655323989123198
Validation loss: 2.4292406823312316

Epoch: 217| Step: 0
Training loss: 2.397686669935732
Validation loss: 2.4413849933970457

Epoch: 6| Step: 1
Training loss: 2.0510395577650593
Validation loss: 2.4855897415033734

Epoch: 6| Step: 2
Training loss: 2.751264108208304
Validation loss: 2.4619108219096684

Epoch: 6| Step: 3
Training loss: 1.9102920452753258
Validation loss: 2.4260701059093277

Epoch: 6| Step: 4
Training loss: 2.0475203101113806
Validation loss: 2.446261486028786

Epoch: 6| Step: 5
Training loss: 2.295365648582674
Validation loss: 2.46528029425577

Epoch: 6| Step: 6
Training loss: 2.342989785563289
Validation loss: 2.4853782493299152

Epoch: 6| Step: 7
Training loss: 1.8813544361617063
Validation loss: 2.4732856804069554

Epoch: 6| Step: 8
Training loss: 2.31449247560166
Validation loss: 2.4745756972011046

Epoch: 6| Step: 9
Training loss: 1.748759920257069
Validation loss: 2.481014902587253

Epoch: 6| Step: 10
Training loss: 3.012518671381534
Validation loss: 2.47652510660096

Epoch: 6| Step: 11
Training loss: 2.0272026233394183
Validation loss: 2.4772230370984896

Epoch: 6| Step: 12
Training loss: 2.6086642273793106
Validation loss: 2.4971397054959734

Epoch: 6| Step: 13
Training loss: 2.243201262547985
Validation loss: 2.4601525631325862

Epoch: 218| Step: 0
Training loss: 2.7541647498912365
Validation loss: 2.430077688076804

Epoch: 6| Step: 1
Training loss: 1.5640309272498556
Validation loss: 2.413434924686033

Epoch: 6| Step: 2
Training loss: 2.1320642968479055
Validation loss: 2.424544742815107

Epoch: 6| Step: 3
Training loss: 1.952332053391802
Validation loss: 2.426968852042009

Epoch: 6| Step: 4
Training loss: 2.4260044455931737
Validation loss: 2.4444609247624256

Epoch: 6| Step: 5
Training loss: 2.1758079869598244
Validation loss: 2.461785425386114

Epoch: 6| Step: 6
Training loss: 2.973352338219819
Validation loss: 2.435969112041965

Epoch: 6| Step: 7
Training loss: 2.24095539971585
Validation loss: 2.3790344066898688

Epoch: 6| Step: 8
Training loss: 2.23795368134376
Validation loss: 2.4087391851111195

Epoch: 6| Step: 9
Training loss: 1.8087589855801325
Validation loss: 2.432711926714586

Epoch: 6| Step: 10
Training loss: 2.1496518673822376
Validation loss: 2.4611390421464283

Epoch: 6| Step: 11
Training loss: 2.5956081490689584
Validation loss: 2.424220058818909

Epoch: 6| Step: 12
Training loss: 1.9283310296328715
Validation loss: 2.4351386240006434

Epoch: 6| Step: 13
Training loss: 2.0592775313100105
Validation loss: 2.4136133102282415

Epoch: 219| Step: 0
Training loss: 1.9386758620194053
Validation loss: 2.3896262720534045

Epoch: 6| Step: 1
Training loss: 2.2815332106280484
Validation loss: 2.503636528639581

Epoch: 6| Step: 2
Training loss: 3.1175142274729226
Validation loss: 2.4014295581838323

Epoch: 6| Step: 3
Training loss: 1.7045390007590446
Validation loss: 2.447986103470289

Epoch: 6| Step: 4
Training loss: 2.082481006476166
Validation loss: 2.427168757529301

Epoch: 6| Step: 5
Training loss: 1.8700774106409475
Validation loss: 2.440330733782768

Epoch: 6| Step: 6
Training loss: 1.9526680373637106
Validation loss: 2.466047227820014

Epoch: 6| Step: 7
Training loss: 2.4553039980995215
Validation loss: 2.4152120997756508

Epoch: 6| Step: 8
Training loss: 1.7689658771240675
Validation loss: 2.4154657733031937

Epoch: 6| Step: 9
Training loss: 2.3449187352917096
Validation loss: 2.492812570090866

Epoch: 6| Step: 10
Training loss: 2.0099637274055073
Validation loss: 2.4740411732679766

Epoch: 6| Step: 11
Training loss: 2.5755462696656646
Validation loss: 2.4003609939540986

Epoch: 6| Step: 12
Training loss: 2.707810238915945
Validation loss: 2.4597396266110567

Epoch: 6| Step: 13
Training loss: 2.160787259145302
Validation loss: 2.4711857051524126

Epoch: 220| Step: 0
Training loss: 2.1856293445398896
Validation loss: 2.403941708958634

Epoch: 6| Step: 1
Training loss: 2.159926114231505
Validation loss: 2.4386085627199217

Epoch: 6| Step: 2
Training loss: 1.8830161716579121
Validation loss: 2.418858299916176

Epoch: 6| Step: 3
Training loss: 2.405577132040418
Validation loss: 2.418511703346717

Epoch: 6| Step: 4
Training loss: 2.347558855775366
Validation loss: 2.414440067758704

Epoch: 6| Step: 5
Training loss: 2.227356243867866
Validation loss: 2.4365687783066226

Epoch: 6| Step: 6
Training loss: 2.4949529246627
Validation loss: 2.436236270335984

Epoch: 6| Step: 7
Training loss: 2.223095252154659
Validation loss: 2.440453581769409

Epoch: 6| Step: 8
Training loss: 2.5657989851843515
Validation loss: 2.4541176184889912

Epoch: 6| Step: 9
Training loss: 1.947019020007257
Validation loss: 2.426129218328751

Epoch: 6| Step: 10
Training loss: 2.0711762551789477
Validation loss: 2.457396108742831

Epoch: 6| Step: 11
Training loss: 2.5178079551986237
Validation loss: 2.465414156721712

Epoch: 6| Step: 12
Training loss: 2.399879742629462
Validation loss: 2.4257100756205565

Epoch: 6| Step: 13
Training loss: 1.5624834441261561
Validation loss: 2.491530308696474

Epoch: 221| Step: 0
Training loss: 1.731199502036328
Validation loss: 2.449429504869746

Epoch: 6| Step: 1
Training loss: 1.641745048755971
Validation loss: 2.401765594956682

Epoch: 6| Step: 2
Training loss: 1.8809965248055527
Validation loss: 2.4663633329109795

Epoch: 6| Step: 3
Training loss: 2.533519433949242
Validation loss: 2.5075447921769016

Epoch: 6| Step: 4
Training loss: 2.254149637022815
Validation loss: 2.44683788741161

Epoch: 6| Step: 5
Training loss: 2.1930380337013635
Validation loss: 2.424154700024716

Epoch: 6| Step: 6
Training loss: 1.953644279113927
Validation loss: 2.428246916101921

Epoch: 6| Step: 7
Training loss: 2.2614162947795964
Validation loss: 2.48292366408366

Epoch: 6| Step: 8
Training loss: 1.841505656676728
Validation loss: 2.411538315291361

Epoch: 6| Step: 9
Training loss: 3.005597614394402
Validation loss: 2.460175300901374

Epoch: 6| Step: 10
Training loss: 2.494446021062763
Validation loss: 2.4718764811784224

Epoch: 6| Step: 11
Training loss: 1.7503453322690483
Validation loss: 2.4427028678421667

Epoch: 6| Step: 12
Training loss: 2.1333637573139064
Validation loss: 2.4660726858366973

Epoch: 6| Step: 13
Training loss: 2.8720276436073053
Validation loss: 2.4280315953084473

Epoch: 222| Step: 0
Training loss: 2.1460778057004637
Validation loss: 2.438988498527581

Epoch: 6| Step: 1
Training loss: 1.7934786335438377
Validation loss: 2.435642500183156

Epoch: 6| Step: 2
Training loss: 2.1545105704515017
Validation loss: 2.43542777429927

Epoch: 6| Step: 3
Training loss: 2.722857299562226
Validation loss: 2.4695091113714365

Epoch: 6| Step: 4
Training loss: 2.420482308899723
Validation loss: 2.42992336010882

Epoch: 6| Step: 5
Training loss: 2.3060359824517183
Validation loss: 2.467079441628421

Epoch: 6| Step: 6
Training loss: 2.008716186922506
Validation loss: 2.4216999574216187

Epoch: 6| Step: 7
Training loss: 1.739021743612155
Validation loss: 2.4483311285033857

Epoch: 6| Step: 8
Training loss: 2.444265025470845
Validation loss: 2.4500476520283123

Epoch: 6| Step: 9
Training loss: 2.359140043370079
Validation loss: 2.443395961300237

Epoch: 6| Step: 10
Training loss: 1.9145177805750622
Validation loss: 2.448391947864485

Epoch: 6| Step: 11
Training loss: 2.4227421346459406
Validation loss: 2.4888718777353307

Epoch: 6| Step: 12
Training loss: 2.226580060923073
Validation loss: 2.380000847338661

Epoch: 6| Step: 13
Training loss: 1.7770676618498464
Validation loss: 2.4768248641922357

Epoch: 223| Step: 0
Training loss: 2.093002071877159
Validation loss: 2.4315691888065434

Epoch: 6| Step: 1
Training loss: 2.8186295578762546
Validation loss: 2.463055632412354

Epoch: 6| Step: 2
Training loss: 1.9693979075173065
Validation loss: 2.397121102791971

Epoch: 6| Step: 3
Training loss: 1.7495731105567864
Validation loss: 2.4189464104707072

Epoch: 6| Step: 4
Training loss: 1.9833025099124932
Validation loss: 2.4304235339505507

Epoch: 6| Step: 5
Training loss: 1.7872874687131592
Validation loss: 2.4507245442504733

Epoch: 6| Step: 6
Training loss: 1.5452756994974313
Validation loss: 2.4048494008487293

Epoch: 6| Step: 7
Training loss: 2.5139665527243102
Validation loss: 2.490400745384648

Epoch: 6| Step: 8
Training loss: 2.561736016245849
Validation loss: 2.482654954605063

Epoch: 6| Step: 9
Training loss: 1.6385938878194373
Validation loss: 2.447020274723054

Epoch: 6| Step: 10
Training loss: 2.392012648418246
Validation loss: 2.414013073697269

Epoch: 6| Step: 11
Training loss: 2.4357467606053214
Validation loss: 2.4643797853735414

Epoch: 6| Step: 12
Training loss: 2.9172932814557497
Validation loss: 2.4194146135254027

Epoch: 6| Step: 13
Training loss: 2.0737566244561068
Validation loss: 2.43331978270595

Epoch: 224| Step: 0
Training loss: 1.5677963519391045
Validation loss: 2.4425156858423795

Epoch: 6| Step: 1
Training loss: 2.3500731558268644
Validation loss: 2.424472456230262

Epoch: 6| Step: 2
Training loss: 2.1561085751359226
Validation loss: 2.4645052485764594

Epoch: 6| Step: 3
Training loss: 2.681590480571775
Validation loss: 2.436237242656897

Epoch: 6| Step: 4
Training loss: 2.506953107044567
Validation loss: 2.4398328967176113

Epoch: 6| Step: 5
Training loss: 1.6953034994000706
Validation loss: 2.4184314997265295

Epoch: 6| Step: 6
Training loss: 2.344189005109188
Validation loss: 2.4579021975420936

Epoch: 6| Step: 7
Training loss: 1.9854857572507247
Validation loss: 2.496663783896904

Epoch: 6| Step: 8
Training loss: 2.8712887237156286
Validation loss: 2.474598246500324

Epoch: 6| Step: 9
Training loss: 2.188521337497955
Validation loss: 2.4301292414334377

Epoch: 6| Step: 10
Training loss: 2.523120210617997
Validation loss: 2.4931240296517663

Epoch: 6| Step: 11
Training loss: 1.7631818358825355
Validation loss: 2.476108797111846

Epoch: 6| Step: 12
Training loss: 1.9589021005591871
Validation loss: 2.482741106711707

Epoch: 6| Step: 13
Training loss: 2.2833484769815544
Validation loss: 2.45453196665121

Epoch: 225| Step: 0
Training loss: 2.459364324641052
Validation loss: 2.4413685543964876

Epoch: 6| Step: 1
Training loss: 2.0830603484276806
Validation loss: 2.457996660986277

Epoch: 6| Step: 2
Training loss: 1.9404825204338676
Validation loss: 2.506752968750465

Epoch: 6| Step: 3
Training loss: 2.0561991305566574
Validation loss: 2.446224598842385

Epoch: 6| Step: 4
Training loss: 2.0020181487153517
Validation loss: 2.4784772173980105

Epoch: 6| Step: 5
Training loss: 2.82164067407553
Validation loss: 2.3954837567222462

Epoch: 6| Step: 6
Training loss: 2.0865036556852683
Validation loss: 2.4864338739221945

Epoch: 6| Step: 7
Training loss: 1.8511337878464085
Validation loss: 2.4059316938392774

Epoch: 6| Step: 8
Training loss: 2.54194135171748
Validation loss: 2.5030419229510565

Epoch: 6| Step: 9
Training loss: 2.241937603465911
Validation loss: 2.4269122213433856

Epoch: 6| Step: 10
Training loss: 2.878725043589074
Validation loss: 2.421668471978836

Epoch: 6| Step: 11
Training loss: 1.713397343673063
Validation loss: 2.4592493087806497

Epoch: 6| Step: 12
Training loss: 1.6480191680756406
Validation loss: 2.4091714821068084

Epoch: 6| Step: 13
Training loss: 2.475498680969639
Validation loss: 2.446017716163555

Epoch: 226| Step: 0
Training loss: 1.829640339179248
Validation loss: 2.4755535747143007

Epoch: 6| Step: 1
Training loss: 2.3109410160184964
Validation loss: 2.4599155963974906

Epoch: 6| Step: 2
Training loss: 2.8720691503206592
Validation loss: 2.4327035583150733

Epoch: 6| Step: 3
Training loss: 2.0760310817001413
Validation loss: 2.4380869131210043

Epoch: 6| Step: 4
Training loss: 1.8039042436895039
Validation loss: 2.4068364213335625

Epoch: 6| Step: 5
Training loss: 1.717430579324767
Validation loss: 2.4173969852690442

Epoch: 6| Step: 6
Training loss: 1.868827642148344
Validation loss: 2.4337265491175817

Epoch: 6| Step: 7
Training loss: 2.1478169602772805
Validation loss: 2.4135496690820966

Epoch: 6| Step: 8
Training loss: 2.042383638987174
Validation loss: 2.4760315318352757

Epoch: 6| Step: 9
Training loss: 2.1874981471462576
Validation loss: 2.4570424184159476

Epoch: 6| Step: 10
Training loss: 2.2813743661920682
Validation loss: 2.4421870653692177

Epoch: 6| Step: 11
Training loss: 2.4447894527217775
Validation loss: 2.4537886325502907

Epoch: 6| Step: 12
Training loss: 2.4750413525141903
Validation loss: 2.4329309470323817

Epoch: 6| Step: 13
Training loss: 2.406051627565227
Validation loss: 2.4371632379378005

Epoch: 227| Step: 0
Training loss: 1.9765215481221146
Validation loss: 2.445133348785253

Epoch: 6| Step: 1
Training loss: 2.7877307779208587
Validation loss: 2.410204988495622

Epoch: 6| Step: 2
Training loss: 2.46358703399457
Validation loss: 2.4032335331832444

Epoch: 6| Step: 3
Training loss: 1.973526020737707
Validation loss: 2.41018719285243

Epoch: 6| Step: 4
Training loss: 2.1104135852827626
Validation loss: 2.4539523297490553

Epoch: 6| Step: 5
Training loss: 2.546829878518537
Validation loss: 2.455910636183809

Epoch: 6| Step: 6
Training loss: 2.3687897852472886
Validation loss: 2.448479723838349

Epoch: 6| Step: 7
Training loss: 2.524755269645029
Validation loss: 2.5060120229496903

Epoch: 6| Step: 8
Training loss: 2.183938533197459
Validation loss: 2.397470954286138

Epoch: 6| Step: 9
Training loss: 1.4560923478739627
Validation loss: 2.428056339060663

Epoch: 6| Step: 10
Training loss: 2.089517214924846
Validation loss: 2.4960169739525995

Epoch: 6| Step: 11
Training loss: 1.9039002616828848
Validation loss: 2.4102941907603257

Epoch: 6| Step: 12
Training loss: 2.5182871504495155
Validation loss: 2.411485998788379

Epoch: 6| Step: 13
Training loss: 1.918690159265261
Validation loss: 2.502141701683993

Epoch: 228| Step: 0
Training loss: 2.533772471497173
Validation loss: 2.4504355166775675

Epoch: 6| Step: 1
Training loss: 2.187649748989854
Validation loss: 2.4209577047871194

Epoch: 6| Step: 2
Training loss: 1.8802792297128246
Validation loss: 2.464237380173176

Epoch: 6| Step: 3
Training loss: 2.084921600185114
Validation loss: 2.475020262559746

Epoch: 6| Step: 4
Training loss: 2.1838959568379095
Validation loss: 2.4552466374601947

Epoch: 6| Step: 5
Training loss: 2.3288648824975176
Validation loss: 2.4591071824639976

Epoch: 6| Step: 6
Training loss: 2.1817407269167672
Validation loss: 2.4926783395661904

Epoch: 6| Step: 7
Training loss: 2.0306536459318534
Validation loss: 2.459642901649934

Epoch: 6| Step: 8
Training loss: 2.152380415090099
Validation loss: 2.4037243362715492

Epoch: 6| Step: 9
Training loss: 2.578269723240295
Validation loss: 2.410211849098203

Epoch: 6| Step: 10
Training loss: 2.973558567166311
Validation loss: 2.464764932334649

Epoch: 6| Step: 11
Training loss: 2.2690288361843343
Validation loss: 2.408220977353756

Epoch: 6| Step: 12
Training loss: 1.359462954427166
Validation loss: 2.459632159871904

Epoch: 6| Step: 13
Training loss: 1.4726864434746683
Validation loss: 2.467419856993633

Epoch: 229| Step: 0
Training loss: 1.9165873165567187
Validation loss: 2.497181300124701

Epoch: 6| Step: 1
Training loss: 2.0535679076739153
Validation loss: 2.4375143458278425

Epoch: 6| Step: 2
Training loss: 2.0127890100931123
Validation loss: 2.406989890638148

Epoch: 6| Step: 3
Training loss: 2.3276289853126984
Validation loss: 2.4498433682279765

Epoch: 6| Step: 4
Training loss: 1.7852301050179915
Validation loss: 2.469282408284373

Epoch: 6| Step: 5
Training loss: 2.3163671377652864
Validation loss: 2.4454004884607805

Epoch: 6| Step: 6
Training loss: 2.41970383321439
Validation loss: 2.3687159313817268

Epoch: 6| Step: 7
Training loss: 1.833063871637107
Validation loss: 2.4532712661970537

Epoch: 6| Step: 8
Training loss: 2.1052993394854544
Validation loss: 2.421085942844483

Epoch: 6| Step: 9
Training loss: 1.831743360076028
Validation loss: 2.4554083492403467

Epoch: 6| Step: 10
Training loss: 2.408059764842785
Validation loss: 2.480012741204994

Epoch: 6| Step: 11
Training loss: 2.6568859461036385
Validation loss: 2.4390253458957867

Epoch: 6| Step: 12
Training loss: 1.8817073380180371
Validation loss: 2.4240105318808043

Epoch: 6| Step: 13
Training loss: 3.0791137966078708
Validation loss: 2.4305001405960773

Epoch: 230| Step: 0
Training loss: 1.860754190764397
Validation loss: 2.398399013616543

Epoch: 6| Step: 1
Training loss: 2.636610331248984
Validation loss: 2.471457043310654

Epoch: 6| Step: 2
Training loss: 2.745260489355964
Validation loss: 2.4440410996112005

Epoch: 6| Step: 3
Training loss: 2.045903331960136
Validation loss: 2.4796579821506817

Epoch: 6| Step: 4
Training loss: 2.080968531915549
Validation loss: 2.448272556327462

Epoch: 6| Step: 5
Training loss: 1.9660766252543311
Validation loss: 2.374674163210852

Epoch: 6| Step: 6
Training loss: 2.8696439858508205
Validation loss: 2.436778246446729

Epoch: 6| Step: 7
Training loss: 1.7145178274416497
Validation loss: 2.414972124564955

Epoch: 6| Step: 8
Training loss: 1.7461202393299706
Validation loss: 2.463140122507511

Epoch: 6| Step: 9
Training loss: 2.1591302183670447
Validation loss: 2.4532833911704297

Epoch: 6| Step: 10
Training loss: 1.8266942873256447
Validation loss: 2.486319179203207

Epoch: 6| Step: 11
Training loss: 2.1249840679693426
Validation loss: 2.454500508602118

Epoch: 6| Step: 12
Training loss: 2.092779589424579
Validation loss: 2.428802261440897

Epoch: 6| Step: 13
Training loss: 2.7188091052415997
Validation loss: 2.432666974550667

Epoch: 231| Step: 0
Training loss: 2.271607176724056
Validation loss: 2.4615452742684454

Epoch: 6| Step: 1
Training loss: 1.8028249666176719
Validation loss: 2.4393148688893485

Epoch: 6| Step: 2
Training loss: 1.6846192814440555
Validation loss: 2.4340620835776754

Epoch: 6| Step: 3
Training loss: 2.184229231133253
Validation loss: 2.3932184303052955

Epoch: 6| Step: 4
Training loss: 2.7332306129258575
Validation loss: 2.444584832288371

Epoch: 6| Step: 5
Training loss: 1.8061051518528928
Validation loss: 2.4668089521982477

Epoch: 6| Step: 6
Training loss: 1.7880800706484856
Validation loss: 2.413603666869163

Epoch: 6| Step: 7
Training loss: 2.3371013689039497
Validation loss: 2.397943672802208

Epoch: 6| Step: 8
Training loss: 2.11844476622334
Validation loss: 2.4599109681335007

Epoch: 6| Step: 9
Training loss: 2.2030439429556337
Validation loss: 2.414496933649261

Epoch: 6| Step: 10
Training loss: 2.6533555360884287
Validation loss: 2.4444711818270686

Epoch: 6| Step: 11
Training loss: 2.0393973473865614
Validation loss: 2.3872012036813364

Epoch: 6| Step: 12
Training loss: 2.0738330777055785
Validation loss: 2.38545594104921

Epoch: 6| Step: 13
Training loss: 2.2949452500471796
Validation loss: 2.3920272670497313

Epoch: 232| Step: 0
Training loss: 2.883288832598548
Validation loss: 2.4222801168704646

Epoch: 6| Step: 1
Training loss: 2.1674937234719467
Validation loss: 2.4606899269113867

Epoch: 6| Step: 2
Training loss: 1.8598860350939779
Validation loss: 2.403744156023182

Epoch: 6| Step: 3
Training loss: 1.76923076444645
Validation loss: 2.4560263125578787

Epoch: 6| Step: 4
Training loss: 1.5991494212662727
Validation loss: 2.4887152200155347

Epoch: 6| Step: 5
Training loss: 2.3116356548859383
Validation loss: 2.4349533726161128

Epoch: 6| Step: 6
Training loss: 1.6686564329968694
Validation loss: 2.4215882612229125

Epoch: 6| Step: 7
Training loss: 2.6362251780513914
Validation loss: 2.4745008539349413

Epoch: 6| Step: 8
Training loss: 2.27635461909336
Validation loss: 2.4285907330749232

Epoch: 6| Step: 9
Training loss: 2.144023786583657
Validation loss: 2.4477884489860178

Epoch: 6| Step: 10
Training loss: 2.291230616843924
Validation loss: 2.455571268730773

Epoch: 6| Step: 11
Training loss: 1.5855824491199293
Validation loss: 2.45161585947273

Epoch: 6| Step: 12
Training loss: 2.4016536062478027
Validation loss: 2.421971477236915

Epoch: 6| Step: 13
Training loss: 2.5055950498134973
Validation loss: 2.454808018571645

Epoch: 233| Step: 0
Training loss: 2.4146441404000023
Validation loss: 2.4207485128906314

Epoch: 6| Step: 1
Training loss: 2.184305747139091
Validation loss: 2.444961476003514

Epoch: 6| Step: 2
Training loss: 2.0422319940041054
Validation loss: 2.431322458070432

Epoch: 6| Step: 3
Training loss: 2.7456588292181574
Validation loss: 2.3943590255047114

Epoch: 6| Step: 4
Training loss: 1.9604224026224812
Validation loss: 2.494428235967805

Epoch: 6| Step: 5
Training loss: 1.6716075932925674
Validation loss: 2.4061360294245957

Epoch: 6| Step: 6
Training loss: 1.843991086036337
Validation loss: 2.4365734056665844

Epoch: 6| Step: 7
Training loss: 2.495764004652472
Validation loss: 2.440200197737411

Epoch: 6| Step: 8
Training loss: 1.7525945231459088
Validation loss: 2.5409150857349574

Epoch: 6| Step: 9
Training loss: 2.0475793456561853
Validation loss: 2.423157794760548

Epoch: 6| Step: 10
Training loss: 1.7787965977798568
Validation loss: 2.487779824326439

Epoch: 6| Step: 11
Training loss: 2.2151542863005003
Validation loss: 2.4725427534609894

Epoch: 6| Step: 12
Training loss: 2.5987504303873576
Validation loss: 2.4907506168856854

Epoch: 6| Step: 13
Training loss: 2.0086194505979864
Validation loss: 2.487307994467398

Epoch: 234| Step: 0
Training loss: 3.100140070058044
Validation loss: 2.4306772484226395

Epoch: 6| Step: 1
Training loss: 2.1180336025191258
Validation loss: 2.4034421061158557

Epoch: 6| Step: 2
Training loss: 2.209515764859154
Validation loss: 2.4557606917951667

Epoch: 6| Step: 3
Training loss: 1.9697391507716242
Validation loss: 2.4306544794049554

Epoch: 6| Step: 4
Training loss: 2.081558030620061
Validation loss: 2.461257110118629

Epoch: 6| Step: 5
Training loss: 2.4168033780420024
Validation loss: 2.4353372635769386

Epoch: 6| Step: 6
Training loss: 1.839619681610177
Validation loss: 2.4423017133003553

Epoch: 6| Step: 7
Training loss: 2.0580046243272734
Validation loss: 2.5136570051232296

Epoch: 6| Step: 8
Training loss: 2.0125329009026354
Validation loss: 2.4943673730875866

Epoch: 6| Step: 9
Training loss: 1.9033555741466521
Validation loss: 2.4901545459644314

Epoch: 6| Step: 10
Training loss: 1.861515063798414
Validation loss: 2.5353406886469454

Epoch: 6| Step: 11
Training loss: 1.8026403400532116
Validation loss: 2.427363054286735

Epoch: 6| Step: 12
Training loss: 2.3395681075577013
Validation loss: 2.418972712867118

Epoch: 6| Step: 13
Training loss: 1.8976683137650776
Validation loss: 2.458085468582464

Epoch: 235| Step: 0
Training loss: 1.4542604337845544
Validation loss: 2.4851957515736602

Epoch: 6| Step: 1
Training loss: 2.2738520188641624
Validation loss: 2.421123498925918

Epoch: 6| Step: 2
Training loss: 2.1046599637660792
Validation loss: 2.511674607595728

Epoch: 6| Step: 3
Training loss: 2.1896388904940833
Validation loss: 2.4384681119044718

Epoch: 6| Step: 4
Training loss: 1.918817771186943
Validation loss: 2.4312774211677284

Epoch: 6| Step: 5
Training loss: 1.5469489031775931
Validation loss: 2.4736621524390596

Epoch: 6| Step: 6
Training loss: 2.5141628589122926
Validation loss: 2.486353987822759

Epoch: 6| Step: 7
Training loss: 3.056135609988239
Validation loss: 2.4439073189555587

Epoch: 6| Step: 8
Training loss: 1.9367873203930845
Validation loss: 2.3887902471818414

Epoch: 6| Step: 9
Training loss: 2.2585412139746683
Validation loss: 2.423386781595672

Epoch: 6| Step: 10
Training loss: 2.0916032176127426
Validation loss: 2.4134210709472024

Epoch: 6| Step: 11
Training loss: 2.093093883138449
Validation loss: 2.4295344430304926

Epoch: 6| Step: 12
Training loss: 1.7416451469564258
Validation loss: 2.4362904208642266

Epoch: 6| Step: 13
Training loss: 2.5614143490877073
Validation loss: 2.4197352372143044

Epoch: 236| Step: 0
Training loss: 2.3812486863821016
Validation loss: 2.4150047280731046

Epoch: 6| Step: 1
Training loss: 2.118411227799248
Validation loss: 2.464424447754118

Epoch: 6| Step: 2
Training loss: 1.5962891640634527
Validation loss: 2.481602832044793

Epoch: 6| Step: 3
Training loss: 1.838775000386039
Validation loss: 2.468369348291826

Epoch: 6| Step: 4
Training loss: 2.0246670201945736
Validation loss: 2.467908587878393

Epoch: 6| Step: 5
Training loss: 1.685085547338581
Validation loss: 2.4286870902596025

Epoch: 6| Step: 6
Training loss: 2.4736079453077933
Validation loss: 2.3770317849057476

Epoch: 6| Step: 7
Training loss: 2.3686705120508895
Validation loss: 2.4432066823993237

Epoch: 6| Step: 8
Training loss: 2.2019883057424963
Validation loss: 2.422625537794614

Epoch: 6| Step: 9
Training loss: 2.1169471745087654
Validation loss: 2.496584821740938

Epoch: 6| Step: 10
Training loss: 2.5669396251181027
Validation loss: 2.397394810156346

Epoch: 6| Step: 11
Training loss: 2.3000132601811836
Validation loss: 2.427810498398956

Epoch: 6| Step: 12
Training loss: 2.2528193082586188
Validation loss: 2.5012840890469623

Epoch: 6| Step: 13
Training loss: 1.7925121249503089
Validation loss: 2.4335572775891054

Epoch: 237| Step: 0
Training loss: 1.7306508814459682
Validation loss: 2.4028899213486925

Epoch: 6| Step: 1
Training loss: 1.6854721176525451
Validation loss: 2.380348015314957

Epoch: 6| Step: 2
Training loss: 2.8004231031090643
Validation loss: 2.4364553615759563

Epoch: 6| Step: 3
Training loss: 1.7952100918797267
Validation loss: 2.4006304015094817

Epoch: 6| Step: 4
Training loss: 2.3773294368818227
Validation loss: 2.4460826212662

Epoch: 6| Step: 5
Training loss: 1.5771009691966509
Validation loss: 2.436240162774189

Epoch: 6| Step: 6
Training loss: 2.3873613806622243
Validation loss: 2.480114906891116

Epoch: 6| Step: 7
Training loss: 2.0283511090133155
Validation loss: 2.536192340543834

Epoch: 6| Step: 8
Training loss: 2.3763577445143502
Validation loss: 2.423189238634791

Epoch: 6| Step: 9
Training loss: 2.5050859216508954
Validation loss: 2.4031391776149795

Epoch: 6| Step: 10
Training loss: 2.3669150419149627
Validation loss: 2.4921012609158115

Epoch: 6| Step: 11
Training loss: 1.6337773880709614
Validation loss: 2.4840937319978287

Epoch: 6| Step: 12
Training loss: 2.203522125597019
Validation loss: 2.4593587540507436

Epoch: 6| Step: 13
Training loss: 1.3778597396950982
Validation loss: 2.427619751925404

Epoch: 238| Step: 0
Training loss: 1.8721804081517128
Validation loss: 2.4689279266037603

Epoch: 6| Step: 1
Training loss: 2.5815689665710266
Validation loss: 2.4189805098437676

Epoch: 6| Step: 2
Training loss: 2.4691501727686784
Validation loss: 2.438340574584654

Epoch: 6| Step: 3
Training loss: 2.0729486919849345
Validation loss: 2.4453137255673467

Epoch: 6| Step: 4
Training loss: 2.0902984409712073
Validation loss: 2.4819772637044855

Epoch: 6| Step: 5
Training loss: 2.143700277124419
Validation loss: 2.4348694663961457

Epoch: 6| Step: 6
Training loss: 2.1942885647979455
Validation loss: 2.4448686176084156

Epoch: 6| Step: 7
Training loss: 2.280769611100801
Validation loss: 2.461911809082239

Epoch: 6| Step: 8
Training loss: 1.7036222379475787
Validation loss: 2.48832259605266

Epoch: 6| Step: 9
Training loss: 1.8910118526932524
Validation loss: 2.4747174075256906

Epoch: 6| Step: 10
Training loss: 1.555748045834125
Validation loss: 2.4679188729242676

Epoch: 6| Step: 11
Training loss: 1.54819178166536
Validation loss: 2.412691509626727

Epoch: 6| Step: 12
Training loss: 2.087828504103924
Validation loss: 2.4507030316324236

Epoch: 6| Step: 13
Training loss: 3.5510948051101607
Validation loss: 2.4128960419900727

Epoch: 239| Step: 0
Training loss: 2.2887829294132795
Validation loss: 2.4719133838233907

Epoch: 6| Step: 1
Training loss: 2.2527842778578417
Validation loss: 2.516575847538937

Epoch: 6| Step: 2
Training loss: 2.7945207458588754
Validation loss: 2.4546175297948603

Epoch: 6| Step: 3
Training loss: 1.898675848672574
Validation loss: 2.493535501759913

Epoch: 6| Step: 4
Training loss: 2.4960811417668656
Validation loss: 2.391827319509478

Epoch: 6| Step: 5
Training loss: 1.9658904122343746
Validation loss: 2.467411760080497

Epoch: 6| Step: 6
Training loss: 2.632101172279615
Validation loss: 2.46751604541623

Epoch: 6| Step: 7
Training loss: 1.7910627485792183
Validation loss: 2.4199025113951276

Epoch: 6| Step: 8
Training loss: 1.6552195672465628
Validation loss: 2.472226633274054

Epoch: 6| Step: 9
Training loss: 1.6907455880811053
Validation loss: 2.4594731195762143

Epoch: 6| Step: 10
Training loss: 2.0748031568804364
Validation loss: 2.4478397675852177

Epoch: 6| Step: 11
Training loss: 1.8062578775306701
Validation loss: 2.4833013931662746

Epoch: 6| Step: 12
Training loss: 1.8320529180030263
Validation loss: 2.4689674987769323

Epoch: 6| Step: 13
Training loss: 1.8038050488103667
Validation loss: 2.474716232777753

Epoch: 240| Step: 0
Training loss: 2.0785078112006037
Validation loss: 2.468044455892075

Epoch: 6| Step: 1
Training loss: 1.1107847363563095
Validation loss: 2.434913143938506

Epoch: 6| Step: 2
Training loss: 1.9607818055370594
Validation loss: 2.414655357821968

Epoch: 6| Step: 3
Training loss: 2.3295897925782065
Validation loss: 2.455663467687343

Epoch: 6| Step: 4
Training loss: 1.9451453815052078
Validation loss: 2.457193880871047

Epoch: 6| Step: 5
Training loss: 2.463597002006103
Validation loss: 2.4440827944280543

Epoch: 6| Step: 6
Training loss: 2.206051877557418
Validation loss: 2.4723555784432087

Epoch: 6| Step: 7
Training loss: 2.049935186338455
Validation loss: 2.4500386783978056

Epoch: 6| Step: 8
Training loss: 1.7430017048427453
Validation loss: 2.4580156447080928

Epoch: 6| Step: 9
Training loss: 2.9684660123216156
Validation loss: 2.455219967689528

Epoch: 6| Step: 10
Training loss: 2.3050015510338717
Validation loss: 2.4884264944112506

Epoch: 6| Step: 11
Training loss: 1.7557607926476018
Validation loss: 2.400338440407458

Epoch: 6| Step: 12
Training loss: 2.124392478716089
Validation loss: 2.4709999000591227

Epoch: 6| Step: 13
Training loss: 2.1687565652269707
Validation loss: 2.4612837582191824

Epoch: 241| Step: 0
Training loss: 2.4535414226884167
Validation loss: 2.4186916636710736

Epoch: 6| Step: 1
Training loss: 2.620085520913746
Validation loss: 2.4630329045801207

Epoch: 6| Step: 2
Training loss: 2.4020765698732793
Validation loss: 2.4190113371709576

Epoch: 6| Step: 3
Training loss: 1.6745682174077583
Validation loss: 2.4116218001374823

Epoch: 6| Step: 4
Training loss: 2.370542760740516
Validation loss: 2.4349263194853195

Epoch: 6| Step: 5
Training loss: 1.517148932959742
Validation loss: 2.4111093730062394

Epoch: 6| Step: 6
Training loss: 2.063778336605955
Validation loss: 2.4734390368339034

Epoch: 6| Step: 7
Training loss: 1.7361437052740043
Validation loss: 2.4111452418782693

Epoch: 6| Step: 8
Training loss: 1.9715032550534324
Validation loss: 2.4894149149394313

Epoch: 6| Step: 9
Training loss: 1.8756623687631626
Validation loss: 2.3966448878439244

Epoch: 6| Step: 10
Training loss: 2.045331999450474
Validation loss: 2.432853174547612

Epoch: 6| Step: 11
Training loss: 2.3223268133496906
Validation loss: 2.4553253419795995

Epoch: 6| Step: 12
Training loss: 1.9216190570890024
Validation loss: 2.498335401041946

Epoch: 6| Step: 13
Training loss: 1.8342999886507816
Validation loss: 2.4717141805771243

Epoch: 242| Step: 0
Training loss: 2.368738654519643
Validation loss: 2.4052269503667283

Epoch: 6| Step: 1
Training loss: 1.9685598614625923
Validation loss: 2.4088609239815497

Epoch: 6| Step: 2
Training loss: 1.801314070314594
Validation loss: 2.4608464284238902

Epoch: 6| Step: 3
Training loss: 2.1993403833065646
Validation loss: 2.384639369566671

Epoch: 6| Step: 4
Training loss: 2.1704727146671865
Validation loss: 2.376792799913938

Epoch: 6| Step: 5
Training loss: 2.0903418972225416
Validation loss: 2.3995392761142607

Epoch: 6| Step: 6
Training loss: 2.229106106039464
Validation loss: 2.4684347193085774

Epoch: 6| Step: 7
Training loss: 2.5408764741695977
Validation loss: 2.4739630019829852

Epoch: 6| Step: 8
Training loss: 2.0256742979534397
Validation loss: 2.4583837209563772

Epoch: 6| Step: 9
Training loss: 2.1832728278048767
Validation loss: 2.4681987445543365

Epoch: 6| Step: 10
Training loss: 1.8005371590307198
Validation loss: 2.4803960276459427

Epoch: 6| Step: 11
Training loss: 2.065153553497639
Validation loss: 2.497965228682831

Epoch: 6| Step: 12
Training loss: 1.8376340129536035
Validation loss: 2.4228025990771838

Epoch: 6| Step: 13
Training loss: 2.1554482116495
Validation loss: 2.4536110123723995

Epoch: 243| Step: 0
Training loss: 2.121972339403107
Validation loss: 2.448491795059418

Epoch: 6| Step: 1
Training loss: 2.2278751185019634
Validation loss: 2.441514088470168

Epoch: 6| Step: 2
Training loss: 2.219408931402967
Validation loss: 2.392468281162963

Epoch: 6| Step: 3
Training loss: 1.7936728430977613
Validation loss: 2.4576104016931524

Epoch: 6| Step: 4
Training loss: 1.9163255664435583
Validation loss: 2.4854530466382987

Epoch: 6| Step: 5
Training loss: 1.7613799790773654
Validation loss: 2.394761983871302

Epoch: 6| Step: 6
Training loss: 2.1080170958403017
Validation loss: 2.4800757508529823

Epoch: 6| Step: 7
Training loss: 2.1748613642213526
Validation loss: 2.4523352867247286

Epoch: 6| Step: 8
Training loss: 1.5574488820953212
Validation loss: 2.4268471616440306

Epoch: 6| Step: 9
Training loss: 1.5638398338756547
Validation loss: 2.5003035125254476

Epoch: 6| Step: 10
Training loss: 2.3786389430908037
Validation loss: 2.4794944704335564

Epoch: 6| Step: 11
Training loss: 2.291616635787915
Validation loss: 2.466868328211612

Epoch: 6| Step: 12
Training loss: 2.7800226825365075
Validation loss: 2.434294789054203

Epoch: 6| Step: 13
Training loss: 2.4303151390215376
Validation loss: 2.5012580382702274

Epoch: 244| Step: 0
Training loss: 2.253071913179753
Validation loss: 2.392863424107359

Epoch: 6| Step: 1
Training loss: 2.209254186799167
Validation loss: 2.405572662460677

Epoch: 6| Step: 2
Training loss: 2.265999388180387
Validation loss: 2.395592270146663

Epoch: 6| Step: 3
Training loss: 1.658103912944121
Validation loss: 2.4148122895642077

Epoch: 6| Step: 4
Training loss: 2.3999269315404996
Validation loss: 2.4235078142997537

Epoch: 6| Step: 5
Training loss: 2.7220765732274903
Validation loss: 2.4816083785291108

Epoch: 6| Step: 6
Training loss: 2.1478192913825547
Validation loss: 2.4885348254243738

Epoch: 6| Step: 7
Training loss: 1.537724411876954
Validation loss: 2.4571948537671777

Epoch: 6| Step: 8
Training loss: 2.635458683287119
Validation loss: 2.4579262943101967

Epoch: 6| Step: 9
Training loss: 2.1599474179967304
Validation loss: 2.440410243951271

Epoch: 6| Step: 10
Training loss: 1.769132725046704
Validation loss: 2.4957990451686896

Epoch: 6| Step: 11
Training loss: 2.0284285684053067
Validation loss: 2.4660269685024465

Epoch: 6| Step: 12
Training loss: 1.791279780585544
Validation loss: 2.439962287199859

Epoch: 6| Step: 13
Training loss: 1.5851003758268853
Validation loss: 2.4560640780681346

Epoch: 245| Step: 0
Training loss: 2.169622227179906
Validation loss: 2.4915750106886136

Epoch: 6| Step: 1
Training loss: 2.6853646955252897
Validation loss: 2.4221247453958785

Epoch: 6| Step: 2
Training loss: 2.3054808204926944
Validation loss: 2.4911578181871543

Epoch: 6| Step: 3
Training loss: 2.3583858007878327
Validation loss: 2.4160518847284167

Epoch: 6| Step: 4
Training loss: 2.197205836860186
Validation loss: 2.3977981650002236

Epoch: 6| Step: 5
Training loss: 2.053428002792547
Validation loss: 2.4539472248238927

Epoch: 6| Step: 6
Training loss: 1.6890188375611666
Validation loss: 2.4669080690404006

Epoch: 6| Step: 7
Training loss: 1.6479654223740419
Validation loss: 2.4230452235939732

Epoch: 6| Step: 8
Training loss: 1.8510822687399149
Validation loss: 2.454367260456705

Epoch: 6| Step: 9
Training loss: 1.7216054605028706
Validation loss: 2.3607928905107896

Epoch: 6| Step: 10
Training loss: 1.6490718109290172
Validation loss: 2.4238415279158168

Epoch: 6| Step: 11
Training loss: 2.4624014239259386
Validation loss: 2.485154166782651

Epoch: 6| Step: 12
Training loss: 2.169155696333604
Validation loss: 2.45479322657362

Epoch: 6| Step: 13
Training loss: 1.6739637215350949
Validation loss: 2.461593608700897

Epoch: 246| Step: 0
Training loss: 2.1632971115880895
Validation loss: 2.4865695122256084

Epoch: 6| Step: 1
Training loss: 2.1861295494369464
Validation loss: 2.5233438273090134

Epoch: 6| Step: 2
Training loss: 2.0877164762717735
Validation loss: 2.459174322235355

Epoch: 6| Step: 3
Training loss: 2.1240083961392706
Validation loss: 2.4897940192085173

Epoch: 6| Step: 4
Training loss: 1.9272517225223413
Validation loss: 2.46921303600615

Epoch: 6| Step: 5
Training loss: 2.1501479120164233
Validation loss: 2.413351006479138

Epoch: 6| Step: 6
Training loss: 1.8787675516878468
Validation loss: 2.456718268512116

Epoch: 6| Step: 7
Training loss: 2.3059259740125513
Validation loss: 2.454277295171261

Epoch: 6| Step: 8
Training loss: 2.1658751680395327
Validation loss: 2.4843352950484636

Epoch: 6| Step: 9
Training loss: 2.229756309981944
Validation loss: 2.3821546152372823

Epoch: 6| Step: 10
Training loss: 2.6759557068470556
Validation loss: 2.433193623382015

Epoch: 6| Step: 11
Training loss: 1.6211224289161235
Validation loss: 2.463616523749202

Epoch: 6| Step: 12
Training loss: 2.0502510475329982
Validation loss: 2.4481367963067884

Epoch: 6| Step: 13
Training loss: 1.6557986526172297
Validation loss: 2.41620876131092

Epoch: 247| Step: 0
Training loss: 1.6206769660241656
Validation loss: 2.4589137524833533

Epoch: 6| Step: 1
Training loss: 1.8877384439386722
Validation loss: 2.475976297684584

Epoch: 6| Step: 2
Training loss: 1.684043664846388
Validation loss: 2.459044629061294

Epoch: 6| Step: 3
Training loss: 1.7173116040355707
Validation loss: 2.469700596140567

Epoch: 6| Step: 4
Training loss: 2.2756088741561955
Validation loss: 2.450109897314342

Epoch: 6| Step: 5
Training loss: 2.522217068641241
Validation loss: 2.468654671746108

Epoch: 6| Step: 6
Training loss: 2.186227482831888
Validation loss: 2.4068695408645624

Epoch: 6| Step: 7
Training loss: 2.0143239161647757
Validation loss: 2.4148099582204514

Epoch: 6| Step: 8
Training loss: 2.581151307369098
Validation loss: 2.4714269967167843

Epoch: 6| Step: 9
Training loss: 2.3150286896412977
Validation loss: 2.4609627212765948

Epoch: 6| Step: 10
Training loss: 1.8804710042676105
Validation loss: 2.511900392402008

Epoch: 6| Step: 11
Training loss: 1.5032634996461154
Validation loss: 2.4809625486949938

Epoch: 6| Step: 12
Training loss: 2.2993526459934777
Validation loss: 2.441106992957905

Epoch: 6| Step: 13
Training loss: 1.8763841606223
Validation loss: 2.424315481492754

Epoch: 248| Step: 0
Training loss: 2.0044293232173795
Validation loss: 2.4639032669081944

Epoch: 6| Step: 1
Training loss: 1.7304165317759779
Validation loss: 2.446862066948213

Epoch: 6| Step: 2
Training loss: 1.8236962168386612
Validation loss: 2.471166294038053

Epoch: 6| Step: 3
Training loss: 1.7925466402123058
Validation loss: 2.455781959675494

Epoch: 6| Step: 4
Training loss: 1.8166821998258762
Validation loss: 2.4509273372918297

Epoch: 6| Step: 5
Training loss: 2.374760665880847
Validation loss: 2.434092411305432

Epoch: 6| Step: 6
Training loss: 2.2525103657914753
Validation loss: 2.5032659271205757

Epoch: 6| Step: 7
Training loss: 1.5873038884176498
Validation loss: 2.441257011987757

Epoch: 6| Step: 8
Training loss: 2.183009415784897
Validation loss: 2.4461015481032256

Epoch: 6| Step: 9
Training loss: 2.7636055335180085
Validation loss: 2.4140524978980054

Epoch: 6| Step: 10
Training loss: 1.4376000908545379
Validation loss: 2.428738301582078

Epoch: 6| Step: 11
Training loss: 2.2814686291586304
Validation loss: 2.4743472131202506

Epoch: 6| Step: 12
Training loss: 2.149891753022262
Validation loss: 2.463902072437534

Epoch: 6| Step: 13
Training loss: 2.3716861292812745
Validation loss: 2.4304064000465764

Epoch: 249| Step: 0
Training loss: 1.878983969875332
Validation loss: 2.4316309561390796

Epoch: 6| Step: 1
Training loss: 1.585646579161046
Validation loss: 2.438268744840065

Epoch: 6| Step: 2
Training loss: 1.9780807996394747
Validation loss: 2.3825979355732483

Epoch: 6| Step: 3
Training loss: 1.5739673196000434
Validation loss: 2.4119820462081107

Epoch: 6| Step: 4
Training loss: 2.385190783693304
Validation loss: 2.4162077788081873

Epoch: 6| Step: 5
Training loss: 2.209206918152837
Validation loss: 2.4450005684189335

Epoch: 6| Step: 6
Training loss: 2.2736636963624357
Validation loss: 2.4771927385889243

Epoch: 6| Step: 7
Training loss: 1.5642256553527203
Validation loss: 2.4385535469387274

Epoch: 6| Step: 8
Training loss: 2.2684991955384715
Validation loss: 2.4597819245420522

Epoch: 6| Step: 9
Training loss: 1.962364316003778
Validation loss: 2.4946177185594016

Epoch: 6| Step: 10
Training loss: 2.205868791276719
Validation loss: 2.4839621477074507

Epoch: 6| Step: 11
Training loss: 2.2237970679342633
Validation loss: 2.395875725141502

Epoch: 6| Step: 12
Training loss: 2.321297176541088
Validation loss: 2.4630153121197487

Epoch: 6| Step: 13
Training loss: 2.0751973805136754
Validation loss: 2.4502069944174845

Epoch: 250| Step: 0
Training loss: 2.0311521066404796
Validation loss: 2.4217131159330307

Epoch: 6| Step: 1
Training loss: 1.6597725458465455
Validation loss: 2.454977371406931

Epoch: 6| Step: 2
Training loss: 1.9285595643723088
Validation loss: 2.477006852635117

Epoch: 6| Step: 3
Training loss: 2.01420460414972
Validation loss: 2.4379734455618087

Epoch: 6| Step: 4
Training loss: 1.9572181231731036
Validation loss: 2.4579859980601215

Epoch: 6| Step: 5
Training loss: 2.5658614278529073
Validation loss: 2.5020700060311962

Epoch: 6| Step: 6
Training loss: 1.8759058353688163
Validation loss: 2.44557008418953

Epoch: 6| Step: 7
Training loss: 2.7987984804126147
Validation loss: 2.4539399714555

Epoch: 6| Step: 8
Training loss: 1.971687184622324
Validation loss: 2.3658846379293026

Epoch: 6| Step: 9
Training loss: 2.6535097236404823
Validation loss: 2.4685708398012247

Epoch: 6| Step: 10
Training loss: 1.5475736639334146
Validation loss: 2.467766362937365

Epoch: 6| Step: 11
Training loss: 1.697143550297429
Validation loss: 2.4040893124951745

Epoch: 6| Step: 12
Training loss: 1.9307149398961472
Validation loss: 2.3944331612433865

Epoch: 6| Step: 13
Training loss: 1.609801226719538
Validation loss: 2.482297313745849

Epoch: 251| Step: 0
Training loss: 2.004440147261843
Validation loss: 2.4492568219672743

Epoch: 6| Step: 1
Training loss: 1.7467116386991557
Validation loss: 2.449628697223649

Epoch: 6| Step: 2
Training loss: 2.566691250703993
Validation loss: 2.4538848162161075

Epoch: 6| Step: 3
Training loss: 2.2769735306921457
Validation loss: 2.4088904994274367

Epoch: 6| Step: 4
Training loss: 2.5380100357783113
Validation loss: 2.441121566483362

Epoch: 6| Step: 5
Training loss: 1.7807656014318791
Validation loss: 2.48506734834545

Epoch: 6| Step: 6
Training loss: 1.9009742899063653
Validation loss: 2.472319010070899

Epoch: 6| Step: 7
Training loss: 1.852340470419321
Validation loss: 2.4162455857769762

Epoch: 6| Step: 8
Training loss: 1.8891506909655618
Validation loss: 2.432525812864556

Epoch: 6| Step: 9
Training loss: 1.869883741344964
Validation loss: 2.4198226420383424

Epoch: 6| Step: 10
Training loss: 2.2880986498659874
Validation loss: 2.3682578803574446

Epoch: 6| Step: 11
Training loss: 1.6530706010892786
Validation loss: 2.4687389894309772

Epoch: 6| Step: 12
Training loss: 1.7832671673107607
Validation loss: 2.475678931941792

Epoch: 6| Step: 13
Training loss: 2.2519329033743545
Validation loss: 2.4568734207899743

Epoch: 252| Step: 0
Training loss: 1.5296953834276
Validation loss: 2.5022543085258144

Epoch: 6| Step: 1
Training loss: 2.009566791215085
Validation loss: 2.526823090963153

Epoch: 6| Step: 2
Training loss: 1.788074337115907
Validation loss: 2.4501544478460233

Epoch: 6| Step: 3
Training loss: 2.5580252678333775
Validation loss: 2.462710788180104

Epoch: 6| Step: 4
Training loss: 2.0662238287494277
Validation loss: 2.502449106048015

Epoch: 6| Step: 5
Training loss: 2.1260351016142462
Validation loss: 2.4663669439284357

Epoch: 6| Step: 6
Training loss: 1.9647518917627496
Validation loss: 2.459799722515243

Epoch: 6| Step: 7
Training loss: 2.632152531253541
Validation loss: 2.4643309807573646

Epoch: 6| Step: 8
Training loss: 1.7539086288741872
Validation loss: 2.4351321136629047

Epoch: 6| Step: 9
Training loss: 1.9462629087751357
Validation loss: 2.410712708616308

Epoch: 6| Step: 10
Training loss: 1.3809816988837968
Validation loss: 2.4866255874092165

Epoch: 6| Step: 11
Training loss: 1.603607435304642
Validation loss: 2.4688118516311333

Epoch: 6| Step: 12
Training loss: 3.1277264717491007
Validation loss: 2.441392407974873

Epoch: 6| Step: 13
Training loss: 1.5893685945358538
Validation loss: 2.448504971877347

Epoch: 253| Step: 0
Training loss: 1.9199175907370498
Validation loss: 2.364544304959346

Epoch: 6| Step: 1
Training loss: 2.6863133671787716
Validation loss: 2.4730699344081066

Epoch: 6| Step: 2
Training loss: 1.7885452922176286
Validation loss: 2.4629771707511723

Epoch: 6| Step: 3
Training loss: 1.9775812591948656
Validation loss: 2.43323519010547

Epoch: 6| Step: 4
Training loss: 2.358624875904775
Validation loss: 2.481101799797897

Epoch: 6| Step: 5
Training loss: 2.1005686852789904
Validation loss: 2.473493705775648

Epoch: 6| Step: 6
Training loss: 1.8018200705918779
Validation loss: 2.411811595609144

Epoch: 6| Step: 7
Training loss: 1.6849234655866847
Validation loss: 2.398479005834515

Epoch: 6| Step: 8
Training loss: 1.7988924725317306
Validation loss: 2.448722686410053

Epoch: 6| Step: 9
Training loss: 2.0518640184762202
Validation loss: 2.4372517364929536

Epoch: 6| Step: 10
Training loss: 1.8149303716119356
Validation loss: 2.429661740929914

Epoch: 6| Step: 11
Training loss: 2.167407153823844
Validation loss: 2.4352991387474887

Epoch: 6| Step: 12
Training loss: 2.4647893884531293
Validation loss: 2.4624172206982338

Epoch: 6| Step: 13
Training loss: 2.144655651382429
Validation loss: 2.4348642440746358

Epoch: 254| Step: 0
Training loss: 1.9943874404409243
Validation loss: 2.4168790305638224

Epoch: 6| Step: 1
Training loss: 2.433449338299006
Validation loss: 2.384853999718836

Epoch: 6| Step: 2
Training loss: 2.107001544656717
Validation loss: 2.4140377784793556

Epoch: 6| Step: 3
Training loss: 1.8766166075720383
Validation loss: 2.4397383205376943

Epoch: 6| Step: 4
Training loss: 1.9046775711213857
Validation loss: 2.4378085439399393

Epoch: 6| Step: 5
Training loss: 1.5104468068590526
Validation loss: 2.4036493645443455

Epoch: 6| Step: 6
Training loss: 1.897219671517937
Validation loss: 2.3651063637046548

Epoch: 6| Step: 7
Training loss: 1.8617594200235068
Validation loss: 2.4460745742505328

Epoch: 6| Step: 8
Training loss: 2.0117768214464253
Validation loss: 2.4456701949156447

Epoch: 6| Step: 9
Training loss: 1.7342399338376064
Validation loss: 2.3972814109896983

Epoch: 6| Step: 10
Training loss: 2.5781845548282387
Validation loss: 2.47129306159883

Epoch: 6| Step: 11
Training loss: 2.4481639872395697
Validation loss: 2.4871216363638973

Epoch: 6| Step: 12
Training loss: 2.172762024138308
Validation loss: 2.4568830403969715

Epoch: 6| Step: 13
Training loss: 2.308105726990545
Validation loss: 2.4138478489893096

Epoch: 255| Step: 0
Training loss: 2.2392283195220317
Validation loss: 2.4724360324539663

Epoch: 6| Step: 1
Training loss: 2.5947340971263393
Validation loss: 2.4525556507795847

Epoch: 6| Step: 2
Training loss: 1.702191298137228
Validation loss: 2.408308026174819

Epoch: 6| Step: 3
Training loss: 1.630018700568457
Validation loss: 2.429172033993754

Epoch: 6| Step: 4
Training loss: 1.9508551263169065
Validation loss: 2.439335512431003

Epoch: 6| Step: 5
Training loss: 1.7552771701011136
Validation loss: 2.4606680982216953

Epoch: 6| Step: 6
Training loss: 1.827134149149938
Validation loss: 2.438532320136706

Epoch: 6| Step: 7
Training loss: 1.836831966595663
Validation loss: 2.401024156347806

Epoch: 6| Step: 8
Training loss: 1.701989731691542
Validation loss: 2.4996825467848347

Epoch: 6| Step: 9
Training loss: 2.508358334472699
Validation loss: 2.5304227323072

Epoch: 6| Step: 10
Training loss: 2.179040300000971
Validation loss: 2.387956384875272

Epoch: 6| Step: 11
Training loss: 1.8759700808792896
Validation loss: 2.3940930664759663

Epoch: 6| Step: 12
Training loss: 2.050611507112107
Validation loss: 2.5483466699824886

Epoch: 6| Step: 13
Training loss: 2.356768450375752
Validation loss: 2.4849867890082464

Epoch: 256| Step: 0
Training loss: 2.333645618067906
Validation loss: 2.4695501530059256

Epoch: 6| Step: 1
Training loss: 1.7493107664602676
Validation loss: 2.4609996594432295

Epoch: 6| Step: 2
Training loss: 2.0857827347051376
Validation loss: 2.4786324685981262

Epoch: 6| Step: 3
Training loss: 2.521479269032882
Validation loss: 2.3976726118662133

Epoch: 6| Step: 4
Training loss: 2.012719951480677
Validation loss: 2.5008042344253676

Epoch: 6| Step: 5
Training loss: 1.4839125063313312
Validation loss: 2.510217015245031

Epoch: 6| Step: 6
Training loss: 1.821869867490995
Validation loss: 2.4277899675232275

Epoch: 6| Step: 7
Training loss: 2.153610382956859
Validation loss: 2.468918077721715

Epoch: 6| Step: 8
Training loss: 1.8629894227993566
Validation loss: 2.3939372738224

Epoch: 6| Step: 9
Training loss: 1.7035636686894942
Validation loss: 2.462342320215046

Epoch: 6| Step: 10
Training loss: 1.832801445474808
Validation loss: 2.4778230796726755

Epoch: 6| Step: 11
Training loss: 2.9171450268064967
Validation loss: 2.5189627962984624

Epoch: 6| Step: 12
Training loss: 2.0933081317202618
Validation loss: 2.4191624063783084

Epoch: 6| Step: 13
Training loss: 0.7610444434367922
Validation loss: 2.4358682200480044

Epoch: 257| Step: 0
Training loss: 2.0267767140769024
Validation loss: 2.4618147581283787

Epoch: 6| Step: 1
Training loss: 1.935302349392268
Validation loss: 2.4279629671630727

Epoch: 6| Step: 2
Training loss: 1.6393964254569502
Validation loss: 2.4163288156816134

Epoch: 6| Step: 3
Training loss: 1.9695252602655227
Validation loss: 2.4200680383092457

Epoch: 6| Step: 4
Training loss: 1.6866233809323485
Validation loss: 2.4292207524196527

Epoch: 6| Step: 5
Training loss: 1.9834157472472136
Validation loss: 2.4329639315685525

Epoch: 6| Step: 6
Training loss: 1.9985336650411307
Validation loss: 2.441568227993624

Epoch: 6| Step: 7
Training loss: 2.3284553447075944
Validation loss: 2.475052409623449

Epoch: 6| Step: 8
Training loss: 2.5109131086075145
Validation loss: 2.4398783861687687

Epoch: 6| Step: 9
Training loss: 2.0708797037726643
Validation loss: 2.4311357569972034

Epoch: 6| Step: 10
Training loss: 1.4856329957893708
Validation loss: 2.437195708678525

Epoch: 6| Step: 11
Training loss: 1.6783223126733688
Validation loss: 2.517934288671374

Epoch: 6| Step: 12
Training loss: 2.4512270248713635
Validation loss: 2.531228651176754

Epoch: 6| Step: 13
Training loss: 2.01573310976121
Validation loss: 2.5297923963526885

Epoch: 258| Step: 0
Training loss: 2.132128036275901
Validation loss: 2.4199432181680343

Epoch: 6| Step: 1
Training loss: 2.2262804354643966
Validation loss: 2.4393701502041045

Epoch: 6| Step: 2
Training loss: 1.4513957902094268
Validation loss: 2.515257007279247

Epoch: 6| Step: 3
Training loss: 1.8538979396320336
Validation loss: 2.475340582420559

Epoch: 6| Step: 4
Training loss: 2.045453342283261
Validation loss: 2.5105057305153085

Epoch: 6| Step: 5
Training loss: 2.0256833607082676
Validation loss: 2.488487245042083

Epoch: 6| Step: 6
Training loss: 1.9587995569402727
Validation loss: 2.4147717582591457

Epoch: 6| Step: 7
Training loss: 1.5663474968524693
Validation loss: 2.4602342769215335

Epoch: 6| Step: 8
Training loss: 1.9967672924908721
Validation loss: 2.5081077281536004

Epoch: 6| Step: 9
Training loss: 2.7952231532019565
Validation loss: 2.454818285402368

Epoch: 6| Step: 10
Training loss: 2.419503804717252
Validation loss: 2.4633553982656373

Epoch: 6| Step: 11
Training loss: 1.8292212174723899
Validation loss: 2.5403817302916325

Epoch: 6| Step: 12
Training loss: 2.5480526500813654
Validation loss: 2.464285016805515

Epoch: 6| Step: 13
Training loss: 1.5775690893650176
Validation loss: 2.473131786842787

Epoch: 259| Step: 0
Training loss: 2.055859945573679
Validation loss: 2.485668256207413

Epoch: 6| Step: 1
Training loss: 1.7927783873319632
Validation loss: 2.450740972796605

Epoch: 6| Step: 2
Training loss: 1.9694681825568754
Validation loss: 2.435484326990133

Epoch: 6| Step: 3
Training loss: 2.1222656834175977
Validation loss: 2.423868748129748

Epoch: 6| Step: 4
Training loss: 1.6165257818571326
Validation loss: 2.4702875736881222

Epoch: 6| Step: 5
Training loss: 1.8380067243401157
Validation loss: 2.512682218254358

Epoch: 6| Step: 6
Training loss: 2.161778425544839
Validation loss: 2.4457866826578263

Epoch: 6| Step: 7
Training loss: 2.2985647823688455
Validation loss: 2.4499566978016505

Epoch: 6| Step: 8
Training loss: 2.702524195588354
Validation loss: 2.4449780114281037

Epoch: 6| Step: 9
Training loss: 1.7265227990742742
Validation loss: 2.4472927480939646

Epoch: 6| Step: 10
Training loss: 2.0411364067880724
Validation loss: 2.4257348631336475

Epoch: 6| Step: 11
Training loss: 2.2047898515481577
Validation loss: 2.475704887373596

Epoch: 6| Step: 12
Training loss: 2.1286281579048145
Validation loss: 2.4293232886730323

Epoch: 6| Step: 13
Training loss: 1.6205400003724089
Validation loss: 2.4822351113328223

Epoch: 260| Step: 0
Training loss: 2.241989286480504
Validation loss: 2.386170505979174

Epoch: 6| Step: 1
Training loss: 1.9803626880423155
Validation loss: 2.4533033513188376

Epoch: 6| Step: 2
Training loss: 1.9438680778528823
Validation loss: 2.5647880319829346

Epoch: 6| Step: 3
Training loss: 1.638365870424648
Validation loss: 2.4343542483206932

Epoch: 6| Step: 4
Training loss: 2.147159598642126
Validation loss: 2.458466036304958

Epoch: 6| Step: 5
Training loss: 1.9864414299050852
Validation loss: 2.421522075490073

Epoch: 6| Step: 6
Training loss: 1.7220772183126107
Validation loss: 2.428281814981158

Epoch: 6| Step: 7
Training loss: 2.19597553272896
Validation loss: 2.4309289748725815

Epoch: 6| Step: 8
Training loss: 1.5930444988446093
Validation loss: 2.369007123437713

Epoch: 6| Step: 9
Training loss: 1.8086690866421573
Validation loss: 2.470784785052732

Epoch: 6| Step: 10
Training loss: 1.7848985348241253
Validation loss: 2.409816481657261

Epoch: 6| Step: 11
Training loss: 2.121769300477086
Validation loss: 2.4066185511175187

Epoch: 6| Step: 12
Training loss: 2.8417794243450456
Validation loss: 2.399924818608084

Epoch: 6| Step: 13
Training loss: 1.990982708613034
Validation loss: 2.3819584728639343

Epoch: 261| Step: 0
Training loss: 1.9929487980315292
Validation loss: 2.4203671591431317

Epoch: 6| Step: 1
Training loss: 1.9713213643646086
Validation loss: 2.4337103038258294

Epoch: 6| Step: 2
Training loss: 2.4077765836518608
Validation loss: 2.455748826465636

Epoch: 6| Step: 3
Training loss: 1.375119637573095
Validation loss: 2.4799175430000857

Epoch: 6| Step: 4
Training loss: 1.6748856861335315
Validation loss: 2.3945498391579307

Epoch: 6| Step: 5
Training loss: 1.806859348563167
Validation loss: 2.471301437294832

Epoch: 6| Step: 6
Training loss: 1.9708911212516569
Validation loss: 2.4476478231794214

Epoch: 6| Step: 7
Training loss: 1.8328228442070091
Validation loss: 2.4140747401334077

Epoch: 6| Step: 8
Training loss: 1.996492290089292
Validation loss: 2.443403068652743

Epoch: 6| Step: 9
Training loss: 2.1076559338062837
Validation loss: 2.4428309697502293

Epoch: 6| Step: 10
Training loss: 2.417812558061102
Validation loss: 2.4774657921185312

Epoch: 6| Step: 11
Training loss: 1.8609389451643477
Validation loss: 2.3780151133528316

Epoch: 6| Step: 12
Training loss: 1.7457040782899402
Validation loss: 2.409660597522287

Epoch: 6| Step: 13
Training loss: 1.856174246529898
Validation loss: 2.531921162024596

Epoch: 262| Step: 0
Training loss: 1.716521118376396
Validation loss: 2.4238566378376256

Epoch: 6| Step: 1
Training loss: 2.168647618584289
Validation loss: 2.490068940682093

Epoch: 6| Step: 2
Training loss: 2.9345275774238573
Validation loss: 2.399722620101463

Epoch: 6| Step: 3
Training loss: 1.9352200537255584
Validation loss: 2.3899669638343175

Epoch: 6| Step: 4
Training loss: 2.029987353581466
Validation loss: 2.5393869873898516

Epoch: 6| Step: 5
Training loss: 1.296357614653883
Validation loss: 2.4817496903797664

Epoch: 6| Step: 6
Training loss: 1.6621413625649204
Validation loss: 2.463903666972498

Epoch: 6| Step: 7
Training loss: 1.7449971623657239
Validation loss: 2.4418327563441014

Epoch: 6| Step: 8
Training loss: 1.8033204288455773
Validation loss: 2.475819047916389

Epoch: 6| Step: 9
Training loss: 2.097364124721189
Validation loss: 2.464080637813314

Epoch: 6| Step: 10
Training loss: 2.216184825681195
Validation loss: 2.444035750036043

Epoch: 6| Step: 11
Training loss: 1.6923971819391412
Validation loss: 2.5167746658502557

Epoch: 6| Step: 12
Training loss: 2.1257816447881845
Validation loss: 2.4769499625005964

Epoch: 6| Step: 13
Training loss: 2.5810253128649117
Validation loss: 2.450107781620018

Epoch: 263| Step: 0
Training loss: 2.617933480148404
Validation loss: 2.544697710936074

Epoch: 6| Step: 1
Training loss: 1.653036202423721
Validation loss: 2.4422686459878347

Epoch: 6| Step: 2
Training loss: 2.286932360984527
Validation loss: 2.4131719386387918

Epoch: 6| Step: 3
Training loss: 1.8867372626429042
Validation loss: 2.4702057150603425

Epoch: 6| Step: 4
Training loss: 1.2605955243955527
Validation loss: 2.4606834018704165

Epoch: 6| Step: 5
Training loss: 1.6933651476346963
Validation loss: 2.5327076605877843

Epoch: 6| Step: 6
Training loss: 1.7316690591912482
Validation loss: 2.4160421205884384

Epoch: 6| Step: 7
Training loss: 2.146306760345122
Validation loss: 2.4668339949705174

Epoch: 6| Step: 8
Training loss: 2.369734901055757
Validation loss: 2.4972660230662704

Epoch: 6| Step: 9
Training loss: 1.971202049954234
Validation loss: 2.451291468880099

Epoch: 6| Step: 10
Training loss: 2.0620793000225035
Validation loss: 2.472546253843196

Epoch: 6| Step: 11
Training loss: 1.6748268948965002
Validation loss: 2.4204106206986835

Epoch: 6| Step: 12
Training loss: 2.4363187226124285
Validation loss: 2.423158588770738

Epoch: 6| Step: 13
Training loss: 1.8734222767826227
Validation loss: 2.5775147959827547

Epoch: 264| Step: 0
Training loss: 1.9224329812977037
Validation loss: 2.493666034989087

Epoch: 6| Step: 1
Training loss: 1.9843161867091796
Validation loss: 2.5630141712073318

Epoch: 6| Step: 2
Training loss: 1.821398431598042
Validation loss: 2.450494253711797

Epoch: 6| Step: 3
Training loss: 1.9229387890282643
Validation loss: 2.471994052899721

Epoch: 6| Step: 4
Training loss: 1.6417541977579082
Validation loss: 2.35509712499593

Epoch: 6| Step: 5
Training loss: 2.2663307932166976
Validation loss: 2.475343791965636

Epoch: 6| Step: 6
Training loss: 1.583363516001209
Validation loss: 2.445145635734404

Epoch: 6| Step: 7
Training loss: 1.8609917928236956
Validation loss: 2.4911850798210744

Epoch: 6| Step: 8
Training loss: 2.281023301657363
Validation loss: 2.479402295320353

Epoch: 6| Step: 9
Training loss: 2.367398192846149
Validation loss: 2.419822593304411

Epoch: 6| Step: 10
Training loss: 1.8007861486935133
Validation loss: 2.495035354893466

Epoch: 6| Step: 11
Training loss: 2.1149906711958817
Validation loss: 2.4689146344975947

Epoch: 6| Step: 12
Training loss: 1.818080335732647
Validation loss: 2.4679923940162993

Epoch: 6| Step: 13
Training loss: 2.674671873128786
Validation loss: 2.465712105898756

Epoch: 265| Step: 0
Training loss: 2.1109678682730695
Validation loss: 2.4432736830611073

Epoch: 6| Step: 1
Training loss: 1.8457217260967447
Validation loss: 2.4973892402931877

Epoch: 6| Step: 2
Training loss: 2.229530898905598
Validation loss: 2.456684360060028

Epoch: 6| Step: 3
Training loss: 1.8697561049909368
Validation loss: 2.4290655467938174

Epoch: 6| Step: 4
Training loss: 2.8855229070134607
Validation loss: 2.481964328632192

Epoch: 6| Step: 5
Training loss: 1.5232752786977712
Validation loss: 2.4890943855346674

Epoch: 6| Step: 6
Training loss: 1.505220388960381
Validation loss: 2.4717573864807103

Epoch: 6| Step: 7
Training loss: 1.9171605786809414
Validation loss: 2.505243521457676

Epoch: 6| Step: 8
Training loss: 1.9619963321554292
Validation loss: 2.4414649270502506

Epoch: 6| Step: 9
Training loss: 1.4687327931796275
Validation loss: 2.472279811443548

Epoch: 6| Step: 10
Training loss: 1.9753113054640938
Validation loss: 2.472703797017174

Epoch: 6| Step: 11
Training loss: 2.3890750822306015
Validation loss: 2.4147067000473

Epoch: 6| Step: 12
Training loss: 1.4715810235154407
Validation loss: 2.3769755714826095

Epoch: 6| Step: 13
Training loss: 2.203911607067111
Validation loss: 2.3907287294190502

Epoch: 266| Step: 0
Training loss: 2.2139582941250273
Validation loss: 2.4151156444321447

Epoch: 6| Step: 1
Training loss: 2.205635101822733
Validation loss: 2.474215649800632

Epoch: 6| Step: 2
Training loss: 2.147776443043361
Validation loss: 2.4987029464096415

Epoch: 6| Step: 3
Training loss: 1.9708291231826858
Validation loss: 2.4234705564537653

Epoch: 6| Step: 4
Training loss: 1.9338700530569772
Validation loss: 2.436525840658629

Epoch: 6| Step: 5
Training loss: 1.705738966430779
Validation loss: 2.439655111651105

Epoch: 6| Step: 6
Training loss: 2.1747182992496543
Validation loss: 2.4048705081421033

Epoch: 6| Step: 7
Training loss: 1.5542865792139837
Validation loss: 2.530924598016714

Epoch: 6| Step: 8
Training loss: 2.0550631915769673
Validation loss: 2.439579607948624

Epoch: 6| Step: 9
Training loss: 2.029186080536869
Validation loss: 2.4785620687311365

Epoch: 6| Step: 10
Training loss: 2.249049621774138
Validation loss: 2.4640671879471627

Epoch: 6| Step: 11
Training loss: 2.450032027677497
Validation loss: 2.3900996126908782

Epoch: 6| Step: 12
Training loss: 1.450116231797947
Validation loss: 2.4592383130097937

Epoch: 6| Step: 13
Training loss: 1.6092973708901974
Validation loss: 2.4252155512198956

Epoch: 267| Step: 0
Training loss: 1.5180289483809453
Validation loss: 2.4330933317298364

Epoch: 6| Step: 1
Training loss: 1.7164925054824922
Validation loss: 2.464782819138969

Epoch: 6| Step: 2
Training loss: 1.380395274427843
Validation loss: 2.456425065038588

Epoch: 6| Step: 3
Training loss: 1.759997556858101
Validation loss: 2.4555137681700705

Epoch: 6| Step: 4
Training loss: 2.1385550410438863
Validation loss: 2.4551602186040973

Epoch: 6| Step: 5
Training loss: 2.0521163808675666
Validation loss: 2.4749497366373756

Epoch: 6| Step: 6
Training loss: 2.308685455824493
Validation loss: 2.5281526003758157

Epoch: 6| Step: 7
Training loss: 2.0774613087857867
Validation loss: 2.4057184534395772

Epoch: 6| Step: 8
Training loss: 2.0244181845034617
Validation loss: 2.434315759511234

Epoch: 6| Step: 9
Training loss: 1.4783827446066804
Validation loss: 2.434708333140252

Epoch: 6| Step: 10
Training loss: 2.184999180843802
Validation loss: 2.393119433413544

Epoch: 6| Step: 11
Training loss: 2.6484529837996864
Validation loss: 2.4449693358489566

Epoch: 6| Step: 12
Training loss: 1.80810382048686
Validation loss: 2.4695086873003995

Epoch: 6| Step: 13
Training loss: 2.921359093146688
Validation loss: 2.459176526037593

Epoch: 268| Step: 0
Training loss: 1.9552434190201127
Validation loss: 2.4163666642555244

Epoch: 6| Step: 1
Training loss: 1.668181001617179
Validation loss: 2.4478479575151706

Epoch: 6| Step: 2
Training loss: 1.6283862704233063
Validation loss: 2.4788510900808114

Epoch: 6| Step: 3
Training loss: 2.8323004653829535
Validation loss: 2.4634980329215157

Epoch: 6| Step: 4
Training loss: 1.5966675177527425
Validation loss: 2.4556643696778364

Epoch: 6| Step: 5
Training loss: 1.4436611329839242
Validation loss: 2.4336484575914636

Epoch: 6| Step: 6
Training loss: 2.5526974827874045
Validation loss: 2.4908183467006304

Epoch: 6| Step: 7
Training loss: 2.0024415848459136
Validation loss: 2.467528959605692

Epoch: 6| Step: 8
Training loss: 1.5652388410549742
Validation loss: 2.4677150099388143

Epoch: 6| Step: 9
Training loss: 1.7979334491935128
Validation loss: 2.5188700146679386

Epoch: 6| Step: 10
Training loss: 1.9833758985402334
Validation loss: 2.453787635841108

Epoch: 6| Step: 11
Training loss: 2.0040789970314976
Validation loss: 2.459439602468149

Epoch: 6| Step: 12
Training loss: 1.9904175918296925
Validation loss: 2.40858331746777

Epoch: 6| Step: 13
Training loss: 1.1284001149672078
Validation loss: 2.358025373249548

Epoch: 269| Step: 0
Training loss: 2.021591463799941
Validation loss: 2.439441745742387

Epoch: 6| Step: 1
Training loss: 2.0329054908682416
Validation loss: 2.4326308486631354

Epoch: 6| Step: 2
Training loss: 2.0472539885753775
Validation loss: 2.523064877434892

Epoch: 6| Step: 3
Training loss: 1.5808747008278066
Validation loss: 2.4731082943366536

Epoch: 6| Step: 4
Training loss: 1.022155074722224
Validation loss: 2.466777727619501

Epoch: 6| Step: 5
Training loss: 1.9051627513618452
Validation loss: 2.379859078686868

Epoch: 6| Step: 6
Training loss: 1.5888092649437482
Validation loss: 2.440337708241444

Epoch: 6| Step: 7
Training loss: 2.9667409423216675
Validation loss: 2.4587207160130586

Epoch: 6| Step: 8
Training loss: 1.6844724411107028
Validation loss: 2.456140833252153

Epoch: 6| Step: 9
Training loss: 2.186225737954551
Validation loss: 2.449924025760808

Epoch: 6| Step: 10
Training loss: 2.019760502507115
Validation loss: 2.440171988284492

Epoch: 6| Step: 11
Training loss: 2.077903907889184
Validation loss: 2.460351981418178

Epoch: 6| Step: 12
Training loss: 1.770613383676845
Validation loss: 2.4473882668223377

Epoch: 6| Step: 13
Training loss: 1.6846821888801184
Validation loss: 2.513197842144338

Epoch: 270| Step: 0
Training loss: 1.8279501676507566
Validation loss: 2.4311241363432594

Epoch: 6| Step: 1
Training loss: 2.3358543151537328
Validation loss: 2.4608036169565475

Epoch: 6| Step: 2
Training loss: 1.9281548347823447
Validation loss: 2.4247528591728242

Epoch: 6| Step: 3
Training loss: 2.06504826191439
Validation loss: 2.5211654843595572

Epoch: 6| Step: 4
Training loss: 1.535859391020215
Validation loss: 2.401498335561739

Epoch: 6| Step: 5
Training loss: 2.38943072637961
Validation loss: 2.4686179550868674

Epoch: 6| Step: 6
Training loss: 1.3965361045379658
Validation loss: 2.4102984335426108

Epoch: 6| Step: 7
Training loss: 2.5449792089905836
Validation loss: 2.4502238983098215

Epoch: 6| Step: 8
Training loss: 1.32911761720534
Validation loss: 2.4501315909232892

Epoch: 6| Step: 9
Training loss: 2.295736848311839
Validation loss: 2.4686219595097683

Epoch: 6| Step: 10
Training loss: 1.6853080925157924
Validation loss: 2.4502256477032605

Epoch: 6| Step: 11
Training loss: 2.050525467679813
Validation loss: 2.4300984296044006

Epoch: 6| Step: 12
Training loss: 1.7456160538359138
Validation loss: 2.4922088828892393

Epoch: 6| Step: 13
Training loss: 1.8143512873819827
Validation loss: 2.443023562821789

Epoch: 271| Step: 0
Training loss: 1.8148430773782653
Validation loss: 2.4354546850175613

Epoch: 6| Step: 1
Training loss: 2.3673266882939683
Validation loss: 2.457688950196376

Epoch: 6| Step: 2
Training loss: 1.387453985739987
Validation loss: 2.4964826369089677

Epoch: 6| Step: 3
Training loss: 2.272023393698593
Validation loss: 2.41786466663377

Epoch: 6| Step: 4
Training loss: 1.6625135492905636
Validation loss: 2.4773981210122735

Epoch: 6| Step: 5
Training loss: 2.01564818376323
Validation loss: 2.391153236863181

Epoch: 6| Step: 6
Training loss: 2.40177580780239
Validation loss: 2.4331081982277913

Epoch: 6| Step: 7
Training loss: 1.9399095134672322
Validation loss: 2.4748239187957752

Epoch: 6| Step: 8
Training loss: 1.874241230342071
Validation loss: 2.5011272063199006

Epoch: 6| Step: 9
Training loss: 1.972533692433578
Validation loss: 2.467917330325937

Epoch: 6| Step: 10
Training loss: 1.6734150718518122
Validation loss: 2.41483421003058

Epoch: 6| Step: 11
Training loss: 1.262473055108214
Validation loss: 2.447908254245467

Epoch: 6| Step: 12
Training loss: 2.357316085097846
Validation loss: 2.399650579869637

Epoch: 6| Step: 13
Training loss: 1.9571565447081065
Validation loss: 2.4735900342245314

Epoch: 272| Step: 0
Training loss: 2.0544458979717306
Validation loss: 2.467422797352022

Epoch: 6| Step: 1
Training loss: 2.1761009762139256
Validation loss: 2.4165461732601483

Epoch: 6| Step: 2
Training loss: 1.4399746864796015
Validation loss: 2.4452204569837104

Epoch: 6| Step: 3
Training loss: 2.1430515541714508
Validation loss: 2.4304376799971252

Epoch: 6| Step: 4
Training loss: 2.584230626050892
Validation loss: 2.4439641191455346

Epoch: 6| Step: 5
Training loss: 1.8525427947461746
Validation loss: 2.446535788603694

Epoch: 6| Step: 6
Training loss: 2.295213163029769
Validation loss: 2.3689035126343874

Epoch: 6| Step: 7
Training loss: 1.6310481710284372
Validation loss: 2.477621700624372

Epoch: 6| Step: 8
Training loss: 1.3880101168316028
Validation loss: 2.5020660477116867

Epoch: 6| Step: 9
Training loss: 1.7294755070041878
Validation loss: 2.515024515414664

Epoch: 6| Step: 10
Training loss: 2.991075274174217
Validation loss: 2.417699407180094

Epoch: 6| Step: 11
Training loss: 1.5621541975744622
Validation loss: 2.4634180264064125

Epoch: 6| Step: 12
Training loss: 1.6868510234608605
Validation loss: 2.4725988771791614

Epoch: 6| Step: 13
Training loss: 1.645594092577585
Validation loss: 2.4812100528208263

Epoch: 273| Step: 0
Training loss: 1.9704623571486823
Validation loss: 2.4679265775911925

Epoch: 6| Step: 1
Training loss: 2.0654135268280296
Validation loss: 2.53118374199884

Epoch: 6| Step: 2
Training loss: 1.6766803170338
Validation loss: 2.444211197408661

Epoch: 6| Step: 3
Training loss: 2.1448416285526224
Validation loss: 2.460006368431921

Epoch: 6| Step: 4
Training loss: 2.2723856062261505
Validation loss: 2.4189394050698994

Epoch: 6| Step: 5
Training loss: 2.0332087535945145
Validation loss: 2.4447462840449448

Epoch: 6| Step: 6
Training loss: 1.5058660247299676
Validation loss: 2.5411083012244275

Epoch: 6| Step: 7
Training loss: 1.5558300324895191
Validation loss: 2.5122571048740743

Epoch: 6| Step: 8
Training loss: 2.0534877973314236
Validation loss: 2.439930774742941

Epoch: 6| Step: 9
Training loss: 2.009461434553549
Validation loss: 2.4681582382222977

Epoch: 6| Step: 10
Training loss: 1.8604355680467393
Validation loss: 2.4616599787349234

Epoch: 6| Step: 11
Training loss: 2.5439917034817614
Validation loss: 2.488200341892564

Epoch: 6| Step: 12
Training loss: 1.876998980197213
Validation loss: 2.416207600557109

Epoch: 6| Step: 13
Training loss: 2.1643943119096294
Validation loss: 2.429100050806335

Epoch: 274| Step: 0
Training loss: 2.627170755099987
Validation loss: 2.4067756218315823

Epoch: 6| Step: 1
Training loss: 1.3146896262907692
Validation loss: 2.465281193767582

Epoch: 6| Step: 2
Training loss: 1.6981588631666331
Validation loss: 2.4909813716221016

Epoch: 6| Step: 3
Training loss: 1.8360203501086756
Validation loss: 2.4419728803134304

Epoch: 6| Step: 4
Training loss: 2.495298638063456
Validation loss: 2.399380505630542

Epoch: 6| Step: 5
Training loss: 2.500135418085318
Validation loss: 2.379964276413894

Epoch: 6| Step: 6
Training loss: 2.2640530098346976
Validation loss: 2.4642777330066385

Epoch: 6| Step: 7
Training loss: 2.153758281707339
Validation loss: 2.354845638590851

Epoch: 6| Step: 8
Training loss: 1.3200492822232694
Validation loss: 2.446817688021992

Epoch: 6| Step: 9
Training loss: 1.5135431050317611
Validation loss: 2.386733051429934

Epoch: 6| Step: 10
Training loss: 1.9920010946990838
Validation loss: 2.4359488114758165

Epoch: 6| Step: 11
Training loss: 1.575692142809741
Validation loss: 2.475438229853468

Epoch: 6| Step: 12
Training loss: 1.5554872688942254
Validation loss: 2.4375629990111296

Epoch: 6| Step: 13
Training loss: 2.3908365193458017
Validation loss: 2.436340178098488

Epoch: 275| Step: 0
Training loss: 1.833517354341615
Validation loss: 2.410788295456413

Epoch: 6| Step: 1
Training loss: 2.3927224127411004
Validation loss: 2.4463292330045867

Epoch: 6| Step: 2
Training loss: 1.6795146054731285
Validation loss: 2.5489710478126084

Epoch: 6| Step: 3
Training loss: 1.54884105547093
Validation loss: 2.4476083247551985

Epoch: 6| Step: 4
Training loss: 2.0469786639571503
Validation loss: 2.521437713274411

Epoch: 6| Step: 5
Training loss: 1.4421019490534028
Validation loss: 2.4880153375927128

Epoch: 6| Step: 6
Training loss: 1.7668154593853862
Validation loss: 2.4947407326123208

Epoch: 6| Step: 7
Training loss: 2.361151626339036
Validation loss: 2.493595789680194

Epoch: 6| Step: 8
Training loss: 2.123469306309
Validation loss: 2.493671489874442

Epoch: 6| Step: 9
Training loss: 1.6308815960312502
Validation loss: 2.558516001762764

Epoch: 6| Step: 10
Training loss: 1.9540869213282088
Validation loss: 2.3955820180974534

Epoch: 6| Step: 11
Training loss: 2.9650143861984497
Validation loss: 2.515899009408073

Epoch: 6| Step: 12
Training loss: 1.9557334876150323
Validation loss: 2.5040955221697017

Epoch: 6| Step: 13
Training loss: 1.0133043038033163
Validation loss: 2.517208694598237

Epoch: 276| Step: 0
Training loss: 1.3379216322821073
Validation loss: 2.3652818085572602

Epoch: 6| Step: 1
Training loss: 1.616551813325894
Validation loss: 2.449316416235289

Epoch: 6| Step: 2
Training loss: 1.8216768971697161
Validation loss: 2.4549589411501227

Epoch: 6| Step: 3
Training loss: 2.0636763252587236
Validation loss: 2.447995554836062

Epoch: 6| Step: 4
Training loss: 1.8405257659741805
Validation loss: 2.4767308368006615

Epoch: 6| Step: 5
Training loss: 1.7410273088726893
Validation loss: 2.4814150500481036

Epoch: 6| Step: 6
Training loss: 1.9266850515278209
Validation loss: 2.4362098323186228

Epoch: 6| Step: 7
Training loss: 1.776526361666578
Validation loss: 2.3842308456197423

Epoch: 6| Step: 8
Training loss: 1.6855712747410165
Validation loss: 2.348245902907849

Epoch: 6| Step: 9
Training loss: 2.6666877765614694
Validation loss: 2.4749931740151356

Epoch: 6| Step: 10
Training loss: 2.03340480657981
Validation loss: 2.4173095097069193

Epoch: 6| Step: 11
Training loss: 1.9170952884351329
Validation loss: 2.501609342700315

Epoch: 6| Step: 12
Training loss: 2.0164828581891308
Validation loss: 2.5055783516824133

Epoch: 6| Step: 13
Training loss: 2.056794105591965
Validation loss: 2.4788219325627154

Epoch: 277| Step: 0
Training loss: 1.4170308860368648
Validation loss: 2.4662896593087176

Epoch: 6| Step: 1
Training loss: 1.8329605966298368
Validation loss: 2.496610626574671

Epoch: 6| Step: 2
Training loss: 1.8973089560731884
Validation loss: 2.4427412449661103

Epoch: 6| Step: 3
Training loss: 1.869599384703431
Validation loss: 2.4118670975553216

Epoch: 6| Step: 4
Training loss: 1.3036976788593124
Validation loss: 2.440203438793663

Epoch: 6| Step: 5
Training loss: 2.1540527205395343
Validation loss: 2.4537807737903776

Epoch: 6| Step: 6
Training loss: 2.01106064781727
Validation loss: 2.4184168223308884

Epoch: 6| Step: 7
Training loss: 2.120748642864915
Validation loss: 2.443596408199803

Epoch: 6| Step: 8
Training loss: 2.183555206886745
Validation loss: 2.4757348975817313

Epoch: 6| Step: 9
Training loss: 2.7907287578367224
Validation loss: 2.471943513695386

Epoch: 6| Step: 10
Training loss: 2.4296140997001796
Validation loss: 2.352057373317212

Epoch: 6| Step: 11
Training loss: 1.7798818051818723
Validation loss: 2.448600132887264

Epoch: 6| Step: 12
Training loss: 1.6414627116322804
Validation loss: 2.488331160660786

Epoch: 6| Step: 13
Training loss: 1.0941260100222414
Validation loss: 2.4166394282734185

Epoch: 278| Step: 0
Training loss: 2.0722087884671487
Validation loss: 2.5109409960287175

Epoch: 6| Step: 1
Training loss: 1.6787237906948678
Validation loss: 2.4225595597718454

Epoch: 6| Step: 2
Training loss: 1.4765122016534336
Validation loss: 2.483939518280238

Epoch: 6| Step: 3
Training loss: 1.3969652748379568
Validation loss: 2.415053450458442

Epoch: 6| Step: 4
Training loss: 2.5593905307545417
Validation loss: 2.506028727398047

Epoch: 6| Step: 5
Training loss: 1.4791106988052207
Validation loss: 2.5339525512242247

Epoch: 6| Step: 6
Training loss: 1.8199130426320675
Validation loss: 2.507644104334474

Epoch: 6| Step: 7
Training loss: 1.7819037994337408
Validation loss: 2.5295660731742178

Epoch: 6| Step: 8
Training loss: 2.3599761803281636
Validation loss: 2.4246770404997946

Epoch: 6| Step: 9
Training loss: 2.1986718590379932
Validation loss: 2.507245532513552

Epoch: 6| Step: 10
Training loss: 1.9048775907421636
Validation loss: 2.3900878027082295

Epoch: 6| Step: 11
Training loss: 1.8703846394099852
Validation loss: 2.412387237812437

Epoch: 6| Step: 12
Training loss: 1.8110482551469198
Validation loss: 2.37158852849139

Epoch: 6| Step: 13
Training loss: 2.0258844963505966
Validation loss: 2.379412942371451

Epoch: 279| Step: 0
Training loss: 1.7614055617368423
Validation loss: 2.404884105191822

Epoch: 6| Step: 1
Training loss: 1.893823298681862
Validation loss: 2.4589757290283614

Epoch: 6| Step: 2
Training loss: 1.8214897965578158
Validation loss: 2.3913724458559584

Epoch: 6| Step: 3
Training loss: 1.716812220516777
Validation loss: 2.4636340094179854

Epoch: 6| Step: 4
Training loss: 1.4159533256769468
Validation loss: 2.4639469203556796

Epoch: 6| Step: 5
Training loss: 1.276508770002219
Validation loss: 2.5195234406218185

Epoch: 6| Step: 6
Training loss: 1.9883968417099416
Validation loss: 2.429372446750931

Epoch: 6| Step: 7
Training loss: 2.782722854669663
Validation loss: 2.435584456505823

Epoch: 6| Step: 8
Training loss: 1.5185543734927327
Validation loss: 2.4299505206344385

Epoch: 6| Step: 9
Training loss: 1.928114400429549
Validation loss: 2.4093567516083323

Epoch: 6| Step: 10
Training loss: 1.7747125957076209
Validation loss: 2.4929393156749393

Epoch: 6| Step: 11
Training loss: 2.3822979480931368
Validation loss: 2.4255387966426905

Epoch: 6| Step: 12
Training loss: 1.7895560437550522
Validation loss: 2.4238924217251805

Epoch: 6| Step: 13
Training loss: 2.6250066302987785
Validation loss: 2.4953261647264537

Epoch: 280| Step: 0
Training loss: 1.7383963214633467
Validation loss: 2.4714250393084525

Epoch: 6| Step: 1
Training loss: 1.3191077248873508
Validation loss: 2.4327233574739524

Epoch: 6| Step: 2
Training loss: 1.9839484289450113
Validation loss: 2.4143422840059623

Epoch: 6| Step: 3
Training loss: 1.2762871434768785
Validation loss: 2.4411834386734528

Epoch: 6| Step: 4
Training loss: 2.0913037485533703
Validation loss: 2.4303538267349407

Epoch: 6| Step: 5
Training loss: 2.0721716252758573
Validation loss: 2.4977099543494203

Epoch: 6| Step: 6
Training loss: 1.8879151904486875
Validation loss: 2.4094629985106577

Epoch: 6| Step: 7
Training loss: 1.1304927356761585
Validation loss: 2.4009075747074067

Epoch: 6| Step: 8
Training loss: 2.023488047789539
Validation loss: 2.4579949035648436

Epoch: 6| Step: 9
Training loss: 2.2344164010860603
Validation loss: 2.408803845749952

Epoch: 6| Step: 10
Training loss: 2.035489865889935
Validation loss: 2.4742671585114953

Epoch: 6| Step: 11
Training loss: 2.424114938837335
Validation loss: 2.4990373152546863

Epoch: 6| Step: 12
Training loss: 1.7565555401759023
Validation loss: 2.5417323783988475

Epoch: 6| Step: 13
Training loss: 1.9829684100768092
Validation loss: 2.4798367088530564

Epoch: 281| Step: 0
Training loss: 1.2636814971981998
Validation loss: 2.4406376079166288

Epoch: 6| Step: 1
Training loss: 1.1594695553946577
Validation loss: 2.454089465595707

Epoch: 6| Step: 2
Training loss: 1.8100715679962245
Validation loss: 2.4871021238853404

Epoch: 6| Step: 3
Training loss: 1.6924490236074365
Validation loss: 2.4632421559175537

Epoch: 6| Step: 4
Training loss: 2.1716949607819114
Validation loss: 2.45135048450573

Epoch: 6| Step: 5
Training loss: 2.8535340065073598
Validation loss: 2.5288484251272614

Epoch: 6| Step: 6
Training loss: 1.649650091580666
Validation loss: 2.437424700898874

Epoch: 6| Step: 7
Training loss: 1.7652230944677183
Validation loss: 2.4982911196517374

Epoch: 6| Step: 8
Training loss: 2.2039082534926977
Validation loss: 2.447831813272799

Epoch: 6| Step: 9
Training loss: 1.6671947675723524
Validation loss: 2.4330350128144

Epoch: 6| Step: 10
Training loss: 1.7178314528825858
Validation loss: 2.399653454768539

Epoch: 6| Step: 11
Training loss: 2.049889012565478
Validation loss: 2.5080755192505038

Epoch: 6| Step: 12
Training loss: 2.062481388817249
Validation loss: 2.4293573088746685

Epoch: 6| Step: 13
Training loss: 2.456880646715878
Validation loss: 2.4251749157657647

Epoch: 282| Step: 0
Training loss: 1.839806169583683
Validation loss: 2.430641632977905

Epoch: 6| Step: 1
Training loss: 1.907417315169647
Validation loss: 2.4289557835612907

Epoch: 6| Step: 2
Training loss: 1.4102586196557547
Validation loss: 2.480824197085902

Epoch: 6| Step: 3
Training loss: 1.798941311500773
Validation loss: 2.4584782096952926

Epoch: 6| Step: 4
Training loss: 1.8390148587728576
Validation loss: 2.3862217909612253

Epoch: 6| Step: 5
Training loss: 2.587522084607217
Validation loss: 2.415325894698372

Epoch: 6| Step: 6
Training loss: 1.8550905504772457
Validation loss: 2.5037210193208206

Epoch: 6| Step: 7
Training loss: 1.9043067031997982
Validation loss: 2.4822017745438427

Epoch: 6| Step: 8
Training loss: 1.667763976630817
Validation loss: 2.5005893822642924

Epoch: 6| Step: 9
Training loss: 1.7915760357430424
Validation loss: 2.503279067548967

Epoch: 6| Step: 10
Training loss: 2.236640048865914
Validation loss: 2.4506876593833975

Epoch: 6| Step: 11
Training loss: 2.174241238367069
Validation loss: 2.444918488619

Epoch: 6| Step: 12
Training loss: 1.9156575932927027
Validation loss: 2.482062319705956

Epoch: 6| Step: 13
Training loss: 2.435479818612525
Validation loss: 2.4465608523720435

Epoch: 283| Step: 0
Training loss: 1.4795715512181051
Validation loss: 2.457614891379235

Epoch: 6| Step: 1
Training loss: 1.735261982423416
Validation loss: 2.4054761371210636

Epoch: 6| Step: 2
Training loss: 1.7539159693799113
Validation loss: 2.4172933089244277

Epoch: 6| Step: 3
Training loss: 1.5927177527053293
Validation loss: 2.412379322819986

Epoch: 6| Step: 4
Training loss: 1.9671102082912693
Validation loss: 2.4747428851228674

Epoch: 6| Step: 5
Training loss: 1.6683352065607784
Validation loss: 2.4776149852931866

Epoch: 6| Step: 6
Training loss: 2.093840184333393
Validation loss: 2.439867774876327

Epoch: 6| Step: 7
Training loss: 2.0937651448627284
Validation loss: 2.5122800139424744

Epoch: 6| Step: 8
Training loss: 2.4556503418090303
Validation loss: 2.434069753226622

Epoch: 6| Step: 9
Training loss: 2.103961922029043
Validation loss: 2.5377090165956613

Epoch: 6| Step: 10
Training loss: 1.655651344213567
Validation loss: 2.4204834506572737

Epoch: 6| Step: 11
Training loss: 2.6514826459667415
Validation loss: 2.499287245779681

Epoch: 6| Step: 12
Training loss: 1.766796432383733
Validation loss: 2.337929890341163

Epoch: 6| Step: 13
Training loss: 1.7139898098717263
Validation loss: 2.45155112909771

Epoch: 284| Step: 0
Training loss: 1.8841142388593723
Validation loss: 2.444220418987374

Epoch: 6| Step: 1
Training loss: 1.690791346462821
Validation loss: 2.464574574454687

Epoch: 6| Step: 2
Training loss: 2.9523362817036394
Validation loss: 2.508864721174144

Epoch: 6| Step: 3
Training loss: 2.167937077471346
Validation loss: 2.4051473525877114

Epoch: 6| Step: 4
Training loss: 1.9023358542652493
Validation loss: 2.440656409966744

Epoch: 6| Step: 5
Training loss: 2.332368401416105
Validation loss: 2.389153152036099

Epoch: 6| Step: 6
Training loss: 1.4342819349893747
Validation loss: 2.4373539617147206

Epoch: 6| Step: 7
Training loss: 2.1937412055293026
Validation loss: 2.452996026870681

Epoch: 6| Step: 8
Training loss: 2.2057214682008204
Validation loss: 2.456746139794797

Epoch: 6| Step: 9
Training loss: 1.183214183414401
Validation loss: 2.403234262837647

Epoch: 6| Step: 10
Training loss: 1.6751736337424952
Validation loss: 2.4614534955983127

Epoch: 6| Step: 11
Training loss: 1.4110782388344243
Validation loss: 2.4786001709312115

Epoch: 6| Step: 12
Training loss: 1.697089955465033
Validation loss: 2.414550776472141

Epoch: 6| Step: 13
Training loss: 0.8893709891169187
Validation loss: 2.531982321004354

Epoch: 285| Step: 0
Training loss: 1.9362498526329934
Validation loss: 2.4645731826720345

Epoch: 6| Step: 1
Training loss: 1.586347029102956
Validation loss: 2.4240168653276633

Epoch: 6| Step: 2
Training loss: 1.5497391512017686
Validation loss: 2.448597369899807

Epoch: 6| Step: 3
Training loss: 1.8489200068696803
Validation loss: 2.4330514881010474

Epoch: 6| Step: 4
Training loss: 1.8569036777763752
Validation loss: 2.549206829150966

Epoch: 6| Step: 5
Training loss: 1.9141092100088166
Validation loss: 2.4876243231682507

Epoch: 6| Step: 6
Training loss: 1.8519089129275217
Validation loss: 2.411118293756738

Epoch: 6| Step: 7
Training loss: 1.6409102418982437
Validation loss: 2.4836011514515763

Epoch: 6| Step: 8
Training loss: 2.5170289854579058
Validation loss: 2.4568647830415635

Epoch: 6| Step: 9
Training loss: 2.304539148760851
Validation loss: 2.3965896917734653

Epoch: 6| Step: 10
Training loss: 1.6239780733949063
Validation loss: 2.467900797974196

Epoch: 6| Step: 11
Training loss: 1.4587439730927507
Validation loss: 2.460332545786127

Epoch: 6| Step: 12
Training loss: 2.602509105860659
Validation loss: 2.4439861536721494

Epoch: 6| Step: 13
Training loss: 2.00298896601395
Validation loss: 2.4489767421431576

Epoch: 286| Step: 0
Training loss: 1.862462917701185
Validation loss: 2.495771170366605

Epoch: 6| Step: 1
Training loss: 1.6325947739575088
Validation loss: 2.527205520168976

Epoch: 6| Step: 2
Training loss: 1.605136957712686
Validation loss: 2.4716398024643684

Epoch: 6| Step: 3
Training loss: 1.6394400540881287
Validation loss: 2.4525084595023543

Epoch: 6| Step: 4
Training loss: 2.757650570532629
Validation loss: 2.4582626940250747

Epoch: 6| Step: 5
Training loss: 1.5337067183999638
Validation loss: 2.4454706539195095

Epoch: 6| Step: 6
Training loss: 1.5019605063466623
Validation loss: 2.505971610184176

Epoch: 6| Step: 7
Training loss: 1.6578089017406534
Validation loss: 2.483877734745174

Epoch: 6| Step: 8
Training loss: 2.1701736922122423
Validation loss: 2.4372152167913836

Epoch: 6| Step: 9
Training loss: 2.1919256944452936
Validation loss: 2.4552516075991972

Epoch: 6| Step: 10
Training loss: 1.9918211356984317
Validation loss: 2.400151460065919

Epoch: 6| Step: 11
Training loss: 1.6002304864810197
Validation loss: 2.4055367861625903

Epoch: 6| Step: 12
Training loss: 1.4520075613618384
Validation loss: 2.4546202504957733

Epoch: 6| Step: 13
Training loss: 2.025257956004764
Validation loss: 2.547558662843431

Epoch: 287| Step: 0
Training loss: 1.722264528609455
Validation loss: 2.5059293941889385

Epoch: 6| Step: 1
Training loss: 1.1497745645399364
Validation loss: 2.502179295236547

Epoch: 6| Step: 2
Training loss: 1.4735117079493278
Validation loss: 2.40461223487999

Epoch: 6| Step: 3
Training loss: 2.126869052875285
Validation loss: 2.3743308289848444

Epoch: 6| Step: 4
Training loss: 1.6769339769408929
Validation loss: 2.42964001649308

Epoch: 6| Step: 5
Training loss: 2.2223397886118503
Validation loss: 2.4903101228135345

Epoch: 6| Step: 6
Training loss: 1.9055094296600679
Validation loss: 2.5469104365018698

Epoch: 6| Step: 7
Training loss: 1.7000538144289274
Validation loss: 2.4900890311626136

Epoch: 6| Step: 8
Training loss: 1.8824704441217512
Validation loss: 2.442027475776792

Epoch: 6| Step: 9
Training loss: 2.163257325144482
Validation loss: 2.5391370122812926

Epoch: 6| Step: 10
Training loss: 2.8559058985875065
Validation loss: 2.479509190548411

Epoch: 6| Step: 11
Training loss: 1.7019916928421426
Validation loss: 2.438335565769782

Epoch: 6| Step: 12
Training loss: 1.801531918639171
Validation loss: 2.4794276544679192

Epoch: 6| Step: 13
Training loss: 1.7351795426840189
Validation loss: 2.397975614880213

Epoch: 288| Step: 0
Training loss: 2.032439133224223
Validation loss: 2.3874681274901475

Epoch: 6| Step: 1
Training loss: 1.4614456027567002
Validation loss: 2.4258145668944424

Epoch: 6| Step: 2
Training loss: 1.5424967756191292
Validation loss: 2.450578580595266

Epoch: 6| Step: 3
Training loss: 2.0602932308342625
Validation loss: 2.419311288557869

Epoch: 6| Step: 4
Training loss: 1.97028115691531
Validation loss: 2.479500146740217

Epoch: 6| Step: 5
Training loss: 1.6564514469500473
Validation loss: 2.407222155621634

Epoch: 6| Step: 6
Training loss: 1.9833153726528525
Validation loss: 2.4760301319972386

Epoch: 6| Step: 7
Training loss: 1.8522779796545021
Validation loss: 2.46503698973752

Epoch: 6| Step: 8
Training loss: 2.227824713333305
Validation loss: 2.480148314110857

Epoch: 6| Step: 9
Training loss: 1.5384320357134798
Validation loss: 2.4438481109993413

Epoch: 6| Step: 10
Training loss: 2.4436554092871563
Validation loss: 2.4750458815328313

Epoch: 6| Step: 11
Training loss: 1.7121088903949948
Validation loss: 2.4515718460676075

Epoch: 6| Step: 12
Training loss: 1.7150895413971148
Validation loss: 2.42126374458411

Epoch: 6| Step: 13
Training loss: 1.7270088136776087
Validation loss: 2.429357468221226

Epoch: 289| Step: 0
Training loss: 1.8260830944328457
Validation loss: 2.52973249172044

Epoch: 6| Step: 1
Training loss: 1.9707676070734692
Validation loss: 2.3912786332414147

Epoch: 6| Step: 2
Training loss: 1.228199055309892
Validation loss: 2.4569855908507368

Epoch: 6| Step: 3
Training loss: 1.8475936653231777
Validation loss: 2.419010776542724

Epoch: 6| Step: 4
Training loss: 1.435814242214839
Validation loss: 2.4317911911196144

Epoch: 6| Step: 5
Training loss: 1.3977789153872902
Validation loss: 2.4283032380161536

Epoch: 6| Step: 6
Training loss: 1.8008671737991218
Validation loss: 2.4316253272860826

Epoch: 6| Step: 7
Training loss: 2.0434586063501996
Validation loss: 2.436398335300043

Epoch: 6| Step: 8
Training loss: 1.721394325361165
Validation loss: 2.4210924517740198

Epoch: 6| Step: 9
Training loss: 1.6671740315973886
Validation loss: 2.4566914206201456

Epoch: 6| Step: 10
Training loss: 2.2027417654477346
Validation loss: 2.442241530079582

Epoch: 6| Step: 11
Training loss: 2.493124280553156
Validation loss: 2.4297086331436586

Epoch: 6| Step: 12
Training loss: 1.7223940972049416
Validation loss: 2.5160319985610053

Epoch: 6| Step: 13
Training loss: 2.417130381939435
Validation loss: 2.4325735928274677

Epoch: 290| Step: 0
Training loss: 2.5352079741810285
Validation loss: 2.4463950583048857

Epoch: 6| Step: 1
Training loss: 1.4571911926026406
Validation loss: 2.4181256506500772

Epoch: 6| Step: 2
Training loss: 0.9866353680075438
Validation loss: 2.4724570589092068

Epoch: 6| Step: 3
Training loss: 1.466924953837254
Validation loss: 2.437859068349775

Epoch: 6| Step: 4
Training loss: 2.3628695042593733
Validation loss: 2.470465588794933

Epoch: 6| Step: 5
Training loss: 1.6901780530142714
Validation loss: 2.4873962069857734

Epoch: 6| Step: 6
Training loss: 1.4480170436983615
Validation loss: 2.4932157283147895

Epoch: 6| Step: 7
Training loss: 1.8910088898133581
Validation loss: 2.424606193202929

Epoch: 6| Step: 8
Training loss: 1.9866436582978166
Validation loss: 2.4632872723928196

Epoch: 6| Step: 9
Training loss: 1.9249945033601834
Validation loss: 2.4824091513708244

Epoch: 6| Step: 10
Training loss: 2.122230744913418
Validation loss: 2.368224139113855

Epoch: 6| Step: 11
Training loss: 1.5177698591124091
Validation loss: 2.4008565668579047

Epoch: 6| Step: 12
Training loss: 1.7490864140148725
Validation loss: 2.3668711168710996

Epoch: 6| Step: 13
Training loss: 2.345729449757312
Validation loss: 2.4882380579872416

Epoch: 291| Step: 0
Training loss: 1.5232489053436458
Validation loss: 2.470907346330131

Epoch: 6| Step: 1
Training loss: 2.264166105754934
Validation loss: 2.4778974744492586

Epoch: 6| Step: 2
Training loss: 1.211355469464849
Validation loss: 2.46651935751416

Epoch: 6| Step: 3
Training loss: 2.0796349568253323
Validation loss: 2.4257125645291278

Epoch: 6| Step: 4
Training loss: 1.5418020738814124
Validation loss: 2.431352814699142

Epoch: 6| Step: 5
Training loss: 2.053033547418593
Validation loss: 2.4533970597509853

Epoch: 6| Step: 6
Training loss: 2.143377163776532
Validation loss: 2.461965274090632

Epoch: 6| Step: 7
Training loss: 1.5909199739059168
Validation loss: 2.470955478955648

Epoch: 6| Step: 8
Training loss: 1.31718363009028
Validation loss: 2.4575069280119117

Epoch: 6| Step: 9
Training loss: 2.0326666953409123
Validation loss: 2.569192845395428

Epoch: 6| Step: 10
Training loss: 1.3944413185506759
Validation loss: 2.4528851971562475

Epoch: 6| Step: 11
Training loss: 2.0472902066131207
Validation loss: 2.4184058815391256

Epoch: 6| Step: 12
Training loss: 1.477700173619752
Validation loss: 2.4796907555701138

Epoch: 6| Step: 13
Training loss: 2.4067213909588143
Validation loss: 2.42247728367161

Epoch: 292| Step: 0
Training loss: 2.322276918273108
Validation loss: 2.4264881417902977

Epoch: 6| Step: 1
Training loss: 2.1301930869255608
Validation loss: 2.489897546252949

Epoch: 6| Step: 2
Training loss: 1.778284113356857
Validation loss: 2.5346824377285357

Epoch: 6| Step: 3
Training loss: 1.8679031851959396
Validation loss: 2.4700868610292357

Epoch: 6| Step: 4
Training loss: 1.591583424866358
Validation loss: 2.4359902112120815

Epoch: 6| Step: 5
Training loss: 2.0337746995810537
Validation loss: 2.5047676299656363

Epoch: 6| Step: 6
Training loss: 1.9916779708009473
Validation loss: 2.357646647285838

Epoch: 6| Step: 7
Training loss: 1.5536052828578133
Validation loss: 2.497610316979285

Epoch: 6| Step: 8
Training loss: 1.517387152282739
Validation loss: 2.4156260787213686

Epoch: 6| Step: 9
Training loss: 1.2918517021215528
Validation loss: 2.4369785580921643

Epoch: 6| Step: 10
Training loss: 1.772899731003425
Validation loss: 2.567699059364787

Epoch: 6| Step: 11
Training loss: 1.8263545796596894
Validation loss: 2.3937659104872653

Epoch: 6| Step: 12
Training loss: 1.9665118619908781
Validation loss: 2.4289349562832108

Epoch: 6| Step: 13
Training loss: 1.5712526458256675
Validation loss: 2.438895287630971

Epoch: 293| Step: 0
Training loss: 1.9212430830007616
Validation loss: 2.4835850434940543

Epoch: 6| Step: 1
Training loss: 1.9110776711034625
Validation loss: 2.4254367367011125

Epoch: 6| Step: 2
Training loss: 1.9436465563954122
Validation loss: 2.5231712894516414

Epoch: 6| Step: 3
Training loss: 1.9033131724067587
Validation loss: 2.5226904702028192

Epoch: 6| Step: 4
Training loss: 2.0487562081485553
Validation loss: 2.4752882224392003

Epoch: 6| Step: 5
Training loss: 1.4434099201442399
Validation loss: 2.4680996670801214

Epoch: 6| Step: 6
Training loss: 1.3631761395613857
Validation loss: 2.3692542944285964

Epoch: 6| Step: 7
Training loss: 1.9716344018565792
Validation loss: 2.5283787996339417

Epoch: 6| Step: 8
Training loss: 1.99226044166022
Validation loss: 2.536948307038876

Epoch: 6| Step: 9
Training loss: 2.2604471957581294
Validation loss: 2.4066026288338147

Epoch: 6| Step: 10
Training loss: 1.9616588466405231
Validation loss: 2.407012188018094

Epoch: 6| Step: 11
Training loss: 1.8551704889800218
Validation loss: 2.4846657089975803

Epoch: 6| Step: 12
Training loss: 1.46300160861758
Validation loss: 2.4458105046768894

Epoch: 6| Step: 13
Training loss: 2.0995913198714975
Validation loss: 2.4628796205042773

Epoch: 294| Step: 0
Training loss: 1.4820382447346632
Validation loss: 2.4986708881654724

Epoch: 6| Step: 1
Training loss: 1.764257390868847
Validation loss: 2.5222045381415255

Epoch: 6| Step: 2
Training loss: 1.830716374996059
Validation loss: 2.473604079542784

Epoch: 6| Step: 3
Training loss: 1.8064756575865164
Validation loss: 2.4645161834002303

Epoch: 6| Step: 4
Training loss: 1.8754359692123532
Validation loss: 2.432755688306726

Epoch: 6| Step: 5
Training loss: 1.683892809865636
Validation loss: 2.4602680963295267

Epoch: 6| Step: 6
Training loss: 1.63553418103766
Validation loss: 2.445853332786035

Epoch: 6| Step: 7
Training loss: 2.4239219628919453
Validation loss: 2.460247806095151

Epoch: 6| Step: 8
Training loss: 1.8593317235189923
Validation loss: 2.444473246816141

Epoch: 6| Step: 9
Training loss: 1.565708756633479
Validation loss: 2.4726863801511665

Epoch: 6| Step: 10
Training loss: 2.0802337731525165
Validation loss: 2.447456786542526

Epoch: 6| Step: 11
Training loss: 1.6939113469711764
Validation loss: 2.4168905133999186

Epoch: 6| Step: 12
Training loss: 1.7558390071990257
Validation loss: 2.5201988964269333

Epoch: 6| Step: 13
Training loss: 1.7220415675189322
Validation loss: 2.459029692613822

Epoch: 295| Step: 0
Training loss: 1.730551551921711
Validation loss: 2.4706892810910173

Epoch: 6| Step: 1
Training loss: 1.5044275742628466
Validation loss: 2.4722859553888332

Epoch: 6| Step: 2
Training loss: 1.734568954482705
Validation loss: 2.483969227746779

Epoch: 6| Step: 3
Training loss: 1.9011030910096602
Validation loss: 2.4436036796816025

Epoch: 6| Step: 4
Training loss: 2.2972083855360506
Validation loss: 2.486193020037447

Epoch: 6| Step: 5
Training loss: 1.9257288803810475
Validation loss: 2.4151468204297277

Epoch: 6| Step: 6
Training loss: 2.0224260431260648
Validation loss: 2.4988353569847415

Epoch: 6| Step: 7
Training loss: 1.4966659049447775
Validation loss: 2.389718111254049

Epoch: 6| Step: 8
Training loss: 1.7675410314219044
Validation loss: 2.407147495187913

Epoch: 6| Step: 9
Training loss: 0.975264334914821
Validation loss: 2.489174028168044

Epoch: 6| Step: 10
Training loss: 1.5318667668308497
Validation loss: 2.5076780868756927

Epoch: 6| Step: 11
Training loss: 2.1149499760116064
Validation loss: 2.4812733265249447

Epoch: 6| Step: 12
Training loss: 1.6603216829338563
Validation loss: 2.3817545677413907

Epoch: 6| Step: 13
Training loss: 2.9109952190940436
Validation loss: 2.452409145374992

Epoch: 296| Step: 0
Training loss: 1.3372044495223563
Validation loss: 2.4202773488679488

Epoch: 6| Step: 1
Training loss: 2.3982737730723507
Validation loss: 2.514599888244606

Epoch: 6| Step: 2
Training loss: 2.071310932596115
Validation loss: 2.4122810144939906

Epoch: 6| Step: 3
Training loss: 1.735560244161666
Validation loss: 2.5048850088384333

Epoch: 6| Step: 4
Training loss: 1.9354408150416413
Validation loss: 2.45298645890745

Epoch: 6| Step: 5
Training loss: 1.7771792828266104
Validation loss: 2.4027281702957906

Epoch: 6| Step: 6
Training loss: 1.8596088038033654
Validation loss: 2.4408389987008117

Epoch: 6| Step: 7
Training loss: 1.296059133516921
Validation loss: 2.466379643774547

Epoch: 6| Step: 8
Training loss: 2.075096849686152
Validation loss: 2.4375248043458955

Epoch: 6| Step: 9
Training loss: 1.7276275249838395
Validation loss: 2.446408677111403

Epoch: 6| Step: 10
Training loss: 1.7281016398225462
Validation loss: 2.469803037888995

Epoch: 6| Step: 11
Training loss: 1.4058472374479305
Validation loss: 2.531723112948354

Epoch: 6| Step: 12
Training loss: 2.1555820480938443
Validation loss: 2.477122230017062

Epoch: 6| Step: 13
Training loss: 1.6456951453547197
Validation loss: 2.4535021319921992

Epoch: 297| Step: 0
Training loss: 1.302314839445531
Validation loss: 2.4827150028316862

Epoch: 6| Step: 1
Training loss: 1.7605108277308308
Validation loss: 2.404514020542167

Epoch: 6| Step: 2
Training loss: 1.5762586983328035
Validation loss: 2.4296611954209095

Epoch: 6| Step: 3
Training loss: 2.344239654254571
Validation loss: 2.5474691557942837

Epoch: 6| Step: 4
Training loss: 1.3983932573363247
Validation loss: 2.445007115915372

Epoch: 6| Step: 5
Training loss: 2.185656397361923
Validation loss: 2.403677152052045

Epoch: 6| Step: 6
Training loss: 1.5957007343923342
Validation loss: 2.5139122856503398

Epoch: 6| Step: 7
Training loss: 1.9739254937841464
Validation loss: 2.507827081498304

Epoch: 6| Step: 8
Training loss: 1.762977167562634
Validation loss: 2.4789015008654744

Epoch: 6| Step: 9
Training loss: 1.6793898207788143
Validation loss: 2.458920763374589

Epoch: 6| Step: 10
Training loss: 2.0369891737442827
Validation loss: 2.473599772265057

Epoch: 6| Step: 11
Training loss: 1.8667361939061342
Validation loss: 2.457712795581945

Epoch: 6| Step: 12
Training loss: 2.2705571651222285
Validation loss: 2.4667629076278703

Epoch: 6| Step: 13
Training loss: 1.9570381941072534
Validation loss: 2.4832380947419663

Epoch: 298| Step: 0
Training loss: 1.494332733769112
Validation loss: 2.4456106648433122

Epoch: 6| Step: 1
Training loss: 1.8873780798535427
Validation loss: 2.4121662033724895

Epoch: 6| Step: 2
Training loss: 1.830115970313896
Validation loss: 2.485544853995247

Epoch: 6| Step: 3
Training loss: 1.6415822460846732
Validation loss: 2.4238347064205357

Epoch: 6| Step: 4
Training loss: 1.4270945731878262
Validation loss: 2.4662059398004104

Epoch: 6| Step: 5
Training loss: 2.1840303424711656
Validation loss: 2.437193726407374

Epoch: 6| Step: 6
Training loss: 1.73503691268483
Validation loss: 2.4413603637320898

Epoch: 6| Step: 7
Training loss: 1.981237739982338
Validation loss: 2.4431771823867083

Epoch: 6| Step: 8
Training loss: 1.171232225248612
Validation loss: 2.393276610252274

Epoch: 6| Step: 9
Training loss: 2.2132121001596228
Validation loss: 2.3661695346737392

Epoch: 6| Step: 10
Training loss: 2.090335624066201
Validation loss: 2.400771415039485

Epoch: 6| Step: 11
Training loss: 2.81673519419839
Validation loss: 2.4410051423064805

Epoch: 6| Step: 12
Training loss: 1.9204262335846531
Validation loss: 2.4076833015987287

Epoch: 6| Step: 13
Training loss: 1.8350918384614348
Validation loss: 2.451765595181231

Epoch: 299| Step: 0
Training loss: 1.8007653622536663
Validation loss: 2.482270513752382

Epoch: 6| Step: 1
Training loss: 1.5059076640380853
Validation loss: 2.479632256263764

Epoch: 6| Step: 2
Training loss: 1.4639766313741052
Validation loss: 2.472529042718925

Epoch: 6| Step: 3
Training loss: 1.0274348345509108
Validation loss: 2.4229349167636878

Epoch: 6| Step: 4
Training loss: 1.3237951270634325
Validation loss: 2.4147103899058737

Epoch: 6| Step: 5
Training loss: 2.3009754351548466
Validation loss: 2.537753930513403

Epoch: 6| Step: 6
Training loss: 1.802165130640451
Validation loss: 2.426046058352358

Epoch: 6| Step: 7
Training loss: 1.724902222115081
Validation loss: 2.4253930280274623

Epoch: 6| Step: 8
Training loss: 2.038880087925588
Validation loss: 2.482551533433136

Epoch: 6| Step: 9
Training loss: 2.3731025343909837
Validation loss: 2.4382833626663363

Epoch: 6| Step: 10
Training loss: 1.7760669188135225
Validation loss: 2.478540985979176

Epoch: 6| Step: 11
Training loss: 2.1780851209976904
Validation loss: 2.434651203818236

Epoch: 6| Step: 12
Training loss: 1.8687551134734859
Validation loss: 2.4857153047431284

Epoch: 6| Step: 13
Training loss: 2.0649704442899455
Validation loss: 2.452229471365249

Epoch: 300| Step: 0
Training loss: 1.9639425163674789
Validation loss: 2.4494259641258616

Epoch: 6| Step: 1
Training loss: 1.721141261459263
Validation loss: 2.4588363378618983

Epoch: 6| Step: 2
Training loss: 1.4477144644448172
Validation loss: 2.4844967577571624

Epoch: 6| Step: 3
Training loss: 2.028357926498852
Validation loss: 2.466558723560054

Epoch: 6| Step: 4
Training loss: 2.097371286255356
Validation loss: 2.3940855562742747

Epoch: 6| Step: 5
Training loss: 1.7839698772538786
Validation loss: 2.416731080019647

Epoch: 6| Step: 6
Training loss: 1.2646271810623098
Validation loss: 2.4824492511585667

Epoch: 6| Step: 7
Training loss: 2.0174478967076634
Validation loss: 2.433646287556573

Epoch: 6| Step: 8
Training loss: 1.375909374537881
Validation loss: 2.474825882320881

Epoch: 6| Step: 9
Training loss: 1.7883237287909897
Validation loss: 2.546574315960434

Epoch: 6| Step: 10
Training loss: 1.8710546310253728
Validation loss: 2.476127477353903

Epoch: 6| Step: 11
Training loss: 1.4777662426554914
Validation loss: 2.45920297985015

Epoch: 6| Step: 12
Training loss: 2.413995143111178
Validation loss: 2.3755793601532713

Epoch: 6| Step: 13
Training loss: 1.6509813684790453
Validation loss: 2.4428165722376884

Testing loss: 2.8192079287223253
