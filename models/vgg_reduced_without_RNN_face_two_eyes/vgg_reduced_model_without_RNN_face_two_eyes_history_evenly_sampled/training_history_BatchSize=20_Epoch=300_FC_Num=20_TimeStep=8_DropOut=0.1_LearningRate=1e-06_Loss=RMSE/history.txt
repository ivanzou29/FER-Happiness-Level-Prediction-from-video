Epoch: 1| Step: 0
Training loss: 4.241574631287678
Validation loss: 4.008645131642637

Epoch: 5| Step: 1
Training loss: 3.9976611452145376
Validation loss: 4.001966141917332

Epoch: 5| Step: 2
Training loss: 4.061522850482345
Validation loss: 3.9971558498591016

Epoch: 5| Step: 3
Training loss: 3.740823708262177
Validation loss: 3.992882867508762

Epoch: 5| Step: 4
Training loss: 4.301092124464991
Validation loss: 3.9868698040281965

Epoch: 5| Step: 5
Training loss: 4.94276205769944
Validation loss: 3.982395852405988

Epoch: 5| Step: 6
Training loss: 2.792430820547346
Validation loss: 3.975054008440482

Epoch: 5| Step: 7
Training loss: 4.1309916590077975
Validation loss: 3.9685338880115695

Epoch: 5| Step: 8
Training loss: 3.751614032536009
Validation loss: 3.9650003129635465

Epoch: 5| Step: 9
Training loss: 4.302073160795265
Validation loss: 3.95797897505713

Epoch: 5| Step: 10
Training loss: 4.917673018746928
Validation loss: 3.954746499873841

Epoch: 2| Step: 0
Training loss: 4.378796483347693
Validation loss: 3.9502740278165938

Epoch: 5| Step: 1
Training loss: 4.643166408089731
Validation loss: 3.944007067387669

Epoch: 5| Step: 2
Training loss: 3.688583344198307
Validation loss: 3.937253032439015

Epoch: 5| Step: 3
Training loss: 3.9130007584861373
Validation loss: 3.934655560144842

Epoch: 5| Step: 4
Training loss: 3.625683687126702
Validation loss: 3.9295724267110055

Epoch: 5| Step: 5
Training loss: 3.7373120876265906
Validation loss: 3.923683802133717

Epoch: 5| Step: 6
Training loss: 3.508862990193227
Validation loss: 3.9152522198158612

Epoch: 5| Step: 7
Training loss: 3.8544601466159416
Validation loss: 3.9096375023221395

Epoch: 5| Step: 8
Training loss: 4.559569789602937
Validation loss: 3.90916268518827

Epoch: 5| Step: 9
Training loss: 4.161768641100307
Validation loss: 3.9011214942649977

Epoch: 5| Step: 10
Training loss: 4.7111484360165985
Validation loss: 3.8976112105072915

Epoch: 3| Step: 0
Training loss: 3.7760235946047422
Validation loss: 3.8898780785468645

Epoch: 5| Step: 1
Training loss: 5.5582813167092135
Validation loss: 3.888638827541131

Epoch: 5| Step: 2
Training loss: 4.586598545241339
Validation loss: 3.880271879497423

Epoch: 5| Step: 3
Training loss: 3.967423945889632
Validation loss: 3.8775851081468975

Epoch: 5| Step: 4
Training loss: 4.105561666408104
Validation loss: 3.8695119392519692

Epoch: 5| Step: 5
Training loss: 2.630393436578465
Validation loss: 3.866286190699814

Epoch: 5| Step: 6
Training loss: 3.3196177754355687
Validation loss: 3.8586434068674476

Epoch: 5| Step: 7
Training loss: 4.007959790711474
Validation loss: 3.8524768099140423

Epoch: 5| Step: 8
Training loss: 4.218209465154492
Validation loss: 3.8482075650781806

Epoch: 5| Step: 9
Training loss: 4.244660108278925
Validation loss: 3.845142899472568

Epoch: 5| Step: 10
Training loss: 3.049410503514624
Validation loss: 3.842989997418198

Epoch: 4| Step: 0
Training loss: 3.641308503393021
Validation loss: 3.8350750286663184

Epoch: 5| Step: 1
Training loss: 3.8591974503298383
Validation loss: 3.8319860063939126

Epoch: 5| Step: 2
Training loss: 3.6264658627830295
Validation loss: 3.8279876637471277

Epoch: 5| Step: 3
Training loss: 3.611076977560325
Validation loss: 3.8198237553271133

Epoch: 5| Step: 4
Training loss: 4.576742230315033
Validation loss: 3.8198461337896883

Epoch: 5| Step: 5
Training loss: 5.025443570880729
Validation loss: 3.8146762322168786

Epoch: 5| Step: 6
Training loss: 3.9290574404818095
Validation loss: 3.811391853978907

Epoch: 5| Step: 7
Training loss: 3.229355312292568
Validation loss: 3.8046418827156656

Epoch: 5| Step: 8
Training loss: 4.211452473873742
Validation loss: 3.80248925299184

Epoch: 5| Step: 9
Training loss: 3.444472576012806
Validation loss: 3.7975479367559086

Epoch: 5| Step: 10
Training loss: 4.347638482317131
Validation loss: 3.789776214610662

Epoch: 5| Step: 0
Training loss: 3.9153733789894694
Validation loss: 3.7866250025571406

Epoch: 5| Step: 1
Training loss: 3.931971710863925
Validation loss: 3.7833837273693556

Epoch: 5| Step: 2
Training loss: 3.880540148310718
Validation loss: 3.777711218998184

Epoch: 5| Step: 3
Training loss: 3.1351899902596676
Validation loss: 3.7712069969707405

Epoch: 5| Step: 4
Training loss: 3.8747686501628915
Validation loss: 3.7641777709533297

Epoch: 5| Step: 5
Training loss: 4.845801331317921
Validation loss: 3.760108806756805

Epoch: 5| Step: 6
Training loss: 4.613572927842635
Validation loss: 3.754829238207929

Epoch: 5| Step: 7
Training loss: 3.1675158081623676
Validation loss: 3.748562078401942

Epoch: 5| Step: 8
Training loss: 4.329631006319003
Validation loss: 3.7457158463525824

Epoch: 5| Step: 9
Training loss: 3.6519388719020047
Validation loss: 3.743751000762997

Epoch: 5| Step: 10
Training loss: 3.467550946819184
Validation loss: 3.7347689644889837

Epoch: 6| Step: 0
Training loss: 4.325668353880551
Validation loss: 3.7329912361472504

Epoch: 5| Step: 1
Training loss: 4.508545708487115
Validation loss: 3.727347718122839

Epoch: 5| Step: 2
Training loss: 2.8368659903414124
Validation loss: 3.7198325008905115

Epoch: 5| Step: 3
Training loss: 4.0009387822005
Validation loss: 3.714993289092431

Epoch: 5| Step: 4
Training loss: 4.114857312830671
Validation loss: 3.7105869060675096

Epoch: 5| Step: 5
Training loss: 3.780667851300279
Validation loss: 3.706011105996053

Epoch: 5| Step: 6
Training loss: 2.651598818726391
Validation loss: 3.6979340629855932

Epoch: 5| Step: 7
Training loss: 3.9535797219479276
Validation loss: 3.693954958303808

Epoch: 5| Step: 8
Training loss: 3.4865569394887794
Validation loss: 3.6878530209240363

Epoch: 5| Step: 9
Training loss: 4.182164223115985
Validation loss: 3.683299613653149

Epoch: 5| Step: 10
Training loss: 4.451573151682478
Validation loss: 3.6778525391215915

Epoch: 7| Step: 0
Training loss: 3.2057386202431353
Validation loss: 3.6715191635761855

Epoch: 5| Step: 1
Training loss: 4.3424221726264
Validation loss: 3.6656104260363778

Epoch: 5| Step: 2
Training loss: 3.3299031410221027
Validation loss: 3.6598671857344027

Epoch: 5| Step: 3
Training loss: 3.9300866957558616
Validation loss: 3.6530977348392923

Epoch: 5| Step: 4
Training loss: 4.013351331102268
Validation loss: 3.6467447789940235

Epoch: 5| Step: 5
Training loss: 3.9925423481223454
Validation loss: 3.640363197678539

Epoch: 5| Step: 6
Training loss: 3.3447516536467625
Validation loss: 3.6354510804630804

Epoch: 5| Step: 7
Training loss: 3.7405850796334086
Validation loss: 3.631861099214105

Epoch: 5| Step: 8
Training loss: 4.762030174329598
Validation loss: 3.625134535949588

Epoch: 5| Step: 9
Training loss: 2.9195506596704783
Validation loss: 3.6166939446641826

Epoch: 5| Step: 10
Training loss: 4.142868643307814
Validation loss: 3.6134985591302815

Epoch: 8| Step: 0
Training loss: 4.212369714188059
Validation loss: 3.6055044868066997

Epoch: 5| Step: 1
Training loss: 3.945560983821031
Validation loss: 3.5990706012042026

Epoch: 5| Step: 2
Training loss: 3.659835622254282
Validation loss: 3.590065294203777

Epoch: 5| Step: 3
Training loss: 3.7649954748443117
Validation loss: 3.590249444078267

Epoch: 5| Step: 4
Training loss: 3.3672996555422334
Validation loss: 3.5790197752261523

Epoch: 5| Step: 5
Training loss: 4.033379517177853
Validation loss: 3.5688032479291016

Epoch: 5| Step: 6
Training loss: 3.248393028288811
Validation loss: 3.568390207299843

Epoch: 5| Step: 7
Training loss: 3.664374429727764
Validation loss: 3.559023951860131

Epoch: 5| Step: 8
Training loss: 3.267009678821921
Validation loss: 3.5522341637396435

Epoch: 5| Step: 9
Training loss: 3.6917383438167097
Validation loss: 3.5436671842414302

Epoch: 5| Step: 10
Training loss: 4.438175418654938
Validation loss: 3.5363146860744985

Epoch: 9| Step: 0
Training loss: 3.20467030535939
Validation loss: 3.5315399138031416

Epoch: 5| Step: 1
Training loss: 4.123243015526479
Validation loss: 3.52624191728827

Epoch: 5| Step: 2
Training loss: 4.210147705749008
Validation loss: 3.5198491082380365

Epoch: 5| Step: 3
Training loss: 3.415784039507361
Validation loss: 3.5071353342325615

Epoch: 5| Step: 4
Training loss: 3.827901156362115
Validation loss: 3.5010409997130285

Epoch: 5| Step: 5
Training loss: 3.8875228586782105
Validation loss: 3.4972394759652228

Epoch: 5| Step: 6
Training loss: 3.5497375230062813
Validation loss: 3.4870493487684664

Epoch: 5| Step: 7
Training loss: 3.6262611300098095
Validation loss: 3.4787639870967326

Epoch: 5| Step: 8
Training loss: 3.5028256862697456
Validation loss: 3.475076382991872

Epoch: 5| Step: 9
Training loss: 3.0607419320021747
Validation loss: 3.466148334243804

Epoch: 5| Step: 10
Training loss: 4.069841764031242
Validation loss: 3.4596804058454937

Epoch: 10| Step: 0
Training loss: 3.2514477952910346
Validation loss: 3.4482666220698537

Epoch: 5| Step: 1
Training loss: 3.5309772217306725
Validation loss: 3.4448522493278664

Epoch: 5| Step: 2
Training loss: 3.549396307750812
Validation loss: 3.4342134412944083

Epoch: 5| Step: 3
Training loss: 3.5034285509966487
Validation loss: 3.427112445445207

Epoch: 5| Step: 4
Training loss: 3.9561041059305366
Validation loss: 3.4135824089189017

Epoch: 5| Step: 5
Training loss: 3.988439424163562
Validation loss: 3.408130874194699

Epoch: 5| Step: 6
Training loss: 3.721226869100555
Validation loss: 3.4060163399907495

Epoch: 5| Step: 7
Training loss: 2.9139096626516627
Validation loss: 3.3940085959078177

Epoch: 5| Step: 8
Training loss: 3.413724904423831
Validation loss: 3.3834591677308388

Epoch: 5| Step: 9
Training loss: 4.113406216569748
Validation loss: 3.3771382603166415

Epoch: 5| Step: 10
Training loss: 3.629464524342327
Validation loss: 3.368273775838685

Epoch: 11| Step: 0
Training loss: 2.2810459829576404
Validation loss: 3.3636512929613236

Epoch: 5| Step: 1
Training loss: 3.3068495727784266
Validation loss: 3.3526424419034804

Epoch: 5| Step: 2
Training loss: 3.4525982899523986
Validation loss: 3.3425960625466447

Epoch: 5| Step: 3
Training loss: 3.2394958353441226
Validation loss: 3.3320915390692614

Epoch: 5| Step: 4
Training loss: 3.2371889119569124
Validation loss: 3.325011485521981

Epoch: 5| Step: 5
Training loss: 3.9422455301447537
Validation loss: 3.3167235183810817

Epoch: 5| Step: 6
Training loss: 3.8432490324737416
Validation loss: 3.309706920666285

Epoch: 5| Step: 7
Training loss: 4.008443503871605
Validation loss: 3.298959903004385

Epoch: 5| Step: 8
Training loss: 3.651191929633259
Validation loss: 3.29091278379955

Epoch: 5| Step: 9
Training loss: 3.6579540226937124
Validation loss: 3.2825852059971092

Epoch: 5| Step: 10
Training loss: 3.886980916291682
Validation loss: 3.2750574637472893

Epoch: 12| Step: 0
Training loss: 3.9291059848688263
Validation loss: 3.2619998006399307

Epoch: 5| Step: 1
Training loss: 2.5062033936692876
Validation loss: 3.2549666797483825

Epoch: 5| Step: 2
Training loss: 3.061643675370157
Validation loss: 3.2476618143788976

Epoch: 5| Step: 3
Training loss: 3.8477451062471544
Validation loss: 3.2345132495529234

Epoch: 5| Step: 4
Training loss: 3.594134500915199
Validation loss: 3.222074568461515

Epoch: 5| Step: 5
Training loss: 3.084183824792599
Validation loss: 3.2134668543577853

Epoch: 5| Step: 6
Training loss: 3.4168935250742503
Validation loss: 3.2033857902211595

Epoch: 5| Step: 7
Training loss: 3.6866642926319426
Validation loss: 3.200204923949037

Epoch: 5| Step: 8
Training loss: 3.5683873034022695
Validation loss: 3.1870637145101988

Epoch: 5| Step: 9
Training loss: 3.1905094973947827
Validation loss: 3.1739247765602987

Epoch: 5| Step: 10
Training loss: 3.7287795791194474
Validation loss: 3.163484095882039

Epoch: 13| Step: 0
Training loss: 3.5270648563003935
Validation loss: 3.151123539386338

Epoch: 5| Step: 1
Training loss: 3.749460817357402
Validation loss: 3.1468332145818447

Epoch: 5| Step: 2
Training loss: 3.500067846458061
Validation loss: 3.1311409464079625

Epoch: 5| Step: 3
Training loss: 3.1438313528649
Validation loss: 3.130144142184887

Epoch: 5| Step: 4
Training loss: 3.060926071854464
Validation loss: 3.1111182231304175

Epoch: 5| Step: 5
Training loss: 3.717918623626227
Validation loss: 3.104480408491651

Epoch: 5| Step: 6
Training loss: 3.4915500545527434
Validation loss: 3.0938727556578742

Epoch: 5| Step: 7
Training loss: 2.9379666546201078
Validation loss: 3.079057963420985

Epoch: 5| Step: 8
Training loss: 3.1737022210604238
Validation loss: 3.069083839187108

Epoch: 5| Step: 9
Training loss: 3.06239069529508
Validation loss: 3.0613656738169848

Epoch: 5| Step: 10
Training loss: 3.316459879986351
Validation loss: 3.046680271940194

Epoch: 14| Step: 0
Training loss: 3.387973152702816
Validation loss: 3.0346929730026972

Epoch: 5| Step: 1
Training loss: 3.162173463149573
Validation loss: 3.027310052817142

Epoch: 5| Step: 2
Training loss: 3.5186673034382148
Validation loss: 3.0187133569433326

Epoch: 5| Step: 3
Training loss: 2.7334615871144012
Validation loss: 3.00553852788899

Epoch: 5| Step: 4
Training loss: 3.0564111397979423
Validation loss: 3.00042282050841

Epoch: 5| Step: 5
Training loss: 3.0907266659885244
Validation loss: 2.9869712004612685

Epoch: 5| Step: 6
Training loss: 4.210293580825827
Validation loss: 2.9731288642715654

Epoch: 5| Step: 7
Training loss: 2.4788644002657314
Validation loss: 2.96507686198079

Epoch: 5| Step: 8
Training loss: 2.8095423087433904
Validation loss: 2.9528402336709947

Epoch: 5| Step: 9
Training loss: 3.432010498262012
Validation loss: 2.9437498171509113

Epoch: 5| Step: 10
Training loss: 3.496742640113299
Validation loss: 2.9345281872054763

Epoch: 15| Step: 0
Training loss: 3.547696056365259
Validation loss: 2.919497840945698

Epoch: 5| Step: 1
Training loss: 3.4817927760952325
Validation loss: 2.9122873897551647

Epoch: 5| Step: 2
Training loss: 2.6206265301726095
Validation loss: 2.8974218065716437

Epoch: 5| Step: 3
Training loss: 2.8290949891514074
Validation loss: 2.8864598991376265

Epoch: 5| Step: 4
Training loss: 3.250045776044811
Validation loss: 2.8798308623689164

Epoch: 5| Step: 5
Training loss: 3.008289012071707
Validation loss: 2.8707595663075307

Epoch: 5| Step: 6
Training loss: 2.879983977167275
Validation loss: 2.8564500862630706

Epoch: 5| Step: 7
Training loss: 3.224456173488189
Validation loss: 2.8524755850335

Epoch: 5| Step: 8
Training loss: 2.909561895314904
Validation loss: 2.8404055318442496

Epoch: 5| Step: 9
Training loss: 3.4232209924566366
Validation loss: 2.830889399416553

Epoch: 5| Step: 10
Training loss: 3.3488475411431917
Validation loss: 2.8167285542194738

Epoch: 16| Step: 0
Training loss: 3.3517318007028507
Validation loss: 2.8063918276953363

Epoch: 5| Step: 1
Training loss: 3.3621091140387085
Validation loss: 2.798561290423487

Epoch: 5| Step: 2
Training loss: 3.173864032248804
Validation loss: 2.787379744073237

Epoch: 5| Step: 3
Training loss: 2.877439541948
Validation loss: 2.77072867868876

Epoch: 5| Step: 4
Training loss: 2.353261137693336
Validation loss: 2.7724024804302836

Epoch: 5| Step: 5
Training loss: 3.686320229291772
Validation loss: 2.7591596769463003

Epoch: 5| Step: 6
Training loss: 2.866682210776599
Validation loss: 2.7515598862347996

Epoch: 5| Step: 7
Training loss: 3.1791393360514704
Validation loss: 2.7350513963541285

Epoch: 5| Step: 8
Training loss: 2.735266055289502
Validation loss: 2.7291924764174733

Epoch: 5| Step: 9
Training loss: 2.1569918033760684
Validation loss: 2.725622080114533

Epoch: 5| Step: 10
Training loss: 3.6062193447773647
Validation loss: 2.7099739706000774

Epoch: 17| Step: 0
Training loss: 3.1067463100304304
Validation loss: 2.701922250881866

Epoch: 5| Step: 1
Training loss: 2.836021064809199
Validation loss: 2.6931550876812

Epoch: 5| Step: 2
Training loss: 2.2866414778112625
Validation loss: 2.6937041836905493

Epoch: 5| Step: 3
Training loss: 3.207806399451548
Validation loss: 2.6809234624533556

Epoch: 5| Step: 4
Training loss: 3.642525631114713
Validation loss: 2.675286212491401

Epoch: 5| Step: 5
Training loss: 3.1734519007781943
Validation loss: 2.659800232577943

Epoch: 5| Step: 6
Training loss: 3.255736203944554
Validation loss: 2.659443845528112

Epoch: 5| Step: 7
Training loss: 2.6758494124815
Validation loss: 2.6482317928675196

Epoch: 5| Step: 8
Training loss: 3.1473786724724704
Validation loss: 2.63113290640538

Epoch: 5| Step: 9
Training loss: 2.430029645668321
Validation loss: 2.637654876244137

Epoch: 5| Step: 10
Training loss: 2.8065567800465474
Validation loss: 2.618496769900394

Epoch: 18| Step: 0
Training loss: 2.816153378714929
Validation loss: 2.614000211694082

Epoch: 5| Step: 1
Training loss: 2.60329464363072
Validation loss: 2.60817689968742

Epoch: 5| Step: 2
Training loss: 3.204536982758156
Validation loss: 2.597113308514717

Epoch: 5| Step: 3
Training loss: 3.0875989087281397
Validation loss: 2.595793457652002

Epoch: 5| Step: 4
Training loss: 2.7215177982665737
Validation loss: 2.5947676420527044

Epoch: 5| Step: 5
Training loss: 3.3507098911875888
Validation loss: 2.5815017298961593

Epoch: 5| Step: 6
Training loss: 2.939195508852348
Validation loss: 2.5730963296292875

Epoch: 5| Step: 7
Training loss: 2.85387253928044
Validation loss: 2.5740317786645273

Epoch: 5| Step: 8
Training loss: 2.4170440729910676
Validation loss: 2.5771902588027698

Epoch: 5| Step: 9
Training loss: 3.292784842970267
Validation loss: 2.5657612646640575

Epoch: 5| Step: 10
Training loss: 2.946435203379644
Validation loss: 2.566538619784236

Epoch: 19| Step: 0
Training loss: 2.449292049497505
Validation loss: 2.5584478686615477

Epoch: 5| Step: 1
Training loss: 2.665024032913831
Validation loss: 2.553221912728411

Epoch: 5| Step: 2
Training loss: 3.2728552106934967
Validation loss: 2.5543710061557414

Epoch: 5| Step: 3
Training loss: 3.149735327606459
Validation loss: 2.5462785439252067

Epoch: 5| Step: 4
Training loss: 2.412984761765033
Validation loss: 2.5424997432684937

Epoch: 5| Step: 5
Training loss: 3.0929619912625066
Validation loss: 2.5458671830063824

Epoch: 5| Step: 6
Training loss: 2.6710994554153564
Validation loss: 2.5326191561626707

Epoch: 5| Step: 7
Training loss: 3.2596291432913707
Validation loss: 2.5319769668808667

Epoch: 5| Step: 8
Training loss: 3.623216255937876
Validation loss: 2.5207469172468264

Epoch: 5| Step: 9
Training loss: 2.2566808484682235
Validation loss: 2.523536635734563

Epoch: 5| Step: 10
Training loss: 2.727570355676644
Validation loss: 2.525865340900197

Epoch: 20| Step: 0
Training loss: 2.7048656173579286
Validation loss: 2.524954892761466

Epoch: 5| Step: 1
Training loss: 2.7400890700627674
Validation loss: 2.5292789508163724

Epoch: 5| Step: 2
Training loss: 3.189576015219006
Validation loss: 2.519086328173571

Epoch: 5| Step: 3
Training loss: 3.1590433884334166
Validation loss: 2.525140112566678

Epoch: 5| Step: 4
Training loss: 2.6187133895754884
Validation loss: 2.514295426004398

Epoch: 5| Step: 5
Training loss: 2.534799888733158
Validation loss: 2.519093784752937

Epoch: 5| Step: 6
Training loss: 2.9748834795532657
Validation loss: 2.5179810397555458

Epoch: 5| Step: 7
Training loss: 3.5262932211070575
Validation loss: 2.501356927185966

Epoch: 5| Step: 8
Training loss: 3.0186826394347106
Validation loss: 2.5007837851187884

Epoch: 5| Step: 9
Training loss: 2.45689491172685
Validation loss: 2.5123577072933325

Epoch: 5| Step: 10
Training loss: 2.718435685854091
Validation loss: 2.5086694443635196

Epoch: 21| Step: 0
Training loss: 3.294472926679475
Validation loss: 2.516906575907184

Epoch: 5| Step: 1
Training loss: 2.863902525484426
Validation loss: 2.5098408742618714

Epoch: 5| Step: 2
Training loss: 2.844366656504703
Validation loss: 2.499986854641717

Epoch: 5| Step: 3
Training loss: 2.6652407012511024
Validation loss: 2.5030149307744667

Epoch: 5| Step: 4
Training loss: 3.009195856801256
Validation loss: 2.492505234114123

Epoch: 5| Step: 5
Training loss: 2.6935510159170737
Validation loss: 2.4966410334244222

Epoch: 5| Step: 6
Training loss: 2.927064581072235
Validation loss: 2.5066609706445218

Epoch: 5| Step: 7
Training loss: 3.360590799025322
Validation loss: 2.4938376659119075

Epoch: 5| Step: 8
Training loss: 2.737121684788619
Validation loss: 2.494878067930849

Epoch: 5| Step: 9
Training loss: 2.4780263335127253
Validation loss: 2.489161326179244

Epoch: 5| Step: 10
Training loss: 2.7053770705752167
Validation loss: 2.492566018013335

Epoch: 22| Step: 0
Training loss: 2.5245759362389784
Validation loss: 2.504202262174026

Epoch: 5| Step: 1
Training loss: 2.5078537601867676
Validation loss: 2.484269693858913

Epoch: 5| Step: 2
Training loss: 3.087871476656316
Validation loss: 2.4867237391338097

Epoch: 5| Step: 3
Training loss: 2.709651763050365
Validation loss: 2.4928835722497955

Epoch: 5| Step: 4
Training loss: 2.5936076113672137
Validation loss: 2.493152177751004

Epoch: 5| Step: 5
Training loss: 2.9263752434940504
Validation loss: 2.5008568433628255

Epoch: 5| Step: 6
Training loss: 3.1993282984048577
Validation loss: 2.501485900860096

Epoch: 5| Step: 7
Training loss: 3.116821267548522
Validation loss: 2.489396456439471

Epoch: 5| Step: 8
Training loss: 3.16239331333101
Validation loss: 2.4982081852371096

Epoch: 5| Step: 9
Training loss: 2.9426973505856076
Validation loss: 2.4867169762171364

Epoch: 5| Step: 10
Training loss: 2.669648073412761
Validation loss: 2.4928276424649454

Epoch: 23| Step: 0
Training loss: 2.4685172442072854
Validation loss: 2.480255437658793

Epoch: 5| Step: 1
Training loss: 3.091414986483106
Validation loss: 2.4929271424263066

Epoch: 5| Step: 2
Training loss: 3.0764462303250246
Validation loss: 2.493244303124499

Epoch: 5| Step: 3
Training loss: 3.1304921525614042
Validation loss: 2.4893181411988823

Epoch: 5| Step: 4
Training loss: 2.6972332730794233
Validation loss: 2.486160172502575

Epoch: 5| Step: 5
Training loss: 3.3577448238548477
Validation loss: 2.4954131388902865

Epoch: 5| Step: 6
Training loss: 2.919802660087243
Validation loss: 2.4895053322187866

Epoch: 5| Step: 7
Training loss: 2.7665285692640955
Validation loss: 2.483257374328212

Epoch: 5| Step: 8
Training loss: 2.6472575842341364
Validation loss: 2.4983065222311316

Epoch: 5| Step: 9
Training loss: 2.8500427376738378
Validation loss: 2.4921997771563618

Epoch: 5| Step: 10
Training loss: 2.326212872224788
Validation loss: 2.487835819675943

Epoch: 24| Step: 0
Training loss: 3.0866341492633893
Validation loss: 2.4952520815281454

Epoch: 5| Step: 1
Training loss: 2.9390173706288976
Validation loss: 2.492671592805061

Epoch: 5| Step: 2
Training loss: 2.475330034079983
Validation loss: 2.489764415285647

Epoch: 5| Step: 3
Training loss: 2.5955534031429397
Validation loss: 2.483483686380759

Epoch: 5| Step: 4
Training loss: 2.9203271693008706
Validation loss: 2.4795228539047653

Epoch: 5| Step: 5
Training loss: 3.0487267760220798
Validation loss: 2.487572450016112

Epoch: 5| Step: 6
Training loss: 2.956695013444379
Validation loss: 2.487806455224275

Epoch: 5| Step: 7
Training loss: 2.8602705423400803
Validation loss: 2.4872045044536435

Epoch: 5| Step: 8
Training loss: 2.8884980495684673
Validation loss: 2.4910610504074504

Epoch: 5| Step: 9
Training loss: 2.6992319992778118
Validation loss: 2.4865589599697997

Epoch: 5| Step: 10
Training loss: 3.1015222196101306
Validation loss: 2.481634642808025

Epoch: 25| Step: 0
Training loss: 3.0635120510177463
Validation loss: 2.493141733562034

Epoch: 5| Step: 1
Training loss: 2.4687893055551315
Validation loss: 2.4909842787653433

Epoch: 5| Step: 2
Training loss: 3.22468907831351
Validation loss: 2.482493227528199

Epoch: 5| Step: 3
Training loss: 3.091321512236571
Validation loss: 2.4915121884442635

Epoch: 5| Step: 4
Training loss: 3.035384985750366
Validation loss: 2.487650623894685

Epoch: 5| Step: 5
Training loss: 2.8251200355076693
Validation loss: 2.496280762592674

Epoch: 5| Step: 6
Training loss: 3.1553385712191706
Validation loss: 2.48827118408817

Epoch: 5| Step: 7
Training loss: 2.538575956237985
Validation loss: 2.4920716195919477

Epoch: 5| Step: 8
Training loss: 2.9621685760147907
Validation loss: 2.49221359621418

Epoch: 5| Step: 9
Training loss: 2.576938240409586
Validation loss: 2.4924293904983426

Epoch: 5| Step: 10
Training loss: 2.4956935030360183
Validation loss: 2.4802088065057646

Epoch: 26| Step: 0
Training loss: 2.8344130609179645
Validation loss: 2.4891339311479173

Epoch: 5| Step: 1
Training loss: 2.262720179513766
Validation loss: 2.4908490434838417

Epoch: 5| Step: 2
Training loss: 3.4337512295904413
Validation loss: 2.484738481786575

Epoch: 5| Step: 3
Training loss: 3.0653769545380687
Validation loss: 2.4938151302093203

Epoch: 5| Step: 4
Training loss: 2.99175321051788
Validation loss: 2.48984824255873

Epoch: 5| Step: 5
Training loss: 3.0842317526655467
Validation loss: 2.481186235907847

Epoch: 5| Step: 6
Training loss: 2.998831998428282
Validation loss: 2.4968212971999466

Epoch: 5| Step: 7
Training loss: 2.457060554463064
Validation loss: 2.4848696360158424

Epoch: 5| Step: 8
Training loss: 2.907731201740826
Validation loss: 2.4867398896466892

Epoch: 5| Step: 9
Training loss: 2.490037522856709
Validation loss: 2.482869313255896

Epoch: 5| Step: 10
Training loss: 2.723265307482274
Validation loss: 2.497737822910414

Epoch: 27| Step: 0
Training loss: 2.7143144050315122
Validation loss: 2.4869672418811106

Epoch: 5| Step: 1
Training loss: 2.377529102712904
Validation loss: 2.4806705655334484

Epoch: 5| Step: 2
Training loss: 2.8799071519508095
Validation loss: 2.488317722877414

Epoch: 5| Step: 3
Training loss: 2.9593701403858925
Validation loss: 2.4869581834453047

Epoch: 5| Step: 4
Training loss: 3.1481906235599055
Validation loss: 2.485373730371951

Epoch: 5| Step: 5
Training loss: 2.7731020442484517
Validation loss: 2.4807894121492957

Epoch: 5| Step: 6
Training loss: 3.212625547100656
Validation loss: 2.4791673236479648

Epoch: 5| Step: 7
Training loss: 3.332521498683027
Validation loss: 2.481794260712412

Epoch: 5| Step: 8
Training loss: 1.9639236388968193
Validation loss: 2.480824356226822

Epoch: 5| Step: 9
Training loss: 2.843435416794695
Validation loss: 2.4731380655019755

Epoch: 5| Step: 10
Training loss: 3.0263156646449154
Validation loss: 2.479171703461387

Epoch: 28| Step: 0
Training loss: 3.401311812058206
Validation loss: 2.4779105750775403

Epoch: 5| Step: 1
Training loss: 2.926819233954682
Validation loss: 2.480480243868428

Epoch: 5| Step: 2
Training loss: 2.574805787549308
Validation loss: 2.473275218663751

Epoch: 5| Step: 3
Training loss: 2.4216629427701597
Validation loss: 2.4756975662400533

Epoch: 5| Step: 4
Training loss: 2.37562071067465
Validation loss: 2.4684910657261314

Epoch: 5| Step: 5
Training loss: 3.336672985465983
Validation loss: 2.47863162823216

Epoch: 5| Step: 6
Training loss: 2.741642128816232
Validation loss: 2.4847899379565033

Epoch: 5| Step: 7
Training loss: 2.5164044043538034
Validation loss: 2.47748605878718

Epoch: 5| Step: 8
Training loss: 2.95314389177365
Validation loss: 2.476849498289134

Epoch: 5| Step: 9
Training loss: 3.3426742962492866
Validation loss: 2.48350467349568

Epoch: 5| Step: 10
Training loss: 2.428066191089981
Validation loss: 2.4767261245465395

Epoch: 29| Step: 0
Training loss: 3.0746099085050673
Validation loss: 2.4737870479715545

Epoch: 5| Step: 1
Training loss: 2.872047234850755
Validation loss: 2.47784585186798

Epoch: 5| Step: 2
Training loss: 2.2977502932688934
Validation loss: 2.473133217346035

Epoch: 5| Step: 3
Training loss: 2.9896924644692957
Validation loss: 2.489360894297278

Epoch: 5| Step: 4
Training loss: 3.6201314130924973
Validation loss: 2.4795051075527748

Epoch: 5| Step: 5
Training loss: 2.389789410335298
Validation loss: 2.4686403988795322

Epoch: 5| Step: 6
Training loss: 2.656346397894655
Validation loss: 2.47774663971486

Epoch: 5| Step: 7
Training loss: 1.911966538671158
Validation loss: 2.4765388019484194

Epoch: 5| Step: 8
Training loss: 3.2619038238099742
Validation loss: 2.466754746201755

Epoch: 5| Step: 9
Training loss: 2.857043373555765
Validation loss: 2.4806637158397296

Epoch: 5| Step: 10
Training loss: 2.9906845102796877
Validation loss: 2.480545049231397

Epoch: 30| Step: 0
Training loss: 2.8444531587957305
Validation loss: 2.4792624389840143

Epoch: 5| Step: 1
Training loss: 2.7192531427055058
Validation loss: 2.4763855608748746

Epoch: 5| Step: 2
Training loss: 2.8773467396107706
Validation loss: 2.467457320845601

Epoch: 5| Step: 3
Training loss: 2.8877973593315045
Validation loss: 2.4616977916391143

Epoch: 5| Step: 4
Training loss: 2.645860166238403
Validation loss: 2.472683067625412

Epoch: 5| Step: 5
Training loss: 2.4796171874261557
Validation loss: 2.4751663845662217

Epoch: 5| Step: 6
Training loss: 2.851706974079845
Validation loss: 2.4763888084044705

Epoch: 5| Step: 7
Training loss: 2.7795917839738027
Validation loss: 2.476870846951579

Epoch: 5| Step: 8
Training loss: 2.867769187524519
Validation loss: 2.471870054117122

Epoch: 5| Step: 9
Training loss: 3.1807025910603968
Validation loss: 2.4766169799182802

Epoch: 5| Step: 10
Training loss: 3.1947473152066377
Validation loss: 2.479307444370432

Epoch: 31| Step: 0
Training loss: 2.935078860885462
Validation loss: 2.4756950012493895

Epoch: 5| Step: 1
Training loss: 3.0786406574045495
Validation loss: 2.473366877909345

Epoch: 5| Step: 2
Training loss: 3.1709852051090537
Validation loss: 2.4748337591951732

Epoch: 5| Step: 3
Training loss: 2.247022353899342
Validation loss: 2.4765485987854268

Epoch: 5| Step: 4
Training loss: 2.985264989953438
Validation loss: 2.4789304144172495

Epoch: 5| Step: 5
Training loss: 3.6331632055179806
Validation loss: 2.4702040955342848

Epoch: 5| Step: 6
Training loss: 2.929723632589684
Validation loss: 2.478278189005204

Epoch: 5| Step: 7
Training loss: 2.500945389332519
Validation loss: 2.4691930591113715

Epoch: 5| Step: 8
Training loss: 2.2006709722881075
Validation loss: 2.4814245559194834

Epoch: 5| Step: 9
Training loss: 2.449494317475841
Validation loss: 2.478232173394199

Epoch: 5| Step: 10
Training loss: 2.7440007401512636
Validation loss: 2.474594684789707

Epoch: 32| Step: 0
Training loss: 2.878752374354057
Validation loss: 2.4870463264226683

Epoch: 5| Step: 1
Training loss: 2.502945595168674
Validation loss: 2.481502614059457

Epoch: 5| Step: 2
Training loss: 2.8905128251038508
Validation loss: 2.481769691192161

Epoch: 5| Step: 3
Training loss: 2.726876139705052
Validation loss: 2.478983485492217

Epoch: 5| Step: 4
Training loss: 3.1565083313023354
Validation loss: 2.4754304356820906

Epoch: 5| Step: 5
Training loss: 2.676263339754629
Validation loss: 2.48430910266221

Epoch: 5| Step: 6
Training loss: 2.690153541862692
Validation loss: 2.4768305538623414

Epoch: 5| Step: 7
Training loss: 3.106237160485364
Validation loss: 2.4734402526106747

Epoch: 5| Step: 8
Training loss: 2.8995837800824598
Validation loss: 2.468445224934455

Epoch: 5| Step: 9
Training loss: 2.577077756940955
Validation loss: 2.4800490431446685

Epoch: 5| Step: 10
Training loss: 3.0407115708324968
Validation loss: 2.470199580989525

Epoch: 33| Step: 0
Training loss: 2.7604646978458134
Validation loss: 2.4656143264563397

Epoch: 5| Step: 1
Training loss: 2.4672803729637733
Validation loss: 2.4658110303043115

Epoch: 5| Step: 2
Training loss: 2.9536850816951716
Validation loss: 2.4591277896471557

Epoch: 5| Step: 3
Training loss: 3.136439480825722
Validation loss: 2.468211422511207

Epoch: 5| Step: 4
Training loss: 2.632846730176683
Validation loss: 2.4580463000611883

Epoch: 5| Step: 5
Training loss: 2.567394234801284
Validation loss: 2.4592026754494487

Epoch: 5| Step: 6
Training loss: 3.434311792765648
Validation loss: 2.4702124686956886

Epoch: 5| Step: 7
Training loss: 2.2802911075667076
Validation loss: 2.461157829238597

Epoch: 5| Step: 8
Training loss: 2.6797656167435897
Validation loss: 2.479909426933638

Epoch: 5| Step: 9
Training loss: 3.3951510970772514
Validation loss: 2.4754615946147953

Epoch: 5| Step: 10
Training loss: 2.5486778010328774
Validation loss: 2.4769830066919805

Epoch: 34| Step: 0
Training loss: 3.1260230869214354
Validation loss: 2.476246500084376

Epoch: 5| Step: 1
Training loss: 2.464304531017674
Validation loss: 2.4629398125795428

Epoch: 5| Step: 2
Training loss: 3.199789850963971
Validation loss: 2.4752207429620428

Epoch: 5| Step: 3
Training loss: 1.7812161358743006
Validation loss: 2.4524940937144177

Epoch: 5| Step: 4
Training loss: 2.984795026530772
Validation loss: 2.469587078993912

Epoch: 5| Step: 5
Training loss: 3.061026082258943
Validation loss: 2.4732578452104104

Epoch: 5| Step: 6
Training loss: 2.9482971772571305
Validation loss: 2.465385805272671

Epoch: 5| Step: 7
Training loss: 3.1570484926488733
Validation loss: 2.456579865363233

Epoch: 5| Step: 8
Training loss: 2.2990169787881305
Validation loss: 2.480451215055946

Epoch: 5| Step: 9
Training loss: 3.1487902119527047
Validation loss: 2.462000645703745

Epoch: 5| Step: 10
Training loss: 2.638522874534564
Validation loss: 2.4610742632862093

Epoch: 35| Step: 0
Training loss: 2.5117306152822874
Validation loss: 2.4590418100444413

Epoch: 5| Step: 1
Training loss: 2.928544373337451
Validation loss: 2.4675340109782256

Epoch: 5| Step: 2
Training loss: 3.1564107419619294
Validation loss: 2.470470842743336

Epoch: 5| Step: 3
Training loss: 2.766084104890809
Validation loss: 2.4655114049660005

Epoch: 5| Step: 4
Training loss: 2.770458243850719
Validation loss: 2.477479288245106

Epoch: 5| Step: 5
Training loss: 3.1493300315824553
Validation loss: 2.462944426824776

Epoch: 5| Step: 6
Training loss: 2.923678407677314
Validation loss: 2.468618104629748

Epoch: 5| Step: 7
Training loss: 3.063539912329133
Validation loss: 2.460253371546368

Epoch: 5| Step: 8
Training loss: 2.8697458437788077
Validation loss: 2.4636600381568496

Epoch: 5| Step: 9
Training loss: 2.277408134374767
Validation loss: 2.46344334924902

Epoch: 5| Step: 10
Training loss: 2.5299788685998
Validation loss: 2.4625441284123517

Epoch: 36| Step: 0
Training loss: 3.160806369748621
Validation loss: 2.47502006679242

Epoch: 5| Step: 1
Training loss: 2.075483895375577
Validation loss: 2.4575763855871116

Epoch: 5| Step: 2
Training loss: 2.88748377675705
Validation loss: 2.459359352389454

Epoch: 5| Step: 3
Training loss: 2.752823507230874
Validation loss: 2.4719382016883067

Epoch: 5| Step: 4
Training loss: 2.999579241174414
Validation loss: 2.4602737596841986

Epoch: 5| Step: 5
Training loss: 2.7907466131454783
Validation loss: 2.4675546823294714

Epoch: 5| Step: 6
Training loss: 2.7881726466923946
Validation loss: 2.4671852695205856

Epoch: 5| Step: 7
Training loss: 2.867028338512797
Validation loss: 2.4727777429426454

Epoch: 5| Step: 8
Training loss: 2.4131970875921493
Validation loss: 2.4725228179847916

Epoch: 5| Step: 9
Training loss: 3.5115919249380387
Validation loss: 2.454830299346487

Epoch: 5| Step: 10
Training loss: 2.598385907714429
Validation loss: 2.460430742478306

Epoch: 37| Step: 0
Training loss: 2.3919471624975186
Validation loss: 2.474923386915329

Epoch: 5| Step: 1
Training loss: 3.1334165528250577
Validation loss: 2.4714298918526034

Epoch: 5| Step: 2
Training loss: 2.8134209714440237
Validation loss: 2.463617455086491

Epoch: 5| Step: 3
Training loss: 2.8848261223133442
Validation loss: 2.4550843673366813

Epoch: 5| Step: 4
Training loss: 2.7936199149412744
Validation loss: 2.4585575646664397

Epoch: 5| Step: 5
Training loss: 3.0231624350005473
Validation loss: 2.47046523597161

Epoch: 5| Step: 6
Training loss: 2.9285249972234815
Validation loss: 2.4655437456769635

Epoch: 5| Step: 7
Training loss: 2.957048181765016
Validation loss: 2.466684224036583

Epoch: 5| Step: 8
Training loss: 2.299852789438572
Validation loss: 2.4750996532205596

Epoch: 5| Step: 9
Training loss: 2.562374204943944
Validation loss: 2.463095786034058

Epoch: 5| Step: 10
Training loss: 3.1913118196708847
Validation loss: 2.4659093815423647

Epoch: 38| Step: 0
Training loss: 2.3995818846796952
Validation loss: 2.4645160637748518

Epoch: 5| Step: 1
Training loss: 3.1070939327954594
Validation loss: 2.466895132894663

Epoch: 5| Step: 2
Training loss: 2.6995803436232912
Validation loss: 2.4667954356259876

Epoch: 5| Step: 3
Training loss: 2.4499410388624843
Validation loss: 2.466765933989637

Epoch: 5| Step: 4
Training loss: 3.041774765253696
Validation loss: 2.4628179441422513

Epoch: 5| Step: 5
Training loss: 2.8932789759063806
Validation loss: 2.4653698237088335

Epoch: 5| Step: 6
Training loss: 2.426737672042933
Validation loss: 2.467135492196843

Epoch: 5| Step: 7
Training loss: 3.211613122255839
Validation loss: 2.4692828775565205

Epoch: 5| Step: 8
Training loss: 2.832710889623559
Validation loss: 2.4663826446207593

Epoch: 5| Step: 9
Training loss: 2.9717390572856774
Validation loss: 2.466605005793429

Epoch: 5| Step: 10
Training loss: 2.7819058791473465
Validation loss: 2.4645142153019672

Epoch: 39| Step: 0
Training loss: 3.493592254953642
Validation loss: 2.4492373877845885

Epoch: 5| Step: 1
Training loss: 2.991232139320469
Validation loss: 2.4640177544414748

Epoch: 5| Step: 2
Training loss: 2.8302196522583363
Validation loss: 2.463848749865754

Epoch: 5| Step: 3
Training loss: 2.6982997980639465
Validation loss: 2.461795057560967

Epoch: 5| Step: 4
Training loss: 2.598021700973267
Validation loss: 2.4592700429929573

Epoch: 5| Step: 5
Training loss: 2.6162781003708733
Validation loss: 2.4566626543978547

Epoch: 5| Step: 6
Training loss: 2.985344055385965
Validation loss: 2.457542919283673

Epoch: 5| Step: 7
Training loss: 2.7144957833994257
Validation loss: 2.4590761624219373

Epoch: 5| Step: 8
Training loss: 2.605096289965627
Validation loss: 2.457113664911918

Epoch: 5| Step: 9
Training loss: 2.422005926715583
Validation loss: 2.4691718216084872

Epoch: 5| Step: 10
Training loss: 2.8170012164399347
Validation loss: 2.4527361841034097

Epoch: 40| Step: 0
Training loss: 2.542213058108742
Validation loss: 2.461655701588068

Epoch: 5| Step: 1
Training loss: 3.037058348395707
Validation loss: 2.445761553305061

Epoch: 5| Step: 2
Training loss: 2.85836557383098
Validation loss: 2.4632905684129596

Epoch: 5| Step: 3
Training loss: 2.49811893266748
Validation loss: 2.4573627385712498

Epoch: 5| Step: 4
Training loss: 2.991508227503265
Validation loss: 2.457686394574835

Epoch: 5| Step: 5
Training loss: 2.580471381365976
Validation loss: 2.4592029360664895

Epoch: 5| Step: 6
Training loss: 2.76760939618779
Validation loss: 2.459597454623754

Epoch: 5| Step: 7
Training loss: 3.0259135356483218
Validation loss: 2.4611587641103903

Epoch: 5| Step: 8
Training loss: 2.6106300305369876
Validation loss: 2.4537400472079516

Epoch: 5| Step: 9
Training loss: 2.9739164671258647
Validation loss: 2.4653627672055523

Epoch: 5| Step: 10
Training loss: 2.949036366463231
Validation loss: 2.4605934773755584

Epoch: 41| Step: 0
Training loss: 2.2897781451174306
Validation loss: 2.463321970407042

Epoch: 5| Step: 1
Training loss: 2.8307137627812735
Validation loss: 2.4595705485212087

Epoch: 5| Step: 2
Training loss: 2.9264014774633718
Validation loss: 2.460344454134106

Epoch: 5| Step: 3
Training loss: 3.1903026451596097
Validation loss: 2.4562390514009635

Epoch: 5| Step: 4
Training loss: 2.8257993124336327
Validation loss: 2.4535739410288038

Epoch: 5| Step: 5
Training loss: 2.545333864088421
Validation loss: 2.462803830544762

Epoch: 5| Step: 6
Training loss: 3.405414163773777
Validation loss: 2.4618040320751766

Epoch: 5| Step: 7
Training loss: 2.8025926507612686
Validation loss: 2.459329651055389

Epoch: 5| Step: 8
Training loss: 2.24143613128582
Validation loss: 2.4633787558687157

Epoch: 5| Step: 9
Training loss: 3.089367932360369
Validation loss: 2.4548691364414417

Epoch: 5| Step: 10
Training loss: 2.4949973598305717
Validation loss: 2.46011895524171

Epoch: 42| Step: 0
Training loss: 2.8882363837763236
Validation loss: 2.455814742729721

Epoch: 5| Step: 1
Training loss: 2.99176070154966
Validation loss: 2.450598279796646

Epoch: 5| Step: 2
Training loss: 3.3671984041749923
Validation loss: 2.4512886032969825

Epoch: 5| Step: 3
Training loss: 2.3460480676980398
Validation loss: 2.4578416077756557

Epoch: 5| Step: 4
Training loss: 3.0761695498503117
Validation loss: 2.4556667332254274

Epoch: 5| Step: 5
Training loss: 1.6900941195039945
Validation loss: 2.4643820516186183

Epoch: 5| Step: 6
Training loss: 2.2619320994472325
Validation loss: 2.4650370552575747

Epoch: 5| Step: 7
Training loss: 2.8631936511369838
Validation loss: 2.456499470724154

Epoch: 5| Step: 8
Training loss: 3.4660279186817085
Validation loss: 2.457042177394054

Epoch: 5| Step: 9
Training loss: 2.4685106765055673
Validation loss: 2.4637647757258287

Epoch: 5| Step: 10
Training loss: 2.9618119933781504
Validation loss: 2.451544612150343

Epoch: 43| Step: 0
Training loss: 2.470229755634844
Validation loss: 2.4665551013903935

Epoch: 5| Step: 1
Training loss: 2.390115721067751
Validation loss: 2.4508358566102095

Epoch: 5| Step: 2
Training loss: 2.8300403832024448
Validation loss: 2.452713401410832

Epoch: 5| Step: 3
Training loss: 2.7857559221949852
Validation loss: 2.45609043858355

Epoch: 5| Step: 4
Training loss: 3.0545014229610525
Validation loss: 2.4475267241515977

Epoch: 5| Step: 5
Training loss: 2.8944551403834855
Validation loss: 2.463060226664738

Epoch: 5| Step: 6
Training loss: 2.820912136252482
Validation loss: 2.455085766064847

Epoch: 5| Step: 7
Training loss: 3.039839853535716
Validation loss: 2.4485460054057344

Epoch: 5| Step: 8
Training loss: 3.231388353230247
Validation loss: 2.444584008008578

Epoch: 5| Step: 9
Training loss: 2.203705623221014
Validation loss: 2.456562911284079

Epoch: 5| Step: 10
Training loss: 3.0418915513048623
Validation loss: 2.449712286289676

Epoch: 44| Step: 0
Training loss: 2.716561938726459
Validation loss: 2.4487671899424854

Epoch: 5| Step: 1
Training loss: 2.8853217888575875
Validation loss: 2.452329798434253

Epoch: 5| Step: 2
Training loss: 3.001269707605114
Validation loss: 2.4519123512891827

Epoch: 5| Step: 3
Training loss: 3.127686985686408
Validation loss: 2.454751910016587

Epoch: 5| Step: 4
Training loss: 2.419508140485628
Validation loss: 2.4640008250091165

Epoch: 5| Step: 5
Training loss: 2.9762768545785687
Validation loss: 2.4529429432771215

Epoch: 5| Step: 6
Training loss: 2.5708952362010478
Validation loss: 2.445527152579912

Epoch: 5| Step: 7
Training loss: 2.421396712790048
Validation loss: 2.455515554512134

Epoch: 5| Step: 8
Training loss: 2.858207255734937
Validation loss: 2.452025500027191

Epoch: 5| Step: 9
Training loss: 2.692829879486853
Validation loss: 2.450032457735634

Epoch: 5| Step: 10
Training loss: 2.981199002579492
Validation loss: 2.45137647895825

Epoch: 45| Step: 0
Training loss: 2.6283823656125986
Validation loss: 2.454379817668242

Epoch: 5| Step: 1
Training loss: 2.290940175354748
Validation loss: 2.442603153978425

Epoch: 5| Step: 2
Training loss: 2.925984150226294
Validation loss: 2.447625253926371

Epoch: 5| Step: 3
Training loss: 2.554818899525953
Validation loss: 2.454680473822176

Epoch: 5| Step: 4
Training loss: 2.5579691583177433
Validation loss: 2.449637940269912

Epoch: 5| Step: 5
Training loss: 3.2143438606452444
Validation loss: 2.4563454929720057

Epoch: 5| Step: 6
Training loss: 2.9191127510838015
Validation loss: 2.458647667373364

Epoch: 5| Step: 7
Training loss: 3.087542384547845
Validation loss: 2.4491599258518613

Epoch: 5| Step: 8
Training loss: 3.124717089244622
Validation loss: 2.456513668026795

Epoch: 5| Step: 9
Training loss: 2.769183439681709
Validation loss: 2.457954913283043

Epoch: 5| Step: 10
Training loss: 2.593512374839581
Validation loss: 2.4567249856568623

Epoch: 46| Step: 0
Training loss: 2.650291491617394
Validation loss: 2.4531070501390455

Epoch: 5| Step: 1
Training loss: 2.517505866671775
Validation loss: 2.453721387727674

Epoch: 5| Step: 2
Training loss: 2.581904652041331
Validation loss: 2.4488697850443937

Epoch: 5| Step: 3
Training loss: 2.5383765599892256
Validation loss: 2.4733206962951635

Epoch: 5| Step: 4
Training loss: 2.7627508023711074
Validation loss: 2.450712942209902

Epoch: 5| Step: 5
Training loss: 2.9808562140634858
Validation loss: 2.4567691595307597

Epoch: 5| Step: 6
Training loss: 3.398262668365706
Validation loss: 2.4423123266140188

Epoch: 5| Step: 7
Training loss: 2.2895507291833272
Validation loss: 2.4526196271376985

Epoch: 5| Step: 8
Training loss: 2.9084897178716043
Validation loss: 2.4539840768903454

Epoch: 5| Step: 9
Training loss: 2.374712675683781
Validation loss: 2.4475570955718244

Epoch: 5| Step: 10
Training loss: 3.519514721017652
Validation loss: 2.455730819053478

Epoch: 47| Step: 0
Training loss: 2.932894403678708
Validation loss: 2.453583887028531

Epoch: 5| Step: 1
Training loss: 3.1034016189137312
Validation loss: 2.4622615973024704

Epoch: 5| Step: 2
Training loss: 2.968581345435522
Validation loss: 2.4435302777429677

Epoch: 5| Step: 3
Training loss: 2.4524313559535287
Validation loss: 2.461423316475865

Epoch: 5| Step: 4
Training loss: 2.742721114446983
Validation loss: 2.4527794358312023

Epoch: 5| Step: 5
Training loss: 2.940643900730471
Validation loss: 2.4520003645624855

Epoch: 5| Step: 6
Training loss: 2.5037915088947456
Validation loss: 2.452321654833942

Epoch: 5| Step: 7
Training loss: 2.728075367409433
Validation loss: 2.45428589502117

Epoch: 5| Step: 8
Training loss: 3.1500732110613536
Validation loss: 2.444452741575594

Epoch: 5| Step: 9
Training loss: 2.5643607106230224
Validation loss: 2.4512508871001346

Epoch: 5| Step: 10
Training loss: 2.4309683119271113
Validation loss: 2.4501193462423854

Epoch: 48| Step: 0
Training loss: 2.46071330669019
Validation loss: 2.446443819904857

Epoch: 5| Step: 1
Training loss: 2.3365054253503565
Validation loss: 2.4475306373892605

Epoch: 5| Step: 2
Training loss: 2.8958537880886364
Validation loss: 2.4506259581074685

Epoch: 5| Step: 3
Training loss: 2.683075834046421
Validation loss: 2.4625629516320617

Epoch: 5| Step: 4
Training loss: 3.046008803657338
Validation loss: 2.454571427816603

Epoch: 5| Step: 5
Training loss: 3.251408491836443
Validation loss: 2.4524339045070715

Epoch: 5| Step: 6
Training loss: 2.798790643285311
Validation loss: 2.4656155325745788

Epoch: 5| Step: 7
Training loss: 2.1488102260136084
Validation loss: 2.456925379158903

Epoch: 5| Step: 8
Training loss: 2.7923051379184636
Validation loss: 2.4518416416550917

Epoch: 5| Step: 9
Training loss: 3.212837492436805
Validation loss: 2.441642518389409

Epoch: 5| Step: 10
Training loss: 2.7175550794590713
Validation loss: 2.4430479380387666

Epoch: 49| Step: 0
Training loss: 3.123679988545146
Validation loss: 2.4551826752587624

Epoch: 5| Step: 1
Training loss: 3.1427928218204633
Validation loss: 2.4534785800512746

Epoch: 5| Step: 2
Training loss: 2.629172777832796
Validation loss: 2.449665258960929

Epoch: 5| Step: 3
Training loss: 2.6081806121901225
Validation loss: 2.447294534151514

Epoch: 5| Step: 4
Training loss: 3.0159042308183084
Validation loss: 2.43616355983622

Epoch: 5| Step: 5
Training loss: 2.3880029398262677
Validation loss: 2.438639100925876

Epoch: 5| Step: 6
Training loss: 2.4018067791015545
Validation loss: 2.4547920078276446

Epoch: 5| Step: 7
Training loss: 3.095529988257766
Validation loss: 2.4480670311136725

Epoch: 5| Step: 8
Training loss: 2.7707773265102027
Validation loss: 2.453151862887838

Epoch: 5| Step: 9
Training loss: 2.0486228410920213
Validation loss: 2.4428718708583763

Epoch: 5| Step: 10
Training loss: 3.23307471928858
Validation loss: 2.4575702559826573

Epoch: 50| Step: 0
Training loss: 2.1463515263996085
Validation loss: 2.4628717532797864

Epoch: 5| Step: 1
Training loss: 3.098478768478322
Validation loss: 2.451201883833497

Epoch: 5| Step: 2
Training loss: 2.700331727595037
Validation loss: 2.4484973024230143

Epoch: 5| Step: 3
Training loss: 2.2578798699805054
Validation loss: 2.444286382887347

Epoch: 5| Step: 4
Training loss: 3.0703581595483733
Validation loss: 2.450976535890599

Epoch: 5| Step: 5
Training loss: 2.752385751846084
Validation loss: 2.4406623404604355

Epoch: 5| Step: 6
Training loss: 2.965528486990695
Validation loss: 2.435703773733096

Epoch: 5| Step: 7
Training loss: 2.6053106211385213
Validation loss: 2.4377798146488794

Epoch: 5| Step: 8
Training loss: 3.3140734408430466
Validation loss: 2.4531256270304955

Epoch: 5| Step: 9
Training loss: 3.1186636199914544
Validation loss: 2.4492666850150577

Epoch: 5| Step: 10
Training loss: 2.2016763455998536
Validation loss: 2.4482584044295304

Epoch: 51| Step: 0
Training loss: 2.5555573362077046
Validation loss: 2.440897214657977

Epoch: 5| Step: 1
Training loss: 1.9026555426596985
Validation loss: 2.443430820074769

Epoch: 5| Step: 2
Training loss: 2.743953646877246
Validation loss: 2.445960968902839

Epoch: 5| Step: 3
Training loss: 3.1422706960991564
Validation loss: 2.446661527146053

Epoch: 5| Step: 4
Training loss: 2.3600111350103936
Validation loss: 2.446238545571699

Epoch: 5| Step: 5
Training loss: 3.0036138384782824
Validation loss: 2.4536853299526076

Epoch: 5| Step: 6
Training loss: 2.760512632225359
Validation loss: 2.4442500301727845

Epoch: 5| Step: 7
Training loss: 2.637554663502978
Validation loss: 2.4429460801586558

Epoch: 5| Step: 8
Training loss: 3.439960362183843
Validation loss: 2.443473499992599

Epoch: 5| Step: 9
Training loss: 2.710610493662277
Validation loss: 2.4474005398321417

Epoch: 5| Step: 10
Training loss: 2.9444677623889106
Validation loss: 2.441642652785001

Epoch: 52| Step: 0
Training loss: 3.0731469192017995
Validation loss: 2.4579198161692504

Epoch: 5| Step: 1
Training loss: 2.48819875056402
Validation loss: 2.4378711890046945

Epoch: 5| Step: 2
Training loss: 2.9784474249364132
Validation loss: 2.4462021128751066

Epoch: 5| Step: 3
Training loss: 3.0796192240973053
Validation loss: 2.4622627956924616

Epoch: 5| Step: 4
Training loss: 2.3974844067079384
Validation loss: 2.4442935967287345

Epoch: 5| Step: 5
Training loss: 2.9914248617594
Validation loss: 2.4550116845863212

Epoch: 5| Step: 6
Training loss: 2.8262607900556103
Validation loss: 2.4549806660526867

Epoch: 5| Step: 7
Training loss: 2.6389450959583116
Validation loss: 2.439911227400891

Epoch: 5| Step: 8
Training loss: 2.4185671951647025
Validation loss: 2.4328272988338373

Epoch: 5| Step: 9
Training loss: 2.7265886453069066
Validation loss: 2.4402526571444776

Epoch: 5| Step: 10
Training loss: 2.794271269434136
Validation loss: 2.4424784670887476

Epoch: 53| Step: 0
Training loss: 2.8012243795521217
Validation loss: 2.4527204728793963

Epoch: 5| Step: 1
Training loss: 2.9599913844421373
Validation loss: 2.4373709694719423

Epoch: 5| Step: 2
Training loss: 2.892272974335038
Validation loss: 2.446186012791364

Epoch: 5| Step: 3
Training loss: 2.818647151855407
Validation loss: 2.443658220875453

Epoch: 5| Step: 4
Training loss: 3.1950638727958345
Validation loss: 2.452462719285257

Epoch: 5| Step: 5
Training loss: 1.8119584951805148
Validation loss: 2.447556856758154

Epoch: 5| Step: 6
Training loss: 2.8572920419709202
Validation loss: 2.4411806237097853

Epoch: 5| Step: 7
Training loss: 2.799417799639285
Validation loss: 2.439681041570395

Epoch: 5| Step: 8
Training loss: 2.453324813966195
Validation loss: 2.4483672164419428

Epoch: 5| Step: 9
Training loss: 3.0801711664074247
Validation loss: 2.44374944886572

Epoch: 5| Step: 10
Training loss: 2.5209363700889704
Validation loss: 2.4445230776512292

Epoch: 54| Step: 0
Training loss: 2.537889415006157
Validation loss: 2.4456149606170627

Epoch: 5| Step: 1
Training loss: 2.7264787283983516
Validation loss: 2.4339290468171897

Epoch: 5| Step: 2
Training loss: 2.686057746152849
Validation loss: 2.447670975614871

Epoch: 5| Step: 3
Training loss: 2.924672465448288
Validation loss: 2.434539261503061

Epoch: 5| Step: 4
Training loss: 2.504064879250262
Validation loss: 2.446983315161142

Epoch: 5| Step: 5
Training loss: 2.85576347364326
Validation loss: 2.4379172082460356

Epoch: 5| Step: 6
Training loss: 3.0089938135257817
Validation loss: 2.4391750305030815

Epoch: 5| Step: 7
Training loss: 2.342904103536186
Validation loss: 2.4410332838435407

Epoch: 5| Step: 8
Training loss: 2.9604485342058626
Validation loss: 2.442936450271672

Epoch: 5| Step: 9
Training loss: 2.4831180871789984
Validation loss: 2.4418415354565943

Epoch: 5| Step: 10
Training loss: 3.336984224505655
Validation loss: 2.4365282469713962

Epoch: 55| Step: 0
Training loss: 3.2717610074272967
Validation loss: 2.4404746101296815

Epoch: 5| Step: 1
Training loss: 2.789592019471901
Validation loss: 2.441222735983414

Epoch: 5| Step: 2
Training loss: 2.701973377618998
Validation loss: 2.4401305891057974

Epoch: 5| Step: 3
Training loss: 2.553036777648317
Validation loss: 2.451767431307523

Epoch: 5| Step: 4
Training loss: 2.8125411136589147
Validation loss: 2.4435348961164394

Epoch: 5| Step: 5
Training loss: 2.6343725093589945
Validation loss: 2.443399251627203

Epoch: 5| Step: 6
Training loss: 2.3625449807057968
Validation loss: 2.430429070654002

Epoch: 5| Step: 7
Training loss: 2.8182823926704765
Validation loss: 2.442509510045574

Epoch: 5| Step: 8
Training loss: 2.565778356468837
Validation loss: 2.4377379594441524

Epoch: 5| Step: 9
Training loss: 3.0259199966070978
Validation loss: 2.4481827639490517

Epoch: 5| Step: 10
Training loss: 2.8071194361767335
Validation loss: 2.431796761606773

Epoch: 56| Step: 0
Training loss: 3.1532564980768014
Validation loss: 2.437276765305032

Epoch: 5| Step: 1
Training loss: 2.6695785022602774
Validation loss: 2.45426649857222

Epoch: 5| Step: 2
Training loss: 2.9334970349091543
Validation loss: 2.4394983146733673

Epoch: 5| Step: 3
Training loss: 2.7133482841560927
Validation loss: 2.433180855158288

Epoch: 5| Step: 4
Training loss: 2.640456696513334
Validation loss: 2.4319654051219146

Epoch: 5| Step: 5
Training loss: 2.8817121685341567
Validation loss: 2.4417864171834465

Epoch: 5| Step: 6
Training loss: 2.6963042715072683
Validation loss: 2.449250201571737

Epoch: 5| Step: 7
Training loss: 2.452429411608191
Validation loss: 2.4418263803915035

Epoch: 5| Step: 8
Training loss: 2.6213220533837793
Validation loss: 2.4344362578112384

Epoch: 5| Step: 9
Training loss: 2.6984416102392967
Validation loss: 2.4521449623647347

Epoch: 5| Step: 10
Training loss: 2.8702441145590116
Validation loss: 2.43915183421042

Epoch: 57| Step: 0
Training loss: 3.1240925806567654
Validation loss: 2.4354072886906373

Epoch: 5| Step: 1
Training loss: 2.5770344595153913
Validation loss: 2.4462154917151806

Epoch: 5| Step: 2
Training loss: 2.5162232439918237
Validation loss: 2.430310634767961

Epoch: 5| Step: 3
Training loss: 2.780233990543834
Validation loss: 2.446934372583874

Epoch: 5| Step: 4
Training loss: 2.8641787341517273
Validation loss: 2.4302561843274058

Epoch: 5| Step: 5
Training loss: 2.554943760142809
Validation loss: 2.442743079479756

Epoch: 5| Step: 6
Training loss: 2.929778156149453
Validation loss: 2.4461068533346597

Epoch: 5| Step: 7
Training loss: 2.4435401806916417
Validation loss: 2.437448428996486

Epoch: 5| Step: 8
Training loss: 2.979196579433981
Validation loss: 2.4312493169669547

Epoch: 5| Step: 9
Training loss: 2.679298661828297
Validation loss: 2.443619268549394

Epoch: 5| Step: 10
Training loss: 2.798900275887659
Validation loss: 2.442178721039451

Epoch: 58| Step: 0
Training loss: 2.8618536873344804
Validation loss: 2.448394480204814

Epoch: 5| Step: 1
Training loss: 2.6655730051244504
Validation loss: 2.4406782810854812

Epoch: 5| Step: 2
Training loss: 3.3784712847745055
Validation loss: 2.4349244696066306

Epoch: 5| Step: 3
Training loss: 3.0294438909965455
Validation loss: 2.436550775919944

Epoch: 5| Step: 4
Training loss: 2.892740661052161
Validation loss: 2.434485798103185

Epoch: 5| Step: 5
Training loss: 2.8143143629589655
Validation loss: 2.450633363556096

Epoch: 5| Step: 6
Training loss: 2.368950618411178
Validation loss: 2.4490023200374247

Epoch: 5| Step: 7
Training loss: 1.9693228478579785
Validation loss: 2.438798741953288

Epoch: 5| Step: 8
Training loss: 2.6683400288135872
Validation loss: 2.4402666380049207

Epoch: 5| Step: 9
Training loss: 2.565191855440545
Validation loss: 2.4470167545892734

Epoch: 5| Step: 10
Training loss: 2.911893881404764
Validation loss: 2.4275600157660335

Epoch: 59| Step: 0
Training loss: 2.629873474761783
Validation loss: 2.4314909499712383

Epoch: 5| Step: 1
Training loss: 2.8939392884799284
Validation loss: 2.4416837890381906

Epoch: 5| Step: 2
Training loss: 2.4253532781565545
Validation loss: 2.442728703488661

Epoch: 5| Step: 3
Training loss: 3.209165952238804
Validation loss: 2.43531233852336

Epoch: 5| Step: 4
Training loss: 2.8057480191058337
Validation loss: 2.4283935859927874

Epoch: 5| Step: 5
Training loss: 2.980540263466675
Validation loss: 2.434789641567824

Epoch: 5| Step: 6
Training loss: 2.4971654080934282
Validation loss: 2.4530595339991934

Epoch: 5| Step: 7
Training loss: 2.401991010371148
Validation loss: 2.4486193239948966

Epoch: 5| Step: 8
Training loss: 2.7496839688513934
Validation loss: 2.438051186151793

Epoch: 5| Step: 9
Training loss: 3.1007946226524123
Validation loss: 2.432135105770569

Epoch: 5| Step: 10
Training loss: 2.4417233192546095
Validation loss: 2.4438387453487724

Epoch: 60| Step: 0
Training loss: 2.3949878251118695
Validation loss: 2.43864036296165

Epoch: 5| Step: 1
Training loss: 2.561300787955096
Validation loss: 2.4509075167846732

Epoch: 5| Step: 2
Training loss: 2.2609855768012803
Validation loss: 2.4328132915546252

Epoch: 5| Step: 3
Training loss: 2.8310710252525304
Validation loss: 2.436528641534916

Epoch: 5| Step: 4
Training loss: 2.854183299069543
Validation loss: 2.441777371196265

Epoch: 5| Step: 5
Training loss: 3.0129393641020012
Validation loss: 2.440336629349983

Epoch: 5| Step: 6
Training loss: 2.8842987943193594
Validation loss: 2.4321602842101786

Epoch: 5| Step: 7
Training loss: 2.4911236540226875
Validation loss: 2.4354773165277717

Epoch: 5| Step: 8
Training loss: 2.7361248411898034
Validation loss: 2.4452608389994595

Epoch: 5| Step: 9
Training loss: 2.9288649561452043
Validation loss: 2.4212655233720244

Epoch: 5| Step: 10
Training loss: 3.159639710034833
Validation loss: 2.42548080712504

Epoch: 61| Step: 0
Training loss: 2.7733560899418293
Validation loss: 2.435625791913766

Epoch: 5| Step: 1
Training loss: 2.78143464236332
Validation loss: 2.4378786132178396

Epoch: 5| Step: 2
Training loss: 2.7566757669110293
Validation loss: 2.425392671818408

Epoch: 5| Step: 3
Training loss: 2.8420868086634012
Validation loss: 2.4291731859142645

Epoch: 5| Step: 4
Training loss: 2.450482153646371
Validation loss: 2.4369890651962924

Epoch: 5| Step: 5
Training loss: 2.317833806331242
Validation loss: 2.43867875408265

Epoch: 5| Step: 6
Training loss: 2.5443682357484527
Validation loss: 2.43761754916006

Epoch: 5| Step: 7
Training loss: 2.733998823175407
Validation loss: 2.4394897993092863

Epoch: 5| Step: 8
Training loss: 2.675036071819344
Validation loss: 2.434233610103289

Epoch: 5| Step: 9
Training loss: 3.398221134006784
Validation loss: 2.4485644127366557

Epoch: 5| Step: 10
Training loss: 2.7760673841438672
Validation loss: 2.4389807518483737

Epoch: 62| Step: 0
Training loss: 2.1344285369011966
Validation loss: 2.4319564975926395

Epoch: 5| Step: 1
Training loss: 3.5394975340115615
Validation loss: 2.430147233369191

Epoch: 5| Step: 2
Training loss: 2.4640730969498077
Validation loss: 2.4334072063333916

Epoch: 5| Step: 3
Training loss: 3.310984138711159
Validation loss: 2.432328371311774

Epoch: 5| Step: 4
Training loss: 2.718502340327342
Validation loss: 2.4288116892951432

Epoch: 5| Step: 5
Training loss: 2.823022950671335
Validation loss: 2.4399956342530995

Epoch: 5| Step: 6
Training loss: 2.598385815958011
Validation loss: 2.4269897225998833

Epoch: 5| Step: 7
Training loss: 2.6849722396580518
Validation loss: 2.432589439178865

Epoch: 5| Step: 8
Training loss: 2.3970149788895765
Validation loss: 2.432707054899557

Epoch: 5| Step: 9
Training loss: 2.4249176601313183
Validation loss: 2.4335313013818656

Epoch: 5| Step: 10
Training loss: 2.7421906300062266
Validation loss: 2.4392026103662525

Epoch: 63| Step: 0
Training loss: 3.149759095683326
Validation loss: 2.4335513782395846

Epoch: 5| Step: 1
Training loss: 2.7819206200799083
Validation loss: 2.4260041613317935

Epoch: 5| Step: 2
Training loss: 2.677789043422162
Validation loss: 2.4374647650684387

Epoch: 5| Step: 3
Training loss: 2.9345716124165175
Validation loss: 2.425936771423618

Epoch: 5| Step: 4
Training loss: 2.7722858455630575
Validation loss: 2.437992891719962

Epoch: 5| Step: 5
Training loss: 2.598451145707461
Validation loss: 2.445677312430763

Epoch: 5| Step: 6
Training loss: 3.1477977017422436
Validation loss: 2.4425566426095067

Epoch: 5| Step: 7
Training loss: 2.587668032879927
Validation loss: 2.433165081934341

Epoch: 5| Step: 8
Training loss: 1.8169924866726213
Validation loss: 2.43923406181317

Epoch: 5| Step: 9
Training loss: 2.8371725624482003
Validation loss: 2.4319732774531735

Epoch: 5| Step: 10
Training loss: 2.423265316501463
Validation loss: 2.4330726447090236

Epoch: 64| Step: 0
Training loss: 2.7910105850035407
Validation loss: 2.431654050219746

Epoch: 5| Step: 1
Training loss: 2.6154572646161602
Validation loss: 2.4496918960657696

Epoch: 5| Step: 2
Training loss: 2.5539021349313935
Validation loss: 2.420380624650882

Epoch: 5| Step: 3
Training loss: 2.9423920498008838
Validation loss: 2.4367476817636478

Epoch: 5| Step: 4
Training loss: 2.4415850520462588
Validation loss: 2.4315752553292986

Epoch: 5| Step: 5
Training loss: 2.840511616037633
Validation loss: 2.4335718952728342

Epoch: 5| Step: 6
Training loss: 2.244857633702695
Validation loss: 2.4416150175357143

Epoch: 5| Step: 7
Training loss: 3.1723076285738143
Validation loss: 2.4261473012150083

Epoch: 5| Step: 8
Training loss: 2.751180742112201
Validation loss: 2.4291160219254273

Epoch: 5| Step: 9
Training loss: 2.6208288567711504
Validation loss: 2.4262839381968933

Epoch: 5| Step: 10
Training loss: 3.0206778299931796
Validation loss: 2.4366109471404513

Epoch: 65| Step: 0
Training loss: 2.833618056259051
Validation loss: 2.433731198735658

Epoch: 5| Step: 1
Training loss: 2.74454929118928
Validation loss: 2.4372512053050412

Epoch: 5| Step: 2
Training loss: 2.25406766475465
Validation loss: 2.4259966405455664

Epoch: 5| Step: 3
Training loss: 2.5264280567717936
Validation loss: 2.4221553961703974

Epoch: 5| Step: 4
Training loss: 2.7653990400000774
Validation loss: 2.428860764844173

Epoch: 5| Step: 5
Training loss: 3.0838670182804555
Validation loss: 2.426212371228211

Epoch: 5| Step: 6
Training loss: 2.110264004466878
Validation loss: 2.4321498880032375

Epoch: 5| Step: 7
Training loss: 2.947687704048403
Validation loss: 2.43510349386859

Epoch: 5| Step: 8
Training loss: 2.9356264673383268
Validation loss: 2.4273129678088217

Epoch: 5| Step: 9
Training loss: 2.633648838586225
Validation loss: 2.430609766584602

Epoch: 5| Step: 10
Training loss: 3.111756605971085
Validation loss: 2.43055125887052

Epoch: 66| Step: 0
Training loss: 2.883654463714589
Validation loss: 2.4394783487617455

Epoch: 5| Step: 1
Training loss: 2.6396643341409973
Validation loss: 2.422272049519728

Epoch: 5| Step: 2
Training loss: 2.9442039447507935
Validation loss: 2.427028913300205

Epoch: 5| Step: 3
Training loss: 2.4513587181340726
Validation loss: 2.431668903904461

Epoch: 5| Step: 4
Training loss: 2.7064569477834075
Validation loss: 2.4377986008819823

Epoch: 5| Step: 5
Training loss: 2.8684064472403183
Validation loss: 2.4391878950487733

Epoch: 5| Step: 6
Training loss: 2.624253939011939
Validation loss: 2.421982423091627

Epoch: 5| Step: 7
Training loss: 2.1152225398950413
Validation loss: 2.4323612744316794

Epoch: 5| Step: 8
Training loss: 3.2528088975810014
Validation loss: 2.4366705902950896

Epoch: 5| Step: 9
Training loss: 2.6358301092227205
Validation loss: 2.4228210887740116

Epoch: 5| Step: 10
Training loss: 2.7401531095954983
Validation loss: 2.425465196277037

Epoch: 67| Step: 0
Training loss: 2.312778971572964
Validation loss: 2.4294569184842665

Epoch: 5| Step: 1
Training loss: 3.186060112749479
Validation loss: 2.42644031120007

Epoch: 5| Step: 2
Training loss: 2.8251677167951
Validation loss: 2.4368149936266215

Epoch: 5| Step: 3
Training loss: 2.720901339636669
Validation loss: 2.430898723684679

Epoch: 5| Step: 4
Training loss: 2.538847459343307
Validation loss: 2.4323847915948464

Epoch: 5| Step: 5
Training loss: 2.9536251875715758
Validation loss: 2.4388210796366243

Epoch: 5| Step: 6
Training loss: 2.759641046540204
Validation loss: 2.444249169070481

Epoch: 5| Step: 7
Training loss: 2.577713072264321
Validation loss: 2.425341532550676

Epoch: 5| Step: 8
Training loss: 2.7753925148986354
Validation loss: 2.42762698677996

Epoch: 5| Step: 9
Training loss: 2.1771126582408096
Validation loss: 2.433693690790829

Epoch: 5| Step: 10
Training loss: 3.0173877051063966
Validation loss: 2.420840473435268

Epoch: 68| Step: 0
Training loss: 2.9958737925493106
Validation loss: 2.4211923537583235

Epoch: 5| Step: 1
Training loss: 2.329880225578034
Validation loss: 2.435990054404199

Epoch: 5| Step: 2
Training loss: 2.501559819941422
Validation loss: 2.438281184139488

Epoch: 5| Step: 3
Training loss: 3.0510095957777374
Validation loss: 2.4360269744889362

Epoch: 5| Step: 4
Training loss: 2.742624709876445
Validation loss: 2.419254720216011

Epoch: 5| Step: 5
Training loss: 2.8145600297943405
Validation loss: 2.4261091064674

Epoch: 5| Step: 6
Training loss: 2.1216560306966707
Validation loss: 2.428061220207181

Epoch: 5| Step: 7
Training loss: 2.4748693990447013
Validation loss: 2.431236017101921

Epoch: 5| Step: 8
Training loss: 2.8660575448732537
Validation loss: 2.434423297599533

Epoch: 5| Step: 9
Training loss: 2.6853477376452415
Validation loss: 2.4262639813563607

Epoch: 5| Step: 10
Training loss: 3.2757466986499155
Validation loss: 2.4312433909280946

Epoch: 69| Step: 0
Training loss: 2.9892082023304907
Validation loss: 2.429160784403256

Epoch: 5| Step: 1
Training loss: 2.622252525093433
Validation loss: 2.4238652652370853

Epoch: 5| Step: 2
Training loss: 2.8036813445407938
Validation loss: 2.426576026803949

Epoch: 5| Step: 3
Training loss: 2.431890145487254
Validation loss: 2.429048735237188

Epoch: 5| Step: 4
Training loss: 2.7338266749328164
Validation loss: 2.4223007023840686

Epoch: 5| Step: 5
Training loss: 2.602597692233594
Validation loss: 2.4189771078766196

Epoch: 5| Step: 6
Training loss: 2.8096409146716548
Validation loss: 2.429094872016765

Epoch: 5| Step: 7
Training loss: 2.463665228575098
Validation loss: 2.4264640019676023

Epoch: 5| Step: 8
Training loss: 3.05054335210008
Validation loss: 2.4247893482448433

Epoch: 5| Step: 9
Training loss: 2.7748197307972333
Validation loss: 2.424538260071575

Epoch: 5| Step: 10
Training loss: 2.5959489073111817
Validation loss: 2.4257438706591197

Epoch: 70| Step: 0
Training loss: 2.8471773056167646
Validation loss: 2.428697195176307

Epoch: 5| Step: 1
Training loss: 2.7177617699567644
Validation loss: 2.432741097332853

Epoch: 5| Step: 2
Training loss: 2.3894500837171058
Validation loss: 2.4156228927753602

Epoch: 5| Step: 3
Training loss: 3.131559735053212
Validation loss: 2.4238142555694546

Epoch: 5| Step: 4
Training loss: 2.070878091964214
Validation loss: 2.4188929505886048

Epoch: 5| Step: 5
Training loss: 2.770260476765833
Validation loss: 2.4286293258092435

Epoch: 5| Step: 6
Training loss: 2.8989481103469883
Validation loss: 2.4321321580620454

Epoch: 5| Step: 7
Training loss: 2.3247968195253526
Validation loss: 2.4297796756239785

Epoch: 5| Step: 8
Training loss: 3.1751786489613187
Validation loss: 2.428992569926319

Epoch: 5| Step: 9
Training loss: 2.697912847057177
Validation loss: 2.432049140627064

Epoch: 5| Step: 10
Training loss: 2.767295117603798
Validation loss: 2.444920100253243

Epoch: 71| Step: 0
Training loss: 2.2998220001670546
Validation loss: 2.4386840880768617

Epoch: 5| Step: 1
Training loss: 2.733195023022417
Validation loss: 2.434300038925683

Epoch: 5| Step: 2
Training loss: 2.9687504818564574
Validation loss: 2.4296761098251203

Epoch: 5| Step: 3
Training loss: 2.4183234969854173
Validation loss: 2.435206429860074

Epoch: 5| Step: 4
Training loss: 2.759542381938506
Validation loss: 2.425581224875995

Epoch: 5| Step: 5
Training loss: 3.0645077410584762
Validation loss: 2.4256458630102835

Epoch: 5| Step: 6
Training loss: 2.6148409672184645
Validation loss: 2.428705018989758

Epoch: 5| Step: 7
Training loss: 2.256818612006193
Validation loss: 2.439421850830422

Epoch: 5| Step: 8
Training loss: 2.8679085222496528
Validation loss: 2.426933542384517

Epoch: 5| Step: 9
Training loss: 2.8194489993187535
Validation loss: 2.433693582291147

Epoch: 5| Step: 10
Training loss: 2.891326489259329
Validation loss: 2.4323970059273945

Epoch: 72| Step: 0
Training loss: 2.8100134135839077
Validation loss: 2.4258741891014006

Epoch: 5| Step: 1
Training loss: 2.686392178755707
Validation loss: 2.4378167212991486

Epoch: 5| Step: 2
Training loss: 2.7183739413049164
Validation loss: 2.4371858367523576

Epoch: 5| Step: 3
Training loss: 2.7332292172521
Validation loss: 2.424457723940117

Epoch: 5| Step: 4
Training loss: 2.8114111594027573
Validation loss: 2.4314619942056446

Epoch: 5| Step: 5
Training loss: 2.907754652133566
Validation loss: 2.4331550914529756

Epoch: 5| Step: 6
Training loss: 2.389760777460022
Validation loss: 2.4172106085800342

Epoch: 5| Step: 7
Training loss: 3.018272542216677
Validation loss: 2.420696226521397

Epoch: 5| Step: 8
Training loss: 3.303503812002203
Validation loss: 2.4213436458129163

Epoch: 5| Step: 9
Training loss: 2.2470132289169404
Validation loss: 2.42247159650953

Epoch: 5| Step: 10
Training loss: 1.9068736322598723
Validation loss: 2.420711339131262

Epoch: 73| Step: 0
Training loss: 2.622416814715723
Validation loss: 2.4193591501512017

Epoch: 5| Step: 1
Training loss: 2.748577790531945
Validation loss: 2.417276516246986

Epoch: 5| Step: 2
Training loss: 2.361645446104103
Validation loss: 2.4338502297260383

Epoch: 5| Step: 3
Training loss: 2.8274547140877933
Validation loss: 2.434457193878121

Epoch: 5| Step: 4
Training loss: 2.876947821193346
Validation loss: 2.4305829013706157

Epoch: 5| Step: 5
Training loss: 2.512450116170006
Validation loss: 2.421537130011725

Epoch: 5| Step: 6
Training loss: 3.1116205282797127
Validation loss: 2.4281244229359724

Epoch: 5| Step: 7
Training loss: 2.8551437673095967
Validation loss: 2.423779758811236

Epoch: 5| Step: 8
Training loss: 3.0537690247713285
Validation loss: 2.41984099770971

Epoch: 5| Step: 9
Training loss: 2.480805237542325
Validation loss: 2.4178405862403514

Epoch: 5| Step: 10
Training loss: 2.0629690388340753
Validation loss: 2.434346114355617

Epoch: 74| Step: 0
Training loss: 2.734864894033514
Validation loss: 2.4167865225575547

Epoch: 5| Step: 1
Training loss: 3.0733408662065163
Validation loss: 2.435655536006066

Epoch: 5| Step: 2
Training loss: 2.7464764302615854
Validation loss: 2.4265846910201474

Epoch: 5| Step: 3
Training loss: 2.6045910502187084
Validation loss: 2.4251697095665747

Epoch: 5| Step: 4
Training loss: 2.602451481875337
Validation loss: 2.424536277496898

Epoch: 5| Step: 5
Training loss: 2.6069756172424174
Validation loss: 2.420259295741868

Epoch: 5| Step: 6
Training loss: 2.902845624245403
Validation loss: 2.421692592646736

Epoch: 5| Step: 7
Training loss: 2.8526418654981858
Validation loss: 2.419848556697008

Epoch: 5| Step: 8
Training loss: 2.601122294805725
Validation loss: 2.422685192452584

Epoch: 5| Step: 9
Training loss: 2.3581274915530877
Validation loss: 2.4318420155438365

Epoch: 5| Step: 10
Training loss: 2.6720803165185782
Validation loss: 2.422466310421155

Epoch: 75| Step: 0
Training loss: 2.6504949719234343
Validation loss: 2.430792602683575

Epoch: 5| Step: 1
Training loss: 2.503562201371573
Validation loss: 2.4022988528046274

Epoch: 5| Step: 2
Training loss: 2.505183758420158
Validation loss: 2.4192520561740425

Epoch: 5| Step: 3
Training loss: 2.9164775423767604
Validation loss: 2.4083716504185193

Epoch: 5| Step: 4
Training loss: 3.1023512445117705
Validation loss: 2.428888184234153

Epoch: 5| Step: 5
Training loss: 2.860741294078853
Validation loss: 2.4196887090145025

Epoch: 5| Step: 6
Training loss: 2.570181707051699
Validation loss: 2.4265835436815033

Epoch: 5| Step: 7
Training loss: 2.820172081830553
Validation loss: 2.4251286880258256

Epoch: 5| Step: 8
Training loss: 2.7012109760535368
Validation loss: 2.426266313317024

Epoch: 5| Step: 9
Training loss: 1.8240330211511402
Validation loss: 2.432765798453531

Epoch: 5| Step: 10
Training loss: 3.047418008003321
Validation loss: 2.4206971224783342

Epoch: 76| Step: 0
Training loss: 2.2937414891555425
Validation loss: 2.4255696135462466

Epoch: 5| Step: 1
Training loss: 2.5102637364407068
Validation loss: 2.4262838277809404

Epoch: 5| Step: 2
Training loss: 3.016008579980601
Validation loss: 2.4173073912879115

Epoch: 5| Step: 3
Training loss: 3.1114590049175046
Validation loss: 2.42270447879172

Epoch: 5| Step: 4
Training loss: 2.4434931510328175
Validation loss: 2.419586726530134

Epoch: 5| Step: 5
Training loss: 2.377734266706965
Validation loss: 2.427137747041122

Epoch: 5| Step: 6
Training loss: 3.057194064313713
Validation loss: 2.4168437882954983

Epoch: 5| Step: 7
Training loss: 2.464575799805281
Validation loss: 2.429736515655081

Epoch: 5| Step: 8
Training loss: 2.6483546781389955
Validation loss: 2.429858823102114

Epoch: 5| Step: 9
Training loss: 2.913153376167931
Validation loss: 2.437358510275889

Epoch: 5| Step: 10
Training loss: 2.62352784065435
Validation loss: 2.40867820161339

Epoch: 77| Step: 0
Training loss: 2.4278710741884257
Validation loss: 2.424313355977335

Epoch: 5| Step: 1
Training loss: 2.846486210995874
Validation loss: 2.4264044000647487

Epoch: 5| Step: 2
Training loss: 2.364063177720078
Validation loss: 2.4212828156635733

Epoch: 5| Step: 3
Training loss: 2.7489661961180794
Validation loss: 2.4216774332293447

Epoch: 5| Step: 4
Training loss: 2.785683088512188
Validation loss: 2.4227464688515914

Epoch: 5| Step: 5
Training loss: 2.377535019224567
Validation loss: 2.4271986802494636

Epoch: 5| Step: 6
Training loss: 2.720855511452764
Validation loss: 2.433541397771778

Epoch: 5| Step: 7
Training loss: 2.673964547800338
Validation loss: 2.4192398348174233

Epoch: 5| Step: 8
Training loss: 2.8575400212673365
Validation loss: 2.4156663038467854

Epoch: 5| Step: 9
Training loss: 2.8439260575008323
Validation loss: 2.434987023574985

Epoch: 5| Step: 10
Training loss: 3.0082875855015123
Validation loss: 2.4237464165905536

Epoch: 78| Step: 0
Training loss: 2.9016066342942946
Validation loss: 2.4139559643596122

Epoch: 5| Step: 1
Training loss: 2.6238131792041206
Validation loss: 2.424434909729653

Epoch: 5| Step: 2
Training loss: 2.405312293509739
Validation loss: 2.4174745731170564

Epoch: 5| Step: 3
Training loss: 2.6099231623889274
Validation loss: 2.4267800835414692

Epoch: 5| Step: 4
Training loss: 2.645485732506372
Validation loss: 2.44788472179409

Epoch: 5| Step: 5
Training loss: 2.2615036936292694
Validation loss: 2.4195792949291772

Epoch: 5| Step: 6
Training loss: 2.6093697005349443
Validation loss: 2.4288965684176542

Epoch: 5| Step: 7
Training loss: 2.615361547476244
Validation loss: 2.423124600564099

Epoch: 5| Step: 8
Training loss: 3.3161120604388046
Validation loss: 2.4240625151513178

Epoch: 5| Step: 9
Training loss: 2.8798381068503627
Validation loss: 2.418239910622063

Epoch: 5| Step: 10
Training loss: 2.649374107006127
Validation loss: 2.4213339945959866

Epoch: 79| Step: 0
Training loss: 2.8390193618915007
Validation loss: 2.411665151416312

Epoch: 5| Step: 1
Training loss: 2.5200707619435287
Validation loss: 2.42682692262918

Epoch: 5| Step: 2
Training loss: 3.1876786125853074
Validation loss: 2.414841232648561

Epoch: 5| Step: 3
Training loss: 2.858036749516086
Validation loss: 2.411751022512792

Epoch: 5| Step: 4
Training loss: 2.9749687513745875
Validation loss: 2.407334388994237

Epoch: 5| Step: 5
Training loss: 2.4718090371687795
Validation loss: 2.4134480815215604

Epoch: 5| Step: 6
Training loss: 2.4864634247051054
Validation loss: 2.41728266848497

Epoch: 5| Step: 7
Training loss: 2.482930657256194
Validation loss: 2.4277738472375368

Epoch: 5| Step: 8
Training loss: 2.6047722887908336
Validation loss: 2.423121948182711

Epoch: 5| Step: 9
Training loss: 2.160213531783182
Validation loss: 2.422686563855412

Epoch: 5| Step: 10
Training loss: 2.8455127660250144
Validation loss: 2.42051126891579

Epoch: 80| Step: 0
Training loss: 2.3507343240645473
Validation loss: 2.414666233325847

Epoch: 5| Step: 1
Training loss: 3.03317860079429
Validation loss: 2.411140386028705

Epoch: 5| Step: 2
Training loss: 2.4785458297632537
Validation loss: 2.4199314370337577

Epoch: 5| Step: 3
Training loss: 2.3942154991975766
Validation loss: 2.4222895293630726

Epoch: 5| Step: 4
Training loss: 2.965108304289162
Validation loss: 2.416848837408203

Epoch: 5| Step: 5
Training loss: 2.9304803614639328
Validation loss: 2.4096672926428044

Epoch: 5| Step: 6
Training loss: 2.7484463724640493
Validation loss: 2.418962025764639

Epoch: 5| Step: 7
Training loss: 2.4918215491937064
Validation loss: 2.4114500961813294

Epoch: 5| Step: 8
Training loss: 2.672123412246043
Validation loss: 2.413807847395589

Epoch: 5| Step: 9
Training loss: 2.487992729575031
Validation loss: 2.416204667900571

Epoch: 5| Step: 10
Training loss: 2.9174220787174736
Validation loss: 2.4247219399043054

Epoch: 81| Step: 0
Training loss: 3.2206847662833336
Validation loss: 2.4131973606140296

Epoch: 5| Step: 1
Training loss: 2.713640871388406
Validation loss: 2.4216239468285186

Epoch: 5| Step: 2
Training loss: 2.351153670857006
Validation loss: 2.409917395741113

Epoch: 5| Step: 3
Training loss: 2.2286672181199045
Validation loss: 2.411883824260956

Epoch: 5| Step: 4
Training loss: 2.6558701187457348
Validation loss: 2.436912531035792

Epoch: 5| Step: 5
Training loss: 2.8857453270393245
Validation loss: 2.408796724645061

Epoch: 5| Step: 6
Training loss: 2.67468925525043
Validation loss: 2.412868524273563

Epoch: 5| Step: 7
Training loss: 3.004376398208829
Validation loss: 2.430641587625045

Epoch: 5| Step: 8
Training loss: 2.8397713800205273
Validation loss: 2.4186096047213796

Epoch: 5| Step: 9
Training loss: 2.4270268926211145
Validation loss: 2.4136063339591116

Epoch: 5| Step: 10
Training loss: 2.39039959811063
Validation loss: 2.420440062432548

Epoch: 82| Step: 0
Training loss: 2.4655684238610127
Validation loss: 2.425816905099617

Epoch: 5| Step: 1
Training loss: 2.2976212100327764
Validation loss: 2.4081773043222

Epoch: 5| Step: 2
Training loss: 3.3321090993250335
Validation loss: 2.424210009266119

Epoch: 5| Step: 3
Training loss: 3.003299170612732
Validation loss: 2.399443587712242

Epoch: 5| Step: 4
Training loss: 2.78285950798243
Validation loss: 2.4084369345754633

Epoch: 5| Step: 5
Training loss: 2.3453459328766066
Validation loss: 2.399554783191865

Epoch: 5| Step: 6
Training loss: 2.4908512563136123
Validation loss: 2.4203574907924557

Epoch: 5| Step: 7
Training loss: 2.845631741876657
Validation loss: 2.40872186662739

Epoch: 5| Step: 8
Training loss: 3.0304479422743698
Validation loss: 2.412501630358002

Epoch: 5| Step: 9
Training loss: 2.334604144308006
Validation loss: 2.4137980295709203

Epoch: 5| Step: 10
Training loss: 2.1919798618769897
Validation loss: 2.4090407868886023

Epoch: 83| Step: 0
Training loss: 1.9728041791687545
Validation loss: 2.4251787117914687

Epoch: 5| Step: 1
Training loss: 2.4577711292235938
Validation loss: 2.4148229546900493

Epoch: 5| Step: 2
Training loss: 2.7510845473237344
Validation loss: 2.4040656939576945

Epoch: 5| Step: 3
Training loss: 2.8565035717883585
Validation loss: 2.4198579516324723

Epoch: 5| Step: 4
Training loss: 2.693530037876208
Validation loss: 2.4184336070904817

Epoch: 5| Step: 5
Training loss: 3.0128537425421427
Validation loss: 2.407264082408082

Epoch: 5| Step: 6
Training loss: 3.2690810026843655
Validation loss: 2.415781832608606

Epoch: 5| Step: 7
Training loss: 2.8408891309557163
Validation loss: 2.413763517115038

Epoch: 5| Step: 8
Training loss: 2.511129212196999
Validation loss: 2.4268665775871257

Epoch: 5| Step: 9
Training loss: 2.3698128723760754
Validation loss: 2.411949108482797

Epoch: 5| Step: 10
Training loss: 2.400916095575175
Validation loss: 2.4148181423312143

Epoch: 84| Step: 0
Training loss: 2.836182807002025
Validation loss: 2.4134295752529837

Epoch: 5| Step: 1
Training loss: 2.3629710096275174
Validation loss: 2.4145202946018514

Epoch: 5| Step: 2
Training loss: 2.881170368542256
Validation loss: 2.4126516928767625

Epoch: 5| Step: 3
Training loss: 2.9221099922214813
Validation loss: 2.419218088851948

Epoch: 5| Step: 4
Training loss: 3.3635520338692397
Validation loss: 2.4119679784563894

Epoch: 5| Step: 5
Training loss: 2.4217684814655227
Validation loss: 2.412395999746807

Epoch: 5| Step: 6
Training loss: 2.5205772416943812
Validation loss: 2.420815514022086

Epoch: 5| Step: 7
Training loss: 2.3283946245992215
Validation loss: 2.415428935887132

Epoch: 5| Step: 8
Training loss: 2.6923734258654837
Validation loss: 2.411536297578463

Epoch: 5| Step: 9
Training loss: 2.6058628407625264
Validation loss: 2.4144836540541808

Epoch: 5| Step: 10
Training loss: 2.0796793237492475
Validation loss: 2.411352742958275

Epoch: 85| Step: 0
Training loss: 2.6547725383212417
Validation loss: 2.4113319985975044

Epoch: 5| Step: 1
Training loss: 2.44035934585
Validation loss: 2.4130956626070605

Epoch: 5| Step: 2
Training loss: 3.165705350889805
Validation loss: 2.42320422778529

Epoch: 5| Step: 3
Training loss: 2.573428042683366
Validation loss: 2.4188658683335316

Epoch: 5| Step: 4
Training loss: 2.5002136139206934
Validation loss: 2.411394450150505

Epoch: 5| Step: 5
Training loss: 2.628676428533983
Validation loss: 2.4220140685167264

Epoch: 5| Step: 6
Training loss: 1.928485326005466
Validation loss: 2.410396323911133

Epoch: 5| Step: 7
Training loss: 2.8811321375110217
Validation loss: 2.4176846993609624

Epoch: 5| Step: 8
Training loss: 3.012760838023235
Validation loss: 2.417377724457934

Epoch: 5| Step: 9
Training loss: 2.733701960974895
Validation loss: 2.413595329936975

Epoch: 5| Step: 10
Training loss: 2.6767917479208316
Validation loss: 2.4127326029008622

Epoch: 86| Step: 0
Training loss: 2.8648472519877357
Validation loss: 2.4109125860400735

Epoch: 5| Step: 1
Training loss: 3.24760921279948
Validation loss: 2.40591318782762

Epoch: 5| Step: 2
Training loss: 2.5840237730544766
Validation loss: 2.4011393758449615

Epoch: 5| Step: 3
Training loss: 2.627962892592616
Validation loss: 2.4106013078460724

Epoch: 5| Step: 4
Training loss: 2.166224642438445
Validation loss: 2.408322885465592

Epoch: 5| Step: 5
Training loss: 2.246407077330393
Validation loss: 2.4135935433718902

Epoch: 5| Step: 6
Training loss: 2.123192411065068
Validation loss: 2.42221854343902

Epoch: 5| Step: 7
Training loss: 2.1797048916686874
Validation loss: 2.419902346128985

Epoch: 5| Step: 8
Training loss: 2.894280509024133
Validation loss: 2.425113413190224

Epoch: 5| Step: 9
Training loss: 3.131343049819725
Validation loss: 2.4120167520864375

Epoch: 5| Step: 10
Training loss: 3.04013976001713
Validation loss: 2.4222223165798753

Epoch: 87| Step: 0
Training loss: 2.9144673002394517
Validation loss: 2.4163655194918006

Epoch: 5| Step: 1
Training loss: 2.42699545727129
Validation loss: 2.41257450779953

Epoch: 5| Step: 2
Training loss: 2.1673723929922115
Validation loss: 2.416840027972565

Epoch: 5| Step: 3
Training loss: 2.174060737112366
Validation loss: 2.4109914735221794

Epoch: 5| Step: 4
Training loss: 3.0299701938485057
Validation loss: 2.410334832457437

Epoch: 5| Step: 5
Training loss: 2.7122312421421686
Validation loss: 2.4046660943376463

Epoch: 5| Step: 6
Training loss: 2.715708642863288
Validation loss: 2.418711950620717

Epoch: 5| Step: 7
Training loss: 2.738081594200181
Validation loss: 2.41061109934138

Epoch: 5| Step: 8
Training loss: 3.062650871453127
Validation loss: 2.422063288149038

Epoch: 5| Step: 9
Training loss: 2.882634185817403
Validation loss: 2.4110657884454256

Epoch: 5| Step: 10
Training loss: 2.2332594427534525
Validation loss: 2.4092373628255825

Epoch: 88| Step: 0
Training loss: 2.6163613908714565
Validation loss: 2.418415123071545

Epoch: 5| Step: 1
Training loss: 2.1767092905160075
Validation loss: 2.4047619938946476

Epoch: 5| Step: 2
Training loss: 2.6260432032381793
Validation loss: 2.412963056110451

Epoch: 5| Step: 3
Training loss: 2.423977831106506
Validation loss: 2.400389941473651

Epoch: 5| Step: 4
Training loss: 2.5257763490590985
Validation loss: 2.405027387091829

Epoch: 5| Step: 5
Training loss: 3.103793247642131
Validation loss: 2.388598648218126

Epoch: 5| Step: 6
Training loss: 2.5496339423035015
Validation loss: 2.406953640313038

Epoch: 5| Step: 7
Training loss: 2.9456215450947307
Validation loss: 2.414253679423111

Epoch: 5| Step: 8
Training loss: 2.7124713878616786
Validation loss: 2.416288658878422

Epoch: 5| Step: 9
Training loss: 3.0372359172793795
Validation loss: 2.4096234341052933

Epoch: 5| Step: 10
Training loss: 2.273199429451171
Validation loss: 2.4105492975043337

Epoch: 89| Step: 0
Training loss: 2.6562238804150082
Validation loss: 2.4043885675338887

Epoch: 5| Step: 1
Training loss: 2.1968956936855983
Validation loss: 2.412125325765684

Epoch: 5| Step: 2
Training loss: 2.685574840053261
Validation loss: 2.412636456463129

Epoch: 5| Step: 3
Training loss: 2.387603445957667
Validation loss: 2.413871808844826

Epoch: 5| Step: 4
Training loss: 2.6543517566702475
Validation loss: 2.415585678874304

Epoch: 5| Step: 5
Training loss: 2.710770043909485
Validation loss: 2.410551866408716

Epoch: 5| Step: 6
Training loss: 2.703417811769064
Validation loss: 2.411858687124284

Epoch: 5| Step: 7
Training loss: 2.312171087844784
Validation loss: 2.4029369305885844

Epoch: 5| Step: 8
Training loss: 3.020499761295041
Validation loss: 2.4092808229809406

Epoch: 5| Step: 9
Training loss: 2.809327094801518
Validation loss: 2.404439985048427

Epoch: 5| Step: 10
Training loss: 2.9918591989036605
Validation loss: 2.4216185053859327

Epoch: 90| Step: 0
Training loss: 3.004052603818513
Validation loss: 2.4140843072741163

Epoch: 5| Step: 1
Training loss: 2.7260299206195064
Validation loss: 2.4152999909537267

Epoch: 5| Step: 2
Training loss: 2.0666981366540487
Validation loss: 2.4113624734606427

Epoch: 5| Step: 3
Training loss: 2.320775149681597
Validation loss: 2.4159122586553035

Epoch: 5| Step: 4
Training loss: 2.6420542443689508
Validation loss: 2.4132674709730293

Epoch: 5| Step: 5
Training loss: 2.6432740055784785
Validation loss: 2.4043694083003357

Epoch: 5| Step: 6
Training loss: 2.624380401874678
Validation loss: 2.40145036833503

Epoch: 5| Step: 7
Training loss: 2.377070177216249
Validation loss: 2.4124991788272436

Epoch: 5| Step: 8
Training loss: 2.9091598545920974
Validation loss: 2.408201216270029

Epoch: 5| Step: 9
Training loss: 2.7932769818718004
Validation loss: 2.4223161595285854

Epoch: 5| Step: 10
Training loss: 2.8556824902904667
Validation loss: 2.401867226207794

Epoch: 91| Step: 0
Training loss: 1.965797450713902
Validation loss: 2.4081231752775922

Epoch: 5| Step: 1
Training loss: 1.9103256181703014
Validation loss: 2.410282063317885

Epoch: 5| Step: 2
Training loss: 3.188317586723988
Validation loss: 2.403946205032217

Epoch: 5| Step: 3
Training loss: 2.854914787610839
Validation loss: 2.3984953566797182

Epoch: 5| Step: 4
Training loss: 2.7021355554558313
Validation loss: 2.4099450412989296

Epoch: 5| Step: 5
Training loss: 3.0800648110246485
Validation loss: 2.4027758202027254

Epoch: 5| Step: 6
Training loss: 2.6098834244866955
Validation loss: 2.414420981916329

Epoch: 5| Step: 7
Training loss: 2.35420357554262
Validation loss: 2.4230948486558055

Epoch: 5| Step: 8
Training loss: 2.861819697002139
Validation loss: 2.4139502119862253

Epoch: 5| Step: 9
Training loss: 2.3473468900399395
Validation loss: 2.413899080945918

Epoch: 5| Step: 10
Training loss: 2.8902135607736468
Validation loss: 2.411178746654762

Epoch: 92| Step: 0
Training loss: 1.8944523431135367
Validation loss: 2.4194245600823274

Epoch: 5| Step: 1
Training loss: 2.6326699600347245
Validation loss: 2.4250369091246498

Epoch: 5| Step: 2
Training loss: 2.825682032802079
Validation loss: 2.413010747734635

Epoch: 5| Step: 3
Training loss: 2.830898716167488
Validation loss: 2.417782147002462

Epoch: 5| Step: 4
Training loss: 2.635753313559094
Validation loss: 2.398043548145663

Epoch: 5| Step: 5
Training loss: 2.780925431761708
Validation loss: 2.400669954178477

Epoch: 5| Step: 6
Training loss: 2.7534195706653213
Validation loss: 2.4114896871964344

Epoch: 5| Step: 7
Training loss: 2.7551681332939566
Validation loss: 2.4221254333729036

Epoch: 5| Step: 8
Training loss: 2.3787944999216863
Validation loss: 2.4105683225399965

Epoch: 5| Step: 9
Training loss: 2.8358176129854775
Validation loss: 2.409193345358091

Epoch: 5| Step: 10
Training loss: 2.6780905010267024
Validation loss: 2.411872942056857

Epoch: 93| Step: 0
Training loss: 2.5628706501183944
Validation loss: 2.4054780213695905

Epoch: 5| Step: 1
Training loss: 2.5422983062173112
Validation loss: 2.4184485472730057

Epoch: 5| Step: 2
Training loss: 2.485001203202814
Validation loss: 2.417921284460812

Epoch: 5| Step: 3
Training loss: 2.9093680114334366
Validation loss: 2.4099150937032943

Epoch: 5| Step: 4
Training loss: 2.5240899060494657
Validation loss: 2.3984860084670436

Epoch: 5| Step: 5
Training loss: 2.5382145331324604
Validation loss: 2.4054837178020043

Epoch: 5| Step: 6
Training loss: 2.8348815465330355
Validation loss: 2.4077925865447236

Epoch: 5| Step: 7
Training loss: 3.08184032549873
Validation loss: 2.4141207223809693

Epoch: 5| Step: 8
Training loss: 2.5300601941513277
Validation loss: 2.4132810079644265

Epoch: 5| Step: 9
Training loss: 2.300639072034227
Validation loss: 2.406181754252614

Epoch: 5| Step: 10
Training loss: 2.5914351463144336
Validation loss: 2.4164849024837918

Epoch: 94| Step: 0
Training loss: 2.333627125999761
Validation loss: 2.413023860136552

Epoch: 5| Step: 1
Training loss: 2.136564092251925
Validation loss: 2.4052978685984736

Epoch: 5| Step: 2
Training loss: 2.9513324767063307
Validation loss: 2.405787408175584

Epoch: 5| Step: 3
Training loss: 2.710843922871607
Validation loss: 2.404762175659293

Epoch: 5| Step: 4
Training loss: 2.7306179720770043
Validation loss: 2.4003998013223904

Epoch: 5| Step: 5
Training loss: 2.659615393059956
Validation loss: 2.424723042660267

Epoch: 5| Step: 6
Training loss: 2.764140274739156
Validation loss: 2.4065078950865044

Epoch: 5| Step: 7
Training loss: 2.79775228540598
Validation loss: 2.40515988004882

Epoch: 5| Step: 8
Training loss: 2.30179437633374
Validation loss: 2.417344043651944

Epoch: 5| Step: 9
Training loss: 2.8143338476633355
Validation loss: 2.4199347868088608

Epoch: 5| Step: 10
Training loss: 2.6842729577952174
Validation loss: 2.4098687641928396

Epoch: 95| Step: 0
Training loss: 2.568970303706464
Validation loss: 2.406008166618209

Epoch: 5| Step: 1
Training loss: 2.178380977962796
Validation loss: 2.4177324553089723

Epoch: 5| Step: 2
Training loss: 2.545963147522222
Validation loss: 2.397155107841278

Epoch: 5| Step: 3
Training loss: 2.304553425655222
Validation loss: 2.4001721707495083

Epoch: 5| Step: 4
Training loss: 2.350620828963101
Validation loss: 2.4036717851690304

Epoch: 5| Step: 5
Training loss: 3.2263080043965733
Validation loss: 2.415369003305564

Epoch: 5| Step: 6
Training loss: 2.936317043326668
Validation loss: 2.4030187011313053

Epoch: 5| Step: 7
Training loss: 3.098105399243114
Validation loss: 2.404862419166921

Epoch: 5| Step: 8
Training loss: 2.7304692739068703
Validation loss: 2.40793792265283

Epoch: 5| Step: 9
Training loss: 2.459274650571953
Validation loss: 2.407956137890575

Epoch: 5| Step: 10
Training loss: 2.418780213790772
Validation loss: 2.4070598292701795

Epoch: 96| Step: 0
Training loss: 3.0152894460939543
Validation loss: 2.4031165562636883

Epoch: 5| Step: 1
Training loss: 2.65778333501047
Validation loss: 2.4104434369602172

Epoch: 5| Step: 2
Training loss: 2.3332765663144412
Validation loss: 2.3963736318575126

Epoch: 5| Step: 3
Training loss: 2.6313503291558376
Validation loss: 2.4148672485365417

Epoch: 5| Step: 4
Training loss: 2.5898886744312515
Validation loss: 2.4284652591705407

Epoch: 5| Step: 5
Training loss: 2.125357990403458
Validation loss: 2.409015046489638

Epoch: 5| Step: 6
Training loss: 2.7706221784477916
Validation loss: 2.415179385489603

Epoch: 5| Step: 7
Training loss: 2.999237758440106
Validation loss: 2.4135763558471877

Epoch: 5| Step: 8
Training loss: 2.475273880110073
Validation loss: 2.4108740350900204

Epoch: 5| Step: 9
Training loss: 2.430032589069877
Validation loss: 2.403005029515606

Epoch: 5| Step: 10
Training loss: 2.795198673427684
Validation loss: 2.397633805264453

Epoch: 97| Step: 0
Training loss: 3.0242256497555946
Validation loss: 2.404320848998083

Epoch: 5| Step: 1
Training loss: 2.3104650461986673
Validation loss: 2.4158973144607843

Epoch: 5| Step: 2
Training loss: 2.709703411891017
Validation loss: 2.405985533882537

Epoch: 5| Step: 3
Training loss: 2.5055602230339624
Validation loss: 2.4135678833928687

Epoch: 5| Step: 4
Training loss: 2.8487670573870054
Validation loss: 2.4048497750250886

Epoch: 5| Step: 5
Training loss: 2.405262038296425
Validation loss: 2.405185170334952

Epoch: 5| Step: 6
Training loss: 2.4321815961373763
Validation loss: 2.416200639205594

Epoch: 5| Step: 7
Training loss: 2.9169511565472974
Validation loss: 2.410384333121018

Epoch: 5| Step: 8
Training loss: 2.2828411667085895
Validation loss: 2.396230902372674

Epoch: 5| Step: 9
Training loss: 2.007007719609535
Validation loss: 2.3971951884018545

Epoch: 5| Step: 10
Training loss: 3.3376770486911798
Validation loss: 2.404138120667067

Epoch: 98| Step: 0
Training loss: 2.6789865717022705
Validation loss: 2.390896659427629

Epoch: 5| Step: 1
Training loss: 2.422825780483038
Validation loss: 2.405404300643807

Epoch: 5| Step: 2
Training loss: 2.357288069194814
Validation loss: 2.3993864558735165

Epoch: 5| Step: 3
Training loss: 2.4500533390077766
Validation loss: 2.402283929573092

Epoch: 5| Step: 4
Training loss: 2.6875854301181477
Validation loss: 2.409630544255721

Epoch: 5| Step: 5
Training loss: 2.624089219262915
Validation loss: 2.3931163631953716

Epoch: 5| Step: 6
Training loss: 2.422039592441361
Validation loss: 2.4059778354433887

Epoch: 5| Step: 7
Training loss: 2.5038029356306004
Validation loss: 2.3971785827169967

Epoch: 5| Step: 8
Training loss: 2.833252026756381
Validation loss: 2.409702544650982

Epoch: 5| Step: 9
Training loss: 3.3154860658866263
Validation loss: 2.410448815089039

Epoch: 5| Step: 10
Training loss: 2.467549768659049
Validation loss: 2.410817888729907

Epoch: 99| Step: 0
Training loss: 2.629946181323202
Validation loss: 2.4188634033807106

Epoch: 5| Step: 1
Training loss: 3.0758565686620445
Validation loss: 2.401036628445768

Epoch: 5| Step: 2
Training loss: 2.882943499310183
Validation loss: 2.414623713102398

Epoch: 5| Step: 3
Training loss: 2.2046195297523736
Validation loss: 2.409830945477948

Epoch: 5| Step: 4
Training loss: 2.7307744325772187
Validation loss: 2.4176162297620354

Epoch: 5| Step: 5
Training loss: 2.482798526021189
Validation loss: 2.4112758166523363

Epoch: 5| Step: 6
Training loss: 2.8015509363160245
Validation loss: 2.416454262004161

Epoch: 5| Step: 7
Training loss: 2.665502433150338
Validation loss: 2.399082915892966

Epoch: 5| Step: 8
Training loss: 2.3171141702234577
Validation loss: 2.4174274955559745

Epoch: 5| Step: 9
Training loss: 2.5502949787141467
Validation loss: 2.413039153599088

Epoch: 5| Step: 10
Training loss: 2.407083441327276
Validation loss: 2.411111841899013

Epoch: 100| Step: 0
Training loss: 2.6518889586445193
Validation loss: 2.413475107726922

Epoch: 5| Step: 1
Training loss: 2.375842296414398
Validation loss: 2.415113317627218

Epoch: 5| Step: 2
Training loss: 2.4355118297022558
Validation loss: 2.4125668946741103

Epoch: 5| Step: 3
Training loss: 1.9678776942953544
Validation loss: 2.4209042384895656

Epoch: 5| Step: 4
Training loss: 2.6182916390320514
Validation loss: 2.411506004042151

Epoch: 5| Step: 5
Training loss: 2.911022738295518
Validation loss: 2.420447278499529

Epoch: 5| Step: 6
Training loss: 2.8321393433035205
Validation loss: 2.422274607579276

Epoch: 5| Step: 7
Training loss: 2.518240948675471
Validation loss: 2.419769426649329

Epoch: 5| Step: 8
Training loss: 2.683367457281451
Validation loss: 2.3954955759538534

Epoch: 5| Step: 9
Training loss: 2.7165600956645397
Validation loss: 2.4066879423680048

Epoch: 5| Step: 10
Training loss: 2.986837918645453
Validation loss: 2.405146511594409

Epoch: 101| Step: 0
Training loss: 2.5456245956963794
Validation loss: 2.4159352928866946

Epoch: 5| Step: 1
Training loss: 2.738184427897734
Validation loss: 2.4105900805986935

Epoch: 5| Step: 2
Training loss: 2.508788112166519
Validation loss: 2.407240916215603

Epoch: 5| Step: 3
Training loss: 2.6240343406686395
Validation loss: 2.3903264971873677

Epoch: 5| Step: 4
Training loss: 2.825185270057549
Validation loss: 2.402205947137093

Epoch: 5| Step: 5
Training loss: 2.613484692601882
Validation loss: 2.4021539337831523

Epoch: 5| Step: 6
Training loss: 2.306078681682045
Validation loss: 2.403220946076549

Epoch: 5| Step: 7
Training loss: 2.4979705202365183
Validation loss: 2.411658026003999

Epoch: 5| Step: 8
Training loss: 2.5709026551960106
Validation loss: 2.4170617380718307

Epoch: 5| Step: 9
Training loss: 2.7992894497246694
Validation loss: 2.3911619420527646

Epoch: 5| Step: 10
Training loss: 2.801542085657244
Validation loss: 2.3979264217489145

Epoch: 102| Step: 0
Training loss: 2.540994044453421
Validation loss: 2.4038190544058633

Epoch: 5| Step: 1
Training loss: 2.2386539275462196
Validation loss: 2.41655834989199

Epoch: 5| Step: 2
Training loss: 2.7610823398458164
Validation loss: 2.3931762831582915

Epoch: 5| Step: 3
Training loss: 2.448154832873909
Validation loss: 2.410870547248165

Epoch: 5| Step: 4
Training loss: 2.3249318799940246
Validation loss: 2.413654866833835

Epoch: 5| Step: 5
Training loss: 2.5678332584057815
Validation loss: 2.406471578908662

Epoch: 5| Step: 6
Training loss: 3.1549985311900737
Validation loss: 2.412610518529491

Epoch: 5| Step: 7
Training loss: 2.8827741253374057
Validation loss: 2.4049978856592147

Epoch: 5| Step: 8
Training loss: 2.5352021435079424
Validation loss: 2.407218511261318

Epoch: 5| Step: 9
Training loss: 2.8440943918136576
Validation loss: 2.389836771668485

Epoch: 5| Step: 10
Training loss: 2.1808523258270904
Validation loss: 2.408461490587411

Epoch: 103| Step: 0
Training loss: 2.3079030509235343
Validation loss: 2.40076536251264

Epoch: 5| Step: 1
Training loss: 2.46478358465843
Validation loss: 2.404947779509807

Epoch: 5| Step: 2
Training loss: 2.7881382711813405
Validation loss: 2.3888030042311046

Epoch: 5| Step: 3
Training loss: 2.8392244316952397
Validation loss: 2.4110458598174236

Epoch: 5| Step: 4
Training loss: 2.6091661198324165
Validation loss: 2.404118682185696

Epoch: 5| Step: 5
Training loss: 2.5370439692781797
Validation loss: 2.418305007884475

Epoch: 5| Step: 6
Training loss: 2.4427480687621896
Validation loss: 2.4125245297877838

Epoch: 5| Step: 7
Training loss: 2.271355058657768
Validation loss: 2.3979332779242095

Epoch: 5| Step: 8
Training loss: 3.0272311281974873
Validation loss: 2.4089701842372837

Epoch: 5| Step: 9
Training loss: 2.526613581040189
Validation loss: 2.4003141681670637

Epoch: 5| Step: 10
Training loss: 2.7474262157525975
Validation loss: 2.3877654544558236

Epoch: 104| Step: 0
Training loss: 2.374240151371954
Validation loss: 2.405640599389671

Epoch: 5| Step: 1
Training loss: 2.4616308779515803
Validation loss: 2.397515492789397

Epoch: 5| Step: 2
Training loss: 3.124966277894223
Validation loss: 2.401117023394754

Epoch: 5| Step: 3
Training loss: 2.46525142339192
Validation loss: 2.3890691567403355

Epoch: 5| Step: 4
Training loss: 2.627865362779966
Validation loss: 2.398627021946534

Epoch: 5| Step: 5
Training loss: 2.953311328963835
Validation loss: 2.3956129367747097

Epoch: 5| Step: 6
Training loss: 2.5012414710773054
Validation loss: 2.392988435722259

Epoch: 5| Step: 7
Training loss: 2.859056465458607
Validation loss: 2.4068129368025852

Epoch: 5| Step: 8
Training loss: 2.205140618924552
Validation loss: 2.404373296883265

Epoch: 5| Step: 9
Training loss: 2.4409993801592798
Validation loss: 2.410616349744499

Epoch: 5| Step: 10
Training loss: 2.419561745707326
Validation loss: 2.4028781907665544

Epoch: 105| Step: 0
Training loss: 1.7704802740851655
Validation loss: 2.4053125780848488

Epoch: 5| Step: 1
Training loss: 3.1495400289731204
Validation loss: 2.4034024412006567

Epoch: 5| Step: 2
Training loss: 2.4029119548439417
Validation loss: 2.394183734762016

Epoch: 5| Step: 3
Training loss: 2.4838405970045914
Validation loss: 2.4130941795148306

Epoch: 5| Step: 4
Training loss: 2.314560049943073
Validation loss: 2.4067371782424534

Epoch: 5| Step: 5
Training loss: 2.608588368517959
Validation loss: 2.4072787543211724

Epoch: 5| Step: 6
Training loss: 3.1618985535226387
Validation loss: 2.3883387559444293

Epoch: 5| Step: 7
Training loss: 2.4211888479566155
Validation loss: 2.4184542809967082

Epoch: 5| Step: 8
Training loss: 3.015825650353899
Validation loss: 2.417933218789677

Epoch: 5| Step: 9
Training loss: 2.212701639588447
Validation loss: 2.4024439546282808

Epoch: 5| Step: 10
Training loss: 2.903375496132977
Validation loss: 2.414069423976895

Epoch: 106| Step: 0
Training loss: 2.5241692488883727
Validation loss: 2.4005253506514417

Epoch: 5| Step: 1
Training loss: 2.531195745946345
Validation loss: 2.410195135253394

Epoch: 5| Step: 2
Training loss: 2.42420109439067
Validation loss: 2.396795758104943

Epoch: 5| Step: 3
Training loss: 2.158433554935564
Validation loss: 2.4046837480025594

Epoch: 5| Step: 4
Training loss: 2.7060869339584466
Validation loss: 2.398271677924625

Epoch: 5| Step: 5
Training loss: 2.6375336016643365
Validation loss: 2.4076775539372073

Epoch: 5| Step: 6
Training loss: 3.016779070985273
Validation loss: 2.398000439181167

Epoch: 5| Step: 7
Training loss: 2.843332280929866
Validation loss: 2.404861305171765

Epoch: 5| Step: 8
Training loss: 2.1821252460495986
Validation loss: 2.4031899924691897

Epoch: 5| Step: 9
Training loss: 2.6578993220784213
Validation loss: 2.396266951161365

Epoch: 5| Step: 10
Training loss: 2.621621091640118
Validation loss: 2.392500850592345

Epoch: 107| Step: 0
Training loss: 3.0755395245394577
Validation loss: 2.417993721834765

Epoch: 5| Step: 1
Training loss: 2.4107262727146743
Validation loss: 2.3975985543743468

Epoch: 5| Step: 2
Training loss: 2.6376719920410228
Validation loss: 2.3848039481675034

Epoch: 5| Step: 3
Training loss: 1.8382329348380713
Validation loss: 2.387319627307383

Epoch: 5| Step: 4
Training loss: 2.373687180526038
Validation loss: 2.405530836212687

Epoch: 5| Step: 5
Training loss: 2.7060977707967395
Validation loss: 2.3888210444949025

Epoch: 5| Step: 6
Training loss: 2.693363358437274
Validation loss: 2.4009411817739568

Epoch: 5| Step: 7
Training loss: 2.987299260374279
Validation loss: 2.407229788845298

Epoch: 5| Step: 8
Training loss: 3.1640834477990984
Validation loss: 2.388375319930978

Epoch: 5| Step: 9
Training loss: 1.9670086380148784
Validation loss: 2.3997998019092965

Epoch: 5| Step: 10
Training loss: 2.4262768520184133
Validation loss: 2.4018696256165573

Epoch: 108| Step: 0
Training loss: 2.8741842024671826
Validation loss: 2.399939469160353

Epoch: 5| Step: 1
Training loss: 2.050335935654361
Validation loss: 2.3975630025012853

Epoch: 5| Step: 2
Training loss: 1.9896827659592555
Validation loss: 2.3916914704025536

Epoch: 5| Step: 3
Training loss: 2.7438227893671785
Validation loss: 2.403567624523186

Epoch: 5| Step: 4
Training loss: 2.3291109800648178
Validation loss: 2.407953112141414

Epoch: 5| Step: 5
Training loss: 2.9700679062295436
Validation loss: 2.392421374833561

Epoch: 5| Step: 6
Training loss: 2.774766974073047
Validation loss: 2.4102311033548105

Epoch: 5| Step: 7
Training loss: 2.3316605111895936
Validation loss: 2.4030678649628014

Epoch: 5| Step: 8
Training loss: 2.822216543015033
Validation loss: 2.3808173197169977

Epoch: 5| Step: 9
Training loss: 2.7101828984269725
Validation loss: 2.382971134483097

Epoch: 5| Step: 10
Training loss: 2.734149683797177
Validation loss: 2.396468837891693

Epoch: 109| Step: 0
Training loss: 2.839061015269889
Validation loss: 2.4040409373523453

Epoch: 5| Step: 1
Training loss: 2.5005812922831376
Validation loss: 2.419518046394534

Epoch: 5| Step: 2
Training loss: 2.9314984637208754
Validation loss: 2.3956065983285697

Epoch: 5| Step: 3
Training loss: 2.2264496356400034
Validation loss: 2.3962557295027866

Epoch: 5| Step: 4
Training loss: 2.7613701283342547
Validation loss: 2.39749592896986

Epoch: 5| Step: 5
Training loss: 2.40178762062066
Validation loss: 2.4001050264697064

Epoch: 5| Step: 6
Training loss: 2.839359121410484
Validation loss: 2.3989169663759435

Epoch: 5| Step: 7
Training loss: 2.7368922390670374
Validation loss: 2.399366984238841

Epoch: 5| Step: 8
Training loss: 2.326154758444845
Validation loss: 2.412755805617693

Epoch: 5| Step: 9
Training loss: 2.377354107701619
Validation loss: 2.391069392776996

Epoch: 5| Step: 10
Training loss: 2.309958014498869
Validation loss: 2.396905220729932

Epoch: 110| Step: 0
Training loss: 2.471697050264974
Validation loss: 2.4007974125403657

Epoch: 5| Step: 1
Training loss: 2.6951009031525754
Validation loss: 2.397017215241921

Epoch: 5| Step: 2
Training loss: 2.526547243052168
Validation loss: 2.4048686777846555

Epoch: 5| Step: 3
Training loss: 2.250448923890366
Validation loss: 2.401113062273946

Epoch: 5| Step: 4
Training loss: 2.8589822468161397
Validation loss: 2.3870474319158625

Epoch: 5| Step: 5
Training loss: 2.4784296259828937
Validation loss: 2.411132971987723

Epoch: 5| Step: 6
Training loss: 3.0030171798737992
Validation loss: 2.4152488927341227

Epoch: 5| Step: 7
Training loss: 2.0813748754664307
Validation loss: 2.396109005680511

Epoch: 5| Step: 8
Training loss: 2.3416362131475763
Validation loss: 2.3955130853041395

Epoch: 5| Step: 9
Training loss: 2.724051907295479
Validation loss: 2.396805078682629

Epoch: 5| Step: 10
Training loss: 2.834922419702596
Validation loss: 2.3917413858589636

Epoch: 111| Step: 0
Training loss: 2.7220929519512187
Validation loss: 2.402843506530276

Epoch: 5| Step: 1
Training loss: 2.6136178796287974
Validation loss: 2.400955567192997

Epoch: 5| Step: 2
Training loss: 2.6750913301367403
Validation loss: 2.3990844589392117

Epoch: 5| Step: 3
Training loss: 2.667724776946578
Validation loss: 2.4068643898668993

Epoch: 5| Step: 4
Training loss: 2.7774236697087376
Validation loss: 2.4069492680832654

Epoch: 5| Step: 5
Training loss: 2.4929736580556807
Validation loss: 2.386623380595823

Epoch: 5| Step: 6
Training loss: 2.250717472548554
Validation loss: 2.4142918302412273

Epoch: 5| Step: 7
Training loss: 2.360246509996712
Validation loss: 2.3973971049682588

Epoch: 5| Step: 8
Training loss: 2.227896093565215
Validation loss: 2.397487688400909

Epoch: 5| Step: 9
Training loss: 2.5784541989161265
Validation loss: 2.3896628453055175

Epoch: 5| Step: 10
Training loss: 2.924389415166538
Validation loss: 2.40970094350712

Epoch: 112| Step: 0
Training loss: 2.5836735983276435
Validation loss: 2.3960038060714055

Epoch: 5| Step: 1
Training loss: 2.403573368147033
Validation loss: 2.404297401739584

Epoch: 5| Step: 2
Training loss: 2.5211312824643644
Validation loss: 2.385100900532133

Epoch: 5| Step: 3
Training loss: 2.04407455247161
Validation loss: 2.4178665072985974

Epoch: 5| Step: 4
Training loss: 2.6331622064090983
Validation loss: 2.40336415965941

Epoch: 5| Step: 5
Training loss: 2.514186092205148
Validation loss: 2.3973002910832006

Epoch: 5| Step: 6
Training loss: 2.973623992956954
Validation loss: 2.3892116541625614

Epoch: 5| Step: 7
Training loss: 2.6569524397206012
Validation loss: 2.4061258420114453

Epoch: 5| Step: 8
Training loss: 2.1081901330779043
Validation loss: 2.4034557976449276

Epoch: 5| Step: 9
Training loss: 3.107591740672635
Validation loss: 2.4012977599302516

Epoch: 5| Step: 10
Training loss: 2.661877493999358
Validation loss: 2.394572346588307

Epoch: 113| Step: 0
Training loss: 2.5090502955236924
Validation loss: 2.399749268339152

Epoch: 5| Step: 1
Training loss: 2.1885505333535793
Validation loss: 2.400436603448191

Epoch: 5| Step: 2
Training loss: 2.5295677717502336
Validation loss: 2.392299744561104

Epoch: 5| Step: 3
Training loss: 3.058671075810539
Validation loss: 2.399888449814468

Epoch: 5| Step: 4
Training loss: 2.6321297957467285
Validation loss: 2.3953007309815706

Epoch: 5| Step: 5
Training loss: 2.8307572228598037
Validation loss: 2.406751451259527

Epoch: 5| Step: 6
Training loss: 2.75989071615829
Validation loss: 2.3876749692402086

Epoch: 5| Step: 7
Training loss: 2.207405747230004
Validation loss: 2.3863791661599976

Epoch: 5| Step: 8
Training loss: 2.4337198338061983
Validation loss: 2.3892259068709527

Epoch: 5| Step: 9
Training loss: 2.782297687150294
Validation loss: 2.403745585159233

Epoch: 5| Step: 10
Training loss: 2.0878342138222417
Validation loss: 2.387056653088298

Epoch: 114| Step: 0
Training loss: 2.69843047759043
Validation loss: 2.407055342207609

Epoch: 5| Step: 1
Training loss: 2.477484594580123
Validation loss: 2.399994051961809

Epoch: 5| Step: 2
Training loss: 3.2909875161077045
Validation loss: 2.3874309278754513

Epoch: 5| Step: 3
Training loss: 2.0862559100525044
Validation loss: 2.399979471175267

Epoch: 5| Step: 4
Training loss: 2.6239689209772274
Validation loss: 2.4157496619538343

Epoch: 5| Step: 5
Training loss: 2.678087474155031
Validation loss: 2.3969163842655568

Epoch: 5| Step: 6
Training loss: 2.1504116906183217
Validation loss: 2.4001561191842224

Epoch: 5| Step: 7
Training loss: 2.263199343004128
Validation loss: 2.3950571594329704

Epoch: 5| Step: 8
Training loss: 2.381531518029608
Validation loss: 2.394879233452473

Epoch: 5| Step: 9
Training loss: 2.630086965247192
Validation loss: 2.3872221845801898

Epoch: 5| Step: 10
Training loss: 2.713969620964027
Validation loss: 2.3991931086989897

Epoch: 115| Step: 0
Training loss: 2.4656845569065564
Validation loss: 2.3925960735813905

Epoch: 5| Step: 1
Training loss: 2.98616333750709
Validation loss: 2.407829989032344

Epoch: 5| Step: 2
Training loss: 2.905717698438301
Validation loss: 2.4052426621909997

Epoch: 5| Step: 3
Training loss: 2.526330570859498
Validation loss: 2.4053566905500867

Epoch: 5| Step: 4
Training loss: 2.551213132974119
Validation loss: 2.39884066669563

Epoch: 5| Step: 5
Training loss: 3.109292034019935
Validation loss: 2.395674060237324

Epoch: 5| Step: 6
Training loss: 2.27025945802333
Validation loss: 2.395867931085839

Epoch: 5| Step: 7
Training loss: 2.1052728395490385
Validation loss: 2.404096705603702

Epoch: 5| Step: 8
Training loss: 2.082824441427696
Validation loss: 2.3907536844600625

Epoch: 5| Step: 9
Training loss: 2.453270877461244
Validation loss: 2.400882273531479

Epoch: 5| Step: 10
Training loss: 2.7092609773114096
Validation loss: 2.4065504138270297

Epoch: 116| Step: 0
Training loss: 2.5512421032467034
Validation loss: 2.3927563147691346

Epoch: 5| Step: 1
Training loss: 2.2915870883880873
Validation loss: 2.4011767319616193

Epoch: 5| Step: 2
Training loss: 2.4572708182901137
Validation loss: 2.408574214898644

Epoch: 5| Step: 3
Training loss: 2.7842176228069317
Validation loss: 2.4232571794333015

Epoch: 5| Step: 4
Training loss: 2.820000544067763
Validation loss: 2.3897198073178596

Epoch: 5| Step: 5
Training loss: 2.209521375930398
Validation loss: 2.411293933315731

Epoch: 5| Step: 6
Training loss: 1.987355494494121
Validation loss: 2.3962626182743487

Epoch: 5| Step: 7
Training loss: 3.2042207657935156
Validation loss: 2.3929728523464484

Epoch: 5| Step: 8
Training loss: 2.6675942913576067
Validation loss: 2.401296232185139

Epoch: 5| Step: 9
Training loss: 2.1352898040552355
Validation loss: 2.400354405845476

Epoch: 5| Step: 10
Training loss: 2.8353627360697207
Validation loss: 2.40932045070655

Epoch: 117| Step: 0
Training loss: 2.471333564267775
Validation loss: 2.3902530915723714

Epoch: 5| Step: 1
Training loss: 2.0179730127683153
Validation loss: 2.385376159636425

Epoch: 5| Step: 2
Training loss: 2.068687405748543
Validation loss: 2.3955130799532176

Epoch: 5| Step: 3
Training loss: 2.5012752141639605
Validation loss: 2.3948793431754

Epoch: 5| Step: 4
Training loss: 3.2117681241073783
Validation loss: 2.396498402598768

Epoch: 5| Step: 5
Training loss: 2.0517920918349537
Validation loss: 2.3911715022324604

Epoch: 5| Step: 6
Training loss: 3.015542459099496
Validation loss: 2.3944200953226664

Epoch: 5| Step: 7
Training loss: 2.5268983522176325
Validation loss: 2.3940504341100866

Epoch: 5| Step: 8
Training loss: 2.0982021992343993
Validation loss: 2.3966702797488075

Epoch: 5| Step: 9
Training loss: 3.073265926534864
Validation loss: 2.3935833338988006

Epoch: 5| Step: 10
Training loss: 2.664496780751482
Validation loss: 2.3948765374782943

Epoch: 118| Step: 0
Training loss: 2.4322076710826805
Validation loss: 2.390762504233287

Epoch: 5| Step: 1
Training loss: 2.09592688966599
Validation loss: 2.406477586189873

Epoch: 5| Step: 2
Training loss: 2.8814503829684934
Validation loss: 2.398957560373405

Epoch: 5| Step: 3
Training loss: 2.4567504140104917
Validation loss: 2.40529125191155

Epoch: 5| Step: 4
Training loss: 2.721578595460644
Validation loss: 2.4003105848774817

Epoch: 5| Step: 5
Training loss: 2.7800541567844577
Validation loss: 2.3940505786732382

Epoch: 5| Step: 6
Training loss: 1.933643378959843
Validation loss: 2.399000335824786

Epoch: 5| Step: 7
Training loss: 2.7480489572220255
Validation loss: 2.383227654596836

Epoch: 5| Step: 8
Training loss: 2.1291848656560264
Validation loss: 2.398074821009983

Epoch: 5| Step: 9
Training loss: 2.5283020183892995
Validation loss: 2.3894386937851557

Epoch: 5| Step: 10
Training loss: 3.1670423251408244
Validation loss: 2.400496640784531

Epoch: 119| Step: 0
Training loss: 2.779558331649647
Validation loss: 2.4099929447638417

Epoch: 5| Step: 1
Training loss: 2.4625976775494953
Validation loss: 2.395243844964703

Epoch: 5| Step: 2
Training loss: 2.5892545049881757
Validation loss: 2.3846793777486797

Epoch: 5| Step: 3
Training loss: 2.498093450259711
Validation loss: 2.401810390045543

Epoch: 5| Step: 4
Training loss: 2.4762039647066842
Validation loss: 2.404965909731156

Epoch: 5| Step: 5
Training loss: 2.9398706488147903
Validation loss: 2.387437066823598

Epoch: 5| Step: 6
Training loss: 2.3112637076169955
Validation loss: 2.3859147535500016

Epoch: 5| Step: 7
Training loss: 2.197336478892331
Validation loss: 2.393534416532983

Epoch: 5| Step: 8
Training loss: 2.760684843651886
Validation loss: 2.408708657368318

Epoch: 5| Step: 9
Training loss: 2.2841614212408263
Validation loss: 2.4034087142869462

Epoch: 5| Step: 10
Training loss: 2.595778441933073
Validation loss: 2.4104688534122523

Epoch: 120| Step: 0
Training loss: 2.9029188856986345
Validation loss: 2.3726940931763294

Epoch: 5| Step: 1
Training loss: 2.1705017139188145
Validation loss: 2.3862942513689007

Epoch: 5| Step: 2
Training loss: 2.3144899003209636
Validation loss: 2.396728180158615

Epoch: 5| Step: 3
Training loss: 1.884517673133251
Validation loss: 2.398293528301292

Epoch: 5| Step: 4
Training loss: 2.736533223320416
Validation loss: 2.422761988757306

Epoch: 5| Step: 5
Training loss: 2.2645512634458442
Validation loss: 2.400639008792996

Epoch: 5| Step: 6
Training loss: 2.694564228956543
Validation loss: 2.4081980024039322

Epoch: 5| Step: 7
Training loss: 2.6651469509698096
Validation loss: 2.4066561113961837

Epoch: 5| Step: 8
Training loss: 3.2542818180148463
Validation loss: 2.3814997157459037

Epoch: 5| Step: 9
Training loss: 2.142042372981666
Validation loss: 2.392064711345087

Epoch: 5| Step: 10
Training loss: 2.7480367241450314
Validation loss: 2.4064269504865807

Epoch: 121| Step: 0
Training loss: 2.5749475492302016
Validation loss: 2.395648439468069

Epoch: 5| Step: 1
Training loss: 2.7736948672948705
Validation loss: 2.4049404860226153

Epoch: 5| Step: 2
Training loss: 2.3281658604255675
Validation loss: 2.4130090722913367

Epoch: 5| Step: 3
Training loss: 2.197242078866894
Validation loss: 2.389987163156539

Epoch: 5| Step: 4
Training loss: 2.163560829818508
Validation loss: 2.3988729497631525

Epoch: 5| Step: 5
Training loss: 2.419241969029124
Validation loss: 2.3994740570426436

Epoch: 5| Step: 6
Training loss: 2.883160164397624
Validation loss: 2.4047065134589496

Epoch: 5| Step: 7
Training loss: 2.7234101968732785
Validation loss: 2.3985030267616025

Epoch: 5| Step: 8
Training loss: 3.0231368829676204
Validation loss: 2.4083530593690416

Epoch: 5| Step: 9
Training loss: 2.4880094035360356
Validation loss: 2.413757504600717

Epoch: 5| Step: 10
Training loss: 2.0875431124866566
Validation loss: 2.386281185468604

Epoch: 122| Step: 0
Training loss: 3.168134014743691
Validation loss: 2.3914421948063986

Epoch: 5| Step: 1
Training loss: 2.3887808674285664
Validation loss: 2.400604511127237

Epoch: 5| Step: 2
Training loss: 1.84424616716278
Validation loss: 2.40065399350873

Epoch: 5| Step: 3
Training loss: 2.6813710432140345
Validation loss: 2.390399799735672

Epoch: 5| Step: 4
Training loss: 2.602367654562933
Validation loss: 2.396804198395513

Epoch: 5| Step: 5
Training loss: 2.6157505018964224
Validation loss: 2.4250125405152563

Epoch: 5| Step: 6
Training loss: 2.651259547625108
Validation loss: 2.399812059239057

Epoch: 5| Step: 7
Training loss: 2.6879628692174125
Validation loss: 2.3944969384228476

Epoch: 5| Step: 8
Training loss: 2.717813440125114
Validation loss: 2.4067585256893556

Epoch: 5| Step: 9
Training loss: 1.667803289349779
Validation loss: 2.384407392198558

Epoch: 5| Step: 10
Training loss: 2.5349869634831057
Validation loss: 2.382508814338229

Epoch: 123| Step: 0
Training loss: 2.774542188253881
Validation loss: 2.4116039394730793

Epoch: 5| Step: 1
Training loss: 2.731952051504336
Validation loss: 2.398550309025465

Epoch: 5| Step: 2
Training loss: 2.0258635481047462
Validation loss: 2.398166221216422

Epoch: 5| Step: 3
Training loss: 2.553022956443104
Validation loss: 2.3975150816471493

Epoch: 5| Step: 4
Training loss: 2.73321150957942
Validation loss: 2.388564301864512

Epoch: 5| Step: 5
Training loss: 2.4244586576310714
Validation loss: 2.3883547366565434

Epoch: 5| Step: 6
Training loss: 1.9448757677192579
Validation loss: 2.3911096889967727

Epoch: 5| Step: 7
Training loss: 2.5788450218219645
Validation loss: 2.388215359091469

Epoch: 5| Step: 8
Training loss: 2.5877223928219215
Validation loss: 2.376881510977237

Epoch: 5| Step: 9
Training loss: 3.023659237165312
Validation loss: 2.39162547831488

Epoch: 5| Step: 10
Training loss: 2.163846772937143
Validation loss: 2.4017079318044567

Epoch: 124| Step: 0
Training loss: 2.352456160652727
Validation loss: 2.3948655341041256

Epoch: 5| Step: 1
Training loss: 3.0957225329636104
Validation loss: 2.405679966847828

Epoch: 5| Step: 2
Training loss: 2.512487314676174
Validation loss: 2.3966859278655894

Epoch: 5| Step: 3
Training loss: 2.293134589103722
Validation loss: 2.3908522689084863

Epoch: 5| Step: 4
Training loss: 1.9956500312341634
Validation loss: 2.3818942916115176

Epoch: 5| Step: 5
Training loss: 2.3450730721937476
Validation loss: 2.3791043007678367

Epoch: 5| Step: 6
Training loss: 2.6050036700144155
Validation loss: 2.401424081124039

Epoch: 5| Step: 7
Training loss: 2.355051285171118
Validation loss: 2.403512715426361

Epoch: 5| Step: 8
Training loss: 2.8453549058782235
Validation loss: 2.3992793193240822

Epoch: 5| Step: 9
Training loss: 2.8694469062504933
Validation loss: 2.4086020429791737

Epoch: 5| Step: 10
Training loss: 2.290801133361664
Validation loss: 2.392059261606449

Epoch: 125| Step: 0
Training loss: 2.8534623179590453
Validation loss: 2.3883971331136267

Epoch: 5| Step: 1
Training loss: 2.857971514015974
Validation loss: 2.384862757463298

Epoch: 5| Step: 2
Training loss: 2.588108315578721
Validation loss: 2.3845514739154736

Epoch: 5| Step: 3
Training loss: 2.4443187705399967
Validation loss: 2.4031452593670917

Epoch: 5| Step: 4
Training loss: 2.5413961631370685
Validation loss: 2.386782936857844

Epoch: 5| Step: 5
Training loss: 2.4827870026150056
Validation loss: 2.3876436213623347

Epoch: 5| Step: 6
Training loss: 2.405909427469633
Validation loss: 2.380356433151193

Epoch: 5| Step: 7
Training loss: 2.2234661859094715
Validation loss: 2.3913960423541654

Epoch: 5| Step: 8
Training loss: 2.746640060150881
Validation loss: 2.3937133019433077

Epoch: 5| Step: 9
Training loss: 2.2694694786397855
Validation loss: 2.403251948355187

Epoch: 5| Step: 10
Training loss: 2.2363739675295906
Validation loss: 2.3819432010211097

Epoch: 126| Step: 0
Training loss: 2.4337330590017525
Validation loss: 2.397271389668673

Epoch: 5| Step: 1
Training loss: 2.366607494241349
Validation loss: 2.392243191193698

Epoch: 5| Step: 2
Training loss: 2.3992858777954478
Validation loss: 2.394623578762093

Epoch: 5| Step: 3
Training loss: 2.6284025029877753
Validation loss: 2.3998919942097703

Epoch: 5| Step: 4
Training loss: 2.613153337618319
Validation loss: 2.4009991244029174

Epoch: 5| Step: 5
Training loss: 2.0579107841824187
Validation loss: 2.397471426386635

Epoch: 5| Step: 6
Training loss: 2.6346406560603595
Validation loss: 2.3999182148811293

Epoch: 5| Step: 7
Training loss: 2.3640492602152183
Validation loss: 2.396253160785104

Epoch: 5| Step: 8
Training loss: 2.4850530119063583
Validation loss: 2.3935629432160876

Epoch: 5| Step: 9
Training loss: 3.0298878863652483
Validation loss: 2.4039141329988998

Epoch: 5| Step: 10
Training loss: 2.6644064046434854
Validation loss: 2.4100196060251524

Epoch: 127| Step: 0
Training loss: 2.0068501938362235
Validation loss: 2.4183955597720774

Epoch: 5| Step: 1
Training loss: 2.6874378108436483
Validation loss: 2.382932247687885

Epoch: 5| Step: 2
Training loss: 2.49147803274044
Validation loss: 2.397291840775961

Epoch: 5| Step: 3
Training loss: 2.317590008976357
Validation loss: 2.411970920515743

Epoch: 5| Step: 4
Training loss: 2.56890023342115
Validation loss: 2.3933406844334555

Epoch: 5| Step: 5
Training loss: 3.390002074789577
Validation loss: 2.387165970562936

Epoch: 5| Step: 6
Training loss: 2.190580868786654
Validation loss: 2.3820403904575813

Epoch: 5| Step: 7
Training loss: 2.0072740359704144
Validation loss: 2.392926638352064

Epoch: 5| Step: 8
Training loss: 2.6025454751914427
Validation loss: 2.396223995322197

Epoch: 5| Step: 9
Training loss: 2.9524937515128067
Validation loss: 2.3915547238558656

Epoch: 5| Step: 10
Training loss: 2.0813592967984613
Validation loss: 2.384178180441902

Epoch: 128| Step: 0
Training loss: 2.710125188575289
Validation loss: 2.382133530514531

Epoch: 5| Step: 1
Training loss: 2.5449573810059127
Validation loss: 2.3970455892490348

Epoch: 5| Step: 2
Training loss: 2.5387231218501367
Validation loss: 2.390367187736531

Epoch: 5| Step: 3
Training loss: 2.4893218878142545
Validation loss: 2.4047088631266402

Epoch: 5| Step: 4
Training loss: 2.334143418515551
Validation loss: 2.3857160237909496

Epoch: 5| Step: 5
Training loss: 2.628422821624375
Validation loss: 2.376846014869033

Epoch: 5| Step: 6
Training loss: 3.046041990996363
Validation loss: 2.387816932523875

Epoch: 5| Step: 7
Training loss: 2.233250688570472
Validation loss: 2.4052354180945548

Epoch: 5| Step: 8
Training loss: 2.0214048803059006
Validation loss: 2.3885365236845195

Epoch: 5| Step: 9
Training loss: 2.4540653248854096
Validation loss: 2.3827595377226807

Epoch: 5| Step: 10
Training loss: 2.3955069167535523
Validation loss: 2.397400571776871

Epoch: 129| Step: 0
Training loss: 2.9792910107537014
Validation loss: 2.3846305346719534

Epoch: 5| Step: 1
Training loss: 2.0316281480191525
Validation loss: 2.3812358501042876

Epoch: 5| Step: 2
Training loss: 2.703704066351523
Validation loss: 2.4073954022734605

Epoch: 5| Step: 3
Training loss: 2.2041385564712233
Validation loss: 2.39491323500885

Epoch: 5| Step: 4
Training loss: 2.7853224010584725
Validation loss: 2.4139977492351963

Epoch: 5| Step: 5
Training loss: 3.0430853335337096
Validation loss: 2.4086561484901865

Epoch: 5| Step: 6
Training loss: 2.4815085326829567
Validation loss: 2.3794342946980054

Epoch: 5| Step: 7
Training loss: 2.3972887898035
Validation loss: 2.3891657955527585

Epoch: 5| Step: 8
Training loss: 1.7917142314659302
Validation loss: 2.399835630440228

Epoch: 5| Step: 9
Training loss: 2.4105261915992
Validation loss: 2.399677796723207

Epoch: 5| Step: 10
Training loss: 2.4988843335772177
Validation loss: 2.3962560857637056

Epoch: 130| Step: 0
Training loss: 2.4409591387462446
Validation loss: 2.389656497513896

Epoch: 5| Step: 1
Training loss: 2.790812138586777
Validation loss: 2.393699206615469

Epoch: 5| Step: 2
Training loss: 2.168713580878358
Validation loss: 2.389335471660636

Epoch: 5| Step: 3
Training loss: 2.3819451426315643
Validation loss: 2.4001405780734957

Epoch: 5| Step: 4
Training loss: 2.78918465312093
Validation loss: 2.4085120829850504

Epoch: 5| Step: 5
Training loss: 2.4178938106824144
Validation loss: 2.386208157134882

Epoch: 5| Step: 6
Training loss: 2.253910058082788
Validation loss: 2.3803681799463488

Epoch: 5| Step: 7
Training loss: 2.7217054417174924
Validation loss: 2.3740945459840077

Epoch: 5| Step: 8
Training loss: 3.099840430798194
Validation loss: 2.391599725203267

Epoch: 5| Step: 9
Training loss: 2.1510358045250277
Validation loss: 2.3839437273056054

Epoch: 5| Step: 10
Training loss: 2.143456584101877
Validation loss: 2.388911177235584

Epoch: 131| Step: 0
Training loss: 2.6245474652362133
Validation loss: 2.3878516074184626

Epoch: 5| Step: 1
Training loss: 2.4292012307623576
Validation loss: 2.3935150483129752

Epoch: 5| Step: 2
Training loss: 2.7116566344554087
Validation loss: 2.390929700604884

Epoch: 5| Step: 3
Training loss: 2.460255943257825
Validation loss: 2.3891924955472112

Epoch: 5| Step: 4
Training loss: 2.8071198608443804
Validation loss: 2.3862344937893525

Epoch: 5| Step: 5
Training loss: 2.4583886889243733
Validation loss: 2.3915542243244734

Epoch: 5| Step: 6
Training loss: 2.6263836438374155
Validation loss: 2.403238170325219

Epoch: 5| Step: 7
Training loss: 2.7035006223564637
Validation loss: 2.401172245649608

Epoch: 5| Step: 8
Training loss: 2.163375580213018
Validation loss: 2.4010336494983724

Epoch: 5| Step: 9
Training loss: 2.258869702408374
Validation loss: 2.3931675644068617

Epoch: 5| Step: 10
Training loss: 2.2544974835877323
Validation loss: 2.3965327497043507

Epoch: 132| Step: 0
Training loss: 2.734815289608043
Validation loss: 2.3929935437392147

Epoch: 5| Step: 1
Training loss: 2.206169243650273
Validation loss: 2.3787313466010547

Epoch: 5| Step: 2
Training loss: 2.204998329144664
Validation loss: 2.389617037194594

Epoch: 5| Step: 3
Training loss: 2.865812465646843
Validation loss: 2.3847357568080385

Epoch: 5| Step: 4
Training loss: 2.612257775571767
Validation loss: 2.3857630941905557

Epoch: 5| Step: 5
Training loss: 2.713881331630333
Validation loss: 2.3800757669146306

Epoch: 5| Step: 6
Training loss: 2.413586517123608
Validation loss: 2.3861853140363314

Epoch: 5| Step: 7
Training loss: 2.595759704753932
Validation loss: 2.400418468921181

Epoch: 5| Step: 8
Training loss: 2.2029272761798024
Validation loss: 2.385298995838552

Epoch: 5| Step: 9
Training loss: 2.2750919784564783
Validation loss: 2.369832713409353

Epoch: 5| Step: 10
Training loss: 2.5393833368508645
Validation loss: 2.3674252477082534

Epoch: 133| Step: 0
Training loss: 2.9755301700345176
Validation loss: 2.3811957668391925

Epoch: 5| Step: 1
Training loss: 2.1124610084682236
Validation loss: 2.3855969574528033

Epoch: 5| Step: 2
Training loss: 2.2676216535308558
Validation loss: 2.3869582673766447

Epoch: 5| Step: 3
Training loss: 2.221463223486268
Validation loss: 2.3959107103376693

Epoch: 5| Step: 4
Training loss: 2.337741117230256
Validation loss: 2.400620790362388

Epoch: 5| Step: 5
Training loss: 2.3722139380213836
Validation loss: 2.375044068303822

Epoch: 5| Step: 6
Training loss: 2.0870196218038854
Validation loss: 2.3783779107524863

Epoch: 5| Step: 7
Training loss: 2.873057165069098
Validation loss: 2.3732899844341526

Epoch: 5| Step: 8
Training loss: 2.5483298797617286
Validation loss: 2.3986977484147953

Epoch: 5| Step: 9
Training loss: 2.908338555128188
Validation loss: 2.3930010471906584

Epoch: 5| Step: 10
Training loss: 2.5421091434569276
Validation loss: 2.388722430950814

Epoch: 134| Step: 0
Training loss: 2.4274805969028557
Validation loss: 2.4010534450149663

Epoch: 5| Step: 1
Training loss: 2.550795737629943
Validation loss: 2.3983551820406017

Epoch: 5| Step: 2
Training loss: 2.539065223105511
Validation loss: 2.3970512394117085

Epoch: 5| Step: 3
Training loss: 2.6201308367725917
Validation loss: 2.392623576405773

Epoch: 5| Step: 4
Training loss: 2.4363547348910575
Validation loss: 2.3909208675093057

Epoch: 5| Step: 5
Training loss: 2.6759418077399673
Validation loss: 2.404219427031195

Epoch: 5| Step: 6
Training loss: 2.2294683400840785
Validation loss: 2.401034672377501

Epoch: 5| Step: 7
Training loss: 2.4272224702915235
Validation loss: 2.3870403919681342

Epoch: 5| Step: 8
Training loss: 2.5340321639382433
Validation loss: 2.3972654384535095

Epoch: 5| Step: 9
Training loss: 2.5929750870560837
Validation loss: 2.377113246227122

Epoch: 5| Step: 10
Training loss: 2.181123977999317
Validation loss: 2.4101471959189307

Epoch: 135| Step: 0
Training loss: 2.179748971817434
Validation loss: 2.395537452207879

Epoch: 5| Step: 1
Training loss: 2.5159233342848553
Validation loss: 2.3948664183152615

Epoch: 5| Step: 2
Training loss: 2.472048234234436
Validation loss: 2.377980435175579

Epoch: 5| Step: 3
Training loss: 2.5266984118612084
Validation loss: 2.4024859808072865

Epoch: 5| Step: 4
Training loss: 1.7489511889216545
Validation loss: 2.4140770243992202

Epoch: 5| Step: 5
Training loss: 2.911336242263187
Validation loss: 2.390340658520859

Epoch: 5| Step: 6
Training loss: 2.5089931857889627
Validation loss: 2.3894043004961065

Epoch: 5| Step: 7
Training loss: 2.4480498473820616
Validation loss: 2.3967423518008744

Epoch: 5| Step: 8
Training loss: 2.4836921953175968
Validation loss: 2.405461073737297

Epoch: 5| Step: 9
Training loss: 2.4922377243482026
Validation loss: 2.395209020209004

Epoch: 5| Step: 10
Training loss: 2.9580798689742083
Validation loss: 2.38459820822488

Epoch: 136| Step: 0
Training loss: 2.6419275445813937
Validation loss: 2.4062424744710875

Epoch: 5| Step: 1
Training loss: 2.5395421910154417
Validation loss: 2.381297276390692

Epoch: 5| Step: 2
Training loss: 1.574609296264495
Validation loss: 2.388215456239104

Epoch: 5| Step: 3
Training loss: 2.4722587663709374
Validation loss: 2.396614874603451

Epoch: 5| Step: 4
Training loss: 2.1381367053012865
Validation loss: 2.3994622948029773

Epoch: 5| Step: 5
Training loss: 1.662314056093988
Validation loss: 2.3900911111825285

Epoch: 5| Step: 6
Training loss: 2.741816047224249
Validation loss: 2.387875704654466

Epoch: 5| Step: 7
Training loss: 2.500998679007052
Validation loss: 2.3926758596161015

Epoch: 5| Step: 8
Training loss: 2.3870650569326872
Validation loss: 2.3797912379407027

Epoch: 5| Step: 9
Training loss: 3.109733829208762
Validation loss: 2.386153524356121

Epoch: 5| Step: 10
Training loss: 3.1396581575471623
Validation loss: 2.3879660566564906

Epoch: 137| Step: 0
Training loss: 2.668924945037543
Validation loss: 2.4044276798744706

Epoch: 5| Step: 1
Training loss: 2.623484037530669
Validation loss: 2.39377600752843

Epoch: 5| Step: 2
Training loss: 2.660118965414188
Validation loss: 2.3947380105260847

Epoch: 5| Step: 3
Training loss: 2.26255284874665
Validation loss: 2.3901183628826805

Epoch: 5| Step: 4
Training loss: 2.58769290960527
Validation loss: 2.3898130074457398

Epoch: 5| Step: 5
Training loss: 2.06787887625823
Validation loss: 2.3767954996818212

Epoch: 5| Step: 6
Training loss: 2.8965156538053196
Validation loss: 2.3948306546046605

Epoch: 5| Step: 7
Training loss: 2.3940887291191837
Validation loss: 2.3826557809231104

Epoch: 5| Step: 8
Training loss: 2.5570386980311346
Validation loss: 2.408634214372773

Epoch: 5| Step: 9
Training loss: 2.196407601569865
Validation loss: 2.399348494373628

Epoch: 5| Step: 10
Training loss: 2.3142546105859676
Validation loss: 2.4092178548207768

Epoch: 138| Step: 0
Training loss: 2.189851750098268
Validation loss: 2.3864991017311588

Epoch: 5| Step: 1
Training loss: 2.366597621429932
Validation loss: 2.3984016281362877

Epoch: 5| Step: 2
Training loss: 2.4360852170423724
Validation loss: 2.4003934381360814

Epoch: 5| Step: 3
Training loss: 2.6030838101025893
Validation loss: 2.375397483236131

Epoch: 5| Step: 4
Training loss: 2.5124338890981037
Validation loss: 2.3981217974245914

Epoch: 5| Step: 5
Training loss: 2.667716554755417
Validation loss: 2.4071589972885405

Epoch: 5| Step: 6
Training loss: 2.054612307024791
Validation loss: 2.393571014682647

Epoch: 5| Step: 7
Training loss: 2.7854639768802976
Validation loss: 2.390731638637786

Epoch: 5| Step: 8
Training loss: 2.2043083746294267
Validation loss: 2.3877093090602806

Epoch: 5| Step: 9
Training loss: 2.506884251579612
Validation loss: 2.38456915500898

Epoch: 5| Step: 10
Training loss: 2.586957102410694
Validation loss: 2.4141087830099712

Epoch: 139| Step: 0
Training loss: 2.6272258404270588
Validation loss: 2.392795777959044

Epoch: 5| Step: 1
Training loss: 2.7782127855675256
Validation loss: 2.3993622765756135

Epoch: 5| Step: 2
Training loss: 2.418812938728883
Validation loss: 2.4065342620566232

Epoch: 5| Step: 3
Training loss: 2.3872650070781365
Validation loss: 2.3850191670616283

Epoch: 5| Step: 4
Training loss: 3.0901107190489867
Validation loss: 2.3724475350361

Epoch: 5| Step: 5
Training loss: 2.056305802814236
Validation loss: 2.3894657984295278

Epoch: 5| Step: 6
Training loss: 2.7557534806462187
Validation loss: 2.37955070288087

Epoch: 5| Step: 7
Training loss: 2.1839263062253154
Validation loss: 2.3756946212861325

Epoch: 5| Step: 8
Training loss: 2.3092589476956036
Validation loss: 2.3888670878676708

Epoch: 5| Step: 9
Training loss: 2.13475412154523
Validation loss: 2.3713919159564307

Epoch: 5| Step: 10
Training loss: 2.166973483540844
Validation loss: 2.382929916891381

Epoch: 140| Step: 0
Training loss: 2.180123890497391
Validation loss: 2.3894525213443205

Epoch: 5| Step: 1
Training loss: 2.096701861310031
Validation loss: 2.3837313586513966

Epoch: 5| Step: 2
Training loss: 2.6637355570265107
Validation loss: 2.369929990593273

Epoch: 5| Step: 3
Training loss: 3.0470574740030636
Validation loss: 2.3712460491828558

Epoch: 5| Step: 4
Training loss: 2.742596718013772
Validation loss: 2.3826503182715046

Epoch: 5| Step: 5
Training loss: 2.089774157354703
Validation loss: 2.3826944764089975

Epoch: 5| Step: 6
Training loss: 2.066556005694114
Validation loss: 2.3727420269595583

Epoch: 5| Step: 7
Training loss: 2.1395952852751683
Validation loss: 2.3827176585387138

Epoch: 5| Step: 8
Training loss: 2.981554865893794
Validation loss: 2.3895315551240497

Epoch: 5| Step: 9
Training loss: 2.3804963408556006
Validation loss: 2.3978704351534996

Epoch: 5| Step: 10
Training loss: 2.2878762774728334
Validation loss: 2.3963192837938934

Epoch: 141| Step: 0
Training loss: 2.32631228749447
Validation loss: 2.363931037282831

Epoch: 5| Step: 1
Training loss: 2.235100581660239
Validation loss: 2.385987142966482

Epoch: 5| Step: 2
Training loss: 2.879193109224367
Validation loss: 2.3964323679746338

Epoch: 5| Step: 3
Training loss: 2.5124383491809423
Validation loss: 2.3791138684523743

Epoch: 5| Step: 4
Training loss: 2.505159870612141
Validation loss: 2.3789305251366577

Epoch: 5| Step: 5
Training loss: 2.5098674590235306
Validation loss: 2.3778473894844527

Epoch: 5| Step: 6
Training loss: 2.5319163069490047
Validation loss: 2.3936847931171266

Epoch: 5| Step: 7
Training loss: 2.5533583797026522
Validation loss: 2.385498162268474

Epoch: 5| Step: 8
Training loss: 2.1062827721827957
Validation loss: 2.3835731780931546

Epoch: 5| Step: 9
Training loss: 2.3779982664648975
Validation loss: 2.378238243852175

Epoch: 5| Step: 10
Training loss: 2.4397430858433955
Validation loss: 2.3785290019804437

Epoch: 142| Step: 0
Training loss: 2.408325687207115
Validation loss: 2.3804743529652224

Epoch: 5| Step: 1
Training loss: 2.5176449834145016
Validation loss: 2.3884839416386

Epoch: 5| Step: 2
Training loss: 2.5088650880121457
Validation loss: 2.3669683879654477

Epoch: 5| Step: 3
Training loss: 2.7757687509063684
Validation loss: 2.3751752105486945

Epoch: 5| Step: 4
Training loss: 2.0444913773516946
Validation loss: 2.3965607785802887

Epoch: 5| Step: 5
Training loss: 2.345525450572265
Validation loss: 2.3886246461936387

Epoch: 5| Step: 6
Training loss: 2.244211486281966
Validation loss: 2.3933854904590626

Epoch: 5| Step: 7
Training loss: 2.76892651410747
Validation loss: 2.3794873315267897

Epoch: 5| Step: 8
Training loss: 2.3583349499736226
Validation loss: 2.399181319436791

Epoch: 5| Step: 9
Training loss: 2.625858711387185
Validation loss: 2.3986158156044857

Epoch: 5| Step: 10
Training loss: 2.4239337661431524
Validation loss: 2.3740042675408555

Epoch: 143| Step: 0
Training loss: 2.909152314773456
Validation loss: 2.389853039506681

Epoch: 5| Step: 1
Training loss: 2.4260699949552906
Validation loss: 2.4084041506133036

Epoch: 5| Step: 2
Training loss: 2.3639190569799298
Validation loss: 2.3977846181133735

Epoch: 5| Step: 3
Training loss: 2.2001898943702707
Validation loss: 2.382296692259704

Epoch: 5| Step: 4
Training loss: 2.491868527846283
Validation loss: 2.3788712399586514

Epoch: 5| Step: 5
Training loss: 2.4077460852294
Validation loss: 2.4064074196986267

Epoch: 5| Step: 6
Training loss: 2.8639436504638542
Validation loss: 2.3909154065855063

Epoch: 5| Step: 7
Training loss: 1.6783333931360673
Validation loss: 2.3957475843952247

Epoch: 5| Step: 8
Training loss: 2.460424945073382
Validation loss: 2.407504633202406

Epoch: 5| Step: 9
Training loss: 2.3202196096200107
Validation loss: 2.3848156004942287

Epoch: 5| Step: 10
Training loss: 2.635069742600822
Validation loss: 2.376313095348205

Epoch: 144| Step: 0
Training loss: 2.228734078427974
Validation loss: 2.393564435197028

Epoch: 5| Step: 1
Training loss: 2.201957555647651
Validation loss: 2.389198713664076

Epoch: 5| Step: 2
Training loss: 2.619266424493321
Validation loss: 2.377045617770468

Epoch: 5| Step: 3
Training loss: 2.6003024512217014
Validation loss: 2.3952723989172258

Epoch: 5| Step: 4
Training loss: 2.4055910075068767
Validation loss: 2.3813226376268863

Epoch: 5| Step: 5
Training loss: 1.892491829777647
Validation loss: 2.378157019417471

Epoch: 5| Step: 6
Training loss: 2.4729985245801673
Validation loss: 2.3839955341531693

Epoch: 5| Step: 7
Training loss: 2.1810149932443923
Validation loss: 2.377539303214071

Epoch: 5| Step: 8
Training loss: 3.036631732436843
Validation loss: 2.389072724698477

Epoch: 5| Step: 9
Training loss: 2.4569733192880046
Validation loss: 2.3805797200371237

Epoch: 5| Step: 10
Training loss: 2.600029387674774
Validation loss: 2.3812453704669263

Epoch: 145| Step: 0
Training loss: 2.330246848099444
Validation loss: 2.3801000775161856

Epoch: 5| Step: 1
Training loss: 2.405750074100979
Validation loss: 2.3711696105197033

Epoch: 5| Step: 2
Training loss: 2.3152426873822645
Validation loss: 2.3997591217397423

Epoch: 5| Step: 3
Training loss: 2.3612657259512844
Validation loss: 2.3887963139523025

Epoch: 5| Step: 4
Training loss: 2.591265764128693
Validation loss: 2.3879518372243433

Epoch: 5| Step: 5
Training loss: 2.30589950503339
Validation loss: 2.3778512901738966

Epoch: 5| Step: 6
Training loss: 2.836265523976477
Validation loss: 2.3843247710269626

Epoch: 5| Step: 7
Training loss: 2.160359323072242
Validation loss: 2.3750397938458496

Epoch: 5| Step: 8
Training loss: 2.3480731003736843
Validation loss: 2.389888614893044

Epoch: 5| Step: 9
Training loss: 2.70047431594283
Validation loss: 2.3592204229576583

Epoch: 5| Step: 10
Training loss: 2.4279354929768298
Validation loss: 2.3802475040935978

Epoch: 146| Step: 0
Training loss: 3.16377162773731
Validation loss: 2.366931990975719

Epoch: 5| Step: 1
Training loss: 3.0067970840803318
Validation loss: 2.385596430882694

Epoch: 5| Step: 2
Training loss: 2.0995103537696442
Validation loss: 2.3865391082771645

Epoch: 5| Step: 3
Training loss: 1.9446194804594417
Validation loss: 2.3933832603535024

Epoch: 5| Step: 4
Training loss: 2.590880035620768
Validation loss: 2.395179399984203

Epoch: 5| Step: 5
Training loss: 2.4882830705141985
Validation loss: 2.3903716642981436

Epoch: 5| Step: 6
Training loss: 2.096255042218472
Validation loss: 2.385412758286964

Epoch: 5| Step: 7
Training loss: 2.64468036270666
Validation loss: 2.384884582349236

Epoch: 5| Step: 8
Training loss: 2.375802958425977
Validation loss: 2.3966768175484896

Epoch: 5| Step: 9
Training loss: 2.030098221756284
Validation loss: 2.38141699234938

Epoch: 5| Step: 10
Training loss: 1.931406035801697
Validation loss: 2.3723136203492654

Epoch: 147| Step: 0
Training loss: 2.3914470381250816
Validation loss: 2.373075442705772

Epoch: 5| Step: 1
Training loss: 2.3149444444882246
Validation loss: 2.386231157943794

Epoch: 5| Step: 2
Training loss: 2.622005571244502
Validation loss: 2.3800247741634153

Epoch: 5| Step: 3
Training loss: 2.0477286153185994
Validation loss: 2.3787462774867763

Epoch: 5| Step: 4
Training loss: 2.194984818842707
Validation loss: 2.363891664836301

Epoch: 5| Step: 5
Training loss: 2.426093678772007
Validation loss: 2.3883743023640065

Epoch: 5| Step: 6
Training loss: 3.029804789735439
Validation loss: 2.3987985071851856

Epoch: 5| Step: 7
Training loss: 2.045136740107146
Validation loss: 2.385291436990295

Epoch: 5| Step: 8
Training loss: 2.4439349209413557
Validation loss: 2.400798867990588

Epoch: 5| Step: 9
Training loss: 2.677200097136451
Validation loss: 2.387423968520531

Epoch: 5| Step: 10
Training loss: 2.245734091449179
Validation loss: 2.4058947546649154

Epoch: 148| Step: 0
Training loss: 2.275738053545375
Validation loss: 2.4160541883466466

Epoch: 5| Step: 1
Training loss: 2.596615415009384
Validation loss: 2.378181181467677

Epoch: 5| Step: 2
Training loss: 2.1473433604195304
Validation loss: 2.3628034791637056

Epoch: 5| Step: 3
Training loss: 2.1212822424664215
Validation loss: 2.387477686354196

Epoch: 5| Step: 4
Training loss: 2.086576328251762
Validation loss: 2.3772311996627886

Epoch: 5| Step: 5
Training loss: 2.7886530043944973
Validation loss: 2.3902421173239574

Epoch: 5| Step: 6
Training loss: 2.0205494658360585
Validation loss: 2.387685272955996

Epoch: 5| Step: 7
Training loss: 3.2354557608956562
Validation loss: 2.3899270924391365

Epoch: 5| Step: 8
Training loss: 2.8634507778300753
Validation loss: 2.39428134601741

Epoch: 5| Step: 9
Training loss: 2.236816779309208
Validation loss: 2.375236477868909

Epoch: 5| Step: 10
Training loss: 2.0247844204532743
Validation loss: 2.369554079395747

Epoch: 149| Step: 0
Training loss: 2.4844465905197115
Validation loss: 2.383982722343682

Epoch: 5| Step: 1
Training loss: 2.594155613080902
Validation loss: 2.398314377956537

Epoch: 5| Step: 2
Training loss: 2.306461078526276
Validation loss: 2.4045636357029694

Epoch: 5| Step: 3
Training loss: 1.9511247692206997
Validation loss: 2.4048737083327336

Epoch: 5| Step: 4
Training loss: 2.8811715270504346
Validation loss: 2.4050637559889

Epoch: 5| Step: 5
Training loss: 2.6416012014787182
Validation loss: 2.39771720756804

Epoch: 5| Step: 6
Training loss: 1.8573281056895812
Validation loss: 2.3888087897939596

Epoch: 5| Step: 7
Training loss: 2.60759304213458
Validation loss: 2.398207251238557

Epoch: 5| Step: 8
Training loss: 1.9981814699900804
Validation loss: 2.3857922070107382

Epoch: 5| Step: 9
Training loss: 2.6020204982903095
Validation loss: 2.387468000782863

Epoch: 5| Step: 10
Training loss: 2.658315147489169
Validation loss: 2.4061131102148416

Epoch: 150| Step: 0
Training loss: 2.9643647582238937
Validation loss: 2.387033229565225

Epoch: 5| Step: 1
Training loss: 2.5083282035530163
Validation loss: 2.3849128244420013

Epoch: 5| Step: 2
Training loss: 2.1181170122857647
Validation loss: 2.3946204398139357

Epoch: 5| Step: 3
Training loss: 2.267881650760076
Validation loss: 2.3914481830250107

Epoch: 5| Step: 4
Training loss: 2.7926358964957694
Validation loss: 2.370200395320304

Epoch: 5| Step: 5
Training loss: 2.644782500960424
Validation loss: 2.3986716715120635

Epoch: 5| Step: 6
Training loss: 2.290689456548035
Validation loss: 2.3705358015529505

Epoch: 5| Step: 7
Training loss: 1.9486349756772348
Validation loss: 2.3833899616105874

Epoch: 5| Step: 8
Training loss: 2.4268410252018535
Validation loss: 2.3727359634391814

Epoch: 5| Step: 9
Training loss: 2.362927623174705
Validation loss: 2.373835815343145

Epoch: 5| Step: 10
Training loss: 2.079430535746945
Validation loss: 2.3858301510353606

Epoch: 151| Step: 0
Training loss: 2.4645359433525535
Validation loss: 2.387362252618951

Epoch: 5| Step: 1
Training loss: 2.5832222227587276
Validation loss: 2.3562301944777118

Epoch: 5| Step: 2
Training loss: 2.21452111210323
Validation loss: 2.38094805568018

Epoch: 5| Step: 3
Training loss: 2.379429551369235
Validation loss: 2.380721530307156

Epoch: 5| Step: 4
Training loss: 2.371814900919727
Validation loss: 2.3751610839999375

Epoch: 5| Step: 5
Training loss: 2.5333615196901964
Validation loss: 2.3728406715174697

Epoch: 5| Step: 6
Training loss: 2.1580522165141556
Validation loss: 2.394577740289188

Epoch: 5| Step: 7
Training loss: 2.356730412651188
Validation loss: 2.3877616032457483

Epoch: 5| Step: 8
Training loss: 2.401054818095987
Validation loss: 2.380010608538462

Epoch: 5| Step: 9
Training loss: 2.6210227081176742
Validation loss: 2.380304562177642

Epoch: 5| Step: 10
Training loss: 2.38379836402963
Validation loss: 2.3958375731899273

Epoch: 152| Step: 0
Training loss: 2.314247811139932
Validation loss: 2.381119004819547

Epoch: 5| Step: 1
Training loss: 2.0910871282930303
Validation loss: 2.378564552730812

Epoch: 5| Step: 2
Training loss: 2.194058531885399
Validation loss: 2.375595818971849

Epoch: 5| Step: 3
Training loss: 2.2925207684989517
Validation loss: 2.3835904889299164

Epoch: 5| Step: 4
Training loss: 2.70728559523916
Validation loss: 2.3911629520006588

Epoch: 5| Step: 5
Training loss: 2.397388837860617
Validation loss: 2.373987937533553

Epoch: 5| Step: 6
Training loss: 2.784134558369122
Validation loss: 2.374325528575241

Epoch: 5| Step: 7
Training loss: 2.5298344928147287
Validation loss: 2.38413374870326

Epoch: 5| Step: 8
Training loss: 2.452889595156666
Validation loss: 2.391919618670023

Epoch: 5| Step: 9
Training loss: 2.4498990952868653
Validation loss: 2.3764359257329706

Epoch: 5| Step: 10
Training loss: 2.1466867422661804
Validation loss: 2.368388147064972

Epoch: 153| Step: 0
Training loss: 2.862634021003734
Validation loss: 2.3906103438393864

Epoch: 5| Step: 1
Training loss: 2.1821405423687015
Validation loss: 2.379188617424514

Epoch: 5| Step: 2
Training loss: 2.0202543340277024
Validation loss: 2.395366079199731

Epoch: 5| Step: 3
Training loss: 2.4884912710621157
Validation loss: 2.385870194049386

Epoch: 5| Step: 4
Training loss: 3.0845709370349366
Validation loss: 2.366167131567058

Epoch: 5| Step: 5
Training loss: 2.4002857356049985
Validation loss: 2.363341539143262

Epoch: 5| Step: 6
Training loss: 2.2518658848561355
Validation loss: 2.3892691398166717

Epoch: 5| Step: 7
Training loss: 2.513350127524096
Validation loss: 2.397682996112925

Epoch: 5| Step: 8
Training loss: 1.9681917640407507
Validation loss: 2.3995766870553594

Epoch: 5| Step: 9
Training loss: 2.278286825327196
Validation loss: 2.3706038720200833

Epoch: 5| Step: 10
Training loss: 2.185371998735608
Validation loss: 2.37731305962092

Epoch: 154| Step: 0
Training loss: 2.3489902153022464
Validation loss: 2.396040986537832

Epoch: 5| Step: 1
Training loss: 2.523043386194416
Validation loss: 2.3801670612558934

Epoch: 5| Step: 2
Training loss: 3.113287070160024
Validation loss: 2.377273211085898

Epoch: 5| Step: 3
Training loss: 1.9644810245070308
Validation loss: 2.388587281058307

Epoch: 5| Step: 4
Training loss: 2.284600084229369
Validation loss: 2.376407799734091

Epoch: 5| Step: 5
Training loss: 1.9611701371396801
Validation loss: 2.382303175882781

Epoch: 5| Step: 6
Training loss: 2.3600127513993603
Validation loss: 2.386016042461932

Epoch: 5| Step: 7
Training loss: 2.490551450402021
Validation loss: 2.3793933541530325

Epoch: 5| Step: 8
Training loss: 2.113300203530994
Validation loss: 2.4046349999472936

Epoch: 5| Step: 9
Training loss: 2.3833026319362562
Validation loss: 2.403092527578849

Epoch: 5| Step: 10
Training loss: 2.5037645606361747
Validation loss: 2.3931895910033045

Epoch: 155| Step: 0
Training loss: 2.428327762577297
Validation loss: 2.380924093449051

Epoch: 5| Step: 1
Training loss: 2.815473129461282
Validation loss: 2.3860807166679265

Epoch: 5| Step: 2
Training loss: 2.32647380262686
Validation loss: 2.384517273539436

Epoch: 5| Step: 3
Training loss: 2.327601431532526
Validation loss: 2.3916132122576372

Epoch: 5| Step: 4
Training loss: 2.5032361066640894
Validation loss: 2.3847617624953723

Epoch: 5| Step: 5
Training loss: 2.240635032046111
Validation loss: 2.386946127699054

Epoch: 5| Step: 6
Training loss: 2.528592256763505
Validation loss: 2.404918108672778

Epoch: 5| Step: 7
Training loss: 2.4479306376173517
Validation loss: 2.3588384974365644

Epoch: 5| Step: 8
Training loss: 2.4560448830259074
Validation loss: 2.3693334003628084

Epoch: 5| Step: 9
Training loss: 2.1118989890825484
Validation loss: 2.365998799680595

Epoch: 5| Step: 10
Training loss: 1.8637820036792847
Validation loss: 2.3646340848322493

Epoch: 156| Step: 0
Training loss: 2.8396237798447124
Validation loss: 2.3747045142094656

Epoch: 5| Step: 1
Training loss: 2.353537405079459
Validation loss: 2.408439404078874

Epoch: 5| Step: 2
Training loss: 2.261180859843018
Validation loss: 2.3779249309279886

Epoch: 5| Step: 3
Training loss: 2.2695518400797923
Validation loss: 2.374142109190003

Epoch: 5| Step: 4
Training loss: 2.095113168177195
Validation loss: 2.3840351477379094

Epoch: 5| Step: 5
Training loss: 2.1383278208557734
Validation loss: 2.379907401913462

Epoch: 5| Step: 6
Training loss: 2.4464669229566236
Validation loss: 2.3945054767497456

Epoch: 5| Step: 7
Training loss: 2.443556865270091
Validation loss: 2.3911519283212592

Epoch: 5| Step: 8
Training loss: 2.3359533200956246
Validation loss: 2.382740958794182

Epoch: 5| Step: 9
Training loss: 2.6184925981627867
Validation loss: 2.3827542592903885

Epoch: 5| Step: 10
Training loss: 2.180149043176605
Validation loss: 2.394593087325171

Epoch: 157| Step: 0
Training loss: 2.4975079513591245
Validation loss: 2.3994743775679424

Epoch: 5| Step: 1
Training loss: 2.1101505690451923
Validation loss: 2.3819507102230553

Epoch: 5| Step: 2
Training loss: 2.1867561165416736
Validation loss: 2.3778244304875327

Epoch: 5| Step: 3
Training loss: 2.1771781450522067
Validation loss: 2.3904810757643458

Epoch: 5| Step: 4
Training loss: 2.386435034538394
Validation loss: 2.4096151419177216

Epoch: 5| Step: 5
Training loss: 2.6133192028260486
Validation loss: 2.393837865433865

Epoch: 5| Step: 6
Training loss: 2.5119725598944345
Validation loss: 2.36701103967941

Epoch: 5| Step: 7
Training loss: 2.1012374456372127
Validation loss: 2.3909253730569158

Epoch: 5| Step: 8
Training loss: 2.3156881264590528
Validation loss: 2.394399636818065

Epoch: 5| Step: 9
Training loss: 2.9481773306152914
Validation loss: 2.3776278106725406

Epoch: 5| Step: 10
Training loss: 2.1025912238072224
Validation loss: 2.394078289661889

Epoch: 158| Step: 0
Training loss: 2.39827834604659
Validation loss: 2.3982710974828656

Epoch: 5| Step: 1
Training loss: 2.6623061311012792
Validation loss: 2.360013014279719

Epoch: 5| Step: 2
Training loss: 2.1284300105223997
Validation loss: 2.3869659143859523

Epoch: 5| Step: 3
Training loss: 2.5456275927565324
Validation loss: 2.381253067043479

Epoch: 5| Step: 4
Training loss: 2.378784176555404
Validation loss: 2.367148653909243

Epoch: 5| Step: 5
Training loss: 2.0007164387183805
Validation loss: 2.3695441717981933

Epoch: 5| Step: 6
Training loss: 2.887821301836021
Validation loss: 2.3905402832119673

Epoch: 5| Step: 7
Training loss: 2.3811323402151867
Validation loss: 2.376178129196699

Epoch: 5| Step: 8
Training loss: 2.1202078245970184
Validation loss: 2.394365216285139

Epoch: 5| Step: 9
Training loss: 1.913144198860011
Validation loss: 2.376217251133097

Epoch: 5| Step: 10
Training loss: 2.5615968740962423
Validation loss: 2.3761068160330914

Epoch: 159| Step: 0
Training loss: 2.164476706185838
Validation loss: 2.3737690298620158

Epoch: 5| Step: 1
Training loss: 2.2091055785368887
Validation loss: 2.3749828586272823

Epoch: 5| Step: 2
Training loss: 2.8091215399104343
Validation loss: 2.3707096658940237

Epoch: 5| Step: 3
Training loss: 2.6658248665442548
Validation loss: 2.394472519175186

Epoch: 5| Step: 4
Training loss: 2.083754407927228
Validation loss: 2.3537568601304923

Epoch: 5| Step: 5
Training loss: 2.4246373328146853
Validation loss: 2.3525378441776272

Epoch: 5| Step: 6
Training loss: 1.5979121593161436
Validation loss: 2.374573994821596

Epoch: 5| Step: 7
Training loss: 2.394929488703034
Validation loss: 2.3932961410782467

Epoch: 5| Step: 8
Training loss: 2.21299610071748
Validation loss: 2.389221475374704

Epoch: 5| Step: 9
Training loss: 2.89410257189604
Validation loss: 2.3865317972028013

Epoch: 5| Step: 10
Training loss: 2.3839212808349552
Validation loss: 2.364564577257488

Epoch: 160| Step: 0
Training loss: 2.470205819361728
Validation loss: 2.3833823036657606

Epoch: 5| Step: 1
Training loss: 2.180493824348898
Validation loss: 2.3920482988595926

Epoch: 5| Step: 2
Training loss: 2.2948639038555725
Validation loss: 2.381852856265643

Epoch: 5| Step: 3
Training loss: 2.2938627875348407
Validation loss: 2.366200141566728

Epoch: 5| Step: 4
Training loss: 2.4068557175047394
Validation loss: 2.3921984248577863

Epoch: 5| Step: 5
Training loss: 2.3126569127639285
Validation loss: 2.363964441261076

Epoch: 5| Step: 6
Training loss: 2.1828290934604397
Validation loss: 2.3953614565177967

Epoch: 5| Step: 7
Training loss: 2.596069769299414
Validation loss: 2.3669049732586678

Epoch: 5| Step: 8
Training loss: 2.138227247588315
Validation loss: 2.392366478879913

Epoch: 5| Step: 9
Training loss: 2.3148450559830627
Validation loss: 2.4003873312556143

Epoch: 5| Step: 10
Training loss: 2.7878457201408873
Validation loss: 2.381855170356824

Epoch: 161| Step: 0
Training loss: 2.799276248172074
Validation loss: 2.3811573258470573

Epoch: 5| Step: 1
Training loss: 2.5507755483940393
Validation loss: 2.3872733511257676

Epoch: 5| Step: 2
Training loss: 2.2056347775370932
Validation loss: 2.4039864661645374

Epoch: 5| Step: 3
Training loss: 2.088000359787307
Validation loss: 2.3880196001911167

Epoch: 5| Step: 4
Training loss: 2.379230546065893
Validation loss: 2.378174411720178

Epoch: 5| Step: 5
Training loss: 2.0521970094542077
Validation loss: 2.3670296272681877

Epoch: 5| Step: 6
Training loss: 3.0991441345079576
Validation loss: 2.384552643090699

Epoch: 5| Step: 7
Training loss: 2.2900462461574427
Validation loss: 2.3853267988239275

Epoch: 5| Step: 8
Training loss: 2.52668359734022
Validation loss: 2.3722394196008145

Epoch: 5| Step: 9
Training loss: 1.938037305592922
Validation loss: 2.404927979804556

Epoch: 5| Step: 10
Training loss: 1.7540802391428856
Validation loss: 2.385900580989828

Epoch: 162| Step: 0
Training loss: 2.6112775433933426
Validation loss: 2.387687017169414

Epoch: 5| Step: 1
Training loss: 2.77405500387984
Validation loss: 2.378200326381773

Epoch: 5| Step: 2
Training loss: 2.48115551670166
Validation loss: 2.389769352018208

Epoch: 5| Step: 3
Training loss: 2.514560260893356
Validation loss: 2.3764642628364405

Epoch: 5| Step: 4
Training loss: 2.0123100522834436
Validation loss: 2.389395972473391

Epoch: 5| Step: 5
Training loss: 1.9282680959170189
Validation loss: 2.38380349819173

Epoch: 5| Step: 6
Training loss: 2.031659598501218
Validation loss: 2.411963208231141

Epoch: 5| Step: 7
Training loss: 2.34057952062531
Validation loss: 2.368032565536707

Epoch: 5| Step: 8
Training loss: 2.4832652750439315
Validation loss: 2.39527163205296

Epoch: 5| Step: 9
Training loss: 2.169788923061893
Validation loss: 2.3491777723588583

Epoch: 5| Step: 10
Training loss: 2.5133766884272815
Validation loss: 2.3816295843280835

Epoch: 163| Step: 0
Training loss: 2.1870745653890116
Validation loss: 2.385801979975775

Epoch: 5| Step: 1
Training loss: 3.0248498106944584
Validation loss: 2.3783958490062735

Epoch: 5| Step: 2
Training loss: 2.067104171261379
Validation loss: 2.38021148518436

Epoch: 5| Step: 3
Training loss: 2.406744373613333
Validation loss: 2.3685898275603807

Epoch: 5| Step: 4
Training loss: 2.0914758886542932
Validation loss: 2.3838534938561424

Epoch: 5| Step: 5
Training loss: 2.8877649953547113
Validation loss: 2.3637933826871493

Epoch: 5| Step: 6
Training loss: 2.622716909916697
Validation loss: 2.3846005207269667

Epoch: 5| Step: 7
Training loss: 1.9883847312753866
Validation loss: 2.376909760797932

Epoch: 5| Step: 8
Training loss: 2.2824923124319687
Validation loss: 2.3823162641386726

Epoch: 5| Step: 9
Training loss: 2.212914220106721
Validation loss: 2.3875446306174104

Epoch: 5| Step: 10
Training loss: 1.7589681259919452
Validation loss: 2.3793175899032906

Epoch: 164| Step: 0
Training loss: 2.3862185289596676
Validation loss: 2.3735825756750053

Epoch: 5| Step: 1
Training loss: 2.1196866646019425
Validation loss: 2.3804308434395245

Epoch: 5| Step: 2
Training loss: 2.2887827210767115
Validation loss: 2.399849170556466

Epoch: 5| Step: 3
Training loss: 2.6036763352674592
Validation loss: 2.3959130568613256

Epoch: 5| Step: 4
Training loss: 2.0452768624321362
Validation loss: 2.4003489861420104

Epoch: 5| Step: 5
Training loss: 2.627772275136178
Validation loss: 2.39409892331399

Epoch: 5| Step: 6
Training loss: 2.2182226494571498
Validation loss: 2.4053191915156433

Epoch: 5| Step: 7
Training loss: 2.1723166915414542
Validation loss: 2.377719561277834

Epoch: 5| Step: 8
Training loss: 2.410322631830469
Validation loss: 2.4008953849021433

Epoch: 5| Step: 9
Training loss: 2.3936615651181716
Validation loss: 2.3685329169706053

Epoch: 5| Step: 10
Training loss: 2.705953716595578
Validation loss: 2.365080024825513

Epoch: 165| Step: 0
Training loss: 2.3619952273147002
Validation loss: 2.3655965505459493

Epoch: 5| Step: 1
Training loss: 2.4789636566218656
Validation loss: 2.387913836731813

Epoch: 5| Step: 2
Training loss: 2.5835380370549825
Validation loss: 2.369802243221408

Epoch: 5| Step: 3
Training loss: 1.9945442172389873
Validation loss: 2.382682819626787

Epoch: 5| Step: 4
Training loss: 1.8923105340045254
Validation loss: 2.374390133596193

Epoch: 5| Step: 5
Training loss: 2.4737065451469147
Validation loss: 2.394458505403801

Epoch: 5| Step: 6
Training loss: 2.6233231774617862
Validation loss: 2.3639516965744654

Epoch: 5| Step: 7
Training loss: 2.086909835446994
Validation loss: 2.380260163681244

Epoch: 5| Step: 8
Training loss: 2.2768344735018755
Validation loss: 2.3792360575144094

Epoch: 5| Step: 9
Training loss: 2.020085330709366
Validation loss: 2.371345082460916

Epoch: 5| Step: 10
Training loss: 2.8779222315499786
Validation loss: 2.3722587389058747

Epoch: 166| Step: 0
Training loss: 2.6802428979543835
Validation loss: 2.3490487660111703

Epoch: 5| Step: 1
Training loss: 2.548488831134681
Validation loss: 2.3729010472977468

Epoch: 5| Step: 2
Training loss: 2.458464333443684
Validation loss: 2.3847782197531515

Epoch: 5| Step: 3
Training loss: 2.017672186668698
Validation loss: 2.3709035874430002

Epoch: 5| Step: 4
Training loss: 2.09378996853613
Validation loss: 2.3946678276439233

Epoch: 5| Step: 5
Training loss: 2.1113437083866398
Validation loss: 2.3746287061593363

Epoch: 5| Step: 6
Training loss: 1.3903468850450216
Validation loss: 2.3911808575983984

Epoch: 5| Step: 7
Training loss: 2.044041776681816
Validation loss: 2.3531108453818392

Epoch: 5| Step: 8
Training loss: 2.6527619741433988
Validation loss: 2.370831432767449

Epoch: 5| Step: 9
Training loss: 3.016462456832341
Validation loss: 2.36493714113134

Epoch: 5| Step: 10
Training loss: 2.1749309748077574
Validation loss: 2.3709507594471075

Epoch: 167| Step: 0
Training loss: 2.749955090242757
Validation loss: 2.388289542236132

Epoch: 5| Step: 1
Training loss: 2.7032994561320662
Validation loss: 2.3662171997579544

Epoch: 5| Step: 2
Training loss: 2.365335174101092
Validation loss: 2.4002354931702428

Epoch: 5| Step: 3
Training loss: 2.2554186105523035
Validation loss: 2.355247568122069

Epoch: 5| Step: 4
Training loss: 2.648246645732013
Validation loss: 2.3766173375478323

Epoch: 5| Step: 5
Training loss: 2.2694991038897
Validation loss: 2.3870759877929797

Epoch: 5| Step: 6
Training loss: 1.8458972647153322
Validation loss: 2.3704300637283398

Epoch: 5| Step: 7
Training loss: 2.1825294698886366
Validation loss: 2.403233020078188

Epoch: 5| Step: 8
Training loss: 2.1461165775158464
Validation loss: 2.374201894702994

Epoch: 5| Step: 9
Training loss: 2.019212354499213
Validation loss: 2.382046992087818

Epoch: 5| Step: 10
Training loss: 2.323533721757926
Validation loss: 2.3661570488935793

Epoch: 168| Step: 0
Training loss: 2.0943048226015057
Validation loss: 2.377276698075057

Epoch: 5| Step: 1
Training loss: 2.5027612695726984
Validation loss: 2.386823241537129

Epoch: 5| Step: 2
Training loss: 2.194077982932792
Validation loss: 2.399579054566628

Epoch: 5| Step: 3
Training loss: 2.4894315495103023
Validation loss: 2.3861464516882718

Epoch: 5| Step: 4
Training loss: 2.182160099649081
Validation loss: 2.402588682763515

Epoch: 5| Step: 5
Training loss: 2.606157066097077
Validation loss: 2.4089328281870044

Epoch: 5| Step: 6
Training loss: 1.9929933002893334
Validation loss: 2.4075825654015337

Epoch: 5| Step: 7
Training loss: 2.450055771796248
Validation loss: 2.4050805102903423

Epoch: 5| Step: 8
Training loss: 2.628385540434245
Validation loss: 2.360050086634786

Epoch: 5| Step: 9
Training loss: 2.2018431052183436
Validation loss: 2.392114201048308

Epoch: 5| Step: 10
Training loss: 2.2139375100832153
Validation loss: 2.3941546800800046

Epoch: 169| Step: 0
Training loss: 2.5326922981784024
Validation loss: 2.379656824033222

Epoch: 5| Step: 1
Training loss: 2.4540380248813336
Validation loss: 2.363559722697647

Epoch: 5| Step: 2
Training loss: 2.094559128834359
Validation loss: 2.3704199094218072

Epoch: 5| Step: 3
Training loss: 2.7081780804860305
Validation loss: 2.397994286650691

Epoch: 5| Step: 4
Training loss: 1.891240925990875
Validation loss: 2.3664368417630364

Epoch: 5| Step: 5
Training loss: 2.273211176248007
Validation loss: 2.3560072875832656

Epoch: 5| Step: 6
Training loss: 2.1536763629955824
Validation loss: 2.373804799315098

Epoch: 5| Step: 7
Training loss: 2.1498104632911645
Validation loss: 2.3594314176195996

Epoch: 5| Step: 8
Training loss: 2.4140101553664604
Validation loss: 2.3814498719730404

Epoch: 5| Step: 9
Training loss: 2.501489767605313
Validation loss: 2.3814389804175438

Epoch: 5| Step: 10
Training loss: 2.3635601793362473
Validation loss: 2.3852718449201835

Epoch: 170| Step: 0
Training loss: 2.3944493041710784
Validation loss: 2.3646279528178593

Epoch: 5| Step: 1
Training loss: 2.2355066381469815
Validation loss: 2.3619737238506446

Epoch: 5| Step: 2
Training loss: 2.1867656019942294
Validation loss: 2.373741374463644

Epoch: 5| Step: 3
Training loss: 1.6267658322755252
Validation loss: 2.3587290735288833

Epoch: 5| Step: 4
Training loss: 2.1298174386746203
Validation loss: 2.3539924392856357

Epoch: 5| Step: 5
Training loss: 2.586713323008502
Validation loss: 2.3669047393048714

Epoch: 5| Step: 6
Training loss: 2.274499075100506
Validation loss: 2.3715049704800433

Epoch: 5| Step: 7
Training loss: 2.2728206676020126
Validation loss: 2.409415166438203

Epoch: 5| Step: 8
Training loss: 2.362928733070636
Validation loss: 2.3922706557454285

Epoch: 5| Step: 9
Training loss: 2.9137370155336457
Validation loss: 2.3728925781646457

Epoch: 5| Step: 10
Training loss: 2.284944547318396
Validation loss: 2.3527439700610437

Epoch: 171| Step: 0
Training loss: 2.58918618071976
Validation loss: 2.4059728967085565

Epoch: 5| Step: 1
Training loss: 1.9596171398303284
Validation loss: 2.373681003857103

Epoch: 5| Step: 2
Training loss: 2.157484171291029
Validation loss: 2.384855319778609

Epoch: 5| Step: 3
Training loss: 2.0154688575059083
Validation loss: 2.3689111421715463

Epoch: 5| Step: 4
Training loss: 2.221055887699952
Validation loss: 2.383949004179607

Epoch: 5| Step: 5
Training loss: 2.3341729379243055
Validation loss: 2.3892425828503057

Epoch: 5| Step: 6
Training loss: 2.4900457572562757
Validation loss: 2.3802135553008976

Epoch: 5| Step: 7
Training loss: 1.9316955496883537
Validation loss: 2.3806062826456333

Epoch: 5| Step: 8
Training loss: 1.9585752202524265
Validation loss: 2.3857626729638124

Epoch: 5| Step: 9
Training loss: 3.1971096217476935
Validation loss: 2.3638674955445644

Epoch: 5| Step: 10
Training loss: 2.2407775060873645
Validation loss: 2.384426009212694

Epoch: 172| Step: 0
Training loss: 2.479393625422631
Validation loss: 2.357303626376287

Epoch: 5| Step: 1
Training loss: 2.823294967321633
Validation loss: 2.3679925998040954

Epoch: 5| Step: 2
Training loss: 2.107202499044351
Validation loss: 2.394693296181017

Epoch: 5| Step: 3
Training loss: 2.018307460783937
Validation loss: 2.376339163002773

Epoch: 5| Step: 4
Training loss: 2.549435410921255
Validation loss: 2.3717437230075844

Epoch: 5| Step: 5
Training loss: 2.865231046564188
Validation loss: 2.3672590596554475

Epoch: 5| Step: 6
Training loss: 1.8702366404816655
Validation loss: 2.380520386007959

Epoch: 5| Step: 7
Training loss: 2.229759731606381
Validation loss: 2.3826283459550437

Epoch: 5| Step: 8
Training loss: 1.7555452772368096
Validation loss: 2.3941419708211926

Epoch: 5| Step: 9
Training loss: 2.479509784024553
Validation loss: 2.392627353358485

Epoch: 5| Step: 10
Training loss: 1.9176671554341127
Validation loss: 2.3971953926636282

Epoch: 173| Step: 0
Training loss: 2.6465259056070227
Validation loss: 2.3849263396372105

Epoch: 5| Step: 1
Training loss: 2.489570798536425
Validation loss: 2.4078374909672235

Epoch: 5| Step: 2
Training loss: 2.268048062779024
Validation loss: 2.377080833728026

Epoch: 5| Step: 3
Training loss: 2.2293898449941714
Validation loss: 2.415167504425867

Epoch: 5| Step: 4
Training loss: 1.955930419265454
Validation loss: 2.392914449673429

Epoch: 5| Step: 5
Training loss: 2.391003148707443
Validation loss: 2.3947785597458515

Epoch: 5| Step: 6
Training loss: 2.3453987934215164
Validation loss: 2.3800079533495864

Epoch: 5| Step: 7
Training loss: 2.1060339570672437
Validation loss: 2.4023588137217313

Epoch: 5| Step: 8
Training loss: 2.3009366823293655
Validation loss: 2.3804827121998637

Epoch: 5| Step: 9
Training loss: 2.4624275661601103
Validation loss: 2.3800419212320962

Epoch: 5| Step: 10
Training loss: 2.094950317667723
Validation loss: 2.364662099349184

Epoch: 174| Step: 0
Training loss: 2.195452702616818
Validation loss: 2.356666199210574

Epoch: 5| Step: 1
Training loss: 1.9645410384165878
Validation loss: 2.3743911603953207

Epoch: 5| Step: 2
Training loss: 2.00942465333711
Validation loss: 2.3761982941504103

Epoch: 5| Step: 3
Training loss: 2.4526369617727086
Validation loss: 2.3794714442511933

Epoch: 5| Step: 4
Training loss: 2.0233426458447163
Validation loss: 2.360882896655765

Epoch: 5| Step: 5
Training loss: 2.3467155514126428
Validation loss: 2.3727230897517972

Epoch: 5| Step: 6
Training loss: 1.959634294646862
Validation loss: 2.384355332490446

Epoch: 5| Step: 7
Training loss: 2.4831964348388915
Validation loss: 2.3634119482942584

Epoch: 5| Step: 8
Training loss: 2.9415035155730997
Validation loss: 2.3887446627379614

Epoch: 5| Step: 9
Training loss: 2.196671686219813
Validation loss: 2.3736125825921772

Epoch: 5| Step: 10
Training loss: 2.5980484974646303
Validation loss: 2.3791246181779506

Epoch: 175| Step: 0
Training loss: 2.129038619379662
Validation loss: 2.378884069597748

Epoch: 5| Step: 1
Training loss: 2.550446235656922
Validation loss: 2.3763775050114346

Epoch: 5| Step: 2
Training loss: 2.1984727586902517
Validation loss: 2.365450575126806

Epoch: 5| Step: 3
Training loss: 2.3239159138317693
Validation loss: 2.4008393554216743

Epoch: 5| Step: 4
Training loss: 1.981544999744844
Validation loss: 2.3826490970545913

Epoch: 5| Step: 5
Training loss: 2.0551240986574433
Validation loss: 2.3422860707079716

Epoch: 5| Step: 6
Training loss: 2.326982051201463
Validation loss: 2.399999152545711

Epoch: 5| Step: 7
Training loss: 2.09849738904033
Validation loss: 2.3758764414674807

Epoch: 5| Step: 8
Training loss: 2.18429603270202
Validation loss: 2.3710368238241566

Epoch: 5| Step: 9
Training loss: 2.0767418410082503
Validation loss: 2.3621265643830403

Epoch: 5| Step: 10
Training loss: 3.0507073191966323
Validation loss: 2.370654445606219

Epoch: 176| Step: 0
Training loss: 2.3561895226121528
Validation loss: 2.394830405180636

Epoch: 5| Step: 1
Training loss: 2.015456673150995
Validation loss: 2.391344643477102

Epoch: 5| Step: 2
Training loss: 2.1883305743922294
Validation loss: 2.37793760934904

Epoch: 5| Step: 3
Training loss: 2.5445943344958617
Validation loss: 2.3870054883416914

Epoch: 5| Step: 4
Training loss: 2.325985123499024
Validation loss: 2.368478471803802

Epoch: 5| Step: 5
Training loss: 2.378764131056026
Validation loss: 2.3983854749335496

Epoch: 5| Step: 6
Training loss: 2.1625268217859976
Validation loss: 2.361136839346641

Epoch: 5| Step: 7
Training loss: 2.9852670664461183
Validation loss: 2.3781381177834864

Epoch: 5| Step: 8
Training loss: 1.7985179521875283
Validation loss: 2.382084407616919

Epoch: 5| Step: 9
Training loss: 1.9823165189060827
Validation loss: 2.4170595446602365

Epoch: 5| Step: 10
Training loss: 2.036286550888131
Validation loss: 2.389851764043513

Epoch: 177| Step: 0
Training loss: 1.8988068146835069
Validation loss: 2.401805919860462

Epoch: 5| Step: 1
Training loss: 2.1596726605724244
Validation loss: 2.3998328657901404

Epoch: 5| Step: 2
Training loss: 2.9710278255221465
Validation loss: 2.367692854796103

Epoch: 5| Step: 3
Training loss: 1.8325366398790022
Validation loss: 2.3728510834051693

Epoch: 5| Step: 4
Training loss: 2.4989084721931456
Validation loss: 2.4023546593624547

Epoch: 5| Step: 5
Training loss: 2.3777944287443
Validation loss: 2.3883007047171447

Epoch: 5| Step: 6
Training loss: 2.08592812753922
Validation loss: 2.36881965536741

Epoch: 5| Step: 7
Training loss: 2.0500713754649453
Validation loss: 2.3483903567142663

Epoch: 5| Step: 8
Training loss: 2.4036183023305386
Validation loss: 2.400320299264596

Epoch: 5| Step: 9
Training loss: 2.2612036347367264
Validation loss: 2.3601910666313572

Epoch: 5| Step: 10
Training loss: 2.2858040698333055
Validation loss: 2.3953385971616235

Epoch: 178| Step: 0
Training loss: 2.4861813102581247
Validation loss: 2.3912047776209904

Epoch: 5| Step: 1
Training loss: 2.1675197926885876
Validation loss: 2.3954687899639917

Epoch: 5| Step: 2
Training loss: 2.201766440676565
Validation loss: 2.3973996981244636

Epoch: 5| Step: 3
Training loss: 2.6549102995064247
Validation loss: 2.385294261485238

Epoch: 5| Step: 4
Training loss: 1.9325636460654407
Validation loss: 2.3894581438636315

Epoch: 5| Step: 5
Training loss: 2.5566533075984132
Validation loss: 2.3516664502129725

Epoch: 5| Step: 6
Training loss: 2.068148421209387
Validation loss: 2.3902625513512294

Epoch: 5| Step: 7
Training loss: 1.9534877592806104
Validation loss: 2.3890458516724484

Epoch: 5| Step: 8
Training loss: 1.8025754649836605
Validation loss: 2.3831315366129098

Epoch: 5| Step: 9
Training loss: 2.295397951782993
Validation loss: 2.375620554198533

Epoch: 5| Step: 10
Training loss: 2.8811990001078813
Validation loss: 2.3692266480081368

Epoch: 179| Step: 0
Training loss: 2.700774477331416
Validation loss: 2.375151251060736

Epoch: 5| Step: 1
Training loss: 2.3816761746849657
Validation loss: 2.3808896428440187

Epoch: 5| Step: 2
Training loss: 2.2802913166791035
Validation loss: 2.3662715030237425

Epoch: 5| Step: 3
Training loss: 2.3115931614431555
Validation loss: 2.4023702661848536

Epoch: 5| Step: 4
Training loss: 2.0795431246036187
Validation loss: 2.3753427966209224

Epoch: 5| Step: 5
Training loss: 1.978678900862519
Validation loss: 2.397902837125957

Epoch: 5| Step: 6
Training loss: 2.917559859340835
Validation loss: 2.3954356476526666

Epoch: 5| Step: 7
Training loss: 2.318623451419539
Validation loss: 2.3898478421777325

Epoch: 5| Step: 8
Training loss: 1.829558307833031
Validation loss: 2.390885648459755

Epoch: 5| Step: 9
Training loss: 1.4622534878330957
Validation loss: 2.3725592312675627

Epoch: 5| Step: 10
Training loss: 2.4560648802286016
Validation loss: 2.3676192639402425

Epoch: 180| Step: 0
Training loss: 1.812326751847648
Validation loss: 2.3919995473048514

Epoch: 5| Step: 1
Training loss: 2.5443969091429315
Validation loss: 2.3921455691107405

Epoch: 5| Step: 2
Training loss: 2.0457152364276525
Validation loss: 2.382930644693996

Epoch: 5| Step: 3
Training loss: 1.8920655870420944
Validation loss: 2.3772016369018214

Epoch: 5| Step: 4
Training loss: 2.1319864650676013
Validation loss: 2.3771386332289426

Epoch: 5| Step: 5
Training loss: 2.306617265109805
Validation loss: 2.3949357122630004

Epoch: 5| Step: 6
Training loss: 2.2153341298790203
Validation loss: 2.380920255937971

Epoch: 5| Step: 7
Training loss: 2.5981102568185386
Validation loss: 2.3856083431596935

Epoch: 5| Step: 8
Training loss: 2.3806360529620223
Validation loss: 2.393386759754527

Epoch: 5| Step: 9
Training loss: 2.5172760088921216
Validation loss: 2.3802659215418633

Epoch: 5| Step: 10
Training loss: 2.40305720954195
Validation loss: 2.353055291082363

Epoch: 181| Step: 0
Training loss: 2.692734699132484
Validation loss: 2.3811639762207726

Epoch: 5| Step: 1
Training loss: 2.1848013444064573
Validation loss: 2.371234773983573

Epoch: 5| Step: 2
Training loss: 2.4725027413348206
Validation loss: 2.3669252394185323

Epoch: 5| Step: 3
Training loss: 2.424409586027145
Validation loss: 2.3550246977618663

Epoch: 5| Step: 4
Training loss: 2.0855262150860234
Validation loss: 2.3643540862182157

Epoch: 5| Step: 5
Training loss: 2.276462390926647
Validation loss: 2.3540363321062956

Epoch: 5| Step: 6
Training loss: 1.9082402954854325
Validation loss: 2.385542525608046

Epoch: 5| Step: 7
Training loss: 2.145220536318954
Validation loss: 2.3609343940558776

Epoch: 5| Step: 8
Training loss: 2.4778265870803167
Validation loss: 2.381869418651031

Epoch: 5| Step: 9
Training loss: 1.9026834862109754
Validation loss: 2.380810034682102

Epoch: 5| Step: 10
Training loss: 2.2598575187600733
Validation loss: 2.369550767130642

Epoch: 182| Step: 0
Training loss: 2.2837080580728433
Validation loss: 2.390358990695058

Epoch: 5| Step: 1
Training loss: 1.7552553014008256
Validation loss: 2.4017812386959663

Epoch: 5| Step: 2
Training loss: 2.0579632656796774
Validation loss: 2.391544292096556

Epoch: 5| Step: 3
Training loss: 2.1543042899563574
Validation loss: 2.404425252631222

Epoch: 5| Step: 4
Training loss: 2.5150456679579523
Validation loss: 2.4020782508074507

Epoch: 5| Step: 5
Training loss: 2.44953120670658
Validation loss: 2.3799125918662742

Epoch: 5| Step: 6
Training loss: 2.410596513646617
Validation loss: 2.413582979030751

Epoch: 5| Step: 7
Training loss: 2.018032676401976
Validation loss: 2.3763051082082196

Epoch: 5| Step: 8
Training loss: 2.173649015356819
Validation loss: 2.3759843646203116

Epoch: 5| Step: 9
Training loss: 2.519936509770662
Validation loss: 2.3930504436111897

Epoch: 5| Step: 10
Training loss: 2.291012190794261
Validation loss: 2.38515968047216

Epoch: 183| Step: 0
Training loss: 1.8790661273910503
Validation loss: 2.399279740314799

Epoch: 5| Step: 1
Training loss: 2.197988596337321
Validation loss: 2.380709152074196

Epoch: 5| Step: 2
Training loss: 2.212456494781873
Validation loss: 2.364903862548061

Epoch: 5| Step: 3
Training loss: 2.154643247950793
Validation loss: 2.375463342292789

Epoch: 5| Step: 4
Training loss: 2.5158461953291673
Validation loss: 2.3463511241211923

Epoch: 5| Step: 5
Training loss: 2.0179244535386376
Validation loss: 2.383902075401075

Epoch: 5| Step: 6
Training loss: 2.8137755998067995
Validation loss: 2.3559146315486963

Epoch: 5| Step: 7
Training loss: 2.2770823202686437
Validation loss: 2.3787978138647206

Epoch: 5| Step: 8
Training loss: 2.273426698219882
Validation loss: 2.3600938985685223

Epoch: 5| Step: 9
Training loss: 1.997143911483817
Validation loss: 2.359977742426139

Epoch: 5| Step: 10
Training loss: 2.2730808043778823
Validation loss: 2.357210991933046

Epoch: 184| Step: 0
Training loss: 2.7668297508922306
Validation loss: 2.3783262294579233

Epoch: 5| Step: 1
Training loss: 2.4523585391684812
Validation loss: 2.3610317913809293

Epoch: 5| Step: 2
Training loss: 2.0898573260000046
Validation loss: 2.3506165640788304

Epoch: 5| Step: 3
Training loss: 2.3362622497792604
Validation loss: 2.3850991872106375

Epoch: 5| Step: 4
Training loss: 2.335672114680252
Validation loss: 2.37361198261956

Epoch: 5| Step: 5
Training loss: 2.0842887849149214
Validation loss: 2.3629347154332745

Epoch: 5| Step: 6
Training loss: 2.4084813064822232
Validation loss: 2.378643813556834

Epoch: 5| Step: 7
Training loss: 2.5361730479095606
Validation loss: 2.414216940320529

Epoch: 5| Step: 8
Training loss: 1.6191041065694807
Validation loss: 2.3720348935422586

Epoch: 5| Step: 9
Training loss: 1.8808287621024102
Validation loss: 2.372821676754376

Epoch: 5| Step: 10
Training loss: 2.1466761912061534
Validation loss: 2.3786893684752033

Epoch: 185| Step: 0
Training loss: 2.1960466453795697
Validation loss: 2.3677171766855327

Epoch: 5| Step: 1
Training loss: 1.9496060829387027
Validation loss: 2.3545408587660206

Epoch: 5| Step: 2
Training loss: 2.494789128843117
Validation loss: 2.420339458918685

Epoch: 5| Step: 3
Training loss: 2.5065027542327414
Validation loss: 2.3841955164557187

Epoch: 5| Step: 4
Training loss: 2.21060900724718
Validation loss: 2.385913037589462

Epoch: 5| Step: 5
Training loss: 2.439899144198855
Validation loss: 2.393384850990966

Epoch: 5| Step: 6
Training loss: 1.8442347907532497
Validation loss: 2.386867195197425

Epoch: 5| Step: 7
Training loss: 2.4938084225037485
Validation loss: 2.4145878789156203

Epoch: 5| Step: 8
Training loss: 1.7165425082865022
Validation loss: 2.411800469661962

Epoch: 5| Step: 9
Training loss: 2.476408559545513
Validation loss: 2.369104647156324

Epoch: 5| Step: 10
Training loss: 1.8060153848408884
Validation loss: 2.36534591057801

Epoch: 186| Step: 0
Training loss: 2.2455838628112317
Validation loss: 2.3758732896203845

Epoch: 5| Step: 1
Training loss: 2.405693980789186
Validation loss: 2.351724824190701

Epoch: 5| Step: 2
Training loss: 2.2104032160726947
Validation loss: 2.359116936000255

Epoch: 5| Step: 3
Training loss: 2.22588501377395
Validation loss: 2.3747861838257203

Epoch: 5| Step: 4
Training loss: 1.9685430266561692
Validation loss: 2.3914031198645946

Epoch: 5| Step: 5
Training loss: 2.1772606030682446
Validation loss: 2.3657991619991603

Epoch: 5| Step: 6
Training loss: 1.9396063522245863
Validation loss: 2.3868462831408466

Epoch: 5| Step: 7
Training loss: 2.639577443377982
Validation loss: 2.382431237004779

Epoch: 5| Step: 8
Training loss: 2.4669900729409133
Validation loss: 2.359518805059307

Epoch: 5| Step: 9
Training loss: 1.7033846595979039
Validation loss: 2.3597719450368073

Epoch: 5| Step: 10
Training loss: 2.298999037826622
Validation loss: 2.3592906856160765

Epoch: 187| Step: 0
Training loss: 2.0849436703397983
Validation loss: 2.3695231988219376

Epoch: 5| Step: 1
Training loss: 2.3279148493397193
Validation loss: 2.3596438753362783

Epoch: 5| Step: 2
Training loss: 2.6278897682540334
Validation loss: 2.368943824449808

Epoch: 5| Step: 3
Training loss: 2.36587719801275
Validation loss: 2.3655747709559276

Epoch: 5| Step: 4
Training loss: 2.1452663252738016
Validation loss: 2.367578186763563

Epoch: 5| Step: 5
Training loss: 2.3738649567243018
Validation loss: 2.3770443246501616

Epoch: 5| Step: 6
Training loss: 2.1180158170158103
Validation loss: 2.361593087080563

Epoch: 5| Step: 7
Training loss: 2.188583759506473
Validation loss: 2.410994834654929

Epoch: 5| Step: 8
Training loss: 1.8553511732895223
Validation loss: 2.392097455599819

Epoch: 5| Step: 9
Training loss: 2.358256498057903
Validation loss: 2.353276467667958

Epoch: 5| Step: 10
Training loss: 2.0402753591757574
Validation loss: 2.3642321570633484

Epoch: 188| Step: 0
Training loss: 2.242364962795595
Validation loss: 2.3388794364251364

Epoch: 5| Step: 1
Training loss: 3.05162937229715
Validation loss: 2.38240309569903

Epoch: 5| Step: 2
Training loss: 2.1374084363812114
Validation loss: 2.35646522583288

Epoch: 5| Step: 3
Training loss: 2.028509785926388
Validation loss: 2.413723866744319

Epoch: 5| Step: 4
Training loss: 2.007390909425623
Validation loss: 2.3650521339534794

Epoch: 5| Step: 5
Training loss: 1.7270074331480336
Validation loss: 2.377201840724691

Epoch: 5| Step: 6
Training loss: 2.094499823830006
Validation loss: 2.4032164342449325

Epoch: 5| Step: 7
Training loss: 2.598658042994531
Validation loss: 2.3308574363255965

Epoch: 5| Step: 8
Training loss: 1.9694011156486728
Validation loss: 2.349099569019808

Epoch: 5| Step: 9
Training loss: 2.257291317880906
Validation loss: 2.372253642437254

Epoch: 5| Step: 10
Training loss: 2.020084386517034
Validation loss: 2.3943642655056503

Epoch: 189| Step: 0
Training loss: 2.6352348616743977
Validation loss: 2.377556912454061

Epoch: 5| Step: 1
Training loss: 1.6275230041612612
Validation loss: 2.3673233658733546

Epoch: 5| Step: 2
Training loss: 2.5491593302828703
Validation loss: 2.349562632142042

Epoch: 5| Step: 3
Training loss: 2.519489045491963
Validation loss: 2.3985739311035474

Epoch: 5| Step: 4
Training loss: 1.8593498677069875
Validation loss: 2.365229680692016

Epoch: 5| Step: 5
Training loss: 2.339427675372145
Validation loss: 2.338382296655591

Epoch: 5| Step: 6
Training loss: 2.383714448916776
Validation loss: 2.3917783230869487

Epoch: 5| Step: 7
Training loss: 2.2636218456305524
Validation loss: 2.359042780939731

Epoch: 5| Step: 8
Training loss: 1.8456181905267532
Validation loss: 2.380384767201216

Epoch: 5| Step: 9
Training loss: 2.1211434318105384
Validation loss: 2.3618211968918295

Epoch: 5| Step: 10
Training loss: 1.898468833633363
Validation loss: 2.3826309422733045

Epoch: 190| Step: 0
Training loss: 2.6883986101859514
Validation loss: 2.3671451276329725

Epoch: 5| Step: 1
Training loss: 2.309128236298262
Validation loss: 2.396052104347665

Epoch: 5| Step: 2
Training loss: 2.018489015320188
Validation loss: 2.3495643255503293

Epoch: 5| Step: 3
Training loss: 1.804225779997312
Validation loss: 2.325867860237195

Epoch: 5| Step: 4
Training loss: 2.3449588963987322
Validation loss: 2.3810471252555874

Epoch: 5| Step: 5
Training loss: 1.7938920180825497
Validation loss: 2.3973117741282395

Epoch: 5| Step: 6
Training loss: 2.6577299595237744
Validation loss: 2.361504920407188

Epoch: 5| Step: 7
Training loss: 2.360827169611145
Validation loss: 2.3942506574873135

Epoch: 5| Step: 8
Training loss: 2.1053086257090343
Validation loss: 2.3705697959359395

Epoch: 5| Step: 9
Training loss: 2.0964083520429946
Validation loss: 2.369669486466922

Epoch: 5| Step: 10
Training loss: 1.8850363107113335
Validation loss: 2.385179882886997

Epoch: 191| Step: 0
Training loss: 2.3370646433412494
Validation loss: 2.3290142225683486

Epoch: 5| Step: 1
Training loss: 1.9158809198435027
Validation loss: 2.391653380332602

Epoch: 5| Step: 2
Training loss: 2.25989665951391
Validation loss: 2.403614739965391

Epoch: 5| Step: 3
Training loss: 1.982611105019577
Validation loss: 2.3788760905510427

Epoch: 5| Step: 4
Training loss: 2.5657095928859244
Validation loss: 2.3832010018013765

Epoch: 5| Step: 5
Training loss: 2.2550509238572536
Validation loss: 2.3929284789153504

Epoch: 5| Step: 6
Training loss: 1.8494555239149644
Validation loss: 2.3935914834827785

Epoch: 5| Step: 7
Training loss: 1.9553052406365277
Validation loss: 2.377983451626784

Epoch: 5| Step: 8
Training loss: 2.480351194464623
Validation loss: 2.383161736872555

Epoch: 5| Step: 9
Training loss: 1.9393954081173053
Validation loss: 2.4077206227328753

Epoch: 5| Step: 10
Training loss: 2.7921362429772163
Validation loss: 2.3778033116803043

Epoch: 192| Step: 0
Training loss: 2.3287972113450763
Validation loss: 2.3781857930776296

Epoch: 5| Step: 1
Training loss: 2.8198720318592496
Validation loss: 2.377082441745238

Epoch: 5| Step: 2
Training loss: 2.550406412387478
Validation loss: 2.38338136463944

Epoch: 5| Step: 3
Training loss: 1.7527262705136688
Validation loss: 2.387899519291425

Epoch: 5| Step: 4
Training loss: 2.2510860788841236
Validation loss: 2.3956565124691194

Epoch: 5| Step: 5
Training loss: 2.227379364617384
Validation loss: 2.38745380845066

Epoch: 5| Step: 6
Training loss: 2.3059702261584913
Validation loss: 2.3672222052464487

Epoch: 5| Step: 7
Training loss: 1.8740792874933994
Validation loss: 2.363656611622601

Epoch: 5| Step: 8
Training loss: 1.5901344277278067
Validation loss: 2.390600607689459

Epoch: 5| Step: 9
Training loss: 1.9860992149702195
Validation loss: 2.3865172802602825

Epoch: 5| Step: 10
Training loss: 2.134110722859312
Validation loss: 2.3718892835601246

Epoch: 193| Step: 0
Training loss: 1.89554950839235
Validation loss: 2.3793948539414695

Epoch: 5| Step: 1
Training loss: 2.357748721646102
Validation loss: 2.370687104932702

Epoch: 5| Step: 2
Training loss: 1.8324178519577854
Validation loss: 2.4048940745360734

Epoch: 5| Step: 3
Training loss: 1.7414157680629576
Validation loss: 2.364390606922753

Epoch: 5| Step: 4
Training loss: 1.9495098378279823
Validation loss: 2.3786105101047808

Epoch: 5| Step: 5
Training loss: 2.3704186472954616
Validation loss: 2.355083118039009

Epoch: 5| Step: 6
Training loss: 1.9103672402525136
Validation loss: 2.3698175251516926

Epoch: 5| Step: 7
Training loss: 2.274027744503082
Validation loss: 2.324027371784938

Epoch: 5| Step: 8
Training loss: 2.7197289293919233
Validation loss: 2.4183975282998076

Epoch: 5| Step: 9
Training loss: 2.4710113212545317
Validation loss: 2.375844708078641

Epoch: 5| Step: 10
Training loss: 2.3389856360272914
Validation loss: 2.379338701734671

Epoch: 194| Step: 0
Training loss: 2.271877527038764
Validation loss: 2.369261948805167

Epoch: 5| Step: 1
Training loss: 1.7902121369164505
Validation loss: 2.3732445451593893

Epoch: 5| Step: 2
Training loss: 2.121535787308872
Validation loss: 2.395088875356994

Epoch: 5| Step: 3
Training loss: 2.181176118227968
Validation loss: 2.3771539041240817

Epoch: 5| Step: 4
Training loss: 2.1772459294930133
Validation loss: 2.3709970860565965

Epoch: 5| Step: 5
Training loss: 2.0255844921003545
Validation loss: 2.378222097066403

Epoch: 5| Step: 6
Training loss: 3.0547778806462262
Validation loss: 2.360727624516352

Epoch: 5| Step: 7
Training loss: 2.1752194787144155
Validation loss: 2.3659855447695004

Epoch: 5| Step: 8
Training loss: 2.36709433394297
Validation loss: 2.3681084981374285

Epoch: 5| Step: 9
Training loss: 1.5218602549878455
Validation loss: 2.3820398706349253

Epoch: 5| Step: 10
Training loss: 1.918458149735612
Validation loss: 2.369218205776622

Epoch: 195| Step: 0
Training loss: 2.2137332130282448
Validation loss: 2.3690242274284063

Epoch: 5| Step: 1
Training loss: 1.967355385570885
Validation loss: 2.386255252205607

Epoch: 5| Step: 2
Training loss: 1.9474820826909662
Validation loss: 2.391783522384131

Epoch: 5| Step: 3
Training loss: 2.5712720940678717
Validation loss: 2.387297163180603

Epoch: 5| Step: 4
Training loss: 1.7188108953612236
Validation loss: 2.381016917555303

Epoch: 5| Step: 5
Training loss: 2.4366158079935705
Validation loss: 2.3812633732469792

Epoch: 5| Step: 6
Training loss: 2.1583187849028245
Validation loss: 2.3668257986159245

Epoch: 5| Step: 7
Training loss: 2.1529323098562
Validation loss: 2.37718870112363

Epoch: 5| Step: 8
Training loss: 2.4031091974778094
Validation loss: 2.3957595874481163

Epoch: 5| Step: 9
Training loss: 2.5293052643743588
Validation loss: 2.4254918047879612

Epoch: 5| Step: 10
Training loss: 1.8234052457465577
Validation loss: 2.3636310277529815

Epoch: 196| Step: 0
Training loss: 2.133621230170202
Validation loss: 2.354799152089214

Epoch: 5| Step: 1
Training loss: 2.1436280952692415
Validation loss: 2.368334766963753

Epoch: 5| Step: 2
Training loss: 2.2324707880276895
Validation loss: 2.3862382389553307

Epoch: 5| Step: 3
Training loss: 1.8844768718050222
Validation loss: 2.3669256629145443

Epoch: 5| Step: 4
Training loss: 2.35810807930512
Validation loss: 2.37099057692257

Epoch: 5| Step: 5
Training loss: 2.287233109877451
Validation loss: 2.393014032477008

Epoch: 5| Step: 6
Training loss: 2.48797634298724
Validation loss: 2.3762472738681346

Epoch: 5| Step: 7
Training loss: 2.4503797976332007
Validation loss: 2.3590282469788577

Epoch: 5| Step: 8
Training loss: 1.7402518428863425
Validation loss: 2.364448902045058

Epoch: 5| Step: 9
Training loss: 2.3487133115427508
Validation loss: 2.357342525405872

Epoch: 5| Step: 10
Training loss: 1.6353789242157437
Validation loss: 2.364542507353871

Epoch: 197| Step: 0
Training loss: 2.464249480318748
Validation loss: 2.3823405470346097

Epoch: 5| Step: 1
Training loss: 1.847903793559631
Validation loss: 2.375837741761292

Epoch: 5| Step: 2
Training loss: 2.561165811207857
Validation loss: 2.366894329420637

Epoch: 5| Step: 3
Training loss: 2.211877414155555
Validation loss: 2.351980959028248

Epoch: 5| Step: 4
Training loss: 1.9897531034194014
Validation loss: 2.3828224454928066

Epoch: 5| Step: 5
Training loss: 2.1349095804690568
Validation loss: 2.3989905909797824

Epoch: 5| Step: 6
Training loss: 2.307767097165995
Validation loss: 2.352306653363299

Epoch: 5| Step: 7
Training loss: 2.1037069391296375
Validation loss: 2.35580777715163

Epoch: 5| Step: 8
Training loss: 1.5674559769235963
Validation loss: 2.3752405436645043

Epoch: 5| Step: 9
Training loss: 2.0696774066423775
Validation loss: 2.347220197926206

Epoch: 5| Step: 10
Training loss: 2.346175401138827
Validation loss: 2.37708244282372

Epoch: 198| Step: 0
Training loss: 2.014335515567082
Validation loss: 2.3785725802460673

Epoch: 5| Step: 1
Training loss: 2.6398809163372134
Validation loss: 2.3496572527322668

Epoch: 5| Step: 2
Training loss: 1.937377064404076
Validation loss: 2.4148955540053856

Epoch: 5| Step: 3
Training loss: 2.5090380374705603
Validation loss: 2.362535248260316

Epoch: 5| Step: 4
Training loss: 1.8379165696229334
Validation loss: 2.3948884432027975

Epoch: 5| Step: 5
Training loss: 2.3557774482236393
Validation loss: 2.3745978554118095

Epoch: 5| Step: 6
Training loss: 1.582150301751241
Validation loss: 2.3730285117166674

Epoch: 5| Step: 7
Training loss: 2.504326985876877
Validation loss: 2.335195809603072

Epoch: 5| Step: 8
Training loss: 2.0572727894621146
Validation loss: 2.3929650445506288

Epoch: 5| Step: 9
Training loss: 2.215959325189882
Validation loss: 2.3721363795691057

Epoch: 5| Step: 10
Training loss: 1.6384834481300514
Validation loss: 2.3719867984804375

Epoch: 199| Step: 0
Training loss: 2.4205157988185744
Validation loss: 2.34728005861777

Epoch: 5| Step: 1
Training loss: 2.112870886934925
Validation loss: 2.351735224914869

Epoch: 5| Step: 2
Training loss: 1.716471392750114
Validation loss: 2.3898574387230327

Epoch: 5| Step: 3
Training loss: 2.12049050648621
Validation loss: 2.3648148929659474

Epoch: 5| Step: 4
Training loss: 1.9173111108602712
Validation loss: 2.380921394055679

Epoch: 5| Step: 5
Training loss: 2.0123868258859954
Validation loss: 2.3628643034537897

Epoch: 5| Step: 6
Training loss: 2.0711404548366317
Validation loss: 2.350753476579134

Epoch: 5| Step: 7
Training loss: 2.2393887694071513
Validation loss: 2.3630891504049045

Epoch: 5| Step: 8
Training loss: 2.381918417365478
Validation loss: 2.4067409234596475

Epoch: 5| Step: 9
Training loss: 2.0741351841761784
Validation loss: 2.363685452255336

Epoch: 5| Step: 10
Training loss: 2.652143198333022
Validation loss: 2.3618064824753624

Epoch: 200| Step: 0
Training loss: 1.9869195438370524
Validation loss: 2.342820358488714

Epoch: 5| Step: 1
Training loss: 1.6190103034386103
Validation loss: 2.3878606612224873

Epoch: 5| Step: 2
Training loss: 2.566981142355974
Validation loss: 2.3883269549657333

Epoch: 5| Step: 3
Training loss: 2.300195382982985
Validation loss: 2.372633297216106

Epoch: 5| Step: 4
Training loss: 1.4718693014305906
Validation loss: 2.3838253413790667

Epoch: 5| Step: 5
Training loss: 2.0219473635711305
Validation loss: 2.366550582561713

Epoch: 5| Step: 6
Training loss: 1.857194086300967
Validation loss: 2.3802072975549744

Epoch: 5| Step: 7
Training loss: 2.0062617981941107
Validation loss: 2.362397445594435

Epoch: 5| Step: 8
Training loss: 2.5054198643025187
Validation loss: 2.385510439349932

Epoch: 5| Step: 9
Training loss: 2.9779177806769077
Validation loss: 2.3813875060423357

Epoch: 5| Step: 10
Training loss: 2.1383131031121048
Validation loss: 2.366357852422449

Epoch: 201| Step: 0
Training loss: 2.040125427317103
Validation loss: 2.371413405368329

Epoch: 5| Step: 1
Training loss: 2.125796337137235
Validation loss: 2.370324386080283

Epoch: 5| Step: 2
Training loss: 2.064446426712762
Validation loss: 2.3662457264084473

Epoch: 5| Step: 3
Training loss: 2.0777501506747993
Validation loss: 2.3665099510293444

Epoch: 5| Step: 4
Training loss: 2.3714508843480187
Validation loss: 2.380358799316024

Epoch: 5| Step: 5
Training loss: 1.5459564255943392
Validation loss: 2.333831829080739

Epoch: 5| Step: 6
Training loss: 2.002011360624017
Validation loss: 2.369283591707848

Epoch: 5| Step: 7
Training loss: 2.092750880288488
Validation loss: 2.358055070965025

Epoch: 5| Step: 8
Training loss: 2.302989372908024
Validation loss: 2.3662235107537453

Epoch: 5| Step: 9
Training loss: 2.457375894946172
Validation loss: 2.3761058795261567

Epoch: 5| Step: 10
Training loss: 2.338968919042758
Validation loss: 2.373042961011709

Epoch: 202| Step: 0
Training loss: 1.980345472001429
Validation loss: 2.364563763029589

Epoch: 5| Step: 1
Training loss: 2.166520028165026
Validation loss: 2.3798922165506586

Epoch: 5| Step: 2
Training loss: 2.888147890800563
Validation loss: 2.3613417024428274

Epoch: 5| Step: 3
Training loss: 1.3841713731897403
Validation loss: 2.374875320676569

Epoch: 5| Step: 4
Training loss: 1.6100335856897365
Validation loss: 2.390821515989432

Epoch: 5| Step: 5
Training loss: 2.1934168766463618
Validation loss: 2.381143309076596

Epoch: 5| Step: 6
Training loss: 2.2433929924403064
Validation loss: 2.3804222357814266

Epoch: 5| Step: 7
Training loss: 2.0982668536711646
Validation loss: 2.376435865321547

Epoch: 5| Step: 8
Training loss: 2.567609948884249
Validation loss: 2.394402113304292

Epoch: 5| Step: 9
Training loss: 2.07457584963821
Validation loss: 2.3538307231925812

Epoch: 5| Step: 10
Training loss: 2.0396152492541906
Validation loss: 2.364686418803128

Epoch: 203| Step: 0
Training loss: 1.44104379785121
Validation loss: 2.4192152350834784

Epoch: 5| Step: 1
Training loss: 2.2936704949260767
Validation loss: 2.3863442034445748

Epoch: 5| Step: 2
Training loss: 2.3777765808320326
Validation loss: 2.382222528041445

Epoch: 5| Step: 3
Training loss: 1.5612135359550414
Validation loss: 2.36077062300008

Epoch: 5| Step: 4
Training loss: 2.4791586953256717
Validation loss: 2.3590487872842827

Epoch: 5| Step: 5
Training loss: 2.2960198296079417
Validation loss: 2.3821111606163816

Epoch: 5| Step: 6
Training loss: 1.9486928471178948
Validation loss: 2.3892260409960135

Epoch: 5| Step: 7
Training loss: 2.0062309002784136
Validation loss: 2.354177781134252

Epoch: 5| Step: 8
Training loss: 2.1460233684451335
Validation loss: 2.361415572525902

Epoch: 5| Step: 9
Training loss: 2.5352743676739933
Validation loss: 2.3887430239355165

Epoch: 5| Step: 10
Training loss: 2.014593289129463
Validation loss: 2.3595983721001796

Epoch: 204| Step: 0
Training loss: 2.600520661380354
Validation loss: 2.391727193159631

Epoch: 5| Step: 1
Training loss: 1.8767862712200252
Validation loss: 2.378046020564968

Epoch: 5| Step: 2
Training loss: 2.0901731997915753
Validation loss: 2.3544796996809376

Epoch: 5| Step: 3
Training loss: 2.5428520211004413
Validation loss: 2.364501344199786

Epoch: 5| Step: 4
Training loss: 2.302036428764834
Validation loss: 2.380108252802254

Epoch: 5| Step: 5
Training loss: 1.7533108862587066
Validation loss: 2.3841417762843276

Epoch: 5| Step: 6
Training loss: 2.146424172054395
Validation loss: 2.362904808893387

Epoch: 5| Step: 7
Training loss: 1.7737021899887118
Validation loss: 2.369701068872306

Epoch: 5| Step: 8
Training loss: 2.030945153469228
Validation loss: 2.3749906165170236

Epoch: 5| Step: 9
Training loss: 1.767281084761604
Validation loss: 2.367000644884197

Epoch: 5| Step: 10
Training loss: 2.3702690789426835
Validation loss: 2.346569359571641

Epoch: 205| Step: 0
Training loss: 2.1221603044439337
Validation loss: 2.3750122752193543

Epoch: 5| Step: 1
Training loss: 1.8981690393588742
Validation loss: 2.3691793367140574

Epoch: 5| Step: 2
Training loss: 2.1479087595111133
Validation loss: 2.377619703412558

Epoch: 5| Step: 3
Training loss: 2.1607102413207198
Validation loss: 2.362574323205728

Epoch: 5| Step: 4
Training loss: 2.2386560575625007
Validation loss: 2.36951875427984

Epoch: 5| Step: 5
Training loss: 2.7860058188285226
Validation loss: 2.4046260700706865

Epoch: 5| Step: 6
Training loss: 1.676978335045554
Validation loss: 2.365949621885946

Epoch: 5| Step: 7
Training loss: 2.3077953009975025
Validation loss: 2.371534108072437

Epoch: 5| Step: 8
Training loss: 1.7443848852180242
Validation loss: 2.356580046239481

Epoch: 5| Step: 9
Training loss: 2.0754471354560575
Validation loss: 2.3898757359863825

Epoch: 5| Step: 10
Training loss: 1.7942209961221096
Validation loss: 2.399406292759388

Epoch: 206| Step: 0
Training loss: 1.6629656548270988
Validation loss: 2.3658638698194423

Epoch: 5| Step: 1
Training loss: 2.549672094467569
Validation loss: 2.366514943412918

Epoch: 5| Step: 2
Training loss: 1.5530575589863558
Validation loss: 2.3840410502540874

Epoch: 5| Step: 3
Training loss: 1.9052154985824619
Validation loss: 2.392807312620218

Epoch: 5| Step: 4
Training loss: 2.2492113850649544
Validation loss: 2.37132712546575

Epoch: 5| Step: 5
Training loss: 1.8432763347930448
Validation loss: 2.3666610411225144

Epoch: 5| Step: 6
Training loss: 2.369774440381386
Validation loss: 2.4082591380459957

Epoch: 5| Step: 7
Training loss: 2.661761680281453
Validation loss: 2.3558764565289327

Epoch: 5| Step: 8
Training loss: 1.8918144330807518
Validation loss: 2.388032763933503

Epoch: 5| Step: 9
Training loss: 1.9677015873591586
Validation loss: 2.3511013344256195

Epoch: 5| Step: 10
Training loss: 2.3376690114980168
Validation loss: 2.39019308760204

Epoch: 207| Step: 0
Training loss: 2.136307866901458
Validation loss: 2.342862196918244

Epoch: 5| Step: 1
Training loss: 2.078266798645578
Validation loss: 2.3371462384654293

Epoch: 5| Step: 2
Training loss: 2.1450503751090255
Validation loss: 2.380046892232427

Epoch: 5| Step: 3
Training loss: 2.142581018186857
Validation loss: 2.3971353582028483

Epoch: 5| Step: 4
Training loss: 2.078728150914119
Validation loss: 2.3897813593516863

Epoch: 5| Step: 5
Training loss: 2.2009603268394105
Validation loss: 2.36133365760567

Epoch: 5| Step: 6
Training loss: 2.0745341318025288
Validation loss: 2.3748429208136206

Epoch: 5| Step: 7
Training loss: 2.041458300902502
Validation loss: 2.3516005937900855

Epoch: 5| Step: 8
Training loss: 1.9984832615269494
Validation loss: 2.3947313213054633

Epoch: 5| Step: 9
Training loss: 2.1883386366761273
Validation loss: 2.3711177710305873

Epoch: 5| Step: 10
Training loss: 2.2002692144573732
Validation loss: 2.3682309573313676

Epoch: 208| Step: 0
Training loss: 2.416494977267425
Validation loss: 2.362849402949504

Epoch: 5| Step: 1
Training loss: 1.6483262010940105
Validation loss: 2.3432590716995354

Epoch: 5| Step: 2
Training loss: 2.045556262406013
Validation loss: 2.379628584200468

Epoch: 5| Step: 3
Training loss: 1.6184261572499832
Validation loss: 2.3563331521657016

Epoch: 5| Step: 4
Training loss: 2.1663814748233996
Validation loss: 2.369644252046446

Epoch: 5| Step: 5
Training loss: 2.4107865014940937
Validation loss: 2.386816813692882

Epoch: 5| Step: 6
Training loss: 2.195611682203185
Validation loss: 2.3741489627829555

Epoch: 5| Step: 7
Training loss: 2.049285517603614
Validation loss: 2.3605141554836875

Epoch: 5| Step: 8
Training loss: 1.9394704581693356
Validation loss: 2.359543489349517

Epoch: 5| Step: 9
Training loss: 2.369003958663757
Validation loss: 2.364057600534381

Epoch: 5| Step: 10
Training loss: 2.115147582692476
Validation loss: 2.3818892948683055

Epoch: 209| Step: 0
Training loss: 2.091960996712792
Validation loss: 2.391329515734001

Epoch: 5| Step: 1
Training loss: 1.8419788064431197
Validation loss: 2.3791753414432595

Epoch: 5| Step: 2
Training loss: 2.334510801315239
Validation loss: 2.3805558461740683

Epoch: 5| Step: 3
Training loss: 1.9510504729694567
Validation loss: 2.3938506491302864

Epoch: 5| Step: 4
Training loss: 2.232671982312455
Validation loss: 2.378061093203446

Epoch: 5| Step: 5
Training loss: 2.216446553920373
Validation loss: 2.400170519455558

Epoch: 5| Step: 6
Training loss: 1.6253927196442433
Validation loss: 2.365252295876737

Epoch: 5| Step: 7
Training loss: 1.7394990577004412
Validation loss: 2.3845445351846823

Epoch: 5| Step: 8
Training loss: 2.602067594783476
Validation loss: 2.3723515216827913

Epoch: 5| Step: 9
Training loss: 1.8786353790384334
Validation loss: 2.3767236662592803

Epoch: 5| Step: 10
Training loss: 2.430379100631098
Validation loss: 2.3919638446918285

Epoch: 210| Step: 0
Training loss: 1.3691030108064253
Validation loss: 2.36948289145366

Epoch: 5| Step: 1
Training loss: 2.4894443829650954
Validation loss: 2.325471083221629

Epoch: 5| Step: 2
Training loss: 2.324185411230168
Validation loss: 2.3423927298484792

Epoch: 5| Step: 3
Training loss: 1.659375031609544
Validation loss: 2.352749678398312

Epoch: 5| Step: 4
Training loss: 2.2912827488067133
Validation loss: 2.3781621722265

Epoch: 5| Step: 5
Training loss: 1.7981910861549921
Validation loss: 2.3394392057821576

Epoch: 5| Step: 6
Training loss: 1.9185199761204452
Validation loss: 2.3693329978553366

Epoch: 5| Step: 7
Training loss: 2.2906544848700285
Validation loss: 2.3497612899583182

Epoch: 5| Step: 8
Training loss: 1.6530377168454442
Validation loss: 2.3514102822068104

Epoch: 5| Step: 9
Training loss: 2.6543539123919073
Validation loss: 2.3729094710247196

Epoch: 5| Step: 10
Training loss: 2.1141575602314133
Validation loss: 2.342187784407778

Epoch: 211| Step: 0
Training loss: 2.042151905966708
Validation loss: 2.3576723433941176

Epoch: 5| Step: 1
Training loss: 1.9855924461128842
Validation loss: 2.3574430339332073

Epoch: 5| Step: 2
Training loss: 1.6808383990873232
Validation loss: 2.3352808720686573

Epoch: 5| Step: 3
Training loss: 2.1989192995925535
Validation loss: 2.380802486348097

Epoch: 5| Step: 4
Training loss: 1.9733628018000329
Validation loss: 2.3586527416960728

Epoch: 5| Step: 5
Training loss: 2.2335867391651734
Validation loss: 2.3499073563176713

Epoch: 5| Step: 6
Training loss: 1.8210110613273838
Validation loss: 2.362877134835435

Epoch: 5| Step: 7
Training loss: 2.497107835591411
Validation loss: 2.383175616987479

Epoch: 5| Step: 8
Training loss: 2.0187180318751845
Validation loss: 2.3996458449858995

Epoch: 5| Step: 9
Training loss: 1.619083932728468
Validation loss: 2.3688895110170196

Epoch: 5| Step: 10
Training loss: 2.31044316965994
Validation loss: 2.3373205650729183

Epoch: 212| Step: 0
Training loss: 2.365228427718834
Validation loss: 2.353032049327631

Epoch: 5| Step: 1
Training loss: 1.8362268098180918
Validation loss: 2.373161623396913

Epoch: 5| Step: 2
Training loss: 1.5736263855008308
Validation loss: 2.36050760441017

Epoch: 5| Step: 3
Training loss: 2.550508493325189
Validation loss: 2.383687621956909

Epoch: 5| Step: 4
Training loss: 2.0828065842060117
Validation loss: 2.3797917787223617

Epoch: 5| Step: 5
Training loss: 2.1823821007344146
Validation loss: 2.3695335127673767

Epoch: 5| Step: 6
Training loss: 2.1399831436063774
Validation loss: 2.3554113117772886

Epoch: 5| Step: 7
Training loss: 1.7068175437417181
Validation loss: 2.382078952802893

Epoch: 5| Step: 8
Training loss: 1.9261282401247342
Validation loss: 2.3705735106962886

Epoch: 5| Step: 9
Training loss: 2.3097065730153203
Validation loss: 2.411312666482977

Epoch: 5| Step: 10
Training loss: 1.983634990971067
Validation loss: 2.3502423316619487

Epoch: 213| Step: 0
Training loss: 2.1841560963541427
Validation loss: 2.358133623076696

Epoch: 5| Step: 1
Training loss: 2.0994107600463026
Validation loss: 2.3561722492877015

Epoch: 5| Step: 2
Training loss: 1.77281910874056
Validation loss: 2.360702449806031

Epoch: 5| Step: 3
Training loss: 1.6115806797815206
Validation loss: 2.386803359684631

Epoch: 5| Step: 4
Training loss: 2.2613844550347695
Validation loss: 2.3659838902029167

Epoch: 5| Step: 5
Training loss: 2.063531213227134
Validation loss: 2.359746638453559

Epoch: 5| Step: 6
Training loss: 2.3752190338322903
Validation loss: 2.3378720272445483

Epoch: 5| Step: 7
Training loss: 2.026144095400104
Validation loss: 2.3784652843593217

Epoch: 5| Step: 8
Training loss: 1.9168642674740493
Validation loss: 2.3592860457654874

Epoch: 5| Step: 9
Training loss: 2.247404933187569
Validation loss: 2.391705933429634

Epoch: 5| Step: 10
Training loss: 2.133698443620683
Validation loss: 2.4125143087809575

Epoch: 214| Step: 0
Training loss: 1.9787365563153438
Validation loss: 2.3767047931361933

Epoch: 5| Step: 1
Training loss: 2.0594411188142265
Validation loss: 2.3522368763373196

Epoch: 5| Step: 2
Training loss: 2.1386073272579553
Validation loss: 2.326541519321121

Epoch: 5| Step: 3
Training loss: 2.1402025014666104
Validation loss: 2.379883595633701

Epoch: 5| Step: 4
Training loss: 2.0482542326976687
Validation loss: 2.3783053996794146

Epoch: 5| Step: 5
Training loss: 2.0260416012905345
Validation loss: 2.405232000949749

Epoch: 5| Step: 6
Training loss: 2.3270006985337504
Validation loss: 2.3757827615213634

Epoch: 5| Step: 7
Training loss: 1.9900815117019135
Validation loss: 2.38286092632649

Epoch: 5| Step: 8
Training loss: 2.373799171038917
Validation loss: 2.3922387631435114

Epoch: 5| Step: 9
Training loss: 1.6174375184150276
Validation loss: 2.362737616062511

Epoch: 5| Step: 10
Training loss: 1.7486997951365872
Validation loss: 2.406217017904597

Epoch: 215| Step: 0
Training loss: 1.898802168872174
Validation loss: 2.3855043083398226

Epoch: 5| Step: 1
Training loss: 2.7140344524965743
Validation loss: 2.359976014124354

Epoch: 5| Step: 2
Training loss: 2.4246082264728632
Validation loss: 2.327238259916454

Epoch: 5| Step: 3
Training loss: 1.4986950443172908
Validation loss: 2.3872070763541338

Epoch: 5| Step: 4
Training loss: 2.2615674747350654
Validation loss: 2.3380697381551014

Epoch: 5| Step: 5
Training loss: 2.239833114061227
Validation loss: 2.327753753584474

Epoch: 5| Step: 6
Training loss: 2.122076491844144
Validation loss: 2.351665258691988

Epoch: 5| Step: 7
Training loss: 1.7789046926244487
Validation loss: 2.3810542658279097

Epoch: 5| Step: 8
Training loss: 1.772956682135386
Validation loss: 2.348120383838054

Epoch: 5| Step: 9
Training loss: 1.7026771866606092
Validation loss: 2.405900280685969

Epoch: 5| Step: 10
Training loss: 1.9160013771888387
Validation loss: 2.3762115622200795

Epoch: 216| Step: 0
Training loss: 1.6707664450989563
Validation loss: 2.372765557528875

Epoch: 5| Step: 1
Training loss: 1.7581614508242145
Validation loss: 2.3599561249839973

Epoch: 5| Step: 2
Training loss: 1.9063603728812961
Validation loss: 2.3552545572438577

Epoch: 5| Step: 3
Training loss: 1.7092999848079842
Validation loss: 2.4005787753150467

Epoch: 5| Step: 4
Training loss: 1.67855115199959
Validation loss: 2.3764080144129283

Epoch: 5| Step: 5
Training loss: 2.26128967115398
Validation loss: 2.396145941914379

Epoch: 5| Step: 6
Training loss: 2.6078117393460545
Validation loss: 2.392617865427652

Epoch: 5| Step: 7
Training loss: 2.1694750802252285
Validation loss: 2.355292265053964

Epoch: 5| Step: 8
Training loss: 2.037905309886352
Validation loss: 2.368876727894485

Epoch: 5| Step: 9
Training loss: 2.4383553202488035
Validation loss: 2.3664237637232075

Epoch: 5| Step: 10
Training loss: 2.0416213309516
Validation loss: 2.3740878120964704

Epoch: 217| Step: 0
Training loss: 1.9880017157150018
Validation loss: 2.363431159695296

Epoch: 5| Step: 1
Training loss: 2.1692574734560717
Validation loss: 2.3655357699575057

Epoch: 5| Step: 2
Training loss: 2.3493667439211414
Validation loss: 2.411679963447284

Epoch: 5| Step: 3
Training loss: 2.2021546086734483
Validation loss: 2.380159897557259

Epoch: 5| Step: 4
Training loss: 1.857588222046411
Validation loss: 2.3641527448910344

Epoch: 5| Step: 5
Training loss: 1.7879311928491988
Validation loss: 2.3992399552971366

Epoch: 5| Step: 6
Training loss: 1.8552607048249126
Validation loss: 2.32053242363445

Epoch: 5| Step: 7
Training loss: 1.846216846806333
Validation loss: 2.351121379161343

Epoch: 5| Step: 8
Training loss: 1.8233845864065727
Validation loss: 2.3584909818246094

Epoch: 5| Step: 9
Training loss: 2.559575342481227
Validation loss: 2.3858368657496416

Epoch: 5| Step: 10
Training loss: 1.8382519357713363
Validation loss: 2.3901274552944494

Epoch: 218| Step: 0
Training loss: 1.976141602102764
Validation loss: 2.3691032928906206

Epoch: 5| Step: 1
Training loss: 2.0356317063602662
Validation loss: 2.3567969434578226

Epoch: 5| Step: 2
Training loss: 1.8215453593962163
Validation loss: 2.386736926319118

Epoch: 5| Step: 3
Training loss: 1.988921356587336
Validation loss: 2.3590171742010004

Epoch: 5| Step: 4
Training loss: 1.8028660950320772
Validation loss: 2.323476537306225

Epoch: 5| Step: 5
Training loss: 2.179273996815968
Validation loss: 2.337826753811749

Epoch: 5| Step: 6
Training loss: 1.6410869129789951
Validation loss: 2.3561247580092592

Epoch: 5| Step: 7
Training loss: 2.582274825110585
Validation loss: 2.35371533081292

Epoch: 5| Step: 8
Training loss: 1.8995253974038042
Validation loss: 2.361990535252097

Epoch: 5| Step: 9
Training loss: 2.0606211572066884
Validation loss: 2.305376403529003

Epoch: 5| Step: 10
Training loss: 2.1156759461617654
Validation loss: 2.3787246150623758

Epoch: 219| Step: 0
Training loss: 1.9408140449772064
Validation loss: 2.366687783778655

Epoch: 5| Step: 1
Training loss: 2.2216027416276893
Validation loss: 2.3851567816545036

Epoch: 5| Step: 2
Training loss: 1.6666212870459847
Validation loss: 2.3497036936696176

Epoch: 5| Step: 3
Training loss: 1.7987334219226259
Validation loss: 2.3862245421048947

Epoch: 5| Step: 4
Training loss: 2.197177407083238
Validation loss: 2.3328763273264435

Epoch: 5| Step: 5
Training loss: 1.920172829200602
Validation loss: 2.363888440615445

Epoch: 5| Step: 6
Training loss: 2.037461159926846
Validation loss: 2.3854826642973235

Epoch: 5| Step: 7
Training loss: 2.115666029291381
Validation loss: 2.391663853420464

Epoch: 5| Step: 8
Training loss: 2.1222916341529285
Validation loss: 2.3532842045174585

Epoch: 5| Step: 9
Training loss: 1.996796127934706
Validation loss: 2.3694676901341656

Epoch: 5| Step: 10
Training loss: 2.1444051736761782
Validation loss: 2.372328645658824

Epoch: 220| Step: 0
Training loss: 2.041436461361251
Validation loss: 2.378701894092636

Epoch: 5| Step: 1
Training loss: 1.8427480140957904
Validation loss: 2.3902776129150727

Epoch: 5| Step: 2
Training loss: 1.9849548093518572
Validation loss: 2.361150279998014

Epoch: 5| Step: 3
Training loss: 2.2068767662332966
Validation loss: 2.3729074463943407

Epoch: 5| Step: 4
Training loss: 1.9168259582116725
Validation loss: 2.350028723988681

Epoch: 5| Step: 5
Training loss: 2.284619599278931
Validation loss: 2.3580159320026053

Epoch: 5| Step: 6
Training loss: 1.974351151030402
Validation loss: 2.342613278174156

Epoch: 5| Step: 7
Training loss: 2.04371853958787
Validation loss: 2.3818484099753015

Epoch: 5| Step: 8
Training loss: 1.8085628366815083
Validation loss: 2.386913429847529

Epoch: 5| Step: 9
Training loss: 1.9985538857386482
Validation loss: 2.3184636207982505

Epoch: 5| Step: 10
Training loss: 2.142665475266194
Validation loss: 2.360394575980119

Epoch: 221| Step: 0
Training loss: 1.7989272629779536
Validation loss: 2.3823047900600565

Epoch: 5| Step: 1
Training loss: 2.2447128695106264
Validation loss: 2.36474970436961

Epoch: 5| Step: 2
Training loss: 1.8033410536247647
Validation loss: 2.351730411001928

Epoch: 5| Step: 3
Training loss: 2.088741632213074
Validation loss: 2.328516581241803

Epoch: 5| Step: 4
Training loss: 2.20837577443156
Validation loss: 2.3760419857925874

Epoch: 5| Step: 5
Training loss: 1.709403268974359
Validation loss: 2.347092556351702

Epoch: 5| Step: 6
Training loss: 2.0160548025433016
Validation loss: 2.4175829594781066

Epoch: 5| Step: 7
Training loss: 1.782914972996143
Validation loss: 2.3414928185485033

Epoch: 5| Step: 8
Training loss: 1.9490176538614206
Validation loss: 2.3998887681479553

Epoch: 5| Step: 9
Training loss: 2.4256590783257064
Validation loss: 2.4010390970187303

Epoch: 5| Step: 10
Training loss: 2.127997696215594
Validation loss: 2.382406760802263

Epoch: 222| Step: 0
Training loss: 2.103335742112769
Validation loss: 2.371487898975181

Epoch: 5| Step: 1
Training loss: 2.3041292193257275
Validation loss: 2.3807533020667946

Epoch: 5| Step: 2
Training loss: 1.9456427113884573
Validation loss: 2.367544819695347

Epoch: 5| Step: 3
Training loss: 1.8125831321856618
Validation loss: 2.377750376912863

Epoch: 5| Step: 4
Training loss: 2.001927043465775
Validation loss: 2.3454846018252358

Epoch: 5| Step: 5
Training loss: 1.8055647002094541
Validation loss: 2.368097316256758

Epoch: 5| Step: 6
Training loss: 1.9748982898259522
Validation loss: 2.3814069610550956

Epoch: 5| Step: 7
Training loss: 1.95679519661168
Validation loss: 2.4015562268522403

Epoch: 5| Step: 8
Training loss: 1.7760690666464216
Validation loss: 2.339082929092754

Epoch: 5| Step: 9
Training loss: 2.137419814005595
Validation loss: 2.3622266202899

Epoch: 5| Step: 10
Training loss: 2.2288410507491094
Validation loss: 2.363373092213257

Epoch: 223| Step: 0
Training loss: 1.9736387317838622
Validation loss: 2.351466397045667

Epoch: 5| Step: 1
Training loss: 1.9008148127680282
Validation loss: 2.3762821585842118

Epoch: 5| Step: 2
Training loss: 1.7270563722476295
Validation loss: 2.3767229403312156

Epoch: 5| Step: 3
Training loss: 2.106918939603587
Validation loss: 2.370918465983252

Epoch: 5| Step: 4
Training loss: 2.007859047672985
Validation loss: 2.365491590627081

Epoch: 5| Step: 5
Training loss: 2.0777029885325593
Validation loss: 2.3692675061657065

Epoch: 5| Step: 6
Training loss: 2.2568309722806155
Validation loss: 2.3752616215784714

Epoch: 5| Step: 7
Training loss: 2.006119544995935
Validation loss: 2.3888764533313602

Epoch: 5| Step: 8
Training loss: 2.286821954846447
Validation loss: 2.3905953980447623

Epoch: 5| Step: 9
Training loss: 1.9965742096592638
Validation loss: 2.4055682877209144

Epoch: 5| Step: 10
Training loss: 1.713565915138099
Validation loss: 2.3799242589853766

Epoch: 224| Step: 0
Training loss: 2.104320205777244
Validation loss: 2.37405648620225

Epoch: 5| Step: 1
Training loss: 1.7861790638019688
Validation loss: 2.363902530417359

Epoch: 5| Step: 2
Training loss: 2.073822041019577
Validation loss: 2.382796748939876

Epoch: 5| Step: 3
Training loss: 1.5548765748033875
Validation loss: 2.36745710802879

Epoch: 5| Step: 4
Training loss: 2.349559551925257
Validation loss: 2.3913872206293956

Epoch: 5| Step: 5
Training loss: 2.020858594074527
Validation loss: 2.3848653502740715

Epoch: 5| Step: 6
Training loss: 1.5756350221054152
Validation loss: 2.330869499670737

Epoch: 5| Step: 7
Training loss: 2.3007227011000646
Validation loss: 2.378243769457806

Epoch: 5| Step: 8
Training loss: 2.057331545157571
Validation loss: 2.396494781511394

Epoch: 5| Step: 9
Training loss: 1.8894403702875395
Validation loss: 2.3659057547686206

Epoch: 5| Step: 10
Training loss: 1.7140030940149218
Validation loss: 2.400036571806841

Epoch: 225| Step: 0
Training loss: 1.9716009055312205
Validation loss: 2.3670345890423103

Epoch: 5| Step: 1
Training loss: 2.420670732912714
Validation loss: 2.362616265387583

Epoch: 5| Step: 2
Training loss: 1.9552026912856426
Validation loss: 2.3861076606922498

Epoch: 5| Step: 3
Training loss: 2.056543012804056
Validation loss: 2.386807072809446

Epoch: 5| Step: 4
Training loss: 1.7943050416325477
Validation loss: 2.334665356274275

Epoch: 5| Step: 5
Training loss: 2.086495542710254
Validation loss: 2.371197552147296

Epoch: 5| Step: 6
Training loss: 1.7361294919206558
Validation loss: 2.3832937802538545

Epoch: 5| Step: 7
Training loss: 1.78654943146796
Validation loss: 2.3989529331241193

Epoch: 5| Step: 8
Training loss: 1.7455373812114545
Validation loss: 2.3399255067778943

Epoch: 5| Step: 9
Training loss: 1.913907352309852
Validation loss: 2.4068346340120206

Epoch: 5| Step: 10
Training loss: 2.206752091028751
Validation loss: 2.372870545744521

Epoch: 226| Step: 0
Training loss: 2.234829302932246
Validation loss: 2.3419917051573464

Epoch: 5| Step: 1
Training loss: 1.9104360051842026
Validation loss: 2.323925272984235

Epoch: 5| Step: 2
Training loss: 2.0758297513637114
Validation loss: 2.3822615706241588

Epoch: 5| Step: 3
Training loss: 2.0271064163676282
Validation loss: 2.382596684201879

Epoch: 5| Step: 4
Training loss: 1.853403584477581
Validation loss: 2.3799303548196122

Epoch: 5| Step: 5
Training loss: 1.8432302227234616
Validation loss: 2.3891493266697035

Epoch: 5| Step: 6
Training loss: 1.7397388304998538
Validation loss: 2.403570476604784

Epoch: 5| Step: 7
Training loss: 2.2118848516628034
Validation loss: 2.3794066151806637

Epoch: 5| Step: 8
Training loss: 2.4410664802634265
Validation loss: 2.36443036898178

Epoch: 5| Step: 9
Training loss: 1.2318866613446733
Validation loss: 2.3689432530549084

Epoch: 5| Step: 10
Training loss: 1.9799545192311556
Validation loss: 2.376029193136901

Epoch: 227| Step: 0
Training loss: 2.1625678343965764
Validation loss: 2.4001447763195474

Epoch: 5| Step: 1
Training loss: 1.8338000902694895
Validation loss: 2.399863522462149

Epoch: 5| Step: 2
Training loss: 1.7745066373501555
Validation loss: 2.3738100452690327

Epoch: 5| Step: 3
Training loss: 2.4196541725099223
Validation loss: 2.3441592935842124

Epoch: 5| Step: 4
Training loss: 1.5277562669723181
Validation loss: 2.3512670115801853

Epoch: 5| Step: 5
Training loss: 2.469930149434335
Validation loss: 2.4061813829469845

Epoch: 5| Step: 6
Training loss: 1.84014501352662
Validation loss: 2.368468242021155

Epoch: 5| Step: 7
Training loss: 1.8173530326096519
Validation loss: 2.368068356142022

Epoch: 5| Step: 8
Training loss: 1.8889857981013163
Validation loss: 2.3602689611261534

Epoch: 5| Step: 9
Training loss: 1.9685146857216005
Validation loss: 2.3801845164204796

Epoch: 5| Step: 10
Training loss: 1.7584117630857539
Validation loss: 2.3817768365821332

Epoch: 228| Step: 0
Training loss: 1.9565851917666097
Validation loss: 2.386160912870387

Epoch: 5| Step: 1
Training loss: 1.939085096647175
Validation loss: 2.3733363258731934

Epoch: 5| Step: 2
Training loss: 2.5589334742853067
Validation loss: 2.3502007544213894

Epoch: 5| Step: 3
Training loss: 1.8677023971755466
Validation loss: 2.3602082589497098

Epoch: 5| Step: 4
Training loss: 1.8630564172119426
Validation loss: 2.328330257837811

Epoch: 5| Step: 5
Training loss: 1.619396083728398
Validation loss: 2.3829935457955185

Epoch: 5| Step: 6
Training loss: 1.6853923351038858
Validation loss: 2.3818567606205066

Epoch: 5| Step: 7
Training loss: 1.8142871596005565
Validation loss: 2.36159470347232

Epoch: 5| Step: 8
Training loss: 2.250731031552105
Validation loss: 2.399653949408917

Epoch: 5| Step: 9
Training loss: 1.7774959289461238
Validation loss: 2.349383241790952

Epoch: 5| Step: 10
Training loss: 1.9547152339635772
Validation loss: 2.35860226021587

Epoch: 229| Step: 0
Training loss: 1.5876587795841477
Validation loss: 2.3677107040101566

Epoch: 5| Step: 1
Training loss: 2.0064570382502573
Validation loss: 2.387195823383254

Epoch: 5| Step: 2
Training loss: 2.039422832820068
Validation loss: 2.3778859745470204

Epoch: 5| Step: 3
Training loss: 1.6697752414148561
Validation loss: 2.371538079682112

Epoch: 5| Step: 4
Training loss: 1.811748282984313
Validation loss: 2.3728775175318138

Epoch: 5| Step: 5
Training loss: 2.20238152262166
Validation loss: 2.3936311696001753

Epoch: 5| Step: 6
Training loss: 2.004048065461914
Validation loss: 2.3446068010480756

Epoch: 5| Step: 7
Training loss: 1.9953364598591419
Validation loss: 2.362926547996429

Epoch: 5| Step: 8
Training loss: 2.291923115570849
Validation loss: 2.399853079282715

Epoch: 5| Step: 9
Training loss: 1.830553121409183
Validation loss: 2.3413005167592877

Epoch: 5| Step: 10
Training loss: 1.7562477437612356
Validation loss: 2.3634807369928836

Epoch: 230| Step: 0
Training loss: 2.3998738812052016
Validation loss: 2.365319654028961

Epoch: 5| Step: 1
Training loss: 1.7195088878600446
Validation loss: 2.3520662428229366

Epoch: 5| Step: 2
Training loss: 2.3399253665400916
Validation loss: 2.411621193143887

Epoch: 5| Step: 3
Training loss: 1.7277737334648027
Validation loss: 2.379229258443139

Epoch: 5| Step: 4
Training loss: 1.5499851287620616
Validation loss: 2.306844008760633

Epoch: 5| Step: 5
Training loss: 1.7482759293671202
Validation loss: 2.378733596909448

Epoch: 5| Step: 6
Training loss: 2.1141091803269703
Validation loss: 2.3472790472634872

Epoch: 5| Step: 7
Training loss: 2.185156738804915
Validation loss: 2.3746924090504695

Epoch: 5| Step: 8
Training loss: 1.9358507335514152
Validation loss: 2.400099182685856

Epoch: 5| Step: 9
Training loss: 1.4991605316992198
Validation loss: 2.377205875659013

Epoch: 5| Step: 10
Training loss: 2.121939306169567
Validation loss: 2.3948470030617317

Epoch: 231| Step: 0
Training loss: 1.7757424319682127
Validation loss: 2.4572208703796483

Epoch: 5| Step: 1
Training loss: 1.7713527441276111
Validation loss: 2.3279998210479396

Epoch: 5| Step: 2
Training loss: 2.0781869520547063
Validation loss: 2.335198729820639

Epoch: 5| Step: 3
Training loss: 2.121734803277604
Validation loss: 2.366022810676808

Epoch: 5| Step: 4
Training loss: 1.7851945802008438
Validation loss: 2.3393918542490764

Epoch: 5| Step: 5
Training loss: 1.6295231444595895
Validation loss: 2.364534676153156

Epoch: 5| Step: 6
Training loss: 2.3413914320753375
Validation loss: 2.3878766923729193

Epoch: 5| Step: 7
Training loss: 1.8491894286538206
Validation loss: 2.3723784271232407

Epoch: 5| Step: 8
Training loss: 2.0987807231060707
Validation loss: 2.3546747335834795

Epoch: 5| Step: 9
Training loss: 2.0164210204064195
Validation loss: 2.350512140436657

Epoch: 5| Step: 10
Training loss: 1.578923844697627
Validation loss: 2.31880018715444

Epoch: 232| Step: 0
Training loss: 1.477608688539406
Validation loss: 2.376309846985334

Epoch: 5| Step: 1
Training loss: 1.6129030241504667
Validation loss: 2.3708525260913866

Epoch: 5| Step: 2
Training loss: 1.6067816570624305
Validation loss: 2.3523023702836015

Epoch: 5| Step: 3
Training loss: 2.179099601846613
Validation loss: 2.3617188996250196

Epoch: 5| Step: 4
Training loss: 2.2562019913656415
Validation loss: 2.358231157818482

Epoch: 5| Step: 5
Training loss: 2.1583151395563585
Validation loss: 2.392669182309324

Epoch: 5| Step: 6
Training loss: 2.1674895435683816
Validation loss: 2.3544488593076127

Epoch: 5| Step: 7
Training loss: 2.4515956314794876
Validation loss: 2.4069906308697435

Epoch: 5| Step: 8
Training loss: 1.7560484448095925
Validation loss: 2.30182068870311

Epoch: 5| Step: 9
Training loss: 1.8562843859021154
Validation loss: 2.337037188741358

Epoch: 5| Step: 10
Training loss: 1.581493974040416
Validation loss: 2.415168308493268

Epoch: 233| Step: 0
Training loss: 1.98237316654293
Validation loss: 2.3311833633716668

Epoch: 5| Step: 1
Training loss: 1.9396106544589053
Validation loss: 2.3540735661026226

Epoch: 5| Step: 2
Training loss: 1.7584646413988678
Validation loss: 2.398640378640813

Epoch: 5| Step: 3
Training loss: 1.9022344600921595
Validation loss: 2.3540967861399364

Epoch: 5| Step: 4
Training loss: 2.36333481909199
Validation loss: 2.3477575930570387

Epoch: 5| Step: 5
Training loss: 2.136496914187113
Validation loss: 2.3889415823710207

Epoch: 5| Step: 6
Training loss: 2.1839450833329486
Validation loss: 2.376633612273697

Epoch: 5| Step: 7
Training loss: 1.8094243887846315
Validation loss: 2.3386202157533225

Epoch: 5| Step: 8
Training loss: 1.3302431158279457
Validation loss: 2.349945889585052

Epoch: 5| Step: 9
Training loss: 1.7886672603683444
Validation loss: 2.3853811883032208

Epoch: 5| Step: 10
Training loss: 1.8721046345111119
Validation loss: 2.348587436496505

Epoch: 234| Step: 0
Training loss: 1.864852083185161
Validation loss: 2.329594611525631

Epoch: 5| Step: 1
Training loss: 2.1140296724848118
Validation loss: 2.3844408297164046

Epoch: 5| Step: 2
Training loss: 1.7477346471767785
Validation loss: 2.3262204985105543

Epoch: 5| Step: 3
Training loss: 1.68470921925035
Validation loss: 2.393276394944194

Epoch: 5| Step: 4
Training loss: 1.8702212790262502
Validation loss: 2.3930579578648667

Epoch: 5| Step: 5
Training loss: 1.767753668229801
Validation loss: 2.361417791567335

Epoch: 5| Step: 6
Training loss: 2.107913153573124
Validation loss: 2.409766262929785

Epoch: 5| Step: 7
Training loss: 1.746683656862243
Validation loss: 2.337999013744669

Epoch: 5| Step: 8
Training loss: 1.8752844912549882
Validation loss: 2.3386397026146697

Epoch: 5| Step: 9
Training loss: 2.1574600804814095
Validation loss: 2.3480150144766085

Epoch: 5| Step: 10
Training loss: 1.7363241429492442
Validation loss: 2.3605280069476398

Epoch: 235| Step: 0
Training loss: 1.511849883155933
Validation loss: 2.3562470017054475

Epoch: 5| Step: 1
Training loss: 2.1682139764883344
Validation loss: 2.3615341531592176

Epoch: 5| Step: 2
Training loss: 1.5776015064934508
Validation loss: 2.338607076431781

Epoch: 5| Step: 3
Training loss: 2.064976217211454
Validation loss: 2.394313700195759

Epoch: 5| Step: 4
Training loss: 2.3195970247784077
Validation loss: 2.380888982253238

Epoch: 5| Step: 5
Training loss: 1.6970733077086153
Validation loss: 2.4206776567860713

Epoch: 5| Step: 6
Training loss: 2.3272900204124385
Validation loss: 2.358404448203113

Epoch: 5| Step: 7
Training loss: 2.114683239711136
Validation loss: 2.381021987729652

Epoch: 5| Step: 8
Training loss: 1.5507979308031163
Validation loss: 2.321099523595248

Epoch: 5| Step: 9
Training loss: 1.8384001103732321
Validation loss: 2.4089481864657656

Epoch: 5| Step: 10
Training loss: 1.7545661619359691
Validation loss: 2.3422265070624193

Epoch: 236| Step: 0
Training loss: 1.878272824174505
Validation loss: 2.3799086277688413

Epoch: 5| Step: 1
Training loss: 1.1937474495426115
Validation loss: 2.3641369302360125

Epoch: 5| Step: 2
Training loss: 2.037636678593059
Validation loss: 2.4070845926354596

Epoch: 5| Step: 3
Training loss: 2.3141297448463574
Validation loss: 2.346353402752849

Epoch: 5| Step: 4
Training loss: 2.006588692760747
Validation loss: 2.354339500338689

Epoch: 5| Step: 5
Training loss: 1.9045366185223966
Validation loss: 2.372504085905207

Epoch: 5| Step: 6
Training loss: 2.0205122964697706
Validation loss: 2.35154899037565

Epoch: 5| Step: 7
Training loss: 2.0411649074443554
Validation loss: 2.3763866586281694

Epoch: 5| Step: 8
Training loss: 2.3135782769363917
Validation loss: 2.417773618774217

Epoch: 5| Step: 9
Training loss: 1.8035432565153375
Validation loss: 2.3633989478871373

Epoch: 5| Step: 10
Training loss: 1.4076221129869944
Validation loss: 2.3736263192774785

Epoch: 237| Step: 0
Training loss: 2.3004693174448927
Validation loss: 2.3781015095891305

Epoch: 5| Step: 1
Training loss: 1.8363722266228908
Validation loss: 2.371263250002058

Epoch: 5| Step: 2
Training loss: 2.2222666206163177
Validation loss: 2.350043081247805

Epoch: 5| Step: 3
Training loss: 1.7188414115872517
Validation loss: 2.365924320701018

Epoch: 5| Step: 4
Training loss: 1.503100132092116
Validation loss: 2.321020399605673

Epoch: 5| Step: 5
Training loss: 1.8501457234287664
Validation loss: 2.381662239007672

Epoch: 5| Step: 6
Training loss: 2.1700821756369812
Validation loss: 2.3426184084849297

Epoch: 5| Step: 7
Training loss: 2.0820708709439506
Validation loss: 2.3372821823288668

Epoch: 5| Step: 8
Training loss: 1.990755531426946
Validation loss: 2.357360063118987

Epoch: 5| Step: 9
Training loss: 1.1346701288009822
Validation loss: 2.329827979051295

Epoch: 5| Step: 10
Training loss: 1.9902431199590138
Validation loss: 2.3986920166292194

Epoch: 238| Step: 0
Training loss: 2.338784412679309
Validation loss: 2.3560244951976785

Epoch: 5| Step: 1
Training loss: 1.8538884872183579
Validation loss: 2.3632362512629834

Epoch: 5| Step: 2
Training loss: 1.5552806393711582
Validation loss: 2.3656300225791584

Epoch: 5| Step: 3
Training loss: 1.9856949268644146
Validation loss: 2.3973188266882377

Epoch: 5| Step: 4
Training loss: 2.0479931288991344
Validation loss: 2.37460806499589

Epoch: 5| Step: 5
Training loss: 1.8521083880154074
Validation loss: 2.3851139997694117

Epoch: 5| Step: 6
Training loss: 1.4778586052817098
Validation loss: 2.374065558600388

Epoch: 5| Step: 7
Training loss: 1.9249918404938806
Validation loss: 2.4242542029816083

Epoch: 5| Step: 8
Training loss: 1.8723694468315986
Validation loss: 2.4203106679108215

Epoch: 5| Step: 9
Training loss: 2.1072471906865244
Validation loss: 2.4016874686659038

Epoch: 5| Step: 10
Training loss: 1.8200112285896433
Validation loss: 2.3725940751236974

Epoch: 239| Step: 0
Training loss: 1.768017928062783
Validation loss: 2.3873602896420287

Epoch: 5| Step: 1
Training loss: 1.7829974119560215
Validation loss: 2.3916521637128008

Epoch: 5| Step: 2
Training loss: 2.080923619611431
Validation loss: 2.3779734945202846

Epoch: 5| Step: 3
Training loss: 1.5206960415816035
Validation loss: 2.4064516276816175

Epoch: 5| Step: 4
Training loss: 1.8888391304318732
Validation loss: 2.3393834292797155

Epoch: 5| Step: 5
Training loss: 1.493727204216709
Validation loss: 2.3832758552004862

Epoch: 5| Step: 6
Training loss: 1.5106280825626486
Validation loss: 2.3891745519777445

Epoch: 5| Step: 7
Training loss: 2.1978954175551686
Validation loss: 2.366078001454957

Epoch: 5| Step: 8
Training loss: 1.5470650296096362
Validation loss: 2.403514462553309

Epoch: 5| Step: 9
Training loss: 2.378542817515257
Validation loss: 2.328410407861889

Epoch: 5| Step: 10
Training loss: 2.6358121994800263
Validation loss: 2.3438000745448804

Epoch: 240| Step: 0
Training loss: 1.5959287224821954
Validation loss: 2.39699526980796

Epoch: 5| Step: 1
Training loss: 1.6279950051570817
Validation loss: 2.3529511723330176

Epoch: 5| Step: 2
Training loss: 1.816471681134178
Validation loss: 2.385552487928869

Epoch: 5| Step: 3
Training loss: 1.6334649201670233
Validation loss: 2.357590462611885

Epoch: 5| Step: 4
Training loss: 2.1853487608487048
Validation loss: 2.387675873293329

Epoch: 5| Step: 5
Training loss: 1.9530216037084696
Validation loss: 2.3814709239948626

Epoch: 5| Step: 6
Training loss: 1.70455354746429
Validation loss: 2.394811275458118

Epoch: 5| Step: 7
Training loss: 1.7440540253775596
Validation loss: 2.3297603446764477

Epoch: 5| Step: 8
Training loss: 2.2034262593228386
Validation loss: 2.3704533338951452

Epoch: 5| Step: 9
Training loss: 2.530389898660996
Validation loss: 2.4096660574567066

Epoch: 5| Step: 10
Training loss: 1.8227106759079588
Validation loss: 2.3860580818622146

Epoch: 241| Step: 0
Training loss: 1.4500874591627884
Validation loss: 2.353919422351356

Epoch: 5| Step: 1
Training loss: 1.9596358154566835
Validation loss: 2.353718000413424

Epoch: 5| Step: 2
Training loss: 2.233810139995481
Validation loss: 2.440911716966605

Epoch: 5| Step: 3
Training loss: 1.532651454541971
Validation loss: 2.383205143293371

Epoch: 5| Step: 4
Training loss: 1.5690116998395514
Validation loss: 2.4012926258060285

Epoch: 5| Step: 5
Training loss: 2.155833549642042
Validation loss: 2.3951398834823405

Epoch: 5| Step: 6
Training loss: 1.3217504221693837
Validation loss: 2.362665496288571

Epoch: 5| Step: 7
Training loss: 1.8570492728726482
Validation loss: 2.3878809825018066

Epoch: 5| Step: 8
Training loss: 2.4221934447586526
Validation loss: 2.436240734169704

Epoch: 5| Step: 9
Training loss: 1.9067778560033612
Validation loss: 2.385501886022283

Epoch: 5| Step: 10
Training loss: 2.0399608752294838
Validation loss: 2.3790822482883613

Epoch: 242| Step: 0
Training loss: 1.8771414925233743
Validation loss: 2.3907286329097057

Epoch: 5| Step: 1
Training loss: 1.8322455112122786
Validation loss: 2.3100085596477267

Epoch: 5| Step: 2
Training loss: 1.910994706502357
Validation loss: 2.3594498378329263

Epoch: 5| Step: 3
Training loss: 1.702078821681318
Validation loss: 2.366104381232195

Epoch: 5| Step: 4
Training loss: 1.4054915184055492
Validation loss: 2.3765925479732655

Epoch: 5| Step: 5
Training loss: 1.7825823034302812
Validation loss: 2.3453168842101197

Epoch: 5| Step: 6
Training loss: 2.0698416696340605
Validation loss: 2.3583928871382462

Epoch: 5| Step: 7
Training loss: 1.846587890409123
Validation loss: 2.363887933068673

Epoch: 5| Step: 8
Training loss: 2.1905643253385745
Validation loss: 2.352536805660831

Epoch: 5| Step: 9
Training loss: 1.734919144782928
Validation loss: 2.3447590231720445

Epoch: 5| Step: 10
Training loss: 2.0275918738907666
Validation loss: 2.3608748524269685

Epoch: 243| Step: 0
Training loss: 2.0731665174750646
Validation loss: 2.3544781987209835

Epoch: 5| Step: 1
Training loss: 2.3011148984787737
Validation loss: 2.329273485397211

Epoch: 5| Step: 2
Training loss: 1.6740297354104712
Validation loss: 2.3637493687240565

Epoch: 5| Step: 3
Training loss: 1.5551025756661538
Validation loss: 2.3417467368195126

Epoch: 5| Step: 4
Training loss: 2.344373187819787
Validation loss: 2.41397426109574

Epoch: 5| Step: 5
Training loss: 1.5772364919546291
Validation loss: 2.3842109803209843

Epoch: 5| Step: 6
Training loss: 1.6389501105833206
Validation loss: 2.3442223349814966

Epoch: 5| Step: 7
Training loss: 1.6153902396079727
Validation loss: 2.3804425720976523

Epoch: 5| Step: 8
Training loss: 2.293893241047731
Validation loss: 2.37973540534355

Epoch: 5| Step: 9
Training loss: 1.5044441351161646
Validation loss: 2.3802280374497964

Epoch: 5| Step: 10
Training loss: 1.7949024153724455
Validation loss: 2.356153682675614

Epoch: 244| Step: 0
Training loss: 2.083102467778738
Validation loss: 2.3956989263112507

Epoch: 5| Step: 1
Training loss: 1.7194980034047054
Validation loss: 2.336085577225861

Epoch: 5| Step: 2
Training loss: 2.236236970201448
Validation loss: 2.3633335835550597

Epoch: 5| Step: 3
Training loss: 2.2897689822747402
Validation loss: 2.3607853042365647

Epoch: 5| Step: 4
Training loss: 1.326046832429943
Validation loss: 2.3616626766834976

Epoch: 5| Step: 5
Training loss: 2.0521645957489993
Validation loss: 2.3972077937803693

Epoch: 5| Step: 6
Training loss: 1.385172322842142
Validation loss: 2.340579660823918

Epoch: 5| Step: 7
Training loss: 1.8052988049141379
Validation loss: 2.3647343956515137

Epoch: 5| Step: 8
Training loss: 1.5387394754900507
Validation loss: 2.3419461594303

Epoch: 5| Step: 9
Training loss: 1.7786054555425146
Validation loss: 2.311714849461928

Epoch: 5| Step: 10
Training loss: 1.8263231184236797
Validation loss: 2.3152991860673002

Epoch: 245| Step: 0
Training loss: 1.6999605510846834
Validation loss: 2.338945864489769

Epoch: 5| Step: 1
Training loss: 1.7403008890338327
Validation loss: 2.3964320946474045

Epoch: 5| Step: 2
Training loss: 1.9738753074021047
Validation loss: 2.34663224172419

Epoch: 5| Step: 3
Training loss: 1.5107558384816753
Validation loss: 2.358708570653977

Epoch: 5| Step: 4
Training loss: 2.039124586541307
Validation loss: 2.3286572756557375

Epoch: 5| Step: 5
Training loss: 1.5035481608738912
Validation loss: 2.394040604598445

Epoch: 5| Step: 6
Training loss: 1.9473360253619834
Validation loss: 2.38194983843789

Epoch: 5| Step: 7
Training loss: 2.128014389950277
Validation loss: 2.399914644887234

Epoch: 5| Step: 8
Training loss: 1.5750274474159254
Validation loss: 2.381551351855724

Epoch: 5| Step: 9
Training loss: 1.5651349547579674
Validation loss: 2.408852960153337

Epoch: 5| Step: 10
Training loss: 2.0584751507582166
Validation loss: 2.360986283404902

Epoch: 246| Step: 0
Training loss: 1.497533677984979
Validation loss: 2.394396334832444

Epoch: 5| Step: 1
Training loss: 1.5104423871536041
Validation loss: 2.422855449988728

Epoch: 5| Step: 2
Training loss: 2.1991283337180714
Validation loss: 2.362946866721714

Epoch: 5| Step: 3
Training loss: 1.7010647272468997
Validation loss: 2.3684172905294356

Epoch: 5| Step: 4
Training loss: 1.670500644974868
Validation loss: 2.3511716489014516

Epoch: 5| Step: 5
Training loss: 2.1566952231912797
Validation loss: 2.402899409261958

Epoch: 5| Step: 6
Training loss: 1.7271041365759856
Validation loss: 2.380351371252214

Epoch: 5| Step: 7
Training loss: 1.6921318911558432
Validation loss: 2.3323849634651883

Epoch: 5| Step: 8
Training loss: 2.10144848141996
Validation loss: 2.384179952489911

Epoch: 5| Step: 9
Training loss: 2.1207153657232154
Validation loss: 2.4143730834855814

Epoch: 5| Step: 10
Training loss: 1.6722632697056965
Validation loss: 2.404061689175109

Epoch: 247| Step: 0
Training loss: 2.064005331306078
Validation loss: 2.3769302547045283

Epoch: 5| Step: 1
Training loss: 1.8919141803536872
Validation loss: 2.368813865896562

Epoch: 5| Step: 2
Training loss: 1.6465377346456225
Validation loss: 2.4314707970563454

Epoch: 5| Step: 3
Training loss: 1.8288712241930531
Validation loss: 2.413356607844769

Epoch: 5| Step: 4
Training loss: 1.3550548966045213
Validation loss: 2.3454617173408128

Epoch: 5| Step: 5
Training loss: 1.9180066635207018
Validation loss: 2.3227082470823524

Epoch: 5| Step: 6
Training loss: 1.5919613993052883
Validation loss: 2.4267889931684996

Epoch: 5| Step: 7
Training loss: 2.1100208565282315
Validation loss: 2.3800364224211528

Epoch: 5| Step: 8
Training loss: 1.8890852530018678
Validation loss: 2.3256836284729863

Epoch: 5| Step: 9
Training loss: 1.9856846610169618
Validation loss: 2.3940996525399174

Epoch: 5| Step: 10
Training loss: 1.7275067677344593
Validation loss: 2.396286669442805

Epoch: 248| Step: 0
Training loss: 1.9263118608704564
Validation loss: 2.3956320269216937

Epoch: 5| Step: 1
Training loss: 1.755930117326659
Validation loss: 2.3765369573749613

Epoch: 5| Step: 2
Training loss: 1.5672867504879269
Validation loss: 2.4119020245791196

Epoch: 5| Step: 3
Training loss: 2.057126530325147
Validation loss: 2.3142081395520777

Epoch: 5| Step: 4
Training loss: 1.7466660485497076
Validation loss: 2.412437563506975

Epoch: 5| Step: 5
Training loss: 1.4945723564369469
Validation loss: 2.3751098616038298

Epoch: 5| Step: 6
Training loss: 2.158259464408867
Validation loss: 2.479821573543893

Epoch: 5| Step: 7
Training loss: 1.8660815167626974
Validation loss: 2.4118273718952916

Epoch: 5| Step: 8
Training loss: 2.3504014301352827
Validation loss: 2.4298531985843788

Epoch: 5| Step: 9
Training loss: 1.5974080608817431
Validation loss: 2.4079579041512584

Epoch: 5| Step: 10
Training loss: 1.5493698808186154
Validation loss: 2.3941428178216664

Epoch: 249| Step: 0
Training loss: 1.701929635338247
Validation loss: 2.3442396214468246

Epoch: 5| Step: 1
Training loss: 1.721233861954221
Validation loss: 2.3565580342789856

Epoch: 5| Step: 2
Training loss: 1.6480089688242212
Validation loss: 2.425280258294811

Epoch: 5| Step: 3
Training loss: 2.239289753915233
Validation loss: 2.3818052285408564

Epoch: 5| Step: 4
Training loss: 1.8085091820342176
Validation loss: 2.3322785435450055

Epoch: 5| Step: 5
Training loss: 1.7272136030162384
Validation loss: 2.3671664444127662

Epoch: 5| Step: 6
Training loss: 2.025104910876207
Validation loss: 2.39219277930821

Epoch: 5| Step: 7
Training loss: 1.3706821356335266
Validation loss: 2.3902171322731554

Epoch: 5| Step: 8
Training loss: 1.8408956901841755
Validation loss: 2.36676952693003

Epoch: 5| Step: 9
Training loss: 1.9621852233552735
Validation loss: 2.354774761550269

Epoch: 5| Step: 10
Training loss: 1.99763999219238
Validation loss: 2.3792179100926303

Epoch: 250| Step: 0
Training loss: 1.6465347662440035
Validation loss: 2.347324924738638

Epoch: 5| Step: 1
Training loss: 1.6727730308934687
Validation loss: 2.3279041957214113

Epoch: 5| Step: 2
Training loss: 1.5409721494085107
Validation loss: 2.3670795754099676

Epoch: 5| Step: 3
Training loss: 1.9651556961848602
Validation loss: 2.3876409950623345

Epoch: 5| Step: 4
Training loss: 1.798066117612382
Validation loss: 2.373124269740648

Epoch: 5| Step: 5
Training loss: 2.0720011032646513
Validation loss: 2.392100505155664

Epoch: 5| Step: 6
Training loss: 1.4559901713783616
Validation loss: 2.3906886063956447

Epoch: 5| Step: 7
Training loss: 2.481124767150668
Validation loss: 2.3674427470061077

Epoch: 5| Step: 8
Training loss: 1.837761804523316
Validation loss: 2.354598061270417

Epoch: 5| Step: 9
Training loss: 1.6662593184809382
Validation loss: 2.3359305913641033

Epoch: 5| Step: 10
Training loss: 1.8013212176399502
Validation loss: 2.371793670234856

Epoch: 251| Step: 0
Training loss: 1.755656229558258
Validation loss: 2.3709540508341798

Epoch: 5| Step: 1
Training loss: 1.620018586417117
Validation loss: 2.38378015885127

Epoch: 5| Step: 2
Training loss: 1.5814104534055993
Validation loss: 2.4001242133353475

Epoch: 5| Step: 3
Training loss: 1.2772932130108101
Validation loss: 2.369201037721103

Epoch: 5| Step: 4
Training loss: 1.781373404528052
Validation loss: 2.3751561821067404

Epoch: 5| Step: 5
Training loss: 2.1501812880622886
Validation loss: 2.3842044707034535

Epoch: 5| Step: 6
Training loss: 1.882666237876094
Validation loss: 2.4158330904062364

Epoch: 5| Step: 7
Training loss: 2.0885381024743266
Validation loss: 2.397529425070004

Epoch: 5| Step: 8
Training loss: 2.221793438022039
Validation loss: 2.385976936677419

Epoch: 5| Step: 9
Training loss: 2.0995314756624546
Validation loss: 2.3965512693164945

Epoch: 5| Step: 10
Training loss: 1.560876613342082
Validation loss: 2.3623494158589957

Epoch: 252| Step: 0
Training loss: 1.785644664769615
Validation loss: 2.404944783021327

Epoch: 5| Step: 1
Training loss: 1.5873542808876562
Validation loss: 2.3777757916135367

Epoch: 5| Step: 2
Training loss: 1.9298662728345117
Validation loss: 2.3776338962209875

Epoch: 5| Step: 3
Training loss: 1.8360651499423335
Validation loss: 2.3792112532017518

Epoch: 5| Step: 4
Training loss: 1.4443443561177065
Validation loss: 2.3572845466562105

Epoch: 5| Step: 5
Training loss: 1.614571930219519
Validation loss: 2.341991293572215

Epoch: 5| Step: 6
Training loss: 1.093710925902906
Validation loss: 2.3527977172329106

Epoch: 5| Step: 7
Training loss: 2.31362331016743
Validation loss: 2.426652560523808

Epoch: 5| Step: 8
Training loss: 2.2817760540321204
Validation loss: 2.369878603208176

Epoch: 5| Step: 9
Training loss: 1.8251166737506768
Validation loss: 2.43853132770481

Epoch: 5| Step: 10
Training loss: 1.6126267996916144
Validation loss: 2.3967789934883124

Epoch: 253| Step: 0
Training loss: 2.015821580393943
Validation loss: 2.3540341333327297

Epoch: 5| Step: 1
Training loss: 2.4282845620219335
Validation loss: 2.3650614403417216

Epoch: 5| Step: 2
Training loss: 2.091389364374599
Validation loss: 2.385170744744171

Epoch: 5| Step: 3
Training loss: 2.372569697876747
Validation loss: 2.357344161568609

Epoch: 5| Step: 4
Training loss: 1.3799895011115486
Validation loss: 2.3427953327652244

Epoch: 5| Step: 5
Training loss: 1.4386761042014609
Validation loss: 2.362271442372789

Epoch: 5| Step: 6
Training loss: 1.4942989090996246
Validation loss: 2.3907325501136243

Epoch: 5| Step: 7
Training loss: 1.7031075012987948
Validation loss: 2.376016918315906

Epoch: 5| Step: 8
Training loss: 1.3454888648001546
Validation loss: 2.3583791405338794

Epoch: 5| Step: 9
Training loss: 1.5743234755749722
Validation loss: 2.3315847297136507

Epoch: 5| Step: 10
Training loss: 1.8511945785479342
Validation loss: 2.3684057453267493

Epoch: 254| Step: 0
Training loss: 1.4135105046225025
Validation loss: 2.374857559854882

Epoch: 5| Step: 1
Training loss: 2.1634950410254015
Validation loss: 2.412857015390542

Epoch: 5| Step: 2
Training loss: 1.596431645249906
Validation loss: 2.3469716703890446

Epoch: 5| Step: 3
Training loss: 1.4839004561154592
Validation loss: 2.415992166028235

Epoch: 5| Step: 4
Training loss: 2.157663738804872
Validation loss: 2.396017871257351

Epoch: 5| Step: 5
Training loss: 1.1747585170231716
Validation loss: 2.3846606234930072

Epoch: 5| Step: 6
Training loss: 1.8698941966841902
Validation loss: 2.4881280953751537

Epoch: 5| Step: 7
Training loss: 1.7738441975631325
Validation loss: 2.3856428083680217

Epoch: 5| Step: 8
Training loss: 1.9998081234443148
Validation loss: 2.3901477240510673

Epoch: 5| Step: 9
Training loss: 2.0153261894699277
Validation loss: 2.3489044689320586

Epoch: 5| Step: 10
Training loss: 1.815501260398232
Validation loss: 2.3814950750291843

Epoch: 255| Step: 0
Training loss: 1.8486127575221263
Validation loss: 2.417940886586097

Epoch: 5| Step: 1
Training loss: 2.0770670556974142
Validation loss: 2.388783761311752

Epoch: 5| Step: 2
Training loss: 1.1769737203867978
Validation loss: 2.3753834216851955

Epoch: 5| Step: 3
Training loss: 1.544418619513244
Validation loss: 2.3932446308987196

Epoch: 5| Step: 4
Training loss: 1.8055678693237351
Validation loss: 2.3934575189663003

Epoch: 5| Step: 5
Training loss: 2.1404966886726897
Validation loss: 2.362022961903114

Epoch: 5| Step: 6
Training loss: 1.5226786753224923
Validation loss: 2.3584244781532795

Epoch: 5| Step: 7
Training loss: 1.84846108067644
Validation loss: 2.4181724548810433

Epoch: 5| Step: 8
Training loss: 1.9003467770386273
Validation loss: 2.3547387356845406

Epoch: 5| Step: 9
Training loss: 2.170842206452358
Validation loss: 2.3420436310768142

Epoch: 5| Step: 10
Training loss: 1.243573932549715
Validation loss: 2.311294940100352

Epoch: 256| Step: 0
Training loss: 1.6074502045555665
Validation loss: 2.3324704032164756

Epoch: 5| Step: 1
Training loss: 1.8701213308741633
Validation loss: 2.3921333030411076

Epoch: 5| Step: 2
Training loss: 1.7489421235591098
Validation loss: 2.3961402559150065

Epoch: 5| Step: 3
Training loss: 1.4631089988462522
Validation loss: 2.3588530977755657

Epoch: 5| Step: 4
Training loss: 2.232159029220852
Validation loss: 2.4229544005601142

Epoch: 5| Step: 5
Training loss: 1.5207661217595803
Validation loss: 2.4553796687409326

Epoch: 5| Step: 6
Training loss: 1.683730117691791
Validation loss: 2.353805413725428

Epoch: 5| Step: 7
Training loss: 1.660810417990818
Validation loss: 2.3868290088061594

Epoch: 5| Step: 8
Training loss: 2.1122010691038016
Validation loss: 2.398813437137876

Epoch: 5| Step: 9
Training loss: 1.8078838627741818
Validation loss: 2.387040908553868

Epoch: 5| Step: 10
Training loss: 1.8634564139445662
Validation loss: 2.3434817296658004

Epoch: 257| Step: 0
Training loss: 1.481632469792429
Validation loss: 2.3395976702891748

Epoch: 5| Step: 1
Training loss: 1.6289573313801917
Validation loss: 2.3834077707144705

Epoch: 5| Step: 2
Training loss: 1.5431655178876744
Validation loss: 2.429140173122873

Epoch: 5| Step: 3
Training loss: 1.3787807158907492
Validation loss: 2.387143610235953

Epoch: 5| Step: 4
Training loss: 2.218261665010042
Validation loss: 2.429289178294061

Epoch: 5| Step: 5
Training loss: 1.7274464549531556
Validation loss: 2.401394209817537

Epoch: 5| Step: 6
Training loss: 1.8329959110936553
Validation loss: 2.441002707324401

Epoch: 5| Step: 7
Training loss: 1.9758341054004505
Validation loss: 2.4167643949149293

Epoch: 5| Step: 8
Training loss: 1.6764512934425737
Validation loss: 2.3901849693336774

Epoch: 5| Step: 9
Training loss: 1.789901137045999
Validation loss: 2.4063472624268245

Epoch: 5| Step: 10
Training loss: 2.045680971810545
Validation loss: 2.3701856377403994

Epoch: 258| Step: 0
Training loss: 2.036862878707773
Validation loss: 2.3791631130252813

Epoch: 5| Step: 1
Training loss: 1.366814262669839
Validation loss: 2.4027265042204142

Epoch: 5| Step: 2
Training loss: 1.5142981630260897
Validation loss: 2.3988294089851045

Epoch: 5| Step: 3
Training loss: 1.9104451778146638
Validation loss: 2.390941987860493

Epoch: 5| Step: 4
Training loss: 1.3244123289240102
Validation loss: 2.4089088330416786

Epoch: 5| Step: 5
Training loss: 1.802815444793121
Validation loss: 2.4127880799420596

Epoch: 5| Step: 6
Training loss: 2.16009918744563
Validation loss: 2.368310618118193

Epoch: 5| Step: 7
Training loss: 1.5177118151678686
Validation loss: 2.4322624941716686

Epoch: 5| Step: 8
Training loss: 1.6342990077132609
Validation loss: 2.352923519578285

Epoch: 5| Step: 9
Training loss: 1.744886215457033
Validation loss: 2.4284221328475324

Epoch: 5| Step: 10
Training loss: 2.0314276984321937
Validation loss: 2.381302480539462

Epoch: 259| Step: 0
Training loss: 2.0015230340215906
Validation loss: 2.377287584975515

Epoch: 5| Step: 1
Training loss: 1.7468440344834872
Validation loss: 2.3875631259947703

Epoch: 5| Step: 2
Training loss: 2.162144440984274
Validation loss: 2.396583316331493

Epoch: 5| Step: 3
Training loss: 1.466474190277733
Validation loss: 2.3684539239314173

Epoch: 5| Step: 4
Training loss: 1.7062933612386042
Validation loss: 2.372592507825688

Epoch: 5| Step: 5
Training loss: 1.4904308264598911
Validation loss: 2.3972748138831723

Epoch: 5| Step: 6
Training loss: 1.8667526057873842
Validation loss: 2.4158011263062575

Epoch: 5| Step: 7
Training loss: 2.0679842543011775
Validation loss: 2.370409200793775

Epoch: 5| Step: 8
Training loss: 1.7656807679677937
Validation loss: 2.374324349505128

Epoch: 5| Step: 9
Training loss: 1.6323021634203971
Validation loss: 2.451319407094112

Epoch: 5| Step: 10
Training loss: 1.533460150878488
Validation loss: 2.3597462082371248

Epoch: 260| Step: 0
Training loss: 1.712937183682551
Validation loss: 2.429242291702712

Epoch: 5| Step: 1
Training loss: 1.992631810326398
Validation loss: 2.4044725661069117

Epoch: 5| Step: 2
Training loss: 1.8640082838259144
Validation loss: 2.343437658574285

Epoch: 5| Step: 3
Training loss: 1.6794369532888163
Validation loss: 2.39177099613982

Epoch: 5| Step: 4
Training loss: 2.1167077228238917
Validation loss: 2.4237990977871524

Epoch: 5| Step: 5
Training loss: 1.7549034631158367
Validation loss: 2.388589485052969

Epoch: 5| Step: 6
Training loss: 1.4969831965133444
Validation loss: 2.423477761381577

Epoch: 5| Step: 7
Training loss: 1.8231802032346658
Validation loss: 2.4150763092387195

Epoch: 5| Step: 8
Training loss: 1.8661062389889493
Validation loss: 2.3963307635162048

Epoch: 5| Step: 9
Training loss: 1.5705415928678803
Validation loss: 2.3734524039600573

Epoch: 5| Step: 10
Training loss: 1.90307809806369
Validation loss: 2.37235834802975

Epoch: 261| Step: 0
Training loss: 1.9690790658268187
Validation loss: 2.3849863293889455

Epoch: 5| Step: 1
Training loss: 1.7003797752057006
Validation loss: 2.401927202169188

Epoch: 5| Step: 2
Training loss: 1.3487554959811854
Validation loss: 2.3589006466081335

Epoch: 5| Step: 3
Training loss: 1.8324313184453758
Validation loss: 2.349479664552336

Epoch: 5| Step: 4
Training loss: 1.636574240338832
Validation loss: 2.404097373147071

Epoch: 5| Step: 5
Training loss: 1.877420135099754
Validation loss: 2.3548508924876255

Epoch: 5| Step: 6
Training loss: 1.9035548559350302
Validation loss: 2.4322280613728693

Epoch: 5| Step: 7
Training loss: 1.9123321808630946
Validation loss: 2.3858571118580807

Epoch: 5| Step: 8
Training loss: 1.5227253349685244
Validation loss: 2.3983131636468005

Epoch: 5| Step: 9
Training loss: 1.315358772433666
Validation loss: 2.4400997092001564

Epoch: 5| Step: 10
Training loss: 2.529672390078021
Validation loss: 2.3024027126831363

Epoch: 262| Step: 0
Training loss: 1.9362615503467806
Validation loss: 2.406581600115379

Epoch: 5| Step: 1
Training loss: 1.7236063925471625
Validation loss: 2.4142587679326923

Epoch: 5| Step: 2
Training loss: 2.0888918411062676
Validation loss: 2.377489697205104

Epoch: 5| Step: 3
Training loss: 1.5955809753058396
Validation loss: 2.3616354722191844

Epoch: 5| Step: 4
Training loss: 1.4968178692389718
Validation loss: 2.3431458753564676

Epoch: 5| Step: 5
Training loss: 1.7052993193975634
Validation loss: 2.3870649828286292

Epoch: 5| Step: 6
Training loss: 2.1994323084726255
Validation loss: 2.3492861439580723

Epoch: 5| Step: 7
Training loss: 1.6829437629701323
Validation loss: 2.3726760761592915

Epoch: 5| Step: 8
Training loss: 1.2333620478320264
Validation loss: 2.3881759726459193

Epoch: 5| Step: 9
Training loss: 1.8301948501996352
Validation loss: 2.382456724442294

Epoch: 5| Step: 10
Training loss: 1.3493736933551237
Validation loss: 2.3892897237974724

Epoch: 263| Step: 0
Training loss: 1.997849082665541
Validation loss: 2.414352249336011

Epoch: 5| Step: 1
Training loss: 1.3254882668602188
Validation loss: 2.409603529189831

Epoch: 5| Step: 2
Training loss: 1.8591697002518939
Validation loss: 2.400115521959499

Epoch: 5| Step: 3
Training loss: 1.471201858964485
Validation loss: 2.3300095632067164

Epoch: 5| Step: 4
Training loss: 1.7210436688589947
Validation loss: 2.3587865901847254

Epoch: 5| Step: 5
Training loss: 1.6554403665367785
Validation loss: 2.3724626697169224

Epoch: 5| Step: 6
Training loss: 1.6049691789704081
Validation loss: 2.436486585438947

Epoch: 5| Step: 7
Training loss: 1.924497598259553
Validation loss: 2.37590492443698

Epoch: 5| Step: 8
Training loss: 1.7580404854323433
Validation loss: 2.361558646491994

Epoch: 5| Step: 9
Training loss: 1.817663598443767
Validation loss: 2.389188747501049

Epoch: 5| Step: 10
Training loss: 2.218638994905565
Validation loss: 2.3709828951483036

Epoch: 264| Step: 0
Training loss: 1.8785260424500603
Validation loss: 2.3486148106551954

Epoch: 5| Step: 1
Training loss: 1.4685816566902037
Validation loss: 2.388564170922186

Epoch: 5| Step: 2
Training loss: 1.8488119434556898
Validation loss: 2.38981961656874

Epoch: 5| Step: 3
Training loss: 2.2328906697603954
Validation loss: 2.3470683331264173

Epoch: 5| Step: 4
Training loss: 1.755450480102484
Validation loss: 2.3466543293106112

Epoch: 5| Step: 5
Training loss: 1.2810827936996714
Validation loss: 2.390600590531323

Epoch: 5| Step: 6
Training loss: 1.4626955276593012
Validation loss: 2.3665921856248056

Epoch: 5| Step: 7
Training loss: 1.528891635175821
Validation loss: 2.3436147955723823

Epoch: 5| Step: 8
Training loss: 1.596976436371879
Validation loss: 2.3513210697210774

Epoch: 5| Step: 9
Training loss: 2.405074984517602
Validation loss: 2.313248639261082

Epoch: 5| Step: 10
Training loss: 1.167526722832952
Validation loss: 2.375445333868557

Epoch: 265| Step: 0
Training loss: 1.7374998243592537
Validation loss: 2.4008596880425728

Epoch: 5| Step: 1
Training loss: 1.7147921682607397
Validation loss: 2.403724056307788

Epoch: 5| Step: 2
Training loss: 1.095447367637801
Validation loss: 2.3924576728306564

Epoch: 5| Step: 3
Training loss: 2.203598729057451
Validation loss: 2.408639117316731

Epoch: 5| Step: 4
Training loss: 1.230275117685564
Validation loss: 2.3694233969362815

Epoch: 5| Step: 5
Training loss: 1.9521224233431145
Validation loss: 2.3231533041655363

Epoch: 5| Step: 6
Training loss: 1.3858960787358112
Validation loss: 2.3977405470339668

Epoch: 5| Step: 7
Training loss: 1.8555177059742216
Validation loss: 2.3726078771342283

Epoch: 5| Step: 8
Training loss: 1.9198427698209404
Validation loss: 2.3944046486753465

Epoch: 5| Step: 9
Training loss: 1.9372645204250705
Validation loss: 2.3972037572217735

Epoch: 5| Step: 10
Training loss: 1.7140340435826895
Validation loss: 2.337255042889308

Epoch: 266| Step: 0
Training loss: 1.3880054790322724
Validation loss: 2.3548047664444702

Epoch: 5| Step: 1
Training loss: 1.192241888443015
Validation loss: 2.3226066995797803

Epoch: 5| Step: 2
Training loss: 1.9972540959712415
Validation loss: 2.3844394400797038

Epoch: 5| Step: 3
Training loss: 1.4248911966647713
Validation loss: 2.4145411782654547

Epoch: 5| Step: 4
Training loss: 1.2125906212359852
Validation loss: 2.3107441136726794

Epoch: 5| Step: 5
Training loss: 1.7865542357331854
Validation loss: 2.410363028422091

Epoch: 5| Step: 6
Training loss: 2.142751820564498
Validation loss: 2.37426717038036

Epoch: 5| Step: 7
Training loss: 2.1855070572431288
Validation loss: 2.445924872713065

Epoch: 5| Step: 8
Training loss: 1.5711972605155013
Validation loss: 2.401029744829469

Epoch: 5| Step: 9
Training loss: 1.688362607535818
Validation loss: 2.358489999463123

Epoch: 5| Step: 10
Training loss: 1.727719225850489
Validation loss: 2.3566625908919665

Epoch: 267| Step: 0
Training loss: 1.9051215161592732
Validation loss: 2.3433773190202096

Epoch: 5| Step: 1
Training loss: 2.150569565315484
Validation loss: 2.3685802888001652

Epoch: 5| Step: 2
Training loss: 1.782808726086914
Validation loss: 2.3494638853428875

Epoch: 5| Step: 3
Training loss: 1.3679941032321616
Validation loss: 2.340400083619754

Epoch: 5| Step: 4
Training loss: 1.0031995252454506
Validation loss: 2.352363555734697

Epoch: 5| Step: 5
Training loss: 1.833926328932818
Validation loss: 2.4339066937286855

Epoch: 5| Step: 6
Training loss: 1.3833843277337283
Validation loss: 2.370393317023864

Epoch: 5| Step: 7
Training loss: 1.5279175443970123
Validation loss: 2.3629836077150865

Epoch: 5| Step: 8
Training loss: 1.7577126707763737
Validation loss: 2.365669255016027

Epoch: 5| Step: 9
Training loss: 2.1433629256480295
Validation loss: 2.385337704332588

Epoch: 5| Step: 10
Training loss: 2.018007038977514
Validation loss: 2.35791695319105

Epoch: 268| Step: 0
Training loss: 1.5166073005012588
Validation loss: 2.44301960511191

Epoch: 5| Step: 1
Training loss: 1.4386311931591154
Validation loss: 2.3577712280920844

Epoch: 5| Step: 2
Training loss: 1.5936351809561307
Validation loss: 2.3559542624442265

Epoch: 5| Step: 3
Training loss: 1.5124480782416403
Validation loss: 2.5076931654872854

Epoch: 5| Step: 4
Training loss: 1.583031910095734
Validation loss: 2.3995212464531046

Epoch: 5| Step: 5
Training loss: 1.7514268643951632
Validation loss: 2.4055136917914854

Epoch: 5| Step: 6
Training loss: 1.4857417189245186
Validation loss: 2.3925519481814947

Epoch: 5| Step: 7
Training loss: 1.6080683616748706
Validation loss: 2.3392163690655656

Epoch: 5| Step: 8
Training loss: 2.325797126877283
Validation loss: 2.404136470497632

Epoch: 5| Step: 9
Training loss: 2.055047297432309
Validation loss: 2.336623358347174

Epoch: 5| Step: 10
Training loss: 1.6296551855729315
Validation loss: 2.335448568358086

Epoch: 269| Step: 0
Training loss: 1.642218841921491
Validation loss: 2.373481222772863

Epoch: 5| Step: 1
Training loss: 1.9513132466067709
Validation loss: 2.4365830591234356

Epoch: 5| Step: 2
Training loss: 2.0810294827779154
Validation loss: 2.414275288524881

Epoch: 5| Step: 3
Training loss: 1.5289802077255463
Validation loss: 2.3401293269672094

Epoch: 5| Step: 4
Training loss: 1.5207773311528832
Validation loss: 2.3938061195481657

Epoch: 5| Step: 5
Training loss: 1.629803673323975
Validation loss: 2.3250866130089234

Epoch: 5| Step: 6
Training loss: 2.1312645964807846
Validation loss: 2.392416027706503

Epoch: 5| Step: 7
Training loss: 1.3832451095177458
Validation loss: 2.3376984962570275

Epoch: 5| Step: 8
Training loss: 1.7333705158402593
Validation loss: 2.402751780641638

Epoch: 5| Step: 9
Training loss: 1.765020351346614
Validation loss: 2.3619326662563016

Epoch: 5| Step: 10
Training loss: 1.5393281504060687
Validation loss: 2.391121777515853

Epoch: 270| Step: 0
Training loss: 1.4895605961413676
Validation loss: 2.430114471173072

Epoch: 5| Step: 1
Training loss: 1.8443859102862996
Validation loss: 2.3634139723812484

Epoch: 5| Step: 2
Training loss: 1.729145586122757
Validation loss: 2.4146435946833837

Epoch: 5| Step: 3
Training loss: 1.8382888994815676
Validation loss: 2.396727592925197

Epoch: 5| Step: 4
Training loss: 1.9039660044087483
Validation loss: 2.362368498623119

Epoch: 5| Step: 5
Training loss: 1.5724312831255862
Validation loss: 2.377365816492237

Epoch: 5| Step: 6
Training loss: 1.43837122845522
Validation loss: 2.4126289683877724

Epoch: 5| Step: 7
Training loss: 1.721058768714733
Validation loss: 2.3749424749854775

Epoch: 5| Step: 8
Training loss: 1.2269897688646632
Validation loss: 2.350832839743418

Epoch: 5| Step: 9
Training loss: 2.0683088863791834
Validation loss: 2.3806829416668864

Epoch: 5| Step: 10
Training loss: 1.5907303870762248
Validation loss: 2.41311670945735

Epoch: 271| Step: 0
Training loss: 2.1513967767413105
Validation loss: 2.442797656680033

Epoch: 5| Step: 1
Training loss: 1.302690954213952
Validation loss: 2.4239113663578724

Epoch: 5| Step: 2
Training loss: 1.6144262504048352
Validation loss: 2.4143516122356936

Epoch: 5| Step: 3
Training loss: 1.8686009248706938
Validation loss: 2.364123365593331

Epoch: 5| Step: 4
Training loss: 1.8757168353236393
Validation loss: 2.3878638627372886

Epoch: 5| Step: 5
Training loss: 1.5473857768461827
Validation loss: 2.3887520861662574

Epoch: 5| Step: 6
Training loss: 1.8285780777235565
Validation loss: 2.3947613511938894

Epoch: 5| Step: 7
Training loss: 1.8347893553984533
Validation loss: 2.3606630131944883

Epoch: 5| Step: 8
Training loss: 1.3916356132758438
Validation loss: 2.3670176626483324

Epoch: 5| Step: 9
Training loss: 1.640012208846634
Validation loss: 2.3410150344794856

Epoch: 5| Step: 10
Training loss: 1.7135239651431413
Validation loss: 2.3647899558190084

Epoch: 272| Step: 0
Training loss: 2.087438607598011
Validation loss: 2.3211463387605877

Epoch: 5| Step: 1
Training loss: 1.773062779837854
Validation loss: 2.3995346083195126

Epoch: 5| Step: 2
Training loss: 1.2649721887418732
Validation loss: 2.397093597560852

Epoch: 5| Step: 3
Training loss: 1.8166032581754128
Validation loss: 2.3908877050451998

Epoch: 5| Step: 4
Training loss: 1.6691950058241434
Validation loss: 2.3980338400368373

Epoch: 5| Step: 5
Training loss: 1.9566787737331544
Validation loss: 2.380990753604405

Epoch: 5| Step: 6
Training loss: 1.6654892656798628
Validation loss: 2.4295885456109834

Epoch: 5| Step: 7
Training loss: 1.6544536709932045
Validation loss: 2.375088166012836

Epoch: 5| Step: 8
Training loss: 1.5903822528146336
Validation loss: 2.408494164666394

Epoch: 5| Step: 9
Training loss: 1.274268972972962
Validation loss: 2.394766144443727

Epoch: 5| Step: 10
Training loss: 1.498814273121016
Validation loss: 2.368244409681357

Epoch: 273| Step: 0
Training loss: 1.4764920979826723
Validation loss: 2.3512302848515034

Epoch: 5| Step: 1
Training loss: 1.651554794077007
Validation loss: 2.3685280863263944

Epoch: 5| Step: 2
Training loss: 1.9216212903786414
Validation loss: 2.4043593856007797

Epoch: 5| Step: 3
Training loss: 1.704396744223231
Validation loss: 2.399471178723541

Epoch: 5| Step: 4
Training loss: 1.6634865063921778
Validation loss: 2.424540696257117

Epoch: 5| Step: 5
Training loss: 1.691583989695917
Validation loss: 2.398609613349942

Epoch: 5| Step: 6
Training loss: 1.73851344240141
Validation loss: 2.347337452805351

Epoch: 5| Step: 7
Training loss: 1.5825245782712254
Validation loss: 2.3469263114239367

Epoch: 5| Step: 8
Training loss: 1.433028356501828
Validation loss: 2.310892109285531

Epoch: 5| Step: 9
Training loss: 1.6288468237998415
Validation loss: 2.3700905451939858

Epoch: 5| Step: 10
Training loss: 2.1273585301844364
Validation loss: 2.370263150783716

Epoch: 274| Step: 0
Training loss: 1.175157856990211
Validation loss: 2.3041967259794514

Epoch: 5| Step: 1
Training loss: 1.5380820622471023
Validation loss: 2.3955112552881865

Epoch: 5| Step: 2
Training loss: 1.7049962534262026
Validation loss: 2.4034715957123187

Epoch: 5| Step: 3
Training loss: 1.3371128020937768
Validation loss: 2.3643100951627156

Epoch: 5| Step: 4
Training loss: 1.567349195268383
Validation loss: 2.4364104274463254

Epoch: 5| Step: 5
Training loss: 1.557584890192194
Validation loss: 2.5009364209910943

Epoch: 5| Step: 6
Training loss: 1.9327521448109906
Validation loss: 2.438593377050172

Epoch: 5| Step: 7
Training loss: 1.8520364919202252
Validation loss: 2.457030617705875

Epoch: 5| Step: 8
Training loss: 1.5955917338195649
Validation loss: 2.3763649347781164

Epoch: 5| Step: 9
Training loss: 2.4980459205798606
Validation loss: 2.3360877267741627

Epoch: 5| Step: 10
Training loss: 1.5981331185860832
Validation loss: 2.344667000715843

Epoch: 275| Step: 0
Training loss: 1.7848024247187648
Validation loss: 2.373200354319652

Epoch: 5| Step: 1
Training loss: 1.7252343364159857
Validation loss: 2.3086306664076077

Epoch: 5| Step: 2
Training loss: 1.6628343231656024
Validation loss: 2.4020528082754473

Epoch: 5| Step: 3
Training loss: 1.7945077312491071
Validation loss: 2.357013307339065

Epoch: 5| Step: 4
Training loss: 1.7151903223693465
Validation loss: 2.4039770993142215

Epoch: 5| Step: 5
Training loss: 1.5484804241801748
Validation loss: 2.391117814310988

Epoch: 5| Step: 6
Training loss: 1.999198395303828
Validation loss: 2.3196498178243616

Epoch: 5| Step: 7
Training loss: 1.2111625216204787
Validation loss: 2.37326149114541

Epoch: 5| Step: 8
Training loss: 1.8732096707716965
Validation loss: 2.3532170808907225

Epoch: 5| Step: 9
Training loss: 1.7712621581010946
Validation loss: 2.4014547270906195

Epoch: 5| Step: 10
Training loss: 1.583812774883379
Validation loss: 2.4027412454530537

Epoch: 276| Step: 0
Training loss: 1.6425348700272304
Validation loss: 2.3263792099493967

Epoch: 5| Step: 1
Training loss: 2.0519927597066885
Validation loss: 2.3445334401466438

Epoch: 5| Step: 2
Training loss: 1.6350630440646
Validation loss: 2.328561742284733

Epoch: 5| Step: 3
Training loss: 1.300607480651094
Validation loss: 2.3573455340086595

Epoch: 5| Step: 4
Training loss: 1.4424775233905935
Validation loss: 2.413279183985942

Epoch: 5| Step: 5
Training loss: 2.113419674554649
Validation loss: 2.3953469098746107

Epoch: 5| Step: 6
Training loss: 1.6654643569975676
Validation loss: 2.322277286987062

Epoch: 5| Step: 7
Training loss: 1.8391177938052166
Validation loss: 2.3961192584172117

Epoch: 5| Step: 8
Training loss: 1.7030484943530064
Validation loss: 2.362667961550155

Epoch: 5| Step: 9
Training loss: 1.537170021188856
Validation loss: 2.340161074700466

Epoch: 5| Step: 10
Training loss: 1.4557581189528763
Validation loss: 2.35308180486946

Epoch: 277| Step: 0
Training loss: 1.9030872435183472
Validation loss: 2.3507095930756363

Epoch: 5| Step: 1
Training loss: 1.4997910512986607
Validation loss: 2.4201373124614887

Epoch: 5| Step: 2
Training loss: 1.7021268667056895
Validation loss: 2.3875748695454933

Epoch: 5| Step: 3
Training loss: 1.4589561040914738
Validation loss: 2.3724118083346077

Epoch: 5| Step: 4
Training loss: 1.4402410661724567
Validation loss: 2.388351652799616

Epoch: 5| Step: 5
Training loss: 1.8316390343624798
Validation loss: 2.336373555458685

Epoch: 5| Step: 6
Training loss: 1.6786483744113716
Validation loss: 2.449300609807127

Epoch: 5| Step: 7
Training loss: 1.922102255682259
Validation loss: 2.4017593912294535

Epoch: 5| Step: 8
Training loss: 1.5417557596117948
Validation loss: 2.386999920726276

Epoch: 5| Step: 9
Training loss: 1.451355708147057
Validation loss: 2.4240756100745764

Epoch: 5| Step: 10
Training loss: 1.554309818264742
Validation loss: 2.4314002352334594

Epoch: 278| Step: 0
Training loss: 1.240449325076926
Validation loss: 2.353349724873762

Epoch: 5| Step: 1
Training loss: 1.595105735239783
Validation loss: 2.404087338649719

Epoch: 5| Step: 2
Training loss: 1.9992585595994616
Validation loss: 2.406584426787215

Epoch: 5| Step: 3
Training loss: 1.5508498169468639
Validation loss: 2.355729581699134

Epoch: 5| Step: 4
Training loss: 1.5290813269782448
Validation loss: 2.3897793549153734

Epoch: 5| Step: 5
Training loss: 2.213369265555747
Validation loss: 2.343559647900557

Epoch: 5| Step: 6
Training loss: 1.5308390474636784
Validation loss: 2.3812112701025065

Epoch: 5| Step: 7
Training loss: 1.4232859056568126
Validation loss: 2.390671868655385

Epoch: 5| Step: 8
Training loss: 1.8003046890510477
Validation loss: 2.4068449606220375

Epoch: 5| Step: 9
Training loss: 1.4990682887223417
Validation loss: 2.4087806501979583

Epoch: 5| Step: 10
Training loss: 1.2106269192028047
Validation loss: 2.341556839361209

Epoch: 279| Step: 0
Training loss: 1.6895520484495783
Validation loss: 2.409171260770436

Epoch: 5| Step: 1
Training loss: 1.5862915696152449
Validation loss: 2.3293467526691902

Epoch: 5| Step: 2
Training loss: 1.8142871596005565
Validation loss: 2.345105272263499

Epoch: 5| Step: 3
Training loss: 1.717072379060254
Validation loss: 2.407619624558486

Epoch: 5| Step: 4
Training loss: 1.6389661849736439
Validation loss: 2.3449630239835337

Epoch: 5| Step: 5
Training loss: 1.4740181451350929
Validation loss: 2.3929767508782116

Epoch: 5| Step: 6
Training loss: 1.8402346703940673
Validation loss: 2.4194929747985197

Epoch: 5| Step: 7
Training loss: 1.4102440381396617
Validation loss: 2.36651099153893

Epoch: 5| Step: 8
Training loss: 1.948424030125854
Validation loss: 2.404247770421691

Epoch: 5| Step: 9
Training loss: 1.640593973502196
Validation loss: 2.433688592353947

Epoch: 5| Step: 10
Training loss: 1.8814457408168372
Validation loss: 2.406343458001716

Epoch: 280| Step: 0
Training loss: 1.7507872173270613
Validation loss: 2.3766862262032062

Epoch: 5| Step: 1
Training loss: 1.5117208791318582
Validation loss: 2.4220588680444455

Epoch: 5| Step: 2
Training loss: 1.5632228705063604
Validation loss: 2.3610027315703777

Epoch: 5| Step: 3
Training loss: 1.7717778846997672
Validation loss: 2.4037364717360434

Epoch: 5| Step: 4
Training loss: 1.1372453970557057
Validation loss: 2.3830613658420514

Epoch: 5| Step: 5
Training loss: 1.971828052669201
Validation loss: 2.3797723293573347

Epoch: 5| Step: 6
Training loss: 1.299239611157121
Validation loss: 2.3716734736502145

Epoch: 5| Step: 7
Training loss: 1.2187611995084628
Validation loss: 2.4150989024262937

Epoch: 5| Step: 8
Training loss: 1.7419197321507744
Validation loss: 2.3352516004966013

Epoch: 5| Step: 9
Training loss: 2.3873304216966695
Validation loss: 2.295335554140072

Epoch: 5| Step: 10
Training loss: 1.8170399862622797
Validation loss: 2.3652379539835726

Epoch: 281| Step: 0
Training loss: 1.2389427367702381
Validation loss: 2.4281664522991386

Epoch: 5| Step: 1
Training loss: 1.113848090171144
Validation loss: 2.4140910979139205

Epoch: 5| Step: 2
Training loss: 1.9190465691716962
Validation loss: 2.4105807133525694

Epoch: 5| Step: 3
Training loss: 1.227648746078647
Validation loss: 2.3943683170228307

Epoch: 5| Step: 4
Training loss: 1.9937568616599513
Validation loss: 2.379372785838351

Epoch: 5| Step: 5
Training loss: 2.0616545822953025
Validation loss: 2.384286895514616

Epoch: 5| Step: 6
Training loss: 1.999951719654984
Validation loss: 2.3869008485091467

Epoch: 5| Step: 7
Training loss: 1.3806214296183392
Validation loss: 2.3763818612096297

Epoch: 5| Step: 8
Training loss: 1.7503425399144883
Validation loss: 2.412350048386892

Epoch: 5| Step: 9
Training loss: 1.6480537437916085
Validation loss: 2.3882431624758387

Epoch: 5| Step: 10
Training loss: 1.6558626549704702
Validation loss: 2.3876484648704164

Epoch: 282| Step: 0
Training loss: 1.8216402507843277
Validation loss: 2.405840105405363

Epoch: 5| Step: 1
Training loss: 1.5046151212117755
Validation loss: 2.423308429864546

Epoch: 5| Step: 2
Training loss: 1.5466269862631556
Validation loss: 2.35943829003949

Epoch: 5| Step: 3
Training loss: 1.214971603093106
Validation loss: 2.372833391704161

Epoch: 5| Step: 4
Training loss: 1.2776215510760798
Validation loss: 2.398008430498227

Epoch: 5| Step: 5
Training loss: 1.900916157241603
Validation loss: 2.4257449074260085

Epoch: 5| Step: 6
Training loss: 2.0051413256525943
Validation loss: 2.405324019681678

Epoch: 5| Step: 7
Training loss: 1.9520403482378845
Validation loss: 2.386047843106487

Epoch: 5| Step: 8
Training loss: 1.715701503472365
Validation loss: 2.327405105950393

Epoch: 5| Step: 9
Training loss: 1.4032825950698513
Validation loss: 2.327312186370514

Epoch: 5| Step: 10
Training loss: 1.816895252977047
Validation loss: 2.3878488847214836

Epoch: 283| Step: 0
Training loss: 2.5849796607215296
Validation loss: 2.316611316126211

Epoch: 5| Step: 1
Training loss: 1.2436377738275903
Validation loss: 2.3797355642423

Epoch: 5| Step: 2
Training loss: 1.0935843751028336
Validation loss: 2.374098972241246

Epoch: 5| Step: 3
Training loss: 1.5469705571416303
Validation loss: 2.388431075068682

Epoch: 5| Step: 4
Training loss: 1.4778077057187742
Validation loss: 2.4259218213489704

Epoch: 5| Step: 5
Training loss: 1.5796042581693548
Validation loss: 2.3958023836152935

Epoch: 5| Step: 6
Training loss: 1.6175009750764198
Validation loss: 2.4014914842269595

Epoch: 5| Step: 7
Training loss: 1.2836940528839444
Validation loss: 2.375719756639803

Epoch: 5| Step: 8
Training loss: 0.8593667463426448
Validation loss: 2.361421880069721

Epoch: 5| Step: 9
Training loss: 2.372109712388924
Validation loss: 2.3747533072094162

Epoch: 5| Step: 10
Training loss: 1.732446990750334
Validation loss: 2.38165279619849

Epoch: 284| Step: 0
Training loss: 1.4134245640097165
Validation loss: 2.3590710694175

Epoch: 5| Step: 1
Training loss: 2.149743920977857
Validation loss: 2.410257702949826

Epoch: 5| Step: 2
Training loss: 1.5745293474124378
Validation loss: 2.406011943870109

Epoch: 5| Step: 3
Training loss: 1.0638660176681998
Validation loss: 2.290825017116753

Epoch: 5| Step: 4
Training loss: 1.6221978897000107
Validation loss: 2.412034988070035

Epoch: 5| Step: 5
Training loss: 1.4747491429260629
Validation loss: 2.364362569671885

Epoch: 5| Step: 6
Training loss: 1.5393331067126539
Validation loss: 2.3722798714107376

Epoch: 5| Step: 7
Training loss: 2.029899147986144
Validation loss: 2.390167204291144

Epoch: 5| Step: 8
Training loss: 1.532189139595376
Validation loss: 2.3330464831349853

Epoch: 5| Step: 9
Training loss: 1.6858908433795516
Validation loss: 2.3795295692282186

Epoch: 5| Step: 10
Training loss: 1.336490717332245
Validation loss: 2.412716070682888

Epoch: 285| Step: 0
Training loss: 1.6868390802358961
Validation loss: 2.3500190520708806

Epoch: 5| Step: 1
Training loss: 1.7555121395655073
Validation loss: 2.3698349721675624

Epoch: 5| Step: 2
Training loss: 1.206105936173928
Validation loss: 2.38509177068558

Epoch: 5| Step: 3
Training loss: 1.4125563888772061
Validation loss: 2.4045491263382965

Epoch: 5| Step: 4
Training loss: 1.6566022822164355
Validation loss: 2.456087807189607

Epoch: 5| Step: 5
Training loss: 1.2950652490475012
Validation loss: 2.403521457448112

Epoch: 5| Step: 6
Training loss: 1.710576825033246
Validation loss: 2.3604283395412025

Epoch: 5| Step: 7
Training loss: 2.436383994475497
Validation loss: 2.492369781009319

Epoch: 5| Step: 8
Training loss: 1.7236590245660943
Validation loss: 2.4289122785907966

Epoch: 5| Step: 9
Training loss: 1.4515998794456804
Validation loss: 2.4265439622790814

Epoch: 5| Step: 10
Training loss: 1.1870746854764134
Validation loss: 2.437500330249479

Epoch: 286| Step: 0
Training loss: 1.4970574126462328
Validation loss: 2.4243698877083166

Epoch: 5| Step: 1
Training loss: 1.8096055564186266
Validation loss: 2.3473368117142046

Epoch: 5| Step: 2
Training loss: 1.5318715138203092
Validation loss: 2.3757080475600185

Epoch: 5| Step: 3
Training loss: 1.7428605357679803
Validation loss: 2.4384443579835735

Epoch: 5| Step: 4
Training loss: 1.7467454210513176
Validation loss: 2.3724360861683502

Epoch: 5| Step: 5
Training loss: 1.4273580115095967
Validation loss: 2.374366183461556

Epoch: 5| Step: 6
Training loss: 2.2075982099829603
Validation loss: 2.36017370256684

Epoch: 5| Step: 7
Training loss: 1.4986034090639462
Validation loss: 2.353974394297597

Epoch: 5| Step: 8
Training loss: 1.3881976770631903
Validation loss: 2.313260960669249

Epoch: 5| Step: 9
Training loss: 1.173219189609764
Validation loss: 2.4042025664953344

Epoch: 5| Step: 10
Training loss: 1.8599311573865538
Validation loss: 2.3645230957297616

Epoch: 287| Step: 0
Training loss: 1.2590894673579907
Validation loss: 2.454814925790124

Epoch: 5| Step: 1
Training loss: 2.4105119489093934
Validation loss: 2.339284628688491

Epoch: 5| Step: 2
Training loss: 1.853978122454534
Validation loss: 2.4158732749440555

Epoch: 5| Step: 3
Training loss: 1.9173011627951386
Validation loss: 2.354807920362813

Epoch: 5| Step: 4
Training loss: 1.4455284163572635
Validation loss: 2.3856377662827057

Epoch: 5| Step: 5
Training loss: 1.6889669611868774
Validation loss: 2.3751146216547463

Epoch: 5| Step: 6
Training loss: 1.9248662481039038
Validation loss: 2.3530533321705605

Epoch: 5| Step: 7
Training loss: 1.3096221526692904
Validation loss: 2.33928626378259

Epoch: 5| Step: 8
Training loss: 1.4299564629709647
Validation loss: 2.375957031730799

Epoch: 5| Step: 9
Training loss: 1.1874615512445883
Validation loss: 2.422856147281229

Epoch: 5| Step: 10
Training loss: 1.1306788377822763
Validation loss: 2.2927503128712146

Epoch: 288| Step: 0
Training loss: 1.1195332369417392
Validation loss: 2.37077739074382

Epoch: 5| Step: 1
Training loss: 1.2360881072248175
Validation loss: 2.3270265154668666

Epoch: 5| Step: 2
Training loss: 1.6424330421630258
Validation loss: 2.416807128875163

Epoch: 5| Step: 3
Training loss: 2.615137920353009
Validation loss: 2.3841987062255194

Epoch: 5| Step: 4
Training loss: 1.5842779336723767
Validation loss: 2.363438722290822

Epoch: 5| Step: 5
Training loss: 1.4605975239968445
Validation loss: 2.398574398177267

Epoch: 5| Step: 6
Training loss: 1.376429898027155
Validation loss: 2.3707040329731615

Epoch: 5| Step: 7
Training loss: 1.6112289120734646
Validation loss: 2.3918721195863424

Epoch: 5| Step: 8
Training loss: 1.7471217600463598
Validation loss: 2.3897338284950314

Epoch: 5| Step: 9
Training loss: 1.3496334002022201
Validation loss: 2.367020234932983

Epoch: 5| Step: 10
Training loss: 1.6539399934190644
Validation loss: 2.317872943588528

Epoch: 289| Step: 0
Training loss: 1.9936610139223363
Validation loss: 2.3614590030434743

Epoch: 5| Step: 1
Training loss: 1.6377857162827245
Validation loss: 2.334521459924825

Epoch: 5| Step: 2
Training loss: 1.4936386960750723
Validation loss: 2.3808144150738

Epoch: 5| Step: 3
Training loss: 1.3706021201837213
Validation loss: 2.429529967930343

Epoch: 5| Step: 4
Training loss: 1.5148958634948761
Validation loss: 2.3009913407602083

Epoch: 5| Step: 5
Training loss: 2.3941066545966545
Validation loss: 2.3722509990991316

Epoch: 5| Step: 6
Training loss: 1.4368030683076887
Validation loss: 2.3428287639860215

Epoch: 5| Step: 7
Training loss: 1.6559043379625389
Validation loss: 2.302683103495196

Epoch: 5| Step: 8
Training loss: 1.8360519698149087
Validation loss: 2.346633860773841

Epoch: 5| Step: 9
Training loss: 0.9295107248681741
Validation loss: 2.3464771530017914

Epoch: 5| Step: 10
Training loss: 1.1829065524846039
Validation loss: 2.3557847426548637

Epoch: 290| Step: 0
Training loss: 1.4983666587209803
Validation loss: 2.35591121468574

Epoch: 5| Step: 1
Training loss: 2.1516458865028283
Validation loss: 2.3838416556176516

Epoch: 5| Step: 2
Training loss: 1.1710404030811654
Validation loss: 2.4183214446502426

Epoch: 5| Step: 3
Training loss: 1.9248469254704177
Validation loss: 2.432428131171618

Epoch: 5| Step: 4
Training loss: 1.8974689163456473
Validation loss: 2.400156954449317

Epoch: 5| Step: 5
Training loss: 1.7749464698564046
Validation loss: 2.386404816617959

Epoch: 5| Step: 6
Training loss: 1.7002241996576695
Validation loss: 2.3919285981276777

Epoch: 5| Step: 7
Training loss: 1.542912735706953
Validation loss: 2.3945663661824557

Epoch: 5| Step: 8
Training loss: 0.991078004238353
Validation loss: 2.371896262014612

Epoch: 5| Step: 9
Training loss: 1.7448784953665195
Validation loss: 2.4019037966515877

Epoch: 5| Step: 10
Training loss: 1.7918155593513303
Validation loss: 2.3784654632832405

Epoch: 291| Step: 0
Training loss: 1.985965721956298
Validation loss: 2.3876825355744735

Epoch: 5| Step: 1
Training loss: 1.606595945397846
Validation loss: 2.3941625059473632

Epoch: 5| Step: 2
Training loss: 1.4054463527351604
Validation loss: 2.3886537434559707

Epoch: 5| Step: 3
Training loss: 1.7367936187270216
Validation loss: 2.3768626725435262

Epoch: 5| Step: 4
Training loss: 2.0182735577695357
Validation loss: 2.3501798313535094

Epoch: 5| Step: 5
Training loss: 1.9146378878464587
Validation loss: 2.3749164994073544

Epoch: 5| Step: 6
Training loss: 1.3499191083338289
Validation loss: 2.4382135962696134

Epoch: 5| Step: 7
Training loss: 1.4263684879335181
Validation loss: 2.413025930257664

Epoch: 5| Step: 8
Training loss: 1.2220247240359299
Validation loss: 2.310695306507386

Epoch: 5| Step: 9
Training loss: 1.4305439036037795
Validation loss: 2.3644196890659654

Epoch: 5| Step: 10
Training loss: 1.630606808778436
Validation loss: 2.3470463745025976

Epoch: 292| Step: 0
Training loss: 2.055466768850302
Validation loss: 2.3723650500850173

Epoch: 5| Step: 1
Training loss: 1.3748614935039403
Validation loss: 2.3799873666487468

Epoch: 5| Step: 2
Training loss: 1.609435145170886
Validation loss: 2.358260765975339

Epoch: 5| Step: 3
Training loss: 1.114599578358755
Validation loss: 2.372200891830921

Epoch: 5| Step: 4
Training loss: 1.5377937935596633
Validation loss: 2.345776890842655

Epoch: 5| Step: 5
Training loss: 1.4249137852337317
Validation loss: 2.3488240097301074

Epoch: 5| Step: 6
Training loss: 1.141002383574822
Validation loss: 2.356344368112983

Epoch: 5| Step: 7
Training loss: 1.6923641461346162
Validation loss: 2.409543935811409

Epoch: 5| Step: 8
Training loss: 1.6561004283233027
Validation loss: 2.3385395940108267

Epoch: 5| Step: 9
Training loss: 1.5910603884799719
Validation loss: 2.3832928734628056

Epoch: 5| Step: 10
Training loss: 1.8347909147173609
Validation loss: 2.3155447945469954

Epoch: 293| Step: 0
Training loss: 1.6101020726136026
Validation loss: 2.4243010586179654

Epoch: 5| Step: 1
Training loss: 1.8881842250936363
Validation loss: 2.383617538541182

Epoch: 5| Step: 2
Training loss: 1.6498534281970902
Validation loss: 2.359871258857574

Epoch: 5| Step: 3
Training loss: 1.7395322948285803
Validation loss: 2.387802765885691

Epoch: 5| Step: 4
Training loss: 1.5761610595634585
Validation loss: 2.3271948087636565

Epoch: 5| Step: 5
Training loss: 1.5118224431238878
Validation loss: 2.40446184760793

Epoch: 5| Step: 6
Training loss: 1.3100070893481668
Validation loss: 2.4019756903242055

Epoch: 5| Step: 7
Training loss: 1.6206746858099998
Validation loss: 2.3832005887274943

Epoch: 5| Step: 8
Training loss: 1.8369940781391447
Validation loss: 2.4118555578518404

Epoch: 5| Step: 9
Training loss: 1.0234080303113404
Validation loss: 2.3518197382229467

Epoch: 5| Step: 10
Training loss: 1.8775951228318586
Validation loss: 2.361324157931361

Epoch: 294| Step: 0
Training loss: 1.4058492301369259
Validation loss: 2.4254045302751073

Epoch: 5| Step: 1
Training loss: 1.0875713763436254
Validation loss: 2.3641815003126467

Epoch: 5| Step: 2
Training loss: 1.892569558642894
Validation loss: 2.3890958116732675

Epoch: 5| Step: 3
Training loss: 1.5173652332675711
Validation loss: 2.385570130169814

Epoch: 5| Step: 4
Training loss: 1.365040035359348
Validation loss: 2.430172473546605

Epoch: 5| Step: 5
Training loss: 1.5589134251778407
Validation loss: 2.394376289412148

Epoch: 5| Step: 6
Training loss: 1.6732141710814368
Validation loss: 2.43222466001662

Epoch: 5| Step: 7
Training loss: 1.4126901447966884
Validation loss: 2.351299486628165

Epoch: 5| Step: 8
Training loss: 1.4968911379141334
Validation loss: 2.3772575775355245

Epoch: 5| Step: 9
Training loss: 2.3198260173015814
Validation loss: 2.349551642416331

Epoch: 5| Step: 10
Training loss: 1.5336369963585683
Validation loss: 2.4132131050005916

Epoch: 295| Step: 0
Training loss: 1.6983746416098982
Validation loss: 2.4848749451396794

Epoch: 5| Step: 1
Training loss: 1.9882943203539578
Validation loss: 2.3197249381974463

Epoch: 5| Step: 2
Training loss: 1.6902738308692864
Validation loss: 2.3834546350092545

Epoch: 5| Step: 3
Training loss: 1.3470110689542436
Validation loss: 2.3445276218680413

Epoch: 5| Step: 4
Training loss: 1.966515984123752
Validation loss: 2.3095706577123427

Epoch: 5| Step: 5
Training loss: 1.373147583655531
Validation loss: 2.422646753704891

Epoch: 5| Step: 6
Training loss: 1.1589599503944679
Validation loss: 2.4302865141897785

Epoch: 5| Step: 7
Training loss: 1.5613413520273711
Validation loss: 2.32441182088205

Epoch: 5| Step: 8
Training loss: 1.259825428570813
Validation loss: 2.4070247345303755

Epoch: 5| Step: 9
Training loss: 1.6218188766735764
Validation loss: 2.468000101569961

Epoch: 5| Step: 10
Training loss: 1.7765187790723886
Validation loss: 2.4156225919038263

Epoch: 296| Step: 0
Training loss: 1.9797183690001567
Validation loss: 2.3647983011144293

Epoch: 5| Step: 1
Training loss: 1.435006508363858
Validation loss: 2.376914351146371

Epoch: 5| Step: 2
Training loss: 2.274422972724335
Validation loss: 2.4363014760106814

Epoch: 5| Step: 3
Training loss: 1.5463366872284168
Validation loss: 2.3657309890441662

Epoch: 5| Step: 4
Training loss: 1.210510276987159
Validation loss: 2.444189190083749

Epoch: 5| Step: 5
Training loss: 1.6295822533831736
Validation loss: 2.4022035779459654

Epoch: 5| Step: 6
Training loss: 1.2008190101935885
Validation loss: 2.3915121973885816

Epoch: 5| Step: 7
Training loss: 1.3733146916361865
Validation loss: 2.3463690624811537

Epoch: 5| Step: 8
Training loss: 1.5328421586926608
Validation loss: 2.3660115961849866

Epoch: 5| Step: 9
Training loss: 1.028032949205323
Validation loss: 2.449651371509352

Epoch: 5| Step: 10
Training loss: 1.6970438049543206
Validation loss: 2.3980857845363115

Epoch: 297| Step: 0
Training loss: 2.139358034192013
Validation loss: 2.423739887287467

Epoch: 5| Step: 1
Training loss: 1.4248122175199411
Validation loss: 2.4005174307224517

Epoch: 5| Step: 2
Training loss: 1.1007532705050056
Validation loss: 2.367930564756942

Epoch: 5| Step: 3
Training loss: 1.42938913035612
Validation loss: 2.33889953986873

Epoch: 5| Step: 4
Training loss: 1.8722367588287596
Validation loss: 2.30957630986336

Epoch: 5| Step: 5
Training loss: 1.4128478086194352
Validation loss: 2.4276825448022024

Epoch: 5| Step: 6
Training loss: 1.437353624272011
Validation loss: 2.3489809232756556

Epoch: 5| Step: 7
Training loss: 1.172899688317759
Validation loss: 2.3523929917209276

Epoch: 5| Step: 8
Training loss: 1.424749800819106
Validation loss: 2.38504687119537

Epoch: 5| Step: 9
Training loss: 1.7773655481364183
Validation loss: 2.3767427614315553

Epoch: 5| Step: 10
Training loss: 1.5178052027815356
Validation loss: 2.3884614498221297

Epoch: 298| Step: 0
Training loss: 1.3512793007213737
Validation loss: 2.362778272862958

Epoch: 5| Step: 1
Training loss: 1.7581170390491627
Validation loss: 2.4094313345403697

Epoch: 5| Step: 2
Training loss: 1.5240596967854785
Validation loss: 2.305793368134703

Epoch: 5| Step: 3
Training loss: 1.603931071167879
Validation loss: 2.3626221910320306

Epoch: 5| Step: 4
Training loss: 1.6601506491173903
Validation loss: 2.3576343072042896

Epoch: 5| Step: 5
Training loss: 1.3701023527879854
Validation loss: 2.4233308108913114

Epoch: 5| Step: 6
Training loss: 2.13052670463293
Validation loss: 2.4119094521997253

Epoch: 5| Step: 7
Training loss: 1.5275697662853702
Validation loss: 2.4637062406112307

Epoch: 5| Step: 8
Training loss: 1.3511984450591623
Validation loss: 2.3932709875986093

Epoch: 5| Step: 9
Training loss: 1.8546796224887994
Validation loss: 2.412095628433278

Epoch: 5| Step: 10
Training loss: 1.2120516665874508
Validation loss: 2.372780253144298

Epoch: 299| Step: 0
Training loss: 1.4326746850414331
Validation loss: 2.4372427977946054

Epoch: 5| Step: 1
Training loss: 1.0326512959725522
Validation loss: 2.299046311941884

Epoch: 5| Step: 2
Training loss: 1.3870822913518406
Validation loss: 2.3839732505503823

Epoch: 5| Step: 3
Training loss: 1.4019123997251008
Validation loss: 2.4015476756971013

Epoch: 5| Step: 4
Training loss: 1.8361109874813148
Validation loss: 2.288372308266688

Epoch: 5| Step: 5
Training loss: 1.9000797782010213
Validation loss: 2.348545491566877

Epoch: 5| Step: 6
Training loss: 1.6852854573495573
Validation loss: 2.4085518117031293

Epoch: 5| Step: 7
Training loss: 2.070536360243837
Validation loss: 2.3528340315981904

Epoch: 5| Step: 8
Training loss: 1.3351351464547347
Validation loss: 2.330918345791521

Epoch: 5| Step: 9
Training loss: 1.586202965678616
Validation loss: 2.4358782025591283

Epoch: 5| Step: 10
Training loss: 1.2094161783152255
Validation loss: 2.4216972653698066

Epoch: 300| Step: 0
Training loss: 1.0209981953887983
Validation loss: 2.35610216347784

Epoch: 5| Step: 1
Training loss: 1.3095142372409019
Validation loss: 2.408795280945172

Epoch: 5| Step: 2
Training loss: 1.5102347253419457
Validation loss: 2.3723149403628327

Epoch: 5| Step: 3
Training loss: 1.9602247667862023
Validation loss: 2.364388658486608

Epoch: 5| Step: 4
Training loss: 1.8064178494405285
Validation loss: 2.371300512970444

Epoch: 5| Step: 5
Training loss: 2.13045855282958
Validation loss: 2.4399845070618555

Epoch: 5| Step: 6
Training loss: 1.2817189823695911
Validation loss: 2.3430007491702263

Epoch: 5| Step: 7
Training loss: 1.4099869137691037
Validation loss: 2.3973459021235066

Epoch: 5| Step: 8
Training loss: 1.6963896252169852
Validation loss: 2.402914581523534

Epoch: 5| Step: 9
Training loss: 1.4586141134351578
Validation loss: 2.3562742210543126

Epoch: 5| Step: 10
Training loss: 1.635655096212297
Validation loss: 2.4311016003414414

Testing loss: 2.743423226955197
