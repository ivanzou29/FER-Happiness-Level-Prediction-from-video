Epoch: 1| Step: 0
Training loss: 3.203534355987948
Validation loss: 3.670288419005622

Epoch: 5| Step: 1
Training loss: 3.1556882452789283
Validation loss: 3.666387552021156

Epoch: 5| Step: 2
Training loss: 5.067144076960876
Validation loss: 3.662828606007534

Epoch: 5| Step: 3
Training loss: 4.221316764739586
Validation loss: 3.653852281153869

Epoch: 5| Step: 4
Training loss: 3.811616138500869
Validation loss: 3.653039420653814

Epoch: 5| Step: 5
Training loss: 3.626328849579554
Validation loss: 3.6499343594211386

Epoch: 5| Step: 6
Training loss: 3.5923903837317597
Validation loss: 3.6445185799548767

Epoch: 5| Step: 7
Training loss: 4.639477314941779
Validation loss: 3.63825927467871

Epoch: 5| Step: 8
Training loss: 3.8700379626558523
Validation loss: 3.631889593871906

Epoch: 5| Step: 9
Training loss: 3.280109316237013
Validation loss: 3.6308654231900084

Epoch: 5| Step: 10
Training loss: 3.1964386911681077
Validation loss: 3.6264499724802843

Epoch: 2| Step: 0
Training loss: 3.997483415503629
Validation loss: 3.622665468251305

Epoch: 5| Step: 1
Training loss: 4.306425377273975
Validation loss: 3.615370377702087

Epoch: 5| Step: 2
Training loss: 2.902509682020653
Validation loss: 3.6122829409089436

Epoch: 5| Step: 3
Training loss: 4.150020663658081
Validation loss: 3.604813302865379

Epoch: 5| Step: 4
Training loss: 3.1074111334077386
Validation loss: 3.6001296334529203

Epoch: 5| Step: 5
Training loss: 3.313773000573306
Validation loss: 3.598159865062718

Epoch: 5| Step: 6
Training loss: 4.34826535245003
Validation loss: 3.594822316741783

Epoch: 5| Step: 7
Training loss: 3.5348601665114776
Validation loss: 3.589190540771499

Epoch: 5| Step: 8
Training loss: 3.5196762139783706
Validation loss: 3.5823164744566376

Epoch: 5| Step: 9
Training loss: 4.092441961381418
Validation loss: 3.580775022807853

Epoch: 5| Step: 10
Training loss: 4.20636791500422
Validation loss: 3.5754119321343247

Epoch: 3| Step: 0
Training loss: 4.262597431400556
Validation loss: 3.5714904087180406

Epoch: 5| Step: 1
Training loss: 3.194026175127164
Validation loss: 3.567589659394143

Epoch: 5| Step: 2
Training loss: 3.0285105173458318
Validation loss: 3.562903549230419

Epoch: 5| Step: 3
Training loss: 3.867209941143852
Validation loss: 3.5543562648115574

Epoch: 5| Step: 4
Training loss: 4.06908505139885
Validation loss: 3.551751860574359

Epoch: 5| Step: 5
Training loss: 3.56839772638634
Validation loss: 3.5485638241652544

Epoch: 5| Step: 6
Training loss: 3.5464315935499857
Validation loss: 3.542060315274503

Epoch: 5| Step: 7
Training loss: 4.100633265273735
Validation loss: 3.5393933382854477

Epoch: 5| Step: 8
Training loss: 3.8207784107272427
Validation loss: 3.5349258441134874

Epoch: 5| Step: 9
Training loss: 3.684684066169102
Validation loss: 3.529025597697364

Epoch: 5| Step: 10
Training loss: 3.942240691912866
Validation loss: 3.522901987603967

Epoch: 4| Step: 0
Training loss: 3.374078695504453
Validation loss: 3.5230572055550913

Epoch: 5| Step: 1
Training loss: 3.4795278182816416
Validation loss: 3.513967350845474

Epoch: 5| Step: 2
Training loss: 2.744946083970731
Validation loss: 3.5122500245454797

Epoch: 5| Step: 3
Training loss: 4.662955352392751
Validation loss: 3.5041763172868103

Epoch: 5| Step: 4
Training loss: 3.0737344634232384
Validation loss: 3.498942533326578

Epoch: 5| Step: 5
Training loss: 3.0149345595816124
Validation loss: 3.493555662482596

Epoch: 5| Step: 6
Training loss: 3.6645434619035
Validation loss: 3.4920318921952767

Epoch: 5| Step: 7
Training loss: 3.42740786483547
Validation loss: 3.4862252404267897

Epoch: 5| Step: 8
Training loss: 4.506796261167444
Validation loss: 3.480870538088526

Epoch: 5| Step: 9
Training loss: 4.025847607566708
Validation loss: 3.4759854077281007

Epoch: 5| Step: 10
Training loss: 4.299453904716758
Validation loss: 3.471579529434224

Epoch: 5| Step: 0
Training loss: 3.981140139993821
Validation loss: 3.4668316882504464

Epoch: 5| Step: 1
Training loss: 3.63287799735143
Validation loss: 3.4613648530416516

Epoch: 5| Step: 2
Training loss: 3.874030453382543
Validation loss: 3.453820620245217

Epoch: 5| Step: 3
Training loss: 3.6569622682789893
Validation loss: 3.4492329698784974

Epoch: 5| Step: 4
Training loss: 3.845273344049042
Validation loss: 3.442227781853251

Epoch: 5| Step: 5
Training loss: 3.674677651728953
Validation loss: 3.43704019866541

Epoch: 5| Step: 6
Training loss: 3.1514290731741164
Validation loss: 3.430387348319553

Epoch: 5| Step: 7
Training loss: 3.8556115955918084
Validation loss: 3.423090704330384

Epoch: 5| Step: 8
Training loss: 3.1421439829373314
Validation loss: 3.4167788857540047

Epoch: 5| Step: 9
Training loss: 3.8037200888448965
Validation loss: 3.414097188685736

Epoch: 5| Step: 10
Training loss: 3.4469206294258536
Validation loss: 3.4055482582382086

Epoch: 6| Step: 0
Training loss: 3.8587502657312833
Validation loss: 3.403975506433322

Epoch: 5| Step: 1
Training loss: 3.0019432767608465
Validation loss: 3.3965639759846336

Epoch: 5| Step: 2
Training loss: 3.4864592882802246
Validation loss: 3.39100542840996

Epoch: 5| Step: 3
Training loss: 3.8361590101999274
Validation loss: 3.3863603199025953

Epoch: 5| Step: 4
Training loss: 2.6312196707166824
Validation loss: 3.379972807310099

Epoch: 5| Step: 5
Training loss: 2.568695487304839
Validation loss: 3.372082616479605

Epoch: 5| Step: 6
Training loss: 3.7989267841462424
Validation loss: 3.3713731682386157

Epoch: 5| Step: 7
Training loss: 4.384386510963039
Validation loss: 3.3616528857623313

Epoch: 5| Step: 8
Training loss: 3.106258498243531
Validation loss: 3.357858673627077

Epoch: 5| Step: 9
Training loss: 4.266455936194954
Validation loss: 3.3492006014485267

Epoch: 5| Step: 10
Training loss: 4.141800393312898
Validation loss: 3.345106847629766

Epoch: 7| Step: 0
Training loss: 3.393719785777105
Validation loss: 3.339990812972679

Epoch: 5| Step: 1
Training loss: 4.004454992884683
Validation loss: 3.330296066860961

Epoch: 5| Step: 2
Training loss: 3.7574354843113684
Validation loss: 3.328829994002778

Epoch: 5| Step: 3
Training loss: 3.3334246781866907
Validation loss: 3.3192696727786064

Epoch: 5| Step: 4
Training loss: 2.7929043849117496
Validation loss: 3.3147591726649823

Epoch: 5| Step: 5
Training loss: 3.584221456310418
Validation loss: 3.3075387136548904

Epoch: 5| Step: 6
Training loss: 3.542564293298819
Validation loss: 3.302859408873302

Epoch: 5| Step: 7
Training loss: 3.7886114422247434
Validation loss: 3.2943090568029554

Epoch: 5| Step: 8
Training loss: 3.238058305711391
Validation loss: 3.288917852244362

Epoch: 5| Step: 9
Training loss: 3.3282252909991663
Validation loss: 3.285921890449293

Epoch: 5| Step: 10
Training loss: 4.058937976033403
Validation loss: 3.2786412366796904

Epoch: 8| Step: 0
Training loss: 3.622777586437773
Validation loss: 3.2684889595970357

Epoch: 5| Step: 1
Training loss: 4.102775583257299
Validation loss: 3.266605266770848

Epoch: 5| Step: 2
Training loss: 3.6829202952609656
Validation loss: 3.257993891226801

Epoch: 5| Step: 3
Training loss: 3.05275389993956
Validation loss: 3.249199892604122

Epoch: 5| Step: 4
Training loss: 3.8032280161187195
Validation loss: 3.2425654215148225

Epoch: 5| Step: 5
Training loss: 3.231493122096462
Validation loss: 3.2343065261429014

Epoch: 5| Step: 6
Training loss: 2.6681683802166587
Validation loss: 3.2294915048133572

Epoch: 5| Step: 7
Training loss: 3.3804499104386774
Validation loss: 3.2222287424672422

Epoch: 5| Step: 8
Training loss: 4.026912751246585
Validation loss: 3.2162871949926144

Epoch: 5| Step: 9
Training loss: 2.9091606741364244
Validation loss: 3.208631753859861

Epoch: 5| Step: 10
Training loss: 3.492218904972743
Validation loss: 3.1998738226189554

Epoch: 9| Step: 0
Training loss: 2.8091451345060032
Validation loss: 3.1995852268245124

Epoch: 5| Step: 1
Training loss: 2.9062700168371487
Validation loss: 3.1932482698556606

Epoch: 5| Step: 2
Training loss: 3.6397174801021217
Validation loss: 3.183952717461375

Epoch: 5| Step: 3
Training loss: 3.667305558347787
Validation loss: 3.1770102374327225

Epoch: 5| Step: 4
Training loss: 3.822261882423436
Validation loss: 3.1746130145719316

Epoch: 5| Step: 5
Training loss: 3.850646863818653
Validation loss: 3.1669038695616902

Epoch: 5| Step: 6
Training loss: 3.0322959117975445
Validation loss: 3.1633735484974177

Epoch: 5| Step: 7
Training loss: 2.9826057342435295
Validation loss: 3.1486278132290524

Epoch: 5| Step: 8
Training loss: 3.7484717751924
Validation loss: 3.145444505459572

Epoch: 5| Step: 9
Training loss: 3.2152415292526104
Validation loss: 3.1341063948052184

Epoch: 5| Step: 10
Training loss: 3.633081176010513
Validation loss: 3.1303256769083574

Epoch: 10| Step: 0
Training loss: 3.9327703256206092
Validation loss: 3.121295444439371

Epoch: 5| Step: 1
Training loss: 3.3600326958836617
Validation loss: 3.1139017884151614

Epoch: 5| Step: 2
Training loss: 3.560862784043309
Validation loss: 3.105985944280913

Epoch: 5| Step: 3
Training loss: 3.6091332292707037
Validation loss: 3.0966669383134384

Epoch: 5| Step: 4
Training loss: 2.5387374904668087
Validation loss: 3.0928721263275163

Epoch: 5| Step: 5
Training loss: 4.054670800558699
Validation loss: 3.0834044093814534

Epoch: 5| Step: 6
Training loss: 3.1168867458491647
Validation loss: 3.0789017251955424

Epoch: 5| Step: 7
Training loss: 2.7518669206967212
Validation loss: 3.0726859585750517

Epoch: 5| Step: 8
Training loss: 2.907783841868703
Validation loss: 3.0627929826948708

Epoch: 5| Step: 9
Training loss: 3.3003566491419747
Validation loss: 3.0545051998051687

Epoch: 5| Step: 10
Training loss: 3.3937343983440877
Validation loss: 3.051345378716571

Epoch: 11| Step: 0
Training loss: 3.3067934797437504
Validation loss: 3.041277457798199

Epoch: 5| Step: 1
Training loss: 3.7199815265648026
Validation loss: 3.036670741902729

Epoch: 5| Step: 2
Training loss: 3.2244498145808516
Validation loss: 3.02730771893122

Epoch: 5| Step: 3
Training loss: 3.4265919403606593
Validation loss: 3.0201542326835424

Epoch: 5| Step: 4
Training loss: 3.433638883777951
Validation loss: 3.010741788998959

Epoch: 5| Step: 5
Training loss: 3.11842784249729
Validation loss: 2.9995315555188347

Epoch: 5| Step: 6
Training loss: 2.7416474334907925
Validation loss: 2.9955345062163508

Epoch: 5| Step: 7
Training loss: 2.600085231411041
Validation loss: 2.9856965447749273

Epoch: 5| Step: 8
Training loss: 3.6501242681800217
Validation loss: 2.978570315785018

Epoch: 5| Step: 9
Training loss: 3.1755434066840236
Validation loss: 2.971902422458575

Epoch: 5| Step: 10
Training loss: 3.5381356682521385
Validation loss: 2.966515050087583

Epoch: 12| Step: 0
Training loss: 3.5391440140050356
Validation loss: 2.9581964459105685

Epoch: 5| Step: 1
Training loss: 2.827671920986736
Validation loss: 2.9472732873840113

Epoch: 5| Step: 2
Training loss: 2.9280019565325595
Validation loss: 2.9435361948742713

Epoch: 5| Step: 3
Training loss: 3.3648310866337923
Validation loss: 2.9379312918206377

Epoch: 5| Step: 4
Training loss: 3.009279205603939
Validation loss: 2.927469047631529

Epoch: 5| Step: 5
Training loss: 3.4983421213864436
Validation loss: 2.9253864107066865

Epoch: 5| Step: 6
Training loss: 2.955952254739546
Validation loss: 2.9166610969689506

Epoch: 5| Step: 7
Training loss: 3.3543177663441943
Validation loss: 2.9103203817990617

Epoch: 5| Step: 8
Training loss: 3.140781987000716
Validation loss: 2.900770573295495

Epoch: 5| Step: 9
Training loss: 3.0451588027710867
Validation loss: 2.8913255493933105

Epoch: 5| Step: 10
Training loss: 3.5522671350858777
Validation loss: 2.8890694780544477

Epoch: 13| Step: 0
Training loss: 2.951707933921114
Validation loss: 2.881374774850864

Epoch: 5| Step: 1
Training loss: 3.123159705933574
Validation loss: 2.8668211261701777

Epoch: 5| Step: 2
Training loss: 3.3339037089318713
Validation loss: 2.85807653538971

Epoch: 5| Step: 3
Training loss: 3.3733506587743323
Validation loss: 2.852519720131811

Epoch: 5| Step: 4
Training loss: 2.329044646841271
Validation loss: 2.8497006930378816

Epoch: 5| Step: 5
Training loss: 3.226378502575655
Validation loss: 2.8397836638906044

Epoch: 5| Step: 6
Training loss: 2.987496386410112
Validation loss: 2.829146506251739

Epoch: 5| Step: 7
Training loss: 3.2826536536879427
Validation loss: 2.823997502848844

Epoch: 5| Step: 8
Training loss: 3.3850310277150713
Validation loss: 2.8127935759937768

Epoch: 5| Step: 9
Training loss: 3.029894024094112
Validation loss: 2.8065726072966344

Epoch: 5| Step: 10
Training loss: 3.3872579565532646
Validation loss: 2.795972445535801

Epoch: 14| Step: 0
Training loss: 2.7743917193750094
Validation loss: 2.791067991926023

Epoch: 5| Step: 1
Training loss: 3.1680257959086258
Validation loss: 2.782335720907558

Epoch: 5| Step: 2
Training loss: 2.913896244000596
Validation loss: 2.7746021922383135

Epoch: 5| Step: 3
Training loss: 2.9920888540874575
Validation loss: 2.768142689737991

Epoch: 5| Step: 4
Training loss: 3.3502916180664672
Validation loss: 2.765508054264477

Epoch: 5| Step: 5
Training loss: 3.1272526060912775
Validation loss: 2.765059890608765

Epoch: 5| Step: 6
Training loss: 2.6432307100839605
Validation loss: 2.7514524753840433

Epoch: 5| Step: 7
Training loss: 3.146444972790224
Validation loss: 2.745864861659148

Epoch: 5| Step: 8
Training loss: 3.24045304933829
Validation loss: 2.738528048673606

Epoch: 5| Step: 9
Training loss: 3.2846359947738595
Validation loss: 2.7322538440690782

Epoch: 5| Step: 10
Training loss: 3.1002884945912412
Validation loss: 2.7277896675906295

Epoch: 15| Step: 0
Training loss: 3.1730523390806855
Validation loss: 2.7221360648844364

Epoch: 5| Step: 1
Training loss: 2.79880725456171
Validation loss: 2.7097102852726254

Epoch: 5| Step: 2
Training loss: 3.043330238427061
Validation loss: 2.7029170688329063

Epoch: 5| Step: 3
Training loss: 3.2324286607745996
Validation loss: 2.6910554795490937

Epoch: 5| Step: 4
Training loss: 2.227888816524825
Validation loss: 2.6856055922069504

Epoch: 5| Step: 5
Training loss: 3.3541421988090403
Validation loss: 2.676891273250885

Epoch: 5| Step: 6
Training loss: 3.207292330077845
Validation loss: 2.6645023717884877

Epoch: 5| Step: 7
Training loss: 2.796842947834847
Validation loss: 2.667739486687012

Epoch: 5| Step: 8
Training loss: 3.271237309933786
Validation loss: 2.6614799960185764

Epoch: 5| Step: 9
Training loss: 2.9367496262551174
Validation loss: 2.653990711369528

Epoch: 5| Step: 10
Training loss: 3.0169937111065455
Validation loss: 2.6481359447284722

Epoch: 16| Step: 0
Training loss: 2.476599467389711
Validation loss: 2.6400247799315406

Epoch: 5| Step: 1
Training loss: 3.6014823987414992
Validation loss: 2.636816965428908

Epoch: 5| Step: 2
Training loss: 2.8961040635564603
Validation loss: 2.627317973619728

Epoch: 5| Step: 3
Training loss: 3.11806068523828
Validation loss: 2.6223189095033868

Epoch: 5| Step: 4
Training loss: 3.0869009324795895
Validation loss: 2.6176699428032366

Epoch: 5| Step: 5
Training loss: 2.7005664866949783
Validation loss: 2.6089055444237017

Epoch: 5| Step: 6
Training loss: 3.103008557734735
Validation loss: 2.6011101375222316

Epoch: 5| Step: 7
Training loss: 3.0248896933376517
Validation loss: 2.592768703294384

Epoch: 5| Step: 8
Training loss: 2.9538938137177047
Validation loss: 2.5920013689054993

Epoch: 5| Step: 9
Training loss: 2.8740347195454743
Validation loss: 2.5827307744317443

Epoch: 5| Step: 10
Training loss: 2.7894961236412956
Validation loss: 2.5751960033859898

Epoch: 17| Step: 0
Training loss: 2.856724245195174
Validation loss: 2.5758043730321427

Epoch: 5| Step: 1
Training loss: 3.2627936687790133
Validation loss: 2.567168095932605

Epoch: 5| Step: 2
Training loss: 3.2797585140280305
Validation loss: 2.5667735224842105

Epoch: 5| Step: 3
Training loss: 2.3808876142321385
Validation loss: 2.5594061966782635

Epoch: 5| Step: 4
Training loss: 2.735415015664417
Validation loss: 2.5612887369277386

Epoch: 5| Step: 5
Training loss: 2.7066970773062766
Validation loss: 2.5595278006509483

Epoch: 5| Step: 6
Training loss: 3.0858421600679815
Validation loss: 2.5497434754080484

Epoch: 5| Step: 7
Training loss: 2.685665924207889
Validation loss: 2.5511440762848725

Epoch: 5| Step: 8
Training loss: 3.4414030631458714
Validation loss: 2.541666462247838

Epoch: 5| Step: 9
Training loss: 2.8851416464796777
Validation loss: 2.5434688558178364

Epoch: 5| Step: 10
Training loss: 2.686380197415004
Validation loss: 2.5381828527315538

Epoch: 18| Step: 0
Training loss: 2.819760847163989
Validation loss: 2.5326962751858564

Epoch: 5| Step: 1
Training loss: 3.4125524887128424
Validation loss: 2.534673049666311

Epoch: 5| Step: 2
Training loss: 2.851270352382511
Validation loss: 2.52847003795646

Epoch: 5| Step: 3
Training loss: 2.4625136399254415
Validation loss: 2.5180401854853898

Epoch: 5| Step: 4
Training loss: 2.92042056516965
Validation loss: 2.523006998712011

Epoch: 5| Step: 5
Training loss: 2.5488241962972595
Validation loss: 2.5174442154676195

Epoch: 5| Step: 6
Training loss: 3.2976789172310124
Validation loss: 2.505925979312888

Epoch: 5| Step: 7
Training loss: 2.702625559272918
Validation loss: 2.507650875219137

Epoch: 5| Step: 8
Training loss: 3.0790493734179245
Validation loss: 2.4974447933317783

Epoch: 5| Step: 9
Training loss: 3.10519158428034
Validation loss: 2.5034969780455496

Epoch: 5| Step: 10
Training loss: 2.652551027718577
Validation loss: 2.503264952159692

Epoch: 19| Step: 0
Training loss: 2.5316199515048505
Validation loss: 2.500749352652065

Epoch: 5| Step: 1
Training loss: 2.6810728001227617
Validation loss: 2.4949698038518218

Epoch: 5| Step: 2
Training loss: 2.9580988903009655
Validation loss: 2.5004875692096005

Epoch: 5| Step: 3
Training loss: 2.8080589835827063
Validation loss: 2.4919982106885747

Epoch: 5| Step: 4
Training loss: 2.903513943309751
Validation loss: 2.494535248835558

Epoch: 5| Step: 5
Training loss: 3.0059369469461785
Validation loss: 2.494767716689062

Epoch: 5| Step: 6
Training loss: 2.6677447960886562
Validation loss: 2.4884710584802483

Epoch: 5| Step: 7
Training loss: 2.5983590229453633
Validation loss: 2.4893176375989703

Epoch: 5| Step: 8
Training loss: 3.454392282612861
Validation loss: 2.484632877384183

Epoch: 5| Step: 9
Training loss: 2.9453426126817743
Validation loss: 2.4829743112232983

Epoch: 5| Step: 10
Training loss: 3.2341861393286693
Validation loss: 2.4808882871655022

Epoch: 20| Step: 0
Training loss: 2.7146085568649476
Validation loss: 2.4816046006401327

Epoch: 5| Step: 1
Training loss: 2.95569268874907
Validation loss: 2.483408841112975

Epoch: 5| Step: 2
Training loss: 2.9816682534154086
Validation loss: 2.4759192761859143

Epoch: 5| Step: 3
Training loss: 3.2319592285983845
Validation loss: 2.4828091262685734

Epoch: 5| Step: 4
Training loss: 2.789098060872737
Validation loss: 2.4712319826839093

Epoch: 5| Step: 5
Training loss: 2.357713227808102
Validation loss: 2.4752502401495016

Epoch: 5| Step: 6
Training loss: 2.9800202718467665
Validation loss: 2.479078747486506

Epoch: 5| Step: 7
Training loss: 2.8998766511137686
Validation loss: 2.478823580070397

Epoch: 5| Step: 8
Training loss: 2.956192925771233
Validation loss: 2.470094813212311

Epoch: 5| Step: 9
Training loss: 3.0347284238874637
Validation loss: 2.473575229137364

Epoch: 5| Step: 10
Training loss: 2.729880601137358
Validation loss: 2.468253080867522

Epoch: 21| Step: 0
Training loss: 2.8017265820682296
Validation loss: 2.465270277415637

Epoch: 5| Step: 1
Training loss: 2.968452197748413
Validation loss: 2.473172781317201

Epoch: 5| Step: 2
Training loss: 2.4576454062146533
Validation loss: 2.4674421132376314

Epoch: 5| Step: 3
Training loss: 3.480860558579083
Validation loss: 2.461593458731275

Epoch: 5| Step: 4
Training loss: 2.698268872300639
Validation loss: 2.4743771444758758

Epoch: 5| Step: 5
Training loss: 2.913353882403614
Validation loss: 2.476259504365438

Epoch: 5| Step: 6
Training loss: 3.0596271975939873
Validation loss: 2.464652497426434

Epoch: 5| Step: 7
Training loss: 2.780912314499297
Validation loss: 2.4769498248457307

Epoch: 5| Step: 8
Training loss: 3.0083650948352734
Validation loss: 2.4729022259612

Epoch: 5| Step: 9
Training loss: 2.77049163394113
Validation loss: 2.4736346945778895

Epoch: 5| Step: 10
Training loss: 2.5733383595050223
Validation loss: 2.4579339333003816

Epoch: 22| Step: 0
Training loss: 2.656442164033637
Validation loss: 2.465245537491934

Epoch: 5| Step: 1
Training loss: 2.71411667562735
Validation loss: 2.462931165920768

Epoch: 5| Step: 2
Training loss: 2.495574085185298
Validation loss: 2.4654048329627964

Epoch: 5| Step: 3
Training loss: 2.9632968008094465
Validation loss: 2.4597482042366776

Epoch: 5| Step: 4
Training loss: 3.256782643398287
Validation loss: 2.4580601254820897

Epoch: 5| Step: 5
Training loss: 2.686340969244141
Validation loss: 2.455063157110989

Epoch: 5| Step: 6
Training loss: 3.1383555549027995
Validation loss: 2.4541403327809177

Epoch: 5| Step: 7
Training loss: 2.767731290144656
Validation loss: 2.4654546519872658

Epoch: 5| Step: 8
Training loss: 3.076176215274716
Validation loss: 2.454400203415441

Epoch: 5| Step: 9
Training loss: 2.7523721520774576
Validation loss: 2.462800483907835

Epoch: 5| Step: 10
Training loss: 3.0430491367049726
Validation loss: 2.462208045020896

Epoch: 23| Step: 0
Training loss: 3.3496705875419965
Validation loss: 2.459860155662888

Epoch: 5| Step: 1
Training loss: 2.9110912075607995
Validation loss: 2.45378430825039

Epoch: 5| Step: 2
Training loss: 2.549907540533773
Validation loss: 2.4530563245599475

Epoch: 5| Step: 3
Training loss: 2.5049795150680665
Validation loss: 2.4526840314202434

Epoch: 5| Step: 4
Training loss: 2.92486191122026
Validation loss: 2.4528504560202595

Epoch: 5| Step: 5
Training loss: 3.0322496791087437
Validation loss: 2.4533381905375

Epoch: 5| Step: 6
Training loss: 3.014619966155641
Validation loss: 2.4557291680585904

Epoch: 5| Step: 7
Training loss: 2.2365779020923204
Validation loss: 2.445841702397678

Epoch: 5| Step: 8
Training loss: 3.072952649611668
Validation loss: 2.45564646239022

Epoch: 5| Step: 9
Training loss: 3.044162892999685
Validation loss: 2.450338334991418

Epoch: 5| Step: 10
Training loss: 2.728011131750535
Validation loss: 2.449601225327965

Epoch: 24| Step: 0
Training loss: 3.117085467129063
Validation loss: 2.452212157894818

Epoch: 5| Step: 1
Training loss: 3.0273757243775163
Validation loss: 2.451311342757249

Epoch: 5| Step: 2
Training loss: 3.098670976068955
Validation loss: 2.4519410937799035

Epoch: 5| Step: 3
Training loss: 2.905251280115087
Validation loss: 2.4617358861806817

Epoch: 5| Step: 4
Training loss: 2.6521301632982066
Validation loss: 2.4484872907387665

Epoch: 5| Step: 5
Training loss: 2.824253361702244
Validation loss: 2.449436343525235

Epoch: 5| Step: 6
Training loss: 2.7143814242131263
Validation loss: 2.452339470361904

Epoch: 5| Step: 7
Training loss: 2.247924165003176
Validation loss: 2.4492012341632474

Epoch: 5| Step: 8
Training loss: 2.7074483354734236
Validation loss: 2.444324620828643

Epoch: 5| Step: 9
Training loss: 3.1345558547901673
Validation loss: 2.4505033512142904

Epoch: 5| Step: 10
Training loss: 3.0328305243418865
Validation loss: 2.4520736060015484

Epoch: 25| Step: 0
Training loss: 2.531982598430262
Validation loss: 2.4540132735762294

Epoch: 5| Step: 1
Training loss: 3.1428708069987326
Validation loss: 2.454527592482654

Epoch: 5| Step: 2
Training loss: 2.7827848849674703
Validation loss: 2.442771653845977

Epoch: 5| Step: 3
Training loss: 3.26251130668464
Validation loss: 2.449205770666034

Epoch: 5| Step: 4
Training loss: 2.837710328226154
Validation loss: 2.4572394839849196

Epoch: 5| Step: 5
Training loss: 2.9969796235057213
Validation loss: 2.4482769542369067

Epoch: 5| Step: 6
Training loss: 2.7979422296609378
Validation loss: 2.451125299265922

Epoch: 5| Step: 7
Training loss: 2.352414809984077
Validation loss: 2.4499306207911795

Epoch: 5| Step: 8
Training loss: 3.1122426367069016
Validation loss: 2.4525778903446054

Epoch: 5| Step: 9
Training loss: 2.4923786341160805
Validation loss: 2.4471429366984894

Epoch: 5| Step: 10
Training loss: 3.0813716284092907
Validation loss: 2.4501954035281437

Epoch: 26| Step: 0
Training loss: 2.9668603605267214
Validation loss: 2.448515656722141

Epoch: 5| Step: 1
Training loss: 2.8684880687670953
Validation loss: 2.4535338086827494

Epoch: 5| Step: 2
Training loss: 2.6283847240519025
Validation loss: 2.4528338545166664

Epoch: 5| Step: 3
Training loss: 2.7934158500859176
Validation loss: 2.4498854561189827

Epoch: 5| Step: 4
Training loss: 2.6454509448772074
Validation loss: 2.447709137640305

Epoch: 5| Step: 5
Training loss: 2.987095576409463
Validation loss: 2.450621298699448

Epoch: 5| Step: 6
Training loss: 2.713851549804263
Validation loss: 2.4489832408001986

Epoch: 5| Step: 7
Training loss: 2.9501949892419552
Validation loss: 2.448958040612008

Epoch: 5| Step: 8
Training loss: 3.23415886345695
Validation loss: 2.4473205413063472

Epoch: 5| Step: 9
Training loss: 2.2182741326453495
Validation loss: 2.4478841866297922

Epoch: 5| Step: 10
Training loss: 3.378521671349298
Validation loss: 2.447098358579128

Epoch: 27| Step: 0
Training loss: 3.2577450239845946
Validation loss: 2.4503570526668343

Epoch: 5| Step: 1
Training loss: 2.874118669845929
Validation loss: 2.4492521296002367

Epoch: 5| Step: 2
Training loss: 2.849819204384844
Validation loss: 2.450027131706186

Epoch: 5| Step: 3
Training loss: 3.5945075522033165
Validation loss: 2.4484978447824854

Epoch: 5| Step: 4
Training loss: 2.4070841346683483
Validation loss: 2.4443979464751378

Epoch: 5| Step: 5
Training loss: 2.9365843299410743
Validation loss: 2.447490693475963

Epoch: 5| Step: 6
Training loss: 2.611369940823106
Validation loss: 2.439260368259155

Epoch: 5| Step: 7
Training loss: 2.769434573445977
Validation loss: 2.4478588138429975

Epoch: 5| Step: 8
Training loss: 2.619067800534921
Validation loss: 2.454039942880289

Epoch: 5| Step: 9
Training loss: 2.3991473511208388
Validation loss: 2.4416038331506256

Epoch: 5| Step: 10
Training loss: 2.9920061420030843
Validation loss: 2.442743536008968

Epoch: 28| Step: 0
Training loss: 2.747881680358171
Validation loss: 2.450362460108166

Epoch: 5| Step: 1
Training loss: 2.3704441946783366
Validation loss: 2.4468615315602458

Epoch: 5| Step: 2
Training loss: 3.1014473458924403
Validation loss: 2.448908927083671

Epoch: 5| Step: 3
Training loss: 2.6251944515322503
Validation loss: 2.4394161747973175

Epoch: 5| Step: 4
Training loss: 3.31039419356621
Validation loss: 2.447980628468527

Epoch: 5| Step: 5
Training loss: 3.0517140621863956
Validation loss: 2.4415283897119084

Epoch: 5| Step: 6
Training loss: 2.660377974939549
Validation loss: 2.4413996419181405

Epoch: 5| Step: 7
Training loss: 2.686515627828525
Validation loss: 2.447262853172989

Epoch: 5| Step: 8
Training loss: 3.2953947821193643
Validation loss: 2.443243671810095

Epoch: 5| Step: 9
Training loss: 2.6359721165109917
Validation loss: 2.435869228299272

Epoch: 5| Step: 10
Training loss: 2.803891804919125
Validation loss: 2.4387306217932347

Epoch: 29| Step: 0
Training loss: 2.7499419119508697
Validation loss: 2.4474713892957496

Epoch: 5| Step: 1
Training loss: 2.6240019036088413
Validation loss: 2.4338079235248866

Epoch: 5| Step: 2
Training loss: 2.640211806614966
Validation loss: 2.4458541403916083

Epoch: 5| Step: 3
Training loss: 2.5710255291864597
Validation loss: 2.4461250851327656

Epoch: 5| Step: 4
Training loss: 3.11685308895055
Validation loss: 2.4436345987122228

Epoch: 5| Step: 5
Training loss: 2.9832019997215373
Validation loss: 2.4343108924856667

Epoch: 5| Step: 6
Training loss: 2.5169439234649604
Validation loss: 2.444373659709063

Epoch: 5| Step: 7
Training loss: 3.062864787894389
Validation loss: 2.4387948840832587

Epoch: 5| Step: 8
Training loss: 3.2412210885555863
Validation loss: 2.441928428280136

Epoch: 5| Step: 9
Training loss: 3.0857599521214705
Validation loss: 2.442534200544117

Epoch: 5| Step: 10
Training loss: 2.6858838566987226
Validation loss: 2.438806734137095

Epoch: 30| Step: 0
Training loss: 2.434419886673486
Validation loss: 2.436116602449277

Epoch: 5| Step: 1
Training loss: 3.1266978419958655
Validation loss: 2.4427242777485705

Epoch: 5| Step: 2
Training loss: 2.427039957818607
Validation loss: 2.442463115499665

Epoch: 5| Step: 3
Training loss: 2.864279454614793
Validation loss: 2.4378252109590286

Epoch: 5| Step: 4
Training loss: 2.7966265008593547
Validation loss: 2.451714446591145

Epoch: 5| Step: 5
Training loss: 2.956503897927739
Validation loss: 2.4390612456873386

Epoch: 5| Step: 6
Training loss: 3.1095906091821583
Validation loss: 2.443087505995304

Epoch: 5| Step: 7
Training loss: 2.745787428461082
Validation loss: 2.4375078313179515

Epoch: 5| Step: 8
Training loss: 2.920182987645714
Validation loss: 2.4422834540102305

Epoch: 5| Step: 9
Training loss: 3.0103698163638324
Validation loss: 2.4396633752928456

Epoch: 5| Step: 10
Training loss: 2.8299876449369186
Validation loss: 2.443832730249158

Epoch: 31| Step: 0
Training loss: 2.857847045222455
Validation loss: 2.4405878689681018

Epoch: 5| Step: 1
Training loss: 3.1558434252849983
Validation loss: 2.4351090167728757

Epoch: 5| Step: 2
Training loss: 3.158290996284528
Validation loss: 2.4438872002441214

Epoch: 5| Step: 3
Training loss: 2.8994591241446135
Validation loss: 2.4405626115049985

Epoch: 5| Step: 4
Training loss: 2.7280428564894765
Validation loss: 2.4336441027719182

Epoch: 5| Step: 5
Training loss: 2.788567165124703
Validation loss: 2.438190655796062

Epoch: 5| Step: 6
Training loss: 2.6742363918300915
Validation loss: 2.4422233406704628

Epoch: 5| Step: 7
Training loss: 3.1615902885202916
Validation loss: 2.437091512347191

Epoch: 5| Step: 8
Training loss: 2.5094423315912793
Validation loss: 2.4350612757679766

Epoch: 5| Step: 9
Training loss: 2.89808377063638
Validation loss: 2.4349741894771437

Epoch: 5| Step: 10
Training loss: 2.2245130241769018
Validation loss: 2.45083079488002

Epoch: 32| Step: 0
Training loss: 2.5033224916117534
Validation loss: 2.441714867821621

Epoch: 5| Step: 1
Training loss: 2.8807382124944607
Validation loss: 2.440441469738228

Epoch: 5| Step: 2
Training loss: 3.0481350371817553
Validation loss: 2.4432900169088674

Epoch: 5| Step: 3
Training loss: 3.0055140048398665
Validation loss: 2.446163441055347

Epoch: 5| Step: 4
Training loss: 2.2788787432119832
Validation loss: 2.4395441550483405

Epoch: 5| Step: 5
Training loss: 2.9163683239166875
Validation loss: 2.438732061963216

Epoch: 5| Step: 6
Training loss: 2.610286621929996
Validation loss: 2.442147057675461

Epoch: 5| Step: 7
Training loss: 3.113258428741247
Validation loss: 2.4452132070847394

Epoch: 5| Step: 8
Training loss: 2.973948374574002
Validation loss: 2.4485294480079998

Epoch: 5| Step: 9
Training loss: 3.1118036494643784
Validation loss: 2.4444444972709785

Epoch: 5| Step: 10
Training loss: 2.658460975938823
Validation loss: 2.4336918520892548

Epoch: 33| Step: 0
Training loss: 3.070828382331932
Validation loss: 2.436584260147572

Epoch: 5| Step: 1
Training loss: 3.484501720912474
Validation loss: 2.435713068569151

Epoch: 5| Step: 2
Training loss: 2.6654021622779602
Validation loss: 2.4421954191180255

Epoch: 5| Step: 3
Training loss: 2.5389470939818377
Validation loss: 2.434745542739894

Epoch: 5| Step: 4
Training loss: 3.0095580745480137
Validation loss: 2.4355972694942154

Epoch: 5| Step: 5
Training loss: 2.4097761599476923
Validation loss: 2.4365352354709975

Epoch: 5| Step: 6
Training loss: 2.6957490871498297
Validation loss: 2.440330334581337

Epoch: 5| Step: 7
Training loss: 2.756685453517726
Validation loss: 2.4357772704885807

Epoch: 5| Step: 8
Training loss: 2.1298645662403333
Validation loss: 2.4396190303970915

Epoch: 5| Step: 9
Training loss: 3.100051781006549
Validation loss: 2.442335540124675

Epoch: 5| Step: 10
Training loss: 3.17514245622296
Validation loss: 2.428858328769764

Epoch: 34| Step: 0
Training loss: 2.9859458424178658
Validation loss: 2.4366539411550723

Epoch: 5| Step: 1
Training loss: 2.602670977543299
Validation loss: 2.4417803623812038

Epoch: 5| Step: 2
Training loss: 2.8641757374555943
Validation loss: 2.4285555356709416

Epoch: 5| Step: 3
Training loss: 2.6445629844846295
Validation loss: 2.4412565184259503

Epoch: 5| Step: 4
Training loss: 2.652921588410436
Validation loss: 2.4404728369389477

Epoch: 5| Step: 5
Training loss: 2.7747567491195815
Validation loss: 2.435573549676592

Epoch: 5| Step: 6
Training loss: 2.8920896376545806
Validation loss: 2.4373831835348243

Epoch: 5| Step: 7
Training loss: 3.0563825894480314
Validation loss: 2.441211605984167

Epoch: 5| Step: 8
Training loss: 2.3796859490733313
Validation loss: 2.431429447947897

Epoch: 5| Step: 9
Training loss: 2.9026146578751746
Validation loss: 2.439647707555648

Epoch: 5| Step: 10
Training loss: 3.4147283747096013
Validation loss: 2.4369270570575274

Epoch: 35| Step: 0
Training loss: 2.7853860853899297
Validation loss: 2.4324079301619883

Epoch: 5| Step: 1
Training loss: 2.90824821442338
Validation loss: 2.4275500676930255

Epoch: 5| Step: 2
Training loss: 3.1745532525012568
Validation loss: 2.4332356115428095

Epoch: 5| Step: 3
Training loss: 2.9184641794107917
Validation loss: 2.4325147510977505

Epoch: 5| Step: 4
Training loss: 2.832988792863163
Validation loss: 2.439876121855857

Epoch: 5| Step: 5
Training loss: 3.047185168006716
Validation loss: 2.4317747051859957

Epoch: 5| Step: 6
Training loss: 2.9645931655674276
Validation loss: 2.437656072600492

Epoch: 5| Step: 7
Training loss: 2.3825269184012883
Validation loss: 2.432532053002545

Epoch: 5| Step: 8
Training loss: 2.3565724888301407
Validation loss: 2.4329259291878307

Epoch: 5| Step: 9
Training loss: 3.17715105495297
Validation loss: 2.4281377176725196

Epoch: 5| Step: 10
Training loss: 2.4043582564450943
Validation loss: 2.438690524281188

Epoch: 36| Step: 0
Training loss: 2.833265322448665
Validation loss: 2.424694468114289

Epoch: 5| Step: 1
Training loss: 2.493028648276126
Validation loss: 2.437648975835536

Epoch: 5| Step: 2
Training loss: 2.4602199901126234
Validation loss: 2.4373449544972656

Epoch: 5| Step: 3
Training loss: 2.831722942539263
Validation loss: 2.438674729926359

Epoch: 5| Step: 4
Training loss: 2.4780679934319845
Validation loss: 2.4319919762460476

Epoch: 5| Step: 5
Training loss: 3.288809941034457
Validation loss: 2.431326995245386

Epoch: 5| Step: 6
Training loss: 2.65858868136891
Validation loss: 2.4311602561485195

Epoch: 5| Step: 7
Training loss: 3.2659529379860404
Validation loss: 2.441465712481516

Epoch: 5| Step: 8
Training loss: 2.7635535979825177
Validation loss: 2.432150695415811

Epoch: 5| Step: 9
Training loss: 3.137573277806974
Validation loss: 2.442828840405555

Epoch: 5| Step: 10
Training loss: 2.7604163307813523
Validation loss: 2.435994266113083

Epoch: 37| Step: 0
Training loss: 2.7710179910340753
Validation loss: 2.4404383813182307

Epoch: 5| Step: 1
Training loss: 2.9374199714310536
Validation loss: 2.4387260384728897

Epoch: 5| Step: 2
Training loss: 2.7734503947213445
Validation loss: 2.4390463518839205

Epoch: 5| Step: 3
Training loss: 3.12720731980352
Validation loss: 2.4328584601964103

Epoch: 5| Step: 4
Training loss: 2.8580617755275926
Validation loss: 2.434486863791782

Epoch: 5| Step: 5
Training loss: 2.669876600549978
Validation loss: 2.437628738163082

Epoch: 5| Step: 6
Training loss: 3.1589001397762817
Validation loss: 2.432987869655215

Epoch: 5| Step: 7
Training loss: 2.639347647783326
Validation loss: 2.4355933718182783

Epoch: 5| Step: 8
Training loss: 2.6886100250938054
Validation loss: 2.429659760425652

Epoch: 5| Step: 9
Training loss: 2.7538813163764884
Validation loss: 2.424898599666121

Epoch: 5| Step: 10
Training loss: 2.683675573176044
Validation loss: 2.423986874774273

Epoch: 38| Step: 0
Training loss: 2.948119103767689
Validation loss: 2.435300481992964

Epoch: 5| Step: 1
Training loss: 2.438131201764795
Validation loss: 2.4399820421675287

Epoch: 5| Step: 2
Training loss: 2.372746854426926
Validation loss: 2.437433087798067

Epoch: 5| Step: 3
Training loss: 3.195760159274389
Validation loss: 2.4381182601426783

Epoch: 5| Step: 4
Training loss: 3.0075217366562725
Validation loss: 2.437569507063263

Epoch: 5| Step: 5
Training loss: 2.7943885875585712
Validation loss: 2.4383772130586254

Epoch: 5| Step: 6
Training loss: 2.9936631351364174
Validation loss: 2.4280085623281473

Epoch: 5| Step: 7
Training loss: 3.2449950781551236
Validation loss: 2.4335650541740694

Epoch: 5| Step: 8
Training loss: 2.956422287031711
Validation loss: 2.4277066014928437

Epoch: 5| Step: 9
Training loss: 2.238358155106056
Validation loss: 2.431769217932372

Epoch: 5| Step: 10
Training loss: 2.617634658191603
Validation loss: 2.4367649557172517

Epoch: 39| Step: 0
Training loss: 3.078647937019949
Validation loss: 2.4367542908880773

Epoch: 5| Step: 1
Training loss: 2.4777411414927117
Validation loss: 2.426995338965441

Epoch: 5| Step: 2
Training loss: 2.728419679717443
Validation loss: 2.423392567107917

Epoch: 5| Step: 3
Training loss: 2.7097632423666456
Validation loss: 2.4367145075177508

Epoch: 5| Step: 4
Training loss: 3.206191813812837
Validation loss: 2.430858693671148

Epoch: 5| Step: 5
Training loss: 2.311778187865907
Validation loss: 2.422838158340245

Epoch: 5| Step: 6
Training loss: 2.675929245023369
Validation loss: 2.4320802956214433

Epoch: 5| Step: 7
Training loss: 2.873418289958387
Validation loss: 2.4278265149591114

Epoch: 5| Step: 8
Training loss: 2.9439880469224673
Validation loss: 2.43236896525308

Epoch: 5| Step: 9
Training loss: 2.843230986130167
Validation loss: 2.4302922410818675

Epoch: 5| Step: 10
Training loss: 3.0768443895328703
Validation loss: 2.4244031917464692

Epoch: 40| Step: 0
Training loss: 2.6505734093198323
Validation loss: 2.4287180899375747

Epoch: 5| Step: 1
Training loss: 2.996574989871249
Validation loss: 2.430258476591287

Epoch: 5| Step: 2
Training loss: 2.881814427232498
Validation loss: 2.432704032535687

Epoch: 5| Step: 3
Training loss: 3.0035776422383527
Validation loss: 2.4307521627652897

Epoch: 5| Step: 4
Training loss: 3.164388757533004
Validation loss: 2.434015470087091

Epoch: 5| Step: 5
Training loss: 2.7558254615648967
Validation loss: 2.4218576526582916

Epoch: 5| Step: 6
Training loss: 2.4828684335389504
Validation loss: 2.4323503826608226

Epoch: 5| Step: 7
Training loss: 2.3018545552033793
Validation loss: 2.428952177614739

Epoch: 5| Step: 8
Training loss: 2.62942812587348
Validation loss: 2.4175350431022524

Epoch: 5| Step: 9
Training loss: 3.0509813074610213
Validation loss: 2.4296441938380697

Epoch: 5| Step: 10
Training loss: 3.0317841678586746
Validation loss: 2.422506470117014

Epoch: 41| Step: 0
Training loss: 2.517537402999306
Validation loss: 2.431170564846868

Epoch: 5| Step: 1
Training loss: 3.0784629984756027
Validation loss: 2.4268860409106288

Epoch: 5| Step: 2
Training loss: 2.3157327068366373
Validation loss: 2.4296858677104995

Epoch: 5| Step: 3
Training loss: 2.5647805463223277
Validation loss: 2.4295164138452923

Epoch: 5| Step: 4
Training loss: 2.5431328177079973
Validation loss: 2.429527214911325

Epoch: 5| Step: 5
Training loss: 3.1547615394009414
Validation loss: 2.435707212331884

Epoch: 5| Step: 6
Training loss: 2.9979183604377235
Validation loss: 2.429651509186471

Epoch: 5| Step: 7
Training loss: 2.669073945514349
Validation loss: 2.4273516431711606

Epoch: 5| Step: 8
Training loss: 3.0612150338085256
Validation loss: 2.433875515767329

Epoch: 5| Step: 9
Training loss: 3.0821924590483083
Validation loss: 2.431033732718384

Epoch: 5| Step: 10
Training loss: 2.8775248843127086
Validation loss: 2.429874211593713

Epoch: 42| Step: 0
Training loss: 2.079424115017417
Validation loss: 2.4290227920825402

Epoch: 5| Step: 1
Training loss: 2.5379517928190323
Validation loss: 2.4318542800411818

Epoch: 5| Step: 2
Training loss: 2.7033784780562407
Validation loss: 2.4305027068721574

Epoch: 5| Step: 3
Training loss: 2.959625194893855
Validation loss: 2.4272476711739186

Epoch: 5| Step: 4
Training loss: 3.055736000821057
Validation loss: 2.4281584166469106

Epoch: 5| Step: 5
Training loss: 3.30980601615306
Validation loss: 2.4323603437742407

Epoch: 5| Step: 6
Training loss: 3.0695587087069587
Validation loss: 2.4261401042149506

Epoch: 5| Step: 7
Training loss: 3.0233595884866133
Validation loss: 2.4208697659208207

Epoch: 5| Step: 8
Training loss: 2.841282371272814
Validation loss: 2.432445607591891

Epoch: 5| Step: 9
Training loss: 2.9282962191261053
Validation loss: 2.4313563374775335

Epoch: 5| Step: 10
Training loss: 2.176377712930552
Validation loss: 2.434585288442486

Epoch: 43| Step: 0
Training loss: 2.2829762028687446
Validation loss: 2.4192814388899477

Epoch: 5| Step: 1
Training loss: 2.5907327038287815
Validation loss: 2.427090055739907

Epoch: 5| Step: 2
Training loss: 3.1183972604527193
Validation loss: 2.42077769370382

Epoch: 5| Step: 3
Training loss: 2.918470714856766
Validation loss: 2.4322970972309927

Epoch: 5| Step: 4
Training loss: 2.8162962829877394
Validation loss: 2.4231185689578623

Epoch: 5| Step: 5
Training loss: 2.6569567469420443
Validation loss: 2.425735782593958

Epoch: 5| Step: 6
Training loss: 2.309967510110502
Validation loss: 2.4240256095500516

Epoch: 5| Step: 7
Training loss: 2.9315033435129054
Validation loss: 2.4108770539832105

Epoch: 5| Step: 8
Training loss: 2.994132662151023
Validation loss: 2.423596965924303

Epoch: 5| Step: 9
Training loss: 2.672412037557125
Validation loss: 2.426312945720028

Epoch: 5| Step: 10
Training loss: 3.5066405379720385
Validation loss: 2.419852740350605

Epoch: 44| Step: 0
Training loss: 2.674093028530989
Validation loss: 2.415993507274663

Epoch: 5| Step: 1
Training loss: 3.258227571167732
Validation loss: 2.4245188688355617

Epoch: 5| Step: 2
Training loss: 2.6598584964945995
Validation loss: 2.424964865034704

Epoch: 5| Step: 3
Training loss: 3.0721150705124516
Validation loss: 2.4342978947468437

Epoch: 5| Step: 4
Training loss: 2.7039433822573145
Validation loss: 2.4223904434640025

Epoch: 5| Step: 5
Training loss: 2.607987543246002
Validation loss: 2.4337143888601185

Epoch: 5| Step: 6
Training loss: 3.1787506897955957
Validation loss: 2.4259749815654414

Epoch: 5| Step: 7
Training loss: 2.5897786634272846
Validation loss: 2.4282562922688906

Epoch: 5| Step: 8
Training loss: 2.6135685282411756
Validation loss: 2.4289822942019996

Epoch: 5| Step: 9
Training loss: 2.9587863163397383
Validation loss: 2.4326807555712437

Epoch: 5| Step: 10
Training loss: 2.4695140766824677
Validation loss: 2.4301792978227272

Epoch: 45| Step: 0
Training loss: 2.819351582075792
Validation loss: 2.4248660752671873

Epoch: 5| Step: 1
Training loss: 2.890241937773083
Validation loss: 2.425065132892766

Epoch: 5| Step: 2
Training loss: 2.6204312847512385
Validation loss: 2.425722303482283

Epoch: 5| Step: 3
Training loss: 3.0254755765489882
Validation loss: 2.4211159301538525

Epoch: 5| Step: 4
Training loss: 3.120209187806386
Validation loss: 2.4212040972570543

Epoch: 5| Step: 5
Training loss: 2.5642815886258243
Validation loss: 2.428196202246153

Epoch: 5| Step: 6
Training loss: 2.4355781999789885
Validation loss: 2.4173630311195318

Epoch: 5| Step: 7
Training loss: 3.073504237665892
Validation loss: 2.4228518640609984

Epoch: 5| Step: 8
Training loss: 3.0290339913537396
Validation loss: 2.426388154351391

Epoch: 5| Step: 9
Training loss: 2.419249163237318
Validation loss: 2.4238487264525426

Epoch: 5| Step: 10
Training loss: 2.704164426437257
Validation loss: 2.4241124504035505

Epoch: 46| Step: 0
Training loss: 2.725648218452703
Validation loss: 2.4268294315198244

Epoch: 5| Step: 1
Training loss: 2.9080014437497423
Validation loss: 2.414208865670871

Epoch: 5| Step: 2
Training loss: 2.866965469785754
Validation loss: 2.4191125798365167

Epoch: 5| Step: 3
Training loss: 2.991243298112987
Validation loss: 2.423503000145637

Epoch: 5| Step: 4
Training loss: 3.3083648782630686
Validation loss: 2.415103483879449

Epoch: 5| Step: 5
Training loss: 2.6063992098536035
Validation loss: 2.4196900757586928

Epoch: 5| Step: 6
Training loss: 2.792863067548194
Validation loss: 2.4284997600997906

Epoch: 5| Step: 7
Training loss: 2.4014222897742212
Validation loss: 2.4326128245111156

Epoch: 5| Step: 8
Training loss: 2.780322831160294
Validation loss: 2.4270225153575558

Epoch: 5| Step: 9
Training loss: 2.50244002477096
Validation loss: 2.4265345044839415

Epoch: 5| Step: 10
Training loss: 2.8028414715764463
Validation loss: 2.4283647041434895

Epoch: 47| Step: 0
Training loss: 3.541425779041813
Validation loss: 2.4204448159515684

Epoch: 5| Step: 1
Training loss: 3.2178196719933334
Validation loss: 2.423695840210627

Epoch: 5| Step: 2
Training loss: 2.981940269931224
Validation loss: 2.425569340860063

Epoch: 5| Step: 3
Training loss: 2.5093538770344823
Validation loss: 2.4127289116114214

Epoch: 5| Step: 4
Training loss: 3.0716321598901435
Validation loss: 2.426143908240545

Epoch: 5| Step: 5
Training loss: 2.251400511696798
Validation loss: 2.4218536143131115

Epoch: 5| Step: 6
Training loss: 2.6427260848729612
Validation loss: 2.424875101878277

Epoch: 5| Step: 7
Training loss: 2.0035266776996994
Validation loss: 2.4269226695642647

Epoch: 5| Step: 8
Training loss: 2.702468704197695
Validation loss: 2.425741235937601

Epoch: 5| Step: 9
Training loss: 2.5646963243877674
Validation loss: 2.417600401117039

Epoch: 5| Step: 10
Training loss: 3.020592585649618
Validation loss: 2.4214596913921267

Epoch: 48| Step: 0
Training loss: 2.9299078693161436
Validation loss: 2.419112371066891

Epoch: 5| Step: 1
Training loss: 3.118962368203961
Validation loss: 2.418222438611216

Epoch: 5| Step: 2
Training loss: 2.605968879156714
Validation loss: 2.420803267729412

Epoch: 5| Step: 3
Training loss: 2.371151365683075
Validation loss: 2.414561835597494

Epoch: 5| Step: 4
Training loss: 2.803106856101353
Validation loss: 2.4118220008265716

Epoch: 5| Step: 5
Training loss: 2.7177643140118155
Validation loss: 2.4285528681085373

Epoch: 5| Step: 6
Training loss: 2.910550453061987
Validation loss: 2.4199510355888982

Epoch: 5| Step: 7
Training loss: 2.8375256507823248
Validation loss: 2.4123193325390533

Epoch: 5| Step: 8
Training loss: 2.6945894460125563
Validation loss: 2.404378704849947

Epoch: 5| Step: 9
Training loss: 2.9967595719591698
Validation loss: 2.4186302485044178

Epoch: 5| Step: 10
Training loss: 2.703430511320943
Validation loss: 2.4178895048879068

Epoch: 49| Step: 0
Training loss: 3.0428424461311727
Validation loss: 2.416569763704721

Epoch: 5| Step: 1
Training loss: 2.8258433543186667
Validation loss: 2.4201587662787536

Epoch: 5| Step: 2
Training loss: 2.516673752056868
Validation loss: 2.4227618427328843

Epoch: 5| Step: 3
Training loss: 2.4420933603409467
Validation loss: 2.4210631683360893

Epoch: 5| Step: 4
Training loss: 2.8040230051530846
Validation loss: 2.4263910218713964

Epoch: 5| Step: 5
Training loss: 3.361104404733516
Validation loss: 2.4187155670642984

Epoch: 5| Step: 6
Training loss: 2.7776007553490696
Validation loss: 2.410303709090012

Epoch: 5| Step: 7
Training loss: 2.172728336569031
Validation loss: 2.4124406532368345

Epoch: 5| Step: 8
Training loss: 2.5061406061741707
Validation loss: 2.417420226994926

Epoch: 5| Step: 9
Training loss: 3.019468556057994
Validation loss: 2.422184028188263

Epoch: 5| Step: 10
Training loss: 3.0839290215306296
Validation loss: 2.4109373651262476

Epoch: 50| Step: 0
Training loss: 3.064576671047649
Validation loss: 2.403725022582574

Epoch: 5| Step: 1
Training loss: 2.410870957707865
Validation loss: 2.4129916335879646

Epoch: 5| Step: 2
Training loss: 2.6306373372222542
Validation loss: 2.406712993969258

Epoch: 5| Step: 3
Training loss: 3.1780610294711864
Validation loss: 2.420462249678053

Epoch: 5| Step: 4
Training loss: 2.9800482737068283
Validation loss: 2.411596597549843

Epoch: 5| Step: 5
Training loss: 2.6228194489665966
Validation loss: 2.4197821745270205

Epoch: 5| Step: 6
Training loss: 2.646840562112247
Validation loss: 2.4210425823595902

Epoch: 5| Step: 7
Training loss: 2.678383735256876
Validation loss: 2.413384540119753

Epoch: 5| Step: 8
Training loss: 2.7421932383420193
Validation loss: 2.4098449134718667

Epoch: 5| Step: 9
Training loss: 2.8736997234763426
Validation loss: 2.41006505134192

Epoch: 5| Step: 10
Training loss: 2.779271997593774
Validation loss: 2.4127303874903467

Epoch: 51| Step: 0
Training loss: 2.606659075424315
Validation loss: 2.41702048187251

Epoch: 5| Step: 1
Training loss: 2.739673124710543
Validation loss: 2.4127308050714773

Epoch: 5| Step: 2
Training loss: 2.888480715974683
Validation loss: 2.4160709300993766

Epoch: 5| Step: 3
Training loss: 2.82278545304602
Validation loss: 2.4231321450762167

Epoch: 5| Step: 4
Training loss: 3.0294602606446572
Validation loss: 2.423909092417485

Epoch: 5| Step: 5
Training loss: 2.642649038509439
Validation loss: 2.4174766049619607

Epoch: 5| Step: 6
Training loss: 2.705217466655987
Validation loss: 2.418948915876903

Epoch: 5| Step: 7
Training loss: 2.8527598754294674
Validation loss: 2.4181759873190796

Epoch: 5| Step: 8
Training loss: 2.2929318374704035
Validation loss: 2.4063797899626818

Epoch: 5| Step: 9
Training loss: 2.960834108827294
Validation loss: 2.4078233345857325

Epoch: 5| Step: 10
Training loss: 3.0863715144261286
Validation loss: 2.4117851013780323

Epoch: 52| Step: 0
Training loss: 3.134701889198248
Validation loss: 2.4136001139311416

Epoch: 5| Step: 1
Training loss: 2.69907291531803
Validation loss: 2.4102035610623673

Epoch: 5| Step: 2
Training loss: 2.6468787543440206
Validation loss: 2.412176281846073

Epoch: 5| Step: 3
Training loss: 2.254386652320675
Validation loss: 2.412165930233898

Epoch: 5| Step: 4
Training loss: 3.027277752556823
Validation loss: 2.4236495287269584

Epoch: 5| Step: 5
Training loss: 3.000047842280059
Validation loss: 2.415687745370165

Epoch: 5| Step: 6
Training loss: 2.5618514193854653
Validation loss: 2.4198208155746808

Epoch: 5| Step: 7
Training loss: 2.4555460651592136
Validation loss: 2.4134512023557626

Epoch: 5| Step: 8
Training loss: 2.62781945447107
Validation loss: 2.414290214089317

Epoch: 5| Step: 9
Training loss: 3.201217157626643
Validation loss: 2.4135812689329748

Epoch: 5| Step: 10
Training loss: 2.7953653363628543
Validation loss: 2.417114520415462

Epoch: 53| Step: 0
Training loss: 2.98231683032716
Validation loss: 2.427400784674758

Epoch: 5| Step: 1
Training loss: 2.621280942051165
Validation loss: 2.4158551862544186

Epoch: 5| Step: 2
Training loss: 2.548259803288301
Validation loss: 2.414856613331457

Epoch: 5| Step: 3
Training loss: 2.7780507578761373
Validation loss: 2.4099154585828177

Epoch: 5| Step: 4
Training loss: 2.8082974719315144
Validation loss: 2.4229690457076285

Epoch: 5| Step: 5
Training loss: 3.077648610075889
Validation loss: 2.4165324816368976

Epoch: 5| Step: 6
Training loss: 2.5880341572814243
Validation loss: 2.413756728208887

Epoch: 5| Step: 7
Training loss: 2.524088961476837
Validation loss: 2.41061872449265

Epoch: 5| Step: 8
Training loss: 3.2010330440075316
Validation loss: 2.4116834671266796

Epoch: 5| Step: 9
Training loss: 2.8156396931086
Validation loss: 2.4161572207579187

Epoch: 5| Step: 10
Training loss: 2.524857254525729
Validation loss: 2.4078954198955587

Epoch: 54| Step: 0
Training loss: 2.3731419171425308
Validation loss: 2.4112872267639522

Epoch: 5| Step: 1
Training loss: 2.838441526180588
Validation loss: 2.4175066359819413

Epoch: 5| Step: 2
Training loss: 3.0863877366371613
Validation loss: 2.4166810092210462

Epoch: 5| Step: 3
Training loss: 2.521109342571184
Validation loss: 2.410065046555168

Epoch: 5| Step: 4
Training loss: 2.5837856224937417
Validation loss: 2.4212625386075133

Epoch: 5| Step: 5
Training loss: 3.0896244477622923
Validation loss: 2.4187338553536355

Epoch: 5| Step: 6
Training loss: 2.748357108687843
Validation loss: 2.40351394630836

Epoch: 5| Step: 7
Training loss: 2.9674122255708397
Validation loss: 2.4157682374684524

Epoch: 5| Step: 8
Training loss: 2.9078348412083375
Validation loss: 2.418410086769371

Epoch: 5| Step: 9
Training loss: 2.7587287396612963
Validation loss: 2.409165151665704

Epoch: 5| Step: 10
Training loss: 2.639253881097679
Validation loss: 2.406530536758221

Epoch: 55| Step: 0
Training loss: 3.017387863136187
Validation loss: 2.4058294217701444

Epoch: 5| Step: 1
Training loss: 2.773192832792917
Validation loss: 2.4089738302044394

Epoch: 5| Step: 2
Training loss: 2.6138699129420053
Validation loss: 2.416082263451003

Epoch: 5| Step: 3
Training loss: 2.5313213008681377
Validation loss: 2.4084447858844324

Epoch: 5| Step: 4
Training loss: 2.3469458598526702
Validation loss: 2.413113201484653

Epoch: 5| Step: 5
Training loss: 2.3036775089311066
Validation loss: 2.4041926230743034

Epoch: 5| Step: 6
Training loss: 2.897680301931555
Validation loss: 2.40651987163484

Epoch: 5| Step: 7
Training loss: 3.23448910719234
Validation loss: 2.4214705760375455

Epoch: 5| Step: 8
Training loss: 3.084611747954695
Validation loss: 2.4143272270946836

Epoch: 5| Step: 9
Training loss: 2.463866316605821
Validation loss: 2.4114628056473393

Epoch: 5| Step: 10
Training loss: 3.167985156448346
Validation loss: 2.4129328952321005

Epoch: 56| Step: 0
Training loss: 3.010615640332302
Validation loss: 2.425345454101081

Epoch: 5| Step: 1
Training loss: 2.885408385410659
Validation loss: 2.4091647387871387

Epoch: 5| Step: 2
Training loss: 2.6738400734187926
Validation loss: 2.4184999775149096

Epoch: 5| Step: 3
Training loss: 3.1963988604919136
Validation loss: 2.4038024544857497

Epoch: 5| Step: 4
Training loss: 2.486245944334839
Validation loss: 2.415081319586095

Epoch: 5| Step: 5
Training loss: 3.101203647868317
Validation loss: 2.4142298624647163

Epoch: 5| Step: 6
Training loss: 3.0019879112635612
Validation loss: 2.4090929223790614

Epoch: 5| Step: 7
Training loss: 2.210684394502288
Validation loss: 2.4038962689232832

Epoch: 5| Step: 8
Training loss: 2.7427285902234124
Validation loss: 2.404561879742925

Epoch: 5| Step: 9
Training loss: 2.6578816507483483
Validation loss: 2.405292526648397

Epoch: 5| Step: 10
Training loss: 2.328721450081897
Validation loss: 2.420036772634434

Epoch: 57| Step: 0
Training loss: 2.5168066625835506
Validation loss: 2.409469847394134

Epoch: 5| Step: 1
Training loss: 2.8009567737778065
Validation loss: 2.4045206436325537

Epoch: 5| Step: 2
Training loss: 2.9646246908327396
Validation loss: 2.4060836157015815

Epoch: 5| Step: 3
Training loss: 2.7743600949520597
Validation loss: 2.4088702244820643

Epoch: 5| Step: 4
Training loss: 2.7384701825535482
Validation loss: 2.412456150709517

Epoch: 5| Step: 5
Training loss: 2.7669702049335902
Validation loss: 2.4121032616455333

Epoch: 5| Step: 6
Training loss: 2.3358065463201947
Validation loss: 2.417927524120378

Epoch: 5| Step: 7
Training loss: 2.91849440572574
Validation loss: 2.4144353024175884

Epoch: 5| Step: 8
Training loss: 2.469913256894264
Validation loss: 2.4246700865474304

Epoch: 5| Step: 9
Training loss: 3.1533035273148027
Validation loss: 2.4066949791694867

Epoch: 5| Step: 10
Training loss: 2.9916151809158267
Validation loss: 2.4217846470180033

Epoch: 58| Step: 0
Training loss: 2.562859765826209
Validation loss: 2.4084172125194305

Epoch: 5| Step: 1
Training loss: 2.8414908018163003
Validation loss: 2.4101320532327084

Epoch: 5| Step: 2
Training loss: 2.9139135900500412
Validation loss: 2.4091010312023386

Epoch: 5| Step: 3
Training loss: 2.9057672571390043
Validation loss: 2.4047577781236877

Epoch: 5| Step: 4
Training loss: 2.406242766926781
Validation loss: 2.4072125857028426

Epoch: 5| Step: 5
Training loss: 2.765954639164925
Validation loss: 2.406642090807129

Epoch: 5| Step: 6
Training loss: 2.8162611502042743
Validation loss: 2.405355136073327

Epoch: 5| Step: 7
Training loss: 2.5459914283757983
Validation loss: 2.4045751384356273

Epoch: 5| Step: 8
Training loss: 2.78124314210882
Validation loss: 2.4116194774028457

Epoch: 5| Step: 9
Training loss: 2.853969112344047
Validation loss: 2.419529475913012

Epoch: 5| Step: 10
Training loss: 3.093632859603662
Validation loss: 2.4120862606569045

Epoch: 59| Step: 0
Training loss: 2.8150350378102083
Validation loss: 2.410524013511108

Epoch: 5| Step: 1
Training loss: 3.3495605465191045
Validation loss: 2.4023717879113082

Epoch: 5| Step: 2
Training loss: 2.561714424113361
Validation loss: 2.402085995896559

Epoch: 5| Step: 3
Training loss: 2.761545135350211
Validation loss: 2.4085754272282993

Epoch: 5| Step: 4
Training loss: 2.6307240701274988
Validation loss: 2.4076924900557968

Epoch: 5| Step: 5
Training loss: 2.174030579001836
Validation loss: 2.4141671869241423

Epoch: 5| Step: 6
Training loss: 2.664568453089305
Validation loss: 2.408253600937516

Epoch: 5| Step: 7
Training loss: 2.9507881081652663
Validation loss: 2.4063245668272093

Epoch: 5| Step: 8
Training loss: 2.8572134383884107
Validation loss: 2.403357230975014

Epoch: 5| Step: 9
Training loss: 2.901975379865701
Validation loss: 2.4035089385132764

Epoch: 5| Step: 10
Training loss: 2.5487282218208467
Validation loss: 2.412580131157643

Epoch: 60| Step: 0
Training loss: 2.451314950847959
Validation loss: 2.398856028137938

Epoch: 5| Step: 1
Training loss: 2.669716303180046
Validation loss: 2.411426615652061

Epoch: 5| Step: 2
Training loss: 3.349810233363726
Validation loss: 2.410674385239328

Epoch: 5| Step: 3
Training loss: 3.0613802984381144
Validation loss: 2.4077647485764175

Epoch: 5| Step: 4
Training loss: 2.374119846484417
Validation loss: 2.406088783287466

Epoch: 5| Step: 5
Training loss: 2.7437748240953295
Validation loss: 2.4088067719847546

Epoch: 5| Step: 6
Training loss: 2.891584742225648
Validation loss: 2.4089448645139666

Epoch: 5| Step: 7
Training loss: 2.714953347607929
Validation loss: 2.4062897415618867

Epoch: 5| Step: 8
Training loss: 2.6862693452915107
Validation loss: 2.398457560646247

Epoch: 5| Step: 9
Training loss: 2.6777635791168217
Validation loss: 2.409423748723575

Epoch: 5| Step: 10
Training loss: 2.6500451713886672
Validation loss: 2.4050605475236604

Epoch: 61| Step: 0
Training loss: 2.729822696335822
Validation loss: 2.400593268095872

Epoch: 5| Step: 1
Training loss: 3.1969570414139126
Validation loss: 2.406375471023291

Epoch: 5| Step: 2
Training loss: 2.726944686205563
Validation loss: 2.407657340118275

Epoch: 5| Step: 3
Training loss: 2.5503996816326215
Validation loss: 2.395506918358833

Epoch: 5| Step: 4
Training loss: 2.9937478720512076
Validation loss: 2.407314142475537

Epoch: 5| Step: 5
Training loss: 2.7148992519056847
Validation loss: 2.4026145645687387

Epoch: 5| Step: 6
Training loss: 2.816316431229667
Validation loss: 2.405111657546167

Epoch: 5| Step: 7
Training loss: 2.4693240693366914
Validation loss: 2.406666397228447

Epoch: 5| Step: 8
Training loss: 3.044446711141047
Validation loss: 2.4050089865803934

Epoch: 5| Step: 9
Training loss: 2.412083478163109
Validation loss: 2.4045897883744454

Epoch: 5| Step: 10
Training loss: 2.57167865657257
Validation loss: 2.40662261502734

Epoch: 62| Step: 0
Training loss: 3.010222502434024
Validation loss: 2.4139511853187146

Epoch: 5| Step: 1
Training loss: 2.604027116215356
Validation loss: 2.4072070893189736

Epoch: 5| Step: 2
Training loss: 2.6787397749541455
Validation loss: 2.4045378644351185

Epoch: 5| Step: 3
Training loss: 2.586014023308373
Validation loss: 2.4060885696586203

Epoch: 5| Step: 4
Training loss: 2.7001769467051724
Validation loss: 2.406846118435169

Epoch: 5| Step: 5
Training loss: 2.617504225967042
Validation loss: 2.408625084322673

Epoch: 5| Step: 6
Training loss: 2.6583684215402377
Validation loss: 2.4064305140153115

Epoch: 5| Step: 7
Training loss: 2.955878694535945
Validation loss: 2.4059459641759946

Epoch: 5| Step: 8
Training loss: 2.69130508387741
Validation loss: 2.4060493900206223

Epoch: 5| Step: 9
Training loss: 2.785126545494866
Validation loss: 2.4081443571398458

Epoch: 5| Step: 10
Training loss: 3.013867434314438
Validation loss: 2.4050420129569607

Epoch: 63| Step: 0
Training loss: 2.7144127812436265
Validation loss: 2.4031133398646882

Epoch: 5| Step: 1
Training loss: 2.848597492656851
Validation loss: 2.4108084532482894

Epoch: 5| Step: 2
Training loss: 2.7461995827479315
Validation loss: 2.4054553506072325

Epoch: 5| Step: 3
Training loss: 3.0006328551037247
Validation loss: 2.411845585394705

Epoch: 5| Step: 4
Training loss: 2.6246264964001007
Validation loss: 2.396318676668518

Epoch: 5| Step: 5
Training loss: 3.020303526271508
Validation loss: 2.401734294363478

Epoch: 5| Step: 6
Training loss: 2.7922688494222068
Validation loss: 2.4130503173936924

Epoch: 5| Step: 7
Training loss: 2.486838217264576
Validation loss: 2.402225645483479

Epoch: 5| Step: 8
Training loss: 2.52111463842495
Validation loss: 2.406185489679946

Epoch: 5| Step: 9
Training loss: 2.5904485074101467
Validation loss: 2.3971858003622426

Epoch: 5| Step: 10
Training loss: 2.8527882906893285
Validation loss: 2.407393079720664

Epoch: 64| Step: 0
Training loss: 2.6863533057668607
Validation loss: 2.4065017691002697

Epoch: 5| Step: 1
Training loss: 2.671115075623456
Validation loss: 2.3969865874076928

Epoch: 5| Step: 2
Training loss: 2.8039461393965324
Validation loss: 2.399111898068143

Epoch: 5| Step: 3
Training loss: 2.873242877884663
Validation loss: 2.406462955200695

Epoch: 5| Step: 4
Training loss: 2.7161914581436415
Validation loss: 2.40038609022624

Epoch: 5| Step: 5
Training loss: 3.1590953125807597
Validation loss: 2.4116294274082555

Epoch: 5| Step: 6
Training loss: 2.9986449996292106
Validation loss: 2.3985759773560473

Epoch: 5| Step: 7
Training loss: 2.7525574323186954
Validation loss: 2.4071197445463755

Epoch: 5| Step: 8
Training loss: 2.514121322939436
Validation loss: 2.403336176526738

Epoch: 5| Step: 9
Training loss: 2.837758722147553
Validation loss: 2.404044476691827

Epoch: 5| Step: 10
Training loss: 2.020633831860314
Validation loss: 2.40911383766036

Epoch: 65| Step: 0
Training loss: 2.7565698174281223
Validation loss: 2.391988504973985

Epoch: 5| Step: 1
Training loss: 2.7340418149405665
Validation loss: 2.3904373263642142

Epoch: 5| Step: 2
Training loss: 2.8441676577202983
Validation loss: 2.39906695214506

Epoch: 5| Step: 3
Training loss: 2.6920771101837504
Validation loss: 2.4026479813057664

Epoch: 5| Step: 4
Training loss: 2.7511499774781236
Validation loss: 2.4012089932307115

Epoch: 5| Step: 5
Training loss: 2.8947195385684976
Validation loss: 2.3998629926128956

Epoch: 5| Step: 6
Training loss: 2.052209556557487
Validation loss: 2.401810429538545

Epoch: 5| Step: 7
Training loss: 2.7092024557925103
Validation loss: 2.3954441162802875

Epoch: 5| Step: 8
Training loss: 3.035492278243655
Validation loss: 2.3961662795896337

Epoch: 5| Step: 9
Training loss: 2.8212069205331884
Validation loss: 2.4004110238999004

Epoch: 5| Step: 10
Training loss: 2.89303224696342
Validation loss: 2.402111965295859

Epoch: 66| Step: 0
Training loss: 2.528433563301021
Validation loss: 2.407322755679772

Epoch: 5| Step: 1
Training loss: 2.877124996192098
Validation loss: 2.400216304523933

Epoch: 5| Step: 2
Training loss: 2.290635853906914
Validation loss: 2.400122074941505

Epoch: 5| Step: 3
Training loss: 2.607191257064876
Validation loss: 2.3991241973811106

Epoch: 5| Step: 4
Training loss: 3.1228816672805446
Validation loss: 2.3957295994997496

Epoch: 5| Step: 5
Training loss: 2.9662680440258242
Validation loss: 2.397917602666603

Epoch: 5| Step: 6
Training loss: 2.8229832565129986
Validation loss: 2.4076323441293046

Epoch: 5| Step: 7
Training loss: 2.449246979813886
Validation loss: 2.4002265410511208

Epoch: 5| Step: 8
Training loss: 2.826214139526104
Validation loss: 2.4113844135927014

Epoch: 5| Step: 9
Training loss: 2.806404544508461
Validation loss: 2.41600361965454

Epoch: 5| Step: 10
Training loss: 2.9036860487452385
Validation loss: 2.413343045782763

Epoch: 67| Step: 0
Training loss: 2.830563163393541
Validation loss: 2.401607667110991

Epoch: 5| Step: 1
Training loss: 3.036848423777358
Validation loss: 2.408531491330699

Epoch: 5| Step: 2
Training loss: 2.8823951481113683
Validation loss: 2.4015382934633913

Epoch: 5| Step: 3
Training loss: 2.5578576812761837
Validation loss: 2.4041939943624797

Epoch: 5| Step: 4
Training loss: 2.664072970820011
Validation loss: 2.4063388417589713

Epoch: 5| Step: 5
Training loss: 2.4786886721443553
Validation loss: 2.408146664064088

Epoch: 5| Step: 6
Training loss: 3.2009181910711457
Validation loss: 2.4195434207636577

Epoch: 5| Step: 7
Training loss: 2.0840059974642684
Validation loss: 2.4114572121085063

Epoch: 5| Step: 8
Training loss: 2.6516394600070914
Validation loss: 2.3963779271008714

Epoch: 5| Step: 9
Training loss: 2.9460710515028197
Validation loss: 2.4112869386412243

Epoch: 5| Step: 10
Training loss: 2.65601446566032
Validation loss: 2.402345135149226

Epoch: 68| Step: 0
Training loss: 2.583966382714429
Validation loss: 2.401930240845908

Epoch: 5| Step: 1
Training loss: 2.5455366491415523
Validation loss: 2.4027454578268896

Epoch: 5| Step: 2
Training loss: 2.88220605441601
Validation loss: 2.4002658921023925

Epoch: 5| Step: 3
Training loss: 3.1866138198758764
Validation loss: 2.398451865697232

Epoch: 5| Step: 4
Training loss: 2.501754717140329
Validation loss: 2.4076193301404345

Epoch: 5| Step: 5
Training loss: 2.641174800901761
Validation loss: 2.408232208194237

Epoch: 5| Step: 6
Training loss: 2.803597836287637
Validation loss: 2.4107177673799107

Epoch: 5| Step: 7
Training loss: 3.1746065752071755
Validation loss: 2.3972042657354904

Epoch: 5| Step: 8
Training loss: 2.589049987210211
Validation loss: 2.4050596958406403

Epoch: 5| Step: 9
Training loss: 2.0720730187794563
Validation loss: 2.401187947704976

Epoch: 5| Step: 10
Training loss: 3.030595846478442
Validation loss: 2.406487567042985

Epoch: 69| Step: 0
Training loss: 2.481766200720088
Validation loss: 2.4010134139127226

Epoch: 5| Step: 1
Training loss: 2.548869095396291
Validation loss: 2.403889391362749

Epoch: 5| Step: 2
Training loss: 2.6455343082491005
Validation loss: 2.4042497841215154

Epoch: 5| Step: 3
Training loss: 2.842495987620076
Validation loss: 2.3988083831936433

Epoch: 5| Step: 4
Training loss: 3.201993714573616
Validation loss: 2.400576650141245

Epoch: 5| Step: 5
Training loss: 2.785263594475476
Validation loss: 2.4080086269002683

Epoch: 5| Step: 6
Training loss: 2.82564490730008
Validation loss: 2.4028971047683094

Epoch: 5| Step: 7
Training loss: 2.475087204755133
Validation loss: 2.406167800153468

Epoch: 5| Step: 8
Training loss: 2.7416641301043834
Validation loss: 2.402797882484709

Epoch: 5| Step: 9
Training loss: 2.9148746616643555
Validation loss: 2.3989501182988255

Epoch: 5| Step: 10
Training loss: 2.4095467116622524
Validation loss: 2.399879579189176

Epoch: 70| Step: 0
Training loss: 2.269816132883809
Validation loss: 2.3970959375791883

Epoch: 5| Step: 1
Training loss: 3.163609149620493
Validation loss: 2.3990181353728706

Epoch: 5| Step: 2
Training loss: 2.9425494035772237
Validation loss: 2.4018089981836495

Epoch: 5| Step: 3
Training loss: 2.5408149188425244
Validation loss: 2.4050858878868473

Epoch: 5| Step: 4
Training loss: 2.675562227292929
Validation loss: 2.407021382764778

Epoch: 5| Step: 5
Training loss: 2.8771006332050444
Validation loss: 2.3976237544083

Epoch: 5| Step: 6
Training loss: 2.6532257815788443
Validation loss: 2.3959121430762806

Epoch: 5| Step: 7
Training loss: 3.1637732856342704
Validation loss: 2.407840356091166

Epoch: 5| Step: 8
Training loss: 2.6356488353003362
Validation loss: 2.397471388960778

Epoch: 5| Step: 9
Training loss: 2.2629316434561875
Validation loss: 2.3985664846322083

Epoch: 5| Step: 10
Training loss: 2.790166641645813
Validation loss: 2.400722499977353

Epoch: 71| Step: 0
Training loss: 2.617562975922903
Validation loss: 2.391586635227146

Epoch: 5| Step: 1
Training loss: 2.8439014101068474
Validation loss: 2.398751291800507

Epoch: 5| Step: 2
Training loss: 2.6886943558486456
Validation loss: 2.397673992229442

Epoch: 5| Step: 3
Training loss: 2.7440226356417963
Validation loss: 2.3958185360430595

Epoch: 5| Step: 4
Training loss: 2.778531320935958
Validation loss: 2.399585729739251

Epoch: 5| Step: 5
Training loss: 2.745032418759659
Validation loss: 2.393712169907658

Epoch: 5| Step: 6
Training loss: 3.127319085783643
Validation loss: 2.392104765739301

Epoch: 5| Step: 7
Training loss: 3.037207971671284
Validation loss: 2.397667852761181

Epoch: 5| Step: 8
Training loss: 2.486219381275235
Validation loss: 2.3816913131524426

Epoch: 5| Step: 9
Training loss: 1.9095969912380237
Validation loss: 2.391048550710405

Epoch: 5| Step: 10
Training loss: 2.8970019134736384
Validation loss: 2.401552691851845

Epoch: 72| Step: 0
Training loss: 2.471035442695555
Validation loss: 2.3888601659647577

Epoch: 5| Step: 1
Training loss: 2.6450711351430685
Validation loss: 2.3971529839100643

Epoch: 5| Step: 2
Training loss: 2.786115269918265
Validation loss: 2.391330317632218

Epoch: 5| Step: 3
Training loss: 2.4680457740446267
Validation loss: 2.3868675238600257

Epoch: 5| Step: 4
Training loss: 2.717725275663586
Validation loss: 2.4005778291323705

Epoch: 5| Step: 5
Training loss: 2.587787991773795
Validation loss: 2.402856969949953

Epoch: 5| Step: 6
Training loss: 2.6125135905081143
Validation loss: 2.398973590036327

Epoch: 5| Step: 7
Training loss: 2.5861251163706664
Validation loss: 2.3978623289790093

Epoch: 5| Step: 8
Training loss: 3.1340615691057048
Validation loss: 2.397287925734884

Epoch: 5| Step: 9
Training loss: 3.330521414776838
Validation loss: 2.389503173430581

Epoch: 5| Step: 10
Training loss: 2.5302259469443302
Validation loss: 2.393640191904149

Epoch: 73| Step: 0
Training loss: 2.587100594327259
Validation loss: 2.3911099002113336

Epoch: 5| Step: 1
Training loss: 2.765368692191633
Validation loss: 2.387404794485415

Epoch: 5| Step: 2
Training loss: 2.105720236060558
Validation loss: 2.4004650854861658

Epoch: 5| Step: 3
Training loss: 3.0388851947595374
Validation loss: 2.4082547421055844

Epoch: 5| Step: 4
Training loss: 2.7252274444573312
Validation loss: 2.39538160740719

Epoch: 5| Step: 5
Training loss: 2.5310394764703723
Validation loss: 2.399249772857033

Epoch: 5| Step: 6
Training loss: 3.118426466311729
Validation loss: 2.3869687664349066

Epoch: 5| Step: 7
Training loss: 3.1447547596225918
Validation loss: 2.4035689887017546

Epoch: 5| Step: 8
Training loss: 2.4372794222674288
Validation loss: 2.3937163949575657

Epoch: 5| Step: 9
Training loss: 2.4797276628843687
Validation loss: 2.3907213346473446

Epoch: 5| Step: 10
Training loss: 2.9116262934534527
Validation loss: 2.4061947749512296

Epoch: 74| Step: 0
Training loss: 2.779646850769039
Validation loss: 2.4070299767803975

Epoch: 5| Step: 1
Training loss: 2.509066924569812
Validation loss: 2.3962937934892863

Epoch: 5| Step: 2
Training loss: 2.719149417695838
Validation loss: 2.4004561657286994

Epoch: 5| Step: 3
Training loss: 2.690777576475702
Validation loss: 2.396953280517306

Epoch: 5| Step: 4
Training loss: 2.5884156122863056
Validation loss: 2.3965611347958604

Epoch: 5| Step: 5
Training loss: 2.5202944050734684
Validation loss: 2.3895006210571847

Epoch: 5| Step: 6
Training loss: 2.9885742043901944
Validation loss: 2.398857167364401

Epoch: 5| Step: 7
Training loss: 3.211425447166719
Validation loss: 2.3943535916951406

Epoch: 5| Step: 8
Training loss: 2.637457397984673
Validation loss: 2.392244896719554

Epoch: 5| Step: 9
Training loss: 2.290879293484686
Validation loss: 2.394993913647789

Epoch: 5| Step: 10
Training loss: 2.860108828574798
Validation loss: 2.39660064444366

Epoch: 75| Step: 0
Training loss: 2.6814817421807446
Validation loss: 2.406862230832963

Epoch: 5| Step: 1
Training loss: 2.662205112943969
Validation loss: 2.383977676747303

Epoch: 5| Step: 2
Training loss: 2.6659821784188606
Validation loss: 2.403157103857856

Epoch: 5| Step: 3
Training loss: 2.7801628130981797
Validation loss: 2.3914798058448743

Epoch: 5| Step: 4
Training loss: 2.555006841362978
Validation loss: 2.398617072512982

Epoch: 5| Step: 5
Training loss: 2.749010254741926
Validation loss: 2.3963047314644665

Epoch: 5| Step: 6
Training loss: 2.9059078876575377
Validation loss: 2.3896691179841723

Epoch: 5| Step: 7
Training loss: 2.670767392808984
Validation loss: 2.396207288223109

Epoch: 5| Step: 8
Training loss: 2.6459464001463653
Validation loss: 2.3996130979665393

Epoch: 5| Step: 9
Training loss: 2.855220590811222
Validation loss: 2.402208113557566

Epoch: 5| Step: 10
Training loss: 2.744863394584809
Validation loss: 2.3916645892843365

Epoch: 76| Step: 0
Training loss: 2.345375717907089
Validation loss: 2.3959364813116744

Epoch: 5| Step: 1
Training loss: 2.1441474390434174
Validation loss: 2.401888957420347

Epoch: 5| Step: 2
Training loss: 2.9294632075600884
Validation loss: 2.401421246776721

Epoch: 5| Step: 3
Training loss: 2.748805393495253
Validation loss: 2.4078978537552196

Epoch: 5| Step: 4
Training loss: 2.4135514493065413
Validation loss: 2.385316878819557

Epoch: 5| Step: 5
Training loss: 2.5262750786504333
Validation loss: 2.405166513085488

Epoch: 5| Step: 6
Training loss: 2.701788952472264
Validation loss: 2.3982813658296136

Epoch: 5| Step: 7
Training loss: 3.153557412598227
Validation loss: 2.3916389813027905

Epoch: 5| Step: 8
Training loss: 2.5774022794416087
Validation loss: 2.397558149082789

Epoch: 5| Step: 9
Training loss: 3.0960607665059583
Validation loss: 2.3971514888153624

Epoch: 5| Step: 10
Training loss: 3.166060205577556
Validation loss: 2.3897364342579133

Epoch: 77| Step: 0
Training loss: 2.65595818206889
Validation loss: 2.396081163839863

Epoch: 5| Step: 1
Training loss: 2.8275840621311277
Validation loss: 2.3916667266647895

Epoch: 5| Step: 2
Training loss: 2.9672158543747096
Validation loss: 2.398712453486915

Epoch: 5| Step: 3
Training loss: 2.682439253120131
Validation loss: 2.3940742697787187

Epoch: 5| Step: 4
Training loss: 2.5056098938674753
Validation loss: 2.390350069690857

Epoch: 5| Step: 5
Training loss: 3.2088253750361027
Validation loss: 2.390421621256041

Epoch: 5| Step: 6
Training loss: 2.3113526255804917
Validation loss: 2.3959128021999545

Epoch: 5| Step: 7
Training loss: 2.993278921888776
Validation loss: 2.3862953203158086

Epoch: 5| Step: 8
Training loss: 2.809126802031652
Validation loss: 2.3860387227926645

Epoch: 5| Step: 9
Training loss: 2.043420453581682
Validation loss: 2.400173273035653

Epoch: 5| Step: 10
Training loss: 2.50265428782013
Validation loss: 2.390522004976564

Epoch: 78| Step: 0
Training loss: 2.3106096118912975
Validation loss: 2.3850435777589074

Epoch: 5| Step: 1
Training loss: 3.0117752722991336
Validation loss: 2.3918176794195967

Epoch: 5| Step: 2
Training loss: 3.0584587369426868
Validation loss: 2.3967771478598117

Epoch: 5| Step: 3
Training loss: 2.331293599638897
Validation loss: 2.3920991060364294

Epoch: 5| Step: 4
Training loss: 2.644250852068417
Validation loss: 2.382659963173221

Epoch: 5| Step: 5
Training loss: 2.9825379474588796
Validation loss: 2.3884074052697026

Epoch: 5| Step: 6
Training loss: 2.5731510153440498
Validation loss: 2.400820770114054

Epoch: 5| Step: 7
Training loss: 2.810487832727649
Validation loss: 2.3946542079140647

Epoch: 5| Step: 8
Training loss: 2.574687724020275
Validation loss: 2.3920146825997377

Epoch: 5| Step: 9
Training loss: 2.5035387742544666
Validation loss: 2.399008901937236

Epoch: 5| Step: 10
Training loss: 2.9901187607772783
Validation loss: 2.3949306362199505

Epoch: 79| Step: 0
Training loss: 3.2619232661836506
Validation loss: 2.3941000669457417

Epoch: 5| Step: 1
Training loss: 2.610798521697612
Validation loss: 2.407620240546952

Epoch: 5| Step: 2
Training loss: 3.0884105189217044
Validation loss: 2.3939881501382017

Epoch: 5| Step: 3
Training loss: 2.8473755916650276
Validation loss: 2.3849968349781214

Epoch: 5| Step: 4
Training loss: 2.128679791926248
Validation loss: 2.385410133829686

Epoch: 5| Step: 5
Training loss: 2.3052839121701365
Validation loss: 2.3872158023771584

Epoch: 5| Step: 6
Training loss: 2.81446439170303
Validation loss: 2.3840642816587794

Epoch: 5| Step: 7
Training loss: 2.878872626637523
Validation loss: 2.386884733472795

Epoch: 5| Step: 8
Training loss: 2.4514871949202406
Validation loss: 2.3805675273710425

Epoch: 5| Step: 9
Training loss: 2.3873769598607844
Validation loss: 2.398245887147557

Epoch: 5| Step: 10
Training loss: 2.8834907540215613
Validation loss: 2.398777279133265

Epoch: 80| Step: 0
Training loss: 3.022073285166653
Validation loss: 2.409488558567968

Epoch: 5| Step: 1
Training loss: 3.0401049397576343
Validation loss: 2.401737555305724

Epoch: 5| Step: 2
Training loss: 2.2759542790330882
Validation loss: 2.3955277382235676

Epoch: 5| Step: 3
Training loss: 3.000945578010807
Validation loss: 2.3853128377225272

Epoch: 5| Step: 4
Training loss: 2.2484197365361984
Validation loss: 2.404366230895851

Epoch: 5| Step: 5
Training loss: 2.760933555336829
Validation loss: 2.3873914135893237

Epoch: 5| Step: 6
Training loss: 2.428257561284541
Validation loss: 2.3962008507806973

Epoch: 5| Step: 7
Training loss: 2.5346498615497755
Validation loss: 2.394684868255633

Epoch: 5| Step: 8
Training loss: 2.9509574564830894
Validation loss: 2.3968014174134353

Epoch: 5| Step: 9
Training loss: 2.560872188943257
Validation loss: 2.3935712053300158

Epoch: 5| Step: 10
Training loss: 2.808187866593988
Validation loss: 2.3992839010667995

Epoch: 81| Step: 0
Training loss: 2.4442582950613208
Validation loss: 2.4028959461192785

Epoch: 5| Step: 1
Training loss: 3.2063490110580433
Validation loss: 2.399151100706272

Epoch: 5| Step: 2
Training loss: 3.084429485918113
Validation loss: 2.3874005754468253

Epoch: 5| Step: 3
Training loss: 2.081960938144956
Validation loss: 2.3964401061711484

Epoch: 5| Step: 4
Training loss: 2.4612873131523108
Validation loss: 2.4006118231274507

Epoch: 5| Step: 5
Training loss: 2.771053783471612
Validation loss: 2.39892521753077

Epoch: 5| Step: 6
Training loss: 2.702194847643098
Validation loss: 2.4061186250797357

Epoch: 5| Step: 7
Training loss: 3.0183907115361643
Validation loss: 2.4002714438992396

Epoch: 5| Step: 8
Training loss: 2.7481796134986003
Validation loss: 2.3995565567049817

Epoch: 5| Step: 9
Training loss: 2.5551912236927063
Validation loss: 2.387760085092091

Epoch: 5| Step: 10
Training loss: 2.2320783856481685
Validation loss: 2.3902083684057422

Epoch: 82| Step: 0
Training loss: 2.894085436632161
Validation loss: 2.3839870399118146

Epoch: 5| Step: 1
Training loss: 2.5019479791735724
Validation loss: 2.3831379760107674

Epoch: 5| Step: 2
Training loss: 2.5036459086697014
Validation loss: 2.3943948722783435

Epoch: 5| Step: 3
Training loss: 2.678060054102848
Validation loss: 2.3902600131954186

Epoch: 5| Step: 4
Training loss: 2.3308861251633473
Validation loss: 2.3963938124807163

Epoch: 5| Step: 5
Training loss: 2.3784149113515816
Validation loss: 2.3978642234870287

Epoch: 5| Step: 6
Training loss: 2.8825997788429376
Validation loss: 2.3937374868949175

Epoch: 5| Step: 7
Training loss: 2.4515943672243683
Validation loss: 2.381700165408522

Epoch: 5| Step: 8
Training loss: 3.3454065230375702
Validation loss: 2.3974643143939876

Epoch: 5| Step: 9
Training loss: 2.8369271729473304
Validation loss: 2.3897986134184523

Epoch: 5| Step: 10
Training loss: 2.716817936654522
Validation loss: 2.4050433901565

Epoch: 83| Step: 0
Training loss: 2.525613419455014
Validation loss: 2.3962564099290002

Epoch: 5| Step: 1
Training loss: 2.6307605931598848
Validation loss: 2.401629101783666

Epoch: 5| Step: 2
Training loss: 2.545129283027048
Validation loss: 2.390121050816433

Epoch: 5| Step: 3
Training loss: 2.6534825887186093
Validation loss: 2.3864094488612455

Epoch: 5| Step: 4
Training loss: 2.8032030517870696
Validation loss: 2.3839362147030663

Epoch: 5| Step: 5
Training loss: 3.061194783994347
Validation loss: 2.392019271826865

Epoch: 5| Step: 6
Training loss: 2.768254296424086
Validation loss: 2.390585477382843

Epoch: 5| Step: 7
Training loss: 2.4196378157849194
Validation loss: 2.3867452893987675

Epoch: 5| Step: 8
Training loss: 2.773172457213491
Validation loss: 2.400659770266801

Epoch: 5| Step: 9
Training loss: 2.7439026427333517
Validation loss: 2.3948792157897576

Epoch: 5| Step: 10
Training loss: 2.6112023082886573
Validation loss: 2.397689969528484

Epoch: 84| Step: 0
Training loss: 2.626516176776316
Validation loss: 2.4015877128386336

Epoch: 5| Step: 1
Training loss: 3.21185601455413
Validation loss: 2.396522338009159

Epoch: 5| Step: 2
Training loss: 3.007038442910824
Validation loss: 2.381754494548473

Epoch: 5| Step: 3
Training loss: 1.9814805675846474
Validation loss: 2.3848849983563025

Epoch: 5| Step: 4
Training loss: 2.6655927720978227
Validation loss: 2.3751223219073907

Epoch: 5| Step: 5
Training loss: 2.583601988902421
Validation loss: 2.393393004464182

Epoch: 5| Step: 6
Training loss: 2.7331437308757636
Validation loss: 2.398061630075103

Epoch: 5| Step: 7
Training loss: 2.281788174626371
Validation loss: 2.3884289251324513

Epoch: 5| Step: 8
Training loss: 3.078350852774635
Validation loss: 2.3948855128072073

Epoch: 5| Step: 9
Training loss: 2.7353153028880195
Validation loss: 2.3963230190825766

Epoch: 5| Step: 10
Training loss: 2.4285822375241333
Validation loss: 2.3904345068737674

Epoch: 85| Step: 0
Training loss: 2.475838251441771
Validation loss: 2.398183807277424

Epoch: 5| Step: 1
Training loss: 2.6696511098530915
Validation loss: 2.392218949340335

Epoch: 5| Step: 2
Training loss: 2.351933142769292
Validation loss: 2.377473515682146

Epoch: 5| Step: 3
Training loss: 2.949948656314231
Validation loss: 2.386826280646366

Epoch: 5| Step: 4
Training loss: 2.9295784484912257
Validation loss: 2.3802215427888314

Epoch: 5| Step: 5
Training loss: 2.1932996977842625
Validation loss: 2.377153939173693

Epoch: 5| Step: 6
Training loss: 2.937519641567063
Validation loss: 2.397771041213042

Epoch: 5| Step: 7
Training loss: 2.529771160888835
Validation loss: 2.39516182504444

Epoch: 5| Step: 8
Training loss: 2.90741632500226
Validation loss: 2.400677983596127

Epoch: 5| Step: 9
Training loss: 2.431079723210547
Validation loss: 2.3955911143854807

Epoch: 5| Step: 10
Training loss: 3.117444938412026
Validation loss: 2.3863049096613267

Epoch: 86| Step: 0
Training loss: 2.6562518849085683
Validation loss: 2.393069307270471

Epoch: 5| Step: 1
Training loss: 2.761964433633027
Validation loss: 2.393193881249084

Epoch: 5| Step: 2
Training loss: 2.9423886465881424
Validation loss: 2.390307882692581

Epoch: 5| Step: 3
Training loss: 2.556555388846053
Validation loss: 2.398060131270715

Epoch: 5| Step: 4
Training loss: 1.985769067520255
Validation loss: 2.372825678621436

Epoch: 5| Step: 5
Training loss: 2.5167894215571867
Validation loss: 2.3971096557303153

Epoch: 5| Step: 6
Training loss: 3.0481469262722665
Validation loss: 2.3893096638232856

Epoch: 5| Step: 7
Training loss: 2.4939916890364553
Validation loss: 2.383041470354462

Epoch: 5| Step: 8
Training loss: 2.9743166483305257
Validation loss: 2.3898916130959886

Epoch: 5| Step: 9
Training loss: 2.5498712619372794
Validation loss: 2.3774581627316365

Epoch: 5| Step: 10
Training loss: 2.8756994972122176
Validation loss: 2.377643071956472

Epoch: 87| Step: 0
Training loss: 2.6592428961283567
Validation loss: 2.3872531213238926

Epoch: 5| Step: 1
Training loss: 2.434366902446868
Validation loss: 2.3881360262624542

Epoch: 5| Step: 2
Training loss: 2.73570349981792
Validation loss: 2.3797836799116734

Epoch: 5| Step: 3
Training loss: 2.5551561398209595
Validation loss: 2.3874963476119486

Epoch: 5| Step: 4
Training loss: 2.4967804204528163
Validation loss: 2.381679343609898

Epoch: 5| Step: 5
Training loss: 2.6859822090338
Validation loss: 2.3955834055511476

Epoch: 5| Step: 6
Training loss: 2.9293785644405386
Validation loss: 2.3848138869677658

Epoch: 5| Step: 7
Training loss: 2.979723435951857
Validation loss: 2.384966362353756

Epoch: 5| Step: 8
Training loss: 2.6659674224408425
Validation loss: 2.3773111185408387

Epoch: 5| Step: 9
Training loss: 2.8200658124995264
Validation loss: 2.3888240762331803

Epoch: 5| Step: 10
Training loss: 2.440902877794543
Validation loss: 2.3950192652543683

Epoch: 88| Step: 0
Training loss: 2.664316383413215
Validation loss: 2.3866041743484634

Epoch: 5| Step: 1
Training loss: 2.911230434353615
Validation loss: 2.381909465824957

Epoch: 5| Step: 2
Training loss: 2.6458534079763836
Validation loss: 2.389528870818643

Epoch: 5| Step: 3
Training loss: 3.199126189852641
Validation loss: 2.3852410383241915

Epoch: 5| Step: 4
Training loss: 2.427053317647072
Validation loss: 2.3866157002637745

Epoch: 5| Step: 5
Training loss: 2.780176705706602
Validation loss: 2.39934425039255

Epoch: 5| Step: 6
Training loss: 2.280706576066834
Validation loss: 2.3934091410183993

Epoch: 5| Step: 7
Training loss: 2.956722913663638
Validation loss: 2.4013904573291542

Epoch: 5| Step: 8
Training loss: 1.9999727008863826
Validation loss: 2.395703132875932

Epoch: 5| Step: 9
Training loss: 2.50672256694851
Validation loss: 2.398137283201161

Epoch: 5| Step: 10
Training loss: 2.987343475199723
Validation loss: 2.3905727148320235

Epoch: 89| Step: 0
Training loss: 2.909879161777172
Validation loss: 2.394576329770133

Epoch: 5| Step: 1
Training loss: 2.782353385908179
Validation loss: 2.38753615437163

Epoch: 5| Step: 2
Training loss: 2.935620457379938
Validation loss: 2.3880147681712396

Epoch: 5| Step: 3
Training loss: 2.8702595647209455
Validation loss: 2.393407958495983

Epoch: 5| Step: 4
Training loss: 2.145958930725572
Validation loss: 2.382057235663694

Epoch: 5| Step: 5
Training loss: 2.1308578085609504
Validation loss: 2.385870090896454

Epoch: 5| Step: 6
Training loss: 3.269474370865012
Validation loss: 2.3891660251806353

Epoch: 5| Step: 7
Training loss: 2.251996214455223
Validation loss: 2.391339118125858

Epoch: 5| Step: 8
Training loss: 2.84777614095185
Validation loss: 2.38246639380072

Epoch: 5| Step: 9
Training loss: 2.7651590073239753
Validation loss: 2.384397143666728

Epoch: 5| Step: 10
Training loss: 2.1829456329705343
Validation loss: 2.384115080480746

Epoch: 90| Step: 0
Training loss: 2.6069183663543147
Validation loss: 2.396002416721221

Epoch: 5| Step: 1
Training loss: 2.3552109306778912
Validation loss: 2.3860311652133945

Epoch: 5| Step: 2
Training loss: 3.183349450222046
Validation loss: 2.4081796431515423

Epoch: 5| Step: 3
Training loss: 3.1274537180792983
Validation loss: 2.387664733660041

Epoch: 5| Step: 4
Training loss: 2.991758629564023
Validation loss: 2.3877992303864515

Epoch: 5| Step: 5
Training loss: 2.2538732463463207
Validation loss: 2.379120303638757

Epoch: 5| Step: 6
Training loss: 2.382929464502504
Validation loss: 2.3847241132288994

Epoch: 5| Step: 7
Training loss: 2.3791501776752404
Validation loss: 2.374465197812348

Epoch: 5| Step: 8
Training loss: 2.5281200130682233
Validation loss: 2.3847236369922946

Epoch: 5| Step: 9
Training loss: 2.6008693928792193
Validation loss: 2.3708385176019564

Epoch: 5| Step: 10
Training loss: 2.8558870314473506
Validation loss: 2.382288439469801

Epoch: 91| Step: 0
Training loss: 2.4252850551794842
Validation loss: 2.379429363898466

Epoch: 5| Step: 1
Training loss: 2.6643139672945457
Validation loss: 2.3902350353032404

Epoch: 5| Step: 2
Training loss: 2.613038010389017
Validation loss: 2.3850785982353075

Epoch: 5| Step: 3
Training loss: 2.987317137927634
Validation loss: 2.3891793896996654

Epoch: 5| Step: 4
Training loss: 2.7205267176018144
Validation loss: 2.3882788756258098

Epoch: 5| Step: 5
Training loss: 3.086013831631115
Validation loss: 2.3886490264844347

Epoch: 5| Step: 6
Training loss: 2.92156768651476
Validation loss: 2.3946136908473474

Epoch: 5| Step: 7
Training loss: 2.684869676691338
Validation loss: 2.3869957321181556

Epoch: 5| Step: 8
Training loss: 2.2073378088393136
Validation loss: 2.3998975468715735

Epoch: 5| Step: 9
Training loss: 2.4065303886836156
Validation loss: 2.3936297376383098

Epoch: 5| Step: 10
Training loss: 2.5147792745089004
Validation loss: 2.388961261315324

Epoch: 92| Step: 0
Training loss: 3.036323313167582
Validation loss: 2.3858432054369314

Epoch: 5| Step: 1
Training loss: 2.888346170733305
Validation loss: 2.3775850356418795

Epoch: 5| Step: 2
Training loss: 2.7009023889150496
Validation loss: 2.388022748889321

Epoch: 5| Step: 3
Training loss: 3.219190400744056
Validation loss: 2.389024269762116

Epoch: 5| Step: 4
Training loss: 2.583833974092815
Validation loss: 2.3897728996213616

Epoch: 5| Step: 5
Training loss: 2.266582839014114
Validation loss: 2.391594160779639

Epoch: 5| Step: 6
Training loss: 2.7758956975772926
Validation loss: 2.38353188863174

Epoch: 5| Step: 7
Training loss: 2.393317308487369
Validation loss: 2.37278626469063

Epoch: 5| Step: 8
Training loss: 2.481966974940897
Validation loss: 2.3689275791412627

Epoch: 5| Step: 9
Training loss: 2.550267213022707
Validation loss: 2.3808168120103885

Epoch: 5| Step: 10
Training loss: 2.24140060386864
Validation loss: 2.3852275216877326

Epoch: 93| Step: 0
Training loss: 3.239855412447737
Validation loss: 2.3916564749389475

Epoch: 5| Step: 1
Training loss: 2.7692659194459783
Validation loss: 2.3833598599749366

Epoch: 5| Step: 2
Training loss: 2.6952428836401263
Validation loss: 2.3820317396467345

Epoch: 5| Step: 3
Training loss: 2.602852533009458
Validation loss: 2.389279977974205

Epoch: 5| Step: 4
Training loss: 2.4651000649838335
Validation loss: 2.3881418338374085

Epoch: 5| Step: 5
Training loss: 2.45901113530415
Validation loss: 2.3921196035068717

Epoch: 5| Step: 6
Training loss: 2.5114269413377817
Validation loss: 2.3760508385958437

Epoch: 5| Step: 7
Training loss: 2.4058201393511767
Validation loss: 2.372360008956853

Epoch: 5| Step: 8
Training loss: 2.7238270501228072
Validation loss: 2.3884844514721184

Epoch: 5| Step: 9
Training loss: 2.5043794419906367
Validation loss: 2.3812516610124677

Epoch: 5| Step: 10
Training loss: 2.9109963657326325
Validation loss: 2.3843517714506928

Epoch: 94| Step: 0
Training loss: 2.3134608978733073
Validation loss: 2.39013731028421

Epoch: 5| Step: 1
Training loss: 2.5549002742527844
Validation loss: 2.3770816501393153

Epoch: 5| Step: 2
Training loss: 3.0109019872751652
Validation loss: 2.394852117819317

Epoch: 5| Step: 3
Training loss: 2.9335732694233485
Validation loss: 2.3823305123654257

Epoch: 5| Step: 4
Training loss: 3.3619343788873
Validation loss: 2.384155509294002

Epoch: 5| Step: 5
Training loss: 2.183888424010955
Validation loss: 2.3894041964228245

Epoch: 5| Step: 6
Training loss: 2.398725958261876
Validation loss: 2.3988476249901933

Epoch: 5| Step: 7
Training loss: 2.463122750944066
Validation loss: 2.4030630450656294

Epoch: 5| Step: 8
Training loss: 2.551494504509655
Validation loss: 2.378068810866201

Epoch: 5| Step: 9
Training loss: 2.824185488598656
Validation loss: 2.383068354073823

Epoch: 5| Step: 10
Training loss: 2.4032173367186087
Validation loss: 2.3856155579300222

Epoch: 95| Step: 0
Training loss: 2.460977124091964
Validation loss: 2.392073922821989

Epoch: 5| Step: 1
Training loss: 2.5415272179376363
Validation loss: 2.3856383605443807

Epoch: 5| Step: 2
Training loss: 2.7791520682146413
Validation loss: 2.3860406745008516

Epoch: 5| Step: 3
Training loss: 2.658763190247064
Validation loss: 2.3786108970310593

Epoch: 5| Step: 4
Training loss: 2.5853331628963
Validation loss: 2.390374734824177

Epoch: 5| Step: 5
Training loss: 2.7090715038146853
Validation loss: 2.3810988131700612

Epoch: 5| Step: 6
Training loss: 2.463044345544781
Validation loss: 2.393212138006733

Epoch: 5| Step: 7
Training loss: 3.006291785316574
Validation loss: 2.37968363610463

Epoch: 5| Step: 8
Training loss: 2.6831343922605053
Validation loss: 2.3852606972839667

Epoch: 5| Step: 9
Training loss: 2.7855513668278187
Validation loss: 2.378867002552361

Epoch: 5| Step: 10
Training loss: 2.4472706909614366
Validation loss: 2.3843995762455434

Epoch: 96| Step: 0
Training loss: 2.7438638024853486
Validation loss: 2.3788761983179243

Epoch: 5| Step: 1
Training loss: 2.4908216793655096
Validation loss: 2.370745080860652

Epoch: 5| Step: 2
Training loss: 2.451284507808144
Validation loss: 2.3870282161925975

Epoch: 5| Step: 3
Training loss: 2.754958797084416
Validation loss: 2.3702834725937216

Epoch: 5| Step: 4
Training loss: 2.664785784759444
Validation loss: 2.390511732255225

Epoch: 5| Step: 5
Training loss: 3.055887518295642
Validation loss: 2.3774196618445695

Epoch: 5| Step: 6
Training loss: 2.8034892378223417
Validation loss: 2.381970368355688

Epoch: 5| Step: 7
Training loss: 2.5676007561010556
Validation loss: 2.380642881398455

Epoch: 5| Step: 8
Training loss: 2.6474775977263048
Validation loss: 2.391018141274323

Epoch: 5| Step: 9
Training loss: 2.5107136045570124
Validation loss: 2.379129128824197

Epoch: 5| Step: 10
Training loss: 2.3546500483358823
Validation loss: 2.383115970539205

Epoch: 97| Step: 0
Training loss: 2.5370554341961236
Validation loss: 2.3805016189098493

Epoch: 5| Step: 1
Training loss: 2.6034000539919884
Validation loss: 2.360939172914217

Epoch: 5| Step: 2
Training loss: 2.1917465408139516
Validation loss: 2.378009054653438

Epoch: 5| Step: 3
Training loss: 2.9207967308751255
Validation loss: 2.3857309367534256

Epoch: 5| Step: 4
Training loss: 2.691057733523882
Validation loss: 2.384245111974131

Epoch: 5| Step: 5
Training loss: 2.5445514213177103
Validation loss: 2.384678554263106

Epoch: 5| Step: 6
Training loss: 2.4350764624087473
Validation loss: 2.3741941882257347

Epoch: 5| Step: 7
Training loss: 2.6378113693923617
Validation loss: 2.3887852868638166

Epoch: 5| Step: 8
Training loss: 3.5033204812764773
Validation loss: 2.3818266735127063

Epoch: 5| Step: 9
Training loss: 2.197092658122653
Validation loss: 2.385304830741435

Epoch: 5| Step: 10
Training loss: 2.7307469304043166
Validation loss: 2.3768493919296745

Epoch: 98| Step: 0
Training loss: 3.017470037505939
Validation loss: 2.37596257505007

Epoch: 5| Step: 1
Training loss: 2.7666321553142197
Validation loss: 2.3846476335715643

Epoch: 5| Step: 2
Training loss: 2.770665978753179
Validation loss: 2.3905191772747356

Epoch: 5| Step: 3
Training loss: 2.3055020202283707
Validation loss: 2.3823643502845817

Epoch: 5| Step: 4
Training loss: 2.5012896072629927
Validation loss: 2.3792437713658785

Epoch: 5| Step: 5
Training loss: 2.539903706805388
Validation loss: 2.3883194507838614

Epoch: 5| Step: 6
Training loss: 2.714775073603032
Validation loss: 2.3896755655125426

Epoch: 5| Step: 7
Training loss: 2.67747864729829
Validation loss: 2.3951194659126953

Epoch: 5| Step: 8
Training loss: 2.8634997358660064
Validation loss: 2.3927751502120533

Epoch: 5| Step: 9
Training loss: 2.4753923509738343
Validation loss: 2.384605656924766

Epoch: 5| Step: 10
Training loss: 2.368134463410385
Validation loss: 2.3850018999164355

Epoch: 99| Step: 0
Training loss: 2.3805047538596082
Validation loss: 2.376445116881673

Epoch: 5| Step: 1
Training loss: 2.2741877310972356
Validation loss: 2.3862293976253452

Epoch: 5| Step: 2
Training loss: 2.728119239058207
Validation loss: 2.3907984531851336

Epoch: 5| Step: 3
Training loss: 2.679891595213726
Validation loss: 2.3915102019067946

Epoch: 5| Step: 4
Training loss: 2.4935889055807494
Validation loss: 2.372127571597461

Epoch: 5| Step: 5
Training loss: 2.469371669094086
Validation loss: 2.3799899502291524

Epoch: 5| Step: 6
Training loss: 2.6752407001333363
Validation loss: 2.3746740466166685

Epoch: 5| Step: 7
Training loss: 3.0563231476999455
Validation loss: 2.3834753692346307

Epoch: 5| Step: 8
Training loss: 2.5680895993653827
Validation loss: 2.393057480876375

Epoch: 5| Step: 9
Training loss: 2.6511348165898436
Validation loss: 2.3754644592822145

Epoch: 5| Step: 10
Training loss: 2.987925868625078
Validation loss: 2.3779148086264628

Epoch: 100| Step: 0
Training loss: 2.685548739345944
Validation loss: 2.3953709862911254

Epoch: 5| Step: 1
Training loss: 2.572757196053244
Validation loss: 2.3946949983560586

Epoch: 5| Step: 2
Training loss: 2.5858752655192907
Validation loss: 2.380845271409989

Epoch: 5| Step: 3
Training loss: 2.570656240372203
Validation loss: 2.362274846237779

Epoch: 5| Step: 4
Training loss: 2.4562760058086766
Validation loss: 2.3787863319753866

Epoch: 5| Step: 5
Training loss: 2.6600391065261224
Validation loss: 2.375365111001427

Epoch: 5| Step: 6
Training loss: 2.4671639284888673
Validation loss: 2.3776793842318718

Epoch: 5| Step: 7
Training loss: 2.875954345202809
Validation loss: 2.368549384165452

Epoch: 5| Step: 8
Training loss: 3.3696123141278393
Validation loss: 2.3946760645346097

Epoch: 5| Step: 9
Training loss: 2.2938724537107165
Validation loss: 2.3820854047321114

Epoch: 5| Step: 10
Training loss: 2.148380459114943
Validation loss: 2.3882903285170345

Epoch: 101| Step: 0
Training loss: 2.860359064250576
Validation loss: 2.3894234794078772

Epoch: 5| Step: 1
Training loss: 2.4889199771055925
Validation loss: 2.379701025868256

Epoch: 5| Step: 2
Training loss: 2.33002604244888
Validation loss: 2.3810256560355145

Epoch: 5| Step: 3
Training loss: 2.942850961295102
Validation loss: 2.3657632861330167

Epoch: 5| Step: 4
Training loss: 2.3813025521314164
Validation loss: 2.3880878872559506

Epoch: 5| Step: 5
Training loss: 2.598051250513155
Validation loss: 2.3803630028338163

Epoch: 5| Step: 6
Training loss: 2.6381045620363146
Validation loss: 2.3814723535792877

Epoch: 5| Step: 7
Training loss: 2.721181637102844
Validation loss: 2.37285253168789

Epoch: 5| Step: 8
Training loss: 2.4652216360179793
Validation loss: 2.377994250663219

Epoch: 5| Step: 9
Training loss: 2.8425657720010378
Validation loss: 2.3757119496038466

Epoch: 5| Step: 10
Training loss: 2.6251016324668326
Validation loss: 2.386084541581847

Epoch: 102| Step: 0
Training loss: 2.6409425262414175
Validation loss: 2.3851161591428025

Epoch: 5| Step: 1
Training loss: 2.3829862937709163
Validation loss: 2.3902907095235464

Epoch: 5| Step: 2
Training loss: 2.5223006294637176
Validation loss: 2.3698178767328315

Epoch: 5| Step: 3
Training loss: 2.9206850617378106
Validation loss: 2.3638076498354677

Epoch: 5| Step: 4
Training loss: 2.2878103118706776
Validation loss: 2.3805952294661297

Epoch: 5| Step: 5
Training loss: 2.1611255312942186
Validation loss: 2.3723995812547902

Epoch: 5| Step: 6
Training loss: 2.7163594577325885
Validation loss: 2.3823304408043624

Epoch: 5| Step: 7
Training loss: 2.6361315716278937
Validation loss: 2.3798223779305556

Epoch: 5| Step: 8
Training loss: 2.7198911880719
Validation loss: 2.3863138275247

Epoch: 5| Step: 9
Training loss: 2.921263115608177
Validation loss: 2.3822881553727298

Epoch: 5| Step: 10
Training loss: 2.9492543199427836
Validation loss: 2.3871646958119195

Epoch: 103| Step: 0
Training loss: 2.5685074332027393
Validation loss: 2.3756547833734554

Epoch: 5| Step: 1
Training loss: 2.6585321832344277
Validation loss: 2.3881706857892344

Epoch: 5| Step: 2
Training loss: 2.557030306407126
Validation loss: 2.3814154074437575

Epoch: 5| Step: 3
Training loss: 2.373940783764017
Validation loss: 2.3738483773698773

Epoch: 5| Step: 4
Training loss: 2.4136639608638357
Validation loss: 2.3865120219557063

Epoch: 5| Step: 5
Training loss: 2.6665509814759405
Validation loss: 2.380220600899962

Epoch: 5| Step: 6
Training loss: 2.765146160160135
Validation loss: 2.37865660292851

Epoch: 5| Step: 7
Training loss: 2.087687697509559
Validation loss: 2.3952002071761336

Epoch: 5| Step: 8
Training loss: 2.844280822173813
Validation loss: 2.379525506451603

Epoch: 5| Step: 9
Training loss: 3.00967531854705
Validation loss: 2.395199514676306

Epoch: 5| Step: 10
Training loss: 2.8582631435247237
Validation loss: 2.3695811621148244

Epoch: 104| Step: 0
Training loss: 2.908877098018153
Validation loss: 2.384819187715968

Epoch: 5| Step: 1
Training loss: 2.5607320687998447
Validation loss: 2.378183452778325

Epoch: 5| Step: 2
Training loss: 2.7284986731645025
Validation loss: 2.3842358659496936

Epoch: 5| Step: 3
Training loss: 2.35009446055712
Validation loss: 2.379749764361306

Epoch: 5| Step: 4
Training loss: 3.0991641363626115
Validation loss: 2.3691948114839176

Epoch: 5| Step: 5
Training loss: 2.3650925433902263
Validation loss: 2.382594272378077

Epoch: 5| Step: 6
Training loss: 2.118392319997252
Validation loss: 2.3832388042127692

Epoch: 5| Step: 7
Training loss: 2.7844269855753963
Validation loss: 2.3819834568258593

Epoch: 5| Step: 8
Training loss: 2.8462121386516515
Validation loss: 2.397092718449168

Epoch: 5| Step: 9
Training loss: 2.617945774743681
Validation loss: 2.3822579343533037

Epoch: 5| Step: 10
Training loss: 2.238810904317135
Validation loss: 2.3890864620923695

Epoch: 105| Step: 0
Training loss: 2.5702558238729054
Validation loss: 2.365116985780845

Epoch: 5| Step: 1
Training loss: 2.2496577108482536
Validation loss: 2.3791238358719746

Epoch: 5| Step: 2
Training loss: 2.408552282163862
Validation loss: 2.3960041072665836

Epoch: 5| Step: 3
Training loss: 2.567230510293331
Validation loss: 2.375034068650695

Epoch: 5| Step: 4
Training loss: 2.6800516398280045
Validation loss: 2.3678580163344765

Epoch: 5| Step: 5
Training loss: 2.378370403204957
Validation loss: 2.3922177067525316

Epoch: 5| Step: 6
Training loss: 2.4711351099933894
Validation loss: 2.3808512841279947

Epoch: 5| Step: 7
Training loss: 2.8969362386179087
Validation loss: 2.374471413468756

Epoch: 5| Step: 8
Training loss: 2.702752412905916
Validation loss: 2.3757818756030935

Epoch: 5| Step: 9
Training loss: 2.756599397203703
Validation loss: 2.369603443660398

Epoch: 5| Step: 10
Training loss: 3.0487259939952627
Validation loss: 2.367945693663309

Epoch: 106| Step: 0
Training loss: 2.516741392360953
Validation loss: 2.3789326712640744

Epoch: 5| Step: 1
Training loss: 2.4420293150258368
Validation loss: 2.3813785503530602

Epoch: 5| Step: 2
Training loss: 3.017985630605376
Validation loss: 2.362703544797266

Epoch: 5| Step: 3
Training loss: 2.4180177551135125
Validation loss: 2.3674966139276

Epoch: 5| Step: 4
Training loss: 3.155991949731111
Validation loss: 2.376897959161229

Epoch: 5| Step: 5
Training loss: 2.6180138037939122
Validation loss: 2.385657063054982

Epoch: 5| Step: 6
Training loss: 2.430979100214799
Validation loss: 2.380262384541217

Epoch: 5| Step: 7
Training loss: 2.543266032900456
Validation loss: 2.38943804575047

Epoch: 5| Step: 8
Training loss: 2.7281477290339513
Validation loss: 2.3741861059539

Epoch: 5| Step: 9
Training loss: 2.594843714276406
Validation loss: 2.3738037387832183

Epoch: 5| Step: 10
Training loss: 2.140354779862254
Validation loss: 2.378903808032116

Epoch: 107| Step: 0
Training loss: 2.6476930005091353
Validation loss: 2.3886231446875805

Epoch: 5| Step: 1
Training loss: 2.59549103179658
Validation loss: 2.376592343019437

Epoch: 5| Step: 2
Training loss: 2.8025627057072935
Validation loss: 2.3681771915512906

Epoch: 5| Step: 3
Training loss: 2.749082672402445
Validation loss: 2.390170156023834

Epoch: 5| Step: 4
Training loss: 2.570025859954993
Validation loss: 2.3720228736509643

Epoch: 5| Step: 5
Training loss: 2.274315313912019
Validation loss: 2.3693047713073216

Epoch: 5| Step: 6
Training loss: 3.0699172214444146
Validation loss: 2.3675297667327615

Epoch: 5| Step: 7
Training loss: 2.619518733485326
Validation loss: 2.3798395092218083

Epoch: 5| Step: 8
Training loss: 2.3273595793391593
Validation loss: 2.3684108002836606

Epoch: 5| Step: 9
Training loss: 2.1058172670009885
Validation loss: 2.3757076806639748

Epoch: 5| Step: 10
Training loss: 2.7841465472038953
Validation loss: 2.3626859301044254

Epoch: 108| Step: 0
Training loss: 2.4215264838702386
Validation loss: 2.381476728446776

Epoch: 5| Step: 1
Training loss: 2.4258919166961457
Validation loss: 2.37737610719696

Epoch: 5| Step: 2
Training loss: 2.1098114692384202
Validation loss: 2.3642121183037967

Epoch: 5| Step: 3
Training loss: 3.145483557516699
Validation loss: 2.3678700140604945

Epoch: 5| Step: 4
Training loss: 2.755267819854316
Validation loss: 2.371433690295047

Epoch: 5| Step: 5
Training loss: 2.627794231778175
Validation loss: 2.3690785421011924

Epoch: 5| Step: 6
Training loss: 2.2988872407039
Validation loss: 2.373847605204574

Epoch: 5| Step: 7
Training loss: 2.0009683410565
Validation loss: 2.3720985666616206

Epoch: 5| Step: 8
Training loss: 2.7660750545543733
Validation loss: 2.384998259224384

Epoch: 5| Step: 9
Training loss: 3.30130647171177
Validation loss: 2.3714598386111807

Epoch: 5| Step: 10
Training loss: 2.414063191336622
Validation loss: 2.366224017257828

Epoch: 109| Step: 0
Training loss: 2.4938869123233154
Validation loss: 2.372539649135098

Epoch: 5| Step: 1
Training loss: 2.568808628721901
Validation loss: 2.3782046199525544

Epoch: 5| Step: 2
Training loss: 2.7740657470931644
Validation loss: 2.377661376957776

Epoch: 5| Step: 3
Training loss: 2.2339720462699675
Validation loss: 2.3619648931769626

Epoch: 5| Step: 4
Training loss: 2.7518161498636036
Validation loss: 2.366358351855874

Epoch: 5| Step: 5
Training loss: 2.1934952460281614
Validation loss: 2.379225772699383

Epoch: 5| Step: 6
Training loss: 2.8483477303676987
Validation loss: 2.373830725500288

Epoch: 5| Step: 7
Training loss: 2.5339413687013104
Validation loss: 2.375765083019155

Epoch: 5| Step: 8
Training loss: 2.849872746889221
Validation loss: 2.374576801835287

Epoch: 5| Step: 9
Training loss: 2.6268178912101128
Validation loss: 2.3826989625442

Epoch: 5| Step: 10
Training loss: 2.6946394370224453
Validation loss: 2.384016375510153

Epoch: 110| Step: 0
Training loss: 2.414278384928731
Validation loss: 2.3892633832661225

Epoch: 5| Step: 1
Training loss: 2.7132585686576736
Validation loss: 2.3717273623029604

Epoch: 5| Step: 2
Training loss: 2.1669939478643143
Validation loss: 2.361773691118412

Epoch: 5| Step: 3
Training loss: 2.75580625530175
Validation loss: 2.388454964132535

Epoch: 5| Step: 4
Training loss: 2.195372882704943
Validation loss: 2.379982874863753

Epoch: 5| Step: 5
Training loss: 2.410490683625628
Validation loss: 2.3789561955601726

Epoch: 5| Step: 6
Training loss: 2.7459990266657894
Validation loss: 2.393320863685386

Epoch: 5| Step: 7
Training loss: 2.8307607602786913
Validation loss: 2.364164959861238

Epoch: 5| Step: 8
Training loss: 3.084728148861804
Validation loss: 2.3889526774179553

Epoch: 5| Step: 9
Training loss: 2.651031933799719
Validation loss: 2.383847161782402

Epoch: 5| Step: 10
Training loss: 2.538766227456187
Validation loss: 2.37496431709258

Epoch: 111| Step: 0
Training loss: 2.7593645693969586
Validation loss: 2.3725383632838017

Epoch: 5| Step: 1
Training loss: 2.604907660284644
Validation loss: 2.3814785606354474

Epoch: 5| Step: 2
Training loss: 2.3161278182617906
Validation loss: 2.3900025546873374

Epoch: 5| Step: 3
Training loss: 2.6434002800537755
Validation loss: 2.381025930592961

Epoch: 5| Step: 4
Training loss: 2.5823063090715728
Validation loss: 2.3967667415047984

Epoch: 5| Step: 5
Training loss: 2.3305223653817255
Validation loss: 2.395949724606186

Epoch: 5| Step: 6
Training loss: 2.570322332392383
Validation loss: 2.398394968908265

Epoch: 5| Step: 7
Training loss: 2.5623826721127165
Validation loss: 2.3930941516671607

Epoch: 5| Step: 8
Training loss: 2.8494691454744236
Validation loss: 2.3944170578218076

Epoch: 5| Step: 9
Training loss: 2.7063186390125424
Validation loss: 2.3976370824759936

Epoch: 5| Step: 10
Training loss: 2.589184707400313
Validation loss: 2.395425054602028

Epoch: 112| Step: 0
Training loss: 2.554323409614002
Validation loss: 2.3850143257382124

Epoch: 5| Step: 1
Training loss: 3.051894840673622
Validation loss: 2.3840417814811627

Epoch: 5| Step: 2
Training loss: 2.2614783915352494
Validation loss: 2.3900718974048303

Epoch: 5| Step: 3
Training loss: 2.448416303142432
Validation loss: 2.379381496417418

Epoch: 5| Step: 4
Training loss: 2.3542236276222743
Validation loss: 2.3837130152995925

Epoch: 5| Step: 5
Training loss: 2.8854340003051857
Validation loss: 2.358192000036154

Epoch: 5| Step: 6
Training loss: 2.555362343970885
Validation loss: 2.3620827847245565

Epoch: 5| Step: 7
Training loss: 2.59305691938382
Validation loss: 2.3874223819651696

Epoch: 5| Step: 8
Training loss: 2.323230180552989
Validation loss: 2.3615947512367343

Epoch: 5| Step: 9
Training loss: 2.713562236178311
Validation loss: 2.3578730888472705

Epoch: 5| Step: 10
Training loss: 2.7083464010852607
Validation loss: 2.3725655561888797

Epoch: 113| Step: 0
Training loss: 2.9236924338086188
Validation loss: 2.374432840938994

Epoch: 5| Step: 1
Training loss: 2.152506245815595
Validation loss: 2.387681425374523

Epoch: 5| Step: 2
Training loss: 1.9839516736343783
Validation loss: 2.3811153942585577

Epoch: 5| Step: 3
Training loss: 2.547053980242956
Validation loss: 2.3662978091395814

Epoch: 5| Step: 4
Training loss: 2.3459148327327024
Validation loss: 2.373409286880373

Epoch: 5| Step: 5
Training loss: 2.685073378002465
Validation loss: 2.364300949006029

Epoch: 5| Step: 6
Training loss: 2.7788251957776984
Validation loss: 2.3681418258693707

Epoch: 5| Step: 7
Training loss: 2.6725554910292537
Validation loss: 2.375567141283116

Epoch: 5| Step: 8
Training loss: 2.9916580568435873
Validation loss: 2.3703439735351344

Epoch: 5| Step: 9
Training loss: 2.6450565329208775
Validation loss: 2.363030036273809

Epoch: 5| Step: 10
Training loss: 2.589626757707021
Validation loss: 2.3689252875930875

Epoch: 114| Step: 0
Training loss: 2.717795281111688
Validation loss: 2.3657572697445683

Epoch: 5| Step: 1
Training loss: 2.8570744165670163
Validation loss: 2.357447236987992

Epoch: 5| Step: 2
Training loss: 2.6361286774632773
Validation loss: 2.375638557517534

Epoch: 5| Step: 3
Training loss: 2.019705021537412
Validation loss: 2.3894236473185675

Epoch: 5| Step: 4
Training loss: 2.776604533910426
Validation loss: 2.387512867626633

Epoch: 5| Step: 5
Training loss: 2.4227288494531147
Validation loss: 2.364921938235233

Epoch: 5| Step: 6
Training loss: 2.6056621885768316
Validation loss: 2.3810541549295587

Epoch: 5| Step: 7
Training loss: 2.2570681285387098
Validation loss: 2.3848344244796085

Epoch: 5| Step: 8
Training loss: 2.6365487503067606
Validation loss: 2.379522428390026

Epoch: 5| Step: 9
Training loss: 2.6619598951234877
Validation loss: 2.389996992981081

Epoch: 5| Step: 10
Training loss: 2.7546285344919212
Validation loss: 2.3762382998849527

Epoch: 115| Step: 0
Training loss: 2.761846946751665
Validation loss: 2.3828272191855033

Epoch: 5| Step: 1
Training loss: 2.2675667695936608
Validation loss: 2.3822913676046844

Epoch: 5| Step: 2
Training loss: 3.0484857458601313
Validation loss: 2.3803260637498784

Epoch: 5| Step: 3
Training loss: 2.282168686752783
Validation loss: 2.378798876480924

Epoch: 5| Step: 4
Training loss: 2.1205947317070746
Validation loss: 2.371302201666257

Epoch: 5| Step: 5
Training loss: 2.5473271068119856
Validation loss: 2.385438602911051

Epoch: 5| Step: 6
Training loss: 2.643062572522275
Validation loss: 2.371346391662169

Epoch: 5| Step: 7
Training loss: 2.5107535826024963
Validation loss: 2.3696274516695452

Epoch: 5| Step: 8
Training loss: 2.608554185611259
Validation loss: 2.3670495165413494

Epoch: 5| Step: 9
Training loss: 2.439532972728698
Validation loss: 2.3763698940516402

Epoch: 5| Step: 10
Training loss: 3.009563461534564
Validation loss: 2.384442278485719

Epoch: 116| Step: 0
Training loss: 2.6166784901766915
Validation loss: 2.3820372360040682

Epoch: 5| Step: 1
Training loss: 2.509557859378152
Validation loss: 2.38213062155717

Epoch: 5| Step: 2
Training loss: 2.7466660143410113
Validation loss: 2.3761068915578276

Epoch: 5| Step: 3
Training loss: 2.9433052650343137
Validation loss: 2.39182156482852

Epoch: 5| Step: 4
Training loss: 2.7110632611657146
Validation loss: 2.387110295419554

Epoch: 5| Step: 5
Training loss: 2.5993498135938102
Validation loss: 2.374018125605351

Epoch: 5| Step: 6
Training loss: 2.835246020210096
Validation loss: 2.3725280299845957

Epoch: 5| Step: 7
Training loss: 2.1951122260459766
Validation loss: 2.380737132496232

Epoch: 5| Step: 8
Training loss: 1.9787789082057183
Validation loss: 2.3761386948111065

Epoch: 5| Step: 9
Training loss: 2.5059380582139745
Validation loss: 2.369317703602746

Epoch: 5| Step: 10
Training loss: 2.424898782564413
Validation loss: 2.3848589080155693

Epoch: 117| Step: 0
Training loss: 2.6892947923959016
Validation loss: 2.364533636400204

Epoch: 5| Step: 1
Training loss: 2.349619725078513
Validation loss: 2.390341284860845

Epoch: 5| Step: 2
Training loss: 2.920441464535511
Validation loss: 2.3846430441335897

Epoch: 5| Step: 3
Training loss: 2.6028894471276542
Validation loss: 2.3760178785951394

Epoch: 5| Step: 4
Training loss: 2.5885121416113326
Validation loss: 2.36528365925203

Epoch: 5| Step: 5
Training loss: 2.6769540263215776
Validation loss: 2.362027314998901

Epoch: 5| Step: 6
Training loss: 2.057837215150615
Validation loss: 2.375940362311873

Epoch: 5| Step: 7
Training loss: 2.6499074271965015
Validation loss: 2.378251937111597

Epoch: 5| Step: 8
Training loss: 2.759767007253723
Validation loss: 2.366214038294851

Epoch: 5| Step: 9
Training loss: 2.048765168800082
Validation loss: 2.3889709129315606

Epoch: 5| Step: 10
Training loss: 2.8030803187795126
Validation loss: 2.3720595702535916

Epoch: 118| Step: 0
Training loss: 2.2954349285218
Validation loss: 2.3715451797015605

Epoch: 5| Step: 1
Training loss: 2.385310130398639
Validation loss: 2.3713458219272785

Epoch: 5| Step: 2
Training loss: 3.0276880474579486
Validation loss: 2.3699975624866343

Epoch: 5| Step: 3
Training loss: 1.9724988213597245
Validation loss: 2.378840998161791

Epoch: 5| Step: 4
Training loss: 3.195810890036056
Validation loss: 2.382594829201322

Epoch: 5| Step: 5
Training loss: 2.7048825410171626
Validation loss: 2.378046989188208

Epoch: 5| Step: 6
Training loss: 2.3808900175555783
Validation loss: 2.3490960953168267

Epoch: 5| Step: 7
Training loss: 2.575802398400442
Validation loss: 2.3655193468090827

Epoch: 5| Step: 8
Training loss: 2.644361031264807
Validation loss: 2.390338912490031

Epoch: 5| Step: 9
Training loss: 2.4664304435444793
Validation loss: 2.379124618716729

Epoch: 5| Step: 10
Training loss: 2.477364972666359
Validation loss: 2.36935370309723

Epoch: 119| Step: 0
Training loss: 2.5328938362292073
Validation loss: 2.377498685334958

Epoch: 5| Step: 1
Training loss: 2.467759042146132
Validation loss: 2.375656865014548

Epoch: 5| Step: 2
Training loss: 2.3325041478356283
Validation loss: 2.371981507964102

Epoch: 5| Step: 3
Training loss: 2.579922875722787
Validation loss: 2.3725338012074464

Epoch: 5| Step: 4
Training loss: 2.4622121265049857
Validation loss: 2.37394725889111

Epoch: 5| Step: 5
Training loss: 2.461988436624501
Validation loss: 2.3780361968595636

Epoch: 5| Step: 6
Training loss: 2.5496581615130425
Validation loss: 2.3837277181697853

Epoch: 5| Step: 7
Training loss: 2.535121923370022
Validation loss: 2.381048572321431

Epoch: 5| Step: 8
Training loss: 2.558246618120457
Validation loss: 2.3822747102248734

Epoch: 5| Step: 9
Training loss: 2.876613661659707
Validation loss: 2.361386739996614

Epoch: 5| Step: 10
Training loss: 2.8896390315937657
Validation loss: 2.372668798001948

Epoch: 120| Step: 0
Training loss: 2.4697420082800914
Validation loss: 2.374650956537183

Epoch: 5| Step: 1
Training loss: 2.1432967393558338
Validation loss: 2.3697697918484173

Epoch: 5| Step: 2
Training loss: 2.5960622385496346
Validation loss: 2.3789899877217278

Epoch: 5| Step: 3
Training loss: 2.3104919788227143
Validation loss: 2.3757440991363983

Epoch: 5| Step: 4
Training loss: 2.2821875957774718
Validation loss: 2.372569983137529

Epoch: 5| Step: 5
Training loss: 2.8791780382328365
Validation loss: 2.365708138945083

Epoch: 5| Step: 6
Training loss: 2.505421767524345
Validation loss: 2.3741061628669695

Epoch: 5| Step: 7
Training loss: 2.9986760078896433
Validation loss: 2.352552976176232

Epoch: 5| Step: 8
Training loss: 2.7980115914639807
Validation loss: 2.3609672529907177

Epoch: 5| Step: 9
Training loss: 2.732323012836929
Validation loss: 2.3671665256377454

Epoch: 5| Step: 10
Training loss: 2.2703706695812738
Validation loss: 2.367118948982843

Epoch: 121| Step: 0
Training loss: 2.754352506368711
Validation loss: 2.3806679583159207

Epoch: 5| Step: 1
Training loss: 2.4413244126908835
Validation loss: 2.371510330163479

Epoch: 5| Step: 2
Training loss: 2.3769081882564143
Validation loss: 2.3759476304475475

Epoch: 5| Step: 3
Training loss: 3.02780238461387
Validation loss: 2.3729897623242273

Epoch: 5| Step: 4
Training loss: 2.1320457337790137
Validation loss: 2.358182244189874

Epoch: 5| Step: 5
Training loss: 2.2071334410108108
Validation loss: 2.3847694380481124

Epoch: 5| Step: 6
Training loss: 2.3900259426736006
Validation loss: 2.3790760683851024

Epoch: 5| Step: 7
Training loss: 3.0046603244736847
Validation loss: 2.3766872811342092

Epoch: 5| Step: 8
Training loss: 3.1511837929864033
Validation loss: 2.363889170484863

Epoch: 5| Step: 9
Training loss: 1.9985537067953196
Validation loss: 2.35926928789657

Epoch: 5| Step: 10
Training loss: 2.309639888949352
Validation loss: 2.3862716841227205

Epoch: 122| Step: 0
Training loss: 2.348020096954433
Validation loss: 2.382300213864635

Epoch: 5| Step: 1
Training loss: 2.9766461217953695
Validation loss: 2.3928170601476815

Epoch: 5| Step: 2
Training loss: 2.3841829955061735
Validation loss: 2.3848574396124804

Epoch: 5| Step: 3
Training loss: 2.2559052433783764
Validation loss: 2.3828709372447694

Epoch: 5| Step: 4
Training loss: 1.9566980866417425
Validation loss: 2.372403363929918

Epoch: 5| Step: 5
Training loss: 2.52818442370313
Validation loss: 2.3698849012083887

Epoch: 5| Step: 6
Training loss: 2.7527853991209126
Validation loss: 2.386348736970455

Epoch: 5| Step: 7
Training loss: 2.763394248146818
Validation loss: 2.378467154436965

Epoch: 5| Step: 8
Training loss: 2.7603643352418437
Validation loss: 2.377761110161051

Epoch: 5| Step: 9
Training loss: 2.5081545397465974
Validation loss: 2.3494856124171446

Epoch: 5| Step: 10
Training loss: 2.6507005053566313
Validation loss: 2.3763694992088373

Epoch: 123| Step: 0
Training loss: 2.5941527639919832
Validation loss: 2.3823786127508875

Epoch: 5| Step: 1
Training loss: 2.4278520231826666
Validation loss: 2.382271787450179

Epoch: 5| Step: 2
Training loss: 1.9283932194797686
Validation loss: 2.3811957872949536

Epoch: 5| Step: 3
Training loss: 2.5768024173259794
Validation loss: 2.373319781982854

Epoch: 5| Step: 4
Training loss: 2.7759681009609043
Validation loss: 2.3925022060796315

Epoch: 5| Step: 5
Training loss: 2.657447724424798
Validation loss: 2.3780073658690855

Epoch: 5| Step: 6
Training loss: 2.6762664577756707
Validation loss: 2.382253737407565

Epoch: 5| Step: 7
Training loss: 2.5625882947643257
Validation loss: 2.3848583210844287

Epoch: 5| Step: 8
Training loss: 1.8485429825597703
Validation loss: 2.3770862967760356

Epoch: 5| Step: 9
Training loss: 3.0580248151312466
Validation loss: 2.3633425387424762

Epoch: 5| Step: 10
Training loss: 2.6061828641226112
Validation loss: 2.3802902522803997

Epoch: 124| Step: 0
Training loss: 2.384810913555686
Validation loss: 2.3625724372929087

Epoch: 5| Step: 1
Training loss: 2.2732591067452357
Validation loss: 2.3657178464171578

Epoch: 5| Step: 2
Training loss: 2.0903921958500282
Validation loss: 2.3667246703400555

Epoch: 5| Step: 3
Training loss: 2.464814344614614
Validation loss: 2.3721729955237176

Epoch: 5| Step: 4
Training loss: 2.481172620974454
Validation loss: 2.3667865972651163

Epoch: 5| Step: 5
Training loss: 2.959443613805794
Validation loss: 2.3722875592515145

Epoch: 5| Step: 6
Training loss: 3.074667135691324
Validation loss: 2.3702620573012143

Epoch: 5| Step: 7
Training loss: 2.814836252304709
Validation loss: 2.3668835858868595

Epoch: 5| Step: 8
Training loss: 2.6308885557146526
Validation loss: 2.3721586414365556

Epoch: 5| Step: 9
Training loss: 1.9087396841513637
Validation loss: 2.359894454438954

Epoch: 5| Step: 10
Training loss: 2.730961527310017
Validation loss: 2.3555810614135195

Epoch: 125| Step: 0
Training loss: 2.68105403655311
Validation loss: 2.3710188861191845

Epoch: 5| Step: 1
Training loss: 2.819794921722807
Validation loss: 2.3679162834743304

Epoch: 5| Step: 2
Training loss: 2.5367124039899833
Validation loss: 2.3533706339206595

Epoch: 5| Step: 3
Training loss: 2.997189317753805
Validation loss: 2.367989299428949

Epoch: 5| Step: 4
Training loss: 1.9898535726339996
Validation loss: 2.386932569164605

Epoch: 5| Step: 5
Training loss: 2.6342801041893553
Validation loss: 2.376230063814299

Epoch: 5| Step: 6
Training loss: 2.3196110034258663
Validation loss: 2.3722993189844948

Epoch: 5| Step: 7
Training loss: 2.435442422861699
Validation loss: 2.365362171272937

Epoch: 5| Step: 8
Training loss: 2.435468462895495
Validation loss: 2.3667246871296848

Epoch: 5| Step: 9
Training loss: 2.4333754636000147
Validation loss: 2.3654790459961226

Epoch: 5| Step: 10
Training loss: 2.5482648555951704
Validation loss: 2.39022696329705

Epoch: 126| Step: 0
Training loss: 2.574350634425086
Validation loss: 2.3786516990777815

Epoch: 5| Step: 1
Training loss: 2.2434841752978807
Validation loss: 2.38281872938644

Epoch: 5| Step: 2
Training loss: 2.6430898144198287
Validation loss: 2.386496578908833

Epoch: 5| Step: 3
Training loss: 3.1367810766885356
Validation loss: 2.381551868555635

Epoch: 5| Step: 4
Training loss: 2.380710963316827
Validation loss: 2.3685678297988346

Epoch: 5| Step: 5
Training loss: 2.5878515622051843
Validation loss: 2.368372748208037

Epoch: 5| Step: 6
Training loss: 1.8316642214637566
Validation loss: 2.3665092387593742

Epoch: 5| Step: 7
Training loss: 2.4618563435320437
Validation loss: 2.386983052404773

Epoch: 5| Step: 8
Training loss: 2.711619442522884
Validation loss: 2.366207132465965

Epoch: 5| Step: 9
Training loss: 2.7525606371500237
Validation loss: 2.3739106098276155

Epoch: 5| Step: 10
Training loss: 2.26812837349753
Validation loss: 2.385281745765897

Epoch: 127| Step: 0
Training loss: 2.0753864801653745
Validation loss: 2.3640984005482757

Epoch: 5| Step: 1
Training loss: 2.271740571758209
Validation loss: 2.3656917505872035

Epoch: 5| Step: 2
Training loss: 2.5585631856475954
Validation loss: 2.382630708787692

Epoch: 5| Step: 3
Training loss: 2.394535232714877
Validation loss: 2.362498062982876

Epoch: 5| Step: 4
Training loss: 2.9039343355599727
Validation loss: 2.3732747070401365

Epoch: 5| Step: 5
Training loss: 2.697733535344469
Validation loss: 2.3851188064953672

Epoch: 5| Step: 6
Training loss: 2.1888043465830496
Validation loss: 2.3830622157050763

Epoch: 5| Step: 7
Training loss: 2.5965221252497774
Validation loss: 2.3781234730641545

Epoch: 5| Step: 8
Training loss: 2.9490717769152295
Validation loss: 2.380936394116278

Epoch: 5| Step: 9
Training loss: 2.5397384917438472
Validation loss: 2.39471238188322

Epoch: 5| Step: 10
Training loss: 2.6383993486670807
Validation loss: 2.37767187663516

Epoch: 128| Step: 0
Training loss: 2.2704189750765598
Validation loss: 2.371135651765778

Epoch: 5| Step: 1
Training loss: 2.8279501507910085
Validation loss: 2.38002469337726

Epoch: 5| Step: 2
Training loss: 2.540651358342186
Validation loss: 2.374373713387465

Epoch: 5| Step: 3
Training loss: 2.1302985162151518
Validation loss: 2.3845320542343016

Epoch: 5| Step: 4
Training loss: 2.506978974907337
Validation loss: 2.3702368702901464

Epoch: 5| Step: 5
Training loss: 2.8340681656505216
Validation loss: 2.3724081958685344

Epoch: 5| Step: 6
Training loss: 2.0912668106853607
Validation loss: 2.3701503204148895

Epoch: 5| Step: 7
Training loss: 2.814044697740704
Validation loss: 2.355533439041668

Epoch: 5| Step: 8
Training loss: 2.818472137627455
Validation loss: 2.3530064125860437

Epoch: 5| Step: 9
Training loss: 2.4765717418991597
Validation loss: 2.373295888829475

Epoch: 5| Step: 10
Training loss: 2.4360778768145974
Validation loss: 2.3475869266321996

Epoch: 129| Step: 0
Training loss: 2.886777719765157
Validation loss: 2.3722280270051717

Epoch: 5| Step: 1
Training loss: 2.6982026899762492
Validation loss: 2.3765941811310367

Epoch: 5| Step: 2
Training loss: 2.428459715878418
Validation loss: 2.3817261880953042

Epoch: 5| Step: 3
Training loss: 2.721865918289958
Validation loss: 2.3809335978304738

Epoch: 5| Step: 4
Training loss: 2.6886673986709977
Validation loss: 2.3902213356146347

Epoch: 5| Step: 5
Training loss: 1.7074812725821833
Validation loss: 2.367428137916798

Epoch: 5| Step: 6
Training loss: 3.0181703251831906
Validation loss: 2.3691819575094057

Epoch: 5| Step: 7
Training loss: 2.451412015907285
Validation loss: 2.3791574058340266

Epoch: 5| Step: 8
Training loss: 2.6631287311491114
Validation loss: 2.375657411053848

Epoch: 5| Step: 9
Training loss: 1.894859615853083
Validation loss: 2.3754563705401575

Epoch: 5| Step: 10
Training loss: 2.1525715951388205
Validation loss: 2.361656439256498

Epoch: 130| Step: 0
Training loss: 2.8514491228531025
Validation loss: 2.382963943712041

Epoch: 5| Step: 1
Training loss: 2.085699975138204
Validation loss: 2.3849423002176917

Epoch: 5| Step: 2
Training loss: 2.9594519922378115
Validation loss: 2.371225490202198

Epoch: 5| Step: 3
Training loss: 2.554911192453558
Validation loss: 2.3644275716074783

Epoch: 5| Step: 4
Training loss: 2.741457502354019
Validation loss: 2.3747799743908184

Epoch: 5| Step: 5
Training loss: 2.399320657268228
Validation loss: 2.374342265477132

Epoch: 5| Step: 6
Training loss: 2.6348421779904543
Validation loss: 2.3645185420415116

Epoch: 5| Step: 7
Training loss: 1.9303081302059169
Validation loss: 2.3827846902710195

Epoch: 5| Step: 8
Training loss: 2.47630169093846
Validation loss: 2.3729898957464672

Epoch: 5| Step: 9
Training loss: 2.738388255337251
Validation loss: 2.3820150782988536

Epoch: 5| Step: 10
Training loss: 2.079583251541412
Validation loss: 2.3632820722632255

Epoch: 131| Step: 0
Training loss: 2.3001383739808414
Validation loss: 2.345900461136258

Epoch: 5| Step: 1
Training loss: 2.7612192006981626
Validation loss: 2.3825432754250193

Epoch: 5| Step: 2
Training loss: 2.0278667738152203
Validation loss: 2.375430829576239

Epoch: 5| Step: 3
Training loss: 2.5690162427900285
Validation loss: 2.3693581273909765

Epoch: 5| Step: 4
Training loss: 2.80944675443031
Validation loss: 2.372292685905737

Epoch: 5| Step: 5
Training loss: 2.5031296214467034
Validation loss: 2.349263722093608

Epoch: 5| Step: 6
Training loss: 2.549796085058258
Validation loss: 2.3720723108258985

Epoch: 5| Step: 7
Training loss: 2.1185696865538004
Validation loss: 2.379592844112496

Epoch: 5| Step: 8
Training loss: 2.3895990501447897
Validation loss: 2.3847827433560065

Epoch: 5| Step: 9
Training loss: 2.877202558613741
Validation loss: 2.375736778581599

Epoch: 5| Step: 10
Training loss: 2.4765258208726544
Validation loss: 2.362723792742894

Epoch: 132| Step: 0
Training loss: 2.3690735004724672
Validation loss: 2.3656843815867967

Epoch: 5| Step: 1
Training loss: 2.309386657768011
Validation loss: 2.359116514362548

Epoch: 5| Step: 2
Training loss: 2.8063336060437725
Validation loss: 2.3649599672434625

Epoch: 5| Step: 3
Training loss: 2.667499998140916
Validation loss: 2.378118799886668

Epoch: 5| Step: 4
Training loss: 2.4632211897448744
Validation loss: 2.3563329965847206

Epoch: 5| Step: 5
Training loss: 2.3400022933818305
Validation loss: 2.3848637808284177

Epoch: 5| Step: 6
Training loss: 2.685848172018889
Validation loss: 2.3764954777044296

Epoch: 5| Step: 7
Training loss: 2.791715156551582
Validation loss: 2.3591818520944496

Epoch: 5| Step: 8
Training loss: 2.0591095308996312
Validation loss: 2.361826084671587

Epoch: 5| Step: 9
Training loss: 2.8158137826578584
Validation loss: 2.3747371880066566

Epoch: 5| Step: 10
Training loss: 2.040682094645678
Validation loss: 2.3686966216028607

Epoch: 133| Step: 0
Training loss: 2.8034173751311116
Validation loss: 2.365498857270567

Epoch: 5| Step: 1
Training loss: 2.22829115837927
Validation loss: 2.3699889131494993

Epoch: 5| Step: 2
Training loss: 2.4411174633888995
Validation loss: 2.3478151928642137

Epoch: 5| Step: 3
Training loss: 2.8201943158777345
Validation loss: 2.363057706371348

Epoch: 5| Step: 4
Training loss: 2.396575304216777
Validation loss: 2.371248424438539

Epoch: 5| Step: 5
Training loss: 2.52653271074256
Validation loss: 2.3671476250515373

Epoch: 5| Step: 6
Training loss: 2.2823164028102285
Validation loss: 2.3554179058676588

Epoch: 5| Step: 7
Training loss: 2.6251325119722657
Validation loss: 2.3740421148867976

Epoch: 5| Step: 8
Training loss: 2.3200656746743715
Validation loss: 2.365211581885179

Epoch: 5| Step: 9
Training loss: 2.5166146363528274
Validation loss: 2.3736749589357826

Epoch: 5| Step: 10
Training loss: 2.53607753477494
Validation loss: 2.361700785854009

Epoch: 134| Step: 0
Training loss: 2.3104822789866253
Validation loss: 2.3669352375867594

Epoch: 5| Step: 1
Training loss: 2.2230284367508726
Validation loss: 2.3644368658166135

Epoch: 5| Step: 2
Training loss: 2.5391595909922304
Validation loss: 2.3414751034130705

Epoch: 5| Step: 3
Training loss: 2.728415223160574
Validation loss: 2.3544015319852463

Epoch: 5| Step: 4
Training loss: 2.664133557577372
Validation loss: 2.3586549627933455

Epoch: 5| Step: 5
Training loss: 2.2665199353839083
Validation loss: 2.363602127885984

Epoch: 5| Step: 6
Training loss: 1.8524622280373038
Validation loss: 2.3697691048989737

Epoch: 5| Step: 7
Training loss: 2.5638062474010486
Validation loss: 2.355180449291983

Epoch: 5| Step: 8
Training loss: 2.759046327191626
Validation loss: 2.3588479011564067

Epoch: 5| Step: 9
Training loss: 2.774000169870912
Validation loss: 2.3546734924137107

Epoch: 5| Step: 10
Training loss: 2.870763061578767
Validation loss: 2.3558310823876583

Epoch: 135| Step: 0
Training loss: 2.4066431294115356
Validation loss: 2.380057470788173

Epoch: 5| Step: 1
Training loss: 2.975679361687717
Validation loss: 2.349118452210718

Epoch: 5| Step: 2
Training loss: 2.5085855878889034
Validation loss: 2.3726801074449697

Epoch: 5| Step: 3
Training loss: 2.501040051602869
Validation loss: 2.36766389406528

Epoch: 5| Step: 4
Training loss: 1.8640714685139579
Validation loss: 2.3552554514276207

Epoch: 5| Step: 5
Training loss: 3.1384111639154395
Validation loss: 2.3631327009587757

Epoch: 5| Step: 6
Training loss: 2.6592629791227056
Validation loss: 2.354751214508904

Epoch: 5| Step: 7
Training loss: 2.0025186177315737
Validation loss: 2.3711281818342127

Epoch: 5| Step: 8
Training loss: 2.4704613850055352
Validation loss: 2.3682933709570038

Epoch: 5| Step: 9
Training loss: 2.0001556812729886
Validation loss: 2.3762500681166183

Epoch: 5| Step: 10
Training loss: 2.634378482549318
Validation loss: 2.36345397974279

Epoch: 136| Step: 0
Training loss: 1.9629310717614545
Validation loss: 2.364397952848707

Epoch: 5| Step: 1
Training loss: 2.9150582010992334
Validation loss: 2.383029355907049

Epoch: 5| Step: 2
Training loss: 3.23235873710996
Validation loss: 2.373136029648532

Epoch: 5| Step: 3
Training loss: 2.06674716495307
Validation loss: 2.369506512271343

Epoch: 5| Step: 4
Training loss: 2.718654762441563
Validation loss: 2.378683702988092

Epoch: 5| Step: 5
Training loss: 2.4076245828086207
Validation loss: 2.3659339481859307

Epoch: 5| Step: 6
Training loss: 2.429445309849515
Validation loss: 2.370658953984767

Epoch: 5| Step: 7
Training loss: 2.6720936111338984
Validation loss: 2.3772084094195614

Epoch: 5| Step: 8
Training loss: 2.431000382423763
Validation loss: 2.3736179326563236

Epoch: 5| Step: 9
Training loss: 2.0163893322417836
Validation loss: 2.3537378736478365

Epoch: 5| Step: 10
Training loss: 2.1771595286005283
Validation loss: 2.3618790127194185

Epoch: 137| Step: 0
Training loss: 2.499100427906207
Validation loss: 2.3779481153533633

Epoch: 5| Step: 1
Training loss: 2.6110868035756463
Validation loss: 2.3549969844443055

Epoch: 5| Step: 2
Training loss: 1.9725548444310312
Validation loss: 2.3725983999099722

Epoch: 5| Step: 3
Training loss: 2.3512820459967494
Validation loss: 2.365092879414515

Epoch: 5| Step: 4
Training loss: 2.0742815083637858
Validation loss: 2.3433860042221717

Epoch: 5| Step: 5
Training loss: 2.787186534003347
Validation loss: 2.3565796328507957

Epoch: 5| Step: 6
Training loss: 2.2117138904665024
Validation loss: 2.373745555139883

Epoch: 5| Step: 7
Training loss: 2.7763457188428657
Validation loss: 2.366533125414791

Epoch: 5| Step: 8
Training loss: 3.2493210596889295
Validation loss: 2.3761798289911407

Epoch: 5| Step: 9
Training loss: 2.549322531969872
Validation loss: 2.3569496780837484

Epoch: 5| Step: 10
Training loss: 2.1910871249573924
Validation loss: 2.3465995218241718

Epoch: 138| Step: 0
Training loss: 1.7648009681328949
Validation loss: 2.354148590979703

Epoch: 5| Step: 1
Training loss: 2.1046369675401784
Validation loss: 2.373872208535541

Epoch: 5| Step: 2
Training loss: 2.755179642429972
Validation loss: 2.3656860255260828

Epoch: 5| Step: 3
Training loss: 2.5063217343079196
Validation loss: 2.367971378154619

Epoch: 5| Step: 4
Training loss: 2.7711872266818616
Validation loss: 2.3618360349572383

Epoch: 5| Step: 5
Training loss: 2.9897765164756445
Validation loss: 2.352567687445529

Epoch: 5| Step: 6
Training loss: 2.1635515732248356
Validation loss: 2.358150846702136

Epoch: 5| Step: 7
Training loss: 2.4281116539233647
Validation loss: 2.3764089475644328

Epoch: 5| Step: 8
Training loss: 2.6324757889868713
Validation loss: 2.3962328719910713

Epoch: 5| Step: 9
Training loss: 2.8123475775212334
Validation loss: 2.362542808298095

Epoch: 5| Step: 10
Training loss: 2.0861675692776247
Validation loss: 2.371455155545494

Epoch: 139| Step: 0
Training loss: 2.214356168601736
Validation loss: 2.368483773392112

Epoch: 5| Step: 1
Training loss: 2.0172819675395055
Validation loss: 2.3752970873989963

Epoch: 5| Step: 2
Training loss: 1.9958943306581745
Validation loss: 2.366515258652582

Epoch: 5| Step: 3
Training loss: 2.3315227727364833
Validation loss: 2.355136275454626

Epoch: 5| Step: 4
Training loss: 2.3640081123303225
Validation loss: 2.393256745054622

Epoch: 5| Step: 5
Training loss: 2.588373149296206
Validation loss: 2.378780867981931

Epoch: 5| Step: 6
Training loss: 2.518747796372427
Validation loss: 2.3554840220721847

Epoch: 5| Step: 7
Training loss: 2.505613224252123
Validation loss: 2.383616157566476

Epoch: 5| Step: 8
Training loss: 2.5957837691455867
Validation loss: 2.3672888104732532

Epoch: 5| Step: 9
Training loss: 2.9416787475971846
Validation loss: 2.3610623752969766

Epoch: 5| Step: 10
Training loss: 3.0303996358269027
Validation loss: 2.365801710685297

Epoch: 140| Step: 0
Training loss: 2.178427492697974
Validation loss: 2.352165703251433

Epoch: 5| Step: 1
Training loss: 2.397020151052807
Validation loss: 2.3711673676286886

Epoch: 5| Step: 2
Training loss: 2.150882176235454
Validation loss: 2.3492741560841695

Epoch: 5| Step: 3
Training loss: 2.922810450658913
Validation loss: 2.363120049423333

Epoch: 5| Step: 4
Training loss: 2.0830345956875163
Validation loss: 2.365946090571928

Epoch: 5| Step: 5
Training loss: 2.5294960444325763
Validation loss: 2.366327165773867

Epoch: 5| Step: 6
Training loss: 2.8356881360429993
Validation loss: 2.3657632427873336

Epoch: 5| Step: 7
Training loss: 2.379674627678785
Validation loss: 2.3531668276102704

Epoch: 5| Step: 8
Training loss: 2.640390058370042
Validation loss: 2.372762880727015

Epoch: 5| Step: 9
Training loss: 2.392671095929635
Validation loss: 2.357778348908968

Epoch: 5| Step: 10
Training loss: 2.5908135026884684
Validation loss: 2.347192456901593

Epoch: 141| Step: 0
Training loss: 2.454907201190114
Validation loss: 2.349699685154095

Epoch: 5| Step: 1
Training loss: 2.5668068025983635
Validation loss: 2.3649004586729534

Epoch: 5| Step: 2
Training loss: 2.4869913204089205
Validation loss: 2.3589443657787355

Epoch: 5| Step: 3
Training loss: 2.368726777539119
Validation loss: 2.371977638692385

Epoch: 5| Step: 4
Training loss: 1.9624437725006136
Validation loss: 2.373931388534862

Epoch: 5| Step: 5
Training loss: 2.667637012684693
Validation loss: 2.3845439255989085

Epoch: 5| Step: 6
Training loss: 2.326427173457639
Validation loss: 2.3824550953032593

Epoch: 5| Step: 7
Training loss: 3.009410403985182
Validation loss: 2.3641755666484334

Epoch: 5| Step: 8
Training loss: 2.5706676481285964
Validation loss: 2.3895544520622347

Epoch: 5| Step: 9
Training loss: 1.9087125162717247
Validation loss: 2.381195748536669

Epoch: 5| Step: 10
Training loss: 2.6661793641052753
Validation loss: 2.3696539596218695

Epoch: 142| Step: 0
Training loss: 2.6733706565718554
Validation loss: 2.3446955872809285

Epoch: 5| Step: 1
Training loss: 2.486401193508515
Validation loss: 2.377009400968592

Epoch: 5| Step: 2
Training loss: 2.6032962921314287
Validation loss: 2.349334707016391

Epoch: 5| Step: 3
Training loss: 2.4598997804339615
Validation loss: 2.3673371623352133

Epoch: 5| Step: 4
Training loss: 1.9462666450430623
Validation loss: 2.3723656925174086

Epoch: 5| Step: 5
Training loss: 2.0143930381466744
Validation loss: 2.3571444793386265

Epoch: 5| Step: 6
Training loss: 2.189347712950852
Validation loss: 2.3506629179008174

Epoch: 5| Step: 7
Training loss: 2.9124934904492368
Validation loss: 2.352720019410394

Epoch: 5| Step: 8
Training loss: 2.850973324461236
Validation loss: 2.360647057330766

Epoch: 5| Step: 9
Training loss: 2.056900862905297
Validation loss: 2.3499312535417176

Epoch: 5| Step: 10
Training loss: 2.558660468476491
Validation loss: 2.364821097670583

Epoch: 143| Step: 0
Training loss: 2.8570563916338063
Validation loss: 2.3625519677717692

Epoch: 5| Step: 1
Training loss: 2.3479415034752154
Validation loss: 2.337331899126395

Epoch: 5| Step: 2
Training loss: 1.8808519594991084
Validation loss: 2.332834094412543

Epoch: 5| Step: 3
Training loss: 2.835120553711455
Validation loss: 2.355859057942711

Epoch: 5| Step: 4
Training loss: 2.4497219706447244
Validation loss: 2.366744473624954

Epoch: 5| Step: 5
Training loss: 1.7182823932224518
Validation loss: 2.3576342811072077

Epoch: 5| Step: 6
Training loss: 2.616597396597835
Validation loss: 2.342741627776375

Epoch: 5| Step: 7
Training loss: 2.140122960381711
Validation loss: 2.3635996180441157

Epoch: 5| Step: 8
Training loss: 2.199430790871358
Validation loss: 2.3457384508395833

Epoch: 5| Step: 9
Training loss: 3.1075975714884323
Validation loss: 2.3331876169431416

Epoch: 5| Step: 10
Training loss: 2.497702019265845
Validation loss: 2.3797734416311034

Epoch: 144| Step: 0
Training loss: 2.3614608941879713
Validation loss: 2.3576678395411186

Epoch: 5| Step: 1
Training loss: 2.691602370337663
Validation loss: 2.3536551294827888

Epoch: 5| Step: 2
Training loss: 2.525510521068722
Validation loss: 2.3503542754568034

Epoch: 5| Step: 3
Training loss: 1.9089833034186872
Validation loss: 2.3452580315473672

Epoch: 5| Step: 4
Training loss: 2.31109359863974
Validation loss: 2.3443619441251564

Epoch: 5| Step: 5
Training loss: 2.3965090476011928
Validation loss: 2.346517826053437

Epoch: 5| Step: 6
Training loss: 2.5924274795674433
Validation loss: 2.3547206433403236

Epoch: 5| Step: 7
Training loss: 2.3826142775837322
Validation loss: 2.345924666914831

Epoch: 5| Step: 8
Training loss: 3.096006091000975
Validation loss: 2.3746618344238084

Epoch: 5| Step: 9
Training loss: 2.387759117724936
Validation loss: 2.3691581343514487

Epoch: 5| Step: 10
Training loss: 1.8433357031923665
Validation loss: 2.372479512689945

Epoch: 145| Step: 0
Training loss: 2.711741039785678
Validation loss: 2.357981481567758

Epoch: 5| Step: 1
Training loss: 2.975292505582336
Validation loss: 2.339419227519044

Epoch: 5| Step: 2
Training loss: 2.3224203380641613
Validation loss: 2.358335460889584

Epoch: 5| Step: 3
Training loss: 2.296095423845458
Validation loss: 2.3452032067333883

Epoch: 5| Step: 4
Training loss: 2.2947825547803795
Validation loss: 2.3563170337038946

Epoch: 5| Step: 5
Training loss: 2.562129854590643
Validation loss: 2.3658919055327425

Epoch: 5| Step: 6
Training loss: 2.3754256017713504
Validation loss: 2.3483929996183592

Epoch: 5| Step: 7
Training loss: 2.260985787699192
Validation loss: 2.3639464596509026

Epoch: 5| Step: 8
Training loss: 2.6446598985221743
Validation loss: 2.365111940585137

Epoch: 5| Step: 9
Training loss: 1.7613386264267155
Validation loss: 2.3558366518435334

Epoch: 5| Step: 10
Training loss: 2.6759709423238096
Validation loss: 2.374110828825246

Epoch: 146| Step: 0
Training loss: 2.6283025402651163
Validation loss: 2.367035249438093

Epoch: 5| Step: 1
Training loss: 1.8617194005634485
Validation loss: 2.3677902642842645

Epoch: 5| Step: 2
Training loss: 2.9997892305721154
Validation loss: 2.3512068871271383

Epoch: 5| Step: 3
Training loss: 2.7545314214482297
Validation loss: 2.3571240246744978

Epoch: 5| Step: 4
Training loss: 2.5557136924393875
Validation loss: 2.359230113658879

Epoch: 5| Step: 5
Training loss: 2.3950073366311617
Validation loss: 2.371869486751664

Epoch: 5| Step: 6
Training loss: 2.035960208886207
Validation loss: 2.3470524372157695

Epoch: 5| Step: 7
Training loss: 1.9114273304378269
Validation loss: 2.353757428677003

Epoch: 5| Step: 8
Training loss: 2.42095368611952
Validation loss: 2.3642707680644177

Epoch: 5| Step: 9
Training loss: 2.598989870011306
Validation loss: 2.350558235106816

Epoch: 5| Step: 10
Training loss: 2.5050546092707173
Validation loss: 2.351522470207874

Epoch: 147| Step: 0
Training loss: 2.3689092537281122
Validation loss: 2.3469193226245317

Epoch: 5| Step: 1
Training loss: 2.2207345817706625
Validation loss: 2.3589885829592974

Epoch: 5| Step: 2
Training loss: 1.8904523534211117
Validation loss: 2.3482189425844666

Epoch: 5| Step: 3
Training loss: 2.507741196233694
Validation loss: 2.367799625955891

Epoch: 5| Step: 4
Training loss: 2.1519985579872265
Validation loss: 2.376353595404009

Epoch: 5| Step: 5
Training loss: 2.5060022778694777
Validation loss: 2.348657707256553

Epoch: 5| Step: 6
Training loss: 2.2873872739605465
Validation loss: 2.3610994398619614

Epoch: 5| Step: 7
Training loss: 2.545561375636535
Validation loss: 2.3503785509849346

Epoch: 5| Step: 8
Training loss: 2.571729275363034
Validation loss: 2.3531027903811506

Epoch: 5| Step: 9
Training loss: 2.7835932943347492
Validation loss: 2.3482939907534837

Epoch: 5| Step: 10
Training loss: 2.819217966146518
Validation loss: 2.3572614189225316

Epoch: 148| Step: 0
Training loss: 2.355600331238775
Validation loss: 2.344182441221804

Epoch: 5| Step: 1
Training loss: 2.305556621576801
Validation loss: 2.322752729145778

Epoch: 5| Step: 2
Training loss: 2.320408366371069
Validation loss: 2.3448862440318887

Epoch: 5| Step: 3
Training loss: 2.4543707533358368
Validation loss: 2.3549565046488037

Epoch: 5| Step: 4
Training loss: 2.0943394300991462
Validation loss: 2.3388505003599716

Epoch: 5| Step: 5
Training loss: 2.7660368704279583
Validation loss: 2.3311220698709016

Epoch: 5| Step: 6
Training loss: 2.056863539045703
Validation loss: 2.353416923148802

Epoch: 5| Step: 7
Training loss: 2.5643023223582007
Validation loss: 2.3476994600425236

Epoch: 5| Step: 8
Training loss: 2.463542129054171
Validation loss: 2.37188030713955

Epoch: 5| Step: 9
Training loss: 2.7383509040713037
Validation loss: 2.356145435697352

Epoch: 5| Step: 10
Training loss: 2.48116522194957
Validation loss: 2.3498429684263105

Epoch: 149| Step: 0
Training loss: 2.7933052340469704
Validation loss: 2.3363443431140496

Epoch: 5| Step: 1
Training loss: 2.5591945263178326
Validation loss: 2.370531539513617

Epoch: 5| Step: 2
Training loss: 2.5712330569764723
Validation loss: 2.3581250106732248

Epoch: 5| Step: 3
Training loss: 2.5280185370550288
Validation loss: 2.3743238452689215

Epoch: 5| Step: 4
Training loss: 2.247587181836027
Validation loss: 2.366815431169322

Epoch: 5| Step: 5
Training loss: 2.4707727957691676
Validation loss: 2.356133552359684

Epoch: 5| Step: 6
Training loss: 2.054402610841619
Validation loss: 2.361403513236879

Epoch: 5| Step: 7
Training loss: 2.7332452674572836
Validation loss: 2.367190028780541

Epoch: 5| Step: 8
Training loss: 1.964910365770896
Validation loss: 2.360132571295904

Epoch: 5| Step: 9
Training loss: 2.3173952612721362
Validation loss: 2.3350190176591954

Epoch: 5| Step: 10
Training loss: 2.401281503433975
Validation loss: 2.347289243791683

Epoch: 150| Step: 0
Training loss: 2.283296059445767
Validation loss: 2.347257057299237

Epoch: 5| Step: 1
Training loss: 2.714031904945259
Validation loss: 2.3689332114163664

Epoch: 5| Step: 2
Training loss: 2.205291764728224
Validation loss: 2.3458576736698467

Epoch: 5| Step: 3
Training loss: 2.644832531940213
Validation loss: 2.3454540158970243

Epoch: 5| Step: 4
Training loss: 2.667539503382417
Validation loss: 2.3610692874872545

Epoch: 5| Step: 5
Training loss: 1.9604995664067313
Validation loss: 2.3625082806369777

Epoch: 5| Step: 6
Training loss: 2.7492739846138226
Validation loss: 2.3668386767594827

Epoch: 5| Step: 7
Training loss: 2.1387553716934318
Validation loss: 2.377628497507899

Epoch: 5| Step: 8
Training loss: 2.4549567314732377
Validation loss: 2.3571100194298897

Epoch: 5| Step: 9
Training loss: 2.2143997743121346
Validation loss: 2.3583661738014046

Epoch: 5| Step: 10
Training loss: 2.36322081937846
Validation loss: 2.3308403365808674

Epoch: 151| Step: 0
Training loss: 2.4223277991536847
Validation loss: 2.3599202819595297

Epoch: 5| Step: 1
Training loss: 2.505535101777709
Validation loss: 2.355021690004196

Epoch: 5| Step: 2
Training loss: 2.198942719341906
Validation loss: 2.331627244741059

Epoch: 5| Step: 3
Training loss: 1.5801304076495817
Validation loss: 2.3399389476557757

Epoch: 5| Step: 4
Training loss: 2.148217984169047
Validation loss: 2.344686963785843

Epoch: 5| Step: 5
Training loss: 2.3411104725057976
Validation loss: 2.3701532451576544

Epoch: 5| Step: 6
Training loss: 2.6011321023952876
Validation loss: 2.3246962752594826

Epoch: 5| Step: 7
Training loss: 2.296393934462005
Validation loss: 2.3218987337559276

Epoch: 5| Step: 8
Training loss: 2.8170669775310624
Validation loss: 2.350501217319018

Epoch: 5| Step: 9
Training loss: 2.6735180716131213
Validation loss: 2.341975301901361

Epoch: 5| Step: 10
Training loss: 2.7346067493867383
Validation loss: 2.339726328854469

Epoch: 152| Step: 0
Training loss: 2.3243916936050804
Validation loss: 2.3573049194502236

Epoch: 5| Step: 1
Training loss: 2.239372692995962
Validation loss: 2.3326354017602657

Epoch: 5| Step: 2
Training loss: 2.199811025652882
Validation loss: 2.3615343377082705

Epoch: 5| Step: 3
Training loss: 2.3608194944023455
Validation loss: 2.3471858970444637

Epoch: 5| Step: 4
Training loss: 2.308681325009846
Validation loss: 2.3498230753433074

Epoch: 5| Step: 5
Training loss: 2.417645015213396
Validation loss: 2.343824542647896

Epoch: 5| Step: 6
Training loss: 2.165311046924123
Validation loss: 2.33617461789908

Epoch: 5| Step: 7
Training loss: 2.6950955068618954
Validation loss: 2.3373467615864496

Epoch: 5| Step: 8
Training loss: 2.0510894253196175
Validation loss: 2.3691818828459943

Epoch: 5| Step: 9
Training loss: 2.7571015995137906
Validation loss: 2.3410278416143306

Epoch: 5| Step: 10
Training loss: 2.71942875599668
Validation loss: 2.360483480837485

Epoch: 153| Step: 0
Training loss: 2.2659352057301603
Validation loss: 2.348440896144913

Epoch: 5| Step: 1
Training loss: 2.5356783336646638
Validation loss: 2.362930133730348

Epoch: 5| Step: 2
Training loss: 2.740539055306395
Validation loss: 2.3351454989505345

Epoch: 5| Step: 3
Training loss: 2.672117255756102
Validation loss: 2.356495189076433

Epoch: 5| Step: 4
Training loss: 2.3341163502174735
Validation loss: 2.373263199510131

Epoch: 5| Step: 5
Training loss: 2.568300891979116
Validation loss: 2.354080043603471

Epoch: 5| Step: 6
Training loss: 2.179539829297156
Validation loss: 2.3700395539424077

Epoch: 5| Step: 7
Training loss: 2.264549052503356
Validation loss: 2.362386268152188

Epoch: 5| Step: 8
Training loss: 1.9055132458360826
Validation loss: 2.3581916108467142

Epoch: 5| Step: 9
Training loss: 2.2823294607004914
Validation loss: 2.3804361232544418

Epoch: 5| Step: 10
Training loss: 2.537740509962463
Validation loss: 2.350937791652554

Epoch: 154| Step: 0
Training loss: 2.7791813218522945
Validation loss: 2.35792361257602

Epoch: 5| Step: 1
Training loss: 2.3695971622223384
Validation loss: 2.338061395591894

Epoch: 5| Step: 2
Training loss: 2.155941042672545
Validation loss: 2.352613094560193

Epoch: 5| Step: 3
Training loss: 2.669978578603015
Validation loss: 2.3685267236131944

Epoch: 5| Step: 4
Training loss: 2.5644737643757223
Validation loss: 2.3420164209308254

Epoch: 5| Step: 5
Training loss: 2.591606817341496
Validation loss: 2.3394230311936086

Epoch: 5| Step: 6
Training loss: 1.9701608718986068
Validation loss: 2.3493831555863642

Epoch: 5| Step: 7
Training loss: 2.36075213327567
Validation loss: 2.3279953566966074

Epoch: 5| Step: 8
Training loss: 1.8931101709580362
Validation loss: 2.3340671366223873

Epoch: 5| Step: 9
Training loss: 2.255965695208272
Validation loss: 2.3531632760240933

Epoch: 5| Step: 10
Training loss: 2.6300457189669157
Validation loss: 2.3385109014977066

Epoch: 155| Step: 0
Training loss: 2.132577289285289
Validation loss: 2.346441249390716

Epoch: 5| Step: 1
Training loss: 2.533165007152257
Validation loss: 2.3505354687303104

Epoch: 5| Step: 2
Training loss: 2.3177590239621457
Validation loss: 2.3316934638129196

Epoch: 5| Step: 3
Training loss: 2.1933682883974055
Validation loss: 2.352319883997896

Epoch: 5| Step: 4
Training loss: 2.750563390414982
Validation loss: 2.348494403123989

Epoch: 5| Step: 5
Training loss: 2.5352975015421135
Validation loss: 2.313899783095466

Epoch: 5| Step: 6
Training loss: 2.0794348926592625
Validation loss: 2.3421129291555207

Epoch: 5| Step: 7
Training loss: 2.6304913258412252
Validation loss: 2.3241925125109515

Epoch: 5| Step: 8
Training loss: 2.139420776234068
Validation loss: 2.327261545011749

Epoch: 5| Step: 9
Training loss: 2.3554829206404175
Validation loss: 2.31847041340919

Epoch: 5| Step: 10
Training loss: 2.7250878136160943
Validation loss: 2.3250207432996848

Epoch: 156| Step: 0
Training loss: 2.4610089972872924
Validation loss: 2.32689160301963

Epoch: 5| Step: 1
Training loss: 2.068038440044564
Validation loss: 2.3451837290444604

Epoch: 5| Step: 2
Training loss: 2.531672878027557
Validation loss: 2.3489308904175203

Epoch: 5| Step: 3
Training loss: 2.1740446162835085
Validation loss: 2.3452606266048917

Epoch: 5| Step: 4
Training loss: 2.69642594047714
Validation loss: 2.3561010944335794

Epoch: 5| Step: 5
Training loss: 2.3153610058416003
Validation loss: 2.3694288067708262

Epoch: 5| Step: 6
Training loss: 2.6969438563957504
Validation loss: 2.3301078356391485

Epoch: 5| Step: 7
Training loss: 2.389565226700508
Validation loss: 2.3705742590548744

Epoch: 5| Step: 8
Training loss: 2.2953844488928197
Validation loss: 2.3723243473969102

Epoch: 5| Step: 9
Training loss: 1.9729546349593712
Validation loss: 2.3510657080653026

Epoch: 5| Step: 10
Training loss: 2.337771917020722
Validation loss: 2.3670864862748093

Epoch: 157| Step: 0
Training loss: 2.7081477957531375
Validation loss: 2.3859917061810823

Epoch: 5| Step: 1
Training loss: 2.5248662252208987
Validation loss: 2.365911432704347

Epoch: 5| Step: 2
Training loss: 2.307992408263945
Validation loss: 2.3549922729954833

Epoch: 5| Step: 3
Training loss: 2.6310306484825285
Validation loss: 2.3464633038132092

Epoch: 5| Step: 4
Training loss: 2.051736896014279
Validation loss: 2.3625971547845874

Epoch: 5| Step: 5
Training loss: 2.3027169806913013
Validation loss: 2.3509125470035594

Epoch: 5| Step: 6
Training loss: 2.65735468613384
Validation loss: 2.3526731743591083

Epoch: 5| Step: 7
Training loss: 2.0123241513590253
Validation loss: 2.334848207912425

Epoch: 5| Step: 8
Training loss: 2.3377513158813077
Validation loss: 2.344497662042483

Epoch: 5| Step: 9
Training loss: 2.0871821772597037
Validation loss: 2.363265668166274

Epoch: 5| Step: 10
Training loss: 2.099182937254121
Validation loss: 2.368760905028445

Epoch: 158| Step: 0
Training loss: 2.2389398641070937
Validation loss: 2.347463150249775

Epoch: 5| Step: 1
Training loss: 2.2742284074143866
Validation loss: 2.360024600539512

Epoch: 5| Step: 2
Training loss: 2.8146901398183988
Validation loss: 2.34257057184059

Epoch: 5| Step: 3
Training loss: 2.346795201881488
Validation loss: 2.337668036013973

Epoch: 5| Step: 4
Training loss: 2.2421959002932255
Validation loss: 2.3556060111600114

Epoch: 5| Step: 5
Training loss: 2.0391996491007993
Validation loss: 2.3548521226772614

Epoch: 5| Step: 6
Training loss: 2.637070108244819
Validation loss: 2.3355932286230785

Epoch: 5| Step: 7
Training loss: 2.0863963561836556
Validation loss: 2.3444594908396397

Epoch: 5| Step: 8
Training loss: 2.3429619036323572
Validation loss: 2.34662450588517

Epoch: 5| Step: 9
Training loss: 2.3407309860863665
Validation loss: 2.336256666579369

Epoch: 5| Step: 10
Training loss: 2.7362125870615825
Validation loss: 2.330497871197095

Epoch: 159| Step: 0
Training loss: 2.3371450307664747
Validation loss: 2.353490040910292

Epoch: 5| Step: 1
Training loss: 2.147103856311473
Validation loss: 2.3437751894455214

Epoch: 5| Step: 2
Training loss: 2.4600640578574793
Validation loss: 2.31812025564274

Epoch: 5| Step: 3
Training loss: 2.2763937903984988
Validation loss: 2.3615001247813523

Epoch: 5| Step: 4
Training loss: 2.0953476916379628
Validation loss: 2.3371953038613693

Epoch: 5| Step: 5
Training loss: 2.410671580910245
Validation loss: 2.3352871173697034

Epoch: 5| Step: 6
Training loss: 2.9093762062799593
Validation loss: 2.3477461340756847

Epoch: 5| Step: 7
Training loss: 2.6118139872073534
Validation loss: 2.334779345887596

Epoch: 5| Step: 8
Training loss: 1.9893641792216403
Validation loss: 2.3167228079162494

Epoch: 5| Step: 9
Training loss: 2.1084178872423873
Validation loss: 2.3441072198599437

Epoch: 5| Step: 10
Training loss: 2.478536210451846
Validation loss: 2.335683764609056

Epoch: 160| Step: 0
Training loss: 2.4664128503720186
Validation loss: 2.328262926249895

Epoch: 5| Step: 1
Training loss: 2.588900709420843
Validation loss: 2.3360089315731685

Epoch: 5| Step: 2
Training loss: 2.160460079962274
Validation loss: 2.3459664554454447

Epoch: 5| Step: 3
Training loss: 2.2428523018483615
Validation loss: 2.352488428577578

Epoch: 5| Step: 4
Training loss: 2.7352291843831065
Validation loss: 2.3504466565952704

Epoch: 5| Step: 5
Training loss: 2.5164942217055053
Validation loss: 2.3436374924430767

Epoch: 5| Step: 6
Training loss: 2.347726931912264
Validation loss: 2.3595606733483834

Epoch: 5| Step: 7
Training loss: 2.236516180002525
Validation loss: 2.3601567658007054

Epoch: 5| Step: 8
Training loss: 2.1147309300317865
Validation loss: 2.3420442550083873

Epoch: 5| Step: 9
Training loss: 2.1844310485896505
Validation loss: 2.3348218054888945

Epoch: 5| Step: 10
Training loss: 2.26665205202814
Validation loss: 2.330217433528831

Epoch: 161| Step: 0
Training loss: 2.290155143479864
Validation loss: 2.3518749903352587

Epoch: 5| Step: 1
Training loss: 2.7203367141268227
Validation loss: 2.337264101835203

Epoch: 5| Step: 2
Training loss: 2.191623289406662
Validation loss: 2.348099445508123

Epoch: 5| Step: 3
Training loss: 1.525531444814374
Validation loss: 2.3488460657915717

Epoch: 5| Step: 4
Training loss: 2.5779912740531605
Validation loss: 2.3482077314967555

Epoch: 5| Step: 5
Training loss: 2.0268281196397737
Validation loss: 2.3643156544039137

Epoch: 5| Step: 6
Training loss: 2.7641632182487235
Validation loss: 2.316584898410916

Epoch: 5| Step: 7
Training loss: 2.303381701880278
Validation loss: 2.3340400366852814

Epoch: 5| Step: 8
Training loss: 2.5823833092824913
Validation loss: 2.3386146458563837

Epoch: 5| Step: 9
Training loss: 2.551307051533314
Validation loss: 2.337641261312957

Epoch: 5| Step: 10
Training loss: 1.9464492846745478
Validation loss: 2.340813730404912

Epoch: 162| Step: 0
Training loss: 2.8667193038306986
Validation loss: 2.3375068474494314

Epoch: 5| Step: 1
Training loss: 2.2255468360910786
Validation loss: 2.327685145905071

Epoch: 5| Step: 2
Training loss: 2.6190903763356586
Validation loss: 2.337871317763566

Epoch: 5| Step: 3
Training loss: 1.9997998375865964
Validation loss: 2.3329559524932595

Epoch: 5| Step: 4
Training loss: 2.4967345846366222
Validation loss: 2.3315595756961134

Epoch: 5| Step: 5
Training loss: 2.498134966408798
Validation loss: 2.3215557286909827

Epoch: 5| Step: 6
Training loss: 2.509906405645457
Validation loss: 2.345729743746581

Epoch: 5| Step: 7
Training loss: 2.277266381652386
Validation loss: 2.345151017356905

Epoch: 5| Step: 8
Training loss: 1.875558197855532
Validation loss: 2.357198005179946

Epoch: 5| Step: 9
Training loss: 2.237035594460895
Validation loss: 2.340178021985614

Epoch: 5| Step: 10
Training loss: 1.894522377858575
Validation loss: 2.3462161220356625

Epoch: 163| Step: 0
Training loss: 2.8207687051226076
Validation loss: 2.3485873284313654

Epoch: 5| Step: 1
Training loss: 2.2827349493599867
Validation loss: 2.3583039697795845

Epoch: 5| Step: 2
Training loss: 2.3136658693719014
Validation loss: 2.390614762573499

Epoch: 5| Step: 3
Training loss: 2.2477904172650818
Validation loss: 2.3385441007194254

Epoch: 5| Step: 4
Training loss: 2.280663610891023
Validation loss: 2.354125922486897

Epoch: 5| Step: 5
Training loss: 2.873622896188627
Validation loss: 2.3274475552350435

Epoch: 5| Step: 6
Training loss: 1.9094246865658233
Validation loss: 2.3652482405505135

Epoch: 5| Step: 7
Training loss: 2.0686688502319956
Validation loss: 2.3519666648285744

Epoch: 5| Step: 8
Training loss: 2.1199964069839834
Validation loss: 2.3304497491800102

Epoch: 5| Step: 9
Training loss: 2.264666018925663
Validation loss: 2.3316724120539307

Epoch: 5| Step: 10
Training loss: 2.4277220009866674
Validation loss: 2.336114259197911

Epoch: 164| Step: 0
Training loss: 2.5196357173109805
Validation loss: 2.339864103728726

Epoch: 5| Step: 1
Training loss: 1.9152342032102398
Validation loss: 2.346267667643737

Epoch: 5| Step: 2
Training loss: 2.303316180344275
Validation loss: 2.3328831823691227

Epoch: 5| Step: 3
Training loss: 2.3504228333264554
Validation loss: 2.343760807463637

Epoch: 5| Step: 4
Training loss: 2.4471136412802417
Validation loss: 2.335058327994404

Epoch: 5| Step: 5
Training loss: 2.527700596517227
Validation loss: 2.312659026722307

Epoch: 5| Step: 6
Training loss: 2.6783499980408862
Validation loss: 2.3335520279996973

Epoch: 5| Step: 7
Training loss: 2.141862942895717
Validation loss: 2.33664965209441

Epoch: 5| Step: 8
Training loss: 1.789761069563954
Validation loss: 2.340510168382605

Epoch: 5| Step: 9
Training loss: 2.501391023838173
Validation loss: 2.329439154452615

Epoch: 5| Step: 10
Training loss: 2.3529549465057005
Validation loss: 2.3229352090489965

Epoch: 165| Step: 0
Training loss: 2.283409977297149
Validation loss: 2.3195855924633118

Epoch: 5| Step: 1
Training loss: 1.9374583455191878
Validation loss: 2.3335284585127973

Epoch: 5| Step: 2
Training loss: 2.3180689384734925
Validation loss: 2.3189875830463063

Epoch: 5| Step: 3
Training loss: 2.9827942181721867
Validation loss: 2.3339408550203027

Epoch: 5| Step: 4
Training loss: 2.4228030487824834
Validation loss: 2.367876493337778

Epoch: 5| Step: 5
Training loss: 2.4710335129889383
Validation loss: 2.313517041704687

Epoch: 5| Step: 6
Training loss: 1.9654878504806288
Validation loss: 2.3548179699791767

Epoch: 5| Step: 7
Training loss: 2.243550594044157
Validation loss: 2.344875111033591

Epoch: 5| Step: 8
Training loss: 1.8916518520273662
Validation loss: 2.3517685350474413

Epoch: 5| Step: 9
Training loss: 2.3554579195244894
Validation loss: 2.387571021249233

Epoch: 5| Step: 10
Training loss: 2.5648317660360545
Validation loss: 2.3661518677738616

Epoch: 166| Step: 0
Training loss: 2.678557844581673
Validation loss: 2.3062784278509953

Epoch: 5| Step: 1
Training loss: 2.0923068638569067
Validation loss: 2.335606422219046

Epoch: 5| Step: 2
Training loss: 2.0046618488957106
Validation loss: 2.323405032142721

Epoch: 5| Step: 3
Training loss: 2.2508247771154046
Validation loss: 2.333006041692191

Epoch: 5| Step: 4
Training loss: 2.053106243448499
Validation loss: 2.3285390658135356

Epoch: 5| Step: 5
Training loss: 2.2567751920440675
Validation loss: 2.33207827389224

Epoch: 5| Step: 6
Training loss: 2.6137714924013054
Validation loss: 2.3188952200033963

Epoch: 5| Step: 7
Training loss: 2.223515295944975
Validation loss: 2.3076861546211944

Epoch: 5| Step: 8
Training loss: 2.351392670135352
Validation loss: 2.3209725629487976

Epoch: 5| Step: 9
Training loss: 2.569213261098786
Validation loss: 2.34217225707609

Epoch: 5| Step: 10
Training loss: 2.2680213619887932
Validation loss: 2.3540787030192667

Epoch: 167| Step: 0
Training loss: 2.791793640057985
Validation loss: 2.3207897298904814

Epoch: 5| Step: 1
Training loss: 2.510746555628736
Validation loss: 2.323965942498613

Epoch: 5| Step: 2
Training loss: 2.7415969082229674
Validation loss: 2.3300234271230855

Epoch: 5| Step: 3
Training loss: 1.6498009706159298
Validation loss: 2.338751187272621

Epoch: 5| Step: 4
Training loss: 2.241234766349359
Validation loss: 2.339161367577368

Epoch: 5| Step: 5
Training loss: 2.436681952509007
Validation loss: 2.3457028375648505

Epoch: 5| Step: 6
Training loss: 1.9803712960066344
Validation loss: 2.3572050048323283

Epoch: 5| Step: 7
Training loss: 1.817707014402186
Validation loss: 2.354939643032939

Epoch: 5| Step: 8
Training loss: 2.4577302893526407
Validation loss: 2.359779003867281

Epoch: 5| Step: 9
Training loss: 2.0865406778750435
Validation loss: 2.3529299675585813

Epoch: 5| Step: 10
Training loss: 2.412274337255183
Validation loss: 2.341877202887647

Epoch: 168| Step: 0
Training loss: 2.014772338311659
Validation loss: 2.346167069368515

Epoch: 5| Step: 1
Training loss: 2.677770434915158
Validation loss: 2.3399623528736977

Epoch: 5| Step: 2
Training loss: 2.19588541720713
Validation loss: 2.3504329513191977

Epoch: 5| Step: 3
Training loss: 1.9653754605061822
Validation loss: 2.3332301972561367

Epoch: 5| Step: 4
Training loss: 2.283289167807732
Validation loss: 2.307608457661131

Epoch: 5| Step: 5
Training loss: 1.998988670713944
Validation loss: 2.3642342530991107

Epoch: 5| Step: 6
Training loss: 2.145236540336604
Validation loss: 2.3675147320827548

Epoch: 5| Step: 7
Training loss: 2.231814537970611
Validation loss: 2.3052755971962196

Epoch: 5| Step: 8
Training loss: 2.3180415796166263
Validation loss: 2.3279404111071202

Epoch: 5| Step: 9
Training loss: 2.803922586082557
Validation loss: 2.3175642771863103

Epoch: 5| Step: 10
Training loss: 2.692445418744131
Validation loss: 2.304955465131986

Epoch: 169| Step: 0
Training loss: 2.2006771476046874
Validation loss: 2.2974101828431133

Epoch: 5| Step: 1
Training loss: 2.0475232211741967
Validation loss: 2.313011226002386

Epoch: 5| Step: 2
Training loss: 2.1613865361679356
Validation loss: 2.3365209014673884

Epoch: 5| Step: 3
Training loss: 2.356358399667658
Validation loss: 2.334390224738745

Epoch: 5| Step: 4
Training loss: 2.7050208350770024
Validation loss: 2.331897298824032

Epoch: 5| Step: 5
Training loss: 2.238975643541717
Validation loss: 2.344239220098692

Epoch: 5| Step: 6
Training loss: 1.922805064866006
Validation loss: 2.2945910744036215

Epoch: 5| Step: 7
Training loss: 2.544062084951907
Validation loss: 2.2945309111727488

Epoch: 5| Step: 8
Training loss: 1.8640815727492404
Validation loss: 2.3071967979295436

Epoch: 5| Step: 9
Training loss: 2.5325052422095493
Validation loss: 2.3491668201194424

Epoch: 5| Step: 10
Training loss: 2.7598475223384384
Validation loss: 2.310405508817587

Epoch: 170| Step: 0
Training loss: 2.6421017101037583
Validation loss: 2.3365091174641557

Epoch: 5| Step: 1
Training loss: 2.0865162250208815
Validation loss: 2.355858851185121

Epoch: 5| Step: 2
Training loss: 2.200601092498239
Validation loss: 2.3337654004526778

Epoch: 5| Step: 3
Training loss: 2.3103221226144415
Validation loss: 2.328283942771445

Epoch: 5| Step: 4
Training loss: 2.284918565697184
Validation loss: 2.333910111769742

Epoch: 5| Step: 5
Training loss: 2.213914141264321
Validation loss: 2.338620472816736

Epoch: 5| Step: 6
Training loss: 1.9937511216880968
Validation loss: 2.3566811219480006

Epoch: 5| Step: 7
Training loss: 2.1817906668763167
Validation loss: 2.3417701633799917

Epoch: 5| Step: 8
Training loss: 2.2906043162329284
Validation loss: 2.3228819410554813

Epoch: 5| Step: 9
Training loss: 2.4085952427179227
Validation loss: 2.334136561133227

Epoch: 5| Step: 10
Training loss: 2.4736219210861194
Validation loss: 2.3473947254562546

Epoch: 171| Step: 0
Training loss: 2.1650393928661793
Validation loss: 2.3259179946148056

Epoch: 5| Step: 1
Training loss: 2.396309072833967
Validation loss: 2.3215098996381407

Epoch: 5| Step: 2
Training loss: 2.5326762949368997
Validation loss: 2.343631006863968

Epoch: 5| Step: 3
Training loss: 2.2303428280320943
Validation loss: 2.3098235635027504

Epoch: 5| Step: 4
Training loss: 2.0834607911857144
Validation loss: 2.3097895852054826

Epoch: 5| Step: 5
Training loss: 2.414853555887109
Validation loss: 2.324691207955988

Epoch: 5| Step: 6
Training loss: 2.733490370294395
Validation loss: 2.3449789488165207

Epoch: 5| Step: 7
Training loss: 1.9878661915976692
Validation loss: 2.3126560259428484

Epoch: 5| Step: 8
Training loss: 2.3398790054339993
Validation loss: 2.303542242300328

Epoch: 5| Step: 9
Training loss: 2.1823455027006973
Validation loss: 2.3424571036422606

Epoch: 5| Step: 10
Training loss: 2.0669563008465794
Validation loss: 2.333263570501463

Epoch: 172| Step: 0
Training loss: 2.2744179410725303
Validation loss: 2.3296282932577714

Epoch: 5| Step: 1
Training loss: 2.2849977617649326
Validation loss: 2.350620996919004

Epoch: 5| Step: 2
Training loss: 2.5208450085918668
Validation loss: 2.304562525265916

Epoch: 5| Step: 3
Training loss: 1.8280808533122785
Validation loss: 2.3148432103697627

Epoch: 5| Step: 4
Training loss: 2.590392087766923
Validation loss: 2.333041592200959

Epoch: 5| Step: 5
Training loss: 2.012202588016054
Validation loss: 2.3251392891300147

Epoch: 5| Step: 6
Training loss: 2.041118068040623
Validation loss: 2.344761350911548

Epoch: 5| Step: 7
Training loss: 2.157918754243206
Validation loss: 2.3462476388056404

Epoch: 5| Step: 8
Training loss: 2.691057733523882
Validation loss: 2.326140561229751

Epoch: 5| Step: 9
Training loss: 2.180359986181649
Validation loss: 2.364022156956934

Epoch: 5| Step: 10
Training loss: 2.3787240395505003
Validation loss: 2.3498932687875116

Epoch: 173| Step: 0
Training loss: 2.399898121578814
Validation loss: 2.3528645717111174

Epoch: 5| Step: 1
Training loss: 2.164445533319174
Validation loss: 2.36548796434146

Epoch: 5| Step: 2
Training loss: 2.586731941376154
Validation loss: 2.330166170987492

Epoch: 5| Step: 3
Training loss: 2.5898287443298784
Validation loss: 2.345564802327386

Epoch: 5| Step: 4
Training loss: 2.0943830301784843
Validation loss: 2.305977054458914

Epoch: 5| Step: 5
Training loss: 2.053735780951139
Validation loss: 2.327791475712776

Epoch: 5| Step: 6
Training loss: 2.464284213679708
Validation loss: 2.3049070270061778

Epoch: 5| Step: 7
Training loss: 2.3219353238018283
Validation loss: 2.3405684909116005

Epoch: 5| Step: 8
Training loss: 1.8907149742722666
Validation loss: 2.3365580064256912

Epoch: 5| Step: 9
Training loss: 2.0341192081743795
Validation loss: 2.3148965387536595

Epoch: 5| Step: 10
Training loss: 2.1362925772221333
Validation loss: 2.316548011375156

Epoch: 174| Step: 0
Training loss: 1.4827625551645716
Validation loss: 2.3534828591894414

Epoch: 5| Step: 1
Training loss: 1.930533590428139
Validation loss: 2.341013333791838

Epoch: 5| Step: 2
Training loss: 2.1994514951983426
Validation loss: 2.3347675574865234

Epoch: 5| Step: 3
Training loss: 2.3816861852011133
Validation loss: 2.343694899263395

Epoch: 5| Step: 4
Training loss: 2.636131300300096
Validation loss: 2.3378393700613826

Epoch: 5| Step: 5
Training loss: 2.513381526275857
Validation loss: 2.306321423828522

Epoch: 5| Step: 6
Training loss: 2.1887388808372665
Validation loss: 2.3020379499970387

Epoch: 5| Step: 7
Training loss: 2.161678060983448
Validation loss: 2.3473260846060486

Epoch: 5| Step: 8
Training loss: 2.6249801998299933
Validation loss: 2.3402425218799046

Epoch: 5| Step: 9
Training loss: 2.005799705858482
Validation loss: 2.322409229834962

Epoch: 5| Step: 10
Training loss: 2.5213266525758335
Validation loss: 2.3482511519196256

Epoch: 175| Step: 0
Training loss: 2.145038148767515
Validation loss: 2.3246729170489147

Epoch: 5| Step: 1
Training loss: 2.5111531381644148
Validation loss: 2.3070881271686607

Epoch: 5| Step: 2
Training loss: 2.2859129606482544
Validation loss: 2.350580892198691

Epoch: 5| Step: 3
Training loss: 2.1804613496660967
Validation loss: 2.359160954344929

Epoch: 5| Step: 4
Training loss: 2.257809437680395
Validation loss: 2.3237285502086866

Epoch: 5| Step: 5
Training loss: 2.2289974350433175
Validation loss: 2.3661903770254726

Epoch: 5| Step: 6
Training loss: 1.9995294255740705
Validation loss: 2.322744014251515

Epoch: 5| Step: 7
Training loss: 2.480085784905087
Validation loss: 2.355741423000387

Epoch: 5| Step: 8
Training loss: 2.0217145853215666
Validation loss: 2.375077686215833

Epoch: 5| Step: 9
Training loss: 2.18509912890125
Validation loss: 2.3308142704200114

Epoch: 5| Step: 10
Training loss: 2.394952186314258
Validation loss: 2.3530349169035496

Epoch: 176| Step: 0
Training loss: 2.1233889138429523
Validation loss: 2.367725580959275

Epoch: 5| Step: 1
Training loss: 2.0639257416045544
Validation loss: 2.3335216097601643

Epoch: 5| Step: 2
Training loss: 2.4172643273244896
Validation loss: 2.351485032283577

Epoch: 5| Step: 3
Training loss: 2.1950685630291655
Validation loss: 2.3236944426044555

Epoch: 5| Step: 4
Training loss: 2.2003894894619163
Validation loss: 2.3334036529363553

Epoch: 5| Step: 5
Training loss: 2.5969436471176905
Validation loss: 2.3259577067558976

Epoch: 5| Step: 6
Training loss: 1.8568623338779016
Validation loss: 2.3466959759391175

Epoch: 5| Step: 7
Training loss: 2.953707037188293
Validation loss: 2.3113956103539457

Epoch: 5| Step: 8
Training loss: 1.5061600084449256
Validation loss: 2.3029274392187222

Epoch: 5| Step: 9
Training loss: 2.6232349274374167
Validation loss: 2.3219587382579854

Epoch: 5| Step: 10
Training loss: 2.153327066493093
Validation loss: 2.3301406418883595

Epoch: 177| Step: 0
Training loss: 2.114245182554655
Validation loss: 2.326360067247076

Epoch: 5| Step: 1
Training loss: 2.5128449426214026
Validation loss: 2.3459317679577043

Epoch: 5| Step: 2
Training loss: 2.3614442353458083
Validation loss: 2.312188254697539

Epoch: 5| Step: 3
Training loss: 2.278610374538095
Validation loss: 2.33311906027028

Epoch: 5| Step: 4
Training loss: 2.2548811207496904
Validation loss: 2.312029967337977

Epoch: 5| Step: 5
Training loss: 2.0011108412958065
Validation loss: 2.2930932766285563

Epoch: 5| Step: 6
Training loss: 2.1257301646875937
Validation loss: 2.3319835446687454

Epoch: 5| Step: 7
Training loss: 2.322826321018157
Validation loss: 2.315545579511686

Epoch: 5| Step: 8
Training loss: 2.120483198160943
Validation loss: 2.3481271026681485

Epoch: 5| Step: 9
Training loss: 1.6752645767550052
Validation loss: 2.332636551896829

Epoch: 5| Step: 10
Training loss: 2.9967174055014025
Validation loss: 2.32715647217471

Epoch: 178| Step: 0
Training loss: 1.962376708513203
Validation loss: 2.3040140282071118

Epoch: 5| Step: 1
Training loss: 2.5234411847822846
Validation loss: 2.3263867310014157

Epoch: 5| Step: 2
Training loss: 2.1684127765306553
Validation loss: 2.317146311845358

Epoch: 5| Step: 3
Training loss: 2.653516821802735
Validation loss: 2.33712985275647

Epoch: 5| Step: 4
Training loss: 1.8534475139166666
Validation loss: 2.314538685065351

Epoch: 5| Step: 5
Training loss: 2.2007331580180938
Validation loss: 2.3263603917850206

Epoch: 5| Step: 6
Training loss: 2.1657138954842363
Validation loss: 2.3495034728339195

Epoch: 5| Step: 7
Training loss: 1.9368381600386138
Validation loss: 2.341410388380569

Epoch: 5| Step: 8
Training loss: 2.101306318246587
Validation loss: 2.3387584279325493

Epoch: 5| Step: 9
Training loss: 2.1568819308660103
Validation loss: 2.3362519711067096

Epoch: 5| Step: 10
Training loss: 2.8160387452830444
Validation loss: 2.324678627321018

Epoch: 179| Step: 0
Training loss: 2.349355885315526
Validation loss: 2.3644016686316376

Epoch: 5| Step: 1
Training loss: 2.4893801192552556
Validation loss: 2.325979868877912

Epoch: 5| Step: 2
Training loss: 2.062106008178252
Validation loss: 2.349785073566229

Epoch: 5| Step: 3
Training loss: 2.474532007996634
Validation loss: 2.3196344546060796

Epoch: 5| Step: 4
Training loss: 2.1221820996715293
Validation loss: 2.350539070094768

Epoch: 5| Step: 5
Training loss: 2.293673717259353
Validation loss: 2.3408443933916634

Epoch: 5| Step: 6
Training loss: 2.409596085949742
Validation loss: 2.3031939823580827

Epoch: 5| Step: 7
Training loss: 1.701552969185135
Validation loss: 2.3311699533910044

Epoch: 5| Step: 8
Training loss: 2.3826060721610856
Validation loss: 2.3506705237556305

Epoch: 5| Step: 9
Training loss: 2.024111602314825
Validation loss: 2.337815879986467

Epoch: 5| Step: 10
Training loss: 1.8208165596451977
Validation loss: 2.32775983736045

Epoch: 180| Step: 0
Training loss: 1.9849942660308963
Validation loss: 2.348064003427278

Epoch: 5| Step: 1
Training loss: 2.259292276010331
Validation loss: 2.339404936014094

Epoch: 5| Step: 2
Training loss: 2.4050769671458556
Validation loss: 2.323271160721554

Epoch: 5| Step: 3
Training loss: 2.0075134767148874
Validation loss: 2.323665790748795

Epoch: 5| Step: 4
Training loss: 2.20939037528077
Validation loss: 2.3097241927244716

Epoch: 5| Step: 5
Training loss: 2.19994389722555
Validation loss: 2.325761094715697

Epoch: 5| Step: 6
Training loss: 1.8286867501304152
Validation loss: 2.3207368777163695

Epoch: 5| Step: 7
Training loss: 2.2688859294598482
Validation loss: 2.2890001827701476

Epoch: 5| Step: 8
Training loss: 2.5522743516915436
Validation loss: 2.3069024256396538

Epoch: 5| Step: 9
Training loss: 2.26997977730906
Validation loss: 2.304735732508055

Epoch: 5| Step: 10
Training loss: 2.575870059527094
Validation loss: 2.2902713724883883

Epoch: 181| Step: 0
Training loss: 2.134368329016787
Validation loss: 2.3140274763422095

Epoch: 5| Step: 1
Training loss: 2.5933806374688504
Validation loss: 2.3050967401509066

Epoch: 5| Step: 2
Training loss: 2.043343795865744
Validation loss: 2.300460217244913

Epoch: 5| Step: 3
Training loss: 2.122097389129202
Validation loss: 2.3131520522416067

Epoch: 5| Step: 4
Training loss: 1.6415211001436432
Validation loss: 2.2842878628484073

Epoch: 5| Step: 5
Training loss: 2.3651075636293206
Validation loss: 2.291079548515867

Epoch: 5| Step: 6
Training loss: 2.1309282971782144
Validation loss: 2.2901064035063383

Epoch: 5| Step: 7
Training loss: 2.356332497202342
Validation loss: 2.311165872386661

Epoch: 5| Step: 8
Training loss: 2.504536422961185
Validation loss: 2.2965159657035836

Epoch: 5| Step: 9
Training loss: 1.9125158172152807
Validation loss: 2.336020149626019

Epoch: 5| Step: 10
Training loss: 2.3361217209248335
Validation loss: 2.349122976820292

Epoch: 182| Step: 0
Training loss: 2.054606040819308
Validation loss: 2.3312780107438895

Epoch: 5| Step: 1
Training loss: 2.591089561784289
Validation loss: 2.3189486459060067

Epoch: 5| Step: 2
Training loss: 2.0100993036060846
Validation loss: 2.350007236480917

Epoch: 5| Step: 3
Training loss: 2.2028862573573798
Validation loss: 2.3288575037480967

Epoch: 5| Step: 4
Training loss: 2.2055818102427267
Validation loss: 2.314092593783845

Epoch: 5| Step: 5
Training loss: 2.163524464401257
Validation loss: 2.319146776206642

Epoch: 5| Step: 6
Training loss: 1.8074583110512825
Validation loss: 2.3407951744921176

Epoch: 5| Step: 7
Training loss: 2.165657089458041
Validation loss: 2.3397419578822922

Epoch: 5| Step: 8
Training loss: 2.205189488372023
Validation loss: 2.314881567039267

Epoch: 5| Step: 9
Training loss: 2.305788973082991
Validation loss: 2.3063575918509294

Epoch: 5| Step: 10
Training loss: 2.7083221044063093
Validation loss: 2.3047978645375125

Epoch: 183| Step: 0
Training loss: 1.9889091294725036
Validation loss: 2.329231221277455

Epoch: 5| Step: 1
Training loss: 2.6237370313784614
Validation loss: 2.3226876268482273

Epoch: 5| Step: 2
Training loss: 2.213046089495693
Validation loss: 2.368606297606594

Epoch: 5| Step: 3
Training loss: 1.7575205242537617
Validation loss: 2.278728348370361

Epoch: 5| Step: 4
Training loss: 2.6271154871119182
Validation loss: 2.324151555757734

Epoch: 5| Step: 5
Training loss: 1.9183875595877722
Validation loss: 2.2823294371121117

Epoch: 5| Step: 6
Training loss: 2.1548707393106454
Validation loss: 2.32502628456666

Epoch: 5| Step: 7
Training loss: 2.189829648503584
Validation loss: 2.3174709481019504

Epoch: 5| Step: 8
Training loss: 1.5458397531847359
Validation loss: 2.3439774039912953

Epoch: 5| Step: 9
Training loss: 2.3405394881025683
Validation loss: 2.3542325461365516

Epoch: 5| Step: 10
Training loss: 2.8691899845247897
Validation loss: 2.2770182768287586

Epoch: 184| Step: 0
Training loss: 1.9455701665016794
Validation loss: 2.3417646995024777

Epoch: 5| Step: 1
Training loss: 1.8692389674609198
Validation loss: 2.3385305701530905

Epoch: 5| Step: 2
Training loss: 2.172868240806777
Validation loss: 2.3459911457352733

Epoch: 5| Step: 3
Training loss: 2.3080857907354786
Validation loss: 2.3214351859951248

Epoch: 5| Step: 4
Training loss: 1.7763253113192135
Validation loss: 2.36298994850287

Epoch: 5| Step: 5
Training loss: 2.433608837295227
Validation loss: 2.3479912123932407

Epoch: 5| Step: 6
Training loss: 2.397883049811844
Validation loss: 2.3576164980534884

Epoch: 5| Step: 7
Training loss: 2.0402967437261954
Validation loss: 2.3095665495711177

Epoch: 5| Step: 8
Training loss: 2.1065281624875154
Validation loss: 2.3372504761098947

Epoch: 5| Step: 9
Training loss: 2.829444198217239
Validation loss: 2.320849963000254

Epoch: 5| Step: 10
Training loss: 2.3298495261265457
Validation loss: 2.3237508361914108

Epoch: 185| Step: 0
Training loss: 2.074641240370276
Validation loss: 2.320110263755448

Epoch: 5| Step: 1
Training loss: 2.379769405125174
Validation loss: 2.331575367221453

Epoch: 5| Step: 2
Training loss: 2.586572759224729
Validation loss: 2.3071045817872364

Epoch: 5| Step: 3
Training loss: 1.8182609031556995
Validation loss: 2.3158625749946142

Epoch: 5| Step: 4
Training loss: 2.466564321542645
Validation loss: 2.3362455286702306

Epoch: 5| Step: 5
Training loss: 1.7686371217975903
Validation loss: 2.3292725586765584

Epoch: 5| Step: 6
Training loss: 1.702653872220554
Validation loss: 2.287355871942538

Epoch: 5| Step: 7
Training loss: 2.0645117918284295
Validation loss: 2.3266892202318297

Epoch: 5| Step: 8
Training loss: 2.0722838031571924
Validation loss: 2.327027874940684

Epoch: 5| Step: 9
Training loss: 2.307675458161879
Validation loss: 2.3032679147703825

Epoch: 5| Step: 10
Training loss: 2.926748525854886
Validation loss: 2.3352501294433186

Epoch: 186| Step: 0
Training loss: 2.3500707209882514
Validation loss: 2.2902943119997863

Epoch: 5| Step: 1
Training loss: 2.497291146405595
Validation loss: 2.3477573255285713

Epoch: 5| Step: 2
Training loss: 2.1232476582551865
Validation loss: 2.304345863567689

Epoch: 5| Step: 3
Training loss: 2.3982868954967778
Validation loss: 2.3023117743497

Epoch: 5| Step: 4
Training loss: 2.1938344520767505
Validation loss: 2.329007016008146

Epoch: 5| Step: 5
Training loss: 2.420020987364504
Validation loss: 2.3508054619682577

Epoch: 5| Step: 6
Training loss: 1.9337161863461654
Validation loss: 2.2958728891468407

Epoch: 5| Step: 7
Training loss: 1.570218211517433
Validation loss: 2.3207008862931113

Epoch: 5| Step: 8
Training loss: 2.266895648198606
Validation loss: 2.2847153688394846

Epoch: 5| Step: 9
Training loss: 2.1088591898635904
Validation loss: 2.302604694951236

Epoch: 5| Step: 10
Training loss: 2.2205941501474755
Validation loss: 2.296256650634522

Epoch: 187| Step: 0
Training loss: 2.2243973762434996
Validation loss: 2.3035399892081516

Epoch: 5| Step: 1
Training loss: 2.3825173116977663
Validation loss: 2.3067570763805985

Epoch: 5| Step: 2
Training loss: 2.567133273610141
Validation loss: 2.289353411503348

Epoch: 5| Step: 3
Training loss: 2.0709956355617627
Validation loss: 2.3192861295143494

Epoch: 5| Step: 4
Training loss: 2.0302622814523343
Validation loss: 2.3392095621727256

Epoch: 5| Step: 5
Training loss: 2.1567198752787444
Validation loss: 2.3299123264284756

Epoch: 5| Step: 6
Training loss: 2.0602953138058466
Validation loss: 2.3182875809616785

Epoch: 5| Step: 7
Training loss: 2.3737038538878252
Validation loss: 2.318518517307592

Epoch: 5| Step: 8
Training loss: 2.313084193490487
Validation loss: 2.3542923602903536

Epoch: 5| Step: 9
Training loss: 2.0968653717047365
Validation loss: 2.3451235415480056

Epoch: 5| Step: 10
Training loss: 1.893043358529418
Validation loss: 2.3339861818618015

Epoch: 188| Step: 0
Training loss: 2.2628358707556577
Validation loss: 2.3557258837968855

Epoch: 5| Step: 1
Training loss: 2.4434723679283934
Validation loss: 2.3289630386663136

Epoch: 5| Step: 2
Training loss: 2.349208223593965
Validation loss: 2.3044153107344996

Epoch: 5| Step: 3
Training loss: 2.342921403010266
Validation loss: 2.3209010253756177

Epoch: 5| Step: 4
Training loss: 2.012955072734464
Validation loss: 2.3215138607546177

Epoch: 5| Step: 5
Training loss: 2.7765208982357477
Validation loss: 2.2990266143726057

Epoch: 5| Step: 6
Training loss: 2.247795508522144
Validation loss: 2.3067032736393203

Epoch: 5| Step: 7
Training loss: 2.0260750212943353
Validation loss: 2.312151545883818

Epoch: 5| Step: 8
Training loss: 1.819745216875882
Validation loss: 2.316435772991396

Epoch: 5| Step: 9
Training loss: 1.59685602643411
Validation loss: 2.2877346691070124

Epoch: 5| Step: 10
Training loss: 2.20999082105983
Validation loss: 2.3278912778409655

Epoch: 189| Step: 0
Training loss: 2.5889154441937765
Validation loss: 2.344755502584657

Epoch: 5| Step: 1
Training loss: 2.1720725868418316
Validation loss: 2.3075798038270836

Epoch: 5| Step: 2
Training loss: 2.5898238651668746
Validation loss: 2.281441041524518

Epoch: 5| Step: 3
Training loss: 2.4124236732228392
Validation loss: 2.3564983983911643

Epoch: 5| Step: 4
Training loss: 1.73082176723788
Validation loss: 2.3094228133081005

Epoch: 5| Step: 5
Training loss: 1.7267725199700963
Validation loss: 2.381965580030526

Epoch: 5| Step: 6
Training loss: 2.5599161472594676
Validation loss: 2.315322529227334

Epoch: 5| Step: 7
Training loss: 2.117249322530557
Validation loss: 2.3489385455367877

Epoch: 5| Step: 8
Training loss: 2.0571232851550607
Validation loss: 2.317290947499029

Epoch: 5| Step: 9
Training loss: 2.2915989490098454
Validation loss: 2.32952591059513

Epoch: 5| Step: 10
Training loss: 1.6238763298714582
Validation loss: 2.382774243248574

Epoch: 190| Step: 0
Training loss: 2.030898195758927
Validation loss: 2.320847145131225

Epoch: 5| Step: 1
Training loss: 2.0363188660874174
Validation loss: 2.3034539148738338

Epoch: 5| Step: 2
Training loss: 1.978016857306812
Validation loss: 2.3481953751107922

Epoch: 5| Step: 3
Training loss: 2.5963685938601064
Validation loss: 2.326823207903111

Epoch: 5| Step: 4
Training loss: 1.9375859518367191
Validation loss: 2.3205686540863333

Epoch: 5| Step: 5
Training loss: 2.3099155934093214
Validation loss: 2.3001794183757305

Epoch: 5| Step: 6
Training loss: 2.44545699110099
Validation loss: 2.3213180043275234

Epoch: 5| Step: 7
Training loss: 2.447360415194618
Validation loss: 2.307812582603034

Epoch: 5| Step: 8
Training loss: 1.9429186450616311
Validation loss: 2.345251643364883

Epoch: 5| Step: 9
Training loss: 2.1434136485491133
Validation loss: 2.30131550437282

Epoch: 5| Step: 10
Training loss: 2.15878235651892
Validation loss: 2.3355419836381786

Epoch: 191| Step: 0
Training loss: 2.2620948386577497
Validation loss: 2.288807464271784

Epoch: 5| Step: 1
Training loss: 2.62103335087824
Validation loss: 2.337591662958634

Epoch: 5| Step: 2
Training loss: 2.327146593382085
Validation loss: 2.3033541229377366

Epoch: 5| Step: 3
Training loss: 1.894617011891817
Validation loss: 2.3299643928165716

Epoch: 5| Step: 4
Training loss: 2.0849801484770683
Validation loss: 2.3171146006105863

Epoch: 5| Step: 5
Training loss: 1.9210460084472327
Validation loss: 2.312574469374165

Epoch: 5| Step: 6
Training loss: 2.0379918821133853
Validation loss: 2.2848767949964475

Epoch: 5| Step: 7
Training loss: 2.275640619649193
Validation loss: 2.2963024924603337

Epoch: 5| Step: 8
Training loss: 2.257587989283676
Validation loss: 2.301513468450229

Epoch: 5| Step: 9
Training loss: 2.0590343836191822
Validation loss: 2.3131471874025697

Epoch: 5| Step: 10
Training loss: 1.7999558946716059
Validation loss: 2.3268454030978782

Epoch: 192| Step: 0
Training loss: 1.8151966948894809
Validation loss: 2.3081576321982236

Epoch: 5| Step: 1
Training loss: 1.9574424935927637
Validation loss: 2.364620745295467

Epoch: 5| Step: 2
Training loss: 2.040252338398268
Validation loss: 2.313831301992685

Epoch: 5| Step: 3
Training loss: 2.772202595616009
Validation loss: 2.357592145904361

Epoch: 5| Step: 4
Training loss: 1.9352952040988622
Validation loss: 2.3129430333739007

Epoch: 5| Step: 5
Training loss: 2.0361415945179315
Validation loss: 2.3017549384014506

Epoch: 5| Step: 6
Training loss: 2.2569190768911076
Validation loss: 2.318508659760766

Epoch: 5| Step: 7
Training loss: 2.2532600521082244
Validation loss: 2.294055922276482

Epoch: 5| Step: 8
Training loss: 1.851762012404101
Validation loss: 2.316724485491911

Epoch: 5| Step: 9
Training loss: 2.4229422894011643
Validation loss: 2.3370727113869414

Epoch: 5| Step: 10
Training loss: 2.0993623810025746
Validation loss: 2.310481492301726

Epoch: 193| Step: 0
Training loss: 1.8008647245642326
Validation loss: 2.2908011378380726

Epoch: 5| Step: 1
Training loss: 2.4013267783619687
Validation loss: 2.2864553478755085

Epoch: 5| Step: 2
Training loss: 1.8877345918297608
Validation loss: 2.3051192318461795

Epoch: 5| Step: 3
Training loss: 2.065000925133154
Validation loss: 2.316364018940098

Epoch: 5| Step: 4
Training loss: 2.316137185640678
Validation loss: 2.317764499081011

Epoch: 5| Step: 5
Training loss: 2.0176459538301867
Validation loss: 2.319197892662503

Epoch: 5| Step: 6
Training loss: 2.0495483179960146
Validation loss: 2.295651624942099

Epoch: 5| Step: 7
Training loss: 2.4255395544660865
Validation loss: 2.296016987964603

Epoch: 5| Step: 8
Training loss: 2.367855166709978
Validation loss: 2.3145423723456426

Epoch: 5| Step: 9
Training loss: 2.166793587219484
Validation loss: 2.3415272772781566

Epoch: 5| Step: 10
Training loss: 2.178419612624481
Validation loss: 2.3264835195365836

Epoch: 194| Step: 0
Training loss: 2.0113534540154747
Validation loss: 2.323496760779094

Epoch: 5| Step: 1
Training loss: 1.951281234227298
Validation loss: 2.3310364729199997

Epoch: 5| Step: 2
Training loss: 2.4669852407606947
Validation loss: 2.324984808819369

Epoch: 5| Step: 3
Training loss: 1.7298321037186424
Validation loss: 2.3981710124714017

Epoch: 5| Step: 4
Training loss: 2.693625101614795
Validation loss: 2.3033789594714618

Epoch: 5| Step: 5
Training loss: 2.0416263524441454
Validation loss: 2.32619000974863

Epoch: 5| Step: 6
Training loss: 2.3700607538282976
Validation loss: 2.3156651722504193

Epoch: 5| Step: 7
Training loss: 1.7458792262391822
Validation loss: 2.3373628951539636

Epoch: 5| Step: 8
Training loss: 2.471757240239278
Validation loss: 2.336832251924975

Epoch: 5| Step: 9
Training loss: 2.363366395031267
Validation loss: 2.311557667574176

Epoch: 5| Step: 10
Training loss: 1.4997716570939195
Validation loss: 2.314938991492846

Epoch: 195| Step: 0
Training loss: 1.7945814671214066
Validation loss: 2.321590143229147

Epoch: 5| Step: 1
Training loss: 2.1826642673543715
Validation loss: 2.330910933398218

Epoch: 5| Step: 2
Training loss: 1.9159800986010982
Validation loss: 2.2904708803965423

Epoch: 5| Step: 3
Training loss: 2.3210349451382104
Validation loss: 2.308410015352571

Epoch: 5| Step: 4
Training loss: 2.2529957219678796
Validation loss: 2.3403828191830582

Epoch: 5| Step: 5
Training loss: 2.34780492327699
Validation loss: 2.2799584945249953

Epoch: 5| Step: 6
Training loss: 1.6467545582922634
Validation loss: 2.3037133990805585

Epoch: 5| Step: 7
Training loss: 2.1364898838024224
Validation loss: 2.3141293637560345

Epoch: 5| Step: 8
Training loss: 1.914991628165409
Validation loss: 2.265326564370913

Epoch: 5| Step: 9
Training loss: 2.3960730612414824
Validation loss: 2.3045042765683346

Epoch: 5| Step: 10
Training loss: 2.8019227238304385
Validation loss: 2.3371185906685756

Epoch: 196| Step: 0
Training loss: 2.639462277096063
Validation loss: 2.284129555107386

Epoch: 5| Step: 1
Training loss: 1.9156638784025968
Validation loss: 2.3452800828861595

Epoch: 5| Step: 2
Training loss: 2.4399742870852066
Validation loss: 2.340813413894382

Epoch: 5| Step: 3
Training loss: 1.9311608624180001
Validation loss: 2.2945131814971984

Epoch: 5| Step: 4
Training loss: 1.8867346089646304
Validation loss: 2.343532752903286

Epoch: 5| Step: 5
Training loss: 1.9838378058977637
Validation loss: 2.352921174853796

Epoch: 5| Step: 6
Training loss: 2.2852153020548425
Validation loss: 2.2828860920568683

Epoch: 5| Step: 7
Training loss: 2.0062313756345667
Validation loss: 2.314411858541715

Epoch: 5| Step: 8
Training loss: 2.3784504972209772
Validation loss: 2.3256555324471937

Epoch: 5| Step: 9
Training loss: 1.966132285637738
Validation loss: 2.2999870263367317

Epoch: 5| Step: 10
Training loss: 1.9697030803167708
Validation loss: 2.364678507852712

Epoch: 197| Step: 0
Training loss: 1.6143236833392007
Validation loss: 2.3208833833729723

Epoch: 5| Step: 1
Training loss: 1.9218832496528035
Validation loss: 2.307605071479058

Epoch: 5| Step: 2
Training loss: 2.0137021851501564
Validation loss: 2.3358848050842114

Epoch: 5| Step: 3
Training loss: 2.4736212463951865
Validation loss: 2.335805044885274

Epoch: 5| Step: 4
Training loss: 2.1044426790507744
Validation loss: 2.3436293097154515

Epoch: 5| Step: 5
Training loss: 1.779036501813939
Validation loss: 2.336303687722615

Epoch: 5| Step: 6
Training loss: 2.2830624630871723
Validation loss: 2.372879916003413

Epoch: 5| Step: 7
Training loss: 2.353898317239475
Validation loss: 2.3180273139094862

Epoch: 5| Step: 8
Training loss: 1.6368704568480155
Validation loss: 2.37261657635213

Epoch: 5| Step: 9
Training loss: 2.439378063797157
Validation loss: 2.303749145118081

Epoch: 5| Step: 10
Training loss: 2.4239215694492486
Validation loss: 2.313209760676489

Epoch: 198| Step: 0
Training loss: 2.155704816367505
Validation loss: 2.3136075113496966

Epoch: 5| Step: 1
Training loss: 2.168643440904774
Validation loss: 2.2940376061415755

Epoch: 5| Step: 2
Training loss: 2.1483774627619936
Validation loss: 2.301769247600983

Epoch: 5| Step: 3
Training loss: 1.9022196077106508
Validation loss: 2.326876225917177

Epoch: 5| Step: 4
Training loss: 1.5380704364298254
Validation loss: 2.324473421464964

Epoch: 5| Step: 5
Training loss: 2.43881688857723
Validation loss: 2.2982562623910106

Epoch: 5| Step: 6
Training loss: 2.022712960742976
Validation loss: 2.3094988246831676

Epoch: 5| Step: 7
Training loss: 1.9855730540223135
Validation loss: 2.3243051781892574

Epoch: 5| Step: 8
Training loss: 2.7329130787822726
Validation loss: 2.2818923609947364

Epoch: 5| Step: 9
Training loss: 1.8518284473882882
Validation loss: 2.3109974335035948

Epoch: 5| Step: 10
Training loss: 2.068163407707777
Validation loss: 2.28517627523234

Epoch: 199| Step: 0
Training loss: 2.0122638445366197
Validation loss: 2.335401767107502

Epoch: 5| Step: 1
Training loss: 2.0921848197389945
Validation loss: 2.333144045841425

Epoch: 5| Step: 2
Training loss: 2.0690747285662154
Validation loss: 2.3085441277947165

Epoch: 5| Step: 3
Training loss: 1.7165682730516032
Validation loss: 2.3192460942205546

Epoch: 5| Step: 4
Training loss: 2.2908111246845015
Validation loss: 2.3433035985305573

Epoch: 5| Step: 5
Training loss: 1.3415434707724412
Validation loss: 2.3035279674857003

Epoch: 5| Step: 6
Training loss: 2.0132657223311035
Validation loss: 2.321828724151252

Epoch: 5| Step: 7
Training loss: 2.5614026208760055
Validation loss: 2.3441946372205

Epoch: 5| Step: 8
Training loss: 2.79856804266879
Validation loss: 2.344402952403282

Epoch: 5| Step: 9
Training loss: 1.7485071354175827
Validation loss: 2.3540392877600476

Epoch: 5| Step: 10
Training loss: 2.410582469182243
Validation loss: 2.3044364223740823

Epoch: 200| Step: 0
Training loss: 1.794918355014741
Validation loss: 2.3030146207946234

Epoch: 5| Step: 1
Training loss: 2.875344628949631
Validation loss: 2.353331692659692

Epoch: 5| Step: 2
Training loss: 1.823200211044306
Validation loss: 2.323445990469875

Epoch: 5| Step: 3
Training loss: 2.4248621085377953
Validation loss: 2.297495351023422

Epoch: 5| Step: 4
Training loss: 2.5598475987549176
Validation loss: 2.2952332993340505

Epoch: 5| Step: 5
Training loss: 2.263919793706576
Validation loss: 2.274264825425262

Epoch: 5| Step: 6
Training loss: 1.7907248690518107
Validation loss: 2.304241323968514

Epoch: 5| Step: 7
Training loss: 1.9202630951549993
Validation loss: 2.370030701400639

Epoch: 5| Step: 8
Training loss: 2.1739223353560524
Validation loss: 2.3563178039980643

Epoch: 5| Step: 9
Training loss: 1.7361906703097603
Validation loss: 2.311186186942539

Epoch: 5| Step: 10
Training loss: 1.5584890383009669
Validation loss: 2.291431903467203

Epoch: 201| Step: 0
Training loss: 2.1164246483359004
Validation loss: 2.306923434506344

Epoch: 5| Step: 1
Training loss: 2.0004593798444685
Validation loss: 2.309795811748659

Epoch: 5| Step: 2
Training loss: 2.6399664424439613
Validation loss: 2.3182215197242444

Epoch: 5| Step: 3
Training loss: 2.057323317143469
Validation loss: 2.309590958549368

Epoch: 5| Step: 4
Training loss: 2.376503619004473
Validation loss: 2.2809685479949473

Epoch: 5| Step: 5
Training loss: 2.182921277054866
Validation loss: 2.2876575008928426

Epoch: 5| Step: 6
Training loss: 1.9585365703987023
Validation loss: 2.326705891020313

Epoch: 5| Step: 7
Training loss: 1.8634603802128573
Validation loss: 2.3184206133674663

Epoch: 5| Step: 8
Training loss: 1.7821033508351476
Validation loss: 2.339608365990988

Epoch: 5| Step: 9
Training loss: 2.224071514695071
Validation loss: 2.3253045449282332

Epoch: 5| Step: 10
Training loss: 1.934343658834286
Validation loss: 2.3611066744201916

Epoch: 202| Step: 0
Training loss: 2.1160459925046573
Validation loss: 2.3188403700015447

Epoch: 5| Step: 1
Training loss: 2.047715575033044
Validation loss: 2.322507603647879

Epoch: 5| Step: 2
Training loss: 1.7426137360023457
Validation loss: 2.2997587025685937

Epoch: 5| Step: 3
Training loss: 1.9514232698838094
Validation loss: 2.3175068978717834

Epoch: 5| Step: 4
Training loss: 1.6544329914900417
Validation loss: 2.3384904241704207

Epoch: 5| Step: 5
Training loss: 2.3280119388444604
Validation loss: 2.3017465700262565

Epoch: 5| Step: 6
Training loss: 2.087411081396186
Validation loss: 2.341644020753476

Epoch: 5| Step: 7
Training loss: 2.439656697339362
Validation loss: 2.3132231196184727

Epoch: 5| Step: 8
Training loss: 2.4625384255136704
Validation loss: 2.3479210625378317

Epoch: 5| Step: 9
Training loss: 2.30408099971222
Validation loss: 2.3107206643504083

Epoch: 5| Step: 10
Training loss: 1.871348321914216
Validation loss: 2.3014837016847194

Epoch: 203| Step: 0
Training loss: 1.7324379766462132
Validation loss: 2.3064062596107364

Epoch: 5| Step: 1
Training loss: 2.399623316768265
Validation loss: 2.296961624446304

Epoch: 5| Step: 2
Training loss: 2.239995117182178
Validation loss: 2.2667252078208664

Epoch: 5| Step: 3
Training loss: 2.1223566781081136
Validation loss: 2.3559423590994952

Epoch: 5| Step: 4
Training loss: 2.1334797580456963
Validation loss: 2.2771596779827985

Epoch: 5| Step: 5
Training loss: 2.108398098258715
Validation loss: 2.2781173744863454

Epoch: 5| Step: 6
Training loss: 2.1854165100543677
Validation loss: 2.3009648361848782

Epoch: 5| Step: 7
Training loss: 1.9653614492169411
Validation loss: 2.358273852323036

Epoch: 5| Step: 8
Training loss: 2.5841155764948103
Validation loss: 2.3037641201859946

Epoch: 5| Step: 9
Training loss: 1.7278574924472019
Validation loss: 2.3035441670814523

Epoch: 5| Step: 10
Training loss: 2.0237790559564255
Validation loss: 2.286010639680203

Epoch: 204| Step: 0
Training loss: 2.027827504679062
Validation loss: 2.2928499491255665

Epoch: 5| Step: 1
Training loss: 1.9265463278432773
Validation loss: 2.2576288511283615

Epoch: 5| Step: 2
Training loss: 2.7240494566361506
Validation loss: 2.297840345541394

Epoch: 5| Step: 3
Training loss: 1.8443650335173816
Validation loss: 2.2847420349901095

Epoch: 5| Step: 4
Training loss: 2.5617624477464886
Validation loss: 2.282814700710883

Epoch: 5| Step: 5
Training loss: 1.8329051847185693
Validation loss: 2.26459564995208

Epoch: 5| Step: 6
Training loss: 2.0693234942405496
Validation loss: 2.2859176641946926

Epoch: 5| Step: 7
Training loss: 1.9494532747933244
Validation loss: 2.2804789805778536

Epoch: 5| Step: 8
Training loss: 1.9029383425323418
Validation loss: 2.2512923827928155

Epoch: 5| Step: 9
Training loss: 2.1239444130414387
Validation loss: 2.313463229400581

Epoch: 5| Step: 10
Training loss: 1.844526224480924
Validation loss: 2.2892607554366484

Epoch: 205| Step: 0
Training loss: 2.1915046003442655
Validation loss: 2.295986149487976

Epoch: 5| Step: 1
Training loss: 2.0099001469647795
Validation loss: 2.3663985694427456

Epoch: 5| Step: 2
Training loss: 2.0298958592879695
Validation loss: 2.3104685696601646

Epoch: 5| Step: 3
Training loss: 2.2274104059870106
Validation loss: 2.3273302808399374

Epoch: 5| Step: 4
Training loss: 1.8316754807019213
Validation loss: 2.3474590483567854

Epoch: 5| Step: 5
Training loss: 1.7076835171783233
Validation loss: 2.328232409729093

Epoch: 5| Step: 6
Training loss: 2.408083724800069
Validation loss: 2.346396191559015

Epoch: 5| Step: 7
Training loss: 1.7126888560833444
Validation loss: 2.333512806545712

Epoch: 5| Step: 8
Training loss: 2.139134911704073
Validation loss: 2.3067149420646715

Epoch: 5| Step: 9
Training loss: 2.557536272106828
Validation loss: 2.294977539057681

Epoch: 5| Step: 10
Training loss: 1.8426972956207333
Validation loss: 2.3361079716635023

Epoch: 206| Step: 0
Training loss: 1.8200894329608723
Validation loss: 2.3332820346865475

Epoch: 5| Step: 1
Training loss: 2.053872530643357
Validation loss: 2.3151860588699065

Epoch: 5| Step: 2
Training loss: 2.406388811343388
Validation loss: 2.2995759437306638

Epoch: 5| Step: 3
Training loss: 2.44564066382017
Validation loss: 2.339161001524794

Epoch: 5| Step: 4
Training loss: 2.0220251861875163
Validation loss: 2.3067024517682935

Epoch: 5| Step: 5
Training loss: 1.887367279237038
Validation loss: 2.3665212297822014

Epoch: 5| Step: 6
Training loss: 2.0802440881561455
Validation loss: 2.2669888915513314

Epoch: 5| Step: 7
Training loss: 1.988335149667725
Validation loss: 2.291648931425347

Epoch: 5| Step: 8
Training loss: 2.1602218093719068
Validation loss: 2.339335792783702

Epoch: 5| Step: 9
Training loss: 2.2280479428528093
Validation loss: 2.3059991901534564

Epoch: 5| Step: 10
Training loss: 1.9535662343396254
Validation loss: 2.2986775225196894

Epoch: 207| Step: 0
Training loss: 2.2863364799082246
Validation loss: 2.27745174293393

Epoch: 5| Step: 1
Training loss: 2.4379915573186732
Validation loss: 2.294834075414173

Epoch: 5| Step: 2
Training loss: 1.9350741181483622
Validation loss: 2.310788884841847

Epoch: 5| Step: 3
Training loss: 1.82144274024902
Validation loss: 2.277209883322713

Epoch: 5| Step: 4
Training loss: 2.455948680614879
Validation loss: 2.285141282566788

Epoch: 5| Step: 5
Training loss: 1.4816556415355067
Validation loss: 2.3400561431313394

Epoch: 5| Step: 6
Training loss: 2.5880330518000485
Validation loss: 2.32095551519239

Epoch: 5| Step: 7
Training loss: 1.653538337477635
Validation loss: 2.278675519664893

Epoch: 5| Step: 8
Training loss: 1.5369162529074014
Validation loss: 2.295832325527361

Epoch: 5| Step: 9
Training loss: 2.301407474598043
Validation loss: 2.3445171640199476

Epoch: 5| Step: 10
Training loss: 2.10142363475921
Validation loss: 2.3196490154603975

Epoch: 208| Step: 0
Training loss: 2.0171495926040963
Validation loss: 2.3327087988991084

Epoch: 5| Step: 1
Training loss: 1.9324702534230611
Validation loss: 2.336519511309205

Epoch: 5| Step: 2
Training loss: 2.130827598439738
Validation loss: 2.309350815823899

Epoch: 5| Step: 3
Training loss: 2.2600460422518265
Validation loss: 2.3404421033309473

Epoch: 5| Step: 4
Training loss: 1.5788309010416102
Validation loss: 2.3395061790044696

Epoch: 5| Step: 5
Training loss: 1.740857424875951
Validation loss: 2.316070717717228

Epoch: 5| Step: 6
Training loss: 2.418406211215872
Validation loss: 2.3211295689526903

Epoch: 5| Step: 7
Training loss: 1.9061145421662535
Validation loss: 2.3082052018761474

Epoch: 5| Step: 8
Training loss: 2.1283258329342463
Validation loss: 2.299087689724631

Epoch: 5| Step: 9
Training loss: 2.3601380181768503
Validation loss: 2.332247579973938

Epoch: 5| Step: 10
Training loss: 2.329944590781519
Validation loss: 2.3065696432325686

Epoch: 209| Step: 0
Training loss: 2.3596991512115513
Validation loss: 2.3478398058409256

Epoch: 5| Step: 1
Training loss: 1.825442310191734
Validation loss: 2.258269256309678

Epoch: 5| Step: 2
Training loss: 1.8153395935652976
Validation loss: 2.332479333464962

Epoch: 5| Step: 3
Training loss: 2.669895710569265
Validation loss: 2.322132730622468

Epoch: 5| Step: 4
Training loss: 2.399309726631108
Validation loss: 2.3427914251390582

Epoch: 5| Step: 5
Training loss: 1.8935361785534932
Validation loss: 2.304022776672174

Epoch: 5| Step: 6
Training loss: 2.2306814543254236
Validation loss: 2.254242506891989

Epoch: 5| Step: 7
Training loss: 1.5014765148174445
Validation loss: 2.2777715998123202

Epoch: 5| Step: 8
Training loss: 2.050432448016016
Validation loss: 2.308796583068891

Epoch: 5| Step: 9
Training loss: 1.534690961140602
Validation loss: 2.3072446457544182

Epoch: 5| Step: 10
Training loss: 2.048880024589916
Validation loss: 2.3111890465397047

Epoch: 210| Step: 0
Training loss: 2.2328695280615265
Validation loss: 2.3405978843809105

Epoch: 5| Step: 1
Training loss: 2.2236529698251934
Validation loss: 2.3234867566421933

Epoch: 5| Step: 2
Training loss: 1.7177730211145743
Validation loss: 2.2950815991856612

Epoch: 5| Step: 3
Training loss: 2.4217090180647776
Validation loss: 2.283169844745794

Epoch: 5| Step: 4
Training loss: 2.186373393271865
Validation loss: 2.253987361454882

Epoch: 5| Step: 5
Training loss: 1.8164970785422527
Validation loss: 2.2988202873992223

Epoch: 5| Step: 6
Training loss: 2.3730944970144474
Validation loss: 2.302053340444946

Epoch: 5| Step: 7
Training loss: 1.8048011116497864
Validation loss: 2.3988653572753056

Epoch: 5| Step: 8
Training loss: 2.1817889184506534
Validation loss: 2.288837248605971

Epoch: 5| Step: 9
Training loss: 1.778795056392353
Validation loss: 2.3160518550902647

Epoch: 5| Step: 10
Training loss: 1.7837365178946682
Validation loss: 2.336775810897828

Epoch: 211| Step: 0
Training loss: 1.926675708720935
Validation loss: 2.2773409368358015

Epoch: 5| Step: 1
Training loss: 1.9771946435217176
Validation loss: 2.3299124414115315

Epoch: 5| Step: 2
Training loss: 1.5336400278175828
Validation loss: 2.3181673018342988

Epoch: 5| Step: 3
Training loss: 1.793613957685801
Validation loss: 2.3161045806230596

Epoch: 5| Step: 4
Training loss: 2.6189167743464794
Validation loss: 2.3661484158546786

Epoch: 5| Step: 5
Training loss: 1.9344603166885206
Validation loss: 2.3308877122559717

Epoch: 5| Step: 6
Training loss: 2.322664141649581
Validation loss: 2.355953536645515

Epoch: 5| Step: 7
Training loss: 2.0053069515665727
Validation loss: 2.354811945222441

Epoch: 5| Step: 8
Training loss: 1.7514560636497587
Validation loss: 2.2982854161837247

Epoch: 5| Step: 9
Training loss: 2.46526670378823
Validation loss: 2.3424558198828764

Epoch: 5| Step: 10
Training loss: 1.8919128571456993
Validation loss: 2.307708123394536

Epoch: 212| Step: 0
Training loss: 2.2374724146671583
Validation loss: 2.330486623537028

Epoch: 5| Step: 1
Training loss: 2.1060544475027103
Validation loss: 2.326515555409007

Epoch: 5| Step: 2
Training loss: 1.9555172117524828
Validation loss: 2.2695554366600383

Epoch: 5| Step: 3
Training loss: 1.8965026037438177
Validation loss: 2.3007054598392362

Epoch: 5| Step: 4
Training loss: 1.6412676324645328
Validation loss: 2.3310067251760245

Epoch: 5| Step: 5
Training loss: 2.0012533313883134
Validation loss: 2.305584588922115

Epoch: 5| Step: 6
Training loss: 2.5934293617702773
Validation loss: 2.328159964354588

Epoch: 5| Step: 7
Training loss: 2.047262839344723
Validation loss: 2.3181471214452887

Epoch: 5| Step: 8
Training loss: 1.795781673682606
Validation loss: 2.3375170657671314

Epoch: 5| Step: 9
Training loss: 2.215630178082311
Validation loss: 2.2972812679751855

Epoch: 5| Step: 10
Training loss: 1.8291696025619175
Validation loss: 2.3519235386341455

Epoch: 213| Step: 0
Training loss: 2.0060579820051934
Validation loss: 2.3165464924781127

Epoch: 5| Step: 1
Training loss: 1.9172940125914424
Validation loss: 2.338011969529434

Epoch: 5| Step: 2
Training loss: 2.4152138936351077
Validation loss: 2.287155490957915

Epoch: 5| Step: 3
Training loss: 1.3841808897723455
Validation loss: 2.2845743466864037

Epoch: 5| Step: 4
Training loss: 1.7159861450302893
Validation loss: 2.336058028538486

Epoch: 5| Step: 5
Training loss: 1.8880210157372397
Validation loss: 2.333372695505875

Epoch: 5| Step: 6
Training loss: 2.027438534558711
Validation loss: 2.3120171370682483

Epoch: 5| Step: 7
Training loss: 2.3837626579600713
Validation loss: 2.3078115439552027

Epoch: 5| Step: 8
Training loss: 2.0663964428155155
Validation loss: 2.233588755793623

Epoch: 5| Step: 9
Training loss: 2.6198881420980005
Validation loss: 2.2845397964742387

Epoch: 5| Step: 10
Training loss: 2.0810008406777176
Validation loss: 2.2813828963833296

Epoch: 214| Step: 0
Training loss: 2.264996987481882
Validation loss: 2.2877409943377125

Epoch: 5| Step: 1
Training loss: 2.1279920942618578
Validation loss: 2.2874527306180585

Epoch: 5| Step: 2
Training loss: 2.4697283966914405
Validation loss: 2.3086724781569457

Epoch: 5| Step: 3
Training loss: 1.832466708163204
Validation loss: 2.269057541859899

Epoch: 5| Step: 4
Training loss: 1.760523625421978
Validation loss: 2.28428911476608

Epoch: 5| Step: 5
Training loss: 2.0945846260551964
Validation loss: 2.272018750528094

Epoch: 5| Step: 6
Training loss: 2.2889777158066598
Validation loss: 2.3110122695303716

Epoch: 5| Step: 7
Training loss: 1.7720465898266087
Validation loss: 2.300770030610718

Epoch: 5| Step: 8
Training loss: 2.115463624825874
Validation loss: 2.273255715634597

Epoch: 5| Step: 9
Training loss: 2.0179179552562356
Validation loss: 2.339378045305127

Epoch: 5| Step: 10
Training loss: 1.2661529193503616
Validation loss: 2.3344360414306564

Epoch: 215| Step: 0
Training loss: 2.1057049507323136
Validation loss: 2.3099527772461586

Epoch: 5| Step: 1
Training loss: 1.9471677948798445
Validation loss: 2.2964408089658077

Epoch: 5| Step: 2
Training loss: 2.0142725465802136
Validation loss: 2.2888418800594783

Epoch: 5| Step: 3
Training loss: 2.060288370559044
Validation loss: 2.3308695480647748

Epoch: 5| Step: 4
Training loss: 1.869151020718707
Validation loss: 2.2534893875466477

Epoch: 5| Step: 5
Training loss: 2.09210504849435
Validation loss: 2.3279911940722116

Epoch: 5| Step: 6
Training loss: 1.8278528646733054
Validation loss: 2.3230783078966737

Epoch: 5| Step: 7
Training loss: 2.3748527280420815
Validation loss: 2.31809789285668

Epoch: 5| Step: 8
Training loss: 2.378256121716279
Validation loss: 2.2888076558049457

Epoch: 5| Step: 9
Training loss: 1.93595412326477
Validation loss: 2.290604607224488

Epoch: 5| Step: 10
Training loss: 1.8274232870718394
Validation loss: 2.295140456186798

Epoch: 216| Step: 0
Training loss: 1.6328604659194612
Validation loss: 2.279686685864902

Epoch: 5| Step: 1
Training loss: 2.0691094123743135
Validation loss: 2.2883260650285715

Epoch: 5| Step: 2
Training loss: 1.8857438311181989
Validation loss: 2.303940476364046

Epoch: 5| Step: 3
Training loss: 1.9312617255290092
Validation loss: 2.3852268918553174

Epoch: 5| Step: 4
Training loss: 1.7244313062798775
Validation loss: 2.268292891272879

Epoch: 5| Step: 5
Training loss: 1.8978767979855888
Validation loss: 2.2975914770830803

Epoch: 5| Step: 6
Training loss: 2.234788762976159
Validation loss: 2.3096849845399814

Epoch: 5| Step: 7
Training loss: 2.916598855093165
Validation loss: 2.3372510777384843

Epoch: 5| Step: 8
Training loss: 2.018113367183612
Validation loss: 2.2746998170248647

Epoch: 5| Step: 9
Training loss: 1.7123248602417571
Validation loss: 2.3002564573939597

Epoch: 5| Step: 10
Training loss: 1.9227521181909573
Validation loss: 2.30471363695889

Epoch: 217| Step: 0
Training loss: 1.9153222745626364
Validation loss: 2.290365448937176

Epoch: 5| Step: 1
Training loss: 2.2130679592310973
Validation loss: 2.3223097203387257

Epoch: 5| Step: 2
Training loss: 1.5771770840809762
Validation loss: 2.2986950505565877

Epoch: 5| Step: 3
Training loss: 1.833752959807438
Validation loss: 2.3098110719804903

Epoch: 5| Step: 4
Training loss: 2.0719869499973864
Validation loss: 2.2730039011032197

Epoch: 5| Step: 5
Training loss: 2.1345862534003084
Validation loss: 2.2973495684026557

Epoch: 5| Step: 6
Training loss: 2.335765002972021
Validation loss: 2.3744297314428073

Epoch: 5| Step: 7
Training loss: 1.642404517616566
Validation loss: 2.2873776554711713

Epoch: 5| Step: 8
Training loss: 2.032711852834546
Validation loss: 2.2562962095284735

Epoch: 5| Step: 9
Training loss: 1.9589126893274134
Validation loss: 2.244914881727897

Epoch: 5| Step: 10
Training loss: 2.087613350537588
Validation loss: 2.259522011252257

Epoch: 218| Step: 0
Training loss: 2.210689139822899
Validation loss: 2.3339703791878303

Epoch: 5| Step: 1
Training loss: 1.4952901968094892
Validation loss: 2.2626980124445994

Epoch: 5| Step: 2
Training loss: 1.4811597032025248
Validation loss: 2.2795102065946025

Epoch: 5| Step: 3
Training loss: 2.2185475431673636
Validation loss: 2.388527499275234

Epoch: 5| Step: 4
Training loss: 1.9862918156518843
Validation loss: 2.352844506959339

Epoch: 5| Step: 5
Training loss: 2.4440857366392064
Validation loss: 2.329675909264573

Epoch: 5| Step: 6
Training loss: 1.904434965946662
Validation loss: 2.3435554319720633

Epoch: 5| Step: 7
Training loss: 1.6940300657133123
Validation loss: 2.352025816134862

Epoch: 5| Step: 8
Training loss: 2.2807852911869255
Validation loss: 2.310812483242321

Epoch: 5| Step: 9
Training loss: 2.476161791998618
Validation loss: 2.294298537478868

Epoch: 5| Step: 10
Training loss: 1.59786127915393
Validation loss: 2.328217875578616

Epoch: 219| Step: 0
Training loss: 1.6668798389800827
Validation loss: 2.3131472267469064

Epoch: 5| Step: 1
Training loss: 1.925793135105313
Validation loss: 2.331551177402266

Epoch: 5| Step: 2
Training loss: 2.090951672222208
Validation loss: 2.2916383217618264

Epoch: 5| Step: 3
Training loss: 1.7105753615525565
Validation loss: 2.302270279131601

Epoch: 5| Step: 4
Training loss: 2.2505320873536765
Validation loss: 2.311586689098478

Epoch: 5| Step: 5
Training loss: 1.7425568193451368
Validation loss: 2.3064665026592506

Epoch: 5| Step: 6
Training loss: 2.136812588097424
Validation loss: 2.3574552004784874

Epoch: 5| Step: 7
Training loss: 2.080674751216326
Validation loss: 2.3103365479726587

Epoch: 5| Step: 8
Training loss: 2.2409253971154444
Validation loss: 2.305102233667777

Epoch: 5| Step: 9
Training loss: 1.7143733393890204
Validation loss: 2.302107506875983

Epoch: 5| Step: 10
Training loss: 2.434578636574468
Validation loss: 2.3326921424367977

Epoch: 220| Step: 0
Training loss: 2.1730639818921516
Validation loss: 2.332405136075565

Epoch: 5| Step: 1
Training loss: 2.1471120733993616
Validation loss: 2.2892497388342914

Epoch: 5| Step: 2
Training loss: 1.8734102503279775
Validation loss: 2.308024881293952

Epoch: 5| Step: 3
Training loss: 1.8460556097364733
Validation loss: 2.31167596282546

Epoch: 5| Step: 4
Training loss: 2.464674083837166
Validation loss: 2.339788728198167

Epoch: 5| Step: 5
Training loss: 1.8179880125617878
Validation loss: 2.3060618784525246

Epoch: 5| Step: 6
Training loss: 2.070383552915464
Validation loss: 2.348078564857072

Epoch: 5| Step: 7
Training loss: 1.968900160134122
Validation loss: 2.292177801844744

Epoch: 5| Step: 8
Training loss: 2.0482031320773495
Validation loss: 2.292923911513086

Epoch: 5| Step: 9
Training loss: 1.7244070416107853
Validation loss: 2.339509196299316

Epoch: 5| Step: 10
Training loss: 1.5810797950301445
Validation loss: 2.3286571787757104

Epoch: 221| Step: 0
Training loss: 1.7120742157153082
Validation loss: 2.2900094219783607

Epoch: 5| Step: 1
Training loss: 2.5339621625091073
Validation loss: 2.3288210367731463

Epoch: 5| Step: 2
Training loss: 2.1285263422491245
Validation loss: 2.30851988987196

Epoch: 5| Step: 3
Training loss: 1.4688460136035626
Validation loss: 2.3222234364667815

Epoch: 5| Step: 4
Training loss: 2.127584120345879
Validation loss: 2.326727227912727

Epoch: 5| Step: 5
Training loss: 2.0776647760847866
Validation loss: 2.324748634910893

Epoch: 5| Step: 6
Training loss: 2.057803731680968
Validation loss: 2.315537051171602

Epoch: 5| Step: 7
Training loss: 1.8764021399188764
Validation loss: 2.3260601759378883

Epoch: 5| Step: 8
Training loss: 2.2444999015469866
Validation loss: 2.3329352373982633

Epoch: 5| Step: 9
Training loss: 1.6783256510255997
Validation loss: 2.3050641074232456

Epoch: 5| Step: 10
Training loss: 1.8125464334788353
Validation loss: 2.3550661931043764

Epoch: 222| Step: 0
Training loss: 2.220276535784501
Validation loss: 2.3642703018041242

Epoch: 5| Step: 1
Training loss: 1.7128552005806352
Validation loss: 2.3111625535343103

Epoch: 5| Step: 2
Training loss: 1.7646170245500605
Validation loss: 2.301448881777553

Epoch: 5| Step: 3
Training loss: 2.0307819707566455
Validation loss: 2.280263901430781

Epoch: 5| Step: 4
Training loss: 1.87930312693826
Validation loss: 2.3011002047473497

Epoch: 5| Step: 5
Training loss: 2.3644820764402357
Validation loss: 2.31134310349375

Epoch: 5| Step: 6
Training loss: 1.8573413915676145
Validation loss: 2.305174223720222

Epoch: 5| Step: 7
Training loss: 1.4194304863495828
Validation loss: 2.3140905874876334

Epoch: 5| Step: 8
Training loss: 2.567541884365747
Validation loss: 2.273553606592464

Epoch: 5| Step: 9
Training loss: 2.2451744254814994
Validation loss: 2.316200921662149

Epoch: 5| Step: 10
Training loss: 1.5072932955353677
Validation loss: 2.2886424099317453

Epoch: 223| Step: 0
Training loss: 2.265766954907635
Validation loss: 2.3453738881208994

Epoch: 5| Step: 1
Training loss: 1.4993047692537957
Validation loss: 2.313468394988401

Epoch: 5| Step: 2
Training loss: 1.9435652887336805
Validation loss: 2.3656833542596227

Epoch: 5| Step: 3
Training loss: 1.0585355285174263
Validation loss: 2.2934371828371876

Epoch: 5| Step: 4
Training loss: 2.422211162248301
Validation loss: 2.283189664518016

Epoch: 5| Step: 5
Training loss: 2.1399594128405184
Validation loss: 2.3283177073259393

Epoch: 5| Step: 6
Training loss: 2.221921668655726
Validation loss: 2.317215226578074

Epoch: 5| Step: 7
Training loss: 1.8249994277953205
Validation loss: 2.3058986812082205

Epoch: 5| Step: 8
Training loss: 2.0759967432235427
Validation loss: 2.276519916250537

Epoch: 5| Step: 9
Training loss: 1.9381271085755345
Validation loss: 2.321804271579067

Epoch: 5| Step: 10
Training loss: 1.9171822794226814
Validation loss: 2.3050649265418923

Epoch: 224| Step: 0
Training loss: 2.3882589162594012
Validation loss: 2.306625864217652

Epoch: 5| Step: 1
Training loss: 1.752365352992361
Validation loss: 2.310554693904341

Epoch: 5| Step: 2
Training loss: 2.238725707978256
Validation loss: 2.3035226644193334

Epoch: 5| Step: 3
Training loss: 1.8495963558395416
Validation loss: 2.312567699076647

Epoch: 5| Step: 4
Training loss: 2.0929395331165748
Validation loss: 2.296451219500433

Epoch: 5| Step: 5
Training loss: 1.9395588426310557
Validation loss: 2.3546387121755177

Epoch: 5| Step: 6
Training loss: 1.9291254993547575
Validation loss: 2.3311826496555974

Epoch: 5| Step: 7
Training loss: 2.2409251843296096
Validation loss: 2.4122658246256674

Epoch: 5| Step: 8
Training loss: 1.8942036453622826
Validation loss: 2.2938099709825144

Epoch: 5| Step: 9
Training loss: 1.4580850753190933
Validation loss: 2.303155375388999

Epoch: 5| Step: 10
Training loss: 1.6624736812487368
Validation loss: 2.3379511313789565

Epoch: 225| Step: 0
Training loss: 2.0137767745925026
Validation loss: 2.3099944751706993

Epoch: 5| Step: 1
Training loss: 1.9260729091071005
Validation loss: 2.284941344090049

Epoch: 5| Step: 2
Training loss: 1.7131589638016393
Validation loss: 2.3607484921082813

Epoch: 5| Step: 3
Training loss: 2.3938873570328285
Validation loss: 2.314451165538322

Epoch: 5| Step: 4
Training loss: 1.8841706755082435
Validation loss: 2.2743438130913938

Epoch: 5| Step: 5
Training loss: 1.2905428622435289
Validation loss: 2.3191114001561948

Epoch: 5| Step: 6
Training loss: 2.0394671393064394
Validation loss: 2.276060702434219

Epoch: 5| Step: 7
Training loss: 2.1483144274053094
Validation loss: 2.2819513391067336

Epoch: 5| Step: 8
Training loss: 1.4754802633198076
Validation loss: 2.3300738753266184

Epoch: 5| Step: 9
Training loss: 1.770323990517721
Validation loss: 2.2442314667691083

Epoch: 5| Step: 10
Training loss: 2.6571005861813832
Validation loss: 2.2946712270270244

Epoch: 226| Step: 0
Training loss: 1.6442445337437543
Validation loss: 2.3278991298944858

Epoch: 5| Step: 1
Training loss: 1.821080189199865
Validation loss: 2.355942622434036

Epoch: 5| Step: 2
Training loss: 2.271799028010496
Validation loss: 2.3035603721278

Epoch: 5| Step: 3
Training loss: 2.1615136074367602
Validation loss: 2.314644048806812

Epoch: 5| Step: 4
Training loss: 2.058435538942368
Validation loss: 2.3100683380911975

Epoch: 5| Step: 5
Training loss: 1.9727478006099517
Validation loss: 2.3024070730008024

Epoch: 5| Step: 6
Training loss: 2.0725757823382853
Validation loss: 2.3665609972078308

Epoch: 5| Step: 7
Training loss: 1.4466243254856854
Validation loss: 2.348148923994276

Epoch: 5| Step: 8
Training loss: 2.2562489094824016
Validation loss: 2.2876410991461498

Epoch: 5| Step: 9
Training loss: 2.2970645333285433
Validation loss: 2.315319717918135

Epoch: 5| Step: 10
Training loss: 1.8283133776516607
Validation loss: 2.326592616555835

Epoch: 227| Step: 0
Training loss: 1.579926321991745
Validation loss: 2.3452231564940176

Epoch: 5| Step: 1
Training loss: 2.3224492878710326
Validation loss: 2.391432506263586

Epoch: 5| Step: 2
Training loss: 1.8822566434652042
Validation loss: 2.275747533103439

Epoch: 5| Step: 3
Training loss: 2.143578267239328
Validation loss: 2.316484209094971

Epoch: 5| Step: 4
Training loss: 1.8937126986918495
Validation loss: 2.2744852204601536

Epoch: 5| Step: 5
Training loss: 2.0356777350411788
Validation loss: 2.3296494680301874

Epoch: 5| Step: 6
Training loss: 1.9903551239130943
Validation loss: 2.332960599655774

Epoch: 5| Step: 7
Training loss: 1.7808735767625765
Validation loss: 2.3167146070325217

Epoch: 5| Step: 8
Training loss: 1.745607790645309
Validation loss: 2.323282308416159

Epoch: 5| Step: 9
Training loss: 2.1059553896824403
Validation loss: 2.319755023461138

Epoch: 5| Step: 10
Training loss: 1.8228133544710596
Validation loss: 2.3587878552745445

Epoch: 228| Step: 0
Training loss: 2.0001392316038356
Validation loss: 2.2898108014413623

Epoch: 5| Step: 1
Training loss: 2.4300495626159604
Validation loss: 2.3854816895585143

Epoch: 5| Step: 2
Training loss: 2.190916390840333
Validation loss: 2.27687359855087

Epoch: 5| Step: 3
Training loss: 1.439288312361305
Validation loss: 2.31885770417073

Epoch: 5| Step: 4
Training loss: 1.416894090386717
Validation loss: 2.3269247597920124

Epoch: 5| Step: 5
Training loss: 1.9787149884324897
Validation loss: 2.3408541371675966

Epoch: 5| Step: 6
Training loss: 2.050304655371998
Validation loss: 2.312913435872835

Epoch: 5| Step: 7
Training loss: 1.7585530395405187
Validation loss: 2.341677849397337

Epoch: 5| Step: 8
Training loss: 1.6441467995594514
Validation loss: 2.3294064846978477

Epoch: 5| Step: 9
Training loss: 1.9792887465989721
Validation loss: 2.3149207907542384

Epoch: 5| Step: 10
Training loss: 1.886191663705806
Validation loss: 2.3145528304994802

Epoch: 229| Step: 0
Training loss: 1.1004653769856705
Validation loss: 2.3840545187756366

Epoch: 5| Step: 1
Training loss: 1.7464664070094156
Validation loss: 2.2989112434092074

Epoch: 5| Step: 2
Training loss: 2.061699220507755
Validation loss: 2.324064303366531

Epoch: 5| Step: 3
Training loss: 1.7389743751756954
Validation loss: 2.2933381556209587

Epoch: 5| Step: 4
Training loss: 1.8698287861007634
Validation loss: 2.2506594403661246

Epoch: 5| Step: 5
Training loss: 2.2457784680215456
Validation loss: 2.307583991606241

Epoch: 5| Step: 6
Training loss: 2.4862928365524035
Validation loss: 2.2632579904116374

Epoch: 5| Step: 7
Training loss: 1.4030130218477972
Validation loss: 2.2841509204606734

Epoch: 5| Step: 8
Training loss: 2.0282260393504514
Validation loss: 2.3140382736138925

Epoch: 5| Step: 9
Training loss: 1.8695499685444739
Validation loss: 2.31240351751987

Epoch: 5| Step: 10
Training loss: 1.7854280160597362
Validation loss: 2.315261968509357

Epoch: 230| Step: 0
Training loss: 1.7678507051997474
Validation loss: 2.3600303708363146

Epoch: 5| Step: 1
Training loss: 1.8377040075079598
Validation loss: 2.3019064721778504

Epoch: 5| Step: 2
Training loss: 1.6973615647780214
Validation loss: 2.334757177802808

Epoch: 5| Step: 3
Training loss: 2.1345440329868497
Validation loss: 2.327020171428831

Epoch: 5| Step: 4
Training loss: 1.7992140431576513
Validation loss: 2.3510493697542123

Epoch: 5| Step: 5
Training loss: 2.526638775808281
Validation loss: 2.3263226574713394

Epoch: 5| Step: 6
Training loss: 1.6486053381353418
Validation loss: 2.3356446590783473

Epoch: 5| Step: 7
Training loss: 1.813298214065109
Validation loss: 2.3096668656042123

Epoch: 5| Step: 8
Training loss: 1.701817281684993
Validation loss: 2.332874141576795

Epoch: 5| Step: 9
Training loss: 1.9428325609948083
Validation loss: 2.3736497444168627

Epoch: 5| Step: 10
Training loss: 1.694979023986477
Validation loss: 2.3579581127816587

Epoch: 231| Step: 0
Training loss: 1.4925769078105724
Validation loss: 2.325150213418235

Epoch: 5| Step: 1
Training loss: 1.8800407046111722
Validation loss: 2.397592822099504

Epoch: 5| Step: 2
Training loss: 1.7885087668033655
Validation loss: 2.315652254734224

Epoch: 5| Step: 3
Training loss: 2.289696719480488
Validation loss: 2.323691825668726

Epoch: 5| Step: 4
Training loss: 1.7978592540404454
Validation loss: 2.2639134036195405

Epoch: 5| Step: 5
Training loss: 2.313276418302747
Validation loss: 2.3747265458075364

Epoch: 5| Step: 6
Training loss: 1.3055434017878231
Validation loss: 2.3367269363671612

Epoch: 5| Step: 7
Training loss: 1.6811300780910086
Validation loss: 2.33100293361327

Epoch: 5| Step: 8
Training loss: 2.6394011240160205
Validation loss: 2.3354191913111566

Epoch: 5| Step: 9
Training loss: 1.8014717019616906
Validation loss: 2.30245038845577

Epoch: 5| Step: 10
Training loss: 1.8740184758027725
Validation loss: 2.310021201865984

Epoch: 232| Step: 0
Training loss: 1.9934437100950162
Validation loss: 2.29380333054888

Epoch: 5| Step: 1
Training loss: 1.390077204446976
Validation loss: 2.325579253795443

Epoch: 5| Step: 2
Training loss: 1.6552516879562993
Validation loss: 2.2739283534284107

Epoch: 5| Step: 3
Training loss: 1.5383237043405193
Validation loss: 2.239146739836962

Epoch: 5| Step: 4
Training loss: 1.8615992729854434
Validation loss: 2.323571540531164

Epoch: 5| Step: 5
Training loss: 1.7125985082430737
Validation loss: 2.230430610028509

Epoch: 5| Step: 6
Training loss: 2.0402983796935024
Validation loss: 2.3010197446267564

Epoch: 5| Step: 7
Training loss: 2.2242841876432746
Validation loss: 2.2941510744232745

Epoch: 5| Step: 8
Training loss: 1.7025365250264302
Validation loss: 2.3360440517346523

Epoch: 5| Step: 9
Training loss: 2.694270897440108
Validation loss: 2.346196770765136

Epoch: 5| Step: 10
Training loss: 1.8201785713665535
Validation loss: 2.3101424733089115

Epoch: 233| Step: 0
Training loss: 1.9966525435969813
Validation loss: 2.337796398869054

Epoch: 5| Step: 1
Training loss: 1.6168532463766165
Validation loss: 2.3158466763253283

Epoch: 5| Step: 2
Training loss: 2.073634638322463
Validation loss: 2.3205267804931795

Epoch: 5| Step: 3
Training loss: 1.7684003909043504
Validation loss: 2.3167034238618736

Epoch: 5| Step: 4
Training loss: 2.0959042526390532
Validation loss: 2.3249111463328678

Epoch: 5| Step: 5
Training loss: 1.8434074212902367
Validation loss: 2.3579379484012613

Epoch: 5| Step: 6
Training loss: 1.908480792893623
Validation loss: 2.3728157895462103

Epoch: 5| Step: 7
Training loss: 1.5807139245628106
Validation loss: 2.324736143910767

Epoch: 5| Step: 8
Training loss: 1.7451292783620391
Validation loss: 2.327423949814108

Epoch: 5| Step: 9
Training loss: 1.9952587912073914
Validation loss: 2.396363203423917

Epoch: 5| Step: 10
Training loss: 2.613863892885589
Validation loss: 2.3252968379121346

Epoch: 234| Step: 0
Training loss: 1.4695998634653957
Validation loss: 2.3524931613872893

Epoch: 5| Step: 1
Training loss: 2.222512507022642
Validation loss: 2.328729619690926

Epoch: 5| Step: 2
Training loss: 2.2908793975576396
Validation loss: 2.3750700602967854

Epoch: 5| Step: 3
Training loss: 1.7084318303191546
Validation loss: 2.3603598159616617

Epoch: 5| Step: 4
Training loss: 1.913432301687593
Validation loss: 2.3330526333243746

Epoch: 5| Step: 5
Training loss: 1.6756701310314646
Validation loss: 2.4077336851528695

Epoch: 5| Step: 6
Training loss: 2.2068565637104167
Validation loss: 2.3239071558637057

Epoch: 5| Step: 7
Training loss: 2.260592850764213
Validation loss: 2.357763859345054

Epoch: 5| Step: 8
Training loss: 1.7291381404622563
Validation loss: 2.3278412377225495

Epoch: 5| Step: 9
Training loss: 1.4840337260596195
Validation loss: 2.3794030402700264

Epoch: 5| Step: 10
Training loss: 2.1130621438661787
Validation loss: 2.3095296015018842

Epoch: 235| Step: 0
Training loss: 2.1786080699045933
Validation loss: 2.315762888247031

Epoch: 5| Step: 1
Training loss: 2.070368006699897
Validation loss: 2.2818356586924446

Epoch: 5| Step: 2
Training loss: 2.081420350764042
Validation loss: 2.278457863550773

Epoch: 5| Step: 3
Training loss: 1.8851793536759633
Validation loss: 2.346150752125282

Epoch: 5| Step: 4
Training loss: 1.4657068583518844
Validation loss: 2.2925975186206187

Epoch: 5| Step: 5
Training loss: 1.9671165714096677
Validation loss: 2.325542130756467

Epoch: 5| Step: 6
Training loss: 1.4518692168877219
Validation loss: 2.350222908824923

Epoch: 5| Step: 7
Training loss: 1.6930179097669782
Validation loss: 2.30934052116695

Epoch: 5| Step: 8
Training loss: 2.116429604999585
Validation loss: 2.300509945843736

Epoch: 5| Step: 9
Training loss: 1.98903691109786
Validation loss: 2.336607537302253

Epoch: 5| Step: 10
Training loss: 2.1009643157150966
Validation loss: 2.290418808305141

Epoch: 236| Step: 0
Training loss: 2.428940833070382
Validation loss: 2.2837520806710083

Epoch: 5| Step: 1
Training loss: 1.4471261681872185
Validation loss: 2.287834251500506

Epoch: 5| Step: 2
Training loss: 2.2784300841871477
Validation loss: 2.3397033486031336

Epoch: 5| Step: 3
Training loss: 1.6387719725089454
Validation loss: 2.2694922765385543

Epoch: 5| Step: 4
Training loss: 1.4873902063962146
Validation loss: 2.360824748578466

Epoch: 5| Step: 5
Training loss: 2.0428926588662004
Validation loss: 2.3077605563250794

Epoch: 5| Step: 6
Training loss: 1.8510201863116071
Validation loss: 2.271207896155286

Epoch: 5| Step: 7
Training loss: 1.6755382299384731
Validation loss: 2.3108193527046144

Epoch: 5| Step: 8
Training loss: 2.149364812304908
Validation loss: 2.304907942390529

Epoch: 5| Step: 9
Training loss: 2.143338787354708
Validation loss: 2.3472162452406935

Epoch: 5| Step: 10
Training loss: 1.7243178608336165
Validation loss: 2.335410810189923

Epoch: 237| Step: 0
Training loss: 1.6821836864039155
Validation loss: 2.4069540205528646

Epoch: 5| Step: 1
Training loss: 2.1267881163036413
Validation loss: 2.295120409544644

Epoch: 5| Step: 2
Training loss: 2.0933716844985866
Validation loss: 2.4048866327101917

Epoch: 5| Step: 3
Training loss: 1.4517737227745486
Validation loss: 2.3041958537038267

Epoch: 5| Step: 4
Training loss: 1.8674390934583354
Validation loss: 2.346703951880042

Epoch: 5| Step: 5
Training loss: 2.1890016034060724
Validation loss: 2.2833996886254053

Epoch: 5| Step: 6
Training loss: 1.730180290066866
Validation loss: 2.3343701823988012

Epoch: 5| Step: 7
Training loss: 1.7777494868703034
Validation loss: 2.332321593316709

Epoch: 5| Step: 8
Training loss: 2.137503582689283
Validation loss: 2.305667375924418

Epoch: 5| Step: 9
Training loss: 1.593015089946572
Validation loss: 2.348406476090501

Epoch: 5| Step: 10
Training loss: 1.96365860675968
Validation loss: 2.305043995828214

Epoch: 238| Step: 0
Training loss: 1.0930085530099112
Validation loss: 2.293740814084189

Epoch: 5| Step: 1
Training loss: 2.0238928558653257
Validation loss: 2.354519548538426

Epoch: 5| Step: 2
Training loss: 1.970865354486175
Validation loss: 2.344703737312937

Epoch: 5| Step: 3
Training loss: 1.828485111078944
Validation loss: 2.292448187622876

Epoch: 5| Step: 4
Training loss: 1.8104722090945127
Validation loss: 2.313054877096226

Epoch: 5| Step: 5
Training loss: 1.7280870154070955
Validation loss: 2.350662155023715

Epoch: 5| Step: 6
Training loss: 2.1979245973657893
Validation loss: 2.3261333799319206

Epoch: 5| Step: 7
Training loss: 1.569236196732233
Validation loss: 2.2855587672358917

Epoch: 5| Step: 8
Training loss: 1.9185848450797727
Validation loss: 2.332900135820754

Epoch: 5| Step: 9
Training loss: 1.8428465359193509
Validation loss: 2.314625159047295

Epoch: 5| Step: 10
Training loss: 2.5893063455144953
Validation loss: 2.288121483152806

Epoch: 239| Step: 0
Training loss: 1.2850315763994868
Validation loss: 2.291227087854423

Epoch: 5| Step: 1
Training loss: 2.8420349650584433
Validation loss: 2.351764644511081

Epoch: 5| Step: 2
Training loss: 1.7577121282107544
Validation loss: 2.3769311916955735

Epoch: 5| Step: 3
Training loss: 2.03887096689347
Validation loss: 2.3312156827136588

Epoch: 5| Step: 4
Training loss: 1.7149091634244062
Validation loss: 2.313439430868245

Epoch: 5| Step: 5
Training loss: 1.7424732880481002
Validation loss: 2.3269881171644275

Epoch: 5| Step: 6
Training loss: 1.521516498427333
Validation loss: 2.3313786560308722

Epoch: 5| Step: 7
Training loss: 1.824151178778988
Validation loss: 2.3851673160506386

Epoch: 5| Step: 8
Training loss: 1.8058477197956266
Validation loss: 2.38243388734082

Epoch: 5| Step: 9
Training loss: 1.8820904498767677
Validation loss: 2.341352893793865

Epoch: 5| Step: 10
Training loss: 1.5623468705481964
Validation loss: 2.352073334043638

Epoch: 240| Step: 0
Training loss: 2.242090522184144
Validation loss: 2.3890251158942832

Epoch: 5| Step: 1
Training loss: 2.030010020978275
Validation loss: 2.341168559158686

Epoch: 5| Step: 2
Training loss: 1.4512631373504936
Validation loss: 2.3192021816093407

Epoch: 5| Step: 3
Training loss: 1.61830388111431
Validation loss: 2.3279619861150245

Epoch: 5| Step: 4
Training loss: 2.146567012456132
Validation loss: 2.3201845007461905

Epoch: 5| Step: 5
Training loss: 1.9564424950220554
Validation loss: 2.338028126467351

Epoch: 5| Step: 6
Training loss: 1.865948828830677
Validation loss: 2.3487137033942838

Epoch: 5| Step: 7
Training loss: 2.0517574638936518
Validation loss: 2.2619137781993417

Epoch: 5| Step: 8
Training loss: 1.8673607654066022
Validation loss: 2.3203084849037015

Epoch: 5| Step: 9
Training loss: 1.412985038186763
Validation loss: 2.34814036121959

Epoch: 5| Step: 10
Training loss: 1.7585555477051682
Validation loss: 2.3285943479262836

Epoch: 241| Step: 0
Training loss: 2.3640948447809005
Validation loss: 2.3611485378967374

Epoch: 5| Step: 1
Training loss: 1.8392676486161141
Validation loss: 2.3411731267817766

Epoch: 5| Step: 2
Training loss: 2.155043333463159
Validation loss: 2.276150365437629

Epoch: 5| Step: 3
Training loss: 1.6531136524986394
Validation loss: 2.2919353726569507

Epoch: 5| Step: 4
Training loss: 1.324906342273256
Validation loss: 2.3349871829939497

Epoch: 5| Step: 5
Training loss: 1.651773557286834
Validation loss: 2.348675289626542

Epoch: 5| Step: 6
Training loss: 1.8379601557649958
Validation loss: 2.296121316956926

Epoch: 5| Step: 7
Training loss: 2.1388737552762485
Validation loss: 2.311453832345896

Epoch: 5| Step: 8
Training loss: 1.863752453480672
Validation loss: 2.3653427067646406

Epoch: 5| Step: 9
Training loss: 1.3507943589041607
Validation loss: 2.3148779268126933

Epoch: 5| Step: 10
Training loss: 2.0519372207080435
Validation loss: 2.3317369146933626

Epoch: 242| Step: 0
Training loss: 1.9751906025333503
Validation loss: 2.333595200389495

Epoch: 5| Step: 1
Training loss: 1.878928773233473
Validation loss: 2.385027098684592

Epoch: 5| Step: 2
Training loss: 1.319632360673622
Validation loss: 2.3318498139310257

Epoch: 5| Step: 3
Training loss: 2.1238489960695106
Validation loss: 2.293203668142216

Epoch: 5| Step: 4
Training loss: 1.5428140683443359
Validation loss: 2.3739606982871546

Epoch: 5| Step: 5
Training loss: 1.352943024060873
Validation loss: 2.3406507557706915

Epoch: 5| Step: 6
Training loss: 1.661619874122569
Validation loss: 2.3292798051379595

Epoch: 5| Step: 7
Training loss: 2.2833446135787585
Validation loss: 2.27974901140884

Epoch: 5| Step: 8
Training loss: 2.490798036698106
Validation loss: 2.323998736168136

Epoch: 5| Step: 9
Training loss: 1.856088185562539
Validation loss: 2.3570358327714414

Epoch: 5| Step: 10
Training loss: 1.7812604401934995
Validation loss: 2.359653141398572

Epoch: 243| Step: 0
Training loss: 1.655036337646598
Validation loss: 2.3434644616768887

Epoch: 5| Step: 1
Training loss: 1.8216748031104106
Validation loss: 2.3478135407794762

Epoch: 5| Step: 2
Training loss: 1.659701511709618
Validation loss: 2.3626230601831706

Epoch: 5| Step: 3
Training loss: 1.7495483769359268
Validation loss: 2.412380163417221

Epoch: 5| Step: 4
Training loss: 1.9844040155166756
Validation loss: 2.3300923026245064

Epoch: 5| Step: 5
Training loss: 1.7458950672144866
Validation loss: 2.424637897428585

Epoch: 5| Step: 6
Training loss: 1.8684159710746417
Validation loss: 2.4110695396981576

Epoch: 5| Step: 7
Training loss: 1.7246264481698432
Validation loss: 2.367418795892411

Epoch: 5| Step: 8
Training loss: 2.0849198848783335
Validation loss: 2.406265036071583

Epoch: 5| Step: 9
Training loss: 2.3034581930690203
Validation loss: 2.3593756486858806

Epoch: 5| Step: 10
Training loss: 2.039983899296072
Validation loss: 2.2830924054615918

Epoch: 244| Step: 0
Training loss: 1.6526561108142166
Validation loss: 2.355099250388564

Epoch: 5| Step: 1
Training loss: 1.8889600500402843
Validation loss: 2.351335058747821

Epoch: 5| Step: 2
Training loss: 1.6108751434778412
Validation loss: 2.3677163797829954

Epoch: 5| Step: 3
Training loss: 2.0153990626307317
Validation loss: 2.2711742538835455

Epoch: 5| Step: 4
Training loss: 1.5480329244843198
Validation loss: 2.3367580287352645

Epoch: 5| Step: 5
Training loss: 1.690175654971821
Validation loss: 2.3310416045145406

Epoch: 5| Step: 6
Training loss: 1.9555291599722335
Validation loss: 2.2663604459206095

Epoch: 5| Step: 7
Training loss: 1.4525541599438523
Validation loss: 2.3010971120218904

Epoch: 5| Step: 8
Training loss: 1.432848994165745
Validation loss: 2.3645361224823627

Epoch: 5| Step: 9
Training loss: 2.7627913619139886
Validation loss: 2.329624846644235

Epoch: 5| Step: 10
Training loss: 1.5752385246465501
Validation loss: 2.346980144034713

Epoch: 245| Step: 0
Training loss: 1.6649040995292408
Validation loss: 2.2603816386998643

Epoch: 5| Step: 1
Training loss: 2.078797654588032
Validation loss: 2.4139081644976184

Epoch: 5| Step: 2
Training loss: 2.3463843227626207
Validation loss: 2.3439859043202054

Epoch: 5| Step: 3
Training loss: 1.889236949504559
Validation loss: 2.3636004721932786

Epoch: 5| Step: 4
Training loss: 1.5600588994033346
Validation loss: 2.3710617914995917

Epoch: 5| Step: 5
Training loss: 1.508372385703221
Validation loss: 2.3997428751179846

Epoch: 5| Step: 6
Training loss: 1.7696144471810105
Validation loss: 2.311562415426433

Epoch: 5| Step: 7
Training loss: 1.845247339556577
Validation loss: 2.31618421898401

Epoch: 5| Step: 8
Training loss: 1.888373303014228
Validation loss: 2.3177937913002853

Epoch: 5| Step: 9
Training loss: 1.8716092922535226
Validation loss: 2.2893557429463915

Epoch: 5| Step: 10
Training loss: 1.6531163927513992
Validation loss: 2.3811544932150213

Epoch: 246| Step: 0
Training loss: 2.000673180774294
Validation loss: 2.3823800369482626

Epoch: 5| Step: 1
Training loss: 1.7655799657429112
Validation loss: 2.336936946217755

Epoch: 5| Step: 2
Training loss: 1.8360308684286868
Validation loss: 2.3298525993909314

Epoch: 5| Step: 3
Training loss: 1.9367907056409774
Validation loss: 2.347282965985862

Epoch: 5| Step: 4
Training loss: 2.009596095520831
Validation loss: 2.404065777668296

Epoch: 5| Step: 5
Training loss: 1.8798558617183372
Validation loss: 2.421448679651162

Epoch: 5| Step: 6
Training loss: 1.6143165942299702
Validation loss: 2.355408406279271

Epoch: 5| Step: 7
Training loss: 1.9899009597516057
Validation loss: 2.3708745924031507

Epoch: 5| Step: 8
Training loss: 2.1640172189320093
Validation loss: 2.2724870107853454

Epoch: 5| Step: 9
Training loss: 1.6095318764086461
Validation loss: 2.3887911722767936

Epoch: 5| Step: 10
Training loss: 1.6488681610314935
Validation loss: 2.3909809046815194

Epoch: 247| Step: 0
Training loss: 2.1918539042201393
Validation loss: 2.3092946300952635

Epoch: 5| Step: 1
Training loss: 1.805839798227288
Validation loss: 2.3747355114694244

Epoch: 5| Step: 2
Training loss: 1.690914655258629
Validation loss: 2.3403481398564363

Epoch: 5| Step: 3
Training loss: 2.0183216360915046
Validation loss: 2.3705444559241364

Epoch: 5| Step: 4
Training loss: 1.6623841180784389
Validation loss: 2.365796082874895

Epoch: 5| Step: 5
Training loss: 1.8388155840309803
Validation loss: 2.2995374465904144

Epoch: 5| Step: 6
Training loss: 1.5748843922647222
Validation loss: 2.361724941497965

Epoch: 5| Step: 7
Training loss: 2.1405280989273097
Validation loss: 2.347907441880656

Epoch: 5| Step: 8
Training loss: 1.4853436973308365
Validation loss: 2.2903096369675553

Epoch: 5| Step: 9
Training loss: 1.959223024354649
Validation loss: 2.339780298083796

Epoch: 5| Step: 10
Training loss: 1.2664888518573574
Validation loss: 2.3883176055952067

Epoch: 248| Step: 0
Training loss: 2.021612102509152
Validation loss: 2.3791816633226786

Epoch: 5| Step: 1
Training loss: 1.5782963121551044
Validation loss: 2.3235625065376055

Epoch: 5| Step: 2
Training loss: 1.587022307005399
Validation loss: 2.2992980868637916

Epoch: 5| Step: 3
Training loss: 1.5701045567630492
Validation loss: 2.3143526375900287

Epoch: 5| Step: 4
Training loss: 1.4139189673652905
Validation loss: 2.3197609469729414

Epoch: 5| Step: 5
Training loss: 2.276814682292712
Validation loss: 2.3240191051193535

Epoch: 5| Step: 6
Training loss: 2.0559538793252035
Validation loss: 2.3154775047017577

Epoch: 5| Step: 7
Training loss: 1.4104910582509496
Validation loss: 2.363388643508637

Epoch: 5| Step: 8
Training loss: 2.036890853909096
Validation loss: 2.3538517897019973

Epoch: 5| Step: 9
Training loss: 1.8200482352645424
Validation loss: 2.350124426484218

Epoch: 5| Step: 10
Training loss: 2.1968084376793375
Validation loss: 2.3670769219617513

Epoch: 249| Step: 0
Training loss: 2.277193826808231
Validation loss: 2.357994951076899

Epoch: 5| Step: 1
Training loss: 2.409688301348488
Validation loss: 2.3420806583913847

Epoch: 5| Step: 2
Training loss: 1.5614881672552858
Validation loss: 2.324778571353565

Epoch: 5| Step: 3
Training loss: 2.311567582489322
Validation loss: 2.3127622802070946

Epoch: 5| Step: 4
Training loss: 1.5549301648174128
Validation loss: 2.410844943357043

Epoch: 5| Step: 5
Training loss: 1.8084605355358734
Validation loss: 2.413159547320682

Epoch: 5| Step: 6
Training loss: 1.3402574973584231
Validation loss: 2.390467626292614

Epoch: 5| Step: 7
Training loss: 1.6401077181633392
Validation loss: 2.335517502307009

Epoch: 5| Step: 8
Training loss: 1.999512493799453
Validation loss: 2.3751721700234056

Epoch: 5| Step: 9
Training loss: 1.1750221717041245
Validation loss: 2.4145747229820835

Epoch: 5| Step: 10
Training loss: 1.634464067471982
Validation loss: 2.3610952747963205

Epoch: 250| Step: 0
Training loss: 2.162115991266977
Validation loss: 2.324173291131395

Epoch: 5| Step: 1
Training loss: 1.4282798299186648
Validation loss: 2.3412926543544574

Epoch: 5| Step: 2
Training loss: 1.627288234311327
Validation loss: 2.3216905316027026

Epoch: 5| Step: 3
Training loss: 2.4027485328124483
Validation loss: 2.357829895631658

Epoch: 5| Step: 4
Training loss: 1.5670959019919741
Validation loss: 2.3725420857673654

Epoch: 5| Step: 5
Training loss: 1.2519778816048757
Validation loss: 2.3427398670617987

Epoch: 5| Step: 6
Training loss: 2.112018990915342
Validation loss: 2.293892570491413

Epoch: 5| Step: 7
Training loss: 1.7576959868069773
Validation loss: 2.3498780607495227

Epoch: 5| Step: 8
Training loss: 1.6674195575899082
Validation loss: 2.3037119512886948

Epoch: 5| Step: 9
Training loss: 2.09623752688096
Validation loss: 2.298482756754948

Epoch: 5| Step: 10
Training loss: 1.676278420704473
Validation loss: 2.2912240153689662

Epoch: 251| Step: 0
Training loss: 1.8653393141700856
Validation loss: 2.3724140300579446

Epoch: 5| Step: 1
Training loss: 1.973814127812222
Validation loss: 2.3533545801379008

Epoch: 5| Step: 2
Training loss: 1.9378266828215132
Validation loss: 2.2932552499593317

Epoch: 5| Step: 3
Training loss: 1.5221715117374321
Validation loss: 2.394865452748121

Epoch: 5| Step: 4
Training loss: 2.57461882797726
Validation loss: 2.3265518585247986

Epoch: 5| Step: 5
Training loss: 1.2736414646556198
Validation loss: 2.3620655105401727

Epoch: 5| Step: 6
Training loss: 1.338499857723327
Validation loss: 2.336676572007738

Epoch: 5| Step: 7
Training loss: 1.890857398512
Validation loss: 2.397049105762974

Epoch: 5| Step: 8
Training loss: 2.035713807681991
Validation loss: 2.4215503052880893

Epoch: 5| Step: 9
Training loss: 1.718262967550697
Validation loss: 2.443402345747594

Epoch: 5| Step: 10
Training loss: 1.6069040681160178
Validation loss: 2.3304338906234543

Epoch: 252| Step: 0
Training loss: 1.7908858956347475
Validation loss: 2.405865010260292

Epoch: 5| Step: 1
Training loss: 1.4768171141359163
Validation loss: 2.3628275882724905

Epoch: 5| Step: 2
Training loss: 1.8927467357691494
Validation loss: 2.364090472448452

Epoch: 5| Step: 3
Training loss: 1.8588804981878122
Validation loss: 2.390074162778714

Epoch: 5| Step: 4
Training loss: 1.4029146695252628
Validation loss: 2.32670924830213

Epoch: 5| Step: 5
Training loss: 2.5053165171865692
Validation loss: 2.399297710352233

Epoch: 5| Step: 6
Training loss: 1.9753601277045043
Validation loss: 2.3295325174307355

Epoch: 5| Step: 7
Training loss: 1.822096969142893
Validation loss: 2.316851294412417

Epoch: 5| Step: 8
Training loss: 1.5745495621363137
Validation loss: 2.327812537789873

Epoch: 5| Step: 9
Training loss: 1.8658535713482811
Validation loss: 2.286468743162228

Epoch: 5| Step: 10
Training loss: 1.7548355325433935
Validation loss: 2.385268552869132

Epoch: 253| Step: 0
Training loss: 2.023333219101896
Validation loss: 2.3409061781227734

Epoch: 5| Step: 1
Training loss: 1.5324979873569335
Validation loss: 2.3996114868854117

Epoch: 5| Step: 2
Training loss: 1.4903535607749263
Validation loss: 2.2994391776593814

Epoch: 5| Step: 3
Training loss: 1.7561731450651437
Validation loss: 2.320358697414698

Epoch: 5| Step: 4
Training loss: 1.4462519711124107
Validation loss: 2.34184396115151

Epoch: 5| Step: 5
Training loss: 1.9690092612417325
Validation loss: 2.3597442168554874

Epoch: 5| Step: 6
Training loss: 2.1274421346933283
Validation loss: 2.413800285422528

Epoch: 5| Step: 7
Training loss: 1.7590828607288613
Validation loss: 2.3636693546464764

Epoch: 5| Step: 8
Training loss: 1.4747889933548644
Validation loss: 2.368825853370149

Epoch: 5| Step: 9
Training loss: 1.9442697817451038
Validation loss: 2.287693387428278

Epoch: 5| Step: 10
Training loss: 2.1322653491308263
Validation loss: 2.3795618137028063

Epoch: 254| Step: 0
Training loss: 1.6323745359196213
Validation loss: 2.365327845175778

Epoch: 5| Step: 1
Training loss: 1.8342275245041328
Validation loss: 2.4337656102681424

Epoch: 5| Step: 2
Training loss: 1.754873370196669
Validation loss: 2.3650565722559516

Epoch: 5| Step: 3
Training loss: 1.1925497602081474
Validation loss: 2.3429130115229473

Epoch: 5| Step: 4
Training loss: 2.071905595602421
Validation loss: 2.3852931104072232

Epoch: 5| Step: 5
Training loss: 1.5406888317944074
Validation loss: 2.376071092024056

Epoch: 5| Step: 6
Training loss: 1.7538653328589522
Validation loss: 2.368766088017385

Epoch: 5| Step: 7
Training loss: 1.3994173421242317
Validation loss: 2.404263169824341

Epoch: 5| Step: 8
Training loss: 1.7116877334967304
Validation loss: 2.45975134241034

Epoch: 5| Step: 9
Training loss: 2.1992192920528306
Validation loss: 2.3551077443201054

Epoch: 5| Step: 10
Training loss: 2.4890546569892225
Validation loss: 2.322319856496163

Epoch: 255| Step: 0
Training loss: 2.1342035584970716
Validation loss: 2.3108232411751075

Epoch: 5| Step: 1
Training loss: 1.1893565572490452
Validation loss: 2.382041586695001

Epoch: 5| Step: 2
Training loss: 2.1718989309186303
Validation loss: 2.321639839947689

Epoch: 5| Step: 3
Training loss: 1.454667370059726
Validation loss: 2.326804972318094

Epoch: 5| Step: 4
Training loss: 1.8161317679456135
Validation loss: 2.2717476022513226

Epoch: 5| Step: 5
Training loss: 1.8731755599287028
Validation loss: 2.302370194874931

Epoch: 5| Step: 6
Training loss: 1.5538073784935698
Validation loss: 2.322725115312623

Epoch: 5| Step: 7
Training loss: 1.524865131980724
Validation loss: 2.3392886994350515

Epoch: 5| Step: 8
Training loss: 2.127378366940279
Validation loss: 2.3257814096528895

Epoch: 5| Step: 9
Training loss: 1.6333072770564026
Validation loss: 2.3156929914954145

Epoch: 5| Step: 10
Training loss: 2.0061275076386087
Validation loss: 2.3460241473102283

Epoch: 256| Step: 0
Training loss: 1.977029375868162
Validation loss: 2.396266947951822

Epoch: 5| Step: 1
Training loss: 1.631650666472423
Validation loss: 2.3108486963502806

Epoch: 5| Step: 2
Training loss: 2.5677531291982345
Validation loss: 2.366045956786447

Epoch: 5| Step: 3
Training loss: 1.4760313340146
Validation loss: 2.4295725807636335

Epoch: 5| Step: 4
Training loss: 1.8577898465276108
Validation loss: 2.384508682245319

Epoch: 5| Step: 5
Training loss: 1.3487046738468988
Validation loss: 2.3474102116903786

Epoch: 5| Step: 6
Training loss: 1.3010811674760963
Validation loss: 2.394892361095958

Epoch: 5| Step: 7
Training loss: 1.7906762719927578
Validation loss: 2.377749388222471

Epoch: 5| Step: 8
Training loss: 2.117168468657257
Validation loss: 2.4807704693910537

Epoch: 5| Step: 9
Training loss: 1.7640350745124393
Validation loss: 2.3523632666613015

Epoch: 5| Step: 10
Training loss: 1.674589288945684
Validation loss: 2.3709552672622136

Epoch: 257| Step: 0
Training loss: 1.8375923652530182
Validation loss: 2.381533983138288

Epoch: 5| Step: 1
Training loss: 1.454964652533339
Validation loss: 2.3468593096312027

Epoch: 5| Step: 2
Training loss: 1.9050395436825938
Validation loss: 2.3854377485211424

Epoch: 5| Step: 3
Training loss: 1.6785659949379954
Validation loss: 2.373150794807698

Epoch: 5| Step: 4
Training loss: 1.7081457205617265
Validation loss: 2.369964199192964

Epoch: 5| Step: 5
Training loss: 1.5332962688168028
Validation loss: 2.319495131067514

Epoch: 5| Step: 6
Training loss: 1.533342449879842
Validation loss: 2.3099483201893625

Epoch: 5| Step: 7
Training loss: 2.091230328200004
Validation loss: 2.2776494827509164

Epoch: 5| Step: 8
Training loss: 2.4034344933956886
Validation loss: 2.3968731143790674

Epoch: 5| Step: 9
Training loss: 1.5419960529262033
Validation loss: 2.357951514379125

Epoch: 5| Step: 10
Training loss: 1.8553011848679086
Validation loss: 2.4059136332309254

Epoch: 258| Step: 0
Training loss: 2.148845952828075
Validation loss: 2.3893969263027675

Epoch: 5| Step: 1
Training loss: 1.7237429143304954
Validation loss: 2.3333631160552253

Epoch: 5| Step: 2
Training loss: 1.5650603107860428
Validation loss: 2.3914707046388517

Epoch: 5| Step: 3
Training loss: 1.7566816295056504
Validation loss: 2.353086186762607

Epoch: 5| Step: 4
Training loss: 1.260888549913407
Validation loss: 2.403444581818031

Epoch: 5| Step: 5
Training loss: 2.4379215365043754
Validation loss: 2.340068313801155

Epoch: 5| Step: 6
Training loss: 1.0893298068715154
Validation loss: 2.3812740314487466

Epoch: 5| Step: 7
Training loss: 1.5282884100853624
Validation loss: 2.331124097800428

Epoch: 5| Step: 8
Training loss: 1.8867551432825418
Validation loss: 2.2843685700127

Epoch: 5| Step: 9
Training loss: 1.7833602852730666
Validation loss: 2.3279285776124428

Epoch: 5| Step: 10
Training loss: 1.883776595972714
Validation loss: 2.399633422281718

Epoch: 259| Step: 0
Training loss: 1.5963297142491737
Validation loss: 2.3803757409659627

Epoch: 5| Step: 1
Training loss: 1.8309331990946909
Validation loss: 2.365041869297013

Epoch: 5| Step: 2
Training loss: 1.8858383999682151
Validation loss: 2.3094949883749174

Epoch: 5| Step: 3
Training loss: 1.5528813898316962
Validation loss: 2.4314726695953954

Epoch: 5| Step: 4
Training loss: 1.8991828365845516
Validation loss: 2.3445464893963064

Epoch: 5| Step: 5
Training loss: 1.838706278433516
Validation loss: 2.3532289086887856

Epoch: 5| Step: 6
Training loss: 2.254439107492613
Validation loss: 2.3567264530723993

Epoch: 5| Step: 7
Training loss: 1.6180016868403333
Validation loss: 2.3079169882082557

Epoch: 5| Step: 8
Training loss: 1.398424883737608
Validation loss: 2.3270167534520514

Epoch: 5| Step: 9
Training loss: 2.2055916471221457
Validation loss: 2.399975349015962

Epoch: 5| Step: 10
Training loss: 1.5284316927265853
Validation loss: 2.3575564300513747

Epoch: 260| Step: 0
Training loss: 2.502447837263078
Validation loss: 2.3489533367412614

Epoch: 5| Step: 1
Training loss: 1.852656882022873
Validation loss: 2.3462974808543566

Epoch: 5| Step: 2
Training loss: 1.091136207022194
Validation loss: 2.380116155552095

Epoch: 5| Step: 3
Training loss: 1.8858983248329337
Validation loss: 2.349700002649722

Epoch: 5| Step: 4
Training loss: 1.399036939641824
Validation loss: 2.323427827131692

Epoch: 5| Step: 5
Training loss: 1.455195275013505
Validation loss: 2.3291866571149433

Epoch: 5| Step: 6
Training loss: 2.0512236780945377
Validation loss: 2.3901410611332636

Epoch: 5| Step: 7
Training loss: 1.5515448470326327
Validation loss: 2.368983518742987

Epoch: 5| Step: 8
Training loss: 1.251173231759528
Validation loss: 2.3900351512817846

Epoch: 5| Step: 9
Training loss: 1.9884373092111713
Validation loss: 2.4047209579088045

Epoch: 5| Step: 10
Training loss: 1.9372778119079526
Validation loss: 2.416340135092158

Epoch: 261| Step: 0
Training loss: 1.5594189593706775
Validation loss: 2.3728790808601987

Epoch: 5| Step: 1
Training loss: 1.2641956122514295
Validation loss: 2.328571038726361

Epoch: 5| Step: 2
Training loss: 1.7890383789568671
Validation loss: 2.395235955736103

Epoch: 5| Step: 3
Training loss: 1.7062851172106612
Validation loss: 2.3641825228706

Epoch: 5| Step: 4
Training loss: 1.533890763144657
Validation loss: 2.314385321566205

Epoch: 5| Step: 5
Training loss: 1.718049617597056
Validation loss: 2.3467597499349795

Epoch: 5| Step: 6
Training loss: 1.941620291072848
Validation loss: 2.3415153104460718

Epoch: 5| Step: 7
Training loss: 1.5361092984581834
Validation loss: 2.380172958285274

Epoch: 5| Step: 8
Training loss: 1.5748734922918834
Validation loss: 2.3245618843168505

Epoch: 5| Step: 9
Training loss: 1.784139397828656
Validation loss: 2.367417870026157

Epoch: 5| Step: 10
Training loss: 2.705992308014329
Validation loss: 2.4452743183944907

Epoch: 262| Step: 0
Training loss: 2.244417789298851
Validation loss: 2.390007660504637

Epoch: 5| Step: 1
Training loss: 1.5570610751727876
Validation loss: 2.3273721149151103

Epoch: 5| Step: 2
Training loss: 2.3299950379412944
Validation loss: 2.3553791791316923

Epoch: 5| Step: 3
Training loss: 1.4356382172258013
Validation loss: 2.3404616916786223

Epoch: 5| Step: 4
Training loss: 2.01233102314157
Validation loss: 2.308208797648345

Epoch: 5| Step: 5
Training loss: 2.09091906111681
Validation loss: 2.336972597089652

Epoch: 5| Step: 6
Training loss: 1.7944741173145384
Validation loss: 2.3815802814958777

Epoch: 5| Step: 7
Training loss: 1.6470875930377211
Validation loss: 2.3050327727189464

Epoch: 5| Step: 8
Training loss: 1.8067911941056998
Validation loss: 2.3923956292178534

Epoch: 5| Step: 9
Training loss: 1.4095549001296446
Validation loss: 2.2862941021343723

Epoch: 5| Step: 10
Training loss: 1.173455812435781
Validation loss: 2.299317127070069

Epoch: 263| Step: 0
Training loss: 1.4487708702921016
Validation loss: 2.2963636782219146

Epoch: 5| Step: 1
Training loss: 2.1405158467551604
Validation loss: 2.3045778065239704

Epoch: 5| Step: 2
Training loss: 1.588532678130521
Validation loss: 2.395838385349706

Epoch: 5| Step: 3
Training loss: 1.765897746667278
Validation loss: 2.3260759022999777

Epoch: 5| Step: 4
Training loss: 1.6460649673415033
Validation loss: 2.3974158975345192

Epoch: 5| Step: 5
Training loss: 1.2776075085009062
Validation loss: 2.340569197384394

Epoch: 5| Step: 6
Training loss: 2.013397286875132
Validation loss: 2.4019414498688327

Epoch: 5| Step: 7
Training loss: 1.9189173572629767
Validation loss: 2.4304486415180175

Epoch: 5| Step: 8
Training loss: 2.207453378463704
Validation loss: 2.3776678742990334

Epoch: 5| Step: 9
Training loss: 1.8433272313482036
Validation loss: 2.3001775660104684

Epoch: 5| Step: 10
Training loss: 1.474758842926751
Validation loss: 2.4013603315207273

Epoch: 264| Step: 0
Training loss: 1.5552390955518338
Validation loss: 2.3652522817863466

Epoch: 5| Step: 1
Training loss: 1.2146288813605248
Validation loss: 2.4189015755549526

Epoch: 5| Step: 2
Training loss: 1.7279972656943623
Validation loss: 2.4026191901011154

Epoch: 5| Step: 3
Training loss: 1.514866826086768
Validation loss: 2.36700253864112

Epoch: 5| Step: 4
Training loss: 2.4977707460450778
Validation loss: 2.3884474201022172

Epoch: 5| Step: 5
Training loss: 1.8752968870993212
Validation loss: 2.4250294889402055

Epoch: 5| Step: 6
Training loss: 1.4301508585176939
Validation loss: 2.4186267729075634

Epoch: 5| Step: 7
Training loss: 1.5824958778315608
Validation loss: 2.42804236285747

Epoch: 5| Step: 8
Training loss: 1.9586610993231965
Validation loss: 2.3807228397363

Epoch: 5| Step: 9
Training loss: 1.9482584634736804
Validation loss: 2.42248069448087

Epoch: 5| Step: 10
Training loss: 1.2201922270719376
Validation loss: 2.288776009492834

Epoch: 265| Step: 0
Training loss: 1.6784113804772294
Validation loss: 2.434544834126567

Epoch: 5| Step: 1
Training loss: 1.6390662645091272
Validation loss: 2.3419335395796783

Epoch: 5| Step: 2
Training loss: 1.987735815873441
Validation loss: 2.3643999533220055

Epoch: 5| Step: 3
Training loss: 1.3835361979236271
Validation loss: 2.320018291275753

Epoch: 5| Step: 4
Training loss: 1.757348368087403
Validation loss: 2.291246665621556

Epoch: 5| Step: 5
Training loss: 1.7299976267274664
Validation loss: 2.308682615335

Epoch: 5| Step: 6
Training loss: 1.6997621566218792
Validation loss: 2.3393580418625444

Epoch: 5| Step: 7
Training loss: 1.5671993540413476
Validation loss: 2.358912244852274

Epoch: 5| Step: 8
Training loss: 2.4650416468570557
Validation loss: 2.3872862515888538

Epoch: 5| Step: 9
Training loss: 1.3849497512626006
Validation loss: 2.339053506721772

Epoch: 5| Step: 10
Training loss: 1.3736327048878902
Validation loss: 2.4131240047918707

Epoch: 266| Step: 0
Training loss: 1.4454650798367936
Validation loss: 2.316253944852584

Epoch: 5| Step: 1
Training loss: 2.0150679180729916
Validation loss: 2.340876823022207

Epoch: 5| Step: 2
Training loss: 2.1068929126830143
Validation loss: 2.4255071813502207

Epoch: 5| Step: 3
Training loss: 1.7155860215503236
Validation loss: 2.354798121101832

Epoch: 5| Step: 4
Training loss: 1.1783837699527369
Validation loss: 2.4143111974334706

Epoch: 5| Step: 5
Training loss: 1.775664892718646
Validation loss: 2.37387518700945

Epoch: 5| Step: 6
Training loss: 1.8254836473654608
Validation loss: 2.325185313466031

Epoch: 5| Step: 7
Training loss: 1.5583045327828189
Validation loss: 2.3959925922751304

Epoch: 5| Step: 8
Training loss: 1.7286174162294832
Validation loss: 2.3796722619109745

Epoch: 5| Step: 9
Training loss: 1.1870347667670618
Validation loss: 2.437882934183608

Epoch: 5| Step: 10
Training loss: 2.2731378626570944
Validation loss: 2.399411251421008

Epoch: 267| Step: 0
Training loss: 1.9550768445417572
Validation loss: 2.381492916678383

Epoch: 5| Step: 1
Training loss: 1.8901551979164815
Validation loss: 2.3859304550151452

Epoch: 5| Step: 2
Training loss: 1.9967785759750074
Validation loss: 2.4192182960229034

Epoch: 5| Step: 3
Training loss: 1.1077020415210568
Validation loss: 2.4037637127164277

Epoch: 5| Step: 4
Training loss: 1.3285070879470402
Validation loss: 2.3464202266984677

Epoch: 5| Step: 5
Training loss: 1.484632610253041
Validation loss: 2.4526414887848667

Epoch: 5| Step: 6
Training loss: 1.9567287919462224
Validation loss: 2.3798096664607544

Epoch: 5| Step: 7
Training loss: 1.677363575648073
Validation loss: 2.374215908182662

Epoch: 5| Step: 8
Training loss: 2.078422697155354
Validation loss: 2.3410398043677207

Epoch: 5| Step: 9
Training loss: 1.659393566192958
Validation loss: 2.417600247358004

Epoch: 5| Step: 10
Training loss: 0.844795674049164
Validation loss: 2.323043393416322

Epoch: 268| Step: 0
Training loss: 1.7647144366505798
Validation loss: 2.3456284496941633

Epoch: 5| Step: 1
Training loss: 1.611767074444817
Validation loss: 2.405906547259469

Epoch: 5| Step: 2
Training loss: 2.2026554987180167
Validation loss: 2.348319298486334

Epoch: 5| Step: 3
Training loss: 1.813777802015682
Validation loss: 2.3667322619483246

Epoch: 5| Step: 4
Training loss: 1.24351583989036
Validation loss: 2.4289570395461006

Epoch: 5| Step: 5
Training loss: 1.7893781758292553
Validation loss: 2.3256579145818215

Epoch: 5| Step: 6
Training loss: 1.578132176146857
Validation loss: 2.397318376479948

Epoch: 5| Step: 7
Training loss: 2.0891476051040208
Validation loss: 2.3376446527883923

Epoch: 5| Step: 8
Training loss: 1.2183997800339659
Validation loss: 2.3880553741181076

Epoch: 5| Step: 9
Training loss: 1.4833883118173996
Validation loss: 2.367850193933784

Epoch: 5| Step: 10
Training loss: 2.167178228093056
Validation loss: 2.328573235120875

Epoch: 269| Step: 0
Training loss: 1.9806952412826466
Validation loss: 2.382809966281167

Epoch: 5| Step: 1
Training loss: 1.6120768709004731
Validation loss: 2.373270894967711

Epoch: 5| Step: 2
Training loss: 1.3471410678833728
Validation loss: 2.452545103744852

Epoch: 5| Step: 3
Training loss: 1.8975062971048318
Validation loss: 2.3818556331747907

Epoch: 5| Step: 4
Training loss: 1.7548829483601087
Validation loss: 2.3904176381222006

Epoch: 5| Step: 5
Training loss: 1.8388107866499863
Validation loss: 2.412356476741497

Epoch: 5| Step: 6
Training loss: 1.3938643199069163
Validation loss: 2.350418800950908

Epoch: 5| Step: 7
Training loss: 1.7077924135637585
Validation loss: 2.409189850826625

Epoch: 5| Step: 8
Training loss: 0.9604877256694391
Validation loss: 2.3155332791176177

Epoch: 5| Step: 9
Training loss: 2.2475596014994754
Validation loss: 2.4003435263751562

Epoch: 5| Step: 10
Training loss: 1.6215328495110597
Validation loss: 2.4027313173239047

Epoch: 270| Step: 0
Training loss: 1.6241441086594992
Validation loss: 2.4117516028992436

Epoch: 5| Step: 1
Training loss: 1.6116333458554986
Validation loss: 2.348606611430631

Epoch: 5| Step: 2
Training loss: 2.107628106039564
Validation loss: 2.3904531353968244

Epoch: 5| Step: 3
Training loss: 1.7317520102336015
Validation loss: 2.380866842396064

Epoch: 5| Step: 4
Training loss: 2.158444269439478
Validation loss: 2.4141490971323156

Epoch: 5| Step: 5
Training loss: 1.3484937636217431
Validation loss: 2.375994367826837

Epoch: 5| Step: 6
Training loss: 1.410877920183391
Validation loss: 2.3001801522998218

Epoch: 5| Step: 7
Training loss: 1.7041112161707221
Validation loss: 2.3733288985143313

Epoch: 5| Step: 8
Training loss: 1.9270694904002033
Validation loss: 2.3696645975556

Epoch: 5| Step: 9
Training loss: 1.2483821412609208
Validation loss: 2.375107206333187

Epoch: 5| Step: 10
Training loss: 1.9197955783659943
Validation loss: 2.3234042183864996

Epoch: 271| Step: 0
Training loss: 1.9474396010938175
Validation loss: 2.3766690446766696

Epoch: 5| Step: 1
Training loss: 1.3661411313921221
Validation loss: 2.3707033192598295

Epoch: 5| Step: 2
Training loss: 1.7559018750505133
Validation loss: 2.394451537566399

Epoch: 5| Step: 3
Training loss: 1.259574556277013
Validation loss: 2.403507061254071

Epoch: 5| Step: 4
Training loss: 1.8818040735212622
Validation loss: 2.408063082160251

Epoch: 5| Step: 5
Training loss: 1.9844345924860987
Validation loss: 2.405792977067669

Epoch: 5| Step: 6
Training loss: 1.581118775000145
Validation loss: 2.4381982693486832

Epoch: 5| Step: 7
Training loss: 1.6658554805156753
Validation loss: 2.3552301970005214

Epoch: 5| Step: 8
Training loss: 1.1241877590676899
Validation loss: 2.3245034050156415

Epoch: 5| Step: 9
Training loss: 1.864484034900848
Validation loss: 2.397657024719545

Epoch: 5| Step: 10
Training loss: 2.316320922720967
Validation loss: 2.3871581759921603

Epoch: 272| Step: 0
Training loss: 2.4348049425646816
Validation loss: 2.3484874730258944

Epoch: 5| Step: 1
Training loss: 1.3572256261998272
Validation loss: 2.3847090112145897

Epoch: 5| Step: 2
Training loss: 1.5308469125017012
Validation loss: 2.38879924698829

Epoch: 5| Step: 3
Training loss: 1.3011780554591144
Validation loss: 2.404093611015246

Epoch: 5| Step: 4
Training loss: 1.3672741235811448
Validation loss: 2.3405125047291073

Epoch: 5| Step: 5
Training loss: 1.6864262449601974
Validation loss: 2.355005059636654

Epoch: 5| Step: 6
Training loss: 2.1886011894177524
Validation loss: 2.3630768056556675

Epoch: 5| Step: 7
Training loss: 1.611832973114269
Validation loss: 2.3701241879376904

Epoch: 5| Step: 8
Training loss: 1.964687576306079
Validation loss: 2.3767133980778783

Epoch: 5| Step: 9
Training loss: 1.46758223840961
Validation loss: 2.3508998504238594

Epoch: 5| Step: 10
Training loss: 1.8140105825744282
Validation loss: 2.4114748915378876

Epoch: 273| Step: 0
Training loss: 1.4512140978989536
Validation loss: 2.381274347964312

Epoch: 5| Step: 1
Training loss: 1.464425151778589
Validation loss: 2.4663946282199576

Epoch: 5| Step: 2
Training loss: 1.7926401406469292
Validation loss: 2.35688792016996

Epoch: 5| Step: 3
Training loss: 1.652144471905706
Validation loss: 2.366185752871377

Epoch: 5| Step: 4
Training loss: 1.138146935408157
Validation loss: 2.3891134988384164

Epoch: 5| Step: 5
Training loss: 1.6032093048236846
Validation loss: 2.433670734046483

Epoch: 5| Step: 6
Training loss: 1.579816761256035
Validation loss: 2.3656274076020853

Epoch: 5| Step: 7
Training loss: 2.427670441918888
Validation loss: 2.3059314983508004

Epoch: 5| Step: 8
Training loss: 2.074088974393324
Validation loss: 2.4108031649812576

Epoch: 5| Step: 9
Training loss: 1.3048440074132428
Validation loss: 2.399903894281083

Epoch: 5| Step: 10
Training loss: 1.3063078087239308
Validation loss: 2.4313552577638964

Epoch: 274| Step: 0
Training loss: 1.6525369445549156
Validation loss: 2.3554870150906906

Epoch: 5| Step: 1
Training loss: 1.9560690701699137
Validation loss: 2.447573616603078

Epoch: 5| Step: 2
Training loss: 1.9434709526503802
Validation loss: 2.3958556685581405

Epoch: 5| Step: 3
Training loss: 1.1860179687862809
Validation loss: 2.3032697557459327

Epoch: 5| Step: 4
Training loss: 1.3395046327688107
Validation loss: 2.341558063670755

Epoch: 5| Step: 5
Training loss: 1.8192807658619932
Validation loss: 2.3825002265619055

Epoch: 5| Step: 6
Training loss: 2.2798611319230107
Validation loss: 2.348752597335288

Epoch: 5| Step: 7
Training loss: 1.7469291310120987
Validation loss: 2.3191839408183283

Epoch: 5| Step: 8
Training loss: 1.798374379738125
Validation loss: 2.3593000440691565

Epoch: 5| Step: 9
Training loss: 1.1929368490114514
Validation loss: 2.352386846869003

Epoch: 5| Step: 10
Training loss: 1.708700590277406
Validation loss: 2.3887352087534484

Epoch: 275| Step: 0
Training loss: 1.9011203348961732
Validation loss: 2.3074134441377607

Epoch: 5| Step: 1
Training loss: 1.6152444859918196
Validation loss: 2.417492373971614

Epoch: 5| Step: 2
Training loss: 1.7625644455618952
Validation loss: 2.35461937786445

Epoch: 5| Step: 3
Training loss: 2.45898311454371
Validation loss: 2.4504684926153444

Epoch: 5| Step: 4
Training loss: 1.6449851091632703
Validation loss: 2.333676256596486

Epoch: 5| Step: 5
Training loss: 1.8537868868038179
Validation loss: 2.338131952551708

Epoch: 5| Step: 6
Training loss: 1.4091816331793134
Validation loss: 2.3989897718724085

Epoch: 5| Step: 7
Training loss: 1.3722848093291893
Validation loss: 2.3700073573144236

Epoch: 5| Step: 8
Training loss: 1.4249315211924714
Validation loss: 2.399795890959722

Epoch: 5| Step: 9
Training loss: 1.8422523493591973
Validation loss: 2.365929421051591

Epoch: 5| Step: 10
Training loss: 1.6055671309054231
Validation loss: 2.354531544003468

Epoch: 276| Step: 0
Training loss: 1.2317812262561054
Validation loss: 2.4182824234482894

Epoch: 5| Step: 1
Training loss: 1.9775243537261629
Validation loss: 2.3867126274644623

Epoch: 5| Step: 2
Training loss: 2.2421289097378145
Validation loss: 2.3710756397314223

Epoch: 5| Step: 3
Training loss: 1.2623537904283657
Validation loss: 2.353305336379761

Epoch: 5| Step: 4
Training loss: 1.0994035924649128
Validation loss: 2.372308583434422

Epoch: 5| Step: 5
Training loss: 1.5926327248543073
Validation loss: 2.3232670194262792

Epoch: 5| Step: 6
Training loss: 1.1979834938759053
Validation loss: 2.4083985228270066

Epoch: 5| Step: 7
Training loss: 1.8265213412696621
Validation loss: 2.3741886154023684

Epoch: 5| Step: 8
Training loss: 1.4206042637383611
Validation loss: 2.3653318261224996

Epoch: 5| Step: 9
Training loss: 2.030265334692525
Validation loss: 2.410045697895433

Epoch: 5| Step: 10
Training loss: 1.9389759102791093
Validation loss: 2.3255062677208636

Epoch: 277| Step: 0
Training loss: 1.942423686292229
Validation loss: 2.4238198983314105

Epoch: 5| Step: 1
Training loss: 1.2041073046421276
Validation loss: 2.3605126404409473

Epoch: 5| Step: 2
Training loss: 1.9982209041275953
Validation loss: 2.3406259929919333

Epoch: 5| Step: 3
Training loss: 1.7187276665363624
Validation loss: 2.3545922858267634

Epoch: 5| Step: 4
Training loss: 1.8355615758540575
Validation loss: 2.395734839713197

Epoch: 5| Step: 5
Training loss: 2.152134381476923
Validation loss: 2.3701968952165835

Epoch: 5| Step: 6
Training loss: 1.3082150039292997
Validation loss: 2.300019417333475

Epoch: 5| Step: 7
Training loss: 1.38691052467401
Validation loss: 2.3924913943059187

Epoch: 5| Step: 8
Training loss: 1.6022389541795203
Validation loss: 2.428179361443278

Epoch: 5| Step: 9
Training loss: 1.4571348260877253
Validation loss: 2.431264321801472

Epoch: 5| Step: 10
Training loss: 1.227464914927606
Validation loss: 2.3964048537686327

Epoch: 278| Step: 0
Training loss: 1.6354730276451102
Validation loss: 2.3865154648305946

Epoch: 5| Step: 1
Training loss: 1.9623875822682866
Validation loss: 2.3616575128419566

Epoch: 5| Step: 2
Training loss: 1.2163601454350228
Validation loss: 2.358386679652973

Epoch: 5| Step: 3
Training loss: 1.870127514046228
Validation loss: 2.32828047930315

Epoch: 5| Step: 4
Training loss: 1.249420508528637
Validation loss: 2.3496048436894177

Epoch: 5| Step: 5
Training loss: 1.0849160529328137
Validation loss: 2.3774863884476476

Epoch: 5| Step: 6
Training loss: 1.3167120694327892
Validation loss: 2.3801487916814352

Epoch: 5| Step: 7
Training loss: 1.351279962368046
Validation loss: 2.3656114928087955

Epoch: 5| Step: 8
Training loss: 2.346519156754348
Validation loss: 2.416042113160801

Epoch: 5| Step: 9
Training loss: 1.619127372438979
Validation loss: 2.431907230460401

Epoch: 5| Step: 10
Training loss: 1.9327073656875882
Validation loss: 2.3777331701911923

Epoch: 279| Step: 0
Training loss: 1.6545930887724185
Validation loss: 2.398139575164567

Epoch: 5| Step: 1
Training loss: 1.79166280021546
Validation loss: 2.408345890094042

Epoch: 5| Step: 2
Training loss: 1.7190057737598576
Validation loss: 2.3854219245198913

Epoch: 5| Step: 3
Training loss: 1.8082217664039975
Validation loss: 2.3767207442087073

Epoch: 5| Step: 4
Training loss: 2.025672650175478
Validation loss: 2.4614106066801806

Epoch: 5| Step: 5
Training loss: 1.3566789309176155
Validation loss: 2.3231475757984406

Epoch: 5| Step: 6
Training loss: 1.1341294098975083
Validation loss: 2.4445536882668004

Epoch: 5| Step: 7
Training loss: 1.745851094497734
Validation loss: 2.4122401903767905

Epoch: 5| Step: 8
Training loss: 1.5831876319637321
Validation loss: 2.461698391492123

Epoch: 5| Step: 9
Training loss: 1.446462225480438
Validation loss: 2.3765138810804554

Epoch: 5| Step: 10
Training loss: 2.1714559466386
Validation loss: 2.3449035463752814

Epoch: 280| Step: 0
Training loss: 1.6659096508600013
Validation loss: 2.360371569410385

Epoch: 5| Step: 1
Training loss: 1.607119340573176
Validation loss: 2.3534678932972777

Epoch: 5| Step: 2
Training loss: 2.3641987178307535
Validation loss: 2.325152241594679

Epoch: 5| Step: 3
Training loss: 1.7848583949577819
Validation loss: 2.384618376693837

Epoch: 5| Step: 4
Training loss: 1.5226901055022355
Validation loss: 2.361891496150141

Epoch: 5| Step: 5
Training loss: 1.3245211005713593
Validation loss: 2.4042840945989417

Epoch: 5| Step: 6
Training loss: 1.4091750347777054
Validation loss: 2.3992046361115333

Epoch: 5| Step: 7
Training loss: 1.6833486002365086
Validation loss: 2.416192372773563

Epoch: 5| Step: 8
Training loss: 1.4302946375372616
Validation loss: 2.3834383568433952

Epoch: 5| Step: 9
Training loss: 1.587176285426385
Validation loss: 2.3537890198243008

Epoch: 5| Step: 10
Training loss: 1.372074700073612
Validation loss: 2.4159385537614293

Epoch: 281| Step: 0
Training loss: 1.4806071596693156
Validation loss: 2.4085400427041717

Epoch: 5| Step: 1
Training loss: 1.2641071589895254
Validation loss: 2.363661033564876

Epoch: 5| Step: 2
Training loss: 1.3760711659059264
Validation loss: 2.404411334718884

Epoch: 5| Step: 3
Training loss: 1.404734409384932
Validation loss: 2.3814011402852384

Epoch: 5| Step: 4
Training loss: 1.8537252164947298
Validation loss: 2.3648368454164617

Epoch: 5| Step: 5
Training loss: 1.3458267841632485
Validation loss: 2.373756545174876

Epoch: 5| Step: 6
Training loss: 2.0005984603041504
Validation loss: 2.4089400662197438

Epoch: 5| Step: 7
Training loss: 2.259479580433457
Validation loss: 2.3302892390171928

Epoch: 5| Step: 8
Training loss: 1.3320112031116118
Validation loss: 2.4201687129551597

Epoch: 5| Step: 9
Training loss: 1.516267620591239
Validation loss: 2.4337000361703662

Epoch: 5| Step: 10
Training loss: 1.8548774499846803
Validation loss: 2.4499663482290304

Epoch: 282| Step: 0
Training loss: 1.3615397613076543
Validation loss: 2.3695691081386845

Epoch: 5| Step: 1
Training loss: 1.6773206491571941
Validation loss: 2.361338590907172

Epoch: 5| Step: 2
Training loss: 1.376011303151081
Validation loss: 2.4243342562692898

Epoch: 5| Step: 3
Training loss: 2.0416701440067913
Validation loss: 2.352511699132581

Epoch: 5| Step: 4
Training loss: 1.3690309140467656
Validation loss: 2.4369282289822154

Epoch: 5| Step: 5
Training loss: 2.024324907399747
Validation loss: 2.4156394900009803

Epoch: 5| Step: 6
Training loss: 1.5974148518968605
Validation loss: 2.4091399531741486

Epoch: 5| Step: 7
Training loss: 1.9098383789186713
Validation loss: 2.4297504293580885

Epoch: 5| Step: 8
Training loss: 1.656249568147423
Validation loss: 2.404411944598831

Epoch: 5| Step: 9
Training loss: 1.4854261190248328
Validation loss: 2.3734414141369666

Epoch: 5| Step: 10
Training loss: 1.3403294519840847
Validation loss: 2.4257540829521878

Epoch: 283| Step: 0
Training loss: 2.10966252380694
Validation loss: 2.3736509205819507

Epoch: 5| Step: 1
Training loss: 1.5040769802135951
Validation loss: 2.363144941271123

Epoch: 5| Step: 2
Training loss: 1.690531092378397
Validation loss: 2.414027813444107

Epoch: 5| Step: 3
Training loss: 1.7312471520576052
Validation loss: 2.39876099914318

Epoch: 5| Step: 4
Training loss: 1.6443593712371736
Validation loss: 2.465075123154785

Epoch: 5| Step: 5
Training loss: 1.6044262102229236
Validation loss: 2.411629793622949

Epoch: 5| Step: 6
Training loss: 1.7136071684433625
Validation loss: 2.3194199413550796

Epoch: 5| Step: 7
Training loss: 1.298091318045243
Validation loss: 2.3612895418804967

Epoch: 5| Step: 8
Training loss: 1.3094746371941353
Validation loss: 2.37994494748748

Epoch: 5| Step: 9
Training loss: 1.3099483026976126
Validation loss: 2.393711450202596

Epoch: 5| Step: 10
Training loss: 1.5968940987536642
Validation loss: 2.4057778847648166

Epoch: 284| Step: 0
Training loss: 1.7219285184709001
Validation loss: 2.429024965192535

Epoch: 5| Step: 1
Training loss: 1.4219483576704584
Validation loss: 2.359243377184745

Epoch: 5| Step: 2
Training loss: 1.829794813962211
Validation loss: 2.3605649398053803

Epoch: 5| Step: 3
Training loss: 2.1228522498403177
Validation loss: 2.3857856931112034

Epoch: 5| Step: 4
Training loss: 1.7909161821919424
Validation loss: 2.3570142079254275

Epoch: 5| Step: 5
Training loss: 1.614970212136136
Validation loss: 2.427464517862721

Epoch: 5| Step: 6
Training loss: 1.7806955779720748
Validation loss: 2.459324034520204

Epoch: 5| Step: 7
Training loss: 1.3751062438839732
Validation loss: 2.366342746949102

Epoch: 5| Step: 8
Training loss: 1.718104431983947
Validation loss: 2.4095751913454446

Epoch: 5| Step: 9
Training loss: 1.6494222294101024
Validation loss: 2.4172421266345396

Epoch: 5| Step: 10
Training loss: 1.3008424670045187
Validation loss: 2.398042980477349

Epoch: 285| Step: 0
Training loss: 1.649635711105594
Validation loss: 2.39383552651444

Epoch: 5| Step: 1
Training loss: 1.645239090979985
Validation loss: 2.3831574468540055

Epoch: 5| Step: 2
Training loss: 1.5537446196409996
Validation loss: 2.3330576604905446

Epoch: 5| Step: 3
Training loss: 1.6448187135095707
Validation loss: 2.426499816077709

Epoch: 5| Step: 4
Training loss: 1.3590468964390379
Validation loss: 2.3615185006331028

Epoch: 5| Step: 5
Training loss: 1.519958592904921
Validation loss: 2.375271212296601

Epoch: 5| Step: 6
Training loss: 1.5039458034317708
Validation loss: 2.4419586583123993

Epoch: 5| Step: 7
Training loss: 2.004229127329614
Validation loss: 2.4366606005090965

Epoch: 5| Step: 8
Training loss: 1.5879056397275977
Validation loss: 2.407000849237748

Epoch: 5| Step: 9
Training loss: 1.627755396620016
Validation loss: 2.3965200038491545

Epoch: 5| Step: 10
Training loss: 1.898797209142125
Validation loss: 2.398261290882061

Epoch: 286| Step: 0
Training loss: 1.7792028743564592
Validation loss: 2.4196145911220976

Epoch: 5| Step: 1
Training loss: 1.1292038891464862
Validation loss: 2.4398998166568884

Epoch: 5| Step: 2
Training loss: 1.6188170842590024
Validation loss: 2.459273566436495

Epoch: 5| Step: 3
Training loss: 1.8347487476686102
Validation loss: 2.4899520206289005

Epoch: 5| Step: 4
Training loss: 2.061114337035491
Validation loss: 2.453592930236276

Epoch: 5| Step: 5
Training loss: 1.5001159464211122
Validation loss: 2.388936829481392

Epoch: 5| Step: 6
Training loss: 1.6063967062602909
Validation loss: 2.4378999298378883

Epoch: 5| Step: 7
Training loss: 1.591178015483883
Validation loss: 2.405470207270479

Epoch: 5| Step: 8
Training loss: 1.4800507853790104
Validation loss: 2.4465821300199404

Epoch: 5| Step: 9
Training loss: 1.6312066901877522
Validation loss: 2.3926509749819616

Epoch: 5| Step: 10
Training loss: 1.603446038951452
Validation loss: 2.4226813057488403

Epoch: 287| Step: 0
Training loss: 1.88804349337605
Validation loss: 2.3628496861288575

Epoch: 5| Step: 1
Training loss: 1.7418346646459884
Validation loss: 2.394879059501481

Epoch: 5| Step: 2
Training loss: 1.6732868401019663
Validation loss: 2.3565596024503153

Epoch: 5| Step: 3
Training loss: 1.2531407952205027
Validation loss: 2.3950625177897074

Epoch: 5| Step: 4
Training loss: 1.200855294043779
Validation loss: 2.3645823394988694

Epoch: 5| Step: 5
Training loss: 2.1277695727321544
Validation loss: 2.399430495119353

Epoch: 5| Step: 6
Training loss: 1.7387758387189023
Validation loss: 2.4283901507619516

Epoch: 5| Step: 7
Training loss: 1.5345188982394302
Validation loss: 2.325871206053045

Epoch: 5| Step: 8
Training loss: 1.3199875109977608
Validation loss: 2.494035514306061

Epoch: 5| Step: 9
Training loss: 1.5187237709825996
Validation loss: 2.384991162707399

Epoch: 5| Step: 10
Training loss: 1.5412185206605598
Validation loss: 2.397481269366763

Epoch: 288| Step: 0
Training loss: 1.5391320537206297
Validation loss: 2.4700596203009724

Epoch: 5| Step: 1
Training loss: 1.2748888790101875
Validation loss: 2.3761927206327926

Epoch: 5| Step: 2
Training loss: 1.3421478478788378
Validation loss: 2.4568200745387383

Epoch: 5| Step: 3
Training loss: 2.1732982116427872
Validation loss: 2.4018529577880265

Epoch: 5| Step: 4
Training loss: 1.3444312387050812
Validation loss: 2.4282390464704866

Epoch: 5| Step: 5
Training loss: 1.6271340222670865
Validation loss: 2.4654695120772216

Epoch: 5| Step: 6
Training loss: 1.2213352367287036
Validation loss: 2.3675156752365685

Epoch: 5| Step: 7
Training loss: 1.285931941561546
Validation loss: 2.401063495394664

Epoch: 5| Step: 8
Training loss: 2.223441416025902
Validation loss: 2.4217703382177205

Epoch: 5| Step: 9
Training loss: 1.5487521563030808
Validation loss: 2.3678251198526685

Epoch: 5| Step: 10
Training loss: 1.6916209166154828
Validation loss: 2.3010020788757126

Epoch: 289| Step: 0
Training loss: 1.6335290677999244
Validation loss: 2.4248887617263697

Epoch: 5| Step: 1
Training loss: 1.3418404517947784
Validation loss: 2.395748388024875

Epoch: 5| Step: 2
Training loss: 2.0032030920556307
Validation loss: 2.4544677299284112

Epoch: 5| Step: 3
Training loss: 1.720813067904181
Validation loss: 2.3574313849618678

Epoch: 5| Step: 4
Training loss: 1.4524676569162625
Validation loss: 2.3999772295717654

Epoch: 5| Step: 5
Training loss: 2.1467253920221006
Validation loss: 2.4123937319550817

Epoch: 5| Step: 6
Training loss: 1.4905287225688522
Validation loss: 2.4653706909523168

Epoch: 5| Step: 7
Training loss: 1.6080214354476532
Validation loss: 2.36485496443618

Epoch: 5| Step: 8
Training loss: 1.122388457637665
Validation loss: 2.453992351827183

Epoch: 5| Step: 9
Training loss: 1.3310705395298266
Validation loss: 2.4449992488517105

Epoch: 5| Step: 10
Training loss: 1.7962097926939122
Validation loss: 2.4309527357909237

Epoch: 290| Step: 0
Training loss: 1.680256450016927
Validation loss: 2.4093777614257568

Epoch: 5| Step: 1
Training loss: 1.327687359679183
Validation loss: 2.38346236747555

Epoch: 5| Step: 2
Training loss: 1.5384639602421992
Validation loss: 2.3465247297390452

Epoch: 5| Step: 3
Training loss: 1.432635327349795
Validation loss: 2.337056819888155

Epoch: 5| Step: 4
Training loss: 1.4976400248126711
Validation loss: 2.3999902951478433

Epoch: 5| Step: 5
Training loss: 1.7308535180394162
Validation loss: 2.341243631574467

Epoch: 5| Step: 6
Training loss: 1.459187402859279
Validation loss: 2.3914924670763504

Epoch: 5| Step: 7
Training loss: 1.326865417977736
Validation loss: 2.387050223187635

Epoch: 5| Step: 8
Training loss: 1.7238420829493117
Validation loss: 2.3834373974026355

Epoch: 5| Step: 9
Training loss: 1.8105865112048318
Validation loss: 2.3565800157792642

Epoch: 5| Step: 10
Training loss: 1.5161345107209316
Validation loss: 2.3414235382485824

Epoch: 291| Step: 0
Training loss: 1.2385725286481708
Validation loss: 2.377644498451299

Epoch: 5| Step: 1
Training loss: 1.6874314753430053
Validation loss: 2.432459747148679

Epoch: 5| Step: 2
Training loss: 1.38985717664026
Validation loss: 2.3919250697986114

Epoch: 5| Step: 3
Training loss: 1.4996730130150293
Validation loss: 2.51876460312649

Epoch: 5| Step: 4
Training loss: 1.3092354183408432
Validation loss: 2.484415560784854

Epoch: 5| Step: 5
Training loss: 1.7138477117839297
Validation loss: 2.3852449806620637

Epoch: 5| Step: 6
Training loss: 1.8573068609238392
Validation loss: 2.4631576115582114

Epoch: 5| Step: 7
Training loss: 0.897002658331854
Validation loss: 2.361120030552977

Epoch: 5| Step: 8
Training loss: 1.7166818834142723
Validation loss: 2.405175368475364

Epoch: 5| Step: 9
Training loss: 1.7947776827836606
Validation loss: 2.434307527739809

Epoch: 5| Step: 10
Training loss: 1.5806858699929398
Validation loss: 2.4054716449728346

Epoch: 292| Step: 0
Training loss: 2.487244394482971
Validation loss: 2.4274421496021636

Epoch: 5| Step: 1
Training loss: 1.8617572429870053
Validation loss: 2.4738436025409163

Epoch: 5| Step: 2
Training loss: 1.418890535225374
Validation loss: 2.452162682993991

Epoch: 5| Step: 3
Training loss: 1.2043172205401342
Validation loss: 2.4150880187864407

Epoch: 5| Step: 4
Training loss: 1.65047693873314
Validation loss: 2.3393387768738956

Epoch: 5| Step: 5
Training loss: 1.8668706138209388
Validation loss: 2.412255537163144

Epoch: 5| Step: 6
Training loss: 1.403869181776757
Validation loss: 2.4135833656613848

Epoch: 5| Step: 7
Training loss: 0.927155774033045
Validation loss: 2.413031862257695

Epoch: 5| Step: 8
Training loss: 1.3736308824234627
Validation loss: 2.4466968266206166

Epoch: 5| Step: 9
Training loss: 1.5328912308409195
Validation loss: 2.468423412897483

Epoch: 5| Step: 10
Training loss: 1.3868607569234332
Validation loss: 2.3577034058272845

Epoch: 293| Step: 0
Training loss: 1.1238410065900166
Validation loss: 2.4335123431475676

Epoch: 5| Step: 1
Training loss: 1.3593527693410559
Validation loss: 2.362044671949073

Epoch: 5| Step: 2
Training loss: 1.9997046967887862
Validation loss: 2.394850940291331

Epoch: 5| Step: 3
Training loss: 1.6527876742340055
Validation loss: 2.3894830612122178

Epoch: 5| Step: 4
Training loss: 1.3941204416957595
Validation loss: 2.4016803232582826

Epoch: 5| Step: 5
Training loss: 1.673650280330093
Validation loss: 2.4638316759419348

Epoch: 5| Step: 6
Training loss: 1.610541800325121
Validation loss: 2.3551054714371586

Epoch: 5| Step: 7
Training loss: 1.5016271984122673
Validation loss: 2.429435963597227

Epoch: 5| Step: 8
Training loss: 1.4165536424017828
Validation loss: 2.357305699753118

Epoch: 5| Step: 9
Training loss: 1.8223854671538495
Validation loss: 2.3233249367511166

Epoch: 5| Step: 10
Training loss: 1.9368677645926968
Validation loss: 2.3999537414789347

Epoch: 294| Step: 0
Training loss: 2.0990431194992376
Validation loss: 2.382961003493748

Epoch: 5| Step: 1
Training loss: 1.5567059473286418
Validation loss: 2.422811358792335

Epoch: 5| Step: 2
Training loss: 1.298715182104772
Validation loss: 2.4001843385933186

Epoch: 5| Step: 3
Training loss: 1.8114463111108507
Validation loss: 2.425344899165088

Epoch: 5| Step: 4
Training loss: 1.4252718917056686
Validation loss: 2.401501226396415

Epoch: 5| Step: 5
Training loss: 1.1632571923078459
Validation loss: 2.4093411964260594

Epoch: 5| Step: 6
Training loss: 1.936907154565994
Validation loss: 2.3641653182470446

Epoch: 5| Step: 7
Training loss: 1.1978983117507973
Validation loss: 2.447211132777367

Epoch: 5| Step: 8
Training loss: 1.6395763860779107
Validation loss: 2.373381774732499

Epoch: 5| Step: 9
Training loss: 1.6839107914127396
Validation loss: 2.382385256487164

Epoch: 5| Step: 10
Training loss: 1.5279318221295648
Validation loss: 2.415545381298553

Epoch: 295| Step: 0
Training loss: 1.4606941550863306
Validation loss: 2.462865701391397

Epoch: 5| Step: 1
Training loss: 2.3100300563161476
Validation loss: 2.4288752968005505

Epoch: 5| Step: 2
Training loss: 1.4497033308989908
Validation loss: 2.3912465628422734

Epoch: 5| Step: 3
Training loss: 1.192902972513295
Validation loss: 2.4415458839437116

Epoch: 5| Step: 4
Training loss: 1.2911277641497991
Validation loss: 2.429215558057351

Epoch: 5| Step: 5
Training loss: 1.6064370013082876
Validation loss: 2.41694949287533

Epoch: 5| Step: 6
Training loss: 1.3982241164072227
Validation loss: 2.445345679214682

Epoch: 5| Step: 7
Training loss: 1.8955439112594938
Validation loss: 2.4494004084483847

Epoch: 5| Step: 8
Training loss: 2.041375029099242
Validation loss: 2.473674176428001

Epoch: 5| Step: 9
Training loss: 1.146032084942925
Validation loss: 2.40725297750913

Epoch: 5| Step: 10
Training loss: 1.7670725062400723
Validation loss: 2.4324117665433937

Epoch: 296| Step: 0
Training loss: 1.4510790460194203
Validation loss: 2.4585224964896684

Epoch: 5| Step: 1
Training loss: 1.6695913244211218
Validation loss: 2.3332873777912178

Epoch: 5| Step: 2
Training loss: 1.3985149852234882
Validation loss: 2.392582241688498

Epoch: 5| Step: 3
Training loss: 1.5992589247613893
Validation loss: 2.347106598433396

Epoch: 5| Step: 4
Training loss: 1.4236936571127157
Validation loss: 2.3043607908133596

Epoch: 5| Step: 5
Training loss: 1.8336121462730892
Validation loss: 2.4176574142930347

Epoch: 5| Step: 6
Training loss: 1.503980917129794
Validation loss: 2.3825792316453134

Epoch: 5| Step: 7
Training loss: 1.77596986090372
Validation loss: 2.402593206977808

Epoch: 5| Step: 8
Training loss: 2.277376518210061
Validation loss: 2.3959164348669497

Epoch: 5| Step: 9
Training loss: 1.3631111191887184
Validation loss: 2.4664334765506584

Epoch: 5| Step: 10
Training loss: 1.1954411954724418
Validation loss: 2.4373307317875295

Epoch: 297| Step: 0
Training loss: 1.3262560091592628
Validation loss: 2.34752351146288

Epoch: 5| Step: 1
Training loss: 1.248978769847309
Validation loss: 2.4329276925999417

Epoch: 5| Step: 2
Training loss: 2.1206237384624873
Validation loss: 2.4464256868900707

Epoch: 5| Step: 3
Training loss: 1.3958332811422005
Validation loss: 2.3929546837547973

Epoch: 5| Step: 4
Training loss: 1.763783262332528
Validation loss: 2.515809644647293

Epoch: 5| Step: 5
Training loss: 1.8506070017559428
Validation loss: 2.4974331414414883

Epoch: 5| Step: 6
Training loss: 1.5092926666360642
Validation loss: 2.475094435510114

Epoch: 5| Step: 7
Training loss: 1.8716092922535226
Validation loss: 2.4784798322617108

Epoch: 5| Step: 8
Training loss: 1.4442958245887718
Validation loss: 2.533525535633014

Epoch: 5| Step: 9
Training loss: 1.419780236149444
Validation loss: 2.5071307259213627

Epoch: 5| Step: 10
Training loss: 0.9378961361965836
Validation loss: 2.444366597130512

Epoch: 298| Step: 0
Training loss: 1.8517987064400314
Validation loss: 2.393959074877501

Epoch: 5| Step: 1
Training loss: 1.5908073485650025
Validation loss: 2.4511800726224946

Epoch: 5| Step: 2
Training loss: 1.6440096863974085
Validation loss: 2.4357162082390844

Epoch: 5| Step: 3
Training loss: 2.183896066009124
Validation loss: 2.4280676259712077

Epoch: 5| Step: 4
Training loss: 1.3693497915659396
Validation loss: 2.3676552751829067

Epoch: 5| Step: 5
Training loss: 1.5765052263274282
Validation loss: 2.4452598964769527

Epoch: 5| Step: 6
Training loss: 1.3403198463983939
Validation loss: 2.413102109160688

Epoch: 5| Step: 7
Training loss: 1.4818893501426766
Validation loss: 2.4248339870737206

Epoch: 5| Step: 8
Training loss: 1.402038923621129
Validation loss: 2.4363219072751083

Epoch: 5| Step: 9
Training loss: 1.3513603279743525
Validation loss: 2.4210838060227395

Epoch: 5| Step: 10
Training loss: 1.9613855465595762
Validation loss: 2.337069831355609

Epoch: 299| Step: 0
Training loss: 1.3355793166034826
Validation loss: 2.443690906401107

Epoch: 5| Step: 1
Training loss: 2.0742451869048533
Validation loss: 2.403107820236604

Epoch: 5| Step: 2
Training loss: 1.4271156233130087
Validation loss: 2.4347201120035384

Epoch: 5| Step: 3
Training loss: 1.5026001646450262
Validation loss: 2.4472784260651204

Epoch: 5| Step: 4
Training loss: 1.3663487068391547
Validation loss: 2.3469992676543496

Epoch: 5| Step: 5
Training loss: 1.6195034085432494
Validation loss: 2.429372655694119

Epoch: 5| Step: 6
Training loss: 1.415277117495164
Validation loss: 2.426589662814668

Epoch: 5| Step: 7
Training loss: 1.6272338771493122
Validation loss: 2.5017495514357546

Epoch: 5| Step: 8
Training loss: 1.014986336244965
Validation loss: 2.415878702797932

Epoch: 5| Step: 9
Training loss: 1.8893467388758813
Validation loss: 2.4767677638975942

Epoch: 5| Step: 10
Training loss: 1.3231600690184593
Validation loss: 2.4266099207118925

Epoch: 300| Step: 0
Training loss: 1.630689052436449
Validation loss: 2.45437205167451

Epoch: 5| Step: 1
Training loss: 1.5364954108813023
Validation loss: 2.4009492695453005

Epoch: 5| Step: 2
Training loss: 1.441567264650725
Validation loss: 2.4941767678231113

Epoch: 5| Step: 3
Training loss: 1.7695286900247074
Validation loss: 2.4845986286583948

Epoch: 5| Step: 4
Training loss: 1.1220933133283626
Validation loss: 2.4653433861543688

Epoch: 5| Step: 5
Training loss: 2.0720684162612684
Validation loss: 2.3976058252870924

Epoch: 5| Step: 6
Training loss: 1.3943318884326277
Validation loss: 2.3997128792578506

Epoch: 5| Step: 7
Training loss: 1.4384870871931255
Validation loss: 2.375099242662213

Epoch: 5| Step: 8
Training loss: 1.797043634877316
Validation loss: 2.3326066272800223

Epoch: 5| Step: 9
Training loss: 1.630597962769034
Validation loss: 2.359291605978797

Epoch: 5| Step: 10
Training loss: 1.3690544678139616
Validation loss: 2.3654920826570387

Epoch: 301| Step: 0
Training loss: 1.3876338035057505
Validation loss: 2.4629347111898525

Epoch: 5| Step: 1
Training loss: 2.1908754736135387
Validation loss: 2.4472534256902367

Epoch: 5| Step: 2
Training loss: 1.2977561255413148
Validation loss: 2.3950142573592643

Epoch: 5| Step: 3
Training loss: 1.708634241476399
Validation loss: 2.4048555177187727

Epoch: 5| Step: 4
Training loss: 1.5293209614811758
Validation loss: 2.4067885210834357

Epoch: 5| Step: 5
Training loss: 1.3568304076877609
Validation loss: 2.385126796903438

Epoch: 5| Step: 6
Training loss: 1.7742869489589597
Validation loss: 2.487484906433653

Epoch: 5| Step: 7
Training loss: 1.2727102531651333
Validation loss: 2.4244084323719974

Epoch: 5| Step: 8
Training loss: 1.5952120040340503
Validation loss: 2.4587304503848553

Epoch: 5| Step: 9
Training loss: 1.3668213708279118
Validation loss: 2.4660371064986677

Epoch: 5| Step: 10
Training loss: 1.4504020363759191
Validation loss: 2.478364657726469

Epoch: 302| Step: 0
Training loss: 1.807958371830967
Validation loss: 2.421057951706733

Epoch: 5| Step: 1
Training loss: 1.4496739744462854
Validation loss: 2.349867121592758

Epoch: 5| Step: 2
Training loss: 2.0157402064792698
Validation loss: 2.4412894167273267

Epoch: 5| Step: 3
Training loss: 1.5720875135673367
Validation loss: 2.4074264567508226

Epoch: 5| Step: 4
Training loss: 1.5231516251958608
Validation loss: 2.4086732481929714

Epoch: 5| Step: 5
Training loss: 1.428243355886322
Validation loss: 2.3559276699910416

Epoch: 5| Step: 6
Training loss: 1.1698940573109262
Validation loss: 2.4184790453539926

Epoch: 5| Step: 7
Training loss: 1.4536214821212232
Validation loss: 2.359102495952582

Epoch: 5| Step: 8
Training loss: 1.2725425336882756
Validation loss: 2.484467773810365

Epoch: 5| Step: 9
Training loss: 1.2122725971560062
Validation loss: 2.4305276965426166

Epoch: 5| Step: 10
Training loss: 1.7480180961754614
Validation loss: 2.3805903495313543

Epoch: 303| Step: 0
Training loss: 1.7313027879950642
Validation loss: 2.387891181726225

Epoch: 5| Step: 1
Training loss: 1.529652443348693
Validation loss: 2.416473701511449

Epoch: 5| Step: 2
Training loss: 1.5223804425681717
Validation loss: 2.4134018495761005

Epoch: 5| Step: 3
Training loss: 1.303280282774254
Validation loss: 2.433097777622494

Epoch: 5| Step: 4
Training loss: 1.1864302484784766
Validation loss: 2.427447669871459

Epoch: 5| Step: 5
Training loss: 1.4792569719427175
Validation loss: 2.454063230360209

Epoch: 5| Step: 6
Training loss: 1.2574590340344214
Validation loss: 2.420565932212813

Epoch: 5| Step: 7
Training loss: 1.9309515886090671
Validation loss: 2.4112470434112208

Epoch: 5| Step: 8
Training loss: 1.3744396021406529
Validation loss: 2.472950392326193

Epoch: 5| Step: 9
Training loss: 1.5008190620897504
Validation loss: 2.4616409153289514

Epoch: 5| Step: 10
Training loss: 1.8039793136028086
Validation loss: 2.4805517421613894

Epoch: 304| Step: 0
Training loss: 1.578220024647232
Validation loss: 2.4306427994953475

Epoch: 5| Step: 1
Training loss: 1.4553546821914451
Validation loss: 2.4756701666797487

Epoch: 5| Step: 2
Training loss: 1.070323192236739
Validation loss: 2.441883426359869

Epoch: 5| Step: 3
Training loss: 1.3307525224620556
Validation loss: 2.41536847791907

Epoch: 5| Step: 4
Training loss: 1.9730247228961486
Validation loss: 2.4849328949434266

Epoch: 5| Step: 5
Training loss: 1.180967028597703
Validation loss: 2.4593775724631652

Epoch: 5| Step: 6
Training loss: 1.6586213320263847
Validation loss: 2.4716635713429342

Epoch: 5| Step: 7
Training loss: 1.5446351143275145
Validation loss: 2.4974646212319085

Epoch: 5| Step: 8
Training loss: 1.6385113861461316
Validation loss: 2.415282169695403

Epoch: 5| Step: 9
Training loss: 1.8914613371448914
Validation loss: 2.4742004536842286

Epoch: 5| Step: 10
Training loss: 1.513448194158415
Validation loss: 2.503296766207265

Epoch: 305| Step: 0
Training loss: 1.490763359126397
Validation loss: 2.3897575044659174

Epoch: 5| Step: 1
Training loss: 1.8724687020063342
Validation loss: 2.4476757223345937

Epoch: 5| Step: 2
Training loss: 1.6927062362266656
Validation loss: 2.401657798112926

Epoch: 5| Step: 3
Training loss: 1.4052731830100968
Validation loss: 2.344282985778174

Epoch: 5| Step: 4
Training loss: 1.534433442224505
Validation loss: 2.422789836405978

Epoch: 5| Step: 5
Training loss: 1.35741647403658
Validation loss: 2.4162362664507127

Epoch: 5| Step: 6
Training loss: 1.297687597659774
Validation loss: 2.3984409733213656

Epoch: 5| Step: 7
Training loss: 1.8991612440196153
Validation loss: 2.356770291983017

Epoch: 5| Step: 8
Training loss: 1.362960121786071
Validation loss: 2.43242642483728

Epoch: 5| Step: 9
Training loss: 1.418090646932085
Validation loss: 2.325845921353762

Epoch: 5| Step: 10
Training loss: 1.8647838747522816
Validation loss: 2.3686112525603003

Epoch: 306| Step: 0
Training loss: 1.5702593590394165
Validation loss: 2.469682204391758

Epoch: 5| Step: 1
Training loss: 1.633645753110286
Validation loss: 2.3723668314972

Epoch: 5| Step: 2
Training loss: 1.5963466658631216
Validation loss: 2.4123705895181047

Epoch: 5| Step: 3
Training loss: 1.2241321954273214
Validation loss: 2.4606430484364723

Epoch: 5| Step: 4
Training loss: 1.9875950556642326
Validation loss: 2.394388399983917

Epoch: 5| Step: 5
Training loss: 1.5361633879764633
Validation loss: 2.4239454783805927

Epoch: 5| Step: 6
Training loss: 1.5112452985439577
Validation loss: 2.4668991608984716

Epoch: 5| Step: 7
Training loss: 1.4641409446846638
Validation loss: 2.43693142705031

Epoch: 5| Step: 8
Training loss: 1.6705730038823983
Validation loss: 2.5711978250763945

Epoch: 5| Step: 9
Training loss: 1.8704340972507434
Validation loss: 2.4429597334085384

Epoch: 5| Step: 10
Training loss: 1.5286963831933813
Validation loss: 2.4668306392517056

Epoch: 307| Step: 0
Training loss: 1.0601042496501667
Validation loss: 2.4643638279740037

Epoch: 5| Step: 1
Training loss: 1.1158589820297586
Validation loss: 2.4572032446542806

Epoch: 5| Step: 2
Training loss: 1.8348951911618354
Validation loss: 2.366991155498336

Epoch: 5| Step: 3
Training loss: 1.0959391348255278
Validation loss: 2.4307593977886115

Epoch: 5| Step: 4
Training loss: 2.212000830424258
Validation loss: 2.3748225678516457

Epoch: 5| Step: 5
Training loss: 1.3491331549321748
Validation loss: 2.5049203127187423

Epoch: 5| Step: 6
Training loss: 1.466875706572133
Validation loss: 2.441230930785071

Epoch: 5| Step: 7
Training loss: 1.2571731743315195
Validation loss: 2.475896241389406

Epoch: 5| Step: 8
Training loss: 1.7199726264460946
Validation loss: 2.3608324959828906

Epoch: 5| Step: 9
Training loss: 1.8563712725857182
Validation loss: 2.45448456896526

Epoch: 5| Step: 10
Training loss: 1.5864375035635703
Validation loss: 2.5046407551966174

Epoch: 308| Step: 0
Training loss: 1.211807824211341
Validation loss: 2.402689885480444

Epoch: 5| Step: 1
Training loss: 1.3078881937998672
Validation loss: 2.316287821128164

Epoch: 5| Step: 2
Training loss: 1.053472765997356
Validation loss: 2.4468287584690507

Epoch: 5| Step: 3
Training loss: 1.4678980202762413
Validation loss: 2.426086673931899

Epoch: 5| Step: 4
Training loss: 1.9570657266408642
Validation loss: 2.5098173086122006

Epoch: 5| Step: 5
Training loss: 1.295327239648684
Validation loss: 2.4019086092690043

Epoch: 5| Step: 6
Training loss: 1.9960450168341684
Validation loss: 2.3994158574860025

Epoch: 5| Step: 7
Training loss: 1.774289838004207
Validation loss: 2.4083520374692324

Epoch: 5| Step: 8
Training loss: 1.3273422178334806
Validation loss: 2.4713595762288367

Epoch: 5| Step: 9
Training loss: 1.5168079596857877
Validation loss: 2.3976981928294805

Epoch: 5| Step: 10
Training loss: 1.499187328810461
Validation loss: 2.3855246883798706

Epoch: 309| Step: 0
Training loss: 1.2932149416442935
Validation loss: 2.491898441128979

Epoch: 5| Step: 1
Training loss: 1.4306595629728731
Validation loss: 2.4294174609296326

Epoch: 5| Step: 2
Training loss: 1.293275825477129
Validation loss: 2.4296593763532477

Epoch: 5| Step: 3
Training loss: 1.5765383458626503
Validation loss: 2.4149297742722764

Epoch: 5| Step: 4
Training loss: 1.3136666879996746
Validation loss: 2.4646853694823534

Epoch: 5| Step: 5
Training loss: 1.2423044785414623
Validation loss: 2.4549376066158106

Epoch: 5| Step: 6
Training loss: 1.6381482275429844
Validation loss: 2.4784458108903156

Epoch: 5| Step: 7
Training loss: 1.9910681478313272
Validation loss: 2.4646796262915847

Epoch: 5| Step: 8
Training loss: 1.7738048828322746
Validation loss: 2.4590489899822563

Epoch: 5| Step: 9
Training loss: 1.6693307644643507
Validation loss: 2.4826915710613227

Epoch: 5| Step: 10
Training loss: 1.9035515368303377
Validation loss: 2.5232241239466684

Epoch: 310| Step: 0
Training loss: 1.4535778529546395
Validation loss: 2.3654942913717556

Epoch: 5| Step: 1
Training loss: 1.4044250939080014
Validation loss: 2.395437515184015

Epoch: 5| Step: 2
Training loss: 1.313522167903083
Validation loss: 2.3375617891631295

Epoch: 5| Step: 3
Training loss: 1.136487642371228
Validation loss: 2.3677923268543144

Epoch: 5| Step: 4
Training loss: 1.28195180513127
Validation loss: 2.4387674352143804

Epoch: 5| Step: 5
Training loss: 1.6334898789310917
Validation loss: 2.4076840277750695

Epoch: 5| Step: 6
Training loss: 1.4107555267831426
Validation loss: 2.4204846146563006

Epoch: 5| Step: 7
Training loss: 1.5681567221481743
Validation loss: 2.4298461412785612

Epoch: 5| Step: 8
Training loss: 1.522776298820677
Validation loss: 2.3873323642949713

Epoch: 5| Step: 9
Training loss: 1.9336073749717246
Validation loss: 2.4336605117840273

Epoch: 5| Step: 10
Training loss: 1.8604369136424794
Validation loss: 2.3727510881768725

Epoch: 311| Step: 0
Training loss: 1.4834563775766962
Validation loss: 2.4395276794729663

Epoch: 5| Step: 1
Training loss: 1.0329146388071049
Validation loss: 2.4038021452025014

Epoch: 5| Step: 2
Training loss: 1.1735456637781652
Validation loss: 2.4451127442329215

Epoch: 5| Step: 3
Training loss: 1.5660474561318944
Validation loss: 2.4250517346253417

Epoch: 5| Step: 4
Training loss: 1.5406410139075652
Validation loss: 2.417361869859459

Epoch: 5| Step: 5
Training loss: 2.306214838354344
Validation loss: 2.425119759085024

Epoch: 5| Step: 6
Training loss: 1.3426440811271674
Validation loss: 2.4707448751947796

Epoch: 5| Step: 7
Training loss: 1.2235383578025747
Validation loss: 2.3996167111432256

Epoch: 5| Step: 8
Training loss: 1.8980796068458115
Validation loss: 2.529775658302357

Epoch: 5| Step: 9
Training loss: 1.3559378216337132
Validation loss: 2.367971241743034

Epoch: 5| Step: 10
Training loss: 1.7161073656261852
Validation loss: 2.4656969920189873

Epoch: 312| Step: 0
Training loss: 1.1439736736442894
Validation loss: 2.477417193553853

Epoch: 5| Step: 1
Training loss: 1.5082504348033428
Validation loss: 2.466778689980535

Epoch: 5| Step: 2
Training loss: 1.4157992493626523
Validation loss: 2.3711397786523114

Epoch: 5| Step: 3
Training loss: 1.4908369253565568
Validation loss: 2.447561598462063

Epoch: 5| Step: 4
Training loss: 1.4475833683020867
Validation loss: 2.404608151580476

Epoch: 5| Step: 5
Training loss: 1.8536845734176137
Validation loss: 2.4417776000761124

Epoch: 5| Step: 6
Training loss: 1.9379329197733182
Validation loss: 2.4435928107439464

Epoch: 5| Step: 7
Training loss: 1.3620823176206993
Validation loss: 2.500335836926

Epoch: 5| Step: 8
Training loss: 1.3281642234844557
Validation loss: 2.386105544117891

Epoch: 5| Step: 9
Training loss: 1.580646728511081
Validation loss: 2.5430924716425687

Epoch: 5| Step: 10
Training loss: 1.1781415599195437
Validation loss: 2.4681813280971174

Epoch: 313| Step: 0
Training loss: 2.167122450596954
Validation loss: 2.398764283364611

Epoch: 5| Step: 1
Training loss: 1.4113697526263413
Validation loss: 2.395812144638322

Epoch: 5| Step: 2
Training loss: 2.033411958873195
Validation loss: 2.389327320972072

Epoch: 5| Step: 3
Training loss: 1.1221990685754994
Validation loss: 2.4039335976623004

Epoch: 5| Step: 4
Training loss: 1.2785980412498494
Validation loss: 2.389675037159167

Epoch: 5| Step: 5
Training loss: 1.3887358703031818
Validation loss: 2.3089117243419737

Epoch: 5| Step: 6
Training loss: 1.542536653302678
Validation loss: 2.423796944318799

Epoch: 5| Step: 7
Training loss: 1.819043875741305
Validation loss: 2.358460216731713

Epoch: 5| Step: 8
Training loss: 1.0502686792577225
Validation loss: 2.438602108953242

Epoch: 5| Step: 9
Training loss: 1.1614589890733358
Validation loss: 2.4854641151903443

Epoch: 5| Step: 10
Training loss: 1.4990097592006233
Validation loss: 2.3535857497089

Epoch: 314| Step: 0
Training loss: 1.8167627128386201
Validation loss: 2.3779735387214775

Epoch: 5| Step: 1
Training loss: 1.156692523300848
Validation loss: 2.4376547637810635

Epoch: 5| Step: 2
Training loss: 1.5640377869687683
Validation loss: 2.397869297596506

Epoch: 5| Step: 3
Training loss: 1.5519821936234774
Validation loss: 2.418157122852787

Epoch: 5| Step: 4
Training loss: 1.5364940143472339
Validation loss: 2.5450732991715617

Epoch: 5| Step: 5
Training loss: 1.407664287187241
Validation loss: 2.4729854704963956

Epoch: 5| Step: 6
Training loss: 1.0126805980352764
Validation loss: 2.4906385501285007

Epoch: 5| Step: 7
Training loss: 1.6343210360952458
Validation loss: 2.479446472036809

Epoch: 5| Step: 8
Training loss: 1.9116534584784188
Validation loss: 2.448477521925616

Epoch: 5| Step: 9
Training loss: 1.473362356233769
Validation loss: 2.3726344025718142

Epoch: 5| Step: 10
Training loss: 1.6311394548046798
Validation loss: 2.442031226709591

Epoch: 315| Step: 0
Training loss: 1.5373548144510256
Validation loss: 2.4403511050501545

Epoch: 5| Step: 1
Training loss: 1.524001579514133
Validation loss: 2.448496556940302

Epoch: 5| Step: 2
Training loss: 1.5095755591926305
Validation loss: 2.4392836181707254

Epoch: 5| Step: 3
Training loss: 1.3057777281126315
Validation loss: 2.370246032479007

Epoch: 5| Step: 4
Training loss: 1.7641938071970487
Validation loss: 2.380077584563455

Epoch: 5| Step: 5
Training loss: 1.3416486766548925
Validation loss: 2.4564396499620327

Epoch: 5| Step: 6
Training loss: 1.8024991461636748
Validation loss: 2.4742793256527267

Epoch: 5| Step: 7
Training loss: 1.3993053620335414
Validation loss: 2.4265010469208206

Epoch: 5| Step: 8
Training loss: 1.3533158588377432
Validation loss: 2.372018808824778

Epoch: 5| Step: 9
Training loss: 1.500300536248042
Validation loss: 2.4281007726529142

Epoch: 5| Step: 10
Training loss: 1.5813722344599637
Validation loss: 2.4608826187923576

Epoch: 316| Step: 0
Training loss: 1.0153525353801531
Validation loss: 2.401632707657512

Epoch: 5| Step: 1
Training loss: 1.4182480045804182
Validation loss: 2.4192236236484113

Epoch: 5| Step: 2
Training loss: 2.171253581991189
Validation loss: 2.4402703049734296

Epoch: 5| Step: 3
Training loss: 1.3221618972279394
Validation loss: 2.418017197435585

Epoch: 5| Step: 4
Training loss: 1.67704053393735
Validation loss: 2.4733431627138884

Epoch: 5| Step: 5
Training loss: 1.541614565956972
Validation loss: 2.4743160266848885

Epoch: 5| Step: 6
Training loss: 1.3476351529004231
Validation loss: 2.3745328490181965

Epoch: 5| Step: 7
Training loss: 1.4783374270812892
Validation loss: 2.4158272167520405

Epoch: 5| Step: 8
Training loss: 1.1019476359331064
Validation loss: 2.5242571517884183

Epoch: 5| Step: 9
Training loss: 1.4866239676879696
Validation loss: 2.33738832041907

Epoch: 5| Step: 10
Training loss: 1.916899901863592
Validation loss: 2.42739602787942

Epoch: 317| Step: 0
Training loss: 1.5973439552615218
Validation loss: 2.4718005356227004

Epoch: 5| Step: 1
Training loss: 1.7611631206583729
Validation loss: 2.4099099758100433

Epoch: 5| Step: 2
Training loss: 1.3809298183057448
Validation loss: 2.4742688349550144

Epoch: 5| Step: 3
Training loss: 1.4337523162211139
Validation loss: 2.530388030429116

Epoch: 5| Step: 4
Training loss: 1.8708278650261951
Validation loss: 2.4135374889551566

Epoch: 5| Step: 5
Training loss: 1.427621568223272
Validation loss: 2.422040089919181

Epoch: 5| Step: 6
Training loss: 1.3541620205530522
Validation loss: 2.4587003087409274

Epoch: 5| Step: 7
Training loss: 1.4373482333798737
Validation loss: 2.339904500595265

Epoch: 5| Step: 8
Training loss: 1.518256351321356
Validation loss: 2.507113345243006

Epoch: 5| Step: 9
Training loss: 1.2141234295454997
Validation loss: 2.46547659011111

Epoch: 5| Step: 10
Training loss: 1.7658798573971868
Validation loss: 2.472735584373493

Epoch: 318| Step: 0
Training loss: 1.4075632533060443
Validation loss: 2.4325712745538532

Epoch: 5| Step: 1
Training loss: 1.2038071915299695
Validation loss: 2.488855160110118

Epoch: 5| Step: 2
Training loss: 1.8553680071334988
Validation loss: 2.404355147265792

Epoch: 5| Step: 3
Training loss: 1.7143272369328784
Validation loss: 2.474834784202155

Epoch: 5| Step: 4
Training loss: 1.4638874645495659
Validation loss: 2.310675829728729

Epoch: 5| Step: 5
Training loss: 1.1342625249583547
Validation loss: 2.4749800796966683

Epoch: 5| Step: 6
Training loss: 1.6600372630843234
Validation loss: 2.452111099401978

Epoch: 5| Step: 7
Training loss: 1.2772826667202686
Validation loss: 2.4189509194581205

Epoch: 5| Step: 8
Training loss: 1.2183293814971192
Validation loss: 2.3589697027038716

Epoch: 5| Step: 9
Training loss: 1.8236110418351485
Validation loss: 2.418011242148254

Epoch: 5| Step: 10
Training loss: 1.50535683960775
Validation loss: 2.4014154825259704

Epoch: 319| Step: 0
Training loss: 0.9548917249145435
Validation loss: 2.476173969501359

Epoch: 5| Step: 1
Training loss: 1.473666626154886
Validation loss: 2.458153348048375

Epoch: 5| Step: 2
Training loss: 1.5051095879536074
Validation loss: 2.42006207270836

Epoch: 5| Step: 3
Training loss: 1.9845760574009887
Validation loss: 2.390106518133012

Epoch: 5| Step: 4
Training loss: 1.1009537117051664
Validation loss: 2.3046482845506646

Epoch: 5| Step: 5
Training loss: 1.3946875903971252
Validation loss: 2.4343135268835976

Epoch: 5| Step: 6
Training loss: 1.4886158644610263
Validation loss: 2.4402613873124426

Epoch: 5| Step: 7
Training loss: 1.1782178503223835
Validation loss: 2.455590660093491

Epoch: 5| Step: 8
Training loss: 1.5236006429322866
Validation loss: 2.384600327212234

Epoch: 5| Step: 9
Training loss: 1.6913383064983802
Validation loss: 2.396476821478999

Epoch: 5| Step: 10
Training loss: 1.8902204727068384
Validation loss: 2.4964796619748597

Epoch: 320| Step: 0
Training loss: 1.1696334763611456
Validation loss: 2.393847923618094

Epoch: 5| Step: 1
Training loss: 1.4037947944294595
Validation loss: 2.3870596108153075

Epoch: 5| Step: 2
Training loss: 1.3499778321883298
Validation loss: 2.408809281551541

Epoch: 5| Step: 3
Training loss: 1.252126886982356
Validation loss: 2.3822353729926484

Epoch: 5| Step: 4
Training loss: 2.098810144940608
Validation loss: 2.4245031888792603

Epoch: 5| Step: 5
Training loss: 1.2254084120369395
Validation loss: 2.4865819738304675

Epoch: 5| Step: 6
Training loss: 1.0971231489614652
Validation loss: 2.443456608155262

Epoch: 5| Step: 7
Training loss: 1.3466950457874907
Validation loss: 2.441354542568194

Epoch: 5| Step: 8
Training loss: 1.252853664788568
Validation loss: 2.3752309938368024

Epoch: 5| Step: 9
Training loss: 1.9483157342399269
Validation loss: 2.445259223920348

Epoch: 5| Step: 10
Training loss: 1.8494499161975686
Validation loss: 2.468942575769658

Epoch: 321| Step: 0
Training loss: 1.612415589481547
Validation loss: 2.4748672869067887

Epoch: 5| Step: 1
Training loss: 1.4435988706284668
Validation loss: 2.554141284233217

Epoch: 5| Step: 2
Training loss: 1.1051403407048348
Validation loss: 2.432621059382616

Epoch: 5| Step: 3
Training loss: 2.1981421862666033
Validation loss: 2.4665640970415454

Epoch: 5| Step: 4
Training loss: 1.3177455349019507
Validation loss: 2.451416519037059

Epoch: 5| Step: 5
Training loss: 1.6021818126609517
Validation loss: 2.422829534161153

Epoch: 5| Step: 6
Training loss: 1.485698310863107
Validation loss: 2.368497425630944

Epoch: 5| Step: 7
Training loss: 1.2952798432028663
Validation loss: 2.5118530719278214

Epoch: 5| Step: 8
Training loss: 1.3277242616928753
Validation loss: 2.47455789724047

Epoch: 5| Step: 9
Training loss: 1.7305109780973802
Validation loss: 2.4254458298919226

Epoch: 5| Step: 10
Training loss: 1.1912780692765368
Validation loss: 2.401933843065702

Epoch: 322| Step: 0
Training loss: 1.744555929020503
Validation loss: 2.518359448457469

Epoch: 5| Step: 1
Training loss: 1.3215781020467805
Validation loss: 2.435283266077533

Epoch: 5| Step: 2
Training loss: 1.6504056489700778
Validation loss: 2.490884040957489

Epoch: 5| Step: 3
Training loss: 1.2609105311727615
Validation loss: 2.451059605184016

Epoch: 5| Step: 4
Training loss: 1.9312132081906732
Validation loss: 2.4514095677322394

Epoch: 5| Step: 5
Training loss: 1.1392737968392097
Validation loss: 2.412658798353171

Epoch: 5| Step: 6
Training loss: 1.691434018653766
Validation loss: 2.4133340440242694

Epoch: 5| Step: 7
Training loss: 1.4946162246021533
Validation loss: 2.4336934411362137

Epoch: 5| Step: 8
Training loss: 1.1571417282492564
Validation loss: 2.4281454018112267

Epoch: 5| Step: 9
Training loss: 1.520005336049401
Validation loss: 2.412524387925585

Epoch: 5| Step: 10
Training loss: 1.1307541661578997
Validation loss: 2.4653519973162648

Epoch: 323| Step: 0
Training loss: 1.434079038716234
Validation loss: 2.3930385994475682

Epoch: 5| Step: 1
Training loss: 1.4906769141667853
Validation loss: 2.4415332801503533

Epoch: 5| Step: 2
Training loss: 1.4075736280328057
Validation loss: 2.482448161653328

Epoch: 5| Step: 3
Training loss: 1.1436287508206824
Validation loss: 2.4487638429666085

Epoch: 5| Step: 4
Training loss: 1.933740598708752
Validation loss: 2.496416493336256

Epoch: 5| Step: 5
Training loss: 0.9691359151212986
Validation loss: 2.4552772903189295

Epoch: 5| Step: 6
Training loss: 1.6411360898258802
Validation loss: 2.4938892869326126

Epoch: 5| Step: 7
Training loss: 1.2374072916773264
Validation loss: 2.48719008447475

Epoch: 5| Step: 8
Training loss: 1.923640363021721
Validation loss: 2.3566511197308424

Epoch: 5| Step: 9
Training loss: 1.7190175628475044
Validation loss: 2.506451753021195

Epoch: 5| Step: 10
Training loss: 1.504561640624349
Validation loss: 2.496189631495708

Epoch: 324| Step: 0
Training loss: 1.2002274436777856
Validation loss: 2.5295277414019006

Epoch: 5| Step: 1
Training loss: 1.3988470830966917
Validation loss: 2.440649651749316

Epoch: 5| Step: 2
Training loss: 2.2644218670351024
Validation loss: 2.4675496980110045

Epoch: 5| Step: 3
Training loss: 1.428618067593151
Validation loss: 2.4184150785494496

Epoch: 5| Step: 4
Training loss: 1.545144548536739
Validation loss: 2.4712879203970832

Epoch: 5| Step: 5
Training loss: 1.5771536528793413
Validation loss: 2.449331632763272

Epoch: 5| Step: 6
Training loss: 1.3041862392886523
Validation loss: 2.4033063561873647

Epoch: 5| Step: 7
Training loss: 1.4986571022748916
Validation loss: 2.415924427870745

Epoch: 5| Step: 8
Training loss: 1.5049631343647987
Validation loss: 2.4394164017968585

Epoch: 5| Step: 9
Training loss: 0.994115832905885
Validation loss: 2.5018852816235024

Epoch: 5| Step: 10
Training loss: 1.5658859187796295
Validation loss: 2.4639805186926784

Epoch: 325| Step: 0
Training loss: 1.9334227823523789
Validation loss: 2.438697025645022

Epoch: 5| Step: 1
Training loss: 1.263099835733586
Validation loss: 2.515060851728219

Epoch: 5| Step: 2
Training loss: 1.9762229175388863
Validation loss: 2.4506566028572223

Epoch: 5| Step: 3
Training loss: 1.586949443716154
Validation loss: 2.397920145011758

Epoch: 5| Step: 4
Training loss: 1.5232021052113578
Validation loss: 2.4203897119462097

Epoch: 5| Step: 5
Training loss: 1.2674069516791167
Validation loss: 2.439900811684295

Epoch: 5| Step: 6
Training loss: 1.6458753588497814
Validation loss: 2.4184402334024924

Epoch: 5| Step: 7
Training loss: 1.185682461823647
Validation loss: 2.3760748515911656

Epoch: 5| Step: 8
Training loss: 0.7685545323915822
Validation loss: 2.429129728107719

Epoch: 5| Step: 9
Training loss: 1.4014129950184229
Validation loss: 2.3950784868205166

Epoch: 5| Step: 10
Training loss: 1.4069053394464401
Validation loss: 2.345721097277259

Epoch: 326| Step: 0
Training loss: 1.0107460795894265
Validation loss: 2.386923515062355

Epoch: 5| Step: 1
Training loss: 1.8523759946104181
Validation loss: 2.4709035261415147

Epoch: 5| Step: 2
Training loss: 1.871114647097555
Validation loss: 2.481042777851056

Epoch: 5| Step: 3
Training loss: 1.6366243540052332
Validation loss: 2.443180571642948

Epoch: 5| Step: 4
Training loss: 1.5263090018850145
Validation loss: 2.4336929681617883

Epoch: 5| Step: 5
Training loss: 0.9405221547017392
Validation loss: 2.4350690433386037

Epoch: 5| Step: 6
Training loss: 1.1546555428218732
Validation loss: 2.3736467256984737

Epoch: 5| Step: 7
Training loss: 1.7561204692818244
Validation loss: 2.4551984923723515

Epoch: 5| Step: 8
Training loss: 1.605685031551171
Validation loss: 2.44154539884036

Epoch: 5| Step: 9
Training loss: 1.4903634791614797
Validation loss: 2.4351426897945867

Epoch: 5| Step: 10
Training loss: 1.2778727051584555
Validation loss: 2.452591435098374

Epoch: 327| Step: 0
Training loss: 1.4326648665219077
Validation loss: 2.415764242004473

Epoch: 5| Step: 1
Training loss: 1.5632112028870389
Validation loss: 2.4339571464079195

Epoch: 5| Step: 2
Training loss: 1.3683047715774994
Validation loss: 2.4035049664017265

Epoch: 5| Step: 3
Training loss: 0.9457162042317627
Validation loss: 2.3749224440169074

Epoch: 5| Step: 4
Training loss: 1.9889833301211954
Validation loss: 2.3630018532330825

Epoch: 5| Step: 5
Training loss: 1.3495675506956613
Validation loss: 2.4544917267220785

Epoch: 5| Step: 6
Training loss: 1.71857597163612
Validation loss: 2.438274577050984

Epoch: 5| Step: 7
Training loss: 1.312338955399577
Validation loss: 2.4511568518809317

Epoch: 5| Step: 8
Training loss: 1.44048248711493
Validation loss: 2.409418751083554

Epoch: 5| Step: 9
Training loss: 1.4981321785523674
Validation loss: 2.3922926139788054

Epoch: 5| Step: 10
Training loss: 1.2421511278885393
Validation loss: 2.384807916490157

Epoch: 328| Step: 0
Training loss: 1.3186522208027789
Validation loss: 2.418575578557434

Epoch: 5| Step: 1
Training loss: 1.4457523810657127
Validation loss: 2.4294355826551666

Epoch: 5| Step: 2
Training loss: 1.504649743926537
Validation loss: 2.4869066736915117

Epoch: 5| Step: 3
Training loss: 1.2155102928193442
Validation loss: 2.374770635918556

Epoch: 5| Step: 4
Training loss: 1.575493157093777
Validation loss: 2.4353311795820103

Epoch: 5| Step: 5
Training loss: 2.0070248257366043
Validation loss: 2.441029872701768

Epoch: 5| Step: 6
Training loss: 1.4646001587828712
Validation loss: 2.40631605232651

Epoch: 5| Step: 7
Training loss: 1.2102156425662933
Validation loss: 2.4743238513052113

Epoch: 5| Step: 8
Training loss: 1.4014109534895922
Validation loss: 2.4208562872491033

Epoch: 5| Step: 9
Training loss: 1.4508053713402234
Validation loss: 2.3607390677245577

Epoch: 5| Step: 10
Training loss: 1.688311699518076
Validation loss: 2.4175504045260157

Epoch: 329| Step: 0
Training loss: 1.3540024975763498
Validation loss: 2.371589141407178

Epoch: 5| Step: 1
Training loss: 1.5604740741730962
Validation loss: 2.4526091556375818

Epoch: 5| Step: 2
Training loss: 1.4736452702525944
Validation loss: 2.454712030869354

Epoch: 5| Step: 3
Training loss: 1.1335430026115159
Validation loss: 2.3899677189923385

Epoch: 5| Step: 4
Training loss: 1.8170667534398122
Validation loss: 2.394964164451917

Epoch: 5| Step: 5
Training loss: 1.1906191868277183
Validation loss: 2.394921951151708

Epoch: 5| Step: 6
Training loss: 1.4622770481852658
Validation loss: 2.4808816442279804

Epoch: 5| Step: 7
Training loss: 1.1164054000349393
Validation loss: 2.3881571551399716

Epoch: 5| Step: 8
Training loss: 1.9387967477028627
Validation loss: 2.4864113556619656

Epoch: 5| Step: 9
Training loss: 1.2401583911117406
Validation loss: 2.437077965602765

Epoch: 5| Step: 10
Training loss: 1.4898824413698462
Validation loss: 2.4007859424298417

Epoch: 330| Step: 0
Training loss: 1.355646259216791
Validation loss: 2.495581215490239

Epoch: 5| Step: 1
Training loss: 2.000914126344111
Validation loss: 2.43903888918181

Epoch: 5| Step: 2
Training loss: 1.3513448021704257
Validation loss: 2.446819901905862

Epoch: 5| Step: 3
Training loss: 1.0792780805146307
Validation loss: 2.4651547919822208

Epoch: 5| Step: 4
Training loss: 1.3430384149063588
Validation loss: 2.4680705373155445

Epoch: 5| Step: 5
Training loss: 1.1440339033131544
Validation loss: 2.4137878803367605

Epoch: 5| Step: 6
Training loss: 1.6656505189125252
Validation loss: 2.481220020292749

Epoch: 5| Step: 7
Training loss: 1.4684633015770647
Validation loss: 2.427246329809152

Epoch: 5| Step: 8
Training loss: 2.0715379075383016
Validation loss: 2.4280702338841427

Epoch: 5| Step: 9
Training loss: 1.150916609148547
Validation loss: 2.4709281414575224

Epoch: 5| Step: 10
Training loss: 1.607848397049768
Validation loss: 2.391323222753367

Epoch: 331| Step: 0
Training loss: 1.6928263070492533
Validation loss: 2.488694902120624

Epoch: 5| Step: 1
Training loss: 1.6444830445679457
Validation loss: 2.4331446067769193

Epoch: 5| Step: 2
Training loss: 1.404714042234593
Validation loss: 2.458966010223515

Epoch: 5| Step: 3
Training loss: 1.3179566623063337
Validation loss: 2.4256526831112786

Epoch: 5| Step: 4
Training loss: 1.1782862950009478
Validation loss: 2.5123820827834313

Epoch: 5| Step: 5
Training loss: 1.3748400335026463
Validation loss: 2.479205184917188

Epoch: 5| Step: 6
Training loss: 1.8057589962452774
Validation loss: 2.5029382297800815

Epoch: 5| Step: 7
Training loss: 1.5117518694894296
Validation loss: 2.426908428029134

Epoch: 5| Step: 8
Training loss: 1.1924070063705399
Validation loss: 2.434087185210305

Epoch: 5| Step: 9
Training loss: 1.7823308375959233
Validation loss: 2.4693742520728432

Epoch: 5| Step: 10
Training loss: 1.3219334510523706
Validation loss: 2.440205887705597

Epoch: 332| Step: 0
Training loss: 1.35329634746661
Validation loss: 2.485732166214961

Epoch: 5| Step: 1
Training loss: 1.1307377725159786
Validation loss: 2.4261898709650556

Epoch: 5| Step: 2
Training loss: 1.1528654307754442
Validation loss: 2.337273641166719

Epoch: 5| Step: 3
Training loss: 1.4153787798785156
Validation loss: 2.439290279278947

Epoch: 5| Step: 4
Training loss: 1.4062029936669487
Validation loss: 2.4954501855649585

Epoch: 5| Step: 5
Training loss: 1.818246938341223
Validation loss: 2.4188339761067117

Epoch: 5| Step: 6
Training loss: 1.4176813680348603
Validation loss: 2.412541293377889

Epoch: 5| Step: 7
Training loss: 0.7350064667268027
Validation loss: 2.4625332171045224

Epoch: 5| Step: 8
Training loss: 1.916298506111017
Validation loss: 2.4433926216558044

Epoch: 5| Step: 9
Training loss: 1.5831757349919913
Validation loss: 2.448191796740088

Epoch: 5| Step: 10
Training loss: 1.4582956672527185
Validation loss: 2.5019827834846615

Epoch: 333| Step: 0
Training loss: 1.58273744245123
Validation loss: 2.398178514689444

Epoch: 5| Step: 1
Training loss: 1.340810265888936
Validation loss: 2.381884061865038

Epoch: 5| Step: 2
Training loss: 1.6015735904960897
Validation loss: 2.4282597202988287

Epoch: 5| Step: 3
Training loss: 1.1837400843236225
Validation loss: 2.4633251128740254

Epoch: 5| Step: 4
Training loss: 1.329271741478689
Validation loss: 2.434431902294794

Epoch: 5| Step: 5
Training loss: 1.206331266126489
Validation loss: 2.4502610841606716

Epoch: 5| Step: 6
Training loss: 1.4997838977277436
Validation loss: 2.364098230296651

Epoch: 5| Step: 7
Training loss: 1.321406075201421
Validation loss: 2.3843248108095896

Epoch: 5| Step: 8
Training loss: 1.7754205715897768
Validation loss: 2.4924333237508116

Epoch: 5| Step: 9
Training loss: 1.4014555687232282
Validation loss: 2.439808782015566

Epoch: 5| Step: 10
Training loss: 2.192141594817387
Validation loss: 2.4200447626897055

Epoch: 334| Step: 0
Training loss: 1.1374535037588112
Validation loss: 2.4465318465302177

Epoch: 5| Step: 1
Training loss: 1.3597240657531966
Validation loss: 2.4870664856437408

Epoch: 5| Step: 2
Training loss: 1.802287499947678
Validation loss: 2.4755226551263565

Epoch: 5| Step: 3
Training loss: 0.9408084348341019
Validation loss: 2.356607940561345

Epoch: 5| Step: 4
Training loss: 1.5292438678153908
Validation loss: 2.3737653978616216

Epoch: 5| Step: 5
Training loss: 1.187869867647121
Validation loss: 2.4246378752246702

Epoch: 5| Step: 6
Training loss: 1.5406102951617022
Validation loss: 2.4686794995249004

Epoch: 5| Step: 7
Training loss: 1.7375498400887965
Validation loss: 2.4706804135606664

Epoch: 5| Step: 8
Training loss: 1.867455435327103
Validation loss: 2.421187780650225

Epoch: 5| Step: 9
Training loss: 1.0345046961858917
Validation loss: 2.4122883394557784

Epoch: 5| Step: 10
Training loss: 1.8109887498477717
Validation loss: 2.3593156135189743

Epoch: 335| Step: 0
Training loss: 1.3600993802420567
Validation loss: 2.4603031807842926

Epoch: 5| Step: 1
Training loss: 1.2584777873325423
Validation loss: 2.3814633239307237

Epoch: 5| Step: 2
Training loss: 1.6860649223362556
Validation loss: 2.372254760937984

Epoch: 5| Step: 3
Training loss: 1.3281138700131068
Validation loss: 2.518522261020548

Epoch: 5| Step: 4
Training loss: 1.137565114180256
Validation loss: 2.5685562810050335

Epoch: 5| Step: 5
Training loss: 1.9003927577791861
Validation loss: 2.5585719079077367

Epoch: 5| Step: 6
Training loss: 1.7173707456413188
Validation loss: 2.5202371788494204

Epoch: 5| Step: 7
Training loss: 1.514813943523442
Validation loss: 2.509988590942255

Epoch: 5| Step: 8
Training loss: 1.5212598838265652
Validation loss: 2.447214404356287

Epoch: 5| Step: 9
Training loss: 1.543570331203151
Validation loss: 2.4046321779137023

Epoch: 5| Step: 10
Training loss: 1.3501654664819764
Validation loss: 2.473831878349044

Epoch: 336| Step: 0
Training loss: 1.8956353499887453
Validation loss: 2.457608389468266

Epoch: 5| Step: 1
Training loss: 1.1649683557559491
Validation loss: 2.3931699441503134

Epoch: 5| Step: 2
Training loss: 1.249979018988958
Validation loss: 2.346234560774244

Epoch: 5| Step: 3
Training loss: 1.0806423045108229
Validation loss: 2.4074714372188732

Epoch: 5| Step: 4
Training loss: 1.6444500610897155
Validation loss: 2.354007187027068

Epoch: 5| Step: 5
Training loss: 0.834782560156198
Validation loss: 2.4237944703663

Epoch: 5| Step: 6
Training loss: 1.6968482308708752
Validation loss: 2.453313836575442

Epoch: 5| Step: 7
Training loss: 1.3416768427081833
Validation loss: 2.3443515883306936

Epoch: 5| Step: 8
Training loss: 1.9264798705858468
Validation loss: 2.4696249521867837

Epoch: 5| Step: 9
Training loss: 1.33797460139335
Validation loss: 2.3886471450595144

Epoch: 5| Step: 10
Training loss: 1.5968449778263476
Validation loss: 2.4445789333333487

Epoch: 337| Step: 0
Training loss: 1.238202306114271
Validation loss: 2.4431876156146366

Epoch: 5| Step: 1
Training loss: 1.9463144808888044
Validation loss: 2.526625456532235

Epoch: 5| Step: 2
Training loss: 1.2711303030431038
Validation loss: 2.4872274896653175

Epoch: 5| Step: 3
Training loss: 1.1345496702623017
Validation loss: 2.474595939366079

Epoch: 5| Step: 4
Training loss: 1.6062144383156434
Validation loss: 2.4884739224544306

Epoch: 5| Step: 5
Training loss: 0.870988574328632
Validation loss: 2.42660194751954

Epoch: 5| Step: 6
Training loss: 1.027444058586985
Validation loss: 2.4440561391972135

Epoch: 5| Step: 7
Training loss: 1.901606673493188
Validation loss: 2.463594064625958

Epoch: 5| Step: 8
Training loss: 1.370403800889271
Validation loss: 2.4692745214881433

Epoch: 5| Step: 9
Training loss: 1.3040558890845435
Validation loss: 2.414045904675764

Epoch: 5| Step: 10
Training loss: 1.6321973600168267
Validation loss: 2.5038750887341763

Epoch: 338| Step: 0
Training loss: 1.5194802557618663
Validation loss: 2.3769993756099326

Epoch: 5| Step: 1
Training loss: 1.6627213352263641
Validation loss: 2.43950027668134

Epoch: 5| Step: 2
Training loss: 1.139986303565082
Validation loss: 2.428635381730513

Epoch: 5| Step: 3
Training loss: 1.9430478560384747
Validation loss: 2.4160388147570555

Epoch: 5| Step: 4
Training loss: 1.3782968011801937
Validation loss: 2.4599711880354334

Epoch: 5| Step: 5
Training loss: 1.2699981300460386
Validation loss: 2.4254679681756954

Epoch: 5| Step: 6
Training loss: 1.234043608013956
Validation loss: 2.424372399141653

Epoch: 5| Step: 7
Training loss: 1.5295072486359
Validation loss: 2.563711356774868

Epoch: 5| Step: 8
Training loss: 1.3803668620878276
Validation loss: 2.500021597553607

Epoch: 5| Step: 9
Training loss: 0.9443713776211595
Validation loss: 2.495921137180808

Epoch: 5| Step: 10
Training loss: 1.0768539012185925
Validation loss: 2.3995032268063206

Epoch: 339| Step: 0
Training loss: 1.177094242866845
Validation loss: 2.3881331203226974

Epoch: 5| Step: 1
Training loss: 0.8242306098265514
Validation loss: 2.454944180084416

Epoch: 5| Step: 2
Training loss: 1.5340536491929788
Validation loss: 2.489944012430845

Epoch: 5| Step: 3
Training loss: 1.3254487393402248
Validation loss: 2.412097664809169

Epoch: 5| Step: 4
Training loss: 1.1256383568258794
Validation loss: 2.365418762020152

Epoch: 5| Step: 5
Training loss: 2.2595374042397367
Validation loss: 2.426742145953817

Epoch: 5| Step: 6
Training loss: 1.2304184676296146
Validation loss: 2.374104485884122

Epoch: 5| Step: 7
Training loss: 1.7742231200150524
Validation loss: 2.378287050049927

Epoch: 5| Step: 8
Training loss: 1.3401576972803282
Validation loss: 2.391131170601435

Epoch: 5| Step: 9
Training loss: 1.3380502870059259
Validation loss: 2.4050537319191774

Epoch: 5| Step: 10
Training loss: 1.5270930325910037
Validation loss: 2.36282320817007

Epoch: 340| Step: 0
Training loss: 1.2553938837998437
Validation loss: 2.4153725738079226

Epoch: 5| Step: 1
Training loss: 1.3564398197642344
Validation loss: 2.418455016659294

Epoch: 5| Step: 2
Training loss: 1.0051719316338226
Validation loss: 2.4061068569649935

Epoch: 5| Step: 3
Training loss: 1.3258573133760432
Validation loss: 2.427991255113544

Epoch: 5| Step: 4
Training loss: 1.073147770457335
Validation loss: 2.4870455553861692

Epoch: 5| Step: 5
Training loss: 1.6076588786205002
Validation loss: 2.4654275176124893

Epoch: 5| Step: 6
Training loss: 1.5302567666709201
Validation loss: 2.4407266233143763

Epoch: 5| Step: 7
Training loss: 1.1345772513008145
Validation loss: 2.4610671465492593

Epoch: 5| Step: 8
Training loss: 1.4863663015588278
Validation loss: 2.5428008990408966

Epoch: 5| Step: 9
Training loss: 2.0750628404408777
Validation loss: 2.3899246059523716

Epoch: 5| Step: 10
Training loss: 1.9190525325882175
Validation loss: 2.400536096338561

Epoch: 341| Step: 0
Training loss: 1.458570633609545
Validation loss: 2.4967127799847493

Epoch: 5| Step: 1
Training loss: 1.1714570889756655
Validation loss: 2.405756933554678

Epoch: 5| Step: 2
Training loss: 1.4669530711712624
Validation loss: 2.492572374225693

Epoch: 5| Step: 3
Training loss: 1.4035663853550906
Validation loss: 2.4050585147828367

Epoch: 5| Step: 4
Training loss: 1.3969368155027477
Validation loss: 2.4331432217763873

Epoch: 5| Step: 5
Training loss: 1.6035290809280505
Validation loss: 2.3948337649093556

Epoch: 5| Step: 6
Training loss: 1.3612451952244335
Validation loss: 2.483300597222918

Epoch: 5| Step: 7
Training loss: 1.4807623016088594
Validation loss: 2.43168323827256

Epoch: 5| Step: 8
Training loss: 1.597900446577778
Validation loss: 2.520922912888114

Epoch: 5| Step: 9
Training loss: 1.9195397308125
Validation loss: 2.4875332217369204

Epoch: 5| Step: 10
Training loss: 1.1366361083307315
Validation loss: 2.4184994681787644

Epoch: 342| Step: 0
Training loss: 1.7119950461939861
Validation loss: 2.3920015702440525

Epoch: 5| Step: 1
Training loss: 1.2578934827051502
Validation loss: 2.411638193158922

Epoch: 5| Step: 2
Training loss: 1.8755179007847247
Validation loss: 2.387237625080907

Epoch: 5| Step: 3
Training loss: 1.4023894406156692
Validation loss: 2.4403137114606124

Epoch: 5| Step: 4
Training loss: 1.4887346993660204
Validation loss: 2.4125215294270634

Epoch: 5| Step: 5
Training loss: 1.172200323089128
Validation loss: 2.35524474024849

Epoch: 5| Step: 6
Training loss: 1.1097943225387457
Validation loss: 2.430926347880045

Epoch: 5| Step: 7
Training loss: 1.2627688074518246
Validation loss: 2.511478763271856

Epoch: 5| Step: 8
Training loss: 1.6485325935017994
Validation loss: 2.4621646502012102

Epoch: 5| Step: 9
Training loss: 1.5070019851144982
Validation loss: 2.457784796602728

Epoch: 5| Step: 10
Training loss: 1.3338401794693246
Validation loss: 2.415512261855325

Epoch: 343| Step: 0
Training loss: 1.1043824698730411
Validation loss: 2.4222409869257104

Epoch: 5| Step: 1
Training loss: 1.1371016234458342
Validation loss: 2.4290163856711926

Epoch: 5| Step: 2
Training loss: 2.0828181456298323
Validation loss: 2.3703003959458386

Epoch: 5| Step: 3
Training loss: 1.7364700310886505
Validation loss: 2.4079200809765444

Epoch: 5| Step: 4
Training loss: 1.3398055802405169
Validation loss: 2.367639238672603

Epoch: 5| Step: 5
Training loss: 1.5391744969858456
Validation loss: 2.4151854507219768

Epoch: 5| Step: 6
Training loss: 0.9413789927228623
Validation loss: 2.394449643034884

Epoch: 5| Step: 7
Training loss: 1.0777553532803041
Validation loss: 2.457265073940841

Epoch: 5| Step: 8
Training loss: 1.6522399292562613
Validation loss: 2.4910710587350637

Epoch: 5| Step: 9
Training loss: 1.4075076519366831
Validation loss: 2.5201028745054272

Epoch: 5| Step: 10
Training loss: 1.1952651768710014
Validation loss: 2.4321572074097735

Epoch: 344| Step: 0
Training loss: 0.9931066265771283
Validation loss: 2.4586079640299565

Epoch: 5| Step: 1
Training loss: 1.1584134353183926
Validation loss: 2.4081054350451376

Epoch: 5| Step: 2
Training loss: 1.832289297316687
Validation loss: 2.512757393436591

Epoch: 5| Step: 3
Training loss: 0.915193135614178
Validation loss: 2.4927529815918916

Epoch: 5| Step: 4
Training loss: 1.4017487009939478
Validation loss: 2.410293516424223

Epoch: 5| Step: 5
Training loss: 1.3215905047949599
Validation loss: 2.4736531349271877

Epoch: 5| Step: 6
Training loss: 1.863250540234349
Validation loss: 2.441111747190263

Epoch: 5| Step: 7
Training loss: 1.2155376059686709
Validation loss: 2.4180484648389173

Epoch: 5| Step: 8
Training loss: 1.5602634444682086
Validation loss: 2.436038425473874

Epoch: 5| Step: 9
Training loss: 1.3082087619462992
Validation loss: 2.4322389747719906

Epoch: 5| Step: 10
Training loss: 1.733993557061146
Validation loss: 2.3780617055290496

Epoch: 345| Step: 0
Training loss: 1.2945026622463418
Validation loss: 2.379485136878256

Epoch: 5| Step: 1
Training loss: 2.0107732532356137
Validation loss: 2.4204000977630864

Epoch: 5| Step: 2
Training loss: 1.2292800247593958
Validation loss: 2.4260600587365047

Epoch: 5| Step: 3
Training loss: 1.2427483498119756
Validation loss: 2.4299796653216443

Epoch: 5| Step: 4
Training loss: 1.2321907709413513
Validation loss: 2.48560154844238

Epoch: 5| Step: 5
Training loss: 1.4856521733631012
Validation loss: 2.386224425000728

Epoch: 5| Step: 6
Training loss: 1.1543855842803192
Validation loss: 2.377354188578525

Epoch: 5| Step: 7
Training loss: 1.312340136283571
Validation loss: 2.4375606005560546

Epoch: 5| Step: 8
Training loss: 1.01692158025538
Validation loss: 2.4150275342377103

Epoch: 5| Step: 9
Training loss: 1.6870807550771276
Validation loss: 2.4720963042022346

Epoch: 5| Step: 10
Training loss: 0.9703138096504157
Validation loss: 2.3935018965135453

Epoch: 346| Step: 0
Training loss: 1.3615099048065096
Validation loss: 2.4901630620620003

Epoch: 5| Step: 1
Training loss: 1.6735737806547533
Validation loss: 2.475418120924146

Epoch: 5| Step: 2
Training loss: 1.1010971709775175
Validation loss: 2.467558265110585

Epoch: 5| Step: 3
Training loss: 1.507100070392515
Validation loss: 2.4223529726414865

Epoch: 5| Step: 4
Training loss: 1.8018005531431287
Validation loss: 2.426075179145172

Epoch: 5| Step: 5
Training loss: 1.905928412655171
Validation loss: 2.466371526815458

Epoch: 5| Step: 6
Training loss: 1.043045498313678
Validation loss: 2.423028088830458

Epoch: 5| Step: 7
Training loss: 1.1858747302344863
Validation loss: 2.389267021751037

Epoch: 5| Step: 8
Training loss: 1.322582843543836
Validation loss: 2.403990388958828

Epoch: 5| Step: 9
Training loss: 1.4481030716962462
Validation loss: 2.4339081146336925

Epoch: 5| Step: 10
Training loss: 1.2198648488900297
Validation loss: 2.45437955653906

Epoch: 347| Step: 0
Training loss: 1.5535130497654746
Validation loss: 2.4722662677492213

Epoch: 5| Step: 1
Training loss: 1.3403019246817953
Validation loss: 2.400032635607035

Epoch: 5| Step: 2
Training loss: 1.458527315953056
Validation loss: 2.428979276702388

Epoch: 5| Step: 3
Training loss: 0.8971551118782566
Validation loss: 2.4021755007187626

Epoch: 5| Step: 4
Training loss: 1.4970857603267735
Validation loss: 2.4757846780412565

Epoch: 5| Step: 5
Training loss: 1.9932415137412327
Validation loss: 2.4018368816987197

Epoch: 5| Step: 6
Training loss: 1.1160843744889513
Validation loss: 2.425978892581184

Epoch: 5| Step: 7
Training loss: 1.6142795974359956
Validation loss: 2.457284734666506

Epoch: 5| Step: 8
Training loss: 1.2016268233008933
Validation loss: 2.39288666146099

Epoch: 5| Step: 9
Training loss: 1.2948546241109393
Validation loss: 2.50500032822949

Epoch: 5| Step: 10
Training loss: 1.0413007792974098
Validation loss: 2.4282353882550787

Epoch: 348| Step: 0
Training loss: 0.9477088441901187
Validation loss: 2.533581126557162

Epoch: 5| Step: 1
Training loss: 1.5631806988956531
Validation loss: 2.4952803063066122

Epoch: 5| Step: 2
Training loss: 1.142254905955649
Validation loss: 2.373699716338898

Epoch: 5| Step: 3
Training loss: 1.1312336936323413
Validation loss: 2.483519157195772

Epoch: 5| Step: 4
Training loss: 1.464404393746506
Validation loss: 2.3899023612740042

Epoch: 5| Step: 5
Training loss: 1.2640721720359651
Validation loss: 2.506775765513557

Epoch: 5| Step: 6
Training loss: 1.0275538704665637
Validation loss: 2.5061722640345003

Epoch: 5| Step: 7
Training loss: 1.8210670970012048
Validation loss: 2.4728420275711698

Epoch: 5| Step: 8
Training loss: 1.641294942038595
Validation loss: 2.460292707600714

Epoch: 5| Step: 9
Training loss: 1.908434194983904
Validation loss: 2.424075138396288

Epoch: 5| Step: 10
Training loss: 1.2760840220785283
Validation loss: 2.411225748461304

Epoch: 349| Step: 0
Training loss: 1.9667288684167967
Validation loss: 2.423178904445976

Epoch: 5| Step: 1
Training loss: 1.5156806070410827
Validation loss: 2.4303306274719447

Epoch: 5| Step: 2
Training loss: 1.4486927815708084
Validation loss: 2.3365630567711393

Epoch: 5| Step: 3
Training loss: 1.076523351303535
Validation loss: 2.3988228706398917

Epoch: 5| Step: 4
Training loss: 0.8780306035684433
Validation loss: 2.4006311970971552

Epoch: 5| Step: 5
Training loss: 1.5354869379589187
Validation loss: 2.4407155472472812

Epoch: 5| Step: 6
Training loss: 1.1152720536850074
Validation loss: 2.3975598321155633

Epoch: 5| Step: 7
Training loss: 1.1828935018441082
Validation loss: 2.372553802097685

Epoch: 5| Step: 8
Training loss: 1.5769481236470881
Validation loss: 2.3799500037877834

Epoch: 5| Step: 9
Training loss: 1.6928719387707005
Validation loss: 2.4964633968167966

Epoch: 5| Step: 10
Training loss: 1.1723816348684393
Validation loss: 2.330196286471322

Epoch: 350| Step: 0
Training loss: 1.4805297838981564
Validation loss: 2.4366326273122416

Epoch: 5| Step: 1
Training loss: 1.1567748656954755
Validation loss: 2.41156868708818

Epoch: 5| Step: 2
Training loss: 1.1275175324153193
Validation loss: 2.4525167540523545

Epoch: 5| Step: 3
Training loss: 1.211899996298557
Validation loss: 2.4911352283976482

Epoch: 5| Step: 4
Training loss: 1.3077834624025841
Validation loss: 2.403389449107946

Epoch: 5| Step: 5
Training loss: 1.8775119485487595
Validation loss: 2.4020113743341143

Epoch: 5| Step: 6
Training loss: 1.1522929552165646
Validation loss: 2.5199172056067694

Epoch: 5| Step: 7
Training loss: 1.2540593514306673
Validation loss: 2.482272052078492

Epoch: 5| Step: 8
Training loss: 1.722031806687498
Validation loss: 2.4541156065341236

Epoch: 5| Step: 9
Training loss: 1.5685990127914455
Validation loss: 2.389237193200243

Epoch: 5| Step: 10
Training loss: 1.5352516824116424
Validation loss: 2.533270968593548

Epoch: 351| Step: 0
Training loss: 1.0341118492231856
Validation loss: 2.4200352238795344

Epoch: 5| Step: 1
Training loss: 1.4006607029325053
Validation loss: 2.4039625901419277

Epoch: 5| Step: 2
Training loss: 1.314459654747897
Validation loss: 2.4046627339538706

Epoch: 5| Step: 3
Training loss: 1.4472271583376952
Validation loss: 2.398497553173065

Epoch: 5| Step: 4
Training loss: 1.5718441605623612
Validation loss: 2.3470758905548696

Epoch: 5| Step: 5
Training loss: 1.6839109329989628
Validation loss: 2.3666514591123895

Epoch: 5| Step: 6
Training loss: 1.4048843110128382
Validation loss: 2.3987457749600485

Epoch: 5| Step: 7
Training loss: 1.2621572104680392
Validation loss: 2.404261576787262

Epoch: 5| Step: 8
Training loss: 1.3588286430951388
Validation loss: 2.4016889652066062

Epoch: 5| Step: 9
Training loss: 1.0953363630930473
Validation loss: 2.4006642591383476

Epoch: 5| Step: 10
Training loss: 1.459756302287012
Validation loss: 2.4222919625184773

Epoch: 352| Step: 0
Training loss: 1.4168775999821928
Validation loss: 2.4384622412570476

Epoch: 5| Step: 1
Training loss: 2.2632027140676945
Validation loss: 2.5063717818012488

Epoch: 5| Step: 2
Training loss: 1.5572791040566616
Validation loss: 2.3344283486380837

Epoch: 5| Step: 3
Training loss: 1.3246962775002373
Validation loss: 2.48396346670173

Epoch: 5| Step: 4
Training loss: 1.2630223959162639
Validation loss: 2.395179061758808

Epoch: 5| Step: 5
Training loss: 1.0863828226232937
Validation loss: 2.4139430380941795

Epoch: 5| Step: 6
Training loss: 1.2711150164662754
Validation loss: 2.4329988934453053

Epoch: 5| Step: 7
Training loss: 1.2265293092549754
Validation loss: 2.4507719341087433

Epoch: 5| Step: 8
Training loss: 1.3193704076819865
Validation loss: 2.431892537411804

Epoch: 5| Step: 9
Training loss: 1.372877737293156
Validation loss: 2.3982281850237532

Epoch: 5| Step: 10
Training loss: 0.9668484144248415
Validation loss: 2.3210953011106175

Epoch: 353| Step: 0
Training loss: 1.3701327180967835
Validation loss: 2.4680672227495153

Epoch: 5| Step: 1
Training loss: 1.1785248338480534
Validation loss: 2.422891759721052

Epoch: 5| Step: 2
Training loss: 1.2473793692355075
Validation loss: 2.515512810291174

Epoch: 5| Step: 3
Training loss: 1.5150082306591088
Validation loss: 2.356783534543618

Epoch: 5| Step: 4
Training loss: 1.4128025406096394
Validation loss: 2.439249991803177

Epoch: 5| Step: 5
Training loss: 1.754158936375539
Validation loss: 2.4420581523171045

Epoch: 5| Step: 6
Training loss: 1.120692909170228
Validation loss: 2.468139022462285

Epoch: 5| Step: 7
Training loss: 1.1007470975062605
Validation loss: 2.434319141622264

Epoch: 5| Step: 8
Training loss: 1.0799781242556952
Validation loss: 2.412784113543834

Epoch: 5| Step: 9
Training loss: 1.8990682174297753
Validation loss: 2.379249620579923

Epoch: 5| Step: 10
Training loss: 1.0377140329956627
Validation loss: 2.4510631869740807

Epoch: 354| Step: 0
Training loss: 1.5715129306369253
Validation loss: 2.428906704654739

Epoch: 5| Step: 1
Training loss: 1.2957802253626176
Validation loss: 2.5011862750075124

Epoch: 5| Step: 2
Training loss: 1.2767367072517986
Validation loss: 2.470848183583034

Epoch: 5| Step: 3
Training loss: 1.0050223710526165
Validation loss: 2.4342610821873825

Epoch: 5| Step: 4
Training loss: 1.0471121675948898
Validation loss: 2.523094959377244

Epoch: 5| Step: 5
Training loss: 1.7451945812309961
Validation loss: 2.4675438944750345

Epoch: 5| Step: 6
Training loss: 1.33712599685773
Validation loss: 2.429290345460937

Epoch: 5| Step: 7
Training loss: 1.3447995190301292
Validation loss: 2.3678142457456115

Epoch: 5| Step: 8
Training loss: 1.5772395907772185
Validation loss: 2.341397651223179

Epoch: 5| Step: 9
Training loss: 1.0447317360410964
Validation loss: 2.483499477056713

Epoch: 5| Step: 10
Training loss: 1.2761097117855371
Validation loss: 2.387302171156044

Epoch: 355| Step: 0
Training loss: 1.0993475322751038
Validation loss: 2.4802074725942322

Epoch: 5| Step: 1
Training loss: 1.276959422677405
Validation loss: 2.4527007739989926

Epoch: 5| Step: 2
Training loss: 1.430545486900344
Validation loss: 2.4939957041148957

Epoch: 5| Step: 3
Training loss: 1.5325405365652878
Validation loss: 2.4693856491228963

Epoch: 5| Step: 4
Training loss: 1.1858176310275481
Validation loss: 2.438597609493489

Epoch: 5| Step: 5
Training loss: 1.2194285337896542
Validation loss: 2.4712288315983577

Epoch: 5| Step: 6
Training loss: 1.3831564696360839
Validation loss: 2.459780793730129

Epoch: 5| Step: 7
Training loss: 1.4539370985002287
Validation loss: 2.4779219276923343

Epoch: 5| Step: 8
Training loss: 1.7464029947158224
Validation loss: 2.43023832295006

Epoch: 5| Step: 9
Training loss: 0.8642146385314393
Validation loss: 2.5105614931648677

Epoch: 5| Step: 10
Training loss: 1.5506225812248113
Validation loss: 2.499233999110497

Epoch: 356| Step: 0
Training loss: 0.8705195428932202
Validation loss: 2.433296589068951

Epoch: 5| Step: 1
Training loss: 1.455857691496461
Validation loss: 2.52078502354154

Epoch: 5| Step: 2
Training loss: 1.194230381440953
Validation loss: 2.4150638799232027

Epoch: 5| Step: 3
Training loss: 1.1394160408835383
Validation loss: 2.441767102028371

Epoch: 5| Step: 4
Training loss: 0.6944333422621077
Validation loss: 2.3604893417848825

Epoch: 5| Step: 5
Training loss: 1.5890363662956346
Validation loss: 2.4424708070504106

Epoch: 5| Step: 6
Training loss: 1.5928092872986885
Validation loss: 2.4801208200400318

Epoch: 5| Step: 7
Training loss: 1.5019596332860454
Validation loss: 2.3788781553636427

Epoch: 5| Step: 8
Training loss: 1.8318653804301321
Validation loss: 2.41631624427299

Epoch: 5| Step: 9
Training loss: 1.3928360666699575
Validation loss: 2.410981007301198

Epoch: 5| Step: 10
Training loss: 1.0892930912777536
Validation loss: 2.4171613452858507

Epoch: 357| Step: 0
Training loss: 1.1460493519926438
Validation loss: 2.4540039874631634

Epoch: 5| Step: 1
Training loss: 1.3478614540328608
Validation loss: 2.372976937549041

Epoch: 5| Step: 2
Training loss: 1.095261755188197
Validation loss: 2.4250689925187965

Epoch: 5| Step: 3
Training loss: 1.5800978160711003
Validation loss: 2.4816347213194554

Epoch: 5| Step: 4
Training loss: 1.0113224151674103
Validation loss: 2.483692861079639

Epoch: 5| Step: 5
Training loss: 1.3935260301943497
Validation loss: 2.42890498529184

Epoch: 5| Step: 6
Training loss: 1.8786973103478062
Validation loss: 2.525042127665768

Epoch: 5| Step: 7
Training loss: 1.2475675280226812
Validation loss: 2.512483172012647

Epoch: 5| Step: 8
Training loss: 1.7090916539989303
Validation loss: 2.4630778312942465

Epoch: 5| Step: 9
Training loss: 1.2459149845290454
Validation loss: 2.4330854946322997

Epoch: 5| Step: 10
Training loss: 1.6950450633537524
Validation loss: 2.4544562291403476

Epoch: 358| Step: 0
Training loss: 1.0802353922079833
Validation loss: 2.494215339410569

Epoch: 5| Step: 1
Training loss: 1.3031092251707912
Validation loss: 2.459248612424985

Epoch: 5| Step: 2
Training loss: 1.4359137864173168
Validation loss: 2.3698701865570624

Epoch: 5| Step: 3
Training loss: 1.98304842363754
Validation loss: 2.4751361799929708

Epoch: 5| Step: 4
Training loss: 1.2497197313819246
Validation loss: 2.4109861941631148

Epoch: 5| Step: 5
Training loss: 1.1808437213875997
Validation loss: 2.4727606987916215

Epoch: 5| Step: 6
Training loss: 1.5923877953206107
Validation loss: 2.4078488119666255

Epoch: 5| Step: 7
Training loss: 1.4372567510043204
Validation loss: 2.489481067929785

Epoch: 5| Step: 8
Training loss: 1.0968545721602623
Validation loss: 2.366599068664904

Epoch: 5| Step: 9
Training loss: 1.230403111235997
Validation loss: 2.489138518464303

Epoch: 5| Step: 10
Training loss: 1.0642002190239646
Validation loss: 2.4722416584977167

Epoch: 359| Step: 0
Training loss: 0.9745931681353813
Validation loss: 2.346326623910917

Epoch: 5| Step: 1
Training loss: 1.7444037466438014
Validation loss: 2.4028901886068543

Epoch: 5| Step: 2
Training loss: 1.6440442739265684
Validation loss: 2.479386110452767

Epoch: 5| Step: 3
Training loss: 1.1816505620869615
Validation loss: 2.3453492481728464

Epoch: 5| Step: 4
Training loss: 1.3508968588411658
Validation loss: 2.4730701520988814

Epoch: 5| Step: 5
Training loss: 1.0913786658676705
Validation loss: 2.417289425217178

Epoch: 5| Step: 6
Training loss: 1.1770425918865168
Validation loss: 2.3928077936763077

Epoch: 5| Step: 7
Training loss: 1.2873611782749501
Validation loss: 2.4535292300281952

Epoch: 5| Step: 8
Training loss: 1.488474675622697
Validation loss: 2.418337776356003

Epoch: 5| Step: 9
Training loss: 1.3351118871685812
Validation loss: 2.458452810161914

Epoch: 5| Step: 10
Training loss: 1.033638240580396
Validation loss: 2.451039590155659

Epoch: 360| Step: 0
Training loss: 1.4452423078658592
Validation loss: 2.429191532140369

Epoch: 5| Step: 1
Training loss: 1.6399656878347761
Validation loss: 2.4556347264846203

Epoch: 5| Step: 2
Training loss: 0.8585418477220598
Validation loss: 2.3646719899989357

Epoch: 5| Step: 3
Training loss: 1.2075288111248754
Validation loss: 2.4510886463481065

Epoch: 5| Step: 4
Training loss: 1.0783966385675785
Validation loss: 2.4256292814078253

Epoch: 5| Step: 5
Training loss: 1.345672208433636
Validation loss: 2.4281373027410074

Epoch: 5| Step: 6
Training loss: 1.4551749587640703
Validation loss: 2.4594502283424977

Epoch: 5| Step: 7
Training loss: 1.2435037608778112
Validation loss: 2.5207478396804173

Epoch: 5| Step: 8
Training loss: 0.8569370019741697
Validation loss: 2.475011933630344

Epoch: 5| Step: 9
Training loss: 1.5075907173506575
Validation loss: 2.433885852991071

Epoch: 5| Step: 10
Training loss: 1.9564467602336288
Validation loss: 2.415050877319446

Epoch: 361| Step: 0
Training loss: 1.9124411430527395
Validation loss: 2.496888112827632

Epoch: 5| Step: 1
Training loss: 1.381161366721636
Validation loss: 2.482296115733089

Epoch: 5| Step: 2
Training loss: 1.1310169064129227
Validation loss: 2.489326445690924

Epoch: 5| Step: 3
Training loss: 1.33035642874416
Validation loss: 2.4538373057342002

Epoch: 5| Step: 4
Training loss: 1.7724641658028453
Validation loss: 2.4133622686844807

Epoch: 5| Step: 5
Training loss: 1.2272676518364198
Validation loss: 2.390207284584146

Epoch: 5| Step: 6
Training loss: 0.9631494944017968
Validation loss: 2.4624340407709258

Epoch: 5| Step: 7
Training loss: 1.1339932831963926
Validation loss: 2.426599729980665

Epoch: 5| Step: 8
Training loss: 0.9970743775168115
Validation loss: 2.5480092840312274

Epoch: 5| Step: 9
Training loss: 1.3869002102610144
Validation loss: 2.4663297075257598

Epoch: 5| Step: 10
Training loss: 1.1039546667065585
Validation loss: 2.54710512362853

Epoch: 362| Step: 0
Training loss: 1.1639489240091363
Validation loss: 2.508818768925619

Epoch: 5| Step: 1
Training loss: 1.2716129079798966
Validation loss: 2.50052993449157

Epoch: 5| Step: 2
Training loss: 1.6625042277117446
Validation loss: 2.4888768899108804

Epoch: 5| Step: 3
Training loss: 1.013829213538875
Validation loss: 2.515478364398971

Epoch: 5| Step: 4
Training loss: 1.6792234977526557
Validation loss: 2.4713324491150717

Epoch: 5| Step: 5
Training loss: 1.8326443620260904
Validation loss: 2.417144976995018

Epoch: 5| Step: 6
Training loss: 1.3701014392080948
Validation loss: 2.52515929609134

Epoch: 5| Step: 7
Training loss: 1.1793535783092781
Validation loss: 2.4087744129196094

Epoch: 5| Step: 8
Training loss: 1.266392745758481
Validation loss: 2.3801212664210443

Epoch: 5| Step: 9
Training loss: 1.2974581039514916
Validation loss: 2.4280759987343754

Epoch: 5| Step: 10
Training loss: 1.2262604943000412
Validation loss: 2.5566192856441616

Epoch: 363| Step: 0
Training loss: 0.9473659501580313
Validation loss: 2.395350968291792

Epoch: 5| Step: 1
Training loss: 1.1641021824159818
Validation loss: 2.4302819666333257

Epoch: 5| Step: 2
Training loss: 1.1727115950971359
Validation loss: 2.4626820776952134

Epoch: 5| Step: 3
Training loss: 1.1312498693308044
Validation loss: 2.5112512724695084

Epoch: 5| Step: 4
Training loss: 1.4807605304900677
Validation loss: 2.4003993677120428

Epoch: 5| Step: 5
Training loss: 1.315457327480817
Validation loss: 2.4250989559472567

Epoch: 5| Step: 6
Training loss: 1.4171515177372014
Validation loss: 2.4138273517601516

Epoch: 5| Step: 7
Training loss: 1.1368141265392753
Validation loss: 2.3717915549383086

Epoch: 5| Step: 8
Training loss: 1.2094752188860618
Validation loss: 2.457807350793474

Epoch: 5| Step: 9
Training loss: 1.437124949746995
Validation loss: 2.365712104080541

Epoch: 5| Step: 10
Training loss: 2.3258295199632792
Validation loss: 2.413275337373333

Epoch: 364| Step: 0
Training loss: 1.2114580573718259
Validation loss: 2.435712929636295

Epoch: 5| Step: 1
Training loss: 1.1842968555125564
Validation loss: 2.4644863954615697

Epoch: 5| Step: 2
Training loss: 1.0620291171347844
Validation loss: 2.485441765555641

Epoch: 5| Step: 3
Training loss: 1.3074188879757949
Validation loss: 2.45414210027495

Epoch: 5| Step: 4
Training loss: 1.2260706212922632
Validation loss: 2.341954975278143

Epoch: 5| Step: 5
Training loss: 1.2908589185753048
Validation loss: 2.4702155588085084

Epoch: 5| Step: 6
Training loss: 2.1881840317583072
Validation loss: 2.5330061523220735

Epoch: 5| Step: 7
Training loss: 1.4840322801569963
Validation loss: 2.451451200754774

Epoch: 5| Step: 8
Training loss: 1.2345562572430524
Validation loss: 2.4108636842665625

Epoch: 5| Step: 9
Training loss: 1.373752461536205
Validation loss: 2.4527376129141194

Epoch: 5| Step: 10
Training loss: 1.3705629804906874
Validation loss: 2.479985861218612

Epoch: 365| Step: 0
Training loss: 1.1787072460556063
Validation loss: 2.3903674483511526

Epoch: 5| Step: 1
Training loss: 1.4640966519308307
Validation loss: 2.455816925536955

Epoch: 5| Step: 2
Training loss: 1.226139748970621
Validation loss: 2.4191900586170516

Epoch: 5| Step: 3
Training loss: 0.9958913260829
Validation loss: 2.455865281892331

Epoch: 5| Step: 4
Training loss: 1.8303049897529444
Validation loss: 2.4628315371928187

Epoch: 5| Step: 5
Training loss: 0.9700942096481165
Validation loss: 2.4865823181810347

Epoch: 5| Step: 6
Training loss: 1.1585578568211121
Validation loss: 2.4511735390003535

Epoch: 5| Step: 7
Training loss: 1.3869109544395537
Validation loss: 2.4909894096757763

Epoch: 5| Step: 8
Training loss: 1.1313482357808993
Validation loss: 2.4205108537360593

Epoch: 5| Step: 9
Training loss: 1.1834441238350915
Validation loss: 2.4105654478964094

Epoch: 5| Step: 10
Training loss: 2.1662313561977213
Validation loss: 2.464738572542203

Epoch: 366| Step: 0
Training loss: 1.2713342158986791
Validation loss: 2.434650774202088

Epoch: 5| Step: 1
Training loss: 1.0260767793537218
Validation loss: 2.397324649445792

Epoch: 5| Step: 2
Training loss: 1.1188840455461078
Validation loss: 2.39790185246825

Epoch: 5| Step: 3
Training loss: 1.5421888480910078
Validation loss: 2.442901606480686

Epoch: 5| Step: 4
Training loss: 1.8439461555232555
Validation loss: 2.3973493112604727

Epoch: 5| Step: 5
Training loss: 1.1903948884404325
Validation loss: 2.388567479896967

Epoch: 5| Step: 6
Training loss: 1.1115618361116388
Validation loss: 2.379808158854387

Epoch: 5| Step: 7
Training loss: 1.4715001756808623
Validation loss: 2.4243843112310746

Epoch: 5| Step: 8
Training loss: 1.237069629239096
Validation loss: 2.433382820407776

Epoch: 5| Step: 9
Training loss: 1.8494120153169444
Validation loss: 2.510246731325193

Epoch: 5| Step: 10
Training loss: 1.0131438833520727
Validation loss: 2.461804369998634

Epoch: 367| Step: 0
Training loss: 1.014818017646575
Validation loss: 2.4243116788280323

Epoch: 5| Step: 1
Training loss: 1.2636249893193003
Validation loss: 2.5398591498623153

Epoch: 5| Step: 2
Training loss: 1.4725120736940267
Validation loss: 2.4246013056295097

Epoch: 5| Step: 3
Training loss: 1.5153582623337845
Validation loss: 2.486420316592973

Epoch: 5| Step: 4
Training loss: 1.5634878469104017
Validation loss: 2.415326158988373

Epoch: 5| Step: 5
Training loss: 1.1493386606069367
Validation loss: 2.4230853996162147

Epoch: 5| Step: 6
Training loss: 1.3182180371286287
Validation loss: 2.4307612139237373

Epoch: 5| Step: 7
Training loss: 1.3935350979428571
Validation loss: 2.4669200661949446

Epoch: 5| Step: 8
Training loss: 1.8175663350631075
Validation loss: 2.4201641601577633

Epoch: 5| Step: 9
Training loss: 1.353423893009506
Validation loss: 2.4509519450824815

Epoch: 5| Step: 10
Training loss: 1.2773177584648945
Validation loss: 2.477053231509094

Epoch: 368| Step: 0
Training loss: 1.5499004485862806
Validation loss: 2.4311817708669805

Epoch: 5| Step: 1
Training loss: 1.0252688962343348
Validation loss: 2.4310256042523783

Epoch: 5| Step: 2
Training loss: 1.6625734212624286
Validation loss: 2.504241771908392

Epoch: 5| Step: 3
Training loss: 1.4704065112423275
Validation loss: 2.3848650234854727

Epoch: 5| Step: 4
Training loss: 1.2620114674870861
Validation loss: 2.3768458681808866

Epoch: 5| Step: 5
Training loss: 1.927015114341418
Validation loss: 2.462921325326227

Epoch: 5| Step: 6
Training loss: 0.8061073517100105
Validation loss: 2.4019790587363863

Epoch: 5| Step: 7
Training loss: 1.189263139156166
Validation loss: 2.433697313413354

Epoch: 5| Step: 8
Training loss: 0.9765339961660473
Validation loss: 2.42153837581684

Epoch: 5| Step: 9
Training loss: 1.0431390401856426
Validation loss: 2.4471744002827016

Epoch: 5| Step: 10
Training loss: 1.2682715636679234
Validation loss: 2.3749840276555614

Epoch: 369| Step: 0
Training loss: 0.8508213212425978
Validation loss: 2.396085617956947

Epoch: 5| Step: 1
Training loss: 1.3319009398320096
Validation loss: 2.430951142315982

Epoch: 5| Step: 2
Training loss: 1.6803617321859223
Validation loss: 2.41238664801462

Epoch: 5| Step: 3
Training loss: 1.1973069449881963
Validation loss: 2.422747652926445

Epoch: 5| Step: 4
Training loss: 1.3498200225952524
Validation loss: 2.4265994204336288

Epoch: 5| Step: 5
Training loss: 1.1150804403395005
Validation loss: 2.5618845002598345

Epoch: 5| Step: 6
Training loss: 1.365176831343842
Validation loss: 2.4955805991269804

Epoch: 5| Step: 7
Training loss: 1.2425327900756369
Validation loss: 2.4931242173136687

Epoch: 5| Step: 8
Training loss: 1.2889285856104329
Validation loss: 2.4557246206398062

Epoch: 5| Step: 9
Training loss: 1.458394003923052
Validation loss: 2.4475923491368743

Epoch: 5| Step: 10
Training loss: 1.009300552787845
Validation loss: 2.3972042967489418

Epoch: 370| Step: 0
Training loss: 1.0555608453673835
Validation loss: 2.417234589192509

Epoch: 5| Step: 1
Training loss: 1.1394240445260133
Validation loss: 2.447985011193754

Epoch: 5| Step: 2
Training loss: 1.2828026179909942
Validation loss: 2.4446584479523974

Epoch: 5| Step: 3
Training loss: 1.1774277422332726
Validation loss: 2.420994138284421

Epoch: 5| Step: 4
Training loss: 1.2704845429267992
Validation loss: 2.488234489785731

Epoch: 5| Step: 5
Training loss: 1.4821527812316926
Validation loss: 2.4282280744471447

Epoch: 5| Step: 6
Training loss: 1.4088364445481891
Validation loss: 2.4656500423827485

Epoch: 5| Step: 7
Training loss: 1.9504313700946934
Validation loss: 2.4070697272980435

Epoch: 5| Step: 8
Training loss: 1.0582168302215285
Validation loss: 2.397925270320079

Epoch: 5| Step: 9
Training loss: 1.45063889009925
Validation loss: 2.4993947506498597

Epoch: 5| Step: 10
Training loss: 0.8810022073386833
Validation loss: 2.4274112178552456

Epoch: 371| Step: 0
Training loss: 1.4117534183537146
Validation loss: 2.419770107350084

Epoch: 5| Step: 1
Training loss: 1.1477430151126728
Validation loss: 2.4262714009352506

Epoch: 5| Step: 2
Training loss: 1.3877150274456123
Validation loss: 2.4452732406327304

Epoch: 5| Step: 3
Training loss: 1.391983996929609
Validation loss: 2.441478001087782

Epoch: 5| Step: 4
Training loss: 1.808642920202623
Validation loss: 2.4552096179612466

Epoch: 5| Step: 5
Training loss: 1.1536259129212991
Validation loss: 2.405784227315825

Epoch: 5| Step: 6
Training loss: 1.4067303155145867
Validation loss: 2.5425710240900896

Epoch: 5| Step: 7
Training loss: 1.110095421495713
Validation loss: 2.447370815924165

Epoch: 5| Step: 8
Training loss: 1.4006063595731042
Validation loss: 2.4703337398798833

Epoch: 5| Step: 9
Training loss: 1.2188039914422926
Validation loss: 2.455451242246936

Epoch: 5| Step: 10
Training loss: 1.3369729117571758
Validation loss: 2.3883832543623638

Epoch: 372| Step: 0
Training loss: 0.9454245382703909
Validation loss: 2.4890813921773085

Epoch: 5| Step: 1
Training loss: 0.9049585611645868
Validation loss: 2.4360658335313214

Epoch: 5| Step: 2
Training loss: 0.9335595926715942
Validation loss: 2.481811058955354

Epoch: 5| Step: 3
Training loss: 1.5703470406600386
Validation loss: 2.4325893770003497

Epoch: 5| Step: 4
Training loss: 1.404435958659783
Validation loss: 2.4665167206162377

Epoch: 5| Step: 5
Training loss: 1.7686571400128566
Validation loss: 2.4151200082468365

Epoch: 5| Step: 6
Training loss: 1.7315500295507018
Validation loss: 2.4763196207131686

Epoch: 5| Step: 7
Training loss: 1.01859301662287
Validation loss: 2.393470755626286

Epoch: 5| Step: 8
Training loss: 1.2989530345540492
Validation loss: 2.4831422789140034

Epoch: 5| Step: 9
Training loss: 1.3108141835425207
Validation loss: 2.425442501468834

Epoch: 5| Step: 10
Training loss: 0.8162537573805315
Validation loss: 2.3953629615593437

Epoch: 373| Step: 0
Training loss: 1.413791356514765
Validation loss: 2.478575653528652

Epoch: 5| Step: 1
Training loss: 1.0637265586735636
Validation loss: 2.487942753390698

Epoch: 5| Step: 2
Training loss: 1.2786361269249022
Validation loss: 2.4257790126879057

Epoch: 5| Step: 3
Training loss: 1.1629347490749766
Validation loss: 2.4263713379794196

Epoch: 5| Step: 4
Training loss: 1.0690308296711057
Validation loss: 2.41321339236218

Epoch: 5| Step: 5
Training loss: 0.9723283145935436
Validation loss: 2.5292318095259945

Epoch: 5| Step: 6
Training loss: 1.4575260743676415
Validation loss: 2.5046311235140237

Epoch: 5| Step: 7
Training loss: 1.734305646729747
Validation loss: 2.51867880378998

Epoch: 5| Step: 8
Training loss: 1.0763869165928863
Validation loss: 2.5587503174439656

Epoch: 5| Step: 9
Training loss: 1.2181296603807028
Validation loss: 2.435926141196523

Epoch: 5| Step: 10
Training loss: 1.7694963531758374
Validation loss: 2.5497305965611567

Epoch: 374| Step: 0
Training loss: 1.07206727018948
Validation loss: 2.382379487607404

Epoch: 5| Step: 1
Training loss: 1.2683950181281576
Validation loss: 2.458116644529235

Epoch: 5| Step: 2
Training loss: 1.111834633551731
Validation loss: 2.3946829996020433

Epoch: 5| Step: 3
Training loss: 1.079292549734875
Validation loss: 2.4568977655538626

Epoch: 5| Step: 4
Training loss: 1.3080116913299213
Validation loss: 2.4873949258846277

Epoch: 5| Step: 5
Training loss: 1.3256340902791086
Validation loss: 2.4476960476592104

Epoch: 5| Step: 6
Training loss: 1.2843459337198715
Validation loss: 2.443864829141879

Epoch: 5| Step: 7
Training loss: 1.9795189259571773
Validation loss: 2.4182796586849458

Epoch: 5| Step: 8
Training loss: 1.490051498291188
Validation loss: 2.443930679908588

Epoch: 5| Step: 9
Training loss: 1.0418054615377774
Validation loss: 2.430922404749428

Epoch: 5| Step: 10
Training loss: 1.6645423304823617
Validation loss: 2.462401444748219

Epoch: 375| Step: 0
Training loss: 0.8283962309410376
Validation loss: 2.4191942868574743

Epoch: 5| Step: 1
Training loss: 1.7424383966401267
Validation loss: 2.4262475149242073

Epoch: 5| Step: 2
Training loss: 1.0625352292671701
Validation loss: 2.3873150064949016

Epoch: 5| Step: 3
Training loss: 1.131159609139206
Validation loss: 2.4407711886149106

Epoch: 5| Step: 4
Training loss: 1.2020250221447137
Validation loss: 2.438329563379214

Epoch: 5| Step: 5
Training loss: 1.0953871327439695
Validation loss: 2.4256718486232867

Epoch: 5| Step: 6
Training loss: 1.8915515237234841
Validation loss: 2.4901265678257207

Epoch: 5| Step: 7
Training loss: 1.600539760144593
Validation loss: 2.4448032482496522

Epoch: 5| Step: 8
Training loss: 0.9811543351209481
Validation loss: 2.4072419694712273

Epoch: 5| Step: 9
Training loss: 1.207727570897376
Validation loss: 2.4735159488257006

Epoch: 5| Step: 10
Training loss: 1.5059132053040705
Validation loss: 2.364391750015387

Epoch: 376| Step: 0
Training loss: 1.2178508180263075
Validation loss: 2.465423363983526

Epoch: 5| Step: 1
Training loss: 1.320313086876372
Validation loss: 2.3942061289202936

Epoch: 5| Step: 2
Training loss: 1.0358885280259298
Validation loss: 2.5085074782685206

Epoch: 5| Step: 3
Training loss: 1.9654977366090647
Validation loss: 2.429781145366425

Epoch: 5| Step: 4
Training loss: 1.2223999924894402
Validation loss: 2.502912678647831

Epoch: 5| Step: 5
Training loss: 1.103976263267924
Validation loss: 2.5318143380852183

Epoch: 5| Step: 6
Training loss: 1.3347319578904457
Validation loss: 2.5187857028868756

Epoch: 5| Step: 7
Training loss: 1.060458184849056
Validation loss: 2.438216260622659

Epoch: 5| Step: 8
Training loss: 1.486801172438378
Validation loss: 2.440160078672668

Epoch: 5| Step: 9
Training loss: 0.9442769202772425
Validation loss: 2.5079776245830185

Epoch: 5| Step: 10
Training loss: 1.2447654795851586
Validation loss: 2.498190840483899

Epoch: 377| Step: 0
Training loss: 1.046895439745512
Validation loss: 2.4758356317172248

Epoch: 5| Step: 1
Training loss: 1.00184556409746
Validation loss: 2.4384318438194974

Epoch: 5| Step: 2
Training loss: 0.9200367784923241
Validation loss: 2.4404879751982453

Epoch: 5| Step: 3
Training loss: 1.2525558092243065
Validation loss: 2.4151340422469065

Epoch: 5| Step: 4
Training loss: 1.7259449954943302
Validation loss: 2.431280450577245

Epoch: 5| Step: 5
Training loss: 1.0705423038788453
Validation loss: 2.364683266134817

Epoch: 5| Step: 6
Training loss: 1.7658738492620498
Validation loss: 2.4453678907846124

Epoch: 5| Step: 7
Training loss: 1.2150284605264279
Validation loss: 2.427949998794609

Epoch: 5| Step: 8
Training loss: 1.0221797990173573
Validation loss: 2.3743458609641754

Epoch: 5| Step: 9
Training loss: 1.4708443987955149
Validation loss: 2.4798961730123192

Epoch: 5| Step: 10
Training loss: 1.4691592518833378
Validation loss: 2.4704081754755216

Epoch: 378| Step: 0
Training loss: 1.0483254590266888
Validation loss: 2.4166896208654958

Epoch: 5| Step: 1
Training loss: 1.2422325557958696
Validation loss: 2.400418708152582

Epoch: 5| Step: 2
Training loss: 1.0948640871398019
Validation loss: 2.447132811569454

Epoch: 5| Step: 3
Training loss: 1.1830985163139203
Validation loss: 2.43646433735959

Epoch: 5| Step: 4
Training loss: 1.178314572166499
Validation loss: 2.496031086165426

Epoch: 5| Step: 5
Training loss: 1.9060805198497346
Validation loss: 2.4285968925417842

Epoch: 5| Step: 6
Training loss: 1.0878928165653419
Validation loss: 2.4481916061575473

Epoch: 5| Step: 7
Training loss: 0.9964854349200251
Validation loss: 2.3721855134012877

Epoch: 5| Step: 8
Training loss: 1.2789410045191554
Validation loss: 2.507174074582286

Epoch: 5| Step: 9
Training loss: 1.3928326003738514
Validation loss: 2.411938278123727

Epoch: 5| Step: 10
Training loss: 1.7212851121433592
Validation loss: 2.4315846439656306

Epoch: 379| Step: 0
Training loss: 0.9771453338884851
Validation loss: 2.473569251111355

Epoch: 5| Step: 1
Training loss: 0.9567930586878859
Validation loss: 2.4511736357445253

Epoch: 5| Step: 2
Training loss: 0.85432441154234
Validation loss: 2.4481989582348236

Epoch: 5| Step: 3
Training loss: 1.064605533992954
Validation loss: 2.4265334173422586

Epoch: 5| Step: 4
Training loss: 0.8417833862640116
Validation loss: 2.493824131356447

Epoch: 5| Step: 5
Training loss: 1.759806066253712
Validation loss: 2.3564445999076638

Epoch: 5| Step: 6
Training loss: 1.877947080693309
Validation loss: 2.48624928003536

Epoch: 5| Step: 7
Training loss: 1.6165643495777344
Validation loss: 2.4395328129959153

Epoch: 5| Step: 8
Training loss: 1.3938138168846694
Validation loss: 2.4792193866217738

Epoch: 5| Step: 9
Training loss: 1.234737777516621
Validation loss: 2.454288858948855

Epoch: 5| Step: 10
Training loss: 1.078756617308087
Validation loss: 2.435655742305165

Epoch: 380| Step: 0
Training loss: 0.95322214475762
Validation loss: 2.387915495427929

Epoch: 5| Step: 1
Training loss: 1.1246198435723793
Validation loss: 2.501520123346068

Epoch: 5| Step: 2
Training loss: 1.830820232385577
Validation loss: 2.4292978671309493

Epoch: 5| Step: 3
Training loss: 1.002140852981799
Validation loss: 2.3899967489522074

Epoch: 5| Step: 4
Training loss: 1.5500291206331547
Validation loss: 2.485835757229948

Epoch: 5| Step: 5
Training loss: 1.0892304913461606
Validation loss: 2.437190742741761

Epoch: 5| Step: 6
Training loss: 1.5234848406356416
Validation loss: 2.4518039925200403

Epoch: 5| Step: 7
Training loss: 1.531584878231466
Validation loss: 2.5157556985838534

Epoch: 5| Step: 8
Training loss: 1.0542060600931613
Validation loss: 2.381563545943728

Epoch: 5| Step: 9
Training loss: 0.9603137961768984
Validation loss: 2.441329480479827

Epoch: 5| Step: 10
Training loss: 1.0306452509623758
Validation loss: 2.489305281346711

Epoch: 381| Step: 0
Training loss: 1.5452219289498974
Validation loss: 2.4533003438789844

Epoch: 5| Step: 1
Training loss: 0.9060587845693434
Validation loss: 2.4273129693930677

Epoch: 5| Step: 2
Training loss: 1.182725493482598
Validation loss: 2.4332318080681756

Epoch: 5| Step: 3
Training loss: 1.3607110659600903
Validation loss: 2.438009178927895

Epoch: 5| Step: 4
Training loss: 1.312305481438241
Validation loss: 2.4731372662876994

Epoch: 5| Step: 5
Training loss: 1.1235499043265533
Validation loss: 2.4997129767761956

Epoch: 5| Step: 6
Training loss: 1.1119200834469427
Validation loss: 2.4176963342442024

Epoch: 5| Step: 7
Training loss: 0.8339251602198772
Validation loss: 2.4660229193218814

Epoch: 5| Step: 8
Training loss: 2.004398397053976
Validation loss: 2.4940450625310735

Epoch: 5| Step: 9
Training loss: 1.3895913472247152
Validation loss: 2.4958149520632946

Epoch: 5| Step: 10
Training loss: 1.2167548942365594
Validation loss: 2.488907830034546

Epoch: 382| Step: 0
Training loss: 1.322898994788335
Validation loss: 2.519399972408062

Epoch: 5| Step: 1
Training loss: 1.0030367161770941
Validation loss: 2.4650111747005337

Epoch: 5| Step: 2
Training loss: 1.1434457989329232
Validation loss: 2.493807191984768

Epoch: 5| Step: 3
Training loss: 1.2247495434135898
Validation loss: 2.521909955886658

Epoch: 5| Step: 4
Training loss: 1.7827713476006752
Validation loss: 2.4651735567898987

Epoch: 5| Step: 5
Training loss: 1.9644217369741181
Validation loss: 2.4757094467616643

Epoch: 5| Step: 6
Training loss: 0.9631960618466127
Validation loss: 2.3983011712362035

Epoch: 5| Step: 7
Training loss: 1.2112214278560582
Validation loss: 2.424009066571505

Epoch: 5| Step: 8
Training loss: 1.2261391170193425
Validation loss: 2.5431987334025368

Epoch: 5| Step: 9
Training loss: 1.2587733892940332
Validation loss: 2.496724506599583

Epoch: 5| Step: 10
Training loss: 1.150041718348228
Validation loss: 2.4538120603233344

Epoch: 383| Step: 0
Training loss: 1.4094337874033738
Validation loss: 2.461680521849977

Epoch: 5| Step: 1
Training loss: 1.2898872280360074
Validation loss: 2.536201702765839

Epoch: 5| Step: 2
Training loss: 1.128298216225863
Validation loss: 2.5066890628704805

Epoch: 5| Step: 3
Training loss: 1.0254739781969635
Validation loss: 2.4675963013852513

Epoch: 5| Step: 4
Training loss: 1.0675221846908518
Validation loss: 2.432028275538622

Epoch: 5| Step: 5
Training loss: 1.2396470008121747
Validation loss: 2.438731727675661

Epoch: 5| Step: 6
Training loss: 1.4091566775235045
Validation loss: 2.5316327999538535

Epoch: 5| Step: 7
Training loss: 1.9399729298148225
Validation loss: 2.4412789008284577

Epoch: 5| Step: 8
Training loss: 1.3237027313467067
Validation loss: 2.4578100147673747

Epoch: 5| Step: 9
Training loss: 1.0296457701868147
Validation loss: 2.349831969101791

Epoch: 5| Step: 10
Training loss: 1.4550735371152503
Validation loss: 2.4165263571936073

Epoch: 384| Step: 0
Training loss: 1.168073005233455
Validation loss: 2.4308001139045556

Epoch: 5| Step: 1
Training loss: 1.1568664763150527
Validation loss: 2.4388293681790802

Epoch: 5| Step: 2
Training loss: 1.2937688743209674
Validation loss: 2.4216600696515727

Epoch: 5| Step: 3
Training loss: 1.3320614540054108
Validation loss: 2.4717566345299917

Epoch: 5| Step: 4
Training loss: 1.3743524760664014
Validation loss: 2.4401541816282895

Epoch: 5| Step: 5
Training loss: 0.9601903352204546
Validation loss: 2.4335899449782232

Epoch: 5| Step: 6
Training loss: 0.8908980770748451
Validation loss: 2.400685366920429

Epoch: 5| Step: 7
Training loss: 1.1383285397437515
Validation loss: 2.4873832707197217

Epoch: 5| Step: 8
Training loss: 1.237208241449996
Validation loss: 2.3887939421935283

Epoch: 5| Step: 9
Training loss: 1.8581009033775773
Validation loss: 2.472728286588329

Epoch: 5| Step: 10
Training loss: 1.9300293407285285
Validation loss: 2.5021817675061437

Epoch: 385| Step: 0
Training loss: 1.5446260846689788
Validation loss: 2.3600120344527777

Epoch: 5| Step: 1
Training loss: 0.7503918180600183
Validation loss: 2.5311124210500786

Epoch: 5| Step: 2
Training loss: 0.8762820932603205
Validation loss: 2.3941312328423012

Epoch: 5| Step: 3
Training loss: 1.2388757668405146
Validation loss: 2.43968610751896

Epoch: 5| Step: 4
Training loss: 1.0648535299096926
Validation loss: 2.418988936315625

Epoch: 5| Step: 5
Training loss: 1.535272336652302
Validation loss: 2.4417045317197337

Epoch: 5| Step: 6
Training loss: 1.4187832429327025
Validation loss: 2.420494285676615

Epoch: 5| Step: 7
Training loss: 0.9403718195745701
Validation loss: 2.3981311844725663

Epoch: 5| Step: 8
Training loss: 1.4772623008413437
Validation loss: 2.440339439509315

Epoch: 5| Step: 9
Training loss: 1.8178766021522104
Validation loss: 2.4531921509204353

Epoch: 5| Step: 10
Training loss: 1.3388265858176294
Validation loss: 2.4215008132008427

Epoch: 386| Step: 0
Training loss: 0.9354476716836891
Validation loss: 2.4598238392565186

Epoch: 5| Step: 1
Training loss: 1.2139735401607101
Validation loss: 2.407267020631706

Epoch: 5| Step: 2
Training loss: 1.3969774776136872
Validation loss: 2.4638923236416206

Epoch: 5| Step: 3
Training loss: 0.9589892851476575
Validation loss: 2.456398497817037

Epoch: 5| Step: 4
Training loss: 1.4918950777976105
Validation loss: 2.4554317537288255

Epoch: 5| Step: 5
Training loss: 0.7562867368492227
Validation loss: 2.4118444225410185

Epoch: 5| Step: 6
Training loss: 1.4492491850009197
Validation loss: 2.5127530032971688

Epoch: 5| Step: 7
Training loss: 1.233894544364529
Validation loss: 2.478861555180928

Epoch: 5| Step: 8
Training loss: 1.7909765540866827
Validation loss: 2.4999688613141893

Epoch: 5| Step: 9
Training loss: 1.0221441118716872
Validation loss: 2.517184842993703

Epoch: 5| Step: 10
Training loss: 1.0675638923017317
Validation loss: 2.574673995143179

Epoch: 387| Step: 0
Training loss: 1.1095663630961332
Validation loss: 2.4470699614997793

Epoch: 5| Step: 1
Training loss: 1.1801782054820984
Validation loss: 2.4241984759702526

Epoch: 5| Step: 2
Training loss: 1.6109440386220433
Validation loss: 2.4843282934467643

Epoch: 5| Step: 3
Training loss: 1.0207378511474314
Validation loss: 2.3934220309032934

Epoch: 5| Step: 4
Training loss: 1.158211667831848
Validation loss: 2.4409814220013097

Epoch: 5| Step: 5
Training loss: 1.9899022777084059
Validation loss: 2.385512828343996

Epoch: 5| Step: 6
Training loss: 1.0019424765097227
Validation loss: 2.384996816704768

Epoch: 5| Step: 7
Training loss: 1.0673188716517077
Validation loss: 2.452800565466872

Epoch: 5| Step: 8
Training loss: 1.1911972112657583
Validation loss: 2.4395442596097756

Epoch: 5| Step: 9
Training loss: 1.029929500500387
Validation loss: 2.385764278353093

Epoch: 5| Step: 10
Training loss: 1.165807810911437
Validation loss: 2.490783797057215

Epoch: 388| Step: 0
Training loss: 1.0739263518067332
Validation loss: 2.5009303197533552

Epoch: 5| Step: 1
Training loss: 1.7079724961954188
Validation loss: 2.4988702272187284

Epoch: 5| Step: 2
Training loss: 1.6060517452212575
Validation loss: 2.437954441427023

Epoch: 5| Step: 3
Training loss: 1.3005347490871086
Validation loss: 2.452745533548298

Epoch: 5| Step: 4
Training loss: 1.147665477946701
Validation loss: 2.398719579947754

Epoch: 5| Step: 5
Training loss: 1.0182611146615763
Validation loss: 2.442224814995978

Epoch: 5| Step: 6
Training loss: 1.031847867187301
Validation loss: 2.418971094013643

Epoch: 5| Step: 7
Training loss: 1.2411788107903388
Validation loss: 2.426341150946933

Epoch: 5| Step: 8
Training loss: 1.1300603122144626
Validation loss: 2.460425944303566

Epoch: 5| Step: 9
Training loss: 1.029949639950294
Validation loss: 2.408418418541418

Epoch: 5| Step: 10
Training loss: 1.8817370497135157
Validation loss: 2.5389861074713598

Epoch: 389| Step: 0
Training loss: 1.3043781302048505
Validation loss: 2.5767008199159367

Epoch: 5| Step: 1
Training loss: 1.656154629822557
Validation loss: 2.4832975104881614

Epoch: 5| Step: 2
Training loss: 0.9403036157829189
Validation loss: 2.472555631027508

Epoch: 5| Step: 3
Training loss: 1.0577781322311248
Validation loss: 2.410578811822685

Epoch: 5| Step: 4
Training loss: 0.9707881959291832
Validation loss: 2.479867178714082

Epoch: 5| Step: 5
Training loss: 1.0931201756296196
Validation loss: 2.493977909641036

Epoch: 5| Step: 6
Training loss: 1.4116612906655757
Validation loss: 2.4162713573704413

Epoch: 5| Step: 7
Training loss: 1.4998998608541612
Validation loss: 2.487215160135583

Epoch: 5| Step: 8
Training loss: 1.3765913251268473
Validation loss: 2.4082203471476955

Epoch: 5| Step: 9
Training loss: 1.185125888946042
Validation loss: 2.4944857017681468

Epoch: 5| Step: 10
Training loss: 1.1992973277041612
Validation loss: 2.41783171149831

Epoch: 390| Step: 0
Training loss: 0.8624723277974071
Validation loss: 2.4218377498497032

Epoch: 5| Step: 1
Training loss: 0.9211225509994073
Validation loss: 2.4432668006624474

Epoch: 5| Step: 2
Training loss: 1.008777422620861
Validation loss: 2.5095210459956556

Epoch: 5| Step: 3
Training loss: 1.1886791598836086
Validation loss: 2.403111404689219

Epoch: 5| Step: 4
Training loss: 1.0074045109518908
Validation loss: 2.3648675774207812

Epoch: 5| Step: 5
Training loss: 1.8042417694153552
Validation loss: 2.4507351148112546

Epoch: 5| Step: 6
Training loss: 1.1967651416369738
Validation loss: 2.460905321688559

Epoch: 5| Step: 7
Training loss: 1.2280429239972137
Validation loss: 2.3695763303618826

Epoch: 5| Step: 8
Training loss: 1.4527164007820226
Validation loss: 2.486081799655754

Epoch: 5| Step: 9
Training loss: 1.1729187449859761
Validation loss: 2.442994944704406

Epoch: 5| Step: 10
Training loss: 1.1771097883554291
Validation loss: 2.422132213640638

Epoch: 391| Step: 0
Training loss: 1.4367482251311823
Validation loss: 2.401652825943098

Epoch: 5| Step: 1
Training loss: 1.7496203283165943
Validation loss: 2.4367286075743166

Epoch: 5| Step: 2
Training loss: 0.6216162636942872
Validation loss: 2.454913335355296

Epoch: 5| Step: 3
Training loss: 0.9602038676634723
Validation loss: 2.3719612914901202

Epoch: 5| Step: 4
Training loss: 1.0868206138231182
Validation loss: 2.4557146989695933

Epoch: 5| Step: 5
Training loss: 1.017550770104517
Validation loss: 2.366546917817317

Epoch: 5| Step: 6
Training loss: 1.3281367133128927
Validation loss: 2.5164916066115093

Epoch: 5| Step: 7
Training loss: 1.514436708232935
Validation loss: 2.341031043660867

Epoch: 5| Step: 8
Training loss: 1.5329039069091652
Validation loss: 2.4416874911514896

Epoch: 5| Step: 9
Training loss: 1.2195619177276609
Validation loss: 2.4468239718636706

Epoch: 5| Step: 10
Training loss: 0.9940155190401924
Validation loss: 2.4315844183435766

Epoch: 392| Step: 0
Training loss: 0.993814081249175
Validation loss: 2.45926907769364

Epoch: 5| Step: 1
Training loss: 1.4322811426874258
Validation loss: 2.4997275498838567

Epoch: 5| Step: 2
Training loss: 1.1362825585831935
Validation loss: 2.398593186863688

Epoch: 5| Step: 3
Training loss: 1.0043988039985685
Validation loss: 2.527961318355701

Epoch: 5| Step: 4
Training loss: 1.3539848890320647
Validation loss: 2.4787560965149606

Epoch: 5| Step: 5
Training loss: 1.133388451797327
Validation loss: 2.430314949146848

Epoch: 5| Step: 6
Training loss: 1.2867887384109835
Validation loss: 2.467197015425978

Epoch: 5| Step: 7
Training loss: 1.034135826556768
Validation loss: 2.4316733202461975

Epoch: 5| Step: 8
Training loss: 1.7710699334749695
Validation loss: 2.4916886624964847

Epoch: 5| Step: 9
Training loss: 1.230483330534273
Validation loss: 2.4314081589507084

Epoch: 5| Step: 10
Training loss: 0.9893338173291427
Validation loss: 2.442603375434026

Epoch: 393| Step: 0
Training loss: 1.0426331169343894
Validation loss: 2.4459247920072618

Epoch: 5| Step: 1
Training loss: 1.358618953530284
Validation loss: 2.4728668340427364

Epoch: 5| Step: 2
Training loss: 1.104576640521916
Validation loss: 2.460244645630168

Epoch: 5| Step: 3
Training loss: 1.4145095708583257
Validation loss: 2.500927187122819

Epoch: 5| Step: 4
Training loss: 1.5226440711045695
Validation loss: 2.4677791257037502

Epoch: 5| Step: 5
Training loss: 0.9511136266274278
Validation loss: 2.467844246417622

Epoch: 5| Step: 6
Training loss: 1.0331094912122454
Validation loss: 2.4139517463255054

Epoch: 5| Step: 7
Training loss: 1.2293629354904079
Validation loss: 2.4309257889450966

Epoch: 5| Step: 8
Training loss: 0.9748501528006737
Validation loss: 2.5045851590996793

Epoch: 5| Step: 9
Training loss: 2.0317412735986435
Validation loss: 2.476353484432912

Epoch: 5| Step: 10
Training loss: 0.8827706048527464
Validation loss: 2.5281986818596907

Epoch: 394| Step: 0
Training loss: 1.2404680167168505
Validation loss: 2.457114046779641

Epoch: 5| Step: 1
Training loss: 1.4264079349677943
Validation loss: 2.538728637453559

Epoch: 5| Step: 2
Training loss: 0.8332087821070919
Validation loss: 2.552280059491574

Epoch: 5| Step: 3
Training loss: 1.2505078714512694
Validation loss: 2.4649643747666197

Epoch: 5| Step: 4
Training loss: 1.2188162663368673
Validation loss: 2.4404442976350156

Epoch: 5| Step: 5
Training loss: 1.2459956880926528
Validation loss: 2.4891445136847605

Epoch: 5| Step: 6
Training loss: 1.1185212610071715
Validation loss: 2.4708948274607714

Epoch: 5| Step: 7
Training loss: 1.3648994700822423
Validation loss: 2.424854614869253

Epoch: 5| Step: 8
Training loss: 1.9057788579327948
Validation loss: 2.4552825303041854

Epoch: 5| Step: 9
Training loss: 0.9804526095942561
Validation loss: 2.485927339044522

Epoch: 5| Step: 10
Training loss: 1.0332867709303233
Validation loss: 2.517677257253616

Epoch: 395| Step: 0
Training loss: 1.174487393752871
Validation loss: 2.4688890822187366

Epoch: 5| Step: 1
Training loss: 0.992815855006768
Validation loss: 2.388441610050247

Epoch: 5| Step: 2
Training loss: 1.1342449733731212
Validation loss: 2.464552557567625

Epoch: 5| Step: 3
Training loss: 1.2359393866099007
Validation loss: 2.5268113315542595

Epoch: 5| Step: 4
Training loss: 1.160191904669659
Validation loss: 2.435408390292546

Epoch: 5| Step: 5
Training loss: 1.134704798317316
Validation loss: 2.482220786421353

Epoch: 5| Step: 6
Training loss: 1.1913992959741981
Validation loss: 2.422282429911758

Epoch: 5| Step: 7
Training loss: 0.9062143187240084
Validation loss: 2.4002098436549493

Epoch: 5| Step: 8
Training loss: 1.84083417082814
Validation loss: 2.431990595859764

Epoch: 5| Step: 9
Training loss: 1.4511372085887104
Validation loss: 2.453944594788213

Epoch: 5| Step: 10
Training loss: 1.1969011508086742
Validation loss: 2.425128919005507

Epoch: 396| Step: 0
Training loss: 0.6279132656957929
Validation loss: 2.4494314484565125

Epoch: 5| Step: 1
Training loss: 1.2216245057887534
Validation loss: 2.454460610747458

Epoch: 5| Step: 2
Training loss: 1.2186598622172464
Validation loss: 2.460753085454869

Epoch: 5| Step: 3
Training loss: 1.1168475400754223
Validation loss: 2.4852674618342157

Epoch: 5| Step: 4
Training loss: 1.0472385856896989
Validation loss: 2.414098997205577

Epoch: 5| Step: 5
Training loss: 1.448103647943115
Validation loss: 2.4415653236986987

Epoch: 5| Step: 6
Training loss: 1.1832028993169974
Validation loss: 2.4389775827452422

Epoch: 5| Step: 7
Training loss: 1.8486903323229174
Validation loss: 2.5009648747859825

Epoch: 5| Step: 8
Training loss: 1.4248276957692905
Validation loss: 2.4609258346424374

Epoch: 5| Step: 9
Training loss: 1.2109476396689898
Validation loss: 2.5065743315332796

Epoch: 5| Step: 10
Training loss: 1.2002656821346955
Validation loss: 2.3968511681605205

Epoch: 397| Step: 0
Training loss: 1.2146246120620678
Validation loss: 2.4454466755333266

Epoch: 5| Step: 1
Training loss: 1.250798828458954
Validation loss: 2.549045045170136

Epoch: 5| Step: 2
Training loss: 1.2211958966330878
Validation loss: 2.3965159067617066

Epoch: 5| Step: 3
Training loss: 0.8168827838132834
Validation loss: 2.4383616737363565

Epoch: 5| Step: 4
Training loss: 0.9203675439820903
Validation loss: 2.3805347117525066

Epoch: 5| Step: 5
Training loss: 1.0978487870853662
Validation loss: 2.475037064310515

Epoch: 5| Step: 6
Training loss: 1.138775200842374
Validation loss: 2.5433727578785845

Epoch: 5| Step: 7
Training loss: 1.9015681822291464
Validation loss: 2.4964381904388904

Epoch: 5| Step: 8
Training loss: 1.1375839244358579
Validation loss: 2.3968882306647954

Epoch: 5| Step: 9
Training loss: 1.3545155540381537
Validation loss: 2.4557245934972447

Epoch: 5| Step: 10
Training loss: 1.4039964208584454
Validation loss: 2.4959775332840413

Epoch: 398| Step: 0
Training loss: 1.7991724999695295
Validation loss: 2.416595385443982

Epoch: 5| Step: 1
Training loss: 1.351458771534384
Validation loss: 2.4757570096978996

Epoch: 5| Step: 2
Training loss: 1.4493873683176353
Validation loss: 2.5486838000394014

Epoch: 5| Step: 3
Training loss: 1.2455294775428243
Validation loss: 2.4994693439021227

Epoch: 5| Step: 4
Training loss: 0.7440253541430742
Validation loss: 2.49185502786297

Epoch: 5| Step: 5
Training loss: 1.3872456583823733
Validation loss: 2.4626216711161506

Epoch: 5| Step: 6
Training loss: 0.7775176730707852
Validation loss: 2.5427544671775792

Epoch: 5| Step: 7
Training loss: 1.2421936418873316
Validation loss: 2.38385532636891

Epoch: 5| Step: 8
Training loss: 1.1272019982522616
Validation loss: 2.441594087196123

Epoch: 5| Step: 9
Training loss: 0.9878737925237675
Validation loss: 2.5046832303726685

Epoch: 5| Step: 10
Training loss: 1.1430160856842189
Validation loss: 2.4554241570696678

Epoch: 399| Step: 0
Training loss: 1.5011799462940463
Validation loss: 2.5231748791151576

Epoch: 5| Step: 1
Training loss: 1.2378744425848924
Validation loss: 2.468323798129393

Epoch: 5| Step: 2
Training loss: 1.6095449117205332
Validation loss: 2.3884306360653853

Epoch: 5| Step: 3
Training loss: 1.1622272848369926
Validation loss: 2.4153876698420538

Epoch: 5| Step: 4
Training loss: 1.1095001257595078
Validation loss: 2.5002814257561554

Epoch: 5| Step: 5
Training loss: 0.9159624291694135
Validation loss: 2.4515392967261764

Epoch: 5| Step: 6
Training loss: 1.2077308775253186
Validation loss: 2.3920660960161313

Epoch: 5| Step: 7
Training loss: 0.9126304428717835
Validation loss: 2.472146514661889

Epoch: 5| Step: 8
Training loss: 1.5271653951719883
Validation loss: 2.4640066077579643

Epoch: 5| Step: 9
Training loss: 0.8598058834122203
Validation loss: 2.38897035276544

Epoch: 5| Step: 10
Training loss: 1.4569409217141354
Validation loss: 2.5222192077035355

Epoch: 400| Step: 0
Training loss: 1.0868184200956834
Validation loss: 2.4491044792555847

Epoch: 5| Step: 1
Training loss: 1.2303862044484926
Validation loss: 2.424877160296129

Epoch: 5| Step: 2
Training loss: 1.180609437548129
Validation loss: 2.4464927922055253

Epoch: 5| Step: 3
Training loss: 1.4887497532457585
Validation loss: 2.4798934397246724

Epoch: 5| Step: 4
Training loss: 0.8937754874163201
Validation loss: 2.432627268187506

Epoch: 5| Step: 5
Training loss: 0.9973653418492495
Validation loss: 2.431536528007362

Epoch: 5| Step: 6
Training loss: 1.8274157199655667
Validation loss: 2.449398060833564

Epoch: 5| Step: 7
Training loss: 1.0740952299368163
Validation loss: 2.467086423079828

Epoch: 5| Step: 8
Training loss: 1.2050573511048777
Validation loss: 2.4166590535260015

Epoch: 5| Step: 9
Training loss: 1.301636927057761
Validation loss: 2.444483655634961

Epoch: 5| Step: 10
Training loss: 0.9891483890309183
Validation loss: 2.442538431406657

Epoch: 401| Step: 0
Training loss: 1.325459891706422
Validation loss: 2.424204972312643

Epoch: 5| Step: 1
Training loss: 1.2752823367450838
Validation loss: 2.448256988711673

Epoch: 5| Step: 2
Training loss: 1.0927093459792243
Validation loss: 2.4277453159913396

Epoch: 5| Step: 3
Training loss: 1.0258275436333018
Validation loss: 2.4439485461140666

Epoch: 5| Step: 4
Training loss: 1.1169972291056554
Validation loss: 2.442943872733548

Epoch: 5| Step: 5
Training loss: 1.0464282434780103
Validation loss: 2.4419238110677544

Epoch: 5| Step: 6
Training loss: 1.1488326035314673
Validation loss: 2.426298025434998

Epoch: 5| Step: 7
Training loss: 1.665906502301678
Validation loss: 2.547657012916698

Epoch: 5| Step: 8
Training loss: 1.9018950197468039
Validation loss: 2.4650692877932188

Epoch: 5| Step: 9
Training loss: 0.9231045169404501
Validation loss: 2.4652628774585983

Epoch: 5| Step: 10
Training loss: 1.0683496115620201
Validation loss: 2.3695430574275447

Epoch: 402| Step: 0
Training loss: 1.1657574494001355
Validation loss: 2.4818839417872414

Epoch: 5| Step: 1
Training loss: 0.9573987916788573
Validation loss: 2.5055962551032116

Epoch: 5| Step: 2
Training loss: 0.9766162094605304
Validation loss: 2.4080592985442637

Epoch: 5| Step: 3
Training loss: 1.0119067867910605
Validation loss: 2.525343244638069

Epoch: 5| Step: 4
Training loss: 1.0610055511178387
Validation loss: 2.495691820439669

Epoch: 5| Step: 5
Training loss: 1.1362617858846202
Validation loss: 2.4504785275905743

Epoch: 5| Step: 6
Training loss: 1.2966567166019398
Validation loss: 2.4578715044070734

Epoch: 5| Step: 7
Training loss: 1.1909200207707056
Validation loss: 2.3494378523072137

Epoch: 5| Step: 8
Training loss: 1.3804248951809555
Validation loss: 2.429041811742285

Epoch: 5| Step: 9
Training loss: 1.8511324998862209
Validation loss: 2.5248297553642183

Epoch: 5| Step: 10
Training loss: 0.9404725315558579
Validation loss: 2.410506010176358

Epoch: 403| Step: 0
Training loss: 1.3944132779012837
Validation loss: 2.3597048745015234

Epoch: 5| Step: 1
Training loss: 1.0186576754620917
Validation loss: 2.4549626148901824

Epoch: 5| Step: 2
Training loss: 1.2110049321257674
Validation loss: 2.387752929679484

Epoch: 5| Step: 3
Training loss: 1.1131316502761737
Validation loss: 2.5266315824744607

Epoch: 5| Step: 4
Training loss: 1.460542676480409
Validation loss: 2.432083393600997

Epoch: 5| Step: 5
Training loss: 1.113574019635029
Validation loss: 2.4490556659515805

Epoch: 5| Step: 6
Training loss: 0.9962826418823999
Validation loss: 2.442417112110285

Epoch: 5| Step: 7
Training loss: 1.3523902783689534
Validation loss: 2.496276262344321

Epoch: 5| Step: 8
Training loss: 1.681965689083505
Validation loss: 2.5559035444442917

Epoch: 5| Step: 9
Training loss: 0.8510245277487521
Validation loss: 2.4159137888303386

Epoch: 5| Step: 10
Training loss: 0.5851466372913781
Validation loss: 2.4746279562299396

Epoch: 404| Step: 0
Training loss: 1.2907089353889762
Validation loss: 2.510644630644706

Epoch: 5| Step: 1
Training loss: 0.9434691497558281
Validation loss: 2.553220417651933

Epoch: 5| Step: 2
Training loss: 1.9670737260151439
Validation loss: 2.477247501655963

Epoch: 5| Step: 3
Training loss: 1.3163815278128783
Validation loss: 2.503002378913758

Epoch: 5| Step: 4
Training loss: 0.8941407663221068
Validation loss: 2.4545927571782156

Epoch: 5| Step: 5
Training loss: 1.3661285659138955
Validation loss: 2.4919306873196123

Epoch: 5| Step: 6
Training loss: 1.2726389247401133
Validation loss: 2.451942389222896

Epoch: 5| Step: 7
Training loss: 0.9410600460932811
Validation loss: 2.378500072413102

Epoch: 5| Step: 8
Training loss: 1.158225459740646
Validation loss: 2.5254825346622707

Epoch: 5| Step: 9
Training loss: 1.2496113172863637
Validation loss: 2.505621060102811

Epoch: 5| Step: 10
Training loss: 1.0618726898042494
Validation loss: 2.4997912653054324

Epoch: 405| Step: 0
Training loss: 1.078326441424916
Validation loss: 2.5260052932811625

Epoch: 5| Step: 1
Training loss: 1.1906590854841992
Validation loss: 2.491616343240649

Epoch: 5| Step: 2
Training loss: 1.0222673205491706
Validation loss: 2.530032257058619

Epoch: 5| Step: 3
Training loss: 1.9986225391467984
Validation loss: 2.4527856359390503

Epoch: 5| Step: 4
Training loss: 0.5959400893876742
Validation loss: 2.3991104789947877

Epoch: 5| Step: 5
Training loss: 1.201727811357348
Validation loss: 2.54957184829502

Epoch: 5| Step: 6
Training loss: 1.1781968557771383
Validation loss: 2.4039206446992574

Epoch: 5| Step: 7
Training loss: 1.3570228923393102
Validation loss: 2.468583698105045

Epoch: 5| Step: 8
Training loss: 1.1554696310683497
Validation loss: 2.426509846638489

Epoch: 5| Step: 9
Training loss: 0.7760640254202701
Validation loss: 2.4150764504202606

Epoch: 5| Step: 10
Training loss: 1.2426456590160608
Validation loss: 2.4722965758233078

Epoch: 406| Step: 0
Training loss: 1.3937077160908722
Validation loss: 2.4500207268526895

Epoch: 5| Step: 1
Training loss: 1.2785395353408378
Validation loss: 2.489634512599521

Epoch: 5| Step: 2
Training loss: 0.8826464944233843
Validation loss: 2.509915483910969

Epoch: 5| Step: 3
Training loss: 1.5436971369661505
Validation loss: 2.442608289565382

Epoch: 5| Step: 4
Training loss: 0.996092972100646
Validation loss: 2.5035471413997423

Epoch: 5| Step: 5
Training loss: 1.8467970416918866
Validation loss: 2.455380810976587

Epoch: 5| Step: 6
Training loss: 0.976062371934422
Validation loss: 2.544327449812057

Epoch: 5| Step: 7
Training loss: 1.2861595064143254
Validation loss: 2.5056437229005417

Epoch: 5| Step: 8
Training loss: 1.0109203236932267
Validation loss: 2.4074756881704

Epoch: 5| Step: 9
Training loss: 0.800768224098516
Validation loss: 2.5005842961697033

Epoch: 5| Step: 10
Training loss: 1.1526018791101333
Validation loss: 2.4364430060750237

Epoch: 407| Step: 0
Training loss: 1.2055423281471824
Validation loss: 2.522406467978732

Epoch: 5| Step: 1
Training loss: 1.3335574180333492
Validation loss: 2.399274735435602

Epoch: 5| Step: 2
Training loss: 0.8829168072409801
Validation loss: 2.4160334408481767

Epoch: 5| Step: 3
Training loss: 1.9816263340833808
Validation loss: 2.42871586271975

Epoch: 5| Step: 4
Training loss: 1.0550024056972176
Validation loss: 2.4724119044579074

Epoch: 5| Step: 5
Training loss: 1.0138563748956881
Validation loss: 2.4457247906533652

Epoch: 5| Step: 6
Training loss: 1.0504518013726956
Validation loss: 2.499959762823692

Epoch: 5| Step: 7
Training loss: 1.364266419434755
Validation loss: 2.4976111540388426

Epoch: 5| Step: 8
Training loss: 0.9451390256997623
Validation loss: 2.460508972766557

Epoch: 5| Step: 9
Training loss: 1.203254841325358
Validation loss: 2.5053382587253576

Epoch: 5| Step: 10
Training loss: 1.4180764401739392
Validation loss: 2.49021279190751

Epoch: 408| Step: 0
Training loss: 1.1331126900544477
Validation loss: 2.4994383252775636

Epoch: 5| Step: 1
Training loss: 1.737342289415307
Validation loss: 2.416149773303259

Epoch: 5| Step: 2
Training loss: 1.1206028092629117
Validation loss: 2.468762060374527

Epoch: 5| Step: 3
Training loss: 1.050320832872917
Validation loss: 2.430117377548805

Epoch: 5| Step: 4
Training loss: 0.8579171386156703
Validation loss: 2.520066403873055

Epoch: 5| Step: 5
Training loss: 1.23587423131299
Validation loss: 2.4853413640365916

Epoch: 5| Step: 6
Training loss: 1.2291311592964926
Validation loss: 2.4351360294478526

Epoch: 5| Step: 7
Training loss: 1.0061339364732556
Validation loss: 2.4608950531673597

Epoch: 5| Step: 8
Training loss: 1.2437716285703577
Validation loss: 2.433387170427277

Epoch: 5| Step: 9
Training loss: 1.3053946491717991
Validation loss: 2.4691634259698563

Epoch: 5| Step: 10
Training loss: 1.2530566513181511
Validation loss: 2.512697530577239

Epoch: 409| Step: 0
Training loss: 1.3478893133785115
Validation loss: 2.4950791320345322

Epoch: 5| Step: 1
Training loss: 1.4519737359185818
Validation loss: 2.4899550337350638

Epoch: 5| Step: 2
Training loss: 1.7500814010216856
Validation loss: 2.444204386088305

Epoch: 5| Step: 3
Training loss: 0.827841800273402
Validation loss: 2.418254621425122

Epoch: 5| Step: 4
Training loss: 0.92562295067333
Validation loss: 2.4200712899077623

Epoch: 5| Step: 5
Training loss: 1.0519138174436717
Validation loss: 2.5096251143116355

Epoch: 5| Step: 6
Training loss: 1.2539784063095347
Validation loss: 2.418912109248863

Epoch: 5| Step: 7
Training loss: 1.003740348912037
Validation loss: 2.518837319480897

Epoch: 5| Step: 8
Training loss: 1.1670576643830584
Validation loss: 2.3620794375627328

Epoch: 5| Step: 9
Training loss: 1.3789348653358307
Validation loss: 2.5498597500809845

Epoch: 5| Step: 10
Training loss: 1.1915246623244644
Validation loss: 2.489465289965062

Epoch: 410| Step: 0
Training loss: 1.2390768581871727
Validation loss: 2.5142934907537717

Epoch: 5| Step: 1
Training loss: 0.9784643650905145
Validation loss: 2.4944109594842807

Epoch: 5| Step: 2
Training loss: 0.7904876830983054
Validation loss: 2.424794846536074

Epoch: 5| Step: 3
Training loss: 1.3420864720008308
Validation loss: 2.4423409375098277

Epoch: 5| Step: 4
Training loss: 1.2566957432615071
Validation loss: 2.439812699751458

Epoch: 5| Step: 5
Training loss: 1.425502467661434
Validation loss: 2.4570701775109116

Epoch: 5| Step: 6
Training loss: 0.8872712216541254
Validation loss: 2.4220333517322055

Epoch: 5| Step: 7
Training loss: 1.0554181429168301
Validation loss: 2.4383314159315317

Epoch: 5| Step: 8
Training loss: 0.8786662473419512
Validation loss: 2.5017647134298393

Epoch: 5| Step: 9
Training loss: 1.2047361015282814
Validation loss: 2.3721232870207793

Epoch: 5| Step: 10
Training loss: 2.055884879024899
Validation loss: 2.4822921106483045

Epoch: 411| Step: 0
Training loss: 1.0002337420991245
Validation loss: 2.4544680641617513

Epoch: 5| Step: 1
Training loss: 1.001898037175012
Validation loss: 2.37837403571835

Epoch: 5| Step: 2
Training loss: 1.1475422801952944
Validation loss: 2.4701187806590905

Epoch: 5| Step: 3
Training loss: 1.094036991069344
Validation loss: 2.4808845314305135

Epoch: 5| Step: 4
Training loss: 0.9165781729782658
Validation loss: 2.458312769894728

Epoch: 5| Step: 5
Training loss: 1.109276565697907
Validation loss: 2.4432309172840347

Epoch: 5| Step: 6
Training loss: 1.2336077176560163
Validation loss: 2.467645583207715

Epoch: 5| Step: 7
Training loss: 1.3024632573574013
Validation loss: 2.524168938103316

Epoch: 5| Step: 8
Training loss: 2.026487901148432
Validation loss: 2.453234965112658

Epoch: 5| Step: 9
Training loss: 1.154945359196747
Validation loss: 2.4356570679869707

Epoch: 5| Step: 10
Training loss: 1.089439617960932
Validation loss: 2.3282539974465624

Epoch: 412| Step: 0
Training loss: 1.0460244324604173
Validation loss: 2.3905754253113964

Epoch: 5| Step: 1
Training loss: 1.1089086492629943
Validation loss: 2.472226904443364

Epoch: 5| Step: 2
Training loss: 0.9149635959637599
Validation loss: 2.4085637466887433

Epoch: 5| Step: 3
Training loss: 1.239162047573597
Validation loss: 2.5023706322562993

Epoch: 5| Step: 4
Training loss: 1.494756275072594
Validation loss: 2.4689240898536444

Epoch: 5| Step: 5
Training loss: 1.786043376571007
Validation loss: 2.447375583128666

Epoch: 5| Step: 6
Training loss: 1.0888369158313096
Validation loss: 2.4552477912433597

Epoch: 5| Step: 7
Training loss: 1.380184024620716
Validation loss: 2.4534809707821186

Epoch: 5| Step: 8
Training loss: 0.9685430921047785
Validation loss: 2.472397321471891

Epoch: 5| Step: 9
Training loss: 1.2242576179103795
Validation loss: 2.515485716510116

Epoch: 5| Step: 10
Training loss: 1.3591025945521222
Validation loss: 2.492392977789751

Epoch: 413| Step: 0
Training loss: 1.2655136153575008
Validation loss: 2.4617233081738887

Epoch: 5| Step: 1
Training loss: 1.8492803875183872
Validation loss: 2.4018422542828466

Epoch: 5| Step: 2
Training loss: 1.2133138658373113
Validation loss: 2.498649954051631

Epoch: 5| Step: 3
Training loss: 0.9805348286645937
Validation loss: 2.401654081262171

Epoch: 5| Step: 4
Training loss: 1.0010321773803061
Validation loss: 2.468842135654958

Epoch: 5| Step: 5
Training loss: 1.1899090975013458
Validation loss: 2.4347647045905667

Epoch: 5| Step: 6
Training loss: 1.030611591980597
Validation loss: 2.48934430817194

Epoch: 5| Step: 7
Training loss: 1.126524686773971
Validation loss: 2.4697672486359448

Epoch: 5| Step: 8
Training loss: 0.8489810417898285
Validation loss: 2.4612058473361698

Epoch: 5| Step: 9
Training loss: 1.1486617926768907
Validation loss: 2.5139434815852715

Epoch: 5| Step: 10
Training loss: 1.1060074211582143
Validation loss: 2.5226176743692488

Epoch: 414| Step: 0
Training loss: 1.4327968284556922
Validation loss: 2.5207160190860622

Epoch: 5| Step: 1
Training loss: 2.0647805061714846
Validation loss: 2.4397844705820866

Epoch: 5| Step: 2
Training loss: 0.9043033673772239
Validation loss: 2.3930465869796884

Epoch: 5| Step: 3
Training loss: 1.0106243562430912
Validation loss: 2.427751553633188

Epoch: 5| Step: 4
Training loss: 1.1915565270875206
Validation loss: 2.435499737304931

Epoch: 5| Step: 5
Training loss: 0.7568941352372087
Validation loss: 2.4575935016650954

Epoch: 5| Step: 6
Training loss: 1.123131206497425
Validation loss: 2.481955181182713

Epoch: 5| Step: 7
Training loss: 1.0198291913234308
Validation loss: 2.437887200459405

Epoch: 5| Step: 8
Training loss: 1.1754189373446526
Validation loss: 2.403111700192961

Epoch: 5| Step: 9
Training loss: 0.8929584452517607
Validation loss: 2.486288602296857

Epoch: 5| Step: 10
Training loss: 1.4084624370485863
Validation loss: 2.4621893315379584

Epoch: 415| Step: 0
Training loss: 0.9894609007471497
Validation loss: 2.3455501870375643

Epoch: 5| Step: 1
Training loss: 1.0701350044038611
Validation loss: 2.4047237521199913

Epoch: 5| Step: 2
Training loss: 0.9918824575488775
Validation loss: 2.4829875001871775

Epoch: 5| Step: 3
Training loss: 0.9781416370573502
Validation loss: 2.44240246601782

Epoch: 5| Step: 4
Training loss: 1.258678256796422
Validation loss: 2.39583191588486

Epoch: 5| Step: 5
Training loss: 1.7111142559284085
Validation loss: 2.427666822975042

Epoch: 5| Step: 6
Training loss: 1.5733928927904874
Validation loss: 2.4342281236533094

Epoch: 5| Step: 7
Training loss: 0.9816168943512782
Validation loss: 2.4724905921502978

Epoch: 5| Step: 8
Training loss: 1.1043116036543754
Validation loss: 2.5028115029849842

Epoch: 5| Step: 9
Training loss: 1.0816461311550107
Validation loss: 2.4605643087585984

Epoch: 5| Step: 10
Training loss: 1.255113774875806
Validation loss: 2.4551248930608565

Epoch: 416| Step: 0
Training loss: 0.9129051315075641
Validation loss: 2.477229834212977

Epoch: 5| Step: 1
Training loss: 0.8247515867945915
Validation loss: 2.4882855421666012

Epoch: 5| Step: 2
Training loss: 1.5922355936590293
Validation loss: 2.427221898357313

Epoch: 5| Step: 3
Training loss: 1.8997026160558559
Validation loss: 2.4117873623013097

Epoch: 5| Step: 4
Training loss: 0.8564726630512011
Validation loss: 2.4011557555516365

Epoch: 5| Step: 5
Training loss: 1.2375250110603333
Validation loss: 2.4797406282327987

Epoch: 5| Step: 6
Training loss: 1.452224370308996
Validation loss: 2.486077039644839

Epoch: 5| Step: 7
Training loss: 0.9758792165257375
Validation loss: 2.445136666131308

Epoch: 5| Step: 8
Training loss: 1.1387162109956392
Validation loss: 2.4828802725204477

Epoch: 5| Step: 9
Training loss: 0.8914805201650284
Validation loss: 2.498961984833771

Epoch: 5| Step: 10
Training loss: 1.1710349059892395
Validation loss: 2.487346969661188

Epoch: 417| Step: 0
Training loss: 1.1410729560696846
Validation loss: 2.4124375507548574

Epoch: 5| Step: 1
Training loss: 0.9229707186839204
Validation loss: 2.431715068986393

Epoch: 5| Step: 2
Training loss: 1.2513046132305927
Validation loss: 2.4513008897224435

Epoch: 5| Step: 3
Training loss: 1.351619564902391
Validation loss: 2.4693448601481833

Epoch: 5| Step: 4
Training loss: 1.0963595730730558
Validation loss: 2.4730759986439463

Epoch: 5| Step: 5
Training loss: 1.6517366055880405
Validation loss: 2.4295097945281627

Epoch: 5| Step: 6
Training loss: 1.4080840125216143
Validation loss: 2.4560922203310414

Epoch: 5| Step: 7
Training loss: 1.166424703483986
Validation loss: 2.472730339643365

Epoch: 5| Step: 8
Training loss: 1.1788232934683258
Validation loss: 2.348291912422134

Epoch: 5| Step: 9
Training loss: 0.8749024132397387
Validation loss: 2.430095232038498

Epoch: 5| Step: 10
Training loss: 0.9210838220269965
Validation loss: 2.4032992683954664

Epoch: 418| Step: 0
Training loss: 0.9496249675843621
Validation loss: 2.4579648634582996

Epoch: 5| Step: 1
Training loss: 0.920514573870262
Validation loss: 2.3260207923358944

Epoch: 5| Step: 2
Training loss: 1.0954097144156694
Validation loss: 2.4121364820987448

Epoch: 5| Step: 3
Training loss: 1.0909974476044026
Validation loss: 2.4952102040481354

Epoch: 5| Step: 4
Training loss: 1.7200654977703242
Validation loss: 2.4838235214255415

Epoch: 5| Step: 5
Training loss: 1.127516369415345
Validation loss: 2.4948808433729015

Epoch: 5| Step: 6
Training loss: 0.8954807223316915
Validation loss: 2.5187393871008363

Epoch: 5| Step: 7
Training loss: 1.3137067061385574
Validation loss: 2.5315381454156496

Epoch: 5| Step: 8
Training loss: 1.1183370797842598
Validation loss: 2.4595507893275683

Epoch: 5| Step: 9
Training loss: 1.4784418488291187
Validation loss: 2.453010353140608

Epoch: 5| Step: 10
Training loss: 1.0982363651018856
Validation loss: 2.4539314931464298

Epoch: 419| Step: 0
Training loss: 1.2991144538714872
Validation loss: 2.560920337486178

Epoch: 5| Step: 1
Training loss: 0.8595611023967461
Validation loss: 2.416680154207617

Epoch: 5| Step: 2
Training loss: 1.194350210558367
Validation loss: 2.4936271431406323

Epoch: 5| Step: 3
Training loss: 0.7496323479118465
Validation loss: 2.447909625132078

Epoch: 5| Step: 4
Training loss: 1.366113644258387
Validation loss: 2.438028907134662

Epoch: 5| Step: 5
Training loss: 1.646278232688642
Validation loss: 2.4558549870780655

Epoch: 5| Step: 6
Training loss: 1.1454388661949098
Validation loss: 2.4601055102894684

Epoch: 5| Step: 7
Training loss: 1.193132194709167
Validation loss: 2.528815029686632

Epoch: 5| Step: 8
Training loss: 1.274424398679947
Validation loss: 2.4003346852005367

Epoch: 5| Step: 9
Training loss: 0.9305929054685045
Validation loss: 2.3615783734139244

Epoch: 5| Step: 10
Training loss: 1.524096302489073
Validation loss: 2.441494042702826

Epoch: 420| Step: 0
Training loss: 1.0121114550458352
Validation loss: 2.423115060653064

Epoch: 5| Step: 1
Training loss: 1.7085895888875728
Validation loss: 2.4151404513823387

Epoch: 5| Step: 2
Training loss: 1.0350130953858696
Validation loss: 2.442896090699634

Epoch: 5| Step: 3
Training loss: 1.291463846259615
Validation loss: 2.541846603998669

Epoch: 5| Step: 4
Training loss: 0.768145092172953
Validation loss: 2.4493730151077537

Epoch: 5| Step: 5
Training loss: 1.6964674149275278
Validation loss: 2.4088000228548307

Epoch: 5| Step: 6
Training loss: 1.226638159878487
Validation loss: 2.3766860514599886

Epoch: 5| Step: 7
Training loss: 1.0704862356142877
Validation loss: 2.4826874840059245

Epoch: 5| Step: 8
Training loss: 1.241243783679774
Validation loss: 2.419273864354941

Epoch: 5| Step: 9
Training loss: 0.9266208430893872
Validation loss: 2.5379751366283148

Epoch: 5| Step: 10
Training loss: 1.0832323919855296
Validation loss: 2.483384214272147

Epoch: 421| Step: 0
Training loss: 1.4253352055396074
Validation loss: 2.417819163808635

Epoch: 5| Step: 1
Training loss: 0.9378085264524069
Validation loss: 2.455744164250257

Epoch: 5| Step: 2
Training loss: 1.4047289357422954
Validation loss: 2.527344695384903

Epoch: 5| Step: 3
Training loss: 0.9833001823548492
Validation loss: 2.5032613185836423

Epoch: 5| Step: 4
Training loss: 0.7950210696853205
Validation loss: 2.427345607810497

Epoch: 5| Step: 5
Training loss: 1.1733168823179856
Validation loss: 2.489304009466955

Epoch: 5| Step: 6
Training loss: 1.1210496740947855
Validation loss: 2.3753737628872496

Epoch: 5| Step: 7
Training loss: 1.2637089955274086
Validation loss: 2.483932332883095

Epoch: 5| Step: 8
Training loss: 1.7915886115289428
Validation loss: 2.4283862948309545

Epoch: 5| Step: 9
Training loss: 1.1236893648755586
Validation loss: 2.498089134921475

Epoch: 5| Step: 10
Training loss: 1.1224469780240587
Validation loss: 2.47917783084409

Epoch: 422| Step: 0
Training loss: 1.692348931133548
Validation loss: 2.418019728189709

Epoch: 5| Step: 1
Training loss: 1.1706396076128063
Validation loss: 2.453751974490305

Epoch: 5| Step: 2
Training loss: 1.24940447926629
Validation loss: 2.4451709412660207

Epoch: 5| Step: 3
Training loss: 1.186782369107517
Validation loss: 2.357020098708896

Epoch: 5| Step: 4
Training loss: 1.3342085687624354
Validation loss: 2.4437874421265615

Epoch: 5| Step: 5
Training loss: 0.676590495598544
Validation loss: 2.4423313550961225

Epoch: 5| Step: 6
Training loss: 0.9481099249610091
Validation loss: 2.3835691819017

Epoch: 5| Step: 7
Training loss: 1.4772357515896155
Validation loss: 2.4404300331103297

Epoch: 5| Step: 8
Training loss: 1.2691238923524013
Validation loss: 2.4304974888800928

Epoch: 5| Step: 9
Training loss: 1.2002697045509063
Validation loss: 2.450382288685917

Epoch: 5| Step: 10
Training loss: 1.169172910173802
Validation loss: 2.4326024428846047

Epoch: 423| Step: 0
Training loss: 1.0236071962799016
Validation loss: 2.4192977461009

Epoch: 5| Step: 1
Training loss: 1.2620628997737116
Validation loss: 2.4729001297668955

Epoch: 5| Step: 2
Training loss: 1.4554351163900232
Validation loss: 2.3767281221367926

Epoch: 5| Step: 3
Training loss: 0.9984235855112005
Validation loss: 2.4266875626210775

Epoch: 5| Step: 4
Training loss: 1.9267227935315483
Validation loss: 2.4161076314608065

Epoch: 5| Step: 5
Training loss: 1.0242901809889131
Validation loss: 2.434359607587054

Epoch: 5| Step: 6
Training loss: 1.1463268373251154
Validation loss: 2.4595255066673642

Epoch: 5| Step: 7
Training loss: 0.9658493485054133
Validation loss: 2.504779111611435

Epoch: 5| Step: 8
Training loss: 1.023262707875308
Validation loss: 2.5292789913597944

Epoch: 5| Step: 9
Training loss: 1.333203602479748
Validation loss: 2.4233773135946564

Epoch: 5| Step: 10
Training loss: 1.0096420714236363
Validation loss: 2.4118716250921204

Epoch: 424| Step: 0
Training loss: 0.9503456616221415
Validation loss: 2.460005856747195

Epoch: 5| Step: 1
Training loss: 1.296764966594107
Validation loss: 2.405151962590134

Epoch: 5| Step: 2
Training loss: 1.0243535492136595
Validation loss: 2.499012748047411

Epoch: 5| Step: 3
Training loss: 0.9324318906440311
Validation loss: 2.473824869300388

Epoch: 5| Step: 4
Training loss: 1.1423904134334777
Validation loss: 2.500255426053515

Epoch: 5| Step: 5
Training loss: 1.3006425846639735
Validation loss: 2.446182858786956

Epoch: 5| Step: 6
Training loss: 0.8495138882000765
Validation loss: 2.4772434345952594

Epoch: 5| Step: 7
Training loss: 1.0567114166406915
Validation loss: 2.44461569119423

Epoch: 5| Step: 8
Training loss: 1.812293007968515
Validation loss: 2.3862475524249316

Epoch: 5| Step: 9
Training loss: 1.173148264585674
Validation loss: 2.4888820895430768

Epoch: 5| Step: 10
Training loss: 1.2171041673137133
Validation loss: 2.4165462936688575

Epoch: 425| Step: 0
Training loss: 1.0532905086330537
Validation loss: 2.4452044998385474

Epoch: 5| Step: 1
Training loss: 0.9744586713393429
Validation loss: 2.4320970672492472

Epoch: 5| Step: 2
Training loss: 1.7478932915247225
Validation loss: 2.4418566494825606

Epoch: 5| Step: 3
Training loss: 1.3266864390712907
Validation loss: 2.4245095199817865

Epoch: 5| Step: 4
Training loss: 1.0097350479307199
Validation loss: 2.4592566778377174

Epoch: 5| Step: 5
Training loss: 0.9971116792502316
Validation loss: 2.472230683182006

Epoch: 5| Step: 6
Training loss: 1.3299968319331705
Validation loss: 2.475085715823949

Epoch: 5| Step: 7
Training loss: 1.2976099252900946
Validation loss: 2.4143057957874374

Epoch: 5| Step: 8
Training loss: 1.0245721365953027
Validation loss: 2.4625057965173913

Epoch: 5| Step: 9
Training loss: 0.9835568009784883
Validation loss: 2.44042398807396

Epoch: 5| Step: 10
Training loss: 1.2125647163817193
Validation loss: 2.4261266569366646

Epoch: 426| Step: 0
Training loss: 0.7492102597643613
Validation loss: 2.445035292126222

Epoch: 5| Step: 1
Training loss: 1.008424558269819
Validation loss: 2.4349728944823816

Epoch: 5| Step: 2
Training loss: 1.4852305305924418
Validation loss: 2.399430970573829

Epoch: 5| Step: 3
Training loss: 1.2983705101681084
Validation loss: 2.4461011414591716

Epoch: 5| Step: 4
Training loss: 1.7522284079903254
Validation loss: 2.435159018173665

Epoch: 5| Step: 5
Training loss: 1.2630122023874182
Validation loss: 2.4618644175836124

Epoch: 5| Step: 6
Training loss: 0.7310943372625841
Validation loss: 2.4971994500763697

Epoch: 5| Step: 7
Training loss: 0.8223796412053888
Validation loss: 2.511307479473437

Epoch: 5| Step: 8
Training loss: 1.2571602308865573
Validation loss: 2.421450438187523

Epoch: 5| Step: 9
Training loss: 1.0833173469439867
Validation loss: 2.3901935648940107

Epoch: 5| Step: 10
Training loss: 1.1490492975235411
Validation loss: 2.491690293780103

Epoch: 427| Step: 0
Training loss: 1.01350792531028
Validation loss: 2.4421316488909386

Epoch: 5| Step: 1
Training loss: 1.2792666832076636
Validation loss: 2.3760882562957315

Epoch: 5| Step: 2
Training loss: 1.026504870325604
Validation loss: 2.473260022988443

Epoch: 5| Step: 3
Training loss: 1.1852198342936333
Validation loss: 2.4888064131194

Epoch: 5| Step: 4
Training loss: 1.0366084438995011
Validation loss: 2.4051726494008867

Epoch: 5| Step: 5
Training loss: 0.9199535907048522
Validation loss: 2.512692055779549

Epoch: 5| Step: 6
Training loss: 1.305679172836438
Validation loss: 2.5125217913712823

Epoch: 5| Step: 7
Training loss: 1.0200077273506218
Validation loss: 2.4917312581459865

Epoch: 5| Step: 8
Training loss: 1.0865145460577903
Validation loss: 2.4338416224476447

Epoch: 5| Step: 9
Training loss: 1.647357677396139
Validation loss: 2.4649508470395713

Epoch: 5| Step: 10
Training loss: 0.9479249842072719
Validation loss: 2.5088301681659675

Epoch: 428| Step: 0
Training loss: 1.2504791771834007
Validation loss: 2.466958850654633

Epoch: 5| Step: 1
Training loss: 1.1356826727272609
Validation loss: 2.4502068563064703

Epoch: 5| Step: 2
Training loss: 0.8812166491751664
Validation loss: 2.4276507905770712

Epoch: 5| Step: 3
Training loss: 0.8485352489722947
Validation loss: 2.4227754610595675

Epoch: 5| Step: 4
Training loss: 0.9986475799620609
Validation loss: 2.435728123265446

Epoch: 5| Step: 5
Training loss: 0.8083072836765193
Validation loss: 2.447449773712416

Epoch: 5| Step: 6
Training loss: 1.8796645317672094
Validation loss: 2.369154717652062

Epoch: 5| Step: 7
Training loss: 1.2057470508454742
Validation loss: 2.490303846271304

Epoch: 5| Step: 8
Training loss: 0.9488253936162891
Validation loss: 2.4524552054189

Epoch: 5| Step: 9
Training loss: 0.856482962777935
Validation loss: 2.3767999295380204

Epoch: 5| Step: 10
Training loss: 1.2952537053917956
Validation loss: 2.4644280262437697

Epoch: 429| Step: 0
Training loss: 0.9367305458986909
Validation loss: 2.4493615475714714

Epoch: 5| Step: 1
Training loss: 1.1327835079297843
Validation loss: 2.4346193367294284

Epoch: 5| Step: 2
Training loss: 0.9498153507074167
Validation loss: 2.4658826170865487

Epoch: 5| Step: 3
Training loss: 1.2062398050302352
Validation loss: 2.4614697213063734

Epoch: 5| Step: 4
Training loss: 1.0735529830536548
Validation loss: 2.4746453687545555

Epoch: 5| Step: 5
Training loss: 1.3359772079545182
Validation loss: 2.483646060153873

Epoch: 5| Step: 6
Training loss: 0.9498724864409902
Validation loss: 2.479592306843085

Epoch: 5| Step: 7
Training loss: 1.7450047453020605
Validation loss: 2.5239949696543373

Epoch: 5| Step: 8
Training loss: 1.0780112717946848
Validation loss: 2.4575029252980163

Epoch: 5| Step: 9
Training loss: 1.125692472326073
Validation loss: 2.522775767271615

Epoch: 5| Step: 10
Training loss: 0.8315211420336198
Validation loss: 2.4263023643829533

Epoch: 430| Step: 0
Training loss: 0.8441021855334488
Validation loss: 2.379834529170417

Epoch: 5| Step: 1
Training loss: 1.1734757743516107
Validation loss: 2.4497582086718936

Epoch: 5| Step: 2
Training loss: 1.0646901278047685
Validation loss: 2.5096502191437366

Epoch: 5| Step: 3
Training loss: 0.9931595013569059
Validation loss: 2.438093722079153

Epoch: 5| Step: 4
Training loss: 1.2537092012440023
Validation loss: 2.583830665154594

Epoch: 5| Step: 5
Training loss: 1.3796037849439604
Validation loss: 2.398709817930798

Epoch: 5| Step: 6
Training loss: 0.8225877724283858
Validation loss: 2.5034992311530306

Epoch: 5| Step: 7
Training loss: 1.6921508418768194
Validation loss: 2.5249999218622627

Epoch: 5| Step: 8
Training loss: 1.1503715578322231
Validation loss: 2.4320090104329086

Epoch: 5| Step: 9
Training loss: 0.8750165869639305
Validation loss: 2.4328568806147692

Epoch: 5| Step: 10
Training loss: 1.1008952940647705
Validation loss: 2.5231294303264065

Epoch: 431| Step: 0
Training loss: 0.9056144985435188
Validation loss: 2.4430661422955704

Epoch: 5| Step: 1
Training loss: 1.0032576309891086
Validation loss: 2.5002234020705805

Epoch: 5| Step: 2
Training loss: 1.2202454708510027
Validation loss: 2.455594820436436

Epoch: 5| Step: 3
Training loss: 1.1384491743588145
Validation loss: 2.454069013543649

Epoch: 5| Step: 4
Training loss: 1.6260362402242778
Validation loss: 2.4457851077570707

Epoch: 5| Step: 5
Training loss: 0.8684891219855155
Validation loss: 2.501090397485838

Epoch: 5| Step: 6
Training loss: 1.044036204678596
Validation loss: 2.4583305920612895

Epoch: 5| Step: 7
Training loss: 1.0834454820733355
Validation loss: 2.4703093002527026

Epoch: 5| Step: 8
Training loss: 0.9301295151305501
Validation loss: 2.393548902698058

Epoch: 5| Step: 9
Training loss: 1.5658143559081226
Validation loss: 2.4001186836286825

Epoch: 5| Step: 10
Training loss: 1.1456901229604457
Validation loss: 2.460528205396093

Epoch: 432| Step: 0
Training loss: 0.9174324579350469
Validation loss: 2.448846590552282

Epoch: 5| Step: 1
Training loss: 0.9549403803125497
Validation loss: 2.4212960913205013

Epoch: 5| Step: 2
Training loss: 0.9369066586021982
Validation loss: 2.483266852499907

Epoch: 5| Step: 3
Training loss: 1.233401433679803
Validation loss: 2.4334486198114074

Epoch: 5| Step: 4
Training loss: 1.2645214591477447
Validation loss: 2.432597705745616

Epoch: 5| Step: 5
Training loss: 1.0684548846133382
Validation loss: 2.4377630768597705

Epoch: 5| Step: 6
Training loss: 0.920050933920672
Validation loss: 2.4688788110792688

Epoch: 5| Step: 7
Training loss: 1.0085382731432533
Validation loss: 2.3845948475135255

Epoch: 5| Step: 8
Training loss: 1.8902637987868005
Validation loss: 2.4574835015589995

Epoch: 5| Step: 9
Training loss: 1.2425709258623188
Validation loss: 2.4427288588144656

Epoch: 5| Step: 10
Training loss: 1.0671786351205745
Validation loss: 2.3718779519719213

Epoch: 433| Step: 0
Training loss: 1.3782906603559493
Validation loss: 2.5219259044460656

Epoch: 5| Step: 1
Training loss: 0.7695992918963952
Validation loss: 2.391545724235143

Epoch: 5| Step: 2
Training loss: 0.9382868643536331
Validation loss: 2.441972651451886

Epoch: 5| Step: 3
Training loss: 1.183015436579646
Validation loss: 2.4687017558357898

Epoch: 5| Step: 4
Training loss: 2.1279086234042346
Validation loss: 2.4550438294569674

Epoch: 5| Step: 5
Training loss: 0.813900950211897
Validation loss: 2.4342404119360483

Epoch: 5| Step: 6
Training loss: 0.8545463152499264
Validation loss: 2.4484454583757107

Epoch: 5| Step: 7
Training loss: 1.2220282846289718
Validation loss: 2.519616671061153

Epoch: 5| Step: 8
Training loss: 1.0828465443993676
Validation loss: 2.509440718487916

Epoch: 5| Step: 9
Training loss: 1.105344623835488
Validation loss: 2.4259757899763996

Epoch: 5| Step: 10
Training loss: 1.10652977805355
Validation loss: 2.417396267312921

Epoch: 434| Step: 0
Training loss: 1.2029087318147254
Validation loss: 2.475964044142333

Epoch: 5| Step: 1
Training loss: 1.2506608169970597
Validation loss: 2.4158182157604844

Epoch: 5| Step: 2
Training loss: 1.1506912020111495
Validation loss: 2.4160973348906487

Epoch: 5| Step: 3
Training loss: 0.8479614411575579
Validation loss: 2.5008646443990425

Epoch: 5| Step: 4
Training loss: 0.8063929734137729
Validation loss: 2.4694558636743418

Epoch: 5| Step: 5
Training loss: 0.9732445465922831
Validation loss: 2.524699000536244

Epoch: 5| Step: 6
Training loss: 1.8336953614876859
Validation loss: 2.4651735937078842

Epoch: 5| Step: 7
Training loss: 0.8499769796732299
Validation loss: 2.4844481548431285

Epoch: 5| Step: 8
Training loss: 0.8994550830213734
Validation loss: 2.4588605190499946

Epoch: 5| Step: 9
Training loss: 1.0374069792629477
Validation loss: 2.4525083654241215

Epoch: 5| Step: 10
Training loss: 1.2359900230696386
Validation loss: 2.4582415571091905

Epoch: 435| Step: 0
Training loss: 1.0767393744772324
Validation loss: 2.421208383392254

Epoch: 5| Step: 1
Training loss: 1.376976110388273
Validation loss: 2.4930383381522443

Epoch: 5| Step: 2
Training loss: 0.9553165879191745
Validation loss: 2.56445768754994

Epoch: 5| Step: 3
Training loss: 0.9534835766286558
Validation loss: 2.463398775231382

Epoch: 5| Step: 4
Training loss: 1.0685231642900923
Validation loss: 2.4927820049575162

Epoch: 5| Step: 5
Training loss: 0.7583447583005134
Validation loss: 2.424281193846438

Epoch: 5| Step: 6
Training loss: 1.1409974208739115
Validation loss: 2.458853150630238

Epoch: 5| Step: 7
Training loss: 1.6808793918021472
Validation loss: 2.463219202918857

Epoch: 5| Step: 8
Training loss: 1.1892363753245014
Validation loss: 2.4374500592429396

Epoch: 5| Step: 9
Training loss: 1.2191483262395437
Validation loss: 2.4385076132983787

Epoch: 5| Step: 10
Training loss: 1.1850902803048993
Validation loss: 2.4861803729371954

Epoch: 436| Step: 0
Training loss: 1.052929578811903
Validation loss: 2.465386133866429

Epoch: 5| Step: 1
Training loss: 0.8665320178729476
Validation loss: 2.421488957859744

Epoch: 5| Step: 2
Training loss: 1.0906693807496652
Validation loss: 2.4720052221609237

Epoch: 5| Step: 3
Training loss: 0.9703045953744992
Validation loss: 2.4270287485193283

Epoch: 5| Step: 4
Training loss: 1.012601607134073
Validation loss: 2.4700819596611487

Epoch: 5| Step: 5
Training loss: 1.2568200976626662
Validation loss: 2.361412794378624

Epoch: 5| Step: 6
Training loss: 1.1040809466119084
Validation loss: 2.4241125714939913

Epoch: 5| Step: 7
Training loss: 1.2058033051845842
Validation loss: 2.4676571004425867

Epoch: 5| Step: 8
Training loss: 1.2820265672820197
Validation loss: 2.4137951173525916

Epoch: 5| Step: 9
Training loss: 0.9242050982488413
Validation loss: 2.493735887153063

Epoch: 5| Step: 10
Training loss: 2.013396457962523
Validation loss: 2.489708459192877

Epoch: 437| Step: 0
Training loss: 1.2527335794682442
Validation loss: 2.453537265132878

Epoch: 5| Step: 1
Training loss: 1.1192624756418321
Validation loss: 2.5197707302543617

Epoch: 5| Step: 2
Training loss: 0.9447103742277595
Validation loss: 2.5648868168670114

Epoch: 5| Step: 3
Training loss: 1.8830240217875682
Validation loss: 2.418878875866249

Epoch: 5| Step: 4
Training loss: 1.1798008239074562
Validation loss: 2.561150986854226

Epoch: 5| Step: 5
Training loss: 1.0366974495695307
Validation loss: 2.4951813342740246

Epoch: 5| Step: 6
Training loss: 1.0563998415148441
Validation loss: 2.4298067111461057

Epoch: 5| Step: 7
Training loss: 0.988062898541074
Validation loss: 2.4662173348600316

Epoch: 5| Step: 8
Training loss: 1.0003513076724107
Validation loss: 2.4727747229018218

Epoch: 5| Step: 9
Training loss: 0.8414131936412836
Validation loss: 2.4811647704233883

Epoch: 5| Step: 10
Training loss: 0.8753530947918537
Validation loss: 2.518228514446712

Epoch: 438| Step: 0
Training loss: 1.0437323243249192
Validation loss: 2.4584032913968645

Epoch: 5| Step: 1
Training loss: 0.8748270613203933
Validation loss: 2.4646936781805477

Epoch: 5| Step: 2
Training loss: 1.0590440418821963
Validation loss: 2.3713352180224567

Epoch: 5| Step: 3
Training loss: 1.086223866419407
Validation loss: 2.4561762840466703

Epoch: 5| Step: 4
Training loss: 1.082678260573978
Validation loss: 2.4505073936079644

Epoch: 5| Step: 5
Training loss: 0.9789147391107214
Validation loss: 2.4866684177291014

Epoch: 5| Step: 6
Training loss: 1.8775806469619214
Validation loss: 2.424344404708029

Epoch: 5| Step: 7
Training loss: 1.0837336619728477
Validation loss: 2.421573343587226

Epoch: 5| Step: 8
Training loss: 0.9919223581316545
Validation loss: 2.4796577588350446

Epoch: 5| Step: 9
Training loss: 0.7289475702183651
Validation loss: 2.412145737022748

Epoch: 5| Step: 10
Training loss: 1.251384254745237
Validation loss: 2.35535231950626

Epoch: 439| Step: 0
Training loss: 0.9734849884549015
Validation loss: 2.4222536244259922

Epoch: 5| Step: 1
Training loss: 1.743299668110409
Validation loss: 2.41143836737378

Epoch: 5| Step: 2
Training loss: 1.5747797796907048
Validation loss: 2.3700387702601504

Epoch: 5| Step: 3
Training loss: 0.791125857360732
Validation loss: 2.46654218106269

Epoch: 5| Step: 4
Training loss: 1.2253892474764134
Validation loss: 2.4411432874595276

Epoch: 5| Step: 5
Training loss: 1.1963053052149868
Validation loss: 2.4340143133487584

Epoch: 5| Step: 6
Training loss: 1.0442621447930254
Validation loss: 2.387042726805883

Epoch: 5| Step: 7
Training loss: 1.0137006869475307
Validation loss: 2.5072602154679156

Epoch: 5| Step: 8
Training loss: 0.9104030421886667
Validation loss: 2.408255701239895

Epoch: 5| Step: 9
Training loss: 0.8828328560701905
Validation loss: 2.4785077918917415

Epoch: 5| Step: 10
Training loss: 0.6853333491168905
Validation loss: 2.408084276261666

Epoch: 440| Step: 0
Training loss: 1.154970698542293
Validation loss: 2.486318387319229

Epoch: 5| Step: 1
Training loss: 1.06941084925961
Validation loss: 2.4705704975373264

Epoch: 5| Step: 2
Training loss: 1.0333978653313007
Validation loss: 2.4171712974027946

Epoch: 5| Step: 3
Training loss: 0.8455945092770931
Validation loss: 2.50296247781533

Epoch: 5| Step: 4
Training loss: 0.9540918792889189
Validation loss: 2.3813900800297407

Epoch: 5| Step: 5
Training loss: 1.0375371650565566
Validation loss: 2.415786901981304

Epoch: 5| Step: 6
Training loss: 1.0493761616303385
Validation loss: 2.5265659597969803

Epoch: 5| Step: 7
Training loss: 1.0508076263861068
Validation loss: 2.419055213080827

Epoch: 5| Step: 8
Training loss: 0.8473310418066717
Validation loss: 2.440653875374804

Epoch: 5| Step: 9
Training loss: 1.0350759798992675
Validation loss: 2.4778595900945866

Epoch: 5| Step: 10
Training loss: 2.0011490858702645
Validation loss: 2.3765648445275915

Epoch: 441| Step: 0
Training loss: 0.7158327608990702
Validation loss: 2.485301353204815

Epoch: 5| Step: 1
Training loss: 1.4163266596706852
Validation loss: 2.4800374883563228

Epoch: 5| Step: 2
Training loss: 0.8195462962788526
Validation loss: 2.498861054965237

Epoch: 5| Step: 3
Training loss: 0.9939272188716232
Validation loss: 2.418923811886306

Epoch: 5| Step: 4
Training loss: 0.9029977913467248
Validation loss: 2.467269343887125

Epoch: 5| Step: 5
Training loss: 1.7665602645981346
Validation loss: 2.510594166954245

Epoch: 5| Step: 6
Training loss: 1.3812812905197982
Validation loss: 2.3797386522623407

Epoch: 5| Step: 7
Training loss: 0.8751526426960518
Validation loss: 2.5324553599040867

Epoch: 5| Step: 8
Training loss: 1.1399748530040332
Validation loss: 2.5162662251153147

Epoch: 5| Step: 9
Training loss: 1.369776905787703
Validation loss: 2.441716321455479

Epoch: 5| Step: 10
Training loss: 1.212836763472951
Validation loss: 2.5004620791575256

Epoch: 442| Step: 0
Training loss: 0.8566128818039459
Validation loss: 2.53184536508188

Epoch: 5| Step: 1
Training loss: 1.206051672804304
Validation loss: 2.4518241806296697

Epoch: 5| Step: 2
Training loss: 1.0234370340826706
Validation loss: 2.473887944323858

Epoch: 5| Step: 3
Training loss: 1.1510392386064192
Validation loss: 2.5445895056156513

Epoch: 5| Step: 4
Training loss: 1.6914469865998707
Validation loss: 2.4493452676884724

Epoch: 5| Step: 5
Training loss: 1.0957663886698266
Validation loss: 2.438518611609756

Epoch: 5| Step: 6
Training loss: 0.8603392653176397
Validation loss: 2.477271337291615

Epoch: 5| Step: 7
Training loss: 1.043823920276374
Validation loss: 2.5015369259408122

Epoch: 5| Step: 8
Training loss: 0.8911599008567197
Validation loss: 2.4625668763713207

Epoch: 5| Step: 9
Training loss: 1.1249238624239934
Validation loss: 2.4492359108766966

Epoch: 5| Step: 10
Training loss: 1.480577530299217
Validation loss: 2.5050264158201467

Epoch: 443| Step: 0
Training loss: 0.8972170293898508
Validation loss: 2.4920118266585973

Epoch: 5| Step: 1
Training loss: 0.9187871977353856
Validation loss: 2.496513446574263

Epoch: 5| Step: 2
Training loss: 1.11462706483036
Validation loss: 2.430102672623329

Epoch: 5| Step: 3
Training loss: 0.9540975642828201
Validation loss: 2.569345204895101

Epoch: 5| Step: 4
Training loss: 0.985792652982629
Validation loss: 2.3799308891065127

Epoch: 5| Step: 5
Training loss: 0.9211729900517387
Validation loss: 2.510673640170303

Epoch: 5| Step: 6
Training loss: 0.9276476046490404
Validation loss: 2.42694737497526

Epoch: 5| Step: 7
Training loss: 0.9533680465242602
Validation loss: 2.473379198475169

Epoch: 5| Step: 8
Training loss: 1.7931225945452263
Validation loss: 2.484613211225719

Epoch: 5| Step: 9
Training loss: 1.1543919351489027
Validation loss: 2.4726664479065192

Epoch: 5| Step: 10
Training loss: 1.1228453878358011
Validation loss: 2.4358847929937095

Epoch: 444| Step: 0
Training loss: 0.7075538600599333
Validation loss: 2.52015794821897

Epoch: 5| Step: 1
Training loss: 0.7194828775156556
Validation loss: 2.415748443673547

Epoch: 5| Step: 2
Training loss: 0.9664324140900261
Validation loss: 2.466507424411245

Epoch: 5| Step: 3
Training loss: 0.7712206039514627
Validation loss: 2.4622275850646367

Epoch: 5| Step: 4
Training loss: 1.096836041576468
Validation loss: 2.4448547411839794

Epoch: 5| Step: 5
Training loss: 0.7266960431498432
Validation loss: 2.460658837743745

Epoch: 5| Step: 6
Training loss: 1.0388981968898476
Validation loss: 2.512407168230098

Epoch: 5| Step: 7
Training loss: 1.0218446289588827
Validation loss: 2.4615640124355784

Epoch: 5| Step: 8
Training loss: 1.6875307292259627
Validation loss: 2.5295895693655557

Epoch: 5| Step: 9
Training loss: 1.6924247934601273
Validation loss: 2.496669934580304

Epoch: 5| Step: 10
Training loss: 1.1283656743277954
Validation loss: 2.50922716775164

Epoch: 445| Step: 0
Training loss: 0.6311663657201885
Validation loss: 2.3903064787702655

Epoch: 5| Step: 1
Training loss: 1.2948754764029042
Validation loss: 2.453241581024794

Epoch: 5| Step: 2
Training loss: 0.8934787738842562
Validation loss: 2.4179379263445644

Epoch: 5| Step: 3
Training loss: 1.0413168637719052
Validation loss: 2.4258358595379694

Epoch: 5| Step: 4
Training loss: 0.8994214184985223
Validation loss: 2.456046287991807

Epoch: 5| Step: 5
Training loss: 1.9222421683058775
Validation loss: 2.4528666816761335

Epoch: 5| Step: 6
Training loss: 1.1486409325029685
Validation loss: 2.4826227469598003

Epoch: 5| Step: 7
Training loss: 1.2208017538280562
Validation loss: 2.390739373303481

Epoch: 5| Step: 8
Training loss: 1.0794966996969826
Validation loss: 2.461053795320221

Epoch: 5| Step: 9
Training loss: 1.2673603922988501
Validation loss: 2.4731276902086177

Epoch: 5| Step: 10
Training loss: 1.0201924836169594
Validation loss: 2.4674421807717946

Epoch: 446| Step: 0
Training loss: 1.1855090165103064
Validation loss: 2.3929998949988653

Epoch: 5| Step: 1
Training loss: 1.0354781891769766
Validation loss: 2.4562028124439834

Epoch: 5| Step: 2
Training loss: 0.8313043490547212
Validation loss: 2.416286657864088

Epoch: 5| Step: 3
Training loss: 1.967094270104363
Validation loss: 2.5395055674895217

Epoch: 5| Step: 4
Training loss: 0.8369357841815386
Validation loss: 2.537192477687442

Epoch: 5| Step: 5
Training loss: 1.1971722764033308
Validation loss: 2.495280955620706

Epoch: 5| Step: 6
Training loss: 1.079905380589995
Validation loss: 2.461118951798869

Epoch: 5| Step: 7
Training loss: 1.1447004902670403
Validation loss: 2.436065316817993

Epoch: 5| Step: 8
Training loss: 0.9269129921656462
Validation loss: 2.459006652858829

Epoch: 5| Step: 9
Training loss: 1.1966475467340985
Validation loss: 2.4659813002215594

Epoch: 5| Step: 10
Training loss: 1.2145831451066897
Validation loss: 2.5089978236469515

Epoch: 447| Step: 0
Training loss: 0.9199108924939071
Validation loss: 2.447788138976516

Epoch: 5| Step: 1
Training loss: 0.7053912410634108
Validation loss: 2.3688418915874503

Epoch: 5| Step: 2
Training loss: 0.8711600855728423
Validation loss: 2.4698978495514434

Epoch: 5| Step: 3
Training loss: 0.8164049723491984
Validation loss: 2.432022139519927

Epoch: 5| Step: 4
Training loss: 1.4802370720511249
Validation loss: 2.413667428206009

Epoch: 5| Step: 5
Training loss: 0.9127477988741854
Validation loss: 2.432444989985644

Epoch: 5| Step: 6
Training loss: 1.0529163889751865
Validation loss: 2.4775768565600145

Epoch: 5| Step: 7
Training loss: 0.8822325768138026
Validation loss: 2.449034609732328

Epoch: 5| Step: 8
Training loss: 2.005485878764624
Validation loss: 2.506265368437632

Epoch: 5| Step: 9
Training loss: 0.9961437138012955
Validation loss: 2.420435196632688

Epoch: 5| Step: 10
Training loss: 0.9199714404317245
Validation loss: 2.363225653277558

Epoch: 448| Step: 0
Training loss: 0.6755489986629376
Validation loss: 2.4463125610467418

Epoch: 5| Step: 1
Training loss: 0.7035807086465342
Validation loss: 2.472148150026104

Epoch: 5| Step: 2
Training loss: 0.9786574209575151
Validation loss: 2.4348376458593046

Epoch: 5| Step: 3
Training loss: 0.730891875253421
Validation loss: 2.5067634679583586

Epoch: 5| Step: 4
Training loss: 0.9628285664645165
Validation loss: 2.4616926012382288

Epoch: 5| Step: 5
Training loss: 1.121848991751376
Validation loss: 2.4375918959760954

Epoch: 5| Step: 6
Training loss: 1.2048802638417282
Validation loss: 2.4353230886189325

Epoch: 5| Step: 7
Training loss: 0.8631866886598303
Validation loss: 2.4815982060049944

Epoch: 5| Step: 8
Training loss: 1.1660018229985585
Validation loss: 2.4615042835097913

Epoch: 5| Step: 9
Training loss: 1.9776915088809799
Validation loss: 2.4455247561700593

Epoch: 5| Step: 10
Training loss: 1.1668653602794457
Validation loss: 2.5012011442015925

Epoch: 449| Step: 0
Training loss: 1.8214774926612083
Validation loss: 2.430954910339424

Epoch: 5| Step: 1
Training loss: 1.1362385997473088
Validation loss: 2.453127223867434

Epoch: 5| Step: 2
Training loss: 1.012998853639517
Validation loss: 2.377466570312053

Epoch: 5| Step: 3
Training loss: 0.978388368779632
Validation loss: 2.429126302360928

Epoch: 5| Step: 4
Training loss: 0.9940570728737871
Validation loss: 2.4448765574442133

Epoch: 5| Step: 5
Training loss: 0.6642084746641708
Validation loss: 2.42126382293551

Epoch: 5| Step: 6
Training loss: 0.9765668029690356
Validation loss: 2.472754102445559

Epoch: 5| Step: 7
Training loss: 0.8587586707020316
Validation loss: 2.5417075980118478

Epoch: 5| Step: 8
Training loss: 1.2187892711865778
Validation loss: 2.448369455101706

Epoch: 5| Step: 9
Training loss: 1.0500218934092727
Validation loss: 2.488333668324662

Epoch: 5| Step: 10
Training loss: 1.2566518226340453
Validation loss: 2.469934356203765

Epoch: 450| Step: 0
Training loss: 1.1034967201436523
Validation loss: 2.4451736326369096

Epoch: 5| Step: 1
Training loss: 2.018234338241022
Validation loss: 2.443380747677259

Epoch: 5| Step: 2
Training loss: 1.3310229380928906
Validation loss: 2.437444499572167

Epoch: 5| Step: 3
Training loss: 0.8478292824771075
Validation loss: 2.428150229988716

Epoch: 5| Step: 4
Training loss: 0.8329698524904299
Validation loss: 2.434928726325949

Epoch: 5| Step: 5
Training loss: 1.0326859851168755
Validation loss: 2.4334112644850516

Epoch: 5| Step: 6
Training loss: 0.9182160713933873
Validation loss: 2.5495679730253253

Epoch: 5| Step: 7
Training loss: 0.9679486436579878
Validation loss: 2.4472845835421517

Epoch: 5| Step: 8
Training loss: 1.130814361994096
Validation loss: 2.515803044496835

Epoch: 5| Step: 9
Training loss: 0.7842105845140067
Validation loss: 2.4869745726184047

Epoch: 5| Step: 10
Training loss: 0.9351893878824148
Validation loss: 2.5085570202296115

Epoch: 451| Step: 0
Training loss: 1.00444111509695
Validation loss: 2.4717822930335904

Epoch: 5| Step: 1
Training loss: 1.1802755746880473
Validation loss: 2.50571354298047

Epoch: 5| Step: 2
Training loss: 0.8976003976416429
Validation loss: 2.461934741989319

Epoch: 5| Step: 3
Training loss: 1.1770064348516494
Validation loss: 2.4357815415049435

Epoch: 5| Step: 4
Training loss: 1.09808960094942
Validation loss: 2.470526477044064

Epoch: 5| Step: 5
Training loss: 1.902280583204362
Validation loss: 2.40420746408159

Epoch: 5| Step: 6
Training loss: 0.8241567723985634
Validation loss: 2.4838950008909797

Epoch: 5| Step: 7
Training loss: 0.6981832199272824
Validation loss: 2.533375800318681

Epoch: 5| Step: 8
Training loss: 1.1995788431210546
Validation loss: 2.420066572201823

Epoch: 5| Step: 9
Training loss: 1.1615770162435302
Validation loss: 2.577362403187539

Epoch: 5| Step: 10
Training loss: 0.8868822123561562
Validation loss: 2.4516064471606147

Epoch: 452| Step: 0
Training loss: 0.9973844655370999
Validation loss: 2.4229285080105023

Epoch: 5| Step: 1
Training loss: 1.1833059130881074
Validation loss: 2.431033741154764

Epoch: 5| Step: 2
Training loss: 1.314757177321346
Validation loss: 2.433535823903937

Epoch: 5| Step: 3
Training loss: 1.171856791036917
Validation loss: 2.47906413132976

Epoch: 5| Step: 4
Training loss: 1.1582567996989126
Validation loss: 2.4863501408441477

Epoch: 5| Step: 5
Training loss: 1.0840371608769275
Validation loss: 2.4569342055552466

Epoch: 5| Step: 6
Training loss: 0.8568633395792142
Validation loss: 2.520782829869646

Epoch: 5| Step: 7
Training loss: 0.8863444945907195
Validation loss: 2.3918448782213444

Epoch: 5| Step: 8
Training loss: 0.8994687340239422
Validation loss: 2.45058214948864

Epoch: 5| Step: 9
Training loss: 0.7719507666710961
Validation loss: 2.4902664656705755

Epoch: 5| Step: 10
Training loss: 1.8585598224559416
Validation loss: 2.4209717525988315

Epoch: 453| Step: 0
Training loss: 1.172275017176689
Validation loss: 2.489848839748295

Epoch: 5| Step: 1
Training loss: 0.9120799351909612
Validation loss: 2.4443727147468843

Epoch: 5| Step: 2
Training loss: 0.7877598575978884
Validation loss: 2.476719375734246

Epoch: 5| Step: 3
Training loss: 0.7467781642561613
Validation loss: 2.5155332978266043

Epoch: 5| Step: 4
Training loss: 0.7247325453220608
Validation loss: 2.4591110746671543

Epoch: 5| Step: 5
Training loss: 2.0858461738625036
Validation loss: 2.4321936207082886

Epoch: 5| Step: 6
Training loss: 1.1051978867900305
Validation loss: 2.454804971201765

Epoch: 5| Step: 7
Training loss: 0.8733722669231914
Validation loss: 2.4402946246986033

Epoch: 5| Step: 8
Training loss: 1.2175553653512508
Validation loss: 2.4524289997412927

Epoch: 5| Step: 9
Training loss: 0.9129269711429265
Validation loss: 2.440771030013502

Epoch: 5| Step: 10
Training loss: 0.8379235961402433
Validation loss: 2.5033914542590714

Epoch: 454| Step: 0
Training loss: 0.8558843639491653
Validation loss: 2.433019890350255

Epoch: 5| Step: 1
Training loss: 1.7537295246084552
Validation loss: 2.436585565859518

Epoch: 5| Step: 2
Training loss: 0.8898322944473096
Validation loss: 2.4760329213186982

Epoch: 5| Step: 3
Training loss: 1.0090174605689597
Validation loss: 2.483853837103196

Epoch: 5| Step: 4
Training loss: 1.0393903974997132
Validation loss: 2.4243557580715116

Epoch: 5| Step: 5
Training loss: 0.8809700027321056
Validation loss: 2.467083029775818

Epoch: 5| Step: 6
Training loss: 1.4253746811698216
Validation loss: 2.368167550452619

Epoch: 5| Step: 7
Training loss: 0.8613861825627044
Validation loss: 2.4295366520871475

Epoch: 5| Step: 8
Training loss: 0.7412265780963649
Validation loss: 2.4331245568549265

Epoch: 5| Step: 9
Training loss: 1.2951289452974188
Validation loss: 2.469203110392857

Epoch: 5| Step: 10
Training loss: 0.8174369183388139
Validation loss: 2.468746730999063

Epoch: 455| Step: 0
Training loss: 0.9453269705177156
Validation loss: 2.471532879357542

Epoch: 5| Step: 1
Training loss: 0.9553652216795098
Validation loss: 2.43171432890133

Epoch: 5| Step: 2
Training loss: 1.0039865780765322
Validation loss: 2.4802708561144544

Epoch: 5| Step: 3
Training loss: 1.146866430931405
Validation loss: 2.4466222957127215

Epoch: 5| Step: 4
Training loss: 0.9487588027123554
Validation loss: 2.5024062308003465

Epoch: 5| Step: 5
Training loss: 1.8764181496068706
Validation loss: 2.453372015141796

Epoch: 5| Step: 6
Training loss: 1.069776581853184
Validation loss: 2.5270560454383255

Epoch: 5| Step: 7
Training loss: 0.7840636893210545
Validation loss: 2.521467228487046

Epoch: 5| Step: 8
Training loss: 0.8510977850675308
Validation loss: 2.4032953479399266

Epoch: 5| Step: 9
Training loss: 0.8798777318674418
Validation loss: 2.5036728254389202

Epoch: 5| Step: 10
Training loss: 0.7770288107377501
Validation loss: 2.355793957786471

Epoch: 456| Step: 0
Training loss: 1.0239728153688359
Validation loss: 2.420905174609982

Epoch: 5| Step: 1
Training loss: 0.9018805499841244
Validation loss: 2.4803736137405044

Epoch: 5| Step: 2
Training loss: 0.9452848509220816
Validation loss: 2.389209174442285

Epoch: 5| Step: 3
Training loss: 1.356968646233343
Validation loss: 2.4894794012154597

Epoch: 5| Step: 4
Training loss: 0.838524922900735
Validation loss: 2.4657878392177985

Epoch: 5| Step: 5
Training loss: 1.0151956677809582
Validation loss: 2.4746878604774105

Epoch: 5| Step: 6
Training loss: 1.4019535552561204
Validation loss: 2.527696199876329

Epoch: 5| Step: 7
Training loss: 0.8357344764091637
Validation loss: 2.4325630663878743

Epoch: 5| Step: 8
Training loss: 0.8145827229165004
Validation loss: 2.4905394852485507

Epoch: 5| Step: 9
Training loss: 1.7353453799745664
Validation loss: 2.4603117158072063

Epoch: 5| Step: 10
Training loss: 1.023157678453936
Validation loss: 2.547345589357609

Epoch: 457| Step: 0
Training loss: 1.0022191220686905
Validation loss: 2.4717694684823415

Epoch: 5| Step: 1
Training loss: 1.1677146303459116
Validation loss: 2.496188224475738

Epoch: 5| Step: 2
Training loss: 0.7626989464667149
Validation loss: 2.4880221670469185

Epoch: 5| Step: 3
Training loss: 0.8869514328090278
Validation loss: 2.4383620133315347

Epoch: 5| Step: 4
Training loss: 0.8605123103434337
Validation loss: 2.474772843288242

Epoch: 5| Step: 5
Training loss: 0.8060438705838828
Validation loss: 2.4308547883972937

Epoch: 5| Step: 6
Training loss: 1.68676176524296
Validation loss: 2.46006280524911

Epoch: 5| Step: 7
Training loss: 0.8985946517831028
Validation loss: 2.4524720133248854

Epoch: 5| Step: 8
Training loss: 1.0199967998566635
Validation loss: 2.373514032761318

Epoch: 5| Step: 9
Training loss: 1.2239876709797068
Validation loss: 2.455478327125441

Epoch: 5| Step: 10
Training loss: 1.1762752065683968
Validation loss: 2.39193795696316

Epoch: 458| Step: 0
Training loss: 0.9863446526983901
Validation loss: 2.4339533335279833

Epoch: 5| Step: 1
Training loss: 1.0659348560346313
Validation loss: 2.416905444028312

Epoch: 5| Step: 2
Training loss: 0.9436671542758506
Validation loss: 2.520946060490106

Epoch: 5| Step: 3
Training loss: 1.3159156134023449
Validation loss: 2.432367345302725

Epoch: 5| Step: 4
Training loss: 0.9629853919635505
Validation loss: 2.4002030804982124

Epoch: 5| Step: 5
Training loss: 1.208919591200205
Validation loss: 2.4456996690504553

Epoch: 5| Step: 6
Training loss: 0.832446464844877
Validation loss: 2.4672932956601294

Epoch: 5| Step: 7
Training loss: 0.8613419650602923
Validation loss: 2.5521129309264983

Epoch: 5| Step: 8
Training loss: 1.1157099950560325
Validation loss: 2.391174704675047

Epoch: 5| Step: 9
Training loss: 1.6217279503518438
Validation loss: 2.409732566167375

Epoch: 5| Step: 10
Training loss: 1.2095325810876383
Validation loss: 2.44327271458967

Epoch: 459| Step: 0
Training loss: 0.8953165330513064
Validation loss: 2.417003849051542

Epoch: 5| Step: 1
Training loss: 1.0814430483435584
Validation loss: 2.4125271104031834

Epoch: 5| Step: 2
Training loss: 1.2374298345537518
Validation loss: 2.4808380001976484

Epoch: 5| Step: 3
Training loss: 1.0469048339236593
Validation loss: 2.4645141570495634

Epoch: 5| Step: 4
Training loss: 1.7681331542910168
Validation loss: 2.4380792889685177

Epoch: 5| Step: 5
Training loss: 0.9133344179573951
Validation loss: 2.454771327694446

Epoch: 5| Step: 6
Training loss: 1.0351582077295756
Validation loss: 2.4494127807495043

Epoch: 5| Step: 7
Training loss: 0.6989301799973141
Validation loss: 2.422268218246341

Epoch: 5| Step: 8
Training loss: 1.1869683330332184
Validation loss: 2.4898591494828177

Epoch: 5| Step: 9
Training loss: 0.7688340645083789
Validation loss: 2.5142019684200356

Epoch: 5| Step: 10
Training loss: 1.0729955193638463
Validation loss: 2.478191618991249

Epoch: 460| Step: 0
Training loss: 1.1475233734675816
Validation loss: 2.4199586383289144

Epoch: 5| Step: 1
Training loss: 0.814835785546153
Validation loss: 2.4902605081530536

Epoch: 5| Step: 2
Training loss: 1.0273056893496293
Validation loss: 2.493767554967982

Epoch: 5| Step: 3
Training loss: 0.96292597026834
Validation loss: 2.438916557524073

Epoch: 5| Step: 4
Training loss: 1.8378439237557518
Validation loss: 2.432202205886683

Epoch: 5| Step: 5
Training loss: 0.9535612452500576
Validation loss: 2.4600714020688432

Epoch: 5| Step: 6
Training loss: 1.2920274794552713
Validation loss: 2.484699291306547

Epoch: 5| Step: 7
Training loss: 0.7942975190896291
Validation loss: 2.4062521702373485

Epoch: 5| Step: 8
Training loss: 1.0025491410385545
Validation loss: 2.4512006481367576

Epoch: 5| Step: 9
Training loss: 0.9895983577725439
Validation loss: 2.3850854714580327

Epoch: 5| Step: 10
Training loss: 1.281413044673682
Validation loss: 2.4665618094157495

Epoch: 461| Step: 0
Training loss: 1.783061394798864
Validation loss: 2.394213891979727

Epoch: 5| Step: 1
Training loss: 1.1767753378168535
Validation loss: 2.4320638917592086

Epoch: 5| Step: 2
Training loss: 0.9146025928621557
Validation loss: 2.4332955686892377

Epoch: 5| Step: 3
Training loss: 0.7769859295532084
Validation loss: 2.437204505546116

Epoch: 5| Step: 4
Training loss: 1.0975936926123893
Validation loss: 2.40734637101508

Epoch: 5| Step: 5
Training loss: 1.1276501594073463
Validation loss: 2.39829755955164

Epoch: 5| Step: 6
Training loss: 1.007733837281029
Validation loss: 2.494934224048295

Epoch: 5| Step: 7
Training loss: 0.6963200930065073
Validation loss: 2.4796836746872484

Epoch: 5| Step: 8
Training loss: 0.9265270207062917
Validation loss: 2.416743901206334

Epoch: 5| Step: 9
Training loss: 1.0898401403880076
Validation loss: 2.485330972639206

Epoch: 5| Step: 10
Training loss: 0.8677368142596946
Validation loss: 2.4638021021390366

Epoch: 462| Step: 0
Training loss: 1.0281727857992502
Validation loss: 2.545121216770109

Epoch: 5| Step: 1
Training loss: 1.7817443697013335
Validation loss: 2.5031003135078436

Epoch: 5| Step: 2
Training loss: 0.9544741353107018
Validation loss: 2.5448369283434134

Epoch: 5| Step: 3
Training loss: 0.7594875424978823
Validation loss: 2.4244305674395568

Epoch: 5| Step: 4
Training loss: 0.7845184240639415
Validation loss: 2.458410154101423

Epoch: 5| Step: 5
Training loss: 1.1783810891200175
Validation loss: 2.4605191949711114

Epoch: 5| Step: 6
Training loss: 0.8541081377461538
Validation loss: 2.450848968524383

Epoch: 5| Step: 7
Training loss: 0.9698691517776118
Validation loss: 2.527729313950118

Epoch: 5| Step: 8
Training loss: 1.4694677182000813
Validation loss: 2.4497203286814515

Epoch: 5| Step: 9
Training loss: 1.0013578256370694
Validation loss: 2.4849658876586145

Epoch: 5| Step: 10
Training loss: 0.8924934797823512
Validation loss: 2.4932157771565033

Epoch: 463| Step: 0
Training loss: 0.9755989509149896
Validation loss: 2.396929540325277

Epoch: 5| Step: 1
Training loss: 1.6532084770254813
Validation loss: 2.3676310522740094

Epoch: 5| Step: 2
Training loss: 0.8250783261773061
Validation loss: 2.42012516548917

Epoch: 5| Step: 3
Training loss: 0.7883347658530104
Validation loss: 2.4751561399935094

Epoch: 5| Step: 4
Training loss: 0.9006860873003676
Validation loss: 2.459558156439056

Epoch: 5| Step: 5
Training loss: 1.4431175266764593
Validation loss: 2.483038593080411

Epoch: 5| Step: 6
Training loss: 0.7495793116406677
Validation loss: 2.4216400085406535

Epoch: 5| Step: 7
Training loss: 1.0926682163337702
Validation loss: 2.483259363704576

Epoch: 5| Step: 8
Training loss: 0.967712893165601
Validation loss: 2.444633604827463

Epoch: 5| Step: 9
Training loss: 0.9979100441497244
Validation loss: 2.559127132551325

Epoch: 5| Step: 10
Training loss: 0.9412617869354691
Validation loss: 2.4643300861002086

Epoch: 464| Step: 0
Training loss: 1.7541221706639671
Validation loss: 2.4780834017036777

Epoch: 5| Step: 1
Training loss: 1.3474701241488187
Validation loss: 2.5544373511880845

Epoch: 5| Step: 2
Training loss: 1.166294799304047
Validation loss: 2.4454119335555062

Epoch: 5| Step: 3
Training loss: 0.8704082374718521
Validation loss: 2.431778936846328

Epoch: 5| Step: 4
Training loss: 0.963783979447713
Validation loss: 2.4690650218694685

Epoch: 5| Step: 5
Training loss: 1.0994375308038264
Validation loss: 2.454599480139539

Epoch: 5| Step: 6
Training loss: 0.7986382069805507
Validation loss: 2.533266002761987

Epoch: 5| Step: 7
Training loss: 1.1482352253806145
Validation loss: 2.3293831748201206

Epoch: 5| Step: 8
Training loss: 0.6888663845419902
Validation loss: 2.4233360919202367

Epoch: 5| Step: 9
Training loss: 0.8978819082897989
Validation loss: 2.4786895559304303

Epoch: 5| Step: 10
Training loss: 1.1161649065380241
Validation loss: 2.4256642633938093

Epoch: 465| Step: 0
Training loss: 0.9396409701469096
Validation loss: 2.4911941357506278

Epoch: 5| Step: 1
Training loss: 1.8283511942938926
Validation loss: 2.405967106601779

Epoch: 5| Step: 2
Training loss: 0.9974173036394219
Validation loss: 2.4534431587185

Epoch: 5| Step: 3
Training loss: 0.8890265459188773
Validation loss: 2.4311297663566758

Epoch: 5| Step: 4
Training loss: 1.2671540995569268
Validation loss: 2.542371530766537

Epoch: 5| Step: 5
Training loss: 1.083974532349036
Validation loss: 2.4175409613870418

Epoch: 5| Step: 6
Training loss: 1.0794211074178985
Validation loss: 2.446915274603064

Epoch: 5| Step: 7
Training loss: 0.7598753313031535
Validation loss: 2.390625055763372

Epoch: 5| Step: 8
Training loss: 0.9813093556231711
Validation loss: 2.465210430822381

Epoch: 5| Step: 9
Training loss: 0.7168473478004386
Validation loss: 2.4150418224809655

Epoch: 5| Step: 10
Training loss: 0.8690051712610966
Validation loss: 2.4631934760311602

Epoch: 466| Step: 0
Training loss: 1.4231205609385968
Validation loss: 2.5623210731464185

Epoch: 5| Step: 1
Training loss: 0.7661361545043868
Validation loss: 2.503692473975511

Epoch: 5| Step: 2
Training loss: 0.7357680723023271
Validation loss: 2.4021380187258017

Epoch: 5| Step: 3
Training loss: 0.835963061646
Validation loss: 2.4646597041860856

Epoch: 5| Step: 4
Training loss: 0.9686710879272443
Validation loss: 2.4335411328263548

Epoch: 5| Step: 5
Training loss: 1.1188841520891266
Validation loss: 2.449592828808623

Epoch: 5| Step: 6
Training loss: 1.8067632190246627
Validation loss: 2.425333355410623

Epoch: 5| Step: 7
Training loss: 0.9031735522673019
Validation loss: 2.4661739560129736

Epoch: 5| Step: 8
Training loss: 0.895237706174278
Validation loss: 2.458599774490436

Epoch: 5| Step: 9
Training loss: 0.8234541180144436
Validation loss: 2.4349053748176743

Epoch: 5| Step: 10
Training loss: 0.9637793411063309
Validation loss: 2.461383800596653

Epoch: 467| Step: 0
Training loss: 0.7977241778616261
Validation loss: 2.470159923213252

Epoch: 5| Step: 1
Training loss: 0.873129616727208
Validation loss: 2.4668641572632595

Epoch: 5| Step: 2
Training loss: 1.6951256574341553
Validation loss: 2.4118628920777363

Epoch: 5| Step: 3
Training loss: 1.1291465107619152
Validation loss: 2.4647314018976374

Epoch: 5| Step: 4
Training loss: 1.2457486813894416
Validation loss: 2.455260942244837

Epoch: 5| Step: 5
Training loss: 0.8770770896514207
Validation loss: 2.3383092787850686

Epoch: 5| Step: 6
Training loss: 1.038627189142682
Validation loss: 2.476571887856296

Epoch: 5| Step: 7
Training loss: 0.8145849546593599
Validation loss: 2.48259737914357

Epoch: 5| Step: 8
Training loss: 1.0523715552923734
Validation loss: 2.4430447112497884

Epoch: 5| Step: 9
Training loss: 0.928346901514238
Validation loss: 2.491845489764825

Epoch: 5| Step: 10
Training loss: 0.878224290549116
Validation loss: 2.4262875850903436

Epoch: 468| Step: 0
Training loss: 1.086516850115693
Validation loss: 2.4723575434101885

Epoch: 5| Step: 1
Training loss: 0.8435737637736345
Validation loss: 2.4091596629288894

Epoch: 5| Step: 2
Training loss: 0.9882567934168981
Validation loss: 2.4907987129117712

Epoch: 5| Step: 3
Training loss: 1.006607814220049
Validation loss: 2.458272209123663

Epoch: 5| Step: 4
Training loss: 1.7181968492434865
Validation loss: 2.467095066086184

Epoch: 5| Step: 5
Training loss: 0.9426324227190931
Validation loss: 2.451349541187215

Epoch: 5| Step: 6
Training loss: 0.7264998624319746
Validation loss: 2.428136147689553

Epoch: 5| Step: 7
Training loss: 0.8669802100069007
Validation loss: 2.4598161128578244

Epoch: 5| Step: 8
Training loss: 1.0709413783167665
Validation loss: 2.4674665552891466

Epoch: 5| Step: 9
Training loss: 1.2301655713734447
Validation loss: 2.4877328581168996

Epoch: 5| Step: 10
Training loss: 0.8866540490294791
Validation loss: 2.410357254179159

Epoch: 469| Step: 0
Training loss: 0.9833083049907996
Validation loss: 2.3619084248185187

Epoch: 5| Step: 1
Training loss: 0.8408445206368294
Validation loss: 2.3725007556070503

Epoch: 5| Step: 2
Training loss: 1.2226410886171837
Validation loss: 2.391086851982414

Epoch: 5| Step: 3
Training loss: 0.9710593538952107
Validation loss: 2.4243833383861975

Epoch: 5| Step: 4
Training loss: 0.8875949580474413
Validation loss: 2.488095466064737

Epoch: 5| Step: 5
Training loss: 1.0637668462152265
Validation loss: 2.4497264883926775

Epoch: 5| Step: 6
Training loss: 1.0887775196053031
Validation loss: 2.454495112888394

Epoch: 5| Step: 7
Training loss: 0.9288692560040142
Validation loss: 2.403959533238886

Epoch: 5| Step: 8
Training loss: 0.6629808705031326
Validation loss: 2.4516338819470818

Epoch: 5| Step: 9
Training loss: 1.8727574607161737
Validation loss: 2.4521486633208935

Epoch: 5| Step: 10
Training loss: 0.7549559248128557
Validation loss: 2.418608825647251

Epoch: 470| Step: 0
Training loss: 0.7040728432225328
Validation loss: 2.380687700266382

Epoch: 5| Step: 1
Training loss: 1.0576751214078302
Validation loss: 2.4009365722286122

Epoch: 5| Step: 2
Training loss: 1.1157865476782995
Validation loss: 2.5353943373114887

Epoch: 5| Step: 3
Training loss: 0.9666153554342741
Validation loss: 2.4673819302123143

Epoch: 5| Step: 4
Training loss: 1.695411222193987
Validation loss: 2.3854696788522505

Epoch: 5| Step: 5
Training loss: 0.9355049840671005
Validation loss: 2.4347987103577085

Epoch: 5| Step: 6
Training loss: 1.088945025069632
Validation loss: 2.4828901434578543

Epoch: 5| Step: 7
Training loss: 1.0560688721240545
Validation loss: 2.3900227462002626

Epoch: 5| Step: 8
Training loss: 0.8547473112445058
Validation loss: 2.3861203665453576

Epoch: 5| Step: 9
Training loss: 1.1017250860906045
Validation loss: 2.4636608009034404

Epoch: 5| Step: 10
Training loss: 0.7945971001237772
Validation loss: 2.4830948801540145

Epoch: 471| Step: 0
Training loss: 0.6488989601304459
Validation loss: 2.5317519082908597

Epoch: 5| Step: 1
Training loss: 0.9286021460702858
Validation loss: 2.3978803181917367

Epoch: 5| Step: 2
Training loss: 1.6970030622123105
Validation loss: 2.4760017939075722

Epoch: 5| Step: 3
Training loss: 0.8672900439969663
Validation loss: 2.4137243935508996

Epoch: 5| Step: 4
Training loss: 1.3207269052092547
Validation loss: 2.46665147683434

Epoch: 5| Step: 5
Training loss: 1.0122022026009405
Validation loss: 2.46718277517104

Epoch: 5| Step: 6
Training loss: 0.9591742364522299
Validation loss: 2.4454574403094265

Epoch: 5| Step: 7
Training loss: 0.9869110801918964
Validation loss: 2.397274404303744

Epoch: 5| Step: 8
Training loss: 0.7953856518871624
Validation loss: 2.434292586948272

Epoch: 5| Step: 9
Training loss: 1.1020074581475414
Validation loss: 2.4762858165763717

Epoch: 5| Step: 10
Training loss: 1.12348539332566
Validation loss: 2.4160736793519026

Epoch: 472| Step: 0
Training loss: 0.9395124452384841
Validation loss: 2.432288769564377

Epoch: 5| Step: 1
Training loss: 1.732677075362978
Validation loss: 2.5491221243467233

Epoch: 5| Step: 2
Training loss: 0.9374788281911115
Validation loss: 2.4502791511265034

Epoch: 5| Step: 3
Training loss: 0.8839790266535137
Validation loss: 2.4383804812451606

Epoch: 5| Step: 4
Training loss: 1.041521761670081
Validation loss: 2.481240986259315

Epoch: 5| Step: 5
Training loss: 0.9637654568710424
Validation loss: 2.596627864843398

Epoch: 5| Step: 6
Training loss: 1.278864803586388
Validation loss: 2.4795644121713636

Epoch: 5| Step: 7
Training loss: 0.9693746091348732
Validation loss: 2.520347555188689

Epoch: 5| Step: 8
Training loss: 1.3359429431826702
Validation loss: 2.532688498303395

Epoch: 5| Step: 9
Training loss: 0.7894979729387812
Validation loss: 2.3843747208178385

Epoch: 5| Step: 10
Training loss: 0.9306522140469216
Validation loss: 2.4714605908716787

Epoch: 473| Step: 0
Training loss: 1.227299414209689
Validation loss: 2.42857220179979

Epoch: 5| Step: 1
Training loss: 0.9556431259521975
Validation loss: 2.3925079173338335

Epoch: 5| Step: 2
Training loss: 0.9565900135787925
Validation loss: 2.4858171494273296

Epoch: 5| Step: 3
Training loss: 0.8745851214352581
Validation loss: 2.4753844629313573

Epoch: 5| Step: 4
Training loss: 0.817515008187841
Validation loss: 2.4343408558953046

Epoch: 5| Step: 5
Training loss: 1.6286495015544549
Validation loss: 2.5016592677282854

Epoch: 5| Step: 6
Training loss: 0.8680077187814615
Validation loss: 2.4581654489407385

Epoch: 5| Step: 7
Training loss: 0.9812267458644685
Validation loss: 2.4099340620463665

Epoch: 5| Step: 8
Training loss: 0.8699214214157615
Validation loss: 2.3931662478608517

Epoch: 5| Step: 9
Training loss: 1.2450617998556939
Validation loss: 2.470382082410739

Epoch: 5| Step: 10
Training loss: 0.8847508376614199
Validation loss: 2.5136412519328553

Epoch: 474| Step: 0
Training loss: 0.9890128582734712
Validation loss: 2.448012454101284

Epoch: 5| Step: 1
Training loss: 0.9839614120414772
Validation loss: 2.450304899566031

Epoch: 5| Step: 2
Training loss: 1.8022832667698463
Validation loss: 2.455506761645785

Epoch: 5| Step: 3
Training loss: 1.0620365253927524
Validation loss: 2.459661529236855

Epoch: 5| Step: 4
Training loss: 0.8868177585530586
Validation loss: 2.3835999807971544

Epoch: 5| Step: 5
Training loss: 1.1157399649915611
Validation loss: 2.4137500072579576

Epoch: 5| Step: 6
Training loss: 0.8488365429225152
Validation loss: 2.4955784819180256

Epoch: 5| Step: 7
Training loss: 0.9331607213372296
Validation loss: 2.4652569068334502

Epoch: 5| Step: 8
Training loss: 0.9301879561621202
Validation loss: 2.4143580469411727

Epoch: 5| Step: 9
Training loss: 0.7270126179042214
Validation loss: 2.389772446382365

Epoch: 5| Step: 10
Training loss: 0.8917626927859807
Validation loss: 2.5002579884055844

Epoch: 475| Step: 0
Training loss: 0.8328559978641285
Validation loss: 2.441679374003505

Epoch: 5| Step: 1
Training loss: 1.1478876367534099
Validation loss: 2.4346254962126386

Epoch: 5| Step: 2
Training loss: 1.0993893879289964
Validation loss: 2.407335223898569

Epoch: 5| Step: 3
Training loss: 0.8486338660405932
Validation loss: 2.4160199548255736

Epoch: 5| Step: 4
Training loss: 0.9104780356865068
Validation loss: 2.405267255610423

Epoch: 5| Step: 5
Training loss: 0.7986524244117514
Validation loss: 2.480507092401192

Epoch: 5| Step: 6
Training loss: 1.794920812363668
Validation loss: 2.432908730715808

Epoch: 5| Step: 7
Training loss: 0.7236728425479168
Validation loss: 2.4596601867879038

Epoch: 5| Step: 8
Training loss: 1.139294566937094
Validation loss: 2.53946926446226

Epoch: 5| Step: 9
Training loss: 1.0432646828044865
Validation loss: 2.483278725714593

Epoch: 5| Step: 10
Training loss: 0.8925504116705969
Validation loss: 2.444089090021359

Epoch: 476| Step: 0
Training loss: 1.1480698808076324
Validation loss: 2.4316122772373836

Epoch: 5| Step: 1
Training loss: 0.9286873189688627
Validation loss: 2.4683739098049866

Epoch: 5| Step: 2
Training loss: 0.9795590622227694
Validation loss: 2.442080580386148

Epoch: 5| Step: 3
Training loss: 1.0323158882345567
Validation loss: 2.443062349928148

Epoch: 5| Step: 4
Training loss: 0.8191820984593405
Validation loss: 2.547943698294701

Epoch: 5| Step: 5
Training loss: 0.8946290608199708
Validation loss: 2.501631161548609

Epoch: 5| Step: 6
Training loss: 0.9265650075328534
Validation loss: 2.43093552335888

Epoch: 5| Step: 7
Training loss: 0.9459473550999578
Validation loss: 2.4464555459333592

Epoch: 5| Step: 8
Training loss: 0.8884609768637383
Validation loss: 2.4144336099122636

Epoch: 5| Step: 9
Training loss: 0.8851890982099199
Validation loss: 2.477579663282747

Epoch: 5| Step: 10
Training loss: 1.9043822597043536
Validation loss: 2.412801279617889

Epoch: 477| Step: 0
Training loss: 1.2201062017086366
Validation loss: 2.449353651449887

Epoch: 5| Step: 1
Training loss: 1.018284938419833
Validation loss: 2.4851874330206165

Epoch: 5| Step: 2
Training loss: 1.2301608230155021
Validation loss: 2.484548886529638

Epoch: 5| Step: 3
Training loss: 0.8232749850979025
Validation loss: 2.485147684312074

Epoch: 5| Step: 4
Training loss: 1.0137280281404557
Validation loss: 2.448589899662331

Epoch: 5| Step: 5
Training loss: 0.7464094842046534
Validation loss: 2.3297038742738643

Epoch: 5| Step: 6
Training loss: 0.8019214235516385
Validation loss: 2.404602865669658

Epoch: 5| Step: 7
Training loss: 0.7069703808290039
Validation loss: 2.441150649212461

Epoch: 5| Step: 8
Training loss: 0.9876290080147652
Validation loss: 2.3835281220043067

Epoch: 5| Step: 9
Training loss: 0.9982929859435802
Validation loss: 2.382303407786317

Epoch: 5| Step: 10
Training loss: 1.7005743823497326
Validation loss: 2.4779458013276767

Epoch: 478| Step: 0
Training loss: 0.9477893128972024
Validation loss: 2.421357852846687

Epoch: 5| Step: 1
Training loss: 0.6386175103337305
Validation loss: 2.5142298861489856

Epoch: 5| Step: 2
Training loss: 1.0160408929119615
Validation loss: 2.494606375126113

Epoch: 5| Step: 3
Training loss: 0.7474969580598002
Validation loss: 2.344088058155279

Epoch: 5| Step: 4
Training loss: 1.873286799716071
Validation loss: 2.4112895880932044

Epoch: 5| Step: 5
Training loss: 1.2295566629800505
Validation loss: 2.4820682643657217

Epoch: 5| Step: 6
Training loss: 1.0867491508745588
Validation loss: 2.4144960152179555

Epoch: 5| Step: 7
Training loss: 0.8587137973156282
Validation loss: 2.527567777061969

Epoch: 5| Step: 8
Training loss: 1.0457521936519925
Validation loss: 2.442376634267911

Epoch: 5| Step: 9
Training loss: 0.689337680218043
Validation loss: 2.469123788150755

Epoch: 5| Step: 10
Training loss: 1.0801217206603433
Validation loss: 2.4179233350151117

Epoch: 479| Step: 0
Training loss: 1.1770445161793721
Validation loss: 2.4785790378217323

Epoch: 5| Step: 1
Training loss: 1.2223130009394587
Validation loss: 2.4631455653744303

Epoch: 5| Step: 2
Training loss: 0.9457024959922946
Validation loss: 2.4707556527046193

Epoch: 5| Step: 3
Training loss: 1.1815820096192784
Validation loss: 2.5083898498765946

Epoch: 5| Step: 4
Training loss: 0.7791664186433067
Validation loss: 2.5351199848040964

Epoch: 5| Step: 5
Training loss: 0.7179221485775125
Validation loss: 2.451558977227796

Epoch: 5| Step: 6
Training loss: 0.8023427114507831
Validation loss: 2.4154143898989724

Epoch: 5| Step: 7
Training loss: 1.8401580347734496
Validation loss: 2.459814515673169

Epoch: 5| Step: 8
Training loss: 0.6006754986734297
Validation loss: 2.3785445883725926

Epoch: 5| Step: 9
Training loss: 0.7316319796595714
Validation loss: 2.4369803385592825

Epoch: 5| Step: 10
Training loss: 1.089625729865954
Validation loss: 2.422362774842814

Epoch: 480| Step: 0
Training loss: 0.773211899039154
Validation loss: 2.400665034424935

Epoch: 5| Step: 1
Training loss: 0.909170148658087
Validation loss: 2.4044492536037785

Epoch: 5| Step: 2
Training loss: 0.8582312168251649
Validation loss: 2.4227490084216123

Epoch: 5| Step: 3
Training loss: 0.773711377598881
Validation loss: 2.4508850089290655

Epoch: 5| Step: 4
Training loss: 0.5914252848818521
Validation loss: 2.4850672544681944

Epoch: 5| Step: 5
Training loss: 1.5940905936330056
Validation loss: 2.339930130786043

Epoch: 5| Step: 6
Training loss: 1.336651884331779
Validation loss: 2.4224965695494522

Epoch: 5| Step: 7
Training loss: 1.0850812431541683
Validation loss: 2.4733722065415136

Epoch: 5| Step: 8
Training loss: 0.886990912929551
Validation loss: 2.4218237451693008

Epoch: 5| Step: 9
Training loss: 1.3248116845237603
Validation loss: 2.4100732930504454

Epoch: 5| Step: 10
Training loss: 0.8870533719310444
Validation loss: 2.475935815051094

Epoch: 481| Step: 0
Training loss: 0.702874986916192
Validation loss: 2.504126275280951

Epoch: 5| Step: 1
Training loss: 1.0694413363974409
Validation loss: 2.5192765103545214

Epoch: 5| Step: 2
Training loss: 0.9291116870699767
Validation loss: 2.508081827980038

Epoch: 5| Step: 3
Training loss: 1.1351334046429806
Validation loss: 2.5449027684195813

Epoch: 5| Step: 4
Training loss: 0.9968547531989664
Validation loss: 2.4649881643327185

Epoch: 5| Step: 5
Training loss: 1.3190248519343548
Validation loss: 2.472472740628682

Epoch: 5| Step: 6
Training loss: 0.9141173713060085
Validation loss: 2.368674478721228

Epoch: 5| Step: 7
Training loss: 0.8652780147250773
Validation loss: 2.4053094392301873

Epoch: 5| Step: 8
Training loss: 1.1094915301948165
Validation loss: 2.4541112807211096

Epoch: 5| Step: 9
Training loss: 0.910944552255228
Validation loss: 2.515125732364753

Epoch: 5| Step: 10
Training loss: 1.849868321243088
Validation loss: 2.441423498867999

Epoch: 482| Step: 0
Training loss: 0.6136537623266888
Validation loss: 2.491588450454033

Epoch: 5| Step: 1
Training loss: 0.9147379083431114
Validation loss: 2.3836302092694197

Epoch: 5| Step: 2
Training loss: 1.2891998217872263
Validation loss: 2.395324590597738

Epoch: 5| Step: 3
Training loss: 1.8663786089683867
Validation loss: 2.3765760901245527

Epoch: 5| Step: 4
Training loss: 0.5267203991325767
Validation loss: 2.4409795767114364

Epoch: 5| Step: 5
Training loss: 0.8428722690525022
Validation loss: 2.5373705465758016

Epoch: 5| Step: 6
Training loss: 0.8240015909934193
Validation loss: 2.420610007648208

Epoch: 5| Step: 7
Training loss: 0.8131461875084464
Validation loss: 2.5142054128418616

Epoch: 5| Step: 8
Training loss: 0.9429801984469695
Validation loss: 2.4395161681521427

Epoch: 5| Step: 9
Training loss: 0.7828523606680353
Validation loss: 2.4972646412906734

Epoch: 5| Step: 10
Training loss: 0.7696493222815717
Validation loss: 2.5138259086937706

Epoch: 483| Step: 0
Training loss: 0.9724589994265277
Validation loss: 2.4742598528101905

Epoch: 5| Step: 1
Training loss: 0.8683246339617247
Validation loss: 2.3987694239690165

Epoch: 5| Step: 2
Training loss: 0.8986789544771897
Validation loss: 2.493575960831536

Epoch: 5| Step: 3
Training loss: 0.7112071186272604
Validation loss: 2.5147891333940273

Epoch: 5| Step: 4
Training loss: 0.8891502685667455
Validation loss: 2.4692513525483095

Epoch: 5| Step: 5
Training loss: 1.1795070585983214
Validation loss: 2.4946073986886175

Epoch: 5| Step: 6
Training loss: 0.9988461632679284
Validation loss: 2.5188384644913495

Epoch: 5| Step: 7
Training loss: 0.9005886695835267
Validation loss: 2.459408088881888

Epoch: 5| Step: 8
Training loss: 0.984056936074473
Validation loss: 2.468742857102735

Epoch: 5| Step: 9
Training loss: 1.809199320379716
Validation loss: 2.419618021859589

Epoch: 5| Step: 10
Training loss: 0.706144229598043
Validation loss: 2.4764018440303017

Epoch: 484| Step: 0
Training loss: 0.9058396956200759
Validation loss: 2.4629818989015373

Epoch: 5| Step: 1
Training loss: 0.7202951987747737
Validation loss: 2.4619028162170675

Epoch: 5| Step: 2
Training loss: 1.0972540176119883
Validation loss: 2.4660223059666078

Epoch: 5| Step: 3
Training loss: 1.2658297055317818
Validation loss: 2.408463036672679

Epoch: 5| Step: 4
Training loss: 0.8070478912144459
Validation loss: 2.4477390543417963

Epoch: 5| Step: 5
Training loss: 0.8389348989743495
Validation loss: 2.3790296383178147

Epoch: 5| Step: 6
Training loss: 0.9141742931373562
Validation loss: 2.4432209888170755

Epoch: 5| Step: 7
Training loss: 1.193671003194426
Validation loss: 2.443416651675472

Epoch: 5| Step: 8
Training loss: 1.5990337225654403
Validation loss: 2.431955169366544

Epoch: 5| Step: 9
Training loss: 1.077449697661239
Validation loss: 2.4680469841682964

Epoch: 5| Step: 10
Training loss: 0.7224105004708131
Validation loss: 2.4546580224948604

Epoch: 485| Step: 0
Training loss: 0.8381510154333383
Validation loss: 2.4334788042724353

Epoch: 5| Step: 1
Training loss: 1.7019038590958857
Validation loss: 2.4003449863727124

Epoch: 5| Step: 2
Training loss: 0.6700288559265194
Validation loss: 2.4945071636177967

Epoch: 5| Step: 3
Training loss: 0.9735222756590505
Validation loss: 2.525900001388866

Epoch: 5| Step: 4
Training loss: 0.8599971599864641
Validation loss: 2.4294607753540935

Epoch: 5| Step: 5
Training loss: 0.8944019407403974
Validation loss: 2.385972533529653

Epoch: 5| Step: 6
Training loss: 1.1433787613695598
Validation loss: 2.4844453006744645

Epoch: 5| Step: 7
Training loss: 1.2203142935413656
Validation loss: 2.4338897270687077

Epoch: 5| Step: 8
Training loss: 0.7989878972704083
Validation loss: 2.42218979117179

Epoch: 5| Step: 9
Training loss: 1.0832972092596669
Validation loss: 2.3827677630591113

Epoch: 5| Step: 10
Training loss: 0.7582371102233286
Validation loss: 2.371260908005964

Epoch: 486| Step: 0
Training loss: 0.9945548942494206
Validation loss: 2.4779139954552476

Epoch: 5| Step: 1
Training loss: 0.6026589940438616
Validation loss: 2.416572673640174

Epoch: 5| Step: 2
Training loss: 0.9167358560170625
Validation loss: 2.4145319367702194

Epoch: 5| Step: 3
Training loss: 0.6299456188028054
Validation loss: 2.4078723204645947

Epoch: 5| Step: 4
Training loss: 1.1933216644672047
Validation loss: 2.5354206986260053

Epoch: 5| Step: 5
Training loss: 1.061116832919669
Validation loss: 2.471688167939797

Epoch: 5| Step: 6
Training loss: 0.9171547710031532
Validation loss: 2.422689755326888

Epoch: 5| Step: 7
Training loss: 1.7863662592197764
Validation loss: 2.4329287626590728

Epoch: 5| Step: 8
Training loss: 0.8646605851617131
Validation loss: 2.3844373058971984

Epoch: 5| Step: 9
Training loss: 0.9920525947229631
Validation loss: 2.538110967883877

Epoch: 5| Step: 10
Training loss: 0.6398224572072708
Validation loss: 2.4642952686002224

Epoch: 487| Step: 0
Training loss: 1.83227068997669
Validation loss: 2.405995948313126

Epoch: 5| Step: 1
Training loss: 0.8616225243359497
Validation loss: 2.470463563173287

Epoch: 5| Step: 2
Training loss: 0.9412191687875278
Validation loss: 2.4267062847115453

Epoch: 5| Step: 3
Training loss: 1.1398507194488996
Validation loss: 2.5316021349079993

Epoch: 5| Step: 4
Training loss: 1.040008057324669
Validation loss: 2.4867510009242113

Epoch: 5| Step: 5
Training loss: 0.9502110573070858
Validation loss: 2.4529445862186097

Epoch: 5| Step: 6
Training loss: 0.8074646959175356
Validation loss: 2.4138457270012803

Epoch: 5| Step: 7
Training loss: 0.6781056291476785
Validation loss: 2.3963344549244754

Epoch: 5| Step: 8
Training loss: 0.8152331817866807
Validation loss: 2.464410685084159

Epoch: 5| Step: 9
Training loss: 0.822253881810073
Validation loss: 2.384261864186637

Epoch: 5| Step: 10
Training loss: 0.8289788360885205
Validation loss: 2.4616604942415297

Epoch: 488| Step: 0
Training loss: 1.1027979314570904
Validation loss: 2.462073268949952

Epoch: 5| Step: 1
Training loss: 0.7578295676285549
Validation loss: 2.4249975176122875

Epoch: 5| Step: 2
Training loss: 1.1692313829774637
Validation loss: 2.472795078299586

Epoch: 5| Step: 3
Training loss: 0.7814745389606707
Validation loss: 2.514004959623402

Epoch: 5| Step: 4
Training loss: 0.8669486189360134
Validation loss: 2.4808310794046773

Epoch: 5| Step: 5
Training loss: 0.8094087262288617
Validation loss: 2.4125939945071018

Epoch: 5| Step: 6
Training loss: 1.6247937731829678
Validation loss: 2.5232569253602826

Epoch: 5| Step: 7
Training loss: 1.1458580996986847
Validation loss: 2.4366944093778673

Epoch: 5| Step: 8
Training loss: 0.8311990507186521
Validation loss: 2.4085692942602464

Epoch: 5| Step: 9
Training loss: 0.680870561185024
Validation loss: 2.4104464460230433

Epoch: 5| Step: 10
Training loss: 1.0743858623565787
Validation loss: 2.423468718987467

Epoch: 489| Step: 0
Training loss: 1.5787420294070402
Validation loss: 2.4667545622497786

Epoch: 5| Step: 1
Training loss: 1.0865749985308197
Validation loss: 2.412422973977594

Epoch: 5| Step: 2
Training loss: 0.8042989366754135
Validation loss: 2.5230470329408976

Epoch: 5| Step: 3
Training loss: 1.249650667968469
Validation loss: 2.45738857553427

Epoch: 5| Step: 4
Training loss: 1.0375596845074022
Validation loss: 2.4310855716135125

Epoch: 5| Step: 5
Training loss: 1.0293281449086695
Validation loss: 2.457878768076868

Epoch: 5| Step: 6
Training loss: 0.8475538622639133
Validation loss: 2.4362411919173947

Epoch: 5| Step: 7
Training loss: 1.0604202447817128
Validation loss: 2.480446196707017

Epoch: 5| Step: 8
Training loss: 1.1683484739192325
Validation loss: 2.4827309646434563

Epoch: 5| Step: 9
Training loss: 0.7272407073590728
Validation loss: 2.4142465446605015

Epoch: 5| Step: 10
Training loss: 0.8135855465499761
Validation loss: 2.409879235510297

Epoch: 490| Step: 0
Training loss: 0.7107321054739931
Validation loss: 2.4612797949782768

Epoch: 5| Step: 1
Training loss: 0.9464861307352228
Validation loss: 2.445138687047092

Epoch: 5| Step: 2
Training loss: 0.934185463043869
Validation loss: 2.4470187556183234

Epoch: 5| Step: 3
Training loss: 1.1140728194305876
Validation loss: 2.3950280417566168

Epoch: 5| Step: 4
Training loss: 1.216203131404861
Validation loss: 2.3824433598738333

Epoch: 5| Step: 5
Training loss: 1.7269239090555921
Validation loss: 2.426745411322528

Epoch: 5| Step: 6
Training loss: 0.9470938615315864
Validation loss: 2.417126643274654

Epoch: 5| Step: 7
Training loss: 0.7437896301225695
Validation loss: 2.3953887052489082

Epoch: 5| Step: 8
Training loss: 0.6832294910505939
Validation loss: 2.533088316332563

Epoch: 5| Step: 9
Training loss: 0.6870316730955173
Validation loss: 2.4963833597896614

Epoch: 5| Step: 10
Training loss: 0.9864920904767619
Validation loss: 2.450718269887142

Epoch: 491| Step: 0
Training loss: 1.1723402498486095
Validation loss: 2.455055526940181

Epoch: 5| Step: 1
Training loss: 0.6053785687628312
Validation loss: 2.3914447108034063

Epoch: 5| Step: 2
Training loss: 0.7316930781603354
Validation loss: 2.424391199384615

Epoch: 5| Step: 3
Training loss: 1.044527182503358
Validation loss: 2.5232864548531007

Epoch: 5| Step: 4
Training loss: 0.9217189398101079
Validation loss: 2.4044101512101537

Epoch: 5| Step: 5
Training loss: 1.14716351489476
Validation loss: 2.443395615060216

Epoch: 5| Step: 6
Training loss: 0.7763214289777707
Validation loss: 2.4985707576250693

Epoch: 5| Step: 7
Training loss: 0.9723555931315309
Validation loss: 2.427146833331059

Epoch: 5| Step: 8
Training loss: 1.6679095005348723
Validation loss: 2.487329873318899

Epoch: 5| Step: 9
Training loss: 0.9625950295736678
Validation loss: 2.509699510753958

Epoch: 5| Step: 10
Training loss: 0.9606217896923461
Validation loss: 2.4075950173674587

Epoch: 492| Step: 0
Training loss: 0.8730645914008334
Validation loss: 2.4241376222793782

Epoch: 5| Step: 1
Training loss: 1.6691542975046296
Validation loss: 2.39819959303853

Epoch: 5| Step: 2
Training loss: 0.7861469907252118
Validation loss: 2.445069454920406

Epoch: 5| Step: 3
Training loss: 0.9336383761031133
Validation loss: 2.4096632852010207

Epoch: 5| Step: 4
Training loss: 0.8301415991356406
Validation loss: 2.482704305118024

Epoch: 5| Step: 5
Training loss: 1.223061247710408
Validation loss: 2.3850553519883038

Epoch: 5| Step: 6
Training loss: 0.8900408585952808
Validation loss: 2.428570907613744

Epoch: 5| Step: 7
Training loss: 1.1291711621822567
Validation loss: 2.4081630562567824

Epoch: 5| Step: 8
Training loss: 0.6972478442235688
Validation loss: 2.411551139103682

Epoch: 5| Step: 9
Training loss: 1.0882888695093436
Validation loss: 2.41319553975935

Epoch: 5| Step: 10
Training loss: 0.6468467733886688
Validation loss: 2.392093701388145

Epoch: 493| Step: 0
Training loss: 0.712612735462757
Validation loss: 2.524422322879754

Epoch: 5| Step: 1
Training loss: 1.0831723032382716
Validation loss: 2.4820559329637137

Epoch: 5| Step: 2
Training loss: 0.9262120978648306
Validation loss: 2.3621908480740137

Epoch: 5| Step: 3
Training loss: 1.0655042026102146
Validation loss: 2.3518852339751226

Epoch: 5| Step: 4
Training loss: 0.6762144871974943
Validation loss: 2.394789336572002

Epoch: 5| Step: 5
Training loss: 0.8548987244416566
Validation loss: 2.5120710244764552

Epoch: 5| Step: 6
Training loss: 1.083331927274134
Validation loss: 2.4056138272532035

Epoch: 5| Step: 7
Training loss: 0.9582554674995268
Validation loss: 2.384752049230718

Epoch: 5| Step: 8
Training loss: 0.8730778699318416
Validation loss: 2.3979179835374484

Epoch: 5| Step: 9
Training loss: 0.7216762599424906
Validation loss: 2.489582619032155

Epoch: 5| Step: 10
Training loss: 1.8476290227000878
Validation loss: 2.4435440887729603

Epoch: 494| Step: 0
Training loss: 0.8381073500263267
Validation loss: 2.443521752299131

Epoch: 5| Step: 1
Training loss: 0.7830607601161361
Validation loss: 2.462381022431444

Epoch: 5| Step: 2
Training loss: 1.0459280143423917
Validation loss: 2.481736807837474

Epoch: 5| Step: 3
Training loss: 1.0905723187421439
Validation loss: 2.48316297054814

Epoch: 5| Step: 4
Training loss: 0.8912075881176104
Validation loss: 2.4122279510308093

Epoch: 5| Step: 5
Training loss: 0.628934895117793
Validation loss: 2.462816270313476

Epoch: 5| Step: 6
Training loss: 0.7952337754413425
Validation loss: 2.3998690783945533

Epoch: 5| Step: 7
Training loss: 1.0438536129993057
Validation loss: 2.4213082213014143

Epoch: 5| Step: 8
Training loss: 0.9892379593057365
Validation loss: 2.4674066294935297

Epoch: 5| Step: 9
Training loss: 0.927198492177226
Validation loss: 2.4009492295042523

Epoch: 5| Step: 10
Training loss: 1.9357332357384958
Validation loss: 2.5123202435978635

Epoch: 495| Step: 0
Training loss: 0.739117144123084
Validation loss: 2.327365461465761

Epoch: 5| Step: 1
Training loss: 0.933111664867739
Validation loss: 2.4660589604336716

Epoch: 5| Step: 2
Training loss: 0.8197291161708943
Validation loss: 2.491070316730869

Epoch: 5| Step: 3
Training loss: 1.0757034860954313
Validation loss: 2.454033555812593

Epoch: 5| Step: 4
Training loss: 1.3014938189828351
Validation loss: 2.507486072643472

Epoch: 5| Step: 5
Training loss: 1.5857286738573866
Validation loss: 2.5289983301668233

Epoch: 5| Step: 6
Training loss: 0.678594302028543
Validation loss: 2.4895344902441017

Epoch: 5| Step: 7
Training loss: 0.8086072763979403
Validation loss: 2.4604262016651846

Epoch: 5| Step: 8
Training loss: 0.8778823653081492
Validation loss: 2.5088062358836463

Epoch: 5| Step: 9
Training loss: 0.6448934057780831
Validation loss: 2.4139622071002846

Epoch: 5| Step: 10
Training loss: 1.0703900719815156
Validation loss: 2.463189591839972

Epoch: 496| Step: 0
Training loss: 0.7523082340528666
Validation loss: 2.4680590905659927

Epoch: 5| Step: 1
Training loss: 1.560965891170341
Validation loss: 2.4385239722369705

Epoch: 5| Step: 2
Training loss: 0.7831356181211107
Validation loss: 2.3916708690398725

Epoch: 5| Step: 3
Training loss: 1.0659197581438256
Validation loss: 2.469638360885203

Epoch: 5| Step: 4
Training loss: 1.0020643027567822
Validation loss: 2.44294796961222

Epoch: 5| Step: 5
Training loss: 0.8105361753929531
Validation loss: 2.4858351564980423

Epoch: 5| Step: 6
Training loss: 0.7846438885491069
Validation loss: 2.4637529447814552

Epoch: 5| Step: 7
Training loss: 0.8261589969145351
Validation loss: 2.474353395447646

Epoch: 5| Step: 8
Training loss: 0.673104646918726
Validation loss: 2.497457825810683

Epoch: 5| Step: 9
Training loss: 1.064128861339531
Validation loss: 2.4795793634649366

Epoch: 5| Step: 10
Training loss: 0.8788076726944869
Validation loss: 2.4904550157440424

Epoch: 497| Step: 0
Training loss: 0.6912359254173317
Validation loss: 2.495452777506886

Epoch: 5| Step: 1
Training loss: 0.7361978673693156
Validation loss: 2.4370335084412433

Epoch: 5| Step: 2
Training loss: 0.8967513474347147
Validation loss: 2.413891297293048

Epoch: 5| Step: 3
Training loss: 1.173929422739574
Validation loss: 2.4336278906393587

Epoch: 5| Step: 4
Training loss: 1.8612146973448354
Validation loss: 2.4384869233233015

Epoch: 5| Step: 5
Training loss: 1.0625656332052031
Validation loss: 2.463974938770195

Epoch: 5| Step: 6
Training loss: 0.9067159638665251
Validation loss: 2.389233690404031

Epoch: 5| Step: 7
Training loss: 0.7670075526008627
Validation loss: 2.364040759370751

Epoch: 5| Step: 8
Training loss: 0.766067143662315
Validation loss: 2.495853736891691

Epoch: 5| Step: 9
Training loss: 0.6804882024881739
Validation loss: 2.4936212563649587

Epoch: 5| Step: 10
Training loss: 0.5031704816933692
Validation loss: 2.353911066803721

Epoch: 498| Step: 0
Training loss: 0.563624820344566
Validation loss: 2.504597450205495

Epoch: 5| Step: 1
Training loss: 0.8127792318737727
Validation loss: 2.532087545255741

Epoch: 5| Step: 2
Training loss: 0.7974999539007575
Validation loss: 2.4935892345704027

Epoch: 5| Step: 3
Training loss: 0.7072113819278735
Validation loss: 2.470056568394903

Epoch: 5| Step: 4
Training loss: 1.1543207827704687
Validation loss: 2.540071461569922

Epoch: 5| Step: 5
Training loss: 0.9944043961836724
Validation loss: 2.380509882740512

Epoch: 5| Step: 6
Training loss: 0.8212279524957289
Validation loss: 2.457846708262872

Epoch: 5| Step: 7
Training loss: 0.8814398297325949
Validation loss: 2.503538965743724

Epoch: 5| Step: 8
Training loss: 0.7582213095479607
Validation loss: 2.409424316902559

Epoch: 5| Step: 9
Training loss: 1.6304140865007524
Validation loss: 2.376016097222905

Epoch: 5| Step: 10
Training loss: 0.755776610266557
Validation loss: 2.4660002635401472

Epoch: 499| Step: 0
Training loss: 1.1493403201241192
Validation loss: 2.4279982407326273

Epoch: 5| Step: 1
Training loss: 0.916842252358434
Validation loss: 2.44015564407141

Epoch: 5| Step: 2
Training loss: 0.7960105770189513
Validation loss: 2.474744973540768

Epoch: 5| Step: 3
Training loss: 0.7448362768369283
Validation loss: 2.3948501524177366

Epoch: 5| Step: 4
Training loss: 0.8674359352355516
Validation loss: 2.4678373611233573

Epoch: 5| Step: 5
Training loss: 1.5749502446626185
Validation loss: 2.4585329693935845

Epoch: 5| Step: 6
Training loss: 0.82506998227702
Validation loss: 2.5298814870867172

Epoch: 5| Step: 7
Training loss: 1.2109730376904788
Validation loss: 2.4213035414748396

Epoch: 5| Step: 8
Training loss: 0.8339404199528087
Validation loss: 2.447306688736102

Epoch: 5| Step: 9
Training loss: 0.8467235795802149
Validation loss: 2.418218395255484

Epoch: 5| Step: 10
Training loss: 1.0705498202551413
Validation loss: 2.554509435953731

Epoch: 500| Step: 0
Training loss: 1.023349787324054
Validation loss: 2.3861826839825393

Epoch: 5| Step: 1
Training loss: 0.7800236804742051
Validation loss: 2.400457479344488

Epoch: 5| Step: 2
Training loss: 1.035567694893232
Validation loss: 2.464013213475874

Epoch: 5| Step: 3
Training loss: 1.0688295323633297
Validation loss: 2.4186994249862988

Epoch: 5| Step: 4
Training loss: 0.9335918665910821
Validation loss: 2.4799109165868507

Epoch: 5| Step: 5
Training loss: 1.6490653049314297
Validation loss: 2.4268996572216266

Epoch: 5| Step: 6
Training loss: 1.0076328679354818
Validation loss: 2.511085370812689

Epoch: 5| Step: 7
Training loss: 0.7405528890536774
Validation loss: 2.5046561596704264

Epoch: 5| Step: 8
Training loss: 0.9819865845542738
Validation loss: 2.4822788467280326

Epoch: 5| Step: 9
Training loss: 0.6645656026270722
Validation loss: 2.4524406971524306

Epoch: 5| Step: 10
Training loss: 0.959763996649212
Validation loss: 2.4511793938461692

Epoch: 501| Step: 0
Training loss: 0.9343081179255852
Validation loss: 2.4352054660758804

Epoch: 5| Step: 1
Training loss: 0.7106918497439738
Validation loss: 2.4465653728136556

Epoch: 5| Step: 2
Training loss: 1.088503652879283
Validation loss: 2.4315434154049154

Epoch: 5| Step: 3
Training loss: 0.7708216271070029
Validation loss: 2.450641847521864

Epoch: 5| Step: 4
Training loss: 0.6359833993679566
Validation loss: 2.3934323141624643

Epoch: 5| Step: 5
Training loss: 1.2730393050449507
Validation loss: 2.4580895334456443

Epoch: 5| Step: 6
Training loss: 0.9312855425714893
Validation loss: 2.4813183336660476

Epoch: 5| Step: 7
Training loss: 0.6818135214415135
Validation loss: 2.434191779756749

Epoch: 5| Step: 8
Training loss: 0.8925537506715377
Validation loss: 2.4968172479049624

Epoch: 5| Step: 9
Training loss: 0.8609684476465238
Validation loss: 2.5097422557885745

Epoch: 5| Step: 10
Training loss: 1.9972653767051967
Validation loss: 2.503197659994958

Epoch: 502| Step: 0
Training loss: 1.1993281907831372
Validation loss: 2.4135729515736863

Epoch: 5| Step: 1
Training loss: 0.7589949202185358
Validation loss: 2.4513554458113225

Epoch: 5| Step: 2
Training loss: 0.9313641023818756
Validation loss: 2.442216174249601

Epoch: 5| Step: 3
Training loss: 0.9986011138248172
Validation loss: 2.3696078734382153

Epoch: 5| Step: 4
Training loss: 0.7801873418601091
Validation loss: 2.491134379385575

Epoch: 5| Step: 5
Training loss: 0.9161870344626485
Validation loss: 2.427134665458171

Epoch: 5| Step: 6
Training loss: 0.7518700095476423
Validation loss: 2.4840528251269824

Epoch: 5| Step: 7
Training loss: 0.6642968605720727
Validation loss: 2.4301249077358955

Epoch: 5| Step: 8
Training loss: 0.8212435570265258
Validation loss: 2.4989190933565015

Epoch: 5| Step: 9
Training loss: 1.9648468442251668
Validation loss: 2.4640241426799805

Epoch: 5| Step: 10
Training loss: 0.8407676405585918
Validation loss: 2.449427655477998

Epoch: 503| Step: 0
Training loss: 0.8370766053436529
Validation loss: 2.474635408987803

Epoch: 5| Step: 1
Training loss: 0.6927490341925935
Validation loss: 2.4922439054991115

Epoch: 5| Step: 2
Training loss: 0.6992632036623
Validation loss: 2.4770935784153076

Epoch: 5| Step: 3
Training loss: 0.8976708831789598
Validation loss: 2.4721462792606097

Epoch: 5| Step: 4
Training loss: 0.9935684206152018
Validation loss: 2.379199321825798

Epoch: 5| Step: 5
Training loss: 0.7219431477536229
Validation loss: 2.4025558926255726

Epoch: 5| Step: 6
Training loss: 0.6574354817460732
Validation loss: 2.4872686893526

Epoch: 5| Step: 7
Training loss: 0.5931471977059646
Validation loss: 2.4605324574133514

Epoch: 5| Step: 8
Training loss: 0.5520566957873231
Validation loss: 2.543791467460101

Epoch: 5| Step: 9
Training loss: 1.991974942704672
Validation loss: 2.408398725074141

Epoch: 5| Step: 10
Training loss: 0.7321453742406023
Validation loss: 2.4960590053103604

Epoch: 504| Step: 0
Training loss: 0.9590051652631989
Validation loss: 2.4795334205956214

Epoch: 5| Step: 1
Training loss: 1.729138898818033
Validation loss: 2.4069410646723814

Epoch: 5| Step: 2
Training loss: 0.8670731202721241
Validation loss: 2.3430773179209403

Epoch: 5| Step: 3
Training loss: 1.1573479568613052
Validation loss: 2.517403998447493

Epoch: 5| Step: 4
Training loss: 0.7875789254616513
Validation loss: 2.399219584907571

Epoch: 5| Step: 5
Training loss: 0.9957960993032066
Validation loss: 2.4569440795203414

Epoch: 5| Step: 6
Training loss: 0.7729732006061307
Validation loss: 2.4399913847973083

Epoch: 5| Step: 7
Training loss: 1.0701068207192863
Validation loss: 2.4645561951628787

Epoch: 5| Step: 8
Training loss: 0.6974621450413206
Validation loss: 2.4184723714472067

Epoch: 5| Step: 9
Training loss: 0.8038680709803612
Validation loss: 2.414360298022209

Epoch: 5| Step: 10
Training loss: 0.7558366244734077
Validation loss: 2.609308328526537

Epoch: 505| Step: 0
Training loss: 0.7966476564919118
Validation loss: 2.5192786595456442

Epoch: 5| Step: 1
Training loss: 0.8224179088358831
Validation loss: 2.4618033978828007

Epoch: 5| Step: 2
Training loss: 0.9569619289905386
Validation loss: 2.461139667135167

Epoch: 5| Step: 3
Training loss: 0.7530079762567017
Validation loss: 2.496592758321664

Epoch: 5| Step: 4
Training loss: 0.8915022160646427
Validation loss: 2.530927178952161

Epoch: 5| Step: 5
Training loss: 0.8419340159143266
Validation loss: 2.5476052627457237

Epoch: 5| Step: 6
Training loss: 0.773944649932644
Validation loss: 2.431580116760228

Epoch: 5| Step: 7
Training loss: 1.0512110175163587
Validation loss: 2.4459307862401496

Epoch: 5| Step: 8
Training loss: 1.732035665889302
Validation loss: 2.4810637633978407

Epoch: 5| Step: 9
Training loss: 1.1429290493414774
Validation loss: 2.4117989613252466

Epoch: 5| Step: 10
Training loss: 0.7590826735597477
Validation loss: 2.4225975660329566

Epoch: 506| Step: 0
Training loss: 0.9444625122704436
Validation loss: 2.4357443682556235

Epoch: 5| Step: 1
Training loss: 0.9195848240312375
Validation loss: 2.483399805312291

Epoch: 5| Step: 2
Training loss: 0.8902065565676418
Validation loss: 2.4471670000807264

Epoch: 5| Step: 3
Training loss: 0.9718878288280949
Validation loss: 2.483528328820207

Epoch: 5| Step: 4
Training loss: 0.8294775012795325
Validation loss: 2.4463178157805214

Epoch: 5| Step: 5
Training loss: 0.7858278808593371
Validation loss: 2.5001769157077036

Epoch: 5| Step: 6
Training loss: 0.673821623397642
Validation loss: 2.4214377906724103

Epoch: 5| Step: 7
Training loss: 0.9469946719546418
Validation loss: 2.4128068355091106

Epoch: 5| Step: 8
Training loss: 0.9462671424996036
Validation loss: 2.446765622930886

Epoch: 5| Step: 9
Training loss: 1.6971564043764904
Validation loss: 2.482397240433343

Epoch: 5| Step: 10
Training loss: 0.6902161609295225
Validation loss: 2.4079260556318505

Epoch: 507| Step: 0
Training loss: 1.6690061679769543
Validation loss: 2.4400748112562303

Epoch: 5| Step: 1
Training loss: 1.0034422043149833
Validation loss: 2.4410428871062306

Epoch: 5| Step: 2
Training loss: 0.7796347896517256
Validation loss: 2.422046648149137

Epoch: 5| Step: 3
Training loss: 0.7783244861600964
Validation loss: 2.452738475217181

Epoch: 5| Step: 4
Training loss: 0.8230234310249328
Validation loss: 2.4784274372316286

Epoch: 5| Step: 5
Training loss: 0.8026014528882593
Validation loss: 2.370547524014152

Epoch: 5| Step: 6
Training loss: 0.7083881487860417
Validation loss: 2.4579718400299053

Epoch: 5| Step: 7
Training loss: 1.4756067805960917
Validation loss: 2.5115505090649135

Epoch: 5| Step: 8
Training loss: 1.0095835656262764
Validation loss: 2.427031759465574

Epoch: 5| Step: 9
Training loss: 0.8754703756055525
Validation loss: 2.390435787388289

Epoch: 5| Step: 10
Training loss: 0.7345595432294365
Validation loss: 2.4481040816519055

Epoch: 508| Step: 0
Training loss: 0.7978497321902774
Validation loss: 2.3866961658219505

Epoch: 5| Step: 1
Training loss: 0.7856251469432174
Validation loss: 2.427720695787523

Epoch: 5| Step: 2
Training loss: 1.0900314333521768
Validation loss: 2.4963407870372967

Epoch: 5| Step: 3
Training loss: 0.870692002236956
Validation loss: 2.4186048836343086

Epoch: 5| Step: 4
Training loss: 1.6232749879653647
Validation loss: 2.500547853553391

Epoch: 5| Step: 5
Training loss: 0.8173946256706839
Validation loss: 2.4185521528960954

Epoch: 5| Step: 6
Training loss: 0.6121056824982356
Validation loss: 2.497384485409753

Epoch: 5| Step: 7
Training loss: 1.3868897668397027
Validation loss: 2.3694690977479897

Epoch: 5| Step: 8
Training loss: 0.7637006749334846
Validation loss: 2.5220944199371145

Epoch: 5| Step: 9
Training loss: 0.7764862161237047
Validation loss: 2.4370363100490073

Epoch: 5| Step: 10
Training loss: 1.1410170103572075
Validation loss: 2.408580630978776

Epoch: 509| Step: 0
Training loss: 0.9289739739680534
Validation loss: 2.4244425363435607

Epoch: 5| Step: 1
Training loss: 0.8712431775213172
Validation loss: 2.469812623744612

Epoch: 5| Step: 2
Training loss: 1.1772475620357135
Validation loss: 2.4239201247101962

Epoch: 5| Step: 3
Training loss: 0.7163892205230877
Validation loss: 2.414182751363868

Epoch: 5| Step: 4
Training loss: 0.6901549746445662
Validation loss: 2.520094322250037

Epoch: 5| Step: 5
Training loss: 1.960701734496222
Validation loss: 2.427744067827461

Epoch: 5| Step: 6
Training loss: 0.9049512172428381
Validation loss: 2.4399912324492687

Epoch: 5| Step: 7
Training loss: 0.7023980939673065
Validation loss: 2.463322594841933

Epoch: 5| Step: 8
Training loss: 1.0247871875813692
Validation loss: 2.400410086195109

Epoch: 5| Step: 9
Training loss: 0.8842980705203944
Validation loss: 2.4192033441686682

Epoch: 5| Step: 10
Training loss: 0.8049207553006011
Validation loss: 2.4749100917902718

Epoch: 510| Step: 0
Training loss: 0.7670013357247829
Validation loss: 2.4994274160500662

Epoch: 5| Step: 1
Training loss: 0.4444234908482653
Validation loss: 2.409344142757027

Epoch: 5| Step: 2
Training loss: 0.9217075907110416
Validation loss: 2.3744220122088904

Epoch: 5| Step: 3
Training loss: 1.5378231732394005
Validation loss: 2.3942870840789485

Epoch: 5| Step: 4
Training loss: 0.9258935272765109
Validation loss: 2.431611652566549

Epoch: 5| Step: 5
Training loss: 0.9715487137899503
Validation loss: 2.412929614358571

Epoch: 5| Step: 6
Training loss: 0.8000089317061599
Validation loss: 2.4866967791106176

Epoch: 5| Step: 7
Training loss: 0.7420140113844349
Validation loss: 2.4185681332496674

Epoch: 5| Step: 8
Training loss: 0.9089198740003173
Validation loss: 2.4432742423190863

Epoch: 5| Step: 9
Training loss: 1.1569897115541745
Validation loss: 2.3709134650308306

Epoch: 5| Step: 10
Training loss: 0.6824139250110454
Validation loss: 2.4661330681782863

Epoch: 511| Step: 0
Training loss: 0.6621024882540769
Validation loss: 2.501121214197201

Epoch: 5| Step: 1
Training loss: 0.9156684136107279
Validation loss: 2.412607050199653

Epoch: 5| Step: 2
Training loss: 1.1265827277665104
Validation loss: 2.5186622305707504

Epoch: 5| Step: 3
Training loss: 1.8756005914733955
Validation loss: 2.47201919611122

Epoch: 5| Step: 4
Training loss: 0.8504407651503127
Validation loss: 2.388728887473774

Epoch: 5| Step: 5
Training loss: 0.9875867008826384
Validation loss: 2.447166683706927

Epoch: 5| Step: 6
Training loss: 0.6972975309535847
Validation loss: 2.468225070509312

Epoch: 5| Step: 7
Training loss: 0.8739024158423002
Validation loss: 2.4670751333507157

Epoch: 5| Step: 8
Training loss: 1.0474418130523273
Validation loss: 2.4596792652846737

Epoch: 5| Step: 9
Training loss: 0.8294471766235306
Validation loss: 2.4388816668132645

Epoch: 5| Step: 10
Training loss: 0.8681500908979278
Validation loss: 2.4254699737705576

Epoch: 512| Step: 0
Training loss: 0.7823910200993246
Validation loss: 2.3826190839727794

Epoch: 5| Step: 1
Training loss: 0.8142553221915437
Validation loss: 2.3832705650035453

Epoch: 5| Step: 2
Training loss: 0.7975358653598842
Validation loss: 2.4167674997981923

Epoch: 5| Step: 3
Training loss: 0.8153410172364215
Validation loss: 2.5150962849257716

Epoch: 5| Step: 4
Training loss: 0.9729229052150985
Validation loss: 2.4366050541321402

Epoch: 5| Step: 5
Training loss: 0.8083726516153918
Validation loss: 2.426346161277544

Epoch: 5| Step: 6
Training loss: 1.6738378108310774
Validation loss: 2.484954362954758

Epoch: 5| Step: 7
Training loss: 1.3215832886647245
Validation loss: 2.458812037836396

Epoch: 5| Step: 8
Training loss: 1.0106107322237758
Validation loss: 2.413111583480991

Epoch: 5| Step: 9
Training loss: 0.8013035257347364
Validation loss: 2.472498283607938

Epoch: 5| Step: 10
Training loss: 0.8245444354892852
Validation loss: 2.4718087218746803

Epoch: 513| Step: 0
Training loss: 0.78847640526302
Validation loss: 2.4239279935566875

Epoch: 5| Step: 1
Training loss: 0.9183298577579239
Validation loss: 2.4213830274189876

Epoch: 5| Step: 2
Training loss: 0.9035706869022162
Validation loss: 2.4759900333420566

Epoch: 5| Step: 3
Training loss: 1.793736245770506
Validation loss: 2.464810734962893

Epoch: 5| Step: 4
Training loss: 0.5378635729356707
Validation loss: 2.4770392005734294

Epoch: 5| Step: 5
Training loss: 1.0284847986547214
Validation loss: 2.498629434274006

Epoch: 5| Step: 6
Training loss: 0.5322497721519717
Validation loss: 2.442929354154557

Epoch: 5| Step: 7
Training loss: 0.9959506960599964
Validation loss: 2.456212405452732

Epoch: 5| Step: 8
Training loss: 0.5922757971166462
Validation loss: 2.4040897465063567

Epoch: 5| Step: 9
Training loss: 0.8285606605847186
Validation loss: 2.4658461733883064

Epoch: 5| Step: 10
Training loss: 1.0141033805048272
Validation loss: 2.437768910280469

Epoch: 514| Step: 0
Training loss: 0.9302218848790216
Validation loss: 2.4558527333201274

Epoch: 5| Step: 1
Training loss: 0.6576047718857638
Validation loss: 2.458508638736366

Epoch: 5| Step: 2
Training loss: 0.9786758748482302
Validation loss: 2.472269967100397

Epoch: 5| Step: 3
Training loss: 0.8665529283448218
Validation loss: 2.3829639205819078

Epoch: 5| Step: 4
Training loss: 0.8465583828769293
Validation loss: 2.411648956300585

Epoch: 5| Step: 5
Training loss: 0.8983513168794954
Validation loss: 2.3987388289277933

Epoch: 5| Step: 6
Training loss: 0.9041244309459294
Validation loss: 2.4563805478726657

Epoch: 5| Step: 7
Training loss: 0.8434444863368201
Validation loss: 2.431558317737028

Epoch: 5| Step: 8
Training loss: 1.7309501443357354
Validation loss: 2.4730249746327497

Epoch: 5| Step: 9
Training loss: 0.8261562192619403
Validation loss: 2.396957834085257

Epoch: 5| Step: 10
Training loss: 0.6652673449944838
Validation loss: 2.5042862838517137

Epoch: 515| Step: 0
Training loss: 1.635565376404864
Validation loss: 2.4263121110064123

Epoch: 5| Step: 1
Training loss: 0.6975179263856912
Validation loss: 2.4883440152446514

Epoch: 5| Step: 2
Training loss: 1.104915844573734
Validation loss: 2.501814294640388

Epoch: 5| Step: 3
Training loss: 1.1877030148889212
Validation loss: 2.435921702044666

Epoch: 5| Step: 4
Training loss: 1.0718014794762465
Validation loss: 2.491088939837258

Epoch: 5| Step: 5
Training loss: 0.8499084297110426
Validation loss: 2.4553918323748527

Epoch: 5| Step: 6
Training loss: 0.6692145703684207
Validation loss: 2.46019100984666

Epoch: 5| Step: 7
Training loss: 0.903691428991924
Validation loss: 2.475195238175823

Epoch: 5| Step: 8
Training loss: 0.607388388149178
Validation loss: 2.3849308290987334

Epoch: 5| Step: 9
Training loss: 0.8625787491714517
Validation loss: 2.46688327019818

Epoch: 5| Step: 10
Training loss: 0.886755988729692
Validation loss: 2.462482578987816

Epoch: 516| Step: 0
Training loss: 1.157595238526602
Validation loss: 2.416654139802041

Epoch: 5| Step: 1
Training loss: 0.8575078968874483
Validation loss: 2.4842936721195965

Epoch: 5| Step: 2
Training loss: 0.7116556836858292
Validation loss: 2.4159936791748637

Epoch: 5| Step: 3
Training loss: 0.9140202439151012
Validation loss: 2.4590761728471557

Epoch: 5| Step: 4
Training loss: 1.0235245645777773
Validation loss: 2.4557753401679623

Epoch: 5| Step: 5
Training loss: 0.8083327604730942
Validation loss: 2.34856060125909

Epoch: 5| Step: 6
Training loss: 0.8504726540319771
Validation loss: 2.473516341634861

Epoch: 5| Step: 7
Training loss: 1.6890779111654923
Validation loss: 2.451673861355901

Epoch: 5| Step: 8
Training loss: 0.8227691920640496
Validation loss: 2.4359310907676353

Epoch: 5| Step: 9
Training loss: 0.7037380089424295
Validation loss: 2.4792003558641107

Epoch: 5| Step: 10
Training loss: 0.992071700660109
Validation loss: 2.3887431967235155

Epoch: 517| Step: 0
Training loss: 0.9604206090640717
Validation loss: 2.439409583394032

Epoch: 5| Step: 1
Training loss: 0.8221796856185868
Validation loss: 2.4219898123888424

Epoch: 5| Step: 2
Training loss: 1.6174114274975184
Validation loss: 2.392210308546071

Epoch: 5| Step: 3
Training loss: 0.7023511230624884
Validation loss: 2.389986566758201

Epoch: 5| Step: 4
Training loss: 0.7533571289180925
Validation loss: 2.4625036123517963

Epoch: 5| Step: 5
Training loss: 0.796596628073821
Validation loss: 2.5153084832695862

Epoch: 5| Step: 6
Training loss: 0.8554076429864457
Validation loss: 2.4098311646260786

Epoch: 5| Step: 7
Training loss: 0.9870261564450938
Validation loss: 2.4165530010079497

Epoch: 5| Step: 8
Training loss: 0.7983911340318702
Validation loss: 2.3662433713205786

Epoch: 5| Step: 9
Training loss: 0.794820493189527
Validation loss: 2.467902775837252

Epoch: 5| Step: 10
Training loss: 0.8835655646377932
Validation loss: 2.407266847043386

Epoch: 518| Step: 0
Training loss: 0.4486022699677056
Validation loss: 2.397091605121135

Epoch: 5| Step: 1
Training loss: 0.6994998729043099
Validation loss: 2.4216358713790083

Epoch: 5| Step: 2
Training loss: 1.0759385093043832
Validation loss: 2.4718808827256895

Epoch: 5| Step: 3
Training loss: 1.7426521126509813
Validation loss: 2.4661754518838332

Epoch: 5| Step: 4
Training loss: 1.002805053930553
Validation loss: 2.373222130362521

Epoch: 5| Step: 5
Training loss: 0.6594958642044706
Validation loss: 2.4807176982612162

Epoch: 5| Step: 6
Training loss: 0.8847435954806101
Validation loss: 2.374097663478072

Epoch: 5| Step: 7
Training loss: 1.24553172671944
Validation loss: 2.4176953883984145

Epoch: 5| Step: 8
Training loss: 1.024542292305166
Validation loss: 2.4783649877026517

Epoch: 5| Step: 9
Training loss: 0.908079996273769
Validation loss: 2.5004593806539774

Epoch: 5| Step: 10
Training loss: 0.9406140108195317
Validation loss: 2.447786765927206

Epoch: 519| Step: 0
Training loss: 0.6801927157756495
Validation loss: 2.389559084636949

Epoch: 5| Step: 1
Training loss: 0.6956931368899579
Validation loss: 2.4483403963430397

Epoch: 5| Step: 2
Training loss: 0.7227767431483225
Validation loss: 2.3863712610537475

Epoch: 5| Step: 3
Training loss: 0.984516527204762
Validation loss: 2.4906364194546677

Epoch: 5| Step: 4
Training loss: 1.6330479356325867
Validation loss: 2.435707224962174

Epoch: 5| Step: 5
Training loss: 0.930654007335994
Validation loss: 2.4783447455479215

Epoch: 5| Step: 6
Training loss: 0.6444814258159943
Validation loss: 2.5814597003747535

Epoch: 5| Step: 7
Training loss: 0.7999657549085065
Validation loss: 2.489566759845606

Epoch: 5| Step: 8
Training loss: 1.1973697187715628
Validation loss: 2.487907510514661

Epoch: 5| Step: 9
Training loss: 0.7569392570605613
Validation loss: 2.4644373989493045

Epoch: 5| Step: 10
Training loss: 0.8400932473696733
Validation loss: 2.457969866691582

Epoch: 520| Step: 0
Training loss: 1.141708277665658
Validation loss: 2.390980495096146

Epoch: 5| Step: 1
Training loss: 0.9614626062256223
Validation loss: 2.433286694475712

Epoch: 5| Step: 2
Training loss: 0.6978466701042472
Validation loss: 2.451153664528841

Epoch: 5| Step: 3
Training loss: 0.6704904128988657
Validation loss: 2.541266563335764

Epoch: 5| Step: 4
Training loss: 0.6955199628634736
Validation loss: 2.4451691693840756

Epoch: 5| Step: 5
Training loss: 0.7396059211899335
Validation loss: 2.474539004164266

Epoch: 5| Step: 6
Training loss: 0.8731724864195155
Validation loss: 2.4474481511742527

Epoch: 5| Step: 7
Training loss: 0.911553681245608
Validation loss: 2.4616347182582463

Epoch: 5| Step: 8
Training loss: 1.0450493565452599
Validation loss: 2.5154793947557366

Epoch: 5| Step: 9
Training loss: 0.9120239609908546
Validation loss: 2.377176137336703

Epoch: 5| Step: 10
Training loss: 1.6561012201242402
Validation loss: 2.448007310084957

Epoch: 521| Step: 0
Training loss: 0.529782399816418
Validation loss: 2.445798912867582

Epoch: 5| Step: 1
Training loss: 0.7194574440412136
Validation loss: 2.4491863475923057

Epoch: 5| Step: 2
Training loss: 0.856844592567001
Validation loss: 2.3905209540059515

Epoch: 5| Step: 3
Training loss: 0.8053801435098816
Validation loss: 2.440437940115055

Epoch: 5| Step: 4
Training loss: 1.3089664668603036
Validation loss: 2.450540403101578

Epoch: 5| Step: 5
Training loss: 1.7995207837413114
Validation loss: 2.3611215061181703

Epoch: 5| Step: 6
Training loss: 0.7604115542583966
Validation loss: 2.498846475008858

Epoch: 5| Step: 7
Training loss: 0.7752377529929891
Validation loss: 2.550020354380917

Epoch: 5| Step: 8
Training loss: 0.9072507397209004
Validation loss: 2.4537565775427947

Epoch: 5| Step: 9
Training loss: 0.6257967638623937
Validation loss: 2.489289345212854

Epoch: 5| Step: 10
Training loss: 0.8012546163655095
Validation loss: 2.4109264935369095

Epoch: 522| Step: 0
Training loss: 0.726645352141398
Validation loss: 2.4240595930553317

Epoch: 5| Step: 1
Training loss: 0.9496797297851175
Validation loss: 2.4379550718335374

Epoch: 5| Step: 2
Training loss: 0.93838084483991
Validation loss: 2.424168867318337

Epoch: 5| Step: 3
Training loss: 0.9666980423165321
Validation loss: 2.477611939072238

Epoch: 5| Step: 4
Training loss: 0.9889430969866801
Validation loss: 2.4760790906553134

Epoch: 5| Step: 5
Training loss: 0.9592345119336473
Validation loss: 2.514805649055321

Epoch: 5| Step: 6
Training loss: 0.7103414447222247
Validation loss: 2.4891278071600595

Epoch: 5| Step: 7
Training loss: 1.6195848175479077
Validation loss: 2.4002137635428187

Epoch: 5| Step: 8
Training loss: 0.6436669305332986
Validation loss: 2.4292039820401308

Epoch: 5| Step: 9
Training loss: 1.1083297640998753
Validation loss: 2.4707179369213534

Epoch: 5| Step: 10
Training loss: 0.7944216642322272
Validation loss: 2.4358268487600574

Epoch: 523| Step: 0
Training loss: 0.9656555528961359
Validation loss: 2.485632320996643

Epoch: 5| Step: 1
Training loss: 1.1327077882976015
Validation loss: 2.4739121962661708

Epoch: 5| Step: 2
Training loss: 1.0051352255265151
Validation loss: 2.4438208311342295

Epoch: 5| Step: 3
Training loss: 0.42427478932984647
Validation loss: 2.4228813988691176

Epoch: 5| Step: 4
Training loss: 0.902146817470367
Validation loss: 2.4352139379943343

Epoch: 5| Step: 5
Training loss: 0.8540103970995827
Validation loss: 2.4101229230064014

Epoch: 5| Step: 6
Training loss: 0.7799024404133202
Validation loss: 2.500175136666366

Epoch: 5| Step: 7
Training loss: 1.6551813960859318
Validation loss: 2.463441892305449

Epoch: 5| Step: 8
Training loss: 0.8900474884458077
Validation loss: 2.4844544719755617

Epoch: 5| Step: 9
Training loss: 0.749003224802651
Validation loss: 2.3826602504538315

Epoch: 5| Step: 10
Training loss: 0.7928530228076949
Validation loss: 2.4120265117958133

Epoch: 524| Step: 0
Training loss: 0.5468010988711385
Validation loss: 2.417094794919345

Epoch: 5| Step: 1
Training loss: 0.9842703627421971
Validation loss: 2.448518663756776

Epoch: 5| Step: 2
Training loss: 0.7361748735734575
Validation loss: 2.4158661110072006

Epoch: 5| Step: 3
Training loss: 0.806171123579333
Validation loss: 2.3620267245651365

Epoch: 5| Step: 4
Training loss: 0.7835223149211713
Validation loss: 2.441727781456637

Epoch: 5| Step: 5
Training loss: 0.7575202063581697
Validation loss: 2.4300874992074926

Epoch: 5| Step: 6
Training loss: 0.94739246895591
Validation loss: 2.443123190795859

Epoch: 5| Step: 7
Training loss: 1.2051683883619524
Validation loss: 2.4051145493673602

Epoch: 5| Step: 8
Training loss: 0.7260439673395981
Validation loss: 2.4128263580592697

Epoch: 5| Step: 9
Training loss: 1.6023419228129057
Validation loss: 2.437413041862022

Epoch: 5| Step: 10
Training loss: 0.9755911917635661
Validation loss: 2.5007454775859377

Epoch: 525| Step: 0
Training loss: 0.8479914551790252
Validation loss: 2.4787845504949426

Epoch: 5| Step: 1
Training loss: 0.6777817987125583
Validation loss: 2.4967868234357833

Epoch: 5| Step: 2
Training loss: 0.8327163597854551
Validation loss: 2.4511128226508

Epoch: 5| Step: 3
Training loss: 1.6141117350629175
Validation loss: 2.4539787301861065

Epoch: 5| Step: 4
Training loss: 0.8652654431278461
Validation loss: 2.5030746810702023

Epoch: 5| Step: 5
Training loss: 0.8241974163458322
Validation loss: 2.4269506453494514

Epoch: 5| Step: 6
Training loss: 0.7728585667807328
Validation loss: 2.462115687140294

Epoch: 5| Step: 7
Training loss: 1.1557790467253
Validation loss: 2.386337797407421

Epoch: 5| Step: 8
Training loss: 0.9024865834197847
Validation loss: 2.4177369236163035

Epoch: 5| Step: 9
Training loss: 0.913944791078001
Validation loss: 2.483101262159128

Epoch: 5| Step: 10
Training loss: 0.7162778882893555
Validation loss: 2.4244403242314667

Epoch: 526| Step: 0
Training loss: 0.9789943475803623
Validation loss: 2.45685431189607

Epoch: 5| Step: 1
Training loss: 0.6518241960546232
Validation loss: 2.391344318645979

Epoch: 5| Step: 2
Training loss: 1.1263145607788208
Validation loss: 2.4704951240792665

Epoch: 5| Step: 3
Training loss: 0.9943992113562178
Validation loss: 2.4299948225308445

Epoch: 5| Step: 4
Training loss: 0.9092917204277403
Validation loss: 2.493551251400069

Epoch: 5| Step: 5
Training loss: 0.8327588047946676
Validation loss: 2.41444031090977

Epoch: 5| Step: 6
Training loss: 0.7130078363081579
Validation loss: 2.4726087077710095

Epoch: 5| Step: 7
Training loss: 0.5878647960172284
Validation loss: 2.412840729993522

Epoch: 5| Step: 8
Training loss: 1.5769207580434843
Validation loss: 2.4448666756372566

Epoch: 5| Step: 9
Training loss: 0.8722332057916001
Validation loss: 2.3798558459363064

Epoch: 5| Step: 10
Training loss: 0.8425632183682251
Validation loss: 2.4994996985388345

Epoch: 527| Step: 0
Training loss: 0.6781147266084385
Validation loss: 2.463445155857852

Epoch: 5| Step: 1
Training loss: 0.7627743180661031
Validation loss: 2.4041132320462175

Epoch: 5| Step: 2
Training loss: 0.4278455267586419
Validation loss: 2.4888134283897916

Epoch: 5| Step: 3
Training loss: 1.0789730772278086
Validation loss: 2.4230514162020675

Epoch: 5| Step: 4
Training loss: 0.7962224569901758
Validation loss: 2.481132973267719

Epoch: 5| Step: 5
Training loss: 0.9309198562368913
Validation loss: 2.355816106384145

Epoch: 5| Step: 6
Training loss: 0.6932719645674703
Validation loss: 2.388058392872609

Epoch: 5| Step: 7
Training loss: 0.7116895617331818
Validation loss: 2.386081894226349

Epoch: 5| Step: 8
Training loss: 0.9375048955153756
Validation loss: 2.3997886715501298

Epoch: 5| Step: 9
Training loss: 0.8299622578255142
Validation loss: 2.457952509172812

Epoch: 5| Step: 10
Training loss: 1.7302312063611096
Validation loss: 2.3309500127616367

Epoch: 528| Step: 0
Training loss: 1.6862672612329732
Validation loss: 2.4425675812311174

Epoch: 5| Step: 1
Training loss: 0.6506744773440241
Validation loss: 2.4365556142717133

Epoch: 5| Step: 2
Training loss: 0.7805391129096407
Validation loss: 2.437236233121292

Epoch: 5| Step: 3
Training loss: 0.6045032062666355
Validation loss: 2.5113277542751264

Epoch: 5| Step: 4
Training loss: 0.6473341137249162
Validation loss: 2.4489381821827387

Epoch: 5| Step: 5
Training loss: 0.9383940883761656
Validation loss: 2.4897793104758392

Epoch: 5| Step: 6
Training loss: 0.8218829063934514
Validation loss: 2.446570191360499

Epoch: 5| Step: 7
Training loss: 0.936370487074441
Validation loss: 2.507297225129303

Epoch: 5| Step: 8
Training loss: 0.7664025698387766
Validation loss: 2.468176999930555

Epoch: 5| Step: 9
Training loss: 0.9640822706869278
Validation loss: 2.4827606617249236

Epoch: 5| Step: 10
Training loss: 0.891161506079514
Validation loss: 2.386290420345196

Epoch: 529| Step: 0
Training loss: 0.9549648787246711
Validation loss: 2.412118725681535

Epoch: 5| Step: 1
Training loss: 0.5348142101656813
Validation loss: 2.380959682731741

Epoch: 5| Step: 2
Training loss: 0.9827403771359463
Validation loss: 2.4471345139349996

Epoch: 5| Step: 3
Training loss: 0.8871520743934412
Validation loss: 2.454145473343658

Epoch: 5| Step: 4
Training loss: 0.6703514301225896
Validation loss: 2.4835634041647574

Epoch: 5| Step: 5
Training loss: 0.844805586982806
Validation loss: 2.422807740526444

Epoch: 5| Step: 6
Training loss: 0.8248428946517901
Validation loss: 2.4190386742633962

Epoch: 5| Step: 7
Training loss: 0.9458582225051151
Validation loss: 2.4656535889411684

Epoch: 5| Step: 8
Training loss: 0.8935643596855279
Validation loss: 2.4141101199930803

Epoch: 5| Step: 9
Training loss: 0.8066237034535271
Validation loss: 2.424353656912829

Epoch: 5| Step: 10
Training loss: 1.701191425758602
Validation loss: 2.4715586291288165

Epoch: 530| Step: 0
Training loss: 0.5847076224162812
Validation loss: 2.5020878221056733

Epoch: 5| Step: 1
Training loss: 1.0964660708235177
Validation loss: 2.4446762417247876

Epoch: 5| Step: 2
Training loss: 0.7888825844085955
Validation loss: 2.4545889408424357

Epoch: 5| Step: 3
Training loss: 0.879283637511072
Validation loss: 2.420578291971098

Epoch: 5| Step: 4
Training loss: 0.7195359783866336
Validation loss: 2.4720435477955336

Epoch: 5| Step: 5
Training loss: 1.0726644472613311
Validation loss: 2.5337820951006624

Epoch: 5| Step: 6
Training loss: 0.711789637028372
Validation loss: 2.5240654252535384

Epoch: 5| Step: 7
Training loss: 0.7626674124368387
Validation loss: 2.440156144159517

Epoch: 5| Step: 8
Training loss: 1.5382904594924531
Validation loss: 2.47649677469279

Epoch: 5| Step: 9
Training loss: 0.7461126035535095
Validation loss: 2.4842458928637927

Epoch: 5| Step: 10
Training loss: 0.936478248755002
Validation loss: 2.482379351457972

Epoch: 531| Step: 0
Training loss: 0.7305745746842753
Validation loss: 2.4788458655292924

Epoch: 5| Step: 1
Training loss: 0.8757841819693687
Validation loss: 2.5056221738076148

Epoch: 5| Step: 2
Training loss: 0.7576288610327577
Validation loss: 2.456339865438672

Epoch: 5| Step: 3
Training loss: 0.6293391757531585
Validation loss: 2.430207651751629

Epoch: 5| Step: 4
Training loss: 1.146921779499679
Validation loss: 2.504752007146087

Epoch: 5| Step: 5
Training loss: 1.0075918739778649
Validation loss: 2.46823095242008

Epoch: 5| Step: 6
Training loss: 0.7652715528880771
Validation loss: 2.4473447359772402

Epoch: 5| Step: 7
Training loss: 1.6933845773337222
Validation loss: 2.4591812620165148

Epoch: 5| Step: 8
Training loss: 0.7622343616851949
Validation loss: 2.4790935623635852

Epoch: 5| Step: 9
Training loss: 0.7991446541813187
Validation loss: 2.390316747011156

Epoch: 5| Step: 10
Training loss: 0.6722662252437875
Validation loss: 2.5116404489588353

Epoch: 532| Step: 0
Training loss: 0.8669338714587477
Validation loss: 2.3978411589261266

Epoch: 5| Step: 1
Training loss: 0.8343567206848578
Validation loss: 2.497407011487224

Epoch: 5| Step: 2
Training loss: 1.7049280124580581
Validation loss: 2.4071270596535648

Epoch: 5| Step: 3
Training loss: 0.50620420036834
Validation loss: 2.5154632534704056

Epoch: 5| Step: 4
Training loss: 0.8498540065712458
Validation loss: 2.369245612080653

Epoch: 5| Step: 5
Training loss: 0.9084348977612314
Validation loss: 2.454174393378587

Epoch: 5| Step: 6
Training loss: 1.1834656296684096
Validation loss: 2.416080302586554

Epoch: 5| Step: 7
Training loss: 0.8460689044379446
Validation loss: 2.4083273893273676

Epoch: 5| Step: 8
Training loss: 0.9712019929841063
Validation loss: 2.474742969032549

Epoch: 5| Step: 9
Training loss: 0.6736646813352846
Validation loss: 2.48862789433235

Epoch: 5| Step: 10
Training loss: 0.9904953953050072
Validation loss: 2.4121965125303078

Epoch: 533| Step: 0
Training loss: 0.832429638257606
Validation loss: 2.4877314473444314

Epoch: 5| Step: 1
Training loss: 0.9806339383128226
Validation loss: 2.4857961735856873

Epoch: 5| Step: 2
Training loss: 0.7605531038833508
Validation loss: 2.4448640059486855

Epoch: 5| Step: 3
Training loss: 0.8715724228615165
Validation loss: 2.471724162486785

Epoch: 5| Step: 4
Training loss: 1.5219139109812863
Validation loss: 2.523896245016816

Epoch: 5| Step: 5
Training loss: 0.8211583454192303
Validation loss: 2.427177908660851

Epoch: 5| Step: 6
Training loss: 0.9343394728830969
Validation loss: 2.4505491117882507

Epoch: 5| Step: 7
Training loss: 0.7044070952582886
Validation loss: 2.4142640342952024

Epoch: 5| Step: 8
Training loss: 0.7608907258307683
Validation loss: 2.431079541831795

Epoch: 5| Step: 9
Training loss: 0.9153908426887323
Validation loss: 2.446603932448878

Epoch: 5| Step: 10
Training loss: 1.0538801140510126
Validation loss: 2.4869386552525117

Epoch: 534| Step: 0
Training loss: 1.2936637370518618
Validation loss: 2.3835406439739506

Epoch: 5| Step: 1
Training loss: 0.6126598684743523
Validation loss: 2.4650412630974268

Epoch: 5| Step: 2
Training loss: 0.9751841774626998
Validation loss: 2.5011659692464825

Epoch: 5| Step: 3
Training loss: 0.6813383989988733
Validation loss: 2.446440638463302

Epoch: 5| Step: 4
Training loss: 0.5794599173740358
Validation loss: 2.408551442359458

Epoch: 5| Step: 5
Training loss: 0.9543947923028172
Validation loss: 2.4120395806570807

Epoch: 5| Step: 6
Training loss: 1.0959784014063334
Validation loss: 2.4195517679278025

Epoch: 5| Step: 7
Training loss: 0.7505154825020269
Validation loss: 2.4238951853747146

Epoch: 5| Step: 8
Training loss: 0.7373942541831303
Validation loss: 2.4252495423637073

Epoch: 5| Step: 9
Training loss: 1.54182186720168
Validation loss: 2.38407789951822

Epoch: 5| Step: 10
Training loss: 0.7887016075390684
Validation loss: 2.435661986002291

Epoch: 535| Step: 0
Training loss: 0.6630607004658114
Validation loss: 2.3724035865353796

Epoch: 5| Step: 1
Training loss: 1.1022402795236261
Validation loss: 2.4294320085504317

Epoch: 5| Step: 2
Training loss: 0.7660972929064812
Validation loss: 2.388765310264587

Epoch: 5| Step: 3
Training loss: 0.5329304651239184
Validation loss: 2.407785113750006

Epoch: 5| Step: 4
Training loss: 1.7176687827876715
Validation loss: 2.429581302880282

Epoch: 5| Step: 5
Training loss: 0.7420006767845666
Validation loss: 2.4421762174200405

Epoch: 5| Step: 6
Training loss: 0.8864461000691408
Validation loss: 2.4506022969266885

Epoch: 5| Step: 7
Training loss: 0.5645571022227519
Validation loss: 2.45274291633445

Epoch: 5| Step: 8
Training loss: 0.6703569428620496
Validation loss: 2.3729421900653427

Epoch: 5| Step: 9
Training loss: 0.8458380118054318
Validation loss: 2.362785322440763

Epoch: 5| Step: 10
Training loss: 0.8934703349337266
Validation loss: 2.49549178267173

Epoch: 536| Step: 0
Training loss: 1.0112962466535131
Validation loss: 2.5317529345562093

Epoch: 5| Step: 1
Training loss: 0.9403012387028281
Validation loss: 2.4479610686943216

Epoch: 5| Step: 2
Training loss: 0.7167041521101413
Validation loss: 2.4656012005245262

Epoch: 5| Step: 3
Training loss: 0.5790726910192039
Validation loss: 2.4016810693961044

Epoch: 5| Step: 4
Training loss: 0.9195477480125428
Validation loss: 2.4401406345515575

Epoch: 5| Step: 5
Training loss: 1.584129242204976
Validation loss: 2.4147916553420767

Epoch: 5| Step: 6
Training loss: 0.7535620580657526
Validation loss: 2.3995798451610257

Epoch: 5| Step: 7
Training loss: 0.7195742483473005
Validation loss: 2.464483026663962

Epoch: 5| Step: 8
Training loss: 0.9039624050834358
Validation loss: 2.4153829976492074

Epoch: 5| Step: 9
Training loss: 0.7851292619764132
Validation loss: 2.528560645145729

Epoch: 5| Step: 10
Training loss: 1.0222323944672953
Validation loss: 2.445128109592067

Epoch: 537| Step: 0
Training loss: 0.8869879561814006
Validation loss: 2.456140455408192

Epoch: 5| Step: 1
Training loss: 0.9843264976541422
Validation loss: 2.4234507970065042

Epoch: 5| Step: 2
Training loss: 0.8827256016456067
Validation loss: 2.3936062670507594

Epoch: 5| Step: 3
Training loss: 1.1068914848836182
Validation loss: 2.4454040625524236

Epoch: 5| Step: 4
Training loss: 1.6340783428008483
Validation loss: 2.4122848595039095

Epoch: 5| Step: 5
Training loss: 0.7464456976387954
Validation loss: 2.432622008909774

Epoch: 5| Step: 6
Training loss: 0.754447268522249
Validation loss: 2.4573068696176197

Epoch: 5| Step: 7
Training loss: 0.7310182676994236
Validation loss: 2.4362483427670028

Epoch: 5| Step: 8
Training loss: 0.8703849885568189
Validation loss: 2.4696948962727387

Epoch: 5| Step: 9
Training loss: 0.7497469157136095
Validation loss: 2.4384629488053817

Epoch: 5| Step: 10
Training loss: 0.6842354732402781
Validation loss: 2.4953248311907896

Epoch: 538| Step: 0
Training loss: 0.5823247284849407
Validation loss: 2.470728355277919

Epoch: 5| Step: 1
Training loss: 0.6767924686602411
Validation loss: 2.4525399347405052

Epoch: 5| Step: 2
Training loss: 0.9362546278427912
Validation loss: 2.44121367478062

Epoch: 5| Step: 3
Training loss: 0.5820062619164094
Validation loss: 2.417969617280714

Epoch: 5| Step: 4
Training loss: 0.8858370998215171
Validation loss: 2.389724779642208

Epoch: 5| Step: 5
Training loss: 0.9209581438694986
Validation loss: 2.459782090255461

Epoch: 5| Step: 6
Training loss: 1.072814078503455
Validation loss: 2.5100711718714614

Epoch: 5| Step: 7
Training loss: 0.7896425362554467
Validation loss: 2.47458487400126

Epoch: 5| Step: 8
Training loss: 0.9124230574475987
Validation loss: 2.4845299285814355

Epoch: 5| Step: 9
Training loss: 0.7348655928768667
Validation loss: 2.4753653876734796

Epoch: 5| Step: 10
Training loss: 1.854046664122929
Validation loss: 2.3288136072463708

Epoch: 539| Step: 0
Training loss: 0.578765977758412
Validation loss: 2.463486250647571

Epoch: 5| Step: 1
Training loss: 0.909894586368282
Validation loss: 2.4250805227317613

Epoch: 5| Step: 2
Training loss: 0.7995609196086918
Validation loss: 2.44691030010385

Epoch: 5| Step: 3
Training loss: 0.9660287907833518
Validation loss: 2.454320263827752

Epoch: 5| Step: 4
Training loss: 0.980063639686184
Validation loss: 2.3310724328863466

Epoch: 5| Step: 5
Training loss: 0.7103378365894687
Validation loss: 2.4230842294604997

Epoch: 5| Step: 6
Training loss: 0.8678545748848124
Validation loss: 2.409016980115238

Epoch: 5| Step: 7
Training loss: 0.7092525931127056
Validation loss: 2.424297481173391

Epoch: 5| Step: 8
Training loss: 1.6725543771978948
Validation loss: 2.459422573246526

Epoch: 5| Step: 9
Training loss: 0.9375134149227387
Validation loss: 2.434515969967968

Epoch: 5| Step: 10
Training loss: 0.7205051884302226
Validation loss: 2.5000237033089463

Epoch: 540| Step: 0
Training loss: 0.6683484164063611
Validation loss: 2.5238595579914977

Epoch: 5| Step: 1
Training loss: 0.6729879697770232
Validation loss: 2.412603540423298

Epoch: 5| Step: 2
Training loss: 0.8267714757261168
Validation loss: 2.457610128389506

Epoch: 5| Step: 3
Training loss: 0.9903533081621897
Validation loss: 2.453210740752649

Epoch: 5| Step: 4
Training loss: 0.6546139532398746
Validation loss: 2.4769011866593567

Epoch: 5| Step: 5
Training loss: 0.9971627875325988
Validation loss: 2.4421832590399157

Epoch: 5| Step: 6
Training loss: 0.9079239611064939
Validation loss: 2.4168958912370564

Epoch: 5| Step: 7
Training loss: 0.812296878660677
Validation loss: 2.4560333416077094

Epoch: 5| Step: 8
Training loss: 0.7141879883398374
Validation loss: 2.3995586347051283

Epoch: 5| Step: 9
Training loss: 0.7877082155865374
Validation loss: 2.4573457825906173

Epoch: 5| Step: 10
Training loss: 1.6792581408679443
Validation loss: 2.427283912034491

Epoch: 541| Step: 0
Training loss: 0.6456976768600738
Validation loss: 2.4381199987696958

Epoch: 5| Step: 1
Training loss: 0.8470795599019495
Validation loss: 2.4195999611653094

Epoch: 5| Step: 2
Training loss: 1.7227668986174671
Validation loss: 2.4237836564459583

Epoch: 5| Step: 3
Training loss: 0.7206851781249098
Validation loss: 2.5437555415494835

Epoch: 5| Step: 4
Training loss: 0.766506193995722
Validation loss: 2.3856398155714373

Epoch: 5| Step: 5
Training loss: 0.7245877820522394
Validation loss: 2.4575238223762406

Epoch: 5| Step: 6
Training loss: 1.0394174070074016
Validation loss: 2.481406948177889

Epoch: 5| Step: 7
Training loss: 0.89953963638433
Validation loss: 2.4092010015991727

Epoch: 5| Step: 8
Training loss: 0.7616177222916707
Validation loss: 2.3817488247814373

Epoch: 5| Step: 9
Training loss: 0.9571008150936822
Validation loss: 2.3657108556975333

Epoch: 5| Step: 10
Training loss: 0.7399101654502078
Validation loss: 2.438581737267531

Epoch: 542| Step: 0
Training loss: 1.6528000077676912
Validation loss: 2.523912555833231

Epoch: 5| Step: 1
Training loss: 0.7027046430573619
Validation loss: 2.3921116418155135

Epoch: 5| Step: 2
Training loss: 0.8432121681980337
Validation loss: 2.4685845341027726

Epoch: 5| Step: 3
Training loss: 0.6463956051642258
Validation loss: 2.3623862909412012

Epoch: 5| Step: 4
Training loss: 0.7898515966914228
Validation loss: 2.3628253043707055

Epoch: 5| Step: 5
Training loss: 0.881038943509229
Validation loss: 2.439788316379715

Epoch: 5| Step: 6
Training loss: 0.854269920869292
Validation loss: 2.4983007234430663

Epoch: 5| Step: 7
Training loss: 0.786706788351879
Validation loss: 2.4474340238387975

Epoch: 5| Step: 8
Training loss: 0.899213207237733
Validation loss: 2.3732934410888866

Epoch: 5| Step: 9
Training loss: 0.830930061723084
Validation loss: 2.376235716001568

Epoch: 5| Step: 10
Training loss: 0.9435861761121122
Validation loss: 2.4503261331934354

Epoch: 543| Step: 0
Training loss: 0.9727697957264093
Validation loss: 2.3659732335528285

Epoch: 5| Step: 1
Training loss: 0.7048495019751169
Validation loss: 2.4374678235997447

Epoch: 5| Step: 2
Training loss: 0.5734652811331834
Validation loss: 2.3885772618994037

Epoch: 5| Step: 3
Training loss: 0.8596545371666336
Validation loss: 2.394470878939699

Epoch: 5| Step: 4
Training loss: 0.7253193217839723
Validation loss: 2.38618422247841

Epoch: 5| Step: 5
Training loss: 0.9625919644896781
Validation loss: 2.417850565779947

Epoch: 5| Step: 6
Training loss: 0.7175360669896882
Validation loss: 2.544439548355561

Epoch: 5| Step: 7
Training loss: 0.8111813187878395
Validation loss: 2.493769260451058

Epoch: 5| Step: 8
Training loss: 0.7684354774476404
Validation loss: 2.473824201918953

Epoch: 5| Step: 9
Training loss: 1.6930545941792485
Validation loss: 2.4408841438113473

Epoch: 5| Step: 10
Training loss: 1.0662494027067884
Validation loss: 2.3849082876490906

Epoch: 544| Step: 0
Training loss: 0.5850496813878951
Validation loss: 2.4547936380438466

Epoch: 5| Step: 1
Training loss: 0.8580445828581288
Validation loss: 2.4400319594696316

Epoch: 5| Step: 2
Training loss: 1.591485752522522
Validation loss: 2.3785798866841055

Epoch: 5| Step: 3
Training loss: 1.1220820520117227
Validation loss: 2.3998930353348373

Epoch: 5| Step: 4
Training loss: 0.8729628281386491
Validation loss: 2.498163469557505

Epoch: 5| Step: 5
Training loss: 0.8090156154964476
Validation loss: 2.440486557073715

Epoch: 5| Step: 6
Training loss: 0.6246359718676745
Validation loss: 2.4057811615384685

Epoch: 5| Step: 7
Training loss: 0.8147385643633197
Validation loss: 2.425119334123073

Epoch: 5| Step: 8
Training loss: 0.6289788672182721
Validation loss: 2.428477919702488

Epoch: 5| Step: 9
Training loss: 0.7761149062515428
Validation loss: 2.4379421313795673

Epoch: 5| Step: 10
Training loss: 0.8160932753209328
Validation loss: 2.4463791496907406

Epoch: 545| Step: 0
Training loss: 0.6628411674145261
Validation loss: 2.440916201132732

Epoch: 5| Step: 1
Training loss: 1.7172903625392006
Validation loss: 2.4295621196692916

Epoch: 5| Step: 2
Training loss: 1.1068741993225406
Validation loss: 2.4142557904338138

Epoch: 5| Step: 3
Training loss: 0.9160805294898847
Validation loss: 2.48978007551742

Epoch: 5| Step: 4
Training loss: 0.6640382201300061
Validation loss: 2.4443844968574098

Epoch: 5| Step: 5
Training loss: 0.7640451362992776
Validation loss: 2.388266078206775

Epoch: 5| Step: 6
Training loss: 0.6777720811891971
Validation loss: 2.39733129453695

Epoch: 5| Step: 7
Training loss: 0.8797626646192096
Validation loss: 2.457850708330819

Epoch: 5| Step: 8
Training loss: 0.8795630819307504
Validation loss: 2.4318520209072862

Epoch: 5| Step: 9
Training loss: 0.7778034480339481
Validation loss: 2.5283029542900946

Epoch: 5| Step: 10
Training loss: 0.6567823657587065
Validation loss: 2.46284842469837

Epoch: 546| Step: 0
Training loss: 0.8171652592099594
Validation loss: 2.4619714635608667

Epoch: 5| Step: 1
Training loss: 1.0400923594398535
Validation loss: 2.461764000574031

Epoch: 5| Step: 2
Training loss: 1.0273429377447478
Validation loss: 2.4113522842070436

Epoch: 5| Step: 3
Training loss: 0.8546115290545503
Validation loss: 2.4631705121709513

Epoch: 5| Step: 4
Training loss: 0.7951866664904593
Validation loss: 2.4574095174005053

Epoch: 5| Step: 5
Training loss: 0.8910139472674705
Validation loss: 2.4918717860617523

Epoch: 5| Step: 6
Training loss: 0.756475350403822
Validation loss: 2.5386488912854484

Epoch: 5| Step: 7
Training loss: 0.594550797370451
Validation loss: 2.470386368317245

Epoch: 5| Step: 8
Training loss: 0.9803620846544636
Validation loss: 2.4224857794668324

Epoch: 5| Step: 9
Training loss: 1.5287323320167894
Validation loss: 2.47386739998726

Epoch: 5| Step: 10
Training loss: 0.6610168625820357
Validation loss: 2.408891697762786

Epoch: 547| Step: 0
Training loss: 0.7137831861594052
Validation loss: 2.4545194415517786

Epoch: 5| Step: 1
Training loss: 1.5739798163364411
Validation loss: 2.4534790429420874

Epoch: 5| Step: 2
Training loss: 0.5710249852895412
Validation loss: 2.500951776526925

Epoch: 5| Step: 3
Training loss: 1.030914251985241
Validation loss: 2.4870371316937656

Epoch: 5| Step: 4
Training loss: 0.7323576225072115
Validation loss: 2.4640315926560996

Epoch: 5| Step: 5
Training loss: 1.047933754803753
Validation loss: 2.4897398822003707

Epoch: 5| Step: 6
Training loss: 0.9485839165127762
Validation loss: 2.501767445366286

Epoch: 5| Step: 7
Training loss: 0.7454406915940014
Validation loss: 2.4188255416759286

Epoch: 5| Step: 8
Training loss: 0.9538717002766588
Validation loss: 2.407103065678049

Epoch: 5| Step: 9
Training loss: 0.6966752617098939
Validation loss: 2.4387381984443874

Epoch: 5| Step: 10
Training loss: 0.6247620606496649
Validation loss: 2.49969227342813

Epoch: 548| Step: 0
Training loss: 1.0200161420255445
Validation loss: 2.449440075524499

Epoch: 5| Step: 1
Training loss: 0.7318628644710805
Validation loss: 2.475145841519221

Epoch: 5| Step: 2
Training loss: 0.8712639065129321
Validation loss: 2.3737656327592283

Epoch: 5| Step: 3
Training loss: 0.8262866506368665
Validation loss: 2.451159025239554

Epoch: 5| Step: 4
Training loss: 0.9955231472104378
Validation loss: 2.4280383643625387

Epoch: 5| Step: 5
Training loss: 0.6459911112690507
Validation loss: 2.4010532795191453

Epoch: 5| Step: 6
Training loss: 1.5654689048571309
Validation loss: 2.4116622222716684

Epoch: 5| Step: 7
Training loss: 0.8582412870983241
Validation loss: 2.4309245007577402

Epoch: 5| Step: 8
Training loss: 1.0744498819171748
Validation loss: 2.4659246568219317

Epoch: 5| Step: 9
Training loss: 0.7766170843271429
Validation loss: 2.4135283392144156

Epoch: 5| Step: 10
Training loss: 0.7366659264826904
Validation loss: 2.4074466150048437

Epoch: 549| Step: 0
Training loss: 0.8271163339701354
Validation loss: 2.4286498379779493

Epoch: 5| Step: 1
Training loss: 1.6932364554489368
Validation loss: 2.409336400783225

Epoch: 5| Step: 2
Training loss: 0.843064418168664
Validation loss: 2.476281743277438

Epoch: 5| Step: 3
Training loss: 0.9729587743225401
Validation loss: 2.505048401396723

Epoch: 5| Step: 4
Training loss: 1.0605811575447168
Validation loss: 2.371561998652614

Epoch: 5| Step: 5
Training loss: 0.7204087232420596
Validation loss: 2.4247845170756688

Epoch: 5| Step: 6
Training loss: 0.7449991075139172
Validation loss: 2.47169773066714

Epoch: 5| Step: 7
Training loss: 0.6712904760563928
Validation loss: 2.4552518936951278

Epoch: 5| Step: 8
Training loss: 0.9275064610053151
Validation loss: 2.3983542165418767

Epoch: 5| Step: 9
Training loss: 0.6290493441028964
Validation loss: 2.4294140978483623

Epoch: 5| Step: 10
Training loss: 0.7352938889054336
Validation loss: 2.4363547838204216

Epoch: 550| Step: 0
Training loss: 0.7752531684089874
Validation loss: 2.462133514057465

Epoch: 5| Step: 1
Training loss: 0.7154462599442568
Validation loss: 2.5234093575137115

Epoch: 5| Step: 2
Training loss: 0.7974628075683552
Validation loss: 2.499071151704327

Epoch: 5| Step: 3
Training loss: 0.7539168441107165
Validation loss: 2.3921727534676225

Epoch: 5| Step: 4
Training loss: 0.70011567284028
Validation loss: 2.4493801161064876

Epoch: 5| Step: 5
Training loss: 0.641382839133414
Validation loss: 2.4450216100986624

Epoch: 5| Step: 6
Training loss: 0.7260672409245655
Validation loss: 2.438914581381703

Epoch: 5| Step: 7
Training loss: 0.7232360163792892
Validation loss: 2.3895724914807204

Epoch: 5| Step: 8
Training loss: 1.0592044884396443
Validation loss: 2.4451289588516807

Epoch: 5| Step: 9
Training loss: 1.670874251564619
Validation loss: 2.425255712430372

Epoch: 5| Step: 10
Training loss: 0.7845772653413603
Validation loss: 2.382481204435666

Epoch: 551| Step: 0
Training loss: 0.7039581025698884
Validation loss: 2.3633959372277977

Epoch: 5| Step: 1
Training loss: 1.5230960561125584
Validation loss: 2.4547342963277727

Epoch: 5| Step: 2
Training loss: 0.626607591714051
Validation loss: 2.3809755773044285

Epoch: 5| Step: 3
Training loss: 0.7512303036537165
Validation loss: 2.497586775526611

Epoch: 5| Step: 4
Training loss: 0.847203779975268
Validation loss: 2.3563880433233226

Epoch: 5| Step: 5
Training loss: 0.716745483884498
Validation loss: 2.431993230662838

Epoch: 5| Step: 6
Training loss: 0.6978376804084605
Validation loss: 2.4996288782935534

Epoch: 5| Step: 7
Training loss: 1.0053696708798818
Validation loss: 2.423332968476535

Epoch: 5| Step: 8
Training loss: 0.809822954208564
Validation loss: 2.4657090735648133

Epoch: 5| Step: 9
Training loss: 1.1771469549128917
Validation loss: 2.4097192443584645

Epoch: 5| Step: 10
Training loss: 0.842727960484512
Validation loss: 2.571545565410968

Epoch: 552| Step: 0
Training loss: 0.8941298671223565
Validation loss: 2.434956331122789

Epoch: 5| Step: 1
Training loss: 0.9906528348652377
Validation loss: 2.430239487551308

Epoch: 5| Step: 2
Training loss: 1.6289511841355562
Validation loss: 2.481708135651003

Epoch: 5| Step: 3
Training loss: 0.8430666805652643
Validation loss: 2.378193272102529

Epoch: 5| Step: 4
Training loss: 0.7273144676140577
Validation loss: 2.433954518997233

Epoch: 5| Step: 5
Training loss: 1.0819550635442832
Validation loss: 2.444164028573337

Epoch: 5| Step: 6
Training loss: 0.8624144470243291
Validation loss: 2.3813295566785793

Epoch: 5| Step: 7
Training loss: 0.7508433289520561
Validation loss: 2.4940410968715976

Epoch: 5| Step: 8
Training loss: 0.6133951457982986
Validation loss: 2.473945369114394

Epoch: 5| Step: 9
Training loss: 0.6255243724264439
Validation loss: 2.4630577120047756

Epoch: 5| Step: 10
Training loss: 0.9056704739986791
Validation loss: 2.389657066101631

Epoch: 553| Step: 0
Training loss: 1.5614186932310274
Validation loss: 2.45558693718088

Epoch: 5| Step: 1
Training loss: 0.9861403787027616
Validation loss: 2.570269829694189

Epoch: 5| Step: 2
Training loss: 0.5759194548538507
Validation loss: 2.4437878709232725

Epoch: 5| Step: 3
Training loss: 0.8428559688324406
Validation loss: 2.4790017795372443

Epoch: 5| Step: 4
Training loss: 1.0666415335753954
Validation loss: 2.509327747593407

Epoch: 5| Step: 5
Training loss: 0.8535761342543127
Validation loss: 2.437309159327291

Epoch: 5| Step: 6
Training loss: 0.8911052212285319
Validation loss: 2.4642646987864945

Epoch: 5| Step: 7
Training loss: 0.7555434480995087
Validation loss: 2.466592333091276

Epoch: 5| Step: 8
Training loss: 0.7662397369021046
Validation loss: 2.586617342037581

Epoch: 5| Step: 9
Training loss: 0.7336214135492289
Validation loss: 2.508577837433544

Epoch: 5| Step: 10
Training loss: 0.5938507546719012
Validation loss: 2.4786413500853883

Epoch: 554| Step: 0
Training loss: 1.5823112334229648
Validation loss: 2.4215215059149124

Epoch: 5| Step: 1
Training loss: 0.8957329553360674
Validation loss: 2.468205622608493

Epoch: 5| Step: 2
Training loss: 0.7863779384792802
Validation loss: 2.4158655194057777

Epoch: 5| Step: 3
Training loss: 0.8870123154603438
Validation loss: 2.458234535937826

Epoch: 5| Step: 4
Training loss: 0.7860560030168622
Validation loss: 2.4339768837591533

Epoch: 5| Step: 5
Training loss: 0.6555681319251689
Validation loss: 2.4130555545214505

Epoch: 5| Step: 6
Training loss: 0.9474814572193192
Validation loss: 2.4835432118636183

Epoch: 5| Step: 7
Training loss: 0.8053446928553654
Validation loss: 2.446855012599906

Epoch: 5| Step: 8
Training loss: 0.7143923475507095
Validation loss: 2.455662078683974

Epoch: 5| Step: 9
Training loss: 1.0030585246178778
Validation loss: 2.418296383970747

Epoch: 5| Step: 10
Training loss: 0.5277058806163456
Validation loss: 2.474143404209906

Epoch: 555| Step: 0
Training loss: 0.7398752433414255
Validation loss: 2.53579264190628

Epoch: 5| Step: 1
Training loss: 0.6369438943482989
Validation loss: 2.4300525471373526

Epoch: 5| Step: 2
Training loss: 0.8785076678684496
Validation loss: 2.417754655737906

Epoch: 5| Step: 3
Training loss: 0.9160902566337311
Validation loss: 2.4471663956181664

Epoch: 5| Step: 4
Training loss: 0.7624856071989871
Validation loss: 2.429025160445159

Epoch: 5| Step: 5
Training loss: 0.7834415596064412
Validation loss: 2.459857784680439

Epoch: 5| Step: 6
Training loss: 1.6843316038978304
Validation loss: 2.4615102783389

Epoch: 5| Step: 7
Training loss: 0.7185099242260995
Validation loss: 2.455946648239194

Epoch: 5| Step: 8
Training loss: 0.7195076473643512
Validation loss: 2.425957836320834

Epoch: 5| Step: 9
Training loss: 0.9916181657989133
Validation loss: 2.442794604822011

Epoch: 5| Step: 10
Training loss: 0.5307526504317457
Validation loss: 2.486012222259037

Epoch: 556| Step: 0
Training loss: 0.6804035405163873
Validation loss: 2.422007775876409

Epoch: 5| Step: 1
Training loss: 0.5976845229698107
Validation loss: 2.487688250938486

Epoch: 5| Step: 2
Training loss: 1.0376428069220545
Validation loss: 2.3828893139751908

Epoch: 5| Step: 3
Training loss: 0.566346606041044
Validation loss: 2.4939698902137204

Epoch: 5| Step: 4
Training loss: 0.6836559594321964
Validation loss: 2.4632794918112064

Epoch: 5| Step: 5
Training loss: 1.5690961843345868
Validation loss: 2.4566256969361246

Epoch: 5| Step: 6
Training loss: 0.8606523211096458
Validation loss: 2.4470377129301557

Epoch: 5| Step: 7
Training loss: 0.7022666566352935
Validation loss: 2.4585254052575696

Epoch: 5| Step: 8
Training loss: 0.7435615268690327
Validation loss: 2.419360622515311

Epoch: 5| Step: 9
Training loss: 0.9969947479936168
Validation loss: 2.4564974356733145

Epoch: 5| Step: 10
Training loss: 0.6666794095212291
Validation loss: 2.4721321878088407

Epoch: 557| Step: 0
Training loss: 0.6366818189149387
Validation loss: 2.430407771839255

Epoch: 5| Step: 1
Training loss: 0.5987515355132289
Validation loss: 2.4438658645153337

Epoch: 5| Step: 2
Training loss: 0.7236641119032292
Validation loss: 2.4297349656971865

Epoch: 5| Step: 3
Training loss: 0.8333751588497694
Validation loss: 2.4758369384734515

Epoch: 5| Step: 4
Training loss: 1.0710929753741045
Validation loss: 2.4029869197059153

Epoch: 5| Step: 5
Training loss: 0.6830562549284287
Validation loss: 2.319269709368527

Epoch: 5| Step: 6
Training loss: 0.7658981692279193
Validation loss: 2.3926936360330835

Epoch: 5| Step: 7
Training loss: 1.0609688665728094
Validation loss: 2.397299243084174

Epoch: 5| Step: 8
Training loss: 0.7170944219955053
Validation loss: 2.381603874904658

Epoch: 5| Step: 9
Training loss: 1.5848187790048354
Validation loss: 2.458024907843358

Epoch: 5| Step: 10
Training loss: 0.7294562355180281
Validation loss: 2.426483879508468

Epoch: 558| Step: 0
Training loss: 0.8713338888711868
Validation loss: 2.462818141399983

Epoch: 5| Step: 1
Training loss: 0.8876154730451676
Validation loss: 2.4408322651461636

Epoch: 5| Step: 2
Training loss: 0.8275108939430473
Validation loss: 2.4356304747456936

Epoch: 5| Step: 3
Training loss: 1.5527707653459781
Validation loss: 2.4401955940643707

Epoch: 5| Step: 4
Training loss: 0.6087148709902344
Validation loss: 2.453211693805628

Epoch: 5| Step: 5
Training loss: 0.7344401310385105
Validation loss: 2.423211988400575

Epoch: 5| Step: 6
Training loss: 0.7887570384780069
Validation loss: 2.4741012471515536

Epoch: 5| Step: 7
Training loss: 0.88720562041973
Validation loss: 2.4503310651858055

Epoch: 5| Step: 8
Training loss: 0.7669635282620906
Validation loss: 2.388302648673068

Epoch: 5| Step: 9
Training loss: 0.7681399708492483
Validation loss: 2.5157965768013355

Epoch: 5| Step: 10
Training loss: 1.0362773654209578
Validation loss: 2.4913514165599078

Epoch: 559| Step: 0
Training loss: 0.8226417170705388
Validation loss: 2.4569738013452773

Epoch: 5| Step: 1
Training loss: 0.7553804048088872
Validation loss: 2.447410718846841

Epoch: 5| Step: 2
Training loss: 0.6940786579832757
Validation loss: 2.39333502497536

Epoch: 5| Step: 3
Training loss: 0.7302837443536251
Validation loss: 2.46467893016998

Epoch: 5| Step: 4
Training loss: 0.9067776886609472
Validation loss: 2.3980512496060875

Epoch: 5| Step: 5
Training loss: 0.6791717940606969
Validation loss: 2.424278189530117

Epoch: 5| Step: 6
Training loss: 0.5730476634222327
Validation loss: 2.432694424808024

Epoch: 5| Step: 7
Training loss: 0.760663754456228
Validation loss: 2.4298225235796673

Epoch: 5| Step: 8
Training loss: 1.1782464326561293
Validation loss: 2.447913674950762

Epoch: 5| Step: 9
Training loss: 0.815818830821651
Validation loss: 2.4089987835408073

Epoch: 5| Step: 10
Training loss: 1.6472351606924804
Validation loss: 2.449825018643885

Epoch: 560| Step: 0
Training loss: 0.5281880437026398
Validation loss: 2.4732388991862013

Epoch: 5| Step: 1
Training loss: 0.8416666518736986
Validation loss: 2.44183686663569

Epoch: 5| Step: 2
Training loss: 0.6360420188024025
Validation loss: 2.3825769785130952

Epoch: 5| Step: 3
Training loss: 0.901450933366246
Validation loss: 2.469756078595821

Epoch: 5| Step: 4
Training loss: 0.7765768283926732
Validation loss: 2.4240189220947106

Epoch: 5| Step: 5
Training loss: 0.7929838958947445
Validation loss: 2.5036223087725196

Epoch: 5| Step: 6
Training loss: 1.6506937504771684
Validation loss: 2.4902910481292926

Epoch: 5| Step: 7
Training loss: 0.9273375616212602
Validation loss: 2.3803701210913975

Epoch: 5| Step: 8
Training loss: 0.8159720256255073
Validation loss: 2.409991515077484

Epoch: 5| Step: 9
Training loss: 0.8490206026670992
Validation loss: 2.397709632269945

Epoch: 5| Step: 10
Training loss: 0.8964060165301241
Validation loss: 2.479831641189048

Epoch: 561| Step: 0
Training loss: 1.5865468325093985
Validation loss: 2.4714725353269906

Epoch: 5| Step: 1
Training loss: 0.7623799901856192
Validation loss: 2.4457942977210507

Epoch: 5| Step: 2
Training loss: 0.5490338357424518
Validation loss: 2.4162105069499145

Epoch: 5| Step: 3
Training loss: 0.8204661997354277
Validation loss: 2.4034576482780015

Epoch: 5| Step: 4
Training loss: 0.5503552189221592
Validation loss: 2.432061299196766

Epoch: 5| Step: 5
Training loss: 0.8029530545237451
Validation loss: 2.4143692662232725

Epoch: 5| Step: 6
Training loss: 0.7962044531283001
Validation loss: 2.4214517817042074

Epoch: 5| Step: 7
Training loss: 0.7323410192999891
Validation loss: 2.539847651169472

Epoch: 5| Step: 8
Training loss: 0.8990214896237961
Validation loss: 2.393282502294964

Epoch: 5| Step: 9
Training loss: 0.9574622293198768
Validation loss: 2.4268157229097103

Epoch: 5| Step: 10
Training loss: 0.7988505092180144
Validation loss: 2.455477437073179

Epoch: 562| Step: 0
Training loss: 1.5727422335409742
Validation loss: 2.43607473340133

Epoch: 5| Step: 1
Training loss: 0.7380220876686207
Validation loss: 2.4250798102217948

Epoch: 5| Step: 2
Training loss: 0.6480668398843968
Validation loss: 2.47213597239584

Epoch: 5| Step: 3
Training loss: 0.8869647722463182
Validation loss: 2.484273163270394

Epoch: 5| Step: 4
Training loss: 0.6213738631531793
Validation loss: 2.46613907462528

Epoch: 5| Step: 5
Training loss: 0.8645477670608178
Validation loss: 2.3790173676631197

Epoch: 5| Step: 6
Training loss: 0.8053345532371217
Validation loss: 2.3947080611710465

Epoch: 5| Step: 7
Training loss: 1.0463586928993005
Validation loss: 2.36687579384284

Epoch: 5| Step: 8
Training loss: 0.41554235124214467
Validation loss: 2.4496561527208356

Epoch: 5| Step: 9
Training loss: 0.7792581343044217
Validation loss: 2.491472132655183

Epoch: 5| Step: 10
Training loss: 0.6971936869977263
Validation loss: 2.431404181806702

Epoch: 563| Step: 0
Training loss: 0.9059814515625632
Validation loss: 2.441376007877209

Epoch: 5| Step: 1
Training loss: 1.052080053695754
Validation loss: 2.40822618932188

Epoch: 5| Step: 2
Training loss: 0.6661053594283998
Validation loss: 2.4189780489820287

Epoch: 5| Step: 3
Training loss: 0.6427827642570306
Validation loss: 2.5426376850854076

Epoch: 5| Step: 4
Training loss: 0.5374218395980112
Validation loss: 2.421917565454999

Epoch: 5| Step: 5
Training loss: 0.6078415184644875
Validation loss: 2.4218196125557694

Epoch: 5| Step: 6
Training loss: 0.7981715780361838
Validation loss: 2.394281092253222

Epoch: 5| Step: 7
Training loss: 0.8424044582629353
Validation loss: 2.3703288345195355

Epoch: 5| Step: 8
Training loss: 1.0048670345806403
Validation loss: 2.414690111804639

Epoch: 5| Step: 9
Training loss: 1.697965664146865
Validation loss: 2.4119869285294198

Epoch: 5| Step: 10
Training loss: 0.9761502425722761
Validation loss: 2.443771005911632

Epoch: 564| Step: 0
Training loss: 0.47440407476673413
Validation loss: 2.4704835702650927

Epoch: 5| Step: 1
Training loss: 0.4206102628237603
Validation loss: 2.4604565326374632

Epoch: 5| Step: 2
Training loss: 1.0127887737881376
Validation loss: 2.4890919600032477

Epoch: 5| Step: 3
Training loss: 0.6913819820649465
Validation loss: 2.404078191864979

Epoch: 5| Step: 4
Training loss: 0.6351892085046301
Validation loss: 2.4759154880630425

Epoch: 5| Step: 5
Training loss: 0.7478820380125664
Validation loss: 2.4630034650850408

Epoch: 5| Step: 6
Training loss: 0.9084430336693453
Validation loss: 2.3908652315528247

Epoch: 5| Step: 7
Training loss: 0.7974848937753403
Validation loss: 2.4732324652997995

Epoch: 5| Step: 8
Training loss: 0.914854928851544
Validation loss: 2.440672219857842

Epoch: 5| Step: 9
Training loss: 1.598005410539732
Validation loss: 2.488277435879347

Epoch: 5| Step: 10
Training loss: 0.9140646518779758
Validation loss: 2.505897980836697

Epoch: 565| Step: 0
Training loss: 0.649476976143682
Validation loss: 2.4262182081178434

Epoch: 5| Step: 1
Training loss: 0.9378303581553518
Validation loss: 2.4510248350340174

Epoch: 5| Step: 2
Training loss: 0.9172277178549323
Validation loss: 2.4924620803280626

Epoch: 5| Step: 3
Training loss: 1.0310490152268377
Validation loss: 2.469916191689472

Epoch: 5| Step: 4
Training loss: 0.708750410332132
Validation loss: 2.4436597436429133

Epoch: 5| Step: 5
Training loss: 0.6775645062399562
Validation loss: 2.4887403560216774

Epoch: 5| Step: 6
Training loss: 0.7918460207772263
Validation loss: 2.3667099430813408

Epoch: 5| Step: 7
Training loss: 0.8328405751260892
Validation loss: 2.4630971989475077

Epoch: 5| Step: 8
Training loss: 1.6141920866742858
Validation loss: 2.40106686081571

Epoch: 5| Step: 9
Training loss: 0.6804362152415445
Validation loss: 2.518622155144639

Epoch: 5| Step: 10
Training loss: 0.8265894923282745
Validation loss: 2.4845604719285412

Epoch: 566| Step: 0
Training loss: 0.676108705422663
Validation loss: 2.457907973778907

Epoch: 5| Step: 1
Training loss: 0.5581275221371451
Validation loss: 2.4288594940326975

Epoch: 5| Step: 2
Training loss: 0.5503405708635754
Validation loss: 2.478423174539897

Epoch: 5| Step: 3
Training loss: 0.6019636525812257
Validation loss: 2.4799226564908006

Epoch: 5| Step: 4
Training loss: 0.7933447186136585
Validation loss: 2.4367666242953585

Epoch: 5| Step: 5
Training loss: 0.9263121937452119
Validation loss: 2.504409581519723

Epoch: 5| Step: 6
Training loss: 0.8012671880321657
Validation loss: 2.4459696042809913

Epoch: 5| Step: 7
Training loss: 0.616282052411695
Validation loss: 2.4289042612381

Epoch: 5| Step: 8
Training loss: 0.6786238580182244
Validation loss: 2.3756609516732228

Epoch: 5| Step: 9
Training loss: 0.7515277799013623
Validation loss: 2.4560083160527486

Epoch: 5| Step: 10
Training loss: 1.8853899144194368
Validation loss: 2.4501226945055796

Epoch: 567| Step: 0
Training loss: 0.5881984069772814
Validation loss: 2.4331947275665526

Epoch: 5| Step: 1
Training loss: 0.7965836085698724
Validation loss: 2.4008815647850565

Epoch: 5| Step: 2
Training loss: 1.4864922130905556
Validation loss: 2.4345074466541416

Epoch: 5| Step: 3
Training loss: 0.659002842669803
Validation loss: 2.464247436063092

Epoch: 5| Step: 4
Training loss: 1.0604052370026271
Validation loss: 2.3865768481465786

Epoch: 5| Step: 5
Training loss: 0.5860274182307624
Validation loss: 2.462492948640379

Epoch: 5| Step: 6
Training loss: 0.7774387474096052
Validation loss: 2.4603422930574306

Epoch: 5| Step: 7
Training loss: 0.794712798345571
Validation loss: 2.396201184047419

Epoch: 5| Step: 8
Training loss: 0.7820338322523473
Validation loss: 2.3993401025669314

Epoch: 5| Step: 9
Training loss: 0.8013381882101027
Validation loss: 2.468948190931395

Epoch: 5| Step: 10
Training loss: 1.1633937373961514
Validation loss: 2.430260844277136

Epoch: 568| Step: 0
Training loss: 0.7161159763470141
Validation loss: 2.422888891762949

Epoch: 5| Step: 1
Training loss: 0.6211380133061153
Validation loss: 2.488163906962386

Epoch: 5| Step: 2
Training loss: 0.5317803148202137
Validation loss: 2.44633468550345

Epoch: 5| Step: 3
Training loss: 0.8233023516299476
Validation loss: 2.427039121242461

Epoch: 5| Step: 4
Training loss: 0.8981956156323592
Validation loss: 2.3645537884440175

Epoch: 5| Step: 5
Training loss: 0.6762964346591885
Validation loss: 2.440323187814142

Epoch: 5| Step: 6
Training loss: 0.5717819826115463
Validation loss: 2.3947421235016253

Epoch: 5| Step: 7
Training loss: 0.8363564412981704
Validation loss: 2.3771661633681

Epoch: 5| Step: 8
Training loss: 1.619669902513821
Validation loss: 2.4115565033342183

Epoch: 5| Step: 9
Training loss: 0.7840467366427676
Validation loss: 2.37627310921332

Epoch: 5| Step: 10
Training loss: 0.8061028412766351
Validation loss: 2.426220360493768

Epoch: 569| Step: 0
Training loss: 0.6738670448452113
Validation loss: 2.3506791002162513

Epoch: 5| Step: 1
Training loss: 0.9102668858685119
Validation loss: 2.372097977653921

Epoch: 5| Step: 2
Training loss: 0.7193663069450849
Validation loss: 2.469861885217488

Epoch: 5| Step: 3
Training loss: 0.570895954743976
Validation loss: 2.4354403881104885

Epoch: 5| Step: 4
Training loss: 1.694764008987044
Validation loss: 2.4055165405000105

Epoch: 5| Step: 5
Training loss: 0.6320487228637761
Validation loss: 2.4040236367428345

Epoch: 5| Step: 6
Training loss: 0.8543062367425615
Validation loss: 2.4096391576913114

Epoch: 5| Step: 7
Training loss: 0.825593822794453
Validation loss: 2.4088707842776085

Epoch: 5| Step: 8
Training loss: 0.7229369572000682
Validation loss: 2.384335903685355

Epoch: 5| Step: 9
Training loss: 0.748981778056874
Validation loss: 2.440510468644027

Epoch: 5| Step: 10
Training loss: 1.0153493653916712
Validation loss: 2.4603684774890517

Epoch: 570| Step: 0
Training loss: 0.586557848286462
Validation loss: 2.449403118198049

Epoch: 5| Step: 1
Training loss: 0.8057287201801059
Validation loss: 2.4592633557334254

Epoch: 5| Step: 2
Training loss: 0.7623417971602234
Validation loss: 2.455951889405937

Epoch: 5| Step: 3
Training loss: 0.9524122606251706
Validation loss: 2.4275535252338503

Epoch: 5| Step: 4
Training loss: 0.9625949366924782
Validation loss: 2.411867882527389

Epoch: 5| Step: 5
Training loss: 0.8613603027976485
Validation loss: 2.443379469728616

Epoch: 5| Step: 6
Training loss: 0.6360294612967515
Validation loss: 2.3991626945711513

Epoch: 5| Step: 7
Training loss: 0.7862228057719115
Validation loss: 2.431758813201037

Epoch: 5| Step: 8
Training loss: 1.6986645726610707
Validation loss: 2.3760624901509764

Epoch: 5| Step: 9
Training loss: 0.8912845311156457
Validation loss: 2.435470429202531

Epoch: 5| Step: 10
Training loss: 0.6417760510122379
Validation loss: 2.374993229280502

Epoch: 571| Step: 0
Training loss: 1.5300427562997534
Validation loss: 2.48522625682281

Epoch: 5| Step: 1
Training loss: 0.8561875619886194
Validation loss: 2.4286187331886673

Epoch: 5| Step: 2
Training loss: 0.9488252679774748
Validation loss: 2.39331521007184

Epoch: 5| Step: 3
Training loss: 0.5735369676600007
Validation loss: 2.428158421925892

Epoch: 5| Step: 4
Training loss: 0.6809743997450558
Validation loss: 2.426238890712569

Epoch: 5| Step: 5
Training loss: 0.6611175535348488
Validation loss: 2.453875219331701

Epoch: 5| Step: 6
Training loss: 0.4965210823757704
Validation loss: 2.454694306711998

Epoch: 5| Step: 7
Training loss: 0.9647511426212595
Validation loss: 2.4681572504320117

Epoch: 5| Step: 8
Training loss: 0.9158777324291614
Validation loss: 2.412819473015527

Epoch: 5| Step: 9
Training loss: 0.6602998611172165
Validation loss: 2.4410752127719135

Epoch: 5| Step: 10
Training loss: 1.0352667407681513
Validation loss: 2.405847859695766

Epoch: 572| Step: 0
Training loss: 0.9046997425259026
Validation loss: 2.5106470282063778

Epoch: 5| Step: 1
Training loss: 0.8862552860032424
Validation loss: 2.419249719571572

Epoch: 5| Step: 2
Training loss: 1.0014262756926158
Validation loss: 2.3820834150752357

Epoch: 5| Step: 3
Training loss: 0.48337796871121047
Validation loss: 2.378088396519507

Epoch: 5| Step: 4
Training loss: 0.6055144262004944
Validation loss: 2.490009417795491

Epoch: 5| Step: 5
Training loss: 1.0655161737711882
Validation loss: 2.453959151621623

Epoch: 5| Step: 6
Training loss: 1.523134015494531
Validation loss: 2.4100106008949482

Epoch: 5| Step: 7
Training loss: 0.8415187721493204
Validation loss: 2.413669800483349

Epoch: 5| Step: 8
Training loss: 0.6316076040040929
Validation loss: 2.4204504692165476

Epoch: 5| Step: 9
Training loss: 0.7511681757462417
Validation loss: 2.438622316996921

Epoch: 5| Step: 10
Training loss: 0.8784430745700087
Validation loss: 2.401814695846324

Epoch: 573| Step: 0
Training loss: 0.7001571751294519
Validation loss: 2.4093952800185106

Epoch: 5| Step: 1
Training loss: 0.5492003729446684
Validation loss: 2.469014572747703

Epoch: 5| Step: 2
Training loss: 1.7368495574438423
Validation loss: 2.512027504672603

Epoch: 5| Step: 3
Training loss: 0.5881468002462547
Validation loss: 2.4805424789182453

Epoch: 5| Step: 4
Training loss: 0.6359964498054935
Validation loss: 2.3945883657266167

Epoch: 5| Step: 5
Training loss: 0.9733856407789996
Validation loss: 2.449793691133549

Epoch: 5| Step: 6
Training loss: 0.6149046483593567
Validation loss: 2.452374930111474

Epoch: 5| Step: 7
Training loss: 0.46519229548077584
Validation loss: 2.463778170533854

Epoch: 5| Step: 8
Training loss: 0.9222179356887757
Validation loss: 2.4499619847442102

Epoch: 5| Step: 9
Training loss: 0.7091160591512661
Validation loss: 2.4436068700623292

Epoch: 5| Step: 10
Training loss: 0.8440874978875818
Validation loss: 2.437057288736941

Epoch: 574| Step: 0
Training loss: 0.6730817116053511
Validation loss: 2.391672552463898

Epoch: 5| Step: 1
Training loss: 0.7442634461136169
Validation loss: 2.4801741225054545

Epoch: 5| Step: 2
Training loss: 0.7431786594636596
Validation loss: 2.4188498729892243

Epoch: 5| Step: 3
Training loss: 1.5087097344639262
Validation loss: 2.4235592006471705

Epoch: 5| Step: 4
Training loss: 0.8578182338390947
Validation loss: 2.3668996107285674

Epoch: 5| Step: 5
Training loss: 0.7517209573989647
Validation loss: 2.5218145440063573

Epoch: 5| Step: 6
Training loss: 0.5831042390502782
Validation loss: 2.4729872799825996

Epoch: 5| Step: 7
Training loss: 0.8070234817175319
Validation loss: 2.4652882120282436

Epoch: 5| Step: 8
Training loss: 0.8159981031349051
Validation loss: 2.3957556656227927

Epoch: 5| Step: 9
Training loss: 0.7840011222354486
Validation loss: 2.3646508296172777

Epoch: 5| Step: 10
Training loss: 0.8133561318816253
Validation loss: 2.4437444490390097

Epoch: 575| Step: 0
Training loss: 0.8227439811854994
Validation loss: 2.3941666643492

Epoch: 5| Step: 1
Training loss: 1.6226940666717928
Validation loss: 2.441046898956752

Epoch: 5| Step: 2
Training loss: 0.7330255487472943
Validation loss: 2.4241050654615592

Epoch: 5| Step: 3
Training loss: 0.8201544473155511
Validation loss: 2.4147191763224094

Epoch: 5| Step: 4
Training loss: 0.6526763890259565
Validation loss: 2.459904828713812

Epoch: 5| Step: 5
Training loss: 0.5947536468602505
Validation loss: 2.4390974487071997

Epoch: 5| Step: 6
Training loss: 0.7616430782975494
Validation loss: 2.408117418020126

Epoch: 5| Step: 7
Training loss: 0.842508179259852
Validation loss: 2.421166022532764

Epoch: 5| Step: 8
Training loss: 0.5567205539002852
Validation loss: 2.4874047026382193

Epoch: 5| Step: 9
Training loss: 0.6912135917222413
Validation loss: 2.419417581496653

Epoch: 5| Step: 10
Training loss: 0.8875677942521437
Validation loss: 2.413909323171052

Epoch: 576| Step: 0
Training loss: 0.8065251228454218
Validation loss: 2.460994610284096

Epoch: 5| Step: 1
Training loss: 0.7696318584840995
Validation loss: 2.342149940050609

Epoch: 5| Step: 2
Training loss: 0.49401258234552453
Validation loss: 2.4478187836447587

Epoch: 5| Step: 3
Training loss: 0.7047932437635144
Validation loss: 2.4129562755766663

Epoch: 5| Step: 4
Training loss: 1.7409382947386867
Validation loss: 2.4105591163302695

Epoch: 5| Step: 5
Training loss: 0.77855549589156
Validation loss: 2.4449173698065745

Epoch: 5| Step: 6
Training loss: 0.7522397374460658
Validation loss: 2.395826227535145

Epoch: 5| Step: 7
Training loss: 0.5637440435006056
Validation loss: 2.5003037191297914

Epoch: 5| Step: 8
Training loss: 0.6590892136261995
Validation loss: 2.4038559865505906

Epoch: 5| Step: 9
Training loss: 0.8474732302486059
Validation loss: 2.3591968002125134

Epoch: 5| Step: 10
Training loss: 0.7628783178630787
Validation loss: 2.4187997125060345

Epoch: 577| Step: 0
Training loss: 0.7961462091563741
Validation loss: 2.365807968608361

Epoch: 5| Step: 1
Training loss: 0.7769631072065275
Validation loss: 2.4480978785886216

Epoch: 5| Step: 2
Training loss: 0.7743820049101451
Validation loss: 2.4218508599778836

Epoch: 5| Step: 3
Training loss: 0.8653598117534189
Validation loss: 2.4339726948912768

Epoch: 5| Step: 4
Training loss: 0.6450443421875849
Validation loss: 2.3881135147983548

Epoch: 5| Step: 5
Training loss: 1.5124744822974139
Validation loss: 2.459989556771358

Epoch: 5| Step: 6
Training loss: 0.7907506805161314
Validation loss: 2.4544968665488787

Epoch: 5| Step: 7
Training loss: 0.6231798370933876
Validation loss: 2.3995658067298575

Epoch: 5| Step: 8
Training loss: 0.6851880908905407
Validation loss: 2.4096482413428695

Epoch: 5| Step: 9
Training loss: 0.8812535454969576
Validation loss: 2.408548513153465

Epoch: 5| Step: 10
Training loss: 0.5901993948810232
Validation loss: 2.4115884859557277

Epoch: 578| Step: 0
Training loss: 0.8931354810928603
Validation loss: 2.4149347116748188

Epoch: 5| Step: 1
Training loss: 0.6690132719171776
Validation loss: 2.408103083368651

Epoch: 5| Step: 2
Training loss: 0.8329228741362182
Validation loss: 2.4507595195043077

Epoch: 5| Step: 3
Training loss: 0.8151814888221658
Validation loss: 2.377213039092958

Epoch: 5| Step: 4
Training loss: 0.7036270680291272
Validation loss: 2.4745831229216493

Epoch: 5| Step: 5
Training loss: 0.6092184550384175
Validation loss: 2.4425983858560407

Epoch: 5| Step: 6
Training loss: 0.7688914703827755
Validation loss: 2.472807192553497

Epoch: 5| Step: 7
Training loss: 0.6627417051500597
Validation loss: 2.4927799697025765

Epoch: 5| Step: 8
Training loss: 0.6868124471545166
Validation loss: 2.547882533055873

Epoch: 5| Step: 9
Training loss: 0.8412447931205055
Validation loss: 2.395768274295101

Epoch: 5| Step: 10
Training loss: 1.714952539282168
Validation loss: 2.4821778029283683

Epoch: 579| Step: 0
Training loss: 0.7080962869019672
Validation loss: 2.4409468396508522

Epoch: 5| Step: 1
Training loss: 0.5262480478862157
Validation loss: 2.3585551499319584

Epoch: 5| Step: 2
Training loss: 0.559619362164307
Validation loss: 2.457089857533264

Epoch: 5| Step: 3
Training loss: 0.7805261692007449
Validation loss: 2.402787109569636

Epoch: 5| Step: 4
Training loss: 0.954561932636233
Validation loss: 2.4266148940394228

Epoch: 5| Step: 5
Training loss: 0.7968801984430431
Validation loss: 2.355408622872054

Epoch: 5| Step: 6
Training loss: 0.7782180699833096
Validation loss: 2.4024302354570697

Epoch: 5| Step: 7
Training loss: 0.8091681831088984
Validation loss: 2.4306944853595374

Epoch: 5| Step: 8
Training loss: 0.989939056842263
Validation loss: 2.4002278697457307

Epoch: 5| Step: 9
Training loss: 0.7703954810583377
Validation loss: 2.3187022105262747

Epoch: 5| Step: 10
Training loss: 1.6468750115816235
Validation loss: 2.462030903133596

Epoch: 580| Step: 0
Training loss: 0.6781524116495732
Validation loss: 2.4019850847243394

Epoch: 5| Step: 1
Training loss: 0.6226462627840014
Validation loss: 2.426895645224199

Epoch: 5| Step: 2
Training loss: 0.805613124277496
Validation loss: 2.4127084404719663

Epoch: 5| Step: 3
Training loss: 0.5355872764345306
Validation loss: 2.4144212781594856

Epoch: 5| Step: 4
Training loss: 0.691754485112668
Validation loss: 2.3975174501249312

Epoch: 5| Step: 5
Training loss: 0.90015466208865
Validation loss: 2.360000309086399

Epoch: 5| Step: 6
Training loss: 0.9526597748062873
Validation loss: 2.453171972500821

Epoch: 5| Step: 7
Training loss: 0.6335546592008209
Validation loss: 2.42362971044599

Epoch: 5| Step: 8
Training loss: 1.6258607198786543
Validation loss: 2.5140585272072546

Epoch: 5| Step: 9
Training loss: 0.9742101184061849
Validation loss: 2.4069562689725714

Epoch: 5| Step: 10
Training loss: 0.6061313572048902
Validation loss: 2.425046850592769

Epoch: 581| Step: 0
Training loss: 0.7392424930814452
Validation loss: 2.3330004985001387

Epoch: 5| Step: 1
Training loss: 0.8992105558205977
Validation loss: 2.4950051339770063

Epoch: 5| Step: 2
Training loss: 0.7657538325070313
Validation loss: 2.348427116939778

Epoch: 5| Step: 3
Training loss: 1.6418569390008197
Validation loss: 2.4466695261276867

Epoch: 5| Step: 4
Training loss: 0.8519259385953288
Validation loss: 2.3936880532442752

Epoch: 5| Step: 5
Training loss: 0.8606386084716917
Validation loss: 2.408691434454724

Epoch: 5| Step: 6
Training loss: 0.859315245891781
Validation loss: 2.428149116119625

Epoch: 5| Step: 7
Training loss: 0.6634544281275518
Validation loss: 2.4776652256694147

Epoch: 5| Step: 8
Training loss: 0.6998099273391781
Validation loss: 2.412027524698864

Epoch: 5| Step: 9
Training loss: 0.5126790071346916
Validation loss: 2.459652485410936

Epoch: 5| Step: 10
Training loss: 0.5824265385830564
Validation loss: 2.4128216851567235

Epoch: 582| Step: 0
Training loss: 0.6439762615973277
Validation loss: 2.4243549247989353

Epoch: 5| Step: 1
Training loss: 1.5302527157878287
Validation loss: 2.35633701339948

Epoch: 5| Step: 2
Training loss: 0.5487107392345566
Validation loss: 2.528078838238109

Epoch: 5| Step: 3
Training loss: 1.0943464015533255
Validation loss: 2.5228374060634464

Epoch: 5| Step: 4
Training loss: 0.9350077244240638
Validation loss: 2.4906208870961453

Epoch: 5| Step: 5
Training loss: 0.6887132603007532
Validation loss: 2.4036698989713097

Epoch: 5| Step: 6
Training loss: 0.7541681338835156
Validation loss: 2.48405656239721

Epoch: 5| Step: 7
Training loss: 0.8152699205502644
Validation loss: 2.448999436073595

Epoch: 5| Step: 8
Training loss: 0.7507681886169962
Validation loss: 2.4383196298056617

Epoch: 5| Step: 9
Training loss: 0.7144363993693885
Validation loss: 2.4431995403733886

Epoch: 5| Step: 10
Training loss: 0.7660470694430166
Validation loss: 2.4562436432693433

Epoch: 583| Step: 0
Training loss: 0.5628380819095322
Validation loss: 2.4732069426010086

Epoch: 5| Step: 1
Training loss: 1.7173513096575408
Validation loss: 2.4339106328144906

Epoch: 5| Step: 2
Training loss: 0.7676560068780385
Validation loss: 2.502617927334084

Epoch: 5| Step: 3
Training loss: 0.6384081281346518
Validation loss: 2.4234645161879853

Epoch: 5| Step: 4
Training loss: 0.6483888952583935
Validation loss: 2.434582769643247

Epoch: 5| Step: 5
Training loss: 0.48094578453895065
Validation loss: 2.4369719022369467

Epoch: 5| Step: 6
Training loss: 0.720757459127549
Validation loss: 2.4335603721082473

Epoch: 5| Step: 7
Training loss: 0.6481649446455561
Validation loss: 2.4776575167531267

Epoch: 5| Step: 8
Training loss: 0.6370431974412039
Validation loss: 2.463896296206477

Epoch: 5| Step: 9
Training loss: 0.8174119440536611
Validation loss: 2.3952912702295834

Epoch: 5| Step: 10
Training loss: 0.5183773851176505
Validation loss: 2.3556621882063453

Epoch: 584| Step: 0
Training loss: 0.8116141405153139
Validation loss: 2.4709288760225103

Epoch: 5| Step: 1
Training loss: 0.6015191496054565
Validation loss: 2.419475110253701

Epoch: 5| Step: 2
Training loss: 0.6222822466089294
Validation loss: 2.459569896033622

Epoch: 5| Step: 3
Training loss: 0.7088351342203545
Validation loss: 2.429367380400754

Epoch: 5| Step: 4
Training loss: 0.7896333650088843
Validation loss: 2.396540267748128

Epoch: 5| Step: 5
Training loss: 0.651467540050903
Validation loss: 2.4861042720484594

Epoch: 5| Step: 6
Training loss: 0.8669725100043137
Validation loss: 2.406683576046841

Epoch: 5| Step: 7
Training loss: 0.6101924841522023
Validation loss: 2.4296063896066924

Epoch: 5| Step: 8
Training loss: 1.549610070434445
Validation loss: 2.535713288690003

Epoch: 5| Step: 9
Training loss: 0.6268781100164609
Validation loss: 2.466631419432466

Epoch: 5| Step: 10
Training loss: 1.1254637610025553
Validation loss: 2.4514507994426147

Epoch: 585| Step: 0
Training loss: 0.671059468362957
Validation loss: 2.4447872684576795

Epoch: 5| Step: 1
Training loss: 0.5319940181481921
Validation loss: 2.418509221867798

Epoch: 5| Step: 2
Training loss: 0.6166443184935668
Validation loss: 2.4798651845489035

Epoch: 5| Step: 3
Training loss: 1.6471246490327602
Validation loss: 2.4567726333425375

Epoch: 5| Step: 4
Training loss: 0.6339160104347598
Validation loss: 2.4670357599577053

Epoch: 5| Step: 5
Training loss: 0.7362580607544541
Validation loss: 2.3844620128401917

Epoch: 5| Step: 6
Training loss: 0.878193239703272
Validation loss: 2.483746520913396

Epoch: 5| Step: 7
Training loss: 0.7535334243372853
Validation loss: 2.3856973131458665

Epoch: 5| Step: 8
Training loss: 0.785873995996765
Validation loss: 2.446008904875926

Epoch: 5| Step: 9
Training loss: 0.6854864892692435
Validation loss: 2.459742199901884

Epoch: 5| Step: 10
Training loss: 0.7068787299613457
Validation loss: 2.545713075966501

Epoch: 586| Step: 0
Training loss: 0.6492841318124098
Validation loss: 2.4136904944814224

Epoch: 5| Step: 1
Training loss: 1.6024615485804816
Validation loss: 2.406456712714117

Epoch: 5| Step: 2
Training loss: 0.6156966637276113
Validation loss: 2.401993342416541

Epoch: 5| Step: 3
Training loss: 0.4990694506309877
Validation loss: 2.464426900164374

Epoch: 5| Step: 4
Training loss: 0.7539390596356088
Validation loss: 2.3723333626613647

Epoch: 5| Step: 5
Training loss: 0.882320266824558
Validation loss: 2.4053025790332363

Epoch: 5| Step: 6
Training loss: 0.9579383754939023
Validation loss: 2.3913444472919734

Epoch: 5| Step: 7
Training loss: 0.5719062275516286
Validation loss: 2.407801336451414

Epoch: 5| Step: 8
Training loss: 0.7486418506804238
Validation loss: 2.437864336835502

Epoch: 5| Step: 9
Training loss: 0.6838747373471308
Validation loss: 2.4324781476309973

Epoch: 5| Step: 10
Training loss: 0.6651846884485533
Validation loss: 2.4232859079278275

Epoch: 587| Step: 0
Training loss: 0.7681344615083521
Validation loss: 2.393938163730835

Epoch: 5| Step: 1
Training loss: 0.466111114388222
Validation loss: 2.4428083780327357

Epoch: 5| Step: 2
Training loss: 1.5148924797605225
Validation loss: 2.46911197094424

Epoch: 5| Step: 3
Training loss: 0.971436835377067
Validation loss: 2.491389893231556

Epoch: 5| Step: 4
Training loss: 0.7945732083114772
Validation loss: 2.4098640430028504

Epoch: 5| Step: 5
Training loss: 0.6295068846243536
Validation loss: 2.396529028114192

Epoch: 5| Step: 6
Training loss: 0.7934942148739278
Validation loss: 2.3771857505269325

Epoch: 5| Step: 7
Training loss: 0.6435898350103171
Validation loss: 2.437053153553113

Epoch: 5| Step: 8
Training loss: 0.5681221588198013
Validation loss: 2.4276153894592594

Epoch: 5| Step: 9
Training loss: 0.763826632611874
Validation loss: 2.420769348648807

Epoch: 5| Step: 10
Training loss: 0.8256386192521065
Validation loss: 2.46484871846868

Epoch: 588| Step: 0
Training loss: 0.8828846049611978
Validation loss: 2.4526280216569636

Epoch: 5| Step: 1
Training loss: 0.6006887952603854
Validation loss: 2.406155999782986

Epoch: 5| Step: 2
Training loss: 0.6799965736709552
Validation loss: 2.4756058876609255

Epoch: 5| Step: 3
Training loss: 0.6389099284061738
Validation loss: 2.4263903171422174

Epoch: 5| Step: 4
Training loss: 0.5825903850225591
Validation loss: 2.3954461143711794

Epoch: 5| Step: 5
Training loss: 0.8564288182339493
Validation loss: 2.3752736946953896

Epoch: 5| Step: 6
Training loss: 0.7511684137940076
Validation loss: 2.335985832442788

Epoch: 5| Step: 7
Training loss: 1.5403078723914576
Validation loss: 2.454440774904167

Epoch: 5| Step: 8
Training loss: 0.5890872474551527
Validation loss: 2.413237448814468

Epoch: 5| Step: 9
Training loss: 0.588569958324719
Validation loss: 2.4472551473516955

Epoch: 5| Step: 10
Training loss: 0.8617267680897508
Validation loss: 2.474570438500105

Epoch: 589| Step: 0
Training loss: 0.6660671717589164
Validation loss: 2.3564098218759826

Epoch: 5| Step: 1
Training loss: 0.6392654786785159
Validation loss: 2.4299370016009414

Epoch: 5| Step: 2
Training loss: 0.6065127078829693
Validation loss: 2.478628775640084

Epoch: 5| Step: 3
Training loss: 0.7918343533725012
Validation loss: 2.419038883039382

Epoch: 5| Step: 4
Training loss: 0.6006417845525306
Validation loss: 2.500944957778593

Epoch: 5| Step: 5
Training loss: 0.8503538531166931
Validation loss: 2.412173837424206

Epoch: 5| Step: 6
Training loss: 0.6925211823318931
Validation loss: 2.4671460942773873

Epoch: 5| Step: 7
Training loss: 0.5624517843986757
Validation loss: 2.4594282239549767

Epoch: 5| Step: 8
Training loss: 0.5786106801678745
Validation loss: 2.424919966956535

Epoch: 5| Step: 9
Training loss: 0.7246541628915486
Validation loss: 2.4672216900618302

Epoch: 5| Step: 10
Training loss: 1.8250458045332476
Validation loss: 2.4466334749697327

Epoch: 590| Step: 0
Training loss: 0.7428816109468558
Validation loss: 2.4042563455616905

Epoch: 5| Step: 1
Training loss: 0.5227824995208498
Validation loss: 2.361732715257675

Epoch: 5| Step: 2
Training loss: 0.7053997331319163
Validation loss: 2.3251107157212734

Epoch: 5| Step: 3
Training loss: 0.7978438303466555
Validation loss: 2.3443650442933763

Epoch: 5| Step: 4
Training loss: 0.701745035430503
Validation loss: 2.380139274472249

Epoch: 5| Step: 5
Training loss: 0.7319678768707619
Validation loss: 2.4650796751640103

Epoch: 5| Step: 6
Training loss: 0.8126074646526402
Validation loss: 2.394460915448558

Epoch: 5| Step: 7
Training loss: 0.4863892022811521
Validation loss: 2.4151310223059674

Epoch: 5| Step: 8
Training loss: 0.6586358886125651
Validation loss: 2.434342659353909

Epoch: 5| Step: 9
Training loss: 0.8741429763968243
Validation loss: 2.378594121186277

Epoch: 5| Step: 10
Training loss: 1.7280346562256979
Validation loss: 2.419897291204315

Epoch: 591| Step: 0
Training loss: 1.4433547498657289
Validation loss: 2.389389654551199

Epoch: 5| Step: 1
Training loss: 0.8330287416429452
Validation loss: 2.509241597483181

Epoch: 5| Step: 2
Training loss: 0.932464810850319
Validation loss: 2.3953102211287534

Epoch: 5| Step: 3
Training loss: 0.995919305822526
Validation loss: 2.478885092445484

Epoch: 5| Step: 4
Training loss: 0.6282354058552697
Validation loss: 2.481830143809209

Epoch: 5| Step: 5
Training loss: 0.6134371711158745
Validation loss: 2.4286656421099857

Epoch: 5| Step: 6
Training loss: 0.49786330187168676
Validation loss: 2.4281796359479286

Epoch: 5| Step: 7
Training loss: 0.79958667508597
Validation loss: 2.424131808933906

Epoch: 5| Step: 8
Training loss: 0.6317899236182273
Validation loss: 2.3648573428588784

Epoch: 5| Step: 9
Training loss: 0.5192364881885241
Validation loss: 2.4425724239328126

Epoch: 5| Step: 10
Training loss: 0.5726068150102444
Validation loss: 2.38528377601457

Epoch: 592| Step: 0
Training loss: 0.7811604639244821
Validation loss: 2.458351881507519

Epoch: 5| Step: 1
Training loss: 0.5547430521051595
Validation loss: 2.4380420095873063

Epoch: 5| Step: 2
Training loss: 0.7780257257459328
Validation loss: 2.378194004049652

Epoch: 5| Step: 3
Training loss: 0.512202783790629
Validation loss: 2.4538587637113314

Epoch: 5| Step: 4
Training loss: 0.8487529779306118
Validation loss: 2.438329933469233

Epoch: 5| Step: 5
Training loss: 0.9674663345137705
Validation loss: 2.4702764890243953

Epoch: 5| Step: 6
Training loss: 1.4374965170113205
Validation loss: 2.5088129157524555

Epoch: 5| Step: 7
Training loss: 0.7001366796910404
Validation loss: 2.4677831205799454

Epoch: 5| Step: 8
Training loss: 0.6600021543612142
Validation loss: 2.5180992687408685

Epoch: 5| Step: 9
Training loss: 0.7991754574204366
Validation loss: 2.4742718573166353

Epoch: 5| Step: 10
Training loss: 0.6485282650584178
Validation loss: 2.4061785217075666

Epoch: 593| Step: 0
Training loss: 0.7633035459356357
Validation loss: 2.4589958003968997

Epoch: 5| Step: 1
Training loss: 0.5537693053468997
Validation loss: 2.410256158547586

Epoch: 5| Step: 2
Training loss: 0.6590454869179397
Validation loss: 2.4477399121216763

Epoch: 5| Step: 3
Training loss: 0.49596437884963057
Validation loss: 2.439702056361458

Epoch: 5| Step: 4
Training loss: 1.5458643530572074
Validation loss: 2.468056069165779

Epoch: 5| Step: 5
Training loss: 0.6316831188735014
Validation loss: 2.4276755735867974

Epoch: 5| Step: 6
Training loss: 0.6215201060095712
Validation loss: 2.5076012489029926

Epoch: 5| Step: 7
Training loss: 0.6170599600439152
Validation loss: 2.4060614152001674

Epoch: 5| Step: 8
Training loss: 0.7785980226941874
Validation loss: 2.380928341191897

Epoch: 5| Step: 9
Training loss: 0.7330757579217646
Validation loss: 2.465178068059651

Epoch: 5| Step: 10
Training loss: 0.8816880348178525
Validation loss: 2.4712707959478983

Epoch: 594| Step: 0
Training loss: 1.546030218468134
Validation loss: 2.4682698715580194

Epoch: 5| Step: 1
Training loss: 0.538666621259335
Validation loss: 2.3795398807417527

Epoch: 5| Step: 2
Training loss: 0.6197260306302255
Validation loss: 2.38553120675342

Epoch: 5| Step: 3
Training loss: 0.9230281600314088
Validation loss: 2.420787630424063

Epoch: 5| Step: 4
Training loss: 0.7822097986070394
Validation loss: 2.395425802688269

Epoch: 5| Step: 5
Training loss: 0.8234668212534499
Validation loss: 2.4328764150886966

Epoch: 5| Step: 6
Training loss: 0.7487876550825489
Validation loss: 2.409457460444769

Epoch: 5| Step: 7
Training loss: 0.6783124673369395
Validation loss: 2.4219226643254634

Epoch: 5| Step: 8
Training loss: 0.6549409798974621
Validation loss: 2.4759006352728012

Epoch: 5| Step: 9
Training loss: 0.6076434059580679
Validation loss: 2.4768361332869246

Epoch: 5| Step: 10
Training loss: 0.8109600071365395
Validation loss: 2.443006004665613

Epoch: 595| Step: 0
Training loss: 0.9155996716221678
Validation loss: 2.4308157738081166

Epoch: 5| Step: 1
Training loss: 0.8626849155952485
Validation loss: 2.4087767144511254

Epoch: 5| Step: 2
Training loss: 0.6895379508682878
Validation loss: 2.472930148095091

Epoch: 5| Step: 3
Training loss: 1.6179602799131718
Validation loss: 2.5046971729803063

Epoch: 5| Step: 4
Training loss: 0.6591987211517086
Validation loss: 2.4364772230569263

Epoch: 5| Step: 5
Training loss: 0.5229401859247752
Validation loss: 2.4644169505933995

Epoch: 5| Step: 6
Training loss: 0.7806742644818475
Validation loss: 2.424683051312247

Epoch: 5| Step: 7
Training loss: 0.7858709242666359
Validation loss: 2.4038570839481164

Epoch: 5| Step: 8
Training loss: 0.8690685456637312
Validation loss: 2.419025200225895

Epoch: 5| Step: 9
Training loss: 0.4952641857663181
Validation loss: 2.4345694764054318

Epoch: 5| Step: 10
Training loss: 0.9651162693165837
Validation loss: 2.3965017541054854

Epoch: 596| Step: 0
Training loss: 0.5559957416083189
Validation loss: 2.413443577655693

Epoch: 5| Step: 1
Training loss: 0.7156020764673128
Validation loss: 2.4484181313098365

Epoch: 5| Step: 2
Training loss: 0.9521833990476338
Validation loss: 2.472681466828903

Epoch: 5| Step: 3
Training loss: 0.7884285901594724
Validation loss: 2.4228316191826655

Epoch: 5| Step: 4
Training loss: 0.7422794485857639
Validation loss: 2.4353430991238456

Epoch: 5| Step: 5
Training loss: 0.8927473913585673
Validation loss: 2.4743553712611046

Epoch: 5| Step: 6
Training loss: 1.5785663100999876
Validation loss: 2.4767907967991105

Epoch: 5| Step: 7
Training loss: 0.7166674754411733
Validation loss: 2.4763983956832885

Epoch: 5| Step: 8
Training loss: 0.9197631828647012
Validation loss: 2.4321428392063

Epoch: 5| Step: 9
Training loss: 0.7162307041624807
Validation loss: 2.4152576623315505

Epoch: 5| Step: 10
Training loss: 0.7792481906760943
Validation loss: 2.478456298389092

Epoch: 597| Step: 0
Training loss: 0.7282244634842467
Validation loss: 2.4263318138692194

Epoch: 5| Step: 1
Training loss: 0.7501004072371561
Validation loss: 2.5432889070916556

Epoch: 5| Step: 2
Training loss: 1.5946245225076006
Validation loss: 2.4383045211916734

Epoch: 5| Step: 3
Training loss: 0.7306336405482193
Validation loss: 2.5064574506149793

Epoch: 5| Step: 4
Training loss: 0.8910030098188878
Validation loss: 2.53571972479445

Epoch: 5| Step: 5
Training loss: 0.7937975906763206
Validation loss: 2.3259617804359407

Epoch: 5| Step: 6
Training loss: 0.8013057572697241
Validation loss: 2.47744364817082

Epoch: 5| Step: 7
Training loss: 0.7273762975308491
Validation loss: 2.5005531950042363

Epoch: 5| Step: 8
Training loss: 0.6596497166817111
Validation loss: 2.4396288220716134

Epoch: 5| Step: 9
Training loss: 0.631745746195171
Validation loss: 2.4001279531167024

Epoch: 5| Step: 10
Training loss: 0.84797205513668
Validation loss: 2.4446770366109374

Epoch: 598| Step: 0
Training loss: 0.958067103737508
Validation loss: 2.48447411049834

Epoch: 5| Step: 1
Training loss: 0.7771598560062914
Validation loss: 2.4563666075875727

Epoch: 5| Step: 2
Training loss: 0.8643434298936172
Validation loss: 2.4884025570047013

Epoch: 5| Step: 3
Training loss: 0.7592748316879666
Validation loss: 2.430198826392

Epoch: 5| Step: 4
Training loss: 0.8600788355334176
Validation loss: 2.503381035379492

Epoch: 5| Step: 5
Training loss: 0.7526659868626978
Validation loss: 2.412422106828194

Epoch: 5| Step: 6
Training loss: 1.0915832310500897
Validation loss: 2.4849769460006885

Epoch: 5| Step: 7
Training loss: 0.5086459143354247
Validation loss: 2.465162067469942

Epoch: 5| Step: 8
Training loss: 1.5014574599666004
Validation loss: 2.4747631186689443

Epoch: 5| Step: 9
Training loss: 0.6094674749387946
Validation loss: 2.5541061156779166

Epoch: 5| Step: 10
Training loss: 0.6821001575176179
Validation loss: 2.397766600384015

Epoch: 599| Step: 0
Training loss: 0.7637729821750889
Validation loss: 2.4150524993314755

Epoch: 5| Step: 1
Training loss: 0.7920958125458981
Validation loss: 2.462742812259544

Epoch: 5| Step: 2
Training loss: 1.5464833081562845
Validation loss: 2.4400393960200817

Epoch: 5| Step: 3
Training loss: 0.7972431080622859
Validation loss: 2.3402807656977633

Epoch: 5| Step: 4
Training loss: 0.4680155085924347
Validation loss: 2.4334186865024465

Epoch: 5| Step: 5
Training loss: 0.5430037123586582
Validation loss: 2.4104730512183195

Epoch: 5| Step: 6
Training loss: 0.8038430458780269
Validation loss: 2.4106482847534556

Epoch: 5| Step: 7
Training loss: 0.7636555233348704
Validation loss: 2.4860426870688013

Epoch: 5| Step: 8
Training loss: 0.704087615701688
Validation loss: 2.4633230423535077

Epoch: 5| Step: 9
Training loss: 0.8254076441875565
Validation loss: 2.4221220982701492

Epoch: 5| Step: 10
Training loss: 0.6485069421559847
Validation loss: 2.499369431004128

Epoch: 600| Step: 0
Training loss: 0.6085012970458401
Validation loss: 2.496356640159208

Epoch: 5| Step: 1
Training loss: 0.6430956950429603
Validation loss: 2.4708528484254524

Epoch: 5| Step: 2
Training loss: 0.6748821915146032
Validation loss: 2.4115897238778574

Epoch: 5| Step: 3
Training loss: 0.6393738135273683
Validation loss: 2.438173488677522

Epoch: 5| Step: 4
Training loss: 0.7124681867223053
Validation loss: 2.4122272325989846

Epoch: 5| Step: 5
Training loss: 1.6352827013225049
Validation loss: 2.3407235702669738

Epoch: 5| Step: 6
Training loss: 0.5875554697756185
Validation loss: 2.4664722681421094

Epoch: 5| Step: 7
Training loss: 0.8435396356072207
Validation loss: 2.408358427529356

Epoch: 5| Step: 8
Training loss: 0.6379630211828216
Validation loss: 2.3661882968073162

Epoch: 5| Step: 9
Training loss: 0.7526343096512266
Validation loss: 2.4536460833539655

Epoch: 5| Step: 10
Training loss: 0.6687248590681345
Validation loss: 2.3663472581254497

Epoch: 601| Step: 0
Training loss: 0.8670862155911008
Validation loss: 2.355849853403669

Epoch: 5| Step: 1
Training loss: 0.6923741392552786
Validation loss: 2.42186635174962

Epoch: 5| Step: 2
Training loss: 1.473008333813205
Validation loss: 2.4022317487578313

Epoch: 5| Step: 3
Training loss: 0.5682871664524327
Validation loss: 2.468008351326468

Epoch: 5| Step: 4
Training loss: 0.810075737862018
Validation loss: 2.4657260250590887

Epoch: 5| Step: 5
Training loss: 0.6757900700517266
Validation loss: 2.3461327192158605

Epoch: 5| Step: 6
Training loss: 0.5724116064321796
Validation loss: 2.496263147699357

Epoch: 5| Step: 7
Training loss: 0.6094306529136473
Validation loss: 2.4064304319849636

Epoch: 5| Step: 8
Training loss: 0.9008845962303372
Validation loss: 2.379618665220388

Epoch: 5| Step: 9
Training loss: 1.0057518170079813
Validation loss: 2.440445121212067

Epoch: 5| Step: 10
Training loss: 0.5531862656020663
Validation loss: 2.528047736620249

Epoch: 602| Step: 0
Training loss: 0.45692243666376764
Validation loss: 2.408533121458567

Epoch: 5| Step: 1
Training loss: 0.7189780163859425
Validation loss: 2.355366071803357

Epoch: 5| Step: 2
Training loss: 0.9598238314474957
Validation loss: 2.432260705507917

Epoch: 5| Step: 3
Training loss: 0.7935317723211632
Validation loss: 2.417620024931227

Epoch: 5| Step: 4
Training loss: 0.8484986158527151
Validation loss: 2.493916836347058

Epoch: 5| Step: 5
Training loss: 0.7078292305760606
Validation loss: 2.440196250681892

Epoch: 5| Step: 6
Training loss: 0.703101878315849
Validation loss: 2.437112092146257

Epoch: 5| Step: 7
Training loss: 0.6504118403276663
Validation loss: 2.4734274532394

Epoch: 5| Step: 8
Training loss: 1.4868206556538208
Validation loss: 2.435841006578223

Epoch: 5| Step: 9
Training loss: 0.6288576758919046
Validation loss: 2.388802719835611

Epoch: 5| Step: 10
Training loss: 0.8473778192676104
Validation loss: 2.4486784176322547

Epoch: 603| Step: 0
Training loss: 0.6584837227680013
Validation loss: 2.4820174773735437

Epoch: 5| Step: 1
Training loss: 0.9638640646222049
Validation loss: 2.426156584056115

Epoch: 5| Step: 2
Training loss: 0.8193186961600354
Validation loss: 2.3994140149542216

Epoch: 5| Step: 3
Training loss: 0.5794355899029207
Validation loss: 2.464555325292326

Epoch: 5| Step: 4
Training loss: 0.690929636502906
Validation loss: 2.469535026800833

Epoch: 5| Step: 5
Training loss: 0.6218204685244679
Validation loss: 2.441803398267119

Epoch: 5| Step: 6
Training loss: 1.4522694355798056
Validation loss: 2.4554314405080495

Epoch: 5| Step: 7
Training loss: 0.4007671725531672
Validation loss: 2.424531607073239

Epoch: 5| Step: 8
Training loss: 0.9247985968545314
Validation loss: 2.3659480146998804

Epoch: 5| Step: 9
Training loss: 0.6346392696505236
Validation loss: 2.513145933247196

Epoch: 5| Step: 10
Training loss: 0.6822727409436378
Validation loss: 2.485446453549486

Epoch: 604| Step: 0
Training loss: 0.6243906865712594
Validation loss: 2.4413635318423346

Epoch: 5| Step: 1
Training loss: 0.7450735496851705
Validation loss: 2.454325919755114

Epoch: 5| Step: 2
Training loss: 0.685680974033404
Validation loss: 2.4515291060961704

Epoch: 5| Step: 3
Training loss: 0.6399094376713536
Validation loss: 2.4657604111566007

Epoch: 5| Step: 4
Training loss: 1.084233215912816
Validation loss: 2.4090400840010067

Epoch: 5| Step: 5
Training loss: 0.5376822728115023
Validation loss: 2.4214747907674656

Epoch: 5| Step: 6
Training loss: 1.6160049906549723
Validation loss: 2.4647952249974043

Epoch: 5| Step: 7
Training loss: 0.5383148814022122
Validation loss: 2.4783286590265075

Epoch: 5| Step: 8
Training loss: 0.7431890054895552
Validation loss: 2.416696560653217

Epoch: 5| Step: 9
Training loss: 0.6649664168374957
Validation loss: 2.4288675685295185

Epoch: 5| Step: 10
Training loss: 0.5743729261126348
Validation loss: 2.4620287102165306

Epoch: 605| Step: 0
Training loss: 0.6334858361477089
Validation loss: 2.4225764131856566

Epoch: 5| Step: 1
Training loss: 0.5523928338543146
Validation loss: 2.436098092116796

Epoch: 5| Step: 2
Training loss: 1.4900294171700041
Validation loss: 2.5180627375279454

Epoch: 5| Step: 3
Training loss: 0.6974405448622171
Validation loss: 2.3628467762152647

Epoch: 5| Step: 4
Training loss: 0.6166453334194104
Validation loss: 2.407631511191402

Epoch: 5| Step: 5
Training loss: 1.0953677066924536
Validation loss: 2.4689343935130594

Epoch: 5| Step: 6
Training loss: 0.736156291794714
Validation loss: 2.341469463665376

Epoch: 5| Step: 7
Training loss: 0.7437088081429161
Validation loss: 2.428850643720053

Epoch: 5| Step: 8
Training loss: 0.8559593292048803
Validation loss: 2.4055036013893694

Epoch: 5| Step: 9
Training loss: 0.5725544275623146
Validation loss: 2.426746258564031

Epoch: 5| Step: 10
Training loss: 0.6624021529869897
Validation loss: 2.424923797211889

Epoch: 606| Step: 0
Training loss: 1.485545931305988
Validation loss: 2.413292578563445

Epoch: 5| Step: 1
Training loss: 0.766672546599134
Validation loss: 2.361463585429452

Epoch: 5| Step: 2
Training loss: 0.6866427191783652
Validation loss: 2.3798565186633343

Epoch: 5| Step: 3
Training loss: 1.0426283148600934
Validation loss: 2.402210159382396

Epoch: 5| Step: 4
Training loss: 0.673449644966097
Validation loss: 2.4961779357464815

Epoch: 5| Step: 5
Training loss: 0.6223137587269935
Validation loss: 2.411166260034422

Epoch: 5| Step: 6
Training loss: 0.7892786995083481
Validation loss: 2.463232365481268

Epoch: 5| Step: 7
Training loss: 0.4943614059392538
Validation loss: 2.381315712095701

Epoch: 5| Step: 8
Training loss: 0.4915373610599809
Validation loss: 2.437223336184766

Epoch: 5| Step: 9
Training loss: 0.6900866572240092
Validation loss: 2.398679454319958

Epoch: 5| Step: 10
Training loss: 0.7724600115552288
Validation loss: 2.4196335258081025

Epoch: 607| Step: 0
Training loss: 0.6675590016866522
Validation loss: 2.3856459945907798

Epoch: 5| Step: 1
Training loss: 0.6611298148285877
Validation loss: 2.3825291188560396

Epoch: 5| Step: 2
Training loss: 0.8423942694270743
Validation loss: 2.362031187546111

Epoch: 5| Step: 3
Training loss: 0.7260992152330775
Validation loss: 2.434823116848413

Epoch: 5| Step: 4
Training loss: 0.876057564723076
Validation loss: 2.4537133349419253

Epoch: 5| Step: 5
Training loss: 0.4350265679522287
Validation loss: 2.4238052006806874

Epoch: 5| Step: 6
Training loss: 0.9429747308701012
Validation loss: 2.4218975689299866

Epoch: 5| Step: 7
Training loss: 0.5605320413467666
Validation loss: 2.4256006329849336

Epoch: 5| Step: 8
Training loss: 0.7378426515524921
Validation loss: 2.3453681823268413

Epoch: 5| Step: 9
Training loss: 1.507167065296221
Validation loss: 2.421063990034929

Epoch: 5| Step: 10
Training loss: 0.7987262688873947
Validation loss: 2.411824386080019

Epoch: 608| Step: 0
Training loss: 0.577469067013456
Validation loss: 2.4259262196204063

Epoch: 5| Step: 1
Training loss: 0.8057200649333451
Validation loss: 2.3582503570699243

Epoch: 5| Step: 2
Training loss: 1.5049689959504058
Validation loss: 2.4477574494125585

Epoch: 5| Step: 3
Training loss: 0.6907219814371129
Validation loss: 2.392885323868918

Epoch: 5| Step: 4
Training loss: 0.6561258516500523
Validation loss: 2.4053211057300916

Epoch: 5| Step: 5
Training loss: 0.8539446836933146
Validation loss: 2.465160477388767

Epoch: 5| Step: 6
Training loss: 0.615155508647973
Validation loss: 2.3765365345129412

Epoch: 5| Step: 7
Training loss: 0.7709178147974586
Validation loss: 2.4607039747564117

Epoch: 5| Step: 8
Training loss: 0.6766712524191338
Validation loss: 2.441062813965826

Epoch: 5| Step: 9
Training loss: 0.5171260370802444
Validation loss: 2.4569825983521856

Epoch: 5| Step: 10
Training loss: 0.8796472435204592
Validation loss: 2.3617181430329417

Epoch: 609| Step: 0
Training loss: 0.8522834875410122
Validation loss: 2.3825694368530295

Epoch: 5| Step: 1
Training loss: 0.6180282612344633
Validation loss: 2.3913567672579767

Epoch: 5| Step: 2
Training loss: 0.7445378882641581
Validation loss: 2.4467380664997513

Epoch: 5| Step: 3
Training loss: 0.7273222529822854
Validation loss: 2.480220568256447

Epoch: 5| Step: 4
Training loss: 0.8399784068897159
Validation loss: 2.422874258828129

Epoch: 5| Step: 5
Training loss: 0.6405102929487599
Validation loss: 2.4560216738332508

Epoch: 5| Step: 6
Training loss: 1.5389278759629288
Validation loss: 2.4079463521015354

Epoch: 5| Step: 7
Training loss: 0.6536742479042597
Validation loss: 2.3793990284553854

Epoch: 5| Step: 8
Training loss: 0.7356174185985285
Validation loss: 2.4191430600084822

Epoch: 5| Step: 9
Training loss: 0.5848876703450774
Validation loss: 2.4152513892385934

Epoch: 5| Step: 10
Training loss: 0.5831904804062412
Validation loss: 2.432296743087037

Epoch: 610| Step: 0
Training loss: 0.5706317478378437
Validation loss: 2.4251535063232392

Epoch: 5| Step: 1
Training loss: 1.4823088873021297
Validation loss: 2.406706184109582

Epoch: 5| Step: 2
Training loss: 0.724988894541956
Validation loss: 2.4269610279132485

Epoch: 5| Step: 3
Training loss: 0.5375637837201604
Validation loss: 2.42956293427297

Epoch: 5| Step: 4
Training loss: 0.5040925147431818
Validation loss: 2.4308800686857013

Epoch: 5| Step: 5
Training loss: 0.6446433692283997
Validation loss: 2.3523468474520928

Epoch: 5| Step: 6
Training loss: 0.7332735526759755
Validation loss: 2.4406079339953597

Epoch: 5| Step: 7
Training loss: 0.6892692385532039
Validation loss: 2.449223234134555

Epoch: 5| Step: 8
Training loss: 0.7892204353225407
Validation loss: 2.418040865767437

Epoch: 5| Step: 9
Training loss: 0.7162407320897589
Validation loss: 2.457905247330069

Epoch: 5| Step: 10
Training loss: 0.6487879897444131
Validation loss: 2.4591061097223097

Epoch: 611| Step: 0
Training loss: 0.5523731952248427
Validation loss: 2.5237518595274535

Epoch: 5| Step: 1
Training loss: 0.6632906747963901
Validation loss: 2.4585844119918803

Epoch: 5| Step: 2
Training loss: 0.7041324180159458
Validation loss: 2.437420337049392

Epoch: 5| Step: 3
Training loss: 1.6076399700398263
Validation loss: 2.463184255750611

Epoch: 5| Step: 4
Training loss: 0.8370537835983735
Validation loss: 2.416663762502089

Epoch: 5| Step: 5
Training loss: 0.5315420245712896
Validation loss: 2.4186945774132296

Epoch: 5| Step: 6
Training loss: 0.6058956487091105
Validation loss: 2.3778912416845484

Epoch: 5| Step: 7
Training loss: 0.5156547364416785
Validation loss: 2.4601990273618974

Epoch: 5| Step: 8
Training loss: 0.9420443386548579
Validation loss: 2.410502476070224

Epoch: 5| Step: 9
Training loss: 0.8125535873934819
Validation loss: 2.3964344042882564

Epoch: 5| Step: 10
Training loss: 0.40801773241838657
Validation loss: 2.4329769301116

Epoch: 612| Step: 0
Training loss: 0.8385378243178641
Validation loss: 2.3954632901785615

Epoch: 5| Step: 1
Training loss: 0.5165165504931714
Validation loss: 2.4023554703861505

Epoch: 5| Step: 2
Training loss: 0.7641926816410682
Validation loss: 2.398447829629082

Epoch: 5| Step: 3
Training loss: 1.437627786678595
Validation loss: 2.4264373560450676

Epoch: 5| Step: 4
Training loss: 0.6023991204328816
Validation loss: 2.466900033839606

Epoch: 5| Step: 5
Training loss: 0.670750186537675
Validation loss: 2.4024201305034714

Epoch: 5| Step: 6
Training loss: 0.5635141660945638
Validation loss: 2.34423557952898

Epoch: 5| Step: 7
Training loss: 0.878808859621515
Validation loss: 2.4354919142665987

Epoch: 5| Step: 8
Training loss: 0.7242016326296992
Validation loss: 2.4481244955724404

Epoch: 5| Step: 9
Training loss: 0.8387679906243128
Validation loss: 2.443468756650564

Epoch: 5| Step: 10
Training loss: 0.7420103564426481
Validation loss: 2.314211102316046

Epoch: 613| Step: 0
Training loss: 0.8055795706169173
Validation loss: 2.4054733587043944

Epoch: 5| Step: 1
Training loss: 0.5815006884524074
Validation loss: 2.4578003914870297

Epoch: 5| Step: 2
Training loss: 0.7901189549134442
Validation loss: 2.4619331508650335

Epoch: 5| Step: 3
Training loss: 1.5192335763922054
Validation loss: 2.419801474468852

Epoch: 5| Step: 4
Training loss: 0.6327755057741876
Validation loss: 2.412401625646411

Epoch: 5| Step: 5
Training loss: 0.73792104663407
Validation loss: 2.3943393266817985

Epoch: 5| Step: 6
Training loss: 0.5881922762231698
Validation loss: 2.5080646256154444

Epoch: 5| Step: 7
Training loss: 0.5411010564563585
Validation loss: 2.3964810400501353

Epoch: 5| Step: 8
Training loss: 0.5103554072565544
Validation loss: 2.4234523308844564

Epoch: 5| Step: 9
Training loss: 0.7349923156803695
Validation loss: 2.429875822128166

Epoch: 5| Step: 10
Training loss: 0.48288011602110414
Validation loss: 2.495668203878354

Epoch: 614| Step: 0
Training loss: 0.6502268587883661
Validation loss: 2.439860715015736

Epoch: 5| Step: 1
Training loss: 0.7076941907081782
Validation loss: 2.3786589433011787

Epoch: 5| Step: 2
Training loss: 0.8753911915019363
Validation loss: 2.4536464119526706

Epoch: 5| Step: 3
Training loss: 0.5119843703581466
Validation loss: 2.4236634847782597

Epoch: 5| Step: 4
Training loss: 0.6599015867669431
Validation loss: 2.4087594111374124

Epoch: 5| Step: 5
Training loss: 0.5361021272810286
Validation loss: 2.3810210553093563

Epoch: 5| Step: 6
Training loss: 0.7644904547121022
Validation loss: 2.4106986414331266

Epoch: 5| Step: 7
Training loss: 0.6975056852088493
Validation loss: 2.4511270417406057

Epoch: 5| Step: 8
Training loss: 0.47701879450720847
Validation loss: 2.444501516750151

Epoch: 5| Step: 9
Training loss: 1.5217367998543656
Validation loss: 2.4335436616581325

Epoch: 5| Step: 10
Training loss: 0.545621661889351
Validation loss: 2.3509335322504423

Epoch: 615| Step: 0
Training loss: 0.7848463822961826
Validation loss: 2.4984009797304694

Epoch: 5| Step: 1
Training loss: 0.7651942851619414
Validation loss: 2.388435709822282

Epoch: 5| Step: 2
Training loss: 0.6344511691062005
Validation loss: 2.3899004542864923

Epoch: 5| Step: 3
Training loss: 0.6678530274920804
Validation loss: 2.3935244389684445

Epoch: 5| Step: 4
Training loss: 0.6805774737632451
Validation loss: 2.409378116278409

Epoch: 5| Step: 5
Training loss: 0.642207772336394
Validation loss: 2.434509674891771

Epoch: 5| Step: 6
Training loss: 0.5487357228101067
Validation loss: 2.4403341348712595

Epoch: 5| Step: 7
Training loss: 0.6058089254343276
Validation loss: 2.4142299824580067

Epoch: 5| Step: 8
Training loss: 1.5271027904205978
Validation loss: 2.4445511157670357

Epoch: 5| Step: 9
Training loss: 0.6612230743594198
Validation loss: 2.5290413633096427

Epoch: 5| Step: 10
Training loss: 0.4747129727548743
Validation loss: 2.40852545777241

Epoch: 616| Step: 0
Training loss: 0.8332406509039739
Validation loss: 2.5136854005961506

Epoch: 5| Step: 1
Training loss: 1.5321174033226328
Validation loss: 2.399153270953813

Epoch: 5| Step: 2
Training loss: 0.6334099951156312
Validation loss: 2.431583985022658

Epoch: 5| Step: 3
Training loss: 0.5526655174472734
Validation loss: 2.3593181577997298

Epoch: 5| Step: 4
Training loss: 0.5718305580922738
Validation loss: 2.411407160441366

Epoch: 5| Step: 5
Training loss: 0.7767839956342855
Validation loss: 2.344641315767072

Epoch: 5| Step: 6
Training loss: 0.595216120529996
Validation loss: 2.476528654148345

Epoch: 5| Step: 7
Training loss: 0.8308575729257314
Validation loss: 2.4246895801901567

Epoch: 5| Step: 8
Training loss: 0.7891069909573704
Validation loss: 2.4718761347792237

Epoch: 5| Step: 9
Training loss: 0.62921547247784
Validation loss: 2.4860101603216376

Epoch: 5| Step: 10
Training loss: 0.7332148214148062
Validation loss: 2.445198250103051

Epoch: 617| Step: 0
Training loss: 0.7515292471589693
Validation loss: 2.393759116272676

Epoch: 5| Step: 1
Training loss: 0.5495491314739964
Validation loss: 2.5332998930786266

Epoch: 5| Step: 2
Training loss: 0.5321045621979981
Validation loss: 2.29720632989835

Epoch: 5| Step: 3
Training loss: 0.582452301724772
Validation loss: 2.479463222081015

Epoch: 5| Step: 4
Training loss: 0.9776414937592534
Validation loss: 2.4627528190808974

Epoch: 5| Step: 5
Training loss: 0.6741268214634939
Validation loss: 2.4646462762029513

Epoch: 5| Step: 6
Training loss: 0.8780512741471498
Validation loss: 2.4252781219973714

Epoch: 5| Step: 7
Training loss: 0.5900155379382998
Validation loss: 2.432029626915337

Epoch: 5| Step: 8
Training loss: 0.4423741556630049
Validation loss: 2.4773128934870026

Epoch: 5| Step: 9
Training loss: 0.6948769523248697
Validation loss: 2.4914277519183385

Epoch: 5| Step: 10
Training loss: 1.5820197210951448
Validation loss: 2.452613889664284

Epoch: 618| Step: 0
Training loss: 0.848826571733903
Validation loss: 2.4019772560601127

Epoch: 5| Step: 1
Training loss: 0.6305497298295968
Validation loss: 2.4064518247657776

Epoch: 5| Step: 2
Training loss: 0.9782243245550345
Validation loss: 2.393922790007446

Epoch: 5| Step: 3
Training loss: 0.8500182472402148
Validation loss: 2.4424904976458204

Epoch: 5| Step: 4
Training loss: 0.6568223637072453
Validation loss: 2.396928079316884

Epoch: 5| Step: 5
Training loss: 0.687744443959043
Validation loss: 2.442539557606242

Epoch: 5| Step: 6
Training loss: 0.5525098149044919
Validation loss: 2.4218030248685087

Epoch: 5| Step: 7
Training loss: 0.40110638538010407
Validation loss: 2.422518086075245

Epoch: 5| Step: 8
Training loss: 1.562499008178396
Validation loss: 2.3964498662013067

Epoch: 5| Step: 9
Training loss: 0.6614285234557502
Validation loss: 2.4388356494774315

Epoch: 5| Step: 10
Training loss: 0.7281145316095897
Validation loss: 2.4522910831616205

Epoch: 619| Step: 0
Training loss: 0.5811470022518557
Validation loss: 2.4554773947891633

Epoch: 5| Step: 1
Training loss: 0.7746020325867223
Validation loss: 2.437714686377471

Epoch: 5| Step: 2
Training loss: 0.6987951263432468
Validation loss: 2.427861490628336

Epoch: 5| Step: 3
Training loss: 0.6973753343284942
Validation loss: 2.459182713144484

Epoch: 5| Step: 4
Training loss: 0.8051395072654601
Validation loss: 2.401096918236769

Epoch: 5| Step: 5
Training loss: 0.6886443238094436
Validation loss: 2.391298728213828

Epoch: 5| Step: 6
Training loss: 1.4409839042384096
Validation loss: 2.4342318718599416

Epoch: 5| Step: 7
Training loss: 0.8746212752752085
Validation loss: 2.4323405991024063

Epoch: 5| Step: 8
Training loss: 0.48295306100974195
Validation loss: 2.448240038777574

Epoch: 5| Step: 9
Training loss: 0.5578458888214995
Validation loss: 2.50249281214616

Epoch: 5| Step: 10
Training loss: 0.8299188079533125
Validation loss: 2.4115365426169215

Epoch: 620| Step: 0
Training loss: 1.6397914403793197
Validation loss: 2.426870543152918

Epoch: 5| Step: 1
Training loss: 0.5534314723577797
Validation loss: 2.3747223398694763

Epoch: 5| Step: 2
Training loss: 0.6825558221436385
Validation loss: 2.3850140801246287

Epoch: 5| Step: 3
Training loss: 0.5496850705160872
Validation loss: 2.459516233027521

Epoch: 5| Step: 4
Training loss: 0.6704929686852548
Validation loss: 2.4568255507114545

Epoch: 5| Step: 5
Training loss: 0.5514137748362639
Validation loss: 2.4312526638017364

Epoch: 5| Step: 6
Training loss: 0.561724896987579
Validation loss: 2.4547155117697903

Epoch: 5| Step: 7
Training loss: 0.7116948798957702
Validation loss: 2.379166950676727

Epoch: 5| Step: 8
Training loss: 0.5115475841531167
Validation loss: 2.4958101340907133

Epoch: 5| Step: 9
Training loss: 0.6127989992855656
Validation loss: 2.3708697565280006

Epoch: 5| Step: 10
Training loss: 0.5657890640389209
Validation loss: 2.4745577972665203

Epoch: 621| Step: 0
Training loss: 0.7084372855557596
Validation loss: 2.455468847138732

Epoch: 5| Step: 1
Training loss: 0.6534625527219059
Validation loss: 2.3585105490757954

Epoch: 5| Step: 2
Training loss: 0.5347763996696764
Validation loss: 2.412425499973519

Epoch: 5| Step: 3
Training loss: 0.6780872580577316
Validation loss: 2.3349352500183516

Epoch: 5| Step: 4
Training loss: 0.6437410076216978
Validation loss: 2.4955927352915404

Epoch: 5| Step: 5
Training loss: 0.5236313304431948
Validation loss: 2.475620733417326

Epoch: 5| Step: 6
Training loss: 0.8445798184159065
Validation loss: 2.3991465860294463

Epoch: 5| Step: 7
Training loss: 0.49586469513686765
Validation loss: 2.4471017696427095

Epoch: 5| Step: 8
Training loss: 0.7477648728886576
Validation loss: 2.4265332313976655

Epoch: 5| Step: 9
Training loss: 1.5074391273367334
Validation loss: 2.448287778296098

Epoch: 5| Step: 10
Training loss: 0.6507429938274425
Validation loss: 2.441588024567005

Epoch: 622| Step: 0
Training loss: 0.959455230787613
Validation loss: 2.445533424537366

Epoch: 5| Step: 1
Training loss: 0.4729793799686235
Validation loss: 2.457262847036844

Epoch: 5| Step: 2
Training loss: 1.654218255238699
Validation loss: 2.397855704603987

Epoch: 5| Step: 3
Training loss: 0.43637352060959433
Validation loss: 2.4383314784893177

Epoch: 5| Step: 4
Training loss: 0.5670001106615312
Validation loss: 2.4399694539364867

Epoch: 5| Step: 5
Training loss: 0.8198335975351339
Validation loss: 2.4245615406638543

Epoch: 5| Step: 6
Training loss: 0.7455591413473599
Validation loss: 2.448654905145929

Epoch: 5| Step: 7
Training loss: 0.6519266496862952
Validation loss: 2.451297164478056

Epoch: 5| Step: 8
Training loss: 0.4667535067407656
Validation loss: 2.420436121283697

Epoch: 5| Step: 9
Training loss: 0.629563195806759
Validation loss: 2.538620524594791

Epoch: 5| Step: 10
Training loss: 0.5140732332170035
Validation loss: 2.4617107988356324

Epoch: 623| Step: 0
Training loss: 0.664839122141993
Validation loss: 2.371990846068727

Epoch: 5| Step: 1
Training loss: 0.8203333170837975
Validation loss: 2.432990567127106

Epoch: 5| Step: 2
Training loss: 0.4986223972068058
Validation loss: 2.387716575729365

Epoch: 5| Step: 3
Training loss: 0.694833998031585
Validation loss: 2.4148169076565327

Epoch: 5| Step: 4
Training loss: 0.7015061498156244
Validation loss: 2.4366679673884195

Epoch: 5| Step: 5
Training loss: 0.8424012742649668
Validation loss: 2.4759025891428

Epoch: 5| Step: 6
Training loss: 0.7187959822168289
Validation loss: 2.3708090784186817

Epoch: 5| Step: 7
Training loss: 1.5334284331366763
Validation loss: 2.5009508273156285

Epoch: 5| Step: 8
Training loss: 0.485264023805664
Validation loss: 2.4553858818595815

Epoch: 5| Step: 9
Training loss: 0.5830440541924605
Validation loss: 2.4083512156911544

Epoch: 5| Step: 10
Training loss: 0.3326662722896928
Validation loss: 2.4417757538130616

Epoch: 624| Step: 0
Training loss: 0.5830927903498501
Validation loss: 2.4221881390120745

Epoch: 5| Step: 1
Training loss: 0.6054720970799623
Validation loss: 2.4963349287405285

Epoch: 5| Step: 2
Training loss: 0.690350561720257
Validation loss: 2.4206879150752822

Epoch: 5| Step: 3
Training loss: 0.5701894235408124
Validation loss: 2.366991669961251

Epoch: 5| Step: 4
Training loss: 0.9693316282583542
Validation loss: 2.4547897468277253

Epoch: 5| Step: 5
Training loss: 0.38927447507789936
Validation loss: 2.465411742207926

Epoch: 5| Step: 6
Training loss: 0.7896676717185241
Validation loss: 2.4072645797444823

Epoch: 5| Step: 7
Training loss: 1.5238407481633176
Validation loss: 2.444575104510658

Epoch: 5| Step: 8
Training loss: 0.6165274216910439
Validation loss: 2.386631138243188

Epoch: 5| Step: 9
Training loss: 0.8018534111987973
Validation loss: 2.4716779823329915

Epoch: 5| Step: 10
Training loss: 0.4801114467295949
Validation loss: 2.4770396497467546

Epoch: 625| Step: 0
Training loss: 1.4826380153696115
Validation loss: 2.373894261897156

Epoch: 5| Step: 1
Training loss: 0.5665288858178671
Validation loss: 2.465221738970352

Epoch: 5| Step: 2
Training loss: 0.6595463390020565
Validation loss: 2.449653125497784

Epoch: 5| Step: 3
Training loss: 0.735225428570483
Validation loss: 2.465722417261863

Epoch: 5| Step: 4
Training loss: 0.8889999622413619
Validation loss: 2.400883208916268

Epoch: 5| Step: 5
Training loss: 0.6571576335975318
Validation loss: 2.432781292377466

Epoch: 5| Step: 6
Training loss: 0.6265300618667065
Validation loss: 2.3828536050425946

Epoch: 5| Step: 7
Training loss: 0.7781892328675792
Validation loss: 2.431310993309656

Epoch: 5| Step: 8
Training loss: 0.6023347777256257
Validation loss: 2.372368652891166

Epoch: 5| Step: 9
Training loss: 0.6659153837687216
Validation loss: 2.3878616532416173

Epoch: 5| Step: 10
Training loss: 0.850590141977984
Validation loss: 2.4433153185757877

Epoch: 626| Step: 0
Training loss: 0.5280223295193479
Validation loss: 2.3968185642557738

Epoch: 5| Step: 1
Training loss: 0.620224974868911
Validation loss: 2.473695571148824

Epoch: 5| Step: 2
Training loss: 0.8440134908605841
Validation loss: 2.4540218069702204

Epoch: 5| Step: 3
Training loss: 0.7186176758739808
Validation loss: 2.379293982443228

Epoch: 5| Step: 4
Training loss: 0.7659945082878482
Validation loss: 2.4457080962312907

Epoch: 5| Step: 5
Training loss: 0.505396421230901
Validation loss: 2.455516145957072

Epoch: 5| Step: 6
Training loss: 0.6302908588527898
Validation loss: 2.400576586599587

Epoch: 5| Step: 7
Training loss: 0.6327238845002653
Validation loss: 2.398116630309904

Epoch: 5| Step: 8
Training loss: 1.486797885121711
Validation loss: 2.472508471019767

Epoch: 5| Step: 9
Training loss: 0.8401819657030888
Validation loss: 2.4577892291230494

Epoch: 5| Step: 10
Training loss: 0.5985577335540314
Validation loss: 2.448012267693715

Epoch: 627| Step: 0
Training loss: 0.5370857649729126
Validation loss: 2.443388718578298

Epoch: 5| Step: 1
Training loss: 1.4674159545486551
Validation loss: 2.4480612484124107

Epoch: 5| Step: 2
Training loss: 0.5492644560938225
Validation loss: 2.468402980165628

Epoch: 5| Step: 3
Training loss: 0.8082319546734321
Validation loss: 2.491327572085503

Epoch: 5| Step: 4
Training loss: 0.4544213758254119
Validation loss: 2.435026454048647

Epoch: 5| Step: 5
Training loss: 0.5435659568460021
Validation loss: 2.397503834553619

Epoch: 5| Step: 6
Training loss: 0.8148931325576526
Validation loss: 2.435362358908479

Epoch: 5| Step: 7
Training loss: 0.7560792351859049
Validation loss: 2.387340935762909

Epoch: 5| Step: 8
Training loss: 0.5057332238749265
Validation loss: 2.455696995620495

Epoch: 5| Step: 9
Training loss: 0.87707508488006
Validation loss: 2.3883424876134334

Epoch: 5| Step: 10
Training loss: 0.5893248239560237
Validation loss: 2.4060149331692076

Epoch: 628| Step: 0
Training loss: 0.7684084839246762
Validation loss: 2.498976495895453

Epoch: 5| Step: 1
Training loss: 0.5548609610111616
Validation loss: 2.3962157402153057

Epoch: 5| Step: 2
Training loss: 0.5519179390330996
Validation loss: 2.462846683750598

Epoch: 5| Step: 3
Training loss: 1.414557944488033
Validation loss: 2.3726170571799123

Epoch: 5| Step: 4
Training loss: 0.5707218843336522
Validation loss: 2.40400923395843

Epoch: 5| Step: 5
Training loss: 0.8881138653094105
Validation loss: 2.4493663306570155

Epoch: 5| Step: 6
Training loss: 0.5874670029565571
Validation loss: 2.470008122448774

Epoch: 5| Step: 7
Training loss: 0.6595890610695805
Validation loss: 2.3660310237685

Epoch: 5| Step: 8
Training loss: 0.5915192056522267
Validation loss: 2.4076074277414556

Epoch: 5| Step: 9
Training loss: 0.6919747510021962
Validation loss: 2.424680190230817

Epoch: 5| Step: 10
Training loss: 0.5726164175546639
Validation loss: 2.4303993944512077

Epoch: 629| Step: 0
Training loss: 0.6134095999173282
Validation loss: 2.3811321797946756

Epoch: 5| Step: 1
Training loss: 0.6176160941857091
Validation loss: 2.4065589860885264

Epoch: 5| Step: 2
Training loss: 1.4684973966207213
Validation loss: 2.4287899604215433

Epoch: 5| Step: 3
Training loss: 0.48440822364321884
Validation loss: 2.4089250870197425

Epoch: 5| Step: 4
Training loss: 0.6745461881077878
Validation loss: 2.4441943515754607

Epoch: 5| Step: 5
Training loss: 0.6362801193572738
Validation loss: 2.442617015381064

Epoch: 5| Step: 6
Training loss: 0.9501589918104879
Validation loss: 2.457032070104019

Epoch: 5| Step: 7
Training loss: 0.767403774504318
Validation loss: 2.5024272794767466

Epoch: 5| Step: 8
Training loss: 1.0871510482953564
Validation loss: 2.4167408470778

Epoch: 5| Step: 9
Training loss: 0.5424136336089372
Validation loss: 2.3800677487778548

Epoch: 5| Step: 10
Training loss: 0.5494709797711819
Validation loss: 2.4151501959477106

Epoch: 630| Step: 0
Training loss: 0.5377704782599197
Validation loss: 2.362148662285671

Epoch: 5| Step: 1
Training loss: 0.6405922951142348
Validation loss: 2.430689340553257

Epoch: 5| Step: 2
Training loss: 0.5237390588969568
Validation loss: 2.440543253050344

Epoch: 5| Step: 3
Training loss: 0.5597960331411348
Validation loss: 2.412703146806373

Epoch: 5| Step: 4
Training loss: 0.9188109085757381
Validation loss: 2.4064048847221904

Epoch: 5| Step: 5
Training loss: 0.604493814444625
Validation loss: 2.4375609712886863

Epoch: 5| Step: 6
Training loss: 0.742972831835199
Validation loss: 2.411701197516003

Epoch: 5| Step: 7
Training loss: 1.71654493894124
Validation loss: 2.4256838970092542

Epoch: 5| Step: 8
Training loss: 0.65684849831705
Validation loss: 2.4082372109579286

Epoch: 5| Step: 9
Training loss: 0.6731446711535788
Validation loss: 2.501620718941001

Epoch: 5| Step: 10
Training loss: 0.6483943649100664
Validation loss: 2.3860192507495777

Epoch: 631| Step: 0
Training loss: 0.5594453255970436
Validation loss: 2.382856604566182

Epoch: 5| Step: 1
Training loss: 0.7342843344703547
Validation loss: 2.422836765860919

Epoch: 5| Step: 2
Training loss: 0.7301662859236157
Validation loss: 2.4353905082792657

Epoch: 5| Step: 3
Training loss: 0.5843217315466864
Validation loss: 2.4456060325693123

Epoch: 5| Step: 4
Training loss: 0.7160138835147006
Validation loss: 2.4212689512408816

Epoch: 5| Step: 5
Training loss: 1.5523305691762774
Validation loss: 2.4098323827063446

Epoch: 5| Step: 6
Training loss: 0.560162987661874
Validation loss: 2.3439142624913476

Epoch: 5| Step: 7
Training loss: 0.5737592454551824
Validation loss: 2.320654921050355

Epoch: 5| Step: 8
Training loss: 0.6984517669927374
Validation loss: 2.461792887343985

Epoch: 5| Step: 9
Training loss: 0.5631979479944035
Validation loss: 2.3989223853071744

Epoch: 5| Step: 10
Training loss: 0.7967052278869297
Validation loss: 2.4638552727669145

Epoch: 632| Step: 0
Training loss: 0.7233984357861774
Validation loss: 2.3973934093148155

Epoch: 5| Step: 1
Training loss: 1.530234408778582
Validation loss: 2.3861277949148616

Epoch: 5| Step: 2
Training loss: 0.7604463954670807
Validation loss: 2.3857502263247246

Epoch: 5| Step: 3
Training loss: 0.4946796809173142
Validation loss: 2.379882946074405

Epoch: 5| Step: 4
Training loss: 0.7136194970965637
Validation loss: 2.35388943557765

Epoch: 5| Step: 5
Training loss: 0.5745856741160661
Validation loss: 2.418052587464356

Epoch: 5| Step: 6
Training loss: 0.5135815036893151
Validation loss: 2.42122189980968

Epoch: 5| Step: 7
Training loss: 0.7009452729935771
Validation loss: 2.457233386404125

Epoch: 5| Step: 8
Training loss: 0.5088518217482431
Validation loss: 2.379885844852582

Epoch: 5| Step: 9
Training loss: 0.7088036004575643
Validation loss: 2.4016290804344855

Epoch: 5| Step: 10
Training loss: 0.7757780706949384
Validation loss: 2.417393589557405

Epoch: 633| Step: 0
Training loss: 0.7458888866115745
Validation loss: 2.358346264018615

Epoch: 5| Step: 1
Training loss: 0.5857134581437063
Validation loss: 2.430347358431798

Epoch: 5| Step: 2
Training loss: 0.517116095693312
Validation loss: 2.4189168821978955

Epoch: 5| Step: 3
Training loss: 0.5338654927858816
Validation loss: 2.465092481479807

Epoch: 5| Step: 4
Training loss: 0.5031621599394636
Validation loss: 2.4046061227217677

Epoch: 5| Step: 5
Training loss: 0.6209938880724069
Validation loss: 2.4851907979942114

Epoch: 5| Step: 6
Training loss: 0.7966460104649273
Validation loss: 2.4118619120563785

Epoch: 5| Step: 7
Training loss: 0.6389132169109031
Validation loss: 2.415750792948246

Epoch: 5| Step: 8
Training loss: 1.6090717955954412
Validation loss: 2.418288335663591

Epoch: 5| Step: 9
Training loss: 0.7219791023526988
Validation loss: 2.4741815050345433

Epoch: 5| Step: 10
Training loss: 0.7061531135471534
Validation loss: 2.4713168141025106

Epoch: 634| Step: 0
Training loss: 0.5679362186733538
Validation loss: 2.481113260769089

Epoch: 5| Step: 1
Training loss: 1.4077428734906703
Validation loss: 2.4048498816280293

Epoch: 5| Step: 2
Training loss: 0.6189061391705628
Validation loss: 2.554147272414919

Epoch: 5| Step: 3
Training loss: 0.9075453806793361
Validation loss: 2.454104334959994

Epoch: 5| Step: 4
Training loss: 0.9155962864666747
Validation loss: 2.4350756670206573

Epoch: 5| Step: 5
Training loss: 1.031443779974393
Validation loss: 2.4722764848926233

Epoch: 5| Step: 6
Training loss: 0.45546879187660616
Validation loss: 2.4498952255966504

Epoch: 5| Step: 7
Training loss: 0.7309569089350474
Validation loss: 2.4572598188823513

Epoch: 5| Step: 8
Training loss: 0.49322856821133304
Validation loss: 2.38490145476368

Epoch: 5| Step: 9
Training loss: 0.5112163610980277
Validation loss: 2.5213579164080966

Epoch: 5| Step: 10
Training loss: 0.6648997022167703
Validation loss: 2.4044417261705457

Epoch: 635| Step: 0
Training loss: 0.6876890399433365
Validation loss: 2.494758080800116

Epoch: 5| Step: 1
Training loss: 0.48783026658621115
Validation loss: 2.3784737455058123

Epoch: 5| Step: 2
Training loss: 0.5734521068822667
Validation loss: 2.442680849027003

Epoch: 5| Step: 3
Training loss: 1.4911904723955887
Validation loss: 2.489658255644011

Epoch: 5| Step: 4
Training loss: 0.790406734509388
Validation loss: 2.3695243889364686

Epoch: 5| Step: 5
Training loss: 0.42009862684094923
Validation loss: 2.4810177503692348

Epoch: 5| Step: 6
Training loss: 0.5876903509638625
Validation loss: 2.4569118525588913

Epoch: 5| Step: 7
Training loss: 0.5681516654510111
Validation loss: 2.3955715434114646

Epoch: 5| Step: 8
Training loss: 0.668934553296516
Validation loss: 2.4442113704709114

Epoch: 5| Step: 9
Training loss: 0.4933762046861112
Validation loss: 2.366251742638373

Epoch: 5| Step: 10
Training loss: 0.8800207235323697
Validation loss: 2.417308831494878

Epoch: 636| Step: 0
Training loss: 0.7211828935103971
Validation loss: 2.42376123517688

Epoch: 5| Step: 1
Training loss: 1.4663026589176016
Validation loss: 2.370291695798316

Epoch: 5| Step: 2
Training loss: 0.8985605570234911
Validation loss: 2.438193445822559

Epoch: 5| Step: 3
Training loss: 0.8418438183646286
Validation loss: 2.36580355392981

Epoch: 5| Step: 4
Training loss: 0.8180863464409819
Validation loss: 2.405376857090513

Epoch: 5| Step: 5
Training loss: 0.7435760759504441
Validation loss: 2.3557849755365265

Epoch: 5| Step: 6
Training loss: 0.5126985095696449
Validation loss: 2.3466329985371805

Epoch: 5| Step: 7
Training loss: 0.630670147084088
Validation loss: 2.391137309698953

Epoch: 5| Step: 8
Training loss: 0.8053136815042825
Validation loss: 2.3947616552216346

Epoch: 5| Step: 9
Training loss: 0.6395281729588042
Validation loss: 2.364389096532492

Epoch: 5| Step: 10
Training loss: 0.5559544399568952
Validation loss: 2.446489005673787

Epoch: 637| Step: 0
Training loss: 0.5332824312694934
Validation loss: 2.3557729113654955

Epoch: 5| Step: 1
Training loss: 0.7775330432849548
Validation loss: 2.5082005087638004

Epoch: 5| Step: 2
Training loss: 0.6199699887964623
Validation loss: 2.444152385164287

Epoch: 5| Step: 3
Training loss: 0.5996004035601616
Validation loss: 2.475354365103572

Epoch: 5| Step: 4
Training loss: 0.7981974156804545
Validation loss: 2.3686363356367583

Epoch: 5| Step: 5
Training loss: 0.5564263450038306
Validation loss: 2.448771276031638

Epoch: 5| Step: 6
Training loss: 1.6396521454088138
Validation loss: 2.4208349915784826

Epoch: 5| Step: 7
Training loss: 0.6999997939381978
Validation loss: 2.3895932450385615

Epoch: 5| Step: 8
Training loss: 0.6993448367530359
Validation loss: 2.450457623786911

Epoch: 5| Step: 9
Training loss: 0.8013336137418314
Validation loss: 2.403630077296332

Epoch: 5| Step: 10
Training loss: 0.615191164467193
Validation loss: 2.4012498986624995

Epoch: 638| Step: 0
Training loss: 0.5350510431165253
Validation loss: 2.458967336891641

Epoch: 5| Step: 1
Training loss: 0.6613478430632276
Validation loss: 2.3998807895016157

Epoch: 5| Step: 2
Training loss: 0.5464278709316305
Validation loss: 2.3784332713122476

Epoch: 5| Step: 3
Training loss: 0.4632165461574459
Validation loss: 2.4533249623513407

Epoch: 5| Step: 4
Training loss: 1.4995678438088171
Validation loss: 2.437821210501001

Epoch: 5| Step: 5
Training loss: 0.9248210901499616
Validation loss: 2.451308137304091

Epoch: 5| Step: 6
Training loss: 0.6984442358524224
Validation loss: 2.441134000172213

Epoch: 5| Step: 7
Training loss: 0.4414342516904223
Validation loss: 2.427758449128549

Epoch: 5| Step: 8
Training loss: 0.4415356944182648
Validation loss: 2.497341487794975

Epoch: 5| Step: 9
Training loss: 0.7355712724509866
Validation loss: 2.401247019802985

Epoch: 5| Step: 10
Training loss: 0.659962100761497
Validation loss: 2.468690166628394

Epoch: 639| Step: 0
Training loss: 0.4082192960757531
Validation loss: 2.4778630079561283

Epoch: 5| Step: 1
Training loss: 0.7480883076401021
Validation loss: 2.433390029699604

Epoch: 5| Step: 2
Training loss: 0.4958172876368997
Validation loss: 2.4009892670153445

Epoch: 5| Step: 3
Training loss: 0.7087700469934347
Validation loss: 2.4252602313573663

Epoch: 5| Step: 4
Training loss: 0.8726186363426424
Validation loss: 2.3325509500734967

Epoch: 5| Step: 5
Training loss: 0.6715989321930799
Validation loss: 2.4462402160718164

Epoch: 5| Step: 6
Training loss: 0.6226892910067884
Validation loss: 2.3807726631955433

Epoch: 5| Step: 7
Training loss: 0.4638752023104877
Validation loss: 2.404456055994843

Epoch: 5| Step: 8
Training loss: 0.7034715222435453
Validation loss: 2.34567761444687

Epoch: 5| Step: 9
Training loss: 1.540868793256261
Validation loss: 2.4279262713158447

Epoch: 5| Step: 10
Training loss: 0.6156621747483833
Validation loss: 2.4497652379164054

Epoch: 640| Step: 0
Training loss: 0.7301823671724269
Validation loss: 2.4633433697005227

Epoch: 5| Step: 1
Training loss: 0.6859337782704527
Validation loss: 2.4298013154606353

Epoch: 5| Step: 2
Training loss: 0.49448367789459197
Validation loss: 2.480692945752707

Epoch: 5| Step: 3
Training loss: 0.6991915990576836
Validation loss: 2.480221303428615

Epoch: 5| Step: 4
Training loss: 1.473482583125864
Validation loss: 2.4435936872898902

Epoch: 5| Step: 5
Training loss: 0.6655237613394045
Validation loss: 2.3689223245395516

Epoch: 5| Step: 6
Training loss: 0.5595238684641644
Validation loss: 2.435807372679628

Epoch: 5| Step: 7
Training loss: 0.7165244933611739
Validation loss: 2.390348364958025

Epoch: 5| Step: 8
Training loss: 0.5116580024362579
Validation loss: 2.4555423286067026

Epoch: 5| Step: 9
Training loss: 0.6272786088807207
Validation loss: 2.358410837174028

Epoch: 5| Step: 10
Training loss: 0.789363690292997
Validation loss: 2.41658857956338

Epoch: 641| Step: 0
Training loss: 0.5765668129695032
Validation loss: 2.394734414610656

Epoch: 5| Step: 1
Training loss: 0.7684365245910635
Validation loss: 2.4303432186876543

Epoch: 5| Step: 2
Training loss: 0.5092874674097153
Validation loss: 2.4071981892187324

Epoch: 5| Step: 3
Training loss: 1.449082195912383
Validation loss: 2.4061908456290975

Epoch: 5| Step: 4
Training loss: 0.768857670818951
Validation loss: 2.414383942210019

Epoch: 5| Step: 5
Training loss: 0.8597276137605245
Validation loss: 2.489736201084077

Epoch: 5| Step: 6
Training loss: 0.7268727778288444
Validation loss: 2.4651874982298767

Epoch: 5| Step: 7
Training loss: 0.8792104915043251
Validation loss: 2.4637231507364334

Epoch: 5| Step: 8
Training loss: 0.5633871447191741
Validation loss: 2.411528195349214

Epoch: 5| Step: 9
Training loss: 0.5653542318381916
Validation loss: 2.479329589249881

Epoch: 5| Step: 10
Training loss: 0.6100625047944581
Validation loss: 2.4104841019317678

Epoch: 642| Step: 0
Training loss: 0.6739885222224604
Validation loss: 2.355266256166606

Epoch: 5| Step: 1
Training loss: 0.7265586032557844
Validation loss: 2.4067239857856375

Epoch: 5| Step: 2
Training loss: 0.8228780318900725
Validation loss: 2.438193974176567

Epoch: 5| Step: 3
Training loss: 0.6377268574552086
Validation loss: 2.477361052226561

Epoch: 5| Step: 4
Training loss: 0.4259322537374067
Validation loss: 2.4461039198428414

Epoch: 5| Step: 5
Training loss: 1.4607366740049628
Validation loss: 2.4462534920008245

Epoch: 5| Step: 6
Training loss: 0.6082859578257886
Validation loss: 2.421741111672047

Epoch: 5| Step: 7
Training loss: 0.49167779233704695
Validation loss: 2.4113508850949863

Epoch: 5| Step: 8
Training loss: 0.4517749867223793
Validation loss: 2.4121437676442135

Epoch: 5| Step: 9
Training loss: 0.7152343266652215
Validation loss: 2.3926102118384134

Epoch: 5| Step: 10
Training loss: 0.6223602098514579
Validation loss: 2.38718944003583

Epoch: 643| Step: 0
Training loss: 1.395785667782254
Validation loss: 2.466814338644934

Epoch: 5| Step: 1
Training loss: 0.6606531473910378
Validation loss: 2.431936102390165

Epoch: 5| Step: 2
Training loss: 0.773125672336246
Validation loss: 2.4534440563006985

Epoch: 5| Step: 3
Training loss: 0.640439681254105
Validation loss: 2.427978942594219

Epoch: 5| Step: 4
Training loss: 0.5299348540574649
Validation loss: 2.4749077725164965

Epoch: 5| Step: 5
Training loss: 0.4704492921330692
Validation loss: 2.348044860637976

Epoch: 5| Step: 6
Training loss: 0.5955890483753691
Validation loss: 2.459101021229854

Epoch: 5| Step: 7
Training loss: 0.5092016439967949
Validation loss: 2.3708726006368845

Epoch: 5| Step: 8
Training loss: 0.5197241288866067
Validation loss: 2.4448649971207153

Epoch: 5| Step: 9
Training loss: 0.5272504935988046
Validation loss: 2.369036601786492

Epoch: 5| Step: 10
Training loss: 0.7208232004265632
Validation loss: 2.404200837995822

Epoch: 644| Step: 0
Training loss: 0.8121403485034264
Validation loss: 2.4027052265811024

Epoch: 5| Step: 1
Training loss: 0.6188677839437504
Validation loss: 2.430774383499471

Epoch: 5| Step: 2
Training loss: 1.5116225416535236
Validation loss: 2.4075308050386663

Epoch: 5| Step: 3
Training loss: 0.8207196269856945
Validation loss: 2.367198402436265

Epoch: 5| Step: 4
Training loss: 0.4949631611284342
Validation loss: 2.4359105736089783

Epoch: 5| Step: 5
Training loss: 0.6001620898251898
Validation loss: 2.509481425789391

Epoch: 5| Step: 6
Training loss: 0.6277875961977207
Validation loss: 2.3713201199304623

Epoch: 5| Step: 7
Training loss: 0.7448054270151202
Validation loss: 2.468101718532183

Epoch: 5| Step: 8
Training loss: 0.45737187008804586
Validation loss: 2.437168580245367

Epoch: 5| Step: 9
Training loss: 0.5878511586676792
Validation loss: 2.454385830943348

Epoch: 5| Step: 10
Training loss: 0.5233128812108098
Validation loss: 2.4560149182312183

Epoch: 645| Step: 0
Training loss: 0.6541743832839716
Validation loss: 2.4600951910147337

Epoch: 5| Step: 1
Training loss: 0.6456994307562907
Validation loss: 2.4301264289616675

Epoch: 5| Step: 2
Training loss: 0.44123715563010435
Validation loss: 2.4794750046870635

Epoch: 5| Step: 3
Training loss: 0.9959205027992009
Validation loss: 2.434232119353011

Epoch: 5| Step: 4
Training loss: 0.5885625655478135
Validation loss: 2.430579721317976

Epoch: 5| Step: 5
Training loss: 0.9576127134868654
Validation loss: 2.3962279399180537

Epoch: 5| Step: 6
Training loss: 1.4602321615228362
Validation loss: 2.388751883328925

Epoch: 5| Step: 7
Training loss: 0.6990868428015972
Validation loss: 2.4122565818527137

Epoch: 5| Step: 8
Training loss: 0.6307889349854121
Validation loss: 2.4100711922046014

Epoch: 5| Step: 9
Training loss: 0.6192662204948144
Validation loss: 2.40413246796564

Epoch: 5| Step: 10
Training loss: 0.6376660794484568
Validation loss: 2.3746957084762053

Epoch: 646| Step: 0
Training loss: 1.4987169182238715
Validation loss: 2.4109548548415916

Epoch: 5| Step: 1
Training loss: 0.719957043041827
Validation loss: 2.466954063098543

Epoch: 5| Step: 2
Training loss: 0.6045732828939687
Validation loss: 2.407923369740394

Epoch: 5| Step: 3
Training loss: 0.6797355108733684
Validation loss: 2.4521510396663526

Epoch: 5| Step: 4
Training loss: 0.5290896865339911
Validation loss: 2.4640767799903305

Epoch: 5| Step: 5
Training loss: 0.3693466620701221
Validation loss: 2.432401067872355

Epoch: 5| Step: 6
Training loss: 0.5439990032551554
Validation loss: 2.4133806012583428

Epoch: 5| Step: 7
Training loss: 0.5783203928907777
Validation loss: 2.418952688288824

Epoch: 5| Step: 8
Training loss: 0.6849345545586621
Validation loss: 2.4167782167595533

Epoch: 5| Step: 9
Training loss: 0.6900933294824875
Validation loss: 2.346070744306455

Epoch: 5| Step: 10
Training loss: 0.5101630463081736
Validation loss: 2.3575173132587386

Epoch: 647| Step: 0
Training loss: 1.452059857887009
Validation loss: 2.4272519529742858

Epoch: 5| Step: 1
Training loss: 0.6365564057438127
Validation loss: 2.4484617776160063

Epoch: 5| Step: 2
Training loss: 0.5800587043979174
Validation loss: 2.3746051929728282

Epoch: 5| Step: 3
Training loss: 0.8261631453393331
Validation loss: 2.3912035500518134

Epoch: 5| Step: 4
Training loss: 0.5441871530065792
Validation loss: 2.4174200255025515

Epoch: 5| Step: 5
Training loss: 0.6009276123741065
Validation loss: 2.3548970970981875

Epoch: 5| Step: 6
Training loss: 0.8701042748037903
Validation loss: 2.46738605612745

Epoch: 5| Step: 7
Training loss: 0.5677621331810246
Validation loss: 2.4476887045450715

Epoch: 5| Step: 8
Training loss: 0.5871535588515
Validation loss: 2.3958768818354113

Epoch: 5| Step: 9
Training loss: 0.636034592098605
Validation loss: 2.40841138571096

Epoch: 5| Step: 10
Training loss: 0.5320361155372891
Validation loss: 2.4479363159005474

Epoch: 648| Step: 0
Training loss: 1.6042085699908553
Validation loss: 2.5044750533630573

Epoch: 5| Step: 1
Training loss: 0.612262365408687
Validation loss: 2.4497746426519327

Epoch: 5| Step: 2
Training loss: 0.8926440325220923
Validation loss: 2.3989818399277634

Epoch: 5| Step: 3
Training loss: 0.5891186128395953
Validation loss: 2.4616555412079344

Epoch: 5| Step: 4
Training loss: 0.5005681267292424
Validation loss: 2.4019642391816927

Epoch: 5| Step: 5
Training loss: 0.6923828770646898
Validation loss: 2.4167417727444818

Epoch: 5| Step: 6
Training loss: 0.46433754614609696
Validation loss: 2.4424842430650466

Epoch: 5| Step: 7
Training loss: 0.4051787116330221
Validation loss: 2.453864747965956

Epoch: 5| Step: 8
Training loss: 0.47610622200624964
Validation loss: 2.4257751002930683

Epoch: 5| Step: 9
Training loss: 0.43495898064326033
Validation loss: 2.4188459403779383

Epoch: 5| Step: 10
Training loss: 0.5869358204697854
Validation loss: 2.4319452687885392

Epoch: 649| Step: 0
Training loss: 0.5153018632465347
Validation loss: 2.4551352608976194

Epoch: 5| Step: 1
Training loss: 0.7956540346803611
Validation loss: 2.414582227319672

Epoch: 5| Step: 2
Training loss: 0.41671495356509275
Validation loss: 2.381017761149512

Epoch: 5| Step: 3
Training loss: 0.5426914412590289
Validation loss: 2.534627426749033

Epoch: 5| Step: 4
Training loss: 1.5540478027679727
Validation loss: 2.407558618558835

Epoch: 5| Step: 5
Training loss: 0.5367875123154768
Validation loss: 2.3631479907621

Epoch: 5| Step: 6
Training loss: 0.8121593201266706
Validation loss: 2.423651309994915

Epoch: 5| Step: 7
Training loss: 0.7489186279496445
Validation loss: 2.4077189127303593

Epoch: 5| Step: 8
Training loss: 0.46183679430415175
Validation loss: 2.4116925441413413

Epoch: 5| Step: 9
Training loss: 0.7666805542503508
Validation loss: 2.3651855503814385

Epoch: 5| Step: 10
Training loss: 0.6294941257372401
Validation loss: 2.375956225723008

Epoch: 650| Step: 0
Training loss: 0.44171791551563094
Validation loss: 2.4072832761107223

Epoch: 5| Step: 1
Training loss: 0.5804566711976292
Validation loss: 2.5062403810893583

Epoch: 5| Step: 2
Training loss: 0.6254946896703452
Validation loss: 2.443204830920426

Epoch: 5| Step: 3
Training loss: 0.6593395802173325
Validation loss: 2.4466428948870114

Epoch: 5| Step: 4
Training loss: 0.7988642752006144
Validation loss: 2.4482436314990506

Epoch: 5| Step: 5
Training loss: 0.7776011898514392
Validation loss: 2.3568868106924827

Epoch: 5| Step: 6
Training loss: 0.519126246635691
Validation loss: 2.4335326139992004

Epoch: 5| Step: 7
Training loss: 1.442685105266483
Validation loss: 2.479284595122705

Epoch: 5| Step: 8
Training loss: 0.6459859442111788
Validation loss: 2.413744454068753

Epoch: 5| Step: 9
Training loss: 0.6803058792864489
Validation loss: 2.4586134701087685

Epoch: 5| Step: 10
Training loss: 0.553765807216803
Validation loss: 2.3696665816823668

Epoch: 651| Step: 0
Training loss: 0.7009206125076296
Validation loss: 2.387041853658455

Epoch: 5| Step: 1
Training loss: 0.7634374936916181
Validation loss: 2.4469167240998266

Epoch: 5| Step: 2
Training loss: 1.4069270729246923
Validation loss: 2.403306858076269

Epoch: 5| Step: 3
Training loss: 0.7413600525366206
Validation loss: 2.3825585517604817

Epoch: 5| Step: 4
Training loss: 0.585986453236631
Validation loss: 2.373067654788315

Epoch: 5| Step: 5
Training loss: 0.8839949394400556
Validation loss: 2.413786115155848

Epoch: 5| Step: 6
Training loss: 0.7404819366446486
Validation loss: 2.362833386443637

Epoch: 5| Step: 7
Training loss: 0.7064404416516207
Validation loss: 2.3629726446052994

Epoch: 5| Step: 8
Training loss: 0.6266985224767117
Validation loss: 2.4559428193933237

Epoch: 5| Step: 9
Training loss: 0.4036427425963502
Validation loss: 2.4342022957303326

Epoch: 5| Step: 10
Training loss: 0.4284377389819524
Validation loss: 2.4732375838014105

Epoch: 652| Step: 0
Training loss: 0.6299885505816619
Validation loss: 2.443746177893381

Epoch: 5| Step: 1
Training loss: 1.6696215264667724
Validation loss: 2.469248750233793

Epoch: 5| Step: 2
Training loss: 0.5434759501739805
Validation loss: 2.4104493808992937

Epoch: 5| Step: 3
Training loss: 0.542385062026571
Validation loss: 2.4959758775840117

Epoch: 5| Step: 4
Training loss: 0.3956716880850623
Validation loss: 2.347629626888934

Epoch: 5| Step: 5
Training loss: 0.9122118351177572
Validation loss: 2.4046477422352885

Epoch: 5| Step: 6
Training loss: 0.5571611614067521
Validation loss: 2.4676418919880145

Epoch: 5| Step: 7
Training loss: 0.4496150880611368
Validation loss: 2.392094112926338

Epoch: 5| Step: 8
Training loss: 0.5338155003632958
Validation loss: 2.4244984834979886

Epoch: 5| Step: 9
Training loss: 0.6111241935885394
Validation loss: 2.4087494875915354

Epoch: 5| Step: 10
Training loss: 0.8319053733777789
Validation loss: 2.4241279642077704

Epoch: 653| Step: 0
Training loss: 0.5712074156233052
Validation loss: 2.3523066239375874

Epoch: 5| Step: 1
Training loss: 0.5188106041862023
Validation loss: 2.5180400969098615

Epoch: 5| Step: 2
Training loss: 0.5132146620850966
Validation loss: 2.4163632989244763

Epoch: 5| Step: 3
Training loss: 0.578158480731522
Validation loss: 2.3803068072291658

Epoch: 5| Step: 4
Training loss: 0.8375194234161404
Validation loss: 2.4231564945087882

Epoch: 5| Step: 5
Training loss: 0.828883669273293
Validation loss: 2.4681847546867646

Epoch: 5| Step: 6
Training loss: 0.5153326592975582
Validation loss: 2.43606185715108

Epoch: 5| Step: 7
Training loss: 0.7027438932307516
Validation loss: 2.432232221624572

Epoch: 5| Step: 8
Training loss: 0.4725977018050221
Validation loss: 2.5030260752991405

Epoch: 5| Step: 9
Training loss: 0.7444904936676076
Validation loss: 2.463647818570472

Epoch: 5| Step: 10
Training loss: 1.6302301163685646
Validation loss: 2.4117503911031966

Epoch: 654| Step: 0
Training loss: 0.8712580230868889
Validation loss: 2.348318871634849

Epoch: 5| Step: 1
Training loss: 0.6033147088578186
Validation loss: 2.441849428441814

Epoch: 5| Step: 2
Training loss: 0.6049497779777051
Validation loss: 2.4315434726021268

Epoch: 5| Step: 3
Training loss: 0.6691057444409525
Validation loss: 2.387703697991273

Epoch: 5| Step: 4
Training loss: 0.5652745483716507
Validation loss: 2.4362582495344154

Epoch: 5| Step: 5
Training loss: 0.5821489560712972
Validation loss: 2.3791998950676616

Epoch: 5| Step: 6
Training loss: 0.5169893190472228
Validation loss: 2.4022941466181913

Epoch: 5| Step: 7
Training loss: 0.6990790414025521
Validation loss: 2.4097979474994737

Epoch: 5| Step: 8
Training loss: 0.5438846574862691
Validation loss: 2.412338249564503

Epoch: 5| Step: 9
Training loss: 0.7046350582258268
Validation loss: 2.4478429199783793

Epoch: 5| Step: 10
Training loss: 1.6683704330302944
Validation loss: 2.4574753661698607

Epoch: 655| Step: 0
Training loss: 0.6276716826490529
Validation loss: 2.4398036312104074

Epoch: 5| Step: 1
Training loss: 0.7587574052527856
Validation loss: 2.4384664473818143

Epoch: 5| Step: 2
Training loss: 0.8461730215427455
Validation loss: 2.4498454056669026

Epoch: 5| Step: 3
Training loss: 0.45344353036268537
Validation loss: 2.4224883177227405

Epoch: 5| Step: 4
Training loss: 0.5862998350715438
Validation loss: 2.3867403398683966

Epoch: 5| Step: 5
Training loss: 0.5560363970187983
Validation loss: 2.492716201310364

Epoch: 5| Step: 6
Training loss: 0.5270417372934993
Validation loss: 2.455469323227043

Epoch: 5| Step: 7
Training loss: 1.5458583380775253
Validation loss: 2.379078321600164

Epoch: 5| Step: 8
Training loss: 0.48201761025493517
Validation loss: 2.4613727935302996

Epoch: 5| Step: 9
Training loss: 0.6996577499082558
Validation loss: 2.4096561855202565

Epoch: 5| Step: 10
Training loss: 0.49695989135491986
Validation loss: 2.441214204056182

Epoch: 656| Step: 0
Training loss: 0.7647370619588216
Validation loss: 2.3680213648931314

Epoch: 5| Step: 1
Training loss: 0.48794406692856757
Validation loss: 2.484923452013451

Epoch: 5| Step: 2
Training loss: 0.6917466871859872
Validation loss: 2.4513783321087264

Epoch: 5| Step: 3
Training loss: 0.7827581725618337
Validation loss: 2.3661559654315902

Epoch: 5| Step: 4
Training loss: 0.7981685536329685
Validation loss: 2.393213921576187

Epoch: 5| Step: 5
Training loss: 0.8887606062973827
Validation loss: 2.4599671768255056

Epoch: 5| Step: 6
Training loss: 0.5514495798859054
Validation loss: 2.4456580321979073

Epoch: 5| Step: 7
Training loss: 0.8640862763429196
Validation loss: 2.4259602578714055

Epoch: 5| Step: 8
Training loss: 0.5166687660277179
Validation loss: 2.358443941603736

Epoch: 5| Step: 9
Training loss: 1.3974963382952765
Validation loss: 2.4408453819590266

Epoch: 5| Step: 10
Training loss: 0.6023817057840887
Validation loss: 2.4465939638370613

Epoch: 657| Step: 0
Training loss: 0.48001067492416555
Validation loss: 2.4036919426481997

Epoch: 5| Step: 1
Training loss: 1.603353922005243
Validation loss: 2.4981937918301265

Epoch: 5| Step: 2
Training loss: 0.677730373403735
Validation loss: 2.5065895021851103

Epoch: 5| Step: 3
Training loss: 0.4715627837385635
Validation loss: 2.3586934939059754

Epoch: 5| Step: 4
Training loss: 0.8697199915670469
Validation loss: 2.436473616667875

Epoch: 5| Step: 5
Training loss: 0.568700786180055
Validation loss: 2.346764998993592

Epoch: 5| Step: 6
Training loss: 0.6285143276696717
Validation loss: 2.4185221942185637

Epoch: 5| Step: 7
Training loss: 0.6540649002840386
Validation loss: 2.364724956255865

Epoch: 5| Step: 8
Training loss: 0.673646653658893
Validation loss: 2.4568343059885307

Epoch: 5| Step: 9
Training loss: 0.492988086689973
Validation loss: 2.3809764957451978

Epoch: 5| Step: 10
Training loss: 0.6265649039205731
Validation loss: 2.409468623810663

Epoch: 658| Step: 0
Training loss: 1.5235009595907387
Validation loss: 2.4113433885090507

Epoch: 5| Step: 1
Training loss: 0.6650216076502619
Validation loss: 2.393807675634351

Epoch: 5| Step: 2
Training loss: 0.679356571182687
Validation loss: 2.4073290473035462

Epoch: 5| Step: 3
Training loss: 0.7839653890959435
Validation loss: 2.39243521087119

Epoch: 5| Step: 4
Training loss: 0.7618271579382262
Validation loss: 2.427046869067324

Epoch: 5| Step: 5
Training loss: 0.672820512694659
Validation loss: 2.4273259901443054

Epoch: 5| Step: 6
Training loss: 0.556012572290451
Validation loss: 2.377783177588682

Epoch: 5| Step: 7
Training loss: 0.5886483616173548
Validation loss: 2.4321519139126084

Epoch: 5| Step: 8
Training loss: 0.6839130200998094
Validation loss: 2.3427482361892613

Epoch: 5| Step: 9
Training loss: 0.5598802490431192
Validation loss: 2.4383852523585743

Epoch: 5| Step: 10
Training loss: 0.68933798285087
Validation loss: 2.347999771344487

Epoch: 659| Step: 0
Training loss: 0.8338097204069543
Validation loss: 2.361428849831766

Epoch: 5| Step: 1
Training loss: 0.5708792235266452
Validation loss: 2.429790349964372

Epoch: 5| Step: 2
Training loss: 0.5347609904989155
Validation loss: 2.4801217736056858

Epoch: 5| Step: 3
Training loss: 1.5388001349034361
Validation loss: 2.3850730680417236

Epoch: 5| Step: 4
Training loss: 0.5046775297237099
Validation loss: 2.3938001929174653

Epoch: 5| Step: 5
Training loss: 0.3555834658458371
Validation loss: 2.424399368070655

Epoch: 5| Step: 6
Training loss: 0.49472448662564444
Validation loss: 2.485388775654144

Epoch: 5| Step: 7
Training loss: 0.6054600868835881
Validation loss: 2.3653252547930173

Epoch: 5| Step: 8
Training loss: 0.6591925725737197
Validation loss: 2.375338575045295

Epoch: 5| Step: 9
Training loss: 0.6218234160608962
Validation loss: 2.332737249567311

Epoch: 5| Step: 10
Training loss: 0.6722272348830051
Validation loss: 2.490860212078767

Epoch: 660| Step: 0
Training loss: 0.6702473019634896
Validation loss: 2.4504052750927627

Epoch: 5| Step: 1
Training loss: 0.5697526143119928
Validation loss: 2.4255222396749447

Epoch: 5| Step: 2
Training loss: 1.538316807449752
Validation loss: 2.479719558602563

Epoch: 5| Step: 3
Training loss: 0.613025052929284
Validation loss: 2.3829493716835084

Epoch: 5| Step: 4
Training loss: 0.7689863105368989
Validation loss: 2.3918714915035957

Epoch: 5| Step: 5
Training loss: 0.5620990224684186
Validation loss: 2.473529371929241

Epoch: 5| Step: 6
Training loss: 0.7009337507020947
Validation loss: 2.4067889109358838

Epoch: 5| Step: 7
Training loss: 0.6198420838010764
Validation loss: 2.43009964491043

Epoch: 5| Step: 8
Training loss: 0.5353581402724891
Validation loss: 2.4358704944012644

Epoch: 5| Step: 9
Training loss: 0.6163683658460216
Validation loss: 2.4425204247377352

Epoch: 5| Step: 10
Training loss: 0.6938390442691595
Validation loss: 2.3654172734205106

Epoch: 661| Step: 0
Training loss: 0.6219076426004388
Validation loss: 2.4268934585877378

Epoch: 5| Step: 1
Training loss: 0.4725081787208872
Validation loss: 2.3527002405509405

Epoch: 5| Step: 2
Training loss: 0.715571632227689
Validation loss: 2.4053626177495637

Epoch: 5| Step: 3
Training loss: 0.5455701793034481
Validation loss: 2.4002885835758034

Epoch: 5| Step: 4
Training loss: 0.6289537305264414
Validation loss: 2.381129102195055

Epoch: 5| Step: 5
Training loss: 0.6824111518388584
Validation loss: 2.4222844693656893

Epoch: 5| Step: 6
Training loss: 0.6873768349342252
Validation loss: 2.3802150588807716

Epoch: 5| Step: 7
Training loss: 0.6388715146185573
Validation loss: 2.417272108600561

Epoch: 5| Step: 8
Training loss: 1.3789438129096059
Validation loss: 2.3896186357031457

Epoch: 5| Step: 9
Training loss: 0.5055808401451342
Validation loss: 2.385433719450644

Epoch: 5| Step: 10
Training loss: 0.627808293641327
Validation loss: 2.462016921431606

Epoch: 662| Step: 0
Training loss: 0.48008928588607325
Validation loss: 2.4028348279245146

Epoch: 5| Step: 1
Training loss: 0.6395718361217766
Validation loss: 2.447426950189391

Epoch: 5| Step: 2
Training loss: 0.5547431058279071
Validation loss: 2.435159646671948

Epoch: 5| Step: 3
Training loss: 0.5724576035672226
Validation loss: 2.4197862693016563

Epoch: 5| Step: 4
Training loss: 0.5673273949142348
Validation loss: 2.4094312563361946

Epoch: 5| Step: 5
Training loss: 0.615191552019092
Validation loss: 2.4399468798531267

Epoch: 5| Step: 6
Training loss: 0.47403401165372216
Validation loss: 2.4276003061008695

Epoch: 5| Step: 7
Training loss: 1.488809727031985
Validation loss: 2.3684826574401483

Epoch: 5| Step: 8
Training loss: 0.48214457337512995
Validation loss: 2.435991107858303

Epoch: 5| Step: 9
Training loss: 0.6022130742801537
Validation loss: 2.45366190932811

Epoch: 5| Step: 10
Training loss: 0.6913802793980931
Validation loss: 2.4438235523157585

Epoch: 663| Step: 0
Training loss: 0.6005296882402243
Validation loss: 2.49133738074122

Epoch: 5| Step: 1
Training loss: 0.8972480529738521
Validation loss: 2.410066392695731

Epoch: 5| Step: 2
Training loss: 0.6372648366380973
Validation loss: 2.4414469272957477

Epoch: 5| Step: 3
Training loss: 0.5001686527009808
Validation loss: 2.3990957838424376

Epoch: 5| Step: 4
Training loss: 0.5314804587050986
Validation loss: 2.4399162897194

Epoch: 5| Step: 5
Training loss: 0.6423234985841196
Validation loss: 2.432952638922535

Epoch: 5| Step: 6
Training loss: 0.7018783113396407
Validation loss: 2.457222597577082

Epoch: 5| Step: 7
Training loss: 1.419760252767609
Validation loss: 2.433058658335177

Epoch: 5| Step: 8
Training loss: 0.5803598047551741
Validation loss: 2.3771560836696883

Epoch: 5| Step: 9
Training loss: 0.9062263880317386
Validation loss: 2.4221719274658327

Epoch: 5| Step: 10
Training loss: 0.47879689572084055
Validation loss: 2.374904694342344

Epoch: 664| Step: 0
Training loss: 1.3959488702280667
Validation loss: 2.3989174713205035

Epoch: 5| Step: 1
Training loss: 0.6282984005537474
Validation loss: 2.3882822783837994

Epoch: 5| Step: 2
Training loss: 0.49626341494149234
Validation loss: 2.3549992421916253

Epoch: 5| Step: 3
Training loss: 0.765510667321687
Validation loss: 2.423998453496475

Epoch: 5| Step: 4
Training loss: 0.5110487592225444
Validation loss: 2.4376314220858624

Epoch: 5| Step: 5
Training loss: 0.784682477284
Validation loss: 2.4230173085210334

Epoch: 5| Step: 6
Training loss: 0.8430560048280371
Validation loss: 2.4089334177662245

Epoch: 5| Step: 7
Training loss: 0.902825231201575
Validation loss: 2.402398786123639

Epoch: 5| Step: 8
Training loss: 0.5709750624871396
Validation loss: 2.3940576386985937

Epoch: 5| Step: 9
Training loss: 0.4634881006501406
Validation loss: 2.4416086924635465

Epoch: 5| Step: 10
Training loss: 0.663709546704508
Validation loss: 2.4806531787664183

Epoch: 665| Step: 0
Training loss: 0.7438992486795333
Validation loss: 2.456564775132311

Epoch: 5| Step: 1
Training loss: 0.6329170423267582
Validation loss: 2.4166844918594705

Epoch: 5| Step: 2
Training loss: 1.577833243113007
Validation loss: 2.418921970966201

Epoch: 5| Step: 3
Training loss: 0.6093297599236253
Validation loss: 2.3787915211409834

Epoch: 5| Step: 4
Training loss: 0.7796375419191371
Validation loss: 2.4036704434464045

Epoch: 5| Step: 5
Training loss: 0.6393775424552477
Validation loss: 2.344034828735466

Epoch: 5| Step: 6
Training loss: 0.6750586069236904
Validation loss: 2.3918604003497035

Epoch: 5| Step: 7
Training loss: 0.5397078479670521
Validation loss: 2.434936227946507

Epoch: 5| Step: 8
Training loss: 0.3235980377207911
Validation loss: 2.3780855790974216

Epoch: 5| Step: 9
Training loss: 0.6563554633637865
Validation loss: 2.3930211400193406

Epoch: 5| Step: 10
Training loss: 0.5209363422255073
Validation loss: 2.4320981584920305

Epoch: 666| Step: 0
Training loss: 0.4714786898974221
Validation loss: 2.386543072908954

Epoch: 5| Step: 1
Training loss: 0.4657961761171469
Validation loss: 2.4225208089625108

Epoch: 5| Step: 2
Training loss: 0.5464192262308105
Validation loss: 2.406690632034942

Epoch: 5| Step: 3
Training loss: 0.584527646491867
Validation loss: 2.4119094766466356

Epoch: 5| Step: 4
Training loss: 0.6050581986044197
Validation loss: 2.4353248181882403

Epoch: 5| Step: 5
Training loss: 0.5048173164665926
Validation loss: 2.403232695787202

Epoch: 5| Step: 6
Training loss: 0.542589700244444
Validation loss: 2.4252519334381755

Epoch: 5| Step: 7
Training loss: 0.7985719302605043
Validation loss: 2.439735725097157

Epoch: 5| Step: 8
Training loss: 1.5086990675273952
Validation loss: 2.3852731765712774

Epoch: 5| Step: 9
Training loss: 0.558339467892704
Validation loss: 2.4279912762309235

Epoch: 5| Step: 10
Training loss: 0.8802397381900244
Validation loss: 2.435612598046912

Epoch: 667| Step: 0
Training loss: 0.3777358472256931
Validation loss: 2.4206846547735466

Epoch: 5| Step: 1
Training loss: 0.5686518385300381
Validation loss: 2.3799921104815356

Epoch: 5| Step: 2
Training loss: 0.38048127798020215
Validation loss: 2.412715070022637

Epoch: 5| Step: 3
Training loss: 0.6564919616050208
Validation loss: 2.369832386711388

Epoch: 5| Step: 4
Training loss: 0.7011386576570455
Validation loss: 2.4687119929237356

Epoch: 5| Step: 5
Training loss: 0.693222505196871
Validation loss: 2.420638095575885

Epoch: 5| Step: 6
Training loss: 0.7717985262034022
Validation loss: 2.4414924673956424

Epoch: 5| Step: 7
Training loss: 0.5284443989849864
Validation loss: 2.4008517793606394

Epoch: 5| Step: 8
Training loss: 0.719643286515912
Validation loss: 2.433498417242231

Epoch: 5| Step: 9
Training loss: 0.4369233281769242
Validation loss: 2.4601353585675017

Epoch: 5| Step: 10
Training loss: 1.516145675730809
Validation loss: 2.422618817638246

Epoch: 668| Step: 0
Training loss: 0.4319307379355431
Validation loss: 2.4072498981603005

Epoch: 5| Step: 1
Training loss: 0.4998895254874521
Validation loss: 2.4012764536166427

Epoch: 5| Step: 2
Training loss: 0.6488736535714043
Validation loss: 2.410756732371442

Epoch: 5| Step: 3
Training loss: 0.740053340948293
Validation loss: 2.3897098680020408

Epoch: 5| Step: 4
Training loss: 0.6595774940775255
Validation loss: 2.38311351782447

Epoch: 5| Step: 5
Training loss: 0.6871409128659802
Validation loss: 2.4261941884450855

Epoch: 5| Step: 6
Training loss: 0.61624055963524
Validation loss: 2.3880291278621835

Epoch: 5| Step: 7
Training loss: 1.433280640380224
Validation loss: 2.4211468192354615

Epoch: 5| Step: 8
Training loss: 0.3969771982005888
Validation loss: 2.4054802669059248

Epoch: 5| Step: 9
Training loss: 0.6988172603847966
Validation loss: 2.4313330771342967

Epoch: 5| Step: 10
Training loss: 0.5537409698576705
Validation loss: 2.442924781859954

Epoch: 669| Step: 0
Training loss: 0.48399591994043667
Validation loss: 2.3664136864765486

Epoch: 5| Step: 1
Training loss: 0.5189607973268693
Validation loss: 2.350346428068205

Epoch: 5| Step: 2
Training loss: 0.45866126192289824
Validation loss: 2.41137482191927

Epoch: 5| Step: 3
Training loss: 0.8071081916934075
Validation loss: 2.3714024271766503

Epoch: 5| Step: 4
Training loss: 0.9192145152937088
Validation loss: 2.4220669821478857

Epoch: 5| Step: 5
Training loss: 0.5849697768318868
Validation loss: 2.4034652886575594

Epoch: 5| Step: 6
Training loss: 1.468291353079516
Validation loss: 2.4005266503460305

Epoch: 5| Step: 7
Training loss: 0.6470822338660684
Validation loss: 2.3992981698055815

Epoch: 5| Step: 8
Training loss: 0.6149861152756309
Validation loss: 2.427741338126725

Epoch: 5| Step: 9
Training loss: 0.5642569177817873
Validation loss: 2.348673378363372

Epoch: 5| Step: 10
Training loss: 0.4063688251140042
Validation loss: 2.4361294399996964

Epoch: 670| Step: 0
Training loss: 1.4563683032005539
Validation loss: 2.3231625692811084

Epoch: 5| Step: 1
Training loss: 0.5541782459206135
Validation loss: 2.400548384082829

Epoch: 5| Step: 2
Training loss: 0.411873682248637
Validation loss: 2.440544443196894

Epoch: 5| Step: 3
Training loss: 0.7478910836720771
Validation loss: 2.4022431858189317

Epoch: 5| Step: 4
Training loss: 0.6773870276118737
Validation loss: 2.433978831259013

Epoch: 5| Step: 5
Training loss: 0.45974224099171523
Validation loss: 2.47472176983436

Epoch: 5| Step: 6
Training loss: 0.648826987709367
Validation loss: 2.4857741304038825

Epoch: 5| Step: 7
Training loss: 0.5989159665811118
Validation loss: 2.3950604005658853

Epoch: 5| Step: 8
Training loss: 0.443534362811073
Validation loss: 2.377652001821565

Epoch: 5| Step: 9
Training loss: 0.6114400206709547
Validation loss: 2.391074884442063

Epoch: 5| Step: 10
Training loss: 0.6290515471185698
Validation loss: 2.408046894757534

Epoch: 671| Step: 0
Training loss: 0.5714694007481413
Validation loss: 2.3561162176924753

Epoch: 5| Step: 1
Training loss: 0.626599958065907
Validation loss: 2.473552957341506

Epoch: 5| Step: 2
Training loss: 0.5440222310825058
Validation loss: 2.425519737887736

Epoch: 5| Step: 3
Training loss: 0.5652422816758944
Validation loss: 2.3879472766818526

Epoch: 5| Step: 4
Training loss: 0.676709260065887
Validation loss: 2.43388033468441

Epoch: 5| Step: 5
Training loss: 0.5499254165277414
Validation loss: 2.4596471390422883

Epoch: 5| Step: 6
Training loss: 0.7103659879296382
Validation loss: 2.4057276414089

Epoch: 5| Step: 7
Training loss: 0.5441495282607947
Validation loss: 2.4481739395104154

Epoch: 5| Step: 8
Training loss: 1.4811183339765033
Validation loss: 2.4072211779708694

Epoch: 5| Step: 9
Training loss: 0.5207607377639708
Validation loss: 2.407512614801388

Epoch: 5| Step: 10
Training loss: 0.7926902845803437
Validation loss: 2.3942831908929594

Epoch: 672| Step: 0
Training loss: 0.44337769189043774
Validation loss: 2.3710160154250506

Epoch: 5| Step: 1
Training loss: 0.5294084044346724
Validation loss: 2.3570146364651943

Epoch: 5| Step: 2
Training loss: 0.619773493161081
Validation loss: 2.4472688294627645

Epoch: 5| Step: 3
Training loss: 1.561059822123903
Validation loss: 2.3764741329538466

Epoch: 5| Step: 4
Training loss: 0.6023191919528006
Validation loss: 2.40443715319004

Epoch: 5| Step: 5
Training loss: 0.5226572113712519
Validation loss: 2.358862188978664

Epoch: 5| Step: 6
Training loss: 0.7237752138532332
Validation loss: 2.4099225093634646

Epoch: 5| Step: 7
Training loss: 0.6915581746403521
Validation loss: 2.3659459558043547

Epoch: 5| Step: 8
Training loss: 0.6405483293010842
Validation loss: 2.407697894826262

Epoch: 5| Step: 9
Training loss: 0.4763107885778715
Validation loss: 2.4764283679835692

Epoch: 5| Step: 10
Training loss: 0.5427669726546472
Validation loss: 2.4376256072666687

Epoch: 673| Step: 0
Training loss: 0.6237308490848174
Validation loss: 2.4462041161425563

Epoch: 5| Step: 1
Training loss: 0.7191753787253045
Validation loss: 2.40431859384878

Epoch: 5| Step: 2
Training loss: 0.5993579747523691
Validation loss: 2.366368329668599

Epoch: 5| Step: 3
Training loss: 1.3716237926542154
Validation loss: 2.4051805422761703

Epoch: 5| Step: 4
Training loss: 0.5923321761095116
Validation loss: 2.3863972671808567

Epoch: 5| Step: 5
Training loss: 0.6766064407140181
Validation loss: 2.322981262706814

Epoch: 5| Step: 6
Training loss: 0.5394483926553069
Validation loss: 2.4660878208040047

Epoch: 5| Step: 7
Training loss: 0.641049686249895
Validation loss: 2.4104990972344464

Epoch: 5| Step: 8
Training loss: 0.5620246574178523
Validation loss: 2.31819317733033

Epoch: 5| Step: 9
Training loss: 0.4798672019521645
Validation loss: 2.4252439948927327

Epoch: 5| Step: 10
Training loss: 0.7171741293198933
Validation loss: 2.4107436150822332

Epoch: 674| Step: 0
Training loss: 0.6291820324248778
Validation loss: 2.443242261580715

Epoch: 5| Step: 1
Training loss: 0.5900721076366596
Validation loss: 2.397513742360144

Epoch: 5| Step: 2
Training loss: 0.37448398532163546
Validation loss: 2.373060402679068

Epoch: 5| Step: 3
Training loss: 0.49688364957082565
Validation loss: 2.3853489021219145

Epoch: 5| Step: 4
Training loss: 0.5707527969331923
Validation loss: 2.3158957961305746

Epoch: 5| Step: 5
Training loss: 0.5140643342979657
Validation loss: 2.41823751738491

Epoch: 5| Step: 6
Training loss: 0.667885356850618
Validation loss: 2.4026569014622337

Epoch: 5| Step: 7
Training loss: 0.5297289559224664
Validation loss: 2.3651200180960004

Epoch: 5| Step: 8
Training loss: 0.7341431190778799
Validation loss: 2.3651366239495544

Epoch: 5| Step: 9
Training loss: 1.495540984902926
Validation loss: 2.3499866596926333

Epoch: 5| Step: 10
Training loss: 0.5813632178022068
Validation loss: 2.344022158336261

Epoch: 675| Step: 0
Training loss: 0.6712150437471922
Validation loss: 2.3900642710593556

Epoch: 5| Step: 1
Training loss: 0.5977852127459946
Validation loss: 2.398752264353399

Epoch: 5| Step: 2
Training loss: 0.509679618975662
Validation loss: 2.4620504279230233

Epoch: 5| Step: 3
Training loss: 0.5090935321432973
Validation loss: 2.416565426907795

Epoch: 5| Step: 4
Training loss: 0.8670002503180225
Validation loss: 2.353105784794243

Epoch: 5| Step: 5
Training loss: 0.565174473433638
Validation loss: 2.3529266139137177

Epoch: 5| Step: 6
Training loss: 0.5552916661670855
Validation loss: 2.4047924656660857

Epoch: 5| Step: 7
Training loss: 0.5301744568900099
Validation loss: 2.3791057145333085

Epoch: 5| Step: 8
Training loss: 0.4480090230901635
Validation loss: 2.3140702153399686

Epoch: 5| Step: 9
Training loss: 1.4654684540324996
Validation loss: 2.379713246674306

Epoch: 5| Step: 10
Training loss: 0.5749739526985675
Validation loss: 2.4567301406382

Epoch: 676| Step: 0
Training loss: 0.438395758237166
Validation loss: 2.41109031608862

Epoch: 5| Step: 1
Training loss: 0.806743144247066
Validation loss: 2.3732773924465054

Epoch: 5| Step: 2
Training loss: 0.5111571571811743
Validation loss: 2.44576395367568

Epoch: 5| Step: 3
Training loss: 0.7568972851900474
Validation loss: 2.3791179254665806

Epoch: 5| Step: 4
Training loss: 0.43502184095032004
Validation loss: 2.3682764960475273

Epoch: 5| Step: 5
Training loss: 0.7187789413596181
Validation loss: 2.4423289361316534

Epoch: 5| Step: 6
Training loss: 0.49337887759408877
Validation loss: 2.395820646176624

Epoch: 5| Step: 7
Training loss: 0.5700660591160766
Validation loss: 2.38444854178219

Epoch: 5| Step: 8
Training loss: 1.5331485422708513
Validation loss: 2.371523021797987

Epoch: 5| Step: 9
Training loss: 0.6011829417339745
Validation loss: 2.394451630713714

Epoch: 5| Step: 10
Training loss: 0.6361978658664936
Validation loss: 2.4188700457378975

Epoch: 677| Step: 0
Training loss: 0.5273941581087168
Validation loss: 2.3721967835412947

Epoch: 5| Step: 1
Training loss: 0.569206864397567
Validation loss: 2.413634300519324

Epoch: 5| Step: 2
Training loss: 0.506564528868917
Validation loss: 2.4423134623649596

Epoch: 5| Step: 3
Training loss: 0.5714301823482627
Validation loss: 2.4013011912144737

Epoch: 5| Step: 4
Training loss: 0.46002033279408067
Validation loss: 2.35159169282087

Epoch: 5| Step: 5
Training loss: 0.40900104055179026
Validation loss: 2.414391108952013

Epoch: 5| Step: 6
Training loss: 0.6539604574725785
Validation loss: 2.431241767064391

Epoch: 5| Step: 7
Training loss: 0.6236983812260075
Validation loss: 2.4061643582293444

Epoch: 5| Step: 8
Training loss: 0.7481890510923486
Validation loss: 2.4341225775142994

Epoch: 5| Step: 9
Training loss: 0.605814730329313
Validation loss: 2.4338645928532876

Epoch: 5| Step: 10
Training loss: 1.5627841691056232
Validation loss: 2.466564951392843

Epoch: 678| Step: 0
Training loss: 0.4829295649162321
Validation loss: 2.366288874345256

Epoch: 5| Step: 1
Training loss: 0.5718380890070994
Validation loss: 2.393098221403609

Epoch: 5| Step: 2
Training loss: 0.7033086536885027
Validation loss: 2.4563426849472014

Epoch: 5| Step: 3
Training loss: 0.6369693239646729
Validation loss: 2.4096314225168984

Epoch: 5| Step: 4
Training loss: 0.5331285864741804
Validation loss: 2.3890912779949156

Epoch: 5| Step: 5
Training loss: 0.6364171302515332
Validation loss: 2.4227564197182367

Epoch: 5| Step: 6
Training loss: 0.5420963771442164
Validation loss: 2.4538906922781765

Epoch: 5| Step: 7
Training loss: 0.3987368226041421
Validation loss: 2.4457082141560607

Epoch: 5| Step: 8
Training loss: 0.6361808611134318
Validation loss: 2.4946348538490413

Epoch: 5| Step: 9
Training loss: 0.7856948295884378
Validation loss: 2.38063032130317

Epoch: 5| Step: 10
Training loss: 1.5355691524375334
Validation loss: 2.415383012508536

Epoch: 679| Step: 0
Training loss: 0.4134820432304227
Validation loss: 2.408560486473359

Epoch: 5| Step: 1
Training loss: 0.7818551961950693
Validation loss: 2.45623370334296

Epoch: 5| Step: 2
Training loss: 0.5922277411725984
Validation loss: 2.4462749714378305

Epoch: 5| Step: 3
Training loss: 0.7067743119051363
Validation loss: 2.4008865628443483

Epoch: 5| Step: 4
Training loss: 0.5316837447461956
Validation loss: 2.372708423495256

Epoch: 5| Step: 5
Training loss: 0.44673711877065475
Validation loss: 2.3764940267874217

Epoch: 5| Step: 6
Training loss: 0.5695744271780865
Validation loss: 2.4214567449808135

Epoch: 5| Step: 7
Training loss: 1.3691960866363437
Validation loss: 2.4211992689928996

Epoch: 5| Step: 8
Training loss: 0.6665599981047314
Validation loss: 2.4715451748361286

Epoch: 5| Step: 9
Training loss: 0.48363151710952373
Validation loss: 2.4820631088163334

Epoch: 5| Step: 10
Training loss: 0.39813327394448517
Validation loss: 2.425375817891027

Epoch: 680| Step: 0
Training loss: 0.41433070151709767
Validation loss: 2.377588418122351

Epoch: 5| Step: 1
Training loss: 1.4476134259415345
Validation loss: 2.4629262758142847

Epoch: 5| Step: 2
Training loss: 0.48020575854369013
Validation loss: 2.5115801317923325

Epoch: 5| Step: 3
Training loss: 0.4863881453279604
Validation loss: 2.460130353225269

Epoch: 5| Step: 4
Training loss: 0.6150971516966359
Validation loss: 2.382900219342757

Epoch: 5| Step: 5
Training loss: 0.6492222782410967
Validation loss: 2.3778415794075216

Epoch: 5| Step: 6
Training loss: 0.7815176314661039
Validation loss: 2.453065903746511

Epoch: 5| Step: 7
Training loss: 0.6292522260666681
Validation loss: 2.454324148476434

Epoch: 5| Step: 8
Training loss: 0.5422222851854602
Validation loss: 2.446007378985539

Epoch: 5| Step: 9
Training loss: 0.6449234896015217
Validation loss: 2.438040729366014

Epoch: 5| Step: 10
Training loss: 0.6679635744842443
Validation loss: 2.5127915955534275

Epoch: 681| Step: 0
Training loss: 0.6331256280125839
Validation loss: 2.4325493711195794

Epoch: 5| Step: 1
Training loss: 0.5444352906889193
Validation loss: 2.399995992855432

Epoch: 5| Step: 2
Training loss: 0.45774000589866165
Validation loss: 2.368787919434533

Epoch: 5| Step: 3
Training loss: 0.4411334823837065
Validation loss: 2.338526197710684

Epoch: 5| Step: 4
Training loss: 1.3975878643878108
Validation loss: 2.4376160567983165

Epoch: 5| Step: 5
Training loss: 0.5301030343597647
Validation loss: 2.3452692452578554

Epoch: 5| Step: 6
Training loss: 0.5928208208078283
Validation loss: 2.3787484728169863

Epoch: 5| Step: 7
Training loss: 0.6825415224153139
Validation loss: 2.3842590696505095

Epoch: 5| Step: 8
Training loss: 0.7503141698854445
Validation loss: 2.363764790108307

Epoch: 5| Step: 9
Training loss: 0.570915582629754
Validation loss: 2.4171224904332798

Epoch: 5| Step: 10
Training loss: 0.6437093638584845
Validation loss: 2.4694311039138706

Epoch: 682| Step: 0
Training loss: 1.42514692854073
Validation loss: 2.385030325500751

Epoch: 5| Step: 1
Training loss: 0.41788831275504207
Validation loss: 2.448070701582486

Epoch: 5| Step: 2
Training loss: 0.8194704365963322
Validation loss: 2.4519903023583938

Epoch: 5| Step: 3
Training loss: 0.6062643177268783
Validation loss: 2.4247677551329763

Epoch: 5| Step: 4
Training loss: 0.8321731518014521
Validation loss: 2.3385600588488398

Epoch: 5| Step: 5
Training loss: 0.4669525972094975
Validation loss: 2.377739251157247

Epoch: 5| Step: 6
Training loss: 0.5109317639230143
Validation loss: 2.4636262158833793

Epoch: 5| Step: 7
Training loss: 0.5473638801673518
Validation loss: 2.433463654278211

Epoch: 5| Step: 8
Training loss: 0.5503297673321091
Validation loss: 2.3701971439880323

Epoch: 5| Step: 9
Training loss: 0.6080200586210013
Validation loss: 2.4480525397767674

Epoch: 5| Step: 10
Training loss: 0.5649678084815432
Validation loss: 2.412317395184122

Epoch: 683| Step: 0
Training loss: 0.4451204354208288
Validation loss: 2.4535001696873877

Epoch: 5| Step: 1
Training loss: 0.7555789082165727
Validation loss: 2.4309485564761957

Epoch: 5| Step: 2
Training loss: 0.48331547805537545
Validation loss: 2.374372750283848

Epoch: 5| Step: 3
Training loss: 0.6737685688623547
Validation loss: 2.4137892015663946

Epoch: 5| Step: 4
Training loss: 0.6609089640055205
Validation loss: 2.3819335852365815

Epoch: 5| Step: 5
Training loss: 0.4427610889491486
Validation loss: 2.469602043978034

Epoch: 5| Step: 6
Training loss: 0.3540930274065203
Validation loss: 2.493288084979208

Epoch: 5| Step: 7
Training loss: 0.5471745896572865
Validation loss: 2.309099224953971

Epoch: 5| Step: 8
Training loss: 0.7467972399721392
Validation loss: 2.334035020421987

Epoch: 5| Step: 9
Training loss: 1.4095331225960508
Validation loss: 2.3764460017436146

Epoch: 5| Step: 10
Training loss: 0.6158146619310665
Validation loss: 2.340973586847456

Epoch: 684| Step: 0
Training loss: 0.5763663787991244
Validation loss: 2.3502849760395192

Epoch: 5| Step: 1
Training loss: 0.6432622728566907
Validation loss: 2.4662046466522045

Epoch: 5| Step: 2
Training loss: 0.6277505906959467
Validation loss: 2.460935810307946

Epoch: 5| Step: 3
Training loss: 0.36357853118691497
Validation loss: 2.380860407623288

Epoch: 5| Step: 4
Training loss: 0.7279327351573116
Validation loss: 2.4397821757097944

Epoch: 5| Step: 5
Training loss: 0.5208435121177404
Validation loss: 2.4012178092995113

Epoch: 5| Step: 6
Training loss: 1.419644293223132
Validation loss: 2.4290642782002827

Epoch: 5| Step: 7
Training loss: 0.5835047765109731
Validation loss: 2.3993378416677222

Epoch: 5| Step: 8
Training loss: 0.5820052377917372
Validation loss: 2.3631475687587806

Epoch: 5| Step: 9
Training loss: 0.643576475477926
Validation loss: 2.360997165071434

Epoch: 5| Step: 10
Training loss: 0.687001741359897
Validation loss: 2.439761790760434

Epoch: 685| Step: 0
Training loss: 0.6524216611101497
Validation loss: 2.348319704595603

Epoch: 5| Step: 1
Training loss: 0.4884045254540633
Validation loss: 2.4212420157372176

Epoch: 5| Step: 2
Training loss: 0.5153285821795999
Validation loss: 2.4422814365051253

Epoch: 5| Step: 3
Training loss: 0.6898744284697783
Validation loss: 2.3646003108526172

Epoch: 5| Step: 4
Training loss: 0.5973696052449758
Validation loss: 2.477262091275784

Epoch: 5| Step: 5
Training loss: 1.551623675320686
Validation loss: 2.3187689833453686

Epoch: 5| Step: 6
Training loss: 0.6307187233608135
Validation loss: 2.424357704840462

Epoch: 5| Step: 7
Training loss: 0.6986807772856152
Validation loss: 2.4193846040692657

Epoch: 5| Step: 8
Training loss: 0.6385200623367767
Validation loss: 2.3938299003543486

Epoch: 5| Step: 9
Training loss: 0.558227846040022
Validation loss: 2.367096342967829

Epoch: 5| Step: 10
Training loss: 0.770113381113489
Validation loss: 2.3941046254050753

Epoch: 686| Step: 0
Training loss: 0.5703087898029198
Validation loss: 2.435290269203224

Epoch: 5| Step: 1
Training loss: 0.5614428918539888
Validation loss: 2.4228366854441554

Epoch: 5| Step: 2
Training loss: 1.4253901533114028
Validation loss: 2.4357969917756765

Epoch: 5| Step: 3
Training loss: 0.6021451729120827
Validation loss: 2.380301769996191

Epoch: 5| Step: 4
Training loss: 0.5955393581724182
Validation loss: 2.337649813195335

Epoch: 5| Step: 5
Training loss: 0.5582376158451492
Validation loss: 2.4667822951936427

Epoch: 5| Step: 6
Training loss: 0.604590757649969
Validation loss: 2.482341667953955

Epoch: 5| Step: 7
Training loss: 0.594289634823967
Validation loss: 2.4451506064844977

Epoch: 5| Step: 8
Training loss: 0.5745425965426133
Validation loss: 2.4601936201790933

Epoch: 5| Step: 9
Training loss: 0.4501057037077726
Validation loss: 2.434430161560341

Epoch: 5| Step: 10
Training loss: 0.5441287979407061
Validation loss: 2.3651002025642613

Epoch: 687| Step: 0
Training loss: 1.52871946539839
Validation loss: 2.367812242202043

Epoch: 5| Step: 1
Training loss: 0.6578287027497413
Validation loss: 2.407032458377909

Epoch: 5| Step: 2
Training loss: 0.513997833915332
Validation loss: 2.4221882787206908

Epoch: 5| Step: 3
Training loss: 0.5081385519418786
Validation loss: 2.325814972037043

Epoch: 5| Step: 4
Training loss: 0.5889303195697412
Validation loss: 2.3507014284222887

Epoch: 5| Step: 5
Training loss: 0.5050236931521025
Validation loss: 2.4054857459205223

Epoch: 5| Step: 6
Training loss: 0.7062120908504842
Validation loss: 2.41627386342839

Epoch: 5| Step: 7
Training loss: 0.7323942865897834
Validation loss: 2.3708033478728985

Epoch: 5| Step: 8
Training loss: 0.536070356222721
Validation loss: 2.4146971077688058

Epoch: 5| Step: 9
Training loss: 0.5381958947794524
Validation loss: 2.433296632791975

Epoch: 5| Step: 10
Training loss: 0.532038076079687
Validation loss: 2.371102371520453

Epoch: 688| Step: 0
Training loss: 0.46684858602338475
Validation loss: 2.433461823304038

Epoch: 5| Step: 1
Training loss: 0.800926865154721
Validation loss: 2.4552576866084754

Epoch: 5| Step: 2
Training loss: 0.5089334586872066
Validation loss: 2.3999209334994895

Epoch: 5| Step: 3
Training loss: 0.5930794895185668
Validation loss: 2.375573170597887

Epoch: 5| Step: 4
Training loss: 0.7563297671030409
Validation loss: 2.3875312655376986

Epoch: 5| Step: 5
Training loss: 1.4205545015712013
Validation loss: 2.3628354571380994

Epoch: 5| Step: 6
Training loss: 0.39407136760417727
Validation loss: 2.4056324916902803

Epoch: 5| Step: 7
Training loss: 0.44951042988932377
Validation loss: 2.3368546603252827

Epoch: 5| Step: 8
Training loss: 0.5721557824236414
Validation loss: 2.4045133275261814

Epoch: 5| Step: 9
Training loss: 0.550668204319649
Validation loss: 2.4422758857332596

Epoch: 5| Step: 10
Training loss: 0.43956378814972813
Validation loss: 2.4302230237932583

Epoch: 689| Step: 0
Training loss: 0.5450985529799037
Validation loss: 2.423830808339064

Epoch: 5| Step: 1
Training loss: 0.5819841148184774
Validation loss: 2.388373037918369

Epoch: 5| Step: 2
Training loss: 0.5884866323030487
Validation loss: 2.4318106951483185

Epoch: 5| Step: 3
Training loss: 1.3896076038229421
Validation loss: 2.379074130898613

Epoch: 5| Step: 4
Training loss: 0.5293384549746336
Validation loss: 2.4327989738558795

Epoch: 5| Step: 5
Training loss: 0.33714759583468146
Validation loss: 2.4821684404056024

Epoch: 5| Step: 6
Training loss: 0.5159778543606724
Validation loss: 2.4683808538409413

Epoch: 5| Step: 7
Training loss: 0.6800246882164369
Validation loss: 2.4164557785746155

Epoch: 5| Step: 8
Training loss: 0.7314252659656988
Validation loss: 2.416236706237567

Epoch: 5| Step: 9
Training loss: 0.4197911081081615
Validation loss: 2.39146291820265

Epoch: 5| Step: 10
Training loss: 0.7292463713180659
Validation loss: 2.4158527895936914

Epoch: 690| Step: 0
Training loss: 0.4536487249318
Validation loss: 2.3990632387605317

Epoch: 5| Step: 1
Training loss: 1.4018973062265296
Validation loss: 2.419657785426239

Epoch: 5| Step: 2
Training loss: 0.7850298803559042
Validation loss: 2.4128346131795677

Epoch: 5| Step: 3
Training loss: 0.4634229922451408
Validation loss: 2.4485150986613378

Epoch: 5| Step: 4
Training loss: 0.643212790544572
Validation loss: 2.4090100692855083

Epoch: 5| Step: 5
Training loss: 0.6288844987413115
Validation loss: 2.410064256741015

Epoch: 5| Step: 6
Training loss: 0.7138144999420043
Validation loss: 2.482610729136325

Epoch: 5| Step: 7
Training loss: 0.4868133759093403
Validation loss: 2.428860581716481

Epoch: 5| Step: 8
Training loss: 0.47249382948504576
Validation loss: 2.4515353731556364

Epoch: 5| Step: 9
Training loss: 0.4294778138826456
Validation loss: 2.4836447244756825

Epoch: 5| Step: 10
Training loss: 0.557898589043851
Validation loss: 2.424674110685896

Epoch: 691| Step: 0
Training loss: 0.8008211079424149
Validation loss: 2.443665930433296

Epoch: 5| Step: 1
Training loss: 0.47516334448112074
Validation loss: 2.368559124369645

Epoch: 5| Step: 2
Training loss: 0.6095854322519452
Validation loss: 2.3956447496780426

Epoch: 5| Step: 3
Training loss: 0.47304459058617937
Validation loss: 2.4287451620819382

Epoch: 5| Step: 4
Training loss: 0.5955804917476908
Validation loss: 2.3557912034801274

Epoch: 5| Step: 5
Training loss: 0.6727514981522849
Validation loss: 2.4112788945809798

Epoch: 5| Step: 6
Training loss: 0.5336508076714125
Validation loss: 2.3655872224209684

Epoch: 5| Step: 7
Training loss: 0.4094188237211392
Validation loss: 2.389618629266201

Epoch: 5| Step: 8
Training loss: 1.5033828419034967
Validation loss: 2.4093672717023824

Epoch: 5| Step: 9
Training loss: 0.4996069018531652
Validation loss: 2.4285623951036697

Epoch: 5| Step: 10
Training loss: 0.31981578553707396
Validation loss: 2.3205394366655963

Epoch: 692| Step: 0
Training loss: 0.41188650749003375
Validation loss: 2.401769569411153

Epoch: 5| Step: 1
Training loss: 0.4970697429181566
Validation loss: 2.4349589790358586

Epoch: 5| Step: 2
Training loss: 0.7265549526027686
Validation loss: 2.4283955291288524

Epoch: 5| Step: 3
Training loss: 0.544387774399704
Validation loss: 2.4818410480091098

Epoch: 5| Step: 4
Training loss: 0.409210276769051
Validation loss: 2.3614283010451733

Epoch: 5| Step: 5
Training loss: 0.6108615545108805
Validation loss: 2.44103379110344

Epoch: 5| Step: 6
Training loss: 0.531018150450423
Validation loss: 2.3597513099905965

Epoch: 5| Step: 7
Training loss: 0.4031067067808433
Validation loss: 2.449659485788379

Epoch: 5| Step: 8
Training loss: 1.497838529300531
Validation loss: 2.425686116442247

Epoch: 5| Step: 9
Training loss: 0.5731736618233354
Validation loss: 2.4273750478082983

Epoch: 5| Step: 10
Training loss: 0.6519093466220208
Validation loss: 2.446679324163476

Epoch: 693| Step: 0
Training loss: 0.6440466243706667
Validation loss: 2.401416184442604

Epoch: 5| Step: 1
Training loss: 0.6652662026569273
Validation loss: 2.3693823510372423

Epoch: 5| Step: 2
Training loss: 0.398771856300925
Validation loss: 2.4189628015455833

Epoch: 5| Step: 3
Training loss: 0.6060811545038557
Validation loss: 2.4668073756496933

Epoch: 5| Step: 4
Training loss: 0.5703343165157114
Validation loss: 2.4651599626140666

Epoch: 5| Step: 5
Training loss: 1.4423887631055317
Validation loss: 2.346100959410116

Epoch: 5| Step: 6
Training loss: 0.5215692343942768
Validation loss: 2.444747730108863

Epoch: 5| Step: 7
Training loss: 0.5573394671704149
Validation loss: 2.4259812131917053

Epoch: 5| Step: 8
Training loss: 0.6401981001347574
Validation loss: 2.4305174484039256

Epoch: 5| Step: 9
Training loss: 0.46130123980653454
Validation loss: 2.4534700667108744

Epoch: 5| Step: 10
Training loss: 0.5469028465810726
Validation loss: 2.3395639551140177

Epoch: 694| Step: 0
Training loss: 0.44507549068829066
Validation loss: 2.4271023072806406

Epoch: 5| Step: 1
Training loss: 0.5128773683925151
Validation loss: 2.3945437987412843

Epoch: 5| Step: 2
Training loss: 1.4433882817534152
Validation loss: 2.3697555367953003

Epoch: 5| Step: 3
Training loss: 0.6544164292156035
Validation loss: 2.393974459076596

Epoch: 5| Step: 4
Training loss: 0.7436212845025129
Validation loss: 2.4261100189174076

Epoch: 5| Step: 5
Training loss: 0.5788339443586167
Validation loss: 2.4151472163633705

Epoch: 5| Step: 6
Training loss: 0.36759343941352823
Validation loss: 2.3617603335261577

Epoch: 5| Step: 7
Training loss: 0.49268715337779573
Validation loss: 2.4352389151122953

Epoch: 5| Step: 8
Training loss: 0.6827152165436576
Validation loss: 2.4061174157740837

Epoch: 5| Step: 9
Training loss: 0.45987290756898425
Validation loss: 2.3648579228294104

Epoch: 5| Step: 10
Training loss: 0.5849103953540762
Validation loss: 2.391882019906409

Epoch: 695| Step: 0
Training loss: 0.700858468486849
Validation loss: 2.3680157940526345

Epoch: 5| Step: 1
Training loss: 0.4379422472999591
Validation loss: 2.386890256246774

Epoch: 5| Step: 2
Training loss: 0.5075262289832938
Validation loss: 2.4418215509086707

Epoch: 5| Step: 3
Training loss: 1.3894645049128092
Validation loss: 2.508783439943802

Epoch: 5| Step: 4
Training loss: 0.660732333938326
Validation loss: 2.38534712771807

Epoch: 5| Step: 5
Training loss: 0.5869994648828618
Validation loss: 2.399058920541252

Epoch: 5| Step: 6
Training loss: 0.6534766222618396
Validation loss: 2.388952120466929

Epoch: 5| Step: 7
Training loss: 0.48340196704539257
Validation loss: 2.3426928109546927

Epoch: 5| Step: 8
Training loss: 0.6021395553641531
Validation loss: 2.458355184144745

Epoch: 5| Step: 9
Training loss: 0.5602439566971026
Validation loss: 2.3688271271675503

Epoch: 5| Step: 10
Training loss: 0.6636882849556728
Validation loss: 2.3436836342661707

Epoch: 696| Step: 0
Training loss: 0.5311179838518402
Validation loss: 2.4164194731867426

Epoch: 5| Step: 1
Training loss: 1.4569257028103806
Validation loss: 2.4400849824826003

Epoch: 5| Step: 2
Training loss: 0.5717478157321988
Validation loss: 2.4418206369804643

Epoch: 5| Step: 3
Training loss: 0.5927069436600612
Validation loss: 2.3753455061313784

Epoch: 5| Step: 4
Training loss: 0.6161312529342765
Validation loss: 2.426095068325304

Epoch: 5| Step: 5
Training loss: 0.4042454378145455
Validation loss: 2.3704961159493108

Epoch: 5| Step: 6
Training loss: 0.6711269694622868
Validation loss: 2.385599560211921

Epoch: 5| Step: 7
Training loss: 0.6294539536746118
Validation loss: 2.4381697360157397

Epoch: 5| Step: 8
Training loss: 0.6610521636411585
Validation loss: 2.448239720448165

Epoch: 5| Step: 9
Training loss: 0.5053688823264568
Validation loss: 2.3720694867985963

Epoch: 5| Step: 10
Training loss: 0.4808016918300974
Validation loss: 2.380957309626973

Epoch: 697| Step: 0
Training loss: 0.5358668711752943
Validation loss: 2.433453649220143

Epoch: 5| Step: 1
Training loss: 0.7096407455570894
Validation loss: 2.4565548777271977

Epoch: 5| Step: 2
Training loss: 0.4980772270976941
Validation loss: 2.337183804063085

Epoch: 5| Step: 3
Training loss: 0.609028057222533
Validation loss: 2.3891607952393077

Epoch: 5| Step: 4
Training loss: 1.4274670811212904
Validation loss: 2.397963393332448

Epoch: 5| Step: 5
Training loss: 0.3648939943534966
Validation loss: 2.406234933736464

Epoch: 5| Step: 6
Training loss: 0.48784248474946185
Validation loss: 2.414732604848067

Epoch: 5| Step: 7
Training loss: 0.6859930385272522
Validation loss: 2.3978921683755736

Epoch: 5| Step: 8
Training loss: 0.7287956292866149
Validation loss: 2.3753158216865513

Epoch: 5| Step: 9
Training loss: 0.3126541115317354
Validation loss: 2.372098576928726

Epoch: 5| Step: 10
Training loss: 0.43011229931062467
Validation loss: 2.375952494561557

Epoch: 698| Step: 0
Training loss: 0.7265537220414386
Validation loss: 2.37043878067209

Epoch: 5| Step: 1
Training loss: 0.6038572461774275
Validation loss: 2.348302211266023

Epoch: 5| Step: 2
Training loss: 0.5687508300104478
Validation loss: 2.393303810148283

Epoch: 5| Step: 3
Training loss: 0.5303614984106872
Validation loss: 2.401394008581822

Epoch: 5| Step: 4
Training loss: 0.4978663397803678
Validation loss: 2.3784484880859673

Epoch: 5| Step: 5
Training loss: 0.5394714020899932
Validation loss: 2.414683684354182

Epoch: 5| Step: 6
Training loss: 0.5321667838866577
Validation loss: 2.41076070582725

Epoch: 5| Step: 7
Training loss: 0.4698131425971645
Validation loss: 2.3915246293151746

Epoch: 5| Step: 8
Training loss: 1.379746524157382
Validation loss: 2.4257153852890885

Epoch: 5| Step: 9
Training loss: 0.6154985859619929
Validation loss: 2.3401269168387446

Epoch: 5| Step: 10
Training loss: 0.5256550913848363
Validation loss: 2.372959862589154

Epoch: 699| Step: 0
Training loss: 0.41724438154507376
Validation loss: 2.404377750566489

Epoch: 5| Step: 1
Training loss: 1.374793904204363
Validation loss: 2.3738021188252567

Epoch: 5| Step: 2
Training loss: 0.32804778870911616
Validation loss: 2.341321148534446

Epoch: 5| Step: 3
Training loss: 0.7245921829528487
Validation loss: 2.4231795582688105

Epoch: 5| Step: 4
Training loss: 0.6516682902565493
Validation loss: 2.4342684468501035

Epoch: 5| Step: 5
Training loss: 0.3936450182517743
Validation loss: 2.3905214494635834

Epoch: 5| Step: 6
Training loss: 0.5639829426292939
Validation loss: 2.4096060506939097

Epoch: 5| Step: 7
Training loss: 0.45838432859171646
Validation loss: 2.435560985500331

Epoch: 5| Step: 8
Training loss: 0.688677667776272
Validation loss: 2.467798968087774

Epoch: 5| Step: 9
Training loss: 0.5321205243510949
Validation loss: 2.4314341578405227

Epoch: 5| Step: 10
Training loss: 0.5241572427837459
Validation loss: 2.3618748218928682

Epoch: 700| Step: 0
Training loss: 0.5698252386167367
Validation loss: 2.3635837790799563

Epoch: 5| Step: 1
Training loss: 0.5504826487059666
Validation loss: 2.344040600115146

Epoch: 5| Step: 2
Training loss: 0.4528952213282458
Validation loss: 2.393513106448285

Epoch: 5| Step: 3
Training loss: 0.548405875139186
Validation loss: 2.4080819384042975

Epoch: 5| Step: 4
Training loss: 0.6186522955770255
Validation loss: 2.4400332475767716

Epoch: 5| Step: 5
Training loss: 0.5632456499719921
Validation loss: 2.3116077851490293

Epoch: 5| Step: 6
Training loss: 0.8088103663041494
Validation loss: 2.4429608468211166

Epoch: 5| Step: 7
Training loss: 0.9218784590834038
Validation loss: 2.4803712303261216

Epoch: 5| Step: 8
Training loss: 0.6093163828900686
Validation loss: 2.4167335845400935

Epoch: 5| Step: 9
Training loss: 0.3447009501249622
Validation loss: 2.3479551064650215

Epoch: 5| Step: 10
Training loss: 1.5860302526852574
Validation loss: 2.371517123258358

Epoch: 701| Step: 0
Training loss: 0.7545656078144759
Validation loss: 2.436227573097571

Epoch: 5| Step: 1
Training loss: 1.3881698537945595
Validation loss: 2.343369689493905

Epoch: 5| Step: 2
Training loss: 0.5210981903573287
Validation loss: 2.393487929207893

Epoch: 5| Step: 3
Training loss: 0.5181112458781342
Validation loss: 2.451964547047208

Epoch: 5| Step: 4
Training loss: 0.5580327878602814
Validation loss: 2.436952852420306

Epoch: 5| Step: 5
Training loss: 0.6135769028144257
Validation loss: 2.3721628281443436

Epoch: 5| Step: 6
Training loss: 0.8073107727415043
Validation loss: 2.375184350450052

Epoch: 5| Step: 7
Training loss: 0.5902051513223435
Validation loss: 2.461455925451512

Epoch: 5| Step: 8
Training loss: 0.5491753562399914
Validation loss: 2.3599936153686323

Epoch: 5| Step: 9
Training loss: 0.5789177588426948
Validation loss: 2.4332491944291808

Epoch: 5| Step: 10
Training loss: 0.28835098229583755
Validation loss: 2.390427753596136

Epoch: 702| Step: 0
Training loss: 0.5269436484036857
Validation loss: 2.376233020992022

Epoch: 5| Step: 1
Training loss: 0.3834868932931266
Validation loss: 2.376234206397418

Epoch: 5| Step: 2
Training loss: 0.3428529500438841
Validation loss: 2.3871928583076114

Epoch: 5| Step: 3
Training loss: 0.7616471477013641
Validation loss: 2.4372287096536454

Epoch: 5| Step: 4
Training loss: 1.4454086684116303
Validation loss: 2.379162406159704

Epoch: 5| Step: 5
Training loss: 0.41587211031837124
Validation loss: 2.4066996756850947

Epoch: 5| Step: 6
Training loss: 0.7015469538743989
Validation loss: 2.35977552632989

Epoch: 5| Step: 7
Training loss: 0.5642126026309906
Validation loss: 2.444520751570659

Epoch: 5| Step: 8
Training loss: 0.6165237237460379
Validation loss: 2.3497075205190328

Epoch: 5| Step: 9
Training loss: 0.4830084258128467
Validation loss: 2.332166756620177

Epoch: 5| Step: 10
Training loss: 0.5343349865661543
Validation loss: 2.363892506408192

Epoch: 703| Step: 0
Training loss: 0.6533069466676277
Validation loss: 2.3821481904002315

Epoch: 5| Step: 1
Training loss: 0.5088552186682403
Validation loss: 2.3566474395921198

Epoch: 5| Step: 2
Training loss: 0.5256139004291757
Validation loss: 2.400169476982207

Epoch: 5| Step: 3
Training loss: 0.5852424059036629
Validation loss: 2.4207106973503087

Epoch: 5| Step: 4
Training loss: 0.8395669880325833
Validation loss: 2.4540463926108766

Epoch: 5| Step: 5
Training loss: 0.41259191384918525
Validation loss: 2.4551163890839085

Epoch: 5| Step: 6
Training loss: 1.3570311059331295
Validation loss: 2.4623014484024495

Epoch: 5| Step: 7
Training loss: 0.5700934002296041
Validation loss: 2.4791409732531275

Epoch: 5| Step: 8
Training loss: 0.4312841056384787
Validation loss: 2.4064101064830927

Epoch: 5| Step: 9
Training loss: 0.6200827761736742
Validation loss: 2.4105735576155625

Epoch: 5| Step: 10
Training loss: 0.5112325965232255
Validation loss: 2.4009352348501793

Epoch: 704| Step: 0
Training loss: 0.4472440356245496
Validation loss: 2.401078004468417

Epoch: 5| Step: 1
Training loss: 0.7192774785918239
Validation loss: 2.3493225573433123

Epoch: 5| Step: 2
Training loss: 1.398714773298712
Validation loss: 2.4050252242768786

Epoch: 5| Step: 3
Training loss: 0.5362984101023127
Validation loss: 2.3699660505581597

Epoch: 5| Step: 4
Training loss: 0.4888722009893245
Validation loss: 2.417030863605242

Epoch: 5| Step: 5
Training loss: 0.5906781742843924
Validation loss: 2.40343598138198

Epoch: 5| Step: 6
Training loss: 0.553080447067532
Validation loss: 2.32571255474505

Epoch: 5| Step: 7
Training loss: 0.5070407578527601
Validation loss: 2.399875266711736

Epoch: 5| Step: 8
Training loss: 0.4977398842521803
Validation loss: 2.4415297242801937

Epoch: 5| Step: 9
Training loss: 0.4424747935621316
Validation loss: 2.4523102119321467

Epoch: 5| Step: 10
Training loss: 0.44498140172990747
Validation loss: 2.4195230991977295

Epoch: 705| Step: 0
Training loss: 0.453924673760342
Validation loss: 2.384245711959127

Epoch: 5| Step: 1
Training loss: 1.337829053812456
Validation loss: 2.3924530576556453

Epoch: 5| Step: 2
Training loss: 0.5332384482061132
Validation loss: 2.39843865866508

Epoch: 5| Step: 3
Training loss: 0.5714554242866542
Validation loss: 2.358713414887267

Epoch: 5| Step: 4
Training loss: 0.5421394491752708
Validation loss: 2.4419236042483505

Epoch: 5| Step: 5
Training loss: 0.7455209260686163
Validation loss: 2.4066609082521517

Epoch: 5| Step: 6
Training loss: 0.8477263883060321
Validation loss: 2.4613760160811275

Epoch: 5| Step: 7
Training loss: 0.45260406014192806
Validation loss: 2.4110538296934614

Epoch: 5| Step: 8
Training loss: 0.5695428227006298
Validation loss: 2.3559687479033755

Epoch: 5| Step: 9
Training loss: 0.5410563870164314
Validation loss: 2.39942078941682

Epoch: 5| Step: 10
Training loss: 0.41347773663944687
Validation loss: 2.455586984161024

Epoch: 706| Step: 0
Training loss: 0.5572128299554614
Validation loss: 2.3985801836847065

Epoch: 5| Step: 1
Training loss: 1.4432068203430823
Validation loss: 2.4072978621787335

Epoch: 5| Step: 2
Training loss: 0.48368876052339266
Validation loss: 2.353469190657299

Epoch: 5| Step: 3
Training loss: 0.4644391839812202
Validation loss: 2.380661138566303

Epoch: 5| Step: 4
Training loss: 0.4038667832946378
Validation loss: 2.4078111744686623

Epoch: 5| Step: 5
Training loss: 0.5996148174424091
Validation loss: 2.473545078720521

Epoch: 5| Step: 6
Training loss: 0.534023841007815
Validation loss: 2.417937451348451

Epoch: 5| Step: 7
Training loss: 0.7511304045451167
Validation loss: 2.414321667269291

Epoch: 5| Step: 8
Training loss: 0.5060591137661923
Validation loss: 2.444628943436297

Epoch: 5| Step: 9
Training loss: 0.37470221617037947
Validation loss: 2.441158111759894

Epoch: 5| Step: 10
Training loss: 0.3788284536506988
Validation loss: 2.4192599963668426

Epoch: 707| Step: 0
Training loss: 0.4629543920447679
Validation loss: 2.418593823916481

Epoch: 5| Step: 1
Training loss: 0.3305251350728021
Validation loss: 2.399825958424031

Epoch: 5| Step: 2
Training loss: 0.6184229256029163
Validation loss: 2.427595968944762

Epoch: 5| Step: 3
Training loss: 0.5204299954473084
Validation loss: 2.471354410787916

Epoch: 5| Step: 4
Training loss: 0.34826281492338773
Validation loss: 2.359465042848469

Epoch: 5| Step: 5
Training loss: 0.6406061355790651
Validation loss: 2.3961890264688073

Epoch: 5| Step: 6
Training loss: 0.45420514637850523
Validation loss: 2.363472102855777

Epoch: 5| Step: 7
Training loss: 0.6310381089928093
Validation loss: 2.417875847378652

Epoch: 5| Step: 8
Training loss: 1.4697701989473126
Validation loss: 2.3854807416864348

Epoch: 5| Step: 9
Training loss: 0.7573690001518759
Validation loss: 2.448966503687554

Epoch: 5| Step: 10
Training loss: 0.5954968204653629
Validation loss: 2.368998125815742

Epoch: 708| Step: 0
Training loss: 0.5268639819259056
Validation loss: 2.392025084978153

Epoch: 5| Step: 1
Training loss: 0.5547316359032834
Validation loss: 2.395588055896255

Epoch: 5| Step: 2
Training loss: 0.5088201941632496
Validation loss: 2.51289877314837

Epoch: 5| Step: 3
Training loss: 0.6156019777747068
Validation loss: 2.409452495592458

Epoch: 5| Step: 4
Training loss: 0.5960045474042162
Validation loss: 2.3849026479536075

Epoch: 5| Step: 5
Training loss: 0.2817758571484799
Validation loss: 2.37973129659524

Epoch: 5| Step: 6
Training loss: 0.6387761348819837
Validation loss: 2.4485085757273186

Epoch: 5| Step: 7
Training loss: 0.5823068670246241
Validation loss: 2.4605667160473534

Epoch: 5| Step: 8
Training loss: 0.6333717888735071
Validation loss: 2.4006576222050433

Epoch: 5| Step: 9
Training loss: 0.4682024778058948
Validation loss: 2.4667388483354458

Epoch: 5| Step: 10
Training loss: 1.5343493799374233
Validation loss: 2.362284629134419

Epoch: 709| Step: 0
Training loss: 0.6069517125243261
Validation loss: 2.4128560155856125

Epoch: 5| Step: 1
Training loss: 0.5022003514960489
Validation loss: 2.457647199873923

Epoch: 5| Step: 2
Training loss: 0.7538878285425473
Validation loss: 2.3794144944026536

Epoch: 5| Step: 3
Training loss: 0.39587991423668867
Validation loss: 2.431812670738198

Epoch: 5| Step: 4
Training loss: 0.45318187159414214
Validation loss: 2.3401279143035763

Epoch: 5| Step: 5
Training loss: 0.5504417184542669
Validation loss: 2.3645421571567464

Epoch: 5| Step: 6
Training loss: 0.6208370565989769
Validation loss: 2.401732919536091

Epoch: 5| Step: 7
Training loss: 0.45346244217609655
Validation loss: 2.4502329853069926

Epoch: 5| Step: 8
Training loss: 1.4335460187153597
Validation loss: 2.3739896151386737

Epoch: 5| Step: 9
Training loss: 0.5893348873561692
Validation loss: 2.3996700230290364

Epoch: 5| Step: 10
Training loss: 0.5057529646842679
Validation loss: 2.421574545703704

Epoch: 710| Step: 0
Training loss: 0.5368077488923374
Validation loss: 2.3713374964308414

Epoch: 5| Step: 1
Training loss: 0.45479588085370876
Validation loss: 2.405569929981037

Epoch: 5| Step: 2
Training loss: 0.7810532131309931
Validation loss: 2.4205177465576613

Epoch: 5| Step: 3
Training loss: 0.5197120007894489
Validation loss: 2.3906085379522533

Epoch: 5| Step: 4
Training loss: 1.4005110301843502
Validation loss: 2.3954199453486944

Epoch: 5| Step: 5
Training loss: 0.5166987596306846
Validation loss: 2.3978625134049403

Epoch: 5| Step: 6
Training loss: 0.46931406097924694
Validation loss: 2.3778886334529776

Epoch: 5| Step: 7
Training loss: 0.6455791624402352
Validation loss: 2.425111939561769

Epoch: 5| Step: 8
Training loss: 0.7430602313178793
Validation loss: 2.4185065633647045

Epoch: 5| Step: 9
Training loss: 0.6205910141504869
Validation loss: 2.4095438868695873

Epoch: 5| Step: 10
Training loss: 0.5395692848036154
Validation loss: 2.3450398374975006

Epoch: 711| Step: 0
Training loss: 0.6301138993647402
Validation loss: 2.311190420320871

Epoch: 5| Step: 1
Training loss: 0.6254165691686558
Validation loss: 2.3688475727666907

Epoch: 5| Step: 2
Training loss: 0.44586495379441377
Validation loss: 2.4790049719325107

Epoch: 5| Step: 3
Training loss: 0.7621672654760252
Validation loss: 2.455695581581122

Epoch: 5| Step: 4
Training loss: 1.361719893314409
Validation loss: 2.4174447951523947

Epoch: 5| Step: 5
Training loss: 0.38407072258660435
Validation loss: 2.3430813279187395

Epoch: 5| Step: 6
Training loss: 0.5148298027221718
Validation loss: 2.3388196840817885

Epoch: 5| Step: 7
Training loss: 0.4355050481718285
Validation loss: 2.359474147991662

Epoch: 5| Step: 8
Training loss: 0.5640386623935572
Validation loss: 2.3524629286714176

Epoch: 5| Step: 9
Training loss: 0.7553890056002929
Validation loss: 2.417197690704254

Epoch: 5| Step: 10
Training loss: 0.5196864821194093
Validation loss: 2.3451729161134764

Epoch: 712| Step: 0
Training loss: 0.5438961369802481
Validation loss: 2.4047014591070117

Epoch: 5| Step: 1
Training loss: 0.5229729825986298
Validation loss: 2.3477763418129087

Epoch: 5| Step: 2
Training loss: 0.41497949509347776
Validation loss: 2.3976668519686264

Epoch: 5| Step: 3
Training loss: 0.6132856235226718
Validation loss: 2.3919762535055735

Epoch: 5| Step: 4
Training loss: 0.8801641998663368
Validation loss: 2.4124515323487388

Epoch: 5| Step: 5
Training loss: 0.4929577839836254
Validation loss: 2.403341380954333

Epoch: 5| Step: 6
Training loss: 0.43393856806007575
Validation loss: 2.4771365078285683

Epoch: 5| Step: 7
Training loss: 0.4488991305207933
Validation loss: 2.450304361791556

Epoch: 5| Step: 8
Training loss: 0.6587920681081609
Validation loss: 2.3524151194847187

Epoch: 5| Step: 9
Training loss: 0.5763921025836419
Validation loss: 2.420870771946891

Epoch: 5| Step: 10
Training loss: 1.545351221970661
Validation loss: 2.3996248658771173

Epoch: 713| Step: 0
Training loss: 0.5845351667764954
Validation loss: 2.423081342157047

Epoch: 5| Step: 1
Training loss: 0.7398750419404008
Validation loss: 2.4371754924876194

Epoch: 5| Step: 2
Training loss: 1.4928913952775908
Validation loss: 2.3199237326404556

Epoch: 5| Step: 3
Training loss: 0.6653044810960831
Validation loss: 2.379953200863471

Epoch: 5| Step: 4
Training loss: 0.48501129810702154
Validation loss: 2.3528294193300487

Epoch: 5| Step: 5
Training loss: 0.4607201564901639
Validation loss: 2.374796368041066

Epoch: 5| Step: 6
Training loss: 0.6569023069300847
Validation loss: 2.4276459012131886

Epoch: 5| Step: 7
Training loss: 0.6239110997768871
Validation loss: 2.3425763873193595

Epoch: 5| Step: 8
Training loss: 0.5575812974593423
Validation loss: 2.4349932279263315

Epoch: 5| Step: 9
Training loss: 0.5756594173153123
Validation loss: 2.4450478154813786

Epoch: 5| Step: 10
Training loss: 0.7297471914443165
Validation loss: 2.429380075276183

Epoch: 714| Step: 0
Training loss: 0.7009941449621457
Validation loss: 2.392442069388526

Epoch: 5| Step: 1
Training loss: 0.6266350102503018
Validation loss: 2.3581227004738103

Epoch: 5| Step: 2
Training loss: 0.45722597000755044
Validation loss: 2.4272655313223366

Epoch: 5| Step: 3
Training loss: 0.4478098128265448
Validation loss: 2.384584068693329

Epoch: 5| Step: 4
Training loss: 1.2915160901481058
Validation loss: 2.329892760520919

Epoch: 5| Step: 5
Training loss: 0.7044257530063518
Validation loss: 2.4203613399191637

Epoch: 5| Step: 6
Training loss: 0.6625201546104429
Validation loss: 2.3620166437541164

Epoch: 5| Step: 7
Training loss: 0.4660069313741265
Validation loss: 2.3574911136051053

Epoch: 5| Step: 8
Training loss: 0.3848751706094788
Validation loss: 2.392399638794778

Epoch: 5| Step: 9
Training loss: 0.41773834295120144
Validation loss: 2.452401790239086

Epoch: 5| Step: 10
Training loss: 0.6167804003128529
Validation loss: 2.3481402684187245

Epoch: 715| Step: 0
Training loss: 0.7425852061359961
Validation loss: 2.366635709629723

Epoch: 5| Step: 1
Training loss: 0.48433886670115134
Validation loss: 2.3448878555407657

Epoch: 5| Step: 2
Training loss: 0.6930997550501602
Validation loss: 2.4116022125577947

Epoch: 5| Step: 3
Training loss: 1.4396987353532964
Validation loss: 2.3592485604365097

Epoch: 5| Step: 4
Training loss: 0.48548670830981894
Validation loss: 2.3831509851872434

Epoch: 5| Step: 5
Training loss: 0.5337430574738371
Validation loss: 2.3632075201384786

Epoch: 5| Step: 6
Training loss: 0.4677485576854103
Validation loss: 2.423034752569729

Epoch: 5| Step: 7
Training loss: 0.6629163387528749
Validation loss: 2.3377293755668975

Epoch: 5| Step: 8
Training loss: 0.5833108903336844
Validation loss: 2.3118661634326787

Epoch: 5| Step: 9
Training loss: 0.5464538587512308
Validation loss: 2.383307830630502

Epoch: 5| Step: 10
Training loss: 0.5357715661215858
Validation loss: 2.380687095077293

Epoch: 716| Step: 0
Training loss: 0.5664465791222354
Validation loss: 2.360528099261499

Epoch: 5| Step: 1
Training loss: 0.411153217452648
Validation loss: 2.395702349562997

Epoch: 5| Step: 2
Training loss: 0.45730025370999755
Validation loss: 2.3741101712075205

Epoch: 5| Step: 3
Training loss: 0.6824991235971937
Validation loss: 2.3743471739094386

Epoch: 5| Step: 4
Training loss: 0.32533473099191085
Validation loss: 2.43135581976334

Epoch: 5| Step: 5
Training loss: 0.36164994213589524
Validation loss: 2.3372805173147317

Epoch: 5| Step: 6
Training loss: 0.5266105924202383
Validation loss: 2.3712351177865876

Epoch: 5| Step: 7
Training loss: 0.49978397590324597
Validation loss: 2.336679584727911

Epoch: 5| Step: 8
Training loss: 0.6359929822108717
Validation loss: 2.3990149642386047

Epoch: 5| Step: 9
Training loss: 0.5257601094636669
Validation loss: 2.3687375549219793

Epoch: 5| Step: 10
Training loss: 1.4988542790600317
Validation loss: 2.4330154279830993

Epoch: 717| Step: 0
Training loss: 0.6655251271357185
Validation loss: 2.335419303278781

Epoch: 5| Step: 1
Training loss: 0.5240485766477121
Validation loss: 2.3771872042570497

Epoch: 5| Step: 2
Training loss: 0.4848522941827366
Validation loss: 2.370909918403044

Epoch: 5| Step: 3
Training loss: 1.3701009171621696
Validation loss: 2.349917789086823

Epoch: 5| Step: 4
Training loss: 0.6907512342294939
Validation loss: 2.338723287694845

Epoch: 5| Step: 5
Training loss: 0.7788947270037473
Validation loss: 2.4177304915414863

Epoch: 5| Step: 6
Training loss: 0.5341312588736337
Validation loss: 2.386725793044701

Epoch: 5| Step: 7
Training loss: 0.5862895924958904
Validation loss: 2.4153125761431173

Epoch: 5| Step: 8
Training loss: 0.5949443549895276
Validation loss: 2.390285562482391

Epoch: 5| Step: 9
Training loss: 0.5789140523160797
Validation loss: 2.4058409003358303

Epoch: 5| Step: 10
Training loss: 0.627815319223943
Validation loss: 2.383506685887339

Epoch: 718| Step: 0
Training loss: 0.5004009189187142
Validation loss: 2.4019939006128825

Epoch: 5| Step: 1
Training loss: 0.5148410617601894
Validation loss: 2.3896492254793977

Epoch: 5| Step: 2
Training loss: 0.5720478203214416
Validation loss: 2.3907079492588625

Epoch: 5| Step: 3
Training loss: 0.5485085205000532
Validation loss: 2.4001193576191087

Epoch: 5| Step: 4
Training loss: 0.7070480049634966
Validation loss: 2.3752147240712964

Epoch: 5| Step: 5
Training loss: 0.5423304146830953
Validation loss: 2.3749746052496685

Epoch: 5| Step: 6
Training loss: 0.6522415446548157
Validation loss: 2.4061969399112244

Epoch: 5| Step: 7
Training loss: 1.490084219350929
Validation loss: 2.4009150555611054

Epoch: 5| Step: 8
Training loss: 0.3445300333602772
Validation loss: 2.3453018990019427

Epoch: 5| Step: 9
Training loss: 0.6024939521707614
Validation loss: 2.434572727590191

Epoch: 5| Step: 10
Training loss: 0.47671432890665855
Validation loss: 2.428520101821517

Epoch: 719| Step: 0
Training loss: 0.44501281157278266
Validation loss: 2.365487103829352

Epoch: 5| Step: 1
Training loss: 0.562359421435625
Validation loss: 2.41010589156096

Epoch: 5| Step: 2
Training loss: 0.6093191952706818
Validation loss: 2.403214232463761

Epoch: 5| Step: 3
Training loss: 0.5262812896451249
Validation loss: 2.4037125345708867

Epoch: 5| Step: 4
Training loss: 1.4875081775344334
Validation loss: 2.3348423254220947

Epoch: 5| Step: 5
Training loss: 0.7235550523334933
Validation loss: 2.4125761729184627

Epoch: 5| Step: 6
Training loss: 0.590044985163441
Validation loss: 2.3819993671684925

Epoch: 5| Step: 7
Training loss: 0.6832542012110273
Validation loss: 2.3716051160770966

Epoch: 5| Step: 8
Training loss: 0.5504668129576386
Validation loss: 2.414019268235651

Epoch: 5| Step: 9
Training loss: 0.5595471974869637
Validation loss: 2.3934600526601995

Epoch: 5| Step: 10
Training loss: 0.5273972095660159
Validation loss: 2.337182440624645

Epoch: 720| Step: 0
Training loss: 0.5642320404557981
Validation loss: 2.3996535626706605

Epoch: 5| Step: 1
Training loss: 0.500563750740934
Validation loss: 2.4038876135810687

Epoch: 5| Step: 2
Training loss: 0.5571637823905237
Validation loss: 2.3196572601237175

Epoch: 5| Step: 3
Training loss: 0.5326717090013934
Validation loss: 2.3574740580646028

Epoch: 5| Step: 4
Training loss: 0.5946216459390199
Validation loss: 2.372629145644575

Epoch: 5| Step: 5
Training loss: 0.7379406743925165
Validation loss: 2.3349626554967102

Epoch: 5| Step: 6
Training loss: 0.6127809804526421
Validation loss: 2.3695403250534115

Epoch: 5| Step: 7
Training loss: 0.7281473573845902
Validation loss: 2.380031823014191

Epoch: 5| Step: 8
Training loss: 0.5076766492620252
Validation loss: 2.375206297726621

Epoch: 5| Step: 9
Training loss: 0.5657930409051695
Validation loss: 2.4304277046748024

Epoch: 5| Step: 10
Training loss: 1.500214402452668
Validation loss: 2.4290329335976883

Epoch: 721| Step: 0
Training loss: 0.6188001207801588
Validation loss: 2.304580617588069

Epoch: 5| Step: 1
Training loss: 0.5970442636764256
Validation loss: 2.392156799869153

Epoch: 5| Step: 2
Training loss: 0.6112687932189276
Validation loss: 2.4186948158968806

Epoch: 5| Step: 3
Training loss: 0.6733302834256031
Validation loss: 2.4321676794774523

Epoch: 5| Step: 4
Training loss: 0.5046830806007222
Validation loss: 2.388397888767993

Epoch: 5| Step: 5
Training loss: 0.44464084098980383
Validation loss: 2.308862489819978

Epoch: 5| Step: 6
Training loss: 0.5806672415339971
Validation loss: 2.436276746548855

Epoch: 5| Step: 7
Training loss: 1.4265945414259165
Validation loss: 2.4788866946653623

Epoch: 5| Step: 8
Training loss: 0.43303751277971464
Validation loss: 2.3554827911241976

Epoch: 5| Step: 9
Training loss: 0.48339412186362707
Validation loss: 2.367463128760384

Epoch: 5| Step: 10
Training loss: 0.7482460892151641
Validation loss: 2.4049590288336313

Epoch: 722| Step: 0
Training loss: 0.48667399046016163
Validation loss: 2.3725003395895934

Epoch: 5| Step: 1
Training loss: 0.5044495071628782
Validation loss: 2.40207641191877

Epoch: 5| Step: 2
Training loss: 0.6394324717043856
Validation loss: 2.389131825406201

Epoch: 5| Step: 3
Training loss: 0.48917330318489427
Validation loss: 2.457903912266031

Epoch: 5| Step: 4
Training loss: 0.4607175690274141
Validation loss: 2.301490822329284

Epoch: 5| Step: 5
Training loss: 1.3526487009940096
Validation loss: 2.3764167007986607

Epoch: 5| Step: 6
Training loss: 0.8193796939555366
Validation loss: 2.368096536803334

Epoch: 5| Step: 7
Training loss: 0.6445437805807273
Validation loss: 2.4027726876367366

Epoch: 5| Step: 8
Training loss: 0.4336768233989854
Validation loss: 2.336048721287007

Epoch: 5| Step: 9
Training loss: 0.6029771791666195
Validation loss: 2.3000388728901093

Epoch: 5| Step: 10
Training loss: 0.3371428666435199
Validation loss: 2.4013669259440027

Epoch: 723| Step: 0
Training loss: 0.4802005608592319
Validation loss: 2.349599879204753

Epoch: 5| Step: 1
Training loss: 0.40088689798434374
Validation loss: 2.3448866212169013

Epoch: 5| Step: 2
Training loss: 0.6853146499342622
Validation loss: 2.373245423923137

Epoch: 5| Step: 3
Training loss: 0.5666609092962211
Validation loss: 2.3901764262985505

Epoch: 5| Step: 4
Training loss: 0.6534469322133161
Validation loss: 2.368124148784443

Epoch: 5| Step: 5
Training loss: 0.44201641614773624
Validation loss: 2.4234300483027384

Epoch: 5| Step: 6
Training loss: 0.6660781338798714
Validation loss: 2.37528127786797

Epoch: 5| Step: 7
Training loss: 1.3323052982988024
Validation loss: 2.353954865030548

Epoch: 5| Step: 8
Training loss: 0.39462573742367146
Validation loss: 2.3663494519581016

Epoch: 5| Step: 9
Training loss: 0.44706785002197336
Validation loss: 2.3560763936636215

Epoch: 5| Step: 10
Training loss: 0.6514642920453859
Validation loss: 2.383183382899639

Epoch: 724| Step: 0
Training loss: 0.5183879347108006
Validation loss: 2.403898266387557

Epoch: 5| Step: 1
Training loss: 0.4935748212034084
Validation loss: 2.438980172685887

Epoch: 5| Step: 2
Training loss: 0.5298394663172682
Validation loss: 2.370775770880648

Epoch: 5| Step: 3
Training loss: 0.6543685190632242
Validation loss: 2.399586445545712

Epoch: 5| Step: 4
Training loss: 0.44810378986106153
Validation loss: 2.349612142008377

Epoch: 5| Step: 5
Training loss: 0.5512448247030827
Validation loss: 2.420885410770261

Epoch: 5| Step: 6
Training loss: 0.4533450973289823
Validation loss: 2.357989608510602

Epoch: 5| Step: 7
Training loss: 0.43131437097643066
Validation loss: 2.378085842675026

Epoch: 5| Step: 8
Training loss: 0.6078547073262314
Validation loss: 2.3684930955212185

Epoch: 5| Step: 9
Training loss: 0.6036977894245095
Validation loss: 2.3831897455124853

Epoch: 5| Step: 10
Training loss: 1.5098912432327671
Validation loss: 2.3852776154028867

Epoch: 725| Step: 0
Training loss: 0.6458006871083639
Validation loss: 2.4496840942800016

Epoch: 5| Step: 1
Training loss: 0.471492674974963
Validation loss: 2.3744957307050223

Epoch: 5| Step: 2
Training loss: 0.748700048471263
Validation loss: 2.4031050113448504

Epoch: 5| Step: 3
Training loss: 1.322391340626971
Validation loss: 2.4178273833267543

Epoch: 5| Step: 4
Training loss: 0.4928056075171104
Validation loss: 2.3900352510370433

Epoch: 5| Step: 5
Training loss: 0.49796185235236745
Validation loss: 2.4048400634773697

Epoch: 5| Step: 6
Training loss: 0.5731427497985578
Validation loss: 2.4050584966619093

Epoch: 5| Step: 7
Training loss: 0.6276872561419259
Validation loss: 2.3502063104948943

Epoch: 5| Step: 8
Training loss: 0.3437447439138677
Validation loss: 2.4050977169579553

Epoch: 5| Step: 9
Training loss: 0.3632327221688292
Validation loss: 2.4554036571442124

Epoch: 5| Step: 10
Training loss: 0.6697544522623391
Validation loss: 2.376397262107825

Epoch: 726| Step: 0
Training loss: 0.5419348059169221
Validation loss: 2.40056340353811

Epoch: 5| Step: 1
Training loss: 1.3371081660647197
Validation loss: 2.385930127297945

Epoch: 5| Step: 2
Training loss: 0.5831829938844263
Validation loss: 2.3467622368213403

Epoch: 5| Step: 3
Training loss: 0.5408803998052983
Validation loss: 2.4097768046407735

Epoch: 5| Step: 4
Training loss: 0.4834461535398721
Validation loss: 2.3650189149813827

Epoch: 5| Step: 5
Training loss: 0.53520650697275
Validation loss: 2.357706994611801

Epoch: 5| Step: 6
Training loss: 0.39379093850469116
Validation loss: 2.386615689522034

Epoch: 5| Step: 7
Training loss: 0.5668967918068355
Validation loss: 2.475259743803286

Epoch: 5| Step: 8
Training loss: 0.5393551294815071
Validation loss: 2.4921993389446997

Epoch: 5| Step: 9
Training loss: 0.4718759416735013
Validation loss: 2.415752708713082

Epoch: 5| Step: 10
Training loss: 0.2856965237763179
Validation loss: 2.4157630234662353

Epoch: 727| Step: 0
Training loss: 0.6172253560878344
Validation loss: 2.464200578969796

Epoch: 5| Step: 1
Training loss: 1.3920526783884901
Validation loss: 2.353593461578317

Epoch: 5| Step: 2
Training loss: 0.6481889455181641
Validation loss: 2.3599044419285105

Epoch: 5| Step: 3
Training loss: 0.5200155768445598
Validation loss: 2.3440110562322864

Epoch: 5| Step: 4
Training loss: 0.5581998703516691
Validation loss: 2.39974939065895

Epoch: 5| Step: 5
Training loss: 0.46912823358158773
Validation loss: 2.3459597276952815

Epoch: 5| Step: 6
Training loss: 0.5122900241930449
Validation loss: 2.3469356290625454

Epoch: 5| Step: 7
Training loss: 0.5872239296145576
Validation loss: 2.427574257702781

Epoch: 5| Step: 8
Training loss: 0.4325632272655523
Validation loss: 2.3579843616072957

Epoch: 5| Step: 9
Training loss: 0.4265679257784899
Validation loss: 2.409795230449324

Epoch: 5| Step: 10
Training loss: 0.5766533601701168
Validation loss: 2.3976005292847398

Epoch: 728| Step: 0
Training loss: 0.46909837492826206
Validation loss: 2.40619152431128

Epoch: 5| Step: 1
Training loss: 0.591418104166333
Validation loss: 2.3598872063874343

Epoch: 5| Step: 2
Training loss: 0.5137463939846484
Validation loss: 2.3569991263214813

Epoch: 5| Step: 3
Training loss: 0.44222590208951973
Validation loss: 2.43538922192717

Epoch: 5| Step: 4
Training loss: 0.4194397931423492
Validation loss: 2.4140855587837247

Epoch: 5| Step: 5
Training loss: 0.46828997609278844
Validation loss: 2.3507085657475417

Epoch: 5| Step: 6
Training loss: 0.6969148410647161
Validation loss: 2.3375250275132813

Epoch: 5| Step: 7
Training loss: 1.3787109841907266
Validation loss: 2.4100457244887115

Epoch: 5| Step: 8
Training loss: 0.6476332491297973
Validation loss: 2.363456346558947

Epoch: 5| Step: 9
Training loss: 0.6378797933169273
Validation loss: 2.3880683234959394

Epoch: 5| Step: 10
Training loss: 0.6945112090335667
Validation loss: 2.4053239733185405

Epoch: 729| Step: 0
Training loss: 0.44767625773990216
Validation loss: 2.397170961334859

Epoch: 5| Step: 1
Training loss: 0.592318691930138
Validation loss: 2.426760127083649

Epoch: 5| Step: 2
Training loss: 0.6536843692519652
Validation loss: 2.331347559547751

Epoch: 5| Step: 3
Training loss: 0.5086527401982973
Validation loss: 2.318870567900067

Epoch: 5| Step: 4
Training loss: 0.6833925441543436
Validation loss: 2.3838999955827798

Epoch: 5| Step: 5
Training loss: 0.6012960066611518
Validation loss: 2.406450904329345

Epoch: 5| Step: 6
Training loss: 0.623482363623509
Validation loss: 2.416718815151418

Epoch: 5| Step: 7
Training loss: 0.4429449253302278
Validation loss: 2.432422240150008

Epoch: 5| Step: 8
Training loss: 0.39154314856421163
Validation loss: 2.4518231470485006

Epoch: 5| Step: 9
Training loss: 1.3765326541085572
Validation loss: 2.416098704727482

Epoch: 5| Step: 10
Training loss: 0.4221262889850288
Validation loss: 2.420517024231549

Epoch: 730| Step: 0
Training loss: 1.361910242654949
Validation loss: 2.327267057259642

Epoch: 5| Step: 1
Training loss: 0.4240396384961948
Validation loss: 2.377232231705257

Epoch: 5| Step: 2
Training loss: 0.5345147736437302
Validation loss: 2.3986459788218397

Epoch: 5| Step: 3
Training loss: 0.571457614650221
Validation loss: 2.404683253330701

Epoch: 5| Step: 4
Training loss: 0.5794319381224741
Validation loss: 2.3559416420023944

Epoch: 5| Step: 5
Training loss: 0.5258108394283262
Validation loss: 2.3796501123496205

Epoch: 5| Step: 6
Training loss: 0.6364718233376044
Validation loss: 2.421098695967347

Epoch: 5| Step: 7
Training loss: 0.5318497470011265
Validation loss: 2.375989461718404

Epoch: 5| Step: 8
Training loss: 0.5841811751152542
Validation loss: 2.395592699811442

Epoch: 5| Step: 9
Training loss: 0.5074375235337544
Validation loss: 2.384647354593331

Epoch: 5| Step: 10
Training loss: 0.5690812969507422
Validation loss: 2.4261936654027596

Epoch: 731| Step: 0
Training loss: 0.5679263008552474
Validation loss: 2.33098164905673

Epoch: 5| Step: 1
Training loss: 0.43940403982053855
Validation loss: 2.362487855050883

Epoch: 5| Step: 2
Training loss: 0.48834150324042397
Validation loss: 2.378890558211217

Epoch: 5| Step: 3
Training loss: 0.6249408217070107
Validation loss: 2.3840993756621707

Epoch: 5| Step: 4
Training loss: 0.4785300272117152
Validation loss: 2.3415782445682622

Epoch: 5| Step: 5
Training loss: 0.44091590720335816
Validation loss: 2.2894505350358143

Epoch: 5| Step: 6
Training loss: 0.6625378552903708
Validation loss: 2.4617035628750825

Epoch: 5| Step: 7
Training loss: 0.44830423229044114
Validation loss: 2.360584204785088

Epoch: 5| Step: 8
Training loss: 1.3211269236888192
Validation loss: 2.3816278803500155

Epoch: 5| Step: 9
Training loss: 0.37864272795413423
Validation loss: 2.3208247771388644

Epoch: 5| Step: 10
Training loss: 0.5715101287107774
Validation loss: 2.3577548073998496

Epoch: 732| Step: 0
Training loss: 0.617519579048033
Validation loss: 2.3587364528464416

Epoch: 5| Step: 1
Training loss: 1.3501985757093866
Validation loss: 2.3934402237962065

Epoch: 5| Step: 2
Training loss: 0.587471644752116
Validation loss: 2.446811108175477

Epoch: 5| Step: 3
Training loss: 0.3839051942108256
Validation loss: 2.42273572167924

Epoch: 5| Step: 4
Training loss: 0.4273310113713347
Validation loss: 2.347717683478456

Epoch: 5| Step: 5
Training loss: 0.6566137032603688
Validation loss: 2.3711686115171706

Epoch: 5| Step: 6
Training loss: 0.38755503694324495
Validation loss: 2.3365749085274325

Epoch: 5| Step: 7
Training loss: 0.4124112763499973
Validation loss: 2.376937792416267

Epoch: 5| Step: 8
Training loss: 0.5521672442984253
Validation loss: 2.350715906444056

Epoch: 5| Step: 9
Training loss: 0.7384301898221549
Validation loss: 2.4268063063162932

Epoch: 5| Step: 10
Training loss: 0.512703392328446
Validation loss: 2.336045175500866

Epoch: 733| Step: 0
Training loss: 0.4380266051605757
Validation loss: 2.369651075373701

Epoch: 5| Step: 1
Training loss: 0.3889944568560252
Validation loss: 2.293787725482109

Epoch: 5| Step: 2
Training loss: 0.40211856429096743
Validation loss: 2.3781564383782627

Epoch: 5| Step: 3
Training loss: 0.5315102052166406
Validation loss: 2.4201691689759253

Epoch: 5| Step: 4
Training loss: 0.5287667466616134
Validation loss: 2.429045724680282

Epoch: 5| Step: 5
Training loss: 0.4281648011745432
Validation loss: 2.3694574191803137

Epoch: 5| Step: 6
Training loss: 0.5710843754741282
Validation loss: 2.4228817120654544

Epoch: 5| Step: 7
Training loss: 1.427814862321756
Validation loss: 2.398651066507768

Epoch: 5| Step: 8
Training loss: 0.6197025625040168
Validation loss: 2.390338859937486

Epoch: 5| Step: 9
Training loss: 0.4989287852123874
Validation loss: 2.4138932811763922

Epoch: 5| Step: 10
Training loss: 0.6235702851272035
Validation loss: 2.4525169223472814

Epoch: 734| Step: 0
Training loss: 0.45680782366974015
Validation loss: 2.414237812803718

Epoch: 5| Step: 1
Training loss: 0.6062704869377665
Validation loss: 2.3795716607371604

Epoch: 5| Step: 2
Training loss: 0.42675690465346083
Validation loss: 2.406390369946477

Epoch: 5| Step: 3
Training loss: 0.37814508258674373
Validation loss: 2.4149670471125386

Epoch: 5| Step: 4
Training loss: 0.34704276401152245
Validation loss: 2.3456441475968894

Epoch: 5| Step: 5
Training loss: 0.590662861170612
Validation loss: 2.4380037256854217

Epoch: 5| Step: 6
Training loss: 0.5775666762746826
Validation loss: 2.4549138178170757

Epoch: 5| Step: 7
Training loss: 0.4093366153572004
Validation loss: 2.4199761638825144

Epoch: 5| Step: 8
Training loss: 0.690713136322332
Validation loss: 2.46379946753557

Epoch: 5| Step: 9
Training loss: 1.3874790739938654
Validation loss: 2.4105950736833393

Epoch: 5| Step: 10
Training loss: 0.6300771960389395
Validation loss: 2.4854911143702507

Epoch: 735| Step: 0
Training loss: 0.5062288974555224
Validation loss: 2.3367376331407534

Epoch: 5| Step: 1
Training loss: 0.49765217418588564
Validation loss: 2.3882274075149086

Epoch: 5| Step: 2
Training loss: 0.5855234590598316
Validation loss: 2.3840020110053075

Epoch: 5| Step: 3
Training loss: 0.5738118345312646
Validation loss: 2.4290606966890858

Epoch: 5| Step: 4
Training loss: 0.42441700751331324
Validation loss: 2.3457112004925236

Epoch: 5| Step: 5
Training loss: 0.48368823679843126
Validation loss: 2.4183697694726622

Epoch: 5| Step: 6
Training loss: 0.6335342200520138
Validation loss: 2.388179394873001

Epoch: 5| Step: 7
Training loss: 1.3954925643055809
Validation loss: 2.3985672376171916

Epoch: 5| Step: 8
Training loss: 0.5134438998751621
Validation loss: 2.3542028023787487

Epoch: 5| Step: 9
Training loss: 0.47444314753648975
Validation loss: 2.4146761054826658

Epoch: 5| Step: 10
Training loss: 0.5873198161889874
Validation loss: 2.3184151154710624

Epoch: 736| Step: 0
Training loss: 0.5695929495170177
Validation loss: 2.3715878366638545

Epoch: 5| Step: 1
Training loss: 0.6168376558821145
Validation loss: 2.3701992098716627

Epoch: 5| Step: 2
Training loss: 0.5981979408552669
Validation loss: 2.4127834935610957

Epoch: 5| Step: 3
Training loss: 0.46609078158572453
Validation loss: 2.3755787649940396

Epoch: 5| Step: 4
Training loss: 0.5081803676661605
Validation loss: 2.337762239354876

Epoch: 5| Step: 5
Training loss: 0.630477293540425
Validation loss: 2.371016017182068

Epoch: 5| Step: 6
Training loss: 0.5237660871233821
Validation loss: 2.32020168620577

Epoch: 5| Step: 7
Training loss: 0.6587624592842418
Validation loss: 2.406023555819209

Epoch: 5| Step: 8
Training loss: 0.5741275273738142
Validation loss: 2.4008420110640514

Epoch: 5| Step: 9
Training loss: 0.595630303606436
Validation loss: 2.3725037498500243

Epoch: 5| Step: 10
Training loss: 1.4081875063470495
Validation loss: 2.397359489451717

Epoch: 737| Step: 0
Training loss: 0.5880167119366332
Validation loss: 2.4512636114006137

Epoch: 5| Step: 1
Training loss: 0.5055029950340887
Validation loss: 2.3731623601367224

Epoch: 5| Step: 2
Training loss: 0.6635841666424016
Validation loss: 2.3812500881084917

Epoch: 5| Step: 3
Training loss: 0.4319902100480278
Validation loss: 2.417651788959473

Epoch: 5| Step: 4
Training loss: 0.39707388062382076
Validation loss: 2.3611121684568075

Epoch: 5| Step: 5
Training loss: 0.6252184009429953
Validation loss: 2.4473012892084114

Epoch: 5| Step: 6
Training loss: 1.3681730369475023
Validation loss: 2.4044109274213508

Epoch: 5| Step: 7
Training loss: 0.5796688704054834
Validation loss: 2.4317515110444967

Epoch: 5| Step: 8
Training loss: 0.3976250387058041
Validation loss: 2.48620161569805

Epoch: 5| Step: 9
Training loss: 0.4764062594085022
Validation loss: 2.451513390796336

Epoch: 5| Step: 10
Training loss: 0.6444487316598279
Validation loss: 2.428192191335169

Epoch: 738| Step: 0
Training loss: 0.46053930637135926
Validation loss: 2.380738423610756

Epoch: 5| Step: 1
Training loss: 0.43151002522068843
Validation loss: 2.367714119003686

Epoch: 5| Step: 2
Training loss: 0.6880241476744862
Validation loss: 2.418150939974446

Epoch: 5| Step: 3
Training loss: 0.560158997426551
Validation loss: 2.3912742832751683

Epoch: 5| Step: 4
Training loss: 1.3337278328852666
Validation loss: 2.4025425139500207

Epoch: 5| Step: 5
Training loss: 0.48209538396359497
Validation loss: 2.4198043308567008

Epoch: 5| Step: 6
Training loss: 0.5987126855631191
Validation loss: 2.399450838076101

Epoch: 5| Step: 7
Training loss: 0.5942975330512118
Validation loss: 2.3894974324641436

Epoch: 5| Step: 8
Training loss: 0.34431480477019216
Validation loss: 2.392289722196924

Epoch: 5| Step: 9
Training loss: 0.5113286868588455
Validation loss: 2.371968793383838

Epoch: 5| Step: 10
Training loss: 0.26236575133791584
Validation loss: 2.4279541822149646

Epoch: 739| Step: 0
Training loss: 0.5782816906535405
Validation loss: 2.3707289273759984

Epoch: 5| Step: 1
Training loss: 0.4242097217870689
Validation loss: 2.364244195418291

Epoch: 5| Step: 2
Training loss: 0.5203926574548221
Validation loss: 2.4572958758484362

Epoch: 5| Step: 3
Training loss: 0.41815634109659144
Validation loss: 2.419322638519557

Epoch: 5| Step: 4
Training loss: 1.4448609342612346
Validation loss: 2.3560220752144767

Epoch: 5| Step: 5
Training loss: 0.6507761044888446
Validation loss: 2.347389305796237

Epoch: 5| Step: 6
Training loss: 0.500816274956487
Validation loss: 2.415674400156115

Epoch: 5| Step: 7
Training loss: 0.3820147278690254
Validation loss: 2.3282011099084996

Epoch: 5| Step: 8
Training loss: 0.6719419312961248
Validation loss: 2.3657868313908477

Epoch: 5| Step: 9
Training loss: 0.5816707646827656
Validation loss: 2.4045735594652022

Epoch: 5| Step: 10
Training loss: 0.47496458975662026
Validation loss: 2.3785803037938456

Epoch: 740| Step: 0
Training loss: 0.5023714986348348
Validation loss: 2.406823635244878

Epoch: 5| Step: 1
Training loss: 0.4505452845852773
Validation loss: 2.395725113688159

Epoch: 5| Step: 2
Training loss: 0.49162776848377
Validation loss: 2.422700238688519

Epoch: 5| Step: 3
Training loss: 0.6418761619401349
Validation loss: 2.373434112943254

Epoch: 5| Step: 4
Training loss: 0.5222031572369931
Validation loss: 2.363905187428782

Epoch: 5| Step: 5
Training loss: 0.5703564718356656
Validation loss: 2.387951951023079

Epoch: 5| Step: 6
Training loss: 0.633048190271225
Validation loss: 2.386715890670446

Epoch: 5| Step: 7
Training loss: 0.4562823525807279
Validation loss: 2.356678309936255

Epoch: 5| Step: 8
Training loss: 0.36008933846279845
Validation loss: 2.3470817789751734

Epoch: 5| Step: 9
Training loss: 0.47776283684676213
Validation loss: 2.4095514366658572

Epoch: 5| Step: 10
Training loss: 1.4487351590071953
Validation loss: 2.344977462000457

Epoch: 741| Step: 0
Training loss: 0.6659328151915805
Validation loss: 2.367816512384184

Epoch: 5| Step: 1
Training loss: 0.48666685632915374
Validation loss: 2.4081439696359723

Epoch: 5| Step: 2
Training loss: 0.5533925643160104
Validation loss: 2.406116038123821

Epoch: 5| Step: 3
Training loss: 1.3279922418999701
Validation loss: 2.4216357390490026

Epoch: 5| Step: 4
Training loss: 0.6286856933910618
Validation loss: 2.3394744533408685

Epoch: 5| Step: 5
Training loss: 0.45120183011311166
Validation loss: 2.3835674992078553

Epoch: 5| Step: 6
Training loss: 0.38356137498401877
Validation loss: 2.443967369895815

Epoch: 5| Step: 7
Training loss: 0.5161926728162729
Validation loss: 2.3604160471280933

Epoch: 5| Step: 8
Training loss: 0.3532520280922879
Validation loss: 2.439350542669118

Epoch: 5| Step: 9
Training loss: 0.6972632314603525
Validation loss: 2.359227798021738

Epoch: 5| Step: 10
Training loss: 0.38341439865398846
Validation loss: 2.3919245081807468

Epoch: 742| Step: 0
Training loss: 0.4415337707503733
Validation loss: 2.425723285301869

Epoch: 5| Step: 1
Training loss: 0.6224131934220183
Validation loss: 2.3934577559479293

Epoch: 5| Step: 2
Training loss: 0.40182235414470163
Validation loss: 2.3941629037450958

Epoch: 5| Step: 3
Training loss: 0.5623170237166847
Validation loss: 2.421435589578777

Epoch: 5| Step: 4
Training loss: 0.407209181014417
Validation loss: 2.349150020075041

Epoch: 5| Step: 5
Training loss: 0.5056277890122569
Validation loss: 2.4010899274895947

Epoch: 5| Step: 6
Training loss: 0.59001142127087
Validation loss: 2.3423079519225816

Epoch: 5| Step: 7
Training loss: 1.3620871749657273
Validation loss: 2.410417321476676

Epoch: 5| Step: 8
Training loss: 0.5802753768164328
Validation loss: 2.3378726599654285

Epoch: 5| Step: 9
Training loss: 0.4715144181812989
Validation loss: 2.364947583478957

Epoch: 5| Step: 10
Training loss: 0.6018609879349125
Validation loss: 2.386846952286532

Epoch: 743| Step: 0
Training loss: 0.5357701198682254
Validation loss: 2.4269732378528492

Epoch: 5| Step: 1
Training loss: 0.5042250460198218
Validation loss: 2.398091093898972

Epoch: 5| Step: 2
Training loss: 0.6457031000763876
Validation loss: 2.4033404209254954

Epoch: 5| Step: 3
Training loss: 0.4801805764021523
Validation loss: 2.3701715344528065

Epoch: 5| Step: 4
Training loss: 1.4209253682209466
Validation loss: 2.43249936824467

Epoch: 5| Step: 5
Training loss: 0.4976486259367508
Validation loss: 2.3545871483974055

Epoch: 5| Step: 6
Training loss: 0.48159617445517844
Validation loss: 2.3409346775545714

Epoch: 5| Step: 7
Training loss: 0.7745696749687697
Validation loss: 2.3821023066589957

Epoch: 5| Step: 8
Training loss: 0.5792887033103524
Validation loss: 2.4052456551108157

Epoch: 5| Step: 9
Training loss: 0.4349491996534566
Validation loss: 2.377985760858823

Epoch: 5| Step: 10
Training loss: 0.6549475779194395
Validation loss: 2.349918179646559

Epoch: 744| Step: 0
Training loss: 0.434950210308827
Validation loss: 2.429848907652039

Epoch: 5| Step: 1
Training loss: 0.5176374293486071
Validation loss: 2.3351834732902903

Epoch: 5| Step: 2
Training loss: 0.4834150369279458
Validation loss: 2.3479400354591227

Epoch: 5| Step: 3
Training loss: 0.5748468713450111
Validation loss: 2.3698818647132955

Epoch: 5| Step: 4
Training loss: 0.5346534204463342
Validation loss: 2.4721195916618934

Epoch: 5| Step: 5
Training loss: 0.5142860946672789
Validation loss: 2.363197475281769

Epoch: 5| Step: 6
Training loss: 0.49087754267710854
Validation loss: 2.3662286288777135

Epoch: 5| Step: 7
Training loss: 0.5094001014937025
Validation loss: 2.3674591914635417

Epoch: 5| Step: 8
Training loss: 0.6829541511170982
Validation loss: 2.343338108854612

Epoch: 5| Step: 9
Training loss: 1.4094265558324441
Validation loss: 2.344215665107976

Epoch: 5| Step: 10
Training loss: 0.5161761603762828
Validation loss: 2.3879423559455053

Epoch: 745| Step: 0
Training loss: 0.3506820355738986
Validation loss: 2.3302699777147784

Epoch: 5| Step: 1
Training loss: 1.423684697717516
Validation loss: 2.389904697874685

Epoch: 5| Step: 2
Training loss: 0.6053752703952598
Validation loss: 2.381340821760342

Epoch: 5| Step: 3
Training loss: 0.3358880494560179
Validation loss: 2.323810320697266

Epoch: 5| Step: 4
Training loss: 0.5176926971878382
Validation loss: 2.4263032281565198

Epoch: 5| Step: 5
Training loss: 0.5474346566943558
Validation loss: 2.3562644296594173

Epoch: 5| Step: 6
Training loss: 0.5905277252826875
Validation loss: 2.3860941006165954

Epoch: 5| Step: 7
Training loss: 0.4884186818310666
Validation loss: 2.368670150558638

Epoch: 5| Step: 8
Training loss: 0.41729830509808746
Validation loss: 2.396158825636108

Epoch: 5| Step: 9
Training loss: 0.49224663939232166
Validation loss: 2.361037699285811

Epoch: 5| Step: 10
Training loss: 0.5333432582835748
Validation loss: 2.486998304205276

Epoch: 746| Step: 0
Training loss: 0.43540398002771474
Validation loss: 2.3642273330836567

Epoch: 5| Step: 1
Training loss: 1.3640070953128662
Validation loss: 2.4202030376787276

Epoch: 5| Step: 2
Training loss: 0.36435139862625504
Validation loss: 2.381987219707363

Epoch: 5| Step: 3
Training loss: 0.4459605604383037
Validation loss: 2.3281825911132388

Epoch: 5| Step: 4
Training loss: 0.4450918956231316
Validation loss: 2.3582720999437545

Epoch: 5| Step: 5
Training loss: 0.7276112770237402
Validation loss: 2.420035312334441

Epoch: 5| Step: 6
Training loss: 0.6977099330705687
Validation loss: 2.3389383673816417

Epoch: 5| Step: 7
Training loss: 0.5582490404277093
Validation loss: 2.384607134621068

Epoch: 5| Step: 8
Training loss: 0.5435736600448009
Validation loss: 2.4132169862382287

Epoch: 5| Step: 9
Training loss: 0.6337880515162512
Validation loss: 2.360441118456606

Epoch: 5| Step: 10
Training loss: 0.6184009742841411
Validation loss: 2.385138144010789

Epoch: 747| Step: 0
Training loss: 0.5814781889560152
Validation loss: 2.4124617594661952

Epoch: 5| Step: 1
Training loss: 0.46017799196545683
Validation loss: 2.4714239605029857

Epoch: 5| Step: 2
Training loss: 0.6073377986505475
Validation loss: 2.440025898212467

Epoch: 5| Step: 3
Training loss: 0.5497406673255062
Validation loss: 2.3958918570120353

Epoch: 5| Step: 4
Training loss: 0.6672960206516108
Validation loss: 2.3721594411696416

Epoch: 5| Step: 5
Training loss: 1.293105703055948
Validation loss: 2.342116349729754

Epoch: 5| Step: 6
Training loss: 0.5881627615745595
Validation loss: 2.3755815114664958

Epoch: 5| Step: 7
Training loss: 0.5409056073091905
Validation loss: 2.366384703590624

Epoch: 5| Step: 8
Training loss: 0.47204831332113584
Validation loss: 2.4592448585641806

Epoch: 5| Step: 9
Training loss: 0.5358210423228119
Validation loss: 2.2932946278114397

Epoch: 5| Step: 10
Training loss: 0.4675197988795345
Validation loss: 2.415322890918416

Epoch: 748| Step: 0
Training loss: 0.5349930841676301
Validation loss: 2.315847047446812

Epoch: 5| Step: 1
Training loss: 0.3687096961673727
Validation loss: 2.3055105061838517

Epoch: 5| Step: 2
Training loss: 0.4645358115497377
Validation loss: 2.429654049980243

Epoch: 5| Step: 3
Training loss: 0.37312653574795224
Validation loss: 2.3580018070264157

Epoch: 5| Step: 4
Training loss: 0.6958835913921118
Validation loss: 2.3269171325092084

Epoch: 5| Step: 5
Training loss: 0.4933207196989047
Validation loss: 2.439744010532288

Epoch: 5| Step: 6
Training loss: 0.340126336656921
Validation loss: 2.3597946407719106

Epoch: 5| Step: 7
Training loss: 0.48520598348613897
Validation loss: 2.423176866802808

Epoch: 5| Step: 8
Training loss: 1.406173237718818
Validation loss: 2.3599799992105055

Epoch: 5| Step: 9
Training loss: 0.3956195438002742
Validation loss: 2.331012826307205

Epoch: 5| Step: 10
Training loss: 0.4716267368457559
Validation loss: 2.4067287387000924

Epoch: 749| Step: 0
Training loss: 0.32649388664796414
Validation loss: 2.3712536446951162

Epoch: 5| Step: 1
Training loss: 0.43621678857166296
Validation loss: 2.323945008272956

Epoch: 5| Step: 2
Training loss: 0.4933827736713057
Validation loss: 2.331962936917039

Epoch: 5| Step: 3
Training loss: 0.5367853470398497
Validation loss: 2.375805863800838

Epoch: 5| Step: 4
Training loss: 0.4147223846434945
Validation loss: 2.4211338016512114

Epoch: 5| Step: 5
Training loss: 0.7415657249795304
Validation loss: 2.402182366110836

Epoch: 5| Step: 6
Training loss: 0.37757711203984073
Validation loss: 2.3275445419727925

Epoch: 5| Step: 7
Training loss: 0.42731866710632077
Validation loss: 2.3090979348616187

Epoch: 5| Step: 8
Training loss: 1.2901583088722908
Validation loss: 2.3857618498521562

Epoch: 5| Step: 9
Training loss: 0.41373695315509257
Validation loss: 2.3895622956775613

Epoch: 5| Step: 10
Training loss: 0.5889935713694052
Validation loss: 2.400484469717897

Epoch: 750| Step: 0
Training loss: 0.35749511802114275
Validation loss: 2.352203036611628

Epoch: 5| Step: 1
Training loss: 0.6252481921450879
Validation loss: 2.36450186733608

Epoch: 5| Step: 2
Training loss: 0.5519213138816462
Validation loss: 2.400312762621028

Epoch: 5| Step: 3
Training loss: 0.47787465354294206
Validation loss: 2.3535351753401503

Epoch: 5| Step: 4
Training loss: 0.5738946168521772
Validation loss: 2.371373961478063

Epoch: 5| Step: 5
Training loss: 0.641924261637606
Validation loss: 2.384581657804526

Epoch: 5| Step: 6
Training loss: 1.3306287614402805
Validation loss: 2.3323871991349576

Epoch: 5| Step: 7
Training loss: 0.2983740804104324
Validation loss: 2.3740919889231256

Epoch: 5| Step: 8
Training loss: 0.529053128695198
Validation loss: 2.374662159377773

Epoch: 5| Step: 9
Training loss: 0.5004602936153224
Validation loss: 2.402852685221357

Epoch: 5| Step: 10
Training loss: 0.5430087067975604
Validation loss: 2.430302478566703

Testing loss: 2.930248472406904
