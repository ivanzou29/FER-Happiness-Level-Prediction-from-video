Epoch: 1| Step: 0
Training loss: 4.897670752765056
Validation loss: 4.871235540691907

Epoch: 6| Step: 1
Training loss: 6.527964956787895
Validation loss: 4.865755966132851

Epoch: 6| Step: 2
Training loss: 4.855873342706763
Validation loss: 4.859266358191062

Epoch: 6| Step: 3
Training loss: 5.73772446935034
Validation loss: 4.8551921818349655

Epoch: 6| Step: 4
Training loss: 5.0580505786446945
Validation loss: 4.847319243712465

Epoch: 6| Step: 5
Training loss: 4.8543836466001435
Validation loss: 4.843892406919979

Epoch: 6| Step: 6
Training loss: 4.290295255233047
Validation loss: 4.837730670455498

Epoch: 6| Step: 7
Training loss: 4.615281074536269
Validation loss: 4.833145659172612

Epoch: 6| Step: 8
Training loss: 4.316510312306124
Validation loss: 4.826635743586402

Epoch: 6| Step: 9
Training loss: 4.637186645450149
Validation loss: 4.824109911644739

Epoch: 6| Step: 10
Training loss: 4.4034274103672955
Validation loss: 4.81910436924424

Epoch: 6| Step: 11
Training loss: 4.480273773819955
Validation loss: 4.815165535434425

Epoch: 6| Step: 12
Training loss: 5.290846913838448
Validation loss: 4.809945402134201

Epoch: 6| Step: 13
Training loss: 4.1306508978864285
Validation loss: 4.8077729620088245

Epoch: 2| Step: 0
Training loss: 4.217419449828994
Validation loss: 4.799538431996906

Epoch: 6| Step: 1
Training loss: 4.953410721007909
Validation loss: 4.797472732540754

Epoch: 6| Step: 2
Training loss: 4.223863907153301
Validation loss: 4.793579793252005

Epoch: 6| Step: 3
Training loss: 3.582117510207279
Validation loss: 4.787957703580454

Epoch: 6| Step: 4
Training loss: 4.487169411895954
Validation loss: 4.782234186577943

Epoch: 6| Step: 5
Training loss: 4.58889701007148
Validation loss: 4.778934066657627

Epoch: 6| Step: 6
Training loss: 5.79239845684087
Validation loss: 4.774007037254766

Epoch: 6| Step: 7
Training loss: 4.983364660532455
Validation loss: 4.769406126100311

Epoch: 6| Step: 8
Training loss: 5.4046774986242925
Validation loss: 4.768127423474384

Epoch: 6| Step: 9
Training loss: 4.54799551773857
Validation loss: 4.7607291418779765

Epoch: 6| Step: 10
Training loss: 5.324205495099972
Validation loss: 4.757339058214508

Epoch: 6| Step: 11
Training loss: 4.877380376822169
Validation loss: 4.750437113538449

Epoch: 6| Step: 12
Training loss: 5.412124881563855
Validation loss: 4.7482285685697

Epoch: 6| Step: 13
Training loss: 5.406121048464362
Validation loss: 4.7455707985245414

Epoch: 3| Step: 0
Training loss: 5.476572948233614
Validation loss: 4.735895590146201

Epoch: 6| Step: 1
Training loss: 3.766544973607511
Validation loss: 4.732219840010837

Epoch: 6| Step: 2
Training loss: 5.333411136695477
Validation loss: 4.7301129277187215

Epoch: 6| Step: 3
Training loss: 5.117635320039999
Validation loss: 4.723703977517071

Epoch: 6| Step: 4
Training loss: 3.848728336522287
Validation loss: 4.719625883815844

Epoch: 6| Step: 5
Training loss: 4.846948170801352
Validation loss: 4.712285387541235

Epoch: 6| Step: 6
Training loss: 5.097342692703275
Validation loss: 4.70961626204614

Epoch: 6| Step: 7
Training loss: 4.369720761523716
Validation loss: 4.70512713768852

Epoch: 6| Step: 8
Training loss: 3.9203226733237244
Validation loss: 4.6968377675294395

Epoch: 6| Step: 9
Training loss: 5.910315350737727
Validation loss: 4.695374433463787

Epoch: 6| Step: 10
Training loss: 5.645568878999644
Validation loss: 4.690544717967435

Epoch: 6| Step: 11
Training loss: 3.7690037175395767
Validation loss: 4.6870379782875675

Epoch: 6| Step: 12
Training loss: 4.344250986312839
Validation loss: 4.681781810255051

Epoch: 6| Step: 13
Training loss: 5.188612117823852
Validation loss: 4.67542863519026

Epoch: 4| Step: 0
Training loss: 4.79312613554506
Validation loss: 4.672361791853051

Epoch: 6| Step: 1
Training loss: 5.2672933318336375
Validation loss: 4.666976590273582

Epoch: 6| Step: 2
Training loss: 4.402121483269947
Validation loss: 4.6587568693524375

Epoch: 6| Step: 3
Training loss: 5.015616063380376
Validation loss: 4.6572434342244255

Epoch: 6| Step: 4
Training loss: 4.476894186623975
Validation loss: 4.651974909192292

Epoch: 6| Step: 5
Training loss: 3.981243862943845
Validation loss: 4.65147483081953

Epoch: 6| Step: 6
Training loss: 4.4451215599095875
Validation loss: 4.64397337160472

Epoch: 6| Step: 7
Training loss: 3.7058571824430904
Validation loss: 4.639948691528905

Epoch: 6| Step: 8
Training loss: 4.353964014524064
Validation loss: 4.631931312641102

Epoch: 6| Step: 9
Training loss: 4.167916809730841
Validation loss: 4.625741018471319

Epoch: 6| Step: 10
Training loss: 5.573872802093354
Validation loss: 4.624802944128245

Epoch: 6| Step: 11
Training loss: 5.543880718285622
Validation loss: 4.618606653833295

Epoch: 6| Step: 12
Training loss: 4.766066033639454
Validation loss: 4.612762898015174

Epoch: 6| Step: 13
Training loss: 5.7390098031374555
Validation loss: 4.60759913219311

Epoch: 5| Step: 0
Training loss: 4.571308985917115
Validation loss: 4.602385218287906

Epoch: 6| Step: 1
Training loss: 4.476819415484326
Validation loss: 4.591860807613039

Epoch: 6| Step: 2
Training loss: 4.991314401227827
Validation loss: 4.592119233423144

Epoch: 6| Step: 3
Training loss: 4.638766446404379
Validation loss: 4.5880971894451

Epoch: 6| Step: 4
Training loss: 4.8792053082133435
Validation loss: 4.580736346697026

Epoch: 6| Step: 5
Training loss: 5.414568372380174
Validation loss: 4.575074710075674

Epoch: 6| Step: 6
Training loss: 5.223898900290758
Validation loss: 4.568173562300727

Epoch: 6| Step: 7
Training loss: 4.5909568962677785
Validation loss: 4.562397592574961

Epoch: 6| Step: 8
Training loss: 4.792678637689984
Validation loss: 4.5546233247717485

Epoch: 6| Step: 9
Training loss: 4.185005697704525
Validation loss: 4.550359031289655

Epoch: 6| Step: 10
Training loss: 3.255281997864412
Validation loss: 4.544009705107517

Epoch: 6| Step: 11
Training loss: 4.297166627177554
Validation loss: 4.537691453694602

Epoch: 6| Step: 12
Training loss: 4.731945459407847
Validation loss: 4.532182454258833

Epoch: 6| Step: 13
Training loss: 5.050119402389765
Validation loss: 4.528417694599367

Epoch: 6| Step: 0
Training loss: 5.009732501717984
Validation loss: 4.516865262436039

Epoch: 6| Step: 1
Training loss: 3.9581481622584125
Validation loss: 4.513880713586632

Epoch: 6| Step: 2
Training loss: 4.857704979561545
Validation loss: 4.507708966188415

Epoch: 6| Step: 3
Training loss: 4.296050169412069
Validation loss: 4.50136774508761

Epoch: 6| Step: 4
Training loss: 4.724024773929246
Validation loss: 4.494146098945435

Epoch: 6| Step: 5
Training loss: 3.7680619454688027
Validation loss: 4.48399060450404

Epoch: 6| Step: 6
Training loss: 4.545892458541987
Validation loss: 4.479155142622153

Epoch: 6| Step: 7
Training loss: 3.4227672789640935
Validation loss: 4.473928219819719

Epoch: 6| Step: 8
Training loss: 5.100745329903487
Validation loss: 4.467879011042221

Epoch: 6| Step: 9
Training loss: 5.894221576420703
Validation loss: 4.460709695344206

Epoch: 6| Step: 10
Training loss: 3.6645114517896995
Validation loss: 4.457328986105012

Epoch: 6| Step: 11
Training loss: 5.525614998537316
Validation loss: 4.452457915568382

Epoch: 6| Step: 12
Training loss: 3.9601222897923067
Validation loss: 4.440562022400963

Epoch: 6| Step: 13
Training loss: 4.73160484525294
Validation loss: 4.434248989775085

Epoch: 7| Step: 0
Training loss: 4.705438494786926
Validation loss: 4.428013313764178

Epoch: 6| Step: 1
Training loss: 4.104588030309445
Validation loss: 4.4223871158098955

Epoch: 6| Step: 2
Training loss: 3.9796940851774876
Validation loss: 4.41586273098921

Epoch: 6| Step: 3
Training loss: 5.227451767701217
Validation loss: 4.407330475581151

Epoch: 6| Step: 4
Training loss: 4.864950140357459
Validation loss: 4.398264432510576

Epoch: 6| Step: 5
Training loss: 3.8122893728639187
Validation loss: 4.390092002488937

Epoch: 6| Step: 6
Training loss: 4.545430481586915
Validation loss: 4.382682248084151

Epoch: 6| Step: 7
Training loss: 4.6505608333246355
Validation loss: 4.3774273890309585

Epoch: 6| Step: 8
Training loss: 4.082956076081871
Validation loss: 4.367046724857569

Epoch: 6| Step: 9
Training loss: 4.379795389142835
Validation loss: 4.358871216204003

Epoch: 6| Step: 10
Training loss: 5.5489728372321165
Validation loss: 4.351816756825196

Epoch: 6| Step: 11
Training loss: 4.6798613297874585
Validation loss: 4.345336921639993

Epoch: 6| Step: 12
Training loss: 3.7000017475433347
Validation loss: 4.331285103051326

Epoch: 6| Step: 13
Training loss: 3.763296459975815
Validation loss: 4.331251751153387

Epoch: 8| Step: 0
Training loss: 5.584140472525251
Validation loss: 4.3182558179448565

Epoch: 6| Step: 1
Training loss: 5.3295681696550234
Validation loss: 4.309887554132371

Epoch: 6| Step: 2
Training loss: 3.34098430588983
Validation loss: 4.296763829856179

Epoch: 6| Step: 3
Training loss: 4.733407201772627
Validation loss: 4.2974279632207

Epoch: 6| Step: 4
Training loss: 3.3142603389351115
Validation loss: 4.284056363266597

Epoch: 6| Step: 5
Training loss: 4.258966747934265
Validation loss: 4.2763700734453165

Epoch: 6| Step: 6
Training loss: 3.8349250032136792
Validation loss: 4.265378602114575

Epoch: 6| Step: 7
Training loss: 3.394176117786861
Validation loss: 4.2579680684677585

Epoch: 6| Step: 8
Training loss: 4.262344608103331
Validation loss: 4.248047234678176

Epoch: 6| Step: 9
Training loss: 4.614699776287571
Validation loss: 4.234567403007411

Epoch: 6| Step: 10
Training loss: 3.2268517020531724
Validation loss: 4.227297749975208

Epoch: 6| Step: 11
Training loss: 4.875975682361477
Validation loss: 4.220775222358048

Epoch: 6| Step: 12
Training loss: 4.9139534311971875
Validation loss: 4.210738523149132

Epoch: 6| Step: 13
Training loss: 4.885316935851829
Validation loss: 4.200214537645958

Epoch: 9| Step: 0
Training loss: 3.6779718955430174
Validation loss: 4.186134322611305

Epoch: 6| Step: 1
Training loss: 4.928993333406094
Validation loss: 4.185621006246153

Epoch: 6| Step: 2
Training loss: 3.485829550090296
Validation loss: 4.170243537279238

Epoch: 6| Step: 3
Training loss: 5.308471049504071
Validation loss: 4.155078915092326

Epoch: 6| Step: 4
Training loss: 4.289762846253812
Validation loss: 4.145905848018529

Epoch: 6| Step: 5
Training loss: 4.222409617855311
Validation loss: 4.141082553886471

Epoch: 6| Step: 6
Training loss: 4.381109277312752
Validation loss: 4.125231289213605

Epoch: 6| Step: 7
Training loss: 3.973470448767244
Validation loss: 4.11843038922862

Epoch: 6| Step: 8
Training loss: 3.93247253136763
Validation loss: 4.10003225037231

Epoch: 6| Step: 9
Training loss: 4.442931383920594
Validation loss: 4.083432173563379

Epoch: 6| Step: 10
Training loss: 4.246356973499369
Validation loss: 4.0752011566872355

Epoch: 6| Step: 11
Training loss: 4.621022343990787
Validation loss: 4.069205750519808

Epoch: 6| Step: 12
Training loss: 3.802323564578124
Validation loss: 4.056220412044111

Epoch: 6| Step: 13
Training loss: 3.3007091627205924
Validation loss: 4.036872605081152

Epoch: 10| Step: 0
Training loss: 3.9921778251396343
Validation loss: 4.024503694331298

Epoch: 6| Step: 1
Training loss: 4.286667563367624
Validation loss: 4.022327504860966

Epoch: 6| Step: 2
Training loss: 3.6492035610868605
Validation loss: 4.0015217119488815

Epoch: 6| Step: 3
Training loss: 4.860085389442842
Validation loss: 3.993523623066518

Epoch: 6| Step: 4
Training loss: 4.211037148055653
Validation loss: 3.982451108372279

Epoch: 6| Step: 5
Training loss: 3.7029644251265013
Validation loss: 3.966998750582621

Epoch: 6| Step: 6
Training loss: 5.204861920931889
Validation loss: 3.958410654570338

Epoch: 6| Step: 7
Training loss: 3.953560545075988
Validation loss: 3.939034577839332

Epoch: 6| Step: 8
Training loss: 4.230378577062984
Validation loss: 3.932095098387138

Epoch: 6| Step: 9
Training loss: 3.7115201793781414
Validation loss: 3.9125501608310587

Epoch: 6| Step: 10
Training loss: 3.1167892928317507
Validation loss: 3.8940236826873718

Epoch: 6| Step: 11
Training loss: 3.7346076414035108
Validation loss: 3.885539118619707

Epoch: 6| Step: 12
Training loss: 4.091547948872153
Validation loss: 3.8675903203325306

Epoch: 6| Step: 13
Training loss: 3.9719961512567132
Validation loss: 3.859774958695069

Epoch: 11| Step: 0
Training loss: 3.756420361405202
Validation loss: 3.8378434652034934

Epoch: 6| Step: 1
Training loss: 3.6165554738567747
Validation loss: 3.8269620627796073

Epoch: 6| Step: 2
Training loss: 3.628462617527825
Validation loss: 3.818290201532042

Epoch: 6| Step: 3
Training loss: 3.627279814354489
Validation loss: 3.8070799765343737

Epoch: 6| Step: 4
Training loss: 4.0070433594328625
Validation loss: 3.7919147810992793

Epoch: 6| Step: 5
Training loss: 4.755303483939299
Validation loss: 3.77972405184221

Epoch: 6| Step: 6
Training loss: 4.426747363936765
Validation loss: 3.7640386940424877

Epoch: 6| Step: 7
Training loss: 3.2407314478019402
Validation loss: 3.747650138995721

Epoch: 6| Step: 8
Training loss: 4.114902042970426
Validation loss: 3.733770004915314

Epoch: 6| Step: 9
Training loss: 4.2260225130881555
Validation loss: 3.714185818008661

Epoch: 6| Step: 10
Training loss: 3.058947468421612
Validation loss: 3.6988529354021162

Epoch: 6| Step: 11
Training loss: 3.4277443910110073
Validation loss: 3.6893242185214787

Epoch: 6| Step: 12
Training loss: 4.314037325411539
Validation loss: 3.676716692307705

Epoch: 6| Step: 13
Training loss: 4.115550691227776
Validation loss: 3.6560351344828246

Epoch: 12| Step: 0
Training loss: 3.245148632483822
Validation loss: 3.648116816293773

Epoch: 6| Step: 1
Training loss: 3.5242994653975925
Validation loss: 3.623869718662393

Epoch: 6| Step: 2
Training loss: 4.538079948248953
Validation loss: 3.610627690927989

Epoch: 6| Step: 3
Training loss: 3.8637086575930226
Validation loss: 3.591216680284223

Epoch: 6| Step: 4
Training loss: 3.570053658816777
Validation loss: 3.5819462359167353

Epoch: 6| Step: 5
Training loss: 3.3569156604634625
Validation loss: 3.558194240975388

Epoch: 6| Step: 6
Training loss: 3.7418243295689995
Validation loss: 3.54415060207109

Epoch: 6| Step: 7
Training loss: 4.367092288485823
Validation loss: 3.526847273404264

Epoch: 6| Step: 8
Training loss: 3.732725281812202
Validation loss: 3.506061154670232

Epoch: 6| Step: 9
Training loss: 3.3174301022810577
Validation loss: 3.489268014859279

Epoch: 6| Step: 10
Training loss: 3.6167287185432024
Validation loss: 3.478860865365501

Epoch: 6| Step: 11
Training loss: 4.257806228493088
Validation loss: 3.4637711022057207

Epoch: 6| Step: 12
Training loss: 2.957270704524093
Validation loss: 3.443925507066734

Epoch: 6| Step: 13
Training loss: 3.1683546553256674
Validation loss: 3.4229087300180154

Epoch: 13| Step: 0
Training loss: 3.674350374894892
Validation loss: 3.4111484131621688

Epoch: 6| Step: 1
Training loss: 3.375513249683891
Validation loss: 3.4018525835885267

Epoch: 6| Step: 2
Training loss: 4.209366825721694
Validation loss: 3.3747686164747663

Epoch: 6| Step: 3
Training loss: 4.11171130934036
Validation loss: 3.359815663546644

Epoch: 6| Step: 4
Training loss: 3.5909728888495036
Validation loss: 3.34338925301424

Epoch: 6| Step: 5
Training loss: 3.5560884837930327
Validation loss: 3.3222784514134163

Epoch: 6| Step: 6
Training loss: 3.1370826595604777
Validation loss: 3.3077557922267578

Epoch: 6| Step: 7
Training loss: 3.9546502228015803
Validation loss: 3.2935812353560845

Epoch: 6| Step: 8
Training loss: 3.749348011558781
Validation loss: 3.2721916833633804

Epoch: 6| Step: 9
Training loss: 2.8210039215871983
Validation loss: 3.2606565095074123

Epoch: 6| Step: 10
Training loss: 2.292004046025458
Validation loss: 3.233238909613039

Epoch: 6| Step: 11
Training loss: 3.50377478719729
Validation loss: 3.2269094929572586

Epoch: 6| Step: 12
Training loss: 3.4656424134129136
Validation loss: 3.2019888434830146

Epoch: 6| Step: 13
Training loss: 2.8348847423988066
Validation loss: 3.1919054170245027

Epoch: 14| Step: 0
Training loss: 3.2756037497745525
Validation loss: 3.179495913401242

Epoch: 6| Step: 1
Training loss: 3.8702309086638427
Validation loss: 3.159004944667943

Epoch: 6| Step: 2
Training loss: 3.268175653067656
Validation loss: 3.1420838203400807

Epoch: 6| Step: 3
Training loss: 3.4533285365813926
Validation loss: 3.127893655365753

Epoch: 6| Step: 4
Training loss: 3.2187054084725992
Validation loss: 3.108085709247923

Epoch: 6| Step: 5
Training loss: 2.198918215338857
Validation loss: 3.0950964248312816

Epoch: 6| Step: 6
Training loss: 3.3819189851826534
Validation loss: 3.075892623620329

Epoch: 6| Step: 7
Training loss: 3.789598187205497
Validation loss: 3.0679223553363846

Epoch: 6| Step: 8
Training loss: 3.3023751467856317
Validation loss: 3.046394280352143

Epoch: 6| Step: 9
Training loss: 3.7033431234381986
Validation loss: 3.045249631224108

Epoch: 6| Step: 10
Training loss: 3.027228135393139
Validation loss: 3.0196510391683034

Epoch: 6| Step: 11
Training loss: 3.3626809110508686
Validation loss: 2.9988116462379137

Epoch: 6| Step: 12
Training loss: 2.7821682903471148
Validation loss: 3.00400548414957

Epoch: 6| Step: 13
Training loss: 3.2106317156423856
Validation loss: 2.97864017241639

Epoch: 15| Step: 0
Training loss: 2.65098741597024
Validation loss: 2.9487969440013155

Epoch: 6| Step: 1
Training loss: 3.957009920776363
Validation loss: 2.9475696608349935

Epoch: 6| Step: 2
Training loss: 3.254559912632513
Validation loss: 2.9257292771700962

Epoch: 6| Step: 3
Training loss: 2.2189522234675847
Validation loss: 2.92259953375092

Epoch: 6| Step: 4
Training loss: 3.3006265276699653
Validation loss: 2.904938358497759

Epoch: 6| Step: 5
Training loss: 2.799703180384377
Validation loss: 2.897147103655108

Epoch: 6| Step: 6
Training loss: 3.9220995591758507
Validation loss: 2.8751530136186956

Epoch: 6| Step: 7
Training loss: 3.2571397265082207
Validation loss: 2.858495591281086

Epoch: 6| Step: 8
Training loss: 3.7843731049360447
Validation loss: 2.852970053589211

Epoch: 6| Step: 9
Training loss: 2.3093637386145525
Validation loss: 2.8401363292217257

Epoch: 6| Step: 10
Training loss: 3.2227180983648447
Validation loss: 2.8283205700677465

Epoch: 6| Step: 11
Training loss: 2.3709116430595967
Validation loss: 2.8109267224534875

Epoch: 6| Step: 12
Training loss: 3.03381459397251
Validation loss: 2.812458699787944

Epoch: 6| Step: 13
Training loss: 3.2324301359411054
Validation loss: 2.79498318695172

Epoch: 16| Step: 0
Training loss: 3.0730238728761288
Validation loss: 2.7876921915040023

Epoch: 6| Step: 1
Training loss: 3.1843889799550524
Validation loss: 2.7696841173861664

Epoch: 6| Step: 2
Training loss: 2.794495236125004
Validation loss: 2.7686845538768914

Epoch: 6| Step: 3
Training loss: 3.092270622658982
Validation loss: 2.7550243836799986

Epoch: 6| Step: 4
Training loss: 2.6303371486027842
Validation loss: 2.7443072891466187

Epoch: 6| Step: 5
Training loss: 2.8946251487173456
Validation loss: 2.7363031305131873

Epoch: 6| Step: 6
Training loss: 3.2816629785685225
Validation loss: 2.7230091370916174

Epoch: 6| Step: 7
Training loss: 3.4330248746606924
Validation loss: 2.717527754343669

Epoch: 6| Step: 8
Training loss: 2.6947902892268587
Validation loss: 2.699232232920407

Epoch: 6| Step: 9
Training loss: 3.2981440555903228
Validation loss: 2.70377404608312

Epoch: 6| Step: 10
Training loss: 2.733258090107828
Validation loss: 2.696079459265574

Epoch: 6| Step: 11
Training loss: 2.5180173125334666
Validation loss: 2.689742707192494

Epoch: 6| Step: 12
Training loss: 3.384664050832743
Validation loss: 2.6789968100285977

Epoch: 6| Step: 13
Training loss: 3.169649141792806
Validation loss: 2.668386044129554

Epoch: 17| Step: 0
Training loss: 3.153724793323204
Validation loss: 2.6562204087869348

Epoch: 6| Step: 1
Training loss: 2.8056791884707994
Validation loss: 2.6632031981988225

Epoch: 6| Step: 2
Training loss: 2.020640321408587
Validation loss: 2.6406670169165833

Epoch: 6| Step: 3
Training loss: 3.1178773198000016
Validation loss: 2.638012508194595

Epoch: 6| Step: 4
Training loss: 2.219133370818543
Validation loss: 2.639469224608627

Epoch: 6| Step: 5
Training loss: 3.318459961137376
Validation loss: 2.638070930677678

Epoch: 6| Step: 6
Training loss: 2.95136075074988
Validation loss: 2.6360999155572036

Epoch: 6| Step: 7
Training loss: 3.3935137980899897
Validation loss: 2.635434368333013

Epoch: 6| Step: 8
Training loss: 3.198482964457648
Validation loss: 2.627948968902967

Epoch: 6| Step: 9
Training loss: 3.28838451945674
Validation loss: 2.6298059923138113

Epoch: 6| Step: 10
Training loss: 3.1086914231227225
Validation loss: 2.610894926528761

Epoch: 6| Step: 11
Training loss: 2.7311337688514263
Validation loss: 2.6151901496616072

Epoch: 6| Step: 12
Training loss: 2.740083936394122
Validation loss: 2.6111845614731557

Epoch: 6| Step: 13
Training loss: 2.8322745383108203
Validation loss: 2.6102684711235242

Epoch: 18| Step: 0
Training loss: 3.6017824052052063
Validation loss: 2.5963144741915687

Epoch: 6| Step: 1
Training loss: 3.00682721534745
Validation loss: 2.594333444191974

Epoch: 6| Step: 2
Training loss: 2.6245528248961127
Validation loss: 2.590472336123646

Epoch: 6| Step: 3
Training loss: 2.4557941275803445
Validation loss: 2.5992953062519564

Epoch: 6| Step: 4
Training loss: 3.2153583916558963
Validation loss: 2.5912665348237662

Epoch: 6| Step: 5
Training loss: 2.6217200359612103
Validation loss: 2.5892050426990885

Epoch: 6| Step: 6
Training loss: 2.6297257890367396
Validation loss: 2.5819961475715854

Epoch: 6| Step: 7
Training loss: 3.2835342449030698
Validation loss: 2.58292684787362

Epoch: 6| Step: 8
Training loss: 2.891042648248922
Validation loss: 2.5759192782647697

Epoch: 6| Step: 9
Training loss: 2.895240851152394
Validation loss: 2.557762154511102

Epoch: 6| Step: 10
Training loss: 3.3549615301209204
Validation loss: 2.5686958416062216

Epoch: 6| Step: 11
Training loss: 2.115645406559806
Validation loss: 2.5891328862219036

Epoch: 6| Step: 12
Training loss: 3.0007239104108248
Validation loss: 2.560152219358564

Epoch: 6| Step: 13
Training loss: 2.7729300881014898
Validation loss: 2.5741569681801915

Epoch: 19| Step: 0
Training loss: 3.576408940889672
Validation loss: 2.5624588433578936

Epoch: 6| Step: 1
Training loss: 3.415045625038376
Validation loss: 2.56383975951712

Epoch: 6| Step: 2
Training loss: 3.013411109505734
Validation loss: 2.5751280945790938

Epoch: 6| Step: 3
Training loss: 2.7334914169497746
Validation loss: 2.5685648096376448

Epoch: 6| Step: 4
Training loss: 3.205930197904797
Validation loss: 2.551871163390901

Epoch: 6| Step: 5
Training loss: 3.033944888525315
Validation loss: 2.551085021741185

Epoch: 6| Step: 6
Training loss: 2.680580724313627
Validation loss: 2.570361527936179

Epoch: 6| Step: 7
Training loss: 3.665019416705606
Validation loss: 2.566771249261186

Epoch: 6| Step: 8
Training loss: 2.30131444274086
Validation loss: 2.5621977216871294

Epoch: 6| Step: 9
Training loss: 3.141436723410934
Validation loss: 2.558605827748288

Epoch: 6| Step: 10
Training loss: 2.2873555872624105
Validation loss: 2.5556635268332575

Epoch: 6| Step: 11
Training loss: 2.34226372959308
Validation loss: 2.552034226816313

Epoch: 6| Step: 12
Training loss: 2.1668556448856267
Validation loss: 2.55816409516017

Epoch: 6| Step: 13
Training loss: 2.3249031662003157
Validation loss: 2.560587743994286

Epoch: 20| Step: 0
Training loss: 3.302985436153613
Validation loss: 2.5554948163167244

Epoch: 6| Step: 1
Training loss: 2.740864926561376
Validation loss: 2.5561144091639294

Epoch: 6| Step: 2
Training loss: 2.5294671078692605
Validation loss: 2.543642642351407

Epoch: 6| Step: 3
Training loss: 3.255291226158122
Validation loss: 2.5511994395573505

Epoch: 6| Step: 4
Training loss: 3.274564489862217
Validation loss: 2.55735848961909

Epoch: 6| Step: 5
Training loss: 3.2571426544571818
Validation loss: 2.5525078553307314

Epoch: 6| Step: 6
Training loss: 2.8655019685881253
Validation loss: 2.5430353068161193

Epoch: 6| Step: 7
Training loss: 2.318146796310446
Validation loss: 2.5569977853455277

Epoch: 6| Step: 8
Training loss: 2.456968952596063
Validation loss: 2.553603035293771

Epoch: 6| Step: 9
Training loss: 2.6740468439408627
Validation loss: 2.5494971945219085

Epoch: 6| Step: 10
Training loss: 2.5059871507210203
Validation loss: 2.546445547506669

Epoch: 6| Step: 11
Training loss: 2.806514729202741
Validation loss: 2.5453210490450986

Epoch: 6| Step: 12
Training loss: 3.072437744751476
Validation loss: 2.5407814899862906

Epoch: 6| Step: 13
Training loss: 3.688338232943565
Validation loss: 2.5361577499572294

Epoch: 21| Step: 0
Training loss: 3.4439470349003947
Validation loss: 2.540375168752971

Epoch: 6| Step: 1
Training loss: 3.2748886205938246
Validation loss: 2.5344227876418097

Epoch: 6| Step: 2
Training loss: 2.78591938451503
Validation loss: 2.540353953634447

Epoch: 6| Step: 3
Training loss: 3.6881674469607924
Validation loss: 2.5554645650164907

Epoch: 6| Step: 4
Training loss: 3.171537033641846
Validation loss: 2.5463314033674327

Epoch: 6| Step: 5
Training loss: 2.7440236782798446
Validation loss: 2.5570779177304708

Epoch: 6| Step: 6
Training loss: 2.4814220609029687
Validation loss: 2.5529433605498464

Epoch: 6| Step: 7
Training loss: 2.9268819574521427
Validation loss: 2.5507876862766965

Epoch: 6| Step: 8
Training loss: 2.2964316219130745
Validation loss: 2.544422387265448

Epoch: 6| Step: 9
Training loss: 2.4500285244273816
Validation loss: 2.541391459318152

Epoch: 6| Step: 10
Training loss: 3.125454678836807
Validation loss: 2.5405229869663732

Epoch: 6| Step: 11
Training loss: 2.3466642445132733
Validation loss: 2.5572998342142803

Epoch: 6| Step: 12
Training loss: 2.259475781737449
Validation loss: 2.562367171459776

Epoch: 6| Step: 13
Training loss: 3.3385622655716087
Validation loss: 2.5471639825938643

Epoch: 22| Step: 0
Training loss: 2.5858654000640744
Validation loss: 2.552745040350434

Epoch: 6| Step: 1
Training loss: 3.0509738055429736
Validation loss: 2.558978912813382

Epoch: 6| Step: 2
Training loss: 2.4999603268336457
Validation loss: 2.5422543741056987

Epoch: 6| Step: 3
Training loss: 2.929388168302108
Validation loss: 2.5510854880248

Epoch: 6| Step: 4
Training loss: 3.7878808764827636
Validation loss: 2.553344903617319

Epoch: 6| Step: 5
Training loss: 2.4607665956281144
Validation loss: 2.544258398685484

Epoch: 6| Step: 6
Training loss: 2.7592698696064275
Validation loss: 2.554503320163155

Epoch: 6| Step: 7
Training loss: 2.8620576208513415
Validation loss: 2.5500659301135955

Epoch: 6| Step: 8
Training loss: 3.1959218980701722
Validation loss: 2.5400040771768815

Epoch: 6| Step: 9
Training loss: 2.509318342317455
Validation loss: 2.5385746090663526

Epoch: 6| Step: 10
Training loss: 2.690181902155877
Validation loss: 2.5504759504189596

Epoch: 6| Step: 11
Training loss: 3.119845908345681
Validation loss: 2.5512844034742668

Epoch: 6| Step: 12
Training loss: 2.5469028962836697
Validation loss: 2.539359721290455

Epoch: 6| Step: 13
Training loss: 3.506171643474669
Validation loss: 2.5395239868298844

Epoch: 23| Step: 0
Training loss: 2.8452127907390268
Validation loss: 2.5418930917792726

Epoch: 6| Step: 1
Training loss: 2.6888702802653457
Validation loss: 2.5527717873870883

Epoch: 6| Step: 2
Training loss: 3.656049804423391
Validation loss: 2.550254370999169

Epoch: 6| Step: 3
Training loss: 2.477897981922072
Validation loss: 2.554545833837676

Epoch: 6| Step: 4
Training loss: 2.442971470913349
Validation loss: 2.544551323590015

Epoch: 6| Step: 5
Training loss: 2.621765869197359
Validation loss: 2.54183597965696

Epoch: 6| Step: 6
Training loss: 3.0149680889712
Validation loss: 2.548301622848066

Epoch: 6| Step: 7
Training loss: 3.347360106002976
Validation loss: 2.5407530744568234

Epoch: 6| Step: 8
Training loss: 2.5445154411520536
Validation loss: 2.5514082850654742

Epoch: 6| Step: 9
Training loss: 2.274125981379882
Validation loss: 2.5346704907508393

Epoch: 6| Step: 10
Training loss: 3.432893475500768
Validation loss: 2.5443988809433065

Epoch: 6| Step: 11
Training loss: 2.8942526658806966
Validation loss: 2.5464808581019884

Epoch: 6| Step: 12
Training loss: 3.1046393288502374
Validation loss: 2.5452200578804973

Epoch: 6| Step: 13
Training loss: 2.782740075926905
Validation loss: 2.5477479140496864

Epoch: 24| Step: 0
Training loss: 3.008149363492214
Validation loss: 2.5620218006361255

Epoch: 6| Step: 1
Training loss: 2.66797661396169
Validation loss: 2.5357679889911533

Epoch: 6| Step: 2
Training loss: 3.265361428461463
Validation loss: 2.5541255840093036

Epoch: 6| Step: 3
Training loss: 2.4026345177820114
Validation loss: 2.557594165304413

Epoch: 6| Step: 4
Training loss: 3.311546620338714
Validation loss: 2.5513439347116544

Epoch: 6| Step: 5
Training loss: 3.4488391084071623
Validation loss: 2.5488140999258797

Epoch: 6| Step: 6
Training loss: 2.088877916419969
Validation loss: 2.551839518416006

Epoch: 6| Step: 7
Training loss: 2.0644204417720955
Validation loss: 2.561956869812679

Epoch: 6| Step: 8
Training loss: 2.636396193378046
Validation loss: 2.537656009876561

Epoch: 6| Step: 9
Training loss: 2.8798193965021013
Validation loss: 2.553450840878783

Epoch: 6| Step: 10
Training loss: 2.979368634258149
Validation loss: 2.5541752408316047

Epoch: 6| Step: 11
Training loss: 2.8294457149579744
Validation loss: 2.5469324510734133

Epoch: 6| Step: 12
Training loss: 2.8934450981715227
Validation loss: 2.5360745506896727

Epoch: 6| Step: 13
Training loss: 3.6627780639498146
Validation loss: 2.5471008399954678

Epoch: 25| Step: 0
Training loss: 2.7649415459412383
Validation loss: 2.550110536922545

Epoch: 6| Step: 1
Training loss: 2.853510778946518
Validation loss: 2.549132685636081

Epoch: 6| Step: 2
Training loss: 3.1249699400409705
Validation loss: 2.545321297319235

Epoch: 6| Step: 3
Training loss: 2.3040019421966633
Validation loss: 2.5479245363965375

Epoch: 6| Step: 4
Training loss: 2.244303910678665
Validation loss: 2.538532018280656

Epoch: 6| Step: 5
Training loss: 3.3322715180719906
Validation loss: 2.5366565587891805

Epoch: 6| Step: 6
Training loss: 3.1508015354599745
Validation loss: 2.5404418137007396

Epoch: 6| Step: 7
Training loss: 2.755344918704864
Validation loss: 2.535184497196495

Epoch: 6| Step: 8
Training loss: 2.9736775512336466
Validation loss: 2.532519709878439

Epoch: 6| Step: 9
Training loss: 2.641734956486412
Validation loss: 2.5385666704339895

Epoch: 6| Step: 10
Training loss: 3.3237757673408868
Validation loss: 2.5391494743652836

Epoch: 6| Step: 11
Training loss: 2.4901929186193867
Validation loss: 2.538313474520573

Epoch: 6| Step: 12
Training loss: 3.171090465918939
Validation loss: 2.5399534630188176

Epoch: 6| Step: 13
Training loss: 2.9539020464649575
Validation loss: 2.5347828808393307

Epoch: 26| Step: 0
Training loss: 2.674808252895579
Validation loss: 2.545284758961992

Epoch: 6| Step: 1
Training loss: 2.7133621673863977
Validation loss: 2.544409129847368

Epoch: 6| Step: 2
Training loss: 3.217468302821814
Validation loss: 2.541820336559243

Epoch: 6| Step: 3
Training loss: 2.3999652780564276
Validation loss: 2.532762865092839

Epoch: 6| Step: 4
Training loss: 3.026511037189116
Validation loss: 2.533240408385882

Epoch: 6| Step: 5
Training loss: 3.1910189483472107
Validation loss: 2.5322466222273197

Epoch: 6| Step: 6
Training loss: 2.7519995615759214
Validation loss: 2.537292129825885

Epoch: 6| Step: 7
Training loss: 2.556988627599819
Validation loss: 2.5285331915834823

Epoch: 6| Step: 8
Training loss: 2.4229525230249576
Validation loss: 2.5348674954112993

Epoch: 6| Step: 9
Training loss: 3.1590814259737936
Validation loss: 2.5235522235329984

Epoch: 6| Step: 10
Training loss: 3.447658440792132
Validation loss: 2.532557793910881

Epoch: 6| Step: 11
Training loss: 2.5658841001124664
Validation loss: 2.5338991998365867

Epoch: 6| Step: 12
Training loss: 2.6260141502632486
Validation loss: 2.548921990629692

Epoch: 6| Step: 13
Training loss: 3.420886868155929
Validation loss: 2.5231674813342964

Epoch: 27| Step: 0
Training loss: 3.4061321273147325
Validation loss: 2.5306119774312417

Epoch: 6| Step: 1
Training loss: 2.826905129723542
Validation loss: 2.5447478846825033

Epoch: 6| Step: 2
Training loss: 2.8370197847662735
Validation loss: 2.532142565854584

Epoch: 6| Step: 3
Training loss: 2.2881938861646214
Validation loss: 2.5371232141851485

Epoch: 6| Step: 4
Training loss: 2.8785597283397024
Validation loss: 2.5306950777065973

Epoch: 6| Step: 5
Training loss: 2.357294238790496
Validation loss: 2.530933172425148

Epoch: 6| Step: 6
Training loss: 2.457331361621156
Validation loss: 2.5232857507700563

Epoch: 6| Step: 7
Training loss: 3.5709350844448764
Validation loss: 2.540413455929587

Epoch: 6| Step: 8
Training loss: 2.858010555389325
Validation loss: 2.536686295111921

Epoch: 6| Step: 9
Training loss: 3.348108606033109
Validation loss: 2.5172627037275395

Epoch: 6| Step: 10
Training loss: 3.51663912239557
Validation loss: 2.5353447423929123

Epoch: 6| Step: 11
Training loss: 2.7136165342540215
Validation loss: 2.530942056757928

Epoch: 6| Step: 12
Training loss: 1.9199891801370292
Validation loss: 2.516432150437726

Epoch: 6| Step: 13
Training loss: 2.32281051416003
Validation loss: 2.518983563128212

Epoch: 28| Step: 0
Training loss: 2.882405570237799
Validation loss: 2.5355122770636425

Epoch: 6| Step: 1
Training loss: 2.718827432867098
Validation loss: 2.536222885398414

Epoch: 6| Step: 2
Training loss: 3.457337446715172
Validation loss: 2.540576930333559

Epoch: 6| Step: 3
Training loss: 2.4340798273717454
Validation loss: 2.5424310902063283

Epoch: 6| Step: 4
Training loss: 2.9455716856387686
Validation loss: 2.519429114649131

Epoch: 6| Step: 5
Training loss: 2.761056175768525
Validation loss: 2.5344807293494753

Epoch: 6| Step: 6
Training loss: 3.1822286663073047
Validation loss: 2.5342881637972527

Epoch: 6| Step: 7
Training loss: 2.1237414503907743
Validation loss: 2.5253234924910983

Epoch: 6| Step: 8
Training loss: 2.0868756759747566
Validation loss: 2.52277260282789

Epoch: 6| Step: 9
Training loss: 3.1351875567875283
Validation loss: 2.5263678612964156

Epoch: 6| Step: 10
Training loss: 2.900669277176252
Validation loss: 2.521391122874991

Epoch: 6| Step: 11
Training loss: 3.242711183469316
Validation loss: 2.524412115711212

Epoch: 6| Step: 12
Training loss: 2.968741165951083
Validation loss: 2.5201117970190423

Epoch: 6| Step: 13
Training loss: 2.828608181812359
Validation loss: 2.537604913462792

Epoch: 29| Step: 0
Training loss: 2.652016531039768
Validation loss: 2.5334741383536863

Epoch: 6| Step: 1
Training loss: 4.021497892233839
Validation loss: 2.531043759938558

Epoch: 6| Step: 2
Training loss: 2.945547888782714
Validation loss: 2.5145521139080467

Epoch: 6| Step: 3
Training loss: 2.579014480201093
Validation loss: 2.541806775095655

Epoch: 6| Step: 4
Training loss: 2.744777923105614
Validation loss: 2.533282523449851

Epoch: 6| Step: 5
Training loss: 3.4896847079151345
Validation loss: 2.5289505744015446

Epoch: 6| Step: 6
Training loss: 2.6995119854738183
Validation loss: 2.54790951778269

Epoch: 6| Step: 7
Training loss: 2.2845562530291073
Validation loss: 2.532365598433844

Epoch: 6| Step: 8
Training loss: 2.482017598221181
Validation loss: 2.524932998276734

Epoch: 6| Step: 9
Training loss: 2.9742900353865305
Validation loss: 2.5339718202961223

Epoch: 6| Step: 10
Training loss: 2.8241045283729345
Validation loss: 2.5360139003163544

Epoch: 6| Step: 11
Training loss: 2.6608095417179642
Validation loss: 2.5166213097573658

Epoch: 6| Step: 12
Training loss: 2.891271735347549
Validation loss: 2.525368203366879

Epoch: 6| Step: 13
Training loss: 1.4363176210054114
Validation loss: 2.5272585218951527

Epoch: 30| Step: 0
Training loss: 2.995440037518959
Validation loss: 2.53408563999606

Epoch: 6| Step: 1
Training loss: 2.0690398137137
Validation loss: 2.530116323763605

Epoch: 6| Step: 2
Training loss: 2.6782135315620543
Validation loss: 2.5370740734189074

Epoch: 6| Step: 3
Training loss: 3.3283608223192696
Validation loss: 2.531757320608119

Epoch: 6| Step: 4
Training loss: 2.965520768901498
Validation loss: 2.5303943949748002

Epoch: 6| Step: 5
Training loss: 2.9459836483544968
Validation loss: 2.5393118262162213

Epoch: 6| Step: 6
Training loss: 2.8164677077530853
Validation loss: 2.533466887016557

Epoch: 6| Step: 7
Training loss: 2.6491381413293085
Validation loss: 2.5236620475311797

Epoch: 6| Step: 8
Training loss: 3.1659309804192386
Validation loss: 2.531896190940157

Epoch: 6| Step: 9
Training loss: 3.0709439082188976
Validation loss: 2.531622447681675

Epoch: 6| Step: 10
Training loss: 2.585677303811479
Validation loss: 2.526276258851825

Epoch: 6| Step: 11
Training loss: 2.993695150681245
Validation loss: 2.524795143137077

Epoch: 6| Step: 12
Training loss: 2.165854583064544
Validation loss: 2.528162180980573

Epoch: 6| Step: 13
Training loss: 3.2445747870416017
Validation loss: 2.5287618314669937

Epoch: 31| Step: 0
Training loss: 2.48171201771668
Validation loss: 2.523542201800596

Epoch: 6| Step: 1
Training loss: 3.318349603612747
Validation loss: 2.5203682689046465

Epoch: 6| Step: 2
Training loss: 2.553186378068069
Validation loss: 2.5250044927533724

Epoch: 6| Step: 3
Training loss: 2.12935360749127
Validation loss: 2.5170428678270413

Epoch: 6| Step: 4
Training loss: 3.3677207719215434
Validation loss: 2.5168696820832634

Epoch: 6| Step: 5
Training loss: 2.950815902639806
Validation loss: 2.5225107227153107

Epoch: 6| Step: 6
Training loss: 3.038605408015749
Validation loss: 2.540048710554459

Epoch: 6| Step: 7
Training loss: 2.656317137823407
Validation loss: 2.515892844595897

Epoch: 6| Step: 8
Training loss: 2.9528432237324878
Validation loss: 2.5232770690950184

Epoch: 6| Step: 9
Training loss: 2.6554434056544203
Validation loss: 2.5369371276156447

Epoch: 6| Step: 10
Training loss: 2.173881427286204
Validation loss: 2.5117896938573794

Epoch: 6| Step: 11
Training loss: 3.4087277421270077
Validation loss: 2.528599216401571

Epoch: 6| Step: 12
Training loss: 2.737975360583947
Validation loss: 2.52346135599994

Epoch: 6| Step: 13
Training loss: 2.895595257163982
Validation loss: 2.531635958892217

Epoch: 32| Step: 0
Training loss: 3.563547616147261
Validation loss: 2.5268320602593786

Epoch: 6| Step: 1
Training loss: 2.7953849531478485
Validation loss: 2.5212801363842283

Epoch: 6| Step: 2
Training loss: 2.770860533234217
Validation loss: 2.5127675224578

Epoch: 6| Step: 3
Training loss: 2.3598474698964673
Validation loss: 2.5378509705515966

Epoch: 6| Step: 4
Training loss: 2.7998654878186433
Validation loss: 2.5214331084654242

Epoch: 6| Step: 5
Training loss: 2.4645954375777284
Validation loss: 2.5243829451813227

Epoch: 6| Step: 6
Training loss: 3.288238349647391
Validation loss: 2.5191055053886244

Epoch: 6| Step: 7
Training loss: 2.669071801681577
Validation loss: 2.5208532288011223

Epoch: 6| Step: 8
Training loss: 3.329797458846913
Validation loss: 2.5195077007083797

Epoch: 6| Step: 9
Training loss: 2.963569216385063
Validation loss: 2.529106570526576

Epoch: 6| Step: 10
Training loss: 2.940980513159545
Validation loss: 2.5299049529886477

Epoch: 6| Step: 11
Training loss: 2.3651773208049534
Validation loss: 2.5121452035730765

Epoch: 6| Step: 12
Training loss: 2.597452577336112
Validation loss: 2.5214875512276143

Epoch: 6| Step: 13
Training loss: 2.257617453627839
Validation loss: 2.5332563625239963

Epoch: 33| Step: 0
Training loss: 2.4025653519807384
Validation loss: 2.5168878637238876

Epoch: 6| Step: 1
Training loss: 2.747893567068914
Validation loss: 2.5399323589373775

Epoch: 6| Step: 2
Training loss: 2.635019707216983
Validation loss: 2.5105288934946106

Epoch: 6| Step: 3
Training loss: 2.7171516543322314
Validation loss: 2.522230269914776

Epoch: 6| Step: 4
Training loss: 3.7988167024651536
Validation loss: 2.5287892128495315

Epoch: 6| Step: 5
Training loss: 2.326189708881574
Validation loss: 2.5369319052124966

Epoch: 6| Step: 6
Training loss: 2.6867243512431616
Validation loss: 2.514115921601438

Epoch: 6| Step: 7
Training loss: 2.59011530998733
Validation loss: 2.5165226768494775

Epoch: 6| Step: 8
Training loss: 3.20115548968122
Validation loss: 2.5217613394152494

Epoch: 6| Step: 9
Training loss: 2.461729763809016
Validation loss: 2.5301169904820875

Epoch: 6| Step: 10
Training loss: 2.7816173868021568
Validation loss: 2.520849336840982

Epoch: 6| Step: 11
Training loss: 3.0192106602329454
Validation loss: 2.5055699800652547

Epoch: 6| Step: 12
Training loss: 2.9566590491895233
Validation loss: 2.510754383116713

Epoch: 6| Step: 13
Training loss: 3.079562708292234
Validation loss: 2.514193920201087

Epoch: 34| Step: 0
Training loss: 3.5232150056205875
Validation loss: 2.520452086310561

Epoch: 6| Step: 1
Training loss: 2.231741466944763
Validation loss: 2.5202695812298517

Epoch: 6| Step: 2
Training loss: 2.8201911033646407
Validation loss: 2.5288229948768555

Epoch: 6| Step: 3
Training loss: 3.6918477435225494
Validation loss: 2.5289746064804595

Epoch: 6| Step: 4
Training loss: 2.8001825818069577
Validation loss: 2.5343955561393696

Epoch: 6| Step: 5
Training loss: 2.0604344052540213
Validation loss: 2.5169659393904915

Epoch: 6| Step: 6
Training loss: 2.7571963737766114
Validation loss: 2.5112341066187267

Epoch: 6| Step: 7
Training loss: 2.8420787553499163
Validation loss: 2.505859764785243

Epoch: 6| Step: 8
Training loss: 2.842451197222874
Validation loss: 2.5207442445266435

Epoch: 6| Step: 9
Training loss: 2.2071361415547472
Validation loss: 2.5297415647087993

Epoch: 6| Step: 10
Training loss: 3.12634629813178
Validation loss: 2.5238709690360235

Epoch: 6| Step: 11
Training loss: 2.538804355116469
Validation loss: 2.5213763849474726

Epoch: 6| Step: 12
Training loss: 3.338299167691208
Validation loss: 2.525193231247913

Epoch: 6| Step: 13
Training loss: 1.7854858361299055
Validation loss: 2.520121239325462

Epoch: 35| Step: 0
Training loss: 2.4963514406913734
Validation loss: 2.5219412206201426

Epoch: 6| Step: 1
Training loss: 3.6073074033509407
Validation loss: 2.5287342277649225

Epoch: 6| Step: 2
Training loss: 2.544229080862366
Validation loss: 2.517502612610264

Epoch: 6| Step: 3
Training loss: 2.1860565872965294
Validation loss: 2.5252714064645145

Epoch: 6| Step: 4
Training loss: 2.6685629499936128
Validation loss: 2.5266154023449254

Epoch: 6| Step: 5
Training loss: 3.7984236710303336
Validation loss: 2.530700707043491

Epoch: 6| Step: 6
Training loss: 2.6693522718458302
Validation loss: 2.5201246705706906

Epoch: 6| Step: 7
Training loss: 2.316844673544821
Validation loss: 2.5276806700883743

Epoch: 6| Step: 8
Training loss: 3.093346463482493
Validation loss: 2.525324240673608

Epoch: 6| Step: 9
Training loss: 3.1678609770894326
Validation loss: 2.520149919020727

Epoch: 6| Step: 10
Training loss: 2.489177452637026
Validation loss: 2.5233900799174203

Epoch: 6| Step: 11
Training loss: 2.610786102124209
Validation loss: 2.5282622610441448

Epoch: 6| Step: 12
Training loss: 2.9404201197017206
Validation loss: 2.525119686224343

Epoch: 6| Step: 13
Training loss: 1.766044499347493
Validation loss: 2.535842047102789

Epoch: 36| Step: 0
Training loss: 2.834301689570975
Validation loss: 2.5097294770954943

Epoch: 6| Step: 1
Training loss: 3.166368035406581
Validation loss: 2.5246748312921206

Epoch: 6| Step: 2
Training loss: 2.6335874599855824
Validation loss: 2.5126349461741935

Epoch: 6| Step: 3
Training loss: 2.466723709048301
Validation loss: 2.516542617263069

Epoch: 6| Step: 4
Training loss: 2.6172409735383777
Validation loss: 2.5175115443396745

Epoch: 6| Step: 5
Training loss: 2.485333911405886
Validation loss: 2.525215864584438

Epoch: 6| Step: 6
Training loss: 2.850137600170347
Validation loss: 2.514907830480735

Epoch: 6| Step: 7
Training loss: 2.694856555355567
Validation loss: 2.523227945186739

Epoch: 6| Step: 8
Training loss: 3.0735982537712925
Validation loss: 2.5120704121591464

Epoch: 6| Step: 9
Training loss: 3.2911069047986694
Validation loss: 2.5196504196343557

Epoch: 6| Step: 10
Training loss: 2.924816262758814
Validation loss: 2.542563217922207

Epoch: 6| Step: 11
Training loss: 2.620429465060997
Validation loss: 2.530198655074739

Epoch: 6| Step: 12
Training loss: 3.10401615742283
Validation loss: 2.5283804118082376

Epoch: 6| Step: 13
Training loss: 2.5146339312384987
Validation loss: 2.5226287089185675

Epoch: 37| Step: 0
Training loss: 1.9308729353020888
Validation loss: 2.5237522851498584

Epoch: 6| Step: 1
Training loss: 2.47546901690118
Validation loss: 2.5258975990212873

Epoch: 6| Step: 2
Training loss: 3.2179471097858947
Validation loss: 2.5226995359987563

Epoch: 6| Step: 3
Training loss: 2.5575285346713064
Validation loss: 2.5115532803730996

Epoch: 6| Step: 4
Training loss: 3.0972173507340406
Validation loss: 2.527232342230653

Epoch: 6| Step: 5
Training loss: 2.789816532733993
Validation loss: 2.5194393857600255

Epoch: 6| Step: 6
Training loss: 2.870357579939954
Validation loss: 2.5164770712440436

Epoch: 6| Step: 7
Training loss: 2.795543161751195
Validation loss: 2.5142605209100526

Epoch: 6| Step: 8
Training loss: 2.7068772925871656
Validation loss: 2.5129801184159115

Epoch: 6| Step: 9
Training loss: 3.2622631235471884
Validation loss: 2.521572854420239

Epoch: 6| Step: 10
Training loss: 3.2620845018547895
Validation loss: 2.5266853861264558

Epoch: 6| Step: 11
Training loss: 2.8329312282284707
Validation loss: 2.5165887605712833

Epoch: 6| Step: 12
Training loss: 2.6424825782165486
Validation loss: 2.5169504432138914

Epoch: 6| Step: 13
Training loss: 2.610962527581461
Validation loss: 2.521431069901905

Epoch: 38| Step: 0
Training loss: 3.132217008163781
Validation loss: 2.523389883330897

Epoch: 6| Step: 1
Training loss: 2.4931252368574013
Validation loss: 2.5198684709639716

Epoch: 6| Step: 2
Training loss: 3.0838708838561804
Validation loss: 2.5062112067050135

Epoch: 6| Step: 3
Training loss: 3.0323572397868133
Validation loss: 2.5184377767615556

Epoch: 6| Step: 4
Training loss: 3.414104679641473
Validation loss: 2.5038949455751034

Epoch: 6| Step: 5
Training loss: 2.583410959205497
Validation loss: 2.516538973315564

Epoch: 6| Step: 6
Training loss: 2.86951553668615
Validation loss: 2.5214009091366334

Epoch: 6| Step: 7
Training loss: 1.4255910250082617
Validation loss: 2.5165689458239977

Epoch: 6| Step: 8
Training loss: 2.1105908316031474
Validation loss: 2.5121782593458897

Epoch: 6| Step: 9
Training loss: 3.2950136254452906
Validation loss: 2.5146532025577306

Epoch: 6| Step: 10
Training loss: 3.2435658661723274
Validation loss: 2.517826557706129

Epoch: 6| Step: 11
Training loss: 2.2993837526138754
Validation loss: 2.520899341003467

Epoch: 6| Step: 12
Training loss: 2.433602175384191
Validation loss: 2.525350177191854

Epoch: 6| Step: 13
Training loss: 3.2299407195329106
Validation loss: 2.5122924357744885

Epoch: 39| Step: 0
Training loss: 2.9802877988668657
Validation loss: 2.5135769857259445

Epoch: 6| Step: 1
Training loss: 2.9900305720268605
Validation loss: 2.514186170719752

Epoch: 6| Step: 2
Training loss: 2.499436601097634
Validation loss: 2.511102259989339

Epoch: 6| Step: 3
Training loss: 2.3911810334266077
Validation loss: 2.5144986669500056

Epoch: 6| Step: 4
Training loss: 3.0044265514733826
Validation loss: 2.511985389431128

Epoch: 6| Step: 5
Training loss: 3.039875931717743
Validation loss: 2.5150306859229254

Epoch: 6| Step: 6
Training loss: 2.731480576059463
Validation loss: 2.5074245232119803

Epoch: 6| Step: 7
Training loss: 2.7844625200244915
Validation loss: 2.507782253138817

Epoch: 6| Step: 8
Training loss: 3.0276313497461707
Validation loss: 2.509384286800709

Epoch: 6| Step: 9
Training loss: 2.9081035978709058
Validation loss: 2.501807963445566

Epoch: 6| Step: 10
Training loss: 2.1845993428865693
Validation loss: 2.5122167568536145

Epoch: 6| Step: 11
Training loss: 3.1556764591438906
Validation loss: 2.5133575450211603

Epoch: 6| Step: 12
Training loss: 2.5604953833435786
Validation loss: 2.5093552010714855

Epoch: 6| Step: 13
Training loss: 2.883056134109136
Validation loss: 2.520787585365503

Epoch: 40| Step: 0
Training loss: 2.5993358717530386
Validation loss: 2.5083775701994018

Epoch: 6| Step: 1
Training loss: 2.6180220910139136
Validation loss: 2.511141021052299

Epoch: 6| Step: 2
Training loss: 3.412669161561726
Validation loss: 2.5126975795504034

Epoch: 6| Step: 3
Training loss: 2.379835526689657
Validation loss: 2.506837491942594

Epoch: 6| Step: 4
Training loss: 2.6442495897596987
Validation loss: 2.508596207936001

Epoch: 6| Step: 5
Training loss: 2.499145934131388
Validation loss: 2.514792631041121

Epoch: 6| Step: 6
Training loss: 3.3628246958922396
Validation loss: 2.5149105904439937

Epoch: 6| Step: 7
Training loss: 2.8882817849036733
Validation loss: 2.515422293398394

Epoch: 6| Step: 8
Training loss: 2.5405597673700946
Validation loss: 2.521481106246853

Epoch: 6| Step: 9
Training loss: 2.402302662567847
Validation loss: 2.503352767780197

Epoch: 6| Step: 10
Training loss: 2.7979268914379345
Validation loss: 2.5006871232847208

Epoch: 6| Step: 11
Training loss: 3.31303833239873
Validation loss: 2.4985591171419363

Epoch: 6| Step: 12
Training loss: 2.6500902448438715
Validation loss: 2.499049744437919

Epoch: 6| Step: 13
Training loss: 2.718362714872571
Validation loss: 2.5143328531322684

Epoch: 41| Step: 0
Training loss: 2.840814101971984
Validation loss: 2.5103813158345316

Epoch: 6| Step: 1
Training loss: 3.336344709713565
Validation loss: 2.5083294494335013

Epoch: 6| Step: 2
Training loss: 2.4756785840035747
Validation loss: 2.514083287973438

Epoch: 6| Step: 3
Training loss: 2.845609957937813
Validation loss: 2.515872401766825

Epoch: 6| Step: 4
Training loss: 2.3665436224673773
Validation loss: 2.5096713848064134

Epoch: 6| Step: 5
Training loss: 2.744995418468328
Validation loss: 2.5192447220569325

Epoch: 6| Step: 6
Training loss: 3.007883838947015
Validation loss: 2.505502568957055

Epoch: 6| Step: 7
Training loss: 1.7961630032575664
Validation loss: 2.4990839161664113

Epoch: 6| Step: 8
Training loss: 3.114808515660858
Validation loss: 2.508772673795417

Epoch: 6| Step: 9
Training loss: 2.5902922229062937
Validation loss: 2.5241746693392346

Epoch: 6| Step: 10
Training loss: 3.0246163369253467
Validation loss: 2.5171437072417415

Epoch: 6| Step: 11
Training loss: 2.438955312715987
Validation loss: 2.502940611165915

Epoch: 6| Step: 12
Training loss: 3.04322040188165
Validation loss: 2.5133333809547596

Epoch: 6| Step: 13
Training loss: 3.404525180149283
Validation loss: 2.5258096248171866

Epoch: 42| Step: 0
Training loss: 3.274168092321673
Validation loss: 2.5198766943588367

Epoch: 6| Step: 1
Training loss: 2.889411300309029
Validation loss: 2.5159366022077054

Epoch: 6| Step: 2
Training loss: 2.433983834293693
Validation loss: 2.5145638485763

Epoch: 6| Step: 3
Training loss: 2.9461037460881863
Validation loss: 2.5231037514140584

Epoch: 6| Step: 4
Training loss: 3.233131501364389
Validation loss: 2.516691105927727

Epoch: 6| Step: 5
Training loss: 2.2595417304139205
Validation loss: 2.5181167817886685

Epoch: 6| Step: 6
Training loss: 3.134571523391021
Validation loss: 2.517340604316449

Epoch: 6| Step: 7
Training loss: 2.7678514559639025
Validation loss: 2.5075706948303136

Epoch: 6| Step: 8
Training loss: 2.6481982097720227
Validation loss: 2.504555701347979

Epoch: 6| Step: 9
Training loss: 2.2528365586787755
Validation loss: 2.513140842471774

Epoch: 6| Step: 10
Training loss: 2.5429548740740855
Validation loss: 2.5160196288161703

Epoch: 6| Step: 11
Training loss: 3.187168178864462
Validation loss: 2.495769803171302

Epoch: 6| Step: 12
Training loss: 2.9319925827619504
Validation loss: 2.513182035581988

Epoch: 6| Step: 13
Training loss: 1.8454151070126612
Validation loss: 2.5096416001119524

Epoch: 43| Step: 0
Training loss: 2.643870148510062
Validation loss: 2.498310624524363

Epoch: 6| Step: 1
Training loss: 2.9923691657074922
Validation loss: 2.509430013135395

Epoch: 6| Step: 2
Training loss: 2.512707078285706
Validation loss: 2.520274984637709

Epoch: 6| Step: 3
Training loss: 2.95125670093388
Validation loss: 2.5096562705801873

Epoch: 6| Step: 4
Training loss: 2.55369021113721
Validation loss: 2.5201397230312446

Epoch: 6| Step: 5
Training loss: 2.8222509258375865
Validation loss: 2.5232307758064687

Epoch: 6| Step: 6
Training loss: 2.890952921644698
Validation loss: 2.513052992455838

Epoch: 6| Step: 7
Training loss: 2.8683170099881914
Validation loss: 2.5126623573959193

Epoch: 6| Step: 8
Training loss: 2.82792072717583
Validation loss: 2.5181984710850145

Epoch: 6| Step: 9
Training loss: 2.2966505706547884
Validation loss: 2.522197347915899

Epoch: 6| Step: 10
Training loss: 3.135291586035942
Validation loss: 2.513755861635327

Epoch: 6| Step: 11
Training loss: 2.8009074035069457
Validation loss: 2.506458064814918

Epoch: 6| Step: 12
Training loss: 2.803061861583815
Validation loss: 2.5156911979988887

Epoch: 6| Step: 13
Training loss: 2.7624438249909207
Validation loss: 2.5086295082165364

Epoch: 44| Step: 0
Training loss: 2.034118270496261
Validation loss: 2.493836257564961

Epoch: 6| Step: 1
Training loss: 2.5144870624797275
Validation loss: 2.5077066241667056

Epoch: 6| Step: 2
Training loss: 2.9570035139468707
Validation loss: 2.5120044973691216

Epoch: 6| Step: 3
Training loss: 2.89716239087981
Validation loss: 2.51627624118622

Epoch: 6| Step: 4
Training loss: 3.441550902358614
Validation loss: 2.513385251300715

Epoch: 6| Step: 5
Training loss: 2.4207359342520007
Validation loss: 2.501075617834699

Epoch: 6| Step: 6
Training loss: 3.096085716697249
Validation loss: 2.5132760778343157

Epoch: 6| Step: 7
Training loss: 3.731375539127825
Validation loss: 2.5250023565582906

Epoch: 6| Step: 8
Training loss: 2.650020340175661
Validation loss: 2.498203862913709

Epoch: 6| Step: 9
Training loss: 3.029592316397812
Validation loss: 2.514088597607672

Epoch: 6| Step: 10
Training loss: 2.2633771597542824
Validation loss: 2.525047126422833

Epoch: 6| Step: 11
Training loss: 2.1929390998034526
Validation loss: 2.523687265670376

Epoch: 6| Step: 12
Training loss: 2.565169920619133
Validation loss: 2.5054718595983942

Epoch: 6| Step: 13
Training loss: 2.621481308233985
Validation loss: 2.5129248210799373

Epoch: 45| Step: 0
Training loss: 1.9151660462743814
Validation loss: 2.506421839546362

Epoch: 6| Step: 1
Training loss: 2.860474588725042
Validation loss: 2.517621579912898

Epoch: 6| Step: 2
Training loss: 3.152989884989127
Validation loss: 2.500325247413919

Epoch: 6| Step: 3
Training loss: 2.6145691484975857
Validation loss: 2.5218140855261595

Epoch: 6| Step: 4
Training loss: 3.27076819936122
Validation loss: 2.508669461736032

Epoch: 6| Step: 5
Training loss: 2.803883471838857
Validation loss: 2.5248341641042122

Epoch: 6| Step: 6
Training loss: 3.0978626697163905
Validation loss: 2.519785032967437

Epoch: 6| Step: 7
Training loss: 2.0725480587383323
Validation loss: 2.5216433665109865

Epoch: 6| Step: 8
Training loss: 2.136835461206371
Validation loss: 2.5152273228731468

Epoch: 6| Step: 9
Training loss: 3.103059575523494
Validation loss: 2.5085642587497152

Epoch: 6| Step: 10
Training loss: 2.7591571933587935
Validation loss: 2.508139715863371

Epoch: 6| Step: 11
Training loss: 3.2272856781683803
Validation loss: 2.518087549530116

Epoch: 6| Step: 12
Training loss: 3.2411170755089613
Validation loss: 2.5013960770334815

Epoch: 6| Step: 13
Training loss: 1.7652556446581085
Validation loss: 2.520667575507644

Epoch: 46| Step: 0
Training loss: 3.0550018695132564
Validation loss: 2.5096908254941783

Epoch: 6| Step: 1
Training loss: 3.0454542711275927
Validation loss: 2.498461625325298

Epoch: 6| Step: 2
Training loss: 3.100988685702904
Validation loss: 2.5023696866566656

Epoch: 6| Step: 3
Training loss: 2.5207863690333703
Validation loss: 2.5004999952850913

Epoch: 6| Step: 4
Training loss: 2.177783749965774
Validation loss: 2.4971199941060327

Epoch: 6| Step: 5
Training loss: 2.8952695082690827
Validation loss: 2.507118706449952

Epoch: 6| Step: 6
Training loss: 1.8044689756259547
Validation loss: 2.50855718476489

Epoch: 6| Step: 7
Training loss: 3.0417710029439404
Validation loss: 2.5087286123988704

Epoch: 6| Step: 8
Training loss: 2.866267667400678
Validation loss: 2.50122354980996

Epoch: 6| Step: 9
Training loss: 2.6821420177206607
Validation loss: 2.5033835924841865

Epoch: 6| Step: 10
Training loss: 2.5887385292849006
Validation loss: 2.5102426125383674

Epoch: 6| Step: 11
Training loss: 3.0145362904816486
Validation loss: 2.5157811335443423

Epoch: 6| Step: 12
Training loss: 3.010241511088126
Validation loss: 2.506195552990331

Epoch: 6| Step: 13
Training loss: 2.939739753207647
Validation loss: 2.506698236650652

Epoch: 47| Step: 0
Training loss: 2.747874045071594
Validation loss: 2.489677995476557

Epoch: 6| Step: 1
Training loss: 2.2206193812541057
Validation loss: 2.5096937811928384

Epoch: 6| Step: 2
Training loss: 2.8243785512200805
Validation loss: 2.4997989881366354

Epoch: 6| Step: 3
Training loss: 3.305938556042463
Validation loss: 2.504541659687495

Epoch: 6| Step: 4
Training loss: 2.371373670668016
Validation loss: 2.4981009602645785

Epoch: 6| Step: 5
Training loss: 2.827061996060846
Validation loss: 2.509702687084621

Epoch: 6| Step: 6
Training loss: 2.367709363564299
Validation loss: 2.4994853751348045

Epoch: 6| Step: 7
Training loss: 3.159749121545633
Validation loss: 2.5137177069152083

Epoch: 6| Step: 8
Training loss: 3.30969479378246
Validation loss: 2.5213103301146833

Epoch: 6| Step: 9
Training loss: 2.120853192649248
Validation loss: 2.5128010954636846

Epoch: 6| Step: 10
Training loss: 2.6323834078075867
Validation loss: 2.5072105139338015

Epoch: 6| Step: 11
Training loss: 2.6335288864472237
Validation loss: 2.519215322765363

Epoch: 6| Step: 12
Training loss: 3.2374653818054444
Validation loss: 2.5235608057208605

Epoch: 6| Step: 13
Training loss: 2.509906975591535
Validation loss: 2.500119222854033

Epoch: 48| Step: 0
Training loss: 3.2800098800510376
Validation loss: 2.5019656421632317

Epoch: 6| Step: 1
Training loss: 2.693636696682951
Validation loss: 2.5143193065482525

Epoch: 6| Step: 2
Training loss: 2.9227277357979378
Validation loss: 2.5142822738160335

Epoch: 6| Step: 3
Training loss: 2.159096870231613
Validation loss: 2.51114448396536

Epoch: 6| Step: 4
Training loss: 2.530908632218609
Validation loss: 2.5227406522923763

Epoch: 6| Step: 5
Training loss: 3.298119621915844
Validation loss: 2.502133551148611

Epoch: 6| Step: 6
Training loss: 2.568492024408381
Validation loss: 2.5098749879337583

Epoch: 6| Step: 7
Training loss: 2.6423105131148543
Validation loss: 2.5103517279797365

Epoch: 6| Step: 8
Training loss: 2.5833123934317554
Validation loss: 2.5152865853357227

Epoch: 6| Step: 9
Training loss: 2.408170156879718
Validation loss: 2.503025650249252

Epoch: 6| Step: 10
Training loss: 3.5073997747521797
Validation loss: 2.508145478616222

Epoch: 6| Step: 11
Training loss: 2.776694005836938
Validation loss: 2.4997179825978755

Epoch: 6| Step: 12
Training loss: 2.3556353508531336
Validation loss: 2.5042632648028773

Epoch: 6| Step: 13
Training loss: 2.739609944222786
Validation loss: 2.4952869319736632

Epoch: 49| Step: 0
Training loss: 2.8440206210304946
Validation loss: 2.502314285983311

Epoch: 6| Step: 1
Training loss: 3.368532270709823
Validation loss: 2.5039113713248677

Epoch: 6| Step: 2
Training loss: 2.7083898000454956
Validation loss: 2.5055797017590953

Epoch: 6| Step: 3
Training loss: 2.9385964802404634
Validation loss: 2.508550901757885

Epoch: 6| Step: 4
Training loss: 2.7283312462868823
Validation loss: 2.508973239530019

Epoch: 6| Step: 5
Training loss: 2.8245786909721846
Validation loss: 2.4978030385619308

Epoch: 6| Step: 6
Training loss: 3.5120480121033153
Validation loss: 2.489628155064946

Epoch: 6| Step: 7
Training loss: 1.769982960290301
Validation loss: 2.494013686570727

Epoch: 6| Step: 8
Training loss: 2.648349726750038
Validation loss: 2.5094935018791857

Epoch: 6| Step: 9
Training loss: 2.6428707888335605
Validation loss: 2.503441667857909

Epoch: 6| Step: 10
Training loss: 1.9965127105881493
Validation loss: 2.5123963153153963

Epoch: 6| Step: 11
Training loss: 2.2564084660471857
Validation loss: 2.5020008591570377

Epoch: 6| Step: 12
Training loss: 2.656071286640857
Validation loss: 2.5085030750704167

Epoch: 6| Step: 13
Training loss: 3.4189812953333565
Validation loss: 2.4990365540729185

Epoch: 50| Step: 0
Training loss: 2.6870464563247256
Validation loss: 2.501953465185683

Epoch: 6| Step: 1
Training loss: 2.2002506850208716
Validation loss: 2.511094698005472

Epoch: 6| Step: 2
Training loss: 3.056518318239943
Validation loss: 2.50177717210154

Epoch: 6| Step: 3
Training loss: 2.9926207704322576
Validation loss: 2.49768387553222

Epoch: 6| Step: 4
Training loss: 2.130078698078962
Validation loss: 2.4980747818784104

Epoch: 6| Step: 5
Training loss: 2.5009876207779733
Validation loss: 2.5011140258860105

Epoch: 6| Step: 6
Training loss: 2.6725881416766253
Validation loss: 2.5012862803459446

Epoch: 6| Step: 7
Training loss: 2.2199241862368093
Validation loss: 2.4991843410648036

Epoch: 6| Step: 8
Training loss: 3.081241791812882
Validation loss: 2.5055738701797625

Epoch: 6| Step: 9
Training loss: 2.954094621634408
Validation loss: 2.509721262843681

Epoch: 6| Step: 10
Training loss: 3.4203384642401895
Validation loss: 2.484995050460651

Epoch: 6| Step: 11
Training loss: 3.2331691097227546
Validation loss: 2.4909408341291055

Epoch: 6| Step: 12
Training loss: 2.4195398701904383
Validation loss: 2.511251600166143

Epoch: 6| Step: 13
Training loss: 2.7138888868498716
Validation loss: 2.508695948545821

Epoch: 51| Step: 0
Training loss: 2.073173877598744
Validation loss: 2.503637706713085

Epoch: 6| Step: 1
Training loss: 3.0627410171024576
Validation loss: 2.498942860777438

Epoch: 6| Step: 2
Training loss: 2.6790019679331056
Validation loss: 2.4945811435609944

Epoch: 6| Step: 3
Training loss: 3.069402273434049
Validation loss: 2.4961185030753197

Epoch: 6| Step: 4
Training loss: 2.334425216604495
Validation loss: 2.5063841214248903

Epoch: 6| Step: 5
Training loss: 2.92519642749069
Validation loss: 2.5018525253507495

Epoch: 6| Step: 6
Training loss: 2.843158870083532
Validation loss: 2.505337531179386

Epoch: 6| Step: 7
Training loss: 2.2831173922299484
Validation loss: 2.5023417334226554

Epoch: 6| Step: 8
Training loss: 3.3279714056400502
Validation loss: 2.5078266593066463

Epoch: 6| Step: 9
Training loss: 3.486044171734655
Validation loss: 2.5073980296173346

Epoch: 6| Step: 10
Training loss: 2.58451375346658
Validation loss: 2.5007192233421907

Epoch: 6| Step: 11
Training loss: 3.0103707667528785
Validation loss: 2.504115469402047

Epoch: 6| Step: 12
Training loss: 1.4712701644099018
Validation loss: 2.5101639294421565

Epoch: 6| Step: 13
Training loss: 2.8253878841969633
Validation loss: 2.511251781879523

Epoch: 52| Step: 0
Training loss: 2.9112548393055326
Validation loss: 2.51185559387184

Epoch: 6| Step: 1
Training loss: 2.602804534713057
Validation loss: 2.5129697301098686

Epoch: 6| Step: 2
Training loss: 2.8474569787316435
Validation loss: 2.503838608520033

Epoch: 6| Step: 3
Training loss: 2.542341257426679
Validation loss: 2.5083520325708544

Epoch: 6| Step: 4
Training loss: 2.7560368946412934
Validation loss: 2.4951419143024665

Epoch: 6| Step: 5
Training loss: 2.9686780418910788
Validation loss: 2.5134523752617874

Epoch: 6| Step: 6
Training loss: 2.430278939143797
Validation loss: 2.5098379978977796

Epoch: 6| Step: 7
Training loss: 2.675449679359694
Validation loss: 2.5086431361104613

Epoch: 6| Step: 8
Training loss: 2.9176441916011933
Validation loss: 2.4948864147989043

Epoch: 6| Step: 9
Training loss: 2.8270953079528507
Validation loss: 2.496362821380927

Epoch: 6| Step: 10
Training loss: 3.3200716537188826
Validation loss: 2.50014338082186

Epoch: 6| Step: 11
Training loss: 2.7726705860875502
Validation loss: 2.502264001608165

Epoch: 6| Step: 12
Training loss: 2.6439094657691276
Validation loss: 2.494828635567891

Epoch: 6| Step: 13
Training loss: 1.6603661258652491
Validation loss: 2.5194581441153345

Epoch: 53| Step: 0
Training loss: 2.1076607979716853
Validation loss: 2.512374011387707

Epoch: 6| Step: 1
Training loss: 2.8783463615589437
Validation loss: 2.4944997427388658

Epoch: 6| Step: 2
Training loss: 2.6055832227183755
Validation loss: 2.5126212700400425

Epoch: 6| Step: 3
Training loss: 2.4355379668855233
Validation loss: 2.4990950730920085

Epoch: 6| Step: 4
Training loss: 1.9488758710592933
Validation loss: 2.5040701927231246

Epoch: 6| Step: 5
Training loss: 2.64597622543115
Validation loss: 2.503083859903508

Epoch: 6| Step: 6
Training loss: 3.1208242364469876
Validation loss: 2.4929715098390006

Epoch: 6| Step: 7
Training loss: 2.272433029547691
Validation loss: 2.5009430901025502

Epoch: 6| Step: 8
Training loss: 3.438914337502275
Validation loss: 2.499730057652801

Epoch: 6| Step: 9
Training loss: 2.888348647082705
Validation loss: 2.5014673110890078

Epoch: 6| Step: 10
Training loss: 2.7250886885183254
Validation loss: 2.498036797125932

Epoch: 6| Step: 11
Training loss: 3.1783442928910066
Validation loss: 2.5106396956223542

Epoch: 6| Step: 12
Training loss: 3.4110005700103363
Validation loss: 2.498421705066076

Epoch: 6| Step: 13
Training loss: 1.85002432884509
Validation loss: 2.508047954659091

Epoch: 54| Step: 0
Training loss: 2.644388079465519
Validation loss: 2.501861193247178

Epoch: 6| Step: 1
Training loss: 3.3198046486613393
Validation loss: 2.508804572300274

Epoch: 6| Step: 2
Training loss: 2.9394690224860804
Validation loss: 2.4904678794385324

Epoch: 6| Step: 3
Training loss: 2.2981106295537046
Validation loss: 2.5108616425661574

Epoch: 6| Step: 4
Training loss: 2.707736805486842
Validation loss: 2.489941369452139

Epoch: 6| Step: 5
Training loss: 3.0082338508648654
Validation loss: 2.4921356667941588

Epoch: 6| Step: 6
Training loss: 2.8750066342484595
Validation loss: 2.5092072662637968

Epoch: 6| Step: 7
Training loss: 2.7209604857693925
Validation loss: 2.509280562503265

Epoch: 6| Step: 8
Training loss: 2.989377128764612
Validation loss: 2.501612363798734

Epoch: 6| Step: 9
Training loss: 2.7496788530964875
Validation loss: 2.504654317279876

Epoch: 6| Step: 10
Training loss: 2.496531464549387
Validation loss: 2.495752585280251

Epoch: 6| Step: 11
Training loss: 2.4619934722913017
Validation loss: 2.4938606259669243

Epoch: 6| Step: 12
Training loss: 2.5010655993156354
Validation loss: 2.4999779546442475

Epoch: 6| Step: 13
Training loss: 2.654335049768021
Validation loss: 2.5131232111001345

Epoch: 55| Step: 0
Training loss: 2.6948988445031645
Validation loss: 2.501749941861329

Epoch: 6| Step: 1
Training loss: 2.131919590090311
Validation loss: 2.5023072793642984

Epoch: 6| Step: 2
Training loss: 3.058815744657665
Validation loss: 2.4862954246363778

Epoch: 6| Step: 3
Training loss: 3.3239909541148136
Validation loss: 2.477918887538993

Epoch: 6| Step: 4
Training loss: 2.613001148397352
Validation loss: 2.4960386136733925

Epoch: 6| Step: 5
Training loss: 2.6034388834924793
Validation loss: 2.49419285234549

Epoch: 6| Step: 6
Training loss: 3.156853344347774
Validation loss: 2.500298399190663

Epoch: 6| Step: 7
Training loss: 2.8886159152477773
Validation loss: 2.5063682417173037

Epoch: 6| Step: 8
Training loss: 2.5469518544589502
Validation loss: 2.4885727769932595

Epoch: 6| Step: 9
Training loss: 2.8678694493522245
Validation loss: 2.495492729850252

Epoch: 6| Step: 10
Training loss: 2.6064694611798136
Validation loss: 2.5009733417724713

Epoch: 6| Step: 11
Training loss: 2.8096186819676303
Validation loss: 2.497701974104257

Epoch: 6| Step: 12
Training loss: 2.4927455552336677
Validation loss: 2.5041164215088356

Epoch: 6| Step: 13
Training loss: 2.2955398311960664
Validation loss: 2.4912050347240107

Epoch: 56| Step: 0
Training loss: 2.556189326006946
Validation loss: 2.4879260758917088

Epoch: 6| Step: 1
Training loss: 2.740018764069621
Validation loss: 2.4898404327475196

Epoch: 6| Step: 2
Training loss: 2.751056381546373
Validation loss: 2.491699167820814

Epoch: 6| Step: 3
Training loss: 1.9284481130260644
Validation loss: 2.5040560449368026

Epoch: 6| Step: 4
Training loss: 2.4218913416157344
Validation loss: 2.492533053901215

Epoch: 6| Step: 5
Training loss: 3.115347335824233
Validation loss: 2.4788914889085234

Epoch: 6| Step: 6
Training loss: 3.2694621198448814
Validation loss: 2.5008851555751415

Epoch: 6| Step: 7
Training loss: 2.666252869051406
Validation loss: 2.4811990448499825

Epoch: 6| Step: 8
Training loss: 2.553692638557765
Validation loss: 2.4738183322707483

Epoch: 6| Step: 9
Training loss: 2.0039561007063877
Validation loss: 2.498114198671311

Epoch: 6| Step: 10
Training loss: 2.635903917787246
Validation loss: 2.49498545504392

Epoch: 6| Step: 11
Training loss: 3.1463114562490664
Validation loss: 2.4923552201672154

Epoch: 6| Step: 12
Training loss: 3.535262267488334
Validation loss: 2.5004271152662847

Epoch: 6| Step: 13
Training loss: 2.5873729029598627
Validation loss: 2.4828637664907864

Epoch: 57| Step: 0
Training loss: 3.044535359729071
Validation loss: 2.5033646061499444

Epoch: 6| Step: 1
Training loss: 2.6386577795006567
Validation loss: 2.483875238064389

Epoch: 6| Step: 2
Training loss: 2.844675605126335
Validation loss: 2.480324585846183

Epoch: 6| Step: 3
Training loss: 2.4812950380018886
Validation loss: 2.4914787993183327

Epoch: 6| Step: 4
Training loss: 2.836612001184454
Validation loss: 2.5175052587313274

Epoch: 6| Step: 5
Training loss: 2.5944014500992987
Validation loss: 2.4896163430232834

Epoch: 6| Step: 6
Training loss: 3.5708695192109694
Validation loss: 2.4900585890898435

Epoch: 6| Step: 7
Training loss: 2.5680931272406506
Validation loss: 2.487552898304382

Epoch: 6| Step: 8
Training loss: 2.664688707961843
Validation loss: 2.4852034511619316

Epoch: 6| Step: 9
Training loss: 2.8400230718400836
Validation loss: 2.50375329960007

Epoch: 6| Step: 10
Training loss: 1.9317470787345172
Validation loss: 2.505607221371279

Epoch: 6| Step: 11
Training loss: 2.7269834177137637
Validation loss: 2.5095943121292583

Epoch: 6| Step: 12
Training loss: 2.928095270451731
Validation loss: 2.4887326678908566

Epoch: 6| Step: 13
Training loss: 2.0430007261031284
Validation loss: 2.4871469621576967

Epoch: 58| Step: 0
Training loss: 2.8111257798570666
Validation loss: 2.499889567202361

Epoch: 6| Step: 1
Training loss: 2.617757342348211
Validation loss: 2.49504378754477

Epoch: 6| Step: 2
Training loss: 2.5348277297916044
Validation loss: 2.506150564510882

Epoch: 6| Step: 3
Training loss: 2.9873150628599654
Validation loss: 2.4964408724940115

Epoch: 6| Step: 4
Training loss: 2.496554193429167
Validation loss: 2.493763377094928

Epoch: 6| Step: 5
Training loss: 2.7354320117978097
Validation loss: 2.5072746079517074

Epoch: 6| Step: 6
Training loss: 2.7959267484595274
Validation loss: 2.492372872965829

Epoch: 6| Step: 7
Training loss: 2.3988929340979634
Validation loss: 2.4995539892899377

Epoch: 6| Step: 8
Training loss: 3.376328383506481
Validation loss: 2.499614550501683

Epoch: 6| Step: 9
Training loss: 2.663960653466979
Validation loss: 2.50052527477629

Epoch: 6| Step: 10
Training loss: 2.79246727769714
Validation loss: 2.4756616074586586

Epoch: 6| Step: 11
Training loss: 2.4553946910811013
Validation loss: 2.4904734247084965

Epoch: 6| Step: 12
Training loss: 2.906936728446025
Validation loss: 2.475952765901323

Epoch: 6| Step: 13
Training loss: 2.2384777681849886
Validation loss: 2.4919547276613865

Epoch: 59| Step: 0
Training loss: 2.6733280268717143
Validation loss: 2.471627229220162

Epoch: 6| Step: 1
Training loss: 2.7377016594173593
Validation loss: 2.490490902470428

Epoch: 6| Step: 2
Training loss: 2.282252783700192
Validation loss: 2.5028250227411926

Epoch: 6| Step: 3
Training loss: 3.2483666056740574
Validation loss: 2.4846923381921493

Epoch: 6| Step: 4
Training loss: 3.3783851883278335
Validation loss: 2.49373858059581

Epoch: 6| Step: 5
Training loss: 2.739511254429697
Validation loss: 2.476558387302379

Epoch: 6| Step: 6
Training loss: 2.9532422239258858
Validation loss: 2.4895107838635324

Epoch: 6| Step: 7
Training loss: 2.1831344640107857
Validation loss: 2.497547472045708

Epoch: 6| Step: 8
Training loss: 2.8623105182152315
Validation loss: 2.483906151729178

Epoch: 6| Step: 9
Training loss: 2.2628660042975945
Validation loss: 2.4842288881803625

Epoch: 6| Step: 10
Training loss: 2.878917512910465
Validation loss: 2.488207092019778

Epoch: 6| Step: 11
Training loss: 2.5367469910558405
Validation loss: 2.476812499439314

Epoch: 6| Step: 12
Training loss: 1.9870293353852118
Validation loss: 2.492542244812624

Epoch: 6| Step: 13
Training loss: 3.391124635791376
Validation loss: 2.4849393521825425

Epoch: 60| Step: 0
Training loss: 2.824530155641496
Validation loss: 2.4955449376305157

Epoch: 6| Step: 1
Training loss: 3.1762905111360347
Validation loss: 2.484092160227057

Epoch: 6| Step: 2
Training loss: 2.8765183461461414
Validation loss: 2.504094210708344

Epoch: 6| Step: 3
Training loss: 2.101896351669806
Validation loss: 2.5045431920113206

Epoch: 6| Step: 4
Training loss: 2.1918156151385957
Validation loss: 2.500508765268527

Epoch: 6| Step: 5
Training loss: 2.2022102567196042
Validation loss: 2.506455447432284

Epoch: 6| Step: 6
Training loss: 2.750643828192588
Validation loss: 2.513282243964956

Epoch: 6| Step: 7
Training loss: 2.916038027637069
Validation loss: 2.4945769824658073

Epoch: 6| Step: 8
Training loss: 2.551271540444783
Validation loss: 2.5129835288069313

Epoch: 6| Step: 9
Training loss: 2.3637760369507403
Validation loss: 2.4912540409245594

Epoch: 6| Step: 10
Training loss: 3.6297155818435862
Validation loss: 2.4924697482126374

Epoch: 6| Step: 11
Training loss: 2.415432932967113
Validation loss: 2.4892466083936595

Epoch: 6| Step: 12
Training loss: 2.942249921804053
Validation loss: 2.4870856479363823

Epoch: 6| Step: 13
Training loss: 2.791962384935159
Validation loss: 2.502139667894809

Epoch: 61| Step: 0
Training loss: 2.475047806557456
Validation loss: 2.4948797330936947

Epoch: 6| Step: 1
Training loss: 2.4983601914230955
Validation loss: 2.5023007634676278

Epoch: 6| Step: 2
Training loss: 2.9139417362501847
Validation loss: 2.496114612090134

Epoch: 6| Step: 3
Training loss: 2.781231655103211
Validation loss: 2.4974076007101838

Epoch: 6| Step: 4
Training loss: 2.8942132896170416
Validation loss: 2.5068161407711296

Epoch: 6| Step: 5
Training loss: 3.2089849693776076
Validation loss: 2.4986118400426274

Epoch: 6| Step: 6
Training loss: 2.6458015940607256
Validation loss: 2.4963348953642694

Epoch: 6| Step: 7
Training loss: 2.5379202283342526
Validation loss: 2.496076415203623

Epoch: 6| Step: 8
Training loss: 2.839165985791082
Validation loss: 2.507786081552086

Epoch: 6| Step: 9
Training loss: 2.513563650271961
Validation loss: 2.50368833928663

Epoch: 6| Step: 10
Training loss: 2.4658464184880438
Validation loss: 2.5048188589063938

Epoch: 6| Step: 11
Training loss: 1.8747690694378076
Validation loss: 2.498399699141661

Epoch: 6| Step: 12
Training loss: 3.073642313134662
Validation loss: 2.492270275768687

Epoch: 6| Step: 13
Training loss: 3.474230586435594
Validation loss: 2.4975414574771926

Epoch: 62| Step: 0
Training loss: 2.6587083099640556
Validation loss: 2.510815809568884

Epoch: 6| Step: 1
Training loss: 2.820859565406286
Validation loss: 2.509598840593731

Epoch: 6| Step: 2
Training loss: 3.009885395694468
Validation loss: 2.4880596813126004

Epoch: 6| Step: 3
Training loss: 2.2227004437335323
Validation loss: 2.4962352072165883

Epoch: 6| Step: 4
Training loss: 2.8503124266587743
Validation loss: 2.5059615989624726

Epoch: 6| Step: 5
Training loss: 2.682511334853031
Validation loss: 2.5024282537395313

Epoch: 6| Step: 6
Training loss: 2.649641275417715
Validation loss: 2.493609899146006

Epoch: 6| Step: 7
Training loss: 2.0828319963600124
Validation loss: 2.5017684793204498

Epoch: 6| Step: 8
Training loss: 3.089431059967513
Validation loss: 2.4932711064918913

Epoch: 6| Step: 9
Training loss: 2.920934678812278
Validation loss: 2.501085488712023

Epoch: 6| Step: 10
Training loss: 3.157604568936638
Validation loss: 2.491651214700954

Epoch: 6| Step: 11
Training loss: 2.3690437114671483
Validation loss: 2.501651761232069

Epoch: 6| Step: 12
Training loss: 2.576057946358984
Validation loss: 2.486516219525021

Epoch: 6| Step: 13
Training loss: 2.8436589488449897
Validation loss: 2.492523817700506

Epoch: 63| Step: 0
Training loss: 1.6895313046398135
Validation loss: 2.492204084176274

Epoch: 6| Step: 1
Training loss: 2.502312830157229
Validation loss: 2.492757038774513

Epoch: 6| Step: 2
Training loss: 3.270176685937776
Validation loss: 2.486984315976494

Epoch: 6| Step: 3
Training loss: 2.889268546547694
Validation loss: 2.493181655587978

Epoch: 6| Step: 4
Training loss: 2.4397885265324164
Validation loss: 2.4873081315490126

Epoch: 6| Step: 5
Training loss: 2.38866588626089
Validation loss: 2.4999717680044564

Epoch: 6| Step: 6
Training loss: 3.217954666984843
Validation loss: 2.4927748656173163

Epoch: 6| Step: 7
Training loss: 1.908475546000846
Validation loss: 2.498279255188394

Epoch: 6| Step: 8
Training loss: 2.627975866053068
Validation loss: 2.4932144964750393

Epoch: 6| Step: 9
Training loss: 3.027917189893095
Validation loss: 2.5064613766847677

Epoch: 6| Step: 10
Training loss: 2.9364247078722183
Validation loss: 2.488835743626888

Epoch: 6| Step: 11
Training loss: 2.866086493784854
Validation loss: 2.497297907890419

Epoch: 6| Step: 12
Training loss: 3.028799738080013
Validation loss: 2.4959475389573735

Epoch: 6| Step: 13
Training loss: 2.7097381665192875
Validation loss: 2.499904434879676

Epoch: 64| Step: 0
Training loss: 3.074513286746118
Validation loss: 2.489618479718783

Epoch: 6| Step: 1
Training loss: 2.6543823857178857
Validation loss: 2.497579288610438

Epoch: 6| Step: 2
Training loss: 2.5215649344460536
Validation loss: 2.485212652675041

Epoch: 6| Step: 3
Training loss: 2.7714706968974046
Validation loss: 2.4981034653049083

Epoch: 6| Step: 4
Training loss: 2.4491875021369394
Validation loss: 2.4903080556844306

Epoch: 6| Step: 5
Training loss: 2.6788011870164135
Validation loss: 2.499815101348953

Epoch: 6| Step: 6
Training loss: 2.9450774162233544
Validation loss: 2.4908752978104527

Epoch: 6| Step: 7
Training loss: 3.2836245709392506
Validation loss: 2.49664600125155

Epoch: 6| Step: 8
Training loss: 2.337619137915275
Validation loss: 2.491629227176463

Epoch: 6| Step: 9
Training loss: 2.138927259830371
Validation loss: 2.4894512373333617

Epoch: 6| Step: 10
Training loss: 2.181346740326256
Validation loss: 2.492277430955199

Epoch: 6| Step: 11
Training loss: 3.424312193925204
Validation loss: 2.5007919749077745

Epoch: 6| Step: 12
Training loss: 2.418379494532989
Validation loss: 2.4947797941242698

Epoch: 6| Step: 13
Training loss: 2.9327661233201394
Validation loss: 2.48331819876418

Epoch: 65| Step: 0
Training loss: 1.7063861387388204
Validation loss: 2.4911566182608875

Epoch: 6| Step: 1
Training loss: 2.9312355935855
Validation loss: 2.49151075254459

Epoch: 6| Step: 2
Training loss: 2.7778043512556785
Validation loss: 2.485424011439389

Epoch: 6| Step: 3
Training loss: 3.342260296257527
Validation loss: 2.483280629387939

Epoch: 6| Step: 4
Training loss: 2.609164840549775
Validation loss: 2.4892689248968662

Epoch: 6| Step: 5
Training loss: 2.5398932873093685
Validation loss: 2.4957758122510034

Epoch: 6| Step: 6
Training loss: 2.696852534301117
Validation loss: 2.4948068702616926

Epoch: 6| Step: 7
Training loss: 2.362287025338324
Validation loss: 2.490476966798553

Epoch: 6| Step: 8
Training loss: 2.991769467626862
Validation loss: 2.4977138577320774

Epoch: 6| Step: 9
Training loss: 2.810934012274622
Validation loss: 2.4831487903654117

Epoch: 6| Step: 10
Training loss: 2.6789702854195925
Validation loss: 2.4848202831123674

Epoch: 6| Step: 11
Training loss: 2.4952012736565217
Validation loss: 2.4904106410725255

Epoch: 6| Step: 12
Training loss: 3.0424428149877696
Validation loss: 2.4978840025428637

Epoch: 6| Step: 13
Training loss: 2.5980460197184634
Validation loss: 2.490626602891828

Epoch: 66| Step: 0
Training loss: 2.672374388666278
Validation loss: 2.4830482445075583

Epoch: 6| Step: 1
Training loss: 2.4459441225433274
Validation loss: 2.499893832259685

Epoch: 6| Step: 2
Training loss: 2.8454306530288678
Validation loss: 2.4844710917769115

Epoch: 6| Step: 3
Training loss: 3.5954553952888526
Validation loss: 2.469724974319554

Epoch: 6| Step: 4
Training loss: 2.882612516088091
Validation loss: 2.4951725465932797

Epoch: 6| Step: 5
Training loss: 2.4072624157446643
Validation loss: 2.4986771929381035

Epoch: 6| Step: 6
Training loss: 2.3286835685260026
Validation loss: 2.491980210088158

Epoch: 6| Step: 7
Training loss: 3.105661139136886
Validation loss: 2.4980667489205968

Epoch: 6| Step: 8
Training loss: 2.260172630063462
Validation loss: 2.4981838695052003

Epoch: 6| Step: 9
Training loss: 2.5874628368417882
Validation loss: 2.490460484353528

Epoch: 6| Step: 10
Training loss: 2.0994993385046805
Validation loss: 2.4878477380655455

Epoch: 6| Step: 11
Training loss: 2.444173139148895
Validation loss: 2.4877550954539367

Epoch: 6| Step: 12
Training loss: 2.58738681711526
Validation loss: 2.4860903843577717

Epoch: 6| Step: 13
Training loss: 3.5539614428487907
Validation loss: 2.4901532137772886

Epoch: 67| Step: 0
Training loss: 2.681222726109645
Validation loss: 2.4925664818733937

Epoch: 6| Step: 1
Training loss: 2.085960816670947
Validation loss: 2.483460945236096

Epoch: 6| Step: 2
Training loss: 3.0074131291781683
Validation loss: 2.4934102444217023

Epoch: 6| Step: 3
Training loss: 2.393347393072515
Validation loss: 2.492979636854828

Epoch: 6| Step: 4
Training loss: 2.6632576450992658
Validation loss: 2.508655227476691

Epoch: 6| Step: 5
Training loss: 2.9759740372930152
Validation loss: 2.5000154535779884

Epoch: 6| Step: 6
Training loss: 3.0683752262281523
Validation loss: 2.502818544042978

Epoch: 6| Step: 7
Training loss: 2.4682565509806187
Validation loss: 2.502904737012723

Epoch: 6| Step: 8
Training loss: 2.2170629400491
Validation loss: 2.503204320521595

Epoch: 6| Step: 9
Training loss: 2.8607819644602683
Validation loss: 2.4854851815071437

Epoch: 6| Step: 10
Training loss: 3.0236970854123357
Validation loss: 2.478712352744612

Epoch: 6| Step: 11
Training loss: 3.2475942363971186
Validation loss: 2.4797396192104273

Epoch: 6| Step: 12
Training loss: 2.1578747805944594
Validation loss: 2.477049866865468

Epoch: 6| Step: 13
Training loss: 2.7822827768320653
Validation loss: 2.4987927834308623

Epoch: 68| Step: 0
Training loss: 3.436380238651172
Validation loss: 2.498839881350437

Epoch: 6| Step: 1
Training loss: 3.0289241086734933
Validation loss: 2.486053187377496

Epoch: 6| Step: 2
Training loss: 2.5299096031776007
Validation loss: 2.4982220274993088

Epoch: 6| Step: 3
Training loss: 2.2118893788288836
Validation loss: 2.4947188653179446

Epoch: 6| Step: 4
Training loss: 1.8556100249465153
Validation loss: 2.4917526161426387

Epoch: 6| Step: 5
Training loss: 3.114783256178701
Validation loss: 2.492193759454265

Epoch: 6| Step: 6
Training loss: 2.5732486732010296
Validation loss: 2.492148557303351

Epoch: 6| Step: 7
Training loss: 2.848381714057484
Validation loss: 2.4849949225362726

Epoch: 6| Step: 8
Training loss: 2.5476365150358755
Validation loss: 2.4850221898812754

Epoch: 6| Step: 9
Training loss: 3.1846718302586328
Validation loss: 2.4882485052438406

Epoch: 6| Step: 10
Training loss: 2.32601443894186
Validation loss: 2.5046828649692663

Epoch: 6| Step: 11
Training loss: 2.4121457487136033
Validation loss: 2.5008633368814635

Epoch: 6| Step: 12
Training loss: 2.7166669911889505
Validation loss: 2.4834641881587656

Epoch: 6| Step: 13
Training loss: 2.590500876256651
Validation loss: 2.489165397455395

Epoch: 69| Step: 0
Training loss: 2.3109342068228944
Validation loss: 2.5016932639321205

Epoch: 6| Step: 1
Training loss: 2.5474776040722147
Validation loss: 2.48780111731999

Epoch: 6| Step: 2
Training loss: 2.3872403388100034
Validation loss: 2.495750303351221

Epoch: 6| Step: 3
Training loss: 3.174915528863324
Validation loss: 2.4831678507422796

Epoch: 6| Step: 4
Training loss: 2.4470054932701393
Validation loss: 2.5035719149899833

Epoch: 6| Step: 5
Training loss: 2.512130489981332
Validation loss: 2.4856517284677744

Epoch: 6| Step: 6
Training loss: 3.5779991960689865
Validation loss: 2.488867590700064

Epoch: 6| Step: 7
Training loss: 2.6781110658583596
Validation loss: 2.4950307111177326

Epoch: 6| Step: 8
Training loss: 2.565536374827682
Validation loss: 2.498050069739168

Epoch: 6| Step: 9
Training loss: 2.5899350709766837
Validation loss: 2.4910048548307864

Epoch: 6| Step: 10
Training loss: 2.5007654925454434
Validation loss: 2.5031758000086897

Epoch: 6| Step: 11
Training loss: 2.4983607640031886
Validation loss: 2.4895192908357626

Epoch: 6| Step: 12
Training loss: 2.9036266012652514
Validation loss: 2.4776515365483207

Epoch: 6| Step: 13
Training loss: 2.950543117635443
Validation loss: 2.490197876661359

Epoch: 70| Step: 0
Training loss: 2.637309684937963
Validation loss: 2.491552523459176

Epoch: 6| Step: 1
Training loss: 2.7003818771726076
Validation loss: 2.4703578749419344

Epoch: 6| Step: 2
Training loss: 2.2982935255483876
Validation loss: 2.49543532627874

Epoch: 6| Step: 3
Training loss: 2.654406816845603
Validation loss: 2.4898141283818207

Epoch: 6| Step: 4
Training loss: 2.9905017855303573
Validation loss: 2.505239810933031

Epoch: 6| Step: 5
Training loss: 2.6121037086823544
Validation loss: 2.4858290176799938

Epoch: 6| Step: 6
Training loss: 2.4693571865063957
Validation loss: 2.493185821582595

Epoch: 6| Step: 7
Training loss: 2.8322361523396364
Validation loss: 2.488987575456703

Epoch: 6| Step: 8
Training loss: 2.6014881753471313
Validation loss: 2.493467919777047

Epoch: 6| Step: 9
Training loss: 3.0717894129894234
Validation loss: 2.480984510370763

Epoch: 6| Step: 10
Training loss: 2.6051916521268685
Validation loss: 2.488189666217064

Epoch: 6| Step: 11
Training loss: 2.3031091490242783
Validation loss: 2.4997091483055236

Epoch: 6| Step: 12
Training loss: 3.061291670354036
Validation loss: 2.4935461889898636

Epoch: 6| Step: 13
Training loss: 3.074193312116802
Validation loss: 2.483162674246643

Epoch: 71| Step: 0
Training loss: 2.2739367379319186
Validation loss: 2.478865380686783

Epoch: 6| Step: 1
Training loss: 2.599695492298943
Validation loss: 2.481349277636052

Epoch: 6| Step: 2
Training loss: 2.987500695902851
Validation loss: 2.4956984018708215

Epoch: 6| Step: 3
Training loss: 2.4461141131615576
Validation loss: 2.4751508027728693

Epoch: 6| Step: 4
Training loss: 2.840480727759037
Validation loss: 2.4885830363855894

Epoch: 6| Step: 5
Training loss: 2.353703940047737
Validation loss: 2.500773527598342

Epoch: 6| Step: 6
Training loss: 3.381032285890998
Validation loss: 2.4799079651911695

Epoch: 6| Step: 7
Training loss: 2.7750543743683083
Validation loss: 2.4945456368329215

Epoch: 6| Step: 8
Training loss: 2.8529734843907537
Validation loss: 2.485380895098112

Epoch: 6| Step: 9
Training loss: 1.883970039340026
Validation loss: 2.4891518508838946

Epoch: 6| Step: 10
Training loss: 2.201651113986061
Validation loss: 2.497278469277977

Epoch: 6| Step: 11
Training loss: 2.7705872409690615
Validation loss: 2.4816536869223205

Epoch: 6| Step: 12
Training loss: 2.946428891797069
Validation loss: 2.4890220248906734

Epoch: 6| Step: 13
Training loss: 3.198762183395385
Validation loss: 2.4837963059466497

Epoch: 72| Step: 0
Training loss: 3.269625463005658
Validation loss: 2.495286349441694

Epoch: 6| Step: 1
Training loss: 2.4614673831195937
Validation loss: 2.4901453369746025

Epoch: 6| Step: 2
Training loss: 2.249389565630807
Validation loss: 2.496904728413309

Epoch: 6| Step: 3
Training loss: 2.3729218877835954
Validation loss: 2.5100433544517666

Epoch: 6| Step: 4
Training loss: 1.6804664402533087
Validation loss: 2.4900796767651303

Epoch: 6| Step: 5
Training loss: 2.764770462000426
Validation loss: 2.48383846978853

Epoch: 6| Step: 6
Training loss: 2.4065359366813066
Validation loss: 2.4804916384655664

Epoch: 6| Step: 7
Training loss: 3.3379029105793507
Validation loss: 2.4866980729427355

Epoch: 6| Step: 8
Training loss: 2.4219106363935623
Validation loss: 2.4890856989284162

Epoch: 6| Step: 9
Training loss: 2.5773845187197866
Validation loss: 2.4793798300380803

Epoch: 6| Step: 10
Training loss: 2.6182409187712326
Validation loss: 2.484393262599328

Epoch: 6| Step: 11
Training loss: 2.7984272149949714
Validation loss: 2.4908950874347537

Epoch: 6| Step: 12
Training loss: 3.2613254698343783
Validation loss: 2.5051553136566085

Epoch: 6| Step: 13
Training loss: 3.2770137507057324
Validation loss: 2.4893713579532277

Epoch: 73| Step: 0
Training loss: 2.4107052071213704
Validation loss: 2.498610582134472

Epoch: 6| Step: 1
Training loss: 2.472182772413335
Validation loss: 2.4674085267106096

Epoch: 6| Step: 2
Training loss: 2.5576994985740806
Validation loss: 2.4850591067342065

Epoch: 6| Step: 3
Training loss: 3.0136419703939974
Validation loss: 2.4904206365729484

Epoch: 6| Step: 4
Training loss: 2.5576837450174263
Validation loss: 2.491274385284301

Epoch: 6| Step: 5
Training loss: 2.0316020953854643
Validation loss: 2.4982630099560925

Epoch: 6| Step: 6
Training loss: 2.213570580387142
Validation loss: 2.4844946465807434

Epoch: 6| Step: 7
Training loss: 2.8396316721984283
Validation loss: 2.4822396566605613

Epoch: 6| Step: 8
Training loss: 3.006155374984767
Validation loss: 2.479351369447799

Epoch: 6| Step: 9
Training loss: 2.535809589951355
Validation loss: 2.4871365958271205

Epoch: 6| Step: 10
Training loss: 3.2276086473682657
Validation loss: 2.491011918969717

Epoch: 6| Step: 11
Training loss: 2.6430180106673347
Validation loss: 2.487520034716778

Epoch: 6| Step: 12
Training loss: 3.110143518601485
Validation loss: 2.483713658570225

Epoch: 6| Step: 13
Training loss: 2.6120025745279847
Validation loss: 2.4881206284237547

Epoch: 74| Step: 0
Training loss: 2.087136827502871
Validation loss: 2.48270415693991

Epoch: 6| Step: 1
Training loss: 3.336374866125576
Validation loss: 2.4825704930646686

Epoch: 6| Step: 2
Training loss: 3.023304386806463
Validation loss: 2.491565280137967

Epoch: 6| Step: 3
Training loss: 2.8923498008194466
Validation loss: 2.4901861980683293

Epoch: 6| Step: 4
Training loss: 3.2708903670147347
Validation loss: 2.4926070574665653

Epoch: 6| Step: 5
Training loss: 2.3081122346427434
Validation loss: 2.4895576228240692

Epoch: 6| Step: 6
Training loss: 2.5800679601545604
Validation loss: 2.478435830192658

Epoch: 6| Step: 7
Training loss: 2.4120880249561205
Validation loss: 2.49140319405231

Epoch: 6| Step: 8
Training loss: 2.8107977908213586
Validation loss: 2.489198346430372

Epoch: 6| Step: 9
Training loss: 2.779233908995543
Validation loss: 2.496460527631508

Epoch: 6| Step: 10
Training loss: 2.87548425991239
Validation loss: 2.4813273290039017

Epoch: 6| Step: 11
Training loss: 1.9780548854653477
Validation loss: 2.487843904731871

Epoch: 6| Step: 12
Training loss: 2.370896659590836
Validation loss: 2.492002646135886

Epoch: 6| Step: 13
Training loss: 2.3581107080563872
Validation loss: 2.487970973504606

Epoch: 75| Step: 0
Training loss: 2.5162745993520823
Validation loss: 2.485990310155136

Epoch: 6| Step: 1
Training loss: 2.3614426199366814
Validation loss: 2.4931348512936795

Epoch: 6| Step: 2
Training loss: 2.441033174619863
Validation loss: 2.4874318466871737

Epoch: 6| Step: 3
Training loss: 3.2728253431750236
Validation loss: 2.4861210518679844

Epoch: 6| Step: 4
Training loss: 3.3164962558641813
Validation loss: 2.4879557583619145

Epoch: 6| Step: 5
Training loss: 2.1595875438090024
Validation loss: 2.4776972670224646

Epoch: 6| Step: 6
Training loss: 2.7556846125265895
Validation loss: 2.4884611550793694

Epoch: 6| Step: 7
Training loss: 2.4791704279339464
Validation loss: 2.4854929503368406

Epoch: 6| Step: 8
Training loss: 2.7966637558253176
Validation loss: 2.4787688404467865

Epoch: 6| Step: 9
Training loss: 3.2509687887129193
Validation loss: 2.4814015309026796

Epoch: 6| Step: 10
Training loss: 2.6591106494090804
Validation loss: 2.489974171224113

Epoch: 6| Step: 11
Training loss: 2.433800555361928
Validation loss: 2.4908477878307256

Epoch: 6| Step: 12
Training loss: 2.6269363346059604
Validation loss: 2.4882780313853337

Epoch: 6| Step: 13
Training loss: 1.3590016345589009
Validation loss: 2.4813196370182893

Epoch: 76| Step: 0
Training loss: 2.5525160961035915
Validation loss: 2.471242043308104

Epoch: 6| Step: 1
Training loss: 2.1808972573547454
Validation loss: 2.4875045169091177

Epoch: 6| Step: 2
Training loss: 3.1683381002899647
Validation loss: 2.4861006488382453

Epoch: 6| Step: 3
Training loss: 3.045955577924673
Validation loss: 2.479998281476963

Epoch: 6| Step: 4
Training loss: 2.4414811511947834
Validation loss: 2.4876021310377205

Epoch: 6| Step: 5
Training loss: 2.83344337773263
Validation loss: 2.477993567047765

Epoch: 6| Step: 6
Training loss: 1.9633293003284804
Validation loss: 2.4712055082533726

Epoch: 6| Step: 7
Training loss: 2.808445105512132
Validation loss: 2.4866260987711324

Epoch: 6| Step: 8
Training loss: 2.177526790835118
Validation loss: 2.4909721108855534

Epoch: 6| Step: 9
Training loss: 2.8140796887488646
Validation loss: 2.4800117860468354

Epoch: 6| Step: 10
Training loss: 2.705274664283889
Validation loss: 2.5007526326140597

Epoch: 6| Step: 11
Training loss: 2.696185338319782
Validation loss: 2.482463123461664

Epoch: 6| Step: 12
Training loss: 2.8212642173425757
Validation loss: 2.480630641101971

Epoch: 6| Step: 13
Training loss: 3.2249092503280714
Validation loss: 2.4876851557357664

Epoch: 77| Step: 0
Training loss: 3.272593678531697
Validation loss: 2.4930190838183304

Epoch: 6| Step: 1
Training loss: 3.0583371265467543
Validation loss: 2.4892791268368177

Epoch: 6| Step: 2
Training loss: 2.4232685632808337
Validation loss: 2.4846263543450973

Epoch: 6| Step: 3
Training loss: 3.134653363936136
Validation loss: 2.472938638501008

Epoch: 6| Step: 4
Training loss: 2.3138972005075336
Validation loss: 2.4892457185718566

Epoch: 6| Step: 5
Training loss: 2.74162473636863
Validation loss: 2.4926572867313395

Epoch: 6| Step: 6
Training loss: 2.7220484576484183
Validation loss: 2.500528382279348

Epoch: 6| Step: 7
Training loss: 2.787998712514747
Validation loss: 2.4896649675804827

Epoch: 6| Step: 8
Training loss: 2.0762699423423054
Validation loss: 2.4870425176237325

Epoch: 6| Step: 9
Training loss: 2.4448663956661254
Validation loss: 2.4953006075660573

Epoch: 6| Step: 10
Training loss: 2.7631096042151504
Validation loss: 2.4751376269456475

Epoch: 6| Step: 11
Training loss: 2.48766967348117
Validation loss: 2.4956215997928664

Epoch: 6| Step: 12
Training loss: 2.4419742503327773
Validation loss: 2.4938935036574894

Epoch: 6| Step: 13
Training loss: 2.614185490425427
Validation loss: 2.4695725364221146

Epoch: 78| Step: 0
Training loss: 2.5469111340539676
Validation loss: 2.4877049310623707

Epoch: 6| Step: 1
Training loss: 2.7332573922780536
Validation loss: 2.475240828637742

Epoch: 6| Step: 2
Training loss: 2.5576431022575044
Validation loss: 2.4941161760758215

Epoch: 6| Step: 3
Training loss: 1.8940009879297985
Validation loss: 2.466994979932301

Epoch: 6| Step: 4
Training loss: 2.3087174693874064
Validation loss: 2.492273556088918

Epoch: 6| Step: 5
Training loss: 2.940504769310848
Validation loss: 2.486486904444225

Epoch: 6| Step: 6
Training loss: 2.7961284983826786
Validation loss: 2.4763388837660365

Epoch: 6| Step: 7
Training loss: 3.130598165618314
Validation loss: 2.48043801157261

Epoch: 6| Step: 8
Training loss: 2.8438750857834876
Validation loss: 2.467110150099043

Epoch: 6| Step: 9
Training loss: 2.6346149557028693
Validation loss: 2.482295873548543

Epoch: 6| Step: 10
Training loss: 2.289346410441092
Validation loss: 2.4814065380212975

Epoch: 6| Step: 11
Training loss: 3.342467730643859
Validation loss: 2.4861954937676742

Epoch: 6| Step: 12
Training loss: 2.4241134635443453
Validation loss: 2.479215561145134

Epoch: 6| Step: 13
Training loss: 2.7064091131290873
Validation loss: 2.4822941142242754

Epoch: 79| Step: 0
Training loss: 2.5939431176048147
Validation loss: 2.4814974795465745

Epoch: 6| Step: 1
Training loss: 2.816969224002682
Validation loss: 2.504552568134016

Epoch: 6| Step: 2
Training loss: 2.3824672761573136
Validation loss: 2.4912498886789773

Epoch: 6| Step: 3
Training loss: 2.947881655715425
Validation loss: 2.4827899061879837

Epoch: 6| Step: 4
Training loss: 2.383764358261226
Validation loss: 2.4951059049030913

Epoch: 6| Step: 5
Training loss: 2.886129481730669
Validation loss: 2.4778224702730243

Epoch: 6| Step: 6
Training loss: 2.7019043740858226
Validation loss: 2.512302557486387

Epoch: 6| Step: 7
Training loss: 2.7832302801580964
Validation loss: 2.5023751558647724

Epoch: 6| Step: 8
Training loss: 2.3159520956826958
Validation loss: 2.4867303218773786

Epoch: 6| Step: 9
Training loss: 1.9784910420795105
Validation loss: 2.48191851357813

Epoch: 6| Step: 10
Training loss: 3.4067702989685236
Validation loss: 2.477179363537196

Epoch: 6| Step: 11
Training loss: 2.5993881532703624
Validation loss: 2.4897784579124007

Epoch: 6| Step: 12
Training loss: 2.758787161227221
Validation loss: 2.499967511283851

Epoch: 6| Step: 13
Training loss: 2.4456029359956486
Validation loss: 2.48770383973679

Epoch: 80| Step: 0
Training loss: 2.0296421436530934
Validation loss: 2.488874913264967

Epoch: 6| Step: 1
Training loss: 2.841390112641486
Validation loss: 2.4766858228921635

Epoch: 6| Step: 2
Training loss: 3.5958902371450683
Validation loss: 2.47762381765721

Epoch: 6| Step: 3
Training loss: 2.910127575624253
Validation loss: 2.477757083613208

Epoch: 6| Step: 4
Training loss: 1.901193760749247
Validation loss: 2.4780812157501915

Epoch: 6| Step: 5
Training loss: 2.76225273441121
Validation loss: 2.4856973571385446

Epoch: 6| Step: 6
Training loss: 2.1757751136022083
Validation loss: 2.4822607286540457

Epoch: 6| Step: 7
Training loss: 2.3502622539199596
Validation loss: 2.4804511659628896

Epoch: 6| Step: 8
Training loss: 2.8089256461906635
Validation loss: 2.4796747318000123

Epoch: 6| Step: 9
Training loss: 2.956701948205544
Validation loss: 2.4822517573544696

Epoch: 6| Step: 10
Training loss: 2.4988955919330293
Validation loss: 2.478649738702075

Epoch: 6| Step: 11
Training loss: 2.7734046611722234
Validation loss: 2.487281570041447

Epoch: 6| Step: 12
Training loss: 2.8480358315581906
Validation loss: 2.473382758049262

Epoch: 6| Step: 13
Training loss: 2.355168312359228
Validation loss: 2.4965471542143254

Epoch: 81| Step: 0
Training loss: 1.9539090223266018
Validation loss: 2.474414419070273

Epoch: 6| Step: 1
Training loss: 2.4945838432848833
Validation loss: 2.4877556550173403

Epoch: 6| Step: 2
Training loss: 2.581768074416384
Validation loss: 2.4844316788359007

Epoch: 6| Step: 3
Training loss: 2.6597274457074014
Validation loss: 2.470033005124448

Epoch: 6| Step: 4
Training loss: 3.049929921330065
Validation loss: 2.503865736183314

Epoch: 6| Step: 5
Training loss: 2.8896466223274966
Validation loss: 2.4849755893730703

Epoch: 6| Step: 6
Training loss: 2.439812761220511
Validation loss: 2.4991467999120904

Epoch: 6| Step: 7
Training loss: 2.6623183103364965
Validation loss: 2.474549516508678

Epoch: 6| Step: 8
Training loss: 2.4998523668567114
Validation loss: 2.4987375517381203

Epoch: 6| Step: 9
Training loss: 2.744804502936116
Validation loss: 2.4683115881292803

Epoch: 6| Step: 10
Training loss: 2.2810654238926626
Validation loss: 2.484758610207714

Epoch: 6| Step: 11
Training loss: 3.0129479102978958
Validation loss: 2.473957824879687

Epoch: 6| Step: 12
Training loss: 3.0617069073813292
Validation loss: 2.487067520555625

Epoch: 6| Step: 13
Training loss: 2.8106685185302673
Validation loss: 2.4772796808741306

Epoch: 82| Step: 0
Training loss: 2.329741256165309
Validation loss: 2.475306746788977

Epoch: 6| Step: 1
Training loss: 2.3614476680865337
Validation loss: 2.4836352332950593

Epoch: 6| Step: 2
Training loss: 1.8236924909240144
Validation loss: 2.4747010159086136

Epoch: 6| Step: 3
Training loss: 2.6222676179839364
Validation loss: 2.4761219977963274

Epoch: 6| Step: 4
Training loss: 2.5269213740650476
Validation loss: 2.477962757050681

Epoch: 6| Step: 5
Training loss: 3.1366757286608413
Validation loss: 2.4783443708305253

Epoch: 6| Step: 6
Training loss: 3.4297802332547915
Validation loss: 2.4916987552429264

Epoch: 6| Step: 7
Training loss: 2.9779605335722903
Validation loss: 2.471959229785368

Epoch: 6| Step: 8
Training loss: 2.3899534192194665
Validation loss: 2.473301947692267

Epoch: 6| Step: 9
Training loss: 2.5448944254263597
Validation loss: 2.4703634609427194

Epoch: 6| Step: 10
Training loss: 2.735426695069996
Validation loss: 2.474376274172609

Epoch: 6| Step: 11
Training loss: 2.434574719366499
Validation loss: 2.4779840883627764

Epoch: 6| Step: 12
Training loss: 3.1886042757730264
Validation loss: 2.481929843728492

Epoch: 6| Step: 13
Training loss: 2.2571401684005203
Validation loss: 2.474566364967536

Epoch: 83| Step: 0
Training loss: 2.7004377646010282
Validation loss: 2.481227391257427

Epoch: 6| Step: 1
Training loss: 2.487131760527792
Validation loss: 2.500541042930707

Epoch: 6| Step: 2
Training loss: 3.3107492390676185
Validation loss: 2.482705334620079

Epoch: 6| Step: 3
Training loss: 2.4676340212461163
Validation loss: 2.477111121085919

Epoch: 6| Step: 4
Training loss: 2.615905083138855
Validation loss: 2.473549396457706

Epoch: 6| Step: 5
Training loss: 1.8242786079077997
Validation loss: 2.4894922910617248

Epoch: 6| Step: 6
Training loss: 2.878151865946644
Validation loss: 2.4725167057337267

Epoch: 6| Step: 7
Training loss: 2.499133913699607
Validation loss: 2.4695003548347634

Epoch: 6| Step: 8
Training loss: 3.045688182818131
Validation loss: 2.4731803333068862

Epoch: 6| Step: 9
Training loss: 2.2970134667419875
Validation loss: 2.4917551738633805

Epoch: 6| Step: 10
Training loss: 2.775563888993728
Validation loss: 2.474175276686613

Epoch: 6| Step: 11
Training loss: 2.6906679688322295
Validation loss: 2.4793320470799314

Epoch: 6| Step: 12
Training loss: 3.2438663410351816
Validation loss: 2.4769839718154474

Epoch: 6| Step: 13
Training loss: 1.756866539629769
Validation loss: 2.4770671588702857

Epoch: 84| Step: 0
Training loss: 2.6483183077207295
Validation loss: 2.4846426227025105

Epoch: 6| Step: 1
Training loss: 2.420603953889796
Validation loss: 2.479467751294212

Epoch: 6| Step: 2
Training loss: 3.020904820791164
Validation loss: 2.4712175810230876

Epoch: 6| Step: 3
Training loss: 2.7446482341623986
Validation loss: 2.4809280395331568

Epoch: 6| Step: 4
Training loss: 2.8790145708717754
Validation loss: 2.4890684904185516

Epoch: 6| Step: 5
Training loss: 1.8397302288823425
Validation loss: 2.47470709686625

Epoch: 6| Step: 6
Training loss: 2.6753812393467196
Validation loss: 2.4806955221105738

Epoch: 6| Step: 7
Training loss: 2.9354578589713864
Validation loss: 2.4947478694095495

Epoch: 6| Step: 8
Training loss: 2.50489185472905
Validation loss: 2.483404469288462

Epoch: 6| Step: 9
Training loss: 3.2999708636760476
Validation loss: 2.4752049636867253

Epoch: 6| Step: 10
Training loss: 2.964160785242022
Validation loss: 2.483981336012169

Epoch: 6| Step: 11
Training loss: 2.153777986013672
Validation loss: 2.5006948192577423

Epoch: 6| Step: 12
Training loss: 2.443862241230829
Validation loss: 2.5009285986521816

Epoch: 6| Step: 13
Training loss: 2.1623726867949196
Validation loss: 2.491879323047803

Epoch: 85| Step: 0
Training loss: 2.72128817586269
Validation loss: 2.4832034685389517

Epoch: 6| Step: 1
Training loss: 2.2566280227951085
Validation loss: 2.488402056310201

Epoch: 6| Step: 2
Training loss: 2.612440033730935
Validation loss: 2.4941907863786157

Epoch: 6| Step: 3
Training loss: 2.918761527387903
Validation loss: 2.497420964947613

Epoch: 6| Step: 4
Training loss: 2.6814382633725358
Validation loss: 2.4723759922482738

Epoch: 6| Step: 5
Training loss: 3.1870341241001343
Validation loss: 2.493408717594131

Epoch: 6| Step: 6
Training loss: 2.2553926059302327
Validation loss: 2.501936407685721

Epoch: 6| Step: 7
Training loss: 3.1229386206515386
Validation loss: 2.4774535159344855

Epoch: 6| Step: 8
Training loss: 2.2118922891450428
Validation loss: 2.4927055568024907

Epoch: 6| Step: 9
Training loss: 2.1848154216120115
Validation loss: 2.4815628812890123

Epoch: 6| Step: 10
Training loss: 2.4986461788438117
Validation loss: 2.492699971760154

Epoch: 6| Step: 11
Training loss: 3.243701406713936
Validation loss: 2.4863753456118376

Epoch: 6| Step: 12
Training loss: 2.3297813718983864
Validation loss: 2.4825775822361074

Epoch: 6| Step: 13
Training loss: 2.6838764336080128
Validation loss: 2.478600691189025

Epoch: 86| Step: 0
Training loss: 2.87548823979294
Validation loss: 2.4816587859888193

Epoch: 6| Step: 1
Training loss: 3.0115621602754006
Validation loss: 2.4892487660042337

Epoch: 6| Step: 2
Training loss: 2.5190483162710975
Validation loss: 2.4824555331021942

Epoch: 6| Step: 3
Training loss: 2.834972206800285
Validation loss: 2.478593516172536

Epoch: 6| Step: 4
Training loss: 2.7045436069374387
Validation loss: 2.4690630625886247

Epoch: 6| Step: 5
Training loss: 2.516592846560382
Validation loss: 2.476807466989972

Epoch: 6| Step: 6
Training loss: 3.363980423297686
Validation loss: 2.4827052778270984

Epoch: 6| Step: 7
Training loss: 2.2272393519602716
Validation loss: 2.4714481494905414

Epoch: 6| Step: 8
Training loss: 2.6285376552520843
Validation loss: 2.491433031632411

Epoch: 6| Step: 9
Training loss: 2.516575983026288
Validation loss: 2.476060475794255

Epoch: 6| Step: 10
Training loss: 1.557838658579036
Validation loss: 2.476520909474213

Epoch: 6| Step: 11
Training loss: 2.428592545553769
Validation loss: 2.4816115179845664

Epoch: 6| Step: 12
Training loss: 2.7830167152486736
Validation loss: 2.476308999933258

Epoch: 6| Step: 13
Training loss: 2.6853716207020533
Validation loss: 2.4732507210330836

Epoch: 87| Step: 0
Training loss: 2.1689525674546606
Validation loss: 2.479903604768985

Epoch: 6| Step: 1
Training loss: 2.467985493553968
Validation loss: 2.459870861011013

Epoch: 6| Step: 2
Training loss: 3.263695689947148
Validation loss: 2.481227249707008

Epoch: 6| Step: 3
Training loss: 2.5355000549328435
Validation loss: 2.474259751270012

Epoch: 6| Step: 4
Training loss: 2.1306957877886035
Validation loss: 2.4891688044276385

Epoch: 6| Step: 5
Training loss: 3.4003230334142347
Validation loss: 2.46519637927913

Epoch: 6| Step: 6
Training loss: 2.664337770442194
Validation loss: 2.478208460274793

Epoch: 6| Step: 7
Training loss: 2.66769760787061
Validation loss: 2.476760839753049

Epoch: 6| Step: 8
Training loss: 2.0668846687065368
Validation loss: 2.471120712436477

Epoch: 6| Step: 9
Training loss: 3.03919664886081
Validation loss: 2.484248233346367

Epoch: 6| Step: 10
Training loss: 2.7179643219212455
Validation loss: 2.4693910309872384

Epoch: 6| Step: 11
Training loss: 2.6377411393128933
Validation loss: 2.478521204251502

Epoch: 6| Step: 12
Training loss: 2.7547798232144887
Validation loss: 2.474621150932825

Epoch: 6| Step: 13
Training loss: 1.8060428434593927
Validation loss: 2.4901343448244364

Epoch: 88| Step: 0
Training loss: 2.2580448017929795
Validation loss: 2.473328851602842

Epoch: 6| Step: 1
Training loss: 2.515852070861094
Validation loss: 2.4832193043570068

Epoch: 6| Step: 2
Training loss: 2.7093297054812155
Validation loss: 2.480465528482676

Epoch: 6| Step: 3
Training loss: 2.973389864613671
Validation loss: 2.486210929520598

Epoch: 6| Step: 4
Training loss: 2.644830007877415
Validation loss: 2.478556746084977

Epoch: 6| Step: 5
Training loss: 2.7839090730244185
Validation loss: 2.464633023415535

Epoch: 6| Step: 6
Training loss: 2.333154966712209
Validation loss: 2.481676430165627

Epoch: 6| Step: 7
Training loss: 3.4577889684263408
Validation loss: 2.46273136208676

Epoch: 6| Step: 8
Training loss: 2.798161557052279
Validation loss: 2.462179280778154

Epoch: 6| Step: 9
Training loss: 2.2643361602156076
Validation loss: 2.492168748288518

Epoch: 6| Step: 10
Training loss: 2.2145916292376686
Validation loss: 2.4627638454829097

Epoch: 6| Step: 11
Training loss: 2.21322718162757
Validation loss: 2.48981298032023

Epoch: 6| Step: 12
Training loss: 2.559115430922928
Validation loss: 2.4846140604025138

Epoch: 6| Step: 13
Training loss: 3.3451123180833946
Validation loss: 2.4839934602155322

Epoch: 89| Step: 0
Training loss: 2.4721447745585112
Validation loss: 2.479561011646743

Epoch: 6| Step: 1
Training loss: 3.16767748376856
Validation loss: 2.4810574298825303

Epoch: 6| Step: 2
Training loss: 3.218557703884972
Validation loss: 2.4939025250810154

Epoch: 6| Step: 3
Training loss: 2.487022860211453
Validation loss: 2.486968680404068

Epoch: 6| Step: 4
Training loss: 2.958118395093761
Validation loss: 2.481729571643541

Epoch: 6| Step: 5
Training loss: 2.279988188127405
Validation loss: 2.4700451183943635

Epoch: 6| Step: 6
Training loss: 2.429029762070027
Validation loss: 2.474844794960511

Epoch: 6| Step: 7
Training loss: 2.3630841133557716
Validation loss: 2.4828640783159592

Epoch: 6| Step: 8
Training loss: 2.467038684147371
Validation loss: 2.500440853995132

Epoch: 6| Step: 9
Training loss: 3.0989590342972333
Validation loss: 2.4774531113321125

Epoch: 6| Step: 10
Training loss: 2.2715188021359256
Validation loss: 2.479759180834793

Epoch: 6| Step: 11
Training loss: 2.218119572009133
Validation loss: 2.4748390116393018

Epoch: 6| Step: 12
Training loss: 2.3833249400953633
Validation loss: 2.477162554583801

Epoch: 6| Step: 13
Training loss: 3.0212624782167263
Validation loss: 2.4816504452493944

Epoch: 90| Step: 0
Training loss: 2.3868506062697747
Validation loss: 2.475896203595866

Epoch: 6| Step: 1
Training loss: 3.032053732745651
Validation loss: 2.488141016950127

Epoch: 6| Step: 2
Training loss: 2.181013244196904
Validation loss: 2.4830913048198684

Epoch: 6| Step: 3
Training loss: 1.579503882779828
Validation loss: 2.4776186399256055

Epoch: 6| Step: 4
Training loss: 2.558793154801227
Validation loss: 2.4664480636160016

Epoch: 6| Step: 5
Training loss: 3.0147036395071436
Validation loss: 2.4774792830712173

Epoch: 6| Step: 6
Training loss: 3.227408753042649
Validation loss: 2.4673962051635785

Epoch: 6| Step: 7
Training loss: 2.527458742523785
Validation loss: 2.490880021892533

Epoch: 6| Step: 8
Training loss: 2.7314625079064125
Validation loss: 2.492890968373828

Epoch: 6| Step: 9
Training loss: 3.0106108887705805
Validation loss: 2.477461450680702

Epoch: 6| Step: 10
Training loss: 2.557203448004735
Validation loss: 2.4710380965584298

Epoch: 6| Step: 11
Training loss: 2.592181363365815
Validation loss: 2.470737588650106

Epoch: 6| Step: 12
Training loss: 2.218518419672028
Validation loss: 2.461134327642928

Epoch: 6| Step: 13
Training loss: 2.9052882089960614
Validation loss: 2.480762429487036

Epoch: 91| Step: 0
Training loss: 2.97329267990078
Validation loss: 2.471775598138672

Epoch: 6| Step: 1
Training loss: 2.4296653231378382
Validation loss: 2.484700217836719

Epoch: 6| Step: 2
Training loss: 2.502421541460789
Validation loss: 2.4749744909087914

Epoch: 6| Step: 3
Training loss: 3.0822531036477665
Validation loss: 2.475264662364787

Epoch: 6| Step: 4
Training loss: 2.5281705609378635
Validation loss: 2.4585032768457

Epoch: 6| Step: 5
Training loss: 2.6975962818063564
Validation loss: 2.4776103802624134

Epoch: 6| Step: 6
Training loss: 3.0718648543631732
Validation loss: 2.475466222284034

Epoch: 6| Step: 7
Training loss: 2.130585230632136
Validation loss: 2.482020007942491

Epoch: 6| Step: 8
Training loss: 3.064452346986437
Validation loss: 2.4714873462676783

Epoch: 6| Step: 9
Training loss: 2.732901388634431
Validation loss: 2.4809838469818937

Epoch: 6| Step: 10
Training loss: 1.9786505846122322
Validation loss: 2.494657293768477

Epoch: 6| Step: 11
Training loss: 2.626898306235647
Validation loss: 2.4858816021855525

Epoch: 6| Step: 12
Training loss: 2.443772876369008
Validation loss: 2.4949482596691235

Epoch: 6| Step: 13
Training loss: 2.3921381331718803
Validation loss: 2.4795739447816514

Epoch: 92| Step: 0
Training loss: 1.893354038351419
Validation loss: 2.4840362033011942

Epoch: 6| Step: 1
Training loss: 2.931309121517817
Validation loss: 2.470966910212676

Epoch: 6| Step: 2
Training loss: 3.5803663405193915
Validation loss: 2.48763946613839

Epoch: 6| Step: 3
Training loss: 3.038132552227968
Validation loss: 2.4868957605191664

Epoch: 6| Step: 4
Training loss: 2.5006348757464205
Validation loss: 2.478684736732671

Epoch: 6| Step: 5
Training loss: 2.1000510527445044
Validation loss: 2.4803781077003353

Epoch: 6| Step: 6
Training loss: 2.477408375975293
Validation loss: 2.4581725042038487

Epoch: 6| Step: 7
Training loss: 3.441194941325839
Validation loss: 2.487969594810016

Epoch: 6| Step: 8
Training loss: 2.1674106738769745
Validation loss: 2.47838598609663

Epoch: 6| Step: 9
Training loss: 2.6295682121869257
Validation loss: 2.4863029702777832

Epoch: 6| Step: 10
Training loss: 2.2465805985616765
Validation loss: 2.470977669635321

Epoch: 6| Step: 11
Training loss: 2.3873245294609746
Validation loss: 2.4907707317162497

Epoch: 6| Step: 12
Training loss: 1.9335963393685314
Validation loss: 2.4746334613690655

Epoch: 6| Step: 13
Training loss: 2.932920579336376
Validation loss: 2.456512623373612

Epoch: 93| Step: 0
Training loss: 2.016867321320141
Validation loss: 2.4701857269936482

Epoch: 6| Step: 1
Training loss: 3.2243807530818573
Validation loss: 2.4683919916765418

Epoch: 6| Step: 2
Training loss: 2.6298945072904196
Validation loss: 2.4942435101401097

Epoch: 6| Step: 3
Training loss: 3.0352662212622383
Validation loss: 2.4975339355252304

Epoch: 6| Step: 4
Training loss: 2.410020128854607
Validation loss: 2.467529985049698

Epoch: 6| Step: 5
Training loss: 3.0560309146296074
Validation loss: 2.476433470045078

Epoch: 6| Step: 6
Training loss: 3.262299080577637
Validation loss: 2.468854756311497

Epoch: 6| Step: 7
Training loss: 1.9541257201936282
Validation loss: 2.506498895220998

Epoch: 6| Step: 8
Training loss: 2.659997069851975
Validation loss: 2.494960395826972

Epoch: 6| Step: 9
Training loss: 2.0602427759903703
Validation loss: 2.4741141414746832

Epoch: 6| Step: 10
Training loss: 2.794883914372494
Validation loss: 2.5008294401081694

Epoch: 6| Step: 11
Training loss: 2.236252749309694
Validation loss: 2.4813204160330953

Epoch: 6| Step: 12
Training loss: 2.6602664874253956
Validation loss: 2.4724619415710873

Epoch: 6| Step: 13
Training loss: 2.3171127296983474
Validation loss: 2.487622146629237

Epoch: 94| Step: 0
Training loss: 2.6442108185555684
Validation loss: 2.4883148515115474

Epoch: 6| Step: 1
Training loss: 2.3076899222826244
Validation loss: 2.4720784132777545

Epoch: 6| Step: 2
Training loss: 3.2526035151036843
Validation loss: 2.481995193795022

Epoch: 6| Step: 3
Training loss: 2.2830951492191875
Validation loss: 2.464994883902333

Epoch: 6| Step: 4
Training loss: 2.290134738639687
Validation loss: 2.4865059485118834

Epoch: 6| Step: 5
Training loss: 2.388507678298475
Validation loss: 2.4939183022140905

Epoch: 6| Step: 6
Training loss: 2.393663059179664
Validation loss: 2.4788417062023576

Epoch: 6| Step: 7
Training loss: 2.7472188931779153
Validation loss: 2.4834650619871166

Epoch: 6| Step: 8
Training loss: 2.9925654797572543
Validation loss: 2.488180156826851

Epoch: 6| Step: 9
Training loss: 2.945880703542972
Validation loss: 2.4744192030705197

Epoch: 6| Step: 10
Training loss: 2.665470858518908
Validation loss: 2.4722076124615526

Epoch: 6| Step: 11
Training loss: 2.7038216988505
Validation loss: 2.468645352437599

Epoch: 6| Step: 12
Training loss: 2.3742815235973804
Validation loss: 2.479574384190678

Epoch: 6| Step: 13
Training loss: 2.377107989768141
Validation loss: 2.484583630182454

Epoch: 95| Step: 0
Training loss: 2.0979201507791974
Validation loss: 2.4692613438947624

Epoch: 6| Step: 1
Training loss: 2.85039908308667
Validation loss: 2.464924286425853

Epoch: 6| Step: 2
Training loss: 2.639497595290057
Validation loss: 2.4862081459467316

Epoch: 6| Step: 3
Training loss: 2.0398496080575232
Validation loss: 2.4751113299764804

Epoch: 6| Step: 4
Training loss: 2.4917027112550234
Validation loss: 2.4776695486429623

Epoch: 6| Step: 5
Training loss: 3.0589445066478365
Validation loss: 2.48423898491868

Epoch: 6| Step: 6
Training loss: 2.7404757207843486
Validation loss: 2.4706772659221543

Epoch: 6| Step: 7
Training loss: 3.4614198232355444
Validation loss: 2.4795225706093027

Epoch: 6| Step: 8
Training loss: 2.2276475905855926
Validation loss: 2.470478147196983

Epoch: 6| Step: 9
Training loss: 2.234601309459374
Validation loss: 2.46457966620889

Epoch: 6| Step: 10
Training loss: 2.0067859207194725
Validation loss: 2.4680810231978754

Epoch: 6| Step: 11
Training loss: 2.8854594497171355
Validation loss: 2.47760687927441

Epoch: 6| Step: 12
Training loss: 2.883211764674259
Validation loss: 2.4661463534464234

Epoch: 6| Step: 13
Training loss: 2.9228629823532337
Validation loss: 2.478969409637352

Epoch: 96| Step: 0
Training loss: 2.710389359434605
Validation loss: 2.47141247741946

Epoch: 6| Step: 1
Training loss: 2.522082268990767
Validation loss: 2.476582191787276

Epoch: 6| Step: 2
Training loss: 2.8032720282704715
Validation loss: 2.4779407396251116

Epoch: 6| Step: 3
Training loss: 2.0977242172851676
Validation loss: 2.479654820578353

Epoch: 6| Step: 4
Training loss: 1.828977597949874
Validation loss: 2.488211235948988

Epoch: 6| Step: 5
Training loss: 3.168833509921061
Validation loss: 2.466328394952642

Epoch: 6| Step: 6
Training loss: 2.490386599207678
Validation loss: 2.472180111483292

Epoch: 6| Step: 7
Training loss: 2.3989233463025754
Validation loss: 2.494711589193872

Epoch: 6| Step: 8
Training loss: 2.5942817051084113
Validation loss: 2.478502630487717

Epoch: 6| Step: 9
Training loss: 3.3014985698931985
Validation loss: 2.4704657527539897

Epoch: 6| Step: 10
Training loss: 2.643812884942344
Validation loss: 2.4734350225897312

Epoch: 6| Step: 11
Training loss: 2.722371900643146
Validation loss: 2.4841454068912117

Epoch: 6| Step: 12
Training loss: 2.6862135181106455
Validation loss: 2.472669865170382

Epoch: 6| Step: 13
Training loss: 2.3928545360103635
Validation loss: 2.4843918427071654

Epoch: 97| Step: 0
Training loss: 2.214369519577114
Validation loss: 2.4821038349374422

Epoch: 6| Step: 1
Training loss: 2.114900148708579
Validation loss: 2.478436084649746

Epoch: 6| Step: 2
Training loss: 3.2235053036354566
Validation loss: 2.475787917039677

Epoch: 6| Step: 3
Training loss: 2.5346075325251256
Validation loss: 2.4935189963510473

Epoch: 6| Step: 4
Training loss: 2.6250807431836534
Validation loss: 2.4959378711603395

Epoch: 6| Step: 5
Training loss: 2.5497883241348265
Validation loss: 2.47729108191379

Epoch: 6| Step: 6
Training loss: 1.900016410656379
Validation loss: 2.4666169041262145

Epoch: 6| Step: 7
Training loss: 2.8189962173820846
Validation loss: 2.468740999852602

Epoch: 6| Step: 8
Training loss: 1.9335297545044283
Validation loss: 2.4921495129533207

Epoch: 6| Step: 9
Training loss: 3.032973281395532
Validation loss: 2.4837549908595067

Epoch: 6| Step: 10
Training loss: 2.4779147238109314
Validation loss: 2.496078044133209

Epoch: 6| Step: 11
Training loss: 3.0431268575039416
Validation loss: 2.4793698551682923

Epoch: 6| Step: 12
Training loss: 3.347405832688325
Validation loss: 2.474666696029568

Epoch: 6| Step: 13
Training loss: 1.9928399307925744
Validation loss: 2.482531864211383

Epoch: 98| Step: 0
Training loss: 3.302158840210665
Validation loss: 2.4963819040991138

Epoch: 6| Step: 1
Training loss: 2.3489805729413056
Validation loss: 2.4972632235840098

Epoch: 6| Step: 2
Training loss: 2.64229445193058
Validation loss: 2.4841911674597066

Epoch: 6| Step: 3
Training loss: 2.6970906017843372
Validation loss: 2.492654012572727

Epoch: 6| Step: 4
Training loss: 2.605483757101646
Validation loss: 2.467036574657662

Epoch: 6| Step: 5
Training loss: 2.66011609734748
Validation loss: 2.4786799976819776

Epoch: 6| Step: 6
Training loss: 2.120103917723903
Validation loss: 2.4983622878044094

Epoch: 6| Step: 7
Training loss: 2.6785829452993672
Validation loss: 2.48207667135352

Epoch: 6| Step: 8
Training loss: 3.254655584580827
Validation loss: 2.49345916615543

Epoch: 6| Step: 9
Training loss: 2.399558535345779
Validation loss: 2.4802493403292725

Epoch: 6| Step: 10
Training loss: 2.4780944514466205
Validation loss: 2.4989590343948027

Epoch: 6| Step: 11
Training loss: 2.1746556985127494
Validation loss: 2.4898836319710527

Epoch: 6| Step: 12
Training loss: 2.3035977130797067
Validation loss: 2.493016406051504

Epoch: 6| Step: 13
Training loss: 2.888832980209972
Validation loss: 2.4725259171339684

Epoch: 99| Step: 0
Training loss: 2.7806791941359728
Validation loss: 2.4776586998068346

Epoch: 6| Step: 1
Training loss: 2.7888998203223774
Validation loss: 2.4951905832411887

Epoch: 6| Step: 2
Training loss: 2.270217765412071
Validation loss: 2.496364037289827

Epoch: 6| Step: 3
Training loss: 2.129139626686507
Validation loss: 2.480097252638836

Epoch: 6| Step: 4
Training loss: 2.9412772060421646
Validation loss: 2.482415352347388

Epoch: 6| Step: 5
Training loss: 2.807616508152092
Validation loss: 2.479450480167254

Epoch: 6| Step: 6
Training loss: 2.814270055933401
Validation loss: 2.481126412095974

Epoch: 6| Step: 7
Training loss: 3.412338275360924
Validation loss: 2.491908729009501

Epoch: 6| Step: 8
Training loss: 2.242342315539399
Validation loss: 2.481125363340142

Epoch: 6| Step: 9
Training loss: 2.7452664818160843
Validation loss: 2.4678471976973477

Epoch: 6| Step: 10
Training loss: 2.5465188742821434
Validation loss: 2.467100058077503

Epoch: 6| Step: 11
Training loss: 2.198857929992082
Validation loss: 2.491531827414674

Epoch: 6| Step: 12
Training loss: 1.9835278362247017
Validation loss: 2.478133620169423

Epoch: 6| Step: 13
Training loss: 2.2140992543165465
Validation loss: 2.4722778070105003

Epoch: 100| Step: 0
Training loss: 2.332685471466109
Validation loss: 2.4772210252814895

Epoch: 6| Step: 1
Training loss: 1.8293519426618952
Validation loss: 2.470220880227991

Epoch: 6| Step: 2
Training loss: 2.768065587997652
Validation loss: 2.486555905116892

Epoch: 6| Step: 3
Training loss: 2.6549775610081503
Validation loss: 2.4672210432344652

Epoch: 6| Step: 4
Training loss: 2.7496938535034015
Validation loss: 2.4823063897064896

Epoch: 6| Step: 5
Training loss: 2.6089062298218804
Validation loss: 2.4684696996341975

Epoch: 6| Step: 6
Training loss: 3.010564323068843
Validation loss: 2.4800063827804983

Epoch: 6| Step: 7
Training loss: 2.438645118323402
Validation loss: 2.473055370851761

Epoch: 6| Step: 8
Training loss: 3.442068220332487
Validation loss: 2.4693196933396373

Epoch: 6| Step: 9
Training loss: 2.269541860217507
Validation loss: 2.474608401180578

Epoch: 6| Step: 10
Training loss: 2.588971619746258
Validation loss: 2.4752936639683814

Epoch: 6| Step: 11
Training loss: 2.3179316266683587
Validation loss: 2.4871636892031703

Epoch: 6| Step: 12
Training loss: 2.856101241296798
Validation loss: 2.480693349826661

Epoch: 6| Step: 13
Training loss: 1.7828652269622027
Validation loss: 2.479249648989573

Epoch: 101| Step: 0
Training loss: 3.0838274345061834
Validation loss: 2.4843782174797786

Epoch: 6| Step: 1
Training loss: 2.0952593928241376
Validation loss: 2.478874887027757

Epoch: 6| Step: 2
Training loss: 2.229924177240714
Validation loss: 2.474684956721736

Epoch: 6| Step: 3
Training loss: 2.969442507635456
Validation loss: 2.4770590639956986

Epoch: 6| Step: 4
Training loss: 3.2428157335617973
Validation loss: 2.4819959808609515

Epoch: 6| Step: 5
Training loss: 1.9101677954701248
Validation loss: 2.476843887843359

Epoch: 6| Step: 6
Training loss: 2.86979801756519
Validation loss: 2.4707960407114347

Epoch: 6| Step: 7
Training loss: 2.420066699850662
Validation loss: 2.487783816454583

Epoch: 6| Step: 8
Training loss: 2.2366876971094185
Validation loss: 2.4717827939831705

Epoch: 6| Step: 9
Training loss: 1.9494234944604507
Validation loss: 2.4713607914725815

Epoch: 6| Step: 10
Training loss: 2.5508571455736253
Validation loss: 2.483677416386497

Epoch: 6| Step: 11
Training loss: 2.8873779205012875
Validation loss: 2.4794187820010762

Epoch: 6| Step: 12
Training loss: 3.1823530342107844
Validation loss: 2.4771630829053692

Epoch: 6| Step: 13
Training loss: 2.102584760411131
Validation loss: 2.4758732219103248

Epoch: 102| Step: 0
Training loss: 2.4839869741998215
Validation loss: 2.466953917611562

Epoch: 6| Step: 1
Training loss: 2.7904184502074774
Validation loss: 2.489688568492906

Epoch: 6| Step: 2
Training loss: 2.9983783153519266
Validation loss: 2.4970960194049874

Epoch: 6| Step: 3
Training loss: 2.46918995474078
Validation loss: 2.465694280421222

Epoch: 6| Step: 4
Training loss: 2.5722594148854894
Validation loss: 2.485372369834949

Epoch: 6| Step: 5
Training loss: 2.6203235569119543
Validation loss: 2.485186741869743

Epoch: 6| Step: 6
Training loss: 2.8358847032576797
Validation loss: 2.4663230053657377

Epoch: 6| Step: 7
Training loss: 2.4814472341098424
Validation loss: 2.4808609294329598

Epoch: 6| Step: 8
Training loss: 2.2966534773729785
Validation loss: 2.4791630374105984

Epoch: 6| Step: 9
Training loss: 3.056919852960944
Validation loss: 2.475843544726545

Epoch: 6| Step: 10
Training loss: 2.662416816808931
Validation loss: 2.468211470289719

Epoch: 6| Step: 11
Training loss: 2.2220434540792415
Validation loss: 2.49058861982992

Epoch: 6| Step: 12
Training loss: 2.26947536169891
Validation loss: 2.4845168004296654

Epoch: 6| Step: 13
Training loss: 2.26390336492964
Validation loss: 2.490302280478986

Epoch: 103| Step: 0
Training loss: 2.7991616901498455
Validation loss: 2.482088115428994

Epoch: 6| Step: 1
Training loss: 3.0361204051993993
Validation loss: 2.4851758814916756

Epoch: 6| Step: 2
Training loss: 2.8043710004056632
Validation loss: 2.4853067630110193

Epoch: 6| Step: 3
Training loss: 2.47044015321737
Validation loss: 2.480341090168926

Epoch: 6| Step: 4
Training loss: 2.636525781422582
Validation loss: 2.4608769057926976

Epoch: 6| Step: 5
Training loss: 2.696985847608572
Validation loss: 2.4813511941544504

Epoch: 6| Step: 6
Training loss: 2.582792830579832
Validation loss: 2.4750987060062495

Epoch: 6| Step: 7
Training loss: 2.4278205003138895
Validation loss: 2.482685404334425

Epoch: 6| Step: 8
Training loss: 2.249107183701857
Validation loss: 2.4594585484722176

Epoch: 6| Step: 9
Training loss: 1.8851138410924084
Validation loss: 2.4717458458270443

Epoch: 6| Step: 10
Training loss: 2.7083677045157235
Validation loss: 2.485535224639616

Epoch: 6| Step: 11
Training loss: 2.181203663505977
Validation loss: 2.4649021873777377

Epoch: 6| Step: 12
Training loss: 2.9731080843476545
Validation loss: 2.4699764276556864

Epoch: 6| Step: 13
Training loss: 2.9120833397666663
Validation loss: 2.4897006947647635

Epoch: 104| Step: 0
Training loss: 2.312168613093244
Validation loss: 2.4612177905193207

Epoch: 6| Step: 1
Training loss: 2.0639546206608954
Validation loss: 2.4556246013956997

Epoch: 6| Step: 2
Training loss: 2.5604738738640225
Validation loss: 2.4729391682433173

Epoch: 6| Step: 3
Training loss: 2.774600190925248
Validation loss: 2.473645718592363

Epoch: 6| Step: 4
Training loss: 2.6072078088332664
Validation loss: 2.47374440397847

Epoch: 6| Step: 5
Training loss: 1.8347520612930421
Validation loss: 2.4725740617982934

Epoch: 6| Step: 6
Training loss: 2.352587707700675
Validation loss: 2.4788727048748167

Epoch: 6| Step: 7
Training loss: 2.87483214842046
Validation loss: 2.466255429756719

Epoch: 6| Step: 8
Training loss: 2.6506602994137487
Validation loss: 2.466810362465283

Epoch: 6| Step: 9
Training loss: 2.4473866206746187
Validation loss: 2.4931514641295607

Epoch: 6| Step: 10
Training loss: 3.0028796680285375
Validation loss: 2.469301940104779

Epoch: 6| Step: 11
Training loss: 2.6948661102837663
Validation loss: 2.4701680920698053

Epoch: 6| Step: 12
Training loss: 2.315183680355708
Validation loss: 2.4688097654631616

Epoch: 6| Step: 13
Training loss: 3.812319266616162
Validation loss: 2.469512415697242

Epoch: 105| Step: 0
Training loss: 2.564905665635366
Validation loss: 2.4606982725417166

Epoch: 6| Step: 1
Training loss: 2.5153482415210515
Validation loss: 2.472827933345427

Epoch: 6| Step: 2
Training loss: 2.964973698156818
Validation loss: 2.4881251537266293

Epoch: 6| Step: 3
Training loss: 2.230079523387797
Validation loss: 2.4809173651144256

Epoch: 6| Step: 4
Training loss: 2.280546524065074
Validation loss: 2.4827411624712834

Epoch: 6| Step: 5
Training loss: 2.58254625779385
Validation loss: 2.460864982832194

Epoch: 6| Step: 6
Training loss: 2.983940692077007
Validation loss: 2.4671619926368056

Epoch: 6| Step: 7
Training loss: 2.5554817668194927
Validation loss: 2.4916227317138753

Epoch: 6| Step: 8
Training loss: 2.2857051874729004
Validation loss: 2.4900826269148615

Epoch: 6| Step: 9
Training loss: 3.3702476385575344
Validation loss: 2.4578796358774526

Epoch: 6| Step: 10
Training loss: 2.2711461636243078
Validation loss: 2.4708907136298355

Epoch: 6| Step: 11
Training loss: 2.614782247284487
Validation loss: 2.480588011409559

Epoch: 6| Step: 12
Training loss: 2.4405069632810896
Validation loss: 2.4898626368466523

Epoch: 6| Step: 13
Training loss: 2.061312131113039
Validation loss: 2.4778866933432466

Epoch: 106| Step: 0
Training loss: 2.282972965436316
Validation loss: 2.481998539856393

Epoch: 6| Step: 1
Training loss: 2.230430696232959
Validation loss: 2.4668608613413165

Epoch: 6| Step: 2
Training loss: 2.4935897660942197
Validation loss: 2.468966371652923

Epoch: 6| Step: 3
Training loss: 2.4671063323436897
Validation loss: 2.4736061658129618

Epoch: 6| Step: 4
Training loss: 2.536575178918548
Validation loss: 2.473910059476805

Epoch: 6| Step: 5
Training loss: 2.5524060622666522
Validation loss: 2.471995448800863

Epoch: 6| Step: 6
Training loss: 3.213453063897475
Validation loss: 2.485261013699901

Epoch: 6| Step: 7
Training loss: 2.396679958082048
Validation loss: 2.4852130642665915

Epoch: 6| Step: 8
Training loss: 2.0348804601852297
Validation loss: 2.4684849434919873

Epoch: 6| Step: 9
Training loss: 3.1451380552911856
Validation loss: 2.479072917166306

Epoch: 6| Step: 10
Training loss: 2.230831404029526
Validation loss: 2.469332040587316

Epoch: 6| Step: 11
Training loss: 2.782981933370622
Validation loss: 2.4678001596334136

Epoch: 6| Step: 12
Training loss: 2.928204702882369
Validation loss: 2.454262174069731

Epoch: 6| Step: 13
Training loss: 2.649180980290514
Validation loss: 2.4653721176399737

Epoch: 107| Step: 0
Training loss: 2.6960151972639497
Validation loss: 2.4769249971648652

Epoch: 6| Step: 1
Training loss: 3.3976353893573794
Validation loss: 2.467508097389921

Epoch: 6| Step: 2
Training loss: 2.7218102956585675
Validation loss: 2.4647681982956975

Epoch: 6| Step: 3
Training loss: 2.394731273666712
Validation loss: 2.46797822015701

Epoch: 6| Step: 4
Training loss: 2.715213448580074
Validation loss: 2.4864229859976583

Epoch: 6| Step: 5
Training loss: 2.3287914781464965
Validation loss: 2.4673815925332327

Epoch: 6| Step: 6
Training loss: 3.0553464837265376
Validation loss: 2.4675234448498684

Epoch: 6| Step: 7
Training loss: 2.656919686662454
Validation loss: 2.4816393286964082

Epoch: 6| Step: 8
Training loss: 1.91764887921864
Validation loss: 2.4739946861165256

Epoch: 6| Step: 9
Training loss: 2.47594976215824
Validation loss: 2.466910507030707

Epoch: 6| Step: 10
Training loss: 2.4604051771119084
Validation loss: 2.4725647769621584

Epoch: 6| Step: 11
Training loss: 2.274442365444873
Validation loss: 2.4630391840026205

Epoch: 6| Step: 12
Training loss: 1.8937964833412146
Validation loss: 2.485061061656357

Epoch: 6| Step: 13
Training loss: 2.7498053568534324
Validation loss: 2.4738520348881665

Epoch: 108| Step: 0
Training loss: 2.9928012945438005
Validation loss: 2.4709955514109585

Epoch: 6| Step: 1
Training loss: 2.525935492627442
Validation loss: 2.4700693291877522

Epoch: 6| Step: 2
Training loss: 2.1560707570640054
Validation loss: 2.484705185807193

Epoch: 6| Step: 3
Training loss: 2.541964424910822
Validation loss: 2.469323279269944

Epoch: 6| Step: 4
Training loss: 2.2866842264033176
Validation loss: 2.456964943788648

Epoch: 6| Step: 5
Training loss: 2.628233144669254
Validation loss: 2.4694701214464136

Epoch: 6| Step: 6
Training loss: 2.890383158696637
Validation loss: 2.4543194845992846

Epoch: 6| Step: 7
Training loss: 2.3455394779900973
Validation loss: 2.454400769016455

Epoch: 6| Step: 8
Training loss: 3.1553905563318594
Validation loss: 2.4739194439269276

Epoch: 6| Step: 9
Training loss: 2.6467546275757696
Validation loss: 2.4669968026453795

Epoch: 6| Step: 10
Training loss: 1.9430795132578926
Validation loss: 2.4602586566814226

Epoch: 6| Step: 11
Training loss: 2.4169067614322715
Validation loss: 2.470627123660726

Epoch: 6| Step: 12
Training loss: 2.505325557850291
Validation loss: 2.471973667571579

Epoch: 6| Step: 13
Training loss: 3.158285259058765
Validation loss: 2.4565184404477223

Epoch: 109| Step: 0
Training loss: 2.078786414877488
Validation loss: 2.4624721593195495

Epoch: 6| Step: 1
Training loss: 2.2453011084408963
Validation loss: 2.4671940197266506

Epoch: 6| Step: 2
Training loss: 3.008641195703207
Validation loss: 2.4810521859531405

Epoch: 6| Step: 3
Training loss: 1.9946258582251803
Validation loss: 2.464557204160325

Epoch: 6| Step: 4
Training loss: 2.3195719452291708
Validation loss: 2.4797731141916537

Epoch: 6| Step: 5
Training loss: 2.358321504147611
Validation loss: 2.478278398997379

Epoch: 6| Step: 6
Training loss: 2.281725481202729
Validation loss: 2.4689680610408127

Epoch: 6| Step: 7
Training loss: 2.764821684814777
Validation loss: 2.457036245743902

Epoch: 6| Step: 8
Training loss: 2.7586936515581018
Validation loss: 2.4927361182452232

Epoch: 6| Step: 9
Training loss: 2.1912169349208193
Validation loss: 2.4804335425264

Epoch: 6| Step: 10
Training loss: 3.3377411944499125
Validation loss: 2.478709728817827

Epoch: 6| Step: 11
Training loss: 3.4750052747068922
Validation loss: 2.4887274257123364

Epoch: 6| Step: 12
Training loss: 2.405437282692188
Validation loss: 2.4645457556557737

Epoch: 6| Step: 13
Training loss: 2.169696401286337
Validation loss: 2.4806661826824197

Epoch: 110| Step: 0
Training loss: 1.722290553853237
Validation loss: 2.490176232511928

Epoch: 6| Step: 1
Training loss: 2.622477454714965
Validation loss: 2.4720050354884493

Epoch: 6| Step: 2
Training loss: 3.1973755385906473
Validation loss: 2.470381429665488

Epoch: 6| Step: 3
Training loss: 2.5502272934685744
Validation loss: 2.478239495833002

Epoch: 6| Step: 4
Training loss: 2.4283174534236767
Validation loss: 2.4679254307742875

Epoch: 6| Step: 5
Training loss: 2.710523238397176
Validation loss: 2.493623607581429

Epoch: 6| Step: 6
Training loss: 3.0555504558019755
Validation loss: 2.480039781125012

Epoch: 6| Step: 7
Training loss: 2.946365127871262
Validation loss: 2.4729456277729907

Epoch: 6| Step: 8
Training loss: 2.359893135625481
Validation loss: 2.4850754393136025

Epoch: 6| Step: 9
Training loss: 2.2138425256056338
Validation loss: 2.4818669854800177

Epoch: 6| Step: 10
Training loss: 2.5236325026241007
Validation loss: 2.483261379920925

Epoch: 6| Step: 11
Training loss: 1.9254021261734247
Validation loss: 2.487447579319445

Epoch: 6| Step: 12
Training loss: 2.68963024079786
Validation loss: 2.485298864659061

Epoch: 6| Step: 13
Training loss: 2.9401788062911867
Validation loss: 2.472026498582374

Epoch: 111| Step: 0
Training loss: 3.0421691549146734
Validation loss: 2.4643707084091493

Epoch: 6| Step: 1
Training loss: 2.2245139887775687
Validation loss: 2.478577397391739

Epoch: 6| Step: 2
Training loss: 2.236388679584091
Validation loss: 2.4951693009075067

Epoch: 6| Step: 3
Training loss: 3.0768284269593766
Validation loss: 2.465849063380374

Epoch: 6| Step: 4
Training loss: 2.7202347833617835
Validation loss: 2.4670867478101

Epoch: 6| Step: 5
Training loss: 2.0066028320365517
Validation loss: 2.4792311137726024

Epoch: 6| Step: 6
Training loss: 1.9732234328291585
Validation loss: 2.477010060021151

Epoch: 6| Step: 7
Training loss: 2.833258085560603
Validation loss: 2.474173401236902

Epoch: 6| Step: 8
Training loss: 3.2949273743100225
Validation loss: 2.4632164625742137

Epoch: 6| Step: 9
Training loss: 2.2067927138794095
Validation loss: 2.467577363838298

Epoch: 6| Step: 10
Training loss: 3.2567754691256856
Validation loss: 2.4730522075766905

Epoch: 6| Step: 11
Training loss: 2.285125993055565
Validation loss: 2.4797525777764533

Epoch: 6| Step: 12
Training loss: 2.4162092324028013
Validation loss: 2.473501370275898

Epoch: 6| Step: 13
Training loss: 1.6174415720508772
Validation loss: 2.459565704891181

Epoch: 112| Step: 0
Training loss: 2.1390818581774487
Validation loss: 2.4765814661451575

Epoch: 6| Step: 1
Training loss: 2.6962101865047563
Validation loss: 2.4822451604102755

Epoch: 6| Step: 2
Training loss: 2.085293216716205
Validation loss: 2.4557351660242763

Epoch: 6| Step: 3
Training loss: 2.3629703033428036
Validation loss: 2.4684716126510846

Epoch: 6| Step: 4
Training loss: 2.388737650329829
Validation loss: 2.479593579568768

Epoch: 6| Step: 5
Training loss: 2.6993906322467347
Validation loss: 2.4848901265301104

Epoch: 6| Step: 6
Training loss: 2.641866358320309
Validation loss: 2.4579942021603896

Epoch: 6| Step: 7
Training loss: 2.3163200992819726
Validation loss: 2.469441273613245

Epoch: 6| Step: 8
Training loss: 2.1349376110100438
Validation loss: 2.46992773725934

Epoch: 6| Step: 9
Training loss: 3.0846270519103993
Validation loss: 2.4541310983351314

Epoch: 6| Step: 10
Training loss: 2.3212139805971104
Validation loss: 2.480494270842605

Epoch: 6| Step: 11
Training loss: 2.7437671773802954
Validation loss: 2.468916173357701

Epoch: 6| Step: 12
Training loss: 3.435048009101052
Validation loss: 2.4609494976136035

Epoch: 6| Step: 13
Training loss: 2.6050986694862037
Validation loss: 2.460693160774872

Epoch: 113| Step: 0
Training loss: 2.905907067195837
Validation loss: 2.4652484528860246

Epoch: 6| Step: 1
Training loss: 2.89720666462017
Validation loss: 2.458745502300338

Epoch: 6| Step: 2
Training loss: 2.7284287675755596
Validation loss: 2.4468198620915933

Epoch: 6| Step: 3
Training loss: 2.435618138742902
Validation loss: 2.474167475428167

Epoch: 6| Step: 4
Training loss: 2.825356071110038
Validation loss: 2.480772783700498

Epoch: 6| Step: 5
Training loss: 2.27847643994625
Validation loss: 2.4729357420214844

Epoch: 6| Step: 6
Training loss: 2.8851072694084796
Validation loss: 2.4672767788690306

Epoch: 6| Step: 7
Training loss: 2.287634706960496
Validation loss: 2.4752093220289453

Epoch: 6| Step: 8
Training loss: 2.553879636367384
Validation loss: 2.4720547842412595

Epoch: 6| Step: 9
Training loss: 2.0234078070034185
Validation loss: 2.4659302271344603

Epoch: 6| Step: 10
Training loss: 2.078064422871791
Validation loss: 2.473455418157828

Epoch: 6| Step: 11
Training loss: 2.3360812037737473
Validation loss: 2.4657591406480592

Epoch: 6| Step: 12
Training loss: 3.3037717014715673
Validation loss: 2.4708225859335466

Epoch: 6| Step: 13
Training loss: 1.9709840239753627
Validation loss: 2.4627804310555703

Epoch: 114| Step: 0
Training loss: 2.3188687851907726
Validation loss: 2.4598301925298234

Epoch: 6| Step: 1
Training loss: 3.176143686556288
Validation loss: 2.4535060409237843

Epoch: 6| Step: 2
Training loss: 2.792137950762836
Validation loss: 2.470501140674952

Epoch: 6| Step: 3
Training loss: 2.368499694321693
Validation loss: 2.4787555897349507

Epoch: 6| Step: 4
Training loss: 2.6268989415590047
Validation loss: 2.466618034922151

Epoch: 6| Step: 5
Training loss: 2.8435080289075017
Validation loss: 2.4865358572293648

Epoch: 6| Step: 6
Training loss: 2.482932577716487
Validation loss: 2.4811654130990735

Epoch: 6| Step: 7
Training loss: 2.564715474430393
Validation loss: 2.4837359453101078

Epoch: 6| Step: 8
Training loss: 2.429177577243423
Validation loss: 2.484285003813128

Epoch: 6| Step: 9
Training loss: 2.387016115534525
Validation loss: 2.4882251915225853

Epoch: 6| Step: 10
Training loss: 2.03128274744486
Validation loss: 2.481222881271126

Epoch: 6| Step: 11
Training loss: 2.7154085518602216
Validation loss: 2.474659661892533

Epoch: 6| Step: 12
Training loss: 2.665630516771017
Validation loss: 2.4805230118359822

Epoch: 6| Step: 13
Training loss: 2.44180045645559
Validation loss: 2.490400965678138

Epoch: 115| Step: 0
Training loss: 1.6712710992227346
Validation loss: 2.468915199888616

Epoch: 6| Step: 1
Training loss: 2.906112503572918
Validation loss: 2.500209689831825

Epoch: 6| Step: 2
Training loss: 3.093278637051701
Validation loss: 2.493417005634784

Epoch: 6| Step: 3
Training loss: 2.3129356592500723
Validation loss: 2.4610771310170465

Epoch: 6| Step: 4
Training loss: 2.7888604953818352
Validation loss: 2.4914744941315137

Epoch: 6| Step: 5
Training loss: 2.2620722835334366
Validation loss: 2.4784811955479418

Epoch: 6| Step: 6
Training loss: 2.5001055695178414
Validation loss: 2.4635221842215906

Epoch: 6| Step: 7
Training loss: 2.9922128382473994
Validation loss: 2.487369238791353

Epoch: 6| Step: 8
Training loss: 2.002288939060344
Validation loss: 2.487306379892779

Epoch: 6| Step: 9
Training loss: 2.9210566226286234
Validation loss: 2.4919619485660642

Epoch: 6| Step: 10
Training loss: 2.438250499508213
Validation loss: 2.4595713813285953

Epoch: 6| Step: 11
Training loss: 2.599067660206549
Validation loss: 2.4667190135327988

Epoch: 6| Step: 12
Training loss: 2.328054337421238
Validation loss: 2.4527508745790754

Epoch: 6| Step: 13
Training loss: 2.724541907346796
Validation loss: 2.4518753358180536

Epoch: 116| Step: 0
Training loss: 2.9005349685252364
Validation loss: 2.477757992046113

Epoch: 6| Step: 1
Training loss: 3.278927226132422
Validation loss: 2.474362686005116

Epoch: 6| Step: 2
Training loss: 2.429278765578857
Validation loss: 2.4660116335604214

Epoch: 6| Step: 3
Training loss: 2.6856608640581183
Validation loss: 2.469598778181105

Epoch: 6| Step: 4
Training loss: 2.0768587083432966
Validation loss: 2.4772906829765993

Epoch: 6| Step: 5
Training loss: 2.602802977501594
Validation loss: 2.4687210461377775

Epoch: 6| Step: 6
Training loss: 2.4132940062941834
Validation loss: 2.4580227530711025

Epoch: 6| Step: 7
Training loss: 1.8475807610024828
Validation loss: 2.4585939539989865

Epoch: 6| Step: 8
Training loss: 2.797038153466234
Validation loss: 2.4879007415418704

Epoch: 6| Step: 9
Training loss: 2.3956648615330525
Validation loss: 2.4411368761002628

Epoch: 6| Step: 10
Training loss: 2.243228683902667
Validation loss: 2.4619076099514494

Epoch: 6| Step: 11
Training loss: 2.6468813665284174
Validation loss: 2.473554245870777

Epoch: 6| Step: 12
Training loss: 2.775143810360532
Validation loss: 2.4708794106754763

Epoch: 6| Step: 13
Training loss: 2.289735558412743
Validation loss: 2.462964822871762

Epoch: 117| Step: 0
Training loss: 1.8148349323296606
Validation loss: 2.4688764928891738

Epoch: 6| Step: 1
Training loss: 2.9379062777450824
Validation loss: 2.463930442519989

Epoch: 6| Step: 2
Training loss: 2.3604057031182135
Validation loss: 2.4700758927451583

Epoch: 6| Step: 3
Training loss: 3.3200436472034425
Validation loss: 2.4724905384924982

Epoch: 6| Step: 4
Training loss: 2.4009881885941877
Validation loss: 2.4752339566683434

Epoch: 6| Step: 5
Training loss: 2.4320031811166336
Validation loss: 2.448300503860449

Epoch: 6| Step: 6
Training loss: 3.284437103119892
Validation loss: 2.4538316160321756

Epoch: 6| Step: 7
Training loss: 2.7907995803749586
Validation loss: 2.467881972876839

Epoch: 6| Step: 8
Training loss: 2.3341280968759475
Validation loss: 2.455904041032078

Epoch: 6| Step: 9
Training loss: 2.356787873657894
Validation loss: 2.453849943490998

Epoch: 6| Step: 10
Training loss: 2.1067566621647216
Validation loss: 2.476137250970188

Epoch: 6| Step: 11
Training loss: 2.8021886207814006
Validation loss: 2.45996611904887

Epoch: 6| Step: 12
Training loss: 2.2516484050259615
Validation loss: 2.467410897710408

Epoch: 6| Step: 13
Training loss: 1.7238555677811138
Validation loss: 2.4790852334172366

Epoch: 118| Step: 0
Training loss: 2.7235264529979224
Validation loss: 2.4865801098002223

Epoch: 6| Step: 1
Training loss: 2.1593855022611153
Validation loss: 2.476926540363388

Epoch: 6| Step: 2
Training loss: 2.2496962872140296
Validation loss: 2.4660445488342138

Epoch: 6| Step: 3
Training loss: 3.0568314075345007
Validation loss: 2.464678977756932

Epoch: 6| Step: 4
Training loss: 2.4017672707715083
Validation loss: 2.462139820763155

Epoch: 6| Step: 5
Training loss: 1.60072520629422
Validation loss: 2.4461407868403207

Epoch: 6| Step: 6
Training loss: 3.229616064159175
Validation loss: 2.4689408988246075

Epoch: 6| Step: 7
Training loss: 3.3005045938516195
Validation loss: 2.4826641562701295

Epoch: 6| Step: 8
Training loss: 2.143163025686378
Validation loss: 2.461863139337063

Epoch: 6| Step: 9
Training loss: 2.0017288603425714
Validation loss: 2.474123179066122

Epoch: 6| Step: 10
Training loss: 2.693713523812501
Validation loss: 2.4704658295449367

Epoch: 6| Step: 11
Training loss: 2.7995367756911618
Validation loss: 2.48158111293008

Epoch: 6| Step: 12
Training loss: 1.9717595545712694
Validation loss: 2.469243195713284

Epoch: 6| Step: 13
Training loss: 2.4833351694224013
Validation loss: 2.464181988816176

Epoch: 119| Step: 0
Training loss: 2.134030954717419
Validation loss: 2.468028975597091

Epoch: 6| Step: 1
Training loss: 2.8803131102852775
Validation loss: 2.444837503941031

Epoch: 6| Step: 2
Training loss: 1.9391513063319419
Validation loss: 2.4753528903145865

Epoch: 6| Step: 3
Training loss: 2.6227570897029167
Validation loss: 2.4690978476392265

Epoch: 6| Step: 4
Training loss: 2.546207176601216
Validation loss: 2.4556161951964306

Epoch: 6| Step: 5
Training loss: 2.4152019490535186
Validation loss: 2.463480038966771

Epoch: 6| Step: 6
Training loss: 2.432673150042509
Validation loss: 2.470175672445623

Epoch: 6| Step: 7
Training loss: 2.5985283097704492
Validation loss: 2.464268422633501

Epoch: 6| Step: 8
Training loss: 2.8411665699193605
Validation loss: 2.473555945598691

Epoch: 6| Step: 9
Training loss: 2.6844944670874704
Validation loss: 2.4623715114974614

Epoch: 6| Step: 10
Training loss: 2.526802016720277
Validation loss: 2.4923253607117095

Epoch: 6| Step: 11
Training loss: 2.4226168573025277
Validation loss: 2.484183720666241

Epoch: 6| Step: 12
Training loss: 2.63041129257674
Validation loss: 2.4650187085342847

Epoch: 6| Step: 13
Training loss: 3.1721702400694736
Validation loss: 2.4514713946455067

Epoch: 120| Step: 0
Training loss: 3.0189282603577254
Validation loss: 2.4722482556925764

Epoch: 6| Step: 1
Training loss: 2.4567543929062605
Validation loss: 2.4856020001939876

Epoch: 6| Step: 2
Training loss: 3.031350360270793
Validation loss: 2.468084192325017

Epoch: 6| Step: 3
Training loss: 2.488356177431052
Validation loss: 2.459812352046495

Epoch: 6| Step: 4
Training loss: 2.7375976754098965
Validation loss: 2.473143647555576

Epoch: 6| Step: 5
Training loss: 2.280362413782006
Validation loss: 2.46674747749008

Epoch: 6| Step: 6
Training loss: 2.182457589068405
Validation loss: 2.477832422402382

Epoch: 6| Step: 7
Training loss: 2.049536219913139
Validation loss: 2.492006856794439

Epoch: 6| Step: 8
Training loss: 1.9631171404205454
Validation loss: 2.4655132578902603

Epoch: 6| Step: 9
Training loss: 2.388077918604145
Validation loss: 2.4777341388466123

Epoch: 6| Step: 10
Training loss: 2.672702415801313
Validation loss: 2.4792913979595537

Epoch: 6| Step: 11
Training loss: 2.560469497454285
Validation loss: 2.46671428475096

Epoch: 6| Step: 12
Training loss: 2.564013894577585
Validation loss: 2.4872246510547087

Epoch: 6| Step: 13
Training loss: 3.1899672290709176
Validation loss: 2.470742557199132

Epoch: 121| Step: 0
Training loss: 2.010448580737288
Validation loss: 2.4869291921056185

Epoch: 6| Step: 1
Training loss: 2.499242667882386
Validation loss: 2.460483694742524

Epoch: 6| Step: 2
Training loss: 2.6670549427919727
Validation loss: 2.457613647953985

Epoch: 6| Step: 3
Training loss: 2.689451529309167
Validation loss: 2.4694359821773006

Epoch: 6| Step: 4
Training loss: 2.8872448102471875
Validation loss: 2.470676254754753

Epoch: 6| Step: 5
Training loss: 2.5836676924707613
Validation loss: 2.4669793392529185

Epoch: 6| Step: 6
Training loss: 2.6837102206746293
Validation loss: 2.472760127540973

Epoch: 6| Step: 7
Training loss: 3.1529543449563926
Validation loss: 2.4513411930117

Epoch: 6| Step: 8
Training loss: 3.143344593641461
Validation loss: 2.4639844651042146

Epoch: 6| Step: 9
Training loss: 1.710983624119651
Validation loss: 2.4599680761958242

Epoch: 6| Step: 10
Training loss: 2.138444890209218
Validation loss: 2.448481860833074

Epoch: 6| Step: 11
Training loss: 1.9348610780314766
Validation loss: 2.437108879588375

Epoch: 6| Step: 12
Training loss: 2.4646011450783045
Validation loss: 2.467080682361126

Epoch: 6| Step: 13
Training loss: 2.604731648510916
Validation loss: 2.4709258340090217

Epoch: 122| Step: 0
Training loss: 2.268437816484794
Validation loss: 2.4819651869785333

Epoch: 6| Step: 1
Training loss: 2.9904729248413173
Validation loss: 2.456699471470541

Epoch: 6| Step: 2
Training loss: 2.6884261021588074
Validation loss: 2.4637946889278988

Epoch: 6| Step: 3
Training loss: 2.6754647394921176
Validation loss: 2.4711872021391867

Epoch: 6| Step: 4
Training loss: 2.433691129986366
Validation loss: 2.4741757243075497

Epoch: 6| Step: 5
Training loss: 2.624657926523418
Validation loss: 2.474646548715945

Epoch: 6| Step: 6
Training loss: 2.605270263798061
Validation loss: 2.45942648631921

Epoch: 6| Step: 7
Training loss: 2.727498503211683
Validation loss: 2.4740370418720006

Epoch: 6| Step: 8
Training loss: 2.9115670080949454
Validation loss: 2.4885548932641766

Epoch: 6| Step: 9
Training loss: 2.6155444097466
Validation loss: 2.473597687544089

Epoch: 6| Step: 10
Training loss: 2.118480329878249
Validation loss: 2.468378443267706

Epoch: 6| Step: 11
Training loss: 2.4076304253636436
Validation loss: 2.4852867380559927

Epoch: 6| Step: 12
Training loss: 2.2885891682124546
Validation loss: 2.456624858955889

Epoch: 6| Step: 13
Training loss: 1.8860093830761149
Validation loss: 2.4673533727888497

Epoch: 123| Step: 0
Training loss: 3.066672927048416
Validation loss: 2.471369990583825

Epoch: 6| Step: 1
Training loss: 2.486549049984439
Validation loss: 2.4555457728334327

Epoch: 6| Step: 2
Training loss: 1.7932261695655805
Validation loss: 2.463116630978807

Epoch: 6| Step: 3
Training loss: 2.197885980135741
Validation loss: 2.466819367578079

Epoch: 6| Step: 4
Training loss: 3.132762575584123
Validation loss: 2.4517756760831753

Epoch: 6| Step: 5
Training loss: 2.56222886302551
Validation loss: 2.4859527708491167

Epoch: 6| Step: 6
Training loss: 1.8685704301274817
Validation loss: 2.4581097580607403

Epoch: 6| Step: 7
Training loss: 2.7816710421293696
Validation loss: 2.4401566253366327

Epoch: 6| Step: 8
Training loss: 2.632536016147216
Validation loss: 2.4457974171124377

Epoch: 6| Step: 9
Training loss: 2.331209124086599
Validation loss: 2.4561523021456115

Epoch: 6| Step: 10
Training loss: 2.5710449102834785
Validation loss: 2.476782852141337

Epoch: 6| Step: 11
Training loss: 2.7435275115783164
Validation loss: 2.4729026354549344

Epoch: 6| Step: 12
Training loss: 2.5006957039804445
Validation loss: 2.4633096351836827

Epoch: 6| Step: 13
Training loss: 2.299617142532161
Validation loss: 2.4656630864352156

Epoch: 124| Step: 0
Training loss: 2.615117133819476
Validation loss: 2.459937822573426

Epoch: 6| Step: 1
Training loss: 2.6058094997147645
Validation loss: 2.4506090036361554

Epoch: 6| Step: 2
Training loss: 2.3345670730847914
Validation loss: 2.4720767602377385

Epoch: 6| Step: 3
Training loss: 2.372907017483628
Validation loss: 2.4509483416872784

Epoch: 6| Step: 4
Training loss: 2.894113116623385
Validation loss: 2.4652836032097443

Epoch: 6| Step: 5
Training loss: 2.817189778238688
Validation loss: 2.4592934706703606

Epoch: 6| Step: 6
Training loss: 2.4025043216789506
Validation loss: 2.4437610462002954

Epoch: 6| Step: 7
Training loss: 2.5061385132305753
Validation loss: 2.4662457328825043

Epoch: 6| Step: 8
Training loss: 2.4234087609678223
Validation loss: 2.4747856196447655

Epoch: 6| Step: 9
Training loss: 2.242216635059511
Validation loss: 2.465577175646087

Epoch: 6| Step: 10
Training loss: 2.3342201273455925
Validation loss: 2.456970064877232

Epoch: 6| Step: 11
Training loss: 2.8975486523523677
Validation loss: 2.4609126795363316

Epoch: 6| Step: 12
Training loss: 2.247484496405809
Validation loss: 2.463699332306271

Epoch: 6| Step: 13
Training loss: 3.0986999062031826
Validation loss: 2.460041093964107

Epoch: 125| Step: 0
Training loss: 2.5885686022292833
Validation loss: 2.4523456067683376

Epoch: 6| Step: 1
Training loss: 2.9450340240533777
Validation loss: 2.4777459382110947

Epoch: 6| Step: 2
Training loss: 2.2784494428016875
Validation loss: 2.4687437226420883

Epoch: 6| Step: 3
Training loss: 2.300444858486296
Validation loss: 2.4615798374939737

Epoch: 6| Step: 4
Training loss: 2.9550931316229176
Validation loss: 2.4822135614499627

Epoch: 6| Step: 5
Training loss: 2.823583845474024
Validation loss: 2.4418354146484176

Epoch: 6| Step: 6
Training loss: 2.1487617386724196
Validation loss: 2.4546624298516777

Epoch: 6| Step: 7
Training loss: 2.222126929571191
Validation loss: 2.4694541715057436

Epoch: 6| Step: 8
Training loss: 2.313784474549332
Validation loss: 2.4666000595705886

Epoch: 6| Step: 9
Training loss: 3.1569720660361287
Validation loss: 2.469185272221232

Epoch: 6| Step: 10
Training loss: 2.2534090283713493
Validation loss: 2.46840227574681

Epoch: 6| Step: 11
Training loss: 2.767268064544189
Validation loss: 2.4635861088894604

Epoch: 6| Step: 12
Training loss: 2.1952074779219086
Validation loss: 2.448024552759942

Epoch: 6| Step: 13
Training loss: 1.794344239378177
Validation loss: 2.4447785030690645

Epoch: 126| Step: 0
Training loss: 2.7475000635898574
Validation loss: 2.4586308672764696

Epoch: 6| Step: 1
Training loss: 2.6285133464983064
Validation loss: 2.457715031987693

Epoch: 6| Step: 2
Training loss: 2.627238091537199
Validation loss: 2.4638619933452146

Epoch: 6| Step: 3
Training loss: 2.7433430120020073
Validation loss: 2.463495879814543

Epoch: 6| Step: 4
Training loss: 2.8027047717295495
Validation loss: 2.4635568986990815

Epoch: 6| Step: 5
Training loss: 2.6377598494395635
Validation loss: 2.46515170748509

Epoch: 6| Step: 6
Training loss: 2.1793251967038514
Validation loss: 2.4553673797551703

Epoch: 6| Step: 7
Training loss: 1.6550885572683152
Validation loss: 2.4557466164555537

Epoch: 6| Step: 8
Training loss: 2.2087056787747117
Validation loss: 2.455409105153527

Epoch: 6| Step: 9
Training loss: 2.8260881876863073
Validation loss: 2.487167844147541

Epoch: 6| Step: 10
Training loss: 2.140719891971808
Validation loss: 2.4835385481479992

Epoch: 6| Step: 11
Training loss: 2.6750323284726902
Validation loss: 2.4513281219027085

Epoch: 6| Step: 12
Training loss: 3.0352000818806557
Validation loss: 2.4665997384139406

Epoch: 6| Step: 13
Training loss: 1.8617703691979017
Validation loss: 2.449547286373309

Epoch: 127| Step: 0
Training loss: 2.630223481288888
Validation loss: 2.456359819536603

Epoch: 6| Step: 1
Training loss: 2.3968152452801457
Validation loss: 2.4825464274226516

Epoch: 6| Step: 2
Training loss: 2.1212261573112436
Validation loss: 2.465579783395452

Epoch: 6| Step: 3
Training loss: 3.4055348616761796
Validation loss: 2.4520549693873384

Epoch: 6| Step: 4
Training loss: 2.887927637181662
Validation loss: 2.4601062376651406

Epoch: 6| Step: 5
Training loss: 2.689363764855323
Validation loss: 2.461165268620797

Epoch: 6| Step: 6
Training loss: 2.0220440518252745
Validation loss: 2.4536581897579666

Epoch: 6| Step: 7
Training loss: 1.7503920524674774
Validation loss: 2.476428467882003

Epoch: 6| Step: 8
Training loss: 2.856314767316059
Validation loss: 2.4722005194783367

Epoch: 6| Step: 9
Training loss: 2.1724288563553222
Validation loss: 2.467874583867421

Epoch: 6| Step: 10
Training loss: 2.269723486842852
Validation loss: 2.4539730068595644

Epoch: 6| Step: 11
Training loss: 2.416790356156353
Validation loss: 2.4839575162568113

Epoch: 6| Step: 12
Training loss: 2.8259837437922783
Validation loss: 2.4406151240458622

Epoch: 6| Step: 13
Training loss: 2.1992863971611976
Validation loss: 2.4695956514827317

Epoch: 128| Step: 0
Training loss: 2.4796008416401025
Validation loss: 2.449255039434078

Epoch: 6| Step: 1
Training loss: 2.269123717074477
Validation loss: 2.457431434498795

Epoch: 6| Step: 2
Training loss: 2.0313843902733284
Validation loss: 2.4660728001887455

Epoch: 6| Step: 3
Training loss: 2.8958429203743807
Validation loss: 2.4395441145898946

Epoch: 6| Step: 4
Training loss: 2.3492360313903884
Validation loss: 2.4492883034040767

Epoch: 6| Step: 5
Training loss: 1.8623960299562632
Validation loss: 2.4619862259676872

Epoch: 6| Step: 6
Training loss: 2.0823243813348493
Validation loss: 2.4642558034560427

Epoch: 6| Step: 7
Training loss: 3.155730100813003
Validation loss: 2.4422701502023303

Epoch: 6| Step: 8
Training loss: 2.1412112136418915
Validation loss: 2.441627491235595

Epoch: 6| Step: 9
Training loss: 2.6408915187708897
Validation loss: 2.453718926707211

Epoch: 6| Step: 10
Training loss: 2.9468886309376225
Validation loss: 2.4631774896101475

Epoch: 6| Step: 11
Training loss: 2.763891937876116
Validation loss: 2.448703247988189

Epoch: 6| Step: 12
Training loss: 2.548861425189556
Validation loss: 2.482707133408001

Epoch: 6| Step: 13
Training loss: 2.8341215009790974
Validation loss: 2.4770615359805985

Epoch: 129| Step: 0
Training loss: 2.1823509651327555
Validation loss: 2.46965954662565

Epoch: 6| Step: 1
Training loss: 2.5965974184269203
Validation loss: 2.46540050252154

Epoch: 6| Step: 2
Training loss: 2.887001859954351
Validation loss: 2.4569679039627927

Epoch: 6| Step: 3
Training loss: 2.1290900194838343
Validation loss: 2.458158442674199

Epoch: 6| Step: 4
Training loss: 2.664988963549809
Validation loss: 2.4528199411075424

Epoch: 6| Step: 5
Training loss: 3.102676921659778
Validation loss: 2.4693299652407443

Epoch: 6| Step: 6
Training loss: 2.7511088129929964
Validation loss: 2.4417188381456376

Epoch: 6| Step: 7
Training loss: 2.0239946342140813
Validation loss: 2.45079671187281

Epoch: 6| Step: 8
Training loss: 2.3195851017478293
Validation loss: 2.471642321876754

Epoch: 6| Step: 9
Training loss: 2.5906577003541114
Validation loss: 2.4517168447933213

Epoch: 6| Step: 10
Training loss: 2.5358257614592663
Validation loss: 2.446078822046811

Epoch: 6| Step: 11
Training loss: 2.2636292184492017
Validation loss: 2.441415049547314

Epoch: 6| Step: 12
Training loss: 2.0562500324655084
Validation loss: 2.4537799943905885

Epoch: 6| Step: 13
Training loss: 2.913593817034911
Validation loss: 2.4541425379697888

Epoch: 130| Step: 0
Training loss: 2.092178552108445
Validation loss: 2.4660219712201057

Epoch: 6| Step: 1
Training loss: 2.8503037274123924
Validation loss: 2.4519278120516934

Epoch: 6| Step: 2
Training loss: 2.919529427274401
Validation loss: 2.454020024241835

Epoch: 6| Step: 3
Training loss: 2.147808412869629
Validation loss: 2.4676759054387594

Epoch: 6| Step: 4
Training loss: 2.2082891879677606
Validation loss: 2.465708396708691

Epoch: 6| Step: 5
Training loss: 2.5081978855336766
Validation loss: 2.462393872714402

Epoch: 6| Step: 6
Training loss: 2.3401608260225175
Validation loss: 2.444846433746691

Epoch: 6| Step: 7
Training loss: 2.5821105667835873
Validation loss: 2.4752043360350986

Epoch: 6| Step: 8
Training loss: 3.169369012988346
Validation loss: 2.468823148475259

Epoch: 6| Step: 9
Training loss: 2.85489257343161
Validation loss: 2.4758242426137462

Epoch: 6| Step: 10
Training loss: 1.756501382776721
Validation loss: 2.481371238988494

Epoch: 6| Step: 11
Training loss: 2.864551465406308
Validation loss: 2.4644378181715942

Epoch: 6| Step: 12
Training loss: 2.206490401443568
Validation loss: 2.472246022063971

Epoch: 6| Step: 13
Training loss: 2.2725378399710623
Validation loss: 2.4452175025083154

Epoch: 131| Step: 0
Training loss: 2.260626283644738
Validation loss: 2.4592393221042004

Epoch: 6| Step: 1
Training loss: 3.0574442334208674
Validation loss: 2.457131303800032

Epoch: 6| Step: 2
Training loss: 2.255401168460853
Validation loss: 2.4740743236628133

Epoch: 6| Step: 3
Training loss: 2.5915033192893926
Validation loss: 2.455731667256237

Epoch: 6| Step: 4
Training loss: 2.7695638764992445
Validation loss: 2.464508308917301

Epoch: 6| Step: 5
Training loss: 2.435396705286755
Validation loss: 2.4489679038162877

Epoch: 6| Step: 6
Training loss: 1.5778200213652909
Validation loss: 2.454381509784665

Epoch: 6| Step: 7
Training loss: 2.812237451802576
Validation loss: 2.4462921435335696

Epoch: 6| Step: 8
Training loss: 2.8015855727599295
Validation loss: 2.4518547063668796

Epoch: 6| Step: 9
Training loss: 2.4528088214023867
Validation loss: 2.4507203045065546

Epoch: 6| Step: 10
Training loss: 2.6523230752715015
Validation loss: 2.4567394362735646

Epoch: 6| Step: 11
Training loss: 1.9828445660438438
Validation loss: 2.4568976455575466

Epoch: 6| Step: 12
Training loss: 2.7632535260605184
Validation loss: 2.4609347956587695

Epoch: 6| Step: 13
Training loss: 2.546872940530705
Validation loss: 2.45234962939918

Epoch: 132| Step: 0
Training loss: 2.7653017016741117
Validation loss: 2.4529982048704224

Epoch: 6| Step: 1
Training loss: 2.3120425003725718
Validation loss: 2.4470885988881443

Epoch: 6| Step: 2
Training loss: 2.6521125434251775
Validation loss: 2.4584661510108194

Epoch: 6| Step: 3
Training loss: 2.5038386438440354
Validation loss: 2.464383905392018

Epoch: 6| Step: 4
Training loss: 1.8234784668387665
Validation loss: 2.454592197365785

Epoch: 6| Step: 5
Training loss: 2.783675689733194
Validation loss: 2.4686745834202157

Epoch: 6| Step: 6
Training loss: 2.1709144718677975
Validation loss: 2.457363673321963

Epoch: 6| Step: 7
Training loss: 2.375933012149681
Validation loss: 2.479988115786983

Epoch: 6| Step: 8
Training loss: 2.5814235970633694
Validation loss: 2.463945858044787

Epoch: 6| Step: 9
Training loss: 2.82778928671516
Validation loss: 2.443060685649939

Epoch: 6| Step: 10
Training loss: 2.288733344775299
Validation loss: 2.4311757476507716

Epoch: 6| Step: 11
Training loss: 2.605520725446724
Validation loss: 2.4680357325921145

Epoch: 6| Step: 12
Training loss: 2.6564684609727753
Validation loss: 2.461254233223101

Epoch: 6| Step: 13
Training loss: 2.5427417565919965
Validation loss: 2.455605968241579

Epoch: 133| Step: 0
Training loss: 3.0510360083891674
Validation loss: 2.4621137379479

Epoch: 6| Step: 1
Training loss: 2.5529898039229075
Validation loss: 2.4583876492392065

Epoch: 6| Step: 2
Training loss: 2.847856679385534
Validation loss: 2.4816478378586657

Epoch: 6| Step: 3
Training loss: 2.1251999256107457
Validation loss: 2.4406494794849034

Epoch: 6| Step: 4
Training loss: 1.834570517834912
Validation loss: 2.4731798409329953

Epoch: 6| Step: 5
Training loss: 2.6118662015169276
Validation loss: 2.439334827731379

Epoch: 6| Step: 6
Training loss: 2.433539474151471
Validation loss: 2.4560446575632517

Epoch: 6| Step: 7
Training loss: 2.534970222313299
Validation loss: 2.444793922959501

Epoch: 6| Step: 8
Training loss: 2.9434023058518926
Validation loss: 2.466040294885706

Epoch: 6| Step: 9
Training loss: 2.6448500200234357
Validation loss: 2.4549442879059673

Epoch: 6| Step: 10
Training loss: 2.2361465580291457
Validation loss: 2.4549818648640547

Epoch: 6| Step: 11
Training loss: 2.697710557131924
Validation loss: 2.4701167703209763

Epoch: 6| Step: 12
Training loss: 2.060420403960888
Validation loss: 2.4371875039904305

Epoch: 6| Step: 13
Training loss: 2.216073154164676
Validation loss: 2.4458833728086424

Epoch: 134| Step: 0
Training loss: 2.8255655077143422
Validation loss: 2.43978087381013

Epoch: 6| Step: 1
Training loss: 2.593121188131764
Validation loss: 2.4485937400059012

Epoch: 6| Step: 2
Training loss: 2.3818961961294076
Validation loss: 2.452311165857802

Epoch: 6| Step: 3
Training loss: 3.253135049384844
Validation loss: 2.463215776706999

Epoch: 6| Step: 4
Training loss: 2.828678477382285
Validation loss: 2.4506375992659812

Epoch: 6| Step: 5
Training loss: 2.38495427165788
Validation loss: 2.468923811572213

Epoch: 6| Step: 6
Training loss: 1.576896567059211
Validation loss: 2.4689571983707235

Epoch: 6| Step: 7
Training loss: 2.4004243952313264
Validation loss: 2.448163768381307

Epoch: 6| Step: 8
Training loss: 1.5512341815593826
Validation loss: 2.468467375347841

Epoch: 6| Step: 9
Training loss: 1.5968023503867226
Validation loss: 2.46310023553776

Epoch: 6| Step: 10
Training loss: 2.9186873566074385
Validation loss: 2.4425636705378255

Epoch: 6| Step: 11
Training loss: 2.6130208568536246
Validation loss: 2.457668959949465

Epoch: 6| Step: 12
Training loss: 2.457265481867286
Validation loss: 2.4415083374993403

Epoch: 6| Step: 13
Training loss: 3.1361721983070514
Validation loss: 2.44173310354058

Epoch: 135| Step: 0
Training loss: 2.8144487199609873
Validation loss: 2.4677382338185985

Epoch: 6| Step: 1
Training loss: 3.150438453798435
Validation loss: 2.4591836899449415

Epoch: 6| Step: 2
Training loss: 2.675356465056275
Validation loss: 2.4589860055644985

Epoch: 6| Step: 3
Training loss: 2.128879035985751
Validation loss: 2.4403928030329465

Epoch: 6| Step: 4
Training loss: 2.6917201774010118
Validation loss: 2.464493288037292

Epoch: 6| Step: 5
Training loss: 2.2998922861833453
Validation loss: 2.456576378755872

Epoch: 6| Step: 6
Training loss: 2.6383350081045878
Validation loss: 2.4506347648247235

Epoch: 6| Step: 7
Training loss: 2.4643622893920623
Validation loss: 2.477486365080561

Epoch: 6| Step: 8
Training loss: 2.8697097868180124
Validation loss: 2.4720550206882996

Epoch: 6| Step: 9
Training loss: 2.2020245773094147
Validation loss: 2.468380532915989

Epoch: 6| Step: 10
Training loss: 2.6472347082657732
Validation loss: 2.4747159106025154

Epoch: 6| Step: 11
Training loss: 1.4921872603331368
Validation loss: 2.4649436000495433

Epoch: 6| Step: 12
Training loss: 2.186189531435552
Validation loss: 2.454771038409456

Epoch: 6| Step: 13
Training loss: 1.9393909210033482
Validation loss: 2.4449749004280994

Epoch: 136| Step: 0
Training loss: 2.8143117367493646
Validation loss: 2.4632307928881616

Epoch: 6| Step: 1
Training loss: 2.7785274595997786
Validation loss: 2.476395073629643

Epoch: 6| Step: 2
Training loss: 2.803544515562135
Validation loss: 2.462936491108696

Epoch: 6| Step: 3
Training loss: 2.4669169127192454
Validation loss: 2.484559036654498

Epoch: 6| Step: 4
Training loss: 3.0092522680304628
Validation loss: 2.4544791690385983

Epoch: 6| Step: 5
Training loss: 2.3501395042081015
Validation loss: 2.4630356623029463

Epoch: 6| Step: 6
Training loss: 2.316649348608187
Validation loss: 2.468043592704325

Epoch: 6| Step: 7
Training loss: 2.2853050248712226
Validation loss: 2.4918977292060758

Epoch: 6| Step: 8
Training loss: 2.4024334650422845
Validation loss: 2.4681134351472287

Epoch: 6| Step: 9
Training loss: 2.4823344745752034
Validation loss: 2.4741996449697043

Epoch: 6| Step: 10
Training loss: 1.748705316917533
Validation loss: 2.462185194832194

Epoch: 6| Step: 11
Training loss: 2.1229984730640012
Validation loss: 2.463189917604366

Epoch: 6| Step: 12
Training loss: 2.639347647783326
Validation loss: 2.4632514956681715

Epoch: 6| Step: 13
Training loss: 2.336085694374237
Validation loss: 2.4449942447653252

Epoch: 137| Step: 0
Training loss: 2.128952725804337
Validation loss: 2.4613146228460527

Epoch: 6| Step: 1
Training loss: 2.8160288395163486
Validation loss: 2.442218598049489

Epoch: 6| Step: 2
Training loss: 2.7624322598122237
Validation loss: 2.4425274296793904

Epoch: 6| Step: 3
Training loss: 2.792993590771307
Validation loss: 2.4569896152755724

Epoch: 6| Step: 4
Training loss: 1.8699754148284913
Validation loss: 2.460242056192429

Epoch: 6| Step: 5
Training loss: 2.271435252451432
Validation loss: 2.468100965987055

Epoch: 6| Step: 6
Training loss: 2.455111822778631
Validation loss: 2.458858036325864

Epoch: 6| Step: 7
Training loss: 2.473828271492081
Validation loss: 2.4598321758399626

Epoch: 6| Step: 8
Training loss: 1.2107157350331348
Validation loss: 2.4403293733460445

Epoch: 6| Step: 9
Training loss: 3.0058819012110773
Validation loss: 2.451573942459918

Epoch: 6| Step: 10
Training loss: 2.4494219973981393
Validation loss: 2.4656693030136774

Epoch: 6| Step: 11
Training loss: 2.7026367628585137
Validation loss: 2.4433299481793007

Epoch: 6| Step: 12
Training loss: 2.553292176319151
Validation loss: 2.4494306080150356

Epoch: 6| Step: 13
Training loss: 2.7288984113482915
Validation loss: 2.4675206625324373

Epoch: 138| Step: 0
Training loss: 2.5780401042485295
Validation loss: 2.4567825272616615

Epoch: 6| Step: 1
Training loss: 2.7680811778165793
Validation loss: 2.4576917081784373

Epoch: 6| Step: 2
Training loss: 2.8805337805943223
Validation loss: 2.4456039066891013

Epoch: 6| Step: 3
Training loss: 2.0644515081740358
Validation loss: 2.47136988685024

Epoch: 6| Step: 4
Training loss: 2.5396389820322134
Validation loss: 2.4364365402588444

Epoch: 6| Step: 5
Training loss: 2.5577089133752264
Validation loss: 2.4339282126089232

Epoch: 6| Step: 6
Training loss: 1.8104502828072147
Validation loss: 2.4537280655383276

Epoch: 6| Step: 7
Training loss: 1.9457308767438408
Validation loss: 2.412104649692952

Epoch: 6| Step: 8
Training loss: 2.577269811110248
Validation loss: 2.453663469247281

Epoch: 6| Step: 9
Training loss: 2.8072003766694227
Validation loss: 2.457167817544558

Epoch: 6| Step: 10
Training loss: 2.414463639494882
Validation loss: 2.45465247882249

Epoch: 6| Step: 11
Training loss: 2.671709914433512
Validation loss: 2.463191374696977

Epoch: 6| Step: 12
Training loss: 2.6546377337878226
Validation loss: 2.469523248415145

Epoch: 6| Step: 13
Training loss: 2.155491349923429
Validation loss: 2.4454889879538735

Epoch: 139| Step: 0
Training loss: 2.3583808471781893
Validation loss: 2.450712283179711

Epoch: 6| Step: 1
Training loss: 3.1914129735719414
Validation loss: 2.451461088699607

Epoch: 6| Step: 2
Training loss: 1.8662553958597639
Validation loss: 2.44478680916426

Epoch: 6| Step: 3
Training loss: 2.35860627642676
Validation loss: 2.4430227652989034

Epoch: 6| Step: 4
Training loss: 2.093701831775977
Validation loss: 2.4557261531501076

Epoch: 6| Step: 5
Training loss: 2.089870103331211
Validation loss: 2.423084231576514

Epoch: 6| Step: 6
Training loss: 2.399895538599838
Validation loss: 2.446736617421038

Epoch: 6| Step: 7
Training loss: 2.897129802341236
Validation loss: 2.477038501974201

Epoch: 6| Step: 8
Training loss: 2.456751869704813
Validation loss: 2.451036138550843

Epoch: 6| Step: 9
Training loss: 2.358246792484861
Validation loss: 2.4588637748684654

Epoch: 6| Step: 10
Training loss: 2.059408240274342
Validation loss: 2.4571044541609983

Epoch: 6| Step: 11
Training loss: 2.8951351138194754
Validation loss: 2.4383275804527558

Epoch: 6| Step: 12
Training loss: 2.742479357715631
Validation loss: 2.461576469405171

Epoch: 6| Step: 13
Training loss: 2.624700529182216
Validation loss: 2.4354168951898894

Epoch: 140| Step: 0
Training loss: 2.041697352691278
Validation loss: 2.438815633465491

Epoch: 6| Step: 1
Training loss: 2.45265863930143
Validation loss: 2.449847030803157

Epoch: 6| Step: 2
Training loss: 2.258305690450745
Validation loss: 2.444569809588214

Epoch: 6| Step: 3
Training loss: 1.91287699206314
Validation loss: 2.4516163248066323

Epoch: 6| Step: 4
Training loss: 2.8845861091106335
Validation loss: 2.436508507139998

Epoch: 6| Step: 5
Training loss: 2.5023580874086804
Validation loss: 2.45960275419696

Epoch: 6| Step: 6
Training loss: 2.26907727531831
Validation loss: 2.459085988170764

Epoch: 6| Step: 7
Training loss: 2.3440427470166383
Validation loss: 2.438964308205156

Epoch: 6| Step: 8
Training loss: 2.797536590582324
Validation loss: 2.462335703767774

Epoch: 6| Step: 9
Training loss: 2.6988368778636196
Validation loss: 2.4555857407529142

Epoch: 6| Step: 10
Training loss: 2.4815194855600784
Validation loss: 2.4522283182528186

Epoch: 6| Step: 11
Training loss: 3.0448739547824792
Validation loss: 2.453456068614785

Epoch: 6| Step: 12
Training loss: 2.527706727460452
Validation loss: 2.4627670370666706

Epoch: 6| Step: 13
Training loss: 2.0918400721715615
Validation loss: 2.4539202967294322

Epoch: 141| Step: 0
Training loss: 2.8561656847639707
Validation loss: 2.458953469134409

Epoch: 6| Step: 1
Training loss: 1.9867631253991813
Validation loss: 2.458507051129934

Epoch: 6| Step: 2
Training loss: 3.048692835873651
Validation loss: 2.456369021599332

Epoch: 6| Step: 3
Training loss: 2.259205213738766
Validation loss: 2.4393153502324134

Epoch: 6| Step: 4
Training loss: 2.354007906891565
Validation loss: 2.473627503084227

Epoch: 6| Step: 5
Training loss: 2.0136647709925612
Validation loss: 2.437560420185407

Epoch: 6| Step: 6
Training loss: 1.8481804585964656
Validation loss: 2.4680778135566035

Epoch: 6| Step: 7
Training loss: 2.636821920001249
Validation loss: 2.4327735501699035

Epoch: 6| Step: 8
Training loss: 2.4888131667531628
Validation loss: 2.4347657622601044

Epoch: 6| Step: 9
Training loss: 2.216802897844241
Validation loss: 2.453527903554222

Epoch: 6| Step: 10
Training loss: 3.2776716793439276
Validation loss: 2.4631819681082145

Epoch: 6| Step: 11
Training loss: 1.9627330204335285
Validation loss: 2.4719420026472867

Epoch: 6| Step: 12
Training loss: 2.1842325057675773
Validation loss: 2.447171540354523

Epoch: 6| Step: 13
Training loss: 3.1591436133469744
Validation loss: 2.452243466531548

Epoch: 142| Step: 0
Training loss: 2.128669263615723
Validation loss: 2.46442760962046

Epoch: 6| Step: 1
Training loss: 2.905161171675445
Validation loss: 2.454714287763359

Epoch: 6| Step: 2
Training loss: 1.9029283819749128
Validation loss: 2.4653075898735755

Epoch: 6| Step: 3
Training loss: 2.028549276917935
Validation loss: 2.4430088663220744

Epoch: 6| Step: 4
Training loss: 2.777080539512135
Validation loss: 2.468135440004859

Epoch: 6| Step: 5
Training loss: 2.334562375312001
Validation loss: 2.454548788536257

Epoch: 6| Step: 6
Training loss: 2.7484403869370855
Validation loss: 2.462635203309687

Epoch: 6| Step: 7
Training loss: 3.3372307086558175
Validation loss: 2.4827229517400373

Epoch: 6| Step: 8
Training loss: 2.0571165630007386
Validation loss: 2.46209647836502

Epoch: 6| Step: 9
Training loss: 2.1544723923428855
Validation loss: 2.448610818363788

Epoch: 6| Step: 10
Training loss: 2.606946717590233
Validation loss: 2.4417087629699425

Epoch: 6| Step: 11
Training loss: 2.3501580692454396
Validation loss: 2.455688739999277

Epoch: 6| Step: 12
Training loss: 2.3738261885868153
Validation loss: 2.459949876128062

Epoch: 6| Step: 13
Training loss: 2.551074351460515
Validation loss: 2.453367709439097

Epoch: 143| Step: 0
Training loss: 2.1906216826801512
Validation loss: 2.4435193985118033

Epoch: 6| Step: 1
Training loss: 2.6267415581917257
Validation loss: 2.458209290320109

Epoch: 6| Step: 2
Training loss: 2.7769131226018784
Validation loss: 2.4418086708412257

Epoch: 6| Step: 3
Training loss: 2.4365320484567277
Validation loss: 2.4443220061352147

Epoch: 6| Step: 4
Training loss: 1.9699931382771385
Validation loss: 2.4429759066995453

Epoch: 6| Step: 5
Training loss: 2.386204041267741
Validation loss: 2.448667191175831

Epoch: 6| Step: 6
Training loss: 2.6999610509535614
Validation loss: 2.4471238597262217

Epoch: 6| Step: 7
Training loss: 2.8691191857499705
Validation loss: 2.451607516909718

Epoch: 6| Step: 8
Training loss: 2.477401639369657
Validation loss: 2.4416972304335207

Epoch: 6| Step: 9
Training loss: 1.6868413416814325
Validation loss: 2.438010640554638

Epoch: 6| Step: 10
Training loss: 2.357165584206937
Validation loss: 2.4572523843690517

Epoch: 6| Step: 11
Training loss: 2.4369068891342187
Validation loss: 2.460498950047033

Epoch: 6| Step: 12
Training loss: 2.717214391837438
Validation loss: 2.447736549078203

Epoch: 6| Step: 13
Training loss: 2.5252092595777054
Validation loss: 2.4457128095488887

Epoch: 144| Step: 0
Training loss: 1.663330705229085
Validation loss: 2.4749779091291755

Epoch: 6| Step: 1
Training loss: 2.670324399864686
Validation loss: 2.4673299935875286

Epoch: 6| Step: 2
Training loss: 2.666666318972883
Validation loss: 2.435235964318018

Epoch: 6| Step: 3
Training loss: 2.0771309906119653
Validation loss: 2.4650647430447363

Epoch: 6| Step: 4
Training loss: 2.894400116167546
Validation loss: 2.4595245612726133

Epoch: 6| Step: 5
Training loss: 2.669154159353034
Validation loss: 2.440068874081358

Epoch: 6| Step: 6
Training loss: 2.7072637548961165
Validation loss: 2.463352781917227

Epoch: 6| Step: 7
Training loss: 2.4636542930961545
Validation loss: 2.455888246208443

Epoch: 6| Step: 8
Training loss: 2.496199580233991
Validation loss: 2.4597805060765063

Epoch: 6| Step: 9
Training loss: 1.4178296065564964
Validation loss: 2.4515084329476093

Epoch: 6| Step: 10
Training loss: 2.8130358715299315
Validation loss: 2.462225328810245

Epoch: 6| Step: 11
Training loss: 2.6243977537029544
Validation loss: 2.4595009127352983

Epoch: 6| Step: 12
Training loss: 2.443165577034066
Validation loss: 2.46225679592786

Epoch: 6| Step: 13
Training loss: 2.3253401927839534
Validation loss: 2.4498445224629743

Epoch: 145| Step: 0
Training loss: 3.229036357260288
Validation loss: 2.447611844038188

Epoch: 6| Step: 1
Training loss: 2.569607252398621
Validation loss: 2.4318253017195537

Epoch: 6| Step: 2
Training loss: 2.44249936465955
Validation loss: 2.454047023584582

Epoch: 6| Step: 3
Training loss: 2.445369634478795
Validation loss: 2.447340647506331

Epoch: 6| Step: 4
Training loss: 2.538848022792407
Validation loss: 2.463198411401375

Epoch: 6| Step: 5
Training loss: 2.296490695488517
Validation loss: 2.434183909334377

Epoch: 6| Step: 6
Training loss: 1.618009938628012
Validation loss: 2.4639913320324993

Epoch: 6| Step: 7
Training loss: 2.4712602432030972
Validation loss: 2.432043819487837

Epoch: 6| Step: 8
Training loss: 2.749144160870531
Validation loss: 2.4453644649841073

Epoch: 6| Step: 9
Training loss: 2.179584569107237
Validation loss: 2.454361474842447

Epoch: 6| Step: 10
Training loss: 2.10454373396124
Validation loss: 2.4493935843455676

Epoch: 6| Step: 11
Training loss: 2.369361408006488
Validation loss: 2.43918801906939

Epoch: 6| Step: 12
Training loss: 2.5150765715635055
Validation loss: 2.4323098347851313

Epoch: 6| Step: 13
Training loss: 2.932691656355527
Validation loss: 2.425279290037521

Epoch: 146| Step: 0
Training loss: 2.2160720783038155
Validation loss: 2.439196629027645

Epoch: 6| Step: 1
Training loss: 2.51015128055939
Validation loss: 2.441245951978834

Epoch: 6| Step: 2
Training loss: 2.4961331025604867
Validation loss: 2.4383977268099786

Epoch: 6| Step: 3
Training loss: 2.591742784500565
Validation loss: 2.4549396889079413

Epoch: 6| Step: 4
Training loss: 2.5931136488189095
Validation loss: 2.4366919232696835

Epoch: 6| Step: 5
Training loss: 2.280108231435101
Validation loss: 2.433468343904568

Epoch: 6| Step: 6
Training loss: 2.6837652115552872
Validation loss: 2.437983723348386

Epoch: 6| Step: 7
Training loss: 2.5205704312857966
Validation loss: 2.4538572895849162

Epoch: 6| Step: 8
Training loss: 2.3385605390051984
Validation loss: 2.450371603610769

Epoch: 6| Step: 9
Training loss: 2.1865039192476874
Validation loss: 2.4522591708801733

Epoch: 6| Step: 10
Training loss: 2.5007524311725424
Validation loss: 2.460349638001228

Epoch: 6| Step: 11
Training loss: 2.810879728053311
Validation loss: 2.4555473064993736

Epoch: 6| Step: 12
Training loss: 2.080887643240034
Validation loss: 2.4829127783190827

Epoch: 6| Step: 13
Training loss: 2.4124383987705365
Validation loss: 2.45071695601376

Epoch: 147| Step: 0
Training loss: 2.2840720710339877
Validation loss: 2.4614816048850288

Epoch: 6| Step: 1
Training loss: 2.542651834971087
Validation loss: 2.441377125162299

Epoch: 6| Step: 2
Training loss: 2.698893415660926
Validation loss: 2.446871627427904

Epoch: 6| Step: 3
Training loss: 2.9219965781962722
Validation loss: 2.4615068060056813

Epoch: 6| Step: 4
Training loss: 2.412576557585213
Validation loss: 2.4190596895425327

Epoch: 6| Step: 5
Training loss: 2.1315068870395586
Validation loss: 2.45868531389659

Epoch: 6| Step: 6
Training loss: 2.589118683412024
Validation loss: 2.442380649175863

Epoch: 6| Step: 7
Training loss: 2.731579381429949
Validation loss: 2.457381098637629

Epoch: 6| Step: 8
Training loss: 2.394413159493769
Validation loss: 2.4631271098488248

Epoch: 6| Step: 9
Training loss: 2.035797193937488
Validation loss: 2.457539458557217

Epoch: 6| Step: 10
Training loss: 2.4078007444655443
Validation loss: 2.447757880393998

Epoch: 6| Step: 11
Training loss: 1.8910864274816857
Validation loss: 2.4584332813060046

Epoch: 6| Step: 12
Training loss: 2.4969465682332523
Validation loss: 2.4563638428993357

Epoch: 6| Step: 13
Training loss: 2.7587845685804107
Validation loss: 2.4665916970119977

Epoch: 148| Step: 0
Training loss: 2.4616825973969814
Validation loss: 2.4620466356422965

Epoch: 6| Step: 1
Training loss: 3.0004790241542514
Validation loss: 2.450965095076578

Epoch: 6| Step: 2
Training loss: 2.1261269442176935
Validation loss: 2.4445218506387607

Epoch: 6| Step: 3
Training loss: 2.2785523023028973
Validation loss: 2.437443416770642

Epoch: 6| Step: 4
Training loss: 1.4022415676451694
Validation loss: 2.451524711929453

Epoch: 6| Step: 5
Training loss: 2.869587655036264
Validation loss: 2.4408632943794992

Epoch: 6| Step: 6
Training loss: 2.4420136939624735
Validation loss: 2.4409287062359484

Epoch: 6| Step: 7
Training loss: 2.4239120284443003
Validation loss: 2.4455864813202632

Epoch: 6| Step: 8
Training loss: 2.5632099935805894
Validation loss: 2.454580399497999

Epoch: 6| Step: 9
Training loss: 2.484117122677775
Validation loss: 2.4368085508904898

Epoch: 6| Step: 10
Training loss: 2.4791190733201396
Validation loss: 2.4381630224273656

Epoch: 6| Step: 11
Training loss: 2.1601600026103256
Validation loss: 2.4346982721253245

Epoch: 6| Step: 12
Training loss: 2.8846803315505127
Validation loss: 2.4418257746068983

Epoch: 6| Step: 13
Training loss: 2.39037496219095
Validation loss: 2.464871935032168

Epoch: 149| Step: 0
Training loss: 3.0214689090384717
Validation loss: 2.4449773508520942

Epoch: 6| Step: 1
Training loss: 2.963657227169878
Validation loss: 2.455527735221417

Epoch: 6| Step: 2
Training loss: 3.055098640110604
Validation loss: 2.453445530675401

Epoch: 6| Step: 3
Training loss: 2.3112679369711655
Validation loss: 2.4527745098071696

Epoch: 6| Step: 4
Training loss: 1.7580836108204576
Validation loss: 2.459435076503018

Epoch: 6| Step: 5
Training loss: 2.573206515852134
Validation loss: 2.447886723160906

Epoch: 6| Step: 6
Training loss: 1.8943454926652252
Validation loss: 2.449088931059346

Epoch: 6| Step: 7
Training loss: 2.170001312642206
Validation loss: 2.452668190774324

Epoch: 6| Step: 8
Training loss: 2.696825039821856
Validation loss: 2.4507045107944103

Epoch: 6| Step: 9
Training loss: 1.4585301765926868
Validation loss: 2.4550279330288576

Epoch: 6| Step: 10
Training loss: 2.5536373674871036
Validation loss: 2.438017803564538

Epoch: 6| Step: 11
Training loss: 2.468117162016312
Validation loss: 2.443126825669691

Epoch: 6| Step: 12
Training loss: 2.3732989393199495
Validation loss: 2.443836890677153

Epoch: 6| Step: 13
Training loss: 2.3450270161973736
Validation loss: 2.4658537605524478

Epoch: 150| Step: 0
Training loss: 2.755501792196938
Validation loss: 2.4472627442273427

Epoch: 6| Step: 1
Training loss: 2.6086022609081736
Validation loss: 2.433504162912506

Epoch: 6| Step: 2
Training loss: 2.140841842026641
Validation loss: 2.42402286561477

Epoch: 6| Step: 3
Training loss: 2.134300299882977
Validation loss: 2.4310425497743524

Epoch: 6| Step: 4
Training loss: 2.3650150213107297
Validation loss: 2.433029659059797

Epoch: 6| Step: 5
Training loss: 2.9945608741176706
Validation loss: 2.454026685047512

Epoch: 6| Step: 6
Training loss: 2.240160301467181
Validation loss: 2.438379058215146

Epoch: 6| Step: 7
Training loss: 2.4477809354338746
Validation loss: 2.454099289372966

Epoch: 6| Step: 8
Training loss: 2.428417597635015
Validation loss: 2.4507489354499548

Epoch: 6| Step: 9
Training loss: 2.61069532785993
Validation loss: 2.4509242788209473

Epoch: 6| Step: 10
Training loss: 1.7641329241904213
Validation loss: 2.4546577687060633

Epoch: 6| Step: 11
Training loss: 2.2942190579400714
Validation loss: 2.442482437745919

Epoch: 6| Step: 12
Training loss: 2.6414312452314395
Validation loss: 2.4543608303707605

Epoch: 6| Step: 13
Training loss: 2.4131830582628346
Validation loss: 2.440130687863715

Epoch: 151| Step: 0
Training loss: 1.902605042734544
Validation loss: 2.442470916209799

Epoch: 6| Step: 1
Training loss: 1.933765812163752
Validation loss: 2.446086807213088

Epoch: 6| Step: 2
Training loss: 2.8113537465886878
Validation loss: 2.4502675438381822

Epoch: 6| Step: 3
Training loss: 2.4765540282288065
Validation loss: 2.466627215344605

Epoch: 6| Step: 4
Training loss: 2.5551632312806887
Validation loss: 2.4268500370726054

Epoch: 6| Step: 5
Training loss: 2.6595662676907996
Validation loss: 2.412887290902576

Epoch: 6| Step: 6
Training loss: 1.9629675703007965
Validation loss: 2.431306571037626

Epoch: 6| Step: 7
Training loss: 3.0520098333437833
Validation loss: 2.44590975814662

Epoch: 6| Step: 8
Training loss: 2.438673177239411
Validation loss: 2.4526053518943374

Epoch: 6| Step: 9
Training loss: 2.3063958512167346
Validation loss: 2.4482479949050737

Epoch: 6| Step: 10
Training loss: 2.2232374561041306
Validation loss: 2.421562635672636

Epoch: 6| Step: 11
Training loss: 2.836301333625705
Validation loss: 2.4417539045985888

Epoch: 6| Step: 12
Training loss: 2.0710979771004343
Validation loss: 2.4477866685255094

Epoch: 6| Step: 13
Training loss: 2.0685978536754583
Validation loss: 2.4284204595915724

Epoch: 152| Step: 0
Training loss: 2.0232939798130074
Validation loss: 2.456692884697689

Epoch: 6| Step: 1
Training loss: 2.5231267306643397
Validation loss: 2.4542783418204617

Epoch: 6| Step: 2
Training loss: 2.7508349451589806
Validation loss: 2.449185717459828

Epoch: 6| Step: 3
Training loss: 2.779398441134354
Validation loss: 2.4559759499860516

Epoch: 6| Step: 4
Training loss: 2.3146168067450494
Validation loss: 2.4365524162364296

Epoch: 6| Step: 5
Training loss: 2.311670721701889
Validation loss: 2.445989737307261

Epoch: 6| Step: 6
Training loss: 2.5295907693032174
Validation loss: 2.441820232773164

Epoch: 6| Step: 7
Training loss: 1.6894708356866124
Validation loss: 2.442769226921665

Epoch: 6| Step: 8
Training loss: 2.6684750346058967
Validation loss: 2.4413474644300326

Epoch: 6| Step: 9
Training loss: 2.4258631202531493
Validation loss: 2.448847463647361

Epoch: 6| Step: 10
Training loss: 2.2302073844991983
Validation loss: 2.4278728502473017

Epoch: 6| Step: 11
Training loss: 2.8641371130914615
Validation loss: 2.45884611973645

Epoch: 6| Step: 12
Training loss: 1.9484458109442087
Validation loss: 2.4654518122243836

Epoch: 6| Step: 13
Training loss: 2.9510878545286454
Validation loss: 2.463108428328053

Epoch: 153| Step: 0
Training loss: 2.543446860656499
Validation loss: 2.463077826090106

Epoch: 6| Step: 1
Training loss: 2.200205281823841
Validation loss: 2.4425129185961327

Epoch: 6| Step: 2
Training loss: 1.962255331447482
Validation loss: 2.440487417402695

Epoch: 6| Step: 3
Training loss: 2.138349897281342
Validation loss: 2.454095948624542

Epoch: 6| Step: 4
Training loss: 2.802106514495675
Validation loss: 2.4485641436583028

Epoch: 6| Step: 5
Training loss: 2.6525105801729967
Validation loss: 2.448536951934201

Epoch: 6| Step: 6
Training loss: 2.5706506755946164
Validation loss: 2.4413199014467866

Epoch: 6| Step: 7
Training loss: 1.8867579232960983
Validation loss: 2.4563317852300965

Epoch: 6| Step: 8
Training loss: 2.252103352229812
Validation loss: 2.4481070886684857

Epoch: 6| Step: 9
Training loss: 3.2079913134564304
Validation loss: 2.4803188690489635

Epoch: 6| Step: 10
Training loss: 1.9144317270829334
Validation loss: 2.461437264575684

Epoch: 6| Step: 11
Training loss: 2.5713351456003855
Validation loss: 2.454464844030522

Epoch: 6| Step: 12
Training loss: 2.313622794918028
Validation loss: 2.4482344910439937

Epoch: 6| Step: 13
Training loss: 2.720341446846859
Validation loss: 2.434846241719993

Epoch: 154| Step: 0
Training loss: 2.76051315043032
Validation loss: 2.444667350098114

Epoch: 6| Step: 1
Training loss: 2.2401588114571958
Validation loss: 2.4461302771249116

Epoch: 6| Step: 2
Training loss: 2.131501965437074
Validation loss: 2.457830359547215

Epoch: 6| Step: 3
Training loss: 2.3221570014413886
Validation loss: 2.4380194102966932

Epoch: 6| Step: 4
Training loss: 2.120875788215639
Validation loss: 2.4853860272614914

Epoch: 6| Step: 5
Training loss: 3.222064339580828
Validation loss: 2.4709687917273593

Epoch: 6| Step: 6
Training loss: 2.1848200048686657
Validation loss: 2.4511170742666577

Epoch: 6| Step: 7
Training loss: 2.2926891357875263
Validation loss: 2.427491404915035

Epoch: 6| Step: 8
Training loss: 2.5125111328182013
Validation loss: 2.437651701803416

Epoch: 6| Step: 9
Training loss: 1.9141678761650165
Validation loss: 2.442669784969741

Epoch: 6| Step: 10
Training loss: 2.383112453904881
Validation loss: 2.445148699336479

Epoch: 6| Step: 11
Training loss: 2.5429595618953633
Validation loss: 2.4559935218894213

Epoch: 6| Step: 12
Training loss: 2.619314758292526
Validation loss: 2.4321884290059015

Epoch: 6| Step: 13
Training loss: 1.8519018964716445
Validation loss: 2.439916761487444

Epoch: 155| Step: 0
Training loss: 2.6074617418534625
Validation loss: 2.4564449714806953

Epoch: 6| Step: 1
Training loss: 2.43189200821583
Validation loss: 2.4431856292859306

Epoch: 6| Step: 2
Training loss: 2.4913248225267397
Validation loss: 2.4091819551248066

Epoch: 6| Step: 3
Training loss: 2.1487273419546455
Validation loss: 2.461983253084104

Epoch: 6| Step: 4
Training loss: 3.026685601341857
Validation loss: 2.4170223900018444

Epoch: 6| Step: 5
Training loss: 2.7999104485496424
Validation loss: 2.434863149070318

Epoch: 6| Step: 6
Training loss: 2.536864658737815
Validation loss: 2.4466296430753185

Epoch: 6| Step: 7
Training loss: 2.3737584934815876
Validation loss: 2.4147924693547975

Epoch: 6| Step: 8
Training loss: 2.374075056964003
Validation loss: 2.4451557921581752

Epoch: 6| Step: 9
Training loss: 2.4337806691106976
Validation loss: 2.444905652129279

Epoch: 6| Step: 10
Training loss: 1.8933400607437285
Validation loss: 2.4421020030965215

Epoch: 6| Step: 11
Training loss: 2.0568272577504163
Validation loss: 2.434277659755882

Epoch: 6| Step: 12
Training loss: 2.070264131952685
Validation loss: 2.418378619978805

Epoch: 6| Step: 13
Training loss: 2.1489607849945367
Validation loss: 2.4103063117600505

Epoch: 156| Step: 0
Training loss: 2.132923835950506
Validation loss: 2.4114120019330585

Epoch: 6| Step: 1
Training loss: 2.23056516422257
Validation loss: 2.4298753716217476

Epoch: 6| Step: 2
Training loss: 2.607622208917952
Validation loss: 2.437017343051572

Epoch: 6| Step: 3
Training loss: 2.4957109853298602
Validation loss: 2.4290624776828635

Epoch: 6| Step: 4
Training loss: 1.889498035842751
Validation loss: 2.4193978101407545

Epoch: 6| Step: 5
Training loss: 1.9616244507262994
Validation loss: 2.4346449870124722

Epoch: 6| Step: 6
Training loss: 2.332593584871535
Validation loss: 2.425029438196595

Epoch: 6| Step: 7
Training loss: 2.557087462145654
Validation loss: 2.4334187423386875

Epoch: 6| Step: 8
Training loss: 1.9555706733723732
Validation loss: 2.4322447002289405

Epoch: 6| Step: 9
Training loss: 3.0882649203890944
Validation loss: 2.441311889137488

Epoch: 6| Step: 10
Training loss: 2.797893999187331
Validation loss: 2.4121924638563517

Epoch: 6| Step: 11
Training loss: 2.814321817992223
Validation loss: 2.414137920897031

Epoch: 6| Step: 12
Training loss: 2.2394285873061555
Validation loss: 2.445798054406963

Epoch: 6| Step: 13
Training loss: 2.3263505151218644
Validation loss: 2.4572282820355675

Epoch: 157| Step: 0
Training loss: 1.9458276150910072
Validation loss: 2.422490590351113

Epoch: 6| Step: 1
Training loss: 2.6729427234294367
Validation loss: 2.452346314492589

Epoch: 6| Step: 2
Training loss: 2.046092575439955
Validation loss: 2.4502044393624582

Epoch: 6| Step: 3
Training loss: 1.999920068574098
Validation loss: 2.422241248873645

Epoch: 6| Step: 4
Training loss: 2.077526493936434
Validation loss: 2.4498518674869056

Epoch: 6| Step: 5
Training loss: 2.1152517330341567
Validation loss: 2.426253961402006

Epoch: 6| Step: 6
Training loss: 2.468118514407213
Validation loss: 2.4304238925867057

Epoch: 6| Step: 7
Training loss: 1.9019014130161331
Validation loss: 2.4456966564533578

Epoch: 6| Step: 8
Training loss: 2.7350428174448815
Validation loss: 2.440405572392116

Epoch: 6| Step: 9
Training loss: 2.5062020618296597
Validation loss: 2.4644368247290807

Epoch: 6| Step: 10
Training loss: 2.655560841637125
Validation loss: 2.423511277607523

Epoch: 6| Step: 11
Training loss: 2.6010000176405916
Validation loss: 2.435056593947039

Epoch: 6| Step: 12
Training loss: 3.3140993395911087
Validation loss: 2.457211326170431

Epoch: 6| Step: 13
Training loss: 2.03456303303242
Validation loss: 2.490482022065697

Epoch: 158| Step: 0
Training loss: 3.055880340500351
Validation loss: 2.4101014569725545

Epoch: 6| Step: 1
Training loss: 2.1336375446776583
Validation loss: 2.4587648540319043

Epoch: 6| Step: 2
Training loss: 2.028750128425787
Validation loss: 2.4324406351193955

Epoch: 6| Step: 3
Training loss: 2.4768653467853188
Validation loss: 2.440933020752139

Epoch: 6| Step: 4
Training loss: 2.566624183633476
Validation loss: 2.4489844100960347

Epoch: 6| Step: 5
Training loss: 2.219647078427333
Validation loss: 2.436409928693828

Epoch: 6| Step: 6
Training loss: 2.3561841596313946
Validation loss: 2.4340929842583465

Epoch: 6| Step: 7
Training loss: 1.9941720091379829
Validation loss: 2.450010713022704

Epoch: 6| Step: 8
Training loss: 1.8532122895394627
Validation loss: 2.4570298497708767

Epoch: 6| Step: 9
Training loss: 2.4507334526053612
Validation loss: 2.4374812451217704

Epoch: 6| Step: 10
Training loss: 2.2846808566671384
Validation loss: 2.436147943253821

Epoch: 6| Step: 11
Training loss: 2.3221935520906913
Validation loss: 2.4450970820567886

Epoch: 6| Step: 12
Training loss: 2.9272660891857734
Validation loss: 2.4642823182185394

Epoch: 6| Step: 13
Training loss: 2.6440212823008378
Validation loss: 2.434265551222824

Epoch: 159| Step: 0
Training loss: 2.2249595895590772
Validation loss: 2.449428871659938

Epoch: 6| Step: 1
Training loss: 2.432851123931968
Validation loss: 2.435290672915305

Epoch: 6| Step: 2
Training loss: 2.3486862081378335
Validation loss: 2.4231938143134473

Epoch: 6| Step: 3
Training loss: 1.8857523020508131
Validation loss: 2.4382425097068734

Epoch: 6| Step: 4
Training loss: 2.7116599755496718
Validation loss: 2.4275688137571416

Epoch: 6| Step: 5
Training loss: 2.925305479351169
Validation loss: 2.430813913946074

Epoch: 6| Step: 6
Training loss: 2.3764814474616447
Validation loss: 2.4569071857680904

Epoch: 6| Step: 7
Training loss: 2.320744637986621
Validation loss: 2.4483860345228794

Epoch: 6| Step: 8
Training loss: 1.9859110976774408
Validation loss: 2.4463007132927586

Epoch: 6| Step: 9
Training loss: 2.8980215756157466
Validation loss: 2.435063534030086

Epoch: 6| Step: 10
Training loss: 2.6806980374099276
Validation loss: 2.4265919807281393

Epoch: 6| Step: 11
Training loss: 2.4067860786457604
Validation loss: 2.431061365924995

Epoch: 6| Step: 12
Training loss: 2.177298710100236
Validation loss: 2.441544869636594

Epoch: 6| Step: 13
Training loss: 1.2445178934591068
Validation loss: 2.42739351429375

Epoch: 160| Step: 0
Training loss: 2.3037055558436506
Validation loss: 2.450369663908394

Epoch: 6| Step: 1
Training loss: 2.4644126938354116
Validation loss: 2.415488681248196

Epoch: 6| Step: 2
Training loss: 2.672404275862367
Validation loss: 2.424822057105629

Epoch: 6| Step: 3
Training loss: 2.368044254379179
Validation loss: 2.429202491896975

Epoch: 6| Step: 4
Training loss: 2.593867012050231
Validation loss: 2.4378366797874245

Epoch: 6| Step: 5
Training loss: 1.8358799052842718
Validation loss: 2.43750873897512

Epoch: 6| Step: 6
Training loss: 2.6807317450756605
Validation loss: 2.4382691191449886

Epoch: 6| Step: 7
Training loss: 1.920291217037299
Validation loss: 2.4489293876840423

Epoch: 6| Step: 8
Training loss: 2.9580213534478776
Validation loss: 2.418458539144339

Epoch: 6| Step: 9
Training loss: 2.0750521549886045
Validation loss: 2.432487354670423

Epoch: 6| Step: 10
Training loss: 1.8494937461794734
Validation loss: 2.4244668218602103

Epoch: 6| Step: 11
Training loss: 2.2807493313628764
Validation loss: 2.45197387277306

Epoch: 6| Step: 12
Training loss: 2.4432192487047106
Validation loss: 2.4212419029737133

Epoch: 6| Step: 13
Training loss: 2.5000183104798204
Validation loss: 2.43888405818783

Epoch: 161| Step: 0
Training loss: 2.614620213546125
Validation loss: 2.434626437587108

Epoch: 6| Step: 1
Training loss: 2.2104416146220265
Validation loss: 2.4133452632865606

Epoch: 6| Step: 2
Training loss: 2.2525880552094226
Validation loss: 2.4287487229476388

Epoch: 6| Step: 3
Training loss: 1.989353692614475
Validation loss: 2.4488060844608737

Epoch: 6| Step: 4
Training loss: 2.1531443690520877
Validation loss: 2.457295682842156

Epoch: 6| Step: 5
Training loss: 3.2018942352497506
Validation loss: 2.4376882191725553

Epoch: 6| Step: 6
Training loss: 2.071721356939282
Validation loss: 2.3803634853278255

Epoch: 6| Step: 7
Training loss: 2.9636533656911794
Validation loss: 2.41468754464858

Epoch: 6| Step: 8
Training loss: 2.7772519811392598
Validation loss: 2.4346738091021374

Epoch: 6| Step: 9
Training loss: 2.3155141209299663
Validation loss: 2.430013405201506

Epoch: 6| Step: 10
Training loss: 1.9194984939382478
Validation loss: 2.441603634703976

Epoch: 6| Step: 11
Training loss: 1.7626003588517773
Validation loss: 2.4178972989959084

Epoch: 6| Step: 12
Training loss: 2.2966320921459764
Validation loss: 2.428407935999474

Epoch: 6| Step: 13
Training loss: 2.547996695242375
Validation loss: 2.446189364866354

Epoch: 162| Step: 0
Training loss: 2.7222298461997605
Validation loss: 2.409289199316239

Epoch: 6| Step: 1
Training loss: 2.141839232957321
Validation loss: 2.4138824728157404

Epoch: 6| Step: 2
Training loss: 2.952688194950344
Validation loss: 2.438744547255209

Epoch: 6| Step: 3
Training loss: 2.5077050682182467
Validation loss: 2.424128810777754

Epoch: 6| Step: 4
Training loss: 2.071162211388521
Validation loss: 2.4393182792764834

Epoch: 6| Step: 5
Training loss: 2.2752143758858843
Validation loss: 2.4233942120992773

Epoch: 6| Step: 6
Training loss: 1.1871827354245172
Validation loss: 2.4590271039817826

Epoch: 6| Step: 7
Training loss: 2.8146679469975617
Validation loss: 2.444591255578762

Epoch: 6| Step: 8
Training loss: 2.198039794172885
Validation loss: 2.472788209900766

Epoch: 6| Step: 9
Training loss: 2.36330273831269
Validation loss: 2.4454322053603565

Epoch: 6| Step: 10
Training loss: 3.04015591522731
Validation loss: 2.4263995927142314

Epoch: 6| Step: 11
Training loss: 2.1492117301690383
Validation loss: 2.4216874520057736

Epoch: 6| Step: 12
Training loss: 1.903428475373111
Validation loss: 2.438732019914469

Epoch: 6| Step: 13
Training loss: 2.4612774326545117
Validation loss: 2.433845359136215

Epoch: 163| Step: 0
Training loss: 2.6095363544212957
Validation loss: 2.419391238902686

Epoch: 6| Step: 1
Training loss: 2.5320802433743523
Validation loss: 2.4522850637045517

Epoch: 6| Step: 2
Training loss: 2.6911388867904247
Validation loss: 2.430596314502086

Epoch: 6| Step: 3
Training loss: 2.8692243861156728
Validation loss: 2.462532385298803

Epoch: 6| Step: 4
Training loss: 2.1000817055929075
Validation loss: 2.411744311917172

Epoch: 6| Step: 5
Training loss: 1.7315412861602493
Validation loss: 2.437244675365759

Epoch: 6| Step: 6
Training loss: 2.0324788997817076
Validation loss: 2.4521965661533507

Epoch: 6| Step: 7
Training loss: 2.547761727646802
Validation loss: 2.440748669212419

Epoch: 6| Step: 8
Training loss: 1.9701825939313786
Validation loss: 2.463199993382143

Epoch: 6| Step: 9
Training loss: 2.120143614349058
Validation loss: 2.4199709634488946

Epoch: 6| Step: 10
Training loss: 2.6424940367949876
Validation loss: 2.4441374298197904

Epoch: 6| Step: 11
Training loss: 2.490927733590139
Validation loss: 2.4389299458464615

Epoch: 6| Step: 12
Training loss: 1.7752360495913773
Validation loss: 2.430319578920465

Epoch: 6| Step: 13
Training loss: 2.6899402983326137
Validation loss: 2.441169101805451

Epoch: 164| Step: 0
Training loss: 2.3114642323823675
Validation loss: 2.4423158923663535

Epoch: 6| Step: 1
Training loss: 2.904675457105044
Validation loss: 2.443521529877604

Epoch: 6| Step: 2
Training loss: 2.3320508793143726
Validation loss: 2.407943836844433

Epoch: 6| Step: 3
Training loss: 2.4385946701223076
Validation loss: 2.432237554999929

Epoch: 6| Step: 4
Training loss: 2.4016078411083575
Validation loss: 2.4478353259506207

Epoch: 6| Step: 5
Training loss: 2.1066729157793738
Validation loss: 2.428858597920219

Epoch: 6| Step: 6
Training loss: 2.5001350366362245
Validation loss: 2.4450049161178997

Epoch: 6| Step: 7
Training loss: 2.3120347663350973
Validation loss: 2.4328172548035147

Epoch: 6| Step: 8
Training loss: 2.4624675535591414
Validation loss: 2.4405015912527217

Epoch: 6| Step: 9
Training loss: 1.8960814121569516
Validation loss: 2.426037262236034

Epoch: 6| Step: 10
Training loss: 2.80118880239534
Validation loss: 2.419539146512834

Epoch: 6| Step: 11
Training loss: 2.3631892414940623
Validation loss: 2.4472190775839104

Epoch: 6| Step: 12
Training loss: 2.254052116130021
Validation loss: 2.4281837640718185

Epoch: 6| Step: 13
Training loss: 2.2915677367155367
Validation loss: 2.426826661704404

Epoch: 165| Step: 0
Training loss: 2.013835497035111
Validation loss: 2.4362798791787075

Epoch: 6| Step: 1
Training loss: 2.93210528488872
Validation loss: 2.400994995452282

Epoch: 6| Step: 2
Training loss: 1.8607892980745062
Validation loss: 2.421174473163582

Epoch: 6| Step: 3
Training loss: 2.638195839161036
Validation loss: 2.4266324054591926

Epoch: 6| Step: 4
Training loss: 2.950340775026122
Validation loss: 2.4365723787679974

Epoch: 6| Step: 5
Training loss: 2.127987500648789
Validation loss: 2.413700977099789

Epoch: 6| Step: 6
Training loss: 2.3837188497827446
Validation loss: 2.4115655917231376

Epoch: 6| Step: 7
Training loss: 2.2603211507232195
Validation loss: 2.4396767962952945

Epoch: 6| Step: 8
Training loss: 2.6542456750373713
Validation loss: 2.4233613342755254

Epoch: 6| Step: 9
Training loss: 2.4816500516616666
Validation loss: 2.404931244944303

Epoch: 6| Step: 10
Training loss: 2.390536836481954
Validation loss: 2.399418915369779

Epoch: 6| Step: 11
Training loss: 1.5186862508322108
Validation loss: 2.416103758580436

Epoch: 6| Step: 12
Training loss: 2.5510894916288835
Validation loss: 2.405467656918671

Epoch: 6| Step: 13
Training loss: 2.151140988129734
Validation loss: 2.4157655812550214

Epoch: 166| Step: 0
Training loss: 2.0625994109269143
Validation loss: 2.4386626826476094

Epoch: 6| Step: 1
Training loss: 2.8482348949132623
Validation loss: 2.4372265433324407

Epoch: 6| Step: 2
Training loss: 2.650204769356331
Validation loss: 2.435617261431791

Epoch: 6| Step: 3
Training loss: 2.605722760996982
Validation loss: 2.4232924500911923

Epoch: 6| Step: 4
Training loss: 2.319779357283682
Validation loss: 2.427607539957343

Epoch: 6| Step: 5
Training loss: 2.3739549445719104
Validation loss: 2.425585418194827

Epoch: 6| Step: 6
Training loss: 2.6131825335778567
Validation loss: 2.428643947291819

Epoch: 6| Step: 7
Training loss: 2.0083569927589493
Validation loss: 2.4334548059616123

Epoch: 6| Step: 8
Training loss: 1.886549094965905
Validation loss: 2.4163032664450506

Epoch: 6| Step: 9
Training loss: 2.3916371515382346
Validation loss: 2.4439228240656483

Epoch: 6| Step: 10
Training loss: 1.7316276854434567
Validation loss: 2.4351197977702075

Epoch: 6| Step: 11
Training loss: 1.997744540164472
Validation loss: 2.448437830617021

Epoch: 6| Step: 12
Training loss: 2.792175692558406
Validation loss: 2.4430347795338427

Epoch: 6| Step: 13
Training loss: 2.3673094664523338
Validation loss: 2.4432068188074614

Epoch: 167| Step: 0
Training loss: 2.650258926121801
Validation loss: 2.444255396060453

Epoch: 6| Step: 1
Training loss: 2.544233766335883
Validation loss: 2.4014365682256655

Epoch: 6| Step: 2
Training loss: 2.0310340179644717
Validation loss: 2.4211471654806465

Epoch: 6| Step: 3
Training loss: 2.338764534053364
Validation loss: 2.439474510882647

Epoch: 6| Step: 4
Training loss: 2.335113380015642
Validation loss: 2.4214707464902165

Epoch: 6| Step: 5
Training loss: 2.5201589349551115
Validation loss: 2.431212748226244

Epoch: 6| Step: 6
Training loss: 2.414573837494191
Validation loss: 2.4059062979181385

Epoch: 6| Step: 7
Training loss: 1.8058672595156264
Validation loss: 2.402996630208176

Epoch: 6| Step: 8
Training loss: 2.518825982322644
Validation loss: 2.427910212649646

Epoch: 6| Step: 9
Training loss: 1.9178676850520588
Validation loss: 2.4228696719649707

Epoch: 6| Step: 10
Training loss: 2.2511360691181177
Validation loss: 2.4370710628142978

Epoch: 6| Step: 11
Training loss: 2.8337048866642043
Validation loss: 2.4056214916895606

Epoch: 6| Step: 12
Training loss: 2.1504120232316932
Validation loss: 2.411314003953256

Epoch: 6| Step: 13
Training loss: 2.5456268434918248
Validation loss: 2.420583545114033

Epoch: 168| Step: 0
Training loss: 2.9497073141475822
Validation loss: 2.44627274343708

Epoch: 6| Step: 1
Training loss: 2.560141804165168
Validation loss: 2.4417532263516626

Epoch: 6| Step: 2
Training loss: 3.2380247302085854
Validation loss: 2.437882737537243

Epoch: 6| Step: 3
Training loss: 2.507880284234088
Validation loss: 2.4184075299224097

Epoch: 6| Step: 4
Training loss: 2.145454472055419
Validation loss: 2.4255201664788415

Epoch: 6| Step: 5
Training loss: 2.2355661485032146
Validation loss: 2.418502915868265

Epoch: 6| Step: 6
Training loss: 1.6788411691867104
Validation loss: 2.4064538723094495

Epoch: 6| Step: 7
Training loss: 2.5735495917546847
Validation loss: 2.42415440444226

Epoch: 6| Step: 8
Training loss: 2.1385544836146746
Validation loss: 2.411332078866362

Epoch: 6| Step: 9
Training loss: 2.1041733644083016
Validation loss: 2.4313521462036536

Epoch: 6| Step: 10
Training loss: 2.3810928893636887
Validation loss: 2.3860741154537504

Epoch: 6| Step: 11
Training loss: 1.7870822925287395
Validation loss: 2.4039039100416617

Epoch: 6| Step: 12
Training loss: 2.0500827726075443
Validation loss: 2.4370770872392713

Epoch: 6| Step: 13
Training loss: 1.8332559034584637
Validation loss: 2.4305329556056576

Epoch: 169| Step: 0
Training loss: 2.489883745229544
Validation loss: 2.4226288552730124

Epoch: 6| Step: 1
Training loss: 1.68926923335362
Validation loss: 2.4207568447796657

Epoch: 6| Step: 2
Training loss: 2.2349392905299994
Validation loss: 2.4335261141134974

Epoch: 6| Step: 3
Training loss: 1.9583062379734664
Validation loss: 2.429975908446025

Epoch: 6| Step: 4
Training loss: 2.7998030695463147
Validation loss: 2.44389015213175

Epoch: 6| Step: 5
Training loss: 3.0071561022810784
Validation loss: 2.462669536792085

Epoch: 6| Step: 6
Training loss: 2.1432067449670744
Validation loss: 2.436541855693324

Epoch: 6| Step: 7
Training loss: 2.705846574063845
Validation loss: 2.413765907884544

Epoch: 6| Step: 8
Training loss: 2.4287943777760606
Validation loss: 2.425658177860243

Epoch: 6| Step: 9
Training loss: 1.9417568941668037
Validation loss: 2.435143198281544

Epoch: 6| Step: 10
Training loss: 2.374987150458661
Validation loss: 2.42836625075316

Epoch: 6| Step: 11
Training loss: 2.1688744105292685
Validation loss: 2.414401894861268

Epoch: 6| Step: 12
Training loss: 2.4512764349897553
Validation loss: 2.4099999687240095

Epoch: 6| Step: 13
Training loss: 2.131422099662841
Validation loss: 2.418478176135918

Epoch: 170| Step: 0
Training loss: 2.2365212969244626
Validation loss: 2.4352452798886346

Epoch: 6| Step: 1
Training loss: 2.5736632608820096
Validation loss: 2.447505326926674

Epoch: 6| Step: 2
Training loss: 2.3657953682227464
Validation loss: 2.414735396498431

Epoch: 6| Step: 3
Training loss: 2.2311583086081743
Validation loss: 2.4354698271001167

Epoch: 6| Step: 4
Training loss: 2.3348016433273475
Validation loss: 2.4085586211342993

Epoch: 6| Step: 5
Training loss: 2.2332104402388606
Validation loss: 2.395972137567806

Epoch: 6| Step: 6
Training loss: 2.1882414514912227
Validation loss: 2.431120690207618

Epoch: 6| Step: 7
Training loss: 1.5967125378883646
Validation loss: 2.4110191992715015

Epoch: 6| Step: 8
Training loss: 2.2316352746686694
Validation loss: 2.398419659266192

Epoch: 6| Step: 9
Training loss: 2.6967939203303
Validation loss: 2.4489967913030544

Epoch: 6| Step: 10
Training loss: 2.203782003930881
Validation loss: 2.4231974251261352

Epoch: 6| Step: 11
Training loss: 2.662686616330331
Validation loss: 2.394536723019386

Epoch: 6| Step: 12
Training loss: 2.6228023594033347
Validation loss: 2.3921090809724195

Epoch: 6| Step: 13
Training loss: 2.4103111575901996
Validation loss: 2.4117907053175047

Epoch: 171| Step: 0
Training loss: 2.640813877190129
Validation loss: 2.4069980182620885

Epoch: 6| Step: 1
Training loss: 2.5548924355157623
Validation loss: 2.4376367383896986

Epoch: 6| Step: 2
Training loss: 2.631159232198212
Validation loss: 2.428802165388902

Epoch: 6| Step: 3
Training loss: 1.0560716376858914
Validation loss: 2.3989108557368386

Epoch: 6| Step: 4
Training loss: 1.917705199242358
Validation loss: 2.4237676184586316

Epoch: 6| Step: 5
Training loss: 2.667702255232169
Validation loss: 2.407572046027648

Epoch: 6| Step: 6
Training loss: 2.3026353913469233
Validation loss: 2.4360400008877714

Epoch: 6| Step: 7
Training loss: 2.3771781971552475
Validation loss: 2.430512201964616

Epoch: 6| Step: 8
Training loss: 2.345770918273838
Validation loss: 2.4286703869184927

Epoch: 6| Step: 9
Training loss: 2.4694718862734044
Validation loss: 2.4564127400584908

Epoch: 6| Step: 10
Training loss: 1.9667849952316245
Validation loss: 2.4278674164744944

Epoch: 6| Step: 11
Training loss: 2.5033512541852883
Validation loss: 2.4270940362563245

Epoch: 6| Step: 12
Training loss: 2.4227686064055574
Validation loss: 2.4350815963667864

Epoch: 6| Step: 13
Training loss: 2.435832113221531
Validation loss: 2.4340830281290424

Epoch: 172| Step: 0
Training loss: 2.1508176623836084
Validation loss: 2.424523476898388

Epoch: 6| Step: 1
Training loss: 2.3550360995560986
Validation loss: 2.4322958313769125

Epoch: 6| Step: 2
Training loss: 2.180609613978215
Validation loss: 2.457646762281683

Epoch: 6| Step: 3
Training loss: 2.762787133393704
Validation loss: 2.4233737718122557

Epoch: 6| Step: 4
Training loss: 2.417422625813375
Validation loss: 2.431137485327469

Epoch: 6| Step: 5
Training loss: 1.9228490826545717
Validation loss: 2.435987178188025

Epoch: 6| Step: 6
Training loss: 2.780348213672169
Validation loss: 2.437493658990976

Epoch: 6| Step: 7
Training loss: 2.4508366693731034
Validation loss: 2.421659837811715

Epoch: 6| Step: 8
Training loss: 2.3341733464948176
Validation loss: 2.4374196838912052

Epoch: 6| Step: 9
Training loss: 2.8251355636613202
Validation loss: 2.4380500484152963

Epoch: 6| Step: 10
Training loss: 2.35780575336075
Validation loss: 2.423259351895114

Epoch: 6| Step: 11
Training loss: 1.969487127939439
Validation loss: 2.458724672430923

Epoch: 6| Step: 12
Training loss: 2.133484563334951
Validation loss: 2.4127684742047837

Epoch: 6| Step: 13
Training loss: 1.6485654952992495
Validation loss: 2.4356955219182224

Epoch: 173| Step: 0
Training loss: 1.998859974672813
Validation loss: 2.425354011726525

Epoch: 6| Step: 1
Training loss: 2.1636971395945523
Validation loss: 2.4304420806444393

Epoch: 6| Step: 2
Training loss: 1.9814414620773333
Validation loss: 2.438239491050283

Epoch: 6| Step: 3
Training loss: 2.3047578445302728
Validation loss: 2.4391271105243204

Epoch: 6| Step: 4
Training loss: 2.3566721409037603
Validation loss: 2.407970748095951

Epoch: 6| Step: 5
Training loss: 2.5952489726853973
Validation loss: 2.424508189262068

Epoch: 6| Step: 6
Training loss: 2.01593027094945
Validation loss: 2.4086613355689614

Epoch: 6| Step: 7
Training loss: 2.2281663973735815
Validation loss: 2.4070264929539937

Epoch: 6| Step: 8
Training loss: 2.561982265366362
Validation loss: 2.429556548279301

Epoch: 6| Step: 9
Training loss: 2.4237675317264986
Validation loss: 2.402002938465999

Epoch: 6| Step: 10
Training loss: 2.2684805928157483
Validation loss: 2.402876172183116

Epoch: 6| Step: 11
Training loss: 2.935266985211924
Validation loss: 2.4284744201957555

Epoch: 6| Step: 12
Training loss: 2.4222699243279457
Validation loss: 2.409952574945669

Epoch: 6| Step: 13
Training loss: 2.077456718205129
Validation loss: 2.413968894803838

Epoch: 174| Step: 0
Training loss: 2.6825473305543115
Validation loss: 2.4374154189006743

Epoch: 6| Step: 1
Training loss: 2.584388199649115
Validation loss: 2.4414220912624502

Epoch: 6| Step: 2
Training loss: 2.739007306671703
Validation loss: 2.423849425574644

Epoch: 6| Step: 3
Training loss: 1.9909661232802738
Validation loss: 2.4369971111794735

Epoch: 6| Step: 4
Training loss: 2.3203813433468747
Validation loss: 2.4196292358236793

Epoch: 6| Step: 5
Training loss: 2.208492045427281
Validation loss: 2.417253830993505

Epoch: 6| Step: 6
Training loss: 2.1219709911179265
Validation loss: 2.4260158931622544

Epoch: 6| Step: 7
Training loss: 2.0006576887211276
Validation loss: 2.416478083561225

Epoch: 6| Step: 8
Training loss: 1.7453368592504717
Validation loss: 2.43277894558597

Epoch: 6| Step: 9
Training loss: 2.199705568031561
Validation loss: 2.4133021859852564

Epoch: 6| Step: 10
Training loss: 2.365030747711765
Validation loss: 2.409485068720571

Epoch: 6| Step: 11
Training loss: 2.320876133339768
Validation loss: 2.4112758336633515

Epoch: 6| Step: 12
Training loss: 2.757043747564167
Validation loss: 2.440902898800218

Epoch: 6| Step: 13
Training loss: 2.2317144386053824
Validation loss: 2.4295801938879964

Epoch: 175| Step: 0
Training loss: 2.6839579816732777
Validation loss: 2.423361451700896

Epoch: 6| Step: 1
Training loss: 2.05103002583339
Validation loss: 2.4258457216420712

Epoch: 6| Step: 2
Training loss: 2.047160470871728
Validation loss: 2.4351878857641065

Epoch: 6| Step: 3
Training loss: 1.9583456837149689
Validation loss: 2.407528362289195

Epoch: 6| Step: 4
Training loss: 3.145665465332828
Validation loss: 2.4335428541809936

Epoch: 6| Step: 5
Training loss: 2.4707118098291034
Validation loss: 2.449535294661018

Epoch: 6| Step: 6
Training loss: 2.3328722997871654
Validation loss: 2.424955887388516

Epoch: 6| Step: 7
Training loss: 2.109577536572785
Validation loss: 2.4520402041702725

Epoch: 6| Step: 8
Training loss: 2.0299150041347125
Validation loss: 2.4465690308654158

Epoch: 6| Step: 9
Training loss: 2.6031432518656916
Validation loss: 2.414187954708797

Epoch: 6| Step: 10
Training loss: 1.9765604494106828
Validation loss: 2.441020363908868

Epoch: 6| Step: 11
Training loss: 2.1275124002850605
Validation loss: 2.441844766985152

Epoch: 6| Step: 12
Training loss: 2.413534260950977
Validation loss: 2.4564032631561292

Epoch: 6| Step: 13
Training loss: 2.3042143772513413
Validation loss: 2.4457021292305097

Epoch: 176| Step: 0
Training loss: 2.4420048094381075
Validation loss: 2.391520918423074

Epoch: 6| Step: 1
Training loss: 1.9316782701794941
Validation loss: 2.401509412094042

Epoch: 6| Step: 2
Training loss: 2.7117414793898957
Validation loss: 2.42992776485266

Epoch: 6| Step: 3
Training loss: 2.157386369773928
Validation loss: 2.4218439931799924

Epoch: 6| Step: 4
Training loss: 2.8396931310534677
Validation loss: 2.431199391219475

Epoch: 6| Step: 5
Training loss: 2.3179933408455566
Validation loss: 2.4097494949290534

Epoch: 6| Step: 6
Training loss: 2.2412687007466405
Validation loss: 2.4413836513991054

Epoch: 6| Step: 7
Training loss: 1.5170474898286024
Validation loss: 2.422881389346255

Epoch: 6| Step: 8
Training loss: 2.5969775238180843
Validation loss: 2.4021721752707483

Epoch: 6| Step: 9
Training loss: 2.459852288161127
Validation loss: 2.439973079849608

Epoch: 6| Step: 10
Training loss: 2.0834082653557338
Validation loss: 2.420522226139788

Epoch: 6| Step: 11
Training loss: 2.3109905368375134
Validation loss: 2.4001606202128936

Epoch: 6| Step: 12
Training loss: 1.7587873002403025
Validation loss: 2.4005930021838737

Epoch: 6| Step: 13
Training loss: 2.892067214385235
Validation loss: 2.4001535578452016

Epoch: 177| Step: 0
Training loss: 2.4093731515286056
Validation loss: 2.4071349509130133

Epoch: 6| Step: 1
Training loss: 1.3949774447706178
Validation loss: 2.441217886928792

Epoch: 6| Step: 2
Training loss: 2.66457185322722
Validation loss: 2.398078938952911

Epoch: 6| Step: 3
Training loss: 2.28132106722565
Validation loss: 2.415913287968714

Epoch: 6| Step: 4
Training loss: 2.2091110827248754
Validation loss: 2.422417000555838

Epoch: 6| Step: 5
Training loss: 2.413656157334222
Validation loss: 2.4163832298489276

Epoch: 6| Step: 6
Training loss: 3.255903897041124
Validation loss: 2.408919876563762

Epoch: 6| Step: 7
Training loss: 2.2315474538986315
Validation loss: 2.417269649181269

Epoch: 6| Step: 8
Training loss: 2.038198470704324
Validation loss: 2.4316408379654275

Epoch: 6| Step: 9
Training loss: 1.9729360249854284
Validation loss: 2.421763643740738

Epoch: 6| Step: 10
Training loss: 2.094324289389295
Validation loss: 2.4156821257970673

Epoch: 6| Step: 11
Training loss: 2.5072737736070767
Validation loss: 2.4191270087412593

Epoch: 6| Step: 12
Training loss: 2.08212205642297
Validation loss: 2.408052505267213

Epoch: 6| Step: 13
Training loss: 2.0645929756542447
Validation loss: 2.388651842716115

Epoch: 178| Step: 0
Training loss: 2.520314460086711
Validation loss: 2.422042105232536

Epoch: 6| Step: 1
Training loss: 1.7838726478974405
Validation loss: 2.450191137757359

Epoch: 6| Step: 2
Training loss: 2.0775244282412095
Validation loss: 2.397717216121645

Epoch: 6| Step: 3
Training loss: 2.0633849355174525
Validation loss: 2.421926656510198

Epoch: 6| Step: 4
Training loss: 1.8986342214377616
Validation loss: 2.4200950250145095

Epoch: 6| Step: 5
Training loss: 3.2203954546228126
Validation loss: 2.420498811374634

Epoch: 6| Step: 6
Training loss: 1.7981101393524779
Validation loss: 2.4469862853149413

Epoch: 6| Step: 7
Training loss: 1.9317209749703452
Validation loss: 2.396683509361632

Epoch: 6| Step: 8
Training loss: 2.0019226369629686
Validation loss: 2.4097267329646312

Epoch: 6| Step: 9
Training loss: 2.7335773285456764
Validation loss: 2.4126072892850496

Epoch: 6| Step: 10
Training loss: 2.369275673384526
Validation loss: 2.431288589790036

Epoch: 6| Step: 11
Training loss: 2.369381231180549
Validation loss: 2.4170291856453305

Epoch: 6| Step: 12
Training loss: 2.5286048914655597
Validation loss: 2.4027333317611643

Epoch: 6| Step: 13
Training loss: 2.7447437858869077
Validation loss: 2.4197841504023216

Epoch: 179| Step: 0
Training loss: 2.138275862308247
Validation loss: 2.4162265842231023

Epoch: 6| Step: 1
Training loss: 2.256102234289249
Validation loss: 2.4390475942639425

Epoch: 6| Step: 2
Training loss: 2.4571946518847416
Validation loss: 2.4315553825082965

Epoch: 6| Step: 3
Training loss: 2.284242731066721
Validation loss: 2.4087371139666582

Epoch: 6| Step: 4
Training loss: 2.0062297118875376
Validation loss: 2.4099170329894584

Epoch: 6| Step: 5
Training loss: 1.4016195568433878
Validation loss: 2.4149827836771456

Epoch: 6| Step: 6
Training loss: 1.3670470683318139
Validation loss: 2.4079658166425304

Epoch: 6| Step: 7
Training loss: 2.435585639602294
Validation loss: 2.422787096361803

Epoch: 6| Step: 8
Training loss: 1.8539626905849682
Validation loss: 2.407542493784199

Epoch: 6| Step: 9
Training loss: 2.4372378477317342
Validation loss: 2.4332428265387436

Epoch: 6| Step: 10
Training loss: 3.2730654411731748
Validation loss: 2.421611743794228

Epoch: 6| Step: 11
Training loss: 2.483309631319885
Validation loss: 2.4252344088794917

Epoch: 6| Step: 12
Training loss: 3.008949599893981
Validation loss: 2.409757277598092

Epoch: 6| Step: 13
Training loss: 1.641019210684386
Validation loss: 2.4161008024544195

Epoch: 180| Step: 0
Training loss: 2.606567151283072
Validation loss: 2.4134442181824127

Epoch: 6| Step: 1
Training loss: 3.0433564043232515
Validation loss: 2.3905021780163747

Epoch: 6| Step: 2
Training loss: 2.3682923209469
Validation loss: 2.397815150756203

Epoch: 6| Step: 3
Training loss: 2.1188301948966815
Validation loss: 2.4255838777389087

Epoch: 6| Step: 4
Training loss: 1.792250013383633
Validation loss: 2.4183305847369905

Epoch: 6| Step: 5
Training loss: 2.2411237047293713
Validation loss: 2.4162280982839377

Epoch: 6| Step: 6
Training loss: 2.079310831742975
Validation loss: 2.4280005182343833

Epoch: 6| Step: 7
Training loss: 1.9898157699648675
Validation loss: 2.4249710770558743

Epoch: 6| Step: 8
Training loss: 2.7214362367851743
Validation loss: 2.42563124089432

Epoch: 6| Step: 9
Training loss: 2.2583803301023204
Validation loss: 2.450143729341263

Epoch: 6| Step: 10
Training loss: 2.6383425989267435
Validation loss: 2.424390227599939

Epoch: 6| Step: 11
Training loss: 1.9969383886362226
Validation loss: 2.411041597616218

Epoch: 6| Step: 12
Training loss: 1.7765266300763987
Validation loss: 2.4234163532569633

Epoch: 6| Step: 13
Training loss: 1.9980422212876523
Validation loss: 2.3979544129527963

Epoch: 181| Step: 0
Training loss: 1.9394715030717562
Validation loss: 2.389771654152575

Epoch: 6| Step: 1
Training loss: 1.4446282493988485
Validation loss: 2.408276349680259

Epoch: 6| Step: 2
Training loss: 2.655265176752505
Validation loss: 2.389907752910256

Epoch: 6| Step: 3
Training loss: 2.5281069987143034
Validation loss: 2.415426418869618

Epoch: 6| Step: 4
Training loss: 2.4205139273353327
Validation loss: 2.4060519312318345

Epoch: 6| Step: 5
Training loss: 2.6242187790730127
Validation loss: 2.427922203468341

Epoch: 6| Step: 6
Training loss: 1.9723441604146021
Validation loss: 2.4101212184312812

Epoch: 6| Step: 7
Training loss: 2.4227236337649054
Validation loss: 2.391726227397028

Epoch: 6| Step: 8
Training loss: 2.153803003581076
Validation loss: 2.4098423012610324

Epoch: 6| Step: 9
Training loss: 2.203701836573038
Validation loss: 2.4109751654224474

Epoch: 6| Step: 10
Training loss: 2.6357402879242415
Validation loss: 2.397777268089344

Epoch: 6| Step: 11
Training loss: 2.0219409961335923
Validation loss: 2.411753595983523

Epoch: 6| Step: 12
Training loss: 2.2971536895459943
Validation loss: 2.426386796662955

Epoch: 6| Step: 13
Training loss: 2.2790035526504044
Validation loss: 2.4255811572332373

Epoch: 182| Step: 0
Training loss: 2.4113968140325976
Validation loss: 2.409202458357229

Epoch: 6| Step: 1
Training loss: 2.348509774583857
Validation loss: 2.3943656991696223

Epoch: 6| Step: 2
Training loss: 2.063724963234431
Validation loss: 2.4230129568131997

Epoch: 6| Step: 3
Training loss: 2.062675353023106
Validation loss: 2.3659165666734316

Epoch: 6| Step: 4
Training loss: 1.9622516256231621
Validation loss: 2.424887794898585

Epoch: 6| Step: 5
Training loss: 2.3713166636425425
Validation loss: 2.4295421892289286

Epoch: 6| Step: 6
Training loss: 2.550849948676488
Validation loss: 2.391930440530732

Epoch: 6| Step: 7
Training loss: 2.1044278376182626
Validation loss: 2.452250115435933

Epoch: 6| Step: 8
Training loss: 2.3157305447596053
Validation loss: 2.3983172758358253

Epoch: 6| Step: 9
Training loss: 2.5109877405083836
Validation loss: 2.400079350458638

Epoch: 6| Step: 10
Training loss: 2.094833093881979
Validation loss: 2.378562046282361

Epoch: 6| Step: 11
Training loss: 2.469770486183898
Validation loss: 2.4365712361323806

Epoch: 6| Step: 12
Training loss: 2.2003771371968117
Validation loss: 2.410506129291491

Epoch: 6| Step: 13
Training loss: 2.6410127614647156
Validation loss: 2.3900280493402684

Epoch: 183| Step: 0
Training loss: 2.164400039955411
Validation loss: 2.409127885897784

Epoch: 6| Step: 1
Training loss: 2.0071256776471076
Validation loss: 2.4114386820563314

Epoch: 6| Step: 2
Training loss: 2.5684685397427858
Validation loss: 2.399038273981288

Epoch: 6| Step: 3
Training loss: 2.3636118255688676
Validation loss: 2.416285562928714

Epoch: 6| Step: 4
Training loss: 2.079599989978037
Validation loss: 2.42550943423882

Epoch: 6| Step: 5
Training loss: 2.120813846561064
Validation loss: 2.411629326420159

Epoch: 6| Step: 6
Training loss: 2.399995676672538
Validation loss: 2.397367321432456

Epoch: 6| Step: 7
Training loss: 2.267776625140405
Validation loss: 2.44773031156818

Epoch: 6| Step: 8
Training loss: 3.361381605699255
Validation loss: 2.4479471467022424

Epoch: 6| Step: 9
Training loss: 2.0166864483496267
Validation loss: 2.4388652666507546

Epoch: 6| Step: 10
Training loss: 2.0703667399660777
Validation loss: 2.4271677393264737

Epoch: 6| Step: 11
Training loss: 2.2895948812964675
Validation loss: 2.4116787707494356

Epoch: 6| Step: 12
Training loss: 1.9190499235957696
Validation loss: 2.4427598833717394

Epoch: 6| Step: 13
Training loss: 2.006204517835311
Validation loss: 2.4368380280574535

Epoch: 184| Step: 0
Training loss: 2.713371305676439
Validation loss: 2.4563660638344884

Epoch: 6| Step: 1
Training loss: 2.6965003892759287
Validation loss: 2.454619861973601

Epoch: 6| Step: 2
Training loss: 2.2096780485507543
Validation loss: 2.4177289513825553

Epoch: 6| Step: 3
Training loss: 2.477562350538461
Validation loss: 2.4257766971681147

Epoch: 6| Step: 4
Training loss: 2.114181806154016
Validation loss: 2.4229817830996825

Epoch: 6| Step: 5
Training loss: 2.1603796293295923
Validation loss: 2.3969870761812455

Epoch: 6| Step: 6
Training loss: 1.9986190796917775
Validation loss: 2.41663075916515

Epoch: 6| Step: 7
Training loss: 1.9747442393747103
Validation loss: 2.4091515511105794

Epoch: 6| Step: 8
Training loss: 2.3112139863364463
Validation loss: 2.395740821482558

Epoch: 6| Step: 9
Training loss: 1.9690454049481532
Validation loss: 2.386739401089126

Epoch: 6| Step: 10
Training loss: 1.4167007367394242
Validation loss: 2.415644002507853

Epoch: 6| Step: 11
Training loss: 2.170421635497624
Validation loss: 2.4025446939386836

Epoch: 6| Step: 12
Training loss: 2.3913174293371346
Validation loss: 2.408723542924123

Epoch: 6| Step: 13
Training loss: 2.9097937851033655
Validation loss: 2.4170767440083982

Epoch: 185| Step: 0
Training loss: 2.4008494622234835
Validation loss: 2.4043285538090102

Epoch: 6| Step: 1
Training loss: 2.759167908169271
Validation loss: 2.39115250941903

Epoch: 6| Step: 2
Training loss: 1.8196075777232736
Validation loss: 2.4138876640634885

Epoch: 6| Step: 3
Training loss: 1.8430409118573987
Validation loss: 2.4114852886402804

Epoch: 6| Step: 4
Training loss: 2.084872198784883
Validation loss: 2.4052238577653897

Epoch: 6| Step: 5
Training loss: 1.6614033401938775
Validation loss: 2.404669655145279

Epoch: 6| Step: 6
Training loss: 2.1796244950571473
Validation loss: 2.4120425890572545

Epoch: 6| Step: 7
Training loss: 2.464786873477104
Validation loss: 2.443848935527343

Epoch: 6| Step: 8
Training loss: 1.9725718867325563
Validation loss: 2.39408444797275

Epoch: 6| Step: 9
Training loss: 2.054144958113144
Validation loss: 2.388846708440295

Epoch: 6| Step: 10
Training loss: 2.8229050489423546
Validation loss: 2.418955397702549

Epoch: 6| Step: 11
Training loss: 2.9237175502011974
Validation loss: 2.4299226717020255

Epoch: 6| Step: 12
Training loss: 2.018599570134785
Validation loss: 2.3878972947983805

Epoch: 6| Step: 13
Training loss: 2.159003890259751
Validation loss: 2.416099704251622

Epoch: 186| Step: 0
Training loss: 2.064469755136424
Validation loss: 2.404841929035683

Epoch: 6| Step: 1
Training loss: 1.6718899735109998
Validation loss: 2.4039279007559817

Epoch: 6| Step: 2
Training loss: 2.282730249363122
Validation loss: 2.3959264169152883

Epoch: 6| Step: 3
Training loss: 2.4752815857045096
Validation loss: 2.440291624338695

Epoch: 6| Step: 4
Training loss: 1.8286036981349358
Validation loss: 2.4361464363114633

Epoch: 6| Step: 5
Training loss: 2.2892865276398986
Validation loss: 2.391300979024619

Epoch: 6| Step: 6
Training loss: 2.493264470840913
Validation loss: 2.4188470516420097

Epoch: 6| Step: 7
Training loss: 2.315464079049206
Validation loss: 2.4214914558711182

Epoch: 6| Step: 8
Training loss: 2.1132853114852375
Validation loss: 2.408613363045926

Epoch: 6| Step: 9
Training loss: 2.4533082930005703
Validation loss: 2.4361661822336362

Epoch: 6| Step: 10
Training loss: 2.86334719718564
Validation loss: 2.3978809714287657

Epoch: 6| Step: 11
Training loss: 2.150175965671091
Validation loss: 2.4123580920634855

Epoch: 6| Step: 12
Training loss: 1.8977979045716853
Validation loss: 2.414475942363261

Epoch: 6| Step: 13
Training loss: 2.4123915534277516
Validation loss: 2.4197071335088407

Epoch: 187| Step: 0
Training loss: 1.7327685089994074
Validation loss: 2.4498550015942753

Epoch: 6| Step: 1
Training loss: 2.7626109105280734
Validation loss: 2.403471882638651

Epoch: 6| Step: 2
Training loss: 2.440622921208902
Validation loss: 2.3980922217294545

Epoch: 6| Step: 3
Training loss: 2.315907210683557
Validation loss: 2.3934810070788757

Epoch: 6| Step: 4
Training loss: 2.0894079021267546
Validation loss: 2.405026610546616

Epoch: 6| Step: 5
Training loss: 1.9829177912659277
Validation loss: 2.4021517806541515

Epoch: 6| Step: 6
Training loss: 2.375312884952658
Validation loss: 2.4272909725652507

Epoch: 6| Step: 7
Training loss: 2.6311538859955625
Validation loss: 2.3965468251574933

Epoch: 6| Step: 8
Training loss: 1.5969037286671295
Validation loss: 2.401351411885882

Epoch: 6| Step: 9
Training loss: 2.620418546893011
Validation loss: 2.421129471970661

Epoch: 6| Step: 10
Training loss: 2.1042294508628716
Validation loss: 2.4072490589665074

Epoch: 6| Step: 11
Training loss: 2.558798559014131
Validation loss: 2.3858407114704328

Epoch: 6| Step: 12
Training loss: 2.3927781126558787
Validation loss: 2.4123870050814236

Epoch: 6| Step: 13
Training loss: 1.0300081462908321
Validation loss: 2.4066497849909805

Epoch: 188| Step: 0
Training loss: 2.3730846511910926
Validation loss: 2.4008224209607594

Epoch: 6| Step: 1
Training loss: 2.0440822506236027
Validation loss: 2.38460016917519

Epoch: 6| Step: 2
Training loss: 2.382738556261752
Validation loss: 2.4150239419944586

Epoch: 6| Step: 3
Training loss: 2.2338964843536546
Validation loss: 2.4104471229752478

Epoch: 6| Step: 4
Training loss: 2.368532107354024
Validation loss: 2.4166138823207546

Epoch: 6| Step: 5
Training loss: 2.622443271019756
Validation loss: 2.407213676245253

Epoch: 6| Step: 6
Training loss: 2.2312404814017577
Validation loss: 2.3793278560045388

Epoch: 6| Step: 7
Training loss: 2.159337583623466
Validation loss: 2.4139113909397674

Epoch: 6| Step: 8
Training loss: 2.5919017411198513
Validation loss: 2.415553046061732

Epoch: 6| Step: 9
Training loss: 1.8840438804902264
Validation loss: 2.4186858637344435

Epoch: 6| Step: 10
Training loss: 1.8547494236829134
Validation loss: 2.3796011897449882

Epoch: 6| Step: 11
Training loss: 1.527895464362111
Validation loss: 2.374917443939556

Epoch: 6| Step: 12
Training loss: 2.271005804762483
Validation loss: 2.4219286195215957

Epoch: 6| Step: 13
Training loss: 2.4744405711466824
Validation loss: 2.4030486269224176

Epoch: 189| Step: 0
Training loss: 2.254001132812486
Validation loss: 2.39564317659298

Epoch: 6| Step: 1
Training loss: 2.590420895992772
Validation loss: 2.4060690558354776

Epoch: 6| Step: 2
Training loss: 2.4455684247627447
Validation loss: 2.429274641426351

Epoch: 6| Step: 3
Training loss: 2.3224332731288504
Validation loss: 2.4401227861670827

Epoch: 6| Step: 4
Training loss: 2.2236042917170713
Validation loss: 2.429931588269343

Epoch: 6| Step: 5
Training loss: 2.649868198931827
Validation loss: 2.387294083326868

Epoch: 6| Step: 6
Training loss: 1.6789631545912787
Validation loss: 2.4479596980983334

Epoch: 6| Step: 7
Training loss: 2.10474934079991
Validation loss: 2.4554656178793954

Epoch: 6| Step: 8
Training loss: 2.5595159135529824
Validation loss: 2.4303483784670474

Epoch: 6| Step: 9
Training loss: 2.6491388613175735
Validation loss: 2.379232942443122

Epoch: 6| Step: 10
Training loss: 1.8262864999955286
Validation loss: 2.4267852667426295

Epoch: 6| Step: 11
Training loss: 1.9323143010900223
Validation loss: 2.399895892183973

Epoch: 6| Step: 12
Training loss: 2.0414321401409095
Validation loss: 2.4348853038599434

Epoch: 6| Step: 13
Training loss: 1.5858046753232182
Validation loss: 2.4127352093260725

Epoch: 190| Step: 0
Training loss: 2.088895950012357
Validation loss: 2.430737894097144

Epoch: 6| Step: 1
Training loss: 1.760864998273512
Validation loss: 2.433269592848878

Epoch: 6| Step: 2
Training loss: 2.561928103758121
Validation loss: 2.440639691905187

Epoch: 6| Step: 3
Training loss: 2.4053293423771085
Validation loss: 2.409660046421438

Epoch: 6| Step: 4
Training loss: 1.7800521168954957
Validation loss: 2.4010512529951935

Epoch: 6| Step: 5
Training loss: 2.546975163087437
Validation loss: 2.380816591268351

Epoch: 6| Step: 6
Training loss: 2.095674228380113
Validation loss: 2.397419909675936

Epoch: 6| Step: 7
Training loss: 2.1243567895740063
Validation loss: 2.388063330546222

Epoch: 6| Step: 8
Training loss: 2.6649018249177954
Validation loss: 2.4253756519408305

Epoch: 6| Step: 9
Training loss: 1.9630201002851537
Validation loss: 2.4164297707713196

Epoch: 6| Step: 10
Training loss: 2.5102597473824524
Validation loss: 2.4005937401162947

Epoch: 6| Step: 11
Training loss: 1.8360683313382264
Validation loss: 2.412165628399775

Epoch: 6| Step: 12
Training loss: 2.256985945360793
Validation loss: 2.408478397947186

Epoch: 6| Step: 13
Training loss: 2.523015604092625
Validation loss: 2.3929570267491562

Epoch: 191| Step: 0
Training loss: 2.4352849040896456
Validation loss: 2.3991117121353867

Epoch: 6| Step: 1
Training loss: 2.0437463042899497
Validation loss: 2.4084338274682207

Epoch: 6| Step: 2
Training loss: 2.0698607905658237
Validation loss: 2.400409209366038

Epoch: 6| Step: 3
Training loss: 2.0346532628420735
Validation loss: 2.4101344465408086

Epoch: 6| Step: 4
Training loss: 2.403913279843272
Validation loss: 2.411603229891233

Epoch: 6| Step: 5
Training loss: 1.9335815429302174
Validation loss: 2.4147124219533325

Epoch: 6| Step: 6
Training loss: 2.251865355476014
Validation loss: 2.4700859944037172

Epoch: 6| Step: 7
Training loss: 2.569039165621472
Validation loss: 2.4140084381374036

Epoch: 6| Step: 8
Training loss: 1.944729024255874
Validation loss: 2.4447088737909515

Epoch: 6| Step: 9
Training loss: 2.042305774955839
Validation loss: 2.433635107632564

Epoch: 6| Step: 10
Training loss: 2.4137497980245133
Validation loss: 2.4098771081660932

Epoch: 6| Step: 11
Training loss: 1.9677704084576562
Validation loss: 2.433633375808968

Epoch: 6| Step: 12
Training loss: 2.377290123501721
Validation loss: 2.4307896412185444

Epoch: 6| Step: 13
Training loss: 3.2205931191890222
Validation loss: 2.421298549296928

Epoch: 192| Step: 0
Training loss: 1.9134104338118925
Validation loss: 2.3922871018012253

Epoch: 6| Step: 1
Training loss: 1.8726259460670909
Validation loss: 2.415623846861564

Epoch: 6| Step: 2
Training loss: 2.037612574925166
Validation loss: 2.395327530623708

Epoch: 6| Step: 3
Training loss: 3.094000141550664
Validation loss: 2.4020107451670882

Epoch: 6| Step: 4
Training loss: 2.0827771652441016
Validation loss: 2.3967364238737607

Epoch: 6| Step: 5
Training loss: 2.1809529011996056
Validation loss: 2.407872253389044

Epoch: 6| Step: 6
Training loss: 2.4124540136826536
Validation loss: 2.3700558981744573

Epoch: 6| Step: 7
Training loss: 1.7887705602204007
Validation loss: 2.4037698899406714

Epoch: 6| Step: 8
Training loss: 3.2153521630562807
Validation loss: 2.4060935854032044

Epoch: 6| Step: 9
Training loss: 1.3124912806630016
Validation loss: 2.3962771382293093

Epoch: 6| Step: 10
Training loss: 2.4389198276157233
Validation loss: 2.4069539875348425

Epoch: 6| Step: 11
Training loss: 2.0852552576953483
Validation loss: 2.3928623985387873

Epoch: 6| Step: 12
Training loss: 1.889785138688286
Validation loss: 2.3930063972957227

Epoch: 6| Step: 13
Training loss: 1.7575315802003706
Validation loss: 2.395737249544081

Epoch: 193| Step: 0
Training loss: 1.6210616878418211
Validation loss: 2.4104622658092754

Epoch: 6| Step: 1
Training loss: 2.8562840499350854
Validation loss: 2.352538645132031

Epoch: 6| Step: 2
Training loss: 2.0028041017201215
Validation loss: 2.396404516785983

Epoch: 6| Step: 3
Training loss: 2.01731009609423
Validation loss: 2.4049128031892066

Epoch: 6| Step: 4
Training loss: 2.119355502858725
Validation loss: 2.4258859141629228

Epoch: 6| Step: 5
Training loss: 1.9324874024763992
Validation loss: 2.394399658231705

Epoch: 6| Step: 6
Training loss: 2.047452655845719
Validation loss: 2.4096811222154986

Epoch: 6| Step: 7
Training loss: 2.506439498624715
Validation loss: 2.4092463649934848

Epoch: 6| Step: 8
Training loss: 2.5436877568758276
Validation loss: 2.377487841993938

Epoch: 6| Step: 9
Training loss: 2.3684123178510603
Validation loss: 2.3766740038549576

Epoch: 6| Step: 10
Training loss: 2.2493121897245083
Validation loss: 2.4088700579269013

Epoch: 6| Step: 11
Training loss: 1.572674317879127
Validation loss: 2.383125617859339

Epoch: 6| Step: 12
Training loss: 2.1575106929721826
Validation loss: 2.3970142762188966

Epoch: 6| Step: 13
Training loss: 3.1470603486739495
Validation loss: 2.4215521484447806

Epoch: 194| Step: 0
Training loss: 2.8055021755146843
Validation loss: 2.4173432238701875

Epoch: 6| Step: 1
Training loss: 2.517940237728347
Validation loss: 2.412458409941229

Epoch: 6| Step: 2
Training loss: 2.3556667263660214
Validation loss: 2.405050041635434

Epoch: 6| Step: 3
Training loss: 2.492745459588694
Validation loss: 2.4053607230190557

Epoch: 6| Step: 4
Training loss: 2.1990780285656566
Validation loss: 2.4167917966714296

Epoch: 6| Step: 5
Training loss: 2.195188797150044
Validation loss: 2.4361885956186975

Epoch: 6| Step: 6
Training loss: 1.360729463533386
Validation loss: 2.4558739095857107

Epoch: 6| Step: 7
Training loss: 2.261921242723201
Validation loss: 2.4297076560998794

Epoch: 6| Step: 8
Training loss: 1.5965927053667897
Validation loss: 2.434491013865164

Epoch: 6| Step: 9
Training loss: 1.479709803122115
Validation loss: 2.403548614470266

Epoch: 6| Step: 10
Training loss: 2.42422233775516
Validation loss: 2.408939233734012

Epoch: 6| Step: 11
Training loss: 1.9903665036412612
Validation loss: 2.4212825075543893

Epoch: 6| Step: 12
Training loss: 2.446617192782475
Validation loss: 2.445277305825992

Epoch: 6| Step: 13
Training loss: 2.0185303559703116
Validation loss: 2.4513231448545274

Epoch: 195| Step: 0
Training loss: 2.0394446939244064
Validation loss: 2.4381417175707885

Epoch: 6| Step: 1
Training loss: 1.830205857939793
Validation loss: 2.3989216129305526

Epoch: 6| Step: 2
Training loss: 1.8442695015104653
Validation loss: 2.4249496705710643

Epoch: 6| Step: 3
Training loss: 2.7758159915501084
Validation loss: 2.40643710626322

Epoch: 6| Step: 4
Training loss: 2.534878237958268
Validation loss: 2.4380399380995397

Epoch: 6| Step: 5
Training loss: 2.312687840436371
Validation loss: 2.388846222830439

Epoch: 6| Step: 6
Training loss: 1.9333240051154108
Validation loss: 2.3789768450655093

Epoch: 6| Step: 7
Training loss: 2.4946555231227077
Validation loss: 2.382422415442791

Epoch: 6| Step: 8
Training loss: 2.20000371932669
Validation loss: 2.3715192950123076

Epoch: 6| Step: 9
Training loss: 1.6787474374758662
Validation loss: 2.378885433921531

Epoch: 6| Step: 10
Training loss: 2.232109254856593
Validation loss: 2.3696625149780073

Epoch: 6| Step: 11
Training loss: 2.4187466012699192
Validation loss: 2.3736769002892695

Epoch: 6| Step: 12
Training loss: 2.1454243563436872
Validation loss: 2.380868464007745

Epoch: 6| Step: 13
Training loss: 2.4500671572141894
Validation loss: 2.351023089843953

Epoch: 196| Step: 0
Training loss: 1.6068075496326237
Validation loss: 2.4056970338897963

Epoch: 6| Step: 1
Training loss: 2.1521031406176716
Validation loss: 2.3767508457956676

Epoch: 6| Step: 2
Training loss: 1.6557418475565937
Validation loss: 2.3661605127182295

Epoch: 6| Step: 3
Training loss: 2.009257349630927
Validation loss: 2.3838221365913266

Epoch: 6| Step: 4
Training loss: 2.3305332094358158
Validation loss: 2.390344821962686

Epoch: 6| Step: 5
Training loss: 2.8749348176947684
Validation loss: 2.3341170328322978

Epoch: 6| Step: 6
Training loss: 1.9054548137134824
Validation loss: 2.386770483724126

Epoch: 6| Step: 7
Training loss: 1.6157004480804127
Validation loss: 2.3982119141339657

Epoch: 6| Step: 8
Training loss: 2.089654931781139
Validation loss: 2.3686468341918467

Epoch: 6| Step: 9
Training loss: 2.143826839749271
Validation loss: 2.3887784462871866

Epoch: 6| Step: 10
Training loss: 3.0514712365445127
Validation loss: 2.37775124269048

Epoch: 6| Step: 11
Training loss: 2.0328932937411626
Validation loss: 2.409260405541645

Epoch: 6| Step: 12
Training loss: 2.3711739892596047
Validation loss: 2.380345103098561

Epoch: 6| Step: 13
Training loss: 2.2905786069827085
Validation loss: 2.3905715947141313

Epoch: 197| Step: 0
Training loss: 2.657443148847303
Validation loss: 2.4082448473514106

Epoch: 6| Step: 1
Training loss: 2.1806983927968306
Validation loss: 2.401773993232224

Epoch: 6| Step: 2
Training loss: 2.0087627136549773
Validation loss: 2.429808376061886

Epoch: 6| Step: 3
Training loss: 2.0648856959446675
Validation loss: 2.4087940559547607

Epoch: 6| Step: 4
Training loss: 1.9547339564229875
Validation loss: 2.3979980273483386

Epoch: 6| Step: 5
Training loss: 2.4129098652756045
Validation loss: 2.4345398843696815

Epoch: 6| Step: 6
Training loss: 2.4736987382648015
Validation loss: 2.395642500273098

Epoch: 6| Step: 7
Training loss: 2.070413263136053
Validation loss: 2.4158046229474706

Epoch: 6| Step: 8
Training loss: 2.322598445518195
Validation loss: 2.4102847628012314

Epoch: 6| Step: 9
Training loss: 2.2042453162926745
Validation loss: 2.427938931490679

Epoch: 6| Step: 10
Training loss: 2.492858891949097
Validation loss: 2.4012030848717263

Epoch: 6| Step: 11
Training loss: 1.9393927650240392
Validation loss: 2.3940020520809058

Epoch: 6| Step: 12
Training loss: 1.6911849302192483
Validation loss: 2.405470637835248

Epoch: 6| Step: 13
Training loss: 1.870377054908958
Validation loss: 2.4123212539515135

Epoch: 198| Step: 0
Training loss: 2.0998782531324323
Validation loss: 2.4082010863954304

Epoch: 6| Step: 1
Training loss: 2.2264438530614155
Validation loss: 2.4108895580518057

Epoch: 6| Step: 2
Training loss: 1.9224996404560681
Validation loss: 2.3982370793952255

Epoch: 6| Step: 3
Training loss: 2.1680941158854043
Validation loss: 2.411684925574248

Epoch: 6| Step: 4
Training loss: 1.9434241509304966
Validation loss: 2.4044623487225447

Epoch: 6| Step: 5
Training loss: 2.2197731775104246
Validation loss: 2.4239005127683115

Epoch: 6| Step: 6
Training loss: 1.645617708334178
Validation loss: 2.4083378585646313

Epoch: 6| Step: 7
Training loss: 2.0207331786620677
Validation loss: 2.397780954597776

Epoch: 6| Step: 8
Training loss: 1.7523024262901576
Validation loss: 2.3987386817081364

Epoch: 6| Step: 9
Training loss: 2.6088429896584313
Validation loss: 2.3795099367198427

Epoch: 6| Step: 10
Training loss: 2.8384993150450524
Validation loss: 2.3912829044020514

Epoch: 6| Step: 11
Training loss: 2.4235183554761526
Validation loss: 2.413578371323542

Epoch: 6| Step: 12
Training loss: 2.060523502163057
Validation loss: 2.401309769403577

Epoch: 6| Step: 13
Training loss: 2.732169084396352
Validation loss: 2.409459524586089

Epoch: 199| Step: 0
Training loss: 2.080606226975329
Validation loss: 2.4041477737356916

Epoch: 6| Step: 1
Training loss: 1.5829797985838636
Validation loss: 2.3823456154680724

Epoch: 6| Step: 2
Training loss: 2.422978402092271
Validation loss: 2.3767439037069518

Epoch: 6| Step: 3
Training loss: 2.317109848645441
Validation loss: 2.387024633364577

Epoch: 6| Step: 4
Training loss: 2.6352658938576474
Validation loss: 2.3755256371240523

Epoch: 6| Step: 5
Training loss: 1.9985781622350285
Validation loss: 2.383535009915868

Epoch: 6| Step: 6
Training loss: 2.394802855976696
Validation loss: 2.367584730183771

Epoch: 6| Step: 7
Training loss: 1.8156975789098475
Validation loss: 2.388005429387497

Epoch: 6| Step: 8
Training loss: 2.2670367873698227
Validation loss: 2.403651102506199

Epoch: 6| Step: 9
Training loss: 1.128139776835788
Validation loss: 2.3682655444494682

Epoch: 6| Step: 10
Training loss: 2.16015051070101
Validation loss: 2.3944079056810135

Epoch: 6| Step: 11
Training loss: 2.341356504902775
Validation loss: 2.4373023650067167

Epoch: 6| Step: 12
Training loss: 2.3389439452762195
Validation loss: 2.4015235971544815

Epoch: 6| Step: 13
Training loss: 3.036747460098316
Validation loss: 2.3982286981306298

Epoch: 200| Step: 0
Training loss: 1.8541785964867779
Validation loss: 2.4226000877693528

Epoch: 6| Step: 1
Training loss: 2.2728418572757794
Validation loss: 2.3987720444974183

Epoch: 6| Step: 2
Training loss: 2.5339711950602397
Validation loss: 2.3944763788632666

Epoch: 6| Step: 3
Training loss: 2.238505247401771
Validation loss: 2.413684715984301

Epoch: 6| Step: 4
Training loss: 1.9066634433336733
Validation loss: 2.4216644084404324

Epoch: 6| Step: 5
Training loss: 2.462172425455484
Validation loss: 2.417807608510031

Epoch: 6| Step: 6
Training loss: 2.567045413802541
Validation loss: 2.369107149001917

Epoch: 6| Step: 7
Training loss: 2.157033142287969
Validation loss: 2.4032865754941377

Epoch: 6| Step: 8
Training loss: 1.6666138481671715
Validation loss: 2.400019037776216

Epoch: 6| Step: 9
Training loss: 2.3732424808464656
Validation loss: 2.3920082735289028

Epoch: 6| Step: 10
Training loss: 2.2895176145397085
Validation loss: 2.432552037987989

Epoch: 6| Step: 11
Training loss: 2.162000865332671
Validation loss: 2.4163885112086803

Epoch: 6| Step: 12
Training loss: 1.898373826454379
Validation loss: 2.3753418312120482

Epoch: 6| Step: 13
Training loss: 1.3372575807582967
Validation loss: 2.4011560459577086

Epoch: 201| Step: 0
Training loss: 2.2349897485963033
Validation loss: 2.450914197555086

Epoch: 6| Step: 1
Training loss: 2.3884353083872867
Validation loss: 2.416709040976435

Epoch: 6| Step: 2
Training loss: 2.3860760461818566
Validation loss: 2.4106646918392087

Epoch: 6| Step: 3
Training loss: 2.125475101092692
Validation loss: 2.3728128194662954

Epoch: 6| Step: 4
Training loss: 2.1396653746191805
Validation loss: 2.3973922116481257

Epoch: 6| Step: 5
Training loss: 2.3739805543291133
Validation loss: 2.4085910278022657

Epoch: 6| Step: 6
Training loss: 1.418697117563526
Validation loss: 2.3856336881176694

Epoch: 6| Step: 7
Training loss: 1.4445215483814713
Validation loss: 2.3691261540688275

Epoch: 6| Step: 8
Training loss: 3.0262540566544445
Validation loss: 2.385497921003416

Epoch: 6| Step: 9
Training loss: 2.1659357109497237
Validation loss: 2.389754049097563

Epoch: 6| Step: 10
Training loss: 2.1048003145949137
Validation loss: 2.4211762176047493

Epoch: 6| Step: 11
Training loss: 2.34645544942088
Validation loss: 2.3686351807928574

Epoch: 6| Step: 12
Training loss: 1.6389322176376362
Validation loss: 2.401759317578776

Epoch: 6| Step: 13
Training loss: 2.1587038313761107
Validation loss: 2.4048981552181004

Epoch: 202| Step: 0
Training loss: 2.341987353954492
Validation loss: 2.3631866465974456

Epoch: 6| Step: 1
Training loss: 2.184848377195875
Validation loss: 2.436407009832228

Epoch: 6| Step: 2
Training loss: 2.252140087032477
Validation loss: 2.3719364370419735

Epoch: 6| Step: 3
Training loss: 2.567272115695536
Validation loss: 2.3859916255969584

Epoch: 6| Step: 4
Training loss: 1.875465208198186
Validation loss: 2.4327297351546453

Epoch: 6| Step: 5
Training loss: 2.472376706681737
Validation loss: 2.4365864007362092

Epoch: 6| Step: 6
Training loss: 2.0128708586563446
Validation loss: 2.4291308431102148

Epoch: 6| Step: 7
Training loss: 1.7798682759868782
Validation loss: 2.4289599789701963

Epoch: 6| Step: 8
Training loss: 2.249910140892263
Validation loss: 2.4392711797793667

Epoch: 6| Step: 9
Training loss: 2.146451941150546
Validation loss: 2.3838800958024917

Epoch: 6| Step: 10
Training loss: 2.145331895133501
Validation loss: 2.4212837061094823

Epoch: 6| Step: 11
Training loss: 2.8708502633786406
Validation loss: 2.4207539870005568

Epoch: 6| Step: 12
Training loss: 1.5526122231089416
Validation loss: 2.441187889260384

Epoch: 6| Step: 13
Training loss: 1.6469503627956785
Validation loss: 2.4187005522165586

Epoch: 203| Step: 0
Training loss: 2.3953405011575275
Validation loss: 2.4056332605801374

Epoch: 6| Step: 1
Training loss: 2.024645235044724
Validation loss: 2.4154754633564797

Epoch: 6| Step: 2
Training loss: 1.6256373696038096
Validation loss: 2.3918306904234448

Epoch: 6| Step: 3
Training loss: 2.3638512798783617
Validation loss: 2.3945907202373027

Epoch: 6| Step: 4
Training loss: 1.8969257127999484
Validation loss: 2.383101704955557

Epoch: 6| Step: 5
Training loss: 2.44827432386916
Validation loss: 2.374895924704124

Epoch: 6| Step: 6
Training loss: 2.3520152521093025
Validation loss: 2.4061247142174618

Epoch: 6| Step: 7
Training loss: 2.344291319323594
Validation loss: 2.365570054023228

Epoch: 6| Step: 8
Training loss: 2.253355067936437
Validation loss: 2.382372367148416

Epoch: 6| Step: 9
Training loss: 1.1753579832129413
Validation loss: 2.3601054355504427

Epoch: 6| Step: 10
Training loss: 2.4875088485483716
Validation loss: 2.4082045174244793

Epoch: 6| Step: 11
Training loss: 1.9029749894174939
Validation loss: 2.3991526308859337

Epoch: 6| Step: 12
Training loss: 2.2643594298326235
Validation loss: 2.437165505823083

Epoch: 6| Step: 13
Training loss: 1.791951740858258
Validation loss: 2.3824571753068633

Epoch: 204| Step: 0
Training loss: 2.471067668573335
Validation loss: 2.3673520080613875

Epoch: 6| Step: 1
Training loss: 2.6363376822434743
Validation loss: 2.384511692588415

Epoch: 6| Step: 2
Training loss: 2.345405502559322
Validation loss: 2.3899039695141533

Epoch: 6| Step: 3
Training loss: 2.010058501232052
Validation loss: 2.3858472176981156

Epoch: 6| Step: 4
Training loss: 1.5792125316122656
Validation loss: 2.379612649387846

Epoch: 6| Step: 5
Training loss: 2.2805925231778916
Validation loss: 2.3855210398883435

Epoch: 6| Step: 6
Training loss: 1.997409752536569
Validation loss: 2.4149550577857095

Epoch: 6| Step: 7
Training loss: 2.4480386473653026
Validation loss: 2.401479241874264

Epoch: 6| Step: 8
Training loss: 2.468036017206103
Validation loss: 2.3686708080632166

Epoch: 6| Step: 9
Training loss: 1.6538134952964714
Validation loss: 2.4126129040659614

Epoch: 6| Step: 10
Training loss: 1.8201966473955002
Validation loss: 2.4107144143683494

Epoch: 6| Step: 11
Training loss: 1.8685202849698015
Validation loss: 2.3998301449354953

Epoch: 6| Step: 12
Training loss: 1.7974466492610282
Validation loss: 2.404418617016539

Epoch: 6| Step: 13
Training loss: 2.2821724476762526
Validation loss: 2.410679587649298

Epoch: 205| Step: 0
Training loss: 2.291940799847344
Validation loss: 2.3908437963472005

Epoch: 6| Step: 1
Training loss: 1.8203859764626846
Validation loss: 2.4118819609606903

Epoch: 6| Step: 2
Training loss: 1.670944739390797
Validation loss: 2.4214484732003916

Epoch: 6| Step: 3
Training loss: 2.37849570554354
Validation loss: 2.412112715975679

Epoch: 6| Step: 4
Training loss: 1.843031015674329
Validation loss: 2.4239300919114375

Epoch: 6| Step: 5
Training loss: 2.08398529024113
Validation loss: 2.3990827652214994

Epoch: 6| Step: 6
Training loss: 1.8495315164777095
Validation loss: 2.4097150856665692

Epoch: 6| Step: 7
Training loss: 1.9635821135088034
Validation loss: 2.4095580086719033

Epoch: 6| Step: 8
Training loss: 1.9381223109871553
Validation loss: 2.3996821469468994

Epoch: 6| Step: 9
Training loss: 2.083588266669411
Validation loss: 2.389514087773325

Epoch: 6| Step: 10
Training loss: 2.639277368248796
Validation loss: 2.4108106193820698

Epoch: 6| Step: 11
Training loss: 2.052157276454387
Validation loss: 2.4175657234352785

Epoch: 6| Step: 12
Training loss: 2.9113413196358384
Validation loss: 2.4424248526136636

Epoch: 6| Step: 13
Training loss: 2.0799044684333072
Validation loss: 2.368119342205371

Epoch: 206| Step: 0
Training loss: 1.9860924324929803
Validation loss: 2.378375145951307

Epoch: 6| Step: 1
Training loss: 2.3467855505017807
Validation loss: 2.41080421136359

Epoch: 6| Step: 2
Training loss: 2.2124438866002865
Validation loss: 2.4238279600015216

Epoch: 6| Step: 3
Training loss: 2.1956322053681943
Validation loss: 2.3834985910947797

Epoch: 6| Step: 4
Training loss: 2.262523554052333
Validation loss: 2.414786587861213

Epoch: 6| Step: 5
Training loss: 2.208156170726248
Validation loss: 2.381581864946224

Epoch: 6| Step: 6
Training loss: 1.9925870606895675
Validation loss: 2.362730277994829

Epoch: 6| Step: 7
Training loss: 1.9594912115796939
Validation loss: 2.3578641838313628

Epoch: 6| Step: 8
Training loss: 1.4445658636820202
Validation loss: 2.4008727787145703

Epoch: 6| Step: 9
Training loss: 2.290860039906984
Validation loss: 2.362461736021638

Epoch: 6| Step: 10
Training loss: 2.6113808968232606
Validation loss: 2.3765921251211366

Epoch: 6| Step: 11
Training loss: 1.911414732336156
Validation loss: 2.4015664998338235

Epoch: 6| Step: 12
Training loss: 2.2422936178476127
Validation loss: 2.403419587882172

Epoch: 6| Step: 13
Training loss: 2.053661249696117
Validation loss: 2.379683240734347

Epoch: 207| Step: 0
Training loss: 2.489209156301639
Validation loss: 2.397743921395785

Epoch: 6| Step: 1
Training loss: 1.9486435402694078
Validation loss: 2.3898652330718417

Epoch: 6| Step: 2
Training loss: 1.6013036006916785
Validation loss: 2.4137620535508395

Epoch: 6| Step: 3
Training loss: 1.7983499858652032
Validation loss: 2.4127083304972974

Epoch: 6| Step: 4
Training loss: 1.8291128375127998
Validation loss: 2.4021431222279324

Epoch: 6| Step: 5
Training loss: 2.0677834087998694
Validation loss: 2.379182837830555

Epoch: 6| Step: 6
Training loss: 1.9561508543587698
Validation loss: 2.3803860773541032

Epoch: 6| Step: 7
Training loss: 2.6907357541991708
Validation loss: 2.424114386792321

Epoch: 6| Step: 8
Training loss: 2.5132340151374186
Validation loss: 2.4152722188164666

Epoch: 6| Step: 9
Training loss: 1.5646423149250996
Validation loss: 2.4280948579345076

Epoch: 6| Step: 10
Training loss: 2.514618950828334
Validation loss: 2.393229125246714

Epoch: 6| Step: 11
Training loss: 2.089590581372344
Validation loss: 2.395839249941104

Epoch: 6| Step: 12
Training loss: 1.7868020382289052
Validation loss: 2.437728317922292

Epoch: 6| Step: 13
Training loss: 1.8509110862113443
Validation loss: 2.3726996878779807

Epoch: 208| Step: 0
Training loss: 2.0846344381723645
Validation loss: 2.396884922481353

Epoch: 6| Step: 1
Training loss: 2.3807598340425136
Validation loss: 2.3929203410008446

Epoch: 6| Step: 2
Training loss: 2.4635966148996116
Validation loss: 2.405370002947734

Epoch: 6| Step: 3
Training loss: 1.7904463833704274
Validation loss: 2.384105065646562

Epoch: 6| Step: 4
Training loss: 1.9083324376844055
Validation loss: 2.4020709027151197

Epoch: 6| Step: 5
Training loss: 2.7083183190345292
Validation loss: 2.4079804331770425

Epoch: 6| Step: 6
Training loss: 2.093430224239577
Validation loss: 2.399340853706415

Epoch: 6| Step: 7
Training loss: 2.1816187680753827
Validation loss: 2.430278470779226

Epoch: 6| Step: 8
Training loss: 1.7217827136999027
Validation loss: 2.3974816543168216

Epoch: 6| Step: 9
Training loss: 1.9427499093387177
Validation loss: 2.406569154091186

Epoch: 6| Step: 10
Training loss: 1.9478274714266184
Validation loss: 2.4220906574772205

Epoch: 6| Step: 11
Training loss: 1.8524547632127906
Validation loss: 2.413384490724686

Epoch: 6| Step: 12
Training loss: 1.9886747619092433
Validation loss: 2.4166883383498083

Epoch: 6| Step: 13
Training loss: 2.082408076498026
Validation loss: 2.408558982493962

Epoch: 209| Step: 0
Training loss: 2.24803966318891
Validation loss: 2.3671836987016848

Epoch: 6| Step: 1
Training loss: 1.8143835475298482
Validation loss: 2.404733222403558

Epoch: 6| Step: 2
Training loss: 2.2772265971756154
Validation loss: 2.38441325239936

Epoch: 6| Step: 3
Training loss: 1.7200276567763915
Validation loss: 2.3905049802681844

Epoch: 6| Step: 4
Training loss: 3.1420986077602135
Validation loss: 2.410275913419792

Epoch: 6| Step: 5
Training loss: 1.9718151149936156
Validation loss: 2.387765341721856

Epoch: 6| Step: 6
Training loss: 1.8819609809827753
Validation loss: 2.3678391380496184

Epoch: 6| Step: 7
Training loss: 1.8410563431447238
Validation loss: 2.340426719960704

Epoch: 6| Step: 8
Training loss: 2.8290749319164292
Validation loss: 2.3607941610410204

Epoch: 6| Step: 9
Training loss: 1.7584971133184832
Validation loss: 2.4299832586659313

Epoch: 6| Step: 10
Training loss: 1.957641141049014
Validation loss: 2.3622421639392197

Epoch: 6| Step: 11
Training loss: 1.9939682724436316
Validation loss: 2.3818904723462713

Epoch: 6| Step: 12
Training loss: 2.008287425591532
Validation loss: 2.383254822349242

Epoch: 6| Step: 13
Training loss: 1.7163704091819758
Validation loss: 2.347297513693974

Epoch: 210| Step: 0
Training loss: 2.515147098615375
Validation loss: 2.391665109158895

Epoch: 6| Step: 1
Training loss: 1.3572333994040096
Validation loss: 2.380892642149977

Epoch: 6| Step: 2
Training loss: 1.9325837551191765
Validation loss: 2.45751464758767

Epoch: 6| Step: 3
Training loss: 2.428249510097464
Validation loss: 2.394712842216317

Epoch: 6| Step: 4
Training loss: 1.9513615085525662
Validation loss: 2.3823144008489145

Epoch: 6| Step: 5
Training loss: 1.8846778967803561
Validation loss: 2.428990433727554

Epoch: 6| Step: 6
Training loss: 2.408470021453097
Validation loss: 2.41102488899179

Epoch: 6| Step: 7
Training loss: 1.711747347977173
Validation loss: 2.3895022818704486

Epoch: 6| Step: 8
Training loss: 1.878427170804566
Validation loss: 2.379514107799723

Epoch: 6| Step: 9
Training loss: 2.463074352844258
Validation loss: 2.3999943179401693

Epoch: 6| Step: 10
Training loss: 1.5449964888696373
Validation loss: 2.42106014202533

Epoch: 6| Step: 11
Training loss: 2.602782733667795
Validation loss: 2.385920610585728

Epoch: 6| Step: 12
Training loss: 1.9952841234691163
Validation loss: 2.4163005418562316

Epoch: 6| Step: 13
Training loss: 2.162003291421338
Validation loss: 2.4395000423333895

Epoch: 211| Step: 0
Training loss: 2.1731306878301546
Validation loss: 2.403036650676425

Epoch: 6| Step: 1
Training loss: 1.8021485936102877
Validation loss: 2.388053073013029

Epoch: 6| Step: 2
Training loss: 2.624952043367739
Validation loss: 2.4031629391389653

Epoch: 6| Step: 3
Training loss: 2.0866616810057597
Validation loss: 2.395588729556131

Epoch: 6| Step: 4
Training loss: 1.5982194201728686
Validation loss: 2.3979464834634245

Epoch: 6| Step: 5
Training loss: 1.8298871277566793
Validation loss: 2.3772191882515554

Epoch: 6| Step: 6
Training loss: 1.6747345044970496
Validation loss: 2.4166048587989923

Epoch: 6| Step: 7
Training loss: 2.237559789785786
Validation loss: 2.42999421801669

Epoch: 6| Step: 8
Training loss: 2.1223595988607165
Validation loss: 2.3956558773526444

Epoch: 6| Step: 9
Training loss: 2.0576264571753704
Validation loss: 2.3782804552298638

Epoch: 6| Step: 10
Training loss: 1.7104343040136203
Validation loss: 2.390242336122991

Epoch: 6| Step: 11
Training loss: 2.071568061566796
Validation loss: 2.3775351292087885

Epoch: 6| Step: 12
Training loss: 2.762379439126792
Validation loss: 2.383918499879643

Epoch: 6| Step: 13
Training loss: 2.0745909046291087
Validation loss: 2.382913358111512

Epoch: 212| Step: 0
Training loss: 2.5102330585200967
Validation loss: 2.383872648061732

Epoch: 6| Step: 1
Training loss: 2.56631390595613
Validation loss: 2.3705535504148623

Epoch: 6| Step: 2
Training loss: 2.0195907495466248
Validation loss: 2.3634577002639143

Epoch: 6| Step: 3
Training loss: 1.8338268078279363
Validation loss: 2.3901367171411128

Epoch: 6| Step: 4
Training loss: 2.3821003834722156
Validation loss: 2.3595610818688364

Epoch: 6| Step: 5
Training loss: 2.8817318594070276
Validation loss: 2.36825820456636

Epoch: 6| Step: 6
Training loss: 1.7868413338520184
Validation loss: 2.3823387305743022

Epoch: 6| Step: 7
Training loss: 2.094590545008502
Validation loss: 2.3559393731884293

Epoch: 6| Step: 8
Training loss: 1.5749706810538409
Validation loss: 2.392349891650776

Epoch: 6| Step: 9
Training loss: 2.1162599453182604
Validation loss: 2.383209964626414

Epoch: 6| Step: 10
Training loss: 1.6722891463951446
Validation loss: 2.4056285177566643

Epoch: 6| Step: 11
Training loss: 1.9552667090498617
Validation loss: 2.401241341612142

Epoch: 6| Step: 12
Training loss: 1.9818243018684987
Validation loss: 2.434890636688385

Epoch: 6| Step: 13
Training loss: 1.4462369694365915
Validation loss: 2.400565017184179

Epoch: 213| Step: 0
Training loss: 2.06480694845184
Validation loss: 2.392882053005859

Epoch: 6| Step: 1
Training loss: 2.2239545573456367
Validation loss: 2.417596529567609

Epoch: 6| Step: 2
Training loss: 1.1787669651270989
Validation loss: 2.3975853544036063

Epoch: 6| Step: 3
Training loss: 2.4663738936149704
Validation loss: 2.3776360645442836

Epoch: 6| Step: 4
Training loss: 2.292026618663143
Validation loss: 2.3801285476400444

Epoch: 6| Step: 5
Training loss: 2.4530381108343113
Validation loss: 2.4086404780907893

Epoch: 6| Step: 6
Training loss: 2.2789491520591016
Validation loss: 2.348690292606369

Epoch: 6| Step: 7
Training loss: 1.9684974871777576
Validation loss: 2.3976143589581755

Epoch: 6| Step: 8
Training loss: 2.10521281709214
Validation loss: 2.4308022358571906

Epoch: 6| Step: 9
Training loss: 2.7394766164284023
Validation loss: 2.398206214325691

Epoch: 6| Step: 10
Training loss: 2.0791822913225566
Validation loss: 2.3573039036966614

Epoch: 6| Step: 11
Training loss: 1.5354857734162728
Validation loss: 2.3809999519348106

Epoch: 6| Step: 12
Training loss: 1.890347294864792
Validation loss: 2.4162145565834905

Epoch: 6| Step: 13
Training loss: 1.6247148997290606
Validation loss: 2.387112930895032

Epoch: 214| Step: 0
Training loss: 2.3333731261901964
Validation loss: 2.363267451555959

Epoch: 6| Step: 1
Training loss: 1.4984132003007211
Validation loss: 2.4085097050953785

Epoch: 6| Step: 2
Training loss: 2.060331996904742
Validation loss: 2.404504588044375

Epoch: 6| Step: 3
Training loss: 2.103555181303156
Validation loss: 2.379782004775137

Epoch: 6| Step: 4
Training loss: 2.6591553002232806
Validation loss: 2.4113452104965374

Epoch: 6| Step: 5
Training loss: 1.83924982482984
Validation loss: 2.4369908590683482

Epoch: 6| Step: 6
Training loss: 2.4130526408758555
Validation loss: 2.4127315095402433

Epoch: 6| Step: 7
Training loss: 1.9645983199528592
Validation loss: 2.3944718104051588

Epoch: 6| Step: 8
Training loss: 1.7996957945727743
Validation loss: 2.449864297678477

Epoch: 6| Step: 9
Training loss: 2.6770021201158465
Validation loss: 2.3658238046015416

Epoch: 6| Step: 10
Training loss: 1.5946338671008404
Validation loss: 2.4058694547886295

Epoch: 6| Step: 11
Training loss: 1.9010440216746614
Validation loss: 2.4041474959539215

Epoch: 6| Step: 12
Training loss: 2.2711270576924174
Validation loss: 2.423701555174441

Epoch: 6| Step: 13
Training loss: 1.167434519171043
Validation loss: 2.409179731128653

Epoch: 215| Step: 0
Training loss: 1.718840232561308
Validation loss: 2.4085401555301558

Epoch: 6| Step: 1
Training loss: 2.3952975019469402
Validation loss: 2.3334221237036075

Epoch: 6| Step: 2
Training loss: 1.9545562382938908
Validation loss: 2.39242921226433

Epoch: 6| Step: 3
Training loss: 2.2210171359250044
Validation loss: 2.393097540079432

Epoch: 6| Step: 4
Training loss: 1.5228638962954026
Validation loss: 2.4165760471664983

Epoch: 6| Step: 5
Training loss: 1.796973316985878
Validation loss: 2.3715677497957683

Epoch: 6| Step: 6
Training loss: 2.0263660109183332
Validation loss: 2.427318585538773

Epoch: 6| Step: 7
Training loss: 1.7877785018891508
Validation loss: 2.398217325839244

Epoch: 6| Step: 8
Training loss: 2.4571461370199117
Validation loss: 2.388038682870354

Epoch: 6| Step: 9
Training loss: 1.5764369434458096
Validation loss: 2.411649795026347

Epoch: 6| Step: 10
Training loss: 2.2362290806055727
Validation loss: 2.3663964179063632

Epoch: 6| Step: 11
Training loss: 1.964069373119531
Validation loss: 2.387040545547688

Epoch: 6| Step: 12
Training loss: 2.3281284818687262
Validation loss: 2.4130762675982966

Epoch: 6| Step: 13
Training loss: 2.7601933994811056
Validation loss: 2.380943454265707

Epoch: 216| Step: 0
Training loss: 2.2237816292977706
Validation loss: 2.387519478821803

Epoch: 6| Step: 1
Training loss: 1.7921305506869656
Validation loss: 2.4085083447796403

Epoch: 6| Step: 2
Training loss: 1.737808746240544
Validation loss: 2.4077256941715515

Epoch: 6| Step: 3
Training loss: 2.0401940257234497
Validation loss: 2.3834197541647506

Epoch: 6| Step: 4
Training loss: 2.1431787113324208
Validation loss: 2.3872743165420083

Epoch: 6| Step: 5
Training loss: 1.9520432795510654
Validation loss: 2.363230890713626

Epoch: 6| Step: 6
Training loss: 2.383130862121015
Validation loss: 2.380633179865425

Epoch: 6| Step: 7
Training loss: 2.176259287946361
Validation loss: 2.3518347276838583

Epoch: 6| Step: 8
Training loss: 2.2066187650354427
Validation loss: 2.403659764566131

Epoch: 6| Step: 9
Training loss: 1.941066167199871
Validation loss: 2.424357918445651

Epoch: 6| Step: 10
Training loss: 2.1164959555843432
Validation loss: 2.4050942234041486

Epoch: 6| Step: 11
Training loss: 1.6406622746184174
Validation loss: 2.4067091645573426

Epoch: 6| Step: 12
Training loss: 2.697072833641057
Validation loss: 2.398711837882826

Epoch: 6| Step: 13
Training loss: 2.158800137483749
Validation loss: 2.4098285656981777

Epoch: 217| Step: 0
Training loss: 1.6103687366428048
Validation loss: 2.3817108582527657

Epoch: 6| Step: 1
Training loss: 2.644805939014734
Validation loss: 2.4058398464668302

Epoch: 6| Step: 2
Training loss: 1.9045091403131935
Validation loss: 2.41932678387554

Epoch: 6| Step: 3
Training loss: 2.004173216409218
Validation loss: 2.3783243118410407

Epoch: 6| Step: 4
Training loss: 2.7395389297039165
Validation loss: 2.407902402063793

Epoch: 6| Step: 5
Training loss: 1.9876011132964764
Validation loss: 2.4344164557340977

Epoch: 6| Step: 6
Training loss: 1.8365043901224316
Validation loss: 2.4022341349962186

Epoch: 6| Step: 7
Training loss: 1.8835713610273754
Validation loss: 2.410995813965424

Epoch: 6| Step: 8
Training loss: 1.7484857274717354
Validation loss: 2.4143118048126104

Epoch: 6| Step: 9
Training loss: 2.268604713180665
Validation loss: 2.429627054965712

Epoch: 6| Step: 10
Training loss: 1.6726075466001724
Validation loss: 2.3904241233127577

Epoch: 6| Step: 11
Training loss: 2.476485579105367
Validation loss: 2.404158007918839

Epoch: 6| Step: 12
Training loss: 1.6195226938672171
Validation loss: 2.3606168731136274

Epoch: 6| Step: 13
Training loss: 2.348153517069909
Validation loss: 2.3993717763014324

Epoch: 218| Step: 0
Training loss: 2.212357028285776
Validation loss: 2.38507079361825

Epoch: 6| Step: 1
Training loss: 1.993865021165107
Validation loss: 2.386081877035719

Epoch: 6| Step: 2
Training loss: 1.7035257410467666
Validation loss: 2.4040500133642895

Epoch: 6| Step: 3
Training loss: 1.8058997372311112
Validation loss: 2.432053975812221

Epoch: 6| Step: 4
Training loss: 2.372010608359894
Validation loss: 2.3929171221459007

Epoch: 6| Step: 5
Training loss: 2.2146486872602162
Validation loss: 2.3888057269137932

Epoch: 6| Step: 6
Training loss: 2.7434923159611797
Validation loss: 2.426601258698725

Epoch: 6| Step: 7
Training loss: 2.1290458983369387
Validation loss: 2.4101844863459485

Epoch: 6| Step: 8
Training loss: 2.2555035991771057
Validation loss: 2.3594460762225657

Epoch: 6| Step: 9
Training loss: 2.355677454671326
Validation loss: 2.3875166977625604

Epoch: 6| Step: 10
Training loss: 1.6950819852012926
Validation loss: 2.383623518453573

Epoch: 6| Step: 11
Training loss: 1.482388100220483
Validation loss: 2.4163327486761794

Epoch: 6| Step: 12
Training loss: 1.9527881789650197
Validation loss: 2.3787119074259877

Epoch: 6| Step: 13
Training loss: 1.946209436482697
Validation loss: 2.383234726245447

Epoch: 219| Step: 0
Training loss: 1.8047896847550189
Validation loss: 2.3713975548107955

Epoch: 6| Step: 1
Training loss: 2.4673430864247337
Validation loss: 2.404204964639731

Epoch: 6| Step: 2
Training loss: 1.4604951729490652
Validation loss: 2.3995719306583325

Epoch: 6| Step: 3
Training loss: 1.9782702038640878
Validation loss: 2.4008804390657317

Epoch: 6| Step: 4
Training loss: 2.1375748559883494
Validation loss: 2.337485645147676

Epoch: 6| Step: 5
Training loss: 2.0891235251347595
Validation loss: 2.390147940713569

Epoch: 6| Step: 6
Training loss: 1.5546805990248065
Validation loss: 2.394307175216464

Epoch: 6| Step: 7
Training loss: 2.7489391361408027
Validation loss: 2.3874203175624524

Epoch: 6| Step: 8
Training loss: 2.3473767512490804
Validation loss: 2.3567658560240328

Epoch: 6| Step: 9
Training loss: 1.9552137268783272
Validation loss: 2.3799986154630317

Epoch: 6| Step: 10
Training loss: 1.5036551129599063
Validation loss: 2.3511742243475564

Epoch: 6| Step: 11
Training loss: 1.8925855575431325
Validation loss: 2.3536214985855564

Epoch: 6| Step: 12
Training loss: 2.558853532255438
Validation loss: 2.394858360848934

Epoch: 6| Step: 13
Training loss: 1.9891205760451383
Validation loss: 2.4329211294549355

Epoch: 220| Step: 0
Training loss: 2.1771255805435366
Validation loss: 2.358397429826598

Epoch: 6| Step: 1
Training loss: 1.8207470943999189
Validation loss: 2.393946734035445

Epoch: 6| Step: 2
Training loss: 2.3031156707947393
Validation loss: 2.391015623756251

Epoch: 6| Step: 3
Training loss: 2.4822639757266813
Validation loss: 2.4101681291750783

Epoch: 6| Step: 4
Training loss: 1.840898798476024
Validation loss: 2.4093571655180286

Epoch: 6| Step: 5
Training loss: 2.2072611191132823
Validation loss: 2.376927892406905

Epoch: 6| Step: 6
Training loss: 1.5052637092233405
Validation loss: 2.404424249853316

Epoch: 6| Step: 7
Training loss: 2.514720967552308
Validation loss: 2.396645762841162

Epoch: 6| Step: 8
Training loss: 2.2109065508613983
Validation loss: 2.4173332517808377

Epoch: 6| Step: 9
Training loss: 2.2845273448487267
Validation loss: 2.366751556341449

Epoch: 6| Step: 10
Training loss: 1.9415639279843957
Validation loss: 2.3785364152568

Epoch: 6| Step: 11
Training loss: 1.5007740248943569
Validation loss: 2.4019499948191774

Epoch: 6| Step: 12
Training loss: 2.049452927327331
Validation loss: 2.3641574142279453

Epoch: 6| Step: 13
Training loss: 1.7516522781816766
Validation loss: 2.396738977098586

Epoch: 221| Step: 0
Training loss: 2.1379009651534844
Validation loss: 2.389001058689284

Epoch: 6| Step: 1
Training loss: 1.8966138581408947
Validation loss: 2.4048799903734417

Epoch: 6| Step: 2
Training loss: 2.9625584335036885
Validation loss: 2.406016953914115

Epoch: 6| Step: 3
Training loss: 1.8823579104880346
Validation loss: 2.4015780409400698

Epoch: 6| Step: 4
Training loss: 2.0071706970642333
Validation loss: 2.3828340972884545

Epoch: 6| Step: 5
Training loss: 1.3198859976176553
Validation loss: 2.386582161629066

Epoch: 6| Step: 6
Training loss: 2.0707108024508094
Validation loss: 2.418478625585303

Epoch: 6| Step: 7
Training loss: 2.281256584262491
Validation loss: 2.3945220511880616

Epoch: 6| Step: 8
Training loss: 1.74559583968061
Validation loss: 2.419813516062871

Epoch: 6| Step: 9
Training loss: 1.8549041852857457
Validation loss: 2.403225230681945

Epoch: 6| Step: 10
Training loss: 1.4884345508828942
Validation loss: 2.3796949477606364

Epoch: 6| Step: 11
Training loss: 2.4357177870189495
Validation loss: 2.379964856473153

Epoch: 6| Step: 12
Training loss: 2.1575238431848516
Validation loss: 2.4003318388864843

Epoch: 6| Step: 13
Training loss: 1.8914866099880696
Validation loss: 2.401762305232711

Epoch: 222| Step: 0
Training loss: 1.9011916288686357
Validation loss: 2.3884772193393142

Epoch: 6| Step: 1
Training loss: 1.921546473762755
Validation loss: 2.3862759298667595

Epoch: 6| Step: 2
Training loss: 2.758068645566315
Validation loss: 2.3941902161759265

Epoch: 6| Step: 3
Training loss: 1.9631911621797975
Validation loss: 2.3862092959535626

Epoch: 6| Step: 4
Training loss: 1.7314614232277115
Validation loss: 2.3366234121078238

Epoch: 6| Step: 5
Training loss: 2.674979564553039
Validation loss: 2.395789250792666

Epoch: 6| Step: 6
Training loss: 1.877753588215296
Validation loss: 2.3657535539235264

Epoch: 6| Step: 7
Training loss: 1.656665246119872
Validation loss: 2.3621618443062498

Epoch: 6| Step: 8
Training loss: 1.745889058585601
Validation loss: 2.403402342000215

Epoch: 6| Step: 9
Training loss: 1.8781854908574998
Validation loss: 2.408524847337471

Epoch: 6| Step: 10
Training loss: 1.9353022261977777
Validation loss: 2.3891989046603346

Epoch: 6| Step: 11
Training loss: 2.2190325919702203
Validation loss: 2.431738183353086

Epoch: 6| Step: 12
Training loss: 1.8144089084653796
Validation loss: 2.360375794946353

Epoch: 6| Step: 13
Training loss: 2.341808888561241
Validation loss: 2.3513438933632735

Epoch: 223| Step: 0
Training loss: 2.1674172739611843
Validation loss: 2.435975733276634

Epoch: 6| Step: 1
Training loss: 1.458042479075481
Validation loss: 2.3693061303269602

Epoch: 6| Step: 2
Training loss: 2.6365784106170693
Validation loss: 2.4018984652976827

Epoch: 6| Step: 3
Training loss: 2.100663797734726
Validation loss: 2.3615036453741722

Epoch: 6| Step: 4
Training loss: 1.9811663781458406
Validation loss: 2.3640268059474545

Epoch: 6| Step: 5
Training loss: 1.9151570207448465
Validation loss: 2.4244178064650725

Epoch: 6| Step: 6
Training loss: 1.9533096836511514
Validation loss: 2.3747273954147565

Epoch: 6| Step: 7
Training loss: 1.4384517835877104
Validation loss: 2.3731399132356628

Epoch: 6| Step: 8
Training loss: 1.956605906910555
Validation loss: 2.3904801293384015

Epoch: 6| Step: 9
Training loss: 2.2362289739892214
Validation loss: 2.4069208936634183

Epoch: 6| Step: 10
Training loss: 1.9336034292884312
Validation loss: 2.3737520999192085

Epoch: 6| Step: 11
Training loss: 2.4078617395395194
Validation loss: 2.3329915713454366

Epoch: 6| Step: 12
Training loss: 1.803909067818352
Validation loss: 2.397001338271563

Epoch: 6| Step: 13
Training loss: 1.9043440749358842
Validation loss: 2.4308656678861635

Epoch: 224| Step: 0
Training loss: 2.0297308302696613
Validation loss: 2.420035111589469

Epoch: 6| Step: 1
Training loss: 2.2827569869939994
Validation loss: 2.36314209843901

Epoch: 6| Step: 2
Training loss: 2.213756045263772
Validation loss: 2.4140242855558336

Epoch: 6| Step: 3
Training loss: 1.9012458029756487
Validation loss: 2.3896688798222256

Epoch: 6| Step: 4
Training loss: 2.588101130147233
Validation loss: 2.3662124023064597

Epoch: 6| Step: 5
Training loss: 1.6250330848260213
Validation loss: 2.3843151575894774

Epoch: 6| Step: 6
Training loss: 1.9996806128112494
Validation loss: 2.3804308030533377

Epoch: 6| Step: 7
Training loss: 2.770834289397646
Validation loss: 2.3841966632249587

Epoch: 6| Step: 8
Training loss: 1.9722964119127966
Validation loss: 2.3796332436397463

Epoch: 6| Step: 9
Training loss: 1.3573203508571858
Validation loss: 2.3877032083910557

Epoch: 6| Step: 10
Training loss: 2.0646642254002128
Validation loss: 2.4197773391878425

Epoch: 6| Step: 11
Training loss: 1.9393461107615757
Validation loss: 2.4131515275627935

Epoch: 6| Step: 12
Training loss: 1.6988113791946706
Validation loss: 2.4054871079455564

Epoch: 6| Step: 13
Training loss: 1.7634921399496468
Validation loss: 2.428236117787076

Epoch: 225| Step: 0
Training loss: 2.3056605467068705
Validation loss: 2.3556953475867366

Epoch: 6| Step: 1
Training loss: 1.9109485441872824
Validation loss: 2.4056628805027334

Epoch: 6| Step: 2
Training loss: 2.1960722670832573
Validation loss: 2.422972140523917

Epoch: 6| Step: 3
Training loss: 2.851866990646027
Validation loss: 2.3886218310031646

Epoch: 6| Step: 4
Training loss: 2.0051780665371663
Validation loss: 2.392578002849322

Epoch: 6| Step: 5
Training loss: 1.1458491526580965
Validation loss: 2.3756607898041198

Epoch: 6| Step: 6
Training loss: 1.5919470218920178
Validation loss: 2.4093180289245004

Epoch: 6| Step: 7
Training loss: 1.8024609194049273
Validation loss: 2.3912993135642067

Epoch: 6| Step: 8
Training loss: 2.060518873847066
Validation loss: 2.3429697325339167

Epoch: 6| Step: 9
Training loss: 2.0381530838394015
Validation loss: 2.387460867581422

Epoch: 6| Step: 10
Training loss: 2.034838397196165
Validation loss: 2.400365489258496

Epoch: 6| Step: 11
Training loss: 1.6914311290435344
Validation loss: 2.415277796620856

Epoch: 6| Step: 12
Training loss: 2.1577672734033793
Validation loss: 2.408550604683544

Epoch: 6| Step: 13
Training loss: 1.7887825559456478
Validation loss: 2.4169176188501176

Epoch: 226| Step: 0
Training loss: 1.737411933149018
Validation loss: 2.406996041476509

Epoch: 6| Step: 1
Training loss: 2.1319984307703823
Validation loss: 2.4380479779858732

Epoch: 6| Step: 2
Training loss: 1.858837402587384
Validation loss: 2.408153233516447

Epoch: 6| Step: 3
Training loss: 1.7052270358890635
Validation loss: 2.407440282157911

Epoch: 6| Step: 4
Training loss: 1.294262241920903
Validation loss: 2.3413824296105905

Epoch: 6| Step: 5
Training loss: 2.233072608228538
Validation loss: 2.3949792018003335

Epoch: 6| Step: 6
Training loss: 1.2642106996100069
Validation loss: 2.358902848453095

Epoch: 6| Step: 7
Training loss: 2.8913146150050664
Validation loss: 2.365746040990187

Epoch: 6| Step: 8
Training loss: 2.1891122598594825
Validation loss: 2.3347806278287035

Epoch: 6| Step: 9
Training loss: 1.4307078071650523
Validation loss: 2.3652038428633415

Epoch: 6| Step: 10
Training loss: 2.8751784559509437
Validation loss: 2.3996881477214034

Epoch: 6| Step: 11
Training loss: 2.1184649115315506
Validation loss: 2.3938251212939172

Epoch: 6| Step: 12
Training loss: 1.9337582296678417
Validation loss: 2.3772820582257803

Epoch: 6| Step: 13
Training loss: 1.3937828983820493
Validation loss: 2.409828552932254

Epoch: 227| Step: 0
Training loss: 2.100447007696484
Validation loss: 2.422698721265206

Epoch: 6| Step: 1
Training loss: 2.5612749102057384
Validation loss: 2.3388956569723782

Epoch: 6| Step: 2
Training loss: 1.1779316852333157
Validation loss: 2.396037239574998

Epoch: 6| Step: 3
Training loss: 1.690384695070291
Validation loss: 2.360326882316064

Epoch: 6| Step: 4
Training loss: 2.1319859059209687
Validation loss: 2.4104623264314706

Epoch: 6| Step: 5
Training loss: 1.7141436492432858
Validation loss: 2.3669236716161417

Epoch: 6| Step: 6
Training loss: 1.7151971335593512
Validation loss: 2.3914994510391194

Epoch: 6| Step: 7
Training loss: 2.056480640590149
Validation loss: 2.356956925379459

Epoch: 6| Step: 8
Training loss: 1.4209703355145142
Validation loss: 2.3813317808474537

Epoch: 6| Step: 9
Training loss: 2.773741455615079
Validation loss: 2.405956078295816

Epoch: 6| Step: 10
Training loss: 2.3467180913290155
Validation loss: 2.3895424457342753

Epoch: 6| Step: 11
Training loss: 1.6696760030068978
Validation loss: 2.4524516167764974

Epoch: 6| Step: 12
Training loss: 2.476778327851514
Validation loss: 2.360357170165014

Epoch: 6| Step: 13
Training loss: 2.1953773353206727
Validation loss: 2.4189305438976976

Epoch: 228| Step: 0
Training loss: 2.404754173737598
Validation loss: 2.415862206965716

Epoch: 6| Step: 1
Training loss: 1.8397579618567579
Validation loss: 2.382399695304611

Epoch: 6| Step: 2
Training loss: 1.86430474727292
Validation loss: 2.394217260604307

Epoch: 6| Step: 3
Training loss: 1.7336327966570717
Validation loss: 2.3576650151141876

Epoch: 6| Step: 4
Training loss: 1.7621845720635159
Validation loss: 2.3626991503592705

Epoch: 6| Step: 5
Training loss: 1.7015116338071505
Validation loss: 2.3958259075918233

Epoch: 6| Step: 6
Training loss: 1.8992043033679649
Validation loss: 2.3473582089922425

Epoch: 6| Step: 7
Training loss: 2.57585719386831
Validation loss: 2.375044207547399

Epoch: 6| Step: 8
Training loss: 2.036960263523405
Validation loss: 2.3660680939290697

Epoch: 6| Step: 9
Training loss: 1.5151344370601978
Validation loss: 2.3560083914902137

Epoch: 6| Step: 10
Training loss: 2.0946864980142923
Validation loss: 2.34538791207298

Epoch: 6| Step: 11
Training loss: 2.0842393685154725
Validation loss: 2.3747954882319453

Epoch: 6| Step: 12
Training loss: 2.480721720614175
Validation loss: 2.4005697096735976

Epoch: 6| Step: 13
Training loss: 2.3432384695691035
Validation loss: 2.384597547048836

Epoch: 229| Step: 0
Training loss: 2.3687650252295978
Validation loss: 2.3735669410378875

Epoch: 6| Step: 1
Training loss: 1.6226807696675964
Validation loss: 2.374128004569508

Epoch: 6| Step: 2
Training loss: 1.6701338070241163
Validation loss: 2.3633745934901924

Epoch: 6| Step: 3
Training loss: 2.4098565952483284
Validation loss: 2.3663686405943345

Epoch: 6| Step: 4
Training loss: 2.0738927437721792
Validation loss: 2.3648811475511797

Epoch: 6| Step: 5
Training loss: 1.8667828747930177
Validation loss: 2.4366893245842753

Epoch: 6| Step: 6
Training loss: 1.7281169539362589
Validation loss: 2.387789683546076

Epoch: 6| Step: 7
Training loss: 1.735778378285007
Validation loss: 2.443714311385973

Epoch: 6| Step: 8
Training loss: 1.794525202274719
Validation loss: 2.4640504700591532

Epoch: 6| Step: 9
Training loss: 1.8489917017831474
Validation loss: 2.4079574048287493

Epoch: 6| Step: 10
Training loss: 1.9520826075772049
Validation loss: 2.4519421497907885

Epoch: 6| Step: 11
Training loss: 2.4297032003110095
Validation loss: 2.391233088193272

Epoch: 6| Step: 12
Training loss: 1.6985709523094104
Validation loss: 2.451005812332777

Epoch: 6| Step: 13
Training loss: 3.1244730695887664
Validation loss: 2.464576520660651

Epoch: 230| Step: 0
Training loss: 1.9848984155677316
Validation loss: 2.4171917896089643

Epoch: 6| Step: 1
Training loss: 1.6542354063393734
Validation loss: 2.3776219089479853

Epoch: 6| Step: 2
Training loss: 2.1219515532447075
Validation loss: 2.4176385553239093

Epoch: 6| Step: 3
Training loss: 1.7375763910639195
Validation loss: 2.400586845618724

Epoch: 6| Step: 4
Training loss: 2.0530678054530593
Validation loss: 2.360330801098587

Epoch: 6| Step: 5
Training loss: 2.3487385874699864
Validation loss: 2.3576699811014574

Epoch: 6| Step: 6
Training loss: 2.3348288057945843
Validation loss: 2.363254653210136

Epoch: 6| Step: 7
Training loss: 2.153779646480689
Validation loss: 2.3564532021338764

Epoch: 6| Step: 8
Training loss: 2.3024041713194343
Validation loss: 2.3871495802414486

Epoch: 6| Step: 9
Training loss: 2.003828199625228
Validation loss: 2.441005178539752

Epoch: 6| Step: 10
Training loss: 1.574387004181096
Validation loss: 2.3383075300821146

Epoch: 6| Step: 11
Training loss: 1.95498038094279
Validation loss: 2.416205571889145

Epoch: 6| Step: 12
Training loss: 1.8206443647827373
Validation loss: 2.447352198492747

Epoch: 6| Step: 13
Training loss: 1.7412918594050013
Validation loss: 2.3504710075177573

Epoch: 231| Step: 0
Training loss: 1.7718588907360597
Validation loss: 2.384271976745751

Epoch: 6| Step: 1
Training loss: 1.602419144945812
Validation loss: 2.3742427309484753

Epoch: 6| Step: 2
Training loss: 2.0006408856663054
Validation loss: 2.3810956240925623

Epoch: 6| Step: 3
Training loss: 2.3838438709901544
Validation loss: 2.37272128105525

Epoch: 6| Step: 4
Training loss: 1.5074980412813686
Validation loss: 2.362365459520531

Epoch: 6| Step: 5
Training loss: 1.844414672011238
Validation loss: 2.3743308894498276

Epoch: 6| Step: 6
Training loss: 1.8804428574253764
Validation loss: 2.430882318176746

Epoch: 6| Step: 7
Training loss: 1.4459044198068698
Validation loss: 2.429405405733786

Epoch: 6| Step: 8
Training loss: 2.8740951109182182
Validation loss: 2.3752533734867356

Epoch: 6| Step: 9
Training loss: 2.101797324749399
Validation loss: 2.421417566262788

Epoch: 6| Step: 10
Training loss: 2.3064327550083146
Validation loss: 2.4331819040337535

Epoch: 6| Step: 11
Training loss: 1.9084410660608735
Validation loss: 2.4474084683114503

Epoch: 6| Step: 12
Training loss: 2.5674414092958844
Validation loss: 2.4120975946626375

Epoch: 6| Step: 13
Training loss: 1.0963401098852827
Validation loss: 2.416738193657131

Epoch: 232| Step: 0
Training loss: 2.279002506497433
Validation loss: 2.4020615790902293

Epoch: 6| Step: 1
Training loss: 2.7386430835965196
Validation loss: 2.3670291355578366

Epoch: 6| Step: 2
Training loss: 1.3419027717036933
Validation loss: 2.376173389078007

Epoch: 6| Step: 3
Training loss: 1.9396623419852042
Validation loss: 2.3616285877390015

Epoch: 6| Step: 4
Training loss: 2.2152185408891207
Validation loss: 2.3456151463415758

Epoch: 6| Step: 5
Training loss: 1.7563747375283925
Validation loss: 2.357680340919705

Epoch: 6| Step: 6
Training loss: 2.0411456345031387
Validation loss: 2.409404401298

Epoch: 6| Step: 7
Training loss: 1.6185864281214866
Validation loss: 2.3841058597593388

Epoch: 6| Step: 8
Training loss: 2.0601268177439924
Validation loss: 2.3943216128067886

Epoch: 6| Step: 9
Training loss: 2.0454056685802104
Validation loss: 2.3505935763229626

Epoch: 6| Step: 10
Training loss: 1.8679936795423862
Validation loss: 2.3416666327207802

Epoch: 6| Step: 11
Training loss: 2.0631626105152203
Validation loss: 2.399995982707671

Epoch: 6| Step: 12
Training loss: 1.7537389050959993
Validation loss: 2.3465458864208717

Epoch: 6| Step: 13
Training loss: 2.3849390765072225
Validation loss: 2.41526668398718

Epoch: 233| Step: 0
Training loss: 2.179939392192267
Validation loss: 2.4097765471891015

Epoch: 6| Step: 1
Training loss: 1.9830631515519652
Validation loss: 2.3358213904987397

Epoch: 6| Step: 2
Training loss: 1.6556452240794124
Validation loss: 2.3788064656591166

Epoch: 6| Step: 3
Training loss: 1.7157589636024784
Validation loss: 2.3941124883790126

Epoch: 6| Step: 4
Training loss: 2.4859755056989807
Validation loss: 2.360282735825649

Epoch: 6| Step: 5
Training loss: 1.7935061511659276
Validation loss: 2.4167382954925287

Epoch: 6| Step: 6
Training loss: 1.905243780002069
Validation loss: 2.3498533327496522

Epoch: 6| Step: 7
Training loss: 2.410910316852994
Validation loss: 2.4015469951688093

Epoch: 6| Step: 8
Training loss: 1.89453911533886
Validation loss: 2.382047510832686

Epoch: 6| Step: 9
Training loss: 1.6884005933784503
Validation loss: 2.3940790017608946

Epoch: 6| Step: 10
Training loss: 2.054334022663394
Validation loss: 2.415492994506346

Epoch: 6| Step: 11
Training loss: 2.14891618424422
Validation loss: 2.3950054077509386

Epoch: 6| Step: 12
Training loss: 1.8730179801358964
Validation loss: 2.4171902952423245

Epoch: 6| Step: 13
Training loss: 2.0523143451095835
Validation loss: 2.390412134222515

Epoch: 234| Step: 0
Training loss: 1.731950732378374
Validation loss: 2.4214848357912633

Epoch: 6| Step: 1
Training loss: 1.7954488651023357
Validation loss: 2.3879401137783245

Epoch: 6| Step: 2
Training loss: 1.9000844836274715
Validation loss: 2.415767177848702

Epoch: 6| Step: 3
Training loss: 2.1526654067159354
Validation loss: 2.3926406535419495

Epoch: 6| Step: 4
Training loss: 2.049972403735987
Validation loss: 2.4297682521180994

Epoch: 6| Step: 5
Training loss: 1.5274795510879022
Validation loss: 2.4156220495920775

Epoch: 6| Step: 6
Training loss: 2.00577510073543
Validation loss: 2.4120075514051122

Epoch: 6| Step: 7
Training loss: 1.9943774584280156
Validation loss: 2.3774850341040135

Epoch: 6| Step: 8
Training loss: 1.9172390483961743
Validation loss: 2.384012841923112

Epoch: 6| Step: 9
Training loss: 1.6186673677187369
Validation loss: 2.366584999250279

Epoch: 6| Step: 10
Training loss: 1.9602254357411015
Validation loss: 2.4051381091065216

Epoch: 6| Step: 11
Training loss: 2.845262565363157
Validation loss: 2.3640769623021645

Epoch: 6| Step: 12
Training loss: 1.8546171462639691
Validation loss: 2.3580961857453944

Epoch: 6| Step: 13
Training loss: 1.671601602892485
Validation loss: 2.4005459053937814

Epoch: 235| Step: 0
Training loss: 1.5494902880186712
Validation loss: 2.372339927546198

Epoch: 6| Step: 1
Training loss: 2.0574731545533624
Validation loss: 2.4136471949806664

Epoch: 6| Step: 2
Training loss: 1.4870962797189053
Validation loss: 2.356316185074433

Epoch: 6| Step: 3
Training loss: 2.543252439833153
Validation loss: 2.352584819964829

Epoch: 6| Step: 4
Training loss: 2.4577676370046304
Validation loss: 2.3906038205482516

Epoch: 6| Step: 5
Training loss: 1.331213109754465
Validation loss: 2.381070575366043

Epoch: 6| Step: 6
Training loss: 1.9728666589905397
Validation loss: 2.3975327345027093

Epoch: 6| Step: 7
Training loss: 2.4789396123267102
Validation loss: 2.4061137633476846

Epoch: 6| Step: 8
Training loss: 1.6823798314977567
Validation loss: 2.385704187272533

Epoch: 6| Step: 9
Training loss: 2.371244975614076
Validation loss: 2.4055879686586823

Epoch: 6| Step: 10
Training loss: 1.4067924301069614
Validation loss: 2.4238952456609497

Epoch: 6| Step: 11
Training loss: 2.0565351294316434
Validation loss: 2.3951804060974364

Epoch: 6| Step: 12
Training loss: 1.6695901106159052
Validation loss: 2.404823599596006

Epoch: 6| Step: 13
Training loss: 1.6170007717670964
Validation loss: 2.3936943025228983

Epoch: 236| Step: 0
Training loss: 1.1085398041904813
Validation loss: 2.4124335136435464

Epoch: 6| Step: 1
Training loss: 1.7272423143766604
Validation loss: 2.4411562792056785

Epoch: 6| Step: 2
Training loss: 1.878067812945521
Validation loss: 2.362558644475078

Epoch: 6| Step: 3
Training loss: 1.911318310451822
Validation loss: 2.4212666647602474

Epoch: 6| Step: 4
Training loss: 2.763799204774385
Validation loss: 2.366456966766475

Epoch: 6| Step: 5
Training loss: 2.565498551517926
Validation loss: 2.350158061609577

Epoch: 6| Step: 6
Training loss: 1.5708361459533173
Validation loss: 2.3761624091423057

Epoch: 6| Step: 7
Training loss: 2.1610421266417084
Validation loss: 2.4127648679728084

Epoch: 6| Step: 8
Training loss: 1.9407808766442622
Validation loss: 2.3628314231610443

Epoch: 6| Step: 9
Training loss: 2.21865146042048
Validation loss: 2.3170242369218217

Epoch: 6| Step: 10
Training loss: 1.322095130285094
Validation loss: 2.361725333361631

Epoch: 6| Step: 11
Training loss: 2.1205611148546266
Validation loss: 2.3337785813135783

Epoch: 6| Step: 12
Training loss: 2.03148626273954
Validation loss: 2.3735644746754136

Epoch: 6| Step: 13
Training loss: 1.7788077225370156
Validation loss: 2.378060698102423

Epoch: 237| Step: 0
Training loss: 1.7297132922612617
Validation loss: 2.40347759075892

Epoch: 6| Step: 1
Training loss: 1.9495073918928654
Validation loss: 2.4207760723508396

Epoch: 6| Step: 2
Training loss: 1.8266304623480314
Validation loss: 2.404688268275168

Epoch: 6| Step: 3
Training loss: 2.1685044735050303
Validation loss: 2.423924154324292

Epoch: 6| Step: 4
Training loss: 1.6564048838621028
Validation loss: 2.394490160200844

Epoch: 6| Step: 5
Training loss: 1.792528019344266
Validation loss: 2.3835893397179637

Epoch: 6| Step: 6
Training loss: 2.201869742273252
Validation loss: 2.33129696900826

Epoch: 6| Step: 7
Training loss: 1.537835886172212
Validation loss: 2.4408267037264695

Epoch: 6| Step: 8
Training loss: 1.7672371719894184
Validation loss: 2.4016209773393604

Epoch: 6| Step: 9
Training loss: 2.3938009072410975
Validation loss: 2.362947909885215

Epoch: 6| Step: 10
Training loss: 2.006607465895181
Validation loss: 2.374500154594938

Epoch: 6| Step: 11
Training loss: 1.8598607815149584
Validation loss: 2.434853136075303

Epoch: 6| Step: 12
Training loss: 1.7430975893313079
Validation loss: 2.3914265070175844

Epoch: 6| Step: 13
Training loss: 2.835370472109655
Validation loss: 2.4056925251035524

Epoch: 238| Step: 0
Training loss: 1.759262165360904
Validation loss: 2.4071050871070243

Epoch: 6| Step: 1
Training loss: 1.9669280325713348
Validation loss: 2.452979374096646

Epoch: 6| Step: 2
Training loss: 2.635583432516345
Validation loss: 2.4039305145946828

Epoch: 6| Step: 3
Training loss: 1.6606889655414092
Validation loss: 2.3775357082432835

Epoch: 6| Step: 4
Training loss: 1.9159478069595006
Validation loss: 2.366992297064316

Epoch: 6| Step: 5
Training loss: 1.7884453121203316
Validation loss: 2.393523659762335

Epoch: 6| Step: 6
Training loss: 1.7787565212706573
Validation loss: 2.3583093377233326

Epoch: 6| Step: 7
Training loss: 1.4172078763092066
Validation loss: 2.3795432022656438

Epoch: 6| Step: 8
Training loss: 1.6314517835435982
Validation loss: 2.3835372331023117

Epoch: 6| Step: 9
Training loss: 2.5486994100641462
Validation loss: 2.3630323601188117

Epoch: 6| Step: 10
Training loss: 1.4438068692455173
Validation loss: 2.4277221065852728

Epoch: 6| Step: 11
Training loss: 2.2309570846841478
Validation loss: 2.3672719424812168

Epoch: 6| Step: 12
Training loss: 2.2917624944822976
Validation loss: 2.368147685725161

Epoch: 6| Step: 13
Training loss: 1.8387797978603995
Validation loss: 2.428042530737097

Epoch: 239| Step: 0
Training loss: 1.9665114982728567
Validation loss: 2.40435105073466

Epoch: 6| Step: 1
Training loss: 1.6155980356943533
Validation loss: 2.405618938301073

Epoch: 6| Step: 2
Training loss: 2.1895871695627953
Validation loss: 2.366026105668601

Epoch: 6| Step: 3
Training loss: 1.7476108454747783
Validation loss: 2.4166654438981756

Epoch: 6| Step: 4
Training loss: 1.771513310945801
Validation loss: 2.369022257913767

Epoch: 6| Step: 5
Training loss: 1.6020388011257718
Validation loss: 2.4304642936656276

Epoch: 6| Step: 6
Training loss: 1.7796658615926915
Validation loss: 2.3897306917063026

Epoch: 6| Step: 7
Training loss: 2.181930645659541
Validation loss: 2.373711862200747

Epoch: 6| Step: 8
Training loss: 1.3701217118376832
Validation loss: 2.4031034474105333

Epoch: 6| Step: 9
Training loss: 1.762123078428483
Validation loss: 2.4015608848464773

Epoch: 6| Step: 10
Training loss: 1.92516138960805
Validation loss: 2.37360557138155

Epoch: 6| Step: 11
Training loss: 1.7537732997877291
Validation loss: 2.425270309327029

Epoch: 6| Step: 12
Training loss: 2.162557250571534
Validation loss: 2.3869118306013486

Epoch: 6| Step: 13
Training loss: 3.3936575411571557
Validation loss: 2.346832836967372

Epoch: 240| Step: 0
Training loss: 1.5038935673166522
Validation loss: 2.410622428584625

Epoch: 6| Step: 1
Training loss: 2.045486794805131
Validation loss: 2.365914426076236

Epoch: 6| Step: 2
Training loss: 1.9171238920545985
Validation loss: 2.34776283224105

Epoch: 6| Step: 3
Training loss: 2.5473667910323003
Validation loss: 2.3838014596919517

Epoch: 6| Step: 4
Training loss: 2.016914605696623
Validation loss: 2.3511293030164313

Epoch: 6| Step: 5
Training loss: 2.212338061252309
Validation loss: 2.3607857798725673

Epoch: 6| Step: 6
Training loss: 2.151748159427948
Validation loss: 2.3849662801226117

Epoch: 6| Step: 7
Training loss: 2.0158520947650773
Validation loss: 2.3944901741191837

Epoch: 6| Step: 8
Training loss: 1.6665769393927696
Validation loss: 2.3611543211902926

Epoch: 6| Step: 9
Training loss: 1.6223322905398712
Validation loss: 2.3873452515530196

Epoch: 6| Step: 10
Training loss: 1.8332546679641388
Validation loss: 2.3988790893532483

Epoch: 6| Step: 11
Training loss: 1.6767757283732725
Validation loss: 2.330152614326943

Epoch: 6| Step: 12
Training loss: 1.7419751640896888
Validation loss: 2.3579430252554117

Epoch: 6| Step: 13
Training loss: 1.5169241145245447
Validation loss: 2.3883823441367253

Epoch: 241| Step: 0
Training loss: 2.2360113594230673
Validation loss: 2.385944020318755

Epoch: 6| Step: 1
Training loss: 1.6833330204777694
Validation loss: 2.3900644174725465

Epoch: 6| Step: 2
Training loss: 2.3093316307692975
Validation loss: 2.405457073942243

Epoch: 6| Step: 3
Training loss: 1.7729201717618488
Validation loss: 2.3978677762200973

Epoch: 6| Step: 4
Training loss: 2.355031240138612
Validation loss: 2.422007321260298

Epoch: 6| Step: 5
Training loss: 1.8202525116691346
Validation loss: 2.3865243228253403

Epoch: 6| Step: 6
Training loss: 1.8859055308592962
Validation loss: 2.394749653590023

Epoch: 6| Step: 7
Training loss: 1.548318747885299
Validation loss: 2.406560326200711

Epoch: 6| Step: 8
Training loss: 1.9643309513679397
Validation loss: 2.374885450535685

Epoch: 6| Step: 9
Training loss: 1.9520245923541213
Validation loss: 2.3897734188346864

Epoch: 6| Step: 10
Training loss: 1.4696418002707003
Validation loss: 2.3893296659140186

Epoch: 6| Step: 11
Training loss: 1.9086994630609888
Validation loss: 2.414110988660025

Epoch: 6| Step: 12
Training loss: 2.2830640295259
Validation loss: 2.458246171830283

Epoch: 6| Step: 13
Training loss: 1.4846172737369552
Validation loss: 2.446796922678663

Epoch: 242| Step: 0
Training loss: 1.7504073077724016
Validation loss: 2.4163412597096743

Epoch: 6| Step: 1
Training loss: 1.7366106899756195
Validation loss: 2.3801429963776792

Epoch: 6| Step: 2
Training loss: 2.0345008072869066
Validation loss: 2.4108667382638873

Epoch: 6| Step: 3
Training loss: 1.6328766732632567
Validation loss: 2.4362624681456446

Epoch: 6| Step: 4
Training loss: 2.655158413257749
Validation loss: 2.3912654187538407

Epoch: 6| Step: 5
Training loss: 2.06971357787342
Validation loss: 2.378060573049971

Epoch: 6| Step: 6
Training loss: 1.434444746594767
Validation loss: 2.373731549143497

Epoch: 6| Step: 7
Training loss: 1.9499716365414241
Validation loss: 2.3731293189678357

Epoch: 6| Step: 8
Training loss: 2.098811053716575
Validation loss: 2.4197482284195417

Epoch: 6| Step: 9
Training loss: 1.5890773266125924
Validation loss: 2.3703304427910443

Epoch: 6| Step: 10
Training loss: 1.9863890992054862
Validation loss: 2.386527638925272

Epoch: 6| Step: 11
Training loss: 1.5849812448156086
Validation loss: 2.3690857533754874

Epoch: 6| Step: 12
Training loss: 2.4354149141025245
Validation loss: 2.3978321919876233

Epoch: 6| Step: 13
Training loss: 1.4414147684315954
Validation loss: 2.379108650895647

Epoch: 243| Step: 0
Training loss: 1.9482580351603256
Validation loss: 2.3833324772134565

Epoch: 6| Step: 1
Training loss: 1.2833720985766954
Validation loss: 2.384282627949833

Epoch: 6| Step: 2
Training loss: 2.3481021400539057
Validation loss: 2.417032778090317

Epoch: 6| Step: 3
Training loss: 2.43720869622256
Validation loss: 2.4131685943489862

Epoch: 6| Step: 4
Training loss: 2.370069807449012
Validation loss: 2.42833970804977

Epoch: 6| Step: 5
Training loss: 2.065188764945514
Validation loss: 2.4336184161306025

Epoch: 6| Step: 6
Training loss: 1.80046201180784
Validation loss: 2.3354732040893547

Epoch: 6| Step: 7
Training loss: 2.240827194305708
Validation loss: 2.3398951308544893

Epoch: 6| Step: 8
Training loss: 1.6981701651903518
Validation loss: 2.3968967946994613

Epoch: 6| Step: 9
Training loss: 1.6806590264714278
Validation loss: 2.3683139283290773

Epoch: 6| Step: 10
Training loss: 2.0918148834279675
Validation loss: 2.37537593057553

Epoch: 6| Step: 11
Training loss: 1.679558043703155
Validation loss: 2.401865496027657

Epoch: 6| Step: 12
Training loss: 1.37268044152434
Validation loss: 2.3427489354390127

Epoch: 6| Step: 13
Training loss: 1.0919632622823519
Validation loss: 2.404909603050599

Epoch: 244| Step: 0
Training loss: 1.713273287301057
Validation loss: 2.3706814092373825

Epoch: 6| Step: 1
Training loss: 1.9119576227368005
Validation loss: 2.3412352318836667

Epoch: 6| Step: 2
Training loss: 3.1383554029642564
Validation loss: 2.370112320063585

Epoch: 6| Step: 3
Training loss: 2.0309851840599658
Validation loss: 2.379108829771181

Epoch: 6| Step: 4
Training loss: 1.390595425066259
Validation loss: 2.3909477891559243

Epoch: 6| Step: 5
Training loss: 1.5670277416156881
Validation loss: 2.4057760039480054

Epoch: 6| Step: 6
Training loss: 1.6253132151473955
Validation loss: 2.374035995294346

Epoch: 6| Step: 7
Training loss: 1.769804876531555
Validation loss: 2.4214943503638047

Epoch: 6| Step: 8
Training loss: 1.624323410618127
Validation loss: 2.411939976631657

Epoch: 6| Step: 9
Training loss: 2.0828118498129378
Validation loss: 2.411752957133755

Epoch: 6| Step: 10
Training loss: 1.6226857652399624
Validation loss: 2.4279558700467043

Epoch: 6| Step: 11
Training loss: 2.003494071584203
Validation loss: 2.385240534246169

Epoch: 6| Step: 12
Training loss: 2.332014994348966
Validation loss: 2.3998906888303133

Epoch: 6| Step: 13
Training loss: 2.0223210027111405
Validation loss: 2.4396771152165893

Epoch: 245| Step: 0
Training loss: 1.3313296083816226
Validation loss: 2.395035407978016

Epoch: 6| Step: 1
Training loss: 1.4441848067112701
Validation loss: 2.4105862445839334

Epoch: 6| Step: 2
Training loss: 1.6824511126689525
Validation loss: 2.3539485287657738

Epoch: 6| Step: 3
Training loss: 2.2652665479506293
Validation loss: 2.3875162424845997

Epoch: 6| Step: 4
Training loss: 1.7139282563461085
Validation loss: 2.377099113940071

Epoch: 6| Step: 5
Training loss: 2.099187366746477
Validation loss: 2.390638569227595

Epoch: 6| Step: 6
Training loss: 2.074980227824308
Validation loss: 2.376501162162195

Epoch: 6| Step: 7
Training loss: 2.2222478454490138
Validation loss: 2.3828348923627383

Epoch: 6| Step: 8
Training loss: 1.3347389243081331
Validation loss: 2.4122839880538844

Epoch: 6| Step: 9
Training loss: 1.977360500233096
Validation loss: 2.379215572155454

Epoch: 6| Step: 10
Training loss: 1.9830595447258932
Validation loss: 2.426061122842706

Epoch: 6| Step: 11
Training loss: 1.947195222092709
Validation loss: 2.373447990538765

Epoch: 6| Step: 12
Training loss: 2.7167100817091807
Validation loss: 2.3621014295446905

Epoch: 6| Step: 13
Training loss: 0.8440546262925359
Validation loss: 2.439202736488153

Epoch: 246| Step: 0
Training loss: 2.0379036719979613
Validation loss: 2.3915889307884717

Epoch: 6| Step: 1
Training loss: 1.4369199660650356
Validation loss: 2.374928547292223

Epoch: 6| Step: 2
Training loss: 1.8865142142748383
Validation loss: 2.396461281112437

Epoch: 6| Step: 3
Training loss: 1.5290399289253525
Validation loss: 2.418118049170707

Epoch: 6| Step: 4
Training loss: 2.0130619046527385
Validation loss: 2.392215792233709

Epoch: 6| Step: 5
Training loss: 1.9141600292037035
Validation loss: 2.380139298168381

Epoch: 6| Step: 6
Training loss: 1.9857302865994073
Validation loss: 2.4026139563665874

Epoch: 6| Step: 7
Training loss: 1.936020132153243
Validation loss: 2.439896046686645

Epoch: 6| Step: 8
Training loss: 1.9934034040291664
Validation loss: 2.3814226459513197

Epoch: 6| Step: 9
Training loss: 1.4803118861694222
Validation loss: 2.4105967422965415

Epoch: 6| Step: 10
Training loss: 1.7416477479165746
Validation loss: 2.3386859770250394

Epoch: 6| Step: 11
Training loss: 2.6170554056566813
Validation loss: 2.3955910421503885

Epoch: 6| Step: 12
Training loss: 1.4777134844689603
Validation loss: 2.435829242081218

Epoch: 6| Step: 13
Training loss: 2.9496785392831235
Validation loss: 2.423527843024617

Epoch: 247| Step: 0
Training loss: 1.7946455683684321
Validation loss: 2.3644308647563954

Epoch: 6| Step: 1
Training loss: 2.2790706100539255
Validation loss: 2.415779957458003

Epoch: 6| Step: 2
Training loss: 1.952186236795597
Validation loss: 2.39488237687853

Epoch: 6| Step: 3
Training loss: 2.047573756565125
Validation loss: 2.372597161633433

Epoch: 6| Step: 4
Training loss: 2.0528514476605726
Validation loss: 2.3993243427408824

Epoch: 6| Step: 5
Training loss: 2.1778814018123454
Validation loss: 2.3670256730042993

Epoch: 6| Step: 6
Training loss: 1.6256944932937163
Validation loss: 2.401019367049244

Epoch: 6| Step: 7
Training loss: 1.9182550096251292
Validation loss: 2.35967528881045

Epoch: 6| Step: 8
Training loss: 1.9505248806091884
Validation loss: 2.3407983056689736

Epoch: 6| Step: 9
Training loss: 1.4843994941698229
Validation loss: 2.3526404807213934

Epoch: 6| Step: 10
Training loss: 1.6485503099358687
Validation loss: 2.414427617117248

Epoch: 6| Step: 11
Training loss: 1.4378814191246325
Validation loss: 2.381272592056001

Epoch: 6| Step: 12
Training loss: 2.0002679645316626
Validation loss: 2.348179460627451

Epoch: 6| Step: 13
Training loss: 1.8682098781872176
Validation loss: 2.3715927324203068

Epoch: 248| Step: 0
Training loss: 1.8886909365555034
Validation loss: 2.3830935539235325

Epoch: 6| Step: 1
Training loss: 2.7115020603831215
Validation loss: 2.3639227930363673

Epoch: 6| Step: 2
Training loss: 2.071232659607464
Validation loss: 2.3481651411030433

Epoch: 6| Step: 3
Training loss: 2.0940303330141843
Validation loss: 2.3872837054362153

Epoch: 6| Step: 4
Training loss: 1.7443533123749773
Validation loss: 2.4099667390313466

Epoch: 6| Step: 5
Training loss: 1.730066050222278
Validation loss: 2.397731407578931

Epoch: 6| Step: 6
Training loss: 1.4948856266631902
Validation loss: 2.388065981072754

Epoch: 6| Step: 7
Training loss: 1.7235763756695301
Validation loss: 2.404022273355457

Epoch: 6| Step: 8
Training loss: 1.711616416250491
Validation loss: 2.3712868725453897

Epoch: 6| Step: 9
Training loss: 1.8892397258661409
Validation loss: 2.3971472698199197

Epoch: 6| Step: 10
Training loss: 1.856927109856712
Validation loss: 2.413295345853282

Epoch: 6| Step: 11
Training loss: 1.6385437616365996
Validation loss: 2.361929797000868

Epoch: 6| Step: 12
Training loss: 1.7788002837010803
Validation loss: 2.3929265922843967

Epoch: 6| Step: 13
Training loss: 1.9567529172045834
Validation loss: 2.390754536950202

Epoch: 249| Step: 0
Training loss: 1.6337680484676667
Validation loss: 2.4126336708848095

Epoch: 6| Step: 1
Training loss: 1.47361922210433
Validation loss: 2.4062505753208425

Epoch: 6| Step: 2
Training loss: 1.6795909765144226
Validation loss: 2.3506641219265054

Epoch: 6| Step: 3
Training loss: 1.621504913030916
Validation loss: 2.3965399896194386

Epoch: 6| Step: 4
Training loss: 1.6606622620387237
Validation loss: 2.416817734281995

Epoch: 6| Step: 5
Training loss: 2.094548770499735
Validation loss: 2.452244475368043

Epoch: 6| Step: 6
Training loss: 2.0845200655441065
Validation loss: 2.3946963782945603

Epoch: 6| Step: 7
Training loss: 2.0711277921879874
Validation loss: 2.416385120445489

Epoch: 6| Step: 8
Training loss: 2.0450088497054324
Validation loss: 2.40925440626325

Epoch: 6| Step: 9
Training loss: 1.4321923331292123
Validation loss: 2.411448964498737

Epoch: 6| Step: 10
Training loss: 1.8612867512863018
Validation loss: 2.405799072357662

Epoch: 6| Step: 11
Training loss: 2.0044418124942647
Validation loss: 2.39214859502808

Epoch: 6| Step: 12
Training loss: 2.5266193371703976
Validation loss: 2.3816237920893886

Epoch: 6| Step: 13
Training loss: 2.2252181428420994
Validation loss: 2.3557811357067253

Epoch: 250| Step: 0
Training loss: 1.869347699373162
Validation loss: 2.4292362056345933

Epoch: 6| Step: 1
Training loss: 1.843011999330252
Validation loss: 2.3967611890771368

Epoch: 6| Step: 2
Training loss: 1.8209245823300018
Validation loss: 2.409682351010525

Epoch: 6| Step: 3
Training loss: 1.8650047919899584
Validation loss: 2.4165788891996436

Epoch: 6| Step: 4
Training loss: 2.57789916003025
Validation loss: 2.3562575244541337

Epoch: 6| Step: 5
Training loss: 1.7938866353912601
Validation loss: 2.3939020584557986

Epoch: 6| Step: 6
Training loss: 2.179888097358301
Validation loss: 2.3413111992072704

Epoch: 6| Step: 7
Training loss: 1.7522499743067157
Validation loss: 2.3629618691369902

Epoch: 6| Step: 8
Training loss: 2.0255750757907727
Validation loss: 2.3935744045619596

Epoch: 6| Step: 9
Training loss: 1.693696970654952
Validation loss: 2.4136816485584642

Epoch: 6| Step: 10
Training loss: 1.6730067620377314
Validation loss: 2.393127114298001

Epoch: 6| Step: 11
Training loss: 1.3823524183861957
Validation loss: 2.3811881174488208

Epoch: 6| Step: 12
Training loss: 1.918593668082955
Validation loss: 2.384502497053454

Epoch: 6| Step: 13
Training loss: 1.5289866009680861
Validation loss: 2.4229976469498795

Epoch: 251| Step: 0
Training loss: 1.815816607188896
Validation loss: 2.395268627740764

Epoch: 6| Step: 1
Training loss: 1.6983512681058384
Validation loss: 2.382917921833111

Epoch: 6| Step: 2
Training loss: 1.7453822109196668
Validation loss: 2.376424707521024

Epoch: 6| Step: 3
Training loss: 1.2733187005731794
Validation loss: 2.400646426409838

Epoch: 6| Step: 4
Training loss: 1.48620829556588
Validation loss: 2.35846055804894

Epoch: 6| Step: 5
Training loss: 1.9030185262526969
Validation loss: 2.4060435244473886

Epoch: 6| Step: 6
Training loss: 1.8258444099780906
Validation loss: 2.4603021846302564

Epoch: 6| Step: 7
Training loss: 2.058992582481033
Validation loss: 2.3681674681794322

Epoch: 6| Step: 8
Training loss: 2.2744245451132414
Validation loss: 2.3715158400956824

Epoch: 6| Step: 9
Training loss: 2.0252931547484425
Validation loss: 2.375239658623316

Epoch: 6| Step: 10
Training loss: 1.821459887473118
Validation loss: 2.4005844897805972

Epoch: 6| Step: 11
Training loss: 2.524966883678254
Validation loss: 2.3928760255209847

Epoch: 6| Step: 12
Training loss: 2.118902546390143
Validation loss: 2.4177940268813627

Epoch: 6| Step: 13
Training loss: 2.144858191188601
Validation loss: 2.4335540023984317

Epoch: 252| Step: 0
Training loss: 1.3034976856253577
Validation loss: 2.39306212702413

Epoch: 6| Step: 1
Training loss: 1.8164873002540516
Validation loss: 2.3867280245372946

Epoch: 6| Step: 2
Training loss: 2.0367865594682635
Validation loss: 2.3883948559520416

Epoch: 6| Step: 3
Training loss: 2.4850038896065865
Validation loss: 2.4405569848692266

Epoch: 6| Step: 4
Training loss: 1.3801940005535902
Validation loss: 2.4209400194229533

Epoch: 6| Step: 5
Training loss: 1.9089123628981672
Validation loss: 2.3870116777877985

Epoch: 6| Step: 6
Training loss: 1.8986408140470858
Validation loss: 2.3557317484190317

Epoch: 6| Step: 7
Training loss: 1.7586584471601359
Validation loss: 2.3925173789125753

Epoch: 6| Step: 8
Training loss: 2.3312527940339636
Validation loss: 2.4382626287315303

Epoch: 6| Step: 9
Training loss: 1.5523383253259049
Validation loss: 2.3958743908232276

Epoch: 6| Step: 10
Training loss: 1.9245539656278203
Validation loss: 2.3706910174035407

Epoch: 6| Step: 11
Training loss: 1.74176088592382
Validation loss: 2.3866787319642606

Epoch: 6| Step: 12
Training loss: 2.0847496050683207
Validation loss: 2.417971057093242

Epoch: 6| Step: 13
Training loss: 1.4815433195683372
Validation loss: 2.3456647919878635

Epoch: 253| Step: 0
Training loss: 1.6894667431938495
Validation loss: 2.387106931801148

Epoch: 6| Step: 1
Training loss: 1.426071179318861
Validation loss: 2.3724663663853227

Epoch: 6| Step: 2
Training loss: 1.9675048644843065
Validation loss: 2.3398732522760386

Epoch: 6| Step: 3
Training loss: 1.1061201568956167
Validation loss: 2.3715288846496954

Epoch: 6| Step: 4
Training loss: 1.7135949247329594
Validation loss: 2.354319185729844

Epoch: 6| Step: 5
Training loss: 2.0625629993411647
Validation loss: 2.445144052557289

Epoch: 6| Step: 6
Training loss: 1.7185817982993066
Validation loss: 2.392907413058955

Epoch: 6| Step: 7
Training loss: 2.156174810453091
Validation loss: 2.3935032246568446

Epoch: 6| Step: 8
Training loss: 1.5639233781675272
Validation loss: 2.408433659286214

Epoch: 6| Step: 9
Training loss: 1.6470785460373183
Validation loss: 2.338752075160367

Epoch: 6| Step: 10
Training loss: 2.499111876091179
Validation loss: 2.4289904938873277

Epoch: 6| Step: 11
Training loss: 2.3113505625574557
Validation loss: 2.4262676605066895

Epoch: 6| Step: 12
Training loss: 1.8521307865867784
Validation loss: 2.3478059453240467

Epoch: 6| Step: 13
Training loss: 1.8223361444269583
Validation loss: 2.4098397081961633

Epoch: 254| Step: 0
Training loss: 1.7624535899443603
Validation loss: 2.4090084527827456

Epoch: 6| Step: 1
Training loss: 1.5730585030106297
Validation loss: 2.3249346885015814

Epoch: 6| Step: 2
Training loss: 2.0594224799880965
Validation loss: 2.33363808965079

Epoch: 6| Step: 3
Training loss: 1.516928279586997
Validation loss: 2.3780769316875356

Epoch: 6| Step: 4
Training loss: 1.916160585789575
Validation loss: 2.360038923602507

Epoch: 6| Step: 5
Training loss: 1.879300589628162
Validation loss: 2.407405228105913

Epoch: 6| Step: 6
Training loss: 2.4408268843809062
Validation loss: 2.4529453836510093

Epoch: 6| Step: 7
Training loss: 1.8139527516841245
Validation loss: 2.3929545337687976

Epoch: 6| Step: 8
Training loss: 1.282219031864548
Validation loss: 2.3818627896206896

Epoch: 6| Step: 9
Training loss: 1.8445657768071764
Validation loss: 2.400219186221832

Epoch: 6| Step: 10
Training loss: 1.7927523214324914
Validation loss: 2.413403479069924

Epoch: 6| Step: 11
Training loss: 1.574678339733772
Validation loss: 2.382911769628805

Epoch: 6| Step: 12
Training loss: 2.3700522031547555
Validation loss: 2.375059132468619

Epoch: 6| Step: 13
Training loss: 1.4097803941113192
Validation loss: 2.389933935091473

Epoch: 255| Step: 0
Training loss: 1.4464178034467376
Validation loss: 2.365475058794518

Epoch: 6| Step: 1
Training loss: 2.2750114943664594
Validation loss: 2.3853967449687032

Epoch: 6| Step: 2
Training loss: 1.795579924557081
Validation loss: 2.406272316488128

Epoch: 6| Step: 3
Training loss: 1.810160014313664
Validation loss: 2.4201492930642714

Epoch: 6| Step: 4
Training loss: 1.2315374184149817
Validation loss: 2.3772022580762266

Epoch: 6| Step: 5
Training loss: 1.6808754202333756
Validation loss: 2.41010251004178

Epoch: 6| Step: 6
Training loss: 1.55961181738271
Validation loss: 2.4348638787222883

Epoch: 6| Step: 7
Training loss: 1.8401468274371748
Validation loss: 2.3945406575473074

Epoch: 6| Step: 8
Training loss: 2.3482291590495685
Validation loss: 2.3411763565526775

Epoch: 6| Step: 9
Training loss: 2.2052303562377027
Validation loss: 2.366287037979202

Epoch: 6| Step: 10
Training loss: 2.3684787564749334
Validation loss: 2.4230698648537494

Epoch: 6| Step: 11
Training loss: 1.5519227407780698
Validation loss: 2.3919344056045104

Epoch: 6| Step: 12
Training loss: 1.5809144399076738
Validation loss: 2.438771904401568

Epoch: 6| Step: 13
Training loss: 2.5906311035084353
Validation loss: 2.386779888563566

Epoch: 256| Step: 0
Training loss: 1.6805851866296582
Validation loss: 2.315288112322938

Epoch: 6| Step: 1
Training loss: 1.4440067475813771
Validation loss: 2.4066644862144684

Epoch: 6| Step: 2
Training loss: 2.4943251097222117
Validation loss: 2.3588964830941017

Epoch: 6| Step: 3
Training loss: 2.1929256183553423
Validation loss: 2.3358062598622906

Epoch: 6| Step: 4
Training loss: 2.1160458798329165
Validation loss: 2.3944470739856567

Epoch: 6| Step: 5
Training loss: 2.034391116592627
Validation loss: 2.44655923972291

Epoch: 6| Step: 6
Training loss: 1.8655113453966092
Validation loss: 2.425563970627075

Epoch: 6| Step: 7
Training loss: 1.5399867347046878
Validation loss: 2.3926619274672474

Epoch: 6| Step: 8
Training loss: 1.709343851701825
Validation loss: 2.363552072089831

Epoch: 6| Step: 9
Training loss: 2.0761027427783474
Validation loss: 2.4395676208339263

Epoch: 6| Step: 10
Training loss: 1.841518603568318
Validation loss: 2.383769508628416

Epoch: 6| Step: 11
Training loss: 1.6400161339966406
Validation loss: 2.435754210238823

Epoch: 6| Step: 12
Training loss: 1.4764058670849263
Validation loss: 2.3470279208420926

Epoch: 6| Step: 13
Training loss: 1.4215423697947607
Validation loss: 2.383767107132633

Epoch: 257| Step: 0
Training loss: 1.814198585945548
Validation loss: 2.362960613876361

Epoch: 6| Step: 1
Training loss: 1.376095595399172
Validation loss: 2.3841095717088514

Epoch: 6| Step: 2
Training loss: 1.2549307372445169
Validation loss: 2.2861258610086543

Epoch: 6| Step: 3
Training loss: 1.9485138438425311
Validation loss: 2.3695112943979657

Epoch: 6| Step: 4
Training loss: 1.7648209623138027
Validation loss: 2.363019013709895

Epoch: 6| Step: 5
Training loss: 2.0049855558488687
Validation loss: 2.388072225740278

Epoch: 6| Step: 6
Training loss: 1.4506560650103855
Validation loss: 2.4110936015914954

Epoch: 6| Step: 7
Training loss: 0.973126094966951
Validation loss: 2.402356607953136

Epoch: 6| Step: 8
Training loss: 2.1921334377591273
Validation loss: 2.3863694836500886

Epoch: 6| Step: 9
Training loss: 1.7570601824341232
Validation loss: 2.364014986627528

Epoch: 6| Step: 10
Training loss: 2.019040193751872
Validation loss: 2.3893894630337247

Epoch: 6| Step: 11
Training loss: 1.7890089268554956
Validation loss: 2.332110366472744

Epoch: 6| Step: 12
Training loss: 2.165326131699868
Validation loss: 2.4391968339762324

Epoch: 6| Step: 13
Training loss: 3.2051724472904914
Validation loss: 2.3556358471184002

Epoch: 258| Step: 0
Training loss: 1.733181310675031
Validation loss: 2.411792914150464

Epoch: 6| Step: 1
Training loss: 1.7113397552157732
Validation loss: 2.3153584891030365

Epoch: 6| Step: 2
Training loss: 1.4558259207339017
Validation loss: 2.4042530325884472

Epoch: 6| Step: 3
Training loss: 1.6268122178111564
Validation loss: 2.406405607555626

Epoch: 6| Step: 4
Training loss: 1.9366909922233673
Validation loss: 2.355170406664915

Epoch: 6| Step: 5
Training loss: 1.6875276210078545
Validation loss: 2.3444967894523154

Epoch: 6| Step: 6
Training loss: 2.07548940930735
Validation loss: 2.380099253523344

Epoch: 6| Step: 7
Training loss: 1.3737018699649375
Validation loss: 2.395742087389973

Epoch: 6| Step: 8
Training loss: 2.4204816193965253
Validation loss: 2.392000586908257

Epoch: 6| Step: 9
Training loss: 2.141967686477966
Validation loss: 2.341717768309222

Epoch: 6| Step: 10
Training loss: 2.310374958933441
Validation loss: 2.457108007837227

Epoch: 6| Step: 11
Training loss: 1.728468520390121
Validation loss: 2.3426042738387483

Epoch: 6| Step: 12
Training loss: 1.6383575756391817
Validation loss: 2.402100405943533

Epoch: 6| Step: 13
Training loss: 1.8433919655969846
Validation loss: 2.4321207450785787

Epoch: 259| Step: 0
Training loss: 1.7205161990107358
Validation loss: 2.4119382382651096

Epoch: 6| Step: 1
Training loss: 1.4881578128918878
Validation loss: 2.4121030235730014

Epoch: 6| Step: 2
Training loss: 1.8095365172193316
Validation loss: 2.4228104006586997

Epoch: 6| Step: 3
Training loss: 1.7228520772959355
Validation loss: 2.3694427402838056

Epoch: 6| Step: 4
Training loss: 1.5368704894978165
Validation loss: 2.4200716511373654

Epoch: 6| Step: 5
Training loss: 1.852616794626437
Validation loss: 2.405002908475298

Epoch: 6| Step: 6
Training loss: 1.7952399734707927
Validation loss: 2.4045154289632693

Epoch: 6| Step: 7
Training loss: 2.27231866631352
Validation loss: 2.4433493391152714

Epoch: 6| Step: 8
Training loss: 1.9667182005041017
Validation loss: 2.4788197963858707

Epoch: 6| Step: 9
Training loss: 2.622627366775951
Validation loss: 2.3869273515141445

Epoch: 6| Step: 10
Training loss: 1.747291103205422
Validation loss: 2.418437059644054

Epoch: 6| Step: 11
Training loss: 1.8578026157690501
Validation loss: 2.4725900372337373

Epoch: 6| Step: 12
Training loss: 1.9720355275340984
Validation loss: 2.4194535507723924

Epoch: 6| Step: 13
Training loss: 1.1081642205902733
Validation loss: 2.428028607247058

Epoch: 260| Step: 0
Training loss: 1.5366895943432404
Validation loss: 2.3787710521609795

Epoch: 6| Step: 1
Training loss: 1.4849148220461332
Validation loss: 2.416968034772949

Epoch: 6| Step: 2
Training loss: 1.7269424779840308
Validation loss: 2.3675615958692617

Epoch: 6| Step: 3
Training loss: 2.5222962813444
Validation loss: 2.375947978424091

Epoch: 6| Step: 4
Training loss: 1.6734208420495165
Validation loss: 2.363950195664032

Epoch: 6| Step: 5
Training loss: 1.941689729621799
Validation loss: 2.3910155583522115

Epoch: 6| Step: 6
Training loss: 1.9571676911020552
Validation loss: 2.4091641875728613

Epoch: 6| Step: 7
Training loss: 1.9108103624846668
Validation loss: 2.3842689843789255

Epoch: 6| Step: 8
Training loss: 1.7361145918069492
Validation loss: 2.3141050403147916

Epoch: 6| Step: 9
Training loss: 1.7788428387839026
Validation loss: 2.322882404586985

Epoch: 6| Step: 10
Training loss: 1.7647190977050518
Validation loss: 2.356543854873223

Epoch: 6| Step: 11
Training loss: 2.0660882427503076
Validation loss: 2.359680352692009

Epoch: 6| Step: 12
Training loss: 1.7187046391830294
Validation loss: 2.388314606489721

Epoch: 6| Step: 13
Training loss: 1.650067359820929
Validation loss: 2.4163205592368033

Epoch: 261| Step: 0
Training loss: 1.7733948152085368
Validation loss: 2.4081135471935737

Epoch: 6| Step: 1
Training loss: 1.5727219197888267
Validation loss: 2.3604649264145854

Epoch: 6| Step: 2
Training loss: 1.8397560179703065
Validation loss: 2.4132183417750706

Epoch: 6| Step: 3
Training loss: 1.7732472590779302
Validation loss: 2.429575986887919

Epoch: 6| Step: 4
Training loss: 1.9889969352710064
Validation loss: 2.444651401926697

Epoch: 6| Step: 5
Training loss: 2.5599900956260297
Validation loss: 2.3631364209008745

Epoch: 6| Step: 6
Training loss: 1.5600404836830295
Validation loss: 2.386643841309441

Epoch: 6| Step: 7
Training loss: 1.9039856015630665
Validation loss: 2.4568273173171598

Epoch: 6| Step: 8
Training loss: 1.8919024604793058
Validation loss: 2.4202875360318017

Epoch: 6| Step: 9
Training loss: 1.479163245971736
Validation loss: 2.394848076754948

Epoch: 6| Step: 10
Training loss: 2.20035048207269
Validation loss: 2.418556286852819

Epoch: 6| Step: 11
Training loss: 1.9725357472089915
Validation loss: 2.417730821310328

Epoch: 6| Step: 12
Training loss: 1.1196702166795645
Validation loss: 2.385179952750339

Epoch: 6| Step: 13
Training loss: 1.7052582845515984
Validation loss: 2.369584353706192

Epoch: 262| Step: 0
Training loss: 1.643358696025457
Validation loss: 2.3663404664400147

Epoch: 6| Step: 1
Training loss: 1.5433269616085428
Validation loss: 2.4175497714498007

Epoch: 6| Step: 2
Training loss: 1.5883141359901642
Validation loss: 2.413264369022849

Epoch: 6| Step: 3
Training loss: 1.5827699796758947
Validation loss: 2.430513247245245

Epoch: 6| Step: 4
Training loss: 1.6225377281516484
Validation loss: 2.323473711589006

Epoch: 6| Step: 5
Training loss: 1.5656122111942197
Validation loss: 2.3990081335958138

Epoch: 6| Step: 6
Training loss: 1.9709369683253628
Validation loss: 2.359558075004537

Epoch: 6| Step: 7
Training loss: 1.9677170359666611
Validation loss: 2.3276058151353127

Epoch: 6| Step: 8
Training loss: 2.101660743884525
Validation loss: 2.372586797795333

Epoch: 6| Step: 9
Training loss: 1.8261425648341367
Validation loss: 2.4250644034639848

Epoch: 6| Step: 10
Training loss: 1.672281946585118
Validation loss: 2.3915273170083275

Epoch: 6| Step: 11
Training loss: 2.464350583030252
Validation loss: 2.384103507528781

Epoch: 6| Step: 12
Training loss: 1.950273920040387
Validation loss: 2.4111960443022107

Epoch: 6| Step: 13
Training loss: 1.7842438283831992
Validation loss: 2.3673307990791215

Epoch: 263| Step: 0
Training loss: 2.0889468541230496
Validation loss: 2.3511734131150486

Epoch: 6| Step: 1
Training loss: 2.681505926406972
Validation loss: 2.4059065866852327

Epoch: 6| Step: 2
Training loss: 1.76051048916631
Validation loss: 2.401634693127478

Epoch: 6| Step: 3
Training loss: 2.194626235943315
Validation loss: 2.362318437849101

Epoch: 6| Step: 4
Training loss: 1.7717729058026392
Validation loss: 2.424143131037946

Epoch: 6| Step: 5
Training loss: 1.570953238419599
Validation loss: 2.4312487654874353

Epoch: 6| Step: 6
Training loss: 1.4782117886700423
Validation loss: 2.3717480650176026

Epoch: 6| Step: 7
Training loss: 1.7483270686970427
Validation loss: 2.430159958983339

Epoch: 6| Step: 8
Training loss: 1.7059959921213992
Validation loss: 2.400599102133633

Epoch: 6| Step: 9
Training loss: 1.8071037729819734
Validation loss: 2.3412276337017355

Epoch: 6| Step: 10
Training loss: 1.3096855050328688
Validation loss: 2.390419150298188

Epoch: 6| Step: 11
Training loss: 1.6974085494114586
Validation loss: 2.436324201723866

Epoch: 6| Step: 12
Training loss: 1.607002954600193
Validation loss: 2.3644186140240513

Epoch: 6| Step: 13
Training loss: 1.766677542718962
Validation loss: 2.4129613901960503

Epoch: 264| Step: 0
Training loss: 2.4707606372999904
Validation loss: 2.370056193472914

Epoch: 6| Step: 1
Training loss: 1.4989461375631312
Validation loss: 2.409988845582717

Epoch: 6| Step: 2
Training loss: 1.6075408261159014
Validation loss: 2.440300581284548

Epoch: 6| Step: 3
Training loss: 2.049477822393407
Validation loss: 2.3707815809721904

Epoch: 6| Step: 4
Training loss: 1.3084370533514433
Validation loss: 2.4278362507121076

Epoch: 6| Step: 5
Training loss: 1.6896448280190972
Validation loss: 2.398909785999361

Epoch: 6| Step: 6
Training loss: 1.74945972822118
Validation loss: 2.381689392862978

Epoch: 6| Step: 7
Training loss: 1.547304652491574
Validation loss: 2.3716114851603134

Epoch: 6| Step: 8
Training loss: 1.7355529633938336
Validation loss: 2.3534549305508277

Epoch: 6| Step: 9
Training loss: 1.9386789980097836
Validation loss: 2.4007520592869174

Epoch: 6| Step: 10
Training loss: 1.8474616498670526
Validation loss: 2.3982459309751167

Epoch: 6| Step: 11
Training loss: 1.9801589151631054
Validation loss: 2.3749043661831513

Epoch: 6| Step: 12
Training loss: 1.5583546390538936
Validation loss: 2.396330383730362

Epoch: 6| Step: 13
Training loss: 2.658811164729903
Validation loss: 2.3734895159071097

Epoch: 265| Step: 0
Training loss: 1.7519423740699258
Validation loss: 2.3996524248906215

Epoch: 6| Step: 1
Training loss: 1.3911066828390808
Validation loss: 2.496178126259871

Epoch: 6| Step: 2
Training loss: 1.4173500245428203
Validation loss: 2.4155353508440895

Epoch: 6| Step: 3
Training loss: 1.8757278936853532
Validation loss: 2.3662815830427255

Epoch: 6| Step: 4
Training loss: 1.6666553337983432
Validation loss: 2.431152875743218

Epoch: 6| Step: 5
Training loss: 1.2646923160673362
Validation loss: 2.394254801280965

Epoch: 6| Step: 6
Training loss: 2.0379442678436206
Validation loss: 2.4325325198793086

Epoch: 6| Step: 7
Training loss: 1.8952938472021776
Validation loss: 2.39416447459041

Epoch: 6| Step: 8
Training loss: 1.8986899125697798
Validation loss: 2.4280278649824742

Epoch: 6| Step: 9
Training loss: 1.8163397664034207
Validation loss: 2.443371793628942

Epoch: 6| Step: 10
Training loss: 2.033810454292449
Validation loss: 2.418652848241798

Epoch: 6| Step: 11
Training loss: 1.7905198204479593
Validation loss: 2.437022285146682

Epoch: 6| Step: 12
Training loss: 2.6975248683175566
Validation loss: 2.4126064243271013

Epoch: 6| Step: 13
Training loss: 1.2608836808944395
Validation loss: 2.3851650212953177

Epoch: 266| Step: 0
Training loss: 1.9277273253338043
Validation loss: 2.408071966554811

Epoch: 6| Step: 1
Training loss: 2.2160197908364685
Validation loss: 2.384911199130618

Epoch: 6| Step: 2
Training loss: 1.4533321274014523
Validation loss: 2.3961754667400093

Epoch: 6| Step: 3
Training loss: 1.3391704146390706
Validation loss: 2.424984608973384

Epoch: 6| Step: 4
Training loss: 1.4723821329244744
Validation loss: 2.358205020994981

Epoch: 6| Step: 5
Training loss: 1.7776550691031856
Validation loss: 2.3846135485327102

Epoch: 6| Step: 6
Training loss: 2.062387058749263
Validation loss: 2.3778676874465736

Epoch: 6| Step: 7
Training loss: 1.38950079577939
Validation loss: 2.3723851496535144

Epoch: 6| Step: 8
Training loss: 1.040419474058039
Validation loss: 2.3287755499521707

Epoch: 6| Step: 9
Training loss: 2.219273142860809
Validation loss: 2.408620771538079

Epoch: 6| Step: 10
Training loss: 2.2722666238904243
Validation loss: 2.406918535504011

Epoch: 6| Step: 11
Training loss: 1.293346891397678
Validation loss: 2.41366443351454

Epoch: 6| Step: 12
Training loss: 1.9779208495269491
Validation loss: 2.3155690729720586

Epoch: 6| Step: 13
Training loss: 1.4416335012042532
Validation loss: 2.374820339745502

Epoch: 267| Step: 0
Training loss: 1.345613651041737
Validation loss: 2.409726276563529

Epoch: 6| Step: 1
Training loss: 1.2354688023356963
Validation loss: 2.321751530834618

Epoch: 6| Step: 2
Training loss: 2.563653267719214
Validation loss: 2.361899015917276

Epoch: 6| Step: 3
Training loss: 2.245195663693439
Validation loss: 2.3661345626217614

Epoch: 6| Step: 4
Training loss: 2.5229212938597563
Validation loss: 2.389679424366043

Epoch: 6| Step: 5
Training loss: 1.393756255747351
Validation loss: 2.41967852780548

Epoch: 6| Step: 6
Training loss: 2.0752691852660217
Validation loss: 2.381221092013555

Epoch: 6| Step: 7
Training loss: 1.9235100962545184
Validation loss: 2.314225967036621

Epoch: 6| Step: 8
Training loss: 1.5410909694726609
Validation loss: 2.335631193488085

Epoch: 6| Step: 9
Training loss: 1.5460192692778423
Validation loss: 2.428855886359952

Epoch: 6| Step: 10
Training loss: 1.612730435606496
Validation loss: 2.4509476963181154

Epoch: 6| Step: 11
Training loss: 1.1923379225720339
Validation loss: 2.3871620045493245

Epoch: 6| Step: 12
Training loss: 1.5000991788500915
Validation loss: 2.385131189789234

Epoch: 6| Step: 13
Training loss: 2.177234321967924
Validation loss: 2.38107820144724

Epoch: 268| Step: 0
Training loss: 1.7945551616983793
Validation loss: 2.3931957569571196

Epoch: 6| Step: 1
Training loss: 1.8584646352503118
Validation loss: 2.37793890521786

Epoch: 6| Step: 2
Training loss: 1.880020667632108
Validation loss: 2.369206090981172

Epoch: 6| Step: 3
Training loss: 2.1191136230998615
Validation loss: 2.425193899006129

Epoch: 6| Step: 4
Training loss: 1.466602297295145
Validation loss: 2.453170470790887

Epoch: 6| Step: 5
Training loss: 2.5156134374127714
Validation loss: 2.493319993426229

Epoch: 6| Step: 6
Training loss: 1.4532975945467705
Validation loss: 2.4554913463867476

Epoch: 6| Step: 7
Training loss: 1.2383941695174636
Validation loss: 2.371922116109745

Epoch: 6| Step: 8
Training loss: 1.9409306210279442
Validation loss: 2.4028766992341355

Epoch: 6| Step: 9
Training loss: 2.470324050712243
Validation loss: 2.348657511871891

Epoch: 6| Step: 10
Training loss: 1.534383875555096
Validation loss: 2.368266126832848

Epoch: 6| Step: 11
Training loss: 1.519631978204634
Validation loss: 2.3731191708096926

Epoch: 6| Step: 12
Training loss: 1.6706251660028297
Validation loss: 2.3878370823954094

Epoch: 6| Step: 13
Training loss: 1.79847201820476
Validation loss: 2.3686425205901274

Epoch: 269| Step: 0
Training loss: 1.9315080587568048
Validation loss: 2.3890357024471345

Epoch: 6| Step: 1
Training loss: 1.9019362622240379
Validation loss: 2.4021402289640448

Epoch: 6| Step: 2
Training loss: 1.1669887654401971
Validation loss: 2.412601088996094

Epoch: 6| Step: 3
Training loss: 2.5250280699727656
Validation loss: 2.3947601457877306

Epoch: 6| Step: 4
Training loss: 1.7495270498691573
Validation loss: 2.381561137648589

Epoch: 6| Step: 5
Training loss: 1.8064453019414262
Validation loss: 2.3874188303323405

Epoch: 6| Step: 6
Training loss: 1.0508860709509154
Validation loss: 2.4461246774445833

Epoch: 6| Step: 7
Training loss: 1.8637571226990655
Validation loss: 2.4099076844030574

Epoch: 6| Step: 8
Training loss: 2.1374959979103503
Validation loss: 2.441075697968703

Epoch: 6| Step: 9
Training loss: 1.522741227105434
Validation loss: 2.3565347101229777

Epoch: 6| Step: 10
Training loss: 1.7549527111366294
Validation loss: 2.4183879305194176

Epoch: 6| Step: 11
Training loss: 1.9430214746282912
Validation loss: 2.385258381122778

Epoch: 6| Step: 12
Training loss: 2.148674525277426
Validation loss: 2.3225813070433596

Epoch: 6| Step: 13
Training loss: 1.064875919474637
Validation loss: 2.3697284474144533

Epoch: 270| Step: 0
Training loss: 1.197051036827034
Validation loss: 2.3544719874478006

Epoch: 6| Step: 1
Training loss: 1.594827325257407
Validation loss: 2.444503770486198

Epoch: 6| Step: 2
Training loss: 2.1484056505096625
Validation loss: 2.4235906065221675

Epoch: 6| Step: 3
Training loss: 1.2771627782076898
Validation loss: 2.3366525452607707

Epoch: 6| Step: 4
Training loss: 1.2469722317905436
Validation loss: 2.3559267227422573

Epoch: 6| Step: 5
Training loss: 1.8404687682395575
Validation loss: 2.3772107970509926

Epoch: 6| Step: 6
Training loss: 2.1786492175255985
Validation loss: 2.4160067446154168

Epoch: 6| Step: 7
Training loss: 1.5137266875156394
Validation loss: 2.3692023470250674

Epoch: 6| Step: 8
Training loss: 1.2913796608478616
Validation loss: 2.354030119667217

Epoch: 6| Step: 9
Training loss: 1.8195652553579549
Validation loss: 2.430618010351867

Epoch: 6| Step: 10
Training loss: 2.4726067849947158
Validation loss: 2.4214608930356687

Epoch: 6| Step: 11
Training loss: 1.990884990870894
Validation loss: 2.3869941254090907

Epoch: 6| Step: 12
Training loss: 1.6258388701552695
Validation loss: 2.361927503547735

Epoch: 6| Step: 13
Training loss: 2.0765766312668745
Validation loss: 2.4480956616716716

Epoch: 271| Step: 0
Training loss: 1.573868856994163
Validation loss: 2.3670608571646032

Epoch: 6| Step: 1
Training loss: 1.7161022252131695
Validation loss: 2.3689242021506045

Epoch: 6| Step: 2
Training loss: 1.7019914126779094
Validation loss: 2.357297190359381

Epoch: 6| Step: 3
Training loss: 1.6034132521704183
Validation loss: 2.410671147020585

Epoch: 6| Step: 4
Training loss: 1.6580750828205537
Validation loss: 2.4320929879311506

Epoch: 6| Step: 5
Training loss: 1.8238566854123544
Validation loss: 2.3692115034760413

Epoch: 6| Step: 6
Training loss: 1.6118722447774472
Validation loss: 2.43841545640192

Epoch: 6| Step: 7
Training loss: 1.8277682094780878
Validation loss: 2.3350281632312493

Epoch: 6| Step: 8
Training loss: 1.762782078348444
Validation loss: 2.3520988812260564

Epoch: 6| Step: 9
Training loss: 1.8628557467100175
Validation loss: 2.4377269202770515

Epoch: 6| Step: 10
Training loss: 2.5255199614623183
Validation loss: 2.4499215180226646

Epoch: 6| Step: 11
Training loss: 1.3955040111449932
Validation loss: 2.3947215221549865

Epoch: 6| Step: 12
Training loss: 2.2814797063690335
Validation loss: 2.3849026855767037

Epoch: 6| Step: 13
Training loss: 1.548507830488233
Validation loss: 2.353513594578721

Epoch: 272| Step: 0
Training loss: 1.2696184333795955
Validation loss: 2.4171199062391513

Epoch: 6| Step: 1
Training loss: 1.7972687662980589
Validation loss: 2.4182852062302884

Epoch: 6| Step: 2
Training loss: 1.2994067287195108
Validation loss: 2.3898809654358626

Epoch: 6| Step: 3
Training loss: 1.8214824011405641
Validation loss: 2.415327467701085

Epoch: 6| Step: 4
Training loss: 1.548009052146645
Validation loss: 2.3403924958711495

Epoch: 6| Step: 5
Training loss: 1.9600406130650716
Validation loss: 2.3904219140386385

Epoch: 6| Step: 6
Training loss: 1.6797256110547423
Validation loss: 2.335093572240604

Epoch: 6| Step: 7
Training loss: 1.8885602789871876
Validation loss: 2.3651992243677955

Epoch: 6| Step: 8
Training loss: 1.698866744138636
Validation loss: 2.3612702945981927

Epoch: 6| Step: 9
Training loss: 1.7494555034969652
Validation loss: 2.415178514022517

Epoch: 6| Step: 10
Training loss: 1.8926741159383635
Validation loss: 2.360705975932302

Epoch: 6| Step: 11
Training loss: 2.3801347538922646
Validation loss: 2.425661038845014

Epoch: 6| Step: 12
Training loss: 1.364935890061607
Validation loss: 2.38690168626466

Epoch: 6| Step: 13
Training loss: 2.4109085368050267
Validation loss: 2.345598479884166

Epoch: 273| Step: 0
Training loss: 1.851428513970534
Validation loss: 2.3454687705994632

Epoch: 6| Step: 1
Training loss: 1.1768419924182765
Validation loss: 2.3625589597000807

Epoch: 6| Step: 2
Training loss: 1.7450061799079308
Validation loss: 2.3426975569880275

Epoch: 6| Step: 3
Training loss: 2.5094458469066687
Validation loss: 2.3799780136010416

Epoch: 6| Step: 4
Training loss: 1.872101832737873
Validation loss: 2.4012872760134227

Epoch: 6| Step: 5
Training loss: 1.7773417378508527
Validation loss: 2.3383986297354546

Epoch: 6| Step: 6
Training loss: 1.5378377465925885
Validation loss: 2.3865747964398745

Epoch: 6| Step: 7
Training loss: 1.7358921048523497
Validation loss: 2.3387641964386274

Epoch: 6| Step: 8
Training loss: 1.7647561154976286
Validation loss: 2.413635344612126

Epoch: 6| Step: 9
Training loss: 1.800017354139806
Validation loss: 2.3171682611825326

Epoch: 6| Step: 10
Training loss: 1.4974898952850109
Validation loss: 2.3622182149015782

Epoch: 6| Step: 11
Training loss: 1.665286191795854
Validation loss: 2.393182324884108

Epoch: 6| Step: 12
Training loss: 1.7911448790856523
Validation loss: 2.3651774161890793

Epoch: 6| Step: 13
Training loss: 1.567540317120338
Validation loss: 2.332566611792016

Epoch: 274| Step: 0
Training loss: 1.1379598547386038
Validation loss: 2.3851186807381253

Epoch: 6| Step: 1
Training loss: 2.506218804904927
Validation loss: 2.413639815193594

Epoch: 6| Step: 2
Training loss: 1.832013355810298
Validation loss: 2.4255809627602987

Epoch: 6| Step: 3
Training loss: 2.3672540737144847
Validation loss: 2.352068192747268

Epoch: 6| Step: 4
Training loss: 1.7938134690596415
Validation loss: 2.3951907058897732

Epoch: 6| Step: 5
Training loss: 1.274026558963005
Validation loss: 2.386376082972933

Epoch: 6| Step: 6
Training loss: 1.869070468331352
Validation loss: 2.372927755281868

Epoch: 6| Step: 7
Training loss: 2.480724796086018
Validation loss: 2.3336440471321502

Epoch: 6| Step: 8
Training loss: 1.7267114911588302
Validation loss: 2.4367263434907445

Epoch: 6| Step: 9
Training loss: 1.232569762725811
Validation loss: 2.4041965508638143

Epoch: 6| Step: 10
Training loss: 1.5014696074619553
Validation loss: 2.39249498073419

Epoch: 6| Step: 11
Training loss: 1.764970776367321
Validation loss: 2.3874570352083366

Epoch: 6| Step: 12
Training loss: 1.296941181010902
Validation loss: 2.407564568821503

Epoch: 6| Step: 13
Training loss: 1.465134329902905
Validation loss: 2.374758594249547

Epoch: 275| Step: 0
Training loss: 2.11876065411885
Validation loss: 2.3993203452702834

Epoch: 6| Step: 1
Training loss: 1.2726359272663728
Validation loss: 2.345963137743073

Epoch: 6| Step: 2
Training loss: 1.5785402563675404
Validation loss: 2.4167634784060907

Epoch: 6| Step: 3
Training loss: 1.4835575462933894
Validation loss: 2.3698589507869627

Epoch: 6| Step: 4
Training loss: 2.3818035053142497
Validation loss: 2.375290503704842

Epoch: 6| Step: 5
Training loss: 1.4925174048861003
Validation loss: 2.4369063115828635

Epoch: 6| Step: 6
Training loss: 1.6757177949998037
Validation loss: 2.382011794661801

Epoch: 6| Step: 7
Training loss: 1.977371954745012
Validation loss: 2.3293275735467636

Epoch: 6| Step: 8
Training loss: 2.190643667448993
Validation loss: 2.4240358724433007

Epoch: 6| Step: 9
Training loss: 1.4511925758743907
Validation loss: 2.4121485587684663

Epoch: 6| Step: 10
Training loss: 1.8423499918189667
Validation loss: 2.3984311038166437

Epoch: 6| Step: 11
Training loss: 1.6857274247204712
Validation loss: 2.3694634318538186

Epoch: 6| Step: 12
Training loss: 1.8002630385954532
Validation loss: 2.3704952810477447

Epoch: 6| Step: 13
Training loss: 1.4736629859661485
Validation loss: 2.431073305347178

Epoch: 276| Step: 0
Training loss: 1.5629587644383702
Validation loss: 2.4070640287612286

Epoch: 6| Step: 1
Training loss: 1.819316411387099
Validation loss: 2.369472573501064

Epoch: 6| Step: 2
Training loss: 1.2223921420487642
Validation loss: 2.4363838440063494

Epoch: 6| Step: 3
Training loss: 2.080140935818102
Validation loss: 2.321757689964184

Epoch: 6| Step: 4
Training loss: 1.3967526051538144
Validation loss: 2.3623504457212237

Epoch: 6| Step: 5
Training loss: 1.8455576682928738
Validation loss: 2.387019793960638

Epoch: 6| Step: 6
Training loss: 2.08915502304811
Validation loss: 2.3635045945984494

Epoch: 6| Step: 7
Training loss: 1.9148549210694519
Validation loss: 2.4422915219146115

Epoch: 6| Step: 8
Training loss: 1.4477583526491584
Validation loss: 2.3935916002265185

Epoch: 6| Step: 9
Training loss: 1.8381948026797588
Validation loss: 2.4155470878832097

Epoch: 6| Step: 10
Training loss: 1.8946289666528133
Validation loss: 2.371065071920345

Epoch: 6| Step: 11
Training loss: 1.4234045835137388
Validation loss: 2.4147828386669867

Epoch: 6| Step: 12
Training loss: 1.3336779129296554
Validation loss: 2.306263389073881

Epoch: 6| Step: 13
Training loss: 2.9313971248704482
Validation loss: 2.4254025061287003

Epoch: 277| Step: 0
Training loss: 2.0805959137670818
Validation loss: 2.4083388293751757

Epoch: 6| Step: 1
Training loss: 1.4039891188273228
Validation loss: 2.3667742912984475

Epoch: 6| Step: 2
Training loss: 2.1187090034231986
Validation loss: 2.3517277969209807

Epoch: 6| Step: 3
Training loss: 1.3258684623055743
Validation loss: 2.4107252029030244

Epoch: 6| Step: 4
Training loss: 1.2539776457903737
Validation loss: 2.3426122007855796

Epoch: 6| Step: 5
Training loss: 1.26674028400183
Validation loss: 2.3200190802519045

Epoch: 6| Step: 6
Training loss: 1.8821857723080584
Validation loss: 2.4140071881807916

Epoch: 6| Step: 7
Training loss: 1.5644794133295765
Validation loss: 2.426469544536296

Epoch: 6| Step: 8
Training loss: 1.4461306344165785
Validation loss: 2.405694920697012

Epoch: 6| Step: 9
Training loss: 1.288458156526509
Validation loss: 2.302395625479117

Epoch: 6| Step: 10
Training loss: 1.5147838814813899
Validation loss: 2.3921123234204953

Epoch: 6| Step: 11
Training loss: 2.3455528954417
Validation loss: 2.4445803920807068

Epoch: 6| Step: 12
Training loss: 1.7844955590669285
Validation loss: 2.432603786565286

Epoch: 6| Step: 13
Training loss: 3.157567721718147
Validation loss: 2.4055870303076223

Epoch: 278| Step: 0
Training loss: 1.8869750044339215
Validation loss: 2.4031583061189434

Epoch: 6| Step: 1
Training loss: 1.6203490971374774
Validation loss: 2.3602426757960235

Epoch: 6| Step: 2
Training loss: 1.4383278826230506
Validation loss: 2.3661801747296973

Epoch: 6| Step: 3
Training loss: 1.3862163654508888
Validation loss: 2.3497722421544647

Epoch: 6| Step: 4
Training loss: 1.8011636390075811
Validation loss: 2.3839770051832114

Epoch: 6| Step: 5
Training loss: 1.8427822353393588
Validation loss: 2.278272669647135

Epoch: 6| Step: 6
Training loss: 1.8592917159205402
Validation loss: 2.4411588899386607

Epoch: 6| Step: 7
Training loss: 2.4595831156485044
Validation loss: 2.304544453937864

Epoch: 6| Step: 8
Training loss: 1.4593926896323999
Validation loss: 2.394674679231607

Epoch: 6| Step: 9
Training loss: 1.9131351637920788
Validation loss: 2.3912419946461902

Epoch: 6| Step: 10
Training loss: 1.1497316918222886
Validation loss: 2.409182365872197

Epoch: 6| Step: 11
Training loss: 1.7116953247083126
Validation loss: 2.3914735968750973

Epoch: 6| Step: 12
Training loss: 1.8244181816006386
Validation loss: 2.349578361042977

Epoch: 6| Step: 13
Training loss: 1.8734922704890986
Validation loss: 2.3632878161652457

Epoch: 279| Step: 0
Training loss: 1.7033805305501468
Validation loss: 2.3880432137161542

Epoch: 6| Step: 1
Training loss: 1.6379292456933863
Validation loss: 2.3365394814500826

Epoch: 6| Step: 2
Training loss: 1.7439672847444097
Validation loss: 2.398530563393336

Epoch: 6| Step: 3
Training loss: 1.4441707741043721
Validation loss: 2.309353813682429

Epoch: 6| Step: 4
Training loss: 1.5991836372549784
Validation loss: 2.375215910254729

Epoch: 6| Step: 5
Training loss: 2.4408830494070313
Validation loss: 2.4357763690274177

Epoch: 6| Step: 6
Training loss: 1.8237284424143696
Validation loss: 2.413038011506416

Epoch: 6| Step: 7
Training loss: 1.4274073694642602
Validation loss: 2.298821172866557

Epoch: 6| Step: 8
Training loss: 1.4851261045556015
Validation loss: 2.3392832138708926

Epoch: 6| Step: 9
Training loss: 1.6162441284828306
Validation loss: 2.4036844771027663

Epoch: 6| Step: 10
Training loss: 1.6425082342675914
Validation loss: 2.3911993602301727

Epoch: 6| Step: 11
Training loss: 1.638322213187886
Validation loss: 2.407104920962241

Epoch: 6| Step: 12
Training loss: 1.952842142603811
Validation loss: 2.3917390028183405

Epoch: 6| Step: 13
Training loss: 1.4891944946836917
Validation loss: 2.355054445290737

Epoch: 280| Step: 0
Training loss: 1.9546161300107605
Validation loss: 2.373132661347232

Epoch: 6| Step: 1
Training loss: 1.521736016477633
Validation loss: 2.3905133076446288

Epoch: 6| Step: 2
Training loss: 1.300778500665732
Validation loss: 2.4030571983402913

Epoch: 6| Step: 3
Training loss: 1.2689841162496898
Validation loss: 2.392359964663643

Epoch: 6| Step: 4
Training loss: 2.122977023129281
Validation loss: 2.4243723621310758

Epoch: 6| Step: 5
Training loss: 1.404896148020131
Validation loss: 2.33144694115041

Epoch: 6| Step: 6
Training loss: 1.2942662485247434
Validation loss: 2.351166192697252

Epoch: 6| Step: 7
Training loss: 1.5068460638431613
Validation loss: 2.391494950860995

Epoch: 6| Step: 8
Training loss: 1.959446739331471
Validation loss: 2.3569643869273276

Epoch: 6| Step: 9
Training loss: 1.3435136454108956
Validation loss: 2.3717164785238225

Epoch: 6| Step: 10
Training loss: 2.1464851525177733
Validation loss: 2.4018021317243288

Epoch: 6| Step: 11
Training loss: 2.333805808415002
Validation loss: 2.418128209915439

Epoch: 6| Step: 12
Training loss: 2.0302642778022095
Validation loss: 2.399293065594485

Epoch: 6| Step: 13
Training loss: 1.4541187784931988
Validation loss: 2.369893401102269

Epoch: 281| Step: 0
Training loss: 2.3242388556115676
Validation loss: 2.4360957469419753

Epoch: 6| Step: 1
Training loss: 1.8505746000642158
Validation loss: 2.3706023331456

Epoch: 6| Step: 2
Training loss: 1.7134600989997573
Validation loss: 2.4233343590838894

Epoch: 6| Step: 3
Training loss: 1.6670519701311546
Validation loss: 2.4321641705229076

Epoch: 6| Step: 4
Training loss: 1.4720449620822884
Validation loss: 2.3898910177465083

Epoch: 6| Step: 5
Training loss: 1.1382527176966775
Validation loss: 2.385367521997867

Epoch: 6| Step: 6
Training loss: 1.2884863288281434
Validation loss: 2.429893045759376

Epoch: 6| Step: 7
Training loss: 2.1020017257088095
Validation loss: 2.390751318932373

Epoch: 6| Step: 8
Training loss: 2.107122617444241
Validation loss: 2.3099796287227194

Epoch: 6| Step: 9
Training loss: 1.2739051942927389
Validation loss: 2.4016668809959807

Epoch: 6| Step: 10
Training loss: 1.5880862557745499
Validation loss: 2.3922414133303893

Epoch: 6| Step: 11
Training loss: 2.3854079822454386
Validation loss: 2.346282264806287

Epoch: 6| Step: 12
Training loss: 1.5185733708155325
Validation loss: 2.362067578651777

Epoch: 6| Step: 13
Training loss: 1.460689829675923
Validation loss: 2.3860911024767963

Epoch: 282| Step: 0
Training loss: 1.130227342202557
Validation loss: 2.3432924509018815

Epoch: 6| Step: 1
Training loss: 2.5996891642878244
Validation loss: 2.404353047821115

Epoch: 6| Step: 2
Training loss: 1.4116602773120202
Validation loss: 2.377821577712911

Epoch: 6| Step: 3
Training loss: 1.22604077170876
Validation loss: 2.378229348527183

Epoch: 6| Step: 4
Training loss: 1.8627024137352186
Validation loss: 2.3462821932384004

Epoch: 6| Step: 5
Training loss: 1.9849974489555975
Validation loss: 2.4020654644719643

Epoch: 6| Step: 6
Training loss: 1.5460882016198527
Validation loss: 2.426463704025122

Epoch: 6| Step: 7
Training loss: 1.4412807006742254
Validation loss: 2.403715860020938

Epoch: 6| Step: 8
Training loss: 1.5726026849014745
Validation loss: 2.4029753090857278

Epoch: 6| Step: 9
Training loss: 1.3588553125862308
Validation loss: 2.4039721495373443

Epoch: 6| Step: 10
Training loss: 1.9570240013003544
Validation loss: 2.392334801340862

Epoch: 6| Step: 11
Training loss: 1.7607130745391968
Validation loss: 2.3983056682635877

Epoch: 6| Step: 12
Training loss: 1.8922657428317913
Validation loss: 2.3614908450684364

Epoch: 6| Step: 13
Training loss: 1.272438359444502
Validation loss: 2.372564637733768

Epoch: 283| Step: 0
Training loss: 2.004873893558157
Validation loss: 2.4312658634032576

Epoch: 6| Step: 1
Training loss: 1.777894188460418
Validation loss: 2.394705418531427

Epoch: 6| Step: 2
Training loss: 2.305770878012043
Validation loss: 2.4058170214051433

Epoch: 6| Step: 3
Training loss: 1.424821839154176
Validation loss: 2.4134154984118243

Epoch: 6| Step: 4
Training loss: 1.5993306309522277
Validation loss: 2.44194990796648

Epoch: 6| Step: 5
Training loss: 1.4494755355491578
Validation loss: 2.394376892211926

Epoch: 6| Step: 6
Training loss: 1.6612648527401364
Validation loss: 2.3678809485411305

Epoch: 6| Step: 7
Training loss: 1.2881821834304026
Validation loss: 2.3667305705333948

Epoch: 6| Step: 8
Training loss: 1.4040347558987953
Validation loss: 2.3726905405663477

Epoch: 6| Step: 9
Training loss: 1.883064854595441
Validation loss: 2.3698680214051038

Epoch: 6| Step: 10
Training loss: 1.991462306254697
Validation loss: 2.384714422386535

Epoch: 6| Step: 11
Training loss: 1.831957004238311
Validation loss: 2.3295226641211975

Epoch: 6| Step: 12
Training loss: 1.8895370253412602
Validation loss: 2.4029749826262403

Epoch: 6| Step: 13
Training loss: 1.17243715154416
Validation loss: 2.341534028164864

Epoch: 284| Step: 0
Training loss: 1.945945789864107
Validation loss: 2.402391403796746

Epoch: 6| Step: 1
Training loss: 1.6700519354962104
Validation loss: 2.3764283656628855

Epoch: 6| Step: 2
Training loss: 1.813506274578219
Validation loss: 2.4339856101052137

Epoch: 6| Step: 3
Training loss: 1.3175120251448815
Validation loss: 2.393076675503849

Epoch: 6| Step: 4
Training loss: 1.677519779003441
Validation loss: 2.3957455052296446

Epoch: 6| Step: 5
Training loss: 2.0667069041529182
Validation loss: 2.3848732039366025

Epoch: 6| Step: 6
Training loss: 1.330670957044923
Validation loss: 2.397382031457104

Epoch: 6| Step: 7
Training loss: 1.5162824011200187
Validation loss: 2.3491298455669387

Epoch: 6| Step: 8
Training loss: 1.3496243466376294
Validation loss: 2.3461521873872493

Epoch: 6| Step: 9
Training loss: 1.2858941646796844
Validation loss: 2.411213732025814

Epoch: 6| Step: 10
Training loss: 1.1934074229855194
Validation loss: 2.391307140735628

Epoch: 6| Step: 11
Training loss: 2.6788514726566928
Validation loss: 2.3582576253715373

Epoch: 6| Step: 12
Training loss: 1.7528551516186819
Validation loss: 2.3420705453635167

Epoch: 6| Step: 13
Training loss: 1.8286702573733806
Validation loss: 2.347373695467275

Epoch: 285| Step: 0
Training loss: 1.3633826800107591
Validation loss: 2.391441375793593

Epoch: 6| Step: 1
Training loss: 1.9548883641362622
Validation loss: 2.3537936509060025

Epoch: 6| Step: 2
Training loss: 1.6224783625871868
Validation loss: 2.3523798099939395

Epoch: 6| Step: 3
Training loss: 2.1870079577056574
Validation loss: 2.4030836517119263

Epoch: 6| Step: 4
Training loss: 1.3089515766165924
Validation loss: 2.4162409237310793

Epoch: 6| Step: 5
Training loss: 1.3780389495073253
Validation loss: 2.3841816933537534

Epoch: 6| Step: 6
Training loss: 2.1579615116805897
Validation loss: 2.3832549245396804

Epoch: 6| Step: 7
Training loss: 2.2495738791573094
Validation loss: 2.313247934418695

Epoch: 6| Step: 8
Training loss: 1.3057514352602504
Validation loss: 2.383172343286344

Epoch: 6| Step: 9
Training loss: 1.5420303001791282
Validation loss: 2.390985730707036

Epoch: 6| Step: 10
Training loss: 1.6506579301142759
Validation loss: 2.418758671433324

Epoch: 6| Step: 11
Training loss: 1.5899219540568856
Validation loss: 2.350368231516487

Epoch: 6| Step: 12
Training loss: 1.699636684190433
Validation loss: 2.3695830110745506

Epoch: 6| Step: 13
Training loss: 1.0620630151045551
Validation loss: 2.4161535750200533

Epoch: 286| Step: 0
Training loss: 1.6530291351040023
Validation loss: 2.397567595008749

Epoch: 6| Step: 1
Training loss: 1.065515726253572
Validation loss: 2.4228331439295623

Epoch: 6| Step: 2
Training loss: 2.181677890551522
Validation loss: 2.3668225886821053

Epoch: 6| Step: 3
Training loss: 2.391016111605999
Validation loss: 2.3843313136473534

Epoch: 6| Step: 4
Training loss: 1.6322528664903657
Validation loss: 2.396839863135011

Epoch: 6| Step: 5
Training loss: 1.0782604408881926
Validation loss: 2.4216947628069634

Epoch: 6| Step: 6
Training loss: 1.2990668285408795
Validation loss: 2.413986898331515

Epoch: 6| Step: 7
Training loss: 1.6913440155490886
Validation loss: 2.444015686927024

Epoch: 6| Step: 8
Training loss: 1.8712142873654858
Validation loss: 2.411344259501636

Epoch: 6| Step: 9
Training loss: 1.8577799005752331
Validation loss: 2.3935750118478887

Epoch: 6| Step: 10
Training loss: 1.6311821349777906
Validation loss: 2.3661300694589555

Epoch: 6| Step: 11
Training loss: 1.3489245652301223
Validation loss: 2.4320794723740864

Epoch: 6| Step: 12
Training loss: 1.7140536562779274
Validation loss: 2.3542092076526226

Epoch: 6| Step: 13
Training loss: 1.8635168026636664
Validation loss: 2.3605176764609808

Epoch: 287| Step: 0
Training loss: 1.8488953772200745
Validation loss: 2.4310020749951904

Epoch: 6| Step: 1
Training loss: 1.4222294292333573
Validation loss: 2.3506873478321393

Epoch: 6| Step: 2
Training loss: 1.530311997834011
Validation loss: 2.4305655697695867

Epoch: 6| Step: 3
Training loss: 1.991845075312493
Validation loss: 2.372119137528684

Epoch: 6| Step: 4
Training loss: 1.887803423410895
Validation loss: 2.4118831896973645

Epoch: 6| Step: 5
Training loss: 1.5282989402958518
Validation loss: 2.42070354296382

Epoch: 6| Step: 6
Training loss: 2.6887469393022427
Validation loss: 2.384235062740622

Epoch: 6| Step: 7
Training loss: 1.3117144368176323
Validation loss: 2.358992982136

Epoch: 6| Step: 8
Training loss: 1.595652772069303
Validation loss: 2.3296603056932854

Epoch: 6| Step: 9
Training loss: 1.436548000724734
Validation loss: 2.3626776283455193

Epoch: 6| Step: 10
Training loss: 1.4129607402857545
Validation loss: 2.33156893055498

Epoch: 6| Step: 11
Training loss: 1.327180683791242
Validation loss: 2.399286326566049

Epoch: 6| Step: 12
Training loss: 1.407901048997951
Validation loss: 2.352417978004563

Epoch: 6| Step: 13
Training loss: 1.8517693512694564
Validation loss: 2.456513455130478

Epoch: 288| Step: 0
Training loss: 1.3062769179787614
Validation loss: 2.3723747313984345

Epoch: 6| Step: 1
Training loss: 2.1947663737684713
Validation loss: 2.4050685697446665

Epoch: 6| Step: 2
Training loss: 1.7582144722681485
Validation loss: 2.3942172980810317

Epoch: 6| Step: 3
Training loss: 1.0913010018786544
Validation loss: 2.4013511369833838

Epoch: 6| Step: 4
Training loss: 1.6343798985599316
Validation loss: 2.303625545066594

Epoch: 6| Step: 5
Training loss: 1.4113930643716412
Validation loss: 2.363435849982577

Epoch: 6| Step: 6
Training loss: 2.088971164392961
Validation loss: 2.334884098193829

Epoch: 6| Step: 7
Training loss: 1.4897692193130936
Validation loss: 2.29854164265993

Epoch: 6| Step: 8
Training loss: 1.5727247243149958
Validation loss: 2.379667069279391

Epoch: 6| Step: 9
Training loss: 1.4666505783817025
Validation loss: 2.387421020909222

Epoch: 6| Step: 10
Training loss: 1.6477546904862785
Validation loss: 2.376008206731288

Epoch: 6| Step: 11
Training loss: 1.6222830580636496
Validation loss: 2.394962648723063

Epoch: 6| Step: 12
Training loss: 2.318558566270395
Validation loss: 2.3630863416790686

Epoch: 6| Step: 13
Training loss: 1.8884327686836984
Validation loss: 2.3235357083152754

Epoch: 289| Step: 0
Training loss: 1.4094046494437706
Validation loss: 2.415377959270283

Epoch: 6| Step: 1
Training loss: 1.1239713628589376
Validation loss: 2.3894454251814174

Epoch: 6| Step: 2
Training loss: 1.809010863352179
Validation loss: 2.3465841810047694

Epoch: 6| Step: 3
Training loss: 1.69012585955679
Validation loss: 2.3935127433526167

Epoch: 6| Step: 4
Training loss: 1.3151581504493517
Validation loss: 2.391156822082115

Epoch: 6| Step: 5
Training loss: 1.4000952926629628
Validation loss: 2.31812461293809

Epoch: 6| Step: 6
Training loss: 1.9672968512116704
Validation loss: 2.3813053937381725

Epoch: 6| Step: 7
Training loss: 1.8150925346304634
Validation loss: 2.375047024799419

Epoch: 6| Step: 8
Training loss: 2.1940751576516964
Validation loss: 2.4077567917699496

Epoch: 6| Step: 9
Training loss: 1.5247849985119253
Validation loss: 2.3408506884647577

Epoch: 6| Step: 10
Training loss: 1.658632975333239
Validation loss: 2.3799001167862586

Epoch: 6| Step: 11
Training loss: 2.338665953960477
Validation loss: 2.3799970083389375

Epoch: 6| Step: 12
Training loss: 1.6002045619850462
Validation loss: 2.3955133325167135

Epoch: 6| Step: 13
Training loss: 1.7111538963555966
Validation loss: 2.3719688614746826

Epoch: 290| Step: 0
Training loss: 1.631469539324075
Validation loss: 2.3810539600499196

Epoch: 6| Step: 1
Training loss: 2.301124637800797
Validation loss: 2.437569817320647

Epoch: 6| Step: 2
Training loss: 1.6202850898624044
Validation loss: 2.3772942138230784

Epoch: 6| Step: 3
Training loss: 1.2197790447638637
Validation loss: 2.4060968841219306

Epoch: 6| Step: 4
Training loss: 1.8312778509840835
Validation loss: 2.425643419479583

Epoch: 6| Step: 5
Training loss: 1.6239902586997135
Validation loss: 2.3907884239912782

Epoch: 6| Step: 6
Training loss: 1.671864375856102
Validation loss: 2.442262792873626

Epoch: 6| Step: 7
Training loss: 1.682008922267478
Validation loss: 2.387361548181029

Epoch: 6| Step: 8
Training loss: 1.7302572495697628
Validation loss: 2.3669227688431023

Epoch: 6| Step: 9
Training loss: 1.5351977937236236
Validation loss: 2.366559763355228

Epoch: 6| Step: 10
Training loss: 2.0026732698645775
Validation loss: 2.3894244509293108

Epoch: 6| Step: 11
Training loss: 1.2005142024168094
Validation loss: 2.3799184313575577

Epoch: 6| Step: 12
Training loss: 1.73002112392252
Validation loss: 2.38465162204293

Epoch: 6| Step: 13
Training loss: 1.405202517863862
Validation loss: 2.393590475630619

Epoch: 291| Step: 0
Training loss: 1.628891466837519
Validation loss: 2.4163234493139862

Epoch: 6| Step: 1
Training loss: 1.6459141803955926
Validation loss: 2.368353659158462

Epoch: 6| Step: 2
Training loss: 1.5033354233235945
Validation loss: 2.347279689462585

Epoch: 6| Step: 3
Training loss: 1.8472874214820816
Validation loss: 2.3325290531661147

Epoch: 6| Step: 4
Training loss: 1.531919371990665
Validation loss: 2.3622859032032832

Epoch: 6| Step: 5
Training loss: 1.293271769716663
Validation loss: 2.3934499192073937

Epoch: 6| Step: 6
Training loss: 1.682675777396028
Validation loss: 2.403189980734767

Epoch: 6| Step: 7
Training loss: 1.6094010730594297
Validation loss: 2.4350715047837084

Epoch: 6| Step: 8
Training loss: 1.675196832507399
Validation loss: 2.3675650478936574

Epoch: 6| Step: 9
Training loss: 1.5660707490220174
Validation loss: 2.402772823139505

Epoch: 6| Step: 10
Training loss: 2.49159659432806
Validation loss: 2.3049070809504664

Epoch: 6| Step: 11
Training loss: 0.9739325854864058
Validation loss: 2.3125174227132765

Epoch: 6| Step: 12
Training loss: 1.7643212425158301
Validation loss: 2.3159380628489177

Epoch: 6| Step: 13
Training loss: 1.4111164659655502
Validation loss: 2.4092856474642024

Epoch: 292| Step: 0
Training loss: 1.3330338360268856
Validation loss: 2.3893310811398223

Epoch: 6| Step: 1
Training loss: 2.426454312479033
Validation loss: 2.3695580878632483

Epoch: 6| Step: 2
Training loss: 1.592827922887828
Validation loss: 2.3816077166963785

Epoch: 6| Step: 3
Training loss: 2.4078754038085344
Validation loss: 2.398163419364752

Epoch: 6| Step: 4
Training loss: 1.5134350400656968
Validation loss: 2.3874330175034424

Epoch: 6| Step: 5
Training loss: 1.9412753945659016
Validation loss: 2.3837745073454215

Epoch: 6| Step: 6
Training loss: 1.5972517849310208
Validation loss: 2.3623764558335676

Epoch: 6| Step: 7
Training loss: 1.920544667871347
Validation loss: 2.400958435724405

Epoch: 6| Step: 8
Training loss: 1.6489017790950016
Validation loss: 2.3707874299779377

Epoch: 6| Step: 9
Training loss: 1.7864244493064447
Validation loss: 2.384357339873736

Epoch: 6| Step: 10
Training loss: 1.172016135299981
Validation loss: 2.388056975819051

Epoch: 6| Step: 11
Training loss: 1.3955491569059186
Validation loss: 2.38528855660388

Epoch: 6| Step: 12
Training loss: 1.569597679391948
Validation loss: 2.4163437641036873

Epoch: 6| Step: 13
Training loss: 1.275867320496096
Validation loss: 2.3112949500829663

Epoch: 293| Step: 0
Training loss: 1.3354595734859072
Validation loss: 2.392029609344881

Epoch: 6| Step: 1
Training loss: 1.6975701413389743
Validation loss: 2.4153047238077976

Epoch: 6| Step: 2
Training loss: 1.4609656509706312
Validation loss: 2.3887183408804487

Epoch: 6| Step: 3
Training loss: 1.7963976682146254
Validation loss: 2.42877900724762

Epoch: 6| Step: 4
Training loss: 2.2008046586021
Validation loss: 2.380584825603267

Epoch: 6| Step: 5
Training loss: 1.123146490571801
Validation loss: 2.40024080418618

Epoch: 6| Step: 6
Training loss: 1.4993514407279938
Validation loss: 2.4242198039586196

Epoch: 6| Step: 7
Training loss: 2.2289527243747362
Validation loss: 2.4740101612061554

Epoch: 6| Step: 8
Training loss: 1.813471106468132
Validation loss: 2.472264154424327

Epoch: 6| Step: 9
Training loss: 1.6437595758775627
Validation loss: 2.4048685285417037

Epoch: 6| Step: 10
Training loss: 1.501223700782958
Validation loss: 2.3822102092635453

Epoch: 6| Step: 11
Training loss: 1.4568952645259357
Validation loss: 2.384888109269896

Epoch: 6| Step: 12
Training loss: 2.153085791863395
Validation loss: 2.334877522421867

Epoch: 6| Step: 13
Training loss: 1.582923543335565
Validation loss: 2.4330076622856773

Epoch: 294| Step: 0
Training loss: 1.4052284769019388
Validation loss: 2.3219243545773134

Epoch: 6| Step: 1
Training loss: 1.8174603428770897
Validation loss: 2.34851312307409

Epoch: 6| Step: 2
Training loss: 1.403370261050023
Validation loss: 2.2795533025984

Epoch: 6| Step: 3
Training loss: 1.9275947373358928
Validation loss: 2.3226194647295926

Epoch: 6| Step: 4
Training loss: 1.5350059066807924
Validation loss: 2.400801382190672

Epoch: 6| Step: 5
Training loss: 1.5197653308213743
Validation loss: 2.4175542687263203

Epoch: 6| Step: 6
Training loss: 2.1834820495314866
Validation loss: 2.3418817365614886

Epoch: 6| Step: 7
Training loss: 1.3004378131751126
Validation loss: 2.3810186951861456

Epoch: 6| Step: 8
Training loss: 2.1472244444727724
Validation loss: 2.3150064741751213

Epoch: 6| Step: 9
Training loss: 1.2029545650891995
Validation loss: 2.443832069363575

Epoch: 6| Step: 10
Training loss: 1.5769489551911446
Validation loss: 2.3856372724973496

Epoch: 6| Step: 11
Training loss: 1.8332966743040813
Validation loss: 2.366583315854599

Epoch: 6| Step: 12
Training loss: 1.7515895980930307
Validation loss: 2.369322441747867

Epoch: 6| Step: 13
Training loss: 1.8355950218716732
Validation loss: 2.4239995269685584

Epoch: 295| Step: 0
Training loss: 1.361657998879594
Validation loss: 2.325145551196744

Epoch: 6| Step: 1
Training loss: 1.5974635075563521
Validation loss: 2.4016953206907545

Epoch: 6| Step: 2
Training loss: 1.643291014783501
Validation loss: 2.3525021812701987

Epoch: 6| Step: 3
Training loss: 1.7161741895942675
Validation loss: 2.3900871682572125

Epoch: 6| Step: 4
Training loss: 2.449354055460636
Validation loss: 2.368274912361032

Epoch: 6| Step: 5
Training loss: 1.9710168654921665
Validation loss: 2.3480509660834197

Epoch: 6| Step: 6
Training loss: 1.3916126986944768
Validation loss: 2.3853203406155843

Epoch: 6| Step: 7
Training loss: 1.2455303389300931
Validation loss: 2.4026022553808377

Epoch: 6| Step: 8
Training loss: 1.4159918842298618
Validation loss: 2.3465706678469718

Epoch: 6| Step: 9
Training loss: 1.3591929346692415
Validation loss: 2.454929753622577

Epoch: 6| Step: 10
Training loss: 1.6002915712763548
Validation loss: 2.334060395991387

Epoch: 6| Step: 11
Training loss: 1.8346997573071433
Validation loss: 2.2892064261352214

Epoch: 6| Step: 12
Training loss: 1.1359113729586463
Validation loss: 2.39146905912853

Epoch: 6| Step: 13
Training loss: 2.3534768255684075
Validation loss: 2.366407962078663

Epoch: 296| Step: 0
Training loss: 1.5957034238257064
Validation loss: 2.3213825362575693

Epoch: 6| Step: 1
Training loss: 1.291252726194711
Validation loss: 2.3775659364516146

Epoch: 6| Step: 2
Training loss: 1.9032121434798037
Validation loss: 2.294429348448836

Epoch: 6| Step: 3
Training loss: 1.9811121029202658
Validation loss: 2.3558502108780144

Epoch: 6| Step: 4
Training loss: 1.4792453673294863
Validation loss: 2.379808798200255

Epoch: 6| Step: 5
Training loss: 1.1527854977902026
Validation loss: 2.431167926515999

Epoch: 6| Step: 6
Training loss: 1.296319773754071
Validation loss: 2.4191014821693235

Epoch: 6| Step: 7
Training loss: 1.725025303972937
Validation loss: 2.429868100204496

Epoch: 6| Step: 8
Training loss: 1.5227470202569486
Validation loss: 2.372519570325504

Epoch: 6| Step: 9
Training loss: 1.555877383561514
Validation loss: 2.431110277955382

Epoch: 6| Step: 10
Training loss: 1.4788532551874165
Validation loss: 2.3801738242587693

Epoch: 6| Step: 11
Training loss: 1.9065115702288256
Validation loss: 2.3311528218470317

Epoch: 6| Step: 12
Training loss: 2.357535952863279
Validation loss: 2.2989794441161324

Epoch: 6| Step: 13
Training loss: 1.7447711620739152
Validation loss: 2.3787609474703117

Epoch: 297| Step: 0
Training loss: 1.9437303351974515
Validation loss: 2.3253155070272884

Epoch: 6| Step: 1
Training loss: 0.8358277578602133
Validation loss: 2.3833346166879044

Epoch: 6| Step: 2
Training loss: 2.1646064597966665
Validation loss: 2.386711768159972

Epoch: 6| Step: 3
Training loss: 1.64572658273099
Validation loss: 2.385464190403622

Epoch: 6| Step: 4
Training loss: 1.4985874200471863
Validation loss: 2.363993476593271

Epoch: 6| Step: 5
Training loss: 1.8041845504309002
Validation loss: 2.415304142152314

Epoch: 6| Step: 6
Training loss: 1.563834726552469
Validation loss: 2.339698553215399

Epoch: 6| Step: 7
Training loss: 1.6448711850362474
Validation loss: 2.369058274342306

Epoch: 6| Step: 8
Training loss: 0.9086353217050483
Validation loss: 2.3219552206393828

Epoch: 6| Step: 9
Training loss: 1.8906644706704354
Validation loss: 2.4340335544200506

Epoch: 6| Step: 10
Training loss: 1.6636464489841005
Validation loss: 2.412086775067171

Epoch: 6| Step: 11
Training loss: 1.770600187623977
Validation loss: 2.4428522074742727

Epoch: 6| Step: 12
Training loss: 1.6881030382735436
Validation loss: 2.3394086153329376

Epoch: 6| Step: 13
Training loss: 2.1674803037529506
Validation loss: 2.3871481959403704

Epoch: 298| Step: 0
Training loss: 1.4391312672838004
Validation loss: 2.3868871769420497

Epoch: 6| Step: 1
Training loss: 1.2262888803646876
Validation loss: 2.3316947128171424

Epoch: 6| Step: 2
Training loss: 1.9437968159523626
Validation loss: 2.4240801930694906

Epoch: 6| Step: 3
Training loss: 1.6172327597361544
Validation loss: 2.367291215690113

Epoch: 6| Step: 4
Training loss: 1.8955973034604678
Validation loss: 2.3731083452676294

Epoch: 6| Step: 5
Training loss: 1.462727801196055
Validation loss: 2.3326274475035826

Epoch: 6| Step: 6
Training loss: 1.6184067852010025
Validation loss: 2.391190374817709

Epoch: 6| Step: 7
Training loss: 1.7743226921645836
Validation loss: 2.3823018232013817

Epoch: 6| Step: 8
Training loss: 1.6300709171899115
Validation loss: 2.367595645950096

Epoch: 6| Step: 9
Training loss: 1.8206568707375217
Validation loss: 2.383997939720263

Epoch: 6| Step: 10
Training loss: 1.521006517696022
Validation loss: 2.378685731054582

Epoch: 6| Step: 11
Training loss: 2.3415189169250525
Validation loss: 2.383381950320848

Epoch: 6| Step: 12
Training loss: 1.3844208066091535
Validation loss: 2.3617524021910428

Epoch: 6| Step: 13
Training loss: 1.38965662982641
Validation loss: 2.362552878183099

Epoch: 299| Step: 0
Training loss: 1.5738689327369966
Validation loss: 2.3096437000425456

Epoch: 6| Step: 1
Training loss: 1.945329597122251
Validation loss: 2.383396642325841

Epoch: 6| Step: 2
Training loss: 2.098198790333586
Validation loss: 2.334349406821774

Epoch: 6| Step: 3
Training loss: 1.436300440633773
Validation loss: 2.3832573039621234

Epoch: 6| Step: 4
Training loss: 1.5152906855332473
Validation loss: 2.389503698066893

Epoch: 6| Step: 5
Training loss: 1.5414643885247845
Validation loss: 2.389931457193297

Epoch: 6| Step: 6
Training loss: 1.5233747420466872
Validation loss: 2.3730614981130493

Epoch: 6| Step: 7
Training loss: 1.3143833816413446
Validation loss: 2.4182123821560086

Epoch: 6| Step: 8
Training loss: 0.9182434644936476
Validation loss: 2.4239664680407245

Epoch: 6| Step: 9
Training loss: 1.750654370716278
Validation loss: 2.356640482884983

Epoch: 6| Step: 10
Training loss: 1.5247327726772886
Validation loss: 2.3214591775350764

Epoch: 6| Step: 11
Training loss: 1.109746736381185
Validation loss: 2.369401185108139

Epoch: 6| Step: 12
Training loss: 1.9278974995492657
Validation loss: 2.3427572432542036

Epoch: 6| Step: 13
Training loss: 2.610941981751792
Validation loss: 2.393120222928188

Epoch: 300| Step: 0
Training loss: 1.5093902871441736
Validation loss: 2.377731854802872

Epoch: 6| Step: 1
Training loss: 2.549654514619755
Validation loss: 2.3187798105016357

Epoch: 6| Step: 2
Training loss: 1.864040004341877
Validation loss: 2.4562327300661244

Epoch: 6| Step: 3
Training loss: 1.5882024517486675
Validation loss: 2.406067816671199

Epoch: 6| Step: 4
Training loss: 1.0110966010385827
Validation loss: 2.4057912614325603

Epoch: 6| Step: 5
Training loss: 2.03553425798329
Validation loss: 2.375732447098842

Epoch: 6| Step: 6
Training loss: 1.5361810811214156
Validation loss: 2.3405410817931993

Epoch: 6| Step: 7
Training loss: 1.0992999818850286
Validation loss: 2.426370064807532

Epoch: 6| Step: 8
Training loss: 1.407476864856688
Validation loss: 2.4214259784307557

Epoch: 6| Step: 9
Training loss: 1.8386841053309775
Validation loss: 2.3812051893901485

Epoch: 6| Step: 10
Training loss: 1.49771595946807
Validation loss: 2.4082153470103203

Epoch: 6| Step: 11
Training loss: 1.6991231255645505
Validation loss: 2.3715601839358302

Epoch: 6| Step: 12
Training loss: 1.6605795645967842
Validation loss: 2.3511267575067927

Epoch: 6| Step: 13
Training loss: 1.4428106150078808
Validation loss: 2.4048079404682823

Epoch: 301| Step: 0
Training loss: 1.8589630311693324
Validation loss: 2.4393266722767195

Epoch: 6| Step: 1
Training loss: 1.370687832207544
Validation loss: 2.3495759633348334

Epoch: 6| Step: 2
Training loss: 1.5723108131122756
Validation loss: 2.3721270247456276

Epoch: 6| Step: 3
Training loss: 1.5454054508469046
Validation loss: 2.318690229823635

Epoch: 6| Step: 4
Training loss: 1.5789511755847205
Validation loss: 2.3208761383104695

Epoch: 6| Step: 5
Training loss: 2.35734986556342
Validation loss: 2.307463795045895

Epoch: 6| Step: 6
Training loss: 1.2635993288138003
Validation loss: 2.393576027203913

Epoch: 6| Step: 7
Training loss: 1.298078507099109
Validation loss: 2.4029333341400303

Epoch: 6| Step: 8
Training loss: 1.2624308463315561
Validation loss: 2.344895233044877

Epoch: 6| Step: 9
Training loss: 1.4184466941049756
Validation loss: 2.471727572755909

Epoch: 6| Step: 10
Training loss: 1.5344488246584196
Validation loss: 2.358480710895741

Epoch: 6| Step: 11
Training loss: 1.8742727140709314
Validation loss: 2.3714563273938234

Epoch: 6| Step: 12
Training loss: 1.7462260560979388
Validation loss: 2.4557440389778904

Epoch: 6| Step: 13
Training loss: 1.8828782192806197
Validation loss: 2.309065364786979

Epoch: 302| Step: 0
Training loss: 1.2458099711767632
Validation loss: 2.4660724633699695

Epoch: 6| Step: 1
Training loss: 1.764969830781976
Validation loss: 2.394373647477049

Epoch: 6| Step: 2
Training loss: 2.1094897203685483
Validation loss: 2.343025466335386

Epoch: 6| Step: 3
Training loss: 1.578440039886987
Validation loss: 2.3482448614012053

Epoch: 6| Step: 4
Training loss: 1.5661068294815896
Validation loss: 2.3887825877682234

Epoch: 6| Step: 5
Training loss: 1.8965927391639756
Validation loss: 2.353688989720926

Epoch: 6| Step: 6
Training loss: 1.6410165955182652
Validation loss: 2.348871481085379

Epoch: 6| Step: 7
Training loss: 1.5718904225254526
Validation loss: 2.3961194028555464

Epoch: 6| Step: 8
Training loss: 1.155238508146279
Validation loss: 2.3990184426013257

Epoch: 6| Step: 9
Training loss: 1.7842531820693524
Validation loss: 2.286623650526554

Epoch: 6| Step: 10
Training loss: 1.5193672778154201
Validation loss: 2.376096798734419

Epoch: 6| Step: 11
Training loss: 1.8347096334534558
Validation loss: 2.3471839430641626

Epoch: 6| Step: 12
Training loss: 1.2063570577915494
Validation loss: 2.334569838155614

Epoch: 6| Step: 13
Training loss: 1.9407332729536193
Validation loss: 2.3873473992436236

Epoch: 303| Step: 0
Training loss: 2.045772109763316
Validation loss: 2.325457296344184

Epoch: 6| Step: 1
Training loss: 1.5337766704401188
Validation loss: 2.375013967752537

Epoch: 6| Step: 2
Training loss: 2.4741158418541307
Validation loss: 2.3059431751284674

Epoch: 6| Step: 3
Training loss: 1.4751985901157652
Validation loss: 2.32850337004403

Epoch: 6| Step: 4
Training loss: 1.5576784127857366
Validation loss: 2.3893880043889277

Epoch: 6| Step: 5
Training loss: 1.0537249093106076
Validation loss: 2.3971683262228454

Epoch: 6| Step: 6
Training loss: 1.9170821679364698
Validation loss: 2.373701555610429

Epoch: 6| Step: 7
Training loss: 1.4753356357757028
Validation loss: 2.364517790140001

Epoch: 6| Step: 8
Training loss: 1.6231668843361478
Validation loss: 2.328545204787775

Epoch: 6| Step: 9
Training loss: 1.3429615457728798
Validation loss: 2.3333050825749764

Epoch: 6| Step: 10
Training loss: 1.7787001579630746
Validation loss: 2.3582245906189128

Epoch: 6| Step: 11
Training loss: 1.6841359692543834
Validation loss: 2.3931657358110283

Epoch: 6| Step: 12
Training loss: 1.161912250629602
Validation loss: 2.391007460031628

Epoch: 6| Step: 13
Training loss: 1.6092746295925744
Validation loss: 2.362739153549185

Epoch: 304| Step: 0
Training loss: 1.5727874837546159
Validation loss: 2.4135846445161167

Epoch: 6| Step: 1
Training loss: 1.2504245990593512
Validation loss: 2.2955765175217793

Epoch: 6| Step: 2
Training loss: 1.6663727103719734
Validation loss: 2.439245998017209

Epoch: 6| Step: 3
Training loss: 1.4142618618367058
Validation loss: 2.45357904307362

Epoch: 6| Step: 4
Training loss: 2.3643958623794084
Validation loss: 2.33719745376015

Epoch: 6| Step: 5
Training loss: 1.3600481493224208
Validation loss: 2.4160792876688046

Epoch: 6| Step: 6
Training loss: 1.842998028013651
Validation loss: 2.311937014742067

Epoch: 6| Step: 7
Training loss: 1.611277816449487
Validation loss: 2.3560206008080247

Epoch: 6| Step: 8
Training loss: 1.5317175015276427
Validation loss: 2.3581838952615253

Epoch: 6| Step: 9
Training loss: 1.350332946693166
Validation loss: 2.37107763457077

Epoch: 6| Step: 10
Training loss: 1.6107038918692396
Validation loss: 2.3800055405181815

Epoch: 6| Step: 11
Training loss: 1.2506768778155017
Validation loss: 2.4164125837930372

Epoch: 6| Step: 12
Training loss: 1.4154893620669693
Validation loss: 2.3692898068914365

Epoch: 6| Step: 13
Training loss: 1.9011245988149004
Validation loss: 2.3741558865438663

Epoch: 305| Step: 0
Training loss: 1.654116353856075
Validation loss: 2.3193478153876668

Epoch: 6| Step: 1
Training loss: 1.7449914922206249
Validation loss: 2.324883833259066

Epoch: 6| Step: 2
Training loss: 1.383992354509702
Validation loss: 2.3224160015228925

Epoch: 6| Step: 3
Training loss: 1.4787950541452006
Validation loss: 2.4124005140700078

Epoch: 6| Step: 4
Training loss: 2.4044278664623633
Validation loss: 2.3448003393847143

Epoch: 6| Step: 5
Training loss: 1.4116732819607485
Validation loss: 2.3824768109679035

Epoch: 6| Step: 6
Training loss: 1.217822871547013
Validation loss: 2.427786106943136

Epoch: 6| Step: 7
Training loss: 1.5951929479146592
Validation loss: 2.356284795361499

Epoch: 6| Step: 8
Training loss: 1.668079595880469
Validation loss: 2.3725499694171908

Epoch: 6| Step: 9
Training loss: 1.2874420152958437
Validation loss: 2.360986028233753

Epoch: 6| Step: 10
Training loss: 1.8495439560145908
Validation loss: 2.385543669043115

Epoch: 6| Step: 11
Training loss: 1.1745273329281392
Validation loss: 2.3767400367951064

Epoch: 6| Step: 12
Training loss: 0.86138382988892
Validation loss: 2.40977295775673

Epoch: 6| Step: 13
Training loss: 1.9861855844912
Validation loss: 2.3724816289939716

Epoch: 306| Step: 0
Training loss: 1.3973007270257989
Validation loss: 2.3415897457763895

Epoch: 6| Step: 1
Training loss: 1.1705790156402514
Validation loss: 2.3488191260002487

Epoch: 6| Step: 2
Training loss: 1.787498223363887
Validation loss: 2.404914969836262

Epoch: 6| Step: 3
Training loss: 1.444132059911289
Validation loss: 2.312028575760008

Epoch: 6| Step: 4
Training loss: 1.3231109666688292
Validation loss: 2.356642941395246

Epoch: 6| Step: 5
Training loss: 2.5091499731276494
Validation loss: 2.359315370119775

Epoch: 6| Step: 6
Training loss: 1.6695752592806283
Validation loss: 2.396890220064861

Epoch: 6| Step: 7
Training loss: 1.632680349158425
Validation loss: 2.404144729864218

Epoch: 6| Step: 8
Training loss: 1.735093251561359
Validation loss: 2.3752989416230075

Epoch: 6| Step: 9
Training loss: 1.8619232667299117
Validation loss: 2.3917148332982574

Epoch: 6| Step: 10
Training loss: 1.4309655818945375
Validation loss: 2.393562208471363

Epoch: 6| Step: 11
Training loss: 1.8719099649720523
Validation loss: 2.387412292951735

Epoch: 6| Step: 12
Training loss: 1.2608547972982436
Validation loss: 2.353346150142371

Epoch: 6| Step: 13
Training loss: 1.5925488152799847
Validation loss: 2.290053773468881

Epoch: 307| Step: 0
Training loss: 1.9703990145875587
Validation loss: 2.3545749403569585

Epoch: 6| Step: 1
Training loss: 1.1809058561019807
Validation loss: 2.3538479826598

Epoch: 6| Step: 2
Training loss: 1.1464554687183233
Validation loss: 2.476584427716005

Epoch: 6| Step: 3
Training loss: 1.745395870830066
Validation loss: 2.3491597692336295

Epoch: 6| Step: 4
Training loss: 1.094007407280151
Validation loss: 2.3664091342596754

Epoch: 6| Step: 5
Training loss: 1.2396570979804962
Validation loss: 2.4298235934236607

Epoch: 6| Step: 6
Training loss: 2.6623035340512686
Validation loss: 2.428898638731816

Epoch: 6| Step: 7
Training loss: 1.6250770990714982
Validation loss: 2.3467794690743973

Epoch: 6| Step: 8
Training loss: 1.4652792321429435
Validation loss: 2.4418131722582386

Epoch: 6| Step: 9
Training loss: 1.7076676009711298
Validation loss: 2.350252969104124

Epoch: 6| Step: 10
Training loss: 1.2042505028303703
Validation loss: 2.4026186565914918

Epoch: 6| Step: 11
Training loss: 1.5625561513347987
Validation loss: 2.331274579765417

Epoch: 6| Step: 12
Training loss: 1.4293524344280595
Validation loss: 2.390411341668496

Epoch: 6| Step: 13
Training loss: 1.9583996768291991
Validation loss: 2.356234339854616

Epoch: 308| Step: 0
Training loss: 1.7569658741337246
Validation loss: 2.4015825921440306

Epoch: 6| Step: 1
Training loss: 1.4651433612866402
Validation loss: 2.3698967972651532

Epoch: 6| Step: 2
Training loss: 1.60137633195321
Validation loss: 2.3595498605685505

Epoch: 6| Step: 3
Training loss: 1.3563514495737239
Validation loss: 2.3777951845336895

Epoch: 6| Step: 4
Training loss: 1.3698430021503052
Validation loss: 2.3601019269930354

Epoch: 6| Step: 5
Training loss: 1.4077404600757433
Validation loss: 2.318046071985642

Epoch: 6| Step: 6
Training loss: 1.7109873864552265
Validation loss: 2.362824764045875

Epoch: 6| Step: 7
Training loss: 1.040299446571802
Validation loss: 2.389026180936566

Epoch: 6| Step: 8
Training loss: 1.7285618317888252
Validation loss: 2.425006693323453

Epoch: 6| Step: 9
Training loss: 1.1881151112040085
Validation loss: 2.3729958424815214

Epoch: 6| Step: 10
Training loss: 1.7000899263046596
Validation loss: 2.3633873282720828

Epoch: 6| Step: 11
Training loss: 1.4376931268079178
Validation loss: 2.3658600723541983

Epoch: 6| Step: 12
Training loss: 2.5908961394623593
Validation loss: 2.347329989051924

Epoch: 6| Step: 13
Training loss: 1.9523403575267833
Validation loss: 2.422470291127217

Epoch: 309| Step: 0
Training loss: 1.4296758265618035
Validation loss: 2.348484959038653

Epoch: 6| Step: 1
Training loss: 1.4517392349645473
Validation loss: 2.3603270992721126

Epoch: 6| Step: 2
Training loss: 1.723132286125555
Validation loss: 2.3518642441395428

Epoch: 6| Step: 3
Training loss: 1.556405043634553
Validation loss: 2.3330895868635095

Epoch: 6| Step: 4
Training loss: 2.1680585962871977
Validation loss: 2.2958790183209477

Epoch: 6| Step: 5
Training loss: 1.4725650182336314
Validation loss: 2.3779363587594924

Epoch: 6| Step: 6
Training loss: 1.9765983246583603
Validation loss: 2.3935178534638744

Epoch: 6| Step: 7
Training loss: 0.9272484078762593
Validation loss: 2.4204707589008945

Epoch: 6| Step: 8
Training loss: 1.750741324763176
Validation loss: 2.389104290970018

Epoch: 6| Step: 9
Training loss: 1.8281940544975712
Validation loss: 2.404820532593997

Epoch: 6| Step: 10
Training loss: 1.6553944231227666
Validation loss: 2.345411550932258

Epoch: 6| Step: 11
Training loss: 1.6021508601541326
Validation loss: 2.324454879588827

Epoch: 6| Step: 12
Training loss: 1.6312465916155874
Validation loss: 2.3725078786790497

Epoch: 6| Step: 13
Training loss: 1.1457396497864485
Validation loss: 2.3468909996410052

Epoch: 310| Step: 0
Training loss: 1.564731377896265
Validation loss: 2.377769002382952

Epoch: 6| Step: 1
Training loss: 1.9170199220723594
Validation loss: 2.4114855288999903

Epoch: 6| Step: 2
Training loss: 1.4191529764592898
Validation loss: 2.3508343632055486

Epoch: 6| Step: 3
Training loss: 2.4141122757307674
Validation loss: 2.3515440795992437

Epoch: 6| Step: 4
Training loss: 1.3976752052279822
Validation loss: 2.4075410253733516

Epoch: 6| Step: 5
Training loss: 1.7514726709340367
Validation loss: 2.4060513878284047

Epoch: 6| Step: 6
Training loss: 1.6730676122890333
Validation loss: 2.347400514786061

Epoch: 6| Step: 7
Training loss: 1.4479761271537348
Validation loss: 2.3632346387060066

Epoch: 6| Step: 8
Training loss: 1.6369764903482893
Validation loss: 2.3922037274613137

Epoch: 6| Step: 9
Training loss: 1.4458678132415563
Validation loss: 2.3480295254402828

Epoch: 6| Step: 10
Training loss: 1.3848909609181557
Validation loss: 2.3852774907287944

Epoch: 6| Step: 11
Training loss: 1.399509935096401
Validation loss: 2.3909391116007694

Epoch: 6| Step: 12
Training loss: 1.5034867134991439
Validation loss: 2.3376434798922707

Epoch: 6| Step: 13
Training loss: 1.700236259199635
Validation loss: 2.351401240691246

Epoch: 311| Step: 0
Training loss: 1.650088238524162
Validation loss: 2.467241755133967

Epoch: 6| Step: 1
Training loss: 1.601801263642905
Validation loss: 2.370714871656942

Epoch: 6| Step: 2
Training loss: 1.3808035185009893
Validation loss: 2.3836486371483265

Epoch: 6| Step: 3
Training loss: 1.5232157227894794
Validation loss: 2.3441419868410533

Epoch: 6| Step: 4
Training loss: 1.5270690670969025
Validation loss: 2.382398776336426

Epoch: 6| Step: 5
Training loss: 2.566781351904343
Validation loss: 2.44380157821629

Epoch: 6| Step: 6
Training loss: 1.6204320821162066
Validation loss: 2.3791656172242024

Epoch: 6| Step: 7
Training loss: 1.2580071055874187
Validation loss: 2.333553488588155

Epoch: 6| Step: 8
Training loss: 1.3101419428736278
Validation loss: 2.4057787820151515

Epoch: 6| Step: 9
Training loss: 1.0952934274359762
Validation loss: 2.4093089504123038

Epoch: 6| Step: 10
Training loss: 1.703372342408889
Validation loss: 2.387051328311263

Epoch: 6| Step: 11
Training loss: 1.5231736174702868
Validation loss: 2.3631142270038397

Epoch: 6| Step: 12
Training loss: 1.550836595753568
Validation loss: 2.411878057910631

Epoch: 6| Step: 13
Training loss: 2.2130393022924855
Validation loss: 2.409283536354939

Epoch: 312| Step: 0
Training loss: 1.4824338568201962
Validation loss: 2.405588502042625

Epoch: 6| Step: 1
Training loss: 1.1133434612894713
Validation loss: 2.409384057791516

Epoch: 6| Step: 2
Training loss: 1.5695423116336886
Validation loss: 2.38356719267673

Epoch: 6| Step: 3
Training loss: 1.455097869124644
Validation loss: 2.380571400988471

Epoch: 6| Step: 4
Training loss: 1.8996079843568192
Validation loss: 2.408878053625991

Epoch: 6| Step: 5
Training loss: 1.0231170152505242
Validation loss: 2.4076982137243768

Epoch: 6| Step: 6
Training loss: 1.7360429046796129
Validation loss: 2.34406070632291

Epoch: 6| Step: 7
Training loss: 1.7992023820087004
Validation loss: 2.3674625786653993

Epoch: 6| Step: 8
Training loss: 1.8374848034288696
Validation loss: 2.366600102094125

Epoch: 6| Step: 9
Training loss: 1.5657938000105924
Validation loss: 2.3735954425406565

Epoch: 6| Step: 10
Training loss: 2.232873158468497
Validation loss: 2.3289997521867756

Epoch: 6| Step: 11
Training loss: 1.5178089727243331
Validation loss: 2.345107822669411

Epoch: 6| Step: 12
Training loss: 1.4807631066621554
Validation loss: 2.3829034549561974

Epoch: 6| Step: 13
Training loss: 1.135194050841439
Validation loss: 2.3347608693871336

Epoch: 313| Step: 0
Training loss: 1.4331195265228318
Validation loss: 2.389354223557178

Epoch: 6| Step: 1
Training loss: 1.960438030206242
Validation loss: 2.4690288896564834

Epoch: 6| Step: 2
Training loss: 1.472184244701695
Validation loss: 2.37885349065046

Epoch: 6| Step: 3
Training loss: 1.5742067852464823
Validation loss: 2.4522211340260798

Epoch: 6| Step: 4
Training loss: 1.627809150503414
Validation loss: 2.322365845636245

Epoch: 6| Step: 5
Training loss: 2.509085073860078
Validation loss: 2.3676088907643424

Epoch: 6| Step: 6
Training loss: 0.9860389512185408
Validation loss: 2.3048123222463555

Epoch: 6| Step: 7
Training loss: 1.73124412232651
Validation loss: 2.359608476280257

Epoch: 6| Step: 8
Training loss: 1.106190530072888
Validation loss: 2.4131089418725495

Epoch: 6| Step: 9
Training loss: 1.8064703783805336
Validation loss: 2.357033026621155

Epoch: 6| Step: 10
Training loss: 1.552386704394388
Validation loss: 2.3403698140850198

Epoch: 6| Step: 11
Training loss: 0.9283169814358433
Validation loss: 2.3468992605692662

Epoch: 6| Step: 12
Training loss: 1.6752719060629455
Validation loss: 2.4032776246062784

Epoch: 6| Step: 13
Training loss: 1.3388791629803825
Validation loss: 2.4082299098682056

Epoch: 314| Step: 0
Training loss: 1.407793850621741
Validation loss: 2.367289097453331

Epoch: 6| Step: 1
Training loss: 1.2301833533265758
Validation loss: 2.3229571974945102

Epoch: 6| Step: 2
Training loss: 1.1562644338995618
Validation loss: 2.2879113101054083

Epoch: 6| Step: 3
Training loss: 1.624088838858052
Validation loss: 2.423018124267

Epoch: 6| Step: 4
Training loss: 1.5485801931277985
Validation loss: 2.3759592479810676

Epoch: 6| Step: 5
Training loss: 1.5706342680627663
Validation loss: 2.3297015661526665

Epoch: 6| Step: 6
Training loss: 1.1241452360737978
Validation loss: 2.3323730970129772

Epoch: 6| Step: 7
Training loss: 1.4785530357717451
Validation loss: 2.3733138190464205

Epoch: 6| Step: 8
Training loss: 2.2442793707789597
Validation loss: 2.3341094504696205

Epoch: 6| Step: 9
Training loss: 1.5754261167024726
Validation loss: 2.370324094059909

Epoch: 6| Step: 10
Training loss: 1.3263588325508098
Validation loss: 2.383484149254023

Epoch: 6| Step: 11
Training loss: 1.6990178131912024
Validation loss: 2.4151124280908007

Epoch: 6| Step: 12
Training loss: 1.3674260830472562
Validation loss: 2.3981826655931036

Epoch: 6| Step: 13
Training loss: 2.3792534936492657
Validation loss: 2.3769159064268903

Epoch: 315| Step: 0
Training loss: 1.0789983225324176
Validation loss: 2.3479328515025006

Epoch: 6| Step: 1
Training loss: 1.4943466941995789
Validation loss: 2.3919478623696215

Epoch: 6| Step: 2
Training loss: 1.2448547326024
Validation loss: 2.3662679299370577

Epoch: 6| Step: 3
Training loss: 1.2785850816060136
Validation loss: 2.3539887220462927

Epoch: 6| Step: 4
Training loss: 2.08951036877968
Validation loss: 2.363014141416487

Epoch: 6| Step: 5
Training loss: 1.3231835383969943
Validation loss: 2.371746384205606

Epoch: 6| Step: 6
Training loss: 2.3027824157414543
Validation loss: 2.358565416188868

Epoch: 6| Step: 7
Training loss: 1.675052653381846
Validation loss: 2.395844726927757

Epoch: 6| Step: 8
Training loss: 1.2224819071236306
Validation loss: 2.4137946819002423

Epoch: 6| Step: 9
Training loss: 1.5207326498626899
Validation loss: 2.34743925083425

Epoch: 6| Step: 10
Training loss: 1.6091966252408447
Validation loss: 2.343225884577092

Epoch: 6| Step: 11
Training loss: 1.2250596576877812
Validation loss: 2.404590698861839

Epoch: 6| Step: 12
Training loss: 1.5606192141155621
Validation loss: 2.4016493887565633

Epoch: 6| Step: 13
Training loss: 2.1476475598550424
Validation loss: 2.3672919802475048

Epoch: 316| Step: 0
Training loss: 2.302499023006534
Validation loss: 2.3906246407551675

Epoch: 6| Step: 1
Training loss: 1.4174183179138626
Validation loss: 2.3032486350822334

Epoch: 6| Step: 2
Training loss: 1.4711746331343463
Validation loss: 2.442315940651454

Epoch: 6| Step: 3
Training loss: 1.580963754188984
Validation loss: 2.3748623673693228

Epoch: 6| Step: 4
Training loss: 1.3284198658054758
Validation loss: 2.3422351866809406

Epoch: 6| Step: 5
Training loss: 1.6109982794498512
Validation loss: 2.3844626837301126

Epoch: 6| Step: 6
Training loss: 1.750813022854615
Validation loss: 2.3217948100229684

Epoch: 6| Step: 7
Training loss: 1.4226943788650803
Validation loss: 2.3752963869379777

Epoch: 6| Step: 8
Training loss: 1.4717553416084408
Validation loss: 2.3590237641890974

Epoch: 6| Step: 9
Training loss: 1.6016542734043082
Validation loss: 2.3659077225433083

Epoch: 6| Step: 10
Training loss: 1.643841161484489
Validation loss: 2.37672735845758

Epoch: 6| Step: 11
Training loss: 1.7189984228760484
Validation loss: 2.4567977095473386

Epoch: 6| Step: 12
Training loss: 1.5486669468566754
Validation loss: 2.39461978140512

Epoch: 6| Step: 13
Training loss: 1.1896283000368373
Validation loss: 2.3731628613789253

Epoch: 317| Step: 0
Training loss: 1.8716184003975125
Validation loss: 2.3134096391400933

Epoch: 6| Step: 1
Training loss: 1.4136373818735906
Validation loss: 2.354051547040357

Epoch: 6| Step: 2
Training loss: 1.4659331886294786
Validation loss: 2.423989866231504

Epoch: 6| Step: 3
Training loss: 1.277323264794762
Validation loss: 2.356780672616543

Epoch: 6| Step: 4
Training loss: 2.266901958632369
Validation loss: 2.330395832287622

Epoch: 6| Step: 5
Training loss: 1.3990182789418935
Validation loss: 2.3867189863080744

Epoch: 6| Step: 6
Training loss: 1.847578051083686
Validation loss: 2.3269007397710038

Epoch: 6| Step: 7
Training loss: 1.7422020060529777
Validation loss: 2.401766963360978

Epoch: 6| Step: 8
Training loss: 1.176798333067916
Validation loss: 2.4202605933131416

Epoch: 6| Step: 9
Training loss: 1.314872459420046
Validation loss: 2.4253673649866414

Epoch: 6| Step: 10
Training loss: 1.4250180226574967
Validation loss: 2.3833958119433185

Epoch: 6| Step: 11
Training loss: 1.5349454079776914
Validation loss: 2.4497732832737875

Epoch: 6| Step: 12
Training loss: 1.6899113557354215
Validation loss: 2.373063069962701

Epoch: 6| Step: 13
Training loss: 1.2991198219351014
Validation loss: 2.326997415485968

Epoch: 318| Step: 0
Training loss: 1.679514676451545
Validation loss: 2.366960223616259

Epoch: 6| Step: 1
Training loss: 1.4140891394029043
Validation loss: 2.303074530681065

Epoch: 6| Step: 2
Training loss: 1.2144348830272973
Validation loss: 2.303226407838541

Epoch: 6| Step: 3
Training loss: 1.4438665631952394
Validation loss: 2.3979514226927274

Epoch: 6| Step: 4
Training loss: 1.26888519280911
Validation loss: 2.320132699961272

Epoch: 6| Step: 5
Training loss: 1.027820896985417
Validation loss: 2.3272223893899127

Epoch: 6| Step: 6
Training loss: 2.5416457899726685
Validation loss: 2.3239420364073293

Epoch: 6| Step: 7
Training loss: 1.6338544377610582
Validation loss: 2.431279110382968

Epoch: 6| Step: 8
Training loss: 1.8078947426066732
Validation loss: 2.4360586774102977

Epoch: 6| Step: 9
Training loss: 1.4805358227354561
Validation loss: 2.367200146583151

Epoch: 6| Step: 10
Training loss: 1.4050255849144602
Validation loss: 2.3082032254485485

Epoch: 6| Step: 11
Training loss: 1.3934718791093892
Validation loss: 2.3808049619027853

Epoch: 6| Step: 12
Training loss: 1.5709310803074488
Validation loss: 2.4237245174945348

Epoch: 6| Step: 13
Training loss: 1.9093479560397775
Validation loss: 2.3649114150139647

Epoch: 319| Step: 0
Training loss: 0.9257917443819421
Validation loss: 2.3182818145844486

Epoch: 6| Step: 1
Training loss: 1.5009783891854125
Validation loss: 2.4379744676640716

Epoch: 6| Step: 2
Training loss: 1.2384474970654473
Validation loss: 2.3523460606000817

Epoch: 6| Step: 3
Training loss: 1.7435609339006795
Validation loss: 2.3366006076069548

Epoch: 6| Step: 4
Training loss: 1.9249304696939389
Validation loss: 2.339565397704142

Epoch: 6| Step: 5
Training loss: 1.458818500286641
Validation loss: 2.3503365398522416

Epoch: 6| Step: 6
Training loss: 1.494805401285941
Validation loss: 2.364371040083753

Epoch: 6| Step: 7
Training loss: 1.6706649822298667
Validation loss: 2.401570098062396

Epoch: 6| Step: 8
Training loss: 1.626171716657526
Validation loss: 2.4845003093998574

Epoch: 6| Step: 9
Training loss: 1.2090712409789297
Validation loss: 2.3581899839689333

Epoch: 6| Step: 10
Training loss: 1.6236278903262031
Validation loss: 2.407352682278176

Epoch: 6| Step: 11
Training loss: 1.5146127053429466
Validation loss: 2.3982424140781355

Epoch: 6| Step: 12
Training loss: 1.4998127502550567
Validation loss: 2.396748018722903

Epoch: 6| Step: 13
Training loss: 2.709754443850139
Validation loss: 2.295887481221828

Epoch: 320| Step: 0
Training loss: 1.442616437975989
Validation loss: 2.3784906881875205

Epoch: 6| Step: 1
Training loss: 1.6531168254224724
Validation loss: 2.32324249536962

Epoch: 6| Step: 2
Training loss: 1.3840333538556653
Validation loss: 2.399827109475053

Epoch: 6| Step: 3
Training loss: 1.4586465590019175
Validation loss: 2.3618454804716054

Epoch: 6| Step: 4
Training loss: 1.846986290278255
Validation loss: 2.3315147948918438

Epoch: 6| Step: 5
Training loss: 1.3137566590435283
Validation loss: 2.3075536771128404

Epoch: 6| Step: 6
Training loss: 1.3946669910520488
Validation loss: 2.464353409498069

Epoch: 6| Step: 7
Training loss: 2.3107975028179215
Validation loss: 2.3882657883801848

Epoch: 6| Step: 8
Training loss: 1.1583804530341306
Validation loss: 2.405685352162429

Epoch: 6| Step: 9
Training loss: 1.7818351587546597
Validation loss: 2.355870281588048

Epoch: 6| Step: 10
Training loss: 1.5374969420363866
Validation loss: 2.3589433170410885

Epoch: 6| Step: 11
Training loss: 1.4699904702325328
Validation loss: 2.3740819183094395

Epoch: 6| Step: 12
Training loss: 1.2785120296456856
Validation loss: 2.333246133496307

Epoch: 6| Step: 13
Training loss: 1.9842093691449039
Validation loss: 2.352807918174294

Epoch: 321| Step: 0
Training loss: 1.1455884614019727
Validation loss: 2.3108325318750453

Epoch: 6| Step: 1
Training loss: 2.219743640463065
Validation loss: 2.357512678617429

Epoch: 6| Step: 2
Training loss: 1.7446759845094655
Validation loss: 2.38695907289142

Epoch: 6| Step: 3
Training loss: 1.506801127676343
Validation loss: 2.343018463712145

Epoch: 6| Step: 4
Training loss: 1.4327441616255567
Validation loss: 2.3529614063847926

Epoch: 6| Step: 5
Training loss: 1.270939629700459
Validation loss: 2.367356410106144

Epoch: 6| Step: 6
Training loss: 1.4016694809518353
Validation loss: 2.3982682155821027

Epoch: 6| Step: 7
Training loss: 1.660475828041361
Validation loss: 2.3328986451527314

Epoch: 6| Step: 8
Training loss: 1.6056024723098568
Validation loss: 2.3901813880198444

Epoch: 6| Step: 9
Training loss: 1.8241137978792676
Validation loss: 2.39080755802254

Epoch: 6| Step: 10
Training loss: 1.3287023299270797
Validation loss: 2.3899931110418895

Epoch: 6| Step: 11
Training loss: 1.2597067175998349
Validation loss: 2.3494289357788687

Epoch: 6| Step: 12
Training loss: 1.2753184650097498
Validation loss: 2.378429641584001

Epoch: 6| Step: 13
Training loss: 1.4523428175637472
Validation loss: 2.3921078517238925

Epoch: 322| Step: 0
Training loss: 1.0569927876784901
Validation loss: 2.3563373669920007

Epoch: 6| Step: 1
Training loss: 1.6674813981284013
Validation loss: 2.4270745782977254

Epoch: 6| Step: 2
Training loss: 1.0750976296382502
Validation loss: 2.414397802634782

Epoch: 6| Step: 3
Training loss: 1.2896309264012578
Validation loss: 2.3740663544515495

Epoch: 6| Step: 4
Training loss: 1.7148276221835566
Validation loss: 2.383427238009171

Epoch: 6| Step: 5
Training loss: 2.243231978694044
Validation loss: 2.3905526539719335

Epoch: 6| Step: 6
Training loss: 1.6176122577514094
Validation loss: 2.3791490624162273

Epoch: 6| Step: 7
Training loss: 1.660227910907417
Validation loss: 2.3305165000232666

Epoch: 6| Step: 8
Training loss: 1.587895204506965
Validation loss: 2.3711211984162026

Epoch: 6| Step: 9
Training loss: 1.0577192459810811
Validation loss: 2.407534683191193

Epoch: 6| Step: 10
Training loss: 1.3245541308218758
Validation loss: 2.3615751384358212

Epoch: 6| Step: 11
Training loss: 1.3843371073959738
Validation loss: 2.4034960813916

Epoch: 6| Step: 12
Training loss: 1.473721227906967
Validation loss: 2.313284383686909

Epoch: 6| Step: 13
Training loss: 1.5502645943515578
Validation loss: 2.261989472951248

Epoch: 323| Step: 0
Training loss: 1.0511223335173319
Validation loss: 2.337346020138337

Epoch: 6| Step: 1
Training loss: 2.18202177456097
Validation loss: 2.353040425973392

Epoch: 6| Step: 2
Training loss: 1.4255118337599648
Validation loss: 2.284086289542633

Epoch: 6| Step: 3
Training loss: 1.1329672345998445
Validation loss: 2.3819063908440947

Epoch: 6| Step: 4
Training loss: 1.3722216974009456
Validation loss: 2.3861286748431274

Epoch: 6| Step: 5
Training loss: 1.2076776249085064
Validation loss: 2.416173245599261

Epoch: 6| Step: 6
Training loss: 1.3982260347028261
Validation loss: 2.494967085022597

Epoch: 6| Step: 7
Training loss: 1.753321356835213
Validation loss: 2.4106225599239863

Epoch: 6| Step: 8
Training loss: 2.4402519732274732
Validation loss: 2.3547085813373734

Epoch: 6| Step: 9
Training loss: 1.6445023993999157
Validation loss: 2.3051071805465506

Epoch: 6| Step: 10
Training loss: 1.4426622165328074
Validation loss: 2.3112941525828745

Epoch: 6| Step: 11
Training loss: 1.4683652333241408
Validation loss: 2.3537887181283987

Epoch: 6| Step: 12
Training loss: 1.6327908893231968
Validation loss: 2.4141380690359813

Epoch: 6| Step: 13
Training loss: 1.2694480986140269
Validation loss: 2.3874413953255624

Epoch: 324| Step: 0
Training loss: 1.503675249862669
Validation loss: 2.3657050656625236

Epoch: 6| Step: 1
Training loss: 1.1604207055360007
Validation loss: 2.4108034148795188

Epoch: 6| Step: 2
Training loss: 1.1374733638788803
Validation loss: 2.327007014531776

Epoch: 6| Step: 3
Training loss: 1.395266640861069
Validation loss: 2.3908753108207232

Epoch: 6| Step: 4
Training loss: 1.438136333104273
Validation loss: 2.40388396736486

Epoch: 6| Step: 5
Training loss: 2.1912919012960805
Validation loss: 2.387711274971312

Epoch: 6| Step: 6
Training loss: 1.00135592087296
Validation loss: 2.3094892039293358

Epoch: 6| Step: 7
Training loss: 1.6481114648140944
Validation loss: 2.366300479170698

Epoch: 6| Step: 8
Training loss: 1.4079913484052886
Validation loss: 2.3689990499822295

Epoch: 6| Step: 9
Training loss: 1.6374518816917818
Validation loss: 2.3371847819430207

Epoch: 6| Step: 10
Training loss: 1.817611524159037
Validation loss: 2.3614820484140675

Epoch: 6| Step: 11
Training loss: 1.2006976424268343
Validation loss: 2.3130561516816015

Epoch: 6| Step: 12
Training loss: 1.754266035054782
Validation loss: 2.305357582396451

Epoch: 6| Step: 13
Training loss: 1.6253646294775563
Validation loss: 2.302455694270186

Epoch: 325| Step: 0
Training loss: 1.8617471901677887
Validation loss: 2.3568235413313774

Epoch: 6| Step: 1
Training loss: 1.9907325368247255
Validation loss: 2.3430110507561435

Epoch: 6| Step: 2
Training loss: 1.3540592835716292
Validation loss: 2.338878297031182

Epoch: 6| Step: 3
Training loss: 0.9734807024778515
Validation loss: 2.37238827803878

Epoch: 6| Step: 4
Training loss: 1.863099735143734
Validation loss: 2.3517855632901403

Epoch: 6| Step: 5
Training loss: 1.517142018383883
Validation loss: 2.3295155900938527

Epoch: 6| Step: 6
Training loss: 1.1917965109095334
Validation loss: 2.3769956212799186

Epoch: 6| Step: 7
Training loss: 1.5094540213992957
Validation loss: 2.380056341412989

Epoch: 6| Step: 8
Training loss: 0.961995790369257
Validation loss: 2.4293061507025655

Epoch: 6| Step: 9
Training loss: 1.1011549824869942
Validation loss: 2.286785795108569

Epoch: 6| Step: 10
Training loss: 1.6636276035011872
Validation loss: 2.36131109500252

Epoch: 6| Step: 11
Training loss: 2.369005770198418
Validation loss: 2.4319596104879397

Epoch: 6| Step: 12
Training loss: 1.2286689796008567
Validation loss: 2.3087102805323236

Epoch: 6| Step: 13
Training loss: 1.4252457122443822
Validation loss: 2.3257801155867615

Epoch: 326| Step: 0
Training loss: 1.4150450438484266
Validation loss: 2.3749614123073925

Epoch: 6| Step: 1
Training loss: 1.7267286816191325
Validation loss: 2.4042168529600696

Epoch: 6| Step: 2
Training loss: 1.3288299484819048
Validation loss: 2.3301675044252526

Epoch: 6| Step: 3
Training loss: 1.7296897219649656
Validation loss: 2.3344404330649

Epoch: 6| Step: 4
Training loss: 1.1945674294480952
Validation loss: 2.3522440596825844

Epoch: 6| Step: 5
Training loss: 1.8914561060653443
Validation loss: 2.4127186282485353

Epoch: 6| Step: 6
Training loss: 1.7071825043383313
Validation loss: 2.3897951312909127

Epoch: 6| Step: 7
Training loss: 1.3505637387032534
Validation loss: 2.4082289230457485

Epoch: 6| Step: 8
Training loss: 1.19154692272746
Validation loss: 2.4051649089219413

Epoch: 6| Step: 9
Training loss: 2.248765606828681
Validation loss: 2.414147667783432

Epoch: 6| Step: 10
Training loss: 1.6000957192160994
Validation loss: 2.4044601694063097

Epoch: 6| Step: 11
Training loss: 1.1578916803175907
Validation loss: 2.434493380593772

Epoch: 6| Step: 12
Training loss: 1.4537082445047187
Validation loss: 2.394185517607671

Epoch: 6| Step: 13
Training loss: 0.8111932957468122
Validation loss: 2.380950171994065

Epoch: 327| Step: 0
Training loss: 2.381811713501766
Validation loss: 2.454234320539584

Epoch: 6| Step: 1
Training loss: 1.2229651892597906
Validation loss: 2.4061828964032865

Epoch: 6| Step: 2
Training loss: 0.9361512973233026
Validation loss: 2.3673558020505108

Epoch: 6| Step: 3
Training loss: 1.579347118377641
Validation loss: 2.360012320145154

Epoch: 6| Step: 4
Training loss: 1.0433916813152275
Validation loss: 2.4003089091136927

Epoch: 6| Step: 5
Training loss: 1.2514796083124857
Validation loss: 2.358418711536488

Epoch: 6| Step: 6
Training loss: 1.7345974066471368
Validation loss: 2.378700376623307

Epoch: 6| Step: 7
Training loss: 1.6476738051107371
Validation loss: 2.3394508533891627

Epoch: 6| Step: 8
Training loss: 1.537965257542443
Validation loss: 2.33211916728616

Epoch: 6| Step: 9
Training loss: 1.6338430556492152
Validation loss: 2.3319361351891685

Epoch: 6| Step: 10
Training loss: 0.9805773184801391
Validation loss: 2.325827079034089

Epoch: 6| Step: 11
Training loss: 1.5976660991635592
Validation loss: 2.355527418291597

Epoch: 6| Step: 12
Training loss: 1.9893019179266138
Validation loss: 2.357133001821771

Epoch: 6| Step: 13
Training loss: 1.4675330132015518
Validation loss: 2.3621391805406304

Epoch: 328| Step: 0
Training loss: 1.7877324920125597
Validation loss: 2.3333072371569052

Epoch: 6| Step: 1
Training loss: 1.699519198810609
Validation loss: 2.3762549823178536

Epoch: 6| Step: 2
Training loss: 1.3565907959885786
Validation loss: 2.369607923745817

Epoch: 6| Step: 3
Training loss: 1.6732589840171168
Validation loss: 2.3824707937439493

Epoch: 6| Step: 4
Training loss: 1.3162996152708435
Validation loss: 2.2704129205731545

Epoch: 6| Step: 5
Training loss: 1.1566773733107063
Validation loss: 2.3745501901324912

Epoch: 6| Step: 6
Training loss: 1.7421817522852217
Validation loss: 2.349993942643918

Epoch: 6| Step: 7
Training loss: 1.4139365461537063
Validation loss: 2.388664807642304

Epoch: 6| Step: 8
Training loss: 1.3932300555740325
Validation loss: 2.342540093417859

Epoch: 6| Step: 9
Training loss: 1.3771867702647527
Validation loss: 2.3305365122531807

Epoch: 6| Step: 10
Training loss: 1.540087673119149
Validation loss: 2.4117264994631076

Epoch: 6| Step: 11
Training loss: 2.325193466833056
Validation loss: 2.3861896297678293

Epoch: 6| Step: 12
Training loss: 1.5423922850158662
Validation loss: 2.41959287713214

Epoch: 6| Step: 13
Training loss: 0.5522024338089343
Validation loss: 2.3832700766439836

Epoch: 329| Step: 0
Training loss: 0.9628982698396286
Validation loss: 2.3812711418965367

Epoch: 6| Step: 1
Training loss: 1.5521723659845887
Validation loss: 2.4080706429867695

Epoch: 6| Step: 2
Training loss: 0.7061964554870855
Validation loss: 2.4450386253329253

Epoch: 6| Step: 3
Training loss: 1.1428887882279186
Validation loss: 2.416460316079833

Epoch: 6| Step: 4
Training loss: 1.507309113115717
Validation loss: 2.342612070010599

Epoch: 6| Step: 5
Training loss: 1.8465579359405195
Validation loss: 2.381161316934823

Epoch: 6| Step: 6
Training loss: 1.4601704424826074
Validation loss: 2.3832008065594334

Epoch: 6| Step: 7
Training loss: 1.3542481128946373
Validation loss: 2.405845207447814

Epoch: 6| Step: 8
Training loss: 1.5858688715475597
Validation loss: 2.3726659103954804

Epoch: 6| Step: 9
Training loss: 1.8952417044378156
Validation loss: 2.3614411500002657

Epoch: 6| Step: 10
Training loss: 2.4073504619166854
Validation loss: 2.355521821984076

Epoch: 6| Step: 11
Training loss: 1.8722336388921237
Validation loss: 2.390853304721677

Epoch: 6| Step: 12
Training loss: 1.2651144811221033
Validation loss: 2.382169122175799

Epoch: 6| Step: 13
Training loss: 1.3643059145203031
Validation loss: 2.256299160280396

Epoch: 330| Step: 0
Training loss: 1.119773805461053
Validation loss: 2.3296022872662454

Epoch: 6| Step: 1
Training loss: 1.0666444393663372
Validation loss: 2.3315848363677785

Epoch: 6| Step: 2
Training loss: 2.462758967535746
Validation loss: 2.3379740115251804

Epoch: 6| Step: 3
Training loss: 1.1804916975415276
Validation loss: 2.3975936486342895

Epoch: 6| Step: 4
Training loss: 1.4923623666609607
Validation loss: 2.3377425741047992

Epoch: 6| Step: 5
Training loss: 1.4682629366109432
Validation loss: 2.37484093453457

Epoch: 6| Step: 6
Training loss: 2.1471162929728136
Validation loss: 2.358321503060549

Epoch: 6| Step: 7
Training loss: 1.1947795702125978
Validation loss: 2.4021554935331415

Epoch: 6| Step: 8
Training loss: 1.4250779180807338
Validation loss: 2.410863675227916

Epoch: 6| Step: 9
Training loss: 1.311421359841102
Validation loss: 2.371347063019426

Epoch: 6| Step: 10
Training loss: 1.6591206989725478
Validation loss: 2.403498193317751

Epoch: 6| Step: 11
Training loss: 1.2768685859896256
Validation loss: 2.3567208182757304

Epoch: 6| Step: 12
Training loss: 1.552250240832774
Validation loss: 2.32488132958593

Epoch: 6| Step: 13
Training loss: 1.2540144353762759
Validation loss: 2.3499545756016564

Epoch: 331| Step: 0
Training loss: 1.1697300927297913
Validation loss: 2.3484970475484057

Epoch: 6| Step: 1
Training loss: 0.9481968657705102
Validation loss: 2.4411542754714723

Epoch: 6| Step: 2
Training loss: 2.340347159464327
Validation loss: 2.366795122908756

Epoch: 6| Step: 3
Training loss: 1.371254196995143
Validation loss: 2.3318254351112166

Epoch: 6| Step: 4
Training loss: 1.460567407088774
Validation loss: 2.379305462960252

Epoch: 6| Step: 5
Training loss: 1.578355828957062
Validation loss: 2.4464698602047505

Epoch: 6| Step: 6
Training loss: 1.542548168178392
Validation loss: 2.3207845955111357

Epoch: 6| Step: 7
Training loss: 1.4167211839994307
Validation loss: 2.338251860344583

Epoch: 6| Step: 8
Training loss: 1.4060047359630974
Validation loss: 2.363361057014343

Epoch: 6| Step: 9
Training loss: 1.3145704287919813
Validation loss: 2.3843567302401034

Epoch: 6| Step: 10
Training loss: 1.452230034326972
Validation loss: 2.421613661538963

Epoch: 6| Step: 11
Training loss: 1.6358332822115957
Validation loss: 2.4172389300917114

Epoch: 6| Step: 12
Training loss: 1.4144413056047014
Validation loss: 2.404485773048753

Epoch: 6| Step: 13
Training loss: 1.7411189202060027
Validation loss: 2.3743665592026177

Epoch: 332| Step: 0
Training loss: 1.5078140812208354
Validation loss: 2.3219991904888992

Epoch: 6| Step: 1
Training loss: 1.0462808203857685
Validation loss: 2.357064021344618

Epoch: 6| Step: 2
Training loss: 1.5138630014164078
Validation loss: 2.3892753942153315

Epoch: 6| Step: 3
Training loss: 2.4646812421666784
Validation loss: 2.3737615455375565

Epoch: 6| Step: 4
Training loss: 0.94982570504921
Validation loss: 2.317177471677183

Epoch: 6| Step: 5
Training loss: 1.057544934736206
Validation loss: 2.356597900753952

Epoch: 6| Step: 6
Training loss: 1.4676767039449992
Validation loss: 2.4128790109941747

Epoch: 6| Step: 7
Training loss: 1.28480715198854
Validation loss: 2.3709368077645125

Epoch: 6| Step: 8
Training loss: 1.6535591002619416
Validation loss: 2.3800686783402325

Epoch: 6| Step: 9
Training loss: 1.4807190696040182
Validation loss: 2.3285631338908632

Epoch: 6| Step: 10
Training loss: 1.9762293719591033
Validation loss: 2.33452131826425

Epoch: 6| Step: 11
Training loss: 1.5876191342324075
Validation loss: 2.324958016515678

Epoch: 6| Step: 12
Training loss: 1.61421158315345
Validation loss: 2.3035291427281366

Epoch: 6| Step: 13
Training loss: 1.4896507070105713
Validation loss: 2.3881948087892124

Epoch: 333| Step: 0
Training loss: 1.4896006905493688
Validation loss: 2.3438994307377357

Epoch: 6| Step: 1
Training loss: 1.5698470759173828
Validation loss: 2.339193912052561

Epoch: 6| Step: 2
Training loss: 1.3812206610416093
Validation loss: 2.3496447053932914

Epoch: 6| Step: 3
Training loss: 1.2765217040324006
Validation loss: 2.3618062501874393

Epoch: 6| Step: 4
Training loss: 1.1911452210689828
Validation loss: 2.4127448200298396

Epoch: 6| Step: 5
Training loss: 1.1369168348201575
Validation loss: 2.3702378242583397

Epoch: 6| Step: 6
Training loss: 1.3230270379749958
Validation loss: 2.330617903634361

Epoch: 6| Step: 7
Training loss: 1.5186229825378124
Validation loss: 2.443457910194828

Epoch: 6| Step: 8
Training loss: 1.4822193756311304
Validation loss: 2.332684753813595

Epoch: 6| Step: 9
Training loss: 1.5752515410328107
Validation loss: 2.450330084856335

Epoch: 6| Step: 10
Training loss: 1.6962300291973031
Validation loss: 2.3541467015839763

Epoch: 6| Step: 11
Training loss: 1.4220461899542944
Validation loss: 2.3424599589920265

Epoch: 6| Step: 12
Training loss: 1.7900236121810034
Validation loss: 2.357514676233771

Epoch: 6| Step: 13
Training loss: 2.7032364838824163
Validation loss: 2.3005977071105774

Epoch: 334| Step: 0
Training loss: 1.204805167026509
Validation loss: 2.3065513842325944

Epoch: 6| Step: 1
Training loss: 1.8555604932088632
Validation loss: 2.314047365285273

Epoch: 6| Step: 2
Training loss: 1.3693578006390292
Validation loss: 2.3502288897145087

Epoch: 6| Step: 3
Training loss: 0.8685954580823748
Validation loss: 2.3213905108231323

Epoch: 6| Step: 4
Training loss: 1.342202826202605
Validation loss: 2.410141543483123

Epoch: 6| Step: 5
Training loss: 1.2972946407262993
Validation loss: 2.331370422029532

Epoch: 6| Step: 6
Training loss: 1.418389712392438
Validation loss: 2.390340197345764

Epoch: 6| Step: 7
Training loss: 1.0791737527995129
Validation loss: 2.353761874662415

Epoch: 6| Step: 8
Training loss: 2.336013843730509
Validation loss: 2.4092067945748648

Epoch: 6| Step: 9
Training loss: 1.8602829968089674
Validation loss: 2.4134949201661366

Epoch: 6| Step: 10
Training loss: 1.5729399757258151
Validation loss: 2.435337799919391

Epoch: 6| Step: 11
Training loss: 1.9069029518361855
Validation loss: 2.4306957552116466

Epoch: 6| Step: 12
Training loss: 1.9549042188981838
Validation loss: 2.3852112663692204

Epoch: 6| Step: 13
Training loss: 0.9424771434633177
Validation loss: 2.362144021537059

Epoch: 335| Step: 0
Training loss: 1.0762652514149094
Validation loss: 2.472985776828871

Epoch: 6| Step: 1
Training loss: 1.753466714613252
Validation loss: 2.3551341402986106

Epoch: 6| Step: 2
Training loss: 1.2484701331388923
Validation loss: 2.3299352106956164

Epoch: 6| Step: 3
Training loss: 1.2665256545145054
Validation loss: 2.371423647310488

Epoch: 6| Step: 4
Training loss: 1.3026721945225288
Validation loss: 2.3237594915966433

Epoch: 6| Step: 5
Training loss: 1.0521599895890437
Validation loss: 2.3437440332042803

Epoch: 6| Step: 6
Training loss: 1.5828987662935037
Validation loss: 2.3846872277235165

Epoch: 6| Step: 7
Training loss: 1.834642903457285
Validation loss: 2.418275570900222

Epoch: 6| Step: 8
Training loss: 1.0745389703825774
Validation loss: 2.391728014218318

Epoch: 6| Step: 9
Training loss: 1.8445649366521997
Validation loss: 2.365961672089653

Epoch: 6| Step: 10
Training loss: 2.179567614030558
Validation loss: 2.3990343746136196

Epoch: 6| Step: 11
Training loss: 1.475141133813914
Validation loss: 2.3846665567125718

Epoch: 6| Step: 12
Training loss: 1.4212515166181459
Validation loss: 2.4555523825196373

Epoch: 6| Step: 13
Training loss: 1.6957193053553798
Validation loss: 2.280684101591619

Epoch: 336| Step: 0
Training loss: 1.2485654228280498
Validation loss: 2.3630937339692526

Epoch: 6| Step: 1
Training loss: 1.495242840490659
Validation loss: 2.333107629383911

Epoch: 6| Step: 2
Training loss: 1.1516529146101182
Validation loss: 2.387035981116163

Epoch: 6| Step: 3
Training loss: 1.3643167055671492
Validation loss: 2.419068937055326

Epoch: 6| Step: 4
Training loss: 2.2413735856354964
Validation loss: 2.4269685161342043

Epoch: 6| Step: 5
Training loss: 1.1988900196931174
Validation loss: 2.3291633505405693

Epoch: 6| Step: 6
Training loss: 1.4527431519569662
Validation loss: 2.401842818918486

Epoch: 6| Step: 7
Training loss: 1.112765115587684
Validation loss: 2.3169637854112586

Epoch: 6| Step: 8
Training loss: 1.480228615965683
Validation loss: 2.4118764263232904

Epoch: 6| Step: 9
Training loss: 1.2989288979350906
Validation loss: 2.343321582647041

Epoch: 6| Step: 10
Training loss: 1.683849625050864
Validation loss: 2.3910493886209547

Epoch: 6| Step: 11
Training loss: 1.8599444246705759
Validation loss: 2.376717560582519

Epoch: 6| Step: 12
Training loss: 1.7795012070945682
Validation loss: 2.3707945917192514

Epoch: 6| Step: 13
Training loss: 1.6214510971914928
Validation loss: 2.3902914184608326

Epoch: 337| Step: 0
Training loss: 2.3481243764893245
Validation loss: 2.36043425818821

Epoch: 6| Step: 1
Training loss: 1.2380244232412416
Validation loss: 2.4213777696579997

Epoch: 6| Step: 2
Training loss: 1.241849985393904
Validation loss: 2.3242917627172575

Epoch: 6| Step: 3
Training loss: 1.4291339907604022
Validation loss: 2.416922092906704

Epoch: 6| Step: 4
Training loss: 0.7849270310474145
Validation loss: 2.425322982262898

Epoch: 6| Step: 5
Training loss: 1.4036318672726271
Validation loss: 2.346103778636134

Epoch: 6| Step: 6
Training loss: 1.7199619528532297
Validation loss: 2.3085963118693913

Epoch: 6| Step: 7
Training loss: 1.109469450032776
Validation loss: 2.323898207015287

Epoch: 6| Step: 8
Training loss: 1.5787677022707154
Validation loss: 2.3598146127513315

Epoch: 6| Step: 9
Training loss: 1.3737469078355444
Validation loss: 2.2836600651099404

Epoch: 6| Step: 10
Training loss: 1.7939698991663684
Validation loss: 2.318953358726596

Epoch: 6| Step: 11
Training loss: 1.455991645128781
Validation loss: 2.3691124784003503

Epoch: 6| Step: 12
Training loss: 1.4174940927910544
Validation loss: 2.3731069873451363

Epoch: 6| Step: 13
Training loss: 1.545960126888214
Validation loss: 2.3813098329681575

Epoch: 338| Step: 0
Training loss: 1.6084026621500755
Validation loss: 2.4308788548244555

Epoch: 6| Step: 1
Training loss: 1.4970445923110633
Validation loss: 2.3150750179641175

Epoch: 6| Step: 2
Training loss: 1.4599926182808496
Validation loss: 2.3658808009464227

Epoch: 6| Step: 3
Training loss: 1.489988134196097
Validation loss: 2.367974467983182

Epoch: 6| Step: 4
Training loss: 1.5052230816638876
Validation loss: 2.2995504317757782

Epoch: 6| Step: 5
Training loss: 1.4100282563428659
Validation loss: 2.3375446704656087

Epoch: 6| Step: 6
Training loss: 1.206387443815857
Validation loss: 2.3678066792605126

Epoch: 6| Step: 7
Training loss: 1.569810473914361
Validation loss: 2.3695418824691865

Epoch: 6| Step: 8
Training loss: 1.641886126506324
Validation loss: 2.3149429029441237

Epoch: 6| Step: 9
Training loss: 1.0811549745820048
Validation loss: 2.393250933823812

Epoch: 6| Step: 10
Training loss: 2.095117833868293
Validation loss: 2.41703748952026

Epoch: 6| Step: 11
Training loss: 1.3666334064824877
Validation loss: 2.3262812731634464

Epoch: 6| Step: 12
Training loss: 1.0252924408908122
Validation loss: 2.411520206842382

Epoch: 6| Step: 13
Training loss: 1.6030835627801756
Validation loss: 2.3544533725847674

Epoch: 339| Step: 0
Training loss: 1.4792804226540877
Validation loss: 2.3759338818265463

Epoch: 6| Step: 1
Training loss: 1.6244549937731219
Validation loss: 2.403848146915793

Epoch: 6| Step: 2
Training loss: 1.3608466765167537
Validation loss: 2.3929747073370033

Epoch: 6| Step: 3
Training loss: 1.3378758339168697
Validation loss: 2.341806049933277

Epoch: 6| Step: 4
Training loss: 1.8252962838660642
Validation loss: 2.2729290626713983

Epoch: 6| Step: 5
Training loss: 1.377457503340009
Validation loss: 2.3895898157171955

Epoch: 6| Step: 6
Training loss: 1.5422667632754081
Validation loss: 2.3761008754655673

Epoch: 6| Step: 7
Training loss: 0.9668365778621723
Validation loss: 2.3690584014931533

Epoch: 6| Step: 8
Training loss: 1.1451219199790545
Validation loss: 2.284722087863553

Epoch: 6| Step: 9
Training loss: 1.2926069139425829
Validation loss: 2.3736157098997355

Epoch: 6| Step: 10
Training loss: 2.414999178299853
Validation loss: 2.342380572624067

Epoch: 6| Step: 11
Training loss: 1.377501336666504
Validation loss: 2.4173965780384186

Epoch: 6| Step: 12
Training loss: 1.0709596890860449
Validation loss: 2.363905986700614

Epoch: 6| Step: 13
Training loss: 1.7070222413547687
Validation loss: 2.3072803826388224

Epoch: 340| Step: 0
Training loss: 2.599428510213719
Validation loss: 2.361057234030167

Epoch: 6| Step: 1
Training loss: 0.9743486869934321
Validation loss: 2.4088749470877295

Epoch: 6| Step: 2
Training loss: 1.107196603296698
Validation loss: 2.3623547127536164

Epoch: 6| Step: 3
Training loss: 1.2333556203289056
Validation loss: 2.4064680681737127

Epoch: 6| Step: 4
Training loss: 1.160283605090953
Validation loss: 2.353510018462305

Epoch: 6| Step: 5
Training loss: 1.321035740062055
Validation loss: 2.382604748703174

Epoch: 6| Step: 6
Training loss: 1.5794146716287192
Validation loss: 2.3656094776462013

Epoch: 6| Step: 7
Training loss: 1.2983233166374761
Validation loss: 2.3585483314605087

Epoch: 6| Step: 8
Training loss: 1.4518568186087506
Validation loss: 2.365492985976089

Epoch: 6| Step: 9
Training loss: 1.6174760643958328
Validation loss: 2.4692238617315607

Epoch: 6| Step: 10
Training loss: 1.5561993020007454
Validation loss: 2.3609691130396757

Epoch: 6| Step: 11
Training loss: 1.4156214092958566
Validation loss: 2.2997196104178377

Epoch: 6| Step: 12
Training loss: 1.5430411406327378
Validation loss: 2.4107775263454334

Epoch: 6| Step: 13
Training loss: 1.2158809049283907
Validation loss: 2.3547177473329763

Epoch: 341| Step: 0
Training loss: 1.5326221312852355
Validation loss: 2.3236367501824824

Epoch: 6| Step: 1
Training loss: 1.6954271128362273
Validation loss: 2.3672400331010253

Epoch: 6| Step: 2
Training loss: 1.3986040580914294
Validation loss: 2.3657659215490745

Epoch: 6| Step: 3
Training loss: 1.3428326513932505
Validation loss: 2.3022674619059975

Epoch: 6| Step: 4
Training loss: 1.2763960469492228
Validation loss: 2.353526655036924

Epoch: 6| Step: 5
Training loss: 2.1311616761819963
Validation loss: 2.357176827733424

Epoch: 6| Step: 6
Training loss: 1.3762521244486559
Validation loss: 2.4429673467897883

Epoch: 6| Step: 7
Training loss: 1.5471038649053048
Validation loss: 2.310073893584677

Epoch: 6| Step: 8
Training loss: 1.4813564729047815
Validation loss: 2.354572075745389

Epoch: 6| Step: 9
Training loss: 1.009798030960451
Validation loss: 2.3486200948636995

Epoch: 6| Step: 10
Training loss: 0.9409366560279409
Validation loss: 2.3441443731559826

Epoch: 6| Step: 11
Training loss: 1.8326283602235225
Validation loss: 2.3899345669014624

Epoch: 6| Step: 12
Training loss: 1.244643751903665
Validation loss: 2.3795578619493343

Epoch: 6| Step: 13
Training loss: 1.2857009985403702
Validation loss: 2.279718118177883

Epoch: 342| Step: 0
Training loss: 1.275812286728262
Validation loss: 2.3439426203504876

Epoch: 6| Step: 1
Training loss: 1.1763929632467378
Validation loss: 2.340042145563994

Epoch: 6| Step: 2
Training loss: 1.4342804389318156
Validation loss: 2.435268905001285

Epoch: 6| Step: 3
Training loss: 0.9783156261000564
Validation loss: 2.369751649825436

Epoch: 6| Step: 4
Training loss: 1.4091632337131714
Validation loss: 2.3398004934928713

Epoch: 6| Step: 5
Training loss: 1.406536412212206
Validation loss: 2.357029617361593

Epoch: 6| Step: 6
Training loss: 1.3592405143071433
Validation loss: 2.3401203338888474

Epoch: 6| Step: 7
Training loss: 1.1949955139714397
Validation loss: 2.3702183143426563

Epoch: 6| Step: 8
Training loss: 1.39490651442959
Validation loss: 2.3845862634869692

Epoch: 6| Step: 9
Training loss: 0.9463516387877698
Validation loss: 2.3785883614343204

Epoch: 6| Step: 10
Training loss: 1.3126014488613276
Validation loss: 2.3068623087855755

Epoch: 6| Step: 11
Training loss: 1.6737739972651322
Validation loss: 2.3239831391559624

Epoch: 6| Step: 12
Training loss: 2.5144210683009756
Validation loss: 2.3669439836477233

Epoch: 6| Step: 13
Training loss: 1.5234265449325661
Validation loss: 2.3481299554902564

Epoch: 343| Step: 0
Training loss: 1.22172398719392
Validation loss: 2.3703008285729275

Epoch: 6| Step: 1
Training loss: 2.124821599315683
Validation loss: 2.3961008761607534

Epoch: 6| Step: 2
Training loss: 1.4924578197148253
Validation loss: 2.383863391989347

Epoch: 6| Step: 3
Training loss: 1.2735823098442127
Validation loss: 2.260936120697845

Epoch: 6| Step: 4
Training loss: 1.5808461212515048
Validation loss: 2.3389428777061507

Epoch: 6| Step: 5
Training loss: 1.5400672382687295
Validation loss: 2.3222143022878727

Epoch: 6| Step: 6
Training loss: 0.9277912002025285
Validation loss: 2.319337339062961

Epoch: 6| Step: 7
Training loss: 1.5228270261225527
Validation loss: 2.351490359102071

Epoch: 6| Step: 8
Training loss: 1.691521691309819
Validation loss: 2.410538515626977

Epoch: 6| Step: 9
Training loss: 1.4635709802626478
Validation loss: 2.36230039921525

Epoch: 6| Step: 10
Training loss: 1.3103537950256499
Validation loss: 2.377035272249066

Epoch: 6| Step: 11
Training loss: 1.2382949202592228
Validation loss: 2.3541517621119463

Epoch: 6| Step: 12
Training loss: 1.3345521581468185
Validation loss: 2.2788579977851864

Epoch: 6| Step: 13
Training loss: 1.5902306838005629
Validation loss: 2.35379054137308

Epoch: 344| Step: 0
Training loss: 1.0386417081827037
Validation loss: 2.327690102061018

Epoch: 6| Step: 1
Training loss: 1.5717992624044477
Validation loss: 2.2794967316160863

Epoch: 6| Step: 2
Training loss: 2.301059155608535
Validation loss: 2.312721140984989

Epoch: 6| Step: 3
Training loss: 1.5296337394891768
Validation loss: 2.3490563137940885

Epoch: 6| Step: 4
Training loss: 1.2788664348465735
Validation loss: 2.3922269835470598

Epoch: 6| Step: 5
Training loss: 1.738408390496093
Validation loss: 2.318767087233458

Epoch: 6| Step: 6
Training loss: 1.1211067757198698
Validation loss: 2.316318930529348

Epoch: 6| Step: 7
Training loss: 1.1762526064771908
Validation loss: 2.3945737629980317

Epoch: 6| Step: 8
Training loss: 1.2909627144686695
Validation loss: 2.2939497240967466

Epoch: 6| Step: 9
Training loss: 1.2738771674229739
Validation loss: 2.3775293167513536

Epoch: 6| Step: 10
Training loss: 1.4650916131443814
Validation loss: 2.3963296904873173

Epoch: 6| Step: 11
Training loss: 1.539927902515663
Validation loss: 2.3199285727712375

Epoch: 6| Step: 12
Training loss: 1.630112455268436
Validation loss: 2.338153482309983

Epoch: 6| Step: 13
Training loss: 1.4823264994742897
Validation loss: 2.3928255958978037

Epoch: 345| Step: 0
Training loss: 0.9266582793318179
Validation loss: 2.4105837592004433

Epoch: 6| Step: 1
Training loss: 1.256203943803242
Validation loss: 2.3281433750024005

Epoch: 6| Step: 2
Training loss: 1.2579546072158616
Validation loss: 2.3549010096754297

Epoch: 6| Step: 3
Training loss: 1.5070412199917667
Validation loss: 2.316600113644068

Epoch: 6| Step: 4
Training loss: 1.3395356026902137
Validation loss: 2.3140311788393655

Epoch: 6| Step: 5
Training loss: 1.0167856480333655
Validation loss: 2.3132245769730813

Epoch: 6| Step: 6
Training loss: 1.6366253737441425
Validation loss: 2.3577708937426185

Epoch: 6| Step: 7
Training loss: 1.2520779980351693
Validation loss: 2.3963529311371

Epoch: 6| Step: 8
Training loss: 2.110745811088659
Validation loss: 2.3658115337207652

Epoch: 6| Step: 9
Training loss: 2.2392652655376404
Validation loss: 2.3295758451962327

Epoch: 6| Step: 10
Training loss: 1.294354805118797
Validation loss: 2.340589743053384

Epoch: 6| Step: 11
Training loss: 1.7256108764158882
Validation loss: 2.3448178981993215

Epoch: 6| Step: 12
Training loss: 1.0553999578391005
Validation loss: 2.310152319391276

Epoch: 6| Step: 13
Training loss: 1.3585454229146836
Validation loss: 2.3681249758614795

Epoch: 346| Step: 0
Training loss: 1.2382647877269772
Validation loss: 2.376780125093721

Epoch: 6| Step: 1
Training loss: 1.0578853024289037
Validation loss: 2.4069919840551157

Epoch: 6| Step: 2
Training loss: 1.303142477965753
Validation loss: 2.3040232745965312

Epoch: 6| Step: 3
Training loss: 1.684469539558287
Validation loss: 2.390750382800415

Epoch: 6| Step: 4
Training loss: 1.036758679653728
Validation loss: 2.3343106177452726

Epoch: 6| Step: 5
Training loss: 1.6502777963928783
Validation loss: 2.28322086446462

Epoch: 6| Step: 6
Training loss: 1.057397144988109
Validation loss: 2.382144307508735

Epoch: 6| Step: 7
Training loss: 1.359485621719677
Validation loss: 2.397556073625879

Epoch: 6| Step: 8
Training loss: 1.3281560557605303
Validation loss: 2.349687816678545

Epoch: 6| Step: 9
Training loss: 1.5807333814720845
Validation loss: 2.3073693474433865

Epoch: 6| Step: 10
Training loss: 1.3985441369684068
Validation loss: 2.367593128430833

Epoch: 6| Step: 11
Training loss: 1.3664828855334006
Validation loss: 2.3057236995195014

Epoch: 6| Step: 12
Training loss: 1.1589217891322523
Validation loss: 2.337187139712423

Epoch: 6| Step: 13
Training loss: 2.791511977355723
Validation loss: 2.350647333128605

Epoch: 347| Step: 0
Training loss: 1.3544775777082485
Validation loss: 2.3358754916549893

Epoch: 6| Step: 1
Training loss: 1.510810204462318
Validation loss: 2.343517791292507

Epoch: 6| Step: 2
Training loss: 1.4774283640579164
Validation loss: 2.3603460971045824

Epoch: 6| Step: 3
Training loss: 2.0580287208591983
Validation loss: 2.360235300644608

Epoch: 6| Step: 4
Training loss: 1.5618848734250108
Validation loss: 2.3302754575429154

Epoch: 6| Step: 5
Training loss: 0.9859891101127463
Validation loss: 2.352892750331296

Epoch: 6| Step: 6
Training loss: 1.4946089665037126
Validation loss: 2.407378604447715

Epoch: 6| Step: 7
Training loss: 1.3342174142164527
Validation loss: 2.3415253897416415

Epoch: 6| Step: 8
Training loss: 1.1489731972990371
Validation loss: 2.3531382230265043

Epoch: 6| Step: 9
Training loss: 1.3047876376709526
Validation loss: 2.357184485438261

Epoch: 6| Step: 10
Training loss: 1.421664882687116
Validation loss: 2.3950965633052377

Epoch: 6| Step: 11
Training loss: 1.009410330800673
Validation loss: 2.359118365003779

Epoch: 6| Step: 12
Training loss: 1.5636403309568114
Validation loss: 2.333888269904242

Epoch: 6| Step: 13
Training loss: 1.616192055214472
Validation loss: 2.2936830802187003

Epoch: 348| Step: 0
Training loss: 1.3256121031310515
Validation loss: 2.3656790433818706

Epoch: 6| Step: 1
Training loss: 1.3772611232993215
Validation loss: 2.336143486490831

Epoch: 6| Step: 2
Training loss: 1.6235502818844283
Validation loss: 2.3446789629428104

Epoch: 6| Step: 3
Training loss: 1.138755311084677
Validation loss: 2.356572717282484

Epoch: 6| Step: 4
Training loss: 1.3923809666326399
Validation loss: 2.3949180006582216

Epoch: 6| Step: 5
Training loss: 1.5448015747301322
Validation loss: 2.2790885189164305

Epoch: 6| Step: 6
Training loss: 1.4825369447218542
Validation loss: 2.448071079624753

Epoch: 6| Step: 7
Training loss: 1.546791382658526
Validation loss: 2.364089775173457

Epoch: 6| Step: 8
Training loss: 1.4193405367565586
Validation loss: 2.28289710624053

Epoch: 6| Step: 9
Training loss: 1.2679298042337972
Validation loss: 2.338724873305653

Epoch: 6| Step: 10
Training loss: 1.2058446291957068
Validation loss: 2.3597511752766347

Epoch: 6| Step: 11
Training loss: 2.213551408334875
Validation loss: 2.3168260396318936

Epoch: 6| Step: 12
Training loss: 1.6419374575023755
Validation loss: 2.361681475706856

Epoch: 6| Step: 13
Training loss: 1.164995830593916
Validation loss: 2.3497451902409554

Epoch: 349| Step: 0
Training loss: 1.4205391445976518
Validation loss: 2.3254186273878816

Epoch: 6| Step: 1
Training loss: 1.344872604562282
Validation loss: 2.3815280442673243

Epoch: 6| Step: 2
Training loss: 1.038271380536179
Validation loss: 2.329346533377915

Epoch: 6| Step: 3
Training loss: 1.0930017364083306
Validation loss: 2.3235881343897162

Epoch: 6| Step: 4
Training loss: 1.810438364803924
Validation loss: 2.2975004571084057

Epoch: 6| Step: 5
Training loss: 1.517703567877911
Validation loss: 2.3630621988667078

Epoch: 6| Step: 6
Training loss: 1.5932453328867406
Validation loss: 2.4588745997627033

Epoch: 6| Step: 7
Training loss: 0.9723459997554145
Validation loss: 2.3961268547918895

Epoch: 6| Step: 8
Training loss: 0.9184326947408732
Validation loss: 2.300516052634129

Epoch: 6| Step: 9
Training loss: 1.4917395753286853
Validation loss: 2.337835746391958

Epoch: 6| Step: 10
Training loss: 1.7993032219454212
Validation loss: 2.3490737731330715

Epoch: 6| Step: 11
Training loss: 2.150814891126694
Validation loss: 2.333229931358211

Epoch: 6| Step: 12
Training loss: 1.0691842028120537
Validation loss: 2.332985693514071

Epoch: 6| Step: 13
Training loss: 1.930021990616191
Validation loss: 2.340849550577886

Epoch: 350| Step: 0
Training loss: 0.8154140448069213
Validation loss: 2.3572617778141414

Epoch: 6| Step: 1
Training loss: 1.4620425690847438
Validation loss: 2.435275298122435

Epoch: 6| Step: 2
Training loss: 1.5559859484599499
Validation loss: 2.4306607675902274

Epoch: 6| Step: 3
Training loss: 1.2652478068087205
Validation loss: 2.408466137355666

Epoch: 6| Step: 4
Training loss: 1.2211873063205867
Validation loss: 2.361184127212667

Epoch: 6| Step: 5
Training loss: 1.4540561440921458
Validation loss: 2.344764583939988

Epoch: 6| Step: 6
Training loss: 1.8179733243523242
Validation loss: 2.3844088055076376

Epoch: 6| Step: 7
Training loss: 1.4452245737085043
Validation loss: 2.364930732392727

Epoch: 6| Step: 8
Training loss: 1.4698710931323282
Validation loss: 2.334539956988371

Epoch: 6| Step: 9
Training loss: 1.2999182235232725
Validation loss: 2.3418130561819472

Epoch: 6| Step: 10
Training loss: 2.10980864411942
Validation loss: 2.3923739810833196

Epoch: 6| Step: 11
Training loss: 1.2345486289450993
Validation loss: 2.392334374841585

Epoch: 6| Step: 12
Training loss: 1.1061182169896489
Validation loss: 2.327271244312116

Epoch: 6| Step: 13
Training loss: 0.9576265313231237
Validation loss: 2.349340582136646

Epoch: 351| Step: 0
Training loss: 1.6962242663124465
Validation loss: 2.390726648033329

Epoch: 6| Step: 1
Training loss: 1.6583492722376305
Validation loss: 2.3152302967954674

Epoch: 6| Step: 2
Training loss: 2.199351223738238
Validation loss: 2.377856981632725

Epoch: 6| Step: 3
Training loss: 1.1563602085687053
Validation loss: 2.3460624963055885

Epoch: 6| Step: 4
Training loss: 1.635793711292078
Validation loss: 2.3325028465083135

Epoch: 6| Step: 5
Training loss: 1.0118753319422251
Validation loss: 2.3169274886306765

Epoch: 6| Step: 6
Training loss: 1.2763866606951058
Validation loss: 2.3133139492907375

Epoch: 6| Step: 7
Training loss: 1.0983784427747323
Validation loss: 2.337924771672876

Epoch: 6| Step: 8
Training loss: 1.3902296297185848
Validation loss: 2.3730983774286685

Epoch: 6| Step: 9
Training loss: 1.147876680419649
Validation loss: 2.4732813497709767

Epoch: 6| Step: 10
Training loss: 1.361571105551606
Validation loss: 2.3565427038942377

Epoch: 6| Step: 11
Training loss: 1.6295559911434416
Validation loss: 2.386232015272663

Epoch: 6| Step: 12
Training loss: 1.635026954172053
Validation loss: 2.334029089201204

Epoch: 6| Step: 13
Training loss: 0.8724098697880632
Validation loss: 2.326914255883417

Epoch: 352| Step: 0
Training loss: 1.3799351211859767
Validation loss: 2.300069443027541

Epoch: 6| Step: 1
Training loss: 1.8268433341101837
Validation loss: 2.321748475555786

Epoch: 6| Step: 2
Training loss: 1.5464214083770915
Validation loss: 2.3085278633393127

Epoch: 6| Step: 3
Training loss: 1.506965201489323
Validation loss: 2.3577891583961987

Epoch: 6| Step: 4
Training loss: 0.9588425914114763
Validation loss: 2.4463771083170465

Epoch: 6| Step: 5
Training loss: 1.570224740532007
Validation loss: 2.38560104750157

Epoch: 6| Step: 6
Training loss: 1.1203856674413428
Validation loss: 2.3549541761004757

Epoch: 6| Step: 7
Training loss: 1.1616859498104204
Validation loss: 2.3929256971787303

Epoch: 6| Step: 8
Training loss: 1.3954023103762387
Validation loss: 2.3612572302856587

Epoch: 6| Step: 9
Training loss: 0.9132743437075971
Validation loss: 2.3584221617251186

Epoch: 6| Step: 10
Training loss: 2.073527362776322
Validation loss: 2.3011700328362954

Epoch: 6| Step: 11
Training loss: 1.3215733213200387
Validation loss: 2.353445814102599

Epoch: 6| Step: 12
Training loss: 1.4694126338836697
Validation loss: 2.3680418520923787

Epoch: 6| Step: 13
Training loss: 1.096252412521509
Validation loss: 2.3647445234187483

Epoch: 353| Step: 0
Training loss: 1.290626917507419
Validation loss: 2.332162221099071

Epoch: 6| Step: 1
Training loss: 0.9085923868105135
Validation loss: 2.366904169583955

Epoch: 6| Step: 2
Training loss: 1.278403492924928
Validation loss: 2.3380212031755585

Epoch: 6| Step: 3
Training loss: 1.8410470838022073
Validation loss: 2.351569479360741

Epoch: 6| Step: 4
Training loss: 1.4329450007317344
Validation loss: 2.302837112744072

Epoch: 6| Step: 5
Training loss: 0.7488368870118575
Validation loss: 2.4162746093037297

Epoch: 6| Step: 6
Training loss: 2.271741096506841
Validation loss: 2.4220850382061667

Epoch: 6| Step: 7
Training loss: 1.1982454208168734
Validation loss: 2.3616593517222864

Epoch: 6| Step: 8
Training loss: 1.425785346874465
Validation loss: 2.423946332946542

Epoch: 6| Step: 9
Training loss: 1.124603519510579
Validation loss: 2.323403412905485

Epoch: 6| Step: 10
Training loss: 1.5140992970123786
Validation loss: 2.3662022114817813

Epoch: 6| Step: 11
Training loss: 1.2612873674496086
Validation loss: 2.407450354858871

Epoch: 6| Step: 12
Training loss: 1.3769653752641018
Validation loss: 2.280750002411296

Epoch: 6| Step: 13
Training loss: 1.7785200648898567
Validation loss: 2.4178397083103325

Epoch: 354| Step: 0
Training loss: 1.4275869144629854
Validation loss: 2.3937305822885833

Epoch: 6| Step: 1
Training loss: 1.1777867041455494
Validation loss: 2.3298114956572777

Epoch: 6| Step: 2
Training loss: 1.2020738642081055
Validation loss: 2.3623716408155953

Epoch: 6| Step: 3
Training loss: 2.255336367266888
Validation loss: 2.304237508390368

Epoch: 6| Step: 4
Training loss: 1.7188459889744272
Validation loss: 2.36587435033678

Epoch: 6| Step: 5
Training loss: 1.735964072888497
Validation loss: 2.3095326463044374

Epoch: 6| Step: 6
Training loss: 1.1744740465592503
Validation loss: 2.3255080139235287

Epoch: 6| Step: 7
Training loss: 1.4127562163916056
Validation loss: 2.370492780667203

Epoch: 6| Step: 8
Training loss: 1.1292867052431173
Validation loss: 2.293253690481859

Epoch: 6| Step: 9
Training loss: 1.2886107144349797
Validation loss: 2.3343201131361964

Epoch: 6| Step: 10
Training loss: 1.4138409351409977
Validation loss: 2.40812964738519

Epoch: 6| Step: 11
Training loss: 1.4306702284956716
Validation loss: 2.3659089491509313

Epoch: 6| Step: 12
Training loss: 1.1548981883436535
Validation loss: 2.430952079313121

Epoch: 6| Step: 13
Training loss: 1.7037339827861455
Validation loss: 2.422471490682048

Epoch: 355| Step: 0
Training loss: 1.4682270498848016
Validation loss: 2.376088808709494

Epoch: 6| Step: 1
Training loss: 1.489374995389707
Validation loss: 2.3225108461298833

Epoch: 6| Step: 2
Training loss: 1.1551836612544553
Validation loss: 2.3830504466888827

Epoch: 6| Step: 3
Training loss: 1.2957108569554217
Validation loss: 2.3316686386157177

Epoch: 6| Step: 4
Training loss: 1.2292278026743517
Validation loss: 2.3401101970519362

Epoch: 6| Step: 5
Training loss: 1.4990221651053233
Validation loss: 2.3611115224195682

Epoch: 6| Step: 6
Training loss: 1.9260453667887962
Validation loss: 2.3219324630860667

Epoch: 6| Step: 7
Training loss: 1.1551003798094401
Validation loss: 2.2900039711793423

Epoch: 6| Step: 8
Training loss: 1.530369875461156
Validation loss: 2.323974453144542

Epoch: 6| Step: 9
Training loss: 1.896800901671943
Validation loss: 2.445543064639841

Epoch: 6| Step: 10
Training loss: 0.8865682331339525
Validation loss: 2.407730388676648

Epoch: 6| Step: 11
Training loss: 1.1778319462329483
Validation loss: 2.372457763869228

Epoch: 6| Step: 12
Training loss: 1.5503782426104644
Validation loss: 2.3438991748001583

Epoch: 6| Step: 13
Training loss: 1.507565334795802
Validation loss: 2.289540810740531

Epoch: 356| Step: 0
Training loss: 1.8610684032506055
Validation loss: 2.3352316489830556

Epoch: 6| Step: 1
Training loss: 1.2899780721057517
Validation loss: 2.3669401949555606

Epoch: 6| Step: 2
Training loss: 1.458893677370403
Validation loss: 2.3747840355703502

Epoch: 6| Step: 3
Training loss: 2.0956744559141094
Validation loss: 2.3290583607495403

Epoch: 6| Step: 4
Training loss: 1.3149531916710993
Validation loss: 2.367529487903109

Epoch: 6| Step: 5
Training loss: 0.9377414710283206
Validation loss: 2.3532027484437994

Epoch: 6| Step: 6
Training loss: 1.34004374532322
Validation loss: 2.3596090135389436

Epoch: 6| Step: 7
Training loss: 1.1938688249017928
Validation loss: 2.3281059234073225

Epoch: 6| Step: 8
Training loss: 1.4963763495488478
Validation loss: 2.4033180233438705

Epoch: 6| Step: 9
Training loss: 1.5982362771557206
Validation loss: 2.396606724603457

Epoch: 6| Step: 10
Training loss: 1.6927606036601015
Validation loss: 2.3574596906007605

Epoch: 6| Step: 11
Training loss: 1.5727389742625923
Validation loss: 2.3953019446779162

Epoch: 6| Step: 12
Training loss: 1.223744161278236
Validation loss: 2.301286053651689

Epoch: 6| Step: 13
Training loss: 0.8772506039395324
Validation loss: 2.329098809649235

Epoch: 357| Step: 0
Training loss: 0.9598293582930878
Validation loss: 2.2977710092636046

Epoch: 6| Step: 1
Training loss: 1.3625520433758092
Validation loss: 2.3732081650268593

Epoch: 6| Step: 2
Training loss: 1.0871176036395815
Validation loss: 2.337174915921924

Epoch: 6| Step: 3
Training loss: 1.6069222435076589
Validation loss: 2.3758514121686605

Epoch: 6| Step: 4
Training loss: 1.3069812005784422
Validation loss: 2.3640701483703825

Epoch: 6| Step: 5
Training loss: 1.3050640727716423
Validation loss: 2.4240804558762514

Epoch: 6| Step: 6
Training loss: 1.4343308884563408
Validation loss: 2.2890639010598024

Epoch: 6| Step: 7
Training loss: 1.3986166727375737
Validation loss: 2.3265946164786926

Epoch: 6| Step: 8
Training loss: 1.5111759601185382
Validation loss: 2.3379402537460052

Epoch: 6| Step: 9
Training loss: 2.4077559873569663
Validation loss: 2.3126751612492122

Epoch: 6| Step: 10
Training loss: 1.8896212474828384
Validation loss: 2.3699447021689592

Epoch: 6| Step: 11
Training loss: 0.8404733471408721
Validation loss: 2.3629542898262805

Epoch: 6| Step: 12
Training loss: 1.2252792643422707
Validation loss: 2.3230309329757945

Epoch: 6| Step: 13
Training loss: 1.1264137286232825
Validation loss: 2.338534109156055

Epoch: 358| Step: 0
Training loss: 1.2703420074902123
Validation loss: 2.3540787601928574

Epoch: 6| Step: 1
Training loss: 1.3254026448958074
Validation loss: 2.3870430167809733

Epoch: 6| Step: 2
Training loss: 1.8874898089203227
Validation loss: 2.4341233737404306

Epoch: 6| Step: 3
Training loss: 1.6584365374912928
Validation loss: 2.3114316690321806

Epoch: 6| Step: 4
Training loss: 1.0447791456624025
Validation loss: 2.307225679858478

Epoch: 6| Step: 5
Training loss: 1.1681567394828776
Validation loss: 2.4051985012688717

Epoch: 6| Step: 6
Training loss: 1.5196526878491057
Validation loss: 2.4399364453761305

Epoch: 6| Step: 7
Training loss: 2.229826773000888
Validation loss: 2.3615372313269734

Epoch: 6| Step: 8
Training loss: 1.2014928869512334
Validation loss: 2.3718475912847463

Epoch: 6| Step: 9
Training loss: 1.168865255292982
Validation loss: 2.3181273578087733

Epoch: 6| Step: 10
Training loss: 1.11862911231879
Validation loss: 2.31417245979938

Epoch: 6| Step: 11
Training loss: 1.2191255431020014
Validation loss: 2.4037252049588975

Epoch: 6| Step: 12
Training loss: 1.2549058964012527
Validation loss: 2.3043706282242473

Epoch: 6| Step: 13
Training loss: 1.2233403641102858
Validation loss: 2.357492640376624

Epoch: 359| Step: 0
Training loss: 1.3492763345751966
Validation loss: 2.387643706185549

Epoch: 6| Step: 1
Training loss: 1.6371003573257368
Validation loss: 2.2895054822373817

Epoch: 6| Step: 2
Training loss: 1.310904304893433
Validation loss: 2.350477544027638

Epoch: 6| Step: 3
Training loss: 1.1824284220962562
Validation loss: 2.3319750302720577

Epoch: 6| Step: 4
Training loss: 0.8516773531393228
Validation loss: 2.289376784616361

Epoch: 6| Step: 5
Training loss: 1.3112389091844507
Validation loss: 2.3703526123835417

Epoch: 6| Step: 6
Training loss: 1.8351465997162055
Validation loss: 2.348227429742935

Epoch: 6| Step: 7
Training loss: 1.1339768312566638
Validation loss: 2.3686503387507014

Epoch: 6| Step: 8
Training loss: 2.2232146140014617
Validation loss: 2.345244929414435

Epoch: 6| Step: 9
Training loss: 1.25491121608784
Validation loss: 2.384195687960389

Epoch: 6| Step: 10
Training loss: 1.1657493709044668
Validation loss: 2.4196961159111767

Epoch: 6| Step: 11
Training loss: 1.7832745875133267
Validation loss: 2.3113433696912336

Epoch: 6| Step: 12
Training loss: 0.8087672908886151
Validation loss: 2.387228746107163

Epoch: 6| Step: 13
Training loss: 1.0104939473804708
Validation loss: 2.36109907612477

Epoch: 360| Step: 0
Training loss: 0.9130489566270383
Validation loss: 2.3093431715723143

Epoch: 6| Step: 1
Training loss: 0.9194835096231982
Validation loss: 2.409713961148239

Epoch: 6| Step: 2
Training loss: 0.9915676433479128
Validation loss: 2.318011268063662

Epoch: 6| Step: 3
Training loss: 1.3964375948239838
Validation loss: 2.344771704896275

Epoch: 6| Step: 4
Training loss: 1.8552722063872704
Validation loss: 2.384719163803652

Epoch: 6| Step: 5
Training loss: 1.1792651298220365
Validation loss: 2.3108009309173885

Epoch: 6| Step: 6
Training loss: 1.4106074322040512
Validation loss: 2.2604709329712236

Epoch: 6| Step: 7
Training loss: 1.403213061519519
Validation loss: 2.3726626046355106

Epoch: 6| Step: 8
Training loss: 1.4171508447854875
Validation loss: 2.3458524094669344

Epoch: 6| Step: 9
Training loss: 1.9996274362692203
Validation loss: 2.3393512090808923

Epoch: 6| Step: 10
Training loss: 1.442735591405991
Validation loss: 2.35862860513029

Epoch: 6| Step: 11
Training loss: 1.375181836329169
Validation loss: 2.2912424591709977

Epoch: 6| Step: 12
Training loss: 1.2450058352475362
Validation loss: 2.3696401268828295

Epoch: 6| Step: 13
Training loss: 1.624974470671608
Validation loss: 2.2426387136628056

Epoch: 361| Step: 0
Training loss: 1.0827950216096451
Validation loss: 2.3566884842901343

Epoch: 6| Step: 1
Training loss: 1.2321941570399166
Validation loss: 2.32718568197967

Epoch: 6| Step: 2
Training loss: 2.2396566216357616
Validation loss: 2.3709724204529494

Epoch: 6| Step: 3
Training loss: 1.767553306110287
Validation loss: 2.3059070061648126

Epoch: 6| Step: 4
Training loss: 1.3065761670007054
Validation loss: 2.3791589962846222

Epoch: 6| Step: 5
Training loss: 1.6649866537756322
Validation loss: 2.358474088954504

Epoch: 6| Step: 6
Training loss: 1.0215460501554474
Validation loss: 2.3919085781137572

Epoch: 6| Step: 7
Training loss: 0.9744033748662222
Validation loss: 2.3549824853876355

Epoch: 6| Step: 8
Training loss: 1.5737279690146528
Validation loss: 2.3725410732956362

Epoch: 6| Step: 9
Training loss: 1.4069868488496964
Validation loss: 2.341558418126451

Epoch: 6| Step: 10
Training loss: 1.348337504369055
Validation loss: 2.335795579402443

Epoch: 6| Step: 11
Training loss: 1.4730197447769693
Validation loss: 2.3636429411850886

Epoch: 6| Step: 12
Training loss: 1.0740742534208574
Validation loss: 2.318982055540015

Epoch: 6| Step: 13
Training loss: 1.5025876296095884
Validation loss: 2.36571888131499

Epoch: 362| Step: 0
Training loss: 1.0803326105172073
Validation loss: 2.3083403190935634

Epoch: 6| Step: 1
Training loss: 1.4148712374599
Validation loss: 2.367075518340594

Epoch: 6| Step: 2
Training loss: 1.1270154277960691
Validation loss: 2.3271389624198378

Epoch: 6| Step: 3
Training loss: 1.273185283748658
Validation loss: 2.3970889282121344

Epoch: 6| Step: 4
Training loss: 1.3903562307479032
Validation loss: 2.3388974255132657

Epoch: 6| Step: 5
Training loss: 1.3253709399815843
Validation loss: 2.3716945335428585

Epoch: 6| Step: 6
Training loss: 1.4444509876950729
Validation loss: 2.341478656304809

Epoch: 6| Step: 7
Training loss: 1.1570107303013004
Validation loss: 2.439885510072252

Epoch: 6| Step: 8
Training loss: 1.231010438879455
Validation loss: 2.335465170035249

Epoch: 6| Step: 9
Training loss: 1.2898512767847092
Validation loss: 2.4078771211527394

Epoch: 6| Step: 10
Training loss: 1.4941063970497404
Validation loss: 2.3927770498193115

Epoch: 6| Step: 11
Training loss: 1.3643643686436917
Validation loss: 2.3276803009770908

Epoch: 6| Step: 12
Training loss: 1.4815471013203685
Validation loss: 2.3843254720612634

Epoch: 6| Step: 13
Training loss: 2.755846224942049
Validation loss: 2.377811749306713

Epoch: 363| Step: 0
Training loss: 1.2975221421074221
Validation loss: 2.3955960365330538

Epoch: 6| Step: 1
Training loss: 1.2725977556942951
Validation loss: 2.3203331512850274

Epoch: 6| Step: 2
Training loss: 1.3532655162841407
Validation loss: 2.2951672659373674

Epoch: 6| Step: 3
Training loss: 1.0365692283819115
Validation loss: 2.412407639414649

Epoch: 6| Step: 4
Training loss: 1.1922023927250864
Validation loss: 2.348504002179378

Epoch: 6| Step: 5
Training loss: 0.8467835887264671
Validation loss: 2.3414979162783407

Epoch: 6| Step: 6
Training loss: 1.370532407264039
Validation loss: 2.2967144026344344

Epoch: 6| Step: 7
Training loss: 1.488211562560157
Validation loss: 2.3749715741825224

Epoch: 6| Step: 8
Training loss: 1.507300729818806
Validation loss: 2.32772062679285

Epoch: 6| Step: 9
Training loss: 1.6828690316596584
Validation loss: 2.352569289333743

Epoch: 6| Step: 10
Training loss: 1.4071291400719408
Validation loss: 2.3854050611604225

Epoch: 6| Step: 11
Training loss: 2.2278259975555814
Validation loss: 2.4134752617487636

Epoch: 6| Step: 12
Training loss: 1.4956183014212359
Validation loss: 2.3267092229600146

Epoch: 6| Step: 13
Training loss: 1.3383761450799228
Validation loss: 2.349724998476635

Epoch: 364| Step: 0
Training loss: 1.1282252597374314
Validation loss: 2.290485093880633

Epoch: 6| Step: 1
Training loss: 1.495581476938852
Validation loss: 2.3346423031471617

Epoch: 6| Step: 2
Training loss: 0.9869846689411409
Validation loss: 2.316051650313529

Epoch: 6| Step: 3
Training loss: 2.2023370294106397
Validation loss: 2.3275359309326165

Epoch: 6| Step: 4
Training loss: 1.2022170567083257
Validation loss: 2.329445699353954

Epoch: 6| Step: 5
Training loss: 1.4483330583005116
Validation loss: 2.36687763408463

Epoch: 6| Step: 6
Training loss: 1.323983860845247
Validation loss: 2.3079767702848812

Epoch: 6| Step: 7
Training loss: 1.153085864056834
Validation loss: 2.3694068552085676

Epoch: 6| Step: 8
Training loss: 1.4835543321432143
Validation loss: 2.3972363045557334

Epoch: 6| Step: 9
Training loss: 1.6595433438931355
Validation loss: 2.4365224453020287

Epoch: 6| Step: 10
Training loss: 1.4648694659201067
Validation loss: 2.40927457050436

Epoch: 6| Step: 11
Training loss: 1.6338434934242136
Validation loss: 2.283006277756509

Epoch: 6| Step: 12
Training loss: 0.9700757461153711
Validation loss: 2.3642933604341136

Epoch: 6| Step: 13
Training loss: 1.179133354543211
Validation loss: 2.335291145135416

Epoch: 365| Step: 0
Training loss: 1.4227124776522426
Validation loss: 2.3659281521954862

Epoch: 6| Step: 1
Training loss: 1.6235689317445374
Validation loss: 2.3102070693911747

Epoch: 6| Step: 2
Training loss: 1.2367374652499539
Validation loss: 2.3433032746981346

Epoch: 6| Step: 3
Training loss: 1.6482306617309421
Validation loss: 2.2742292816022753

Epoch: 6| Step: 4
Training loss: 2.187156650300033
Validation loss: 2.3911485650275117

Epoch: 6| Step: 5
Training loss: 1.300323772459485
Validation loss: 2.3649872277738844

Epoch: 6| Step: 6
Training loss: 1.5588219650040545
Validation loss: 2.3384086906716877

Epoch: 6| Step: 7
Training loss: 1.050394093261985
Validation loss: 2.3717192132550298

Epoch: 6| Step: 8
Training loss: 0.9594373701367723
Validation loss: 2.28708007426073

Epoch: 6| Step: 9
Training loss: 1.0656165248500264
Validation loss: 2.3155704668508363

Epoch: 6| Step: 10
Training loss: 1.1472622833359147
Validation loss: 2.3203629941595123

Epoch: 6| Step: 11
Training loss: 1.3166031958979167
Validation loss: 2.4195143696954586

Epoch: 6| Step: 12
Training loss: 1.3712238130529233
Validation loss: 2.430555716268961

Epoch: 6| Step: 13
Training loss: 1.609977535304319
Validation loss: 2.288404042501755

Epoch: 366| Step: 0
Training loss: 1.436479123052464
Validation loss: 2.325376125631073

Epoch: 6| Step: 1
Training loss: 1.3593494807511721
Validation loss: 2.330844111360031

Epoch: 6| Step: 2
Training loss: 1.4972010565971867
Validation loss: 2.3500857696031807

Epoch: 6| Step: 3
Training loss: 0.8448307744831108
Validation loss: 2.365555603515375

Epoch: 6| Step: 4
Training loss: 1.1036774373206306
Validation loss: 2.3446498070602875

Epoch: 6| Step: 5
Training loss: 1.0835276148278001
Validation loss: 2.356507254989246

Epoch: 6| Step: 6
Training loss: 2.137182544535729
Validation loss: 2.4097268771192737

Epoch: 6| Step: 7
Training loss: 1.284019175894321
Validation loss: 2.3747806372207005

Epoch: 6| Step: 8
Training loss: 1.6297672475319689
Validation loss: 2.30721791967426

Epoch: 6| Step: 9
Training loss: 1.5100856900690498
Validation loss: 2.3098343848650575

Epoch: 6| Step: 10
Training loss: 1.2076375975311573
Validation loss: 2.329606998342691

Epoch: 6| Step: 11
Training loss: 1.1557924550993255
Validation loss: 2.3448314455111934

Epoch: 6| Step: 12
Training loss: 1.6577853877432946
Validation loss: 2.3112466947315093

Epoch: 6| Step: 13
Training loss: 0.9126161723455162
Validation loss: 2.373538275018834

Epoch: 367| Step: 0
Training loss: 2.3149160187815085
Validation loss: 2.3160566081192475

Epoch: 6| Step: 1
Training loss: 1.4993715559238887
Validation loss: 2.314196392036521

Epoch: 6| Step: 2
Training loss: 1.5078403292444773
Validation loss: 2.3727836630024264

Epoch: 6| Step: 3
Training loss: 1.503368648204483
Validation loss: 2.3283051319722086

Epoch: 6| Step: 4
Training loss: 1.4512134407426225
Validation loss: 2.3395953505613067

Epoch: 6| Step: 5
Training loss: 1.243353530337936
Validation loss: 2.403591789248021

Epoch: 6| Step: 6
Training loss: 1.127124264315276
Validation loss: 2.348754294056319

Epoch: 6| Step: 7
Training loss: 1.2739182483337794
Validation loss: 2.372128743113612

Epoch: 6| Step: 8
Training loss: 1.2845371227550093
Validation loss: 2.3644619015583395

Epoch: 6| Step: 9
Training loss: 1.0075324209027852
Validation loss: 2.335394366748827

Epoch: 6| Step: 10
Training loss: 1.4200600579147056
Validation loss: 2.3338381892044073

Epoch: 6| Step: 11
Training loss: 1.2683459103512529
Validation loss: 2.334743604976345

Epoch: 6| Step: 12
Training loss: 0.9822993116731901
Validation loss: 2.3766545047053893

Epoch: 6| Step: 13
Training loss: 1.451419280411856
Validation loss: 2.3533697085189753

Epoch: 368| Step: 0
Training loss: 1.4121049007698394
Validation loss: 2.3899689568502827

Epoch: 6| Step: 1
Training loss: 0.7187545610366067
Validation loss: 2.371003290261067

Epoch: 6| Step: 2
Training loss: 2.5034675392345753
Validation loss: 2.3229652069360345

Epoch: 6| Step: 3
Training loss: 1.2562084988243853
Validation loss: 2.3935641963516137

Epoch: 6| Step: 4
Training loss: 1.4057914834086238
Validation loss: 2.363548053978735

Epoch: 6| Step: 5
Training loss: 1.1858373345856885
Validation loss: 2.341901399347642

Epoch: 6| Step: 6
Training loss: 1.3928474497545158
Validation loss: 2.3492806921047467

Epoch: 6| Step: 7
Training loss: 1.0960281624343058
Validation loss: 2.3254336503251216

Epoch: 6| Step: 8
Training loss: 1.490338603083276
Validation loss: 2.315596353651145

Epoch: 6| Step: 9
Training loss: 1.1185774792679983
Validation loss: 2.3562164221994015

Epoch: 6| Step: 10
Training loss: 1.0994902253178325
Validation loss: 2.3937509501238536

Epoch: 6| Step: 11
Training loss: 1.457066757955823
Validation loss: 2.3491596491905056

Epoch: 6| Step: 12
Training loss: 1.4263776811957807
Validation loss: 2.2731719354388975

Epoch: 6| Step: 13
Training loss: 1.0216112805631667
Validation loss: 2.3012160619776822

Epoch: 369| Step: 0
Training loss: 1.3211486245550714
Validation loss: 2.443133146811536

Epoch: 6| Step: 1
Training loss: 1.358424413392904
Validation loss: 2.398443107335214

Epoch: 6| Step: 2
Training loss: 1.401087886610426
Validation loss: 2.353520289298043

Epoch: 6| Step: 3
Training loss: 1.5381564653968842
Validation loss: 2.3857272584892404

Epoch: 6| Step: 4
Training loss: 1.3682251834218457
Validation loss: 2.315682144924629

Epoch: 6| Step: 5
Training loss: 1.054058876608155
Validation loss: 2.316625007360471

Epoch: 6| Step: 6
Training loss: 1.0522397494733338
Validation loss: 2.3793643257340005

Epoch: 6| Step: 7
Training loss: 2.121277072353843
Validation loss: 2.3437589441491102

Epoch: 6| Step: 8
Training loss: 1.5666854495417344
Validation loss: 2.2498601080362475

Epoch: 6| Step: 9
Training loss: 1.258332139239892
Validation loss: 2.363063228418293

Epoch: 6| Step: 10
Training loss: 0.9864199756118753
Validation loss: 2.299845203908152

Epoch: 6| Step: 11
Training loss: 1.5683871940150307
Validation loss: 2.311697394084178

Epoch: 6| Step: 12
Training loss: 1.4957973096896533
Validation loss: 2.349843841213197

Epoch: 6| Step: 13
Training loss: 1.5198635336199222
Validation loss: 2.375505103310218

Epoch: 370| Step: 0
Training loss: 1.7483006128037886
Validation loss: 2.3514403938117026

Epoch: 6| Step: 1
Training loss: 1.2489364868153845
Validation loss: 2.315444647919894

Epoch: 6| Step: 2
Training loss: 1.1146980773235715
Validation loss: 2.4768930544990395

Epoch: 6| Step: 3
Training loss: 1.4850626908501219
Validation loss: 2.319579488353204

Epoch: 6| Step: 4
Training loss: 2.2851499899754
Validation loss: 2.3431605565184306

Epoch: 6| Step: 5
Training loss: 1.2587341343960408
Validation loss: 2.306930139967341

Epoch: 6| Step: 6
Training loss: 0.9945366750660594
Validation loss: 2.4211957208479062

Epoch: 6| Step: 7
Training loss: 1.6519844259677925
Validation loss: 2.351276585687455

Epoch: 6| Step: 8
Training loss: 1.2683356186240047
Validation loss: 2.3683301605274134

Epoch: 6| Step: 9
Training loss: 1.234148125381508
Validation loss: 2.398967806546296

Epoch: 6| Step: 10
Training loss: 1.2375883937824106
Validation loss: 2.3432213398280783

Epoch: 6| Step: 11
Training loss: 0.9686388136523241
Validation loss: 2.298558969859158

Epoch: 6| Step: 12
Training loss: 1.1851131645121027
Validation loss: 2.330633170801751

Epoch: 6| Step: 13
Training loss: 1.733352497190517
Validation loss: 2.3538727307745275

Epoch: 371| Step: 0
Training loss: 1.1707505489871857
Validation loss: 2.3193109982698155

Epoch: 6| Step: 1
Training loss: 1.3730875066223147
Validation loss: 2.3286938195053795

Epoch: 6| Step: 2
Training loss: 2.319034519887781
Validation loss: 2.326115166491809

Epoch: 6| Step: 3
Training loss: 1.438498109033301
Validation loss: 2.387708649819408

Epoch: 6| Step: 4
Training loss: 1.138037424672198
Validation loss: 2.3635126190301636

Epoch: 6| Step: 5
Training loss: 1.1500725557409968
Validation loss: 2.287949884094851

Epoch: 6| Step: 6
Training loss: 1.0683438650396675
Validation loss: 2.3037581811371193

Epoch: 6| Step: 7
Training loss: 1.1145173287976216
Validation loss: 2.284729239989372

Epoch: 6| Step: 8
Training loss: 1.9065842882558004
Validation loss: 2.375389241012403

Epoch: 6| Step: 9
Training loss: 1.500487168991615
Validation loss: 2.4233079929479473

Epoch: 6| Step: 10
Training loss: 1.2812080376429213
Validation loss: 2.270459296618612

Epoch: 6| Step: 11
Training loss: 1.1338821622622093
Validation loss: 2.3036373681896167

Epoch: 6| Step: 12
Training loss: 0.8667021071694827
Validation loss: 2.2876139193461595

Epoch: 6| Step: 13
Training loss: 0.9242110960668448
Validation loss: 2.3485184069655936

Epoch: 372| Step: 0
Training loss: 1.3500723589825956
Validation loss: 2.3338413308135033

Epoch: 6| Step: 1
Training loss: 1.2725834234955107
Validation loss: 2.3109628767510153

Epoch: 6| Step: 2
Training loss: 1.3821575100651136
Validation loss: 2.3271544765903744

Epoch: 6| Step: 3
Training loss: 1.541537159128194
Validation loss: 2.340983222764603

Epoch: 6| Step: 4
Training loss: 1.4111330236942965
Validation loss: 2.3402740122912684

Epoch: 6| Step: 5
Training loss: 1.0013666351239456
Validation loss: 2.2627565425540594

Epoch: 6| Step: 6
Training loss: 1.0488011873504761
Validation loss: 2.396508889279726

Epoch: 6| Step: 7
Training loss: 1.369243797518041
Validation loss: 2.357655148894081

Epoch: 6| Step: 8
Training loss: 1.3263546981976233
Validation loss: 2.306014063895648

Epoch: 6| Step: 9
Training loss: 2.226898703372699
Validation loss: 2.2772828440494206

Epoch: 6| Step: 10
Training loss: 1.3277754379705848
Validation loss: 2.344700456092027

Epoch: 6| Step: 11
Training loss: 1.1865476001429907
Validation loss: 2.303146398225651

Epoch: 6| Step: 12
Training loss: 1.326966442347896
Validation loss: 2.308321193942872

Epoch: 6| Step: 13
Training loss: 1.765276308990329
Validation loss: 2.3348849084980587

Epoch: 373| Step: 0
Training loss: 1.1841685092454428
Validation loss: 2.3777974669946245

Epoch: 6| Step: 1
Training loss: 1.3298072483098708
Validation loss: 2.321860412959037

Epoch: 6| Step: 2
Training loss: 2.0919657834028316
Validation loss: 2.341435973072487

Epoch: 6| Step: 3
Training loss: 1.3124247483978708
Validation loss: 2.34881265472875

Epoch: 6| Step: 4
Training loss: 1.2811545359705214
Validation loss: 2.324635659880974

Epoch: 6| Step: 5
Training loss: 1.2862937090892113
Validation loss: 2.378073964944393

Epoch: 6| Step: 6
Training loss: 1.2982707957499815
Validation loss: 2.321779137476093

Epoch: 6| Step: 7
Training loss: 1.5757556918884346
Validation loss: 2.281679609423149

Epoch: 6| Step: 8
Training loss: 1.133818554556269
Validation loss: 2.2917777682432905

Epoch: 6| Step: 9
Training loss: 1.4790196233741064
Validation loss: 2.3401223485429794

Epoch: 6| Step: 10
Training loss: 1.395724259095606
Validation loss: 2.279159220484821

Epoch: 6| Step: 11
Training loss: 1.263439504964796
Validation loss: 2.340810201693402

Epoch: 6| Step: 12
Training loss: 1.0449780030194098
Validation loss: 2.38522834390898

Epoch: 6| Step: 13
Training loss: 1.6966970389045277
Validation loss: 2.378000562745763

Epoch: 374| Step: 0
Training loss: 1.2382642100993881
Validation loss: 2.3311780473364045

Epoch: 6| Step: 1
Training loss: 1.5011061722261387
Validation loss: 2.287596962555552

Epoch: 6| Step: 2
Training loss: 1.657973274682791
Validation loss: 2.3255554034229826

Epoch: 6| Step: 3
Training loss: 0.7661054232737143
Validation loss: 2.338277171513319

Epoch: 6| Step: 4
Training loss: 1.442572723882642
Validation loss: 2.3831993355211383

Epoch: 6| Step: 5
Training loss: 1.6539369662265646
Validation loss: 2.439428041800555

Epoch: 6| Step: 6
Training loss: 0.605531996838399
Validation loss: 2.365450701929686

Epoch: 6| Step: 7
Training loss: 1.438986797184715
Validation loss: 2.3928813116238956

Epoch: 6| Step: 8
Training loss: 1.601552898099075
Validation loss: 2.4059843021339287

Epoch: 6| Step: 9
Training loss: 1.4376444536688462
Validation loss: 2.377635650503588

Epoch: 6| Step: 10
Training loss: 0.9391704300537347
Validation loss: 2.426010944496677

Epoch: 6| Step: 11
Training loss: 1.0890215435016395
Validation loss: 2.454454061834773

Epoch: 6| Step: 12
Training loss: 0.9837823930809267
Validation loss: 2.3462096610673795

Epoch: 6| Step: 13
Training loss: 2.8725904235684467
Validation loss: 2.2935775158635088

Epoch: 375| Step: 0
Training loss: 1.12586052090684
Validation loss: 2.3258042541003583

Epoch: 6| Step: 1
Training loss: 2.151868487328018
Validation loss: 2.346797688184081

Epoch: 6| Step: 2
Training loss: 1.4753285252291222
Validation loss: 2.3199033984555815

Epoch: 6| Step: 3
Training loss: 1.2389953190989893
Validation loss: 2.40050301864871

Epoch: 6| Step: 4
Training loss: 1.0887940523364923
Validation loss: 2.312514955538231

Epoch: 6| Step: 5
Training loss: 1.1912942302134089
Validation loss: 2.3091769000641493

Epoch: 6| Step: 6
Training loss: 1.4651328653489453
Validation loss: 2.400188341834626

Epoch: 6| Step: 7
Training loss: 1.5536602210993056
Validation loss: 2.3648991898067915

Epoch: 6| Step: 8
Training loss: 1.3285110361389572
Validation loss: 2.2764466157473193

Epoch: 6| Step: 9
Training loss: 1.291504644671339
Validation loss: 2.266201479182955

Epoch: 6| Step: 10
Training loss: 0.9905271078653101
Validation loss: 2.2604791723230337

Epoch: 6| Step: 11
Training loss: 1.680671722908893
Validation loss: 2.3739082350757807

Epoch: 6| Step: 12
Training loss: 1.4376532431480755
Validation loss: 2.2952574541773387

Epoch: 6| Step: 13
Training loss: 1.352237070020038
Validation loss: 2.3785301768106017

Epoch: 376| Step: 0
Training loss: 1.1437981767357404
Validation loss: 2.3379402636148483

Epoch: 6| Step: 1
Training loss: 0.7931152358780513
Validation loss: 2.3893946399012287

Epoch: 6| Step: 2
Training loss: 1.4513085610257526
Validation loss: 2.3760369891501307

Epoch: 6| Step: 3
Training loss: 1.2771097604694182
Validation loss: 2.3465562319852276

Epoch: 6| Step: 4
Training loss: 0.7691157424644887
Validation loss: 2.39562261081854

Epoch: 6| Step: 5
Training loss: 1.6466427836571642
Validation loss: 2.32688763232812

Epoch: 6| Step: 6
Training loss: 1.2277955096150117
Validation loss: 2.3080527665259885

Epoch: 6| Step: 7
Training loss: 1.0586671698190309
Validation loss: 2.4134962691736153

Epoch: 6| Step: 8
Training loss: 1.1500355507704485
Validation loss: 2.3274468194452247

Epoch: 6| Step: 9
Training loss: 1.330784994946234
Validation loss: 2.3810403475061683

Epoch: 6| Step: 10
Training loss: 2.1261860398635957
Validation loss: 2.319776335876478

Epoch: 6| Step: 11
Training loss: 1.5277550185078521
Validation loss: 2.354664478670823

Epoch: 6| Step: 12
Training loss: 1.4510620404210004
Validation loss: 2.323378188519329

Epoch: 6| Step: 13
Training loss: 1.8552896192314632
Validation loss: 2.363026928046178

Epoch: 377| Step: 0
Training loss: 2.376433391688186
Validation loss: 2.3121074403182247

Epoch: 6| Step: 1
Training loss: 1.4765550724226213
Validation loss: 2.375355742991224

Epoch: 6| Step: 2
Training loss: 1.3610198932149624
Validation loss: 2.3299165659435292

Epoch: 6| Step: 3
Training loss: 1.7696943397396532
Validation loss: 2.286621104120619

Epoch: 6| Step: 4
Training loss: 1.0392781084125997
Validation loss: 2.290091346965802

Epoch: 6| Step: 5
Training loss: 1.4089555357204386
Validation loss: 2.3329688335391

Epoch: 6| Step: 6
Training loss: 1.0528157331915804
Validation loss: 2.29719334039055

Epoch: 6| Step: 7
Training loss: 1.2434124454985427
Validation loss: 2.3440551887259495

Epoch: 6| Step: 8
Training loss: 1.1412203554479392
Validation loss: 2.3690170073095964

Epoch: 6| Step: 9
Training loss: 1.2035432559181107
Validation loss: 2.266242444772333

Epoch: 6| Step: 10
Training loss: 1.2825896540010515
Validation loss: 2.299794490009467

Epoch: 6| Step: 11
Training loss: 1.4788248804502087
Validation loss: 2.407160561782981

Epoch: 6| Step: 12
Training loss: 1.003465370116696
Validation loss: 2.2847055296918697

Epoch: 6| Step: 13
Training loss: 1.030002417330081
Validation loss: 2.3797444964895447

Epoch: 378| Step: 0
Training loss: 0.8426192442048459
Validation loss: 2.301753121274319

Epoch: 6| Step: 1
Training loss: 1.4718207865650264
Validation loss: 2.32621554142765

Epoch: 6| Step: 2
Training loss: 0.8690167971064234
Validation loss: 2.2811232838012696

Epoch: 6| Step: 3
Training loss: 1.1530624992986367
Validation loss: 2.3386310430863673

Epoch: 6| Step: 4
Training loss: 1.324392526752744
Validation loss: 2.378489990822699

Epoch: 6| Step: 5
Training loss: 1.3945162903226407
Validation loss: 2.3759864556834684

Epoch: 6| Step: 6
Training loss: 1.4199062593170728
Validation loss: 2.447611015540773

Epoch: 6| Step: 7
Training loss: 1.2647007522661606
Validation loss: 2.3313091136529827

Epoch: 6| Step: 8
Training loss: 1.0625347243973873
Validation loss: 2.3544215856455364

Epoch: 6| Step: 9
Training loss: 2.537798663823722
Validation loss: 2.347670457969065

Epoch: 6| Step: 10
Training loss: 1.101359896594284
Validation loss: 2.3807125634979336

Epoch: 6| Step: 11
Training loss: 1.4546572902341122
Validation loss: 2.3570432315295804

Epoch: 6| Step: 12
Training loss: 1.2022909270562847
Validation loss: 2.3287493340801726

Epoch: 6| Step: 13
Training loss: 1.468133025750333
Validation loss: 2.3163318033772895

Epoch: 379| Step: 0
Training loss: 1.21237677901712
Validation loss: 2.326773846661575

Epoch: 6| Step: 1
Training loss: 1.2857573706356105
Validation loss: 2.2110345850228286

Epoch: 6| Step: 2
Training loss: 1.2394473484793151
Validation loss: 2.363316293563564

Epoch: 6| Step: 3
Training loss: 1.0446391355939628
Validation loss: 2.333081041340934

Epoch: 6| Step: 4
Training loss: 2.1163806011100372
Validation loss: 2.3227215469796825

Epoch: 6| Step: 5
Training loss: 1.2129913632241862
Validation loss: 2.381585040993524

Epoch: 6| Step: 6
Training loss: 1.1811479029861747
Validation loss: 2.334405117458648

Epoch: 6| Step: 7
Training loss: 1.0768386243099688
Validation loss: 2.3083870393028727

Epoch: 6| Step: 8
Training loss: 1.223473419012955
Validation loss: 2.2911883984050876

Epoch: 6| Step: 9
Training loss: 1.207237300136911
Validation loss: 2.3444006046246315

Epoch: 6| Step: 10
Training loss: 1.5862086773623603
Validation loss: 2.3572883856683853

Epoch: 6| Step: 11
Training loss: 1.3364846520076015
Validation loss: 2.3047142443001145

Epoch: 6| Step: 12
Training loss: 1.5319682402543302
Validation loss: 2.285450503413962

Epoch: 6| Step: 13
Training loss: 1.267661681161834
Validation loss: 2.313055632980855

Epoch: 380| Step: 0
Training loss: 1.3751716940062104
Validation loss: 2.351459200422423

Epoch: 6| Step: 1
Training loss: 0.9475880496901533
Validation loss: 2.326141215877346

Epoch: 6| Step: 2
Training loss: 1.2322063469177058
Validation loss: 2.378534494575902

Epoch: 6| Step: 3
Training loss: 1.521426551121599
Validation loss: 2.3113366138114553

Epoch: 6| Step: 4
Training loss: 2.3142245280370295
Validation loss: 2.4299173912725403

Epoch: 6| Step: 5
Training loss: 1.3028357150396959
Validation loss: 2.3765408753174464

Epoch: 6| Step: 6
Training loss: 1.1869152536742469
Validation loss: 2.281922187559158

Epoch: 6| Step: 7
Training loss: 1.2905424003862966
Validation loss: 2.3500608190670604

Epoch: 6| Step: 8
Training loss: 1.1152569823637601
Validation loss: 2.277841244923936

Epoch: 6| Step: 9
Training loss: 1.6332640685102249
Validation loss: 2.296527313041494

Epoch: 6| Step: 10
Training loss: 1.2090962840408621
Validation loss: 2.3674260327970984

Epoch: 6| Step: 11
Training loss: 0.994161549406053
Validation loss: 2.300225105121926

Epoch: 6| Step: 12
Training loss: 1.32045343312751
Validation loss: 2.30943326855888

Epoch: 6| Step: 13
Training loss: 1.1180101047120645
Validation loss: 2.382901585132574

Epoch: 381| Step: 0
Training loss: 2.1718429453288755
Validation loss: 2.3176314663466164

Epoch: 6| Step: 1
Training loss: 0.9781591561785735
Validation loss: 2.3076978230758862

Epoch: 6| Step: 2
Training loss: 1.3363128937781825
Validation loss: 2.3088654921987692

Epoch: 6| Step: 3
Training loss: 0.8961439629132867
Validation loss: 2.3560693297246083

Epoch: 6| Step: 4
Training loss: 1.6234464555186774
Validation loss: 2.3463485193436697

Epoch: 6| Step: 5
Training loss: 1.0127710003282258
Validation loss: 2.3293492419126243

Epoch: 6| Step: 6
Training loss: 1.025694476929491
Validation loss: 2.3065745936329045

Epoch: 6| Step: 7
Training loss: 1.4792967815212787
Validation loss: 2.291513822908384

Epoch: 6| Step: 8
Training loss: 1.2119215381769834
Validation loss: 2.3100309713351015

Epoch: 6| Step: 9
Training loss: 1.5349198564613324
Validation loss: 2.3658506704996967

Epoch: 6| Step: 10
Training loss: 1.3366911251528903
Validation loss: 2.3878246068449522

Epoch: 6| Step: 11
Training loss: 1.0750893134341684
Validation loss: 2.3113525074558354

Epoch: 6| Step: 12
Training loss: 0.6970089565560899
Validation loss: 2.371642173697287

Epoch: 6| Step: 13
Training loss: 1.3347767477490315
Validation loss: 2.3903591553225576

Epoch: 382| Step: 0
Training loss: 2.199109686252691
Validation loss: 2.335697839059254

Epoch: 6| Step: 1
Training loss: 1.5322300635565882
Validation loss: 2.3933981758855043

Epoch: 6| Step: 2
Training loss: 1.6069547361445293
Validation loss: 2.372351008922519

Epoch: 6| Step: 3
Training loss: 1.391585372027527
Validation loss: 2.4371731057479415

Epoch: 6| Step: 4
Training loss: 1.2450313523569378
Validation loss: 2.3229949539201313

Epoch: 6| Step: 5
Training loss: 0.9617731136324048
Validation loss: 2.327255821248921

Epoch: 6| Step: 6
Training loss: 1.3966805700385487
Validation loss: 2.4057077330320333

Epoch: 6| Step: 7
Training loss: 0.8991532501572641
Validation loss: 2.3141706130957664

Epoch: 6| Step: 8
Training loss: 1.2464050095556656
Validation loss: 2.3287436029654596

Epoch: 6| Step: 9
Training loss: 1.00019625883648
Validation loss: 2.346704691463932

Epoch: 6| Step: 10
Training loss: 1.3453389022309876
Validation loss: 2.3932316907829456

Epoch: 6| Step: 11
Training loss: 1.1730418690089706
Validation loss: 2.344979014411325

Epoch: 6| Step: 12
Training loss: 1.079853441484424
Validation loss: 2.2856226476415116

Epoch: 6| Step: 13
Training loss: 1.2515194241353336
Validation loss: 2.3602294298338187

Epoch: 383| Step: 0
Training loss: 0.9896407897063481
Validation loss: 2.3034637333422388

Epoch: 6| Step: 1
Training loss: 1.2363859768751329
Validation loss: 2.347809812392299

Epoch: 6| Step: 2
Training loss: 1.4078844109225508
Validation loss: 2.385078478387711

Epoch: 6| Step: 3
Training loss: 1.1006542817552507
Validation loss: 2.324244495806616

Epoch: 6| Step: 4
Training loss: 1.6968320725211514
Validation loss: 2.353063350603614

Epoch: 6| Step: 5
Training loss: 1.6270600978675478
Validation loss: 2.334984872409795

Epoch: 6| Step: 6
Training loss: 1.2455167002283793
Validation loss: 2.4138684304771187

Epoch: 6| Step: 7
Training loss: 0.87767950276083
Validation loss: 2.3313587725393905

Epoch: 6| Step: 8
Training loss: 0.8015919745010189
Validation loss: 2.2916460519200914

Epoch: 6| Step: 9
Training loss: 1.35830747408133
Validation loss: 2.349357603970647

Epoch: 6| Step: 10
Training loss: 1.33314007113451
Validation loss: 2.3520411247319455

Epoch: 6| Step: 11
Training loss: 1.1200348641725288
Validation loss: 2.389541235549717

Epoch: 6| Step: 12
Training loss: 1.339339892790172
Validation loss: 2.3635170824593703

Epoch: 6| Step: 13
Training loss: 2.706966250741558
Validation loss: 2.3768179864827044

Epoch: 384| Step: 0
Training loss: 1.2564367981000613
Validation loss: 2.3170477214748444

Epoch: 6| Step: 1
Training loss: 1.2884482104929311
Validation loss: 2.3653271081633984

Epoch: 6| Step: 2
Training loss: 0.9006862196542281
Validation loss: 2.2639569493896055

Epoch: 6| Step: 3
Training loss: 1.1776858394104777
Validation loss: 2.281817082961224

Epoch: 6| Step: 4
Training loss: 1.2248499875762051
Validation loss: 2.4007011971012626

Epoch: 6| Step: 5
Training loss: 1.0575374950137633
Validation loss: 2.368441787907931

Epoch: 6| Step: 6
Training loss: 1.1362335113235478
Validation loss: 2.3545639598714145

Epoch: 6| Step: 7
Training loss: 1.0964070335321234
Validation loss: 2.2305696497397793

Epoch: 6| Step: 8
Training loss: 2.313264874957874
Validation loss: 2.386528472514941

Epoch: 6| Step: 9
Training loss: 1.2310417173399275
Validation loss: 2.2687044075421325

Epoch: 6| Step: 10
Training loss: 1.470455072769214
Validation loss: 2.283052140285224

Epoch: 6| Step: 11
Training loss: 1.5210798751754684
Validation loss: 2.3443171153437965

Epoch: 6| Step: 12
Training loss: 1.4270589877462831
Validation loss: 2.390870333383312

Epoch: 6| Step: 13
Training loss: 1.7351721229153545
Validation loss: 2.3553040737232935

Epoch: 385| Step: 0
Training loss: 1.0759388970890331
Validation loss: 2.338792388745497

Epoch: 6| Step: 1
Training loss: 0.8594634270689924
Validation loss: 2.3359927475000246

Epoch: 6| Step: 2
Training loss: 1.46418841135071
Validation loss: 2.3220369370986496

Epoch: 6| Step: 3
Training loss: 1.214234324978676
Validation loss: 2.3328215835163992

Epoch: 6| Step: 4
Training loss: 1.084739078668079
Validation loss: 2.3303012002410646

Epoch: 6| Step: 5
Training loss: 1.3018454474264545
Validation loss: 2.377079164236168

Epoch: 6| Step: 6
Training loss: 1.247884103968985
Validation loss: 2.407243196316429

Epoch: 6| Step: 7
Training loss: 1.466171110848881
Validation loss: 2.3263865998653324

Epoch: 6| Step: 8
Training loss: 2.4583060591741845
Validation loss: 2.2995074702928773

Epoch: 6| Step: 9
Training loss: 1.117117872936149
Validation loss: 2.3562784191219617

Epoch: 6| Step: 10
Training loss: 1.2307397453164495
Validation loss: 2.3236337834390492

Epoch: 6| Step: 11
Training loss: 1.179094430757508
Validation loss: 2.339523452101895

Epoch: 6| Step: 12
Training loss: 1.1989888023572617
Validation loss: 2.289450241658046

Epoch: 6| Step: 13
Training loss: 1.446902251347417
Validation loss: 2.3019856372957985

Epoch: 386| Step: 0
Training loss: 1.0634477539644283
Validation loss: 2.3334566367951433

Epoch: 6| Step: 1
Training loss: 1.3382782980045111
Validation loss: 2.295815863259123

Epoch: 6| Step: 2
Training loss: 1.304168232357235
Validation loss: 2.4055383890124213

Epoch: 6| Step: 3
Training loss: 1.0503919369486159
Validation loss: 2.3379211508771873

Epoch: 6| Step: 4
Training loss: 1.4881846479167717
Validation loss: 2.36291758743514

Epoch: 6| Step: 5
Training loss: 1.5071003867863084
Validation loss: 2.3735636116909604

Epoch: 6| Step: 6
Training loss: 1.5561128149886183
Validation loss: 2.3368571517188976

Epoch: 6| Step: 7
Training loss: 1.1464399754831756
Validation loss: 2.3205449416813404

Epoch: 6| Step: 8
Training loss: 1.7321678069934427
Validation loss: 2.389991236038331

Epoch: 6| Step: 9
Training loss: 1.1803089551238664
Validation loss: 2.3589817592201117

Epoch: 6| Step: 10
Training loss: 0.9168781051115102
Validation loss: 2.3102184149531566

Epoch: 6| Step: 11
Training loss: 0.8551856142868153
Validation loss: 2.2886522897021724

Epoch: 6| Step: 12
Training loss: 2.084779796727291
Validation loss: 2.3345412066659588

Epoch: 6| Step: 13
Training loss: 1.5529229967244007
Validation loss: 2.3478110588284427

Epoch: 387| Step: 0
Training loss: 1.2630439625093752
Validation loss: 2.3519086086006387

Epoch: 6| Step: 1
Training loss: 1.3946825901691258
Validation loss: 2.398536101036676

Epoch: 6| Step: 2
Training loss: 1.5621412246788267
Validation loss: 2.2598958399053286

Epoch: 6| Step: 3
Training loss: 1.2610099856732262
Validation loss: 2.3901063926382022

Epoch: 6| Step: 4
Training loss: 1.4119835846354691
Validation loss: 2.3502536224893325

Epoch: 6| Step: 5
Training loss: 1.1949979081394928
Validation loss: 2.3216585423345997

Epoch: 6| Step: 6
Training loss: 1.1288238812132578
Validation loss: 2.3260180308793132

Epoch: 6| Step: 7
Training loss: 1.060854479051329
Validation loss: 2.3978515670331566

Epoch: 6| Step: 8
Training loss: 2.097647611859542
Validation loss: 2.3359978945456854

Epoch: 6| Step: 9
Training loss: 1.5596089892765985
Validation loss: 2.335550930681281

Epoch: 6| Step: 10
Training loss: 1.5140487497057669
Validation loss: 2.3112115610295625

Epoch: 6| Step: 11
Training loss: 1.164127834457933
Validation loss: 2.3165980713404135

Epoch: 6| Step: 12
Training loss: 1.2878481607144308
Validation loss: 2.319430175248414

Epoch: 6| Step: 13
Training loss: 0.9191140031181356
Validation loss: 2.3211373919696663

Epoch: 388| Step: 0
Training loss: 1.0507300268685091
Validation loss: 2.3126262584874797

Epoch: 6| Step: 1
Training loss: 1.5876713187222773
Validation loss: 2.3687872040616194

Epoch: 6| Step: 2
Training loss: 0.9693460784080351
Validation loss: 2.3472743290606433

Epoch: 6| Step: 3
Training loss: 1.20577730394454
Validation loss: 2.3037068606405184

Epoch: 6| Step: 4
Training loss: 1.214987350759084
Validation loss: 2.312616345339847

Epoch: 6| Step: 5
Training loss: 1.5665850073588001
Validation loss: 2.368992483414406

Epoch: 6| Step: 6
Training loss: 1.3090298509567309
Validation loss: 2.351325454350355

Epoch: 6| Step: 7
Training loss: 1.2710522270337088
Validation loss: 2.2536677963786893

Epoch: 6| Step: 8
Training loss: 0.9853358347821864
Validation loss: 2.3790395414346253

Epoch: 6| Step: 9
Training loss: 1.016444535820831
Validation loss: 2.340701212048112

Epoch: 6| Step: 10
Training loss: 1.0086161048828806
Validation loss: 2.350589402457467

Epoch: 6| Step: 11
Training loss: 2.2388257068504234
Validation loss: 2.366614934028577

Epoch: 6| Step: 12
Training loss: 1.1212287848091136
Validation loss: 2.2884095486441716

Epoch: 6| Step: 13
Training loss: 1.5948007896888294
Validation loss: 2.4090815348634433

Epoch: 389| Step: 0
Training loss: 1.5043675891676251
Validation loss: 2.3333676300150503

Epoch: 6| Step: 1
Training loss: 1.6154341476133494
Validation loss: 2.362833178126357

Epoch: 6| Step: 2
Training loss: 1.185268363100713
Validation loss: 2.410772566604398

Epoch: 6| Step: 3
Training loss: 1.2017423438123331
Validation loss: 2.39028564024044

Epoch: 6| Step: 4
Training loss: 1.1293549487429735
Validation loss: 2.4090654298597305

Epoch: 6| Step: 5
Training loss: 1.1759712851418134
Validation loss: 2.2978565818871575

Epoch: 6| Step: 6
Training loss: 1.4450532422932152
Validation loss: 2.349861782366804

Epoch: 6| Step: 7
Training loss: 2.059601104781076
Validation loss: 2.2880199112750037

Epoch: 6| Step: 8
Training loss: 0.979958177131478
Validation loss: 2.353325645033971

Epoch: 6| Step: 9
Training loss: 0.7711175360291342
Validation loss: 2.373159472590677

Epoch: 6| Step: 10
Training loss: 0.7966575325823988
Validation loss: 2.3225366075575407

Epoch: 6| Step: 11
Training loss: 1.496554072307149
Validation loss: 2.3104713186332426

Epoch: 6| Step: 12
Training loss: 1.2272344315940729
Validation loss: 2.4179286501201007

Epoch: 6| Step: 13
Training loss: 1.22121195449838
Validation loss: 2.3869583178555787

Epoch: 390| Step: 0
Training loss: 1.6502176227973517
Validation loss: 2.3899005138212117

Epoch: 6| Step: 1
Training loss: 1.0832672221234139
Validation loss: 2.3536174379239165

Epoch: 6| Step: 2
Training loss: 1.1122245190326028
Validation loss: 2.3390666216153626

Epoch: 6| Step: 3
Training loss: 0.9028722363149381
Validation loss: 2.346646037477188

Epoch: 6| Step: 4
Training loss: 1.3306320314235007
Validation loss: 2.39641691557671

Epoch: 6| Step: 5
Training loss: 1.2737776413184152
Validation loss: 2.4203269364108575

Epoch: 6| Step: 6
Training loss: 2.4059853346291287
Validation loss: 2.2998938277832854

Epoch: 6| Step: 7
Training loss: 1.5618960930116286
Validation loss: 2.43109623916552

Epoch: 6| Step: 8
Training loss: 1.0639113981313155
Validation loss: 2.3561555987515295

Epoch: 6| Step: 9
Training loss: 1.0462240786058807
Validation loss: 2.3252463665509744

Epoch: 6| Step: 10
Training loss: 1.106377918584782
Validation loss: 2.337716426440801

Epoch: 6| Step: 11
Training loss: 1.2127441219485418
Validation loss: 2.346600890169699

Epoch: 6| Step: 12
Training loss: 1.147141848086782
Validation loss: 2.2405512769664426

Epoch: 6| Step: 13
Training loss: 1.4990991430394527
Validation loss: 2.2609311809242145

Epoch: 391| Step: 0
Training loss: 1.579968197538724
Validation loss: 2.3003913873194213

Epoch: 6| Step: 1
Training loss: 1.1383231988532991
Validation loss: 2.3564104093653735

Epoch: 6| Step: 2
Training loss: 1.4580187685351087
Validation loss: 2.3419584803716478

Epoch: 6| Step: 3
Training loss: 1.1429652414118119
Validation loss: 2.336770502099667

Epoch: 6| Step: 4
Training loss: 1.2043956140754426
Validation loss: 2.3173312278722746

Epoch: 6| Step: 5
Training loss: 0.8093974960912419
Validation loss: 2.33997995785198

Epoch: 6| Step: 6
Training loss: 0.9649754175701784
Validation loss: 2.400430856590827

Epoch: 6| Step: 7
Training loss: 0.9531714943974043
Validation loss: 2.321125088073968

Epoch: 6| Step: 8
Training loss: 1.3894211776960042
Validation loss: 2.3210179000490627

Epoch: 6| Step: 9
Training loss: 2.0561027729234467
Validation loss: 2.3007461776663405

Epoch: 6| Step: 10
Training loss: 1.1405180789529725
Validation loss: 2.2766855820082177

Epoch: 6| Step: 11
Training loss: 1.3649709553824876
Validation loss: 2.2582773893209644

Epoch: 6| Step: 12
Training loss: 0.926766398543851
Validation loss: 2.3289879807633507

Epoch: 6| Step: 13
Training loss: 1.8957927475941152
Validation loss: 2.3115115249515163

Epoch: 392| Step: 0
Training loss: 1.1620897820367764
Validation loss: 2.2925442004573817

Epoch: 6| Step: 1
Training loss: 2.0710978619834344
Validation loss: 2.267804499111271

Epoch: 6| Step: 2
Training loss: 0.8464307232002192
Validation loss: 2.3346774175129137

Epoch: 6| Step: 3
Training loss: 0.7507009409685031
Validation loss: 2.2853922157401625

Epoch: 6| Step: 4
Training loss: 1.3942553677399996
Validation loss: 2.3625837136836276

Epoch: 6| Step: 5
Training loss: 0.9368326673047799
Validation loss: 2.3468449154167255

Epoch: 6| Step: 6
Training loss: 1.693364021268496
Validation loss: 2.3297218582836163

Epoch: 6| Step: 7
Training loss: 1.1208473493037685
Validation loss: 2.3514927205163145

Epoch: 6| Step: 8
Training loss: 0.661911408753083
Validation loss: 2.35633504633612

Epoch: 6| Step: 9
Training loss: 1.4495292392662078
Validation loss: 2.40464879236227

Epoch: 6| Step: 10
Training loss: 1.6358367801473834
Validation loss: 2.3336230184623292

Epoch: 6| Step: 11
Training loss: 1.4677756303782272
Validation loss: 2.3956331131046404

Epoch: 6| Step: 12
Training loss: 1.5178129782782954
Validation loss: 2.3334816506120806

Epoch: 6| Step: 13
Training loss: 1.2189337274031111
Validation loss: 2.276373987474592

Epoch: 393| Step: 0
Training loss: 1.1006303996571578
Validation loss: 2.351189887949383

Epoch: 6| Step: 1
Training loss: 1.2612115649594735
Validation loss: 2.323869574219577

Epoch: 6| Step: 2
Training loss: 1.1664694664822357
Validation loss: 2.3575317271307186

Epoch: 6| Step: 3
Training loss: 1.3921906733449954
Validation loss: 2.3400423646746216

Epoch: 6| Step: 4
Training loss: 0.9930549794234684
Validation loss: 2.2806893296189994

Epoch: 6| Step: 5
Training loss: 1.1418646255631566
Validation loss: 2.344151083149952

Epoch: 6| Step: 6
Training loss: 1.009692132219594
Validation loss: 2.305719382721228

Epoch: 6| Step: 7
Training loss: 1.4489513057901233
Validation loss: 2.2855718985782723

Epoch: 6| Step: 8
Training loss: 1.295080298949895
Validation loss: 2.2714281261851883

Epoch: 6| Step: 9
Training loss: 1.2675929840110405
Validation loss: 2.310041857757781

Epoch: 6| Step: 10
Training loss: 2.0927985007831906
Validation loss: 2.27998420658949

Epoch: 6| Step: 11
Training loss: 1.6294690813266484
Validation loss: 2.324199981075952

Epoch: 6| Step: 12
Training loss: 1.170202511354189
Validation loss: 2.2593788651753415

Epoch: 6| Step: 13
Training loss: 0.96344674476249
Validation loss: 2.323908439941199

Epoch: 394| Step: 0
Training loss: 2.2201106238081474
Validation loss: 2.293686651254963

Epoch: 6| Step: 1
Training loss: 0.9123232017015382
Validation loss: 2.317390142603552

Epoch: 6| Step: 2
Training loss: 1.1427647104094696
Validation loss: 2.273207998213148

Epoch: 6| Step: 3
Training loss: 1.3682662631629086
Validation loss: 2.344681676180169

Epoch: 6| Step: 4
Training loss: 1.0179952107150094
Validation loss: 2.3386279835504413

Epoch: 6| Step: 5
Training loss: 1.2349885791760142
Validation loss: 2.302032035449493

Epoch: 6| Step: 6
Training loss: 1.0196419725182815
Validation loss: 2.2405286834628964

Epoch: 6| Step: 7
Training loss: 1.0760176698729935
Validation loss: 2.2568373432310262

Epoch: 6| Step: 8
Training loss: 1.6823395839358624
Validation loss: 2.2895628668444297

Epoch: 6| Step: 9
Training loss: 1.434560174562119
Validation loss: 2.317078851653005

Epoch: 6| Step: 10
Training loss: 1.3519140238426957
Validation loss: 2.3276596501707396

Epoch: 6| Step: 11
Training loss: 1.1526228227353814
Validation loss: 2.2842152330532977

Epoch: 6| Step: 12
Training loss: 1.3334661457354324
Validation loss: 2.2491521821765

Epoch: 6| Step: 13
Training loss: 1.4704706380611285
Validation loss: 2.361394095267126

Epoch: 395| Step: 0
Training loss: 1.0973068169819655
Validation loss: 2.394532190006958

Epoch: 6| Step: 1
Training loss: 1.1435134580559985
Validation loss: 2.359054157880121

Epoch: 6| Step: 2
Training loss: 1.3032990337128527
Validation loss: 2.3773911166863106

Epoch: 6| Step: 3
Training loss: 1.272922435108523
Validation loss: 2.3397272755399996

Epoch: 6| Step: 4
Training loss: 1.3073961841804755
Validation loss: 2.312314698728052

Epoch: 6| Step: 5
Training loss: 1.0851229899440218
Validation loss: 2.2667141060084295

Epoch: 6| Step: 6
Training loss: 1.2642623253029732
Validation loss: 2.362908809111672

Epoch: 6| Step: 7
Training loss: 1.149353233160333
Validation loss: 2.304471993108022

Epoch: 6| Step: 8
Training loss: 1.0595637308083314
Validation loss: 2.2505939399310195

Epoch: 6| Step: 9
Training loss: 1.1337048928941156
Validation loss: 2.393200368557433

Epoch: 6| Step: 10
Training loss: 1.5146940852849033
Validation loss: 2.2695991599567917

Epoch: 6| Step: 11
Training loss: 0.9150583108446921
Validation loss: 2.3732295618363444

Epoch: 6| Step: 12
Training loss: 2.0983686604857685
Validation loss: 2.3396142403332036

Epoch: 6| Step: 13
Training loss: 1.0758492597193492
Validation loss: 2.3497644953779844

Epoch: 396| Step: 0
Training loss: 1.3038889102685667
Validation loss: 2.319952077098366

Epoch: 6| Step: 1
Training loss: 0.8712879186886546
Validation loss: 2.3348737256160645

Epoch: 6| Step: 2
Training loss: 0.9699702115253285
Validation loss: 2.332661048077362

Epoch: 6| Step: 3
Training loss: 1.4505729003912093
Validation loss: 2.27826022652918

Epoch: 6| Step: 4
Training loss: 1.4595021423240482
Validation loss: 2.347591045774236

Epoch: 6| Step: 5
Training loss: 0.9565550573109926
Validation loss: 2.322308746682415

Epoch: 6| Step: 6
Training loss: 1.3948356659463625
Validation loss: 2.3356115437729073

Epoch: 6| Step: 7
Training loss: 1.5209101130643732
Validation loss: 2.2837403089524235

Epoch: 6| Step: 8
Training loss: 1.1108660818501548
Validation loss: 2.3726279249423183

Epoch: 6| Step: 9
Training loss: 1.2066103994746193
Validation loss: 2.3894111113851455

Epoch: 6| Step: 10
Training loss: 0.9237289536779585
Validation loss: 2.3404575884684427

Epoch: 6| Step: 11
Training loss: 1.7004775722856316
Validation loss: 2.3195433029625208

Epoch: 6| Step: 12
Training loss: 2.0223620292464073
Validation loss: 2.364891506674843

Epoch: 6| Step: 13
Training loss: 1.3946050202334448
Validation loss: 2.3769637405129207

Epoch: 397| Step: 0
Training loss: 1.059701206542737
Validation loss: 2.336027425638149

Epoch: 6| Step: 1
Training loss: 1.483411456133212
Validation loss: 2.319939523806124

Epoch: 6| Step: 2
Training loss: 2.077662940033565
Validation loss: 2.3334204691190696

Epoch: 6| Step: 3
Training loss: 1.2399968437954512
Validation loss: 2.3439935274659507

Epoch: 6| Step: 4
Training loss: 1.2617338669760032
Validation loss: 2.33419140754645

Epoch: 6| Step: 5
Training loss: 0.9240146956658192
Validation loss: 2.3181242634700343

Epoch: 6| Step: 6
Training loss: 0.8939612292388995
Validation loss: 2.3464165747628956

Epoch: 6| Step: 7
Training loss: 1.0746172911263319
Validation loss: 2.2947196008003816

Epoch: 6| Step: 8
Training loss: 1.2134434028538894
Validation loss: 2.2206987785764145

Epoch: 6| Step: 9
Training loss: 1.1761564752285756
Validation loss: 2.3275989599699285

Epoch: 6| Step: 10
Training loss: 1.160335847972617
Validation loss: 2.316718513272758

Epoch: 6| Step: 11
Training loss: 1.3285747888408304
Validation loss: 2.3692465026070875

Epoch: 6| Step: 12
Training loss: 1.2325673448219714
Validation loss: 2.3867035574899673

Epoch: 6| Step: 13
Training loss: 1.2046382354677398
Validation loss: 2.326007532795535

Epoch: 398| Step: 0
Training loss: 1.4686635580395044
Validation loss: 2.3150050467347083

Epoch: 6| Step: 1
Training loss: 1.0995746830673112
Validation loss: 2.4371024439406908

Epoch: 6| Step: 2
Training loss: 0.9255839592324291
Validation loss: 2.367084248720716

Epoch: 6| Step: 3
Training loss: 0.723842575003119
Validation loss: 2.351251588909965

Epoch: 6| Step: 4
Training loss: 0.8767619444982795
Validation loss: 2.309217031661792

Epoch: 6| Step: 5
Training loss: 2.1858076906415005
Validation loss: 2.3401704784322166

Epoch: 6| Step: 6
Training loss: 1.353567587555498
Validation loss: 2.329181503823043

Epoch: 6| Step: 7
Training loss: 0.9576678280372452
Validation loss: 2.3858979764100976

Epoch: 6| Step: 8
Training loss: 1.0676624877515226
Validation loss: 2.29711180540449

Epoch: 6| Step: 9
Training loss: 1.3583604380861842
Validation loss: 2.3623705925142358

Epoch: 6| Step: 10
Training loss: 1.7346820731293748
Validation loss: 2.3581513946207444

Epoch: 6| Step: 11
Training loss: 0.9233535935030246
Validation loss: 2.2630063480388594

Epoch: 6| Step: 12
Training loss: 1.2125078908919145
Validation loss: 2.2351917392186995

Epoch: 6| Step: 13
Training loss: 1.1210032569436392
Validation loss: 2.3326690324424106

Epoch: 399| Step: 0
Training loss: 1.3883773126463563
Validation loss: 2.3380758279826694

Epoch: 6| Step: 1
Training loss: 0.7943477197340275
Validation loss: 2.3456136577428777

Epoch: 6| Step: 2
Training loss: 1.0863121539069758
Validation loss: 2.4531610707137332

Epoch: 6| Step: 3
Training loss: 0.9478613484488811
Validation loss: 2.3199027818300504

Epoch: 6| Step: 4
Training loss: 0.8731282514157986
Validation loss: 2.3338925653572886

Epoch: 6| Step: 5
Training loss: 1.2280908769133099
Validation loss: 2.3815679303317556

Epoch: 6| Step: 6
Training loss: 0.9787081530943791
Validation loss: 2.3278757465552746

Epoch: 6| Step: 7
Training loss: 1.1659148666323953
Validation loss: 2.3192034539216837

Epoch: 6| Step: 8
Training loss: 1.2642652011928286
Validation loss: 2.3928519293575268

Epoch: 6| Step: 9
Training loss: 1.4322043189955431
Validation loss: 2.325551938646995

Epoch: 6| Step: 10
Training loss: 1.1946926629116805
Validation loss: 2.3336982954356045

Epoch: 6| Step: 11
Training loss: 1.1490526692641918
Validation loss: 2.285563742954584

Epoch: 6| Step: 12
Training loss: 2.313603112304937
Validation loss: 2.258465739647865

Epoch: 6| Step: 13
Training loss: 0.7861916466726492
Validation loss: 2.2560287442546696

Epoch: 400| Step: 0
Training loss: 1.0055897175329185
Validation loss: 2.356745317033509

Epoch: 6| Step: 1
Training loss: 1.2775279154405665
Validation loss: 2.331351969095861

Epoch: 6| Step: 2
Training loss: 1.2987657116113078
Validation loss: 2.277825399385039

Epoch: 6| Step: 3
Training loss: 1.1642045312038019
Validation loss: 2.334433367899838

Epoch: 6| Step: 4
Training loss: 1.041761292292245
Validation loss: 2.3417593505609493

Epoch: 6| Step: 5
Training loss: 0.961998454618105
Validation loss: 2.29940793298207

Epoch: 6| Step: 6
Training loss: 1.4191923720577349
Validation loss: 2.318788402095534

Epoch: 6| Step: 7
Training loss: 1.021149151794174
Validation loss: 2.3114619875666818

Epoch: 6| Step: 8
Training loss: 0.9756638321122348
Validation loss: 2.298303373312657

Epoch: 6| Step: 9
Training loss: 0.843440528912245
Validation loss: 2.3171427382403613

Epoch: 6| Step: 10
Training loss: 1.6634913794222774
Validation loss: 2.2922660957264585

Epoch: 6| Step: 11
Training loss: 2.2636994696738046
Validation loss: 2.3410390772303

Epoch: 6| Step: 12
Training loss: 1.0957682925069732
Validation loss: 2.258455744851244

Epoch: 6| Step: 13
Training loss: 1.2791564864375855
Validation loss: 2.3589831687439022

Epoch: 401| Step: 0
Training loss: 1.0274180106240534
Validation loss: 2.2792728243300204

Epoch: 6| Step: 1
Training loss: 1.3241646004467242
Validation loss: 2.3205749025254336

Epoch: 6| Step: 2
Training loss: 1.3146494567168925
Validation loss: 2.342470145853517

Epoch: 6| Step: 3
Training loss: 1.2809310143840065
Validation loss: 2.286222203273986

Epoch: 6| Step: 4
Training loss: 0.9922309325316336
Validation loss: 2.393517641926264

Epoch: 6| Step: 5
Training loss: 1.1496399792749583
Validation loss: 2.3690414524955843

Epoch: 6| Step: 6
Training loss: 1.2318911611270105
Validation loss: 2.359752139459055

Epoch: 6| Step: 7
Training loss: 0.9543515115182031
Validation loss: 2.424542490616171

Epoch: 6| Step: 8
Training loss: 1.3760048489069336
Validation loss: 2.3292571037393093

Epoch: 6| Step: 9
Training loss: 2.0851278841241023
Validation loss: 2.331669914020925

Epoch: 6| Step: 10
Training loss: 1.0675063275545005
Validation loss: 2.458141667392504

Epoch: 6| Step: 11
Training loss: 1.2876138118327818
Validation loss: 2.355571267545494

Epoch: 6| Step: 12
Training loss: 1.7763987953096052
Validation loss: 2.3947387224289156

Epoch: 6| Step: 13
Training loss: 1.2270873580806165
Validation loss: 2.3758259466690363

Epoch: 402| Step: 0
Training loss: 0.9122565271254347
Validation loss: 2.3732620296342013

Epoch: 6| Step: 1
Training loss: 1.291987066626402
Validation loss: 2.308844122371825

Epoch: 6| Step: 2
Training loss: 1.1812598253275446
Validation loss: 2.315919358544412

Epoch: 6| Step: 3
Training loss: 1.0045019972246365
Validation loss: 2.362395936100226

Epoch: 6| Step: 4
Training loss: 1.3388157228780364
Validation loss: 2.3083812015495795

Epoch: 6| Step: 5
Training loss: 1.5168299653449329
Validation loss: 2.3765691237936375

Epoch: 6| Step: 6
Training loss: 1.8086189943862854
Validation loss: 2.396860971439299

Epoch: 6| Step: 7
Training loss: 1.3135412264083781
Validation loss: 2.297863581565456

Epoch: 6| Step: 8
Training loss: 1.2144977530705605
Validation loss: 2.3374765026101914

Epoch: 6| Step: 9
Training loss: 1.069804941384112
Validation loss: 2.3455811170890337

Epoch: 6| Step: 10
Training loss: 1.1368220436383074
Validation loss: 2.3436896477042075

Epoch: 6| Step: 11
Training loss: 1.0325952483202883
Validation loss: 2.4086292571366448

Epoch: 6| Step: 12
Training loss: 1.1318329884290743
Validation loss: 2.3171200053367467

Epoch: 6| Step: 13
Training loss: 1.5329168161715474
Validation loss: 2.3286507912904666

Epoch: 403| Step: 0
Training loss: 0.8634671317506405
Validation loss: 2.2818557759812124

Epoch: 6| Step: 1
Training loss: 1.1646594878508445
Validation loss: 2.3620872378316538

Epoch: 6| Step: 2
Training loss: 1.0039904963548882
Validation loss: 2.392789717043367

Epoch: 6| Step: 3
Training loss: 1.2601262485742792
Validation loss: 2.3268055507555574

Epoch: 6| Step: 4
Training loss: 1.4885417880393481
Validation loss: 2.3545172647439068

Epoch: 6| Step: 5
Training loss: 0.886581645566568
Validation loss: 2.368532908311606

Epoch: 6| Step: 6
Training loss: 1.24417099848251
Validation loss: 2.470739501467438

Epoch: 6| Step: 7
Training loss: 1.2983962179844575
Validation loss: 2.395609983722242

Epoch: 6| Step: 8
Training loss: 1.141616077183979
Validation loss: 2.3291655617859037

Epoch: 6| Step: 9
Training loss: 1.5004874867798093
Validation loss: 2.4454029513006135

Epoch: 6| Step: 10
Training loss: 1.1488021998121403
Validation loss: 2.367674903667378

Epoch: 6| Step: 11
Training loss: 1.510281295848668
Validation loss: 2.3626369014533704

Epoch: 6| Step: 12
Training loss: 2.128729856690344
Validation loss: 2.342453165355166

Epoch: 6| Step: 13
Training loss: 0.8856658734437804
Validation loss: 2.3969372929599633

Epoch: 404| Step: 0
Training loss: 1.0108030439106828
Validation loss: 2.317295755514464

Epoch: 6| Step: 1
Training loss: 1.1692731329110124
Validation loss: 2.3255149788779312

Epoch: 6| Step: 2
Training loss: 1.0913460061575087
Validation loss: 2.3666078809635382

Epoch: 6| Step: 3
Training loss: 0.937118007402306
Validation loss: 2.3537890078435977

Epoch: 6| Step: 4
Training loss: 1.3164211917561242
Validation loss: 2.415808054850799

Epoch: 6| Step: 5
Training loss: 1.2826513210057404
Validation loss: 2.3681115693834345

Epoch: 6| Step: 6
Training loss: 1.2229234202435124
Validation loss: 2.3070974545782814

Epoch: 6| Step: 7
Training loss: 0.7857045399073795
Validation loss: 2.311983265856376

Epoch: 6| Step: 8
Training loss: 2.1610002024525587
Validation loss: 2.3306415988028966

Epoch: 6| Step: 9
Training loss: 1.455793002872288
Validation loss: 2.32268406204485

Epoch: 6| Step: 10
Training loss: 1.3998594673331197
Validation loss: 2.366131171351854

Epoch: 6| Step: 11
Training loss: 1.1364327821501992
Validation loss: 2.4219122686307175

Epoch: 6| Step: 12
Training loss: 1.01987144669892
Validation loss: 2.2784317753298655

Epoch: 6| Step: 13
Training loss: 0.6044518329418701
Validation loss: 2.2500245618220167

Epoch: 405| Step: 0
Training loss: 1.1942628727395412
Validation loss: 2.3835333245089916

Epoch: 6| Step: 1
Training loss: 1.440643935999677
Validation loss: 2.3301844869866226

Epoch: 6| Step: 2
Training loss: 1.0388514942662797
Validation loss: 2.3468352882738692

Epoch: 6| Step: 3
Training loss: 1.52281324850401
Validation loss: 2.3168592530386984

Epoch: 6| Step: 4
Training loss: 1.3103869549526983
Validation loss: 2.44996332622886

Epoch: 6| Step: 5
Training loss: 1.3673221630806955
Validation loss: 2.2982144251153214

Epoch: 6| Step: 6
Training loss: 1.121116186043736
Validation loss: 2.3786977145831547

Epoch: 6| Step: 7
Training loss: 0.9379178387603373
Validation loss: 2.284202875056998

Epoch: 6| Step: 8
Training loss: 0.9172055257296402
Validation loss: 2.3158275384424587

Epoch: 6| Step: 9
Training loss: 2.0744164439098705
Validation loss: 2.272490273873398

Epoch: 6| Step: 10
Training loss: 1.2687056923632205
Validation loss: 2.294308702410248

Epoch: 6| Step: 11
Training loss: 1.0121429614461128
Validation loss: 2.395448217341314

Epoch: 6| Step: 12
Training loss: 1.1083786479510902
Validation loss: 2.3153609172630785

Epoch: 6| Step: 13
Training loss: 1.0259047608928162
Validation loss: 2.3991499146026505

Epoch: 406| Step: 0
Training loss: 0.7558160419512029
Validation loss: 2.3373690361794295

Epoch: 6| Step: 1
Training loss: 1.2894114166605202
Validation loss: 2.2689345682451383

Epoch: 6| Step: 2
Training loss: 0.8720343946555025
Validation loss: 2.346682205606125

Epoch: 6| Step: 3
Training loss: 0.9657583187869747
Validation loss: 2.326802735691882

Epoch: 6| Step: 4
Training loss: 1.3573472256339862
Validation loss: 2.3468390034621245

Epoch: 6| Step: 5
Training loss: 0.7418202746548982
Validation loss: 2.41817354472142

Epoch: 6| Step: 6
Training loss: 1.1425000286310973
Validation loss: 2.373638656683175

Epoch: 6| Step: 7
Training loss: 0.8638793116492142
Validation loss: 2.262486868864253

Epoch: 6| Step: 8
Training loss: 1.556867135486318
Validation loss: 2.2222443188146386

Epoch: 6| Step: 9
Training loss: 1.032800895406422
Validation loss: 2.2620270694763733

Epoch: 6| Step: 10
Training loss: 1.430177114895674
Validation loss: 2.377217751256517

Epoch: 6| Step: 11
Training loss: 1.0989442375448224
Validation loss: 2.3315041725673233

Epoch: 6| Step: 12
Training loss: 1.1488362353212742
Validation loss: 2.3077995367079955

Epoch: 6| Step: 13
Training loss: 2.7942773274360744
Validation loss: 2.3411420081844674

Epoch: 407| Step: 0
Training loss: 0.6990335315061885
Validation loss: 2.4205672963434752

Epoch: 6| Step: 1
Training loss: 1.0788783882626236
Validation loss: 2.328137636890239

Epoch: 6| Step: 2
Training loss: 2.3946946354395946
Validation loss: 2.3567730130557365

Epoch: 6| Step: 3
Training loss: 1.11256337360369
Validation loss: 2.3764999857896143

Epoch: 6| Step: 4
Training loss: 1.2707512730020394
Validation loss: 2.2931896358448856

Epoch: 6| Step: 5
Training loss: 1.35595703125
Validation loss: 2.336761036962052

Epoch: 6| Step: 6
Training loss: 1.1081370041181438
Validation loss: 2.3429669057071396

Epoch: 6| Step: 7
Training loss: 1.11154725071547
Validation loss: 2.308328685538881

Epoch: 6| Step: 8
Training loss: 1.0344397026178234
Validation loss: 2.343246092958324

Epoch: 6| Step: 9
Training loss: 1.1460024391001897
Validation loss: 2.3651958854099306

Epoch: 6| Step: 10
Training loss: 0.8877699750298234
Validation loss: 2.3409954058625333

Epoch: 6| Step: 11
Training loss: 1.1062402627807362
Validation loss: 2.355490321555441

Epoch: 6| Step: 12
Training loss: 1.1818661813391826
Validation loss: 2.410557673685889

Epoch: 6| Step: 13
Training loss: 1.1123991031112266
Validation loss: 2.2894826322402557

Epoch: 408| Step: 0
Training loss: 0.9160757146781268
Validation loss: 2.284337433438117

Epoch: 6| Step: 1
Training loss: 1.032103791961342
Validation loss: 2.2846641911755547

Epoch: 6| Step: 2
Training loss: 1.1873055349034132
Validation loss: 2.3534375794217013

Epoch: 6| Step: 3
Training loss: 1.2450488262483652
Validation loss: 2.276640945317139

Epoch: 6| Step: 4
Training loss: 1.1264603461352292
Validation loss: 2.339087202402427

Epoch: 6| Step: 5
Training loss: 0.8903712530221947
Validation loss: 2.3346286813367385

Epoch: 6| Step: 6
Training loss: 1.236177118851155
Validation loss: 2.3958231318944576

Epoch: 6| Step: 7
Training loss: 1.2237436255034746
Validation loss: 2.429904736658115

Epoch: 6| Step: 8
Training loss: 1.338501728021121
Validation loss: 2.2686111267800793

Epoch: 6| Step: 9
Training loss: 1.387588357259995
Validation loss: 2.3661866152963036

Epoch: 6| Step: 10
Training loss: 0.9341709156489888
Validation loss: 2.3536831668446454

Epoch: 6| Step: 11
Training loss: 2.1994555059616636
Validation loss: 2.2934185185885267

Epoch: 6| Step: 12
Training loss: 1.0015098974545393
Validation loss: 2.303989545124221

Epoch: 6| Step: 13
Training loss: 1.0055558718955406
Validation loss: 2.3150458701865033

Epoch: 409| Step: 0
Training loss: 1.514934579173241
Validation loss: 2.3393298048659337

Epoch: 6| Step: 1
Training loss: 1.1551441368562851
Validation loss: 2.3387267592658123

Epoch: 6| Step: 2
Training loss: 1.0221407296919374
Validation loss: 2.305901615180727

Epoch: 6| Step: 3
Training loss: 1.2308104025620898
Validation loss: 2.359006089416962

Epoch: 6| Step: 4
Training loss: 0.9454295818869567
Validation loss: 2.2999268978070586

Epoch: 6| Step: 5
Training loss: 0.9772970565021654
Validation loss: 2.3081752698401163

Epoch: 6| Step: 6
Training loss: 1.0000570996195115
Validation loss: 2.320269785383224

Epoch: 6| Step: 7
Training loss: 1.0342377240229517
Validation loss: 2.2944254891789013

Epoch: 6| Step: 8
Training loss: 2.093170883026643
Validation loss: 2.3143944423358542

Epoch: 6| Step: 9
Training loss: 1.228374236541694
Validation loss: 2.4062294780024946

Epoch: 6| Step: 10
Training loss: 1.024332426907649
Validation loss: 2.329109266282189

Epoch: 6| Step: 11
Training loss: 0.9571003791598685
Validation loss: 2.3557480090931073

Epoch: 6| Step: 12
Training loss: 1.3222208621225566
Validation loss: 2.2748358959963815

Epoch: 6| Step: 13
Training loss: 1.5271907641971332
Validation loss: 2.3894869362016276

Epoch: 410| Step: 0
Training loss: 1.2938330029384773
Validation loss: 2.2660744000344026

Epoch: 6| Step: 1
Training loss: 1.1285188531614871
Validation loss: 2.3156161665673576

Epoch: 6| Step: 2
Training loss: 1.2702214638910045
Validation loss: 2.3322614476243446

Epoch: 6| Step: 3
Training loss: 1.072527799535029
Validation loss: 2.3159735316490306

Epoch: 6| Step: 4
Training loss: 1.3879690631804693
Validation loss: 2.3585578401412395

Epoch: 6| Step: 5
Training loss: 0.8013342087960922
Validation loss: 2.2995151065487294

Epoch: 6| Step: 6
Training loss: 1.1143197553102004
Validation loss: 2.2811888089403722

Epoch: 6| Step: 7
Training loss: 0.9639309414666006
Validation loss: 2.32546005460815

Epoch: 6| Step: 8
Training loss: 1.2528510957302588
Validation loss: 2.3446882310162835

Epoch: 6| Step: 9
Training loss: 1.2662069607468787
Validation loss: 2.3237110587536596

Epoch: 6| Step: 10
Training loss: 1.1989563894159427
Validation loss: 2.314039043025594

Epoch: 6| Step: 11
Training loss: 1.1589895219370359
Validation loss: 2.3178515633467858

Epoch: 6| Step: 12
Training loss: 1.1831642101660165
Validation loss: 2.3687207546079776

Epoch: 6| Step: 13
Training loss: 2.6079325086660274
Validation loss: 2.319702240545627

Epoch: 411| Step: 0
Training loss: 1.278719333418934
Validation loss: 2.3036234283828563

Epoch: 6| Step: 1
Training loss: 1.2814920708466448
Validation loss: 2.353689379110287

Epoch: 6| Step: 2
Training loss: 1.0845753751197291
Validation loss: 2.3143144399756603

Epoch: 6| Step: 3
Training loss: 1.1566280571725964
Validation loss: 2.388155731167387

Epoch: 6| Step: 4
Training loss: 2.213456838141735
Validation loss: 2.391134215492848

Epoch: 6| Step: 5
Training loss: 1.230791031548099
Validation loss: 2.3615705899188453

Epoch: 6| Step: 6
Training loss: 1.1498999593592583
Validation loss: 2.2634555669028162

Epoch: 6| Step: 7
Training loss: 0.8936254587966013
Validation loss: 2.3687093066674394

Epoch: 6| Step: 8
Training loss: 1.3129970880782644
Validation loss: 2.3235991785078176

Epoch: 6| Step: 9
Training loss: 1.075986094977004
Validation loss: 2.3507725853155845

Epoch: 6| Step: 10
Training loss: 1.1738081690762858
Validation loss: 2.2923347407343884

Epoch: 6| Step: 11
Training loss: 1.1093245481382406
Validation loss: 2.4016392127341732

Epoch: 6| Step: 12
Training loss: 0.8378217975651208
Validation loss: 2.342790707846569

Epoch: 6| Step: 13
Training loss: 1.0024164329573144
Validation loss: 2.4212299711888434

Epoch: 412| Step: 0
Training loss: 0.9416665631409534
Validation loss: 2.331912707679494

Epoch: 6| Step: 1
Training loss: 1.965869431088105
Validation loss: 2.3102785807888853

Epoch: 6| Step: 2
Training loss: 1.1977325076754939
Validation loss: 2.277368057440112

Epoch: 6| Step: 3
Training loss: 0.8490830819306816
Validation loss: 2.2299176150075994

Epoch: 6| Step: 4
Training loss: 1.0189061495695049
Validation loss: 2.308505566434834

Epoch: 6| Step: 5
Training loss: 1.2396235365986397
Validation loss: 2.383796543302962

Epoch: 6| Step: 6
Training loss: 1.3021486901728887
Validation loss: 2.29652914937374

Epoch: 6| Step: 7
Training loss: 1.4463716492393608
Validation loss: 2.281482526790359

Epoch: 6| Step: 8
Training loss: 1.2580412662572724
Validation loss: 2.386010672384746

Epoch: 6| Step: 9
Training loss: 1.1413579179895312
Validation loss: 2.2818438029239245

Epoch: 6| Step: 10
Training loss: 0.9663453560149574
Validation loss: 2.365214924614512

Epoch: 6| Step: 11
Training loss: 1.1010097442493723
Validation loss: 2.3621230935576834

Epoch: 6| Step: 12
Training loss: 1.1345943774749216
Validation loss: 2.355473156838861

Epoch: 6| Step: 13
Training loss: 1.0132560097426524
Validation loss: 2.313636866171778

Epoch: 413| Step: 0
Training loss: 1.134920355905496
Validation loss: 2.3452011396005426

Epoch: 6| Step: 1
Training loss: 1.1358575868897507
Validation loss: 2.3264466274612143

Epoch: 6| Step: 2
Training loss: 1.275565960502351
Validation loss: 2.339609276016428

Epoch: 6| Step: 3
Training loss: 0.9712428352160422
Validation loss: 2.290152744566072

Epoch: 6| Step: 4
Training loss: 1.0398287708284077
Validation loss: 2.353557019505158

Epoch: 6| Step: 5
Training loss: 1.0658382258378738
Validation loss: 2.3871379489730207

Epoch: 6| Step: 6
Training loss: 1.365425805899508
Validation loss: 2.2591544204740526

Epoch: 6| Step: 7
Training loss: 0.9848698477273192
Validation loss: 2.3637905937776655

Epoch: 6| Step: 8
Training loss: 0.8092411416611588
Validation loss: 2.274438524110049

Epoch: 6| Step: 9
Training loss: 0.8260040112668193
Validation loss: 2.2837313952295655

Epoch: 6| Step: 10
Training loss: 2.098286170075946
Validation loss: 2.324185726696038

Epoch: 6| Step: 11
Training loss: 1.6868643799850664
Validation loss: 2.2760861206294005

Epoch: 6| Step: 12
Training loss: 1.3166981721480766
Validation loss: 2.339731695044292

Epoch: 6| Step: 13
Training loss: 1.4672282837875692
Validation loss: 2.3272393174336385

Epoch: 414| Step: 0
Training loss: 0.9464016149645752
Validation loss: 2.286162615419887

Epoch: 6| Step: 1
Training loss: 1.4779329751836285
Validation loss: 2.3624114238339526

Epoch: 6| Step: 2
Training loss: 1.4710998405375033
Validation loss: 2.360470665768014

Epoch: 6| Step: 3
Training loss: 1.194413838376378
Validation loss: 2.3497101657602673

Epoch: 6| Step: 4
Training loss: 0.9660584375108858
Validation loss: 2.322127666004892

Epoch: 6| Step: 5
Training loss: 1.1562696403691135
Validation loss: 2.3072512480585514

Epoch: 6| Step: 6
Training loss: 1.1364674503416432
Validation loss: 2.303423068005503

Epoch: 6| Step: 7
Training loss: 1.3851255479089806
Validation loss: 2.366033853377854

Epoch: 6| Step: 8
Training loss: 1.1208323529509803
Validation loss: 2.391964703181302

Epoch: 6| Step: 9
Training loss: 0.9364328032264227
Validation loss: 2.2842394606375067

Epoch: 6| Step: 10
Training loss: 1.2300600372176604
Validation loss: 2.33064334555787

Epoch: 6| Step: 11
Training loss: 0.6248234499480966
Validation loss: 2.288128903354755

Epoch: 6| Step: 12
Training loss: 1.051248155971003
Validation loss: 2.3666402083319933

Epoch: 6| Step: 13
Training loss: 2.4715211019354077
Validation loss: 2.3194783454529686

Epoch: 415| Step: 0
Training loss: 0.9218671119481782
Validation loss: 2.3056750134607524

Epoch: 6| Step: 1
Training loss: 1.3663349654293495
Validation loss: 2.2693805367435202

Epoch: 6| Step: 2
Training loss: 1.052942089191045
Validation loss: 2.373694668325036

Epoch: 6| Step: 3
Training loss: 0.6483707853260806
Validation loss: 2.299829083597568

Epoch: 6| Step: 4
Training loss: 0.9548347022517917
Validation loss: 2.275291300783503

Epoch: 6| Step: 5
Training loss: 1.0839140998123857
Validation loss: 2.3246302428525376

Epoch: 6| Step: 6
Training loss: 1.4183408811094198
Validation loss: 2.2960207619341646

Epoch: 6| Step: 7
Training loss: 1.04577767096089
Validation loss: 2.279828273481854

Epoch: 6| Step: 8
Training loss: 0.897677091484386
Validation loss: 2.33872712977103

Epoch: 6| Step: 9
Training loss: 2.3052694329531853
Validation loss: 2.293587588982256

Epoch: 6| Step: 10
Training loss: 1.2580831485311947
Validation loss: 2.269273810791274

Epoch: 6| Step: 11
Training loss: 1.0475189733493984
Validation loss: 2.280969824774914

Epoch: 6| Step: 12
Training loss: 1.5332362469053693
Validation loss: 2.3394764956727014

Epoch: 6| Step: 13
Training loss: 0.8753277301110244
Validation loss: 2.358870413960435

Epoch: 416| Step: 0
Training loss: 1.177354843198765
Validation loss: 2.3353700249304414

Epoch: 6| Step: 1
Training loss: 0.837576676175231
Validation loss: 2.280941284750747

Epoch: 6| Step: 2
Training loss: 1.3613091225303497
Validation loss: 2.3497238845259765

Epoch: 6| Step: 3
Training loss: 1.2965130588154818
Validation loss: 2.370107357431456

Epoch: 6| Step: 4
Training loss: 1.229779344010475
Validation loss: 2.34154513599164

Epoch: 6| Step: 5
Training loss: 1.2414485724924798
Validation loss: 2.373089610837961

Epoch: 6| Step: 6
Training loss: 2.13267153319487
Validation loss: 2.402328276398884

Epoch: 6| Step: 7
Training loss: 1.4682486469789335
Validation loss: 2.349946833244527

Epoch: 6| Step: 8
Training loss: 1.3523800532659744
Validation loss: 2.3155075687579845

Epoch: 6| Step: 9
Training loss: 1.0415717781081706
Validation loss: 2.2930612103992503

Epoch: 6| Step: 10
Training loss: 1.1001466349921256
Validation loss: 2.3625086929882757

Epoch: 6| Step: 11
Training loss: 1.0220860884440492
Validation loss: 2.362744853199946

Epoch: 6| Step: 12
Training loss: 1.1253704944466592
Validation loss: 2.27782184850159

Epoch: 6| Step: 13
Training loss: 1.157124781257153
Validation loss: 2.2650734235313603

Epoch: 417| Step: 0
Training loss: 1.1058741388982674
Validation loss: 2.381532242491943

Epoch: 6| Step: 1
Training loss: 1.2620041468351157
Validation loss: 2.305028301143837

Epoch: 6| Step: 2
Training loss: 0.7621190119866772
Validation loss: 2.3254282682287264

Epoch: 6| Step: 3
Training loss: 1.452939503633118
Validation loss: 2.2490702038746284

Epoch: 6| Step: 4
Training loss: 1.0851772034436773
Validation loss: 2.302785377063227

Epoch: 6| Step: 5
Training loss: 2.1652158012054583
Validation loss: 2.3596631554409297

Epoch: 6| Step: 6
Training loss: 1.2845669122702832
Validation loss: 2.308198173027737

Epoch: 6| Step: 7
Training loss: 1.256739662354028
Validation loss: 2.3063199865664217

Epoch: 6| Step: 8
Training loss: 0.9514739009406906
Validation loss: 2.23255810052693

Epoch: 6| Step: 9
Training loss: 0.7993978320239582
Validation loss: 2.308477063663296

Epoch: 6| Step: 10
Training loss: 1.1791724286876575
Validation loss: 2.281884057403061

Epoch: 6| Step: 11
Training loss: 1.5019753482995033
Validation loss: 2.386865195832294

Epoch: 6| Step: 12
Training loss: 1.043155382009907
Validation loss: 2.280901295184955

Epoch: 6| Step: 13
Training loss: 1.3590515453452359
Validation loss: 2.3014681024670924

Epoch: 418| Step: 0
Training loss: 1.2928339032159648
Validation loss: 2.3307282397915197

Epoch: 6| Step: 1
Training loss: 1.2282103142456047
Validation loss: 2.24433541475088

Epoch: 6| Step: 2
Training loss: 1.0505144425769715
Validation loss: 2.3424909407906847

Epoch: 6| Step: 3
Training loss: 2.015111103639143
Validation loss: 2.340291417746514

Epoch: 6| Step: 4
Training loss: 1.0927785646592745
Validation loss: 2.3263201547957126

Epoch: 6| Step: 5
Training loss: 1.1652404150708775
Validation loss: 2.2511788952066976

Epoch: 6| Step: 6
Training loss: 1.1947995250723948
Validation loss: 2.260846055017569

Epoch: 6| Step: 7
Training loss: 0.9494864631800746
Validation loss: 2.3502361779145735

Epoch: 6| Step: 8
Training loss: 1.0009280309309618
Validation loss: 2.349969134044046

Epoch: 6| Step: 9
Training loss: 1.2821189445894856
Validation loss: 2.3374096258790398

Epoch: 6| Step: 10
Training loss: 1.0305642824811696
Validation loss: 2.2920695867049297

Epoch: 6| Step: 11
Training loss: 1.0533107107083108
Validation loss: 2.339825252134091

Epoch: 6| Step: 12
Training loss: 1.0753052921158908
Validation loss: 2.2896419408997475

Epoch: 6| Step: 13
Training loss: 1.4743268077003588
Validation loss: 2.3020770662558654

Epoch: 419| Step: 0
Training loss: 1.1068576673963204
Validation loss: 2.319593194119166

Epoch: 6| Step: 1
Training loss: 2.0212015295026298
Validation loss: 2.4043291594449143

Epoch: 6| Step: 2
Training loss: 1.4227626670658269
Validation loss: 2.241310884968841

Epoch: 6| Step: 3
Training loss: 0.9008540287046094
Validation loss: 2.3667128168320923

Epoch: 6| Step: 4
Training loss: 1.234957497209001
Validation loss: 2.304588268737648

Epoch: 6| Step: 5
Training loss: 1.0693010995145542
Validation loss: 2.341130619208835

Epoch: 6| Step: 6
Training loss: 1.0379444503179354
Validation loss: 2.310277051666816

Epoch: 6| Step: 7
Training loss: 0.7684348569175312
Validation loss: 2.359726226987434

Epoch: 6| Step: 8
Training loss: 0.950702089071983
Validation loss: 2.3205887460281565

Epoch: 6| Step: 9
Training loss: 0.9945576810358664
Validation loss: 2.3724504688333363

Epoch: 6| Step: 10
Training loss: 0.9612641438409705
Validation loss: 2.377998449736222

Epoch: 6| Step: 11
Training loss: 1.1527532334887314
Validation loss: 2.280162409302695

Epoch: 6| Step: 12
Training loss: 1.2379105551581753
Validation loss: 2.3223977429229725

Epoch: 6| Step: 13
Training loss: 1.2859301802101248
Validation loss: 2.3755839244746464

Epoch: 420| Step: 0
Training loss: 0.9777824716172357
Validation loss: 2.3497968193579655

Epoch: 6| Step: 1
Training loss: 0.6938753169517227
Validation loss: 2.3085272847641263

Epoch: 6| Step: 2
Training loss: 1.2272437080972676
Validation loss: 2.3141928155379077

Epoch: 6| Step: 3
Training loss: 2.201941314227073
Validation loss: 2.3127340784751804

Epoch: 6| Step: 4
Training loss: 1.19653427413522
Validation loss: 2.312564198213404

Epoch: 6| Step: 5
Training loss: 0.933605912261015
Validation loss: 2.336565841423596

Epoch: 6| Step: 6
Training loss: 1.228812759442072
Validation loss: 2.2921055523588474

Epoch: 6| Step: 7
Training loss: 1.0245497389150935
Validation loss: 2.306271151358326

Epoch: 6| Step: 8
Training loss: 1.4648036290078494
Validation loss: 2.349702263850154

Epoch: 6| Step: 9
Training loss: 0.8134017488622612
Validation loss: 2.2675016241430375

Epoch: 6| Step: 10
Training loss: 0.9096472630829232
Validation loss: 2.3273473160487583

Epoch: 6| Step: 11
Training loss: 0.8848184397178036
Validation loss: 2.2782447597445974

Epoch: 6| Step: 12
Training loss: 1.2888860408342253
Validation loss: 2.342105061268533

Epoch: 6| Step: 13
Training loss: 1.2439334044063948
Validation loss: 2.3296210022115305

Epoch: 421| Step: 0
Training loss: 0.8932030157741299
Validation loss: 2.2403509161537265

Epoch: 6| Step: 1
Training loss: 1.3998217843928966
Validation loss: 2.345542649831869

Epoch: 6| Step: 2
Training loss: 0.7434929459602132
Validation loss: 2.3949755270356228

Epoch: 6| Step: 3
Training loss: 1.1122280024082856
Validation loss: 2.300617844202356

Epoch: 6| Step: 4
Training loss: 0.9190435083444649
Validation loss: 2.301470003919801

Epoch: 6| Step: 5
Training loss: 1.567685563269565
Validation loss: 2.3594452901082623

Epoch: 6| Step: 6
Training loss: 1.4430818407057202
Validation loss: 2.32867857265029

Epoch: 6| Step: 7
Training loss: 1.0001102625139235
Validation loss: 2.317046866207791

Epoch: 6| Step: 8
Training loss: 0.8350044819146212
Validation loss: 2.3169425234714747

Epoch: 6| Step: 9
Training loss: 2.1445883932647494
Validation loss: 2.293677210071267

Epoch: 6| Step: 10
Training loss: 1.178009760150728
Validation loss: 2.322577826240867

Epoch: 6| Step: 11
Training loss: 0.7028512209771286
Validation loss: 2.3208143212891437

Epoch: 6| Step: 12
Training loss: 1.272630775341886
Validation loss: 2.268149773158919

Epoch: 6| Step: 13
Training loss: 1.1747955550221723
Validation loss: 2.2803893050875548

Epoch: 422| Step: 0
Training loss: 0.6969724835009025
Validation loss: 2.315453177707507

Epoch: 6| Step: 1
Training loss: 1.2192345169614247
Validation loss: 2.3245566981638732

Epoch: 6| Step: 2
Training loss: 1.1282966314138219
Validation loss: 2.289459695793716

Epoch: 6| Step: 3
Training loss: 0.8473983583293514
Validation loss: 2.284584337187569

Epoch: 6| Step: 4
Training loss: 0.8609859279851655
Validation loss: 2.3916847522951183

Epoch: 6| Step: 5
Training loss: 1.1433829317836404
Validation loss: 2.3085237755525965

Epoch: 6| Step: 6
Training loss: 1.028281244620819
Validation loss: 2.2706120908116123

Epoch: 6| Step: 7
Training loss: 1.2522588347681005
Validation loss: 2.345007234219323

Epoch: 6| Step: 8
Training loss: 2.187287456540979
Validation loss: 2.3433994482255676

Epoch: 6| Step: 9
Training loss: 1.5059371116750089
Validation loss: 2.29709337859557

Epoch: 6| Step: 10
Training loss: 1.4126282895323905
Validation loss: 2.3951717909716055

Epoch: 6| Step: 11
Training loss: 1.0549322903857783
Validation loss: 2.26384197394691

Epoch: 6| Step: 12
Training loss: 0.8251487222193418
Validation loss: 2.3265051097079654

Epoch: 6| Step: 13
Training loss: 1.009329961947056
Validation loss: 2.356860763927065

Epoch: 423| Step: 0
Training loss: 0.9172058831473325
Validation loss: 2.461799955642022

Epoch: 6| Step: 1
Training loss: 1.0404261195667832
Validation loss: 2.354294140677074

Epoch: 6| Step: 2
Training loss: 0.970836177434289
Validation loss: 2.294167287710603

Epoch: 6| Step: 3
Training loss: 1.1184650399206035
Validation loss: 2.2889592257558826

Epoch: 6| Step: 4
Training loss: 1.2800011945510297
Validation loss: 2.3474244626487075

Epoch: 6| Step: 5
Training loss: 1.339830226107039
Validation loss: 2.3017527459313007

Epoch: 6| Step: 6
Training loss: 1.338887487879469
Validation loss: 2.4063560143928653

Epoch: 6| Step: 7
Training loss: 0.9641483287226855
Validation loss: 2.317055576529219

Epoch: 6| Step: 8
Training loss: 2.1835659073093536
Validation loss: 2.308489296155109

Epoch: 6| Step: 9
Training loss: 1.2635746583879606
Validation loss: 2.3189515257799185

Epoch: 6| Step: 10
Training loss: 1.153227593218114
Validation loss: 2.292835911309127

Epoch: 6| Step: 11
Training loss: 1.009774125024669
Validation loss: 2.3142882164826246

Epoch: 6| Step: 12
Training loss: 1.0782212477029507
Validation loss: 2.4317388390915493

Epoch: 6| Step: 13
Training loss: 0.7389912496340366
Validation loss: 2.3311671161045786

Epoch: 424| Step: 0
Training loss: 1.0959828065720902
Validation loss: 2.31332165134638

Epoch: 6| Step: 1
Training loss: 1.217778821503485
Validation loss: 2.2616144668772065

Epoch: 6| Step: 2
Training loss: 1.2820896095880154
Validation loss: 2.3290289548346497

Epoch: 6| Step: 3
Training loss: 1.252179106076588
Validation loss: 2.341391413461666

Epoch: 6| Step: 4
Training loss: 1.3301405927018202
Validation loss: 2.235504337699435

Epoch: 6| Step: 5
Training loss: 0.5545106525309448
Validation loss: 2.3140218538972888

Epoch: 6| Step: 6
Training loss: 0.9998254623684052
Validation loss: 2.2903796899389413

Epoch: 6| Step: 7
Training loss: 1.2109471474540092
Validation loss: 2.2740630192236857

Epoch: 6| Step: 8
Training loss: 2.211793551835791
Validation loss: 2.3117052429210725

Epoch: 6| Step: 9
Training loss: 1.2905159818774818
Validation loss: 2.2753668609086586

Epoch: 6| Step: 10
Training loss: 1.514713288424701
Validation loss: 2.369062269580983

Epoch: 6| Step: 11
Training loss: 0.7480357196663329
Validation loss: 2.267072893457947

Epoch: 6| Step: 12
Training loss: 0.7686891547214021
Validation loss: 2.321828987766376

Epoch: 6| Step: 13
Training loss: 0.9468532647889555
Validation loss: 2.279723522724257

Epoch: 425| Step: 0
Training loss: 0.8374387861057327
Validation loss: 2.329538384716439

Epoch: 6| Step: 1
Training loss: 1.1437755081584189
Validation loss: 2.3004780075116393

Epoch: 6| Step: 2
Training loss: 0.6481693126866084
Validation loss: 2.343631932282493

Epoch: 6| Step: 3
Training loss: 1.1468593627528878
Validation loss: 2.255637752203101

Epoch: 6| Step: 4
Training loss: 1.231796613857609
Validation loss: 2.3578449047820937

Epoch: 6| Step: 5
Training loss: 0.9763185120010353
Validation loss: 2.2864771904383727

Epoch: 6| Step: 6
Training loss: 1.0274218395419663
Validation loss: 2.313666295968311

Epoch: 6| Step: 7
Training loss: 0.6526285794606929
Validation loss: 2.3517265007805177

Epoch: 6| Step: 8
Training loss: 1.312696215177049
Validation loss: 2.241224097617338

Epoch: 6| Step: 9
Training loss: 1.1538786412825153
Validation loss: 2.2836691940885907

Epoch: 6| Step: 10
Training loss: 2.151330837612795
Validation loss: 2.3393177588473004

Epoch: 6| Step: 11
Training loss: 1.0200072598666463
Validation loss: 2.221853972491652

Epoch: 6| Step: 12
Training loss: 1.1508228675169356
Validation loss: 2.225633125517838

Epoch: 6| Step: 13
Training loss: 1.4062682256577181
Validation loss: 2.341219733274572

Epoch: 426| Step: 0
Training loss: 1.2110573986131274
Validation loss: 2.331886458364953

Epoch: 6| Step: 1
Training loss: 1.9466363163546072
Validation loss: 2.3428264928688147

Epoch: 6| Step: 2
Training loss: 0.7790700634995851
Validation loss: 2.2734897856864418

Epoch: 6| Step: 3
Training loss: 0.8783250031145597
Validation loss: 2.23093268295675

Epoch: 6| Step: 4
Training loss: 1.2584821920366374
Validation loss: 2.2788238626479895

Epoch: 6| Step: 5
Training loss: 0.9247356578357211
Validation loss: 2.3861670121108904

Epoch: 6| Step: 6
Training loss: 1.434529012419245
Validation loss: 2.3749489079815764

Epoch: 6| Step: 7
Training loss: 1.167737804021667
Validation loss: 2.251167731530849

Epoch: 6| Step: 8
Training loss: 1.2407006536136915
Validation loss: 2.2286196089070627

Epoch: 6| Step: 9
Training loss: 1.076533926486341
Validation loss: 2.405106141438231

Epoch: 6| Step: 10
Training loss: 1.1942205490304387
Validation loss: 2.3608250933545203

Epoch: 6| Step: 11
Training loss: 1.233060547371536
Validation loss: 2.289197708958617

Epoch: 6| Step: 12
Training loss: 1.2492190305555648
Validation loss: 2.256801907750538

Epoch: 6| Step: 13
Training loss: 1.0391403972137065
Validation loss: 2.335177784314624

Epoch: 427| Step: 0
Training loss: 1.2200217825086288
Validation loss: 2.2915202171388973

Epoch: 6| Step: 1
Training loss: 0.9822199407275799
Validation loss: 2.3278614320870386

Epoch: 6| Step: 2
Training loss: 0.8733400539571549
Validation loss: 2.3578807769087975

Epoch: 6| Step: 3
Training loss: 1.892381844907638
Validation loss: 2.2968234090652446

Epoch: 6| Step: 4
Training loss: 1.0505626124842031
Validation loss: 2.303210871625273

Epoch: 6| Step: 5
Training loss: 1.6817185298583182
Validation loss: 2.2870431642106746

Epoch: 6| Step: 6
Training loss: 1.366809247689449
Validation loss: 2.2658206299368957

Epoch: 6| Step: 7
Training loss: 0.9102579150087573
Validation loss: 2.316300942068221

Epoch: 6| Step: 8
Training loss: 1.2703560365392996
Validation loss: 2.3220383679446392

Epoch: 6| Step: 9
Training loss: 1.3164775614001574
Validation loss: 2.3179523729903306

Epoch: 6| Step: 10
Training loss: 1.1162998434389082
Validation loss: 2.3885686497896463

Epoch: 6| Step: 11
Training loss: 1.081075859379401
Validation loss: 2.323779584081855

Epoch: 6| Step: 12
Training loss: 1.0093684051581677
Validation loss: 2.29471945891709

Epoch: 6| Step: 13
Training loss: 0.6043120132651062
Validation loss: 2.3092132864751864

Epoch: 428| Step: 0
Training loss: 1.1867224506775023
Validation loss: 2.256631009466683

Epoch: 6| Step: 1
Training loss: 1.1388921246573116
Validation loss: 2.2580175603651713

Epoch: 6| Step: 2
Training loss: 1.1570132545859346
Validation loss: 2.302957938173236

Epoch: 6| Step: 3
Training loss: 1.1351889052291781
Validation loss: 2.2644732859469783

Epoch: 6| Step: 4
Training loss: 0.8131546904108156
Validation loss: 2.3067013637195197

Epoch: 6| Step: 5
Training loss: 0.7434472084774465
Validation loss: 2.248228608651456

Epoch: 6| Step: 6
Training loss: 1.4716987228934415
Validation loss: 2.310624996282728

Epoch: 6| Step: 7
Training loss: 1.254617459633206
Validation loss: 2.3256697789207705

Epoch: 6| Step: 8
Training loss: 0.649197397443252
Validation loss: 2.4185491266232964

Epoch: 6| Step: 9
Training loss: 1.0527772912388071
Validation loss: 2.331014853231975

Epoch: 6| Step: 10
Training loss: 0.9461251541079106
Validation loss: 2.23144856839528

Epoch: 6| Step: 11
Training loss: 2.0141656605038425
Validation loss: 2.3233859796900758

Epoch: 6| Step: 12
Training loss: 1.0619785487815676
Validation loss: 2.3027292961070094

Epoch: 6| Step: 13
Training loss: 1.1161071248476744
Validation loss: 2.3489166857068184

Epoch: 429| Step: 0
Training loss: 1.5719607987696933
Validation loss: 2.3682280724326485

Epoch: 6| Step: 1
Training loss: 1.9197640339571527
Validation loss: 2.2542041897207215

Epoch: 6| Step: 2
Training loss: 1.194685229100477
Validation loss: 2.3488625793243365

Epoch: 6| Step: 3
Training loss: 1.4404051077087148
Validation loss: 2.2819711936159313

Epoch: 6| Step: 4
Training loss: 1.1568164984174207
Validation loss: 2.269089008430909

Epoch: 6| Step: 5
Training loss: 1.2977675618126319
Validation loss: 2.2905686247185852

Epoch: 6| Step: 6
Training loss: 0.7063462959739512
Validation loss: 2.2918465402959987

Epoch: 6| Step: 7
Training loss: 1.078023712265432
Validation loss: 2.280977439358906

Epoch: 6| Step: 8
Training loss: 1.0092964779572304
Validation loss: 2.2108394697165776

Epoch: 6| Step: 9
Training loss: 1.3117040763974857
Validation loss: 2.2795913201998816

Epoch: 6| Step: 10
Training loss: 0.8196637449265456
Validation loss: 2.296865544018211

Epoch: 6| Step: 11
Training loss: 1.0100044838645286
Validation loss: 2.283009085624157

Epoch: 6| Step: 12
Training loss: 0.960644623078837
Validation loss: 2.2632844834761205

Epoch: 6| Step: 13
Training loss: 0.7784189810247973
Validation loss: 2.30122421671661

Epoch: 430| Step: 0
Training loss: 2.200345822810523
Validation loss: 2.254246164289793

Epoch: 6| Step: 1
Training loss: 0.9759717146085289
Validation loss: 2.393908668069631

Epoch: 6| Step: 2
Training loss: 1.0541049054615672
Validation loss: 2.2737357916459606

Epoch: 6| Step: 3
Training loss: 1.0940107852118233
Validation loss: 2.2541321055007613

Epoch: 6| Step: 4
Training loss: 0.8498919839105972
Validation loss: 2.2349313344109345

Epoch: 6| Step: 5
Training loss: 1.139515690071581
Validation loss: 2.283646030300556

Epoch: 6| Step: 6
Training loss: 1.0357728669084407
Validation loss: 2.2535328378273594

Epoch: 6| Step: 7
Training loss: 0.883474253863855
Validation loss: 2.262697887814412

Epoch: 6| Step: 8
Training loss: 0.9889812779636107
Validation loss: 2.330943740442567

Epoch: 6| Step: 9
Training loss: 1.2689723266337722
Validation loss: 2.3340292297932783

Epoch: 6| Step: 10
Training loss: 1.1896772502340398
Validation loss: 2.386563666168816

Epoch: 6| Step: 11
Training loss: 0.9916342747364074
Validation loss: 2.288896941555362

Epoch: 6| Step: 12
Training loss: 1.1465894920600888
Validation loss: 2.3528068056832625

Epoch: 6| Step: 13
Training loss: 0.6190002234077975
Validation loss: 2.3259023090691473

Epoch: 431| Step: 0
Training loss: 1.0306295204410463
Validation loss: 2.269364761476435

Epoch: 6| Step: 1
Training loss: 1.7119258307897343
Validation loss: 2.271060603332045

Epoch: 6| Step: 2
Training loss: 0.8220548744773164
Validation loss: 2.3098507455587156

Epoch: 6| Step: 3
Training loss: 0.8243907730872562
Validation loss: 2.3416057882524974

Epoch: 6| Step: 4
Training loss: 1.1100704538479094
Validation loss: 2.2371273653273462

Epoch: 6| Step: 5
Training loss: 0.7263984905246141
Validation loss: 2.3458469660260897

Epoch: 6| Step: 6
Training loss: 1.2764923804833093
Validation loss: 2.3853112288051284

Epoch: 6| Step: 7
Training loss: 1.0708095204022374
Validation loss: 2.320114985266085

Epoch: 6| Step: 8
Training loss: 1.5225444817269806
Validation loss: 2.3556408315312938

Epoch: 6| Step: 9
Training loss: 1.0039292863510896
Validation loss: 2.388901829078364

Epoch: 6| Step: 10
Training loss: 0.780401379309432
Validation loss: 2.304855672583187

Epoch: 6| Step: 11
Training loss: 1.1251261958232552
Validation loss: 2.3518722646856602

Epoch: 6| Step: 12
Training loss: 2.1124694731724407
Validation loss: 2.310533553010617

Epoch: 6| Step: 13
Training loss: 0.8852545795553838
Validation loss: 2.324418312660991

Epoch: 432| Step: 0
Training loss: 1.2853475039942195
Validation loss: 2.285480566493725

Epoch: 6| Step: 1
Training loss: 2.17571813193907
Validation loss: 2.2903289220361938

Epoch: 6| Step: 2
Training loss: 1.1139734625848692
Validation loss: 2.3144431438017077

Epoch: 6| Step: 3
Training loss: 1.0014537734410687
Validation loss: 2.2717252840281845

Epoch: 6| Step: 4
Training loss: 1.2322600389916403
Validation loss: 2.318736958194098

Epoch: 6| Step: 5
Training loss: 1.2282868916821503
Validation loss: 2.2170128186667006

Epoch: 6| Step: 6
Training loss: 1.099107102483417
Validation loss: 2.2709452577140476

Epoch: 6| Step: 7
Training loss: 1.1795534979899645
Validation loss: 2.3249384838958815

Epoch: 6| Step: 8
Training loss: 1.5148307056071943
Validation loss: 2.2343937335013164

Epoch: 6| Step: 9
Training loss: 0.8094476807117312
Validation loss: 2.340875075689703

Epoch: 6| Step: 10
Training loss: 1.14146382045013
Validation loss: 2.3283266953425015

Epoch: 6| Step: 11
Training loss: 1.0854108892031988
Validation loss: 2.368401175290037

Epoch: 6| Step: 12
Training loss: 1.123535209300982
Validation loss: 2.31924322466082

Epoch: 6| Step: 13
Training loss: 0.9008939912354915
Validation loss: 2.2631214854439428

Epoch: 433| Step: 0
Training loss: 2.134137535010587
Validation loss: 2.3381992340327153

Epoch: 6| Step: 1
Training loss: 0.9559658114433109
Validation loss: 2.2916099134858805

Epoch: 6| Step: 2
Training loss: 1.030664566788831
Validation loss: 2.2674994047712955

Epoch: 6| Step: 3
Training loss: 1.116919532063132
Validation loss: 2.334445358406304

Epoch: 6| Step: 4
Training loss: 1.1785936147079583
Validation loss: 2.2154779136350653

Epoch: 6| Step: 5
Training loss: 0.9481995687915439
Validation loss: 2.2644247924807623

Epoch: 6| Step: 6
Training loss: 1.3554382760527695
Validation loss: 2.3022742766908686

Epoch: 6| Step: 7
Training loss: 0.6714592911771341
Validation loss: 2.3200358951042097

Epoch: 6| Step: 8
Training loss: 1.1777181292120347
Validation loss: 2.266950719146279

Epoch: 6| Step: 9
Training loss: 1.1218307146347766
Validation loss: 2.320859732175523

Epoch: 6| Step: 10
Training loss: 1.261454173594934
Validation loss: 2.2956305140362097

Epoch: 6| Step: 11
Training loss: 0.8950580894543212
Validation loss: 2.3066322982454546

Epoch: 6| Step: 12
Training loss: 1.1248446993128993
Validation loss: 2.303054297075982

Epoch: 6| Step: 13
Training loss: 1.3096643879188474
Validation loss: 2.3277499594764532

Epoch: 434| Step: 0
Training loss: 0.8054265452445343
Validation loss: 2.2941700869466954

Epoch: 6| Step: 1
Training loss: 0.8958497970014486
Validation loss: 2.3634661533095276

Epoch: 6| Step: 2
Training loss: 1.390315203502219
Validation loss: 2.2791574950124676

Epoch: 6| Step: 3
Training loss: 0.8408568902649284
Validation loss: 2.29477157083116

Epoch: 6| Step: 4
Training loss: 2.2056926077222867
Validation loss: 2.368828853340506

Epoch: 6| Step: 5
Training loss: 0.8971348150257737
Validation loss: 2.361850507137087

Epoch: 6| Step: 6
Training loss: 1.434064657841861
Validation loss: 2.284012712181671

Epoch: 6| Step: 7
Training loss: 1.1753751237125367
Validation loss: 2.309178355531599

Epoch: 6| Step: 8
Training loss: 1.2485374954911845
Validation loss: 2.3293241044763797

Epoch: 6| Step: 9
Training loss: 1.0702389879807421
Validation loss: 2.354873654157815

Epoch: 6| Step: 10
Training loss: 1.0519664560996758
Validation loss: 2.3000186203822155

Epoch: 6| Step: 11
Training loss: 0.7374231104451938
Validation loss: 2.29899155095474

Epoch: 6| Step: 12
Training loss: 1.1480998885928924
Validation loss: 2.3258149928421017

Epoch: 6| Step: 13
Training loss: 0.7141281047708815
Validation loss: 2.2721653990467585

Epoch: 435| Step: 0
Training loss: 1.1011339801548161
Validation loss: 2.316581211061749

Epoch: 6| Step: 1
Training loss: 0.9524175175675162
Validation loss: 2.4196477688408855

Epoch: 6| Step: 2
Training loss: 0.9681583874574413
Validation loss: 2.313950953417558

Epoch: 6| Step: 3
Training loss: 1.0867681825256243
Validation loss: 2.245123070426434

Epoch: 6| Step: 4
Training loss: 1.0654557571927978
Validation loss: 2.2668380714646004

Epoch: 6| Step: 5
Training loss: 0.5649739538788969
Validation loss: 2.308924899411713

Epoch: 6| Step: 6
Training loss: 1.0296721670025046
Validation loss: 2.313295077483706

Epoch: 6| Step: 7
Training loss: 1.146774385284893
Validation loss: 2.4584059797523383

Epoch: 6| Step: 8
Training loss: 2.2427052820459266
Validation loss: 2.2583523707462843

Epoch: 6| Step: 9
Training loss: 0.9353694229826346
Validation loss: 2.361857783354814

Epoch: 6| Step: 10
Training loss: 1.4270161336776706
Validation loss: 2.318756633714008

Epoch: 6| Step: 11
Training loss: 0.9134374910733735
Validation loss: 2.304765516781782

Epoch: 6| Step: 12
Training loss: 1.022285103821871
Validation loss: 2.385566207712916

Epoch: 6| Step: 13
Training loss: 1.256607331275713
Validation loss: 2.352530318462115

Epoch: 436| Step: 0
Training loss: 2.050174994094087
Validation loss: 2.3172588687311597

Epoch: 6| Step: 1
Training loss: 1.1158783718437222
Validation loss: 2.384109448048981

Epoch: 6| Step: 2
Training loss: 0.9783759103041918
Validation loss: 2.3309126238593043

Epoch: 6| Step: 3
Training loss: 0.8704526107023203
Validation loss: 2.358504661743247

Epoch: 6| Step: 4
Training loss: 1.393756298512823
Validation loss: 2.305864037481344

Epoch: 6| Step: 5
Training loss: 0.5520536456733052
Validation loss: 2.2625070199566886

Epoch: 6| Step: 6
Training loss: 1.2705104396831024
Validation loss: 2.264652745420381

Epoch: 6| Step: 7
Training loss: 0.7606012216203596
Validation loss: 2.2992309916530194

Epoch: 6| Step: 8
Training loss: 1.0435509360529964
Validation loss: 2.280704847268911

Epoch: 6| Step: 9
Training loss: 1.2457805945589548
Validation loss: 2.2910640289612334

Epoch: 6| Step: 10
Training loss: 1.2697978047991074
Validation loss: 2.4067087704311527

Epoch: 6| Step: 11
Training loss: 1.4748385421833956
Validation loss: 2.241607153000686

Epoch: 6| Step: 12
Training loss: 1.2717548322966374
Validation loss: 2.25302461371471

Epoch: 6| Step: 13
Training loss: 0.973554112535581
Validation loss: 2.3229747117317743

Epoch: 437| Step: 0
Training loss: 0.9250388085755703
Validation loss: 2.3900438567895232

Epoch: 6| Step: 1
Training loss: 2.0935675698129637
Validation loss: 2.2568062198572063

Epoch: 6| Step: 2
Training loss: 1.1603847496989885
Validation loss: 2.3066539175143705

Epoch: 6| Step: 3
Training loss: 1.0318833920225947
Validation loss: 2.2907763383986754

Epoch: 6| Step: 4
Training loss: 0.9926154347703341
Validation loss: 2.395261814242141

Epoch: 6| Step: 5
Training loss: 1.0583616333028774
Validation loss: 2.3473973880473635

Epoch: 6| Step: 6
Training loss: 1.085477772833489
Validation loss: 2.3276222833100064

Epoch: 6| Step: 7
Training loss: 1.2279646810087295
Validation loss: 2.3077242114404606

Epoch: 6| Step: 8
Training loss: 1.0632651883495108
Validation loss: 2.3139685081248977

Epoch: 6| Step: 9
Training loss: 1.2459761226227641
Validation loss: 2.317537444450103

Epoch: 6| Step: 10
Training loss: 0.7358840291224388
Validation loss: 2.2906567937245508

Epoch: 6| Step: 11
Training loss: 1.0120215828030266
Validation loss: 2.222473250032174

Epoch: 6| Step: 12
Training loss: 0.8189657873336706
Validation loss: 2.3377516569322028

Epoch: 6| Step: 13
Training loss: 0.9872708791194665
Validation loss: 2.3152488787752987

Epoch: 438| Step: 0
Training loss: 0.9629317888046078
Validation loss: 2.3576716877154253

Epoch: 6| Step: 1
Training loss: 2.0420303669538726
Validation loss: 2.278261741131905

Epoch: 6| Step: 2
Training loss: 1.4310368075112199
Validation loss: 2.300394182882238

Epoch: 6| Step: 3
Training loss: 0.9776499682458297
Validation loss: 2.2467210170730643

Epoch: 6| Step: 4
Training loss: 1.2090338726110406
Validation loss: 2.320592842389954

Epoch: 6| Step: 5
Training loss: 0.919461922961236
Validation loss: 2.325515631496838

Epoch: 6| Step: 6
Training loss: 1.2113110366103086
Validation loss: 2.319771419174338

Epoch: 6| Step: 7
Training loss: 1.0002138386019803
Validation loss: 2.36011039748898

Epoch: 6| Step: 8
Training loss: 0.7534033723852408
Validation loss: 2.27841210038757

Epoch: 6| Step: 9
Training loss: 1.236832695035603
Validation loss: 2.3370769543670287

Epoch: 6| Step: 10
Training loss: 0.8070670194721612
Validation loss: 2.3668421428360293

Epoch: 6| Step: 11
Training loss: 1.4668648166896274
Validation loss: 2.362387796643407

Epoch: 6| Step: 12
Training loss: 0.9618507945365656
Validation loss: 2.3603029925906367

Epoch: 6| Step: 13
Training loss: 1.2565128886407706
Validation loss: 2.3179818707596236

Epoch: 439| Step: 0
Training loss: 1.2151827814424248
Validation loss: 2.268270731194845

Epoch: 6| Step: 1
Training loss: 0.8176277185700171
Validation loss: 2.256266967675095

Epoch: 6| Step: 2
Training loss: 0.9561349837003477
Validation loss: 2.3266823116810404

Epoch: 6| Step: 3
Training loss: 2.308755472008417
Validation loss: 2.3475265506687646

Epoch: 6| Step: 4
Training loss: 0.8051271441258908
Validation loss: 2.2842180489746244

Epoch: 6| Step: 5
Training loss: 0.7314177280007026
Validation loss: 2.3012951516999953

Epoch: 6| Step: 6
Training loss: 1.3699641777840617
Validation loss: 2.328122766844262

Epoch: 6| Step: 7
Training loss: 1.1033427685413895
Validation loss: 2.3024612778743876

Epoch: 6| Step: 8
Training loss: 0.8036793439549011
Validation loss: 2.3073989199536498

Epoch: 6| Step: 9
Training loss: 1.219107990995384
Validation loss: 2.3634191801126385

Epoch: 6| Step: 10
Training loss: 1.5152634651556307
Validation loss: 2.284578154707473

Epoch: 6| Step: 11
Training loss: 1.0914985371962989
Validation loss: 2.2482308134080005

Epoch: 6| Step: 12
Training loss: 0.9765350948303095
Validation loss: 2.3264747513992616

Epoch: 6| Step: 13
Training loss: 0.8448329615975628
Validation loss: 2.324685268334392

Epoch: 440| Step: 0
Training loss: 1.6096297867948113
Validation loss: 2.313023804704181

Epoch: 6| Step: 1
Training loss: 0.7395518032033164
Validation loss: 2.327212985112769

Epoch: 6| Step: 2
Training loss: 0.9549222167528714
Validation loss: 2.2016412664869716

Epoch: 6| Step: 3
Training loss: 1.151012932374156
Validation loss: 2.1431513226818293

Epoch: 6| Step: 4
Training loss: 1.1658950820032563
Validation loss: 2.27220554912908

Epoch: 6| Step: 5
Training loss: 1.1707801281842058
Validation loss: 2.2745960078829217

Epoch: 6| Step: 6
Training loss: 1.1349810660039126
Validation loss: 2.2614890826113943

Epoch: 6| Step: 7
Training loss: 1.2229600230410407
Validation loss: 2.311830571179821

Epoch: 6| Step: 8
Training loss: 1.13220040457455
Validation loss: 2.4184671921606022

Epoch: 6| Step: 9
Training loss: 1.0762130812494528
Validation loss: 2.236745454529514

Epoch: 6| Step: 10
Training loss: 1.9728562659658937
Validation loss: 2.3449547780993587

Epoch: 6| Step: 11
Training loss: 0.7487023969875569
Validation loss: 2.2337675685207636

Epoch: 6| Step: 12
Training loss: 0.9883487060202614
Validation loss: 2.2981954438189196

Epoch: 6| Step: 13
Training loss: 0.7757884813722714
Validation loss: 2.2287067041911333

Epoch: 441| Step: 0
Training loss: 0.9331942864850157
Validation loss: 2.300408383531071

Epoch: 6| Step: 1
Training loss: 0.7715335105990503
Validation loss: 2.3557738913232416

Epoch: 6| Step: 2
Training loss: 1.2531074998351852
Validation loss: 2.3900370616478916

Epoch: 6| Step: 3
Training loss: 0.9183661716587738
Validation loss: 2.2865825222902103

Epoch: 6| Step: 4
Training loss: 2.0365784228365187
Validation loss: 2.3677513279299243

Epoch: 6| Step: 5
Training loss: 1.1234536669845188
Validation loss: 2.2693684826170264

Epoch: 6| Step: 6
Training loss: 1.3086300972972171
Validation loss: 2.3054048478902684

Epoch: 6| Step: 7
Training loss: 1.4419784443972958
Validation loss: 2.3453168645345133

Epoch: 6| Step: 8
Training loss: 0.7608680865765058
Validation loss: 2.3127721001718906

Epoch: 6| Step: 9
Training loss: 1.123385966979958
Validation loss: 2.269755506662078

Epoch: 6| Step: 10
Training loss: 1.498398004832775
Validation loss: 2.3132877610015132

Epoch: 6| Step: 11
Training loss: 0.8000476361039716
Validation loss: 2.280970295699739

Epoch: 6| Step: 12
Training loss: 0.7018684179009289
Validation loss: 2.379837795344169

Epoch: 6| Step: 13
Training loss: 0.7269425167435067
Validation loss: 2.311217379432453

Epoch: 442| Step: 0
Training loss: 0.7973285954833271
Validation loss: 2.405391056646509

Epoch: 6| Step: 1
Training loss: 1.354682540444488
Validation loss: 2.3823968856712576

Epoch: 6| Step: 2
Training loss: 1.178986600105684
Validation loss: 2.3330720491142607

Epoch: 6| Step: 3
Training loss: 1.3214473925542598
Validation loss: 2.341481979813911

Epoch: 6| Step: 4
Training loss: 0.9948411133678661
Validation loss: 2.2869310914568945

Epoch: 6| Step: 5
Training loss: 1.1197142936530777
Validation loss: 2.3632388558683295

Epoch: 6| Step: 6
Training loss: 0.7770478725438836
Validation loss: 2.288524685040625

Epoch: 6| Step: 7
Training loss: 2.0314802772865885
Validation loss: 2.3983717362881953

Epoch: 6| Step: 8
Training loss: 0.8979786903809555
Validation loss: 2.2527759073742972

Epoch: 6| Step: 9
Training loss: 0.649227878584417
Validation loss: 2.2984144755015308

Epoch: 6| Step: 10
Training loss: 0.9448056399073701
Validation loss: 2.3710078390636147

Epoch: 6| Step: 11
Training loss: 0.9368461554058773
Validation loss: 2.335691317165168

Epoch: 6| Step: 12
Training loss: 0.6574955428084808
Validation loss: 2.282179973997917

Epoch: 6| Step: 13
Training loss: 0.921417057930713
Validation loss: 2.2567856963822353

Epoch: 443| Step: 0
Training loss: 1.1660433818637996
Validation loss: 2.2342650749828885

Epoch: 6| Step: 1
Training loss: 2.0028251721116215
Validation loss: 2.3026765437596786

Epoch: 6| Step: 2
Training loss: 1.2283488101234377
Validation loss: 2.3032780946566596

Epoch: 6| Step: 3
Training loss: 0.7382215041756064
Validation loss: 2.241169748864557

Epoch: 6| Step: 4
Training loss: 0.9624762272066397
Validation loss: 2.2802201915006086

Epoch: 6| Step: 5
Training loss: 1.221145427681771
Validation loss: 2.2923328512753307

Epoch: 6| Step: 6
Training loss: 1.1092866674367714
Validation loss: 2.347809519209457

Epoch: 6| Step: 7
Training loss: 0.7380629120763468
Validation loss: 2.2358791211699267

Epoch: 6| Step: 8
Training loss: 1.2904769535452894
Validation loss: 2.321456179296345

Epoch: 6| Step: 9
Training loss: 0.9078808940920394
Validation loss: 2.2909432907441207

Epoch: 6| Step: 10
Training loss: 1.0472805319510907
Validation loss: 2.306094509289568

Epoch: 6| Step: 11
Training loss: 0.9064969679965333
Validation loss: 2.2533228184793934

Epoch: 6| Step: 12
Training loss: 1.1152144929680243
Validation loss: 2.2908762720097875

Epoch: 6| Step: 13
Training loss: 1.176123331690491
Validation loss: 2.2684528754817097

Epoch: 444| Step: 0
Training loss: 1.121384320501115
Validation loss: 2.3130647855936073

Epoch: 6| Step: 1
Training loss: 0.9795190231283041
Validation loss: 2.3001927270524467

Epoch: 6| Step: 2
Training loss: 1.9739326804179265
Validation loss: 2.314806625060038

Epoch: 6| Step: 3
Training loss: 0.918671489137727
Validation loss: 2.3324521194564496

Epoch: 6| Step: 4
Training loss: 1.1549728144299083
Validation loss: 2.3477558339203104

Epoch: 6| Step: 5
Training loss: 0.7742583417729464
Validation loss: 2.3466880840897764

Epoch: 6| Step: 6
Training loss: 1.0402953212760067
Validation loss: 2.3675389897494634

Epoch: 6| Step: 7
Training loss: 1.0407397851270868
Validation loss: 2.2967275271223686

Epoch: 6| Step: 8
Training loss: 1.1010182977588596
Validation loss: 2.26332664587649

Epoch: 6| Step: 9
Training loss: 1.0709611361243723
Validation loss: 2.3009437094053045

Epoch: 6| Step: 10
Training loss: 1.2580166763540634
Validation loss: 2.280666350264093

Epoch: 6| Step: 11
Training loss: 1.0763721314359784
Validation loss: 2.3582793997037035

Epoch: 6| Step: 12
Training loss: 1.0540955189052243
Validation loss: 2.276283044298547

Epoch: 6| Step: 13
Training loss: 1.0845892790666694
Validation loss: 2.3444751867280287

Epoch: 445| Step: 0
Training loss: 1.0389766801084046
Validation loss: 2.3030564120565002

Epoch: 6| Step: 1
Training loss: 1.1847999897295522
Validation loss: 2.232334570953568

Epoch: 6| Step: 2
Training loss: 1.1553405587439454
Validation loss: 2.3400791092366564

Epoch: 6| Step: 3
Training loss: 0.8562017287966894
Validation loss: 2.293711164396695

Epoch: 6| Step: 4
Training loss: 0.9863115668087233
Validation loss: 2.2967549947652555

Epoch: 6| Step: 5
Training loss: 0.7904214770449379
Validation loss: 2.3533853068537685

Epoch: 6| Step: 6
Training loss: 1.2778602045996228
Validation loss: 2.314065223366481

Epoch: 6| Step: 7
Training loss: 1.0332701576568557
Validation loss: 2.252698028124486

Epoch: 6| Step: 8
Training loss: 1.102002428014057
Validation loss: 2.34988642027326

Epoch: 6| Step: 9
Training loss: 1.0735286090949268
Validation loss: 2.293802499585243

Epoch: 6| Step: 10
Training loss: 0.8583385112445783
Validation loss: 2.3451059117783153

Epoch: 6| Step: 11
Training loss: 1.9611666116194422
Validation loss: 2.325446509097374

Epoch: 6| Step: 12
Training loss: 0.9935183273030306
Validation loss: 2.3425620455828198

Epoch: 6| Step: 13
Training loss: 0.7495641634110037
Validation loss: 2.2290672946739427

Epoch: 446| Step: 0
Training loss: 0.7462378557453462
Validation loss: 2.249559073843635

Epoch: 6| Step: 1
Training loss: 1.1874404691531246
Validation loss: 2.347184047917255

Epoch: 6| Step: 2
Training loss: 0.9239505743125997
Validation loss: 2.361859740934141

Epoch: 6| Step: 3
Training loss: 1.241545889354693
Validation loss: 2.28502219197548

Epoch: 6| Step: 4
Training loss: 1.0619864625229605
Validation loss: 2.269629056863094

Epoch: 6| Step: 5
Training loss: 1.2164093429143903
Validation loss: 2.37792356497502

Epoch: 6| Step: 6
Training loss: 1.1442010292474005
Validation loss: 2.4038925064767263

Epoch: 6| Step: 7
Training loss: 1.084436270881903
Validation loss: 2.3352871607321677

Epoch: 6| Step: 8
Training loss: 0.9814386320124004
Validation loss: 2.293123055045896

Epoch: 6| Step: 9
Training loss: 0.8901230585553597
Validation loss: 2.338600191029484

Epoch: 6| Step: 10
Training loss: 0.8651408538908999
Validation loss: 2.274068619838482

Epoch: 6| Step: 11
Training loss: 1.0966193572355434
Validation loss: 2.317343160286757

Epoch: 6| Step: 12
Training loss: 0.8882474787188069
Validation loss: 2.3460526801851556

Epoch: 6| Step: 13
Training loss: 2.595560935369052
Validation loss: 2.2742540354653156

Epoch: 447| Step: 0
Training loss: 0.94299840240505
Validation loss: 2.277904293973017

Epoch: 6| Step: 1
Training loss: 1.2120790576739195
Validation loss: 2.248583672308851

Epoch: 6| Step: 2
Training loss: 1.3574603397765115
Validation loss: 2.2450579303157485

Epoch: 6| Step: 3
Training loss: 1.3800066482687872
Validation loss: 2.3026822796326303

Epoch: 6| Step: 4
Training loss: 1.2712920669002081
Validation loss: 2.3083927926377923

Epoch: 6| Step: 5
Training loss: 1.2835054781670163
Validation loss: 2.306947193575987

Epoch: 6| Step: 6
Training loss: 0.9454219534064724
Validation loss: 2.2356844087938024

Epoch: 6| Step: 7
Training loss: 0.8695070330185662
Validation loss: 2.2761178076553485

Epoch: 6| Step: 8
Training loss: 0.6785618021289378
Validation loss: 2.2041243968072344

Epoch: 6| Step: 9
Training loss: 0.874770951946011
Validation loss: 2.2535161865738322

Epoch: 6| Step: 10
Training loss: 2.026251526254859
Validation loss: 2.238338359274642

Epoch: 6| Step: 11
Training loss: 1.0829650485209825
Validation loss: 2.3435444403304055

Epoch: 6| Step: 12
Training loss: 1.0055810635904299
Validation loss: 2.259511435674694

Epoch: 6| Step: 13
Training loss: 0.9313673982290817
Validation loss: 2.3203942759675917

Epoch: 448| Step: 0
Training loss: 0.6129122796497023
Validation loss: 2.23243729407662

Epoch: 6| Step: 1
Training loss: 0.9259713858906499
Validation loss: 2.336958564872209

Epoch: 6| Step: 2
Training loss: 1.1378144426965722
Validation loss: 2.3241388762362902

Epoch: 6| Step: 3
Training loss: 1.1292595228089672
Validation loss: 2.3353148527156273

Epoch: 6| Step: 4
Training loss: 0.6540022457125076
Validation loss: 2.3187596984630385

Epoch: 6| Step: 5
Training loss: 1.1209756609565482
Validation loss: 2.3064856103998403

Epoch: 6| Step: 6
Training loss: 1.0499208465895862
Validation loss: 2.3310498033846465

Epoch: 6| Step: 7
Training loss: 1.2085369311281955
Validation loss: 2.3092945701476957

Epoch: 6| Step: 8
Training loss: 0.9168919517650637
Validation loss: 2.3102007418636052

Epoch: 6| Step: 9
Training loss: 0.842062286524157
Validation loss: 2.3153661245671584

Epoch: 6| Step: 10
Training loss: 1.1397876540062082
Validation loss: 2.275125067562558

Epoch: 6| Step: 11
Training loss: 1.945232343745802
Validation loss: 2.3893117394691217

Epoch: 6| Step: 12
Training loss: 0.8471108716912624
Validation loss: 2.2792006409902004

Epoch: 6| Step: 13
Training loss: 0.8585989829572993
Validation loss: 2.2739250146128738

Epoch: 449| Step: 0
Training loss: 0.9064612964420085
Validation loss: 2.3032039304948317

Epoch: 6| Step: 1
Training loss: 0.6477009600218336
Validation loss: 2.2425698306700768

Epoch: 6| Step: 2
Training loss: 1.4089002431314381
Validation loss: 2.355320715040925

Epoch: 6| Step: 3
Training loss: 1.1623445160775185
Validation loss: 2.266351445742701

Epoch: 6| Step: 4
Training loss: 0.9070655507412473
Validation loss: 2.3125081537485976

Epoch: 6| Step: 5
Training loss: 1.1362615760574448
Validation loss: 2.2859370995855826

Epoch: 6| Step: 6
Training loss: 0.8723725652675758
Validation loss: 2.30691269339293

Epoch: 6| Step: 7
Training loss: 0.6022929178799125
Validation loss: 2.383909599940528

Epoch: 6| Step: 8
Training loss: 0.8694791670261844
Validation loss: 2.438698585675418

Epoch: 6| Step: 9
Training loss: 1.0808630190154735
Validation loss: 2.288772517042036

Epoch: 6| Step: 10
Training loss: 1.2439538644840176
Validation loss: 2.292180363607444

Epoch: 6| Step: 11
Training loss: 1.1882659048359938
Validation loss: 2.369397873170288

Epoch: 6| Step: 12
Training loss: 2.0644203262827405
Validation loss: 2.336256783993498

Epoch: 6| Step: 13
Training loss: 1.2043516173218485
Validation loss: 2.2914792335654055

Epoch: 450| Step: 0
Training loss: 1.0067758477499398
Validation loss: 2.3536838279912558

Epoch: 6| Step: 1
Training loss: 1.1770609738187041
Validation loss: 2.3229073683809527

Epoch: 6| Step: 2
Training loss: 1.2636506493037218
Validation loss: 2.292867895714185

Epoch: 6| Step: 3
Training loss: 0.7401588421535218
Validation loss: 2.2313728371551456

Epoch: 6| Step: 4
Training loss: 0.7962016832672624
Validation loss: 2.3676926620650014

Epoch: 6| Step: 5
Training loss: 1.9423855128971927
Validation loss: 2.312812860505665

Epoch: 6| Step: 6
Training loss: 1.1422456175999138
Validation loss: 2.371366058783433

Epoch: 6| Step: 7
Training loss: 1.1520591255022261
Validation loss: 2.320355892759671

Epoch: 6| Step: 8
Training loss: 1.119703487502487
Validation loss: 2.2765610452564657

Epoch: 6| Step: 9
Training loss: 1.08599809436385
Validation loss: 2.343780280843937

Epoch: 6| Step: 10
Training loss: 0.7599194525398397
Validation loss: 2.32032854263794

Epoch: 6| Step: 11
Training loss: 1.0730588442228963
Validation loss: 2.2579972238812327

Epoch: 6| Step: 12
Training loss: 1.000926959041528
Validation loss: 2.167548889400958

Epoch: 6| Step: 13
Training loss: 0.7678483482503541
Validation loss: 2.2807397309651254

Epoch: 451| Step: 0
Training loss: 0.939506291334395
Validation loss: 2.2890344943033925

Epoch: 6| Step: 1
Training loss: 0.8330187243409908
Validation loss: 2.2504746643956928

Epoch: 6| Step: 2
Training loss: 2.1460853601492356
Validation loss: 2.262428501748708

Epoch: 6| Step: 3
Training loss: 0.9013017194619152
Validation loss: 2.2607749956251766

Epoch: 6| Step: 4
Training loss: 0.8658851948596794
Validation loss: 2.312153739026729

Epoch: 6| Step: 5
Training loss: 1.2384492296909448
Validation loss: 2.2645080551479384

Epoch: 6| Step: 6
Training loss: 0.8918034637247881
Validation loss: 2.3255069269566198

Epoch: 6| Step: 7
Training loss: 1.0045180775604547
Validation loss: 2.3335210978057592

Epoch: 6| Step: 8
Training loss: 1.091996340197065
Validation loss: 2.2677467399878504

Epoch: 6| Step: 9
Training loss: 0.847686415456376
Validation loss: 2.2384801136776913

Epoch: 6| Step: 10
Training loss: 1.2314157868127227
Validation loss: 2.1957811674154595

Epoch: 6| Step: 11
Training loss: 0.9286336936877504
Validation loss: 2.2919031649481263

Epoch: 6| Step: 12
Training loss: 1.1628892862032256
Validation loss: 2.329767393752162

Epoch: 6| Step: 13
Training loss: 0.970612611906505
Validation loss: 2.34370547344612

Epoch: 452| Step: 0
Training loss: 1.2013492608318197
Validation loss: 2.2981841415291773

Epoch: 6| Step: 1
Training loss: 0.765889102771704
Validation loss: 2.244031837822672

Epoch: 6| Step: 2
Training loss: 1.267730092489069
Validation loss: 2.2618768417044017

Epoch: 6| Step: 3
Training loss: 0.9835675879188871
Validation loss: 2.282115050232147

Epoch: 6| Step: 4
Training loss: 1.0314853284109526
Validation loss: 2.2867444273533124

Epoch: 6| Step: 5
Training loss: 1.10499611176372
Validation loss: 2.2977293176806945

Epoch: 6| Step: 6
Training loss: 0.8458434730698736
Validation loss: 2.3373794070065763

Epoch: 6| Step: 7
Training loss: 2.0718037542691183
Validation loss: 2.343044999166982

Epoch: 6| Step: 8
Training loss: 0.8522390425412117
Validation loss: 2.275724560174062

Epoch: 6| Step: 9
Training loss: 1.0675515532719873
Validation loss: 2.3957299162456707

Epoch: 6| Step: 10
Training loss: 1.1422227616613956
Validation loss: 2.325925896315786

Epoch: 6| Step: 11
Training loss: 0.8755914868756081
Validation loss: 2.2267040185403344

Epoch: 6| Step: 12
Training loss: 1.177121130862505
Validation loss: 2.3451311271072672

Epoch: 6| Step: 13
Training loss: 0.6894580527499624
Validation loss: 2.2812248764643757

Epoch: 453| Step: 0
Training loss: 0.9043305557602961
Validation loss: 2.3519821580192386

Epoch: 6| Step: 1
Training loss: 1.1948574920498587
Validation loss: 2.294994122954784

Epoch: 6| Step: 2
Training loss: 1.1922254403852923
Validation loss: 2.3856757944330904

Epoch: 6| Step: 3
Training loss: 1.1635991140656625
Validation loss: 2.3620818659920575

Epoch: 6| Step: 4
Training loss: 1.1220088506985306
Validation loss: 2.2823198770587774

Epoch: 6| Step: 5
Training loss: 2.1216281618078883
Validation loss: 2.311855418115375

Epoch: 6| Step: 6
Training loss: 0.7300699542768606
Validation loss: 2.316562160033104

Epoch: 6| Step: 7
Training loss: 0.8308166449875378
Validation loss: 2.324332209087837

Epoch: 6| Step: 8
Training loss: 0.7027102200659688
Validation loss: 2.3074509666067464

Epoch: 6| Step: 9
Training loss: 0.9152008532426765
Validation loss: 2.3639194202832097

Epoch: 6| Step: 10
Training loss: 1.1333707289042552
Validation loss: 2.2985268599813757

Epoch: 6| Step: 11
Training loss: 1.3801267155920878
Validation loss: 2.309662814242232

Epoch: 6| Step: 12
Training loss: 1.0969332557271394
Validation loss: 2.367802259646812

Epoch: 6| Step: 13
Training loss: 1.0841467383505723
Validation loss: 2.2827156192273064

Epoch: 454| Step: 0
Training loss: 0.7887282844008588
Validation loss: 2.371927005231687

Epoch: 6| Step: 1
Training loss: 0.7471523264826965
Validation loss: 2.321504505408228

Epoch: 6| Step: 2
Training loss: 0.9582446444287361
Validation loss: 2.2595426857337224

Epoch: 6| Step: 3
Training loss: 1.328556753552161
Validation loss: 2.3203835751143416

Epoch: 6| Step: 4
Training loss: 1.2694984783931236
Validation loss: 2.323776360470122

Epoch: 6| Step: 5
Training loss: 1.0116105776661033
Validation loss: 2.2895359254045835

Epoch: 6| Step: 6
Training loss: 0.9903019086392375
Validation loss: 2.1857549055587016

Epoch: 6| Step: 7
Training loss: 1.1449139056258646
Validation loss: 2.3188965455502415

Epoch: 6| Step: 8
Training loss: 1.9054031992667912
Validation loss: 2.308473202335806

Epoch: 6| Step: 9
Training loss: 1.3728678384451862
Validation loss: 2.3572590828630817

Epoch: 6| Step: 10
Training loss: 1.0777464492304
Validation loss: 2.281440594294432

Epoch: 6| Step: 11
Training loss: 0.9891948774075559
Validation loss: 2.1954093677886277

Epoch: 6| Step: 12
Training loss: 1.1063708611108047
Validation loss: 2.247216438678688

Epoch: 6| Step: 13
Training loss: 1.0415667422368744
Validation loss: 2.3076444033217047

Epoch: 455| Step: 0
Training loss: 0.8151031022882469
Validation loss: 2.2660911807459057

Epoch: 6| Step: 1
Training loss: 0.9554019683181966
Validation loss: 2.3578679721571576

Epoch: 6| Step: 2
Training loss: 0.932572832101312
Validation loss: 2.2735507966317074

Epoch: 6| Step: 3
Training loss: 1.3308804818537876
Validation loss: 2.308843418405544

Epoch: 6| Step: 4
Training loss: 0.8363146777722266
Validation loss: 2.2993606780084512

Epoch: 6| Step: 5
Training loss: 1.4679104454882494
Validation loss: 2.3592046040357353

Epoch: 6| Step: 6
Training loss: 1.0805717568107758
Validation loss: 2.2524099057208438

Epoch: 6| Step: 7
Training loss: 2.030531536098811
Validation loss: 2.256509670053916

Epoch: 6| Step: 8
Training loss: 0.8665694362556748
Validation loss: 2.309195318709485

Epoch: 6| Step: 9
Training loss: 0.8318665748931916
Validation loss: 2.219872184674336

Epoch: 6| Step: 10
Training loss: 0.7758891619321998
Validation loss: 2.367059664728404

Epoch: 6| Step: 11
Training loss: 1.096367673571725
Validation loss: 2.395682995659609

Epoch: 6| Step: 12
Training loss: 1.1597718395093637
Validation loss: 2.287440128978549

Epoch: 6| Step: 13
Training loss: 1.271579861900917
Validation loss: 2.278830266048548

Epoch: 456| Step: 0
Training loss: 1.1986511079890894
Validation loss: 2.249468704787103

Epoch: 6| Step: 1
Training loss: 0.7904860996469492
Validation loss: 2.284032712644992

Epoch: 6| Step: 2
Training loss: 0.9012253671419921
Validation loss: 2.2431233543119986

Epoch: 6| Step: 3
Training loss: 1.0845847177124177
Validation loss: 2.3023431728103745

Epoch: 6| Step: 4
Training loss: 1.3211637833686807
Validation loss: 2.3057161483138255

Epoch: 6| Step: 5
Training loss: 1.0256460107932837
Validation loss: 2.2674295505466384

Epoch: 6| Step: 6
Training loss: 0.8788598281468809
Validation loss: 2.21307836752283

Epoch: 6| Step: 7
Training loss: 1.1460181462913352
Validation loss: 2.2336691761207166

Epoch: 6| Step: 8
Training loss: 0.9319357094795158
Validation loss: 2.2625338447435666

Epoch: 6| Step: 9
Training loss: 0.7154127264238321
Validation loss: 2.2886679941927826

Epoch: 6| Step: 10
Training loss: 1.110512378759321
Validation loss: 2.3676087012747984

Epoch: 6| Step: 11
Training loss: 1.0642050357753225
Validation loss: 2.280588363960976

Epoch: 6| Step: 12
Training loss: 2.014777545055729
Validation loss: 2.3618873324812504

Epoch: 6| Step: 13
Training loss: 0.88916950755096
Validation loss: 2.348321496606499

Epoch: 457| Step: 0
Training loss: 0.9791564061594468
Validation loss: 2.3183997296956997

Epoch: 6| Step: 1
Training loss: 1.074479283036808
Validation loss: 2.2848124449236056

Epoch: 6| Step: 2
Training loss: 1.3003367904744905
Validation loss: 2.2979037171797576

Epoch: 6| Step: 3
Training loss: 1.0410401303840637
Validation loss: 2.303046790549183

Epoch: 6| Step: 4
Training loss: 1.9339888968479377
Validation loss: 2.262705712310874

Epoch: 6| Step: 5
Training loss: 1.1345756752595328
Validation loss: 2.2917523154607693

Epoch: 6| Step: 6
Training loss: 0.7841160274523146
Validation loss: 2.3151992436340474

Epoch: 6| Step: 7
Training loss: 0.8109760297320867
Validation loss: 2.1563279939004314

Epoch: 6| Step: 8
Training loss: 1.164407973260291
Validation loss: 2.2201980644348036

Epoch: 6| Step: 9
Training loss: 0.9709110152527803
Validation loss: 2.2810681091180487

Epoch: 6| Step: 10
Training loss: 0.6600295628082297
Validation loss: 2.3310021439556246

Epoch: 6| Step: 11
Training loss: 0.9083387376175379
Validation loss: 2.318142873676624

Epoch: 6| Step: 12
Training loss: 1.4041326901695521
Validation loss: 2.2686253715619165

Epoch: 6| Step: 13
Training loss: 0.8492645616290827
Validation loss: 2.307379680338097

Epoch: 458| Step: 0
Training loss: 1.0549982813961258
Validation loss: 2.3522373090170587

Epoch: 6| Step: 1
Training loss: 0.9219654814719076
Validation loss: 2.2707825041906955

Epoch: 6| Step: 2
Training loss: 0.9353365731447174
Validation loss: 2.3079213625455073

Epoch: 6| Step: 3
Training loss: 0.5738935003570302
Validation loss: 2.3003727460608534

Epoch: 6| Step: 4
Training loss: 1.1650637218746631
Validation loss: 2.2644428466084037

Epoch: 6| Step: 5
Training loss: 2.0616392015474427
Validation loss: 2.2341058524370925

Epoch: 6| Step: 6
Training loss: 0.6990392443864746
Validation loss: 2.3194976444229285

Epoch: 6| Step: 7
Training loss: 0.9070479070298756
Validation loss: 2.272430170819019

Epoch: 6| Step: 8
Training loss: 0.9911307166198453
Validation loss: 2.352607620994683

Epoch: 6| Step: 9
Training loss: 1.6215021928742408
Validation loss: 2.2602994149422906

Epoch: 6| Step: 10
Training loss: 0.7977953812839162
Validation loss: 2.273701298293072

Epoch: 6| Step: 11
Training loss: 1.176699865663517
Validation loss: 2.407388074137888

Epoch: 6| Step: 12
Training loss: 0.9842978855990483
Validation loss: 2.2432360597487317

Epoch: 6| Step: 13
Training loss: 0.5909438579425079
Validation loss: 2.284345907954691

Epoch: 459| Step: 0
Training loss: 0.9964992520587448
Validation loss: 2.2697717372138304

Epoch: 6| Step: 1
Training loss: 1.0247681681205996
Validation loss: 2.398160710513059

Epoch: 6| Step: 2
Training loss: 1.2761607627046232
Validation loss: 2.3673051726139143

Epoch: 6| Step: 3
Training loss: 0.7156323528328505
Validation loss: 2.348081774757469

Epoch: 6| Step: 4
Training loss: 0.900892469515954
Validation loss: 2.3226065649189414

Epoch: 6| Step: 5
Training loss: 1.0039517284734651
Validation loss: 2.3456934112025016

Epoch: 6| Step: 6
Training loss: 1.991851718504395
Validation loss: 2.276120097465996

Epoch: 6| Step: 7
Training loss: 0.9627007535168124
Validation loss: 2.2943960282323905

Epoch: 6| Step: 8
Training loss: 0.7482091662898019
Validation loss: 2.285673889087562

Epoch: 6| Step: 9
Training loss: 1.1009168965005889
Validation loss: 2.2641621405523176

Epoch: 6| Step: 10
Training loss: 0.8454860205958163
Validation loss: 2.3259550218265135

Epoch: 6| Step: 11
Training loss: 0.8401252806994652
Validation loss: 2.3394747226383803

Epoch: 6| Step: 12
Training loss: 0.6278921919999285
Validation loss: 2.3570960924111897

Epoch: 6| Step: 13
Training loss: 1.442628502501971
Validation loss: 2.379522240926574

Epoch: 460| Step: 0
Training loss: 0.72701700412641
Validation loss: 2.2798684184917137

Epoch: 6| Step: 1
Training loss: 0.782798148687997
Validation loss: 2.239370693024182

Epoch: 6| Step: 2
Training loss: 0.5023536716745034
Validation loss: 2.3050599773480784

Epoch: 6| Step: 3
Training loss: 0.9311105751787412
Validation loss: 2.3804263444141043

Epoch: 6| Step: 4
Training loss: 0.8993957385123598
Validation loss: 2.3133194194151967

Epoch: 6| Step: 5
Training loss: 1.3878174633408946
Validation loss: 2.272067584020636

Epoch: 6| Step: 6
Training loss: 0.9841571142867364
Validation loss: 2.360311627459056

Epoch: 6| Step: 7
Training loss: 1.0740154282014056
Validation loss: 2.271940812676812

Epoch: 6| Step: 8
Training loss: 1.299604920728484
Validation loss: 2.306927393997851

Epoch: 6| Step: 9
Training loss: 2.067966730097356
Validation loss: 2.3141377133863164

Epoch: 6| Step: 10
Training loss: 0.64032873420745
Validation loss: 2.388191126805596

Epoch: 6| Step: 11
Training loss: 1.143563235517262
Validation loss: 2.2432058133686477

Epoch: 6| Step: 12
Training loss: 1.1512795917298893
Validation loss: 2.334874882335895

Epoch: 6| Step: 13
Training loss: 1.5405984562875639
Validation loss: 2.296174408589863

Epoch: 461| Step: 0
Training loss: 0.911649404207737
Validation loss: 2.3458075567113124

Epoch: 6| Step: 1
Training loss: 0.7536246608949128
Validation loss: 2.3228815183588147

Epoch: 6| Step: 2
Training loss: 2.113538574798062
Validation loss: 2.2853430040010125

Epoch: 6| Step: 3
Training loss: 0.7249214754659541
Validation loss: 2.249254059737112

Epoch: 6| Step: 4
Training loss: 1.1247131723758115
Validation loss: 2.3162359243425836

Epoch: 6| Step: 5
Training loss: 0.5680091276862573
Validation loss: 2.2635811015973126

Epoch: 6| Step: 6
Training loss: 0.9590969291565462
Validation loss: 2.3238924959287006

Epoch: 6| Step: 7
Training loss: 1.071013228202073
Validation loss: 2.3261161776798214

Epoch: 6| Step: 8
Training loss: 1.0394323164137593
Validation loss: 2.3311710388171076

Epoch: 6| Step: 9
Training loss: 1.2676177172950516
Validation loss: 2.334403972037136

Epoch: 6| Step: 10
Training loss: 1.2398985400529954
Validation loss: 2.341972340874275

Epoch: 6| Step: 11
Training loss: 1.006890577578199
Validation loss: 2.226977115894885

Epoch: 6| Step: 12
Training loss: 1.2150226228279721
Validation loss: 2.275747911045785

Epoch: 6| Step: 13
Training loss: 0.9571969336512797
Validation loss: 2.214352819267933

Epoch: 462| Step: 0
Training loss: 0.6928829221676881
Validation loss: 2.3021694871220353

Epoch: 6| Step: 1
Training loss: 0.9892177441871601
Validation loss: 2.311076777517439

Epoch: 6| Step: 2
Training loss: 1.276579368601255
Validation loss: 2.4115955844657964

Epoch: 6| Step: 3
Training loss: 1.0830485385292308
Validation loss: 2.3473193744047345

Epoch: 6| Step: 4
Training loss: 1.1360718239725176
Validation loss: 2.246563084429367

Epoch: 6| Step: 5
Training loss: 1.1561209632422786
Validation loss: 2.314166816658453

Epoch: 6| Step: 6
Training loss: 1.1449594575459117
Validation loss: 2.2981774930974823

Epoch: 6| Step: 7
Training loss: 0.9399292625534533
Validation loss: 2.310416330783023

Epoch: 6| Step: 8
Training loss: 1.150475490788124
Validation loss: 2.3670897050565616

Epoch: 6| Step: 9
Training loss: 1.2010695995425291
Validation loss: 2.2651378069579913

Epoch: 6| Step: 10
Training loss: 2.095364304143229
Validation loss: 2.2849328776722455

Epoch: 6| Step: 11
Training loss: 0.8433684793381068
Validation loss: 2.2784263654690387

Epoch: 6| Step: 12
Training loss: 0.7652706182444576
Validation loss: 2.3131347850368242

Epoch: 6| Step: 13
Training loss: 0.7477920137907881
Validation loss: 2.3538045402291914

Epoch: 463| Step: 0
Training loss: 0.8789121500453009
Validation loss: 2.393476040415708

Epoch: 6| Step: 1
Training loss: 1.2469886747089145
Validation loss: 2.2915392570838167

Epoch: 6| Step: 2
Training loss: 0.9960907580760826
Validation loss: 2.31628965507592

Epoch: 6| Step: 3
Training loss: 1.0023629166635557
Validation loss: 2.3091306332622645

Epoch: 6| Step: 4
Training loss: 1.098742236304168
Validation loss: 2.2894865843828427

Epoch: 6| Step: 5
Training loss: 0.8181084951625779
Validation loss: 2.287823627508281

Epoch: 6| Step: 6
Training loss: 0.8788739007718609
Validation loss: 2.293774457878633

Epoch: 6| Step: 7
Training loss: 1.7803924236198967
Validation loss: 2.216118697305208

Epoch: 6| Step: 8
Training loss: 0.9229679417772114
Validation loss: 2.407731730266353

Epoch: 6| Step: 9
Training loss: 1.1283334513053287
Validation loss: 2.1909818400815384

Epoch: 6| Step: 10
Training loss: 0.9952635053855249
Validation loss: 2.305633226298692

Epoch: 6| Step: 11
Training loss: 1.0410096703335792
Validation loss: 2.223697847002411

Epoch: 6| Step: 12
Training loss: 1.317259560058561
Validation loss: 2.251228627155499

Epoch: 6| Step: 13
Training loss: 1.1147264703601591
Validation loss: 2.2698507948317164

Epoch: 464| Step: 0
Training loss: 0.6128325065836838
Validation loss: 2.2850573693369363

Epoch: 6| Step: 1
Training loss: 0.8712408514650795
Validation loss: 2.2546839139958146

Epoch: 6| Step: 2
Training loss: 0.9493755007071364
Validation loss: 2.2926368703098765

Epoch: 6| Step: 3
Training loss: 1.24475475346994
Validation loss: 2.3371695224721387

Epoch: 6| Step: 4
Training loss: 1.1914446715116223
Validation loss: 2.294066833661594

Epoch: 6| Step: 5
Training loss: 1.0132280087215197
Validation loss: 2.316943237148201

Epoch: 6| Step: 6
Training loss: 1.0076590724343006
Validation loss: 2.314997384886185

Epoch: 6| Step: 7
Training loss: 0.9539097853836417
Validation loss: 2.2501899133197485

Epoch: 6| Step: 8
Training loss: 0.4947244263853996
Validation loss: 2.3165962636428836

Epoch: 6| Step: 9
Training loss: 1.0771111960038404
Validation loss: 2.2732413842737804

Epoch: 6| Step: 10
Training loss: 1.2406476150872887
Validation loss: 2.31288852105169

Epoch: 6| Step: 11
Training loss: 1.8894687616451642
Validation loss: 2.3268469874377633

Epoch: 6| Step: 12
Training loss: 1.0023267618168357
Validation loss: 2.263588678975014

Epoch: 6| Step: 13
Training loss: 0.756037530923651
Validation loss: 2.252236716361259

Epoch: 465| Step: 0
Training loss: 0.7949745479444138
Validation loss: 2.329454918532196

Epoch: 6| Step: 1
Training loss: 1.0443247577446235
Validation loss: 2.3537724580779757

Epoch: 6| Step: 2
Training loss: 1.1768217330603639
Validation loss: 2.2816280153497175

Epoch: 6| Step: 3
Training loss: 1.0570907339203648
Validation loss: 2.3119214938181853

Epoch: 6| Step: 4
Training loss: 2.0489014356968673
Validation loss: 2.318701596898214

Epoch: 6| Step: 5
Training loss: 1.126462462662064
Validation loss: 2.3417915162793514

Epoch: 6| Step: 6
Training loss: 0.781811893578478
Validation loss: 2.3668640542796537

Epoch: 6| Step: 7
Training loss: 1.1589996018034652
Validation loss: 2.2867541544484786

Epoch: 6| Step: 8
Training loss: 1.0329512810200085
Validation loss: 2.3000625336569493

Epoch: 6| Step: 9
Training loss: 1.019095960042599
Validation loss: 2.301274724208572

Epoch: 6| Step: 10
Training loss: 0.7670240270787806
Validation loss: 2.290930472187784

Epoch: 6| Step: 11
Training loss: 0.7511713100357827
Validation loss: 2.2370578737172178

Epoch: 6| Step: 12
Training loss: 0.9233042096343125
Validation loss: 2.2533993399347136

Epoch: 6| Step: 13
Training loss: 1.2397400358937758
Validation loss: 2.240846219941816

Epoch: 466| Step: 0
Training loss: 1.062811805749547
Validation loss: 2.3112007333593034

Epoch: 6| Step: 1
Training loss: 0.6691057444409525
Validation loss: 2.212574563074425

Epoch: 6| Step: 2
Training loss: 0.7802416588491115
Validation loss: 2.3217143272687597

Epoch: 6| Step: 3
Training loss: 0.8114489212437017
Validation loss: 2.2582266924011702

Epoch: 6| Step: 4
Training loss: 1.1289234094074614
Validation loss: 2.27691108188637

Epoch: 6| Step: 5
Training loss: 1.1389968434525342
Validation loss: 2.3166222308307396

Epoch: 6| Step: 6
Training loss: 1.0815816006961927
Validation loss: 2.283601100817842

Epoch: 6| Step: 7
Training loss: 0.8915382187268205
Validation loss: 2.3398110348749515

Epoch: 6| Step: 8
Training loss: 0.9355641405268449
Validation loss: 2.361992738015472

Epoch: 6| Step: 9
Training loss: 1.2571894838306572
Validation loss: 2.312457347278081

Epoch: 6| Step: 10
Training loss: 1.1322890552161926
Validation loss: 2.3109022178675303

Epoch: 6| Step: 11
Training loss: 2.083908980631564
Validation loss: 2.3002975843825233

Epoch: 6| Step: 12
Training loss: 0.9812708761339209
Validation loss: 2.2748122399337714

Epoch: 6| Step: 13
Training loss: 1.4805941968928564
Validation loss: 2.2548123150065997

Epoch: 467| Step: 0
Training loss: 0.866128532678835
Validation loss: 2.294330111528101

Epoch: 6| Step: 1
Training loss: 1.1063563150300562
Validation loss: 2.2685020626112014

Epoch: 6| Step: 2
Training loss: 0.6753822206996914
Validation loss: 2.263469271593217

Epoch: 6| Step: 3
Training loss: 1.2831433890502664
Validation loss: 2.2447736924165165

Epoch: 6| Step: 4
Training loss: 1.271168002894681
Validation loss: 2.3669888138783506

Epoch: 6| Step: 5
Training loss: 1.086242632912257
Validation loss: 2.2766396131844786

Epoch: 6| Step: 6
Training loss: 0.7467988362442699
Validation loss: 2.327139372225289

Epoch: 6| Step: 7
Training loss: 0.7293836724845243
Validation loss: 2.2709105554617626

Epoch: 6| Step: 8
Training loss: 0.9984376146200051
Validation loss: 2.366631770956327

Epoch: 6| Step: 9
Training loss: 0.8164774667441957
Validation loss: 2.293481992286943

Epoch: 6| Step: 10
Training loss: 1.2248455105893115
Validation loss: 2.3381094478435296

Epoch: 6| Step: 11
Training loss: 1.0627705285730797
Validation loss: 2.364680508088666

Epoch: 6| Step: 12
Training loss: 0.8851188308334904
Validation loss: 2.3449672045838037

Epoch: 6| Step: 13
Training loss: 2.4016200518490853
Validation loss: 2.255717426222265

Epoch: 468| Step: 0
Training loss: 1.2031317376282529
Validation loss: 2.183099129233076

Epoch: 6| Step: 1
Training loss: 0.6475301622118625
Validation loss: 2.2058173579188205

Epoch: 6| Step: 2
Training loss: 1.1420903656409132
Validation loss: 2.218135184123229

Epoch: 6| Step: 3
Training loss: 1.0814510952266323
Validation loss: 2.2482282198113137

Epoch: 6| Step: 4
Training loss: 0.9985474527436637
Validation loss: 2.2575962153103104

Epoch: 6| Step: 5
Training loss: 1.2836345719517266
Validation loss: 2.3360124214447273

Epoch: 6| Step: 6
Training loss: 0.8724904175152904
Validation loss: 2.218752922115109

Epoch: 6| Step: 7
Training loss: 1.9864936392063222
Validation loss: 2.274612015111407

Epoch: 6| Step: 8
Training loss: 0.9055416364191634
Validation loss: 2.278981374385812

Epoch: 6| Step: 9
Training loss: 1.0455191643161164
Validation loss: 2.2782681731185916

Epoch: 6| Step: 10
Training loss: 1.036310380251015
Validation loss: 2.311881918151009

Epoch: 6| Step: 11
Training loss: 0.8557369909008128
Validation loss: 2.330609217600511

Epoch: 6| Step: 12
Training loss: 0.9272547716936932
Validation loss: 2.299877176665751

Epoch: 6| Step: 13
Training loss: 0.39531424224228345
Validation loss: 2.2715297450344414

Epoch: 469| Step: 0
Training loss: 0.7986530960951533
Validation loss: 2.2446577360859616

Epoch: 6| Step: 1
Training loss: 0.9684802879686808
Validation loss: 2.2894596728386785

Epoch: 6| Step: 2
Training loss: 1.4888485605715305
Validation loss: 2.299980338531105

Epoch: 6| Step: 3
Training loss: 1.9516458021699752
Validation loss: 2.331229831975943

Epoch: 6| Step: 4
Training loss: 0.7757726924305163
Validation loss: 2.2129153148802008

Epoch: 6| Step: 5
Training loss: 1.151193697916374
Validation loss: 2.2978633350039908

Epoch: 6| Step: 6
Training loss: 0.9845273036299527
Validation loss: 2.2217174261332304

Epoch: 6| Step: 7
Training loss: 0.693012698907635
Validation loss: 2.2752526406335094

Epoch: 6| Step: 8
Training loss: 1.0605282720406015
Validation loss: 2.2921734483514666

Epoch: 6| Step: 9
Training loss: 1.037455470496857
Validation loss: 2.286645925361353

Epoch: 6| Step: 10
Training loss: 0.9734475161311136
Validation loss: 2.3013157594763345

Epoch: 6| Step: 11
Training loss: 0.6751206537427109
Validation loss: 2.2838396619686776

Epoch: 6| Step: 12
Training loss: 1.1055088642512045
Validation loss: 2.24184102594359

Epoch: 6| Step: 13
Training loss: 1.215702207413094
Validation loss: 2.28125255661553

Epoch: 470| Step: 0
Training loss: 1.112226769830445
Validation loss: 2.2685253471307267

Epoch: 6| Step: 1
Training loss: 1.8683170110424543
Validation loss: 2.283966331287402

Epoch: 6| Step: 2
Training loss: 1.0071609520083804
Validation loss: 2.2135068599466456

Epoch: 6| Step: 3
Training loss: 0.6684479361027523
Validation loss: 2.3268208368774825

Epoch: 6| Step: 4
Training loss: 0.9488153110485376
Validation loss: 2.2778156684880675

Epoch: 6| Step: 5
Training loss: 0.6924360548028946
Validation loss: 2.284866831580246

Epoch: 6| Step: 6
Training loss: 0.7223101225164661
Validation loss: 2.285368757005344

Epoch: 6| Step: 7
Training loss: 1.0722373861405639
Validation loss: 2.320466652788371

Epoch: 6| Step: 8
Training loss: 0.9566684580220144
Validation loss: 2.2645972331266195

Epoch: 6| Step: 9
Training loss: 0.8563299851753627
Validation loss: 2.3077867828968444

Epoch: 6| Step: 10
Training loss: 1.4020639634553906
Validation loss: 2.2944747843278286

Epoch: 6| Step: 11
Training loss: 1.2790306221917724
Validation loss: 2.3170870346514585

Epoch: 6| Step: 12
Training loss: 0.932053832222629
Validation loss: 2.2315152075088958

Epoch: 6| Step: 13
Training loss: 0.6646270147655026
Validation loss: 2.2470187132662702

Epoch: 471| Step: 0
Training loss: 0.7292317406817512
Validation loss: 2.2239446668173026

Epoch: 6| Step: 1
Training loss: 1.8462433201095
Validation loss: 2.3453604138987076

Epoch: 6| Step: 2
Training loss: 0.7150653433118462
Validation loss: 2.3123317924503044

Epoch: 6| Step: 3
Training loss: 0.9833596457716418
Validation loss: 2.2912320904248054

Epoch: 6| Step: 4
Training loss: 1.0301248596954158
Validation loss: 2.3385963991713536

Epoch: 6| Step: 5
Training loss: 1.2203267486170242
Validation loss: 2.2774267688622873

Epoch: 6| Step: 6
Training loss: 0.8178266370846545
Validation loss: 2.3897487131665445

Epoch: 6| Step: 7
Training loss: 0.8462027468089254
Validation loss: 2.232048663424031

Epoch: 6| Step: 8
Training loss: 1.0519065078848815
Validation loss: 2.3352894106391773

Epoch: 6| Step: 9
Training loss: 0.8268213627517796
Validation loss: 2.2733773458698248

Epoch: 6| Step: 10
Training loss: 1.1070464505354725
Validation loss: 2.302361091053433

Epoch: 6| Step: 11
Training loss: 0.9647289315913732
Validation loss: 2.3564050545029542

Epoch: 6| Step: 12
Training loss: 1.0584840049021658
Validation loss: 2.27172652819844

Epoch: 6| Step: 13
Training loss: 0.9899375515806593
Validation loss: 2.249678943201373

Epoch: 472| Step: 0
Training loss: 0.5216930986092351
Validation loss: 2.340952986505593

Epoch: 6| Step: 1
Training loss: 0.8527963081967028
Validation loss: 2.324868654044575

Epoch: 6| Step: 2
Training loss: 0.4837704854762746
Validation loss: 2.3316200374610894

Epoch: 6| Step: 3
Training loss: 0.7350431608645442
Validation loss: 2.2514156573224744

Epoch: 6| Step: 4
Training loss: 1.098083087292811
Validation loss: 2.2662130795573496

Epoch: 6| Step: 5
Training loss: 1.137752207368953
Validation loss: 2.2643032248017905

Epoch: 6| Step: 6
Training loss: 0.7933502782753731
Validation loss: 2.314942762300322

Epoch: 6| Step: 7
Training loss: 1.9688301675611155
Validation loss: 2.280182210243553

Epoch: 6| Step: 8
Training loss: 1.1275555935706263
Validation loss: 2.254567925542993

Epoch: 6| Step: 9
Training loss: 1.3668105995555393
Validation loss: 2.3043052588564152

Epoch: 6| Step: 10
Training loss: 1.1366631667977276
Validation loss: 2.368172525810035

Epoch: 6| Step: 11
Training loss: 0.7352685159545774
Validation loss: 2.362080208148398

Epoch: 6| Step: 12
Training loss: 1.1252051272408692
Validation loss: 2.2888274110764115

Epoch: 6| Step: 13
Training loss: 0.6824088372140739
Validation loss: 2.308585359219316

Epoch: 473| Step: 0
Training loss: 0.682018142696597
Validation loss: 2.3162284909727986

Epoch: 6| Step: 1
Training loss: 0.8937590151778954
Validation loss: 2.3015307643648257

Epoch: 6| Step: 2
Training loss: 0.9928184365493373
Validation loss: 2.220795154049038

Epoch: 6| Step: 3
Training loss: 2.332963357839599
Validation loss: 2.275350594779102

Epoch: 6| Step: 4
Training loss: 0.8288745007560192
Validation loss: 2.252962580945043

Epoch: 6| Step: 5
Training loss: 0.7645327113870624
Validation loss: 2.2603654325903593

Epoch: 6| Step: 6
Training loss: 1.0074707753034404
Validation loss: 2.2446249682089987

Epoch: 6| Step: 7
Training loss: 0.5954188935131647
Validation loss: 2.214561469734041

Epoch: 6| Step: 8
Training loss: 1.2479794384045035
Validation loss: 2.246319546471774

Epoch: 6| Step: 9
Training loss: 0.65039820852813
Validation loss: 2.2844067801804875

Epoch: 6| Step: 10
Training loss: 1.0874148412225257
Validation loss: 2.2435613705503035

Epoch: 6| Step: 11
Training loss: 1.1550093515851487
Validation loss: 2.312025774860298

Epoch: 6| Step: 12
Training loss: 0.7751269144306185
Validation loss: 2.2746076764620144

Epoch: 6| Step: 13
Training loss: 0.9316978197115463
Validation loss: 2.2623484283640236

Epoch: 474| Step: 0
Training loss: 0.6742988600716593
Validation loss: 2.324735843958319

Epoch: 6| Step: 1
Training loss: 1.0057264517943874
Validation loss: 2.356477790162896

Epoch: 6| Step: 2
Training loss: 1.04187640303876
Validation loss: 2.294276988390539

Epoch: 6| Step: 3
Training loss: 1.235728427261088
Validation loss: 2.2733710037924433

Epoch: 6| Step: 4
Training loss: 1.1845410273392092
Validation loss: 2.255640469687795

Epoch: 6| Step: 5
Training loss: 1.150113083628326
Validation loss: 2.322315335965285

Epoch: 6| Step: 6
Training loss: 0.7111883873558928
Validation loss: 2.3210986134919644

Epoch: 6| Step: 7
Training loss: 0.9344703357758216
Validation loss: 2.206867946892365

Epoch: 6| Step: 8
Training loss: 1.1602944956398973
Validation loss: 2.3260046010387407

Epoch: 6| Step: 9
Training loss: 1.0467285509301232
Validation loss: 2.290515552008892

Epoch: 6| Step: 10
Training loss: 1.0029267753997098
Validation loss: 2.2392357726578362

Epoch: 6| Step: 11
Training loss: 2.0284957993491863
Validation loss: 2.3085488979469697

Epoch: 6| Step: 12
Training loss: 0.7618840356154856
Validation loss: 2.2131026689848023

Epoch: 6| Step: 13
Training loss: 0.7221148137976607
Validation loss: 2.324153165097875

Epoch: 475| Step: 0
Training loss: 1.1868856748369054
Validation loss: 2.263421761267496

Epoch: 6| Step: 1
Training loss: 0.7207052752868498
Validation loss: 2.2374948362317344

Epoch: 6| Step: 2
Training loss: 0.9614852956598668
Validation loss: 2.397965250342472

Epoch: 6| Step: 3
Training loss: 0.8800598034261685
Validation loss: 2.368895674206294

Epoch: 6| Step: 4
Training loss: 0.8799970173785209
Validation loss: 2.2990777053781457

Epoch: 6| Step: 5
Training loss: 2.024028088016647
Validation loss: 2.371631970532459

Epoch: 6| Step: 6
Training loss: 0.9361228046164822
Validation loss: 2.283168247501468

Epoch: 6| Step: 7
Training loss: 1.168273783883511
Validation loss: 2.3793319331256586

Epoch: 6| Step: 8
Training loss: 1.2706223714025415
Validation loss: 2.2665827869853645

Epoch: 6| Step: 9
Training loss: 0.8870544470340412
Validation loss: 2.3265929096575846

Epoch: 6| Step: 10
Training loss: 0.9015188699144847
Validation loss: 2.325978487299106

Epoch: 6| Step: 11
Training loss: 1.2398067187600281
Validation loss: 2.3088079177960648

Epoch: 6| Step: 12
Training loss: 0.6670115343809453
Validation loss: 2.3388836520135268

Epoch: 6| Step: 13
Training loss: 1.2079481574264552
Validation loss: 2.2313476078689654

Epoch: 476| Step: 0
Training loss: 0.8622895841042647
Validation loss: 2.290431418180588

Epoch: 6| Step: 1
Training loss: 0.9074833468545968
Validation loss: 2.261797211238378

Epoch: 6| Step: 2
Training loss: 0.8714209656193634
Validation loss: 2.303237688724399

Epoch: 6| Step: 3
Training loss: 1.2486174567125823
Validation loss: 2.2513431416342575

Epoch: 6| Step: 4
Training loss: 1.148391930331289
Validation loss: 2.303873403964596

Epoch: 6| Step: 5
Training loss: 0.9850197754244809
Validation loss: 2.35056264460802

Epoch: 6| Step: 6
Training loss: 0.9612804514175173
Validation loss: 2.3161197226376076

Epoch: 6| Step: 7
Training loss: 1.926006249830617
Validation loss: 2.4026811980506118

Epoch: 6| Step: 8
Training loss: 1.1697228060139893
Validation loss: 2.2787251307786724

Epoch: 6| Step: 9
Training loss: 0.9939401120847939
Validation loss: 2.2743056198487914

Epoch: 6| Step: 10
Training loss: 1.1525156183901544
Validation loss: 2.225594862362205

Epoch: 6| Step: 11
Training loss: 1.0752899932057982
Validation loss: 2.2505725487615904

Epoch: 6| Step: 12
Training loss: 0.5971459098478447
Validation loss: 2.166373474013503

Epoch: 6| Step: 13
Training loss: 0.9332942083082804
Validation loss: 2.2571622094629076

Epoch: 477| Step: 0
Training loss: 2.040540722074922
Validation loss: 2.2375727937898775

Epoch: 6| Step: 1
Training loss: 0.9170633924177423
Validation loss: 2.3176898638017143

Epoch: 6| Step: 2
Training loss: 1.1363961197805306
Validation loss: 2.29504106123529

Epoch: 6| Step: 3
Training loss: 0.9457446915237802
Validation loss: 2.3299404679495863

Epoch: 6| Step: 4
Training loss: 0.7376793724077081
Validation loss: 2.336487122967852

Epoch: 6| Step: 5
Training loss: 1.3684928547983117
Validation loss: 2.318145439369641

Epoch: 6| Step: 6
Training loss: 0.8010752440625867
Validation loss: 2.2818450882021093

Epoch: 6| Step: 7
Training loss: 0.7426650267856283
Validation loss: 2.3386893927458607

Epoch: 6| Step: 8
Training loss: 1.1291874729975087
Validation loss: 2.258478802627123

Epoch: 6| Step: 9
Training loss: 1.2701530459693595
Validation loss: 2.2023709473735247

Epoch: 6| Step: 10
Training loss: 0.9958162407359179
Validation loss: 2.2399216560684305

Epoch: 6| Step: 11
Training loss: 1.2260572036540873
Validation loss: 2.273088901029488

Epoch: 6| Step: 12
Training loss: 0.8683982850699621
Validation loss: 2.259611410970584

Epoch: 6| Step: 13
Training loss: 1.0266233754216578
Validation loss: 2.2750842067005093

Epoch: 478| Step: 0
Training loss: 0.820848743823342
Validation loss: 2.2948614942243326

Epoch: 6| Step: 1
Training loss: 1.1087123879952494
Validation loss: 2.267410621336394

Epoch: 6| Step: 2
Training loss: 1.0641103770146285
Validation loss: 2.312710503839128

Epoch: 6| Step: 3
Training loss: 1.1566197603115889
Validation loss: 2.2438378766123894

Epoch: 6| Step: 4
Training loss: 0.9833787993787678
Validation loss: 2.31505004888954

Epoch: 6| Step: 5
Training loss: 1.165154169220695
Validation loss: 2.2425737517429334

Epoch: 6| Step: 6
Training loss: 1.1981270757347755
Validation loss: 2.271327515230989

Epoch: 6| Step: 7
Training loss: 0.8372366249107351
Validation loss: 2.3424294309748483

Epoch: 6| Step: 8
Training loss: 1.0840488174116025
Validation loss: 2.247058718833705

Epoch: 6| Step: 9
Training loss: 0.6212631570355387
Validation loss: 2.273513241263024

Epoch: 6| Step: 10
Training loss: 0.5452964343133667
Validation loss: 2.3299061470436384

Epoch: 6| Step: 11
Training loss: 0.7558598087122261
Validation loss: 2.3412893918949007

Epoch: 6| Step: 12
Training loss: 1.1593735234747273
Validation loss: 2.2676210848683542

Epoch: 6| Step: 13
Training loss: 2.4974595513567066
Validation loss: 2.2773577774947835

Epoch: 479| Step: 0
Training loss: 0.801106977507952
Validation loss: 2.2587471956193115

Epoch: 6| Step: 1
Training loss: 1.1402195248971423
Validation loss: 2.340674942456175

Epoch: 6| Step: 2
Training loss: 1.1408003580823125
Validation loss: 2.310687632310069

Epoch: 6| Step: 3
Training loss: 1.3125001816522381
Validation loss: 2.1966823565942475

Epoch: 6| Step: 4
Training loss: 1.0029176230294634
Validation loss: 2.278156709036081

Epoch: 6| Step: 5
Training loss: 1.083217150008938
Validation loss: 2.25309083996987

Epoch: 6| Step: 6
Training loss: 0.71280475256028
Validation loss: 2.303936368198161

Epoch: 6| Step: 7
Training loss: 1.8949098818243562
Validation loss: 2.2225648147631483

Epoch: 6| Step: 8
Training loss: 0.8909610649639909
Validation loss: 2.2731295253941135

Epoch: 6| Step: 9
Training loss: 0.9065959861906357
Validation loss: 2.196901531867672

Epoch: 6| Step: 10
Training loss: 0.465102404270343
Validation loss: 2.3075197864897756

Epoch: 6| Step: 11
Training loss: 1.215616893986445
Validation loss: 2.2896916363001236

Epoch: 6| Step: 12
Training loss: 0.8354902407876929
Validation loss: 2.3208525400605455

Epoch: 6| Step: 13
Training loss: 1.193517796166796
Validation loss: 2.3207209439498904

Epoch: 480| Step: 0
Training loss: 0.8701334565393853
Validation loss: 2.183291608184246

Epoch: 6| Step: 1
Training loss: 0.8550151162177639
Validation loss: 2.282903416238814

Epoch: 6| Step: 2
Training loss: 1.9586238510320308
Validation loss: 2.296234667758295

Epoch: 6| Step: 3
Training loss: 0.8780189273614563
Validation loss: 2.2675331123055273

Epoch: 6| Step: 4
Training loss: 1.0640436067178216
Validation loss: 2.2831181962036635

Epoch: 6| Step: 5
Training loss: 0.9991320180943551
Validation loss: 2.3619560727814584

Epoch: 6| Step: 6
Training loss: 1.2314346639730918
Validation loss: 2.3061764348071208

Epoch: 6| Step: 7
Training loss: 0.5943165134411156
Validation loss: 2.2412131337179133

Epoch: 6| Step: 8
Training loss: 1.095224530963344
Validation loss: 2.315731195707741

Epoch: 6| Step: 9
Training loss: 0.8876585832137761
Validation loss: 2.283791761574336

Epoch: 6| Step: 10
Training loss: 0.9477647233411552
Validation loss: 2.2397879375185163

Epoch: 6| Step: 11
Training loss: 1.0100945945858717
Validation loss: 2.2867730765653835

Epoch: 6| Step: 12
Training loss: 0.7007271464034093
Validation loss: 2.270596662254508

Epoch: 6| Step: 13
Training loss: 1.10677441166318
Validation loss: 2.22812417830017

Epoch: 481| Step: 0
Training loss: 0.8856266707658319
Validation loss: 2.277418129296147

Epoch: 6| Step: 1
Training loss: 1.056635435306687
Validation loss: 2.269441828735398

Epoch: 6| Step: 2
Training loss: 0.8221009150650431
Validation loss: 2.256989516530475

Epoch: 6| Step: 3
Training loss: 1.041947225299558
Validation loss: 2.267014944654467

Epoch: 6| Step: 4
Training loss: 1.153343051876804
Validation loss: 2.2413487082595775

Epoch: 6| Step: 5
Training loss: 2.080653208721573
Validation loss: 2.273732750208488

Epoch: 6| Step: 6
Training loss: 0.8335823322862038
Validation loss: 2.321268523810275

Epoch: 6| Step: 7
Training loss: 0.9384653842986728
Validation loss: 2.3055021369848334

Epoch: 6| Step: 8
Training loss: 1.0300746346256517
Validation loss: 2.2494606205592644

Epoch: 6| Step: 9
Training loss: 0.8257597488303672
Validation loss: 2.3453476992862643

Epoch: 6| Step: 10
Training loss: 0.7751502906525642
Validation loss: 2.2283121657666363

Epoch: 6| Step: 11
Training loss: 0.7599086283669186
Validation loss: 2.2486652345505065

Epoch: 6| Step: 12
Training loss: 0.694060452049013
Validation loss: 2.291959728918864

Epoch: 6| Step: 13
Training loss: 0.8154993084636214
Validation loss: 2.2614548451431835

Epoch: 482| Step: 0
Training loss: 1.8268978858477398
Validation loss: 2.210984798319567

Epoch: 6| Step: 1
Training loss: 0.8228506150275298
Validation loss: 2.3151884761376524

Epoch: 6| Step: 2
Training loss: 1.3226372381151934
Validation loss: 2.2817200488151212

Epoch: 6| Step: 3
Training loss: 1.1814405035374158
Validation loss: 2.2588370958676016

Epoch: 6| Step: 4
Training loss: 1.1740775200434121
Validation loss: 2.2551688739998443

Epoch: 6| Step: 5
Training loss: 1.0845948845600792
Validation loss: 2.367782409178201

Epoch: 6| Step: 6
Training loss: 0.6319602596367369
Validation loss: 2.3385350774272093

Epoch: 6| Step: 7
Training loss: 1.080530220318754
Validation loss: 2.2233587981732406

Epoch: 6| Step: 8
Training loss: 0.6190997089139451
Validation loss: 2.323310673140428

Epoch: 6| Step: 9
Training loss: 1.1012535473596463
Validation loss: 2.2992760547389164

Epoch: 6| Step: 10
Training loss: 0.8756295391784684
Validation loss: 2.2149132736130426

Epoch: 6| Step: 11
Training loss: 0.5273626818614133
Validation loss: 2.3052745852072434

Epoch: 6| Step: 12
Training loss: 0.8894421938231591
Validation loss: 2.2884230529204825

Epoch: 6| Step: 13
Training loss: 1.0828586541009646
Validation loss: 2.2798958362467214

Epoch: 483| Step: 0
Training loss: 0.7435676591611942
Validation loss: 2.3416948442760317

Epoch: 6| Step: 1
Training loss: 1.1313001863928438
Validation loss: 2.320872515770737

Epoch: 6| Step: 2
Training loss: 0.7148036841332265
Validation loss: 2.2598187414852613

Epoch: 6| Step: 3
Training loss: 0.7045237721046113
Validation loss: 2.2369595561325375

Epoch: 6| Step: 4
Training loss: 0.8332707302102567
Validation loss: 2.271536026794158

Epoch: 6| Step: 5
Training loss: 0.8872400843457747
Validation loss: 2.2810482818697695

Epoch: 6| Step: 6
Training loss: 0.8589140609544267
Validation loss: 2.174777507941377

Epoch: 6| Step: 7
Training loss: 0.6882767407619231
Validation loss: 2.236833497569973

Epoch: 6| Step: 8
Training loss: 1.8454204686012934
Validation loss: 2.3138768100380993

Epoch: 6| Step: 9
Training loss: 0.8194084271814888
Validation loss: 2.301782970315432

Epoch: 6| Step: 10
Training loss: 0.7561482510806361
Validation loss: 2.3673883742284296

Epoch: 6| Step: 11
Training loss: 0.9238436094764675
Validation loss: 2.3017006461671485

Epoch: 6| Step: 12
Training loss: 0.953289080395229
Validation loss: 2.2537640587718886

Epoch: 6| Step: 13
Training loss: 0.7958029473247533
Validation loss: 2.2398046633612188

Epoch: 484| Step: 0
Training loss: 0.6866413302824309
Validation loss: 2.323611317874874

Epoch: 6| Step: 1
Training loss: 0.8354990513452044
Validation loss: 2.3539623949043222

Epoch: 6| Step: 2
Training loss: 0.964522088058465
Validation loss: 2.2273057837940904

Epoch: 6| Step: 3
Training loss: 1.2033813996018532
Validation loss: 2.314223173227513

Epoch: 6| Step: 4
Training loss: 1.1250947276606165
Validation loss: 2.311535408767483

Epoch: 6| Step: 5
Training loss: 0.8443829317094488
Validation loss: 2.2654135107808058

Epoch: 6| Step: 6
Training loss: 0.6613863708118474
Validation loss: 2.3369392740694876

Epoch: 6| Step: 7
Training loss: 0.45588999680520503
Validation loss: 2.3001589319354157

Epoch: 6| Step: 8
Training loss: 1.4283912493975839
Validation loss: 2.2194982685522877

Epoch: 6| Step: 9
Training loss: 1.8330919655945777
Validation loss: 2.29906580751306

Epoch: 6| Step: 10
Training loss: 0.6826290407911655
Validation loss: 2.245048257226108

Epoch: 6| Step: 11
Training loss: 0.7961051438464308
Validation loss: 2.218524467309433

Epoch: 6| Step: 12
Training loss: 1.1708954850033146
Validation loss: 2.2406345909731344

Epoch: 6| Step: 13
Training loss: 1.0024584709755207
Validation loss: 2.3012522578804453

Epoch: 485| Step: 0
Training loss: 1.134631308191458
Validation loss: 2.2573509495367734

Epoch: 6| Step: 1
Training loss: 0.988689956288693
Validation loss: 2.3274375912112455

Epoch: 6| Step: 2
Training loss: 1.1088409212801646
Validation loss: 2.2837193938382865

Epoch: 6| Step: 3
Training loss: 0.9465751727198205
Validation loss: 2.3422402023474715

Epoch: 6| Step: 4
Training loss: 0.7535820693902882
Validation loss: 2.3360764245450243

Epoch: 6| Step: 5
Training loss: 1.0406389252701802
Validation loss: 2.233775962604661

Epoch: 6| Step: 6
Training loss: 0.8522933483519025
Validation loss: 2.289116380827292

Epoch: 6| Step: 7
Training loss: 0.8004375557570692
Validation loss: 2.2652948791765497

Epoch: 6| Step: 8
Training loss: 0.9205125341976226
Validation loss: 2.2321997834665424

Epoch: 6| Step: 9
Training loss: 0.8314042572072161
Validation loss: 2.347061233337673

Epoch: 6| Step: 10
Training loss: 1.9180471866519313
Validation loss: 2.317974713954658

Epoch: 6| Step: 11
Training loss: 1.072158502393968
Validation loss: 2.1879445352379103

Epoch: 6| Step: 12
Training loss: 0.6469862911299081
Validation loss: 2.3058491961253837

Epoch: 6| Step: 13
Training loss: 1.3953073089263826
Validation loss: 2.286038296648111

Epoch: 486| Step: 0
Training loss: 0.9984384205415449
Validation loss: 2.2711668643577556

Epoch: 6| Step: 1
Training loss: 1.017439995760809
Validation loss: 2.286233577033828

Epoch: 6| Step: 2
Training loss: 0.9965668994403334
Validation loss: 2.3381903607157075

Epoch: 6| Step: 3
Training loss: 1.190627046518244
Validation loss: 2.3102232265909426

Epoch: 6| Step: 4
Training loss: 1.0781412538049584
Validation loss: 2.408386975551911

Epoch: 6| Step: 5
Training loss: 0.7876389759290661
Validation loss: 2.265569757644498

Epoch: 6| Step: 6
Training loss: 0.8243934120858029
Validation loss: 2.1992169000251396

Epoch: 6| Step: 7
Training loss: 0.8142407183775503
Validation loss: 2.278620872724152

Epoch: 6| Step: 8
Training loss: 1.8041394214760742
Validation loss: 2.2528442421798207

Epoch: 6| Step: 9
Training loss: 0.8120881283812438
Validation loss: 2.2390093339459676

Epoch: 6| Step: 10
Training loss: 1.0585556868012784
Validation loss: 2.284088315740253

Epoch: 6| Step: 11
Training loss: 0.8255959525763195
Validation loss: 2.2723589146603134

Epoch: 6| Step: 12
Training loss: 0.6437445029236982
Validation loss: 2.339728757200699

Epoch: 6| Step: 13
Training loss: 0.8614055918762472
Validation loss: 2.2961033031264035

Epoch: 487| Step: 0
Training loss: 0.5961994792319797
Validation loss: 2.3254091342349876

Epoch: 6| Step: 1
Training loss: 0.9072361874762743
Validation loss: 2.3398139066017203

Epoch: 6| Step: 2
Training loss: 1.9543471518039992
Validation loss: 2.3051428015416087

Epoch: 6| Step: 3
Training loss: 0.7363201920059232
Validation loss: 2.3029929673619325

Epoch: 6| Step: 4
Training loss: 1.099528009849806
Validation loss: 2.3490058634546993

Epoch: 6| Step: 5
Training loss: 0.9983398544966772
Validation loss: 2.280257963009592

Epoch: 6| Step: 6
Training loss: 0.6958509781783648
Validation loss: 2.2802058319569922

Epoch: 6| Step: 7
Training loss: 1.0963197220973873
Validation loss: 2.262027850345938

Epoch: 6| Step: 8
Training loss: 0.9357014888670453
Validation loss: 2.381240257704252

Epoch: 6| Step: 9
Training loss: 1.1477144001977961
Validation loss: 2.2893739733605596

Epoch: 6| Step: 10
Training loss: 1.0063550598079496
Validation loss: 2.336287785506338

Epoch: 6| Step: 11
Training loss: 1.042917028852017
Validation loss: 2.36161824578348

Epoch: 6| Step: 12
Training loss: 0.9101092608850927
Validation loss: 2.2754915458250733

Epoch: 6| Step: 13
Training loss: 1.0041957690083152
Validation loss: 2.3334474938529395

Epoch: 488| Step: 0
Training loss: 0.9677530819689338
Validation loss: 2.3265018364291605

Epoch: 6| Step: 1
Training loss: 2.1621105879837947
Validation loss: 2.2305837533010364

Epoch: 6| Step: 2
Training loss: 0.7868867090640249
Validation loss: 2.30782943029425

Epoch: 6| Step: 3
Training loss: 0.8820651444037539
Validation loss: 2.323140859763858

Epoch: 6| Step: 4
Training loss: 1.0228091342030317
Validation loss: 2.395932590805815

Epoch: 6| Step: 5
Training loss: 1.0531644208191606
Validation loss: 2.329057917159422

Epoch: 6| Step: 6
Training loss: 0.8076653425812216
Validation loss: 2.3402466709286505

Epoch: 6| Step: 7
Training loss: 1.0707195649525396
Validation loss: 2.3101286804000547

Epoch: 6| Step: 8
Training loss: 0.7489929193001584
Validation loss: 2.2671411371320693

Epoch: 6| Step: 9
Training loss: 0.7555357563083058
Validation loss: 2.2921332185507404

Epoch: 6| Step: 10
Training loss: 0.770804924484363
Validation loss: 2.3051078978875776

Epoch: 6| Step: 11
Training loss: 0.8463844567771854
Validation loss: 2.2998456979994883

Epoch: 6| Step: 12
Training loss: 1.0107035016751154
Validation loss: 2.3158835114338894

Epoch: 6| Step: 13
Training loss: 0.48181453884622183
Validation loss: 2.2849550321097234

Epoch: 489| Step: 0
Training loss: 1.0830376417147152
Validation loss: 2.3644795187420447

Epoch: 6| Step: 1
Training loss: 0.7444012203130708
Validation loss: 2.206266347931525

Epoch: 6| Step: 2
Training loss: 0.8346032519795704
Validation loss: 2.258641430847346

Epoch: 6| Step: 3
Training loss: 0.84427379315042
Validation loss: 2.3145050318539355

Epoch: 6| Step: 4
Training loss: 0.9788461762647783
Validation loss: 2.305025470050075

Epoch: 6| Step: 5
Training loss: 2.1321113747497242
Validation loss: 2.2046394213655436

Epoch: 6| Step: 6
Training loss: 0.8009213580865114
Validation loss: 2.3219412616251462

Epoch: 6| Step: 7
Training loss: 1.0548001829633962
Validation loss: 2.2713771852583777

Epoch: 6| Step: 8
Training loss: 1.0591571054894957
Validation loss: 2.287290221973775

Epoch: 6| Step: 9
Training loss: 0.8135800885364339
Validation loss: 2.246384515333328

Epoch: 6| Step: 10
Training loss: 0.5239220269771712
Validation loss: 2.3322659323890123

Epoch: 6| Step: 11
Training loss: 0.8969844512080887
Validation loss: 2.3225065329379335

Epoch: 6| Step: 12
Training loss: 1.1053410648432935
Validation loss: 2.300686992726644

Epoch: 6| Step: 13
Training loss: 0.8392780616666456
Validation loss: 2.247130628947139

Epoch: 490| Step: 0
Training loss: 0.7862893653560898
Validation loss: 2.2926084285601713

Epoch: 6| Step: 1
Training loss: 0.7599931783119026
Validation loss: 2.2337740236131034

Epoch: 6| Step: 2
Training loss: 1.119474085049117
Validation loss: 2.2844421690175967

Epoch: 6| Step: 3
Training loss: 0.7214539294797384
Validation loss: 2.250375078355934

Epoch: 6| Step: 4
Training loss: 1.1266026208005653
Validation loss: 2.327763370436666

Epoch: 6| Step: 5
Training loss: 0.9630452432353261
Validation loss: 2.3052558433135286

Epoch: 6| Step: 6
Training loss: 0.6802546447909368
Validation loss: 2.262514708008927

Epoch: 6| Step: 7
Training loss: 0.9964530745509818
Validation loss: 2.3019574836746255

Epoch: 6| Step: 8
Training loss: 2.0115346879919502
Validation loss: 2.2546593005981665

Epoch: 6| Step: 9
Training loss: 0.6559746936795782
Validation loss: 2.3391143589440313

Epoch: 6| Step: 10
Training loss: 1.1992020497106706
Validation loss: 2.233546025721634

Epoch: 6| Step: 11
Training loss: 0.8958448734575143
Validation loss: 2.2604883994541196

Epoch: 6| Step: 12
Training loss: 1.0700532919545085
Validation loss: 2.3296498795948994

Epoch: 6| Step: 13
Training loss: 1.0878098627380122
Validation loss: 2.3678881867400285

Epoch: 491| Step: 0
Training loss: 0.8198967743076073
Validation loss: 2.2633022952406856

Epoch: 6| Step: 1
Training loss: 0.9928222488150419
Validation loss: 2.3096493991885234

Epoch: 6| Step: 2
Training loss: 0.7219540457775897
Validation loss: 2.339779786403144

Epoch: 6| Step: 3
Training loss: 1.0402198025538267
Validation loss: 2.3318812698123987

Epoch: 6| Step: 4
Training loss: 1.0234479248447768
Validation loss: 2.241169110576592

Epoch: 6| Step: 5
Training loss: 0.5495280625221324
Validation loss: 2.2177907171878606

Epoch: 6| Step: 6
Training loss: 0.8665587061493919
Validation loss: 2.2927630032887913

Epoch: 6| Step: 7
Training loss: 1.2139848328323233
Validation loss: 2.2747836620993285

Epoch: 6| Step: 8
Training loss: 1.9027711987285
Validation loss: 2.302889668824857

Epoch: 6| Step: 9
Training loss: 0.7908768897193024
Validation loss: 2.2286871849747367

Epoch: 6| Step: 10
Training loss: 0.9749534473554072
Validation loss: 2.2639232707080796

Epoch: 6| Step: 11
Training loss: 1.0920168632840133
Validation loss: 2.318200705034942

Epoch: 6| Step: 12
Training loss: 0.8438867881944918
Validation loss: 2.3084490561213773

Epoch: 6| Step: 13
Training loss: 0.8348870852641324
Validation loss: 2.290555708931639

Epoch: 492| Step: 0
Training loss: 0.4546617723507544
Validation loss: 2.2724279427229472

Epoch: 6| Step: 1
Training loss: 1.93587573478637
Validation loss: 2.2672052142063093

Epoch: 6| Step: 2
Training loss: 0.7583338723512627
Validation loss: 2.3334414303991498

Epoch: 6| Step: 3
Training loss: 0.816400336285213
Validation loss: 2.252160558362798

Epoch: 6| Step: 4
Training loss: 0.5390704057638973
Validation loss: 2.259751973858217

Epoch: 6| Step: 5
Training loss: 1.0591954847167544
Validation loss: 2.2169525801580012

Epoch: 6| Step: 6
Training loss: 0.8510763898199144
Validation loss: 2.266328944858762

Epoch: 6| Step: 7
Training loss: 0.9907304172202486
Validation loss: 2.2557955177366527

Epoch: 6| Step: 8
Training loss: 1.097844497991831
Validation loss: 2.2400687612873016

Epoch: 6| Step: 9
Training loss: 1.0663481196954068
Validation loss: 2.275645487500137

Epoch: 6| Step: 10
Training loss: 0.7391883081696384
Validation loss: 2.1983938239164273

Epoch: 6| Step: 11
Training loss: 0.9769163177401969
Validation loss: 2.324893426145118

Epoch: 6| Step: 12
Training loss: 1.0529545994215483
Validation loss: 2.3106098265811514

Epoch: 6| Step: 13
Training loss: 1.072691785830821
Validation loss: 2.2657809873184434

Epoch: 493| Step: 0
Training loss: 0.542094590419356
Validation loss: 2.335699345227847

Epoch: 6| Step: 1
Training loss: 0.935178520938124
Validation loss: 2.3534585034830275

Epoch: 6| Step: 2
Training loss: 0.9719894145577559
Validation loss: 2.273426752347314

Epoch: 6| Step: 3
Training loss: 0.940679182348748
Validation loss: 2.3002565498976315

Epoch: 6| Step: 4
Training loss: 1.0427977461052678
Validation loss: 2.287558351235683

Epoch: 6| Step: 5
Training loss: 0.8265737363343623
Validation loss: 2.3436384709118356

Epoch: 6| Step: 6
Training loss: 0.7788465532481156
Validation loss: 2.3030060293531482

Epoch: 6| Step: 7
Training loss: 0.7288621993415266
Validation loss: 2.2700254608807326

Epoch: 6| Step: 8
Training loss: 1.8165418348674183
Validation loss: 2.27740135887603

Epoch: 6| Step: 9
Training loss: 0.7988231257722924
Validation loss: 2.283136896372742

Epoch: 6| Step: 10
Training loss: 0.9934754610203654
Validation loss: 2.34311225773664

Epoch: 6| Step: 11
Training loss: 0.7469815469502726
Validation loss: 2.253616059260071

Epoch: 6| Step: 12
Training loss: 0.9799617048975146
Validation loss: 2.2461862145037466

Epoch: 6| Step: 13
Training loss: 1.3127466151742881
Validation loss: 2.276061802596171

Epoch: 494| Step: 0
Training loss: 0.7976680250354216
Validation loss: 2.247321169181675

Epoch: 6| Step: 1
Training loss: 1.1097876090396934
Validation loss: 2.256263366955954

Epoch: 6| Step: 2
Training loss: 0.9320591720146131
Validation loss: 2.2826238280625093

Epoch: 6| Step: 3
Training loss: 1.8438621745495896
Validation loss: 2.245822262685799

Epoch: 6| Step: 4
Training loss: 1.0425407874638266
Validation loss: 2.3395227496965

Epoch: 6| Step: 5
Training loss: 1.0133627712424296
Validation loss: 2.2756560173887825

Epoch: 6| Step: 6
Training loss: 0.9011222862089548
Validation loss: 2.260450658253905

Epoch: 6| Step: 7
Training loss: 0.6666633610842133
Validation loss: 2.299893394173573

Epoch: 6| Step: 8
Training loss: 0.6416662174900348
Validation loss: 2.153556195629948

Epoch: 6| Step: 9
Training loss: 0.9108235610188717
Validation loss: 2.399590467412523

Epoch: 6| Step: 10
Training loss: 0.5623756907116069
Validation loss: 2.2463251957148693

Epoch: 6| Step: 11
Training loss: 1.0396065685807387
Validation loss: 2.33567566432554

Epoch: 6| Step: 12
Training loss: 0.9514786932359263
Validation loss: 2.2837124495941183

Epoch: 6| Step: 13
Training loss: 0.9149144758580514
Validation loss: 2.241754371759283

Epoch: 495| Step: 0
Training loss: 0.7933920496227588
Validation loss: 2.410350605646172

Epoch: 6| Step: 1
Training loss: 0.8690573663158698
Validation loss: 2.3285367868143165

Epoch: 6| Step: 2
Training loss: 0.8603895267766021
Validation loss: 2.241999574228986

Epoch: 6| Step: 3
Training loss: 1.886587703094798
Validation loss: 2.274904611682169

Epoch: 6| Step: 4
Training loss: 1.1946916650873611
Validation loss: 2.292989837336532

Epoch: 6| Step: 5
Training loss: 1.2018586467199697
Validation loss: 2.283279898083884

Epoch: 6| Step: 6
Training loss: 0.837730765932152
Validation loss: 2.2689956310594255

Epoch: 6| Step: 7
Training loss: 0.8530875732260864
Validation loss: 2.2663332275266854

Epoch: 6| Step: 8
Training loss: 0.8062731480787042
Validation loss: 2.261234592714557

Epoch: 6| Step: 9
Training loss: 0.855985163363999
Validation loss: 2.273308248524342

Epoch: 6| Step: 10
Training loss: 0.8280611553413
Validation loss: 2.2474683256236414

Epoch: 6| Step: 11
Training loss: 0.6380075622008775
Validation loss: 2.259042702139153

Epoch: 6| Step: 12
Training loss: 0.8721546845667907
Validation loss: 2.364177448029324

Epoch: 6| Step: 13
Training loss: 0.7244917781855621
Validation loss: 2.222146080705449

Epoch: 496| Step: 0
Training loss: 1.0996415182670187
Validation loss: 2.265651361285926

Epoch: 6| Step: 1
Training loss: 0.6940093097117306
Validation loss: 2.330382028341733

Epoch: 6| Step: 2
Training loss: 0.9996302636406152
Validation loss: 2.141490778262773

Epoch: 6| Step: 3
Training loss: 0.7588987528929577
Validation loss: 2.290046792459284

Epoch: 6| Step: 4
Training loss: 0.7642309771495372
Validation loss: 2.2246699109194465

Epoch: 6| Step: 5
Training loss: 1.0467620333172822
Validation loss: 2.268676038663253

Epoch: 6| Step: 6
Training loss: 0.778230247886566
Validation loss: 2.241446057862579

Epoch: 6| Step: 7
Training loss: 0.7987689530298495
Validation loss: 2.21448629550212

Epoch: 6| Step: 8
Training loss: 0.5710193747375016
Validation loss: 2.288410695802185

Epoch: 6| Step: 9
Training loss: 0.9008807257243652
Validation loss: 2.258911789459064

Epoch: 6| Step: 10
Training loss: 0.9140771717948102
Validation loss: 2.346661949250275

Epoch: 6| Step: 11
Training loss: 1.0277685875238318
Validation loss: 2.2713944719383767

Epoch: 6| Step: 12
Training loss: 0.7801868070748927
Validation loss: 2.2784798334131575

Epoch: 6| Step: 13
Training loss: 2.4743909491024745
Validation loss: 2.2487172078446163

Epoch: 497| Step: 0
Training loss: 0.822853910894187
Validation loss: 2.2647757811707923

Epoch: 6| Step: 1
Training loss: 0.8011362916957446
Validation loss: 2.2845968434873862

Epoch: 6| Step: 2
Training loss: 0.7323752019634187
Validation loss: 2.3135536839743818

Epoch: 6| Step: 3
Training loss: 1.0644429897560774
Validation loss: 2.3213009834048166

Epoch: 6| Step: 4
Training loss: 0.7299791623107038
Validation loss: 2.2208894729406277

Epoch: 6| Step: 5
Training loss: 0.7576751191190387
Validation loss: 2.277501328926081

Epoch: 6| Step: 6
Training loss: 0.8539934719314141
Validation loss: 2.2775279523458516

Epoch: 6| Step: 7
Training loss: 0.8128365773202806
Validation loss: 2.2112546054399314

Epoch: 6| Step: 8
Training loss: 1.9244453795430527
Validation loss: 2.266053700296148

Epoch: 6| Step: 9
Training loss: 0.7597511113602097
Validation loss: 2.195155410538416

Epoch: 6| Step: 10
Training loss: 1.0795264602888366
Validation loss: 2.2805629240018255

Epoch: 6| Step: 11
Training loss: 1.2924121223251914
Validation loss: 2.2943127618893318

Epoch: 6| Step: 12
Training loss: 0.8364558529054975
Validation loss: 2.2686228730389617

Epoch: 6| Step: 13
Training loss: 0.719451396209764
Validation loss: 2.246990224623923

Epoch: 498| Step: 0
Training loss: 1.175999465919555
Validation loss: 2.2819733550990646

Epoch: 6| Step: 1
Training loss: 0.5951191775993221
Validation loss: 2.246933703776901

Epoch: 6| Step: 2
Training loss: 0.737334355647923
Validation loss: 2.2827829814254925

Epoch: 6| Step: 3
Training loss: 0.683757566169566
Validation loss: 2.237902311228623

Epoch: 6| Step: 4
Training loss: 0.8227832822903894
Validation loss: 2.2304358960792197

Epoch: 6| Step: 5
Training loss: 0.8390441636793805
Validation loss: 2.233778356645778

Epoch: 6| Step: 6
Training loss: 0.6016863905913389
Validation loss: 2.2687889470705267

Epoch: 6| Step: 7
Training loss: 1.0311128929778668
Validation loss: 2.300672602694967

Epoch: 6| Step: 8
Training loss: 0.8894212853617876
Validation loss: 2.2439184114613813

Epoch: 6| Step: 9
Training loss: 1.0017812481074666
Validation loss: 2.3285803615535725

Epoch: 6| Step: 10
Training loss: 0.8976263946003898
Validation loss: 2.3423348680973044

Epoch: 6| Step: 11
Training loss: 1.9945562305073987
Validation loss: 2.264930806015673

Epoch: 6| Step: 12
Training loss: 0.7631034589346886
Validation loss: 2.284314917809308

Epoch: 6| Step: 13
Training loss: 0.9585749418345751
Validation loss: 2.271525191142794

Epoch: 499| Step: 0
Training loss: 1.025439684466264
Validation loss: 2.320464477997818

Epoch: 6| Step: 1
Training loss: 0.5985212860018959
Validation loss: 2.241166539120727

Epoch: 6| Step: 2
Training loss: 1.0093811011351443
Validation loss: 2.2524393666648255

Epoch: 6| Step: 3
Training loss: 1.8731721233541079
Validation loss: 2.2523564164683285

Epoch: 6| Step: 4
Training loss: 0.9696055295463929
Validation loss: 2.2013783300068552

Epoch: 6| Step: 5
Training loss: 0.676180947351444
Validation loss: 2.2520547961677444

Epoch: 6| Step: 6
Training loss: 1.0886705982322584
Validation loss: 2.2229557729071137

Epoch: 6| Step: 7
Training loss: 0.8985620826921346
Validation loss: 2.2930621103884423

Epoch: 6| Step: 8
Training loss: 0.6584266034181026
Validation loss: 2.2215089469352223

Epoch: 6| Step: 9
Training loss: 0.6783132581841023
Validation loss: 2.2089542538350657

Epoch: 6| Step: 10
Training loss: 0.861314077111385
Validation loss: 2.3294609224790217

Epoch: 6| Step: 11
Training loss: 1.009624891969959
Validation loss: 2.289265056236629

Epoch: 6| Step: 12
Training loss: 0.8495463029974202
Validation loss: 2.254878526275311

Epoch: 6| Step: 13
Training loss: 0.7715590815045444
Validation loss: 2.2552000637358005

Epoch: 500| Step: 0
Training loss: 0.8453961315139619
Validation loss: 2.2306453545194906

Epoch: 6| Step: 1
Training loss: 1.8348792089885289
Validation loss: 2.2664837345226188

Epoch: 6| Step: 2
Training loss: 0.7414191032879284
Validation loss: 2.208699684921238

Epoch: 6| Step: 3
Training loss: 0.6448062887880776
Validation loss: 2.207321576809437

Epoch: 6| Step: 4
Training loss: 1.0329448182359244
Validation loss: 2.3569412652974817

Epoch: 6| Step: 5
Training loss: 0.6908524660797952
Validation loss: 2.2136884772145553

Epoch: 6| Step: 6
Training loss: 0.7930661221557604
Validation loss: 2.2731765649761217

Epoch: 6| Step: 7
Training loss: 0.6866454318576347
Validation loss: 2.293796270980704

Epoch: 6| Step: 8
Training loss: 0.8354959837122413
Validation loss: 2.3773307999410536

Epoch: 6| Step: 9
Training loss: 0.9708686549319607
Validation loss: 2.2770943521371643

Epoch: 6| Step: 10
Training loss: 0.609720621152768
Validation loss: 2.318230305254127

Epoch: 6| Step: 11
Training loss: 1.0630886466815104
Validation loss: 2.23758099028367

Epoch: 6| Step: 12
Training loss: 1.048945642348452
Validation loss: 2.2396802552626385

Epoch: 6| Step: 13
Training loss: 1.1851431396402978
Validation loss: 2.2708371811429906

Epoch: 501| Step: 0
Training loss: 0.7192618164852674
Validation loss: 2.2756512036348857

Epoch: 6| Step: 1
Training loss: 0.8503584092100385
Validation loss: 2.2664675426363825

Epoch: 6| Step: 2
Training loss: 0.9807101556627287
Validation loss: 2.324584796442313

Epoch: 6| Step: 3
Training loss: 1.009814085987298
Validation loss: 2.287951463994862

Epoch: 6| Step: 4
Training loss: 1.985108728001392
Validation loss: 2.301235498505185

Epoch: 6| Step: 5
Training loss: 0.8416944118370905
Validation loss: 2.2559279669835086

Epoch: 6| Step: 6
Training loss: 1.015386465377723
Validation loss: 2.3299734636042304

Epoch: 6| Step: 7
Training loss: 0.8147005213145728
Validation loss: 2.3199424433366667

Epoch: 6| Step: 8
Training loss: 0.7260864503057235
Validation loss: 2.285085701447238

Epoch: 6| Step: 9
Training loss: 0.7001941207386128
Validation loss: 2.2712437835553567

Epoch: 6| Step: 10
Training loss: 0.7565441725920621
Validation loss: 2.2057844076302313

Epoch: 6| Step: 11
Training loss: 1.0858185517736347
Validation loss: 2.1893512246598665

Epoch: 6| Step: 12
Training loss: 0.9446475314746559
Validation loss: 2.325761409967841

Epoch: 6| Step: 13
Training loss: 0.8411898094625675
Validation loss: 2.3335552652974787

Epoch: 502| Step: 0
Training loss: 0.7493485959756717
Validation loss: 2.1991468516278334

Epoch: 6| Step: 1
Training loss: 0.5183024969567415
Validation loss: 2.323736971809965

Epoch: 6| Step: 2
Training loss: 1.9624499077690951
Validation loss: 2.281407164159155

Epoch: 6| Step: 3
Training loss: 0.8223685881965869
Validation loss: 2.2764181935713625

Epoch: 6| Step: 4
Training loss: 0.9064562332688938
Validation loss: 2.265549862372056

Epoch: 6| Step: 5
Training loss: 0.6210559377616315
Validation loss: 2.346132495210479

Epoch: 6| Step: 6
Training loss: 0.5601941105219426
Validation loss: 2.3273732183597984

Epoch: 6| Step: 7
Training loss: 1.0669499502911988
Validation loss: 2.3924404572288482

Epoch: 6| Step: 8
Training loss: 0.8766032925122044
Validation loss: 2.3478555162560752

Epoch: 6| Step: 9
Training loss: 0.9801229345812914
Validation loss: 2.2802183319155755

Epoch: 6| Step: 10
Training loss: 0.6740282286808352
Validation loss: 2.2971230381968373

Epoch: 6| Step: 11
Training loss: 0.5998396043169666
Validation loss: 2.290916706847202

Epoch: 6| Step: 12
Training loss: 1.197165803964134
Validation loss: 2.291521357705303

Epoch: 6| Step: 13
Training loss: 0.733883388813761
Validation loss: 2.3335063450113114

Epoch: 503| Step: 0
Training loss: 0.6565115271294985
Validation loss: 2.2590685697028494

Epoch: 6| Step: 1
Training loss: 0.8547772613199148
Validation loss: 2.3509338392199

Epoch: 6| Step: 2
Training loss: 1.1472705959151333
Validation loss: 2.3083444921658356

Epoch: 6| Step: 3
Training loss: 0.8802729174754399
Validation loss: 2.2726955152345587

Epoch: 6| Step: 4
Training loss: 0.615947588523952
Validation loss: 2.2808362040767154

Epoch: 6| Step: 5
Training loss: 0.954944437417852
Validation loss: 2.227800240472164

Epoch: 6| Step: 6
Training loss: 1.011290116993818
Validation loss: 2.3805820385965712

Epoch: 6| Step: 7
Training loss: 1.1590489198861582
Validation loss: 2.21036330444147

Epoch: 6| Step: 8
Training loss: 0.9303244324297872
Validation loss: 2.2940836543473786

Epoch: 6| Step: 9
Training loss: 0.9966960208189154
Validation loss: 2.2278213290128104

Epoch: 6| Step: 10
Training loss: 0.889049374394663
Validation loss: 2.2386707958454357

Epoch: 6| Step: 11
Training loss: 0.7194211977153143
Validation loss: 2.2580738003711307

Epoch: 6| Step: 12
Training loss: 0.8692563097825996
Validation loss: 2.3080359665609733

Epoch: 6| Step: 13
Training loss: 2.431898674811675
Validation loss: 2.2280528905212504

Epoch: 504| Step: 0
Training loss: 1.962776507196568
Validation loss: 2.3230740426594156

Epoch: 6| Step: 1
Training loss: 0.6993253402874414
Validation loss: 2.2925806327967146

Epoch: 6| Step: 2
Training loss: 0.7700815314935165
Validation loss: 2.2729411796874497

Epoch: 6| Step: 3
Training loss: 0.9466277816391075
Validation loss: 2.195761840036901

Epoch: 6| Step: 4
Training loss: 0.9922903413114333
Validation loss: 2.284307441729759

Epoch: 6| Step: 5
Training loss: 0.7988007407869315
Validation loss: 2.319192081569043

Epoch: 6| Step: 6
Training loss: 0.741676516056739
Validation loss: 2.425952378708687

Epoch: 6| Step: 7
Training loss: 0.6650516323968677
Validation loss: 2.299310399407302

Epoch: 6| Step: 8
Training loss: 0.9932845951184216
Validation loss: 2.3014582777127788

Epoch: 6| Step: 9
Training loss: 0.8952093760699108
Validation loss: 2.285445833679548

Epoch: 6| Step: 10
Training loss: 0.9055837615781374
Validation loss: 2.249985950066055

Epoch: 6| Step: 11
Training loss: 1.2086708759340472
Validation loss: 2.3048305872372463

Epoch: 6| Step: 12
Training loss: 0.8078840153985136
Validation loss: 2.2570700307654485

Epoch: 6| Step: 13
Training loss: 0.9442058106703194
Validation loss: 2.223971607452691

Epoch: 505| Step: 0
Training loss: 0.8842253730284559
Validation loss: 2.244889731261717

Epoch: 6| Step: 1
Training loss: 0.9781600397433323
Validation loss: 2.3017394905475417

Epoch: 6| Step: 2
Training loss: 0.7180189478347825
Validation loss: 2.358230788203365

Epoch: 6| Step: 3
Training loss: 0.7777135534866648
Validation loss: 2.2241590808458156

Epoch: 6| Step: 4
Training loss: 0.9068914971142618
Validation loss: 2.318046080833234

Epoch: 6| Step: 5
Training loss: 0.8655397724377019
Validation loss: 2.2880194826980365

Epoch: 6| Step: 6
Training loss: 0.7696358082024615
Validation loss: 2.234035044712334

Epoch: 6| Step: 7
Training loss: 0.7783682125194423
Validation loss: 2.1955226826333867

Epoch: 6| Step: 8
Training loss: 0.880937932269101
Validation loss: 2.309496246054221

Epoch: 6| Step: 9
Training loss: 1.0898289286381575
Validation loss: 2.2754597768460116

Epoch: 6| Step: 10
Training loss: 0.6603121150277889
Validation loss: 2.206720333285417

Epoch: 6| Step: 11
Training loss: 0.7804587744456214
Validation loss: 2.296294994005536

Epoch: 6| Step: 12
Training loss: 1.8209358425077191
Validation loss: 2.2974912893568082

Epoch: 6| Step: 13
Training loss: 0.6773090182048831
Validation loss: 2.2647627794153395

Epoch: 506| Step: 0
Training loss: 0.8446953740178083
Validation loss: 2.296655487739283

Epoch: 6| Step: 1
Training loss: 0.9985396629921983
Validation loss: 2.236655834300079

Epoch: 6| Step: 2
Training loss: 1.1378730078504493
Validation loss: 2.346135768965052

Epoch: 6| Step: 3
Training loss: 0.9174810534399747
Validation loss: 2.282542028153965

Epoch: 6| Step: 4
Training loss: 0.8460243443194663
Validation loss: 2.226647919946875

Epoch: 6| Step: 5
Training loss: 0.7714326865348856
Validation loss: 2.295613389759509

Epoch: 6| Step: 6
Training loss: 0.8559345040019966
Validation loss: 2.182734363162831

Epoch: 6| Step: 7
Training loss: 0.6428558769667742
Validation loss: 2.2474334507939484

Epoch: 6| Step: 8
Training loss: 0.7261147298587298
Validation loss: 2.2000439587263068

Epoch: 6| Step: 9
Training loss: 0.9139699644541813
Validation loss: 2.2138613929001245

Epoch: 6| Step: 10
Training loss: 0.8535462118643394
Validation loss: 2.3114640532630144

Epoch: 6| Step: 11
Training loss: 2.0152114325598496
Validation loss: 2.200591391747523

Epoch: 6| Step: 12
Training loss: 0.727714527656001
Validation loss: 2.2316828161010935

Epoch: 6| Step: 13
Training loss: 0.7845050901462999
Validation loss: 2.3193529949500094

Epoch: 507| Step: 0
Training loss: 0.8922996837948439
Validation loss: 2.2445895626487014

Epoch: 6| Step: 1
Training loss: 1.2348699905134808
Validation loss: 2.277258913391316

Epoch: 6| Step: 2
Training loss: 0.7819526945401273
Validation loss: 2.1873285246879584

Epoch: 6| Step: 3
Training loss: 0.6556801365304444
Validation loss: 2.3985264991333577

Epoch: 6| Step: 4
Training loss: 0.8285607684910743
Validation loss: 2.325284706517614

Epoch: 6| Step: 5
Training loss: 0.9730952241295268
Validation loss: 2.2195761940660725

Epoch: 6| Step: 6
Training loss: 0.8818117056017117
Validation loss: 2.2853219347259457

Epoch: 6| Step: 7
Training loss: 1.0823718474827144
Validation loss: 2.20009709255368

Epoch: 6| Step: 8
Training loss: 0.6986910997518625
Validation loss: 2.244016685773593

Epoch: 6| Step: 9
Training loss: 0.7728086284659251
Validation loss: 2.278458930206774

Epoch: 6| Step: 10
Training loss: 1.0936222546772232
Validation loss: 2.218523290370112

Epoch: 6| Step: 11
Training loss: 0.6715464564945884
Validation loss: 2.2274998250421945

Epoch: 6| Step: 12
Training loss: 1.8327320442199522
Validation loss: 2.2602453173009693

Epoch: 6| Step: 13
Training loss: 0.500504566951117
Validation loss: 2.2538668095765977

Epoch: 508| Step: 0
Training loss: 0.7408819662236126
Validation loss: 2.241554161945107

Epoch: 6| Step: 1
Training loss: 0.8047920085113955
Validation loss: 2.24044982639126

Epoch: 6| Step: 2
Training loss: 0.9760435632926783
Validation loss: 2.212947381655723

Epoch: 6| Step: 3
Training loss: 0.7633776475989448
Validation loss: 2.2143055436855192

Epoch: 6| Step: 4
Training loss: 0.7971158879025327
Validation loss: 2.332419697441683

Epoch: 6| Step: 5
Training loss: 1.0014710335468147
Validation loss: 2.2305868098989285

Epoch: 6| Step: 6
Training loss: 0.9813072904639599
Validation loss: 2.2402527797095404

Epoch: 6| Step: 7
Training loss: 0.7511751584493574
Validation loss: 2.273463662445261

Epoch: 6| Step: 8
Training loss: 0.8542261025443957
Validation loss: 2.2764882584705464

Epoch: 6| Step: 9
Training loss: 0.7257195782200264
Validation loss: 2.214668642751152

Epoch: 6| Step: 10
Training loss: 0.5668701902646022
Validation loss: 2.2864996539416356

Epoch: 6| Step: 11
Training loss: 0.5893678324112878
Validation loss: 2.1904981122605918

Epoch: 6| Step: 12
Training loss: 1.0363952131875613
Validation loss: 2.285281910196436

Epoch: 6| Step: 13
Training loss: 2.515456294687586
Validation loss: 2.307657141255832

Epoch: 509| Step: 0
Training loss: 0.9893575243391499
Validation loss: 2.2320989123353403

Epoch: 6| Step: 1
Training loss: 0.8460358984727948
Validation loss: 2.2387399648495507

Epoch: 6| Step: 2
Training loss: 0.8529271032505181
Validation loss: 2.2722679777666874

Epoch: 6| Step: 3
Training loss: 0.8307891313840147
Validation loss: 2.268216316191735

Epoch: 6| Step: 4
Training loss: 1.088948145025008
Validation loss: 2.2094085913592294

Epoch: 6| Step: 5
Training loss: 0.7753963518291547
Validation loss: 2.310581378614826

Epoch: 6| Step: 6
Training loss: 0.7561503005711451
Validation loss: 2.20083774518294

Epoch: 6| Step: 7
Training loss: 1.418606281143238
Validation loss: 2.2537147453554223

Epoch: 6| Step: 8
Training loss: 0.8958102082808913
Validation loss: 2.2974387459190115

Epoch: 6| Step: 9
Training loss: 0.4783171573034844
Validation loss: 2.2450891691661967

Epoch: 6| Step: 10
Training loss: 1.7968389092842934
Validation loss: 2.353355245734246

Epoch: 6| Step: 11
Training loss: 0.7952966205083358
Validation loss: 2.2828906536063442

Epoch: 6| Step: 12
Training loss: 0.6819132175102709
Validation loss: 2.2406241716714677

Epoch: 6| Step: 13
Training loss: 1.0008141064815292
Validation loss: 2.3324361173393067

Epoch: 510| Step: 0
Training loss: 1.045535925008509
Validation loss: 2.3543379943892995

Epoch: 6| Step: 1
Training loss: 0.5334508690614135
Validation loss: 2.31870837886131

Epoch: 6| Step: 2
Training loss: 0.7683243945740278
Validation loss: 2.38739716498921

Epoch: 6| Step: 3
Training loss: 0.9638960349917078
Validation loss: 2.303039326297823

Epoch: 6| Step: 4
Training loss: 0.9909689621996853
Validation loss: 2.266288273815538

Epoch: 6| Step: 5
Training loss: 0.5569742909290522
Validation loss: 2.167595474551935

Epoch: 6| Step: 6
Training loss: 1.9455633652798594
Validation loss: 2.22160007020875

Epoch: 6| Step: 7
Training loss: 1.1984334853601168
Validation loss: 2.2586414433327486

Epoch: 6| Step: 8
Training loss: 0.8184581323727081
Validation loss: 2.2631735920360114

Epoch: 6| Step: 9
Training loss: 0.9061355189658646
Validation loss: 2.274171601953724

Epoch: 6| Step: 10
Training loss: 0.7392857897767001
Validation loss: 2.210844482566246

Epoch: 6| Step: 11
Training loss: 0.9499885985041625
Validation loss: 2.3242927344398976

Epoch: 6| Step: 12
Training loss: 0.5382351815451342
Validation loss: 2.245582118389891

Epoch: 6| Step: 13
Training loss: 1.3075158989488533
Validation loss: 2.287820237815748

Epoch: 511| Step: 0
Training loss: 1.286842144791731
Validation loss: 2.24884550722038

Epoch: 6| Step: 1
Training loss: 0.49320899078878766
Validation loss: 2.3513659137949134

Epoch: 6| Step: 2
Training loss: 1.1060736521018397
Validation loss: 2.2804698354559014

Epoch: 6| Step: 3
Training loss: 0.7205682643845432
Validation loss: 2.3119539515804797

Epoch: 6| Step: 4
Training loss: 1.1126857838181665
Validation loss: 2.276373513346516

Epoch: 6| Step: 5
Training loss: 1.062764976221854
Validation loss: 2.2707614990806233

Epoch: 6| Step: 6
Training loss: 0.8881342005404114
Validation loss: 2.28972236809598

Epoch: 6| Step: 7
Training loss: 0.71068698535552
Validation loss: 2.27097121632282

Epoch: 6| Step: 8
Training loss: 0.720959666836916
Validation loss: 2.185813956036533

Epoch: 6| Step: 9
Training loss: 0.7622431588270969
Validation loss: 2.2904420367924962

Epoch: 6| Step: 10
Training loss: 1.8310233070227686
Validation loss: 2.260300055767459

Epoch: 6| Step: 11
Training loss: 0.8897975624965104
Validation loss: 2.292572090035407

Epoch: 6| Step: 12
Training loss: 0.6316886624085596
Validation loss: 2.3012053215185597

Epoch: 6| Step: 13
Training loss: 0.5089155102251247
Validation loss: 2.2203865618945953

Epoch: 512| Step: 0
Training loss: 1.7922742242292127
Validation loss: 2.3002147161256072

Epoch: 6| Step: 1
Training loss: 1.0183702193934967
Validation loss: 2.3539184519679797

Epoch: 6| Step: 2
Training loss: 0.8937285040557854
Validation loss: 2.262887173896125

Epoch: 6| Step: 3
Training loss: 0.6860022268843026
Validation loss: 2.285764388534281

Epoch: 6| Step: 4
Training loss: 0.7751733586015583
Validation loss: 2.2307160112600446

Epoch: 6| Step: 5
Training loss: 1.0490565557371108
Validation loss: 2.3191877903927183

Epoch: 6| Step: 6
Training loss: 0.7657869128858664
Validation loss: 2.2047280197749743

Epoch: 6| Step: 7
Training loss: 0.9241153843040301
Validation loss: 2.2556346914771894

Epoch: 6| Step: 8
Training loss: 1.0260663812181339
Validation loss: 2.316778675180018

Epoch: 6| Step: 9
Training loss: 0.7772039546536105
Validation loss: 2.2216688763971715

Epoch: 6| Step: 10
Training loss: 0.8556325398594284
Validation loss: 2.231663384948144

Epoch: 6| Step: 11
Training loss: 0.852614846198594
Validation loss: 2.2425052588737238

Epoch: 6| Step: 12
Training loss: 0.8984436698370011
Validation loss: 2.2995092518466236

Epoch: 6| Step: 13
Training loss: 0.6846613585349296
Validation loss: 2.266908233990746

Epoch: 513| Step: 0
Training loss: 1.1607589440610189
Validation loss: 2.2793788948404723

Epoch: 6| Step: 1
Training loss: 0.773583985916
Validation loss: 2.2947491916539566

Epoch: 6| Step: 2
Training loss: 0.8021138338177028
Validation loss: 2.350416278667582

Epoch: 6| Step: 3
Training loss: 1.6800980177169285
Validation loss: 2.299294952690463

Epoch: 6| Step: 4
Training loss: 0.95503986804689
Validation loss: 2.2974477331102174

Epoch: 6| Step: 5
Training loss: 0.9925263194286618
Validation loss: 2.2861302994693524

Epoch: 6| Step: 6
Training loss: 0.9283674469323785
Validation loss: 2.2743048274136566

Epoch: 6| Step: 7
Training loss: 0.5767019645916751
Validation loss: 2.2148884844714565

Epoch: 6| Step: 8
Training loss: 0.8336635571096033
Validation loss: 2.2215355732182203

Epoch: 6| Step: 9
Training loss: 0.8177056808590643
Validation loss: 2.3025195220283203

Epoch: 6| Step: 10
Training loss: 1.1352047095354982
Validation loss: 2.2763411575321135

Epoch: 6| Step: 11
Training loss: 1.0956990451022806
Validation loss: 2.2237126498391553

Epoch: 6| Step: 12
Training loss: 0.6576999133028933
Validation loss: 2.25134809390504

Epoch: 6| Step: 13
Training loss: 1.1053156123226697
Validation loss: 2.3068291959360074

Epoch: 514| Step: 0
Training loss: 1.0973742248309941
Validation loss: 2.229177315285655

Epoch: 6| Step: 1
Training loss: 0.835558475593978
Validation loss: 2.2872303537105814

Epoch: 6| Step: 2
Training loss: 1.1418552818328853
Validation loss: 2.282735796144534

Epoch: 6| Step: 3
Training loss: 0.6504438911139392
Validation loss: 2.305554356553903

Epoch: 6| Step: 4
Training loss: 0.5347230090373583
Validation loss: 2.267346328454076

Epoch: 6| Step: 5
Training loss: 0.6998825332309757
Validation loss: 2.2764818220179484

Epoch: 6| Step: 6
Training loss: 0.7261476870772025
Validation loss: 2.268981190028471

Epoch: 6| Step: 7
Training loss: 0.3748443598422281
Validation loss: 2.28820250409108

Epoch: 6| Step: 8
Training loss: 0.7654846997068129
Validation loss: 2.2282288026230797

Epoch: 6| Step: 9
Training loss: 0.6687649894531835
Validation loss: 2.2469326175915496

Epoch: 6| Step: 10
Training loss: 1.1316014623795003
Validation loss: 2.2671208044636613

Epoch: 6| Step: 11
Training loss: 1.8933366607694981
Validation loss: 2.206561480783211

Epoch: 6| Step: 12
Training loss: 1.0719729720736644
Validation loss: 2.3045742912985077

Epoch: 6| Step: 13
Training loss: 0.8826716487903342
Validation loss: 2.313641867933934

Epoch: 515| Step: 0
Training loss: 0.99863173337207
Validation loss: 2.310981682184745

Epoch: 6| Step: 1
Training loss: 0.7785991327236351
Validation loss: 2.2613063354563616

Epoch: 6| Step: 2
Training loss: 0.7307795714986504
Validation loss: 2.226361032268186

Epoch: 6| Step: 3
Training loss: 0.49354651700598406
Validation loss: 2.214988115645868

Epoch: 6| Step: 4
Training loss: 0.48173065705358836
Validation loss: 2.2326543223296076

Epoch: 6| Step: 5
Training loss: 1.9163796859623208
Validation loss: 2.3138740213471283

Epoch: 6| Step: 6
Training loss: 1.0575844432943315
Validation loss: 2.3106229253982713

Epoch: 6| Step: 7
Training loss: 0.9823743683569912
Validation loss: 2.2237738788128305

Epoch: 6| Step: 8
Training loss: 0.9613671621544511
Validation loss: 2.3278241411513885

Epoch: 6| Step: 9
Training loss: 0.6505044831745262
Validation loss: 2.2614585804328513

Epoch: 6| Step: 10
Training loss: 0.7624050863008265
Validation loss: 2.244215173164154

Epoch: 6| Step: 11
Training loss: 0.726054106012412
Validation loss: 2.305515585065806

Epoch: 6| Step: 12
Training loss: 1.0238164535026024
Validation loss: 2.29738385343626

Epoch: 6| Step: 13
Training loss: 1.1994113332583496
Validation loss: 2.3631640669712515

Epoch: 516| Step: 0
Training loss: 1.1582619972126391
Validation loss: 2.2718009712225635

Epoch: 6| Step: 1
Training loss: 0.7024199659771116
Validation loss: 2.289985948410159

Epoch: 6| Step: 2
Training loss: 0.662147408352344
Validation loss: 2.2690460571476216

Epoch: 6| Step: 3
Training loss: 0.8489912568867668
Validation loss: 2.293515657203623

Epoch: 6| Step: 4
Training loss: 1.795969925868647
Validation loss: 2.216585023070232

Epoch: 6| Step: 5
Training loss: 0.42561711638735417
Validation loss: 2.29350975365315

Epoch: 6| Step: 6
Training loss: 1.0945095149951494
Validation loss: 2.2948266944879876

Epoch: 6| Step: 7
Training loss: 1.068618547709913
Validation loss: 2.196158122360008

Epoch: 6| Step: 8
Training loss: 0.852602122837818
Validation loss: 2.254190541860994

Epoch: 6| Step: 9
Training loss: 0.7792799333533041
Validation loss: 2.317226508508833

Epoch: 6| Step: 10
Training loss: 0.6574694339188919
Validation loss: 2.2606236061747076

Epoch: 6| Step: 11
Training loss: 0.8336393191923466
Validation loss: 2.3147641831834567

Epoch: 6| Step: 12
Training loss: 0.9740688376882919
Validation loss: 2.3414911401053873

Epoch: 6| Step: 13
Training loss: 0.9561282822179445
Validation loss: 2.277538030600048

Epoch: 517| Step: 0
Training loss: 0.9621690131477709
Validation loss: 2.24138325628342

Epoch: 6| Step: 1
Training loss: 0.9909482410514038
Validation loss: 2.3272844289067027

Epoch: 6| Step: 2
Training loss: 0.9474005534239899
Validation loss: 2.345051499922102

Epoch: 6| Step: 3
Training loss: 0.5984047584441394
Validation loss: 2.3107456580178756

Epoch: 6| Step: 4
Training loss: 0.947053047789055
Validation loss: 2.2482926762733437

Epoch: 6| Step: 5
Training loss: 0.6436558182347241
Validation loss: 2.2870730415790774

Epoch: 6| Step: 6
Training loss: 0.7757555201509544
Validation loss: 2.332916799039787

Epoch: 6| Step: 7
Training loss: 0.8979684019710357
Validation loss: 2.290000555607356

Epoch: 6| Step: 8
Training loss: 0.475593018528041
Validation loss: 2.284304596739221

Epoch: 6| Step: 9
Training loss: 1.0107143527266333
Validation loss: 2.3165130161770815

Epoch: 6| Step: 10
Training loss: 1.7624052279267972
Validation loss: 2.2819138090850135

Epoch: 6| Step: 11
Training loss: 0.9685899540764804
Validation loss: 2.279058228660826

Epoch: 6| Step: 12
Training loss: 1.0909816038711888
Validation loss: 2.159912505064072

Epoch: 6| Step: 13
Training loss: 0.8145332205562146
Validation loss: 2.3116978393421164

Epoch: 518| Step: 0
Training loss: 0.8536737849787664
Validation loss: 2.3497184724202813

Epoch: 6| Step: 1
Training loss: 0.747398673305809
Validation loss: 2.2851297277961122

Epoch: 6| Step: 2
Training loss: 0.779814966213628
Validation loss: 2.294113719395605

Epoch: 6| Step: 3
Training loss: 1.071370402528207
Validation loss: 2.336090393473327

Epoch: 6| Step: 4
Training loss: 0.6032575530817573
Validation loss: 2.2849160468431267

Epoch: 6| Step: 5
Training loss: 1.859749315555291
Validation loss: 2.216455911154332

Epoch: 6| Step: 6
Training loss: 0.7404713918039495
Validation loss: 2.30387163913863

Epoch: 6| Step: 7
Training loss: 1.2983807933557296
Validation loss: 2.2631098856480176

Epoch: 6| Step: 8
Training loss: 0.9934700913556547
Validation loss: 2.2591651463781983

Epoch: 6| Step: 9
Training loss: 0.7446622847283284
Validation loss: 2.2561815180717053

Epoch: 6| Step: 10
Training loss: 0.8864058560095331
Validation loss: 2.3030587919638346

Epoch: 6| Step: 11
Training loss: 0.7246394395374995
Validation loss: 2.196265056497168

Epoch: 6| Step: 12
Training loss: 0.6261660189482678
Validation loss: 2.2995584369011657

Epoch: 6| Step: 13
Training loss: 0.569056133002118
Validation loss: 2.2791900684255872

Epoch: 519| Step: 0
Training loss: 0.5668712417326546
Validation loss: 2.2563876787713766

Epoch: 6| Step: 1
Training loss: 0.72888571003945
Validation loss: 2.2712760054289514

Epoch: 6| Step: 2
Training loss: 0.7712195992313051
Validation loss: 2.2935596340685915

Epoch: 6| Step: 3
Training loss: 1.791326963763784
Validation loss: 2.2852555072418217

Epoch: 6| Step: 4
Training loss: 0.9544626448781715
Validation loss: 2.2339263965927674

Epoch: 6| Step: 5
Training loss: 0.9322649065719978
Validation loss: 2.248789670269017

Epoch: 6| Step: 6
Training loss: 0.9507624001307479
Validation loss: 2.2962540761145447

Epoch: 6| Step: 7
Training loss: 0.8414861897895333
Validation loss: 2.295744410566112

Epoch: 6| Step: 8
Training loss: 0.9144884404953023
Validation loss: 2.278977218696714

Epoch: 6| Step: 9
Training loss: 0.5849045613272604
Validation loss: 2.2403528866429037

Epoch: 6| Step: 10
Training loss: 0.8398692992116694
Validation loss: 2.250151071980023

Epoch: 6| Step: 11
Training loss: 0.9404041132316542
Validation loss: 2.322353715489418

Epoch: 6| Step: 12
Training loss: 0.631107860085385
Validation loss: 2.2893625065813628

Epoch: 6| Step: 13
Training loss: 0.42271882896622825
Validation loss: 2.2700385155002625

Epoch: 520| Step: 0
Training loss: 0.8566170914909874
Validation loss: 2.249458022112343

Epoch: 6| Step: 1
Training loss: 0.6041844189984478
Validation loss: 2.318219211782305

Epoch: 6| Step: 2
Training loss: 0.7580293954569512
Validation loss: 2.216511333160208

Epoch: 6| Step: 3
Training loss: 1.0468740890271222
Validation loss: 2.2300654356057334

Epoch: 6| Step: 4
Training loss: 1.0519911596630245
Validation loss: 2.228820102982268

Epoch: 6| Step: 5
Training loss: 1.1157297079919386
Validation loss: 2.3290170536715866

Epoch: 6| Step: 6
Training loss: 0.8837286322572057
Validation loss: 2.227848336690771

Epoch: 6| Step: 7
Training loss: 0.9651151576534007
Validation loss: 2.2895313149501995

Epoch: 6| Step: 8
Training loss: 0.7307725162567383
Validation loss: 2.241855382502744

Epoch: 6| Step: 9
Training loss: 0.5480669383633736
Validation loss: 2.2069592916359393

Epoch: 6| Step: 10
Training loss: 0.6274743691183343
Validation loss: 2.2207672207728426

Epoch: 6| Step: 11
Training loss: 1.8690221224761947
Validation loss: 2.2765915522895463

Epoch: 6| Step: 12
Training loss: 0.7686346804954837
Validation loss: 2.2796607264127795

Epoch: 6| Step: 13
Training loss: 0.7201547164387513
Validation loss: 2.2343112091130406

Epoch: 521| Step: 0
Training loss: 0.8009309954310287
Validation loss: 2.3053173369061297

Epoch: 6| Step: 1
Training loss: 0.4982294533364712
Validation loss: 2.2200821640136645

Epoch: 6| Step: 2
Training loss: 1.035415041261519
Validation loss: 2.2233455980342702

Epoch: 6| Step: 3
Training loss: 0.7317604842534542
Validation loss: 2.227323388637462

Epoch: 6| Step: 4
Training loss: 0.9429216020707514
Validation loss: 2.1912223740675927

Epoch: 6| Step: 5
Training loss: 0.5042116880675934
Validation loss: 2.2075247194492063

Epoch: 6| Step: 6
Training loss: 0.8723331068272115
Validation loss: 2.2410901364806826

Epoch: 6| Step: 7
Training loss: 0.5095947680850019
Validation loss: 2.2788937872125294

Epoch: 6| Step: 8
Training loss: 0.8147278100661836
Validation loss: 2.233923257920842

Epoch: 6| Step: 9
Training loss: 0.774682939953788
Validation loss: 2.2746898397438016

Epoch: 6| Step: 10
Training loss: 0.6282423792239087
Validation loss: 2.2876505798093723

Epoch: 6| Step: 11
Training loss: 1.8848640376671
Validation loss: 2.2474454691455956

Epoch: 6| Step: 12
Training loss: 0.857819345582423
Validation loss: 2.304423083694012

Epoch: 6| Step: 13
Training loss: 0.7092796110305778
Validation loss: 2.268772056366384

Epoch: 522| Step: 0
Training loss: 0.7412071177669405
Validation loss: 2.260773364982335

Epoch: 6| Step: 1
Training loss: 1.134392419266222
Validation loss: 2.2314255713790105

Epoch: 6| Step: 2
Training loss: 1.8969494046194044
Validation loss: 2.3227886346950437

Epoch: 6| Step: 3
Training loss: 0.39119861448155724
Validation loss: 2.28841395634924

Epoch: 6| Step: 4
Training loss: 0.6179346318719017
Validation loss: 2.212130244083294

Epoch: 6| Step: 5
Training loss: 0.8785236797582613
Validation loss: 2.3220357469344153

Epoch: 6| Step: 6
Training loss: 0.7310372654487126
Validation loss: 2.2878583326283635

Epoch: 6| Step: 7
Training loss: 0.6196008890850542
Validation loss: 2.291144142728091

Epoch: 6| Step: 8
Training loss: 0.6635723998190095
Validation loss: 2.3077587594790714

Epoch: 6| Step: 9
Training loss: 0.9021334712754108
Validation loss: 2.257526746231744

Epoch: 6| Step: 10
Training loss: 0.8877083386093911
Validation loss: 2.2601723805245717

Epoch: 6| Step: 11
Training loss: 0.8773938539215396
Validation loss: 2.3090732908506433

Epoch: 6| Step: 12
Training loss: 0.8278738036736714
Validation loss: 2.3039937260767642

Epoch: 6| Step: 13
Training loss: 0.40352568119956533
Validation loss: 2.2998053150878506

Epoch: 523| Step: 0
Training loss: 0.8912628299169539
Validation loss: 2.2644713460697723

Epoch: 6| Step: 1
Training loss: 0.8237502226301017
Validation loss: 2.2930606916475553

Epoch: 6| Step: 2
Training loss: 0.85100011891455
Validation loss: 2.350266209118196

Epoch: 6| Step: 3
Training loss: 1.0195850343512056
Validation loss: 2.231432111944349

Epoch: 6| Step: 4
Training loss: 0.6716323014981904
Validation loss: 2.295957820689983

Epoch: 6| Step: 5
Training loss: 1.8171259284966048
Validation loss: 2.2801950004030167

Epoch: 6| Step: 6
Training loss: 0.8373659709894072
Validation loss: 2.247091317738994

Epoch: 6| Step: 7
Training loss: 0.6719984340394031
Validation loss: 2.30824799036904

Epoch: 6| Step: 8
Training loss: 0.8665867348331614
Validation loss: 2.2430007841359676

Epoch: 6| Step: 9
Training loss: 0.8934470189999448
Validation loss: 2.275747824868177

Epoch: 6| Step: 10
Training loss: 0.8329659526365096
Validation loss: 2.268796983331428

Epoch: 6| Step: 11
Training loss: 0.7512020174466587
Validation loss: 2.2433108385330156

Epoch: 6| Step: 12
Training loss: 0.7732990025293756
Validation loss: 2.240616763199861

Epoch: 6| Step: 13
Training loss: 0.9075744750199138
Validation loss: 2.287012081424235

Epoch: 524| Step: 0
Training loss: 0.7927985173046016
Validation loss: 2.264667029816698

Epoch: 6| Step: 1
Training loss: 0.9117745350537719
Validation loss: 2.2312368512107295

Epoch: 6| Step: 2
Training loss: 0.6776396055774409
Validation loss: 2.2445362616621756

Epoch: 6| Step: 3
Training loss: 1.1007142284124884
Validation loss: 2.3353972850715174

Epoch: 6| Step: 4
Training loss: 0.8800677952877684
Validation loss: 2.27289715579919

Epoch: 6| Step: 5
Training loss: 0.8207309926969689
Validation loss: 2.335648641225315

Epoch: 6| Step: 6
Training loss: 0.6886038804526323
Validation loss: 2.3032634314211102

Epoch: 6| Step: 7
Training loss: 1.7507906898608323
Validation loss: 2.2009204117019885

Epoch: 6| Step: 8
Training loss: 0.7192608634889408
Validation loss: 2.3638334877418243

Epoch: 6| Step: 9
Training loss: 0.9815015178927141
Validation loss: 2.3032402420815217

Epoch: 6| Step: 10
Training loss: 0.8950610195435615
Validation loss: 2.237017845157406

Epoch: 6| Step: 11
Training loss: 0.7096414594947106
Validation loss: 2.2346027188524116

Epoch: 6| Step: 12
Training loss: 0.642207122651444
Validation loss: 2.2762481418585434

Epoch: 6| Step: 13
Training loss: 1.1921791946301823
Validation loss: 2.202769556625766

Epoch: 525| Step: 0
Training loss: 0.7522648549132902
Validation loss: 2.244184048377286

Epoch: 6| Step: 1
Training loss: 0.7020668757025612
Validation loss: 2.268456609419399

Epoch: 6| Step: 2
Training loss: 0.944591688773466
Validation loss: 2.2740480954569278

Epoch: 6| Step: 3
Training loss: 1.9361114448438832
Validation loss: 2.3275449131565917

Epoch: 6| Step: 4
Training loss: 0.6643687720020311
Validation loss: 2.2723293605408577

Epoch: 6| Step: 5
Training loss: 0.673759169436536
Validation loss: 2.2645395996527053

Epoch: 6| Step: 6
Training loss: 0.806611510852844
Validation loss: 2.3029185569032267

Epoch: 6| Step: 7
Training loss: 1.1483137622008894
Validation loss: 2.2266568324930684

Epoch: 6| Step: 8
Training loss: 0.5708020343228333
Validation loss: 2.298029493582187

Epoch: 6| Step: 9
Training loss: 0.6568015142580738
Validation loss: 2.2051002144341796

Epoch: 6| Step: 10
Training loss: 0.8492213623792795
Validation loss: 2.2282861698219194

Epoch: 6| Step: 11
Training loss: 0.8234942537905173
Validation loss: 2.2546186430475124

Epoch: 6| Step: 12
Training loss: 0.9468641551186718
Validation loss: 2.1429409657230725

Epoch: 6| Step: 13
Training loss: 0.861266810857979
Validation loss: 2.2401465995177356

Epoch: 526| Step: 0
Training loss: 0.8277826141227518
Validation loss: 2.312052455343586

Epoch: 6| Step: 1
Training loss: 0.9401611071361764
Validation loss: 2.2772229519191303

Epoch: 6| Step: 2
Training loss: 0.7605900936846779
Validation loss: 2.3036573863435263

Epoch: 6| Step: 3
Training loss: 1.0063771517011226
Validation loss: 2.299508518265837

Epoch: 6| Step: 4
Training loss: 0.7564714501610437
Validation loss: 2.3033867036515856

Epoch: 6| Step: 5
Training loss: 0.628267022583454
Validation loss: 2.2752060783451054

Epoch: 6| Step: 6
Training loss: 0.803633620111038
Validation loss: 2.3158888625771805

Epoch: 6| Step: 7
Training loss: 0.6345145800142589
Validation loss: 2.2864497170552363

Epoch: 6| Step: 8
Training loss: 1.8393275352728615
Validation loss: 2.4133907915087667

Epoch: 6| Step: 9
Training loss: 0.8315716400848359
Validation loss: 2.2205992610426977

Epoch: 6| Step: 10
Training loss: 0.8502062925878061
Validation loss: 2.2062631919875693

Epoch: 6| Step: 11
Training loss: 0.6994330647818545
Validation loss: 2.2534802550486335

Epoch: 6| Step: 12
Training loss: 0.9001850547214364
Validation loss: 2.320150004586248

Epoch: 6| Step: 13
Training loss: 1.0601839178603099
Validation loss: 2.256945702295029

Epoch: 527| Step: 0
Training loss: 0.901264023585742
Validation loss: 2.209507421903161

Epoch: 6| Step: 1
Training loss: 0.7698179379025144
Validation loss: 2.2817306686433114

Epoch: 6| Step: 2
Training loss: 0.996308337266148
Validation loss: 2.284781741338346

Epoch: 6| Step: 3
Training loss: 0.7246341752489253
Validation loss: 2.2157801987829595

Epoch: 6| Step: 4
Training loss: 0.5716803360112002
Validation loss: 2.207211182251171

Epoch: 6| Step: 5
Training loss: 0.8162937360557563
Validation loss: 2.348206493459248

Epoch: 6| Step: 6
Training loss: 0.6843421544941716
Validation loss: 2.286583206482208

Epoch: 6| Step: 7
Training loss: 0.7277776749281613
Validation loss: 2.2492255857301564

Epoch: 6| Step: 8
Training loss: 0.6288109938233141
Validation loss: 2.246495307170844

Epoch: 6| Step: 9
Training loss: 1.889913188514933
Validation loss: 2.2779294237452152

Epoch: 6| Step: 10
Training loss: 0.7994565473871146
Validation loss: 2.2908287347325538

Epoch: 6| Step: 11
Training loss: 1.1684747830870494
Validation loss: 2.2251166798516318

Epoch: 6| Step: 12
Training loss: 0.722904224636806
Validation loss: 2.287077895185399

Epoch: 6| Step: 13
Training loss: 0.2358689931858701
Validation loss: 2.340996339988683

Epoch: 528| Step: 0
Training loss: 0.743785422948156
Validation loss: 2.216854318020257

Epoch: 6| Step: 1
Training loss: 1.9104874836627257
Validation loss: 2.2162208649021395

Epoch: 6| Step: 2
Training loss: 0.7933016674817168
Validation loss: 2.280927635585275

Epoch: 6| Step: 3
Training loss: 0.7816585998146016
Validation loss: 2.2056436982805856

Epoch: 6| Step: 4
Training loss: 0.6159047425499523
Validation loss: 2.2237703949477923

Epoch: 6| Step: 5
Training loss: 0.9956766489429101
Validation loss: 2.1879935017017376

Epoch: 6| Step: 6
Training loss: 0.6983604064312445
Validation loss: 2.2780344213054007

Epoch: 6| Step: 7
Training loss: 0.7488073960023571
Validation loss: 2.2647267598840815

Epoch: 6| Step: 8
Training loss: 0.6464412478902883
Validation loss: 2.270054328999778

Epoch: 6| Step: 9
Training loss: 0.9480380654760724
Validation loss: 2.233172291989118

Epoch: 6| Step: 10
Training loss: 0.7562624228852172
Validation loss: 2.3079585596283643

Epoch: 6| Step: 11
Training loss: 0.8732331011185731
Validation loss: 2.267550297143883

Epoch: 6| Step: 12
Training loss: 0.9407071885609732
Validation loss: 2.303905857715832

Epoch: 6| Step: 13
Training loss: 1.1023481016120478
Validation loss: 2.297602248382988

Epoch: 529| Step: 0
Training loss: 0.698233779109665
Validation loss: 2.257594680029867

Epoch: 6| Step: 1
Training loss: 0.9210759595555511
Validation loss: 2.2182133626628535

Epoch: 6| Step: 2
Training loss: 0.610994778262737
Validation loss: 2.352567966413895

Epoch: 6| Step: 3
Training loss: 1.8335493422901912
Validation loss: 2.2962046477856872

Epoch: 6| Step: 4
Training loss: 0.7828965954714228
Validation loss: 2.3732034432816156

Epoch: 6| Step: 5
Training loss: 0.6940089661736327
Validation loss: 2.2041172890263816

Epoch: 6| Step: 6
Training loss: 1.020676068758708
Validation loss: 2.172589287077337

Epoch: 6| Step: 7
Training loss: 0.8881940626101004
Validation loss: 2.2678673334816812

Epoch: 6| Step: 8
Training loss: 1.035874143018031
Validation loss: 2.275107208068892

Epoch: 6| Step: 9
Training loss: 0.6936468898339128
Validation loss: 2.208887679195229

Epoch: 6| Step: 10
Training loss: 0.715626480900594
Validation loss: 2.2737344217311617

Epoch: 6| Step: 11
Training loss: 0.9615083565033923
Validation loss: 2.2477858392297314

Epoch: 6| Step: 12
Training loss: 0.5869398571572728
Validation loss: 2.2279942116166107

Epoch: 6| Step: 13
Training loss: 0.9647578768797832
Validation loss: 2.280373863985781

Epoch: 530| Step: 0
Training loss: 0.5193814800331028
Validation loss: 2.3163162150587353

Epoch: 6| Step: 1
Training loss: 0.7577693179697147
Validation loss: 2.319286275421553

Epoch: 6| Step: 2
Training loss: 0.6106215711358747
Validation loss: 2.2953072575209865

Epoch: 6| Step: 3
Training loss: 0.9037177783714566
Validation loss: 2.268768013335996

Epoch: 6| Step: 4
Training loss: 1.048130990035718
Validation loss: 2.2854645047079507

Epoch: 6| Step: 5
Training loss: 1.0133463607021798
Validation loss: 2.3493051565973655

Epoch: 6| Step: 6
Training loss: 0.960976545579559
Validation loss: 2.293683900607492

Epoch: 6| Step: 7
Training loss: 0.9551755703320459
Validation loss: 2.306303760337607

Epoch: 6| Step: 8
Training loss: 1.0108852414239389
Validation loss: 2.1841976993224805

Epoch: 6| Step: 9
Training loss: 1.92445033511674
Validation loss: 2.2536495376261807

Epoch: 6| Step: 10
Training loss: 0.8042066674504199
Validation loss: 2.2781574337378983

Epoch: 6| Step: 11
Training loss: 0.6839127368545282
Validation loss: 2.238253094552392

Epoch: 6| Step: 12
Training loss: 0.745789350956769
Validation loss: 2.287460083783853

Epoch: 6| Step: 13
Training loss: 0.7965376644819852
Validation loss: 2.221341284782932

Epoch: 531| Step: 0
Training loss: 0.8422276220159739
Validation loss: 2.1935716561968888

Epoch: 6| Step: 1
Training loss: 1.7834180386946794
Validation loss: 2.273956843928803

Epoch: 6| Step: 2
Training loss: 0.8886589300868654
Validation loss: 2.2084318600680253

Epoch: 6| Step: 3
Training loss: 0.8414173376969737
Validation loss: 2.3381507039341067

Epoch: 6| Step: 4
Training loss: 0.6806014482330868
Validation loss: 2.322318625632095

Epoch: 6| Step: 5
Training loss: 0.6605684697587684
Validation loss: 2.2734349594042813

Epoch: 6| Step: 6
Training loss: 0.7747446439348026
Validation loss: 2.27299001197217

Epoch: 6| Step: 7
Training loss: 0.7857951131960484
Validation loss: 2.2205562527290743

Epoch: 6| Step: 8
Training loss: 0.8056417566159318
Validation loss: 2.216512695647147

Epoch: 6| Step: 9
Training loss: 0.9944159345754937
Validation loss: 2.259423204655312

Epoch: 6| Step: 10
Training loss: 0.9925365885180853
Validation loss: 2.3150712828079034

Epoch: 6| Step: 11
Training loss: 0.7341510755966881
Validation loss: 2.224307120763451

Epoch: 6| Step: 12
Training loss: 0.9681633434250658
Validation loss: 2.253614780633714

Epoch: 6| Step: 13
Training loss: 0.7159305919512085
Validation loss: 2.2005114413475595

Epoch: 532| Step: 0
Training loss: 0.7885046771774953
Validation loss: 2.2725410398128494

Epoch: 6| Step: 1
Training loss: 1.7150880122608942
Validation loss: 2.2735016082248696

Epoch: 6| Step: 2
Training loss: 0.7658255178269282
Validation loss: 2.218783972094609

Epoch: 6| Step: 3
Training loss: 0.7484425825292874
Validation loss: 2.3181201428395535

Epoch: 6| Step: 4
Training loss: 0.8626910302174854
Validation loss: 2.2939845455183483

Epoch: 6| Step: 5
Training loss: 0.7870088801822104
Validation loss: 2.2916776289542513

Epoch: 6| Step: 6
Training loss: 1.0743962921464896
Validation loss: 2.2683834529566034

Epoch: 6| Step: 7
Training loss: 0.7160359847467018
Validation loss: 2.3293350927831096

Epoch: 6| Step: 8
Training loss: 0.9126435049427886
Validation loss: 2.2534265666565623

Epoch: 6| Step: 9
Training loss: 1.12031629234534
Validation loss: 2.1673443111605804

Epoch: 6| Step: 10
Training loss: 0.5890785457945205
Validation loss: 2.27824967604422

Epoch: 6| Step: 11
Training loss: 0.9272003242883782
Validation loss: 2.2083651048352557

Epoch: 6| Step: 12
Training loss: 0.7524264344663553
Validation loss: 2.2965714047033736

Epoch: 6| Step: 13
Training loss: 0.8290657961334492
Validation loss: 2.2340197984673

Epoch: 533| Step: 0
Training loss: 0.7750472838836361
Validation loss: 2.125082393209488

Epoch: 6| Step: 1
Training loss: 0.9592296030412677
Validation loss: 2.25951339512725

Epoch: 6| Step: 2
Training loss: 0.8441064576132342
Validation loss: 2.1924953182336653

Epoch: 6| Step: 3
Training loss: 0.8151265386044214
Validation loss: 2.2178975723373475

Epoch: 6| Step: 4
Training loss: 0.7001270170436437
Validation loss: 2.2707420455708522

Epoch: 6| Step: 5
Training loss: 0.7580542424604779
Validation loss: 2.2139062502806923

Epoch: 6| Step: 6
Training loss: 0.6595667853923335
Validation loss: 2.26526924143546

Epoch: 6| Step: 7
Training loss: 1.0086451794360456
Validation loss: 2.269348481697027

Epoch: 6| Step: 8
Training loss: 0.7645442497041665
Validation loss: 2.275111276455738

Epoch: 6| Step: 9
Training loss: 0.5426262523159505
Validation loss: 2.185129020446441

Epoch: 6| Step: 10
Training loss: 0.7823200908090562
Validation loss: 2.3605881155383086

Epoch: 6| Step: 11
Training loss: 0.9619974632705584
Validation loss: 2.270888931197408

Epoch: 6| Step: 12
Training loss: 1.8978859685040563
Validation loss: 2.2589322822685634

Epoch: 6| Step: 13
Training loss: 0.676794362147727
Validation loss: 2.2676752903126656

Epoch: 534| Step: 0
Training loss: 0.731870642175902
Validation loss: 2.228201623236057

Epoch: 6| Step: 1
Training loss: 0.8772316810997732
Validation loss: 2.2519784498738926

Epoch: 6| Step: 2
Training loss: 0.9115629662900614
Validation loss: 2.209328196508865

Epoch: 6| Step: 3
Training loss: 0.675024170796001
Validation loss: 2.230550158606389

Epoch: 6| Step: 4
Training loss: 0.7237003928068138
Validation loss: 2.3090967205421045

Epoch: 6| Step: 5
Training loss: 0.6878679981225396
Validation loss: 2.244882640066347

Epoch: 6| Step: 6
Training loss: 0.6926381833305952
Validation loss: 2.2366883905465698

Epoch: 6| Step: 7
Training loss: 0.8674220549775563
Validation loss: 2.284744622482206

Epoch: 6| Step: 8
Training loss: 0.6310078826992294
Validation loss: 2.3237145483395145

Epoch: 6| Step: 9
Training loss: 1.85951751675706
Validation loss: 2.213716579719152

Epoch: 6| Step: 10
Training loss: 1.0260070691673842
Validation loss: 2.216296779594926

Epoch: 6| Step: 11
Training loss: 0.4697143648272941
Validation loss: 2.254530998897908

Epoch: 6| Step: 12
Training loss: 0.8686609208796963
Validation loss: 2.221346320385701

Epoch: 6| Step: 13
Training loss: 0.8562192716444815
Validation loss: 2.275715947941243

Epoch: 535| Step: 0
Training loss: 0.9234826891794184
Validation loss: 2.2619469127448544

Epoch: 6| Step: 1
Training loss: 1.0250628428849635
Validation loss: 2.3163981298939906

Epoch: 6| Step: 2
Training loss: 0.6210351112563177
Validation loss: 2.28694504164923

Epoch: 6| Step: 3
Training loss: 0.6578998036565921
Validation loss: 2.235093739847427

Epoch: 6| Step: 4
Training loss: 0.9868023931309597
Validation loss: 2.287308760261514

Epoch: 6| Step: 5
Training loss: 0.6095275687913544
Validation loss: 2.2505715588782813

Epoch: 6| Step: 6
Training loss: 0.6228425459210618
Validation loss: 2.2371220618550858

Epoch: 6| Step: 7
Training loss: 0.844089722234988
Validation loss: 2.2643232714190726

Epoch: 6| Step: 8
Training loss: 1.690035151956862
Validation loss: 2.2938890422443556

Epoch: 6| Step: 9
Training loss: 0.7395599433173227
Validation loss: 2.2027773193319726

Epoch: 6| Step: 10
Training loss: 0.9235936324936352
Validation loss: 2.318859688653419

Epoch: 6| Step: 11
Training loss: 0.9629258155195551
Validation loss: 2.266031364458959

Epoch: 6| Step: 12
Training loss: 0.7063826647362724
Validation loss: 2.241342068527046

Epoch: 6| Step: 13
Training loss: 0.6954130035800655
Validation loss: 2.234096098649936

Epoch: 536| Step: 0
Training loss: 0.5664440800102478
Validation loss: 2.2609709431594505

Epoch: 6| Step: 1
Training loss: 1.0089650032998723
Validation loss: 2.1706683546617525

Epoch: 6| Step: 2
Training loss: 0.7333011080062571
Validation loss: 2.2763645330492883

Epoch: 6| Step: 3
Training loss: 1.8318684389692537
Validation loss: 2.23904897081779

Epoch: 6| Step: 4
Training loss: 0.7871700291892603
Validation loss: 2.215171038432896

Epoch: 6| Step: 5
Training loss: 0.8634343766643683
Validation loss: 2.2888708804737927

Epoch: 6| Step: 6
Training loss: 0.8205521732970293
Validation loss: 2.177090515636716

Epoch: 6| Step: 7
Training loss: 0.8279927346030582
Validation loss: 2.2352141492528785

Epoch: 6| Step: 8
Training loss: 0.6014111811573726
Validation loss: 2.273375798693262

Epoch: 6| Step: 9
Training loss: 0.8518234343115597
Validation loss: 2.2622161465085164

Epoch: 6| Step: 10
Training loss: 0.8973752583812741
Validation loss: 2.198176977172793

Epoch: 6| Step: 11
Training loss: 0.9120661135099846
Validation loss: 2.276035715351944

Epoch: 6| Step: 12
Training loss: 0.8052607966246692
Validation loss: 2.334700015147489

Epoch: 6| Step: 13
Training loss: 0.6422460561819071
Validation loss: 2.257310714681819

Epoch: 537| Step: 0
Training loss: 1.0947688126046329
Validation loss: 2.229760248988651

Epoch: 6| Step: 1
Training loss: 0.6802709421160806
Validation loss: 2.2319174711055583

Epoch: 6| Step: 2
Training loss: 0.8976913007063344
Validation loss: 2.313778512469378

Epoch: 6| Step: 3
Training loss: 0.8275859445846898
Validation loss: 2.2368180904599715

Epoch: 6| Step: 4
Training loss: 0.6414775293031636
Validation loss: 2.257147077409689

Epoch: 6| Step: 5
Training loss: 0.7505752026685883
Validation loss: 2.2657044348336317

Epoch: 6| Step: 6
Training loss: 0.9129350343740004
Validation loss: 2.233311468937825

Epoch: 6| Step: 7
Training loss: 1.9887085700859737
Validation loss: 2.239289731018325

Epoch: 6| Step: 8
Training loss: 0.8641530463734173
Validation loss: 2.3077420301368354

Epoch: 6| Step: 9
Training loss: 0.6762795788400708
Validation loss: 2.2848233869874357

Epoch: 6| Step: 10
Training loss: 1.0604876928519107
Validation loss: 2.358179726405298

Epoch: 6| Step: 11
Training loss: 0.6615247142453934
Validation loss: 2.3184718851573662

Epoch: 6| Step: 12
Training loss: 1.09194994349909
Validation loss: 2.307040756146717

Epoch: 6| Step: 13
Training loss: 0.4957010562213267
Validation loss: 2.2411469891535436

Epoch: 538| Step: 0
Training loss: 1.80220051937517
Validation loss: 2.2193132061501215

Epoch: 6| Step: 1
Training loss: 0.9776703920662992
Validation loss: 2.3434704696606037

Epoch: 6| Step: 2
Training loss: 0.7654042996310958
Validation loss: 2.2989043673578404

Epoch: 6| Step: 3
Training loss: 0.994132590870348
Validation loss: 2.2714713879429684

Epoch: 6| Step: 4
Training loss: 0.6358115162820723
Validation loss: 2.252110440610147

Epoch: 6| Step: 5
Training loss: 0.5685325437405353
Validation loss: 2.2762199723047334

Epoch: 6| Step: 6
Training loss: 0.941291200564389
Validation loss: 2.2020832596091395

Epoch: 6| Step: 7
Training loss: 0.9981847619287916
Validation loss: 2.235188238741667

Epoch: 6| Step: 8
Training loss: 0.7782223590778937
Validation loss: 2.258100589267757

Epoch: 6| Step: 9
Training loss: 1.3168228350547042
Validation loss: 2.2548025768881264

Epoch: 6| Step: 10
Training loss: 0.6542129918317212
Validation loss: 2.347189716530606

Epoch: 6| Step: 11
Training loss: 0.7291867026346506
Validation loss: 2.2313502116081496

Epoch: 6| Step: 12
Training loss: 0.7643975519828782
Validation loss: 2.2618836506728

Epoch: 6| Step: 13
Training loss: 0.6687935093068509
Validation loss: 2.317292862519718

Epoch: 539| Step: 0
Training loss: 0.7734057872705633
Validation loss: 2.297806877310238

Epoch: 6| Step: 1
Training loss: 1.113125224640881
Validation loss: 2.267688894887799

Epoch: 6| Step: 2
Training loss: 0.7687559918425979
Validation loss: 2.25711597250434

Epoch: 6| Step: 3
Training loss: 0.717444021187861
Validation loss: 2.2765695653305453

Epoch: 6| Step: 4
Training loss: 0.7176868204806084
Validation loss: 2.2725092527128803

Epoch: 6| Step: 5
Training loss: 0.828800861299649
Validation loss: 2.2909746228881387

Epoch: 6| Step: 6
Training loss: 0.6646188537129791
Validation loss: 2.294720595658965

Epoch: 6| Step: 7
Training loss: 0.9426420971835325
Validation loss: 2.171963207513134

Epoch: 6| Step: 8
Training loss: 0.971574971292918
Validation loss: 2.2613884602512746

Epoch: 6| Step: 9
Training loss: 0.7816203193371888
Validation loss: 2.2542063988681966

Epoch: 6| Step: 10
Training loss: 0.7255907841516714
Validation loss: 2.292751350514938

Epoch: 6| Step: 11
Training loss: 0.6344149985646206
Validation loss: 2.285968936036198

Epoch: 6| Step: 12
Training loss: 1.7764716723196914
Validation loss: 2.1752581164927993

Epoch: 6| Step: 13
Training loss: 0.8453045405720032
Validation loss: 2.25354901002769

Epoch: 540| Step: 0
Training loss: 0.7624139205622428
Validation loss: 2.267139577784222

Epoch: 6| Step: 1
Training loss: 0.9182085089362184
Validation loss: 2.3096113985114366

Epoch: 6| Step: 2
Training loss: 0.6511362744572933
Validation loss: 2.261105322830631

Epoch: 6| Step: 3
Training loss: 1.7624930226072897
Validation loss: 2.275025568920619

Epoch: 6| Step: 4
Training loss: 0.8308675804145504
Validation loss: 2.249156616092676

Epoch: 6| Step: 5
Training loss: 0.3766393986610589
Validation loss: 2.2625426170619867

Epoch: 6| Step: 6
Training loss: 0.7047385457364168
Validation loss: 2.153557269390308

Epoch: 6| Step: 7
Training loss: 0.6499742887987153
Validation loss: 2.288160461702587

Epoch: 6| Step: 8
Training loss: 0.9373309300877063
Validation loss: 2.247597558023085

Epoch: 6| Step: 9
Training loss: 0.5286106292077387
Validation loss: 2.2764499671937632

Epoch: 6| Step: 10
Training loss: 0.7667112624286914
Validation loss: 2.2575190411928445

Epoch: 6| Step: 11
Training loss: 0.6770222905347733
Validation loss: 2.207774660656377

Epoch: 6| Step: 12
Training loss: 0.9289172211200468
Validation loss: 2.256614457189908

Epoch: 6| Step: 13
Training loss: 0.8160570118636233
Validation loss: 2.1965669806397723

Epoch: 541| Step: 0
Training loss: 0.6127170470118684
Validation loss: 2.251406352015167

Epoch: 6| Step: 1
Training loss: 1.7634807157789723
Validation loss: 2.2961520028914593

Epoch: 6| Step: 2
Training loss: 0.9074743813190523
Validation loss: 2.2193520951042447

Epoch: 6| Step: 3
Training loss: 0.8357403959543488
Validation loss: 2.3222561277894966

Epoch: 6| Step: 4
Training loss: 0.7118845908680227
Validation loss: 2.2606947525410677

Epoch: 6| Step: 5
Training loss: 0.8473980769757042
Validation loss: 2.26663121731681

Epoch: 6| Step: 6
Training loss: 0.6578127555212399
Validation loss: 2.2831855661739913

Epoch: 6| Step: 7
Training loss: 1.0049288399019114
Validation loss: 2.272172715936083

Epoch: 6| Step: 8
Training loss: 0.9659617506554015
Validation loss: 2.2716699851914526

Epoch: 6| Step: 9
Training loss: 0.8458234247714052
Validation loss: 2.2185019325974316

Epoch: 6| Step: 10
Training loss: 0.6699517023769979
Validation loss: 2.2504452796872267

Epoch: 6| Step: 11
Training loss: 0.543041937855973
Validation loss: 2.2022902571985856

Epoch: 6| Step: 12
Training loss: 0.6533112347119
Validation loss: 2.327935603602299

Epoch: 6| Step: 13
Training loss: 0.5298850532256576
Validation loss: 2.2120035934048925

Epoch: 542| Step: 0
Training loss: 0.5982383934645444
Validation loss: 2.2473488357183795

Epoch: 6| Step: 1
Training loss: 1.835984444525318
Validation loss: 2.2264441593473165

Epoch: 6| Step: 2
Training loss: 0.763509045190699
Validation loss: 2.245472100660676

Epoch: 6| Step: 3
Training loss: 0.7604309150371186
Validation loss: 2.234471353521038

Epoch: 6| Step: 4
Training loss: 0.7628366727644064
Validation loss: 2.2408217697389152

Epoch: 6| Step: 5
Training loss: 0.8526518966622392
Validation loss: 2.2981770530286316

Epoch: 6| Step: 6
Training loss: 0.5714201426310149
Validation loss: 2.263496491580562

Epoch: 6| Step: 7
Training loss: 0.8849140236466597
Validation loss: 2.2205825129172703

Epoch: 6| Step: 8
Training loss: 0.7474965593647953
Validation loss: 2.2384299576208564

Epoch: 6| Step: 9
Training loss: 1.0192037472928503
Validation loss: 2.2662367609018554

Epoch: 6| Step: 10
Training loss: 0.7625182040183373
Validation loss: 2.2480283961132588

Epoch: 6| Step: 11
Training loss: 0.866378957113867
Validation loss: 2.2110881996836587

Epoch: 6| Step: 12
Training loss: 0.7496896340012639
Validation loss: 2.2108409110714633

Epoch: 6| Step: 13
Training loss: 0.7297609133007279
Validation loss: 2.2002409466051556

Epoch: 543| Step: 0
Training loss: 0.8254025893059601
Validation loss: 2.3138510945680557

Epoch: 6| Step: 1
Training loss: 0.5920943214565553
Validation loss: 2.303888145661089

Epoch: 6| Step: 2
Training loss: 1.0425485057203743
Validation loss: 2.212622750127762

Epoch: 6| Step: 3
Training loss: 0.8785185234188236
Validation loss: 2.2375967140856754

Epoch: 6| Step: 4
Training loss: 0.5450536096961285
Validation loss: 2.2564404100905544

Epoch: 6| Step: 5
Training loss: 0.7457079863752004
Validation loss: 2.2645179170982224

Epoch: 6| Step: 6
Training loss: 1.0374019806301138
Validation loss: 2.21959637032901

Epoch: 6| Step: 7
Training loss: 0.6177355107916573
Validation loss: 2.253534184756747

Epoch: 6| Step: 8
Training loss: 0.7317428900292143
Validation loss: 2.2639134160758685

Epoch: 6| Step: 9
Training loss: 1.8960098631558018
Validation loss: 2.2525628305132974

Epoch: 6| Step: 10
Training loss: 0.7639424266742149
Validation loss: 2.251959500073743

Epoch: 6| Step: 11
Training loss: 0.9630126875757582
Validation loss: 2.212429339767918

Epoch: 6| Step: 12
Training loss: 0.7172729823544644
Validation loss: 2.2751489024917753

Epoch: 6| Step: 13
Training loss: 0.6729218289873108
Validation loss: 2.232846708717471

Epoch: 544| Step: 0
Training loss: 0.770034780212239
Validation loss: 2.202602356190777

Epoch: 6| Step: 1
Training loss: 0.8706297729317541
Validation loss: 2.2272981877220346

Epoch: 6| Step: 2
Training loss: 0.8141598253408453
Validation loss: 2.2874572359899368

Epoch: 6| Step: 3
Training loss: 0.6899152293169746
Validation loss: 2.254142387871553

Epoch: 6| Step: 4
Training loss: 0.7437143782091217
Validation loss: 2.243542267383716

Epoch: 6| Step: 5
Training loss: 0.5192549121167023
Validation loss: 2.2211137878687484

Epoch: 6| Step: 6
Training loss: 0.8674915227558265
Validation loss: 2.233978184616659

Epoch: 6| Step: 7
Training loss: 0.767475888187259
Validation loss: 2.2723869904921363

Epoch: 6| Step: 8
Training loss: 1.7579654881341393
Validation loss: 2.203964121887885

Epoch: 6| Step: 9
Training loss: 0.8398144384192725
Validation loss: 2.2888950990999564

Epoch: 6| Step: 10
Training loss: 0.8634858730377649
Validation loss: 2.2682521164263605

Epoch: 6| Step: 11
Training loss: 0.6479320164504833
Validation loss: 2.22848481529988

Epoch: 6| Step: 12
Training loss: 0.4746855686392052
Validation loss: 2.3129880058207033

Epoch: 6| Step: 13
Training loss: 0.9344659027483844
Validation loss: 2.1827729877162505

Epoch: 545| Step: 0
Training loss: 0.9446634633914728
Validation loss: 2.2052104943682247

Epoch: 6| Step: 1
Training loss: 1.815487602668527
Validation loss: 2.2430366690905057

Epoch: 6| Step: 2
Training loss: 0.5881195383091933
Validation loss: 2.1697570354792046

Epoch: 6| Step: 3
Training loss: 0.5610742513848025
Validation loss: 2.2910747196120305

Epoch: 6| Step: 4
Training loss: 0.8336037832727082
Validation loss: 2.1869366062397573

Epoch: 6| Step: 5
Training loss: 0.5366350888899548
Validation loss: 2.228215466807883

Epoch: 6| Step: 6
Training loss: 0.9096898533414897
Validation loss: 2.261463212977006

Epoch: 6| Step: 7
Training loss: 0.7760201692270505
Validation loss: 2.225899123407098

Epoch: 6| Step: 8
Training loss: 1.0895618908281473
Validation loss: 2.315151488232312

Epoch: 6| Step: 9
Training loss: 0.6857191124849796
Validation loss: 2.2379004960956683

Epoch: 6| Step: 10
Training loss: 0.6761087495018491
Validation loss: 2.3298499640642176

Epoch: 6| Step: 11
Training loss: 0.6295343425766612
Validation loss: 2.194731275322146

Epoch: 6| Step: 12
Training loss: 0.6903621743091947
Validation loss: 2.279894553243024

Epoch: 6| Step: 13
Training loss: 0.6662411573585448
Validation loss: 2.2148190086950437

Epoch: 546| Step: 0
Training loss: 0.9024416387396897
Validation loss: 2.258522868625037

Epoch: 6| Step: 1
Training loss: 1.8187606811209798
Validation loss: 2.178498355590703

Epoch: 6| Step: 2
Training loss: 0.46617124442058994
Validation loss: 2.3016397637868344

Epoch: 6| Step: 3
Training loss: 1.0689333641294754
Validation loss: 2.303483018464175

Epoch: 6| Step: 4
Training loss: 0.7420804398266261
Validation loss: 2.2346372834078383

Epoch: 6| Step: 5
Training loss: 0.8835287985973617
Validation loss: 2.3337432447066866

Epoch: 6| Step: 6
Training loss: 0.8408049295150244
Validation loss: 2.210085447926931

Epoch: 6| Step: 7
Training loss: 0.6701604346093317
Validation loss: 2.235960618282233

Epoch: 6| Step: 8
Training loss: 0.689074339299985
Validation loss: 2.2492219703192866

Epoch: 6| Step: 9
Training loss: 0.8248368246369834
Validation loss: 2.259793962796279

Epoch: 6| Step: 10
Training loss: 0.7320998641094347
Validation loss: 2.3584875936948

Epoch: 6| Step: 11
Training loss: 0.7897650735158652
Validation loss: 2.2758402587571167

Epoch: 6| Step: 12
Training loss: 0.7071210266778482
Validation loss: 2.2934481586456177

Epoch: 6| Step: 13
Training loss: 0.3255365774797735
Validation loss: 2.270365481026674

Epoch: 547| Step: 0
Training loss: 0.4706600375260215
Validation loss: 2.25057610447808

Epoch: 6| Step: 1
Training loss: 0.6468026567632198
Validation loss: 2.205327943600643

Epoch: 6| Step: 2
Training loss: 0.7126770535715163
Validation loss: 2.3117111909410033

Epoch: 6| Step: 3
Training loss: 0.5668422730744863
Validation loss: 2.3156118078731893

Epoch: 6| Step: 4
Training loss: 0.6233383023307062
Validation loss: 2.2525814264133506

Epoch: 6| Step: 5
Training loss: 1.8139988193949734
Validation loss: 2.2116843188128557

Epoch: 6| Step: 6
Training loss: 0.8351870938806589
Validation loss: 2.1464854594640363

Epoch: 6| Step: 7
Training loss: 0.7688592212901744
Validation loss: 2.2947262950005256

Epoch: 6| Step: 8
Training loss: 0.8222498948864683
Validation loss: 2.245996042545583

Epoch: 6| Step: 9
Training loss: 0.7024183324945775
Validation loss: 2.2763762725227727

Epoch: 6| Step: 10
Training loss: 0.9299252310301883
Validation loss: 2.171036948778225

Epoch: 6| Step: 11
Training loss: 0.7629254295586166
Validation loss: 2.246395010056762

Epoch: 6| Step: 12
Training loss: 0.9031374194601327
Validation loss: 2.278568470193884

Epoch: 6| Step: 13
Training loss: 1.160705949942032
Validation loss: 2.250491384858294

Epoch: 548| Step: 0
Training loss: 0.5894570504090064
Validation loss: 2.230067733329378

Epoch: 6| Step: 1
Training loss: 0.9164841354587026
Validation loss: 2.3058816031683427

Epoch: 6| Step: 2
Training loss: 0.8774704798327436
Validation loss: 2.2913104663310415

Epoch: 6| Step: 3
Training loss: 0.7911633012227376
Validation loss: 2.2747583950186745

Epoch: 6| Step: 4
Training loss: 1.9126149211588317
Validation loss: 2.352376405433542

Epoch: 6| Step: 5
Training loss: 0.5972673734211451
Validation loss: 2.2350050427091643

Epoch: 6| Step: 6
Training loss: 0.8337079914610945
Validation loss: 2.260330519138747

Epoch: 6| Step: 7
Training loss: 0.7599210212477615
Validation loss: 2.2129101294721325

Epoch: 6| Step: 8
Training loss: 0.6401576686896483
Validation loss: 2.2518821868568226

Epoch: 6| Step: 9
Training loss: 0.6079613844033926
Validation loss: 2.250541587648248

Epoch: 6| Step: 10
Training loss: 0.7734608887497988
Validation loss: 2.299188280655806

Epoch: 6| Step: 11
Training loss: 0.7394771678822496
Validation loss: 2.2424383524421714

Epoch: 6| Step: 12
Training loss: 0.8232279965228546
Validation loss: 2.2875788709524723

Epoch: 6| Step: 13
Training loss: 0.6578309452977443
Validation loss: 2.286756217800349

Epoch: 549| Step: 0
Training loss: 0.6558303853865035
Validation loss: 2.243613605762271

Epoch: 6| Step: 1
Training loss: 0.7654530857692533
Validation loss: 2.2827702172774105

Epoch: 6| Step: 2
Training loss: 0.9898848358756228
Validation loss: 2.297948092574848

Epoch: 6| Step: 3
Training loss: 0.6626583288043659
Validation loss: 2.2508527872655884

Epoch: 6| Step: 4
Training loss: 0.670896305264079
Validation loss: 2.2383593800275023

Epoch: 6| Step: 5
Training loss: 1.8111278338463128
Validation loss: 2.2586709206076234

Epoch: 6| Step: 6
Training loss: 0.5990847799648312
Validation loss: 2.2921622209421426

Epoch: 6| Step: 7
Training loss: 1.1658762684010793
Validation loss: 2.320860410404844

Epoch: 6| Step: 8
Training loss: 0.5458136750338228
Validation loss: 2.195952913718692

Epoch: 6| Step: 9
Training loss: 0.733865845485554
Validation loss: 2.171523989387304

Epoch: 6| Step: 10
Training loss: 1.0200630058201776
Validation loss: 2.2440496978706928

Epoch: 6| Step: 11
Training loss: 0.9498634190004629
Validation loss: 2.3069839385289677

Epoch: 6| Step: 12
Training loss: 0.9212912311411168
Validation loss: 2.246512629545331

Epoch: 6| Step: 13
Training loss: 0.9419922646956123
Validation loss: 2.3163920439460735

Epoch: 550| Step: 0
Training loss: 0.8355351130231479
Validation loss: 2.2924453966284952

Epoch: 6| Step: 1
Training loss: 0.6063092949962146
Validation loss: 2.223398573380194

Epoch: 6| Step: 2
Training loss: 1.8727566332085337
Validation loss: 2.234175677981991

Epoch: 6| Step: 3
Training loss: 0.6897271668020525
Validation loss: 2.2737031350202233

Epoch: 6| Step: 4
Training loss: 0.7755547645239028
Validation loss: 2.276041597207844

Epoch: 6| Step: 5
Training loss: 0.6045615999121834
Validation loss: 2.308991440914678

Epoch: 6| Step: 6
Training loss: 1.0146678228793615
Validation loss: 2.3440850284354546

Epoch: 6| Step: 7
Training loss: 0.6770482176453341
Validation loss: 2.1784021883344895

Epoch: 6| Step: 8
Training loss: 0.8364429550055728
Validation loss: 2.236769460464056

Epoch: 6| Step: 9
Training loss: 0.8814603865535021
Validation loss: 2.3291285757074243

Epoch: 6| Step: 10
Training loss: 0.7809861691357781
Validation loss: 2.2487185394177307

Epoch: 6| Step: 11
Training loss: 0.8148805516711154
Validation loss: 2.269461465658283

Epoch: 6| Step: 12
Training loss: 0.6248888632191735
Validation loss: 2.2674571633702305

Epoch: 6| Step: 13
Training loss: 0.9413748771536715
Validation loss: 2.243624627060658

Epoch: 551| Step: 0
Training loss: 1.786186538647444
Validation loss: 2.232784586105429

Epoch: 6| Step: 1
Training loss: 0.6661195198530885
Validation loss: 2.223908508377423

Epoch: 6| Step: 2
Training loss: 1.0294870855921117
Validation loss: 2.2765400157618836

Epoch: 6| Step: 3
Training loss: 0.6868516726086155
Validation loss: 2.209792105951007

Epoch: 6| Step: 4
Training loss: 0.7907861824236077
Validation loss: 2.211401685102079

Epoch: 6| Step: 5
Training loss: 0.41051634467199827
Validation loss: 2.212863067515317

Epoch: 6| Step: 6
Training loss: 0.7219095857600223
Validation loss: 2.303060095457408

Epoch: 6| Step: 7
Training loss: 0.6077265328066692
Validation loss: 2.2899599422636308

Epoch: 6| Step: 8
Training loss: 0.5331571230764112
Validation loss: 2.2821523657559184

Epoch: 6| Step: 9
Training loss: 0.8715942040028811
Validation loss: 2.251829172903611

Epoch: 6| Step: 10
Training loss: 0.8800663730126227
Validation loss: 2.2983068808399576

Epoch: 6| Step: 11
Training loss: 0.9962812359458899
Validation loss: 2.2987416757220567

Epoch: 6| Step: 12
Training loss: 0.5804217313101423
Validation loss: 2.1742186921529174

Epoch: 6| Step: 13
Training loss: 0.5263111318206489
Validation loss: 2.282320490359136

Epoch: 552| Step: 0
Training loss: 0.7339785703030597
Validation loss: 2.2807348852274156

Epoch: 6| Step: 1
Training loss: 0.6326165072374729
Validation loss: 2.202069771276561

Epoch: 6| Step: 2
Training loss: 0.5644460499461978
Validation loss: 2.2314818181209204

Epoch: 6| Step: 3
Training loss: 0.7276808632522854
Validation loss: 2.148417337123491

Epoch: 6| Step: 4
Training loss: 1.9232349701272682
Validation loss: 2.2272264660349608

Epoch: 6| Step: 5
Training loss: 0.5711582392694292
Validation loss: 2.2194995102351274

Epoch: 6| Step: 6
Training loss: 0.7203322699558236
Validation loss: 2.277592549315594

Epoch: 6| Step: 7
Training loss: 0.7132116979509346
Validation loss: 2.2654734638980685

Epoch: 6| Step: 8
Training loss: 0.73914500576423
Validation loss: 2.1937001715389206

Epoch: 6| Step: 9
Training loss: 0.9744500467641278
Validation loss: 2.213521036610508

Epoch: 6| Step: 10
Training loss: 0.8725940118655465
Validation loss: 2.270936321426777

Epoch: 6| Step: 11
Training loss: 0.6876697764142213
Validation loss: 2.2379608019401207

Epoch: 6| Step: 12
Training loss: 0.8605471160375783
Validation loss: 2.2086394770723783

Epoch: 6| Step: 13
Training loss: 0.8012071546861688
Validation loss: 2.247602962244444

Epoch: 553| Step: 0
Training loss: 0.5649298268601148
Validation loss: 2.1534129342930726

Epoch: 6| Step: 1
Training loss: 0.7989048256461303
Validation loss: 2.379344156904903

Epoch: 6| Step: 2
Training loss: 0.6551819465996455
Validation loss: 2.2785029979653872

Epoch: 6| Step: 3
Training loss: 0.47655224398223833
Validation loss: 2.2852056306717277

Epoch: 6| Step: 4
Training loss: 0.7497524409214645
Validation loss: 2.309304473686796

Epoch: 6| Step: 5
Training loss: 0.6514625307961863
Validation loss: 2.3239705447597503

Epoch: 6| Step: 6
Training loss: 0.6668414145166472
Validation loss: 2.2192474724957756

Epoch: 6| Step: 7
Training loss: 1.7793442419386392
Validation loss: 2.235486025777315

Epoch: 6| Step: 8
Training loss: 1.0703942483465196
Validation loss: 2.2268425069351503

Epoch: 6| Step: 9
Training loss: 0.6712101818684981
Validation loss: 2.1923591604271784

Epoch: 6| Step: 10
Training loss: 0.866087172481715
Validation loss: 2.2324223412371396

Epoch: 6| Step: 11
Training loss: 1.0856606109875018
Validation loss: 2.365977315266775

Epoch: 6| Step: 12
Training loss: 0.8733709702377637
Validation loss: 2.1891197770532265

Epoch: 6| Step: 13
Training loss: 0.5706731100368534
Validation loss: 2.210808430496694

Epoch: 554| Step: 0
Training loss: 0.9747173119597023
Validation loss: 2.260826563247853

Epoch: 6| Step: 1
Training loss: 0.5289183667371318
Validation loss: 2.342322692513548

Epoch: 6| Step: 2
Training loss: 1.2421985841652439
Validation loss: 2.2106693501914796

Epoch: 6| Step: 3
Training loss: 0.7245987636889388
Validation loss: 2.1943779450434295

Epoch: 6| Step: 4
Training loss: 0.8376036110170746
Validation loss: 2.257545626588773

Epoch: 6| Step: 5
Training loss: 0.4964615367135599
Validation loss: 2.237995791735742

Epoch: 6| Step: 6
Training loss: 0.5270663061394694
Validation loss: 2.253109822354334

Epoch: 6| Step: 7
Training loss: 0.759445789946479
Validation loss: 2.204106483666794

Epoch: 6| Step: 8
Training loss: 0.7831267131716659
Validation loss: 2.2330563118432467

Epoch: 6| Step: 9
Training loss: 1.8889322190207911
Validation loss: 2.3287688677620455

Epoch: 6| Step: 10
Training loss: 0.6415344388968849
Validation loss: 2.172278409780786

Epoch: 6| Step: 11
Training loss: 0.6122705672155776
Validation loss: 2.279378793616554

Epoch: 6| Step: 12
Training loss: 0.7365580637381071
Validation loss: 2.2341777296502627

Epoch: 6| Step: 13
Training loss: 0.6083792351253365
Validation loss: 2.2477765040689666

Epoch: 555| Step: 0
Training loss: 0.6246407668555376
Validation loss: 2.208620751178351

Epoch: 6| Step: 1
Training loss: 0.7902735867768151
Validation loss: 2.263103007303447

Epoch: 6| Step: 2
Training loss: 0.7640943992524308
Validation loss: 2.268802073777242

Epoch: 6| Step: 3
Training loss: 0.8273409244535933
Validation loss: 2.2086584541041803

Epoch: 6| Step: 4
Training loss: 0.5942729855185567
Validation loss: 2.203733444414123

Epoch: 6| Step: 5
Training loss: 0.5849344951276514
Validation loss: 2.256647743956372

Epoch: 6| Step: 6
Training loss: 0.6294506867707039
Validation loss: 2.2753549911636055

Epoch: 6| Step: 7
Training loss: 0.7022017881792769
Validation loss: 2.229801532257642

Epoch: 6| Step: 8
Training loss: 0.49625685406042513
Validation loss: 2.2573873394445845

Epoch: 6| Step: 9
Training loss: 0.6119906458217715
Validation loss: 2.187372636969393

Epoch: 6| Step: 10
Training loss: 1.9194231598307734
Validation loss: 2.2024874050034517

Epoch: 6| Step: 11
Training loss: 0.8021994337465566
Validation loss: 2.2189638241897907

Epoch: 6| Step: 12
Training loss: 0.9100625313244773
Validation loss: 2.3255434277109823

Epoch: 6| Step: 13
Training loss: 0.5671840457443267
Validation loss: 2.250647603772263

Epoch: 556| Step: 0
Training loss: 0.46572478332481726
Validation loss: 2.13605874645821

Epoch: 6| Step: 1
Training loss: 0.88947087514369
Validation loss: 2.2454106527404254

Epoch: 6| Step: 2
Training loss: 0.5881961269522239
Validation loss: 2.216076024281254

Epoch: 6| Step: 3
Training loss: 0.4742542869412321
Validation loss: 2.2464731266450086

Epoch: 6| Step: 4
Training loss: 1.7174742385509192
Validation loss: 2.2560023131425595

Epoch: 6| Step: 5
Training loss: 0.7276277424063198
Validation loss: 2.233825795085742

Epoch: 6| Step: 6
Training loss: 0.7949396454795415
Validation loss: 2.2806669300058378

Epoch: 6| Step: 7
Training loss: 0.5870656152636675
Validation loss: 2.240574720374645

Epoch: 6| Step: 8
Training loss: 0.6535889624872402
Validation loss: 2.200528257769716

Epoch: 6| Step: 9
Training loss: 0.7696552467170826
Validation loss: 2.24724743362546

Epoch: 6| Step: 10
Training loss: 0.949045016241074
Validation loss: 2.1802890038935185

Epoch: 6| Step: 11
Training loss: 0.7902716257816448
Validation loss: 2.184207659503666

Epoch: 6| Step: 12
Training loss: 0.7827640739279502
Validation loss: 2.1720229132654643

Epoch: 6| Step: 13
Training loss: 0.662254655141227
Validation loss: 2.250847332759657

Epoch: 557| Step: 0
Training loss: 0.9679162529232758
Validation loss: 2.1668150198657252

Epoch: 6| Step: 1
Training loss: 0.6396939094047185
Validation loss: 2.2972073722251882

Epoch: 6| Step: 2
Training loss: 1.784978077216922
Validation loss: 2.279080424456465

Epoch: 6| Step: 3
Training loss: 0.633016529864791
Validation loss: 2.1999363424370855

Epoch: 6| Step: 4
Training loss: 0.5467615009784936
Validation loss: 2.2274989204306985

Epoch: 6| Step: 5
Training loss: 0.7277491323845271
Validation loss: 2.192419690830689

Epoch: 6| Step: 6
Training loss: 0.46899970079627995
Validation loss: 2.1902685784200973

Epoch: 6| Step: 7
Training loss: 0.6889680231076424
Validation loss: 2.2506799559182395

Epoch: 6| Step: 8
Training loss: 0.776126886762088
Validation loss: 2.2173216267658056

Epoch: 6| Step: 9
Training loss: 0.6024800028984506
Validation loss: 2.1000344016269743

Epoch: 6| Step: 10
Training loss: 0.6507543514778885
Validation loss: 2.2329704734494125

Epoch: 6| Step: 11
Training loss: 0.71163411647439
Validation loss: 2.2898003422429434

Epoch: 6| Step: 12
Training loss: 0.8243114184312393
Validation loss: 2.2247108599749095

Epoch: 6| Step: 13
Training loss: 1.0811023236455903
Validation loss: 2.179547069570313

Epoch: 558| Step: 0
Training loss: 0.7384598934670308
Validation loss: 2.319888954125232

Epoch: 6| Step: 1
Training loss: 0.7800662036456649
Validation loss: 2.289670274503158

Epoch: 6| Step: 2
Training loss: 0.606653936256033
Validation loss: 2.2482328422724374

Epoch: 6| Step: 3
Training loss: 1.8310138016268602
Validation loss: 2.199451382136905

Epoch: 6| Step: 4
Training loss: 0.8957064708808596
Validation loss: 2.2676974381213233

Epoch: 6| Step: 5
Training loss: 0.7104438493139019
Validation loss: 2.205535340477602

Epoch: 6| Step: 6
Training loss: 0.636272484657484
Validation loss: 2.2137447750905173

Epoch: 6| Step: 7
Training loss: 0.46088359000258244
Validation loss: 2.3123588352635065

Epoch: 6| Step: 8
Training loss: 0.7002773689061353
Validation loss: 2.2361132911069053

Epoch: 6| Step: 9
Training loss: 0.6049332250047357
Validation loss: 2.2007786982643895

Epoch: 6| Step: 10
Training loss: 0.8461898213771764
Validation loss: 2.225303093094593

Epoch: 6| Step: 11
Training loss: 0.6408133811308409
Validation loss: 2.2259116925176565

Epoch: 6| Step: 12
Training loss: 0.9358004741952033
Validation loss: 2.2568631454814683

Epoch: 6| Step: 13
Training loss: 0.5483768005689351
Validation loss: 2.2534980494566583

Epoch: 559| Step: 0
Training loss: 0.7389873780990962
Validation loss: 2.218127553178761

Epoch: 6| Step: 1
Training loss: 0.694813924620687
Validation loss: 2.2602527839322675

Epoch: 6| Step: 2
Training loss: 0.5612505705900627
Validation loss: 2.233349458697158

Epoch: 6| Step: 3
Training loss: 1.062759199502415
Validation loss: 2.2551924405526362

Epoch: 6| Step: 4
Training loss: 0.8718867092645204
Validation loss: 2.282115796144192

Epoch: 6| Step: 5
Training loss: 0.6872324422908824
Validation loss: 2.2681572295930894

Epoch: 6| Step: 6
Training loss: 0.6956000430007843
Validation loss: 2.2318982148654007

Epoch: 6| Step: 7
Training loss: 1.6825822592999466
Validation loss: 2.250684643110749

Epoch: 6| Step: 8
Training loss: 0.6521276470113787
Validation loss: 2.316702965733605

Epoch: 6| Step: 9
Training loss: 0.5972445696954735
Validation loss: 2.3058888897845136

Epoch: 6| Step: 10
Training loss: 0.8644423810357564
Validation loss: 2.2462378465567907

Epoch: 6| Step: 11
Training loss: 0.5018423826608903
Validation loss: 2.2716768274396077

Epoch: 6| Step: 12
Training loss: 0.9290197843656166
Validation loss: 2.2175816948464355

Epoch: 6| Step: 13
Training loss: 0.9373576374045799
Validation loss: 2.301750060611955

Epoch: 560| Step: 0
Training loss: 0.8104074748939092
Validation loss: 2.26417788073531

Epoch: 6| Step: 1
Training loss: 0.578896677656223
Validation loss: 2.3190226558722

Epoch: 6| Step: 2
Training loss: 0.75585511672129
Validation loss: 2.225665831482056

Epoch: 6| Step: 3
Training loss: 0.6108411610541101
Validation loss: 2.2890907573401273

Epoch: 6| Step: 4
Training loss: 0.9188307590412806
Validation loss: 2.2032029129339636

Epoch: 6| Step: 5
Training loss: 0.7410738972870616
Validation loss: 2.2186251068898457

Epoch: 6| Step: 6
Training loss: 0.8313294437277177
Validation loss: 2.2658223542511644

Epoch: 6| Step: 7
Training loss: 0.9121632856165447
Validation loss: 2.317056780868957

Epoch: 6| Step: 8
Training loss: 0.5965280792873076
Validation loss: 2.21299679462765

Epoch: 6| Step: 9
Training loss: 0.5349495760159302
Validation loss: 2.285184841715115

Epoch: 6| Step: 10
Training loss: 0.6545522618421435
Validation loss: 2.24788909823432

Epoch: 6| Step: 11
Training loss: 0.6082102329865363
Validation loss: 2.2851990981739263

Epoch: 6| Step: 12
Training loss: 2.039206196482759
Validation loss: 2.2322825811459603

Epoch: 6| Step: 13
Training loss: 0.7578094325052688
Validation loss: 2.2001896508454166

Epoch: 561| Step: 0
Training loss: 0.8449340918191667
Validation loss: 2.2439972020508097

Epoch: 6| Step: 1
Training loss: 0.8947407506297871
Validation loss: 2.2577715074931306

Epoch: 6| Step: 2
Training loss: 1.0307540857130926
Validation loss: 2.2130091615995315

Epoch: 6| Step: 3
Training loss: 0.7696083146443167
Validation loss: 2.212340863210671

Epoch: 6| Step: 4
Training loss: 0.7567690321359817
Validation loss: 2.2596156212792633

Epoch: 6| Step: 5
Training loss: 0.5560480812143925
Validation loss: 2.214935833840371

Epoch: 6| Step: 6
Training loss: 0.8335087154530026
Validation loss: 2.232351809705094

Epoch: 6| Step: 7
Training loss: 0.5398043075704835
Validation loss: 2.253364678062501

Epoch: 6| Step: 8
Training loss: 0.6402336181114802
Validation loss: 2.2321687489779025

Epoch: 6| Step: 9
Training loss: 0.7644543943555426
Validation loss: 2.3176125165917387

Epoch: 6| Step: 10
Training loss: 0.7472646024291185
Validation loss: 2.2741040122935456

Epoch: 6| Step: 11
Training loss: 0.6593198274065488
Validation loss: 2.1994966505393783

Epoch: 6| Step: 12
Training loss: 1.7037144612043336
Validation loss: 2.207696612952956

Epoch: 6| Step: 13
Training loss: 0.9572060561615412
Validation loss: 2.201719371360935

Epoch: 562| Step: 0
Training loss: 0.6671507885590692
Validation loss: 2.2761509730793557

Epoch: 6| Step: 1
Training loss: 1.7794312678646633
Validation loss: 2.348335632320415

Epoch: 6| Step: 2
Training loss: 0.6845067494005999
Validation loss: 2.225423428022732

Epoch: 6| Step: 3
Training loss: 0.7684907026206259
Validation loss: 2.211126936484558

Epoch: 6| Step: 4
Training loss: 0.7211815298097638
Validation loss: 2.22305872701845

Epoch: 6| Step: 5
Training loss: 0.584267716581107
Validation loss: 2.2142507356729806

Epoch: 6| Step: 6
Training loss: 0.6950265103368024
Validation loss: 2.2296450077463317

Epoch: 6| Step: 7
Training loss: 0.8002549465566413
Validation loss: 2.1950626347143705

Epoch: 6| Step: 8
Training loss: 0.7261545820470274
Validation loss: 2.2302993662111956

Epoch: 6| Step: 9
Training loss: 0.6797674943174634
Validation loss: 2.279808762398706

Epoch: 6| Step: 10
Training loss: 0.8268889793777086
Validation loss: 2.195480986580033

Epoch: 6| Step: 11
Training loss: 0.9075720122168345
Validation loss: 2.2577499492826023

Epoch: 6| Step: 12
Training loss: 0.8431308735387678
Validation loss: 2.292202266254076

Epoch: 6| Step: 13
Training loss: 0.6190240070251091
Validation loss: 2.2230090749693194

Epoch: 563| Step: 0
Training loss: 0.4908815041410586
Validation loss: 2.1953304346822167

Epoch: 6| Step: 1
Training loss: 1.0086849487582534
Validation loss: 2.25191012237934

Epoch: 6| Step: 2
Training loss: 0.6667300333266701
Validation loss: 2.2944757474492277

Epoch: 6| Step: 3
Training loss: 0.8030380825404191
Validation loss: 2.3023016781581815

Epoch: 6| Step: 4
Training loss: 0.8210749035096063
Validation loss: 2.27989755385133

Epoch: 6| Step: 5
Training loss: 0.5024707366716185
Validation loss: 2.195137448733025

Epoch: 6| Step: 6
Training loss: 0.6573554673543552
Validation loss: 2.2858232145898336

Epoch: 6| Step: 7
Training loss: 0.7612410783792996
Validation loss: 2.349778936623081

Epoch: 6| Step: 8
Training loss: 0.6036349922327939
Validation loss: 2.3030524670596924

Epoch: 6| Step: 9
Training loss: 0.8962327525076733
Validation loss: 2.2372496201705863

Epoch: 6| Step: 10
Training loss: 1.8704889072475759
Validation loss: 2.2789760780393027

Epoch: 6| Step: 11
Training loss: 0.862117345208754
Validation loss: 2.215695901034212

Epoch: 6| Step: 12
Training loss: 0.8516323165971198
Validation loss: 2.209977418111076

Epoch: 6| Step: 13
Training loss: 0.5117998714065242
Validation loss: 2.1675177003974406

Epoch: 564| Step: 0
Training loss: 0.7869411317094523
Validation loss: 2.1711235537652303

Epoch: 6| Step: 1
Training loss: 0.6812614544946661
Validation loss: 2.2005901708502034

Epoch: 6| Step: 2
Training loss: 0.7820246098833826
Validation loss: 2.195684660758093

Epoch: 6| Step: 3
Training loss: 0.9375527049190555
Validation loss: 2.211406540174438

Epoch: 6| Step: 4
Training loss: 0.6803098876370277
Validation loss: 2.2069531176348653

Epoch: 6| Step: 5
Training loss: 0.7342981338855461
Validation loss: 2.201594152866166

Epoch: 6| Step: 6
Training loss: 0.6592718667464088
Validation loss: 2.2308837683819434

Epoch: 6| Step: 7
Training loss: 0.5488139249111732
Validation loss: 2.2688504906342097

Epoch: 6| Step: 8
Training loss: 0.9934059531166919
Validation loss: 2.202994632580145

Epoch: 6| Step: 9
Training loss: 1.7318084559739808
Validation loss: 2.1677115534192954

Epoch: 6| Step: 10
Training loss: 0.7593622779565427
Validation loss: 2.2279201246600397

Epoch: 6| Step: 11
Training loss: 0.6790594070862696
Validation loss: 2.2055953718277097

Epoch: 6| Step: 12
Training loss: 0.4547932269211883
Validation loss: 2.2574654379231824

Epoch: 6| Step: 13
Training loss: 0.6210521948006359
Validation loss: 2.19537064646783

Epoch: 565| Step: 0
Training loss: 0.8044770345166083
Validation loss: 2.32051396405969

Epoch: 6| Step: 1
Training loss: 0.8487927601061475
Validation loss: 2.210796305746481

Epoch: 6| Step: 2
Training loss: 0.8027574670444934
Validation loss: 2.236071836598448

Epoch: 6| Step: 3
Training loss: 0.754026413270238
Validation loss: 2.2222783159368213

Epoch: 6| Step: 4
Training loss: 0.8055666592990988
Validation loss: 2.200448090123428

Epoch: 6| Step: 5
Training loss: 0.6706649618338852
Validation loss: 2.1537775450077006

Epoch: 6| Step: 6
Training loss: 0.816199609623549
Validation loss: 2.2412551565604937

Epoch: 6| Step: 7
Training loss: 0.5696556279928574
Validation loss: 2.2181146044952404

Epoch: 6| Step: 8
Training loss: 1.9006373842156414
Validation loss: 2.2079515755995813

Epoch: 6| Step: 9
Training loss: 0.5214159631324539
Validation loss: 2.1654213571749734

Epoch: 6| Step: 10
Training loss: 0.5965382709648548
Validation loss: 2.1786784644827453

Epoch: 6| Step: 11
Training loss: 0.5581718398684343
Validation loss: 2.3239520457547433

Epoch: 6| Step: 12
Training loss: 0.6331934782843017
Validation loss: 2.2574407867147164

Epoch: 6| Step: 13
Training loss: 0.44634967617712434
Validation loss: 2.2152474496961

Epoch: 566| Step: 0
Training loss: 1.7188273325775625
Validation loss: 2.186662656666643

Epoch: 6| Step: 1
Training loss: 0.44551217471290383
Validation loss: 2.2619990067266427

Epoch: 6| Step: 2
Training loss: 0.7249985135819556
Validation loss: 2.234822794391653

Epoch: 6| Step: 3
Training loss: 0.6585621067106403
Validation loss: 2.299785865358493

Epoch: 6| Step: 4
Training loss: 0.7125785248969317
Validation loss: 2.2625891680208854

Epoch: 6| Step: 5
Training loss: 0.6341596087398431
Validation loss: 2.2063089422754607

Epoch: 6| Step: 6
Training loss: 0.7166254321885016
Validation loss: 2.281616300650519

Epoch: 6| Step: 7
Training loss: 0.6808344930018708
Validation loss: 2.1933698972699593

Epoch: 6| Step: 8
Training loss: 0.764887707765076
Validation loss: 2.2813334734213693

Epoch: 6| Step: 9
Training loss: 0.35308656947563327
Validation loss: 2.1969694265803326

Epoch: 6| Step: 10
Training loss: 0.7051720384943
Validation loss: 2.1849651521964883

Epoch: 6| Step: 11
Training loss: 0.9380780027690527
Validation loss: 2.2780894722466645

Epoch: 6| Step: 12
Training loss: 0.7494168000895765
Validation loss: 2.2356974374663254

Epoch: 6| Step: 13
Training loss: 0.9492702077724494
Validation loss: 2.1467276108628788

Epoch: 567| Step: 0
Training loss: 0.7987132467849474
Validation loss: 2.3269919136163124

Epoch: 6| Step: 1
Training loss: 0.6229962654246759
Validation loss: 2.2842102619728686

Epoch: 6| Step: 2
Training loss: 0.6939666452733649
Validation loss: 2.179205222570967

Epoch: 6| Step: 3
Training loss: 0.6802806896575578
Validation loss: 2.243406679132889

Epoch: 6| Step: 4
Training loss: 0.7796028702851876
Validation loss: 2.2288116281214707

Epoch: 6| Step: 5
Training loss: 0.5243738823243371
Validation loss: 2.173532833688065

Epoch: 6| Step: 6
Training loss: 0.8282395049770781
Validation loss: 2.2474017882437836

Epoch: 6| Step: 7
Training loss: 0.6443408800521232
Validation loss: 2.2625628673680165

Epoch: 6| Step: 8
Training loss: 0.7971767527395273
Validation loss: 2.2826068398176327

Epoch: 6| Step: 9
Training loss: 0.7327091721685484
Validation loss: 2.1642984483973766

Epoch: 6| Step: 10
Training loss: 0.7751093818015067
Validation loss: 2.1918609956270982

Epoch: 6| Step: 11
Training loss: 1.6999805365177523
Validation loss: 2.2205712883584305

Epoch: 6| Step: 12
Training loss: 0.759608431443481
Validation loss: 2.217968223116974

Epoch: 6| Step: 13
Training loss: 0.4870062240862787
Validation loss: 2.260394023723068

Epoch: 568| Step: 0
Training loss: 0.632800090338451
Validation loss: 2.200909400783366

Epoch: 6| Step: 1
Training loss: 0.6325694429777722
Validation loss: 2.2519330809675333

Epoch: 6| Step: 2
Training loss: 0.7207092863817124
Validation loss: 2.2333392573709516

Epoch: 6| Step: 3
Training loss: 0.787438373576392
Validation loss: 2.2717943956660815

Epoch: 6| Step: 4
Training loss: 1.8039173943665607
Validation loss: 2.2579187781976966

Epoch: 6| Step: 5
Training loss: 0.49753023165952076
Validation loss: 2.2697412706671405

Epoch: 6| Step: 6
Training loss: 0.5797217459215418
Validation loss: 2.250158182460793

Epoch: 6| Step: 7
Training loss: 1.007663449643075
Validation loss: 2.2484115459186955

Epoch: 6| Step: 8
Training loss: 0.7636072077774166
Validation loss: 2.1786989712429854

Epoch: 6| Step: 9
Training loss: 0.7765343827927401
Validation loss: 2.314465937888991

Epoch: 6| Step: 10
Training loss: 0.8518722040993925
Validation loss: 2.174744382358196

Epoch: 6| Step: 11
Training loss: 0.6687210486731879
Validation loss: 2.1834165862379438

Epoch: 6| Step: 12
Training loss: 0.6751904413225762
Validation loss: 2.1800545221611554

Epoch: 6| Step: 13
Training loss: 0.6437396650503217
Validation loss: 2.1975937978308195

Epoch: 569| Step: 0
Training loss: 0.7646400967626596
Validation loss: 2.2676522503025747

Epoch: 6| Step: 1
Training loss: 0.7911707219789423
Validation loss: 2.2108148442029165

Epoch: 6| Step: 2
Training loss: 0.5627348197777433
Validation loss: 2.1974284476382615

Epoch: 6| Step: 3
Training loss: 0.6033240202409768
Validation loss: 2.184562740924963

Epoch: 6| Step: 4
Training loss: 0.7380511212824914
Validation loss: 2.200795079895176

Epoch: 6| Step: 5
Training loss: 1.7661905648827119
Validation loss: 2.2639360015497916

Epoch: 6| Step: 6
Training loss: 0.7244236546156743
Validation loss: 2.213422493570732

Epoch: 6| Step: 7
Training loss: 0.8201568455838385
Validation loss: 2.2502138527268127

Epoch: 6| Step: 8
Training loss: 0.7953681161916232
Validation loss: 2.278943482443848

Epoch: 6| Step: 9
Training loss: 0.4071008318918097
Validation loss: 2.205290982368955

Epoch: 6| Step: 10
Training loss: 0.781491394896184
Validation loss: 2.3019647916215646

Epoch: 6| Step: 11
Training loss: 0.6193366236879896
Validation loss: 2.198054455480299

Epoch: 6| Step: 12
Training loss: 0.7859330012228739
Validation loss: 2.2340137899080075

Epoch: 6| Step: 13
Training loss: 0.7916557453472992
Validation loss: 2.2281098615564163

Epoch: 570| Step: 0
Training loss: 0.8340260408164416
Validation loss: 2.268990410266608

Epoch: 6| Step: 1
Training loss: 0.5829963363463643
Validation loss: 2.2270603155220927

Epoch: 6| Step: 2
Training loss: 1.7893240125335668
Validation loss: 2.286071943900509

Epoch: 6| Step: 3
Training loss: 0.9144153403029166
Validation loss: 2.251374134995168

Epoch: 6| Step: 4
Training loss: 0.6666757215441257
Validation loss: 2.2361248211431977

Epoch: 6| Step: 5
Training loss: 0.6498755858635687
Validation loss: 2.2812223245939793

Epoch: 6| Step: 6
Training loss: 0.6754831968796968
Validation loss: 2.2571729391550046

Epoch: 6| Step: 7
Training loss: 0.7778358243860549
Validation loss: 2.247900274771361

Epoch: 6| Step: 8
Training loss: 0.6684422738652477
Validation loss: 2.2186137586097807

Epoch: 6| Step: 9
Training loss: 0.656038136570158
Validation loss: 2.228572786092448

Epoch: 6| Step: 10
Training loss: 0.698218221186431
Validation loss: 2.144986112535163

Epoch: 6| Step: 11
Training loss: 0.8271730097303878
Validation loss: 2.3198471323586305

Epoch: 6| Step: 12
Training loss: 0.6442167728679626
Validation loss: 2.258216531935269

Epoch: 6| Step: 13
Training loss: 0.8788939072484029
Validation loss: 2.2368037250651973

Epoch: 571| Step: 0
Training loss: 0.8032054400700545
Validation loss: 2.2342179421975255

Epoch: 6| Step: 1
Training loss: 0.6572200100304284
Validation loss: 2.25362561025749

Epoch: 6| Step: 2
Training loss: 0.533045790938307
Validation loss: 2.3011706489111883

Epoch: 6| Step: 3
Training loss: 0.6474426174880352
Validation loss: 2.301944897959108

Epoch: 6| Step: 4
Training loss: 0.5998584093477247
Validation loss: 2.270948421982174

Epoch: 6| Step: 5
Training loss: 0.8579483327692335
Validation loss: 2.2694848323979993

Epoch: 6| Step: 6
Training loss: 0.7610877529057595
Validation loss: 2.1218148542625346

Epoch: 6| Step: 7
Training loss: 0.891164214886423
Validation loss: 2.254253547870979

Epoch: 6| Step: 8
Training loss: 1.6646873483000741
Validation loss: 2.222871951987934

Epoch: 6| Step: 9
Training loss: 0.858411560999831
Validation loss: 2.246207872285214

Epoch: 6| Step: 10
Training loss: 0.719925375488514
Validation loss: 2.2861875568582577

Epoch: 6| Step: 11
Training loss: 0.7124648403393585
Validation loss: 2.2087170814440826

Epoch: 6| Step: 12
Training loss: 0.5475163377649589
Validation loss: 2.264119058438706

Epoch: 6| Step: 13
Training loss: 0.676540521524606
Validation loss: 2.240316872876029

Epoch: 572| Step: 0
Training loss: 0.6365743368000555
Validation loss: 2.2158364180612544

Epoch: 6| Step: 1
Training loss: 0.9134448320196976
Validation loss: 2.1793037100487456

Epoch: 6| Step: 2
Training loss: 0.5990835860495893
Validation loss: 2.2965623498958605

Epoch: 6| Step: 3
Training loss: 0.9568482515968049
Validation loss: 2.221216982014179

Epoch: 6| Step: 4
Training loss: 0.7740988552902582
Validation loss: 2.2328500314581006

Epoch: 6| Step: 5
Training loss: 1.7094188203372993
Validation loss: 2.255443147749085

Epoch: 6| Step: 6
Training loss: 0.6423826065132736
Validation loss: 2.2471336573333813

Epoch: 6| Step: 7
Training loss: 1.0106659938823437
Validation loss: 2.2837428549221634

Epoch: 6| Step: 8
Training loss: 0.638222796075911
Validation loss: 2.2432437167061297

Epoch: 6| Step: 9
Training loss: 0.6871695808201125
Validation loss: 2.2246669435672985

Epoch: 6| Step: 10
Training loss: 0.7783097442330654
Validation loss: 2.159804084437229

Epoch: 6| Step: 11
Training loss: 0.6437592709438542
Validation loss: 2.154701074874256

Epoch: 6| Step: 12
Training loss: 0.976727067432619
Validation loss: 2.2247149485011

Epoch: 6| Step: 13
Training loss: 0.6102201762883813
Validation loss: 2.1852717247061304

Epoch: 573| Step: 0
Training loss: 0.829006517621638
Validation loss: 2.2983451964206276

Epoch: 6| Step: 1
Training loss: 0.8518431664702097
Validation loss: 2.3052601726566913

Epoch: 6| Step: 2
Training loss: 0.5733442849214807
Validation loss: 2.2972119622519864

Epoch: 6| Step: 3
Training loss: 0.7877797190085261
Validation loss: 2.1876372515488614

Epoch: 6| Step: 4
Training loss: 1.7687033091067426
Validation loss: 2.2523052556182654

Epoch: 6| Step: 5
Training loss: 0.5348230145842792
Validation loss: 2.2597474098455237

Epoch: 6| Step: 6
Training loss: 0.6156017599221344
Validation loss: 2.280376940972321

Epoch: 6| Step: 7
Training loss: 0.5488245139223813
Validation loss: 2.2342407352016327

Epoch: 6| Step: 8
Training loss: 0.8845821636717495
Validation loss: 2.2678866748706508

Epoch: 6| Step: 9
Training loss: 0.6669470798325264
Validation loss: 2.2991915181137417

Epoch: 6| Step: 10
Training loss: 0.6360694757682325
Validation loss: 2.2224795124181895

Epoch: 6| Step: 11
Training loss: 0.4543172016664081
Validation loss: 2.235893869731431

Epoch: 6| Step: 12
Training loss: 0.5588405037448462
Validation loss: 2.205933732386074

Epoch: 6| Step: 13
Training loss: 0.6471089000117571
Validation loss: 2.266372813542212

Epoch: 574| Step: 0
Training loss: 0.5725320710023838
Validation loss: 2.2082689937228217

Epoch: 6| Step: 1
Training loss: 0.5045468302636914
Validation loss: 2.1969211327824296

Epoch: 6| Step: 2
Training loss: 0.6730347094817325
Validation loss: 2.235100374628323

Epoch: 6| Step: 3
Training loss: 0.8011108464469714
Validation loss: 2.244221210956124

Epoch: 6| Step: 4
Training loss: 0.6746625957689741
Validation loss: 2.2013457534846217

Epoch: 6| Step: 5
Training loss: 0.6832905996342874
Validation loss: 2.316010230802563

Epoch: 6| Step: 6
Training loss: 0.5600783885859942
Validation loss: 2.1434975525580486

Epoch: 6| Step: 7
Training loss: 0.6548285302823998
Validation loss: 2.189560139548259

Epoch: 6| Step: 8
Training loss: 0.9550822439280431
Validation loss: 2.237017062433717

Epoch: 6| Step: 9
Training loss: 0.7122672922345643
Validation loss: 2.2145490958028207

Epoch: 6| Step: 10
Training loss: 0.7202188989557445
Validation loss: 2.252361803580478

Epoch: 6| Step: 11
Training loss: 0.4800664721844724
Validation loss: 2.177228918524962

Epoch: 6| Step: 12
Training loss: 1.7960087554055544
Validation loss: 2.17993875244021

Epoch: 6| Step: 13
Training loss: 0.547847047402991
Validation loss: 2.23504981955575

Epoch: 575| Step: 0
Training loss: 0.335169702095442
Validation loss: 2.1995906006562578

Epoch: 6| Step: 1
Training loss: 0.6682886840963372
Validation loss: 2.3097398932377495

Epoch: 6| Step: 2
Training loss: 0.903599744312154
Validation loss: 2.2264619037072713

Epoch: 6| Step: 3
Training loss: 0.6589615750622517
Validation loss: 2.2781411875332784

Epoch: 6| Step: 4
Training loss: 0.6430088906719127
Validation loss: 2.3266211023472527

Epoch: 6| Step: 5
Training loss: 0.6854906847061406
Validation loss: 2.186879537341047

Epoch: 6| Step: 6
Training loss: 0.6693425913141335
Validation loss: 2.2188048020163205

Epoch: 6| Step: 7
Training loss: 0.6274153054593691
Validation loss: 2.27913240690181

Epoch: 6| Step: 8
Training loss: 0.5860537350123145
Validation loss: 2.091712461031617

Epoch: 6| Step: 9
Training loss: 0.5312368727913402
Validation loss: 2.160712655807252

Epoch: 6| Step: 10
Training loss: 0.9050673298527422
Validation loss: 2.250551835163236

Epoch: 6| Step: 11
Training loss: 0.6852095988783763
Validation loss: 2.170086650610705

Epoch: 6| Step: 12
Training loss: 1.8301920494031123
Validation loss: 2.3254690850885704

Epoch: 6| Step: 13
Training loss: 0.5850124941412719
Validation loss: 2.234782966413573

Epoch: 576| Step: 0
Training loss: 0.5770863662621665
Validation loss: 2.230692840049239

Epoch: 6| Step: 1
Training loss: 0.6684300129503683
Validation loss: 2.240147927030076

Epoch: 6| Step: 2
Training loss: 0.5935389494998321
Validation loss: 2.1679331704039404

Epoch: 6| Step: 3
Training loss: 0.9818970205361842
Validation loss: 2.2465887359453407

Epoch: 6| Step: 4
Training loss: 0.6091527288941097
Validation loss: 2.2572437115941826

Epoch: 6| Step: 5
Training loss: 0.6444340950538615
Validation loss: 2.230190421149064

Epoch: 6| Step: 6
Training loss: 0.7299499301199897
Validation loss: 2.3049644630551884

Epoch: 6| Step: 7
Training loss: 0.5881679552467148
Validation loss: 2.231276257913879

Epoch: 6| Step: 8
Training loss: 0.8730423007648975
Validation loss: 2.259566183977616

Epoch: 6| Step: 9
Training loss: 1.866006517617638
Validation loss: 2.1876176020217852

Epoch: 6| Step: 10
Training loss: 0.771780956577947
Validation loss: 2.2107908503989124

Epoch: 6| Step: 11
Training loss: 0.5166485770453001
Validation loss: 2.2384403418974097

Epoch: 6| Step: 12
Training loss: 0.6525136303848236
Validation loss: 2.239373692981182

Epoch: 6| Step: 13
Training loss: 0.8558834237951207
Validation loss: 2.237838842560946

Epoch: 577| Step: 0
Training loss: 0.6091834525297446
Validation loss: 2.216669420585553

Epoch: 6| Step: 1
Training loss: 0.5487157088842368
Validation loss: 2.291452198303422

Epoch: 6| Step: 2
Training loss: 1.0632837994816113
Validation loss: 2.207905864573931

Epoch: 6| Step: 3
Training loss: 0.7745652886953567
Validation loss: 2.191953480069921

Epoch: 6| Step: 4
Training loss: 0.706688096880608
Validation loss: 2.218560389947381

Epoch: 6| Step: 5
Training loss: 0.7011019318530207
Validation loss: 2.23651405482586

Epoch: 6| Step: 6
Training loss: 0.7233923385068862
Validation loss: 2.209695494219858

Epoch: 6| Step: 7
Training loss: 0.6342847675361833
Validation loss: 2.2982489917326565

Epoch: 6| Step: 8
Training loss: 0.7733810095916561
Validation loss: 2.1793335405105703

Epoch: 6| Step: 9
Training loss: 1.7989276605791646
Validation loss: 2.26946020669076

Epoch: 6| Step: 10
Training loss: 0.7138569174887538
Validation loss: 2.221968463753623

Epoch: 6| Step: 11
Training loss: 0.8550864284176699
Validation loss: 2.2619192354872752

Epoch: 6| Step: 12
Training loss: 0.5262703319889616
Validation loss: 2.2420556180166207

Epoch: 6| Step: 13
Training loss: 0.7985384912690615
Validation loss: 2.27058384964164

Epoch: 578| Step: 0
Training loss: 0.5107182630256404
Validation loss: 2.12889951727635

Epoch: 6| Step: 1
Training loss: 0.6162260268309014
Validation loss: 2.251648395917468

Epoch: 6| Step: 2
Training loss: 0.601117576442229
Validation loss: 2.1821469780690697

Epoch: 6| Step: 3
Training loss: 0.7558457720811456
Validation loss: 2.279035266606034

Epoch: 6| Step: 4
Training loss: 0.5405856741124417
Validation loss: 2.193444292749158

Epoch: 6| Step: 5
Training loss: 1.7182033016142475
Validation loss: 2.198813838844307

Epoch: 6| Step: 6
Training loss: 0.7988222303849218
Validation loss: 2.219576438928937

Epoch: 6| Step: 7
Training loss: 0.6289714755715046
Validation loss: 2.2001459056541046

Epoch: 6| Step: 8
Training loss: 0.8494184608371912
Validation loss: 2.2224651512378704

Epoch: 6| Step: 9
Training loss: 0.41601395942462027
Validation loss: 2.2087845485481257

Epoch: 6| Step: 10
Training loss: 0.8838189388726063
Validation loss: 2.20631452141477

Epoch: 6| Step: 11
Training loss: 0.8822074099276
Validation loss: 2.192678874627106

Epoch: 6| Step: 12
Training loss: 0.8474044777480649
Validation loss: 2.1997776159613287

Epoch: 6| Step: 13
Training loss: 0.9773506036239105
Validation loss: 2.230524813413292

Epoch: 579| Step: 0
Training loss: 0.7035625579785163
Validation loss: 2.2496645322991364

Epoch: 6| Step: 1
Training loss: 0.8167078291646539
Validation loss: 2.194968831250292

Epoch: 6| Step: 2
Training loss: 0.68987049729194
Validation loss: 2.1714293981196344

Epoch: 6| Step: 3
Training loss: 0.9237205007176386
Validation loss: 2.321505301885464

Epoch: 6| Step: 4
Training loss: 0.7584117604317632
Validation loss: 2.2892358407618594

Epoch: 6| Step: 5
Training loss: 0.5957881929286667
Validation loss: 2.3212319232534715

Epoch: 6| Step: 6
Training loss: 0.7999964892787195
Validation loss: 2.232876543168983

Epoch: 6| Step: 7
Training loss: 0.7997193902332754
Validation loss: 2.2159707923408996

Epoch: 6| Step: 8
Training loss: 1.7469328159325297
Validation loss: 2.221700282568786

Epoch: 6| Step: 9
Training loss: 0.8565787860556558
Validation loss: 2.219164371576242

Epoch: 6| Step: 10
Training loss: 0.6274261828998906
Validation loss: 2.2495946410766323

Epoch: 6| Step: 11
Training loss: 0.5078033446440315
Validation loss: 2.180229336959343

Epoch: 6| Step: 12
Training loss: 0.7861917224870414
Validation loss: 2.2142466174048576

Epoch: 6| Step: 13
Training loss: 0.646001537527847
Validation loss: 2.297176731636288

Epoch: 580| Step: 0
Training loss: 0.6842133683896594
Validation loss: 2.2827289219070583

Epoch: 6| Step: 1
Training loss: 0.7175918037884204
Validation loss: 2.2724203863585832

Epoch: 6| Step: 2
Training loss: 0.9738552256522747
Validation loss: 2.2389805098120994

Epoch: 6| Step: 3
Training loss: 0.6248312960864773
Validation loss: 2.203423902112706

Epoch: 6| Step: 4
Training loss: 0.5724277722302362
Validation loss: 2.233800267855911

Epoch: 6| Step: 5
Training loss: 0.5828843744871062
Validation loss: 2.16004929193094

Epoch: 6| Step: 6
Training loss: 1.7044803930639258
Validation loss: 2.2580453271698744

Epoch: 6| Step: 7
Training loss: 0.8067366055705648
Validation loss: 2.1865555231724803

Epoch: 6| Step: 8
Training loss: 0.5392874372801237
Validation loss: 2.1768801637965813

Epoch: 6| Step: 9
Training loss: 0.6641651298651949
Validation loss: 2.2346369885699726

Epoch: 6| Step: 10
Training loss: 0.7329764745952138
Validation loss: 2.313452603423821

Epoch: 6| Step: 11
Training loss: 0.45896997632106795
Validation loss: 2.1855040666299206

Epoch: 6| Step: 12
Training loss: 0.7820554396082673
Validation loss: 2.2433771755614798

Epoch: 6| Step: 13
Training loss: 0.6610742991035438
Validation loss: 2.2509893528972165

Epoch: 581| Step: 0
Training loss: 0.5611355445229677
Validation loss: 2.274888107845875

Epoch: 6| Step: 1
Training loss: 0.513672281127305
Validation loss: 2.2140774468725413

Epoch: 6| Step: 2
Training loss: 0.9167781169648108
Validation loss: 2.1486461173429072

Epoch: 6| Step: 3
Training loss: 0.7172955018213456
Validation loss: 2.1952579149783475

Epoch: 6| Step: 4
Training loss: 0.5670494636728199
Validation loss: 2.250235336739296

Epoch: 6| Step: 5
Training loss: 0.7162763072137434
Validation loss: 2.244562988838094

Epoch: 6| Step: 6
Training loss: 0.527475298262487
Validation loss: 2.3000481207701524

Epoch: 6| Step: 7
Training loss: 0.7612380247004129
Validation loss: 2.260653916628583

Epoch: 6| Step: 8
Training loss: 0.6314272848777635
Validation loss: 2.2386917510660584

Epoch: 6| Step: 9
Training loss: 0.7228122439715917
Validation loss: 2.2353999033739007

Epoch: 6| Step: 10
Training loss: 0.7533747721839916
Validation loss: 2.2581343650086114

Epoch: 6| Step: 11
Training loss: 0.57249050473997
Validation loss: 2.2987621837146928

Epoch: 6| Step: 12
Training loss: 1.680514606610974
Validation loss: 2.284366067947139

Epoch: 6| Step: 13
Training loss: 0.9493212860361865
Validation loss: 2.2627259215027102

Epoch: 582| Step: 0
Training loss: 0.8081998372368293
Validation loss: 2.178219117772513

Epoch: 6| Step: 1
Training loss: 0.6422934321815296
Validation loss: 2.2102542872258364

Epoch: 6| Step: 2
Training loss: 0.6189391954721
Validation loss: 2.2128971693743003

Epoch: 6| Step: 3
Training loss: 0.6950783496027529
Validation loss: 2.1923770581709423

Epoch: 6| Step: 4
Training loss: 0.5182115817001808
Validation loss: 2.286679607396476

Epoch: 6| Step: 5
Training loss: 0.9096122065277836
Validation loss: 2.246787601427672

Epoch: 6| Step: 6
Training loss: 0.6991483130753239
Validation loss: 2.262362040042176

Epoch: 6| Step: 7
Training loss: 0.6268839099741456
Validation loss: 2.29713901511714

Epoch: 6| Step: 8
Training loss: 0.8880257405940672
Validation loss: 2.2277676981814714

Epoch: 6| Step: 9
Training loss: 1.7211170889319172
Validation loss: 2.2415504861259374

Epoch: 6| Step: 10
Training loss: 0.5397692484036274
Validation loss: 2.177354956904764

Epoch: 6| Step: 11
Training loss: 0.781788869027515
Validation loss: 2.2158732826435066

Epoch: 6| Step: 12
Training loss: 0.7913809227162178
Validation loss: 2.2627020923799486

Epoch: 6| Step: 13
Training loss: 0.8404365753806463
Validation loss: 2.2962274163773917

Epoch: 583| Step: 0
Training loss: 0.47599852913941804
Validation loss: 2.2791635971497093

Epoch: 6| Step: 1
Training loss: 0.614401116810469
Validation loss: 2.197036812776435

Epoch: 6| Step: 2
Training loss: 0.6306907263039983
Validation loss: 2.2125191661462718

Epoch: 6| Step: 3
Training loss: 0.8471131584619854
Validation loss: 2.2576921455559904

Epoch: 6| Step: 4
Training loss: 0.7158479568118697
Validation loss: 2.1798729463525577

Epoch: 6| Step: 5
Training loss: 0.6958381937241744
Validation loss: 2.323038333543076

Epoch: 6| Step: 6
Training loss: 0.650393213948547
Validation loss: 2.2030704101418035

Epoch: 6| Step: 7
Training loss: 1.08350269509875
Validation loss: 2.24629020898209

Epoch: 6| Step: 8
Training loss: 1.7452382289619026
Validation loss: 2.1740176017467454

Epoch: 6| Step: 9
Training loss: 0.8947190999517396
Validation loss: 2.347013065619165

Epoch: 6| Step: 10
Training loss: 0.6682401183953666
Validation loss: 2.241914349265499

Epoch: 6| Step: 11
Training loss: 0.6581837455998149
Validation loss: 2.295374541138513

Epoch: 6| Step: 12
Training loss: 0.38345427143007466
Validation loss: 2.2024275572433725

Epoch: 6| Step: 13
Training loss: 0.5523978243288457
Validation loss: 2.1809972770211155

Epoch: 584| Step: 0
Training loss: 1.7616761196078945
Validation loss: 2.2759295735125256

Epoch: 6| Step: 1
Training loss: 0.6195217127023792
Validation loss: 2.2030931556440683

Epoch: 6| Step: 2
Training loss: 0.6755405504520237
Validation loss: 2.207346686696401

Epoch: 6| Step: 3
Training loss: 0.5105540875579923
Validation loss: 2.3142322835585003

Epoch: 6| Step: 4
Training loss: 0.7988308111392797
Validation loss: 2.2772759786808856

Epoch: 6| Step: 5
Training loss: 0.557845034037888
Validation loss: 2.17706311084956

Epoch: 6| Step: 6
Training loss: 0.5917203998567856
Validation loss: 2.211998426721016

Epoch: 6| Step: 7
Training loss: 0.5734762464524653
Validation loss: 2.2287407568717477

Epoch: 6| Step: 8
Training loss: 0.8434563584991384
Validation loss: 2.2782283026104144

Epoch: 6| Step: 9
Training loss: 0.5048359419355545
Validation loss: 2.1944731341647783

Epoch: 6| Step: 10
Training loss: 0.820885231262177
Validation loss: 2.1913004750527905

Epoch: 6| Step: 11
Training loss: 0.8171853906082733
Validation loss: 2.2559413105741535

Epoch: 6| Step: 12
Training loss: 0.6104752804299715
Validation loss: 2.2320310076979903

Epoch: 6| Step: 13
Training loss: 0.8323631162057195
Validation loss: 2.2245746667353226

Epoch: 585| Step: 0
Training loss: 1.6190963021206526
Validation loss: 2.220331323215419

Epoch: 6| Step: 1
Training loss: 0.4174340473265861
Validation loss: 2.2626927122565617

Epoch: 6| Step: 2
Training loss: 0.5878123994915403
Validation loss: 2.2719150784151037

Epoch: 6| Step: 3
Training loss: 0.48162816658830443
Validation loss: 2.2289861585484254

Epoch: 6| Step: 4
Training loss: 0.6994951863181194
Validation loss: 2.2658056151094526

Epoch: 6| Step: 5
Training loss: 0.6955383234099283
Validation loss: 2.3217890203354496

Epoch: 6| Step: 6
Training loss: 0.6106240114576914
Validation loss: 2.273894538886639

Epoch: 6| Step: 7
Training loss: 0.4819413235710204
Validation loss: 2.2214278746142155

Epoch: 6| Step: 8
Training loss: 0.5827878604211068
Validation loss: 2.243644229423846

Epoch: 6| Step: 9
Training loss: 0.7974779802230167
Validation loss: 2.203544072404612

Epoch: 6| Step: 10
Training loss: 0.7749823352892478
Validation loss: 2.2298918027568253

Epoch: 6| Step: 11
Training loss: 0.8211783789260187
Validation loss: 2.2411128993428724

Epoch: 6| Step: 12
Training loss: 0.8438883420770695
Validation loss: 2.2352455589364575

Epoch: 6| Step: 13
Training loss: 0.8483733909932284
Validation loss: 2.264091930858966

Epoch: 586| Step: 0
Training loss: 0.7525258050974025
Validation loss: 2.1728901763135955

Epoch: 6| Step: 1
Training loss: 1.0014450837580067
Validation loss: 2.2086091054151322

Epoch: 6| Step: 2
Training loss: 0.48103760949570656
Validation loss: 2.2184274957003005

Epoch: 6| Step: 3
Training loss: 0.5614927067847734
Validation loss: 2.2694594611376577

Epoch: 6| Step: 4
Training loss: 0.7334775107432908
Validation loss: 2.2078333448480016

Epoch: 6| Step: 5
Training loss: 0.5186498522317062
Validation loss: 2.157865383180965

Epoch: 6| Step: 6
Training loss: 1.811234459872874
Validation loss: 2.2456822468947264

Epoch: 6| Step: 7
Training loss: 0.8573513827532507
Validation loss: 2.2033353106032334

Epoch: 6| Step: 8
Training loss: 0.5384037581557772
Validation loss: 2.223380779782111

Epoch: 6| Step: 9
Training loss: 0.8755114967684982
Validation loss: 2.130450072959606

Epoch: 6| Step: 10
Training loss: 0.7583845673186009
Validation loss: 2.2778805330339154

Epoch: 6| Step: 11
Training loss: 0.6446766082538875
Validation loss: 2.185488806755566

Epoch: 6| Step: 12
Training loss: 0.7537208684982197
Validation loss: 2.2015274482317504

Epoch: 6| Step: 13
Training loss: 0.6998862165549347
Validation loss: 2.2733409700267515

Epoch: 587| Step: 0
Training loss: 0.7196425825008286
Validation loss: 2.2496478182262862

Epoch: 6| Step: 1
Training loss: 0.8124815131798588
Validation loss: 2.2311459135441094

Epoch: 6| Step: 2
Training loss: 0.7116610858558454
Validation loss: 2.167948766407671

Epoch: 6| Step: 3
Training loss: 0.5496241000222114
Validation loss: 2.230891859597289

Epoch: 6| Step: 4
Training loss: 0.6893559676488867
Validation loss: 2.2695485095103702

Epoch: 6| Step: 5
Training loss: 0.7501678676297566
Validation loss: 2.207086533487388

Epoch: 6| Step: 6
Training loss: 0.5104941646623515
Validation loss: 2.2242441677881524

Epoch: 6| Step: 7
Training loss: 1.7090705893431992
Validation loss: 2.2089200678926604

Epoch: 6| Step: 8
Training loss: 0.605441135884277
Validation loss: 2.2843803328825323

Epoch: 6| Step: 9
Training loss: 0.7888566305687138
Validation loss: 2.2129835071947723

Epoch: 6| Step: 10
Training loss: 0.5341995486624241
Validation loss: 2.2103492380061027

Epoch: 6| Step: 11
Training loss: 0.5495990212664295
Validation loss: 2.2401961369387395

Epoch: 6| Step: 12
Training loss: 0.9658327169364255
Validation loss: 2.213786077933994

Epoch: 6| Step: 13
Training loss: 0.6622096073048211
Validation loss: 2.187425948499572

Epoch: 588| Step: 0
Training loss: 0.49354360346845516
Validation loss: 2.2563893080389787

Epoch: 6| Step: 1
Training loss: 1.792315328707064
Validation loss: 2.2170027029022563

Epoch: 6| Step: 2
Training loss: 0.6469645949527261
Validation loss: 2.2318071393107215

Epoch: 6| Step: 3
Training loss: 0.6105651481759204
Validation loss: 2.2559312852743667

Epoch: 6| Step: 4
Training loss: 0.5834361536371095
Validation loss: 2.284187630331001

Epoch: 6| Step: 5
Training loss: 0.3803627884904425
Validation loss: 2.2151865926310044

Epoch: 6| Step: 6
Training loss: 0.613193384181376
Validation loss: 2.253096292458

Epoch: 6| Step: 7
Training loss: 0.8827170936546515
Validation loss: 2.275955342075218

Epoch: 6| Step: 8
Training loss: 0.788526145012972
Validation loss: 2.2380261623661215

Epoch: 6| Step: 9
Training loss: 0.7834823757446092
Validation loss: 2.201222570207334

Epoch: 6| Step: 10
Training loss: 0.5869066234758255
Validation loss: 2.13318810515002

Epoch: 6| Step: 11
Training loss: 0.5306476656472874
Validation loss: 2.214860932746011

Epoch: 6| Step: 12
Training loss: 0.5657309880722227
Validation loss: 2.296383081022278

Epoch: 6| Step: 13
Training loss: 0.5791421654090377
Validation loss: 2.2220881745540684

Epoch: 589| Step: 0
Training loss: 0.6301369324477367
Validation loss: 2.227006942642351

Epoch: 6| Step: 1
Training loss: 0.6918913653401567
Validation loss: 2.2803610860717907

Epoch: 6| Step: 2
Training loss: 1.7677380905688898
Validation loss: 2.1967211431962634

Epoch: 6| Step: 3
Training loss: 0.6856027781415758
Validation loss: 2.2516529592681556

Epoch: 6| Step: 4
Training loss: 0.6101769037206769
Validation loss: 2.258586264558468

Epoch: 6| Step: 5
Training loss: 0.7544719174886645
Validation loss: 2.230316722419848

Epoch: 6| Step: 6
Training loss: 0.6796058518050578
Validation loss: 2.140142187693299

Epoch: 6| Step: 7
Training loss: 0.5470063732933589
Validation loss: 2.274958792332079

Epoch: 6| Step: 8
Training loss: 1.1188455295800575
Validation loss: 2.2733161357395986

Epoch: 6| Step: 9
Training loss: 0.9848875497637415
Validation loss: 2.2799909637308446

Epoch: 6| Step: 10
Training loss: 0.5901626331245732
Validation loss: 2.2886533684092183

Epoch: 6| Step: 11
Training loss: 0.744014298737443
Validation loss: 2.2355542589436914

Epoch: 6| Step: 12
Training loss: 0.7048502841884215
Validation loss: 2.162285297970986

Epoch: 6| Step: 13
Training loss: 0.6104543370502363
Validation loss: 2.1958925957053648

Epoch: 590| Step: 0
Training loss: 0.8318702649469699
Validation loss: 2.2727946804860433

Epoch: 6| Step: 1
Training loss: 0.7484559218144439
Validation loss: 2.2178795346356543

Epoch: 6| Step: 2
Training loss: 0.7145081446232158
Validation loss: 2.236019591450066

Epoch: 6| Step: 3
Training loss: 0.6049767248547392
Validation loss: 2.2107618943320353

Epoch: 6| Step: 4
Training loss: 0.6749039616963496
Validation loss: 2.2551729380001593

Epoch: 6| Step: 5
Training loss: 0.7229893921724216
Validation loss: 2.1806769358368383

Epoch: 6| Step: 6
Training loss: 0.8192116025808971
Validation loss: 2.222160853500768

Epoch: 6| Step: 7
Training loss: 0.5605315628352879
Validation loss: 2.1771094983057404

Epoch: 6| Step: 8
Training loss: 0.6039771626872911
Validation loss: 2.230410409935232

Epoch: 6| Step: 9
Training loss: 0.6544420451346225
Validation loss: 2.213720653808644

Epoch: 6| Step: 10
Training loss: 1.7686042968262972
Validation loss: 2.194129949695833

Epoch: 6| Step: 11
Training loss: 0.7383319494207198
Validation loss: 2.156636085085486

Epoch: 6| Step: 12
Training loss: 0.685551939508147
Validation loss: 2.244838719721497

Epoch: 6| Step: 13
Training loss: 0.8279560924512055
Validation loss: 2.209954705182269

Epoch: 591| Step: 0
Training loss: 0.49946696956355136
Validation loss: 2.2248790479956555

Epoch: 6| Step: 1
Training loss: 0.56530728769509
Validation loss: 2.2176812680281595

Epoch: 6| Step: 2
Training loss: 0.6425845253112579
Validation loss: 2.1997784795292294

Epoch: 6| Step: 3
Training loss: 0.613909235845321
Validation loss: 2.2873172111602376

Epoch: 6| Step: 4
Training loss: 0.8012193179393192
Validation loss: 2.2027396623864894

Epoch: 6| Step: 5
Training loss: 0.6880952902122254
Validation loss: 2.2105656062528607

Epoch: 6| Step: 6
Training loss: 0.9541850214585121
Validation loss: 2.197288219996579

Epoch: 6| Step: 7
Training loss: 0.5384703991758267
Validation loss: 2.2219137605352763

Epoch: 6| Step: 8
Training loss: 0.5226805323503895
Validation loss: 2.18351976444429

Epoch: 6| Step: 9
Training loss: 0.7486392233136431
Validation loss: 2.216383121473658

Epoch: 6| Step: 10
Training loss: 0.764660792537178
Validation loss: 2.2166391164489516

Epoch: 6| Step: 11
Training loss: 1.769721553581954
Validation loss: 2.175485454287375

Epoch: 6| Step: 12
Training loss: 0.7723370439445496
Validation loss: 2.2200356640399663

Epoch: 6| Step: 13
Training loss: 0.6360634315890972
Validation loss: 2.21803197893799

Epoch: 592| Step: 0
Training loss: 0.6884451351703412
Validation loss: 2.18265705210341

Epoch: 6| Step: 1
Training loss: 0.7206640051999323
Validation loss: 2.203581847067426

Epoch: 6| Step: 2
Training loss: 0.7038415860059533
Validation loss: 2.1969962464149657

Epoch: 6| Step: 3
Training loss: 0.7008563848764863
Validation loss: 2.148680002914461

Epoch: 6| Step: 4
Training loss: 0.605969990630899
Validation loss: 2.189089512549837

Epoch: 6| Step: 5
Training loss: 0.6912679156694446
Validation loss: 2.26998952005638

Epoch: 6| Step: 6
Training loss: 0.5857261276460256
Validation loss: 2.2139465965396727

Epoch: 6| Step: 7
Training loss: 1.7012853223285567
Validation loss: 2.1753875004397307

Epoch: 6| Step: 8
Training loss: 0.9215205529498364
Validation loss: 2.175997347859441

Epoch: 6| Step: 9
Training loss: 0.748834339925957
Validation loss: 2.196715043119224

Epoch: 6| Step: 10
Training loss: 0.6771751317125677
Validation loss: 2.243639415545851

Epoch: 6| Step: 11
Training loss: 0.5896852798298825
Validation loss: 2.192740784862063

Epoch: 6| Step: 12
Training loss: 0.869007880542786
Validation loss: 2.300024486605792

Epoch: 6| Step: 13
Training loss: 0.47454590235633043
Validation loss: 2.177767269401668

Epoch: 593| Step: 0
Training loss: 1.7582632207526658
Validation loss: 2.2651242877898947

Epoch: 6| Step: 1
Training loss: 0.6730790992324359
Validation loss: 2.222012225243282

Epoch: 6| Step: 2
Training loss: 0.6004786697985799
Validation loss: 2.187089929657853

Epoch: 6| Step: 3
Training loss: 0.5875235390512976
Validation loss: 2.1321307049696814

Epoch: 6| Step: 4
Training loss: 0.7928888440391693
Validation loss: 2.202686648751622

Epoch: 6| Step: 5
Training loss: 0.6311955456804982
Validation loss: 2.166717298766428

Epoch: 6| Step: 6
Training loss: 0.5332156728309078
Validation loss: 2.1617176713279673

Epoch: 6| Step: 7
Training loss: 0.688757678056626
Validation loss: 2.2163016447649597

Epoch: 6| Step: 8
Training loss: 0.545990473814363
Validation loss: 2.2035198848324193

Epoch: 6| Step: 9
Training loss: 0.747392612321849
Validation loss: 2.21348897756642

Epoch: 6| Step: 10
Training loss: 0.6174201044141483
Validation loss: 2.2771888879648476

Epoch: 6| Step: 11
Training loss: 0.6843365366678507
Validation loss: 2.2256000527728355

Epoch: 6| Step: 12
Training loss: 0.7499065738344565
Validation loss: 2.2268441045744107

Epoch: 6| Step: 13
Training loss: 0.5399689171816924
Validation loss: 2.2255581997028853

Epoch: 594| Step: 0
Training loss: 0.4569937698776405
Validation loss: 2.265791288107188

Epoch: 6| Step: 1
Training loss: 0.5955088314199066
Validation loss: 2.1865818024483983

Epoch: 6| Step: 2
Training loss: 0.8030466553589125
Validation loss: 2.1760820878309213

Epoch: 6| Step: 3
Training loss: 0.7295894940906086
Validation loss: 2.2580846074744274

Epoch: 6| Step: 4
Training loss: 1.6913510637332587
Validation loss: 2.2213334216258414

Epoch: 6| Step: 5
Training loss: 0.5464927699962345
Validation loss: 2.216839855059865

Epoch: 6| Step: 6
Training loss: 0.8512000266151316
Validation loss: 2.315894792656781

Epoch: 6| Step: 7
Training loss: 0.5014646654583726
Validation loss: 2.275330221673696

Epoch: 6| Step: 8
Training loss: 0.6479091790023185
Validation loss: 2.2514103374060204

Epoch: 6| Step: 9
Training loss: 0.6940790444248176
Validation loss: 2.2089960675277234

Epoch: 6| Step: 10
Training loss: 0.7679048963759997
Validation loss: 2.2512246471368402

Epoch: 6| Step: 11
Training loss: 0.7952999930906637
Validation loss: 2.2471918450230466

Epoch: 6| Step: 12
Training loss: 0.8339311998196942
Validation loss: 2.2247027312987724

Epoch: 6| Step: 13
Training loss: 0.5281218263429167
Validation loss: 2.208888957018248

Epoch: 595| Step: 0
Training loss: 0.45498846259528175
Validation loss: 2.194171225683561

Epoch: 6| Step: 1
Training loss: 0.5346434147740224
Validation loss: 2.167373254686232

Epoch: 6| Step: 2
Training loss: 0.6160627087080622
Validation loss: 2.2191362231142837

Epoch: 6| Step: 3
Training loss: 0.5797843317556406
Validation loss: 2.185303197027452

Epoch: 6| Step: 4
Training loss: 0.6590883092769182
Validation loss: 2.2605207576255237

Epoch: 6| Step: 5
Training loss: 0.6926600408332021
Validation loss: 2.15202384283355

Epoch: 6| Step: 6
Training loss: 0.7543189149754944
Validation loss: 2.24005754224237

Epoch: 6| Step: 7
Training loss: 0.5597000371145427
Validation loss: 2.2274106494131716

Epoch: 6| Step: 8
Training loss: 0.6234476839156378
Validation loss: 2.2406088409708422

Epoch: 6| Step: 9
Training loss: 0.6716118452458345
Validation loss: 2.3245863569576737

Epoch: 6| Step: 10
Training loss: 0.526507725116465
Validation loss: 2.242414914226755

Epoch: 6| Step: 11
Training loss: 0.6874559561753089
Validation loss: 2.1727335517990345

Epoch: 6| Step: 12
Training loss: 1.7619114535682103
Validation loss: 2.1845717089903594

Epoch: 6| Step: 13
Training loss: 0.5691698201689296
Validation loss: 2.2698963177997196

Epoch: 596| Step: 0
Training loss: 0.6018245175938846
Validation loss: 2.117609461579309

Epoch: 6| Step: 1
Training loss: 0.6008395024149136
Validation loss: 2.2400191912931318

Epoch: 6| Step: 2
Training loss: 0.5155138994224517
Validation loss: 2.2093251563344367

Epoch: 6| Step: 3
Training loss: 0.6550466995117092
Validation loss: 2.1729461962711913

Epoch: 6| Step: 4
Training loss: 0.7725051114922455
Validation loss: 2.2865331789222965

Epoch: 6| Step: 5
Training loss: 0.7181606779208091
Validation loss: 2.2646377370001094

Epoch: 6| Step: 6
Training loss: 0.6376546522558414
Validation loss: 2.209029864677732

Epoch: 6| Step: 7
Training loss: 1.7954611481829394
Validation loss: 2.1885851674923633

Epoch: 6| Step: 8
Training loss: 0.6452411325814228
Validation loss: 2.303445993402742

Epoch: 6| Step: 9
Training loss: 0.5118332654639725
Validation loss: 2.2379938512454447

Epoch: 6| Step: 10
Training loss: 0.45317442394242496
Validation loss: 2.328531930446704

Epoch: 6| Step: 11
Training loss: 0.9154228455987985
Validation loss: 2.248514803837427

Epoch: 6| Step: 12
Training loss: 0.6530479467834739
Validation loss: 2.2267999429971015

Epoch: 6| Step: 13
Training loss: 0.6745344357816262
Validation loss: 2.1981409435990966

Epoch: 597| Step: 0
Training loss: 0.6051356476050098
Validation loss: 2.278262335269995

Epoch: 6| Step: 1
Training loss: 0.43036222368677063
Validation loss: 2.187850213326617

Epoch: 6| Step: 2
Training loss: 0.6269839745653192
Validation loss: 2.2180715072623842

Epoch: 6| Step: 3
Training loss: 0.8583488580231828
Validation loss: 2.196396469982686

Epoch: 6| Step: 4
Training loss: 0.6008714942964769
Validation loss: 2.239525616286756

Epoch: 6| Step: 5
Training loss: 0.47959233809412627
Validation loss: 2.2455314856274944

Epoch: 6| Step: 6
Training loss: 0.682733615883989
Validation loss: 2.2447418781434347

Epoch: 6| Step: 7
Training loss: 0.7352216993460755
Validation loss: 2.2237221932357105

Epoch: 6| Step: 8
Training loss: 0.44428626820389994
Validation loss: 2.175272312026867

Epoch: 6| Step: 9
Training loss: 0.6141412621380643
Validation loss: 2.2017016281576764

Epoch: 6| Step: 10
Training loss: 0.9041658969881734
Validation loss: 2.2104651593250493

Epoch: 6| Step: 11
Training loss: 0.5192379230973704
Validation loss: 2.212476065072686

Epoch: 6| Step: 12
Training loss: 1.7166721615502767
Validation loss: 2.2132947017907414

Epoch: 6| Step: 13
Training loss: 0.6972999030056941
Validation loss: 2.1421001403438904

Epoch: 598| Step: 0
Training loss: 0.6101649617099499
Validation loss: 2.2464182538230064

Epoch: 6| Step: 1
Training loss: 0.763792413823106
Validation loss: 2.157198054460646

Epoch: 6| Step: 2
Training loss: 0.6016386157345183
Validation loss: 2.231743953916917

Epoch: 6| Step: 3
Training loss: 0.5274261127720381
Validation loss: 2.1884734043304044

Epoch: 6| Step: 4
Training loss: 0.6024976620292414
Validation loss: 2.26911695299227

Epoch: 6| Step: 5
Training loss: 0.6244901484864598
Validation loss: 2.1615815444938464

Epoch: 6| Step: 6
Training loss: 0.6625196822859492
Validation loss: 2.2075796895143878

Epoch: 6| Step: 7
Training loss: 0.6452991881394552
Validation loss: 2.226091500799061

Epoch: 6| Step: 8
Training loss: 0.6992892863748634
Validation loss: 2.250604599558164

Epoch: 6| Step: 9
Training loss: 0.6649611507268202
Validation loss: 2.229871260351219

Epoch: 6| Step: 10
Training loss: 1.6760065242986308
Validation loss: 2.288311753549885

Epoch: 6| Step: 11
Training loss: 0.4044934960256177
Validation loss: 2.2830497249247395

Epoch: 6| Step: 12
Training loss: 0.866353776888943
Validation loss: 2.1810843104638553

Epoch: 6| Step: 13
Training loss: 0.700062929458289
Validation loss: 2.2454541451770775

Epoch: 599| Step: 0
Training loss: 0.4571357020814418
Validation loss: 2.251844051522816

Epoch: 6| Step: 1
Training loss: 0.9894923753931362
Validation loss: 2.239679887258978

Epoch: 6| Step: 2
Training loss: 0.7575457781943136
Validation loss: 2.2702424246836928

Epoch: 6| Step: 3
Training loss: 0.7381154030507866
Validation loss: 2.1731898347860747

Epoch: 6| Step: 4
Training loss: 0.5791442752415886
Validation loss: 2.242403721782262

Epoch: 6| Step: 5
Training loss: 0.6782891588995605
Validation loss: 2.237399451651946

Epoch: 6| Step: 6
Training loss: 0.5946149799672675
Validation loss: 2.179526818975747

Epoch: 6| Step: 7
Training loss: 0.6572566032629342
Validation loss: 2.2439864122146327

Epoch: 6| Step: 8
Training loss: 0.6174779281069233
Validation loss: 2.253500136432757

Epoch: 6| Step: 9
Training loss: 0.5535200217105367
Validation loss: 2.2525960855352687

Epoch: 6| Step: 10
Training loss: 1.698155072408913
Validation loss: 2.270566982451419

Epoch: 6| Step: 11
Training loss: 0.6819365987393291
Validation loss: 2.2532855693611284

Epoch: 6| Step: 12
Training loss: 0.6607122844680465
Validation loss: 2.2517953435737526

Epoch: 6| Step: 13
Training loss: 0.7221446107668174
Validation loss: 2.163460484548178

Epoch: 600| Step: 0
Training loss: 0.6478720118067147
Validation loss: 2.215486698990994

Epoch: 6| Step: 1
Training loss: 0.7327570847500997
Validation loss: 2.1949712039642284

Epoch: 6| Step: 2
Training loss: 0.6013771861608902
Validation loss: 2.18166379310102

Epoch: 6| Step: 3
Training loss: 0.8431071905767653
Validation loss: 2.1948981292714826

Epoch: 6| Step: 4
Training loss: 0.8897127197357108
Validation loss: 2.2728596888885217

Epoch: 6| Step: 5
Training loss: 0.5548038897837287
Validation loss: 2.1893271782981905

Epoch: 6| Step: 6
Training loss: 0.6189097024984546
Validation loss: 2.2934113846180586

Epoch: 6| Step: 7
Training loss: 0.37398056700907234
Validation loss: 2.144158839494725

Epoch: 6| Step: 8
Training loss: 1.6383266517267485
Validation loss: 2.217908252136504

Epoch: 6| Step: 9
Training loss: 0.9010367567924543
Validation loss: 2.257289878928966

Epoch: 6| Step: 10
Training loss: 0.542638390025023
Validation loss: 2.265870544004706

Epoch: 6| Step: 11
Training loss: 0.7915670097936449
Validation loss: 2.1756002301837034

Epoch: 6| Step: 12
Training loss: 0.7221119248294519
Validation loss: 2.2256733461606

Epoch: 6| Step: 13
Training loss: 0.6215901100850307
Validation loss: 2.241485450349663

Epoch: 601| Step: 0
Training loss: 0.3751832395137251
Validation loss: 2.1942374874020407

Epoch: 6| Step: 1
Training loss: 0.4650878585855468
Validation loss: 2.163589376065082

Epoch: 6| Step: 2
Training loss: 0.625229221271751
Validation loss: 2.354589113654635

Epoch: 6| Step: 3
Training loss: 0.5754396084966114
Validation loss: 2.2113953385975553

Epoch: 6| Step: 4
Training loss: 0.7992078256466394
Validation loss: 2.22772818165709

Epoch: 6| Step: 5
Training loss: 0.5429778612868071
Validation loss: 2.1811149510934547

Epoch: 6| Step: 6
Training loss: 0.5241486572159635
Validation loss: 2.2810488713484536

Epoch: 6| Step: 7
Training loss: 0.5299388750384407
Validation loss: 2.2283311078531587

Epoch: 6| Step: 8
Training loss: 0.5990300066537674
Validation loss: 2.241937131203127

Epoch: 6| Step: 9
Training loss: 0.8531729492574202
Validation loss: 2.2586140728950737

Epoch: 6| Step: 10
Training loss: 0.7211190034323087
Validation loss: 2.256854201143658

Epoch: 6| Step: 11
Training loss: 0.7342482112438011
Validation loss: 2.1121520472162953

Epoch: 6| Step: 12
Training loss: 1.6773773630627171
Validation loss: 2.2139178791802734

Epoch: 6| Step: 13
Training loss: 0.5890219312707153
Validation loss: 2.2112425387857924

Epoch: 602| Step: 0
Training loss: 0.5243742801629492
Validation loss: 2.210954599471268

Epoch: 6| Step: 1
Training loss: 0.7190550281280684
Validation loss: 2.177623699577709

Epoch: 6| Step: 2
Training loss: 0.7883629294385159
Validation loss: 2.2741822863404453

Epoch: 6| Step: 3
Training loss: 0.6856951648275762
Validation loss: 2.29319304443106

Epoch: 6| Step: 4
Training loss: 1.7560031649532775
Validation loss: 2.240499020705055

Epoch: 6| Step: 5
Training loss: 0.8110727098234919
Validation loss: 2.2274167949078487

Epoch: 6| Step: 6
Training loss: 0.812160787932049
Validation loss: 2.291004600610627

Epoch: 6| Step: 7
Training loss: 0.7448638845434731
Validation loss: 2.259206726364446

Epoch: 6| Step: 8
Training loss: 0.9021948489242305
Validation loss: 2.2452786198229395

Epoch: 6| Step: 9
Training loss: 0.4657795406388247
Validation loss: 2.2893113062635733

Epoch: 6| Step: 10
Training loss: 0.6189015164443481
Validation loss: 2.247759087646151

Epoch: 6| Step: 11
Training loss: 0.6212697289632729
Validation loss: 2.180074714348572

Epoch: 6| Step: 12
Training loss: 0.3466308774301944
Validation loss: 2.242077274535194

Epoch: 6| Step: 13
Training loss: 0.6558081865356951
Validation loss: 2.2550450577356753

Epoch: 603| Step: 0
Training loss: 0.546363127798286
Validation loss: 2.2890304837019

Epoch: 6| Step: 1
Training loss: 0.5444342232602162
Validation loss: 2.2163567340312524

Epoch: 6| Step: 2
Training loss: 0.6803008633390683
Validation loss: 2.1971149655263384

Epoch: 6| Step: 3
Training loss: 0.5146789541733643
Validation loss: 2.167141668449305

Epoch: 6| Step: 4
Training loss: 0.7269824465373251
Validation loss: 2.254959965993446

Epoch: 6| Step: 5
Training loss: 0.5897110038079988
Validation loss: 2.2475314094376047

Epoch: 6| Step: 6
Training loss: 0.7024421767197828
Validation loss: 2.2863273301834885

Epoch: 6| Step: 7
Training loss: 0.6136727753747349
Validation loss: 2.2645468460870157

Epoch: 6| Step: 8
Training loss: 1.761338288021314
Validation loss: 2.2398366702302477

Epoch: 6| Step: 9
Training loss: 0.6432354935760894
Validation loss: 2.2250904305454084

Epoch: 6| Step: 10
Training loss: 0.7487833565874621
Validation loss: 2.222946662153418

Epoch: 6| Step: 11
Training loss: 0.5922974335985359
Validation loss: 2.3251737961662067

Epoch: 6| Step: 12
Training loss: 0.644346268436049
Validation loss: 2.190083259062396

Epoch: 6| Step: 13
Training loss: 0.49612504755252024
Validation loss: 2.2281398054565673

Epoch: 604| Step: 0
Training loss: 0.6696241512410701
Validation loss: 2.19343186981525

Epoch: 6| Step: 1
Training loss: 0.5362445318836908
Validation loss: 2.180519907443791

Epoch: 6| Step: 2
Training loss: 0.48745751134629933
Validation loss: 2.2273642327999412

Epoch: 6| Step: 3
Training loss: 0.7934983087219982
Validation loss: 2.2161499259001602

Epoch: 6| Step: 4
Training loss: 0.7933940780314785
Validation loss: 2.181312149626411

Epoch: 6| Step: 5
Training loss: 0.6675759660876762
Validation loss: 2.1353427645072984

Epoch: 6| Step: 6
Training loss: 1.898831613078756
Validation loss: 2.1512558527095456

Epoch: 6| Step: 7
Training loss: 0.7468302821095827
Validation loss: 2.2190228533768193

Epoch: 6| Step: 8
Training loss: 0.7056525260347596
Validation loss: 2.2434968398619013

Epoch: 6| Step: 9
Training loss: 0.5435502759759249
Validation loss: 2.163139777662894

Epoch: 6| Step: 10
Training loss: 0.5804446054933325
Validation loss: 2.211215439585978

Epoch: 6| Step: 11
Training loss: 0.6052871431742013
Validation loss: 2.246820162619773

Epoch: 6| Step: 12
Training loss: 0.7281718324981664
Validation loss: 2.25603775890955

Epoch: 6| Step: 13
Training loss: 0.45731524259697104
Validation loss: 2.1664243060490183

Epoch: 605| Step: 0
Training loss: 0.7401649221081765
Validation loss: 2.3044314946363387

Epoch: 6| Step: 1
Training loss: 0.6372477668223231
Validation loss: 2.1646918091140672

Epoch: 6| Step: 2
Training loss: 0.7112556835410068
Validation loss: 2.1714742969157714

Epoch: 6| Step: 3
Training loss: 0.6277876674056919
Validation loss: 2.1957431966728036

Epoch: 6| Step: 4
Training loss: 0.5302139164518876
Validation loss: 2.271968718776666

Epoch: 6| Step: 5
Training loss: 1.6434403015333352
Validation loss: 2.231340323989399

Epoch: 6| Step: 6
Training loss: 0.6409271737117297
Validation loss: 2.286695528356198

Epoch: 6| Step: 7
Training loss: 0.6197272088221496
Validation loss: 2.1706244154899745

Epoch: 6| Step: 8
Training loss: 0.5382635858347594
Validation loss: 2.2682106525258967

Epoch: 6| Step: 9
Training loss: 0.8429541189711149
Validation loss: 2.203410611635431

Epoch: 6| Step: 10
Training loss: 0.3538289657316624
Validation loss: 2.166822856955972

Epoch: 6| Step: 11
Training loss: 0.6075931810414525
Validation loss: 2.167962338431531

Epoch: 6| Step: 12
Training loss: 0.7238998023507008
Validation loss: 2.2326124660048348

Epoch: 6| Step: 13
Training loss: 0.7140588672637354
Validation loss: 2.21428717454439

Epoch: 606| Step: 0
Training loss: 0.5031611826426076
Validation loss: 2.201434703382214

Epoch: 6| Step: 1
Training loss: 0.5489003958581299
Validation loss: 2.221568855334703

Epoch: 6| Step: 2
Training loss: 1.7315651754769263
Validation loss: 2.206100933666949

Epoch: 6| Step: 3
Training loss: 0.601476613638911
Validation loss: 2.2361405930176086

Epoch: 6| Step: 4
Training loss: 0.7275340240099232
Validation loss: 2.2035501640476074

Epoch: 6| Step: 5
Training loss: 0.7817875729233604
Validation loss: 2.2254735201056057

Epoch: 6| Step: 6
Training loss: 0.6673260547146997
Validation loss: 2.1283243104028404

Epoch: 6| Step: 7
Training loss: 0.5045140467333767
Validation loss: 2.264484304780255

Epoch: 6| Step: 8
Training loss: 0.6585652518300436
Validation loss: 2.2059934036761977

Epoch: 6| Step: 9
Training loss: 0.6106159095517002
Validation loss: 2.2872209419192977

Epoch: 6| Step: 10
Training loss: 0.736858308585275
Validation loss: 2.1909624686109987

Epoch: 6| Step: 11
Training loss: 0.7162187620078326
Validation loss: 2.2105946362128117

Epoch: 6| Step: 12
Training loss: 0.8125871098112137
Validation loss: 2.2025461046526624

Epoch: 6| Step: 13
Training loss: 0.5148626240120154
Validation loss: 2.2420538365471225

Epoch: 607| Step: 0
Training loss: 0.7279944306883681
Validation loss: 2.282621177518281

Epoch: 6| Step: 1
Training loss: 0.7261304493662039
Validation loss: 2.1573372255264323

Epoch: 6| Step: 2
Training loss: 0.8967995681675731
Validation loss: 2.206725989221174

Epoch: 6| Step: 3
Training loss: 0.674999335959779
Validation loss: 2.2135305509825023

Epoch: 6| Step: 4
Training loss: 0.3842484925041336
Validation loss: 2.2291099415384292

Epoch: 6| Step: 5
Training loss: 0.7126515026641144
Validation loss: 2.2008482031601315

Epoch: 6| Step: 6
Training loss: 0.5551233862424164
Validation loss: 2.24753603475765

Epoch: 6| Step: 7
Training loss: 0.6376524555941219
Validation loss: 2.2144575781955034

Epoch: 6| Step: 8
Training loss: 0.612078635606944
Validation loss: 2.1738594534302305

Epoch: 6| Step: 9
Training loss: 1.6582873786935943
Validation loss: 2.2657823360184035

Epoch: 6| Step: 10
Training loss: 0.7297919090445556
Validation loss: 2.2280789369378797

Epoch: 6| Step: 11
Training loss: 0.6689176679036364
Validation loss: 2.293916756216251

Epoch: 6| Step: 12
Training loss: 0.5438918904176331
Validation loss: 2.195614907751724

Epoch: 6| Step: 13
Training loss: 0.8540513650871084
Validation loss: 2.2379125667880753

Epoch: 608| Step: 0
Training loss: 0.592924749176774
Validation loss: 2.251368706803802

Epoch: 6| Step: 1
Training loss: 0.7294706573781693
Validation loss: 2.2158034067700285

Epoch: 6| Step: 2
Training loss: 1.66805036644398
Validation loss: 2.213851442225905

Epoch: 6| Step: 3
Training loss: 0.5788490555447039
Validation loss: 2.231446027097042

Epoch: 6| Step: 4
Training loss: 0.6155813782626783
Validation loss: 2.3182649488578004

Epoch: 6| Step: 5
Training loss: 0.6462334091004799
Validation loss: 2.162274270525914

Epoch: 6| Step: 6
Training loss: 0.7371030013754443
Validation loss: 2.19659283728001

Epoch: 6| Step: 7
Training loss: 0.8358953590109982
Validation loss: 2.189655584942025

Epoch: 6| Step: 8
Training loss: 0.542766890292438
Validation loss: 2.2119571148363946

Epoch: 6| Step: 9
Training loss: 0.543999879794949
Validation loss: 2.1945785990763995

Epoch: 6| Step: 10
Training loss: 0.6501964244792914
Validation loss: 2.2053482287121957

Epoch: 6| Step: 11
Training loss: 0.5369144155224319
Validation loss: 2.187839788717514

Epoch: 6| Step: 12
Training loss: 0.5773012633428292
Validation loss: 2.2181653123727187

Epoch: 6| Step: 13
Training loss: 0.815037579401396
Validation loss: 2.24897490100522

Epoch: 609| Step: 0
Training loss: 0.5879625042034416
Validation loss: 2.1973559674247816

Epoch: 6| Step: 1
Training loss: 0.5924492692757282
Validation loss: 2.2474091252983937

Epoch: 6| Step: 2
Training loss: 0.7188162151187926
Validation loss: 2.1670183325486945

Epoch: 6| Step: 3
Training loss: 0.4358924897177235
Validation loss: 2.218092830171806

Epoch: 6| Step: 4
Training loss: 0.6356079147278206
Validation loss: 2.1377296192970223

Epoch: 6| Step: 5
Training loss: 0.6502635476542787
Validation loss: 2.150578726393851

Epoch: 6| Step: 6
Training loss: 1.6671130377346093
Validation loss: 2.1934732010145033

Epoch: 6| Step: 7
Training loss: 0.8249871166263673
Validation loss: 2.2611011561127334

Epoch: 6| Step: 8
Training loss: 0.5706040669139517
Validation loss: 2.1878853735328048

Epoch: 6| Step: 9
Training loss: 0.5549687491889016
Validation loss: 2.1518332622278225

Epoch: 6| Step: 10
Training loss: 0.8471398956308634
Validation loss: 2.18320927462002

Epoch: 6| Step: 11
Training loss: 0.6617596808411043
Validation loss: 2.1939911032907142

Epoch: 6| Step: 12
Training loss: 0.39668948876552684
Validation loss: 2.1877358398813205

Epoch: 6| Step: 13
Training loss: 0.5481789710464655
Validation loss: 2.2556688774926044

Epoch: 610| Step: 0
Training loss: 0.6829217059624666
Validation loss: 2.191202822793248

Epoch: 6| Step: 1
Training loss: 0.49137326662024244
Validation loss: 2.2405633276571995

Epoch: 6| Step: 2
Training loss: 0.7900657696447682
Validation loss: 2.2172679373702806

Epoch: 6| Step: 3
Training loss: 0.7284082737594694
Validation loss: 2.2333721661516677

Epoch: 6| Step: 4
Training loss: 0.7631149407550936
Validation loss: 2.263052916646596

Epoch: 6| Step: 5
Training loss: 0.4879182152624446
Validation loss: 2.2341414315966563

Epoch: 6| Step: 6
Training loss: 0.5696593424439872
Validation loss: 2.2669991088228105

Epoch: 6| Step: 7
Training loss: 1.700578798607891
Validation loss: 2.265084818600821

Epoch: 6| Step: 8
Training loss: 0.5284579903246751
Validation loss: 2.2900561590527535

Epoch: 6| Step: 9
Training loss: 0.7054312923114667
Validation loss: 2.2554686286530377

Epoch: 6| Step: 10
Training loss: 0.7313544060274257
Validation loss: 2.1820486700303134

Epoch: 6| Step: 11
Training loss: 0.5548355012547469
Validation loss: 2.094313055276625

Epoch: 6| Step: 12
Training loss: 0.5311836593943314
Validation loss: 2.213037571025253

Epoch: 6| Step: 13
Training loss: 0.5324718784912233
Validation loss: 2.186756809985805

Epoch: 611| Step: 0
Training loss: 0.5514207198464993
Validation loss: 2.1297109846514655

Epoch: 6| Step: 1
Training loss: 0.6490772951631872
Validation loss: 2.2352692346141287

Epoch: 6| Step: 2
Training loss: 1.709074983647117
Validation loss: 2.142733224458816

Epoch: 6| Step: 3
Training loss: 0.7508450356974672
Validation loss: 2.167177217862524

Epoch: 6| Step: 4
Training loss: 0.6622015289721613
Validation loss: 2.2708311695255277

Epoch: 6| Step: 5
Training loss: 0.655663068882539
Validation loss: 2.238714524000372

Epoch: 6| Step: 6
Training loss: 0.5759239051112631
Validation loss: 2.212837606629281

Epoch: 6| Step: 7
Training loss: 0.6930722568969689
Validation loss: 2.282212842389404

Epoch: 6| Step: 8
Training loss: 0.7911065320182761
Validation loss: 2.1862249405639065

Epoch: 6| Step: 9
Training loss: 0.5713692633258032
Validation loss: 2.149609703754206

Epoch: 6| Step: 10
Training loss: 0.7644908445445011
Validation loss: 2.3305464547777173

Epoch: 6| Step: 11
Training loss: 0.5267730450434461
Validation loss: 2.2104911323174266

Epoch: 6| Step: 12
Training loss: 0.5026676421198162
Validation loss: 2.228085521845368

Epoch: 6| Step: 13
Training loss: 0.8621208020772191
Validation loss: 2.231559663496993

Epoch: 612| Step: 0
Training loss: 0.8292764180517698
Validation loss: 2.2675977040109134

Epoch: 6| Step: 1
Training loss: 0.5773260937211859
Validation loss: 2.183662231059465

Epoch: 6| Step: 2
Training loss: 0.6198531181794898
Validation loss: 2.1603932225012246

Epoch: 6| Step: 3
Training loss: 0.7219009576399307
Validation loss: 2.2571598152365184

Epoch: 6| Step: 4
Training loss: 0.7263498712964567
Validation loss: 2.2278700714773474

Epoch: 6| Step: 5
Training loss: 0.4867909844742629
Validation loss: 2.1725786653423738

Epoch: 6| Step: 6
Training loss: 0.6127415365695299
Validation loss: 2.1890278644425556

Epoch: 6| Step: 7
Training loss: 0.6930810719046057
Validation loss: 2.223607364250075

Epoch: 6| Step: 8
Training loss: 0.5775736164054815
Validation loss: 2.232859117876992

Epoch: 6| Step: 9
Training loss: 0.6298992302699276
Validation loss: 2.2758640388854166

Epoch: 6| Step: 10
Training loss: 0.7740098781201776
Validation loss: 2.2006331558137684

Epoch: 6| Step: 11
Training loss: 1.7111162066211767
Validation loss: 2.2502247841643377

Epoch: 6| Step: 12
Training loss: 0.8028848697270113
Validation loss: 2.17330811561161

Epoch: 6| Step: 13
Training loss: 0.37884222059878087
Validation loss: 2.2311400741955127

Epoch: 613| Step: 0
Training loss: 0.6102636167108039
Validation loss: 2.198345943913165

Epoch: 6| Step: 1
Training loss: 0.6871643764392302
Validation loss: 2.276200141401011

Epoch: 6| Step: 2
Training loss: 0.5102576150713746
Validation loss: 2.189449964726327

Epoch: 6| Step: 3
Training loss: 0.7835584866470483
Validation loss: 2.135245130258686

Epoch: 6| Step: 4
Training loss: 0.6959248107657751
Validation loss: 2.117024069718337

Epoch: 6| Step: 5
Training loss: 0.5339389516602405
Validation loss: 2.2570022200348414

Epoch: 6| Step: 6
Training loss: 1.6734558902303434
Validation loss: 2.2756280675078346

Epoch: 6| Step: 7
Training loss: 0.5655803578500234
Validation loss: 2.295205786673518

Epoch: 6| Step: 8
Training loss: 0.5968478101758722
Validation loss: 2.1818734370130586

Epoch: 6| Step: 9
Training loss: 0.6172663964171491
Validation loss: 2.1785724993204054

Epoch: 6| Step: 10
Training loss: 0.4854961924290664
Validation loss: 2.22631300064611

Epoch: 6| Step: 11
Training loss: 0.7537600518816867
Validation loss: 2.190910369381507

Epoch: 6| Step: 12
Training loss: 0.5992182347421035
Validation loss: 2.1912676884562976

Epoch: 6| Step: 13
Training loss: 0.41543635482710595
Validation loss: 2.2405445696511253

Epoch: 614| Step: 0
Training loss: 0.6606164265115099
Validation loss: 2.279556653975825

Epoch: 6| Step: 1
Training loss: 0.4445779162484762
Validation loss: 2.21253266724945

Epoch: 6| Step: 2
Training loss: 0.6554542894552893
Validation loss: 2.2828939551652723

Epoch: 6| Step: 3
Training loss: 0.6847509997340714
Validation loss: 2.260907359532182

Epoch: 6| Step: 4
Training loss: 1.6100093739396626
Validation loss: 2.1499162219781534

Epoch: 6| Step: 5
Training loss: 0.5484776039350012
Validation loss: 2.1843476535775905

Epoch: 6| Step: 6
Training loss: 0.6810882866384996
Validation loss: 2.1789300391727693

Epoch: 6| Step: 7
Training loss: 0.8888449699426476
Validation loss: 2.1740110217004833

Epoch: 6| Step: 8
Training loss: 0.6649034448668382
Validation loss: 2.236412594203885

Epoch: 6| Step: 9
Training loss: 0.6258133364486781
Validation loss: 2.1804896423244484

Epoch: 6| Step: 10
Training loss: 0.2588317979758692
Validation loss: 2.233016537027814

Epoch: 6| Step: 11
Training loss: 0.8326729104609939
Validation loss: 2.1929932094714033

Epoch: 6| Step: 12
Training loss: 0.4410595164998801
Validation loss: 2.1935803975169517

Epoch: 6| Step: 13
Training loss: 0.27888635997213496
Validation loss: 2.196787364178413

Epoch: 615| Step: 0
Training loss: 0.4789882583473188
Validation loss: 2.1473584424781387

Epoch: 6| Step: 1
Training loss: 0.5675669911205526
Validation loss: 2.262979202589003

Epoch: 6| Step: 2
Training loss: 0.6263455212625179
Validation loss: 2.2221674790185375

Epoch: 6| Step: 3
Training loss: 0.8814494658020883
Validation loss: 2.2296237294891124

Epoch: 6| Step: 4
Training loss: 0.5944244669838256
Validation loss: 2.229801403489339

Epoch: 6| Step: 5
Training loss: 1.6891534969579882
Validation loss: 2.182570762642489

Epoch: 6| Step: 6
Training loss: 0.5519643481410087
Validation loss: 2.1928630539755605

Epoch: 6| Step: 7
Training loss: 0.5668762361792699
Validation loss: 2.2521511866964716

Epoch: 6| Step: 8
Training loss: 0.5310034460254066
Validation loss: 2.232871432820379

Epoch: 6| Step: 9
Training loss: 0.5659860301787476
Validation loss: 2.196189476612338

Epoch: 6| Step: 10
Training loss: 0.5754398156586946
Validation loss: 2.1623233156081705

Epoch: 6| Step: 11
Training loss: 0.528058732970982
Validation loss: 2.1343482965797484

Epoch: 6| Step: 12
Training loss: 0.4213826874399794
Validation loss: 2.2218033554345706

Epoch: 6| Step: 13
Training loss: 0.7362027656027559
Validation loss: 2.171665377772758

Epoch: 616| Step: 0
Training loss: 0.5015836907304331
Validation loss: 2.1911272642703747

Epoch: 6| Step: 1
Training loss: 0.5293172008933108
Validation loss: 2.241391784261918

Epoch: 6| Step: 2
Training loss: 0.6787816072625237
Validation loss: 2.244232433175445

Epoch: 6| Step: 3
Training loss: 0.5188064395121808
Validation loss: 2.248490370608744

Epoch: 6| Step: 4
Training loss: 0.6073156920228735
Validation loss: 2.1452177088344886

Epoch: 6| Step: 5
Training loss: 0.659238775925172
Validation loss: 2.1865775265477536

Epoch: 6| Step: 6
Training loss: 1.652185599331586
Validation loss: 2.189860031553651

Epoch: 6| Step: 7
Training loss: 0.5395844185817021
Validation loss: 2.2137644770112357

Epoch: 6| Step: 8
Training loss: 0.48115475071188285
Validation loss: 2.2532133141004262

Epoch: 6| Step: 9
Training loss: 0.7401800211172913
Validation loss: 2.200716395000229

Epoch: 6| Step: 10
Training loss: 0.6592474330422482
Validation loss: 2.1739737768481744

Epoch: 6| Step: 11
Training loss: 0.4994062086673082
Validation loss: 2.291642387089988

Epoch: 6| Step: 12
Training loss: 0.608546745629965
Validation loss: 2.15339377309136

Epoch: 6| Step: 13
Training loss: 0.5965067711243583
Validation loss: 2.2322922079160974

Epoch: 617| Step: 0
Training loss: 0.584212803898374
Validation loss: 2.2065822332227407

Epoch: 6| Step: 1
Training loss: 0.5502437918216183
Validation loss: 2.2249596817365926

Epoch: 6| Step: 2
Training loss: 0.7191516748974959
Validation loss: 2.224874069647836

Epoch: 6| Step: 3
Training loss: 0.6544385841979248
Validation loss: 2.185473272870578

Epoch: 6| Step: 4
Training loss: 0.5129708557829336
Validation loss: 2.2724533586825935

Epoch: 6| Step: 5
Training loss: 0.5829193201429586
Validation loss: 2.2203100515352983

Epoch: 6| Step: 6
Training loss: 0.5734794944333295
Validation loss: 2.1456610334375563

Epoch: 6| Step: 7
Training loss: 0.4462772259300742
Validation loss: 2.172589158458072

Epoch: 6| Step: 8
Training loss: 0.8585915201868012
Validation loss: 2.223806018420855

Epoch: 6| Step: 9
Training loss: 0.6873991632205064
Validation loss: 2.2467389510215825

Epoch: 6| Step: 10
Training loss: 0.8273580346391728
Validation loss: 2.2572223391488317

Epoch: 6| Step: 11
Training loss: 1.6174351599313128
Validation loss: 2.249082028252622

Epoch: 6| Step: 12
Training loss: 0.6530289392236472
Validation loss: 2.235703151390199

Epoch: 6| Step: 13
Training loss: 0.672933210891939
Validation loss: 2.1454453972368963

Epoch: 618| Step: 0
Training loss: 0.5265133288599139
Validation loss: 2.149689085224616

Epoch: 6| Step: 1
Training loss: 0.6827877415548317
Validation loss: 2.1311673864882246

Epoch: 6| Step: 2
Training loss: 0.6687809874583689
Validation loss: 2.2214425529379587

Epoch: 6| Step: 3
Training loss: 0.47964571419794083
Validation loss: 2.2738503479916576

Epoch: 6| Step: 4
Training loss: 0.6155921501263976
Validation loss: 2.1408130134139935

Epoch: 6| Step: 5
Training loss: 0.4581201899433417
Validation loss: 2.210014213383971

Epoch: 6| Step: 6
Training loss: 0.6228468044574162
Validation loss: 2.252499597955556

Epoch: 6| Step: 7
Training loss: 0.6165933042353242
Validation loss: 2.189332773780329

Epoch: 6| Step: 8
Training loss: 0.5367864574386982
Validation loss: 2.1224250991245985

Epoch: 6| Step: 9
Training loss: 0.46221559130948714
Validation loss: 2.1874559729111103

Epoch: 6| Step: 10
Training loss: 1.5930750296452914
Validation loss: 2.2358728080266386

Epoch: 6| Step: 11
Training loss: 0.8759746232537585
Validation loss: 2.203490019387801

Epoch: 6| Step: 12
Training loss: 0.4330618921353543
Validation loss: 2.1783816311177553

Epoch: 6| Step: 13
Training loss: 0.6446644732032957
Validation loss: 2.191613424923912

Epoch: 619| Step: 0
Training loss: 0.733303424557636
Validation loss: 2.214550520851655

Epoch: 6| Step: 1
Training loss: 0.7095827042253371
Validation loss: 2.132823275301825

Epoch: 6| Step: 2
Training loss: 0.6507133622497184
Validation loss: 2.2784144475273216

Epoch: 6| Step: 3
Training loss: 0.35191403932981
Validation loss: 2.2020525696326114

Epoch: 6| Step: 4
Training loss: 0.6874784552926343
Validation loss: 2.170812752356306

Epoch: 6| Step: 5
Training loss: 0.5490538109323593
Validation loss: 2.2112304697470604

Epoch: 6| Step: 6
Training loss: 0.5497823815707881
Validation loss: 2.192475792926854

Epoch: 6| Step: 7
Training loss: 0.48698798764921464
Validation loss: 2.2191805008098107

Epoch: 6| Step: 8
Training loss: 0.5719869410284576
Validation loss: 2.2095756677619964

Epoch: 6| Step: 9
Training loss: 1.7034568813231228
Validation loss: 2.189536531626345

Epoch: 6| Step: 10
Training loss: 0.4162870963065309
Validation loss: 2.2543569808570023

Epoch: 6| Step: 11
Training loss: 0.6573274940201699
Validation loss: 2.1994624376530725

Epoch: 6| Step: 12
Training loss: 0.5894977995044383
Validation loss: 2.2142835391359856

Epoch: 6| Step: 13
Training loss: 0.33106832560576693
Validation loss: 2.2297893969621243

Epoch: 620| Step: 0
Training loss: 0.49682471722664046
Validation loss: 2.2657596591963984

Epoch: 6| Step: 1
Training loss: 0.41646750180353725
Validation loss: 2.143708386473685

Epoch: 6| Step: 2
Training loss: 0.7005068459703826
Validation loss: 2.256686790995062

Epoch: 6| Step: 3
Training loss: 0.6344871027321815
Validation loss: 2.2199494520962517

Epoch: 6| Step: 4
Training loss: 0.4444052673580056
Validation loss: 2.227298706827109

Epoch: 6| Step: 5
Training loss: 0.7160319474727617
Validation loss: 2.109473372231306

Epoch: 6| Step: 6
Training loss: 0.5446261078405418
Validation loss: 2.230300115659202

Epoch: 6| Step: 7
Training loss: 0.7236160091039942
Validation loss: 2.158520560490746

Epoch: 6| Step: 8
Training loss: 0.6348448249118651
Validation loss: 2.3007375398688708

Epoch: 6| Step: 9
Training loss: 0.5321094069020922
Validation loss: 2.2644859067124075

Epoch: 6| Step: 10
Training loss: 1.7009083733210304
Validation loss: 2.1606616122756725

Epoch: 6| Step: 11
Training loss: 0.7068170676198907
Validation loss: 2.233415844235971

Epoch: 6| Step: 12
Training loss: 0.7114466007618746
Validation loss: 2.2266615322608447

Epoch: 6| Step: 13
Training loss: 0.3825481046708212
Validation loss: 2.1755891624077477

Epoch: 621| Step: 0
Training loss: 0.5778764241881977
Validation loss: 2.2543354468535846

Epoch: 6| Step: 1
Training loss: 0.6335253526903034
Validation loss: 2.191860470468438

Epoch: 6| Step: 2
Training loss: 0.4182047311462311
Validation loss: 2.201786587441522

Epoch: 6| Step: 3
Training loss: 0.6613414440852966
Validation loss: 2.1479199478377224

Epoch: 6| Step: 4
Training loss: 0.4628611044182273
Validation loss: 2.154330868634517

Epoch: 6| Step: 5
Training loss: 0.667082326671056
Validation loss: 2.252589529031291

Epoch: 6| Step: 6
Training loss: 0.9001751226013763
Validation loss: 2.2736343903514875

Epoch: 6| Step: 7
Training loss: 0.6595196334802728
Validation loss: 2.147056612818942

Epoch: 6| Step: 8
Training loss: 0.653693168314295
Validation loss: 2.2078050359547485

Epoch: 6| Step: 9
Training loss: 0.4475357039822437
Validation loss: 2.244351491023991

Epoch: 6| Step: 10
Training loss: 0.736611875708762
Validation loss: 2.2762857405151102

Epoch: 6| Step: 11
Training loss: 0.5841214583648933
Validation loss: 2.1868897209355103

Epoch: 6| Step: 12
Training loss: 0.6207382816371615
Validation loss: 2.1763149838189637

Epoch: 6| Step: 13
Training loss: 2.085176021729451
Validation loss: 2.181447809992549

Epoch: 622| Step: 0
Training loss: 0.48670022969041604
Validation loss: 2.197903564893075

Epoch: 6| Step: 1
Training loss: 0.5630814408232914
Validation loss: 2.229231543560519

Epoch: 6| Step: 2
Training loss: 0.5352265249179725
Validation loss: 2.3298612816435122

Epoch: 6| Step: 3
Training loss: 0.8326371543328172
Validation loss: 2.1946549896325864

Epoch: 6| Step: 4
Training loss: 0.7911416789270801
Validation loss: 2.1625826698020507

Epoch: 6| Step: 5
Training loss: 0.7217837866422163
Validation loss: 2.1626899393981605

Epoch: 6| Step: 6
Training loss: 0.5975091790647403
Validation loss: 2.2139040854516665

Epoch: 6| Step: 7
Training loss: 0.4422847816026027
Validation loss: 2.212944513273772

Epoch: 6| Step: 8
Training loss: 0.6985488324964413
Validation loss: 2.2185760145591544

Epoch: 6| Step: 9
Training loss: 0.7050035601045798
Validation loss: 2.2167763176418798

Epoch: 6| Step: 10
Training loss: 0.6532764961819696
Validation loss: 2.2023651225261163

Epoch: 6| Step: 11
Training loss: 0.5739246315820462
Validation loss: 2.2554599959069903

Epoch: 6| Step: 12
Training loss: 0.5196534780260581
Validation loss: 2.2485943069775463

Epoch: 6| Step: 13
Training loss: 2.22229108173919
Validation loss: 2.2324978680715253

Epoch: 623| Step: 0
Training loss: 0.7839385501562878
Validation loss: 2.1787552577925045

Epoch: 6| Step: 1
Training loss: 0.49260778496646834
Validation loss: 2.2167550985846707

Epoch: 6| Step: 2
Training loss: 0.5422726567038755
Validation loss: 2.251260996573823

Epoch: 6| Step: 3
Training loss: 0.6901037156205533
Validation loss: 2.190736970946104

Epoch: 6| Step: 4
Training loss: 0.5016543319153146
Validation loss: 2.2280583743660394

Epoch: 6| Step: 5
Training loss: 0.4924679365951993
Validation loss: 2.2774293742338134

Epoch: 6| Step: 6
Training loss: 0.6046414537665401
Validation loss: 2.1635038061073675

Epoch: 6| Step: 7
Training loss: 0.8199648892631493
Validation loss: 2.2307981118572617

Epoch: 6| Step: 8
Training loss: 0.7497467169643669
Validation loss: 2.2645344271719754

Epoch: 6| Step: 9
Training loss: 1.7172523909743875
Validation loss: 2.2227069684516203

Epoch: 6| Step: 10
Training loss: 0.6027723754058651
Validation loss: 2.280980575099021

Epoch: 6| Step: 11
Training loss: 0.8724555075813583
Validation loss: 2.211492239489327

Epoch: 6| Step: 12
Training loss: 0.628058104487642
Validation loss: 2.2165383103613725

Epoch: 6| Step: 13
Training loss: 0.4585258628597911
Validation loss: 2.140620300560866

Epoch: 624| Step: 0
Training loss: 0.6854941627690753
Validation loss: 2.1928848315601384

Epoch: 6| Step: 1
Training loss: 0.5033122561264821
Validation loss: 2.222888313810219

Epoch: 6| Step: 2
Training loss: 1.6733826586430596
Validation loss: 2.250788207641235

Epoch: 6| Step: 3
Training loss: 0.8752212925779117
Validation loss: 2.3100572639641306

Epoch: 6| Step: 4
Training loss: 0.6162963179307336
Validation loss: 2.1943119370009483

Epoch: 6| Step: 5
Training loss: 0.6473521145467356
Validation loss: 2.2309599345035185

Epoch: 6| Step: 6
Training loss: 0.6788385724047293
Validation loss: 2.1915083390489345

Epoch: 6| Step: 7
Training loss: 0.55197749532905
Validation loss: 2.2124930570593246

Epoch: 6| Step: 8
Training loss: 0.7666133418058991
Validation loss: 2.2100116514983545

Epoch: 6| Step: 9
Training loss: 0.5939579649671761
Validation loss: 2.110708059602714

Epoch: 6| Step: 10
Training loss: 0.7955875468222594
Validation loss: 2.2250000459035695

Epoch: 6| Step: 11
Training loss: 0.47520008139641706
Validation loss: 2.2075563791036705

Epoch: 6| Step: 12
Training loss: 0.5957130806513115
Validation loss: 2.1780805329852084

Epoch: 6| Step: 13
Training loss: 0.7266066342967344
Validation loss: 2.1592577073660006

Epoch: 625| Step: 0
Training loss: 1.70707992379566
Validation loss: 2.1288503283700804

Epoch: 6| Step: 1
Training loss: 0.6234322435353424
Validation loss: 2.2363827255353574

Epoch: 6| Step: 2
Training loss: 0.48011793339362324
Validation loss: 2.1807339907171226

Epoch: 6| Step: 3
Training loss: 0.5763851740792711
Validation loss: 2.1821421818410878

Epoch: 6| Step: 4
Training loss: 0.7833985348884258
Validation loss: 2.2141880102733364

Epoch: 6| Step: 5
Training loss: 0.7180775938663145
Validation loss: 2.2193066991781314

Epoch: 6| Step: 6
Training loss: 0.5672286278812049
Validation loss: 2.1586496056412368

Epoch: 6| Step: 7
Training loss: 0.5709257095196869
Validation loss: 2.2509200961931506

Epoch: 6| Step: 8
Training loss: 0.7064793577209049
Validation loss: 2.1786248147549188

Epoch: 6| Step: 9
Training loss: 0.5359739196681048
Validation loss: 2.2377721838299

Epoch: 6| Step: 10
Training loss: 0.6602014379441192
Validation loss: 2.1987408044138403

Epoch: 6| Step: 11
Training loss: 0.6811430462165076
Validation loss: 2.206068574467238

Epoch: 6| Step: 12
Training loss: 0.5734186112205923
Validation loss: 2.191811906199177

Epoch: 6| Step: 13
Training loss: 0.22346466939638845
Validation loss: 2.153932817569537

Epoch: 626| Step: 0
Training loss: 0.6000906041400624
Validation loss: 2.1727445049212033

Epoch: 6| Step: 1
Training loss: 0.6495008826481061
Validation loss: 2.287921400887656

Epoch: 6| Step: 2
Training loss: 0.5789858877820846
Validation loss: 2.2714015492134867

Epoch: 6| Step: 3
Training loss: 0.7035335413522243
Validation loss: 2.2291728278293363

Epoch: 6| Step: 4
Training loss: 0.6599199221900397
Validation loss: 2.2329562365719333

Epoch: 6| Step: 5
Training loss: 0.6238159885551643
Validation loss: 2.1828756261565987

Epoch: 6| Step: 6
Training loss: 0.39804068608287835
Validation loss: 2.2197763454292536

Epoch: 6| Step: 7
Training loss: 0.6870093328655488
Validation loss: 2.24702920502769

Epoch: 6| Step: 8
Training loss: 0.5714673929566025
Validation loss: 2.187415867607118

Epoch: 6| Step: 9
Training loss: 0.8376211164208268
Validation loss: 2.134421207837822

Epoch: 6| Step: 10
Training loss: 0.5777199073408903
Validation loss: 2.163080723898196

Epoch: 6| Step: 11
Training loss: 0.43166946729036276
Validation loss: 2.2208419746151233

Epoch: 6| Step: 12
Training loss: 1.7199059500597065
Validation loss: 2.1742690524904016

Epoch: 6| Step: 13
Training loss: 0.6478289540727321
Validation loss: 2.266690764428779

Epoch: 627| Step: 0
Training loss: 0.6252532207599769
Validation loss: 2.25406564142642

Epoch: 6| Step: 1
Training loss: 0.595554145569441
Validation loss: 2.2141661284441727

Epoch: 6| Step: 2
Training loss: 0.4548674984193093
Validation loss: 2.1408134008077853

Epoch: 6| Step: 3
Training loss: 0.5078807491509437
Validation loss: 2.2294133379253616

Epoch: 6| Step: 4
Training loss: 0.5446496645928585
Validation loss: 2.156772617365966

Epoch: 6| Step: 5
Training loss: 0.8490350996699115
Validation loss: 2.2125446695126882

Epoch: 6| Step: 6
Training loss: 1.6635287866191322
Validation loss: 2.173944522022065

Epoch: 6| Step: 7
Training loss: 0.7413286158411035
Validation loss: 2.24988587350936

Epoch: 6| Step: 8
Training loss: 0.5117503149183503
Validation loss: 2.2076390390646243

Epoch: 6| Step: 9
Training loss: 0.6629794095612143
Validation loss: 2.3466627609499167

Epoch: 6| Step: 10
Training loss: 0.5132549029458454
Validation loss: 2.216854821067995

Epoch: 6| Step: 11
Training loss: 0.6526855213047986
Validation loss: 2.193528537529236

Epoch: 6| Step: 12
Training loss: 0.4992426262102294
Validation loss: 2.2297494437224437

Epoch: 6| Step: 13
Training loss: 0.2799029277166959
Validation loss: 2.220790883994769

Epoch: 628| Step: 0
Training loss: 0.48223586106325533
Validation loss: 2.2401171348355047

Epoch: 6| Step: 1
Training loss: 0.707788725531584
Validation loss: 2.257074386373076

Epoch: 6| Step: 2
Training loss: 0.5717293371412451
Validation loss: 2.1567455731068885

Epoch: 6| Step: 3
Training loss: 0.4976035445014248
Validation loss: 2.2222825873148557

Epoch: 6| Step: 4
Training loss: 0.7863284039485037
Validation loss: 2.2309581743382947

Epoch: 6| Step: 5
Training loss: 0.5982902255995228
Validation loss: 2.1514764217452567

Epoch: 6| Step: 6
Training loss: 0.48861420532778393
Validation loss: 2.163108570714999

Epoch: 6| Step: 7
Training loss: 0.6516128374227322
Validation loss: 2.1521639696999273

Epoch: 6| Step: 8
Training loss: 0.8161743418752204
Validation loss: 2.1108902715138504

Epoch: 6| Step: 9
Training loss: 0.6813234394631046
Validation loss: 2.207079992791502

Epoch: 6| Step: 10
Training loss: 0.8826268768960499
Validation loss: 2.188879086386591

Epoch: 6| Step: 11
Training loss: 1.5968674482252865
Validation loss: 2.2073924969864405

Epoch: 6| Step: 12
Training loss: 0.6595278350372941
Validation loss: 2.217292963524074

Epoch: 6| Step: 13
Training loss: 0.7270012627948776
Validation loss: 2.129339238871476

Epoch: 629| Step: 0
Training loss: 0.6195736402750882
Validation loss: 2.267923937948386

Epoch: 6| Step: 1
Training loss: 0.5410004210831842
Validation loss: 2.1967303802234714

Epoch: 6| Step: 2
Training loss: 0.6823018318370284
Validation loss: 2.2574272742586756

Epoch: 6| Step: 3
Training loss: 0.5207935286252428
Validation loss: 2.2408468649000413

Epoch: 6| Step: 4
Training loss: 0.46550472933602965
Validation loss: 2.256319227165865

Epoch: 6| Step: 5
Training loss: 0.4872194418183833
Validation loss: 2.223360321926376

Epoch: 6| Step: 6
Training loss: 0.6739779319645357
Validation loss: 2.1682792756767726

Epoch: 6| Step: 7
Training loss: 0.592898058792542
Validation loss: 2.172849048826435

Epoch: 6| Step: 8
Training loss: 0.41751541080699917
Validation loss: 2.1812595886589503

Epoch: 6| Step: 9
Training loss: 0.6064889495924746
Validation loss: 2.244642213648046

Epoch: 6| Step: 10
Training loss: 0.6838614457365985
Validation loss: 2.2243339042969263

Epoch: 6| Step: 11
Training loss: 1.634527957097201
Validation loss: 2.163271187614703

Epoch: 6| Step: 12
Training loss: 0.9645088015956141
Validation loss: 2.140183354953519

Epoch: 6| Step: 13
Training loss: 0.5392788715388572
Validation loss: 2.144219979433565

Epoch: 630| Step: 0
Training loss: 0.5109672561053483
Validation loss: 2.1946894923943363

Epoch: 6| Step: 1
Training loss: 0.821934758033614
Validation loss: 2.224570379734982

Epoch: 6| Step: 2
Training loss: 0.5209512163906833
Validation loss: 2.1726735900575624

Epoch: 6| Step: 3
Training loss: 0.7246007378981115
Validation loss: 2.191276026566764

Epoch: 6| Step: 4
Training loss: 0.6485487601185058
Validation loss: 2.1774757800089115

Epoch: 6| Step: 5
Training loss: 0.6731107126913944
Validation loss: 2.2538576542949733

Epoch: 6| Step: 6
Training loss: 0.5544859291575374
Validation loss: 2.2250069222106954

Epoch: 6| Step: 7
Training loss: 1.5032686541586397
Validation loss: 2.202841007986565

Epoch: 6| Step: 8
Training loss: 0.40263570914464586
Validation loss: 2.1947147257801243

Epoch: 6| Step: 9
Training loss: 0.822577555516115
Validation loss: 2.217782664293251

Epoch: 6| Step: 10
Training loss: 0.606298726866699
Validation loss: 2.2406689080219206

Epoch: 6| Step: 11
Training loss: 0.43707527252609446
Validation loss: 2.2826484072211737

Epoch: 6| Step: 12
Training loss: 0.6500593836874435
Validation loss: 2.109131439622439

Epoch: 6| Step: 13
Training loss: 0.677529845583287
Validation loss: 2.201598097428274

Epoch: 631| Step: 0
Training loss: 0.7171430037913012
Validation loss: 2.2302390675810493

Epoch: 6| Step: 1
Training loss: 0.5909096390214792
Validation loss: 2.195534293888998

Epoch: 6| Step: 2
Training loss: 0.6222748472556469
Validation loss: 2.2072399479590366

Epoch: 6| Step: 3
Training loss: 0.6769201130860474
Validation loss: 2.1728431584065606

Epoch: 6| Step: 4
Training loss: 0.5507713479308529
Validation loss: 2.1860741980192246

Epoch: 6| Step: 5
Training loss: 0.6884672340139851
Validation loss: 2.1980784401909985

Epoch: 6| Step: 6
Training loss: 0.3177710169047592
Validation loss: 2.177870837081644

Epoch: 6| Step: 7
Training loss: 0.49448642015276806
Validation loss: 2.2642097463025572

Epoch: 6| Step: 8
Training loss: 0.736338445859262
Validation loss: 2.140096148948353

Epoch: 6| Step: 9
Training loss: 1.6645313014498915
Validation loss: 2.1998066134769876

Epoch: 6| Step: 10
Training loss: 0.5860615916774464
Validation loss: 2.221040391918967

Epoch: 6| Step: 11
Training loss: 0.67748783695381
Validation loss: 2.216449749148401

Epoch: 6| Step: 12
Training loss: 0.614877361072056
Validation loss: 2.17857345131297

Epoch: 6| Step: 13
Training loss: 0.2825859316168595
Validation loss: 2.157612233419444

Epoch: 632| Step: 0
Training loss: 0.3723997925056613
Validation loss: 2.180604518691363

Epoch: 6| Step: 1
Training loss: 0.7355005688305282
Validation loss: 2.1800735678051715

Epoch: 6| Step: 2
Training loss: 0.780021770124582
Validation loss: 2.1930097147235696

Epoch: 6| Step: 3
Training loss: 0.7142007155594009
Validation loss: 2.183991785933914

Epoch: 6| Step: 4
Training loss: 1.5761469918216673
Validation loss: 2.179617854309115

Epoch: 6| Step: 5
Training loss: 0.51097670471782
Validation loss: 2.1785923063284494

Epoch: 6| Step: 6
Training loss: 0.5547586852051777
Validation loss: 2.2130436301650356

Epoch: 6| Step: 7
Training loss: 0.6230700258360508
Validation loss: 2.249420404128366

Epoch: 6| Step: 8
Training loss: 0.554421374457481
Validation loss: 2.214205309837213

Epoch: 6| Step: 9
Training loss: 0.5979124779061611
Validation loss: 2.249185290439272

Epoch: 6| Step: 10
Training loss: 0.5564667011728196
Validation loss: 2.1929782495431325

Epoch: 6| Step: 11
Training loss: 0.5136348290374462
Validation loss: 2.179455717802853

Epoch: 6| Step: 12
Training loss: 0.7295475827674646
Validation loss: 2.23751048616505

Epoch: 6| Step: 13
Training loss: 0.660633952640441
Validation loss: 2.219294154172071

Epoch: 633| Step: 0
Training loss: 0.5984983806667873
Validation loss: 2.228025918691214

Epoch: 6| Step: 1
Training loss: 0.7970152338838372
Validation loss: 2.2257600850696995

Epoch: 6| Step: 2
Training loss: 0.5653232349074498
Validation loss: 2.0921527474078707

Epoch: 6| Step: 3
Training loss: 0.5082275161930073
Validation loss: 2.2092369819134126

Epoch: 6| Step: 4
Training loss: 0.6126508449169109
Validation loss: 2.27534959764817

Epoch: 6| Step: 5
Training loss: 0.6232038915925214
Validation loss: 2.180201751150466

Epoch: 6| Step: 6
Training loss: 0.7427389003960474
Validation loss: 2.182139510869141

Epoch: 6| Step: 7
Training loss: 0.6132108319911537
Validation loss: 2.1813006180959524

Epoch: 6| Step: 8
Training loss: 0.5918042525533466
Validation loss: 2.285787373276487

Epoch: 6| Step: 9
Training loss: 1.7069116895343885
Validation loss: 2.0701660915559263

Epoch: 6| Step: 10
Training loss: 0.6359846411625899
Validation loss: 2.1864741320913925

Epoch: 6| Step: 11
Training loss: 0.6113091852831269
Validation loss: 2.2544393940549767

Epoch: 6| Step: 12
Training loss: 0.7325060173021865
Validation loss: 2.1948587801725914

Epoch: 6| Step: 13
Training loss: 0.6903246161596472
Validation loss: 2.1735792221799644

Epoch: 634| Step: 0
Training loss: 0.6309057637924701
Validation loss: 2.1796079766588656

Epoch: 6| Step: 1
Training loss: 0.6312167923756867
Validation loss: 2.159667700475975

Epoch: 6| Step: 2
Training loss: 0.7742046058509896
Validation loss: 2.298344757778174

Epoch: 6| Step: 3
Training loss: 0.5442570284563529
Validation loss: 2.2443850487593324

Epoch: 6| Step: 4
Training loss: 0.6661957304288912
Validation loss: 2.289728920158249

Epoch: 6| Step: 5
Training loss: 0.483020364896728
Validation loss: 2.1964717859690936

Epoch: 6| Step: 6
Training loss: 0.6321719188721756
Validation loss: 2.1835444617969255

Epoch: 6| Step: 7
Training loss: 0.6053940511585126
Validation loss: 2.1543910743456443

Epoch: 6| Step: 8
Training loss: 1.6213246376427644
Validation loss: 2.1633752051545496

Epoch: 6| Step: 9
Training loss: 0.4251167992370397
Validation loss: 2.0836721362195063

Epoch: 6| Step: 10
Training loss: 0.6573538805682185
Validation loss: 2.2309540487032167

Epoch: 6| Step: 11
Training loss: 0.6484105207966376
Validation loss: 2.1896663433627057

Epoch: 6| Step: 12
Training loss: 0.8432323139234827
Validation loss: 2.2319125417674086

Epoch: 6| Step: 13
Training loss: 0.8368149902388752
Validation loss: 2.2003196729700143

Epoch: 635| Step: 0
Training loss: 0.5928022449915509
Validation loss: 2.1741590561331847

Epoch: 6| Step: 1
Training loss: 0.9804601174996596
Validation loss: 2.199755757441491

Epoch: 6| Step: 2
Training loss: 0.502954871278604
Validation loss: 2.194424675029932

Epoch: 6| Step: 3
Training loss: 0.49335477559534924
Validation loss: 2.244721483057971

Epoch: 6| Step: 4
Training loss: 0.5786817292880414
Validation loss: 2.207457820648377

Epoch: 6| Step: 5
Training loss: 0.4821856766058711
Validation loss: 2.1397544564351345

Epoch: 6| Step: 6
Training loss: 0.45185859238843606
Validation loss: 2.1817384050292357

Epoch: 6| Step: 7
Training loss: 0.5728019310475144
Validation loss: 2.2289445858646384

Epoch: 6| Step: 8
Training loss: 1.6437976496647064
Validation loss: 2.1933199947886783

Epoch: 6| Step: 9
Training loss: 0.4650983353691027
Validation loss: 2.153567065345637

Epoch: 6| Step: 10
Training loss: 0.7907261071371877
Validation loss: 2.171284360759259

Epoch: 6| Step: 11
Training loss: 0.4908708187398265
Validation loss: 2.16802311394637

Epoch: 6| Step: 12
Training loss: 0.6885712470560055
Validation loss: 2.1873730764761903

Epoch: 6| Step: 13
Training loss: 0.5919160124961177
Validation loss: 2.226197249299147

Epoch: 636| Step: 0
Training loss: 0.46535078012936537
Validation loss: 2.1627296201131028

Epoch: 6| Step: 1
Training loss: 0.5834799792247222
Validation loss: 2.294113282458423

Epoch: 6| Step: 2
Training loss: 0.7851452043809686
Validation loss: 2.242019396049862

Epoch: 6| Step: 3
Training loss: 0.5677322126026897
Validation loss: 2.2274849328574593

Epoch: 6| Step: 4
Training loss: 0.49445571201977917
Validation loss: 2.220108846669443

Epoch: 6| Step: 5
Training loss: 1.628945988232119
Validation loss: 2.1929971490463847

Epoch: 6| Step: 6
Training loss: 0.5505532408251937
Validation loss: 2.1667322477428783

Epoch: 6| Step: 7
Training loss: 0.5461109818999219
Validation loss: 2.1539315279724627

Epoch: 6| Step: 8
Training loss: 0.6697977023250733
Validation loss: 2.171515626788734

Epoch: 6| Step: 9
Training loss: 0.6896970063605707
Validation loss: 2.2016272398088113

Epoch: 6| Step: 10
Training loss: 0.578252572083185
Validation loss: 2.2525900855552825

Epoch: 6| Step: 11
Training loss: 0.7573354733760354
Validation loss: 2.2150271320387294

Epoch: 6| Step: 12
Training loss: 0.46060964271483024
Validation loss: 2.219348956613265

Epoch: 6| Step: 13
Training loss: 0.6122119352673984
Validation loss: 2.2858394914321707

Epoch: 637| Step: 0
Training loss: 0.6782110774876118
Validation loss: 2.20904439037656

Epoch: 6| Step: 1
Training loss: 0.6137076189593511
Validation loss: 2.1521762484726685

Epoch: 6| Step: 2
Training loss: 0.5040763154001947
Validation loss: 2.2110270060976287

Epoch: 6| Step: 3
Training loss: 0.5453140324349718
Validation loss: 2.2002675401381717

Epoch: 6| Step: 4
Training loss: 1.6250506173099901
Validation loss: 2.1659213127799135

Epoch: 6| Step: 5
Training loss: 0.3258170064793407
Validation loss: 2.2204255578980865

Epoch: 6| Step: 6
Training loss: 0.6593206862367145
Validation loss: 2.1725051955928656

Epoch: 6| Step: 7
Training loss: 0.45513395040711546
Validation loss: 2.29460797392262

Epoch: 6| Step: 8
Training loss: 0.4435885169139453
Validation loss: 2.219311257410467

Epoch: 6| Step: 9
Training loss: 0.6575477574775843
Validation loss: 2.172831368080012

Epoch: 6| Step: 10
Training loss: 0.5630239060206618
Validation loss: 2.1942773757276663

Epoch: 6| Step: 11
Training loss: 0.8036145213849193
Validation loss: 2.1722328231812735

Epoch: 6| Step: 12
Training loss: 0.5845521189276566
Validation loss: 2.223243104613544

Epoch: 6| Step: 13
Training loss: 0.6088056349739801
Validation loss: 2.2253544199660578

Epoch: 638| Step: 0
Training loss: 0.7662140273693832
Validation loss: 2.1989935149044335

Epoch: 6| Step: 1
Training loss: 0.5292206881825242
Validation loss: 2.2177519066251783

Epoch: 6| Step: 2
Training loss: 0.5896537424198265
Validation loss: 2.2167664147465715

Epoch: 6| Step: 3
Training loss: 0.5380755525614953
Validation loss: 2.220382399586413

Epoch: 6| Step: 4
Training loss: 0.6192750754717734
Validation loss: 2.1632493672939153

Epoch: 6| Step: 5
Training loss: 0.7582871042210717
Validation loss: 2.187834961028061

Epoch: 6| Step: 6
Training loss: 0.4820605635424208
Validation loss: 2.262807245898316

Epoch: 6| Step: 7
Training loss: 0.5557303766191557
Validation loss: 2.212225625978658

Epoch: 6| Step: 8
Training loss: 1.707132087714593
Validation loss: 2.23813870410663

Epoch: 6| Step: 9
Training loss: 0.4913283827664692
Validation loss: 2.16255754397464

Epoch: 6| Step: 10
Training loss: 0.4732446239879451
Validation loss: 2.2150827610818538

Epoch: 6| Step: 11
Training loss: 0.6791751509021448
Validation loss: 2.2378818509463967

Epoch: 6| Step: 12
Training loss: 0.5755387011439901
Validation loss: 2.2065283606495574

Epoch: 6| Step: 13
Training loss: 0.44660921529170405
Validation loss: 2.227355976840683

Epoch: 639| Step: 0
Training loss: 1.6123845376956152
Validation loss: 2.2297183808773804

Epoch: 6| Step: 1
Training loss: 0.7018979067304228
Validation loss: 2.231826383701268

Epoch: 6| Step: 2
Training loss: 0.7952386848054848
Validation loss: 2.1712796084269357

Epoch: 6| Step: 3
Training loss: 0.6337052159032577
Validation loss: 2.1523715731469117

Epoch: 6| Step: 4
Training loss: 0.761437623402926
Validation loss: 2.2529632090644114

Epoch: 6| Step: 5
Training loss: 0.526724331491524
Validation loss: 2.174503036308082

Epoch: 6| Step: 6
Training loss: 0.7702230064914308
Validation loss: 2.1774840714466244

Epoch: 6| Step: 7
Training loss: 0.6014863003116409
Validation loss: 2.281578237013542

Epoch: 6| Step: 8
Training loss: 0.6732796468514253
Validation loss: 2.205794474889948

Epoch: 6| Step: 9
Training loss: 0.5837734185857419
Validation loss: 2.27541396915862

Epoch: 6| Step: 10
Training loss: 0.5588029323057899
Validation loss: 2.140412465212285

Epoch: 6| Step: 11
Training loss: 0.6211619309723418
Validation loss: 2.213947806597646

Epoch: 6| Step: 12
Training loss: 0.6127645903927642
Validation loss: 2.13711028589136

Epoch: 6| Step: 13
Training loss: 0.6101718973847147
Validation loss: 2.193600396829691

Epoch: 640| Step: 0
Training loss: 0.5717574327033287
Validation loss: 2.1334236114221046

Epoch: 6| Step: 1
Training loss: 0.8127651148868787
Validation loss: 2.1946722364087843

Epoch: 6| Step: 2
Training loss: 0.4905952553935263
Validation loss: 2.2399040086071595

Epoch: 6| Step: 3
Training loss: 0.6382754901079807
Validation loss: 2.1987319279534976

Epoch: 6| Step: 4
Training loss: 0.6082747871061469
Validation loss: 2.1272920845622134

Epoch: 6| Step: 5
Training loss: 0.45979722464583783
Validation loss: 2.2083519677296746

Epoch: 6| Step: 6
Training loss: 0.4309297637300364
Validation loss: 2.2248090741373634

Epoch: 6| Step: 7
Training loss: 0.7371140391450375
Validation loss: 2.1676686784422516

Epoch: 6| Step: 8
Training loss: 0.5574923240235823
Validation loss: 2.1873384600644075

Epoch: 6| Step: 9
Training loss: 1.5368219322545928
Validation loss: 2.1296104618909295

Epoch: 6| Step: 10
Training loss: 0.6862736514798041
Validation loss: 2.245821745579276

Epoch: 6| Step: 11
Training loss: 0.699380227308877
Validation loss: 2.202601567056661

Epoch: 6| Step: 12
Training loss: 0.6667849887711436
Validation loss: 2.19574747924314

Epoch: 6| Step: 13
Training loss: 0.7066279151325973
Validation loss: 2.204611161290333

Epoch: 641| Step: 0
Training loss: 0.7897351108172717
Validation loss: 2.176016945626027

Epoch: 6| Step: 1
Training loss: 0.5219328591258383
Validation loss: 2.170092879881626

Epoch: 6| Step: 2
Training loss: 0.4432944363665504
Validation loss: 2.245320839460045

Epoch: 6| Step: 3
Training loss: 0.4991144444443119
Validation loss: 2.137569457833034

Epoch: 6| Step: 4
Training loss: 0.5237772394166382
Validation loss: 2.1049989258350306

Epoch: 6| Step: 5
Training loss: 0.6455485782649295
Validation loss: 2.179887036567879

Epoch: 6| Step: 6
Training loss: 0.6511579460571949
Validation loss: 2.1199254678056683

Epoch: 6| Step: 7
Training loss: 0.650744184558162
Validation loss: 2.269066181624319

Epoch: 6| Step: 8
Training loss: 0.6333071812032055
Validation loss: 2.258894731836711

Epoch: 6| Step: 9
Training loss: 0.5224230030584442
Validation loss: 2.2084621148879338

Epoch: 6| Step: 10
Training loss: 0.7956256796930591
Validation loss: 2.2653493224822707

Epoch: 6| Step: 11
Training loss: 0.7945538542916333
Validation loss: 2.214416700598479

Epoch: 6| Step: 12
Training loss: 1.598846365356036
Validation loss: 2.2004722829172545

Epoch: 6| Step: 13
Training loss: 0.5762282780340993
Validation loss: 2.1809891984719147

Epoch: 642| Step: 0
Training loss: 0.4406833637082927
Validation loss: 2.207517658617745

Epoch: 6| Step: 1
Training loss: 1.6069287717614147
Validation loss: 2.180036080795548

Epoch: 6| Step: 2
Training loss: 0.5507419382770239
Validation loss: 2.1998478959939107

Epoch: 6| Step: 3
Training loss: 0.7698525856769941
Validation loss: 2.27420831903647

Epoch: 6| Step: 4
Training loss: 0.4472530646413733
Validation loss: 2.127184756344783

Epoch: 6| Step: 5
Training loss: 0.8228069344928888
Validation loss: 2.2032886596485186

Epoch: 6| Step: 6
Training loss: 0.49584851248397727
Validation loss: 2.2911271415715038

Epoch: 6| Step: 7
Training loss: 0.5743145246495995
Validation loss: 2.2001365303229283

Epoch: 6| Step: 8
Training loss: 0.6614522908653148
Validation loss: 2.259684379467783

Epoch: 6| Step: 9
Training loss: 0.5319866794732678
Validation loss: 2.159122436469102

Epoch: 6| Step: 10
Training loss: 0.46507964039290856
Validation loss: 2.2289148218517805

Epoch: 6| Step: 11
Training loss: 0.35134902406727697
Validation loss: 2.1134869202071016

Epoch: 6| Step: 12
Training loss: 0.5906472701460814
Validation loss: 2.187057225877579

Epoch: 6| Step: 13
Training loss: 0.45194068238745994
Validation loss: 2.201971751366106

Epoch: 643| Step: 0
Training loss: 1.7297956479385994
Validation loss: 2.2213120256651213

Epoch: 6| Step: 1
Training loss: 0.39661134838338735
Validation loss: 2.258963734403057

Epoch: 6| Step: 2
Training loss: 0.6300320470697138
Validation loss: 2.215722019239683

Epoch: 6| Step: 3
Training loss: 0.5920948751274505
Validation loss: 2.1502326465527477

Epoch: 6| Step: 4
Training loss: 0.6290238785767337
Validation loss: 2.2154518292917564

Epoch: 6| Step: 5
Training loss: 0.48728421460645954
Validation loss: 2.117885392690596

Epoch: 6| Step: 6
Training loss: 0.5824194004305611
Validation loss: 2.218819448010152

Epoch: 6| Step: 7
Training loss: 0.7943239704972439
Validation loss: 2.1606563412108515

Epoch: 6| Step: 8
Training loss: 0.5897972139101917
Validation loss: 2.1050655618115592

Epoch: 6| Step: 9
Training loss: 0.6924911435796921
Validation loss: 2.1474713020537375

Epoch: 6| Step: 10
Training loss: 0.5485329971420393
Validation loss: 2.154216471481678

Epoch: 6| Step: 11
Training loss: 0.6372421547282201
Validation loss: 2.1054951208407795

Epoch: 6| Step: 12
Training loss: 0.4482542048819267
Validation loss: 2.240302090494398

Epoch: 6| Step: 13
Training loss: 0.4951407522880133
Validation loss: 2.170694798519879

Epoch: 644| Step: 0
Training loss: 0.5288864177101614
Validation loss: 2.29366616326698

Epoch: 6| Step: 1
Training loss: 0.7458739431254509
Validation loss: 2.229021838404392

Epoch: 6| Step: 2
Training loss: 0.6044819327179447
Validation loss: 2.22874700854874

Epoch: 6| Step: 3
Training loss: 0.7270686529767031
Validation loss: 2.1978441142934195

Epoch: 6| Step: 4
Training loss: 1.582046320337171
Validation loss: 2.1888200717508037

Epoch: 6| Step: 5
Training loss: 0.4840820411003378
Validation loss: 2.1745641277049637

Epoch: 6| Step: 6
Training loss: 0.8152075185039713
Validation loss: 2.2203470156106877

Epoch: 6| Step: 7
Training loss: 0.5069377701318525
Validation loss: 2.229280800859383

Epoch: 6| Step: 8
Training loss: 0.7649229684704428
Validation loss: 2.1887975603406464

Epoch: 6| Step: 9
Training loss: 0.4144722332805519
Validation loss: 2.2070454792940115

Epoch: 6| Step: 10
Training loss: 0.6140425506535044
Validation loss: 2.213933908839357

Epoch: 6| Step: 11
Training loss: 0.48583361751074794
Validation loss: 2.1431786491307414

Epoch: 6| Step: 12
Training loss: 0.5561047032074201
Validation loss: 2.224282047321918

Epoch: 6| Step: 13
Training loss: 0.45612787153699685
Validation loss: 2.159928130792802

Epoch: 645| Step: 0
Training loss: 0.46046651603433836
Validation loss: 2.184967234820074

Epoch: 6| Step: 1
Training loss: 0.4803202329768862
Validation loss: 2.1755376465754575

Epoch: 6| Step: 2
Training loss: 0.6492666894723462
Validation loss: 2.2000202593798153

Epoch: 6| Step: 3
Training loss: 0.5710115198720326
Validation loss: 2.158286533647313

Epoch: 6| Step: 4
Training loss: 0.43384355789286927
Validation loss: 2.2466253669298237

Epoch: 6| Step: 5
Training loss: 0.5069711023518426
Validation loss: 2.202392952213592

Epoch: 6| Step: 6
Training loss: 0.8053153838289945
Validation loss: 2.2516173858373474

Epoch: 6| Step: 7
Training loss: 0.6019673904619844
Validation loss: 2.155914545084702

Epoch: 6| Step: 8
Training loss: 0.6265621213840473
Validation loss: 2.133198796232484

Epoch: 6| Step: 9
Training loss: 1.653130021835805
Validation loss: 2.15771757228339

Epoch: 6| Step: 10
Training loss: 0.45626512528522734
Validation loss: 2.228850868940613

Epoch: 6| Step: 11
Training loss: 0.46003994597228454
Validation loss: 2.221035848777879

Epoch: 6| Step: 12
Training loss: 0.6291304478946633
Validation loss: 2.199264386883333

Epoch: 6| Step: 13
Training loss: 0.39399388041802663
Validation loss: 2.2181283743517057

Epoch: 646| Step: 0
Training loss: 0.5541065827640786
Validation loss: 2.173397133703752

Epoch: 6| Step: 1
Training loss: 0.7533859275783613
Validation loss: 2.1281419420479697

Epoch: 6| Step: 2
Training loss: 0.7786019652053996
Validation loss: 2.181391251514235

Epoch: 6| Step: 3
Training loss: 0.501290146986969
Validation loss: 2.156892807593182

Epoch: 6| Step: 4
Training loss: 0.621254282424259
Validation loss: 2.1737460828238695

Epoch: 6| Step: 5
Training loss: 0.6249019545899515
Validation loss: 2.251655423109342

Epoch: 6| Step: 6
Training loss: 1.572567890563558
Validation loss: 2.1529518913342245

Epoch: 6| Step: 7
Training loss: 0.5004588941925026
Validation loss: 2.2239432097474063

Epoch: 6| Step: 8
Training loss: 0.4804410228637308
Validation loss: 2.1823661506220398

Epoch: 6| Step: 9
Training loss: 0.43660706267382604
Validation loss: 2.303483650614562

Epoch: 6| Step: 10
Training loss: 0.6141398305952105
Validation loss: 2.1859148777931514

Epoch: 6| Step: 11
Training loss: 0.4847636663134502
Validation loss: 2.2487349491675594

Epoch: 6| Step: 12
Training loss: 0.6029716682215187
Validation loss: 2.1653176705755466

Epoch: 6| Step: 13
Training loss: 0.5605422760778107
Validation loss: 2.184778542825475

Epoch: 647| Step: 0
Training loss: 0.63653002323233
Validation loss: 2.1612271504145695

Epoch: 6| Step: 1
Training loss: 1.5866998803778978
Validation loss: 2.1297719140183085

Epoch: 6| Step: 2
Training loss: 0.6770214101400749
Validation loss: 2.2552311063992767

Epoch: 6| Step: 3
Training loss: 0.6457743361403179
Validation loss: 2.208788684544485

Epoch: 6| Step: 4
Training loss: 0.6617184500485296
Validation loss: 2.1494109107455457

Epoch: 6| Step: 5
Training loss: 0.6131394580765703
Validation loss: 2.139579491880892

Epoch: 6| Step: 6
Training loss: 0.7550291484612316
Validation loss: 2.263306256569398

Epoch: 6| Step: 7
Training loss: 0.35782900276607793
Validation loss: 2.1512920263042052

Epoch: 6| Step: 8
Training loss: 0.6587770942168582
Validation loss: 2.1392199338639686

Epoch: 6| Step: 9
Training loss: 0.5709167310489828
Validation loss: 2.175244795352375

Epoch: 6| Step: 10
Training loss: 0.5732704688509107
Validation loss: 2.286017812446373

Epoch: 6| Step: 11
Training loss: 0.3896978437799166
Validation loss: 2.233992845890215

Epoch: 6| Step: 12
Training loss: 0.6860250560519285
Validation loss: 2.2457363129242096

Epoch: 6| Step: 13
Training loss: 0.4353819735940836
Validation loss: 2.2358180952824664

Epoch: 648| Step: 0
Training loss: 0.350126097732915
Validation loss: 2.2038001988964355

Epoch: 6| Step: 1
Training loss: 0.5865882565874825
Validation loss: 2.218719864669078

Epoch: 6| Step: 2
Training loss: 0.5929197479627283
Validation loss: 2.1857528975774896

Epoch: 6| Step: 3
Training loss: 0.4936289795912919
Validation loss: 2.230171201150752

Epoch: 6| Step: 4
Training loss: 0.5080872599344852
Validation loss: 2.25652430706498

Epoch: 6| Step: 5
Training loss: 0.5541267246776256
Validation loss: 2.206454303211555

Epoch: 6| Step: 6
Training loss: 0.5545969607109323
Validation loss: 2.2898127372051307

Epoch: 6| Step: 7
Training loss: 0.7788295635401814
Validation loss: 2.239505839932849

Epoch: 6| Step: 8
Training loss: 0.6633217887936123
Validation loss: 2.2099072664889343

Epoch: 6| Step: 9
Training loss: 0.6481836120677192
Validation loss: 2.242070700992084

Epoch: 6| Step: 10
Training loss: 0.49910953323987045
Validation loss: 2.232551216473475

Epoch: 6| Step: 11
Training loss: 0.4438139144107793
Validation loss: 2.175022019510685

Epoch: 6| Step: 12
Training loss: 1.639586492371414
Validation loss: 2.1613167242063946

Epoch: 6| Step: 13
Training loss: 0.4891918846071314
Validation loss: 2.207164702072854

Epoch: 649| Step: 0
Training loss: 0.6981291352630239
Validation loss: 2.1864140418198357

Epoch: 6| Step: 1
Training loss: 0.7814723652049639
Validation loss: 2.171306947478513

Epoch: 6| Step: 2
Training loss: 0.6910812346782563
Validation loss: 2.212281135999778

Epoch: 6| Step: 3
Training loss: 1.5453304710153222
Validation loss: 2.2509859789180973

Epoch: 6| Step: 4
Training loss: 0.6586712720323222
Validation loss: 2.19772034338693

Epoch: 6| Step: 5
Training loss: 0.45109980284141743
Validation loss: 2.200209691452498

Epoch: 6| Step: 6
Training loss: 0.5930754192439415
Validation loss: 2.231128571829063

Epoch: 6| Step: 7
Training loss: 0.4178791841462369
Validation loss: 2.315733668866168

Epoch: 6| Step: 8
Training loss: 0.6181242389114986
Validation loss: 2.1977180045533173

Epoch: 6| Step: 9
Training loss: 0.711714602813195
Validation loss: 2.2222659642091505

Epoch: 6| Step: 10
Training loss: 0.6826196760533367
Validation loss: 2.174533562768581

Epoch: 6| Step: 11
Training loss: 0.5688166925082772
Validation loss: 2.211976488462089

Epoch: 6| Step: 12
Training loss: 0.5555945220500762
Validation loss: 2.208726770881115

Epoch: 6| Step: 13
Training loss: 0.6883721238591056
Validation loss: 2.231497470589632

Epoch: 650| Step: 0
Training loss: 0.5909596680790594
Validation loss: 2.1745524315922484

Epoch: 6| Step: 1
Training loss: 0.5481398532816655
Validation loss: 2.175681610338572

Epoch: 6| Step: 2
Training loss: 0.6340153647209626
Validation loss: 2.1822336678523317

Epoch: 6| Step: 3
Training loss: 0.6322544133012323
Validation loss: 2.225597738053922

Epoch: 6| Step: 4
Training loss: 0.6384181647376714
Validation loss: 2.1748023758892208

Epoch: 6| Step: 5
Training loss: 0.7191486911435282
Validation loss: 2.2655006733842464

Epoch: 6| Step: 6
Training loss: 0.6204124888972656
Validation loss: 2.141538040392717

Epoch: 6| Step: 7
Training loss: 0.4318677382403817
Validation loss: 2.1799865228214346

Epoch: 6| Step: 8
Training loss: 0.58157517658666
Validation loss: 2.1899452921975944

Epoch: 6| Step: 9
Training loss: 0.49486655789502626
Validation loss: 2.188456247517874

Epoch: 6| Step: 10
Training loss: 1.630970477128763
Validation loss: 2.2446601013895324

Epoch: 6| Step: 11
Training loss: 0.5712551009035982
Validation loss: 2.1705537112808764

Epoch: 6| Step: 12
Training loss: 0.6347226172329345
Validation loss: 2.242664845595306

Epoch: 6| Step: 13
Training loss: 0.6884720173137867
Validation loss: 2.198101914384916

Epoch: 651| Step: 0
Training loss: 0.6260178860312071
Validation loss: 2.1915952691530687

Epoch: 6| Step: 1
Training loss: 0.6516432055797367
Validation loss: 2.237286266559503

Epoch: 6| Step: 2
Training loss: 0.5871930974477322
Validation loss: 2.2412008577472635

Epoch: 6| Step: 3
Training loss: 0.7593064673624734
Validation loss: 2.2110646129178195

Epoch: 6| Step: 4
Training loss: 0.4737919176424363
Validation loss: 2.214967565806205

Epoch: 6| Step: 5
Training loss: 0.626996404277037
Validation loss: 2.180254648336936

Epoch: 6| Step: 6
Training loss: 1.6662173937206415
Validation loss: 2.2195289696786538

Epoch: 6| Step: 7
Training loss: 0.6902285961520168
Validation loss: 2.154657087908813

Epoch: 6| Step: 8
Training loss: 0.6010810609950225
Validation loss: 2.2048940172346088

Epoch: 6| Step: 9
Training loss: 0.49233390507711133
Validation loss: 2.2087616341639165

Epoch: 6| Step: 10
Training loss: 0.5693230079504467
Validation loss: 2.199793728847175

Epoch: 6| Step: 11
Training loss: 0.6513625435041651
Validation loss: 2.1861355746825395

Epoch: 6| Step: 12
Training loss: 0.5763548221121331
Validation loss: 2.2391919808363734

Epoch: 6| Step: 13
Training loss: 0.47252616983935614
Validation loss: 2.1697981282346226

Epoch: 652| Step: 0
Training loss: 0.5100861342004788
Validation loss: 2.2433281380715533

Epoch: 6| Step: 1
Training loss: 0.5539869263170223
Validation loss: 2.1980057300632265

Epoch: 6| Step: 2
Training loss: 0.428352397198836
Validation loss: 2.221446441483062

Epoch: 6| Step: 3
Training loss: 0.6480048701197496
Validation loss: 2.1417955396255004

Epoch: 6| Step: 4
Training loss: 0.8232867861214271
Validation loss: 2.159690611076354

Epoch: 6| Step: 5
Training loss: 0.42897793530361905
Validation loss: 2.158452138704536

Epoch: 6| Step: 6
Training loss: 1.670333151337271
Validation loss: 2.160291603314734

Epoch: 6| Step: 7
Training loss: 0.4995378802506504
Validation loss: 2.164770760098802

Epoch: 6| Step: 8
Training loss: 0.6024802502287863
Validation loss: 2.1751261625378655

Epoch: 6| Step: 9
Training loss: 0.4777713514913569
Validation loss: 2.157020452602752

Epoch: 6| Step: 10
Training loss: 0.5218214167423497
Validation loss: 2.223942034523009

Epoch: 6| Step: 11
Training loss: 0.4914824264504719
Validation loss: 2.1495755442227287

Epoch: 6| Step: 12
Training loss: 0.7132564912240578
Validation loss: 2.251306450195116

Epoch: 6| Step: 13
Training loss: 0.6593298168882527
Validation loss: 2.1696652466981194

Epoch: 653| Step: 0
Training loss: 0.6211257062644268
Validation loss: 2.228814696926578

Epoch: 6| Step: 1
Training loss: 0.5479949926613966
Validation loss: 2.237603000023844

Epoch: 6| Step: 2
Training loss: 0.41269577033563176
Validation loss: 2.1276949036279587

Epoch: 6| Step: 3
Training loss: 0.6419561094539887
Validation loss: 2.198150377591335

Epoch: 6| Step: 4
Training loss: 0.7132055135840079
Validation loss: 2.249781097168528

Epoch: 6| Step: 5
Training loss: 1.5623591550290152
Validation loss: 2.1334976886047587

Epoch: 6| Step: 6
Training loss: 0.6369181595722879
Validation loss: 2.2211120963674835

Epoch: 6| Step: 7
Training loss: 0.5037313645751911
Validation loss: 2.222772130384345

Epoch: 6| Step: 8
Training loss: 0.46807399324173254
Validation loss: 2.1750365693013456

Epoch: 6| Step: 9
Training loss: 0.5617413172744766
Validation loss: 2.203331216147099

Epoch: 6| Step: 10
Training loss: 0.608675261536917
Validation loss: 2.1631766938171286

Epoch: 6| Step: 11
Training loss: 0.46602266343102305
Validation loss: 2.2129441228677025

Epoch: 6| Step: 12
Training loss: 0.7347902787659353
Validation loss: 2.2248659559713375

Epoch: 6| Step: 13
Training loss: 0.394940324724023
Validation loss: 2.2546842164454657

Epoch: 654| Step: 0
Training loss: 0.5518692309206564
Validation loss: 2.197805546389999

Epoch: 6| Step: 1
Training loss: 0.7825347255277553
Validation loss: 2.217751615322314

Epoch: 6| Step: 2
Training loss: 0.6017349540927762
Validation loss: 2.2568912351744856

Epoch: 6| Step: 3
Training loss: 0.6670374038137201
Validation loss: 2.23010732479081

Epoch: 6| Step: 4
Training loss: 0.4614176593045528
Validation loss: 2.2276629218719086

Epoch: 6| Step: 5
Training loss: 0.5115763633587942
Validation loss: 2.160569395558719

Epoch: 6| Step: 6
Training loss: 0.49600379608897405
Validation loss: 2.2344218039148043

Epoch: 6| Step: 7
Training loss: 1.6206153255575508
Validation loss: 2.162088487383442

Epoch: 6| Step: 8
Training loss: 0.631399295639259
Validation loss: 2.235748135273812

Epoch: 6| Step: 9
Training loss: 0.44152668348055907
Validation loss: 2.1859049077989106

Epoch: 6| Step: 10
Training loss: 0.7015359724845003
Validation loss: 2.181192715839317

Epoch: 6| Step: 11
Training loss: 0.696102550720684
Validation loss: 2.1221881977529975

Epoch: 6| Step: 12
Training loss: 0.6826339086577513
Validation loss: 2.156678594551906

Epoch: 6| Step: 13
Training loss: 0.5465383038146043
Validation loss: 2.156422229348558

Epoch: 655| Step: 0
Training loss: 0.512614565348937
Validation loss: 2.2109535008281265

Epoch: 6| Step: 1
Training loss: 0.45757945512054304
Validation loss: 2.189545708807406

Epoch: 6| Step: 2
Training loss: 0.5740137577700943
Validation loss: 2.195596736613268

Epoch: 6| Step: 3
Training loss: 0.43440809329644614
Validation loss: 2.1465737578404944

Epoch: 6| Step: 4
Training loss: 1.548922253282345
Validation loss: 2.1912301987403238

Epoch: 6| Step: 5
Training loss: 0.47327467759242153
Validation loss: 2.207376047016029

Epoch: 6| Step: 6
Training loss: 0.788904419728946
Validation loss: 2.22534071440694

Epoch: 6| Step: 7
Training loss: 0.6639401491434241
Validation loss: 2.1944248730486082

Epoch: 6| Step: 8
Training loss: 0.40507026083512426
Validation loss: 2.1593910494853006

Epoch: 6| Step: 9
Training loss: 0.5703030415625938
Validation loss: 2.1835238725683803

Epoch: 6| Step: 10
Training loss: 0.5314775428405736
Validation loss: 2.2167557751273987

Epoch: 6| Step: 11
Training loss: 0.6541524243677331
Validation loss: 2.2292553291096424

Epoch: 6| Step: 12
Training loss: 0.49780180642423627
Validation loss: 2.1632123590526184

Epoch: 6| Step: 13
Training loss: 0.6600930900380807
Validation loss: 2.1663166734489416

Epoch: 656| Step: 0
Training loss: 0.6657183702556696
Validation loss: 2.272132038922909

Epoch: 6| Step: 1
Training loss: 0.4861360653269946
Validation loss: 2.1864085438099328

Epoch: 6| Step: 2
Training loss: 0.5704003880334955
Validation loss: 2.2750987219573084

Epoch: 6| Step: 3
Training loss: 0.46765997034104023
Validation loss: 2.2004905768989858

Epoch: 6| Step: 4
Training loss: 0.5921376572219084
Validation loss: 2.2290552399136203

Epoch: 6| Step: 5
Training loss: 0.571587639407526
Validation loss: 2.198205422011946

Epoch: 6| Step: 6
Training loss: 0.6249661198016154
Validation loss: 2.1306455075180164

Epoch: 6| Step: 7
Training loss: 0.6859157471911523
Validation loss: 2.152746770844746

Epoch: 6| Step: 8
Training loss: 0.4593498236056573
Validation loss: 2.175484518619845

Epoch: 6| Step: 9
Training loss: 0.623117592364849
Validation loss: 2.1164360987928728

Epoch: 6| Step: 10
Training loss: 0.6035168595285968
Validation loss: 2.1470743679067215

Epoch: 6| Step: 11
Training loss: 0.5594267869131763
Validation loss: 2.1918895241851346

Epoch: 6| Step: 12
Training loss: 1.5899460968141454
Validation loss: 2.181739103005808

Epoch: 6| Step: 13
Training loss: 0.762799870043835
Validation loss: 2.186668637943949

Epoch: 657| Step: 0
Training loss: 0.5502603651541093
Validation loss: 2.1887755605427093

Epoch: 6| Step: 1
Training loss: 0.4904590411044054
Validation loss: 2.213227209427416

Epoch: 6| Step: 2
Training loss: 0.6794784926097739
Validation loss: 2.155287504167687

Epoch: 6| Step: 3
Training loss: 0.5654078135105367
Validation loss: 2.1884783014827596

Epoch: 6| Step: 4
Training loss: 0.49933160870255927
Validation loss: 2.1245648314313366

Epoch: 6| Step: 5
Training loss: 0.651362246104289
Validation loss: 2.1673641249703985

Epoch: 6| Step: 6
Training loss: 0.49477083931974214
Validation loss: 2.1995004097516926

Epoch: 6| Step: 7
Training loss: 0.46946252075482914
Validation loss: 2.125614061853503

Epoch: 6| Step: 8
Training loss: 0.4071269107805387
Validation loss: 2.1809075864323044

Epoch: 6| Step: 9
Training loss: 0.6259998906351792
Validation loss: 2.160550296638713

Epoch: 6| Step: 10
Training loss: 0.5294984384447077
Validation loss: 2.1711199724266894

Epoch: 6| Step: 11
Training loss: 0.6126934077020768
Validation loss: 2.1940478113599644

Epoch: 6| Step: 12
Training loss: 1.6659837833773894
Validation loss: 2.189239298019732

Epoch: 6| Step: 13
Training loss: 0.33493604650963293
Validation loss: 2.142993045634303

Epoch: 658| Step: 0
Training loss: 0.501548039593315
Validation loss: 2.1736412205697033

Epoch: 6| Step: 1
Training loss: 0.5357230866935409
Validation loss: 2.2005226878428825

Epoch: 6| Step: 2
Training loss: 0.4521760540761223
Validation loss: 2.2250741955234576

Epoch: 6| Step: 3
Training loss: 0.8589247824696061
Validation loss: 2.1535565694224177

Epoch: 6| Step: 4
Training loss: 1.4884966997206766
Validation loss: 2.2287496552975985

Epoch: 6| Step: 5
Training loss: 0.6544118979397806
Validation loss: 2.211921436138431

Epoch: 6| Step: 6
Training loss: 0.6240359500591673
Validation loss: 2.21929746947983

Epoch: 6| Step: 7
Training loss: 0.45777766905683526
Validation loss: 2.236577724426113

Epoch: 6| Step: 8
Training loss: 0.5144780436095036
Validation loss: 2.209254009256431

Epoch: 6| Step: 9
Training loss: 0.6414735802868932
Validation loss: 2.1798683309375435

Epoch: 6| Step: 10
Training loss: 0.6324567619064789
Validation loss: 2.1868138668471793

Epoch: 6| Step: 11
Training loss: 0.6173003129828849
Validation loss: 2.2352935052781526

Epoch: 6| Step: 12
Training loss: 0.520234399381065
Validation loss: 2.234810845527867

Epoch: 6| Step: 13
Training loss: 0.5534453924252819
Validation loss: 2.1428848289228646

Epoch: 659| Step: 0
Training loss: 0.3776987636943861
Validation loss: 2.183940340355978

Epoch: 6| Step: 1
Training loss: 0.3960135158558661
Validation loss: 2.190247394006136

Epoch: 6| Step: 2
Training loss: 0.3326835731835016
Validation loss: 2.1453448857821895

Epoch: 6| Step: 3
Training loss: 0.46564197125324586
Validation loss: 2.1606387024792664

Epoch: 6| Step: 4
Training loss: 0.7805472837540022
Validation loss: 2.2167891336320054

Epoch: 6| Step: 5
Training loss: 0.5537691169866112
Validation loss: 2.1485711252490445

Epoch: 6| Step: 6
Training loss: 0.6513035870432639
Validation loss: 2.1348804640048553

Epoch: 6| Step: 7
Training loss: 0.5462993862252695
Validation loss: 2.2195398893824643

Epoch: 6| Step: 8
Training loss: 0.6478851907654689
Validation loss: 2.156040988212574

Epoch: 6| Step: 9
Training loss: 1.5429339827471449
Validation loss: 2.1825508854376126

Epoch: 6| Step: 10
Training loss: 0.714551021486737
Validation loss: 2.232336550815616

Epoch: 6| Step: 11
Training loss: 0.7544952621614561
Validation loss: 2.1089398019087797

Epoch: 6| Step: 12
Training loss: 0.7488799473715773
Validation loss: 2.149036680254387

Epoch: 6| Step: 13
Training loss: 0.6234430709628203
Validation loss: 2.07800837166461

Epoch: 660| Step: 0
Training loss: 0.5362768483498943
Validation loss: 2.1749638809620415

Epoch: 6| Step: 1
Training loss: 0.49817531649855673
Validation loss: 2.123010446556852

Epoch: 6| Step: 2
Training loss: 0.6182810354822889
Validation loss: 2.134000170831664

Epoch: 6| Step: 3
Training loss: 0.6165491496911116
Validation loss: 2.2170177840239007

Epoch: 6| Step: 4
Training loss: 0.5387988344085025
Validation loss: 2.2264318272764085

Epoch: 6| Step: 5
Training loss: 0.6444294473416694
Validation loss: 2.2783555275120593

Epoch: 6| Step: 6
Training loss: 0.5517967277914448
Validation loss: 2.1062202857318018

Epoch: 6| Step: 7
Training loss: 0.4158324792174064
Validation loss: 2.2020186281381484

Epoch: 6| Step: 8
Training loss: 0.4763661277042876
Validation loss: 2.267291437852134

Epoch: 6| Step: 9
Training loss: 0.532145390751404
Validation loss: 2.2478711095953026

Epoch: 6| Step: 10
Training loss: 0.6102259392204716
Validation loss: 2.1903590174925487

Epoch: 6| Step: 11
Training loss: 1.5879766574652605
Validation loss: 2.2539651892558688

Epoch: 6| Step: 12
Training loss: 0.5766907505379131
Validation loss: 2.166430954105427

Epoch: 6| Step: 13
Training loss: 0.6076973048392839
Validation loss: 2.170149302817895

Epoch: 661| Step: 0
Training loss: 0.6249763007439135
Validation loss: 2.1066770184502097

Epoch: 6| Step: 1
Training loss: 0.5630471694202376
Validation loss: 2.1319741457707275

Epoch: 6| Step: 2
Training loss: 0.501216719324006
Validation loss: 2.1782202005601805

Epoch: 6| Step: 3
Training loss: 0.5392844807331915
Validation loss: 2.1377999844643205

Epoch: 6| Step: 4
Training loss: 0.6875769615445232
Validation loss: 2.2402313947914823

Epoch: 6| Step: 5
Training loss: 0.5671536217442127
Validation loss: 2.193672783760072

Epoch: 6| Step: 6
Training loss: 0.5608608416612394
Validation loss: 2.201639964080016

Epoch: 6| Step: 7
Training loss: 0.503389137545071
Validation loss: 2.156251682342068

Epoch: 6| Step: 8
Training loss: 0.6179678607071025
Validation loss: 2.165290477897624

Epoch: 6| Step: 9
Training loss: 0.4793166948493806
Validation loss: 2.189789400527484

Epoch: 6| Step: 10
Training loss: 0.5557797383611465
Validation loss: 2.1516062670822738

Epoch: 6| Step: 11
Training loss: 1.585896383419636
Validation loss: 2.212585856298623

Epoch: 6| Step: 12
Training loss: 0.4433148567602806
Validation loss: 2.206323420237681

Epoch: 6| Step: 13
Training loss: 0.6856796049213417
Validation loss: 2.1524171510187493

Epoch: 662| Step: 0
Training loss: 0.5052711867203806
Validation loss: 2.2258477437338717

Epoch: 6| Step: 1
Training loss: 0.41184564260072093
Validation loss: 2.1831415162190777

Epoch: 6| Step: 2
Training loss: 0.5640140396393053
Validation loss: 2.2389652039248085

Epoch: 6| Step: 3
Training loss: 0.6267917698748907
Validation loss: 2.159405719732143

Epoch: 6| Step: 4
Training loss: 1.5518453872196678
Validation loss: 2.2564337125132963

Epoch: 6| Step: 5
Training loss: 0.5103010676003333
Validation loss: 2.126940654812737

Epoch: 6| Step: 6
Training loss: 0.7086895206085179
Validation loss: 2.169700298089235

Epoch: 6| Step: 7
Training loss: 0.5871708414537696
Validation loss: 2.216412348209708

Epoch: 6| Step: 8
Training loss: 0.569655601834665
Validation loss: 2.2466096013358716

Epoch: 6| Step: 9
Training loss: 0.4369256131892478
Validation loss: 2.2066926238119495

Epoch: 6| Step: 10
Training loss: 0.5514538222924531
Validation loss: 2.15951182644535

Epoch: 6| Step: 11
Training loss: 0.48047186687668036
Validation loss: 2.2395263477658185

Epoch: 6| Step: 12
Training loss: 0.629455847524186
Validation loss: 2.212636284199341

Epoch: 6| Step: 13
Training loss: 0.7560853447853907
Validation loss: 2.1478682607189308

Epoch: 663| Step: 0
Training loss: 0.6842293971997996
Validation loss: 2.2013882625301995

Epoch: 6| Step: 1
Training loss: 0.4973407451887619
Validation loss: 2.1938003273432205

Epoch: 6| Step: 2
Training loss: 0.414885638433626
Validation loss: 2.154603711012906

Epoch: 6| Step: 3
Training loss: 0.5415468052759717
Validation loss: 2.1545307527553494

Epoch: 6| Step: 4
Training loss: 1.5930724106044512
Validation loss: 2.2526258518916227

Epoch: 6| Step: 5
Training loss: 0.5035240438984155
Validation loss: 2.1819853602318533

Epoch: 6| Step: 6
Training loss: 0.5655534836042698
Validation loss: 2.131453032640147

Epoch: 6| Step: 7
Training loss: 0.5648592375640943
Validation loss: 2.178920785513381

Epoch: 6| Step: 8
Training loss: 0.5112978536505948
Validation loss: 2.1787200990935265

Epoch: 6| Step: 9
Training loss: 0.7055965219162187
Validation loss: 2.2560416452112695

Epoch: 6| Step: 10
Training loss: 0.621485748385405
Validation loss: 2.1331558152559653

Epoch: 6| Step: 11
Training loss: 0.560495301110396
Validation loss: 2.1442829444610556

Epoch: 6| Step: 12
Training loss: 0.4494627911652015
Validation loss: 2.1890326362147903

Epoch: 6| Step: 13
Training loss: 0.47001100045377836
Validation loss: 2.1869282973023645

Epoch: 664| Step: 0
Training loss: 0.33271308900702384
Validation loss: 2.183084124403312

Epoch: 6| Step: 1
Training loss: 0.4191772956840339
Validation loss: 2.1839991082890524

Epoch: 6| Step: 2
Training loss: 0.456807318056407
Validation loss: 2.281997114427116

Epoch: 6| Step: 3
Training loss: 0.5145851110770011
Validation loss: 2.189424057101482

Epoch: 6| Step: 4
Training loss: 0.5406410214911161
Validation loss: 2.2236283299951634

Epoch: 6| Step: 5
Training loss: 0.5025499706663397
Validation loss: 2.18878213895406

Epoch: 6| Step: 6
Training loss: 0.5468317559719541
Validation loss: 2.1443699772112326

Epoch: 6| Step: 7
Training loss: 0.5696402467684081
Validation loss: 2.213369670944109

Epoch: 6| Step: 8
Training loss: 1.5540198804793879
Validation loss: 2.136672840261468

Epoch: 6| Step: 9
Training loss: 0.5341974286859085
Validation loss: 2.166476055742254

Epoch: 6| Step: 10
Training loss: 0.7443889694120189
Validation loss: 2.219870823671916

Epoch: 6| Step: 11
Training loss: 0.6355075197982981
Validation loss: 2.152333754327994

Epoch: 6| Step: 12
Training loss: 0.6994228810955763
Validation loss: 2.1757508494465743

Epoch: 6| Step: 13
Training loss: 0.5316634252453394
Validation loss: 2.144509121249652

Epoch: 665| Step: 0
Training loss: 0.49021970871343856
Validation loss: 2.1690260446651295

Epoch: 6| Step: 1
Training loss: 1.572224529985068
Validation loss: 2.1522664520645067

Epoch: 6| Step: 2
Training loss: 0.7611266745030325
Validation loss: 2.1869161869813

Epoch: 6| Step: 3
Training loss: 0.5441038493088453
Validation loss: 2.1258365702339037

Epoch: 6| Step: 4
Training loss: 0.4715476315216505
Validation loss: 2.199825521324833

Epoch: 6| Step: 5
Training loss: 0.35696327513976517
Validation loss: 2.2583610696280925

Epoch: 6| Step: 6
Training loss: 0.6007093349318873
Validation loss: 2.1291344407355592

Epoch: 6| Step: 7
Training loss: 0.4708845018613464
Validation loss: 2.235852464471879

Epoch: 6| Step: 8
Training loss: 0.36662911508190615
Validation loss: 2.2290333855704487

Epoch: 6| Step: 9
Training loss: 0.6733507538617682
Validation loss: 2.1950416419744725

Epoch: 6| Step: 10
Training loss: 0.637942513050868
Validation loss: 2.1971765611616423

Epoch: 6| Step: 11
Training loss: 0.5663213732034487
Validation loss: 2.1846967311598173

Epoch: 6| Step: 12
Training loss: 0.5368208786637757
Validation loss: 2.2007255188622543

Epoch: 6| Step: 13
Training loss: 0.7078073362452629
Validation loss: 2.1982017652554764

Epoch: 666| Step: 0
Training loss: 0.5378436808438406
Validation loss: 2.215779285915844

Epoch: 6| Step: 1
Training loss: 0.3555167867879361
Validation loss: 2.127690393414599

Epoch: 6| Step: 2
Training loss: 0.5329866074495216
Validation loss: 2.196815976967525

Epoch: 6| Step: 3
Training loss: 0.6402055250909622
Validation loss: 2.216425760825318

Epoch: 6| Step: 4
Training loss: 0.7818203941932893
Validation loss: 2.153742404099914

Epoch: 6| Step: 5
Training loss: 0.5659601756987089
Validation loss: 2.2059812797712124

Epoch: 6| Step: 6
Training loss: 0.26738712705777257
Validation loss: 2.130252170259617

Epoch: 6| Step: 7
Training loss: 0.4764932363236243
Validation loss: 2.244845755668029

Epoch: 6| Step: 8
Training loss: 0.6352756036194782
Validation loss: 2.164410167046406

Epoch: 6| Step: 9
Training loss: 0.5638186574941567
Validation loss: 2.1348923702574303

Epoch: 6| Step: 10
Training loss: 0.6915912272971936
Validation loss: 2.1877026137407407

Epoch: 6| Step: 11
Training loss: 0.3771026986595851
Validation loss: 2.2191978740881844

Epoch: 6| Step: 12
Training loss: 0.6941592049245358
Validation loss: 2.1842675604791255

Epoch: 6| Step: 13
Training loss: 2.0325716853902103
Validation loss: 2.1858073434756946

Epoch: 667| Step: 0
Training loss: 0.6236660550340637
Validation loss: 2.2804041131577097

Epoch: 6| Step: 1
Training loss: 1.618225354338609
Validation loss: 2.166689514007353

Epoch: 6| Step: 2
Training loss: 0.5295660594260942
Validation loss: 2.1212134691489686

Epoch: 6| Step: 3
Training loss: 0.6282868741345126
Validation loss: 2.2000311558904784

Epoch: 6| Step: 4
Training loss: 0.7583277415673755
Validation loss: 2.18590177933881

Epoch: 6| Step: 5
Training loss: 0.4292391779051379
Validation loss: 2.2401509768722585

Epoch: 6| Step: 6
Training loss: 0.4343966190529286
Validation loss: 2.119660723095875

Epoch: 6| Step: 7
Training loss: 0.5713710367452952
Validation loss: 2.1702756105950267

Epoch: 6| Step: 8
Training loss: 0.4410725403948748
Validation loss: 2.1406808481640023

Epoch: 6| Step: 9
Training loss: 0.4501733009104214
Validation loss: 2.0906146319340544

Epoch: 6| Step: 10
Training loss: 0.7001145660788909
Validation loss: 2.131413929134714

Epoch: 6| Step: 11
Training loss: 0.46801291370405657
Validation loss: 2.162436504997892

Epoch: 6| Step: 12
Training loss: 0.5996232419476274
Validation loss: 2.1779545106986435

Epoch: 6| Step: 13
Training loss: 0.5300179949890447
Validation loss: 2.103105355567343

Epoch: 668| Step: 0
Training loss: 0.4114864396100878
Validation loss: 2.230682492110066

Epoch: 6| Step: 1
Training loss: 0.7753763269600344
Validation loss: 2.2277120878427334

Epoch: 6| Step: 2
Training loss: 0.5295910457686779
Validation loss: 2.1751693937791883

Epoch: 6| Step: 3
Training loss: 0.6256488769578484
Validation loss: 2.2365652258595343

Epoch: 6| Step: 4
Training loss: 0.648655958029765
Validation loss: 2.2525991287663536

Epoch: 6| Step: 5
Training loss: 0.5716481702201558
Validation loss: 2.133772233725021

Epoch: 6| Step: 6
Training loss: 0.6242558817985482
Validation loss: 2.2087165161869207

Epoch: 6| Step: 7
Training loss: 0.7151811564306761
Validation loss: 2.143091812629726

Epoch: 6| Step: 8
Training loss: 1.5320460527435364
Validation loss: 2.2041498292387307

Epoch: 6| Step: 9
Training loss: 0.5840186679939517
Validation loss: 2.192028417747087

Epoch: 6| Step: 10
Training loss: 0.5172248066242215
Validation loss: 2.258932935397913

Epoch: 6| Step: 11
Training loss: 0.6070400399414878
Validation loss: 2.1479987084750025

Epoch: 6| Step: 12
Training loss: 0.4592836581134134
Validation loss: 2.194366523356497

Epoch: 6| Step: 13
Training loss: 0.4418773331641254
Validation loss: 2.211692430424497

Epoch: 669| Step: 0
Training loss: 0.3990306366258439
Validation loss: 2.082209748847839

Epoch: 6| Step: 1
Training loss: 0.6375640219909673
Validation loss: 2.1854780940466227

Epoch: 6| Step: 2
Training loss: 0.3910010625697964
Validation loss: 2.1812088913808756

Epoch: 6| Step: 3
Training loss: 0.42133400809497057
Validation loss: 2.17504782788537

Epoch: 6| Step: 4
Training loss: 0.5537486122406734
Validation loss: 2.2404501410607147

Epoch: 6| Step: 5
Training loss: 0.40811566962870455
Validation loss: 2.1891389885831414

Epoch: 6| Step: 6
Training loss: 0.44105161075736854
Validation loss: 2.0885187388733217

Epoch: 6| Step: 7
Training loss: 0.5884295050047006
Validation loss: 2.2129159172950064

Epoch: 6| Step: 8
Training loss: 1.5509054677108436
Validation loss: 2.1761604901005

Epoch: 6| Step: 9
Training loss: 0.5342563943689994
Validation loss: 2.1323610880052413

Epoch: 6| Step: 10
Training loss: 0.5552166845708679
Validation loss: 2.111554744247973

Epoch: 6| Step: 11
Training loss: 0.5463547002633989
Validation loss: 2.208210167571991

Epoch: 6| Step: 12
Training loss: 0.5587719719682235
Validation loss: 2.248465329117105

Epoch: 6| Step: 13
Training loss: 0.44488040975340015
Validation loss: 2.222826729439056

Epoch: 670| Step: 0
Training loss: 0.6301528233653231
Validation loss: 2.3157373830270624

Epoch: 6| Step: 1
Training loss: 0.5446547533741695
Validation loss: 2.2594984149728563

Epoch: 6| Step: 2
Training loss: 0.5965322259222219
Validation loss: 2.114411041581231

Epoch: 6| Step: 3
Training loss: 0.6285168881874833
Validation loss: 2.1988190691543994

Epoch: 6| Step: 4
Training loss: 0.5191495253099213
Validation loss: 2.171798206576143

Epoch: 6| Step: 5
Training loss: 0.49844141273995696
Validation loss: 2.1794053961506967

Epoch: 6| Step: 6
Training loss: 0.6270737576519253
Validation loss: 2.183243640339385

Epoch: 6| Step: 7
Training loss: 1.5944369462501886
Validation loss: 2.2157804891880084

Epoch: 6| Step: 8
Training loss: 0.4491647604964981
Validation loss: 2.1993255889452055

Epoch: 6| Step: 9
Training loss: 0.7164626836649279
Validation loss: 2.1799440115728714

Epoch: 6| Step: 10
Training loss: 0.533692048431038
Validation loss: 2.220980256876657

Epoch: 6| Step: 11
Training loss: 0.6633270005262498
Validation loss: 2.1571287647530952

Epoch: 6| Step: 12
Training loss: 0.48846843946094515
Validation loss: 2.1523901485107144

Epoch: 6| Step: 13
Training loss: 1.038233490843654
Validation loss: 2.2638207340061896

Epoch: 671| Step: 0
Training loss: 0.5731552032033522
Validation loss: 2.219425616768721

Epoch: 6| Step: 1
Training loss: 0.4068702950623077
Validation loss: 2.141860650790865

Epoch: 6| Step: 2
Training loss: 0.6441878820218135
Validation loss: 2.2131154813434737

Epoch: 6| Step: 3
Training loss: 1.5647373965112783
Validation loss: 2.2472672376775935

Epoch: 6| Step: 4
Training loss: 0.7157108905005763
Validation loss: 2.1513471727351288

Epoch: 6| Step: 5
Training loss: 0.5570307920221316
Validation loss: 2.2399602593337073

Epoch: 6| Step: 6
Training loss: 0.49021870561459585
Validation loss: 2.155163746220546

Epoch: 6| Step: 7
Training loss: 0.4529377780732904
Validation loss: 2.1465924663779505

Epoch: 6| Step: 8
Training loss: 0.5055892989259019
Validation loss: 2.0922417323960163

Epoch: 6| Step: 9
Training loss: 0.5631009706203284
Validation loss: 2.195289207349232

Epoch: 6| Step: 10
Training loss: 0.6980001390178291
Validation loss: 2.1880708597089966

Epoch: 6| Step: 11
Training loss: 0.38661614415102386
Validation loss: 2.1563781312618664

Epoch: 6| Step: 12
Training loss: 0.47719641251850287
Validation loss: 2.223923675811924

Epoch: 6| Step: 13
Training loss: 0.6005215245882827
Validation loss: 2.3221343860738175

Epoch: 672| Step: 0
Training loss: 0.4190231642158096
Validation loss: 2.1945387401737806

Epoch: 6| Step: 1
Training loss: 0.523114973311687
Validation loss: 2.13811617220975

Epoch: 6| Step: 2
Training loss: 0.5273554765315834
Validation loss: 2.162700446708976

Epoch: 6| Step: 3
Training loss: 0.6362912199536611
Validation loss: 2.0758344915802094

Epoch: 6| Step: 4
Training loss: 0.622849938530179
Validation loss: 2.2025818502511387

Epoch: 6| Step: 5
Training loss: 0.5392668516402475
Validation loss: 2.1719945008759662

Epoch: 6| Step: 6
Training loss: 0.44113557669265796
Validation loss: 2.1975419981411526

Epoch: 6| Step: 7
Training loss: 1.5841460233678115
Validation loss: 2.235739432115353

Epoch: 6| Step: 8
Training loss: 0.7491158598735776
Validation loss: 2.1872611669900315

Epoch: 6| Step: 9
Training loss: 0.3410088528619411
Validation loss: 2.1576883548758357

Epoch: 6| Step: 10
Training loss: 0.5274333736413314
Validation loss: 2.1942233456300473

Epoch: 6| Step: 11
Training loss: 0.49487678063465657
Validation loss: 2.1696814361039145

Epoch: 6| Step: 12
Training loss: 0.45554339482615736
Validation loss: 2.1985357458836687

Epoch: 6| Step: 13
Training loss: 0.5651075799607473
Validation loss: 2.1710597996240866

Epoch: 673| Step: 0
Training loss: 0.5796775333750773
Validation loss: 2.1280528487710884

Epoch: 6| Step: 1
Training loss: 0.5226511101120732
Validation loss: 2.1213691185345604

Epoch: 6| Step: 2
Training loss: 0.6206959824244143
Validation loss: 2.1891422277674915

Epoch: 6| Step: 3
Training loss: 0.4586836783570492
Validation loss: 2.2148647535594597

Epoch: 6| Step: 4
Training loss: 0.4626532320119328
Validation loss: 2.211519308635237

Epoch: 6| Step: 5
Training loss: 0.5108352488823592
Validation loss: 2.24159586102674

Epoch: 6| Step: 6
Training loss: 0.7298696580558404
Validation loss: 2.142567436447432

Epoch: 6| Step: 7
Training loss: 0.6548975222989375
Validation loss: 2.269257424165076

Epoch: 6| Step: 8
Training loss: 0.5433732865374332
Validation loss: 2.1696503982783764

Epoch: 6| Step: 9
Training loss: 0.6328488563172225
Validation loss: 2.177607409697984

Epoch: 6| Step: 10
Training loss: 0.5609671582215392
Validation loss: 2.2317499134490735

Epoch: 6| Step: 11
Training loss: 1.4953727877430798
Validation loss: 2.186410220534401

Epoch: 6| Step: 12
Training loss: 0.47492562263818644
Validation loss: 2.174391321583177

Epoch: 6| Step: 13
Training loss: 0.3783190001000686
Validation loss: 2.0767500414647446

Epoch: 674| Step: 0
Training loss: 0.7355070114475795
Validation loss: 2.2153981721141993

Epoch: 6| Step: 1
Training loss: 0.47913631743916385
Validation loss: 2.217207719667777

Epoch: 6| Step: 2
Training loss: 0.5075239682292639
Validation loss: 2.179539288819298

Epoch: 6| Step: 3
Training loss: 1.5312076484895734
Validation loss: 2.1587003125639037

Epoch: 6| Step: 4
Training loss: 0.6374227692066778
Validation loss: 2.1232181512474013

Epoch: 6| Step: 5
Training loss: 0.4600053348698374
Validation loss: 2.173704644250773

Epoch: 6| Step: 6
Training loss: 0.4169209618231212
Validation loss: 2.178522284947391

Epoch: 6| Step: 7
Training loss: 0.4322264480418292
Validation loss: 2.2960002573692107

Epoch: 6| Step: 8
Training loss: 0.4347265069985335
Validation loss: 2.2015884051461883

Epoch: 6| Step: 9
Training loss: 0.4335250456393604
Validation loss: 2.1567946511971323

Epoch: 6| Step: 10
Training loss: 0.6151555813181845
Validation loss: 2.250607140296422

Epoch: 6| Step: 11
Training loss: 0.6119793479323964
Validation loss: 2.138608874834652

Epoch: 6| Step: 12
Training loss: 0.5184607699128833
Validation loss: 2.1700987488237224

Epoch: 6| Step: 13
Training loss: 0.5645586330974395
Validation loss: 2.1571100459831793

Epoch: 675| Step: 0
Training loss: 0.4468905446209963
Validation loss: 2.1560508513601424

Epoch: 6| Step: 1
Training loss: 0.6214493986845809
Validation loss: 2.2016814619848692

Epoch: 6| Step: 2
Training loss: 0.5006516501659041
Validation loss: 2.1922025618731076

Epoch: 6| Step: 3
Training loss: 0.4945997434795129
Validation loss: 2.1475856956125052

Epoch: 6| Step: 4
Training loss: 1.5486259184140359
Validation loss: 2.1541470543318146

Epoch: 6| Step: 5
Training loss: 0.5371826676733333
Validation loss: 2.2355509035260814

Epoch: 6| Step: 6
Training loss: 0.5295583494382345
Validation loss: 2.1290950682757317

Epoch: 6| Step: 7
Training loss: 0.5921058477711162
Validation loss: 2.221535684001724

Epoch: 6| Step: 8
Training loss: 0.5079007585562284
Validation loss: 2.1905343125178045

Epoch: 6| Step: 9
Training loss: 0.42414875471720836
Validation loss: 2.204755359176642

Epoch: 6| Step: 10
Training loss: 0.5694786664970922
Validation loss: 2.289577229287046

Epoch: 6| Step: 11
Training loss: 0.6464666727183598
Validation loss: 2.154994777587177

Epoch: 6| Step: 12
Training loss: 0.5859357960994106
Validation loss: 2.164573804792586

Epoch: 6| Step: 13
Training loss: 0.4693064248167695
Validation loss: 2.2160946388810068

Epoch: 676| Step: 0
Training loss: 0.7033454761278016
Validation loss: 2.149713103318358

Epoch: 6| Step: 1
Training loss: 0.49824802600126944
Validation loss: 2.1670290318161265

Epoch: 6| Step: 2
Training loss: 0.6400396417470249
Validation loss: 2.1727447916390537

Epoch: 6| Step: 3
Training loss: 0.43595160936609145
Validation loss: 2.2394065548686557

Epoch: 6| Step: 4
Training loss: 0.6515742806300433
Validation loss: 2.194904072046558

Epoch: 6| Step: 5
Training loss: 0.6660111726405087
Validation loss: 2.1707895085988382

Epoch: 6| Step: 6
Training loss: 0.6855639159429393
Validation loss: 2.1510249273813895

Epoch: 6| Step: 7
Training loss: 0.41694383541892616
Validation loss: 2.256986395164919

Epoch: 6| Step: 8
Training loss: 0.38558839073942686
Validation loss: 2.262296401354927

Epoch: 6| Step: 9
Training loss: 0.6037212626408235
Validation loss: 2.1586873476568713

Epoch: 6| Step: 10
Training loss: 0.48246100880898224
Validation loss: 2.121473660700875

Epoch: 6| Step: 11
Training loss: 1.520901961498261
Validation loss: 2.182877522864674

Epoch: 6| Step: 12
Training loss: 0.46630178716195586
Validation loss: 2.199913936620809

Epoch: 6| Step: 13
Training loss: 0.5504063080826775
Validation loss: 2.205751447551398

Epoch: 677| Step: 0
Training loss: 0.568290916069082
Validation loss: 2.1924065739420864

Epoch: 6| Step: 1
Training loss: 0.7325563027678169
Validation loss: 2.151467559404817

Epoch: 6| Step: 2
Training loss: 0.5590446359713293
Validation loss: 2.1613001607779037

Epoch: 6| Step: 3
Training loss: 0.6095810810715879
Validation loss: 2.181110174340654

Epoch: 6| Step: 4
Training loss: 0.545648561997967
Validation loss: 2.1215992412862468

Epoch: 6| Step: 5
Training loss: 1.4247165833098803
Validation loss: 2.2345655173470425

Epoch: 6| Step: 6
Training loss: 0.4205852502799724
Validation loss: 2.2781093941734727

Epoch: 6| Step: 7
Training loss: 0.546811726860732
Validation loss: 2.172840046535834

Epoch: 6| Step: 8
Training loss: 0.5721484640442709
Validation loss: 2.167082283073126

Epoch: 6| Step: 9
Training loss: 0.740713804691262
Validation loss: 2.1921674001583553

Epoch: 6| Step: 10
Training loss: 0.5007546213958531
Validation loss: 2.230544103922012

Epoch: 6| Step: 11
Training loss: 0.39998008335716556
Validation loss: 2.0988044113369235

Epoch: 6| Step: 12
Training loss: 0.4861630845290464
Validation loss: 2.158658202458733

Epoch: 6| Step: 13
Training loss: 0.7137681133022882
Validation loss: 2.1990522163018213

Epoch: 678| Step: 0
Training loss: 0.5960186482286701
Validation loss: 2.2409316456883093

Epoch: 6| Step: 1
Training loss: 0.46410399164765415
Validation loss: 2.0988258114991813

Epoch: 6| Step: 2
Training loss: 0.7739443418762131
Validation loss: 2.2096386331525912

Epoch: 6| Step: 3
Training loss: 0.5295190098693807
Validation loss: 2.168806732060796

Epoch: 6| Step: 4
Training loss: 0.39704336965318926
Validation loss: 2.1608604421624706

Epoch: 6| Step: 5
Training loss: 0.6367901019036984
Validation loss: 2.200810000667167

Epoch: 6| Step: 6
Training loss: 1.4373340510901484
Validation loss: 2.1760930329343067

Epoch: 6| Step: 7
Training loss: 0.3590624735726794
Validation loss: 2.1106736111773525

Epoch: 6| Step: 8
Training loss: 0.7665512165618533
Validation loss: 2.195685019789353

Epoch: 6| Step: 9
Training loss: 0.47863848918916085
Validation loss: 2.1061425091881834

Epoch: 6| Step: 10
Training loss: 0.5126017167171646
Validation loss: 2.2253578207103644

Epoch: 6| Step: 11
Training loss: 0.5210460292120531
Validation loss: 2.1817113130252888

Epoch: 6| Step: 12
Training loss: 0.4926250722779088
Validation loss: 2.213362807130006

Epoch: 6| Step: 13
Training loss: 0.32283433382435295
Validation loss: 2.1797788743965465

Epoch: 679| Step: 0
Training loss: 0.529231838157957
Validation loss: 2.115633972423286

Epoch: 6| Step: 1
Training loss: 1.6160001957345598
Validation loss: 2.1745802446825238

Epoch: 6| Step: 2
Training loss: 0.6010324198663307
Validation loss: 2.1136979300806846

Epoch: 6| Step: 3
Training loss: 0.6432989651471683
Validation loss: 2.1917202836949676

Epoch: 6| Step: 4
Training loss: 0.5568825714589885
Validation loss: 2.2252482777276446

Epoch: 6| Step: 5
Training loss: 0.5964643773572029
Validation loss: 2.1842790555133287

Epoch: 6| Step: 6
Training loss: 0.4989769423113244
Validation loss: 2.1878445308574372

Epoch: 6| Step: 7
Training loss: 0.4659067389646658
Validation loss: 2.1599573819955364

Epoch: 6| Step: 8
Training loss: 0.5196846470206853
Validation loss: 2.1440775301445005

Epoch: 6| Step: 9
Training loss: 0.566369996061596
Validation loss: 2.234856136445503

Epoch: 6| Step: 10
Training loss: 0.5104422627732805
Validation loss: 2.1500336929375106

Epoch: 6| Step: 11
Training loss: 0.5950221938313612
Validation loss: 2.166851334791345

Epoch: 6| Step: 12
Training loss: 0.5869012155253436
Validation loss: 2.214608636826377

Epoch: 6| Step: 13
Training loss: 0.43615544999681916
Validation loss: 2.186649770207458

Epoch: 680| Step: 0
Training loss: 0.7062662527864273
Validation loss: 2.192224189316148

Epoch: 6| Step: 1
Training loss: 0.332283350662082
Validation loss: 2.134966173131927

Epoch: 6| Step: 2
Training loss: 0.44108118899463367
Validation loss: 2.206250675069659

Epoch: 6| Step: 3
Training loss: 0.43146402535152195
Validation loss: 2.2412054606722034

Epoch: 6| Step: 4
Training loss: 1.5285177962465413
Validation loss: 2.1346268966952278

Epoch: 6| Step: 5
Training loss: 0.49974354485125533
Validation loss: 2.246377613165744

Epoch: 6| Step: 6
Training loss: 0.47926608035671275
Validation loss: 2.1538036701408916

Epoch: 6| Step: 7
Training loss: 0.7318078888078267
Validation loss: 2.151897651516188

Epoch: 6| Step: 8
Training loss: 0.4765816043714118
Validation loss: 2.1963756510670063

Epoch: 6| Step: 9
Training loss: 0.7211776039905132
Validation loss: 2.1929013458114732

Epoch: 6| Step: 10
Training loss: 0.49172021997145393
Validation loss: 2.2041032246017602

Epoch: 6| Step: 11
Training loss: 0.6504801095799447
Validation loss: 2.1995920167481287

Epoch: 6| Step: 12
Training loss: 0.6270918172809467
Validation loss: 2.1891087266875293

Epoch: 6| Step: 13
Training loss: 0.5171923945446
Validation loss: 2.192540954167312

Epoch: 681| Step: 0
Training loss: 1.602402183177754
Validation loss: 2.178404759738206

Epoch: 6| Step: 1
Training loss: 0.36566477420665494
Validation loss: 2.222493534665859

Epoch: 6| Step: 2
Training loss: 0.5037878030360597
Validation loss: 2.129494324423731

Epoch: 6| Step: 3
Training loss: 0.5030869617654625
Validation loss: 2.1910765887997177

Epoch: 6| Step: 4
Training loss: 0.44328798231808536
Validation loss: 2.228148778193014

Epoch: 6| Step: 5
Training loss: 0.5958395879812896
Validation loss: 2.152103419364474

Epoch: 6| Step: 6
Training loss: 0.5745044698068225
Validation loss: 2.15828547886918

Epoch: 6| Step: 7
Training loss: 0.5514011546910496
Validation loss: 2.068220180636225

Epoch: 6| Step: 8
Training loss: 0.4921532573595643
Validation loss: 2.1476814587942257

Epoch: 6| Step: 9
Training loss: 0.42500318077243493
Validation loss: 2.1618973615382853

Epoch: 6| Step: 10
Training loss: 0.3821427071523945
Validation loss: 2.195036872753831

Epoch: 6| Step: 11
Training loss: 0.5168694016362144
Validation loss: 2.153708154777259

Epoch: 6| Step: 12
Training loss: 0.41549400975859
Validation loss: 2.173172495379454

Epoch: 6| Step: 13
Training loss: 0.6841299079734302
Validation loss: 2.1958271051585387

Epoch: 682| Step: 0
Training loss: 0.5231002176446595
Validation loss: 2.1655518958867854

Epoch: 6| Step: 1
Training loss: 0.7041421526718032
Validation loss: 2.1871580000118973

Epoch: 6| Step: 2
Training loss: 0.4973230974497632
Validation loss: 2.1073925892104675

Epoch: 6| Step: 3
Training loss: 0.5037752617022866
Validation loss: 2.144503251611411

Epoch: 6| Step: 4
Training loss: 0.4276793283375619
Validation loss: 2.185981681797267

Epoch: 6| Step: 5
Training loss: 0.6707512084574695
Validation loss: 2.139025153578913

Epoch: 6| Step: 6
Training loss: 0.6018629933681771
Validation loss: 2.240635096118961

Epoch: 6| Step: 7
Training loss: 0.6200132748505517
Validation loss: 2.2248817004981505

Epoch: 6| Step: 8
Training loss: 0.4009484847504802
Validation loss: 2.24115420798799

Epoch: 6| Step: 9
Training loss: 0.37401495144532365
Validation loss: 2.2574979563926303

Epoch: 6| Step: 10
Training loss: 1.6684037295773329
Validation loss: 2.1708310228945287

Epoch: 6| Step: 11
Training loss: 0.5718819956533994
Validation loss: 2.1797941083826653

Epoch: 6| Step: 12
Training loss: 0.5826497727737632
Validation loss: 2.186465076856146

Epoch: 6| Step: 13
Training loss: 0.6371154485491372
Validation loss: 2.1501289220276494

Epoch: 683| Step: 0
Training loss: 1.5546877300319788
Validation loss: 2.2454727936684518

Epoch: 6| Step: 1
Training loss: 0.4988301270399193
Validation loss: 2.079090047918948

Epoch: 6| Step: 2
Training loss: 0.6062368381683909
Validation loss: 2.163210989659697

Epoch: 6| Step: 3
Training loss: 0.45946098093893795
Validation loss: 2.242974985291124

Epoch: 6| Step: 4
Training loss: 0.46254477477494865
Validation loss: 2.1725727641593995

Epoch: 6| Step: 5
Training loss: 0.5412856161631786
Validation loss: 2.1505584682588563

Epoch: 6| Step: 6
Training loss: 0.4579307963152767
Validation loss: 2.176986475118247

Epoch: 6| Step: 7
Training loss: 0.6699954067613668
Validation loss: 2.1574678024267686

Epoch: 6| Step: 8
Training loss: 0.6890590935793732
Validation loss: 2.1630093784237907

Epoch: 6| Step: 9
Training loss: 0.5145333901646667
Validation loss: 2.1732561593792172

Epoch: 6| Step: 10
Training loss: 0.35102181713382896
Validation loss: 2.1365171568620966

Epoch: 6| Step: 11
Training loss: 0.5122604996781296
Validation loss: 2.153462149049396

Epoch: 6| Step: 12
Training loss: 0.5138904411132097
Validation loss: 2.191077826113475

Epoch: 6| Step: 13
Training loss: 0.5697236613872265
Validation loss: 2.173181431116043

Epoch: 684| Step: 0
Training loss: 1.4780334734655682
Validation loss: 2.166560746278766

Epoch: 6| Step: 1
Training loss: 0.6436285922923904
Validation loss: 2.1347217184333633

Epoch: 6| Step: 2
Training loss: 0.46826499643461506
Validation loss: 2.0722693821291336

Epoch: 6| Step: 3
Training loss: 0.47301510515954054
Validation loss: 2.163387858157492

Epoch: 6| Step: 4
Training loss: 0.6890447774325025
Validation loss: 2.1851639481485003

Epoch: 6| Step: 5
Training loss: 0.5213393106036611
Validation loss: 2.2420425862715554

Epoch: 6| Step: 6
Training loss: 0.5875835694064745
Validation loss: 2.20402485554716

Epoch: 6| Step: 7
Training loss: 0.5677560442086668
Validation loss: 2.167219191716355

Epoch: 6| Step: 8
Training loss: 0.29533993225245675
Validation loss: 2.1490384684489534

Epoch: 6| Step: 9
Training loss: 0.7150427536086358
Validation loss: 2.2135342293215654

Epoch: 6| Step: 10
Training loss: 0.43218973022679885
Validation loss: 2.215250584739803

Epoch: 6| Step: 11
Training loss: 0.3650057684102896
Validation loss: 2.096645586938272

Epoch: 6| Step: 12
Training loss: 0.47206793181987394
Validation loss: 2.135793887199537

Epoch: 6| Step: 13
Training loss: 0.47916859819879853
Validation loss: 2.198758680234652

Epoch: 685| Step: 0
Training loss: 0.6328677400567764
Validation loss: 2.1372332257919804

Epoch: 6| Step: 1
Training loss: 0.5947615890335929
Validation loss: 2.1270251995865843

Epoch: 6| Step: 2
Training loss: 0.4967918290399241
Validation loss: 2.1825774525483155

Epoch: 6| Step: 3
Training loss: 0.7001064781540922
Validation loss: 2.191303434356949

Epoch: 6| Step: 4
Training loss: 1.6070625209408527
Validation loss: 2.2042785849975837

Epoch: 6| Step: 5
Training loss: 0.5428522108416842
Validation loss: 2.1522775432926617

Epoch: 6| Step: 6
Training loss: 0.6408938099790631
Validation loss: 2.243621473390012

Epoch: 6| Step: 7
Training loss: 0.5062835564500469
Validation loss: 2.0751945243317604

Epoch: 6| Step: 8
Training loss: 0.6059622691356138
Validation loss: 2.257538821002518

Epoch: 6| Step: 9
Training loss: 0.4974234624914927
Validation loss: 2.1342925271488586

Epoch: 6| Step: 10
Training loss: 0.556942453034673
Validation loss: 2.1514635503381143

Epoch: 6| Step: 11
Training loss: 0.4575104117120737
Validation loss: 2.181750520883792

Epoch: 6| Step: 12
Training loss: 0.47750729570257694
Validation loss: 2.2511366453613815

Epoch: 6| Step: 13
Training loss: 0.4985996544612968
Validation loss: 2.185937835816007

Epoch: 686| Step: 0
Training loss: 0.4869750595599562
Validation loss: 2.134680683633349

Epoch: 6| Step: 1
Training loss: 0.42354737928897146
Validation loss: 2.1797098773253545

Epoch: 6| Step: 2
Training loss: 0.58253610720077
Validation loss: 2.2153785541544697

Epoch: 6| Step: 3
Training loss: 0.821560700227051
Validation loss: 2.2238362496795636

Epoch: 6| Step: 4
Training loss: 0.6214227105124255
Validation loss: 2.169579176677106

Epoch: 6| Step: 5
Training loss: 0.47958161866085625
Validation loss: 2.175285684854128

Epoch: 6| Step: 6
Training loss: 0.49651354952376403
Validation loss: 2.161653952871153

Epoch: 6| Step: 7
Training loss: 1.5865611085853688
Validation loss: 2.220166235175153

Epoch: 6| Step: 8
Training loss: 0.467051193357723
Validation loss: 2.2493536372820446

Epoch: 6| Step: 9
Training loss: 0.4981498163089109
Validation loss: 2.192991408311731

Epoch: 6| Step: 10
Training loss: 0.40279977380316256
Validation loss: 2.130692257614142

Epoch: 6| Step: 11
Training loss: 0.5402298602331347
Validation loss: 2.148903453784812

Epoch: 6| Step: 12
Training loss: 0.5377630244477399
Validation loss: 2.189190482380843

Epoch: 6| Step: 13
Training loss: 0.5621237291063393
Validation loss: 2.1587797890556772

Epoch: 687| Step: 0
Training loss: 0.5984635728380372
Validation loss: 2.146536091858867

Epoch: 6| Step: 1
Training loss: 0.5079831350185328
Validation loss: 2.1691900610352337

Epoch: 6| Step: 2
Training loss: 0.5269874782124221
Validation loss: 2.146128129964635

Epoch: 6| Step: 3
Training loss: 1.5228494144868299
Validation loss: 2.1985578608217717

Epoch: 6| Step: 4
Training loss: 0.7438257307076781
Validation loss: 2.1592886054788774

Epoch: 6| Step: 5
Training loss: 0.5611247629397565
Validation loss: 2.2161335727468225

Epoch: 6| Step: 6
Training loss: 0.6613969599168027
Validation loss: 2.212132096006811

Epoch: 6| Step: 7
Training loss: 0.5863057822914236
Validation loss: 2.1668090367298904

Epoch: 6| Step: 8
Training loss: 0.6001530273319196
Validation loss: 2.211368572250535

Epoch: 6| Step: 9
Training loss: 0.6281648850944128
Validation loss: 2.159254316495435

Epoch: 6| Step: 10
Training loss: 0.44941164933691974
Validation loss: 2.130532544189377

Epoch: 6| Step: 11
Training loss: 0.7253244167468195
Validation loss: 2.1669574350957794

Epoch: 6| Step: 12
Training loss: 0.4938381158692853
Validation loss: 2.2318480516055152

Epoch: 6| Step: 13
Training loss: 0.48914203301790526
Validation loss: 2.1622392623722946

Epoch: 688| Step: 0
Training loss: 0.36622070299479514
Validation loss: 2.1333941646460435

Epoch: 6| Step: 1
Training loss: 0.5074339409290024
Validation loss: 2.158598938501046

Epoch: 6| Step: 2
Training loss: 0.5849059115657163
Validation loss: 2.1295978236824142

Epoch: 6| Step: 3
Training loss: 0.41292754759760447
Validation loss: 2.1403441808193446

Epoch: 6| Step: 4
Training loss: 0.5649716856284291
Validation loss: 2.138547653596568

Epoch: 6| Step: 5
Training loss: 1.5707443174981595
Validation loss: 2.1123308401041117

Epoch: 6| Step: 6
Training loss: 0.5777369562985089
Validation loss: 2.135939484910311

Epoch: 6| Step: 7
Training loss: 0.44490383871895667
Validation loss: 2.163898879862853

Epoch: 6| Step: 8
Training loss: 0.5727097802428943
Validation loss: 2.135769684967609

Epoch: 6| Step: 9
Training loss: 0.34657547149942575
Validation loss: 2.164853581757666

Epoch: 6| Step: 10
Training loss: 0.3884166857420622
Validation loss: 2.1185935709952477

Epoch: 6| Step: 11
Training loss: 0.3880796665247505
Validation loss: 2.1667918290586914

Epoch: 6| Step: 12
Training loss: 0.7237582490546454
Validation loss: 2.22569905759567

Epoch: 6| Step: 13
Training loss: 0.39731887790540876
Validation loss: 2.1528864993735684

Epoch: 689| Step: 0
Training loss: 0.5148689622740342
Validation loss: 2.1500573888217978

Epoch: 6| Step: 1
Training loss: 0.374738622014251
Validation loss: 2.1865621334706873

Epoch: 6| Step: 2
Training loss: 0.4080675255817568
Validation loss: 2.1634127912594128

Epoch: 6| Step: 3
Training loss: 0.5670736918539548
Validation loss: 2.1726261202535713

Epoch: 6| Step: 4
Training loss: 0.4667194892869783
Validation loss: 2.2162425483044523

Epoch: 6| Step: 5
Training loss: 0.566205640322647
Validation loss: 2.230075790719064

Epoch: 6| Step: 6
Training loss: 0.28529506074351624
Validation loss: 2.229799640972444

Epoch: 6| Step: 7
Training loss: 0.6852206027041171
Validation loss: 2.2182544777123523

Epoch: 6| Step: 8
Training loss: 0.5811193093661057
Validation loss: 2.160217188167145

Epoch: 6| Step: 9
Training loss: 0.5821591435159388
Validation loss: 2.1707130665078602

Epoch: 6| Step: 10
Training loss: 0.4043158190430754
Validation loss: 2.187584267442009

Epoch: 6| Step: 11
Training loss: 0.4873586406921762
Validation loss: 2.1548268795394843

Epoch: 6| Step: 12
Training loss: 1.5517044202238741
Validation loss: 2.1084239935198505

Epoch: 6| Step: 13
Training loss: 0.7070658764869405
Validation loss: 2.121871517384596

Epoch: 690| Step: 0
Training loss: 0.6338412787935572
Validation loss: 2.1660124518347197

Epoch: 6| Step: 1
Training loss: 0.471037290995117
Validation loss: 2.136383235465071

Epoch: 6| Step: 2
Training loss: 0.5070488102345134
Validation loss: 2.1663257862778433

Epoch: 6| Step: 3
Training loss: 0.7289695655006095
Validation loss: 2.1062857809502833

Epoch: 6| Step: 4
Training loss: 0.53372753471249
Validation loss: 2.09418538733326

Epoch: 6| Step: 5
Training loss: 0.303539558949655
Validation loss: 2.106582843933534

Epoch: 6| Step: 6
Training loss: 1.5309002535249236
Validation loss: 2.2425860544932084

Epoch: 6| Step: 7
Training loss: 0.4802567704431934
Validation loss: 2.174145552565611

Epoch: 6| Step: 8
Training loss: 0.7106999430061555
Validation loss: 2.2078577461323916

Epoch: 6| Step: 9
Training loss: 0.32684743898146135
Validation loss: 2.1461911184454667

Epoch: 6| Step: 10
Training loss: 0.7831436857656623
Validation loss: 2.1398593727117214

Epoch: 6| Step: 11
Training loss: 0.5681244407206217
Validation loss: 2.1240488562160906

Epoch: 6| Step: 12
Training loss: 0.6480055599827714
Validation loss: 2.1364912559231835

Epoch: 6| Step: 13
Training loss: 0.5891914044500997
Validation loss: 2.1756606138229544

Epoch: 691| Step: 0
Training loss: 1.5590759143416648
Validation loss: 2.13178877294282

Epoch: 6| Step: 1
Training loss: 0.4851301060265097
Validation loss: 2.1825266414041944

Epoch: 6| Step: 2
Training loss: 0.5431607682156652
Validation loss: 2.154484774570612

Epoch: 6| Step: 3
Training loss: 0.8197670712754087
Validation loss: 2.1303132995583653

Epoch: 6| Step: 4
Training loss: 0.5208871400378243
Validation loss: 2.0609159505220145

Epoch: 6| Step: 5
Training loss: 0.5260213873199302
Validation loss: 2.157190211519617

Epoch: 6| Step: 6
Training loss: 0.5013923629782452
Validation loss: 2.1326013846945675

Epoch: 6| Step: 7
Training loss: 0.5764043306736002
Validation loss: 2.2313383690942152

Epoch: 6| Step: 8
Training loss: 0.5472482769739901
Validation loss: 2.1416845798840565

Epoch: 6| Step: 9
Training loss: 0.4811156035685354
Validation loss: 2.1220621530803814

Epoch: 6| Step: 10
Training loss: 0.4395595845440786
Validation loss: 2.20075364157694

Epoch: 6| Step: 11
Training loss: 0.45022074861308603
Validation loss: 2.1601020417366232

Epoch: 6| Step: 12
Training loss: 0.4197205881693856
Validation loss: 2.130542832262456

Epoch: 6| Step: 13
Training loss: 0.4427291154658428
Validation loss: 2.146139711020097

Epoch: 692| Step: 0
Training loss: 0.605416990959604
Validation loss: 2.2220080342522137

Epoch: 6| Step: 1
Training loss: 1.4720085196870465
Validation loss: 2.196361535317891

Epoch: 6| Step: 2
Training loss: 0.6242436123552854
Validation loss: 2.057591721842191

Epoch: 6| Step: 3
Training loss: 0.5428420817869072
Validation loss: 2.1397078749832845

Epoch: 6| Step: 4
Training loss: 0.4650437541854776
Validation loss: 2.1267478168280642

Epoch: 6| Step: 5
Training loss: 0.4951882095110354
Validation loss: 2.1244193181874986

Epoch: 6| Step: 6
Training loss: 0.5583814204085781
Validation loss: 2.1681488917142646

Epoch: 6| Step: 7
Training loss: 0.42802163498222323
Validation loss: 2.152893295214417

Epoch: 6| Step: 8
Training loss: 0.5091368206140172
Validation loss: 2.1334818735038272

Epoch: 6| Step: 9
Training loss: 0.3549665319758146
Validation loss: 2.094300985041343

Epoch: 6| Step: 10
Training loss: 0.6945028842072437
Validation loss: 2.189281857117636

Epoch: 6| Step: 11
Training loss: 0.4219723165378735
Validation loss: 2.099487019069384

Epoch: 6| Step: 12
Training loss: 0.5462675808449575
Validation loss: 2.2062491993422033

Epoch: 6| Step: 13
Training loss: 0.592767404340179
Validation loss: 2.1523675717194504

Epoch: 693| Step: 0
Training loss: 0.41890511842352146
Validation loss: 2.1042835298988014

Epoch: 6| Step: 1
Training loss: 0.5821831780118123
Validation loss: 2.1842437116699327

Epoch: 6| Step: 2
Training loss: 0.5267462276872241
Validation loss: 2.189167239355687

Epoch: 6| Step: 3
Training loss: 0.3328780987165948
Validation loss: 2.1640293048749952

Epoch: 6| Step: 4
Training loss: 0.4212416380326822
Validation loss: 2.1642483991638737

Epoch: 6| Step: 5
Training loss: 0.490877254293427
Validation loss: 2.1907465456518405

Epoch: 6| Step: 6
Training loss: 0.4718535677356291
Validation loss: 2.1490313621859713

Epoch: 6| Step: 7
Training loss: 1.4776273248484937
Validation loss: 2.1635685376917504

Epoch: 6| Step: 8
Training loss: 0.45819374328530854
Validation loss: 2.1145958095125708

Epoch: 6| Step: 9
Training loss: 0.40703682630237353
Validation loss: 2.1592557857546057

Epoch: 6| Step: 10
Training loss: 0.4174097190827584
Validation loss: 2.185923745314813

Epoch: 6| Step: 11
Training loss: 0.46783886414101034
Validation loss: 2.1406030757827135

Epoch: 6| Step: 12
Training loss: 0.5612838366616508
Validation loss: 2.0882799239607284

Epoch: 6| Step: 13
Training loss: 0.49758385471537514
Validation loss: 2.061155814047496

Epoch: 694| Step: 0
Training loss: 0.45293751488189865
Validation loss: 2.163750604958206

Epoch: 6| Step: 1
Training loss: 0.5737896827820614
Validation loss: 2.158112982450297

Epoch: 6| Step: 2
Training loss: 0.46259804021599144
Validation loss: 2.151689053349714

Epoch: 6| Step: 3
Training loss: 0.49052929461100936
Validation loss: 2.149984681107553

Epoch: 6| Step: 4
Training loss: 0.5766181122959542
Validation loss: 2.200832515010859

Epoch: 6| Step: 5
Training loss: 0.46534618504264796
Validation loss: 2.172969352365736

Epoch: 6| Step: 6
Training loss: 0.3420463305651923
Validation loss: 2.16921874770442

Epoch: 6| Step: 7
Training loss: 1.5338416452549806
Validation loss: 2.16205609196996

Epoch: 6| Step: 8
Training loss: 0.46103036882451665
Validation loss: 2.1423135499996655

Epoch: 6| Step: 9
Training loss: 0.4078964833860132
Validation loss: 2.166160399716128

Epoch: 6| Step: 10
Training loss: 0.370213458341131
Validation loss: 2.107886412848967

Epoch: 6| Step: 11
Training loss: 0.6605628302128753
Validation loss: 2.139119023828123

Epoch: 6| Step: 12
Training loss: 0.6401997527186671
Validation loss: 2.1413985458698566

Epoch: 6| Step: 13
Training loss: 0.4619235144650178
Validation loss: 2.2025027135515893

Epoch: 695| Step: 0
Training loss: 0.5816945888062341
Validation loss: 2.153387766951097

Epoch: 6| Step: 1
Training loss: 0.4670331827674403
Validation loss: 2.1770742559167693

Epoch: 6| Step: 2
Training loss: 0.5320831385557117
Validation loss: 2.1391500690136414

Epoch: 6| Step: 3
Training loss: 0.5547797435301053
Validation loss: 2.1293776984448574

Epoch: 6| Step: 4
Training loss: 0.5998113335576928
Validation loss: 2.0573702386878416

Epoch: 6| Step: 5
Training loss: 0.5405186046800182
Validation loss: 2.136951395249388

Epoch: 6| Step: 6
Training loss: 0.6195985081688571
Validation loss: 2.1896030225825007

Epoch: 6| Step: 7
Training loss: 0.49584486117172055
Validation loss: 2.1207633495317957

Epoch: 6| Step: 8
Training loss: 0.6445226032948647
Validation loss: 2.106490067670551

Epoch: 6| Step: 9
Training loss: 1.4338461006769994
Validation loss: 2.1415946171057927

Epoch: 6| Step: 10
Training loss: 0.536253423968857
Validation loss: 2.0635273755855046

Epoch: 6| Step: 11
Training loss: 0.5176945105638354
Validation loss: 2.147542255881741

Epoch: 6| Step: 12
Training loss: 0.6119927398042189
Validation loss: 2.1171056387042206

Epoch: 6| Step: 13
Training loss: 0.21173815304010088
Validation loss: 2.106065082779355

Epoch: 696| Step: 0
Training loss: 1.5631138930751685
Validation loss: 2.1864642092024766

Epoch: 6| Step: 1
Training loss: 0.5479854753267904
Validation loss: 2.188449582025956

Epoch: 6| Step: 2
Training loss: 0.5571276224240247
Validation loss: 2.1088096198213373

Epoch: 6| Step: 3
Training loss: 0.4901207416041025
Validation loss: 2.202446650364021

Epoch: 6| Step: 4
Training loss: 0.7185032047659506
Validation loss: 2.0823020334936837

Epoch: 6| Step: 5
Training loss: 0.574531080978904
Validation loss: 2.0479825500633653

Epoch: 6| Step: 6
Training loss: 0.39824275324969777
Validation loss: 2.168325365116568

Epoch: 6| Step: 7
Training loss: 0.5898094925184781
Validation loss: 2.2019720878336773

Epoch: 6| Step: 8
Training loss: 0.5440347758881235
Validation loss: 2.1094527734222956

Epoch: 6| Step: 9
Training loss: 0.6004414454378465
Validation loss: 2.138694743807097

Epoch: 6| Step: 10
Training loss: 0.4009554716677588
Validation loss: 2.202943795446131

Epoch: 6| Step: 11
Training loss: 0.6615787506630314
Validation loss: 2.226188009015

Epoch: 6| Step: 12
Training loss: 0.4017349748513871
Validation loss: 2.122696626477801

Epoch: 6| Step: 13
Training loss: 0.572143255176307
Validation loss: 2.170365408042959

Epoch: 697| Step: 0
Training loss: 0.4604358205939421
Validation loss: 2.0806908099882517

Epoch: 6| Step: 1
Training loss: 0.4110179568530732
Validation loss: 2.155760419544149

Epoch: 6| Step: 2
Training loss: 0.4595256941017507
Validation loss: 2.152722979520879

Epoch: 6| Step: 3
Training loss: 0.5535647890686001
Validation loss: 2.128949806269813

Epoch: 6| Step: 4
Training loss: 0.5601152093768464
Validation loss: 2.1767974593600785

Epoch: 6| Step: 5
Training loss: 0.7006245551673641
Validation loss: 2.1081623257392224

Epoch: 6| Step: 6
Training loss: 0.4156498801162952
Validation loss: 2.143317880677016

Epoch: 6| Step: 7
Training loss: 1.5121398654663345
Validation loss: 2.1868348981258543

Epoch: 6| Step: 8
Training loss: 0.5198102503062004
Validation loss: 2.1506888160197186

Epoch: 6| Step: 9
Training loss: 0.6568695050707519
Validation loss: 2.239626901540967

Epoch: 6| Step: 10
Training loss: 0.6074614925895894
Validation loss: 2.1740004924058116

Epoch: 6| Step: 11
Training loss: 0.525974530635044
Validation loss: 2.0482507481782735

Epoch: 6| Step: 12
Training loss: 0.6757734000571438
Validation loss: 2.2088823032777545

Epoch: 6| Step: 13
Training loss: 0.3571636330147444
Validation loss: 2.1228561698351363

Epoch: 698| Step: 0
Training loss: 0.6130031514001214
Validation loss: 2.159505993430166

Epoch: 6| Step: 1
Training loss: 0.6528446764067267
Validation loss: 2.212445790694075

Epoch: 6| Step: 2
Training loss: 0.43593080987206245
Validation loss: 2.1258701651666065

Epoch: 6| Step: 3
Training loss: 0.4198611903144093
Validation loss: 2.144040558807345

Epoch: 6| Step: 4
Training loss: 0.6769737350575454
Validation loss: 2.0779530678219533

Epoch: 6| Step: 5
Training loss: 0.6105181413309232
Validation loss: 2.1269911233046117

Epoch: 6| Step: 6
Training loss: 1.5600338356310093
Validation loss: 2.137356548440655

Epoch: 6| Step: 7
Training loss: 0.5673067760895315
Validation loss: 2.136251710603875

Epoch: 6| Step: 8
Training loss: 0.39366400173132055
Validation loss: 2.184701307038037

Epoch: 6| Step: 9
Training loss: 0.6137163841768754
Validation loss: 2.1948313817384566

Epoch: 6| Step: 10
Training loss: 0.5921602046584266
Validation loss: 2.1473420805945937

Epoch: 6| Step: 11
Training loss: 0.44561128464146516
Validation loss: 2.1688110973715444

Epoch: 6| Step: 12
Training loss: 0.7125760154998206
Validation loss: 2.148706212098845

Epoch: 6| Step: 13
Training loss: 0.41549643055269736
Validation loss: 2.2145178426074597

Epoch: 699| Step: 0
Training loss: 0.4695272835867054
Validation loss: 2.1193744558959264

Epoch: 6| Step: 1
Training loss: 0.6073697917233672
Validation loss: 2.130736901738084

Epoch: 6| Step: 2
Training loss: 0.5090163120605073
Validation loss: 2.212560965767146

Epoch: 6| Step: 3
Training loss: 0.6409878749756972
Validation loss: 2.1275297967188163

Epoch: 6| Step: 4
Training loss: 0.5710595085430585
Validation loss: 2.1388634557356765

Epoch: 6| Step: 5
Training loss: 0.5498990508116255
Validation loss: 2.1765289474134475

Epoch: 6| Step: 6
Training loss: 0.5172126487310763
Validation loss: 2.1442225649283304

Epoch: 6| Step: 7
Training loss: 0.5394428404118403
Validation loss: 2.136446417056446

Epoch: 6| Step: 8
Training loss: 0.5064771848889333
Validation loss: 2.0843914921493645

Epoch: 6| Step: 9
Training loss: 0.9591968868067492
Validation loss: 2.156576311751732

Epoch: 6| Step: 10
Training loss: 0.393059563429131
Validation loss: 2.1521550274025447

Epoch: 6| Step: 11
Training loss: 0.6050782451789594
Validation loss: 2.2088505924102497

Epoch: 6| Step: 12
Training loss: 0.4786114343756609
Validation loss: 2.190850437938823

Epoch: 6| Step: 13
Training loss: 1.9758633066727778
Validation loss: 2.14168956427218

Epoch: 700| Step: 0
Training loss: 0.4267146178149884
Validation loss: 2.1492455447968952

Epoch: 6| Step: 1
Training loss: 0.5045352528998962
Validation loss: 2.1539399987127297

Epoch: 6| Step: 2
Training loss: 0.7952908496120678
Validation loss: 2.198199927253435

Epoch: 6| Step: 3
Training loss: 0.497623802456712
Validation loss: 2.210600643483539

Epoch: 6| Step: 4
Training loss: 0.5575394450974607
Validation loss: 2.19128892033276

Epoch: 6| Step: 5
Training loss: 0.7139394073901661
Validation loss: 2.111596687377159

Epoch: 6| Step: 6
Training loss: 0.4113471045829313
Validation loss: 2.222043835964202

Epoch: 6| Step: 7
Training loss: 0.4019313661786174
Validation loss: 2.159450826228776

Epoch: 6| Step: 8
Training loss: 0.48998888107743954
Validation loss: 2.2340725367669974

Epoch: 6| Step: 9
Training loss: 0.43706320347477723
Validation loss: 2.1562402388233006

Epoch: 6| Step: 10
Training loss: 1.5100916896544163
Validation loss: 2.114864730923326

Epoch: 6| Step: 11
Training loss: 0.5552505536752935
Validation loss: 2.0653959373692268

Epoch: 6| Step: 12
Training loss: 0.6098887649721603
Validation loss: 2.215953746616952

Epoch: 6| Step: 13
Training loss: 0.27398795172034845
Validation loss: 2.0954170753186725

Epoch: 701| Step: 0
Training loss: 1.470141786238003
Validation loss: 2.2173929543242465

Epoch: 6| Step: 1
Training loss: 0.43276864666270737
Validation loss: 2.1047948141129167

Epoch: 6| Step: 2
Training loss: 0.5213058108815423
Validation loss: 2.1352473021983314

Epoch: 6| Step: 3
Training loss: 0.6374887362588361
Validation loss: 2.153761999043153

Epoch: 6| Step: 4
Training loss: 0.6271055517558909
Validation loss: 2.148330132718575

Epoch: 6| Step: 5
Training loss: 0.6909031303618642
Validation loss: 2.212389914289057

Epoch: 6| Step: 6
Training loss: 0.5051767758872717
Validation loss: 2.132783055604633

Epoch: 6| Step: 7
Training loss: 0.4598490585036292
Validation loss: 2.1047529205769764

Epoch: 6| Step: 8
Training loss: 0.45622797416404465
Validation loss: 2.1374721351855315

Epoch: 6| Step: 9
Training loss: 0.5456554984606456
Validation loss: 2.248705096250303

Epoch: 6| Step: 10
Training loss: 0.3824456072136736
Validation loss: 2.151314112692782

Epoch: 6| Step: 11
Training loss: 0.5523738966164896
Validation loss: 2.1505673325574834

Epoch: 6| Step: 12
Training loss: 0.4736265988286433
Validation loss: 2.2198115029037275

Epoch: 6| Step: 13
Training loss: 0.7211723557566604
Validation loss: 2.1147826439435438

Epoch: 702| Step: 0
Training loss: 0.386816879306842
Validation loss: 2.1364839057373675

Epoch: 6| Step: 1
Training loss: 0.5603424922492238
Validation loss: 2.1982221726894697

Epoch: 6| Step: 2
Training loss: 1.5406424840588857
Validation loss: 2.209955601314658

Epoch: 6| Step: 3
Training loss: 0.5167824441130494
Validation loss: 2.1979095835227267

Epoch: 6| Step: 4
Training loss: 0.4908493258078869
Validation loss: 2.116115042191955

Epoch: 6| Step: 5
Training loss: 0.5209571373344133
Validation loss: 2.114371498012886

Epoch: 6| Step: 6
Training loss: 0.6253722989353588
Validation loss: 2.1618398053746786

Epoch: 6| Step: 7
Training loss: 0.45843394937941007
Validation loss: 2.1235442426076734

Epoch: 6| Step: 8
Training loss: 0.39835035081581976
Validation loss: 2.1545233962879298

Epoch: 6| Step: 9
Training loss: 0.41741428854558027
Validation loss: 2.1409671582748753

Epoch: 6| Step: 10
Training loss: 0.3641391796188952
Validation loss: 2.170094738145404

Epoch: 6| Step: 11
Training loss: 0.7194134511208172
Validation loss: 2.2425294489366245

Epoch: 6| Step: 12
Training loss: 0.45197884528482823
Validation loss: 2.2052418681348884

Epoch: 6| Step: 13
Training loss: 0.6308216993106549
Validation loss: 2.202313757507343

Epoch: 703| Step: 0
Training loss: 0.7434412756267175
Validation loss: 2.210671166229498

Epoch: 6| Step: 1
Training loss: 1.5102679563079076
Validation loss: 2.229297273766067

Epoch: 6| Step: 2
Training loss: 0.36680371945366297
Validation loss: 2.1715708026984597

Epoch: 6| Step: 3
Training loss: 0.4327644287020119
Validation loss: 2.212182894661

Epoch: 6| Step: 4
Training loss: 0.530205991049079
Validation loss: 2.221843771173256

Epoch: 6| Step: 5
Training loss: 0.6209178891514425
Validation loss: 2.172876633004833

Epoch: 6| Step: 6
Training loss: 0.2756244532478082
Validation loss: 2.176869449941743

Epoch: 6| Step: 7
Training loss: 0.46442785811936266
Validation loss: 2.2349849499156296

Epoch: 6| Step: 8
Training loss: 0.49285168716321454
Validation loss: 2.18590860623697

Epoch: 6| Step: 9
Training loss: 0.6261582133325245
Validation loss: 2.132228526313293

Epoch: 6| Step: 10
Training loss: 0.42087717732771823
Validation loss: 2.118823340620333

Epoch: 6| Step: 11
Training loss: 0.517093301820944
Validation loss: 2.1786937955914256

Epoch: 6| Step: 12
Training loss: 0.6077266799237548
Validation loss: 2.123171897662265

Epoch: 6| Step: 13
Training loss: 0.32902195360976116
Validation loss: 2.2083049984408727

Epoch: 704| Step: 0
Training loss: 0.46352642191417853
Validation loss: 2.1835774060372786

Epoch: 6| Step: 1
Training loss: 0.4214318385009114
Validation loss: 2.152844262747674

Epoch: 6| Step: 2
Training loss: 0.5787387888833867
Validation loss: 2.1032057055948368

Epoch: 6| Step: 3
Training loss: 0.47333671516846815
Validation loss: 2.1607261923061074

Epoch: 6| Step: 4
Training loss: 0.6755732398095722
Validation loss: 2.132175762044307

Epoch: 6| Step: 5
Training loss: 1.4498824170548839
Validation loss: 2.180175155090015

Epoch: 6| Step: 6
Training loss: 0.47353446961972834
Validation loss: 2.198890913537973

Epoch: 6| Step: 7
Training loss: 0.5373512417070526
Validation loss: 2.2028516350939733

Epoch: 6| Step: 8
Training loss: 0.54734354383425
Validation loss: 2.2065659148879204

Epoch: 6| Step: 9
Training loss: 0.6289888410654882
Validation loss: 2.2329349353334127

Epoch: 6| Step: 10
Training loss: 0.6079993737870053
Validation loss: 2.172780981499465

Epoch: 6| Step: 11
Training loss: 0.517205590107484
Validation loss: 2.1197362904993775

Epoch: 6| Step: 12
Training loss: 0.5672353004511275
Validation loss: 2.237438974965036

Epoch: 6| Step: 13
Training loss: 0.4896812357985697
Validation loss: 2.2361167477164483

Epoch: 705| Step: 0
Training loss: 0.4213220716904906
Validation loss: 2.1795330483193296

Epoch: 6| Step: 1
Training loss: 0.42455222860372926
Validation loss: 2.145588369710785

Epoch: 6| Step: 2
Training loss: 1.3760363834500111
Validation loss: 2.148445033622353

Epoch: 6| Step: 3
Training loss: 0.5086037853088854
Validation loss: 2.1944645985046964

Epoch: 6| Step: 4
Training loss: 0.6380529175041703
Validation loss: 2.1963470663912226

Epoch: 6| Step: 5
Training loss: 0.5497773673551921
Validation loss: 2.1504257425943103

Epoch: 6| Step: 6
Training loss: 0.45310757044451877
Validation loss: 2.1368340161226262

Epoch: 6| Step: 7
Training loss: 0.49365741489420506
Validation loss: 2.140842214446571

Epoch: 6| Step: 8
Training loss: 0.5480981227761874
Validation loss: 2.1173277359961293

Epoch: 6| Step: 9
Training loss: 0.5524959791477319
Validation loss: 2.165228549420878

Epoch: 6| Step: 10
Training loss: 0.3792710072489843
Validation loss: 2.101973606601536

Epoch: 6| Step: 11
Training loss: 0.38780497194002805
Validation loss: 2.173965335819359

Epoch: 6| Step: 12
Training loss: 0.5420705927593609
Validation loss: 2.136112587353335

Epoch: 6| Step: 13
Training loss: 0.7003605433491475
Validation loss: 2.0826230483153596

Epoch: 706| Step: 0
Training loss: 0.7241834432314308
Validation loss: 2.1358561208939304

Epoch: 6| Step: 1
Training loss: 0.5763867769496276
Validation loss: 2.1940586604145413

Epoch: 6| Step: 2
Training loss: 0.3800016673264817
Validation loss: 2.1741103499789887

Epoch: 6| Step: 3
Training loss: 1.4886072157283485
Validation loss: 2.1674425019472974

Epoch: 6| Step: 4
Training loss: 0.5881514113411465
Validation loss: 2.1676689285773247

Epoch: 6| Step: 5
Training loss: 0.5522359750969131
Validation loss: 2.1848721143892065

Epoch: 6| Step: 6
Training loss: 0.5844201850761631
Validation loss: 2.163378538017807

Epoch: 6| Step: 7
Training loss: 0.497152025742304
Validation loss: 2.192744839466951

Epoch: 6| Step: 8
Training loss: 0.5092890766434454
Validation loss: 2.14836820399304

Epoch: 6| Step: 9
Training loss: 0.49952925933737163
Validation loss: 2.1113343248557737

Epoch: 6| Step: 10
Training loss: 0.57598284190504
Validation loss: 2.219907781780294

Epoch: 6| Step: 11
Training loss: 0.5042443139470074
Validation loss: 2.1222504991367974

Epoch: 6| Step: 12
Training loss: 0.4913030883019592
Validation loss: 2.1166000874200757

Epoch: 6| Step: 13
Training loss: 0.47459210650892353
Validation loss: 2.150345308781708

Epoch: 707| Step: 0
Training loss: 0.4004121355931045
Validation loss: 2.1297829502603176

Epoch: 6| Step: 1
Training loss: 0.3967145054617555
Validation loss: 2.1703451568254595

Epoch: 6| Step: 2
Training loss: 0.7510424363074589
Validation loss: 2.1903663735717163

Epoch: 6| Step: 3
Training loss: 0.5134079984244713
Validation loss: 2.1591367766780833

Epoch: 6| Step: 4
Training loss: 0.5831305855404822
Validation loss: 2.2110477427127018

Epoch: 6| Step: 5
Training loss: 0.5511719961186525
Validation loss: 2.1011323846642873

Epoch: 6| Step: 6
Training loss: 0.46490830686421525
Validation loss: 2.190692592305564

Epoch: 6| Step: 7
Training loss: 0.55334393214891
Validation loss: 2.136332462642926

Epoch: 6| Step: 8
Training loss: 0.5913265361000998
Validation loss: 2.1858432871589275

Epoch: 6| Step: 9
Training loss: 1.4811362822456524
Validation loss: 2.1188584853398273

Epoch: 6| Step: 10
Training loss: 0.6002109752712963
Validation loss: 2.1107460418562347

Epoch: 6| Step: 11
Training loss: 0.483303515429807
Validation loss: 2.1579663717496747

Epoch: 6| Step: 12
Training loss: 0.5127759888161895
Validation loss: 2.12105361307361

Epoch: 6| Step: 13
Training loss: 0.5156016489001085
Validation loss: 2.0958447043605957

Epoch: 708| Step: 0
Training loss: 0.5346923265178002
Validation loss: 2.194700188759437

Epoch: 6| Step: 1
Training loss: 0.5192989891425861
Validation loss: 2.1715167583711543

Epoch: 6| Step: 2
Training loss: 0.6317429393031071
Validation loss: 2.1116862734209505

Epoch: 6| Step: 3
Training loss: 0.4167431125449318
Validation loss: 2.1902787392346

Epoch: 6| Step: 4
Training loss: 0.42687881814301926
Validation loss: 2.0456516505573075

Epoch: 6| Step: 5
Training loss: 0.43601834220975977
Validation loss: 2.1775152660425428

Epoch: 6| Step: 6
Training loss: 0.3239463673106056
Validation loss: 2.193087538136963

Epoch: 6| Step: 7
Training loss: 0.3653657850199066
Validation loss: 2.1923698713774518

Epoch: 6| Step: 8
Training loss: 0.5169967841393306
Validation loss: 2.179193240793673

Epoch: 6| Step: 9
Training loss: 0.5384210834004175
Validation loss: 2.1757091167753635

Epoch: 6| Step: 10
Training loss: 1.5139103264802494
Validation loss: 2.129340480756515

Epoch: 6| Step: 11
Training loss: 0.4968650708915891
Validation loss: 2.1522452851876186

Epoch: 6| Step: 12
Training loss: 0.5412418980245343
Validation loss: 2.084999498217882

Epoch: 6| Step: 13
Training loss: 0.4210572441002931
Validation loss: 2.203632932403439

Epoch: 709| Step: 0
Training loss: 0.5156648793837865
Validation loss: 2.1599545132706335

Epoch: 6| Step: 1
Training loss: 0.6631552613640489
Validation loss: 2.1794312781871743

Epoch: 6| Step: 2
Training loss: 0.5542979417162921
Validation loss: 2.0477151343460602

Epoch: 6| Step: 3
Training loss: 0.39766217510253404
Validation loss: 2.1686883700427235

Epoch: 6| Step: 4
Training loss: 0.46443048908073925
Validation loss: 2.129552904678156

Epoch: 6| Step: 5
Training loss: 1.4702503576331765
Validation loss: 2.188776614097143

Epoch: 6| Step: 6
Training loss: 0.5577779828673227
Validation loss: 2.1476021081638104

Epoch: 6| Step: 7
Training loss: 0.7079442068007757
Validation loss: 2.181039356342691

Epoch: 6| Step: 8
Training loss: 0.5683942174554945
Validation loss: 2.12088694690131

Epoch: 6| Step: 9
Training loss: 0.2023644053841501
Validation loss: 2.1469332783687216

Epoch: 6| Step: 10
Training loss: 0.4715784884422633
Validation loss: 2.213912774862243

Epoch: 6| Step: 11
Training loss: 0.6196282809880366
Validation loss: 2.058929578483033

Epoch: 6| Step: 12
Training loss: 0.45519572690825233
Validation loss: 2.141253242132718

Epoch: 6| Step: 13
Training loss: 0.3809510145223186
Validation loss: 2.1287282971144172

Epoch: 710| Step: 0
Training loss: 0.6248232591593101
Validation loss: 2.213118830812288

Epoch: 6| Step: 1
Training loss: 0.4210962065446359
Validation loss: 2.157716634257604

Epoch: 6| Step: 2
Training loss: 0.6348016347207869
Validation loss: 2.118727279203919

Epoch: 6| Step: 3
Training loss: 0.5620454700188666
Validation loss: 2.239752951683314

Epoch: 6| Step: 4
Training loss: 0.5560320823799129
Validation loss: 2.083159667949642

Epoch: 6| Step: 5
Training loss: 0.696396250987876
Validation loss: 2.1557104426331826

Epoch: 6| Step: 6
Training loss: 0.4174076485284485
Validation loss: 2.2169123712885326

Epoch: 6| Step: 7
Training loss: 0.4623429805108487
Validation loss: 2.1698553811455508

Epoch: 6| Step: 8
Training loss: 0.6102973120421274
Validation loss: 2.1956886048446203

Epoch: 6| Step: 9
Training loss: 0.4832440370526302
Validation loss: 2.102598651018547

Epoch: 6| Step: 10
Training loss: 0.5073552347051711
Validation loss: 2.190375108371586

Epoch: 6| Step: 11
Training loss: 0.40325936510429505
Validation loss: 2.192358045741637

Epoch: 6| Step: 12
Training loss: 0.42657941847565595
Validation loss: 2.2102867208501187

Epoch: 6| Step: 13
Training loss: 1.9086087751324134
Validation loss: 2.144519653085733

Epoch: 711| Step: 0
Training loss: 0.4816737996577491
Validation loss: 2.1561289844435736

Epoch: 6| Step: 1
Training loss: 0.5256834667587623
Validation loss: 2.1004960696448935

Epoch: 6| Step: 2
Training loss: 0.5174243050653116
Validation loss: 2.1953543411358885

Epoch: 6| Step: 3
Training loss: 0.565700538607215
Validation loss: 2.106637543431158

Epoch: 6| Step: 4
Training loss: 0.554217018144094
Validation loss: 2.172420752728349

Epoch: 6| Step: 5
Training loss: 0.47932682954163186
Validation loss: 2.1870338845740416

Epoch: 6| Step: 6
Training loss: 1.440508886196662
Validation loss: 2.185156227286712

Epoch: 6| Step: 7
Training loss: 0.7448329958530474
Validation loss: 2.1747425454550915

Epoch: 6| Step: 8
Training loss: 0.5246434056541546
Validation loss: 2.100037988220484

Epoch: 6| Step: 9
Training loss: 0.5434730986681702
Validation loss: 2.250662290297435

Epoch: 6| Step: 10
Training loss: 0.24503318897555806
Validation loss: 2.2403484936626246

Epoch: 6| Step: 11
Training loss: 0.5209937198373898
Validation loss: 2.1863433405090227

Epoch: 6| Step: 12
Training loss: 0.527214995313358
Validation loss: 2.1461980764383344

Epoch: 6| Step: 13
Training loss: 0.6132933500031706
Validation loss: 2.1033995501278806

Epoch: 712| Step: 0
Training loss: 0.5036693282171717
Validation loss: 2.1463872929449592

Epoch: 6| Step: 1
Training loss: 0.5814038678033051
Validation loss: 2.1864747353424923

Epoch: 6| Step: 2
Training loss: 0.5672598359191235
Validation loss: 2.168371518602583

Epoch: 6| Step: 3
Training loss: 0.5509515593709808
Validation loss: 2.2516144551372506

Epoch: 6| Step: 4
Training loss: 0.548097823718754
Validation loss: 2.139335663792652

Epoch: 6| Step: 5
Training loss: 0.5961073207685343
Validation loss: 2.19443091348582

Epoch: 6| Step: 6
Training loss: 0.3426695880998829
Validation loss: 2.207552340090048

Epoch: 6| Step: 7
Training loss: 1.4939228771837663
Validation loss: 2.202649852116225

Epoch: 6| Step: 8
Training loss: 0.4721588481034015
Validation loss: 2.1529782562993702

Epoch: 6| Step: 9
Training loss: 0.4051851842914989
Validation loss: 2.180216134383026

Epoch: 6| Step: 10
Training loss: 0.5519013074780249
Validation loss: 2.14978761971413

Epoch: 6| Step: 11
Training loss: 0.6127078783754979
Validation loss: 2.1598698337268343

Epoch: 6| Step: 12
Training loss: 0.45566722085563727
Validation loss: 2.158153368583699

Epoch: 6| Step: 13
Training loss: 0.4769371467432057
Validation loss: 2.159717693833431

Epoch: 713| Step: 0
Training loss: 0.6376847971681606
Validation loss: 2.133168746655271

Epoch: 6| Step: 1
Training loss: 0.5328343272282926
Validation loss: 2.0168586727352302

Epoch: 6| Step: 2
Training loss: 0.6744928149949845
Validation loss: 2.1553101705075486

Epoch: 6| Step: 3
Training loss: 0.41295107540623827
Validation loss: 2.136145704443494

Epoch: 6| Step: 4
Training loss: 0.4375492817506332
Validation loss: 2.1618107195762293

Epoch: 6| Step: 5
Training loss: 0.35198872478264837
Validation loss: 2.152666361829223

Epoch: 6| Step: 6
Training loss: 0.6698136311712215
Validation loss: 2.149566134379497

Epoch: 6| Step: 7
Training loss: 0.6850150237907086
Validation loss: 2.1465944467981695

Epoch: 6| Step: 8
Training loss: 0.5164486923897755
Validation loss: 2.1666062842001814

Epoch: 6| Step: 9
Training loss: 0.42151859911680967
Validation loss: 2.1790832777057396

Epoch: 6| Step: 10
Training loss: 1.4241652436283712
Validation loss: 2.0780735378044586

Epoch: 6| Step: 11
Training loss: 0.6828332212608021
Validation loss: 2.1721756565379056

Epoch: 6| Step: 12
Training loss: 0.560351826297755
Validation loss: 2.0923182343307434

Epoch: 6| Step: 13
Training loss: 0.5705165498006348
Validation loss: 2.1246503033111246

Epoch: 714| Step: 0
Training loss: 0.7353772567981546
Validation loss: 2.196810230166266

Epoch: 6| Step: 1
Training loss: 1.415572229879702
Validation loss: 2.109916613224372

Epoch: 6| Step: 2
Training loss: 0.42011299219878706
Validation loss: 2.0284546820198925

Epoch: 6| Step: 3
Training loss: 0.5919494683972252
Validation loss: 2.115002471234674

Epoch: 6| Step: 4
Training loss: 0.6036208965251301
Validation loss: 2.1565314619408893

Epoch: 6| Step: 5
Training loss: 0.6134247581569451
Validation loss: 2.103535879158372

Epoch: 6| Step: 6
Training loss: 0.3968473379752604
Validation loss: 2.1491182008503613

Epoch: 6| Step: 7
Training loss: 0.5486627784440976
Validation loss: 2.153641594809711

Epoch: 6| Step: 8
Training loss: 0.5157503495873927
Validation loss: 2.165866259862651

Epoch: 6| Step: 9
Training loss: 0.5729800507133493
Validation loss: 2.119251015883492

Epoch: 6| Step: 10
Training loss: 0.5256926792131376
Validation loss: 2.2032942150199086

Epoch: 6| Step: 11
Training loss: 0.5478485161735714
Validation loss: 2.1255164088978376

Epoch: 6| Step: 12
Training loss: 0.5780707153403046
Validation loss: 2.1395545440474173

Epoch: 6| Step: 13
Training loss: 0.3980160709699529
Validation loss: 2.1144226235819006

Epoch: 715| Step: 0
Training loss: 0.5940282069486555
Validation loss: 2.153945718853746

Epoch: 6| Step: 1
Training loss: 0.539195528063709
Validation loss: 2.140869599707531

Epoch: 6| Step: 2
Training loss: 0.7123049904163952
Validation loss: 2.219043169839963

Epoch: 6| Step: 3
Training loss: 0.5431101498258215
Validation loss: 2.1022453962822425

Epoch: 6| Step: 4
Training loss: 0.43070838336858797
Validation loss: 2.0999656814099263

Epoch: 6| Step: 5
Training loss: 0.5504739323333375
Validation loss: 2.215406860293323

Epoch: 6| Step: 6
Training loss: 0.7283000882881066
Validation loss: 2.1493493829212573

Epoch: 6| Step: 7
Training loss: 0.5100338986294535
Validation loss: 2.12471370348826

Epoch: 6| Step: 8
Training loss: 1.414517914163386
Validation loss: 2.147303837115597

Epoch: 6| Step: 9
Training loss: 0.6331019504866549
Validation loss: 2.0787608385749716

Epoch: 6| Step: 10
Training loss: 0.4980643475029507
Validation loss: 2.078953053944804

Epoch: 6| Step: 11
Training loss: 0.38318205531502847
Validation loss: 2.106174729995596

Epoch: 6| Step: 12
Training loss: 0.422412036000167
Validation loss: 2.135803673403319

Epoch: 6| Step: 13
Training loss: 0.3629551726423938
Validation loss: 2.1027800361879563

Epoch: 716| Step: 0
Training loss: 0.4603672379360605
Validation loss: 2.278962207869479

Epoch: 6| Step: 1
Training loss: 0.47377770164242416
Validation loss: 2.1460121750090537

Epoch: 6| Step: 2
Training loss: 0.5659000107530107
Validation loss: 2.1151531320041874

Epoch: 6| Step: 3
Training loss: 0.41021964173675185
Validation loss: 2.1480303527524693

Epoch: 6| Step: 4
Training loss: 0.4838907990346148
Validation loss: 2.1866663972017575

Epoch: 6| Step: 5
Training loss: 0.651588185121991
Validation loss: 2.2189843970971435

Epoch: 6| Step: 6
Training loss: 1.4093703935975035
Validation loss: 2.1705339998161866

Epoch: 6| Step: 7
Training loss: 0.3974432039171
Validation loss: 2.158902572607104

Epoch: 6| Step: 8
Training loss: 0.37637771409600834
Validation loss: 2.1409354802481952

Epoch: 6| Step: 9
Training loss: 0.5563347226889884
Validation loss: 2.1643332941337206

Epoch: 6| Step: 10
Training loss: 0.5011169653267675
Validation loss: 2.119748979642438

Epoch: 6| Step: 11
Training loss: 0.6381878900127959
Validation loss: 2.101753236881578

Epoch: 6| Step: 12
Training loss: 0.5110239743190849
Validation loss: 2.114065254326714

Epoch: 6| Step: 13
Training loss: 0.45104584027562583
Validation loss: 2.1387570450222166

Epoch: 717| Step: 0
Training loss: 0.5104212144402555
Validation loss: 2.212818330909028

Epoch: 6| Step: 1
Training loss: 0.4283872351177853
Validation loss: 2.150672248221452

Epoch: 6| Step: 2
Training loss: 0.4157369333852949
Validation loss: 2.1476159433612834

Epoch: 6| Step: 3
Training loss: 1.4701014043904161
Validation loss: 2.244169655880395

Epoch: 6| Step: 4
Training loss: 0.6835843984781675
Validation loss: 2.068254413955179

Epoch: 6| Step: 5
Training loss: 0.46534080537127326
Validation loss: 2.1506423754398645

Epoch: 6| Step: 6
Training loss: 0.5990343100969974
Validation loss: 2.144368305273617

Epoch: 6| Step: 7
Training loss: 0.4018566738773413
Validation loss: 2.116277669260516

Epoch: 6| Step: 8
Training loss: 0.4991287747342365
Validation loss: 2.123032197434466

Epoch: 6| Step: 9
Training loss: 0.5301453943375044
Validation loss: 2.130384734591951

Epoch: 6| Step: 10
Training loss: 0.5706489302264602
Validation loss: 2.098628590727189

Epoch: 6| Step: 11
Training loss: 0.46911452742509524
Validation loss: 2.1517430363061703

Epoch: 6| Step: 12
Training loss: 0.41431716069367835
Validation loss: 2.127333992171245

Epoch: 6| Step: 13
Training loss: 0.36330981808795854
Validation loss: 2.143268264327966

Epoch: 718| Step: 0
Training loss: 0.47541633730761895
Validation loss: 2.1372411923476853

Epoch: 6| Step: 1
Training loss: 0.4464375021586177
Validation loss: 2.1519000627859506

Epoch: 6| Step: 2
Training loss: 0.6536816793595319
Validation loss: 2.089370782276194

Epoch: 6| Step: 3
Training loss: 0.4077116092393686
Validation loss: 2.1805115887516044

Epoch: 6| Step: 4
Training loss: 0.5902176234192689
Validation loss: 2.0899139303576253

Epoch: 6| Step: 5
Training loss: 0.61587295089483
Validation loss: 2.179404735656583

Epoch: 6| Step: 6
Training loss: 0.5424653333583485
Validation loss: 2.204140590737803

Epoch: 6| Step: 7
Training loss: 0.597250457830561
Validation loss: 2.124569387194803

Epoch: 6| Step: 8
Training loss: 0.3716970859610921
Validation loss: 2.161782605818079

Epoch: 6| Step: 9
Training loss: 0.40986957522493467
Validation loss: 2.118960979678998

Epoch: 6| Step: 10
Training loss: 0.41019641134639645
Validation loss: 2.143386773622554

Epoch: 6| Step: 11
Training loss: 0.422668946193591
Validation loss: 2.2273907833339055

Epoch: 6| Step: 12
Training loss: 1.4787900561649725
Validation loss: 2.115784162321505

Epoch: 6| Step: 13
Training loss: 0.5233986114175967
Validation loss: 2.1677369098443626

Epoch: 719| Step: 0
Training loss: 0.5213622618156957
Validation loss: 2.1674368398991737

Epoch: 6| Step: 1
Training loss: 0.5724911294274898
Validation loss: 2.109325357002614

Epoch: 6| Step: 2
Training loss: 0.46537481153362925
Validation loss: 2.1346986146133555

Epoch: 6| Step: 3
Training loss: 0.6288476999643415
Validation loss: 2.147139114226158

Epoch: 6| Step: 4
Training loss: 0.6960734585973793
Validation loss: 2.1508832572902405

Epoch: 6| Step: 5
Training loss: 0.5020436602333985
Validation loss: 2.235547235037429

Epoch: 6| Step: 6
Training loss: 0.4041739935882642
Validation loss: 2.0949488112631416

Epoch: 6| Step: 7
Training loss: 0.46894937090088734
Validation loss: 2.1968667732756546

Epoch: 6| Step: 8
Training loss: 0.49679224896665464
Validation loss: 2.142779122197954

Epoch: 6| Step: 9
Training loss: 0.45394904744123626
Validation loss: 2.151122087948076

Epoch: 6| Step: 10
Training loss: 1.475139760007151
Validation loss: 2.090893449308963

Epoch: 6| Step: 11
Training loss: 0.4821420236232153
Validation loss: 2.1787882485617454

Epoch: 6| Step: 12
Training loss: 0.4444986066581849
Validation loss: 2.1528606328281468

Epoch: 6| Step: 13
Training loss: 0.539725407438139
Validation loss: 2.1091089680221184

Epoch: 720| Step: 0
Training loss: 0.43969453750433335
Validation loss: 2.197991201978585

Epoch: 6| Step: 1
Training loss: 0.502600523255209
Validation loss: 2.126780664478021

Epoch: 6| Step: 2
Training loss: 0.5460335934403718
Validation loss: 2.2827001085080516

Epoch: 6| Step: 3
Training loss: 0.5717340545816033
Validation loss: 2.1530966818140165

Epoch: 6| Step: 4
Training loss: 0.3356122615996787
Validation loss: 2.168101943622331

Epoch: 6| Step: 5
Training loss: 0.5193096060962046
Validation loss: 2.173045337272963

Epoch: 6| Step: 6
Training loss: 0.4342431712275234
Validation loss: 2.134928697426778

Epoch: 6| Step: 7
Training loss: 0.523960080406153
Validation loss: 2.1375826347769427

Epoch: 6| Step: 8
Training loss: 0.6760278152747463
Validation loss: 2.1872135490459175

Epoch: 6| Step: 9
Training loss: 0.6148696787309801
Validation loss: 2.1282717257878145

Epoch: 6| Step: 10
Training loss: 1.4823977502360104
Validation loss: 2.200046191378498

Epoch: 6| Step: 11
Training loss: 0.5399184687312009
Validation loss: 2.122692676900889

Epoch: 6| Step: 12
Training loss: 0.7131849543571421
Validation loss: 2.217506093511193

Epoch: 6| Step: 13
Training loss: 0.5506197374679102
Validation loss: 2.125244774374541

Epoch: 721| Step: 0
Training loss: 0.43407403275594547
Validation loss: 2.159103417363993

Epoch: 6| Step: 1
Training loss: 0.5859256997509685
Validation loss: 2.1058625918631333

Epoch: 6| Step: 2
Training loss: 0.3728097491550561
Validation loss: 2.127562589519415

Epoch: 6| Step: 3
Training loss: 0.6904303997203385
Validation loss: 2.1170243191769744

Epoch: 6| Step: 4
Training loss: 0.5651073953797063
Validation loss: 2.1644968340561306

Epoch: 6| Step: 5
Training loss: 0.5585961775293489
Validation loss: 2.099893642526349

Epoch: 6| Step: 6
Training loss: 0.4515742699696244
Validation loss: 2.1860879457066074

Epoch: 6| Step: 7
Training loss: 0.41182020627521687
Validation loss: 2.159264566264028

Epoch: 6| Step: 8
Training loss: 0.7438692013401231
Validation loss: 2.192477453318424

Epoch: 6| Step: 9
Training loss: 0.5762227181453624
Validation loss: 2.2363062775343527

Epoch: 6| Step: 10
Training loss: 0.4254939658726655
Validation loss: 2.149065250033511

Epoch: 6| Step: 11
Training loss: 0.4826306343135053
Validation loss: 2.180735458142017

Epoch: 6| Step: 12
Training loss: 1.4573194612475115
Validation loss: 2.1440088711873253

Epoch: 6| Step: 13
Training loss: 0.48229773464738634
Validation loss: 2.1350816329301043

Epoch: 722| Step: 0
Training loss: 0.389273211858375
Validation loss: 2.1506046215771155

Epoch: 6| Step: 1
Training loss: 0.4003738399802037
Validation loss: 2.1393630359838274

Epoch: 6| Step: 2
Training loss: 0.5839598277364665
Validation loss: 2.1633972049196806

Epoch: 6| Step: 3
Training loss: 0.6641939145373696
Validation loss: 2.1241987504510065

Epoch: 6| Step: 4
Training loss: 0.4506800228816418
Validation loss: 2.2121169908482234

Epoch: 6| Step: 5
Training loss: 1.4167854689356405
Validation loss: 2.1544441447476848

Epoch: 6| Step: 6
Training loss: 0.7665530827251342
Validation loss: 2.102639487104954

Epoch: 6| Step: 7
Training loss: 0.5749276903544936
Validation loss: 2.2245371938088883

Epoch: 6| Step: 8
Training loss: 0.4471448043818276
Validation loss: 2.1700346757265496

Epoch: 6| Step: 9
Training loss: 0.560392006138879
Validation loss: 2.1603391625861996

Epoch: 6| Step: 10
Training loss: 0.6373163706778003
Validation loss: 2.1399896557741633

Epoch: 6| Step: 11
Training loss: 0.5673656625174729
Validation loss: 2.112015060516924

Epoch: 6| Step: 12
Training loss: 0.5178856853549348
Validation loss: 2.0849466976055955

Epoch: 6| Step: 13
Training loss: 0.5619869541574956
Validation loss: 2.1392236614831455

Epoch: 723| Step: 0
Training loss: 0.5850021016661884
Validation loss: 2.2127174104232252

Epoch: 6| Step: 1
Training loss: 0.4891616513592487
Validation loss: 2.1530735289938923

Epoch: 6| Step: 2
Training loss: 0.4890598955176475
Validation loss: 2.1800940573268015

Epoch: 6| Step: 3
Training loss: 0.650504987130191
Validation loss: 2.158115066634656

Epoch: 6| Step: 4
Training loss: 0.62710783288523
Validation loss: 2.2553609164411386

Epoch: 6| Step: 5
Training loss: 0.5447749825202799
Validation loss: 2.1790294338210536

Epoch: 6| Step: 6
Training loss: 1.4894798438484198
Validation loss: 2.1371131720855097

Epoch: 6| Step: 7
Training loss: 0.5046441641233237
Validation loss: 2.1664671447111545

Epoch: 6| Step: 8
Training loss: 0.34330928250479975
Validation loss: 2.1555332147511588

Epoch: 6| Step: 9
Training loss: 0.4896657617316942
Validation loss: 2.153908873309657

Epoch: 6| Step: 10
Training loss: 0.5830397605129686
Validation loss: 2.2194490338240316

Epoch: 6| Step: 11
Training loss: 0.7875693896164616
Validation loss: 2.1809034169562187

Epoch: 6| Step: 12
Training loss: 0.4609841791859866
Validation loss: 2.106247180279446

Epoch: 6| Step: 13
Training loss: 0.29868422889554636
Validation loss: 2.1825243238766263

Epoch: 724| Step: 0
Training loss: 0.4200364244935721
Validation loss: 2.1318211875643027

Epoch: 6| Step: 1
Training loss: 0.47959055153855296
Validation loss: 2.1843099071865533

Epoch: 6| Step: 2
Training loss: 0.49814157520606916
Validation loss: 2.157369266381394

Epoch: 6| Step: 3
Training loss: 0.43252398862628444
Validation loss: 2.185520374483796

Epoch: 6| Step: 4
Training loss: 0.492972459491974
Validation loss: 2.217080883795159

Epoch: 6| Step: 5
Training loss: 0.5658627237075761
Validation loss: 2.1364384283377476

Epoch: 6| Step: 6
Training loss: 0.35572876695170175
Validation loss: 2.1776119680982293

Epoch: 6| Step: 7
Training loss: 1.4182959144996596
Validation loss: 2.147278885901895

Epoch: 6| Step: 8
Training loss: 0.5885385130626167
Validation loss: 2.06401614164048

Epoch: 6| Step: 9
Training loss: 0.45283706329886525
Validation loss: 2.1349169856086543

Epoch: 6| Step: 10
Training loss: 0.5977737211580594
Validation loss: 2.203935810114837

Epoch: 6| Step: 11
Training loss: 0.48302045744661315
Validation loss: 2.198588361708724

Epoch: 6| Step: 12
Training loss: 0.6860585490409499
Validation loss: 2.135494145734317

Epoch: 6| Step: 13
Training loss: 0.4676316749292143
Validation loss: 2.211090597419742

Epoch: 725| Step: 0
Training loss: 0.4547596091020152
Validation loss: 2.1314953467538404

Epoch: 6| Step: 1
Training loss: 0.37661136690008756
Validation loss: 2.109116763673779

Epoch: 6| Step: 2
Training loss: 1.44011011749013
Validation loss: 2.125904751426081

Epoch: 6| Step: 3
Training loss: 0.6169593485914052
Validation loss: 2.198472710297072

Epoch: 6| Step: 4
Training loss: 0.5345351798931441
Validation loss: 2.1136907802004243

Epoch: 6| Step: 5
Training loss: 0.49067620963825387
Validation loss: 2.188807934416632

Epoch: 6| Step: 6
Training loss: 0.46261263197595204
Validation loss: 2.164811982735297

Epoch: 6| Step: 7
Training loss: 0.4877604644607002
Validation loss: 2.1136895297269387

Epoch: 6| Step: 8
Training loss: 0.3795754137723967
Validation loss: 2.1355242334181166

Epoch: 6| Step: 9
Training loss: 0.4714025943248946
Validation loss: 2.0954819943065943

Epoch: 6| Step: 10
Training loss: 0.609903131164967
Validation loss: 2.088907513324169

Epoch: 6| Step: 11
Training loss: 0.5297170850205406
Validation loss: 2.107449532751732

Epoch: 6| Step: 12
Training loss: 0.3985872548230973
Validation loss: 2.1509617699742227

Epoch: 6| Step: 13
Training loss: 0.3405265088258468
Validation loss: 2.2048733942449092

Epoch: 726| Step: 0
Training loss: 0.482102369382132
Validation loss: 2.1837966052490234

Epoch: 6| Step: 1
Training loss: 0.46573118240829176
Validation loss: 2.1728021615857886

Epoch: 6| Step: 2
Training loss: 1.4892769433965902
Validation loss: 2.07028594043526

Epoch: 6| Step: 3
Training loss: 0.6394759782868139
Validation loss: 2.177660292204975

Epoch: 6| Step: 4
Training loss: 0.5892473704797713
Validation loss: 2.13866074977275

Epoch: 6| Step: 5
Training loss: 0.34573220814930844
Validation loss: 2.1488688511537113

Epoch: 6| Step: 6
Training loss: 0.4034695845536146
Validation loss: 2.129449453198021

Epoch: 6| Step: 7
Training loss: 0.6593516485770876
Validation loss: 2.155642960964684

Epoch: 6| Step: 8
Training loss: 0.49094221223333756
Validation loss: 2.1857085212496483

Epoch: 6| Step: 9
Training loss: 0.4874248929732045
Validation loss: 2.1453268469110647

Epoch: 6| Step: 10
Training loss: 0.4512686027116103
Validation loss: 2.148535409376271

Epoch: 6| Step: 11
Training loss: 0.5633105954212415
Validation loss: 2.153398237208248

Epoch: 6| Step: 12
Training loss: 0.5565695198554524
Validation loss: 2.172269606933895

Epoch: 6| Step: 13
Training loss: 0.45241784129702
Validation loss: 2.1184054359111135

Epoch: 727| Step: 0
Training loss: 0.5060236601480895
Validation loss: 2.1453786866727813

Epoch: 6| Step: 1
Training loss: 0.5959989719862041
Validation loss: 2.087699104193056

Epoch: 6| Step: 2
Training loss: 0.5140553482624907
Validation loss: 2.131951243353313

Epoch: 6| Step: 3
Training loss: 0.4732443406028117
Validation loss: 2.0662821419515875

Epoch: 6| Step: 4
Training loss: 0.4792165021964914
Validation loss: 2.145758444648798

Epoch: 6| Step: 5
Training loss: 1.43526591970588
Validation loss: 2.123984591900066

Epoch: 6| Step: 6
Training loss: 0.36624171827020907
Validation loss: 2.1536100639317715

Epoch: 6| Step: 7
Training loss: 0.6385676214306417
Validation loss: 2.0587016032235903

Epoch: 6| Step: 8
Training loss: 0.603244362518237
Validation loss: 2.0761747792289946

Epoch: 6| Step: 9
Training loss: 0.40217716509056683
Validation loss: 2.224161554972604

Epoch: 6| Step: 10
Training loss: 0.48662948463366557
Validation loss: 2.080578800135843

Epoch: 6| Step: 11
Training loss: 0.4794519722228343
Validation loss: 2.111506821925299

Epoch: 6| Step: 12
Training loss: 0.5115849851538216
Validation loss: 2.106016095180325

Epoch: 6| Step: 13
Training loss: 0.4679671903657477
Validation loss: 2.1866362488108146

Epoch: 728| Step: 0
Training loss: 0.43811407589863943
Validation loss: 2.123022200209356

Epoch: 6| Step: 1
Training loss: 0.46653072798333894
Validation loss: 2.1499828495811575

Epoch: 6| Step: 2
Training loss: 0.4102228019853074
Validation loss: 2.1532604102140613

Epoch: 6| Step: 3
Training loss: 0.44222888415889433
Validation loss: 2.187932263864831

Epoch: 6| Step: 4
Training loss: 0.647356718257104
Validation loss: 2.0782582464437587

Epoch: 6| Step: 5
Training loss: 0.45301551153770814
Validation loss: 2.157685674425319

Epoch: 6| Step: 6
Training loss: 0.6874780651408041
Validation loss: 2.1445389007492257

Epoch: 6| Step: 7
Training loss: 1.4948261358914585
Validation loss: 2.107310167369418

Epoch: 6| Step: 8
Training loss: 0.42022654991147756
Validation loss: 2.207660966428219

Epoch: 6| Step: 9
Training loss: 0.5214791458382048
Validation loss: 2.1313492199233846

Epoch: 6| Step: 10
Training loss: 0.451602548585463
Validation loss: 2.154584616026702

Epoch: 6| Step: 11
Training loss: 0.6502255525257444
Validation loss: 2.119669982686158

Epoch: 6| Step: 12
Training loss: 0.4103556193859767
Validation loss: 2.1215397786141823

Epoch: 6| Step: 13
Training loss: 0.5942207277412012
Validation loss: 2.1494716794543707

Epoch: 729| Step: 0
Training loss: 0.46904559352123665
Validation loss: 2.2054938982315266

Epoch: 6| Step: 1
Training loss: 0.3860698997945703
Validation loss: 2.1367815527422764

Epoch: 6| Step: 2
Training loss: 0.3753505300332379
Validation loss: 2.1163403066588473

Epoch: 6| Step: 3
Training loss: 0.5439206020146038
Validation loss: 2.1505816290826285

Epoch: 6| Step: 4
Training loss: 0.6551610222025606
Validation loss: 2.154445658339834

Epoch: 6| Step: 5
Training loss: 0.5813772123856936
Validation loss: 2.1685704419264713

Epoch: 6| Step: 6
Training loss: 0.37421161509423656
Validation loss: 2.174079157822442

Epoch: 6| Step: 7
Training loss: 0.4733739873252253
Validation loss: 2.156407019278138

Epoch: 6| Step: 8
Training loss: 0.5011199983788237
Validation loss: 2.069247856840683

Epoch: 6| Step: 9
Training loss: 1.461318675206682
Validation loss: 2.0890680418558363

Epoch: 6| Step: 10
Training loss: 0.4293782074709923
Validation loss: 2.168533454153845

Epoch: 6| Step: 11
Training loss: 0.4942005407625279
Validation loss: 2.184794149120578

Epoch: 6| Step: 12
Training loss: 0.5819486008917755
Validation loss: 2.1545141627405036

Epoch: 6| Step: 13
Training loss: 0.4026402612308729
Validation loss: 2.2059475352778475

Epoch: 730| Step: 0
Training loss: 1.4718544798633453
Validation loss: 2.1377729196443305

Epoch: 6| Step: 1
Training loss: 0.385483667203309
Validation loss: 2.137948149557171

Epoch: 6| Step: 2
Training loss: 0.5757905377036175
Validation loss: 2.1447489832444804

Epoch: 6| Step: 3
Training loss: 0.46544390491408694
Validation loss: 2.1067219556425356

Epoch: 6| Step: 4
Training loss: 0.5236246429227229
Validation loss: 2.163452096113367

Epoch: 6| Step: 5
Training loss: 0.48221086219267983
Validation loss: 2.1326334497756076

Epoch: 6| Step: 6
Training loss: 0.5444854027426447
Validation loss: 2.121764755012883

Epoch: 6| Step: 7
Training loss: 0.4329684448241112
Validation loss: 2.0772867880095833

Epoch: 6| Step: 8
Training loss: 0.4337623715079261
Validation loss: 2.0578437281497646

Epoch: 6| Step: 9
Training loss: 0.5665365135095234
Validation loss: 2.1167261430527935

Epoch: 6| Step: 10
Training loss: 0.4632712943694408
Validation loss: 2.0879343284329637

Epoch: 6| Step: 11
Training loss: 0.427605910148582
Validation loss: 2.155955924866909

Epoch: 6| Step: 12
Training loss: 0.6508617584877205
Validation loss: 2.1408604312105055

Epoch: 6| Step: 13
Training loss: 0.5294181994361892
Validation loss: 2.148580424904819

Epoch: 731| Step: 0
Training loss: 0.5292691719716313
Validation loss: 2.2035746991443155

Epoch: 6| Step: 1
Training loss: 0.49041992262853545
Validation loss: 2.0883020077278593

Epoch: 6| Step: 2
Training loss: 0.42364035459411387
Validation loss: 2.148749452318718

Epoch: 6| Step: 3
Training loss: 0.5025831491559289
Validation loss: 2.088776433752683

Epoch: 6| Step: 4
Training loss: 0.6998138026826424
Validation loss: 2.184012365469127

Epoch: 6| Step: 5
Training loss: 0.6952020364517525
Validation loss: 2.1503164341116765

Epoch: 6| Step: 6
Training loss: 0.4843458659116426
Validation loss: 2.136084116170468

Epoch: 6| Step: 7
Training loss: 0.3545369521952233
Validation loss: 2.163697974908454

Epoch: 6| Step: 8
Training loss: 0.47749723161524005
Validation loss: 2.1449542303222153

Epoch: 6| Step: 9
Training loss: 0.5513760756865018
Validation loss: 2.1520687484648047

Epoch: 6| Step: 10
Training loss: 0.49481646492369213
Validation loss: 2.114690763261322

Epoch: 6| Step: 11
Training loss: 1.429768210879239
Validation loss: 2.153821775195424

Epoch: 6| Step: 12
Training loss: 0.588358923861602
Validation loss: 2.1821201871972744

Epoch: 6| Step: 13
Training loss: 0.30465742109454935
Validation loss: 2.0773285258455765

Epoch: 732| Step: 0
Training loss: 0.5405588252850909
Validation loss: 2.1857285629739622

Epoch: 6| Step: 1
Training loss: 0.5975451896050605
Validation loss: 2.1537721440163144

Epoch: 6| Step: 2
Training loss: 0.5175284883701758
Validation loss: 2.1667719609143843

Epoch: 6| Step: 3
Training loss: 0.637721062647098
Validation loss: 2.164891355349496

Epoch: 6| Step: 4
Training loss: 0.4680168139909646
Validation loss: 2.272082555774009

Epoch: 6| Step: 5
Training loss: 0.5171284287477111
Validation loss: 2.1001924317710183

Epoch: 6| Step: 6
Training loss: 0.4923797867593854
Validation loss: 2.1834734116123125

Epoch: 6| Step: 7
Training loss: 0.6532207236344795
Validation loss: 2.06858209574804

Epoch: 6| Step: 8
Training loss: 0.3938401278025253
Validation loss: 2.1006964210937804

Epoch: 6| Step: 9
Training loss: 0.5042225044897997
Validation loss: 2.0987541872795177

Epoch: 6| Step: 10
Training loss: 0.45481583399859216
Validation loss: 2.129409675423805

Epoch: 6| Step: 11
Training loss: 0.5138682291099347
Validation loss: 2.1165569020030137

Epoch: 6| Step: 12
Training loss: 1.3999214184369284
Validation loss: 2.133421506120286

Epoch: 6| Step: 13
Training loss: 0.3176933529975261
Validation loss: 2.1100719277437814

Epoch: 733| Step: 0
Training loss: 0.611710255297146
Validation loss: 2.1812284340958703

Epoch: 6| Step: 1
Training loss: 0.4426841467439936
Validation loss: 2.1450732619637285

Epoch: 6| Step: 2
Training loss: 0.5821602697551564
Validation loss: 2.2193297466876913

Epoch: 6| Step: 3
Training loss: 0.4180410447388686
Validation loss: 2.134657735193906

Epoch: 6| Step: 4
Training loss: 0.5154052612946523
Validation loss: 2.0932590409177037

Epoch: 6| Step: 5
Training loss: 0.45866581027349285
Validation loss: 2.1377917040016956

Epoch: 6| Step: 6
Training loss: 0.360462492122492
Validation loss: 2.19991576095479

Epoch: 6| Step: 7
Training loss: 0.5011853234857122
Validation loss: 2.198147889349199

Epoch: 6| Step: 8
Training loss: 0.4720635441652758
Validation loss: 2.124219368589518

Epoch: 6| Step: 9
Training loss: 0.38768416612105816
Validation loss: 2.1607178774959266

Epoch: 6| Step: 10
Training loss: 0.5268789998510178
Validation loss: 2.1815559499374495

Epoch: 6| Step: 11
Training loss: 0.5481841629791376
Validation loss: 2.080257719410442

Epoch: 6| Step: 12
Training loss: 0.5484008755097471
Validation loss: 2.0357618009089347

Epoch: 6| Step: 13
Training loss: 1.749104679506234
Validation loss: 2.1050028212275103

Epoch: 734| Step: 0
Training loss: 1.4800589203060515
Validation loss: 2.1275992834308495

Epoch: 6| Step: 1
Training loss: 0.48991318169559206
Validation loss: 2.1667681931340876

Epoch: 6| Step: 2
Training loss: 0.4089856472924672
Validation loss: 2.1229280230480567

Epoch: 6| Step: 3
Training loss: 0.42891173993264187
Validation loss: 2.190165451854725

Epoch: 6| Step: 4
Training loss: 0.3879651876740023
Validation loss: 2.177385641184159

Epoch: 6| Step: 5
Training loss: 0.3866773255635708
Validation loss: 2.1263553584653456

Epoch: 6| Step: 6
Training loss: 0.5252841997664617
Validation loss: 2.166537369340121

Epoch: 6| Step: 7
Training loss: 0.5029238209798924
Validation loss: 2.1587254381586707

Epoch: 6| Step: 8
Training loss: 0.381575786037469
Validation loss: 2.0932773551891857

Epoch: 6| Step: 9
Training loss: 0.4468406924169744
Validation loss: 2.146807006952415

Epoch: 6| Step: 10
Training loss: 0.40763121335401176
Validation loss: 2.0351356547977146

Epoch: 6| Step: 11
Training loss: 0.46662012049742063
Validation loss: 2.1693449820322663

Epoch: 6| Step: 12
Training loss: 0.3661672540677903
Validation loss: 2.2133198771152336

Epoch: 6| Step: 13
Training loss: 0.5251503150193708
Validation loss: 2.1058654661016676

Epoch: 735| Step: 0
Training loss: 0.30987961777435147
Validation loss: 2.147614471510603

Epoch: 6| Step: 1
Training loss: 0.5865297503263439
Validation loss: 2.2133119834337704

Epoch: 6| Step: 2
Training loss: 0.522847597593793
Validation loss: 2.1922465053299405

Epoch: 6| Step: 3
Training loss: 0.5600130949022036
Validation loss: 2.1418092860526694

Epoch: 6| Step: 4
Training loss: 0.5389389228151712
Validation loss: 2.12143764692982

Epoch: 6| Step: 5
Training loss: 0.3865551072495413
Validation loss: 2.1256348230514917

Epoch: 6| Step: 6
Training loss: 0.5026750531057739
Validation loss: 2.104285029011746

Epoch: 6| Step: 7
Training loss: 0.3428306097186872
Validation loss: 2.131093011769291

Epoch: 6| Step: 8
Training loss: 0.3933235038455853
Validation loss: 2.1056232578722556

Epoch: 6| Step: 9
Training loss: 1.3093706244711956
Validation loss: 2.1244556989412593

Epoch: 6| Step: 10
Training loss: 0.36469622862241063
Validation loss: 2.1722752439936635

Epoch: 6| Step: 11
Training loss: 0.5948945107431682
Validation loss: 2.1943013906245468

Epoch: 6| Step: 12
Training loss: 0.5963861270874746
Validation loss: 2.0619169140019227

Epoch: 6| Step: 13
Training loss: 0.5468570433802115
Validation loss: 2.0881230965932116

Epoch: 736| Step: 0
Training loss: 0.4494667529634855
Validation loss: 2.1365292597782592

Epoch: 6| Step: 1
Training loss: 0.5538872063164942
Validation loss: 2.133444411980808

Epoch: 6| Step: 2
Training loss: 0.4928498126160129
Validation loss: 2.1310041748048096

Epoch: 6| Step: 3
Training loss: 0.4636257466844772
Validation loss: 2.188189517106083

Epoch: 6| Step: 4
Training loss: 0.41637104594157753
Validation loss: 2.1337243093756344

Epoch: 6| Step: 5
Training loss: 1.4583828054846828
Validation loss: 2.197287766138819

Epoch: 6| Step: 6
Training loss: 0.43071779361395324
Validation loss: 2.1253665955303838

Epoch: 6| Step: 7
Training loss: 0.4762154394160245
Validation loss: 2.147362934960358

Epoch: 6| Step: 8
Training loss: 0.3433522828013031
Validation loss: 2.1190802924573493

Epoch: 6| Step: 9
Training loss: 0.5815255188906309
Validation loss: 2.1391604744340014

Epoch: 6| Step: 10
Training loss: 0.42375643075435104
Validation loss: 2.1446869493266636

Epoch: 6| Step: 11
Training loss: 0.5192207613276677
Validation loss: 2.118176198269589

Epoch: 6| Step: 12
Training loss: 0.4131178967533232
Validation loss: 2.158361119883201

Epoch: 6| Step: 13
Training loss: 0.7323163579591904
Validation loss: 2.167345821066558

Epoch: 737| Step: 0
Training loss: 0.5503717076750875
Validation loss: 2.171453781400444

Epoch: 6| Step: 1
Training loss: 0.5301069135164334
Validation loss: 2.2121072942416253

Epoch: 6| Step: 2
Training loss: 0.4165007221059962
Validation loss: 2.1063896258286756

Epoch: 6| Step: 3
Training loss: 0.6195841262784945
Validation loss: 2.1584303629034136

Epoch: 6| Step: 4
Training loss: 0.4230341880354211
Validation loss: 2.0897226232004873

Epoch: 6| Step: 5
Training loss: 0.4501016647680142
Validation loss: 2.158491268438049

Epoch: 6| Step: 6
Training loss: 0.4633078646292246
Validation loss: 2.097034145700519

Epoch: 6| Step: 7
Training loss: 0.5281983691383528
Validation loss: 2.080883412569089

Epoch: 6| Step: 8
Training loss: 0.4196046917671221
Validation loss: 2.1119320233749854

Epoch: 6| Step: 9
Training loss: 1.419665957637364
Validation loss: 2.1562773049034463

Epoch: 6| Step: 10
Training loss: 0.5030427379766843
Validation loss: 2.1566360096016415

Epoch: 6| Step: 11
Training loss: 0.3744069814634266
Validation loss: 2.183576463270666

Epoch: 6| Step: 12
Training loss: 0.46388177146070764
Validation loss: 2.141364076370756

Epoch: 6| Step: 13
Training loss: 0.3958508922630932
Validation loss: 2.1389994097529366

Epoch: 738| Step: 0
Training loss: 0.3888916467765625
Validation loss: 2.176369601626063

Epoch: 6| Step: 1
Training loss: 0.5179385963281956
Validation loss: 2.0596007077131975

Epoch: 6| Step: 2
Training loss: 0.6762125480138624
Validation loss: 2.154730665924808

Epoch: 6| Step: 3
Training loss: 0.2256162631306089
Validation loss: 2.143624869829152

Epoch: 6| Step: 4
Training loss: 0.47884267413018416
Validation loss: 2.185284880901325

Epoch: 6| Step: 5
Training loss: 0.5071514815857864
Validation loss: 2.1336798046555554

Epoch: 6| Step: 6
Training loss: 0.44164615626964926
Validation loss: 2.161622794445481

Epoch: 6| Step: 7
Training loss: 0.5813271276513889
Validation loss: 2.1717124601344233

Epoch: 6| Step: 8
Training loss: 0.42740621999339
Validation loss: 2.146161691560096

Epoch: 6| Step: 9
Training loss: 0.560449119843047
Validation loss: 2.110941188712453

Epoch: 6| Step: 10
Training loss: 0.2463753617882552
Validation loss: 2.0800806256867097

Epoch: 6| Step: 11
Training loss: 0.304071757890171
Validation loss: 2.1507651509276635

Epoch: 6| Step: 12
Training loss: 1.3051341771246232
Validation loss: 2.170015577415656

Epoch: 6| Step: 13
Training loss: 0.6713099432309584
Validation loss: 2.1673756197595497

Epoch: 739| Step: 0
Training loss: 0.46434467034364546
Validation loss: 2.137488272778145

Epoch: 6| Step: 1
Training loss: 0.5922337798300358
Validation loss: 2.094230060522382

Epoch: 6| Step: 2
Training loss: 0.37902653151626003
Validation loss: 2.0893602681577494

Epoch: 6| Step: 3
Training loss: 0.5702493449737921
Validation loss: 2.1639575499668315

Epoch: 6| Step: 4
Training loss: 0.3243217534443142
Validation loss: 2.14427242461369

Epoch: 6| Step: 5
Training loss: 0.4231230500766558
Validation loss: 2.1356722538958164

Epoch: 6| Step: 6
Training loss: 0.5025660709576358
Validation loss: 2.112836979139285

Epoch: 6| Step: 7
Training loss: 1.3623796777355286
Validation loss: 2.123005743749322

Epoch: 6| Step: 8
Training loss: 0.5859723907255068
Validation loss: 2.1107208036286065

Epoch: 6| Step: 9
Training loss: 0.44716793142778016
Validation loss: 2.139317308817913

Epoch: 6| Step: 10
Training loss: 0.43123303670277097
Validation loss: 2.173691198009416

Epoch: 6| Step: 11
Training loss: 0.4836391581723007
Validation loss: 2.0167786645752463

Epoch: 6| Step: 12
Training loss: 0.5396376595955077
Validation loss: 2.1066711955180337

Epoch: 6| Step: 13
Training loss: 0.39407707737967607
Validation loss: 2.2299382549935456

Epoch: 740| Step: 0
Training loss: 1.411149074368345
Validation loss: 2.0904836336508996

Epoch: 6| Step: 1
Training loss: 0.4996863364801942
Validation loss: 2.174112919383823

Epoch: 6| Step: 2
Training loss: 0.5538985323132892
Validation loss: 2.1701864006720784

Epoch: 6| Step: 3
Training loss: 0.5332551029567432
Validation loss: 2.188803070504038

Epoch: 6| Step: 4
Training loss: 0.48320391816033265
Validation loss: 2.106648437403736

Epoch: 6| Step: 5
Training loss: 0.5403932648059738
Validation loss: 2.1112543482331234

Epoch: 6| Step: 6
Training loss: 0.5934110477090239
Validation loss: 2.1600369285459813

Epoch: 6| Step: 7
Training loss: 0.333167007295518
Validation loss: 2.104908188613874

Epoch: 6| Step: 8
Training loss: 0.5941395736374039
Validation loss: 2.138805256945907

Epoch: 6| Step: 9
Training loss: 0.47932732694432395
Validation loss: 2.1500887941405127

Epoch: 6| Step: 10
Training loss: 0.6388852290956283
Validation loss: 2.173196799529704

Epoch: 6| Step: 11
Training loss: 0.6043772549670973
Validation loss: 2.05061258226962

Epoch: 6| Step: 12
Training loss: 0.6371924387696927
Validation loss: 2.1560372331892594

Epoch: 6| Step: 13
Training loss: 0.44076712933585566
Validation loss: 2.0753958471161833

Epoch: 741| Step: 0
Training loss: 0.3775369343152478
Validation loss: 2.1378992060157036

Epoch: 6| Step: 1
Training loss: 0.36796633320721395
Validation loss: 2.1252316566403087

Epoch: 6| Step: 2
Training loss: 1.4913447531744781
Validation loss: 2.157958222128718

Epoch: 6| Step: 3
Training loss: 0.45324107031802463
Validation loss: 2.1980183163851916

Epoch: 6| Step: 4
Training loss: 0.45402700160725745
Validation loss: 2.082002502241707

Epoch: 6| Step: 5
Training loss: 0.5016824905565512
Validation loss: 2.102101810116017

Epoch: 6| Step: 6
Training loss: 0.3766084587574433
Validation loss: 2.168466969743272

Epoch: 6| Step: 7
Training loss: 0.42752707696794623
Validation loss: 2.116234723787129

Epoch: 6| Step: 8
Training loss: 0.46228070859684595
Validation loss: 2.099014903048501

Epoch: 6| Step: 9
Training loss: 0.41503776998879627
Validation loss: 2.1800638109904176

Epoch: 6| Step: 10
Training loss: 0.41617821037120717
Validation loss: 2.096403910564481

Epoch: 6| Step: 11
Training loss: 0.48629988929253865
Validation loss: 2.0982071525162485

Epoch: 6| Step: 12
Training loss: 0.5783833364706634
Validation loss: 2.0717737175130977

Epoch: 6| Step: 13
Training loss: 0.46650023990984735
Validation loss: 2.0389077299110214

Epoch: 742| Step: 0
Training loss: 0.3424768278539182
Validation loss: 2.2294680629608643

Epoch: 6| Step: 1
Training loss: 0.4387978648842303
Validation loss: 2.1814830863169306

Epoch: 6| Step: 2
Training loss: 0.32902557673070776
Validation loss: 2.2263500343249807

Epoch: 6| Step: 3
Training loss: 0.4215452530304167
Validation loss: 2.152123231737059

Epoch: 6| Step: 4
Training loss: 0.3793007674641165
Validation loss: 2.0836120885560607

Epoch: 6| Step: 5
Training loss: 0.6529788734470997
Validation loss: 2.1218707045693272

Epoch: 6| Step: 6
Training loss: 0.3613687647054304
Validation loss: 2.1096994810542955

Epoch: 6| Step: 7
Training loss: 1.3890458473949523
Validation loss: 2.1652519472980267

Epoch: 6| Step: 8
Training loss: 0.4966942464395032
Validation loss: 2.1364641853236734

Epoch: 6| Step: 9
Training loss: 0.3492784265651684
Validation loss: 2.074543920907017

Epoch: 6| Step: 10
Training loss: 0.47499025234460096
Validation loss: 2.148713002071212

Epoch: 6| Step: 11
Training loss: 0.4004395059660658
Validation loss: 2.1192524832391717

Epoch: 6| Step: 12
Training loss: 0.45796351432085103
Validation loss: 2.155481169035593

Epoch: 6| Step: 13
Training loss: 0.3361231379693244
Validation loss: 2.1703538009274133

Epoch: 743| Step: 0
Training loss: 1.3919074756274938
Validation loss: 2.105451856805614

Epoch: 6| Step: 1
Training loss: 0.5293872376055454
Validation loss: 2.1543036253364507

Epoch: 6| Step: 2
Training loss: 0.5545403997376362
Validation loss: 2.2364460366433057

Epoch: 6| Step: 3
Training loss: 0.4573886158853799
Validation loss: 2.1523127164550666

Epoch: 6| Step: 4
Training loss: 0.6047487469392484
Validation loss: 2.1318609540138365

Epoch: 6| Step: 5
Training loss: 0.5567856181518743
Validation loss: 2.0758050488344866

Epoch: 6| Step: 6
Training loss: 0.3386554551241527
Validation loss: 2.110073902043344

Epoch: 6| Step: 7
Training loss: 0.5336134732400584
Validation loss: 2.1193307463817597

Epoch: 6| Step: 8
Training loss: 0.5123741379149184
Validation loss: 2.0706182847253465

Epoch: 6| Step: 9
Training loss: 0.3550055703545475
Validation loss: 2.192636931576069

Epoch: 6| Step: 10
Training loss: 0.36683954837692656
Validation loss: 2.176476523295742

Epoch: 6| Step: 11
Training loss: 0.5697456050668144
Validation loss: 2.1096537306743475

Epoch: 6| Step: 12
Training loss: 0.5536021507545268
Validation loss: 2.0509352690739715

Epoch: 6| Step: 13
Training loss: 0.3954304183776848
Validation loss: 2.1373574054436046

Epoch: 744| Step: 0
Training loss: 0.5162419471851581
Validation loss: 2.142208601335459

Epoch: 6| Step: 1
Training loss: 0.4384122601705601
Validation loss: 2.157843533145357

Epoch: 6| Step: 2
Training loss: 0.6755327638873042
Validation loss: 2.0909778705942936

Epoch: 6| Step: 3
Training loss: 0.33534633385787305
Validation loss: 2.141278871163307

Epoch: 6| Step: 4
Training loss: 0.5810545849198964
Validation loss: 2.050413584763917

Epoch: 6| Step: 5
Training loss: 0.6073434171879364
Validation loss: 2.1690088108505794

Epoch: 6| Step: 6
Training loss: 0.44594761246868525
Validation loss: 2.091305038155189

Epoch: 6| Step: 7
Training loss: 0.3293227406182101
Validation loss: 2.1344110783870263

Epoch: 6| Step: 8
Training loss: 0.4864592164853212
Validation loss: 2.112817584031083

Epoch: 6| Step: 9
Training loss: 0.46734767005370637
Validation loss: 2.1434607265514267

Epoch: 6| Step: 10
Training loss: 0.4808839229264581
Validation loss: 2.037437912320689

Epoch: 6| Step: 11
Training loss: 0.4996552620007818
Validation loss: 2.1778088531567903

Epoch: 6| Step: 12
Training loss: 0.5965958456768218
Validation loss: 2.1079507507956166

Epoch: 6| Step: 13
Training loss: 1.7619915600854903
Validation loss: 2.12112037135716

Epoch: 745| Step: 0
Training loss: 1.3560416030747027
Validation loss: 2.1255893131406327

Epoch: 6| Step: 1
Training loss: 0.5155112112086018
Validation loss: 2.132864286339506

Epoch: 6| Step: 2
Training loss: 0.4489659136894117
Validation loss: 2.147642473505733

Epoch: 6| Step: 3
Training loss: 0.48188823266173175
Validation loss: 2.146114160046678

Epoch: 6| Step: 4
Training loss: 0.49357104740419905
Validation loss: 2.1610981298732455

Epoch: 6| Step: 5
Training loss: 0.4991967932181261
Validation loss: 2.150078366490452

Epoch: 6| Step: 6
Training loss: 0.5224712620365672
Validation loss: 2.198450549024025

Epoch: 6| Step: 7
Training loss: 0.43966722147472526
Validation loss: 2.0856335212488477

Epoch: 6| Step: 8
Training loss: 0.5201284088631797
Validation loss: 2.146781956818336

Epoch: 6| Step: 9
Training loss: 0.4681566297492538
Validation loss: 2.118028281650573

Epoch: 6| Step: 10
Training loss: 0.4120936820129306
Validation loss: 2.210584901616281

Epoch: 6| Step: 11
Training loss: 0.5112202086780845
Validation loss: 2.2016877741949696

Epoch: 6| Step: 12
Training loss: 0.41430191100280833
Validation loss: 2.1728310678051743

Epoch: 6| Step: 13
Training loss: 0.5565768288979884
Validation loss: 2.152436873557558

Epoch: 746| Step: 0
Training loss: 0.37934067980960556
Validation loss: 2.0950873812669433

Epoch: 6| Step: 1
Training loss: 0.6267414389254976
Validation loss: 2.1790455942439664

Epoch: 6| Step: 2
Training loss: 0.4800751166874095
Validation loss: 2.0801600951803807

Epoch: 6| Step: 3
Training loss: 0.6236642152816914
Validation loss: 2.132587726174796

Epoch: 6| Step: 4
Training loss: 1.4029591094846803
Validation loss: 2.127408500716529

Epoch: 6| Step: 5
Training loss: 0.5289626245022857
Validation loss: 2.188615323591667

Epoch: 6| Step: 6
Training loss: 0.5882655624182511
Validation loss: 2.1008410673454736

Epoch: 6| Step: 7
Training loss: 0.4410363901147315
Validation loss: 2.147989038700482

Epoch: 6| Step: 8
Training loss: 0.7955840630798839
Validation loss: 2.096441970990928

Epoch: 6| Step: 9
Training loss: 0.431025675465776
Validation loss: 2.168770114169092

Epoch: 6| Step: 10
Training loss: 0.45313558894971917
Validation loss: 2.124239609990438

Epoch: 6| Step: 11
Training loss: 0.4270145857149016
Validation loss: 2.1352099995184184

Epoch: 6| Step: 12
Training loss: 0.5524260938416147
Validation loss: 2.1288311905473956

Epoch: 6| Step: 13
Training loss: 0.40971490638832303
Validation loss: 2.1358716372495046

Epoch: 747| Step: 0
Training loss: 0.559967379471414
Validation loss: 2.1437148723763575

Epoch: 6| Step: 1
Training loss: 0.594713132609552
Validation loss: 2.110619590804065

Epoch: 6| Step: 2
Training loss: 0.516843915601981
Validation loss: 2.144225907236134

Epoch: 6| Step: 3
Training loss: 0.5052468262260829
Validation loss: 2.097066793740135

Epoch: 6| Step: 4
Training loss: 0.43895236836698404
Validation loss: 2.093083167867773

Epoch: 6| Step: 5
Training loss: 0.40716094808014835
Validation loss: 2.0866409196637608

Epoch: 6| Step: 6
Training loss: 0.49780580258698426
Validation loss: 2.166672697918672

Epoch: 6| Step: 7
Training loss: 0.4972718585298626
Validation loss: 2.106791453294383

Epoch: 6| Step: 8
Training loss: 0.30850039651495925
Validation loss: 2.1303953410668974

Epoch: 6| Step: 9
Training loss: 0.5901615726553104
Validation loss: 2.1132320936425373

Epoch: 6| Step: 10
Training loss: 1.3790489749690398
Validation loss: 2.1320662928671954

Epoch: 6| Step: 11
Training loss: 0.544610867912097
Validation loss: 2.117967350337615

Epoch: 6| Step: 12
Training loss: 0.7420587528390863
Validation loss: 2.1087198787421126

Epoch: 6| Step: 13
Training loss: 0.46623133473709194
Validation loss: 2.1625216886348086

Epoch: 748| Step: 0
Training loss: 0.4054293780606371
Validation loss: 2.0957860742637244

Epoch: 6| Step: 1
Training loss: 0.5321901361441604
Validation loss: 2.1086486051823896

Epoch: 6| Step: 2
Training loss: 0.3913101672261578
Validation loss: 2.1858846422175717

Epoch: 6| Step: 3
Training loss: 0.3546344692228587
Validation loss: 2.14471365914243

Epoch: 6| Step: 4
Training loss: 0.5031141813074624
Validation loss: 2.1922470736643795

Epoch: 6| Step: 5
Training loss: 0.45017909353834135
Validation loss: 2.1752535018930517

Epoch: 6| Step: 6
Training loss: 0.5427585990994176
Validation loss: 2.0584733193854987

Epoch: 6| Step: 7
Training loss: 0.6558879580241889
Validation loss: 2.125910231657424

Epoch: 6| Step: 8
Training loss: 0.5152666696371934
Validation loss: 2.2319618605026004

Epoch: 6| Step: 9
Training loss: 0.5127418714908485
Validation loss: 2.090584994818284

Epoch: 6| Step: 10
Training loss: 0.5614949094740305
Validation loss: 2.239426073380046

Epoch: 6| Step: 11
Training loss: 0.339811893592393
Validation loss: 2.1332305422784885

Epoch: 6| Step: 12
Training loss: 0.6954478014343031
Validation loss: 2.131829170736903

Epoch: 6| Step: 13
Training loss: 1.9416161774823084
Validation loss: 2.1382133972024073

Epoch: 749| Step: 0
Training loss: 0.5668333876539767
Validation loss: 2.170996591234101

Epoch: 6| Step: 1
Training loss: 0.4280677785014663
Validation loss: 2.1915002509920716

Epoch: 6| Step: 2
Training loss: 0.4669762909025126
Validation loss: 2.1800719520599094

Epoch: 6| Step: 3
Training loss: 0.5437813311352573
Validation loss: 2.1709216127799005

Epoch: 6| Step: 4
Training loss: 0.48708477677043566
Validation loss: 2.042962909243799

Epoch: 6| Step: 5
Training loss: 0.5968525787456314
Validation loss: 2.2172805412449264

Epoch: 6| Step: 6
Training loss: 1.4080564128834407
Validation loss: 2.1076459804165872

Epoch: 6| Step: 7
Training loss: 0.3333199232602772
Validation loss: 2.123978823734397

Epoch: 6| Step: 8
Training loss: 0.4283190698079435
Validation loss: 2.1854265385836693

Epoch: 6| Step: 9
Training loss: 0.4548361302651254
Validation loss: 2.161394836544763

Epoch: 6| Step: 10
Training loss: 0.5395205113822351
Validation loss: 2.0987010535430204

Epoch: 6| Step: 11
Training loss: 0.3958213787616014
Validation loss: 2.139968667259536

Epoch: 6| Step: 12
Training loss: 0.5470937019095801
Validation loss: 2.140941291414031

Epoch: 6| Step: 13
Training loss: 0.4443962810748314
Validation loss: 2.1329158021867167

Epoch: 750| Step: 0
Training loss: 0.3848313018978708
Validation loss: 2.133379889933242

Epoch: 6| Step: 1
Training loss: 0.5089473661140774
Validation loss: 2.1173337947838964

Epoch: 6| Step: 2
Training loss: 1.3816108870817851
Validation loss: 2.185678313608764

Epoch: 6| Step: 3
Training loss: 0.3996618570150243
Validation loss: 2.080852223117375

Epoch: 6| Step: 4
Training loss: 0.5198303738275698
Validation loss: 2.1280602515685865

Epoch: 6| Step: 5
Training loss: 0.4679544373426709
Validation loss: 2.137857685986653

Epoch: 6| Step: 6
Training loss: 0.2578456597244172
Validation loss: 2.20752281720769

Epoch: 6| Step: 7
Training loss: 0.5620091734032282
Validation loss: 2.0842096339793486

Epoch: 6| Step: 8
Training loss: 0.4482063661444496
Validation loss: 2.1500213697343975

Epoch: 6| Step: 9
Training loss: 0.5753353965135861
Validation loss: 2.027549877172065

Epoch: 6| Step: 10
Training loss: 0.40597407433929145
Validation loss: 2.135237470221737

Epoch: 6| Step: 11
Training loss: 0.5061403473674981
Validation loss: 2.1304779612200466

Epoch: 6| Step: 12
Training loss: 0.5551158970028699
Validation loss: 2.1573182203914

Epoch: 6| Step: 13
Training loss: 0.3774509601444873
Validation loss: 2.1531396177593316

Epoch: 751| Step: 0
Training loss: 0.4931453285813661
Validation loss: 2.1577223752779373

Epoch: 6| Step: 1
Training loss: 0.47141300979233475
Validation loss: 2.1873027870828787

Epoch: 6| Step: 2
Training loss: 0.4968454568105281
Validation loss: 2.0936307357347625

Epoch: 6| Step: 3
Training loss: 0.41389847151581666
Validation loss: 2.1182999956072646

Epoch: 6| Step: 4
Training loss: 0.38925286580343404
Validation loss: 2.126358878358016

Epoch: 6| Step: 5
Training loss: 0.4714110341902475
Validation loss: 2.119696690862409

Epoch: 6| Step: 6
Training loss: 0.40633187936061643
Validation loss: 2.193346080809687

Epoch: 6| Step: 7
Training loss: 0.49634035244024866
Validation loss: 2.193174979001038

Epoch: 6| Step: 8
Training loss: 0.3521255223355331
Validation loss: 2.107991922232225

Epoch: 6| Step: 9
Training loss: 0.45054649177060035
Validation loss: 2.116761538170585

Epoch: 6| Step: 10
Training loss: 0.507339668222261
Validation loss: 2.1436264520534287

Epoch: 6| Step: 11
Training loss: 1.3623709276290552
Validation loss: 2.1271088147863537

Epoch: 6| Step: 12
Training loss: 0.6556566371502949
Validation loss: 2.068248498342309

Epoch: 6| Step: 13
Training loss: 0.6034330539944561
Validation loss: 2.1163719667142598

Epoch: 752| Step: 0
Training loss: 0.30948218887395923
Validation loss: 2.113368122593701

Epoch: 6| Step: 1
Training loss: 0.5007579839720322
Validation loss: 2.070632924323987

Epoch: 6| Step: 2
Training loss: 0.5366819310781739
Validation loss: 2.11398306384367

Epoch: 6| Step: 3
Training loss: 0.4675211694075713
Validation loss: 2.0971337202656564

Epoch: 6| Step: 4
Training loss: 0.5446399793615853
Validation loss: 2.101145690067039

Epoch: 6| Step: 5
Training loss: 1.3516275908391435
Validation loss: 2.14492832668371

Epoch: 6| Step: 6
Training loss: 0.541080897831553
Validation loss: 2.1231267660294613

Epoch: 6| Step: 7
Training loss: 0.3586144277224901
Validation loss: 2.1525478757195375

Epoch: 6| Step: 8
Training loss: 0.5543207917487377
Validation loss: 2.1106676547322873

Epoch: 6| Step: 9
Training loss: 0.42028009084098783
Validation loss: 2.056575666024092

Epoch: 6| Step: 10
Training loss: 0.45100115564033316
Validation loss: 2.1148471672735734

Epoch: 6| Step: 11
Training loss: 0.5043868205541894
Validation loss: 2.090701190728699

Epoch: 6| Step: 12
Training loss: 0.480695996392046
Validation loss: 2.2169538596926066

Epoch: 6| Step: 13
Training loss: 0.6178349346434789
Validation loss: 2.1526082855262456

Epoch: 753| Step: 0
Training loss: 0.4311649929796157
Validation loss: 2.174497330159712

Epoch: 6| Step: 1
Training loss: 0.5901851550217942
Validation loss: 2.1056013289864723

Epoch: 6| Step: 2
Training loss: 0.609723700500102
Validation loss: 2.097516637257

Epoch: 6| Step: 3
Training loss: 0.4184017612274329
Validation loss: 2.1221812890892537

Epoch: 6| Step: 4
Training loss: 0.46194936927882824
Validation loss: 2.0825736163948685

Epoch: 6| Step: 5
Training loss: 1.4129801870767156
Validation loss: 2.10461990809802

Epoch: 6| Step: 6
Training loss: 0.6302682096762775
Validation loss: 2.185502901233942

Epoch: 6| Step: 7
Training loss: 0.4990300067984306
Validation loss: 2.1353570933302097

Epoch: 6| Step: 8
Training loss: 0.5680965064764757
Validation loss: 2.047802173192759

Epoch: 6| Step: 9
Training loss: 0.41155009715190694
Validation loss: 2.1061008104397563

Epoch: 6| Step: 10
Training loss: 0.39098879086605665
Validation loss: 2.123762507532893

Epoch: 6| Step: 11
Training loss: 0.5564856597958393
Validation loss: 2.048936195737113

Epoch: 6| Step: 12
Training loss: 0.36557386806980363
Validation loss: 2.090193134950235

Epoch: 6| Step: 13
Training loss: 0.2977781611816902
Validation loss: 2.0830912032986926

Epoch: 754| Step: 0
Training loss: 0.38543399136070405
Validation loss: 2.180548366289802

Epoch: 6| Step: 1
Training loss: 0.46302613154134487
Validation loss: 2.1497217689663937

Epoch: 6| Step: 2
Training loss: 0.4635231107219521
Validation loss: 2.162650578017497

Epoch: 6| Step: 3
Training loss: 0.4263808551857125
Validation loss: 2.1595734861565115

Epoch: 6| Step: 4
Training loss: 0.40841702054552026
Validation loss: 2.1511481553536314

Epoch: 6| Step: 5
Training loss: 0.40575731185558145
Validation loss: 2.08385143441678

Epoch: 6| Step: 6
Training loss: 0.42659428167194735
Validation loss: 2.1023639151640454

Epoch: 6| Step: 7
Training loss: 0.36080965527526976
Validation loss: 2.124330698735039

Epoch: 6| Step: 8
Training loss: 1.345524791311938
Validation loss: 2.1296222126730635

Epoch: 6| Step: 9
Training loss: 0.49822572974789414
Validation loss: 2.124339358708608

Epoch: 6| Step: 10
Training loss: 0.521027954614624
Validation loss: 2.100153228997019

Epoch: 6| Step: 11
Training loss: 0.5167796183247391
Validation loss: 2.0906431012447797

Epoch: 6| Step: 12
Training loss: 0.5435573762860757
Validation loss: 2.109288921901469

Epoch: 6| Step: 13
Training loss: 0.1705287640820141
Validation loss: 2.177283025353006

Epoch: 755| Step: 0
Training loss: 0.5476436662520664
Validation loss: 2.1726298383460008

Epoch: 6| Step: 1
Training loss: 0.4855875865167803
Validation loss: 2.0887207055981576

Epoch: 6| Step: 2
Training loss: 0.4539021371993238
Validation loss: 2.155524019425513

Epoch: 6| Step: 3
Training loss: 0.5618218466596268
Validation loss: 2.1295777939214733

Epoch: 6| Step: 4
Training loss: 1.3742084825922667
Validation loss: 2.117923092500619

Epoch: 6| Step: 5
Training loss: 0.47491134644434707
Validation loss: 2.1148644096901

Epoch: 6| Step: 6
Training loss: 0.3889375478335913
Validation loss: 2.1569175929190116

Epoch: 6| Step: 7
Training loss: 0.3233480366619666
Validation loss: 2.182371514914631

Epoch: 6| Step: 8
Training loss: 0.5358273829559376
Validation loss: 2.171022207750192

Epoch: 6| Step: 9
Training loss: 0.5861748024105902
Validation loss: 2.1510024453137793

Epoch: 6| Step: 10
Training loss: 0.5210611004302145
Validation loss: 2.2316756415854275

Epoch: 6| Step: 11
Training loss: 0.45860305529744116
Validation loss: 2.0858579876023255

Epoch: 6| Step: 12
Training loss: 0.42908313904401824
Validation loss: 2.165559481842333

Epoch: 6| Step: 13
Training loss: 0.5949717550225365
Validation loss: 2.1404307718697

Epoch: 756| Step: 0
Training loss: 0.42246685191479444
Validation loss: 2.1181434253594706

Epoch: 6| Step: 1
Training loss: 0.48894568440617536
Validation loss: 2.1273836041696597

Epoch: 6| Step: 2
Training loss: 0.4144145980027499
Validation loss: 2.1873056269719258

Epoch: 6| Step: 3
Training loss: 0.3304467935685645
Validation loss: 2.083759534576197

Epoch: 6| Step: 4
Training loss: 0.42716625230545585
Validation loss: 2.1766801136776563

Epoch: 6| Step: 5
Training loss: 0.4891297711549855
Validation loss: 2.1002034263115257

Epoch: 6| Step: 6
Training loss: 0.5691429059592301
Validation loss: 2.1585161529904027

Epoch: 6| Step: 7
Training loss: 0.4543024910655948
Validation loss: 2.1210009473137426

Epoch: 6| Step: 8
Training loss: 1.3645083525735044
Validation loss: 2.1310848279497043

Epoch: 6| Step: 9
Training loss: 0.421166991479887
Validation loss: 2.1187214775923158

Epoch: 6| Step: 10
Training loss: 0.5649124705191666
Validation loss: 2.1227403325046974

Epoch: 6| Step: 11
Training loss: 0.2932625378353686
Validation loss: 2.174269316309894

Epoch: 6| Step: 12
Training loss: 0.5322998836303647
Validation loss: 2.0801976197085192

Epoch: 6| Step: 13
Training loss: 0.3032197936778313
Validation loss: 2.163109445959197

Epoch: 757| Step: 0
Training loss: 0.701861114500477
Validation loss: 2.0875265138811576

Epoch: 6| Step: 1
Training loss: 0.46131307850330994
Validation loss: 2.1830829600641373

Epoch: 6| Step: 2
Training loss: 0.6902369509413039
Validation loss: 2.09683635050018

Epoch: 6| Step: 3
Training loss: 0.5013542610526087
Validation loss: 2.0653414005302135

Epoch: 6| Step: 4
Training loss: 0.4085376956337547
Validation loss: 2.124902733851451

Epoch: 6| Step: 5
Training loss: 0.3208080389633081
Validation loss: 2.0367572631011637

Epoch: 6| Step: 6
Training loss: 1.4215860597239325
Validation loss: 2.1593046494800983

Epoch: 6| Step: 7
Training loss: 0.3534006595720916
Validation loss: 2.122225876694618

Epoch: 6| Step: 8
Training loss: 0.4812966943356658
Validation loss: 2.2209671857330058

Epoch: 6| Step: 9
Training loss: 0.40803754450753354
Validation loss: 2.1039366797956003

Epoch: 6| Step: 10
Training loss: 0.5548160565189129
Validation loss: 2.162582357435099

Epoch: 6| Step: 11
Training loss: 0.3603083887055902
Validation loss: 2.183416737115157

Epoch: 6| Step: 12
Training loss: 0.32884795154735674
Validation loss: 2.169007439798483

Epoch: 6| Step: 13
Training loss: 0.3774083605435087
Validation loss: 2.0630491115540526

Epoch: 758| Step: 0
Training loss: 0.5513781836639833
Validation loss: 2.1706117426645317

Epoch: 6| Step: 1
Training loss: 0.543474332494636
Validation loss: 2.082956302940674

Epoch: 6| Step: 2
Training loss: 0.5803939524704229
Validation loss: 2.1383274120309284

Epoch: 6| Step: 3
Training loss: 0.39373392798910334
Validation loss: 2.134427216302403

Epoch: 6| Step: 4
Training loss: 0.45756792689860576
Validation loss: 2.201179634023276

Epoch: 6| Step: 5
Training loss: 0.48790735807044394
Validation loss: 2.0604650925506505

Epoch: 6| Step: 6
Training loss: 0.4107036570690149
Validation loss: 2.1612787861287326

Epoch: 6| Step: 7
Training loss: 0.5456458310829566
Validation loss: 2.1088343800669365

Epoch: 6| Step: 8
Training loss: 0.5538192723777873
Validation loss: 2.11980556888521

Epoch: 6| Step: 9
Training loss: 0.2893931971610183
Validation loss: 2.141735087574179

Epoch: 6| Step: 10
Training loss: 0.46481993157407575
Validation loss: 2.1199023844286273

Epoch: 6| Step: 11
Training loss: 0.6181644240825734
Validation loss: 2.16896540599368

Epoch: 6| Step: 12
Training loss: 1.4327549780361617
Validation loss: 2.1312431190751817

Epoch: 6| Step: 13
Training loss: 0.47436402497895724
Validation loss: 2.106977216107658

Epoch: 759| Step: 0
Training loss: 0.3303130628568388
Validation loss: 2.111721061030382

Epoch: 6| Step: 1
Training loss: 0.3460978070746781
Validation loss: 2.125944316220641

Epoch: 6| Step: 2
Training loss: 0.5587762387833247
Validation loss: 2.1518001107680482

Epoch: 6| Step: 3
Training loss: 0.4185818605062273
Validation loss: 2.172355509582273

Epoch: 6| Step: 4
Training loss: 0.49032406537412243
Validation loss: 2.147967217396979

Epoch: 6| Step: 5
Training loss: 0.35628315620725487
Validation loss: 2.1454661391960785

Epoch: 6| Step: 6
Training loss: 0.47031145697696647
Validation loss: 2.0821221463051947

Epoch: 6| Step: 7
Training loss: 0.39553629454736544
Validation loss: 2.1015879952038206

Epoch: 6| Step: 8
Training loss: 0.5494183390668244
Validation loss: 2.0879225031123374

Epoch: 6| Step: 9
Training loss: 0.5011245479224876
Validation loss: 2.0735255595343873

Epoch: 6| Step: 10
Training loss: 0.46214420964436254
Validation loss: 2.18203857428165

Epoch: 6| Step: 11
Training loss: 0.5876594671979339
Validation loss: 2.0786866113762947

Epoch: 6| Step: 12
Training loss: 0.4261492442582996
Validation loss: 2.132643131474454

Epoch: 6| Step: 13
Training loss: 1.751963467604644
Validation loss: 2.192019112955223

Epoch: 760| Step: 0
Training loss: 0.4112659519661366
Validation loss: 2.152515050880152

Epoch: 6| Step: 1
Training loss: 0.49928861914136025
Validation loss: 2.1010309741069397

Epoch: 6| Step: 2
Training loss: 0.5318838713608738
Validation loss: 2.161281146009509

Epoch: 6| Step: 3
Training loss: 0.5330008098495944
Validation loss: 2.226727619248131

Epoch: 6| Step: 4
Training loss: 0.5942871274282873
Validation loss: 2.1399180160465066

Epoch: 6| Step: 5
Training loss: 1.3104010556276142
Validation loss: 2.1024745662660345

Epoch: 6| Step: 6
Training loss: 0.48833393575622497
Validation loss: 2.088725514442356

Epoch: 6| Step: 7
Training loss: 0.4167896287997868
Validation loss: 2.140905004598191

Epoch: 6| Step: 8
Training loss: 0.41866650674193256
Validation loss: 2.081517791493789

Epoch: 6| Step: 9
Training loss: 0.2783522470457207
Validation loss: 2.2278715455411224

Epoch: 6| Step: 10
Training loss: 0.4073515775606683
Validation loss: 2.156857184354177

Epoch: 6| Step: 11
Training loss: 0.48389815885722137
Validation loss: 2.1738486580567713

Epoch: 6| Step: 12
Training loss: 0.4887822137153295
Validation loss: 2.112671018987117

Epoch: 6| Step: 13
Training loss: 0.641379214796166
Validation loss: 2.1130420337962104

Epoch: 761| Step: 0
Training loss: 0.40294230483432725
Validation loss: 2.1111440310136023

Epoch: 6| Step: 1
Training loss: 0.5176387535429163
Validation loss: 2.1288594853696154

Epoch: 6| Step: 2
Training loss: 0.5404301860160444
Validation loss: 2.1434409040774196

Epoch: 6| Step: 3
Training loss: 0.4411746236000481
Validation loss: 2.109196955049862

Epoch: 6| Step: 4
Training loss: 0.5281193715986283
Validation loss: 2.1331854242589503

Epoch: 6| Step: 5
Training loss: 0.5273872640105557
Validation loss: 2.1605706794139605

Epoch: 6| Step: 6
Training loss: 0.5665761758507738
Validation loss: 2.0890858578270235

Epoch: 6| Step: 7
Training loss: 0.49826652320877274
Validation loss: 2.107031477086268

Epoch: 6| Step: 8
Training loss: 0.333331535255033
Validation loss: 2.1354467366340155

Epoch: 6| Step: 9
Training loss: 0.3457228552581368
Validation loss: 2.0753576613637397

Epoch: 6| Step: 10
Training loss: 0.48946291037700446
Validation loss: 2.1798690321590173

Epoch: 6| Step: 11
Training loss: 0.2959951110642299
Validation loss: 2.110463577426323

Epoch: 6| Step: 12
Training loss: 0.40181445518512826
Validation loss: 2.0787191344309743

Epoch: 6| Step: 13
Training loss: 1.7189831662244222
Validation loss: 2.110445658280128

Epoch: 762| Step: 0
Training loss: 0.5542306496197964
Validation loss: 2.088600555155171

Epoch: 6| Step: 1
Training loss: 0.523072813158697
Validation loss: 2.094932846489688

Epoch: 6| Step: 2
Training loss: 0.5023299706261483
Validation loss: 2.110679012531337

Epoch: 6| Step: 3
Training loss: 0.571471356382469
Validation loss: 2.152905217356137

Epoch: 6| Step: 4
Training loss: 0.5534276759149683
Validation loss: 2.223432773078345

Epoch: 6| Step: 5
Training loss: 0.5384066088333895
Validation loss: 2.1017742654888756

Epoch: 6| Step: 6
Training loss: 0.4516111935031627
Validation loss: 2.0193349050538356

Epoch: 6| Step: 7
Training loss: 0.32009975998031404
Validation loss: 2.0835334093147186

Epoch: 6| Step: 8
Training loss: 0.6572519101927327
Validation loss: 2.114313988833435

Epoch: 6| Step: 9
Training loss: 0.5035267665154188
Validation loss: 2.1269179272081917

Epoch: 6| Step: 10
Training loss: 0.5655862067813628
Validation loss: 2.1293647542564735

Epoch: 6| Step: 11
Training loss: 0.5072095666152391
Validation loss: 2.1560564077584274

Epoch: 6| Step: 12
Training loss: 1.344240054882139
Validation loss: 2.1036363719504636

Epoch: 6| Step: 13
Training loss: 0.44679343606286087
Validation loss: 2.092099977832237

Epoch: 763| Step: 0
Training loss: 0.41593459508785713
Validation loss: 2.11313877584937

Epoch: 6| Step: 1
Training loss: 0.3399553115836824
Validation loss: 2.0646407358918446

Epoch: 6| Step: 2
Training loss: 0.41750288339864094
Validation loss: 2.18757449373364

Epoch: 6| Step: 3
Training loss: 0.37809927041024494
Validation loss: 2.1549048678433644

Epoch: 6| Step: 4
Training loss: 0.32152782716652306
Validation loss: 2.120208062798751

Epoch: 6| Step: 5
Training loss: 0.6216503024909069
Validation loss: 2.118369212652684

Epoch: 6| Step: 6
Training loss: 0.5857872833975045
Validation loss: 2.1685343147954037

Epoch: 6| Step: 7
Training loss: 1.4233728421346392
Validation loss: 2.162387058206797

Epoch: 6| Step: 8
Training loss: 0.5419149257818294
Validation loss: 2.1110591337817675

Epoch: 6| Step: 9
Training loss: 0.3036841230422559
Validation loss: 2.118033516581637

Epoch: 6| Step: 10
Training loss: 0.5988905882187096
Validation loss: 2.145115112605209

Epoch: 6| Step: 11
Training loss: 0.46216868183651816
Validation loss: 2.16226143256933

Epoch: 6| Step: 12
Training loss: 0.41500771796851493
Validation loss: 2.1680530464082675

Epoch: 6| Step: 13
Training loss: 0.37762296783294436
Validation loss: 2.1350195606762425

Epoch: 764| Step: 0
Training loss: 0.4975505375233306
Validation loss: 2.090782365542101

Epoch: 6| Step: 1
Training loss: 0.44112431122014534
Validation loss: 2.1352989472466763

Epoch: 6| Step: 2
Training loss: 0.36969852169887674
Validation loss: 2.0939252005948523

Epoch: 6| Step: 3
Training loss: 0.6259334745768073
Validation loss: 2.1057751028398006

Epoch: 6| Step: 4
Training loss: 0.5274665124487402
Validation loss: 2.168041724008138

Epoch: 6| Step: 5
Training loss: 0.4073075321486338
Validation loss: 2.1251280261663306

Epoch: 6| Step: 6
Training loss: 0.4235231735156332
Validation loss: 2.1690718073957784

Epoch: 6| Step: 7
Training loss: 0.4035857391743876
Validation loss: 2.1591657352390485

Epoch: 6| Step: 8
Training loss: 1.3223894475437394
Validation loss: 2.100633624459805

Epoch: 6| Step: 9
Training loss: 0.33821953217099543
Validation loss: 2.0233689670040462

Epoch: 6| Step: 10
Training loss: 0.4928157520610206
Validation loss: 2.078330306863848

Epoch: 6| Step: 11
Training loss: 0.2967593946737352
Validation loss: 2.0932744146779942

Epoch: 6| Step: 12
Training loss: 0.5527218389268967
Validation loss: 2.1253775086966815

Epoch: 6| Step: 13
Training loss: 0.4265302142825825
Validation loss: 2.140691854512151

Epoch: 765| Step: 0
Training loss: 0.4566900985192786
Validation loss: 2.0635969679149024

Epoch: 6| Step: 1
Training loss: 0.38343048816789216
Validation loss: 2.0861832803943097

Epoch: 6| Step: 2
Training loss: 0.5250660343875359
Validation loss: 2.1318656499137436

Epoch: 6| Step: 3
Training loss: 0.44749601335721007
Validation loss: 2.196311280016756

Epoch: 6| Step: 4
Training loss: 0.49036779525874513
Validation loss: 2.2086907538868896

Epoch: 6| Step: 5
Training loss: 0.48659328907185384
Validation loss: 2.087973711510568

Epoch: 6| Step: 6
Training loss: 1.391584301222442
Validation loss: 2.170608823061828

Epoch: 6| Step: 7
Training loss: 0.5431886954759113
Validation loss: 2.175850234975445

Epoch: 6| Step: 8
Training loss: 0.3578873401983241
Validation loss: 2.210682711836057

Epoch: 6| Step: 9
Training loss: 0.44744904267957536
Validation loss: 2.1564154505731956

Epoch: 6| Step: 10
Training loss: 0.39825910426603317
Validation loss: 2.1724373127947514

Epoch: 6| Step: 11
Training loss: 0.44264418941378125
Validation loss: 2.08161720432026

Epoch: 6| Step: 12
Training loss: 0.5616073413028059
Validation loss: 2.060083809270871

Epoch: 6| Step: 13
Training loss: 0.40752081908537413
Validation loss: 2.1226743347169807

Epoch: 766| Step: 0
Training loss: 0.461732276163278
Validation loss: 2.0768904089275746

Epoch: 6| Step: 1
Training loss: 0.3035052912657775
Validation loss: 2.1297415530738353

Epoch: 6| Step: 2
Training loss: 0.45937390943644296
Validation loss: 2.1306096662260416

Epoch: 6| Step: 3
Training loss: 0.46926289155472817
Validation loss: 2.0407300244201347

Epoch: 6| Step: 4
Training loss: 0.40327974350953455
Validation loss: 2.0955855738725804

Epoch: 6| Step: 5
Training loss: 0.3802837619251828
Validation loss: 2.090844593323901

Epoch: 6| Step: 6
Training loss: 0.458828773907281
Validation loss: 2.11682338525229

Epoch: 6| Step: 7
Training loss: 0.4803246382778519
Validation loss: 2.108549432146271

Epoch: 6| Step: 8
Training loss: 0.42540920696885587
Validation loss: 2.1535393350221983

Epoch: 6| Step: 9
Training loss: 0.4618994486716912
Validation loss: 2.185648283544475

Epoch: 6| Step: 10
Training loss: 0.33829960850330176
Validation loss: 2.197148635065038

Epoch: 6| Step: 11
Training loss: 0.38407394280392754
Validation loss: 2.0873435944265126

Epoch: 6| Step: 12
Training loss: 1.338416181488516
Validation loss: 2.114230862220055

Epoch: 6| Step: 13
Training loss: 0.47972405881455904
Validation loss: 2.126782485850298

Epoch: 767| Step: 0
Training loss: 0.3703127623609426
Validation loss: 2.0965608876398916

Epoch: 6| Step: 1
Training loss: 0.4854241974973649
Validation loss: 2.1255073774070516

Epoch: 6| Step: 2
Training loss: 0.5282468621322801
Validation loss: 2.13542290023106

Epoch: 6| Step: 3
Training loss: 0.5424283309040263
Validation loss: 2.1476518962537563

Epoch: 6| Step: 4
Training loss: 1.305375700030915
Validation loss: 2.1410979019607805

Epoch: 6| Step: 5
Training loss: 0.5089467219890155
Validation loss: 2.1134731875880064

Epoch: 6| Step: 6
Training loss: 0.537933272566638
Validation loss: 2.121729124374146

Epoch: 6| Step: 7
Training loss: 0.3465375367057986
Validation loss: 2.159790927929398

Epoch: 6| Step: 8
Training loss: 0.45822881641217017
Validation loss: 2.096235354269369

Epoch: 6| Step: 9
Training loss: 0.5378249793901725
Validation loss: 2.144161920655061

Epoch: 6| Step: 10
Training loss: 0.41431514661573454
Validation loss: 2.154869748293829

Epoch: 6| Step: 11
Training loss: 0.5514995679533745
Validation loss: 2.100126088561938

Epoch: 6| Step: 12
Training loss: 0.45408367819074946
Validation loss: 2.1650444253196643

Epoch: 6| Step: 13
Training loss: 0.5631886875748403
Validation loss: 2.142803529404645

Epoch: 768| Step: 0
Training loss: 0.4319948839882513
Validation loss: 2.1317268311982307

Epoch: 6| Step: 1
Training loss: 0.4500905409432813
Validation loss: 2.0733132154405793

Epoch: 6| Step: 2
Training loss: 0.43110381703307366
Validation loss: 2.117847459794735

Epoch: 6| Step: 3
Training loss: 0.47287768701853256
Validation loss: 2.114303613607264

Epoch: 6| Step: 4
Training loss: 0.4925435004895471
Validation loss: 2.0869136098212366

Epoch: 6| Step: 5
Training loss: 0.40309683679187963
Validation loss: 2.105364196069874

Epoch: 6| Step: 6
Training loss: 0.39937955152279053
Validation loss: 2.042399966822675

Epoch: 6| Step: 7
Training loss: 0.42722143483526864
Validation loss: 2.1399683749522853

Epoch: 6| Step: 8
Training loss: 0.4074705019905229
Validation loss: 2.1498218325191067

Epoch: 6| Step: 9
Training loss: 0.4417828160485059
Validation loss: 2.1441320546151843

Epoch: 6| Step: 10
Training loss: 0.41673592548139854
Validation loss: 2.1446533054825196

Epoch: 6| Step: 11
Training loss: 0.45049395141076287
Validation loss: 2.127036417009154

Epoch: 6| Step: 12
Training loss: 1.348538184799649
Validation loss: 2.1447210552342173

Epoch: 6| Step: 13
Training loss: 0.4788071503404478
Validation loss: 2.1865400126940613

Epoch: 769| Step: 0
Training loss: 0.40409573329078635
Validation loss: 2.132230023813796

Epoch: 6| Step: 1
Training loss: 0.29794042543671906
Validation loss: 2.1290630269678306

Epoch: 6| Step: 2
Training loss: 0.4656741314767316
Validation loss: 2.1246418847228408

Epoch: 6| Step: 3
Training loss: 0.3476755479750015
Validation loss: 2.1547206896540696

Epoch: 6| Step: 4
Training loss: 0.5225016640449565
Validation loss: 2.1730517639275164

Epoch: 6| Step: 5
Training loss: 0.46984202022760546
Validation loss: 2.10184562823168

Epoch: 6| Step: 6
Training loss: 0.4978887868069449
Validation loss: 2.1223607403448224

Epoch: 6| Step: 7
Training loss: 0.5178701764378633
Validation loss: 2.1218868967815245

Epoch: 6| Step: 8
Training loss: 1.3149191949769565
Validation loss: 2.1372260844749547

Epoch: 6| Step: 9
Training loss: 0.5690279564383767
Validation loss: 2.1339355556630024

Epoch: 6| Step: 10
Training loss: 0.4618122238579628
Validation loss: 2.163496891921698

Epoch: 6| Step: 11
Training loss: 0.3856302412780497
Validation loss: 2.082160859018931

Epoch: 6| Step: 12
Training loss: 0.4170266344909122
Validation loss: 2.128098159029773

Epoch: 6| Step: 13
Training loss: 0.5249086175588003
Validation loss: 2.152902107626874

Epoch: 770| Step: 0
Training loss: 0.42104122987951353
Validation loss: 2.0690474202183347

Epoch: 6| Step: 1
Training loss: 1.252068096243783
Validation loss: 2.090606762997969

Epoch: 6| Step: 2
Training loss: 0.5575517124945096
Validation loss: 2.0787981503474007

Epoch: 6| Step: 3
Training loss: 0.48206200091982704
Validation loss: 2.1409098833298192

Epoch: 6| Step: 4
Training loss: 0.41707896060093186
Validation loss: 2.1467369447772255

Epoch: 6| Step: 5
Training loss: 0.23853939175388617
Validation loss: 2.1587415439421975

Epoch: 6| Step: 6
Training loss: 0.4720306985921963
Validation loss: 2.1125201611746993

Epoch: 6| Step: 7
Training loss: 0.6230611530449729
Validation loss: 2.1158401930198623

Epoch: 6| Step: 8
Training loss: 0.41435148842738617
Validation loss: 2.146150784338045

Epoch: 6| Step: 9
Training loss: 0.35587227103925867
Validation loss: 2.1074494363468017

Epoch: 6| Step: 10
Training loss: 0.5027839819939248
Validation loss: 2.104495994903803

Epoch: 6| Step: 11
Training loss: 0.41900246681588843
Validation loss: 2.1530774404031985

Epoch: 6| Step: 12
Training loss: 0.3624392771012099
Validation loss: 2.0971018232524403

Epoch: 6| Step: 13
Training loss: 0.35120339596916056
Validation loss: 2.137013816268168

Epoch: 771| Step: 0
Training loss: 0.4706518216488027
Validation loss: 2.108696239286606

Epoch: 6| Step: 1
Training loss: 0.4000735632486068
Validation loss: 2.1643776109451967

Epoch: 6| Step: 2
Training loss: 0.6081023008338473
Validation loss: 2.14663835266017

Epoch: 6| Step: 3
Training loss: 0.4267813983745754
Validation loss: 2.1895460858226974

Epoch: 6| Step: 4
Training loss: 0.6476722245955455
Validation loss: 2.050896370386776

Epoch: 6| Step: 5
Training loss: 0.4015619404117233
Validation loss: 2.1304375624725207

Epoch: 6| Step: 6
Training loss: 0.5296850153771926
Validation loss: 2.1113390591242944

Epoch: 6| Step: 7
Training loss: 0.5196461944772542
Validation loss: 2.1198093868798016

Epoch: 6| Step: 8
Training loss: 1.35202807748013
Validation loss: 2.1433454388386157

Epoch: 6| Step: 9
Training loss: 0.6281324329221112
Validation loss: 2.1702519866240135

Epoch: 6| Step: 10
Training loss: 0.45349676403480943
Validation loss: 2.0882762066857286

Epoch: 6| Step: 11
Training loss: 0.3570766345003726
Validation loss: 2.0722152711420567

Epoch: 6| Step: 12
Training loss: 0.3507236964497184
Validation loss: 2.162159693691812

Epoch: 6| Step: 13
Training loss: 0.3996409585502961
Validation loss: 2.0913100230961845

Epoch: 772| Step: 0
Training loss: 0.6293232169341725
Validation loss: 2.126016036122899

Epoch: 6| Step: 1
Training loss: 0.38471889696202843
Validation loss: 2.138224558328056

Epoch: 6| Step: 2
Training loss: 0.46968135497235136
Validation loss: 2.0776573528999727

Epoch: 6| Step: 3
Training loss: 1.369221509429857
Validation loss: 2.158068890402153

Epoch: 6| Step: 4
Training loss: 0.5065080761957561
Validation loss: 2.1999244957120827

Epoch: 6| Step: 5
Training loss: 0.4223288461396122
Validation loss: 2.110832249999127

Epoch: 6| Step: 6
Training loss: 0.4106612774748968
Validation loss: 2.1371340932778167

Epoch: 6| Step: 7
Training loss: 0.4991650165897835
Validation loss: 2.1309207202750176

Epoch: 6| Step: 8
Training loss: 0.39893173904359086
Validation loss: 2.095083956285213

Epoch: 6| Step: 9
Training loss: 0.5091652092962224
Validation loss: 2.1483856332135822

Epoch: 6| Step: 10
Training loss: 0.5828987926999435
Validation loss: 2.1462259410326436

Epoch: 6| Step: 11
Training loss: 0.41045891629838127
Validation loss: 2.1420563745411827

Epoch: 6| Step: 12
Training loss: 0.4798118628909716
Validation loss: 2.1691576747681047

Epoch: 6| Step: 13
Training loss: 0.5446452323897516
Validation loss: 2.0432566499097726

Epoch: 773| Step: 0
Training loss: 0.4775091368614941
Validation loss: 2.0957452416420477

Epoch: 6| Step: 1
Training loss: 0.37085867011206375
Validation loss: 2.0977386723010905

Epoch: 6| Step: 2
Training loss: 0.5354684907296463
Validation loss: 2.109140397808261

Epoch: 6| Step: 3
Training loss: 0.29638552469079
Validation loss: 2.1559243783396806

Epoch: 6| Step: 4
Training loss: 0.5038144523337645
Validation loss: 2.120732328330321

Epoch: 6| Step: 5
Training loss: 0.4947526180184573
Validation loss: 2.140264270083776

Epoch: 6| Step: 6
Training loss: 0.27813101236938387
Validation loss: 2.1009708097208604

Epoch: 6| Step: 7
Training loss: 0.44217260895043387
Validation loss: 2.1228507318366834

Epoch: 6| Step: 8
Training loss: 0.3388346675692357
Validation loss: 2.204877590481425

Epoch: 6| Step: 9
Training loss: 0.41233302551639406
Validation loss: 2.147215333556005

Epoch: 6| Step: 10
Training loss: 0.34127196195866905
Validation loss: 2.0784890004653045

Epoch: 6| Step: 11
Training loss: 1.4284087752661008
Validation loss: 2.116468514164028

Epoch: 6| Step: 12
Training loss: 0.5192110035467961
Validation loss: 2.1500559031417636

Epoch: 6| Step: 13
Training loss: 0.44209777204728307
Validation loss: 2.11145037633632

Epoch: 774| Step: 0
Training loss: 0.4796637793276882
Validation loss: 2.114375618027935

Epoch: 6| Step: 1
Training loss: 0.5297815841343427
Validation loss: 2.1433630760555014

Epoch: 6| Step: 2
Training loss: 1.3164705436242106
Validation loss: 2.192136198882891

Epoch: 6| Step: 3
Training loss: 0.36959171486001774
Validation loss: 2.1347425832019873

Epoch: 6| Step: 4
Training loss: 0.518574227577351
Validation loss: 2.1040340001225575

Epoch: 6| Step: 5
Training loss: 0.4965161755309651
Validation loss: 2.0917512024607325

Epoch: 6| Step: 6
Training loss: 0.43851414712683695
Validation loss: 2.047388845330851

Epoch: 6| Step: 7
Training loss: 0.4375272469891563
Validation loss: 2.1206263092054285

Epoch: 6| Step: 8
Training loss: 0.3001378845204119
Validation loss: 2.1233710898893174

Epoch: 6| Step: 9
Training loss: 0.4510976226608694
Validation loss: 2.2056913408326553

Epoch: 6| Step: 10
Training loss: 0.4173731972814554
Validation loss: 2.1995697018314484

Epoch: 6| Step: 11
Training loss: 0.7729715427204034
Validation loss: 2.1475131089467476

Epoch: 6| Step: 12
Training loss: 0.3358081635188598
Validation loss: 2.1302653328951093

Epoch: 6| Step: 13
Training loss: 0.5343784611015444
Validation loss: 2.1086411938096554

Epoch: 775| Step: 0
Training loss: 0.5722791129856457
Validation loss: 2.1524221927357305

Epoch: 6| Step: 1
Training loss: 0.4496144749329804
Validation loss: 2.144793058665059

Epoch: 6| Step: 2
Training loss: 0.43266151493901456
Validation loss: 2.09535603889387

Epoch: 6| Step: 3
Training loss: 1.372734153590793
Validation loss: 2.117784869091668

Epoch: 6| Step: 4
Training loss: 0.3438497528644964
Validation loss: 2.1450140090080665

Epoch: 6| Step: 5
Training loss: 0.28908021975668063
Validation loss: 2.094655761623699

Epoch: 6| Step: 6
Training loss: 0.3119469039529788
Validation loss: 2.1203768044691995

Epoch: 6| Step: 7
Training loss: 0.4492221997999329
Validation loss: 2.1163163486354555

Epoch: 6| Step: 8
Training loss: 0.38299256585727337
Validation loss: 2.107224520761147

Epoch: 6| Step: 9
Training loss: 0.43708244902148885
Validation loss: 2.12525194690435

Epoch: 6| Step: 10
Training loss: 0.585547584497634
Validation loss: 2.147457874503353

Epoch: 6| Step: 11
Training loss: 0.3756053330387134
Validation loss: 2.112554012772367

Epoch: 6| Step: 12
Training loss: 0.3775646802930517
Validation loss: 2.092927330631956

Epoch: 6| Step: 13
Training loss: 0.31469164266956356
Validation loss: 2.119537334226954

Epoch: 776| Step: 0
Training loss: 0.34368575102587745
Validation loss: 2.1425607334904746

Epoch: 6| Step: 1
Training loss: 0.39512891162745106
Validation loss: 2.0742908667093256

Epoch: 6| Step: 2
Training loss: 0.31747984356614756
Validation loss: 2.0558211113861216

Epoch: 6| Step: 3
Training loss: 0.5257511249317971
Validation loss: 2.1417185606362636

Epoch: 6| Step: 4
Training loss: 0.38343748339813866
Validation loss: 2.166198249931881

Epoch: 6| Step: 5
Training loss: 0.4656183856775943
Validation loss: 2.1377938038005393

Epoch: 6| Step: 6
Training loss: 0.5394844117922108
Validation loss: 2.1489401918887916

Epoch: 6| Step: 7
Training loss: 0.42165711745781675
Validation loss: 2.212542854433084

Epoch: 6| Step: 8
Training loss: 0.4289029501699448
Validation loss: 2.108266034410602

Epoch: 6| Step: 9
Training loss: 0.3721937640581434
Validation loss: 2.110799301123339

Epoch: 6| Step: 10
Training loss: 0.6113471860016392
Validation loss: 2.141828552686798

Epoch: 6| Step: 11
Training loss: 0.35085362917455704
Validation loss: 2.1111791153511454

Epoch: 6| Step: 12
Training loss: 1.330169988252289
Validation loss: 2.1422395861898016

Epoch: 6| Step: 13
Training loss: 0.3969095140002625
Validation loss: 2.155735662536496

Epoch: 777| Step: 0
Training loss: 0.4344247295537075
Validation loss: 2.088367607010195

Epoch: 6| Step: 1
Training loss: 0.4867605714908818
Validation loss: 2.1387551427493485

Epoch: 6| Step: 2
Training loss: 0.43668456378810633
Validation loss: 2.1133592181139136

Epoch: 6| Step: 3
Training loss: 0.4281398297268346
Validation loss: 2.1636832117244675

Epoch: 6| Step: 4
Training loss: 0.33455673608886943
Validation loss: 2.1635352911454246

Epoch: 6| Step: 5
Training loss: 0.4431859488061332
Validation loss: 2.1027223803668607

Epoch: 6| Step: 6
Training loss: 0.44515009478474077
Validation loss: 2.077248213703833

Epoch: 6| Step: 7
Training loss: 0.5412402186049505
Validation loss: 2.1016009159086404

Epoch: 6| Step: 8
Training loss: 0.4340802118630144
Validation loss: 2.1388019535132896

Epoch: 6| Step: 9
Training loss: 0.49867272043612176
Validation loss: 2.1206134143564594

Epoch: 6| Step: 10
Training loss: 0.4674088684037255
Validation loss: 2.1408920714300885

Epoch: 6| Step: 11
Training loss: 0.32373709693440844
Validation loss: 2.095637387119686

Epoch: 6| Step: 12
Training loss: 1.3157278514536666
Validation loss: 2.0508063145759734

Epoch: 6| Step: 13
Training loss: 0.5579712874141993
Validation loss: 2.1498193867211084

Epoch: 778| Step: 0
Training loss: 0.46203387523185246
Validation loss: 2.1139748501677644

Epoch: 6| Step: 1
Training loss: 0.5108029856335425
Validation loss: 2.165508462583312

Epoch: 6| Step: 2
Training loss: 0.30192610606207076
Validation loss: 2.146097814658364

Epoch: 6| Step: 3
Training loss: 0.5715356539120083
Validation loss: 2.123467086103801

Epoch: 6| Step: 4
Training loss: 0.585319956555302
Validation loss: 2.095232863789907

Epoch: 6| Step: 5
Training loss: 1.3071778793765212
Validation loss: 2.0448171777612036

Epoch: 6| Step: 6
Training loss: 0.419529896028916
Validation loss: 2.0952951566901796

Epoch: 6| Step: 7
Training loss: 0.34798869835928725
Validation loss: 2.14405423942576

Epoch: 6| Step: 8
Training loss: 0.39367198852488977
Validation loss: 2.0945611899691565

Epoch: 6| Step: 9
Training loss: 0.511012747820202
Validation loss: 2.0685168270305407

Epoch: 6| Step: 10
Training loss: 0.4092277553247695
Validation loss: 2.143838148631637

Epoch: 6| Step: 11
Training loss: 0.5076654074451428
Validation loss: 2.092263937310653

Epoch: 6| Step: 12
Training loss: 0.43834439603034947
Validation loss: 2.178401471636071

Epoch: 6| Step: 13
Training loss: 0.3465642065138633
Validation loss: 2.1741675117386734

Epoch: 779| Step: 0
Training loss: 0.419443274709335
Validation loss: 2.065439869154901

Epoch: 6| Step: 1
Training loss: 0.5967082065191197
Validation loss: 2.060278687303732

Epoch: 6| Step: 2
Training loss: 0.3857958213121553
Validation loss: 2.080421947992079

Epoch: 6| Step: 3
Training loss: 0.3691722715022657
Validation loss: 2.1106378315647634

Epoch: 6| Step: 4
Training loss: 0.41727661152631834
Validation loss: 2.1029374369855898

Epoch: 6| Step: 5
Training loss: 0.4372741593152881
Validation loss: 2.199344101697213

Epoch: 6| Step: 6
Training loss: 1.2886961907772205
Validation loss: 2.0627362006338714

Epoch: 6| Step: 7
Training loss: 0.3630486020268144
Validation loss: 2.1040593447546696

Epoch: 6| Step: 8
Training loss: 0.5282943070475549
Validation loss: 2.1495794608044

Epoch: 6| Step: 9
Training loss: 0.39586485770663316
Validation loss: 2.0909034726374918

Epoch: 6| Step: 10
Training loss: 0.3989177502275494
Validation loss: 2.0782966132727205

Epoch: 6| Step: 11
Training loss: 0.46016520117455306
Validation loss: 2.1080149809744833

Epoch: 6| Step: 12
Training loss: 0.47824070097780974
Validation loss: 2.138907449278012

Epoch: 6| Step: 13
Training loss: 0.450253431164145
Validation loss: 2.1462986972439215

Epoch: 780| Step: 0
Training loss: 0.4568442263591268
Validation loss: 2.087857186378426

Epoch: 6| Step: 1
Training loss: 0.4222260180450495
Validation loss: 2.089615780979201

Epoch: 6| Step: 2
Training loss: 0.39230849842597165
Validation loss: 2.170707037427453

Epoch: 6| Step: 3
Training loss: 0.4934203435658497
Validation loss: 2.087449222276496

Epoch: 6| Step: 4
Training loss: 0.32685955445101283
Validation loss: 2.1335259089230996

Epoch: 6| Step: 5
Training loss: 0.33848575594964203
Validation loss: 2.102147996809295

Epoch: 6| Step: 6
Training loss: 0.43940266637396813
Validation loss: 2.1170190838695757

Epoch: 6| Step: 7
Training loss: 0.44130624634164217
Validation loss: 2.1434355924580752

Epoch: 6| Step: 8
Training loss: 0.48772068652782113
Validation loss: 2.1674949890325568

Epoch: 6| Step: 9
Training loss: 0.4168328867605736
Validation loss: 2.1381363372061406

Epoch: 6| Step: 10
Training loss: 1.394703274756679
Validation loss: 2.080548116246412

Epoch: 6| Step: 11
Training loss: 0.45236955348391344
Validation loss: 2.174372563368847

Epoch: 6| Step: 12
Training loss: 0.4741167565254436
Validation loss: 2.1685099897177644

Epoch: 6| Step: 13
Training loss: 0.5153780259018806
Validation loss: 2.1243055289779464

Epoch: 781| Step: 0
Training loss: 0.3425577903636784
Validation loss: 2.112190248678066

Epoch: 6| Step: 1
Training loss: 0.4789891605265687
Validation loss: 2.098381054292497

Epoch: 6| Step: 2
Training loss: 0.4956149696980326
Validation loss: 2.1471991066918488

Epoch: 6| Step: 3
Training loss: 0.38129939556629167
Validation loss: 2.1572141354013317

Epoch: 6| Step: 4
Training loss: 0.5996533107503635
Validation loss: 2.1093560312528

Epoch: 6| Step: 5
Training loss: 0.4744226849880766
Validation loss: 2.1569424611587524

Epoch: 6| Step: 6
Training loss: 1.3567478180420192
Validation loss: 2.1021207644420787

Epoch: 6| Step: 7
Training loss: 0.48573458504182204
Validation loss: 2.1215556531320057

Epoch: 6| Step: 8
Training loss: 0.5794527426763793
Validation loss: 2.0973850335455584

Epoch: 6| Step: 9
Training loss: 0.5981642116500857
Validation loss: 2.125832299980614

Epoch: 6| Step: 10
Training loss: 0.4053365635254314
Validation loss: 2.1554454201797557

Epoch: 6| Step: 11
Training loss: 0.35401211433102736
Validation loss: 2.071543958551191

Epoch: 6| Step: 12
Training loss: 0.3859760203423817
Validation loss: 2.1102440882275744

Epoch: 6| Step: 13
Training loss: 0.3236030914896033
Validation loss: 2.0847497821467744

Epoch: 782| Step: 0
Training loss: 0.45252862686946976
Validation loss: 2.1140938404514347

Epoch: 6| Step: 1
Training loss: 0.3805271362373042
Validation loss: 2.1207161792835096

Epoch: 6| Step: 2
Training loss: 0.4056965285539376
Validation loss: 2.085345596719098

Epoch: 6| Step: 3
Training loss: 0.4344129984859515
Validation loss: 2.0609780068996626

Epoch: 6| Step: 4
Training loss: 0.38094796348640264
Validation loss: 2.1851876162152077

Epoch: 6| Step: 5
Training loss: 0.36564702676789823
Validation loss: 2.0972675442956854

Epoch: 6| Step: 6
Training loss: 0.3825726438865458
Validation loss: 2.107020676347647

Epoch: 6| Step: 7
Training loss: 0.46967570769125255
Validation loss: 2.108921753723929

Epoch: 6| Step: 8
Training loss: 0.5589950827073502
Validation loss: 2.0226497950067666

Epoch: 6| Step: 9
Training loss: 1.346066585007632
Validation loss: 2.091274704107097

Epoch: 6| Step: 10
Training loss: 0.5885154977117472
Validation loss: 2.0904251070514084

Epoch: 6| Step: 11
Training loss: 0.47405133190843035
Validation loss: 2.117821451273795

Epoch: 6| Step: 12
Training loss: 0.40886911336544185
Validation loss: 2.0836705515314278

Epoch: 6| Step: 13
Training loss: 0.35794783285928733
Validation loss: 2.1286473517487248

Epoch: 783| Step: 0
Training loss: 0.4999174109437115
Validation loss: 2.098439672359612

Epoch: 6| Step: 1
Training loss: 0.3766788018151037
Validation loss: 2.021829868313847

Epoch: 6| Step: 2
Training loss: 0.3654232862555139
Validation loss: 2.1534428364988063

Epoch: 6| Step: 3
Training loss: 0.314619577079963
Validation loss: 2.061453135023206

Epoch: 6| Step: 4
Training loss: 1.3318278137755888
Validation loss: 2.151714929213355

Epoch: 6| Step: 5
Training loss: 0.3316440119306426
Validation loss: 2.0738679687240613

Epoch: 6| Step: 6
Training loss: 0.5184562000491459
Validation loss: 2.0790866289518743

Epoch: 6| Step: 7
Training loss: 0.46459170328249944
Validation loss: 2.1527567634081715

Epoch: 6| Step: 8
Training loss: 0.3540193120300822
Validation loss: 2.041225198108346

Epoch: 6| Step: 9
Training loss: 0.3961224148702967
Validation loss: 2.1094816022192955

Epoch: 6| Step: 10
Training loss: 0.4544959867717794
Validation loss: 2.142661571172386

Epoch: 6| Step: 11
Training loss: 0.36676288971356125
Validation loss: 2.0852273817909057

Epoch: 6| Step: 12
Training loss: 0.5532454968254965
Validation loss: 2.1552003895050995

Epoch: 6| Step: 13
Training loss: 0.5817185400327949
Validation loss: 2.100022471703706

Epoch: 784| Step: 0
Training loss: 0.4898543689799669
Validation loss: 2.073666613197475

Epoch: 6| Step: 1
Training loss: 0.34556638308541016
Validation loss: 2.1452143384944287

Epoch: 6| Step: 2
Training loss: 0.4528494194201833
Validation loss: 2.0545172756325254

Epoch: 6| Step: 3
Training loss: 0.566089252029731
Validation loss: 2.1391299051842743

Epoch: 6| Step: 4
Training loss: 0.30808689647867266
Validation loss: 2.112614867831288

Epoch: 6| Step: 5
Training loss: 0.4421649927133238
Validation loss: 2.1424059254850665

Epoch: 6| Step: 6
Training loss: 0.5987827430643969
Validation loss: 2.178850032840787

Epoch: 6| Step: 7
Training loss: 0.585144447238186
Validation loss: 2.0943531434311877

Epoch: 6| Step: 8
Training loss: 1.4189451444747836
Validation loss: 2.137266340511459

Epoch: 6| Step: 9
Training loss: 0.5265335075026187
Validation loss: 2.1546195471731577

Epoch: 6| Step: 10
Training loss: 0.41008176581404804
Validation loss: 2.165360567832841

Epoch: 6| Step: 11
Training loss: 0.4446497720622786
Validation loss: 2.1478486537822734

Epoch: 6| Step: 12
Training loss: 0.5596499294874313
Validation loss: 2.1556714188090274

Epoch: 6| Step: 13
Training loss: 0.39185775785828525
Validation loss: 2.0493312127195398

Epoch: 785| Step: 0
Training loss: 1.2774243343960208
Validation loss: 2.109697591466224

Epoch: 6| Step: 1
Training loss: 0.63616123247245
Validation loss: 2.095889044950239

Epoch: 6| Step: 2
Training loss: 0.6858783800720722
Validation loss: 2.1202151072703725

Epoch: 6| Step: 3
Training loss: 0.522756161569982
Validation loss: 2.1386683699782862

Epoch: 6| Step: 4
Training loss: 0.41005436676383217
Validation loss: 2.0865159786724603

Epoch: 6| Step: 5
Training loss: 0.4706428299270884
Validation loss: 2.104138198590108

Epoch: 6| Step: 6
Training loss: 0.3909460655634027
Validation loss: 2.1696249832762944

Epoch: 6| Step: 7
Training loss: 0.3858314893663366
Validation loss: 2.1031484899053363

Epoch: 6| Step: 8
Training loss: 0.40141283133083305
Validation loss: 2.143930347818269

Epoch: 6| Step: 9
Training loss: 0.4900090737135248
Validation loss: 2.1380806929608775

Epoch: 6| Step: 10
Training loss: 0.5805442042232225
Validation loss: 2.1299570537499077

Epoch: 6| Step: 11
Training loss: 0.39916734607110443
Validation loss: 2.0432561630924724

Epoch: 6| Step: 12
Training loss: 0.5109174438646525
Validation loss: 2.0698654568241786

Epoch: 6| Step: 13
Training loss: 0.3715104022770985
Validation loss: 2.1336707344266252

Epoch: 786| Step: 0
Training loss: 0.5057478085770698
Validation loss: 2.1641504970174563

Epoch: 6| Step: 1
Training loss: 0.3211672937673779
Validation loss: 2.14398955658734

Epoch: 6| Step: 2
Training loss: 0.5454933970424983
Validation loss: 2.0602657625382768

Epoch: 6| Step: 3
Training loss: 0.616138290741759
Validation loss: 2.1312967027235903

Epoch: 6| Step: 4
Training loss: 0.5240773233354281
Validation loss: 2.0764143925266603

Epoch: 6| Step: 5
Training loss: 0.6027093828994081
Validation loss: 2.0902343642559935

Epoch: 6| Step: 6
Training loss: 0.5064707710290282
Validation loss: 2.0616164752845445

Epoch: 6| Step: 7
Training loss: 0.49940053946126384
Validation loss: 2.1533981541702225

Epoch: 6| Step: 8
Training loss: 0.3951734848758913
Validation loss: 2.0759342231886464

Epoch: 6| Step: 9
Training loss: 0.3626834298417722
Validation loss: 2.173514077500603

Epoch: 6| Step: 10
Training loss: 0.5458708672564692
Validation loss: 2.090640952249325

Epoch: 6| Step: 11
Training loss: 1.36543130613986
Validation loss: 2.141945486360266

Epoch: 6| Step: 12
Training loss: 0.3460178558973622
Validation loss: 2.124614368122573

Epoch: 6| Step: 13
Training loss: 0.3334974677084104
Validation loss: 2.1012605748413717

Epoch: 787| Step: 0
Training loss: 0.4404399388509529
Validation loss: 2.1410212762641847

Epoch: 6| Step: 1
Training loss: 0.5625086889655512
Validation loss: 2.1469591040833533

Epoch: 6| Step: 2
Training loss: 0.45044889776154495
Validation loss: 2.0658690318371016

Epoch: 6| Step: 3
Training loss: 0.4252919877015809
Validation loss: 2.106610922813195

Epoch: 6| Step: 4
Training loss: 0.5044874048541689
Validation loss: 2.02884356157109

Epoch: 6| Step: 5
Training loss: 0.4625175356762478
Validation loss: 2.0971065890399427

Epoch: 6| Step: 6
Training loss: 1.3264471788008763
Validation loss: 2.136861728087522

Epoch: 6| Step: 7
Training loss: 0.4586830935944227
Validation loss: 2.0867049660533046

Epoch: 6| Step: 8
Training loss: 0.37662167380985173
Validation loss: 2.1166235822811688

Epoch: 6| Step: 9
Training loss: 0.5373658278916582
Validation loss: 2.019059580567072

Epoch: 6| Step: 10
Training loss: 0.5098520841393741
Validation loss: 2.1010884243810684

Epoch: 6| Step: 11
Training loss: 0.42612710957160244
Validation loss: 2.0491378854858704

Epoch: 6| Step: 12
Training loss: 0.5794055006029474
Validation loss: 2.0956480434560034

Epoch: 6| Step: 13
Training loss: 0.47844935366985253
Validation loss: 2.1032214369245

Epoch: 788| Step: 0
Training loss: 0.3783159278375277
Validation loss: 2.042716538230276

Epoch: 6| Step: 1
Training loss: 0.48118090381255835
Validation loss: 2.098294106733162

Epoch: 6| Step: 2
Training loss: 0.4047436295986431
Validation loss: 2.079607856183093

Epoch: 6| Step: 3
Training loss: 0.40784928166928436
Validation loss: 2.104323191767077

Epoch: 6| Step: 4
Training loss: 0.6418597255029699
Validation loss: 2.0778636078688386

Epoch: 6| Step: 5
Training loss: 0.5367120278727373
Validation loss: 2.094268624397897

Epoch: 6| Step: 6
Training loss: 0.5426996785631242
Validation loss: 2.1727382732232736

Epoch: 6| Step: 7
Training loss: 0.5513812645396517
Validation loss: 2.0875284800294662

Epoch: 6| Step: 8
Training loss: 0.4648924890178943
Validation loss: 2.1641385195499785

Epoch: 6| Step: 9
Training loss: 1.280696516744226
Validation loss: 2.094453286101822

Epoch: 6| Step: 10
Training loss: 0.5851763549936327
Validation loss: 2.07146933444799

Epoch: 6| Step: 11
Training loss: 0.37311615225750694
Validation loss: 2.051595817870003

Epoch: 6| Step: 12
Training loss: 0.43031000647726214
Validation loss: 2.1440857556919535

Epoch: 6| Step: 13
Training loss: 0.7541861138198694
Validation loss: 2.073673700182787

Epoch: 789| Step: 0
Training loss: 0.42885203201223493
Validation loss: 2.122080595691885

Epoch: 6| Step: 1
Training loss: 0.3483801388246897
Validation loss: 2.1021119031756696

Epoch: 6| Step: 2
Training loss: 0.3725869504203689
Validation loss: 2.073466892424966

Epoch: 6| Step: 3
Training loss: 0.3576290384909252
Validation loss: 2.133505667306625

Epoch: 6| Step: 4
Training loss: 0.5347227024995482
Validation loss: 2.110999497479431

Epoch: 6| Step: 5
Training loss: 0.517976053684116
Validation loss: 2.1485318941949725

Epoch: 6| Step: 6
Training loss: 0.5070397586431858
Validation loss: 2.0740697515323885

Epoch: 6| Step: 7
Training loss: 1.3132853656003096
Validation loss: 2.092566481217925

Epoch: 6| Step: 8
Training loss: 0.2810812947480842
Validation loss: 2.1056541157171056

Epoch: 6| Step: 9
Training loss: 0.4780704685354493
Validation loss: 2.096066932411424

Epoch: 6| Step: 10
Training loss: 0.44675346268996735
Validation loss: 2.0997975270130107

Epoch: 6| Step: 11
Training loss: 0.408527756242936
Validation loss: 2.0610086674442094

Epoch: 6| Step: 12
Training loss: 0.40714883405557595
Validation loss: 2.102257632482317

Epoch: 6| Step: 13
Training loss: 0.38003107624600496
Validation loss: 2.1212809378541158

Epoch: 790| Step: 0
Training loss: 0.4191497979489112
Validation loss: 2.0955465014525445

Epoch: 6| Step: 1
Training loss: 0.5107121650230668
Validation loss: 2.147950880739107

Epoch: 6| Step: 2
Training loss: 0.39893086125513977
Validation loss: 2.126187764079894

Epoch: 6| Step: 3
Training loss: 0.5208674292530288
Validation loss: 2.0598261913605818

Epoch: 6| Step: 4
Training loss: 0.2912265729896242
Validation loss: 2.1266249030507054

Epoch: 6| Step: 5
Training loss: 0.6295517162140546
Validation loss: 2.110016101077249

Epoch: 6| Step: 6
Training loss: 0.35377240207762284
Validation loss: 2.1253337516579616

Epoch: 6| Step: 7
Training loss: 0.4610729341840122
Validation loss: 2.0829525478572775

Epoch: 6| Step: 8
Training loss: 0.41678151296318566
Validation loss: 2.1159712970933273

Epoch: 6| Step: 9
Training loss: 0.4257141725391656
Validation loss: 2.1067174847983106

Epoch: 6| Step: 10
Training loss: 0.49835895409740444
Validation loss: 2.1517100597899055

Epoch: 6| Step: 11
Training loss: 0.4600584408705766
Validation loss: 2.1316237765695236

Epoch: 6| Step: 12
Training loss: 1.2586876330414196
Validation loss: 2.1360699242428227

Epoch: 6| Step: 13
Training loss: 0.4945166442546244
Validation loss: 2.1240779039082422

Epoch: 791| Step: 0
Training loss: 0.5156494481619659
Validation loss: 2.1376648104444778

Epoch: 6| Step: 1
Training loss: 0.39614071539355444
Validation loss: 2.137342006925345

Epoch: 6| Step: 2
Training loss: 0.5622219352078532
Validation loss: 2.1002684256109627

Epoch: 6| Step: 3
Training loss: 0.42434623797764887
Validation loss: 2.1245313878102148

Epoch: 6| Step: 4
Training loss: 0.3825925857088769
Validation loss: 2.0656410449119442

Epoch: 6| Step: 5
Training loss: 0.40629001567073364
Validation loss: 2.109472460756946

Epoch: 6| Step: 6
Training loss: 0.5398218915077547
Validation loss: 2.122255670501909

Epoch: 6| Step: 7
Training loss: 0.4256636430896346
Validation loss: 2.139087558126972

Epoch: 6| Step: 8
Training loss: 0.4679033103111178
Validation loss: 2.150118972098422

Epoch: 6| Step: 9
Training loss: 0.36966750473805177
Validation loss: 2.091906736989492

Epoch: 6| Step: 10
Training loss: 0.3945015244569321
Validation loss: 2.0911553814202795

Epoch: 6| Step: 11
Training loss: 0.5168744756287725
Validation loss: 2.1130085910012366

Epoch: 6| Step: 12
Training loss: 1.3194734966135873
Validation loss: 2.0988756368762784

Epoch: 6| Step: 13
Training loss: 0.3918994712185535
Validation loss: 2.0819462658391164

Epoch: 792| Step: 0
Training loss: 0.43879565754004907
Validation loss: 2.097901470722651

Epoch: 6| Step: 1
Training loss: 0.3859350181221794
Validation loss: 2.202870970094987

Epoch: 6| Step: 2
Training loss: 0.43536616113076154
Validation loss: 2.0800022365405804

Epoch: 6| Step: 3
Training loss: 0.4260713481434785
Validation loss: 2.1436583677672267

Epoch: 6| Step: 4
Training loss: 0.38572362541251975
Validation loss: 2.128169030570092

Epoch: 6| Step: 5
Training loss: 0.3517189737299746
Validation loss: 2.1237347302648404

Epoch: 6| Step: 6
Training loss: 1.272708941844737
Validation loss: 2.0553517909475287

Epoch: 6| Step: 7
Training loss: 0.34400343222486085
Validation loss: 2.1063426588705982

Epoch: 6| Step: 8
Training loss: 0.4468154640819796
Validation loss: 2.165341910161029

Epoch: 6| Step: 9
Training loss: 0.4385063314209135
Validation loss: 2.1735020118623165

Epoch: 6| Step: 10
Training loss: 0.38120158544718064
Validation loss: 2.1296288186694414

Epoch: 6| Step: 11
Training loss: 0.5898835882413308
Validation loss: 2.068632724556845

Epoch: 6| Step: 12
Training loss: 0.4033388960207764
Validation loss: 2.134373782111953

Epoch: 6| Step: 13
Training loss: 0.46936493909798865
Validation loss: 2.084653692740612

Epoch: 793| Step: 0
Training loss: 0.4844373386015148
Validation loss: 2.117814088646341

Epoch: 6| Step: 1
Training loss: 0.3552657375581305
Validation loss: 2.055138415457634

Epoch: 6| Step: 2
Training loss: 0.45638957175001676
Validation loss: 2.100085079698308

Epoch: 6| Step: 3
Training loss: 0.5655291375968517
Validation loss: 2.134563419843515

Epoch: 6| Step: 4
Training loss: 0.3669838645035938
Validation loss: 2.121298689334952

Epoch: 6| Step: 5
Training loss: 0.6114438224729971
Validation loss: 2.1596256445492292

Epoch: 6| Step: 6
Training loss: 0.4365840929462494
Validation loss: 2.1012342319906008

Epoch: 6| Step: 7
Training loss: 0.6006963860903642
Validation loss: 2.1684849940448805

Epoch: 6| Step: 8
Training loss: 0.40903916597659196
Validation loss: 2.114593226588834

Epoch: 6| Step: 9
Training loss: 0.40064116292119734
Validation loss: 2.123403541857042

Epoch: 6| Step: 10
Training loss: 0.5280344078419708
Validation loss: 2.0967117706714027

Epoch: 6| Step: 11
Training loss: 1.328431621386852
Validation loss: 2.0630161606565625

Epoch: 6| Step: 12
Training loss: 0.3008131158966284
Validation loss: 2.0287325104685845

Epoch: 6| Step: 13
Training loss: 0.45320039976839716
Validation loss: 2.0560727655189583

Epoch: 794| Step: 0
Training loss: 0.5690185290237705
Validation loss: 2.1212468877330304

Epoch: 6| Step: 1
Training loss: 0.4697085117353398
Validation loss: 2.0723003754011007

Epoch: 6| Step: 2
Training loss: 0.4134793043158311
Validation loss: 2.140806415134937

Epoch: 6| Step: 3
Training loss: 0.36895177945577573
Validation loss: 2.0981158490926393

Epoch: 6| Step: 4
Training loss: 0.4568133527596683
Validation loss: 2.1450495588266167

Epoch: 6| Step: 5
Training loss: 0.3797971339555045
Validation loss: 2.076148366894856

Epoch: 6| Step: 6
Training loss: 0.3050163646122523
Validation loss: 2.0506848915694467

Epoch: 6| Step: 7
Training loss: 0.4356316796095811
Validation loss: 2.115975856820177

Epoch: 6| Step: 8
Training loss: 0.5442060465484131
Validation loss: 2.099289626556773

Epoch: 6| Step: 9
Training loss: 0.453746402452988
Validation loss: 2.085425042908445

Epoch: 6| Step: 10
Training loss: 0.44311457862490217
Validation loss: 2.097059345102743

Epoch: 6| Step: 11
Training loss: 1.3298021834121614
Validation loss: 2.1268603839160933

Epoch: 6| Step: 12
Training loss: 0.656134458997309
Validation loss: 2.0465249823234295

Epoch: 6| Step: 13
Training loss: 0.2743967396980369
Validation loss: 2.08021006631979

Epoch: 795| Step: 0
Training loss: 0.38485519218703984
Validation loss: 2.1651415588529677

Epoch: 6| Step: 1
Training loss: 0.46556109687551744
Validation loss: 2.0617794370425853

Epoch: 6| Step: 2
Training loss: 0.6618833352951813
Validation loss: 2.116404082054909

Epoch: 6| Step: 3
Training loss: 0.29991659753503097
Validation loss: 2.0476341878029207

Epoch: 6| Step: 4
Training loss: 0.44382731073160786
Validation loss: 2.0652836218348174

Epoch: 6| Step: 5
Training loss: 1.2504319875037664
Validation loss: 2.1057700370939374

Epoch: 6| Step: 6
Training loss: 0.7021958463789896
Validation loss: 2.0495991461751784

Epoch: 6| Step: 7
Training loss: 0.273533804146892
Validation loss: 2.0807234615028145

Epoch: 6| Step: 8
Training loss: 0.4769554706737627
Validation loss: 2.148773453474637

Epoch: 6| Step: 9
Training loss: 0.46554951023841773
Validation loss: 2.1259459628535775

Epoch: 6| Step: 10
Training loss: 0.5514164501618484
Validation loss: 2.0978996261092147

Epoch: 6| Step: 11
Training loss: 0.5471902755937054
Validation loss: 2.1451245820092617

Epoch: 6| Step: 12
Training loss: 0.4166745801015244
Validation loss: 2.075208402472947

Epoch: 6| Step: 13
Training loss: 0.339696764674879
Validation loss: 2.1520482244108408

Epoch: 796| Step: 0
Training loss: 0.5519684246126849
Validation loss: 2.076151053831157

Epoch: 6| Step: 1
Training loss: 0.42067193754272425
Validation loss: 2.0764233807438

Epoch: 6| Step: 2
Training loss: 0.42529540384254616
Validation loss: 2.0526940154550766

Epoch: 6| Step: 3
Training loss: 0.34176849247391317
Validation loss: 2.0527858761039095

Epoch: 6| Step: 4
Training loss: 0.4689717086360078
Validation loss: 2.000786645194764

Epoch: 6| Step: 5
Training loss: 0.5181990731349917
Validation loss: 2.137852204004261

Epoch: 6| Step: 6
Training loss: 0.34702273307286857
Validation loss: 2.0962333651017575

Epoch: 6| Step: 7
Training loss: 0.36593788648628917
Validation loss: 2.032422159010565

Epoch: 6| Step: 8
Training loss: 0.47853527418004127
Validation loss: 2.06237323230953

Epoch: 6| Step: 9
Training loss: 0.28412605382536754
Validation loss: 2.112198120346052

Epoch: 6| Step: 10
Training loss: 0.5732792025155502
Validation loss: 2.112948703362553

Epoch: 6| Step: 11
Training loss: 0.5210782873784908
Validation loss: 2.093264782362304

Epoch: 6| Step: 12
Training loss: 1.3296135582631976
Validation loss: 2.114557220509511

Epoch: 6| Step: 13
Training loss: 0.5003440388561985
Validation loss: 2.0685530210344463

Epoch: 797| Step: 0
Training loss: 0.37914697138318587
Validation loss: 2.122787232542789

Epoch: 6| Step: 1
Training loss: 0.37814204831744297
Validation loss: 2.0901892009190015

Epoch: 6| Step: 2
Training loss: 1.2524847130975167
Validation loss: 2.113990803321278

Epoch: 6| Step: 3
Training loss: 0.3659993285110442
Validation loss: 2.0940976002040146

Epoch: 6| Step: 4
Training loss: 0.3892322124172896
Validation loss: 2.0796123175076073

Epoch: 6| Step: 5
Training loss: 0.5838487652662908
Validation loss: 2.1172826178232547

Epoch: 6| Step: 6
Training loss: 0.5021510346329546
Validation loss: 2.128067497731921

Epoch: 6| Step: 7
Training loss: 0.4662956515608263
Validation loss: 2.1148599990923636

Epoch: 6| Step: 8
Training loss: 0.4459302198300962
Validation loss: 2.090223997980923

Epoch: 6| Step: 9
Training loss: 0.4399477739116729
Validation loss: 2.141579110192972

Epoch: 6| Step: 10
Training loss: 0.2770355016013136
Validation loss: 2.113073715668503

Epoch: 6| Step: 11
Training loss: 0.3584577630858183
Validation loss: 2.0929554334768827

Epoch: 6| Step: 12
Training loss: 0.6242673871663279
Validation loss: 2.0821261475993382

Epoch: 6| Step: 13
Training loss: 0.23336510041106132
Validation loss: 2.1567796832646478

Epoch: 798| Step: 0
Training loss: 0.47956247843922917
Validation loss: 2.0851629377744496

Epoch: 6| Step: 1
Training loss: 0.48493591256317564
Validation loss: 2.0872109814160242

Epoch: 6| Step: 2
Training loss: 0.5306343550469603
Validation loss: 2.0673348948782286

Epoch: 6| Step: 3
Training loss: 1.2648682392240136
Validation loss: 2.1280437702197497

Epoch: 6| Step: 4
Training loss: 0.31093353815286345
Validation loss: 2.190299907544292

Epoch: 6| Step: 5
Training loss: 0.48701318496229434
Validation loss: 2.117703417061344

Epoch: 6| Step: 6
Training loss: 0.35286206482648913
Validation loss: 2.0959766653129215

Epoch: 6| Step: 7
Training loss: 0.5146219438541333
Validation loss: 2.0864914622515607

Epoch: 6| Step: 8
Training loss: 0.31688974667832703
Validation loss: 2.0638986446085434

Epoch: 6| Step: 9
Training loss: 0.44422379640120657
Validation loss: 2.137110891080772

Epoch: 6| Step: 10
Training loss: 0.5533850516523765
Validation loss: 2.0663499917348336

Epoch: 6| Step: 11
Training loss: 0.4550163325323279
Validation loss: 2.0998062979328846

Epoch: 6| Step: 12
Training loss: 0.5981081581734161
Validation loss: 2.033170322744138

Epoch: 6| Step: 13
Training loss: 0.3760331346630571
Validation loss: 2.0433107473869625

Epoch: 799| Step: 0
Training loss: 1.302923963668847
Validation loss: 2.115162181647718

Epoch: 6| Step: 1
Training loss: 0.5101524434670571
Validation loss: 2.1359814256953777

Epoch: 6| Step: 2
Training loss: 0.5050943842584571
Validation loss: 2.095331651599593

Epoch: 6| Step: 3
Training loss: 0.49019399225852267
Validation loss: 2.0978210803654083

Epoch: 6| Step: 4
Training loss: 0.37238876851811975
Validation loss: 2.2037714575058835

Epoch: 6| Step: 5
Training loss: 0.28700886478673
Validation loss: 2.2181847334809692

Epoch: 6| Step: 6
Training loss: 0.4723670484555481
Validation loss: 2.028670879901651

Epoch: 6| Step: 7
Training loss: 0.5015198139790981
Validation loss: 2.1001145809164616

Epoch: 6| Step: 8
Training loss: 0.4294545322372256
Validation loss: 2.150484282565

Epoch: 6| Step: 9
Training loss: 0.3455760636098925
Validation loss: 2.0746052514407123

Epoch: 6| Step: 10
Training loss: 0.6580878363365847
Validation loss: 2.1068625937745646

Epoch: 6| Step: 11
Training loss: 0.5126036934507072
Validation loss: 2.103382804855262

Epoch: 6| Step: 12
Training loss: 0.4822263437226588
Validation loss: 2.1423349349698153

Epoch: 6| Step: 13
Training loss: 0.41505654690882987
Validation loss: 2.1377839451611216

Epoch: 800| Step: 0
Training loss: 0.32762136863986874
Validation loss: 2.0777877723978513

Epoch: 6| Step: 1
Training loss: 1.2541727038435673
Validation loss: 2.073255611302008

Epoch: 6| Step: 2
Training loss: 0.6152165001588615
Validation loss: 2.141299434986503

Epoch: 6| Step: 3
Training loss: 0.4182769850982644
Validation loss: 2.0787842332764193

Epoch: 6| Step: 4
Training loss: 0.3656404247453737
Validation loss: 2.1080397985905646

Epoch: 6| Step: 5
Training loss: 0.38370804259093527
Validation loss: 2.038615000562919

Epoch: 6| Step: 6
Training loss: 0.5746269850946591
Validation loss: 2.15234772288558

Epoch: 6| Step: 7
Training loss: 0.4627193021211301
Validation loss: 2.1042671601981917

Epoch: 6| Step: 8
Training loss: 0.4236222571416167
Validation loss: 2.1097800950164363

Epoch: 6| Step: 9
Training loss: 0.6118142142412598
Validation loss: 2.169645706763948

Epoch: 6| Step: 10
Training loss: 0.3253928263430646
Validation loss: 2.062046342330464

Epoch: 6| Step: 11
Training loss: 0.365977199984258
Validation loss: 2.1408121212703737

Epoch: 6| Step: 12
Training loss: 0.41387737382250084
Validation loss: 2.097367014884149

Epoch: 6| Step: 13
Training loss: 0.18429879496804505
Validation loss: 2.0908876057169103

Testing loss: 2.855297627491425
