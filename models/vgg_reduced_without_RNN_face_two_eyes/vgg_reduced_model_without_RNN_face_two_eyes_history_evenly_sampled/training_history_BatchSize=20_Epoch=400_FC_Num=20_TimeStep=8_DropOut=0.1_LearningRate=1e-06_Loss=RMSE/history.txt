Epoch: 1| Step: 0
Training loss: 4.935610832280005
Validation loss: 5.639758822575337

Epoch: 5| Step: 1
Training loss: 6.010713549002652
Validation loss: 5.635998037999695

Epoch: 5| Step: 2
Training loss: 5.971404279345254
Validation loss: 5.631678134787681

Epoch: 5| Step: 3
Training loss: 6.224427052063896
Validation loss: 5.6279109263773375

Epoch: 5| Step: 4
Training loss: 5.7461724188403025
Validation loss: 5.624458407235351

Epoch: 5| Step: 5
Training loss: 4.22624501500799
Validation loss: 5.618948817480082

Epoch: 5| Step: 6
Training loss: 5.70547161162293
Validation loss: 5.61445532449329

Epoch: 5| Step: 7
Training loss: 6.104582719218509
Validation loss: 5.608267073340511

Epoch: 5| Step: 8
Training loss: 6.079034340115277
Validation loss: 5.6041060288611595

Epoch: 5| Step: 9
Training loss: 5.865841808996713
Validation loss: 5.601747316833961

Epoch: 5| Step: 10
Training loss: 4.971709515630665
Validation loss: 5.597868858924098

Epoch: 2| Step: 0
Training loss: 5.480051972358563
Validation loss: 5.592122841129292

Epoch: 5| Step: 1
Training loss: 6.281197163373856
Validation loss: 5.587123953610999

Epoch: 5| Step: 2
Training loss: 5.627055491953272
Validation loss: 5.581649417367671

Epoch: 5| Step: 3
Training loss: 5.04191662297506
Validation loss: 5.5777973076382965

Epoch: 5| Step: 4
Training loss: 5.255434765457051
Validation loss: 5.573800674016527

Epoch: 5| Step: 5
Training loss: 5.553786407220866
Validation loss: 5.569542245278341

Epoch: 5| Step: 6
Training loss: 4.476167511615379
Validation loss: 5.562942511247075

Epoch: 5| Step: 7
Training loss: 6.8404354621626045
Validation loss: 5.5597697008794

Epoch: 5| Step: 8
Training loss: 5.966246074720778
Validation loss: 5.554826235258439

Epoch: 5| Step: 9
Training loss: 5.335186437693736
Validation loss: 5.549852975045137

Epoch: 5| Step: 10
Training loss: 5.535130922721254
Validation loss: 5.546061402614283

Epoch: 3| Step: 0
Training loss: 5.023473000883013
Validation loss: 5.540847074990992

Epoch: 5| Step: 1
Training loss: 5.273001464901422
Validation loss: 5.536422481028542

Epoch: 5| Step: 2
Training loss: 5.35604942061947
Validation loss: 5.531244530897274

Epoch: 5| Step: 3
Training loss: 6.483582524051916
Validation loss: 5.525519801428661

Epoch: 5| Step: 4
Training loss: 4.877351829354693
Validation loss: 5.518855568798844

Epoch: 5| Step: 5
Training loss: 5.510966551757933
Validation loss: 5.5152513396689695

Epoch: 5| Step: 6
Training loss: 5.51235078017149
Validation loss: 5.509484835607134

Epoch: 5| Step: 7
Training loss: 5.385072363860459
Validation loss: 5.504250547995121

Epoch: 5| Step: 8
Training loss: 5.605650108673315
Validation loss: 5.500480903043153

Epoch: 5| Step: 9
Training loss: 6.492313829058209
Validation loss: 5.496554603457907

Epoch: 5| Step: 10
Training loss: 5.3913064277184795
Validation loss: 5.490886323056116

Epoch: 4| Step: 0
Training loss: 5.860622263083236
Validation loss: 5.484986742215471

Epoch: 5| Step: 1
Training loss: 5.5515045188755545
Validation loss: 5.48093932531094

Epoch: 5| Step: 2
Training loss: 6.164934413341377
Validation loss: 5.472791692752579

Epoch: 5| Step: 3
Training loss: 5.858132355210328
Validation loss: 5.468468503489861

Epoch: 5| Step: 4
Training loss: 5.692883971896887
Validation loss: 5.463185428012108

Epoch: 5| Step: 5
Training loss: 5.403033231151168
Validation loss: 5.458386391904184

Epoch: 5| Step: 6
Training loss: 5.223999124699238
Validation loss: 5.452662623621656

Epoch: 5| Step: 7
Training loss: 5.3207581007181135
Validation loss: 5.447565524070548

Epoch: 5| Step: 8
Training loss: 5.051003671750895
Validation loss: 5.4404502449157714

Epoch: 5| Step: 9
Training loss: 5.307517733515089
Validation loss: 5.433388845262187

Epoch: 5| Step: 10
Training loss: 4.92186318047936
Validation loss: 5.431617814970152

Epoch: 5| Step: 0
Training loss: 5.958506157064814
Validation loss: 5.423234282700869

Epoch: 5| Step: 1
Training loss: 5.127203304907891
Validation loss: 5.418521244934598

Epoch: 5| Step: 2
Training loss: 5.550443978636785
Validation loss: 5.410346888806208

Epoch: 5| Step: 3
Training loss: 5.2580022225010685
Validation loss: 5.4052539339130625

Epoch: 5| Step: 4
Training loss: 6.189825680547588
Validation loss: 5.400503514589393

Epoch: 5| Step: 5
Training loss: 5.092254419112396
Validation loss: 5.392038224232157

Epoch: 5| Step: 6
Training loss: 5.261122773876017
Validation loss: 5.386871620558848

Epoch: 5| Step: 7
Training loss: 5.55138873347176
Validation loss: 5.382278737635177

Epoch: 5| Step: 8
Training loss: 6.3606720522519336
Validation loss: 5.375424268403908

Epoch: 5| Step: 9
Training loss: 4.349824239753607
Validation loss: 5.367626204198991

Epoch: 5| Step: 10
Training loss: 4.753011050291115
Validation loss: 5.362771947047925

Epoch: 6| Step: 0
Training loss: 4.985286426025261
Validation loss: 5.354995819749215

Epoch: 5| Step: 1
Training loss: 5.410701088032686
Validation loss: 5.35062403703763

Epoch: 5| Step: 2
Training loss: 5.942560549031557
Validation loss: 5.345813402020089

Epoch: 5| Step: 3
Training loss: 5.296610507719385
Validation loss: 5.340723400728376

Epoch: 5| Step: 4
Training loss: 5.817586006738601
Validation loss: 5.33190774066503

Epoch: 5| Step: 5
Training loss: 4.919767382635399
Validation loss: 5.325834321798749

Epoch: 5| Step: 6
Training loss: 4.994597377187182
Validation loss: 5.318635624580417

Epoch: 5| Step: 7
Training loss: 6.001962976419673
Validation loss: 5.3142252215697185

Epoch: 5| Step: 8
Training loss: 5.140205528514032
Validation loss: 5.310306095581077

Epoch: 5| Step: 9
Training loss: 5.437679068587452
Validation loss: 5.300035518280343

Epoch: 5| Step: 10
Training loss: 4.970005284696106
Validation loss: 5.294041263676203

Epoch: 7| Step: 0
Training loss: 5.010468396126652
Validation loss: 5.2856337684139625

Epoch: 5| Step: 1
Training loss: 4.946238065044358
Validation loss: 5.2830393372099556

Epoch: 5| Step: 2
Training loss: 5.743954673333229
Validation loss: 5.271442928501655

Epoch: 5| Step: 3
Training loss: 5.2287242849193225
Validation loss: 5.267565607498802

Epoch: 5| Step: 4
Training loss: 5.758553155805909
Validation loss: 5.2613295013370704

Epoch: 5| Step: 5
Training loss: 4.895616805246157
Validation loss: 5.251273579386103

Epoch: 5| Step: 6
Training loss: 5.4629718009364785
Validation loss: 5.244886393447782

Epoch: 5| Step: 7
Training loss: 5.184569116859205
Validation loss: 5.237663874332532

Epoch: 5| Step: 8
Training loss: 5.573167152360882
Validation loss: 5.230479080094541

Epoch: 5| Step: 9
Training loss: 5.292030662372823
Validation loss: 5.222809233990278

Epoch: 5| Step: 10
Training loss: 5.111195091350048
Validation loss: 5.214863317788662

Epoch: 8| Step: 0
Training loss: 5.216531796077945
Validation loss: 5.205448090127092

Epoch: 5| Step: 1
Training loss: 5.403036761294197
Validation loss: 5.2029880716421655

Epoch: 5| Step: 2
Training loss: 4.806669790837458
Validation loss: 5.191911397427124

Epoch: 5| Step: 3
Training loss: 5.031621315090364
Validation loss: 5.183060944077067

Epoch: 5| Step: 4
Training loss: 5.503669554992982
Validation loss: 5.1763021819372685

Epoch: 5| Step: 5
Training loss: 5.394108893166949
Validation loss: 5.168646405689659

Epoch: 5| Step: 6
Training loss: 5.566814335370133
Validation loss: 5.162220036117595

Epoch: 5| Step: 7
Training loss: 5.6706514746519785
Validation loss: 5.1503978165815205

Epoch: 5| Step: 8
Training loss: 5.242812186256659
Validation loss: 5.14677136809845

Epoch: 5| Step: 9
Training loss: 4.996933950681227
Validation loss: 5.134616736173049

Epoch: 5| Step: 10
Training loss: 4.340301022615706
Validation loss: 5.125224789087383

Epoch: 9| Step: 0
Training loss: 5.604852665131096
Validation loss: 5.119323123507178

Epoch: 5| Step: 1
Training loss: 5.830425882111604
Validation loss: 5.108070602663853

Epoch: 5| Step: 2
Training loss: 5.273553781993424
Validation loss: 5.1015549581641215

Epoch: 5| Step: 3
Training loss: 5.013877492922826
Validation loss: 5.092861796415358

Epoch: 5| Step: 4
Training loss: 4.862537201491488
Validation loss: 5.085177511517552

Epoch: 5| Step: 5
Training loss: 5.2323101468917725
Validation loss: 5.07675281093287

Epoch: 5| Step: 6
Training loss: 4.8733920844659675
Validation loss: 5.064930619842507

Epoch: 5| Step: 7
Training loss: 4.295062206381818
Validation loss: 5.056402316184084

Epoch: 5| Step: 8
Training loss: 4.787208982541842
Validation loss: 5.048388698451427

Epoch: 5| Step: 9
Training loss: 5.196110760160945
Validation loss: 5.043892553716844

Epoch: 5| Step: 10
Training loss: 5.3672393840741845
Validation loss: 5.032540980864087

Epoch: 10| Step: 0
Training loss: 5.097898326986811
Validation loss: 5.018852633947752

Epoch: 5| Step: 1
Training loss: 4.448459684412434
Validation loss: 5.012703766423753

Epoch: 5| Step: 2
Training loss: 4.574535850785527
Validation loss: 5.004738336534231

Epoch: 5| Step: 3
Training loss: 4.825473884673911
Validation loss: 4.992899851577376

Epoch: 5| Step: 4
Training loss: 4.193545404437876
Validation loss: 4.984918417187581

Epoch: 5| Step: 5
Training loss: 5.743097225449592
Validation loss: 4.9731253555012485

Epoch: 5| Step: 6
Training loss: 5.096412758416491
Validation loss: 4.963828536489088

Epoch: 5| Step: 7
Training loss: 5.114019773347333
Validation loss: 4.951557814540924

Epoch: 5| Step: 8
Training loss: 5.4997175317535305
Validation loss: 4.9446982886639175

Epoch: 5| Step: 9
Training loss: 4.707436040037605
Validation loss: 4.937547232029549

Epoch: 5| Step: 10
Training loss: 5.881253749023281
Validation loss: 4.924346316935622

Epoch: 11| Step: 0
Training loss: 5.856363809593159
Validation loss: 4.913442019688059

Epoch: 5| Step: 1
Training loss: 4.978499917222179
Validation loss: 4.898680694635509

Epoch: 5| Step: 2
Training loss: 4.4359820281370705
Validation loss: 4.891055068320534

Epoch: 5| Step: 3
Training loss: 4.358867437970198
Validation loss: 4.878582597454959

Epoch: 5| Step: 4
Training loss: 5.246830664805801
Validation loss: 4.8690499300235945

Epoch: 5| Step: 5
Training loss: 4.574392626525551
Validation loss: 4.855647173668013

Epoch: 5| Step: 6
Training loss: 5.437711514272449
Validation loss: 4.8458086321153955

Epoch: 5| Step: 7
Training loss: 4.850715796750489
Validation loss: 4.834163112225887

Epoch: 5| Step: 8
Training loss: 4.891860757039162
Validation loss: 4.822539070653401

Epoch: 5| Step: 9
Training loss: 4.8260707003255785
Validation loss: 4.811337317107484

Epoch: 5| Step: 10
Training loss: 4.392689284109282
Validation loss: 4.800432540690276

Epoch: 12| Step: 0
Training loss: 4.383015293046789
Validation loss: 4.789715552736913

Epoch: 5| Step: 1
Training loss: 4.282433562022272
Validation loss: 4.7749605709046445

Epoch: 5| Step: 2
Training loss: 4.7806475889390665
Validation loss: 4.765324568024435

Epoch: 5| Step: 3
Training loss: 4.911021251249541
Validation loss: 4.754362526308202

Epoch: 5| Step: 4
Training loss: 4.684570007133354
Validation loss: 4.7379895508773275

Epoch: 5| Step: 5
Training loss: 5.078279369648855
Validation loss: 4.728694187269825

Epoch: 5| Step: 6
Training loss: 4.614744207995131
Validation loss: 4.7178511746540535

Epoch: 5| Step: 7
Training loss: 6.297110957796037
Validation loss: 4.7000156271418785

Epoch: 5| Step: 8
Training loss: 4.389618347540085
Validation loss: 4.694817726949381

Epoch: 5| Step: 9
Training loss: 4.236690999903357
Validation loss: 4.67993134940376

Epoch: 5| Step: 10
Training loss: 4.736292082659255
Validation loss: 4.6618242358618724

Epoch: 13| Step: 0
Training loss: 4.618942211317355
Validation loss: 4.651439805374547

Epoch: 5| Step: 1
Training loss: 5.445964495074882
Validation loss: 4.635858561667233

Epoch: 5| Step: 2
Training loss: 4.061984924528845
Validation loss: 4.626553457213844

Epoch: 5| Step: 3
Training loss: 4.891636947896818
Validation loss: 4.613470760564976

Epoch: 5| Step: 4
Training loss: 4.500783640128033
Validation loss: 4.598024258400495

Epoch: 5| Step: 5
Training loss: 5.22221597486262
Validation loss: 4.581896876578236

Epoch: 5| Step: 6
Training loss: 3.985374774038017
Validation loss: 4.5625545573178945

Epoch: 5| Step: 7
Training loss: 4.004172533066045
Validation loss: 4.556971622696741

Epoch: 5| Step: 8
Training loss: 4.212552640229449
Validation loss: 4.538412435192477

Epoch: 5| Step: 9
Training loss: 5.339185583467028
Validation loss: 4.529087470276421

Epoch: 5| Step: 10
Training loss: 4.6050601742402915
Validation loss: 4.505703509923271

Epoch: 14| Step: 0
Training loss: 4.727519999219208
Validation loss: 4.497841856446915

Epoch: 5| Step: 1
Training loss: 3.6597326923166706
Validation loss: 4.480004979883816

Epoch: 5| Step: 2
Training loss: 4.282590336066744
Validation loss: 4.460185511031852

Epoch: 5| Step: 3
Training loss: 4.838073554524997
Validation loss: 4.448815638227577

Epoch: 5| Step: 4
Training loss: 4.128742947412162
Validation loss: 4.431351999840206

Epoch: 5| Step: 5
Training loss: 4.574819784315002
Validation loss: 4.41804913372367

Epoch: 5| Step: 6
Training loss: 4.681023357695726
Validation loss: 4.407112362430969

Epoch: 5| Step: 7
Training loss: 4.928976306910192
Validation loss: 4.385762079342533

Epoch: 5| Step: 8
Training loss: 3.7224826832324327
Validation loss: 4.3705654657693485

Epoch: 5| Step: 9
Training loss: 5.4588107223051
Validation loss: 4.348991945178713

Epoch: 5| Step: 10
Training loss: 3.989371125609178
Validation loss: 4.337814623297247

Epoch: 15| Step: 0
Training loss: 4.4624657894073385
Validation loss: 4.318695607819403

Epoch: 5| Step: 1
Training loss: 3.079805331828297
Validation loss: 4.2994993069529945

Epoch: 5| Step: 2
Training loss: 5.04567475115648
Validation loss: 4.2867920133301896

Epoch: 5| Step: 3
Training loss: 4.551209366597893
Validation loss: 4.265146673339416

Epoch: 5| Step: 4
Training loss: 4.568378580549625
Validation loss: 4.24480913486909

Epoch: 5| Step: 5
Training loss: 3.04144617265652
Validation loss: 4.233990315495039

Epoch: 5| Step: 6
Training loss: 4.705506187719449
Validation loss: 4.214101011389156

Epoch: 5| Step: 7
Training loss: 4.3434520591811845
Validation loss: 4.1971375431874085

Epoch: 5| Step: 8
Training loss: 4.662493520123681
Validation loss: 4.172469980907063

Epoch: 5| Step: 9
Training loss: 4.131121168566107
Validation loss: 4.161747459343505

Epoch: 5| Step: 10
Training loss: 4.381341752031642
Validation loss: 4.144902622882048

Epoch: 16| Step: 0
Training loss: 4.0862280776963615
Validation loss: 4.122205279127442

Epoch: 5| Step: 1
Training loss: 4.221654725557998
Validation loss: 4.098441060038534

Epoch: 5| Step: 2
Training loss: 4.658325961430721
Validation loss: 4.083662730917522

Epoch: 5| Step: 3
Training loss: 3.682805580776805
Validation loss: 4.065109989624852

Epoch: 5| Step: 4
Training loss: 4.489271726953909
Validation loss: 4.048775485796889

Epoch: 5| Step: 5
Training loss: 3.6987983762846226
Validation loss: 4.028525036036869

Epoch: 5| Step: 6
Training loss: 3.427993390765768
Validation loss: 4.0056376631224

Epoch: 5| Step: 7
Training loss: 4.223765690648224
Validation loss: 3.9869710849647286

Epoch: 5| Step: 8
Training loss: 4.307921259423456
Validation loss: 3.9637960712611293

Epoch: 5| Step: 9
Training loss: 3.3623504945779628
Validation loss: 3.9405417516288646

Epoch: 5| Step: 10
Training loss: 4.960315959772761
Validation loss: 3.9238383029029946

Epoch: 17| Step: 0
Training loss: 4.4216364604111345
Validation loss: 3.902159642282806

Epoch: 5| Step: 1
Training loss: 3.5627485489724875
Validation loss: 3.8734076169163485

Epoch: 5| Step: 2
Training loss: 3.7185930491432804
Validation loss: 3.8625604639850626

Epoch: 5| Step: 3
Training loss: 3.3557020823449304
Validation loss: 3.830229045760123

Epoch: 5| Step: 4
Training loss: 4.1786364223097365
Validation loss: 3.8177680339503697

Epoch: 5| Step: 5
Training loss: 4.269881252451194
Validation loss: 3.7943864542769785

Epoch: 5| Step: 6
Training loss: 3.6014637302583252
Validation loss: 3.781745912702308

Epoch: 5| Step: 7
Training loss: 4.025177869953777
Validation loss: 3.740346226047489

Epoch: 5| Step: 8
Training loss: 4.4419861803247755
Validation loss: 3.7246702984978834

Epoch: 5| Step: 9
Training loss: 3.4645032575616486
Validation loss: 3.704531865732447

Epoch: 5| Step: 10
Training loss: 3.5843046040095046
Validation loss: 3.682542387203765

Epoch: 18| Step: 0
Training loss: 3.9269121505434694
Validation loss: 3.6584764265968124

Epoch: 5| Step: 1
Training loss: 3.5446434226898695
Validation loss: 3.641003803022078

Epoch: 5| Step: 2
Training loss: 3.690450877734215
Validation loss: 3.615645039426539

Epoch: 5| Step: 3
Training loss: 3.9050503528977694
Validation loss: 3.5922443219345035

Epoch: 5| Step: 4
Training loss: 3.4612419735039484
Validation loss: 3.568865875781778

Epoch: 5| Step: 5
Training loss: 3.8908361661051942
Validation loss: 3.552618842637925

Epoch: 5| Step: 6
Training loss: 3.7773339035710602
Validation loss: 3.534711189289602

Epoch: 5| Step: 7
Training loss: 3.7150532275323376
Validation loss: 3.50348715359231

Epoch: 5| Step: 8
Training loss: 3.7531375475061513
Validation loss: 3.4808125607896576

Epoch: 5| Step: 9
Training loss: 3.722848252811865
Validation loss: 3.4529552181334213

Epoch: 5| Step: 10
Training loss: 2.7238061301972105
Validation loss: 3.435186437985999

Epoch: 19| Step: 0
Training loss: 3.620247981814105
Validation loss: 3.416798495779006

Epoch: 5| Step: 1
Training loss: 3.227646763284365
Validation loss: 3.4022758340255104

Epoch: 5| Step: 2
Training loss: 3.000621413403755
Validation loss: 3.371668272143711

Epoch: 5| Step: 3
Training loss: 4.419653452410528
Validation loss: 3.344003760701003

Epoch: 5| Step: 4
Training loss: 3.2765697706557537
Validation loss: 3.32636014955754

Epoch: 5| Step: 5
Training loss: 3.1489714744731967
Validation loss: 3.315315670510568

Epoch: 5| Step: 6
Training loss: 3.92412548163196
Validation loss: 3.2807971538336367

Epoch: 5| Step: 7
Training loss: 3.45241957143346
Validation loss: 3.263282152531003

Epoch: 5| Step: 8
Training loss: 2.933317412708889
Validation loss: 3.236293249843218

Epoch: 5| Step: 9
Training loss: 3.6335267380034693
Validation loss: 3.219300577122472

Epoch: 5| Step: 10
Training loss: 2.967113806927823
Validation loss: 3.1958353117493496

Epoch: 20| Step: 0
Training loss: 4.01005268509423
Validation loss: 3.180203356881935

Epoch: 5| Step: 1
Training loss: 4.31027429615061
Validation loss: 3.150913981114551

Epoch: 5| Step: 2
Training loss: 2.8354730567304527
Validation loss: 3.1327065045934868

Epoch: 5| Step: 3
Training loss: 2.638848423787002
Validation loss: 3.119469734994503

Epoch: 5| Step: 4
Training loss: 2.481660043192219
Validation loss: 3.0906987528038394

Epoch: 5| Step: 5
Training loss: 2.8383660965031132
Validation loss: 3.0783084514680605

Epoch: 5| Step: 6
Training loss: 2.9177304825537336
Validation loss: 3.061279190834038

Epoch: 5| Step: 7
Training loss: 3.834469640631773
Validation loss: 3.044933341355299

Epoch: 5| Step: 8
Training loss: 2.6793221538823335
Validation loss: 3.0300265872037535

Epoch: 5| Step: 9
Training loss: 3.3642494500531046
Validation loss: 3.005971549798687

Epoch: 5| Step: 10
Training loss: 3.109604103427591
Validation loss: 2.986880943829843

Epoch: 21| Step: 0
Training loss: 2.7673054562828447
Validation loss: 2.9652648650059823

Epoch: 5| Step: 1
Training loss: 3.3344826306433957
Validation loss: 2.954866726348377

Epoch: 5| Step: 2
Training loss: 3.4818733027160813
Validation loss: 2.9386129092894384

Epoch: 5| Step: 3
Training loss: 2.8173036878241384
Validation loss: 2.9334184649867825

Epoch: 5| Step: 4
Training loss: 3.4164093820106984
Validation loss: 2.908394264095129

Epoch: 5| Step: 5
Training loss: 3.526968732227485
Validation loss: 2.904880628454001

Epoch: 5| Step: 6
Training loss: 3.1648695681725845
Validation loss: 2.8845886811166026

Epoch: 5| Step: 7
Training loss: 2.6897181738381613
Validation loss: 2.860659386993555

Epoch: 5| Step: 8
Training loss: 2.8844703931315605
Validation loss: 2.8544774189832567

Epoch: 5| Step: 9
Training loss: 2.7817903486685176
Validation loss: 2.83482747128686

Epoch: 5| Step: 10
Training loss: 2.876970362304098
Validation loss: 2.8382340405166335

Epoch: 22| Step: 0
Training loss: 3.3262249174609475
Validation loss: 2.8187925253637225

Epoch: 5| Step: 1
Training loss: 2.645239956216516
Validation loss: 2.8089600767034026

Epoch: 5| Step: 2
Training loss: 3.019726745672574
Validation loss: 2.80705814911215

Epoch: 5| Step: 3
Training loss: 3.2920879303694455
Validation loss: 2.787530167600943

Epoch: 5| Step: 4
Training loss: 2.78907275799059
Validation loss: 2.792182033306294

Epoch: 5| Step: 5
Training loss: 3.022771402168557
Validation loss: 2.7511227554055293

Epoch: 5| Step: 6
Training loss: 3.2817443475268475
Validation loss: 2.7703284513662525

Epoch: 5| Step: 7
Training loss: 2.7871990229538124
Validation loss: 2.7453500545868845

Epoch: 5| Step: 8
Training loss: 3.1664826356383697
Validation loss: 2.7384090938212293

Epoch: 5| Step: 9
Training loss: 2.8202403051376925
Validation loss: 2.731943187443667

Epoch: 5| Step: 10
Training loss: 2.5653903756326106
Validation loss: 2.7269672328818837

Epoch: 23| Step: 0
Training loss: 2.7726079855442793
Validation loss: 2.7177197846864996

Epoch: 5| Step: 1
Training loss: 2.516326806402271
Validation loss: 2.718827305572703

Epoch: 5| Step: 2
Training loss: 2.8852047802262377
Validation loss: 2.71367428889136

Epoch: 5| Step: 3
Training loss: 2.848377696302486
Validation loss: 2.69413580073086

Epoch: 5| Step: 4
Training loss: 3.309843041423914
Validation loss: 2.702065052262818

Epoch: 5| Step: 5
Training loss: 3.0446713034328132
Validation loss: 2.6896001799556806

Epoch: 5| Step: 6
Training loss: 3.164935709705621
Validation loss: 2.691453073979144

Epoch: 5| Step: 7
Training loss: 2.7969685970394282
Validation loss: 2.6732771837314937

Epoch: 5| Step: 8
Training loss: 3.015141739937621
Validation loss: 2.6626215301035083

Epoch: 5| Step: 9
Training loss: 3.0217998317770216
Validation loss: 2.666891129593785

Epoch: 5| Step: 10
Training loss: 2.5820344818141177
Validation loss: 2.6838938182043637

Epoch: 24| Step: 0
Training loss: 2.9255949605350207
Validation loss: 2.66691218163738

Epoch: 5| Step: 1
Training loss: 2.3024090382587468
Validation loss: 2.661600504089007

Epoch: 5| Step: 2
Training loss: 3.036589177465835
Validation loss: 2.661411395197947

Epoch: 5| Step: 3
Training loss: 2.4128240970470713
Validation loss: 2.660157630043912

Epoch: 5| Step: 4
Training loss: 2.558231427112873
Validation loss: 2.659574383984601

Epoch: 5| Step: 5
Training loss: 3.5312094897081763
Validation loss: 2.636424096346095

Epoch: 5| Step: 6
Training loss: 2.960904325032653
Validation loss: 2.6425749361853446

Epoch: 5| Step: 7
Training loss: 2.9723819400580083
Validation loss: 2.643873637324717

Epoch: 5| Step: 8
Training loss: 3.001925962842715
Validation loss: 2.6351249974735826

Epoch: 5| Step: 9
Training loss: 2.5989455615833847
Validation loss: 2.6480680650824215

Epoch: 5| Step: 10
Training loss: 3.341383907947138
Validation loss: 2.645082254914781

Epoch: 25| Step: 0
Training loss: 2.7145488331833003
Validation loss: 2.635767973157171

Epoch: 5| Step: 1
Training loss: 2.684886459990357
Validation loss: 2.6499237315029354

Epoch: 5| Step: 2
Training loss: 3.1160439901123715
Validation loss: 2.6362832463031407

Epoch: 5| Step: 3
Training loss: 3.6332622946931004
Validation loss: 2.640225034488882

Epoch: 5| Step: 4
Training loss: 2.4821526526231366
Validation loss: 2.6394761750167097

Epoch: 5| Step: 5
Training loss: 3.091581104530676
Validation loss: 2.6440130726925775

Epoch: 5| Step: 6
Training loss: 3.4459770409455186
Validation loss: 2.628724045128783

Epoch: 5| Step: 7
Training loss: 2.704803298595711
Validation loss: 2.6303971927709107

Epoch: 5| Step: 8
Training loss: 2.2967502274650675
Validation loss: 2.632968525392416

Epoch: 5| Step: 9
Training loss: 2.5744324104888707
Validation loss: 2.622681817346145

Epoch: 5| Step: 10
Training loss: 2.5934461852315613
Validation loss: 2.6283290455925266

Epoch: 26| Step: 0
Training loss: 2.428176459082591
Validation loss: 2.632568505812774

Epoch: 5| Step: 1
Training loss: 3.2145599944544165
Validation loss: 2.632573719625193

Epoch: 5| Step: 2
Training loss: 3.0368162350995425
Validation loss: 2.6204815018333307

Epoch: 5| Step: 3
Training loss: 2.6478895672707776
Validation loss: 2.6251754096627926

Epoch: 5| Step: 4
Training loss: 2.6457073351878506
Validation loss: 2.624539575664083

Epoch: 5| Step: 5
Training loss: 2.373250417261058
Validation loss: 2.6395259491552903

Epoch: 5| Step: 6
Training loss: 2.771464847122227
Validation loss: 2.625128046087765

Epoch: 5| Step: 7
Training loss: 3.2787742357307255
Validation loss: 2.6325035884065215

Epoch: 5| Step: 8
Training loss: 2.704909777308912
Validation loss: 2.6176142489586702

Epoch: 5| Step: 9
Training loss: 3.3182826400964447
Validation loss: 2.630805023521359

Epoch: 5| Step: 10
Training loss: 2.981032651899656
Validation loss: 2.6325141409293638

Epoch: 27| Step: 0
Training loss: 3.1883431609727304
Validation loss: 2.624198354616114

Epoch: 5| Step: 1
Training loss: 2.9363493593439505
Validation loss: 2.624754347784706

Epoch: 5| Step: 2
Training loss: 3.2244913690741055
Validation loss: 2.6346032740816168

Epoch: 5| Step: 3
Training loss: 2.3130110098728913
Validation loss: 2.6266558035056478

Epoch: 5| Step: 4
Training loss: 2.7830484983088617
Validation loss: 2.634411738705437

Epoch: 5| Step: 5
Training loss: 3.210927995728026
Validation loss: 2.631407724611063

Epoch: 5| Step: 6
Training loss: 2.784898914577781
Validation loss: 2.6114871352440785

Epoch: 5| Step: 7
Training loss: 3.0548674781638345
Validation loss: 2.628296634224525

Epoch: 5| Step: 8
Training loss: 2.6237329422322198
Validation loss: 2.632825208080498

Epoch: 5| Step: 9
Training loss: 2.9470491424595027
Validation loss: 2.6214202432504106

Epoch: 5| Step: 10
Training loss: 2.37994021540974
Validation loss: 2.632014124365835

Epoch: 28| Step: 0
Training loss: 3.1896477737412052
Validation loss: 2.6397904782853057

Epoch: 5| Step: 1
Training loss: 2.830323265942229
Validation loss: 2.6297438494153247

Epoch: 5| Step: 2
Training loss: 2.830703150335157
Validation loss: 2.6254559446638726

Epoch: 5| Step: 3
Training loss: 2.9831794620947574
Validation loss: 2.6151825484941056

Epoch: 5| Step: 4
Training loss: 2.476665410451797
Validation loss: 2.6372499760437553

Epoch: 5| Step: 5
Training loss: 2.825515639246138
Validation loss: 2.623939889978181

Epoch: 5| Step: 6
Training loss: 3.0257947145808086
Validation loss: 2.622047313580842

Epoch: 5| Step: 7
Training loss: 3.110233054306318
Validation loss: 2.618146214038379

Epoch: 5| Step: 8
Training loss: 2.476438116084844
Validation loss: 2.627221099998105

Epoch: 5| Step: 9
Training loss: 2.894764508566905
Validation loss: 2.6319320159213744

Epoch: 5| Step: 10
Training loss: 2.8637128767440507
Validation loss: 2.6173971695497262

Epoch: 29| Step: 0
Training loss: 2.7381458548296065
Validation loss: 2.6296394697105008

Epoch: 5| Step: 1
Training loss: 2.8352408065653574
Validation loss: 2.6233520081110466

Epoch: 5| Step: 2
Training loss: 3.0113210056748767
Validation loss: 2.6342123409658194

Epoch: 5| Step: 3
Training loss: 2.815371763842235
Validation loss: 2.6283643602535434

Epoch: 5| Step: 4
Training loss: 2.577913865200469
Validation loss: 2.6226123121237923

Epoch: 5| Step: 5
Training loss: 3.125468562284011
Validation loss: 2.6215785983357383

Epoch: 5| Step: 6
Training loss: 2.7450521346736596
Validation loss: 2.609335899244284

Epoch: 5| Step: 7
Training loss: 2.7695284952384043
Validation loss: 2.618190275861059

Epoch: 5| Step: 8
Training loss: 2.5467800754573573
Validation loss: 2.623253693141888

Epoch: 5| Step: 9
Training loss: 3.382331373433767
Validation loss: 2.6266197914416245

Epoch: 5| Step: 10
Training loss: 2.854939005879972
Validation loss: 2.6308614505774526

Epoch: 30| Step: 0
Training loss: 2.7528987691982736
Validation loss: 2.615686011940989

Epoch: 5| Step: 1
Training loss: 3.175519080795314
Validation loss: 2.623643682936087

Epoch: 5| Step: 2
Training loss: 2.873509227859339
Validation loss: 2.617509477621332

Epoch: 5| Step: 3
Training loss: 2.0284721747434684
Validation loss: 2.6163269244351164

Epoch: 5| Step: 4
Training loss: 3.63883528698244
Validation loss: 2.63150898587827

Epoch: 5| Step: 5
Training loss: 3.073644019646595
Validation loss: 2.634630430243924

Epoch: 5| Step: 6
Training loss: 2.8247686038152042
Validation loss: 2.6186731173959643

Epoch: 5| Step: 7
Training loss: 2.513472020785925
Validation loss: 2.6196968265151495

Epoch: 5| Step: 8
Training loss: 2.833475689023226
Validation loss: 2.6473978823631965

Epoch: 5| Step: 9
Training loss: 2.6841489614546044
Validation loss: 2.6172866285808585

Epoch: 5| Step: 10
Training loss: 2.6926415519377396
Validation loss: 2.622062415474319

Epoch: 31| Step: 0
Training loss: 2.7655999134025087
Validation loss: 2.617723131292026

Epoch: 5| Step: 1
Training loss: 2.8575733950342923
Validation loss: 2.622276639165875

Epoch: 5| Step: 2
Training loss: 2.9342831793283444
Validation loss: 2.6106456629600476

Epoch: 5| Step: 3
Training loss: 2.743767090485684
Validation loss: 2.6233022544716786

Epoch: 5| Step: 4
Training loss: 3.158999161669749
Validation loss: 2.6217539631154234

Epoch: 5| Step: 5
Training loss: 3.1273608635827967
Validation loss: 2.604486214177787

Epoch: 5| Step: 6
Training loss: 2.676341467358443
Validation loss: 2.6135875644332964

Epoch: 5| Step: 7
Training loss: 2.3446491805418725
Validation loss: 2.6240520992541216

Epoch: 5| Step: 8
Training loss: 2.5937438413248137
Validation loss: 2.61114241377564

Epoch: 5| Step: 9
Training loss: 3.0099758542635375
Validation loss: 2.6227975894756153

Epoch: 5| Step: 10
Training loss: 3.180793288747281
Validation loss: 2.6170096447012883

Epoch: 32| Step: 0
Training loss: 2.899137592336189
Validation loss: 2.619481302081348

Epoch: 5| Step: 1
Training loss: 2.915836561240646
Validation loss: 2.6133821885074413

Epoch: 5| Step: 2
Training loss: 3.6218626981564164
Validation loss: 2.61239982578176

Epoch: 5| Step: 3
Training loss: 2.549590085311538
Validation loss: 2.6225555824542637

Epoch: 5| Step: 4
Training loss: 2.7423472127022626
Validation loss: 2.6102503977801805

Epoch: 5| Step: 5
Training loss: 3.051939525840046
Validation loss: 2.618948747750044

Epoch: 5| Step: 6
Training loss: 2.637740416213547
Validation loss: 2.6051132142338793

Epoch: 5| Step: 7
Training loss: 2.4853533851601863
Validation loss: 2.6225607985773913

Epoch: 5| Step: 8
Training loss: 2.8245997930297473
Validation loss: 2.6175476453330564

Epoch: 5| Step: 9
Training loss: 2.341375750552106
Validation loss: 2.6260447261675153

Epoch: 5| Step: 10
Training loss: 3.153330595272023
Validation loss: 2.6201626466400976

Epoch: 33| Step: 0
Training loss: 2.6719706557255813
Validation loss: 2.603169608604584

Epoch: 5| Step: 1
Training loss: 2.503476872280374
Validation loss: 2.620225401285447

Epoch: 5| Step: 2
Training loss: 3.4637401246694473
Validation loss: 2.6257621315058373

Epoch: 5| Step: 3
Training loss: 2.8634424515502044
Validation loss: 2.6240022269946577

Epoch: 5| Step: 4
Training loss: 3.04864732107229
Validation loss: 2.6221892861304186

Epoch: 5| Step: 5
Training loss: 2.687327978262096
Validation loss: 2.6173259362389705

Epoch: 5| Step: 6
Training loss: 2.6377893153603083
Validation loss: 2.6233060599078906

Epoch: 5| Step: 7
Training loss: 3.0753407545393667
Validation loss: 2.6279346159044423

Epoch: 5| Step: 8
Training loss: 3.3442937105865056
Validation loss: 2.6093640503147957

Epoch: 5| Step: 9
Training loss: 2.536221085144336
Validation loss: 2.609713292668501

Epoch: 5| Step: 10
Training loss: 2.126677468111995
Validation loss: 2.624366095785739

Epoch: 34| Step: 0
Training loss: 2.6815903027529853
Validation loss: 2.6297450952902626

Epoch: 5| Step: 1
Training loss: 2.8630958903060515
Validation loss: 2.612509962666313

Epoch: 5| Step: 2
Training loss: 2.628057697173727
Validation loss: 2.620118326409765

Epoch: 5| Step: 3
Training loss: 2.3677451103320264
Validation loss: 2.6112321946508668

Epoch: 5| Step: 4
Training loss: 2.848592136054717
Validation loss: 2.6207640359375493

Epoch: 5| Step: 5
Training loss: 2.882027702711967
Validation loss: 2.621025661021018

Epoch: 5| Step: 6
Training loss: 3.161211099441854
Validation loss: 2.608368178602084

Epoch: 5| Step: 7
Training loss: 2.427103121653645
Validation loss: 2.6126711440832033

Epoch: 5| Step: 8
Training loss: 2.910861223074291
Validation loss: 2.612476383547405

Epoch: 5| Step: 9
Training loss: 3.26794905760338
Validation loss: 2.6225683881353166

Epoch: 5| Step: 10
Training loss: 3.217118525680452
Validation loss: 2.608766465792369

Epoch: 35| Step: 0
Training loss: 3.1134567689897614
Validation loss: 2.6183063004421196

Epoch: 5| Step: 1
Training loss: 2.4423201414515345
Validation loss: 2.6149355053848637

Epoch: 5| Step: 2
Training loss: 3.2726784784359393
Validation loss: 2.631064448757271

Epoch: 5| Step: 3
Training loss: 2.295859183588824
Validation loss: 2.6086719536756338

Epoch: 5| Step: 4
Training loss: 3.188585283607739
Validation loss: 2.609463075258277

Epoch: 5| Step: 5
Training loss: 2.2265922678245853
Validation loss: 2.6047218574274513

Epoch: 5| Step: 6
Training loss: 3.141057682123453
Validation loss: 2.613591091709608

Epoch: 5| Step: 7
Training loss: 2.777371649192898
Validation loss: 2.6170639839100125

Epoch: 5| Step: 8
Training loss: 2.9060176633441115
Validation loss: 2.609384572217446

Epoch: 5| Step: 9
Training loss: 3.136161555186839
Validation loss: 2.612218509909059

Epoch: 5| Step: 10
Training loss: 2.562194340781999
Validation loss: 2.6213789994752763

Epoch: 36| Step: 0
Training loss: 3.0704656276422027
Validation loss: 2.606510731377318

Epoch: 5| Step: 1
Training loss: 3.0105491177857546
Validation loss: 2.62080326747475

Epoch: 5| Step: 2
Training loss: 2.0674152182524597
Validation loss: 2.6155927976232225

Epoch: 5| Step: 3
Training loss: 2.9715572536292614
Validation loss: 2.6258386648272265

Epoch: 5| Step: 4
Training loss: 3.044436843735735
Validation loss: 2.6101431847866214

Epoch: 5| Step: 5
Training loss: 2.964282559444042
Validation loss: 2.619455622304093

Epoch: 5| Step: 6
Training loss: 2.2332237852567802
Validation loss: 2.6246592226733845

Epoch: 5| Step: 7
Training loss: 3.1787043370707204
Validation loss: 2.6194639940233033

Epoch: 5| Step: 8
Training loss: 2.529721210483676
Validation loss: 2.630215120423555

Epoch: 5| Step: 9
Training loss: 2.7359281651954723
Validation loss: 2.6217975311331227

Epoch: 5| Step: 10
Training loss: 3.310694940457295
Validation loss: 2.6162078292365147

Epoch: 37| Step: 0
Training loss: 2.3221429354483303
Validation loss: 2.615674818165354

Epoch: 5| Step: 1
Training loss: 3.2241816938899155
Validation loss: 2.6265829951267343

Epoch: 5| Step: 2
Training loss: 2.8268460074099147
Validation loss: 2.6167440029786406

Epoch: 5| Step: 3
Training loss: 2.750679799066883
Validation loss: 2.615833097681842

Epoch: 5| Step: 4
Training loss: 2.3660933480699797
Validation loss: 2.6093530927237922

Epoch: 5| Step: 5
Training loss: 3.137234960053212
Validation loss: 2.610185703181724

Epoch: 5| Step: 6
Training loss: 3.3433133134277386
Validation loss: 2.618014823173328

Epoch: 5| Step: 7
Training loss: 2.6090900928035663
Validation loss: 2.610767304740036

Epoch: 5| Step: 8
Training loss: 3.2041064735847002
Validation loss: 2.6214678097502517

Epoch: 5| Step: 9
Training loss: 2.965448410838359
Validation loss: 2.615134059897239

Epoch: 5| Step: 10
Training loss: 2.158019072680823
Validation loss: 2.615837880309172

Epoch: 38| Step: 0
Training loss: 2.380856671226162
Validation loss: 2.6001987195568774

Epoch: 5| Step: 1
Training loss: 3.1531427781782475
Validation loss: 2.611798995865708

Epoch: 5| Step: 2
Training loss: 2.864375676806955
Validation loss: 2.6204315567263383

Epoch: 5| Step: 3
Training loss: 3.296820328245596
Validation loss: 2.6144517186344016

Epoch: 5| Step: 4
Training loss: 2.386499073264156
Validation loss: 2.615787537817882

Epoch: 5| Step: 5
Training loss: 2.719165551008751
Validation loss: 2.61525360149123

Epoch: 5| Step: 6
Training loss: 2.8297428119378387
Validation loss: 2.605512271537354

Epoch: 5| Step: 7
Training loss: 3.0712871994231232
Validation loss: 2.615529984756096

Epoch: 5| Step: 8
Training loss: 2.722960533094231
Validation loss: 2.614385990516087

Epoch: 5| Step: 9
Training loss: 2.5460395612916846
Validation loss: 2.6136717390923296

Epoch: 5| Step: 10
Training loss: 3.0007520368842933
Validation loss: 2.609919421914619

Epoch: 39| Step: 0
Training loss: 2.9788874959968115
Validation loss: 2.620626325717336

Epoch: 5| Step: 1
Training loss: 2.9243762076583883
Validation loss: 2.621917853757539

Epoch: 5| Step: 2
Training loss: 2.5400510770813507
Validation loss: 2.620260033644873

Epoch: 5| Step: 3
Training loss: 2.6550041418528174
Validation loss: 2.6152867876499966

Epoch: 5| Step: 4
Training loss: 2.695937286055037
Validation loss: 2.6197338232822958

Epoch: 5| Step: 5
Training loss: 2.3500734601815134
Validation loss: 2.613820242648304

Epoch: 5| Step: 6
Training loss: 2.8758271727435627
Validation loss: 2.6156847338868987

Epoch: 5| Step: 7
Training loss: 3.3940374544197938
Validation loss: 2.628323937480558

Epoch: 5| Step: 8
Training loss: 3.1073824378291772
Validation loss: 2.6169672028893474

Epoch: 5| Step: 9
Training loss: 2.6332411601034917
Validation loss: 2.6131500334313835

Epoch: 5| Step: 10
Training loss: 2.8649877274335274
Validation loss: 2.6084688050098666

Epoch: 40| Step: 0
Training loss: 2.329998517015501
Validation loss: 2.6110781477572056

Epoch: 5| Step: 1
Training loss: 2.5391245673002776
Validation loss: 2.6077170667904395

Epoch: 5| Step: 2
Training loss: 2.933106078390252
Validation loss: 2.6063235929414477

Epoch: 5| Step: 3
Training loss: 2.776737967953725
Validation loss: 2.6128795586120166

Epoch: 5| Step: 4
Training loss: 2.8013765561659207
Validation loss: 2.606848939434788

Epoch: 5| Step: 5
Training loss: 2.9061269426442293
Validation loss: 2.6150455109665933

Epoch: 5| Step: 6
Training loss: 2.012673042392562
Validation loss: 2.606529686335794

Epoch: 5| Step: 7
Training loss: 3.269000193719867
Validation loss: 2.6119991442366093

Epoch: 5| Step: 8
Training loss: 3.7764991360368807
Validation loss: 2.618868533051068

Epoch: 5| Step: 9
Training loss: 2.837988413985342
Validation loss: 2.6134927872082225

Epoch: 5| Step: 10
Training loss: 2.6512546016611815
Validation loss: 2.620878494989753

Epoch: 41| Step: 0
Training loss: 2.8726624647233563
Validation loss: 2.600515891987458

Epoch: 5| Step: 1
Training loss: 3.050932232079436
Validation loss: 2.6186835445401027

Epoch: 5| Step: 2
Training loss: 3.2201440255314693
Validation loss: 2.621390733181662

Epoch: 5| Step: 3
Training loss: 2.666850222786951
Validation loss: 2.614599232677801

Epoch: 5| Step: 4
Training loss: 3.2812507266089224
Validation loss: 2.60839589783791

Epoch: 5| Step: 5
Training loss: 2.636031449774304
Validation loss: 2.6142999776340465

Epoch: 5| Step: 6
Training loss: 2.1675945887006534
Validation loss: 2.592909463612269

Epoch: 5| Step: 7
Training loss: 2.7605916573581717
Validation loss: 2.6101956338625656

Epoch: 5| Step: 8
Training loss: 3.201412580562888
Validation loss: 2.6143121883133547

Epoch: 5| Step: 9
Training loss: 2.491206056596796
Validation loss: 2.6028398460304274

Epoch: 5| Step: 10
Training loss: 2.459147065395969
Validation loss: 2.617162679310578

Epoch: 42| Step: 0
Training loss: 2.3537720093429932
Validation loss: 2.6173671718899265

Epoch: 5| Step: 1
Training loss: 2.666485800172574
Validation loss: 2.6139308139876176

Epoch: 5| Step: 2
Training loss: 2.570152022619004
Validation loss: 2.603736624044623

Epoch: 5| Step: 3
Training loss: 3.0674123486320726
Validation loss: 2.6118718365088744

Epoch: 5| Step: 4
Training loss: 2.915584872215989
Validation loss: 2.5972683401266656

Epoch: 5| Step: 5
Training loss: 2.9544382556061253
Validation loss: 2.622377644466524

Epoch: 5| Step: 6
Training loss: 2.9111218380265296
Validation loss: 2.618893549994962

Epoch: 5| Step: 7
Training loss: 2.49071274893577
Validation loss: 2.607100391068176

Epoch: 5| Step: 8
Training loss: 3.2550020605218464
Validation loss: 2.612007307243054

Epoch: 5| Step: 9
Training loss: 3.276696233244097
Validation loss: 2.6084910071834932

Epoch: 5| Step: 10
Training loss: 2.4721476678167305
Validation loss: 2.6031160449471886

Epoch: 43| Step: 0
Training loss: 3.084013752136047
Validation loss: 2.614387457478245

Epoch: 5| Step: 1
Training loss: 2.775344837517055
Validation loss: 2.616592487009798

Epoch: 5| Step: 2
Training loss: 2.360988646179845
Validation loss: 2.6079414246102632

Epoch: 5| Step: 3
Training loss: 2.815615814227871
Validation loss: 2.6068885180602397

Epoch: 5| Step: 4
Training loss: 2.8580784594135227
Validation loss: 2.6174015639015615

Epoch: 5| Step: 5
Training loss: 2.775583473930852
Validation loss: 2.6088242696628168

Epoch: 5| Step: 6
Training loss: 2.920037982380106
Validation loss: 2.6192784192044196

Epoch: 5| Step: 7
Training loss: 2.716047675948886
Validation loss: 2.617932713386786

Epoch: 5| Step: 8
Training loss: 2.8310838258999786
Validation loss: 2.6050448384521108

Epoch: 5| Step: 9
Training loss: 3.121871297564903
Validation loss: 2.6133540601198257

Epoch: 5| Step: 10
Training loss: 2.7713326217042353
Validation loss: 2.609711607945079

Epoch: 44| Step: 0
Training loss: 2.654869798100642
Validation loss: 2.599834414739697

Epoch: 5| Step: 1
Training loss: 2.4723808532951055
Validation loss: 2.603235490913623

Epoch: 5| Step: 2
Training loss: 2.4697615084394964
Validation loss: 2.608473989350537

Epoch: 5| Step: 3
Training loss: 2.998707492872157
Validation loss: 2.615926521979695

Epoch: 5| Step: 4
Training loss: 3.1913682989060814
Validation loss: 2.611357215705013

Epoch: 5| Step: 5
Training loss: 2.940997050927534
Validation loss: 2.6162872710590555

Epoch: 5| Step: 6
Training loss: 3.3756285188144877
Validation loss: 2.6117227166470545

Epoch: 5| Step: 7
Training loss: 2.5293125225746675
Validation loss: 2.6115920549288645

Epoch: 5| Step: 8
Training loss: 2.532628284605662
Validation loss: 2.6151150241790315

Epoch: 5| Step: 9
Training loss: 2.5969985473475985
Validation loss: 2.602231922375318

Epoch: 5| Step: 10
Training loss: 3.0666129072978165
Validation loss: 2.6104456975793577

Epoch: 45| Step: 0
Training loss: 2.4179749619707662
Validation loss: 2.603551369774862

Epoch: 5| Step: 1
Training loss: 2.4556502447192368
Validation loss: 2.5977175578055403

Epoch: 5| Step: 2
Training loss: 2.7441825890641467
Validation loss: 2.6128594958713522

Epoch: 5| Step: 3
Training loss: 3.0381162293069566
Validation loss: 2.60575505026574

Epoch: 5| Step: 4
Training loss: 2.672918729317975
Validation loss: 2.606390086012533

Epoch: 5| Step: 5
Training loss: 2.9373943228684873
Validation loss: 2.6129136329323606

Epoch: 5| Step: 6
Training loss: 2.3579552022676085
Validation loss: 2.611026876957514

Epoch: 5| Step: 7
Training loss: 3.06297236322432
Validation loss: 2.6076874773481653

Epoch: 5| Step: 8
Training loss: 2.6722577807976706
Validation loss: 2.589729296282959

Epoch: 5| Step: 9
Training loss: 3.25352726775216
Validation loss: 2.5892002435512915

Epoch: 5| Step: 10
Training loss: 3.2895010250360737
Validation loss: 2.5925013549641664

Epoch: 46| Step: 0
Training loss: 2.5008083943851527
Validation loss: 2.607031849099931

Epoch: 5| Step: 1
Training loss: 2.0764292057791303
Validation loss: 2.6158577349794183

Epoch: 5| Step: 2
Training loss: 2.7171076055958774
Validation loss: 2.596186589899107

Epoch: 5| Step: 3
Training loss: 3.1261528940231127
Validation loss: 2.611889638527756

Epoch: 5| Step: 4
Training loss: 2.8907645526913255
Validation loss: 2.6036734897042897

Epoch: 5| Step: 5
Training loss: 3.40865178256631
Validation loss: 2.5951408514828125

Epoch: 5| Step: 6
Training loss: 3.2806878471205
Validation loss: 2.6061935783041794

Epoch: 5| Step: 7
Training loss: 2.577146772273524
Validation loss: 2.6095116073378883

Epoch: 5| Step: 8
Training loss: 2.8779265394345694
Validation loss: 2.611521473148728

Epoch: 5| Step: 9
Training loss: 2.705470836791716
Validation loss: 2.6058480857299493

Epoch: 5| Step: 10
Training loss: 2.5930578388335053
Validation loss: 2.6049296177405745

Epoch: 47| Step: 0
Training loss: 2.4000038226415072
Validation loss: 2.6192568306424264

Epoch: 5| Step: 1
Training loss: 2.218610409925883
Validation loss: 2.6093659140733414

Epoch: 5| Step: 2
Training loss: 3.600231131445466
Validation loss: 2.6129069876457023

Epoch: 5| Step: 3
Training loss: 3.1531324947937285
Validation loss: 2.610040197825493

Epoch: 5| Step: 4
Training loss: 3.055698705460381
Validation loss: 2.6050088169658125

Epoch: 5| Step: 5
Training loss: 2.7557306401540744
Validation loss: 2.6047745239287803

Epoch: 5| Step: 6
Training loss: 2.5732551588857127
Validation loss: 2.61745453355216

Epoch: 5| Step: 7
Training loss: 2.9143496619883384
Validation loss: 2.612888694133074

Epoch: 5| Step: 8
Training loss: 2.3726986225302475
Validation loss: 2.6157986566265676

Epoch: 5| Step: 9
Training loss: 2.974585329535939
Validation loss: 2.607454504552679

Epoch: 5| Step: 10
Training loss: 2.5472614018616273
Validation loss: 2.607727427636456

Epoch: 48| Step: 0
Training loss: 3.1213262707699485
Validation loss: 2.6082416677016633

Epoch: 5| Step: 1
Training loss: 2.7513988578350905
Validation loss: 2.594199017076341

Epoch: 5| Step: 2
Training loss: 3.0240481053315564
Validation loss: 2.6182153599933313

Epoch: 5| Step: 3
Training loss: 2.3519238165888976
Validation loss: 2.5973840186422885

Epoch: 5| Step: 4
Training loss: 2.8120421990691575
Validation loss: 2.615177666638998

Epoch: 5| Step: 5
Training loss: 2.885695589725302
Validation loss: 2.5858329957791537

Epoch: 5| Step: 6
Training loss: 2.671967354232409
Validation loss: 2.597455617240904

Epoch: 5| Step: 7
Training loss: 2.648072794331449
Validation loss: 2.6093682946127643

Epoch: 5| Step: 8
Training loss: 2.474056865670786
Validation loss: 2.6147912722315354

Epoch: 5| Step: 9
Training loss: 3.2547735223925907
Validation loss: 2.6180021793152695

Epoch: 5| Step: 10
Training loss: 2.7190010568743688
Validation loss: 2.6048040190074135

Epoch: 49| Step: 0
Training loss: 2.7811933361667664
Validation loss: 2.5980110241384033

Epoch: 5| Step: 1
Training loss: 2.684782295280751
Validation loss: 2.5972341844252056

Epoch: 5| Step: 2
Training loss: 1.8730852522911134
Validation loss: 2.5944148616407503

Epoch: 5| Step: 3
Training loss: 3.1049973231993606
Validation loss: 2.597339609780003

Epoch: 5| Step: 4
Training loss: 3.356497308296705
Validation loss: 2.5942505216290153

Epoch: 5| Step: 5
Training loss: 3.424614771876451
Validation loss: 2.60004611025705

Epoch: 5| Step: 6
Training loss: 2.697740075261491
Validation loss: 2.5900094628835246

Epoch: 5| Step: 7
Training loss: 2.7200544012463697
Validation loss: 2.596915948783678

Epoch: 5| Step: 8
Training loss: 2.4178730047494112
Validation loss: 2.6124915142719307

Epoch: 5| Step: 9
Training loss: 2.8117913942950565
Validation loss: 2.596767277187053

Epoch: 5| Step: 10
Training loss: 2.614071759232051
Validation loss: 2.5880907244104936

Epoch: 50| Step: 0
Training loss: 3.0608874376768465
Validation loss: 2.598705914656586

Epoch: 5| Step: 1
Training loss: 3.450606726770948
Validation loss: 2.5894722719835563

Epoch: 5| Step: 2
Training loss: 2.448563045357637
Validation loss: 2.5877601845438956

Epoch: 5| Step: 3
Training loss: 2.2294067419908217
Validation loss: 2.6034406697616124

Epoch: 5| Step: 4
Training loss: 3.0194683981371013
Validation loss: 2.5940463809423813

Epoch: 5| Step: 5
Training loss: 3.3122146771465286
Validation loss: 2.603234727701155

Epoch: 5| Step: 6
Training loss: 2.553220461831506
Validation loss: 2.5910420925978723

Epoch: 5| Step: 7
Training loss: 2.1278574188551276
Validation loss: 2.604190753128067

Epoch: 5| Step: 8
Training loss: 3.06328868441858
Validation loss: 2.596980419166128

Epoch: 5| Step: 9
Training loss: 2.6790866901173733
Validation loss: 2.6046855317728475

Epoch: 5| Step: 10
Training loss: 2.522466797624339
Validation loss: 2.610087166308443

Epoch: 51| Step: 0
Training loss: 2.858399104778706
Validation loss: 2.6112362051957643

Epoch: 5| Step: 1
Training loss: 2.883143956427831
Validation loss: 2.5936745342173673

Epoch: 5| Step: 2
Training loss: 2.5448502056953157
Validation loss: 2.604779353434298

Epoch: 5| Step: 3
Training loss: 2.143939383012833
Validation loss: 2.60128928193507

Epoch: 5| Step: 4
Training loss: 2.319745851934198
Validation loss: 2.6102081191036697

Epoch: 5| Step: 5
Training loss: 3.4160880707637435
Validation loss: 2.6030334558391193

Epoch: 5| Step: 6
Training loss: 2.7067567099860383
Validation loss: 2.604526095945487

Epoch: 5| Step: 7
Training loss: 2.6435728153527416
Validation loss: 2.596164597996584

Epoch: 5| Step: 8
Training loss: 2.981028972885473
Validation loss: 2.6028998626470337

Epoch: 5| Step: 9
Training loss: 3.5770328637400532
Validation loss: 2.6078296388776003

Epoch: 5| Step: 10
Training loss: 2.351185207579483
Validation loss: 2.5951905938015525

Epoch: 52| Step: 0
Training loss: 2.3269066406852965
Validation loss: 2.611002795956767

Epoch: 5| Step: 1
Training loss: 2.9175364877597794
Validation loss: 2.594271079090367

Epoch: 5| Step: 2
Training loss: 2.6202062704700926
Validation loss: 2.595936035495873

Epoch: 5| Step: 3
Training loss: 2.370334660848325
Validation loss: 2.603046540251072

Epoch: 5| Step: 4
Training loss: 2.7865307854951045
Validation loss: 2.6075077372276216

Epoch: 5| Step: 5
Training loss: 2.877795808834635
Validation loss: 2.6092788239399374

Epoch: 5| Step: 6
Training loss: 3.449704093958852
Validation loss: 2.6011178507757293

Epoch: 5| Step: 7
Training loss: 3.354487496585148
Validation loss: 2.606161459727605

Epoch: 5| Step: 8
Training loss: 2.8305635003138656
Validation loss: 2.6095510748458155

Epoch: 5| Step: 9
Training loss: 2.4850514768491885
Validation loss: 2.6031189679367914

Epoch: 5| Step: 10
Training loss: 2.383667739224938
Validation loss: 2.5958583613177253

Epoch: 53| Step: 0
Training loss: 2.696446188631855
Validation loss: 2.6008040253027813

Epoch: 5| Step: 1
Training loss: 2.372942284056984
Validation loss: 2.5984032698449835

Epoch: 5| Step: 2
Training loss: 2.9333359443768527
Validation loss: 2.5890255295044504

Epoch: 5| Step: 3
Training loss: 2.847385472111992
Validation loss: 2.594150821115123

Epoch: 5| Step: 4
Training loss: 2.996645323352386
Validation loss: 2.6096220802761185

Epoch: 5| Step: 5
Training loss: 2.883656282658971
Validation loss: 2.600308033386842

Epoch: 5| Step: 6
Training loss: 2.8926213149839395
Validation loss: 2.598224858373292

Epoch: 5| Step: 7
Training loss: 2.313518299967798
Validation loss: 2.599672599164121

Epoch: 5| Step: 8
Training loss: 2.7776110556690092
Validation loss: 2.5979145887214123

Epoch: 5| Step: 9
Training loss: 2.6734174771119252
Validation loss: 2.5944097742058347

Epoch: 5| Step: 10
Training loss: 3.301820200996637
Validation loss: 2.6049592778746082

Epoch: 54| Step: 0
Training loss: 2.456700628745506
Validation loss: 2.592629448721819

Epoch: 5| Step: 1
Training loss: 2.87095689512266
Validation loss: 2.6047267136047307

Epoch: 5| Step: 2
Training loss: 2.7704993790076964
Validation loss: 2.6029898633099076

Epoch: 5| Step: 3
Training loss: 2.4725010056295944
Validation loss: 2.59760135577521

Epoch: 5| Step: 4
Training loss: 2.758364095449102
Validation loss: 2.5919694191562304

Epoch: 5| Step: 5
Training loss: 2.325321942261405
Validation loss: 2.585480729993967

Epoch: 5| Step: 6
Training loss: 3.197291575089406
Validation loss: 2.587692577223678

Epoch: 5| Step: 7
Training loss: 2.6657560899885486
Validation loss: 2.597813096092755

Epoch: 5| Step: 8
Training loss: 3.128598849356189
Validation loss: 2.603825728874019

Epoch: 5| Step: 9
Training loss: 2.751407869793334
Validation loss: 2.5960771361014285

Epoch: 5| Step: 10
Training loss: 3.218121958079394
Validation loss: 2.609853994179797

Epoch: 55| Step: 0
Training loss: 2.8857165753410783
Validation loss: 2.5938214167323004

Epoch: 5| Step: 1
Training loss: 2.3086355757434163
Validation loss: 2.5992617487443406

Epoch: 5| Step: 2
Training loss: 2.8661991255612658
Validation loss: 2.5933737572746227

Epoch: 5| Step: 3
Training loss: 2.9009396839308272
Validation loss: 2.58791207005722

Epoch: 5| Step: 4
Training loss: 2.843764755713778
Validation loss: 2.5981710654898342

Epoch: 5| Step: 5
Training loss: 2.599517660149607
Validation loss: 2.61323113392416

Epoch: 5| Step: 6
Training loss: 2.4888681531034775
Validation loss: 2.5892013752677796

Epoch: 5| Step: 7
Training loss: 3.0881194694020184
Validation loss: 2.5953910332179

Epoch: 5| Step: 8
Training loss: 2.804898564889659
Validation loss: 2.595217860098396

Epoch: 5| Step: 9
Training loss: 2.7550598758345695
Validation loss: 2.5898482519810466

Epoch: 5| Step: 10
Training loss: 3.0560869294330395
Validation loss: 2.608330854519358

Epoch: 56| Step: 0
Training loss: 2.23077401178389
Validation loss: 2.5968274815365016

Epoch: 5| Step: 1
Training loss: 2.3884007696980705
Validation loss: 2.585480220335782

Epoch: 5| Step: 2
Training loss: 3.2228701988639856
Validation loss: 2.6021790241235476

Epoch: 5| Step: 3
Training loss: 2.8770408021369187
Validation loss: 2.5999621156625468

Epoch: 5| Step: 4
Training loss: 2.536479304943034
Validation loss: 2.6094167213673356

Epoch: 5| Step: 5
Training loss: 2.29494493838145
Validation loss: 2.5969507587243945

Epoch: 5| Step: 6
Training loss: 3.0909156531503954
Validation loss: 2.6046763778149753

Epoch: 5| Step: 7
Training loss: 2.282664448390905
Validation loss: 2.6025953951391876

Epoch: 5| Step: 8
Training loss: 3.4527840424413734
Validation loss: 2.5850824877559666

Epoch: 5| Step: 9
Training loss: 3.049630977631793
Validation loss: 2.595084469643267

Epoch: 5| Step: 10
Training loss: 2.883618746028804
Validation loss: 2.5960497287271287

Epoch: 57| Step: 0
Training loss: 2.378611378802689
Validation loss: 2.60662216354779

Epoch: 5| Step: 1
Training loss: 3.1703890622493436
Validation loss: 2.5998133539913044

Epoch: 5| Step: 2
Training loss: 3.0577609705493884
Validation loss: 2.600090196818235

Epoch: 5| Step: 3
Training loss: 2.603604818134125
Validation loss: 2.5918670285498657

Epoch: 5| Step: 4
Training loss: 3.0295331359854263
Validation loss: 2.5949068628920107

Epoch: 5| Step: 5
Training loss: 3.1389602120397377
Validation loss: 2.593474133149493

Epoch: 5| Step: 6
Training loss: 2.4036738489460117
Validation loss: 2.5869628521103794

Epoch: 5| Step: 7
Training loss: 2.1670943962841136
Validation loss: 2.582520619237723

Epoch: 5| Step: 8
Training loss: 2.3440607500699104
Validation loss: 2.6094470653685984

Epoch: 5| Step: 9
Training loss: 3.038352275321312
Validation loss: 2.5844690867530757

Epoch: 5| Step: 10
Training loss: 2.9863531936182115
Validation loss: 2.6030881916855195

Epoch: 58| Step: 0
Training loss: 3.0878977283876234
Validation loss: 2.596142237577453

Epoch: 5| Step: 1
Training loss: 2.745386849331826
Validation loss: 2.590110431364149

Epoch: 5| Step: 2
Training loss: 2.7478759538952273
Validation loss: 2.5997014021760463

Epoch: 5| Step: 3
Training loss: 2.307473674223103
Validation loss: 2.603697631599798

Epoch: 5| Step: 4
Training loss: 3.0375206966244486
Validation loss: 2.5872125325332735

Epoch: 5| Step: 5
Training loss: 2.8203636439539075
Validation loss: 2.5939151075335682

Epoch: 5| Step: 6
Training loss: 3.0113731017708263
Validation loss: 2.5951699013735636

Epoch: 5| Step: 7
Training loss: 2.4026387847604975
Validation loss: 2.6063087490398287

Epoch: 5| Step: 8
Training loss: 2.873446832821134
Validation loss: 2.5984989116701884

Epoch: 5| Step: 9
Training loss: 2.679882698623458
Validation loss: 2.5973039690287933

Epoch: 5| Step: 10
Training loss: 2.811626213821382
Validation loss: 2.603003613718505

Epoch: 59| Step: 0
Training loss: 2.9202117265731156
Validation loss: 2.5967110915858638

Epoch: 5| Step: 1
Training loss: 2.9366489557373723
Validation loss: 2.5960484340933343

Epoch: 5| Step: 2
Training loss: 2.890638031801283
Validation loss: 2.6073036276724157

Epoch: 5| Step: 3
Training loss: 2.9999774296229416
Validation loss: 2.6005665291257385

Epoch: 5| Step: 4
Training loss: 2.1312913325712213
Validation loss: 2.583088595943834

Epoch: 5| Step: 5
Training loss: 2.2711033325203114
Validation loss: 2.5949211673940265

Epoch: 5| Step: 6
Training loss: 2.9989041870218216
Validation loss: 2.5947782650492464

Epoch: 5| Step: 7
Training loss: 2.543159442554939
Validation loss: 2.5964626276806357

Epoch: 5| Step: 8
Training loss: 3.50352055735033
Validation loss: 2.590034905066724

Epoch: 5| Step: 9
Training loss: 2.3101579301690607
Validation loss: 2.584832907057445

Epoch: 5| Step: 10
Training loss: 2.752031702851505
Validation loss: 2.5908285155186044

Epoch: 60| Step: 0
Training loss: 3.0528933824751796
Validation loss: 2.5863061987869758

Epoch: 5| Step: 1
Training loss: 3.4941699654214617
Validation loss: 2.586056129493763

Epoch: 5| Step: 2
Training loss: 2.5536310187064433
Validation loss: 2.602243325692249

Epoch: 5| Step: 3
Training loss: 2.1719516219201167
Validation loss: 2.601973979296822

Epoch: 5| Step: 4
Training loss: 2.8431865427363143
Validation loss: 2.60802187316315

Epoch: 5| Step: 5
Training loss: 3.0287207049985176
Validation loss: 2.5912670215784313

Epoch: 5| Step: 6
Training loss: 3.1219122318342594
Validation loss: 2.5913018144067457

Epoch: 5| Step: 7
Training loss: 2.102143274768932
Validation loss: 2.597418138322096

Epoch: 5| Step: 8
Training loss: 2.7368387512329337
Validation loss: 2.587673368863543

Epoch: 5| Step: 9
Training loss: 2.5732988905042893
Validation loss: 2.5962956500380483

Epoch: 5| Step: 10
Training loss: 2.505270456877515
Validation loss: 2.6018651315534953

Epoch: 61| Step: 0
Training loss: 2.6946305006445064
Validation loss: 2.596825078641339

Epoch: 5| Step: 1
Training loss: 2.6556302413475725
Validation loss: 2.5967505236172173

Epoch: 5| Step: 2
Training loss: 2.355768744500079
Validation loss: 2.5994667570113075

Epoch: 5| Step: 3
Training loss: 3.2537144195686394
Validation loss: 2.5996464475910397

Epoch: 5| Step: 4
Training loss: 2.9174228959408275
Validation loss: 2.591080758031048

Epoch: 5| Step: 5
Training loss: 2.58442279443978
Validation loss: 2.589616750128445

Epoch: 5| Step: 6
Training loss: 2.9408203189857707
Validation loss: 2.607961015988149

Epoch: 5| Step: 7
Training loss: 2.798173400582999
Validation loss: 2.588489967639224

Epoch: 5| Step: 8
Training loss: 3.1780995895885287
Validation loss: 2.5950156725376363

Epoch: 5| Step: 9
Training loss: 2.38140297145554
Validation loss: 2.605896643815985

Epoch: 5| Step: 10
Training loss: 2.6862859423377596
Validation loss: 2.588951755940861

Epoch: 62| Step: 0
Training loss: 2.3966324067972016
Validation loss: 2.5844733957408264

Epoch: 5| Step: 1
Training loss: 2.9135522472383597
Validation loss: 2.603660152439342

Epoch: 5| Step: 2
Training loss: 3.55954285075998
Validation loss: 2.59205721548444

Epoch: 5| Step: 3
Training loss: 2.125476895842324
Validation loss: 2.59495304819879

Epoch: 5| Step: 4
Training loss: 2.4492333516684957
Validation loss: 2.589200890105041

Epoch: 5| Step: 5
Training loss: 2.1681065421089873
Validation loss: 2.596261769377564

Epoch: 5| Step: 6
Training loss: 2.8805567902534053
Validation loss: 2.5943006130477717

Epoch: 5| Step: 7
Training loss: 3.3192119614516855
Validation loss: 2.5958606006743556

Epoch: 5| Step: 8
Training loss: 2.779397068643764
Validation loss: 2.589074844716201

Epoch: 5| Step: 9
Training loss: 3.1010880191419625
Validation loss: 2.594948479990999

Epoch: 5| Step: 10
Training loss: 2.3161299799679735
Validation loss: 2.5899365894022326

Epoch: 63| Step: 0
Training loss: 3.9171807513123706
Validation loss: 2.586889802622976

Epoch: 5| Step: 1
Training loss: 2.3176392848555643
Validation loss: 2.5887958336381374

Epoch: 5| Step: 2
Training loss: 2.556294626905016
Validation loss: 2.5779567828942818

Epoch: 5| Step: 3
Training loss: 2.820161007011612
Validation loss: 2.5876846718790176

Epoch: 5| Step: 4
Training loss: 2.3546712104016216
Validation loss: 2.590825973476171

Epoch: 5| Step: 5
Training loss: 2.7009826284935317
Validation loss: 2.5927741721514335

Epoch: 5| Step: 6
Training loss: 2.82629891975376
Validation loss: 2.5868287436282036

Epoch: 5| Step: 7
Training loss: 2.423092542209053
Validation loss: 2.5909059194669806

Epoch: 5| Step: 8
Training loss: 2.603222291737956
Validation loss: 2.602363700294092

Epoch: 5| Step: 9
Training loss: 2.6333570511470112
Validation loss: 2.591091495083704

Epoch: 5| Step: 10
Training loss: 2.9854568198343956
Validation loss: 2.5826969947494547

Epoch: 64| Step: 0
Training loss: 2.946588942882164
Validation loss: 2.574151353207272

Epoch: 5| Step: 1
Training loss: 3.6562826041047622
Validation loss: 2.6003452271399228

Epoch: 5| Step: 2
Training loss: 3.0802320056083476
Validation loss: 2.5931371821587637

Epoch: 5| Step: 3
Training loss: 2.0293941529559403
Validation loss: 2.588510993747234

Epoch: 5| Step: 4
Training loss: 2.6384308858135905
Validation loss: 2.5965807220126575

Epoch: 5| Step: 5
Training loss: 1.9344534147820134
Validation loss: 2.590754000679243

Epoch: 5| Step: 6
Training loss: 2.735698183617733
Validation loss: 2.5977484332115424

Epoch: 5| Step: 7
Training loss: 2.472552594125956
Validation loss: 2.586923280797217

Epoch: 5| Step: 8
Training loss: 2.8432190787229636
Validation loss: 2.5831474140705972

Epoch: 5| Step: 9
Training loss: 2.466050809152714
Validation loss: 2.581983114851943

Epoch: 5| Step: 10
Training loss: 3.296165787767912
Validation loss: 2.583536797673996

Epoch: 65| Step: 0
Training loss: 3.066843183938195
Validation loss: 2.5849450961939477

Epoch: 5| Step: 1
Training loss: 3.055221471921909
Validation loss: 2.5924495521220883

Epoch: 5| Step: 2
Training loss: 2.1811787416027655
Validation loss: 2.584255696573322

Epoch: 5| Step: 3
Training loss: 2.646268873836655
Validation loss: 2.5942059148462224

Epoch: 5| Step: 4
Training loss: 2.8289547540762032
Validation loss: 2.6053609663223516

Epoch: 5| Step: 5
Training loss: 2.7665756229755987
Validation loss: 2.5938740579663024

Epoch: 5| Step: 6
Training loss: 2.931726178694187
Validation loss: 2.6062417040309453

Epoch: 5| Step: 7
Training loss: 2.8687517020692117
Validation loss: 2.5949982556347035

Epoch: 5| Step: 8
Training loss: 2.3302776446299296
Validation loss: 2.5950249687493803

Epoch: 5| Step: 9
Training loss: 3.024972294451992
Validation loss: 2.59085880214447

Epoch: 5| Step: 10
Training loss: 2.6219866577670263
Validation loss: 2.5837792406341986

Epoch: 66| Step: 0
Training loss: 2.854531276460038
Validation loss: 2.5822519820468988

Epoch: 5| Step: 1
Training loss: 3.541712831682503
Validation loss: 2.5987387424306387

Epoch: 5| Step: 2
Training loss: 2.7433719522284843
Validation loss: 2.608356629079263

Epoch: 5| Step: 3
Training loss: 2.3012265873784616
Validation loss: 2.6053275282704833

Epoch: 5| Step: 4
Training loss: 2.9871661330854753
Validation loss: 2.5989439330105983

Epoch: 5| Step: 5
Training loss: 2.7231033374063953
Validation loss: 2.585745822915926

Epoch: 5| Step: 6
Training loss: 3.2241212046725902
Validation loss: 2.591755884863367

Epoch: 5| Step: 7
Training loss: 2.662368190887597
Validation loss: 2.61102772920447

Epoch: 5| Step: 8
Training loss: 2.8076061480761227
Validation loss: 2.5888361289321455

Epoch: 5| Step: 9
Training loss: 2.2189996068540676
Validation loss: 2.6009299468100866

Epoch: 5| Step: 10
Training loss: 1.8264960179822003
Validation loss: 2.59046416067687

Epoch: 67| Step: 0
Training loss: 2.447928007924747
Validation loss: 2.595933266872049

Epoch: 5| Step: 1
Training loss: 2.438981021984006
Validation loss: 2.582274924388964

Epoch: 5| Step: 2
Training loss: 2.232493855808599
Validation loss: 2.593783356024233

Epoch: 5| Step: 3
Training loss: 2.523058789064609
Validation loss: 2.593503794306261

Epoch: 5| Step: 4
Training loss: 2.655754671474953
Validation loss: 2.579483237265637

Epoch: 5| Step: 5
Training loss: 3.307031976711915
Validation loss: 2.589974281507055

Epoch: 5| Step: 6
Training loss: 3.0646084125529054
Validation loss: 2.5822720314154366

Epoch: 5| Step: 7
Training loss: 2.9110949749616672
Validation loss: 2.583227974816932

Epoch: 5| Step: 8
Training loss: 2.8592839461040316
Validation loss: 2.5806017302888553

Epoch: 5| Step: 9
Training loss: 2.7566117652613764
Validation loss: 2.5974689592225246

Epoch: 5| Step: 10
Training loss: 3.089135630180454
Validation loss: 2.5827369395160575

Epoch: 68| Step: 0
Training loss: 2.8174121769212803
Validation loss: 2.596392381077291

Epoch: 5| Step: 1
Training loss: 2.4156036889245307
Validation loss: 2.577587498493327

Epoch: 5| Step: 2
Training loss: 2.5852037754572517
Validation loss: 2.5908543781106097

Epoch: 5| Step: 3
Training loss: 2.6380644352514544
Validation loss: 2.5973978752205307

Epoch: 5| Step: 4
Training loss: 3.628142211768094
Validation loss: 2.5871713899962683

Epoch: 5| Step: 5
Training loss: 2.7901200712338268
Validation loss: 2.590328394610367

Epoch: 5| Step: 6
Training loss: 2.837786111397067
Validation loss: 2.590233340372425

Epoch: 5| Step: 7
Training loss: 2.3901300852978684
Validation loss: 2.5850392688670687

Epoch: 5| Step: 8
Training loss: 2.6210185237726247
Validation loss: 2.601342990627145

Epoch: 5| Step: 9
Training loss: 2.9138831525741504
Validation loss: 2.605731786822296

Epoch: 5| Step: 10
Training loss: 2.593122199501333
Validation loss: 2.5999285253477042

Epoch: 69| Step: 0
Training loss: 2.1578097023693736
Validation loss: 2.5882245535549804

Epoch: 5| Step: 1
Training loss: 3.1319344448278637
Validation loss: 2.593914285243995

Epoch: 5| Step: 2
Training loss: 2.8511186646245554
Validation loss: 2.5903481449314425

Epoch: 5| Step: 3
Training loss: 2.6636377258841746
Validation loss: 2.59651357391571

Epoch: 5| Step: 4
Training loss: 2.6240555108583665
Validation loss: 2.5829762844864024

Epoch: 5| Step: 5
Training loss: 2.9676914938094896
Validation loss: 2.5833964014310347

Epoch: 5| Step: 6
Training loss: 2.710413021834843
Validation loss: 2.5851121881746955

Epoch: 5| Step: 7
Training loss: 2.446453961508127
Validation loss: 2.5862435578404632

Epoch: 5| Step: 8
Training loss: 2.8329199508092127
Validation loss: 2.5861818570966473

Epoch: 5| Step: 9
Training loss: 2.9591353676924976
Validation loss: 2.5784342212756997

Epoch: 5| Step: 10
Training loss: 2.97697353779004
Validation loss: 2.5960620519100037

Epoch: 70| Step: 0
Training loss: 3.3732394112138278
Validation loss: 2.5798943437766204

Epoch: 5| Step: 1
Training loss: 2.7083721940602694
Validation loss: 2.581964799827879

Epoch: 5| Step: 2
Training loss: 3.1575018788964124
Validation loss: 2.5949346320680258

Epoch: 5| Step: 3
Training loss: 2.6177427699208065
Validation loss: 2.59003592654972

Epoch: 5| Step: 4
Training loss: 2.9294967385811206
Validation loss: 2.589879064802194

Epoch: 5| Step: 5
Training loss: 2.5135612789505553
Validation loss: 2.5687741010929632

Epoch: 5| Step: 6
Training loss: 1.9872636570549382
Validation loss: 2.5926120212270174

Epoch: 5| Step: 7
Training loss: 2.82472074698215
Validation loss: 2.5719609419555556

Epoch: 5| Step: 8
Training loss: 2.1982352461296446
Validation loss: 2.569444485056207

Epoch: 5| Step: 9
Training loss: 2.7642658579336037
Validation loss: 2.5950419646278764

Epoch: 5| Step: 10
Training loss: 3.0244380271289817
Validation loss: 2.5781140617767515

Epoch: 71| Step: 0
Training loss: 2.845486456608721
Validation loss: 2.5845037290654824

Epoch: 5| Step: 1
Training loss: 2.7810632021463078
Validation loss: 2.5896496050154414

Epoch: 5| Step: 2
Training loss: 3.038577631930531
Validation loss: 2.585652007133105

Epoch: 5| Step: 3
Training loss: 2.7380845547501234
Validation loss: 2.5824249058343067

Epoch: 5| Step: 4
Training loss: 2.46291598761475
Validation loss: 2.5906148743208606

Epoch: 5| Step: 5
Training loss: 3.063399513644963
Validation loss: 2.5822590040593463

Epoch: 5| Step: 6
Training loss: 3.2273325151383214
Validation loss: 2.581461642872324

Epoch: 5| Step: 7
Training loss: 2.7777493337658408
Validation loss: 2.594524518462889

Epoch: 5| Step: 8
Training loss: 2.566178635442487
Validation loss: 2.590502175642164

Epoch: 5| Step: 9
Training loss: 2.556712523309839
Validation loss: 2.5868399284373

Epoch: 5| Step: 10
Training loss: 1.81476799703761
Validation loss: 2.587793373080725

Epoch: 72| Step: 0
Training loss: 2.1009056454532677
Validation loss: 2.583286736180892

Epoch: 5| Step: 1
Training loss: 3.5406136387157052
Validation loss: 2.570689267777357

Epoch: 5| Step: 2
Training loss: 2.359075565157938
Validation loss: 2.5884396746352754

Epoch: 5| Step: 3
Training loss: 3.1566651326235866
Validation loss: 2.5823472883768277

Epoch: 5| Step: 4
Training loss: 2.705535255119237
Validation loss: 2.576120049801054

Epoch: 5| Step: 5
Training loss: 2.5774111597566245
Validation loss: 2.591857449005404

Epoch: 5| Step: 6
Training loss: 2.5759990827961587
Validation loss: 2.588491336371754

Epoch: 5| Step: 7
Training loss: 2.4398025983161014
Validation loss: 2.5759600576263155

Epoch: 5| Step: 8
Training loss: 2.6824574737164277
Validation loss: 2.5829575427728075

Epoch: 5| Step: 9
Training loss: 3.005443402930385
Validation loss: 2.5887389818542332

Epoch: 5| Step: 10
Training loss: 2.9096030304702865
Validation loss: 2.583432629000451

Epoch: 73| Step: 0
Training loss: 2.3019956223937568
Validation loss: 2.5836292266754213

Epoch: 5| Step: 1
Training loss: 2.111378939967245
Validation loss: 2.5919408506848405

Epoch: 5| Step: 2
Training loss: 3.1818492392473323
Validation loss: 2.594315369524543

Epoch: 5| Step: 3
Training loss: 2.2891574878969188
Validation loss: 2.5945313605281872

Epoch: 5| Step: 4
Training loss: 2.545721249108319
Validation loss: 2.580936598921015

Epoch: 5| Step: 5
Training loss: 3.040168149212849
Validation loss: 2.5872310075941294

Epoch: 5| Step: 6
Training loss: 3.219735004112
Validation loss: 2.5809308506957835

Epoch: 5| Step: 7
Training loss: 2.65516218462339
Validation loss: 2.590958434412875

Epoch: 5| Step: 8
Training loss: 3.031121634685387
Validation loss: 2.5852954655989686

Epoch: 5| Step: 9
Training loss: 2.740391156475791
Validation loss: 2.589831405147704

Epoch: 5| Step: 10
Training loss: 2.7659442092388318
Validation loss: 2.574796775781465

Epoch: 74| Step: 0
Training loss: 2.925493417187738
Validation loss: 2.5898582042218417

Epoch: 5| Step: 1
Training loss: 1.9518949984388043
Validation loss: 2.5843201107886062

Epoch: 5| Step: 2
Training loss: 2.746632247804827
Validation loss: 2.5701229313428358

Epoch: 5| Step: 3
Training loss: 3.3562771020004587
Validation loss: 2.573957745671718

Epoch: 5| Step: 4
Training loss: 2.8369703697617727
Validation loss: 2.5848329660696217

Epoch: 5| Step: 5
Training loss: 2.716873222720818
Validation loss: 2.5695209677654214

Epoch: 5| Step: 6
Training loss: 2.8138980357791428
Validation loss: 2.577775363575634

Epoch: 5| Step: 7
Training loss: 2.425198839825141
Validation loss: 2.589362260119547

Epoch: 5| Step: 8
Training loss: 2.2105167918729096
Validation loss: 2.572465335325344

Epoch: 5| Step: 9
Training loss: 3.2049016723784614
Validation loss: 2.5830525501364865

Epoch: 5| Step: 10
Training loss: 2.78918337092561
Validation loss: 2.5861544261409706

Epoch: 75| Step: 0
Training loss: 2.437577662086608
Validation loss: 2.5692933707116246

Epoch: 5| Step: 1
Training loss: 3.2543754468331088
Validation loss: 2.576589790140562

Epoch: 5| Step: 2
Training loss: 2.161675965409976
Validation loss: 2.594733514196417

Epoch: 5| Step: 3
Training loss: 2.1698510049393884
Validation loss: 2.590110355151054

Epoch: 5| Step: 4
Training loss: 3.4600283287520353
Validation loss: 2.573911289210083

Epoch: 5| Step: 5
Training loss: 2.781772778702078
Validation loss: 2.589554927798404

Epoch: 5| Step: 6
Training loss: 2.6161340215923774
Validation loss: 2.5727096865614882

Epoch: 5| Step: 7
Training loss: 2.4557032551751905
Validation loss: 2.5901514030012973

Epoch: 5| Step: 8
Training loss: 3.3226265775681747
Validation loss: 2.5694526106477285

Epoch: 5| Step: 9
Training loss: 2.1807188376531403
Validation loss: 2.5911604537629715

Epoch: 5| Step: 10
Training loss: 3.000660187877053
Validation loss: 2.584011531357221

Epoch: 76| Step: 0
Training loss: 2.9948876053190463
Validation loss: 2.5821906227646063

Epoch: 5| Step: 1
Training loss: 2.900064263782757
Validation loss: 2.587115090630135

Epoch: 5| Step: 2
Training loss: 2.665046219416004
Validation loss: 2.5805531432809965

Epoch: 5| Step: 3
Training loss: 3.484733939392925
Validation loss: 2.586008447959459

Epoch: 5| Step: 4
Training loss: 2.4582895716850803
Validation loss: 2.5855535297665635

Epoch: 5| Step: 5
Training loss: 2.7885794768954324
Validation loss: 2.5796296264407936

Epoch: 5| Step: 6
Training loss: 2.593510260475444
Validation loss: 2.587407578723072

Epoch: 5| Step: 7
Training loss: 2.384527271053213
Validation loss: 2.581710265529796

Epoch: 5| Step: 8
Training loss: 2.396215148576822
Validation loss: 2.5850899334704702

Epoch: 5| Step: 9
Training loss: 2.833003604626744
Validation loss: 2.578626342434396

Epoch: 5| Step: 10
Training loss: 2.5362719415774997
Validation loss: 2.5879084225872844

Epoch: 77| Step: 0
Training loss: 2.756130234934069
Validation loss: 2.587408951000624

Epoch: 5| Step: 1
Training loss: 2.221198973576772
Validation loss: 2.5763664923109975

Epoch: 5| Step: 2
Training loss: 2.319460420179139
Validation loss: 2.5759613524040117

Epoch: 5| Step: 3
Training loss: 1.6726371240212787
Validation loss: 2.593126231134854

Epoch: 5| Step: 4
Training loss: 2.4762268801692535
Validation loss: 2.5903451921908194

Epoch: 5| Step: 5
Training loss: 3.508811213792102
Validation loss: 2.5866676942597886

Epoch: 5| Step: 6
Training loss: 2.920052352592728
Validation loss: 2.5740827684816394

Epoch: 5| Step: 7
Training loss: 2.7504696878393595
Validation loss: 2.5772647400646163

Epoch: 5| Step: 8
Training loss: 3.071191559958679
Validation loss: 2.5867378580762357

Epoch: 5| Step: 9
Training loss: 2.717562010337445
Validation loss: 2.5754131046300683

Epoch: 5| Step: 10
Training loss: 3.32654444455344
Validation loss: 2.5700945988264845

Epoch: 78| Step: 0
Training loss: 2.4678397130123937
Validation loss: 2.580858572152216

Epoch: 5| Step: 1
Training loss: 2.6385249528281474
Validation loss: 2.5694158447353113

Epoch: 5| Step: 2
Training loss: 3.160598327874191
Validation loss: 2.570313728801754

Epoch: 5| Step: 3
Training loss: 2.912939924160816
Validation loss: 2.5772488066907577

Epoch: 5| Step: 4
Training loss: 2.497182689132706
Validation loss: 2.582214783826178

Epoch: 5| Step: 5
Training loss: 2.90620602810317
Validation loss: 2.579736532457103

Epoch: 5| Step: 6
Training loss: 2.788563745178742
Validation loss: 2.567801944425969

Epoch: 5| Step: 7
Training loss: 2.3091648899247286
Validation loss: 2.5782450926731584

Epoch: 5| Step: 8
Training loss: 2.7005664866949783
Validation loss: 2.570035109899596

Epoch: 5| Step: 9
Training loss: 2.812313751835564
Validation loss: 2.5870121006088076

Epoch: 5| Step: 10
Training loss: 2.948962148656952
Validation loss: 2.5638458875338186

Epoch: 79| Step: 0
Training loss: 2.258249207603664
Validation loss: 2.5819043273544606

Epoch: 5| Step: 1
Training loss: 2.6124727056072232
Validation loss: 2.5835520353704515

Epoch: 5| Step: 2
Training loss: 2.2776818785082913
Validation loss: 2.5761920637366695

Epoch: 5| Step: 3
Training loss: 2.872759900001077
Validation loss: 2.5918994078404354

Epoch: 5| Step: 4
Training loss: 2.8887106665224143
Validation loss: 2.575161582304681

Epoch: 5| Step: 5
Training loss: 2.9935459011643584
Validation loss: 2.5976908822487763

Epoch: 5| Step: 6
Training loss: 2.7685304025059234
Validation loss: 2.588664609885862

Epoch: 5| Step: 7
Training loss: 2.3857189025866865
Validation loss: 2.589614827607685

Epoch: 5| Step: 8
Training loss: 3.1816903819390467
Validation loss: 2.591713942498948

Epoch: 5| Step: 9
Training loss: 2.490967072050638
Validation loss: 2.59066324739037

Epoch: 5| Step: 10
Training loss: 3.213501437948833
Validation loss: 2.5813092059968774

Epoch: 80| Step: 0
Training loss: 3.0899304788910515
Validation loss: 2.5670862951819067

Epoch: 5| Step: 1
Training loss: 3.062605096998889
Validation loss: 2.573606401544647

Epoch: 5| Step: 2
Training loss: 2.7564646423219976
Validation loss: 2.5789458319572396

Epoch: 5| Step: 3
Training loss: 2.825456234710624
Validation loss: 2.563236306865671

Epoch: 5| Step: 4
Training loss: 2.6100378964767774
Validation loss: 2.586128477886198

Epoch: 5| Step: 5
Training loss: 3.2547070089223427
Validation loss: 2.5811300762977356

Epoch: 5| Step: 6
Training loss: 2.322693293712649
Validation loss: 2.5702271536927888

Epoch: 5| Step: 7
Training loss: 2.1618470236960627
Validation loss: 2.584671835491538

Epoch: 5| Step: 8
Training loss: 1.8128350046934618
Validation loss: 2.561739439787033

Epoch: 5| Step: 9
Training loss: 2.7751260264879187
Validation loss: 2.577715873884029

Epoch: 5| Step: 10
Training loss: 3.131377464639133
Validation loss: 2.574221339314642

Epoch: 81| Step: 0
Training loss: 2.676897470476568
Validation loss: 2.581748729133407

Epoch: 5| Step: 1
Training loss: 3.5755938110164855
Validation loss: 2.577808468834805

Epoch: 5| Step: 2
Training loss: 2.4930647020753653
Validation loss: 2.566286971900489

Epoch: 5| Step: 3
Training loss: 2.340398502977747
Validation loss: 2.571103813483303

Epoch: 5| Step: 4
Training loss: 2.197195528395787
Validation loss: 2.576224754973928

Epoch: 5| Step: 5
Training loss: 2.928406946700441
Validation loss: 2.5795875336209924

Epoch: 5| Step: 6
Training loss: 2.7872414507511105
Validation loss: 2.5821650812009804

Epoch: 5| Step: 7
Training loss: 2.3723625797714614
Validation loss: 2.58380573239208

Epoch: 5| Step: 8
Training loss: 2.924498823218159
Validation loss: 2.574675293554765

Epoch: 5| Step: 9
Training loss: 3.0024744001912342
Validation loss: 2.577367677949195

Epoch: 5| Step: 10
Training loss: 2.3007473643581187
Validation loss: 2.5811451087009405

Epoch: 82| Step: 0
Training loss: 2.435375363598206
Validation loss: 2.5814109229473723

Epoch: 5| Step: 1
Training loss: 2.7820341740640786
Validation loss: 2.5773685124805517

Epoch: 5| Step: 2
Training loss: 2.6345708844358673
Validation loss: 2.573036436837354

Epoch: 5| Step: 3
Training loss: 2.0860259648112485
Validation loss: 2.5646676220465117

Epoch: 5| Step: 4
Training loss: 2.8953551485365705
Validation loss: 2.5660776024741043

Epoch: 5| Step: 5
Training loss: 2.7536146510069694
Validation loss: 2.5876957311319364

Epoch: 5| Step: 6
Training loss: 3.025068449396667
Validation loss: 2.587477791336037

Epoch: 5| Step: 7
Training loss: 2.4090472719614535
Validation loss: 2.5899505937179366

Epoch: 5| Step: 8
Training loss: 2.4349228366163636
Validation loss: 2.5727618893590862

Epoch: 5| Step: 9
Training loss: 3.4153879765727315
Validation loss: 2.586055615983648

Epoch: 5| Step: 10
Training loss: 2.93706785229244
Validation loss: 2.5680914112204336

Epoch: 83| Step: 0
Training loss: 2.888804094178672
Validation loss: 2.5827608165472364

Epoch: 5| Step: 1
Training loss: 3.4638352501523153
Validation loss: 2.5754027929614427

Epoch: 5| Step: 2
Training loss: 2.621902545697868
Validation loss: 2.5693135241947047

Epoch: 5| Step: 3
Training loss: 2.259610842561293
Validation loss: 2.573028681250027

Epoch: 5| Step: 4
Training loss: 2.5143959407517538
Validation loss: 2.5632919210337164

Epoch: 5| Step: 5
Training loss: 3.0007647493281686
Validation loss: 2.5765492426286425

Epoch: 5| Step: 6
Training loss: 3.148341629423968
Validation loss: 2.5812670243649896

Epoch: 5| Step: 7
Training loss: 2.064526342791626
Validation loss: 2.5806155289594552

Epoch: 5| Step: 8
Training loss: 2.4737796973266963
Validation loss: 2.5763187100557885

Epoch: 5| Step: 9
Training loss: 2.961975559862728
Validation loss: 2.5794698966721654

Epoch: 5| Step: 10
Training loss: 2.1778471365845653
Validation loss: 2.5913499743183985

Epoch: 84| Step: 0
Training loss: 2.632812228330151
Validation loss: 2.576828560970685

Epoch: 5| Step: 1
Training loss: 2.6880211435746637
Validation loss: 2.5664739420811724

Epoch: 5| Step: 2
Training loss: 1.9107852204503273
Validation loss: 2.5885125823355493

Epoch: 5| Step: 3
Training loss: 3.32064264787852
Validation loss: 2.5819986794422936

Epoch: 5| Step: 4
Training loss: 2.822972699462033
Validation loss: 2.576319302127723

Epoch: 5| Step: 5
Training loss: 2.2239392270079694
Validation loss: 2.5893799248244447

Epoch: 5| Step: 6
Training loss: 2.7199234458023613
Validation loss: 2.570354961143406

Epoch: 5| Step: 7
Training loss: 2.3186200581049143
Validation loss: 2.592539157119804

Epoch: 5| Step: 8
Training loss: 3.25585688526262
Validation loss: 2.5903161777599104

Epoch: 5| Step: 9
Training loss: 2.9054508546143234
Validation loss: 2.564794180223823

Epoch: 5| Step: 10
Training loss: 2.9129066936453336
Validation loss: 2.5841012930322615

Epoch: 85| Step: 0
Training loss: 3.101326037408453
Validation loss: 2.5792887547378536

Epoch: 5| Step: 1
Training loss: 3.0852020546204866
Validation loss: 2.577718565106909

Epoch: 5| Step: 2
Training loss: 2.7304883091216485
Validation loss: 2.5774760742483838

Epoch: 5| Step: 3
Training loss: 3.2894402873703004
Validation loss: 2.5680744805581095

Epoch: 5| Step: 4
Training loss: 2.148144289295828
Validation loss: 2.571495069616342

Epoch: 5| Step: 5
Training loss: 2.2367153049113355
Validation loss: 2.5707423602518538

Epoch: 5| Step: 6
Training loss: 2.0361856211302323
Validation loss: 2.573237422342421

Epoch: 5| Step: 7
Training loss: 2.614533128800991
Validation loss: 2.587681903838597

Epoch: 5| Step: 8
Training loss: 2.8299923627770562
Validation loss: 2.564438794501683

Epoch: 5| Step: 9
Training loss: 2.7130298290419668
Validation loss: 2.5799703557272564

Epoch: 5| Step: 10
Training loss: 2.749984654470457
Validation loss: 2.587195803298919

Epoch: 86| Step: 0
Training loss: 2.772639801931084
Validation loss: 2.572638455556376

Epoch: 5| Step: 1
Training loss: 2.462466294885777
Validation loss: 2.583285505610897

Epoch: 5| Step: 2
Training loss: 2.542046023548717
Validation loss: 2.5804925443400264

Epoch: 5| Step: 3
Training loss: 3.0233865580838404
Validation loss: 2.580850252018441

Epoch: 5| Step: 4
Training loss: 3.586595263024462
Validation loss: 2.5824569855793533

Epoch: 5| Step: 5
Training loss: 2.7421325504198855
Validation loss: 2.559819656260295

Epoch: 5| Step: 6
Training loss: 2.6292832261579795
Validation loss: 2.5706743507477627

Epoch: 5| Step: 7
Training loss: 2.832512923747357
Validation loss: 2.591112468420367

Epoch: 5| Step: 8
Training loss: 2.1398477744391577
Validation loss: 2.596574333095563

Epoch: 5| Step: 9
Training loss: 2.7281189768791347
Validation loss: 2.588211002466725

Epoch: 5| Step: 10
Training loss: 1.9883000760789102
Validation loss: 2.5584333061231255

Epoch: 87| Step: 0
Training loss: 2.4418444919169358
Validation loss: 2.581031643924622

Epoch: 5| Step: 1
Training loss: 2.678937000577648
Validation loss: 2.5657923527596633

Epoch: 5| Step: 2
Training loss: 2.7769334707344018
Validation loss: 2.570512097777524

Epoch: 5| Step: 3
Training loss: 3.174808442352055
Validation loss: 2.559385173868087

Epoch: 5| Step: 4
Training loss: 2.9073756509366278
Validation loss: 2.562838461248438

Epoch: 5| Step: 5
Training loss: 2.8030067444419764
Validation loss: 2.576776424641169

Epoch: 5| Step: 6
Training loss: 2.6430888221702094
Validation loss: 2.572492806615026

Epoch: 5| Step: 7
Training loss: 2.647872099262488
Validation loss: 2.5672101087804617

Epoch: 5| Step: 8
Training loss: 2.5986918973459594
Validation loss: 2.5755408806866025

Epoch: 5| Step: 9
Training loss: 2.1742034067208125
Validation loss: 2.5676837635335352

Epoch: 5| Step: 10
Training loss: 3.0205515412187856
Validation loss: 2.5730296457179667

Epoch: 88| Step: 0
Training loss: 2.5433800243159888
Validation loss: 2.559257442661294

Epoch: 5| Step: 1
Training loss: 2.711882500744724
Validation loss: 2.564808957032212

Epoch: 5| Step: 2
Training loss: 3.1932370783634676
Validation loss: 2.5510250121374987

Epoch: 5| Step: 3
Training loss: 2.453825929451215
Validation loss: 2.5835955926974083

Epoch: 5| Step: 4
Training loss: 2.993387882893905
Validation loss: 2.5671851044731553

Epoch: 5| Step: 5
Training loss: 2.7775332873089704
Validation loss: 2.5673850317595597

Epoch: 5| Step: 6
Training loss: 1.946474517239989
Validation loss: 2.5669113293739803

Epoch: 5| Step: 7
Training loss: 2.2843696479369373
Validation loss: 2.5896558902420646

Epoch: 5| Step: 8
Training loss: 2.600851425732141
Validation loss: 2.5692530143782446

Epoch: 5| Step: 9
Training loss: 3.0309426063331752
Validation loss: 2.5842424986679626

Epoch: 5| Step: 10
Training loss: 3.197056823511849
Validation loss: 2.5675965346186107

Epoch: 89| Step: 0
Training loss: 2.4252431767242557
Validation loss: 2.5688872140987

Epoch: 5| Step: 1
Training loss: 2.4095111892544883
Validation loss: 2.5600969866068586

Epoch: 5| Step: 2
Training loss: 3.200551557690877
Validation loss: 2.57763696888439

Epoch: 5| Step: 3
Training loss: 2.626042295337578
Validation loss: 2.556381618700547

Epoch: 5| Step: 4
Training loss: 2.8575859100964127
Validation loss: 2.5757411054379973

Epoch: 5| Step: 5
Training loss: 2.5741461365896714
Validation loss: 2.5700002625822256

Epoch: 5| Step: 6
Training loss: 2.1906865479969304
Validation loss: 2.5739914308876983

Epoch: 5| Step: 7
Training loss: 2.8048740845568285
Validation loss: 2.558283901294859

Epoch: 5| Step: 8
Training loss: 2.685561257063762
Validation loss: 2.568596384794458

Epoch: 5| Step: 9
Training loss: 2.77683576399451
Validation loss: 2.572967458715768

Epoch: 5| Step: 10
Training loss: 3.159126406283691
Validation loss: 2.555510478033078

Epoch: 90| Step: 0
Training loss: 2.5536335395477123
Validation loss: 2.5664733906905037

Epoch: 5| Step: 1
Training loss: 2.9657344560753645
Validation loss: 2.5580523550217293

Epoch: 5| Step: 2
Training loss: 2.8180065079526564
Validation loss: 2.5646616624269902

Epoch: 5| Step: 3
Training loss: 2.8475669982905436
Validation loss: 2.58119755506205

Epoch: 5| Step: 4
Training loss: 2.648570009590671
Validation loss: 2.5422424304421054

Epoch: 5| Step: 5
Training loss: 2.5978777109838727
Validation loss: 2.569044873595232

Epoch: 5| Step: 6
Training loss: 2.303986523595445
Validation loss: 2.5651815076809332

Epoch: 5| Step: 7
Training loss: 2.592841391382334
Validation loss: 2.561907229729127

Epoch: 5| Step: 8
Training loss: 2.643150160537362
Validation loss: 2.571707931616649

Epoch: 5| Step: 9
Training loss: 2.8949611823291144
Validation loss: 2.5778608030780186

Epoch: 5| Step: 10
Training loss: 2.992095228719676
Validation loss: 2.560368367365052

Epoch: 91| Step: 0
Training loss: 3.1825085621708884
Validation loss: 2.5704001623602735

Epoch: 5| Step: 1
Training loss: 2.2843136008135074
Validation loss: 2.5642004251332615

Epoch: 5| Step: 2
Training loss: 2.785805389814923
Validation loss: 2.5720783751360328

Epoch: 5| Step: 3
Training loss: 2.9372256536407404
Validation loss: 2.5787046564552814

Epoch: 5| Step: 4
Training loss: 2.7803868872565864
Validation loss: 2.58562302381947

Epoch: 5| Step: 5
Training loss: 2.760658416718524
Validation loss: 2.5751799138575295

Epoch: 5| Step: 6
Training loss: 2.3412847141802304
Validation loss: 2.5640977175028237

Epoch: 5| Step: 7
Training loss: 2.194211744962682
Validation loss: 2.57439277901324

Epoch: 5| Step: 8
Training loss: 3.0841238365989034
Validation loss: 2.5569079008630697

Epoch: 5| Step: 9
Training loss: 2.7106356493965205
Validation loss: 2.557515054497124

Epoch: 5| Step: 10
Training loss: 2.4519967564348235
Validation loss: 2.5686567024853226

Epoch: 92| Step: 0
Training loss: 2.144807613610567
Validation loss: 2.55409840147617

Epoch: 5| Step: 1
Training loss: 3.3597846202847808
Validation loss: 2.559313079182299

Epoch: 5| Step: 2
Training loss: 3.174899608797094
Validation loss: 2.575391965615179

Epoch: 5| Step: 3
Training loss: 2.489855114348624
Validation loss: 2.5568722088789078

Epoch: 5| Step: 4
Training loss: 2.6837346513342135
Validation loss: 2.5574177481459475

Epoch: 5| Step: 5
Training loss: 2.2207476796802963
Validation loss: 2.5621246945445795

Epoch: 5| Step: 6
Training loss: 2.8194648123904837
Validation loss: 2.5633531296288043

Epoch: 5| Step: 7
Training loss: 2.5425068659956955
Validation loss: 2.5798680528287434

Epoch: 5| Step: 8
Training loss: 2.945237055047489
Validation loss: 2.5583730901036867

Epoch: 5| Step: 9
Training loss: 2.5577934586009037
Validation loss: 2.5553561800594933

Epoch: 5| Step: 10
Training loss: 2.6014239300089184
Validation loss: 2.5792399481819475

Epoch: 93| Step: 0
Training loss: 3.210954726421248
Validation loss: 2.581066681996874

Epoch: 5| Step: 1
Training loss: 2.2620895687890257
Validation loss: 2.5690407662503585

Epoch: 5| Step: 2
Training loss: 3.1300234282472954
Validation loss: 2.5623474060653106

Epoch: 5| Step: 3
Training loss: 2.3687373460416565
Validation loss: 2.598914133203596

Epoch: 5| Step: 4
Training loss: 2.437618546170779
Validation loss: 2.5732040769514035

Epoch: 5| Step: 5
Training loss: 2.5300680155903286
Validation loss: 2.5721596294152254

Epoch: 5| Step: 6
Training loss: 2.919403826326854
Validation loss: 2.5645145867842847

Epoch: 5| Step: 7
Training loss: 2.86096980744917
Validation loss: 2.548366009282417

Epoch: 5| Step: 8
Training loss: 2.5877268152754467
Validation loss: 2.550721036256873

Epoch: 5| Step: 9
Training loss: 2.3976298907817624
Validation loss: 2.568706835903151

Epoch: 5| Step: 10
Training loss: 2.8108018622930047
Validation loss: 2.5647680338554024

Epoch: 94| Step: 0
Training loss: 2.5349681531722754
Validation loss: 2.5652615972921753

Epoch: 5| Step: 1
Training loss: 2.7099727266072398
Validation loss: 2.568690154813619

Epoch: 5| Step: 2
Training loss: 2.3127918574733166
Validation loss: 2.5641985760363584

Epoch: 5| Step: 3
Training loss: 2.463374599305576
Validation loss: 2.572325606499429

Epoch: 5| Step: 4
Training loss: 3.1830297801368106
Validation loss: 2.5666455526752654

Epoch: 5| Step: 5
Training loss: 1.960282417697769
Validation loss: 2.57413180228989

Epoch: 5| Step: 6
Training loss: 3.0005492661240374
Validation loss: 2.5656378897503926

Epoch: 5| Step: 7
Training loss: 2.6820899270248098
Validation loss: 2.5598518315140057

Epoch: 5| Step: 8
Training loss: 3.0072077948345166
Validation loss: 2.5669212237316605

Epoch: 5| Step: 9
Training loss: 2.8324654502815343
Validation loss: 2.577327897644643

Epoch: 5| Step: 10
Training loss: 2.811106612168818
Validation loss: 2.5627082702053086

Epoch: 95| Step: 0
Training loss: 3.252018668399168
Validation loss: 2.561321753004276

Epoch: 5| Step: 1
Training loss: 2.857810003864581
Validation loss: 2.5712358347483795

Epoch: 5| Step: 2
Training loss: 2.924321909498182
Validation loss: 2.569421482029769

Epoch: 5| Step: 3
Training loss: 3.0747434369494906
Validation loss: 2.5790431252600836

Epoch: 5| Step: 4
Training loss: 2.134898412820325
Validation loss: 2.569039769350066

Epoch: 5| Step: 5
Training loss: 2.8650602926198045
Validation loss: 2.5569721588145318

Epoch: 5| Step: 6
Training loss: 2.8759238375897054
Validation loss: 2.563521802996213

Epoch: 5| Step: 7
Training loss: 2.6350419653893167
Validation loss: 2.5623778987660195

Epoch: 5| Step: 8
Training loss: 2.0912604262963668
Validation loss: 2.557105128242829

Epoch: 5| Step: 9
Training loss: 2.8728676227222074
Validation loss: 2.5860513473029516

Epoch: 5| Step: 10
Training loss: 1.5387114303552052
Validation loss: 2.546683631349322

Epoch: 96| Step: 0
Training loss: 2.382421742902265
Validation loss: 2.5758954771505183

Epoch: 5| Step: 1
Training loss: 2.8376012708430407
Validation loss: 2.573694453742872

Epoch: 5| Step: 2
Training loss: 2.2958094402346116
Validation loss: 2.5609299226391355

Epoch: 5| Step: 3
Training loss: 3.0434099888696498
Validation loss: 2.5654498353605226

Epoch: 5| Step: 4
Training loss: 2.672808389311535
Validation loss: 2.568913452267117

Epoch: 5| Step: 5
Training loss: 2.5243205601034773
Validation loss: 2.5775040232609867

Epoch: 5| Step: 6
Training loss: 2.5545147478682555
Validation loss: 2.569487259861081

Epoch: 5| Step: 7
Training loss: 2.867650963851088
Validation loss: 2.5665982906368145

Epoch: 5| Step: 8
Training loss: 2.7124379867285713
Validation loss: 2.5680317171612184

Epoch: 5| Step: 9
Training loss: 2.8781227070388193
Validation loss: 2.559222585827743

Epoch: 5| Step: 10
Training loss: 2.8766421728170655
Validation loss: 2.5657585219313637

Epoch: 97| Step: 0
Training loss: 2.0464464277669157
Validation loss: 2.570987859920832

Epoch: 5| Step: 1
Training loss: 2.289941300052105
Validation loss: 2.567783089961258

Epoch: 5| Step: 2
Training loss: 2.836159101082884
Validation loss: 2.543002444473556

Epoch: 5| Step: 3
Training loss: 2.4058094364464173
Validation loss: 2.5544002306593274

Epoch: 5| Step: 4
Training loss: 3.029744197006076
Validation loss: 2.5665839161802304

Epoch: 5| Step: 5
Training loss: 3.263560249250545
Validation loss: 2.564580630419153

Epoch: 5| Step: 6
Training loss: 2.697011484027609
Validation loss: 2.5819385835800164

Epoch: 5| Step: 7
Training loss: 2.4202850044713022
Validation loss: 2.575547604466457

Epoch: 5| Step: 8
Training loss: 2.8105061563242177
Validation loss: 2.5645704246409307

Epoch: 5| Step: 9
Training loss: 2.9497399684290233
Validation loss: 2.5604643821216855

Epoch: 5| Step: 10
Training loss: 2.62156143223014
Validation loss: 2.559626295774051

Epoch: 98| Step: 0
Training loss: 3.066367373857862
Validation loss: 2.5552518999553953

Epoch: 5| Step: 1
Training loss: 2.8369891946268826
Validation loss: 2.5539231978565913

Epoch: 5| Step: 2
Training loss: 2.02531811134657
Validation loss: 2.559056731638001

Epoch: 5| Step: 3
Training loss: 2.747534340113652
Validation loss: 2.571659427790247

Epoch: 5| Step: 4
Training loss: 2.7522707147406917
Validation loss: 2.554675142814577

Epoch: 5| Step: 5
Training loss: 2.554202625795257
Validation loss: 2.5742226708188873

Epoch: 5| Step: 6
Training loss: 2.677606603243766
Validation loss: 2.560406856203842

Epoch: 5| Step: 7
Training loss: 2.4316827854653282
Validation loss: 2.566001149009872

Epoch: 5| Step: 8
Training loss: 2.83570982804691
Validation loss: 2.568078788104541

Epoch: 5| Step: 9
Training loss: 2.3569334420156105
Validation loss: 2.5571274069412695

Epoch: 5| Step: 10
Training loss: 3.0910308910789768
Validation loss: 2.581125574008896

Epoch: 99| Step: 0
Training loss: 1.7691184398147026
Validation loss: 2.5602210991598695

Epoch: 5| Step: 1
Training loss: 2.8462019190624384
Validation loss: 2.5719638265918334

Epoch: 5| Step: 2
Training loss: 2.636125783295483
Validation loss: 2.585205147912967

Epoch: 5| Step: 3
Training loss: 2.531346731339165
Validation loss: 2.5549641753178096

Epoch: 5| Step: 4
Training loss: 2.4136652449865448
Validation loss: 2.561887484302215

Epoch: 5| Step: 5
Training loss: 2.997883686010622
Validation loss: 2.565189093110501

Epoch: 5| Step: 6
Training loss: 2.6823541924062315
Validation loss: 2.5639791409020583

Epoch: 5| Step: 7
Training loss: 2.243298192346518
Validation loss: 2.5626362710090262

Epoch: 5| Step: 8
Training loss: 3.4306635065292745
Validation loss: 2.57030269051039

Epoch: 5| Step: 9
Training loss: 2.872013033101467
Validation loss: 2.552300519200557

Epoch: 5| Step: 10
Training loss: 2.7961240644748844
Validation loss: 2.5715840454697556

Epoch: 100| Step: 0
Training loss: 3.1183247798093525
Validation loss: 2.564894828959827

Epoch: 5| Step: 1
Training loss: 2.6237141320774247
Validation loss: 2.5621145115028834

Epoch: 5| Step: 2
Training loss: 3.0911822211103774
Validation loss: 2.546622178135206

Epoch: 5| Step: 3
Training loss: 3.007552653396389
Validation loss: 2.578997464187609

Epoch: 5| Step: 4
Training loss: 2.4514736764837837
Validation loss: 2.5523257189212134

Epoch: 5| Step: 5
Training loss: 2.062984178527725
Validation loss: 2.564713028454732

Epoch: 5| Step: 6
Training loss: 2.841188891417011
Validation loss: 2.558052508355966

Epoch: 5| Step: 7
Training loss: 2.740136490784476
Validation loss: 2.562752562931412

Epoch: 5| Step: 8
Training loss: 2.2221883002977
Validation loss: 2.5668761879665514

Epoch: 5| Step: 9
Training loss: 2.8022343950547537
Validation loss: 2.5689131239423837

Epoch: 5| Step: 10
Training loss: 2.3680688205719114
Validation loss: 2.5416022762760817

Epoch: 101| Step: 0
Training loss: 2.490940655050791
Validation loss: 2.565311519241009

Epoch: 5| Step: 1
Training loss: 3.236671701172653
Validation loss: 2.5628411490880656

Epoch: 5| Step: 2
Training loss: 2.349839095430592
Validation loss: 2.553678387216996

Epoch: 5| Step: 3
Training loss: 2.9129805205322756
Validation loss: 2.565254739619035

Epoch: 5| Step: 4
Training loss: 2.6485004248781676
Validation loss: 2.5740451150736905

Epoch: 5| Step: 5
Training loss: 2.6246821801474263
Validation loss: 2.5389735991483215

Epoch: 5| Step: 6
Training loss: 2.490262714299531
Validation loss: 2.5772716284480253

Epoch: 5| Step: 7
Training loss: 2.03412389655849
Validation loss: 2.57377140281719

Epoch: 5| Step: 8
Training loss: 2.772063094749023
Validation loss: 2.552105517580819

Epoch: 5| Step: 9
Training loss: 3.1089906694597986
Validation loss: 2.5489907615421243

Epoch: 5| Step: 10
Training loss: 2.6271583221728307
Validation loss: 2.5668860335216412

Epoch: 102| Step: 0
Training loss: 3.3158277674306547
Validation loss: 2.5582198907455114

Epoch: 5| Step: 1
Training loss: 2.5059093253315146
Validation loss: 2.5579661456511276

Epoch: 5| Step: 2
Training loss: 1.9840680583347865
Validation loss: 2.553397286454712

Epoch: 5| Step: 3
Training loss: 1.9714911013118674
Validation loss: 2.5669964194039663

Epoch: 5| Step: 4
Training loss: 2.9513565500519703
Validation loss: 2.5574630517138757

Epoch: 5| Step: 5
Training loss: 2.175463668684699
Validation loss: 2.5625761837643126

Epoch: 5| Step: 6
Training loss: 2.0690013260318567
Validation loss: 2.55791825419847

Epoch: 5| Step: 7
Training loss: 3.340711264571493
Validation loss: 2.552832904270607

Epoch: 5| Step: 8
Training loss: 2.947535801379695
Validation loss: 2.5464377894594374

Epoch: 5| Step: 9
Training loss: 2.7350759425246225
Validation loss: 2.5577355779327022

Epoch: 5| Step: 10
Training loss: 2.932907897991027
Validation loss: 2.5451939773508916

Epoch: 103| Step: 0
Training loss: 2.7688209472935204
Validation loss: 2.5325155837870597

Epoch: 5| Step: 1
Training loss: 2.740761062567732
Validation loss: 2.553531585545944

Epoch: 5| Step: 2
Training loss: 2.0009171052126007
Validation loss: 2.574203092558048

Epoch: 5| Step: 3
Training loss: 2.3075361847029354
Validation loss: 2.562122203070101

Epoch: 5| Step: 4
Training loss: 3.234328117583679
Validation loss: 2.556729386827198

Epoch: 5| Step: 5
Training loss: 2.6688022009861054
Validation loss: 2.5492818966971225

Epoch: 5| Step: 6
Training loss: 2.7509322753634766
Validation loss: 2.5510473389098687

Epoch: 5| Step: 7
Training loss: 2.5345232486286955
Validation loss: 2.5570566702505486

Epoch: 5| Step: 8
Training loss: 3.036357234538997
Validation loss: 2.5596753190696595

Epoch: 5| Step: 9
Training loss: 2.5512189270549532
Validation loss: 2.554504305675524

Epoch: 5| Step: 10
Training loss: 2.7446975740136894
Validation loss: 2.56269901482253

Epoch: 104| Step: 0
Training loss: 2.7456597844001656
Validation loss: 2.560593086350623

Epoch: 5| Step: 1
Training loss: 2.8128015144641343
Validation loss: 2.5472190710584366

Epoch: 5| Step: 2
Training loss: 2.2574652698502535
Validation loss: 2.545071481002709

Epoch: 5| Step: 3
Training loss: 3.155022713024765
Validation loss: 2.553938188635062

Epoch: 5| Step: 4
Training loss: 2.560816793523874
Validation loss: 2.5482931883682283

Epoch: 5| Step: 5
Training loss: 2.8686737449334676
Validation loss: 2.5534521480742063

Epoch: 5| Step: 6
Training loss: 2.757547079395122
Validation loss: 2.5450156600685996

Epoch: 5| Step: 7
Training loss: 2.653836758489574
Validation loss: 2.5488506108226723

Epoch: 5| Step: 8
Training loss: 1.8827619743690722
Validation loss: 2.5723003569143423

Epoch: 5| Step: 9
Training loss: 2.685717501681875
Validation loss: 2.575716968252695

Epoch: 5| Step: 10
Training loss: 2.7222132055518196
Validation loss: 2.549611942008408

Epoch: 105| Step: 0
Training loss: 2.185001254048631
Validation loss: 2.5456271013033622

Epoch: 5| Step: 1
Training loss: 2.956170020926901
Validation loss: 2.5478282387464484

Epoch: 5| Step: 2
Training loss: 2.9292978256474322
Validation loss: 2.5647549640697154

Epoch: 5| Step: 3
Training loss: 2.7067902693063823
Validation loss: 2.5459285114565535

Epoch: 5| Step: 4
Training loss: 2.757391532777483
Validation loss: 2.5536248486081536

Epoch: 5| Step: 5
Training loss: 2.578160511119071
Validation loss: 2.5528482258170095

Epoch: 5| Step: 6
Training loss: 2.69849859807966
Validation loss: 2.571494870227219

Epoch: 5| Step: 7
Training loss: 2.551324246198574
Validation loss: 2.5565523394163963

Epoch: 5| Step: 8
Training loss: 2.618165883764753
Validation loss: 2.5519069303446633

Epoch: 5| Step: 9
Training loss: 2.6918744702822464
Validation loss: 2.575876173354799

Epoch: 5| Step: 10
Training loss: 2.69771002686317
Validation loss: 2.551364875068173

Epoch: 106| Step: 0
Training loss: 2.288530515754445
Validation loss: 2.56604627156545

Epoch: 5| Step: 1
Training loss: 2.914926845620628
Validation loss: 2.563728008261438

Epoch: 5| Step: 2
Training loss: 2.566980863719032
Validation loss: 2.5543733556499824

Epoch: 5| Step: 3
Training loss: 2.226696773295061
Validation loss: 2.548803001716576

Epoch: 5| Step: 4
Training loss: 2.3373053892996354
Validation loss: 2.5598625057672604

Epoch: 5| Step: 5
Training loss: 2.636698495292574
Validation loss: 2.555823764426092

Epoch: 5| Step: 6
Training loss: 2.770304799163322
Validation loss: 2.5236281070226494

Epoch: 5| Step: 7
Training loss: 2.4989893777903176
Validation loss: 2.557948463451486

Epoch: 5| Step: 8
Training loss: 2.972328679286657
Validation loss: 2.5543212045992076

Epoch: 5| Step: 9
Training loss: 2.821585919854098
Validation loss: 2.5394010604915924

Epoch: 5| Step: 10
Training loss: 3.2462782457347164
Validation loss: 2.537202150459705

Epoch: 107| Step: 0
Training loss: 2.716535521386134
Validation loss: 2.549595900174474

Epoch: 5| Step: 1
Training loss: 2.6392568621707477
Validation loss: 2.5499793602568377

Epoch: 5| Step: 2
Training loss: 2.7819824968633435
Validation loss: 2.545283980387215

Epoch: 5| Step: 3
Training loss: 2.8473196576408637
Validation loss: 2.5463518996727994

Epoch: 5| Step: 4
Training loss: 2.404063135184449
Validation loss: 2.5624464636211672

Epoch: 5| Step: 5
Training loss: 2.7471662139154707
Validation loss: 2.542709903728571

Epoch: 5| Step: 6
Training loss: 3.0800140316135773
Validation loss: 2.5411397302677257

Epoch: 5| Step: 7
Training loss: 2.5822378009585916
Validation loss: 2.5498281661063387

Epoch: 5| Step: 8
Training loss: 2.843474657751052
Validation loss: 2.550375342809439

Epoch: 5| Step: 9
Training loss: 2.30602977910793
Validation loss: 2.5513510458107294

Epoch: 5| Step: 10
Training loss: 2.296852267405841
Validation loss: 2.547328257131698

Epoch: 108| Step: 0
Training loss: 2.7928148347286332
Validation loss: 2.5468710003399995

Epoch: 5| Step: 1
Training loss: 2.003651385245495
Validation loss: 2.532493772889096

Epoch: 5| Step: 2
Training loss: 2.7992544441811327
Validation loss: 2.5497215690630264

Epoch: 5| Step: 3
Training loss: 2.8711643340069433
Validation loss: 2.551563302038536

Epoch: 5| Step: 4
Training loss: 2.350402343071587
Validation loss: 2.5392955234520453

Epoch: 5| Step: 5
Training loss: 2.873842752825692
Validation loss: 2.5477210946484727

Epoch: 5| Step: 6
Training loss: 2.3594080436363125
Validation loss: 2.5306883765811214

Epoch: 5| Step: 7
Training loss: 2.5630648850984263
Validation loss: 2.5495400505979213

Epoch: 5| Step: 8
Training loss: 3.0602262191428107
Validation loss: 2.535134856206173

Epoch: 5| Step: 9
Training loss: 2.7397902571321353
Validation loss: 2.547092725631325

Epoch: 5| Step: 10
Training loss: 2.6222244302646947
Validation loss: 2.541716009461583

Epoch: 109| Step: 0
Training loss: 2.6828383891612213
Validation loss: 2.5533305579641925

Epoch: 5| Step: 1
Training loss: 2.6053528080755433
Validation loss: 2.5589437215801274

Epoch: 5| Step: 2
Training loss: 2.5794652056328093
Validation loss: 2.554534297384863

Epoch: 5| Step: 3
Training loss: 2.5280653146080536
Validation loss: 2.5567302922679915

Epoch: 5| Step: 4
Training loss: 3.04820324238673
Validation loss: 2.5216981422558216

Epoch: 5| Step: 5
Training loss: 2.181253615761632
Validation loss: 2.5455296688383564

Epoch: 5| Step: 6
Training loss: 2.7169363176663066
Validation loss: 2.5446015480782718

Epoch: 5| Step: 7
Training loss: 1.6192805801479442
Validation loss: 2.5578560175226173

Epoch: 5| Step: 8
Training loss: 3.128605098257024
Validation loss: 2.555377540497182

Epoch: 5| Step: 9
Training loss: 2.3971278687620226
Validation loss: 2.572110055669783

Epoch: 5| Step: 10
Training loss: 3.5499104018388947
Validation loss: 2.5386512189759673

Epoch: 110| Step: 0
Training loss: 1.9723961384822293
Validation loss: 2.552068993982476

Epoch: 5| Step: 1
Training loss: 2.757428366732734
Validation loss: 2.5367944181468287

Epoch: 5| Step: 2
Training loss: 3.123743338636949
Validation loss: 2.5575374258537904

Epoch: 5| Step: 3
Training loss: 2.8227222746373557
Validation loss: 2.5558844056116783

Epoch: 5| Step: 4
Training loss: 2.4439321893940105
Validation loss: 2.5469970462500324

Epoch: 5| Step: 5
Training loss: 2.7885696445829016
Validation loss: 2.569306820021103

Epoch: 5| Step: 6
Training loss: 2.3542915806221063
Validation loss: 2.542165446718202

Epoch: 5| Step: 7
Training loss: 2.695072771551358
Validation loss: 2.5557729289180493

Epoch: 5| Step: 8
Training loss: 2.7899713825139107
Validation loss: 2.5397993585135725

Epoch: 5| Step: 9
Training loss: 2.5322004817821484
Validation loss: 2.5494596556475084

Epoch: 5| Step: 10
Training loss: 2.8943872660502814
Validation loss: 2.543343600195143

Epoch: 111| Step: 0
Training loss: 2.6549593314236795
Validation loss: 2.546127233721281

Epoch: 5| Step: 1
Training loss: 3.119343177176027
Validation loss: 2.551459626023545

Epoch: 5| Step: 2
Training loss: 2.686869880083969
Validation loss: 2.533860078683823

Epoch: 5| Step: 3
Training loss: 2.6140662868766467
Validation loss: 2.554974894573963

Epoch: 5| Step: 4
Training loss: 2.49432568322857
Validation loss: 2.554238827816919

Epoch: 5| Step: 5
Training loss: 1.9001875609126955
Validation loss: 2.5565950240813096

Epoch: 5| Step: 6
Training loss: 2.5442199910191365
Validation loss: 2.5582645447762853

Epoch: 5| Step: 7
Training loss: 3.0318703557381714
Validation loss: 2.5589421682337297

Epoch: 5| Step: 8
Training loss: 2.412687138231923
Validation loss: 2.5481626817577547

Epoch: 5| Step: 9
Training loss: 2.8589210358342783
Validation loss: 2.559201132766852

Epoch: 5| Step: 10
Training loss: 2.696753252271645
Validation loss: 2.558105343980607

Epoch: 112| Step: 0
Training loss: 3.4537181776294776
Validation loss: 2.53716361324084

Epoch: 5| Step: 1
Training loss: 2.6496435249531536
Validation loss: 2.5440967575121465

Epoch: 5| Step: 2
Training loss: 2.806651923064638
Validation loss: 2.5332981312264624

Epoch: 5| Step: 3
Training loss: 2.513003861496824
Validation loss: 2.555302128822048

Epoch: 5| Step: 4
Training loss: 2.883179349223707
Validation loss: 2.5634935455306613

Epoch: 5| Step: 5
Training loss: 2.7019454940505043
Validation loss: 2.5340353001577296

Epoch: 5| Step: 6
Training loss: 2.2586258739824636
Validation loss: 2.5295447719612074

Epoch: 5| Step: 7
Training loss: 2.72337325299941
Validation loss: 2.53068385951616

Epoch: 5| Step: 8
Training loss: 2.206423731547498
Validation loss: 2.531155107310328

Epoch: 5| Step: 9
Training loss: 1.9646965563264884
Validation loss: 2.5603308892534984

Epoch: 5| Step: 10
Training loss: 2.712034855351351
Validation loss: 2.543858800405937

Epoch: 113| Step: 0
Training loss: 2.1843304150660487
Validation loss: 2.539524739914179

Epoch: 5| Step: 1
Training loss: 2.955131696680634
Validation loss: 2.5381245995972033

Epoch: 5| Step: 2
Training loss: 2.9188481120379426
Validation loss: 2.536943422173572

Epoch: 5| Step: 3
Training loss: 2.8049894292567643
Validation loss: 2.5312747055259894

Epoch: 5| Step: 4
Training loss: 2.4854452838726417
Validation loss: 2.545240298234008

Epoch: 5| Step: 5
Training loss: 2.4268068366212687
Validation loss: 2.5469976461445794

Epoch: 5| Step: 6
Training loss: 2.7888185196704245
Validation loss: 2.5427270375597293

Epoch: 5| Step: 7
Training loss: 2.331825234468223
Validation loss: 2.5602420950794986

Epoch: 5| Step: 8
Training loss: 2.5124743142404498
Validation loss: 2.531770601747708

Epoch: 5| Step: 9
Training loss: 2.9370887955519054
Validation loss: 2.537808675220909

Epoch: 5| Step: 10
Training loss: 2.7352465303324225
Validation loss: 2.5418326463034613

Epoch: 114| Step: 0
Training loss: 2.4302804106940563
Validation loss: 2.533748342261548

Epoch: 5| Step: 1
Training loss: 2.8880683108464096
Validation loss: 2.540986600686146

Epoch: 5| Step: 2
Training loss: 2.493591200282676
Validation loss: 2.556439156976014

Epoch: 5| Step: 3
Training loss: 2.7560768609367763
Validation loss: 2.5356870992583107

Epoch: 5| Step: 4
Training loss: 3.068739471106715
Validation loss: 2.526586797055074

Epoch: 5| Step: 5
Training loss: 2.493603821105526
Validation loss: 2.5474250562343665

Epoch: 5| Step: 6
Training loss: 2.70979579662932
Validation loss: 2.5534660543029863

Epoch: 5| Step: 7
Training loss: 2.524284669374874
Validation loss: 2.5329144999747504

Epoch: 5| Step: 8
Training loss: 2.695540797198509
Validation loss: 2.546190045044696

Epoch: 5| Step: 9
Training loss: 2.44977725047918
Validation loss: 2.5455650163086316

Epoch: 5| Step: 10
Training loss: 2.4948127336880166
Validation loss: 2.56692573495486

Epoch: 115| Step: 0
Training loss: 2.272450865496588
Validation loss: 2.55521837302948

Epoch: 5| Step: 1
Training loss: 2.3410474327265116
Validation loss: 2.5622466257457344

Epoch: 5| Step: 2
Training loss: 2.856249659431821
Validation loss: 2.543238858789461

Epoch: 5| Step: 3
Training loss: 2.6584515592141207
Validation loss: 2.537574480209299

Epoch: 5| Step: 4
Training loss: 2.6601519479590765
Validation loss: 2.54251927022185

Epoch: 5| Step: 5
Training loss: 3.1474822987853313
Validation loss: 2.5506788734284087

Epoch: 5| Step: 6
Training loss: 2.602514968960942
Validation loss: 2.5404231164378337

Epoch: 5| Step: 7
Training loss: 3.065544328007269
Validation loss: 2.5309266025974955

Epoch: 5| Step: 8
Training loss: 2.0515520082482936
Validation loss: 2.53511579822474

Epoch: 5| Step: 9
Training loss: 2.46322699722085
Validation loss: 2.5463898608954674

Epoch: 5| Step: 10
Training loss: 2.802487756598592
Validation loss: 2.535926047577601

Epoch: 116| Step: 0
Training loss: 3.2597542151725123
Validation loss: 2.5334746493667533

Epoch: 5| Step: 1
Training loss: 2.3928823347737995
Validation loss: 2.5542639478180793

Epoch: 5| Step: 2
Training loss: 2.6287493495967564
Validation loss: 2.5385378120187045

Epoch: 5| Step: 3
Training loss: 2.6333149506937295
Validation loss: 2.5518671710593126

Epoch: 5| Step: 4
Training loss: 2.027793760831832
Validation loss: 2.5426648464645587

Epoch: 5| Step: 5
Training loss: 2.2757908546881516
Validation loss: 2.538599144090434

Epoch: 5| Step: 6
Training loss: 2.778682766889079
Validation loss: 2.5347350444198744

Epoch: 5| Step: 7
Training loss: 2.7360620144625494
Validation loss: 2.538834893790029

Epoch: 5| Step: 8
Training loss: 2.270835934792058
Validation loss: 2.539906821644005

Epoch: 5| Step: 9
Training loss: 2.595414787908701
Validation loss: 2.539245534252004

Epoch: 5| Step: 10
Training loss: 3.292627717410735
Validation loss: 2.541432180402537

Epoch: 117| Step: 0
Training loss: 2.3028560279504076
Validation loss: 2.530120757742188

Epoch: 5| Step: 1
Training loss: 2.5514130211592585
Validation loss: 2.526430929976242

Epoch: 5| Step: 2
Training loss: 2.661850265241118
Validation loss: 2.5255587844562477

Epoch: 5| Step: 3
Training loss: 3.0270879428213213
Validation loss: 2.551378702241046

Epoch: 5| Step: 4
Training loss: 2.237764681712855
Validation loss: 2.541979516469231

Epoch: 5| Step: 5
Training loss: 2.9210814352048855
Validation loss: 2.5404040355615565

Epoch: 5| Step: 6
Training loss: 2.4759456215219355
Validation loss: 2.542226019409915

Epoch: 5| Step: 7
Training loss: 2.6070843538860777
Validation loss: 2.5555087345031717

Epoch: 5| Step: 8
Training loss: 3.157311440438112
Validation loss: 2.5458147026282436

Epoch: 5| Step: 9
Training loss: 2.2337686209390823
Validation loss: 2.539771203523944

Epoch: 5| Step: 10
Training loss: 2.5319336332991424
Validation loss: 2.5539881753291795

Epoch: 118| Step: 0
Training loss: 2.4369389793135374
Validation loss: 2.5248849046748196

Epoch: 5| Step: 1
Training loss: 2.994987432743256
Validation loss: 2.5434267370641566

Epoch: 5| Step: 2
Training loss: 2.8893500738370435
Validation loss: 2.5546374477111806

Epoch: 5| Step: 3
Training loss: 2.749375185644547
Validation loss: 2.5310561940085

Epoch: 5| Step: 4
Training loss: 2.773530770466212
Validation loss: 2.550435527522541

Epoch: 5| Step: 5
Training loss: 2.4776558854133555
Validation loss: 2.5594321954894146

Epoch: 5| Step: 6
Training loss: 2.652516332750434
Validation loss: 2.555643620815755

Epoch: 5| Step: 7
Training loss: 2.1654618899528986
Validation loss: 2.567470696707987

Epoch: 5| Step: 8
Training loss: 2.433281304399792
Validation loss: 2.540379913810771

Epoch: 5| Step: 9
Training loss: 2.7938839566674876
Validation loss: 2.5598162301515606

Epoch: 5| Step: 10
Training loss: 2.408080754570375
Validation loss: 2.5716553325963027

Epoch: 119| Step: 0
Training loss: 2.3518215302920966
Validation loss: 2.5392683911518845

Epoch: 5| Step: 1
Training loss: 2.1751699359321575
Validation loss: 2.5353590694865513

Epoch: 5| Step: 2
Training loss: 1.9743886460149367
Validation loss: 2.5489825259668635

Epoch: 5| Step: 3
Training loss: 3.1384728492630813
Validation loss: 2.522113574279755

Epoch: 5| Step: 4
Training loss: 2.492200032265463
Validation loss: 2.544017270310318

Epoch: 5| Step: 5
Training loss: 2.2821121676842124
Validation loss: 2.546710920707442

Epoch: 5| Step: 6
Training loss: 3.4411106913643694
Validation loss: 2.5359737781309497

Epoch: 5| Step: 7
Training loss: 2.4685205280515916
Validation loss: 2.527219744286303

Epoch: 5| Step: 8
Training loss: 2.441033565304533
Validation loss: 2.5367574184219928

Epoch: 5| Step: 9
Training loss: 3.2603568334644835
Validation loss: 2.538038722419247

Epoch: 5| Step: 10
Training loss: 2.680754779885764
Validation loss: 2.537679881726429

Epoch: 120| Step: 0
Training loss: 2.5960152167886728
Validation loss: 2.5565688309613788

Epoch: 5| Step: 1
Training loss: 2.833312445918863
Validation loss: 2.5255340209852397

Epoch: 5| Step: 2
Training loss: 2.6266454353378106
Validation loss: 2.538996752825613

Epoch: 5| Step: 3
Training loss: 2.618988965769009
Validation loss: 2.537477940309378

Epoch: 5| Step: 4
Training loss: 2.3935467188004846
Validation loss: 2.5441827395531376

Epoch: 5| Step: 5
Training loss: 2.7070880570169127
Validation loss: 2.5438773535001507

Epoch: 5| Step: 6
Training loss: 2.80154642588764
Validation loss: 2.5243094537344573

Epoch: 5| Step: 7
Training loss: 1.8921531617429643
Validation loss: 2.536784091991449

Epoch: 5| Step: 8
Training loss: 2.627418221635653
Validation loss: 2.540459407852852

Epoch: 5| Step: 9
Training loss: 1.8424452351437164
Validation loss: 2.5410779099293053

Epoch: 5| Step: 10
Training loss: 3.646057790477137
Validation loss: 2.55321204259686

Epoch: 121| Step: 0
Training loss: 1.8592608120260106
Validation loss: 2.517811243993477

Epoch: 5| Step: 1
Training loss: 3.018377125459405
Validation loss: 2.5218971697229087

Epoch: 5| Step: 2
Training loss: 1.818480654563509
Validation loss: 2.550507256991825

Epoch: 5| Step: 3
Training loss: 2.2599353775980386
Validation loss: 2.550562947687052

Epoch: 5| Step: 4
Training loss: 3.1474030643531363
Validation loss: 2.537529780327644

Epoch: 5| Step: 5
Training loss: 2.5369264038922905
Validation loss: 2.5384808425483407

Epoch: 5| Step: 6
Training loss: 2.5759504915775446
Validation loss: 2.548702840052261

Epoch: 5| Step: 7
Training loss: 3.1185348772915447
Validation loss: 2.5390997059307154

Epoch: 5| Step: 8
Training loss: 2.7824428443488056
Validation loss: 2.514017249544032

Epoch: 5| Step: 9
Training loss: 2.6883814940737527
Validation loss: 2.5402631330622945

Epoch: 5| Step: 10
Training loss: 2.709363408927367
Validation loss: 2.531602471109578

Epoch: 122| Step: 0
Training loss: 3.4160556867201315
Validation loss: 2.5446293483888236

Epoch: 5| Step: 1
Training loss: 2.769399707075313
Validation loss: 2.5334388913580925

Epoch: 5| Step: 2
Training loss: 2.794828891873539
Validation loss: 2.529032454053527

Epoch: 5| Step: 3
Training loss: 2.2146670962330774
Validation loss: 2.534296471907722

Epoch: 5| Step: 4
Training loss: 2.8112968414461497
Validation loss: 2.5341485251984195

Epoch: 5| Step: 5
Training loss: 1.9731971527914234
Validation loss: 2.538837151635912

Epoch: 5| Step: 6
Training loss: 2.7495162711819665
Validation loss: 2.540821214892515

Epoch: 5| Step: 7
Training loss: 2.397872609767529
Validation loss: 2.51550503633713

Epoch: 5| Step: 8
Training loss: 2.5934156638987926
Validation loss: 2.5098734200510453

Epoch: 5| Step: 9
Training loss: 2.483565864514438
Validation loss: 2.554029912134257

Epoch: 5| Step: 10
Training loss: 2.2694059196179133
Validation loss: 2.529092801004327

Epoch: 123| Step: 0
Training loss: 3.0394796756868723
Validation loss: 2.56501305039724

Epoch: 5| Step: 1
Training loss: 2.652443256112785
Validation loss: 2.5325699330632023

Epoch: 5| Step: 2
Training loss: 2.901644924227702
Validation loss: 2.5264618358704594

Epoch: 5| Step: 3
Training loss: 3.019987755302212
Validation loss: 2.531185516463785

Epoch: 5| Step: 4
Training loss: 2.844165981176029
Validation loss: 2.523032090290073

Epoch: 5| Step: 5
Training loss: 2.4547166459595053
Validation loss: 2.5396315302553782

Epoch: 5| Step: 6
Training loss: 2.3349890170768224
Validation loss: 2.546390966333739

Epoch: 5| Step: 7
Training loss: 2.9032687411329574
Validation loss: 2.5397769257962377

Epoch: 5| Step: 8
Training loss: 1.9941199410885548
Validation loss: 2.543881862254483

Epoch: 5| Step: 9
Training loss: 2.124002222415602
Validation loss: 2.5397203051160284

Epoch: 5| Step: 10
Training loss: 2.147939395383453
Validation loss: 2.539147250115451

Epoch: 124| Step: 0
Training loss: 2.5533285930612784
Validation loss: 2.5494055452605964

Epoch: 5| Step: 1
Training loss: 2.441510349343149
Validation loss: 2.551027351146648

Epoch: 5| Step: 2
Training loss: 2.728688283057218
Validation loss: 2.539622456259184

Epoch: 5| Step: 3
Training loss: 1.9712369439679025
Validation loss: 2.5312340798048885

Epoch: 5| Step: 4
Training loss: 3.2511832210806166
Validation loss: 2.552792976633759

Epoch: 5| Step: 5
Training loss: 2.8992495980005493
Validation loss: 2.535284366287532

Epoch: 5| Step: 6
Training loss: 2.3598907109187217
Validation loss: 2.544805941877636

Epoch: 5| Step: 7
Training loss: 2.658543482957378
Validation loss: 2.5212980848948954

Epoch: 5| Step: 8
Training loss: 2.640484416763272
Validation loss: 2.5193272672057856

Epoch: 5| Step: 9
Training loss: 2.6682053736119125
Validation loss: 2.535695686882032

Epoch: 5| Step: 10
Training loss: 2.460346744414837
Validation loss: 2.5170647942772906

Epoch: 125| Step: 0
Training loss: 2.6049521418767956
Validation loss: 2.52028938824362

Epoch: 5| Step: 1
Training loss: 2.161168887203148
Validation loss: 2.529368347483393

Epoch: 5| Step: 2
Training loss: 2.5416711171429136
Validation loss: 2.5390821846450558

Epoch: 5| Step: 3
Training loss: 2.3467131130903383
Validation loss: 2.524081315503883

Epoch: 5| Step: 4
Training loss: 2.7188260297996565
Validation loss: 2.554790652168436

Epoch: 5| Step: 5
Training loss: 2.685129672849315
Validation loss: 2.537857702262298

Epoch: 5| Step: 6
Training loss: 2.0851823104081717
Validation loss: 2.5376056832807636

Epoch: 5| Step: 7
Training loss: 2.3156467369799394
Validation loss: 2.5261868489167956

Epoch: 5| Step: 8
Training loss: 2.732869720296153
Validation loss: 2.519887734806686

Epoch: 5| Step: 9
Training loss: 3.453384872945452
Validation loss: 2.492826956003382

Epoch: 5| Step: 10
Training loss: 2.8406415445750324
Validation loss: 2.5192990930514823

Epoch: 126| Step: 0
Training loss: 2.3156212028029555
Validation loss: 2.5399032142446862

Epoch: 5| Step: 1
Training loss: 2.6823517925350537
Validation loss: 2.5217126414288265

Epoch: 5| Step: 2
Training loss: 2.917322375750609
Validation loss: 2.5199198827648654

Epoch: 5| Step: 3
Training loss: 2.5369268737887696
Validation loss: 2.5481051427207047

Epoch: 5| Step: 4
Training loss: 2.6884262795254616
Validation loss: 2.5556003615077874

Epoch: 5| Step: 5
Training loss: 2.4639820460681015
Validation loss: 2.5208279477330313

Epoch: 5| Step: 6
Training loss: 2.827878656775911
Validation loss: 2.534189704595286

Epoch: 5| Step: 7
Training loss: 2.905976969701842
Validation loss: 2.5230314267798617

Epoch: 5| Step: 8
Training loss: 2.548036275464693
Validation loss: 2.522299682188245

Epoch: 5| Step: 9
Training loss: 2.074166105072857
Validation loss: 2.542603477608099

Epoch: 5| Step: 10
Training loss: 2.6753505833565003
Validation loss: 2.526179045144864

Epoch: 127| Step: 0
Training loss: 2.752896517431641
Validation loss: 2.5097615932698596

Epoch: 5| Step: 1
Training loss: 2.4152237651455564
Validation loss: 2.527020256459712

Epoch: 5| Step: 2
Training loss: 2.6592687170932336
Validation loss: 2.5081847069931946

Epoch: 5| Step: 3
Training loss: 1.8375233395709611
Validation loss: 2.5274807388744933

Epoch: 5| Step: 4
Training loss: 2.27540822820444
Validation loss: 2.5232247132369263

Epoch: 5| Step: 5
Training loss: 2.7714477278562817
Validation loss: 2.533370727426072

Epoch: 5| Step: 6
Training loss: 2.4271154988221726
Validation loss: 2.536979762354998

Epoch: 5| Step: 7
Training loss: 2.666256445882725
Validation loss: 2.5275211708445844

Epoch: 5| Step: 8
Training loss: 2.5765625814295583
Validation loss: 2.525243095587921

Epoch: 5| Step: 9
Training loss: 3.291341757532993
Validation loss: 2.5381369565568233

Epoch: 5| Step: 10
Training loss: 2.9081401625991594
Validation loss: 2.528044985421873

Epoch: 128| Step: 0
Training loss: 2.7027049537597767
Validation loss: 2.559995450245239

Epoch: 5| Step: 1
Training loss: 2.4407433670392997
Validation loss: 2.5191454377762845

Epoch: 5| Step: 2
Training loss: 2.3880162185297102
Validation loss: 2.5236091993476455

Epoch: 5| Step: 3
Training loss: 2.7212075712640043
Validation loss: 2.5241504503861583

Epoch: 5| Step: 4
Training loss: 2.5290748763880435
Validation loss: 2.5406476823755644

Epoch: 5| Step: 5
Training loss: 2.737766190219828
Validation loss: 2.527143091151715

Epoch: 5| Step: 6
Training loss: 2.5555222573621883
Validation loss: 2.5201733722848356

Epoch: 5| Step: 7
Training loss: 2.1507403984028435
Validation loss: 2.5337113101966895

Epoch: 5| Step: 8
Training loss: 2.538178744936526
Validation loss: 2.5218255048096916

Epoch: 5| Step: 9
Training loss: 2.721818529631586
Validation loss: 2.527077396034403

Epoch: 5| Step: 10
Training loss: 3.0852958688178562
Validation loss: 2.5226070544083625

Epoch: 129| Step: 0
Training loss: 2.7247274174978138
Validation loss: 2.5392438754667928

Epoch: 5| Step: 1
Training loss: 2.7484350953734062
Validation loss: 2.541630503778653

Epoch: 5| Step: 2
Training loss: 2.2627016346480517
Validation loss: 2.5087159072283813

Epoch: 5| Step: 3
Training loss: 2.665564686852015
Validation loss: 2.5361325597883964

Epoch: 5| Step: 4
Training loss: 3.000340283486429
Validation loss: 2.533043897585045

Epoch: 5| Step: 5
Training loss: 2.401966691858996
Validation loss: 2.513591272686784

Epoch: 5| Step: 6
Training loss: 2.209086907365673
Validation loss: 2.524168074811292

Epoch: 5| Step: 7
Training loss: 2.5968944378984937
Validation loss: 2.522050471331789

Epoch: 5| Step: 8
Training loss: 2.7275485029374757
Validation loss: 2.541146200044366

Epoch: 5| Step: 9
Training loss: 3.0835644059757827
Validation loss: 2.5498467984264717

Epoch: 5| Step: 10
Training loss: 1.6331689618891252
Validation loss: 2.5492851398597565

Epoch: 130| Step: 0
Training loss: 2.8150232652207565
Validation loss: 2.5070450412564425

Epoch: 5| Step: 1
Training loss: 2.6523871664052883
Validation loss: 2.538717712265532

Epoch: 5| Step: 2
Training loss: 2.881932235344657
Validation loss: 2.510081572173573

Epoch: 5| Step: 3
Training loss: 1.7952938918833437
Validation loss: 2.5106552787418237

Epoch: 5| Step: 4
Training loss: 2.813231902787448
Validation loss: 2.520362023478849

Epoch: 5| Step: 5
Training loss: 2.4367085663636794
Validation loss: 2.537346107022792

Epoch: 5| Step: 6
Training loss: 1.8088217276459764
Validation loss: 2.5294793064482377

Epoch: 5| Step: 7
Training loss: 2.365796174441379
Validation loss: 2.515556259607149

Epoch: 5| Step: 8
Training loss: 2.5199500393834735
Validation loss: 2.5480566836036607

Epoch: 5| Step: 9
Training loss: 2.7702067725612363
Validation loss: 2.519685379278146

Epoch: 5| Step: 10
Training loss: 3.4200579552452512
Validation loss: 2.4989198273877116

Epoch: 131| Step: 0
Training loss: 2.626604770408765
Validation loss: 2.512912503372445

Epoch: 5| Step: 1
Training loss: 2.322563543692561
Validation loss: 2.5332458752068456

Epoch: 5| Step: 2
Training loss: 2.5085560299518357
Validation loss: 2.520021281530951

Epoch: 5| Step: 3
Training loss: 2.445740683607949
Validation loss: 2.512731567716583

Epoch: 5| Step: 4
Training loss: 2.7610784541074396
Validation loss: 2.4823562408011903

Epoch: 5| Step: 5
Training loss: 3.150342341394179
Validation loss: 2.526641188632219

Epoch: 5| Step: 6
Training loss: 2.504677497524914
Validation loss: 2.5109795727431217

Epoch: 5| Step: 7
Training loss: 2.6748410543119228
Validation loss: 2.5400812949556126

Epoch: 5| Step: 8
Training loss: 2.9560571071285935
Validation loss: 2.520547614859024

Epoch: 5| Step: 9
Training loss: 2.249042519187397
Validation loss: 2.533744906194376

Epoch: 5| Step: 10
Training loss: 1.880894043663321
Validation loss: 2.5326574057182514

Epoch: 132| Step: 0
Training loss: 2.8909179539051153
Validation loss: 2.5329449892177576

Epoch: 5| Step: 1
Training loss: 1.6957363179017764
Validation loss: 2.5147198430950466

Epoch: 5| Step: 2
Training loss: 3.0219454767949867
Validation loss: 2.525678623820841

Epoch: 5| Step: 3
Training loss: 2.255523577381487
Validation loss: 2.5171893053523253

Epoch: 5| Step: 4
Training loss: 2.5540465504549577
Validation loss: 2.530219903162085

Epoch: 5| Step: 5
Training loss: 2.337272237197179
Validation loss: 2.5164510993039935

Epoch: 5| Step: 6
Training loss: 2.720622503067858
Validation loss: 2.512263529638789

Epoch: 5| Step: 7
Training loss: 2.6611277952934356
Validation loss: 2.5211948075267037

Epoch: 5| Step: 8
Training loss: 2.908465781561586
Validation loss: 2.48645169557836

Epoch: 5| Step: 9
Training loss: 2.2414009229796843
Validation loss: 2.5239826633121947

Epoch: 5| Step: 10
Training loss: 2.9612532877551563
Validation loss: 2.5115807779131925

Epoch: 133| Step: 0
Training loss: 2.382416138749192
Validation loss: 2.4911065306000624

Epoch: 5| Step: 1
Training loss: 2.471597116237328
Validation loss: 2.5440174758838703

Epoch: 5| Step: 2
Training loss: 2.248900038679391
Validation loss: 2.5114148663785305

Epoch: 5| Step: 3
Training loss: 2.3912821346502713
Validation loss: 2.513606724298458

Epoch: 5| Step: 4
Training loss: 2.6473449433968015
Validation loss: 2.5259162231461336

Epoch: 5| Step: 5
Training loss: 2.6022165753529247
Validation loss: 2.525454461660439

Epoch: 5| Step: 6
Training loss: 3.2280695538407462
Validation loss: 2.522668037781695

Epoch: 5| Step: 7
Training loss: 2.645285562196718
Validation loss: 2.512286276398444

Epoch: 5| Step: 8
Training loss: 1.654586964723894
Validation loss: 2.515382420130281

Epoch: 5| Step: 9
Training loss: 3.19071110563447
Validation loss: 2.525298254144995

Epoch: 5| Step: 10
Training loss: 2.6103427942473387
Validation loss: 2.5214525423493157

Epoch: 134| Step: 0
Training loss: 3.0379239575309853
Validation loss: 2.522207455289702

Epoch: 5| Step: 1
Training loss: 2.122002450882254
Validation loss: 2.498447275448204

Epoch: 5| Step: 2
Training loss: 2.2346878366279377
Validation loss: 2.557781852102414

Epoch: 5| Step: 3
Training loss: 2.649309313032475
Validation loss: 2.499159039803383

Epoch: 5| Step: 4
Training loss: 3.1246578792217585
Validation loss: 2.5373439882906874

Epoch: 5| Step: 5
Training loss: 2.2947689443725356
Validation loss: 2.527522380892825

Epoch: 5| Step: 6
Training loss: 2.961088715167
Validation loss: 2.520519316018965

Epoch: 5| Step: 7
Training loss: 2.27418961815897
Validation loss: 2.5196694694445188

Epoch: 5| Step: 8
Training loss: 2.8034706132306875
Validation loss: 2.51390644637607

Epoch: 5| Step: 9
Training loss: 2.5470916094261473
Validation loss: 2.532687474947697

Epoch: 5| Step: 10
Training loss: 1.9107017440282428
Validation loss: 2.5220602946779644

Epoch: 135| Step: 0
Training loss: 2.824258342375704
Validation loss: 2.5335985573798925

Epoch: 5| Step: 1
Training loss: 2.3395323378954593
Validation loss: 2.5078579718320864

Epoch: 5| Step: 2
Training loss: 2.5244549569040156
Validation loss: 2.5091003601136657

Epoch: 5| Step: 3
Training loss: 2.441709356184336
Validation loss: 2.529108244069849

Epoch: 5| Step: 4
Training loss: 2.350649837168952
Validation loss: 2.5147765352998537

Epoch: 5| Step: 5
Training loss: 2.542140280783859
Validation loss: 2.512176992413243

Epoch: 5| Step: 6
Training loss: 2.1700899761197845
Validation loss: 2.5206915512898966

Epoch: 5| Step: 7
Training loss: 3.1738010816155544
Validation loss: 2.516361013490435

Epoch: 5| Step: 8
Training loss: 2.869201451767581
Validation loss: 2.518421129172359

Epoch: 5| Step: 9
Training loss: 2.9457800213325553
Validation loss: 2.517981817609355

Epoch: 5| Step: 10
Training loss: 1.8762655437722748
Validation loss: 2.5247872251477395

Epoch: 136| Step: 0
Training loss: 2.1440627067420146
Validation loss: 2.518155968344519

Epoch: 5| Step: 1
Training loss: 2.741635432736967
Validation loss: 2.5239700806348986

Epoch: 5| Step: 2
Training loss: 2.104437807447062
Validation loss: 2.51660454013351

Epoch: 5| Step: 3
Training loss: 2.5766177308574973
Validation loss: 2.5118499044401137

Epoch: 5| Step: 4
Training loss: 3.192598790109232
Validation loss: 2.522092065784774

Epoch: 5| Step: 5
Training loss: 2.452819999637674
Validation loss: 2.540906295800979

Epoch: 5| Step: 6
Training loss: 2.7179660763114724
Validation loss: 2.5142664552079372

Epoch: 5| Step: 7
Training loss: 2.322085541206687
Validation loss: 2.537966077922452

Epoch: 5| Step: 8
Training loss: 2.5536791943533825
Validation loss: 2.5258902873654723

Epoch: 5| Step: 9
Training loss: 3.0122881992959565
Validation loss: 2.4744875047382187

Epoch: 5| Step: 10
Training loss: 2.124605142147661
Validation loss: 2.5410438943307048

Epoch: 137| Step: 0
Training loss: 2.454343651012055
Validation loss: 2.5123250018467345

Epoch: 5| Step: 1
Training loss: 2.9995422013981985
Validation loss: 2.498924601406538

Epoch: 5| Step: 2
Training loss: 3.1349449605536432
Validation loss: 2.5224964974520323

Epoch: 5| Step: 3
Training loss: 2.449284262138438
Validation loss: 2.5458563810951036

Epoch: 5| Step: 4
Training loss: 2.1910207480732695
Validation loss: 2.5197827611021606

Epoch: 5| Step: 5
Training loss: 2.7530634029914953
Validation loss: 2.5026328077413815

Epoch: 5| Step: 6
Training loss: 2.6653971531078002
Validation loss: 2.515035187270356

Epoch: 5| Step: 7
Training loss: 2.4482608850751917
Validation loss: 2.508804581496991

Epoch: 5| Step: 8
Training loss: 2.259204686078407
Validation loss: 2.522964449962355

Epoch: 5| Step: 9
Training loss: 2.3632121430688766
Validation loss: 2.530848580791787

Epoch: 5| Step: 10
Training loss: 2.3545728912509003
Validation loss: 2.5037954601348433

Epoch: 138| Step: 0
Training loss: 2.0534471604557276
Validation loss: 2.5047867417899763

Epoch: 5| Step: 1
Training loss: 2.4703728858472753
Validation loss: 2.5197272101539547

Epoch: 5| Step: 2
Training loss: 2.6624107274235964
Validation loss: 2.5254317035710554

Epoch: 5| Step: 3
Training loss: 2.74334353345023
Validation loss: 2.5119941948376914

Epoch: 5| Step: 4
Training loss: 3.0311864472638717
Validation loss: 2.4993182442259396

Epoch: 5| Step: 5
Training loss: 2.670557332965995
Validation loss: 2.517038634883862

Epoch: 5| Step: 6
Training loss: 2.568996289551618
Validation loss: 2.538258987645409

Epoch: 5| Step: 7
Training loss: 2.7995163363569247
Validation loss: 2.5228190406920845

Epoch: 5| Step: 8
Training loss: 2.866128086536793
Validation loss: 2.503550991137341

Epoch: 5| Step: 9
Training loss: 1.8848276711168424
Validation loss: 2.5035280866730716

Epoch: 5| Step: 10
Training loss: 2.445686287388634
Validation loss: 2.507045137378455

Epoch: 139| Step: 0
Training loss: 3.194806121770253
Validation loss: 2.5050351791674017

Epoch: 5| Step: 1
Training loss: 2.6566997371738785
Validation loss: 2.501606358490968

Epoch: 5| Step: 2
Training loss: 2.4821896328101083
Validation loss: 2.504982860618635

Epoch: 5| Step: 3
Training loss: 2.3760046590765795
Validation loss: 2.517325776478881

Epoch: 5| Step: 4
Training loss: 2.578125
Validation loss: 2.5353895778673188

Epoch: 5| Step: 5
Training loss: 2.795620429113938
Validation loss: 2.510801662013899

Epoch: 5| Step: 6
Training loss: 2.6519879424107295
Validation loss: 2.522275585494684

Epoch: 5| Step: 7
Training loss: 2.172913227706436
Validation loss: 2.5012448790246804

Epoch: 5| Step: 8
Training loss: 2.525580379145728
Validation loss: 2.531684356130033

Epoch: 5| Step: 9
Training loss: 2.6124578299153343
Validation loss: 2.5264384800499133

Epoch: 5| Step: 10
Training loss: 2.1904217417586045
Validation loss: 2.5223455194444164

Epoch: 140| Step: 0
Training loss: 2.252969795204056
Validation loss: 2.4939960885588315

Epoch: 5| Step: 1
Training loss: 2.817198241219167
Validation loss: 2.5160168186136023

Epoch: 5| Step: 2
Training loss: 2.501461174251286
Validation loss: 2.4976477744783763

Epoch: 5| Step: 3
Training loss: 2.522498744514387
Validation loss: 2.5054596300826093

Epoch: 5| Step: 4
Training loss: 2.5448971422915605
Validation loss: 2.51589266525568

Epoch: 5| Step: 5
Training loss: 1.8347963073517004
Validation loss: 2.506686285161858

Epoch: 5| Step: 6
Training loss: 3.0965218505285543
Validation loss: 2.5177993564561776

Epoch: 5| Step: 7
Training loss: 2.866366151834381
Validation loss: 2.5209260349081637

Epoch: 5| Step: 8
Training loss: 2.6510608025380447
Validation loss: 2.514075574860827

Epoch: 5| Step: 9
Training loss: 2.4834092860373054
Validation loss: 2.5111308170693296

Epoch: 5| Step: 10
Training loss: 2.43747926360871
Validation loss: 2.490991428383303

Epoch: 141| Step: 0
Training loss: 2.78866719668854
Validation loss: 2.5110478871135924

Epoch: 5| Step: 1
Training loss: 2.333821030012407
Validation loss: 2.5226706088720663

Epoch: 5| Step: 2
Training loss: 2.7311334196651695
Validation loss: 2.5295174225744206

Epoch: 5| Step: 3
Training loss: 2.102549835049911
Validation loss: 2.5078041194846916

Epoch: 5| Step: 4
Training loss: 2.342888839188272
Validation loss: 2.525471127854073

Epoch: 5| Step: 5
Training loss: 2.361951721996501
Validation loss: 2.5163865584733194

Epoch: 5| Step: 6
Training loss: 2.9807805489450643
Validation loss: 2.521810610833168

Epoch: 5| Step: 7
Training loss: 1.8439916678631392
Validation loss: 2.497345713062517

Epoch: 5| Step: 8
Training loss: 2.713815002928016
Validation loss: 2.509744181269461

Epoch: 5| Step: 9
Training loss: 2.820593315367496
Validation loss: 2.5152070703321354

Epoch: 5| Step: 10
Training loss: 2.867335843190763
Validation loss: 2.5066224225826574

Epoch: 142| Step: 0
Training loss: 2.7523269345292016
Validation loss: 2.5319433261617457

Epoch: 5| Step: 1
Training loss: 2.076716813553029
Validation loss: 2.5087138940972555

Epoch: 5| Step: 2
Training loss: 2.636585192653349
Validation loss: 2.506474731003769

Epoch: 5| Step: 3
Training loss: 2.396300715316235
Validation loss: 2.520699668261987

Epoch: 5| Step: 4
Training loss: 2.6256681227780674
Validation loss: 2.482929772398452

Epoch: 5| Step: 5
Training loss: 2.7826232948645866
Validation loss: 2.5189496593201546

Epoch: 5| Step: 6
Training loss: 2.483536488801994
Validation loss: 2.5026165841107946

Epoch: 5| Step: 7
Training loss: 2.5148253502695566
Validation loss: 2.4959797538924056

Epoch: 5| Step: 8
Training loss: 2.604891826118937
Validation loss: 2.5011743822535384

Epoch: 5| Step: 9
Training loss: 2.9210752320805793
Validation loss: 2.49821425618014

Epoch: 5| Step: 10
Training loss: 2.1785053068932068
Validation loss: 2.5190082938023424

Epoch: 143| Step: 0
Training loss: 2.83679119113215
Validation loss: 2.5014438674269304

Epoch: 5| Step: 1
Training loss: 2.371564689511565
Validation loss: 2.5191612328713053

Epoch: 5| Step: 2
Training loss: 2.8920696875484726
Validation loss: 2.50067559107034

Epoch: 5| Step: 3
Training loss: 2.355039541637418
Validation loss: 2.5106831557526657

Epoch: 5| Step: 4
Training loss: 2.450644727460656
Validation loss: 2.5311743364023207

Epoch: 5| Step: 5
Training loss: 2.673664586797093
Validation loss: 2.5069527941252385

Epoch: 5| Step: 6
Training loss: 3.0997199824212167
Validation loss: 2.5000089481152603

Epoch: 5| Step: 7
Training loss: 2.346342153797171
Validation loss: 2.524764247810346

Epoch: 5| Step: 8
Training loss: 2.3544374045822383
Validation loss: 2.5119038869272914

Epoch: 5| Step: 9
Training loss: 2.2655535456471956
Validation loss: 2.5069791548852067

Epoch: 5| Step: 10
Training loss: 2.6647475807643493
Validation loss: 2.5054275835975703

Epoch: 144| Step: 0
Training loss: 2.3063385819788302
Validation loss: 2.501533292416805

Epoch: 5| Step: 1
Training loss: 2.294580468288628
Validation loss: 2.4987192021194944

Epoch: 5| Step: 2
Training loss: 2.469741718672603
Validation loss: 2.5147153401636935

Epoch: 5| Step: 3
Training loss: 2.037920986751495
Validation loss: 2.4983537057643326

Epoch: 5| Step: 4
Training loss: 2.1686535552729143
Validation loss: 2.5398111440896693

Epoch: 5| Step: 5
Training loss: 2.504232828680612
Validation loss: 2.5204654249867917

Epoch: 5| Step: 6
Training loss: 2.9810931150474813
Validation loss: 2.515639205013039

Epoch: 5| Step: 7
Training loss: 2.8094582957987684
Validation loss: 2.4889795291356953

Epoch: 5| Step: 8
Training loss: 2.744866000380781
Validation loss: 2.512469180779327

Epoch: 5| Step: 9
Training loss: 2.8042851321480264
Validation loss: 2.5179019035832177

Epoch: 5| Step: 10
Training loss: 2.896990556274233
Validation loss: 2.530687645686317

Epoch: 145| Step: 0
Training loss: 2.3979027366288808
Validation loss: 2.4860098138293636

Epoch: 5| Step: 1
Training loss: 2.5794094700655643
Validation loss: 2.477926769582758

Epoch: 5| Step: 2
Training loss: 2.902993295102683
Validation loss: 2.5041648095561704

Epoch: 5| Step: 3
Training loss: 2.3215796096629306
Validation loss: 2.4998923729730373

Epoch: 5| Step: 4
Training loss: 2.1014526792286117
Validation loss: 2.51232454571647

Epoch: 5| Step: 5
Training loss: 2.2174324099315283
Validation loss: 2.5316646691524354

Epoch: 5| Step: 6
Training loss: 2.6369183952194795
Validation loss: 2.5160640740246065

Epoch: 5| Step: 7
Training loss: 2.875330864485204
Validation loss: 2.5127966645912547

Epoch: 5| Step: 8
Training loss: 2.404067697146268
Validation loss: 2.508320610209807

Epoch: 5| Step: 9
Training loss: 2.9615337808135673
Validation loss: 2.519926653220397

Epoch: 5| Step: 10
Training loss: 2.574181424740068
Validation loss: 2.52672807767583

Epoch: 146| Step: 0
Training loss: 2.2750165247055034
Validation loss: 2.5046294162150935

Epoch: 5| Step: 1
Training loss: 3.0589594713701835
Validation loss: 2.499226698690825

Epoch: 5| Step: 2
Training loss: 2.0378815603758413
Validation loss: 2.5199460819360056

Epoch: 5| Step: 3
Training loss: 2.553287414091394
Validation loss: 2.5051307148566893

Epoch: 5| Step: 4
Training loss: 2.108919108540194
Validation loss: 2.495222251601272

Epoch: 5| Step: 5
Training loss: 2.9388762151889156
Validation loss: 2.4815688746665323

Epoch: 5| Step: 6
Training loss: 2.747320517039457
Validation loss: 2.4986594702792146

Epoch: 5| Step: 7
Training loss: 1.8466710373359674
Validation loss: 2.5021858237442562

Epoch: 5| Step: 8
Training loss: 3.0127185789721525
Validation loss: 2.489333275924985

Epoch: 5| Step: 9
Training loss: 2.1913135529358354
Validation loss: 2.5213330481291942

Epoch: 5| Step: 10
Training loss: 3.14034623004854
Validation loss: 2.5271846849691295

Epoch: 147| Step: 0
Training loss: 2.3537246041490314
Validation loss: 2.5009273706114303

Epoch: 5| Step: 1
Training loss: 2.4478537909907674
Validation loss: 2.4873171237772014

Epoch: 5| Step: 2
Training loss: 2.4942993973849985
Validation loss: 2.491263047208911

Epoch: 5| Step: 3
Training loss: 2.2030404798379086
Validation loss: 2.515017777122843

Epoch: 5| Step: 4
Training loss: 2.4779196308948506
Validation loss: 2.5026388505367145

Epoch: 5| Step: 5
Training loss: 3.1026749237446842
Validation loss: 2.5066186251200624

Epoch: 5| Step: 6
Training loss: 2.5052899659960928
Validation loss: 2.5193717456443236

Epoch: 5| Step: 7
Training loss: 2.850655858383648
Validation loss: 2.4989182295487082

Epoch: 5| Step: 8
Training loss: 2.6283963347991572
Validation loss: 2.499695045576073

Epoch: 5| Step: 9
Training loss: 1.3477905648788422
Validation loss: 2.4730782843905197

Epoch: 5| Step: 10
Training loss: 2.9625894975623766
Validation loss: 2.520035661154354

Epoch: 148| Step: 0
Training loss: 2.6278912198736024
Validation loss: 2.5042306665767944

Epoch: 5| Step: 1
Training loss: 2.690752943942359
Validation loss: 2.5251396135727844

Epoch: 5| Step: 2
Training loss: 2.645247527224181
Validation loss: 2.503097445785023

Epoch: 5| Step: 3
Training loss: 2.3794000924192398
Validation loss: 2.485165036539812

Epoch: 5| Step: 4
Training loss: 2.554556373707375
Validation loss: 2.5054290386370006

Epoch: 5| Step: 5
Training loss: 2.138082957943023
Validation loss: 2.4892494107123286

Epoch: 5| Step: 6
Training loss: 2.1441298701537295
Validation loss: 2.514804209125585

Epoch: 5| Step: 7
Training loss: 2.486204709138692
Validation loss: 2.5041691891581066

Epoch: 5| Step: 8
Training loss: 2.8570560578376747
Validation loss: 2.4951216425756684

Epoch: 5| Step: 9
Training loss: 2.65762804973505
Validation loss: 2.4966723414546252

Epoch: 5| Step: 10
Training loss: 2.7122802926663625
Validation loss: 2.5153275634153456

Epoch: 149| Step: 0
Training loss: 2.4019987525396735
Validation loss: 2.5090379393813715

Epoch: 5| Step: 1
Training loss: 2.9120666377963107
Validation loss: 2.508908731644138

Epoch: 5| Step: 2
Training loss: 2.1194765448760657
Validation loss: 2.506264176767313

Epoch: 5| Step: 3
Training loss: 2.37191833536921
Validation loss: 2.4991905501696046

Epoch: 5| Step: 4
Training loss: 2.3791873559091186
Validation loss: 2.521109677121415

Epoch: 5| Step: 5
Training loss: 2.3037991120789845
Validation loss: 2.511282010431882

Epoch: 5| Step: 6
Training loss: 2.817374096200772
Validation loss: 2.5062915410573647

Epoch: 5| Step: 7
Training loss: 2.6150804834762913
Validation loss: 2.514143090305727

Epoch: 5| Step: 8
Training loss: 2.295174728424087
Validation loss: 2.519798651907291

Epoch: 5| Step: 9
Training loss: 2.6844183530848285
Validation loss: 2.513520562248085

Epoch: 5| Step: 10
Training loss: 3.0496217524386164
Validation loss: 2.494654835622648

Epoch: 150| Step: 0
Training loss: 2.0994419900575245
Validation loss: 2.507533866076101

Epoch: 5| Step: 1
Training loss: 3.028919700689118
Validation loss: 2.514347571169388

Epoch: 5| Step: 2
Training loss: 1.9479553776394716
Validation loss: 2.5022430058587477

Epoch: 5| Step: 3
Training loss: 2.436998462430761
Validation loss: 2.49491642650655

Epoch: 5| Step: 4
Training loss: 2.480044735689606
Validation loss: 2.481745256751557

Epoch: 5| Step: 5
Training loss: 2.7376414815494456
Validation loss: 2.5058084486784464

Epoch: 5| Step: 6
Training loss: 2.2679526112633033
Validation loss: 2.496204037485932

Epoch: 5| Step: 7
Training loss: 2.785534762092844
Validation loss: 2.4886176917830025

Epoch: 5| Step: 8
Training loss: 3.0984459888921
Validation loss: 2.487140629187286

Epoch: 5| Step: 9
Training loss: 1.6768348067418424
Validation loss: 2.484069171804846

Epoch: 5| Step: 10
Training loss: 2.851784391784225
Validation loss: 2.5148734231942127

Epoch: 151| Step: 0
Training loss: 2.619801596489372
Validation loss: 2.4751777590891404

Epoch: 5| Step: 1
Training loss: 2.1661271254904224
Validation loss: 2.481185451684752

Epoch: 5| Step: 2
Training loss: 2.510090871435002
Validation loss: 2.5183176518701096

Epoch: 5| Step: 3
Training loss: 2.166358473450768
Validation loss: 2.5001303495244653

Epoch: 5| Step: 4
Training loss: 2.690225860019467
Validation loss: 2.5082483238451028

Epoch: 5| Step: 5
Training loss: 3.0123353715288683
Validation loss: 2.486384346884423

Epoch: 5| Step: 6
Training loss: 2.354471935183534
Validation loss: 2.5048589146577163

Epoch: 5| Step: 7
Training loss: 2.455583834401391
Validation loss: 2.520796068147109

Epoch: 5| Step: 8
Training loss: 2.594178497584841
Validation loss: 2.472240308362301

Epoch: 5| Step: 9
Training loss: 2.975980927129355
Validation loss: 2.487955130835746

Epoch: 5| Step: 10
Training loss: 2.327250271520866
Validation loss: 2.4903327571472986

Epoch: 152| Step: 0
Training loss: 3.432573290526573
Validation loss: 2.4851431690611996

Epoch: 5| Step: 1
Training loss: 2.619647154162329
Validation loss: 2.4906224722451906

Epoch: 5| Step: 2
Training loss: 2.323798338749997
Validation loss: 2.5242364496721676

Epoch: 5| Step: 3
Training loss: 2.8067654958195116
Validation loss: 2.4857232048658915

Epoch: 5| Step: 4
Training loss: 2.37719384309041
Validation loss: 2.5137781441237914

Epoch: 5| Step: 5
Training loss: 2.1531496841056605
Validation loss: 2.4393939655225183

Epoch: 5| Step: 6
Training loss: 2.1788122682761415
Validation loss: 2.4870819515529634

Epoch: 5| Step: 7
Training loss: 2.4113531124044516
Validation loss: 2.524556808702647

Epoch: 5| Step: 8
Training loss: 2.392560188070519
Validation loss: 2.477977132958881

Epoch: 5| Step: 9
Training loss: 2.14238405000705
Validation loss: 2.5085909837614078

Epoch: 5| Step: 10
Training loss: 2.708644985950006
Validation loss: 2.50552613554009

Epoch: 153| Step: 0
Training loss: 2.767552625367707
Validation loss: 2.494912709871

Epoch: 5| Step: 1
Training loss: 2.5413808714065325
Validation loss: 2.5130671487593483

Epoch: 5| Step: 2
Training loss: 2.3024021002783086
Validation loss: 2.494710769144944

Epoch: 5| Step: 3
Training loss: 2.278464406374816
Validation loss: 2.484844119874144

Epoch: 5| Step: 4
Training loss: 2.8304344568957456
Validation loss: 2.5035487071003604

Epoch: 5| Step: 5
Training loss: 2.6076525639698747
Validation loss: 2.488920839233286

Epoch: 5| Step: 6
Training loss: 2.468361256570487
Validation loss: 2.4681803413547487

Epoch: 5| Step: 7
Training loss: 2.6151857834533128
Validation loss: 2.528151547805044

Epoch: 5| Step: 8
Training loss: 2.72666996522749
Validation loss: 2.5231055305454824

Epoch: 5| Step: 9
Training loss: 1.8509251266083948
Validation loss: 2.503920506137022

Epoch: 5| Step: 10
Training loss: 2.6118708569379026
Validation loss: 2.483157909672414

Epoch: 154| Step: 0
Training loss: 2.263974344815854
Validation loss: 2.509058783247823

Epoch: 5| Step: 1
Training loss: 2.065866554898972
Validation loss: 2.4893648282786915

Epoch: 5| Step: 2
Training loss: 2.975930935396683
Validation loss: 2.5214042817023645

Epoch: 5| Step: 3
Training loss: 2.526968077578365
Validation loss: 2.505455334594275

Epoch: 5| Step: 4
Training loss: 2.9140649544958666
Validation loss: 2.4907621559407778

Epoch: 5| Step: 5
Training loss: 2.487470413875511
Validation loss: 2.4957714929054324

Epoch: 5| Step: 6
Training loss: 2.500955017783519
Validation loss: 2.5018912063366425

Epoch: 5| Step: 7
Training loss: 2.3640335272849753
Validation loss: 2.4968883017467336

Epoch: 5| Step: 8
Training loss: 2.621637825133257
Validation loss: 2.490734254617714

Epoch: 5| Step: 9
Training loss: 2.7890777160058504
Validation loss: 2.4816110892667966

Epoch: 5| Step: 10
Training loss: 1.946370216434797
Validation loss: 2.5154516809672742

Epoch: 155| Step: 0
Training loss: 2.2376630372047774
Validation loss: 2.4769241515620477

Epoch: 5| Step: 1
Training loss: 2.1801212658532743
Validation loss: 2.4996113290448294

Epoch: 5| Step: 2
Training loss: 2.8168035853888833
Validation loss: 2.5039225712429296

Epoch: 5| Step: 3
Training loss: 1.9416029156982446
Validation loss: 2.506348313436918

Epoch: 5| Step: 4
Training loss: 2.5893794545460587
Validation loss: 2.508410372082656

Epoch: 5| Step: 5
Training loss: 3.2066972862997085
Validation loss: 2.4839423441316795

Epoch: 5| Step: 6
Training loss: 2.32568528525487
Validation loss: 2.529130968062668

Epoch: 5| Step: 7
Training loss: 2.359586289399649
Validation loss: 2.505695075632468

Epoch: 5| Step: 8
Training loss: 1.952840982767527
Validation loss: 2.4887129300887048

Epoch: 5| Step: 9
Training loss: 3.0839285576705433
Validation loss: 2.537345335105339

Epoch: 5| Step: 10
Training loss: 2.7795300255224373
Validation loss: 2.518636481683952

Epoch: 156| Step: 0
Training loss: 2.387568296084792
Validation loss: 2.4971700812645428

Epoch: 5| Step: 1
Training loss: 2.096867759453315
Validation loss: 2.5118520625371343

Epoch: 5| Step: 2
Training loss: 2.10918544341428
Validation loss: 2.484404132589914

Epoch: 5| Step: 3
Training loss: 2.2404045432795407
Validation loss: 2.4975517277586174

Epoch: 5| Step: 4
Training loss: 2.7422021066651574
Validation loss: 2.501615161488385

Epoch: 5| Step: 5
Training loss: 3.2770981452220758
Validation loss: 2.4747684650129753

Epoch: 5| Step: 6
Training loss: 2.271900614472071
Validation loss: 2.5060118009595174

Epoch: 5| Step: 7
Training loss: 2.5741652163321067
Validation loss: 2.5189815866992507

Epoch: 5| Step: 8
Training loss: 3.0537847955870743
Validation loss: 2.508977413533599

Epoch: 5| Step: 9
Training loss: 2.223448385934459
Validation loss: 2.5110530684017984

Epoch: 5| Step: 10
Training loss: 2.348972554526801
Validation loss: 2.484761488778373

Epoch: 157| Step: 0
Training loss: 2.230374469534887
Validation loss: 2.5003528879148194

Epoch: 5| Step: 1
Training loss: 2.8775270385532403
Validation loss: 2.514483726515964

Epoch: 5| Step: 2
Training loss: 2.028368975478474
Validation loss: 2.480662027182699

Epoch: 5| Step: 3
Training loss: 2.5475559377471826
Validation loss: 2.514071739709696

Epoch: 5| Step: 4
Training loss: 2.7826090717444996
Validation loss: 2.502693653998373

Epoch: 5| Step: 5
Training loss: 1.8646308281956951
Validation loss: 2.4757923426975483

Epoch: 5| Step: 6
Training loss: 2.4916683601024916
Validation loss: 2.486563241706354

Epoch: 5| Step: 7
Training loss: 2.63341716761677
Validation loss: 2.4979064461157052

Epoch: 5| Step: 8
Training loss: 2.3301638693753044
Validation loss: 2.4964119265821245

Epoch: 5| Step: 9
Training loss: 2.955470208518838
Validation loss: 2.4878986342844414

Epoch: 5| Step: 10
Training loss: 2.7064397696899203
Validation loss: 2.493625412886493

Epoch: 158| Step: 0
Training loss: 2.641933500690415
Validation loss: 2.5158141181067246

Epoch: 5| Step: 1
Training loss: 2.4200950726836408
Validation loss: 2.5088665216431534

Epoch: 5| Step: 2
Training loss: 2.3979716392157164
Validation loss: 2.4947067500791973

Epoch: 5| Step: 3
Training loss: 1.8631507300001777
Validation loss: 2.4742496386762465

Epoch: 5| Step: 4
Training loss: 2.818458602966693
Validation loss: 2.4921254755192432

Epoch: 5| Step: 5
Training loss: 2.615236107139783
Validation loss: 2.4923519738983653

Epoch: 5| Step: 6
Training loss: 2.5464421003834876
Validation loss: 2.508944711025867

Epoch: 5| Step: 7
Training loss: 2.468502177100934
Validation loss: 2.480972445862141

Epoch: 5| Step: 8
Training loss: 2.7531974583767167
Validation loss: 2.4904734530164143

Epoch: 5| Step: 9
Training loss: 2.920452077437479
Validation loss: 2.4857820837105815

Epoch: 5| Step: 10
Training loss: 1.5907313612955534
Validation loss: 2.5052120391290944

Epoch: 159| Step: 0
Training loss: 2.0444200076610013
Validation loss: 2.5007080654614238

Epoch: 5| Step: 1
Training loss: 1.8970196613786976
Validation loss: 2.496918440320812

Epoch: 5| Step: 2
Training loss: 2.7809928175069762
Validation loss: 2.4594309278680604

Epoch: 5| Step: 3
Training loss: 1.9060762670174707
Validation loss: 2.494215956625124

Epoch: 5| Step: 4
Training loss: 2.567023309064607
Validation loss: 2.445512550796824

Epoch: 5| Step: 5
Training loss: 2.546619800349424
Validation loss: 2.4599038407358296

Epoch: 5| Step: 6
Training loss: 3.3244502595464174
Validation loss: 2.494366307287923

Epoch: 5| Step: 7
Training loss: 2.73613991590421
Validation loss: 2.4944526458625993

Epoch: 5| Step: 8
Training loss: 2.418383635145235
Validation loss: 2.51011338153091

Epoch: 5| Step: 9
Training loss: 2.8070897942162394
Validation loss: 2.4882095369594532

Epoch: 5| Step: 10
Training loss: 2.2233761122828324
Validation loss: 2.492313089317068

Epoch: 160| Step: 0
Training loss: 2.026861526675029
Validation loss: 2.5246438126395003

Epoch: 5| Step: 1
Training loss: 2.5845200263849124
Validation loss: 2.499877393443774

Epoch: 5| Step: 2
Training loss: 2.268160749265642
Validation loss: 2.476169131430795

Epoch: 5| Step: 3
Training loss: 2.5683046052263836
Validation loss: 2.4724555595806463

Epoch: 5| Step: 4
Training loss: 3.170919490517575
Validation loss: 2.478804458881991

Epoch: 5| Step: 5
Training loss: 2.7034655229709927
Validation loss: 2.4948921290427126

Epoch: 5| Step: 6
Training loss: 2.7484142760075776
Validation loss: 2.4865456249886373

Epoch: 5| Step: 7
Training loss: 2.249456233968836
Validation loss: 2.49273849703611

Epoch: 5| Step: 8
Training loss: 2.395907779587385
Validation loss: 2.4842451209581213

Epoch: 5| Step: 9
Training loss: 2.5681519863393922
Validation loss: 2.4967018994071335

Epoch: 5| Step: 10
Training loss: 1.968812487382593
Validation loss: 2.4956258562217717

Epoch: 161| Step: 0
Training loss: 2.679826560457695
Validation loss: 2.490302587254942

Epoch: 5| Step: 1
Training loss: 2.6198777676963627
Validation loss: 2.495600512719617

Epoch: 5| Step: 2
Training loss: 2.4195867742092796
Validation loss: 2.5101437412434375

Epoch: 5| Step: 3
Training loss: 2.167802684025388
Validation loss: 2.4873230507246618

Epoch: 5| Step: 4
Training loss: 2.95352137897659
Validation loss: 2.5081354065666694

Epoch: 5| Step: 5
Training loss: 2.3220238331139225
Validation loss: 2.51801129340823

Epoch: 5| Step: 6
Training loss: 2.813747553169749
Validation loss: 2.528353020928711

Epoch: 5| Step: 7
Training loss: 1.9686135744328506
Validation loss: 2.52022923840219

Epoch: 5| Step: 8
Training loss: 2.675482383799779
Validation loss: 2.4834106682959103

Epoch: 5| Step: 9
Training loss: 1.950296108065109
Validation loss: 2.5186433573760105

Epoch: 5| Step: 10
Training loss: 2.7406025623547015
Validation loss: 2.5009976744610087

Epoch: 162| Step: 0
Training loss: 1.8822211765530106
Validation loss: 2.520808582257281

Epoch: 5| Step: 1
Training loss: 2.0444351680978237
Validation loss: 2.497856545120979

Epoch: 5| Step: 2
Training loss: 3.1043246098901025
Validation loss: 2.5086335545401868

Epoch: 5| Step: 3
Training loss: 2.9141256617023883
Validation loss: 2.508640694734735

Epoch: 5| Step: 4
Training loss: 2.446926473999359
Validation loss: 2.495943256371849

Epoch: 5| Step: 5
Training loss: 2.6197141379278825
Validation loss: 2.507156602688086

Epoch: 5| Step: 6
Training loss: 2.3091340183174256
Validation loss: 2.4890519584779276

Epoch: 5| Step: 7
Training loss: 2.7943340672391868
Validation loss: 2.495221294045876

Epoch: 5| Step: 8
Training loss: 2.447551445736904
Validation loss: 2.5149000322302264

Epoch: 5| Step: 9
Training loss: 2.2601358148394035
Validation loss: 2.495436129652257

Epoch: 5| Step: 10
Training loss: 2.4034780414134516
Validation loss: 2.507641709013357

Epoch: 163| Step: 0
Training loss: 2.68140474241948
Validation loss: 2.501282602898291

Epoch: 5| Step: 1
Training loss: 2.6694867798827455
Validation loss: 2.517372496092024

Epoch: 5| Step: 2
Training loss: 2.007591502573378
Validation loss: 2.4850688885509036

Epoch: 5| Step: 3
Training loss: 2.585475546150776
Validation loss: 2.481172835887848

Epoch: 5| Step: 4
Training loss: 2.704779851560965
Validation loss: 2.445513896818814

Epoch: 5| Step: 5
Training loss: 2.1336201127336203
Validation loss: 2.4825932650843026

Epoch: 5| Step: 6
Training loss: 2.2759160429783605
Validation loss: 2.458327687755656

Epoch: 5| Step: 7
Training loss: 2.427643434351129
Validation loss: 2.476179713468433

Epoch: 5| Step: 8
Training loss: 2.211813170298336
Validation loss: 2.4755726625023837

Epoch: 5| Step: 9
Training loss: 2.8672876158653366
Validation loss: 2.4867499937154447

Epoch: 5| Step: 10
Training loss: 2.7856463713978368
Validation loss: 2.4593668618406146

Epoch: 164| Step: 0
Training loss: 2.4052401318491903
Validation loss: 2.482879425848257

Epoch: 5| Step: 1
Training loss: 2.5152115570943367
Validation loss: 2.507324572010169

Epoch: 5| Step: 2
Training loss: 1.8206317277882889
Validation loss: 2.4920623261300334

Epoch: 5| Step: 3
Training loss: 3.0468897110021462
Validation loss: 2.4690593246876316

Epoch: 5| Step: 4
Training loss: 2.6441141585666674
Validation loss: 2.477904676828909

Epoch: 5| Step: 5
Training loss: 2.2811958620101103
Validation loss: 2.485824243778083

Epoch: 5| Step: 6
Training loss: 2.467350623528458
Validation loss: 2.505234488684418

Epoch: 5| Step: 7
Training loss: 2.4269569484128604
Validation loss: 2.4958111391839384

Epoch: 5| Step: 8
Training loss: 2.425071034914966
Validation loss: 2.4754329170606

Epoch: 5| Step: 9
Training loss: 2.6363980924812123
Validation loss: 2.473978244116322

Epoch: 5| Step: 10
Training loss: 2.6753319578885724
Validation loss: 2.5155568710759595

Epoch: 165| Step: 0
Training loss: 2.457471944468364
Validation loss: 2.500821713283288

Epoch: 5| Step: 1
Training loss: 2.273224915728
Validation loss: 2.4783136557071566

Epoch: 5| Step: 2
Training loss: 2.303417308378859
Validation loss: 2.504483125648482

Epoch: 5| Step: 3
Training loss: 2.5808456399747564
Validation loss: 2.46632251785961

Epoch: 5| Step: 4
Training loss: 2.72841338810563
Validation loss: 2.4896816550550804

Epoch: 5| Step: 5
Training loss: 1.9883643472090815
Validation loss: 2.495323751416783

Epoch: 5| Step: 6
Training loss: 2.803712978382225
Validation loss: 2.4947689991422015

Epoch: 5| Step: 7
Training loss: 2.634686897973648
Validation loss: 2.4840418393002226

Epoch: 5| Step: 8
Training loss: 2.893212227667326
Validation loss: 2.4883590569912597

Epoch: 5| Step: 9
Training loss: 2.445912832845125
Validation loss: 2.498527384365684

Epoch: 5| Step: 10
Training loss: 2.0454553238067685
Validation loss: 2.5253422853067518

Epoch: 166| Step: 0
Training loss: 2.303590778679333
Validation loss: 2.4911607171490004

Epoch: 5| Step: 1
Training loss: 2.885821170661919
Validation loss: 2.483179247460397

Epoch: 5| Step: 2
Training loss: 2.4165156964029664
Validation loss: 2.4672417717591113

Epoch: 5| Step: 3
Training loss: 2.0137026587426328
Validation loss: 2.5105555230490837

Epoch: 5| Step: 4
Training loss: 2.7272768150645748
Validation loss: 2.488126255170915

Epoch: 5| Step: 5
Training loss: 2.4064681709763716
Validation loss: 2.485662105116402

Epoch: 5| Step: 6
Training loss: 2.7240149721246714
Validation loss: 2.4825385626279424

Epoch: 5| Step: 7
Training loss: 1.8980629005862555
Validation loss: 2.505635141244476

Epoch: 5| Step: 8
Training loss: 2.6592870964467386
Validation loss: 2.4985392784324443

Epoch: 5| Step: 9
Training loss: 2.767228949143225
Validation loss: 2.4978471715747275

Epoch: 5| Step: 10
Training loss: 2.3291185550349733
Validation loss: 2.4620214853427607

Epoch: 167| Step: 0
Training loss: 2.4775890064129857
Validation loss: 2.443247127078491

Epoch: 5| Step: 1
Training loss: 2.6129761476417137
Validation loss: 2.497441234434925

Epoch: 5| Step: 2
Training loss: 2.1150889676908533
Validation loss: 2.505689744631154

Epoch: 5| Step: 3
Training loss: 2.3173886768059493
Validation loss: 2.489127471401124

Epoch: 5| Step: 4
Training loss: 2.9337476748378855
Validation loss: 2.4836291628428446

Epoch: 5| Step: 5
Training loss: 1.9556045052273423
Validation loss: 2.4931286610405623

Epoch: 5| Step: 6
Training loss: 2.595139464524408
Validation loss: 2.4898145453906078

Epoch: 5| Step: 7
Training loss: 2.146559570772552
Validation loss: 2.4433793920863947

Epoch: 5| Step: 8
Training loss: 2.8207194280423993
Validation loss: 2.4964351864413112

Epoch: 5| Step: 9
Training loss: 2.354148887184544
Validation loss: 2.4809570038668265

Epoch: 5| Step: 10
Training loss: 2.922865266318526
Validation loss: 2.478280086175242

Epoch: 168| Step: 0
Training loss: 2.6071950978160747
Validation loss: 2.4980403274652625

Epoch: 5| Step: 1
Training loss: 2.5987774945924373
Validation loss: 2.4560517230937773

Epoch: 5| Step: 2
Training loss: 2.3468682462998904
Validation loss: 2.4866702435478825

Epoch: 5| Step: 3
Training loss: 2.0049926906081454
Validation loss: 2.4753208341503687

Epoch: 5| Step: 4
Training loss: 1.9745135637804205
Validation loss: 2.475906227665015

Epoch: 5| Step: 5
Training loss: 2.8076811303859874
Validation loss: 2.449735826301175

Epoch: 5| Step: 6
Training loss: 2.6312789299251174
Validation loss: 2.496204520183245

Epoch: 5| Step: 7
Training loss: 2.794398911317733
Validation loss: 2.4721071857451333

Epoch: 5| Step: 8
Training loss: 2.03338276328785
Validation loss: 2.4787398464071932

Epoch: 5| Step: 9
Training loss: 2.6007588379554005
Validation loss: 2.4608148870151156

Epoch: 5| Step: 10
Training loss: 2.4879370530681233
Validation loss: 2.454326478844876

Epoch: 169| Step: 0
Training loss: 2.752375876861534
Validation loss: 2.475352962811257

Epoch: 5| Step: 1
Training loss: 2.5973494958094006
Validation loss: 2.4803940669799225

Epoch: 5| Step: 2
Training loss: 2.569329534716224
Validation loss: 2.4775529488444916

Epoch: 5| Step: 3
Training loss: 2.6239691935626586
Validation loss: 2.508547198169285

Epoch: 5| Step: 4
Training loss: 2.9055493238231125
Validation loss: 2.483042282061006

Epoch: 5| Step: 5
Training loss: 2.7231528925173096
Validation loss: 2.4761817199195444

Epoch: 5| Step: 6
Training loss: 2.0686430335842694
Validation loss: 2.489065323289965

Epoch: 5| Step: 7
Training loss: 1.6844513516646533
Validation loss: 2.4919074769767113

Epoch: 5| Step: 8
Training loss: 2.179586100527023
Validation loss: 2.4989977786335

Epoch: 5| Step: 9
Training loss: 2.634193216841924
Validation loss: 2.500045629310536

Epoch: 5| Step: 10
Training loss: 2.5168275032269802
Validation loss: 2.51122998536786

Epoch: 170| Step: 0
Training loss: 2.922919754675614
Validation loss: 2.4892304010223674

Epoch: 5| Step: 1
Training loss: 2.2987582213113207
Validation loss: 2.49618228519949

Epoch: 5| Step: 2
Training loss: 2.868531289001646
Validation loss: 2.4768889578756474

Epoch: 5| Step: 3
Training loss: 2.0955328112222285
Validation loss: 2.4959563038807584

Epoch: 5| Step: 4
Training loss: 2.1817116584927585
Validation loss: 2.486369189052566

Epoch: 5| Step: 5
Training loss: 2.874078520008172
Validation loss: 2.4856408773410092

Epoch: 5| Step: 6
Training loss: 2.735497816343975
Validation loss: 2.496498687320748

Epoch: 5| Step: 7
Training loss: 2.562714916613912
Validation loss: 2.4633229226701876

Epoch: 5| Step: 8
Training loss: 2.1238150939485507
Validation loss: 2.502360474469054

Epoch: 5| Step: 9
Training loss: 2.304316707460424
Validation loss: 2.50355960809737

Epoch: 5| Step: 10
Training loss: 1.9942576105996668
Validation loss: 2.500044865359454

Epoch: 171| Step: 0
Training loss: 2.8972662438274583
Validation loss: 2.506610760171155

Epoch: 5| Step: 1
Training loss: 2.2522131314016027
Validation loss: 2.4929578533488423

Epoch: 5| Step: 2
Training loss: 2.6070743857871306
Validation loss: 2.5016013216048223

Epoch: 5| Step: 3
Training loss: 2.204478828617493
Validation loss: 2.4736017310616805

Epoch: 5| Step: 4
Training loss: 2.38012002882702
Validation loss: 2.470650218478391

Epoch: 5| Step: 5
Training loss: 2.2761361272023395
Validation loss: 2.5132536496178206

Epoch: 5| Step: 6
Training loss: 2.315512370512061
Validation loss: 2.4969014356961923

Epoch: 5| Step: 7
Training loss: 2.207377124792483
Validation loss: 2.516903964297336

Epoch: 5| Step: 8
Training loss: 2.677480339170446
Validation loss: 2.474385706067947

Epoch: 5| Step: 9
Training loss: 2.9904241321036995
Validation loss: 2.4843181599219597

Epoch: 5| Step: 10
Training loss: 2.242698265675581
Validation loss: 2.4777162813886715

Epoch: 172| Step: 0
Training loss: 2.9383490126853755
Validation loss: 2.5062113887838486

Epoch: 5| Step: 1
Training loss: 2.332098316141998
Validation loss: 2.5110377715746934

Epoch: 5| Step: 2
Training loss: 1.9535000860537883
Validation loss: 2.4932973594772747

Epoch: 5| Step: 3
Training loss: 2.3768773940598664
Validation loss: 2.4948498992285857

Epoch: 5| Step: 4
Training loss: 2.3299836797511038
Validation loss: 2.472056221590023

Epoch: 5| Step: 5
Training loss: 2.213667084375882
Validation loss: 2.4964628997928098

Epoch: 5| Step: 6
Training loss: 2.427995196669225
Validation loss: 2.472494021321935

Epoch: 5| Step: 7
Training loss: 2.65269465646344
Validation loss: 2.4815100766469156

Epoch: 5| Step: 8
Training loss: 2.6401619589861784
Validation loss: 2.4856367528484085

Epoch: 5| Step: 9
Training loss: 2.7161632816465024
Validation loss: 2.519887712424699

Epoch: 5| Step: 10
Training loss: 2.3478359972396032
Validation loss: 2.4782779024641286

Epoch: 173| Step: 0
Training loss: 2.215145568197644
Validation loss: 2.4992658911392045

Epoch: 5| Step: 1
Training loss: 2.545360559579994
Validation loss: 2.496168459869429

Epoch: 5| Step: 2
Training loss: 1.6726695516770986
Validation loss: 2.461704308784279

Epoch: 5| Step: 3
Training loss: 2.0460035492837347
Validation loss: 2.5114982690783085

Epoch: 5| Step: 4
Training loss: 3.032358969532628
Validation loss: 2.472697269465122

Epoch: 5| Step: 5
Training loss: 2.6171904151103167
Validation loss: 2.510352147704272

Epoch: 5| Step: 6
Training loss: 2.5201282828845883
Validation loss: 2.4840024644430168

Epoch: 5| Step: 7
Training loss: 2.3287727427741403
Validation loss: 2.49825506431509

Epoch: 5| Step: 8
Training loss: 2.78352066102539
Validation loss: 2.4937971113694894

Epoch: 5| Step: 9
Training loss: 2.5284840106092696
Validation loss: 2.447592062669336

Epoch: 5| Step: 10
Training loss: 2.415680870604293
Validation loss: 2.460352646202126

Epoch: 174| Step: 0
Training loss: 1.7269341944718486
Validation loss: 2.478588590770788

Epoch: 5| Step: 1
Training loss: 2.2663718209450816
Validation loss: 2.4798516667752266

Epoch: 5| Step: 2
Training loss: 2.1853944727010397
Validation loss: 2.464446206763405

Epoch: 5| Step: 3
Training loss: 2.956714204952942
Validation loss: 2.4671722828732574

Epoch: 5| Step: 4
Training loss: 2.7053086826385218
Validation loss: 2.5050992561829712

Epoch: 5| Step: 5
Training loss: 2.2419143138168387
Validation loss: 2.4336093134462975

Epoch: 5| Step: 6
Training loss: 2.2919669099120066
Validation loss: 2.4879567877517887

Epoch: 5| Step: 7
Training loss: 2.744248531297025
Validation loss: 2.4629806961775227

Epoch: 5| Step: 8
Training loss: 2.340088896733776
Validation loss: 2.476913634805698

Epoch: 5| Step: 9
Training loss: 2.204241746898913
Validation loss: 2.4754552840486537

Epoch: 5| Step: 10
Training loss: 3.2288748004229957
Validation loss: 2.454222550199763

Epoch: 175| Step: 0
Training loss: 2.4550463690331354
Validation loss: 2.492976653627118

Epoch: 5| Step: 1
Training loss: 2.5446637623628523
Validation loss: 2.46566436323167

Epoch: 5| Step: 2
Training loss: 2.149491263237621
Validation loss: 2.4351925020623386

Epoch: 5| Step: 3
Training loss: 2.080987550609329
Validation loss: 2.4602964286025926

Epoch: 5| Step: 4
Training loss: 2.5771707329286158
Validation loss: 2.4835105636058437

Epoch: 5| Step: 5
Training loss: 2.571537919974105
Validation loss: 2.510010284862292

Epoch: 5| Step: 6
Training loss: 2.4241788673377975
Validation loss: 2.476610463197695

Epoch: 5| Step: 7
Training loss: 2.2656626731108136
Validation loss: 2.4450871822683258

Epoch: 5| Step: 8
Training loss: 2.5421913939424505
Validation loss: 2.5100384662509283

Epoch: 5| Step: 9
Training loss: 2.6860193121379865
Validation loss: 2.517381245993794

Epoch: 5| Step: 10
Training loss: 2.739047608495556
Validation loss: 2.4689383299294856

Epoch: 176| Step: 0
Training loss: 2.322505646566337
Validation loss: 2.5134078716302106

Epoch: 5| Step: 1
Training loss: 2.6935380042400823
Validation loss: 2.4745107158214474

Epoch: 5| Step: 2
Training loss: 2.5772193011406452
Validation loss: 2.4657159003398337

Epoch: 5| Step: 3
Training loss: 2.7187298302614797
Validation loss: 2.4594874816032197

Epoch: 5| Step: 4
Training loss: 1.9115330389601575
Validation loss: 2.514411718781665

Epoch: 5| Step: 5
Training loss: 2.2246563163808433
Validation loss: 2.509416331793895

Epoch: 5| Step: 6
Training loss: 2.615407400981329
Validation loss: 2.4679016799101765

Epoch: 5| Step: 7
Training loss: 2.5615059389890305
Validation loss: 2.4705406165676274

Epoch: 5| Step: 8
Training loss: 2.373735693656955
Validation loss: 2.4999126767730604

Epoch: 5| Step: 9
Training loss: 2.2935737188719587
Validation loss: 2.4894741925329162

Epoch: 5| Step: 10
Training loss: 2.6597702037532645
Validation loss: 2.4549985134530523

Epoch: 177| Step: 0
Training loss: 2.8123445255963673
Validation loss: 2.4739710095808896

Epoch: 5| Step: 1
Training loss: 2.0445387225366165
Validation loss: 2.468152677612208

Epoch: 5| Step: 2
Training loss: 2.084063198668923
Validation loss: 2.461491430405332

Epoch: 5| Step: 3
Training loss: 2.8536356039757984
Validation loss: 2.462315035975094

Epoch: 5| Step: 4
Training loss: 2.0602416187546853
Validation loss: 2.4688550086408982

Epoch: 5| Step: 5
Training loss: 3.060976233244597
Validation loss: 2.47013859438929

Epoch: 5| Step: 6
Training loss: 2.5461364798692734
Validation loss: 2.462377886307769

Epoch: 5| Step: 7
Training loss: 2.535144776493201
Validation loss: 2.452186588390417

Epoch: 5| Step: 8
Training loss: 2.404345464641528
Validation loss: 2.4879155335113836

Epoch: 5| Step: 9
Training loss: 1.5403239700840703
Validation loss: 2.462382236119865

Epoch: 5| Step: 10
Training loss: 2.710865998218398
Validation loss: 2.4608823604367145

Epoch: 178| Step: 0
Training loss: 2.324392001322446
Validation loss: 2.4852932036594804

Epoch: 5| Step: 1
Training loss: 2.5284916483383038
Validation loss: 2.4643216586219188

Epoch: 5| Step: 2
Training loss: 2.196608625734425
Validation loss: 2.4943789940771226

Epoch: 5| Step: 3
Training loss: 2.6868377579323934
Validation loss: 2.4816577426231476

Epoch: 5| Step: 4
Training loss: 2.774582059850103
Validation loss: 2.4715676864373295

Epoch: 5| Step: 5
Training loss: 2.393103617355688
Validation loss: 2.483158012913556

Epoch: 5| Step: 6
Training loss: 2.2347392605588476
Validation loss: 2.452986877996517

Epoch: 5| Step: 7
Training loss: 2.830012413509898
Validation loss: 2.435896521439384

Epoch: 5| Step: 8
Training loss: 2.1440609275501856
Validation loss: 2.4843567114685916

Epoch: 5| Step: 9
Training loss: 2.4967673382327535
Validation loss: 2.490729266765262

Epoch: 5| Step: 10
Training loss: 2.226708872484572
Validation loss: 2.4518435561442216

Epoch: 179| Step: 0
Training loss: 3.0167787548619027
Validation loss: 2.4537600234925137

Epoch: 5| Step: 1
Training loss: 2.6583370312353103
Validation loss: 2.459546280244201

Epoch: 5| Step: 2
Training loss: 2.5924929594645088
Validation loss: 2.478366597241018

Epoch: 5| Step: 3
Training loss: 2.3205407027209453
Validation loss: 2.490082073536841

Epoch: 5| Step: 4
Training loss: 2.1191462503525567
Validation loss: 2.4680369489531273

Epoch: 5| Step: 5
Training loss: 2.508671598554121
Validation loss: 2.5098349856791513

Epoch: 5| Step: 6
Training loss: 2.1345444797680835
Validation loss: 2.4750654315720584

Epoch: 5| Step: 7
Training loss: 2.432366859422805
Validation loss: 2.4763099761897114

Epoch: 5| Step: 8
Training loss: 1.9700566149094514
Validation loss: 2.4822425990871

Epoch: 5| Step: 9
Training loss: 2.435679807606719
Validation loss: 2.494933104544994

Epoch: 5| Step: 10
Training loss: 2.3176813588376457
Validation loss: 2.4743749469595375

Epoch: 180| Step: 0
Training loss: 2.2305128958320104
Validation loss: 2.466810363504536

Epoch: 5| Step: 1
Training loss: 2.320053342995213
Validation loss: 2.4622016499880863

Epoch: 5| Step: 2
Training loss: 2.213146063664798
Validation loss: 2.43793017564719

Epoch: 5| Step: 3
Training loss: 1.9642817336203133
Validation loss: 2.491202105970481

Epoch: 5| Step: 4
Training loss: 2.846604476118351
Validation loss: 2.492809033890558

Epoch: 5| Step: 5
Training loss: 2.0029681354107827
Validation loss: 2.476717864494617

Epoch: 5| Step: 6
Training loss: 2.287810624508349
Validation loss: 2.4688841810687023

Epoch: 5| Step: 7
Training loss: 2.0477669206771747
Validation loss: 2.458752591349423

Epoch: 5| Step: 8
Training loss: 2.7940718599825485
Validation loss: 2.4560386869705697

Epoch: 5| Step: 9
Training loss: 3.396548673647421
Validation loss: 2.477821262854258

Epoch: 5| Step: 10
Training loss: 2.086973011860452
Validation loss: 2.4856308564313716

Epoch: 181| Step: 0
Training loss: 2.4400144470287435
Validation loss: 2.4551073306035693

Epoch: 5| Step: 1
Training loss: 2.6487209652240518
Validation loss: 2.4796081838165986

Epoch: 5| Step: 2
Training loss: 1.7030172751419062
Validation loss: 2.4473586019498024

Epoch: 5| Step: 3
Training loss: 2.3717280486852124
Validation loss: 2.463359599611666

Epoch: 5| Step: 4
Training loss: 2.416976700550131
Validation loss: 2.4978470812568

Epoch: 5| Step: 5
Training loss: 2.619100571794787
Validation loss: 2.4715853787959285

Epoch: 5| Step: 6
Training loss: 2.418835707927639
Validation loss: 2.4790883202262055

Epoch: 5| Step: 7
Training loss: 3.132142259243841
Validation loss: 2.463378998872378

Epoch: 5| Step: 8
Training loss: 2.0360675901948935
Validation loss: 2.5058243411411634

Epoch: 5| Step: 9
Training loss: 2.2619703610786313
Validation loss: 2.467085476945463

Epoch: 5| Step: 10
Training loss: 2.4744040532729814
Validation loss: 2.4587758414936007

Epoch: 182| Step: 0
Training loss: 2.5224095190510436
Validation loss: 2.490826598074304

Epoch: 5| Step: 1
Training loss: 2.826553666927101
Validation loss: 2.431767259174862

Epoch: 5| Step: 2
Training loss: 2.3390021490288593
Validation loss: 2.4362148181440393

Epoch: 5| Step: 3
Training loss: 2.4467196087561955
Validation loss: 2.453909826861938

Epoch: 5| Step: 4
Training loss: 2.362964249465169
Validation loss: 2.4931004653742805

Epoch: 5| Step: 5
Training loss: 1.667567041699377
Validation loss: 2.4681531361929294

Epoch: 5| Step: 6
Training loss: 2.859654147170714
Validation loss: 2.483567728742529

Epoch: 5| Step: 7
Training loss: 2.1202311017373012
Validation loss: 2.5021665609090746

Epoch: 5| Step: 8
Training loss: 2.2525373562881015
Validation loss: 2.496328266316899

Epoch: 5| Step: 9
Training loss: 2.446321809286809
Validation loss: 2.4893586358595896

Epoch: 5| Step: 10
Training loss: 2.8933755521140507
Validation loss: 2.4896318425193553

Epoch: 183| Step: 0
Training loss: 2.729358016044897
Validation loss: 2.453412032579956

Epoch: 5| Step: 1
Training loss: 2.654349780590521
Validation loss: 2.475841295703176

Epoch: 5| Step: 2
Training loss: 2.2476605863134873
Validation loss: 2.472903062572377

Epoch: 5| Step: 3
Training loss: 2.313100788326788
Validation loss: 2.4888927565833674

Epoch: 5| Step: 4
Training loss: 2.4981016581048245
Validation loss: 2.4708214985645096

Epoch: 5| Step: 5
Training loss: 2.5861146987178114
Validation loss: 2.4686363082923273

Epoch: 5| Step: 6
Training loss: 2.2607515734483887
Validation loss: 2.484497829854374

Epoch: 5| Step: 7
Training loss: 2.2702922234676626
Validation loss: 2.4779401571536166

Epoch: 5| Step: 8
Training loss: 2.6141997178768706
Validation loss: 2.5001038437472456

Epoch: 5| Step: 9
Training loss: 2.1204742032644974
Validation loss: 2.447056945625095

Epoch: 5| Step: 10
Training loss: 2.3532223340658107
Validation loss: 2.4739679500649827

Epoch: 184| Step: 0
Training loss: 2.219075890906129
Validation loss: 2.448491813905931

Epoch: 5| Step: 1
Training loss: 2.3964732324516835
Validation loss: 2.4557053587411066

Epoch: 5| Step: 2
Training loss: 2.675209329561
Validation loss: 2.4936779974774335

Epoch: 5| Step: 3
Training loss: 2.2158320406876153
Validation loss: 2.481427786523062

Epoch: 5| Step: 4
Training loss: 2.0219847423834327
Validation loss: 2.4638231752235544

Epoch: 5| Step: 5
Training loss: 2.5757564877866463
Validation loss: 2.4675541436391537

Epoch: 5| Step: 6
Training loss: 2.0137128409539313
Validation loss: 2.483806399282716

Epoch: 5| Step: 7
Training loss: 2.1396711688660166
Validation loss: 2.4899530296311996

Epoch: 5| Step: 8
Training loss: 2.9976923332200047
Validation loss: 2.49018162863918

Epoch: 5| Step: 9
Training loss: 2.808546466455904
Validation loss: 2.4460613361290005

Epoch: 5| Step: 10
Training loss: 2.5136745307629718
Validation loss: 2.5176332722718593

Epoch: 185| Step: 0
Training loss: 2.5613052560292355
Validation loss: 2.5076723225375934

Epoch: 5| Step: 1
Training loss: 2.5108121716046146
Validation loss: 2.5128975953357817

Epoch: 5| Step: 2
Training loss: 2.632289574192928
Validation loss: 2.4775941562688133

Epoch: 5| Step: 3
Training loss: 2.4946019067981324
Validation loss: 2.4681707823974635

Epoch: 5| Step: 4
Training loss: 2.458017415151833
Validation loss: 2.4867114339107355

Epoch: 5| Step: 5
Training loss: 2.723684721431883
Validation loss: 2.4794336664482954

Epoch: 5| Step: 6
Training loss: 2.2913655747953396
Validation loss: 2.4799450574151622

Epoch: 5| Step: 7
Training loss: 2.1669237522288674
Validation loss: 2.4956524691387902

Epoch: 5| Step: 8
Training loss: 2.617588115036059
Validation loss: 2.4555239547917544

Epoch: 5| Step: 9
Training loss: 1.8756350395546637
Validation loss: 2.5075222999178965

Epoch: 5| Step: 10
Training loss: 2.124614119555111
Validation loss: 2.5015345498800894

Epoch: 186| Step: 0
Training loss: 2.544991012887132
Validation loss: 2.4934431013188716

Epoch: 5| Step: 1
Training loss: 1.5819589103831442
Validation loss: 2.4855511714346252

Epoch: 5| Step: 2
Training loss: 2.4551167754390995
Validation loss: 2.4553094259696033

Epoch: 5| Step: 3
Training loss: 2.408590590344688
Validation loss: 2.4650184750523447

Epoch: 5| Step: 4
Training loss: 2.787707686278194
Validation loss: 2.4976049579438793

Epoch: 5| Step: 5
Training loss: 2.546575985071268
Validation loss: 2.47715275914

Epoch: 5| Step: 6
Training loss: 2.1726386833921043
Validation loss: 2.4513092898035556

Epoch: 5| Step: 7
Training loss: 2.341904587610935
Validation loss: 2.473218322507591

Epoch: 5| Step: 8
Training loss: 2.3638108345809163
Validation loss: 2.4871224372690177

Epoch: 5| Step: 9
Training loss: 2.2231173447677426
Validation loss: 2.4862312579191608

Epoch: 5| Step: 10
Training loss: 3.1361399647463126
Validation loss: 2.4845585630448364

Epoch: 187| Step: 0
Training loss: 2.9642368745966072
Validation loss: 2.4541809419929583

Epoch: 5| Step: 1
Training loss: 2.67084987672948
Validation loss: 2.464295238951276

Epoch: 5| Step: 2
Training loss: 1.9153603027074624
Validation loss: 2.5072494322982575

Epoch: 5| Step: 3
Training loss: 3.050487704447496
Validation loss: 2.4930297717195993

Epoch: 5| Step: 4
Training loss: 2.6622973548531275
Validation loss: 2.4748430795437004

Epoch: 5| Step: 5
Training loss: 2.5954591566122898
Validation loss: 2.4838058532795957

Epoch: 5| Step: 6
Training loss: 2.3131277933338352
Validation loss: 2.42490793697635

Epoch: 5| Step: 7
Training loss: 2.381124830585702
Validation loss: 2.500864600319668

Epoch: 5| Step: 8
Training loss: 2.363619390840213
Validation loss: 2.454110508738705

Epoch: 5| Step: 9
Training loss: 1.4401583761965393
Validation loss: 2.502220615526162

Epoch: 5| Step: 10
Training loss: 1.9132204655952576
Validation loss: 2.445523461520714

Epoch: 188| Step: 0
Training loss: 2.338344800743793
Validation loss: 2.4952706641779145

Epoch: 5| Step: 1
Training loss: 2.5128403883801225
Validation loss: 2.49230824657404

Epoch: 5| Step: 2
Training loss: 2.2635045092558643
Validation loss: 2.4158573839429933

Epoch: 5| Step: 3
Training loss: 2.6674765807306233
Validation loss: 2.4330862769734343

Epoch: 5| Step: 4
Training loss: 2.3802573590617113
Validation loss: 2.498028185745317

Epoch: 5| Step: 5
Training loss: 2.870167028637503
Validation loss: 2.4514249260423844

Epoch: 5| Step: 6
Training loss: 2.46194040359272
Validation loss: 2.4415888960577425

Epoch: 5| Step: 7
Training loss: 2.3297933450828285
Validation loss: 2.5057961348663036

Epoch: 5| Step: 8
Training loss: 2.2989050788282674
Validation loss: 2.4962111449376843

Epoch: 5| Step: 9
Training loss: 2.0731312115184894
Validation loss: 2.471750831537095

Epoch: 5| Step: 10
Training loss: 2.223061898327707
Validation loss: 2.4589419215591053

Epoch: 189| Step: 0
Training loss: 2.4833527387163783
Validation loss: 2.433627975439943

Epoch: 5| Step: 1
Training loss: 2.6192035255019244
Validation loss: 2.444157797155047

Epoch: 5| Step: 2
Training loss: 1.9049396701581232
Validation loss: 2.47882881992355

Epoch: 5| Step: 3
Training loss: 3.2568015306934424
Validation loss: 2.465817674334697

Epoch: 5| Step: 4
Training loss: 2.1550598176942968
Validation loss: 2.4767118029653052

Epoch: 5| Step: 5
Training loss: 2.134960057512569
Validation loss: 2.476170276500351

Epoch: 5| Step: 6
Training loss: 2.187311218835123
Validation loss: 2.4780444670281114

Epoch: 5| Step: 7
Training loss: 2.2980824106112236
Validation loss: 2.4968001663534602

Epoch: 5| Step: 8
Training loss: 2.002576717854968
Validation loss: 2.4504416055421223

Epoch: 5| Step: 9
Training loss: 2.5949442308787387
Validation loss: 2.459809296285349

Epoch: 5| Step: 10
Training loss: 2.6156779476444454
Validation loss: 2.4369518924827602

Epoch: 190| Step: 0
Training loss: 1.6294785918860042
Validation loss: 2.539981824916273

Epoch: 5| Step: 1
Training loss: 2.1937708753152294
Validation loss: 2.508695214309347

Epoch: 5| Step: 2
Training loss: 2.5803056222445844
Validation loss: 2.4435587474319487

Epoch: 5| Step: 3
Training loss: 2.752488830710053
Validation loss: 2.4894435534575594

Epoch: 5| Step: 4
Training loss: 2.394631811522671
Validation loss: 2.4714126921442756

Epoch: 5| Step: 5
Training loss: 2.6280447241172378
Validation loss: 2.478506969067431

Epoch: 5| Step: 6
Training loss: 2.255716479511
Validation loss: 2.507229305499478

Epoch: 5| Step: 7
Training loss: 2.324322353586384
Validation loss: 2.5039407844408648

Epoch: 5| Step: 8
Training loss: 2.190782318778825
Validation loss: 2.503182910708486

Epoch: 5| Step: 9
Training loss: 2.898958966420404
Validation loss: 2.5221085000804577

Epoch: 5| Step: 10
Training loss: 2.501628250125296
Validation loss: 2.435372657188412

Epoch: 191| Step: 0
Training loss: 2.4072368629343517
Validation loss: 2.5092330250669113

Epoch: 5| Step: 1
Training loss: 2.493425307013971
Validation loss: 2.5014104740490204

Epoch: 5| Step: 2
Training loss: 2.310151737893748
Validation loss: 2.4751441677412163

Epoch: 5| Step: 3
Training loss: 2.2824917901550585
Validation loss: 2.4786399455155137

Epoch: 5| Step: 4
Training loss: 2.4692332120801486
Validation loss: 2.4381554497719033

Epoch: 5| Step: 5
Training loss: 2.412712435683591
Validation loss: 2.453513361402804

Epoch: 5| Step: 6
Training loss: 2.41643666674676
Validation loss: 2.465859734930694

Epoch: 5| Step: 7
Training loss: 1.9655354611330618
Validation loss: 2.4966838685432458

Epoch: 5| Step: 8
Training loss: 2.443980186138594
Validation loss: 2.49787742789668

Epoch: 5| Step: 9
Training loss: 2.355114051341085
Validation loss: 2.5181355479603136

Epoch: 5| Step: 10
Training loss: 2.9059316809460904
Validation loss: 2.473363846149875

Epoch: 192| Step: 0
Training loss: 2.455086865102283
Validation loss: 2.459331581084888

Epoch: 5| Step: 1
Training loss: 2.4684354364406076
Validation loss: 2.4304790966080976

Epoch: 5| Step: 2
Training loss: 2.36575606473121
Validation loss: 2.465829530201418

Epoch: 5| Step: 3
Training loss: 2.7101637205942994
Validation loss: 2.5057465966357735

Epoch: 5| Step: 4
Training loss: 2.452700632892707
Validation loss: 2.4807419446652297

Epoch: 5| Step: 5
Training loss: 2.1421550099964817
Validation loss: 2.4558341880185073

Epoch: 5| Step: 6
Training loss: 2.31109390812772
Validation loss: 2.4661923637894563

Epoch: 5| Step: 7
Training loss: 2.2512451541219405
Validation loss: 2.48198059274716

Epoch: 5| Step: 8
Training loss: 2.3986393846667657
Validation loss: 2.4680464554533925

Epoch: 5| Step: 9
Training loss: 2.2838332299578097
Validation loss: 2.463476428920925

Epoch: 5| Step: 10
Training loss: 2.7290791698922092
Validation loss: 2.4906435916866676

Epoch: 193| Step: 0
Training loss: 3.0571857977781183
Validation loss: 2.4463969424748493

Epoch: 5| Step: 1
Training loss: 2.1736269683855305
Validation loss: 2.43856505649589

Epoch: 5| Step: 2
Training loss: 2.582823569752348
Validation loss: 2.4504738914413102

Epoch: 5| Step: 3
Training loss: 2.111781238417437
Validation loss: 2.4667224307215925

Epoch: 5| Step: 4
Training loss: 2.2398606830937475
Validation loss: 2.486248785093989

Epoch: 5| Step: 5
Training loss: 2.242555169454994
Validation loss: 2.4311374378748547

Epoch: 5| Step: 6
Training loss: 2.8582434578010494
Validation loss: 2.4747244964028647

Epoch: 5| Step: 7
Training loss: 2.4003446371268526
Validation loss: 2.489742263853971

Epoch: 5| Step: 8
Training loss: 2.160561383905078
Validation loss: 2.4640008083621048

Epoch: 5| Step: 9
Training loss: 2.1300048233479076
Validation loss: 2.4287819669421578

Epoch: 5| Step: 10
Training loss: 2.1170751112495663
Validation loss: 2.488881228947016

Epoch: 194| Step: 0
Training loss: 2.4923028709948243
Validation loss: 2.4806122815591714

Epoch: 5| Step: 1
Training loss: 2.515899453681557
Validation loss: 2.4563299754768186

Epoch: 5| Step: 2
Training loss: 2.4838803356666803
Validation loss: 2.4301513539309805

Epoch: 5| Step: 3
Training loss: 1.7588339317482462
Validation loss: 2.4701733528780005

Epoch: 5| Step: 4
Training loss: 2.4628421255323354
Validation loss: 2.476475645890629

Epoch: 5| Step: 5
Training loss: 2.389272868423093
Validation loss: 2.477376465412551

Epoch: 5| Step: 6
Training loss: 2.6335650989894352
Validation loss: 2.4810128054975245

Epoch: 5| Step: 7
Training loss: 2.216131034709024
Validation loss: 2.4839534008379944

Epoch: 5| Step: 8
Training loss: 2.621279577725976
Validation loss: 2.47242789908673

Epoch: 5| Step: 9
Training loss: 2.2470222477951083
Validation loss: 2.443875293002354

Epoch: 5| Step: 10
Training loss: 2.353545306639856
Validation loss: 2.488280204259776

Epoch: 195| Step: 0
Training loss: 2.927668900931498
Validation loss: 2.4637937940760035

Epoch: 5| Step: 1
Training loss: 2.344509662858018
Validation loss: 2.490983162118106

Epoch: 5| Step: 2
Training loss: 2.221061898995046
Validation loss: 2.4974555059194454

Epoch: 5| Step: 3
Training loss: 1.805017878689548
Validation loss: 2.4817630098107224

Epoch: 5| Step: 4
Training loss: 2.5441862552345618
Validation loss: 2.43497559765156

Epoch: 5| Step: 5
Training loss: 2.735326023929111
Validation loss: 2.4609752552517374

Epoch: 5| Step: 6
Training loss: 2.6431824528116326
Validation loss: 2.4849073711978225

Epoch: 5| Step: 7
Training loss: 1.931642106135681
Validation loss: 2.434501651752497

Epoch: 5| Step: 8
Training loss: 2.4340691507777303
Validation loss: 2.4433542358767233

Epoch: 5| Step: 9
Training loss: 2.1598336115082186
Validation loss: 2.480885841727477

Epoch: 5| Step: 10
Training loss: 2.3647238623806586
Validation loss: 2.457915062114525

Epoch: 196| Step: 0
Training loss: 2.002287748329849
Validation loss: 2.464349979661656

Epoch: 5| Step: 1
Training loss: 2.7125620962321815
Validation loss: 2.4381447479146225

Epoch: 5| Step: 2
Training loss: 2.359471300193492
Validation loss: 2.4661605357550167

Epoch: 5| Step: 3
Training loss: 2.634925424580936
Validation loss: 2.4635821649616427

Epoch: 5| Step: 4
Training loss: 2.5067785870984114
Validation loss: 2.451375626111158

Epoch: 5| Step: 5
Training loss: 2.446590589263886
Validation loss: 2.4981423551950432

Epoch: 5| Step: 6
Training loss: 2.6730183614491936
Validation loss: 2.4585249109914615

Epoch: 5| Step: 7
Training loss: 2.1360427930952897
Validation loss: 2.458831482880613

Epoch: 5| Step: 8
Training loss: 2.1920139061841706
Validation loss: 2.4446034298962322

Epoch: 5| Step: 9
Training loss: 2.4229742693320064
Validation loss: 2.439881891384055

Epoch: 5| Step: 10
Training loss: 1.93201833952814
Validation loss: 2.4836052091333425

Epoch: 197| Step: 0
Training loss: 2.2766123622861256
Validation loss: 2.4992425817179575

Epoch: 5| Step: 1
Training loss: 2.154795944217981
Validation loss: 2.465297645936714

Epoch: 5| Step: 2
Training loss: 2.3843492899017296
Validation loss: 2.4353550070279026

Epoch: 5| Step: 3
Training loss: 3.0089457965404685
Validation loss: 2.452558285963242

Epoch: 5| Step: 4
Training loss: 2.3813860516467167
Validation loss: 2.422710123080299

Epoch: 5| Step: 5
Training loss: 2.759267277413177
Validation loss: 2.4671150454212283

Epoch: 5| Step: 6
Training loss: 2.1870915712809587
Validation loss: 2.471610891790056

Epoch: 5| Step: 7
Training loss: 2.553513843523501
Validation loss: 2.4350319044833615

Epoch: 5| Step: 8
Training loss: 2.0597698753482367
Validation loss: 2.4621807155622877

Epoch: 5| Step: 9
Training loss: 1.6644385544220408
Validation loss: 2.4684292351370463

Epoch: 5| Step: 10
Training loss: 2.391201273954632
Validation loss: 2.4546400055138786

Epoch: 198| Step: 0
Training loss: 1.9984010026475698
Validation loss: 2.437808442984716

Epoch: 5| Step: 1
Training loss: 2.568905709181163
Validation loss: 2.432974545575385

Epoch: 5| Step: 2
Training loss: 1.9048730848993523
Validation loss: 2.4666172678933465

Epoch: 5| Step: 3
Training loss: 2.4340553397013216
Validation loss: 2.4475507125352722

Epoch: 5| Step: 4
Training loss: 2.5800704551657856
Validation loss: 2.4691418354592325

Epoch: 5| Step: 5
Training loss: 2.053580562500158
Validation loss: 2.4534398724572437

Epoch: 5| Step: 6
Training loss: 2.4941458825255376
Validation loss: 2.4334434755604244

Epoch: 5| Step: 7
Training loss: 2.037750406616455
Validation loss: 2.4277408872242194

Epoch: 5| Step: 8
Training loss: 2.781714411333979
Validation loss: 2.508523308665076

Epoch: 5| Step: 9
Training loss: 2.7928417256953812
Validation loss: 2.4718247364823114

Epoch: 5| Step: 10
Training loss: 2.3616883513487728
Validation loss: 2.454784701605155

Epoch: 199| Step: 0
Training loss: 2.13253033346983
Validation loss: 2.462413616381995

Epoch: 5| Step: 1
Training loss: 2.7351050573950157
Validation loss: 2.46530109629237

Epoch: 5| Step: 2
Training loss: 2.702309722553817
Validation loss: 2.4417521123884227

Epoch: 5| Step: 3
Training loss: 2.481141006804771
Validation loss: 2.483371029479827

Epoch: 5| Step: 4
Training loss: 2.025177196708986
Validation loss: 2.439406141606699

Epoch: 5| Step: 5
Training loss: 1.9557159328563225
Validation loss: 2.5058029997524214

Epoch: 5| Step: 6
Training loss: 2.3633252352569967
Validation loss: 2.4555343355599444

Epoch: 5| Step: 7
Training loss: 2.6200145426921693
Validation loss: 2.402140662260149

Epoch: 5| Step: 8
Training loss: 2.0674972106102945
Validation loss: 2.445233225770136

Epoch: 5| Step: 9
Training loss: 2.2417059723576385
Validation loss: 2.4660930716044653

Epoch: 5| Step: 10
Training loss: 2.5632003199373536
Validation loss: 2.461076129967904

Epoch: 200| Step: 0
Training loss: 2.568954155227406
Validation loss: 2.4553410412340746

Epoch: 5| Step: 1
Training loss: 2.384930879083113
Validation loss: 2.4668279819016097

Epoch: 5| Step: 2
Training loss: 2.9153105898456366
Validation loss: 2.4549153748521735

Epoch: 5| Step: 3
Training loss: 2.38298649387158
Validation loss: 2.4562869136010943

Epoch: 5| Step: 4
Training loss: 2.1316857348382845
Validation loss: 2.4786607704060475

Epoch: 5| Step: 5
Training loss: 2.104124415008059
Validation loss: 2.4477833264929063

Epoch: 5| Step: 6
Training loss: 2.8768321294778896
Validation loss: 2.4887125015641516

Epoch: 5| Step: 7
Training loss: 2.1201284330079466
Validation loss: 2.4824797281957003

Epoch: 5| Step: 8
Training loss: 2.051588615257075
Validation loss: 2.466011894497457

Epoch: 5| Step: 9
Training loss: 2.265057933479098
Validation loss: 2.4440398471823013

Epoch: 5| Step: 10
Training loss: 2.1370592700270152
Validation loss: 2.497730382634467

Epoch: 201| Step: 0
Training loss: 2.1478494845175
Validation loss: 2.472927753359947

Epoch: 5| Step: 1
Training loss: 2.5176966885628986
Validation loss: 2.4813087152876117

Epoch: 5| Step: 2
Training loss: 2.944842313680209
Validation loss: 2.473747636321272

Epoch: 5| Step: 3
Training loss: 2.474953306123709
Validation loss: 2.512639299789163

Epoch: 5| Step: 4
Training loss: 2.288527286179346
Validation loss: 2.470642186109312

Epoch: 5| Step: 5
Training loss: 2.3902906794929155
Validation loss: 2.452374998583247

Epoch: 5| Step: 6
Training loss: 2.3560575695031285
Validation loss: 2.4549044212824938

Epoch: 5| Step: 7
Training loss: 2.0942094213409863
Validation loss: 2.46519545373802

Epoch: 5| Step: 8
Training loss: 2.1733016124508904
Validation loss: 2.4652373627230753

Epoch: 5| Step: 9
Training loss: 1.8130126096704613
Validation loss: 2.427405697767084

Epoch: 5| Step: 10
Training loss: 2.8554209902170418
Validation loss: 2.4548159356585093

Epoch: 202| Step: 0
Training loss: 2.323059510997982
Validation loss: 2.4902828608664

Epoch: 5| Step: 1
Training loss: 2.1628122401971086
Validation loss: 2.465856831695531

Epoch: 5| Step: 2
Training loss: 2.383896978014849
Validation loss: 2.4820697635683473

Epoch: 5| Step: 3
Training loss: 2.168198581919379
Validation loss: 2.4707582861161663

Epoch: 5| Step: 4
Training loss: 2.5250140010332256
Validation loss: 2.450575826638376

Epoch: 5| Step: 5
Training loss: 2.01573985164396
Validation loss: 2.468881152111581

Epoch: 5| Step: 6
Training loss: 2.335883098466387
Validation loss: 2.4414090830796735

Epoch: 5| Step: 7
Training loss: 2.517937113024323
Validation loss: 2.45849950724812

Epoch: 5| Step: 8
Training loss: 2.3513275738847392
Validation loss: 2.46631064721159

Epoch: 5| Step: 9
Training loss: 2.2043135663160585
Validation loss: 2.436078156743403

Epoch: 5| Step: 10
Training loss: 2.705399190530087
Validation loss: 2.4316866409132625

Epoch: 203| Step: 0
Training loss: 2.298016322981827
Validation loss: 2.4572099792529185

Epoch: 5| Step: 1
Training loss: 2.7917324077400005
Validation loss: 2.4601938087898323

Epoch: 5| Step: 2
Training loss: 1.9063139107418383
Validation loss: 2.494337700109248

Epoch: 5| Step: 3
Training loss: 2.224845786590362
Validation loss: 2.4650165161951985

Epoch: 5| Step: 4
Training loss: 2.424320487550064
Validation loss: 2.452599531810815

Epoch: 5| Step: 5
Training loss: 2.297616644254981
Validation loss: 2.458058143871013

Epoch: 5| Step: 6
Training loss: 2.082656623290231
Validation loss: 2.5035583752031836

Epoch: 5| Step: 7
Training loss: 1.962001800474066
Validation loss: 2.4890319646840164

Epoch: 5| Step: 8
Training loss: 2.3449592014171663
Validation loss: 2.474411456974309

Epoch: 5| Step: 9
Training loss: 2.609998617062257
Validation loss: 2.45901230712942

Epoch: 5| Step: 10
Training loss: 2.7943379067331167
Validation loss: 2.4521382002643093

Epoch: 204| Step: 0
Training loss: 2.096507178620217
Validation loss: 2.4904532148318053

Epoch: 5| Step: 1
Training loss: 3.5202698266041494
Validation loss: 2.509214497799635

Epoch: 5| Step: 2
Training loss: 2.636973186508491
Validation loss: 2.430219385442751

Epoch: 5| Step: 3
Training loss: 1.9887451949621977
Validation loss: 2.4744213782723374

Epoch: 5| Step: 4
Training loss: 1.8003232294844551
Validation loss: 2.432044929464948

Epoch: 5| Step: 5
Training loss: 2.178084464222766
Validation loss: 2.450573744822757

Epoch: 5| Step: 6
Training loss: 2.103224200194882
Validation loss: 2.4632966681721005

Epoch: 5| Step: 7
Training loss: 2.3985822304662796
Validation loss: 2.4818303506601964

Epoch: 5| Step: 8
Training loss: 1.6409136563633597
Validation loss: 2.5050827215573106

Epoch: 5| Step: 9
Training loss: 1.7363749477393882
Validation loss: 2.4642624095462837

Epoch: 5| Step: 10
Training loss: 3.199772713457261
Validation loss: 2.498094046504432

Epoch: 205| Step: 0
Training loss: 1.9558207714369256
Validation loss: 2.47515783758563

Epoch: 5| Step: 1
Training loss: 2.0854384150277694
Validation loss: 2.4505954667555683

Epoch: 5| Step: 2
Training loss: 2.3370899432351755
Validation loss: 2.4635801815485916

Epoch: 5| Step: 3
Training loss: 2.447201909897337
Validation loss: 2.4928429281409827

Epoch: 5| Step: 4
Training loss: 2.4287922181815227
Validation loss: 2.5157753679015586

Epoch: 5| Step: 5
Training loss: 2.1113887640531694
Validation loss: 2.463617298996467

Epoch: 5| Step: 6
Training loss: 1.7734575984672996
Validation loss: 2.431440559990215

Epoch: 5| Step: 7
Training loss: 2.2063479825920673
Validation loss: 2.479164462365604

Epoch: 5| Step: 8
Training loss: 2.324413644008344
Validation loss: 2.4794081900063087

Epoch: 5| Step: 9
Training loss: 2.858230611959108
Validation loss: 2.4605618201998833

Epoch: 5| Step: 10
Training loss: 2.8912225878810056
Validation loss: 2.466249230767774

Epoch: 206| Step: 0
Training loss: 2.632502597035923
Validation loss: 2.45367115807752

Epoch: 5| Step: 1
Training loss: 2.3324636700612857
Validation loss: 2.449626582160265

Epoch: 5| Step: 2
Training loss: 1.8457055147347294
Validation loss: 2.462549614759152

Epoch: 5| Step: 3
Training loss: 2.6527862404449207
Validation loss: 2.440901441005946

Epoch: 5| Step: 4
Training loss: 2.2896384077821357
Validation loss: 2.4590088854814702

Epoch: 5| Step: 5
Training loss: 2.243873839294701
Validation loss: 2.4782779831507886

Epoch: 5| Step: 6
Training loss: 1.6640015353645063
Validation loss: 2.4634367602148557

Epoch: 5| Step: 7
Training loss: 2.6795909630649972
Validation loss: 2.4666769956501637

Epoch: 5| Step: 8
Training loss: 2.178047465582213
Validation loss: 2.4718441362031753

Epoch: 5| Step: 9
Training loss: 2.7655920684060704
Validation loss: 2.4257433158142723

Epoch: 5| Step: 10
Training loss: 2.0524240072216857
Validation loss: 2.473441890228911

Epoch: 207| Step: 0
Training loss: 2.3401757006420456
Validation loss: 2.46531284285577

Epoch: 5| Step: 1
Training loss: 2.1164511212914694
Validation loss: 2.4409890825124814

Epoch: 5| Step: 2
Training loss: 2.1579309076061617
Validation loss: 2.471913056097306

Epoch: 5| Step: 3
Training loss: 2.317123945191619
Validation loss: 2.4667465213525497

Epoch: 5| Step: 4
Training loss: 3.0012487355729647
Validation loss: 2.4921361461646994

Epoch: 5| Step: 5
Training loss: 2.296522879046576
Validation loss: 2.4773494098756346

Epoch: 5| Step: 6
Training loss: 2.0413103246797846
Validation loss: 2.457720752337164

Epoch: 5| Step: 7
Training loss: 2.4874127128276817
Validation loss: 2.4775696258067663

Epoch: 5| Step: 8
Training loss: 1.9852206613418948
Validation loss: 2.4790067392788186

Epoch: 5| Step: 9
Training loss: 2.1509890299738563
Validation loss: 2.449957324073423

Epoch: 5| Step: 10
Training loss: 2.9445310815824772
Validation loss: 2.4956906494012476

Epoch: 208| Step: 0
Training loss: 2.118862601469824
Validation loss: 2.4778470934173646

Epoch: 5| Step: 1
Training loss: 2.7450120947177052
Validation loss: 2.4523284556306466

Epoch: 5| Step: 2
Training loss: 2.340816442098907
Validation loss: 2.439294334474531

Epoch: 5| Step: 3
Training loss: 2.6022370984529717
Validation loss: 2.4837551601342747

Epoch: 5| Step: 4
Training loss: 2.4028283103475303
Validation loss: 2.467447133618406

Epoch: 5| Step: 5
Training loss: 2.0394293794855196
Validation loss: 2.4230534888654143

Epoch: 5| Step: 6
Training loss: 1.7841050540073982
Validation loss: 2.490920006411431

Epoch: 5| Step: 7
Training loss: 2.0126048090399182
Validation loss: 2.413383455552568

Epoch: 5| Step: 8
Training loss: 2.4759714281655274
Validation loss: 2.4495493795270558

Epoch: 5| Step: 9
Training loss: 2.8563913923863837
Validation loss: 2.4726591551012818

Epoch: 5| Step: 10
Training loss: 2.2911449763342753
Validation loss: 2.438879611805995

Epoch: 209| Step: 0
Training loss: 2.477783191097183
Validation loss: 2.4743771605350404

Epoch: 5| Step: 1
Training loss: 2.861640074718749
Validation loss: 2.480494681150043

Epoch: 5| Step: 2
Training loss: 1.831172131650223
Validation loss: 2.5057330036324292

Epoch: 5| Step: 3
Training loss: 2.5568769213161744
Validation loss: 2.494822954061349

Epoch: 5| Step: 4
Training loss: 2.0186025229047186
Validation loss: 2.4338939771712567

Epoch: 5| Step: 5
Training loss: 2.3607539511424043
Validation loss: 2.438195854169602

Epoch: 5| Step: 6
Training loss: 1.9640479476498849
Validation loss: 2.4485496269943754

Epoch: 5| Step: 7
Training loss: 2.5668788805668257
Validation loss: 2.474563903440027

Epoch: 5| Step: 8
Training loss: 2.5388895298655356
Validation loss: 2.488566331499896

Epoch: 5| Step: 9
Training loss: 2.3328775119601386
Validation loss: 2.459512919441312

Epoch: 5| Step: 10
Training loss: 1.8072024569815135
Validation loss: 2.4410247885373426

Epoch: 210| Step: 0
Training loss: 2.1047393724467964
Validation loss: 2.453151870203115

Epoch: 5| Step: 1
Training loss: 2.279180136390323
Validation loss: 2.4742778937398677

Epoch: 5| Step: 2
Training loss: 2.1066390767685066
Validation loss: 2.421702009010806

Epoch: 5| Step: 3
Training loss: 2.474340073429825
Validation loss: 2.5093364254259165

Epoch: 5| Step: 4
Training loss: 2.3203548337625928
Validation loss: 2.476554158659521

Epoch: 5| Step: 5
Training loss: 1.9237210471469943
Validation loss: 2.489545682757216

Epoch: 5| Step: 6
Training loss: 2.380406099502218
Validation loss: 2.4542551462146496

Epoch: 5| Step: 7
Training loss: 2.04193999608248
Validation loss: 2.4629672189668335

Epoch: 5| Step: 8
Training loss: 2.717449885856428
Validation loss: 2.4497134709351194

Epoch: 5| Step: 9
Training loss: 1.8389779096545085
Validation loss: 2.457377933442494

Epoch: 5| Step: 10
Training loss: 3.0802073914198886
Validation loss: 2.481913674310434

Epoch: 211| Step: 0
Training loss: 3.0737063842508565
Validation loss: 2.4744939353614157

Epoch: 5| Step: 1
Training loss: 2.2887824085718242
Validation loss: 2.460530606989689

Epoch: 5| Step: 2
Training loss: 1.759310207224104
Validation loss: 2.473042025255466

Epoch: 5| Step: 3
Training loss: 2.538177242009121
Validation loss: 2.4684545668082984

Epoch: 5| Step: 4
Training loss: 2.1169284788798093
Validation loss: 2.463576847413086

Epoch: 5| Step: 5
Training loss: 2.7433493562819873
Validation loss: 2.429937556543238

Epoch: 5| Step: 6
Training loss: 2.076413934472245
Validation loss: 2.465427673587906

Epoch: 5| Step: 7
Training loss: 1.8122162432363738
Validation loss: 2.4646158095599096

Epoch: 5| Step: 8
Training loss: 2.0883310137241367
Validation loss: 2.4845646043987797

Epoch: 5| Step: 9
Training loss: 2.557238317322903
Validation loss: 2.4977401907794867

Epoch: 5| Step: 10
Training loss: 2.1572067791716787
Validation loss: 2.469669910537726

Epoch: 212| Step: 0
Training loss: 1.983564075970687
Validation loss: 2.4646298072036523

Epoch: 5| Step: 1
Training loss: 1.9593099093538862
Validation loss: 2.4486136619532513

Epoch: 5| Step: 2
Training loss: 2.7190832175020265
Validation loss: 2.4662217038878116

Epoch: 5| Step: 3
Training loss: 1.8071696728548226
Validation loss: 2.493432407478128

Epoch: 5| Step: 4
Training loss: 2.521949825571273
Validation loss: 2.4715987218851048

Epoch: 5| Step: 5
Training loss: 2.214789711160101
Validation loss: 2.489641807165677

Epoch: 5| Step: 6
Training loss: 2.7824181664455665
Validation loss: 2.4854712858446617

Epoch: 5| Step: 7
Training loss: 2.6863644884651214
Validation loss: 2.451268164480539

Epoch: 5| Step: 8
Training loss: 2.0131347413465415
Validation loss: 2.453816971205037

Epoch: 5| Step: 9
Training loss: 2.5072452462155375
Validation loss: 2.429825607556686

Epoch: 5| Step: 10
Training loss: 1.8153664514815384
Validation loss: 2.445634613318855

Epoch: 213| Step: 0
Training loss: 2.069702058441691
Validation loss: 2.451968369036009

Epoch: 5| Step: 1
Training loss: 2.759935464242718
Validation loss: 2.4436850593162167

Epoch: 5| Step: 2
Training loss: 2.1965109381035406
Validation loss: 2.438689899320974

Epoch: 5| Step: 3
Training loss: 2.0219948828884315
Validation loss: 2.485290326736202

Epoch: 5| Step: 4
Training loss: 2.088134979708315
Validation loss: 2.4800423457569085

Epoch: 5| Step: 5
Training loss: 2.1245467880745807
Validation loss: 2.486464323770906

Epoch: 5| Step: 6
Training loss: 2.3019680725057716
Validation loss: 2.4369660974158647

Epoch: 5| Step: 7
Training loss: 2.5099284434662277
Validation loss: 2.48576804944729

Epoch: 5| Step: 8
Training loss: 2.464588859425076
Validation loss: 2.4636187173341213

Epoch: 5| Step: 9
Training loss: 2.45839635046239
Validation loss: 2.4347938827290765

Epoch: 5| Step: 10
Training loss: 2.773841506115626
Validation loss: 2.468259169401549

Epoch: 214| Step: 0
Training loss: 2.1846689705873894
Validation loss: 2.4497568911441405

Epoch: 5| Step: 1
Training loss: 2.6817852739745565
Validation loss: 2.469568570392865

Epoch: 5| Step: 2
Training loss: 2.1605745155498925
Validation loss: 2.4424000088119215

Epoch: 5| Step: 3
Training loss: 2.7127825260253173
Validation loss: 2.462215058505707

Epoch: 5| Step: 4
Training loss: 2.37021335301406
Validation loss: 2.4572369205928006

Epoch: 5| Step: 5
Training loss: 1.8854747011585986
Validation loss: 2.483665835126063

Epoch: 5| Step: 6
Training loss: 1.652784212172919
Validation loss: 2.4871455768217974

Epoch: 5| Step: 7
Training loss: 2.783060577489918
Validation loss: 2.4646054056715396

Epoch: 5| Step: 8
Training loss: 2.363376583982346
Validation loss: 2.4243986733368743

Epoch: 5| Step: 9
Training loss: 2.3718982318449084
Validation loss: 2.424508687290749

Epoch: 5| Step: 10
Training loss: 2.208073786712006
Validation loss: 2.458357964321553

Epoch: 215| Step: 0
Training loss: 2.6820163227469287
Validation loss: 2.4502601958752117

Epoch: 5| Step: 1
Training loss: 2.167236204363274
Validation loss: 2.501593608949333

Epoch: 5| Step: 2
Training loss: 2.4311795575054753
Validation loss: 2.4482763238703713

Epoch: 5| Step: 3
Training loss: 2.157940851215851
Validation loss: 2.454955272625924

Epoch: 5| Step: 4
Training loss: 2.4813164651650284
Validation loss: 2.4488978681338978

Epoch: 5| Step: 5
Training loss: 2.1662694371270987
Validation loss: 2.4722757165084976

Epoch: 5| Step: 6
Training loss: 2.296412622531579
Validation loss: 2.455267335516894

Epoch: 5| Step: 7
Training loss: 2.1903263906135573
Validation loss: 2.4016788341842537

Epoch: 5| Step: 8
Training loss: 2.1906968870897536
Validation loss: 2.4683583889935115

Epoch: 5| Step: 9
Training loss: 2.175809521037717
Validation loss: 2.420469769654966

Epoch: 5| Step: 10
Training loss: 2.228462559622367
Validation loss: 2.4759555956911115

Epoch: 216| Step: 0
Training loss: 2.434547102871467
Validation loss: 2.447938228207637

Epoch: 5| Step: 1
Training loss: 3.224188497007177
Validation loss: 2.4702953166298784

Epoch: 5| Step: 2
Training loss: 1.9141929114932195
Validation loss: 2.4734820675053126

Epoch: 5| Step: 3
Training loss: 2.0576987592101
Validation loss: 2.471976852968431

Epoch: 5| Step: 4
Training loss: 2.1670806440373256
Validation loss: 2.4469171379422576

Epoch: 5| Step: 5
Training loss: 1.9378852461232925
Validation loss: 2.461491956362224

Epoch: 5| Step: 6
Training loss: 2.246061693045693
Validation loss: 2.4502075437225783

Epoch: 5| Step: 7
Training loss: 1.9792086412763878
Validation loss: 2.4592688024894453

Epoch: 5| Step: 8
Training loss: 1.6543860113096684
Validation loss: 2.4534312461311165

Epoch: 5| Step: 9
Training loss: 2.762548599851327
Validation loss: 2.4200617549098

Epoch: 5| Step: 10
Training loss: 2.326106277937396
Validation loss: 2.4797635709749346

Epoch: 217| Step: 0
Training loss: 2.95163830669384
Validation loss: 2.471137476380183

Epoch: 5| Step: 1
Training loss: 2.598966752664897
Validation loss: 2.4803457805682623

Epoch: 5| Step: 2
Training loss: 2.6385095011279995
Validation loss: 2.444794820571345

Epoch: 5| Step: 3
Training loss: 1.390727778719237
Validation loss: 2.4369197193654526

Epoch: 5| Step: 4
Training loss: 2.262307098764147
Validation loss: 2.4498525591884093

Epoch: 5| Step: 5
Training loss: 2.069818862508551
Validation loss: 2.4807522571109817

Epoch: 5| Step: 6
Training loss: 1.7739138866627437
Validation loss: 2.4520901666506414

Epoch: 5| Step: 7
Training loss: 2.088384557381441
Validation loss: 2.451922493275996

Epoch: 5| Step: 8
Training loss: 2.3093218228175894
Validation loss: 2.470781318490438

Epoch: 5| Step: 9
Training loss: 2.2047229139483306
Validation loss: 2.396580112558529

Epoch: 5| Step: 10
Training loss: 2.786725943480956
Validation loss: 2.451098897380587

Epoch: 218| Step: 0
Training loss: 1.5635781955031092
Validation loss: 2.4330989924840347

Epoch: 5| Step: 1
Training loss: 2.8778019395531547
Validation loss: 2.4442842149549886

Epoch: 5| Step: 2
Training loss: 2.9514547801921416
Validation loss: 2.486317248985569

Epoch: 5| Step: 3
Training loss: 2.363315651383139
Validation loss: 2.4447755166009735

Epoch: 5| Step: 4
Training loss: 2.295572858966575
Validation loss: 2.487005930179251

Epoch: 5| Step: 5
Training loss: 2.5194383234437803
Validation loss: 2.482383112676867

Epoch: 5| Step: 6
Training loss: 1.8265662435553622
Validation loss: 2.4606583558874666

Epoch: 5| Step: 7
Training loss: 1.7699863951639718
Validation loss: 2.499571167662415

Epoch: 5| Step: 8
Training loss: 1.8679088651534037
Validation loss: 2.465660841122584

Epoch: 5| Step: 9
Training loss: 1.9337123025327927
Validation loss: 2.453156005420982

Epoch: 5| Step: 10
Training loss: 2.874202451791926
Validation loss: 2.461372795613398

Epoch: 219| Step: 0
Training loss: 2.2188327397782412
Validation loss: 2.47972477950407

Epoch: 5| Step: 1
Training loss: 3.1048781499127567
Validation loss: 2.4548590859961386

Epoch: 5| Step: 2
Training loss: 2.1756448206427446
Validation loss: 2.4877761676179984

Epoch: 5| Step: 3
Training loss: 2.368352018153313
Validation loss: 2.4737397720518537

Epoch: 5| Step: 4
Training loss: 2.483032151547558
Validation loss: 2.4784157838570464

Epoch: 5| Step: 5
Training loss: 2.222761262313599
Validation loss: 2.4694302775460955

Epoch: 5| Step: 6
Training loss: 2.3529270813323433
Validation loss: 2.428709934721502

Epoch: 5| Step: 7
Training loss: 1.9256436993298627
Validation loss: 2.4609404835224704

Epoch: 5| Step: 8
Training loss: 2.0297137980412976
Validation loss: 2.4287841244347623

Epoch: 5| Step: 9
Training loss: 2.555192436690295
Validation loss: 2.483243674739348

Epoch: 5| Step: 10
Training loss: 1.7032833200765303
Validation loss: 2.437526146364875

Epoch: 220| Step: 0
Training loss: 2.5124608392652714
Validation loss: 2.403983148020507

Epoch: 5| Step: 1
Training loss: 2.752791808249034
Validation loss: 2.426700307434167

Epoch: 5| Step: 2
Training loss: 2.309341541920287
Validation loss: 2.4319815677241237

Epoch: 5| Step: 3
Training loss: 2.301763820195278
Validation loss: 2.467374598929315

Epoch: 5| Step: 4
Training loss: 2.40537017987034
Validation loss: 2.474598912378027

Epoch: 5| Step: 5
Training loss: 2.2494560219899706
Validation loss: 2.464788035275695

Epoch: 5| Step: 6
Training loss: 1.910428205293721
Validation loss: 2.4439358272605376

Epoch: 5| Step: 7
Training loss: 1.5743237784587947
Validation loss: 2.49262347017889

Epoch: 5| Step: 8
Training loss: 2.4960866817559353
Validation loss: 2.4498660562234487

Epoch: 5| Step: 9
Training loss: 1.9538094503835841
Validation loss: 2.4361037964017918

Epoch: 5| Step: 10
Training loss: 2.7189511630297662
Validation loss: 2.427815716886318

Epoch: 221| Step: 0
Training loss: 2.282191774546321
Validation loss: 2.431250555950122

Epoch: 5| Step: 1
Training loss: 2.4220204955666302
Validation loss: 2.460984724444284

Epoch: 5| Step: 2
Training loss: 2.4179168843513517
Validation loss: 2.482982236586853

Epoch: 5| Step: 3
Training loss: 2.471296904007357
Validation loss: 2.431284299282116

Epoch: 5| Step: 4
Training loss: 2.208560056264091
Validation loss: 2.4495174336199095

Epoch: 5| Step: 5
Training loss: 2.246709855208819
Validation loss: 2.4974154966950404

Epoch: 5| Step: 6
Training loss: 1.8514337293697678
Validation loss: 2.4321146092931767

Epoch: 5| Step: 7
Training loss: 2.520510555651597
Validation loss: 2.484422128748496

Epoch: 5| Step: 8
Training loss: 2.0383687794125454
Validation loss: 2.4746403080709247

Epoch: 5| Step: 9
Training loss: 2.1219531262584104
Validation loss: 2.4727059265547293

Epoch: 5| Step: 10
Training loss: 2.654005740650353
Validation loss: 2.4469314851350568

Epoch: 222| Step: 0
Training loss: 1.94620288250386
Validation loss: 2.5096798377419893

Epoch: 5| Step: 1
Training loss: 1.6272635467148273
Validation loss: 2.4613151774839976

Epoch: 5| Step: 2
Training loss: 2.0786396049139206
Validation loss: 2.507334029753063

Epoch: 5| Step: 3
Training loss: 2.560028372845776
Validation loss: 2.4569145263729912

Epoch: 5| Step: 4
Training loss: 2.0261323282571864
Validation loss: 2.460409245957356

Epoch: 5| Step: 5
Training loss: 2.063934520880431
Validation loss: 2.472455440339401

Epoch: 5| Step: 6
Training loss: 2.1098961080492744
Validation loss: 2.4325208669035843

Epoch: 5| Step: 7
Training loss: 3.0313881124906796
Validation loss: 2.44747597404579

Epoch: 5| Step: 8
Training loss: 2.1139343719111903
Validation loss: 2.468823871205691

Epoch: 5| Step: 9
Training loss: 2.461134839093037
Validation loss: 2.468021974478967

Epoch: 5| Step: 10
Training loss: 2.826366826460009
Validation loss: 2.395474295087803

Epoch: 223| Step: 0
Training loss: 2.3358135892224343
Validation loss: 2.4638347269744676

Epoch: 5| Step: 1
Training loss: 2.193560243751867
Validation loss: 2.454504390876606

Epoch: 5| Step: 2
Training loss: 1.8807315961268694
Validation loss: 2.4544329474781588

Epoch: 5| Step: 3
Training loss: 2.8723518780930153
Validation loss: 2.463315815551996

Epoch: 5| Step: 4
Training loss: 1.8519486294289325
Validation loss: 2.49093466106575

Epoch: 5| Step: 5
Training loss: 2.384670246288303
Validation loss: 2.4592625467979143

Epoch: 5| Step: 6
Training loss: 2.7000688685358427
Validation loss: 2.4992876176135557

Epoch: 5| Step: 7
Training loss: 2.5273304486403743
Validation loss: 2.445745136383985

Epoch: 5| Step: 8
Training loss: 2.199409219140114
Validation loss: 2.4363884233149786

Epoch: 5| Step: 9
Training loss: 2.2940244048000262
Validation loss: 2.470222512715765

Epoch: 5| Step: 10
Training loss: 1.520964272841293
Validation loss: 2.489007824013485

Epoch: 224| Step: 0
Training loss: 2.260293409324137
Validation loss: 2.4619718852856445

Epoch: 5| Step: 1
Training loss: 2.000950110778676
Validation loss: 2.4835376980873365

Epoch: 5| Step: 2
Training loss: 1.9570860103171692
Validation loss: 2.410233455082274

Epoch: 5| Step: 3
Training loss: 2.2027110258712725
Validation loss: 2.4734098777052362

Epoch: 5| Step: 4
Training loss: 2.2067994122563697
Validation loss: 2.435892627399613

Epoch: 5| Step: 5
Training loss: 2.127385875720502
Validation loss: 2.4368450798426435

Epoch: 5| Step: 6
Training loss: 2.4270356355054172
Validation loss: 2.4603201580629817

Epoch: 5| Step: 7
Training loss: 2.8564019093924715
Validation loss: 2.441409212237786

Epoch: 5| Step: 8
Training loss: 2.6506649766465036
Validation loss: 2.431600146470071

Epoch: 5| Step: 9
Training loss: 2.5605386810986364
Validation loss: 2.4827154819560073

Epoch: 5| Step: 10
Training loss: 1.379324960220118
Validation loss: 2.4886283043289152

Epoch: 225| Step: 0
Training loss: 2.3477964946475964
Validation loss: 2.456778945461971

Epoch: 5| Step: 1
Training loss: 2.539115553081552
Validation loss: 2.4639112166783574

Epoch: 5| Step: 2
Training loss: 2.6695101796592198
Validation loss: 2.4562988337348908

Epoch: 5| Step: 3
Training loss: 2.1129513410750795
Validation loss: 2.4660030870775502

Epoch: 5| Step: 4
Training loss: 2.731889216085609
Validation loss: 2.457846056360699

Epoch: 5| Step: 5
Training loss: 1.823630652702681
Validation loss: 2.429378031226324

Epoch: 5| Step: 6
Training loss: 2.400442869333304
Validation loss: 2.4402425349431227

Epoch: 5| Step: 7
Training loss: 1.4572857591001662
Validation loss: 2.4751855488774934

Epoch: 5| Step: 8
Training loss: 2.259554497855291
Validation loss: 2.432923076746174

Epoch: 5| Step: 9
Training loss: 2.348592612701703
Validation loss: 2.4313508324091466

Epoch: 5| Step: 10
Training loss: 2.155396997654673
Validation loss: 2.5003917561473603

Epoch: 226| Step: 0
Training loss: 2.8722604055057634
Validation loss: 2.481142892486548

Epoch: 5| Step: 1
Training loss: 2.2706788620045435
Validation loss: 2.433472335584355

Epoch: 5| Step: 2
Training loss: 1.5814027644611712
Validation loss: 2.480874789950242

Epoch: 5| Step: 3
Training loss: 1.9164104774201425
Validation loss: 2.4497462472938696

Epoch: 5| Step: 4
Training loss: 3.1121468768823517
Validation loss: 2.4567353216966006

Epoch: 5| Step: 5
Training loss: 2.1391572027092427
Validation loss: 2.4550416720682415

Epoch: 5| Step: 6
Training loss: 2.475857703586416
Validation loss: 2.427299794767267

Epoch: 5| Step: 7
Training loss: 2.335397511204325
Validation loss: 2.441461167897113

Epoch: 5| Step: 8
Training loss: 1.9671611732618008
Validation loss: 2.4577560504791696

Epoch: 5| Step: 9
Training loss: 1.9732120146488665
Validation loss: 2.4614929077710888

Epoch: 5| Step: 10
Training loss: 1.9832292988950748
Validation loss: 2.4806114739015226

Epoch: 227| Step: 0
Training loss: 2.7244340956444533
Validation loss: 2.4406864183688954

Epoch: 5| Step: 1
Training loss: 2.3591733934779753
Validation loss: 2.467631173602189

Epoch: 5| Step: 2
Training loss: 1.6283012016559495
Validation loss: 2.4625825575681697

Epoch: 5| Step: 3
Training loss: 2.259947404333832
Validation loss: 2.451135480069869

Epoch: 5| Step: 4
Training loss: 2.5640575978419964
Validation loss: 2.514685601448548

Epoch: 5| Step: 5
Training loss: 2.1016112821795274
Validation loss: 2.460031384057707

Epoch: 5| Step: 6
Training loss: 2.0494813123317734
Validation loss: 2.4385405544673358

Epoch: 5| Step: 7
Training loss: 2.157493564423724
Validation loss: 2.469241272911871

Epoch: 5| Step: 8
Training loss: 2.9592768458490695
Validation loss: 2.4527313844639735

Epoch: 5| Step: 9
Training loss: 1.7503383854275083
Validation loss: 2.420099312054628

Epoch: 5| Step: 10
Training loss: 1.942571769871184
Validation loss: 2.4496611424438353

Epoch: 228| Step: 0
Training loss: 2.124165314945446
Validation loss: 2.4584819292723843

Epoch: 5| Step: 1
Training loss: 2.3946898564990793
Validation loss: 2.44356323355994

Epoch: 5| Step: 2
Training loss: 2.228340804040674
Validation loss: 2.461522511660996

Epoch: 5| Step: 3
Training loss: 2.8606596182057227
Validation loss: 2.502488575848713

Epoch: 5| Step: 4
Training loss: 1.8673979189752163
Validation loss: 2.4514503131619954

Epoch: 5| Step: 5
Training loss: 1.9066458119183314
Validation loss: 2.4780321983662854

Epoch: 5| Step: 6
Training loss: 2.485215722589324
Validation loss: 2.44145216165668

Epoch: 5| Step: 7
Training loss: 2.186405998234873
Validation loss: 2.45464973048065

Epoch: 5| Step: 8
Training loss: 2.1680831191679655
Validation loss: 2.4777388507356606

Epoch: 5| Step: 9
Training loss: 2.2155144969248077
Validation loss: 2.4740499738333948

Epoch: 5| Step: 10
Training loss: 2.341145607025735
Validation loss: 2.4648107063602436

Epoch: 229| Step: 0
Training loss: 1.8714482682355296
Validation loss: 2.457802805133613

Epoch: 5| Step: 1
Training loss: 2.3474402304485973
Validation loss: 2.4387306759310268

Epoch: 5| Step: 2
Training loss: 2.4094317319452196
Validation loss: 2.45254525844896

Epoch: 5| Step: 3
Training loss: 2.4307260532221617
Validation loss: 2.45758755152571

Epoch: 5| Step: 4
Training loss: 2.4966382311876862
Validation loss: 2.4510455927986396

Epoch: 5| Step: 5
Training loss: 2.697987696671199
Validation loss: 2.504042037843181

Epoch: 5| Step: 6
Training loss: 1.7797315047854765
Validation loss: 2.4953692371341996

Epoch: 5| Step: 7
Training loss: 2.0545251586368867
Validation loss: 2.4827661080443812

Epoch: 5| Step: 8
Training loss: 2.8442838398309402
Validation loss: 2.4453189245241362

Epoch: 5| Step: 9
Training loss: 2.1550682257099423
Validation loss: 2.4335033759650684

Epoch: 5| Step: 10
Training loss: 1.9910622803638565
Validation loss: 2.493619958928423

Epoch: 230| Step: 0
Training loss: 2.3457395120382403
Validation loss: 2.450889909462679

Epoch: 5| Step: 1
Training loss: 2.1449036544112055
Validation loss: 2.446459915672233

Epoch: 5| Step: 2
Training loss: 2.1808293677548933
Validation loss: 2.4818876608899103

Epoch: 5| Step: 3
Training loss: 2.690713779522182
Validation loss: 2.4300709500224937

Epoch: 5| Step: 4
Training loss: 2.670777748073031
Validation loss: 2.450764498743165

Epoch: 5| Step: 5
Training loss: 2.4993257567049283
Validation loss: 2.46277148508241

Epoch: 5| Step: 6
Training loss: 2.310700928170814
Validation loss: 2.449002563944192

Epoch: 5| Step: 7
Training loss: 2.4554912064848677
Validation loss: 2.408717198533959

Epoch: 5| Step: 8
Training loss: 1.7349641503799547
Validation loss: 2.4368466957642885

Epoch: 5| Step: 9
Training loss: 2.395904097686821
Validation loss: 2.4492149190101937

Epoch: 5| Step: 10
Training loss: 1.5070506330462774
Validation loss: 2.4204540645273314

Epoch: 231| Step: 0
Training loss: 2.6760603933148097
Validation loss: 2.433774136179952

Epoch: 5| Step: 1
Training loss: 3.1465652995296476
Validation loss: 2.458220646317546

Epoch: 5| Step: 2
Training loss: 1.7298499522986528
Validation loss: 2.474075529801588

Epoch: 5| Step: 3
Training loss: 1.9779891945261252
Validation loss: 2.4559989790285517

Epoch: 5| Step: 4
Training loss: 2.089677294225174
Validation loss: 2.4681118999414378

Epoch: 5| Step: 5
Training loss: 1.937339406895071
Validation loss: 2.4833484803496453

Epoch: 5| Step: 6
Training loss: 1.4949009375779343
Validation loss: 2.4778463815957936

Epoch: 5| Step: 7
Training loss: 2.674729367407718
Validation loss: 2.468628468760104

Epoch: 5| Step: 8
Training loss: 1.9986254617851669
Validation loss: 2.4722369060592624

Epoch: 5| Step: 9
Training loss: 2.84161229533723
Validation loss: 2.4666192374315994

Epoch: 5| Step: 10
Training loss: 1.7168751981920503
Validation loss: 2.468322849872786

Epoch: 232| Step: 0
Training loss: 2.0871324866684287
Validation loss: 2.5012839435069245

Epoch: 5| Step: 1
Training loss: 2.0654195293780937
Validation loss: 2.4522653817121727

Epoch: 5| Step: 2
Training loss: 2.1363373299165147
Validation loss: 2.4642452461588413

Epoch: 5| Step: 3
Training loss: 2.5929257105708894
Validation loss: 2.4476683508801984

Epoch: 5| Step: 4
Training loss: 2.9202355666050868
Validation loss: 2.440129037345232

Epoch: 5| Step: 5
Training loss: 1.9914162732452367
Validation loss: 2.459035697645837

Epoch: 5| Step: 6
Training loss: 2.0601854920436646
Validation loss: 2.482396006323318

Epoch: 5| Step: 7
Training loss: 2.0751745173590432
Validation loss: 2.440641744380082

Epoch: 5| Step: 8
Training loss: 2.0562016814795756
Validation loss: 2.434575472271208

Epoch: 5| Step: 9
Training loss: 2.5703125
Validation loss: 2.4619172270697964

Epoch: 5| Step: 10
Training loss: 2.0698915449469855
Validation loss: 2.4459020265755864

Epoch: 233| Step: 0
Training loss: 1.6254557924011768
Validation loss: 2.4814254723079423

Epoch: 5| Step: 1
Training loss: 2.4548716553121825
Validation loss: 2.461506989308337

Epoch: 5| Step: 2
Training loss: 1.8467639276504253
Validation loss: 2.4686054048760218

Epoch: 5| Step: 3
Training loss: 2.5540724080933357
Validation loss: 2.485528261486569

Epoch: 5| Step: 4
Training loss: 2.639746344836125
Validation loss: 2.4387709283607983

Epoch: 5| Step: 5
Training loss: 2.1048350893422545
Validation loss: 2.466240095715506

Epoch: 5| Step: 6
Training loss: 1.7699438965521304
Validation loss: 2.4450333240747075

Epoch: 5| Step: 7
Training loss: 2.528793650168846
Validation loss: 2.4438804310299242

Epoch: 5| Step: 8
Training loss: 1.8339611047927986
Validation loss: 2.463023151823563

Epoch: 5| Step: 9
Training loss: 2.301890806775143
Validation loss: 2.443504782107958

Epoch: 5| Step: 10
Training loss: 2.739945671768096
Validation loss: 2.4273087584634476

Epoch: 234| Step: 0
Training loss: 2.0609513450776427
Validation loss: 2.483135222327359

Epoch: 5| Step: 1
Training loss: 2.1764678693520887
Validation loss: 2.436929359878485

Epoch: 5| Step: 2
Training loss: 2.3148002525154108
Validation loss: 2.4955240730894306

Epoch: 5| Step: 3
Training loss: 2.8268869124234706
Validation loss: 2.4723993911329933

Epoch: 5| Step: 4
Training loss: 2.179984670637637
Validation loss: 2.4756602674726644

Epoch: 5| Step: 5
Training loss: 2.2742988553971726
Validation loss: 2.4458873400345715

Epoch: 5| Step: 6
Training loss: 2.593952952338441
Validation loss: 2.4568621775200445

Epoch: 5| Step: 7
Training loss: 1.972855903417534
Validation loss: 2.456400123836102

Epoch: 5| Step: 8
Training loss: 1.8751705092148687
Validation loss: 2.4920942739318237

Epoch: 5| Step: 9
Training loss: 2.4654291730310702
Validation loss: 2.4634076788599946

Epoch: 5| Step: 10
Training loss: 2.0749202483144344
Validation loss: 2.4042093493244128

Epoch: 235| Step: 0
Training loss: 2.3574488779716423
Validation loss: 2.415730154538321

Epoch: 5| Step: 1
Training loss: 1.821713281065894
Validation loss: 2.506127252632102

Epoch: 5| Step: 2
Training loss: 2.1305565833075857
Validation loss: 2.4977218215170076

Epoch: 5| Step: 3
Training loss: 1.7869292621839614
Validation loss: 2.4437681430495326

Epoch: 5| Step: 4
Training loss: 2.3318045807907715
Validation loss: 2.4315866819433274

Epoch: 5| Step: 5
Training loss: 2.5594765108539357
Validation loss: 2.4495522597036876

Epoch: 5| Step: 6
Training loss: 2.4179018963521455
Validation loss: 2.4752014618857645

Epoch: 5| Step: 7
Training loss: 2.2438208183652275
Validation loss: 2.408677688603841

Epoch: 5| Step: 8
Training loss: 2.6092256057825542
Validation loss: 2.441384927242235

Epoch: 5| Step: 9
Training loss: 2.0397255941100454
Validation loss: 2.471673061820139

Epoch: 5| Step: 10
Training loss: 2.291892739906864
Validation loss: 2.433090107016973

Epoch: 236| Step: 0
Training loss: 2.504023461417806
Validation loss: 2.4703801511560064

Epoch: 5| Step: 1
Training loss: 1.8418855453619085
Validation loss: 2.4649310514115865

Epoch: 5| Step: 2
Training loss: 2.119141750071706
Validation loss: 2.427539463234641

Epoch: 5| Step: 3
Training loss: 2.4535104242277908
Validation loss: 2.471260837622852

Epoch: 5| Step: 4
Training loss: 2.348567538236645
Validation loss: 2.4779195243316723

Epoch: 5| Step: 5
Training loss: 1.9204693748020591
Validation loss: 2.449429962769298

Epoch: 5| Step: 6
Training loss: 2.328344347560702
Validation loss: 2.445637131218137

Epoch: 5| Step: 7
Training loss: 2.0371691803826044
Validation loss: 2.4328304409107666

Epoch: 5| Step: 8
Training loss: 2.6084858184540094
Validation loss: 2.478950882666656

Epoch: 5| Step: 9
Training loss: 2.145764717066692
Validation loss: 2.434492816686008

Epoch: 5| Step: 10
Training loss: 2.2355118640302427
Validation loss: 2.5116215862840985

Epoch: 237| Step: 0
Training loss: 3.002532843442707
Validation loss: 2.4547908486085466

Epoch: 5| Step: 1
Training loss: 2.4263186143688174
Validation loss: 2.4373113802702986

Epoch: 5| Step: 2
Training loss: 1.998672163773591
Validation loss: 2.4500568485005685

Epoch: 5| Step: 3
Training loss: 2.3001874018077437
Validation loss: 2.4690128953323898

Epoch: 5| Step: 4
Training loss: 2.532369483830651
Validation loss: 2.4672762354422813

Epoch: 5| Step: 5
Training loss: 1.4310113999494478
Validation loss: 2.4444824726500265

Epoch: 5| Step: 6
Training loss: 2.2742765261388493
Validation loss: 2.4249200110948967

Epoch: 5| Step: 7
Training loss: 2.2397611562231963
Validation loss: 2.480395097440855

Epoch: 5| Step: 8
Training loss: 1.7185589077231467
Validation loss: 2.4624683843456747

Epoch: 5| Step: 9
Training loss: 2.011681654504769
Validation loss: 2.4529217741075406

Epoch: 5| Step: 10
Training loss: 2.1891251113291257
Validation loss: 2.4853548488574666

Epoch: 238| Step: 0
Training loss: 2.131395812653993
Validation loss: 2.4775166455125834

Epoch: 5| Step: 1
Training loss: 2.1158844150638654
Validation loss: 2.4709372290900835

Epoch: 5| Step: 2
Training loss: 2.1823440824661224
Validation loss: 2.425123215862312

Epoch: 5| Step: 3
Training loss: 2.2048225085733146
Validation loss: 2.447520164017786

Epoch: 5| Step: 4
Training loss: 2.103750685058772
Validation loss: 2.4875578317212996

Epoch: 5| Step: 5
Training loss: 2.6426319869614767
Validation loss: 2.4189704787960484

Epoch: 5| Step: 6
Training loss: 2.286210402223484
Validation loss: 2.4440005086303445

Epoch: 5| Step: 7
Training loss: 2.2394693626561706
Validation loss: 2.444569348680875

Epoch: 5| Step: 8
Training loss: 2.214468034366704
Validation loss: 2.494140377284447

Epoch: 5| Step: 9
Training loss: 2.0183250617758963
Validation loss: 2.4673866712217376

Epoch: 5| Step: 10
Training loss: 2.186475350318418
Validation loss: 2.4714942239867197

Epoch: 239| Step: 0
Training loss: 2.419636928971368
Validation loss: 2.459175963098704

Epoch: 5| Step: 1
Training loss: 2.8978407417697483
Validation loss: 2.4376190352106977

Epoch: 5| Step: 2
Training loss: 1.9852724223727924
Validation loss: 2.448381927896366

Epoch: 5| Step: 3
Training loss: 1.572920801355178
Validation loss: 2.4332529915551233

Epoch: 5| Step: 4
Training loss: 2.4317750457010385
Validation loss: 2.4079067065529682

Epoch: 5| Step: 5
Training loss: 2.3825805551173995
Validation loss: 2.4709179477894927

Epoch: 5| Step: 6
Training loss: 2.2872317547718293
Validation loss: 2.4694199416966427

Epoch: 5| Step: 7
Training loss: 2.1695983810396258
Validation loss: 2.4806133263980428

Epoch: 5| Step: 8
Training loss: 2.282637291881174
Validation loss: 2.436870959708898

Epoch: 5| Step: 9
Training loss: 1.8867743505653165
Validation loss: 2.447498480780746

Epoch: 5| Step: 10
Training loss: 2.267758121624385
Validation loss: 2.477265006498782

Epoch: 240| Step: 0
Training loss: 1.7845208103444719
Validation loss: 2.436252982836908

Epoch: 5| Step: 1
Training loss: 2.1827496857503634
Validation loss: 2.440083086084246

Epoch: 5| Step: 2
Training loss: 2.165214810187518
Validation loss: 2.41745742007857

Epoch: 5| Step: 3
Training loss: 2.1916490716070793
Validation loss: 2.424479796171159

Epoch: 5| Step: 4
Training loss: 2.2502752771465566
Validation loss: 2.454351831773533

Epoch: 5| Step: 5
Training loss: 2.37312513936655
Validation loss: 2.4825063870348067

Epoch: 5| Step: 6
Training loss: 2.1658458866794263
Validation loss: 2.4791054935686088

Epoch: 5| Step: 7
Training loss: 2.561493187339252
Validation loss: 2.4611042060648085

Epoch: 5| Step: 8
Training loss: 2.158031335958484
Validation loss: 2.443494673378563

Epoch: 5| Step: 9
Training loss: 2.1034920495429104
Validation loss: 2.476415573186555

Epoch: 5| Step: 10
Training loss: 2.307105809656216
Validation loss: 2.4591971826782637

Epoch: 241| Step: 0
Training loss: 1.9102677076777324
Validation loss: 2.498910803046345

Epoch: 5| Step: 1
Training loss: 2.2747578670216
Validation loss: 2.462631037163403

Epoch: 5| Step: 2
Training loss: 2.249646370966574
Validation loss: 2.4608222940970466

Epoch: 5| Step: 3
Training loss: 2.211602316607516
Validation loss: 2.437737896345311

Epoch: 5| Step: 4
Training loss: 1.86023820346475
Validation loss: 2.463898791281916

Epoch: 5| Step: 5
Training loss: 2.364713376764306
Validation loss: 2.431784673928622

Epoch: 5| Step: 6
Training loss: 1.9586064439079944
Validation loss: 2.44098626049807

Epoch: 5| Step: 7
Training loss: 2.027258839969835
Validation loss: 2.433267589995241

Epoch: 5| Step: 8
Training loss: 2.8514258783089113
Validation loss: 2.4112932029106324

Epoch: 5| Step: 9
Training loss: 2.3154116677717727
Validation loss: 2.460149504667817

Epoch: 5| Step: 10
Training loss: 1.8651575522055932
Validation loss: 2.425828198730979

Epoch: 242| Step: 0
Training loss: 2.036268402634672
Validation loss: 2.4878019113082153

Epoch: 5| Step: 1
Training loss: 2.3680504966326312
Validation loss: 2.48739924122431

Epoch: 5| Step: 2
Training loss: 1.8381649059956267
Validation loss: 2.4810871976255577

Epoch: 5| Step: 3
Training loss: 2.4415597607987722
Validation loss: 2.4364570340487854

Epoch: 5| Step: 4
Training loss: 2.357139589464309
Validation loss: 2.514954184209834

Epoch: 5| Step: 5
Training loss: 1.985973165148313
Validation loss: 2.4767115814542198

Epoch: 5| Step: 6
Training loss: 1.9547431041392451
Validation loss: 2.46002339257017

Epoch: 5| Step: 7
Training loss: 2.607124408798491
Validation loss: 2.4747838865765552

Epoch: 5| Step: 8
Training loss: 2.1121570466780026
Validation loss: 2.444914861651648

Epoch: 5| Step: 9
Training loss: 2.333667583593806
Validation loss: 2.4663916034814433

Epoch: 5| Step: 10
Training loss: 2.0454307294672858
Validation loss: 2.43293519670238

Epoch: 243| Step: 0
Training loss: 2.540903216491847
Validation loss: 2.4123126692218184

Epoch: 5| Step: 1
Training loss: 2.2262395256434355
Validation loss: 2.443920483776937

Epoch: 5| Step: 2
Training loss: 2.235169809534303
Validation loss: 2.4364253268409404

Epoch: 5| Step: 3
Training loss: 2.4258421861056108
Validation loss: 2.449456797626803

Epoch: 5| Step: 4
Training loss: 2.0641941857329154
Validation loss: 2.4627753714944536

Epoch: 5| Step: 5
Training loss: 2.119021814065709
Validation loss: 2.4541442187590286

Epoch: 5| Step: 6
Training loss: 2.1584250495698467
Validation loss: 2.4360144636922767

Epoch: 5| Step: 7
Training loss: 1.7111602359520974
Validation loss: 2.4770612979415487

Epoch: 5| Step: 8
Training loss: 2.464533137898347
Validation loss: 2.4595380979983026

Epoch: 5| Step: 9
Training loss: 2.1665192578373444
Validation loss: 2.453706291932426

Epoch: 5| Step: 10
Training loss: 1.9518000877288884
Validation loss: 2.480392817403353

Epoch: 244| Step: 0
Training loss: 2.711663668333278
Validation loss: 2.4647802979155857

Epoch: 5| Step: 1
Training loss: 2.281014417215597
Validation loss: 2.467763602709703

Epoch: 5| Step: 2
Training loss: 2.095262806507222
Validation loss: 2.4453270924938164

Epoch: 5| Step: 3
Training loss: 2.189229880665333
Validation loss: 2.435804910399414

Epoch: 5| Step: 4
Training loss: 2.0925933148030573
Validation loss: 2.447291813686798

Epoch: 5| Step: 5
Training loss: 2.6516488110100767
Validation loss: 2.440274823935923

Epoch: 5| Step: 6
Training loss: 1.8062624313824278
Validation loss: 2.438085518835823

Epoch: 5| Step: 7
Training loss: 2.240570548658177
Validation loss: 2.4216069089322807

Epoch: 5| Step: 8
Training loss: 2.007332473548613
Validation loss: 2.471239140690479

Epoch: 5| Step: 9
Training loss: 2.266392860517692
Validation loss: 2.4267888463299983

Epoch: 5| Step: 10
Training loss: 1.8212868370881177
Validation loss: 2.4684161034021135

Epoch: 245| Step: 0
Training loss: 2.2795937156080566
Validation loss: 2.4596005971589534

Epoch: 5| Step: 1
Training loss: 2.30055119088021
Validation loss: 2.430562342230428

Epoch: 5| Step: 2
Training loss: 2.074053109374635
Validation loss: 2.4792916947237096

Epoch: 5| Step: 3
Training loss: 2.6761607102915828
Validation loss: 2.4687568277119474

Epoch: 5| Step: 4
Training loss: 2.127261473107968
Validation loss: 2.466899140114155

Epoch: 5| Step: 5
Training loss: 2.0185210248689844
Validation loss: 2.42146583935417

Epoch: 5| Step: 6
Training loss: 1.9390480256135965
Validation loss: 2.4468673045241247

Epoch: 5| Step: 7
Training loss: 2.641490185094243
Validation loss: 2.4265993834570176

Epoch: 5| Step: 8
Training loss: 1.9528170533599487
Validation loss: 2.4696954028359195

Epoch: 5| Step: 9
Training loss: 1.5724701742427603
Validation loss: 2.463429844389764

Epoch: 5| Step: 10
Training loss: 2.468253749755311
Validation loss: 2.4253414839276393

Epoch: 246| Step: 0
Training loss: 2.08305680029128
Validation loss: 2.4744645172216018

Epoch: 5| Step: 1
Training loss: 2.7776436730968252
Validation loss: 2.4352452893631487

Epoch: 5| Step: 2
Training loss: 2.3178033587802793
Validation loss: 2.447198209840741

Epoch: 5| Step: 3
Training loss: 2.0370159767809
Validation loss: 2.496643706276832

Epoch: 5| Step: 4
Training loss: 2.39560156544271
Validation loss: 2.4268924054099563

Epoch: 5| Step: 5
Training loss: 1.840912267680055
Validation loss: 2.4223110371444796

Epoch: 5| Step: 6
Training loss: 2.308826828500814
Validation loss: 2.4435018822131127

Epoch: 5| Step: 7
Training loss: 1.7895000872125681
Validation loss: 2.443480898790413

Epoch: 5| Step: 8
Training loss: 1.9115581711587102
Validation loss: 2.4199117281428886

Epoch: 5| Step: 9
Training loss: 2.2130957539523926
Validation loss: 2.4672156213078114

Epoch: 5| Step: 10
Training loss: 2.0081875818107764
Validation loss: 2.4568802710726003

Epoch: 247| Step: 0
Training loss: 2.0369567521326006
Validation loss: 2.3975636494091552

Epoch: 5| Step: 1
Training loss: 2.301623567494857
Validation loss: 2.461763742310887

Epoch: 5| Step: 2
Training loss: 2.0516979675425695
Validation loss: 2.4606198300005575

Epoch: 5| Step: 3
Training loss: 2.1557335718894373
Validation loss: 2.469640064346284

Epoch: 5| Step: 4
Training loss: 2.8603025505787265
Validation loss: 2.4505141863626485

Epoch: 5| Step: 5
Training loss: 2.252587631841109
Validation loss: 2.4611535335111623

Epoch: 5| Step: 6
Training loss: 1.8432128899782527
Validation loss: 2.4525882365446536

Epoch: 5| Step: 7
Training loss: 2.103648572030441
Validation loss: 2.515573380677666

Epoch: 5| Step: 8
Training loss: 2.2624546362612747
Validation loss: 2.463496098351344

Epoch: 5| Step: 9
Training loss: 2.044281925892145
Validation loss: 2.4909340507570543

Epoch: 5| Step: 10
Training loss: 2.1202598885718396
Validation loss: 2.43438050745472

Epoch: 248| Step: 0
Training loss: 2.241090087291876
Validation loss: 2.517271969840829

Epoch: 5| Step: 1
Training loss: 2.352468322475768
Validation loss: 2.434255212978615

Epoch: 5| Step: 2
Training loss: 1.50762250424656
Validation loss: 2.4512703042735358

Epoch: 5| Step: 3
Training loss: 1.843281508585818
Validation loss: 2.4444777239246003

Epoch: 5| Step: 4
Training loss: 2.255784863318942
Validation loss: 2.4741278610477426

Epoch: 5| Step: 5
Training loss: 2.2902610166959505
Validation loss: 2.4627788852387

Epoch: 5| Step: 6
Training loss: 2.591616844933132
Validation loss: 2.4415444748337096

Epoch: 5| Step: 7
Training loss: 2.1319134392763557
Validation loss: 2.436559082706946

Epoch: 5| Step: 8
Training loss: 2.44895717069684
Validation loss: 2.4798070444699376

Epoch: 5| Step: 9
Training loss: 2.0573240124698775
Validation loss: 2.469951325406476

Epoch: 5| Step: 10
Training loss: 2.052445497520991
Validation loss: 2.457582634095998

Epoch: 249| Step: 0
Training loss: 2.279762305535112
Validation loss: 2.4479070750100744

Epoch: 5| Step: 1
Training loss: 2.2322097637503346
Validation loss: 2.4498696946966

Epoch: 5| Step: 2
Training loss: 2.0019162058333566
Validation loss: 2.4072859874764543

Epoch: 5| Step: 3
Training loss: 1.5260006982644259
Validation loss: 2.452568810990239

Epoch: 5| Step: 4
Training loss: 2.8763790969358594
Validation loss: 2.5074507619468274

Epoch: 5| Step: 5
Training loss: 2.5757631522813567
Validation loss: 2.442234121228808

Epoch: 5| Step: 6
Training loss: 2.041777458558376
Validation loss: 2.5260158614039474

Epoch: 5| Step: 7
Training loss: 1.8754666701355118
Validation loss: 2.4910284085721215

Epoch: 5| Step: 8
Training loss: 2.1639706147996347
Validation loss: 2.436412523468363

Epoch: 5| Step: 9
Training loss: 2.0686145657465174
Validation loss: 2.411723406160847

Epoch: 5| Step: 10
Training loss: 2.153519823169543
Validation loss: 2.470885662375596

Epoch: 250| Step: 0
Training loss: 2.0199373231738607
Validation loss: 2.468240816507734

Epoch: 5| Step: 1
Training loss: 1.8586070293963917
Validation loss: 2.4584233267698217

Epoch: 5| Step: 2
Training loss: 2.021699962084962
Validation loss: 2.448517326715718

Epoch: 5| Step: 3
Training loss: 2.255543661112291
Validation loss: 2.445868058312862

Epoch: 5| Step: 4
Training loss: 2.1727453450161964
Validation loss: 2.4734205130068263

Epoch: 5| Step: 5
Training loss: 2.373162612918364
Validation loss: 2.456366031480654

Epoch: 5| Step: 6
Training loss: 2.2191546433806257
Validation loss: 2.419354533841514

Epoch: 5| Step: 7
Training loss: 2.6547892424703012
Validation loss: 2.4321128110339485

Epoch: 5| Step: 8
Training loss: 1.7015238944053714
Validation loss: 2.425229693289134

Epoch: 5| Step: 9
Training loss: 1.9830348377909188
Validation loss: 2.4493697092558637

Epoch: 5| Step: 10
Training loss: 2.5119928711711053
Validation loss: 2.418084513321232

Epoch: 251| Step: 0
Training loss: 2.927026949483125
Validation loss: 2.4370019980874544

Epoch: 5| Step: 1
Training loss: 1.7368444097844338
Validation loss: 2.458681183807624

Epoch: 5| Step: 2
Training loss: 2.2051577017306387
Validation loss: 2.4628817096135176

Epoch: 5| Step: 3
Training loss: 1.7404581561846195
Validation loss: 2.409228656441602

Epoch: 5| Step: 4
Training loss: 2.0862252826266405
Validation loss: 2.4480056455032546

Epoch: 5| Step: 5
Training loss: 2.0407951856510764
Validation loss: 2.465591062815485

Epoch: 5| Step: 6
Training loss: 2.079633122513529
Validation loss: 2.442161307972134

Epoch: 5| Step: 7
Training loss: 2.38116838610704
Validation loss: 2.496901081474728

Epoch: 5| Step: 8
Training loss: 1.8074171552231642
Validation loss: 2.4400508287003357

Epoch: 5| Step: 9
Training loss: 2.9289859185992237
Validation loss: 2.398775308397876

Epoch: 5| Step: 10
Training loss: 1.711831403652784
Validation loss: 2.445397484144024

Epoch: 252| Step: 0
Training loss: 2.0761013647040163
Validation loss: 2.4046548841558333

Epoch: 5| Step: 1
Training loss: 2.7957424662605437
Validation loss: 2.4249862264553466

Epoch: 5| Step: 2
Training loss: 2.233721550844089
Validation loss: 2.43592828394213

Epoch: 5| Step: 3
Training loss: 2.0130647471097167
Validation loss: 2.461166236301315

Epoch: 5| Step: 4
Training loss: 2.5126811745072035
Validation loss: 2.428019459849693

Epoch: 5| Step: 5
Training loss: 1.2786889415344826
Validation loss: 2.454870363503589

Epoch: 5| Step: 6
Training loss: 1.55897918753835
Validation loss: 2.4151518306308244

Epoch: 5| Step: 7
Training loss: 1.7288382191466551
Validation loss: 2.436870501027482

Epoch: 5| Step: 8
Training loss: 2.614695532672334
Validation loss: 2.458318990460813

Epoch: 5| Step: 9
Training loss: 2.3280698014442627
Validation loss: 2.435492352155307

Epoch: 5| Step: 10
Training loss: 2.1381449568507622
Validation loss: 2.439997769747622

Epoch: 253| Step: 0
Training loss: 1.842379626478912
Validation loss: 2.4440524144485516

Epoch: 5| Step: 1
Training loss: 1.9608943980066003
Validation loss: 2.4261405374515

Epoch: 5| Step: 2
Training loss: 2.397449302256644
Validation loss: 2.4563783363436107

Epoch: 5| Step: 3
Training loss: 2.0951633522606894
Validation loss: 2.4537703782902462

Epoch: 5| Step: 4
Training loss: 2.1570490586631292
Validation loss: 2.3989235322499316

Epoch: 5| Step: 5
Training loss: 1.6808875476728813
Validation loss: 2.4610500712967056

Epoch: 5| Step: 6
Training loss: 1.9027195114842688
Validation loss: 2.5033445064902193

Epoch: 5| Step: 7
Training loss: 2.3803896734050536
Validation loss: 2.4442871590213477

Epoch: 5| Step: 8
Training loss: 1.9705540701807345
Validation loss: 2.4187800463281675

Epoch: 5| Step: 9
Training loss: 3.013670767427292
Validation loss: 2.479549215750032

Epoch: 5| Step: 10
Training loss: 2.4083853820491474
Validation loss: 2.428009664647248

Epoch: 254| Step: 0
Training loss: 1.9940381000402754
Validation loss: 2.4301180179004502

Epoch: 5| Step: 1
Training loss: 1.8532435515952945
Validation loss: 2.446131887960768

Epoch: 5| Step: 2
Training loss: 2.054997525921374
Validation loss: 2.4422253141355292

Epoch: 5| Step: 3
Training loss: 1.9853961750052467
Validation loss: 2.464584944146883

Epoch: 5| Step: 4
Training loss: 1.9055161236031044
Validation loss: 2.4536274994322036

Epoch: 5| Step: 5
Training loss: 2.0185644908975173
Validation loss: 2.388564204194417

Epoch: 5| Step: 6
Training loss: 2.8565723462671144
Validation loss: 2.4805674026788718

Epoch: 5| Step: 7
Training loss: 2.6569754114876103
Validation loss: 2.439879119574542

Epoch: 5| Step: 8
Training loss: 1.7359797296615114
Validation loss: 2.452360494023777

Epoch: 5| Step: 9
Training loss: 2.153011156236631
Validation loss: 2.4550590616534325

Epoch: 5| Step: 10
Training loss: 2.186234680436182
Validation loss: 2.46414706050429

Epoch: 255| Step: 0
Training loss: 2.2441493367025207
Validation loss: 2.4461176833283806

Epoch: 5| Step: 1
Training loss: 2.3987605470680915
Validation loss: 2.4379842123150532

Epoch: 5| Step: 2
Training loss: 1.7398169431090085
Validation loss: 2.43016872646336

Epoch: 5| Step: 3
Training loss: 2.132756606267379
Validation loss: 2.4886003337550893

Epoch: 5| Step: 4
Training loss: 1.620337620156953
Validation loss: 2.4721123117617543

Epoch: 5| Step: 5
Training loss: 2.069342389530999
Validation loss: 2.501596699753272

Epoch: 5| Step: 6
Training loss: 2.114126209277408
Validation loss: 2.396158320645164

Epoch: 5| Step: 7
Training loss: 2.0579798324086136
Validation loss: 2.4571036925092296

Epoch: 5| Step: 8
Training loss: 2.143842742960166
Validation loss: 2.436756961045012

Epoch: 5| Step: 9
Training loss: 2.5475447072606876
Validation loss: 2.44309572444824

Epoch: 5| Step: 10
Training loss: 2.448414745115525
Validation loss: 2.479124972815884

Epoch: 256| Step: 0
Training loss: 2.4270456554015047
Validation loss: 2.455571020256412

Epoch: 5| Step: 1
Training loss: 1.9249583995336894
Validation loss: 2.434750879033266

Epoch: 5| Step: 2
Training loss: 2.1190521924952774
Validation loss: 2.4600515614451752

Epoch: 5| Step: 3
Training loss: 2.0334840666552614
Validation loss: 2.4690136252755597

Epoch: 5| Step: 4
Training loss: 1.9888705296559983
Validation loss: 2.4578497080536823

Epoch: 5| Step: 5
Training loss: 2.0780819766531526
Validation loss: 2.4155062314060065

Epoch: 5| Step: 6
Training loss: 2.597896157565888
Validation loss: 2.4442812551526014

Epoch: 5| Step: 7
Training loss: 1.6622204681816184
Validation loss: 2.500325071571042

Epoch: 5| Step: 8
Training loss: 2.1879245890954193
Validation loss: 2.5216154114011426

Epoch: 5| Step: 9
Training loss: 2.426559348021436
Validation loss: 2.4472560063487454

Epoch: 5| Step: 10
Training loss: 2.228166290371436
Validation loss: 2.4763874889990327

Epoch: 257| Step: 0
Training loss: 2.2536192501349595
Validation loss: 2.4855520244166383

Epoch: 5| Step: 1
Training loss: 2.4518174495355822
Validation loss: 2.4961559870688217

Epoch: 5| Step: 2
Training loss: 1.8737851339740108
Validation loss: 2.4141202434479854

Epoch: 5| Step: 3
Training loss: 2.1464347243532527
Validation loss: 2.4666403420525524

Epoch: 5| Step: 4
Training loss: 2.1002002257306756
Validation loss: 2.450279229073224

Epoch: 5| Step: 5
Training loss: 2.167393403561523
Validation loss: 2.4150315086282736

Epoch: 5| Step: 6
Training loss: 1.8967070051081476
Validation loss: 2.5132738944390205

Epoch: 5| Step: 7
Training loss: 2.0196464697547856
Validation loss: 2.471667622692087

Epoch: 5| Step: 8
Training loss: 1.9719862602753402
Validation loss: 2.433658042591357

Epoch: 5| Step: 9
Training loss: 2.831803937536886
Validation loss: 2.4772855247284618

Epoch: 5| Step: 10
Training loss: 1.9419910310052941
Validation loss: 2.4291556384594144

Epoch: 258| Step: 0
Training loss: 2.3855818867554155
Validation loss: 2.483337890663213

Epoch: 5| Step: 1
Training loss: 2.289465963070237
Validation loss: 2.4282547740945537

Epoch: 5| Step: 2
Training loss: 2.2576348785966593
Validation loss: 2.470811714296778

Epoch: 5| Step: 3
Training loss: 1.7703829772334236
Validation loss: 2.4721713229274327

Epoch: 5| Step: 4
Training loss: 2.6498594714636963
Validation loss: 2.43523879720692

Epoch: 5| Step: 5
Training loss: 1.6843963621692242
Validation loss: 2.420013169375094

Epoch: 5| Step: 6
Training loss: 1.6567207243304176
Validation loss: 2.4428021536509474

Epoch: 5| Step: 7
Training loss: 2.1578114702248516
Validation loss: 2.415506168257082

Epoch: 5| Step: 8
Training loss: 2.1684327874721365
Validation loss: 2.4316366835547942

Epoch: 5| Step: 9
Training loss: 2.5007717848613247
Validation loss: 2.4598443403850903

Epoch: 5| Step: 10
Training loss: 1.8072200031711858
Validation loss: 2.487405307628983

Epoch: 259| Step: 0
Training loss: 2.117270943098799
Validation loss: 2.468612964088028

Epoch: 5| Step: 1
Training loss: 1.98725885811714
Validation loss: 2.4525091933124457

Epoch: 5| Step: 2
Training loss: 2.3859200647462786
Validation loss: 2.390736691426528

Epoch: 5| Step: 3
Training loss: 2.266732832933974
Validation loss: 2.4815975634413925

Epoch: 5| Step: 4
Training loss: 2.160205585268166
Validation loss: 2.48357193408913

Epoch: 5| Step: 5
Training loss: 1.9559502880862596
Validation loss: 2.421271908998109

Epoch: 5| Step: 6
Training loss: 2.6122864339315535
Validation loss: 2.487458458636699

Epoch: 5| Step: 7
Training loss: 2.01190954988694
Validation loss: 2.4059558289596183

Epoch: 5| Step: 8
Training loss: 2.250596391262442
Validation loss: 2.4092804760944757

Epoch: 5| Step: 9
Training loss: 1.7136512033377882
Validation loss: 2.4353523037535187

Epoch: 5| Step: 10
Training loss: 2.139803318005207
Validation loss: 2.4088520603231696

Epoch: 260| Step: 0
Training loss: 2.265526394506973
Validation loss: 2.4603349835193136

Epoch: 5| Step: 1
Training loss: 1.8543020334728517
Validation loss: 2.4279166747748633

Epoch: 5| Step: 2
Training loss: 1.8732393263356577
Validation loss: 2.4808918951251253

Epoch: 5| Step: 3
Training loss: 2.2533561259966004
Validation loss: 2.4823724032055523

Epoch: 5| Step: 4
Training loss: 1.2929775087918494
Validation loss: 2.4463876431702913

Epoch: 5| Step: 5
Training loss: 2.208676317558693
Validation loss: 2.418549021684172

Epoch: 5| Step: 6
Training loss: 1.7894581852749547
Validation loss: 2.490834578733278

Epoch: 5| Step: 7
Training loss: 1.8528838774337113
Validation loss: 2.4275432901489187

Epoch: 5| Step: 8
Training loss: 3.0703814549747293
Validation loss: 2.4593388065639967

Epoch: 5| Step: 9
Training loss: 2.4601645572797084
Validation loss: 2.465217010436215

Epoch: 5| Step: 10
Training loss: 2.048178221517749
Validation loss: 2.4619891530309936

Epoch: 261| Step: 0
Training loss: 1.4292492637825884
Validation loss: 2.4300699657396287

Epoch: 5| Step: 1
Training loss: 1.795279283606381
Validation loss: 2.432324879452853

Epoch: 5| Step: 2
Training loss: 2.4760670452130604
Validation loss: 2.447778933980564

Epoch: 5| Step: 3
Training loss: 2.7226946046773874
Validation loss: 2.383851222570757

Epoch: 5| Step: 4
Training loss: 2.2429181015158406
Validation loss: 2.4645377574821605

Epoch: 5| Step: 5
Training loss: 1.827462035383617
Validation loss: 2.4338859804417927

Epoch: 5| Step: 6
Training loss: 2.109676650342475
Validation loss: 2.4785423937081315

Epoch: 5| Step: 7
Training loss: 2.805127632650861
Validation loss: 2.4184447004021363

Epoch: 5| Step: 8
Training loss: 1.4461392074521464
Validation loss: 2.429147935353705

Epoch: 5| Step: 9
Training loss: 1.9847146291775148
Validation loss: 2.4188241111159683

Epoch: 5| Step: 10
Training loss: 1.9501942733433324
Validation loss: 2.4386879760824374

Epoch: 262| Step: 0
Training loss: 2.054099111110309
Validation loss: 2.4570097133027065

Epoch: 5| Step: 1
Training loss: 2.2435955451359337
Validation loss: 2.412697410040843

Epoch: 5| Step: 2
Training loss: 2.670644287068298
Validation loss: 2.442636715293241

Epoch: 5| Step: 3
Training loss: 1.6191917935926756
Validation loss: 2.4201543998973496

Epoch: 5| Step: 4
Training loss: 2.146184787548236
Validation loss: 2.396522225687121

Epoch: 5| Step: 5
Training loss: 2.1841192005660988
Validation loss: 2.415377421149141

Epoch: 5| Step: 6
Training loss: 2.0764429843055003
Validation loss: 2.4366717996929417

Epoch: 5| Step: 7
Training loss: 1.8005043859579348
Validation loss: 2.416636534330798

Epoch: 5| Step: 8
Training loss: 2.2931299104219494
Validation loss: 2.414033582624161

Epoch: 5| Step: 9
Training loss: 2.068384849384261
Validation loss: 2.4306283097480126

Epoch: 5| Step: 10
Training loss: 2.1268754424734495
Validation loss: 2.442929087603764

Epoch: 263| Step: 0
Training loss: 1.9956178340430768
Validation loss: 2.4408427840195857

Epoch: 5| Step: 1
Training loss: 2.3922478646424223
Validation loss: 2.473405308895812

Epoch: 5| Step: 2
Training loss: 2.063922276090639
Validation loss: 2.482139061581729

Epoch: 5| Step: 3
Training loss: 2.487095716584826
Validation loss: 2.454921931932803

Epoch: 5| Step: 4
Training loss: 2.1583030988227625
Validation loss: 2.39931927144143

Epoch: 5| Step: 5
Training loss: 2.7921801327361098
Validation loss: 2.4374726795887796

Epoch: 5| Step: 6
Training loss: 1.9878670911244816
Validation loss: 2.478711224363351

Epoch: 5| Step: 7
Training loss: 1.9585487436632594
Validation loss: 2.436705338544486

Epoch: 5| Step: 8
Training loss: 1.7467647347086073
Validation loss: 2.4346931857952576

Epoch: 5| Step: 9
Training loss: 1.6006878953617236
Validation loss: 2.435629117998957

Epoch: 5| Step: 10
Training loss: 1.8291767713865779
Validation loss: 2.4371936985324965

Epoch: 264| Step: 0
Training loss: 2.0136029650703096
Validation loss: 2.425942694573961

Epoch: 5| Step: 1
Training loss: 2.622616639575348
Validation loss: 2.4651457178714966

Epoch: 5| Step: 2
Training loss: 2.0522021212462853
Validation loss: 2.4523217447377643

Epoch: 5| Step: 3
Training loss: 2.680197264115601
Validation loss: 2.4086964399897663

Epoch: 5| Step: 4
Training loss: 1.964111070176529
Validation loss: 2.4320140491434934

Epoch: 5| Step: 5
Training loss: 1.6671520797842367
Validation loss: 2.4655932629618293

Epoch: 5| Step: 6
Training loss: 2.0459840888619394
Validation loss: 2.4460255097299175

Epoch: 5| Step: 7
Training loss: 1.9102033675609738
Validation loss: 2.4652585394886324

Epoch: 5| Step: 8
Training loss: 1.9941067893569842
Validation loss: 2.4823711742468726

Epoch: 5| Step: 9
Training loss: 2.0310925936231587
Validation loss: 2.429637574869065

Epoch: 5| Step: 10
Training loss: 2.3396772475060654
Validation loss: 2.434691001950043

Epoch: 265| Step: 0
Training loss: 2.3134155523033817
Validation loss: 2.4161987765817714

Epoch: 5| Step: 1
Training loss: 2.486139210897965
Validation loss: 2.460646056799597

Epoch: 5| Step: 2
Training loss: 2.101302460532431
Validation loss: 2.516273445024368

Epoch: 5| Step: 3
Training loss: 1.7107046308509521
Validation loss: 2.5043242024772643

Epoch: 5| Step: 4
Training loss: 1.9137202988505573
Validation loss: 2.5100561310362237

Epoch: 5| Step: 5
Training loss: 2.5168437019715406
Validation loss: 2.436370589005906

Epoch: 5| Step: 6
Training loss: 2.351861370776057
Validation loss: 2.421419085018326

Epoch: 5| Step: 7
Training loss: 2.0197809238420295
Validation loss: 2.4940456607715356

Epoch: 5| Step: 8
Training loss: 2.0575434920950744
Validation loss: 2.460860575124612

Epoch: 5| Step: 9
Training loss: 2.175745307995325
Validation loss: 2.4781890245130698

Epoch: 5| Step: 10
Training loss: 1.955756162278489
Validation loss: 2.462293550698763

Epoch: 266| Step: 0
Training loss: 2.3613071235625216
Validation loss: 2.4507361399597016

Epoch: 5| Step: 1
Training loss: 1.7174620224086872
Validation loss: 2.4527327129365433

Epoch: 5| Step: 2
Training loss: 1.8571344548339248
Validation loss: 2.452931695578169

Epoch: 5| Step: 3
Training loss: 2.1245098670735727
Validation loss: 2.496253388181573

Epoch: 5| Step: 4
Training loss: 1.7141844018449248
Validation loss: 2.408249324746017

Epoch: 5| Step: 5
Training loss: 2.0062076076889266
Validation loss: 2.4252665345857976

Epoch: 5| Step: 6
Training loss: 2.2615891915275266
Validation loss: 2.4536916406108396

Epoch: 5| Step: 7
Training loss: 1.6174397294903868
Validation loss: 2.4669258966590064

Epoch: 5| Step: 8
Training loss: 2.3472270351062114
Validation loss: 2.4434935575863053

Epoch: 5| Step: 9
Training loss: 2.6915789854651413
Validation loss: 2.4695368855300193

Epoch: 5| Step: 10
Training loss: 2.753442863274697
Validation loss: 2.4496971474751166

Epoch: 267| Step: 0
Training loss: 2.710310102083669
Validation loss: 2.4513538509576476

Epoch: 5| Step: 1
Training loss: 1.9419668451301735
Validation loss: 2.4142169381967427

Epoch: 5| Step: 2
Training loss: 1.7760719527927895
Validation loss: 2.4398325867480075

Epoch: 5| Step: 3
Training loss: 2.128921256756168
Validation loss: 2.4406228161684766

Epoch: 5| Step: 4
Training loss: 1.860762775459802
Validation loss: 2.448865412277593

Epoch: 5| Step: 5
Training loss: 2.6032332820284085
Validation loss: 2.43980373313383

Epoch: 5| Step: 6
Training loss: 1.7815736844618901
Validation loss: 2.453565748269887

Epoch: 5| Step: 7
Training loss: 2.0023770511520724
Validation loss: 2.453223807578341

Epoch: 5| Step: 8
Training loss: 2.151904828133266
Validation loss: 2.4521301522113914

Epoch: 5| Step: 9
Training loss: 2.351990923714804
Validation loss: 2.4835186916458962

Epoch: 5| Step: 10
Training loss: 1.3477144090569864
Validation loss: 2.422585088531534

Epoch: 268| Step: 0
Training loss: 2.1157486308951072
Validation loss: 2.458861023414118

Epoch: 5| Step: 1
Training loss: 1.9678045757849596
Validation loss: 2.4508267896308467

Epoch: 5| Step: 2
Training loss: 1.6728603988565514
Validation loss: 2.369039269271918

Epoch: 5| Step: 3
Training loss: 2.406100875395066
Validation loss: 2.483379147653377

Epoch: 5| Step: 4
Training loss: 2.4854348279274014
Validation loss: 2.446724151955766

Epoch: 5| Step: 5
Training loss: 2.234205653035309
Validation loss: 2.4488011326467864

Epoch: 5| Step: 6
Training loss: 2.0616807177390424
Validation loss: 2.476043986424504

Epoch: 5| Step: 7
Training loss: 1.6499748112460935
Validation loss: 2.431172303697263

Epoch: 5| Step: 8
Training loss: 2.202897621487575
Validation loss: 2.431433995466942

Epoch: 5| Step: 9
Training loss: 2.548737295585875
Validation loss: 2.485026990083223

Epoch: 5| Step: 10
Training loss: 1.784570643827949
Validation loss: 2.414207802181005

Epoch: 269| Step: 0
Training loss: 2.0587509066331324
Validation loss: 2.3974156205767483

Epoch: 5| Step: 1
Training loss: 2.4027250157947493
Validation loss: 2.415023573640608

Epoch: 5| Step: 2
Training loss: 2.485632716016565
Validation loss: 2.43386551556229

Epoch: 5| Step: 3
Training loss: 1.6632669902457224
Validation loss: 2.421186705931509

Epoch: 5| Step: 4
Training loss: 2.130673072565799
Validation loss: 2.4690387090236774

Epoch: 5| Step: 5
Training loss: 1.4899390091670188
Validation loss: 2.405801862652657

Epoch: 5| Step: 6
Training loss: 2.7803654496376584
Validation loss: 2.453976088170274

Epoch: 5| Step: 7
Training loss: 2.143788582590859
Validation loss: 2.438480307330306

Epoch: 5| Step: 8
Training loss: 2.1416351830608824
Validation loss: 2.4402621353109404

Epoch: 5| Step: 9
Training loss: 2.113585614129315
Validation loss: 2.4216720850658717

Epoch: 5| Step: 10
Training loss: 2.0436711754019887
Validation loss: 2.433070387760058

Epoch: 270| Step: 0
Training loss: 2.2968868333161376
Validation loss: 2.4578202388095476

Epoch: 5| Step: 1
Training loss: 2.3161367738885557
Validation loss: 2.4384036854013065

Epoch: 5| Step: 2
Training loss: 1.9080743658380397
Validation loss: 2.4704752732566173

Epoch: 5| Step: 3
Training loss: 2.6734477093678346
Validation loss: 2.464587955499818

Epoch: 5| Step: 4
Training loss: 2.443435875101375
Validation loss: 2.4254019591332328

Epoch: 5| Step: 5
Training loss: 2.1569852819245683
Validation loss: 2.4199483394727554

Epoch: 5| Step: 6
Training loss: 1.9441336004871086
Validation loss: 2.4370801257444534

Epoch: 5| Step: 7
Training loss: 2.0337267521125595
Validation loss: 2.4581881748458962

Epoch: 5| Step: 8
Training loss: 1.7279054416021753
Validation loss: 2.41095853289727

Epoch: 5| Step: 9
Training loss: 1.8985034318942662
Validation loss: 2.503361113017427

Epoch: 5| Step: 10
Training loss: 1.7677094300116256
Validation loss: 2.517593910071507

Epoch: 271| Step: 0
Training loss: 1.5586153186653753
Validation loss: 2.4489399780320293

Epoch: 5| Step: 1
Training loss: 1.730860680829526
Validation loss: 2.4756419228464983

Epoch: 5| Step: 2
Training loss: 2.4384607231288733
Validation loss: 2.425215753650216

Epoch: 5| Step: 3
Training loss: 2.210766465543871
Validation loss: 2.4749189255205937

Epoch: 5| Step: 4
Training loss: 1.9865582088119873
Validation loss: 2.4879447606595297

Epoch: 5| Step: 5
Training loss: 1.9760035150357693
Validation loss: 2.434404892864088

Epoch: 5| Step: 6
Training loss: 1.9699301437152954
Validation loss: 2.4564468688148224

Epoch: 5| Step: 7
Training loss: 2.121350351903532
Validation loss: 2.436328243441921

Epoch: 5| Step: 8
Training loss: 2.0216019600840984
Validation loss: 2.437597698255212

Epoch: 5| Step: 9
Training loss: 2.176358651434844
Validation loss: 2.45155219782523

Epoch: 5| Step: 10
Training loss: 2.7565653198905857
Validation loss: 2.4755919256718593

Epoch: 272| Step: 0
Training loss: 2.237739643924033
Validation loss: 2.4972287918513536

Epoch: 5| Step: 1
Training loss: 2.912922899707631
Validation loss: 2.4377081745062887

Epoch: 5| Step: 2
Training loss: 2.262040242222512
Validation loss: 2.4586509456311196

Epoch: 5| Step: 3
Training loss: 1.7899670708680286
Validation loss: 2.4363049621701047

Epoch: 5| Step: 4
Training loss: 2.1134083933492023
Validation loss: 2.3788632059075057

Epoch: 5| Step: 5
Training loss: 2.154415068578877
Validation loss: 2.405039891727025

Epoch: 5| Step: 6
Training loss: 2.0862330538071157
Validation loss: 2.42235639738401

Epoch: 5| Step: 7
Training loss: 1.6002126075632253
Validation loss: 2.450908556504954

Epoch: 5| Step: 8
Training loss: 2.014633289600105
Validation loss: 2.4424213468493576

Epoch: 5| Step: 9
Training loss: 1.631728620213485
Validation loss: 2.466830479208019

Epoch: 5| Step: 10
Training loss: 1.69059060673448
Validation loss: 2.422174968263573

Epoch: 273| Step: 0
Training loss: 1.8590429955281862
Validation loss: 2.4098606622081213

Epoch: 5| Step: 1
Training loss: 2.51365451762291
Validation loss: 2.4231288621424745

Epoch: 5| Step: 2
Training loss: 1.9190215971637368
Validation loss: 2.463366057202874

Epoch: 5| Step: 3
Training loss: 1.8707675211431436
Validation loss: 2.463904917628237

Epoch: 5| Step: 4
Training loss: 2.5271833743310195
Validation loss: 2.435416322548436

Epoch: 5| Step: 5
Training loss: 1.3476674839601972
Validation loss: 2.478889719411669

Epoch: 5| Step: 6
Training loss: 2.595967826808473
Validation loss: 2.4520334668733383

Epoch: 5| Step: 7
Training loss: 2.072433364220259
Validation loss: 2.4356125243673588

Epoch: 5| Step: 8
Training loss: 1.7406095877329755
Validation loss: 2.4141720558000532

Epoch: 5| Step: 9
Training loss: 2.282062856004116
Validation loss: 2.455995534393557

Epoch: 5| Step: 10
Training loss: 2.0966014518764062
Validation loss: 2.416539332232147

Epoch: 274| Step: 0
Training loss: 2.378682844824721
Validation loss: 2.4491744252908694

Epoch: 5| Step: 1
Training loss: 1.6813722190252556
Validation loss: 2.438850668079775

Epoch: 5| Step: 2
Training loss: 2.1250577806583224
Validation loss: 2.4647239150318043

Epoch: 5| Step: 3
Training loss: 2.2953438358751694
Validation loss: 2.4840543012010388

Epoch: 5| Step: 4
Training loss: 1.8539458439807055
Validation loss: 2.4021845314853634

Epoch: 5| Step: 5
Training loss: 1.9903312861663576
Validation loss: 2.4596893129711774

Epoch: 5| Step: 6
Training loss: 1.5045152892441664
Validation loss: 2.4483428161742813

Epoch: 5| Step: 7
Training loss: 2.168205179605173
Validation loss: 2.5168823756324223

Epoch: 5| Step: 8
Training loss: 2.438132766363139
Validation loss: 2.459854592448591

Epoch: 5| Step: 9
Training loss: 2.011863214435169
Validation loss: 2.460344058179987

Epoch: 5| Step: 10
Training loss: 1.980492646263163
Validation loss: 2.448427827066038

Epoch: 275| Step: 0
Training loss: 1.4470027628241515
Validation loss: 2.419027839082944

Epoch: 5| Step: 1
Training loss: 1.7936620099221627
Validation loss: 2.431761818290636

Epoch: 5| Step: 2
Training loss: 1.86784995868784
Validation loss: 2.375170037228051

Epoch: 5| Step: 3
Training loss: 1.9574431634985028
Validation loss: 2.425564508602142

Epoch: 5| Step: 4
Training loss: 2.2143879308707928
Validation loss: 2.472388512949974

Epoch: 5| Step: 5
Training loss: 2.322068291855038
Validation loss: 2.4037488167100056

Epoch: 5| Step: 6
Training loss: 1.7309637115306566
Validation loss: 2.4117075675407125

Epoch: 5| Step: 7
Training loss: 2.907730873761964
Validation loss: 2.4469096321916965

Epoch: 5| Step: 8
Training loss: 2.033708932716345
Validation loss: 2.4014234715528264

Epoch: 5| Step: 9
Training loss: 2.0849362374122395
Validation loss: 2.448530796559569

Epoch: 5| Step: 10
Training loss: 2.058327239589963
Validation loss: 2.4263608926673284

Epoch: 276| Step: 0
Training loss: 2.803913487818048
Validation loss: 2.400877670279793

Epoch: 5| Step: 1
Training loss: 1.6279337882371867
Validation loss: 2.451160361885526

Epoch: 5| Step: 2
Training loss: 2.0661807883706436
Validation loss: 2.427211789939204

Epoch: 5| Step: 3
Training loss: 2.479221492983875
Validation loss: 2.444372367596425

Epoch: 5| Step: 4
Training loss: 2.063996321305242
Validation loss: 2.4402528819650793

Epoch: 5| Step: 5
Training loss: 1.835663210893579
Validation loss: 2.4116575901657726

Epoch: 5| Step: 6
Training loss: 1.843249948224008
Validation loss: 2.4173130731009125

Epoch: 5| Step: 7
Training loss: 1.962860805607609
Validation loss: 2.4693686687656906

Epoch: 5| Step: 8
Training loss: 1.8393469137626244
Validation loss: 2.4662133026240993

Epoch: 5| Step: 9
Training loss: 1.9906734322924577
Validation loss: 2.465442928975765

Epoch: 5| Step: 10
Training loss: 1.8442539884036244
Validation loss: 2.4773246027568785

Epoch: 277| Step: 0
Training loss: 2.1141388399335037
Validation loss: 2.4206959776444115

Epoch: 5| Step: 1
Training loss: 1.9891649242319445
Validation loss: 2.5052936723532966

Epoch: 5| Step: 2
Training loss: 2.0344273292385946
Validation loss: 2.4385748934026314

Epoch: 5| Step: 3
Training loss: 2.058101703825886
Validation loss: 2.5005432646126127

Epoch: 5| Step: 4
Training loss: 1.9914976833060904
Validation loss: 2.412881556699821

Epoch: 5| Step: 5
Training loss: 2.025369789362152
Validation loss: 2.4627795639409067

Epoch: 5| Step: 6
Training loss: 2.518387693184104
Validation loss: 2.444351824801556

Epoch: 5| Step: 7
Training loss: 1.5869882795145043
Validation loss: 2.4623270404115867

Epoch: 5| Step: 8
Training loss: 2.204405067786059
Validation loss: 2.4168657900451684

Epoch: 5| Step: 9
Training loss: 1.6704613243725115
Validation loss: 2.4346745840885857

Epoch: 5| Step: 10
Training loss: 2.4484917688837062
Validation loss: 2.41081729110442

Epoch: 278| Step: 0
Training loss: 1.9188239216932226
Validation loss: 2.447732504203227

Epoch: 5| Step: 1
Training loss: 1.6723076091326585
Validation loss: 2.4355215063136586

Epoch: 5| Step: 2
Training loss: 1.7670140161870502
Validation loss: 2.394644741931366

Epoch: 5| Step: 3
Training loss: 1.2721130410773938
Validation loss: 2.4478722328511697

Epoch: 5| Step: 4
Training loss: 2.0365813495395257
Validation loss: 2.4321026781451054

Epoch: 5| Step: 5
Training loss: 2.4341129343104724
Validation loss: 2.4310808209735173

Epoch: 5| Step: 6
Training loss: 2.1842432028721555
Validation loss: 2.412238778495173

Epoch: 5| Step: 7
Training loss: 2.4212088376289636
Validation loss: 2.4209832875004205

Epoch: 5| Step: 8
Training loss: 2.3985179179374994
Validation loss: 2.4714769645632244

Epoch: 5| Step: 9
Training loss: 2.1200828883323544
Validation loss: 2.4962267878331454

Epoch: 5| Step: 10
Training loss: 2.332745875475844
Validation loss: 2.4153183730352743

Epoch: 279| Step: 0
Training loss: 1.8884887606544134
Validation loss: 2.446025212073993

Epoch: 5| Step: 1
Training loss: 1.5489115554255388
Validation loss: 2.425285382864076

Epoch: 5| Step: 2
Training loss: 2.123905236474012
Validation loss: 2.4286119749886788

Epoch: 5| Step: 3
Training loss: 1.907023913765142
Validation loss: 2.4305145514721604

Epoch: 5| Step: 4
Training loss: 2.5361955155357565
Validation loss: 2.4451281787910095

Epoch: 5| Step: 5
Training loss: 2.7643354609967425
Validation loss: 2.46920240594274

Epoch: 5| Step: 6
Training loss: 1.9565864712377377
Validation loss: 2.4274777032115376

Epoch: 5| Step: 7
Training loss: 1.635829347024894
Validation loss: 2.4430135218847284

Epoch: 5| Step: 8
Training loss: 1.9428201051796041
Validation loss: 2.442756733864267

Epoch: 5| Step: 9
Training loss: 1.9897732336147547
Validation loss: 2.387123371816963

Epoch: 5| Step: 10
Training loss: 2.2522757994649476
Validation loss: 2.382708292537873

Epoch: 280| Step: 0
Training loss: 1.9769786652922257
Validation loss: 2.4689739204146814

Epoch: 5| Step: 1
Training loss: 1.8408453092218615
Validation loss: 2.3619058030075597

Epoch: 5| Step: 2
Training loss: 2.3228617320956335
Validation loss: 2.4728921866049944

Epoch: 5| Step: 3
Training loss: 2.466309898797541
Validation loss: 2.4247244171396707

Epoch: 5| Step: 4
Training loss: 1.9023179947443203
Validation loss: 2.433116153260441

Epoch: 5| Step: 5
Training loss: 1.4636819122923204
Validation loss: 2.4559768654316683

Epoch: 5| Step: 6
Training loss: 1.8549129255890515
Validation loss: 2.45724827899738

Epoch: 5| Step: 7
Training loss: 2.1589694358566955
Validation loss: 2.446334111225841

Epoch: 5| Step: 8
Training loss: 2.1850993471234474
Validation loss: 2.380501338907265

Epoch: 5| Step: 9
Training loss: 2.292567879307326
Validation loss: 2.4998889093430274

Epoch: 5| Step: 10
Training loss: 1.7861095862862482
Validation loss: 2.4563648928341553

Epoch: 281| Step: 0
Training loss: 1.6382686587219555
Validation loss: 2.4665288875328497

Epoch: 5| Step: 1
Training loss: 2.059059394420714
Validation loss: 2.4317877280075204

Epoch: 5| Step: 2
Training loss: 2.360567713520361
Validation loss: 2.497787937708058

Epoch: 5| Step: 3
Training loss: 2.078157123518166
Validation loss: 2.4661428346245455

Epoch: 5| Step: 4
Training loss: 2.027003382811243
Validation loss: 2.4564717834520162

Epoch: 5| Step: 5
Training loss: 2.6501161549860814
Validation loss: 2.4475375441965705

Epoch: 5| Step: 6
Training loss: 1.9063201641239993
Validation loss: 2.4376048477546943

Epoch: 5| Step: 7
Training loss: 2.4717283029345745
Validation loss: 2.4766069287067745

Epoch: 5| Step: 8
Training loss: 1.854310583751431
Validation loss: 2.420016163625648

Epoch: 5| Step: 9
Training loss: 1.7173912920135683
Validation loss: 2.416994652504988

Epoch: 5| Step: 10
Training loss: 1.7889195014408832
Validation loss: 2.439179120048615

Epoch: 282| Step: 0
Training loss: 1.9697319488376093
Validation loss: 2.4235945499458165

Epoch: 5| Step: 1
Training loss: 2.1521297286117336
Validation loss: 2.5193995994722944

Epoch: 5| Step: 2
Training loss: 1.8706855726902205
Validation loss: 2.4583232483849025

Epoch: 5| Step: 3
Training loss: 1.2934275847352417
Validation loss: 2.5028549986656934

Epoch: 5| Step: 4
Training loss: 1.9654224066953425
Validation loss: 2.4405580657641397

Epoch: 5| Step: 5
Training loss: 2.1322895009660803
Validation loss: 2.4916734294145897

Epoch: 5| Step: 6
Training loss: 1.9515930271128101
Validation loss: 2.446281958292501

Epoch: 5| Step: 7
Training loss: 1.9210478080229652
Validation loss: 2.4328416885487103

Epoch: 5| Step: 8
Training loss: 2.2808987072667826
Validation loss: 2.4460800503743876

Epoch: 5| Step: 9
Training loss: 2.1355115419726576
Validation loss: 2.4297745779425517

Epoch: 5| Step: 10
Training loss: 2.7087866966110155
Validation loss: 2.457033756220328

Epoch: 283| Step: 0
Training loss: 1.6654066647682677
Validation loss: 2.439960827792914

Epoch: 5| Step: 1
Training loss: 1.7603361875056684
Validation loss: 2.479260826925126

Epoch: 5| Step: 2
Training loss: 2.2478274346837535
Validation loss: 2.4029719335351607

Epoch: 5| Step: 3
Training loss: 2.61051358720173
Validation loss: 2.4437326617444497

Epoch: 5| Step: 4
Training loss: 2.6269729102995627
Validation loss: 2.4382565283790094

Epoch: 5| Step: 5
Training loss: 2.1294793433759214
Validation loss: 2.422104570118124

Epoch: 5| Step: 6
Training loss: 1.898398316532358
Validation loss: 2.425945411503919

Epoch: 5| Step: 7
Training loss: 1.9575230024406427
Validation loss: 2.388571461822916

Epoch: 5| Step: 8
Training loss: 1.8032056661508349
Validation loss: 2.382919843418719

Epoch: 5| Step: 9
Training loss: 1.8938608143428581
Validation loss: 2.393590231432582

Epoch: 5| Step: 10
Training loss: 2.136963880798675
Validation loss: 2.3962591787053733

Epoch: 284| Step: 0
Training loss: 1.7435413796382884
Validation loss: 2.4208146562329356

Epoch: 5| Step: 1
Training loss: 1.725413082253882
Validation loss: 2.412227523797709

Epoch: 5| Step: 2
Training loss: 1.7816164409432127
Validation loss: 2.4223178560513468

Epoch: 5| Step: 3
Training loss: 2.3210401838933774
Validation loss: 2.4319285277386538

Epoch: 5| Step: 4
Training loss: 2.116439630942915
Validation loss: 2.4448569112318976

Epoch: 5| Step: 5
Training loss: 1.9388419395502146
Validation loss: 2.4216792778772094

Epoch: 5| Step: 6
Training loss: 2.1576863908758495
Validation loss: 2.4133161790353452

Epoch: 5| Step: 7
Training loss: 1.394847716424874
Validation loss: 2.458354287312846

Epoch: 5| Step: 8
Training loss: 2.3551907857730203
Validation loss: 2.497059103407833

Epoch: 5| Step: 9
Training loss: 2.519637325922306
Validation loss: 2.44681464013032

Epoch: 5| Step: 10
Training loss: 1.890726386260105
Validation loss: 2.4645421773370644

Epoch: 285| Step: 0
Training loss: 1.7660609694483478
Validation loss: 2.432060817999164

Epoch: 5| Step: 1
Training loss: 2.122558312934908
Validation loss: 2.438846106008423

Epoch: 5| Step: 2
Training loss: 1.6611757267292533
Validation loss: 2.4716091191552807

Epoch: 5| Step: 3
Training loss: 1.9220051915181016
Validation loss: 2.389246098509378

Epoch: 5| Step: 4
Training loss: 1.4505229335840477
Validation loss: 2.431518001259214

Epoch: 5| Step: 5
Training loss: 2.269929571865715
Validation loss: 2.4806349986959906

Epoch: 5| Step: 6
Training loss: 1.83688472904875
Validation loss: 2.480648187179189

Epoch: 5| Step: 7
Training loss: 2.171295857228001
Validation loss: 2.4510530503220647

Epoch: 5| Step: 8
Training loss: 2.3843024926516443
Validation loss: 2.4568901483848

Epoch: 5| Step: 9
Training loss: 2.024806910598519
Validation loss: 2.474193850815118

Epoch: 5| Step: 10
Training loss: 2.1568540749741096
Validation loss: 2.457215308493104

Epoch: 286| Step: 0
Training loss: 2.2981690375139494
Validation loss: 2.420317561832141

Epoch: 5| Step: 1
Training loss: 2.0727660413550835
Validation loss: 2.454353755794425

Epoch: 5| Step: 2
Training loss: 2.3219440516681593
Validation loss: 2.422981799499488

Epoch: 5| Step: 3
Training loss: 2.4291021003670408
Validation loss: 2.4403589939265524

Epoch: 5| Step: 4
Training loss: 1.346129329164699
Validation loss: 2.4376495216603673

Epoch: 5| Step: 5
Training loss: 1.8076253650713188
Validation loss: 2.454654410962925

Epoch: 5| Step: 6
Training loss: 1.7372945320986208
Validation loss: 2.3978729625808284

Epoch: 5| Step: 7
Training loss: 2.4379814846158765
Validation loss: 2.41986134494537

Epoch: 5| Step: 8
Training loss: 1.9538714393952767
Validation loss: 2.4599016443593036

Epoch: 5| Step: 9
Training loss: 1.802014439612824
Validation loss: 2.4027527718475037

Epoch: 5| Step: 10
Training loss: 1.7618222089952802
Validation loss: 2.474544260860057

Epoch: 287| Step: 0
Training loss: 1.8741047311298822
Validation loss: 2.38979049595553

Epoch: 5| Step: 1
Training loss: 2.504205218720267
Validation loss: 2.4719447333189843

Epoch: 5| Step: 2
Training loss: 2.12516952287248
Validation loss: 2.4176410270925914

Epoch: 5| Step: 3
Training loss: 2.046056918831951
Validation loss: 2.464337073780078

Epoch: 5| Step: 4
Training loss: 2.058176537640835
Validation loss: 2.465172500207316

Epoch: 5| Step: 5
Training loss: 2.6038530593232636
Validation loss: 2.5283076256770722

Epoch: 5| Step: 6
Training loss: 1.9440119428856477
Validation loss: 2.485236016319098

Epoch: 5| Step: 7
Training loss: 1.4393349421729078
Validation loss: 2.4578666219656147

Epoch: 5| Step: 8
Training loss: 1.838145774456715
Validation loss: 2.51292611263

Epoch: 5| Step: 9
Training loss: 2.195011647743134
Validation loss: 2.5255236660458418

Epoch: 5| Step: 10
Training loss: 1.692726448157778
Validation loss: 2.4772148043169637

Epoch: 288| Step: 0
Training loss: 2.0795370481712503
Validation loss: 2.4541824107019656

Epoch: 5| Step: 1
Training loss: 1.7993783513124402
Validation loss: 2.423595827749099

Epoch: 5| Step: 2
Training loss: 1.4849580924546104
Validation loss: 2.3936092402473466

Epoch: 5| Step: 3
Training loss: 2.1723386420586572
Validation loss: 2.4965766119895996

Epoch: 5| Step: 4
Training loss: 2.6300266820040017
Validation loss: 2.4789516706991526

Epoch: 5| Step: 5
Training loss: 2.122735780665847
Validation loss: 2.4280198320391544

Epoch: 5| Step: 6
Training loss: 1.7042453125929362
Validation loss: 2.3946558758587333

Epoch: 5| Step: 7
Training loss: 1.7210593228353595
Validation loss: 2.453796305839244

Epoch: 5| Step: 8
Training loss: 2.2248643255122897
Validation loss: 2.396774355080514

Epoch: 5| Step: 9
Training loss: 1.5978867194375537
Validation loss: 2.4767086107195198

Epoch: 5| Step: 10
Training loss: 2.2093051235690195
Validation loss: 2.428956035813754

Epoch: 289| Step: 0
Training loss: 1.7189694351221831
Validation loss: 2.428374045017485

Epoch: 5| Step: 1
Training loss: 2.001390808031602
Validation loss: 2.4097933708533286

Epoch: 5| Step: 2
Training loss: 2.019097818462196
Validation loss: 2.4710586675302046

Epoch: 5| Step: 3
Training loss: 1.7794355554061254
Validation loss: 2.431638694604604

Epoch: 5| Step: 4
Training loss: 2.2023692897846234
Validation loss: 2.4439646530702883

Epoch: 5| Step: 5
Training loss: 2.1116589649584876
Validation loss: 2.411993578663483

Epoch: 5| Step: 6
Training loss: 2.172110455600577
Validation loss: 2.3875726522661784

Epoch: 5| Step: 7
Training loss: 1.9017349302904099
Validation loss: 2.442294589096873

Epoch: 5| Step: 8
Training loss: 2.132964747098677
Validation loss: 2.488062508666767

Epoch: 5| Step: 9
Training loss: 2.381299248133543
Validation loss: 2.4937380413934775

Epoch: 5| Step: 10
Training loss: 1.6936982375677745
Validation loss: 2.4573461665087812

Epoch: 290| Step: 0
Training loss: 2.3333544276056006
Validation loss: 2.432983987819324

Epoch: 5| Step: 1
Training loss: 2.2681712607792863
Validation loss: 2.498569502774361

Epoch: 5| Step: 2
Training loss: 2.37650953806916
Validation loss: 2.419747319397664

Epoch: 5| Step: 3
Training loss: 1.5901182345448885
Validation loss: 2.4438906241816793

Epoch: 5| Step: 4
Training loss: 2.0390718540254795
Validation loss: 2.4646423745381454

Epoch: 5| Step: 5
Training loss: 2.2725441347375046
Validation loss: 2.4492069367154623

Epoch: 5| Step: 6
Training loss: 1.770157389566784
Validation loss: 2.459188566644088

Epoch: 5| Step: 7
Training loss: 2.1014987411186663
Validation loss: 2.477748864246135

Epoch: 5| Step: 8
Training loss: 1.7069409518942897
Validation loss: 2.458414977066496

Epoch: 5| Step: 9
Training loss: 1.6766484646475919
Validation loss: 2.471854986705061

Epoch: 5| Step: 10
Training loss: 1.9502047260116446
Validation loss: 2.4410014774921147

Epoch: 291| Step: 0
Training loss: 1.9698597641229867
Validation loss: 2.475798460322965

Epoch: 5| Step: 1
Training loss: 2.010013546494721
Validation loss: 2.445788001276115

Epoch: 5| Step: 2
Training loss: 2.2916318255001213
Validation loss: 2.4307830527896312

Epoch: 5| Step: 3
Training loss: 2.022413782797699
Validation loss: 2.4604786028474726

Epoch: 5| Step: 4
Training loss: 2.0009940776365562
Validation loss: 2.4034712746534455

Epoch: 5| Step: 5
Training loss: 1.7899835872430472
Validation loss: 2.48179394152197

Epoch: 5| Step: 6
Training loss: 1.9084548081405979
Validation loss: 2.4387190562513497

Epoch: 5| Step: 7
Training loss: 2.0350245691264375
Validation loss: 2.405127455396115

Epoch: 5| Step: 8
Training loss: 1.7033185936326753
Validation loss: 2.360460932915472

Epoch: 5| Step: 9
Training loss: 2.207306593201955
Validation loss: 2.4600166281571596

Epoch: 5| Step: 10
Training loss: 1.916248552355434
Validation loss: 2.422954105889294

Epoch: 292| Step: 0
Training loss: 2.068838379231177
Validation loss: 2.479292890052144

Epoch: 5| Step: 1
Training loss: 1.6320240362070928
Validation loss: 2.415641243214906

Epoch: 5| Step: 2
Training loss: 2.183602921632125
Validation loss: 2.4789532550366955

Epoch: 5| Step: 3
Training loss: 2.2529151892887964
Validation loss: 2.439514850347298

Epoch: 5| Step: 4
Training loss: 1.8449103373421787
Validation loss: 2.4353019705102033

Epoch: 5| Step: 5
Training loss: 2.4439757962316073
Validation loss: 2.3756077360716787

Epoch: 5| Step: 6
Training loss: 1.609354926419298
Validation loss: 2.443935678829815

Epoch: 5| Step: 7
Training loss: 2.3305179663642654
Validation loss: 2.5079885191070685

Epoch: 5| Step: 8
Training loss: 2.0394441094059492
Validation loss: 2.454445807255343

Epoch: 5| Step: 9
Training loss: 1.7038234713323481
Validation loss: 2.422591374381179

Epoch: 5| Step: 10
Training loss: 1.6555025105366614
Validation loss: 2.4242225175319425

Epoch: 293| Step: 0
Training loss: 1.837347390201835
Validation loss: 2.436801352764429

Epoch: 5| Step: 1
Training loss: 2.1353399371496518
Validation loss: 2.45052923748325

Epoch: 5| Step: 2
Training loss: 1.9524624730800872
Validation loss: 2.456219026913577

Epoch: 5| Step: 3
Training loss: 2.204213191540738
Validation loss: 2.413816885621638

Epoch: 5| Step: 4
Training loss: 2.6615404289309574
Validation loss: 2.4525425537389127

Epoch: 5| Step: 5
Training loss: 1.6150680880764516
Validation loss: 2.436291545742929

Epoch: 5| Step: 6
Training loss: 1.8684537416713385
Validation loss: 2.427948063353121

Epoch: 5| Step: 7
Training loss: 2.145962485960531
Validation loss: 2.4310405545768297

Epoch: 5| Step: 8
Training loss: 1.332698487104346
Validation loss: 2.4529156569098753

Epoch: 5| Step: 9
Training loss: 1.6046424837122
Validation loss: 2.456123912674582

Epoch: 5| Step: 10
Training loss: 2.042789837969887
Validation loss: 2.453026029587553

Epoch: 294| Step: 0
Training loss: 1.8908901816786456
Validation loss: 2.4315060650749643

Epoch: 5| Step: 1
Training loss: 1.3905757509576047
Validation loss: 2.462273309431252

Epoch: 5| Step: 2
Training loss: 1.670193334455577
Validation loss: 2.4858065032223355

Epoch: 5| Step: 3
Training loss: 2.0827187839724237
Validation loss: 2.3992336296386565

Epoch: 5| Step: 4
Training loss: 1.869329397142069
Validation loss: 2.3993462959880927

Epoch: 5| Step: 5
Training loss: 2.314534400768346
Validation loss: 2.400317912191641

Epoch: 5| Step: 6
Training loss: 2.3121875861206944
Validation loss: 2.4148619542952656

Epoch: 5| Step: 7
Training loss: 2.030068743627003
Validation loss: 2.4677462174637617

Epoch: 5| Step: 8
Training loss: 1.8614524967875572
Validation loss: 2.4039956783491774

Epoch: 5| Step: 9
Training loss: 1.6594559931699973
Validation loss: 2.4476722471333696

Epoch: 5| Step: 10
Training loss: 2.6592751722952785
Validation loss: 2.460509950082415

Epoch: 295| Step: 0
Training loss: 2.4280244587981343
Validation loss: 2.4542183843968166

Epoch: 5| Step: 1
Training loss: 1.6989247736451214
Validation loss: 2.473929768749845

Epoch: 5| Step: 2
Training loss: 1.995094123665943
Validation loss: 2.491635837858764

Epoch: 5| Step: 3
Training loss: 2.1195377382094067
Validation loss: 2.41221270662679

Epoch: 5| Step: 4
Training loss: 2.1848030904213758
Validation loss: 2.468721688937558

Epoch: 5| Step: 5
Training loss: 2.146766262271387
Validation loss: 2.463942320473379

Epoch: 5| Step: 6
Training loss: 2.0316898749978907
Validation loss: 2.4334927421416808

Epoch: 5| Step: 7
Training loss: 1.9781932511690932
Validation loss: 2.3922589438193453

Epoch: 5| Step: 8
Training loss: 1.968798258356489
Validation loss: 2.4059312606931433

Epoch: 5| Step: 9
Training loss: 1.9056182189600557
Validation loss: 2.4586853368357167

Epoch: 5| Step: 10
Training loss: 1.1757732910697976
Validation loss: 2.4805712968646625

Epoch: 296| Step: 0
Training loss: 2.2036220990745634
Validation loss: 2.419139185629235

Epoch: 5| Step: 1
Training loss: 2.263523468866649
Validation loss: 2.4940655537270393

Epoch: 5| Step: 2
Training loss: 1.5425033446883134
Validation loss: 2.4408680816457853

Epoch: 5| Step: 3
Training loss: 1.837717500127609
Validation loss: 2.48211055723175

Epoch: 5| Step: 4
Training loss: 2.0521600647601748
Validation loss: 2.442123957846641

Epoch: 5| Step: 5
Training loss: 2.1896055714657265
Validation loss: 2.4196382925662645

Epoch: 5| Step: 6
Training loss: 1.8071466510502405
Validation loss: 2.3984663178866192

Epoch: 5| Step: 7
Training loss: 1.3597737746856107
Validation loss: 2.464864367467447

Epoch: 5| Step: 8
Training loss: 2.4773546750956474
Validation loss: 2.451021019418531

Epoch: 5| Step: 9
Training loss: 1.981029363434801
Validation loss: 2.393943132647904

Epoch: 5| Step: 10
Training loss: 1.89813782638321
Validation loss: 2.4078516339567306

Epoch: 297| Step: 0
Training loss: 2.321638556823929
Validation loss: 2.430488183591326

Epoch: 5| Step: 1
Training loss: 1.6506527303195697
Validation loss: 2.4237442133625944

Epoch: 5| Step: 2
Training loss: 1.9897436373642814
Validation loss: 2.444216203622623

Epoch: 5| Step: 3
Training loss: 1.6182664598240473
Validation loss: 2.373223805808393

Epoch: 5| Step: 4
Training loss: 1.9899003606800443
Validation loss: 2.4623341389311464

Epoch: 5| Step: 5
Training loss: 1.7171765841691622
Validation loss: 2.3893646300076457

Epoch: 5| Step: 6
Training loss: 2.697169982407758
Validation loss: 2.4156110223832363

Epoch: 5| Step: 7
Training loss: 1.5270441644423618
Validation loss: 2.488662489357685

Epoch: 5| Step: 8
Training loss: 2.2666387986358667
Validation loss: 2.526506857392761

Epoch: 5| Step: 9
Training loss: 2.1665353246151273
Validation loss: 2.400252937503787

Epoch: 5| Step: 10
Training loss: 1.6769094515235488
Validation loss: 2.3918410400106955

Epoch: 298| Step: 0
Training loss: 1.6069782520951892
Validation loss: 2.4453045794023796

Epoch: 5| Step: 1
Training loss: 2.5681157797979566
Validation loss: 2.456687087863815

Epoch: 5| Step: 2
Training loss: 1.9434048287908274
Validation loss: 2.4188463839297536

Epoch: 5| Step: 3
Training loss: 2.0772442779884583
Validation loss: 2.4309357358587844

Epoch: 5| Step: 4
Training loss: 1.7110802577830266
Validation loss: 2.4023539902676996

Epoch: 5| Step: 5
Training loss: 2.4267534896842786
Validation loss: 2.417998114382773

Epoch: 5| Step: 6
Training loss: 1.636253563954994
Validation loss: 2.440065556149345

Epoch: 5| Step: 7
Training loss: 1.988834086905702
Validation loss: 2.417124494998134

Epoch: 5| Step: 8
Training loss: 1.6426044693329949
Validation loss: 2.4010337028845594

Epoch: 5| Step: 9
Training loss: 1.775044255309395
Validation loss: 2.423429593953434

Epoch: 5| Step: 10
Training loss: 2.255615538262542
Validation loss: 2.433251015027486

Epoch: 299| Step: 0
Training loss: 2.219325890820897
Validation loss: 2.391672745406404

Epoch: 5| Step: 1
Training loss: 2.0328895407642618
Validation loss: 2.4149155989557767

Epoch: 5| Step: 2
Training loss: 1.6618036690532247
Validation loss: 2.36583540574838

Epoch: 5| Step: 3
Training loss: 1.9968306940981086
Validation loss: 2.4463368348514782

Epoch: 5| Step: 4
Training loss: 2.2736478623009337
Validation loss: 2.4359667509567915

Epoch: 5| Step: 5
Training loss: 2.00038119498058
Validation loss: 2.4809324074548598

Epoch: 5| Step: 6
Training loss: 2.129819005878841
Validation loss: 2.443391202069465

Epoch: 5| Step: 7
Training loss: 1.9097586063810805
Validation loss: 2.467229588615566

Epoch: 5| Step: 8
Training loss: 2.3172533824606645
Validation loss: 2.3959159876051546

Epoch: 5| Step: 9
Training loss: 1.2193678732409072
Validation loss: 2.3830463608687547

Epoch: 5| Step: 10
Training loss: 1.6385877039755898
Validation loss: 2.4484442259995607

Epoch: 300| Step: 0
Training loss: 1.8499009930691765
Validation loss: 2.4454288244664815

Epoch: 5| Step: 1
Training loss: 1.2777277284762452
Validation loss: 2.4428487212133185

Epoch: 5| Step: 2
Training loss: 2.3029910293185742
Validation loss: 2.40228537665252

Epoch: 5| Step: 3
Training loss: 2.0974966659792202
Validation loss: 2.408059524241276

Epoch: 5| Step: 4
Training loss: 2.2377108767569913
Validation loss: 2.4225433369539697

Epoch: 5| Step: 5
Training loss: 1.8385190304955739
Validation loss: 2.419167184661973

Epoch: 5| Step: 6
Training loss: 1.784558018586409
Validation loss: 2.3796749821128307

Epoch: 5| Step: 7
Training loss: 2.221592331730401
Validation loss: 2.472980312598205

Epoch: 5| Step: 8
Training loss: 1.9220262173344176
Validation loss: 2.4741620200242944

Epoch: 5| Step: 9
Training loss: 1.874942715087645
Validation loss: 2.479092665536706

Epoch: 5| Step: 10
Training loss: 2.2825895583098865
Validation loss: 2.4639679250924793

Epoch: 301| Step: 0
Training loss: 2.253598937664926
Validation loss: 2.4428862250183343

Epoch: 5| Step: 1
Training loss: 1.7214684922135048
Validation loss: 2.456174673013845

Epoch: 5| Step: 2
Training loss: 1.6953228365675306
Validation loss: 2.4234749348436644

Epoch: 5| Step: 3
Training loss: 1.6732421704013218
Validation loss: 2.443547612860258

Epoch: 5| Step: 4
Training loss: 1.735596235433216
Validation loss: 2.418169856966763

Epoch: 5| Step: 5
Training loss: 2.4325403471655673
Validation loss: 2.4071531945921443

Epoch: 5| Step: 6
Training loss: 1.7201544832006919
Validation loss: 2.433471058226466

Epoch: 5| Step: 7
Training loss: 2.274314475264461
Validation loss: 2.4350149856708976

Epoch: 5| Step: 8
Training loss: 2.1043449049390337
Validation loss: 2.4413018185829998

Epoch: 5| Step: 9
Training loss: 1.9189755658198844
Validation loss: 2.399811690152693

Epoch: 5| Step: 10
Training loss: 1.9701754541253025
Validation loss: 2.4357637737961007

Epoch: 302| Step: 0
Training loss: 1.7206395946123434
Validation loss: 2.4162967371877317

Epoch: 5| Step: 1
Training loss: 2.075317551546823
Validation loss: 2.4979265802962196

Epoch: 5| Step: 2
Training loss: 2.1089384404292173
Validation loss: 2.422302845540773

Epoch: 5| Step: 3
Training loss: 2.0133352359021695
Validation loss: 2.4178732639897027

Epoch: 5| Step: 4
Training loss: 1.9863953405539918
Validation loss: 2.409563642261652

Epoch: 5| Step: 5
Training loss: 2.311223167317316
Validation loss: 2.482406514311645

Epoch: 5| Step: 6
Training loss: 2.006032904646972
Validation loss: 2.40648802618893

Epoch: 5| Step: 7
Training loss: 1.7594317628637457
Validation loss: 2.416895897601354

Epoch: 5| Step: 8
Training loss: 1.500140660366557
Validation loss: 2.4339592908869387

Epoch: 5| Step: 9
Training loss: 1.6940606061189132
Validation loss: 2.3794286172474974

Epoch: 5| Step: 10
Training loss: 1.8556398975343489
Validation loss: 2.424194529827677

Epoch: 303| Step: 0
Training loss: 2.0567846003290864
Validation loss: 2.449453395075877

Epoch: 5| Step: 1
Training loss: 1.9559546153180134
Validation loss: 2.40865221786165

Epoch: 5| Step: 2
Training loss: 2.001929187166336
Validation loss: 2.4518085670771224

Epoch: 5| Step: 3
Training loss: 1.6746730029771886
Validation loss: 2.4111537005173207

Epoch: 5| Step: 4
Training loss: 1.861113432824251
Validation loss: 2.424311157494501

Epoch: 5| Step: 5
Training loss: 2.017202543620681
Validation loss: 2.444214605683873

Epoch: 5| Step: 6
Training loss: 1.8677366079759965
Validation loss: 2.476655244538288

Epoch: 5| Step: 7
Training loss: 1.7390457358156355
Validation loss: 2.4585987734753316

Epoch: 5| Step: 8
Training loss: 2.274919269512721
Validation loss: 2.420524427534421

Epoch: 5| Step: 9
Training loss: 2.154875496898837
Validation loss: 2.507186634188487

Epoch: 5| Step: 10
Training loss: 1.7518132216645224
Validation loss: 2.443811571331517

Epoch: 304| Step: 0
Training loss: 1.730630699140065
Validation loss: 2.377354376212936

Epoch: 5| Step: 1
Training loss: 1.82312619412932
Validation loss: 2.453330551866936

Epoch: 5| Step: 2
Training loss: 1.6486878408380101
Validation loss: 2.401074591016241

Epoch: 5| Step: 3
Training loss: 2.126539345978893
Validation loss: 2.4355468139495806

Epoch: 5| Step: 4
Training loss: 2.5246248551982657
Validation loss: 2.5025629175889894

Epoch: 5| Step: 5
Training loss: 1.5330496352808083
Validation loss: 2.4368467694065257

Epoch: 5| Step: 6
Training loss: 2.253672040542013
Validation loss: 2.4890724351616917

Epoch: 5| Step: 7
Training loss: 1.5257643707013653
Validation loss: 2.4053576236619825

Epoch: 5| Step: 8
Training loss: 1.8093054670766238
Validation loss: 2.441434406339655

Epoch: 5| Step: 9
Training loss: 2.03069837856182
Validation loss: 2.447590328152191

Epoch: 5| Step: 10
Training loss: 2.286506866658317
Validation loss: 2.4523348413896167

Epoch: 305| Step: 0
Training loss: 1.491116204091215
Validation loss: 2.4655680464220366

Epoch: 5| Step: 1
Training loss: 1.4203054967189312
Validation loss: 2.460270399185529

Epoch: 5| Step: 2
Training loss: 1.4824339372347697
Validation loss: 2.4500310765267517

Epoch: 5| Step: 3
Training loss: 2.060020922026821
Validation loss: 2.435709119504877

Epoch: 5| Step: 4
Training loss: 2.7966311044747
Validation loss: 2.4391244850040157

Epoch: 5| Step: 5
Training loss: 2.0775414127854055
Validation loss: 2.449214593480456

Epoch: 5| Step: 6
Training loss: 2.0078331616002805
Validation loss: 2.4855191622220643

Epoch: 5| Step: 7
Training loss: 1.527396042653005
Validation loss: 2.415515774834525

Epoch: 5| Step: 8
Training loss: 1.7287132710536024
Validation loss: 2.460038062976779

Epoch: 5| Step: 9
Training loss: 2.1529182456618416
Validation loss: 2.414489059549407

Epoch: 5| Step: 10
Training loss: 1.9207933064535974
Validation loss: 2.438102070400546

Epoch: 306| Step: 0
Training loss: 2.368576397736941
Validation loss: 2.447405862150125

Epoch: 5| Step: 1
Training loss: 1.935745121323671
Validation loss: 2.395625773066652

Epoch: 5| Step: 2
Training loss: 1.640980709206626
Validation loss: 2.4425683091063783

Epoch: 5| Step: 3
Training loss: 2.2550773553204344
Validation loss: 2.4224093670356655

Epoch: 5| Step: 4
Training loss: 2.0284845159897347
Validation loss: 2.4764661215405464

Epoch: 5| Step: 5
Training loss: 1.8135008186357415
Validation loss: 2.4982202347516074

Epoch: 5| Step: 6
Training loss: 1.104164297473213
Validation loss: 2.442827399240098

Epoch: 5| Step: 7
Training loss: 2.0412455014087563
Validation loss: 2.4470437012939086

Epoch: 5| Step: 8
Training loss: 2.702635968905158
Validation loss: 2.4536679672002233

Epoch: 5| Step: 9
Training loss: 1.7503997482405975
Validation loss: 2.454105889374777

Epoch: 5| Step: 10
Training loss: 1.4301741141911588
Validation loss: 2.471118444590567

Epoch: 307| Step: 0
Training loss: 2.1299191926125567
Validation loss: 2.4267796314039636

Epoch: 5| Step: 1
Training loss: 2.1023804161364454
Validation loss: 2.397097426291676

Epoch: 5| Step: 2
Training loss: 2.005066771691569
Validation loss: 2.3488619724840767

Epoch: 5| Step: 3
Training loss: 1.783261217756671
Validation loss: 2.423569655918648

Epoch: 5| Step: 4
Training loss: 2.233251969672564
Validation loss: 2.401408785216791

Epoch: 5| Step: 5
Training loss: 1.5953379181603242
Validation loss: 2.49288336040276

Epoch: 5| Step: 6
Training loss: 1.5613036343942146
Validation loss: 2.4280952929339246

Epoch: 5| Step: 7
Training loss: 1.7002434808611429
Validation loss: 2.425631199675365

Epoch: 5| Step: 8
Training loss: 2.0355262932462517
Validation loss: 2.4387822108847015

Epoch: 5| Step: 9
Training loss: 1.7872744624696473
Validation loss: 2.4126344375434394

Epoch: 5| Step: 10
Training loss: 1.9647762825457002
Validation loss: 2.4677889058930247

Epoch: 308| Step: 0
Training loss: 1.556385895337753
Validation loss: 2.472294491558863

Epoch: 5| Step: 1
Training loss: 1.8222825028107055
Validation loss: 2.4039081747669546

Epoch: 5| Step: 2
Training loss: 1.4776519308705762
Validation loss: 2.457700685159131

Epoch: 5| Step: 3
Training loss: 1.698224919271392
Validation loss: 2.4268048854786866

Epoch: 5| Step: 4
Training loss: 2.6625239160744103
Validation loss: 2.4709979708434955

Epoch: 5| Step: 5
Training loss: 2.0990954812602074
Validation loss: 2.4150959291477117

Epoch: 5| Step: 6
Training loss: 1.593166019933746
Validation loss: 2.480856373312217

Epoch: 5| Step: 7
Training loss: 1.6810229293466694
Validation loss: 2.443499905582382

Epoch: 5| Step: 8
Training loss: 2.3227056113758153
Validation loss: 2.467826900695739

Epoch: 5| Step: 9
Training loss: 1.9354136524101686
Validation loss: 2.465151453736672

Epoch: 5| Step: 10
Training loss: 1.8139000451077694
Validation loss: 2.403467389944342

Epoch: 309| Step: 0
Training loss: 1.3768176289439977
Validation loss: 2.401469843360245

Epoch: 5| Step: 1
Training loss: 1.9723239127733514
Validation loss: 2.459823691263408

Epoch: 5| Step: 2
Training loss: 1.956464734951667
Validation loss: 2.4855000806818652

Epoch: 5| Step: 3
Training loss: 1.9342323558762413
Validation loss: 2.476149637213326

Epoch: 5| Step: 4
Training loss: 2.08471987043137
Validation loss: 2.4726883096046546

Epoch: 5| Step: 5
Training loss: 2.0965286719310576
Validation loss: 2.4737016514690136

Epoch: 5| Step: 6
Training loss: 1.5754961080161072
Validation loss: 2.434353899741553

Epoch: 5| Step: 7
Training loss: 1.8372592145455402
Validation loss: 2.44042953202786

Epoch: 5| Step: 8
Training loss: 2.5698995983238504
Validation loss: 2.491629261130207

Epoch: 5| Step: 9
Training loss: 1.8569947723413693
Validation loss: 2.4187260475126937

Epoch: 5| Step: 10
Training loss: 1.9143385707516336
Validation loss: 2.4656708345416396

Epoch: 310| Step: 0
Training loss: 2.366103424513989
Validation loss: 2.38412477053339

Epoch: 5| Step: 1
Training loss: 1.6677767712356157
Validation loss: 2.4243488370361588

Epoch: 5| Step: 2
Training loss: 1.4981713274372128
Validation loss: 2.387503304608341

Epoch: 5| Step: 3
Training loss: 2.1331138537674836
Validation loss: 2.458376192859797

Epoch: 5| Step: 4
Training loss: 1.398620593482793
Validation loss: 2.417110593996064

Epoch: 5| Step: 5
Training loss: 1.5940164829440562
Validation loss: 2.378545402125826

Epoch: 5| Step: 6
Training loss: 1.7344699867974995
Validation loss: 2.421467449658163

Epoch: 5| Step: 7
Training loss: 2.4108392128035945
Validation loss: 2.4554935409659366

Epoch: 5| Step: 8
Training loss: 2.0150838909244895
Validation loss: 2.4372983270077007

Epoch: 5| Step: 9
Training loss: 2.3055695478430933
Validation loss: 2.392100513193497

Epoch: 5| Step: 10
Training loss: 1.947023795673589
Validation loss: 2.463947200239668

Epoch: 311| Step: 0
Training loss: 2.2008245916841753
Validation loss: 2.4651553046780994

Epoch: 5| Step: 1
Training loss: 2.2533323195227575
Validation loss: 2.418177231940376

Epoch: 5| Step: 2
Training loss: 2.1518481007539223
Validation loss: 2.4263040855901594

Epoch: 5| Step: 3
Training loss: 1.7859536691702984
Validation loss: 2.4580837075742243

Epoch: 5| Step: 4
Training loss: 2.542699468509443
Validation loss: 2.4288699993172265

Epoch: 5| Step: 5
Training loss: 1.341425015424353
Validation loss: 2.41939878710956

Epoch: 5| Step: 6
Training loss: 1.8273492455043086
Validation loss: 2.4690771066627284

Epoch: 5| Step: 7
Training loss: 1.6655759421275695
Validation loss: 2.4946736488033237

Epoch: 5| Step: 8
Training loss: 1.8909017817399336
Validation loss: 2.431445493387544

Epoch: 5| Step: 9
Training loss: 1.6915425516584102
Validation loss: 2.4632522783156015

Epoch: 5| Step: 10
Training loss: 1.0914421255868558
Validation loss: 2.4109447319187014

Epoch: 312| Step: 0
Training loss: 2.162254376877505
Validation loss: 2.402957986401271

Epoch: 5| Step: 1
Training loss: 1.8352579360663535
Validation loss: 2.4155905358701357

Epoch: 5| Step: 2
Training loss: 2.101264109930062
Validation loss: 2.439985001931644

Epoch: 5| Step: 3
Training loss: 1.7675234285606696
Validation loss: 2.447381215562008

Epoch: 5| Step: 4
Training loss: 2.4699115193693038
Validation loss: 2.4113881877388237

Epoch: 5| Step: 5
Training loss: 1.6080673979588584
Validation loss: 2.408441244495933

Epoch: 5| Step: 6
Training loss: 1.3592149486810905
Validation loss: 2.412951288440471

Epoch: 5| Step: 7
Training loss: 1.7195619919215706
Validation loss: 2.451226350814412

Epoch: 5| Step: 8
Training loss: 1.8343045378739036
Validation loss: 2.4651885880840134

Epoch: 5| Step: 9
Training loss: 2.088570408294351
Validation loss: 2.474240119745151

Epoch: 5| Step: 10
Training loss: 1.852355787092506
Validation loss: 2.421297413217675

Epoch: 313| Step: 0
Training loss: 1.3771898864212984
Validation loss: 2.4560397527015514

Epoch: 5| Step: 1
Training loss: 1.5568472271635412
Validation loss: 2.4021617848168644

Epoch: 5| Step: 2
Training loss: 1.9247943446299043
Validation loss: 2.385621244029487

Epoch: 5| Step: 3
Training loss: 1.4360001244239435
Validation loss: 2.487717704379536

Epoch: 5| Step: 4
Training loss: 1.5401197955366595
Validation loss: 2.4060280927538154

Epoch: 5| Step: 5
Training loss: 1.9215772444648986
Validation loss: 2.4538377257226993

Epoch: 5| Step: 6
Training loss: 1.8543452344767706
Validation loss: 2.4100075851713885

Epoch: 5| Step: 7
Training loss: 1.8996834139835663
Validation loss: 2.489464832735732

Epoch: 5| Step: 8
Training loss: 2.8787001972139183
Validation loss: 2.471781237201638

Epoch: 5| Step: 9
Training loss: 1.8108106172099132
Validation loss: 2.3543990509903154

Epoch: 5| Step: 10
Training loss: 2.0191713820447137
Validation loss: 2.424861684587922

Epoch: 314| Step: 0
Training loss: 2.4716163123727677
Validation loss: 2.444255820841909

Epoch: 5| Step: 1
Training loss: 2.00414930509263
Validation loss: 2.487079595182975

Epoch: 5| Step: 2
Training loss: 2.1342095909980596
Validation loss: 2.465723948756834

Epoch: 5| Step: 3
Training loss: 1.9799960021739635
Validation loss: 2.4527386414064636

Epoch: 5| Step: 4
Training loss: 2.1894110914648257
Validation loss: 2.4820536115877343

Epoch: 5| Step: 5
Training loss: 1.9553818138143815
Validation loss: 2.4359762321180307

Epoch: 5| Step: 6
Training loss: 0.9917981442612004
Validation loss: 2.472545512500814

Epoch: 5| Step: 7
Training loss: 1.6592963650852306
Validation loss: 2.4454506990292235

Epoch: 5| Step: 8
Training loss: 1.5129797749904093
Validation loss: 2.465323454854346

Epoch: 5| Step: 9
Training loss: 1.8399209818251303
Validation loss: 2.4534265816015135

Epoch: 5| Step: 10
Training loss: 1.5966625154370928
Validation loss: 2.4451819719885903

Epoch: 315| Step: 0
Training loss: 2.040891565084272
Validation loss: 2.367388459777387

Epoch: 5| Step: 1
Training loss: 1.9843142642841451
Validation loss: 2.4334737035417304

Epoch: 5| Step: 2
Training loss: 2.5236940046865373
Validation loss: 2.428616115044853

Epoch: 5| Step: 3
Training loss: 2.4253458071460083
Validation loss: 2.4227054226819145

Epoch: 5| Step: 4
Training loss: 1.6108412498336164
Validation loss: 2.435428994314408

Epoch: 5| Step: 5
Training loss: 1.717543438580062
Validation loss: 2.3794797189320276

Epoch: 5| Step: 6
Training loss: 2.121551183338019
Validation loss: 2.4375411735614225

Epoch: 5| Step: 7
Training loss: 1.608716367000966
Validation loss: 2.405210720427322

Epoch: 5| Step: 8
Training loss: 1.4727133985201968
Validation loss: 2.495616826646326

Epoch: 5| Step: 9
Training loss: 1.5276713690644106
Validation loss: 2.4312811623244954

Epoch: 5| Step: 10
Training loss: 1.122964076431462
Validation loss: 2.396881200368433

Epoch: 316| Step: 0
Training loss: 2.1595345511334294
Validation loss: 2.4813889239529647

Epoch: 5| Step: 1
Training loss: 2.371848173329022
Validation loss: 2.45490277129827

Epoch: 5| Step: 2
Training loss: 1.798329900444273
Validation loss: 2.3785507502560406

Epoch: 5| Step: 3
Training loss: 2.1102943959893703
Validation loss: 2.4756876904418785

Epoch: 5| Step: 4
Training loss: 1.7634292046938094
Validation loss: 2.480499198661448

Epoch: 5| Step: 5
Training loss: 1.435104447262077
Validation loss: 2.3760811790225085

Epoch: 5| Step: 6
Training loss: 1.868542678202693
Validation loss: 2.4634927901183588

Epoch: 5| Step: 7
Training loss: 1.1970012926845215
Validation loss: 2.4622343985863475

Epoch: 5| Step: 8
Training loss: 1.9260771796784901
Validation loss: 2.458874508534562

Epoch: 5| Step: 9
Training loss: 2.0250183763965333
Validation loss: 2.418744250400386

Epoch: 5| Step: 10
Training loss: 1.6207601548700097
Validation loss: 2.3935005504288482

Epoch: 317| Step: 0
Training loss: 2.104632889365512
Validation loss: 2.432628036185482

Epoch: 5| Step: 1
Training loss: 1.4588730857718242
Validation loss: 2.4234673289861295

Epoch: 5| Step: 2
Training loss: 1.85731283002154
Validation loss: 2.446210743209976

Epoch: 5| Step: 3
Training loss: 1.6238581974198851
Validation loss: 2.4532604254608175

Epoch: 5| Step: 4
Training loss: 1.6169484279667745
Validation loss: 2.489317238014509

Epoch: 5| Step: 5
Training loss: 2.3743209872085687
Validation loss: 2.415811704293671

Epoch: 5| Step: 6
Training loss: 1.561257058731627
Validation loss: 2.5247700629881487

Epoch: 5| Step: 7
Training loss: 2.160773687435639
Validation loss: 2.39553650831469

Epoch: 5| Step: 8
Training loss: 1.8894268053771777
Validation loss: 2.4432783984517648

Epoch: 5| Step: 9
Training loss: 2.0290023105282926
Validation loss: 2.454987726291349

Epoch: 5| Step: 10
Training loss: 1.8366742542869363
Validation loss: 2.3611668735975364

Epoch: 318| Step: 0
Training loss: 1.8372391003004953
Validation loss: 2.4527129394207488

Epoch: 5| Step: 1
Training loss: 2.5819009583534256
Validation loss: 2.45242073311897

Epoch: 5| Step: 2
Training loss: 1.7841919145337402
Validation loss: 2.4092913407463703

Epoch: 5| Step: 3
Training loss: 1.667317605058954
Validation loss: 2.417453413620269

Epoch: 5| Step: 4
Training loss: 1.8297463424694012
Validation loss: 2.474652941631303

Epoch: 5| Step: 5
Training loss: 1.6615497081666681
Validation loss: 2.4477068470557715

Epoch: 5| Step: 6
Training loss: 1.5950830905521445
Validation loss: 2.4234489986656005

Epoch: 5| Step: 7
Training loss: 1.5470819045900213
Validation loss: 2.4152429420314596

Epoch: 5| Step: 8
Training loss: 1.8431849502846454
Validation loss: 2.388479795883054

Epoch: 5| Step: 9
Training loss: 2.10956194013939
Validation loss: 2.433224835367104

Epoch: 5| Step: 10
Training loss: 1.8561508049454019
Validation loss: 2.432260727115236

Epoch: 319| Step: 0
Training loss: 1.425921540347608
Validation loss: 2.4157326017289975

Epoch: 5| Step: 1
Training loss: 1.856721282625963
Validation loss: 2.4070020900518387

Epoch: 5| Step: 2
Training loss: 1.5977387721753982
Validation loss: 2.4616181786005824

Epoch: 5| Step: 3
Training loss: 1.5814898282645693
Validation loss: 2.410158047622481

Epoch: 5| Step: 4
Training loss: 2.1982956570088064
Validation loss: 2.381147471373757

Epoch: 5| Step: 5
Training loss: 2.260361654664025
Validation loss: 2.4166568936951975

Epoch: 5| Step: 6
Training loss: 1.99675547162958
Validation loss: 2.4890886028784727

Epoch: 5| Step: 7
Training loss: 1.6699833373420592
Validation loss: 2.442004987905771

Epoch: 5| Step: 8
Training loss: 1.8183791736217392
Validation loss: 2.4463240707774734

Epoch: 5| Step: 9
Training loss: 1.9718197096918615
Validation loss: 2.431737527614445

Epoch: 5| Step: 10
Training loss: 2.00101886069709
Validation loss: 2.45306099501899

Epoch: 320| Step: 0
Training loss: 2.2343729726075265
Validation loss: 2.433699023070207

Epoch: 5| Step: 1
Training loss: 2.197835212632468
Validation loss: 2.4292191472552433

Epoch: 5| Step: 2
Training loss: 1.23587958469044
Validation loss: 2.4217644228585553

Epoch: 5| Step: 3
Training loss: 1.8600961264515048
Validation loss: 2.423455462108158

Epoch: 5| Step: 4
Training loss: 2.363613540365828
Validation loss: 2.427612728256018

Epoch: 5| Step: 5
Training loss: 1.5125226389554178
Validation loss: 2.431350660013105

Epoch: 5| Step: 6
Training loss: 1.858919488584447
Validation loss: 2.3981731558119517

Epoch: 5| Step: 7
Training loss: 2.0369944407443863
Validation loss: 2.4377582572049166

Epoch: 5| Step: 8
Training loss: 1.6080281075065976
Validation loss: 2.4573379258174164

Epoch: 5| Step: 9
Training loss: 1.8635915821683635
Validation loss: 2.4945346322138557

Epoch: 5| Step: 10
Training loss: 1.6725190962997052
Validation loss: 2.4089437939111935

Epoch: 321| Step: 0
Training loss: 2.261434744757709
Validation loss: 2.4303007390939593

Epoch: 5| Step: 1
Training loss: 1.7707169288822606
Validation loss: 2.483392431504736

Epoch: 5| Step: 2
Training loss: 2.0837101277711176
Validation loss: 2.4299746793630184

Epoch: 5| Step: 3
Training loss: 1.680899107665343
Validation loss: 2.449351422062948

Epoch: 5| Step: 4
Training loss: 1.4736976078417583
Validation loss: 2.4347397326108036

Epoch: 5| Step: 5
Training loss: 2.0964404228582882
Validation loss: 2.466096580101808

Epoch: 5| Step: 6
Training loss: 1.5836263268408222
Validation loss: 2.4703069885939213

Epoch: 5| Step: 7
Training loss: 2.095828490760421
Validation loss: 2.4520303209131686

Epoch: 5| Step: 8
Training loss: 1.8723304818482385
Validation loss: 2.4494373577043818

Epoch: 5| Step: 9
Training loss: 1.761026995194726
Validation loss: 2.425905427625477

Epoch: 5| Step: 10
Training loss: 1.5975002221956531
Validation loss: 2.4682831027410836

Epoch: 322| Step: 0
Training loss: 2.0241412849871314
Validation loss: 2.508240269809763

Epoch: 5| Step: 1
Training loss: 2.7678133824840083
Validation loss: 2.439096108603831

Epoch: 5| Step: 2
Training loss: 1.7082287671100937
Validation loss: 2.4448146602256218

Epoch: 5| Step: 3
Training loss: 1.4627560807047748
Validation loss: 2.479283270537162

Epoch: 5| Step: 4
Training loss: 2.153783631596307
Validation loss: 2.46241322700725

Epoch: 5| Step: 5
Training loss: 1.9277849586907627
Validation loss: 2.4271420654756346

Epoch: 5| Step: 6
Training loss: 1.9004106981211202
Validation loss: 2.4305163904678393

Epoch: 5| Step: 7
Training loss: 1.7320409654922104
Validation loss: 2.4088317770722547

Epoch: 5| Step: 8
Training loss: 1.181268504164343
Validation loss: 2.396267982494306

Epoch: 5| Step: 9
Training loss: 1.257145153738686
Validation loss: 2.387686995158726

Epoch: 5| Step: 10
Training loss: 1.715676073102782
Validation loss: 2.402588236743814

Epoch: 323| Step: 0
Training loss: 1.92799723494003
Validation loss: 2.4420670896614474

Epoch: 5| Step: 1
Training loss: 1.549476516678625
Validation loss: 2.4004249078687487

Epoch: 5| Step: 2
Training loss: 1.5666429145852185
Validation loss: 2.493542570038819

Epoch: 5| Step: 3
Training loss: 1.7076839360238778
Validation loss: 2.4350770403941056

Epoch: 5| Step: 4
Training loss: 2.101472647068468
Validation loss: 2.4371798746576023

Epoch: 5| Step: 5
Training loss: 1.885637941249684
Validation loss: 2.4682582927865213

Epoch: 5| Step: 6
Training loss: 2.0980532251012285
Validation loss: 2.507774906044701

Epoch: 5| Step: 7
Training loss: 1.6527042942469812
Validation loss: 2.4079279595227705

Epoch: 5| Step: 8
Training loss: 1.8848279873507383
Validation loss: 2.4678864989328373

Epoch: 5| Step: 9
Training loss: 1.8751323653229628
Validation loss: 2.417759857757639

Epoch: 5| Step: 10
Training loss: 1.6040734680977982
Validation loss: 2.406391103970412

Epoch: 324| Step: 0
Training loss: 2.485158736687297
Validation loss: 2.4812851007938463

Epoch: 5| Step: 1
Training loss: 1.7909149840521574
Validation loss: 2.421695517598821

Epoch: 5| Step: 2
Training loss: 2.2970845652364242
Validation loss: 2.466574508778218

Epoch: 5| Step: 3
Training loss: 1.7499516344198882
Validation loss: 2.4524521676695117

Epoch: 5| Step: 4
Training loss: 1.442398846019975
Validation loss: 2.4047975816577973

Epoch: 5| Step: 5
Training loss: 1.6618030951740723
Validation loss: 2.462840209183659

Epoch: 5| Step: 6
Training loss: 1.9051101278276832
Validation loss: 2.4276038543893663

Epoch: 5| Step: 7
Training loss: 1.2015840645034386
Validation loss: 2.4544064338977236

Epoch: 5| Step: 8
Training loss: 1.9979616148834616
Validation loss: 2.4431803418452276

Epoch: 5| Step: 9
Training loss: 1.721843155637399
Validation loss: 2.4698747383570008

Epoch: 5| Step: 10
Training loss: 1.8928650125818067
Validation loss: 2.423692170906934

Epoch: 325| Step: 0
Training loss: 1.413251148786876
Validation loss: 2.4369785402085884

Epoch: 5| Step: 1
Training loss: 2.043237263701303
Validation loss: 2.3763741763657524

Epoch: 5| Step: 2
Training loss: 1.628081847221208
Validation loss: 2.4755935416732138

Epoch: 5| Step: 3
Training loss: 1.5719014948589478
Validation loss: 2.487924556002863

Epoch: 5| Step: 4
Training loss: 2.060587834678801
Validation loss: 2.4746296013499527

Epoch: 5| Step: 5
Training loss: 1.367361090402693
Validation loss: 2.429642672310365

Epoch: 5| Step: 6
Training loss: 1.8274990216420866
Validation loss: 2.392752647304727

Epoch: 5| Step: 7
Training loss: 2.4146308106523673
Validation loss: 2.4662601110823044

Epoch: 5| Step: 8
Training loss: 1.823691706519961
Validation loss: 2.4362703865717927

Epoch: 5| Step: 9
Training loss: 2.313450489082442
Validation loss: 2.3815485778211603

Epoch: 5| Step: 10
Training loss: 1.4961523935960805
Validation loss: 2.4487907919075957

Epoch: 326| Step: 0
Training loss: 1.7069748928098585
Validation loss: 2.384829004442628

Epoch: 5| Step: 1
Training loss: 1.9251469617950383
Validation loss: 2.4531425923247747

Epoch: 5| Step: 2
Training loss: 2.601398084789107
Validation loss: 2.4083813184526583

Epoch: 5| Step: 3
Training loss: 2.069747444631375
Validation loss: 2.449732317394984

Epoch: 5| Step: 4
Training loss: 1.9184306223724759
Validation loss: 2.441476265377087

Epoch: 5| Step: 5
Training loss: 1.6100643866559674
Validation loss: 2.517170199089342

Epoch: 5| Step: 6
Training loss: 1.9653340328988254
Validation loss: 2.433237733478706

Epoch: 5| Step: 7
Training loss: 1.5067610953849564
Validation loss: 2.4309748545072933

Epoch: 5| Step: 8
Training loss: 1.3638766936727906
Validation loss: 2.4348815829812174

Epoch: 5| Step: 9
Training loss: 1.6817532633453052
Validation loss: 2.3754477421585296

Epoch: 5| Step: 10
Training loss: 1.6660874631896005
Validation loss: 2.3632241280402657

Epoch: 327| Step: 0
Training loss: 1.921687295322691
Validation loss: 2.516764914568315

Epoch: 5| Step: 1
Training loss: 1.6027436901605594
Validation loss: 2.4696487440902732

Epoch: 5| Step: 2
Training loss: 1.7109705255534777
Validation loss: 2.4697123684903

Epoch: 5| Step: 3
Training loss: 1.806693015498814
Validation loss: 2.5218579447267238

Epoch: 5| Step: 4
Training loss: 1.7529978279322276
Validation loss: 2.4284073057537747

Epoch: 5| Step: 5
Training loss: 1.7166636201529029
Validation loss: 2.4846826704521567

Epoch: 5| Step: 6
Training loss: 1.880204479886348
Validation loss: 2.4123806469464713

Epoch: 5| Step: 7
Training loss: 2.673247224779721
Validation loss: 2.4321921002484284

Epoch: 5| Step: 8
Training loss: 1.7613393032373235
Validation loss: 2.4670859954749402

Epoch: 5| Step: 9
Training loss: 1.473320444418915
Validation loss: 2.498597664427621

Epoch: 5| Step: 10
Training loss: 1.4407556404242978
Validation loss: 2.4577806566559492

Epoch: 328| Step: 0
Training loss: 1.283716200817269
Validation loss: 2.4343692687695877

Epoch: 5| Step: 1
Training loss: 1.8487895046756613
Validation loss: 2.503679643925574

Epoch: 5| Step: 2
Training loss: 1.5559593634018407
Validation loss: 2.503006528050688

Epoch: 5| Step: 3
Training loss: 2.5918758929352044
Validation loss: 2.429966376970151

Epoch: 5| Step: 4
Training loss: 2.473556475208796
Validation loss: 2.3753636928511037

Epoch: 5| Step: 5
Training loss: 1.8073128764055868
Validation loss: 2.406837878457651

Epoch: 5| Step: 6
Training loss: 1.5946625733487807
Validation loss: 2.3948992045480613

Epoch: 5| Step: 7
Training loss: 1.779121465652269
Validation loss: 2.4360943367841643

Epoch: 5| Step: 8
Training loss: 1.6970084009721256
Validation loss: 2.433504674902268

Epoch: 5| Step: 9
Training loss: 1.6858793883256302
Validation loss: 2.491756975377902

Epoch: 5| Step: 10
Training loss: 1.4801348709822384
Validation loss: 2.4242757858628816

Epoch: 329| Step: 0
Training loss: 1.8888120549912317
Validation loss: 2.40223491617929

Epoch: 5| Step: 1
Training loss: 1.6856299033993585
Validation loss: 2.4978307398161945

Epoch: 5| Step: 2
Training loss: 1.752256029155393
Validation loss: 2.4416830719237064

Epoch: 5| Step: 3
Training loss: 1.835516179216364
Validation loss: 2.4753898902676856

Epoch: 5| Step: 4
Training loss: 2.017834420926221
Validation loss: 2.4204931216822385

Epoch: 5| Step: 5
Training loss: 1.4361507884155655
Validation loss: 2.421189495963837

Epoch: 5| Step: 6
Training loss: 1.9176981127078252
Validation loss: 2.478207877866222

Epoch: 5| Step: 7
Training loss: 2.3834330766876137
Validation loss: 2.4669538573383814

Epoch: 5| Step: 8
Training loss: 1.5777291282950023
Validation loss: 2.4727624861521456

Epoch: 5| Step: 9
Training loss: 1.9832137306866
Validation loss: 2.4882519026533867

Epoch: 5| Step: 10
Training loss: 1.7362479329766314
Validation loss: 2.4578669494785474

Epoch: 330| Step: 0
Training loss: 1.1090164679774224
Validation loss: 2.455183820718589

Epoch: 5| Step: 1
Training loss: 1.8248409541602102
Validation loss: 2.453148962378947

Epoch: 5| Step: 2
Training loss: 1.9018114665160037
Validation loss: 2.4057056571464033

Epoch: 5| Step: 3
Training loss: 2.4818727379632235
Validation loss: 2.4649426504925835

Epoch: 5| Step: 4
Training loss: 1.9978864946629578
Validation loss: 2.402392289506432

Epoch: 5| Step: 5
Training loss: 1.1102141309517464
Validation loss: 2.3922358514710007

Epoch: 5| Step: 6
Training loss: 1.8506955720740201
Validation loss: 2.4274297777955853

Epoch: 5| Step: 7
Training loss: 1.598660924963759
Validation loss: 2.4293049640202704

Epoch: 5| Step: 8
Training loss: 1.6004999869673449
Validation loss: 2.4104930255280363

Epoch: 5| Step: 9
Training loss: 2.286151584448773
Validation loss: 2.4264525057987685

Epoch: 5| Step: 10
Training loss: 1.545326845355124
Validation loss: 2.4254896908729626

Epoch: 331| Step: 0
Training loss: 2.3954493892246336
Validation loss: 2.40818933750575

Epoch: 5| Step: 1
Training loss: 1.7194507904154746
Validation loss: 2.4707280515189725

Epoch: 5| Step: 2
Training loss: 1.6375656668039584
Validation loss: 2.434148859158308

Epoch: 5| Step: 3
Training loss: 1.5793734607153134
Validation loss: 2.414493396890489

Epoch: 5| Step: 4
Training loss: 1.3579148968363852
Validation loss: 2.433112010061417

Epoch: 5| Step: 5
Training loss: 1.4756529090371588
Validation loss: 2.397223927113735

Epoch: 5| Step: 6
Training loss: 1.87643771681781
Validation loss: 2.4439249272815156

Epoch: 5| Step: 7
Training loss: 1.6595361606190144
Validation loss: 2.410319192116789

Epoch: 5| Step: 8
Training loss: 1.944074550898523
Validation loss: 2.420518405335834

Epoch: 5| Step: 9
Training loss: 2.2477875534279166
Validation loss: 2.3949606652148576

Epoch: 5| Step: 10
Training loss: 2.001469072578022
Validation loss: 2.4222648081962563

Epoch: 332| Step: 0
Training loss: 1.3655642655264437
Validation loss: 2.4415959656211066

Epoch: 5| Step: 1
Training loss: 1.6954587530520409
Validation loss: 2.448858579355829

Epoch: 5| Step: 2
Training loss: 1.6718697948909556
Validation loss: 2.4486736927483066

Epoch: 5| Step: 3
Training loss: 1.952444888911139
Validation loss: 2.5173222192106275

Epoch: 5| Step: 4
Training loss: 1.7599393058195094
Validation loss: 2.4521355165374654

Epoch: 5| Step: 5
Training loss: 1.5275024955966374
Validation loss: 2.424099169548

Epoch: 5| Step: 6
Training loss: 2.0570802861681057
Validation loss: 2.4322590391087417

Epoch: 5| Step: 7
Training loss: 1.822382850597094
Validation loss: 2.3851697945988706

Epoch: 5| Step: 8
Training loss: 2.429877466950655
Validation loss: 2.4415794965412303

Epoch: 5| Step: 9
Training loss: 2.092720917555811
Validation loss: 2.416891268631418

Epoch: 5| Step: 10
Training loss: 1.438797655285772
Validation loss: 2.3877056381385153

Epoch: 333| Step: 0
Training loss: 1.944469100553622
Validation loss: 2.431195804945036

Epoch: 5| Step: 1
Training loss: 2.265804836107552
Validation loss: 2.4043963414327956

Epoch: 5| Step: 2
Training loss: 1.6987035913142112
Validation loss: 2.477032433984768

Epoch: 5| Step: 3
Training loss: 1.6149497652065297
Validation loss: 2.46128900364464

Epoch: 5| Step: 4
Training loss: 1.8616211731536534
Validation loss: 2.4176320879944093

Epoch: 5| Step: 5
Training loss: 1.1239653173777067
Validation loss: 2.435646705125177

Epoch: 5| Step: 6
Training loss: 1.6576501218495703
Validation loss: 2.4452659311309013

Epoch: 5| Step: 7
Training loss: 2.405710333214792
Validation loss: 2.4407894025001755

Epoch: 5| Step: 8
Training loss: 1.166365578945853
Validation loss: 2.4213500365268

Epoch: 5| Step: 9
Training loss: 2.0336927544450814
Validation loss: 2.4114861274229673

Epoch: 5| Step: 10
Training loss: 1.6822822578411143
Validation loss: 2.3669319200322083

Epoch: 334| Step: 0
Training loss: 1.9624918214664004
Validation loss: 2.459800238411708

Epoch: 5| Step: 1
Training loss: 1.5980072009099822
Validation loss: 2.382084680438009

Epoch: 5| Step: 2
Training loss: 1.7924299905850387
Validation loss: 2.4106189818543777

Epoch: 5| Step: 3
Training loss: 2.125491590297935
Validation loss: 2.4149256500312823

Epoch: 5| Step: 4
Training loss: 1.9851266833989352
Validation loss: 2.4049663126707883

Epoch: 5| Step: 5
Training loss: 1.6170004031547087
Validation loss: 2.429520112339995

Epoch: 5| Step: 6
Training loss: 1.9244480431654958
Validation loss: 2.3672279114307684

Epoch: 5| Step: 7
Training loss: 1.4527919756842087
Validation loss: 2.416776301012055

Epoch: 5| Step: 8
Training loss: 1.7020795920932823
Validation loss: 2.4495739509251533

Epoch: 5| Step: 9
Training loss: 1.8441214752980666
Validation loss: 2.403275719431469

Epoch: 5| Step: 10
Training loss: 1.8944281795819007
Validation loss: 2.4485494736083218

Epoch: 335| Step: 0
Training loss: 2.042706737164294
Validation loss: 2.474742214881233

Epoch: 5| Step: 1
Training loss: 1.5553107617786053
Validation loss: 2.4204180910548887

Epoch: 5| Step: 2
Training loss: 2.5389695370601886
Validation loss: 2.4459407067209513

Epoch: 5| Step: 3
Training loss: 1.759537456593984
Validation loss: 2.4309807854190506

Epoch: 5| Step: 4
Training loss: 1.4593688376580447
Validation loss: 2.400217658858291

Epoch: 5| Step: 5
Training loss: 1.8018321779199347
Validation loss: 2.4330993317600895

Epoch: 5| Step: 6
Training loss: 1.5767830156674425
Validation loss: 2.4078748437815793

Epoch: 5| Step: 7
Training loss: 1.9699758316145368
Validation loss: 2.4018951501395174

Epoch: 5| Step: 8
Training loss: 1.5853340241008522
Validation loss: 2.3630719931496107

Epoch: 5| Step: 9
Training loss: 1.6767073342085144
Validation loss: 2.421764513896762

Epoch: 5| Step: 10
Training loss: 1.5944554880507777
Validation loss: 2.409329555776596

Epoch: 336| Step: 0
Training loss: 1.4762920959569075
Validation loss: 2.4535121556045936

Epoch: 5| Step: 1
Training loss: 1.4694296704907501
Validation loss: 2.4758548364082986

Epoch: 5| Step: 2
Training loss: 2.367921419592558
Validation loss: 2.431151398394073

Epoch: 5| Step: 3
Training loss: 1.556606546026545
Validation loss: 2.429999992017477

Epoch: 5| Step: 4
Training loss: 2.1283582069459017
Validation loss: 2.4346918058875042

Epoch: 5| Step: 5
Training loss: 1.1968098655088795
Validation loss: 2.4151302399867323

Epoch: 5| Step: 6
Training loss: 1.6993979173232465
Validation loss: 2.447710127398391

Epoch: 5| Step: 7
Training loss: 1.664456961000002
Validation loss: 2.4290817856824054

Epoch: 5| Step: 8
Training loss: 1.989372029159969
Validation loss: 2.4700374296767587

Epoch: 5| Step: 9
Training loss: 2.0030468144385742
Validation loss: 2.409722026390607

Epoch: 5| Step: 10
Training loss: 2.11622997745386
Validation loss: 2.420927973901568

Epoch: 337| Step: 0
Training loss: 1.5510702560519252
Validation loss: 2.4131341185728687

Epoch: 5| Step: 1
Training loss: 2.306458494278108
Validation loss: 2.4111026063982703

Epoch: 5| Step: 2
Training loss: 1.2147344803808908
Validation loss: 2.423288852115111

Epoch: 5| Step: 3
Training loss: 1.5102388299188891
Validation loss: 2.458626999859558

Epoch: 5| Step: 4
Training loss: 1.390922471708532
Validation loss: 2.4129224204327655

Epoch: 5| Step: 5
Training loss: 1.406054801108982
Validation loss: 2.3990215693832955

Epoch: 5| Step: 6
Training loss: 1.742880166066977
Validation loss: 2.469445641089699

Epoch: 5| Step: 7
Training loss: 1.7994192935093698
Validation loss: 2.4360951028998525

Epoch: 5| Step: 8
Training loss: 1.8743288746418443
Validation loss: 2.4600871319983995

Epoch: 5| Step: 9
Training loss: 2.0498748229351396
Validation loss: 2.3835642843934943

Epoch: 5| Step: 10
Training loss: 2.3849724657240725
Validation loss: 2.3941494257000318

Epoch: 338| Step: 0
Training loss: 1.778198439115638
Validation loss: 2.4632761598705666

Epoch: 5| Step: 1
Training loss: 1.8542436590889906
Validation loss: 2.4461588863341097

Epoch: 5| Step: 2
Training loss: 1.4335179113966179
Validation loss: 2.391198391038041

Epoch: 5| Step: 3
Training loss: 1.6044475342567281
Validation loss: 2.372894261405906

Epoch: 5| Step: 4
Training loss: 2.277580863949158
Validation loss: 2.4639946718497936

Epoch: 5| Step: 5
Training loss: 1.7606086701491326
Validation loss: 2.4413419346367227

Epoch: 5| Step: 6
Training loss: 1.8643109497362607
Validation loss: 2.4214168786140107

Epoch: 5| Step: 7
Training loss: 1.5864508037759992
Validation loss: 2.4028674384828017

Epoch: 5| Step: 8
Training loss: 1.9199141136470474
Validation loss: 2.3994796413885378

Epoch: 5| Step: 9
Training loss: 1.7925933910392324
Validation loss: 2.4260022814016065

Epoch: 5| Step: 10
Training loss: 1.019838542594724
Validation loss: 2.4482401968951266

Epoch: 339| Step: 0
Training loss: 1.472227646359862
Validation loss: 2.4078227202462936

Epoch: 5| Step: 1
Training loss: 1.3571496923891189
Validation loss: 2.4664521458792414

Epoch: 5| Step: 2
Training loss: 0.9166452159683716
Validation loss: 2.3941671729725926

Epoch: 5| Step: 3
Training loss: 2.3131748967327903
Validation loss: 2.4308142888715962

Epoch: 5| Step: 4
Training loss: 2.092438358141833
Validation loss: 2.423229200680552

Epoch: 5| Step: 5
Training loss: 1.6755219372275427
Validation loss: 2.4317745312386645

Epoch: 5| Step: 6
Training loss: 1.593390779590228
Validation loss: 2.485756567653115

Epoch: 5| Step: 7
Training loss: 2.0089241245765517
Validation loss: 2.3713886413931693

Epoch: 5| Step: 8
Training loss: 2.1123744408125757
Validation loss: 2.4486203919080887

Epoch: 5| Step: 9
Training loss: 1.5153252216669675
Validation loss: 2.419048247206684

Epoch: 5| Step: 10
Training loss: 2.054015423182868
Validation loss: 2.4291092901743276

Epoch: 340| Step: 0
Training loss: 1.3392323247167928
Validation loss: 2.4608519742902994

Epoch: 5| Step: 1
Training loss: 2.17546750448441
Validation loss: 2.483338056869403

Epoch: 5| Step: 2
Training loss: 1.6292822973220649
Validation loss: 2.4117226471850466

Epoch: 5| Step: 3
Training loss: 1.6817340536891219
Validation loss: 2.3889038058126273

Epoch: 5| Step: 4
Training loss: 1.6771192211157613
Validation loss: 2.440029068055369

Epoch: 5| Step: 5
Training loss: 1.7902327129465336
Validation loss: 2.487101208042319

Epoch: 5| Step: 6
Training loss: 1.285583239643488
Validation loss: 2.4413006697600665

Epoch: 5| Step: 7
Training loss: 1.4147551299745502
Validation loss: 2.4321759743560283

Epoch: 5| Step: 8
Training loss: 1.841429397638206
Validation loss: 2.3966633862658053

Epoch: 5| Step: 9
Training loss: 2.495626343139929
Validation loss: 2.4318208419042677

Epoch: 5| Step: 10
Training loss: 1.5760599354224907
Validation loss: 2.4106997676190183

Epoch: 341| Step: 0
Training loss: 1.9199635994957487
Validation loss: 2.4594845927354183

Epoch: 5| Step: 1
Training loss: 1.8648451154277965
Validation loss: 2.4560228382124096

Epoch: 5| Step: 2
Training loss: 1.5722308232027615
Validation loss: 2.434442613102321

Epoch: 5| Step: 3
Training loss: 1.5299687377378663
Validation loss: 2.533787125180713

Epoch: 5| Step: 4
Training loss: 2.549503584768525
Validation loss: 2.4257177029811237

Epoch: 5| Step: 5
Training loss: 1.6926280623745553
Validation loss: 2.5070563958993324

Epoch: 5| Step: 6
Training loss: 1.8321171396777491
Validation loss: 2.4311158932377253

Epoch: 5| Step: 7
Training loss: 1.7532173282021961
Validation loss: 2.4542847679442934

Epoch: 5| Step: 8
Training loss: 1.6971531733056682
Validation loss: 2.4456662451575233

Epoch: 5| Step: 9
Training loss: 1.120102500652951
Validation loss: 2.432441640575654

Epoch: 5| Step: 10
Training loss: 1.4011799012617074
Validation loss: 2.4278660849554394

Epoch: 342| Step: 0
Training loss: 1.7924720225684623
Validation loss: 2.432446737410422

Epoch: 5| Step: 1
Training loss: 1.809032807085885
Validation loss: 2.526299483235814

Epoch: 5| Step: 2
Training loss: 1.349215371327016
Validation loss: 2.467883061541055

Epoch: 5| Step: 3
Training loss: 1.8100325132579533
Validation loss: 2.45676103690694

Epoch: 5| Step: 4
Training loss: 2.27691049527719
Validation loss: 2.412090497098514

Epoch: 5| Step: 5
Training loss: 1.6458129962034842
Validation loss: 2.4727448115465194

Epoch: 5| Step: 6
Training loss: 1.5866094208790005
Validation loss: 2.418153408038889

Epoch: 5| Step: 7
Training loss: 1.689893649665616
Validation loss: 2.423639044182621

Epoch: 5| Step: 8
Training loss: 1.5360063911891133
Validation loss: 2.4253999270572018

Epoch: 5| Step: 9
Training loss: 2.167469633917079
Validation loss: 2.4692020503433048

Epoch: 5| Step: 10
Training loss: 1.7222367033127441
Validation loss: 2.3946245851088577

Epoch: 343| Step: 0
Training loss: 1.5632708364708914
Validation loss: 2.3988918333608598

Epoch: 5| Step: 1
Training loss: 1.5808587898345685
Validation loss: 2.470689091206252

Epoch: 5| Step: 2
Training loss: 2.116082385162997
Validation loss: 2.3706872319961874

Epoch: 5| Step: 3
Training loss: 1.5408154104925826
Validation loss: 2.444970935915785

Epoch: 5| Step: 4
Training loss: 2.038966501833555
Validation loss: 2.485368068511401

Epoch: 5| Step: 5
Training loss: 1.495977332463629
Validation loss: 2.331725755194813

Epoch: 5| Step: 6
Training loss: 1.5766179660079787
Validation loss: 2.525235479504905

Epoch: 5| Step: 7
Training loss: 1.8364851114618304
Validation loss: 2.4703520538751476

Epoch: 5| Step: 8
Training loss: 2.366807258710357
Validation loss: 2.473128607598185

Epoch: 5| Step: 9
Training loss: 1.2780934038430616
Validation loss: 2.4546870419741444

Epoch: 5| Step: 10
Training loss: 1.75745879959282
Validation loss: 2.366693884458918

Epoch: 344| Step: 0
Training loss: 2.267582856402525
Validation loss: 2.437638566227983

Epoch: 5| Step: 1
Training loss: 1.8155304140544408
Validation loss: 2.401513448888096

Epoch: 5| Step: 2
Training loss: 1.6235967592871015
Validation loss: 2.401368918039167

Epoch: 5| Step: 3
Training loss: 1.2481963496475863
Validation loss: 2.3561314496615013

Epoch: 5| Step: 4
Training loss: 2.212024003890243
Validation loss: 2.453201717036409

Epoch: 5| Step: 5
Training loss: 1.989542922430087
Validation loss: 2.4320503929061568

Epoch: 5| Step: 6
Training loss: 1.5536084288151404
Validation loss: 2.42115184931546

Epoch: 5| Step: 7
Training loss: 1.5538918457591089
Validation loss: 2.394839105032432

Epoch: 5| Step: 8
Training loss: 1.7581654512191034
Validation loss: 2.4514650960497257

Epoch: 5| Step: 9
Training loss: 1.6692807757180224
Validation loss: 2.4905977134400277

Epoch: 5| Step: 10
Training loss: 1.9850026136904788
Validation loss: 2.420392747039112

Epoch: 345| Step: 0
Training loss: 1.959794459854114
Validation loss: 2.5084380594203957

Epoch: 5| Step: 1
Training loss: 1.6577967492882484
Validation loss: 2.4139514863985703

Epoch: 5| Step: 2
Training loss: 1.340411986031669
Validation loss: 2.4592888422779917

Epoch: 5| Step: 3
Training loss: 1.091205525491518
Validation loss: 2.407296832908844

Epoch: 5| Step: 4
Training loss: 1.814566256606652
Validation loss: 2.45896506513494

Epoch: 5| Step: 5
Training loss: 2.4940019179140256
Validation loss: 2.3785381979749434

Epoch: 5| Step: 6
Training loss: 1.786045579151404
Validation loss: 2.4420212221097177

Epoch: 5| Step: 7
Training loss: 2.0589822768068777
Validation loss: 2.428743904404247

Epoch: 5| Step: 8
Training loss: 1.3545739906213357
Validation loss: 2.396642521712874

Epoch: 5| Step: 9
Training loss: 1.6293074664894518
Validation loss: 2.4437841255715993

Epoch: 5| Step: 10
Training loss: 1.3101079123217676
Validation loss: 2.5004329962716945

Epoch: 346| Step: 0
Training loss: 2.3186634510267328
Validation loss: 2.463187765268847

Epoch: 5| Step: 1
Training loss: 1.6969018333378845
Validation loss: 2.458068658906904

Epoch: 5| Step: 2
Training loss: 1.6927777163639746
Validation loss: 2.4397338284273262

Epoch: 5| Step: 3
Training loss: 1.6081865237076172
Validation loss: 2.4689319710199578

Epoch: 5| Step: 4
Training loss: 1.7764091298005082
Validation loss: 2.447116550514081

Epoch: 5| Step: 5
Training loss: 1.664329972956269
Validation loss: 2.3885015957683193

Epoch: 5| Step: 6
Training loss: 1.542012442225665
Validation loss: 2.404385957391848

Epoch: 5| Step: 7
Training loss: 1.6175552171247163
Validation loss: 2.4114069967192546

Epoch: 5| Step: 8
Training loss: 1.5063119646045082
Validation loss: 2.4468216291110774

Epoch: 5| Step: 9
Training loss: 1.9290216818501165
Validation loss: 2.454626687213028

Epoch: 5| Step: 10
Training loss: 1.6353730926864105
Validation loss: 2.4159792649822367

Epoch: 347| Step: 0
Training loss: 1.73253568428138
Validation loss: 2.4296820502379495

Epoch: 5| Step: 1
Training loss: 1.5236317046187966
Validation loss: 2.366234216114292

Epoch: 5| Step: 2
Training loss: 1.6636982550481014
Validation loss: 2.386945440591241

Epoch: 5| Step: 3
Training loss: 1.7463065408169673
Validation loss: 2.4104615457876455

Epoch: 5| Step: 4
Training loss: 1.5811242034690551
Validation loss: 2.4418248129104048

Epoch: 5| Step: 5
Training loss: 1.8255488837495502
Validation loss: 2.3697608495901656

Epoch: 5| Step: 6
Training loss: 2.010507518975296
Validation loss: 2.4712512615343236

Epoch: 5| Step: 7
Training loss: 2.354407531659351
Validation loss: 2.4030037327617517

Epoch: 5| Step: 8
Training loss: 1.4776592722600972
Validation loss: 2.4673835469152143

Epoch: 5| Step: 9
Training loss: 1.7165786205168843
Validation loss: 2.3850892071422076

Epoch: 5| Step: 10
Training loss: 1.2888283719228306
Validation loss: 2.471864335397891

Epoch: 348| Step: 0
Training loss: 2.1340502825661134
Validation loss: 2.455869823831245

Epoch: 5| Step: 1
Training loss: 1.6839774772062104
Validation loss: 2.387862792345326

Epoch: 5| Step: 2
Training loss: 1.7383856924162526
Validation loss: 2.451632499549041

Epoch: 5| Step: 3
Training loss: 1.6476225804759086
Validation loss: 2.445630527492387

Epoch: 5| Step: 4
Training loss: 1.6655468834743217
Validation loss: 2.418352252816685

Epoch: 5| Step: 5
Training loss: 1.9211961741405978
Validation loss: 2.415740581081551

Epoch: 5| Step: 6
Training loss: 1.6418577376708103
Validation loss: 2.47739018192396

Epoch: 5| Step: 7
Training loss: 1.924974005387407
Validation loss: 2.409666378754099

Epoch: 5| Step: 8
Training loss: 2.0254958593532906
Validation loss: 2.4120773950338092

Epoch: 5| Step: 9
Training loss: 1.3083738683183797
Validation loss: 2.4399179393310915

Epoch: 5| Step: 10
Training loss: 1.1729492350111355
Validation loss: 2.428404649641124

Epoch: 349| Step: 0
Training loss: 2.0489223811284702
Validation loss: 2.436752497104884

Epoch: 5| Step: 1
Training loss: 1.624456828376461
Validation loss: 2.37586593385552

Epoch: 5| Step: 2
Training loss: 1.7649682097773485
Validation loss: 2.4185023858625123

Epoch: 5| Step: 3
Training loss: 1.523877280898754
Validation loss: 2.4353517526767723

Epoch: 5| Step: 4
Training loss: 1.8808906211911653
Validation loss: 2.4134067306185223

Epoch: 5| Step: 5
Training loss: 1.6709439546236757
Validation loss: 2.434608664607345

Epoch: 5| Step: 6
Training loss: 2.286946330786418
Validation loss: 2.441343256705803

Epoch: 5| Step: 7
Training loss: 1.2925745429378157
Validation loss: 2.395939204983015

Epoch: 5| Step: 8
Training loss: 1.6914865946022861
Validation loss: 2.532523858233407

Epoch: 5| Step: 9
Training loss: 1.4669329177611299
Validation loss: 2.4188090818387695

Epoch: 5| Step: 10
Training loss: 1.4415709858861037
Validation loss: 2.4230508893072744

Epoch: 350| Step: 0
Training loss: 1.7779686133293047
Validation loss: 2.452235442346282

Epoch: 5| Step: 1
Training loss: 1.3582803550093259
Validation loss: 2.438250049497727

Epoch: 5| Step: 2
Training loss: 1.7524156927272072
Validation loss: 2.4530123012058658

Epoch: 5| Step: 3
Training loss: 1.3245998048113208
Validation loss: 2.4076345812675806

Epoch: 5| Step: 4
Training loss: 1.5547848004894858
Validation loss: 2.4175992813268796

Epoch: 5| Step: 5
Training loss: 1.9912785270261502
Validation loss: 2.45127883832673

Epoch: 5| Step: 6
Training loss: 2.380128843843009
Validation loss: 2.3964794038637334

Epoch: 5| Step: 7
Training loss: 1.4688110338881188
Validation loss: 2.4112735573757886

Epoch: 5| Step: 8
Training loss: 1.6305443739340681
Validation loss: 2.3498925978467344

Epoch: 5| Step: 9
Training loss: 1.674670155629899
Validation loss: 2.369409534719868

Epoch: 5| Step: 10
Training loss: 1.722424134686273
Validation loss: 2.405962903065033

Epoch: 351| Step: 0
Training loss: 1.8061487796497682
Validation loss: 2.4147259402276178

Epoch: 5| Step: 1
Training loss: 1.4051505135116125
Validation loss: 2.44046018400914

Epoch: 5| Step: 2
Training loss: 1.4821443360759559
Validation loss: 2.396819399614368

Epoch: 5| Step: 3
Training loss: 1.4968114978803335
Validation loss: 2.440393142870733

Epoch: 5| Step: 4
Training loss: 1.9027215163490074
Validation loss: 2.4547574190006607

Epoch: 5| Step: 5
Training loss: 1.7226578416189855
Validation loss: 2.4345385923029896

Epoch: 5| Step: 6
Training loss: 1.6707785032159326
Validation loss: 2.4390128515302236

Epoch: 5| Step: 7
Training loss: 1.6571455639549284
Validation loss: 2.410166776177433

Epoch: 5| Step: 8
Training loss: 1.9104176597911564
Validation loss: 2.3724894788067408

Epoch: 5| Step: 9
Training loss: 2.251184045989407
Validation loss: 2.3588632279710726

Epoch: 5| Step: 10
Training loss: 1.9349133853107703
Validation loss: 2.4373048694252515

Epoch: 352| Step: 0
Training loss: 1.727148103438952
Validation loss: 2.4294198573992

Epoch: 5| Step: 1
Training loss: 1.6835528941850686
Validation loss: 2.410491063307508

Epoch: 5| Step: 2
Training loss: 1.4942295820894087
Validation loss: 2.4444071007519277

Epoch: 5| Step: 3
Training loss: 2.078789167465281
Validation loss: 2.459222980561609

Epoch: 5| Step: 4
Training loss: 2.4087980576587498
Validation loss: 2.4331477392248146

Epoch: 5| Step: 5
Training loss: 1.2901106763276873
Validation loss: 2.5552261024109657

Epoch: 5| Step: 6
Training loss: 0.8848404673738264
Validation loss: 2.5165927182048042

Epoch: 5| Step: 7
Training loss: 1.8319095660631401
Validation loss: 2.441105185570035

Epoch: 5| Step: 8
Training loss: 1.8518491756455193
Validation loss: 2.491525011696484

Epoch: 5| Step: 9
Training loss: 1.7959964096951015
Validation loss: 2.369379687184028

Epoch: 5| Step: 10
Training loss: 1.4498453353739968
Validation loss: 2.4345416102832877

Epoch: 353| Step: 0
Training loss: 1.4574963029451413
Validation loss: 2.3783496190854363

Epoch: 5| Step: 1
Training loss: 1.4539098773400647
Validation loss: 2.398719590635292

Epoch: 5| Step: 2
Training loss: 1.6011817293405972
Validation loss: 2.442396133538133

Epoch: 5| Step: 3
Training loss: 1.874875509579801
Validation loss: 2.4734314332923044

Epoch: 5| Step: 4
Training loss: 1.6552295060080986
Validation loss: 2.4773241929592387

Epoch: 5| Step: 5
Training loss: 1.7282640177046382
Validation loss: 2.4066769109738635

Epoch: 5| Step: 6
Training loss: 2.0536710016029116
Validation loss: 2.425424318727618

Epoch: 5| Step: 7
Training loss: 1.5132413387205117
Validation loss: 2.388055084802709

Epoch: 5| Step: 8
Training loss: 1.644233876069669
Validation loss: 2.4885405418907065

Epoch: 5| Step: 9
Training loss: 1.6241252452069483
Validation loss: 2.446073103817484

Epoch: 5| Step: 10
Training loss: 1.9755015183126514
Validation loss: 2.402174625601311

Epoch: 354| Step: 0
Training loss: 1.019540253230422
Validation loss: 2.460896722052386

Epoch: 5| Step: 1
Training loss: 1.5750487910388147
Validation loss: 2.453199619683827

Epoch: 5| Step: 2
Training loss: 2.76871752924425
Validation loss: 2.4783920052586272

Epoch: 5| Step: 3
Training loss: 1.3144664111890056
Validation loss: 2.3889729057053737

Epoch: 5| Step: 4
Training loss: 1.4607405096239026
Validation loss: 2.438587175550783

Epoch: 5| Step: 5
Training loss: 1.8595204657064093
Validation loss: 2.482792417383497

Epoch: 5| Step: 6
Training loss: 1.6410930874055107
Validation loss: 2.426547915694141

Epoch: 5| Step: 7
Training loss: 1.9196682177417757
Validation loss: 2.387469375234402

Epoch: 5| Step: 8
Training loss: 1.4532608460947374
Validation loss: 2.427297736291537

Epoch: 5| Step: 9
Training loss: 1.2761106459469562
Validation loss: 2.3920529951954657

Epoch: 5| Step: 10
Training loss: 1.9611827195481675
Validation loss: 2.4827569733584642

Epoch: 355| Step: 0
Training loss: 1.604104383506324
Validation loss: 2.462775882083286

Epoch: 5| Step: 1
Training loss: 1.4018221339318602
Validation loss: 2.4081722806751635

Epoch: 5| Step: 2
Training loss: 1.6251236795162285
Validation loss: 2.3803811770662846

Epoch: 5| Step: 3
Training loss: 1.7113092445389104
Validation loss: 2.4409849203814122

Epoch: 5| Step: 4
Training loss: 1.7688920169605113
Validation loss: 2.3892657631427565

Epoch: 5| Step: 5
Training loss: 2.1467049566056655
Validation loss: 2.341042569459015

Epoch: 5| Step: 6
Training loss: 1.692120901049423
Validation loss: 2.4619477593883228

Epoch: 5| Step: 7
Training loss: 1.533140222510411
Validation loss: 2.4926146148562376

Epoch: 5| Step: 8
Training loss: 2.0195769373081056
Validation loss: 2.4666072336171814

Epoch: 5| Step: 9
Training loss: 1.1618905510561943
Validation loss: 2.393812039738524

Epoch: 5| Step: 10
Training loss: 1.7940645214628237
Validation loss: 2.4383278264787136

Epoch: 356| Step: 0
Training loss: 1.6794412121854005
Validation loss: 2.416837554323936

Epoch: 5| Step: 1
Training loss: 1.7132730785615096
Validation loss: 2.3340357398560756

Epoch: 5| Step: 2
Training loss: 1.1821113594577533
Validation loss: 2.4309393868467906

Epoch: 5| Step: 3
Training loss: 1.495042715578732
Validation loss: 2.4483981580357526

Epoch: 5| Step: 4
Training loss: 1.6031962179980717
Validation loss: 2.4267317001249498

Epoch: 5| Step: 5
Training loss: 1.6049166655965417
Validation loss: 2.4369815257119676

Epoch: 5| Step: 6
Training loss: 1.5220738494491257
Validation loss: 2.393797557307736

Epoch: 5| Step: 7
Training loss: 1.8844475196055046
Validation loss: 2.3718556626102156

Epoch: 5| Step: 8
Training loss: 2.4256429586750747
Validation loss: 2.4204016335743543

Epoch: 5| Step: 9
Training loss: 1.6892861697220254
Validation loss: 2.3784243869564583

Epoch: 5| Step: 10
Training loss: 2.027748846547341
Validation loss: 2.3945441434801134

Epoch: 357| Step: 0
Training loss: 1.3233783046630345
Validation loss: 2.3876908266258683

Epoch: 5| Step: 1
Training loss: 1.7806151747909487
Validation loss: 2.4255702011954376

Epoch: 5| Step: 2
Training loss: 1.175406564215881
Validation loss: 2.399537499917398

Epoch: 5| Step: 3
Training loss: 1.3482741556435194
Validation loss: 2.478009931712391

Epoch: 5| Step: 4
Training loss: 2.2787029731489024
Validation loss: 2.4034141681573673

Epoch: 5| Step: 5
Training loss: 1.314406418218516
Validation loss: 2.413298610295141

Epoch: 5| Step: 6
Training loss: 2.1227758773324426
Validation loss: 2.3806181875862227

Epoch: 5| Step: 7
Training loss: 1.6775688116340666
Validation loss: 2.3985826152396443

Epoch: 5| Step: 8
Training loss: 1.9396111461422199
Validation loss: 2.4316192861912955

Epoch: 5| Step: 9
Training loss: 1.1629591455540926
Validation loss: 2.460999324013544

Epoch: 5| Step: 10
Training loss: 1.7285632110769686
Validation loss: 2.400558723851584

Epoch: 358| Step: 0
Training loss: 1.4060771835950192
Validation loss: 2.4223653423314455

Epoch: 5| Step: 1
Training loss: 2.139002498345256
Validation loss: 2.4619179367284407

Epoch: 5| Step: 2
Training loss: 1.5395951486976407
Validation loss: 2.392679159690234

Epoch: 5| Step: 3
Training loss: 2.0587436107543304
Validation loss: 2.3973953619379755

Epoch: 5| Step: 4
Training loss: 1.6215273357702067
Validation loss: 2.4317412691175937

Epoch: 5| Step: 5
Training loss: 1.3461631132687188
Validation loss: 2.3980398716624274

Epoch: 5| Step: 6
Training loss: 1.577420823517863
Validation loss: 2.4088641092926117

Epoch: 5| Step: 7
Training loss: 1.0853401572023111
Validation loss: 2.375905130529124

Epoch: 5| Step: 8
Training loss: 2.1563315998061974
Validation loss: 2.4607811350253392

Epoch: 5| Step: 9
Training loss: 1.672126180728947
Validation loss: 2.3873908487572955

Epoch: 5| Step: 10
Training loss: 1.7825282680201437
Validation loss: 2.4291959698715577

Epoch: 359| Step: 0
Training loss: 1.4977462049043622
Validation loss: 2.4334369649015657

Epoch: 5| Step: 1
Training loss: 1.498863027731443
Validation loss: 2.3995234478835417

Epoch: 5| Step: 2
Training loss: 1.67036162715424
Validation loss: 2.4164849263539656

Epoch: 5| Step: 3
Training loss: 1.327285591095217
Validation loss: 2.418965741456357

Epoch: 5| Step: 4
Training loss: 2.2173571445763995
Validation loss: 2.4436628584154247

Epoch: 5| Step: 5
Training loss: 1.527193027874282
Validation loss: 2.479654631897078

Epoch: 5| Step: 6
Training loss: 1.734079284201765
Validation loss: 2.4209563249923822

Epoch: 5| Step: 7
Training loss: 1.451689226184715
Validation loss: 2.4299668269321915

Epoch: 5| Step: 8
Training loss: 1.8395164506388684
Validation loss: 2.4728348306621113

Epoch: 5| Step: 9
Training loss: 1.7968088552491153
Validation loss: 2.382297651890838

Epoch: 5| Step: 10
Training loss: 1.7855318371346698
Validation loss: 2.391393143591954

Epoch: 360| Step: 0
Training loss: 1.7382272090440969
Validation loss: 2.4121299575047743

Epoch: 5| Step: 1
Training loss: 1.438169240656505
Validation loss: 2.371287195259055

Epoch: 5| Step: 2
Training loss: 1.7719080038882278
Validation loss: 2.3968961144550387

Epoch: 5| Step: 3
Training loss: 1.7509097731745682
Validation loss: 2.4897546302936684

Epoch: 5| Step: 4
Training loss: 1.876783031810665
Validation loss: 2.454105273563393

Epoch: 5| Step: 5
Training loss: 1.4529886489393278
Validation loss: 2.4791431954991863

Epoch: 5| Step: 6
Training loss: 1.311972602968151
Validation loss: 2.4453475542336447

Epoch: 5| Step: 7
Training loss: 1.846602867461211
Validation loss: 2.4963863487022313

Epoch: 5| Step: 8
Training loss: 1.4486197907303708
Validation loss: 2.509497772067067

Epoch: 5| Step: 9
Training loss: 2.5919953811392427
Validation loss: 2.5060085897722804

Epoch: 5| Step: 10
Training loss: 1.7629119824418105
Validation loss: 2.515198273115683

Epoch: 361| Step: 0
Training loss: 1.599733899757572
Validation loss: 2.4136121572545806

Epoch: 5| Step: 1
Training loss: 1.5342373415229116
Validation loss: 2.360470855287536

Epoch: 5| Step: 2
Training loss: 1.217939351762699
Validation loss: 2.447505417007414

Epoch: 5| Step: 3
Training loss: 1.6232672770074401
Validation loss: 2.469807918531772

Epoch: 5| Step: 4
Training loss: 1.8196759727777199
Validation loss: 2.4395354417548156

Epoch: 5| Step: 5
Training loss: 1.6274711452803372
Validation loss: 2.4091469317354877

Epoch: 5| Step: 6
Training loss: 1.484894511011401
Validation loss: 2.414401358646205

Epoch: 5| Step: 7
Training loss: 2.2674549999208935
Validation loss: 2.4197701608526256

Epoch: 5| Step: 8
Training loss: 1.5875071758198194
Validation loss: 2.387733665413451

Epoch: 5| Step: 9
Training loss: 1.8620086098501607
Validation loss: 2.388107864154331

Epoch: 5| Step: 10
Training loss: 1.7413374533397623
Validation loss: 2.424874545777417

Epoch: 362| Step: 0
Training loss: 1.9633189175351247
Validation loss: 2.3968757220066603

Epoch: 5| Step: 1
Training loss: 1.7232031267709798
Validation loss: 2.3791032070386366

Epoch: 5| Step: 2
Training loss: 1.8663924691356948
Validation loss: 2.479528148370492

Epoch: 5| Step: 3
Training loss: 1.530333108231557
Validation loss: 2.4326715397792533

Epoch: 5| Step: 4
Training loss: 1.584378081851046
Validation loss: 2.423543335712619

Epoch: 5| Step: 5
Training loss: 1.9917117878525927
Validation loss: 2.403963591512775

Epoch: 5| Step: 6
Training loss: 1.6171204926250384
Validation loss: 2.4267918295795363

Epoch: 5| Step: 7
Training loss: 1.5401918556793583
Validation loss: 2.286581208001935

Epoch: 5| Step: 8
Training loss: 1.5117363349621198
Validation loss: 2.3948773638800724

Epoch: 5| Step: 9
Training loss: 1.5661690929610959
Validation loss: 2.389792670412753

Epoch: 5| Step: 10
Training loss: 1.5561676647053293
Validation loss: 2.4066302932948456

Epoch: 363| Step: 0
Training loss: 1.759951701260132
Validation loss: 2.439000839556893

Epoch: 5| Step: 1
Training loss: 1.9302020294311593
Validation loss: 2.4765690008018417

Epoch: 5| Step: 2
Training loss: 2.103485135536637
Validation loss: 2.428853714154175

Epoch: 5| Step: 3
Training loss: 1.5328651007007796
Validation loss: 2.423745256802298

Epoch: 5| Step: 4
Training loss: 1.2779083404087346
Validation loss: 2.379603140807758

Epoch: 5| Step: 5
Training loss: 1.6020832982784643
Validation loss: 2.4448186669354146

Epoch: 5| Step: 6
Training loss: 1.702364130410214
Validation loss: 2.408170498603322

Epoch: 5| Step: 7
Training loss: 1.6137017170887653
Validation loss: 2.459873674909038

Epoch: 5| Step: 8
Training loss: 1.490962779163215
Validation loss: 2.4441700533464243

Epoch: 5| Step: 9
Training loss: 1.983155724509558
Validation loss: 2.3802704461808863

Epoch: 5| Step: 10
Training loss: 1.5876862604401967
Validation loss: 2.350701946450292

Epoch: 364| Step: 0
Training loss: 2.182457152095693
Validation loss: 2.3893377414880637

Epoch: 5| Step: 1
Training loss: 1.2571010117409391
Validation loss: 2.428639171291832

Epoch: 5| Step: 2
Training loss: 1.7819595931253245
Validation loss: 2.350093845308017

Epoch: 5| Step: 3
Training loss: 1.3152524153240035
Validation loss: 2.475858403554279

Epoch: 5| Step: 4
Training loss: 1.55885278370553
Validation loss: 2.364552406093241

Epoch: 5| Step: 5
Training loss: 1.5021437584746233
Validation loss: 2.456685289851177

Epoch: 5| Step: 6
Training loss: 1.8492337805230212
Validation loss: 2.4661011156718655

Epoch: 5| Step: 7
Training loss: 1.7061974346182294
Validation loss: 2.4081273090395796

Epoch: 5| Step: 8
Training loss: 1.7566630356308957
Validation loss: 2.3811822778413765

Epoch: 5| Step: 9
Training loss: 1.6717439404037364
Validation loss: 2.441534924994491

Epoch: 5| Step: 10
Training loss: 2.1575489278220426
Validation loss: 2.3765734227384905

Epoch: 365| Step: 0
Training loss: 2.1997417688537655
Validation loss: 2.398345480537821

Epoch: 5| Step: 1
Training loss: 1.579840002047002
Validation loss: 2.4547468135425854

Epoch: 5| Step: 2
Training loss: 1.3127276359430078
Validation loss: 2.4311259891136765

Epoch: 5| Step: 3
Training loss: 1.9639423949695334
Validation loss: 2.4584819178018718

Epoch: 5| Step: 4
Training loss: 1.4305014872698234
Validation loss: 2.430295669404621

Epoch: 5| Step: 5
Training loss: 1.047354061913095
Validation loss: 2.416945280861027

Epoch: 5| Step: 6
Training loss: 1.9809677428383061
Validation loss: 2.3644910484202826

Epoch: 5| Step: 7
Training loss: 1.9198412174889001
Validation loss: 2.385860600807614

Epoch: 5| Step: 8
Training loss: 1.3557151108827825
Validation loss: 2.368877175932625

Epoch: 5| Step: 9
Training loss: 1.1744403987781957
Validation loss: 2.3690988232131414

Epoch: 5| Step: 10
Training loss: 2.0026452928808687
Validation loss: 2.446108541741539

Epoch: 366| Step: 0
Training loss: 1.0375448056393066
Validation loss: 2.4479810730248843

Epoch: 5| Step: 1
Training loss: 2.18791870469673
Validation loss: 2.386016588279425

Epoch: 5| Step: 2
Training loss: 1.272463794860208
Validation loss: 2.430343260354117

Epoch: 5| Step: 3
Training loss: 1.8402191232734695
Validation loss: 2.4536379566603808

Epoch: 5| Step: 4
Training loss: 1.5178374826135732
Validation loss: 2.3706457510836816

Epoch: 5| Step: 5
Training loss: 1.8877942039134843
Validation loss: 2.47293556837774

Epoch: 5| Step: 6
Training loss: 1.444867369692948
Validation loss: 2.441103619726238

Epoch: 5| Step: 7
Training loss: 1.2830129915116348
Validation loss: 2.3918098925051945

Epoch: 5| Step: 8
Training loss: 1.884542343275261
Validation loss: 2.4459314769542737

Epoch: 5| Step: 9
Training loss: 1.9444779287210239
Validation loss: 2.353345905581089

Epoch: 5| Step: 10
Training loss: 1.2358059375441883
Validation loss: 2.3969337318956576

Epoch: 367| Step: 0
Training loss: 1.5415049115800887
Validation loss: 2.4386010808063947

Epoch: 5| Step: 1
Training loss: 1.0937350135866428
Validation loss: 2.3553934036432245

Epoch: 5| Step: 2
Training loss: 1.5262670600056374
Validation loss: 2.4251202575166713

Epoch: 5| Step: 3
Training loss: 1.4214650495850303
Validation loss: 2.37385154594487

Epoch: 5| Step: 4
Training loss: 1.5336578278021895
Validation loss: 2.428929041485214

Epoch: 5| Step: 5
Training loss: 2.4174111852732216
Validation loss: 2.4261584628100725

Epoch: 5| Step: 6
Training loss: 1.8530310750127124
Validation loss: 2.4267134293240615

Epoch: 5| Step: 7
Training loss: 1.9357435817442135
Validation loss: 2.444080624217274

Epoch: 5| Step: 8
Training loss: 1.8163607027639543
Validation loss: 2.3871233567817245

Epoch: 5| Step: 9
Training loss: 1.6035000130082722
Validation loss: 2.4241064963420955

Epoch: 5| Step: 10
Training loss: 1.3539572431555345
Validation loss: 2.3985870550922788

Epoch: 368| Step: 0
Training loss: 1.7878209766226327
Validation loss: 2.4214472207320075

Epoch: 5| Step: 1
Training loss: 1.5500672664197594
Validation loss: 2.432906009444122

Epoch: 5| Step: 2
Training loss: 1.2856399877969946
Validation loss: 2.3815691865494744

Epoch: 5| Step: 3
Training loss: 1.5863092296896233
Validation loss: 2.3838230195215333

Epoch: 5| Step: 4
Training loss: 1.4159289945213513
Validation loss: 2.448184944136538

Epoch: 5| Step: 5
Training loss: 1.4720732245632187
Validation loss: 2.3886177386139926

Epoch: 5| Step: 6
Training loss: 1.8015202063222138
Validation loss: 2.373709191326089

Epoch: 5| Step: 7
Training loss: 1.7376599519503408
Validation loss: 2.4204406873386564

Epoch: 5| Step: 8
Training loss: 1.6695946088308127
Validation loss: 2.381541725070006

Epoch: 5| Step: 9
Training loss: 1.72572810521633
Validation loss: 2.4089856029372423

Epoch: 5| Step: 10
Training loss: 2.306857777967635
Validation loss: 2.437978035028951

Epoch: 369| Step: 0
Training loss: 1.543596666265537
Validation loss: 2.4354702218351076

Epoch: 5| Step: 1
Training loss: 1.3894774170200652
Validation loss: 2.44306611711108

Epoch: 5| Step: 2
Training loss: 1.6081522027571475
Validation loss: 2.4319045117576428

Epoch: 5| Step: 3
Training loss: 1.3760712958511867
Validation loss: 2.460525053626537

Epoch: 5| Step: 4
Training loss: 2.179808473135478
Validation loss: 2.396866843440227

Epoch: 5| Step: 5
Training loss: 1.7820167229849233
Validation loss: 2.449010096778135

Epoch: 5| Step: 6
Training loss: 1.798483684089301
Validation loss: 2.432399230828549

Epoch: 5| Step: 7
Training loss: 1.7367816757491827
Validation loss: 2.3725078203287286

Epoch: 5| Step: 8
Training loss: 1.5964108862039033
Validation loss: 2.390583829118411

Epoch: 5| Step: 9
Training loss: 1.7558942712831684
Validation loss: 2.490444879869784

Epoch: 5| Step: 10
Training loss: 1.3544948278069977
Validation loss: 2.415091358295312

Epoch: 370| Step: 0
Training loss: 1.4288415959885132
Validation loss: 2.3436671362007266

Epoch: 5| Step: 1
Training loss: 1.596091700555846
Validation loss: 2.4622900773877965

Epoch: 5| Step: 2
Training loss: 1.591267016635235
Validation loss: 2.4413481606412537

Epoch: 5| Step: 3
Training loss: 1.6473279355489574
Validation loss: 2.4251232084624883

Epoch: 5| Step: 4
Training loss: 1.3848154250042317
Validation loss: 2.4834194067539013

Epoch: 5| Step: 5
Training loss: 1.4220441780470912
Validation loss: 2.3636923567749006

Epoch: 5| Step: 6
Training loss: 1.718682443851672
Validation loss: 2.451219727894317

Epoch: 5| Step: 7
Training loss: 1.8539462297825158
Validation loss: 2.431651799334062

Epoch: 5| Step: 8
Training loss: 1.4327770266202848
Validation loss: 2.4413145291070477

Epoch: 5| Step: 9
Training loss: 1.5663251213696792
Validation loss: 2.4582099588121817

Epoch: 5| Step: 10
Training loss: 2.1720753309769716
Validation loss: 2.4627704347559916

Epoch: 371| Step: 0
Training loss: 1.336736518211148
Validation loss: 2.427613003880775

Epoch: 5| Step: 1
Training loss: 1.6792381217778372
Validation loss: 2.431034958102313

Epoch: 5| Step: 2
Training loss: 1.5349826083611473
Validation loss: 2.4830817774532656

Epoch: 5| Step: 3
Training loss: 1.6584709679055278
Validation loss: 2.421642911324876

Epoch: 5| Step: 4
Training loss: 1.53729797524659
Validation loss: 2.372249507762342

Epoch: 5| Step: 5
Training loss: 1.3483508545232639
Validation loss: 2.3697111148299137

Epoch: 5| Step: 6
Training loss: 1.7360990049152019
Validation loss: 2.400590139623325

Epoch: 5| Step: 7
Training loss: 2.081062477988703
Validation loss: 2.4102287292883946

Epoch: 5| Step: 8
Training loss: 1.6351702154140024
Validation loss: 2.4040302169289234

Epoch: 5| Step: 9
Training loss: 2.1577554506001664
Validation loss: 2.405580360065066

Epoch: 5| Step: 10
Training loss: 1.3762438956392955
Validation loss: 2.5080869050034456

Epoch: 372| Step: 0
Training loss: 1.583930338021324
Validation loss: 2.438739474094681

Epoch: 5| Step: 1
Training loss: 1.974947605162374
Validation loss: 2.5384708514756125

Epoch: 5| Step: 2
Training loss: 1.6606299588406126
Validation loss: 2.377398566939352

Epoch: 5| Step: 3
Training loss: 2.217242306226147
Validation loss: 2.3823981866470523

Epoch: 5| Step: 4
Training loss: 1.5763987551626397
Validation loss: 2.3872282886264893

Epoch: 5| Step: 5
Training loss: 1.41305320506751
Validation loss: 2.335155963089056

Epoch: 5| Step: 6
Training loss: 1.5591912904823968
Validation loss: 2.4365130125620063

Epoch: 5| Step: 7
Training loss: 1.7508866243938592
Validation loss: 2.446859331334493

Epoch: 5| Step: 8
Training loss: 1.1723095914533417
Validation loss: 2.400713472787889

Epoch: 5| Step: 9
Training loss: 1.596088937088352
Validation loss: 2.403360985726023

Epoch: 5| Step: 10
Training loss: 1.4384732476200774
Validation loss: 2.371814048647906

Epoch: 373| Step: 0
Training loss: 1.4360327488769773
Validation loss: 2.418111398121702

Epoch: 5| Step: 1
Training loss: 1.3746603632991166
Validation loss: 2.4361112954562563

Epoch: 5| Step: 2
Training loss: 1.809450082752903
Validation loss: 2.375047276301065

Epoch: 5| Step: 3
Training loss: 2.153378994027513
Validation loss: 2.3747873443146217

Epoch: 5| Step: 4
Training loss: 1.1963771990013619
Validation loss: 2.385262585679151

Epoch: 5| Step: 5
Training loss: 1.4607953497124282
Validation loss: 2.3578917066122886

Epoch: 5| Step: 6
Training loss: 1.250408344327965
Validation loss: 2.4618149986830167

Epoch: 5| Step: 7
Training loss: 1.616751201949492
Validation loss: 2.378732480377389

Epoch: 5| Step: 8
Training loss: 1.7762288044383676
Validation loss: 2.369375836385236

Epoch: 5| Step: 9
Training loss: 1.4774367554839964
Validation loss: 2.4037646064525475

Epoch: 5| Step: 10
Training loss: 2.2757706353476603
Validation loss: 2.4223000403863924

Epoch: 374| Step: 0
Training loss: 1.4053502489295837
Validation loss: 2.4692218973855624

Epoch: 5| Step: 1
Training loss: 1.1913550193903422
Validation loss: 2.406219010778801

Epoch: 5| Step: 2
Training loss: 2.5792973482696824
Validation loss: 2.453043093808722

Epoch: 5| Step: 3
Training loss: 1.5219498633549537
Validation loss: 2.391835903808536

Epoch: 5| Step: 4
Training loss: 2.136773759039678
Validation loss: 2.4473115801982304

Epoch: 5| Step: 5
Training loss: 1.7034580010156886
Validation loss: 2.3835523221053854

Epoch: 5| Step: 6
Training loss: 1.0439559322205987
Validation loss: 2.4200931902818987

Epoch: 5| Step: 7
Training loss: 1.5381050811060641
Validation loss: 2.4100636376541846

Epoch: 5| Step: 8
Training loss: 1.2851655258261376
Validation loss: 2.3099895431973683

Epoch: 5| Step: 9
Training loss: 1.5901267059991138
Validation loss: 2.374369538136114

Epoch: 5| Step: 10
Training loss: 1.1646346663806462
Validation loss: 2.370303252094342

Epoch: 375| Step: 0
Training loss: 2.362745795002708
Validation loss: 2.377498659455921

Epoch: 5| Step: 1
Training loss: 1.2906537493812704
Validation loss: 2.4623698685990387

Epoch: 5| Step: 2
Training loss: 1.4138972570491857
Validation loss: 2.4076348751513694

Epoch: 5| Step: 3
Training loss: 1.7278471435341343
Validation loss: 2.4457243965252276

Epoch: 5| Step: 4
Training loss: 1.5467085315256202
Validation loss: 2.4129414639432545

Epoch: 5| Step: 5
Training loss: 1.507187550746625
Validation loss: 2.3736175729976003

Epoch: 5| Step: 6
Training loss: 1.4634927037783452
Validation loss: 2.4544662848909313

Epoch: 5| Step: 7
Training loss: 1.7252236953762037
Validation loss: 2.414925370039119

Epoch: 5| Step: 8
Training loss: 1.3425784659586415
Validation loss: 2.437425620156602

Epoch: 5| Step: 9
Training loss: 1.779135670566876
Validation loss: 2.4710747399092567

Epoch: 5| Step: 10
Training loss: 1.562349235890521
Validation loss: 2.36310957079369

Epoch: 376| Step: 0
Training loss: 1.5199498872276112
Validation loss: 2.4739675656175004

Epoch: 5| Step: 1
Training loss: 1.8830437735819388
Validation loss: 2.425086387716826

Epoch: 5| Step: 2
Training loss: 1.4037693184043873
Validation loss: 2.4838814586033777

Epoch: 5| Step: 3
Training loss: 1.4722878883320172
Validation loss: 2.404527193671887

Epoch: 5| Step: 4
Training loss: 1.7751356556593194
Validation loss: 2.41757956826935

Epoch: 5| Step: 5
Training loss: 1.3459310352461578
Validation loss: 2.3672070294799754

Epoch: 5| Step: 6
Training loss: 1.142509993127571
Validation loss: 2.377208552984866

Epoch: 5| Step: 7
Training loss: 1.4466647858468296
Validation loss: 2.403956370222611

Epoch: 5| Step: 8
Training loss: 2.3727062593125505
Validation loss: 2.478130059402023

Epoch: 5| Step: 9
Training loss: 1.4720553277543513
Validation loss: 2.402887867567415

Epoch: 5| Step: 10
Training loss: 1.7147977992268582
Validation loss: 2.3518636358936957

Epoch: 377| Step: 0
Training loss: 2.2971489152611544
Validation loss: 2.3658597889933715

Epoch: 5| Step: 1
Training loss: 1.8304473602178355
Validation loss: 2.4057664357359174

Epoch: 5| Step: 2
Training loss: 1.5825496624812
Validation loss: 2.445895622449575

Epoch: 5| Step: 3
Training loss: 1.3887314066084278
Validation loss: 2.367207459964951

Epoch: 5| Step: 4
Training loss: 1.4800602895468007
Validation loss: 2.3955622544199002

Epoch: 5| Step: 5
Training loss: 1.5542485369816093
Validation loss: 2.441397813745505

Epoch: 5| Step: 6
Training loss: 1.0474846047155484
Validation loss: 2.4230994393247127

Epoch: 5| Step: 7
Training loss: 1.7301959991780986
Validation loss: 2.370517518312641

Epoch: 5| Step: 8
Training loss: 1.328954011573508
Validation loss: 2.3998412943308867

Epoch: 5| Step: 9
Training loss: 1.6002470243021363
Validation loss: 2.35861783807606

Epoch: 5| Step: 10
Training loss: 1.879430495503028
Validation loss: 2.366609673750455

Epoch: 378| Step: 0
Training loss: 1.4124961734821173
Validation loss: 2.470282359823841

Epoch: 5| Step: 1
Training loss: 1.2493936021497194
Validation loss: 2.3223240050000293

Epoch: 5| Step: 2
Training loss: 1.3440555846039273
Validation loss: 2.402117759358927

Epoch: 5| Step: 3
Training loss: 2.015263251437691
Validation loss: 2.448451309274576

Epoch: 5| Step: 4
Training loss: 1.7247089085094323
Validation loss: 2.420002635177063

Epoch: 5| Step: 5
Training loss: 1.8680535386967634
Validation loss: 2.3738042393500045

Epoch: 5| Step: 6
Training loss: 1.7844103834715923
Validation loss: 2.4300917316959425

Epoch: 5| Step: 7
Training loss: 1.4794142699418389
Validation loss: 2.4064611681344306

Epoch: 5| Step: 8
Training loss: 1.51482858084628
Validation loss: 2.421265544812764

Epoch: 5| Step: 9
Training loss: 1.4444753335845186
Validation loss: 2.4175921744647435

Epoch: 5| Step: 10
Training loss: 1.3679198129420023
Validation loss: 2.394265844937855

Epoch: 379| Step: 0
Training loss: 1.3618174566933023
Validation loss: 2.3833435693296297

Epoch: 5| Step: 1
Training loss: 1.597843672151555
Validation loss: 2.3831375285022243

Epoch: 5| Step: 2
Training loss: 1.3664537040972076
Validation loss: 2.4300338856424064

Epoch: 5| Step: 3
Training loss: 2.010223010393044
Validation loss: 2.430834525799523

Epoch: 5| Step: 4
Training loss: 1.777003932787526
Validation loss: 2.4127634601170835

Epoch: 5| Step: 5
Training loss: 1.532392659371921
Validation loss: 2.47499191135358

Epoch: 5| Step: 6
Training loss: 1.8966798534281284
Validation loss: 2.4139236212191717

Epoch: 5| Step: 7
Training loss: 1.7278345177762515
Validation loss: 2.416563536187081

Epoch: 5| Step: 8
Training loss: 1.6590114820334791
Validation loss: 2.3903397608380925

Epoch: 5| Step: 9
Training loss: 1.3661388190037649
Validation loss: 2.3086960626566344

Epoch: 5| Step: 10
Training loss: 1.65359853441573
Validation loss: 2.4044536058568307

Epoch: 380| Step: 0
Training loss: 1.7502330216171522
Validation loss: 2.436870069698549

Epoch: 5| Step: 1
Training loss: 1.8334693063539185
Validation loss: 2.455634206059095

Epoch: 5| Step: 2
Training loss: 1.3440766935435013
Validation loss: 2.398704803312379

Epoch: 5| Step: 3
Training loss: 1.459784476036254
Validation loss: 2.3286720266937877

Epoch: 5| Step: 4
Training loss: 1.2414000312356528
Validation loss: 2.43373060673675

Epoch: 5| Step: 5
Training loss: 1.574845636462991
Validation loss: 2.447726408599622

Epoch: 5| Step: 6
Training loss: 1.5455935786686463
Validation loss: 2.3320896031930225

Epoch: 5| Step: 7
Training loss: 1.4920163680602885
Validation loss: 2.320674322914827

Epoch: 5| Step: 8
Training loss: 1.6011138287548468
Validation loss: 2.4383415755052837

Epoch: 5| Step: 9
Training loss: 1.2973092972073177
Validation loss: 2.378547668777403

Epoch: 5| Step: 10
Training loss: 2.2914464208942573
Validation loss: 2.4255115782596417

Epoch: 381| Step: 0
Training loss: 1.5905488721095908
Validation loss: 2.3990825653947883

Epoch: 5| Step: 1
Training loss: 1.9525671200321362
Validation loss: 2.458353762770316

Epoch: 5| Step: 2
Training loss: 1.32544563644746
Validation loss: 2.417476678133797

Epoch: 5| Step: 3
Training loss: 1.6105024221994826
Validation loss: 2.42817854637544

Epoch: 5| Step: 4
Training loss: 1.5938268156800277
Validation loss: 2.3417130542280304

Epoch: 5| Step: 5
Training loss: 2.2677415103848064
Validation loss: 2.4299738137295064

Epoch: 5| Step: 6
Training loss: 1.1450460272287535
Validation loss: 2.4413003137718636

Epoch: 5| Step: 7
Training loss: 1.1794169538886556
Validation loss: 2.4469385287859686

Epoch: 5| Step: 8
Training loss: 1.5234881270383858
Validation loss: 2.43354312860737

Epoch: 5| Step: 9
Training loss: 2.1658858457302452
Validation loss: 2.4520849888460794

Epoch: 5| Step: 10
Training loss: 1.1884749576303872
Validation loss: 2.39521162857795

Epoch: 382| Step: 0
Training loss: 1.1992103998844064
Validation loss: 2.4101476852145947

Epoch: 5| Step: 1
Training loss: 1.397927729434466
Validation loss: 2.3985861904225376

Epoch: 5| Step: 2
Training loss: 1.1676708339054525
Validation loss: 2.4140939582707506

Epoch: 5| Step: 3
Training loss: 1.577111249077811
Validation loss: 2.4487360001795193

Epoch: 5| Step: 4
Training loss: 1.0843162784562255
Validation loss: 2.3360142102762413

Epoch: 5| Step: 5
Training loss: 2.271069843913083
Validation loss: 2.417101640208685

Epoch: 5| Step: 6
Training loss: 1.7082321168021246
Validation loss: 2.4132837370245928

Epoch: 5| Step: 7
Training loss: 1.4850351572209908
Validation loss: 2.4096667713326423

Epoch: 5| Step: 8
Training loss: 1.3736047601676225
Validation loss: 2.3952757205658193

Epoch: 5| Step: 9
Training loss: 2.0239502246149113
Validation loss: 2.3911450419802796

Epoch: 5| Step: 10
Training loss: 1.8938593666046257
Validation loss: 2.438063735917938

Epoch: 383| Step: 0
Training loss: 1.8473317544853065
Validation loss: 2.4334378888262216

Epoch: 5| Step: 1
Training loss: 1.735220900442863
Validation loss: 2.4889889309275746

Epoch: 5| Step: 2
Training loss: 1.7061994608007063
Validation loss: 2.3662659267093247

Epoch: 5| Step: 3
Training loss: 1.4117651133267899
Validation loss: 2.4056697338110573

Epoch: 5| Step: 4
Training loss: 1.3207330428996598
Validation loss: 2.4669900012376633

Epoch: 5| Step: 5
Training loss: 1.1780685532704938
Validation loss: 2.4225654541412576

Epoch: 5| Step: 6
Training loss: 1.3442306546051357
Validation loss: 2.4793157138901467

Epoch: 5| Step: 7
Training loss: 2.01854464782669
Validation loss: 2.379340181085843

Epoch: 5| Step: 8
Training loss: 1.2928851235996637
Validation loss: 2.406912479795455

Epoch: 5| Step: 9
Training loss: 1.892740500524422
Validation loss: 2.395657411369992

Epoch: 5| Step: 10
Training loss: 1.5804155552916572
Validation loss: 2.427061397096518

Epoch: 384| Step: 0
Training loss: 1.3911415169535972
Validation loss: 2.471958960142328

Epoch: 5| Step: 1
Training loss: 1.6455477293702605
Validation loss: 2.424172585604502

Epoch: 5| Step: 2
Training loss: 1.1044106963540843
Validation loss: 2.471490708629812

Epoch: 5| Step: 3
Training loss: 1.122456483316022
Validation loss: 2.4316765399851534

Epoch: 5| Step: 4
Training loss: 1.726431518005187
Validation loss: 2.434895438856183

Epoch: 5| Step: 5
Training loss: 1.7760771881160915
Validation loss: 2.363487826507006

Epoch: 5| Step: 6
Training loss: 1.3965808755037479
Validation loss: 2.4010475357393584

Epoch: 5| Step: 7
Training loss: 2.2110713203828545
Validation loss: 2.4379099040297687

Epoch: 5| Step: 8
Training loss: 1.6923851369763683
Validation loss: 2.3967983468311105

Epoch: 5| Step: 9
Training loss: 1.7667996710367828
Validation loss: 2.408231409794984

Epoch: 5| Step: 10
Training loss: 1.5139003261324668
Validation loss: 2.426103974127843

Epoch: 385| Step: 0
Training loss: 1.6299025601241528
Validation loss: 2.428410192003258

Epoch: 5| Step: 1
Training loss: 1.6497926610664344
Validation loss: 2.430987456622914

Epoch: 5| Step: 2
Training loss: 1.2238222357653594
Validation loss: 2.4457485860219936

Epoch: 5| Step: 3
Training loss: 1.8305083169214178
Validation loss: 2.3866694416602434

Epoch: 5| Step: 4
Training loss: 1.9565135400480513
Validation loss: 2.418484596682058

Epoch: 5| Step: 5
Training loss: 1.3017602392518874
Validation loss: 2.4073162137793207

Epoch: 5| Step: 6
Training loss: 1.1501228266926504
Validation loss: 2.4134170407923285

Epoch: 5| Step: 7
Training loss: 2.1340930713425084
Validation loss: 2.4236883535135987

Epoch: 5| Step: 8
Training loss: 1.028005350681585
Validation loss: 2.366317895240102

Epoch: 5| Step: 9
Training loss: 1.6261740624703789
Validation loss: 2.3884447538987077

Epoch: 5| Step: 10
Training loss: 1.6223253833870408
Validation loss: 2.40454559094012

Epoch: 386| Step: 0
Training loss: 1.5262346460318363
Validation loss: 2.3903722713252584

Epoch: 5| Step: 1
Training loss: 1.5324912198236798
Validation loss: 2.381048907170619

Epoch: 5| Step: 2
Training loss: 1.2011310849590917
Validation loss: 2.4451068821997666

Epoch: 5| Step: 3
Training loss: 1.7041005131846698
Validation loss: 2.3614748410604633

Epoch: 5| Step: 4
Training loss: 1.1914529759984247
Validation loss: 2.3989089823601026

Epoch: 5| Step: 5
Training loss: 1.6634675157710146
Validation loss: 2.4091589648645284

Epoch: 5| Step: 6
Training loss: 1.7966805394308842
Validation loss: 2.4617196065119433

Epoch: 5| Step: 7
Training loss: 1.0937830238806359
Validation loss: 2.302231215151604

Epoch: 5| Step: 8
Training loss: 1.614059740712262
Validation loss: 2.3266132426749055

Epoch: 5| Step: 9
Training loss: 2.3120584839680363
Validation loss: 2.479845010206034

Epoch: 5| Step: 10
Training loss: 1.4272119320289405
Validation loss: 2.380098943314201

Epoch: 387| Step: 0
Training loss: 1.6412092349356724
Validation loss: 2.3589820580783485

Epoch: 5| Step: 1
Training loss: 1.245833605933186
Validation loss: 2.4040706584712206

Epoch: 5| Step: 2
Training loss: 2.2870291053244327
Validation loss: 2.4155015445838894

Epoch: 5| Step: 3
Training loss: 1.5697721244272318
Validation loss: 2.4524443427818974

Epoch: 5| Step: 4
Training loss: 1.2958764517786934
Validation loss: 2.386620332634839

Epoch: 5| Step: 5
Training loss: 1.5179664380129074
Validation loss: 2.3634192701441363

Epoch: 5| Step: 6
Training loss: 1.312390640789076
Validation loss: 2.397772667430065

Epoch: 5| Step: 7
Training loss: 1.4401053991421697
Validation loss: 2.435907976194882

Epoch: 5| Step: 8
Training loss: 1.9191767662181238
Validation loss: 2.3576547715770793

Epoch: 5| Step: 9
Training loss: 1.7677088905143272
Validation loss: 2.3704523637912045

Epoch: 5| Step: 10
Training loss: 1.3074273220161918
Validation loss: 2.378757898595639

Epoch: 388| Step: 0
Training loss: 1.8375389743745794
Validation loss: 2.3599950215723577

Epoch: 5| Step: 1
Training loss: 1.1469392929973623
Validation loss: 2.44290318901222

Epoch: 5| Step: 2
Training loss: 1.5353290955593666
Validation loss: 2.452792827919096

Epoch: 5| Step: 3
Training loss: 1.4337681968219331
Validation loss: 2.418598836516729

Epoch: 5| Step: 4
Training loss: 1.5360056150900012
Validation loss: 2.431143029895463

Epoch: 5| Step: 5
Training loss: 1.4304700700388162
Validation loss: 2.4535931966734337

Epoch: 5| Step: 6
Training loss: 2.456193790326494
Validation loss: 2.49176048477795

Epoch: 5| Step: 7
Training loss: 1.669050522507554
Validation loss: 2.444048625709367

Epoch: 5| Step: 8
Training loss: 1.5029306393150008
Validation loss: 2.4090052889463527

Epoch: 5| Step: 9
Training loss: 1.291475153640835
Validation loss: 2.480676428269251

Epoch: 5| Step: 10
Training loss: 1.5121326914797675
Validation loss: 2.3758250877431886

Epoch: 389| Step: 0
Training loss: 1.1511583858821957
Validation loss: 2.3727603838164835

Epoch: 5| Step: 1
Training loss: 1.6581085142142138
Validation loss: 2.3798157205760258

Epoch: 5| Step: 2
Training loss: 1.6469438484176375
Validation loss: 2.37963124412195

Epoch: 5| Step: 3
Training loss: 1.7753675939830766
Validation loss: 2.38853531030702

Epoch: 5| Step: 4
Training loss: 1.5173723039522204
Validation loss: 2.4436488754791723

Epoch: 5| Step: 5
Training loss: 2.3106586239024143
Validation loss: 2.4058578948421014

Epoch: 5| Step: 6
Training loss: 1.0275074643423154
Validation loss: 2.4227687429062663

Epoch: 5| Step: 7
Training loss: 1.3467794468522845
Validation loss: 2.3521273949066184

Epoch: 5| Step: 8
Training loss: 1.5531288653504072
Validation loss: 2.4567871118532962

Epoch: 5| Step: 9
Training loss: 1.4992388542540853
Validation loss: 2.4244438348481903

Epoch: 5| Step: 10
Training loss: 1.6569718281452366
Validation loss: 2.429881898153873

Epoch: 390| Step: 0
Training loss: 1.299138082361506
Validation loss: 2.3421575538480734

Epoch: 5| Step: 1
Training loss: 1.6374856613346758
Validation loss: 2.3878472334944374

Epoch: 5| Step: 2
Training loss: 2.060419825393009
Validation loss: 2.394798556302579

Epoch: 5| Step: 3
Training loss: 1.4794374764275526
Validation loss: 2.4210009847260667

Epoch: 5| Step: 4
Training loss: 1.4297453654935015
Validation loss: 2.4598802698396476

Epoch: 5| Step: 5
Training loss: 1.273862334923516
Validation loss: 2.4386980958007514

Epoch: 5| Step: 6
Training loss: 1.3013913668338974
Validation loss: 2.4164670127833006

Epoch: 5| Step: 7
Training loss: 1.1685221200007427
Validation loss: 2.4486577256511297

Epoch: 5| Step: 8
Training loss: 2.100530094271662
Validation loss: 2.416443328240349

Epoch: 5| Step: 9
Training loss: 1.796234481096756
Validation loss: 2.3495230734716697

Epoch: 5| Step: 10
Training loss: 1.435855754397538
Validation loss: 2.4268335302492763

Epoch: 391| Step: 0
Training loss: 1.5101392118437125
Validation loss: 2.4190444447402224

Epoch: 5| Step: 1
Training loss: 1.8649875337731217
Validation loss: 2.4258155185574304

Epoch: 5| Step: 2
Training loss: 2.105997164348494
Validation loss: 2.4304092665175165

Epoch: 5| Step: 3
Training loss: 1.5689837399400572
Validation loss: 2.420100630897911

Epoch: 5| Step: 4
Training loss: 1.5913660507855423
Validation loss: 2.3932050787007744

Epoch: 5| Step: 5
Training loss: 1.2496692219814314
Validation loss: 2.426397739504478

Epoch: 5| Step: 6
Training loss: 1.2628007624967326
Validation loss: 2.446347143521747

Epoch: 5| Step: 7
Training loss: 1.493957827487332
Validation loss: 2.453131548280574

Epoch: 5| Step: 8
Training loss: 1.4845307920917157
Validation loss: 2.404444800052997

Epoch: 5| Step: 9
Training loss: 1.4552441803056126
Validation loss: 2.4230388606277042

Epoch: 5| Step: 10
Training loss: 1.3954688160855389
Validation loss: 2.353719348827379

Epoch: 392| Step: 0
Training loss: 1.6726969187040552
Validation loss: 2.41883476888658

Epoch: 5| Step: 1
Training loss: 1.2737141876127762
Validation loss: 2.3874354593377394

Epoch: 5| Step: 2
Training loss: 1.6274460942120448
Validation loss: 2.4246880841006577

Epoch: 5| Step: 3
Training loss: 1.3768997939583472
Validation loss: 2.398775801081875

Epoch: 5| Step: 4
Training loss: 1.7459827362203337
Validation loss: 2.4252200755070996

Epoch: 5| Step: 5
Training loss: 1.65632211780084
Validation loss: 2.4652363280060916

Epoch: 5| Step: 6
Training loss: 1.4090613343891154
Validation loss: 2.4346102130419705

Epoch: 5| Step: 7
Training loss: 1.025678670479651
Validation loss: 2.3504817955305657

Epoch: 5| Step: 8
Training loss: 2.0491158835173895
Validation loss: 2.4406620799643806

Epoch: 5| Step: 9
Training loss: 1.895599252970561
Validation loss: 2.4208310706639335

Epoch: 5| Step: 10
Training loss: 1.3575362562111537
Validation loss: 2.3699072648154083

Epoch: 393| Step: 0
Training loss: 1.0686285875746366
Validation loss: 2.391016177010024

Epoch: 5| Step: 1
Training loss: 1.4643686566803615
Validation loss: 2.4371612971901384

Epoch: 5| Step: 2
Training loss: 1.701225761672549
Validation loss: 2.3929868833886037

Epoch: 5| Step: 3
Training loss: 1.0697233708814446
Validation loss: 2.455287400656064

Epoch: 5| Step: 4
Training loss: 2.3481803220233215
Validation loss: 2.3656303466063693

Epoch: 5| Step: 5
Training loss: 1.74685263303792
Validation loss: 2.350073205461765

Epoch: 5| Step: 6
Training loss: 1.6893829860350313
Validation loss: 2.407157511603634

Epoch: 5| Step: 7
Training loss: 1.334684888961764
Validation loss: 2.444936805822911

Epoch: 5| Step: 8
Training loss: 0.9622266232551652
Validation loss: 2.3168951215669464

Epoch: 5| Step: 9
Training loss: 1.755780889774675
Validation loss: 2.443277141434851

Epoch: 5| Step: 10
Training loss: 1.3358371094578714
Validation loss: 2.364120234404263

Epoch: 394| Step: 0
Training loss: 1.55534571223777
Validation loss: 2.343246521827934

Epoch: 5| Step: 1
Training loss: 1.9750159926913804
Validation loss: 2.4358522142663466

Epoch: 5| Step: 2
Training loss: 1.11269730093512
Validation loss: 2.38448600348842

Epoch: 5| Step: 3
Training loss: 1.4270863034108388
Validation loss: 2.3925603562968267

Epoch: 5| Step: 4
Training loss: 2.2912915934332094
Validation loss: 2.4330055306658895

Epoch: 5| Step: 5
Training loss: 1.289254006696729
Validation loss: 2.3309389792758974

Epoch: 5| Step: 6
Training loss: 1.6143992247261099
Validation loss: 2.461525497598849

Epoch: 5| Step: 7
Training loss: 1.3042567564263008
Validation loss: 2.4086665907543385

Epoch: 5| Step: 8
Training loss: 1.0932799828023028
Validation loss: 2.3670638994446085

Epoch: 5| Step: 9
Training loss: 1.4152803182449143
Validation loss: 2.383343020748682

Epoch: 5| Step: 10
Training loss: 1.459038627463531
Validation loss: 2.437970629520642

Epoch: 395| Step: 0
Training loss: 1.2400755773092884
Validation loss: 2.363995495844539

Epoch: 5| Step: 1
Training loss: 1.4022013982496797
Validation loss: 2.410500636429267

Epoch: 5| Step: 2
Training loss: 2.016412388978087
Validation loss: 2.4109101977578304

Epoch: 5| Step: 3
Training loss: 1.6462340611502322
Validation loss: 2.3412848904706767

Epoch: 5| Step: 4
Training loss: 1.4043575268461852
Validation loss: 2.371882600696599

Epoch: 5| Step: 5
Training loss: 1.256963407725864
Validation loss: 2.411419170065787

Epoch: 5| Step: 6
Training loss: 1.739671061544184
Validation loss: 2.39313921351571

Epoch: 5| Step: 7
Training loss: 1.4247278790233444
Validation loss: 2.426117922400247

Epoch: 5| Step: 8
Training loss: 1.6418976706750081
Validation loss: 2.4068473428192867

Epoch: 5| Step: 9
Training loss: 1.4110360399478814
Validation loss: 2.3925640937037134

Epoch: 5| Step: 10
Training loss: 1.5190913095510552
Validation loss: 2.411552285621259

Epoch: 396| Step: 0
Training loss: 1.3965125021069287
Validation loss: 2.350973442305714

Epoch: 5| Step: 1
Training loss: 1.485879396732629
Validation loss: 2.422648067457703

Epoch: 5| Step: 2
Training loss: 1.359972460762455
Validation loss: 2.372638512804946

Epoch: 5| Step: 3
Training loss: 1.1866227975694499
Validation loss: 2.3367795442735644

Epoch: 5| Step: 4
Training loss: 1.6819503800175153
Validation loss: 2.4057540840651788

Epoch: 5| Step: 5
Training loss: 1.8678549367708768
Validation loss: 2.408389168346241

Epoch: 5| Step: 6
Training loss: 1.1259317777913351
Validation loss: 2.3802796688355086

Epoch: 5| Step: 7
Training loss: 2.033279930518272
Validation loss: 2.333127529836402

Epoch: 5| Step: 8
Training loss: 1.6746389056752637
Validation loss: 2.358152016464725

Epoch: 5| Step: 9
Training loss: 1.7399608940904008
Validation loss: 2.435903050782912

Epoch: 5| Step: 10
Training loss: 1.6017519955063713
Validation loss: 2.4211191088715833

Epoch: 397| Step: 0
Training loss: 1.2663718010031078
Validation loss: 2.4573366728626818

Epoch: 5| Step: 1
Training loss: 2.3101143774805255
Validation loss: 2.397651918083947

Epoch: 5| Step: 2
Training loss: 1.426695982254541
Validation loss: 2.3716971626383816

Epoch: 5| Step: 3
Training loss: 1.4942403523192873
Validation loss: 2.4587943223810105

Epoch: 5| Step: 4
Training loss: 1.3731341273230604
Validation loss: 2.3325268967662853

Epoch: 5| Step: 5
Training loss: 1.485182773246896
Validation loss: 2.395121506018435

Epoch: 5| Step: 6
Training loss: 1.5559913113849146
Validation loss: 2.356614784772195

Epoch: 5| Step: 7
Training loss: 1.4282616347512265
Validation loss: 2.423189086288347

Epoch: 5| Step: 8
Training loss: 1.2463871242800797
Validation loss: 2.4341738482582564

Epoch: 5| Step: 9
Training loss: 1.5763221489459858
Validation loss: 2.3901259552687724

Epoch: 5| Step: 10
Training loss: 1.6110228463180287
Validation loss: 2.407484141865888

Epoch: 398| Step: 0
Training loss: 1.1463464397266485
Validation loss: 2.4796480771523552

Epoch: 5| Step: 1
Training loss: 1.5283493282988427
Validation loss: 2.440932203641333

Epoch: 5| Step: 2
Training loss: 2.4227568958858625
Validation loss: 2.4435767212702633

Epoch: 5| Step: 3
Training loss: 1.3629946257078775
Validation loss: 2.4374124192037265

Epoch: 5| Step: 4
Training loss: 1.034417576216135
Validation loss: 2.3877004796195838

Epoch: 5| Step: 5
Training loss: 1.4157552966517761
Validation loss: 2.389690078288129

Epoch: 5| Step: 6
Training loss: 1.7419709212134953
Validation loss: 2.4204654377274566

Epoch: 5| Step: 7
Training loss: 1.3080420854284056
Validation loss: 2.407102745636056

Epoch: 5| Step: 8
Training loss: 1.490940871449778
Validation loss: 2.4519418779464455

Epoch: 5| Step: 9
Training loss: 1.3359733264424702
Validation loss: 2.3529013753491905

Epoch: 5| Step: 10
Training loss: 1.060250369049634
Validation loss: 2.399409263042736

Epoch: 399| Step: 0
Training loss: 1.030159228896433
Validation loss: 2.3815681068696755

Epoch: 5| Step: 1
Training loss: 1.3831964595518809
Validation loss: 2.373961723112224

Epoch: 5| Step: 2
Training loss: 1.494989052033925
Validation loss: 2.4395683175530842

Epoch: 5| Step: 3
Training loss: 1.7372150708951284
Validation loss: 2.4072799832775336

Epoch: 5| Step: 4
Training loss: 1.4338689638652091
Validation loss: 2.3985239825486775

Epoch: 5| Step: 5
Training loss: 1.4781467073229744
Validation loss: 2.355765325249042

Epoch: 5| Step: 6
Training loss: 2.359073240675373
Validation loss: 2.402416790454549

Epoch: 5| Step: 7
Training loss: 0.856480596635455
Validation loss: 2.376648475976495

Epoch: 5| Step: 8
Training loss: 1.7571976328053411
Validation loss: 2.4056938806175823

Epoch: 5| Step: 9
Training loss: 1.1288629015351428
Validation loss: 2.44104318536969

Epoch: 5| Step: 10
Training loss: 1.887496061510436
Validation loss: 2.369548763432502

Epoch: 400| Step: 0
Training loss: 1.368396638520212
Validation loss: 2.4338253429004966

Epoch: 5| Step: 1
Training loss: 1.697143550297429
Validation loss: 2.530829257551421

Epoch: 5| Step: 2
Training loss: 1.4713626107392745
Validation loss: 2.418570811824734

Epoch: 5| Step: 3
Training loss: 1.4090705136671717
Validation loss: 2.400148858133467

Epoch: 5| Step: 4
Training loss: 2.2126195325728397
Validation loss: 2.368949048161564

Epoch: 5| Step: 5
Training loss: 1.600267957064869
Validation loss: 2.391139428252175

Epoch: 5| Step: 6
Training loss: 1.508929219572262
Validation loss: 2.404476420404773

Epoch: 5| Step: 7
Training loss: 1.4242045842824813
Validation loss: 2.374979345062369

Epoch: 5| Step: 8
Training loss: 1.225591335816672
Validation loss: 2.346741899224386

Epoch: 5| Step: 9
Training loss: 1.9671391754638337
Validation loss: 2.425350872383741

Epoch: 5| Step: 10
Training loss: 1.0305847565408819
Validation loss: 2.3852378945522705

Testing loss: 2.8767505697315348
