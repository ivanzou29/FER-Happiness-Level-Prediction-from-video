Epoch: 1| Step: 0
Training loss: 7.166337412286578
Validation loss: 7.1034852027238795

Epoch: 5| Step: 1
Training loss: 6.035751323312222
Validation loss: 7.097511729923394

Epoch: 5| Step: 2
Training loss: 7.179837595768537
Validation loss: 7.088910259797912

Epoch: 5| Step: 3
Training loss: 6.628418814025038
Validation loss: 7.0831829057484725

Epoch: 5| Step: 4
Training loss: 7.47905476804313
Validation loss: 7.078800960075863

Epoch: 5| Step: 5
Training loss: 6.940648919364457
Validation loss: 7.070815284468077

Epoch: 5| Step: 6
Training loss: 7.091680956003187
Validation loss: 7.0619813534609035

Epoch: 5| Step: 7
Training loss: 7.52994560880635
Validation loss: 7.0562908303127765

Epoch: 5| Step: 8
Training loss: 7.24040824160675
Validation loss: 7.048867063793515

Epoch: 5| Step: 9
Training loss: 6.412881833135686
Validation loss: 7.0418252603673785

Epoch: 5| Step: 10
Training loss: 7.86138829557718
Validation loss: 7.034582948834761

Epoch: 2| Step: 0
Training loss: 7.130625060345039
Validation loss: 7.025867202723488

Epoch: 5| Step: 1
Training loss: 6.556448625986867
Validation loss: 7.01902125643118

Epoch: 5| Step: 2
Training loss: 7.233205086879358
Validation loss: 7.014075389218058

Epoch: 5| Step: 3
Training loss: 6.746373367920335
Validation loss: 7.008145838657104

Epoch: 5| Step: 4
Training loss: 6.535239721336321
Validation loss: 6.998993254779077

Epoch: 5| Step: 5
Training loss: 6.754631431571021
Validation loss: 6.989954377876858

Epoch: 5| Step: 6
Training loss: 7.81222069813239
Validation loss: 6.983564178311055

Epoch: 5| Step: 7
Training loss: 6.266251758610958
Validation loss: 6.978910792335576

Epoch: 5| Step: 8
Training loss: 7.350220771639836
Validation loss: 6.972160277089894

Epoch: 5| Step: 9
Training loss: 6.018707991440561
Validation loss: 6.9656774993936255

Epoch: 5| Step: 10
Training loss: 8.27451542936626
Validation loss: 6.958718791049003

Epoch: 3| Step: 0
Training loss: 7.620817944938873
Validation loss: 6.948687702047098

Epoch: 5| Step: 1
Training loss: 7.371478258221059
Validation loss: 6.941477559065279

Epoch: 5| Step: 2
Training loss: 6.791676464736829
Validation loss: 6.937298539080184

Epoch: 5| Step: 3
Training loss: 5.809952372423049
Validation loss: 6.9281326489799

Epoch: 5| Step: 4
Training loss: 6.469601782405189
Validation loss: 6.9204031701841116

Epoch: 5| Step: 5
Training loss: 6.156508387066449
Validation loss: 6.914334616298242

Epoch: 5| Step: 6
Training loss: 7.952636463921567
Validation loss: 6.906247357013601

Epoch: 5| Step: 7
Training loss: 6.62958842753499
Validation loss: 6.898006405996473

Epoch: 5| Step: 8
Training loss: 7.536391912842965
Validation loss: 6.893076039421597

Epoch: 5| Step: 9
Training loss: 6.780431460715242
Validation loss: 6.887371464190558

Epoch: 5| Step: 10
Training loss: 6.4359105194111565
Validation loss: 6.879782025432086

Epoch: 4| Step: 0
Training loss: 5.3679049482955215
Validation loss: 6.874003694447901

Epoch: 5| Step: 1
Training loss: 5.724425787635345
Validation loss: 6.866681188266754

Epoch: 5| Step: 2
Training loss: 7.281813178159757
Validation loss: 6.858944055267038

Epoch: 5| Step: 3
Training loss: 6.885947371982797
Validation loss: 6.852328527300939

Epoch: 5| Step: 4
Training loss: 6.247598110251395
Validation loss: 6.8448135389435105

Epoch: 5| Step: 5
Training loss: 6.638066487824398
Validation loss: 6.839689686434643

Epoch: 5| Step: 6
Training loss: 7.483989665837291
Validation loss: 6.8345195702063695

Epoch: 5| Step: 7
Training loss: 7.250321216702149
Validation loss: 6.825653897305613

Epoch: 5| Step: 8
Training loss: 6.9835922860847
Validation loss: 6.819072763745943

Epoch: 5| Step: 9
Training loss: 7.039623106924747
Validation loss: 6.814298646896531

Epoch: 5| Step: 10
Training loss: 7.961040522364552
Validation loss: 6.804578513966179

Epoch: 5| Step: 0
Training loss: 7.125046311612785
Validation loss: 6.802480062842409

Epoch: 5| Step: 1
Training loss: 7.02779374688319
Validation loss: 6.790657653483938

Epoch: 5| Step: 2
Training loss: 6.5885744438311
Validation loss: 6.783861602791094

Epoch: 5| Step: 3
Training loss: 6.525725588155258
Validation loss: 6.776643691232828

Epoch: 5| Step: 4
Training loss: 7.022995914754069
Validation loss: 6.769094976342028

Epoch: 5| Step: 5
Training loss: 5.5756962294401555
Validation loss: 6.761428819683085

Epoch: 5| Step: 6
Training loss: 6.9419472676227585
Validation loss: 6.7552459093615305

Epoch: 5| Step: 7
Training loss: 7.040903746077164
Validation loss: 6.749688582260946

Epoch: 5| Step: 8
Training loss: 6.89433870127728
Validation loss: 6.741250097758667

Epoch: 5| Step: 9
Training loss: 6.241297346867996
Validation loss: 6.731334396428731

Epoch: 5| Step: 10
Training loss: 7.209292603391028
Validation loss: 6.724846040062993

Epoch: 6| Step: 0
Training loss: 6.290009573002794
Validation loss: 6.7195487545156976

Epoch: 5| Step: 1
Training loss: 6.5889594587664275
Validation loss: 6.709458193834036

Epoch: 5| Step: 2
Training loss: 6.234614852842255
Validation loss: 6.703617237644149

Epoch: 5| Step: 3
Training loss: 6.882686133204326
Validation loss: 6.693780246597842

Epoch: 5| Step: 4
Training loss: 7.035518452641634
Validation loss: 6.688007791258606

Epoch: 5| Step: 5
Training loss: 6.282888018598457
Validation loss: 6.677867074043302

Epoch: 5| Step: 6
Training loss: 6.049259159347789
Validation loss: 6.67031476075569

Epoch: 5| Step: 7
Training loss: 6.943337948279176
Validation loss: 6.660584189447117

Epoch: 5| Step: 8
Training loss: 6.851072530941323
Validation loss: 6.653308647388298

Epoch: 5| Step: 9
Training loss: 7.10474098844845
Validation loss: 6.646293696970252

Epoch: 5| Step: 10
Training loss: 7.034326041554139
Validation loss: 6.636999002013451

Epoch: 7| Step: 0
Training loss: 6.555280219867518
Validation loss: 6.628080163191673

Epoch: 5| Step: 1
Training loss: 6.788350830704938
Validation loss: 6.619401767131551

Epoch: 5| Step: 2
Training loss: 7.090697585466127
Validation loss: 6.612480002665596

Epoch: 5| Step: 3
Training loss: 7.0512757357766915
Validation loss: 6.606161059479005

Epoch: 5| Step: 4
Training loss: 5.678978205366811
Validation loss: 6.597667335069582

Epoch: 5| Step: 5
Training loss: 6.966828906833427
Validation loss: 6.586633419250045

Epoch: 5| Step: 6
Training loss: 7.7787657912491115
Validation loss: 6.579255129724225

Epoch: 5| Step: 7
Training loss: 5.478490209945505
Validation loss: 6.56888841833054

Epoch: 5| Step: 8
Training loss: 5.76613476161556
Validation loss: 6.560232485036324

Epoch: 5| Step: 9
Training loss: 6.306586488909024
Validation loss: 6.548812419383108

Epoch: 5| Step: 10
Training loss: 6.5308525293043855
Validation loss: 6.541634530225669

Epoch: 8| Step: 0
Training loss: 6.734129722005136
Validation loss: 6.530470225169014

Epoch: 5| Step: 1
Training loss: 5.809813175841681
Validation loss: 6.524530643122637

Epoch: 5| Step: 2
Training loss: 6.005069180740428
Validation loss: 6.512543309207686

Epoch: 5| Step: 3
Training loss: 6.780455371339348
Validation loss: 6.503590254082315

Epoch: 5| Step: 4
Training loss: 6.243126102775456
Validation loss: 6.4946432766655

Epoch: 5| Step: 5
Training loss: 6.024675175311743
Validation loss: 6.486624636522403

Epoch: 5| Step: 6
Training loss: 5.950769634318124
Validation loss: 6.473850215846952

Epoch: 5| Step: 7
Training loss: 7.608448512642459
Validation loss: 6.466354537694236

Epoch: 5| Step: 8
Training loss: 6.813491889069224
Validation loss: 6.456067809752899

Epoch: 5| Step: 9
Training loss: 6.48261930297806
Validation loss: 6.444421994221223

Epoch: 5| Step: 10
Training loss: 6.615012936395638
Validation loss: 6.436864859604461

Epoch: 9| Step: 0
Training loss: 6.823177264723514
Validation loss: 6.42646547917251

Epoch: 5| Step: 1
Training loss: 6.665820195183164
Validation loss: 6.4135126012539425

Epoch: 5| Step: 2
Training loss: 5.443327838982921
Validation loss: 6.409479519232979

Epoch: 5| Step: 3
Training loss: 6.44810959666517
Validation loss: 6.398439109077138

Epoch: 5| Step: 4
Training loss: 7.044609433049428
Validation loss: 6.382680774329123

Epoch: 5| Step: 5
Training loss: 6.041648005314212
Validation loss: 6.372532874856095

Epoch: 5| Step: 6
Training loss: 6.264200785959563
Validation loss: 6.364181369178638

Epoch: 5| Step: 7
Training loss: 5.499370192100694
Validation loss: 6.349148171705725

Epoch: 5| Step: 8
Training loss: 6.810718548434966
Validation loss: 6.339881618299393

Epoch: 5| Step: 9
Training loss: 6.091063234819222
Validation loss: 6.32909718060255

Epoch: 5| Step: 10
Training loss: 6.760211144033451
Validation loss: 6.3210481013074356

Epoch: 10| Step: 0
Training loss: 6.22009784143163
Validation loss: 6.307918429614394

Epoch: 5| Step: 1
Training loss: 5.438748271208032
Validation loss: 6.297616211322165

Epoch: 5| Step: 2
Training loss: 5.8879854880859
Validation loss: 6.288187407028489

Epoch: 5| Step: 3
Training loss: 6.209814658723972
Validation loss: 6.278871081991938

Epoch: 5| Step: 4
Training loss: 5.810156893425573
Validation loss: 6.262520834027018

Epoch: 5| Step: 5
Training loss: 7.3177466195803
Validation loss: 6.252183023490578

Epoch: 5| Step: 6
Training loss: 6.441807759242063
Validation loss: 6.237783651502903

Epoch: 5| Step: 7
Training loss: 6.510137135926128
Validation loss: 6.2273268842195435

Epoch: 5| Step: 8
Training loss: 5.658168741265912
Validation loss: 6.2162022010548155

Epoch: 5| Step: 9
Training loss: 6.953506562125435
Validation loss: 6.205264078638019

Epoch: 5| Step: 10
Training loss: 5.933595357245503
Validation loss: 6.193874562042428

Epoch: 11| Step: 0
Training loss: 5.541511973275089
Validation loss: 6.174020084000799

Epoch: 5| Step: 1
Training loss: 6.759121418577582
Validation loss: 6.167613848330477

Epoch: 5| Step: 2
Training loss: 5.65961368927389
Validation loss: 6.151709423371287

Epoch: 5| Step: 3
Training loss: 6.099900179186945
Validation loss: 6.135738269175399

Epoch: 5| Step: 4
Training loss: 6.658962502988805
Validation loss: 6.122357704072933

Epoch: 5| Step: 5
Training loss: 5.895775604864059
Validation loss: 6.114545098334901

Epoch: 5| Step: 6
Training loss: 6.126354768359627
Validation loss: 6.101745452308126

Epoch: 5| Step: 7
Training loss: 6.101824140617097
Validation loss: 6.0882641504407085

Epoch: 5| Step: 8
Training loss: 6.581304728542179
Validation loss: 6.073023777530071

Epoch: 5| Step: 9
Training loss: 5.7387951022905686
Validation loss: 6.061323039172599

Epoch: 5| Step: 10
Training loss: 5.893155553618994
Validation loss: 6.042513779547655

Epoch: 12| Step: 0
Training loss: 5.674385461008744
Validation loss: 6.029790777537987

Epoch: 5| Step: 1
Training loss: 5.875390222454444
Validation loss: 6.018153627011476

Epoch: 5| Step: 2
Training loss: 5.823552278370652
Validation loss: 6.004234583441524

Epoch: 5| Step: 3
Training loss: 6.107605817005381
Validation loss: 5.992274201792631

Epoch: 5| Step: 4
Training loss: 5.0983166029423765
Validation loss: 5.972313941632198

Epoch: 5| Step: 5
Training loss: 5.262499144637883
Validation loss: 5.961853953804597

Epoch: 5| Step: 6
Training loss: 6.296071041457683
Validation loss: 5.94732247319419

Epoch: 5| Step: 7
Training loss: 7.033880258902765
Validation loss: 5.933120837985885

Epoch: 5| Step: 8
Training loss: 6.591871527355058
Validation loss: 5.921565041972262

Epoch: 5| Step: 9
Training loss: 6.043022407042002
Validation loss: 5.899853446507097

Epoch: 5| Step: 10
Training loss: 5.372902394345179
Validation loss: 5.8896822559741935

Epoch: 13| Step: 0
Training loss: 6.161801076875683
Validation loss: 5.870834395836918

Epoch: 5| Step: 1
Training loss: 5.922740701894267
Validation loss: 5.852912647947385

Epoch: 5| Step: 2
Training loss: 7.095370069857009
Validation loss: 5.842322065798177

Epoch: 5| Step: 3
Training loss: 5.576256361553478
Validation loss: 5.821551274810785

Epoch: 5| Step: 4
Training loss: 6.513093232356584
Validation loss: 5.804914860536097

Epoch: 5| Step: 5
Training loss: 5.063441436263166
Validation loss: 5.792059740367254

Epoch: 5| Step: 6
Training loss: 4.71899716569929
Validation loss: 5.774761534076396

Epoch: 5| Step: 7
Training loss: 5.586488923285379
Validation loss: 5.752942859224195

Epoch: 5| Step: 8
Training loss: 5.678822699485983
Validation loss: 5.738586779970629

Epoch: 5| Step: 9
Training loss: 6.0625050338252295
Validation loss: 5.7200421109131305

Epoch: 5| Step: 10
Training loss: 4.7520920011560355
Validation loss: 5.709231388715467

Epoch: 14| Step: 0
Training loss: 5.517745952923256
Validation loss: 5.683763735656855

Epoch: 5| Step: 1
Training loss: 5.267023370630472
Validation loss: 5.673136093931236

Epoch: 5| Step: 2
Training loss: 4.7202372449313925
Validation loss: 5.648423342955877

Epoch: 5| Step: 3
Training loss: 5.242329216077641
Validation loss: 5.640589549212552

Epoch: 5| Step: 4
Training loss: 5.874897083436168
Validation loss: 5.625521651386277

Epoch: 5| Step: 5
Training loss: 4.867192594424501
Validation loss: 5.600420596622463

Epoch: 5| Step: 6
Training loss: 5.585446294781613
Validation loss: 5.581468237885222

Epoch: 5| Step: 7
Training loss: 6.1171201504913135
Validation loss: 5.566481738266787

Epoch: 5| Step: 8
Training loss: 6.106315295398397
Validation loss: 5.548640741575487

Epoch: 5| Step: 9
Training loss: 6.495898199664936
Validation loss: 5.536946165853135

Epoch: 5| Step: 10
Training loss: 5.596756622579082
Validation loss: 5.513656362029981

Epoch: 15| Step: 0
Training loss: 5.1575228882807345
Validation loss: 5.495723073852293

Epoch: 5| Step: 1
Training loss: 4.349259429681095
Validation loss: 5.474928285694064

Epoch: 5| Step: 2
Training loss: 5.039813980726585
Validation loss: 5.4576957735458995

Epoch: 5| Step: 3
Training loss: 6.050977631073184
Validation loss: 5.441396574749067

Epoch: 5| Step: 4
Training loss: 5.643285234985753
Validation loss: 5.416526843112921

Epoch: 5| Step: 5
Training loss: 6.040179821647037
Validation loss: 5.398378458090947

Epoch: 5| Step: 6
Training loss: 5.322303074696226
Validation loss: 5.3798154726354115

Epoch: 5| Step: 7
Training loss: 5.004705313163448
Validation loss: 5.356264815637455

Epoch: 5| Step: 8
Training loss: 5.845166692518707
Validation loss: 5.33676503061593

Epoch: 5| Step: 9
Training loss: 5.576789931268705
Validation loss: 5.324873333828854

Epoch: 5| Step: 10
Training loss: 5.176569073296083
Validation loss: 5.293799985349452

Epoch: 16| Step: 0
Training loss: 5.151417265011332
Validation loss: 5.27743535804714

Epoch: 5| Step: 1
Training loss: 5.650774755781385
Validation loss: 5.253659946865111

Epoch: 5| Step: 2
Training loss: 4.166064613079298
Validation loss: 5.231833749438127

Epoch: 5| Step: 3
Training loss: 4.902031123311145
Validation loss: 5.21051432305115

Epoch: 5| Step: 4
Training loss: 4.98501821929755
Validation loss: 5.190023386470239

Epoch: 5| Step: 5
Training loss: 5.537387869153844
Validation loss: 5.174602532238524

Epoch: 5| Step: 6
Training loss: 4.6880409437220845
Validation loss: 5.1443953215095

Epoch: 5| Step: 7
Training loss: 5.645993032226155
Validation loss: 5.139300918948753

Epoch: 5| Step: 8
Training loss: 5.375349166529499
Validation loss: 5.106077790814043

Epoch: 5| Step: 9
Training loss: 5.08151028988153
Validation loss: 5.0884829372620315

Epoch: 5| Step: 10
Training loss: 5.683565896087246
Validation loss: 5.074633911723874

Epoch: 17| Step: 0
Training loss: 5.021741708388296
Validation loss: 5.042511551487406

Epoch: 5| Step: 1
Training loss: 5.526679267976305
Validation loss: 5.015479002550106

Epoch: 5| Step: 2
Training loss: 4.828830111967508
Validation loss: 4.990536127655222

Epoch: 5| Step: 3
Training loss: 4.746214110806646
Validation loss: 4.968252800910813

Epoch: 5| Step: 4
Training loss: 5.6844494362309534
Validation loss: 4.9433324490627575

Epoch: 5| Step: 5
Training loss: 5.351993560137103
Validation loss: 4.928960185360778

Epoch: 5| Step: 6
Training loss: 4.477191767644935
Validation loss: 4.898150611396406

Epoch: 5| Step: 7
Training loss: 4.84723326430692
Validation loss: 4.866889490063044

Epoch: 5| Step: 8
Training loss: 5.1372097926535325
Validation loss: 4.845295989942318

Epoch: 5| Step: 9
Training loss: 4.434310841650691
Validation loss: 4.822462462863673

Epoch: 5| Step: 10
Training loss: 4.136811195039401
Validation loss: 4.800842625993037

Epoch: 18| Step: 0
Training loss: 4.768361591005158
Validation loss: 4.776552624566302

Epoch: 5| Step: 1
Training loss: 4.650933834362322
Validation loss: 4.751220347747302

Epoch: 5| Step: 2
Training loss: 4.5032896097819775
Validation loss: 4.730018578382977

Epoch: 5| Step: 3
Training loss: 4.365547213342656
Validation loss: 4.696655703750108

Epoch: 5| Step: 4
Training loss: 4.131212353787319
Validation loss: 4.681138230472811

Epoch: 5| Step: 5
Training loss: 4.329093081179657
Validation loss: 4.666808462772097

Epoch: 5| Step: 6
Training loss: 4.616950789062305
Validation loss: 4.626086366039418

Epoch: 5| Step: 7
Training loss: 5.093691585650486
Validation loss: 4.612812548121263

Epoch: 5| Step: 8
Training loss: 5.732556629059245
Validation loss: 4.57806203137317

Epoch: 5| Step: 9
Training loss: 4.1158922391080885
Validation loss: 4.555213650315984

Epoch: 5| Step: 10
Training loss: 5.01410212229203
Validation loss: 4.5299118085780465

Epoch: 19| Step: 0
Training loss: 5.539210394215211
Validation loss: 4.499576350406531

Epoch: 5| Step: 1
Training loss: 3.532950607900395
Validation loss: 4.48197847077104

Epoch: 5| Step: 2
Training loss: 3.7624849388860335
Validation loss: 4.44667223749133

Epoch: 5| Step: 3
Training loss: 4.008487042330344
Validation loss: 4.421278285950104

Epoch: 5| Step: 4
Training loss: 4.135991566603306
Validation loss: 4.399868011918772

Epoch: 5| Step: 5
Training loss: 4.646274197905149
Validation loss: 4.376928984164857

Epoch: 5| Step: 6
Training loss: 4.692351411998215
Validation loss: 4.347984308147785

Epoch: 5| Step: 7
Training loss: 4.357037098514543
Validation loss: 4.312380569846852

Epoch: 5| Step: 8
Training loss: 5.0405687550140055
Validation loss: 4.283144473101912

Epoch: 5| Step: 9
Training loss: 4.4946290919082665
Validation loss: 4.2682776455083555

Epoch: 5| Step: 10
Training loss: 3.810936278796186
Validation loss: 4.231715883363639

Epoch: 20| Step: 0
Training loss: 3.9913507170593046
Validation loss: 4.205702209030685

Epoch: 5| Step: 1
Training loss: 4.091232340978827
Validation loss: 4.182767555499491

Epoch: 5| Step: 2
Training loss: 4.8238322608973885
Validation loss: 4.151581637993858

Epoch: 5| Step: 3
Training loss: 4.749552655487261
Validation loss: 4.1108432970964195

Epoch: 5| Step: 4
Training loss: 4.040743273356014
Validation loss: 4.088984146560872

Epoch: 5| Step: 5
Training loss: 3.5277019669471144
Validation loss: 4.081815297213495

Epoch: 5| Step: 6
Training loss: 4.474763039223658
Validation loss: 4.050277167391436

Epoch: 5| Step: 7
Training loss: 4.025237338253791
Validation loss: 4.022884675550109

Epoch: 5| Step: 8
Training loss: 3.8785273586821454
Validation loss: 3.9781153344001

Epoch: 5| Step: 9
Training loss: 3.9852049916765377
Validation loss: 3.961713445924983

Epoch: 5| Step: 10
Training loss: 3.635986647788062
Validation loss: 3.9289538014282512

Epoch: 21| Step: 0
Training loss: 3.2449426182168493
Validation loss: 3.889733773308404

Epoch: 5| Step: 1
Training loss: 4.140310369089807
Validation loss: 3.8679743061155882

Epoch: 5| Step: 2
Training loss: 3.824706875408924
Validation loss: 3.8383495397212566

Epoch: 5| Step: 3
Training loss: 3.851349180554664
Validation loss: 3.816184805145401

Epoch: 5| Step: 4
Training loss: 3.346489470402185
Validation loss: 3.788084462153937

Epoch: 5| Step: 5
Training loss: 4.1559826757751015
Validation loss: 3.7541073199188437

Epoch: 5| Step: 6
Training loss: 4.43627611932404
Validation loss: 3.7362625459985086

Epoch: 5| Step: 7
Training loss: 4.685695656962032
Validation loss: 3.7102283743666398

Epoch: 5| Step: 8
Training loss: 2.56614407342585
Validation loss: 3.69231396871911

Epoch: 5| Step: 9
Training loss: 4.262572597209855
Validation loss: 3.6677889313685172

Epoch: 5| Step: 10
Training loss: 3.2679115576758657
Validation loss: 3.618378700640055

Epoch: 22| Step: 0
Training loss: 3.397372936261486
Validation loss: 3.6067165156393526

Epoch: 5| Step: 1
Training loss: 3.700429973878326
Validation loss: 3.563510625492849

Epoch: 5| Step: 2
Training loss: 3.7664377435531855
Validation loss: 3.5533309502657024

Epoch: 5| Step: 3
Training loss: 2.778607087846861
Validation loss: 3.521573910582122

Epoch: 5| Step: 4
Training loss: 4.597380364890687
Validation loss: 3.492045989124984

Epoch: 5| Step: 5
Training loss: 3.9386601025761907
Validation loss: 3.4718547459781512

Epoch: 5| Step: 6
Training loss: 3.969625781892621
Validation loss: 3.4456397122496245

Epoch: 5| Step: 7
Training loss: 3.506792833599271
Validation loss: 3.411317852891188

Epoch: 5| Step: 8
Training loss: 3.0612472774669524
Validation loss: 3.398310351984142

Epoch: 5| Step: 9
Training loss: 3.1199940067624947
Validation loss: 3.3730260529603924

Epoch: 5| Step: 10
Training loss: 3.1996564740326185
Validation loss: 3.3505200849991756

Epoch: 23| Step: 0
Training loss: 2.976563781577808
Validation loss: 3.3255406109449526

Epoch: 5| Step: 1
Training loss: 3.3533211031236325
Validation loss: 3.290554987171138

Epoch: 5| Step: 2
Training loss: 3.532598592431156
Validation loss: 3.28865209001675

Epoch: 5| Step: 3
Training loss: 2.6366471344440967
Validation loss: 3.2615234033550515

Epoch: 5| Step: 4
Training loss: 3.166735765472894
Validation loss: 3.2407483797883456

Epoch: 5| Step: 5
Training loss: 3.794891969854506
Validation loss: 3.226123159663732

Epoch: 5| Step: 6
Training loss: 3.5387641831534533
Validation loss: 3.1979354585816475

Epoch: 5| Step: 7
Training loss: 4.00583913901215
Validation loss: 3.1920441358159395

Epoch: 5| Step: 8
Training loss: 3.371131233723023
Validation loss: 3.1632122169884664

Epoch: 5| Step: 9
Training loss: 3.265489347277841
Validation loss: 3.141976835476051

Epoch: 5| Step: 10
Training loss: 2.9807112808841842
Validation loss: 3.113611809285539

Epoch: 24| Step: 0
Training loss: 3.546445039072385
Validation loss: 3.098009480479053

Epoch: 5| Step: 1
Training loss: 3.1327841893008523
Validation loss: 3.08402402326111

Epoch: 5| Step: 2
Training loss: 3.385415712014088
Validation loss: 3.083994674486175

Epoch: 5| Step: 3
Training loss: 3.0183471094916277
Validation loss: 3.0584014126777888

Epoch: 5| Step: 4
Training loss: 3.60397344229309
Validation loss: 3.037955343765447

Epoch: 5| Step: 5
Training loss: 2.5387685752350633
Validation loss: 3.027478729742638

Epoch: 5| Step: 6
Training loss: 2.3223282506405387
Validation loss: 3.0060265938921624

Epoch: 5| Step: 7
Training loss: 2.0644995504624997
Validation loss: 2.9914200025853006

Epoch: 5| Step: 8
Training loss: 3.665096177820683
Validation loss: 2.9725568179426283

Epoch: 5| Step: 9
Training loss: 3.6608895103705485
Validation loss: 2.967363564235043

Epoch: 5| Step: 10
Training loss: 3.6883190991011654
Validation loss: 2.9518453735213543

Epoch: 25| Step: 0
Training loss: 2.7286768369350787
Validation loss: 2.9318936218647846

Epoch: 5| Step: 1
Training loss: 3.1304185810453067
Validation loss: 2.92382047833328

Epoch: 5| Step: 2
Training loss: 2.7519332852538483
Validation loss: 2.920502331945313

Epoch: 5| Step: 3
Training loss: 3.293573688225376
Validation loss: 2.912259556795672

Epoch: 5| Step: 4
Training loss: 3.1983909793633045
Validation loss: 2.893725197017173

Epoch: 5| Step: 5
Training loss: 3.3206275700696164
Validation loss: 2.8886057072285887

Epoch: 5| Step: 6
Training loss: 2.8541027720926575
Validation loss: 2.8801803161745454

Epoch: 5| Step: 7
Training loss: 3.396023017562665
Validation loss: 2.8653968230209106

Epoch: 5| Step: 8
Training loss: 2.8740355491058933
Validation loss: 2.8551288602939056

Epoch: 5| Step: 9
Training loss: 3.499160938505054
Validation loss: 2.8545427936087404

Epoch: 5| Step: 10
Training loss: 2.601574505385916
Validation loss: 2.8392868203409565

Epoch: 26| Step: 0
Training loss: 2.982101293295404
Validation loss: 2.828650463408598

Epoch: 5| Step: 1
Training loss: 3.100089311851366
Validation loss: 2.814069875386014

Epoch: 5| Step: 2
Training loss: 2.0800841998517514
Validation loss: 2.809036233034249

Epoch: 5| Step: 3
Training loss: 2.775445603343568
Validation loss: 2.8085863600875607

Epoch: 5| Step: 4
Training loss: 2.9054674304980703
Validation loss: 2.80033301337616

Epoch: 5| Step: 5
Training loss: 3.7901171917272385
Validation loss: 2.7985194657132157

Epoch: 5| Step: 6
Training loss: 2.6403285655831965
Validation loss: 2.7891032872386368

Epoch: 5| Step: 7
Training loss: 2.7852077827126833
Validation loss: 2.7901478408363434

Epoch: 5| Step: 8
Training loss: 3.1333179399098707
Validation loss: 2.7757562650191026

Epoch: 5| Step: 9
Training loss: 3.090506192075077
Validation loss: 2.7930098950749915

Epoch: 5| Step: 10
Training loss: 3.74338876958908
Validation loss: 2.755133782391669

Epoch: 27| Step: 0
Training loss: 2.2902506065671826
Validation loss: 2.7670141946108084

Epoch: 5| Step: 1
Training loss: 3.1990364591018023
Validation loss: 2.7699878823620305

Epoch: 5| Step: 2
Training loss: 3.591789573342565
Validation loss: 2.7720093625793703

Epoch: 5| Step: 3
Training loss: 3.4930634562759253
Validation loss: 2.763761216464684

Epoch: 5| Step: 4
Training loss: 2.378364889750437
Validation loss: 2.7528713548851704

Epoch: 5| Step: 5
Training loss: 2.727322972441713
Validation loss: 2.761406873941152

Epoch: 5| Step: 6
Training loss: 3.133319918285898
Validation loss: 2.746877853786109

Epoch: 5| Step: 7
Training loss: 2.3631284049553645
Validation loss: 2.74125521616078

Epoch: 5| Step: 8
Training loss: 2.693775479579006
Validation loss: 2.749043370053336

Epoch: 5| Step: 9
Training loss: 3.5487161974558417
Validation loss: 2.75197307173305

Epoch: 5| Step: 10
Training loss: 3.215253097040316
Validation loss: 2.7397931297507983

Epoch: 28| Step: 0
Training loss: 2.0786942010800926
Validation loss: 2.7476252037233486

Epoch: 5| Step: 1
Training loss: 3.8198864783150763
Validation loss: 2.753119175458185

Epoch: 5| Step: 2
Training loss: 2.258996145055149
Validation loss: 2.7351681366764367

Epoch: 5| Step: 3
Training loss: 2.794686937354491
Validation loss: 2.7530465222251936

Epoch: 5| Step: 4
Training loss: 2.8150674756976453
Validation loss: 2.751508894508572

Epoch: 5| Step: 5
Training loss: 3.364870198936131
Validation loss: 2.741152496727894

Epoch: 5| Step: 6
Training loss: 2.6527519080568887
Validation loss: 2.742266489494666

Epoch: 5| Step: 7
Training loss: 3.5485901571718115
Validation loss: 2.7478389041939435

Epoch: 5| Step: 8
Training loss: 2.6253651864479988
Validation loss: 2.7484797482770777

Epoch: 5| Step: 9
Training loss: 2.9428493409708123
Validation loss: 2.7357559977942807

Epoch: 5| Step: 10
Training loss: 3.549969638103616
Validation loss: 2.724629828651621

Epoch: 29| Step: 0
Training loss: 3.34342455839966
Validation loss: 2.725609194263635

Epoch: 5| Step: 1
Training loss: 2.3853535095471767
Validation loss: 2.723762542973275

Epoch: 5| Step: 2
Training loss: 3.0625507584082827
Validation loss: 2.747348379590295

Epoch: 5| Step: 3
Training loss: 3.2185517777821517
Validation loss: 2.7377286918780492

Epoch: 5| Step: 4
Training loss: 2.187977765906583
Validation loss: 2.741679483867415

Epoch: 5| Step: 5
Training loss: 2.269535557123979
Validation loss: 2.750270186992207

Epoch: 5| Step: 6
Training loss: 3.5244334096950958
Validation loss: 2.7323867005245916

Epoch: 5| Step: 7
Training loss: 3.800855520214742
Validation loss: 2.7392940283484775

Epoch: 5| Step: 8
Training loss: 2.9078997779797042
Validation loss: 2.731165805561862

Epoch: 5| Step: 9
Training loss: 2.3549327335348407
Validation loss: 2.7398543654043315

Epoch: 5| Step: 10
Training loss: 3.2063970461433953
Validation loss: 2.7278353097335484

Epoch: 30| Step: 0
Training loss: 3.470778688242566
Validation loss: 2.746033824191588

Epoch: 5| Step: 1
Training loss: 2.280446995536332
Validation loss: 2.721264246268363

Epoch: 5| Step: 2
Training loss: 3.212193895295189
Validation loss: 2.7324684671129207

Epoch: 5| Step: 3
Training loss: 3.3731930452007086
Validation loss: 2.718809321172053

Epoch: 5| Step: 4
Training loss: 2.828765122275866
Validation loss: 2.725082938618089

Epoch: 5| Step: 5
Training loss: 2.9281467302588817
Validation loss: 2.7380921115346575

Epoch: 5| Step: 6
Training loss: 2.6700845709276253
Validation loss: 2.7237248772521685

Epoch: 5| Step: 7
Training loss: 3.0400208675772564
Validation loss: 2.7321886707547214

Epoch: 5| Step: 8
Training loss: 2.7717475147884745
Validation loss: 2.7379427247070187

Epoch: 5| Step: 9
Training loss: 2.9462074923453136
Validation loss: 2.7392202681286544

Epoch: 5| Step: 10
Training loss: 3.1077120373935614
Validation loss: 2.7230770390715766

Epoch: 31| Step: 0
Training loss: 3.4549735114356057
Validation loss: 2.737213664865165

Epoch: 5| Step: 1
Training loss: 2.032495322321803
Validation loss: 2.7317553387920235

Epoch: 5| Step: 2
Training loss: 3.093340143355185
Validation loss: 2.724998534481501

Epoch: 5| Step: 3
Training loss: 3.0259582893234973
Validation loss: 2.739349367096951

Epoch: 5| Step: 4
Training loss: 3.3741586837491977
Validation loss: 2.7314936425699385

Epoch: 5| Step: 5
Training loss: 3.080684623922935
Validation loss: 2.7231277996947543

Epoch: 5| Step: 6
Training loss: 3.0583251211556783
Validation loss: 2.7195464238209244

Epoch: 5| Step: 7
Training loss: 2.9144507755422944
Validation loss: 2.720070327498659

Epoch: 5| Step: 8
Training loss: 3.3767212611081368
Validation loss: 2.727812895227752

Epoch: 5| Step: 9
Training loss: 2.416548254685621
Validation loss: 2.7326874863097155

Epoch: 5| Step: 10
Training loss: 2.459139987908996
Validation loss: 2.738618654115926

Epoch: 32| Step: 0
Training loss: 3.664997949326424
Validation loss: 2.7456299000244013

Epoch: 5| Step: 1
Training loss: 2.7345070071372133
Validation loss: 2.7359488209574025

Epoch: 5| Step: 2
Training loss: 2.7666794657889913
Validation loss: 2.7302591491420505

Epoch: 5| Step: 3
Training loss: 2.0178526168174478
Validation loss: 2.7258404436981563

Epoch: 5| Step: 4
Training loss: 3.7013277609817083
Validation loss: 2.724940693399859

Epoch: 5| Step: 5
Training loss: 2.812246777473209
Validation loss: 2.7317464084007046

Epoch: 5| Step: 6
Training loss: 2.531219859002646
Validation loss: 2.7399917457817917

Epoch: 5| Step: 7
Training loss: 2.96233324957797
Validation loss: 2.7230783928762117

Epoch: 5| Step: 8
Training loss: 2.2340708705688193
Validation loss: 2.728747620232451

Epoch: 5| Step: 9
Training loss: 2.880959346782335
Validation loss: 2.7160368306717677

Epoch: 5| Step: 10
Training loss: 4.0000641340836305
Validation loss: 2.7332761857846446

Epoch: 33| Step: 0
Training loss: 3.4215140653145806
Validation loss: 2.717022911246468

Epoch: 5| Step: 1
Training loss: 3.11774150925478
Validation loss: 2.7260993328826824

Epoch: 5| Step: 2
Training loss: 3.1263603301410083
Validation loss: 2.7201251440828873

Epoch: 5| Step: 3
Training loss: 2.4988228887753876
Validation loss: 2.71829959739228

Epoch: 5| Step: 4
Training loss: 3.23786715631198
Validation loss: 2.7355013888533963

Epoch: 5| Step: 5
Training loss: 2.657334588717432
Validation loss: 2.7301475123156926

Epoch: 5| Step: 6
Training loss: 2.886670185759457
Validation loss: 2.7189751516391274

Epoch: 5| Step: 7
Training loss: 2.920645388779595
Validation loss: 2.732857996191944

Epoch: 5| Step: 8
Training loss: 2.4875580172266543
Validation loss: 2.7259385262078664

Epoch: 5| Step: 9
Training loss: 3.3390055714503917
Validation loss: 2.7262034799363177

Epoch: 5| Step: 10
Training loss: 2.62322774733573
Validation loss: 2.7223511136156926

Epoch: 34| Step: 0
Training loss: 2.8699704833955213
Validation loss: 2.7320601642672195

Epoch: 5| Step: 1
Training loss: 2.6143946079263913
Validation loss: 2.7324357044776826

Epoch: 5| Step: 2
Training loss: 2.705701096615229
Validation loss: 2.730947785179522

Epoch: 5| Step: 3
Training loss: 3.0725709020195144
Validation loss: 2.7126361116219675

Epoch: 5| Step: 4
Training loss: 3.0086171052472475
Validation loss: 2.706063333203715

Epoch: 5| Step: 5
Training loss: 2.8087696344005963
Validation loss: 2.7322034800652664

Epoch: 5| Step: 6
Training loss: 3.2676528402246947
Validation loss: 2.7164119652648555

Epoch: 5| Step: 7
Training loss: 2.88448758551349
Validation loss: 2.7097865336994733

Epoch: 5| Step: 8
Training loss: 3.39043035695634
Validation loss: 2.7218183092304367

Epoch: 5| Step: 9
Training loss: 3.0425973452539985
Validation loss: 2.718484788518453

Epoch: 5| Step: 10
Training loss: 2.7306078437446084
Validation loss: 2.728605995428968

Epoch: 35| Step: 0
Training loss: 3.0615418161330332
Validation loss: 2.7253819314546157

Epoch: 5| Step: 1
Training loss: 2.7631634463586705
Validation loss: 2.717517189024119

Epoch: 5| Step: 2
Training loss: 2.523137030413363
Validation loss: 2.7248098344878677

Epoch: 5| Step: 3
Training loss: 3.166498598022247
Validation loss: 2.720255339645602

Epoch: 5| Step: 4
Training loss: 2.9651309792727814
Validation loss: 2.724723804517483

Epoch: 5| Step: 5
Training loss: 2.7075241542876447
Validation loss: 2.7163049842005744

Epoch: 5| Step: 6
Training loss: 2.9238305712978243
Validation loss: 2.7040619600004896

Epoch: 5| Step: 7
Training loss: 3.0040451434384132
Validation loss: 2.7218907552573732

Epoch: 5| Step: 8
Training loss: 3.0460718906006665
Validation loss: 2.71594186610307

Epoch: 5| Step: 9
Training loss: 3.2899667398458594
Validation loss: 2.7109466332240415

Epoch: 5| Step: 10
Training loss: 2.815717171061122
Validation loss: 2.7188178211805694

Epoch: 36| Step: 0
Training loss: 2.957073337351163
Validation loss: 2.708177702780926

Epoch: 5| Step: 1
Training loss: 2.815382264710736
Validation loss: 2.715180617477545

Epoch: 5| Step: 2
Training loss: 3.532409072645232
Validation loss: 2.700223162872983

Epoch: 5| Step: 3
Training loss: 2.862551399669021
Validation loss: 2.7009771879539417

Epoch: 5| Step: 4
Training loss: 2.948257875858806
Validation loss: 2.705244547003142

Epoch: 5| Step: 5
Training loss: 2.27105294195202
Validation loss: 2.7088771379818164

Epoch: 5| Step: 6
Training loss: 3.085594756975138
Validation loss: 2.7084475312558887

Epoch: 5| Step: 7
Training loss: 2.3174779770348946
Validation loss: 2.7077935248010454

Epoch: 5| Step: 8
Training loss: 3.0193013132050726
Validation loss: 2.7195268501062584

Epoch: 5| Step: 9
Training loss: 3.613257759636481
Validation loss: 2.7182466019465292

Epoch: 5| Step: 10
Training loss: 2.5801839294224083
Validation loss: 2.705543824783648

Epoch: 37| Step: 0
Training loss: 3.40594061050112
Validation loss: 2.703634228938077

Epoch: 5| Step: 1
Training loss: 3.4283085790422607
Validation loss: 2.7218147959960266

Epoch: 5| Step: 2
Training loss: 2.9650846642279944
Validation loss: 2.720986268464137

Epoch: 5| Step: 3
Training loss: 3.152973702981345
Validation loss: 2.7184681362623206

Epoch: 5| Step: 4
Training loss: 3.0288542098798734
Validation loss: 2.6994155036353686

Epoch: 5| Step: 5
Training loss: 2.5464753381481295
Validation loss: 2.71160581650925

Epoch: 5| Step: 6
Training loss: 2.8177971864089386
Validation loss: 2.7156209377835854

Epoch: 5| Step: 7
Training loss: 2.6775343894709023
Validation loss: 2.724712575080582

Epoch: 5| Step: 8
Training loss: 2.517602084380997
Validation loss: 2.7010857157256662

Epoch: 5| Step: 9
Training loss: 2.1267096430024592
Validation loss: 2.7107219836747185

Epoch: 5| Step: 10
Training loss: 3.445188213018284
Validation loss: 2.7027800538653284

Epoch: 38| Step: 0
Training loss: 3.0135745652731782
Validation loss: 2.7033956661189484

Epoch: 5| Step: 1
Training loss: 2.4481229871011676
Validation loss: 2.6966630578735318

Epoch: 5| Step: 2
Training loss: 2.896184081281094
Validation loss: 2.7074703173059014

Epoch: 5| Step: 3
Training loss: 2.7948492801816496
Validation loss: 2.714049223901972

Epoch: 5| Step: 4
Training loss: 2.785329762493795
Validation loss: 2.7013295930711148

Epoch: 5| Step: 5
Training loss: 2.955897891344553
Validation loss: 2.695031953858466

Epoch: 5| Step: 6
Training loss: 2.5953443292162266
Validation loss: 2.685478944338797

Epoch: 5| Step: 7
Training loss: 3.773744179720211
Validation loss: 2.698260566938881

Epoch: 5| Step: 8
Training loss: 2.4950813544699466
Validation loss: 2.6877833696581397

Epoch: 5| Step: 9
Training loss: 3.086192446450532
Validation loss: 2.6935259623629033

Epoch: 5| Step: 10
Training loss: 3.199280455277179
Validation loss: 2.7076730899921566

Epoch: 39| Step: 0
Training loss: 3.2227445833064334
Validation loss: 2.718026792607085

Epoch: 5| Step: 1
Training loss: 3.541288437935998
Validation loss: 2.702445291928442

Epoch: 5| Step: 2
Training loss: 2.5322790997370026
Validation loss: 2.695742504362793

Epoch: 5| Step: 3
Training loss: 2.872880569094759
Validation loss: 2.705142677774555

Epoch: 5| Step: 4
Training loss: 2.5142066700852426
Validation loss: 2.6978404964429363

Epoch: 5| Step: 5
Training loss: 2.9151162704390066
Validation loss: 2.7010080789112476

Epoch: 5| Step: 6
Training loss: 3.0971285164822304
Validation loss: 2.704404970910556

Epoch: 5| Step: 7
Training loss: 3.0481326906452537
Validation loss: 2.706992482089755

Epoch: 5| Step: 8
Training loss: 2.3043718542124605
Validation loss: 2.708209294459649

Epoch: 5| Step: 9
Training loss: 2.5796926645080513
Validation loss: 2.7018602978516895

Epoch: 5| Step: 10
Training loss: 3.3469731848069673
Validation loss: 2.6970476759247695

Epoch: 40| Step: 0
Training loss: 3.4070358069900446
Validation loss: 2.6938306951464424

Epoch: 5| Step: 1
Training loss: 3.404366488683323
Validation loss: 2.7005985955379908

Epoch: 5| Step: 2
Training loss: 2.8664435063225935
Validation loss: 2.7011267893087725

Epoch: 5| Step: 3
Training loss: 3.0727610058341033
Validation loss: 2.7024402186109433

Epoch: 5| Step: 4
Training loss: 2.669056884130857
Validation loss: 2.693564561471462

Epoch: 5| Step: 5
Training loss: 2.7317912074015065
Validation loss: 2.7049845555702587

Epoch: 5| Step: 6
Training loss: 2.7332440462493324
Validation loss: 2.712613511038982

Epoch: 5| Step: 7
Training loss: 2.9007736621020808
Validation loss: 2.6997528732548255

Epoch: 5| Step: 8
Training loss: 2.8419111405829067
Validation loss: 2.706672782870833

Epoch: 5| Step: 9
Training loss: 2.592298998052963
Validation loss: 2.7029589074974294

Epoch: 5| Step: 10
Training loss: 2.8894053592526827
Validation loss: 2.7031319821033004

Epoch: 41| Step: 0
Training loss: 3.3553002063134834
Validation loss: 2.696909575682193

Epoch: 5| Step: 1
Training loss: 2.953379140746921
Validation loss: 2.685822157010059

Epoch: 5| Step: 2
Training loss: 2.501413803875519
Validation loss: 2.7009013059012523

Epoch: 5| Step: 3
Training loss: 2.840328128019172
Validation loss: 2.7001186413147136

Epoch: 5| Step: 4
Training loss: 2.5405664303493074
Validation loss: 2.7069753433825903

Epoch: 5| Step: 5
Training loss: 2.802424716125445
Validation loss: 2.6845144012823794

Epoch: 5| Step: 6
Training loss: 2.4285475825894123
Validation loss: 2.699634094845401

Epoch: 5| Step: 7
Training loss: 2.3449749606489525
Validation loss: 2.6850246334376227

Epoch: 5| Step: 8
Training loss: 3.0210699229932194
Validation loss: 2.6823626229999884

Epoch: 5| Step: 9
Training loss: 3.275590357095954
Validation loss: 2.6882517021640875

Epoch: 5| Step: 10
Training loss: 3.777435270066644
Validation loss: 2.6944247597706665

Epoch: 42| Step: 0
Training loss: 3.1353162240365853
Validation loss: 2.6851139785428733

Epoch: 5| Step: 1
Training loss: 3.1192369344672626
Validation loss: 2.695267769048678

Epoch: 5| Step: 2
Training loss: 3.0481231480448705
Validation loss: 2.67684553247399

Epoch: 5| Step: 3
Training loss: 2.6685794784778065
Validation loss: 2.682811782130358

Epoch: 5| Step: 4
Training loss: 2.8229959249220435
Validation loss: 2.702709847305425

Epoch: 5| Step: 5
Training loss: 2.6299372970880865
Validation loss: 2.694679307387086

Epoch: 5| Step: 6
Training loss: 3.3159177889969214
Validation loss: 2.6823608778186014

Epoch: 5| Step: 7
Training loss: 2.9248353373811415
Validation loss: 2.689816781505445

Epoch: 5| Step: 8
Training loss: 2.54744765507731
Validation loss: 2.679774465889417

Epoch: 5| Step: 9
Training loss: 3.1876967126321905
Validation loss: 2.7148836206267717

Epoch: 5| Step: 10
Training loss: 2.3160183921175914
Validation loss: 2.6842633608617525

Epoch: 43| Step: 0
Training loss: 2.704946797071579
Validation loss: 2.6874215490667392

Epoch: 5| Step: 1
Training loss: 2.8586221339590763
Validation loss: 2.6919439080503436

Epoch: 5| Step: 2
Training loss: 3.59937105512792
Validation loss: 2.703090487545607

Epoch: 5| Step: 3
Training loss: 2.5781440502965673
Validation loss: 2.6807043664158288

Epoch: 5| Step: 4
Training loss: 2.5940610400380635
Validation loss: 2.6928428793531443

Epoch: 5| Step: 5
Training loss: 2.7479628907298084
Validation loss: 2.6941279141630483

Epoch: 5| Step: 6
Training loss: 3.2441182833366753
Validation loss: 2.6685591898812584

Epoch: 5| Step: 7
Training loss: 2.6152368364614538
Validation loss: 2.6758112878852223

Epoch: 5| Step: 8
Training loss: 2.7464669680759273
Validation loss: 2.6906362512300928

Epoch: 5| Step: 9
Training loss: 2.8551880245792365
Validation loss: 2.679690372950186

Epoch: 5| Step: 10
Training loss: 3.2515679025307263
Validation loss: 2.6795463705423797

Epoch: 44| Step: 0
Training loss: 3.6695593491944973
Validation loss: 2.688510033422176

Epoch: 5| Step: 1
Training loss: 2.745256928612595
Validation loss: 2.670260478117892

Epoch: 5| Step: 2
Training loss: 1.9702630057232973
Validation loss: 2.6725599870158074

Epoch: 5| Step: 3
Training loss: 3.1844937977142718
Validation loss: 2.676540421372444

Epoch: 5| Step: 4
Training loss: 3.022704200630501
Validation loss: 2.679554196699077

Epoch: 5| Step: 5
Training loss: 2.7738870605602624
Validation loss: 2.685506313461404

Epoch: 5| Step: 6
Training loss: 2.996747319879763
Validation loss: 2.6921643690927786

Epoch: 5| Step: 7
Training loss: 3.502178876315981
Validation loss: 2.6918403611987474

Epoch: 5| Step: 8
Training loss: 2.3246750840425867
Validation loss: 2.6545316346104957

Epoch: 5| Step: 9
Training loss: 2.5429570304729467
Validation loss: 2.684203350239525

Epoch: 5| Step: 10
Training loss: 2.5239537894889894
Validation loss: 2.681534658276814

Epoch: 45| Step: 0
Training loss: 2.329569221426093
Validation loss: 2.6704179693414614

Epoch: 5| Step: 1
Training loss: 2.4352908760872003
Validation loss: 2.652551939110169

Epoch: 5| Step: 2
Training loss: 3.4328873637895287
Validation loss: 2.6563276044305453

Epoch: 5| Step: 3
Training loss: 3.253833710410297
Validation loss: 2.6764244385011207

Epoch: 5| Step: 4
Training loss: 2.2889533423738575
Validation loss: 2.6661239412704787

Epoch: 5| Step: 5
Training loss: 3.049869884779827
Validation loss: 2.6577477775157448

Epoch: 5| Step: 6
Training loss: 2.9222937299184863
Validation loss: 2.676000028689844

Epoch: 5| Step: 7
Training loss: 3.0005951926767698
Validation loss: 2.6778245597783976

Epoch: 5| Step: 8
Training loss: 3.527781445625648
Validation loss: 2.6840369063481817

Epoch: 5| Step: 9
Training loss: 2.936961510182331
Validation loss: 2.666301287594449

Epoch: 5| Step: 10
Training loss: 2.0262611747494743
Validation loss: 2.6926571214419974

Epoch: 46| Step: 0
Training loss: 3.1772541604731814
Validation loss: 2.6611323163672838

Epoch: 5| Step: 1
Training loss: 2.9962180458755294
Validation loss: 2.6814022174078698

Epoch: 5| Step: 2
Training loss: 2.0777540521179425
Validation loss: 2.6681219825755145

Epoch: 5| Step: 3
Training loss: 3.0284151015074823
Validation loss: 2.6585074418999928

Epoch: 5| Step: 4
Training loss: 2.6655067265557526
Validation loss: 2.6668531922381207

Epoch: 5| Step: 5
Training loss: 2.1875764016024446
Validation loss: 2.6669942051585758

Epoch: 5| Step: 6
Training loss: 2.3015708410418805
Validation loss: 2.6794125358981375

Epoch: 5| Step: 7
Training loss: 2.8824480855060006
Validation loss: 2.6700187231232886

Epoch: 5| Step: 8
Training loss: 3.1081687849601702
Validation loss: 2.6777021547462567

Epoch: 5| Step: 9
Training loss: 2.993199110214874
Validation loss: 2.6688745559360294

Epoch: 5| Step: 10
Training loss: 3.789344258008328
Validation loss: 2.6682305505802737

Epoch: 47| Step: 0
Training loss: 3.1427896356144465
Validation loss: 2.661649722904914

Epoch: 5| Step: 1
Training loss: 3.625282013545205
Validation loss: 2.7022019089963294

Epoch: 5| Step: 2
Training loss: 2.7112365030082013
Validation loss: 2.669465992073763

Epoch: 5| Step: 3
Training loss: 2.2534378067416325
Validation loss: 2.648831377558327

Epoch: 5| Step: 4
Training loss: 2.5971659950611743
Validation loss: 2.660713310341018

Epoch: 5| Step: 5
Training loss: 2.935362017528706
Validation loss: 2.6623617431849316

Epoch: 5| Step: 6
Training loss: 3.05638165336647
Validation loss: 2.654489446012703

Epoch: 5| Step: 7
Training loss: 3.117578926463921
Validation loss: 2.6557754536668794

Epoch: 5| Step: 8
Training loss: 2.420357998148803
Validation loss: 2.641357691088768

Epoch: 5| Step: 9
Training loss: 2.564008594343805
Validation loss: 2.64249385343484

Epoch: 5| Step: 10
Training loss: 2.986986864784562
Validation loss: 2.657227790665419

Epoch: 48| Step: 0
Training loss: 2.7046715165695674
Validation loss: 2.668311361432607

Epoch: 5| Step: 1
Training loss: 3.0857580977816297
Validation loss: 2.6399626600521597

Epoch: 5| Step: 2
Training loss: 2.247387747162512
Validation loss: 2.626350049315749

Epoch: 5| Step: 3
Training loss: 3.1454127622145474
Validation loss: 2.6431460083123595

Epoch: 5| Step: 4
Training loss: 2.9483720587183124
Validation loss: 2.6536090290405467

Epoch: 5| Step: 5
Training loss: 2.7558451002631275
Validation loss: 2.6770578827447618

Epoch: 5| Step: 6
Training loss: 3.076441580438602
Validation loss: 2.6633118704566927

Epoch: 5| Step: 7
Training loss: 2.8273994821882993
Validation loss: 2.6677780966069853

Epoch: 5| Step: 8
Training loss: 3.0792945150453184
Validation loss: 2.668350151386502

Epoch: 5| Step: 9
Training loss: 2.8548539904989663
Validation loss: 2.6729387680652943

Epoch: 5| Step: 10
Training loss: 2.8464347825612504
Validation loss: 2.6567753484023275

Epoch: 49| Step: 0
Training loss: 2.957420333601913
Validation loss: 2.662810746085425

Epoch: 5| Step: 1
Training loss: 3.1576065320960502
Validation loss: 2.6621972771936546

Epoch: 5| Step: 2
Training loss: 2.72187993326189
Validation loss: 2.6580226708824055

Epoch: 5| Step: 3
Training loss: 2.983586232070261
Validation loss: 2.650899739721964

Epoch: 5| Step: 4
Training loss: 3.098802544447235
Validation loss: 2.6498443702928105

Epoch: 5| Step: 5
Training loss: 2.6236266221929223
Validation loss: 2.665973295031777

Epoch: 5| Step: 6
Training loss: 2.2269756803790552
Validation loss: 2.6735096351839323

Epoch: 5| Step: 7
Training loss: 3.0951112777105663
Validation loss: 2.649838959236646

Epoch: 5| Step: 8
Training loss: 2.9773462420142582
Validation loss: 2.661551845916004

Epoch: 5| Step: 9
Training loss: 2.4458009274711725
Validation loss: 2.654132357441105

Epoch: 5| Step: 10
Training loss: 3.0667209731006615
Validation loss: 2.670253349578454

Epoch: 50| Step: 0
Training loss: 3.6895752579126597
Validation loss: 2.6529022643155504

Epoch: 5| Step: 1
Training loss: 2.7534885820242456
Validation loss: 2.654336303417126

Epoch: 5| Step: 2
Training loss: 2.575705207625546
Validation loss: 2.6411697477239438

Epoch: 5| Step: 3
Training loss: 2.560913525248611
Validation loss: 2.6415351706329204

Epoch: 5| Step: 4
Training loss: 2.813244360862266
Validation loss: 2.6445887907689856

Epoch: 5| Step: 5
Training loss: 3.132554041220517
Validation loss: 2.669792231377324

Epoch: 5| Step: 6
Training loss: 3.354561839706279
Validation loss: 2.6581231883001397

Epoch: 5| Step: 7
Training loss: 2.0838807213415094
Validation loss: 2.6548729431786455

Epoch: 5| Step: 8
Training loss: 2.679186092877793
Validation loss: 2.6622642804440253

Epoch: 5| Step: 9
Training loss: 2.6396448246136948
Validation loss: 2.6677906208308015

Epoch: 5| Step: 10
Training loss: 2.8253185193926273
Validation loss: 2.6419465831232105

Epoch: 51| Step: 0
Training loss: 2.351330615805748
Validation loss: 2.6433779215704205

Epoch: 5| Step: 1
Training loss: 2.855811895581846
Validation loss: 2.6438743645645464

Epoch: 5| Step: 2
Training loss: 3.5585449751391214
Validation loss: 2.6475742588619195

Epoch: 5| Step: 3
Training loss: 2.534375180621911
Validation loss: 2.649052861012452

Epoch: 5| Step: 4
Training loss: 3.1228656346429142
Validation loss: 2.6367483413111397

Epoch: 5| Step: 5
Training loss: 2.9525536685881857
Validation loss: 2.6315457922239887

Epoch: 5| Step: 6
Training loss: 2.854406156493078
Validation loss: 2.6563630496825845

Epoch: 5| Step: 7
Training loss: 2.8879510832683066
Validation loss: 2.662926657141507

Epoch: 5| Step: 8
Training loss: 2.726840729166933
Validation loss: 2.653515443135712

Epoch: 5| Step: 9
Training loss: 2.3676942591340477
Validation loss: 2.6364159768510946

Epoch: 5| Step: 10
Training loss: 2.8960125179336362
Validation loss: 2.6551238334665235

Epoch: 52| Step: 0
Training loss: 3.141225121699773
Validation loss: 2.6640079252004503

Epoch: 5| Step: 1
Training loss: 2.517380475083047
Validation loss: 2.644760381954318

Epoch: 5| Step: 2
Training loss: 3.3400216395425204
Validation loss: 2.651540192513921

Epoch: 5| Step: 3
Training loss: 2.384318291825955
Validation loss: 2.6577933376705865

Epoch: 5| Step: 4
Training loss: 3.5702714980294026
Validation loss: 2.6394491027049516

Epoch: 5| Step: 5
Training loss: 2.642632438062046
Validation loss: 2.652585496079274

Epoch: 5| Step: 6
Training loss: 2.5014743272347317
Validation loss: 2.6443405839987006

Epoch: 5| Step: 7
Training loss: 3.210850326951183
Validation loss: 2.659140633621244

Epoch: 5| Step: 8
Training loss: 2.7115662475011377
Validation loss: 2.6595745541180484

Epoch: 5| Step: 9
Training loss: 2.1676393550791015
Validation loss: 2.6438184683280954

Epoch: 5| Step: 10
Training loss: 2.8524543099250446
Validation loss: 2.6286040282016123

Epoch: 53| Step: 0
Training loss: 2.6421599131203704
Validation loss: 2.6347423194765436

Epoch: 5| Step: 1
Training loss: 3.1485473007858156
Validation loss: 2.6520474838234893

Epoch: 5| Step: 2
Training loss: 2.774799023472962
Validation loss: 2.634374195828081

Epoch: 5| Step: 3
Training loss: 2.6182733361428
Validation loss: 2.6369374640938537

Epoch: 5| Step: 4
Training loss: 2.8958572459891645
Validation loss: 2.6583430788402413

Epoch: 5| Step: 5
Training loss: 3.129898504494595
Validation loss: 2.6449538770040726

Epoch: 5| Step: 6
Training loss: 3.2333572924273564
Validation loss: 2.6407888718049732

Epoch: 5| Step: 7
Training loss: 3.1572125166425113
Validation loss: 2.637625570165256

Epoch: 5| Step: 8
Training loss: 2.1325938353739105
Validation loss: 2.6374610935722775

Epoch: 5| Step: 9
Training loss: 2.5755556192289264
Validation loss: 2.6326015150893127

Epoch: 5| Step: 10
Training loss: 2.631635997304405
Validation loss: 2.6428436339212023

Epoch: 54| Step: 0
Training loss: 2.5765506445691186
Validation loss: 2.620252395329837

Epoch: 5| Step: 1
Training loss: 3.3100124591696627
Validation loss: 2.629176284200143

Epoch: 5| Step: 2
Training loss: 3.3831079367237806
Validation loss: 2.634892958139722

Epoch: 5| Step: 3
Training loss: 1.9918061134436844
Validation loss: 2.6395467114934466

Epoch: 5| Step: 4
Training loss: 2.9689838518093503
Validation loss: 2.629820495946516

Epoch: 5| Step: 5
Training loss: 2.934351755848433
Validation loss: 2.6432458296417853

Epoch: 5| Step: 6
Training loss: 2.514809802164858
Validation loss: 2.6557945309754816

Epoch: 5| Step: 7
Training loss: 2.3574043785273977
Validation loss: 2.663657125126039

Epoch: 5| Step: 8
Training loss: 3.335537960238482
Validation loss: 2.6186068500693924

Epoch: 5| Step: 9
Training loss: 3.1123233791013867
Validation loss: 2.6282209762316753

Epoch: 5| Step: 10
Training loss: 2.264205487924325
Validation loss: 2.645877432429431

Epoch: 55| Step: 0
Training loss: 2.6778132609983856
Validation loss: 2.641714233666845

Epoch: 5| Step: 1
Training loss: 2.1760790636480922
Validation loss: 2.644418218009301

Epoch: 5| Step: 2
Training loss: 1.9753775078894507
Validation loss: 2.624306145147338

Epoch: 5| Step: 3
Training loss: 2.771481794231092
Validation loss: 2.6237471335454035

Epoch: 5| Step: 4
Training loss: 3.10973352253481
Validation loss: 2.657400303193401

Epoch: 5| Step: 5
Training loss: 2.9609262269945367
Validation loss: 2.6229260138197903

Epoch: 5| Step: 6
Training loss: 3.248587081129524
Validation loss: 2.6438424113970673

Epoch: 5| Step: 7
Training loss: 3.1694865136377905
Validation loss: 2.6496934031940853

Epoch: 5| Step: 8
Training loss: 3.428544881695198
Validation loss: 2.6640082812605668

Epoch: 5| Step: 9
Training loss: 2.9211759496010905
Validation loss: 2.6187909688252757

Epoch: 5| Step: 10
Training loss: 2.3107133097613923
Validation loss: 2.6520636000080864

Epoch: 56| Step: 0
Training loss: 2.732527539253191
Validation loss: 2.619874635405734

Epoch: 5| Step: 1
Training loss: 2.570268439289193
Validation loss: 2.6254033131902537

Epoch: 5| Step: 2
Training loss: 2.5601861322805
Validation loss: 2.6374701410331727

Epoch: 5| Step: 3
Training loss: 3.5100597498228803
Validation loss: 2.6261349849998825

Epoch: 5| Step: 4
Training loss: 2.9367921666301937
Validation loss: 2.5974125183622765

Epoch: 5| Step: 5
Training loss: 2.5648854015546014
Validation loss: 2.6232132961854124

Epoch: 5| Step: 6
Training loss: 2.9383016263564112
Validation loss: 2.6195264776782206

Epoch: 5| Step: 7
Training loss: 2.8746586472582853
Validation loss: 2.637903015274098

Epoch: 5| Step: 8
Training loss: 2.7938074946621185
Validation loss: 2.605340765980321

Epoch: 5| Step: 9
Training loss: 2.968663425187075
Validation loss: 2.6370226238832193

Epoch: 5| Step: 10
Training loss: 2.7429082635106323
Validation loss: 2.6182877548314556

Epoch: 57| Step: 0
Training loss: 2.820465168294756
Validation loss: 2.617430873104215

Epoch: 5| Step: 1
Training loss: 2.325275802661087
Validation loss: 2.6377615745627363

Epoch: 5| Step: 2
Training loss: 2.7737136918210497
Validation loss: 2.6205866004398506

Epoch: 5| Step: 3
Training loss: 3.256740622433958
Validation loss: 2.6423055154715662

Epoch: 5| Step: 4
Training loss: 3.0257061473017064
Validation loss: 2.6224661970590133

Epoch: 5| Step: 5
Training loss: 2.146240887008809
Validation loss: 2.6248180328286974

Epoch: 5| Step: 6
Training loss: 2.9737086594904216
Validation loss: 2.645211179987121

Epoch: 5| Step: 7
Training loss: 2.907954218801847
Validation loss: 2.6344673119641904

Epoch: 5| Step: 8
Training loss: 2.6693258338782226
Validation loss: 2.656715821277086

Epoch: 5| Step: 9
Training loss: 3.0095373187155694
Validation loss: 2.614367920141983

Epoch: 5| Step: 10
Training loss: 2.8122106615221862
Validation loss: 2.630233602403436

Epoch: 58| Step: 0
Training loss: 3.015936326475412
Validation loss: 2.6379274639396577

Epoch: 5| Step: 1
Training loss: 2.460310986408285
Validation loss: 2.636384604248793

Epoch: 5| Step: 2
Training loss: 2.902780574409886
Validation loss: 2.652305686723838

Epoch: 5| Step: 3
Training loss: 2.461231807488452
Validation loss: 2.6304237296206736

Epoch: 5| Step: 4
Training loss: 2.1652775737617445
Validation loss: 2.6183962831217027

Epoch: 5| Step: 5
Training loss: 2.428278769161753
Validation loss: 2.613551728370115

Epoch: 5| Step: 6
Training loss: 2.6906251701328343
Validation loss: 2.6205481541560998

Epoch: 5| Step: 7
Training loss: 3.1911187666952006
Validation loss: 2.6269782918479403

Epoch: 5| Step: 8
Training loss: 3.2418065594166405
Validation loss: 2.615736192222218

Epoch: 5| Step: 9
Training loss: 3.3490196843359006
Validation loss: 2.612554658268047

Epoch: 5| Step: 10
Training loss: 2.778348974204093
Validation loss: 2.637713322199064

Epoch: 59| Step: 0
Training loss: 3.0774746125426815
Validation loss: 2.6608524018450748

Epoch: 5| Step: 1
Training loss: 2.5923862778855953
Validation loss: 2.6143560176317706

Epoch: 5| Step: 2
Training loss: 3.172705029655325
Validation loss: 2.603968362128444

Epoch: 5| Step: 3
Training loss: 2.5198277971679675
Validation loss: 2.6383454284749344

Epoch: 5| Step: 4
Training loss: 2.244211698756209
Validation loss: 2.6140005235676886

Epoch: 5| Step: 5
Training loss: 2.7553719157721837
Validation loss: 2.6547465374638666

Epoch: 5| Step: 6
Training loss: 2.6685960962019535
Validation loss: 2.6198530096794057

Epoch: 5| Step: 7
Training loss: 2.9319992506851134
Validation loss: 2.661045670909102

Epoch: 5| Step: 8
Training loss: 2.420130538257098
Validation loss: 2.6118282354295244

Epoch: 5| Step: 9
Training loss: 2.799463363721143
Validation loss: 2.6463140401901994

Epoch: 5| Step: 10
Training loss: 3.513741493065523
Validation loss: 2.633987263500795

Epoch: 60| Step: 0
Training loss: 2.599528849534659
Validation loss: 2.6275968427239023

Epoch: 5| Step: 1
Training loss: 2.8889363073060124
Validation loss: 2.608916197800273

Epoch: 5| Step: 2
Training loss: 2.7033781252849263
Validation loss: 2.633874829245654

Epoch: 5| Step: 3
Training loss: 2.709437942213757
Validation loss: 2.6233766011803805

Epoch: 5| Step: 4
Training loss: 2.988603562070537
Validation loss: 2.6223453765713014

Epoch: 5| Step: 5
Training loss: 2.9591508371597057
Validation loss: 2.6216072496592493

Epoch: 5| Step: 6
Training loss: 2.356411417888486
Validation loss: 2.594042448578683

Epoch: 5| Step: 7
Training loss: 2.9966999022692034
Validation loss: 2.6198156760144764

Epoch: 5| Step: 8
Training loss: 2.799022851467038
Validation loss: 2.6175701372843894

Epoch: 5| Step: 9
Training loss: 2.789454584851836
Validation loss: 2.6259895330823926

Epoch: 5| Step: 10
Training loss: 2.9284899896336962
Validation loss: 2.6261553646210247

Epoch: 61| Step: 0
Training loss: 2.515726122985728
Validation loss: 2.6206444106539144

Epoch: 5| Step: 1
Training loss: 2.7833948330356986
Validation loss: 2.6172222499410744

Epoch: 5| Step: 2
Training loss: 2.729663910351705
Validation loss: 2.6239463104544614

Epoch: 5| Step: 3
Training loss: 2.5832359746819713
Validation loss: 2.6267072806626124

Epoch: 5| Step: 4
Training loss: 3.2355798513538967
Validation loss: 2.626553071632043

Epoch: 5| Step: 5
Training loss: 3.156860896751003
Validation loss: 2.63444534427966

Epoch: 5| Step: 6
Training loss: 2.609222499023025
Validation loss: 2.6130715106716984

Epoch: 5| Step: 7
Training loss: 3.099517993986153
Validation loss: 2.6296837796055197

Epoch: 5| Step: 8
Training loss: 2.5988442823400018
Validation loss: 2.6480043738123062

Epoch: 5| Step: 9
Training loss: 2.943791247036367
Validation loss: 2.6269308187843956

Epoch: 5| Step: 10
Training loss: 2.324422772853344
Validation loss: 2.5889989040089807

Epoch: 62| Step: 0
Training loss: 2.0413088063204037
Validation loss: 2.6194835041161557

Epoch: 5| Step: 1
Training loss: 2.6751151265121274
Validation loss: 2.6332890098301385

Epoch: 5| Step: 2
Training loss: 3.176904758792046
Validation loss: 2.6444293405265173

Epoch: 5| Step: 3
Training loss: 2.7689306471471866
Validation loss: 2.6171013421349922

Epoch: 5| Step: 4
Training loss: 2.576668160089781
Validation loss: 2.609577352129725

Epoch: 5| Step: 5
Training loss: 3.0650568039874764
Validation loss: 2.632032372611679

Epoch: 5| Step: 6
Training loss: 2.4212785540124466
Validation loss: 2.641537418822182

Epoch: 5| Step: 7
Training loss: 3.0647490670317645
Validation loss: 2.6240997098811136

Epoch: 5| Step: 8
Training loss: 2.771356193906409
Validation loss: 2.6328802568956253

Epoch: 5| Step: 9
Training loss: 2.581270091276512
Validation loss: 2.6154143761250213

Epoch: 5| Step: 10
Training loss: 3.271672540064427
Validation loss: 2.62036444356874

Epoch: 63| Step: 0
Training loss: 2.8166531733654288
Validation loss: 2.623749074048112

Epoch: 5| Step: 1
Training loss: 3.136861339477783
Validation loss: 2.5938815980339944

Epoch: 5| Step: 2
Training loss: 2.8775078160422565
Validation loss: 2.6486319769604414

Epoch: 5| Step: 3
Training loss: 2.380913650106853
Validation loss: 2.6025992544930396

Epoch: 5| Step: 4
Training loss: 2.651034811694283
Validation loss: 2.6263866688020934

Epoch: 5| Step: 5
Training loss: 2.8793742861787224
Validation loss: 2.610652848206587

Epoch: 5| Step: 6
Training loss: 3.160217058235648
Validation loss: 2.6161618143540957

Epoch: 5| Step: 7
Training loss: 2.410363384725079
Validation loss: 2.6189715223093923

Epoch: 5| Step: 8
Training loss: 2.9459758790602617
Validation loss: 2.592051377192128

Epoch: 5| Step: 9
Training loss: 2.5314233037702514
Validation loss: 2.624696041074464

Epoch: 5| Step: 10
Training loss: 2.6218453479495034
Validation loss: 2.616258827024747

Epoch: 64| Step: 0
Training loss: 2.8661771652077612
Validation loss: 2.627710581707185

Epoch: 5| Step: 1
Training loss: 2.096791577562913
Validation loss: 2.5964219057157814

Epoch: 5| Step: 2
Training loss: 3.5355688370682232
Validation loss: 2.6322506599399533

Epoch: 5| Step: 3
Training loss: 3.152373246405914
Validation loss: 2.620752831570347

Epoch: 5| Step: 4
Training loss: 2.9323864521180405
Validation loss: 2.626416371642249

Epoch: 5| Step: 5
Training loss: 1.9699301437152954
Validation loss: 2.6148925495120263

Epoch: 5| Step: 6
Training loss: 2.5393954484225647
Validation loss: 2.610333701868211

Epoch: 5| Step: 7
Training loss: 2.8559503110094684
Validation loss: 2.629474592049259

Epoch: 5| Step: 8
Training loss: 2.3899833466336706
Validation loss: 2.6253247048014394

Epoch: 5| Step: 9
Training loss: 2.5530307075336207
Validation loss: 2.593801842596544

Epoch: 5| Step: 10
Training loss: 3.2990167540153426
Validation loss: 2.611980083708621

Epoch: 65| Step: 0
Training loss: 2.89404276279367
Validation loss: 2.641840846644626

Epoch: 5| Step: 1
Training loss: 2.7417669163920593
Validation loss: 2.6157174701046575

Epoch: 5| Step: 2
Training loss: 2.9304331733335984
Validation loss: 2.6333939124642423

Epoch: 5| Step: 3
Training loss: 2.7447199851320803
Validation loss: 2.618349204226379

Epoch: 5| Step: 4
Training loss: 3.1645181963513913
Validation loss: 2.614313498418187

Epoch: 5| Step: 5
Training loss: 2.9087746432005965
Validation loss: 2.610775332161682

Epoch: 5| Step: 6
Training loss: 2.5851729723613444
Validation loss: 2.625813967895403

Epoch: 5| Step: 7
Training loss: 2.7349042107860546
Validation loss: 2.6408676285501205

Epoch: 5| Step: 8
Training loss: 2.9677446771290703
Validation loss: 2.6159016628650367

Epoch: 5| Step: 9
Training loss: 2.518213586979313
Validation loss: 2.636481210209369

Epoch: 5| Step: 10
Training loss: 2.2851470686247177
Validation loss: 2.617023886187262

Epoch: 66| Step: 0
Training loss: 2.792554875366569
Validation loss: 2.604833840009701

Epoch: 5| Step: 1
Training loss: 3.497120626514276
Validation loss: 2.643036455498214

Epoch: 5| Step: 2
Training loss: 2.800236903114094
Validation loss: 2.601533172648072

Epoch: 5| Step: 3
Training loss: 2.761049008667789
Validation loss: 2.6072635784631157

Epoch: 5| Step: 4
Training loss: 2.9774682776925645
Validation loss: 2.620890238762145

Epoch: 5| Step: 5
Training loss: 2.1041635066345457
Validation loss: 2.6100111425351544

Epoch: 5| Step: 6
Training loss: 2.2733369261003817
Validation loss: 2.6104830199041715

Epoch: 5| Step: 7
Training loss: 2.892175536952737
Validation loss: 2.606210686278031

Epoch: 5| Step: 8
Training loss: 2.77679377823212
Validation loss: 2.629523084315571

Epoch: 5| Step: 9
Training loss: 2.216957120103023
Validation loss: 2.6340636298606706

Epoch: 5| Step: 10
Training loss: 3.1832947760305697
Validation loss: 2.600084554040421

Epoch: 67| Step: 0
Training loss: 2.4135583641277005
Validation loss: 2.600898248677777

Epoch: 5| Step: 1
Training loss: 2.871225948274521
Validation loss: 2.6256411209472916

Epoch: 5| Step: 2
Training loss: 2.1717326165600612
Validation loss: 2.613601750999833

Epoch: 5| Step: 3
Training loss: 3.220821417769631
Validation loss: 2.61944459339912

Epoch: 5| Step: 4
Training loss: 2.6401025379381835
Validation loss: 2.6189256460433405

Epoch: 5| Step: 5
Training loss: 2.7494240070891314
Validation loss: 2.6182565370856197

Epoch: 5| Step: 6
Training loss: 2.8056202137193074
Validation loss: 2.629442063179999

Epoch: 5| Step: 7
Training loss: 3.1937419137273793
Validation loss: 2.624183674347941

Epoch: 5| Step: 8
Training loss: 2.666647454033623
Validation loss: 2.6229853743917992

Epoch: 5| Step: 9
Training loss: 2.8369066668363154
Validation loss: 2.6263874428567098

Epoch: 5| Step: 10
Training loss: 2.7679681711737327
Validation loss: 2.615432072675087

Epoch: 68| Step: 0
Training loss: 2.327992377888108
Validation loss: 2.610758346402921

Epoch: 5| Step: 1
Training loss: 2.6806149671050625
Validation loss: 2.6166933967390804

Epoch: 5| Step: 2
Training loss: 2.6325236085592056
Validation loss: 2.6215220614392267

Epoch: 5| Step: 3
Training loss: 2.492905468497697
Validation loss: 2.6023287046544463

Epoch: 5| Step: 4
Training loss: 3.1734000612771114
Validation loss: 2.6260133624311255

Epoch: 5| Step: 5
Training loss: 2.920453710188205
Validation loss: 2.616648602336759

Epoch: 5| Step: 6
Training loss: 1.7836944805612707
Validation loss: 2.612836461009892

Epoch: 5| Step: 7
Training loss: 3.095580821223626
Validation loss: 2.616048396432583

Epoch: 5| Step: 8
Training loss: 3.169571514593196
Validation loss: 2.639133242433771

Epoch: 5| Step: 9
Training loss: 2.9129770829582307
Validation loss: 2.6265664971314933

Epoch: 5| Step: 10
Training loss: 2.7839255161735292
Validation loss: 2.5997691128477722

Epoch: 69| Step: 0
Training loss: 3.029998048838374
Validation loss: 2.591875051205652

Epoch: 5| Step: 1
Training loss: 2.872750438798707
Validation loss: 2.6114633618289163

Epoch: 5| Step: 2
Training loss: 2.354057331978389
Validation loss: 2.604842533800996

Epoch: 5| Step: 3
Training loss: 3.053899873232582
Validation loss: 2.604831051317571

Epoch: 5| Step: 4
Training loss: 2.4683168248515948
Validation loss: 2.5901842916863935

Epoch: 5| Step: 5
Training loss: 2.5397335163508648
Validation loss: 2.611239769028533

Epoch: 5| Step: 6
Training loss: 2.500161165764592
Validation loss: 2.5626262860777578

Epoch: 5| Step: 7
Training loss: 2.9617609574981487
Validation loss: 2.6241271681771723

Epoch: 5| Step: 8
Training loss: 3.1547532262280034
Validation loss: 2.6077670578121133

Epoch: 5| Step: 9
Training loss: 2.821395454764239
Validation loss: 2.6176242415599438

Epoch: 5| Step: 10
Training loss: 2.58394802122717
Validation loss: 2.628066051245835

Epoch: 70| Step: 0
Training loss: 3.107500287498651
Validation loss: 2.608139466710022

Epoch: 5| Step: 1
Training loss: 2.860187352586283
Validation loss: 2.625853533057034

Epoch: 5| Step: 2
Training loss: 2.3478132503269173
Validation loss: 2.6063402003844773

Epoch: 5| Step: 3
Training loss: 2.707905241560666
Validation loss: 2.6062715921928676

Epoch: 5| Step: 4
Training loss: 2.653299285951375
Validation loss: 2.569023915689515

Epoch: 5| Step: 5
Training loss: 3.1701941335060555
Validation loss: 2.6119019929809792

Epoch: 5| Step: 6
Training loss: 3.4777271848688027
Validation loss: 2.629802727571909

Epoch: 5| Step: 7
Training loss: 2.3445387466753167
Validation loss: 2.6055633842106407

Epoch: 5| Step: 8
Training loss: 2.754850358308702
Validation loss: 2.614173925415599

Epoch: 5| Step: 9
Training loss: 2.5000078201171636
Validation loss: 2.6532783858104496

Epoch: 5| Step: 10
Training loss: 2.456540396804085
Validation loss: 2.640781880195574

Epoch: 71| Step: 0
Training loss: 2.9147167954189923
Validation loss: 2.618781546505663

Epoch: 5| Step: 1
Training loss: 2.238317785580686
Validation loss: 2.6309351018218683

Epoch: 5| Step: 2
Training loss: 3.760084960058795
Validation loss: 2.6107012707730313

Epoch: 5| Step: 3
Training loss: 2.2709609762825824
Validation loss: 2.606754983275991

Epoch: 5| Step: 4
Training loss: 2.5738655739504606
Validation loss: 2.621870449913428

Epoch: 5| Step: 5
Training loss: 2.4483762810118934
Validation loss: 2.628755538412105

Epoch: 5| Step: 6
Training loss: 3.095184301949903
Validation loss: 2.6108511569378456

Epoch: 5| Step: 7
Training loss: 2.250792999395802
Validation loss: 2.6451379160694923

Epoch: 5| Step: 8
Training loss: 2.5169671310867265
Validation loss: 2.630070965880655

Epoch: 5| Step: 9
Training loss: 3.1050830145655928
Validation loss: 2.6210854871630733

Epoch: 5| Step: 10
Training loss: 2.65094496594967
Validation loss: 2.634341395610981

Epoch: 72| Step: 0
Training loss: 2.4555353848054184
Validation loss: 2.604693599099084

Epoch: 5| Step: 1
Training loss: 2.1446807753612998
Validation loss: 2.597851408120143

Epoch: 5| Step: 2
Training loss: 2.7233039162244252
Validation loss: 2.6343315374626513

Epoch: 5| Step: 3
Training loss: 2.5565471821517143
Validation loss: 2.611667161994318

Epoch: 5| Step: 4
Training loss: 3.2442549766307756
Validation loss: 2.5962027319219296

Epoch: 5| Step: 5
Training loss: 2.864235670782557
Validation loss: 2.635345906154751

Epoch: 5| Step: 6
Training loss: 2.8724787064071
Validation loss: 2.6039218424903914

Epoch: 5| Step: 7
Training loss: 3.2121244218416574
Validation loss: 2.6111354596199776

Epoch: 5| Step: 8
Training loss: 3.2344506296354743
Validation loss: 2.635736351625416

Epoch: 5| Step: 9
Training loss: 2.140340633020853
Validation loss: 2.5938230925035257

Epoch: 5| Step: 10
Training loss: 2.91737042973706
Validation loss: 2.601730414674809

Epoch: 73| Step: 0
Training loss: 3.302958584060663
Validation loss: 2.610718532836005

Epoch: 5| Step: 1
Training loss: 2.2114749969511056
Validation loss: 2.5950962007310574

Epoch: 5| Step: 2
Training loss: 2.7488870969742685
Validation loss: 2.6117673776239756

Epoch: 5| Step: 3
Training loss: 3.2991497273759824
Validation loss: 2.646256679830466

Epoch: 5| Step: 4
Training loss: 1.964374827555771
Validation loss: 2.5954020863028724

Epoch: 5| Step: 5
Training loss: 2.547156008330453
Validation loss: 2.62295804684119

Epoch: 5| Step: 6
Training loss: 3.052998653987584
Validation loss: 2.615029354869881

Epoch: 5| Step: 7
Training loss: 2.7115246579390666
Validation loss: 2.581384692632827

Epoch: 5| Step: 8
Training loss: 2.8604035742326483
Validation loss: 2.615815784105763

Epoch: 5| Step: 9
Training loss: 2.9998138687884435
Validation loss: 2.622427470392578

Epoch: 5| Step: 10
Training loss: 2.161009138992664
Validation loss: 2.625756365226388

Epoch: 74| Step: 0
Training loss: 2.3460865834901887
Validation loss: 2.6144259159117533

Epoch: 5| Step: 1
Training loss: 3.5288095058568247
Validation loss: 2.5736736044227784

Epoch: 5| Step: 2
Training loss: 2.775176886342253
Validation loss: 2.606393607291763

Epoch: 5| Step: 3
Training loss: 2.208039018224034
Validation loss: 2.597909309791315

Epoch: 5| Step: 4
Training loss: 3.246774540100622
Validation loss: 2.6367531686448307

Epoch: 5| Step: 5
Training loss: 2.7650544176041114
Validation loss: 2.623622484994848

Epoch: 5| Step: 6
Training loss: 2.869667248991437
Validation loss: 2.6359522655172296

Epoch: 5| Step: 7
Training loss: 2.513383708047658
Validation loss: 2.6019528994113146

Epoch: 5| Step: 8
Training loss: 2.5301019396241995
Validation loss: 2.6192449836268668

Epoch: 5| Step: 9
Training loss: 2.852004928755815
Validation loss: 2.612692155153165

Epoch: 5| Step: 10
Training loss: 2.2875335065545204
Validation loss: 2.5922426582439515

Epoch: 75| Step: 0
Training loss: 3.132133886035798
Validation loss: 2.6093465356353143

Epoch: 5| Step: 1
Training loss: 2.2590967241766764
Validation loss: 2.6202041923226846

Epoch: 5| Step: 2
Training loss: 2.828331112595696
Validation loss: 2.6394108330763166

Epoch: 5| Step: 3
Training loss: 3.001892128934643
Validation loss: 2.6330273694130124

Epoch: 5| Step: 4
Training loss: 3.040707493571587
Validation loss: 2.5958345795767688

Epoch: 5| Step: 5
Training loss: 2.7708000429682387
Validation loss: 2.613634837975884

Epoch: 5| Step: 6
Training loss: 1.8705874337382686
Validation loss: 2.6031334774589014

Epoch: 5| Step: 7
Training loss: 2.7980288890413396
Validation loss: 2.5958118202846694

Epoch: 5| Step: 8
Training loss: 2.6237601122177394
Validation loss: 2.617358047102985

Epoch: 5| Step: 9
Training loss: 3.041972906991467
Validation loss: 2.6100986413841003

Epoch: 5| Step: 10
Training loss: 2.6113672018158853
Validation loss: 2.592283044346225

Epoch: 76| Step: 0
Training loss: 2.237925982283363
Validation loss: 2.6026844326595477

Epoch: 5| Step: 1
Training loss: 2.260896048861182
Validation loss: 2.5810439961012137

Epoch: 5| Step: 2
Training loss: 2.9794936278573214
Validation loss: 2.607987347629843

Epoch: 5| Step: 3
Training loss: 2.9993527031984075
Validation loss: 2.594168469024555

Epoch: 5| Step: 4
Training loss: 3.314169696834932
Validation loss: 2.63131844896257

Epoch: 5| Step: 5
Training loss: 3.6476630424261427
Validation loss: 2.6139486088493307

Epoch: 5| Step: 6
Training loss: 2.8366146907983
Validation loss: 2.621274706247947

Epoch: 5| Step: 7
Training loss: 2.2286628320135886
Validation loss: 2.6123170282139294

Epoch: 5| Step: 8
Training loss: 2.258835082486237
Validation loss: 2.613391048582738

Epoch: 5| Step: 9
Training loss: 2.3001138078479366
Validation loss: 2.584807527729405

Epoch: 5| Step: 10
Training loss: 3.1314091381209863
Validation loss: 2.6218254535532517

Epoch: 77| Step: 0
Training loss: 2.4577773376006102
Validation loss: 2.592509451799566

Epoch: 5| Step: 1
Training loss: 2.3809872499819096
Validation loss: 2.6177678838035985

Epoch: 5| Step: 2
Training loss: 2.7266102434148207
Validation loss: 2.618163452473942

Epoch: 5| Step: 3
Training loss: 3.1914740827208217
Validation loss: 2.5937312427311507

Epoch: 5| Step: 4
Training loss: 2.676320087169017
Validation loss: 2.618599946575739

Epoch: 5| Step: 5
Training loss: 2.905744939418135
Validation loss: 2.5724423084861376

Epoch: 5| Step: 6
Training loss: 3.407934209931822
Validation loss: 2.5925119348372068

Epoch: 5| Step: 7
Training loss: 2.119854475460839
Validation loss: 2.5827198140249368

Epoch: 5| Step: 8
Training loss: 2.6740359663730753
Validation loss: 2.6182514994036463

Epoch: 5| Step: 9
Training loss: 2.657374514239467
Validation loss: 2.6416903780590566

Epoch: 5| Step: 10
Training loss: 2.8625737209905124
Validation loss: 2.609575488522188

Epoch: 78| Step: 0
Training loss: 2.8894913383495324
Validation loss: 2.6137033323351107

Epoch: 5| Step: 1
Training loss: 2.7501170393573386
Validation loss: 2.6230146642057526

Epoch: 5| Step: 2
Training loss: 2.2125128535527723
Validation loss: 2.632358339869549

Epoch: 5| Step: 3
Training loss: 3.279491861804671
Validation loss: 2.6121761482608177

Epoch: 5| Step: 4
Training loss: 3.089285972588904
Validation loss: 2.61828625088937

Epoch: 5| Step: 5
Training loss: 2.604924958771849
Validation loss: 2.6180829077128944

Epoch: 5| Step: 6
Training loss: 2.3859648317621454
Validation loss: 2.6444023567321624

Epoch: 5| Step: 7
Training loss: 2.5023987705971606
Validation loss: 2.60802611473047

Epoch: 5| Step: 8
Training loss: 2.666823223604638
Validation loss: 2.5996436617165672

Epoch: 5| Step: 9
Training loss: 2.904173078123994
Validation loss: 2.5989323268106004

Epoch: 5| Step: 10
Training loss: 2.741155272524411
Validation loss: 2.5776965230534827

Epoch: 79| Step: 0
Training loss: 2.550603279109149
Validation loss: 2.60291557498242

Epoch: 5| Step: 1
Training loss: 3.3566318401309165
Validation loss: 2.605013113629114

Epoch: 5| Step: 2
Training loss: 2.4636889380751277
Validation loss: 2.6261068667886014

Epoch: 5| Step: 3
Training loss: 2.8565279435163666
Validation loss: 2.614570385915123

Epoch: 5| Step: 4
Training loss: 3.273677553101357
Validation loss: 2.596314021955322

Epoch: 5| Step: 5
Training loss: 2.81879424337441
Validation loss: 2.6149650608508845

Epoch: 5| Step: 6
Training loss: 2.033812681614328
Validation loss: 2.580185206183093

Epoch: 5| Step: 7
Training loss: 3.1066330364628176
Validation loss: 2.585109069294711

Epoch: 5| Step: 8
Training loss: 2.312410301324651
Validation loss: 2.627679218341709

Epoch: 5| Step: 9
Training loss: 3.0454957627984225
Validation loss: 2.5817141958243948

Epoch: 5| Step: 10
Training loss: 1.7486743674511664
Validation loss: 2.6063963741483342

Epoch: 80| Step: 0
Training loss: 2.140690934773784
Validation loss: 2.607368244330729

Epoch: 5| Step: 1
Training loss: 3.0545298347858183
Validation loss: 2.618300565719775

Epoch: 5| Step: 2
Training loss: 2.513867445468482
Validation loss: 2.616519738592038

Epoch: 5| Step: 3
Training loss: 2.6113641889046244
Validation loss: 2.629489578163989

Epoch: 5| Step: 4
Training loss: 2.6651369316607267
Validation loss: 2.6161996959949154

Epoch: 5| Step: 5
Training loss: 3.127662440044831
Validation loss: 2.6043604985775253

Epoch: 5| Step: 6
Training loss: 2.38113153918917
Validation loss: 2.61115094665544

Epoch: 5| Step: 7
Training loss: 2.615568565571091
Validation loss: 2.6316965300807857

Epoch: 5| Step: 8
Training loss: 2.7805220262011408
Validation loss: 2.626635581977996

Epoch: 5| Step: 9
Training loss: 2.993651985363806
Validation loss: 2.6006563251585835

Epoch: 5| Step: 10
Training loss: 2.939896113577888
Validation loss: 2.574290666249883

Epoch: 81| Step: 0
Training loss: 2.837776365559438
Validation loss: 2.6158692611838767

Epoch: 5| Step: 1
Training loss: 2.633590900121984
Validation loss: 2.6044766977814975

Epoch: 5| Step: 2
Training loss: 2.131872396118041
Validation loss: 2.615399296617318

Epoch: 5| Step: 3
Training loss: 2.534649673422341
Validation loss: 2.588599814541406

Epoch: 5| Step: 4
Training loss: 3.068528761337471
Validation loss: 2.6522895517121343

Epoch: 5| Step: 5
Training loss: 2.983323955698743
Validation loss: 2.6118713751879215

Epoch: 5| Step: 6
Training loss: 2.5435544700361765
Validation loss: 2.613080923167246

Epoch: 5| Step: 7
Training loss: 3.2254358869409576
Validation loss: 2.601006768256435

Epoch: 5| Step: 8
Training loss: 3.018628615946039
Validation loss: 2.5760007796158018

Epoch: 5| Step: 9
Training loss: 2.302393401885238
Validation loss: 2.601476858889287

Epoch: 5| Step: 10
Training loss: 2.5861845791610145
Validation loss: 2.6046619930293384

Epoch: 82| Step: 0
Training loss: 3.0990018098917598
Validation loss: 2.606491491540407

Epoch: 5| Step: 1
Training loss: 2.115463624825874
Validation loss: 2.619903376796141

Epoch: 5| Step: 2
Training loss: 2.8293916173690903
Validation loss: 2.600685902922897

Epoch: 5| Step: 3
Training loss: 2.4976873191258977
Validation loss: 2.5897182823416927

Epoch: 5| Step: 4
Training loss: 2.8728138448578653
Validation loss: 2.6138202151858425

Epoch: 5| Step: 5
Training loss: 2.4119278936030466
Validation loss: 2.599926730749306

Epoch: 5| Step: 6
Training loss: 3.1119080007335205
Validation loss: 2.6202895251395377

Epoch: 5| Step: 7
Training loss: 2.999534093918356
Validation loss: 2.6122995156685564

Epoch: 5| Step: 8
Training loss: 2.26007463061909
Validation loss: 2.626890369072363

Epoch: 5| Step: 9
Training loss: 2.7406789428552294
Validation loss: 2.6057334131203937

Epoch: 5| Step: 10
Training loss: 3.075324163950673
Validation loss: 2.6038889176111737

Epoch: 83| Step: 0
Training loss: 3.053980909026806
Validation loss: 2.6178460071611704

Epoch: 5| Step: 1
Training loss: 2.015511679605812
Validation loss: 2.6105048970750615

Epoch: 5| Step: 2
Training loss: 2.950550228465159
Validation loss: 2.6063493548922

Epoch: 5| Step: 3
Training loss: 2.905318080014154
Validation loss: 2.597148382326736

Epoch: 5| Step: 4
Training loss: 2.915122486243459
Validation loss: 2.6096334729125386

Epoch: 5| Step: 5
Training loss: 2.055646897196741
Validation loss: 2.6386939814064108

Epoch: 5| Step: 6
Training loss: 3.363124724145129
Validation loss: 2.5955243703847617

Epoch: 5| Step: 7
Training loss: 2.6484473124184467
Validation loss: 2.5830903238353438

Epoch: 5| Step: 8
Training loss: 2.315160097720279
Validation loss: 2.5852805753323995

Epoch: 5| Step: 9
Training loss: 2.9513479870723307
Validation loss: 2.5866754044935556

Epoch: 5| Step: 10
Training loss: 2.374187129601874
Validation loss: 2.6080520161564267

Epoch: 84| Step: 0
Training loss: 2.991385011156729
Validation loss: 2.5869757101050563

Epoch: 5| Step: 1
Training loss: 2.01398750443735
Validation loss: 2.624628707792831

Epoch: 5| Step: 2
Training loss: 2.5090543815280952
Validation loss: 2.5904092179570775

Epoch: 5| Step: 3
Training loss: 3.0390422594823248
Validation loss: 2.636617831748963

Epoch: 5| Step: 4
Training loss: 3.128315044655145
Validation loss: 2.6192326334671816

Epoch: 5| Step: 5
Training loss: 2.782191856438282
Validation loss: 2.5981833174354967

Epoch: 5| Step: 6
Training loss: 2.925843343852523
Validation loss: 2.5922194411670767

Epoch: 5| Step: 7
Training loss: 2.2007288245747056
Validation loss: 2.5780049912310274

Epoch: 5| Step: 8
Training loss: 2.339476695111583
Validation loss: 2.5856183379946183

Epoch: 5| Step: 9
Training loss: 2.370256505517287
Validation loss: 2.586057843506518

Epoch: 5| Step: 10
Training loss: 3.175513825177595
Validation loss: 2.593393589187255

Epoch: 85| Step: 0
Training loss: 2.5803918294041344
Validation loss: 2.5958038493003412

Epoch: 5| Step: 1
Training loss: 2.7072297611084197
Validation loss: 2.6027227724643565

Epoch: 5| Step: 2
Training loss: 2.1800029348651133
Validation loss: 2.609348005430628

Epoch: 5| Step: 3
Training loss: 2.5825898320840053
Validation loss: 2.608519919701827

Epoch: 5| Step: 4
Training loss: 3.2756218006895033
Validation loss: 2.615204193235891

Epoch: 5| Step: 5
Training loss: 2.395440232466282
Validation loss: 2.593451822682894

Epoch: 5| Step: 6
Training loss: 2.426290609107353
Validation loss: 2.6184615096478816

Epoch: 5| Step: 7
Training loss: 3.104618133553302
Validation loss: 2.574876526491543

Epoch: 5| Step: 8
Training loss: 2.7127343634690084
Validation loss: 2.5976613355178637

Epoch: 5| Step: 9
Training loss: 2.636469443508951
Validation loss: 2.614425999260625

Epoch: 5| Step: 10
Training loss: 3.224342598557277
Validation loss: 2.586302929687531

Epoch: 86| Step: 0
Training loss: 2.5220906823634825
Validation loss: 2.6258732016753195

Epoch: 5| Step: 1
Training loss: 1.8283559539193066
Validation loss: 2.640441547391731

Epoch: 5| Step: 2
Training loss: 3.0029315929872005
Validation loss: 2.6236521644097315

Epoch: 5| Step: 3
Training loss: 2.699363870211367
Validation loss: 2.5643577064650698

Epoch: 5| Step: 4
Training loss: 2.311418950789873
Validation loss: 2.629334320370112

Epoch: 5| Step: 5
Training loss: 3.47118161863202
Validation loss: 2.613452674911805

Epoch: 5| Step: 6
Training loss: 1.5663191849634512
Validation loss: 2.631866897740921

Epoch: 5| Step: 7
Training loss: 2.4754275058709574
Validation loss: 2.6020945210386577

Epoch: 5| Step: 8
Training loss: 2.5946949535852273
Validation loss: 2.664227711096239

Epoch: 5| Step: 9
Training loss: 3.6366513550246924
Validation loss: 2.6292797423590613

Epoch: 5| Step: 10
Training loss: 3.2412237366518153
Validation loss: 2.63603904917493

Epoch: 87| Step: 0
Training loss: 2.2511063081167704
Validation loss: 2.622009227501978

Epoch: 5| Step: 1
Training loss: 2.4309591908828985
Validation loss: 2.606062546898443

Epoch: 5| Step: 2
Training loss: 2.9259817057289923
Validation loss: 2.6018929890403375

Epoch: 5| Step: 3
Training loss: 2.867140766979072
Validation loss: 2.5751100234904376

Epoch: 5| Step: 4
Training loss: 2.513283344584533
Validation loss: 2.638405156788978

Epoch: 5| Step: 5
Training loss: 3.0513913842512586
Validation loss: 2.621043912413369

Epoch: 5| Step: 6
Training loss: 2.552915372612112
Validation loss: 2.602595098644436

Epoch: 5| Step: 7
Training loss: 2.7502508915980446
Validation loss: 2.596232221194161

Epoch: 5| Step: 8
Training loss: 2.863451443931419
Validation loss: 2.6063803424704055

Epoch: 5| Step: 9
Training loss: 3.0931497627356994
Validation loss: 2.614496820326947

Epoch: 5| Step: 10
Training loss: 2.3462093420067562
Validation loss: 2.6125519205028875

Epoch: 88| Step: 0
Training loss: 2.388210498484336
Validation loss: 2.5996790430867045

Epoch: 5| Step: 1
Training loss: 2.7235561290298524
Validation loss: 2.5517243054713954

Epoch: 5| Step: 2
Training loss: 2.003143224767182
Validation loss: 2.6258697406886897

Epoch: 5| Step: 3
Training loss: 2.350768604796031
Validation loss: 2.5871059007624067

Epoch: 5| Step: 4
Training loss: 2.6261901882065906
Validation loss: 2.588840776253994

Epoch: 5| Step: 5
Training loss: 2.8289323360459275
Validation loss: 2.607023178834902

Epoch: 5| Step: 6
Training loss: 2.2288630864095227
Validation loss: 2.603109989187733

Epoch: 5| Step: 7
Training loss: 3.435388783715153
Validation loss: 2.613683211181429

Epoch: 5| Step: 8
Training loss: 2.711250133241797
Validation loss: 2.587394741700122

Epoch: 5| Step: 9
Training loss: 3.2528286874987504
Validation loss: 2.616203533320247

Epoch: 5| Step: 10
Training loss: 3.039735851858228
Validation loss: 2.612653612324176

Epoch: 89| Step: 0
Training loss: 3.2504263378153144
Validation loss: 2.61107987676316

Epoch: 5| Step: 1
Training loss: 2.771283670030741
Validation loss: 2.6042262051246894

Epoch: 5| Step: 2
Training loss: 2.1879383192974826
Validation loss: 2.616446556051993

Epoch: 5| Step: 3
Training loss: 2.795998803674663
Validation loss: 2.567173743156046

Epoch: 5| Step: 4
Training loss: 2.5874289277124376
Validation loss: 2.616601778086305

Epoch: 5| Step: 5
Training loss: 2.472014092198422
Validation loss: 2.6066512871022005

Epoch: 5| Step: 6
Training loss: 2.354250566005892
Validation loss: 2.5914813014931615

Epoch: 5| Step: 7
Training loss: 3.3979792143403214
Validation loss: 2.600175255058446

Epoch: 5| Step: 8
Training loss: 2.9656902406548844
Validation loss: 2.6331939075325796

Epoch: 5| Step: 9
Training loss: 2.315200260143358
Validation loss: 2.582156971040836

Epoch: 5| Step: 10
Training loss: 2.4478010975496525
Validation loss: 2.6136506682174763

Epoch: 90| Step: 0
Training loss: 2.358163990190794
Validation loss: 2.5975754907800654

Epoch: 5| Step: 1
Training loss: 2.7693558867424937
Validation loss: 2.57467597263173

Epoch: 5| Step: 2
Training loss: 2.901958291088584
Validation loss: 2.586690391786245

Epoch: 5| Step: 3
Training loss: 1.9618451574898954
Validation loss: 2.6180108425972772

Epoch: 5| Step: 4
Training loss: 2.644712095402053
Validation loss: 2.6118600462975836

Epoch: 5| Step: 5
Training loss: 2.4892317604805814
Validation loss: 2.615002371612975

Epoch: 5| Step: 6
Training loss: 3.1194452890598976
Validation loss: 2.5729949316189415

Epoch: 5| Step: 7
Training loss: 2.992531699360875
Validation loss: 2.588665815121146

Epoch: 5| Step: 8
Training loss: 2.61244085509596
Validation loss: 2.5914729046673943

Epoch: 5| Step: 9
Training loss: 2.922558056961996
Validation loss: 2.6022800001940087

Epoch: 5| Step: 10
Training loss: 2.756352370387355
Validation loss: 2.5810871785917384

Epoch: 91| Step: 0
Training loss: 2.3264885597956124
Validation loss: 2.6080336817087573

Epoch: 5| Step: 1
Training loss: 2.178634991042404
Validation loss: 2.5926937320212566

Epoch: 5| Step: 2
Training loss: 2.6052156293955733
Validation loss: 2.582138568887508

Epoch: 5| Step: 3
Training loss: 2.9062196463363645
Validation loss: 2.59594176135807

Epoch: 5| Step: 4
Training loss: 2.1120695634931
Validation loss: 2.6118009668399145

Epoch: 5| Step: 5
Training loss: 2.8810258823703223
Validation loss: 2.5972045752482757

Epoch: 5| Step: 6
Training loss: 3.1686547379780494
Validation loss: 2.6045526394863043

Epoch: 5| Step: 7
Training loss: 2.724324879440147
Validation loss: 2.631509928912743

Epoch: 5| Step: 8
Training loss: 2.9642848114957765
Validation loss: 2.60344661938789

Epoch: 5| Step: 9
Training loss: 2.6062080215256884
Validation loss: 2.609272549628188

Epoch: 5| Step: 10
Training loss: 2.9549562942190244
Validation loss: 2.593311653304663

Epoch: 92| Step: 0
Training loss: 2.859099828268144
Validation loss: 2.6356809315710805

Epoch: 5| Step: 1
Training loss: 2.574359247428485
Validation loss: 2.6065848587222233

Epoch: 5| Step: 2
Training loss: 3.116120502399359
Validation loss: 2.5846335730971393

Epoch: 5| Step: 3
Training loss: 2.267373193225407
Validation loss: 2.594752131332602

Epoch: 5| Step: 4
Training loss: 2.8309527849567355
Validation loss: 2.6362788148672505

Epoch: 5| Step: 5
Training loss: 2.8300622869855308
Validation loss: 2.6057216876162865

Epoch: 5| Step: 6
Training loss: 2.314001163182341
Validation loss: 2.6052520859148163

Epoch: 5| Step: 7
Training loss: 3.0951359274354586
Validation loss: 2.574345981857673

Epoch: 5| Step: 8
Training loss: 2.879240805908426
Validation loss: 2.613440682891068

Epoch: 5| Step: 9
Training loss: 2.0887956219113364
Validation loss: 2.5911374891772048

Epoch: 5| Step: 10
Training loss: 2.5762037111850136
Validation loss: 2.6116807395993096

Epoch: 93| Step: 0
Training loss: 2.813618331668759
Validation loss: 2.574746462236125

Epoch: 5| Step: 1
Training loss: 2.8433909765961793
Validation loss: 2.637931965493796

Epoch: 5| Step: 2
Training loss: 2.977648759612207
Validation loss: 2.6010505556627552

Epoch: 5| Step: 3
Training loss: 2.702914455791816
Validation loss: 2.568786028182268

Epoch: 5| Step: 4
Training loss: 3.070581167177255
Validation loss: 2.6117908479132264

Epoch: 5| Step: 5
Training loss: 3.234284625426316
Validation loss: 2.5953536114096143

Epoch: 5| Step: 6
Training loss: 2.6545341784212795
Validation loss: 2.558610553024039

Epoch: 5| Step: 7
Training loss: 2.4920836041357926
Validation loss: 2.614999931498737

Epoch: 5| Step: 8
Training loss: 1.7304202518598986
Validation loss: 2.5753543547416835

Epoch: 5| Step: 9
Training loss: 2.26796827483821
Validation loss: 2.5861500981456014

Epoch: 5| Step: 10
Training loss: 2.8818723391254015
Validation loss: 2.5984736776573447

Epoch: 94| Step: 0
Training loss: 2.77584253184996
Validation loss: 2.606889768957654

Epoch: 5| Step: 1
Training loss: 3.029950049967466
Validation loss: 2.566614005458564

Epoch: 5| Step: 2
Training loss: 2.2248309982066177
Validation loss: 2.584577738701403

Epoch: 5| Step: 3
Training loss: 2.736579485939963
Validation loss: 2.6021052973740213

Epoch: 5| Step: 4
Training loss: 3.072561745702166
Validation loss: 2.5768288932612884

Epoch: 5| Step: 5
Training loss: 2.9470756777964118
Validation loss: 2.594105367659049

Epoch: 5| Step: 6
Training loss: 2.4443253057037557
Validation loss: 2.5794180025683366

Epoch: 5| Step: 7
Training loss: 2.0603012155472316
Validation loss: 2.602280474051946

Epoch: 5| Step: 8
Training loss: 3.0521335706167485
Validation loss: 2.6116552452122823

Epoch: 5| Step: 9
Training loss: 2.5365516807303794
Validation loss: 2.594906130820272

Epoch: 5| Step: 10
Training loss: 2.583242250703149
Validation loss: 2.6005112744023724

Epoch: 95| Step: 0
Training loss: 2.4370368126181248
Validation loss: 2.583781109949167

Epoch: 5| Step: 1
Training loss: 2.947660527149113
Validation loss: 2.607163562387011

Epoch: 5| Step: 2
Training loss: 2.8894018936308394
Validation loss: 2.595283169824621

Epoch: 5| Step: 3
Training loss: 2.76343445314099
Validation loss: 2.6018153976160057

Epoch: 5| Step: 4
Training loss: 2.84136628234796
Validation loss: 2.616335941114285

Epoch: 5| Step: 5
Training loss: 2.17650500438631
Validation loss: 2.6316208139666437

Epoch: 5| Step: 6
Training loss: 2.510249774709083
Validation loss: 2.6099129094688798

Epoch: 5| Step: 7
Training loss: 2.68495989678978
Validation loss: 2.6153737110498425

Epoch: 5| Step: 8
Training loss: 3.141771097918158
Validation loss: 2.6138581680325017

Epoch: 5| Step: 9
Training loss: 2.638649918516394
Validation loss: 2.593900255876317

Epoch: 5| Step: 10
Training loss: 2.2625324057265765
Validation loss: 2.5759024129861117

Epoch: 96| Step: 0
Training loss: 1.8136244607249306
Validation loss: 2.5869779140431612

Epoch: 5| Step: 1
Training loss: 2.9105445551552624
Validation loss: 2.5979339956913186

Epoch: 5| Step: 2
Training loss: 2.739264601428753
Validation loss: 2.595013171149577

Epoch: 5| Step: 3
Training loss: 3.151648765067975
Validation loss: 2.6214723444583647

Epoch: 5| Step: 4
Training loss: 2.095087563589858
Validation loss: 2.616499623420048

Epoch: 5| Step: 5
Training loss: 2.636403337616183
Validation loss: 2.5783663062821636

Epoch: 5| Step: 6
Training loss: 2.8710185138420354
Validation loss: 2.5904344840138007

Epoch: 5| Step: 7
Training loss: 2.602125318894525
Validation loss: 2.607050140442321

Epoch: 5| Step: 8
Training loss: 1.6671766772361343
Validation loss: 2.582341712060636

Epoch: 5| Step: 9
Training loss: 3.559193733295215
Validation loss: 2.635137169053279

Epoch: 5| Step: 10
Training loss: 2.8999348600240684
Validation loss: 2.6007410829632525

Epoch: 97| Step: 0
Training loss: 2.434650516221767
Validation loss: 2.598994625435842

Epoch: 5| Step: 1
Training loss: 2.9800138713846653
Validation loss: 2.6103730449873854

Epoch: 5| Step: 2
Training loss: 2.7851352771113835
Validation loss: 2.588340232645584

Epoch: 5| Step: 3
Training loss: 2.8866604397760174
Validation loss: 2.5805749771485433

Epoch: 5| Step: 4
Training loss: 2.9225911777393203
Validation loss: 2.5736531972064802

Epoch: 5| Step: 5
Training loss: 3.0292350128173315
Validation loss: 2.607623244157276

Epoch: 5| Step: 6
Training loss: 2.7149831173479018
Validation loss: 2.589957301865238

Epoch: 5| Step: 7
Training loss: 2.880841002324889
Validation loss: 2.603076807827302

Epoch: 5| Step: 8
Training loss: 2.3928200611096173
Validation loss: 2.5685071806821105

Epoch: 5| Step: 9
Training loss: 1.7701757070108624
Validation loss: 2.585063165292928

Epoch: 5| Step: 10
Training loss: 2.291224893701901
Validation loss: 2.5491324935490303

Epoch: 98| Step: 0
Training loss: 2.051958251342528
Validation loss: 2.5912427440833956

Epoch: 5| Step: 1
Training loss: 3.4324923019156155
Validation loss: 2.601857221482348

Epoch: 5| Step: 2
Training loss: 2.931633630956431
Validation loss: 2.5992001516300607

Epoch: 5| Step: 3
Training loss: 2.753199017121875
Validation loss: 2.596317548013578

Epoch: 5| Step: 4
Training loss: 2.3413374627554124
Validation loss: 2.5862384845651323

Epoch: 5| Step: 5
Training loss: 2.3028000166243143
Validation loss: 2.5836626458894827

Epoch: 5| Step: 6
Training loss: 3.183164452938026
Validation loss: 2.58314527832066

Epoch: 5| Step: 7
Training loss: 2.4930553300503835
Validation loss: 2.6330223775173147

Epoch: 5| Step: 8
Training loss: 2.459412311043118
Validation loss: 2.5991968832132395

Epoch: 5| Step: 9
Training loss: 2.7506454750621683
Validation loss: 2.576256350685644

Epoch: 5| Step: 10
Training loss: 2.8007934229545
Validation loss: 2.645710291063312

Epoch: 99| Step: 0
Training loss: 2.8957080585268407
Validation loss: 2.5971519975715776

Epoch: 5| Step: 1
Training loss: 2.9149219380783307
Validation loss: 2.6075531497601

Epoch: 5| Step: 2
Training loss: 2.6670325048158645
Validation loss: 2.6221421110842305

Epoch: 5| Step: 3
Training loss: 2.8107733618676316
Validation loss: 2.603453153917071

Epoch: 5| Step: 4
Training loss: 2.915655687503881
Validation loss: 2.5665068275256306

Epoch: 5| Step: 5
Training loss: 2.4060855165220922
Validation loss: 2.5928574167972136

Epoch: 5| Step: 6
Training loss: 2.8694347752763836
Validation loss: 2.6259611023724454

Epoch: 5| Step: 7
Training loss: 2.2356181921040763
Validation loss: 2.588038625759126

Epoch: 5| Step: 8
Training loss: 2.9949083034635278
Validation loss: 2.577788870071487

Epoch: 5| Step: 9
Training loss: 2.291386905124189
Validation loss: 2.565268126155733

Epoch: 5| Step: 10
Training loss: 2.2654736698517386
Validation loss: 2.5820996427135525

Epoch: 100| Step: 0
Training loss: 2.9672925081800687
Validation loss: 2.6290176583264766

Epoch: 5| Step: 1
Training loss: 2.894808983702383
Validation loss: 2.6354889254035108

Epoch: 5| Step: 2
Training loss: 3.147794975050957
Validation loss: 2.6195873519329114

Epoch: 5| Step: 3
Training loss: 2.3853165273733583
Validation loss: 2.605850934821292

Epoch: 5| Step: 4
Training loss: 2.7109396107250427
Validation loss: 2.5670752430127446

Epoch: 5| Step: 5
Training loss: 3.105450017140827
Validation loss: 2.59586086139756

Epoch: 5| Step: 6
Training loss: 2.1236562407096007
Validation loss: 2.584327463468052

Epoch: 5| Step: 7
Training loss: 2.9278713446216753
Validation loss: 2.6072007222546256

Epoch: 5| Step: 8
Training loss: 2.3200935234753186
Validation loss: 2.614518937482776

Epoch: 5| Step: 9
Training loss: 2.166969852753591
Validation loss: 2.6351793804849786

Epoch: 5| Step: 10
Training loss: 2.2888846995594156
Validation loss: 2.5970237868092534

Epoch: 101| Step: 0
Training loss: 2.568546697363247
Validation loss: 2.6054343175650705

Epoch: 5| Step: 1
Training loss: 2.604025285061898
Validation loss: 2.5878191818000325

Epoch: 5| Step: 2
Training loss: 2.9494350732957173
Validation loss: 2.5968950405808378

Epoch: 5| Step: 3
Training loss: 2.847684716185739
Validation loss: 2.579203288984755

Epoch: 5| Step: 4
Training loss: 2.053824936282663
Validation loss: 2.6136281003589965

Epoch: 5| Step: 5
Training loss: 3.042659562627783
Validation loss: 2.5949117799191055

Epoch: 5| Step: 6
Training loss: 2.595063026559549
Validation loss: 2.573467479817862

Epoch: 5| Step: 7
Training loss: 2.9843400084356517
Validation loss: 2.585818597379618

Epoch: 5| Step: 8
Training loss: 2.6731822067536193
Validation loss: 2.602829771061407

Epoch: 5| Step: 9
Training loss: 2.5568694616242382
Validation loss: 2.6344765876835767

Epoch: 5| Step: 10
Training loss: 2.595692194678125
Validation loss: 2.566160029794532

Epoch: 102| Step: 0
Training loss: 2.5433029681784975
Validation loss: 2.5989536817445202

Epoch: 5| Step: 1
Training loss: 3.195747327248238
Validation loss: 2.5991944938512277

Epoch: 5| Step: 2
Training loss: 2.4579829812263827
Validation loss: 2.5881546261668733

Epoch: 5| Step: 3
Training loss: 2.074284266929617
Validation loss: 2.6080682026968334

Epoch: 5| Step: 4
Training loss: 2.1641825838890516
Validation loss: 2.620510933115988

Epoch: 5| Step: 5
Training loss: 2.814692596264911
Validation loss: 2.6098660792994184

Epoch: 5| Step: 6
Training loss: 2.7964469539495402
Validation loss: 2.6011270778705544

Epoch: 5| Step: 7
Training loss: 2.9287566880700484
Validation loss: 2.6169831187719392

Epoch: 5| Step: 8
Training loss: 2.002736722596208
Validation loss: 2.582277640643931

Epoch: 5| Step: 9
Training loss: 3.019962965883459
Validation loss: 2.5994721802178598

Epoch: 5| Step: 10
Training loss: 3.1758935587075703
Validation loss: 2.5961726606954216

Epoch: 103| Step: 0
Training loss: 2.3919441722300263
Validation loss: 2.576551831591225

Epoch: 5| Step: 1
Training loss: 2.974211477717173
Validation loss: 2.622451335530107

Epoch: 5| Step: 2
Training loss: 2.7699315221702157
Validation loss: 2.5741506122450493

Epoch: 5| Step: 3
Training loss: 2.572098039339599
Validation loss: 2.587908273003263

Epoch: 5| Step: 4
Training loss: 2.651695205883358
Validation loss: 2.5780277088411454

Epoch: 5| Step: 5
Training loss: 3.059236305529746
Validation loss: 2.5964283364775715

Epoch: 5| Step: 6
Training loss: 2.999889689642673
Validation loss: 2.58073511136735

Epoch: 5| Step: 7
Training loss: 2.705050185296821
Validation loss: 2.5915760586961514

Epoch: 5| Step: 8
Training loss: 2.410308387937813
Validation loss: 2.5798876223820453

Epoch: 5| Step: 9
Training loss: 2.425087354994002
Validation loss: 2.601836902302962

Epoch: 5| Step: 10
Training loss: 2.2975812591694273
Validation loss: 2.608748176656971

Epoch: 104| Step: 0
Training loss: 2.1377939033340714
Validation loss: 2.6316048677632695

Epoch: 5| Step: 1
Training loss: 2.8750419613637033
Validation loss: 2.591560059980683

Epoch: 5| Step: 2
Training loss: 2.552758284604937
Validation loss: 2.5754004148711793

Epoch: 5| Step: 3
Training loss: 3.2037672934063566
Validation loss: 2.55864335717872

Epoch: 5| Step: 4
Training loss: 2.9398180966318614
Validation loss: 2.5930822476318003

Epoch: 5| Step: 5
Training loss: 2.3457508955767494
Validation loss: 2.576859661295202

Epoch: 5| Step: 6
Training loss: 2.9708329773662365
Validation loss: 2.6084351581427683

Epoch: 5| Step: 7
Training loss: 2.340795154778504
Validation loss: 2.634006311743797

Epoch: 5| Step: 8
Training loss: 2.281989513356405
Validation loss: 2.572312454022979

Epoch: 5| Step: 9
Training loss: 2.599822416109684
Validation loss: 2.605121482463575

Epoch: 5| Step: 10
Training loss: 3.0066833754735667
Validation loss: 2.5809500223229955

Epoch: 105| Step: 0
Training loss: 2.5010358571773255
Validation loss: 2.5603654716673065

Epoch: 5| Step: 1
Training loss: 2.530783998898043
Validation loss: 2.595543368042457

Epoch: 5| Step: 2
Training loss: 3.0417424719435076
Validation loss: 2.631278785729525

Epoch: 5| Step: 3
Training loss: 2.348323175080283
Validation loss: 2.60902489287032

Epoch: 5| Step: 4
Training loss: 3.0552097664348588
Validation loss: 2.602779710819373

Epoch: 5| Step: 5
Training loss: 2.30435529997899
Validation loss: 2.6020505344477414

Epoch: 5| Step: 6
Training loss: 2.32572690613865
Validation loss: 2.622567220963618

Epoch: 5| Step: 7
Training loss: 2.7348233100682173
Validation loss: 2.616117382737396

Epoch: 5| Step: 8
Training loss: 2.613110272982579
Validation loss: 2.592579401154887

Epoch: 5| Step: 9
Training loss: 2.7547593979911045
Validation loss: 2.5779677809541863

Epoch: 5| Step: 10
Training loss: 3.186410306277836
Validation loss: 2.5974950705396633

Epoch: 106| Step: 0
Training loss: 1.9799993135470346
Validation loss: 2.597618105831367

Epoch: 5| Step: 1
Training loss: 2.3972866018271675
Validation loss: 2.587158312496676

Epoch: 5| Step: 2
Training loss: 3.2923334307524943
Validation loss: 2.5910183156276103

Epoch: 5| Step: 3
Training loss: 3.370945791310519
Validation loss: 2.6017446678656877

Epoch: 5| Step: 4
Training loss: 2.7474233520479543
Validation loss: 2.57349994616359

Epoch: 5| Step: 5
Training loss: 1.9291704852050604
Validation loss: 2.6175643480616526

Epoch: 5| Step: 6
Training loss: 2.815723267596416
Validation loss: 2.571262691041604

Epoch: 5| Step: 7
Training loss: 2.869921303444376
Validation loss: 2.5697670569887263

Epoch: 5| Step: 8
Training loss: 2.2632672900347757
Validation loss: 2.6253394079842063

Epoch: 5| Step: 9
Training loss: 2.6516918791462047
Validation loss: 2.619331583839924

Epoch: 5| Step: 10
Training loss: 2.738449896871769
Validation loss: 2.6119030383022577

Epoch: 107| Step: 0
Training loss: 2.4894572163537303
Validation loss: 2.618729198906826

Epoch: 5| Step: 1
Training loss: 2.0360961618029347
Validation loss: 2.5934323253328664

Epoch: 5| Step: 2
Training loss: 2.3952430550797374
Validation loss: 2.6022022045547506

Epoch: 5| Step: 3
Training loss: 2.425367335390326
Validation loss: 2.617669997647383

Epoch: 5| Step: 4
Training loss: 3.389703159445569
Validation loss: 2.600297547345793

Epoch: 5| Step: 5
Training loss: 2.4321294454081164
Validation loss: 2.5698972889609704

Epoch: 5| Step: 6
Training loss: 2.6641297989116857
Validation loss: 2.5709920324592175

Epoch: 5| Step: 7
Training loss: 3.2910150454376343
Validation loss: 2.5974009753964826

Epoch: 5| Step: 8
Training loss: 2.93332537808929
Validation loss: 2.5664718224229186

Epoch: 5| Step: 9
Training loss: 2.158638778145088
Validation loss: 2.5754889323011403

Epoch: 5| Step: 10
Training loss: 2.650031496256666
Validation loss: 2.571345734796108

Epoch: 108| Step: 0
Training loss: 2.6088481988049743
Validation loss: 2.603185113486721

Epoch: 5| Step: 1
Training loss: 2.4101974013909886
Validation loss: 2.587994090213987

Epoch: 5| Step: 2
Training loss: 2.466541219648745
Validation loss: 2.6019853265989292

Epoch: 5| Step: 3
Training loss: 2.531990884743384
Validation loss: 2.569306153494181

Epoch: 5| Step: 4
Training loss: 2.373485584286776
Validation loss: 2.5892597802762425

Epoch: 5| Step: 5
Training loss: 2.559754366117178
Validation loss: 2.5669262982330023

Epoch: 5| Step: 6
Training loss: 2.6573725404075286
Validation loss: 2.5886425709159067

Epoch: 5| Step: 7
Training loss: 2.668406237007987
Validation loss: 2.5765061273628276

Epoch: 5| Step: 8
Training loss: 2.6403081579688505
Validation loss: 2.5908112198836486

Epoch: 5| Step: 9
Training loss: 2.843854965117256
Validation loss: 2.605933786333759

Epoch: 5| Step: 10
Training loss: 3.434691651787521
Validation loss: 2.5755263928969976

Epoch: 109| Step: 0
Training loss: 2.8218420218972944
Validation loss: 2.5657157918756046

Epoch: 5| Step: 1
Training loss: 2.036433955548291
Validation loss: 2.5965529042902173

Epoch: 5| Step: 2
Training loss: 2.682874558208148
Validation loss: 2.5807877369175753

Epoch: 5| Step: 3
Training loss: 2.6669722521053263
Validation loss: 2.5873417640316565

Epoch: 5| Step: 4
Training loss: 2.686457409562101
Validation loss: 2.6032210814244596

Epoch: 5| Step: 5
Training loss: 3.123849122793862
Validation loss: 2.5697880781674978

Epoch: 5| Step: 6
Training loss: 2.504706149350116
Validation loss: 2.613733694248786

Epoch: 5| Step: 7
Training loss: 2.146723170790607
Validation loss: 2.5917483613619874

Epoch: 5| Step: 8
Training loss: 2.561299298595317
Validation loss: 2.6147255801017613

Epoch: 5| Step: 9
Training loss: 2.78826910108729
Validation loss: 2.603998126739065

Epoch: 5| Step: 10
Training loss: 3.0946248676688164
Validation loss: 2.631884081374657

Epoch: 110| Step: 0
Training loss: 2.8557706534997913
Validation loss: 2.626410705385328

Epoch: 5| Step: 1
Training loss: 2.3236967638636985
Validation loss: 2.5768122975815126

Epoch: 5| Step: 2
Training loss: 2.4814653932493775
Validation loss: 2.5875659050260755

Epoch: 5| Step: 3
Training loss: 2.6745066927663688
Validation loss: 2.5952572110968903

Epoch: 5| Step: 4
Training loss: 2.2459429084879377
Validation loss: 2.6288463902219172

Epoch: 5| Step: 5
Training loss: 2.728887228212807
Validation loss: 2.6101239407863575

Epoch: 5| Step: 6
Training loss: 3.188288422856655
Validation loss: 2.568573751446856

Epoch: 5| Step: 7
Training loss: 2.5575523062360426
Validation loss: 2.5845570545442627

Epoch: 5| Step: 8
Training loss: 2.7871068942427204
Validation loss: 2.5935022181658116

Epoch: 5| Step: 9
Training loss: 2.938719151512244
Validation loss: 2.5868085957860956

Epoch: 5| Step: 10
Training loss: 2.425695543725471
Validation loss: 2.5904612956521933

Epoch: 111| Step: 0
Training loss: 2.0082431435284556
Validation loss: 2.603055197170326

Epoch: 5| Step: 1
Training loss: 2.246800797342081
Validation loss: 2.6053349859910027

Epoch: 5| Step: 2
Training loss: 3.1133178555623235
Validation loss: 2.606340824981223

Epoch: 5| Step: 3
Training loss: 2.65127609405554
Validation loss: 2.617120367323907

Epoch: 5| Step: 4
Training loss: 3.252635620714398
Validation loss: 2.5924971651286897

Epoch: 5| Step: 5
Training loss: 2.335956994425083
Validation loss: 2.5868786348768076

Epoch: 5| Step: 6
Training loss: 3.018624350892598
Validation loss: 2.6113558295057153

Epoch: 5| Step: 7
Training loss: 2.386287469185052
Validation loss: 2.5809377720063607

Epoch: 5| Step: 8
Training loss: 2.530120409184738
Validation loss: 2.587703473472488

Epoch: 5| Step: 9
Training loss: 2.8001364334109384
Validation loss: 2.5808639023479865

Epoch: 5| Step: 10
Training loss: 2.5128291925018895
Validation loss: 2.6063538047562647

Epoch: 112| Step: 0
Training loss: 2.557944644970289
Validation loss: 2.570201723901011

Epoch: 5| Step: 1
Training loss: 2.4837931785420406
Validation loss: 2.6093111929983546

Epoch: 5| Step: 2
Training loss: 3.0156967866091327
Validation loss: 2.597246401307961

Epoch: 5| Step: 3
Training loss: 2.552870171108329
Validation loss: 2.5972444933183434

Epoch: 5| Step: 4
Training loss: 2.2711691535161043
Validation loss: 2.5905357704197196

Epoch: 5| Step: 5
Training loss: 2.525634376227163
Validation loss: 2.578406649232952

Epoch: 5| Step: 6
Training loss: 3.230727640869397
Validation loss: 2.573921117815131

Epoch: 5| Step: 7
Training loss: 2.511613004128487
Validation loss: 2.570262818813699

Epoch: 5| Step: 8
Training loss: 3.15196223827921
Validation loss: 2.5580329346151403

Epoch: 5| Step: 9
Training loss: 2.181913053191119
Validation loss: 2.5891344714581894

Epoch: 5| Step: 10
Training loss: 2.450827524990483
Validation loss: 2.6105437750765863

Epoch: 113| Step: 0
Training loss: 2.883683070616085
Validation loss: 2.594296633636633

Epoch: 5| Step: 1
Training loss: 2.399875371399167
Validation loss: 2.5739815188886053

Epoch: 5| Step: 2
Training loss: 2.689095223298089
Validation loss: 2.5899567010329214

Epoch: 5| Step: 3
Training loss: 2.3944345675641143
Validation loss: 2.557935983711757

Epoch: 5| Step: 4
Training loss: 3.399262707372784
Validation loss: 2.5773240680877643

Epoch: 5| Step: 5
Training loss: 3.1124327686815967
Validation loss: 2.5666616927062624

Epoch: 5| Step: 6
Training loss: 2.3101191249698605
Validation loss: 2.572266726294621

Epoch: 5| Step: 7
Training loss: 2.809346274631109
Validation loss: 2.5767600206408297

Epoch: 5| Step: 8
Training loss: 2.4592680581870376
Validation loss: 2.5832425325481445

Epoch: 5| Step: 9
Training loss: 2.114086286886053
Validation loss: 2.5675039468169314

Epoch: 5| Step: 10
Training loss: 2.2593013513994866
Validation loss: 2.551735153371721

Epoch: 114| Step: 0
Training loss: 2.4515416569306963
Validation loss: 2.6003457181104688

Epoch: 5| Step: 1
Training loss: 2.1697045328119193
Validation loss: 2.5741007740786297

Epoch: 5| Step: 2
Training loss: 2.858830634657508
Validation loss: 2.537598054293531

Epoch: 5| Step: 3
Training loss: 2.441868999113545
Validation loss: 2.560555132451662

Epoch: 5| Step: 4
Training loss: 3.2292365938224217
Validation loss: 2.6110494653352374

Epoch: 5| Step: 5
Training loss: 1.9590095069619518
Validation loss: 2.59261801498529

Epoch: 5| Step: 6
Training loss: 2.750034852240531
Validation loss: 2.5767978030118073

Epoch: 5| Step: 7
Training loss: 2.9494615871671908
Validation loss: 2.590231727106364

Epoch: 5| Step: 8
Training loss: 2.90634548891768
Validation loss: 2.6005710026860442

Epoch: 5| Step: 9
Training loss: 2.6823783687664795
Validation loss: 2.5708185161557737

Epoch: 5| Step: 10
Training loss: 2.7392727829359194
Validation loss: 2.5898759922474324

Epoch: 115| Step: 0
Training loss: 2.4088276519690797
Validation loss: 2.5878960268966877

Epoch: 5| Step: 1
Training loss: 2.737938264924065
Validation loss: 2.622550827718296

Epoch: 5| Step: 2
Training loss: 2.4335994322390526
Validation loss: 2.5947418411897245

Epoch: 5| Step: 3
Training loss: 2.426094170135051
Validation loss: 2.572666339538033

Epoch: 5| Step: 4
Training loss: 2.1020332574944653
Validation loss: 2.5639828759061642

Epoch: 5| Step: 5
Training loss: 2.4250173548441185
Validation loss: 2.5870935289728116

Epoch: 5| Step: 6
Training loss: 2.7019970254832284
Validation loss: 2.5776840752717596

Epoch: 5| Step: 7
Training loss: 2.831931908279202
Validation loss: 2.5764042147799433

Epoch: 5| Step: 8
Training loss: 3.0594245883246587
Validation loss: 2.608405832384356

Epoch: 5| Step: 9
Training loss: 2.5256817643230094
Validation loss: 2.5811129123347376

Epoch: 5| Step: 10
Training loss: 3.1305084507792644
Validation loss: 2.604603690281014

Epoch: 116| Step: 0
Training loss: 2.8417342870577724
Validation loss: 2.5903786529235884

Epoch: 5| Step: 1
Training loss: 2.899371631552106
Validation loss: 2.583069923526124

Epoch: 5| Step: 2
Training loss: 2.6070266481244033
Validation loss: 2.60145327337436

Epoch: 5| Step: 3
Training loss: 2.4229952282577174
Validation loss: 2.5989069875122257

Epoch: 5| Step: 4
Training loss: 2.525957956926182
Validation loss: 2.5678285930313716

Epoch: 5| Step: 5
Training loss: 2.607886340888381
Validation loss: 2.5785792751332384

Epoch: 5| Step: 6
Training loss: 2.015301937265468
Validation loss: 2.5601617032460076

Epoch: 5| Step: 7
Training loss: 2.4255670769294007
Validation loss: 2.5782010213582516

Epoch: 5| Step: 8
Training loss: 2.9141166620615895
Validation loss: 2.587480612601887

Epoch: 5| Step: 9
Training loss: 2.9026294429017794
Validation loss: 2.5766409800650725

Epoch: 5| Step: 10
Training loss: 2.9250102637999342
Validation loss: 2.5645319308129935

Epoch: 117| Step: 0
Training loss: 2.6104315714449933
Validation loss: 2.5696847269137844

Epoch: 5| Step: 1
Training loss: 2.4253063873540355
Validation loss: 2.589017982225684

Epoch: 5| Step: 2
Training loss: 2.8384114553467668
Validation loss: 2.584524394802917

Epoch: 5| Step: 3
Training loss: 2.700485616740653
Validation loss: 2.562468907477517

Epoch: 5| Step: 4
Training loss: 1.9990115703459737
Validation loss: 2.5760478134191076

Epoch: 5| Step: 5
Training loss: 2.7200889359688367
Validation loss: 2.61246951733525

Epoch: 5| Step: 6
Training loss: 2.9683596705775286
Validation loss: 2.627712781723904

Epoch: 5| Step: 7
Training loss: 2.8448817757175884
Validation loss: 2.580951180502846

Epoch: 5| Step: 8
Training loss: 2.8226690617789787
Validation loss: 2.598343861229743

Epoch: 5| Step: 9
Training loss: 2.4625663090022387
Validation loss: 2.5810228416218273

Epoch: 5| Step: 10
Training loss: 2.2900373967211425
Validation loss: 2.589677471647921

Epoch: 118| Step: 0
Training loss: 2.638539139397143
Validation loss: 2.566712549271198

Epoch: 5| Step: 1
Training loss: 2.7501373256727732
Validation loss: 2.5905779931140462

Epoch: 5| Step: 2
Training loss: 2.5226173603442525
Validation loss: 2.5958072259351495

Epoch: 5| Step: 3
Training loss: 2.8497425699251764
Validation loss: 2.5879823695285338

Epoch: 5| Step: 4
Training loss: 2.177311631298749
Validation loss: 2.5820647603897817

Epoch: 5| Step: 5
Training loss: 2.362659719406718
Validation loss: 2.571492955093904

Epoch: 5| Step: 6
Training loss: 3.324367927763205
Validation loss: 2.5912965788915803

Epoch: 5| Step: 7
Training loss: 2.430642286902761
Validation loss: 2.5890988761842735

Epoch: 5| Step: 8
Training loss: 2.388822287239766
Validation loss: 2.5311567374665604

Epoch: 5| Step: 9
Training loss: 2.0484566438131004
Validation loss: 2.5542364992762514

Epoch: 5| Step: 10
Training loss: 3.2554148534749143
Validation loss: 2.5832287399707075

Epoch: 119| Step: 0
Training loss: 2.4676918949230764
Validation loss: 2.5545605083551672

Epoch: 5| Step: 1
Training loss: 2.383964385227464
Validation loss: 2.5809131539883583

Epoch: 5| Step: 2
Training loss: 2.8740196215040075
Validation loss: 2.5870489504023184

Epoch: 5| Step: 3
Training loss: 2.5653819183909112
Validation loss: 2.564628903264751

Epoch: 5| Step: 4
Training loss: 2.4519168284064716
Validation loss: 2.5785258140996286

Epoch: 5| Step: 5
Training loss: 3.2239691631934337
Validation loss: 2.5973291117547155

Epoch: 5| Step: 6
Training loss: 3.0467249124191644
Validation loss: 2.5906337021481733

Epoch: 5| Step: 7
Training loss: 2.3393762086360175
Validation loss: 2.562400378740106

Epoch: 5| Step: 8
Training loss: 3.1318336536766695
Validation loss: 2.560721901744698

Epoch: 5| Step: 9
Training loss: 2.3706231192217526
Validation loss: 2.5986839282901326

Epoch: 5| Step: 10
Training loss: 2.1916281847844985
Validation loss: 2.585232395569727

Epoch: 120| Step: 0
Training loss: 2.572390936345899
Validation loss: 2.5552883253877874

Epoch: 5| Step: 1
Training loss: 2.5467194117664524
Validation loss: 2.588859116903004

Epoch: 5| Step: 2
Training loss: 2.188579402006964
Validation loss: 2.61381066215489

Epoch: 5| Step: 3
Training loss: 2.4489645696766407
Validation loss: 2.571167507269018

Epoch: 5| Step: 4
Training loss: 2.7364882668052486
Validation loss: 2.5842794722749876

Epoch: 5| Step: 5
Training loss: 2.919218599984775
Validation loss: 2.5605761641784

Epoch: 5| Step: 6
Training loss: 2.412418731743738
Validation loss: 2.5814738797789336

Epoch: 5| Step: 7
Training loss: 2.5440723936588845
Validation loss: 2.5506398669148043

Epoch: 5| Step: 8
Training loss: 2.631678034021213
Validation loss: 2.5724935719721573

Epoch: 5| Step: 9
Training loss: 3.044977624369374
Validation loss: 2.6226246639634585

Epoch: 5| Step: 10
Training loss: 2.867949090992619
Validation loss: 2.5705172888583387

Epoch: 121| Step: 0
Training loss: 2.580426477772607
Validation loss: 2.5864055663365697

Epoch: 5| Step: 1
Training loss: 2.691280101815079
Validation loss: 2.5943471322768583

Epoch: 5| Step: 2
Training loss: 2.49494824220107
Validation loss: 2.5695979161108955

Epoch: 5| Step: 3
Training loss: 1.971706169143299
Validation loss: 2.5585850278143187

Epoch: 5| Step: 4
Training loss: 2.941486494329981
Validation loss: 2.589687527004036

Epoch: 5| Step: 5
Training loss: 2.993467530242187
Validation loss: 2.5954490796621403

Epoch: 5| Step: 6
Training loss: 2.838227831555444
Validation loss: 2.6035675350628384

Epoch: 5| Step: 7
Training loss: 2.656833988394538
Validation loss: 2.5321578455423306

Epoch: 5| Step: 8
Training loss: 2.1386498018980786
Validation loss: 2.5739291485982245

Epoch: 5| Step: 9
Training loss: 2.8819479537595245
Validation loss: 2.593815034361616

Epoch: 5| Step: 10
Training loss: 2.4944832968948796
Validation loss: 2.5863682058228146

Epoch: 122| Step: 0
Training loss: 2.302640568421678
Validation loss: 2.5743711869812707

Epoch: 5| Step: 1
Training loss: 3.180067035040468
Validation loss: 2.5534290441498797

Epoch: 5| Step: 2
Training loss: 2.856374364770618
Validation loss: 2.5585739749938634

Epoch: 5| Step: 3
Training loss: 2.6773684061661043
Validation loss: 2.5785140468961325

Epoch: 5| Step: 4
Training loss: 2.8202132527226587
Validation loss: 2.5735793286435147

Epoch: 5| Step: 5
Training loss: 2.881218528989426
Validation loss: 2.581639138874047

Epoch: 5| Step: 6
Training loss: 1.9824100287323085
Validation loss: 2.595341305606423

Epoch: 5| Step: 7
Training loss: 2.696837593606004
Validation loss: 2.588511633540401

Epoch: 5| Step: 8
Training loss: 2.650030956447376
Validation loss: 2.5788164461387693

Epoch: 5| Step: 9
Training loss: 2.172773436095455
Validation loss: 2.6004186252217165

Epoch: 5| Step: 10
Training loss: 2.2636971525767278
Validation loss: 2.5624143904805172

Epoch: 123| Step: 0
Training loss: 2.3287726403946425
Validation loss: 2.554156763543747

Epoch: 5| Step: 1
Training loss: 2.5332847235014717
Validation loss: 2.5769030228412286

Epoch: 5| Step: 2
Training loss: 2.3347730509151816
Validation loss: 2.5594936296027853

Epoch: 5| Step: 3
Training loss: 1.8546175962031533
Validation loss: 2.5925455455980164

Epoch: 5| Step: 4
Training loss: 3.1823356529646403
Validation loss: 2.5663538280160285

Epoch: 5| Step: 5
Training loss: 2.4566129925824107
Validation loss: 2.5639299974199816

Epoch: 5| Step: 6
Training loss: 2.7419603041732508
Validation loss: 2.58787083809196

Epoch: 5| Step: 7
Training loss: 2.9712720899198084
Validation loss: 2.5780431700268185

Epoch: 5| Step: 8
Training loss: 2.6253971526024062
Validation loss: 2.561082769698347

Epoch: 5| Step: 9
Training loss: 3.2342819716486297
Validation loss: 2.6230773818941864

Epoch: 5| Step: 10
Training loss: 2.4650533499370533
Validation loss: 2.5884092319379373

Epoch: 124| Step: 0
Training loss: 2.746291521094483
Validation loss: 2.5925803306622974

Epoch: 5| Step: 1
Training loss: 2.3246977496828207
Validation loss: 2.5839192827126998

Epoch: 5| Step: 2
Training loss: 2.7140216268691155
Validation loss: 2.5468484925099117

Epoch: 5| Step: 3
Training loss: 2.8183404256985978
Validation loss: 2.5833108988994167

Epoch: 5| Step: 4
Training loss: 2.8776773342767186
Validation loss: 2.5826899530827405

Epoch: 5| Step: 5
Training loss: 1.9928459724820284
Validation loss: 2.576124756883369

Epoch: 5| Step: 6
Training loss: 3.051046635884286
Validation loss: 2.577876943498482

Epoch: 5| Step: 7
Training loss: 2.4731928768874094
Validation loss: 2.5564576809444493

Epoch: 5| Step: 8
Training loss: 2.4971034436047588
Validation loss: 2.5799153450407286

Epoch: 5| Step: 9
Training loss: 2.6255036733700057
Validation loss: 2.5714037049097596

Epoch: 5| Step: 10
Training loss: 2.585208017771047
Validation loss: 2.57885901181225

Epoch: 125| Step: 0
Training loss: 2.5629435829862337
Validation loss: 2.569077707170727

Epoch: 5| Step: 1
Training loss: 2.7802947900754083
Validation loss: 2.561479831116544

Epoch: 5| Step: 2
Training loss: 1.9476767883564423
Validation loss: 2.573206920342799

Epoch: 5| Step: 3
Training loss: 2.8045626216704185
Validation loss: 2.5547713916064008

Epoch: 5| Step: 4
Training loss: 1.9069064526509913
Validation loss: 2.5807588936754935

Epoch: 5| Step: 5
Training loss: 2.781940331669996
Validation loss: 2.5564573329694493

Epoch: 5| Step: 6
Training loss: 3.1787895415588503
Validation loss: 2.5417775470009607

Epoch: 5| Step: 7
Training loss: 2.9390465743562744
Validation loss: 2.6127400836630983

Epoch: 5| Step: 8
Training loss: 2.964394999080131
Validation loss: 2.5905449728604655

Epoch: 5| Step: 9
Training loss: 2.069998087490507
Validation loss: 2.5601014938331095

Epoch: 5| Step: 10
Training loss: 2.219748581232906
Validation loss: 2.5781309096043965

Epoch: 126| Step: 0
Training loss: 3.1530349521992362
Validation loss: 2.560146184139172

Epoch: 5| Step: 1
Training loss: 2.974587734091092
Validation loss: 2.584240235851353

Epoch: 5| Step: 2
Training loss: 2.3371752263438133
Validation loss: 2.5713145493352734

Epoch: 5| Step: 3
Training loss: 2.6745183707201985
Validation loss: 2.573540596507237

Epoch: 5| Step: 4
Training loss: 2.3231768155932535
Validation loss: 2.597356868851957

Epoch: 5| Step: 5
Training loss: 2.8558578121789937
Validation loss: 2.578741952034176

Epoch: 5| Step: 6
Training loss: 2.4144827961390742
Validation loss: 2.6166287830600057

Epoch: 5| Step: 7
Training loss: 2.0800939425014793
Validation loss: 2.5689690483160446

Epoch: 5| Step: 8
Training loss: 2.466601245459339
Validation loss: 2.6291739664489473

Epoch: 5| Step: 9
Training loss: 2.5728906380473235
Validation loss: 2.583748819426623

Epoch: 5| Step: 10
Training loss: 2.985872701743265
Validation loss: 2.5968071160904254

Epoch: 127| Step: 0
Training loss: 2.985626437654203
Validation loss: 2.586144951330869

Epoch: 5| Step: 1
Training loss: 2.6501512412332078
Validation loss: 2.594827791034991

Epoch: 5| Step: 2
Training loss: 2.3438346338885823
Validation loss: 2.616325576143972

Epoch: 5| Step: 3
Training loss: 2.749548268062549
Validation loss: 2.5478636972070974

Epoch: 5| Step: 4
Training loss: 2.3585815105897754
Validation loss: 2.568855988812158

Epoch: 5| Step: 5
Training loss: 2.67271677777737
Validation loss: 2.5761873353820453

Epoch: 5| Step: 6
Training loss: 1.6622921835288225
Validation loss: 2.564192410370815

Epoch: 5| Step: 7
Training loss: 2.4083114315035834
Validation loss: 2.5972484484716727

Epoch: 5| Step: 8
Training loss: 2.6779777922617596
Validation loss: 2.586875788674494

Epoch: 5| Step: 9
Training loss: 3.3163805130497956
Validation loss: 2.5708952661163926

Epoch: 5| Step: 10
Training loss: 2.5624233327421995
Validation loss: 2.565502957321176

Epoch: 128| Step: 0
Training loss: 2.29965519186352
Validation loss: 2.595589469921965

Epoch: 5| Step: 1
Training loss: 2.1706076018352602
Validation loss: 2.5812758087029577

Epoch: 5| Step: 2
Training loss: 2.1962283793097868
Validation loss: 2.576778820364648

Epoch: 5| Step: 3
Training loss: 3.2067048700109666
Validation loss: 2.5879447529217425

Epoch: 5| Step: 4
Training loss: 1.9340971320375835
Validation loss: 2.5946380996473764

Epoch: 5| Step: 5
Training loss: 2.7763234771389906
Validation loss: 2.56081621088203

Epoch: 5| Step: 6
Training loss: 2.8640463770835574
Validation loss: 2.5674346540520983

Epoch: 5| Step: 7
Training loss: 3.3088678563957292
Validation loss: 2.57991323096063

Epoch: 5| Step: 8
Training loss: 1.8908644595497657
Validation loss: 2.5511694458240837

Epoch: 5| Step: 9
Training loss: 2.813692391143488
Validation loss: 2.5493406631697133

Epoch: 5| Step: 10
Training loss: 3.1384743685913206
Validation loss: 2.5826591051152046

Epoch: 129| Step: 0
Training loss: 2.877166263638263
Validation loss: 2.5955011263628966

Epoch: 5| Step: 1
Training loss: 3.0455045307772672
Validation loss: 2.5552370944661753

Epoch: 5| Step: 2
Training loss: 2.317910849192321
Validation loss: 2.5629663420733935

Epoch: 5| Step: 3
Training loss: 2.781070489126574
Validation loss: 2.552090663702664

Epoch: 5| Step: 4
Training loss: 1.7049502470079116
Validation loss: 2.5839297002875017

Epoch: 5| Step: 5
Training loss: 2.798723600875567
Validation loss: 2.5893778298573342

Epoch: 5| Step: 6
Training loss: 2.815977701499825
Validation loss: 2.5470791429210164

Epoch: 5| Step: 7
Training loss: 2.259582775898346
Validation loss: 2.5638854550605896

Epoch: 5| Step: 8
Training loss: 2.6427425042994184
Validation loss: 2.5517855398701874

Epoch: 5| Step: 9
Training loss: 2.5569531954172895
Validation loss: 2.583136473295765

Epoch: 5| Step: 10
Training loss: 2.509539713507127
Validation loss: 2.5496548946932442

Epoch: 130| Step: 0
Training loss: 3.2865456127702437
Validation loss: 2.615014504505566

Epoch: 5| Step: 1
Training loss: 2.2599391755215192
Validation loss: 2.5924601327009786

Epoch: 5| Step: 2
Training loss: 2.8266015770753583
Validation loss: 2.57236080202423

Epoch: 5| Step: 3
Training loss: 2.8876741761358695
Validation loss: 2.561328942497286

Epoch: 5| Step: 4
Training loss: 2.1133275053423275
Validation loss: 2.572342535093708

Epoch: 5| Step: 5
Training loss: 2.7126165901125088
Validation loss: 2.620249394592067

Epoch: 5| Step: 6
Training loss: 2.960232371410904
Validation loss: 2.5333296328772876

Epoch: 5| Step: 7
Training loss: 1.9985342615248118
Validation loss: 2.578938933134633

Epoch: 5| Step: 8
Training loss: 1.98299281726023
Validation loss: 2.614971888158196

Epoch: 5| Step: 9
Training loss: 2.3411409224535418
Validation loss: 2.555836297610753

Epoch: 5| Step: 10
Training loss: 3.0356138613462935
Validation loss: 2.6224072265247163

Epoch: 131| Step: 0
Training loss: 2.6646268811717406
Validation loss: 2.5957020114267997

Epoch: 5| Step: 1
Training loss: 2.8450592715989473
Validation loss: 2.5904462836628057

Epoch: 5| Step: 2
Training loss: 2.5483294119678943
Validation loss: 2.587637385436026

Epoch: 5| Step: 3
Training loss: 2.4445269117990427
Validation loss: 2.5832921983167605

Epoch: 5| Step: 4
Training loss: 2.4996785910946344
Validation loss: 2.553801773222929

Epoch: 5| Step: 5
Training loss: 3.038289655858695
Validation loss: 2.537314308679072

Epoch: 5| Step: 6
Training loss: 2.4947158281642934
Validation loss: 2.569510707279804

Epoch: 5| Step: 7
Training loss: 2.4229532118250066
Validation loss: 2.536383510224744

Epoch: 5| Step: 8
Training loss: 2.2391084270997967
Validation loss: 2.5840510926943865

Epoch: 5| Step: 9
Training loss: 2.9992118435914557
Validation loss: 2.553442869682992

Epoch: 5| Step: 10
Training loss: 2.720273785696346
Validation loss: 2.561538353775301

Epoch: 132| Step: 0
Training loss: 2.280354049532011
Validation loss: 2.581625327799992

Epoch: 5| Step: 1
Training loss: 1.7556988024247826
Validation loss: 2.574522790436755

Epoch: 5| Step: 2
Training loss: 2.9171062864779005
Validation loss: 2.5371981522233065

Epoch: 5| Step: 3
Training loss: 3.1628720151399223
Validation loss: 2.5546756837061104

Epoch: 5| Step: 4
Training loss: 2.512692371044965
Validation loss: 2.537958692952212

Epoch: 5| Step: 5
Training loss: 3.135088999578532
Validation loss: 2.587510120034596

Epoch: 5| Step: 6
Training loss: 2.300223057752765
Validation loss: 2.610300433586759

Epoch: 5| Step: 7
Training loss: 2.5644891043446627
Validation loss: 2.5844250283297723

Epoch: 5| Step: 8
Training loss: 2.6144485033588034
Validation loss: 2.6253767900429983

Epoch: 5| Step: 9
Training loss: 2.465242622614353
Validation loss: 2.5776486689803906

Epoch: 5| Step: 10
Training loss: 2.7738633379616937
Validation loss: 2.575422914563201

Epoch: 133| Step: 0
Training loss: 2.5044837797419897
Validation loss: 2.606933542121859

Epoch: 5| Step: 1
Training loss: 2.8239507904195897
Validation loss: 2.5911168962185003

Epoch: 5| Step: 2
Training loss: 2.142873654983117
Validation loss: 2.5152277142643817

Epoch: 5| Step: 3
Training loss: 2.8687992399224265
Validation loss: 2.586439566194994

Epoch: 5| Step: 4
Training loss: 2.9535607717812375
Validation loss: 2.577792459260935

Epoch: 5| Step: 5
Training loss: 2.6738459584412593
Validation loss: 2.605858440233816

Epoch: 5| Step: 6
Training loss: 2.8405955498808573
Validation loss: 2.5744764995147675

Epoch: 5| Step: 7
Training loss: 2.5877302242448805
Validation loss: 2.572306982525131

Epoch: 5| Step: 8
Training loss: 1.8077556736355507
Validation loss: 2.590083443870147

Epoch: 5| Step: 9
Training loss: 3.1146234277974703
Validation loss: 2.5734260612472806

Epoch: 5| Step: 10
Training loss: 1.6731025253684506
Validation loss: 2.5896653591363457

Epoch: 134| Step: 0
Training loss: 2.62621370140675
Validation loss: 2.5667466581728817

Epoch: 5| Step: 1
Training loss: 2.427720527885641
Validation loss: 2.574162319224043

Epoch: 5| Step: 2
Training loss: 2.3901739754661384
Validation loss: 2.5800758217667807

Epoch: 5| Step: 3
Training loss: 2.913761235841013
Validation loss: 2.5933424699542607

Epoch: 5| Step: 4
Training loss: 2.701004519625812
Validation loss: 2.587150544742761

Epoch: 5| Step: 5
Training loss: 3.2031449480133425
Validation loss: 2.601828274831117

Epoch: 5| Step: 6
Training loss: 2.4256683175893583
Validation loss: 2.534349899903093

Epoch: 5| Step: 7
Training loss: 2.633163655122059
Validation loss: 2.5834698781563623

Epoch: 5| Step: 8
Training loss: 2.43165513612638
Validation loss: 2.5361827842085973

Epoch: 5| Step: 9
Training loss: 2.4597920007307796
Validation loss: 2.5682655869145323

Epoch: 5| Step: 10
Training loss: 2.0596130279843163
Validation loss: 2.5476056018668776

Epoch: 135| Step: 0
Training loss: 2.2178004207338575
Validation loss: 2.596964616627206

Epoch: 5| Step: 1
Training loss: 2.39236795553315
Validation loss: 2.5474019932522975

Epoch: 5| Step: 2
Training loss: 2.6540630537935535
Validation loss: 2.5677066283713423

Epoch: 5| Step: 3
Training loss: 2.4314780552458397
Validation loss: 2.5723012090358197

Epoch: 5| Step: 4
Training loss: 1.9835504335569563
Validation loss: 2.6019528639413934

Epoch: 5| Step: 5
Training loss: 2.994182031473313
Validation loss: 2.576340453435177

Epoch: 5| Step: 6
Training loss: 2.4452452239023166
Validation loss: 2.5734512190962375

Epoch: 5| Step: 7
Training loss: 2.506761277100856
Validation loss: 2.587074496020867

Epoch: 5| Step: 8
Training loss: 2.996436386708766
Validation loss: 2.5604681217522183

Epoch: 5| Step: 9
Training loss: 3.071811921412147
Validation loss: 2.5674248088534366

Epoch: 5| Step: 10
Training loss: 2.9004506320076158
Validation loss: 2.622909965885483

Epoch: 136| Step: 0
Training loss: 2.533217901394115
Validation loss: 2.57968367279318

Epoch: 5| Step: 1
Training loss: 3.2537418246084084
Validation loss: 2.5691813352976065

Epoch: 5| Step: 2
Training loss: 2.247118694475881
Validation loss: 2.576651871809378

Epoch: 5| Step: 3
Training loss: 2.1335585410734
Validation loss: 2.5758534984753627

Epoch: 5| Step: 4
Training loss: 2.4943598066195563
Validation loss: 2.5731710529319725

Epoch: 5| Step: 5
Training loss: 2.698066962534486
Validation loss: 2.5874882426368058

Epoch: 5| Step: 6
Training loss: 3.060355233410508
Validation loss: 2.56041910162098

Epoch: 5| Step: 7
Training loss: 2.425588308330581
Validation loss: 2.563639521750094

Epoch: 5| Step: 8
Training loss: 2.655045988183884
Validation loss: 2.55520778020727

Epoch: 5| Step: 9
Training loss: 1.994237406116673
Validation loss: 2.5366818407747633

Epoch: 5| Step: 10
Training loss: 3.0134878541212067
Validation loss: 2.60538401118981

Epoch: 137| Step: 0
Training loss: 2.588635192859868
Validation loss: 2.5604906510332843

Epoch: 5| Step: 1
Training loss: 2.484939223223625
Validation loss: 2.543585484850133

Epoch: 5| Step: 2
Training loss: 2.7617712380089974
Validation loss: 2.5345792925533064

Epoch: 5| Step: 3
Training loss: 3.0014393850214613
Validation loss: 2.5487003424983223

Epoch: 5| Step: 4
Training loss: 2.1671500644874726
Validation loss: 2.5549911805729475

Epoch: 5| Step: 5
Training loss: 2.3699680025218264
Validation loss: 2.5836852869629237

Epoch: 5| Step: 6
Training loss: 2.6556905718343917
Validation loss: 2.558044980936931

Epoch: 5| Step: 7
Training loss: 2.4625573049935707
Validation loss: 2.5519749899479716

Epoch: 5| Step: 8
Training loss: 3.3490063004843083
Validation loss: 2.5732839268347196

Epoch: 5| Step: 9
Training loss: 2.1349772551707513
Validation loss: 2.546740466652056

Epoch: 5| Step: 10
Training loss: 2.405628966409729
Validation loss: 2.540368488116374

Epoch: 138| Step: 0
Training loss: 2.751701955386091
Validation loss: 2.55553179755573

Epoch: 5| Step: 1
Training loss: 2.5482280857996797
Validation loss: 2.5742664925597145

Epoch: 5| Step: 2
Training loss: 2.486647040806998
Validation loss: 2.543911255629836

Epoch: 5| Step: 3
Training loss: 2.805536338270318
Validation loss: 2.6022522581735115

Epoch: 5| Step: 4
Training loss: 3.4259923959036382
Validation loss: 2.5604296828958333

Epoch: 5| Step: 5
Training loss: 2.6286261807538422
Validation loss: 2.5793306109116823

Epoch: 5| Step: 6
Training loss: 2.9641960150168702
Validation loss: 2.5767567608208277

Epoch: 5| Step: 7
Training loss: 1.6874016627163464
Validation loss: 2.6005303568844207

Epoch: 5| Step: 8
Training loss: 2.3804419560766443
Validation loss: 2.549153615998069

Epoch: 5| Step: 9
Training loss: 2.2768310179063227
Validation loss: 2.5809272609042564

Epoch: 5| Step: 10
Training loss: 2.1311064104053328
Validation loss: 2.5946360197944283

Epoch: 139| Step: 0
Training loss: 2.664258127497049
Validation loss: 2.5667834972751513

Epoch: 5| Step: 1
Training loss: 2.67423737252271
Validation loss: 2.5738006470854895

Epoch: 5| Step: 2
Training loss: 2.179127173372847
Validation loss: 2.5959442095108884

Epoch: 5| Step: 3
Training loss: 2.2110857694804107
Validation loss: 2.564111480512017

Epoch: 5| Step: 4
Training loss: 2.0942640669861303
Validation loss: 2.5726609863790904

Epoch: 5| Step: 5
Training loss: 2.8171378149812645
Validation loss: 2.5073169531332864

Epoch: 5| Step: 6
Training loss: 3.2919187489491013
Validation loss: 2.5019072753340628

Epoch: 5| Step: 7
Training loss: 2.0978328694412025
Validation loss: 2.5506443013991853

Epoch: 5| Step: 8
Training loss: 2.657828097827495
Validation loss: 2.564828752434477

Epoch: 5| Step: 9
Training loss: 2.9348317466221885
Validation loss: 2.578994229561761

Epoch: 5| Step: 10
Training loss: 2.433098462496811
Validation loss: 2.558703635970883

Epoch: 140| Step: 0
Training loss: 2.6871356273532716
Validation loss: 2.5280961057073816

Epoch: 5| Step: 1
Training loss: 2.510642288220657
Validation loss: 2.5593330778630894

Epoch: 5| Step: 2
Training loss: 2.5341842974729265
Validation loss: 2.5573419841195872

Epoch: 5| Step: 3
Training loss: 2.0359247261401965
Validation loss: 2.5366873517209827

Epoch: 5| Step: 4
Training loss: 2.2788919254201945
Validation loss: 2.5968407882439504

Epoch: 5| Step: 5
Training loss: 2.900838099425259
Validation loss: 2.559346847963321

Epoch: 5| Step: 6
Training loss: 2.5458482416177413
Validation loss: 2.553454794590695

Epoch: 5| Step: 7
Training loss: 2.542914277180347
Validation loss: 2.536581831140283

Epoch: 5| Step: 8
Training loss: 2.750295016329951
Validation loss: 2.5455419435240985

Epoch: 5| Step: 9
Training loss: 2.3949065917720023
Validation loss: 2.5265290426453353

Epoch: 5| Step: 10
Training loss: 3.0940292694739213
Validation loss: 2.5697157376147657

Epoch: 141| Step: 0
Training loss: 2.480980911845681
Validation loss: 2.5582444996622486

Epoch: 5| Step: 1
Training loss: 2.416747343974826
Validation loss: 2.5618610470867527

Epoch: 5| Step: 2
Training loss: 1.9216847519410918
Validation loss: 2.5371985978193354

Epoch: 5| Step: 3
Training loss: 2.1992892157477595
Validation loss: 2.5356018280563353

Epoch: 5| Step: 4
Training loss: 2.934438530474909
Validation loss: 2.5541011466927857

Epoch: 5| Step: 5
Training loss: 1.97335730455419
Validation loss: 2.617761443766779

Epoch: 5| Step: 6
Training loss: 3.3284272965520243
Validation loss: 2.571464042987395

Epoch: 5| Step: 7
Training loss: 2.646926854153744
Validation loss: 2.541620566442412

Epoch: 5| Step: 8
Training loss: 2.3999084534669177
Validation loss: 2.5349364605167497

Epoch: 5| Step: 9
Training loss: 2.9466214698961637
Validation loss: 2.5582991881912935

Epoch: 5| Step: 10
Training loss: 3.2423291278836808
Validation loss: 2.582929923732158

Epoch: 142| Step: 0
Training loss: 2.0186127985104174
Validation loss: 2.5529924458978233

Epoch: 5| Step: 1
Training loss: 2.855772657177462
Validation loss: 2.5532592823273683

Epoch: 5| Step: 2
Training loss: 2.1973807478522
Validation loss: 2.570966595275706

Epoch: 5| Step: 3
Training loss: 3.35744985376831
Validation loss: 2.5852916220620803

Epoch: 5| Step: 4
Training loss: 2.584447425648501
Validation loss: 2.5693649678427515

Epoch: 5| Step: 5
Training loss: 2.9510130419803278
Validation loss: 2.5889595569091304

Epoch: 5| Step: 6
Training loss: 2.772192877225764
Validation loss: 2.574516823757204

Epoch: 5| Step: 7
Training loss: 2.3313959684516585
Validation loss: 2.610219831820208

Epoch: 5| Step: 8
Training loss: 2.650761667590181
Validation loss: 2.548671841241287

Epoch: 5| Step: 9
Training loss: 2.142802224136688
Validation loss: 2.5975078388939763

Epoch: 5| Step: 10
Training loss: 2.4966134976411554
Validation loss: 2.553402059521659

Epoch: 143| Step: 0
Training loss: 2.7945724471470617
Validation loss: 2.621023685246376

Epoch: 5| Step: 1
Training loss: 2.1658350987101227
Validation loss: 2.5967192888299344

Epoch: 5| Step: 2
Training loss: 2.6402840478849288
Validation loss: 2.5891593776602804

Epoch: 5| Step: 3
Training loss: 2.6794175437430914
Validation loss: 2.555755635787826

Epoch: 5| Step: 4
Training loss: 2.5003836337425205
Validation loss: 2.5409564359530243

Epoch: 5| Step: 5
Training loss: 2.2862804810007837
Validation loss: 2.563067157607786

Epoch: 5| Step: 6
Training loss: 2.85232709275342
Validation loss: 2.5637497014303197

Epoch: 5| Step: 7
Training loss: 2.3474098622137256
Validation loss: 2.598837487635178

Epoch: 5| Step: 8
Training loss: 3.016522684050885
Validation loss: 2.602325777821799

Epoch: 5| Step: 9
Training loss: 2.134493211011172
Validation loss: 2.5646355117087185

Epoch: 5| Step: 10
Training loss: 2.7714946980515993
Validation loss: 2.5555990794867

Epoch: 144| Step: 0
Training loss: 2.7978847961049773
Validation loss: 2.5526843617453654

Epoch: 5| Step: 1
Training loss: 2.50818058533129
Validation loss: 2.5594302062230883

Epoch: 5| Step: 2
Training loss: 2.679362463631476
Validation loss: 2.5459205939927836

Epoch: 5| Step: 3
Training loss: 2.5120918625660287
Validation loss: 2.59609834565945

Epoch: 5| Step: 4
Training loss: 2.9927017128633606
Validation loss: 2.5408513988879275

Epoch: 5| Step: 5
Training loss: 2.523841660201575
Validation loss: 2.516256276756822

Epoch: 5| Step: 6
Training loss: 1.8273428523472037
Validation loss: 2.5752524692495973

Epoch: 5| Step: 7
Training loss: 2.833413927016581
Validation loss: 2.600531476769496

Epoch: 5| Step: 8
Training loss: 2.8667013395415637
Validation loss: 2.533358950342386

Epoch: 5| Step: 9
Training loss: 2.6349427974507154
Validation loss: 2.523888590334036

Epoch: 5| Step: 10
Training loss: 2.45614137288003
Validation loss: 2.524211942875733

Epoch: 145| Step: 0
Training loss: 2.553577987098465
Validation loss: 2.518489176542195

Epoch: 5| Step: 1
Training loss: 3.1277529987854114
Validation loss: 2.57780009360641

Epoch: 5| Step: 2
Training loss: 2.5800224950829937
Validation loss: 2.5723745691586632

Epoch: 5| Step: 3
Training loss: 2.252709664463431
Validation loss: 2.5537768037723816

Epoch: 5| Step: 4
Training loss: 3.2662506234321333
Validation loss: 2.556774633406929

Epoch: 5| Step: 5
Training loss: 2.5396516556555495
Validation loss: 2.558510594949019

Epoch: 5| Step: 6
Training loss: 2.0898112356918688
Validation loss: 2.5659781181124917

Epoch: 5| Step: 7
Training loss: 1.979136242549018
Validation loss: 2.5704124399586474

Epoch: 5| Step: 8
Training loss: 2.8850750405322136
Validation loss: 2.573756611226612

Epoch: 5| Step: 9
Training loss: 2.492829243179451
Validation loss: 2.595925045913315

Epoch: 5| Step: 10
Training loss: 2.4152644353430652
Validation loss: 2.545223375718074

Epoch: 146| Step: 0
Training loss: 1.9449233926038152
Validation loss: 2.5484240906837807

Epoch: 5| Step: 1
Training loss: 2.4801219307243274
Validation loss: 2.5772377453819044

Epoch: 5| Step: 2
Training loss: 2.5820898837128077
Validation loss: 2.5691920311587335

Epoch: 5| Step: 3
Training loss: 2.427448970992985
Validation loss: 2.5578835013901

Epoch: 5| Step: 4
Training loss: 2.9805497024761496
Validation loss: 2.56020595892021

Epoch: 5| Step: 5
Training loss: 2.4241241839862924
Validation loss: 2.571337507510262

Epoch: 5| Step: 6
Training loss: 2.426249828938041
Validation loss: 2.591993731385554

Epoch: 5| Step: 7
Training loss: 3.642070957906608
Validation loss: 2.5955368076733145

Epoch: 5| Step: 8
Training loss: 2.186564872318435
Validation loss: 2.5714684968916415

Epoch: 5| Step: 9
Training loss: 2.1681919842135096
Validation loss: 2.568423166788608

Epoch: 5| Step: 10
Training loss: 2.243005583383292
Validation loss: 2.5508438271271374

Epoch: 147| Step: 0
Training loss: 2.712070459204498
Validation loss: 2.545816023814596

Epoch: 5| Step: 1
Training loss: 2.0602917264645866
Validation loss: 2.592452480710399

Epoch: 5| Step: 2
Training loss: 2.603268542230384
Validation loss: 2.598495918368889

Epoch: 5| Step: 3
Training loss: 2.9559406400922574
Validation loss: 2.5904151401132838

Epoch: 5| Step: 4
Training loss: 2.529960115291749
Validation loss: 2.556165403363344

Epoch: 5| Step: 5
Training loss: 2.9632187562925627
Validation loss: 2.5295196740414734

Epoch: 5| Step: 6
Training loss: 2.2341760933646455
Validation loss: 2.5921777159692825

Epoch: 5| Step: 7
Training loss: 2.285757132537338
Validation loss: 2.5746506276055534

Epoch: 5| Step: 8
Training loss: 2.5744849199100464
Validation loss: 2.5677274282978026

Epoch: 5| Step: 9
Training loss: 2.3664954656367705
Validation loss: 2.579399559008856

Epoch: 5| Step: 10
Training loss: 3.080223800900716
Validation loss: 2.6240497672070875

Epoch: 148| Step: 0
Training loss: 2.9424928479362955
Validation loss: 2.5580725599853342

Epoch: 5| Step: 1
Training loss: 1.9251564977865692
Validation loss: 2.554951980014663

Epoch: 5| Step: 2
Training loss: 2.895505012909692
Validation loss: 2.5766159538520457

Epoch: 5| Step: 3
Training loss: 2.589296308974967
Validation loss: 2.520901490844956

Epoch: 5| Step: 4
Training loss: 2.6404851391111714
Validation loss: 2.5291368238823124

Epoch: 5| Step: 5
Training loss: 2.4698385422172
Validation loss: 2.521406889667647

Epoch: 5| Step: 6
Training loss: 2.2028797635423754
Validation loss: 2.5825534318783734

Epoch: 5| Step: 7
Training loss: 2.404057085613033
Validation loss: 2.570359673796359

Epoch: 5| Step: 8
Training loss: 2.675793100595336
Validation loss: 2.572614883181902

Epoch: 5| Step: 9
Training loss: 3.056686644771382
Validation loss: 2.5507066929328266

Epoch: 5| Step: 10
Training loss: 2.427918210055025
Validation loss: 2.555869710108686

Epoch: 149| Step: 0
Training loss: 2.494170449361621
Validation loss: 2.531129587809414

Epoch: 5| Step: 1
Training loss: 2.596900038248447
Validation loss: 2.575798553636895

Epoch: 5| Step: 2
Training loss: 2.9377366640244187
Validation loss: 2.5566479309384254

Epoch: 5| Step: 3
Training loss: 2.84384373101668
Validation loss: 2.564061305236328

Epoch: 5| Step: 4
Training loss: 1.7984507410272907
Validation loss: 2.5336156020617024

Epoch: 5| Step: 5
Training loss: 2.5045625061715984
Validation loss: 2.5541193247702543

Epoch: 5| Step: 6
Training loss: 3.0324110186951425
Validation loss: 2.5855700713231076

Epoch: 5| Step: 7
Training loss: 2.892443110929475
Validation loss: 2.531957220415117

Epoch: 5| Step: 8
Training loss: 2.2053790094142083
Validation loss: 2.538344162515029

Epoch: 5| Step: 9
Training loss: 2.027046549333607
Validation loss: 2.5460735333067572

Epoch: 5| Step: 10
Training loss: 2.674800409019032
Validation loss: 2.5348879064138843

Epoch: 150| Step: 0
Training loss: 2.4059773080061717
Validation loss: 2.598709961303665

Epoch: 5| Step: 1
Training loss: 2.4562204839665625
Validation loss: 2.5712183315446944

Epoch: 5| Step: 2
Training loss: 2.746230142388762
Validation loss: 2.630576212881732

Epoch: 5| Step: 3
Training loss: 2.3345757537270315
Validation loss: 2.5613565662574325

Epoch: 5| Step: 4
Training loss: 2.6166787635215836
Validation loss: 2.517215222827382

Epoch: 5| Step: 5
Training loss: 2.223074446289169
Validation loss: 2.5431219930937505

Epoch: 5| Step: 6
Training loss: 2.405240230973835
Validation loss: 2.566762699687322

Epoch: 5| Step: 7
Training loss: 1.95483677429023
Validation loss: 2.5480925352895047

Epoch: 5| Step: 8
Training loss: 2.8848651308371625
Validation loss: 2.563428046935938

Epoch: 5| Step: 9
Training loss: 2.768082986574417
Validation loss: 2.5743140350632383

Epoch: 5| Step: 10
Training loss: 2.924235486923616
Validation loss: 2.5271630593533896

Epoch: 151| Step: 0
Training loss: 2.5175320996205053
Validation loss: 2.5281677368629105

Epoch: 5| Step: 1
Training loss: 2.5491081697806934
Validation loss: 2.589083821639273

Epoch: 5| Step: 2
Training loss: 2.319050352483429
Validation loss: 2.5532236206689705

Epoch: 5| Step: 3
Training loss: 2.4783847975715925
Validation loss: 2.563510777461437

Epoch: 5| Step: 4
Training loss: 3.2034751142497093
Validation loss: 2.577568123325994

Epoch: 5| Step: 5
Training loss: 2.4887166024174863
Validation loss: 2.556370036880152

Epoch: 5| Step: 6
Training loss: 1.8975243275607014
Validation loss: 2.5525429605370715

Epoch: 5| Step: 7
Training loss: 2.6973316535353633
Validation loss: 2.5054933317087293

Epoch: 5| Step: 8
Training loss: 2.279246979390409
Validation loss: 2.570649997448854

Epoch: 5| Step: 9
Training loss: 2.512459700531663
Validation loss: 2.5810663293936287

Epoch: 5| Step: 10
Training loss: 2.900772018274093
Validation loss: 2.61041140837704

Epoch: 152| Step: 0
Training loss: 2.191182987039291
Validation loss: 2.553693093322402

Epoch: 5| Step: 1
Training loss: 2.956235670252582
Validation loss: 2.518401470339047

Epoch: 5| Step: 2
Training loss: 3.3483357580039126
Validation loss: 2.583362889459841

Epoch: 5| Step: 3
Training loss: 2.7436093722303356
Validation loss: 2.557757527396858

Epoch: 5| Step: 4
Training loss: 2.6844996182488865
Validation loss: 2.5589375878349925

Epoch: 5| Step: 5
Training loss: 2.9473418269535125
Validation loss: 2.5647664995296853

Epoch: 5| Step: 6
Training loss: 2.1916409127157
Validation loss: 2.5852813081465396

Epoch: 5| Step: 7
Training loss: 2.1480632664120463
Validation loss: 2.588556338448767

Epoch: 5| Step: 8
Training loss: 2.4243952282157326
Validation loss: 2.528784115549195

Epoch: 5| Step: 9
Training loss: 2.042729146703197
Validation loss: 2.5395757285518257

Epoch: 5| Step: 10
Training loss: 2.045424784819526
Validation loss: 2.532984759092247

Epoch: 153| Step: 0
Training loss: 1.8772252547466741
Validation loss: 2.5797716209130206

Epoch: 5| Step: 1
Training loss: 3.4458875111414935
Validation loss: 2.567412009714213

Epoch: 5| Step: 2
Training loss: 2.887279987623076
Validation loss: 2.5956578863832247

Epoch: 5| Step: 3
Training loss: 2.168933330779321
Validation loss: 2.583323034754882

Epoch: 5| Step: 4
Training loss: 2.8755006768841547
Validation loss: 2.5659742696185925

Epoch: 5| Step: 5
Training loss: 2.8540596675075594
Validation loss: 2.5740176498934035

Epoch: 5| Step: 6
Training loss: 2.0950261113034983
Validation loss: 2.607419992154099

Epoch: 5| Step: 7
Training loss: 2.7872197236936618
Validation loss: 2.565060238701244

Epoch: 5| Step: 8
Training loss: 2.12497610190922
Validation loss: 2.6036743305734533

Epoch: 5| Step: 9
Training loss: 1.7905093010876805
Validation loss: 2.5966538730550335

Epoch: 5| Step: 10
Training loss: 2.7454361759090284
Validation loss: 2.5343548929459687

Epoch: 154| Step: 0
Training loss: 2.4294548291240465
Validation loss: 2.575159130322664

Epoch: 5| Step: 1
Training loss: 3.0317188962100703
Validation loss: 2.571283131188755

Epoch: 5| Step: 2
Training loss: 2.596681891100043
Validation loss: 2.552816905774633

Epoch: 5| Step: 3
Training loss: 2.0103940287157145
Validation loss: 2.603868664498128

Epoch: 5| Step: 4
Training loss: 2.04146869504061
Validation loss: 2.5635640306058094

Epoch: 5| Step: 5
Training loss: 2.4925762578840365
Validation loss: 2.5525759933189764

Epoch: 5| Step: 6
Training loss: 2.7822849191240824
Validation loss: 2.572389842080647

Epoch: 5| Step: 7
Training loss: 3.0297859038199118
Validation loss: 2.569712665892038

Epoch: 5| Step: 8
Training loss: 2.771178623187052
Validation loss: 2.5713121016608893

Epoch: 5| Step: 9
Training loss: 2.141645202331249
Validation loss: 2.5921197011033983

Epoch: 5| Step: 10
Training loss: 2.7468733786446884
Validation loss: 2.582864296681762

Epoch: 155| Step: 0
Training loss: 2.769158901908183
Validation loss: 2.572504761307971

Epoch: 5| Step: 1
Training loss: 2.399599769122225
Validation loss: 2.564863909899709

Epoch: 5| Step: 2
Training loss: 2.289578949146279
Validation loss: 2.5636476207408196

Epoch: 5| Step: 3
Training loss: 2.383736853240736
Validation loss: 2.575460912894426

Epoch: 5| Step: 4
Training loss: 3.0829722390646435
Validation loss: 2.606236650994348

Epoch: 5| Step: 5
Training loss: 2.68139291662517
Validation loss: 2.5538837269388717

Epoch: 5| Step: 6
Training loss: 2.545561375636535
Validation loss: 2.609041757263659

Epoch: 5| Step: 7
Training loss: 2.4549131254530634
Validation loss: 2.551528978610797

Epoch: 5| Step: 8
Training loss: 2.7422281028589017
Validation loss: 2.5745364643571604

Epoch: 5| Step: 9
Training loss: 2.5658499987280825
Validation loss: 2.576529520857108

Epoch: 5| Step: 10
Training loss: 2.0930824923819347
Validation loss: 2.539042904054861

Epoch: 156| Step: 0
Training loss: 2.5588306113526182
Validation loss: 2.594924148023825

Epoch: 5| Step: 1
Training loss: 2.7645359804706637
Validation loss: 2.5640452378224916

Epoch: 5| Step: 2
Training loss: 2.775360386446813
Validation loss: 2.5361226150613656

Epoch: 5| Step: 3
Training loss: 1.8962460023338712
Validation loss: 2.5498114831671543

Epoch: 5| Step: 4
Training loss: 1.5660489785535954
Validation loss: 2.567127654259641

Epoch: 5| Step: 5
Training loss: 2.963436953946733
Validation loss: 2.5245370067365043

Epoch: 5| Step: 6
Training loss: 2.3682156083307753
Validation loss: 2.5701008829983847

Epoch: 5| Step: 7
Training loss: 2.6779158271284516
Validation loss: 2.547965513776078

Epoch: 5| Step: 8
Training loss: 2.8511143162346686
Validation loss: 2.5484718165172624

Epoch: 5| Step: 9
Training loss: 2.5505971097274265
Validation loss: 2.5183617521461295

Epoch: 5| Step: 10
Training loss: 2.8741555010220265
Validation loss: 2.563179720316524

Epoch: 157| Step: 0
Training loss: 2.4179865970476753
Validation loss: 2.550969317460147

Epoch: 5| Step: 1
Training loss: 2.0484535012976886
Validation loss: 2.5678819453200328

Epoch: 5| Step: 2
Training loss: 2.867196813251223
Validation loss: 2.561729277230339

Epoch: 5| Step: 3
Training loss: 2.8554241630945274
Validation loss: 2.5770453177631274

Epoch: 5| Step: 4
Training loss: 2.302034150255567
Validation loss: 2.522267929959071

Epoch: 5| Step: 5
Training loss: 2.8044149537340317
Validation loss: 2.5300639929074005

Epoch: 5| Step: 6
Training loss: 2.6328419307342905
Validation loss: 2.577226436338187

Epoch: 5| Step: 7
Training loss: 2.831881394203324
Validation loss: 2.5760110460972037

Epoch: 5| Step: 8
Training loss: 2.4329552953386155
Validation loss: 2.5773464967765203

Epoch: 5| Step: 9
Training loss: 2.001369246028267
Validation loss: 2.5136566522430552

Epoch: 5| Step: 10
Training loss: 2.7470735237327926
Validation loss: 2.5218000362699207

Epoch: 158| Step: 0
Training loss: 2.3249010126514915
Validation loss: 2.547420160261609

Epoch: 5| Step: 1
Training loss: 2.4569808882023185
Validation loss: 2.585362859443697

Epoch: 5| Step: 2
Training loss: 2.5507241398959435
Validation loss: 2.5269877854208294

Epoch: 5| Step: 3
Training loss: 2.2549085058018106
Validation loss: 2.569705393107447

Epoch: 5| Step: 4
Training loss: 2.5002899001837644
Validation loss: 2.539636948997462

Epoch: 5| Step: 5
Training loss: 2.4458538589612733
Validation loss: 2.55480034962684

Epoch: 5| Step: 6
Training loss: 2.315216633854384
Validation loss: 2.555831111818711

Epoch: 5| Step: 7
Training loss: 3.007412019300483
Validation loss: 2.5368574686305667

Epoch: 5| Step: 8
Training loss: 2.939394725333493
Validation loss: 2.5328960568612007

Epoch: 5| Step: 9
Training loss: 2.52964270153281
Validation loss: 2.5887270902469015

Epoch: 5| Step: 10
Training loss: 2.8429581095010756
Validation loss: 2.5757061113723263

Epoch: 159| Step: 0
Training loss: 1.8383060192639407
Validation loss: 2.5470966338553365

Epoch: 5| Step: 1
Training loss: 2.580463989881698
Validation loss: 2.5474818629195086

Epoch: 5| Step: 2
Training loss: 2.9354075019933417
Validation loss: 2.576151942354557

Epoch: 5| Step: 3
Training loss: 2.975491228339744
Validation loss: 2.557775871427579

Epoch: 5| Step: 4
Training loss: 2.1833672858163258
Validation loss: 2.516146056154715

Epoch: 5| Step: 5
Training loss: 2.854596757621049
Validation loss: 2.576290581009167

Epoch: 5| Step: 6
Training loss: 2.690378466220674
Validation loss: 2.5313950951162427

Epoch: 5| Step: 7
Training loss: 2.0472921863587725
Validation loss: 2.564151079933245

Epoch: 5| Step: 8
Training loss: 2.2795311710128336
Validation loss: 2.5950741047508794

Epoch: 5| Step: 9
Training loss: 2.681755135710596
Validation loss: 2.583220054320763

Epoch: 5| Step: 10
Training loss: 2.6148170782118862
Validation loss: 2.5660469004752247

Epoch: 160| Step: 0
Training loss: 2.697995296397821
Validation loss: 2.5805828282752503

Epoch: 5| Step: 1
Training loss: 2.5637503574023284
Validation loss: 2.5868696988613236

Epoch: 5| Step: 2
Training loss: 2.634855660497184
Validation loss: 2.5851922652454142

Epoch: 5| Step: 3
Training loss: 2.550564112629411
Validation loss: 2.609031837912487

Epoch: 5| Step: 4
Training loss: 2.6398496674592415
Validation loss: 2.5984871180036357

Epoch: 5| Step: 5
Training loss: 2.111362227624098
Validation loss: 2.5471483339715877

Epoch: 5| Step: 6
Training loss: 2.7376081262424417
Validation loss: 2.5569824856556487

Epoch: 5| Step: 7
Training loss: 2.5247302449476496
Validation loss: 2.549082757601157

Epoch: 5| Step: 8
Training loss: 1.8408038636947461
Validation loss: 2.524018982896961

Epoch: 5| Step: 9
Training loss: 2.876731848510539
Validation loss: 2.548073684895357

Epoch: 5| Step: 10
Training loss: 2.5801842066335365
Validation loss: 2.547552080543559

Epoch: 161| Step: 0
Training loss: 2.7177561554820184
Validation loss: 2.5678383251145904

Epoch: 5| Step: 1
Training loss: 2.4315557135651624
Validation loss: 2.5733464309596674

Epoch: 5| Step: 2
Training loss: 2.1032939145867595
Validation loss: 2.559811259731936

Epoch: 5| Step: 3
Training loss: 2.419580172227998
Validation loss: 2.5988958802831563

Epoch: 5| Step: 4
Training loss: 2.6387920451101157
Validation loss: 2.622061212879489

Epoch: 5| Step: 5
Training loss: 2.5129329896638253
Validation loss: 2.5280230964036785

Epoch: 5| Step: 6
Training loss: 2.9961838292154486
Validation loss: 2.6066015982591555

Epoch: 5| Step: 7
Training loss: 2.432995473146441
Validation loss: 2.546593543889882

Epoch: 5| Step: 8
Training loss: 2.7825899646675407
Validation loss: 2.5507428973336888

Epoch: 5| Step: 9
Training loss: 2.649794869310881
Validation loss: 2.5692901069061205

Epoch: 5| Step: 10
Training loss: 2.0539636533542986
Validation loss: 2.5381246127278936

Epoch: 162| Step: 0
Training loss: 2.324972591443683
Validation loss: 2.5433326484639363

Epoch: 5| Step: 1
Training loss: 1.874103586173663
Validation loss: 2.5515946168717343

Epoch: 5| Step: 2
Training loss: 2.0188421553136067
Validation loss: 2.5671576173293027

Epoch: 5| Step: 3
Training loss: 2.688030811496529
Validation loss: 2.5706033091761653

Epoch: 5| Step: 4
Training loss: 2.5119353537654154
Validation loss: 2.5543582981746398

Epoch: 5| Step: 5
Training loss: 2.7014860796558287
Validation loss: 2.534660576698995

Epoch: 5| Step: 6
Training loss: 2.9096567839004064
Validation loss: 2.563816729202493

Epoch: 5| Step: 7
Training loss: 2.724945550777062
Validation loss: 2.53372264752977

Epoch: 5| Step: 8
Training loss: 2.728399144541952
Validation loss: 2.5305841619192595

Epoch: 5| Step: 9
Training loss: 2.754801200298803
Validation loss: 2.5843554415513714

Epoch: 5| Step: 10
Training loss: 2.2950493440330715
Validation loss: 2.5524822083286294

Epoch: 163| Step: 0
Training loss: 2.565638968909426
Validation loss: 2.5605353550720524

Epoch: 5| Step: 1
Training loss: 2.2749481949829007
Validation loss: 2.544763255914724

Epoch: 5| Step: 2
Training loss: 2.4016789206466416
Validation loss: 2.5340089143139664

Epoch: 5| Step: 3
Training loss: 2.532089094321049
Validation loss: 2.5234771464306647

Epoch: 5| Step: 4
Training loss: 2.5544020933726284
Validation loss: 2.621794204594414

Epoch: 5| Step: 5
Training loss: 2.6635932397206954
Validation loss: 2.5283819834237

Epoch: 5| Step: 6
Training loss: 2.4398762784139865
Validation loss: 2.5650338761638216

Epoch: 5| Step: 7
Training loss: 2.7417432637128862
Validation loss: 2.6160182475795515

Epoch: 5| Step: 8
Training loss: 1.9368961377635292
Validation loss: 2.571290941393775

Epoch: 5| Step: 9
Training loss: 2.7833907214737623
Validation loss: 2.581481139270049

Epoch: 5| Step: 10
Training loss: 2.565620104544612
Validation loss: 2.617137568436314

Epoch: 164| Step: 0
Training loss: 2.4694020822517637
Validation loss: 2.5662368331662586

Epoch: 5| Step: 1
Training loss: 3.3655650750707724
Validation loss: 2.543880467504332

Epoch: 5| Step: 2
Training loss: 2.42588877170876
Validation loss: 2.582235725017049

Epoch: 5| Step: 3
Training loss: 1.853141915821495
Validation loss: 2.557386968247172

Epoch: 5| Step: 4
Training loss: 2.2130799174679288
Validation loss: 2.5693409608353974

Epoch: 5| Step: 5
Training loss: 2.771811941089723
Validation loss: 2.560691603570848

Epoch: 5| Step: 6
Training loss: 2.3544444930167754
Validation loss: 2.605782373761191

Epoch: 5| Step: 7
Training loss: 2.974269193758103
Validation loss: 2.5885294902425415

Epoch: 5| Step: 8
Training loss: 2.5152319370050016
Validation loss: 2.553788679437537

Epoch: 5| Step: 9
Training loss: 1.860135347712715
Validation loss: 2.5294917684784757

Epoch: 5| Step: 10
Training loss: 2.461152566867292
Validation loss: 2.552942367405572

Epoch: 165| Step: 0
Training loss: 1.980436005030087
Validation loss: 2.5631177014160165

Epoch: 5| Step: 1
Training loss: 2.6245039516600186
Validation loss: 2.511291520646521

Epoch: 5| Step: 2
Training loss: 2.4944494619321405
Validation loss: 2.591456293948528

Epoch: 5| Step: 3
Training loss: 2.1744088959142114
Validation loss: 2.57038835845634

Epoch: 5| Step: 4
Training loss: 2.684255548912524
Validation loss: 2.553553022989294

Epoch: 5| Step: 5
Training loss: 2.020707221536781
Validation loss: 2.554291321794087

Epoch: 5| Step: 6
Training loss: 3.124868924253017
Validation loss: 2.557085823957597

Epoch: 5| Step: 7
Training loss: 2.584974495708446
Validation loss: 2.5452438819533785

Epoch: 5| Step: 8
Training loss: 1.970288477848765
Validation loss: 2.5585569352606954

Epoch: 5| Step: 9
Training loss: 2.462468618589947
Validation loss: 2.5832970908087414

Epoch: 5| Step: 10
Training loss: 3.2617707939335965
Validation loss: 2.559475692524592

Epoch: 166| Step: 0
Training loss: 2.8780700214448993
Validation loss: 2.555830232138824

Epoch: 5| Step: 1
Training loss: 2.615137920353009
Validation loss: 2.5408527463658483

Epoch: 5| Step: 2
Training loss: 2.7303851855674433
Validation loss: 2.5413035307004437

Epoch: 5| Step: 3
Training loss: 2.4780631828535187
Validation loss: 2.564341332992575

Epoch: 5| Step: 4
Training loss: 2.770681381839426
Validation loss: 2.5571182596852777

Epoch: 5| Step: 5
Training loss: 2.137994639847605
Validation loss: 2.555181248797399

Epoch: 5| Step: 6
Training loss: 2.321171765218477
Validation loss: 2.5674972349227208

Epoch: 5| Step: 7
Training loss: 2.61525643690517
Validation loss: 2.5736057221854636

Epoch: 5| Step: 8
Training loss: 2.22615781084482
Validation loss: 2.571299201231816

Epoch: 5| Step: 9
Training loss: 2.47006528559595
Validation loss: 2.572386112805226

Epoch: 5| Step: 10
Training loss: 2.491801838945371
Validation loss: 2.5056193314805477

Epoch: 167| Step: 0
Training loss: 2.267973110550891
Validation loss: 2.6046042483636467

Epoch: 5| Step: 1
Training loss: 2.9808184617286284
Validation loss: 2.5187954412565015

Epoch: 5| Step: 2
Training loss: 2.214472879243287
Validation loss: 2.554514374539275

Epoch: 5| Step: 3
Training loss: 2.6054718612354923
Validation loss: 2.5453020950310483

Epoch: 5| Step: 4
Training loss: 2.945453023214407
Validation loss: 2.575736914217274

Epoch: 5| Step: 5
Training loss: 2.456145643973085
Validation loss: 2.547828639216495

Epoch: 5| Step: 6
Training loss: 2.4406696154317764
Validation loss: 2.5547717839637816

Epoch: 5| Step: 7
Training loss: 2.8912626645692754
Validation loss: 2.479367616581552

Epoch: 5| Step: 8
Training loss: 2.416599261779849
Validation loss: 2.53508440472677

Epoch: 5| Step: 9
Training loss: 2.0768352894828017
Validation loss: 2.5603443566049284

Epoch: 5| Step: 10
Training loss: 1.9669397902628558
Validation loss: 2.544313593387239

Epoch: 168| Step: 0
Training loss: 2.8655191083705955
Validation loss: 2.530233251137336

Epoch: 5| Step: 1
Training loss: 2.4899077795944593
Validation loss: 2.5518256902238794

Epoch: 5| Step: 2
Training loss: 2.388004637108267
Validation loss: 2.537567252712582

Epoch: 5| Step: 3
Training loss: 2.1724797785863736
Validation loss: 2.5483359339116016

Epoch: 5| Step: 4
Training loss: 2.4821636987107167
Validation loss: 2.5580299410653096

Epoch: 5| Step: 5
Training loss: 3.1535652753062964
Validation loss: 2.5418325061108886

Epoch: 5| Step: 6
Training loss: 2.1161553939339224
Validation loss: 2.5690111275109726

Epoch: 5| Step: 7
Training loss: 2.414285396421126
Validation loss: 2.5659210879772303

Epoch: 5| Step: 8
Training loss: 2.3781107557474193
Validation loss: 2.510760874011467

Epoch: 5| Step: 9
Training loss: 1.7903383861127875
Validation loss: 2.570191159915501

Epoch: 5| Step: 10
Training loss: 2.824863639848875
Validation loss: 2.5859771062250934

Epoch: 169| Step: 0
Training loss: 2.464799351602164
Validation loss: 2.5438942340781114

Epoch: 5| Step: 1
Training loss: 2.302523149504453
Validation loss: 2.5635039161047017

Epoch: 5| Step: 2
Training loss: 2.246618378777771
Validation loss: 2.4978804678772883

Epoch: 5| Step: 3
Training loss: 2.739423875313957
Validation loss: 2.5588866478785777

Epoch: 5| Step: 4
Training loss: 2.4125521481268835
Validation loss: 2.5176482861688623

Epoch: 5| Step: 5
Training loss: 2.572557298116702
Validation loss: 2.5551733818262488

Epoch: 5| Step: 6
Training loss: 2.2402733264786114
Validation loss: 2.5303028167184025

Epoch: 5| Step: 7
Training loss: 2.9317996943228977
Validation loss: 2.5388810176689507

Epoch: 5| Step: 8
Training loss: 2.2603716750582232
Validation loss: 2.5180386623931166

Epoch: 5| Step: 9
Training loss: 2.9584652687704476
Validation loss: 2.536972708993053

Epoch: 5| Step: 10
Training loss: 2.259810042542347
Validation loss: 2.524780303232897

Epoch: 170| Step: 0
Training loss: 2.56264346581766
Validation loss: 2.566716711280641

Epoch: 5| Step: 1
Training loss: 2.293201857095283
Validation loss: 2.5301747025082615

Epoch: 5| Step: 2
Training loss: 3.041878070190962
Validation loss: 2.5722725282656898

Epoch: 5| Step: 3
Training loss: 2.444864445304546
Validation loss: 2.600104417589428

Epoch: 5| Step: 4
Training loss: 2.647058268465969
Validation loss: 2.572500099422815

Epoch: 5| Step: 5
Training loss: 2.3673894311368477
Validation loss: 2.5862493051614543

Epoch: 5| Step: 6
Training loss: 2.107768372341727
Validation loss: 2.5387053237987476

Epoch: 5| Step: 7
Training loss: 2.4753519944627023
Validation loss: 2.5851249879394085

Epoch: 5| Step: 8
Training loss: 2.766798987920316
Validation loss: 2.5470553078320624

Epoch: 5| Step: 9
Training loss: 2.336475221116805
Validation loss: 2.5625599839868034

Epoch: 5| Step: 10
Training loss: 2.8900652369227644
Validation loss: 2.550850432088313

Epoch: 171| Step: 0
Training loss: 2.5594000324892847
Validation loss: 2.566570864131883

Epoch: 5| Step: 1
Training loss: 1.5374813574924546
Validation loss: 2.5250032987586257

Epoch: 5| Step: 2
Training loss: 2.3479929855475854
Validation loss: 2.534959350707911

Epoch: 5| Step: 3
Training loss: 2.434070228234297
Validation loss: 2.539715186349707

Epoch: 5| Step: 4
Training loss: 2.909986821305364
Validation loss: 2.5693718195345085

Epoch: 5| Step: 5
Training loss: 1.9164159514052943
Validation loss: 2.5681457413214175

Epoch: 5| Step: 6
Training loss: 2.671810305520454
Validation loss: 2.5575037730162515

Epoch: 5| Step: 7
Training loss: 2.725464433061824
Validation loss: 2.5469795878476815

Epoch: 5| Step: 8
Training loss: 3.134585822822474
Validation loss: 2.523870921295425

Epoch: 5| Step: 9
Training loss: 2.7004314960844993
Validation loss: 2.544061771558499

Epoch: 5| Step: 10
Training loss: 2.393495917717405
Validation loss: 2.5475301468008644

Epoch: 172| Step: 0
Training loss: 2.775866323424098
Validation loss: 2.533432929111105

Epoch: 5| Step: 1
Training loss: 2.327613313500036
Validation loss: 2.514136219641018

Epoch: 5| Step: 2
Training loss: 2.9294612542848975
Validation loss: 2.552409637933708

Epoch: 5| Step: 3
Training loss: 2.096977138163637
Validation loss: 2.510065904806218

Epoch: 5| Step: 4
Training loss: 2.1688002083103215
Validation loss: 2.572679222150382

Epoch: 5| Step: 5
Training loss: 2.539464642883384
Validation loss: 2.5628108784692825

Epoch: 5| Step: 6
Training loss: 2.942169050016003
Validation loss: 2.5599985256161983

Epoch: 5| Step: 7
Training loss: 2.0771883811392136
Validation loss: 2.52123468292785

Epoch: 5| Step: 8
Training loss: 1.9230017731728315
Validation loss: 2.5261047504253913

Epoch: 5| Step: 9
Training loss: 2.0835743065389196
Validation loss: 2.528190641692964

Epoch: 5| Step: 10
Training loss: 3.3269037862704396
Validation loss: 2.5629569965982957

Epoch: 173| Step: 0
Training loss: 1.678945972084556
Validation loss: 2.563749885422485

Epoch: 5| Step: 1
Training loss: 2.156651335145363
Validation loss: 2.571376108327612

Epoch: 5| Step: 2
Training loss: 2.9179112276793457
Validation loss: 2.5497188960487316

Epoch: 5| Step: 3
Training loss: 2.6367691148256953
Validation loss: 2.503316581551175

Epoch: 5| Step: 4
Training loss: 2.2519068584999538
Validation loss: 2.5679042662948426

Epoch: 5| Step: 5
Training loss: 2.771617023285701
Validation loss: 2.5291354615463923

Epoch: 5| Step: 6
Training loss: 2.3100531752770155
Validation loss: 2.5905001676805743

Epoch: 5| Step: 7
Training loss: 2.652240914105481
Validation loss: 2.587861036710798

Epoch: 5| Step: 8
Training loss: 2.0372551987446275
Validation loss: 2.5188973855178145

Epoch: 5| Step: 9
Training loss: 2.612103526133257
Validation loss: 2.546809327676557

Epoch: 5| Step: 10
Training loss: 3.0054978220767854
Validation loss: 2.5289375095808286

Epoch: 174| Step: 0
Training loss: 2.0080554384732343
Validation loss: 2.537557574260081

Epoch: 5| Step: 1
Training loss: 2.154668587428046
Validation loss: 2.5785087143284144

Epoch: 5| Step: 2
Training loss: 2.4534169406051314
Validation loss: 2.5909676521731293

Epoch: 5| Step: 3
Training loss: 2.7614129529802685
Validation loss: 2.537727642936293

Epoch: 5| Step: 4
Training loss: 2.625407868442062
Validation loss: 2.533234110698757

Epoch: 5| Step: 5
Training loss: 2.753113804425307
Validation loss: 2.5387822185643114

Epoch: 5| Step: 6
Training loss: 3.09145555280964
Validation loss: 2.580764081032583

Epoch: 5| Step: 7
Training loss: 2.907138975628892
Validation loss: 2.5279730607529287

Epoch: 5| Step: 8
Training loss: 1.7200995262316108
Validation loss: 2.56122841387732

Epoch: 5| Step: 9
Training loss: 2.368371447105036
Validation loss: 2.569335384229069

Epoch: 5| Step: 10
Training loss: 2.3837316522557273
Validation loss: 2.5182657772460906

Epoch: 175| Step: 0
Training loss: 2.5942101127923243
Validation loss: 2.6094276207264064

Epoch: 5| Step: 1
Training loss: 3.1172994722605427
Validation loss: 2.52353297953667

Epoch: 5| Step: 2
Training loss: 1.9278712199916759
Validation loss: 2.5337564892431823

Epoch: 5| Step: 3
Training loss: 2.526297068055955
Validation loss: 2.508485169401292

Epoch: 5| Step: 4
Training loss: 2.7126942859455183
Validation loss: 2.5537631933690346

Epoch: 5| Step: 5
Training loss: 2.074258635114112
Validation loss: 2.5131973601606696

Epoch: 5| Step: 6
Training loss: 2.4893820347400424
Validation loss: 2.5678734064326236

Epoch: 5| Step: 7
Training loss: 2.741270602140576
Validation loss: 2.577852139121174

Epoch: 5| Step: 8
Training loss: 2.413557376297319
Validation loss: 2.533874923080931

Epoch: 5| Step: 9
Training loss: 2.1951764156206264
Validation loss: 2.578601498538483

Epoch: 5| Step: 10
Training loss: 2.331219249041855
Validation loss: 2.5051679110140275

Epoch: 176| Step: 0
Training loss: 2.25191310506233
Validation loss: 2.52000276541961

Epoch: 5| Step: 1
Training loss: 3.0812044956646423
Validation loss: 2.5070304224870243

Epoch: 5| Step: 2
Training loss: 2.54304028482214
Validation loss: 2.5344930322583146

Epoch: 5| Step: 3
Training loss: 3.152666531549963
Validation loss: 2.529972128084914

Epoch: 5| Step: 4
Training loss: 2.2997423815538323
Validation loss: 2.5313691466038386

Epoch: 5| Step: 5
Training loss: 1.2938369648034096
Validation loss: 2.5283827864681268

Epoch: 5| Step: 6
Training loss: 2.72905898913087
Validation loss: 2.5648513028843114

Epoch: 5| Step: 7
Training loss: 1.786139152936908
Validation loss: 2.5025451092505606

Epoch: 5| Step: 8
Training loss: 2.5649613445559294
Validation loss: 2.493843329103389

Epoch: 5| Step: 9
Training loss: 2.0947289526865736
Validation loss: 2.5594297364515097

Epoch: 5| Step: 10
Training loss: 2.736238901561049
Validation loss: 2.556827864418825

Epoch: 177| Step: 0
Training loss: 2.534081935283511
Validation loss: 2.576833423949849

Epoch: 5| Step: 1
Training loss: 2.195942092701789
Validation loss: 2.551391559706261

Epoch: 5| Step: 2
Training loss: 2.658277298945616
Validation loss: 2.552915132608018

Epoch: 5| Step: 3
Training loss: 2.5615421458821666
Validation loss: 2.5348933302395236

Epoch: 5| Step: 4
Training loss: 2.141699528225577
Validation loss: 2.5652510494397673

Epoch: 5| Step: 5
Training loss: 2.7302461678043435
Validation loss: 2.51560995823149

Epoch: 5| Step: 6
Training loss: 2.176494707419658
Validation loss: 2.5474754565316777

Epoch: 5| Step: 7
Training loss: 2.5131514810126574
Validation loss: 2.5171838118073433

Epoch: 5| Step: 8
Training loss: 2.358238300075683
Validation loss: 2.5496736539643443

Epoch: 5| Step: 9
Training loss: 3.0754820034968513
Validation loss: 2.5830815498860473

Epoch: 5| Step: 10
Training loss: 1.928456890903196
Validation loss: 2.5452174420838274

Epoch: 178| Step: 0
Training loss: 1.6927181380550373
Validation loss: 2.4751734069057947

Epoch: 5| Step: 1
Training loss: 2.039560308381657
Validation loss: 2.5241679397314543

Epoch: 5| Step: 2
Training loss: 3.121018887458713
Validation loss: 2.524750504360646

Epoch: 5| Step: 3
Training loss: 2.78864693417439
Validation loss: 2.5618562427472487

Epoch: 5| Step: 4
Training loss: 2.78877338011485
Validation loss: 2.5211484836301077

Epoch: 5| Step: 5
Training loss: 2.059744641670807
Validation loss: 2.5012080032499537

Epoch: 5| Step: 6
Training loss: 2.4060456820849816
Validation loss: 2.5225139454168795

Epoch: 5| Step: 7
Training loss: 2.8343664604487366
Validation loss: 2.5464237854498193

Epoch: 5| Step: 8
Training loss: 2.4354225500170084
Validation loss: 2.517822694667985

Epoch: 5| Step: 9
Training loss: 2.304243452322962
Validation loss: 2.5807321640187144

Epoch: 5| Step: 10
Training loss: 2.3999076587078734
Validation loss: 2.535587642872239

Epoch: 179| Step: 0
Training loss: 2.323390575927893
Validation loss: 2.5444715090345755

Epoch: 5| Step: 1
Training loss: 2.291578036819656
Validation loss: 2.5693400104484327

Epoch: 5| Step: 2
Training loss: 2.489998552712629
Validation loss: 2.5112332654226663

Epoch: 5| Step: 3
Training loss: 2.827932614690453
Validation loss: 2.5491000185610555

Epoch: 5| Step: 4
Training loss: 2.999385134947518
Validation loss: 2.513139109841017

Epoch: 5| Step: 5
Training loss: 2.1691200842040224
Validation loss: 2.5359988576670958

Epoch: 5| Step: 6
Training loss: 1.7065428988957425
Validation loss: 2.52113279962085

Epoch: 5| Step: 7
Training loss: 2.3352777576452834
Validation loss: 2.546408502769124

Epoch: 5| Step: 8
Training loss: 2.787568961346771
Validation loss: 2.5716904216574084

Epoch: 5| Step: 9
Training loss: 2.5628615333639813
Validation loss: 2.5940496808026694

Epoch: 5| Step: 10
Training loss: 2.5087401198576056
Validation loss: 2.5661265424851654

Epoch: 180| Step: 0
Training loss: 1.8659842856053146
Validation loss: 2.560475869328162

Epoch: 5| Step: 1
Training loss: 2.4717991987293613
Validation loss: 2.5394126369221994

Epoch: 5| Step: 2
Training loss: 2.542233127777714
Validation loss: 2.605220540742721

Epoch: 5| Step: 3
Training loss: 2.9547749103464698
Validation loss: 2.5519969939811666

Epoch: 5| Step: 4
Training loss: 2.884939179465291
Validation loss: 2.5214835590830096

Epoch: 5| Step: 5
Training loss: 2.339408107954391
Validation loss: 2.4849818742150895

Epoch: 5| Step: 6
Training loss: 2.2534195028942503
Validation loss: 2.494882721752516

Epoch: 5| Step: 7
Training loss: 2.3851220116905205
Validation loss: 2.5300501090291796

Epoch: 5| Step: 8
Training loss: 2.2654387298832384
Validation loss: 2.5550109150791473

Epoch: 5| Step: 9
Training loss: 2.4486457117840423
Validation loss: 2.5234255785190447

Epoch: 5| Step: 10
Training loss: 2.7272862564098137
Validation loss: 2.5063095242822118

Epoch: 181| Step: 0
Training loss: 2.309059263953232
Validation loss: 2.576455257147544

Epoch: 5| Step: 1
Training loss: 2.9404977963508556
Validation loss: 2.5427436449855447

Epoch: 5| Step: 2
Training loss: 2.6091935328811484
Validation loss: 2.566250437353209

Epoch: 5| Step: 3
Training loss: 2.210790730379955
Validation loss: 2.5307573704793587

Epoch: 5| Step: 4
Training loss: 2.5362192990403467
Validation loss: 2.5507024073076376

Epoch: 5| Step: 5
Training loss: 3.1674351178082403
Validation loss: 2.5413811084648685

Epoch: 5| Step: 6
Training loss: 2.0863624168539006
Validation loss: 2.5724117253040664

Epoch: 5| Step: 7
Training loss: 2.3658624849833436
Validation loss: 2.546284793240677

Epoch: 5| Step: 8
Training loss: 2.297123071677507
Validation loss: 2.555786223684663

Epoch: 5| Step: 9
Training loss: 2.3885376238272307
Validation loss: 2.5520028932679866

Epoch: 5| Step: 10
Training loss: 1.9089326586508157
Validation loss: 2.5246690940835625

Epoch: 182| Step: 0
Training loss: 2.10782232713494
Validation loss: 2.5361286154624185

Epoch: 5| Step: 1
Training loss: 2.8299323782238726
Validation loss: 2.520796914796506

Epoch: 5| Step: 2
Training loss: 2.9855759685755348
Validation loss: 2.5642233775186933

Epoch: 5| Step: 3
Training loss: 2.3027688526164156
Validation loss: 2.558632245494748

Epoch: 5| Step: 4
Training loss: 2.116261297241989
Validation loss: 2.5369595419912767

Epoch: 5| Step: 5
Training loss: 2.9150789753339588
Validation loss: 2.543614573241207

Epoch: 5| Step: 6
Training loss: 1.9400817528439094
Validation loss: 2.6050254741235093

Epoch: 5| Step: 7
Training loss: 2.4744970330779195
Validation loss: 2.606789686416689

Epoch: 5| Step: 8
Training loss: 2.1683173371921525
Validation loss: 2.5163118187505846

Epoch: 5| Step: 9
Training loss: 2.326394378756851
Validation loss: 2.577196700747034

Epoch: 5| Step: 10
Training loss: 3.130178814250024
Validation loss: 2.573759176104471

Epoch: 183| Step: 0
Training loss: 2.024395690039641
Validation loss: 2.5729962089578273

Epoch: 5| Step: 1
Training loss: 2.100359604336671
Validation loss: 2.537601325016881

Epoch: 5| Step: 2
Training loss: 2.100943208227385
Validation loss: 2.5523577008776885

Epoch: 5| Step: 3
Training loss: 2.5846580267364847
Validation loss: 2.534473486961335

Epoch: 5| Step: 4
Training loss: 2.2573531056345764
Validation loss: 2.572282992510752

Epoch: 5| Step: 5
Training loss: 2.6343111476196475
Validation loss: 2.543617650275837

Epoch: 5| Step: 6
Training loss: 2.2078518852505913
Validation loss: 2.573949648246193

Epoch: 5| Step: 7
Training loss: 2.302047407005147
Validation loss: 2.508479377791108

Epoch: 5| Step: 8
Training loss: 3.019822120227843
Validation loss: 2.50701469821606

Epoch: 5| Step: 9
Training loss: 2.7395273548590895
Validation loss: 2.513013013244904

Epoch: 5| Step: 10
Training loss: 2.914989497851237
Validation loss: 2.5345644057538315

Epoch: 184| Step: 0
Training loss: 2.30564679369989
Validation loss: 2.512877257705242

Epoch: 5| Step: 1
Training loss: 2.2641664216574138
Validation loss: 2.516861383673998

Epoch: 5| Step: 2
Training loss: 2.3300945988062343
Validation loss: 2.485226527089474

Epoch: 5| Step: 3
Training loss: 2.248426416938405
Validation loss: 2.5488784543046643

Epoch: 5| Step: 4
Training loss: 1.6892077670235623
Validation loss: 2.5223972740856193

Epoch: 5| Step: 5
Training loss: 2.8061478831991042
Validation loss: 2.559821834505937

Epoch: 5| Step: 6
Training loss: 2.569004642088881
Validation loss: 2.529555201652622

Epoch: 5| Step: 7
Training loss: 2.2363769525919537
Validation loss: 2.550238084908249

Epoch: 5| Step: 8
Training loss: 2.7391878333307282
Validation loss: 2.5418592656063086

Epoch: 5| Step: 9
Training loss: 3.3318027002049897
Validation loss: 2.512981122252696

Epoch: 5| Step: 10
Training loss: 2.2490112463371816
Validation loss: 2.512447738695735

Epoch: 185| Step: 0
Training loss: 2.039712853324539
Validation loss: 2.5314406810925716

Epoch: 5| Step: 1
Training loss: 2.115020318440987
Validation loss: 2.558877745354375

Epoch: 5| Step: 2
Training loss: 2.703413313996801
Validation loss: 2.5273756839324535

Epoch: 5| Step: 3
Training loss: 2.6155008375443254
Validation loss: 2.546297994579728

Epoch: 5| Step: 4
Training loss: 2.9079299501275186
Validation loss: 2.53722710165666

Epoch: 5| Step: 5
Training loss: 2.312391536334098
Validation loss: 2.513456050203293

Epoch: 5| Step: 6
Training loss: 2.682426454188242
Validation loss: 2.5781464223757853

Epoch: 5| Step: 7
Training loss: 1.994879186982848
Validation loss: 2.520882700517475

Epoch: 5| Step: 8
Training loss: 3.0158517386626826
Validation loss: 2.5382208871434555

Epoch: 5| Step: 9
Training loss: 2.1519443813000234
Validation loss: 2.51978801599567

Epoch: 5| Step: 10
Training loss: 2.2622304808539377
Validation loss: 2.5639453106458205

Epoch: 186| Step: 0
Training loss: 2.1587721959018342
Validation loss: 2.557109510410575

Epoch: 5| Step: 1
Training loss: 2.157669926711284
Validation loss: 2.54460519919096

Epoch: 5| Step: 2
Training loss: 1.6040573413140917
Validation loss: 2.5852844486345536

Epoch: 5| Step: 3
Training loss: 3.053326940349344
Validation loss: 2.5784018270034124

Epoch: 5| Step: 4
Training loss: 2.803151934950416
Validation loss: 2.5943051962308865

Epoch: 5| Step: 5
Training loss: 2.510938650818177
Validation loss: 2.5062671411101136

Epoch: 5| Step: 6
Training loss: 2.8075592725004963
Validation loss: 2.581998524551451

Epoch: 5| Step: 7
Training loss: 2.251513184239642
Validation loss: 2.5517081176760787

Epoch: 5| Step: 8
Training loss: 2.417688997567458
Validation loss: 2.5568077789638606

Epoch: 5| Step: 9
Training loss: 2.518176662419759
Validation loss: 2.514011292733467

Epoch: 5| Step: 10
Training loss: 2.5374165525949928
Validation loss: 2.561871605394213

Epoch: 187| Step: 0
Training loss: 2.4988081952293597
Validation loss: 2.5932714591875197

Epoch: 5| Step: 1
Training loss: 2.9464821352362893
Validation loss: 2.5919582861541386

Epoch: 5| Step: 2
Training loss: 2.133025106376189
Validation loss: 2.54881639922258

Epoch: 5| Step: 3
Training loss: 1.9007344733651057
Validation loss: 2.528668514169549

Epoch: 5| Step: 4
Training loss: 2.3529465363245112
Validation loss: 2.583398591552722

Epoch: 5| Step: 5
Training loss: 2.5786263643065426
Validation loss: 2.5337662975591453

Epoch: 5| Step: 6
Training loss: 2.732493947014557
Validation loss: 2.524879823353114

Epoch: 5| Step: 7
Training loss: 3.050362649838905
Validation loss: 2.509360771009622

Epoch: 5| Step: 8
Training loss: 2.1427331275475936
Validation loss: 2.543388474081082

Epoch: 5| Step: 9
Training loss: 2.0870474958804928
Validation loss: 2.5128532787795677

Epoch: 5| Step: 10
Training loss: 2.2909005242692593
Validation loss: 2.5216176999152538

Epoch: 188| Step: 0
Training loss: 3.1836289479936912
Validation loss: 2.556909474996638

Epoch: 5| Step: 1
Training loss: 2.4468694733110277
Validation loss: 2.551372296594737

Epoch: 5| Step: 2
Training loss: 2.066505819132042
Validation loss: 2.5110385536212414

Epoch: 5| Step: 3
Training loss: 2.036533702291432
Validation loss: 2.5455586896933684

Epoch: 5| Step: 4
Training loss: 2.9578970645638876
Validation loss: 2.5378046935978693

Epoch: 5| Step: 5
Training loss: 2.6165145692133573
Validation loss: 2.520463339361158

Epoch: 5| Step: 6
Training loss: 1.7053606950584512
Validation loss: 2.543019024898073

Epoch: 5| Step: 7
Training loss: 2.792582878720251
Validation loss: 2.56640162498522

Epoch: 5| Step: 8
Training loss: 2.675094895150279
Validation loss: 2.6038614871138592

Epoch: 5| Step: 9
Training loss: 2.501542569140035
Validation loss: 2.5686923724446644

Epoch: 5| Step: 10
Training loss: 2.2812757098695715
Validation loss: 2.516263504335633

Epoch: 189| Step: 0
Training loss: 2.4735595595894644
Validation loss: 2.4862776647581373

Epoch: 5| Step: 1
Training loss: 1.7707028584003563
Validation loss: 2.5801144816316235

Epoch: 5| Step: 2
Training loss: 3.1292085918220303
Validation loss: 2.555755064029202

Epoch: 5| Step: 3
Training loss: 1.984816734828612
Validation loss: 2.5582891452467478

Epoch: 5| Step: 4
Training loss: 2.538203918838271
Validation loss: 2.5460320245358345

Epoch: 5| Step: 5
Training loss: 1.9987661608912815
Validation loss: 2.5519462690951022

Epoch: 5| Step: 6
Training loss: 2.7204685260653645
Validation loss: 2.5746507764662416

Epoch: 5| Step: 7
Training loss: 2.646683463740757
Validation loss: 2.5088984955912554

Epoch: 5| Step: 8
Training loss: 2.3593353874468512
Validation loss: 2.5274849736013985

Epoch: 5| Step: 9
Training loss: 2.168425640728521
Validation loss: 2.5222191990639433

Epoch: 5| Step: 10
Training loss: 2.73699938581834
Validation loss: 2.5572447162954166

Epoch: 190| Step: 0
Training loss: 1.9472489734117528
Validation loss: 2.544058992331668

Epoch: 5| Step: 1
Training loss: 2.9655124076155337
Validation loss: 2.537288171136333

Epoch: 5| Step: 2
Training loss: 2.6315925103390176
Validation loss: 2.563897424889565

Epoch: 5| Step: 3
Training loss: 2.1628641604705434
Validation loss: 2.52876237587369

Epoch: 5| Step: 4
Training loss: 2.4495787044229864
Validation loss: 2.522780831491134

Epoch: 5| Step: 5
Training loss: 2.367621756527512
Validation loss: 2.5535253599895227

Epoch: 5| Step: 6
Training loss: 2.4250571725928936
Validation loss: 2.530457700158235

Epoch: 5| Step: 7
Training loss: 1.9631543034574102
Validation loss: 2.5154896830130546

Epoch: 5| Step: 8
Training loss: 2.1477650092746874
Validation loss: 2.5161217736771078

Epoch: 5| Step: 9
Training loss: 2.5296857733717664
Validation loss: 2.538952953414465

Epoch: 5| Step: 10
Training loss: 3.3392971729288874
Validation loss: 2.564674733187948

Epoch: 191| Step: 0
Training loss: 1.9088821998886567
Validation loss: 2.5387547793523404

Epoch: 5| Step: 1
Training loss: 2.805253505709016
Validation loss: 2.5681358486867354

Epoch: 5| Step: 2
Training loss: 2.8832655139804393
Validation loss: 2.557700987023071

Epoch: 5| Step: 3
Training loss: 1.9802645666441265
Validation loss: 2.586361122608203

Epoch: 5| Step: 4
Training loss: 2.4587775545656205
Validation loss: 2.52679390311781

Epoch: 5| Step: 5
Training loss: 1.9939288737736391
Validation loss: 2.5376706805338722

Epoch: 5| Step: 6
Training loss: 2.3872746945469263
Validation loss: 2.5397846082974715

Epoch: 5| Step: 7
Training loss: 2.2282400136317473
Validation loss: 2.5359960433206035

Epoch: 5| Step: 8
Training loss: 2.494746027922572
Validation loss: 2.536498656900648

Epoch: 5| Step: 9
Training loss: 3.068570407188349
Validation loss: 2.594567997309543

Epoch: 5| Step: 10
Training loss: 2.3877811845499006
Validation loss: 2.5487358843816628

Epoch: 192| Step: 0
Training loss: 2.0441670450157607
Validation loss: 2.560228150555743

Epoch: 5| Step: 1
Training loss: 2.4250108659638463
Validation loss: 2.5220747165494073

Epoch: 5| Step: 2
Training loss: 2.1121681088097715
Validation loss: 2.575857233678601

Epoch: 5| Step: 3
Training loss: 2.5807074357602096
Validation loss: 2.56010089851119

Epoch: 5| Step: 4
Training loss: 2.3890871574371872
Validation loss: 2.560999888664262

Epoch: 5| Step: 5
Training loss: 2.844041075848463
Validation loss: 2.5216779366011832

Epoch: 5| Step: 6
Training loss: 2.45702795080015
Validation loss: 2.5241598135995043

Epoch: 5| Step: 7
Training loss: 2.770161587928777
Validation loss: 2.5444507708852

Epoch: 5| Step: 8
Training loss: 2.4386505932591938
Validation loss: 2.564786439695093

Epoch: 5| Step: 9
Training loss: 2.167251825787533
Validation loss: 2.5864833762100865

Epoch: 5| Step: 10
Training loss: 2.8326784012748125
Validation loss: 2.4992286835618502

Epoch: 193| Step: 0
Training loss: 2.444649213344555
Validation loss: 2.5384491382030867

Epoch: 5| Step: 1
Training loss: 2.940617307354942
Validation loss: 2.541747608506449

Epoch: 5| Step: 2
Training loss: 2.4272615642894877
Validation loss: 2.5156810226627684

Epoch: 5| Step: 3
Training loss: 1.8222415509529826
Validation loss: 2.584743428170892

Epoch: 5| Step: 4
Training loss: 1.8152131130482918
Validation loss: 2.526362785494298

Epoch: 5| Step: 5
Training loss: 2.9092200085322584
Validation loss: 2.501398677675095

Epoch: 5| Step: 6
Training loss: 2.970312891703765
Validation loss: 2.506025771980145

Epoch: 5| Step: 7
Training loss: 2.116600715430762
Validation loss: 2.541149021802074

Epoch: 5| Step: 8
Training loss: 2.4529910688832515
Validation loss: 2.5917982449535546

Epoch: 5| Step: 9
Training loss: 2.3091415555706694
Validation loss: 2.5443834490708364

Epoch: 5| Step: 10
Training loss: 2.3684411081502277
Validation loss: 2.544823541116265

Epoch: 194| Step: 0
Training loss: 2.164980586892149
Validation loss: 2.536906839953029

Epoch: 5| Step: 1
Training loss: 2.2895901953814497
Validation loss: 2.4774142355655293

Epoch: 5| Step: 2
Training loss: 3.1241876690771586
Validation loss: 2.550182891767881

Epoch: 5| Step: 3
Training loss: 1.7520191941407415
Validation loss: 2.4774881179885737

Epoch: 5| Step: 4
Training loss: 3.025342868258079
Validation loss: 2.560461856991902

Epoch: 5| Step: 5
Training loss: 2.8247245451731247
Validation loss: 2.5286079269478847

Epoch: 5| Step: 6
Training loss: 2.3478154844084584
Validation loss: 2.49390796300172

Epoch: 5| Step: 7
Training loss: 1.881284608237457
Validation loss: 2.524269711707221

Epoch: 5| Step: 8
Training loss: 2.0098545955616522
Validation loss: 2.5593825995936816

Epoch: 5| Step: 9
Training loss: 2.2096748116255305
Validation loss: 2.547662964013307

Epoch: 5| Step: 10
Training loss: 2.6323226337148586
Validation loss: 2.5335305758353424

Epoch: 195| Step: 0
Training loss: 2.8834462696809036
Validation loss: 2.559014313441445

Epoch: 5| Step: 1
Training loss: 2.678435630989068
Validation loss: 2.554785305706256

Epoch: 5| Step: 2
Training loss: 2.759272807422501
Validation loss: 2.5155430834372834

Epoch: 5| Step: 3
Training loss: 2.1603811743630983
Validation loss: 2.537228239378509

Epoch: 5| Step: 4
Training loss: 2.2004723778681017
Validation loss: 2.491513975214719

Epoch: 5| Step: 5
Training loss: 2.688840753432705
Validation loss: 2.5509680099974115

Epoch: 5| Step: 6
Training loss: 2.6838599993297336
Validation loss: 2.5571351155142104

Epoch: 5| Step: 7
Training loss: 2.2089244723103003
Validation loss: 2.532686366564946

Epoch: 5| Step: 8
Training loss: 2.2151750589258206
Validation loss: 2.5395553839966634

Epoch: 5| Step: 9
Training loss: 2.404158438718612
Validation loss: 2.5420248753211663

Epoch: 5| Step: 10
Training loss: 1.9847695866954225
Validation loss: 2.516163191042207

Epoch: 196| Step: 0
Training loss: 2.1806449291382397
Validation loss: 2.529330893502482

Epoch: 5| Step: 1
Training loss: 2.4644078566015
Validation loss: 2.560706199319221

Epoch: 5| Step: 2
Training loss: 2.8236626252954653
Validation loss: 2.585787382478555

Epoch: 5| Step: 3
Training loss: 2.2527715778801216
Validation loss: 2.487582980452952

Epoch: 5| Step: 4
Training loss: 1.9410590431238361
Validation loss: 2.528135427091483

Epoch: 5| Step: 5
Training loss: 2.099143980034141
Validation loss: 2.493504172850362

Epoch: 5| Step: 6
Training loss: 2.5348001709075816
Validation loss: 2.5145254339011656

Epoch: 5| Step: 7
Training loss: 2.379459911742187
Validation loss: 2.589942533425887

Epoch: 5| Step: 8
Training loss: 3.370131194959661
Validation loss: 2.5512811367271215

Epoch: 5| Step: 9
Training loss: 2.195913755137305
Validation loss: 2.497309105131827

Epoch: 5| Step: 10
Training loss: 2.2346542290627465
Validation loss: 2.4999455538327626

Epoch: 197| Step: 0
Training loss: 2.3713962921237135
Validation loss: 2.5022593594654947

Epoch: 5| Step: 1
Training loss: 2.223831911685198
Validation loss: 2.5210165107933102

Epoch: 5| Step: 2
Training loss: 2.8022304812985324
Validation loss: 2.5609136613934336

Epoch: 5| Step: 3
Training loss: 2.658954006989478
Validation loss: 2.5160020216939203

Epoch: 5| Step: 4
Training loss: 2.3458919655590935
Validation loss: 2.4971500436471405

Epoch: 5| Step: 5
Training loss: 1.9857435538417707
Validation loss: 2.5381595108326653

Epoch: 5| Step: 6
Training loss: 2.449434943140955
Validation loss: 2.5037967517866093

Epoch: 5| Step: 7
Training loss: 2.7959373223588333
Validation loss: 2.557321180923462

Epoch: 5| Step: 8
Training loss: 2.4686443451110827
Validation loss: 2.538334495104575

Epoch: 5| Step: 9
Training loss: 2.137524106073808
Validation loss: 2.575492197209736

Epoch: 5| Step: 10
Training loss: 2.1525986203807452
Validation loss: 2.542301712572987

Epoch: 198| Step: 0
Training loss: 2.423025534740481
Validation loss: 2.466902746190447

Epoch: 5| Step: 1
Training loss: 2.0909188330653308
Validation loss: 2.5326388271167004

Epoch: 5| Step: 2
Training loss: 2.8061837373314624
Validation loss: 2.547687739303473

Epoch: 5| Step: 3
Training loss: 1.8985230226444414
Validation loss: 2.55523156433259

Epoch: 5| Step: 4
Training loss: 1.934404546114531
Validation loss: 2.499477686720241

Epoch: 5| Step: 5
Training loss: 2.8629178470999066
Validation loss: 2.4999297598744055

Epoch: 5| Step: 6
Training loss: 2.7330065981648843
Validation loss: 2.544270264367736

Epoch: 5| Step: 7
Training loss: 2.4457031522957093
Validation loss: 2.5030635444434477

Epoch: 5| Step: 8
Training loss: 1.9287734859319743
Validation loss: 2.53616260601077

Epoch: 5| Step: 9
Training loss: 2.088702822688366
Validation loss: 2.5445413059775666

Epoch: 5| Step: 10
Training loss: 2.8725212026001143
Validation loss: 2.531207768067561

Epoch: 199| Step: 0
Training loss: 3.0368393167714145
Validation loss: 2.556454801876095

Epoch: 5| Step: 1
Training loss: 2.5447701960087445
Validation loss: 2.522515414991819

Epoch: 5| Step: 2
Training loss: 2.3529007357740372
Validation loss: 2.5802136375423763

Epoch: 5| Step: 3
Training loss: 2.498193087858429
Validation loss: 2.5141435512044987

Epoch: 5| Step: 4
Training loss: 2.1693379245624285
Validation loss: 2.5261867375396165

Epoch: 5| Step: 5
Training loss: 2.0589664129155096
Validation loss: 2.511237228433682

Epoch: 5| Step: 6
Training loss: 2.667910663201399
Validation loss: 2.5731241508629004

Epoch: 5| Step: 7
Training loss: 2.6052569942411594
Validation loss: 2.5292799806190973

Epoch: 5| Step: 8
Training loss: 2.3816291246954586
Validation loss: 2.543272528516308

Epoch: 5| Step: 9
Training loss: 2.319943588162932
Validation loss: 2.4665097100087214

Epoch: 5| Step: 10
Training loss: 1.7054990268593782
Validation loss: 2.5370095570350335

Epoch: 200| Step: 0
Training loss: 2.8398865666369044
Validation loss: 2.564685724730718

Epoch: 5| Step: 1
Training loss: 1.9845601393472032
Validation loss: 2.5580527573988086

Epoch: 5| Step: 2
Training loss: 2.9226753648236357
Validation loss: 2.5705456426459654

Epoch: 5| Step: 3
Training loss: 1.5610392799836055
Validation loss: 2.5037072822083966

Epoch: 5| Step: 4
Training loss: 3.107264430231177
Validation loss: 2.498979970535895

Epoch: 5| Step: 5
Training loss: 2.003408150738342
Validation loss: 2.5293895326113764

Epoch: 5| Step: 6
Training loss: 1.9774925245295651
Validation loss: 2.520002090938617

Epoch: 5| Step: 7
Training loss: 2.688682828141281
Validation loss: 2.553596367176958

Epoch: 5| Step: 8
Training loss: 2.1344891898801195
Validation loss: 2.5179176774614933

Epoch: 5| Step: 9
Training loss: 2.610707017278254
Validation loss: 2.4853300999826535

Epoch: 5| Step: 10
Training loss: 1.9325648797557438
Validation loss: 2.4966143519778985

Epoch: 201| Step: 0
Training loss: 2.4033008684707142
Validation loss: 2.508140355715618

Epoch: 5| Step: 1
Training loss: 2.397487986736411
Validation loss: 2.4998272713087837

Epoch: 5| Step: 2
Training loss: 2.8040123767171496
Validation loss: 2.5407829489953824

Epoch: 5| Step: 3
Training loss: 2.8954302463788535
Validation loss: 2.5330650256589644

Epoch: 5| Step: 4
Training loss: 2.2729021733349595
Validation loss: 2.510000476659803

Epoch: 5| Step: 5
Training loss: 2.5583620854687026
Validation loss: 2.532013789413576

Epoch: 5| Step: 6
Training loss: 2.361013386767194
Validation loss: 2.5560312283658497

Epoch: 5| Step: 7
Training loss: 1.6669700187545407
Validation loss: 2.539409201452573

Epoch: 5| Step: 8
Training loss: 2.1024473234964516
Validation loss: 2.5679556513206285

Epoch: 5| Step: 9
Training loss: 2.6937047613819334
Validation loss: 2.524060995872862

Epoch: 5| Step: 10
Training loss: 2.3424006328860716
Validation loss: 2.5320248154142444

Epoch: 202| Step: 0
Training loss: 1.9822121194449926
Validation loss: 2.546277188746991

Epoch: 5| Step: 1
Training loss: 2.6561061146978675
Validation loss: 2.54098540713889

Epoch: 5| Step: 2
Training loss: 2.498637781948568
Validation loss: 2.575353257753777

Epoch: 5| Step: 3
Training loss: 2.375343297942648
Validation loss: 2.5352294320750626

Epoch: 5| Step: 4
Training loss: 3.236243993371227
Validation loss: 2.560582523772511

Epoch: 5| Step: 5
Training loss: 2.3243781540006374
Validation loss: 2.501533288317494

Epoch: 5| Step: 6
Training loss: 2.078306835508355
Validation loss: 2.524857441859757

Epoch: 5| Step: 7
Training loss: 2.5017664390794647
Validation loss: 2.5518935997964913

Epoch: 5| Step: 8
Training loss: 2.5499314766447148
Validation loss: 2.4945850590332097

Epoch: 5| Step: 9
Training loss: 2.2557403665172227
Validation loss: 2.5297015989289804

Epoch: 5| Step: 10
Training loss: 2.0214824879218245
Validation loss: 2.5198628988178666

Epoch: 203| Step: 0
Training loss: 2.3146671759535997
Validation loss: 2.5497511851901744

Epoch: 5| Step: 1
Training loss: 2.6584985528224174
Validation loss: 2.577390848776032

Epoch: 5| Step: 2
Training loss: 2.3534244503864485
Validation loss: 2.546941045069225

Epoch: 5| Step: 3
Training loss: 2.3691798723434
Validation loss: 2.533189371673048

Epoch: 5| Step: 4
Training loss: 2.1423496621799916
Validation loss: 2.5263549272151655

Epoch: 5| Step: 5
Training loss: 2.7025649532448925
Validation loss: 2.5311259334638856

Epoch: 5| Step: 6
Training loss: 2.4486457117840423
Validation loss: 2.5560893033363854

Epoch: 5| Step: 7
Training loss: 2.5203750025548617
Validation loss: 2.5438343435728767

Epoch: 5| Step: 8
Training loss: 2.6337077715601938
Validation loss: 2.5096149480907384

Epoch: 5| Step: 9
Training loss: 2.362535090917519
Validation loss: 2.5148433937795995

Epoch: 5| Step: 10
Training loss: 2.2566834897194195
Validation loss: 2.544449008693895

Epoch: 204| Step: 0
Training loss: 2.468745267839363
Validation loss: 2.5713281411140794

Epoch: 5| Step: 1
Training loss: 2.4090514286136706
Validation loss: 2.5849932168482934

Epoch: 5| Step: 2
Training loss: 2.6180735440455547
Validation loss: 2.500900225426449

Epoch: 5| Step: 3
Training loss: 2.465820989325402
Validation loss: 2.558591164909584

Epoch: 5| Step: 4
Training loss: 2.446629666127477
Validation loss: 2.5456508480509514

Epoch: 5| Step: 5
Training loss: 2.06169494175725
Validation loss: 2.505301121889566

Epoch: 5| Step: 6
Training loss: 1.9985782218820767
Validation loss: 2.5203609605343185

Epoch: 5| Step: 7
Training loss: 2.952819485477966
Validation loss: 2.5243144077335518

Epoch: 5| Step: 8
Training loss: 2.4574093671755386
Validation loss: 2.4964299501678515

Epoch: 5| Step: 9
Training loss: 2.28460133653702
Validation loss: 2.5569773633471464

Epoch: 5| Step: 10
Training loss: 2.1974823026845
Validation loss: 2.538903681455414

Epoch: 205| Step: 0
Training loss: 2.4757446478957545
Validation loss: 2.475537093359606

Epoch: 5| Step: 1
Training loss: 2.261053484912133
Validation loss: 2.4898373355868637

Epoch: 5| Step: 2
Training loss: 2.503960333610523
Validation loss: 2.5449108796927336

Epoch: 5| Step: 3
Training loss: 2.669209003507732
Validation loss: 2.4857368268462747

Epoch: 5| Step: 4
Training loss: 2.1774260572104716
Validation loss: 2.5774846688506843

Epoch: 5| Step: 5
Training loss: 2.451269042988154
Validation loss: 2.5236598512809048

Epoch: 5| Step: 6
Training loss: 2.429595356754844
Validation loss: 2.5384634255573064

Epoch: 5| Step: 7
Training loss: 2.8338075315796587
Validation loss: 2.50928259459136

Epoch: 5| Step: 8
Training loss: 2.349414135565611
Validation loss: 2.5352965692345246

Epoch: 5| Step: 9
Training loss: 1.7631711534194887
Validation loss: 2.533219280762717

Epoch: 5| Step: 10
Training loss: 2.193030640992958
Validation loss: 2.529674153441992

Epoch: 206| Step: 0
Training loss: 2.5223551693671826
Validation loss: 2.5919602554013266

Epoch: 5| Step: 1
Training loss: 2.667920850823683
Validation loss: 2.550004381469205

Epoch: 5| Step: 2
Training loss: 2.644887790282842
Validation loss: 2.4936097408210527

Epoch: 5| Step: 3
Training loss: 2.1481058870496907
Validation loss: 2.5642752731970084

Epoch: 5| Step: 4
Training loss: 1.849683234443006
Validation loss: 2.489514163588942

Epoch: 5| Step: 5
Training loss: 2.286210402223484
Validation loss: 2.5499991918599156

Epoch: 5| Step: 6
Training loss: 2.7305922146062493
Validation loss: 2.5181990727498365

Epoch: 5| Step: 7
Training loss: 2.4988624845894236
Validation loss: 2.534636457940841

Epoch: 5| Step: 8
Training loss: 2.2801040488477224
Validation loss: 2.533720790861561

Epoch: 5| Step: 9
Training loss: 2.5819479601378226
Validation loss: 2.5608293383112244

Epoch: 5| Step: 10
Training loss: 2.2084069749561364
Validation loss: 2.5138796096068785

Epoch: 207| Step: 0
Training loss: 2.018385305620153
Validation loss: 2.503939156530987

Epoch: 5| Step: 1
Training loss: 2.453106047927637
Validation loss: 2.516851814037102

Epoch: 5| Step: 2
Training loss: 2.19295095036278
Validation loss: 2.5548769165115424

Epoch: 5| Step: 3
Training loss: 1.8788867719437694
Validation loss: 2.576276505424636

Epoch: 5| Step: 4
Training loss: 2.4037850375109002
Validation loss: 2.513943305165297

Epoch: 5| Step: 5
Training loss: 2.4362736086535772
Validation loss: 2.512148292620406

Epoch: 5| Step: 6
Training loss: 2.8542898852256346
Validation loss: 2.503841566007619

Epoch: 5| Step: 7
Training loss: 2.055381976637251
Validation loss: 2.5330933968751568

Epoch: 5| Step: 8
Training loss: 3.029322689888394
Validation loss: 2.541548787904832

Epoch: 5| Step: 9
Training loss: 2.225834027967079
Validation loss: 2.526756194866774

Epoch: 5| Step: 10
Training loss: 2.132810599637146
Validation loss: 2.5074755971648215

Epoch: 208| Step: 0
Training loss: 2.5753084460952045
Validation loss: 2.5210159006487274

Epoch: 5| Step: 1
Training loss: 2.5110946520638238
Validation loss: 2.5804037743264785

Epoch: 5| Step: 2
Training loss: 2.1773044041971663
Validation loss: 2.521830684286067

Epoch: 5| Step: 3
Training loss: 1.3622394505129238
Validation loss: 2.5470397732851255

Epoch: 5| Step: 4
Training loss: 2.6992164534518994
Validation loss: 2.5780295455330284

Epoch: 5| Step: 5
Training loss: 2.8118013997820697
Validation loss: 2.51882281902349

Epoch: 5| Step: 6
Training loss: 2.6985924265994488
Validation loss: 2.545942097284675

Epoch: 5| Step: 7
Training loss: 2.974108547997776
Validation loss: 2.529296232391224

Epoch: 5| Step: 8
Training loss: 2.0943081239993107
Validation loss: 2.500115726212513

Epoch: 5| Step: 9
Training loss: 1.8388467018740753
Validation loss: 2.5298046693662637

Epoch: 5| Step: 10
Training loss: 2.277031329073885
Validation loss: 2.546794442909

Epoch: 209| Step: 0
Training loss: 2.5065683861836843
Validation loss: 2.536684252636342

Epoch: 5| Step: 1
Training loss: 2.5881939864942223
Validation loss: 2.5154454182386217

Epoch: 5| Step: 2
Training loss: 1.8476980579638331
Validation loss: 2.5737384109791166

Epoch: 5| Step: 3
Training loss: 2.4547604497198976
Validation loss: 2.5464626280137286

Epoch: 5| Step: 4
Training loss: 2.496032618578494
Validation loss: 2.5384967051764824

Epoch: 5| Step: 5
Training loss: 2.404888411885384
Validation loss: 2.5644760276392105

Epoch: 5| Step: 6
Training loss: 2.4646162360331005
Validation loss: 2.544752172276343

Epoch: 5| Step: 7
Training loss: 2.5309241756263217
Validation loss: 2.4989951760062645

Epoch: 5| Step: 8
Training loss: 1.704037063383602
Validation loss: 2.535971007225792

Epoch: 5| Step: 9
Training loss: 2.5473637960183733
Validation loss: 2.5401435805914083

Epoch: 5| Step: 10
Training loss: 3.0871527101973917
Validation loss: 2.490719522617757

Epoch: 210| Step: 0
Training loss: 2.758988861680923
Validation loss: 2.5307051911554157

Epoch: 5| Step: 1
Training loss: 2.3199866480278692
Validation loss: 2.548755907717143

Epoch: 5| Step: 2
Training loss: 2.4842458247544785
Validation loss: 2.530402463599008

Epoch: 5| Step: 3
Training loss: 2.2378749511936933
Validation loss: 2.512896869978426

Epoch: 5| Step: 4
Training loss: 2.6321464624322912
Validation loss: 2.529132949737616

Epoch: 5| Step: 5
Training loss: 2.418420407414371
Validation loss: 2.530954880286676

Epoch: 5| Step: 6
Training loss: 2.3766836924252943
Validation loss: 2.58173126840655

Epoch: 5| Step: 7
Training loss: 2.3508916259086843
Validation loss: 2.5354884495161922

Epoch: 5| Step: 8
Training loss: 1.8081493779268734
Validation loss: 2.561732960974159

Epoch: 5| Step: 9
Training loss: 2.4897425985003165
Validation loss: 2.5759811063913207

Epoch: 5| Step: 10
Training loss: 2.719750494312347
Validation loss: 2.589110473986036

Epoch: 211| Step: 0
Training loss: 2.6901524783458814
Validation loss: 2.5971839334141578

Epoch: 5| Step: 1
Training loss: 2.5775799724260176
Validation loss: 2.511075083907969

Epoch: 5| Step: 2
Training loss: 2.358369726792114
Validation loss: 2.4878401909266246

Epoch: 5| Step: 3
Training loss: 2.2131282884152665
Validation loss: 2.562793459772309

Epoch: 5| Step: 4
Training loss: 2.770646273004023
Validation loss: 2.53080637457597

Epoch: 5| Step: 5
Training loss: 1.9930276333414378
Validation loss: 2.4954957647742373

Epoch: 5| Step: 6
Training loss: 2.813940993020452
Validation loss: 2.576565212168058

Epoch: 5| Step: 7
Training loss: 2.4472998200361906
Validation loss: 2.5481787970027283

Epoch: 5| Step: 8
Training loss: 1.9799663199825852
Validation loss: 2.498355368610653

Epoch: 5| Step: 9
Training loss: 2.0424395545036993
Validation loss: 2.5171881259827225

Epoch: 5| Step: 10
Training loss: 2.4936920694683016
Validation loss: 2.526579367662839

Epoch: 212| Step: 0
Training loss: 2.7168357511765135
Validation loss: 2.4818176224489767

Epoch: 5| Step: 1
Training loss: 2.360120440820388
Validation loss: 2.5082139182154344

Epoch: 5| Step: 2
Training loss: 2.567234317958617
Validation loss: 2.5248571560357465

Epoch: 5| Step: 3
Training loss: 2.8564745257587356
Validation loss: 2.575983292367861

Epoch: 5| Step: 4
Training loss: 1.9233493887012458
Validation loss: 2.496290233422016

Epoch: 5| Step: 5
Training loss: 2.631559079245806
Validation loss: 2.5499952981379908

Epoch: 5| Step: 6
Training loss: 2.3674432093929787
Validation loss: 2.5038310629945078

Epoch: 5| Step: 7
Training loss: 1.9879539235299815
Validation loss: 2.5760024376214816

Epoch: 5| Step: 8
Training loss: 2.242692524992607
Validation loss: 2.563939242359822

Epoch: 5| Step: 9
Training loss: 2.4319993577943757
Validation loss: 2.522126030013349

Epoch: 5| Step: 10
Training loss: 1.85427464660089
Validation loss: 2.524617804890673

Epoch: 213| Step: 0
Training loss: 2.5121320084916676
Validation loss: 2.5387043483104517

Epoch: 5| Step: 1
Training loss: 2.103306496938156
Validation loss: 2.5162745973144345

Epoch: 5| Step: 2
Training loss: 2.5730771672359585
Validation loss: 2.5350678027445848

Epoch: 5| Step: 3
Training loss: 1.933972624063283
Validation loss: 2.511910486096416

Epoch: 5| Step: 4
Training loss: 2.334236878339304
Validation loss: 2.537596500003907

Epoch: 5| Step: 5
Training loss: 2.8365055912903445
Validation loss: 2.5485466693214494

Epoch: 5| Step: 6
Training loss: 2.5529941931545324
Validation loss: 2.5060162663341017

Epoch: 5| Step: 7
Training loss: 2.3933625348398535
Validation loss: 2.5017976204613634

Epoch: 5| Step: 8
Training loss: 1.9237324492389483
Validation loss: 2.477042687356852

Epoch: 5| Step: 9
Training loss: 2.4905087547983142
Validation loss: 2.503293713346135

Epoch: 5| Step: 10
Training loss: 2.2585159842563343
Validation loss: 2.5382327002489458

Epoch: 214| Step: 0
Training loss: 2.295868841359378
Validation loss: 2.565657724221233

Epoch: 5| Step: 1
Training loss: 3.0046603244736847
Validation loss: 2.541578603664976

Epoch: 5| Step: 2
Training loss: 2.2163302699321417
Validation loss: 2.4997993337431574

Epoch: 5| Step: 3
Training loss: 2.02143059258165
Validation loss: 2.4560723726139053

Epoch: 5| Step: 4
Training loss: 2.279343945328558
Validation loss: 2.5286423683660244

Epoch: 5| Step: 5
Training loss: 2.783602202062973
Validation loss: 2.4796691479068973

Epoch: 5| Step: 6
Training loss: 2.105051540731424
Validation loss: 2.483876167998286

Epoch: 5| Step: 7
Training loss: 2.1492910458251826
Validation loss: 2.591572995077889

Epoch: 5| Step: 8
Training loss: 2.652029027230508
Validation loss: 2.5184405628857958

Epoch: 5| Step: 9
Training loss: 2.2738255959349125
Validation loss: 2.5423410678516345

Epoch: 5| Step: 10
Training loss: 2.5327756075375505
Validation loss: 2.5278602304781175

Epoch: 215| Step: 0
Training loss: 1.9365942283691706
Validation loss: 2.474320352401645

Epoch: 5| Step: 1
Training loss: 2.745054740290467
Validation loss: 2.5366395628388028

Epoch: 5| Step: 2
Training loss: 3.0941749049771463
Validation loss: 2.552223292805887

Epoch: 5| Step: 3
Training loss: 1.7552780529932295
Validation loss: 2.5258757685303226

Epoch: 5| Step: 4
Training loss: 2.3894879996969647
Validation loss: 2.528527616226416

Epoch: 5| Step: 5
Training loss: 1.9869539818390471
Validation loss: 2.50341373683427

Epoch: 5| Step: 6
Training loss: 2.6230612361739216
Validation loss: 2.520061614462918

Epoch: 5| Step: 7
Training loss: 2.087639732024259
Validation loss: 2.4961633026314636

Epoch: 5| Step: 8
Training loss: 2.85709244138651
Validation loss: 2.581644641734314

Epoch: 5| Step: 9
Training loss: 2.315409814306058
Validation loss: 2.526469393462117

Epoch: 5| Step: 10
Training loss: 2.0573893721030014
Validation loss: 2.531059893527539

Epoch: 216| Step: 0
Training loss: 2.0071950475155003
Validation loss: 2.4904562772568113

Epoch: 5| Step: 1
Training loss: 2.44655687156826
Validation loss: 2.5667077759864014

Epoch: 5| Step: 2
Training loss: 2.0863788723554575
Validation loss: 2.538873262760385

Epoch: 5| Step: 3
Training loss: 2.2648236139934697
Validation loss: 2.5726255567957663

Epoch: 5| Step: 4
Training loss: 2.113496385154764
Validation loss: 2.5548883586004028

Epoch: 5| Step: 5
Training loss: 2.775776137678236
Validation loss: 2.540503838220904

Epoch: 5| Step: 6
Training loss: 2.741468199374852
Validation loss: 2.535296464071825

Epoch: 5| Step: 7
Training loss: 2.1848435757510165
Validation loss: 2.5016511868432736

Epoch: 5| Step: 8
Training loss: 2.4478862246521085
Validation loss: 2.4621686521044843

Epoch: 5| Step: 9
Training loss: 2.5735804413296246
Validation loss: 2.511013045097476

Epoch: 5| Step: 10
Training loss: 2.102525568385924
Validation loss: 2.482339421461505

Epoch: 217| Step: 0
Training loss: 1.8984855991125773
Validation loss: 2.5461892073423558

Epoch: 5| Step: 1
Training loss: 2.8256703889471355
Validation loss: 2.5232900179370077

Epoch: 5| Step: 2
Training loss: 2.6413791640437823
Validation loss: 2.492867177704195

Epoch: 5| Step: 3
Training loss: 2.670290203682196
Validation loss: 2.5595406111707892

Epoch: 5| Step: 4
Training loss: 2.498618793410947
Validation loss: 2.488163761685245

Epoch: 5| Step: 5
Training loss: 2.5399190074292797
Validation loss: 2.483889260315921

Epoch: 5| Step: 6
Training loss: 2.4917050076940153
Validation loss: 2.5737355034298455

Epoch: 5| Step: 7
Training loss: 2.5856778570558148
Validation loss: 2.5290928993293615

Epoch: 5| Step: 8
Training loss: 1.5668256773639722
Validation loss: 2.5258152351006125

Epoch: 5| Step: 9
Training loss: 2.3104598866563126
Validation loss: 2.4904686030933605

Epoch: 5| Step: 10
Training loss: 1.94662174151241
Validation loss: 2.523383703800987

Epoch: 218| Step: 0
Training loss: 2.2915776206547305
Validation loss: 2.496056574221862

Epoch: 5| Step: 1
Training loss: 1.8104653612735422
Validation loss: 2.5491647760386726

Epoch: 5| Step: 2
Training loss: 2.51239545614132
Validation loss: 2.542040021988049

Epoch: 5| Step: 3
Training loss: 2.69776075543531
Validation loss: 2.505903925730773

Epoch: 5| Step: 4
Training loss: 2.2523708568136676
Validation loss: 2.52270068332113

Epoch: 5| Step: 5
Training loss: 2.221139292966235
Validation loss: 2.5382672463989384

Epoch: 5| Step: 6
Training loss: 2.5623804390159766
Validation loss: 2.482026736144686

Epoch: 5| Step: 7
Training loss: 2.276235320511586
Validation loss: 2.5076902605907914

Epoch: 5| Step: 8
Training loss: 2.7128626778730585
Validation loss: 2.5271924321249433

Epoch: 5| Step: 9
Training loss: 2.329205972502498
Validation loss: 2.5608797951458255

Epoch: 5| Step: 10
Training loss: 1.751105368153492
Validation loss: 2.488115044938761

Epoch: 219| Step: 0
Training loss: 2.654597677290777
Validation loss: 2.5391811023207054

Epoch: 5| Step: 1
Training loss: 2.2243831207993203
Validation loss: 2.5112332021287767

Epoch: 5| Step: 2
Training loss: 1.7925784947487837
Validation loss: 2.494138294828246

Epoch: 5| Step: 3
Training loss: 2.5114496303446057
Validation loss: 2.5782389029272115

Epoch: 5| Step: 4
Training loss: 2.842051239689995
Validation loss: 2.5132402558351967

Epoch: 5| Step: 5
Training loss: 2.0345725249279996
Validation loss: 2.520997862674328

Epoch: 5| Step: 6
Training loss: 2.8403237631095277
Validation loss: 2.517292629428329

Epoch: 5| Step: 7
Training loss: 2.061364410352834
Validation loss: 2.5584558307767984

Epoch: 5| Step: 8
Training loss: 2.4119784053196396
Validation loss: 2.51759930038371

Epoch: 5| Step: 9
Training loss: 2.147376224916507
Validation loss: 2.487044803934592

Epoch: 5| Step: 10
Training loss: 2.033170994807967
Validation loss: 2.5316959131646684

Epoch: 220| Step: 0
Training loss: 2.6478104200639754
Validation loss: 2.5318888115538116

Epoch: 5| Step: 1
Training loss: 2.3975669448941406
Validation loss: 2.5153204019438817

Epoch: 5| Step: 2
Training loss: 2.371233010640914
Validation loss: 2.506487563622625

Epoch: 5| Step: 3
Training loss: 2.063797744762461
Validation loss: 2.5348546168356574

Epoch: 5| Step: 4
Training loss: 2.033611743919203
Validation loss: 2.5659347912510415

Epoch: 5| Step: 5
Training loss: 2.2187723507897124
Validation loss: 2.5020874107285063

Epoch: 5| Step: 6
Training loss: 2.7622889856726887
Validation loss: 2.509867224095837

Epoch: 5| Step: 7
Training loss: 2.7008072282172377
Validation loss: 2.516668629199021

Epoch: 5| Step: 8
Training loss: 2.0866541399391854
Validation loss: 2.5002979870064133

Epoch: 5| Step: 9
Training loss: 1.3009735515143293
Validation loss: 2.507124157629162

Epoch: 5| Step: 10
Training loss: 2.703996110033025
Validation loss: 2.5425757751327445

Epoch: 221| Step: 0
Training loss: 2.5762460971230787
Validation loss: 2.550841683425624

Epoch: 5| Step: 1
Training loss: 1.6935684444628514
Validation loss: 2.5571126684540544

Epoch: 5| Step: 2
Training loss: 2.019025669231359
Validation loss: 2.537610655773901

Epoch: 5| Step: 3
Training loss: 2.0451669336658216
Validation loss: 2.5248018873192355

Epoch: 5| Step: 4
Training loss: 2.8199794921399852
Validation loss: 2.54822844596496

Epoch: 5| Step: 5
Training loss: 1.871738903976247
Validation loss: 2.5085487689248307

Epoch: 5| Step: 6
Training loss: 2.2658893299467224
Validation loss: 2.5425697324744547

Epoch: 5| Step: 7
Training loss: 2.493223160470252
Validation loss: 2.5406851854614585

Epoch: 5| Step: 8
Training loss: 2.8539737905409583
Validation loss: 2.5342129171545134

Epoch: 5| Step: 9
Training loss: 2.089911971360198
Validation loss: 2.4727980941686027

Epoch: 5| Step: 10
Training loss: 2.4878140045264967
Validation loss: 2.519440944637076

Epoch: 222| Step: 0
Training loss: 2.3990913021877494
Validation loss: 2.522123275404803

Epoch: 5| Step: 1
Training loss: 1.997599591767159
Validation loss: 2.49888292910044

Epoch: 5| Step: 2
Training loss: 3.2438573742332872
Validation loss: 2.501972117946742

Epoch: 5| Step: 3
Training loss: 2.8732286054756817
Validation loss: 2.5094787717183844

Epoch: 5| Step: 4
Training loss: 1.962281940275585
Validation loss: 2.5052137746839866

Epoch: 5| Step: 5
Training loss: 2.5629028375837857
Validation loss: 2.4829012533781203

Epoch: 5| Step: 6
Training loss: 1.8642894648267314
Validation loss: 2.5188062299581535

Epoch: 5| Step: 7
Training loss: 2.205501275898684
Validation loss: 2.5416927716229027

Epoch: 5| Step: 8
Training loss: 2.3188006166758366
Validation loss: 2.5773363360780093

Epoch: 5| Step: 9
Training loss: 1.9702763771176326
Validation loss: 2.531421069693584

Epoch: 5| Step: 10
Training loss: 2.1156422511514505
Validation loss: 2.5586157832809153

Epoch: 223| Step: 0
Training loss: 2.382392421026837
Validation loss: 2.566769475426707

Epoch: 5| Step: 1
Training loss: 1.5201574765997468
Validation loss: 2.5564494258014276

Epoch: 5| Step: 2
Training loss: 2.4005963180723513
Validation loss: 2.48890523951694

Epoch: 5| Step: 3
Training loss: 2.325897789989917
Validation loss: 2.514602317717665

Epoch: 5| Step: 4
Training loss: 1.9777465410063664
Validation loss: 2.518750806074645

Epoch: 5| Step: 5
Training loss: 2.7914196493455514
Validation loss: 2.5590663267765805

Epoch: 5| Step: 6
Training loss: 2.267110613748951
Validation loss: 2.4744673632178675

Epoch: 5| Step: 7
Training loss: 2.2643825939197484
Validation loss: 2.552480789653352

Epoch: 5| Step: 8
Training loss: 2.3200856107503744
Validation loss: 2.5053699042124684

Epoch: 5| Step: 9
Training loss: 2.8081692731650003
Validation loss: 2.5068527244063556

Epoch: 5| Step: 10
Training loss: 2.345137732066251
Validation loss: 2.56505058003149

Epoch: 224| Step: 0
Training loss: 1.9273328121324906
Validation loss: 2.549741833506992

Epoch: 5| Step: 1
Training loss: 2.308146735222516
Validation loss: 2.543183327261089

Epoch: 5| Step: 2
Training loss: 2.232932205141385
Validation loss: 2.5596646981196822

Epoch: 5| Step: 3
Training loss: 2.2590456436294555
Validation loss: 2.560683957764248

Epoch: 5| Step: 4
Training loss: 2.4298617677656518
Validation loss: 2.6055736089863544

Epoch: 5| Step: 5
Training loss: 1.9561574359481109
Validation loss: 2.5414000871826454

Epoch: 5| Step: 6
Training loss: 2.4692600544231116
Validation loss: 2.5124926511513896

Epoch: 5| Step: 7
Training loss: 2.7620759595388042
Validation loss: 2.6329028564208508

Epoch: 5| Step: 8
Training loss: 2.1437528827080654
Validation loss: 2.541473377960112

Epoch: 5| Step: 9
Training loss: 2.79510732018208
Validation loss: 2.5448233265412785

Epoch: 5| Step: 10
Training loss: 2.6806323996308565
Validation loss: 2.5633824467490145

Epoch: 225| Step: 0
Training loss: 2.4001417038728015
Validation loss: 2.560299466493083

Epoch: 5| Step: 1
Training loss: 2.745038324863291
Validation loss: 2.571489686104592

Epoch: 5| Step: 2
Training loss: 2.4181883285484362
Validation loss: 2.532231197795309

Epoch: 5| Step: 3
Training loss: 2.363656712491134
Validation loss: 2.5311739553262926

Epoch: 5| Step: 4
Training loss: 2.3152769787329404
Validation loss: 2.502846906276963

Epoch: 5| Step: 5
Training loss: 2.5115445612045706
Validation loss: 2.505511642970859

Epoch: 5| Step: 6
Training loss: 2.7106699522942654
Validation loss: 2.4663429597715814

Epoch: 5| Step: 7
Training loss: 1.825408416929094
Validation loss: 2.488811182846175

Epoch: 5| Step: 8
Training loss: 1.7091990657558338
Validation loss: 2.5111024121067773

Epoch: 5| Step: 9
Training loss: 2.4153985829115356
Validation loss: 2.4687058276223546

Epoch: 5| Step: 10
Training loss: 2.3175354853838126
Validation loss: 2.538936986605476

Epoch: 226| Step: 0
Training loss: 1.6039367940440576
Validation loss: 2.49793394814647

Epoch: 5| Step: 1
Training loss: 1.751193184758043
Validation loss: 2.5474684110966126

Epoch: 5| Step: 2
Training loss: 2.581277110994222
Validation loss: 2.5667303718531196

Epoch: 5| Step: 3
Training loss: 2.305247920805785
Validation loss: 2.51854388143432

Epoch: 5| Step: 4
Training loss: 2.760483612592298
Validation loss: 2.540466806745237

Epoch: 5| Step: 5
Training loss: 2.835229538332687
Validation loss: 2.5177282408284913

Epoch: 5| Step: 6
Training loss: 2.4932309062168887
Validation loss: 2.528957547752387

Epoch: 5| Step: 7
Training loss: 2.242142627014501
Validation loss: 2.5184233605298227

Epoch: 5| Step: 8
Training loss: 1.4574650586554514
Validation loss: 2.5670839693069425

Epoch: 5| Step: 9
Training loss: 2.9181259501037555
Validation loss: 2.5597566876353586

Epoch: 5| Step: 10
Training loss: 2.510512090323
Validation loss: 2.520281975381155

Epoch: 227| Step: 0
Training loss: 2.4087635140072083
Validation loss: 2.483518548161549

Epoch: 5| Step: 1
Training loss: 2.532678271813383
Validation loss: 2.516191831795793

Epoch: 5| Step: 2
Training loss: 2.337064337292469
Validation loss: 2.47347422778464

Epoch: 5| Step: 3
Training loss: 2.186912893799366
Validation loss: 2.4978260124582703

Epoch: 5| Step: 4
Training loss: 2.6111525460150333
Validation loss: 2.549204202360267

Epoch: 5| Step: 5
Training loss: 2.1376169050047897
Validation loss: 2.53820698627184

Epoch: 5| Step: 6
Training loss: 2.848579246689551
Validation loss: 2.5031768866371733

Epoch: 5| Step: 7
Training loss: 1.8951688028002092
Validation loss: 2.5945668580531023

Epoch: 5| Step: 8
Training loss: 2.128757856604279
Validation loss: 2.5861666130867285

Epoch: 5| Step: 9
Training loss: 2.7772494915769372
Validation loss: 2.5243573018704377

Epoch: 5| Step: 10
Training loss: 1.9352000336666348
Validation loss: 2.5028829605071956

Epoch: 228| Step: 0
Training loss: 2.557764189676972
Validation loss: 2.5488022151641103

Epoch: 5| Step: 1
Training loss: 2.164528586533938
Validation loss: 2.550397822027267

Epoch: 5| Step: 2
Training loss: 2.192779056619682
Validation loss: 2.4949187374557495

Epoch: 5| Step: 3
Training loss: 2.32079014854957
Validation loss: 2.512057638165525

Epoch: 5| Step: 4
Training loss: 2.4196291447051332
Validation loss: 2.4727853210206043

Epoch: 5| Step: 5
Training loss: 1.562224249349346
Validation loss: 2.543573952608413

Epoch: 5| Step: 6
Training loss: 2.392337659312701
Validation loss: 2.5253499538561086

Epoch: 5| Step: 7
Training loss: 2.590376901193024
Validation loss: 2.557108337422004

Epoch: 5| Step: 8
Training loss: 2.822041412211871
Validation loss: 2.478389376855092

Epoch: 5| Step: 9
Training loss: 1.9782532106525579
Validation loss: 2.5138408382501525

Epoch: 5| Step: 10
Training loss: 2.4865714865801736
Validation loss: 2.532935958067745

Epoch: 229| Step: 0
Training loss: 2.1663601242751205
Validation loss: 2.49209814187591

Epoch: 5| Step: 1
Training loss: 2.1154198957048793
Validation loss: 2.4739528456898543

Epoch: 5| Step: 2
Training loss: 1.7634189969379361
Validation loss: 2.517844655054717

Epoch: 5| Step: 3
Training loss: 2.7437156483926355
Validation loss: 2.5724384317929445

Epoch: 5| Step: 4
Training loss: 2.2706567071474866
Validation loss: 2.536373389600322

Epoch: 5| Step: 5
Training loss: 2.0767443666979855
Validation loss: 2.5020980645044144

Epoch: 5| Step: 6
Training loss: 2.483745855165737
Validation loss: 2.4971694847992087

Epoch: 5| Step: 7
Training loss: 1.8988945807132394
Validation loss: 2.5888791190641163

Epoch: 5| Step: 8
Training loss: 2.774681736334017
Validation loss: 2.558819426342372

Epoch: 5| Step: 9
Training loss: 2.093641363713249
Validation loss: 2.542633768999386

Epoch: 5| Step: 10
Training loss: 2.5562460342040696
Validation loss: 2.5092880502646833

Epoch: 230| Step: 0
Training loss: 2.3321784658306868
Validation loss: 2.54830259667457

Epoch: 5| Step: 1
Training loss: 2.5592672844694655
Validation loss: 2.5189123007908605

Epoch: 5| Step: 2
Training loss: 2.3039319885202887
Validation loss: 2.5311991510382006

Epoch: 5| Step: 3
Training loss: 2.647873089719648
Validation loss: 2.547912713389714

Epoch: 5| Step: 4
Training loss: 2.2348321833748277
Validation loss: 2.5663452171147916

Epoch: 5| Step: 5
Training loss: 2.493069770604809
Validation loss: 2.5277511223480653

Epoch: 5| Step: 6
Training loss: 1.9636495005765418
Validation loss: 2.548459294394465

Epoch: 5| Step: 7
Training loss: 2.2567569152651705
Validation loss: 2.5683700413449095

Epoch: 5| Step: 8
Training loss: 2.261427786497929
Validation loss: 2.5324150279710906

Epoch: 5| Step: 9
Training loss: 2.198567431202017
Validation loss: 2.5209872460589837

Epoch: 5| Step: 10
Training loss: 2.2545848333997314
Validation loss: 2.4914783033578978

Epoch: 231| Step: 0
Training loss: 2.150373883229845
Validation loss: 2.5058565012271354

Epoch: 5| Step: 1
Training loss: 3.1720363030971925
Validation loss: 2.4980212225228624

Epoch: 5| Step: 2
Training loss: 1.9076309830077023
Validation loss: 2.482753702148688

Epoch: 5| Step: 3
Training loss: 1.9932823015248964
Validation loss: 2.5540793770941335

Epoch: 5| Step: 4
Training loss: 2.437136696370237
Validation loss: 2.4962745308454175

Epoch: 5| Step: 5
Training loss: 2.383359152202763
Validation loss: 2.521136318972964

Epoch: 5| Step: 6
Training loss: 2.636930239637484
Validation loss: 2.5214209929684466

Epoch: 5| Step: 7
Training loss: 2.0243221985307467
Validation loss: 2.4900848095395287

Epoch: 5| Step: 8
Training loss: 2.444733377440919
Validation loss: 2.54169211802725

Epoch: 5| Step: 9
Training loss: 2.374201690622582
Validation loss: 2.479757655423394

Epoch: 5| Step: 10
Training loss: 2.036668914548109
Validation loss: 2.52770179329474

Epoch: 232| Step: 0
Training loss: 2.431849165097599
Validation loss: 2.538211407126936

Epoch: 5| Step: 1
Training loss: 1.9165109349990537
Validation loss: 2.5411735397887263

Epoch: 5| Step: 2
Training loss: 2.323673165022189
Validation loss: 2.525325745666927

Epoch: 5| Step: 3
Training loss: 2.178149593438822
Validation loss: 2.5468864327420797

Epoch: 5| Step: 4
Training loss: 2.4320250425617957
Validation loss: 2.549029834526163

Epoch: 5| Step: 5
Training loss: 2.631347520339461
Validation loss: 2.495589803469145

Epoch: 5| Step: 6
Training loss: 2.2948693062463197
Validation loss: 2.5585064085683333

Epoch: 5| Step: 7
Training loss: 1.8261092068124178
Validation loss: 2.488131856146661

Epoch: 5| Step: 8
Training loss: 2.4030303222102027
Validation loss: 2.52537411257832

Epoch: 5| Step: 9
Training loss: 2.6900988588283843
Validation loss: 2.5085802931777272

Epoch: 5| Step: 10
Training loss: 2.092720006135166
Validation loss: 2.51302422717681

Epoch: 233| Step: 0
Training loss: 2.006830591347806
Validation loss: 2.508902770368207

Epoch: 5| Step: 1
Training loss: 2.5978089710745307
Validation loss: 2.5283263101247067

Epoch: 5| Step: 2
Training loss: 2.519973881601283
Validation loss: 2.434808357162954

Epoch: 5| Step: 3
Training loss: 2.6954182037413608
Validation loss: 2.5149507122714243

Epoch: 5| Step: 4
Training loss: 2.1412240185695133
Validation loss: 2.489004147994432

Epoch: 5| Step: 5
Training loss: 2.5770982026946094
Validation loss: 2.513846547651313

Epoch: 5| Step: 6
Training loss: 2.574364896802162
Validation loss: 2.545625912953091

Epoch: 5| Step: 7
Training loss: 1.7604083751355293
Validation loss: 2.499053703175195

Epoch: 5| Step: 8
Training loss: 1.5474588852752862
Validation loss: 2.4962497156434806

Epoch: 5| Step: 9
Training loss: 2.525029769570893
Validation loss: 2.502496500364704

Epoch: 5| Step: 10
Training loss: 2.167100227210405
Validation loss: 2.511285631381955

Epoch: 234| Step: 0
Training loss: 2.196212421197785
Validation loss: 2.501443823357763

Epoch: 5| Step: 1
Training loss: 2.7934738876135587
Validation loss: 2.532217046880836

Epoch: 5| Step: 2
Training loss: 2.1778335617126423
Validation loss: 2.5399754702638604

Epoch: 5| Step: 3
Training loss: 2.15307350041736
Validation loss: 2.526154009180767

Epoch: 5| Step: 4
Training loss: 2.48629226119313
Validation loss: 2.5511595667468914

Epoch: 5| Step: 5
Training loss: 2.038860793386432
Validation loss: 2.4895240916345207

Epoch: 5| Step: 6
Training loss: 2.288986048544667
Validation loss: 2.4973204116513052

Epoch: 5| Step: 7
Training loss: 2.5049821800466114
Validation loss: 2.501059336439564

Epoch: 5| Step: 8
Training loss: 2.585325508652103
Validation loss: 2.505303558845009

Epoch: 5| Step: 9
Training loss: 1.4150038478515932
Validation loss: 2.511957369703586

Epoch: 5| Step: 10
Training loss: 2.622223793808777
Validation loss: 2.4675341211067585

Epoch: 235| Step: 0
Training loss: 2.369529950009174
Validation loss: 2.4637617467181285

Epoch: 5| Step: 1
Training loss: 2.1760619716935636
Validation loss: 2.5595394943844725

Epoch: 5| Step: 2
Training loss: 2.283062149799298
Validation loss: 2.5117591514394353

Epoch: 5| Step: 3
Training loss: 2.1581794841041164
Validation loss: 2.561414202960805

Epoch: 5| Step: 4
Training loss: 2.2431903151693526
Validation loss: 2.5100291157274004

Epoch: 5| Step: 5
Training loss: 2.1058488548722223
Validation loss: 2.4816941992124555

Epoch: 5| Step: 6
Training loss: 2.0356231563888882
Validation loss: 2.574779596482693

Epoch: 5| Step: 7
Training loss: 1.8123225421192508
Validation loss: 2.574411834023965

Epoch: 5| Step: 8
Training loss: 2.5725661951562477
Validation loss: 2.549661823483353

Epoch: 5| Step: 9
Training loss: 2.8999836954118874
Validation loss: 2.508576088876816

Epoch: 5| Step: 10
Training loss: 2.9212445073531113
Validation loss: 2.5278975855661594

Epoch: 236| Step: 0
Training loss: 2.00739257221024
Validation loss: 2.5165586955963413

Epoch: 5| Step: 1
Training loss: 2.1682600495809172
Validation loss: 2.4539609328271883

Epoch: 5| Step: 2
Training loss: 2.691652151094237
Validation loss: 2.4926664010776625

Epoch: 5| Step: 3
Training loss: 2.4562172807450713
Validation loss: 2.497791305207407

Epoch: 5| Step: 4
Training loss: 2.450135760535761
Validation loss: 2.5290033337753695

Epoch: 5| Step: 5
Training loss: 2.0496819737937564
Validation loss: 2.5335657800687277

Epoch: 5| Step: 6
Training loss: 2.7981774052187363
Validation loss: 2.4787950044994647

Epoch: 5| Step: 7
Training loss: 1.9152089947631894
Validation loss: 2.5362640098887907

Epoch: 5| Step: 8
Training loss: 2.0212064837676564
Validation loss: 2.4880430664204476

Epoch: 5| Step: 9
Training loss: 2.3646897839575125
Validation loss: 2.522472482927934

Epoch: 5| Step: 10
Training loss: 2.4979251834914025
Validation loss: 2.4819701325350616

Epoch: 237| Step: 0
Training loss: 2.9645384780875292
Validation loss: 2.541299222156303

Epoch: 5| Step: 1
Training loss: 2.332239394108303
Validation loss: 2.5543708646440586

Epoch: 5| Step: 2
Training loss: 1.9118998863792815
Validation loss: 2.4970440812153023

Epoch: 5| Step: 3
Training loss: 1.681597098785206
Validation loss: 2.435857919653368

Epoch: 5| Step: 4
Training loss: 2.2092344376932243
Validation loss: 2.5096719629778987

Epoch: 5| Step: 5
Training loss: 2.4654803292846115
Validation loss: 2.5238149463458877

Epoch: 5| Step: 6
Training loss: 2.499442705981599
Validation loss: 2.4795233522565594

Epoch: 5| Step: 7
Training loss: 2.215308515706827
Validation loss: 2.562468719891773

Epoch: 5| Step: 8
Training loss: 2.2458283640771737
Validation loss: 2.536259891910383

Epoch: 5| Step: 9
Training loss: 2.3550188890740364
Validation loss: 2.4235725140799125

Epoch: 5| Step: 10
Training loss: 2.0710239555487493
Validation loss: 2.500131973761957

Epoch: 238| Step: 0
Training loss: 2.039301248070844
Validation loss: 2.483596754159858

Epoch: 5| Step: 1
Training loss: 2.3614336342032436
Validation loss: 2.5393495640686163

Epoch: 5| Step: 2
Training loss: 2.862945495321154
Validation loss: 2.5139596764783128

Epoch: 5| Step: 3
Training loss: 2.4122531863442687
Validation loss: 2.5237969547871764

Epoch: 5| Step: 4
Training loss: 2.2373451818683656
Validation loss: 2.509284348785743

Epoch: 5| Step: 5
Training loss: 2.583067993155268
Validation loss: 2.544177445365065

Epoch: 5| Step: 6
Training loss: 2.1652315473185353
Validation loss: 2.534961733363277

Epoch: 5| Step: 7
Training loss: 2.3106621320907084
Validation loss: 2.453502257379035

Epoch: 5| Step: 8
Training loss: 2.3151655557315025
Validation loss: 2.571430133244769

Epoch: 5| Step: 9
Training loss: 1.870663523737759
Validation loss: 2.462972718943402

Epoch: 5| Step: 10
Training loss: 2.1527162426866897
Validation loss: 2.4400275908271376

Epoch: 239| Step: 0
Training loss: 2.4088000372226275
Validation loss: 2.5308414667851946

Epoch: 5| Step: 1
Training loss: 1.9613259223358848
Validation loss: 2.5002213600560923

Epoch: 5| Step: 2
Training loss: 2.7423149579197093
Validation loss: 2.4928204564628107

Epoch: 5| Step: 3
Training loss: 2.050317679190668
Validation loss: 2.5249409706365964

Epoch: 5| Step: 4
Training loss: 2.133054614734681
Validation loss: 2.5279414264338804

Epoch: 5| Step: 5
Training loss: 1.9437851022574317
Validation loss: 2.5105028395954716

Epoch: 5| Step: 6
Training loss: 2.4894631541678764
Validation loss: 2.499892814963672

Epoch: 5| Step: 7
Training loss: 2.653403518489714
Validation loss: 2.5211235746445224

Epoch: 5| Step: 8
Training loss: 2.355631099945049
Validation loss: 2.5538793322092914

Epoch: 5| Step: 9
Training loss: 2.435592296088094
Validation loss: 2.5190561271222216

Epoch: 5| Step: 10
Training loss: 2.1393019771344433
Validation loss: 2.5681765330259947

Epoch: 240| Step: 0
Training loss: 1.9074149402536875
Validation loss: 2.4887565300161008

Epoch: 5| Step: 1
Training loss: 2.256032063533649
Validation loss: 2.4923795968779734

Epoch: 5| Step: 2
Training loss: 2.422683285608782
Validation loss: 2.5132264932297006

Epoch: 5| Step: 3
Training loss: 2.9547913709081497
Validation loss: 2.497087643476693

Epoch: 5| Step: 4
Training loss: 1.9667721456054568
Validation loss: 2.541392587105681

Epoch: 5| Step: 5
Training loss: 2.127380048012781
Validation loss: 2.5062604994634876

Epoch: 5| Step: 6
Training loss: 2.7171595514405515
Validation loss: 2.5902854413978313

Epoch: 5| Step: 7
Training loss: 2.0986898422480342
Validation loss: 2.5309267069288417

Epoch: 5| Step: 8
Training loss: 2.3505933418363334
Validation loss: 2.504295230983387

Epoch: 5| Step: 9
Training loss: 2.1641037038467954
Validation loss: 2.5465665764261773

Epoch: 5| Step: 10
Training loss: 2.292047734800372
Validation loss: 2.546543042580798

Epoch: 241| Step: 0
Training loss: 2.9117984106795642
Validation loss: 2.525197310928408

Epoch: 5| Step: 1
Training loss: 2.0177771146122483
Validation loss: 2.5093539332243386

Epoch: 5| Step: 2
Training loss: 2.1688552830890204
Validation loss: 2.566808288762479

Epoch: 5| Step: 3
Training loss: 2.356739112823192
Validation loss: 2.54467511033902

Epoch: 5| Step: 4
Training loss: 2.1413526203352635
Validation loss: 2.473515851400727

Epoch: 5| Step: 5
Training loss: 1.7756082298617448
Validation loss: 2.551791144782973

Epoch: 5| Step: 6
Training loss: 2.610103208613222
Validation loss: 2.4807094155883833

Epoch: 5| Step: 7
Training loss: 2.050962022352576
Validation loss: 2.502316578830835

Epoch: 5| Step: 8
Training loss: 2.343022246225454
Validation loss: 2.5628917573710326

Epoch: 5| Step: 9
Training loss: 2.288169295990097
Validation loss: 2.5013913825482468

Epoch: 5| Step: 10
Training loss: 2.323175584079712
Validation loss: 2.508760286651365

Epoch: 242| Step: 0
Training loss: 2.4821547657915195
Validation loss: 2.478388637260521

Epoch: 5| Step: 1
Training loss: 1.9445370886697009
Validation loss: 2.583657520414275

Epoch: 5| Step: 2
Training loss: 1.6760506935737949
Validation loss: 2.461924528786232

Epoch: 5| Step: 3
Training loss: 2.661251341253671
Validation loss: 2.563968612770584

Epoch: 5| Step: 4
Training loss: 1.884659363908701
Validation loss: 2.4541770550283926

Epoch: 5| Step: 5
Training loss: 2.169545083419111
Validation loss: 2.5301437796527813

Epoch: 5| Step: 6
Training loss: 2.4705642600859647
Validation loss: 2.475411060960019

Epoch: 5| Step: 7
Training loss: 2.4466035499885654
Validation loss: 2.4730837623990483

Epoch: 5| Step: 8
Training loss: 2.900246931941374
Validation loss: 2.5741159072876094

Epoch: 5| Step: 9
Training loss: 2.2636641863477602
Validation loss: 2.5008315836251103

Epoch: 5| Step: 10
Training loss: 2.0620624193647004
Validation loss: 2.537962731405295

Epoch: 243| Step: 0
Training loss: 2.2913198960085706
Validation loss: 2.4340109874267606

Epoch: 5| Step: 1
Training loss: 2.0772488690385944
Validation loss: 2.5007176353667924

Epoch: 5| Step: 2
Training loss: 2.592334223038763
Validation loss: 2.4910537970462765

Epoch: 5| Step: 3
Training loss: 1.9589762815876868
Validation loss: 2.4715243195523113

Epoch: 5| Step: 4
Training loss: 2.7945151149677474
Validation loss: 2.545096816388691

Epoch: 5| Step: 5
Training loss: 1.9409041494201429
Validation loss: 2.5135038285436844

Epoch: 5| Step: 6
Training loss: 2.5922749932844904
Validation loss: 2.580350287508235

Epoch: 5| Step: 7
Training loss: 2.1899085817460575
Validation loss: 2.5222049071050527

Epoch: 5| Step: 8
Training loss: 2.471440744173169
Validation loss: 2.556451126571655

Epoch: 5| Step: 9
Training loss: 1.972117737642524
Validation loss: 2.54767159680189

Epoch: 5| Step: 10
Training loss: 2.345679950837858
Validation loss: 2.6125618156950208

Epoch: 244| Step: 0
Training loss: 2.0091181565700227
Validation loss: 2.4534538116082745

Epoch: 5| Step: 1
Training loss: 2.4084676456507537
Validation loss: 2.553182576563112

Epoch: 5| Step: 2
Training loss: 2.244213079838295
Validation loss: 2.498602135870163

Epoch: 5| Step: 3
Training loss: 2.202489450106863
Validation loss: 2.57598819227257

Epoch: 5| Step: 4
Training loss: 2.303190825102679
Validation loss: 2.4759590627745567

Epoch: 5| Step: 5
Training loss: 2.731614817821036
Validation loss: 2.508918579367104

Epoch: 5| Step: 6
Training loss: 2.3102866225339396
Validation loss: 2.5422006513800453

Epoch: 5| Step: 7
Training loss: 2.240436681178333
Validation loss: 2.560453969199323

Epoch: 5| Step: 8
Training loss: 1.8629855835050184
Validation loss: 2.5458584726032707

Epoch: 5| Step: 9
Training loss: 2.308290413229111
Validation loss: 2.4695932036862227

Epoch: 5| Step: 10
Training loss: 2.492460038640534
Validation loss: 2.496158183896638

Epoch: 245| Step: 0
Training loss: 1.8576307048993652
Validation loss: 2.515321964392892

Epoch: 5| Step: 1
Training loss: 2.7311509662193267
Validation loss: 2.508762324270255

Epoch: 5| Step: 2
Training loss: 1.8256045189439642
Validation loss: 2.488380590226558

Epoch: 5| Step: 3
Training loss: 2.7870944904232013
Validation loss: 2.524353646353391

Epoch: 5| Step: 4
Training loss: 2.3751766741441442
Validation loss: 2.536888689615994

Epoch: 5| Step: 5
Training loss: 1.9632580161854567
Validation loss: 2.5101963525730406

Epoch: 5| Step: 6
Training loss: 2.342327245573087
Validation loss: 2.4897844814521775

Epoch: 5| Step: 7
Training loss: 2.333225270448332
Validation loss: 2.518827643358447

Epoch: 5| Step: 8
Training loss: 2.682609010954048
Validation loss: 2.4396091073281805

Epoch: 5| Step: 9
Training loss: 2.432208357261677
Validation loss: 2.5375378636440304

Epoch: 5| Step: 10
Training loss: 2.0281868947228547
Validation loss: 2.5942698675654117

Epoch: 246| Step: 0
Training loss: 2.0128340212922993
Validation loss: 2.5607825335577092

Epoch: 5| Step: 1
Training loss: 2.1577920237349315
Validation loss: 2.5491837692152326

Epoch: 5| Step: 2
Training loss: 1.9989228924473177
Validation loss: 2.4976931131796576

Epoch: 5| Step: 3
Training loss: 2.412256942127038
Validation loss: 2.4585001016248857

Epoch: 5| Step: 4
Training loss: 2.647753421804648
Validation loss: 2.5168889831382533

Epoch: 5| Step: 5
Training loss: 2.6101159054681897
Validation loss: 2.479388450352953

Epoch: 5| Step: 6
Training loss: 2.2436685488907435
Validation loss: 2.544046378956947

Epoch: 5| Step: 7
Training loss: 2.456060317774362
Validation loss: 2.532069922293111

Epoch: 5| Step: 8
Training loss: 1.784926852589441
Validation loss: 2.5221405750081107

Epoch: 5| Step: 9
Training loss: 2.7047902529022143
Validation loss: 2.471929811556254

Epoch: 5| Step: 10
Training loss: 2.0531722018362384
Validation loss: 2.49899530013636

Epoch: 247| Step: 0
Training loss: 2.7316970354602796
Validation loss: 2.4860807034928696

Epoch: 5| Step: 1
Training loss: 2.533629441105472
Validation loss: 2.5396320592091013

Epoch: 5| Step: 2
Training loss: 2.5979606736857703
Validation loss: 2.5620293583974045

Epoch: 5| Step: 3
Training loss: 2.0461196087939753
Validation loss: 2.487543856944826

Epoch: 5| Step: 4
Training loss: 2.047666556788313
Validation loss: 2.5158470329448592

Epoch: 5| Step: 5
Training loss: 1.7949064667116124
Validation loss: 2.4991367295509472

Epoch: 5| Step: 6
Training loss: 2.5321214847558187
Validation loss: 2.5126654422364596

Epoch: 5| Step: 7
Training loss: 1.705301276742033
Validation loss: 2.558696159562087

Epoch: 5| Step: 8
Training loss: 2.45786968535717
Validation loss: 2.5340329368649543

Epoch: 5| Step: 9
Training loss: 1.9617352325828676
Validation loss: 2.5122085645109262

Epoch: 5| Step: 10
Training loss: 2.612058527391528
Validation loss: 2.480827699217166

Epoch: 248| Step: 0
Training loss: 2.411892208562878
Validation loss: 2.506537240626242

Epoch: 5| Step: 1
Training loss: 2.0508551883992636
Validation loss: 2.549386522562963

Epoch: 5| Step: 2
Training loss: 2.7600325599076703
Validation loss: 2.4924697800978226

Epoch: 5| Step: 3
Training loss: 1.8053149829257757
Validation loss: 2.519972347469805

Epoch: 5| Step: 4
Training loss: 2.1133730827869317
Validation loss: 2.5614906962513677

Epoch: 5| Step: 5
Training loss: 1.8631031263130187
Validation loss: 2.4872879119292777

Epoch: 5| Step: 6
Training loss: 1.9911092794902832
Validation loss: 2.467070017650848

Epoch: 5| Step: 7
Training loss: 2.148654663207853
Validation loss: 2.5158321178412297

Epoch: 5| Step: 8
Training loss: 2.5633868101847503
Validation loss: 2.5486214525323807

Epoch: 5| Step: 9
Training loss: 1.9212507769372742
Validation loss: 2.49588672391081

Epoch: 5| Step: 10
Training loss: 3.0400235340813655
Validation loss: 2.5301138727104093

Epoch: 249| Step: 0
Training loss: 2.6010688565418962
Validation loss: 2.5186952771513775

Epoch: 5| Step: 1
Training loss: 2.440073268915961
Validation loss: 2.5282973753833757

Epoch: 5| Step: 2
Training loss: 2.3580365963685197
Validation loss: 2.557797564963447

Epoch: 5| Step: 3
Training loss: 1.666917384681165
Validation loss: 2.523341340214191

Epoch: 5| Step: 4
Training loss: 1.688925882437651
Validation loss: 2.5001065508378453

Epoch: 5| Step: 5
Training loss: 2.3160522602160776
Validation loss: 2.5454509243345425

Epoch: 5| Step: 6
Training loss: 2.067527423570676
Validation loss: 2.4926573114147867

Epoch: 5| Step: 7
Training loss: 2.4542572907153684
Validation loss: 2.545600714761366

Epoch: 5| Step: 8
Training loss: 2.826414824129084
Validation loss: 2.4791789279909255

Epoch: 5| Step: 9
Training loss: 2.320277152771588
Validation loss: 2.5116442194353787

Epoch: 5| Step: 10
Training loss: 2.0314438947421984
Validation loss: 2.4705664329746515

Epoch: 250| Step: 0
Training loss: 2.2558416192483044
Validation loss: 2.475231993984809

Epoch: 5| Step: 1
Training loss: 2.4494007779123046
Validation loss: 2.5166646105649173

Epoch: 5| Step: 2
Training loss: 1.8095912613044698
Validation loss: 2.4880387223162397

Epoch: 5| Step: 3
Training loss: 2.462013227500058
Validation loss: 2.4735745316326465

Epoch: 5| Step: 4
Training loss: 2.9300618250446497
Validation loss: 2.4944621205496307

Epoch: 5| Step: 5
Training loss: 2.400700796649378
Validation loss: 2.4784323246815805

Epoch: 5| Step: 6
Training loss: 1.992127062310875
Validation loss: 2.524427811843484

Epoch: 5| Step: 7
Training loss: 2.4862697261835187
Validation loss: 2.5251605976276243

Epoch: 5| Step: 8
Training loss: 2.1033619264008316
Validation loss: 2.48120876542597

Epoch: 5| Step: 9
Training loss: 2.1663472478118107
Validation loss: 2.54078102786567

Epoch: 5| Step: 10
Training loss: 1.8308947195747958
Validation loss: 2.5146596313953795

Epoch: 251| Step: 0
Training loss: 1.861982936899774
Validation loss: 2.5792484176328045

Epoch: 5| Step: 1
Training loss: 1.8849833782687548
Validation loss: 2.503565788431126

Epoch: 5| Step: 2
Training loss: 2.5676071631958477
Validation loss: 2.4676482916223734

Epoch: 5| Step: 3
Training loss: 1.969699993720323
Validation loss: 2.4715908424801847

Epoch: 5| Step: 4
Training loss: 2.5854578408880076
Validation loss: 2.4636430942995933

Epoch: 5| Step: 5
Training loss: 1.9458191606330844
Validation loss: 2.42037687829634

Epoch: 5| Step: 6
Training loss: 2.481896849905688
Validation loss: 2.5223814809601843

Epoch: 5| Step: 7
Training loss: 2.3506735708892976
Validation loss: 2.5168388738337195

Epoch: 5| Step: 8
Training loss: 2.348143058993742
Validation loss: 2.486550461427754

Epoch: 5| Step: 9
Training loss: 2.061606705003581
Validation loss: 2.5470175814860174

Epoch: 5| Step: 10
Training loss: 2.456151468178917
Validation loss: 2.5370366129488806

Epoch: 252| Step: 0
Training loss: 2.4046983546358427
Validation loss: 2.5223504889890096

Epoch: 5| Step: 1
Training loss: 2.266787526704509
Validation loss: 2.510420332095674

Epoch: 5| Step: 2
Training loss: 2.502988745401572
Validation loss: 2.484403704354048

Epoch: 5| Step: 3
Training loss: 2.2833102603312767
Validation loss: 2.522866382085738

Epoch: 5| Step: 4
Training loss: 1.9937954266673545
Validation loss: 2.500974707148238

Epoch: 5| Step: 5
Training loss: 2.2161665368971475
Validation loss: 2.5333192875391246

Epoch: 5| Step: 6
Training loss: 2.051180904138264
Validation loss: 2.554606538977216

Epoch: 5| Step: 7
Training loss: 1.518601316858447
Validation loss: 2.5410339809316964

Epoch: 5| Step: 8
Training loss: 2.6866412897859866
Validation loss: 2.5302534543301305

Epoch: 5| Step: 9
Training loss: 2.4783037003381203
Validation loss: 2.542438246401064

Epoch: 5| Step: 10
Training loss: 2.172023740656249
Validation loss: 2.562811866788975

Epoch: 253| Step: 0
Training loss: 2.9066053603936908
Validation loss: 2.5339822863981496

Epoch: 5| Step: 1
Training loss: 2.0291851405791723
Validation loss: 2.5434556730565507

Epoch: 5| Step: 2
Training loss: 2.9085129982033386
Validation loss: 2.5543760423607393

Epoch: 5| Step: 3
Training loss: 1.7557103451293619
Validation loss: 2.4867716377894555

Epoch: 5| Step: 4
Training loss: 1.6541046066877763
Validation loss: 2.5407122627751915

Epoch: 5| Step: 5
Training loss: 2.1968824535693816
Validation loss: 2.4683729179466263

Epoch: 5| Step: 6
Training loss: 2.241378053239829
Validation loss: 2.4918118298940546

Epoch: 5| Step: 7
Training loss: 2.3229408662045836
Validation loss: 2.532926530132196

Epoch: 5| Step: 8
Training loss: 2.405059718225304
Validation loss: 2.5316418560054252

Epoch: 5| Step: 9
Training loss: 1.87965546261192
Validation loss: 2.4931267196423983

Epoch: 5| Step: 10
Training loss: 2.005826450215115
Validation loss: 2.5116311125649706

Epoch: 254| Step: 0
Training loss: 2.2709267506647515
Validation loss: 2.5144511680113224

Epoch: 5| Step: 1
Training loss: 2.2664725987250507
Validation loss: 2.5428051314424325

Epoch: 5| Step: 2
Training loss: 2.0935196251597343
Validation loss: 2.5103353979856324

Epoch: 5| Step: 3
Training loss: 2.339853124329093
Validation loss: 2.4730259739550773

Epoch: 5| Step: 4
Training loss: 2.184492932630175
Validation loss: 2.5476161769902412

Epoch: 5| Step: 5
Training loss: 2.297507270411298
Validation loss: 2.51328535813569

Epoch: 5| Step: 6
Training loss: 2.219467154641178
Validation loss: 2.505534293456793

Epoch: 5| Step: 7
Training loss: 2.228156018141553
Validation loss: 2.4870150920375806

Epoch: 5| Step: 8
Training loss: 2.7236401655960263
Validation loss: 2.5096154660051178

Epoch: 5| Step: 9
Training loss: 2.456094196221739
Validation loss: 2.473468057770186

Epoch: 5| Step: 10
Training loss: 1.776030069650802
Validation loss: 2.4387111520833287

Epoch: 255| Step: 0
Training loss: 1.9155428397402463
Validation loss: 2.5686834210680143

Epoch: 5| Step: 1
Training loss: 1.8523611929469215
Validation loss: 2.532221184595148

Epoch: 5| Step: 2
Training loss: 2.2432315535599447
Validation loss: 2.523200419123915

Epoch: 5| Step: 3
Training loss: 2.2375525441739805
Validation loss: 2.4846437452946915

Epoch: 5| Step: 4
Training loss: 2.851068490491869
Validation loss: 2.449649444841614

Epoch: 5| Step: 5
Training loss: 1.9050272162187871
Validation loss: 2.4845753859348414

Epoch: 5| Step: 6
Training loss: 2.3691763501724714
Validation loss: 2.5591730419676075

Epoch: 5| Step: 7
Training loss: 2.502051370137586
Validation loss: 2.4964080704564915

Epoch: 5| Step: 8
Training loss: 2.2429289439252327
Validation loss: 2.5113167139661225

Epoch: 5| Step: 9
Training loss: 1.8948765390886741
Validation loss: 2.525484016721314

Epoch: 5| Step: 10
Training loss: 2.583109066570474
Validation loss: 2.534710022166555

Epoch: 256| Step: 0
Training loss: 2.518702738959811
Validation loss: 2.565910860554498

Epoch: 5| Step: 1
Training loss: 2.146482597815461
Validation loss: 2.5082821004296805

Epoch: 5| Step: 2
Training loss: 2.005362355315603
Validation loss: 2.475185334479977

Epoch: 5| Step: 3
Training loss: 1.8648486951962997
Validation loss: 2.541910731356359

Epoch: 5| Step: 4
Training loss: 2.7090444853809976
Validation loss: 2.56320539180345

Epoch: 5| Step: 5
Training loss: 2.4480388421486405
Validation loss: 2.519931572598577

Epoch: 5| Step: 6
Training loss: 2.631802418907614
Validation loss: 2.532352690936828

Epoch: 5| Step: 7
Training loss: 2.1161804056187545
Validation loss: 2.52904994207558

Epoch: 5| Step: 8
Training loss: 2.1404953520558863
Validation loss: 2.518041977357473

Epoch: 5| Step: 9
Training loss: 1.9049791571210304
Validation loss: 2.4708346994827837

Epoch: 5| Step: 10
Training loss: 1.803888581702804
Validation loss: 2.5206307265618766

Epoch: 257| Step: 0
Training loss: 2.317018579150882
Validation loss: 2.4750389877882997

Epoch: 5| Step: 1
Training loss: 1.9683560173973522
Validation loss: 2.594706481912456

Epoch: 5| Step: 2
Training loss: 2.108875356768565
Validation loss: 2.5561245077911563

Epoch: 5| Step: 3
Training loss: 1.970624606455804
Validation loss: 2.504962069827425

Epoch: 5| Step: 4
Training loss: 2.2433081826797734
Validation loss: 2.5355031792256897

Epoch: 5| Step: 5
Training loss: 2.6530227803195143
Validation loss: 2.5015872695099417

Epoch: 5| Step: 6
Training loss: 2.3734386732890864
Validation loss: 2.5017142817160822

Epoch: 5| Step: 7
Training loss: 2.1069419109228944
Validation loss: 2.5419767415211982

Epoch: 5| Step: 8
Training loss: 2.451696089052175
Validation loss: 2.52610374064029

Epoch: 5| Step: 9
Training loss: 1.9508402774605182
Validation loss: 2.4990462057790137

Epoch: 5| Step: 10
Training loss: 2.478441746830383
Validation loss: 2.5367668775967

Epoch: 258| Step: 0
Training loss: 2.4268356218662777
Validation loss: 2.5405338811818954

Epoch: 5| Step: 1
Training loss: 2.014014495206491
Validation loss: 2.5216442128759007

Epoch: 5| Step: 2
Training loss: 2.4868585420817957
Validation loss: 2.5216182733142882

Epoch: 5| Step: 3
Training loss: 2.678548676530394
Validation loss: 2.550943263550982

Epoch: 5| Step: 4
Training loss: 1.8774739792159723
Validation loss: 2.5606508954198497

Epoch: 5| Step: 5
Training loss: 2.0979233328427043
Validation loss: 2.462115533037532

Epoch: 5| Step: 6
Training loss: 2.1160075710932778
Validation loss: 2.579027116392232

Epoch: 5| Step: 7
Training loss: 2.465135366657589
Validation loss: 2.512473838750355

Epoch: 5| Step: 8
Training loss: 2.1562283279877836
Validation loss: 2.4826530452888496

Epoch: 5| Step: 9
Training loss: 2.2546180381305763
Validation loss: 2.5442160048189124

Epoch: 5| Step: 10
Training loss: 2.276756564255577
Validation loss: 2.5232465971444142

Epoch: 259| Step: 0
Training loss: 2.0551731710492156
Validation loss: 2.4926660657953708

Epoch: 5| Step: 1
Training loss: 2.107037867223457
Validation loss: 2.5120905226225725

Epoch: 5| Step: 2
Training loss: 2.4955865049080153
Validation loss: 2.5135307483701057

Epoch: 5| Step: 3
Training loss: 1.3053641934304137
Validation loss: 2.5207379817260125

Epoch: 5| Step: 4
Training loss: 1.9436349644612525
Validation loss: 2.555497530940847

Epoch: 5| Step: 5
Training loss: 2.1424165454399398
Validation loss: 2.497914880363996

Epoch: 5| Step: 6
Training loss: 2.070079286503512
Validation loss: 2.4953874357093637

Epoch: 5| Step: 7
Training loss: 3.033293831396875
Validation loss: 2.417833602022553

Epoch: 5| Step: 8
Training loss: 2.160005036454157
Validation loss: 2.4606624399420154

Epoch: 5| Step: 9
Training loss: 2.660088581675358
Validation loss: 2.5190575295109077

Epoch: 5| Step: 10
Training loss: 1.9640150502982028
Validation loss: 2.477475872441143

Epoch: 260| Step: 0
Training loss: 1.8667960933820162
Validation loss: 2.5243280692649384

Epoch: 5| Step: 1
Training loss: 2.5695654064493554
Validation loss: 2.6026950922930387

Epoch: 5| Step: 2
Training loss: 3.202927299539097
Validation loss: 2.505839253916937

Epoch: 5| Step: 3
Training loss: 1.620615178441461
Validation loss: 2.5726607611714893

Epoch: 5| Step: 4
Training loss: 2.6831546518609812
Validation loss: 2.587854423184605

Epoch: 5| Step: 5
Training loss: 1.6372211568321442
Validation loss: 2.501992797306482

Epoch: 5| Step: 6
Training loss: 2.2115812948155176
Validation loss: 2.5467911190652064

Epoch: 5| Step: 7
Training loss: 2.0313910802118236
Validation loss: 2.497339437777997

Epoch: 5| Step: 8
Training loss: 1.8742625375699529
Validation loss: 2.5617704731135134

Epoch: 5| Step: 9
Training loss: 1.8850693215896561
Validation loss: 2.4781746855238724

Epoch: 5| Step: 10
Training loss: 2.4163851628831052
Validation loss: 2.483506183702264

Epoch: 261| Step: 0
Training loss: 2.193349157158413
Validation loss: 2.4986748772569856

Epoch: 5| Step: 1
Training loss: 1.8717467377141153
Validation loss: 2.552277852209222

Epoch: 5| Step: 2
Training loss: 3.014114396838482
Validation loss: 2.5024949503967093

Epoch: 5| Step: 3
Training loss: 2.4365764726818164
Validation loss: 2.522435766047996

Epoch: 5| Step: 4
Training loss: 2.1666832214114273
Validation loss: 2.463206238553535

Epoch: 5| Step: 5
Training loss: 1.8437862069405706
Validation loss: 2.5434965999701196

Epoch: 5| Step: 6
Training loss: 2.0704361788676704
Validation loss: 2.5189195863938347

Epoch: 5| Step: 7
Training loss: 1.7156343831568315
Validation loss: 2.518064606759553

Epoch: 5| Step: 8
Training loss: 2.357133217168475
Validation loss: 2.4743188593826564

Epoch: 5| Step: 9
Training loss: 2.5010431974174097
Validation loss: 2.51760863908374

Epoch: 5| Step: 10
Training loss: 2.244655088679009
Validation loss: 2.487312711152811

Epoch: 262| Step: 0
Training loss: 2.030070740167201
Validation loss: 2.4723075819547744

Epoch: 5| Step: 1
Training loss: 2.2906522991224256
Validation loss: 2.5739914358675917

Epoch: 5| Step: 2
Training loss: 2.080163400540741
Validation loss: 2.4780881455161237

Epoch: 5| Step: 3
Training loss: 1.763502685272275
Validation loss: 2.499255438648817

Epoch: 5| Step: 4
Training loss: 2.514169402187917
Validation loss: 2.450922162783627

Epoch: 5| Step: 5
Training loss: 2.1067510037300394
Validation loss: 2.5114164271741464

Epoch: 5| Step: 6
Training loss: 2.1158404692741977
Validation loss: 2.530355048412069

Epoch: 5| Step: 7
Training loss: 2.3770990632517717
Validation loss: 2.481575508532916

Epoch: 5| Step: 8
Training loss: 2.43619238184931
Validation loss: 2.517684259792199

Epoch: 5| Step: 9
Training loss: 2.158495411132572
Validation loss: 2.494121988704375

Epoch: 5| Step: 10
Training loss: 2.5208787730091284
Validation loss: 2.5410683275766464

Epoch: 263| Step: 0
Training loss: 2.661464643875275
Validation loss: 2.558649212585918

Epoch: 5| Step: 1
Training loss: 1.9091588324068738
Validation loss: 2.5035476411133226

Epoch: 5| Step: 2
Training loss: 2.054564381671063
Validation loss: 2.5342476976597625

Epoch: 5| Step: 3
Training loss: 2.3587259574598782
Validation loss: 2.5372397731817693

Epoch: 5| Step: 4
Training loss: 1.8962765549351261
Validation loss: 2.5085672152647667

Epoch: 5| Step: 5
Training loss: 2.4015303064197604
Validation loss: 2.4658897864627387

Epoch: 5| Step: 6
Training loss: 1.5689881466964233
Validation loss: 2.5431070131548617

Epoch: 5| Step: 7
Training loss: 2.0348664002299186
Validation loss: 2.4698693772680165

Epoch: 5| Step: 8
Training loss: 2.274860893440118
Validation loss: 2.513270649178738

Epoch: 5| Step: 9
Training loss: 2.215241895947767
Validation loss: 2.4892517001456365

Epoch: 5| Step: 10
Training loss: 2.6034303666940763
Validation loss: 2.5007662039941394

Epoch: 264| Step: 0
Training loss: 1.7988562234843992
Validation loss: 2.5519284045414694

Epoch: 5| Step: 1
Training loss: 2.4343327216221997
Validation loss: 2.4811350025777976

Epoch: 5| Step: 2
Training loss: 1.866649725814422
Validation loss: 2.543334571698196

Epoch: 5| Step: 3
Training loss: 2.607066155217989
Validation loss: 2.4918748817225818

Epoch: 5| Step: 4
Training loss: 1.8880606039835097
Validation loss: 2.5911063316740597

Epoch: 5| Step: 5
Training loss: 1.871259900960676
Validation loss: 2.504870096010593

Epoch: 5| Step: 6
Training loss: 1.8803826953071405
Validation loss: 2.53965178385516

Epoch: 5| Step: 7
Training loss: 2.3439040069843986
Validation loss: 2.5423377835625796

Epoch: 5| Step: 8
Training loss: 2.2040745197305354
Validation loss: 2.518612228815399

Epoch: 5| Step: 9
Training loss: 2.6995972120993277
Validation loss: 2.541478247057542

Epoch: 5| Step: 10
Training loss: 2.1688755098023176
Validation loss: 2.4892861989626582

Epoch: 265| Step: 0
Training loss: 2.2003060561482477
Validation loss: 2.5573406448287113

Epoch: 5| Step: 1
Training loss: 2.0086717956170252
Validation loss: 2.5082791170047045

Epoch: 5| Step: 2
Training loss: 1.5674895918651162
Validation loss: 2.5364182736000047

Epoch: 5| Step: 3
Training loss: 2.577207737363657
Validation loss: 2.499933855145663

Epoch: 5| Step: 4
Training loss: 2.446884381311588
Validation loss: 2.481180180128606

Epoch: 5| Step: 5
Training loss: 2.9160027066127947
Validation loss: 2.4779068644900333

Epoch: 5| Step: 6
Training loss: 2.675280625784289
Validation loss: 2.4993719506716765

Epoch: 5| Step: 7
Training loss: 2.0801285571937917
Validation loss: 2.4481022213105277

Epoch: 5| Step: 8
Training loss: 1.7973862293937093
Validation loss: 2.4604015005578086

Epoch: 5| Step: 9
Training loss: 1.734032743208632
Validation loss: 2.468372595982047

Epoch: 5| Step: 10
Training loss: 2.4121209395281986
Validation loss: 2.5079329369131376

Epoch: 266| Step: 0
Training loss: 2.243067870944464
Validation loss: 2.457319633240828

Epoch: 5| Step: 1
Training loss: 2.0288199340650266
Validation loss: 2.521053397826651

Epoch: 5| Step: 2
Training loss: 1.8757882050969559
Validation loss: 2.51910453859344

Epoch: 5| Step: 3
Training loss: 2.2999556246913366
Validation loss: 2.480297993996717

Epoch: 5| Step: 4
Training loss: 1.7651030182424325
Validation loss: 2.44945082562872

Epoch: 5| Step: 5
Training loss: 1.919318631188194
Validation loss: 2.5103986835886625

Epoch: 5| Step: 6
Training loss: 2.382589661231017
Validation loss: 2.4634501365133574

Epoch: 5| Step: 7
Training loss: 1.874148684198126
Validation loss: 2.500866429100491

Epoch: 5| Step: 8
Training loss: 2.417737120840879
Validation loss: 2.4442540923480154

Epoch: 5| Step: 9
Training loss: 3.0771690472076396
Validation loss: 2.475482300739506

Epoch: 5| Step: 10
Training loss: 2.084533676215818
Validation loss: 2.50222764185417

Epoch: 267| Step: 0
Training loss: 2.375742846313098
Validation loss: 2.537888357887408

Epoch: 5| Step: 1
Training loss: 2.0898488837918836
Validation loss: 2.547612970948343

Epoch: 5| Step: 2
Training loss: 1.7140793193593522
Validation loss: 2.455674915843024

Epoch: 5| Step: 3
Training loss: 2.138308866167118
Validation loss: 2.4667030432049524

Epoch: 5| Step: 4
Training loss: 2.302580203006635
Validation loss: 2.5451288297540473

Epoch: 5| Step: 5
Training loss: 2.434471204862002
Validation loss: 2.5061392625373173

Epoch: 5| Step: 6
Training loss: 1.9192935384979979
Validation loss: 2.5483465824603546

Epoch: 5| Step: 7
Training loss: 2.6543902899308716
Validation loss: 2.4812686347793766

Epoch: 5| Step: 8
Training loss: 2.3407886361344965
Validation loss: 2.446661072919628

Epoch: 5| Step: 9
Training loss: 2.8241367776669293
Validation loss: 2.5450519539888066

Epoch: 5| Step: 10
Training loss: 1.8182883735340838
Validation loss: 2.4899413663633427

Epoch: 268| Step: 0
Training loss: 1.9049858529273953
Validation loss: 2.5717652655563814

Epoch: 5| Step: 1
Training loss: 2.0699611149696926
Validation loss: 2.508450737382125

Epoch: 5| Step: 2
Training loss: 2.29054779713675
Validation loss: 2.4460891716305984

Epoch: 5| Step: 3
Training loss: 2.0123999766259373
Validation loss: 2.5534539833674192

Epoch: 5| Step: 4
Training loss: 1.8776405814171728
Validation loss: 2.4859493759693616

Epoch: 5| Step: 5
Training loss: 2.267993084037503
Validation loss: 2.438665932054746

Epoch: 5| Step: 6
Training loss: 2.2326017158805844
Validation loss: 2.498570278463017

Epoch: 5| Step: 7
Training loss: 2.112687737965413
Validation loss: 2.5018103044063342

Epoch: 5| Step: 8
Training loss: 2.287383208915264
Validation loss: 2.5114675276380902

Epoch: 5| Step: 9
Training loss: 2.423314903203187
Validation loss: 2.4883983083099004

Epoch: 5| Step: 10
Training loss: 2.367478154533812
Validation loss: 2.4883721174806435

Epoch: 269| Step: 0
Training loss: 1.8781992004259593
Validation loss: 2.5537157667002965

Epoch: 5| Step: 1
Training loss: 1.6178350948754991
Validation loss: 2.5399522528368603

Epoch: 5| Step: 2
Training loss: 1.8739093787552767
Validation loss: 2.529483873298912

Epoch: 5| Step: 3
Training loss: 2.5916531831282232
Validation loss: 2.469071320214843

Epoch: 5| Step: 4
Training loss: 2.4353579376771157
Validation loss: 2.572901349376852

Epoch: 5| Step: 5
Training loss: 2.3087537164663363
Validation loss: 2.4916422983047237

Epoch: 5| Step: 6
Training loss: 2.496201299460682
Validation loss: 2.484187962121464

Epoch: 5| Step: 7
Training loss: 2.0970481971582897
Validation loss: 2.5408324851866313

Epoch: 5| Step: 8
Training loss: 2.1726124561207336
Validation loss: 2.517145747749765

Epoch: 5| Step: 9
Training loss: 2.8193932723322344
Validation loss: 2.4786305329116605

Epoch: 5| Step: 10
Training loss: 1.7871910201636845
Validation loss: 2.475628281046103

Epoch: 270| Step: 0
Training loss: 2.320323391769996
Validation loss: 2.4763956952857047

Epoch: 5| Step: 1
Training loss: 2.2469311024077454
Validation loss: 2.5711692391835164

Epoch: 5| Step: 2
Training loss: 2.223975998200086
Validation loss: 2.507070189307993

Epoch: 5| Step: 3
Training loss: 1.806795614656705
Validation loss: 2.5930165749947456

Epoch: 5| Step: 4
Training loss: 2.0588927658043636
Validation loss: 2.4601550255326345

Epoch: 5| Step: 5
Training loss: 2.6952902972647568
Validation loss: 2.447364482420411

Epoch: 5| Step: 6
Training loss: 1.887330897758275
Validation loss: 2.4725792780879208

Epoch: 5| Step: 7
Training loss: 1.5464561743115006
Validation loss: 2.4719003234904435

Epoch: 5| Step: 8
Training loss: 2.100782965974685
Validation loss: 2.4998568996369213

Epoch: 5| Step: 9
Training loss: 3.0581684230931274
Validation loss: 2.465899512287056

Epoch: 5| Step: 10
Training loss: 1.773137273036688
Validation loss: 2.5022962545801404

Epoch: 271| Step: 0
Training loss: 1.7209603402080391
Validation loss: 2.509358943311182

Epoch: 5| Step: 1
Training loss: 2.0892692560611974
Validation loss: 2.4666808431706326

Epoch: 5| Step: 2
Training loss: 2.4453281974898013
Validation loss: 2.539754434335278

Epoch: 5| Step: 3
Training loss: 2.1833077722853753
Validation loss: 2.5176244300735946

Epoch: 5| Step: 4
Training loss: 1.9750720047198596
Validation loss: 2.4933917270760735

Epoch: 5| Step: 5
Training loss: 2.381187610359583
Validation loss: 2.549018389271371

Epoch: 5| Step: 6
Training loss: 2.109330805562784
Validation loss: 2.5184207718699536

Epoch: 5| Step: 7
Training loss: 2.2724945105223036
Validation loss: 2.520411318183331

Epoch: 5| Step: 8
Training loss: 2.2273110720814024
Validation loss: 2.492506272939024

Epoch: 5| Step: 9
Training loss: 1.957460885467075
Validation loss: 2.522463275046894

Epoch: 5| Step: 10
Training loss: 2.9419906056018785
Validation loss: 2.486025824609415

Epoch: 272| Step: 0
Training loss: 2.3130727522607186
Validation loss: 2.5529624129789097

Epoch: 5| Step: 1
Training loss: 2.048642160069007
Validation loss: 2.502139836950396

Epoch: 5| Step: 2
Training loss: 1.9967632925102885
Validation loss: 2.499131434824572

Epoch: 5| Step: 3
Training loss: 1.9044429155739506
Validation loss: 2.463543791983456

Epoch: 5| Step: 4
Training loss: 2.03128051734888
Validation loss: 2.423004249141917

Epoch: 5| Step: 5
Training loss: 2.0795719014289675
Validation loss: 2.4794735362263274

Epoch: 5| Step: 6
Training loss: 2.264100712992737
Validation loss: 2.4866603267893144

Epoch: 5| Step: 7
Training loss: 2.3408952747957428
Validation loss: 2.5428463581733953

Epoch: 5| Step: 8
Training loss: 2.662519886497769
Validation loss: 2.511966740094532

Epoch: 5| Step: 9
Training loss: 1.8576357745404941
Validation loss: 2.5016762169552242

Epoch: 5| Step: 10
Training loss: 2.8167252062370536
Validation loss: 2.5057516446283246

Epoch: 273| Step: 0
Training loss: 1.6742781720672755
Validation loss: 2.507197139504824

Epoch: 5| Step: 1
Training loss: 2.777936182803698
Validation loss: 2.5149334350762214

Epoch: 5| Step: 2
Training loss: 2.5699820726415057
Validation loss: 2.464816054529907

Epoch: 5| Step: 3
Training loss: 1.8333016811875222
Validation loss: 2.503590907943953

Epoch: 5| Step: 4
Training loss: 2.137045436063721
Validation loss: 2.4757765981299866

Epoch: 5| Step: 5
Training loss: 2.7827495861277636
Validation loss: 2.5298144666561377

Epoch: 5| Step: 6
Training loss: 2.0106658254076937
Validation loss: 2.4541948361956982

Epoch: 5| Step: 7
Training loss: 1.8576471330533046
Validation loss: 2.4806880286531308

Epoch: 5| Step: 8
Training loss: 2.0860149926353624
Validation loss: 2.4849898086506905

Epoch: 5| Step: 9
Training loss: 1.9798068232656794
Validation loss: 2.514784021988447

Epoch: 5| Step: 10
Training loss: 2.5505527084339494
Validation loss: 2.5215418291263316

Epoch: 274| Step: 0
Training loss: 1.9295509073817816
Validation loss: 2.5401025683656973

Epoch: 5| Step: 1
Training loss: 2.5440053863168473
Validation loss: 2.472514426725985

Epoch: 5| Step: 2
Training loss: 2.213743121385792
Validation loss: 2.558117971213633

Epoch: 5| Step: 3
Training loss: 2.121589841488069
Validation loss: 2.557138883072034

Epoch: 5| Step: 4
Training loss: 2.1630061356611345
Validation loss: 2.499803525115782

Epoch: 5| Step: 5
Training loss: 1.6039947648854809
Validation loss: 2.5239301605891598

Epoch: 5| Step: 6
Training loss: 2.5788293974391157
Validation loss: 2.5759009091783156

Epoch: 5| Step: 7
Training loss: 2.2298181122642577
Validation loss: 2.4629946656428334

Epoch: 5| Step: 8
Training loss: 2.2195568498144187
Validation loss: 2.526642533034801

Epoch: 5| Step: 9
Training loss: 2.4792048560868913
Validation loss: 2.5850238455585783

Epoch: 5| Step: 10
Training loss: 1.6165485686331098
Validation loss: 2.460255582718212

Epoch: 275| Step: 0
Training loss: 2.3709023915330216
Validation loss: 2.4626045150319116

Epoch: 5| Step: 1
Training loss: 2.3666569584213075
Validation loss: 2.538804151140362

Epoch: 5| Step: 2
Training loss: 2.6444095375079457
Validation loss: 2.5086327196256

Epoch: 5| Step: 3
Training loss: 1.9164243489657602
Validation loss: 2.4429694959522483

Epoch: 5| Step: 4
Training loss: 2.264497252661617
Validation loss: 2.5007319107065795

Epoch: 5| Step: 5
Training loss: 2.287844076492335
Validation loss: 2.5217234491651026

Epoch: 5| Step: 6
Training loss: 1.6516213427322488
Validation loss: 2.4916932898655557

Epoch: 5| Step: 7
Training loss: 2.0851205661960486
Validation loss: 2.5081207665548537

Epoch: 5| Step: 8
Training loss: 1.8665298516793358
Validation loss: 2.536759777155397

Epoch: 5| Step: 9
Training loss: 2.4766871664637264
Validation loss: 2.54219276037463

Epoch: 5| Step: 10
Training loss: 1.9333788203226792
Validation loss: 2.528482012710194

Epoch: 276| Step: 0
Training loss: 1.8669712468136281
Validation loss: 2.469864258014005

Epoch: 5| Step: 1
Training loss: 2.035862893342649
Validation loss: 2.4589205777939647

Epoch: 5| Step: 2
Training loss: 2.4467257477316573
Validation loss: 2.5296859821368054

Epoch: 5| Step: 3
Training loss: 2.0089855997377417
Validation loss: 2.46711407176102

Epoch: 5| Step: 4
Training loss: 2.373096506361134
Validation loss: 2.467513776335252

Epoch: 5| Step: 5
Training loss: 2.2395503788379103
Validation loss: 2.566241313624985

Epoch: 5| Step: 6
Training loss: 1.900209831898288
Validation loss: 2.449638629938746

Epoch: 5| Step: 7
Training loss: 2.7161815393477666
Validation loss: 2.4480304989151116

Epoch: 5| Step: 8
Training loss: 2.325573848335085
Validation loss: 2.488099021843698

Epoch: 5| Step: 9
Training loss: 2.1652698660523755
Validation loss: 2.401572848169674

Epoch: 5| Step: 10
Training loss: 1.7250646247368335
Validation loss: 2.487670887455824

Epoch: 277| Step: 0
Training loss: 2.024233863859535
Validation loss: 2.511471384119123

Epoch: 5| Step: 1
Training loss: 1.8445751477405932
Validation loss: 2.526906911881059

Epoch: 5| Step: 2
Training loss: 2.4967714443384024
Validation loss: 2.5109767568998893

Epoch: 5| Step: 3
Training loss: 2.2228368809785564
Validation loss: 2.5469665983965992

Epoch: 5| Step: 4
Training loss: 2.5617357370384006
Validation loss: 2.4451450989221457

Epoch: 5| Step: 5
Training loss: 2.710618233913063
Validation loss: 2.485633770090305

Epoch: 5| Step: 6
Training loss: 1.683170769965451
Validation loss: 2.5220734489974768

Epoch: 5| Step: 7
Training loss: 1.5272891139724303
Validation loss: 2.5339901179886066

Epoch: 5| Step: 8
Training loss: 2.0879888270579765
Validation loss: 2.5308548955574763

Epoch: 5| Step: 9
Training loss: 2.383662938176901
Validation loss: 2.514461862181798

Epoch: 5| Step: 10
Training loss: 2.6516602299786154
Validation loss: 2.478293592866737

Epoch: 278| Step: 0
Training loss: 2.038941595358893
Validation loss: 2.455243798942471

Epoch: 5| Step: 1
Training loss: 2.37282362150703
Validation loss: 2.526934317421259

Epoch: 5| Step: 2
Training loss: 2.0759396642983456
Validation loss: 2.5144564360863026

Epoch: 5| Step: 3
Training loss: 1.8053393487186786
Validation loss: 2.4996387743704234

Epoch: 5| Step: 4
Training loss: 1.631639122865226
Validation loss: 2.5473287988284428

Epoch: 5| Step: 5
Training loss: 2.061921240781528
Validation loss: 2.4778274877279967

Epoch: 5| Step: 6
Training loss: 1.9847312066874627
Validation loss: 2.5009047768091666

Epoch: 5| Step: 7
Training loss: 2.386205539998571
Validation loss: 2.5108451857074936

Epoch: 5| Step: 8
Training loss: 2.4115022088186455
Validation loss: 2.4789073750244723

Epoch: 5| Step: 9
Training loss: 2.6193097520082143
Validation loss: 2.494031455091567

Epoch: 5| Step: 10
Training loss: 2.1105492608259695
Validation loss: 2.513627875004059

Epoch: 279| Step: 0
Training loss: 2.1812653112010745
Validation loss: 2.4709330541161054

Epoch: 5| Step: 1
Training loss: 1.90764816788636
Validation loss: 2.5172152136613937

Epoch: 5| Step: 2
Training loss: 2.076171875
Validation loss: 2.554707139512865

Epoch: 5| Step: 3
Training loss: 2.188407491728521
Validation loss: 2.514432311128378

Epoch: 5| Step: 4
Training loss: 2.7716415392970966
Validation loss: 2.5181444173787613

Epoch: 5| Step: 5
Training loss: 1.6883777878542625
Validation loss: 2.529111799965509

Epoch: 5| Step: 6
Training loss: 2.061859725058393
Validation loss: 2.475604670876581

Epoch: 5| Step: 7
Training loss: 1.8369178264930204
Validation loss: 2.5411213609758483

Epoch: 5| Step: 8
Training loss: 2.151479003881815
Validation loss: 2.4731743035339844

Epoch: 5| Step: 9
Training loss: 2.844778357052942
Validation loss: 2.4866333877289444

Epoch: 5| Step: 10
Training loss: 2.1658750579599726
Validation loss: 2.5003577068743486

Epoch: 280| Step: 0
Training loss: 1.8231651645403943
Validation loss: 2.510748490550093

Epoch: 5| Step: 1
Training loss: 1.9847355312325035
Validation loss: 2.530379210005527

Epoch: 5| Step: 2
Training loss: 2.2438906272236485
Validation loss: 2.4846359294424616

Epoch: 5| Step: 3
Training loss: 2.2350591932475874
Validation loss: 2.5074082426564503

Epoch: 5| Step: 4
Training loss: 2.485429456048522
Validation loss: 2.459078968889162

Epoch: 5| Step: 5
Training loss: 1.6529219677571414
Validation loss: 2.48472763183034

Epoch: 5| Step: 6
Training loss: 2.3296087260651386
Validation loss: 2.4461738164816333

Epoch: 5| Step: 7
Training loss: 2.234138743040982
Validation loss: 2.4614232477350337

Epoch: 5| Step: 8
Training loss: 2.286335124271172
Validation loss: 2.498435473292311

Epoch: 5| Step: 9
Training loss: 2.8040683243517903
Validation loss: 2.46080057076066

Epoch: 5| Step: 10
Training loss: 1.8092901812818771
Validation loss: 2.509585710782404

Epoch: 281| Step: 0
Training loss: 2.2148709842144503
Validation loss: 2.5144494102846036

Epoch: 5| Step: 1
Training loss: 2.28736444707419
Validation loss: 2.503703808496853

Epoch: 5| Step: 2
Training loss: 1.4146883933483931
Validation loss: 2.5101602476382867

Epoch: 5| Step: 3
Training loss: 2.318157492559304
Validation loss: 2.489873838180945

Epoch: 5| Step: 4
Training loss: 2.5876689542443896
Validation loss: 2.5300125445592725

Epoch: 5| Step: 5
Training loss: 1.6220268046166868
Validation loss: 2.5044794088791575

Epoch: 5| Step: 6
Training loss: 1.7959827363898575
Validation loss: 2.467077550393114

Epoch: 5| Step: 7
Training loss: 1.9186261637236364
Validation loss: 2.475509426391443

Epoch: 5| Step: 8
Training loss: 2.3762691519907078
Validation loss: 2.4984699068650533

Epoch: 5| Step: 9
Training loss: 2.777259449812838
Validation loss: 2.5487058676918934

Epoch: 5| Step: 10
Training loss: 2.394288291864734
Validation loss: 2.483319765863096

Epoch: 282| Step: 0
Training loss: 2.425209653777712
Validation loss: 2.53983758977053

Epoch: 5| Step: 1
Training loss: 1.9622801785150152
Validation loss: 2.467540268556804

Epoch: 5| Step: 2
Training loss: 1.8188835724222334
Validation loss: 2.422157743729181

Epoch: 5| Step: 3
Training loss: 1.778665508051604
Validation loss: 2.4696126344315643

Epoch: 5| Step: 4
Training loss: 2.2524379661561906
Validation loss: 2.5212569313491526

Epoch: 5| Step: 5
Training loss: 2.308300845288239
Validation loss: 2.464939362921795

Epoch: 5| Step: 6
Training loss: 1.9154079146230536
Validation loss: 2.5030060097930322

Epoch: 5| Step: 7
Training loss: 2.266728836029768
Validation loss: 2.4507722154973464

Epoch: 5| Step: 8
Training loss: 2.5265205375097866
Validation loss: 2.4552469172918174

Epoch: 5| Step: 9
Training loss: 2.288477175091398
Validation loss: 2.4253703024191786

Epoch: 5| Step: 10
Training loss: 2.2426294828220956
Validation loss: 2.464934408156398

Epoch: 283| Step: 0
Training loss: 2.042653746964123
Validation loss: 2.541700683344599

Epoch: 5| Step: 1
Training loss: 2.0707748184789274
Validation loss: 2.4843405243084886

Epoch: 5| Step: 2
Training loss: 2.4238571423461996
Validation loss: 2.4622177135459618

Epoch: 5| Step: 3
Training loss: 2.1226405340068504
Validation loss: 2.469500453456274

Epoch: 5| Step: 4
Training loss: 1.9939507553769136
Validation loss: 2.4622969511237573

Epoch: 5| Step: 5
Training loss: 1.8972407206832316
Validation loss: 2.5708221011158168

Epoch: 5| Step: 6
Training loss: 1.7733708843877978
Validation loss: 2.5615708221950206

Epoch: 5| Step: 7
Training loss: 2.909005612239099
Validation loss: 2.526035674612087

Epoch: 5| Step: 8
Training loss: 2.2884842594698056
Validation loss: 2.5805621359400543

Epoch: 5| Step: 9
Training loss: 2.372830554537271
Validation loss: 2.525026215033719

Epoch: 5| Step: 10
Training loss: 2.14741819303611
Validation loss: 2.5382837173658537

Epoch: 284| Step: 0
Training loss: 2.7589877382830714
Validation loss: 2.4853391741517146

Epoch: 5| Step: 1
Training loss: 2.4142268350214113
Validation loss: 2.4691982295928576

Epoch: 5| Step: 2
Training loss: 1.9696877683300118
Validation loss: 2.488121925379285

Epoch: 5| Step: 3
Training loss: 2.685140061516974
Validation loss: 2.4827748978180972

Epoch: 5| Step: 4
Training loss: 1.5615868761298712
Validation loss: 2.5406344042514424

Epoch: 5| Step: 5
Training loss: 2.0880649875670696
Validation loss: 2.433363658737416

Epoch: 5| Step: 6
Training loss: 1.5613897575332718
Validation loss: 2.4287975121401817

Epoch: 5| Step: 7
Training loss: 2.7704534246291797
Validation loss: 2.472398552277575

Epoch: 5| Step: 8
Training loss: 1.914654138173862
Validation loss: 2.5061225020519458

Epoch: 5| Step: 9
Training loss: 2.069185000320599
Validation loss: 2.5450334290999064

Epoch: 5| Step: 10
Training loss: 1.894179541592603
Validation loss: 2.4903246153169056

Epoch: 285| Step: 0
Training loss: 1.745571117996806
Validation loss: 2.474087744514052

Epoch: 5| Step: 1
Training loss: 2.39387819429959
Validation loss: 2.447141939377758

Epoch: 5| Step: 2
Training loss: 1.5472736808183842
Validation loss: 2.500364478009449

Epoch: 5| Step: 3
Training loss: 2.0739413720712596
Validation loss: 2.4740924765591066

Epoch: 5| Step: 4
Training loss: 2.710786930706913
Validation loss: 2.511218198369291

Epoch: 5| Step: 5
Training loss: 2.26080577917447
Validation loss: 2.487804410746458

Epoch: 5| Step: 6
Training loss: 2.115579480085789
Validation loss: 2.4854377134508656

Epoch: 5| Step: 7
Training loss: 2.692781625681139
Validation loss: 2.493605695306665

Epoch: 5| Step: 8
Training loss: 2.171206364519859
Validation loss: 2.572874884838878

Epoch: 5| Step: 9
Training loss: 1.8565431716547216
Validation loss: 2.5554068151878586

Epoch: 5| Step: 10
Training loss: 1.8749855676731337
Validation loss: 2.4352790847202805

Epoch: 286| Step: 0
Training loss: 2.0750128596263555
Validation loss: 2.466353023707699

Epoch: 5| Step: 1
Training loss: 2.219016045751745
Validation loss: 2.4978666093536415

Epoch: 5| Step: 2
Training loss: 1.8580616391718974
Validation loss: 2.542928654375866

Epoch: 5| Step: 3
Training loss: 1.8837253367955409
Validation loss: 2.5404041435402633

Epoch: 5| Step: 4
Training loss: 1.9372269222643865
Validation loss: 2.5041235111098294

Epoch: 5| Step: 5
Training loss: 1.6815194718761677
Validation loss: 2.504770573562498

Epoch: 5| Step: 6
Training loss: 2.069899031899455
Validation loss: 2.44734577563984

Epoch: 5| Step: 7
Training loss: 2.34052919973549
Validation loss: 2.4836759424108954

Epoch: 5| Step: 8
Training loss: 2.4470402765299384
Validation loss: 2.5215624211961574

Epoch: 5| Step: 9
Training loss: 2.545480451668777
Validation loss: 2.475020443825775

Epoch: 5| Step: 10
Training loss: 2.772045377120465
Validation loss: 2.4237704837904084

Epoch: 287| Step: 0
Training loss: 1.617078547101636
Validation loss: 2.4572677937969565

Epoch: 5| Step: 1
Training loss: 2.2421732513293997
Validation loss: 2.4984209642188406

Epoch: 5| Step: 2
Training loss: 1.9658058192500074
Validation loss: 2.5253540510487356

Epoch: 5| Step: 3
Training loss: 2.375435437891816
Validation loss: 2.460781322549248

Epoch: 5| Step: 4
Training loss: 1.5791186990557098
Validation loss: 2.473957114529701

Epoch: 5| Step: 5
Training loss: 2.270629197024124
Validation loss: 2.4833974815794155

Epoch: 5| Step: 6
Training loss: 2.4010808338824003
Validation loss: 2.5092127282310503

Epoch: 5| Step: 7
Training loss: 2.469117245942899
Validation loss: 2.5004487219465985

Epoch: 5| Step: 8
Training loss: 2.689698052317468
Validation loss: 2.4635759410352693

Epoch: 5| Step: 9
Training loss: 1.9920134225224597
Validation loss: 2.552841782684626

Epoch: 5| Step: 10
Training loss: 1.5847288139192053
Validation loss: 2.521829367815651

Epoch: 288| Step: 0
Training loss: 1.6923718240230397
Validation loss: 2.444094517099274

Epoch: 5| Step: 1
Training loss: 2.356924843717573
Validation loss: 2.4883100504403006

Epoch: 5| Step: 2
Training loss: 2.1567225284014073
Validation loss: 2.5324816627285185

Epoch: 5| Step: 3
Training loss: 2.2529823882408917
Validation loss: 2.484770416453189

Epoch: 5| Step: 4
Training loss: 2.3539696219922224
Validation loss: 2.5294141514085964

Epoch: 5| Step: 5
Training loss: 2.519898191242272
Validation loss: 2.4582475630235976

Epoch: 5| Step: 6
Training loss: 2.0643632737512996
Validation loss: 2.5218758743849214

Epoch: 5| Step: 7
Training loss: 2.322223120734342
Validation loss: 2.497002115720053

Epoch: 5| Step: 8
Training loss: 2.134651146111346
Validation loss: 2.4731903372865394

Epoch: 5| Step: 9
Training loss: 2.3315761511873037
Validation loss: 2.455591306330411

Epoch: 5| Step: 10
Training loss: 0.9941454814200205
Validation loss: 2.512162035620413

Epoch: 289| Step: 0
Training loss: 2.0532962164475994
Validation loss: 2.4497213793706325

Epoch: 5| Step: 1
Training loss: 2.2048440273420717
Validation loss: 2.494415379849963

Epoch: 5| Step: 2
Training loss: 1.7945356980942506
Validation loss: 2.466995583693168

Epoch: 5| Step: 3
Training loss: 2.3511570172173943
Validation loss: 2.45680284141938

Epoch: 5| Step: 4
Training loss: 1.9950732703843912
Validation loss: 2.5029819444932664

Epoch: 5| Step: 5
Training loss: 2.134479695512853
Validation loss: 2.529537277272521

Epoch: 5| Step: 6
Training loss: 2.4133791650807384
Validation loss: 2.5279563380375802

Epoch: 5| Step: 7
Training loss: 2.6358210639133373
Validation loss: 2.486982839837519

Epoch: 5| Step: 8
Training loss: 1.9786205207455412
Validation loss: 2.531515066309964

Epoch: 5| Step: 9
Training loss: 1.92158648798684
Validation loss: 2.5138455461997298

Epoch: 5| Step: 10
Training loss: 1.9262285003353445
Validation loss: 2.5172796884357287

Epoch: 290| Step: 0
Training loss: 2.0566850242640418
Validation loss: 2.5015379123358557

Epoch: 5| Step: 1
Training loss: 1.857938002830081
Validation loss: 2.5434118193973254

Epoch: 5| Step: 2
Training loss: 1.517076642654586
Validation loss: 2.4818946177299614

Epoch: 5| Step: 3
Training loss: 2.2029073621239394
Validation loss: 2.5381476499144706

Epoch: 5| Step: 4
Training loss: 2.7871616414762443
Validation loss: 2.487095620722579

Epoch: 5| Step: 5
Training loss: 1.9935548764596205
Validation loss: 2.460282789764241

Epoch: 5| Step: 6
Training loss: 2.5191388911428945
Validation loss: 2.3841201085815578

Epoch: 5| Step: 7
Training loss: 2.2143659665028177
Validation loss: 2.506953111135016

Epoch: 5| Step: 8
Training loss: 1.9862178745636658
Validation loss: 2.509425510927979

Epoch: 5| Step: 9
Training loss: 1.8564577057097178
Validation loss: 2.5016688929193167

Epoch: 5| Step: 10
Training loss: 2.0592154734853403
Validation loss: 2.5440846360758926

Epoch: 291| Step: 0
Training loss: 2.5850650664059676
Validation loss: 2.5412611722798686

Epoch: 5| Step: 1
Training loss: 2.1161464933080927
Validation loss: 2.511856269519706

Epoch: 5| Step: 2
Training loss: 1.8097439562700186
Validation loss: 2.5511331751235895

Epoch: 5| Step: 3
Training loss: 1.7288423563462703
Validation loss: 2.5515673566365766

Epoch: 5| Step: 4
Training loss: 1.7562191672011296
Validation loss: 2.4576968204509186

Epoch: 5| Step: 5
Training loss: 2.085343065465151
Validation loss: 2.4718443104421595

Epoch: 5| Step: 6
Training loss: 2.045443434636929
Validation loss: 2.494507611701183

Epoch: 5| Step: 7
Training loss: 2.585365070706287
Validation loss: 2.4686808391461526

Epoch: 5| Step: 8
Training loss: 2.0645386994814348
Validation loss: 2.5009978676823965

Epoch: 5| Step: 9
Training loss: 2.4387577430997136
Validation loss: 2.4555932784481667

Epoch: 5| Step: 10
Training loss: 2.094519061145938
Validation loss: 2.4681870428856896

Epoch: 292| Step: 0
Training loss: 2.6732457086023333
Validation loss: 2.4310023860907455

Epoch: 5| Step: 1
Training loss: 2.2003271856631925
Validation loss: 2.496441338714843

Epoch: 5| Step: 2
Training loss: 1.979570294096835
Validation loss: 2.527802325653933

Epoch: 5| Step: 3
Training loss: 1.630318521141558
Validation loss: 2.4833017162923636

Epoch: 5| Step: 4
Training loss: 2.187658685650562
Validation loss: 2.4969411554109473

Epoch: 5| Step: 5
Training loss: 1.9792338175842665
Validation loss: 2.527977255104932

Epoch: 5| Step: 6
Training loss: 2.597068043131388
Validation loss: 2.530242178455709

Epoch: 5| Step: 7
Training loss: 2.133056403106924
Validation loss: 2.4657253180560135

Epoch: 5| Step: 8
Training loss: 1.8740635122652995
Validation loss: 2.47078498738112

Epoch: 5| Step: 9
Training loss: 1.7173111875381672
Validation loss: 2.5001192331081064

Epoch: 5| Step: 10
Training loss: 1.9897585553674186
Validation loss: 2.47969892197715

Epoch: 293| Step: 0
Training loss: 2.4082080751292394
Validation loss: 2.4751320172804454

Epoch: 5| Step: 1
Training loss: 1.9223126169068185
Validation loss: 2.421234123338061

Epoch: 5| Step: 2
Training loss: 2.249376316520643
Validation loss: 2.4469305820208302

Epoch: 5| Step: 3
Training loss: 2.642039805953475
Validation loss: 2.5332949799266586

Epoch: 5| Step: 4
Training loss: 2.7070714113633394
Validation loss: 2.5127434567834595

Epoch: 5| Step: 5
Training loss: 1.7155200085363973
Validation loss: 2.5010363922437318

Epoch: 5| Step: 6
Training loss: 1.356240791957554
Validation loss: 2.495688751085165

Epoch: 5| Step: 7
Training loss: 2.2077028586126053
Validation loss: 2.5752275355637595

Epoch: 5| Step: 8
Training loss: 2.6775766850735505
Validation loss: 2.4722811988877167

Epoch: 5| Step: 9
Training loss: 1.442953710885565
Validation loss: 2.5013760763436768

Epoch: 5| Step: 10
Training loss: 1.9493548206240092
Validation loss: 2.5240931734554986

Epoch: 294| Step: 0
Training loss: 2.253457909061671
Validation loss: 2.478401752360036

Epoch: 5| Step: 1
Training loss: 2.0153148323763688
Validation loss: 2.4844727783609133

Epoch: 5| Step: 2
Training loss: 2.1926211764908663
Validation loss: 2.4885591932001745

Epoch: 5| Step: 3
Training loss: 2.781295090213409
Validation loss: 2.5219583750922823

Epoch: 5| Step: 4
Training loss: 1.8725816389553254
Validation loss: 2.5149342770733814

Epoch: 5| Step: 5
Training loss: 2.0227428996775147
Validation loss: 2.5085109964269376

Epoch: 5| Step: 6
Training loss: 1.9337384410628584
Validation loss: 2.5213770051724436

Epoch: 5| Step: 7
Training loss: 2.014749026133445
Validation loss: 2.46182050644057

Epoch: 5| Step: 8
Training loss: 1.7438410964195583
Validation loss: 2.4862557421045954

Epoch: 5| Step: 9
Training loss: 2.1855932372274816
Validation loss: 2.452105937846639

Epoch: 5| Step: 10
Training loss: 2.352023057415885
Validation loss: 2.498348656676822

Epoch: 295| Step: 0
Training loss: 1.296094636646632
Validation loss: 2.5124564730965977

Epoch: 5| Step: 1
Training loss: 1.453111710026172
Validation loss: 2.471340847499241

Epoch: 5| Step: 2
Training loss: 1.7453678678986884
Validation loss: 2.451088673542005

Epoch: 5| Step: 3
Training loss: 2.663011718431991
Validation loss: 2.429649034864401

Epoch: 5| Step: 4
Training loss: 2.2691427348043858
Validation loss: 2.551250826419734

Epoch: 5| Step: 5
Training loss: 2.0976186283651987
Validation loss: 2.43430906004249

Epoch: 5| Step: 6
Training loss: 2.3423515725515704
Validation loss: 2.4847766099894018

Epoch: 5| Step: 7
Training loss: 2.028633545302529
Validation loss: 2.496908078622745

Epoch: 5| Step: 8
Training loss: 2.2520641818954052
Validation loss: 2.5182896954723692

Epoch: 5| Step: 9
Training loss: 2.5479953852481465
Validation loss: 2.50298453375692

Epoch: 5| Step: 10
Training loss: 2.1102962036497797
Validation loss: 2.4687588921175605

Epoch: 296| Step: 0
Training loss: 3.2091546596823193
Validation loss: 2.4634482424917654

Epoch: 5| Step: 1
Training loss: 1.6067089479008856
Validation loss: 2.4502992916396322

Epoch: 5| Step: 2
Training loss: 1.805276287521924
Validation loss: 2.4085840944628396

Epoch: 5| Step: 3
Training loss: 2.073967697554146
Validation loss: 2.419777499165257

Epoch: 5| Step: 4
Training loss: 2.3816462429906986
Validation loss: 2.469784214315797

Epoch: 5| Step: 5
Training loss: 1.7010223988712765
Validation loss: 2.478766420325185

Epoch: 5| Step: 6
Training loss: 2.1754116107341486
Validation loss: 2.4819989401026663

Epoch: 5| Step: 7
Training loss: 1.9754571651139265
Validation loss: 2.513280085565943

Epoch: 5| Step: 8
Training loss: 1.7801264515440858
Validation loss: 2.4703794496359124

Epoch: 5| Step: 9
Training loss: 1.891312781462389
Validation loss: 2.504760007916935

Epoch: 5| Step: 10
Training loss: 2.031744911349883
Validation loss: 2.5150169004963034

Epoch: 297| Step: 0
Training loss: 2.080322595118835
Validation loss: 2.5039176598306

Epoch: 5| Step: 1
Training loss: 1.3765214392159517
Validation loss: 2.5025411652560297

Epoch: 5| Step: 2
Training loss: 1.7093113526484778
Validation loss: 2.453249735156368

Epoch: 5| Step: 3
Training loss: 2.394147484349878
Validation loss: 2.475060707342974

Epoch: 5| Step: 4
Training loss: 2.6793688704231684
Validation loss: 2.509179091886968

Epoch: 5| Step: 5
Training loss: 2.2046224496654405
Validation loss: 2.486501226429772

Epoch: 5| Step: 6
Training loss: 1.7020173977143103
Validation loss: 2.547667303052325

Epoch: 5| Step: 7
Training loss: 2.5407065365553376
Validation loss: 2.525690180930767

Epoch: 5| Step: 8
Training loss: 2.055775401527579
Validation loss: 2.5352063117428263

Epoch: 5| Step: 9
Training loss: 1.8363242533338053
Validation loss: 2.5051431992575304

Epoch: 5| Step: 10
Training loss: 2.4214025221145663
Validation loss: 2.473818065939276

Epoch: 298| Step: 0
Training loss: 1.9508548207860208
Validation loss: 2.504562392553305

Epoch: 5| Step: 1
Training loss: 2.2319179443398256
Validation loss: 2.508612030619084

Epoch: 5| Step: 2
Training loss: 1.8903976177589623
Validation loss: 2.410898909210987

Epoch: 5| Step: 3
Training loss: 2.4209928813453083
Validation loss: 2.495533562970336

Epoch: 5| Step: 4
Training loss: 2.0910809713892595
Validation loss: 2.49359359367921

Epoch: 5| Step: 5
Training loss: 2.0375959596094364
Validation loss: 2.4476251167170773

Epoch: 5| Step: 6
Training loss: 2.4002193827496576
Validation loss: 2.4458880171351045

Epoch: 5| Step: 7
Training loss: 2.2964213435786673
Validation loss: 2.4641036056764754

Epoch: 5| Step: 8
Training loss: 2.1652420079597214
Validation loss: 2.453417686160151

Epoch: 5| Step: 9
Training loss: 2.2763882394256605
Validation loss: 2.4620678960797453

Epoch: 5| Step: 10
Training loss: 1.299697516169548
Validation loss: 2.4871395035990607

Epoch: 299| Step: 0
Training loss: 2.1724863632704787
Validation loss: 2.5125642169844746

Epoch: 5| Step: 1
Training loss: 1.9821711038665815
Validation loss: 2.4366338877569444

Epoch: 5| Step: 2
Training loss: 2.313345471037904
Validation loss: 2.4332645946671305

Epoch: 5| Step: 3
Training loss: 2.2842774877857623
Validation loss: 2.484531231796678

Epoch: 5| Step: 4
Training loss: 2.0128314154082174
Validation loss: 2.4616594423996525

Epoch: 5| Step: 5
Training loss: 1.6566465370956018
Validation loss: 2.4925539524789153

Epoch: 5| Step: 6
Training loss: 2.3616345430000725
Validation loss: 2.461186442925232

Epoch: 5| Step: 7
Training loss: 2.590120832945879
Validation loss: 2.4667282736046037

Epoch: 5| Step: 8
Training loss: 2.0063908512667403
Validation loss: 2.5153093913901645

Epoch: 5| Step: 9
Training loss: 1.7965255397485649
Validation loss: 2.43661870556244

Epoch: 5| Step: 10
Training loss: 1.9186586588139507
Validation loss: 2.5067824436342256

Epoch: 300| Step: 0
Training loss: 2.0297970784057195
Validation loss: 2.4974488316008654

Epoch: 5| Step: 1
Training loss: 1.9697652348668642
Validation loss: 2.509802513957515

Epoch: 5| Step: 2
Training loss: 1.8212391864400606
Validation loss: 2.456592734773242

Epoch: 5| Step: 3
Training loss: 1.7777415742101812
Validation loss: 2.497609483511978

Epoch: 5| Step: 4
Training loss: 2.0367572951976913
Validation loss: 2.5633667521203396

Epoch: 5| Step: 5
Training loss: 2.9250343907608656
Validation loss: 2.547143927621058

Epoch: 5| Step: 6
Training loss: 1.881312489026203
Validation loss: 2.4692724663384604

Epoch: 5| Step: 7
Training loss: 1.985294339339965
Validation loss: 2.4998799295201803

Epoch: 5| Step: 8
Training loss: 2.0275506004105894
Validation loss: 2.5179517356690693

Epoch: 5| Step: 9
Training loss: 2.326827641450126
Validation loss: 2.5617414282609134

Epoch: 5| Step: 10
Training loss: 1.979076189348879
Validation loss: 2.5233630595403747

Epoch: 301| Step: 0
Training loss: 2.24449735218214
Validation loss: 2.5202634118503533

Epoch: 5| Step: 1
Training loss: 2.151235637893923
Validation loss: 2.4492463413233603

Epoch: 5| Step: 2
Training loss: 1.9580716776718141
Validation loss: 2.496306379552455

Epoch: 5| Step: 3
Training loss: 2.233324350747031
Validation loss: 2.4860451960098384

Epoch: 5| Step: 4
Training loss: 2.1950105615592026
Validation loss: 2.42302489568855

Epoch: 5| Step: 5
Training loss: 2.3404976212966786
Validation loss: 2.439924016617024

Epoch: 5| Step: 6
Training loss: 1.8493251239719999
Validation loss: 2.4468983651410037

Epoch: 5| Step: 7
Training loss: 2.4251967753378048
Validation loss: 2.527516888506594

Epoch: 5| Step: 8
Training loss: 1.8089885239624603
Validation loss: 2.435838156497744

Epoch: 5| Step: 9
Training loss: 1.9247788611875618
Validation loss: 2.515873891525009

Epoch: 5| Step: 10
Training loss: 2.0318445362634066
Validation loss: 2.4930740092818975

Epoch: 302| Step: 0
Training loss: 1.812200258397243
Validation loss: 2.4801337445705247

Epoch: 5| Step: 1
Training loss: 2.5672825169407343
Validation loss: 2.423937512288464

Epoch: 5| Step: 2
Training loss: 2.337377404246651
Validation loss: 2.5630300510386266

Epoch: 5| Step: 3
Training loss: 2.1160516260840447
Validation loss: 2.52158278942842

Epoch: 5| Step: 4
Training loss: 2.2728325212557423
Validation loss: 2.5184774550740667

Epoch: 5| Step: 5
Training loss: 1.8487268293990842
Validation loss: 2.422713156853523

Epoch: 5| Step: 6
Training loss: 1.8572220078044501
Validation loss: 2.469769621523382

Epoch: 5| Step: 7
Training loss: 2.1640195325861895
Validation loss: 2.456628798399717

Epoch: 5| Step: 8
Training loss: 1.9149146849350323
Validation loss: 2.524633456079759

Epoch: 5| Step: 9
Training loss: 1.7359621501171631
Validation loss: 2.405750074100979

Epoch: 5| Step: 10
Training loss: 2.2429885762400374
Validation loss: 2.4708203707298972

Epoch: 303| Step: 0
Training loss: 2.3979583162147984
Validation loss: 2.46379087227825

Epoch: 5| Step: 1
Training loss: 2.017684121315679
Validation loss: 2.512582644047865

Epoch: 5| Step: 2
Training loss: 1.8054016153620986
Validation loss: 2.4249094910768045

Epoch: 5| Step: 3
Training loss: 2.522372372350312
Validation loss: 2.439702414421771

Epoch: 5| Step: 4
Training loss: 1.9142860126393457
Validation loss: 2.476354406321316

Epoch: 5| Step: 5
Training loss: 1.860719467189343
Validation loss: 2.4004911001881646

Epoch: 5| Step: 6
Training loss: 1.7982036156783583
Validation loss: 2.5095928942370556

Epoch: 5| Step: 7
Training loss: 2.1177141161037687
Validation loss: 2.517411241061703

Epoch: 5| Step: 8
Training loss: 2.65963063249737
Validation loss: 2.5002816410777204

Epoch: 5| Step: 9
Training loss: 1.9795079656422856
Validation loss: 2.5267272472183606

Epoch: 5| Step: 10
Training loss: 2.289649445467555
Validation loss: 2.511907166102115

Epoch: 304| Step: 0
Training loss: 1.9672146820299232
Validation loss: 2.4968841989134636

Epoch: 5| Step: 1
Training loss: 1.94881323378412
Validation loss: 2.4868959873082916

Epoch: 5| Step: 2
Training loss: 2.4921178538955733
Validation loss: 2.529107439228462

Epoch: 5| Step: 3
Training loss: 2.1160081344621204
Validation loss: 2.462664931400819

Epoch: 5| Step: 4
Training loss: 2.06098581854667
Validation loss: 2.4603302575761603

Epoch: 5| Step: 5
Training loss: 1.556661301766299
Validation loss: 2.472921686687202

Epoch: 5| Step: 6
Training loss: 2.4276573801145434
Validation loss: 2.474332233319393

Epoch: 5| Step: 7
Training loss: 2.095217859234459
Validation loss: 2.4363039477855652

Epoch: 5| Step: 8
Training loss: 2.5212039097141488
Validation loss: 2.5864578217797014

Epoch: 5| Step: 9
Training loss: 1.6738348196245205
Validation loss: 2.514826316671003

Epoch: 5| Step: 10
Training loss: 1.923742797818251
Validation loss: 2.4742131045146296

Epoch: 305| Step: 0
Training loss: 2.66344939305641
Validation loss: 2.4757793830773913

Epoch: 5| Step: 1
Training loss: 1.658295573790297
Validation loss: 2.500659103058694

Epoch: 5| Step: 2
Training loss: 2.4462315596410305
Validation loss: 2.5098595674838333

Epoch: 5| Step: 3
Training loss: 1.4304079835611323
Validation loss: 2.479089711098672

Epoch: 5| Step: 4
Training loss: 2.491218785206671
Validation loss: 2.4640864864403875

Epoch: 5| Step: 5
Training loss: 1.9624929755990244
Validation loss: 2.490526912717201

Epoch: 5| Step: 6
Training loss: 2.3001800425177215
Validation loss: 2.429100771635555

Epoch: 5| Step: 7
Training loss: 2.0540048603865815
Validation loss: 2.450061685816472

Epoch: 5| Step: 8
Training loss: 2.1251487679858503
Validation loss: 2.507533659556286

Epoch: 5| Step: 9
Training loss: 1.934629528943685
Validation loss: 2.46958615925067

Epoch: 5| Step: 10
Training loss: 2.330797134061943
Validation loss: 2.5084573170197153

Epoch: 306| Step: 0
Training loss: 1.9089698149311416
Validation loss: 2.4545672876722446

Epoch: 5| Step: 1
Training loss: 2.394829537013551
Validation loss: 2.4895183352059047

Epoch: 5| Step: 2
Training loss: 1.6836097521806945
Validation loss: 2.4591365659174533

Epoch: 5| Step: 3
Training loss: 2.8772632149480626
Validation loss: 2.498622687165631

Epoch: 5| Step: 4
Training loss: 1.7353058112901916
Validation loss: 2.5121451168306947

Epoch: 5| Step: 5
Training loss: 1.8795693351660139
Validation loss: 2.5113027152132683

Epoch: 5| Step: 6
Training loss: 1.6255473168866097
Validation loss: 2.529919510513967

Epoch: 5| Step: 7
Training loss: 2.1288280787683718
Validation loss: 2.464543468236942

Epoch: 5| Step: 8
Training loss: 2.0210022872088897
Validation loss: 2.508717097734099

Epoch: 5| Step: 9
Training loss: 2.4350494390712965
Validation loss: 2.483414285494773

Epoch: 5| Step: 10
Training loss: 2.0264556644840837
Validation loss: 2.4850398339048625

Epoch: 307| Step: 0
Training loss: 1.9034653633319143
Validation loss: 2.4826184305459655

Epoch: 5| Step: 1
Training loss: 2.4711383903588686
Validation loss: 2.4222592454226874

Epoch: 5| Step: 2
Training loss: 2.578070807609887
Validation loss: 2.4765217981746

Epoch: 5| Step: 3
Training loss: 2.024338922794506
Validation loss: 2.428212937354973

Epoch: 5| Step: 4
Training loss: 2.3832953292199726
Validation loss: 2.5101434900006034

Epoch: 5| Step: 5
Training loss: 1.8894360800008387
Validation loss: 2.470731773406546

Epoch: 5| Step: 6
Training loss: 1.639230189732119
Validation loss: 2.4708653955212903

Epoch: 5| Step: 7
Training loss: 1.9826599880089772
Validation loss: 2.463425888764277

Epoch: 5| Step: 8
Training loss: 1.7963113978968432
Validation loss: 2.47672029282853

Epoch: 5| Step: 9
Training loss: 1.8855789564338177
Validation loss: 2.4439972579241416

Epoch: 5| Step: 10
Training loss: 2.0799951384560917
Validation loss: 2.5062369604996175

Epoch: 308| Step: 0
Training loss: 2.2995430119177307
Validation loss: 2.536748075431154

Epoch: 5| Step: 1
Training loss: 1.7071878112647443
Validation loss: 2.4439708645262166

Epoch: 5| Step: 2
Training loss: 1.729879309021976
Validation loss: 2.513218273576566

Epoch: 5| Step: 3
Training loss: 3.0313149671376407
Validation loss: 2.4812134407532165

Epoch: 5| Step: 4
Training loss: 2.2094188637270813
Validation loss: 2.459505946198753

Epoch: 5| Step: 5
Training loss: 1.830339183121138
Validation loss: 2.494271991978292

Epoch: 5| Step: 6
Training loss: 2.4765299605388944
Validation loss: 2.447969974800507

Epoch: 5| Step: 7
Training loss: 2.134474669066026
Validation loss: 2.467237769252405

Epoch: 5| Step: 8
Training loss: 1.9145869568080327
Validation loss: 2.5005935897412943

Epoch: 5| Step: 9
Training loss: 1.842624320671671
Validation loss: 2.4049487751405136

Epoch: 5| Step: 10
Training loss: 1.463957088425234
Validation loss: 2.5106991776695566

Epoch: 309| Step: 0
Training loss: 2.0021094879866053
Validation loss: 2.5380607200047525

Epoch: 5| Step: 1
Training loss: 2.1032474385822586
Validation loss: 2.459555310910494

Epoch: 5| Step: 2
Training loss: 1.871008757570242
Validation loss: 2.442983510585889

Epoch: 5| Step: 3
Training loss: 1.5649159636192314
Validation loss: 2.4483441616873725

Epoch: 5| Step: 4
Training loss: 2.245719122120521
Validation loss: 2.5456500605245362

Epoch: 5| Step: 5
Training loss: 2.4008543282089274
Validation loss: 2.5369917651513494

Epoch: 5| Step: 6
Training loss: 1.855574626913432
Validation loss: 2.514245294579602

Epoch: 5| Step: 7
Training loss: 2.2803748555471146
Validation loss: 2.4531483849938636

Epoch: 5| Step: 8
Training loss: 2.026063018398664
Validation loss: 2.462097772629684

Epoch: 5| Step: 9
Training loss: 2.1772713344263273
Validation loss: 2.4129068776124374

Epoch: 5| Step: 10
Training loss: 1.9437480595324481
Validation loss: 2.450328337629945

Epoch: 310| Step: 0
Training loss: 2.1668693985603933
Validation loss: 2.4321279249081362

Epoch: 5| Step: 1
Training loss: 1.832596876594324
Validation loss: 2.4887600992718015

Epoch: 5| Step: 2
Training loss: 2.2293478158331332
Validation loss: 2.471047452491678

Epoch: 5| Step: 3
Training loss: 1.9306440569430128
Validation loss: 2.4548628904245278

Epoch: 5| Step: 4
Training loss: 1.8460224178188747
Validation loss: 2.456770733129494

Epoch: 5| Step: 5
Training loss: 2.422893285488193
Validation loss: 2.566415404108351

Epoch: 5| Step: 6
Training loss: 1.9550273938223226
Validation loss: 2.5381060499041252

Epoch: 5| Step: 7
Training loss: 1.8267641789914653
Validation loss: 2.5240821798412534

Epoch: 5| Step: 8
Training loss: 2.6272237531951914
Validation loss: 2.425654525264511

Epoch: 5| Step: 9
Training loss: 2.427230033752316
Validation loss: 2.5112902614332873

Epoch: 5| Step: 10
Training loss: 1.726577551590572
Validation loss: 2.479446003137338

Epoch: 311| Step: 0
Training loss: 2.608305112139666
Validation loss: 2.4499614709616733

Epoch: 5| Step: 1
Training loss: 1.7589915750463345
Validation loss: 2.4937240693816194

Epoch: 5| Step: 2
Training loss: 1.8074604215813097
Validation loss: 2.457445906520068

Epoch: 5| Step: 3
Training loss: 2.3494010446073483
Validation loss: 2.4922430661225534

Epoch: 5| Step: 4
Training loss: 1.5388996018695955
Validation loss: 2.540481794179163

Epoch: 5| Step: 5
Training loss: 1.667201989351356
Validation loss: 2.5278881469527934

Epoch: 5| Step: 6
Training loss: 2.3391917343979904
Validation loss: 2.5507774368702614

Epoch: 5| Step: 7
Training loss: 1.397452662967947
Validation loss: 2.5443734378504455

Epoch: 5| Step: 8
Training loss: 2.4944615049375845
Validation loss: 2.4719002934141585

Epoch: 5| Step: 9
Training loss: 1.8329129893144696
Validation loss: 2.4609147234369053

Epoch: 5| Step: 10
Training loss: 2.6830648153625134
Validation loss: 2.481495986713371

Epoch: 312| Step: 0
Training loss: 2.1536871011663288
Validation loss: 2.5196290595213062

Epoch: 5| Step: 1
Training loss: 1.810235154066675
Validation loss: 2.466253346104003

Epoch: 5| Step: 2
Training loss: 2.198657003044111
Validation loss: 2.4616889984645667

Epoch: 5| Step: 3
Training loss: 1.8515672643415102
Validation loss: 2.547468785458172

Epoch: 5| Step: 4
Training loss: 2.7006271375715203
Validation loss: 2.4406712907938917

Epoch: 5| Step: 5
Training loss: 2.2401588114571958
Validation loss: 2.428510719811402

Epoch: 5| Step: 6
Training loss: 1.7805285414882974
Validation loss: 2.4686785244047873

Epoch: 5| Step: 7
Training loss: 1.9760165459445935
Validation loss: 2.4719765848829356

Epoch: 5| Step: 8
Training loss: 2.399114755446735
Validation loss: 2.4876179223655557

Epoch: 5| Step: 9
Training loss: 1.906622678253735
Validation loss: 2.44146720879038

Epoch: 5| Step: 10
Training loss: 1.9288609390838958
Validation loss: 2.5398097541697418

Epoch: 313| Step: 0
Training loss: 2.23978893903523
Validation loss: 2.5264136201764464

Epoch: 5| Step: 1
Training loss: 2.1643222694241477
Validation loss: 2.4793981925031225

Epoch: 5| Step: 2
Training loss: 2.2367719051695047
Validation loss: 2.5105841557850828

Epoch: 5| Step: 3
Training loss: 2.3268164727296634
Validation loss: 2.497561841976302

Epoch: 5| Step: 4
Training loss: 1.6390973926535786
Validation loss: 2.457997854154771

Epoch: 5| Step: 5
Training loss: 2.1248186819473194
Validation loss: 2.547336144305446

Epoch: 5| Step: 6
Training loss: 1.9054790876607839
Validation loss: 2.407694701051328

Epoch: 5| Step: 7
Training loss: 1.8733093905134997
Validation loss: 2.5434178313283784

Epoch: 5| Step: 8
Training loss: 2.318410177083974
Validation loss: 2.4013584077435186

Epoch: 5| Step: 9
Training loss: 1.6924683933884905
Validation loss: 2.41241631519737

Epoch: 5| Step: 10
Training loss: 2.0382931014067704
Validation loss: 2.467919191831681

Epoch: 314| Step: 0
Training loss: 1.9851507037436973
Validation loss: 2.5423504492784414

Epoch: 5| Step: 1
Training loss: 1.5529727392954298
Validation loss: 2.384957899518031

Epoch: 5| Step: 2
Training loss: 2.675036695709944
Validation loss: 2.450042557278738

Epoch: 5| Step: 3
Training loss: 1.8609556003462202
Validation loss: 2.489157377457283

Epoch: 5| Step: 4
Training loss: 2.194118623112159
Validation loss: 2.361949783487762

Epoch: 5| Step: 5
Training loss: 2.2172433815191837
Validation loss: 2.5004205626862595

Epoch: 5| Step: 6
Training loss: 1.9478116202631677
Validation loss: 2.471820003985203

Epoch: 5| Step: 7
Training loss: 2.37275640020692
Validation loss: 2.4751283569049014

Epoch: 5| Step: 8
Training loss: 1.6976651510539849
Validation loss: 2.459542532049331

Epoch: 5| Step: 9
Training loss: 1.7755102069059672
Validation loss: 2.581842293043989

Epoch: 5| Step: 10
Training loss: 2.163260851950204
Validation loss: 2.5224400875021997

Epoch: 315| Step: 0
Training loss: 2.044915579100265
Validation loss: 2.5132533747147328

Epoch: 5| Step: 1
Training loss: 2.352110535898238
Validation loss: 2.5281573060107903

Epoch: 5| Step: 2
Training loss: 1.2507760499921186
Validation loss: 2.463439978504691

Epoch: 5| Step: 3
Training loss: 2.1363342050705443
Validation loss: 2.473610127959578

Epoch: 5| Step: 4
Training loss: 1.898136067890435
Validation loss: 2.44566851564028

Epoch: 5| Step: 5
Training loss: 2.121654345088799
Validation loss: 2.4584179407086646

Epoch: 5| Step: 6
Training loss: 2.047595763522947
Validation loss: 2.4849982769382573

Epoch: 5| Step: 7
Training loss: 2.2348888313244815
Validation loss: 2.4356773983506677

Epoch: 5| Step: 8
Training loss: 1.9453618299978097
Validation loss: 2.475971651813646

Epoch: 5| Step: 9
Training loss: 2.0434231371330327
Validation loss: 2.3861028924880756

Epoch: 5| Step: 10
Training loss: 2.4741684566742728
Validation loss: 2.3795727574831034

Epoch: 316| Step: 0
Training loss: 1.7536994115448794
Validation loss: 2.46511704042536

Epoch: 5| Step: 1
Training loss: 2.515016659933618
Validation loss: 2.4869965683085002

Epoch: 5| Step: 2
Training loss: 1.71357029791414
Validation loss: 2.5456692672373946

Epoch: 5| Step: 3
Training loss: 2.0450078004347834
Validation loss: 2.507652616242391

Epoch: 5| Step: 4
Training loss: 1.8540326473649587
Validation loss: 2.3505813666276154

Epoch: 5| Step: 5
Training loss: 2.010257642185167
Validation loss: 2.5003303740229668

Epoch: 5| Step: 6
Training loss: 1.981105604234821
Validation loss: 2.4537259059479477

Epoch: 5| Step: 7
Training loss: 2.2325017586046494
Validation loss: 2.5616883163641613

Epoch: 5| Step: 8
Training loss: 2.040454141144029
Validation loss: 2.5110237130723596

Epoch: 5| Step: 9
Training loss: 2.2458234806823705
Validation loss: 2.488279963172805

Epoch: 5| Step: 10
Training loss: 2.1900565330837987
Validation loss: 2.4342591033188268

Epoch: 317| Step: 0
Training loss: 2.1381458489082577
Validation loss: 2.4542845673893177

Epoch: 5| Step: 1
Training loss: 2.068092163231048
Validation loss: 2.4854373632686615

Epoch: 5| Step: 2
Training loss: 1.830482332420999
Validation loss: 2.3965433624624835

Epoch: 5| Step: 3
Training loss: 2.472129054463008
Validation loss: 2.4446638402089804

Epoch: 5| Step: 4
Training loss: 1.5313708199305502
Validation loss: 2.423291657711738

Epoch: 5| Step: 5
Training loss: 2.4063653299015404
Validation loss: 2.4198484454577027

Epoch: 5| Step: 6
Training loss: 2.1124774863945133
Validation loss: 2.4938764681274423

Epoch: 5| Step: 7
Training loss: 1.7425635235672163
Validation loss: 2.448239391647351

Epoch: 5| Step: 8
Training loss: 1.8259661063885297
Validation loss: 2.475058394425074

Epoch: 5| Step: 9
Training loss: 1.9235831012668125
Validation loss: 2.5117379620328486

Epoch: 5| Step: 10
Training loss: 2.1302100992234303
Validation loss: 2.486058384150254

Epoch: 318| Step: 0
Training loss: 2.353014931504537
Validation loss: 2.460970893577304

Epoch: 5| Step: 1
Training loss: 2.4034564163005228
Validation loss: 2.5164961114581432

Epoch: 5| Step: 2
Training loss: 2.2109139916346274
Validation loss: 2.516010334145809

Epoch: 5| Step: 3
Training loss: 1.9618514161577578
Validation loss: 2.545651847061092

Epoch: 5| Step: 4
Training loss: 1.8156134731432385
Validation loss: 2.48497179493843

Epoch: 5| Step: 5
Training loss: 1.8721635981297766
Validation loss: 2.459691706003503

Epoch: 5| Step: 6
Training loss: 1.9109477956000118
Validation loss: 2.489571478687562

Epoch: 5| Step: 7
Training loss: 1.657444792873826
Validation loss: 2.474281459014849

Epoch: 5| Step: 8
Training loss: 1.9393762917104016
Validation loss: 2.470775540184084

Epoch: 5| Step: 9
Training loss: 1.8387158737283302
Validation loss: 2.392398242797321

Epoch: 5| Step: 10
Training loss: 2.2954559094401787
Validation loss: 2.405398888055324

Epoch: 319| Step: 0
Training loss: 2.382936368130317
Validation loss: 2.4759164691340976

Epoch: 5| Step: 1
Training loss: 2.134105248670352
Validation loss: 2.467990247946535

Epoch: 5| Step: 2
Training loss: 1.8429381312615893
Validation loss: 2.476321202593636

Epoch: 5| Step: 3
Training loss: 2.471826784842813
Validation loss: 2.473982278722002

Epoch: 5| Step: 4
Training loss: 1.7662725695810149
Validation loss: 2.5073848238680867

Epoch: 5| Step: 5
Training loss: 2.1342918100523516
Validation loss: 2.53453129045374

Epoch: 5| Step: 6
Training loss: 1.6264910093165137
Validation loss: 2.508984712147898

Epoch: 5| Step: 7
Training loss: 1.858295415768011
Validation loss: 2.515223288685986

Epoch: 5| Step: 8
Training loss: 2.3137962213863092
Validation loss: 2.5210458768774955

Epoch: 5| Step: 9
Training loss: 1.8222595410996711
Validation loss: 2.468770333545542

Epoch: 5| Step: 10
Training loss: 2.0133906555647076
Validation loss: 2.4592586855866005

Epoch: 320| Step: 0
Training loss: 1.9831245868152245
Validation loss: 2.488101743026077

Epoch: 5| Step: 1
Training loss: 1.708215786991432
Validation loss: 2.5206488617497276

Epoch: 5| Step: 2
Training loss: 2.6582184622249954
Validation loss: 2.4583976644028116

Epoch: 5| Step: 3
Training loss: 2.4396556223500196
Validation loss: 2.4340698174737856

Epoch: 5| Step: 4
Training loss: 2.0384022312367684
Validation loss: 2.5252105895143573

Epoch: 5| Step: 5
Training loss: 2.352633108980487
Validation loss: 2.5045433475979224

Epoch: 5| Step: 6
Training loss: 2.1280094602704396
Validation loss: 2.4858398086858817

Epoch: 5| Step: 7
Training loss: 1.6396263352813483
Validation loss: 2.4998905783466885

Epoch: 5| Step: 8
Training loss: 1.8318101956980573
Validation loss: 2.4076857665512534

Epoch: 5| Step: 9
Training loss: 1.532567761215962
Validation loss: 2.5128952034920626

Epoch: 5| Step: 10
Training loss: 2.1379308522874627
Validation loss: 2.418135959786988

Epoch: 321| Step: 0
Training loss: 2.3985358103133905
Validation loss: 2.5039418912142084

Epoch: 5| Step: 1
Training loss: 1.9892542169058078
Validation loss: 2.495617740905167

Epoch: 5| Step: 2
Training loss: 1.6862085840386112
Validation loss: 2.5256482356573025

Epoch: 5| Step: 3
Training loss: 1.892756623943419
Validation loss: 2.456953656070371

Epoch: 5| Step: 4
Training loss: 1.7031774950249097
Validation loss: 2.4454720806853065

Epoch: 5| Step: 5
Training loss: 1.7927800496851454
Validation loss: 2.4482642955661995

Epoch: 5| Step: 6
Training loss: 2.8891719980981967
Validation loss: 2.48079744473211

Epoch: 5| Step: 7
Training loss: 2.24134050381202
Validation loss: 2.441958263576414

Epoch: 5| Step: 8
Training loss: 1.5461747096734775
Validation loss: 2.4622260310917716

Epoch: 5| Step: 9
Training loss: 1.976950565887465
Validation loss: 2.529553013559426

Epoch: 5| Step: 10
Training loss: 2.213296339614441
Validation loss: 2.412463144119351

Epoch: 322| Step: 0
Training loss: 2.8065534669726273
Validation loss: 2.448934070201087

Epoch: 5| Step: 1
Training loss: 2.3519374003610904
Validation loss: 2.4380472366686643

Epoch: 5| Step: 2
Training loss: 1.7134822228352449
Validation loss: 2.4751561047780415

Epoch: 5| Step: 3
Training loss: 1.7185777751292173
Validation loss: 2.5140270390163155

Epoch: 5| Step: 4
Training loss: 2.342736190239026
Validation loss: 2.530234295749705

Epoch: 5| Step: 5
Training loss: 1.7860179465824317
Validation loss: 2.449220883209759

Epoch: 5| Step: 6
Training loss: 1.6412409035052176
Validation loss: 2.49240776264171

Epoch: 5| Step: 7
Training loss: 1.930308253719136
Validation loss: 2.5597934700973792

Epoch: 5| Step: 8
Training loss: 2.918773453350716
Validation loss: 2.466146326418564

Epoch: 5| Step: 9
Training loss: 1.3646384754638976
Validation loss: 2.4081721960427496

Epoch: 5| Step: 10
Training loss: 1.981652983588015
Validation loss: 2.505786292776197

Epoch: 323| Step: 0
Training loss: 2.6599841629359964
Validation loss: 2.479939333540539

Epoch: 5| Step: 1
Training loss: 1.7475483615060878
Validation loss: 2.418493538989339

Epoch: 5| Step: 2
Training loss: 1.7314736782962692
Validation loss: 2.506735551192415

Epoch: 5| Step: 3
Training loss: 2.007140644636617
Validation loss: 2.4847457793769334

Epoch: 5| Step: 4
Training loss: 1.8032626517658659
Validation loss: 2.4787270971550153

Epoch: 5| Step: 5
Training loss: 2.2965361676099563
Validation loss: 2.473721041652252

Epoch: 5| Step: 6
Training loss: 2.174607348899384
Validation loss: 2.535445230550125

Epoch: 5| Step: 7
Training loss: 2.568907194131019
Validation loss: 2.3782717573262717

Epoch: 5| Step: 8
Training loss: 1.5349688621866864
Validation loss: 2.4849239616622865

Epoch: 5| Step: 9
Training loss: 1.5983644888303958
Validation loss: 2.4586339808085547

Epoch: 5| Step: 10
Training loss: 2.4370907170907854
Validation loss: 2.4788447286765924

Epoch: 324| Step: 0
Training loss: 1.832893477762408
Validation loss: 2.4240646102168832

Epoch: 5| Step: 1
Training loss: 2.130676317612455
Validation loss: 2.4629313511991966

Epoch: 5| Step: 2
Training loss: 2.138397728754872
Validation loss: 2.4496161847291007

Epoch: 5| Step: 3
Training loss: 2.249274878747276
Validation loss: 2.47012657706071

Epoch: 5| Step: 4
Training loss: 2.23837306714764
Validation loss: 2.473342747074039

Epoch: 5| Step: 5
Training loss: 2.2104966226175318
Validation loss: 2.4111742066529747

Epoch: 5| Step: 6
Training loss: 1.990922054721245
Validation loss: 2.464409976663467

Epoch: 5| Step: 7
Training loss: 2.196579754064668
Validation loss: 2.436982386226357

Epoch: 5| Step: 8
Training loss: 1.6228495821066717
Validation loss: 2.4364257603530355

Epoch: 5| Step: 9
Training loss: 1.975967679593401
Validation loss: 2.5590594004084926

Epoch: 5| Step: 10
Training loss: 1.877989674292992
Validation loss: 2.4968568336850336

Epoch: 325| Step: 0
Training loss: 1.8586325565630668
Validation loss: 2.4994865484980204

Epoch: 5| Step: 1
Training loss: 2.049375797235509
Validation loss: 2.4489084371577596

Epoch: 5| Step: 2
Training loss: 2.2096226964766887
Validation loss: 2.429914025190573

Epoch: 5| Step: 3
Training loss: 2.081684362775578
Validation loss: 2.432032913645898

Epoch: 5| Step: 4
Training loss: 2.5697267554818657
Validation loss: 2.507943042997596

Epoch: 5| Step: 5
Training loss: 1.1627138248804454
Validation loss: 2.476954543401758

Epoch: 5| Step: 6
Training loss: 1.8462317622994386
Validation loss: 2.5469490864382016

Epoch: 5| Step: 7
Training loss: 1.6232174119285252
Validation loss: 2.4748823753423843

Epoch: 5| Step: 8
Training loss: 2.7239654326969407
Validation loss: 2.477841407116084

Epoch: 5| Step: 9
Training loss: 1.9516635157002922
Validation loss: 2.4265353412340596

Epoch: 5| Step: 10
Training loss: 1.8325366398790022
Validation loss: 2.429081633177831

Epoch: 326| Step: 0
Training loss: 1.614984753657792
Validation loss: 2.409159072340914

Epoch: 5| Step: 1
Training loss: 1.7784101368205518
Validation loss: 2.417665870825458

Epoch: 5| Step: 2
Training loss: 1.5045632252616752
Validation loss: 2.4589187501368435

Epoch: 5| Step: 3
Training loss: 2.29480364555826
Validation loss: 2.47569514000955

Epoch: 5| Step: 4
Training loss: 2.308433979011599
Validation loss: 2.4802595519782016

Epoch: 5| Step: 5
Training loss: 2.409062018147622
Validation loss: 2.4738425848954924

Epoch: 5| Step: 6
Training loss: 2.0075049257514923
Validation loss: 2.4645223404585885

Epoch: 5| Step: 7
Training loss: 1.8307122075546578
Validation loss: 2.4435039574638258

Epoch: 5| Step: 8
Training loss: 2.0573089470117485
Validation loss: 2.4451026159392923

Epoch: 5| Step: 9
Training loss: 2.2102534985039446
Validation loss: 2.4195832258187546

Epoch: 5| Step: 10
Training loss: 2.0847225008201993
Validation loss: 2.4403512715577635

Epoch: 327| Step: 0
Training loss: 2.0676346644835313
Validation loss: 2.4249733796015445

Epoch: 5| Step: 1
Training loss: 1.9773414494242223
Validation loss: 2.4083886744354595

Epoch: 5| Step: 2
Training loss: 2.019639150662603
Validation loss: 2.5011627825871763

Epoch: 5| Step: 3
Training loss: 1.9426686655312235
Validation loss: 2.4173712140103136

Epoch: 5| Step: 4
Training loss: 1.9625975129022626
Validation loss: 2.4620540879577786

Epoch: 5| Step: 5
Training loss: 1.6584445880905903
Validation loss: 2.480583277028475

Epoch: 5| Step: 6
Training loss: 2.0854994638973214
Validation loss: 2.442865591018052

Epoch: 5| Step: 7
Training loss: 1.9616835797255177
Validation loss: 2.4193253183785695

Epoch: 5| Step: 8
Training loss: 2.368662057014072
Validation loss: 2.5152957848353723

Epoch: 5| Step: 9
Training loss: 2.208003817271651
Validation loss: 2.4993894610857588

Epoch: 5| Step: 10
Training loss: 2.269202728918873
Validation loss: 2.4479817898652954

Epoch: 328| Step: 0
Training loss: 2.2187309801602804
Validation loss: 2.5086011398248025

Epoch: 5| Step: 1
Training loss: 2.0562452785820367
Validation loss: 2.4777507204348894

Epoch: 5| Step: 2
Training loss: 1.806345124693278
Validation loss: 2.449283903123841

Epoch: 5| Step: 3
Training loss: 1.4440732024439493
Validation loss: 2.4668169534004587

Epoch: 5| Step: 4
Training loss: 2.5160348688629552
Validation loss: 2.53309336448926

Epoch: 5| Step: 5
Training loss: 2.1500157333508065
Validation loss: 2.5147492327561682

Epoch: 5| Step: 6
Training loss: 2.147971140790183
Validation loss: 2.427542785086345

Epoch: 5| Step: 7
Training loss: 2.1713051906109206
Validation loss: 2.479305365482769

Epoch: 5| Step: 8
Training loss: 1.6193784900246353
Validation loss: 2.491110305913735

Epoch: 5| Step: 9
Training loss: 1.776907127323398
Validation loss: 2.4838720550249733

Epoch: 5| Step: 10
Training loss: 2.153096532979506
Validation loss: 2.48714272265634

Epoch: 329| Step: 0
Training loss: 1.6424676628935875
Validation loss: 2.4215652315350664

Epoch: 5| Step: 1
Training loss: 1.9931890027262817
Validation loss: 2.5070371520808203

Epoch: 5| Step: 2
Training loss: 2.345464155871036
Validation loss: 2.4884948705739993

Epoch: 5| Step: 3
Training loss: 1.979465147566766
Validation loss: 2.482763637608986

Epoch: 5| Step: 4
Training loss: 2.2028884219581273
Validation loss: 2.4992804137711473

Epoch: 5| Step: 5
Training loss: 1.9455106703231069
Validation loss: 2.4260519389673596

Epoch: 5| Step: 6
Training loss: 2.4050347368107
Validation loss: 2.446449843255204

Epoch: 5| Step: 7
Training loss: 1.798275078698193
Validation loss: 2.4990218515246063

Epoch: 5| Step: 8
Training loss: 2.0986409921606533
Validation loss: 2.5447033863659505

Epoch: 5| Step: 9
Training loss: 1.7707788646025222
Validation loss: 2.520510107105322

Epoch: 5| Step: 10
Training loss: 1.8228493886975747
Validation loss: 2.4971682590163016

Epoch: 330| Step: 0
Training loss: 2.116830605693782
Validation loss: 2.4064018106801517

Epoch: 5| Step: 1
Training loss: 1.7323567787850993
Validation loss: 2.3862719430359713

Epoch: 5| Step: 2
Training loss: 1.240077788312606
Validation loss: 2.475922714845939

Epoch: 5| Step: 3
Training loss: 2.0563747889907207
Validation loss: 2.492739699286239

Epoch: 5| Step: 4
Training loss: 2.697594160640863
Validation loss: 2.464379128437753

Epoch: 5| Step: 5
Training loss: 1.9976856430928729
Validation loss: 2.4441453201107852

Epoch: 5| Step: 6
Training loss: 2.0241251480327698
Validation loss: 2.4516620546728953

Epoch: 5| Step: 7
Training loss: 2.5086271204788586
Validation loss: 2.47599021971409

Epoch: 5| Step: 8
Training loss: 2.2661855070065973
Validation loss: 2.447152254084925

Epoch: 5| Step: 9
Training loss: 2.1331478316400996
Validation loss: 2.4322356061058237

Epoch: 5| Step: 10
Training loss: 1.8824318782036364
Validation loss: 2.5228980769917175

Epoch: 331| Step: 0
Training loss: 2.1373044733219757
Validation loss: 2.531424492711427

Epoch: 5| Step: 1
Training loss: 2.192867342755225
Validation loss: 2.4563840065790505

Epoch: 5| Step: 2
Training loss: 1.4996647460127046
Validation loss: 2.4765589307626876

Epoch: 5| Step: 3
Training loss: 2.8310595719925957
Validation loss: 2.4704035160198807

Epoch: 5| Step: 4
Training loss: 1.8231972687331293
Validation loss: 2.4991383082727694

Epoch: 5| Step: 5
Training loss: 1.9137527526596474
Validation loss: 2.501175251944479

Epoch: 5| Step: 6
Training loss: 1.561191697753873
Validation loss: 2.4726846736048063

Epoch: 5| Step: 7
Training loss: 2.257943119903809
Validation loss: 2.425232337551478

Epoch: 5| Step: 8
Training loss: 1.4595246852918653
Validation loss: 2.460226396548702

Epoch: 5| Step: 9
Training loss: 1.94539418489472
Validation loss: 2.461414423896056

Epoch: 5| Step: 10
Training loss: 1.741334988833269
Validation loss: 2.396359199676455

Epoch: 332| Step: 0
Training loss: 1.8254041720638035
Validation loss: 2.493319400152671

Epoch: 5| Step: 1
Training loss: 3.241096478470128
Validation loss: 2.455587387146221

Epoch: 5| Step: 2
Training loss: 1.809549692842418
Validation loss: 2.472965242620785

Epoch: 5| Step: 3
Training loss: 2.0686867142415952
Validation loss: 2.428742486811238

Epoch: 5| Step: 4
Training loss: 1.8366261590735768
Validation loss: 2.406130099069376

Epoch: 5| Step: 5
Training loss: 1.5121655654025887
Validation loss: 2.538015539800155

Epoch: 5| Step: 6
Training loss: 1.8488639771648263
Validation loss: 2.4553705799090424

Epoch: 5| Step: 7
Training loss: 1.9778757670531888
Validation loss: 2.505802109671378

Epoch: 5| Step: 8
Training loss: 1.9238403319925224
Validation loss: 2.3946593252245743

Epoch: 5| Step: 9
Training loss: 1.8259790328912184
Validation loss: 2.460695587211533

Epoch: 5| Step: 10
Training loss: 2.09623365983867
Validation loss: 2.486723352534648

Epoch: 333| Step: 0
Training loss: 1.4271860387371578
Validation loss: 2.4669537508211192

Epoch: 5| Step: 1
Training loss: 1.6802007556357341
Validation loss: 2.4941735966455907

Epoch: 5| Step: 2
Training loss: 2.3755136235640757
Validation loss: 2.4122996347848886

Epoch: 5| Step: 3
Training loss: 2.1870683516647382
Validation loss: 2.458728963539215

Epoch: 5| Step: 4
Training loss: 2.4334096578707824
Validation loss: 2.439414498573203

Epoch: 5| Step: 5
Training loss: 1.4663588356152757
Validation loss: 2.392377363014486

Epoch: 5| Step: 6
Training loss: 2.0179840004610896
Validation loss: 2.395363056811719

Epoch: 5| Step: 7
Training loss: 2.3031048011670445
Validation loss: 2.4467520710730803

Epoch: 5| Step: 8
Training loss: 1.8970853283583502
Validation loss: 2.4572846355547253

Epoch: 5| Step: 9
Training loss: 2.1401583866081704
Validation loss: 2.4575215114698166

Epoch: 5| Step: 10
Training loss: 2.5290023809009234
Validation loss: 2.50170607650081

Epoch: 334| Step: 0
Training loss: 2.407350957105397
Validation loss: 2.4920297277576196

Epoch: 5| Step: 1
Training loss: 2.01729094980969
Validation loss: 2.4527849147540137

Epoch: 5| Step: 2
Training loss: 1.908218742939221
Validation loss: 2.4478037158580466

Epoch: 5| Step: 3
Training loss: 1.9837518749937295
Validation loss: 2.4272140966964924

Epoch: 5| Step: 4
Training loss: 1.7066334276141435
Validation loss: 2.462769423985547

Epoch: 5| Step: 5
Training loss: 1.677402592316709
Validation loss: 2.4411339660412223

Epoch: 5| Step: 6
Training loss: 1.6460268735766064
Validation loss: 2.385421505382327

Epoch: 5| Step: 7
Training loss: 1.7723770668216285
Validation loss: 2.5167232412400815

Epoch: 5| Step: 8
Training loss: 2.2642936214740454
Validation loss: 2.423834981946068

Epoch: 5| Step: 9
Training loss: 2.183313996712279
Validation loss: 2.4330180674716266

Epoch: 5| Step: 10
Training loss: 2.405204545837654
Validation loss: 2.4546645980176724

Epoch: 335| Step: 0
Training loss: 2.6255178394892074
Validation loss: 2.5287839705780923

Epoch: 5| Step: 1
Training loss: 2.0612858753309466
Validation loss: 2.4526813106620087

Epoch: 5| Step: 2
Training loss: 1.5235544013140547
Validation loss: 2.452247816547918

Epoch: 5| Step: 3
Training loss: 2.0522972679610336
Validation loss: 2.531743785236581

Epoch: 5| Step: 4
Training loss: 2.1306295437035603
Validation loss: 2.471214299206627

Epoch: 5| Step: 5
Training loss: 2.3018912210755205
Validation loss: 2.4857626009388003

Epoch: 5| Step: 6
Training loss: 2.3766431645555075
Validation loss: 2.40865260421941

Epoch: 5| Step: 7
Training loss: 1.8336068151696858
Validation loss: 2.461762085468862

Epoch: 5| Step: 8
Training loss: 1.6585798610657363
Validation loss: 2.4350792386322486

Epoch: 5| Step: 9
Training loss: 1.7631748043951518
Validation loss: 2.398699854946757

Epoch: 5| Step: 10
Training loss: 1.5049442820833245
Validation loss: 2.436437529335173

Epoch: 336| Step: 0
Training loss: 1.6320740704650556
Validation loss: 2.439064366332296

Epoch: 5| Step: 1
Training loss: 2.424551979443912
Validation loss: 2.443283945896813

Epoch: 5| Step: 2
Training loss: 1.6582897509625942
Validation loss: 2.4650608035626136

Epoch: 5| Step: 3
Training loss: 1.7686655651198857
Validation loss: 2.3974084538822993

Epoch: 5| Step: 4
Training loss: 2.2768041059675475
Validation loss: 2.3772984734436924

Epoch: 5| Step: 5
Training loss: 1.8738561320006077
Validation loss: 2.4210434157133065

Epoch: 5| Step: 6
Training loss: 2.018309823342112
Validation loss: 2.4176423228879482

Epoch: 5| Step: 7
Training loss: 2.2995739086041165
Validation loss: 2.470654308844135

Epoch: 5| Step: 8
Training loss: 1.6833197067514951
Validation loss: 2.4148378726230044

Epoch: 5| Step: 9
Training loss: 2.0383426959658943
Validation loss: 2.5121304961043593

Epoch: 5| Step: 10
Training loss: 1.771420714255456
Validation loss: 2.376522954075773

Epoch: 337| Step: 0
Training loss: 2.393873712515125
Validation loss: 2.390544120293859

Epoch: 5| Step: 1
Training loss: 2.144212820735262
Validation loss: 2.471890404519198

Epoch: 5| Step: 2
Training loss: 1.6623105421603
Validation loss: 2.4719621948197803

Epoch: 5| Step: 3
Training loss: 1.6051522567166119
Validation loss: 2.4672031907322602

Epoch: 5| Step: 4
Training loss: 1.8880940039476106
Validation loss: 2.4685632404773883

Epoch: 5| Step: 5
Training loss: 2.1552129269442335
Validation loss: 2.4598455899781198

Epoch: 5| Step: 6
Training loss: 2.5014150429510993
Validation loss: 2.4062062304654654

Epoch: 5| Step: 7
Training loss: 1.5331036772335702
Validation loss: 2.4053753330019867

Epoch: 5| Step: 8
Training loss: 1.9091835587796429
Validation loss: 2.47501037577251

Epoch: 5| Step: 9
Training loss: 1.5947275342780642
Validation loss: 2.4760756894855755

Epoch: 5| Step: 10
Training loss: 1.9464470186271785
Validation loss: 2.4861340838985084

Epoch: 338| Step: 0
Training loss: 2.4021543846860074
Validation loss: 2.401429309978976

Epoch: 5| Step: 1
Training loss: 1.2585966142163638
Validation loss: 2.48840628851486

Epoch: 5| Step: 2
Training loss: 2.1195845319193243
Validation loss: 2.481069578190263

Epoch: 5| Step: 3
Training loss: 1.6792322295888358
Validation loss: 2.5101254540697373

Epoch: 5| Step: 4
Training loss: 2.574317108266496
Validation loss: 2.540474265154091

Epoch: 5| Step: 5
Training loss: 1.9246145432226502
Validation loss: 2.429561841100096

Epoch: 5| Step: 6
Training loss: 1.6528768919318226
Validation loss: 2.4298726253243768

Epoch: 5| Step: 7
Training loss: 1.8320985956563398
Validation loss: 2.481146720157835

Epoch: 5| Step: 8
Training loss: 1.8713220763611385
Validation loss: 2.5152724527350383

Epoch: 5| Step: 9
Training loss: 2.5729386384054154
Validation loss: 2.4635477224445212

Epoch: 5| Step: 10
Training loss: 2.1440711578830394
Validation loss: 2.4762686200555377

Epoch: 339| Step: 0
Training loss: 2.2522273165551057
Validation loss: 2.4558068079846396

Epoch: 5| Step: 1
Training loss: 1.6886565871983934
Validation loss: 2.431441446716141

Epoch: 5| Step: 2
Training loss: 1.8940835010728156
Validation loss: 2.470714294908994

Epoch: 5| Step: 3
Training loss: 2.0214607863961893
Validation loss: 2.4828248789001583

Epoch: 5| Step: 4
Training loss: 1.6303152307272166
Validation loss: 2.4399955633325856

Epoch: 5| Step: 5
Training loss: 1.627836978792012
Validation loss: 2.4787521601760774

Epoch: 5| Step: 6
Training loss: 2.1025470001737068
Validation loss: 2.492478483195264

Epoch: 5| Step: 7
Training loss: 2.064024159770592
Validation loss: 2.4421009192107785

Epoch: 5| Step: 8
Training loss: 2.640633125969838
Validation loss: 2.4319333631636137

Epoch: 5| Step: 9
Training loss: 1.925874348028586
Validation loss: 2.45388521948084

Epoch: 5| Step: 10
Training loss: 1.8791300745387831
Validation loss: 2.450900660268156

Epoch: 340| Step: 0
Training loss: 2.34230108615531
Validation loss: 2.428230457837715

Epoch: 5| Step: 1
Training loss: 1.978178848570205
Validation loss: 2.3766046952315083

Epoch: 5| Step: 2
Training loss: 1.6693447610450747
Validation loss: 2.444185241078971

Epoch: 5| Step: 3
Training loss: 1.986992678881723
Validation loss: 2.4657566401772093

Epoch: 5| Step: 4
Training loss: 2.542865991347395
Validation loss: 2.4003327018593565

Epoch: 5| Step: 5
Training loss: 1.773676448638521
Validation loss: 2.3867446610409884

Epoch: 5| Step: 6
Training loss: 1.6387580057817175
Validation loss: 2.4491430240367777

Epoch: 5| Step: 7
Training loss: 1.973927124367215
Validation loss: 2.410230430064707

Epoch: 5| Step: 8
Training loss: 2.108974051339858
Validation loss: 2.500864491658882

Epoch: 5| Step: 9
Training loss: 2.1811044114283584
Validation loss: 2.4387536202600835

Epoch: 5| Step: 10
Training loss: 1.2987473541614651
Validation loss: 2.507206385046597

Epoch: 341| Step: 0
Training loss: 1.5324509251563965
Validation loss: 2.511997501449709

Epoch: 5| Step: 1
Training loss: 1.8751379598089977
Validation loss: 2.470093286503085

Epoch: 5| Step: 2
Training loss: 1.580466016539823
Validation loss: 2.3857850580534015

Epoch: 5| Step: 3
Training loss: 1.926363719576209
Validation loss: 2.4513387379681415

Epoch: 5| Step: 4
Training loss: 2.034850113993578
Validation loss: 2.4790976281987582

Epoch: 5| Step: 5
Training loss: 1.645948872755981
Validation loss: 2.3414185733882755

Epoch: 5| Step: 6
Training loss: 2.168069263224577
Validation loss: 2.447927534558833

Epoch: 5| Step: 7
Training loss: 2.5625357276472753
Validation loss: 2.4500158434153216

Epoch: 5| Step: 8
Training loss: 2.045397742282244
Validation loss: 2.4445864577756975

Epoch: 5| Step: 9
Training loss: 2.052164944286187
Validation loss: 2.4143446296051967

Epoch: 5| Step: 10
Training loss: 1.9309867160919023
Validation loss: 2.500861411226144

Epoch: 342| Step: 0
Training loss: 1.5631153420901518
Validation loss: 2.4409878516230834

Epoch: 5| Step: 1
Training loss: 1.722965480877103
Validation loss: 2.4565148274765107

Epoch: 5| Step: 2
Training loss: 2.4835538646738815
Validation loss: 2.4462679237803475

Epoch: 5| Step: 3
Training loss: 1.741910151143035
Validation loss: 2.419588928246137

Epoch: 5| Step: 4
Training loss: 2.0110523490446846
Validation loss: 2.423568691209126

Epoch: 5| Step: 5
Training loss: 2.209234761450483
Validation loss: 2.5216133872183386

Epoch: 5| Step: 6
Training loss: 1.5341608834282847
Validation loss: 2.4931570147416853

Epoch: 5| Step: 7
Training loss: 1.6244202093017495
Validation loss: 2.457570060911604

Epoch: 5| Step: 8
Training loss: 2.378471848487051
Validation loss: 2.487465066489805

Epoch: 5| Step: 9
Training loss: 2.003961097606187
Validation loss: 2.448187958907486

Epoch: 5| Step: 10
Training loss: 2.460331336557036
Validation loss: 2.5012991800680155

Epoch: 343| Step: 0
Training loss: 1.9017390674624346
Validation loss: 2.4490321340575685

Epoch: 5| Step: 1
Training loss: 1.6403975556164463
Validation loss: 2.446052407614367

Epoch: 5| Step: 2
Training loss: 2.1552278611515505
Validation loss: 2.483817866868731

Epoch: 5| Step: 3
Training loss: 2.002095316977731
Validation loss: 2.4370247582943887

Epoch: 5| Step: 4
Training loss: 2.121947508346974
Validation loss: 2.444036543032629

Epoch: 5| Step: 5
Training loss: 2.229781223564805
Validation loss: 2.4657881001785165

Epoch: 5| Step: 6
Training loss: 1.940126668983038
Validation loss: 2.4608531087770693

Epoch: 5| Step: 7
Training loss: 1.9110859673654805
Validation loss: 2.4706989371790233

Epoch: 5| Step: 8
Training loss: 1.826773053932294
Validation loss: 2.4581808411730615

Epoch: 5| Step: 9
Training loss: 1.9348411774820378
Validation loss: 2.4673325038932603

Epoch: 5| Step: 10
Training loss: 2.4995882648924477
Validation loss: 2.404831480824452

Epoch: 344| Step: 0
Training loss: 2.2838448176669277
Validation loss: 2.479517417521222

Epoch: 5| Step: 1
Training loss: 1.590611078167679
Validation loss: 2.5459299151542787

Epoch: 5| Step: 2
Training loss: 2.288352465604007
Validation loss: 2.447349846818151

Epoch: 5| Step: 3
Training loss: 1.301229863519449
Validation loss: 2.4304651955148513

Epoch: 5| Step: 4
Training loss: 2.0510167740499057
Validation loss: 2.4321397394578472

Epoch: 5| Step: 5
Training loss: 1.759987532398107
Validation loss: 2.453332683068865

Epoch: 5| Step: 6
Training loss: 1.915390550414475
Validation loss: 2.44432725806874

Epoch: 5| Step: 7
Training loss: 2.065055650972576
Validation loss: 2.4270010366530856

Epoch: 5| Step: 8
Training loss: 2.291562118457412
Validation loss: 2.419371159508733

Epoch: 5| Step: 9
Training loss: 2.084152772601139
Validation loss: 2.4660309734941412

Epoch: 5| Step: 10
Training loss: 2.0217276753871958
Validation loss: 2.4292446244979726

Epoch: 345| Step: 0
Training loss: 2.045989449236114
Validation loss: 2.4646749138799273

Epoch: 5| Step: 1
Training loss: 1.9803348774403384
Validation loss: 2.446700703464994

Epoch: 5| Step: 2
Training loss: 1.8956772946150973
Validation loss: 2.41513686368568

Epoch: 5| Step: 3
Training loss: 2.134257626971527
Validation loss: 2.453146590919075

Epoch: 5| Step: 4
Training loss: 1.902388366551999
Validation loss: 2.452490230209394

Epoch: 5| Step: 5
Training loss: 1.452384678108505
Validation loss: 2.4337310249281643

Epoch: 5| Step: 6
Training loss: 1.8945257127818564
Validation loss: 2.3789596868176703

Epoch: 5| Step: 7
Training loss: 2.6457594212898945
Validation loss: 2.4557792191222023

Epoch: 5| Step: 8
Training loss: 2.083580027915187
Validation loss: 2.4162895384329786

Epoch: 5| Step: 9
Training loss: 1.4029732144165041
Validation loss: 2.4627414366177076

Epoch: 5| Step: 10
Training loss: 1.8463004624089372
Validation loss: 2.440915332027515

Epoch: 346| Step: 0
Training loss: 1.7965498256850054
Validation loss: 2.4405158096645696

Epoch: 5| Step: 1
Training loss: 2.1993153417051228
Validation loss: 2.4368087434153463

Epoch: 5| Step: 2
Training loss: 2.062856701147759
Validation loss: 2.4174471175923142

Epoch: 5| Step: 3
Training loss: 2.3270820483343893
Validation loss: 2.49609581028359

Epoch: 5| Step: 4
Training loss: 2.0073216651003887
Validation loss: 2.4110458412098508

Epoch: 5| Step: 5
Training loss: 1.7062744977261355
Validation loss: 2.400424771699444

Epoch: 5| Step: 6
Training loss: 2.0998816593068432
Validation loss: 2.5034588287700537

Epoch: 5| Step: 7
Training loss: 1.8890860733568122
Validation loss: 2.50949471551227

Epoch: 5| Step: 8
Training loss: 2.4167084745101226
Validation loss: 2.452395546300972

Epoch: 5| Step: 9
Training loss: 1.6964158366019306
Validation loss: 2.4895546437338374

Epoch: 5| Step: 10
Training loss: 1.70425720378511
Validation loss: 2.4542718613625487

Epoch: 347| Step: 0
Training loss: 1.9072058110590226
Validation loss: 2.4577729478249033

Epoch: 5| Step: 1
Training loss: 1.5772512302028074
Validation loss: 2.557270051377661

Epoch: 5| Step: 2
Training loss: 1.6938979052614407
Validation loss: 2.428278449271313

Epoch: 5| Step: 3
Training loss: 1.8322622320324056
Validation loss: 2.4866392260965733

Epoch: 5| Step: 4
Training loss: 2.2186343740503465
Validation loss: 2.4314171043377923

Epoch: 5| Step: 5
Training loss: 1.6974704912904612
Validation loss: 2.4945243325534867

Epoch: 5| Step: 6
Training loss: 1.807391960006954
Validation loss: 2.435527330366799

Epoch: 5| Step: 7
Training loss: 2.367959176865083
Validation loss: 2.4420407053215447

Epoch: 5| Step: 8
Training loss: 1.9244609276127065
Validation loss: 2.431578467817927

Epoch: 5| Step: 9
Training loss: 1.8313307734567483
Validation loss: 2.4019864316575887

Epoch: 5| Step: 10
Training loss: 1.8366544581640412
Validation loss: 2.4135699918168636

Epoch: 348| Step: 0
Training loss: 1.5543248506009542
Validation loss: 2.4784332556233357

Epoch: 5| Step: 1
Training loss: 1.7177259689113573
Validation loss: 2.4167200668879243

Epoch: 5| Step: 2
Training loss: 2.5314840514682557
Validation loss: 2.4649088166969535

Epoch: 5| Step: 3
Training loss: 1.6241521090459727
Validation loss: 2.506377823764812

Epoch: 5| Step: 4
Training loss: 2.0008535947757524
Validation loss: 2.386867667784157

Epoch: 5| Step: 5
Training loss: 2.2489814572178375
Validation loss: 2.43987754874099

Epoch: 5| Step: 6
Training loss: 2.23735114939753
Validation loss: 2.4603943490530362

Epoch: 5| Step: 7
Training loss: 1.474378959388478
Validation loss: 2.38054203155277

Epoch: 5| Step: 8
Training loss: 1.7572449170466615
Validation loss: 2.3887739474222207

Epoch: 5| Step: 9
Training loss: 2.1669928476367852
Validation loss: 2.39251603736371

Epoch: 5| Step: 10
Training loss: 2.0299664476750654
Validation loss: 2.4712510426459384

Epoch: 349| Step: 0
Training loss: 2.0153458276265246
Validation loss: 2.4846150457774097

Epoch: 5| Step: 1
Training loss: 1.6533267296510505
Validation loss: 2.437702532342854

Epoch: 5| Step: 2
Training loss: 1.877681467807988
Validation loss: 2.4297703981839827

Epoch: 5| Step: 3
Training loss: 2.277097292825595
Validation loss: 2.408128714282832

Epoch: 5| Step: 4
Training loss: 2.720853320793667
Validation loss: 2.4397768914008724

Epoch: 5| Step: 5
Training loss: 2.166824726306041
Validation loss: 2.4732091592950294

Epoch: 5| Step: 6
Training loss: 1.9785562946022117
Validation loss: 2.51339942511263

Epoch: 5| Step: 7
Training loss: 1.618064605658475
Validation loss: 2.490365161553766

Epoch: 5| Step: 8
Training loss: 1.4713078404338167
Validation loss: 2.4331322046986243

Epoch: 5| Step: 9
Training loss: 1.5064734803608857
Validation loss: 2.4250113649464584

Epoch: 5| Step: 10
Training loss: 1.7897334277529662
Validation loss: 2.4560750040243846

Epoch: 350| Step: 0
Training loss: 1.723501054520557
Validation loss: 2.3816127124157105

Epoch: 5| Step: 1
Training loss: 1.498378115243968
Validation loss: 2.4439421935139305

Epoch: 5| Step: 2
Training loss: 2.3058807904546144
Validation loss: 2.480450070929095

Epoch: 5| Step: 3
Training loss: 1.7072961806803393
Validation loss: 2.4138855389243425

Epoch: 5| Step: 4
Training loss: 2.3612723900060084
Validation loss: 2.4277795293706284

Epoch: 5| Step: 5
Training loss: 2.475634476225335
Validation loss: 2.4213779782323037

Epoch: 5| Step: 6
Training loss: 1.735660454645842
Validation loss: 2.49634229461324

Epoch: 5| Step: 7
Training loss: 1.931517563343306
Validation loss: 2.354219822814815

Epoch: 5| Step: 8
Training loss: 1.371170172232496
Validation loss: 2.5973521173380405

Epoch: 5| Step: 9
Training loss: 1.9979706243469082
Validation loss: 2.448246926829444

Epoch: 5| Step: 10
Training loss: 1.8617431562187017
Validation loss: 2.45538545613238

Epoch: 351| Step: 0
Training loss: 1.998735982095446
Validation loss: 2.4068624822055384

Epoch: 5| Step: 1
Training loss: 2.029530663190283
Validation loss: 2.453251268167697

Epoch: 5| Step: 2
Training loss: 1.5192944653538478
Validation loss: 2.4754963508556345

Epoch: 5| Step: 3
Training loss: 1.7403047249870862
Validation loss: 2.422635690216578

Epoch: 5| Step: 4
Training loss: 1.354721126997017
Validation loss: 2.3615833778511854

Epoch: 5| Step: 5
Training loss: 1.3739367622415501
Validation loss: 2.419938772208873

Epoch: 5| Step: 6
Training loss: 1.6495794164821949
Validation loss: 2.458354272713254

Epoch: 5| Step: 7
Training loss: 2.141462176266574
Validation loss: 2.4727180246570843

Epoch: 5| Step: 8
Training loss: 2.2868747085858847
Validation loss: 2.3603262925430757

Epoch: 5| Step: 9
Training loss: 2.7765438253089187
Validation loss: 2.424014848483311

Epoch: 5| Step: 10
Training loss: 2.3643810392943454
Validation loss: 2.435230260632037

Epoch: 352| Step: 0
Training loss: 1.5604911861103543
Validation loss: 2.4783639419159162

Epoch: 5| Step: 1
Training loss: 1.6299122144311051
Validation loss: 2.423798151149777

Epoch: 5| Step: 2
Training loss: 1.8053217182184904
Validation loss: 2.3908460218517154

Epoch: 5| Step: 3
Training loss: 2.2955082570340655
Validation loss: 2.4132814254502803

Epoch: 5| Step: 4
Training loss: 1.6514750332078405
Validation loss: 2.4066630683987698

Epoch: 5| Step: 5
Training loss: 2.2651154043679496
Validation loss: 2.3867573925040158

Epoch: 5| Step: 6
Training loss: 2.0551840758660425
Validation loss: 2.4309796760106255

Epoch: 5| Step: 7
Training loss: 1.936133425745294
Validation loss: 2.4667368279677686

Epoch: 5| Step: 8
Training loss: 1.543486843768549
Validation loss: 2.4310010520705436

Epoch: 5| Step: 9
Training loss: 2.3849413757796567
Validation loss: 2.4704973852334513

Epoch: 5| Step: 10
Training loss: 2.0307091799940626
Validation loss: 2.496651851117163

Epoch: 353| Step: 0
Training loss: 1.4849140995239718
Validation loss: 2.4622791618306716

Epoch: 5| Step: 1
Training loss: 1.7957346075524965
Validation loss: 2.4818081630174507

Epoch: 5| Step: 2
Training loss: 1.9307328454569066
Validation loss: 2.4497788515916445

Epoch: 5| Step: 3
Training loss: 2.696372092024519
Validation loss: 2.384793194479789

Epoch: 5| Step: 4
Training loss: 1.9863153417845483
Validation loss: 2.512649819038634

Epoch: 5| Step: 5
Training loss: 2.2192342525231585
Validation loss: 2.43043876328281

Epoch: 5| Step: 6
Training loss: 1.8569547143939225
Validation loss: 2.492232785794081

Epoch: 5| Step: 7
Training loss: 2.4072686553431883
Validation loss: 2.4235856264597424

Epoch: 5| Step: 8
Training loss: 2.0539514652004134
Validation loss: 2.469030322017703

Epoch: 5| Step: 9
Training loss: 1.541967293923112
Validation loss: 2.447717159382411

Epoch: 5| Step: 10
Training loss: 1.3924831448944013
Validation loss: 2.4542808195151937

Epoch: 354| Step: 0
Training loss: 1.9818407832535985
Validation loss: 2.4237091613546835

Epoch: 5| Step: 1
Training loss: 1.912797346249841
Validation loss: 2.3347859375828444

Epoch: 5| Step: 2
Training loss: 2.1195452747661343
Validation loss: 2.441060305001046

Epoch: 5| Step: 3
Training loss: 2.289167278092058
Validation loss: 2.336778842140469

Epoch: 5| Step: 4
Training loss: 1.880292290022152
Validation loss: 2.3658354989387553

Epoch: 5| Step: 5
Training loss: 1.9605008433232418
Validation loss: 2.5050320322256057

Epoch: 5| Step: 6
Training loss: 2.374350609590071
Validation loss: 2.453301382585174

Epoch: 5| Step: 7
Training loss: 1.5643208384691887
Validation loss: 2.4497951002077647

Epoch: 5| Step: 8
Training loss: 1.627596468080751
Validation loss: 2.52555959905668

Epoch: 5| Step: 9
Training loss: 1.7259739351614112
Validation loss: 2.4503168875119195

Epoch: 5| Step: 10
Training loss: 2.3854306705069352
Validation loss: 2.4035902304300807

Epoch: 355| Step: 0
Training loss: 1.8967068165561543
Validation loss: 2.419600061820731

Epoch: 5| Step: 1
Training loss: 2.284825384200158
Validation loss: 2.3610923648920865

Epoch: 5| Step: 2
Training loss: 1.3496868812398868
Validation loss: 2.4464022575449236

Epoch: 5| Step: 3
Training loss: 2.0516941327576315
Validation loss: 2.4841766412382293

Epoch: 5| Step: 4
Training loss: 1.8715221575587933
Validation loss: 2.4348409014240273

Epoch: 5| Step: 5
Training loss: 1.9426173648211673
Validation loss: 2.423547068709963

Epoch: 5| Step: 6
Training loss: 1.8367550591985462
Validation loss: 2.4613528581996578

Epoch: 5| Step: 7
Training loss: 2.045845063817513
Validation loss: 2.4779593144968675

Epoch: 5| Step: 8
Training loss: 1.7897421532864013
Validation loss: 2.449516762755579

Epoch: 5| Step: 9
Training loss: 1.7718477896294784
Validation loss: 2.528089305413206

Epoch: 5| Step: 10
Training loss: 2.4233761964738845
Validation loss: 2.4495926566498483

Epoch: 356| Step: 0
Training loss: 2.473892457319206
Validation loss: 2.38200488512559

Epoch: 5| Step: 1
Training loss: 2.0393066260110513
Validation loss: 2.387383613311626

Epoch: 5| Step: 2
Training loss: 1.5291693428424975
Validation loss: 2.4410162343884205

Epoch: 5| Step: 3
Training loss: 1.758754494775859
Validation loss: 2.4324689995765403

Epoch: 5| Step: 4
Training loss: 2.1595512218861472
Validation loss: 2.4519368843696183

Epoch: 5| Step: 5
Training loss: 1.8700276883773277
Validation loss: 2.469599468504083

Epoch: 5| Step: 6
Training loss: 2.2319222172272135
Validation loss: 2.4611279016955305

Epoch: 5| Step: 7
Training loss: 1.8839070790897976
Validation loss: 2.4224426937941463

Epoch: 5| Step: 8
Training loss: 0.9712653575453832
Validation loss: 2.4771349378528873

Epoch: 5| Step: 9
Training loss: 1.6669940468007352
Validation loss: 2.354620003907531

Epoch: 5| Step: 10
Training loss: 2.262823437918621
Validation loss: 2.4628633124839916

Epoch: 357| Step: 0
Training loss: 2.0877614708431045
Validation loss: 2.460921306201987

Epoch: 5| Step: 1
Training loss: 1.58872207701101
Validation loss: 2.4245564415274714

Epoch: 5| Step: 2
Training loss: 1.823417667388932
Validation loss: 2.4303242867445607

Epoch: 5| Step: 3
Training loss: 2.1871627547652963
Validation loss: 2.388961348774552

Epoch: 5| Step: 4
Training loss: 2.1120095084221973
Validation loss: 2.410046908421156

Epoch: 5| Step: 5
Training loss: 1.636266167825273
Validation loss: 2.371789301286105

Epoch: 5| Step: 6
Training loss: 2.1096409382779457
Validation loss: 2.4634404072627936

Epoch: 5| Step: 7
Training loss: 1.5814448270529622
Validation loss: 2.4395726712551715

Epoch: 5| Step: 8
Training loss: 1.7588653802067107
Validation loss: 2.3881209662208644

Epoch: 5| Step: 9
Training loss: 1.917194031297771
Validation loss: 2.525817711639671

Epoch: 5| Step: 10
Training loss: 2.769001166186736
Validation loss: 2.4034818215749967

Epoch: 358| Step: 0
Training loss: 1.5919512902001345
Validation loss: 2.4501999643477066

Epoch: 5| Step: 1
Training loss: 2.1861692467983747
Validation loss: 2.4089044494613447

Epoch: 5| Step: 2
Training loss: 1.9690842117737475
Validation loss: 2.437857779093849

Epoch: 5| Step: 3
Training loss: 1.5180809336863184
Validation loss: 2.4758236782827727

Epoch: 5| Step: 4
Training loss: 2.7843379333974454
Validation loss: 2.5164644398315112

Epoch: 5| Step: 5
Training loss: 1.9907682262497943
Validation loss: 2.447736640197785

Epoch: 5| Step: 6
Training loss: 1.2478252566340169
Validation loss: 2.4206708684726594

Epoch: 5| Step: 7
Training loss: 1.7687591148114652
Validation loss: 2.4936209921485397

Epoch: 5| Step: 8
Training loss: 1.8767429515969998
Validation loss: 2.429870507835195

Epoch: 5| Step: 9
Training loss: 2.0704539124758425
Validation loss: 2.462475200324356

Epoch: 5| Step: 10
Training loss: 1.9222605248801983
Validation loss: 2.4499474120089126

Epoch: 359| Step: 0
Training loss: 1.9221725233570868
Validation loss: 2.3991343958252958

Epoch: 5| Step: 1
Training loss: 2.023011033763957
Validation loss: 2.4327535153678745

Epoch: 5| Step: 2
Training loss: 2.5951605029441356
Validation loss: 2.4451753783044063

Epoch: 5| Step: 3
Training loss: 1.929954355915696
Validation loss: 2.4583805513166386

Epoch: 5| Step: 4
Training loss: 1.8581465181040782
Validation loss: 2.391824572398653

Epoch: 5| Step: 5
Training loss: 1.8526774723226993
Validation loss: 2.4175450085268637

Epoch: 5| Step: 6
Training loss: 1.8895131144011725
Validation loss: 2.422331475815783

Epoch: 5| Step: 7
Training loss: 1.6762873101118048
Validation loss: 2.507891835452321

Epoch: 5| Step: 8
Training loss: 1.461227959302672
Validation loss: 2.459947706367528

Epoch: 5| Step: 9
Training loss: 1.9679584425671042
Validation loss: 2.449538850945581

Epoch: 5| Step: 10
Training loss: 1.641166379705746
Validation loss: 2.461069497095582

Epoch: 360| Step: 0
Training loss: 1.7616507438847138
Validation loss: 2.458494541589596

Epoch: 5| Step: 1
Training loss: 1.9749791735746143
Validation loss: 2.4188709736368352

Epoch: 5| Step: 2
Training loss: 1.7008728395191657
Validation loss: 2.3984146280077625

Epoch: 5| Step: 3
Training loss: 1.5356505086082
Validation loss: 2.3966100823768604

Epoch: 5| Step: 4
Training loss: 2.275366839501485
Validation loss: 2.452118959331087

Epoch: 5| Step: 5
Training loss: 1.648778654114145
Validation loss: 2.475126615790582

Epoch: 5| Step: 6
Training loss: 1.846054963985014
Validation loss: 2.466043070556752

Epoch: 5| Step: 7
Training loss: 2.048529385878052
Validation loss: 2.4577444117447493

Epoch: 5| Step: 8
Training loss: 1.8993794808267432
Validation loss: 2.487757634098313

Epoch: 5| Step: 9
Training loss: 2.086475317268995
Validation loss: 2.509693044694552

Epoch: 5| Step: 10
Training loss: 2.3283513106369127
Validation loss: 2.3835843035065003

Epoch: 361| Step: 0
Training loss: 1.740547674300377
Validation loss: 2.5270825901082308

Epoch: 5| Step: 1
Training loss: 1.4567037833145755
Validation loss: 2.3680336340662422

Epoch: 5| Step: 2
Training loss: 1.9987941921709322
Validation loss: 2.4125646923941844

Epoch: 5| Step: 3
Training loss: 1.7331645969031608
Validation loss: 2.3860262217227333

Epoch: 5| Step: 4
Training loss: 1.7242725082196053
Validation loss: 2.450335975197199

Epoch: 5| Step: 5
Training loss: 1.5878532377113754
Validation loss: 2.504769342287876

Epoch: 5| Step: 6
Training loss: 1.8783745598295274
Validation loss: 2.4555030584427096

Epoch: 5| Step: 7
Training loss: 2.847677181046618
Validation loss: 2.3814085941407357

Epoch: 5| Step: 8
Training loss: 1.9960253082306878
Validation loss: 2.4196360114315563

Epoch: 5| Step: 9
Training loss: 1.7771117341908893
Validation loss: 2.4249149875098084

Epoch: 5| Step: 10
Training loss: 1.8738035835406925
Validation loss: 2.4483571277884733

Epoch: 362| Step: 0
Training loss: 1.9183742615050903
Validation loss: 2.466709475934286

Epoch: 5| Step: 1
Training loss: 1.9883091892760099
Validation loss: 2.4762326757785322

Epoch: 5| Step: 2
Training loss: 1.9565566776215202
Validation loss: 2.3571876851138387

Epoch: 5| Step: 3
Training loss: 1.9975156851714841
Validation loss: 2.4015638417901193

Epoch: 5| Step: 4
Training loss: 1.8730426108080045
Validation loss: 2.388354466161769

Epoch: 5| Step: 5
Training loss: 2.1596309305939694
Validation loss: 2.403840178211695

Epoch: 5| Step: 6
Training loss: 1.8192556038943581
Validation loss: 2.3813855435230935

Epoch: 5| Step: 7
Training loss: 1.60005682903933
Validation loss: 2.4474458352060378

Epoch: 5| Step: 8
Training loss: 2.278492345090978
Validation loss: 2.472658245831904

Epoch: 5| Step: 9
Training loss: 1.7989854443540678
Validation loss: 2.4711151237383406

Epoch: 5| Step: 10
Training loss: 1.8214918253838488
Validation loss: 2.4665388769152483

Epoch: 363| Step: 0
Training loss: 2.1164729753116642
Validation loss: 2.436876113556763

Epoch: 5| Step: 1
Training loss: 1.6617640709267654
Validation loss: 2.4797727327118073

Epoch: 5| Step: 2
Training loss: 1.5239718551539965
Validation loss: 2.4019549866528203

Epoch: 5| Step: 3
Training loss: 2.0986823444015146
Validation loss: 2.3972370408478976

Epoch: 5| Step: 4
Training loss: 2.09346814891783
Validation loss: 2.3909694759366107

Epoch: 5| Step: 5
Training loss: 2.0252942142329156
Validation loss: 2.5227449884674726

Epoch: 5| Step: 6
Training loss: 2.334134429832511
Validation loss: 2.4605319177065934

Epoch: 5| Step: 7
Training loss: 1.8989615639306685
Validation loss: 2.431013559140295

Epoch: 5| Step: 8
Training loss: 1.3487175342375175
Validation loss: 2.4750100836740576

Epoch: 5| Step: 9
Training loss: 1.5357601152596438
Validation loss: 2.475672195807794

Epoch: 5| Step: 10
Training loss: 2.575339182023568
Validation loss: 2.39265590799954

Epoch: 364| Step: 0
Training loss: 1.6181647991945365
Validation loss: 2.4226087789036748

Epoch: 5| Step: 1
Training loss: 2.3847010398323394
Validation loss: 2.478794716983903

Epoch: 5| Step: 2
Training loss: 1.6574721955143616
Validation loss: 2.389671090865333

Epoch: 5| Step: 3
Training loss: 1.8497371125951032
Validation loss: 2.4026122075177887

Epoch: 5| Step: 4
Training loss: 1.8203458332726263
Validation loss: 2.410258043313823

Epoch: 5| Step: 5
Training loss: 1.6789478891498064
Validation loss: 2.4372882882544045

Epoch: 5| Step: 6
Training loss: 1.551768106626884
Validation loss: 2.442271723695776

Epoch: 5| Step: 7
Training loss: 2.554092944659316
Validation loss: 2.408579286668777

Epoch: 5| Step: 8
Training loss: 2.086420239084758
Validation loss: 2.4168004991463126

Epoch: 5| Step: 9
Training loss: 2.1628346178775555
Validation loss: 2.4260172595120864

Epoch: 5| Step: 10
Training loss: 1.8724952498045946
Validation loss: 2.4078631215144624

Epoch: 365| Step: 0
Training loss: 1.891498269415358
Validation loss: 2.4298448899735816

Epoch: 5| Step: 1
Training loss: 1.7442864744712072
Validation loss: 2.3558799294839914

Epoch: 5| Step: 2
Training loss: 2.0670121283615983
Validation loss: 2.5239355571759385

Epoch: 5| Step: 3
Training loss: 1.786839866119323
Validation loss: 2.35522263417131

Epoch: 5| Step: 4
Training loss: 1.885824050588289
Validation loss: 2.443819041751162

Epoch: 5| Step: 5
Training loss: 2.112155692127274
Validation loss: 2.408283065681194

Epoch: 5| Step: 6
Training loss: 1.7911955931254495
Validation loss: 2.4511462266605815

Epoch: 5| Step: 7
Training loss: 1.5711738918811797
Validation loss: 2.4769385919759217

Epoch: 5| Step: 8
Training loss: 2.6398310624602623
Validation loss: 2.453923338146134

Epoch: 5| Step: 9
Training loss: 1.7902648084177473
Validation loss: 2.3628337081419

Epoch: 5| Step: 10
Training loss: 1.7832571399609423
Validation loss: 2.4823356384885877

Epoch: 366| Step: 0
Training loss: 1.6683677892845648
Validation loss: 2.5083834223443615

Epoch: 5| Step: 1
Training loss: 1.9241217529531176
Validation loss: 2.4878099423740943

Epoch: 5| Step: 2
Training loss: 1.3937920499881715
Validation loss: 2.4545012971733007

Epoch: 5| Step: 3
Training loss: 2.707886311735172
Validation loss: 2.437204141596466

Epoch: 5| Step: 4
Training loss: 1.9475086485214061
Validation loss: 2.4390521149662776

Epoch: 5| Step: 5
Training loss: 2.081393546804565
Validation loss: 2.431762427636539

Epoch: 5| Step: 6
Training loss: 1.5109268203878647
Validation loss: 2.4496065889127547

Epoch: 5| Step: 7
Training loss: 1.7681203442563154
Validation loss: 2.4202900824188545

Epoch: 5| Step: 8
Training loss: 1.7942180727291581
Validation loss: 2.379308430053426

Epoch: 5| Step: 9
Training loss: 1.923707042311134
Validation loss: 2.3472202787492176

Epoch: 5| Step: 10
Training loss: 1.8455353837260446
Validation loss: 2.4608210689609837

Epoch: 367| Step: 0
Training loss: 1.3995471579595309
Validation loss: 2.370205170638892

Epoch: 5| Step: 1
Training loss: 2.262798782768549
Validation loss: 2.3960843907484786

Epoch: 5| Step: 2
Training loss: 1.791537775534128
Validation loss: 2.351561471954329

Epoch: 5| Step: 3
Training loss: 2.0419113894823053
Validation loss: 2.366528010115946

Epoch: 5| Step: 4
Training loss: 2.1362069753172426
Validation loss: 2.453349378900279

Epoch: 5| Step: 5
Training loss: 1.9802946055517148
Validation loss: 2.417202908770762

Epoch: 5| Step: 6
Training loss: 1.0324931887570552
Validation loss: 2.4150988610275808

Epoch: 5| Step: 7
Training loss: 2.114675122102635
Validation loss: 2.3902551642538787

Epoch: 5| Step: 8
Training loss: 1.4092501532158828
Validation loss: 2.4637283732788724

Epoch: 5| Step: 9
Training loss: 2.4571962043445996
Validation loss: 2.4562381386623797

Epoch: 5| Step: 10
Training loss: 1.8416131778504072
Validation loss: 2.3898379473761646

Epoch: 368| Step: 0
Training loss: 1.863398838131534
Validation loss: 2.445806003803663

Epoch: 5| Step: 1
Training loss: 1.8711535736905291
Validation loss: 2.446787565172086

Epoch: 5| Step: 2
Training loss: 1.8572885042236014
Validation loss: 2.444181733644145

Epoch: 5| Step: 3
Training loss: 1.2001229521228636
Validation loss: 2.455821727497261

Epoch: 5| Step: 4
Training loss: 1.5548222929062698
Validation loss: 2.4723244799108905

Epoch: 5| Step: 5
Training loss: 2.259390625958997
Validation loss: 2.532087989726211

Epoch: 5| Step: 6
Training loss: 2.0329491184545416
Validation loss: 2.4469267794033858

Epoch: 5| Step: 7
Training loss: 2.6719775263874834
Validation loss: 2.46277865258537

Epoch: 5| Step: 8
Training loss: 2.042467686783905
Validation loss: 2.4892258869978363

Epoch: 5| Step: 9
Training loss: 1.8845569554378516
Validation loss: 2.4263206456754354

Epoch: 5| Step: 10
Training loss: 1.8298831538642746
Validation loss: 2.378378590903863

Epoch: 369| Step: 0
Training loss: 1.7523065761206564
Validation loss: 2.4010163992916125

Epoch: 5| Step: 1
Training loss: 1.5868042329782233
Validation loss: 2.472524377409955

Epoch: 5| Step: 2
Training loss: 2.3270097147726916
Validation loss: 2.446999580244906

Epoch: 5| Step: 3
Training loss: 2.382724047410526
Validation loss: 2.4221622610270557

Epoch: 5| Step: 4
Training loss: 1.6849222628266263
Validation loss: 2.417359562184817

Epoch: 5| Step: 5
Training loss: 1.9423892566234544
Validation loss: 2.49578143817456

Epoch: 5| Step: 6
Training loss: 2.0359398327314198
Validation loss: 2.4285191026589574

Epoch: 5| Step: 7
Training loss: 1.739039634972419
Validation loss: 2.486051337387707

Epoch: 5| Step: 8
Training loss: 2.019777382584877
Validation loss: 2.4580617086838963

Epoch: 5| Step: 9
Training loss: 2.1997756930356354
Validation loss: 2.5016426227470574

Epoch: 5| Step: 10
Training loss: 2.0581412062251614
Validation loss: 2.4598766086548474

Epoch: 370| Step: 0
Training loss: 1.3473792634566168
Validation loss: 2.4792866693746785

Epoch: 5| Step: 1
Training loss: 1.7581860632790036
Validation loss: 2.406854495787736

Epoch: 5| Step: 2
Training loss: 2.221676146116683
Validation loss: 2.433229677171547

Epoch: 5| Step: 3
Training loss: 1.938142546888313
Validation loss: 2.489382164498636

Epoch: 5| Step: 4
Training loss: 2.0562128127425483
Validation loss: 2.448748755869045

Epoch: 5| Step: 5
Training loss: 1.772242139022081
Validation loss: 2.4355964253316063

Epoch: 5| Step: 6
Training loss: 1.679666421447502
Validation loss: 2.447134127367174

Epoch: 5| Step: 7
Training loss: 2.69118982781995
Validation loss: 2.4855959819894577

Epoch: 5| Step: 8
Training loss: 2.0074198891889137
Validation loss: 2.430298219018746

Epoch: 5| Step: 9
Training loss: 1.4602708570508927
Validation loss: 2.467981229447097

Epoch: 5| Step: 10
Training loss: 1.97882674125645
Validation loss: 2.448828504642229

Epoch: 371| Step: 0
Training loss: 1.7132540135756167
Validation loss: 2.3641994714602785

Epoch: 5| Step: 1
Training loss: 1.7855323044827731
Validation loss: 2.509721093277297

Epoch: 5| Step: 2
Training loss: 2.081889364192427
Validation loss: 2.3819424438571803

Epoch: 5| Step: 3
Training loss: 2.013487162660646
Validation loss: 2.450894642626184

Epoch: 5| Step: 4
Training loss: 2.170925673890098
Validation loss: 2.459056963264559

Epoch: 5| Step: 5
Training loss: 1.5848882803066804
Validation loss: 2.358057357312664

Epoch: 5| Step: 6
Training loss: 1.645007719120362
Validation loss: 2.360670482032895

Epoch: 5| Step: 7
Training loss: 1.652197432296045
Validation loss: 2.319791640136497

Epoch: 5| Step: 8
Training loss: 1.8747507565460326
Validation loss: 2.4173311667891806

Epoch: 5| Step: 9
Training loss: 2.5600064869142836
Validation loss: 2.3705374215801007

Epoch: 5| Step: 10
Training loss: 1.774882597465812
Validation loss: 2.4389191075862766

Epoch: 372| Step: 0
Training loss: 1.7929738694992612
Validation loss: 2.4168865897987644

Epoch: 5| Step: 1
Training loss: 2.610579161420782
Validation loss: 2.33590363047771

Epoch: 5| Step: 2
Training loss: 1.8891388908445474
Validation loss: 2.3833396883856217

Epoch: 5| Step: 3
Training loss: 1.7112101855776962
Validation loss: 2.3462855771405353

Epoch: 5| Step: 4
Training loss: 2.096733359088315
Validation loss: 2.3448042403830316

Epoch: 5| Step: 5
Training loss: 1.8541711385723008
Validation loss: 2.334148365351763

Epoch: 5| Step: 6
Training loss: 1.706797498677658
Validation loss: 2.438930385220168

Epoch: 5| Step: 7
Training loss: 1.8984974039304643
Validation loss: 2.4404482857832925

Epoch: 5| Step: 8
Training loss: 1.5628291737003195
Validation loss: 2.3998958710864318

Epoch: 5| Step: 9
Training loss: 2.1538849174763106
Validation loss: 2.405636434712587

Epoch: 5| Step: 10
Training loss: 1.5259401550207374
Validation loss: 2.4912803460370405

Epoch: 373| Step: 0
Training loss: 1.3662284757239649
Validation loss: 2.422427504147143

Epoch: 5| Step: 1
Training loss: 1.894255879633059
Validation loss: 2.412006528927876

Epoch: 5| Step: 2
Training loss: 1.708189128588969
Validation loss: 2.423704390967696

Epoch: 5| Step: 3
Training loss: 2.1193999382313495
Validation loss: 2.476234421291638

Epoch: 5| Step: 4
Training loss: 1.994949819273118
Validation loss: 2.4368208671904563

Epoch: 5| Step: 5
Training loss: 1.752628124086542
Validation loss: 2.367139558791629

Epoch: 5| Step: 6
Training loss: 1.7550175805583395
Validation loss: 2.4903615410683817

Epoch: 5| Step: 7
Training loss: 2.289392232744123
Validation loss: 2.4309423481293955

Epoch: 5| Step: 8
Training loss: 1.8832485596248578
Validation loss: 2.393358641221083

Epoch: 5| Step: 9
Training loss: 1.6532431605318858
Validation loss: 2.488458847405137

Epoch: 5| Step: 10
Training loss: 1.8585940732630946
Validation loss: 2.434223892037987

Epoch: 374| Step: 0
Training loss: 1.629761761649382
Validation loss: 2.4636991273148503

Epoch: 5| Step: 1
Training loss: 2.078849952850095
Validation loss: 2.304353987205386

Epoch: 5| Step: 2
Training loss: 1.8702707411869453
Validation loss: 2.3552430618092175

Epoch: 5| Step: 3
Training loss: 1.8627008777818062
Validation loss: 2.3824225273535156

Epoch: 5| Step: 4
Training loss: 1.7429511616091717
Validation loss: 2.3867393334196674

Epoch: 5| Step: 5
Training loss: 2.4308185459332776
Validation loss: 2.3845924199717956

Epoch: 5| Step: 6
Training loss: 2.0268471758329807
Validation loss: 2.4567058698689896

Epoch: 5| Step: 7
Training loss: 1.9938764406488032
Validation loss: 2.3633855243629425

Epoch: 5| Step: 8
Training loss: 1.3074963423347734
Validation loss: 2.4169306379287017

Epoch: 5| Step: 9
Training loss: 1.5051284381645655
Validation loss: 2.4794613790647158

Epoch: 5| Step: 10
Training loss: 1.87601951855752
Validation loss: 2.4584208000672865

Epoch: 375| Step: 0
Training loss: 1.679328844680532
Validation loss: 2.3512682480062064

Epoch: 5| Step: 1
Training loss: 1.8562701933818828
Validation loss: 2.4203198370284142

Epoch: 5| Step: 2
Training loss: 1.6164139818879617
Validation loss: 2.388641926861251

Epoch: 5| Step: 3
Training loss: 1.9849889211081246
Validation loss: 2.462283503487861

Epoch: 5| Step: 4
Training loss: 2.4027635161087457
Validation loss: 2.4604011426444266

Epoch: 5| Step: 5
Training loss: 2.20002430989099
Validation loss: 2.3975753535997444

Epoch: 5| Step: 6
Training loss: 1.7434678782640225
Validation loss: 2.398117460405732

Epoch: 5| Step: 7
Training loss: 2.1263348369952872
Validation loss: 2.445271650199382

Epoch: 5| Step: 8
Training loss: 1.599231717309153
Validation loss: 2.4446842770890416

Epoch: 5| Step: 9
Training loss: 2.055668469784468
Validation loss: 2.475732125528136

Epoch: 5| Step: 10
Training loss: 1.890556081981712
Validation loss: 2.5044653176567886

Epoch: 376| Step: 0
Training loss: 1.654674428396492
Validation loss: 2.392360910881715

Epoch: 5| Step: 1
Training loss: 1.5907170477054038
Validation loss: 2.387688431221462

Epoch: 5| Step: 2
Training loss: 2.2552273744362217
Validation loss: 2.4669661052340746

Epoch: 5| Step: 3
Training loss: 1.5516521785208568
Validation loss: 2.4268439027504356

Epoch: 5| Step: 4
Training loss: 2.1672407147860655
Validation loss: 2.3922759689051767

Epoch: 5| Step: 5
Training loss: 1.9160853070917105
Validation loss: 2.3819001940513846

Epoch: 5| Step: 6
Training loss: 1.6471509930222203
Validation loss: 2.4368065782988655

Epoch: 5| Step: 7
Training loss: 1.9668430599483633
Validation loss: 2.359067787532437

Epoch: 5| Step: 8
Training loss: 1.7418525271134602
Validation loss: 2.449203411874044

Epoch: 5| Step: 9
Training loss: 1.8926561022619623
Validation loss: 2.340731720986108

Epoch: 5| Step: 10
Training loss: 1.5475628026935255
Validation loss: 2.3809465950940996

Epoch: 377| Step: 0
Training loss: 2.2290714516908525
Validation loss: 2.4067188664324957

Epoch: 5| Step: 1
Training loss: 1.777219998589263
Validation loss: 2.4323200806418774

Epoch: 5| Step: 2
Training loss: 2.5943545820351273
Validation loss: 2.386651655820667

Epoch: 5| Step: 3
Training loss: 1.7669550519363402
Validation loss: 2.4445572114230107

Epoch: 5| Step: 4
Training loss: 1.579886935329257
Validation loss: 2.4185796626551634

Epoch: 5| Step: 5
Training loss: 1.7006655792587753
Validation loss: 2.3927413009506733

Epoch: 5| Step: 6
Training loss: 1.8306116651555338
Validation loss: 2.418377052140875

Epoch: 5| Step: 7
Training loss: 1.6205650110760448
Validation loss: 2.4365414032629364

Epoch: 5| Step: 8
Training loss: 1.718405602369464
Validation loss: 2.5147455760155575

Epoch: 5| Step: 9
Training loss: 1.9062283624140186
Validation loss: 2.4435716167010337

Epoch: 5| Step: 10
Training loss: 1.7666456935045505
Validation loss: 2.4242483100745083

Epoch: 378| Step: 0
Training loss: 1.8600767077758984
Validation loss: 2.4159911197706148

Epoch: 5| Step: 1
Training loss: 1.566234094001639
Validation loss: 2.4038908534725505

Epoch: 5| Step: 2
Training loss: 1.7696275832204575
Validation loss: 2.486763154407044

Epoch: 5| Step: 3
Training loss: 1.8137271278669103
Validation loss: 2.4153297730716305

Epoch: 5| Step: 4
Training loss: 1.7435927945717344
Validation loss: 2.4120074759416306

Epoch: 5| Step: 5
Training loss: 2.2436061717399576
Validation loss: 2.4714411093049002

Epoch: 5| Step: 6
Training loss: 2.3522453457290347
Validation loss: 2.4287888384016614

Epoch: 5| Step: 7
Training loss: 1.6704291393067803
Validation loss: 2.4118769567221627

Epoch: 5| Step: 8
Training loss: 1.651457059412276
Validation loss: 2.4165589460976884

Epoch: 5| Step: 9
Training loss: 2.0987470976472635
Validation loss: 2.381314204904526

Epoch: 5| Step: 10
Training loss: 1.9609026050882399
Validation loss: 2.3122235082700255

Epoch: 379| Step: 0
Training loss: 1.7459212864439944
Validation loss: 2.393434802896273

Epoch: 5| Step: 1
Training loss: 2.329818212269292
Validation loss: 2.412869899130918

Epoch: 5| Step: 2
Training loss: 1.9152503239937984
Validation loss: 2.3451292566826987

Epoch: 5| Step: 3
Training loss: 1.2692149545889178
Validation loss: 2.428467318767951

Epoch: 5| Step: 4
Training loss: 2.381303252978861
Validation loss: 2.3964594732157924

Epoch: 5| Step: 5
Training loss: 2.2231908064897503
Validation loss: 2.3988392512022747

Epoch: 5| Step: 6
Training loss: 1.7579569439351284
Validation loss: 2.361896988361174

Epoch: 5| Step: 7
Training loss: 2.3309229480735647
Validation loss: 2.43959076378329

Epoch: 5| Step: 8
Training loss: 1.7172653722070863
Validation loss: 2.38132073749481

Epoch: 5| Step: 9
Training loss: 1.498615261508559
Validation loss: 2.3529991237056036

Epoch: 5| Step: 10
Training loss: 1.2201904685221694
Validation loss: 2.3648136506137662

Epoch: 380| Step: 0
Training loss: 1.7475553876533527
Validation loss: 2.424682758437474

Epoch: 5| Step: 1
Training loss: 2.0114143807975764
Validation loss: 2.3959094905296623

Epoch: 5| Step: 2
Training loss: 1.8864373733757565
Validation loss: 2.4503874470715727

Epoch: 5| Step: 3
Training loss: 1.8474537776796587
Validation loss: 2.4103334183961294

Epoch: 5| Step: 4
Training loss: 1.6636770455682448
Validation loss: 2.4351989653915336

Epoch: 5| Step: 5
Training loss: 1.786509795786887
Validation loss: 2.4068254800929236

Epoch: 5| Step: 6
Training loss: 1.8955610170518002
Validation loss: 2.4424423047373236

Epoch: 5| Step: 7
Training loss: 1.9400753625015883
Validation loss: 2.398859011926927

Epoch: 5| Step: 8
Training loss: 1.9167289378236816
Validation loss: 2.4900824297578694

Epoch: 5| Step: 9
Training loss: 1.5207071731007882
Validation loss: 2.4108318627028535

Epoch: 5| Step: 10
Training loss: 2.43764231339735
Validation loss: 2.3909385551124682

Epoch: 381| Step: 0
Training loss: 2.1018855757706727
Validation loss: 2.436131333161708

Epoch: 5| Step: 1
Training loss: 1.4324781354264124
Validation loss: 2.4336922244646213

Epoch: 5| Step: 2
Training loss: 1.7997641514866782
Validation loss: 2.3817391186040706

Epoch: 5| Step: 3
Training loss: 1.8092032079229226
Validation loss: 2.4245750029667934

Epoch: 5| Step: 4
Training loss: 1.676506116901983
Validation loss: 2.4110400643490295

Epoch: 5| Step: 5
Training loss: 2.3653974657980026
Validation loss: 2.4883966290226125

Epoch: 5| Step: 6
Training loss: 1.5965821775939975
Validation loss: 2.4423205718179513

Epoch: 5| Step: 7
Training loss: 2.046207697762574
Validation loss: 2.3759475522202553

Epoch: 5| Step: 8
Training loss: 1.43893402553315
Validation loss: 2.4094595809775536

Epoch: 5| Step: 9
Training loss: 1.895586361011767
Validation loss: 2.376298750086846

Epoch: 5| Step: 10
Training loss: 2.3595268756413392
Validation loss: 2.419206865564111

Epoch: 382| Step: 0
Training loss: 2.3858033467907838
Validation loss: 2.4098541261333715

Epoch: 5| Step: 1
Training loss: 1.8424593400544904
Validation loss: 2.3532337456821955

Epoch: 5| Step: 2
Training loss: 1.1532519366274752
Validation loss: 2.295756016322247

Epoch: 5| Step: 3
Training loss: 1.6043284280970014
Validation loss: 2.4814423562139956

Epoch: 5| Step: 4
Training loss: 1.649814843857471
Validation loss: 2.421420789580744

Epoch: 5| Step: 5
Training loss: 1.87097938522571
Validation loss: 2.3613175591636733

Epoch: 5| Step: 6
Training loss: 2.0852545716825905
Validation loss: 2.4173709266127266

Epoch: 5| Step: 7
Training loss: 2.0054710183095494
Validation loss: 2.39550313791987

Epoch: 5| Step: 8
Training loss: 2.0752522970117253
Validation loss: 2.4547352033593333

Epoch: 5| Step: 9
Training loss: 1.5686986420876063
Validation loss: 2.3835582236661033

Epoch: 5| Step: 10
Training loss: 1.3024565759401647
Validation loss: 2.4300401416742625

Epoch: 383| Step: 0
Training loss: 1.9668993047201087
Validation loss: 2.434531135790615

Epoch: 5| Step: 1
Training loss: 1.8919170788060462
Validation loss: 2.4033971419713227

Epoch: 5| Step: 2
Training loss: 1.4208651299521844
Validation loss: 2.4379028279836676

Epoch: 5| Step: 3
Training loss: 1.7563764343364459
Validation loss: 2.351925570428123

Epoch: 5| Step: 4
Training loss: 2.2106279891158094
Validation loss: 2.496235355104992

Epoch: 5| Step: 5
Training loss: 1.8021938385644436
Validation loss: 2.403195291088541

Epoch: 5| Step: 6
Training loss: 1.7357371711679932
Validation loss: 2.3721912400677954

Epoch: 5| Step: 7
Training loss: 1.8156872054193651
Validation loss: 2.4133201201264773

Epoch: 5| Step: 8
Training loss: 1.727141822527053
Validation loss: 2.38737336467014

Epoch: 5| Step: 9
Training loss: 2.269452879926469
Validation loss: 2.4311050686489915

Epoch: 5| Step: 10
Training loss: 1.7461577879493766
Validation loss: 2.423555992338006

Epoch: 384| Step: 0
Training loss: 1.7734849562156132
Validation loss: 2.4213298119135893

Epoch: 5| Step: 1
Training loss: 1.6912324388808884
Validation loss: 2.4427991301341923

Epoch: 5| Step: 2
Training loss: 1.7220840714874026
Validation loss: 2.473856152085002

Epoch: 5| Step: 3
Training loss: 1.9927945876277349
Validation loss: 2.4874584926473737

Epoch: 5| Step: 4
Training loss: 1.936702810378071
Validation loss: 2.4404626599757435

Epoch: 5| Step: 5
Training loss: 1.4991365172637876
Validation loss: 2.4463294258281247

Epoch: 5| Step: 6
Training loss: 2.1316134816867804
Validation loss: 2.392362066060236

Epoch: 5| Step: 7
Training loss: 1.6750531515541875
Validation loss: 2.477997236122981

Epoch: 5| Step: 8
Training loss: 2.036146746617489
Validation loss: 2.4250432742483934

Epoch: 5| Step: 9
Training loss: 1.5833414562753148
Validation loss: 2.404826502423988

Epoch: 5| Step: 10
Training loss: 2.75598178864706
Validation loss: 2.3888570366141595

Epoch: 385| Step: 0
Training loss: 1.37594857874423
Validation loss: 2.3727913983705924

Epoch: 5| Step: 1
Training loss: 1.7642528637331305
Validation loss: 2.41938683775793

Epoch: 5| Step: 2
Training loss: 2.166728446764343
Validation loss: 2.423572133274017

Epoch: 5| Step: 3
Training loss: 1.9871848330335122
Validation loss: 2.5055720683678757

Epoch: 5| Step: 4
Training loss: 2.122279276699489
Validation loss: 2.3892740143648474

Epoch: 5| Step: 5
Training loss: 1.6294219666601313
Validation loss: 2.4427657211268508

Epoch: 5| Step: 6
Training loss: 1.6439755332174957
Validation loss: 2.4134119844999424

Epoch: 5| Step: 7
Training loss: 1.5722763914130597
Validation loss: 2.381862312273824

Epoch: 5| Step: 8
Training loss: 1.2483750749051137
Validation loss: 2.5238439294289576

Epoch: 5| Step: 9
Training loss: 2.788340755649621
Validation loss: 2.421160128991796

Epoch: 5| Step: 10
Training loss: 2.067096328166502
Validation loss: 2.3881015846910634

Epoch: 386| Step: 0
Training loss: 1.355386297263129
Validation loss: 2.400128320285211

Epoch: 5| Step: 1
Training loss: 1.6008753349093559
Validation loss: 2.3555332866729115

Epoch: 5| Step: 2
Training loss: 1.6406780415997966
Validation loss: 2.4119359950210697

Epoch: 5| Step: 3
Training loss: 1.7145613522547836
Validation loss: 2.3921610265944806

Epoch: 5| Step: 4
Training loss: 1.6641084906441748
Validation loss: 2.482214878791393

Epoch: 5| Step: 5
Training loss: 1.8664627264650766
Validation loss: 2.451661976247302

Epoch: 5| Step: 6
Training loss: 1.9013394753935178
Validation loss: 2.4138742239340893

Epoch: 5| Step: 7
Training loss: 2.2858859470314115
Validation loss: 2.424268966118276

Epoch: 5| Step: 8
Training loss: 2.131054163909923
Validation loss: 2.4870161743881023

Epoch: 5| Step: 9
Training loss: 2.0707660682033624
Validation loss: 2.556311593465867

Epoch: 5| Step: 10
Training loss: 1.9403742728074391
Validation loss: 2.438884982151265

Epoch: 387| Step: 0
Training loss: 1.6834509981533747
Validation loss: 2.4202435098047763

Epoch: 5| Step: 1
Training loss: 1.8167413217912878
Validation loss: 2.451660829142007

Epoch: 5| Step: 2
Training loss: 1.8790588951361744
Validation loss: 2.4661389737902746

Epoch: 5| Step: 3
Training loss: 2.216089292014901
Validation loss: 2.3782037273906496

Epoch: 5| Step: 4
Training loss: 1.4657503704790835
Validation loss: 2.4107525765326945

Epoch: 5| Step: 5
Training loss: 1.6689493124586356
Validation loss: 2.367262866247528

Epoch: 5| Step: 6
Training loss: 1.8937444252460875
Validation loss: 2.3693839448033915

Epoch: 5| Step: 7
Training loss: 1.8235304389548983
Validation loss: 2.4637264492951094

Epoch: 5| Step: 8
Training loss: 1.7132036364605607
Validation loss: 2.4044520300052143

Epoch: 5| Step: 9
Training loss: 1.7903289976340346
Validation loss: 2.4389364565578204

Epoch: 5| Step: 10
Training loss: 1.947734382246563
Validation loss: 2.438411293031992

Epoch: 388| Step: 0
Training loss: 1.5453377994514508
Validation loss: 2.3710763446829715

Epoch: 5| Step: 1
Training loss: 1.6263582715197467
Validation loss: 2.390617421531153

Epoch: 5| Step: 2
Training loss: 2.140080292166952
Validation loss: 2.430647965494437

Epoch: 5| Step: 3
Training loss: 1.9033468057697887
Validation loss: 2.4422656102639237

Epoch: 5| Step: 4
Training loss: 2.097872646542988
Validation loss: 2.3969397267162913

Epoch: 5| Step: 5
Training loss: 1.9212819246557205
Validation loss: 2.4504494164242248

Epoch: 5| Step: 6
Training loss: 1.7983180346941556
Validation loss: 2.407605325808738

Epoch: 5| Step: 7
Training loss: 1.9494568826466987
Validation loss: 2.468650458642083

Epoch: 5| Step: 8
Training loss: 2.1930350983642444
Validation loss: 2.4747526610996116

Epoch: 5| Step: 9
Training loss: 1.1946608817976583
Validation loss: 2.4120400956087282

Epoch: 5| Step: 10
Training loss: 2.0944079603642782
Validation loss: 2.356377657696258

Epoch: 389| Step: 0
Training loss: 2.121340124388318
Validation loss: 2.3362422750739436

Epoch: 5| Step: 1
Training loss: 2.0178745934543225
Validation loss: 2.38580401837806

Epoch: 5| Step: 2
Training loss: 2.13618733215376
Validation loss: 2.4801432904975367

Epoch: 5| Step: 3
Training loss: 1.7164857688822797
Validation loss: 2.4295895775717296

Epoch: 5| Step: 4
Training loss: 1.5854892191115861
Validation loss: 2.412042378081424

Epoch: 5| Step: 5
Training loss: 2.1126334560155766
Validation loss: 2.4036992220592763

Epoch: 5| Step: 6
Training loss: 1.6570574393713993
Validation loss: 2.3713848641263993

Epoch: 5| Step: 7
Training loss: 1.546952679157554
Validation loss: 2.4131430977050985

Epoch: 5| Step: 8
Training loss: 1.9905542597635018
Validation loss: 2.438036569036489

Epoch: 5| Step: 9
Training loss: 1.9585276838677983
Validation loss: 2.418542565269266

Epoch: 5| Step: 10
Training loss: 1.3104298478248468
Validation loss: 2.4215266956077968

Epoch: 390| Step: 0
Training loss: 1.8590469070886129
Validation loss: 2.3913483463343725

Epoch: 5| Step: 1
Training loss: 1.5992282883919182
Validation loss: 2.3971731323056478

Epoch: 5| Step: 2
Training loss: 1.6515674255355388
Validation loss: 2.41233860716983

Epoch: 5| Step: 3
Training loss: 2.07239643514592
Validation loss: 2.369825000296367

Epoch: 5| Step: 4
Training loss: 1.5161283777931964
Validation loss: 2.4037062249487136

Epoch: 5| Step: 5
Training loss: 2.0018704727602814
Validation loss: 2.4275073897860104

Epoch: 5| Step: 6
Training loss: 1.9083240669836206
Validation loss: 2.330178574569674

Epoch: 5| Step: 7
Training loss: 1.807782248571133
Validation loss: 2.40378649328517

Epoch: 5| Step: 8
Training loss: 2.442953416015595
Validation loss: 2.4502222232016555

Epoch: 5| Step: 9
Training loss: 1.9598617338535298
Validation loss: 2.398516934601144

Epoch: 5| Step: 10
Training loss: 1.2432471500028848
Validation loss: 2.3586135327623032

Epoch: 391| Step: 0
Training loss: 1.741754383938538
Validation loss: 2.443806260068245

Epoch: 5| Step: 1
Training loss: 2.1568817097889195
Validation loss: 2.428981170160085

Epoch: 5| Step: 2
Training loss: 2.61961366163726
Validation loss: 2.4283466631064554

Epoch: 5| Step: 3
Training loss: 1.747618144220594
Validation loss: 2.4273043732588477

Epoch: 5| Step: 4
Training loss: 1.679748675984427
Validation loss: 2.42476047051346

Epoch: 5| Step: 5
Training loss: 1.4333300438924497
Validation loss: 2.452810353644103

Epoch: 5| Step: 6
Training loss: 1.4698997218124943
Validation loss: 2.4031430201831805

Epoch: 5| Step: 7
Training loss: 1.9192122334437434
Validation loss: 2.413550021728093

Epoch: 5| Step: 8
Training loss: 1.8738397823350454
Validation loss: 2.5073953252867667

Epoch: 5| Step: 9
Training loss: 1.601248808122559
Validation loss: 2.4149488709555595

Epoch: 5| Step: 10
Training loss: 2.1417970442019585
Validation loss: 2.4129460548049946

Epoch: 392| Step: 0
Training loss: 1.5208757821347008
Validation loss: 2.421895927156187

Epoch: 5| Step: 1
Training loss: 1.3863828870201413
Validation loss: 2.4008509710324013

Epoch: 5| Step: 2
Training loss: 2.078523067123376
Validation loss: 2.374913130932598

Epoch: 5| Step: 3
Training loss: 1.4412076653038728
Validation loss: 2.4037227359449242

Epoch: 5| Step: 4
Training loss: 2.067173373750038
Validation loss: 2.3947964950468816

Epoch: 5| Step: 5
Training loss: 1.6367320057917114
Validation loss: 2.3658297563458985

Epoch: 5| Step: 6
Training loss: 2.114626754039333
Validation loss: 2.4409685574556765

Epoch: 5| Step: 7
Training loss: 2.114914127527448
Validation loss: 2.3463682299205213

Epoch: 5| Step: 8
Training loss: 1.9568725643429117
Validation loss: 2.350906687807173

Epoch: 5| Step: 9
Training loss: 1.680679454212096
Validation loss: 2.3679407714202467

Epoch: 5| Step: 10
Training loss: 1.7508800201267791
Validation loss: 2.4462431682640275

Epoch: 393| Step: 0
Training loss: 1.6427459086795495
Validation loss: 2.423984477163851

Epoch: 5| Step: 1
Training loss: 1.518823610884498
Validation loss: 2.3861742662868015

Epoch: 5| Step: 2
Training loss: 1.8617307981932851
Validation loss: 2.4006710060454646

Epoch: 5| Step: 3
Training loss: 1.7148936618501618
Validation loss: 2.3679520271183803

Epoch: 5| Step: 4
Training loss: 1.822893727476112
Validation loss: 2.451649294273056

Epoch: 5| Step: 5
Training loss: 1.678687716285183
Validation loss: 2.384509371399199

Epoch: 5| Step: 6
Training loss: 2.465151324782547
Validation loss: 2.3800523447023236

Epoch: 5| Step: 7
Training loss: 1.9396035864974848
Validation loss: 2.3761326097489297

Epoch: 5| Step: 8
Training loss: 1.9090454366561131
Validation loss: 2.379517436901238

Epoch: 5| Step: 9
Training loss: 1.7289799815442661
Validation loss: 2.4338164945821656

Epoch: 5| Step: 10
Training loss: 1.9668732432262719
Validation loss: 2.371897683859361

Epoch: 394| Step: 0
Training loss: 1.5644147203853582
Validation loss: 2.4299383752411474

Epoch: 5| Step: 1
Training loss: 2.023607165907964
Validation loss: 2.3720457056102164

Epoch: 5| Step: 2
Training loss: 1.5625420373983814
Validation loss: 2.3971702726126805

Epoch: 5| Step: 3
Training loss: 1.8105192871625593
Validation loss: 2.40107415859546

Epoch: 5| Step: 4
Training loss: 1.9309286844052613
Validation loss: 2.4100910432632183

Epoch: 5| Step: 5
Training loss: 1.5729055677952877
Validation loss: 2.371375974444771

Epoch: 5| Step: 6
Training loss: 2.4205517507157466
Validation loss: 2.4324352737329358

Epoch: 5| Step: 7
Training loss: 2.152908168111744
Validation loss: 2.3466257305550715

Epoch: 5| Step: 8
Training loss: 1.3050362583399628
Validation loss: 2.3398179249315243

Epoch: 5| Step: 9
Training loss: 1.6753307528391794
Validation loss: 2.4028503561438175

Epoch: 5| Step: 10
Training loss: 1.7933655675782392
Validation loss: 2.3597748663468163

Epoch: 395| Step: 0
Training loss: 1.9034580358995419
Validation loss: 2.4637583389499467

Epoch: 5| Step: 1
Training loss: 1.3785498053014684
Validation loss: 2.4379657477089323

Epoch: 5| Step: 2
Training loss: 1.5042976167410045
Validation loss: 2.4685403608413092

Epoch: 5| Step: 3
Training loss: 2.4067957866018754
Validation loss: 2.3845655351581767

Epoch: 5| Step: 4
Training loss: 2.2404827588845415
Validation loss: 2.438248951808248

Epoch: 5| Step: 5
Training loss: 1.6855031667547768
Validation loss: 2.3917560918976655

Epoch: 5| Step: 6
Training loss: 1.4837311000632567
Validation loss: 2.4547517366530958

Epoch: 5| Step: 7
Training loss: 1.819781311855833
Validation loss: 2.424908687596422

Epoch: 5| Step: 8
Training loss: 1.7252943810532582
Validation loss: 2.411458160401093

Epoch: 5| Step: 9
Training loss: 1.4422094076854635
Validation loss: 2.442906462162716

Epoch: 5| Step: 10
Training loss: 1.6971786002619564
Validation loss: 2.4271055003395077

Epoch: 396| Step: 0
Training loss: 1.8535221208271646
Validation loss: 2.3876786133667287

Epoch: 5| Step: 1
Training loss: 2.0364475363780943
Validation loss: 2.4225106835737953

Epoch: 5| Step: 2
Training loss: 1.2361225361004349
Validation loss: 2.370795095624741

Epoch: 5| Step: 3
Training loss: 1.5995384265783008
Validation loss: 2.4351391619660006

Epoch: 5| Step: 4
Training loss: 1.5624098179541441
Validation loss: 2.4255780372089903

Epoch: 5| Step: 5
Training loss: 1.623799761097037
Validation loss: 2.4019790939574013

Epoch: 5| Step: 6
Training loss: 1.839955903540758
Validation loss: 2.4417838554170332

Epoch: 5| Step: 7
Training loss: 2.4719153283997386
Validation loss: 2.482994798793802

Epoch: 5| Step: 8
Training loss: 1.781138834914368
Validation loss: 2.3694160774104804

Epoch: 5| Step: 9
Training loss: 1.9775367115148061
Validation loss: 2.434372220614419

Epoch: 5| Step: 10
Training loss: 2.0557842156096786
Validation loss: 2.4542907553384175

Epoch: 397| Step: 0
Training loss: 1.688556340518788
Validation loss: 2.4177631267749113

Epoch: 5| Step: 1
Training loss: 2.199505477291432
Validation loss: 2.379039159966036

Epoch: 5| Step: 2
Training loss: 1.630020016974425
Validation loss: 2.3598779779083263

Epoch: 5| Step: 3
Training loss: 1.6242584590635814
Validation loss: 2.4044812851808954

Epoch: 5| Step: 4
Training loss: 1.9215481487934967
Validation loss: 2.386263589040722

Epoch: 5| Step: 5
Training loss: 1.5059414654434344
Validation loss: 2.417160434230523

Epoch: 5| Step: 6
Training loss: 2.049184413655695
Validation loss: 2.3990311500700705

Epoch: 5| Step: 7
Training loss: 1.6802051544947705
Validation loss: 2.3455181111192664

Epoch: 5| Step: 8
Training loss: 1.5491007195783602
Validation loss: 2.3193228503097094

Epoch: 5| Step: 9
Training loss: 2.322354635035916
Validation loss: 2.4305470393120037

Epoch: 5| Step: 10
Training loss: 2.2925443760228363
Validation loss: 2.3844460081890926

Epoch: 398| Step: 0
Training loss: 1.4825900941076047
Validation loss: 2.3239609497189138

Epoch: 5| Step: 1
Training loss: 2.177919826394589
Validation loss: 2.3668125347967686

Epoch: 5| Step: 2
Training loss: 1.2187809573423296
Validation loss: 2.332473025690531

Epoch: 5| Step: 3
Training loss: 2.3402283723359734
Validation loss: 2.372605894386646

Epoch: 5| Step: 4
Training loss: 1.7880638700380844
Validation loss: 2.4244041339178746

Epoch: 5| Step: 5
Training loss: 1.056756483907777
Validation loss: 2.329181982610789

Epoch: 5| Step: 6
Training loss: 1.988424359700383
Validation loss: 2.3700504432589793

Epoch: 5| Step: 7
Training loss: 1.8081586738770998
Validation loss: 2.37227269794336

Epoch: 5| Step: 8
Training loss: 2.2755531351234723
Validation loss: 2.3758202325403013

Epoch: 5| Step: 9
Training loss: 1.9610310566381879
Validation loss: 2.488190721268248

Epoch: 5| Step: 10
Training loss: 1.8444866713065295
Validation loss: 2.483419544050161

Epoch: 399| Step: 0
Training loss: 1.4957266972323924
Validation loss: 2.451637763532573

Epoch: 5| Step: 1
Training loss: 1.8094828914435417
Validation loss: 2.4038104803721363

Epoch: 5| Step: 2
Training loss: 1.4018643550664232
Validation loss: 2.380610403883274

Epoch: 5| Step: 3
Training loss: 1.4392577495515406
Validation loss: 2.3781760243878916

Epoch: 5| Step: 4
Training loss: 1.7965420621836463
Validation loss: 2.384945641090766

Epoch: 5| Step: 5
Training loss: 2.3425442455106995
Validation loss: 2.355014380146432

Epoch: 5| Step: 6
Training loss: 1.9700171616092363
Validation loss: 2.339979769411816

Epoch: 5| Step: 7
Training loss: 1.470129136621925
Validation loss: 2.422480473302258

Epoch: 5| Step: 8
Training loss: 2.644154734552028
Validation loss: 2.361806148154419

Epoch: 5| Step: 9
Training loss: 1.697085319397374
Validation loss: 2.4258428899372224

Epoch: 5| Step: 10
Training loss: 1.467871301653651
Validation loss: 2.390636569799482

Epoch: 400| Step: 0
Training loss: 1.8956656608912026
Validation loss: 2.3964894600541564

Epoch: 5| Step: 1
Training loss: 1.6408512504429895
Validation loss: 2.3855612406911186

Epoch: 5| Step: 2
Training loss: 1.476500010303429
Validation loss: 2.345309670903174

Epoch: 5| Step: 3
Training loss: 1.5341782888579716
Validation loss: 2.4217806551284617

Epoch: 5| Step: 4
Training loss: 2.6649599772985386
Validation loss: 2.4023652293274402

Epoch: 5| Step: 5
Training loss: 1.4763172087200431
Validation loss: 2.4105541417825127

Epoch: 5| Step: 6
Training loss: 1.7512029872685828
Validation loss: 2.5026288311049276

Epoch: 5| Step: 7
Training loss: 1.4667799703586466
Validation loss: 2.4102658993269697

Epoch: 5| Step: 8
Training loss: 2.3101752684516335
Validation loss: 2.460297949929099

Epoch: 5| Step: 9
Training loss: 1.3062565214733524
Validation loss: 2.346050627460133

Epoch: 5| Step: 10
Training loss: 1.959144654187509
Validation loss: 2.497679372679911

Epoch: 401| Step: 0
Training loss: 1.531267204966521
Validation loss: 2.450425784924831

Epoch: 5| Step: 1
Training loss: 1.6405185483275146
Validation loss: 2.35574993855796

Epoch: 5| Step: 2
Training loss: 2.167440594097765
Validation loss: 2.434348711066696

Epoch: 5| Step: 3
Training loss: 1.3083676726497877
Validation loss: 2.384257784743419

Epoch: 5| Step: 4
Training loss: 2.021044166289972
Validation loss: 2.4598266753551634

Epoch: 5| Step: 5
Training loss: 1.678181456569857
Validation loss: 2.4308140805796463

Epoch: 5| Step: 6
Training loss: 1.382892714075862
Validation loss: 2.5241501385831424

Epoch: 5| Step: 7
Training loss: 1.542184364756264
Validation loss: 2.4000851355427626

Epoch: 5| Step: 8
Training loss: 2.3329044924340754
Validation loss: 2.473571760267235

Epoch: 5| Step: 9
Training loss: 1.7258654261757487
Validation loss: 2.3965300941005814

Epoch: 5| Step: 10
Training loss: 2.1032222730975705
Validation loss: 2.365741451728096

Epoch: 402| Step: 0
Training loss: 2.407749253914652
Validation loss: 2.451100297860117

Epoch: 5| Step: 1
Training loss: 1.7640120979724636
Validation loss: 2.392095895185976

Epoch: 5| Step: 2
Training loss: 1.683589289188007
Validation loss: 2.3620630945754386

Epoch: 5| Step: 3
Training loss: 1.8369694832731454
Validation loss: 2.4252517029987404

Epoch: 5| Step: 4
Training loss: 1.7475748970015228
Validation loss: 2.363287974542705

Epoch: 5| Step: 5
Training loss: 1.7926820347076267
Validation loss: 2.3741870367393125

Epoch: 5| Step: 6
Training loss: 1.8578379071858855
Validation loss: 2.4089752136698084

Epoch: 5| Step: 7
Training loss: 1.7919712990523027
Validation loss: 2.3608887061182102

Epoch: 5| Step: 8
Training loss: 1.9770163516351018
Validation loss: 2.3743234538649394

Epoch: 5| Step: 9
Training loss: 1.463478693393534
Validation loss: 2.3297264260657347

Epoch: 5| Step: 10
Training loss: 1.0774386335807646
Validation loss: 2.3273342639946626

Epoch: 403| Step: 0
Training loss: 1.5455021787126402
Validation loss: 2.426243027421683

Epoch: 5| Step: 1
Training loss: 1.8798281495705198
Validation loss: 2.322606366239001

Epoch: 5| Step: 2
Training loss: 1.4446022556775844
Validation loss: 2.3601755588963624

Epoch: 5| Step: 3
Training loss: 2.374669302955862
Validation loss: 2.424958305182275

Epoch: 5| Step: 4
Training loss: 1.6386789314927401
Validation loss: 2.4105940537974546

Epoch: 5| Step: 5
Training loss: 1.4022653286824291
Validation loss: 2.4046727303355317

Epoch: 5| Step: 6
Training loss: 1.980685431009005
Validation loss: 2.326737174044047

Epoch: 5| Step: 7
Training loss: 1.7688162666551084
Validation loss: 2.3537009828836775

Epoch: 5| Step: 8
Training loss: 1.8671488099498965
Validation loss: 2.3349951237224915

Epoch: 5| Step: 9
Training loss: 1.4790801528918536
Validation loss: 2.3677688486377733

Epoch: 5| Step: 10
Training loss: 2.4762436333564355
Validation loss: 2.3887702212566544

Epoch: 404| Step: 0
Training loss: 1.907804449440906
Validation loss: 2.411192797215027

Epoch: 5| Step: 1
Training loss: 1.5154254428014
Validation loss: 2.3648163163581764

Epoch: 5| Step: 2
Training loss: 1.161628482597875
Validation loss: 2.366081110008499

Epoch: 5| Step: 3
Training loss: 2.614207743584551
Validation loss: 2.4054604801097277

Epoch: 5| Step: 4
Training loss: 1.590308119231307
Validation loss: 2.417503146044294

Epoch: 5| Step: 5
Training loss: 1.6821136695382135
Validation loss: 2.3583329128310084

Epoch: 5| Step: 6
Training loss: 1.49504614423901
Validation loss: 2.378559186308821

Epoch: 5| Step: 7
Training loss: 1.9573538204094538
Validation loss: 2.407663744799562

Epoch: 5| Step: 8
Training loss: 2.1408833814180612
Validation loss: 2.5089877928250073

Epoch: 5| Step: 9
Training loss: 1.7482762703009394
Validation loss: 2.3836831511260765

Epoch: 5| Step: 10
Training loss: 1.4896175762944484
Validation loss: 2.483474241037288

Epoch: 405| Step: 0
Training loss: 1.7931361566982973
Validation loss: 2.3346003580386716

Epoch: 5| Step: 1
Training loss: 1.8513035331574084
Validation loss: 2.3319951415678237

Epoch: 5| Step: 2
Training loss: 1.8842824682288117
Validation loss: 2.429547809190703

Epoch: 5| Step: 3
Training loss: 1.6355327961827995
Validation loss: 2.408871887904564

Epoch: 5| Step: 4
Training loss: 2.023340406997273
Validation loss: 2.3806157344518195

Epoch: 5| Step: 5
Training loss: 1.3828214655871078
Validation loss: 2.362361570158043

Epoch: 5| Step: 6
Training loss: 1.803121771057517
Validation loss: 2.401408739311842

Epoch: 5| Step: 7
Training loss: 1.4556228334993035
Validation loss: 2.381078898054032

Epoch: 5| Step: 8
Training loss: 1.8356393125532628
Validation loss: 2.3197726718347735

Epoch: 5| Step: 9
Training loss: 1.5900531602765655
Validation loss: 2.341489129913614

Epoch: 5| Step: 10
Training loss: 2.137879999302687
Validation loss: 2.3278422575217825

Epoch: 406| Step: 0
Training loss: 1.7503297358901924
Validation loss: 2.4120911911259957

Epoch: 5| Step: 1
Training loss: 2.1822470673318404
Validation loss: 2.3289990455067784

Epoch: 5| Step: 2
Training loss: 1.7946765221404983
Validation loss: 2.3703947943871317

Epoch: 5| Step: 3
Training loss: 1.7006692943251132
Validation loss: 2.374254195399172

Epoch: 5| Step: 4
Training loss: 1.7089167815873865
Validation loss: 2.5132090266896734

Epoch: 5| Step: 5
Training loss: 1.7710184411930951
Validation loss: 2.418057031855567

Epoch: 5| Step: 6
Training loss: 1.9281906314604453
Validation loss: 2.4668999907121645

Epoch: 5| Step: 7
Training loss: 1.8183314467763279
Validation loss: 2.430753924063038

Epoch: 5| Step: 8
Training loss: 1.5755971170248446
Validation loss: 2.3705647185466576

Epoch: 5| Step: 9
Training loss: 1.9568905960675005
Validation loss: 2.438556422230522

Epoch: 5| Step: 10
Training loss: 1.9395032801294285
Validation loss: 2.365206437714662

Epoch: 407| Step: 0
Training loss: 2.624658471551138
Validation loss: 2.467810532393075

Epoch: 5| Step: 1
Training loss: 1.5461445634769841
Validation loss: 2.4227865228514887

Epoch: 5| Step: 2
Training loss: 1.503491312228323
Validation loss: 2.3634075182928886

Epoch: 5| Step: 3
Training loss: 1.1531160514505003
Validation loss: 2.3795880127573636

Epoch: 5| Step: 4
Training loss: 1.8062995877438477
Validation loss: 2.466184408378631

Epoch: 5| Step: 5
Training loss: 2.129937886151788
Validation loss: 2.3305969967091147

Epoch: 5| Step: 6
Training loss: 1.5034421526706645
Validation loss: 2.437296589372306

Epoch: 5| Step: 7
Training loss: 1.7395203706535958
Validation loss: 2.3379115472980456

Epoch: 5| Step: 8
Training loss: 1.7527812246714274
Validation loss: 2.352337086981102

Epoch: 5| Step: 9
Training loss: 1.6541538289274214
Validation loss: 2.3930773370154044

Epoch: 5| Step: 10
Training loss: 1.683599343699923
Validation loss: 2.379715737366853

Epoch: 408| Step: 0
Training loss: 1.7065998291671813
Validation loss: 2.39410956506474

Epoch: 5| Step: 1
Training loss: 1.7838182506054918
Validation loss: 2.4581081623746925

Epoch: 5| Step: 2
Training loss: 1.7756830862145578
Validation loss: 2.328401375026226

Epoch: 5| Step: 3
Training loss: 2.403833240767788
Validation loss: 2.3180987112404687

Epoch: 5| Step: 4
Training loss: 1.6529033606054324
Validation loss: 2.4443778097772584

Epoch: 5| Step: 5
Training loss: 1.7743588377568198
Validation loss: 2.416781546507544

Epoch: 5| Step: 6
Training loss: 1.7121640342222555
Validation loss: 2.3629314204704523

Epoch: 5| Step: 7
Training loss: 1.5248034491276834
Validation loss: 2.350970893355936

Epoch: 5| Step: 8
Training loss: 1.5628804315922507
Validation loss: 2.4132212270688225

Epoch: 5| Step: 9
Training loss: 1.8288028471084352
Validation loss: 2.3727919412877965

Epoch: 5| Step: 10
Training loss: 1.8085924317456048
Validation loss: 2.3525402405016225

Epoch: 409| Step: 0
Training loss: 1.954268403106079
Validation loss: 2.4111451706407836

Epoch: 5| Step: 1
Training loss: 2.259364033905895
Validation loss: 2.3288855072055537

Epoch: 5| Step: 2
Training loss: 1.3146580710629798
Validation loss: 2.31553820481882

Epoch: 5| Step: 3
Training loss: 1.8583988223774561
Validation loss: 2.3480444588484484

Epoch: 5| Step: 4
Training loss: 1.2173468019106681
Validation loss: 2.371625067508243

Epoch: 5| Step: 5
Training loss: 1.9808521990532304
Validation loss: 2.338423444879097

Epoch: 5| Step: 6
Training loss: 1.8794729286308374
Validation loss: 2.421319330029997

Epoch: 5| Step: 7
Training loss: 1.3109553193801118
Validation loss: 2.389512070774784

Epoch: 5| Step: 8
Training loss: 1.8602759478563526
Validation loss: 2.3798657806247676

Epoch: 5| Step: 9
Training loss: 2.0081174151375003
Validation loss: 2.3834153032681615

Epoch: 5| Step: 10
Training loss: 1.6692297142387877
Validation loss: 2.448889020100635

Epoch: 410| Step: 0
Training loss: 2.1102381317849783
Validation loss: 2.395598712434888

Epoch: 5| Step: 1
Training loss: 1.828745875116
Validation loss: 2.4286889807783973

Epoch: 5| Step: 2
Training loss: 1.6591991582831562
Validation loss: 2.403650871062441

Epoch: 5| Step: 3
Training loss: 1.6712179586324871
Validation loss: 2.426731957890685

Epoch: 5| Step: 4
Training loss: 1.4849036630535344
Validation loss: 2.3584745982098374

Epoch: 5| Step: 5
Training loss: 1.935557406769247
Validation loss: 2.357163030533358

Epoch: 5| Step: 6
Training loss: 1.785513476933808
Validation loss: 2.388062014406803

Epoch: 5| Step: 7
Training loss: 1.7141579058096732
Validation loss: 2.4484724040152366

Epoch: 5| Step: 8
Training loss: 1.9790756472354636
Validation loss: 2.472826658174295

Epoch: 5| Step: 9
Training loss: 2.0195218054663107
Validation loss: 2.436519730696819

Epoch: 5| Step: 10
Training loss: 1.6765814873437
Validation loss: 2.443240605819288

Epoch: 411| Step: 0
Training loss: 1.8173077058927964
Validation loss: 2.4236215624368596

Epoch: 5| Step: 1
Training loss: 1.7051850904753834
Validation loss: 2.3951415237948566

Epoch: 5| Step: 2
Training loss: 1.8881101039082946
Validation loss: 2.40227828318035

Epoch: 5| Step: 3
Training loss: 1.2226879859193678
Validation loss: 2.387749463357782

Epoch: 5| Step: 4
Training loss: 1.819455513989244
Validation loss: 2.3558351495717087

Epoch: 5| Step: 5
Training loss: 1.5088864785753968
Validation loss: 2.393565775087232

Epoch: 5| Step: 6
Training loss: 1.3453214461220768
Validation loss: 2.4068674979350466

Epoch: 5| Step: 7
Training loss: 2.370437757568442
Validation loss: 2.3777479014124823

Epoch: 5| Step: 8
Training loss: 2.086542506114308
Validation loss: 2.4378439400558167

Epoch: 5| Step: 9
Training loss: 1.3916902212711748
Validation loss: 2.4330738026852945

Epoch: 5| Step: 10
Training loss: 1.6524123590172
Validation loss: 2.396967925167435

Epoch: 412| Step: 0
Training loss: 1.938114191964382
Validation loss: 2.4022261225191204

Epoch: 5| Step: 1
Training loss: 2.17960207098353
Validation loss: 2.384164701328515

Epoch: 5| Step: 2
Training loss: 1.610560452785432
Validation loss: 2.431321404702319

Epoch: 5| Step: 3
Training loss: 2.2537090671437987
Validation loss: 2.4567308356206863

Epoch: 5| Step: 4
Training loss: 1.4732210002267254
Validation loss: 2.4197098468454654

Epoch: 5| Step: 5
Training loss: 1.5552367960460274
Validation loss: 2.3947779731048717

Epoch: 5| Step: 6
Training loss: 1.6792335074147122
Validation loss: 2.3851098304212304

Epoch: 5| Step: 7
Training loss: 1.8127430719956867
Validation loss: 2.457412636131332

Epoch: 5| Step: 8
Training loss: 1.5561573996819342
Validation loss: 2.38261713430371

Epoch: 5| Step: 9
Training loss: 1.4917708209595184
Validation loss: 2.4333369566749545

Epoch: 5| Step: 10
Training loss: 1.739164800796763
Validation loss: 2.4829892579876645

Epoch: 413| Step: 0
Training loss: 2.1446359744323953
Validation loss: 2.380823961887764

Epoch: 5| Step: 1
Training loss: 1.6027141617186715
Validation loss: 2.4195699699011617

Epoch: 5| Step: 2
Training loss: 2.1513254072415493
Validation loss: 2.369840248003901

Epoch: 5| Step: 3
Training loss: 1.350009753933744
Validation loss: 2.3913153956345847

Epoch: 5| Step: 4
Training loss: 1.538781929583508
Validation loss: 2.45081388471324

Epoch: 5| Step: 5
Training loss: 1.552480386557902
Validation loss: 2.367546354060219

Epoch: 5| Step: 6
Training loss: 1.7639812819078162
Validation loss: 2.394952871392558

Epoch: 5| Step: 7
Training loss: 1.444234415010842
Validation loss: 2.4225121937070924

Epoch: 5| Step: 8
Training loss: 2.0427287965560423
Validation loss: 2.386801474656661

Epoch: 5| Step: 9
Training loss: 1.7488606695095588
Validation loss: 2.4329152243479504

Epoch: 5| Step: 10
Training loss: 1.7682324626219588
Validation loss: 2.397472956569034

Epoch: 414| Step: 0
Training loss: 1.5226357722385588
Validation loss: 2.382930930866139

Epoch: 5| Step: 1
Training loss: 2.1721391037011504
Validation loss: 2.398826225311229

Epoch: 5| Step: 2
Training loss: 1.648299658919604
Validation loss: 2.3829788308648214

Epoch: 5| Step: 3
Training loss: 1.7805412622527097
Validation loss: 2.3486278808902186

Epoch: 5| Step: 4
Training loss: 2.017029383909163
Validation loss: 2.336711046905289

Epoch: 5| Step: 5
Training loss: 2.061441670164588
Validation loss: 2.3860062521080616

Epoch: 5| Step: 6
Training loss: 1.547705687378861
Validation loss: 2.390566411816179

Epoch: 5| Step: 7
Training loss: 1.7865267444853985
Validation loss: 2.382811151911292

Epoch: 5| Step: 8
Training loss: 1.9458260834890355
Validation loss: 2.4236580595500383

Epoch: 5| Step: 9
Training loss: 1.9012326985010244
Validation loss: 2.3412304817909777

Epoch: 5| Step: 10
Training loss: 1.1622068732899176
Validation loss: 2.38342647674534

Epoch: 415| Step: 0
Training loss: 1.4488776697577361
Validation loss: 2.399828856614552

Epoch: 5| Step: 1
Training loss: 1.5669586653525165
Validation loss: 2.419957136533749

Epoch: 5| Step: 2
Training loss: 1.9322378008824213
Validation loss: 2.3834332036094015

Epoch: 5| Step: 3
Training loss: 2.173473949661504
Validation loss: 2.3677154074749174

Epoch: 5| Step: 4
Training loss: 2.2710236519203817
Validation loss: 2.3601687369596553

Epoch: 5| Step: 5
Training loss: 1.4988449735989418
Validation loss: 2.302403369626316

Epoch: 5| Step: 6
Training loss: 1.6890972490291543
Validation loss: 2.2635705670691517

Epoch: 5| Step: 7
Training loss: 1.513490648803455
Validation loss: 2.390289596781164

Epoch: 5| Step: 8
Training loss: 1.1959824024998167
Validation loss: 2.480340104129682

Epoch: 5| Step: 9
Training loss: 1.6848048127090243
Validation loss: 2.337175300932812

Epoch: 5| Step: 10
Training loss: 1.7330602525515375
Validation loss: 2.398224420098688

Epoch: 416| Step: 0
Training loss: 2.299560637595052
Validation loss: 2.4897813533319724

Epoch: 5| Step: 1
Training loss: 1.2475251493804813
Validation loss: 2.39210785547487

Epoch: 5| Step: 2
Training loss: 1.8008663794530362
Validation loss: 2.378531502535679

Epoch: 5| Step: 3
Training loss: 1.3768752055745916
Validation loss: 2.416919285219719

Epoch: 5| Step: 4
Training loss: 1.9433611539132876
Validation loss: 2.3514060640001495

Epoch: 5| Step: 5
Training loss: 1.9428045813178367
Validation loss: 2.351091011587203

Epoch: 5| Step: 6
Training loss: 1.2451321230721863
Validation loss: 2.438060884229786

Epoch: 5| Step: 7
Training loss: 1.5895952410104026
Validation loss: 2.3913295414633597

Epoch: 5| Step: 8
Training loss: 1.585255368115201
Validation loss: 2.3974169198185242

Epoch: 5| Step: 9
Training loss: 2.002135328979866
Validation loss: 2.3465642766829014

Epoch: 5| Step: 10
Training loss: 1.8670663195754764
Validation loss: 2.413357033815718

Epoch: 417| Step: 0
Training loss: 1.715537380628442
Validation loss: 2.3589375712546388

Epoch: 5| Step: 1
Training loss: 1.6621042827523713
Validation loss: 2.4045414105063165

Epoch: 5| Step: 2
Training loss: 2.434518115007778
Validation loss: 2.387789679251492

Epoch: 5| Step: 3
Training loss: 1.854077204857024
Validation loss: 2.434262695611752

Epoch: 5| Step: 4
Training loss: 2.2047842284354084
Validation loss: 2.39596951397708

Epoch: 5| Step: 5
Training loss: 1.8271903232521987
Validation loss: 2.3716112143773374

Epoch: 5| Step: 6
Training loss: 1.659733042910039
Validation loss: 2.3552944626530072

Epoch: 5| Step: 7
Training loss: 1.869845808373427
Validation loss: 2.352093508918274

Epoch: 5| Step: 8
Training loss: 1.077948790814852
Validation loss: 2.3949730511423253

Epoch: 5| Step: 9
Training loss: 1.387500596261111
Validation loss: 2.3824081048155117

Epoch: 5| Step: 10
Training loss: 1.698160688343258
Validation loss: 2.35567510071686

Epoch: 418| Step: 0
Training loss: 2.031354226592813
Validation loss: 2.357244395978188

Epoch: 5| Step: 1
Training loss: 1.9362257181791283
Validation loss: 2.4222794432252157

Epoch: 5| Step: 2
Training loss: 1.749561391088562
Validation loss: 2.3609621831825858

Epoch: 5| Step: 3
Training loss: 1.7333086189317628
Validation loss: 2.4577459096168686

Epoch: 5| Step: 4
Training loss: 1.2387884406968521
Validation loss: 2.383379921679029

Epoch: 5| Step: 5
Training loss: 1.676858409070132
Validation loss: 2.3008220489387226

Epoch: 5| Step: 6
Training loss: 1.7294934281916075
Validation loss: 2.282434533279737

Epoch: 5| Step: 7
Training loss: 2.3643784175145264
Validation loss: 2.285965629946627

Epoch: 5| Step: 8
Training loss: 1.2957560296423445
Validation loss: 2.424376376718012

Epoch: 5| Step: 9
Training loss: 1.6475913963378477
Validation loss: 2.3782766554927726

Epoch: 5| Step: 10
Training loss: 1.8096305890654107
Validation loss: 2.3599319110410693

Epoch: 419| Step: 0
Training loss: 1.420142239310435
Validation loss: 2.315361232824046

Epoch: 5| Step: 1
Training loss: 1.6069697211118548
Validation loss: 2.424198240143073

Epoch: 5| Step: 2
Training loss: 1.655407097295369
Validation loss: 2.3899258341784697

Epoch: 5| Step: 3
Training loss: 1.9177042046425998
Validation loss: 2.363394011293285

Epoch: 5| Step: 4
Training loss: 1.7274436945924057
Validation loss: 2.4126727404122845

Epoch: 5| Step: 5
Training loss: 2.2463873364512748
Validation loss: 2.2838183520747783

Epoch: 5| Step: 6
Training loss: 2.1966059122477852
Validation loss: 2.398746998669459

Epoch: 5| Step: 7
Training loss: 1.1962060518074373
Validation loss: 2.428565379341439

Epoch: 5| Step: 8
Training loss: 1.740867559493092
Validation loss: 2.3508752852972385

Epoch: 5| Step: 9
Training loss: 1.5615690128052426
Validation loss: 2.4023693879369588

Epoch: 5| Step: 10
Training loss: 1.7467939436503341
Validation loss: 2.396237102225221

Epoch: 420| Step: 0
Training loss: 1.5941792078450476
Validation loss: 2.430927520588425

Epoch: 5| Step: 1
Training loss: 1.7385232478362813
Validation loss: 2.3464303969130214

Epoch: 5| Step: 2
Training loss: 1.6480916460442927
Validation loss: 2.333086375016533

Epoch: 5| Step: 3
Training loss: 1.7438802663622273
Validation loss: 2.3646907271539197

Epoch: 5| Step: 4
Training loss: 1.1738365033401337
Validation loss: 2.443808871117344

Epoch: 5| Step: 5
Training loss: 1.6636198646098694
Validation loss: 2.406002003664719

Epoch: 5| Step: 6
Training loss: 2.36899429712217
Validation loss: 2.4211077080348335

Epoch: 5| Step: 7
Training loss: 1.7949441902176495
Validation loss: 2.3865290665548247

Epoch: 5| Step: 8
Training loss: 1.5170726351564634
Validation loss: 2.4102106035545963

Epoch: 5| Step: 9
Training loss: 1.333931381491092
Validation loss: 2.421888474060748

Epoch: 5| Step: 10
Training loss: 2.2640184691723833
Validation loss: 2.4021949090343675

Epoch: 421| Step: 0
Training loss: 1.477371962755507
Validation loss: 2.4087022671729965

Epoch: 5| Step: 1
Training loss: 1.6256498357920872
Validation loss: 2.3695140863115465

Epoch: 5| Step: 2
Training loss: 1.9287511121211427
Validation loss: 2.4324713666916264

Epoch: 5| Step: 3
Training loss: 1.9972321311847534
Validation loss: 2.4795508772492654

Epoch: 5| Step: 4
Training loss: 1.7665716013732136
Validation loss: 2.5103380016211534

Epoch: 5| Step: 5
Training loss: 1.8227418070896657
Validation loss: 2.4038838820482407

Epoch: 5| Step: 6
Training loss: 1.653692538185076
Validation loss: 2.3389009044983795

Epoch: 5| Step: 7
Training loss: 1.1390276135621524
Validation loss: 2.380647828529725

Epoch: 5| Step: 8
Training loss: 1.6597961753355281
Validation loss: 2.4051036626497617

Epoch: 5| Step: 9
Training loss: 2.0626666839754138
Validation loss: 2.390173182833149

Epoch: 5| Step: 10
Training loss: 1.4973278881635248
Validation loss: 2.3893117518081843

Epoch: 422| Step: 0
Training loss: 1.3292712482377709
Validation loss: 2.3422078277137683

Epoch: 5| Step: 1
Training loss: 1.9867406246107617
Validation loss: 2.3872862059492794

Epoch: 5| Step: 2
Training loss: 1.7074703812718193
Validation loss: 2.413979888627115

Epoch: 5| Step: 3
Training loss: 1.6561656426593607
Validation loss: 2.362655563602059

Epoch: 5| Step: 4
Training loss: 1.5157620869412105
Validation loss: 2.35859316366313

Epoch: 5| Step: 5
Training loss: 2.4643416822881905
Validation loss: 2.4041242368152336

Epoch: 5| Step: 6
Training loss: 1.990297625344303
Validation loss: 2.3584434089711683

Epoch: 5| Step: 7
Training loss: 1.8171771638794405
Validation loss: 2.456470412125564

Epoch: 5| Step: 8
Training loss: 1.478946517178508
Validation loss: 2.4202792634330783

Epoch: 5| Step: 9
Training loss: 1.258600639641704
Validation loss: 2.426425364227911

Epoch: 5| Step: 10
Training loss: 1.6599230793285933
Validation loss: 2.3824831262390025

Epoch: 423| Step: 0
Training loss: 1.4890784984261567
Validation loss: 2.3762727844796516

Epoch: 5| Step: 1
Training loss: 1.706614288455164
Validation loss: 2.410862251906457

Epoch: 5| Step: 2
Training loss: 1.2611461556579342
Validation loss: 2.3432790391058096

Epoch: 5| Step: 3
Training loss: 1.8764053164551346
Validation loss: 2.419239090915981

Epoch: 5| Step: 4
Training loss: 1.5358023412305848
Validation loss: 2.3840362746905694

Epoch: 5| Step: 5
Training loss: 1.529222898289585
Validation loss: 2.407165375605653

Epoch: 5| Step: 6
Training loss: 1.8170372307951488
Validation loss: 2.3965429174571393

Epoch: 5| Step: 7
Training loss: 1.8953950466159306
Validation loss: 2.383203833076682

Epoch: 5| Step: 8
Training loss: 2.0948208020759336
Validation loss: 2.3838126781406417

Epoch: 5| Step: 9
Training loss: 1.8031563476799417
Validation loss: 2.3883934471484185

Epoch: 5| Step: 10
Training loss: 2.280251271305539
Validation loss: 2.428442086731883

Epoch: 424| Step: 0
Training loss: 1.367507766269201
Validation loss: 2.438134462395022

Epoch: 5| Step: 1
Training loss: 1.3078865531637884
Validation loss: 2.3586444654138026

Epoch: 5| Step: 2
Training loss: 2.2712122983013012
Validation loss: 2.4145032267524056

Epoch: 5| Step: 3
Training loss: 2.166366287341588
Validation loss: 2.3931149812745316

Epoch: 5| Step: 4
Training loss: 1.6774352121136074
Validation loss: 2.4163650908683576

Epoch: 5| Step: 5
Training loss: 1.8657007403310757
Validation loss: 2.31201980935396

Epoch: 5| Step: 6
Training loss: 1.8272151802305914
Validation loss: 2.367057452600623

Epoch: 5| Step: 7
Training loss: 1.6605394347532754
Validation loss: 2.3584072413078823

Epoch: 5| Step: 8
Training loss: 1.6300584848127113
Validation loss: 2.401643138828692

Epoch: 5| Step: 9
Training loss: 1.3495023163262891
Validation loss: 2.3687003206312043

Epoch: 5| Step: 10
Training loss: 1.7670090913306629
Validation loss: 2.3435728425919415

Epoch: 425| Step: 0
Training loss: 1.6904252447271557
Validation loss: 2.4430322526562502

Epoch: 5| Step: 1
Training loss: 1.9174988087398006
Validation loss: 2.3511524681723928

Epoch: 5| Step: 2
Training loss: 2.424471835006844
Validation loss: 2.373359315324285

Epoch: 5| Step: 3
Training loss: 1.689382068705333
Validation loss: 2.3849037185991966

Epoch: 5| Step: 4
Training loss: 1.6679985526144943
Validation loss: 2.4139120355904633

Epoch: 5| Step: 5
Training loss: 1.6430215679245983
Validation loss: 2.3658096774790196

Epoch: 5| Step: 6
Training loss: 1.968121625134799
Validation loss: 2.3309795297188316

Epoch: 5| Step: 7
Training loss: 1.4668478315622457
Validation loss: 2.5180737126261477

Epoch: 5| Step: 8
Training loss: 1.73718542640646
Validation loss: 2.3707243483004956

Epoch: 5| Step: 9
Training loss: 1.4835924193751437
Validation loss: 2.363541513483654

Epoch: 5| Step: 10
Training loss: 1.3263950075914925
Validation loss: 2.3939990600966654

Epoch: 426| Step: 0
Training loss: 1.7182412521648027
Validation loss: 2.3623674242755697

Epoch: 5| Step: 1
Training loss: 1.3898381782578733
Validation loss: 2.410302799165271

Epoch: 5| Step: 2
Training loss: 1.492543123219698
Validation loss: 2.3925518838909614

Epoch: 5| Step: 3
Training loss: 1.6648791820921256
Validation loss: 2.416379786031188

Epoch: 5| Step: 4
Training loss: 1.6617357347317143
Validation loss: 2.3505669264951634

Epoch: 5| Step: 5
Training loss: 1.6007115778508314
Validation loss: 2.4710196221692606

Epoch: 5| Step: 6
Training loss: 1.7472057513923094
Validation loss: 2.473423080356181

Epoch: 5| Step: 7
Training loss: 1.415270463281726
Validation loss: 2.4029316367339337

Epoch: 5| Step: 8
Training loss: 2.1234540364658026
Validation loss: 2.3936838988304867

Epoch: 5| Step: 9
Training loss: 1.4885085525548896
Validation loss: 2.3694601413715133

Epoch: 5| Step: 10
Training loss: 2.263799945147625
Validation loss: 2.3932290459774923

Epoch: 427| Step: 0
Training loss: 1.8414965290634502
Validation loss: 2.4410706979166457

Epoch: 5| Step: 1
Training loss: 1.8152183668277486
Validation loss: 2.343792887196169

Epoch: 5| Step: 2
Training loss: 1.3953566472672192
Validation loss: 2.432685340796768

Epoch: 5| Step: 3
Training loss: 1.4468847847065964
Validation loss: 2.3572397776574734

Epoch: 5| Step: 4
Training loss: 1.9358636652649803
Validation loss: 2.3879007152776586

Epoch: 5| Step: 5
Training loss: 1.9467039838353806
Validation loss: 2.387033506653636

Epoch: 5| Step: 6
Training loss: 1.8631990362619386
Validation loss: 2.298206142569615

Epoch: 5| Step: 7
Training loss: 1.4210689901131666
Validation loss: 2.4466687214107803

Epoch: 5| Step: 8
Training loss: 1.433151135212572
Validation loss: 2.4108537853329044

Epoch: 5| Step: 9
Training loss: 1.4623005266360931
Validation loss: 2.3978798199781055

Epoch: 5| Step: 10
Training loss: 1.748729244433487
Validation loss: 2.4215672070141543

Epoch: 428| Step: 0
Training loss: 2.315604934914332
Validation loss: 2.4080082521501267

Epoch: 5| Step: 1
Training loss: 1.5472138159017679
Validation loss: 2.302218721130243

Epoch: 5| Step: 2
Training loss: 1.3949526622903097
Validation loss: 2.4025705036590095

Epoch: 5| Step: 3
Training loss: 1.962410180047025
Validation loss: 2.416697263965963

Epoch: 5| Step: 4
Training loss: 1.7046414544786321
Validation loss: 2.389588366850237

Epoch: 5| Step: 5
Training loss: 1.536888019371657
Validation loss: 2.3813047634066766

Epoch: 5| Step: 6
Training loss: 1.651428546363389
Validation loss: 2.411141900093643

Epoch: 5| Step: 7
Training loss: 1.638572207887906
Validation loss: 2.436476182965402

Epoch: 5| Step: 8
Training loss: 1.437507961085292
Validation loss: 2.3935105283607383

Epoch: 5| Step: 9
Training loss: 1.6843767580154105
Validation loss: 2.4000554515899837

Epoch: 5| Step: 10
Training loss: 1.7139991296478876
Validation loss: 2.347752428114295

Epoch: 429| Step: 0
Training loss: 1.6934779916509624
Validation loss: 2.340777670928256

Epoch: 5| Step: 1
Training loss: 1.9099469216446188
Validation loss: 2.408926532238175

Epoch: 5| Step: 2
Training loss: 2.0228409642657095
Validation loss: 2.351257597712067

Epoch: 5| Step: 3
Training loss: 1.7447221049396278
Validation loss: 2.4375198590626823

Epoch: 5| Step: 4
Training loss: 1.4422742922901488
Validation loss: 2.4370130184471397

Epoch: 5| Step: 5
Training loss: 1.3054775655507025
Validation loss: 2.4300521430825324

Epoch: 5| Step: 6
Training loss: 1.5890795021310349
Validation loss: 2.4148344690662844

Epoch: 5| Step: 7
Training loss: 1.9990164007036015
Validation loss: 2.3798344171379924

Epoch: 5| Step: 8
Training loss: 1.5812397801969873
Validation loss: 2.441854102488073

Epoch: 5| Step: 9
Training loss: 1.7902600806977507
Validation loss: 2.3687015411929426

Epoch: 5| Step: 10
Training loss: 1.7992306734154622
Validation loss: 2.422949830248694

Epoch: 430| Step: 0
Training loss: 1.9390119990213142
Validation loss: 2.4682821731642464

Epoch: 5| Step: 1
Training loss: 1.6479278789127576
Validation loss: 2.4181749844125267

Epoch: 5| Step: 2
Training loss: 1.8651870162304172
Validation loss: 2.342178048916382

Epoch: 5| Step: 3
Training loss: 1.3102133222693126
Validation loss: 2.377640202790815

Epoch: 5| Step: 4
Training loss: 1.569642640524083
Validation loss: 2.5126096548584

Epoch: 5| Step: 5
Training loss: 1.2658902114100377
Validation loss: 2.412271111811704

Epoch: 5| Step: 6
Training loss: 1.3854337084111663
Validation loss: 2.406840374100149

Epoch: 5| Step: 7
Training loss: 1.7199191191974146
Validation loss: 2.329288662596669

Epoch: 5| Step: 8
Training loss: 2.154835333673221
Validation loss: 2.3769351014383937

Epoch: 5| Step: 9
Training loss: 1.8785572005359392
Validation loss: 2.3920652718583075

Epoch: 5| Step: 10
Training loss: 1.7551515232329191
Validation loss: 2.39356664049953

Epoch: 431| Step: 0
Training loss: 1.1002904703523768
Validation loss: 2.4361842106132996

Epoch: 5| Step: 1
Training loss: 1.9533596660783301
Validation loss: 2.3965077917265702

Epoch: 5| Step: 2
Training loss: 1.5324546590697201
Validation loss: 2.358800586833341

Epoch: 5| Step: 3
Training loss: 1.6366611370425745
Validation loss: 2.408187297292681

Epoch: 5| Step: 4
Training loss: 1.6698545565058722
Validation loss: 2.361655768401029

Epoch: 5| Step: 5
Training loss: 1.5067246223516453
Validation loss: 2.3815251125027435

Epoch: 5| Step: 6
Training loss: 2.1965798626054904
Validation loss: 2.336927628205557

Epoch: 5| Step: 7
Training loss: 1.2342715642543103
Validation loss: 2.4009221349087544

Epoch: 5| Step: 8
Training loss: 1.7059770554434022
Validation loss: 2.385550538239249

Epoch: 5| Step: 9
Training loss: 1.5625239561151816
Validation loss: 2.389018988001978

Epoch: 5| Step: 10
Training loss: 1.8186315543811562
Validation loss: 2.4159418602605705

Epoch: 432| Step: 0
Training loss: 1.1487883985409115
Validation loss: 2.430905493719145

Epoch: 5| Step: 1
Training loss: 2.0370012293022093
Validation loss: 2.4280087170118443

Epoch: 5| Step: 2
Training loss: 1.7256560556946283
Validation loss: 2.438276603128563

Epoch: 5| Step: 3
Training loss: 1.2300372139023004
Validation loss: 2.3546132273906197

Epoch: 5| Step: 4
Training loss: 2.0953046805671813
Validation loss: 2.3392887016268635

Epoch: 5| Step: 5
Training loss: 1.2737171825490168
Validation loss: 2.358001560229974

Epoch: 5| Step: 6
Training loss: 1.8614295699664043
Validation loss: 2.3618845418638164

Epoch: 5| Step: 7
Training loss: 1.7172352444898786
Validation loss: 2.337409857301098

Epoch: 5| Step: 8
Training loss: 1.6019361106715024
Validation loss: 2.4099293899182936

Epoch: 5| Step: 9
Training loss: 1.5789920955312742
Validation loss: 2.439196700496898

Epoch: 5| Step: 10
Training loss: 1.909460272500342
Validation loss: 2.3920671045105597

Epoch: 433| Step: 0
Training loss: 1.5279883075885894
Validation loss: 2.3446008156577984

Epoch: 5| Step: 1
Training loss: 1.602533855348411
Validation loss: 2.3929755917111453

Epoch: 5| Step: 2
Training loss: 1.7168870713427888
Validation loss: 2.342444573551489

Epoch: 5| Step: 3
Training loss: 1.1406683717607529
Validation loss: 2.4033973867729355

Epoch: 5| Step: 4
Training loss: 1.5165288530693284
Validation loss: 2.3667196995213633

Epoch: 5| Step: 5
Training loss: 2.3485253069535195
Validation loss: 2.3169153715048068

Epoch: 5| Step: 6
Training loss: 1.6100514295905313
Validation loss: 2.39504129944027

Epoch: 5| Step: 7
Training loss: 1.6301686177478816
Validation loss: 2.405886921673488

Epoch: 5| Step: 8
Training loss: 1.7762376634248567
Validation loss: 2.416030881486049

Epoch: 5| Step: 9
Training loss: 1.3058479767306774
Validation loss: 2.383446270063719

Epoch: 5| Step: 10
Training loss: 1.893273067533815
Validation loss: 2.3888653246623677

Epoch: 434| Step: 0
Training loss: 1.5585581075087322
Validation loss: 2.37489691026454

Epoch: 5| Step: 1
Training loss: 1.6142864651684274
Validation loss: 2.339906058563024

Epoch: 5| Step: 2
Training loss: 1.41176448002748
Validation loss: 2.315369931771118

Epoch: 5| Step: 3
Training loss: 2.1974515980325484
Validation loss: 2.4440888319883634

Epoch: 5| Step: 4
Training loss: 1.3860265159189795
Validation loss: 2.413255662294808

Epoch: 5| Step: 5
Training loss: 1.8247163735084968
Validation loss: 2.389153923010324

Epoch: 5| Step: 6
Training loss: 2.004193320728269
Validation loss: 2.3395292411854403

Epoch: 5| Step: 7
Training loss: 1.6280980289150904
Validation loss: 2.4375256467889304

Epoch: 5| Step: 8
Training loss: 1.6841168575606753
Validation loss: 2.369783256017307

Epoch: 5| Step: 9
Training loss: 1.6781521899757295
Validation loss: 2.440158076221641

Epoch: 5| Step: 10
Training loss: 1.4829866843625752
Validation loss: 2.3807818117586663

Epoch: 435| Step: 0
Training loss: 1.3682422601978232
Validation loss: 2.385106568242462

Epoch: 5| Step: 1
Training loss: 1.2583617912426068
Validation loss: 2.3648869233427625

Epoch: 5| Step: 2
Training loss: 1.9445197393583205
Validation loss: 2.4027224593281584

Epoch: 5| Step: 3
Training loss: 1.800421490594001
Validation loss: 2.3239098045485473

Epoch: 5| Step: 4
Training loss: 1.804693841303794
Validation loss: 2.3782486628311603

Epoch: 5| Step: 5
Training loss: 1.5995126399226163
Validation loss: 2.341262889101459

Epoch: 5| Step: 6
Training loss: 1.6863356211241414
Validation loss: 2.3700817480077236

Epoch: 5| Step: 7
Training loss: 1.1407827503386234
Validation loss: 2.3952760673398874

Epoch: 5| Step: 8
Training loss: 2.4698499329729025
Validation loss: 2.3819648718440587

Epoch: 5| Step: 9
Training loss: 1.526214884885943
Validation loss: 2.383127868321353

Epoch: 5| Step: 10
Training loss: 1.387135703573657
Validation loss: 2.3454658577034904

Epoch: 436| Step: 0
Training loss: 1.7361327191173757
Validation loss: 2.4492737083433482

Epoch: 5| Step: 1
Training loss: 1.2360803919390937
Validation loss: 2.3839936555078904

Epoch: 5| Step: 2
Training loss: 1.9034151354089464
Validation loss: 2.481140852850415

Epoch: 5| Step: 3
Training loss: 1.6376150949812056
Validation loss: 2.30932465641516

Epoch: 5| Step: 4
Training loss: 2.054853309352111
Validation loss: 2.3816264879955846

Epoch: 5| Step: 5
Training loss: 1.867038034498112
Validation loss: 2.3813963389737047

Epoch: 5| Step: 6
Training loss: 1.5058266009018577
Validation loss: 2.3662320525107674

Epoch: 5| Step: 7
Training loss: 1.621792709232774
Validation loss: 2.3681367162105142

Epoch: 5| Step: 8
Training loss: 1.664299746512098
Validation loss: 2.3226783568028257

Epoch: 5| Step: 9
Training loss: 1.7156321596645916
Validation loss: 2.354605345745598

Epoch: 5| Step: 10
Training loss: 1.528417575654061
Validation loss: 2.3783446650179028

Epoch: 437| Step: 0
Training loss: 1.6123116375815527
Validation loss: 2.3926076467072686

Epoch: 5| Step: 1
Training loss: 2.1327268702046838
Validation loss: 2.3842523289879423

Epoch: 5| Step: 2
Training loss: 1.5661652871959673
Validation loss: 2.390257099648778

Epoch: 5| Step: 3
Training loss: 1.7653531565739295
Validation loss: 2.4210225246033046

Epoch: 5| Step: 4
Training loss: 1.8464132567627285
Validation loss: 2.4001694855270728

Epoch: 5| Step: 5
Training loss: 1.944620154782604
Validation loss: 2.38193551420853

Epoch: 5| Step: 6
Training loss: 1.6542903895515584
Validation loss: 2.405353042830494

Epoch: 5| Step: 7
Training loss: 1.2696412963121786
Validation loss: 2.4426273565428396

Epoch: 5| Step: 8
Training loss: 1.6398011091630305
Validation loss: 2.3695408081282996

Epoch: 5| Step: 9
Training loss: 1.7400184437442934
Validation loss: 2.3057211383498846

Epoch: 5| Step: 10
Training loss: 1.4629536145327835
Validation loss: 2.410625313795017

Epoch: 438| Step: 0
Training loss: 2.0418875698033143
Validation loss: 2.3820958892143467

Epoch: 5| Step: 1
Training loss: 1.94387880984047
Validation loss: 2.37279361055484

Epoch: 5| Step: 2
Training loss: 1.4757681026650589
Validation loss: 2.3510922688234595

Epoch: 5| Step: 3
Training loss: 1.4119580030760694
Validation loss: 2.392038819349349

Epoch: 5| Step: 4
Training loss: 1.4627067745787046
Validation loss: 2.414389311295786

Epoch: 5| Step: 5
Training loss: 1.6602034977192137
Validation loss: 2.4257799786320673

Epoch: 5| Step: 6
Training loss: 1.5863522142404984
Validation loss: 2.430347085226834

Epoch: 5| Step: 7
Training loss: 1.4216348633930067
Validation loss: 2.32853180163337

Epoch: 5| Step: 8
Training loss: 1.5859705728925284
Validation loss: 2.377683869047292

Epoch: 5| Step: 9
Training loss: 2.2960355093865097
Validation loss: 2.381683786986669

Epoch: 5| Step: 10
Training loss: 1.2122717613049667
Validation loss: 2.428547872886847

Epoch: 439| Step: 0
Training loss: 1.4862977274168645
Validation loss: 2.434513501642942

Epoch: 5| Step: 1
Training loss: 1.3302509122808461
Validation loss: 2.4090903726699335

Epoch: 5| Step: 2
Training loss: 1.563196866085226
Validation loss: 2.292014463849395

Epoch: 5| Step: 3
Training loss: 1.8973104011792197
Validation loss: 2.402897169848947

Epoch: 5| Step: 4
Training loss: 1.76013322011728
Validation loss: 2.3787992148798995

Epoch: 5| Step: 5
Training loss: 1.9023925023029826
Validation loss: 2.3185988323614493

Epoch: 5| Step: 6
Training loss: 1.4343723604597685
Validation loss: 2.4129879108217556

Epoch: 5| Step: 7
Training loss: 1.5049974322376334
Validation loss: 2.3250440555649887

Epoch: 5| Step: 8
Training loss: 2.101542306115223
Validation loss: 2.4503840128569983

Epoch: 5| Step: 9
Training loss: 1.5444007891759903
Validation loss: 2.3762850056550278

Epoch: 5| Step: 10
Training loss: 1.8405200662801486
Validation loss: 2.2743348213982046

Epoch: 440| Step: 0
Training loss: 1.105604776701014
Validation loss: 2.432680495274339

Epoch: 5| Step: 1
Training loss: 1.5503896992460309
Validation loss: 2.4227432816874486

Epoch: 5| Step: 2
Training loss: 1.9658511178814588
Validation loss: 2.3650520857169064

Epoch: 5| Step: 3
Training loss: 2.343854571234878
Validation loss: 2.4368966425743697

Epoch: 5| Step: 4
Training loss: 2.2301376818590386
Validation loss: 2.440670497754288

Epoch: 5| Step: 5
Training loss: 1.2097452508715318
Validation loss: 2.4171259729659176

Epoch: 5| Step: 6
Training loss: 1.239885512419627
Validation loss: 2.422016168529638

Epoch: 5| Step: 7
Training loss: 1.735207778735772
Validation loss: 2.498412907234443

Epoch: 5| Step: 8
Training loss: 1.527252038412003
Validation loss: 2.308806930673232

Epoch: 5| Step: 9
Training loss: 1.8217612464948163
Validation loss: 2.463200735455666

Epoch: 5| Step: 10
Training loss: 1.190004668747535
Validation loss: 2.3892751485032893

Epoch: 441| Step: 0
Training loss: 1.5275184941147752
Validation loss: 2.397173741888225

Epoch: 5| Step: 1
Training loss: 2.17353131923396
Validation loss: 2.2878400951794484

Epoch: 5| Step: 2
Training loss: 1.5693919961693386
Validation loss: 2.4267086730301277

Epoch: 5| Step: 3
Training loss: 2.0308168389557513
Validation loss: 2.409641179120598

Epoch: 5| Step: 4
Training loss: 1.8270349105397672
Validation loss: 2.3956504705623582

Epoch: 5| Step: 5
Training loss: 1.2889136488544086
Validation loss: 2.370674129281843

Epoch: 5| Step: 6
Training loss: 1.4192095915387466
Validation loss: 2.4061978354071494

Epoch: 5| Step: 7
Training loss: 1.9614501526172905
Validation loss: 2.397446244533978

Epoch: 5| Step: 8
Training loss: 1.2491460744438425
Validation loss: 2.366004046147413

Epoch: 5| Step: 9
Training loss: 1.8646574236536506
Validation loss: 2.3945265456771736

Epoch: 5| Step: 10
Training loss: 1.585005011565652
Validation loss: 2.461033778236934

Epoch: 442| Step: 0
Training loss: 1.4568823362449685
Validation loss: 2.328018493264276

Epoch: 5| Step: 1
Training loss: 1.279766153938953
Validation loss: 2.4453202287172493

Epoch: 5| Step: 2
Training loss: 1.5895440196337418
Validation loss: 2.4199709676863677

Epoch: 5| Step: 3
Training loss: 1.6566315697240581
Validation loss: 2.3744741396287137

Epoch: 5| Step: 4
Training loss: 1.212796464050795
Validation loss: 2.456286523255134

Epoch: 5| Step: 5
Training loss: 2.196905895032192
Validation loss: 2.399524765749328

Epoch: 5| Step: 6
Training loss: 1.4922630730310524
Validation loss: 2.306848778538819

Epoch: 5| Step: 7
Training loss: 1.8758494042626488
Validation loss: 2.277564356993574

Epoch: 5| Step: 8
Training loss: 1.387491403157863
Validation loss: 2.4301334843985685

Epoch: 5| Step: 9
Training loss: 1.8719362022826151
Validation loss: 2.3621240513453654

Epoch: 5| Step: 10
Training loss: 1.8733189994743298
Validation loss: 2.4183439735978025

Epoch: 443| Step: 0
Training loss: 1.8518767915035341
Validation loss: 2.4581711275687343

Epoch: 5| Step: 1
Training loss: 1.58551388048576
Validation loss: 2.416887207137892

Epoch: 5| Step: 2
Training loss: 1.9280829921208307
Validation loss: 2.3264375550439675

Epoch: 5| Step: 3
Training loss: 2.0275770578663437
Validation loss: 2.3144916625886225

Epoch: 5| Step: 4
Training loss: 2.4196657995122686
Validation loss: 2.371850285872922

Epoch: 5| Step: 5
Training loss: 1.6128155865239657
Validation loss: 2.3292891972183822

Epoch: 5| Step: 6
Training loss: 1.3291789192822825
Validation loss: 2.370811369768049

Epoch: 5| Step: 7
Training loss: 1.5780193935599829
Validation loss: 2.3978128894882738

Epoch: 5| Step: 8
Training loss: 1.6226779780175171
Validation loss: 2.376792316155765

Epoch: 5| Step: 9
Training loss: 1.0312161873562753
Validation loss: 2.3902976658945434

Epoch: 5| Step: 10
Training loss: 1.1655197750592123
Validation loss: 2.3765106394644793

Epoch: 444| Step: 0
Training loss: 1.9852798681641197
Validation loss: 2.3844842166159763

Epoch: 5| Step: 1
Training loss: 1.3190753264301758
Validation loss: 2.410366243655805

Epoch: 5| Step: 2
Training loss: 1.6473549275641832
Validation loss: 2.340787513550321

Epoch: 5| Step: 3
Training loss: 1.4863702314430425
Validation loss: 2.3147325810782524

Epoch: 5| Step: 4
Training loss: 1.669181793583649
Validation loss: 2.3667412519364976

Epoch: 5| Step: 5
Training loss: 1.496777729226764
Validation loss: 2.3288758366443894

Epoch: 5| Step: 6
Training loss: 1.6320387909944631
Validation loss: 2.4468154070803867

Epoch: 5| Step: 7
Training loss: 2.2510799359397975
Validation loss: 2.4490711102043186

Epoch: 5| Step: 8
Training loss: 1.5873880001418634
Validation loss: 2.4172886351121265

Epoch: 5| Step: 9
Training loss: 1.1953011805179152
Validation loss: 2.46166779255378

Epoch: 5| Step: 10
Training loss: 1.6772702588779569
Validation loss: 2.4050284924824545

Epoch: 445| Step: 0
Training loss: 1.5567948517446675
Validation loss: 2.3689088446553535

Epoch: 5| Step: 1
Training loss: 1.7680188720179215
Validation loss: 2.359317171164597

Epoch: 5| Step: 2
Training loss: 1.310794266888371
Validation loss: 2.3835603796089617

Epoch: 5| Step: 3
Training loss: 1.8464466999004114
Validation loss: 2.3756188987884976

Epoch: 5| Step: 4
Training loss: 1.7317948953969406
Validation loss: 2.4138534683189703

Epoch: 5| Step: 5
Training loss: 1.6553350116451346
Validation loss: 2.4138473838089105

Epoch: 5| Step: 6
Training loss: 2.364299258562525
Validation loss: 2.354281046364074

Epoch: 5| Step: 7
Training loss: 1.6546717627680214
Validation loss: 2.4300551022814223

Epoch: 5| Step: 8
Training loss: 1.3222868113320685
Validation loss: 2.413161428225731

Epoch: 5| Step: 9
Training loss: 1.4973153089903086
Validation loss: 2.3020506265217704

Epoch: 5| Step: 10
Training loss: 1.7530329171815124
Validation loss: 2.4008466688422616

Epoch: 446| Step: 0
Training loss: 1.4263597960674315
Validation loss: 2.403986145707633

Epoch: 5| Step: 1
Training loss: 1.4924122106908877
Validation loss: 2.3725533860895296

Epoch: 5| Step: 2
Training loss: 1.3717278647106388
Validation loss: 2.352269104765782

Epoch: 5| Step: 3
Training loss: 1.3823814797946772
Validation loss: 2.377240785670101

Epoch: 5| Step: 4
Training loss: 1.5069454249756296
Validation loss: 2.2775021720283246

Epoch: 5| Step: 5
Training loss: 1.3604462885686448
Validation loss: 2.3150825292309603

Epoch: 5| Step: 6
Training loss: 1.86926460452852
Validation loss: 2.4323621429044384

Epoch: 5| Step: 7
Training loss: 1.7884649753143127
Validation loss: 2.3704165902551955

Epoch: 5| Step: 8
Training loss: 1.4626981356483137
Validation loss: 2.4168052492162864

Epoch: 5| Step: 9
Training loss: 2.2828896260793776
Validation loss: 2.404708420698462

Epoch: 5| Step: 10
Training loss: 1.5885593184027176
Validation loss: 2.3773923330557487

Epoch: 447| Step: 0
Training loss: 1.6067332835784276
Validation loss: 2.3833284090873135

Epoch: 5| Step: 1
Training loss: 1.7943569950700546
Validation loss: 2.37514355521933

Epoch: 5| Step: 2
Training loss: 1.773381639852803
Validation loss: 2.3429030399590385

Epoch: 5| Step: 3
Training loss: 1.1438350187294128
Validation loss: 2.414021335910191

Epoch: 5| Step: 4
Training loss: 1.9731992068759476
Validation loss: 2.4004496456982327

Epoch: 5| Step: 5
Training loss: 1.608581347276433
Validation loss: 2.3273073819741645

Epoch: 5| Step: 6
Training loss: 1.7755097369198563
Validation loss: 2.3772740295879102

Epoch: 5| Step: 7
Training loss: 2.2141754918418495
Validation loss: 2.3921833593125688

Epoch: 5| Step: 8
Training loss: 1.55543645713159
Validation loss: 2.3968173417009933

Epoch: 5| Step: 9
Training loss: 1.5846103320386644
Validation loss: 2.401599512704953

Epoch: 5| Step: 10
Training loss: 1.1787676730403684
Validation loss: 2.4466581971981247

Epoch: 448| Step: 0
Training loss: 1.8282084649750012
Validation loss: 2.363416559435248

Epoch: 5| Step: 1
Training loss: 1.8057056543935497
Validation loss: 2.3640707795016764

Epoch: 5| Step: 2
Training loss: 2.1179353301177626
Validation loss: 2.460579035327621

Epoch: 5| Step: 3
Training loss: 1.4677967468157056
Validation loss: 2.3826551299676475

Epoch: 5| Step: 4
Training loss: 1.211594778540573
Validation loss: 2.401039944789309

Epoch: 5| Step: 5
Training loss: 2.177755832994059
Validation loss: 2.4526031672740882

Epoch: 5| Step: 6
Training loss: 1.7421838734678834
Validation loss: 2.465034062133308

Epoch: 5| Step: 7
Training loss: 1.6510831745437522
Validation loss: 2.414024483614719

Epoch: 5| Step: 8
Training loss: 0.9965009866643558
Validation loss: 2.305464274222083

Epoch: 5| Step: 9
Training loss: 1.7082583558291204
Validation loss: 2.3714027255506265

Epoch: 5| Step: 10
Training loss: 1.5300268620894242
Validation loss: 2.351731065066765

Epoch: 449| Step: 0
Training loss: 1.9597515760362616
Validation loss: 2.322047899167073

Epoch: 5| Step: 1
Training loss: 1.6990916939073093
Validation loss: 2.4383188927766293

Epoch: 5| Step: 2
Training loss: 2.120389087168071
Validation loss: 2.3808568720441965

Epoch: 5| Step: 3
Training loss: 1.4753715111926278
Validation loss: 2.4118161375999616

Epoch: 5| Step: 4
Training loss: 1.6242904581201256
Validation loss: 2.332690795056117

Epoch: 5| Step: 5
Training loss: 1.3832769098992614
Validation loss: 2.420200055840955

Epoch: 5| Step: 6
Training loss: 1.6681137557953174
Validation loss: 2.446772957289921

Epoch: 5| Step: 7
Training loss: 1.9961814786441043
Validation loss: 2.336985180104438

Epoch: 5| Step: 8
Training loss: 1.5420146068370995
Validation loss: 2.3551616963438944

Epoch: 5| Step: 9
Training loss: 1.2837562239959406
Validation loss: 2.3792856729063443

Epoch: 5| Step: 10
Training loss: 1.674357345049407
Validation loss: 2.330255157580996

Epoch: 450| Step: 0
Training loss: 1.415522375029008
Validation loss: 2.3282995153773407

Epoch: 5| Step: 1
Training loss: 1.7550729384304276
Validation loss: 2.354137995098196

Epoch: 5| Step: 2
Training loss: 1.8124449491361916
Validation loss: 2.3376166879112996

Epoch: 5| Step: 3
Training loss: 1.9323753140039213
Validation loss: 2.355655146967672

Epoch: 5| Step: 4
Training loss: 1.659346798299737
Validation loss: 2.3396629559335977

Epoch: 5| Step: 5
Training loss: 1.0513652327404386
Validation loss: 2.3535199026039044

Epoch: 5| Step: 6
Training loss: 1.44138664914582
Validation loss: 2.36614588271053

Epoch: 5| Step: 7
Training loss: 1.8812988021451778
Validation loss: 2.42440147764918

Epoch: 5| Step: 8
Training loss: 1.9631327465527564
Validation loss: 2.375587552615562

Epoch: 5| Step: 9
Training loss: 1.614867236700649
Validation loss: 2.381357351104377

Epoch: 5| Step: 10
Training loss: 1.5430620768848275
Validation loss: 2.3098573914677947

Testing loss: 2.9245139595786
