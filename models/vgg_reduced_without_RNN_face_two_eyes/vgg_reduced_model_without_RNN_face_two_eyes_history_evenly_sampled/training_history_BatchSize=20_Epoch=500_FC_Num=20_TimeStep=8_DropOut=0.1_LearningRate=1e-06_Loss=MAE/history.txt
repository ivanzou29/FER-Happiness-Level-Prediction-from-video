Epoch: 1| Step: 0
Training loss: 5.0586419105529785
Validation loss: 6.064516585360291

Epoch: 5| Step: 1
Training loss: 6.051609992980957
Validation loss: 6.056322025996383

Epoch: 5| Step: 2
Training loss: 6.560586452484131
Validation loss: 6.052115040440714

Epoch: 5| Step: 3
Training loss: 5.6733808517456055
Validation loss: 6.039592276337326

Epoch: 5| Step: 4
Training loss: 4.650795936584473
Validation loss: 6.031278830702587

Epoch: 5| Step: 5
Training loss: 5.501440525054932
Validation loss: 6.023538722786852

Epoch: 5| Step: 6
Training loss: 5.9039506912231445
Validation loss: 6.01449090691023

Epoch: 5| Step: 7
Training loss: 5.609967231750488
Validation loss: 6.006721727309689

Epoch: 5| Step: 8
Training loss: 7.114304542541504
Validation loss: 5.998245531512845

Epoch: 5| Step: 9
Training loss: 6.053229331970215
Validation loss: 5.987091172126032

Epoch: 5| Step: 10
Training loss: 5.815983295440674
Validation loss: 5.984188992490051

Epoch: 2| Step: 0
Training loss: 5.507002353668213
Validation loss: 5.971677113604802

Epoch: 5| Step: 1
Training loss: 5.987992286682129
Validation loss: 5.966480429454516

Epoch: 5| Step: 2
Training loss: 4.9313812255859375
Validation loss: 5.956516147941671

Epoch: 5| Step: 3
Training loss: 7.435059547424316
Validation loss: 5.947766852635209

Epoch: 5| Step: 4
Training loss: 5.433379650115967
Validation loss: 5.936834155872304

Epoch: 5| Step: 5
Training loss: 6.043597221374512
Validation loss: 5.9327211995278635

Epoch: 5| Step: 6
Training loss: 5.358333587646484
Validation loss: 5.921518146350819

Epoch: 5| Step: 7
Training loss: 5.64711332321167
Validation loss: 5.913649000147338

Epoch: 5| Step: 8
Training loss: 4.829216480255127
Validation loss: 5.904577250121742

Epoch: 5| Step: 9
Training loss: 5.788516521453857
Validation loss: 5.895539493970974

Epoch: 5| Step: 10
Training loss: 6.061869144439697
Validation loss: 5.886071681976318

Epoch: 3| Step: 0
Training loss: 6.36212158203125
Validation loss: 5.881606363481091

Epoch: 5| Step: 1
Training loss: 6.206187725067139
Validation loss: 5.87183972840668

Epoch: 5| Step: 2
Training loss: 4.920777797698975
Validation loss: 5.8620685197973765

Epoch: 5| Step: 3
Training loss: 6.451895713806152
Validation loss: 5.856434463172831

Epoch: 5| Step: 4
Training loss: 5.8772292137146
Validation loss: 5.848485890255179

Epoch: 5| Step: 5
Training loss: 5.503398895263672
Validation loss: 5.83894593228576

Epoch: 5| Step: 6
Training loss: 5.999041557312012
Validation loss: 5.828842957814534

Epoch: 5| Step: 7
Training loss: 5.54984188079834
Validation loss: 5.822409527276152

Epoch: 5| Step: 8
Training loss: 5.026749610900879
Validation loss: 5.8162815442649265

Epoch: 5| Step: 9
Training loss: 5.244286060333252
Validation loss: 5.806053925586003

Epoch: 5| Step: 10
Training loss: 4.640480041503906
Validation loss: 5.798182451596824

Epoch: 4| Step: 0
Training loss: 5.396559715270996
Validation loss: 5.7857169540979525

Epoch: 5| Step: 1
Training loss: 5.15370512008667
Validation loss: 5.780492710810836

Epoch: 5| Step: 2
Training loss: 5.098239421844482
Validation loss: 5.772082149341542

Epoch: 5| Step: 3
Training loss: 4.540790557861328
Validation loss: 5.763249771569365

Epoch: 5| Step: 4
Training loss: 5.394289970397949
Validation loss: 5.753757886989142

Epoch: 5| Step: 5
Training loss: 4.934699058532715
Validation loss: 5.744436653711462

Epoch: 5| Step: 6
Training loss: 6.678997993469238
Validation loss: 5.738481572879258

Epoch: 5| Step: 7
Training loss: 5.858641147613525
Validation loss: 5.724511587491599

Epoch: 5| Step: 8
Training loss: 6.213764190673828
Validation loss: 5.720092153036466

Epoch: 5| Step: 9
Training loss: 6.348686695098877
Validation loss: 5.7104546998136785

Epoch: 5| Step: 10
Training loss: 5.20578670501709
Validation loss: 5.700113009381038

Epoch: 5| Step: 0
Training loss: 4.785043239593506
Validation loss: 5.693236458686091

Epoch: 5| Step: 1
Training loss: 4.96417236328125
Validation loss: 5.681806569458336

Epoch: 5| Step: 2
Training loss: 5.988816261291504
Validation loss: 5.67459314100204

Epoch: 5| Step: 3
Training loss: 6.9727582931518555
Validation loss: 5.6641625947849725

Epoch: 5| Step: 4
Training loss: 5.431942939758301
Validation loss: 5.655859567785776

Epoch: 5| Step: 5
Training loss: 4.644834995269775
Validation loss: 5.645748256355204

Epoch: 5| Step: 6
Training loss: 4.8607635498046875
Validation loss: 5.634693043206328

Epoch: 5| Step: 7
Training loss: 6.0425825119018555
Validation loss: 5.628098923672912

Epoch: 5| Step: 8
Training loss: 5.446135520935059
Validation loss: 5.616700244206254

Epoch: 5| Step: 9
Training loss: 6.154076099395752
Validation loss: 5.60794936456988

Epoch: 5| Step: 10
Training loss: 4.295551300048828
Validation loss: 5.597824301770938

Epoch: 6| Step: 0
Training loss: 5.285648822784424
Validation loss: 5.5897166139336045

Epoch: 5| Step: 1
Training loss: 4.996970176696777
Validation loss: 5.57964208561887

Epoch: 5| Step: 2
Training loss: 5.337034225463867
Validation loss: 5.568178612698791

Epoch: 5| Step: 3
Training loss: 6.3601179122924805
Validation loss: 5.559280533944407

Epoch: 5| Step: 4
Training loss: 5.760957717895508
Validation loss: 5.550432892255886

Epoch: 5| Step: 5
Training loss: 5.586970329284668
Validation loss: 5.538895740303942

Epoch: 5| Step: 6
Training loss: 5.7934417724609375
Validation loss: 5.5296453352897394

Epoch: 5| Step: 7
Training loss: 4.246768951416016
Validation loss: 5.517931194715603

Epoch: 5| Step: 8
Training loss: 4.604980945587158
Validation loss: 5.506989161173503

Epoch: 5| Step: 9
Training loss: 4.902547836303711
Validation loss: 5.497423182251633

Epoch: 5| Step: 10
Training loss: 5.722173690795898
Validation loss: 5.485255313175981

Epoch: 7| Step: 0
Training loss: 4.809207916259766
Validation loss: 5.474294990621587

Epoch: 5| Step: 1
Training loss: 5.9315080642700195
Validation loss: 5.467033165757374

Epoch: 5| Step: 2
Training loss: 5.4575018882751465
Validation loss: 5.4535073670007845

Epoch: 5| Step: 3
Training loss: 5.561131954193115
Validation loss: 5.444884818087342

Epoch: 5| Step: 4
Training loss: 5.26939582824707
Validation loss: 5.4335734152024795

Epoch: 5| Step: 5
Training loss: 4.97848653793335
Validation loss: 5.4237531436386925

Epoch: 5| Step: 6
Training loss: 5.024259090423584
Validation loss: 5.40901045645437

Epoch: 5| Step: 7
Training loss: 4.54009485244751
Validation loss: 5.397128684546358

Epoch: 5| Step: 8
Training loss: 4.274316310882568
Validation loss: 5.386517376028081

Epoch: 5| Step: 9
Training loss: 6.121743202209473
Validation loss: 5.3764958740562525

Epoch: 5| Step: 10
Training loss: 5.254268169403076
Validation loss: 5.3635895226591375

Epoch: 8| Step: 0
Training loss: 6.521060943603516
Validation loss: 5.3528281488726215

Epoch: 5| Step: 1
Training loss: 6.010465145111084
Validation loss: 5.339308374671526

Epoch: 5| Step: 2
Training loss: 4.167267322540283
Validation loss: 5.32570569745956

Epoch: 5| Step: 3
Training loss: 4.246860504150391
Validation loss: 5.318442980448405

Epoch: 5| Step: 4
Training loss: 6.273076057434082
Validation loss: 5.303606274307415

Epoch: 5| Step: 5
Training loss: 5.521690845489502
Validation loss: 5.289359102966965

Epoch: 5| Step: 6
Training loss: 5.012356758117676
Validation loss: 5.279079057837046

Epoch: 5| Step: 7
Training loss: 4.367616653442383
Validation loss: 5.266631731422999

Epoch: 5| Step: 8
Training loss: 4.033118724822998
Validation loss: 5.253112434059061

Epoch: 5| Step: 9
Training loss: 4.338443756103516
Validation loss: 5.238746407211468

Epoch: 5| Step: 10
Training loss: 5.307858943939209
Validation loss: 5.225725179077477

Epoch: 9| Step: 0
Training loss: 4.8556718826293945
Validation loss: 5.211792171642345

Epoch: 5| Step: 1
Training loss: 5.043357849121094
Validation loss: 5.1976583388543895

Epoch: 5| Step: 2
Training loss: 5.806397438049316
Validation loss: 5.180409969822053

Epoch: 5| Step: 3
Training loss: 4.292250156402588
Validation loss: 5.1699156094622865

Epoch: 5| Step: 4
Training loss: 5.422444820404053
Validation loss: 5.153625752336236

Epoch: 5| Step: 5
Training loss: 4.05741024017334
Validation loss: 5.146862312029767

Epoch: 5| Step: 6
Training loss: 4.225105285644531
Validation loss: 5.1233392633417605

Epoch: 5| Step: 7
Training loss: 4.914480209350586
Validation loss: 5.1135684546603954

Epoch: 5| Step: 8
Training loss: 5.68462610244751
Validation loss: 5.097323351008917

Epoch: 5| Step: 9
Training loss: 5.17308235168457
Validation loss: 5.077556292215983

Epoch: 5| Step: 10
Training loss: 4.541029930114746
Validation loss: 5.0638963381449384

Epoch: 10| Step: 0
Training loss: 4.016420364379883
Validation loss: 5.050685236530919

Epoch: 5| Step: 1
Training loss: 5.202332496643066
Validation loss: 5.034839619872391

Epoch: 5| Step: 2
Training loss: 4.301659107208252
Validation loss: 5.017413277779856

Epoch: 5| Step: 3
Training loss: 5.019700050354004
Validation loss: 5.005488882782639

Epoch: 5| Step: 4
Training loss: 5.344369888305664
Validation loss: 4.988949565477268

Epoch: 5| Step: 5
Training loss: 4.037879467010498
Validation loss: 4.971801809085313

Epoch: 5| Step: 6
Training loss: 4.769424915313721
Validation loss: 4.953702008852395

Epoch: 5| Step: 7
Training loss: 5.64802885055542
Validation loss: 4.93572445325954

Epoch: 5| Step: 8
Training loss: 4.33431339263916
Validation loss: 4.914804207381382

Epoch: 5| Step: 9
Training loss: 4.3229498863220215
Validation loss: 4.904654072177026

Epoch: 5| Step: 10
Training loss: 5.225185871124268
Validation loss: 4.884907573781987

Epoch: 11| Step: 0
Training loss: 4.717569828033447
Validation loss: 4.864889057733679

Epoch: 5| Step: 1
Training loss: 4.461944580078125
Validation loss: 4.849130256201631

Epoch: 5| Step: 2
Training loss: 4.31345272064209
Validation loss: 4.835487822050689

Epoch: 5| Step: 3
Training loss: 4.455166816711426
Validation loss: 4.818641426742718

Epoch: 5| Step: 4
Training loss: 4.640144348144531
Validation loss: 4.79571190188008

Epoch: 5| Step: 5
Training loss: 4.861748695373535
Validation loss: 4.778159115904121

Epoch: 5| Step: 6
Training loss: 3.547246217727661
Validation loss: 4.756814120918192

Epoch: 5| Step: 7
Training loss: 4.0584797859191895
Validation loss: 4.729028819709696

Epoch: 5| Step: 8
Training loss: 4.959298610687256
Validation loss: 4.720615079326015

Epoch: 5| Step: 9
Training loss: 4.710618019104004
Validation loss: 4.7048530270976405

Epoch: 5| Step: 10
Training loss: 5.461117744445801
Validation loss: 4.6859350383922616

Epoch: 12| Step: 0
Training loss: 4.472918510437012
Validation loss: 4.659100163367487

Epoch: 5| Step: 1
Training loss: 4.166117191314697
Validation loss: 4.638831471884123

Epoch: 5| Step: 2
Training loss: 4.213780879974365
Validation loss: 4.623750548208913

Epoch: 5| Step: 3
Training loss: 4.084816932678223
Validation loss: 4.599154410823699

Epoch: 5| Step: 4
Training loss: 4.752499580383301
Validation loss: 4.580384892802084

Epoch: 5| Step: 5
Training loss: 4.208133220672607
Validation loss: 4.563083576899703

Epoch: 5| Step: 6
Training loss: 4.470297813415527
Validation loss: 4.538230352504279

Epoch: 5| Step: 7
Training loss: 4.991450309753418
Validation loss: 4.516363677158151

Epoch: 5| Step: 8
Training loss: 3.4967474937438965
Validation loss: 4.48911363335066

Epoch: 5| Step: 9
Training loss: 3.73555326461792
Validation loss: 4.4721939897024505

Epoch: 5| Step: 10
Training loss: 5.093807220458984
Validation loss: 4.444119076575002

Epoch: 13| Step: 0
Training loss: 3.527829647064209
Validation loss: 4.432731879654751

Epoch: 5| Step: 1
Training loss: 3.016662120819092
Validation loss: 4.403960458693966

Epoch: 5| Step: 2
Training loss: 3.7480151653289795
Validation loss: 4.375545383781515

Epoch: 5| Step: 3
Training loss: 3.768395185470581
Validation loss: 4.355985497915617

Epoch: 5| Step: 4
Training loss: 3.843064069747925
Validation loss: 4.329457088183331

Epoch: 5| Step: 5
Training loss: 4.202349662780762
Validation loss: 4.312624480134698

Epoch: 5| Step: 6
Training loss: 4.839879989624023
Validation loss: 4.294499346005019

Epoch: 5| Step: 7
Training loss: 5.071221351623535
Validation loss: 4.268197315995411

Epoch: 5| Step: 8
Training loss: 4.323336124420166
Validation loss: 4.235456697402462

Epoch: 5| Step: 9
Training loss: 4.778609275817871
Validation loss: 4.217509577351231

Epoch: 5| Step: 10
Training loss: 3.763803482055664
Validation loss: 4.190284323948686

Epoch: 14| Step: 0
Training loss: 2.841461420059204
Validation loss: 4.172830894429197

Epoch: 5| Step: 1
Training loss: 5.111133575439453
Validation loss: 4.154027420987365

Epoch: 5| Step: 2
Training loss: 3.5742440223693848
Validation loss: 4.125279859829974

Epoch: 5| Step: 3
Training loss: 4.613335609436035
Validation loss: 4.107384404828472

Epoch: 5| Step: 4
Training loss: 4.5098466873168945
Validation loss: 4.080829215306108

Epoch: 5| Step: 5
Training loss: 3.998957395553589
Validation loss: 4.055927233029437

Epoch: 5| Step: 6
Training loss: 3.542832612991333
Validation loss: 4.037693139045469

Epoch: 5| Step: 7
Training loss: 3.8436264991760254
Validation loss: 4.0127501897914435

Epoch: 5| Step: 8
Training loss: 3.160628080368042
Validation loss: 3.985450037064091

Epoch: 5| Step: 9
Training loss: 4.006214618682861
Validation loss: 3.9686083947458575

Epoch: 5| Step: 10
Training loss: 3.1224889755249023
Validation loss: 3.949719621289161

Epoch: 15| Step: 0
Training loss: 3.4027466773986816
Validation loss: 3.9261292488344255

Epoch: 5| Step: 1
Training loss: 3.350877285003662
Validation loss: 3.8959831576193533

Epoch: 5| Step: 2
Training loss: 3.6135971546173096
Validation loss: 3.8751232188235045

Epoch: 5| Step: 3
Training loss: 3.744264602661133
Validation loss: 3.852824975085515

Epoch: 5| Step: 4
Training loss: 3.8113174438476562
Validation loss: 3.832924494179346

Epoch: 5| Step: 5
Training loss: 4.143637657165527
Validation loss: 3.80984156106108

Epoch: 5| Step: 6
Training loss: 3.813507080078125
Validation loss: 3.7874719686405633

Epoch: 5| Step: 7
Training loss: 3.2250430583953857
Validation loss: 3.759497619444324

Epoch: 5| Step: 8
Training loss: 3.496337413787842
Validation loss: 3.7397370440985567

Epoch: 5| Step: 9
Training loss: 4.234694004058838
Validation loss: 3.712296042391049

Epoch: 5| Step: 10
Training loss: 3.1408889293670654
Validation loss: 3.694324831808767

Epoch: 16| Step: 0
Training loss: 3.039902687072754
Validation loss: 3.674064831067157

Epoch: 5| Step: 1
Training loss: 2.6525521278381348
Validation loss: 3.649563689385691

Epoch: 5| Step: 2
Training loss: 2.872650384902954
Validation loss: 3.6246979467330442

Epoch: 5| Step: 3
Training loss: 3.0049076080322266
Validation loss: 3.6026527420167

Epoch: 5| Step: 4
Training loss: 3.842733383178711
Validation loss: 3.580013972456737

Epoch: 5| Step: 5
Training loss: 3.2259647846221924
Validation loss: 3.558540698020689

Epoch: 5| Step: 6
Training loss: 4.192530632019043
Validation loss: 3.529700650963732

Epoch: 5| Step: 7
Training loss: 3.4458415508270264
Validation loss: 3.5138884898154967

Epoch: 5| Step: 8
Training loss: 4.7699384689331055
Validation loss: 3.48944212800713

Epoch: 5| Step: 9
Training loss: 2.7747814655303955
Validation loss: 3.4696403395745063

Epoch: 5| Step: 10
Training loss: 3.9677011966705322
Validation loss: 3.441094929172147

Epoch: 17| Step: 0
Training loss: 3.363929271697998
Validation loss: 3.424782463299331

Epoch: 5| Step: 1
Training loss: 3.4210143089294434
Validation loss: 3.408977252180858

Epoch: 5| Step: 2
Training loss: 3.3727097511291504
Validation loss: 3.372347093397571

Epoch: 5| Step: 3
Training loss: 2.9949676990509033
Validation loss: 3.35180599458756

Epoch: 5| Step: 4
Training loss: 3.7118847370147705
Validation loss: 3.3360424477566957

Epoch: 5| Step: 5
Training loss: 3.8521926403045654
Validation loss: 3.313360027087632

Epoch: 5| Step: 6
Training loss: 2.575117349624634
Validation loss: 3.2868324813022407

Epoch: 5| Step: 7
Training loss: 3.262528657913208
Validation loss: 3.2688676234214538

Epoch: 5| Step: 8
Training loss: 2.9182839393615723
Validation loss: 3.235518373468871

Epoch: 5| Step: 9
Training loss: 3.0229556560516357
Validation loss: 3.211590777161301

Epoch: 5| Step: 10
Training loss: 2.848727226257324
Validation loss: 3.1934217150493334

Epoch: 18| Step: 0
Training loss: 2.004499912261963
Validation loss: 3.156047803099437

Epoch: 5| Step: 1
Training loss: 2.7732720375061035
Validation loss: 3.1365745349596907

Epoch: 5| Step: 2
Training loss: 2.8925628662109375
Validation loss: 3.131175882072859

Epoch: 5| Step: 3
Training loss: 2.581857442855835
Validation loss: 3.1033950082717405

Epoch: 5| Step: 4
Training loss: 3.325779438018799
Validation loss: 3.0656574259522142

Epoch: 5| Step: 5
Training loss: 3.9181084632873535
Validation loss: 3.045693515449442

Epoch: 5| Step: 6
Training loss: 3.0980730056762695
Validation loss: 3.022831719408753

Epoch: 5| Step: 7
Training loss: 3.269763469696045
Validation loss: 3.011185089747111

Epoch: 5| Step: 8
Training loss: 2.971187114715576
Validation loss: 2.989041684776224

Epoch: 5| Step: 9
Training loss: 3.004924774169922
Validation loss: 2.9625967907649216

Epoch: 5| Step: 10
Training loss: 3.2124476432800293
Validation loss: 2.949468525507117

Epoch: 19| Step: 0
Training loss: 3.192780017852783
Validation loss: 2.922223147525582

Epoch: 5| Step: 1
Training loss: 3.852949619293213
Validation loss: 2.8904427200235348

Epoch: 5| Step: 2
Training loss: 2.7984790802001953
Validation loss: 2.8857081910615325

Epoch: 5| Step: 3
Training loss: 3.0118095874786377
Validation loss: 2.849528681847357

Epoch: 5| Step: 4
Training loss: 2.762967109680176
Validation loss: 2.8316955438224216

Epoch: 5| Step: 5
Training loss: 2.205075740814209
Validation loss: 2.819197057395853

Epoch: 5| Step: 6
Training loss: 2.839556932449341
Validation loss: 2.779958512193413

Epoch: 5| Step: 7
Training loss: 2.404665231704712
Validation loss: 2.7741963555735927

Epoch: 5| Step: 8
Training loss: 2.8509011268615723
Validation loss: 2.742149829864502

Epoch: 5| Step: 9
Training loss: 2.5220389366149902
Validation loss: 2.7346275416753625

Epoch: 5| Step: 10
Training loss: 2.9551236629486084
Validation loss: 2.713594400754539

Epoch: 20| Step: 0
Training loss: 2.758513927459717
Validation loss: 2.6952860355377197

Epoch: 5| Step: 1
Training loss: 2.9461381435394287
Validation loss: 2.662368489849952

Epoch: 5| Step: 2
Training loss: 2.321510076522827
Validation loss: 2.6469098162907425

Epoch: 5| Step: 3
Training loss: 2.9530014991760254
Validation loss: 2.645633130945185

Epoch: 5| Step: 4
Training loss: 2.952369213104248
Validation loss: 2.621107109131352

Epoch: 5| Step: 5
Training loss: 2.381321430206299
Validation loss: 2.6106100774580434

Epoch: 5| Step: 6
Training loss: 2.748629331588745
Validation loss: 2.5887235210787867

Epoch: 5| Step: 7
Training loss: 2.9711623191833496
Validation loss: 2.5611322746481946

Epoch: 5| Step: 8
Training loss: 2.951139450073242
Validation loss: 2.5426139216269217

Epoch: 5| Step: 9
Training loss: 2.4373085498809814
Validation loss: 2.517391263797719

Epoch: 5| Step: 10
Training loss: 2.064251661300659
Validation loss: 2.512803764753444

Epoch: 21| Step: 0
Training loss: 2.2276062965393066
Validation loss: 2.488318786826185

Epoch: 5| Step: 1
Training loss: 1.8909152746200562
Validation loss: 2.472184242740754

Epoch: 5| Step: 2
Training loss: 2.5600199699401855
Validation loss: 2.464312514951152

Epoch: 5| Step: 3
Training loss: 3.44429349899292
Validation loss: 2.445536414782206

Epoch: 5| Step: 4
Training loss: 2.45375394821167
Validation loss: 2.432668785895071

Epoch: 5| Step: 5
Training loss: 2.140794515609741
Validation loss: 2.4129729745208577

Epoch: 5| Step: 6
Training loss: 3.1553916931152344
Validation loss: 2.4114983850909817

Epoch: 5| Step: 7
Training loss: 2.282963275909424
Validation loss: 2.3863143920898438

Epoch: 5| Step: 8
Training loss: 2.7862250804901123
Validation loss: 2.3696463928427747

Epoch: 5| Step: 9
Training loss: 2.6701929569244385
Validation loss: 2.357866423104399

Epoch: 5| Step: 10
Training loss: 2.4145538806915283
Validation loss: 2.35796324412028

Epoch: 22| Step: 0
Training loss: 2.1428427696228027
Validation loss: 2.3481830217505015

Epoch: 5| Step: 1
Training loss: 2.799370288848877
Validation loss: 2.3352037117045414

Epoch: 5| Step: 2
Training loss: 3.146806240081787
Validation loss: 2.3206084030930714

Epoch: 5| Step: 3
Training loss: 2.331824541091919
Validation loss: 2.31622116796432

Epoch: 5| Step: 4
Training loss: 2.801743984222412
Validation loss: 2.316104560770014

Epoch: 5| Step: 5
Training loss: 2.1147968769073486
Validation loss: 2.289993232296359

Epoch: 5| Step: 6
Training loss: 2.1805901527404785
Validation loss: 2.2880151835821008

Epoch: 5| Step: 7
Training loss: 2.5614683628082275
Validation loss: 2.2804428582550376

Epoch: 5| Step: 8
Training loss: 2.152747392654419
Validation loss: 2.2829064887057067

Epoch: 5| Step: 9
Training loss: 2.543731212615967
Validation loss: 2.266117324111282

Epoch: 5| Step: 10
Training loss: 2.4938113689422607
Validation loss: 2.262868822261851

Epoch: 23| Step: 0
Training loss: 2.4476120471954346
Validation loss: 2.2549545277831373

Epoch: 5| Step: 1
Training loss: 2.5290727615356445
Validation loss: 2.2466644817782986

Epoch: 5| Step: 2
Training loss: 2.989060401916504
Validation loss: 2.2356270026135188

Epoch: 5| Step: 3
Training loss: 2.541699171066284
Validation loss: 2.2401152836379183

Epoch: 5| Step: 4
Training loss: 2.229128837585449
Validation loss: 2.2406129452490036

Epoch: 5| Step: 5
Training loss: 2.312997341156006
Validation loss: 2.2455504222582747

Epoch: 5| Step: 6
Training loss: 2.509540557861328
Validation loss: 2.222657411329208

Epoch: 5| Step: 7
Training loss: 2.104811429977417
Validation loss: 2.2156567983729865

Epoch: 5| Step: 8
Training loss: 2.357320547103882
Validation loss: 2.2117387504987818

Epoch: 5| Step: 9
Training loss: 2.5138297080993652
Validation loss: 2.2000751392815703

Epoch: 5| Step: 10
Training loss: 2.3060293197631836
Validation loss: 2.2130915759712138

Epoch: 24| Step: 0
Training loss: 2.281630039215088
Validation loss: 2.206868533165224

Epoch: 5| Step: 1
Training loss: 2.3552768230438232
Validation loss: 2.2141085683658557

Epoch: 5| Step: 2
Training loss: 2.1759183406829834
Validation loss: 2.2194995957036174

Epoch: 5| Step: 3
Training loss: 2.404909133911133
Validation loss: 2.208292034364516

Epoch: 5| Step: 4
Training loss: 2.630626678466797
Validation loss: 2.190859204979353

Epoch: 5| Step: 5
Training loss: 2.4691944122314453
Validation loss: 2.209025162522511

Epoch: 5| Step: 6
Training loss: 2.6359076499938965
Validation loss: 2.1942557622027654

Epoch: 5| Step: 7
Training loss: 2.5496604442596436
Validation loss: 2.2164493837664203

Epoch: 5| Step: 8
Training loss: 2.2739920616149902
Validation loss: 2.209801971271474

Epoch: 5| Step: 9
Training loss: 2.773867130279541
Validation loss: 2.1878284459472983

Epoch: 5| Step: 10
Training loss: 2.2186949253082275
Validation loss: 2.2001393687340522

Epoch: 25| Step: 0
Training loss: 2.2262210845947266
Validation loss: 2.197134047426203

Epoch: 5| Step: 1
Training loss: 2.8891568183898926
Validation loss: 2.1948018048399236

Epoch: 5| Step: 2
Training loss: 1.6005280017852783
Validation loss: 2.1878632883871756

Epoch: 5| Step: 3
Training loss: 2.6053309440612793
Validation loss: 2.1854535533535864

Epoch: 5| Step: 4
Training loss: 2.3177711963653564
Validation loss: 2.1725406608273907

Epoch: 5| Step: 5
Training loss: 2.6665120124816895
Validation loss: 2.1896784895209858

Epoch: 5| Step: 6
Training loss: 2.818573474884033
Validation loss: 2.1855251096910044

Epoch: 5| Step: 7
Training loss: 2.4300954341888428
Validation loss: 2.184461162936303

Epoch: 5| Step: 8
Training loss: 2.3151907920837402
Validation loss: 2.1832278441357356

Epoch: 5| Step: 9
Training loss: 2.793309211730957
Validation loss: 2.170861751802506

Epoch: 5| Step: 10
Training loss: 1.923858880996704
Validation loss: 2.1853178572911087

Epoch: 26| Step: 0
Training loss: 2.4043233394622803
Validation loss: 2.175538229685958

Epoch: 5| Step: 1
Training loss: 2.574976921081543
Validation loss: 2.169480777555896

Epoch: 5| Step: 2
Training loss: 2.0392937660217285
Validation loss: 2.199925914887459

Epoch: 5| Step: 3
Training loss: 2.6927011013031006
Validation loss: 2.1837085293185328

Epoch: 5| Step: 4
Training loss: 2.378035306930542
Validation loss: 2.1826033938315605

Epoch: 5| Step: 5
Training loss: 2.6119961738586426
Validation loss: 2.183923472640335

Epoch: 5| Step: 6
Training loss: 2.162320852279663
Validation loss: 2.183887614998766

Epoch: 5| Step: 7
Training loss: 2.5917351245880127
Validation loss: 2.1677959401120424

Epoch: 5| Step: 8
Training loss: 2.3070197105407715
Validation loss: 2.186523534918344

Epoch: 5| Step: 9
Training loss: 2.3454527854919434
Validation loss: 2.1848369208715295

Epoch: 5| Step: 10
Training loss: 2.5001211166381836
Validation loss: 2.1851263943538872

Epoch: 27| Step: 0
Training loss: 1.948006272315979
Validation loss: 2.1794635685541297

Epoch: 5| Step: 1
Training loss: 2.8406853675842285
Validation loss: 2.1642257141810592

Epoch: 5| Step: 2
Training loss: 2.553619861602783
Validation loss: 2.1764383469858477

Epoch: 5| Step: 3
Training loss: 2.843871831893921
Validation loss: 2.184757876139815

Epoch: 5| Step: 4
Training loss: 2.007002830505371
Validation loss: 2.178711965519895

Epoch: 5| Step: 5
Training loss: 2.2999050617218018
Validation loss: 2.1703985045033116

Epoch: 5| Step: 6
Training loss: 2.3026843070983887
Validation loss: 2.179874002292592

Epoch: 5| Step: 7
Training loss: 2.4961705207824707
Validation loss: 2.1745524432069514

Epoch: 5| Step: 8
Training loss: 2.2764480113983154
Validation loss: 2.18426953336244

Epoch: 5| Step: 9
Training loss: 2.2829158306121826
Validation loss: 2.1728267823496172

Epoch: 5| Step: 10
Training loss: 2.729360342025757
Validation loss: 2.1813026987096316

Epoch: 28| Step: 0
Training loss: 2.8133511543273926
Validation loss: 2.186518015400056

Epoch: 5| Step: 1
Training loss: 2.5331997871398926
Validation loss: 2.1752435584222116

Epoch: 5| Step: 2
Training loss: 2.339716672897339
Validation loss: 2.1629352236306794

Epoch: 5| Step: 3
Training loss: 2.721134901046753
Validation loss: 2.1844106092247912

Epoch: 5| Step: 4
Training loss: 2.6511425971984863
Validation loss: 2.185291833775018

Epoch: 5| Step: 5
Training loss: 2.2235195636749268
Validation loss: 2.1731853536380235

Epoch: 5| Step: 6
Training loss: 2.057053804397583
Validation loss: 2.1738429633519982

Epoch: 5| Step: 7
Training loss: 2.4801087379455566
Validation loss: 2.171557467470887

Epoch: 5| Step: 8
Training loss: 2.654566764831543
Validation loss: 2.1648095910267164

Epoch: 5| Step: 9
Training loss: 1.9988937377929688
Validation loss: 2.189335455176651

Epoch: 5| Step: 10
Training loss: 1.975982904434204
Validation loss: 2.1676497433775213

Epoch: 29| Step: 0
Training loss: 2.8129918575286865
Validation loss: 2.1689827544714815

Epoch: 5| Step: 1
Training loss: 1.8337619304656982
Validation loss: 2.1832646221242924

Epoch: 5| Step: 2
Training loss: 2.960310697555542
Validation loss: 2.166467571771273

Epoch: 5| Step: 3
Training loss: 1.6378856897354126
Validation loss: 2.175465453055597

Epoch: 5| Step: 4
Training loss: 1.9437181949615479
Validation loss: 2.1622685091469878

Epoch: 5| Step: 5
Training loss: 2.7453956604003906
Validation loss: 2.1764492732222362

Epoch: 5| Step: 6
Training loss: 2.391089916229248
Validation loss: 2.180026751692577

Epoch: 5| Step: 7
Training loss: 1.998435616493225
Validation loss: 2.1705857605062504

Epoch: 5| Step: 8
Training loss: 3.001225709915161
Validation loss: 2.156865773662444

Epoch: 5| Step: 9
Training loss: 2.3889052867889404
Validation loss: 2.17725480756452

Epoch: 5| Step: 10
Training loss: 2.7529516220092773
Validation loss: 2.163834136019471

Epoch: 30| Step: 0
Training loss: 2.9896373748779297
Validation loss: 2.180302309733565

Epoch: 5| Step: 1
Training loss: 2.4819493293762207
Validation loss: 2.1640518211549327

Epoch: 5| Step: 2
Training loss: 2.260613203048706
Validation loss: 2.174944475132932

Epoch: 5| Step: 3
Training loss: 2.168627977371216
Validation loss: 2.1630390036490654

Epoch: 5| Step: 4
Training loss: 2.646862745285034
Validation loss: 2.176276678680092

Epoch: 5| Step: 5
Training loss: 2.13611102104187
Validation loss: 2.1537075914362425

Epoch: 5| Step: 6
Training loss: 2.273960590362549
Validation loss: 2.165700876584617

Epoch: 5| Step: 7
Training loss: 2.646328926086426
Validation loss: 2.1582510907162904

Epoch: 5| Step: 8
Training loss: 2.224926710128784
Validation loss: 2.176676901437903

Epoch: 5| Step: 9
Training loss: 2.114368200302124
Validation loss: 2.174218172668129

Epoch: 5| Step: 10
Training loss: 2.47257399559021
Validation loss: 2.1592088450667677

Epoch: 31| Step: 0
Training loss: 2.7412967681884766
Validation loss: 2.1624081019432313

Epoch: 5| Step: 1
Training loss: 2.1328580379486084
Validation loss: 2.156108835692047

Epoch: 5| Step: 2
Training loss: 1.974846601486206
Validation loss: 2.168008315947748

Epoch: 5| Step: 3
Training loss: 2.553466320037842
Validation loss: 2.158778070121683

Epoch: 5| Step: 4
Training loss: 1.8173977136611938
Validation loss: 2.172533994079918

Epoch: 5| Step: 5
Training loss: 2.331597089767456
Validation loss: 2.1621891298601703

Epoch: 5| Step: 6
Training loss: 2.224592685699463
Validation loss: 2.1602769897830103

Epoch: 5| Step: 7
Training loss: 2.788125514984131
Validation loss: 2.1643089825107205

Epoch: 5| Step: 8
Training loss: 3.278667449951172
Validation loss: 2.1551148391539052

Epoch: 5| Step: 9
Training loss: 2.289641857147217
Validation loss: 2.1374342954286965

Epoch: 5| Step: 10
Training loss: 2.1304612159729004
Validation loss: 2.1501503823905863

Epoch: 32| Step: 0
Training loss: 2.70405650138855
Validation loss: 2.160375331037788

Epoch: 5| Step: 1
Training loss: 2.8435261249542236
Validation loss: 2.156120382329469

Epoch: 5| Step: 2
Training loss: 1.7748994827270508
Validation loss: 2.1629224233729865

Epoch: 5| Step: 3
Training loss: 2.5802934169769287
Validation loss: 2.1589765484615038

Epoch: 5| Step: 4
Training loss: 1.8680038452148438
Validation loss: 2.163618608187604

Epoch: 5| Step: 5
Training loss: 2.399850368499756
Validation loss: 2.159375798317694

Epoch: 5| Step: 6
Training loss: 2.512693166732788
Validation loss: 2.1593390434019026

Epoch: 5| Step: 7
Training loss: 2.932044267654419
Validation loss: 2.156717615742837

Epoch: 5| Step: 8
Training loss: 2.6740427017211914
Validation loss: 2.180199065516072

Epoch: 5| Step: 9
Training loss: 1.7550128698349
Validation loss: 2.1587457938860823

Epoch: 5| Step: 10
Training loss: 2.2237257957458496
Validation loss: 2.161466254982897

Epoch: 33| Step: 0
Training loss: 2.7329726219177246
Validation loss: 2.1458746028202835

Epoch: 5| Step: 1
Training loss: 1.9233853816986084
Validation loss: 2.1532372736161753

Epoch: 5| Step: 2
Training loss: 2.1416287422180176
Validation loss: 2.1542376600286013

Epoch: 5| Step: 3
Training loss: 1.8724857568740845
Validation loss: 2.1524053927390807

Epoch: 5| Step: 4
Training loss: 3.2947819232940674
Validation loss: 2.149071337074362

Epoch: 5| Step: 5
Training loss: 2.482149839401245
Validation loss: 2.1548949262147308

Epoch: 5| Step: 6
Training loss: 2.433211088180542
Validation loss: 2.1481936682936964

Epoch: 5| Step: 7
Training loss: 2.2115163803100586
Validation loss: 2.1368769330363118

Epoch: 5| Step: 8
Training loss: 2.474119186401367
Validation loss: 2.154622954706992

Epoch: 5| Step: 9
Training loss: 2.4053094387054443
Validation loss: 2.162041364177581

Epoch: 5| Step: 10
Training loss: 2.343188524246216
Validation loss: 2.1459923610892346

Epoch: 34| Step: 0
Training loss: 2.3864293098449707
Validation loss: 2.1550066727463917

Epoch: 5| Step: 1
Training loss: 1.7171714305877686
Validation loss: 2.163854960472353

Epoch: 5| Step: 2
Training loss: 3.1313157081604004
Validation loss: 2.1512251746269966

Epoch: 5| Step: 3
Training loss: 2.462383508682251
Validation loss: 2.148222597696448

Epoch: 5| Step: 4
Training loss: 2.349412679672241
Validation loss: 2.1398597712157876

Epoch: 5| Step: 5
Training loss: 2.516711711883545
Validation loss: 2.1385945555984334

Epoch: 5| Step: 6
Training loss: 2.3364479541778564
Validation loss: 2.1525943227993545

Epoch: 5| Step: 7
Training loss: 2.8949098587036133
Validation loss: 2.143829973795081

Epoch: 5| Step: 8
Training loss: 2.4815361499786377
Validation loss: 2.1371707634259294

Epoch: 5| Step: 9
Training loss: 2.1124682426452637
Validation loss: 2.150173742284057

Epoch: 5| Step: 10
Training loss: 1.754834771156311
Validation loss: 2.128549339950726

Epoch: 35| Step: 0
Training loss: 2.747875690460205
Validation loss: 2.1386272638074812

Epoch: 5| Step: 1
Training loss: 2.3488833904266357
Validation loss: 2.1352128572361444

Epoch: 5| Step: 2
Training loss: 2.025479316711426
Validation loss: 2.1638454621837986

Epoch: 5| Step: 3
Training loss: 2.9762768745422363
Validation loss: 2.1377729087747555

Epoch: 5| Step: 4
Training loss: 2.5506720542907715
Validation loss: 2.132018055967105

Epoch: 5| Step: 5
Training loss: 2.687959671020508
Validation loss: 2.148677865664164

Epoch: 5| Step: 6
Training loss: 1.8988418579101562
Validation loss: 2.14855255106444

Epoch: 5| Step: 7
Training loss: 1.5275490283966064
Validation loss: 2.1396652780553347

Epoch: 5| Step: 8
Training loss: 2.1755950450897217
Validation loss: 2.132908045604665

Epoch: 5| Step: 9
Training loss: 2.3880467414855957
Validation loss: 2.137141372567864

Epoch: 5| Step: 10
Training loss: 3.1041817665100098
Validation loss: 2.139440933863322

Epoch: 36| Step: 0
Training loss: 2.305680513381958
Validation loss: 2.1411065516933316

Epoch: 5| Step: 1
Training loss: 1.9230769872665405
Validation loss: 2.1319940231179677

Epoch: 5| Step: 2
Training loss: 2.168621063232422
Validation loss: 2.1493197974338325

Epoch: 5| Step: 3
Training loss: 2.592825412750244
Validation loss: 2.140811886838687

Epoch: 5| Step: 4
Training loss: 2.37794828414917
Validation loss: 2.1457741952711538

Epoch: 5| Step: 5
Training loss: 2.092625141143799
Validation loss: 2.1363940674771547

Epoch: 5| Step: 6
Training loss: 2.9846034049987793
Validation loss: 2.139965113773141

Epoch: 5| Step: 7
Training loss: 2.2547340393066406
Validation loss: 2.1462334073999876

Epoch: 5| Step: 8
Training loss: 2.4478118419647217
Validation loss: 2.13558941759089

Epoch: 5| Step: 9
Training loss: 2.447841167449951
Validation loss: 2.1310200537404707

Epoch: 5| Step: 10
Training loss: 2.583458185195923
Validation loss: 2.1269038313178608

Epoch: 37| Step: 0
Training loss: 2.4959118366241455
Validation loss: 2.1260527513360463

Epoch: 5| Step: 1
Training loss: 2.8900365829467773
Validation loss: 2.1321738868631344

Epoch: 5| Step: 2
Training loss: 2.9057884216308594
Validation loss: 2.144874470208281

Epoch: 5| Step: 3
Training loss: 2.6854891777038574
Validation loss: 2.129611897212203

Epoch: 5| Step: 4
Training loss: 2.120786666870117
Validation loss: 2.135963865505752

Epoch: 5| Step: 5
Training loss: 2.428870439529419
Validation loss: 2.138912195800453

Epoch: 5| Step: 6
Training loss: 1.9025096893310547
Validation loss: 2.1446204518759124

Epoch: 5| Step: 7
Training loss: 2.1465859413146973
Validation loss: 2.1543490015050417

Epoch: 5| Step: 8
Training loss: 2.043795347213745
Validation loss: 2.143205063317412

Epoch: 5| Step: 9
Training loss: 1.8842353820800781
Validation loss: 2.1390547367834274

Epoch: 5| Step: 10
Training loss: 2.7036149501800537
Validation loss: 2.1183368108605825

Epoch: 38| Step: 0
Training loss: 3.0502028465270996
Validation loss: 2.1185682076279835

Epoch: 5| Step: 1
Training loss: 2.4081883430480957
Validation loss: 2.135775516110082

Epoch: 5| Step: 2
Training loss: 1.9715064764022827
Validation loss: 2.1252614451992895

Epoch: 5| Step: 3
Training loss: 2.3638367652893066
Validation loss: 2.1306108556767946

Epoch: 5| Step: 4
Training loss: 2.2027714252471924
Validation loss: 2.1403306812368412

Epoch: 5| Step: 5
Training loss: 2.2723193168640137
Validation loss: 2.1289523096494776

Epoch: 5| Step: 6
Training loss: 2.158782958984375
Validation loss: 2.1409975303116666

Epoch: 5| Step: 7
Training loss: 2.4508137702941895
Validation loss: 2.126528247710197

Epoch: 5| Step: 8
Training loss: 2.6968140602111816
Validation loss: 2.133564054325063

Epoch: 5| Step: 9
Training loss: 2.191887378692627
Validation loss: 2.1305285692214966

Epoch: 5| Step: 10
Training loss: 2.2134673595428467
Validation loss: 2.1284997975954445

Epoch: 39| Step: 0
Training loss: 1.6496703624725342
Validation loss: 2.1417935330380677

Epoch: 5| Step: 1
Training loss: 2.5382871627807617
Validation loss: 2.1236561408606907

Epoch: 5| Step: 2
Training loss: 2.288780689239502
Validation loss: 2.1258961282750612

Epoch: 5| Step: 3
Training loss: 2.5646677017211914
Validation loss: 2.144234052268408

Epoch: 5| Step: 4
Training loss: 2.262782335281372
Validation loss: 2.133909620264525

Epoch: 5| Step: 5
Training loss: 1.7139384746551514
Validation loss: 2.1239276983404674

Epoch: 5| Step: 6
Training loss: 2.6135315895080566
Validation loss: 2.1362236776659564

Epoch: 5| Step: 7
Training loss: 2.9642345905303955
Validation loss: 2.122263644331245

Epoch: 5| Step: 8
Training loss: 2.519839286804199
Validation loss: 2.1168285082745295

Epoch: 5| Step: 9
Training loss: 2.1588754653930664
Validation loss: 2.1159609697198354

Epoch: 5| Step: 10
Training loss: 2.7496421337127686
Validation loss: 2.1253070216025076

Epoch: 40| Step: 0
Training loss: 2.732412576675415
Validation loss: 2.120661868843981

Epoch: 5| Step: 1
Training loss: 2.4435458183288574
Validation loss: 2.122175437147899

Epoch: 5| Step: 2
Training loss: 1.6977428197860718
Validation loss: 2.1368804003602717

Epoch: 5| Step: 3
Training loss: 2.184365749359131
Validation loss: 2.12042022520496

Epoch: 5| Step: 4
Training loss: 2.2691705226898193
Validation loss: 2.130120467114192

Epoch: 5| Step: 5
Training loss: 2.32165265083313
Validation loss: 2.1057390333503805

Epoch: 5| Step: 6
Training loss: 2.155881881713867
Validation loss: 2.114826685638838

Epoch: 5| Step: 7
Training loss: 2.633857011795044
Validation loss: 2.1094969216213433

Epoch: 5| Step: 8
Training loss: 2.550509214401245
Validation loss: 2.1150459474132908

Epoch: 5| Step: 9
Training loss: 2.248847484588623
Validation loss: 2.129350654540523

Epoch: 5| Step: 10
Training loss: 2.7741456031799316
Validation loss: 2.1220386617927143

Epoch: 41| Step: 0
Training loss: 2.4661476612091064
Validation loss: 2.1322177994635796

Epoch: 5| Step: 1
Training loss: 3.2651801109313965
Validation loss: 2.1251081497438493

Epoch: 5| Step: 2
Training loss: 2.7417588233947754
Validation loss: 2.1172122134957263

Epoch: 5| Step: 3
Training loss: 1.689771294593811
Validation loss: 2.127483976784573

Epoch: 5| Step: 4
Training loss: 2.216404914855957
Validation loss: 2.116025476045506

Epoch: 5| Step: 5
Training loss: 2.0002615451812744
Validation loss: 2.1209891073165403

Epoch: 5| Step: 6
Training loss: 2.0206408500671387
Validation loss: 2.1216693065499745

Epoch: 5| Step: 7
Training loss: 2.380406379699707
Validation loss: 2.1190119866401917

Epoch: 5| Step: 8
Training loss: 2.0653367042541504
Validation loss: 2.13493981540844

Epoch: 5| Step: 9
Training loss: 2.475498676300049
Validation loss: 2.1219242811203003

Epoch: 5| Step: 10
Training loss: 2.6972761154174805
Validation loss: 2.1063417311637633

Epoch: 42| Step: 0
Training loss: 2.5546936988830566
Validation loss: 2.107401878603043

Epoch: 5| Step: 1
Training loss: 2.7332963943481445
Validation loss: 2.1277801221416843

Epoch: 5| Step: 2
Training loss: 2.3067455291748047
Validation loss: 2.11745459418143

Epoch: 5| Step: 3
Training loss: 2.6055026054382324
Validation loss: 2.113179252993676

Epoch: 5| Step: 4
Training loss: 2.5159053802490234
Validation loss: 2.122901537085092

Epoch: 5| Step: 5
Training loss: 1.7466888427734375
Validation loss: 2.115281343460083

Epoch: 5| Step: 6
Training loss: 2.1245882511138916
Validation loss: 2.117085228684128

Epoch: 5| Step: 7
Training loss: 2.1357455253601074
Validation loss: 2.1091839703180457

Epoch: 5| Step: 8
Training loss: 2.0740225315093994
Validation loss: 2.1217297994962303

Epoch: 5| Step: 9
Training loss: 2.7233242988586426
Validation loss: 2.1159204667614353

Epoch: 5| Step: 10
Training loss: 2.4931392669677734
Validation loss: 2.1255549525701873

Epoch: 43| Step: 0
Training loss: 2.1289243698120117
Validation loss: 2.125686317361811

Epoch: 5| Step: 1
Training loss: 2.7233622074127197
Validation loss: 2.112131723793604

Epoch: 5| Step: 2
Training loss: 2.6199939250946045
Validation loss: 2.1157417579363753

Epoch: 5| Step: 3
Training loss: 1.7858136892318726
Validation loss: 2.1108269255648375

Epoch: 5| Step: 4
Training loss: 2.0941405296325684
Validation loss: 2.12056532982857

Epoch: 5| Step: 5
Training loss: 2.514786958694458
Validation loss: 2.105343505900393

Epoch: 5| Step: 6
Training loss: 2.6793034076690674
Validation loss: 2.120365327404391

Epoch: 5| Step: 7
Training loss: 1.9893274307250977
Validation loss: 2.1206745486105643

Epoch: 5| Step: 8
Training loss: 2.77396821975708
Validation loss: 2.111783495513342

Epoch: 5| Step: 9
Training loss: 2.6145780086517334
Validation loss: 2.125417827278055

Epoch: 5| Step: 10
Training loss: 1.837962031364441
Validation loss: 2.114856449506616

Epoch: 44| Step: 0
Training loss: 2.188961982727051
Validation loss: 2.1088061358339045

Epoch: 5| Step: 1
Training loss: 2.5493788719177246
Validation loss: 2.1066069346602245

Epoch: 5| Step: 2
Training loss: 2.1099541187286377
Validation loss: 2.11124147394652

Epoch: 5| Step: 3
Training loss: 2.668410539627075
Validation loss: 2.1221350944170387

Epoch: 5| Step: 4
Training loss: 2.076751470565796
Validation loss: 2.0921842154636177

Epoch: 5| Step: 5
Training loss: 2.7294182777404785
Validation loss: 2.1102010152673207

Epoch: 5| Step: 6
Training loss: 2.3273491859436035
Validation loss: 2.100409112950807

Epoch: 5| Step: 7
Training loss: 2.031637191772461
Validation loss: 2.132709495482906

Epoch: 5| Step: 8
Training loss: 2.5103461742401123
Validation loss: 2.098002843959357

Epoch: 5| Step: 9
Training loss: 1.9061501026153564
Validation loss: 2.098241823975758

Epoch: 5| Step: 10
Training loss: 2.6874401569366455
Validation loss: 2.112803433531074

Epoch: 45| Step: 0
Training loss: 1.9603240489959717
Validation loss: 2.1012269578954226

Epoch: 5| Step: 1
Training loss: 2.181750535964966
Validation loss: 2.103449039561774

Epoch: 5| Step: 2
Training loss: 3.067047595977783
Validation loss: 2.1084149396547707

Epoch: 5| Step: 3
Training loss: 2.2884278297424316
Validation loss: 2.104986298468805

Epoch: 5| Step: 4
Training loss: 2.73614764213562
Validation loss: 2.0942906295099566

Epoch: 5| Step: 5
Training loss: 2.397327423095703
Validation loss: 2.1007185777028403

Epoch: 5| Step: 6
Training loss: 2.168030261993408
Validation loss: 2.1076346802455124

Epoch: 5| Step: 7
Training loss: 2.0296473503112793
Validation loss: 2.099987978576332

Epoch: 5| Step: 8
Training loss: 2.1329760551452637
Validation loss: 2.1133409930813696

Epoch: 5| Step: 9
Training loss: 2.4924633502960205
Validation loss: 2.099111005824099

Epoch: 5| Step: 10
Training loss: 2.367022752761841
Validation loss: 2.111544762888262

Epoch: 46| Step: 0
Training loss: 1.915004014968872
Validation loss: 2.0947089272160686

Epoch: 5| Step: 1
Training loss: 2.5471272468566895
Validation loss: 2.1021586618115826

Epoch: 5| Step: 2
Training loss: 2.4644062519073486
Validation loss: 2.0832389939215874

Epoch: 5| Step: 3
Training loss: 2.4639201164245605
Validation loss: 2.0944202023167766

Epoch: 5| Step: 4
Training loss: 2.123849391937256
Validation loss: 2.0982103860506447

Epoch: 5| Step: 5
Training loss: 2.653437376022339
Validation loss: 2.0939987654327066

Epoch: 5| Step: 6
Training loss: 1.9722251892089844
Validation loss: 2.121169541471748

Epoch: 5| Step: 7
Training loss: 2.7279257774353027
Validation loss: 2.1171152642978135

Epoch: 5| Step: 8
Training loss: 2.262512445449829
Validation loss: 2.108143009165282

Epoch: 5| Step: 9
Training loss: 2.198695421218872
Validation loss: 2.0976135423106532

Epoch: 5| Step: 10
Training loss: 2.596853017807007
Validation loss: 2.1108774190307944

Epoch: 47| Step: 0
Training loss: 1.7439649105072021
Validation loss: 2.1040504965730893

Epoch: 5| Step: 1
Training loss: 2.918147563934326
Validation loss: 2.09921528959787

Epoch: 5| Step: 2
Training loss: 2.1948800086975098
Validation loss: 2.1207934656450824

Epoch: 5| Step: 3
Training loss: 2.3204123973846436
Validation loss: 2.105828541581349

Epoch: 5| Step: 4
Training loss: 2.242872714996338
Validation loss: 2.096746888211978

Epoch: 5| Step: 5
Training loss: 1.793060302734375
Validation loss: 2.0969303577176985

Epoch: 5| Step: 6
Training loss: 2.834531307220459
Validation loss: 2.099977049776303

Epoch: 5| Step: 7
Training loss: 2.023632049560547
Validation loss: 2.102828944883039

Epoch: 5| Step: 8
Training loss: 2.419922113418579
Validation loss: 2.108018862303867

Epoch: 5| Step: 9
Training loss: 2.6569695472717285
Validation loss: 2.110731763224448

Epoch: 5| Step: 10
Training loss: 2.645686388015747
Validation loss: 2.121649960035919

Epoch: 48| Step: 0
Training loss: 2.9040255546569824
Validation loss: 2.111880047346956

Epoch: 5| Step: 1
Training loss: 2.2875113487243652
Validation loss: 2.106253595762355

Epoch: 5| Step: 2
Training loss: 2.184939384460449
Validation loss: 2.105464936584555

Epoch: 5| Step: 3
Training loss: 2.2593398094177246
Validation loss: 2.104282147140913

Epoch: 5| Step: 4
Training loss: 2.625093460083008
Validation loss: 2.08726183829769

Epoch: 5| Step: 5
Training loss: 1.9234931468963623
Validation loss: 2.09261017845523

Epoch: 5| Step: 6
Training loss: 1.7689024209976196
Validation loss: 2.0943801774773547

Epoch: 5| Step: 7
Training loss: 2.305473804473877
Validation loss: 2.097979332811089

Epoch: 5| Step: 8
Training loss: 2.865226984024048
Validation loss: 2.096389134724935

Epoch: 5| Step: 9
Training loss: 2.240323305130005
Validation loss: 2.0909812476045344

Epoch: 5| Step: 10
Training loss: 2.2533302307128906
Validation loss: 2.106890978351716

Epoch: 49| Step: 0
Training loss: 2.234774351119995
Validation loss: 2.0988846120013984

Epoch: 5| Step: 1
Training loss: 2.3600878715515137
Validation loss: 2.0888844356741956

Epoch: 5| Step: 2
Training loss: 2.2273011207580566
Validation loss: 2.096598357282659

Epoch: 5| Step: 3
Training loss: 3.3339240550994873
Validation loss: 2.092106646107089

Epoch: 5| Step: 4
Training loss: 2.1785683631896973
Validation loss: 2.088864098313034

Epoch: 5| Step: 5
Training loss: 1.6547826528549194
Validation loss: 2.09526147637316

Epoch: 5| Step: 6
Training loss: 2.1018528938293457
Validation loss: 2.094234307607015

Epoch: 5| Step: 7
Training loss: 2.2904152870178223
Validation loss: 2.090776728045556

Epoch: 5| Step: 8
Training loss: 2.1181960105895996
Validation loss: 2.0877747535705566

Epoch: 5| Step: 9
Training loss: 2.632915496826172
Validation loss: 2.1098565375933083

Epoch: 5| Step: 10
Training loss: 2.6092658042907715
Validation loss: 2.088903638624376

Epoch: 50| Step: 0
Training loss: 2.9356589317321777
Validation loss: 2.0784788054804646

Epoch: 5| Step: 1
Training loss: 1.947991132736206
Validation loss: 2.0985418660666353

Epoch: 5| Step: 2
Training loss: 2.373356342315674
Validation loss: 2.1032456428773942

Epoch: 5| Step: 3
Training loss: 2.870257616043091
Validation loss: 2.1192447370098484

Epoch: 5| Step: 4
Training loss: 2.294039249420166
Validation loss: 2.0913062839097876

Epoch: 5| Step: 5
Training loss: 2.3885915279388428
Validation loss: 2.098600831083072

Epoch: 5| Step: 6
Training loss: 1.5333755016326904
Validation loss: 2.1032837821591284

Epoch: 5| Step: 7
Training loss: 2.2507057189941406
Validation loss: 2.090188559665475

Epoch: 5| Step: 8
Training loss: 2.4539618492126465
Validation loss: 2.101567465771911

Epoch: 5| Step: 9
Training loss: 2.221006393432617
Validation loss: 2.099375758119809

Epoch: 5| Step: 10
Training loss: 2.3017568588256836
Validation loss: 2.1034401591106127

Epoch: 51| Step: 0
Training loss: 2.5220284461975098
Validation loss: 2.09425530382382

Epoch: 5| Step: 1
Training loss: 2.0751898288726807
Validation loss: 2.0927487304133754

Epoch: 5| Step: 2
Training loss: 3.106785535812378
Validation loss: 2.0924428355309272

Epoch: 5| Step: 3
Training loss: 2.7471747398376465
Validation loss: 2.1197604440873667

Epoch: 5| Step: 4
Training loss: 2.005702257156372
Validation loss: 2.092077875650057

Epoch: 5| Step: 5
Training loss: 2.2002360820770264
Validation loss: 2.0906178284716863

Epoch: 5| Step: 6
Training loss: 2.4434285163879395
Validation loss: 2.10145898531842

Epoch: 5| Step: 7
Training loss: 1.8690592050552368
Validation loss: 2.0758120641913465

Epoch: 5| Step: 8
Training loss: 1.9021943807601929
Validation loss: 2.0936578294282318

Epoch: 5| Step: 9
Training loss: 2.018497943878174
Validation loss: 2.089372727178758

Epoch: 5| Step: 10
Training loss: 2.7160773277282715
Validation loss: 2.0897625338646675

Epoch: 52| Step: 0
Training loss: 1.957330346107483
Validation loss: 2.0931672268016364

Epoch: 5| Step: 1
Training loss: 2.5995869636535645
Validation loss: 2.093858116416521

Epoch: 5| Step: 2
Training loss: 1.934494972229004
Validation loss: 2.0880198991426857

Epoch: 5| Step: 3
Training loss: 1.8905298709869385
Validation loss: 2.0948421852563017

Epoch: 5| Step: 4
Training loss: 2.93202543258667
Validation loss: 2.0974358320236206

Epoch: 5| Step: 5
Training loss: 1.9559171199798584
Validation loss: 2.0981496405857865

Epoch: 5| Step: 6
Training loss: 2.3356306552886963
Validation loss: 2.087552685891428

Epoch: 5| Step: 7
Training loss: 2.7361807823181152
Validation loss: 2.100405793036184

Epoch: 5| Step: 8
Training loss: 2.02392315864563
Validation loss: 2.099048855484173

Epoch: 5| Step: 9
Training loss: 2.800863742828369
Validation loss: 2.093149697908791

Epoch: 5| Step: 10
Training loss: 2.3643808364868164
Validation loss: 2.0735040556999946

Epoch: 53| Step: 0
Training loss: 2.366563558578491
Validation loss: 2.099402594309981

Epoch: 5| Step: 1
Training loss: 1.6528946161270142
Validation loss: 2.109193378879178

Epoch: 5| Step: 2
Training loss: 2.5578877925872803
Validation loss: 2.0823346248237034

Epoch: 5| Step: 3
Training loss: 1.910794973373413
Validation loss: 2.0917089510989446

Epoch: 5| Step: 4
Training loss: 2.598073720932007
Validation loss: 2.0941807659723426

Epoch: 5| Step: 5
Training loss: 2.4232614040374756
Validation loss: 2.105156993353239

Epoch: 5| Step: 6
Training loss: 2.3772385120391846
Validation loss: 2.1021306117375693

Epoch: 5| Step: 7
Training loss: 2.68330979347229
Validation loss: 2.0934005078449043

Epoch: 5| Step: 8
Training loss: 2.0727334022521973
Validation loss: 2.0732951369336856

Epoch: 5| Step: 9
Training loss: 3.1279091835021973
Validation loss: 2.0976178799906084

Epoch: 5| Step: 10
Training loss: 1.538859248161316
Validation loss: 2.0775994921243317

Epoch: 54| Step: 0
Training loss: 2.9855659008026123
Validation loss: 2.093577136275589

Epoch: 5| Step: 1
Training loss: 2.9097297191619873
Validation loss: 2.083229702006104

Epoch: 5| Step: 2
Training loss: 1.6180469989776611
Validation loss: 2.0938517688423075

Epoch: 5| Step: 3
Training loss: 2.250145435333252
Validation loss: 2.1107716906455254

Epoch: 5| Step: 4
Training loss: 1.756807565689087
Validation loss: 2.0832018724051853

Epoch: 5| Step: 5
Training loss: 2.8666014671325684
Validation loss: 2.0833646994765087

Epoch: 5| Step: 6
Training loss: 2.3622043132781982
Validation loss: 2.102829440947502

Epoch: 5| Step: 7
Training loss: 2.5230956077575684
Validation loss: 2.082570623326045

Epoch: 5| Step: 8
Training loss: 2.226022481918335
Validation loss: 2.082394173068385

Epoch: 5| Step: 9
Training loss: 1.717458724975586
Validation loss: 2.0913610689101683

Epoch: 5| Step: 10
Training loss: 2.2679972648620605
Validation loss: 2.0841593665461384

Epoch: 55| Step: 0
Training loss: 2.7567131519317627
Validation loss: 2.0773423884504583

Epoch: 5| Step: 1
Training loss: 1.923837661743164
Validation loss: 2.0935374844458794

Epoch: 5| Step: 2
Training loss: 2.5000617504119873
Validation loss: 2.089256096911687

Epoch: 5| Step: 3
Training loss: 1.9959526062011719
Validation loss: 2.0910897254943848

Epoch: 5| Step: 4
Training loss: 1.7640297412872314
Validation loss: 2.0936567514173445

Epoch: 5| Step: 5
Training loss: 2.4955296516418457
Validation loss: 2.0759257193534606

Epoch: 5| Step: 6
Training loss: 2.370759963989258
Validation loss: 2.091374692096505

Epoch: 5| Step: 7
Training loss: 2.4089388847351074
Validation loss: 2.0969413864997124

Epoch: 5| Step: 8
Training loss: 2.287951707839966
Validation loss: 2.0778204420561432

Epoch: 5| Step: 9
Training loss: 2.5480356216430664
Validation loss: 2.0982415471025693

Epoch: 5| Step: 10
Training loss: 2.2833666801452637
Validation loss: 2.0881923655027985

Epoch: 56| Step: 0
Training loss: 1.9612846374511719
Validation loss: 2.0959692565343713

Epoch: 5| Step: 1
Training loss: 2.530829429626465
Validation loss: 2.0958014252365276

Epoch: 5| Step: 2
Training loss: 1.8652623891830444
Validation loss: 2.087229016006634

Epoch: 5| Step: 3
Training loss: 2.4448554515838623
Validation loss: 2.093194079655473

Epoch: 5| Step: 4
Training loss: 2.1506776809692383
Validation loss: 2.089097199901458

Epoch: 5| Step: 5
Training loss: 3.047330379486084
Validation loss: 2.077348824470274

Epoch: 5| Step: 6
Training loss: 2.561162233352661
Validation loss: 2.110333619579192

Epoch: 5| Step: 7
Training loss: 2.2335963249206543
Validation loss: 2.0927308759381695

Epoch: 5| Step: 8
Training loss: 2.265552282333374
Validation loss: 2.0793265270930466

Epoch: 5| Step: 9
Training loss: 1.969577431678772
Validation loss: 2.1004044061066

Epoch: 5| Step: 10
Training loss: 2.297057867050171
Validation loss: 2.088829130254766

Epoch: 57| Step: 0
Training loss: 1.8225034475326538
Validation loss: 2.0809886147899013

Epoch: 5| Step: 1
Training loss: 2.027428388595581
Validation loss: 2.0925871390168385

Epoch: 5| Step: 2
Training loss: 2.4841885566711426
Validation loss: 2.1058602358705256

Epoch: 5| Step: 3
Training loss: 2.4163906574249268
Validation loss: 2.0841745958533338

Epoch: 5| Step: 4
Training loss: 2.335951328277588
Validation loss: 2.0895504259294078

Epoch: 5| Step: 5
Training loss: 2.682711124420166
Validation loss: 2.1015816221955004

Epoch: 5| Step: 6
Training loss: 1.6301212310791016
Validation loss: 2.0864193516392864

Epoch: 5| Step: 7
Training loss: 2.898120880126953
Validation loss: 2.0868880133475027

Epoch: 5| Step: 8
Training loss: 3.262331485748291
Validation loss: 2.093427636290109

Epoch: 5| Step: 9
Training loss: 1.6462751626968384
Validation loss: 2.0801894959583076

Epoch: 5| Step: 10
Training loss: 2.04951810836792
Validation loss: 2.099809738897508

Epoch: 58| Step: 0
Training loss: 2.217766046524048
Validation loss: 2.079453335013441

Epoch: 5| Step: 1
Training loss: 1.9466699361801147
Validation loss: 2.094401501840161

Epoch: 5| Step: 2
Training loss: 2.3315939903259277
Validation loss: 2.088345411003277

Epoch: 5| Step: 3
Training loss: 2.5482192039489746
Validation loss: 2.0793231418055873

Epoch: 5| Step: 4
Training loss: 2.9311842918395996
Validation loss: 2.0826694426998014

Epoch: 5| Step: 5
Training loss: 2.106732130050659
Validation loss: 2.078722628214026

Epoch: 5| Step: 6
Training loss: 1.3773925304412842
Validation loss: 2.084240221208142

Epoch: 5| Step: 7
Training loss: 2.297517776489258
Validation loss: 2.0911142441534225

Epoch: 5| Step: 8
Training loss: 2.6252055168151855
Validation loss: 2.1100388931971725

Epoch: 5| Step: 9
Training loss: 2.6891517639160156
Validation loss: 2.09022759109415

Epoch: 5| Step: 10
Training loss: 2.2889184951782227
Validation loss: 2.0747602024386005

Epoch: 59| Step: 0
Training loss: 2.6009087562561035
Validation loss: 2.0764475509684575

Epoch: 5| Step: 1
Training loss: 2.7147326469421387
Validation loss: 2.0971396956392514

Epoch: 5| Step: 2
Training loss: 1.9536380767822266
Validation loss: 2.08425485703253

Epoch: 5| Step: 3
Training loss: 1.7763001918792725
Validation loss: 2.0736609556341685

Epoch: 5| Step: 4
Training loss: 2.484621047973633
Validation loss: 2.0705042269922074

Epoch: 5| Step: 5
Training loss: 2.263305187225342
Validation loss: 2.0856164886105444

Epoch: 5| Step: 6
Training loss: 2.505763292312622
Validation loss: 2.0839637556383686

Epoch: 5| Step: 7
Training loss: 2.927161693572998
Validation loss: 2.0888872031242616

Epoch: 5| Step: 8
Training loss: 1.5712143182754517
Validation loss: 2.0761794864490466

Epoch: 5| Step: 9
Training loss: 2.634571075439453
Validation loss: 2.10403617735832

Epoch: 5| Step: 10
Training loss: 1.8424433469772339
Validation loss: 2.0988369500765236

Epoch: 60| Step: 0
Training loss: 1.7439922094345093
Validation loss: 2.1043010911633893

Epoch: 5| Step: 1
Training loss: 2.4769208431243896
Validation loss: 2.075442023174737

Epoch: 5| Step: 2
Training loss: 2.285210132598877
Validation loss: 2.080923929009386

Epoch: 5| Step: 3
Training loss: 2.795715808868408
Validation loss: 2.0926674283960813

Epoch: 5| Step: 4
Training loss: 2.4100630283355713
Validation loss: 2.08378436744854

Epoch: 5| Step: 5
Training loss: 3.0747227668762207
Validation loss: 2.087198774019877

Epoch: 5| Step: 6
Training loss: 2.1949100494384766
Validation loss: 2.0936647781761746

Epoch: 5| Step: 7
Training loss: 1.8010485172271729
Validation loss: 2.088268874793924

Epoch: 5| Step: 8
Training loss: 1.8609046936035156
Validation loss: 2.0778901910269134

Epoch: 5| Step: 9
Training loss: 2.268653392791748
Validation loss: 2.1056903228964856

Epoch: 5| Step: 10
Training loss: 2.3499817848205566
Validation loss: 2.0967041061770533

Epoch: 61| Step: 0
Training loss: 1.7294689416885376
Validation loss: 2.070938297497329

Epoch: 5| Step: 1
Training loss: 2.184163808822632
Validation loss: 2.0907706842627576

Epoch: 5| Step: 2
Training loss: 2.713982582092285
Validation loss: 2.081575609022571

Epoch: 5| Step: 3
Training loss: 2.456920623779297
Validation loss: 2.0928796888679586

Epoch: 5| Step: 4
Training loss: 2.7086703777313232
Validation loss: 2.0937160676525486

Epoch: 5| Step: 5
Training loss: 2.660562515258789
Validation loss: 2.0995230200470134

Epoch: 5| Step: 6
Training loss: 1.8632720708847046
Validation loss: 2.0934219206533125

Epoch: 5| Step: 7
Training loss: 2.3479275703430176
Validation loss: 2.086124725239251

Epoch: 5| Step: 8
Training loss: 2.218684673309326
Validation loss: 2.081023557211763

Epoch: 5| Step: 9
Training loss: 2.392024278640747
Validation loss: 2.092482700142809

Epoch: 5| Step: 10
Training loss: 1.9064829349517822
Validation loss: 2.07209510700677

Epoch: 62| Step: 0
Training loss: 2.327230930328369
Validation loss: 2.0917148782360937

Epoch: 5| Step: 1
Training loss: 1.8853418827056885
Validation loss: 2.0707239745765604

Epoch: 5| Step: 2
Training loss: 2.2131054401397705
Validation loss: 2.0665551206117034

Epoch: 5| Step: 3
Training loss: 2.388803720474243
Validation loss: 2.092569287105273

Epoch: 5| Step: 4
Training loss: 1.850492238998413
Validation loss: 2.083149681809128

Epoch: 5| Step: 5
Training loss: 2.060429334640503
Validation loss: 2.1075472511270994

Epoch: 5| Step: 6
Training loss: 2.2417845726013184
Validation loss: 2.0784423018014557

Epoch: 5| Step: 7
Training loss: 2.5109307765960693
Validation loss: 2.0738858843362458

Epoch: 5| Step: 8
Training loss: 3.2530722618103027
Validation loss: 2.0886121821659867

Epoch: 5| Step: 9
Training loss: 1.730812430381775
Validation loss: 2.088083804294627

Epoch: 5| Step: 10
Training loss: 2.747124671936035
Validation loss: 2.073222485921716

Epoch: 63| Step: 0
Training loss: 2.6830763816833496
Validation loss: 2.0928521592129945

Epoch: 5| Step: 1
Training loss: 1.886073350906372
Validation loss: 2.079843783891329

Epoch: 5| Step: 2
Training loss: 1.5752826929092407
Validation loss: 2.0688626817477647

Epoch: 5| Step: 3
Training loss: 2.6201367378234863
Validation loss: 2.1070663313711844

Epoch: 5| Step: 4
Training loss: 3.0754687786102295
Validation loss: 2.0888119923171176

Epoch: 5| Step: 5
Training loss: 2.5873453617095947
Validation loss: 2.079927364985148

Epoch: 5| Step: 6
Training loss: 1.7765926122665405
Validation loss: 2.09495525206289

Epoch: 5| Step: 7
Training loss: 2.1618287563323975
Validation loss: 2.0923833872682307

Epoch: 5| Step: 8
Training loss: 1.9005043506622314
Validation loss: 2.0839210748672485

Epoch: 5| Step: 9
Training loss: 2.291229009628296
Validation loss: 2.080855811795881

Epoch: 5| Step: 10
Training loss: 2.6178762912750244
Validation loss: 2.098370373889964

Epoch: 64| Step: 0
Training loss: 2.5609450340270996
Validation loss: 2.0787916132198867

Epoch: 5| Step: 1
Training loss: 2.3928120136260986
Validation loss: 2.0817131996154785

Epoch: 5| Step: 2
Training loss: 2.8432915210723877
Validation loss: 2.072235104858234

Epoch: 5| Step: 3
Training loss: 2.165884256362915
Validation loss: 2.0761367787597

Epoch: 5| Step: 4
Training loss: 1.9277493953704834
Validation loss: 2.0845967992659538

Epoch: 5| Step: 5
Training loss: 2.1205430030822754
Validation loss: 2.075943011109547

Epoch: 5| Step: 6
Training loss: 1.7779476642608643
Validation loss: 2.089085368699925

Epoch: 5| Step: 7
Training loss: 2.2310128211975098
Validation loss: 2.072510107871025

Epoch: 5| Step: 8
Training loss: 2.413970470428467
Validation loss: 2.1010207001880934

Epoch: 5| Step: 9
Training loss: 1.6377332210540771
Validation loss: 2.065348227818807

Epoch: 5| Step: 10
Training loss: 3.1309680938720703
Validation loss: 2.0944557702669533

Epoch: 65| Step: 0
Training loss: 2.07438588142395
Validation loss: 2.0929512285417124

Epoch: 5| Step: 1
Training loss: 2.339938163757324
Validation loss: 2.0973700925868046

Epoch: 5| Step: 2
Training loss: 1.9553207159042358
Validation loss: 2.0834495867452314

Epoch: 5| Step: 3
Training loss: 2.0801262855529785
Validation loss: 2.081429293078761

Epoch: 5| Step: 4
Training loss: 2.4892420768737793
Validation loss: 2.101583183452647

Epoch: 5| Step: 5
Training loss: 2.2289175987243652
Validation loss: 2.0954399826706096

Epoch: 5| Step: 6
Training loss: 2.537104845046997
Validation loss: 2.0755012881371284

Epoch: 5| Step: 7
Training loss: 2.2788119316101074
Validation loss: 2.0891703636415544

Epoch: 5| Step: 8
Training loss: 1.4432885646820068
Validation loss: 2.0847095135719544

Epoch: 5| Step: 9
Training loss: 2.9830687046051025
Validation loss: 2.087782529092604

Epoch: 5| Step: 10
Training loss: 2.5069830417633057
Validation loss: 2.084962985848868

Epoch: 66| Step: 0
Training loss: 2.5123960971832275
Validation loss: 2.08783463252488

Epoch: 5| Step: 1
Training loss: 2.085721969604492
Validation loss: 2.0952721847000944

Epoch: 5| Step: 2
Training loss: 2.275359630584717
Validation loss: 2.1105636191624466

Epoch: 5| Step: 3
Training loss: 2.059842586517334
Validation loss: 2.0970398021000687

Epoch: 5| Step: 4
Training loss: 2.7346863746643066
Validation loss: 2.0987390266951693

Epoch: 5| Step: 5
Training loss: 2.1944851875305176
Validation loss: 2.0889209547350482

Epoch: 5| Step: 6
Training loss: 1.891571044921875
Validation loss: 2.0783722836484193

Epoch: 5| Step: 7
Training loss: 2.6383955478668213
Validation loss: 2.077638456898351

Epoch: 5| Step: 8
Training loss: 2.5496115684509277
Validation loss: 2.083084411518548

Epoch: 5| Step: 9
Training loss: 2.127061367034912
Validation loss: 2.1031897196205716

Epoch: 5| Step: 10
Training loss: 1.9599963426589966
Validation loss: 2.0971634849425285

Epoch: 67| Step: 0
Training loss: 1.673926591873169
Validation loss: 2.0875826035776446

Epoch: 5| Step: 1
Training loss: 2.5330586433410645
Validation loss: 2.0737385160179547

Epoch: 5| Step: 2
Training loss: 2.1486012935638428
Validation loss: 2.083309212038594

Epoch: 5| Step: 3
Training loss: 2.671459913253784
Validation loss: 2.109930076906758

Epoch: 5| Step: 4
Training loss: 2.457475185394287
Validation loss: 2.0784557775784562

Epoch: 5| Step: 5
Training loss: 1.9603633880615234
Validation loss: 2.1043155577874955

Epoch: 5| Step: 6
Training loss: 2.5717363357543945
Validation loss: 2.08879695400115

Epoch: 5| Step: 7
Training loss: 2.3297691345214844
Validation loss: 2.0829297188789613

Epoch: 5| Step: 8
Training loss: 2.4869637489318848
Validation loss: 2.0867143754036195

Epoch: 5| Step: 9
Training loss: 2.069941282272339
Validation loss: 2.082092217219773

Epoch: 5| Step: 10
Training loss: 2.10249924659729
Validation loss: 2.090977866162536

Epoch: 68| Step: 0
Training loss: 2.6014037132263184
Validation loss: 2.0941403245413177

Epoch: 5| Step: 1
Training loss: 2.1740851402282715
Validation loss: 2.0866471875098442

Epoch: 5| Step: 2
Training loss: 2.7351577281951904
Validation loss: 2.0900630156199136

Epoch: 5| Step: 3
Training loss: 2.2045555114746094
Validation loss: 2.094263440819197

Epoch: 5| Step: 4
Training loss: 1.7943439483642578
Validation loss: 2.0802665448957876

Epoch: 5| Step: 5
Training loss: 2.76796293258667
Validation loss: 2.0846078421479914

Epoch: 5| Step: 6
Training loss: 1.9544789791107178
Validation loss: 2.089200629982897

Epoch: 5| Step: 7
Training loss: 2.074918031692505
Validation loss: 2.08600736946188

Epoch: 5| Step: 8
Training loss: 2.0079474449157715
Validation loss: 2.0948946681073917

Epoch: 5| Step: 9
Training loss: 2.6106464862823486
Validation loss: 2.093560790502897

Epoch: 5| Step: 10
Training loss: 1.9253416061401367
Validation loss: 2.0799131701069493

Epoch: 69| Step: 0
Training loss: 2.313493013381958
Validation loss: 2.092611571793915

Epoch: 5| Step: 1
Training loss: 2.3370728492736816
Validation loss: 2.07876056496815

Epoch: 5| Step: 2
Training loss: 2.162165880203247
Validation loss: 2.084108475715883

Epoch: 5| Step: 3
Training loss: 2.2255733013153076
Validation loss: 2.0889744630423923

Epoch: 5| Step: 4
Training loss: 2.019623279571533
Validation loss: 2.0902577997535787

Epoch: 5| Step: 5
Training loss: 2.9370388984680176
Validation loss: 2.0868242222775697

Epoch: 5| Step: 6
Training loss: 2.157681703567505
Validation loss: 2.092189609363515

Epoch: 5| Step: 7
Training loss: 2.4290642738342285
Validation loss: 2.0862626875600507

Epoch: 5| Step: 8
Training loss: 2.332228422164917
Validation loss: 2.079602749116959

Epoch: 5| Step: 9
Training loss: 2.264544725418091
Validation loss: 2.0763224478690856

Epoch: 5| Step: 10
Training loss: 1.8739227056503296
Validation loss: 2.0909134136733187

Epoch: 70| Step: 0
Training loss: 2.1869914531707764
Validation loss: 2.0899294986519763

Epoch: 5| Step: 1
Training loss: 2.249399185180664
Validation loss: 2.0817718146949686

Epoch: 5| Step: 2
Training loss: 2.221724033355713
Validation loss: 2.0874966241980113

Epoch: 5| Step: 3
Training loss: 2.305661678314209
Validation loss: 2.070842919811126

Epoch: 5| Step: 4
Training loss: 2.3709285259246826
Validation loss: 2.0901476413972917

Epoch: 5| Step: 5
Training loss: 2.505566358566284
Validation loss: 2.0955127362282044

Epoch: 5| Step: 6
Training loss: 2.8348045349121094
Validation loss: 2.086005054494386

Epoch: 5| Step: 7
Training loss: 1.89982008934021
Validation loss: 2.076594711631857

Epoch: 5| Step: 8
Training loss: 2.0457959175109863
Validation loss: 2.096260687356354

Epoch: 5| Step: 9
Training loss: 2.5411934852600098
Validation loss: 2.0754661380603747

Epoch: 5| Step: 10
Training loss: 1.8104782104492188
Validation loss: 2.085355633048601

Epoch: 71| Step: 0
Training loss: 1.9650886058807373
Validation loss: 2.0902572139616935

Epoch: 5| Step: 1
Training loss: 1.990592360496521
Validation loss: 2.0835395448951313

Epoch: 5| Step: 2
Training loss: 2.375441074371338
Validation loss: 2.0845955084728938

Epoch: 5| Step: 3
Training loss: 2.9190616607666016
Validation loss: 2.075151921600424

Epoch: 5| Step: 4
Training loss: 2.300116777420044
Validation loss: 2.0923616834866103

Epoch: 5| Step: 5
Training loss: 2.703291416168213
Validation loss: 2.0757245376545894

Epoch: 5| Step: 6
Training loss: 2.2961926460266113
Validation loss: 2.0692921530815864

Epoch: 5| Step: 7
Training loss: 1.9760793447494507
Validation loss: 2.0885082880655923

Epoch: 5| Step: 8
Training loss: 1.6381267309188843
Validation loss: 2.0735984771482405

Epoch: 5| Step: 9
Training loss: 2.302884340286255
Validation loss: 2.078772942225138

Epoch: 5| Step: 10
Training loss: 2.474912405014038
Validation loss: 2.0785421504769275

Epoch: 72| Step: 0
Training loss: 2.9742541313171387
Validation loss: 2.0702959337542133

Epoch: 5| Step: 1
Training loss: 1.9600498676300049
Validation loss: 2.077523519915919

Epoch: 5| Step: 2
Training loss: 2.08328914642334
Validation loss: 2.084882664424117

Epoch: 5| Step: 3
Training loss: 2.0418858528137207
Validation loss: 2.0863639257287465

Epoch: 5| Step: 4
Training loss: 2.1870241165161133
Validation loss: 2.0675314857113745

Epoch: 5| Step: 5
Training loss: 2.367252826690674
Validation loss: 2.0869232710971626

Epoch: 5| Step: 6
Training loss: 2.103085994720459
Validation loss: 2.0738166711663686

Epoch: 5| Step: 7
Training loss: 2.750089168548584
Validation loss: 2.084199236285302

Epoch: 5| Step: 8
Training loss: 1.8862216472625732
Validation loss: 2.0738687989532307

Epoch: 5| Step: 9
Training loss: 1.8612686395645142
Validation loss: 2.077124934042654

Epoch: 5| Step: 10
Training loss: 2.7279937267303467
Validation loss: 2.07617377081225

Epoch: 73| Step: 0
Training loss: 2.180014133453369
Validation loss: 2.0967959909028906

Epoch: 5| Step: 1
Training loss: 1.791621208190918
Validation loss: 2.083929523344963

Epoch: 5| Step: 2
Training loss: 2.0432231426239014
Validation loss: 2.0664246620670443

Epoch: 5| Step: 3
Training loss: 1.9767138957977295
Validation loss: 2.058882685117824

Epoch: 5| Step: 4
Training loss: 2.76094126701355
Validation loss: 2.080699218216763

Epoch: 5| Step: 5
Training loss: 2.2011466026306152
Validation loss: 2.0858899367752897

Epoch: 5| Step: 6
Training loss: 2.6117899417877197
Validation loss: 2.0933141503282773

Epoch: 5| Step: 7
Training loss: 2.1899638175964355
Validation loss: 2.071960682510048

Epoch: 5| Step: 8
Training loss: 3.0543665885925293
Validation loss: 2.084900167680556

Epoch: 5| Step: 9
Training loss: 1.753170371055603
Validation loss: 2.09168218797253

Epoch: 5| Step: 10
Training loss: 2.5147740840911865
Validation loss: 2.086343062821255

Epoch: 74| Step: 0
Training loss: 2.2871346473693848
Validation loss: 2.0837945348473004

Epoch: 5| Step: 1
Training loss: 1.900191068649292
Validation loss: 2.076570822346595

Epoch: 5| Step: 2
Training loss: 1.9958473443984985
Validation loss: 2.087515525920417

Epoch: 5| Step: 3
Training loss: 2.1748318672180176
Validation loss: 2.086532453055023

Epoch: 5| Step: 4
Training loss: 2.4374642372131348
Validation loss: 2.0827268400499896

Epoch: 5| Step: 5
Training loss: 1.3254358768463135
Validation loss: 2.0858981250434794

Epoch: 5| Step: 6
Training loss: 2.420384645462036
Validation loss: 2.0572125706621396

Epoch: 5| Step: 7
Training loss: 2.7078189849853516
Validation loss: 2.076225503798454

Epoch: 5| Step: 8
Training loss: 2.5945794582366943
Validation loss: 2.0796957913265435

Epoch: 5| Step: 9
Training loss: 2.4913225173950195
Validation loss: 2.0768218373739593

Epoch: 5| Step: 10
Training loss: 2.6030704975128174
Validation loss: 2.084484548978908

Epoch: 75| Step: 0
Training loss: 2.550569534301758
Validation loss: 2.094450935240715

Epoch: 5| Step: 1
Training loss: 2.339686632156372
Validation loss: 2.0911590617190123

Epoch: 5| Step: 2
Training loss: 1.964120864868164
Validation loss: 2.086587531592256

Epoch: 5| Step: 3
Training loss: 2.7569754123687744
Validation loss: 2.0819669154382523

Epoch: 5| Step: 4
Training loss: 2.1067121028900146
Validation loss: 2.084737521345897

Epoch: 5| Step: 5
Training loss: 1.874131441116333
Validation loss: 2.085712598216149

Epoch: 5| Step: 6
Training loss: 2.8308541774749756
Validation loss: 2.0800321794325307

Epoch: 5| Step: 7
Training loss: 1.7972710132598877
Validation loss: 2.0911282659858785

Epoch: 5| Step: 8
Training loss: 2.6140475273132324
Validation loss: 2.067968912022088

Epoch: 5| Step: 9
Training loss: 1.5041124820709229
Validation loss: 2.0873896460379324

Epoch: 5| Step: 10
Training loss: 2.5725631713867188
Validation loss: 2.080443471990606

Epoch: 76| Step: 0
Training loss: 1.6874440908432007
Validation loss: 2.0776923471881497

Epoch: 5| Step: 1
Training loss: 2.0810608863830566
Validation loss: 2.073210764956731

Epoch: 5| Step: 2
Training loss: 1.6485464572906494
Validation loss: 2.091562000654077

Epoch: 5| Step: 3
Training loss: 2.0485692024230957
Validation loss: 2.075998927957268

Epoch: 5| Step: 4
Training loss: 2.9133949279785156
Validation loss: 2.081288012125159

Epoch: 5| Step: 5
Training loss: 2.28293776512146
Validation loss: 2.0761286597098074

Epoch: 5| Step: 6
Training loss: 1.775590181350708
Validation loss: 2.0803294233096543

Epoch: 5| Step: 7
Training loss: 2.2252204418182373
Validation loss: 2.073965846851308

Epoch: 5| Step: 8
Training loss: 2.5593960285186768
Validation loss: 2.090171725519242

Epoch: 5| Step: 9
Training loss: 2.537850856781006
Validation loss: 2.0568121556312806

Epoch: 5| Step: 10
Training loss: 3.0968592166900635
Validation loss: 2.075739178606259

Epoch: 77| Step: 0
Training loss: 2.071458101272583
Validation loss: 2.079419018119894

Epoch: 5| Step: 1
Training loss: 1.985329270362854
Validation loss: 2.0912479162216187

Epoch: 5| Step: 2
Training loss: 2.1833903789520264
Validation loss: 2.0819223875640542

Epoch: 5| Step: 3
Training loss: 2.8532962799072266
Validation loss: 2.067058463250437

Epoch: 5| Step: 4
Training loss: 2.124269485473633
Validation loss: 2.0826778334956013

Epoch: 5| Step: 5
Training loss: 2.898979663848877
Validation loss: 2.0750971942819576

Epoch: 5| Step: 6
Training loss: 1.3785209655761719
Validation loss: 2.075311990194423

Epoch: 5| Step: 7
Training loss: 2.2940821647644043
Validation loss: 2.0645803200301303

Epoch: 5| Step: 8
Training loss: 1.87470281124115
Validation loss: 2.077806862451697

Epoch: 5| Step: 9
Training loss: 2.331413507461548
Validation loss: 2.065390148470479

Epoch: 5| Step: 10
Training loss: 2.7556278705596924
Validation loss: 2.0902318595558085

Epoch: 78| Step: 0
Training loss: 2.1668972969055176
Validation loss: 2.0926501110035884

Epoch: 5| Step: 1
Training loss: 2.072417736053467
Validation loss: 2.078688229283979

Epoch: 5| Step: 2
Training loss: 2.453211545944214
Validation loss: 2.0817327371207615

Epoch: 5| Step: 3
Training loss: 1.854544997215271
Validation loss: 2.088769466646256

Epoch: 5| Step: 4
Training loss: 2.366215705871582
Validation loss: 2.0713613904932493

Epoch: 5| Step: 5
Training loss: 1.9826740026474
Validation loss: 2.08425272023806

Epoch: 5| Step: 6
Training loss: 2.063530445098877
Validation loss: 2.079697939657396

Epoch: 5| Step: 7
Training loss: 2.766401767730713
Validation loss: 2.068980270816434

Epoch: 5| Step: 8
Training loss: 2.546637535095215
Validation loss: 2.057049851263723

Epoch: 5| Step: 9
Training loss: 1.9758787155151367
Validation loss: 2.0892723004023233

Epoch: 5| Step: 10
Training loss: 2.501162052154541
Validation loss: 2.081182905422744

Epoch: 79| Step: 0
Training loss: 1.7996032238006592
Validation loss: 2.086153259841345

Epoch: 5| Step: 1
Training loss: 2.7230987548828125
Validation loss: 2.071635336004278

Epoch: 5| Step: 2
Training loss: 2.605273723602295
Validation loss: 2.073023457680979

Epoch: 5| Step: 3
Training loss: 2.6766738891601562
Validation loss: 2.073094503853911

Epoch: 5| Step: 4
Training loss: 2.522921323776245
Validation loss: 2.0650367480452343

Epoch: 5| Step: 5
Training loss: 1.904977798461914
Validation loss: 2.0759215765101935

Epoch: 5| Step: 6
Training loss: 1.6878162622451782
Validation loss: 2.0807881111739785

Epoch: 5| Step: 7
Training loss: 1.9597513675689697
Validation loss: 2.065733996770715

Epoch: 5| Step: 8
Training loss: 2.4404385089874268
Validation loss: 2.0814021351516887

Epoch: 5| Step: 9
Training loss: 2.034165859222412
Validation loss: 2.0828122105649722

Epoch: 5| Step: 10
Training loss: 2.3257296085357666
Validation loss: 2.065879960213938

Epoch: 80| Step: 0
Training loss: 1.9053661823272705
Validation loss: 2.068197701566963

Epoch: 5| Step: 1
Training loss: 2.173302173614502
Validation loss: 2.0830131423088813

Epoch: 5| Step: 2
Training loss: 2.805661678314209
Validation loss: 2.099092957794025

Epoch: 5| Step: 3
Training loss: 2.562917470932007
Validation loss: 2.0599598576945644

Epoch: 5| Step: 4
Training loss: 2.665950298309326
Validation loss: 2.0640399853388467

Epoch: 5| Step: 5
Training loss: 1.9055168628692627
Validation loss: 2.077686737942439

Epoch: 5| Step: 6
Training loss: 1.797459363937378
Validation loss: 2.071098450691469

Epoch: 5| Step: 7
Training loss: 2.025291681289673
Validation loss: 2.0749690084047216

Epoch: 5| Step: 8
Training loss: 2.0269899368286133
Validation loss: 2.083182539991153

Epoch: 5| Step: 9
Training loss: 2.1296517848968506
Validation loss: 2.078548553169415

Epoch: 5| Step: 10
Training loss: 2.514240026473999
Validation loss: 2.0803559762175365

Epoch: 81| Step: 0
Training loss: 1.8107513189315796
Validation loss: 2.082108630928942

Epoch: 5| Step: 1
Training loss: 1.3861463069915771
Validation loss: 2.08341109624473

Epoch: 5| Step: 2
Training loss: 2.299924373626709
Validation loss: 2.0936883418790755

Epoch: 5| Step: 3
Training loss: 2.14829683303833
Validation loss: 2.080911633788898

Epoch: 5| Step: 4
Training loss: 2.3774592876434326
Validation loss: 2.076924213799097

Epoch: 5| Step: 5
Training loss: 2.7893190383911133
Validation loss: 2.095976339873447

Epoch: 5| Step: 6
Training loss: 2.9360125064849854
Validation loss: 2.0686147546255462

Epoch: 5| Step: 7
Training loss: 2.394923448562622
Validation loss: 2.067845441961801

Epoch: 5| Step: 8
Training loss: 1.8507556915283203
Validation loss: 2.075733989797613

Epoch: 5| Step: 9
Training loss: 2.868701934814453
Validation loss: 2.083511689657806

Epoch: 5| Step: 10
Training loss: 1.6574437618255615
Validation loss: 2.094560916705798

Epoch: 82| Step: 0
Training loss: 2.7767586708068848
Validation loss: 2.0712066696536158

Epoch: 5| Step: 1
Training loss: 2.0676777362823486
Validation loss: 2.073434709220804

Epoch: 5| Step: 2
Training loss: 2.1139748096466064
Validation loss: 2.0841956446247716

Epoch: 5| Step: 3
Training loss: 1.794081687927246
Validation loss: 2.0673079593207246

Epoch: 5| Step: 4
Training loss: 2.226929187774658
Validation loss: 2.08152235451565

Epoch: 5| Step: 5
Training loss: 1.9322407245635986
Validation loss: 2.0816858853063276

Epoch: 5| Step: 6
Training loss: 2.619150161743164
Validation loss: 2.0828077536757275

Epoch: 5| Step: 7
Training loss: 2.240701198577881
Validation loss: 2.085568686967255

Epoch: 5| Step: 8
Training loss: 1.7873893976211548
Validation loss: 2.084721995938209

Epoch: 5| Step: 9
Training loss: 2.6618072986602783
Validation loss: 2.090395050664102

Epoch: 5| Step: 10
Training loss: 2.330923080444336
Validation loss: 2.1022445463365123

Epoch: 83| Step: 0
Training loss: 2.555443525314331
Validation loss: 2.0890728965882333

Epoch: 5| Step: 1
Training loss: 2.581620693206787
Validation loss: 2.079620130600468

Epoch: 5| Step: 2
Training loss: 2.42216157913208
Validation loss: 2.0549428129708893

Epoch: 5| Step: 3
Training loss: 2.324737310409546
Validation loss: 2.0691691752403014

Epoch: 5| Step: 4
Training loss: 2.3014838695526123
Validation loss: 2.063879087407102

Epoch: 5| Step: 5
Training loss: 2.1545987129211426
Validation loss: 2.071871139669931

Epoch: 5| Step: 6
Training loss: 1.995693564414978
Validation loss: 2.076590162451549

Epoch: 5| Step: 7
Training loss: 2.504948616027832
Validation loss: 2.0750414402254167

Epoch: 5| Step: 8
Training loss: 1.608838677406311
Validation loss: 2.087573746199249

Epoch: 5| Step: 9
Training loss: 1.6856390237808228
Validation loss: 2.0581088425010763

Epoch: 5| Step: 10
Training loss: 2.415748119354248
Validation loss: 2.0799811963112123

Epoch: 84| Step: 0
Training loss: 1.6318366527557373
Validation loss: 2.054497238128416

Epoch: 5| Step: 1
Training loss: 2.367023229598999
Validation loss: 2.0647817350202993

Epoch: 5| Step: 2
Training loss: 2.317033052444458
Validation loss: 2.0646932471183037

Epoch: 5| Step: 3
Training loss: 1.8628743886947632
Validation loss: 2.0819884179740824

Epoch: 5| Step: 4
Training loss: 1.9938488006591797
Validation loss: 2.0776416588855047

Epoch: 5| Step: 5
Training loss: 1.5952309370040894
Validation loss: 2.0821148118665143

Epoch: 5| Step: 6
Training loss: 2.574126720428467
Validation loss: 2.046426797425875

Epoch: 5| Step: 7
Training loss: 2.5203418731689453
Validation loss: 2.0687488676399313

Epoch: 5| Step: 8
Training loss: 2.7795467376708984
Validation loss: 2.08578561967419

Epoch: 5| Step: 9
Training loss: 2.5060441493988037
Validation loss: 2.077979483912068

Epoch: 5| Step: 10
Training loss: 2.319469690322876
Validation loss: 2.0874978060363443

Epoch: 85| Step: 0
Training loss: 1.8243725299835205
Validation loss: 2.0519281497565647

Epoch: 5| Step: 1
Training loss: 2.1283040046691895
Validation loss: 2.0835109872202717

Epoch: 5| Step: 2
Training loss: 2.494250774383545
Validation loss: 2.0582618636469685

Epoch: 5| Step: 3
Training loss: 1.3807462453842163
Validation loss: 2.0809417565663657

Epoch: 5| Step: 4
Training loss: 1.6947425603866577
Validation loss: 2.067895166335567

Epoch: 5| Step: 5
Training loss: 1.9387004375457764
Validation loss: 2.083286034163608

Epoch: 5| Step: 6
Training loss: 2.911707639694214
Validation loss: 2.067843423094801

Epoch: 5| Step: 7
Training loss: 2.6334030628204346
Validation loss: 2.0752365025140906

Epoch: 5| Step: 8
Training loss: 2.6615004539489746
Validation loss: 2.083860707539384

Epoch: 5| Step: 9
Training loss: 2.2366416454315186
Validation loss: 2.0713127607940347

Epoch: 5| Step: 10
Training loss: 2.481088876724243
Validation loss: 2.08335901588522

Epoch: 86| Step: 0
Training loss: 1.9222285747528076
Validation loss: 2.0808166483397126

Epoch: 5| Step: 1
Training loss: 2.220588207244873
Validation loss: 2.079045719997857

Epoch: 5| Step: 2
Training loss: 2.7190914154052734
Validation loss: 2.067932956962175

Epoch: 5| Step: 3
Training loss: 2.048584461212158
Validation loss: 2.0616447758930985

Epoch: 5| Step: 4
Training loss: 1.899113655090332
Validation loss: 2.0762782096862793

Epoch: 5| Step: 5
Training loss: 2.114030122756958
Validation loss: 2.068854622943427

Epoch: 5| Step: 6
Training loss: 2.2044806480407715
Validation loss: 2.074973826767296

Epoch: 5| Step: 7
Training loss: 1.7559146881103516
Validation loss: 2.0769167164320588

Epoch: 5| Step: 8
Training loss: 2.3461365699768066
Validation loss: 2.0737685926498903

Epoch: 5| Step: 9
Training loss: 2.4934146404266357
Validation loss: 2.090516439048193

Epoch: 5| Step: 10
Training loss: 2.817836284637451
Validation loss: 2.06684450949392

Epoch: 87| Step: 0
Training loss: 1.7994760274887085
Validation loss: 2.05813983819818

Epoch: 5| Step: 1
Training loss: 2.5113916397094727
Validation loss: 2.0755623284206597

Epoch: 5| Step: 2
Training loss: 1.9965442419052124
Validation loss: 2.0895902085047897

Epoch: 5| Step: 3
Training loss: 1.9669430255889893
Validation loss: 2.073850021567396

Epoch: 5| Step: 4
Training loss: 2.6281344890594482
Validation loss: 2.085865374534361

Epoch: 5| Step: 5
Training loss: 2.660078763961792
Validation loss: 2.0784115047865015

Epoch: 5| Step: 6
Training loss: 2.0867867469787598
Validation loss: 2.084567177680231

Epoch: 5| Step: 7
Training loss: 1.8217928409576416
Validation loss: 2.0572548271507345

Epoch: 5| Step: 8
Training loss: 1.5449445247650146
Validation loss: 2.0836873464686896

Epoch: 5| Step: 9
Training loss: 2.4972949028015137
Validation loss: 2.0818640698668776

Epoch: 5| Step: 10
Training loss: 2.90028715133667
Validation loss: 2.0642979721869192

Epoch: 88| Step: 0
Training loss: 1.8765445947647095
Validation loss: 2.0605952483351513

Epoch: 5| Step: 1
Training loss: 1.7000318765640259
Validation loss: 2.08252574295126

Epoch: 5| Step: 2
Training loss: 2.476060390472412
Validation loss: 2.0769073322255123

Epoch: 5| Step: 3
Training loss: 2.156007766723633
Validation loss: 2.062465585688109

Epoch: 5| Step: 4
Training loss: 2.4806456565856934
Validation loss: 2.064864804667811

Epoch: 5| Step: 5
Training loss: 1.6217273473739624
Validation loss: 2.0640555492011448

Epoch: 5| Step: 6
Training loss: 2.0766420364379883
Validation loss: 2.0591333860992105

Epoch: 5| Step: 7
Training loss: 1.9123470783233643
Validation loss: 2.070909492431148

Epoch: 5| Step: 8
Training loss: 2.5024712085723877
Validation loss: 2.072236409751318

Epoch: 5| Step: 9
Training loss: 2.2958216667175293
Validation loss: 2.075346759570542

Epoch: 5| Step: 10
Training loss: 3.4691879749298096
Validation loss: 2.0790890955155894

Epoch: 89| Step: 0
Training loss: 1.813605546951294
Validation loss: 2.0812739890108825

Epoch: 5| Step: 1
Training loss: 2.1495580673217773
Validation loss: 2.0660079256180794

Epoch: 5| Step: 2
Training loss: 2.3837716579437256
Validation loss: 2.085438032304087

Epoch: 5| Step: 3
Training loss: 2.638641357421875
Validation loss: 2.0653148799814205

Epoch: 5| Step: 4
Training loss: 2.0961008071899414
Validation loss: 2.078930475378549

Epoch: 5| Step: 5
Training loss: 1.9074233770370483
Validation loss: 2.0644625181792886

Epoch: 5| Step: 6
Training loss: 2.3272924423217773
Validation loss: 2.0903315646674043

Epoch: 5| Step: 7
Training loss: 2.5627033710479736
Validation loss: 2.074477485431138

Epoch: 5| Step: 8
Training loss: 2.38264799118042
Validation loss: 2.087471410792361

Epoch: 5| Step: 9
Training loss: 2.151535749435425
Validation loss: 2.0680855448528

Epoch: 5| Step: 10
Training loss: 1.991699457168579
Validation loss: 2.079720947050279

Epoch: 90| Step: 0
Training loss: 2.5160560607910156
Validation loss: 2.070376597424989

Epoch: 5| Step: 1
Training loss: 2.3589835166931152
Validation loss: 2.0716539993081042

Epoch: 5| Step: 2
Training loss: 2.034636974334717
Validation loss: 2.0908967423182663

Epoch: 5| Step: 3
Training loss: 1.9761241674423218
Validation loss: 2.065608832143968

Epoch: 5| Step: 4
Training loss: 2.732524871826172
Validation loss: 2.087161417930357

Epoch: 5| Step: 5
Training loss: 2.3384883403778076
Validation loss: 2.0605992424872612

Epoch: 5| Step: 6
Training loss: 1.9539833068847656
Validation loss: 2.0577809195364676

Epoch: 5| Step: 7
Training loss: 2.5348398685455322
Validation loss: 2.0796810350110455

Epoch: 5| Step: 8
Training loss: 1.4713718891143799
Validation loss: 2.0740294507754746

Epoch: 5| Step: 9
Training loss: 2.090503692626953
Validation loss: 2.0652517734035367

Epoch: 5| Step: 10
Training loss: 2.528202533721924
Validation loss: 2.0962082416780534

Epoch: 91| Step: 0
Training loss: 2.531865119934082
Validation loss: 2.0992447278832875

Epoch: 5| Step: 1
Training loss: 2.0967860221862793
Validation loss: 2.0666226622878865

Epoch: 5| Step: 2
Training loss: 1.7562170028686523
Validation loss: 2.0555511482300295

Epoch: 5| Step: 3
Training loss: 1.8437235355377197
Validation loss: 2.066507916296682

Epoch: 5| Step: 4
Training loss: 3.0231525897979736
Validation loss: 2.066058776711905

Epoch: 5| Step: 5
Training loss: 1.9170109033584595
Validation loss: 2.084486246109009

Epoch: 5| Step: 6
Training loss: 2.2962117195129395
Validation loss: 2.0733478761488393

Epoch: 5| Step: 7
Training loss: 1.4940115213394165
Validation loss: 2.0789934191652524

Epoch: 5| Step: 8
Training loss: 2.0449414253234863
Validation loss: 2.0821152733218287

Epoch: 5| Step: 9
Training loss: 2.8775627613067627
Validation loss: 2.0732911171451693

Epoch: 5| Step: 10
Training loss: 2.57696533203125
Validation loss: 2.0745310039930445

Epoch: 92| Step: 0
Training loss: 1.8443056344985962
Validation loss: 2.069099034032514

Epoch: 5| Step: 1
Training loss: 2.142934799194336
Validation loss: 2.075961602631436

Epoch: 5| Step: 2
Training loss: 1.6320436000823975
Validation loss: 2.0689995468303723

Epoch: 5| Step: 3
Training loss: 2.3968183994293213
Validation loss: 2.058340698160151

Epoch: 5| Step: 4
Training loss: 2.6266326904296875
Validation loss: 2.079673041579544

Epoch: 5| Step: 5
Training loss: 1.8277530670166016
Validation loss: 2.077633173235001

Epoch: 5| Step: 6
Training loss: 2.2292580604553223
Validation loss: 2.06999869115891

Epoch: 5| Step: 7
Training loss: 2.5185585021972656
Validation loss: 2.0744067712496688

Epoch: 5| Step: 8
Training loss: 2.456239700317383
Validation loss: 2.0782835957824544

Epoch: 5| Step: 9
Training loss: 2.674767255783081
Validation loss: 2.054640982740669

Epoch: 5| Step: 10
Training loss: 1.9128334522247314
Validation loss: 2.074359970708047

Epoch: 93| Step: 0
Training loss: 2.148077964782715
Validation loss: 2.079222256137479

Epoch: 5| Step: 1
Training loss: 2.4594619274139404
Validation loss: 2.087474194906091

Epoch: 5| Step: 2
Training loss: 1.9361460208892822
Validation loss: 2.063594327178053

Epoch: 5| Step: 3
Training loss: 2.413102865219116
Validation loss: 2.0893676742430656

Epoch: 5| Step: 4
Training loss: 2.6840367317199707
Validation loss: 2.0610771076653593

Epoch: 5| Step: 5
Training loss: 1.6785024404525757
Validation loss: 2.055278916512766

Epoch: 5| Step: 6
Training loss: 2.114694595336914
Validation loss: 2.0812498856616277

Epoch: 5| Step: 7
Training loss: 2.378509998321533
Validation loss: 2.0823883830860095

Epoch: 5| Step: 8
Training loss: 2.6596057415008545
Validation loss: 2.0563383076780584

Epoch: 5| Step: 9
Training loss: 1.8557182550430298
Validation loss: 2.0565674228052937

Epoch: 5| Step: 10
Training loss: 1.854421615600586
Validation loss: 2.0514602225313903

Epoch: 94| Step: 0
Training loss: 2.317613363265991
Validation loss: 2.0587642269749797

Epoch: 5| Step: 1
Training loss: 2.2030670642852783
Validation loss: 2.0836203277751966

Epoch: 5| Step: 2
Training loss: 2.376152992248535
Validation loss: 2.0678546967044955

Epoch: 5| Step: 3
Training loss: 2.097670078277588
Validation loss: 2.0688474370587255

Epoch: 5| Step: 4
Training loss: 1.914554238319397
Validation loss: 2.062530656014719

Epoch: 5| Step: 5
Training loss: 2.0638720989227295
Validation loss: 2.071721920403101

Epoch: 5| Step: 6
Training loss: 2.1447696685791016
Validation loss: 2.0864490078341578

Epoch: 5| Step: 7
Training loss: 2.205118179321289
Validation loss: 2.0723516941070557

Epoch: 5| Step: 8
Training loss: 1.9507904052734375
Validation loss: 2.0578990469696703

Epoch: 5| Step: 9
Training loss: 2.8773186206817627
Validation loss: 2.0819548381272184

Epoch: 5| Step: 10
Training loss: 2.056947708129883
Validation loss: 2.06257789750253

Epoch: 95| Step: 0
Training loss: 2.1764302253723145
Validation loss: 2.071926647616971

Epoch: 5| Step: 1
Training loss: 2.4396471977233887
Validation loss: 2.0790585894738474

Epoch: 5| Step: 2
Training loss: 1.9960768222808838
Validation loss: 2.070179006104828

Epoch: 5| Step: 3
Training loss: 2.573970317840576
Validation loss: 2.053566981387395

Epoch: 5| Step: 4
Training loss: 2.327915668487549
Validation loss: 2.06312648711666

Epoch: 5| Step: 5
Training loss: 2.0188937187194824
Validation loss: 2.0824858770575574

Epoch: 5| Step: 6
Training loss: 2.127650260925293
Validation loss: 2.0885887607451408

Epoch: 5| Step: 7
Training loss: 1.8552345037460327
Validation loss: 2.063342196967012

Epoch: 5| Step: 8
Training loss: 2.6960551738739014
Validation loss: 2.063461172965265

Epoch: 5| Step: 9
Training loss: 2.065600633621216
Validation loss: 2.0472519038825907

Epoch: 5| Step: 10
Training loss: 1.925144910812378
Validation loss: 2.0604833095304427

Epoch: 96| Step: 0
Training loss: 1.6842191219329834
Validation loss: 2.0783357133147535

Epoch: 5| Step: 1
Training loss: 2.4935805797576904
Validation loss: 2.074083443610899

Epoch: 5| Step: 2
Training loss: 2.2892110347747803
Validation loss: 2.068132036475725

Epoch: 5| Step: 3
Training loss: 2.301811933517456
Validation loss: 2.051036657825593

Epoch: 5| Step: 4
Training loss: 2.3204452991485596
Validation loss: 2.069981913412771

Epoch: 5| Step: 5
Training loss: 2.545384407043457
Validation loss: 2.0770465891848326

Epoch: 5| Step: 6
Training loss: 2.236452102661133
Validation loss: 2.064140456978993

Epoch: 5| Step: 7
Training loss: 2.1810765266418457
Validation loss: 2.0727058379880843

Epoch: 5| Step: 8
Training loss: 2.2820396423339844
Validation loss: 2.05013196955445

Epoch: 5| Step: 9
Training loss: 2.005918025970459
Validation loss: 2.0605830133602185

Epoch: 5| Step: 10
Training loss: 1.7866653203964233
Validation loss: 2.063902542155276

Epoch: 97| Step: 0
Training loss: 2.7783641815185547
Validation loss: 2.0616645915533907

Epoch: 5| Step: 1
Training loss: 1.680320382118225
Validation loss: 2.0786210747175318

Epoch: 5| Step: 2
Training loss: 2.2655882835388184
Validation loss: 2.071627893755513

Epoch: 5| Step: 3
Training loss: 2.616295576095581
Validation loss: 2.0589509061587754

Epoch: 5| Step: 4
Training loss: 1.7937263250350952
Validation loss: 2.0539898744193454

Epoch: 5| Step: 5
Training loss: 2.640188217163086
Validation loss: 2.056732855817323

Epoch: 5| Step: 6
Training loss: 2.660885810852051
Validation loss: 2.0781566891618954

Epoch: 5| Step: 7
Training loss: 2.093723773956299
Validation loss: 2.0806249944112634

Epoch: 5| Step: 8
Training loss: 2.469146966934204
Validation loss: 2.0507449168030933

Epoch: 5| Step: 9
Training loss: 1.8990180492401123
Validation loss: 2.0595031758790374

Epoch: 5| Step: 10
Training loss: 1.137608289718628
Validation loss: 2.077574893992434

Epoch: 98| Step: 0
Training loss: 1.790104627609253
Validation loss: 2.0702345550701184

Epoch: 5| Step: 1
Training loss: 2.3902029991149902
Validation loss: 2.068906586657288

Epoch: 5| Step: 2
Training loss: 2.153247833251953
Validation loss: 2.07721443586452

Epoch: 5| Step: 3
Training loss: 2.216801404953003
Validation loss: 2.055460217178509

Epoch: 5| Step: 4
Training loss: 1.9641116857528687
Validation loss: 2.056568238043016

Epoch: 5| Step: 5
Training loss: 1.9072628021240234
Validation loss: 2.0564445641732987

Epoch: 5| Step: 6
Training loss: 2.2605438232421875
Validation loss: 2.0713789078497116

Epoch: 5| Step: 7
Training loss: 1.988564133644104
Validation loss: 2.0732730165604623

Epoch: 5| Step: 8
Training loss: 2.881354331970215
Validation loss: 2.0498220151470554

Epoch: 5| Step: 9
Training loss: 1.9386026859283447
Validation loss: 2.074827290350391

Epoch: 5| Step: 10
Training loss: 2.6665544509887695
Validation loss: 2.0608919384658977

Epoch: 99| Step: 0
Training loss: 1.8550736904144287
Validation loss: 2.0604064746569564

Epoch: 5| Step: 1
Training loss: 2.2083699703216553
Validation loss: 2.065987966393912

Epoch: 5| Step: 2
Training loss: 1.9247125387191772
Validation loss: 2.074683170164785

Epoch: 5| Step: 3
Training loss: 2.6238410472869873
Validation loss: 2.0714691428728003

Epoch: 5| Step: 4
Training loss: 1.9446252584457397
Validation loss: 2.069197057395853

Epoch: 5| Step: 5
Training loss: 2.470914363861084
Validation loss: 2.076474881941272

Epoch: 5| Step: 6
Training loss: 1.9781968593597412
Validation loss: 2.0755606851270123

Epoch: 5| Step: 7
Training loss: 2.681184768676758
Validation loss: 2.0582988313449326

Epoch: 5| Step: 8
Training loss: 2.4226126670837402
Validation loss: 2.0701999997579925

Epoch: 5| Step: 9
Training loss: 1.844212293624878
Validation loss: 2.07504109157029

Epoch: 5| Step: 10
Training loss: 2.0428316593170166
Validation loss: 2.070481966900569

Epoch: 100| Step: 0
Training loss: 2.2515835762023926
Validation loss: 2.077078455237932

Epoch: 5| Step: 1
Training loss: 2.1294515132904053
Validation loss: 2.0645435663961593

Epoch: 5| Step: 2
Training loss: 2.2409090995788574
Validation loss: 2.0587062579329296

Epoch: 5| Step: 3
Training loss: 2.1061758995056152
Validation loss: 2.088568884839294

Epoch: 5| Step: 4
Training loss: 1.7143882513046265
Validation loss: 2.0884235366698234

Epoch: 5| Step: 5
Training loss: 1.9261716604232788
Validation loss: 2.078407259397609

Epoch: 5| Step: 6
Training loss: 2.2084097862243652
Validation loss: 2.0869263628477692

Epoch: 5| Step: 7
Training loss: 2.227806568145752
Validation loss: 2.074318203874814

Epoch: 5| Step: 8
Training loss: 2.0838050842285156
Validation loss: 2.089467315263646

Epoch: 5| Step: 9
Training loss: 2.645043134689331
Validation loss: 2.0727660117610807

Epoch: 5| Step: 10
Training loss: 2.6619412899017334
Validation loss: 2.065382351157486

Epoch: 101| Step: 0
Training loss: 2.29425311088562
Validation loss: 2.0716233279115412

Epoch: 5| Step: 1
Training loss: 1.5128635168075562
Validation loss: 2.065786320676086

Epoch: 5| Step: 2
Training loss: 2.257122039794922
Validation loss: 2.083982418942195

Epoch: 5| Step: 3
Training loss: 1.9969911575317383
Validation loss: 2.058602540723739

Epoch: 5| Step: 4
Training loss: 2.167184352874756
Validation loss: 2.068492576640139

Epoch: 5| Step: 5
Training loss: 2.31585693359375
Validation loss: 2.0636823356792493

Epoch: 5| Step: 6
Training loss: 1.8117358684539795
Validation loss: 2.0637630390864548

Epoch: 5| Step: 7
Training loss: 2.380869150161743
Validation loss: 2.0508953063718733

Epoch: 5| Step: 8
Training loss: 1.9295587539672852
Validation loss: 2.0734922180893602

Epoch: 5| Step: 9
Training loss: 2.4875597953796387
Validation loss: 2.073368319901087

Epoch: 5| Step: 10
Training loss: 3.068056106567383
Validation loss: 2.0483027363336213

Epoch: 102| Step: 0
Training loss: 1.5406421422958374
Validation loss: 2.066413494848436

Epoch: 5| Step: 1
Training loss: 2.5524673461914062
Validation loss: 2.068431902957219

Epoch: 5| Step: 2
Training loss: 2.237434148788452
Validation loss: 2.0665415653618435

Epoch: 5| Step: 3
Training loss: 2.2853267192840576
Validation loss: 2.0567586562966786

Epoch: 5| Step: 4
Training loss: 2.118577718734741
Validation loss: 2.077666116017167

Epoch: 5| Step: 5
Training loss: 1.9435583353042603
Validation loss: 2.070572999215895

Epoch: 5| Step: 6
Training loss: 2.3853981494903564
Validation loss: 2.062582095464071

Epoch: 5| Step: 7
Training loss: 2.604785680770874
Validation loss: 2.0589644216722056

Epoch: 5| Step: 8
Training loss: 2.1641178131103516
Validation loss: 2.0880359782967517

Epoch: 5| Step: 9
Training loss: 2.1121392250061035
Validation loss: 2.0545563659360333

Epoch: 5| Step: 10
Training loss: 2.12060284614563
Validation loss: 2.048365628847512

Epoch: 103| Step: 0
Training loss: 1.8691517114639282
Validation loss: 2.0702380890487344

Epoch: 5| Step: 1
Training loss: 2.1604301929473877
Validation loss: 2.0681891851527716

Epoch: 5| Step: 2
Training loss: 2.364673137664795
Validation loss: 2.055771632861066

Epoch: 5| Step: 3
Training loss: 2.7971646785736084
Validation loss: 2.0709830253354964

Epoch: 5| Step: 4
Training loss: 2.938109874725342
Validation loss: 2.066126072278587

Epoch: 5| Step: 5
Training loss: 1.9935222864151
Validation loss: 2.074294936272406

Epoch: 5| Step: 6
Training loss: 1.8709102869033813
Validation loss: 2.0680931793746127

Epoch: 5| Step: 7
Training loss: 2.038914442062378
Validation loss: 2.0625742891783356

Epoch: 5| Step: 8
Training loss: 1.9450139999389648
Validation loss: 2.072824288440007

Epoch: 5| Step: 9
Training loss: 1.9363079071044922
Validation loss: 2.071928826711511

Epoch: 5| Step: 10
Training loss: 1.9757087230682373
Validation loss: 2.08307017946756

Epoch: 104| Step: 0
Training loss: 2.603105068206787
Validation loss: 2.0663584201566634

Epoch: 5| Step: 1
Training loss: 1.7273941040039062
Validation loss: 2.0784123200242237

Epoch: 5| Step: 2
Training loss: 1.7296034097671509
Validation loss: 2.05991546569332

Epoch: 5| Step: 3
Training loss: 2.6571083068847656
Validation loss: 2.038550692219888

Epoch: 5| Step: 4
Training loss: 2.010101556777954
Validation loss: 2.05506944400008

Epoch: 5| Step: 5
Training loss: 2.076038360595703
Validation loss: 2.057554360358946

Epoch: 5| Step: 6
Training loss: 2.3807730674743652
Validation loss: 2.0611961746728547

Epoch: 5| Step: 7
Training loss: 1.7836421728134155
Validation loss: 2.0770018818557903

Epoch: 5| Step: 8
Training loss: 2.8616385459899902
Validation loss: 2.04815500269654

Epoch: 5| Step: 9
Training loss: 2.117767095565796
Validation loss: 2.0688669322639384

Epoch: 5| Step: 10
Training loss: 2.140131950378418
Validation loss: 2.0466274779330016

Epoch: 105| Step: 0
Training loss: 2.274742364883423
Validation loss: 2.0651166797966085

Epoch: 5| Step: 1
Training loss: 2.220393657684326
Validation loss: 2.062586863835653

Epoch: 5| Step: 2
Training loss: 2.4590904712677
Validation loss: 2.071569865749728

Epoch: 5| Step: 3
Training loss: 2.356044292449951
Validation loss: 2.0663104672585764

Epoch: 5| Step: 4
Training loss: 2.3852107524871826
Validation loss: 2.0619927926730086

Epoch: 5| Step: 5
Training loss: 1.8458983898162842
Validation loss: 2.0575995932343187

Epoch: 5| Step: 6
Training loss: 2.0291104316711426
Validation loss: 2.047309112805192

Epoch: 5| Step: 7
Training loss: 1.6575227975845337
Validation loss: 2.063277316349809

Epoch: 5| Step: 8
Training loss: 2.0112409591674805
Validation loss: 2.051291424741027

Epoch: 5| Step: 9
Training loss: 2.6204705238342285
Validation loss: 2.0481732993997555

Epoch: 5| Step: 10
Training loss: 1.8975598812103271
Validation loss: 2.059068836191649

Epoch: 106| Step: 0
Training loss: 2.0083422660827637
Validation loss: 2.0794963926397343

Epoch: 5| Step: 1
Training loss: 2.5932116508483887
Validation loss: 2.0692497414927327

Epoch: 5| Step: 2
Training loss: 2.289539098739624
Validation loss: 2.0793370405832925

Epoch: 5| Step: 3
Training loss: 1.4862463474273682
Validation loss: 2.0671422430264053

Epoch: 5| Step: 4
Training loss: 2.187629461288452
Validation loss: 2.0520997880607523

Epoch: 5| Step: 5
Training loss: 1.7931747436523438
Validation loss: 2.0405128361076437

Epoch: 5| Step: 6
Training loss: 2.244781732559204
Validation loss: 2.058583662074099

Epoch: 5| Step: 7
Training loss: 1.909208059310913
Validation loss: 2.0729932067214802

Epoch: 5| Step: 8
Training loss: 2.2217252254486084
Validation loss: 2.070605388251684

Epoch: 5| Step: 9
Training loss: 2.2886242866516113
Validation loss: 2.074984191566385

Epoch: 5| Step: 10
Training loss: 3.0587825775146484
Validation loss: 2.0600152733505412

Epoch: 107| Step: 0
Training loss: 2.855433464050293
Validation loss: 2.0733542801231466

Epoch: 5| Step: 1
Training loss: 2.466140031814575
Validation loss: 2.0528609496290966

Epoch: 5| Step: 2
Training loss: 2.9987964630126953
Validation loss: 2.0646328874813613

Epoch: 5| Step: 3
Training loss: 2.2118210792541504
Validation loss: 2.052316742558633

Epoch: 5| Step: 4
Training loss: 2.1570534706115723
Validation loss: 2.054502906337861

Epoch: 5| Step: 5
Training loss: 1.6028926372528076
Validation loss: 2.062115066794939

Epoch: 5| Step: 6
Training loss: 2.136139392852783
Validation loss: 2.0798021747219946

Epoch: 5| Step: 7
Training loss: 1.704858422279358
Validation loss: 2.059250327848619

Epoch: 5| Step: 8
Training loss: 1.8565990924835205
Validation loss: 2.075947787172051

Epoch: 5| Step: 9
Training loss: 1.6277536153793335
Validation loss: 2.0689113358015656

Epoch: 5| Step: 10
Training loss: 2.2459118366241455
Validation loss: 2.0499437111680225

Epoch: 108| Step: 0
Training loss: 2.8725192546844482
Validation loss: 2.070393475153113

Epoch: 5| Step: 1
Training loss: 1.9237438440322876
Validation loss: 2.0438961175180252

Epoch: 5| Step: 2
Training loss: 2.1279892921447754
Validation loss: 2.065218258929509

Epoch: 5| Step: 3
Training loss: 2.2858798503875732
Validation loss: 2.048974484525701

Epoch: 5| Step: 4
Training loss: 2.1603662967681885
Validation loss: 2.0550994027045464

Epoch: 5| Step: 5
Training loss: 2.263084888458252
Validation loss: 2.0549099342797392

Epoch: 5| Step: 6
Training loss: 1.8409141302108765
Validation loss: 2.081427699776106

Epoch: 5| Step: 7
Training loss: 2.1404542922973633
Validation loss: 2.0669845329817904

Epoch: 5| Step: 8
Training loss: 2.00358510017395
Validation loss: 2.0598737219328522

Epoch: 5| Step: 9
Training loss: 2.425414562225342
Validation loss: 2.071783733624284

Epoch: 5| Step: 10
Training loss: 1.945335865020752
Validation loss: 2.087704235507596

Epoch: 109| Step: 0
Training loss: 1.586216688156128
Validation loss: 2.056562218614804

Epoch: 5| Step: 1
Training loss: 2.5655295848846436
Validation loss: 2.047476642875261

Epoch: 5| Step: 2
Training loss: 2.2407736778259277
Validation loss: 2.061852180829612

Epoch: 5| Step: 3
Training loss: 2.0007030963897705
Validation loss: 2.0765343686585784

Epoch: 5| Step: 4
Training loss: 1.9110801219940186
Validation loss: 2.048844970682616

Epoch: 5| Step: 5
Training loss: 2.4872140884399414
Validation loss: 2.067632245761092

Epoch: 5| Step: 6
Training loss: 2.4675798416137695
Validation loss: 2.0734937408918976

Epoch: 5| Step: 7
Training loss: 2.0509417057037354
Validation loss: 2.0452157464078677

Epoch: 5| Step: 8
Training loss: 2.110966444015503
Validation loss: 2.0794882953807874

Epoch: 5| Step: 9
Training loss: 2.2825264930725098
Validation loss: 2.0630116770344396

Epoch: 5| Step: 10
Training loss: 2.0872855186462402
Validation loss: 2.058738657223281

Epoch: 110| Step: 0
Training loss: 2.385514497756958
Validation loss: 2.065457249200472

Epoch: 5| Step: 1
Training loss: 2.0452685356140137
Validation loss: 2.061127967731927

Epoch: 5| Step: 2
Training loss: 2.5020546913146973
Validation loss: 2.0440037596610283

Epoch: 5| Step: 3
Training loss: 1.9613926410675049
Validation loss: 2.0741771318579234

Epoch: 5| Step: 4
Training loss: 2.749147415161133
Validation loss: 2.0459735214069323

Epoch: 5| Step: 5
Training loss: 1.6686592102050781
Validation loss: 2.0564518051762737

Epoch: 5| Step: 6
Training loss: 2.566600799560547
Validation loss: 2.0694074989646993

Epoch: 5| Step: 7
Training loss: 1.5720477104187012
Validation loss: 2.053696681094426

Epoch: 5| Step: 8
Training loss: 2.3180527687072754
Validation loss: 2.0519934405562696

Epoch: 5| Step: 9
Training loss: 2.02976393699646
Validation loss: 2.0566309780202885

Epoch: 5| Step: 10
Training loss: 1.9367971420288086
Validation loss: 2.0451800771938857

Epoch: 111| Step: 0
Training loss: 2.395150899887085
Validation loss: 2.058650170603106

Epoch: 5| Step: 1
Training loss: 1.5242364406585693
Validation loss: 2.047876465705133

Epoch: 5| Step: 2
Training loss: 2.29237699508667
Validation loss: 2.061665706737067

Epoch: 5| Step: 3
Training loss: 2.0231785774230957
Validation loss: 2.05345183034097

Epoch: 5| Step: 4
Training loss: 2.2820212841033936
Validation loss: 2.0571838758325063

Epoch: 5| Step: 5
Training loss: 1.784334421157837
Validation loss: 2.0472409391915924

Epoch: 5| Step: 6
Training loss: 2.4849741458892822
Validation loss: 2.0538677092521422

Epoch: 5| Step: 7
Training loss: 1.8794174194335938
Validation loss: 2.052212590812355

Epoch: 5| Step: 8
Training loss: 2.546133518218994
Validation loss: 2.0723700677194903

Epoch: 5| Step: 9
Training loss: 1.91518235206604
Validation loss: 2.0499244120813187

Epoch: 5| Step: 10
Training loss: 2.736875057220459
Validation loss: 2.0646888825201217

Epoch: 112| Step: 0
Training loss: 1.857456922531128
Validation loss: 2.0525305040421022

Epoch: 5| Step: 1
Training loss: 2.148756504058838
Validation loss: 2.064418359469342

Epoch: 5| Step: 2
Training loss: 2.256911277770996
Validation loss: 2.04990731259828

Epoch: 5| Step: 3
Training loss: 2.039299488067627
Validation loss: 2.0630946620818107

Epoch: 5| Step: 4
Training loss: 2.253218173980713
Validation loss: 2.049277041548042

Epoch: 5| Step: 5
Training loss: 1.6678798198699951
Validation loss: 2.0472707581776444

Epoch: 5| Step: 6
Training loss: 1.6855642795562744
Validation loss: 2.0661652934166694

Epoch: 5| Step: 7
Training loss: 2.484968662261963
Validation loss: 2.0519401360583562

Epoch: 5| Step: 8
Training loss: 2.731290340423584
Validation loss: 2.057767391204834

Epoch: 5| Step: 9
Training loss: 2.6915063858032227
Validation loss: 2.073015013048726

Epoch: 5| Step: 10
Training loss: 1.844190239906311
Validation loss: 2.053264497428812

Epoch: 113| Step: 0
Training loss: 2.3245744705200195
Validation loss: 2.0760536193847656

Epoch: 5| Step: 1
Training loss: 2.3211522102355957
Validation loss: 2.042948674130183

Epoch: 5| Step: 2
Training loss: 1.9787492752075195
Validation loss: 2.0694199531309065

Epoch: 5| Step: 3
Training loss: 2.07170033454895
Validation loss: 2.065371605657762

Epoch: 5| Step: 4
Training loss: 2.7430319786071777
Validation loss: 2.063018775755359

Epoch: 5| Step: 5
Training loss: 2.2435717582702637
Validation loss: 2.0617149350463704

Epoch: 5| Step: 6
Training loss: 2.2024054527282715
Validation loss: 2.06266418451904

Epoch: 5| Step: 7
Training loss: 2.3818447589874268
Validation loss: 2.088427928186232

Epoch: 5| Step: 8
Training loss: 2.291193723678589
Validation loss: 2.060243402757952

Epoch: 5| Step: 9
Training loss: 1.4223474264144897
Validation loss: 2.0578453874075286

Epoch: 5| Step: 10
Training loss: 1.760885238647461
Validation loss: 2.060144205247202

Epoch: 114| Step: 0
Training loss: 1.737005591392517
Validation loss: 2.0635525744448424

Epoch: 5| Step: 1
Training loss: 2.8845791816711426
Validation loss: 2.054653436906876

Epoch: 5| Step: 2
Training loss: 2.5538902282714844
Validation loss: 2.0859220233014835

Epoch: 5| Step: 3
Training loss: 2.326012134552002
Validation loss: 2.0305601076413224

Epoch: 5| Step: 4
Training loss: 1.980926275253296
Validation loss: 2.0783147119706675

Epoch: 5| Step: 5
Training loss: 1.688982605934143
Validation loss: 2.0678481812118203

Epoch: 5| Step: 6
Training loss: 2.384796380996704
Validation loss: 2.051984699823523

Epoch: 5| Step: 7
Training loss: 2.0991833209991455
Validation loss: 2.04346784212256

Epoch: 5| Step: 8
Training loss: 1.827498197555542
Validation loss: 2.0473667767740067

Epoch: 5| Step: 9
Training loss: 2.331895112991333
Validation loss: 2.056564479745844

Epoch: 5| Step: 10
Training loss: 1.821164846420288
Validation loss: 2.038054238083542

Epoch: 115| Step: 0
Training loss: 2.120373249053955
Validation loss: 2.0421178097366006

Epoch: 5| Step: 1
Training loss: 2.469782829284668
Validation loss: 2.049300898787796

Epoch: 5| Step: 2
Training loss: 1.7411396503448486
Validation loss: 2.0774150330533265

Epoch: 5| Step: 3
Training loss: 3.022449493408203
Validation loss: 2.056814173216461

Epoch: 5| Step: 4
Training loss: 1.8446861505508423
Validation loss: 2.0716398967209684

Epoch: 5| Step: 5
Training loss: 3.035691022872925
Validation loss: 2.053694966018841

Epoch: 5| Step: 6
Training loss: 1.9195610284805298
Validation loss: 2.0610484410357732

Epoch: 5| Step: 7
Training loss: 1.845330834388733
Validation loss: 2.0593703985214233

Epoch: 5| Step: 8
Training loss: 1.6491177082061768
Validation loss: 2.061277343380836

Epoch: 5| Step: 9
Training loss: 2.1941707134246826
Validation loss: 2.0564760623439664

Epoch: 5| Step: 10
Training loss: 1.8483256101608276
Validation loss: 2.071469130054597

Epoch: 116| Step: 0
Training loss: 2.3034415245056152
Validation loss: 2.060477169611121

Epoch: 5| Step: 1
Training loss: 1.9410037994384766
Validation loss: 2.0553901631345033

Epoch: 5| Step: 2
Training loss: 1.9310203790664673
Validation loss: 2.0477213269920758

Epoch: 5| Step: 3
Training loss: 1.8730957508087158
Validation loss: 2.0612327821793093

Epoch: 5| Step: 4
Training loss: 2.6654086112976074
Validation loss: 2.047449872057925

Epoch: 5| Step: 5
Training loss: 2.358271360397339
Validation loss: 2.057597775613108

Epoch: 5| Step: 6
Training loss: 2.1352782249450684
Validation loss: 2.037954866245229

Epoch: 5| Step: 7
Training loss: 2.3548855781555176
Validation loss: 2.0552570794218328

Epoch: 5| Step: 8
Training loss: 1.8820991516113281
Validation loss: 2.0628617886574037

Epoch: 5| Step: 9
Training loss: 1.9081951379776
Validation loss: 2.0588870304887013

Epoch: 5| Step: 10
Training loss: 2.264540195465088
Validation loss: 2.0773541196700065

Epoch: 117| Step: 0
Training loss: 1.730362892150879
Validation loss: 2.0727406547915552

Epoch: 5| Step: 1
Training loss: 2.3247368335723877
Validation loss: 2.0590295996717227

Epoch: 5| Step: 2
Training loss: 2.486816883087158
Validation loss: 2.081112692433019

Epoch: 5| Step: 3
Training loss: 2.1794726848602295
Validation loss: 2.04660100834344

Epoch: 5| Step: 4
Training loss: 2.068702220916748
Validation loss: 2.0740128947842504

Epoch: 5| Step: 5
Training loss: 2.3936848640441895
Validation loss: 2.065315277345719

Epoch: 5| Step: 6
Training loss: 1.589880347251892
Validation loss: 2.0557476179574126

Epoch: 5| Step: 7
Training loss: 1.9327478408813477
Validation loss: 2.074956122265067

Epoch: 5| Step: 8
Training loss: 2.3530943393707275
Validation loss: 2.056978723054291

Epoch: 5| Step: 9
Training loss: 2.4141125679016113
Validation loss: 2.066290209370275

Epoch: 5| Step: 10
Training loss: 2.092588424682617
Validation loss: 2.056743403916718

Epoch: 118| Step: 0
Training loss: 2.2371416091918945
Validation loss: 2.0767599408344557

Epoch: 5| Step: 1
Training loss: 1.5960866212844849
Validation loss: 2.0583308768528763

Epoch: 5| Step: 2
Training loss: 2.0422282218933105
Validation loss: 2.05899546223302

Epoch: 5| Step: 3
Training loss: 2.4839329719543457
Validation loss: 2.0461450110199633

Epoch: 5| Step: 4
Training loss: 1.8082656860351562
Validation loss: 2.054629082320839

Epoch: 5| Step: 5
Training loss: 2.1134390830993652
Validation loss: 2.049563043860979

Epoch: 5| Step: 6
Training loss: 2.3569424152374268
Validation loss: 2.058264728515379

Epoch: 5| Step: 7
Training loss: 2.255910873413086
Validation loss: 2.0850625473965883

Epoch: 5| Step: 8
Training loss: 1.8865854740142822
Validation loss: 2.0627593109684605

Epoch: 5| Step: 9
Training loss: 2.390291690826416
Validation loss: 2.064615013778851

Epoch: 5| Step: 10
Training loss: 2.4295990467071533
Validation loss: 2.057459387727963

Epoch: 119| Step: 0
Training loss: 1.8252776861190796
Validation loss: 2.063846395861718

Epoch: 5| Step: 1
Training loss: 1.9995670318603516
Validation loss: 2.054644728219637

Epoch: 5| Step: 2
Training loss: 2.2693428993225098
Validation loss: 2.0465964001993977

Epoch: 5| Step: 3
Training loss: 2.284358263015747
Validation loss: 2.024034487303867

Epoch: 5| Step: 4
Training loss: 2.343693971633911
Validation loss: 2.0592314427898777

Epoch: 5| Step: 5
Training loss: 2.2979183197021484
Validation loss: 2.0485182321199806

Epoch: 5| Step: 6
Training loss: 1.4801206588745117
Validation loss: 2.0609253068124094

Epoch: 5| Step: 7
Training loss: 2.0197298526763916
Validation loss: 2.0616327716458227

Epoch: 5| Step: 8
Training loss: 2.281728744506836
Validation loss: 2.0546037920059694

Epoch: 5| Step: 9
Training loss: 2.3417885303497314
Validation loss: 2.0464072471023886

Epoch: 5| Step: 10
Training loss: 2.3717803955078125
Validation loss: 2.0483182361049037

Epoch: 120| Step: 0
Training loss: 2.9907069206237793
Validation loss: 2.0699842309439056

Epoch: 5| Step: 1
Training loss: 2.2845022678375244
Validation loss: 2.0458348387031147

Epoch: 5| Step: 2
Training loss: 2.122321605682373
Validation loss: 2.0303001403808594

Epoch: 5| Step: 3
Training loss: 1.9613975286483765
Validation loss: 2.0497248480396886

Epoch: 5| Step: 4
Training loss: 1.9980682134628296
Validation loss: 2.066000833306261

Epoch: 5| Step: 5
Training loss: 2.3531742095947266
Validation loss: 2.0607016189123994

Epoch: 5| Step: 6
Training loss: 2.305041790008545
Validation loss: 2.060982063252439

Epoch: 5| Step: 7
Training loss: 1.660857915878296
Validation loss: 2.04221434234291

Epoch: 5| Step: 8
Training loss: 2.417955160140991
Validation loss: 2.068700880132696

Epoch: 5| Step: 9
Training loss: 1.9270761013031006
Validation loss: 2.0540325744177705

Epoch: 5| Step: 10
Training loss: 1.1984021663665771
Validation loss: 2.054375179352299

Epoch: 121| Step: 0
Training loss: 1.7483142614364624
Validation loss: 2.072835127512614

Epoch: 5| Step: 1
Training loss: 2.145301342010498
Validation loss: 2.0565956971978627

Epoch: 5| Step: 2
Training loss: 1.6774753332138062
Validation loss: 2.071488539377848

Epoch: 5| Step: 3
Training loss: 2.136728048324585
Validation loss: 2.0494922104702202

Epoch: 5| Step: 4
Training loss: 2.5061898231506348
Validation loss: 2.0396708250045776

Epoch: 5| Step: 5
Training loss: 2.318115234375
Validation loss: 2.0423676634347565

Epoch: 5| Step: 6
Training loss: 1.8045610189437866
Validation loss: 2.041608702751898

Epoch: 5| Step: 7
Training loss: 2.0920989513397217
Validation loss: 2.0392414651891237

Epoch: 5| Step: 8
Training loss: 1.6251938343048096
Validation loss: 2.0495765004106747

Epoch: 5| Step: 9
Training loss: 2.6009294986724854
Validation loss: 2.0648371122216664

Epoch: 5| Step: 10
Training loss: 2.75034236907959
Validation loss: 2.0528514846678703

Epoch: 122| Step: 0
Training loss: 1.9532887935638428
Validation loss: 2.06165208355073

Epoch: 5| Step: 1
Training loss: 2.254173517227173
Validation loss: 2.070591426664783

Epoch: 5| Step: 2
Training loss: 2.428615093231201
Validation loss: 2.044484293589028

Epoch: 5| Step: 3
Training loss: 1.8686481714248657
Validation loss: 2.074924676649032

Epoch: 5| Step: 4
Training loss: 2.2447028160095215
Validation loss: 2.050336137894661

Epoch: 5| Step: 5
Training loss: 2.0184242725372314
Validation loss: 2.0461289369931785

Epoch: 5| Step: 6
Training loss: 2.114802837371826
Validation loss: 2.0287378782867105

Epoch: 5| Step: 7
Training loss: 1.9398376941680908
Validation loss: 2.045775516058809

Epoch: 5| Step: 8
Training loss: 2.1828057765960693
Validation loss: 2.0239984450801725

Epoch: 5| Step: 9
Training loss: 2.1330864429473877
Validation loss: 2.0296592315038047

Epoch: 5| Step: 10
Training loss: 2.2708559036254883
Validation loss: 2.0532395198781

Epoch: 123| Step: 0
Training loss: 2.5555405616760254
Validation loss: 2.0632975870563137

Epoch: 5| Step: 1
Training loss: 1.8957096338272095
Validation loss: 2.0530944152544905

Epoch: 5| Step: 2
Training loss: 1.868556022644043
Validation loss: 2.0607041479438863

Epoch: 5| Step: 3
Training loss: 2.0143139362335205
Validation loss: 2.0339997788911224

Epoch: 5| Step: 4
Training loss: 1.8607463836669922
Validation loss: 2.0638175549045688

Epoch: 5| Step: 5
Training loss: 2.5777969360351562
Validation loss: 2.075597217006068

Epoch: 5| Step: 6
Training loss: 2.6467552185058594
Validation loss: 2.047992515307601

Epoch: 5| Step: 7
Training loss: 2.1714608669281006
Validation loss: 2.0695881766657673

Epoch: 5| Step: 8
Training loss: 1.8722890615463257
Validation loss: 2.063174924542827

Epoch: 5| Step: 9
Training loss: 1.9574161767959595
Validation loss: 2.0528361079513386

Epoch: 5| Step: 10
Training loss: 1.9219465255737305
Validation loss: 2.0396262586757703

Epoch: 124| Step: 0
Training loss: 2.7870309352874756
Validation loss: 2.059074322382609

Epoch: 5| Step: 1
Training loss: 1.8462448120117188
Validation loss: 2.0787606957138225

Epoch: 5| Step: 2
Training loss: 2.189824342727661
Validation loss: 2.06660060985114

Epoch: 5| Step: 3
Training loss: 2.153308391571045
Validation loss: 2.0513323276273665

Epoch: 5| Step: 4
Training loss: 2.1215085983276367
Validation loss: 2.055897379434237

Epoch: 5| Step: 5
Training loss: 1.788744330406189
Validation loss: 2.040275950585642

Epoch: 5| Step: 6
Training loss: 2.036614179611206
Validation loss: 2.0715038571306454

Epoch: 5| Step: 7
Training loss: 2.393857002258301
Validation loss: 2.0715259813493296

Epoch: 5| Step: 8
Training loss: 2.0090465545654297
Validation loss: 2.0294583189872

Epoch: 5| Step: 9
Training loss: 1.6042115688323975
Validation loss: 2.0547026459888746

Epoch: 5| Step: 10
Training loss: 2.2022621631622314
Validation loss: 2.0586750738082396

Epoch: 125| Step: 0
Training loss: 1.620037317276001
Validation loss: 2.0491872974621352

Epoch: 5| Step: 1
Training loss: 2.4359073638916016
Validation loss: 2.073074822784752

Epoch: 5| Step: 2
Training loss: 2.319531202316284
Validation loss: 2.0661529905052594

Epoch: 5| Step: 3
Training loss: 2.1953012943267822
Validation loss: 2.0498022635777793

Epoch: 5| Step: 4
Training loss: 1.9249340295791626
Validation loss: 2.041195882264004

Epoch: 5| Step: 5
Training loss: 1.8744909763336182
Validation loss: 2.047020367396775

Epoch: 5| Step: 6
Training loss: 2.130976438522339
Validation loss: 2.0437913197343067

Epoch: 5| Step: 7
Training loss: 2.0273871421813965
Validation loss: 2.0752894750205417

Epoch: 5| Step: 8
Training loss: 2.6961426734924316
Validation loss: 2.054903248304962

Epoch: 5| Step: 9
Training loss: 1.7869927883148193
Validation loss: 2.0662433575558405

Epoch: 5| Step: 10
Training loss: 2.230642318725586
Validation loss: 2.053359821278562

Epoch: 126| Step: 0
Training loss: 2.5525693893432617
Validation loss: 2.0349122170479066

Epoch: 5| Step: 1
Training loss: 1.7653543949127197
Validation loss: 2.044964623707597

Epoch: 5| Step: 2
Training loss: 1.7336702346801758
Validation loss: 2.0413750166534097

Epoch: 5| Step: 3
Training loss: 2.3230814933776855
Validation loss: 2.041933985166652

Epoch: 5| Step: 4
Training loss: 1.833949089050293
Validation loss: 2.059976238076405

Epoch: 5| Step: 5
Training loss: 2.2656137943267822
Validation loss: 2.0523444862775904

Epoch: 5| Step: 6
Training loss: 2.0459158420562744
Validation loss: 2.0389760245559034

Epoch: 5| Step: 7
Training loss: 1.897454857826233
Validation loss: 2.062798769243302

Epoch: 5| Step: 8
Training loss: 2.2377445697784424
Validation loss: 2.0402842272994337

Epoch: 5| Step: 9
Training loss: 2.4937844276428223
Validation loss: 2.0669349419173373

Epoch: 5| Step: 10
Training loss: 2.0581185817718506
Validation loss: 2.0532950624342887

Epoch: 127| Step: 0
Training loss: 2.0128238201141357
Validation loss: 2.029514261471328

Epoch: 5| Step: 1
Training loss: 2.0799145698547363
Validation loss: 2.046870639247279

Epoch: 5| Step: 2
Training loss: 2.2277140617370605
Validation loss: 2.0506895049925773

Epoch: 5| Step: 3
Training loss: 2.4113125801086426
Validation loss: 2.0321068430459626

Epoch: 5| Step: 4
Training loss: 2.432025194168091
Validation loss: 2.03087874638137

Epoch: 5| Step: 5
Training loss: 2.5900018215179443
Validation loss: 2.0339768945529895

Epoch: 5| Step: 6
Training loss: 1.3782850503921509
Validation loss: 2.056473998613255

Epoch: 5| Step: 7
Training loss: 1.7150719165802002
Validation loss: 2.023976848971459

Epoch: 5| Step: 8
Training loss: 2.0604088306427
Validation loss: 2.0536483103229153

Epoch: 5| Step: 9
Training loss: 2.1754536628723145
Validation loss: 2.0488868221159904

Epoch: 5| Step: 10
Training loss: 2.130952835083008
Validation loss: 2.0590796906461

Epoch: 128| Step: 0
Training loss: 2.033116102218628
Validation loss: 2.0430705393514326

Epoch: 5| Step: 1
Training loss: 1.739088773727417
Validation loss: 2.0652087401318293

Epoch: 5| Step: 2
Training loss: 1.3350635766983032
Validation loss: 2.028674440999185

Epoch: 5| Step: 3
Training loss: 1.5173711776733398
Validation loss: 2.0531922078901723

Epoch: 5| Step: 4
Training loss: 2.094670057296753
Validation loss: 2.044116876458609

Epoch: 5| Step: 5
Training loss: 2.2332615852355957
Validation loss: 2.059599620039745

Epoch: 5| Step: 6
Training loss: 2.403808355331421
Validation loss: 2.050809878174977

Epoch: 5| Step: 7
Training loss: 2.5443553924560547
Validation loss: 2.0382467316042994

Epoch: 5| Step: 8
Training loss: 2.3270726203918457
Validation loss: 2.075434389934745

Epoch: 5| Step: 9
Training loss: 2.384774684906006
Validation loss: 2.0489187958419963

Epoch: 5| Step: 10
Training loss: 2.717930793762207
Validation loss: 2.0341281352504605

Epoch: 129| Step: 0
Training loss: 2.5946044921875
Validation loss: 2.031743654640772

Epoch: 5| Step: 1
Training loss: 2.2030410766601562
Validation loss: 2.0540920765169206

Epoch: 5| Step: 2
Training loss: 1.895947813987732
Validation loss: 2.073219322389172

Epoch: 5| Step: 3
Training loss: 2.40289044380188
Validation loss: 2.0462729495058776

Epoch: 5| Step: 4
Training loss: 1.9259412288665771
Validation loss: 2.0411322719307354

Epoch: 5| Step: 5
Training loss: 1.8501545190811157
Validation loss: 2.01990621448845

Epoch: 5| Step: 6
Training loss: 2.2318954467773438
Validation loss: 2.047625077668057

Epoch: 5| Step: 7
Training loss: 2.6388442516326904
Validation loss: 2.065525193368235

Epoch: 5| Step: 8
Training loss: 1.6525776386260986
Validation loss: 2.0304848481250066

Epoch: 5| Step: 9
Training loss: 1.521742582321167
Validation loss: 2.0578416124466927

Epoch: 5| Step: 10
Training loss: 2.128803014755249
Validation loss: 2.0646286369651876

Epoch: 130| Step: 0
Training loss: 1.719042420387268
Validation loss: 2.062011326512983

Epoch: 5| Step: 1
Training loss: 2.039747953414917
Validation loss: 2.034364281162139

Epoch: 5| Step: 2
Training loss: 2.7049052715301514
Validation loss: 2.0776459222198813

Epoch: 5| Step: 3
Training loss: 2.3351287841796875
Validation loss: 2.060008220775153

Epoch: 5| Step: 4
Training loss: 1.3596036434173584
Validation loss: 2.050711270301573

Epoch: 5| Step: 5
Training loss: 2.0860745906829834
Validation loss: 2.0762503557307745

Epoch: 5| Step: 6
Training loss: 2.0232081413269043
Validation loss: 2.0810688234144643

Epoch: 5| Step: 7
Training loss: 2.7975597381591797
Validation loss: 2.078811340434577

Epoch: 5| Step: 8
Training loss: 1.971327543258667
Validation loss: 2.059994024615134

Epoch: 5| Step: 9
Training loss: 1.9534485340118408
Validation loss: 2.0359136930076023

Epoch: 5| Step: 10
Training loss: 2.0900862216949463
Validation loss: 2.0459794382895193

Epoch: 131| Step: 0
Training loss: 2.055738687515259
Validation loss: 2.0608189900716147

Epoch: 5| Step: 1
Training loss: 2.023435115814209
Validation loss: 2.072819335486299

Epoch: 5| Step: 2
Training loss: 3.005744457244873
Validation loss: 2.04429962301767

Epoch: 5| Step: 3
Training loss: 2.1291377544403076
Validation loss: 2.065437647604173

Epoch: 5| Step: 4
Training loss: 2.6537680625915527
Validation loss: 2.072549737909789

Epoch: 5| Step: 5
Training loss: 1.8344364166259766
Validation loss: 2.0488886846009122

Epoch: 5| Step: 6
Training loss: 2.1088805198669434
Validation loss: 2.0500161827251477

Epoch: 5| Step: 7
Training loss: 1.7859306335449219
Validation loss: 2.073006522270941

Epoch: 5| Step: 8
Training loss: 1.7535183429718018
Validation loss: 2.0449991328741914

Epoch: 5| Step: 9
Training loss: 1.9214742183685303
Validation loss: 2.0747710094656995

Epoch: 5| Step: 10
Training loss: 1.7127455472946167
Validation loss: 2.052090019308111

Epoch: 132| Step: 0
Training loss: 2.3506054878234863
Validation loss: 2.0421255057857883

Epoch: 5| Step: 1
Training loss: 2.2664647102355957
Validation loss: 2.039587564365838

Epoch: 5| Step: 2
Training loss: 2.0244851112365723
Validation loss: 2.0683630153697026

Epoch: 5| Step: 3
Training loss: 1.4603221416473389
Validation loss: 2.0822245433766353

Epoch: 5| Step: 4
Training loss: 1.8233928680419922
Validation loss: 2.0344607009682605

Epoch: 5| Step: 5
Training loss: 2.081399440765381
Validation loss: 2.075082948130946

Epoch: 5| Step: 6
Training loss: 2.6983299255371094
Validation loss: 2.0569388738242527

Epoch: 5| Step: 7
Training loss: 2.0145959854125977
Validation loss: 2.062340085224439

Epoch: 5| Step: 8
Training loss: 1.7023042440414429
Validation loss: 2.042259462418095

Epoch: 5| Step: 9
Training loss: 2.2628140449523926
Validation loss: 2.066610474740305

Epoch: 5| Step: 10
Training loss: 2.423694372177124
Validation loss: 2.0366149769034436

Epoch: 133| Step: 0
Training loss: 2.290445327758789
Validation loss: 2.0729837161238476

Epoch: 5| Step: 1
Training loss: 2.3626744747161865
Validation loss: 2.0583214939281507

Epoch: 5| Step: 2
Training loss: 2.160778284072876
Validation loss: 2.0547289207417476

Epoch: 5| Step: 3
Training loss: 1.8288376331329346
Validation loss: 2.0553200731995287

Epoch: 5| Step: 4
Training loss: 1.5429842472076416
Validation loss: 2.0518247030114614

Epoch: 5| Step: 5
Training loss: 2.0832011699676514
Validation loss: 2.0555319375889276

Epoch: 5| Step: 6
Training loss: 2.6115024089813232
Validation loss: 2.0772570589537263

Epoch: 5| Step: 7
Training loss: 1.9024360179901123
Validation loss: 2.0681693169378463

Epoch: 5| Step: 8
Training loss: 2.193213939666748
Validation loss: 2.0671415662252777

Epoch: 5| Step: 9
Training loss: 2.0620996952056885
Validation loss: 2.0506400113464682

Epoch: 5| Step: 10
Training loss: 1.9955426454544067
Validation loss: 2.0710173678654495

Epoch: 134| Step: 0
Training loss: 2.295811176300049
Validation loss: 2.057449153674546

Epoch: 5| Step: 1
Training loss: 2.2135918140411377
Validation loss: 2.057539583534323

Epoch: 5| Step: 2
Training loss: 1.585107445716858
Validation loss: 2.062450062844061

Epoch: 5| Step: 3
Training loss: 1.4103838205337524
Validation loss: 2.0726125163416707

Epoch: 5| Step: 4
Training loss: 2.2542312145233154
Validation loss: 2.0496932204051683

Epoch: 5| Step: 5
Training loss: 2.058043956756592
Validation loss: 2.0583275569382535

Epoch: 5| Step: 6
Training loss: 2.0361475944519043
Validation loss: 2.0552876072545208

Epoch: 5| Step: 7
Training loss: 2.192474842071533
Validation loss: 2.0686186385411087

Epoch: 5| Step: 8
Training loss: 2.2621912956237793
Validation loss: 2.058293256708371

Epoch: 5| Step: 9
Training loss: 1.990012526512146
Validation loss: 2.0491585436687676

Epoch: 5| Step: 10
Training loss: 2.4760735034942627
Validation loss: 2.0554467157651017

Epoch: 135| Step: 0
Training loss: 2.433607578277588
Validation loss: 2.0533436190697456

Epoch: 5| Step: 1
Training loss: 1.8066556453704834
Validation loss: 2.060473909942053

Epoch: 5| Step: 2
Training loss: 2.195645809173584
Validation loss: 2.0428832782212125

Epoch: 5| Step: 3
Training loss: 1.956459641456604
Validation loss: 2.0575118039243963

Epoch: 5| Step: 4
Training loss: 2.5558102130889893
Validation loss: 2.050534717498287

Epoch: 5| Step: 5
Training loss: 2.173232316970825
Validation loss: 2.0422586946077246

Epoch: 5| Step: 6
Training loss: 2.506014585494995
Validation loss: 2.0544983366484284

Epoch: 5| Step: 7
Training loss: 1.6972986459732056
Validation loss: 2.055225351805328

Epoch: 5| Step: 8
Training loss: 1.9266217947006226
Validation loss: 2.0458027778133268

Epoch: 5| Step: 9
Training loss: 1.7416696548461914
Validation loss: 2.063752399977817

Epoch: 5| Step: 10
Training loss: 1.8210408687591553
Validation loss: 2.028644190039686

Epoch: 136| Step: 0
Training loss: 1.4705017805099487
Validation loss: 2.0538321105382775

Epoch: 5| Step: 1
Training loss: 1.8224833011627197
Validation loss: 2.034304065089072

Epoch: 5| Step: 2
Training loss: 2.4902186393737793
Validation loss: 2.0813450198019705

Epoch: 5| Step: 3
Training loss: 2.274028778076172
Validation loss: 2.0543851314052457

Epoch: 5| Step: 4
Training loss: 2.3743724822998047
Validation loss: 2.0507549931926112

Epoch: 5| Step: 5
Training loss: 2.366827964782715
Validation loss: 2.078686355262674

Epoch: 5| Step: 6
Training loss: 1.6395829916000366
Validation loss: 2.0502831064244753

Epoch: 5| Step: 7
Training loss: 1.9953372478485107
Validation loss: 2.045076536875899

Epoch: 5| Step: 8
Training loss: 1.8851299285888672
Validation loss: 2.039354101304085

Epoch: 5| Step: 9
Training loss: 2.440047264099121
Validation loss: 2.0522738951508717

Epoch: 5| Step: 10
Training loss: 1.9327659606933594
Validation loss: 2.0501818746648808

Epoch: 137| Step: 0
Training loss: 1.3394355773925781
Validation loss: 2.0512818751796598

Epoch: 5| Step: 1
Training loss: 1.8894603252410889
Validation loss: 2.069402789556852

Epoch: 5| Step: 2
Training loss: 2.271641492843628
Validation loss: 2.0564576413041804

Epoch: 5| Step: 3
Training loss: 2.680752754211426
Validation loss: 2.056734836229714

Epoch: 5| Step: 4
Training loss: 2.4125139713287354
Validation loss: 2.0335572637537473

Epoch: 5| Step: 5
Training loss: 2.3789830207824707
Validation loss: 2.044185798655274

Epoch: 5| Step: 6
Training loss: 2.066218137741089
Validation loss: 2.0422194350150322

Epoch: 5| Step: 7
Training loss: 1.5877997875213623
Validation loss: 2.075949448411183

Epoch: 5| Step: 8
Training loss: 1.9880402088165283
Validation loss: 2.0479330939631306

Epoch: 5| Step: 9
Training loss: 2.013542652130127
Validation loss: 2.0563892805448143

Epoch: 5| Step: 10
Training loss: 2.142526149749756
Validation loss: 2.0394610871550856

Epoch: 138| Step: 0
Training loss: 2.0209147930145264
Validation loss: 2.0497446560090586

Epoch: 5| Step: 1
Training loss: 2.1585423946380615
Validation loss: 2.0444468349538822

Epoch: 5| Step: 2
Training loss: 1.7209783792495728
Validation loss: 2.057199934477447

Epoch: 5| Step: 3
Training loss: 2.2137603759765625
Validation loss: 2.053518138906007

Epoch: 5| Step: 4
Training loss: 2.0024020671844482
Validation loss: 2.0652087209045247

Epoch: 5| Step: 5
Training loss: 2.038001537322998
Validation loss: 2.058789826208545

Epoch: 5| Step: 6
Training loss: 1.773298978805542
Validation loss: 2.078835851402693

Epoch: 5| Step: 7
Training loss: 2.3963005542755127
Validation loss: 2.0661921219159196

Epoch: 5| Step: 8
Training loss: 1.7348806858062744
Validation loss: 2.0797362853122014

Epoch: 5| Step: 9
Training loss: 2.453676700592041
Validation loss: 2.049675310811689

Epoch: 5| Step: 10
Training loss: 2.3240721225738525
Validation loss: 2.0807919168985016

Epoch: 139| Step: 0
Training loss: 2.0059900283813477
Validation loss: 2.067199671140281

Epoch: 5| Step: 1
Training loss: 1.93185555934906
Validation loss: 2.0548607328886628

Epoch: 5| Step: 2
Training loss: 1.6307798624038696
Validation loss: 2.0644380764294694

Epoch: 5| Step: 3
Training loss: 2.6031100749969482
Validation loss: 2.072470159940822

Epoch: 5| Step: 4
Training loss: 2.5978598594665527
Validation loss: 2.057417223530431

Epoch: 5| Step: 5
Training loss: 1.6730581521987915
Validation loss: 2.0600050918517576

Epoch: 5| Step: 6
Training loss: 2.248378276824951
Validation loss: 2.0162313535649288

Epoch: 5| Step: 7
Training loss: 2.085129737854004
Validation loss: 2.0443322043265066

Epoch: 5| Step: 8
Training loss: 1.7283856868743896
Validation loss: 2.0677472750345864

Epoch: 5| Step: 9
Training loss: 2.233022689819336
Validation loss: 2.0629600324938373

Epoch: 5| Step: 10
Training loss: 1.9962674379348755
Validation loss: 2.0497864677060034

Epoch: 140| Step: 0
Training loss: 2.014583110809326
Validation loss: 2.053758318706225

Epoch: 5| Step: 1
Training loss: 2.212235450744629
Validation loss: 2.0598586759259625

Epoch: 5| Step: 2
Training loss: 2.2181053161621094
Validation loss: 2.059003637683007

Epoch: 5| Step: 3
Training loss: 1.9566856622695923
Validation loss: 2.0620351222253617

Epoch: 5| Step: 4
Training loss: 1.8221452236175537
Validation loss: 2.0605550581409084

Epoch: 5| Step: 5
Training loss: 2.385820150375366
Validation loss: 2.0767307678858438

Epoch: 5| Step: 6
Training loss: 2.3283615112304688
Validation loss: 2.0671382988652875

Epoch: 5| Step: 7
Training loss: 2.4015440940856934
Validation loss: 2.0581647580669773

Epoch: 5| Step: 8
Training loss: 1.8315643072128296
Validation loss: 2.0610561332395

Epoch: 5| Step: 9
Training loss: 1.8022619485855103
Validation loss: 2.0357317129770913

Epoch: 5| Step: 10
Training loss: 1.8011980056762695
Validation loss: 2.011660114411385

Epoch: 141| Step: 0
Training loss: 2.3817028999328613
Validation loss: 2.06030842309357

Epoch: 5| Step: 1
Training loss: 2.397430896759033
Validation loss: 2.063467069338727

Epoch: 5| Step: 2
Training loss: 1.996991753578186
Validation loss: 2.054456615960726

Epoch: 5| Step: 3
Training loss: 1.9342025518417358
Validation loss: 2.072977753095729

Epoch: 5| Step: 4
Training loss: 2.5625884532928467
Validation loss: 2.0507801219981205

Epoch: 5| Step: 5
Training loss: 1.8547710180282593
Validation loss: 2.026780684789022

Epoch: 5| Step: 6
Training loss: 1.7832705974578857
Validation loss: 2.0546580937600907

Epoch: 5| Step: 7
Training loss: 1.8814973831176758
Validation loss: 2.045743639751147

Epoch: 5| Step: 8
Training loss: 1.9514023065567017
Validation loss: 2.0519561357395624

Epoch: 5| Step: 9
Training loss: 1.7388293743133545
Validation loss: 2.0593462054447462

Epoch: 5| Step: 10
Training loss: 2.0559208393096924
Validation loss: 2.0470522654953824

Epoch: 142| Step: 0
Training loss: 2.09727144241333
Validation loss: 2.064748405128397

Epoch: 5| Step: 1
Training loss: 1.9136377573013306
Validation loss: 2.0796239965705463

Epoch: 5| Step: 2
Training loss: 1.5886545181274414
Validation loss: 2.0375647365405993

Epoch: 5| Step: 3
Training loss: 3.186157703399658
Validation loss: 2.0374371774734987

Epoch: 5| Step: 4
Training loss: 2.5145821571350098
Validation loss: 2.064325463387274

Epoch: 5| Step: 5
Training loss: 2.150890350341797
Validation loss: 2.0355648212535407

Epoch: 5| Step: 6
Training loss: 1.688476324081421
Validation loss: 2.080818085260289

Epoch: 5| Step: 7
Training loss: 1.8527748584747314
Validation loss: 2.0577175181399108

Epoch: 5| Step: 8
Training loss: 1.6477915048599243
Validation loss: 2.060334272282098

Epoch: 5| Step: 9
Training loss: 1.9500974416732788
Validation loss: 2.054101659405616

Epoch: 5| Step: 10
Training loss: 2.236673355102539
Validation loss: 2.057652194012878

Epoch: 143| Step: 0
Training loss: 2.290644884109497
Validation loss: 2.051312501712512

Epoch: 5| Step: 1
Training loss: 1.7776883840560913
Validation loss: 2.0518995920817056

Epoch: 5| Step: 2
Training loss: 2.5480217933654785
Validation loss: 2.0592287086671397

Epoch: 5| Step: 3
Training loss: 1.9819961786270142
Validation loss: 2.0508012694697224

Epoch: 5| Step: 4
Training loss: 1.6422561407089233
Validation loss: 2.0630324220144622

Epoch: 5| Step: 5
Training loss: 2.2104849815368652
Validation loss: 2.042663037136037

Epoch: 5| Step: 6
Training loss: 1.7311757802963257
Validation loss: 2.0784725886519237

Epoch: 5| Step: 7
Training loss: 1.9705257415771484
Validation loss: 2.0806312868672032

Epoch: 5| Step: 8
Training loss: 1.8521076440811157
Validation loss: 2.056604908358666

Epoch: 5| Step: 9
Training loss: 2.1839284896850586
Validation loss: 2.021414913156981

Epoch: 5| Step: 10
Training loss: 2.7076523303985596
Validation loss: 2.0630622589459984

Epoch: 144| Step: 0
Training loss: 1.806888222694397
Validation loss: 2.0654016771624164

Epoch: 5| Step: 1
Training loss: 1.7695305347442627
Validation loss: 2.026163972834105

Epoch: 5| Step: 2
Training loss: 1.2117111682891846
Validation loss: 2.0609797431576635

Epoch: 5| Step: 3
Training loss: 2.3150033950805664
Validation loss: 2.0152985229287097

Epoch: 5| Step: 4
Training loss: 2.348405122756958
Validation loss: 2.0778553972962084

Epoch: 5| Step: 5
Training loss: 1.6470733880996704
Validation loss: 2.0639375358499508

Epoch: 5| Step: 6
Training loss: 2.808056354522705
Validation loss: 2.093047370192825

Epoch: 5| Step: 7
Training loss: 2.089423894882202
Validation loss: 2.0372351459277573

Epoch: 5| Step: 8
Training loss: 1.5493475198745728
Validation loss: 2.0322703315365698

Epoch: 5| Step: 9
Training loss: 2.3185737133026123
Validation loss: 2.061608091477425

Epoch: 5| Step: 10
Training loss: 2.8407137393951416
Validation loss: 2.072052324971845

Epoch: 145| Step: 0
Training loss: 1.6366554498672485
Validation loss: 2.0628800263968845

Epoch: 5| Step: 1
Training loss: 1.403424859046936
Validation loss: 2.061622005636974

Epoch: 5| Step: 2
Training loss: 2.276336193084717
Validation loss: 2.0705046525565525

Epoch: 5| Step: 3
Training loss: 1.7016443014144897
Validation loss: 2.0569319827582246

Epoch: 5| Step: 4
Training loss: 1.87420654296875
Validation loss: 2.0284128227541522

Epoch: 5| Step: 5
Training loss: 2.114469528198242
Validation loss: 2.0582883024728424

Epoch: 5| Step: 6
Training loss: 2.492143154144287
Validation loss: 2.0452179754934003

Epoch: 5| Step: 7
Training loss: 2.099252223968506
Validation loss: 2.060881030174994

Epoch: 5| Step: 8
Training loss: 2.2245125770568848
Validation loss: 2.0511236998342697

Epoch: 5| Step: 9
Training loss: 1.7278869152069092
Validation loss: 2.056032244877149

Epoch: 5| Step: 10
Training loss: 3.1395504474639893
Validation loss: 2.0676599971709715

Epoch: 146| Step: 0
Training loss: 2.7091877460479736
Validation loss: 2.04864606934209

Epoch: 5| Step: 1
Training loss: 2.057680130004883
Validation loss: 2.0453550520763604

Epoch: 5| Step: 2
Training loss: 2.030412197113037
Validation loss: 2.0453305526446273

Epoch: 5| Step: 3
Training loss: 1.4536049365997314
Validation loss: 2.0410947799682617

Epoch: 5| Step: 4
Training loss: 2.0996487140655518
Validation loss: 2.041257817258117

Epoch: 5| Step: 5
Training loss: 2.092416763305664
Validation loss: 2.036634550299696

Epoch: 5| Step: 6
Training loss: 2.6935646533966064
Validation loss: 2.0447507186602523

Epoch: 5| Step: 7
Training loss: 1.725637435913086
Validation loss: 2.061435652035539

Epoch: 5| Step: 8
Training loss: 1.8002649545669556
Validation loss: 2.0261082751776582

Epoch: 5| Step: 9
Training loss: 1.7097915410995483
Validation loss: 2.0438252802818053

Epoch: 5| Step: 10
Training loss: 2.237302780151367
Validation loss: 2.064179165388948

Epoch: 147| Step: 0
Training loss: 2.745096206665039
Validation loss: 2.056733990228304

Epoch: 5| Step: 1
Training loss: 2.4541313648223877
Validation loss: 2.060210080556972

Epoch: 5| Step: 2
Training loss: 1.6682201623916626
Validation loss: 2.0662558976040093

Epoch: 5| Step: 3
Training loss: 2.2573227882385254
Validation loss: 2.046617309252421

Epoch: 5| Step: 4
Training loss: 2.437648057937622
Validation loss: 2.044365980291879

Epoch: 5| Step: 5
Training loss: 1.2649972438812256
Validation loss: 2.083220024262705

Epoch: 5| Step: 6
Training loss: 1.8286832571029663
Validation loss: 2.043176499746179

Epoch: 5| Step: 7
Training loss: 2.0581536293029785
Validation loss: 2.076155721500356

Epoch: 5| Step: 8
Training loss: 1.6667673587799072
Validation loss: 2.0533625387376353

Epoch: 5| Step: 9
Training loss: 2.228137254714966
Validation loss: 2.020469661681883

Epoch: 5| Step: 10
Training loss: 1.9662971496582031
Validation loss: 2.0569030020826604

Epoch: 148| Step: 0
Training loss: 1.8764957189559937
Validation loss: 2.0410389387479393

Epoch: 5| Step: 1
Training loss: 2.3036835193634033
Validation loss: 2.0746858786511164

Epoch: 5| Step: 2
Training loss: 2.390134334564209
Validation loss: 2.0644602442300446

Epoch: 5| Step: 3
Training loss: 2.5627779960632324
Validation loss: 2.0685165876983316

Epoch: 5| Step: 4
Training loss: 1.6708555221557617
Validation loss: 2.0525555623474943

Epoch: 5| Step: 5
Training loss: 2.1296939849853516
Validation loss: 2.0565751291090444

Epoch: 5| Step: 6
Training loss: 1.871609091758728
Validation loss: 2.046462698649335

Epoch: 5| Step: 7
Training loss: 2.138169050216675
Validation loss: 2.0637624379127257

Epoch: 5| Step: 8
Training loss: 2.0155789852142334
Validation loss: 2.055312036186136

Epoch: 5| Step: 9
Training loss: 1.7216522693634033
Validation loss: 2.0765503119396906

Epoch: 5| Step: 10
Training loss: 1.815615177154541
Validation loss: 2.043317446144678

Epoch: 149| Step: 0
Training loss: 2.022862434387207
Validation loss: 2.0747853735441804

Epoch: 5| Step: 1
Training loss: 2.8143599033355713
Validation loss: 2.0375570815096617

Epoch: 5| Step: 2
Training loss: 1.793511986732483
Validation loss: 2.0899154652831373

Epoch: 5| Step: 3
Training loss: 1.9881467819213867
Validation loss: 2.058037119527017

Epoch: 5| Step: 4
Training loss: 2.1183202266693115
Validation loss: 2.0597182012373403

Epoch: 5| Step: 5
Training loss: 1.5254138708114624
Validation loss: 2.08266350658991

Epoch: 5| Step: 6
Training loss: 1.93368399143219
Validation loss: 2.080863009216965

Epoch: 5| Step: 7
Training loss: 2.232029438018799
Validation loss: 2.0445891952001922

Epoch: 5| Step: 8
Training loss: 2.0164105892181396
Validation loss: 2.0778397129428003

Epoch: 5| Step: 9
Training loss: 2.0617897510528564
Validation loss: 2.031849376616939

Epoch: 5| Step: 10
Training loss: 1.8389849662780762
Validation loss: 2.056717557291831

Epoch: 150| Step: 0
Training loss: 2.153226375579834
Validation loss: 2.07607812394378

Epoch: 5| Step: 1
Training loss: 2.473615884780884
Validation loss: 2.0477373728188137

Epoch: 5| Step: 2
Training loss: 2.0400137901306152
Validation loss: 2.048732831913938

Epoch: 5| Step: 3
Training loss: 2.410795211791992
Validation loss: 2.0667268729978994

Epoch: 5| Step: 4
Training loss: 1.7450847625732422
Validation loss: 2.0655499401912896

Epoch: 5| Step: 5
Training loss: 1.5269107818603516
Validation loss: 2.045928453886381

Epoch: 5| Step: 6
Training loss: 2.4312584400177
Validation loss: 2.0515544299156434

Epoch: 5| Step: 7
Training loss: 2.1960346698760986
Validation loss: 2.053776785891543

Epoch: 5| Step: 8
Training loss: 1.8845990896224976
Validation loss: 2.0664666263006066

Epoch: 5| Step: 9
Training loss: 1.6321319341659546
Validation loss: 2.066117884010397

Epoch: 5| Step: 10
Training loss: 2.0862536430358887
Validation loss: 2.0449267510444886

Epoch: 151| Step: 0
Training loss: 1.9591115713119507
Validation loss: 2.046419971732683

Epoch: 5| Step: 1
Training loss: 1.8858423233032227
Validation loss: 2.0564916928609214

Epoch: 5| Step: 2
Training loss: 1.5976804494857788
Validation loss: 2.0714871242482173

Epoch: 5| Step: 3
Training loss: 1.7613941431045532
Validation loss: 2.058445926635496

Epoch: 5| Step: 4
Training loss: 2.851221799850464
Validation loss: 2.0539723211719143

Epoch: 5| Step: 5
Training loss: 1.4426532983779907
Validation loss: 2.0615672860094296

Epoch: 5| Step: 6
Training loss: 1.860877275466919
Validation loss: 2.0693783811343613

Epoch: 5| Step: 7
Training loss: 2.540714740753174
Validation loss: 2.0510200761979624

Epoch: 5| Step: 8
Training loss: 2.337620735168457
Validation loss: 2.028881860035722

Epoch: 5| Step: 9
Training loss: 2.4001009464263916
Validation loss: 2.0531795614509174

Epoch: 5| Step: 10
Training loss: 1.6749967336654663
Validation loss: 2.054280227230441

Epoch: 152| Step: 0
Training loss: 1.8688039779663086
Validation loss: 2.06326521724783

Epoch: 5| Step: 1
Training loss: 1.86699640750885
Validation loss: 2.05947704469004

Epoch: 5| Step: 2
Training loss: 2.462585926055908
Validation loss: 2.0541722748869207

Epoch: 5| Step: 3
Training loss: 2.098240375518799
Validation loss: 2.053493686901626

Epoch: 5| Step: 4
Training loss: 2.369983196258545
Validation loss: 2.054888766299012

Epoch: 5| Step: 5
Training loss: 2.723019599914551
Validation loss: 2.081185499827067

Epoch: 5| Step: 6
Training loss: 1.430084228515625
Validation loss: 2.084256646453693

Epoch: 5| Step: 7
Training loss: 1.3146921396255493
Validation loss: 2.0710280005649855

Epoch: 5| Step: 8
Training loss: 1.933220624923706
Validation loss: 2.0778494086316837

Epoch: 5| Step: 9
Training loss: 1.6629409790039062
Validation loss: 2.031042545072494

Epoch: 5| Step: 10
Training loss: 2.6228725910186768
Validation loss: 2.060066233399094

Epoch: 153| Step: 0
Training loss: 2.062669277191162
Validation loss: 2.084950221482144

Epoch: 5| Step: 1
Training loss: 1.7972263097763062
Validation loss: 2.09119326068509

Epoch: 5| Step: 2
Training loss: 2.3127312660217285
Validation loss: 2.065421997859914

Epoch: 5| Step: 3
Training loss: 1.86992609500885
Validation loss: 2.045081756448233

Epoch: 5| Step: 4
Training loss: 1.7471405267715454
Validation loss: 2.0602796975002495

Epoch: 5| Step: 5
Training loss: 2.94909930229187
Validation loss: 2.062018422670262

Epoch: 5| Step: 6
Training loss: 1.5580337047576904
Validation loss: 2.0349907875061035

Epoch: 5| Step: 7
Training loss: 2.037823438644409
Validation loss: 2.0746198700320337

Epoch: 5| Step: 8
Training loss: 2.125819444656372
Validation loss: 2.064542099993716

Epoch: 5| Step: 9
Training loss: 1.9072891473770142
Validation loss: 2.05644162495931

Epoch: 5| Step: 10
Training loss: 1.830822467803955
Validation loss: 2.082240230293684

Epoch: 154| Step: 0
Training loss: 2.6593356132507324
Validation loss: 2.0843991143729097

Epoch: 5| Step: 1
Training loss: 1.7718486785888672
Validation loss: 2.0399412749915995

Epoch: 5| Step: 2
Training loss: 2.1375880241394043
Validation loss: 2.0693705146030714

Epoch: 5| Step: 3
Training loss: 2.172086238861084
Validation loss: 2.061708022189397

Epoch: 5| Step: 4
Training loss: 1.1501431465148926
Validation loss: 2.027195374170939

Epoch: 5| Step: 5
Training loss: 1.6369006633758545
Validation loss: 2.0477681083063923

Epoch: 5| Step: 6
Training loss: 2.353494882583618
Validation loss: 2.0581817191134215

Epoch: 5| Step: 7
Training loss: 2.0375304222106934
Validation loss: 2.058650193675872

Epoch: 5| Step: 8
Training loss: 2.4701876640319824
Validation loss: 2.064557542083084

Epoch: 5| Step: 9
Training loss: 1.8388582468032837
Validation loss: 2.076752784431622

Epoch: 5| Step: 10
Training loss: 2.1687164306640625
Validation loss: 2.0600640581500147

Epoch: 155| Step: 0
Training loss: 2.093313694000244
Validation loss: 2.066892752083399

Epoch: 5| Step: 1
Training loss: 1.3891483545303345
Validation loss: 2.0735076755605717

Epoch: 5| Step: 2
Training loss: 2.4202582836151123
Validation loss: 2.068055263129614

Epoch: 5| Step: 3
Training loss: 2.065892219543457
Validation loss: 2.0600183138283352

Epoch: 5| Step: 4
Training loss: 2.2281241416931152
Validation loss: 2.0446663723197034

Epoch: 5| Step: 5
Training loss: 2.0865070819854736
Validation loss: 2.0607017445307907

Epoch: 5| Step: 6
Training loss: 2.4635818004608154
Validation loss: 2.0484399385349725

Epoch: 5| Step: 7
Training loss: 1.9193683862686157
Validation loss: 2.0664054437350203

Epoch: 5| Step: 8
Training loss: 1.872961401939392
Validation loss: 2.070952983312709

Epoch: 5| Step: 9
Training loss: 2.2112483978271484
Validation loss: 2.06939483457996

Epoch: 5| Step: 10
Training loss: 1.640864372253418
Validation loss: 2.054501038725658

Epoch: 156| Step: 0
Training loss: 1.6734809875488281
Validation loss: 2.061541732921395

Epoch: 5| Step: 1
Training loss: 1.7823814153671265
Validation loss: 2.077800991714642

Epoch: 5| Step: 2
Training loss: 2.324267625808716
Validation loss: 2.0773308302766536

Epoch: 5| Step: 3
Training loss: 2.1463217735290527
Validation loss: 2.054686438652777

Epoch: 5| Step: 4
Training loss: 1.47305166721344
Validation loss: 2.0869661633686354

Epoch: 5| Step: 5
Training loss: 2.182875156402588
Validation loss: 2.0772112825865388

Epoch: 5| Step: 6
Training loss: 2.0676162242889404
Validation loss: 2.0682889723008677

Epoch: 5| Step: 7
Training loss: 1.3521488904953003
Validation loss: 2.052114860985869

Epoch: 5| Step: 8
Training loss: 2.4239089488983154
Validation loss: 2.0819266842257593

Epoch: 5| Step: 9
Training loss: 2.3424158096313477
Validation loss: 2.0612651994151454

Epoch: 5| Step: 10
Training loss: 2.575549840927124
Validation loss: 2.062310213683754

Epoch: 157| Step: 0
Training loss: 2.2372524738311768
Validation loss: 2.0754393428884526

Epoch: 5| Step: 1
Training loss: 1.9229732751846313
Validation loss: 2.0899431526020007

Epoch: 5| Step: 2
Training loss: 1.7830883264541626
Validation loss: 2.07176370774546

Epoch: 5| Step: 3
Training loss: 2.329174280166626
Validation loss: 2.0640930462909

Epoch: 5| Step: 4
Training loss: 1.4277393817901611
Validation loss: 2.052701480927006

Epoch: 5| Step: 5
Training loss: 2.205781936645508
Validation loss: 2.0373547077178955

Epoch: 5| Step: 6
Training loss: 2.173039436340332
Validation loss: 2.056623738299134

Epoch: 5| Step: 7
Training loss: 2.006507635116577
Validation loss: 2.0783793618602138

Epoch: 5| Step: 8
Training loss: 2.302607536315918
Validation loss: 2.0444972181832917

Epoch: 5| Step: 9
Training loss: 1.7517807483673096
Validation loss: 2.0397047470974665

Epoch: 5| Step: 10
Training loss: 2.119570732116699
Validation loss: 2.0685932149169264

Epoch: 158| Step: 0
Training loss: 1.700374960899353
Validation loss: 2.049611767133077

Epoch: 5| Step: 1
Training loss: 2.2035913467407227
Validation loss: 2.077609239086028

Epoch: 5| Step: 2
Training loss: 2.536522388458252
Validation loss: 2.088644189219321

Epoch: 5| Step: 3
Training loss: 1.5969908237457275
Validation loss: 2.0565258790087957

Epoch: 5| Step: 4
Training loss: 2.0885415077209473
Validation loss: 2.0788324366333666

Epoch: 5| Step: 5
Training loss: 1.5874418020248413
Validation loss: 2.0687139905909055

Epoch: 5| Step: 6
Training loss: 2.6348304748535156
Validation loss: 2.064440033769095

Epoch: 5| Step: 7
Training loss: 1.8243496417999268
Validation loss: 2.095337267844908

Epoch: 5| Step: 8
Training loss: 2.0062131881713867
Validation loss: 2.0325886280305925

Epoch: 5| Step: 9
Training loss: 1.8714025020599365
Validation loss: 2.041695423023675

Epoch: 5| Step: 10
Training loss: 2.1245484352111816
Validation loss: 2.0913582668509534

Epoch: 159| Step: 0
Training loss: 2.004917621612549
Validation loss: 2.071313160721974

Epoch: 5| Step: 1
Training loss: 2.354351282119751
Validation loss: 2.0628178196568645

Epoch: 5| Step: 2
Training loss: 2.8365206718444824
Validation loss: 2.0662259747905116

Epoch: 5| Step: 3
Training loss: 1.6873576641082764
Validation loss: 2.0381825457337084

Epoch: 5| Step: 4
Training loss: 2.283615827560425
Validation loss: 2.0710808256621003

Epoch: 5| Step: 5
Training loss: 2.285447359085083
Validation loss: 2.0779301171661704

Epoch: 5| Step: 6
Training loss: 2.0851542949676514
Validation loss: 2.0520193012811805

Epoch: 5| Step: 7
Training loss: 1.5005006790161133
Validation loss: 2.0734779219473563

Epoch: 5| Step: 8
Training loss: 1.6091258525848389
Validation loss: 2.052145993837746

Epoch: 5| Step: 9
Training loss: 1.5853888988494873
Validation loss: 2.0558457374572754

Epoch: 5| Step: 10
Training loss: 1.8855557441711426
Validation loss: 2.051528492281514

Epoch: 160| Step: 0
Training loss: 1.8864967823028564
Validation loss: 2.0919034070866083

Epoch: 5| Step: 1
Training loss: 1.486190676689148
Validation loss: 2.0573189002211376

Epoch: 5| Step: 2
Training loss: 2.35982084274292
Validation loss: 2.0383518024157454

Epoch: 5| Step: 3
Training loss: 1.6505749225616455
Validation loss: 2.0529090384001374

Epoch: 5| Step: 4
Training loss: 2.07987117767334
Validation loss: 2.0698437101097515

Epoch: 5| Step: 5
Training loss: 2.2945914268493652
Validation loss: 2.0581846467910276

Epoch: 5| Step: 6
Training loss: 2.219752788543701
Validation loss: 2.0586052248554845

Epoch: 5| Step: 7
Training loss: 2.009972333908081
Validation loss: 2.086290446660852

Epoch: 5| Step: 8
Training loss: 2.3204238414764404
Validation loss: 2.0678295448262203

Epoch: 5| Step: 9
Training loss: 1.6999657154083252
Validation loss: 2.064345581557161

Epoch: 5| Step: 10
Training loss: 2.3582754135131836
Validation loss: 2.075766404469808

Epoch: 161| Step: 0
Training loss: 2.326737642288208
Validation loss: 2.036345984346123

Epoch: 5| Step: 1
Training loss: 2.2262368202209473
Validation loss: 2.067562431417486

Epoch: 5| Step: 2
Training loss: 2.110848903656006
Validation loss: 2.067444691094019

Epoch: 5| Step: 3
Training loss: 1.2923333644866943
Validation loss: 2.0445537464593047

Epoch: 5| Step: 4
Training loss: 2.141981840133667
Validation loss: 2.042406069335117

Epoch: 5| Step: 5
Training loss: 2.231773853302002
Validation loss: 2.0465919356192313

Epoch: 5| Step: 6
Training loss: 2.1749954223632812
Validation loss: 2.083348484449489

Epoch: 5| Step: 7
Training loss: 2.094417095184326
Validation loss: 2.0582899021845993

Epoch: 5| Step: 8
Training loss: 1.8738524913787842
Validation loss: 2.0744212532556183

Epoch: 5| Step: 9
Training loss: 1.9436798095703125
Validation loss: 2.0394490918805523

Epoch: 5| Step: 10
Training loss: 1.77716064453125
Validation loss: 2.0732813650561916

Epoch: 162| Step: 0
Training loss: 2.1476991176605225
Validation loss: 2.08898558667911

Epoch: 5| Step: 1
Training loss: 1.6331589221954346
Validation loss: 2.0579057483262915

Epoch: 5| Step: 2
Training loss: 2.3311409950256348
Validation loss: 2.0811958941080237

Epoch: 5| Step: 3
Training loss: 1.9153194427490234
Validation loss: 2.063544316958356

Epoch: 5| Step: 4
Training loss: 2.7133781909942627
Validation loss: 2.0646698154428953

Epoch: 5| Step: 5
Training loss: 1.9950281381607056
Validation loss: 2.0530104611509588

Epoch: 5| Step: 6
Training loss: 1.3485443592071533
Validation loss: 2.0761110321167977

Epoch: 5| Step: 7
Training loss: 2.143742084503174
Validation loss: 2.0660807496757916

Epoch: 5| Step: 8
Training loss: 2.2717599868774414
Validation loss: 2.073400996064627

Epoch: 5| Step: 9
Training loss: 2.272412061691284
Validation loss: 2.0465374608193674

Epoch: 5| Step: 10
Training loss: 1.4120638370513916
Validation loss: 2.061265363488146

Epoch: 163| Step: 0
Training loss: 1.9551883935928345
Validation loss: 2.0582034100768385

Epoch: 5| Step: 1
Training loss: 2.768712043762207
Validation loss: 2.0351873854155182

Epoch: 5| Step: 2
Training loss: 2.0925025939941406
Validation loss: 2.073334276035268

Epoch: 5| Step: 3
Training loss: 2.015902280807495
Validation loss: 2.0466456579905685

Epoch: 5| Step: 4
Training loss: 1.6442973613739014
Validation loss: 2.0417714067684707

Epoch: 5| Step: 5
Training loss: 2.423457622528076
Validation loss: 2.0538823732765774

Epoch: 5| Step: 6
Training loss: 2.074831247329712
Validation loss: 2.0642826557159424

Epoch: 5| Step: 7
Training loss: 1.7394731044769287
Validation loss: 2.068938196346324

Epoch: 5| Step: 8
Training loss: 2.141944169998169
Validation loss: 2.092248220597544

Epoch: 5| Step: 9
Training loss: 1.7670783996582031
Validation loss: 2.0598482726722636

Epoch: 5| Step: 10
Training loss: 1.3726484775543213
Validation loss: 2.034356872240702

Epoch: 164| Step: 0
Training loss: 1.863745927810669
Validation loss: 2.0662090111804265

Epoch: 5| Step: 1
Training loss: 1.5693359375
Validation loss: 2.0361885729656426

Epoch: 5| Step: 2
Training loss: 2.408764362335205
Validation loss: 2.0588613223004084

Epoch: 5| Step: 3
Training loss: 2.806067705154419
Validation loss: 2.05658543878986

Epoch: 5| Step: 4
Training loss: 2.368410110473633
Validation loss: 2.075912674268087

Epoch: 5| Step: 5
Training loss: 1.9150266647338867
Validation loss: 2.0577125498043594

Epoch: 5| Step: 6
Training loss: 1.3265583515167236
Validation loss: 2.0570730560569355

Epoch: 5| Step: 7
Training loss: 2.3592636585235596
Validation loss: 2.0861764620709162

Epoch: 5| Step: 8
Training loss: 1.648900032043457
Validation loss: 2.1039282583421275

Epoch: 5| Step: 9
Training loss: 2.1060025691986084
Validation loss: 2.076909254955989

Epoch: 5| Step: 10
Training loss: 1.7965036630630493
Validation loss: 2.055829433984654

Epoch: 165| Step: 0
Training loss: 2.4385218620300293
Validation loss: 2.084285136192076

Epoch: 5| Step: 1
Training loss: 1.7658374309539795
Validation loss: 2.0588785448381977

Epoch: 5| Step: 2
Training loss: 1.890160322189331
Validation loss: 2.048739425597652

Epoch: 5| Step: 3
Training loss: 1.8918111324310303
Validation loss: 2.046057402446706

Epoch: 5| Step: 4
Training loss: 2.6707396507263184
Validation loss: 2.015777649418

Epoch: 5| Step: 5
Training loss: 2.016881227493286
Validation loss: 2.0685616295824767

Epoch: 5| Step: 6
Training loss: 1.759304404258728
Validation loss: 2.0763109345589914

Epoch: 5| Step: 7
Training loss: 1.4897863864898682
Validation loss: 2.0776446544995872

Epoch: 5| Step: 8
Training loss: 1.6395164728164673
Validation loss: 2.06200744259742

Epoch: 5| Step: 9
Training loss: 2.257596969604492
Validation loss: 2.0810038197425103

Epoch: 5| Step: 10
Training loss: 2.3256702423095703
Validation loss: 2.081697493471125

Epoch: 166| Step: 0
Training loss: 2.347607135772705
Validation loss: 2.058823470146425

Epoch: 5| Step: 1
Training loss: 2.2403507232666016
Validation loss: 2.0594763127706384

Epoch: 5| Step: 2
Training loss: 2.096886157989502
Validation loss: 2.058164127411381

Epoch: 5| Step: 3
Training loss: 1.9511144161224365
Validation loss: 2.0344191699899654

Epoch: 5| Step: 4
Training loss: 1.6960777044296265
Validation loss: 2.0573821990720687

Epoch: 5| Step: 5
Training loss: 1.9409406185150146
Validation loss: 2.0620516974438905

Epoch: 5| Step: 6
Training loss: 1.7224359512329102
Validation loss: 2.0594077212836153

Epoch: 5| Step: 7
Training loss: 1.66689133644104
Validation loss: 2.050481175863615

Epoch: 5| Step: 8
Training loss: 2.194777011871338
Validation loss: 2.069668403235815

Epoch: 5| Step: 9
Training loss: 2.2950775623321533
Validation loss: 2.0630653289056595

Epoch: 5| Step: 10
Training loss: 2.056812286376953
Validation loss: 2.072075628465222

Epoch: 167| Step: 0
Training loss: 2.2265353202819824
Validation loss: 2.074478910815331

Epoch: 5| Step: 1
Training loss: 2.2006099224090576
Validation loss: 2.043423362957534

Epoch: 5| Step: 2
Training loss: 2.1756739616394043
Validation loss: 2.0665187733147734

Epoch: 5| Step: 3
Training loss: 1.5144422054290771
Validation loss: 2.0789029649508897

Epoch: 5| Step: 4
Training loss: 2.058063268661499
Validation loss: 2.0766679240811254

Epoch: 5| Step: 5
Training loss: 2.3121166229248047
Validation loss: 2.0552516201491

Epoch: 5| Step: 6
Training loss: 1.4106395244598389
Validation loss: 2.0659250751618417

Epoch: 5| Step: 7
Training loss: 2.0493438243865967
Validation loss: 2.090011718452618

Epoch: 5| Step: 8
Training loss: 2.096083402633667
Validation loss: 2.0719402413214407

Epoch: 5| Step: 9
Training loss: 1.4815586805343628
Validation loss: 2.0795829514021515

Epoch: 5| Step: 10
Training loss: 2.5462424755096436
Validation loss: 2.0606134578745854

Epoch: 168| Step: 0
Training loss: 2.0946896076202393
Validation loss: 2.035890479241648

Epoch: 5| Step: 1
Training loss: 1.9963327646255493
Validation loss: 2.0708955231533257

Epoch: 5| Step: 2
Training loss: 2.27894926071167
Validation loss: 2.0835684883979058

Epoch: 5| Step: 3
Training loss: 1.7159461975097656
Validation loss: 2.0543847417318695

Epoch: 5| Step: 4
Training loss: 2.4717049598693848
Validation loss: 2.041648745536804

Epoch: 5| Step: 5
Training loss: 2.0301926136016846
Validation loss: 2.082177795389647

Epoch: 5| Step: 6
Training loss: 1.974972128868103
Validation loss: 2.0842575027096655

Epoch: 5| Step: 7
Training loss: 2.033463716506958
Validation loss: 2.0553921781560427

Epoch: 5| Step: 8
Training loss: 1.8216012716293335
Validation loss: 2.0435844108622563

Epoch: 5| Step: 9
Training loss: 1.202243685722351
Validation loss: 2.056463376168282

Epoch: 5| Step: 10
Training loss: 2.3075718879699707
Validation loss: 2.0422339747028966

Epoch: 169| Step: 0
Training loss: 1.64397394657135
Validation loss: 2.091200696524753

Epoch: 5| Step: 1
Training loss: 1.3005456924438477
Validation loss: 2.056942844903597

Epoch: 5| Step: 2
Training loss: 1.642504334449768
Validation loss: 2.087348602151358

Epoch: 5| Step: 3
Training loss: 2.4262092113494873
Validation loss: 2.0471197994806434

Epoch: 5| Step: 4
Training loss: 1.8141692876815796
Validation loss: 2.0609055847250004

Epoch: 5| Step: 5
Training loss: 2.6246604919433594
Validation loss: 2.061995037140385

Epoch: 5| Step: 6
Training loss: 1.9214649200439453
Validation loss: 2.0700002434433147

Epoch: 5| Step: 7
Training loss: 2.423666000366211
Validation loss: 2.037234934427405

Epoch: 5| Step: 8
Training loss: 2.0572879314422607
Validation loss: 2.0746143364137217

Epoch: 5| Step: 9
Training loss: 1.7810081243515015
Validation loss: 2.0515350423833376

Epoch: 5| Step: 10
Training loss: 2.5200846195220947
Validation loss: 2.0808326557118404

Epoch: 170| Step: 0
Training loss: 2.0134599208831787
Validation loss: 2.093864874173236

Epoch: 5| Step: 1
Training loss: 2.478870153427124
Validation loss: 2.039211828221557

Epoch: 5| Step: 2
Training loss: 1.1923803091049194
Validation loss: 2.0603735754566808

Epoch: 5| Step: 3
Training loss: 1.9125229120254517
Validation loss: 2.066451500820857

Epoch: 5| Step: 4
Training loss: 1.8523975610733032
Validation loss: 2.0765646439726635

Epoch: 5| Step: 5
Training loss: 2.261815071105957
Validation loss: 2.065021408501492

Epoch: 5| Step: 6
Training loss: 2.500595808029175
Validation loss: 2.057278129362291

Epoch: 5| Step: 7
Training loss: 1.5599175691604614
Validation loss: 2.074080403133105

Epoch: 5| Step: 8
Training loss: 1.9540503025054932
Validation loss: 2.058901011302907

Epoch: 5| Step: 9
Training loss: 1.7436729669570923
Validation loss: 2.0636704583321848

Epoch: 5| Step: 10
Training loss: 2.3985729217529297
Validation loss: 2.041529914384247

Epoch: 171| Step: 0
Training loss: 1.8092864751815796
Validation loss: 2.052701703963741

Epoch: 5| Step: 1
Training loss: 2.240999698638916
Validation loss: 2.07676278134828

Epoch: 5| Step: 2
Training loss: 1.7027755975723267
Validation loss: 2.0909251141291794

Epoch: 5| Step: 3
Training loss: 1.793208360671997
Validation loss: 2.0373389874735186

Epoch: 5| Step: 4
Training loss: 1.5858542919158936
Validation loss: 2.055696250289999

Epoch: 5| Step: 5
Training loss: 2.076530933380127
Validation loss: 2.0632969076915453

Epoch: 5| Step: 6
Training loss: 2.245514154434204
Validation loss: 2.0444822413946993

Epoch: 5| Step: 7
Training loss: 2.1204559803009033
Validation loss: 2.076056145852612

Epoch: 5| Step: 8
Training loss: 2.337963581085205
Validation loss: 2.071389203430504

Epoch: 5| Step: 9
Training loss: 1.9157636165618896
Validation loss: 2.07048822218372

Epoch: 5| Step: 10
Training loss: 2.152137041091919
Validation loss: 2.053724886268698

Epoch: 172| Step: 0
Training loss: 1.6137994527816772
Validation loss: 2.0518888888820523

Epoch: 5| Step: 1
Training loss: 1.7760040760040283
Validation loss: 2.0572809262942244

Epoch: 5| Step: 2
Training loss: 2.4160170555114746
Validation loss: 2.037624233512468

Epoch: 5| Step: 3
Training loss: 1.4910669326782227
Validation loss: 2.048675560182141

Epoch: 5| Step: 4
Training loss: 1.3502674102783203
Validation loss: 2.0627433202599965

Epoch: 5| Step: 5
Training loss: 2.2477495670318604
Validation loss: 2.0603801127403014

Epoch: 5| Step: 6
Training loss: 2.323641300201416
Validation loss: 2.040746701660977

Epoch: 5| Step: 7
Training loss: 1.9474643468856812
Validation loss: 2.0542434825692126

Epoch: 5| Step: 8
Training loss: 1.8639190196990967
Validation loss: 2.0356318835289247

Epoch: 5| Step: 9
Training loss: 2.607640266418457
Validation loss: 2.0352085482689644

Epoch: 5| Step: 10
Training loss: 2.2686593532562256
Validation loss: 2.0730103036408782

Epoch: 173| Step: 0
Training loss: 1.7722784280776978
Validation loss: 2.048610661619453

Epoch: 5| Step: 1
Training loss: 2.114175796508789
Validation loss: 2.0828250838864233

Epoch: 5| Step: 2
Training loss: 1.9399986267089844
Validation loss: 2.048229254702086

Epoch: 5| Step: 3
Training loss: 1.0313198566436768
Validation loss: 2.0477088343712593

Epoch: 5| Step: 4
Training loss: 1.5645986795425415
Validation loss: 2.0715957200655373

Epoch: 5| Step: 5
Training loss: 1.5791486501693726
Validation loss: 2.0409244811663063

Epoch: 5| Step: 6
Training loss: 1.7862218618392944
Validation loss: 2.036118886804068

Epoch: 5| Step: 7
Training loss: 2.259136438369751
Validation loss: 2.0429416715457873

Epoch: 5| Step: 8
Training loss: 2.827317476272583
Validation loss: 2.059208590497253

Epoch: 5| Step: 9
Training loss: 2.7416927814483643
Validation loss: 2.0750490721835884

Epoch: 5| Step: 10
Training loss: 2.3830089569091797
Validation loss: 2.0742062496882614

Epoch: 174| Step: 0
Training loss: 2.293673276901245
Validation loss: 2.102757897428287

Epoch: 5| Step: 1
Training loss: 2.086334466934204
Validation loss: 2.084826123329901

Epoch: 5| Step: 2
Training loss: 2.5254228115081787
Validation loss: 2.060674807076813

Epoch: 5| Step: 3
Training loss: 1.4802743196487427
Validation loss: 2.066333076005341

Epoch: 5| Step: 4
Training loss: 1.9943097829818726
Validation loss: 2.08175161064312

Epoch: 5| Step: 5
Training loss: 2.1059508323669434
Validation loss: 2.0501377646641066

Epoch: 5| Step: 6
Training loss: 2.086700439453125
Validation loss: 2.0579827344545754

Epoch: 5| Step: 7
Training loss: 2.1911964416503906
Validation loss: 2.0641715654762844

Epoch: 5| Step: 8
Training loss: 1.4684215784072876
Validation loss: 2.089514217069072

Epoch: 5| Step: 9
Training loss: 2.1205105781555176
Validation loss: 2.062066444786646

Epoch: 5| Step: 10
Training loss: 1.683081030845642
Validation loss: 2.0675713272504908

Epoch: 175| Step: 0
Training loss: 1.9654176235198975
Validation loss: 2.068400821378154

Epoch: 5| Step: 1
Training loss: 1.7169320583343506
Validation loss: 2.0462746184359313

Epoch: 5| Step: 2
Training loss: 1.804474115371704
Validation loss: 2.0469176538528933

Epoch: 5| Step: 3
Training loss: 2.0842373371124268
Validation loss: 2.1001171181278844

Epoch: 5| Step: 4
Training loss: 2.1629586219787598
Validation loss: 2.044245348181776

Epoch: 5| Step: 5
Training loss: 1.334047555923462
Validation loss: 2.0411903012183403

Epoch: 5| Step: 6
Training loss: 1.5412590503692627
Validation loss: 2.0541272663301036

Epoch: 5| Step: 7
Training loss: 2.7416439056396484
Validation loss: 2.060756339821764

Epoch: 5| Step: 8
Training loss: 2.447150945663452
Validation loss: 2.059275891191216

Epoch: 5| Step: 9
Training loss: 1.7605867385864258
Validation loss: 2.0680603891290645

Epoch: 5| Step: 10
Training loss: 2.0704290866851807
Validation loss: 2.1037464628937426

Epoch: 176| Step: 0
Training loss: 1.2271738052368164
Validation loss: 2.061898368661122

Epoch: 5| Step: 1
Training loss: 2.2173995971679688
Validation loss: 2.0494904056672127

Epoch: 5| Step: 2
Training loss: 2.1091768741607666
Validation loss: 2.0626637858729207

Epoch: 5| Step: 3
Training loss: 2.4709041118621826
Validation loss: 2.0573906988225956

Epoch: 5| Step: 4
Training loss: 1.8915923833847046
Validation loss: 2.0544940976686377

Epoch: 5| Step: 5
Training loss: 1.8573423624038696
Validation loss: 2.0816341651383268

Epoch: 5| Step: 6
Training loss: 2.465937614440918
Validation loss: 2.064011404591222

Epoch: 5| Step: 7
Training loss: 1.6396900415420532
Validation loss: 2.0774078574231876

Epoch: 5| Step: 8
Training loss: 1.9064022302627563
Validation loss: 2.0622772657743065

Epoch: 5| Step: 9
Training loss: 1.6052488088607788
Validation loss: 2.0622854155878865

Epoch: 5| Step: 10
Training loss: 2.5817489624023438
Validation loss: 2.0586799934346187

Epoch: 177| Step: 0
Training loss: 2.3826847076416016
Validation loss: 2.076776437861945

Epoch: 5| Step: 1
Training loss: 1.7416112422943115
Validation loss: 2.0653198072987218

Epoch: 5| Step: 2
Training loss: 2.2189056873321533
Validation loss: 2.0440168457646526

Epoch: 5| Step: 3
Training loss: 2.1648287773132324
Validation loss: 2.077614657340511

Epoch: 5| Step: 4
Training loss: 2.030177116394043
Validation loss: 2.071640758104222

Epoch: 5| Step: 5
Training loss: 1.6847352981567383
Validation loss: 2.046058154875232

Epoch: 5| Step: 6
Training loss: 1.5232092142105103
Validation loss: 2.036078453063965

Epoch: 5| Step: 7
Training loss: 1.887312889099121
Validation loss: 2.0629881530679683

Epoch: 5| Step: 8
Training loss: 2.7830278873443604
Validation loss: 2.078020675207979

Epoch: 5| Step: 9
Training loss: 2.1470742225646973
Validation loss: 2.0517833694334953

Epoch: 5| Step: 10
Training loss: 1.0229029655456543
Validation loss: 2.06404717763265

Epoch: 178| Step: 0
Training loss: 3.3464159965515137
Validation loss: 2.0514351834533033

Epoch: 5| Step: 1
Training loss: 1.539710283279419
Validation loss: 2.044061678712086

Epoch: 5| Step: 2
Training loss: 1.4604740142822266
Validation loss: 2.0424503716089393

Epoch: 5| Step: 3
Training loss: 1.9599539041519165
Validation loss: 2.062537440689661

Epoch: 5| Step: 4
Training loss: 1.8988784551620483
Validation loss: 2.0810014996477353

Epoch: 5| Step: 5
Training loss: 2.6684584617614746
Validation loss: 2.0700900400838544

Epoch: 5| Step: 6
Training loss: 2.0371580123901367
Validation loss: 2.044385290914966

Epoch: 5| Step: 7
Training loss: 1.382546305656433
Validation loss: 2.093129145201816

Epoch: 5| Step: 8
Training loss: 1.9694252014160156
Validation loss: 2.1007339121193014

Epoch: 5| Step: 9
Training loss: 1.2271531820297241
Validation loss: 2.040583884844216

Epoch: 5| Step: 10
Training loss: 2.154148578643799
Validation loss: 2.0315914961599533

Epoch: 179| Step: 0
Training loss: 2.00166392326355
Validation loss: 2.0407488576827513

Epoch: 5| Step: 1
Training loss: 2.1143555641174316
Validation loss: 2.0393894705721127

Epoch: 5| Step: 2
Training loss: 2.249152183532715
Validation loss: 2.056012535607943

Epoch: 5| Step: 3
Training loss: 2.1111702919006348
Validation loss: 2.077643822598201

Epoch: 5| Step: 4
Training loss: 2.1968743801116943
Validation loss: 2.0506175230908137

Epoch: 5| Step: 5
Training loss: 2.019496440887451
Validation loss: 2.0684864713299658

Epoch: 5| Step: 6
Training loss: 1.9017021656036377
Validation loss: 2.0686465245421215

Epoch: 5| Step: 7
Training loss: 1.334118127822876
Validation loss: 2.056334933926982

Epoch: 5| Step: 8
Training loss: 1.5491753816604614
Validation loss: 2.050474989798761

Epoch: 5| Step: 9
Training loss: 1.8853435516357422
Validation loss: 2.0373652032626572

Epoch: 5| Step: 10
Training loss: 2.325263500213623
Validation loss: 2.0614406037074264

Epoch: 180| Step: 0
Training loss: 1.5868585109710693
Validation loss: 2.053444404755869

Epoch: 5| Step: 1
Training loss: 2.077131509780884
Validation loss: 2.068560964317732

Epoch: 5| Step: 2
Training loss: 1.743687391281128
Validation loss: 2.069916873849848

Epoch: 5| Step: 3
Training loss: 1.9070634841918945
Validation loss: 2.0723792006892543

Epoch: 5| Step: 4
Training loss: 1.6481552124023438
Validation loss: 2.050242772666357

Epoch: 5| Step: 5
Training loss: 1.8688294887542725
Validation loss: 2.0340142455152286

Epoch: 5| Step: 6
Training loss: 2.026865005493164
Validation loss: 2.047213545409582

Epoch: 5| Step: 7
Training loss: 2.049088478088379
Validation loss: 2.071344970374979

Epoch: 5| Step: 8
Training loss: 1.9021241664886475
Validation loss: 2.1087608029765468

Epoch: 5| Step: 9
Training loss: 2.547825336456299
Validation loss: 2.055027941221832

Epoch: 5| Step: 10
Training loss: 2.3122315406799316
Validation loss: 2.0611359355270222

Epoch: 181| Step: 0
Training loss: 2.4130544662475586
Validation loss: 2.0580054098559963

Epoch: 5| Step: 1
Training loss: 2.0758321285247803
Validation loss: 2.0690885025967836

Epoch: 5| Step: 2
Training loss: 2.0309417247772217
Validation loss: 2.083751880994407

Epoch: 5| Step: 3
Training loss: 1.8417308330535889
Validation loss: 2.063079067455825

Epoch: 5| Step: 4
Training loss: 2.3631112575531006
Validation loss: 2.0956456379223893

Epoch: 5| Step: 5
Training loss: 1.7838096618652344
Validation loss: 2.108912875575404

Epoch: 5| Step: 6
Training loss: 1.5318377017974854
Validation loss: 2.0695866423268474

Epoch: 5| Step: 7
Training loss: 1.8432567119598389
Validation loss: 2.0705815848483833

Epoch: 5| Step: 8
Training loss: 2.531524419784546
Validation loss: 2.0625501166107836

Epoch: 5| Step: 9
Training loss: 1.6881736516952515
Validation loss: 2.053405951428157

Epoch: 5| Step: 10
Training loss: 1.5117263793945312
Validation loss: 2.028439955044818

Epoch: 182| Step: 0
Training loss: 2.0460946559906006
Validation loss: 2.088416766094905

Epoch: 5| Step: 1
Training loss: 2.2901744842529297
Validation loss: 2.0340816295275124

Epoch: 5| Step: 2
Training loss: 2.056230068206787
Validation loss: 2.041445606498308

Epoch: 5| Step: 3
Training loss: 1.6127440929412842
Validation loss: 2.0716305958327426

Epoch: 5| Step: 4
Training loss: 2.5139145851135254
Validation loss: 2.03294510738824

Epoch: 5| Step: 5
Training loss: 1.9461605548858643
Validation loss: 2.0371826451311827

Epoch: 5| Step: 6
Training loss: 1.6003391742706299
Validation loss: 2.0518049065784743

Epoch: 5| Step: 7
Training loss: 1.6444032192230225
Validation loss: 2.083019728301674

Epoch: 5| Step: 8
Training loss: 1.645434021949768
Validation loss: 2.056364761885776

Epoch: 5| Step: 9
Training loss: 2.2338547706604004
Validation loss: 2.063108008394959

Epoch: 5| Step: 10
Training loss: 1.8989471197128296
Validation loss: 2.0940565011834584

Epoch: 183| Step: 0
Training loss: 2.2096359729766846
Validation loss: 2.0373460785035165

Epoch: 5| Step: 1
Training loss: 2.104012966156006
Validation loss: 2.0169971143045733

Epoch: 5| Step: 2
Training loss: 2.2031781673431396
Validation loss: 2.077229981781334

Epoch: 5| Step: 3
Training loss: 2.374929904937744
Validation loss: 2.0556478167092926

Epoch: 5| Step: 4
Training loss: 1.5617923736572266
Validation loss: 2.0660013306525444

Epoch: 5| Step: 5
Training loss: 1.9159533977508545
Validation loss: 2.053306705208235

Epoch: 5| Step: 6
Training loss: 1.759706735610962
Validation loss: 2.0589955391422397

Epoch: 5| Step: 7
Training loss: 1.9442001581192017
Validation loss: 2.07153675376728

Epoch: 5| Step: 8
Training loss: 1.5035322904586792
Validation loss: 2.037883904672438

Epoch: 5| Step: 9
Training loss: 1.9428846836090088
Validation loss: 2.082821880617449

Epoch: 5| Step: 10
Training loss: 2.2529137134552
Validation loss: 2.0594513736745363

Epoch: 184| Step: 0
Training loss: 1.2722429037094116
Validation loss: 2.093560912275827

Epoch: 5| Step: 1
Training loss: 1.6351591348648071
Validation loss: 2.0859727731315036

Epoch: 5| Step: 2
Training loss: 1.8868757486343384
Validation loss: 2.061325591097596

Epoch: 5| Step: 3
Training loss: 2.624666690826416
Validation loss: 2.069160920317455

Epoch: 5| Step: 4
Training loss: 1.7763478755950928
Validation loss: 2.0743416252956597

Epoch: 5| Step: 5
Training loss: 2.467949151992798
Validation loss: 2.043084749611475

Epoch: 5| Step: 6
Training loss: 2.1304521560668945
Validation loss: 2.0550223371034027

Epoch: 5| Step: 7
Training loss: 1.5082097053527832
Validation loss: 2.059737123468871

Epoch: 5| Step: 8
Training loss: 1.7408883571624756
Validation loss: 2.0684535118841354

Epoch: 5| Step: 9
Training loss: 2.0766236782073975
Validation loss: 2.068353170989662

Epoch: 5| Step: 10
Training loss: 2.491854667663574
Validation loss: 2.078248494414873

Epoch: 185| Step: 0
Training loss: 1.7002286911010742
Validation loss: 2.088136069236263

Epoch: 5| Step: 1
Training loss: 2.086935520172119
Validation loss: 2.0680795074791036

Epoch: 5| Step: 2
Training loss: 1.6403417587280273
Validation loss: 2.0906990869070894

Epoch: 5| Step: 3
Training loss: 1.5900447368621826
Validation loss: 2.0678280553510113

Epoch: 5| Step: 4
Training loss: 2.451941967010498
Validation loss: 2.0574220739385134

Epoch: 5| Step: 5
Training loss: 2.013744354248047
Validation loss: 2.038367981551796

Epoch: 5| Step: 6
Training loss: 1.8796966075897217
Validation loss: 2.0453066082410913

Epoch: 5| Step: 7
Training loss: 2.4687612056732178
Validation loss: 2.034683476212204

Epoch: 5| Step: 8
Training loss: 2.3611040115356445
Validation loss: 2.0865820928286483

Epoch: 5| Step: 9
Training loss: 1.7600088119506836
Validation loss: 2.0389028697885494

Epoch: 5| Step: 10
Training loss: 1.550188422203064
Validation loss: 2.057034118201143

Epoch: 186| Step: 0
Training loss: 1.394535779953003
Validation loss: 2.0601180266308528

Epoch: 5| Step: 1
Training loss: 2.115873336791992
Validation loss: 2.0364977903263544

Epoch: 5| Step: 2
Training loss: 1.3826448917388916
Validation loss: 2.0260004381979666

Epoch: 5| Step: 3
Training loss: 2.3517184257507324
Validation loss: 2.0728128007663194

Epoch: 5| Step: 4
Training loss: 2.1649270057678223
Validation loss: 2.0688942017093783

Epoch: 5| Step: 5
Training loss: 1.9026777744293213
Validation loss: 2.0423552169594714

Epoch: 5| Step: 6
Training loss: 2.2860653400421143
Validation loss: 2.0504583876620055

Epoch: 5| Step: 7
Training loss: 2.1308579444885254
Validation loss: 2.0408846139907837

Epoch: 5| Step: 8
Training loss: 1.7631851434707642
Validation loss: 2.065532745853547

Epoch: 5| Step: 9
Training loss: 1.4973268508911133
Validation loss: 2.0573746388958347

Epoch: 5| Step: 10
Training loss: 2.721691608428955
Validation loss: 2.099586586798391

Epoch: 187| Step: 0
Training loss: 1.50483238697052
Validation loss: 2.075030393497918

Epoch: 5| Step: 1
Training loss: 2.9432337284088135
Validation loss: 2.05785067747998

Epoch: 5| Step: 2
Training loss: 1.8967721462249756
Validation loss: 2.051782279886225

Epoch: 5| Step: 3
Training loss: 1.833789587020874
Validation loss: 2.050975654714851

Epoch: 5| Step: 4
Training loss: 1.9046179056167603
Validation loss: 2.0332011997058825

Epoch: 5| Step: 5
Training loss: 1.806701421737671
Validation loss: 2.0502715264597247

Epoch: 5| Step: 6
Training loss: 1.9152361154556274
Validation loss: 2.052114963531494

Epoch: 5| Step: 7
Training loss: 1.8116323947906494
Validation loss: 2.1079969277945896

Epoch: 5| Step: 8
Training loss: 1.9893500804901123
Validation loss: 2.077483871931671

Epoch: 5| Step: 9
Training loss: 1.7573474645614624
Validation loss: 2.085024984933997

Epoch: 5| Step: 10
Training loss: 1.8795697689056396
Validation loss: 2.0702059179223995

Epoch: 188| Step: 0
Training loss: 1.9278345108032227
Validation loss: 2.0329439793863604

Epoch: 5| Step: 1
Training loss: 2.0543084144592285
Validation loss: 2.0597543742067073

Epoch: 5| Step: 2
Training loss: 2.3098437786102295
Validation loss: 2.0543203430791057

Epoch: 5| Step: 3
Training loss: 2.1885921955108643
Validation loss: 2.0715210540320284

Epoch: 5| Step: 4
Training loss: 2.164804697036743
Validation loss: 2.0943445210815756

Epoch: 5| Step: 5
Training loss: 2.148237943649292
Validation loss: 2.066079379409872

Epoch: 5| Step: 6
Training loss: 1.9143091440200806
Validation loss: 2.041134431797971

Epoch: 5| Step: 7
Training loss: 1.6691229343414307
Validation loss: 2.076344629769684

Epoch: 5| Step: 8
Training loss: 1.6342394351959229
Validation loss: 2.029348143967249

Epoch: 5| Step: 9
Training loss: 1.7149944305419922
Validation loss: 2.065365086319626

Epoch: 5| Step: 10
Training loss: 1.2507939338684082
Validation loss: 2.048138863296919

Epoch: 189| Step: 0
Training loss: 2.152745485305786
Validation loss: 2.032458607868482

Epoch: 5| Step: 1
Training loss: 2.0104525089263916
Validation loss: 2.0387929024234897

Epoch: 5| Step: 2
Training loss: 1.6307274103164673
Validation loss: 2.038082250984766

Epoch: 5| Step: 3
Training loss: 1.7387183904647827
Validation loss: 2.0712282324350006

Epoch: 5| Step: 4
Training loss: 2.0784337520599365
Validation loss: 2.0279190822314193

Epoch: 5| Step: 5
Training loss: 1.7108447551727295
Validation loss: 2.0728461383491434

Epoch: 5| Step: 6
Training loss: 2.5385241508483887
Validation loss: 2.07722794881431

Epoch: 5| Step: 7
Training loss: 1.3464248180389404
Validation loss: 2.0452081490588445

Epoch: 5| Step: 8
Training loss: 2.1552202701568604
Validation loss: 2.0674155989000873

Epoch: 5| Step: 9
Training loss: 1.7699886560440063
Validation loss: 2.045567271529987

Epoch: 5| Step: 10
Training loss: 2.158966064453125
Validation loss: 2.0648015186350834

Epoch: 190| Step: 0
Training loss: 1.37563157081604
Validation loss: 2.0274564848151257

Epoch: 5| Step: 1
Training loss: 1.9663736820220947
Validation loss: 2.0722360175143004

Epoch: 5| Step: 2
Training loss: 1.7545719146728516
Validation loss: 2.0395788454240367

Epoch: 5| Step: 3
Training loss: 1.6780122518539429
Validation loss: 2.0651825807427846

Epoch: 5| Step: 4
Training loss: 1.7631347179412842
Validation loss: 2.069949253912895

Epoch: 5| Step: 5
Training loss: 3.0077998638153076
Validation loss: 2.0453860631553074

Epoch: 5| Step: 6
Training loss: 1.6215360164642334
Validation loss: 2.050568906209802

Epoch: 5| Step: 7
Training loss: 2.131206750869751
Validation loss: 2.025445827873804

Epoch: 5| Step: 8
Training loss: 1.6503627300262451
Validation loss: 2.0474086230801

Epoch: 5| Step: 9
Training loss: 2.0044350624084473
Validation loss: 2.023278747835467

Epoch: 5| Step: 10
Training loss: 2.226079225540161
Validation loss: 2.051804683541739

Epoch: 191| Step: 0
Training loss: 1.9557554721832275
Validation loss: 2.072971272212203

Epoch: 5| Step: 1
Training loss: 1.8764721155166626
Validation loss: 2.0351456211459253

Epoch: 5| Step: 2
Training loss: 1.9552425146102905
Validation loss: 2.0335609989781536

Epoch: 5| Step: 3
Training loss: 2.287060260772705
Validation loss: 2.0372007610977336

Epoch: 5| Step: 4
Training loss: 1.4742192029953003
Validation loss: 2.0558589043155795

Epoch: 5| Step: 5
Training loss: 2.3359925746917725
Validation loss: 2.0479799970503776

Epoch: 5| Step: 6
Training loss: 1.612593412399292
Validation loss: 2.071551010172854

Epoch: 5| Step: 7
Training loss: 2.4272215366363525
Validation loss: 2.0497988654721166

Epoch: 5| Step: 8
Training loss: 1.6030666828155518
Validation loss: 2.050342816178517

Epoch: 5| Step: 9
Training loss: 2.2319235801696777
Validation loss: 2.0363499682436705

Epoch: 5| Step: 10
Training loss: 1.4878301620483398
Validation loss: 2.0226652929859776

Epoch: 192| Step: 0
Training loss: 2.2303402423858643
Validation loss: 2.0658806767514957

Epoch: 5| Step: 1
Training loss: 1.163537621498108
Validation loss: 2.063851361633629

Epoch: 5| Step: 2
Training loss: 2.695462703704834
Validation loss: 2.0391401847203574

Epoch: 5| Step: 3
Training loss: 2.0634701251983643
Validation loss: 2.0463917870675363

Epoch: 5| Step: 4
Training loss: 2.123335599899292
Validation loss: 2.0386583728175007

Epoch: 5| Step: 5
Training loss: 2.1893115043640137
Validation loss: 2.03966619635141

Epoch: 5| Step: 6
Training loss: 1.6199045181274414
Validation loss: 2.0512747777405607

Epoch: 5| Step: 7
Training loss: 1.840013861656189
Validation loss: 2.034506873417926

Epoch: 5| Step: 8
Training loss: 1.889072060585022
Validation loss: 2.0720673991787817

Epoch: 5| Step: 9
Training loss: 1.4711310863494873
Validation loss: 2.081576804960928

Epoch: 5| Step: 10
Training loss: 1.9768048524856567
Validation loss: 2.030516178377213

Epoch: 193| Step: 0
Training loss: 1.4669066667556763
Validation loss: 2.0485695010872296

Epoch: 5| Step: 1
Training loss: 1.7171485424041748
Validation loss: 2.0469438632329306

Epoch: 5| Step: 2
Training loss: 2.2353460788726807
Validation loss: 2.0497833451917096

Epoch: 5| Step: 3
Training loss: 1.8144041299819946
Validation loss: 2.06471259363236

Epoch: 5| Step: 4
Training loss: 2.208885669708252
Validation loss: 2.0329372190660044

Epoch: 5| Step: 5
Training loss: 2.288776397705078
Validation loss: 2.0362733282068723

Epoch: 5| Step: 6
Training loss: 1.930466651916504
Validation loss: 2.0251662090260494

Epoch: 5| Step: 7
Training loss: 2.189133644104004
Validation loss: 2.049998458995614

Epoch: 5| Step: 8
Training loss: 1.585666298866272
Validation loss: 2.034427514640234

Epoch: 5| Step: 9
Training loss: 1.7292486429214478
Validation loss: 2.058325876471817

Epoch: 5| Step: 10
Training loss: 2.003450393676758
Validation loss: 2.043198499628293

Epoch: 194| Step: 0
Training loss: 1.6151756048202515
Validation loss: 2.039696039692048

Epoch: 5| Step: 1
Training loss: 2.2133491039276123
Validation loss: 2.054852435665746

Epoch: 5| Step: 2
Training loss: 1.8649885654449463
Validation loss: 2.05910813167531

Epoch: 5| Step: 3
Training loss: 2.1904048919677734
Validation loss: 2.0426654405491327

Epoch: 5| Step: 4
Training loss: 1.6322243213653564
Validation loss: 2.0838410341611473

Epoch: 5| Step: 5
Training loss: 1.8697010278701782
Validation loss: 2.054885564311858

Epoch: 5| Step: 6
Training loss: 2.053562641143799
Validation loss: 2.0120517656367314

Epoch: 5| Step: 7
Training loss: 2.0440433025360107
Validation loss: 2.0406299278300297

Epoch: 5| Step: 8
Training loss: 1.3993146419525146
Validation loss: 2.0535727162514963

Epoch: 5| Step: 9
Training loss: 2.127636671066284
Validation loss: 2.0315682606030534

Epoch: 5| Step: 10
Training loss: 2.231426954269409
Validation loss: 2.042299942303729

Epoch: 195| Step: 0
Training loss: 1.5192197561264038
Validation loss: 2.065026811374131

Epoch: 5| Step: 1
Training loss: 1.9418331384658813
Validation loss: 2.0162315061015468

Epoch: 5| Step: 2
Training loss: 2.4572980403900146
Validation loss: 2.082937922528995

Epoch: 5| Step: 3
Training loss: 1.8873180150985718
Validation loss: 2.0494370819419943

Epoch: 5| Step: 4
Training loss: 1.8642990589141846
Validation loss: 2.0413993020211496

Epoch: 5| Step: 5
Training loss: 1.848780870437622
Validation loss: 2.0450311681275726

Epoch: 5| Step: 6
Training loss: 1.4711226224899292
Validation loss: 2.047745850778395

Epoch: 5| Step: 7
Training loss: 2.3138906955718994
Validation loss: 2.0409988434084

Epoch: 5| Step: 8
Training loss: 2.0430116653442383
Validation loss: 2.075786334212108

Epoch: 5| Step: 9
Training loss: 2.0594584941864014
Validation loss: 2.0606957327935005

Epoch: 5| Step: 10
Training loss: 1.7776960134506226
Validation loss: 2.054398280318065

Epoch: 196| Step: 0
Training loss: 1.6828029155731201
Validation loss: 2.066146086621028

Epoch: 5| Step: 1
Training loss: 1.5803706645965576
Validation loss: 2.06341330851278

Epoch: 5| Step: 2
Training loss: 2.0418002605438232
Validation loss: 2.0849734813936296

Epoch: 5| Step: 3
Training loss: 1.7517368793487549
Validation loss: 2.0615607410348873

Epoch: 5| Step: 4
Training loss: 2.494065046310425
Validation loss: 2.022676150004069

Epoch: 5| Step: 5
Training loss: 2.539663791656494
Validation loss: 2.0994836079177035

Epoch: 5| Step: 6
Training loss: 1.4692355394363403
Validation loss: 2.0763101244485505

Epoch: 5| Step: 7
Training loss: 1.7561826705932617
Validation loss: 2.0617600499942736

Epoch: 5| Step: 8
Training loss: 1.5974308252334595
Validation loss: 2.041491728956981

Epoch: 5| Step: 9
Training loss: 2.538877248764038
Validation loss: 2.049232680310485

Epoch: 5| Step: 10
Training loss: 1.558142066001892
Validation loss: 2.0375420457573346

Epoch: 197| Step: 0
Training loss: 1.8722015619277954
Validation loss: 2.0475850759014005

Epoch: 5| Step: 1
Training loss: 2.4921813011169434
Validation loss: 2.0322530525986866

Epoch: 5| Step: 2
Training loss: 1.8012540340423584
Validation loss: 2.0326456780074746

Epoch: 5| Step: 3
Training loss: 2.2034430503845215
Validation loss: 2.072719499629031

Epoch: 5| Step: 4
Training loss: 2.1473472118377686
Validation loss: 2.0699736789990495

Epoch: 5| Step: 5
Training loss: 2.558182954788208
Validation loss: 2.0488167988356722

Epoch: 5| Step: 6
Training loss: 1.6465736627578735
Validation loss: 2.0237910926982923

Epoch: 5| Step: 7
Training loss: 1.4052798748016357
Validation loss: 2.025255351938227

Epoch: 5| Step: 8
Training loss: 1.6986585855484009
Validation loss: 2.0452954615316083

Epoch: 5| Step: 9
Training loss: 1.5577176809310913
Validation loss: 2.0169510418368923

Epoch: 5| Step: 10
Training loss: 1.4738094806671143
Validation loss: 2.069915795838961

Epoch: 198| Step: 0
Training loss: 1.7721675634384155
Validation loss: 2.0136467000489593

Epoch: 5| Step: 1
Training loss: 1.619762659072876
Validation loss: 2.0435692443642566

Epoch: 5| Step: 2
Training loss: 2.548401355743408
Validation loss: 2.0952726794827368

Epoch: 5| Step: 3
Training loss: 1.8590514659881592
Validation loss: 2.0600173447721746

Epoch: 5| Step: 4
Training loss: 1.2934725284576416
Validation loss: 2.0469865440040507

Epoch: 5| Step: 5
Training loss: 1.4118521213531494
Validation loss: 2.0388011996464064

Epoch: 5| Step: 6
Training loss: 2.079990863800049
Validation loss: 2.076759760097791

Epoch: 5| Step: 7
Training loss: 1.968735694885254
Validation loss: 2.0401700132636615

Epoch: 5| Step: 8
Training loss: 2.297778606414795
Validation loss: 2.0483816234014367

Epoch: 5| Step: 9
Training loss: 2.1668756008148193
Validation loss: 2.041571190280299

Epoch: 5| Step: 10
Training loss: 1.902393102645874
Validation loss: 2.045644344822053

Epoch: 199| Step: 0
Training loss: 1.7775367498397827
Validation loss: 2.056884647697531

Epoch: 5| Step: 1
Training loss: 2.1323418617248535
Validation loss: 2.034624284313571

Epoch: 5| Step: 2
Training loss: 1.9581830501556396
Validation loss: 2.075179235909575

Epoch: 5| Step: 3
Training loss: 1.8829796314239502
Validation loss: 2.040832750258907

Epoch: 5| Step: 4
Training loss: 1.7356656789779663
Validation loss: 2.056170554571254

Epoch: 5| Step: 5
Training loss: 1.9295227527618408
Validation loss: 2.0618378577693814

Epoch: 5| Step: 6
Training loss: 2.7501819133758545
Validation loss: 2.069894516339866

Epoch: 5| Step: 7
Training loss: 2.1578798294067383
Validation loss: 2.0368460532157653

Epoch: 5| Step: 8
Training loss: 1.4788239002227783
Validation loss: 2.0147641730564896

Epoch: 5| Step: 9
Training loss: 1.7335243225097656
Validation loss: 2.074914611795897

Epoch: 5| Step: 10
Training loss: 1.3435254096984863
Validation loss: 2.0609718625263502

Epoch: 200| Step: 0
Training loss: 1.6802501678466797
Validation loss: 2.0481502894432313

Epoch: 5| Step: 1
Training loss: 2.012946605682373
Validation loss: 2.027908491831954

Epoch: 5| Step: 2
Training loss: 1.716647744178772
Validation loss: 2.04029740313048

Epoch: 5| Step: 3
Training loss: 2.2034783363342285
Validation loss: 2.0596614999155842

Epoch: 5| Step: 4
Training loss: 2.4119229316711426
Validation loss: 2.017712764842536

Epoch: 5| Step: 5
Training loss: 1.3569717407226562
Validation loss: 2.082020213527064

Epoch: 5| Step: 6
Training loss: 2.0543315410614014
Validation loss: 2.037358973615913

Epoch: 5| Step: 7
Training loss: 2.6075778007507324
Validation loss: 2.025364306665236

Epoch: 5| Step: 8
Training loss: 1.7919032573699951
Validation loss: 2.051198567113569

Epoch: 5| Step: 9
Training loss: 1.1527423858642578
Validation loss: 2.026778478776255

Epoch: 5| Step: 10
Training loss: 1.9169416427612305
Validation loss: 2.015855589220601

Epoch: 201| Step: 0
Training loss: 2.076596260070801
Validation loss: 2.0461163392630954

Epoch: 5| Step: 1
Training loss: 1.4710466861724854
Validation loss: 2.0318685500852522

Epoch: 5| Step: 2
Training loss: 2.3534646034240723
Validation loss: 2.030208308209655

Epoch: 5| Step: 3
Training loss: 1.9315646886825562
Validation loss: 2.052596021724004

Epoch: 5| Step: 4
Training loss: 2.4117588996887207
Validation loss: 2.041014684143887

Epoch: 5| Step: 5
Training loss: 1.8804943561553955
Validation loss: 2.0340234169396023

Epoch: 5| Step: 6
Training loss: 2.7099854946136475
Validation loss: 2.0205274961327993

Epoch: 5| Step: 7
Training loss: 1.332335114479065
Validation loss: 2.0649471936687345

Epoch: 5| Step: 8
Training loss: 1.6267703771591187
Validation loss: 2.038773346972722

Epoch: 5| Step: 9
Training loss: 1.3870246410369873
Validation loss: 2.0135127139347855

Epoch: 5| Step: 10
Training loss: 1.7613252401351929
Validation loss: 2.077129908787307

Epoch: 202| Step: 0
Training loss: 1.9087337255477905
Validation loss: 2.0386426025821316

Epoch: 5| Step: 1
Training loss: 1.8392322063446045
Validation loss: 2.0513834312397945

Epoch: 5| Step: 2
Training loss: 1.6855884790420532
Validation loss: 2.0605895826893468

Epoch: 5| Step: 3
Training loss: 1.9399865865707397
Validation loss: 2.0469180050716607

Epoch: 5| Step: 4
Training loss: 1.7601253986358643
Validation loss: 2.0656994952950427

Epoch: 5| Step: 5
Training loss: 1.4424244165420532
Validation loss: 2.057624060620544

Epoch: 5| Step: 6
Training loss: 1.7971540689468384
Validation loss: 2.044042520625617

Epoch: 5| Step: 7
Training loss: 2.0875086784362793
Validation loss: 2.007379020414045

Epoch: 5| Step: 8
Training loss: 2.019021511077881
Validation loss: 2.026455436983416

Epoch: 5| Step: 9
Training loss: 2.3142895698547363
Validation loss: 2.0555520185860257

Epoch: 5| Step: 10
Training loss: 2.4772591590881348
Validation loss: 2.0651316104396695

Epoch: 203| Step: 0
Training loss: 1.5810515880584717
Validation loss: 2.0399783080623997

Epoch: 5| Step: 1
Training loss: 2.2873809337615967
Validation loss: 1.9842817424446024

Epoch: 5| Step: 2
Training loss: 1.4444005489349365
Validation loss: 2.0326633991733676

Epoch: 5| Step: 3
Training loss: 2.043057441711426
Validation loss: 2.013794086312735

Epoch: 5| Step: 4
Training loss: 1.6027084589004517
Validation loss: 2.057696562941356

Epoch: 5| Step: 5
Training loss: 2.175215482711792
Validation loss: 2.07360609885185

Epoch: 5| Step: 6
Training loss: 2.333266496658325
Validation loss: 2.0604102816633

Epoch: 5| Step: 7
Training loss: 1.9714208841323853
Validation loss: 2.0436610355172107

Epoch: 5| Step: 8
Training loss: 1.7140852212905884
Validation loss: 2.035766050379763

Epoch: 5| Step: 9
Training loss: 1.8829898834228516
Validation loss: 2.046227470521004

Epoch: 5| Step: 10
Training loss: 1.851253628730774
Validation loss: 2.0226875684594594

Epoch: 204| Step: 0
Training loss: 1.64272940158844
Validation loss: 2.043399639027093

Epoch: 5| Step: 1
Training loss: 2.548099994659424
Validation loss: 2.0258983924824703

Epoch: 5| Step: 2
Training loss: 1.943320870399475
Validation loss: 2.065562960922077

Epoch: 5| Step: 3
Training loss: 1.542223572731018
Validation loss: 2.04725081177168

Epoch: 5| Step: 4
Training loss: 1.602728247642517
Validation loss: 2.0302855609565653

Epoch: 5| Step: 5
Training loss: 1.7037502527236938
Validation loss: 1.992915431658427

Epoch: 5| Step: 6
Training loss: 1.9715359210968018
Validation loss: 2.0786562491488714

Epoch: 5| Step: 7
Training loss: 2.3766772747039795
Validation loss: 2.0443373995442546

Epoch: 5| Step: 8
Training loss: 1.7993615865707397
Validation loss: 2.05843295205024

Epoch: 5| Step: 9
Training loss: 2.455461263656616
Validation loss: 2.0204188798063543

Epoch: 5| Step: 10
Training loss: 1.4089603424072266
Validation loss: 2.0644221254574355

Epoch: 205| Step: 0
Training loss: 2.4424242973327637
Validation loss: 2.0417984557408158

Epoch: 5| Step: 1
Training loss: 1.6978180408477783
Validation loss: 2.033647733349954

Epoch: 5| Step: 2
Training loss: 1.8755178451538086
Validation loss: 2.0594915664324196

Epoch: 5| Step: 3
Training loss: 1.6693077087402344
Validation loss: 2.0501495894565376

Epoch: 5| Step: 4
Training loss: 2.260277032852173
Validation loss: 2.051745537788637

Epoch: 5| Step: 5
Training loss: 1.6518609523773193
Validation loss: 2.023791491344411

Epoch: 5| Step: 6
Training loss: 1.60256826877594
Validation loss: 2.0319658428110103

Epoch: 5| Step: 7
Training loss: 1.5925073623657227
Validation loss: 2.045391562164471

Epoch: 5| Step: 8
Training loss: 1.7660465240478516
Validation loss: 2.026499165001736

Epoch: 5| Step: 9
Training loss: 1.994482398033142
Validation loss: 2.0286251396261235

Epoch: 5| Step: 10
Training loss: 2.403189182281494
Validation loss: 1.990426553192959

Epoch: 206| Step: 0
Training loss: 1.635967493057251
Validation loss: 2.041074606680101

Epoch: 5| Step: 1
Training loss: 1.7469546794891357
Validation loss: 2.0230499262450845

Epoch: 5| Step: 2
Training loss: 1.5372564792633057
Validation loss: 2.0808512844065183

Epoch: 5| Step: 3
Training loss: 2.137641429901123
Validation loss: 2.033046381447905

Epoch: 5| Step: 4
Training loss: 2.356670379638672
Validation loss: 2.0284883001799225

Epoch: 5| Step: 5
Training loss: 2.021207332611084
Validation loss: 2.075040009713942

Epoch: 5| Step: 6
Training loss: 1.9703788757324219
Validation loss: 2.0305563429350495

Epoch: 5| Step: 7
Training loss: 1.9398868083953857
Validation loss: 2.038871067826466

Epoch: 5| Step: 8
Training loss: 1.9919188022613525
Validation loss: 2.0506022284107823

Epoch: 5| Step: 9
Training loss: 1.548311471939087
Validation loss: 2.0662801086261706

Epoch: 5| Step: 10
Training loss: 1.7826776504516602
Validation loss: 2.0106167306182203

Epoch: 207| Step: 0
Training loss: 2.601686477661133
Validation loss: 2.0510050084001277

Epoch: 5| Step: 1
Training loss: 1.6850061416625977
Validation loss: 2.0233248356849916

Epoch: 5| Step: 2
Training loss: 1.9813435077667236
Validation loss: 2.0220889686256327

Epoch: 5| Step: 3
Training loss: 2.2653746604919434
Validation loss: 2.0442246467836442

Epoch: 5| Step: 4
Training loss: 1.719454050064087
Validation loss: 2.0549411055862263

Epoch: 5| Step: 5
Training loss: 2.1083052158355713
Validation loss: 2.017277248444096

Epoch: 5| Step: 6
Training loss: 1.3296974897384644
Validation loss: 2.0545135223737327

Epoch: 5| Step: 7
Training loss: 1.3851838111877441
Validation loss: 2.043629910356255

Epoch: 5| Step: 8
Training loss: 1.5251479148864746
Validation loss: 2.0127912964872134

Epoch: 5| Step: 9
Training loss: 2.2658638954162598
Validation loss: 2.0449617831937728

Epoch: 5| Step: 10
Training loss: 1.777846336364746
Validation loss: 2.046956108462426

Epoch: 208| Step: 0
Training loss: 2.3079447746276855
Validation loss: 2.0337523516788276

Epoch: 5| Step: 1
Training loss: 1.3909838199615479
Validation loss: 2.0261630550507577

Epoch: 5| Step: 2
Training loss: 1.3712174892425537
Validation loss: 2.026656760964342

Epoch: 5| Step: 3
Training loss: 2.4734930992126465
Validation loss: 2.0455272710451515

Epoch: 5| Step: 4
Training loss: 1.6213327646255493
Validation loss: 2.0098799351722962

Epoch: 5| Step: 5
Training loss: 2.158388137817383
Validation loss: 2.0138049869127173

Epoch: 5| Step: 6
Training loss: 1.8910691738128662
Validation loss: 2.0474033253167265

Epoch: 5| Step: 7
Training loss: 1.921616792678833
Validation loss: 2.0242998010368756

Epoch: 5| Step: 8
Training loss: 1.8680431842803955
Validation loss: 2.011903316743912

Epoch: 5| Step: 9
Training loss: 2.1215624809265137
Validation loss: 2.0535984372579925

Epoch: 5| Step: 10
Training loss: 1.5060313940048218
Validation loss: 2.0144983042952833

Epoch: 209| Step: 0
Training loss: 1.57517409324646
Validation loss: 2.010738303584437

Epoch: 5| Step: 1
Training loss: 1.4368896484375
Validation loss: 2.0386912335631666

Epoch: 5| Step: 2
Training loss: 1.801414132118225
Validation loss: 1.9879078403595956

Epoch: 5| Step: 3
Training loss: 1.7018554210662842
Validation loss: 2.0018829914831344

Epoch: 5| Step: 4
Training loss: 2.671597957611084
Validation loss: 2.0257690478396673

Epoch: 5| Step: 5
Training loss: 2.165955066680908
Validation loss: 2.024148425748271

Epoch: 5| Step: 6
Training loss: 2.4502015113830566
Validation loss: 2.0093538479138444

Epoch: 5| Step: 7
Training loss: 1.6176897287368774
Validation loss: 2.0360623149461645

Epoch: 5| Step: 8
Training loss: 1.8137080669403076
Validation loss: 2.022722008407757

Epoch: 5| Step: 9
Training loss: 1.2666704654693604
Validation loss: 1.9983077741438342

Epoch: 5| Step: 10
Training loss: 2.200185775756836
Validation loss: 2.0207469924803703

Epoch: 210| Step: 0
Training loss: 1.9609642028808594
Validation loss: 2.0181705233871297

Epoch: 5| Step: 1
Training loss: 1.2727864980697632
Validation loss: 2.0280090839632097

Epoch: 5| Step: 2
Training loss: 2.153733491897583
Validation loss: 2.0394524374315814

Epoch: 5| Step: 3
Training loss: 2.31463885307312
Validation loss: 2.007292838506801

Epoch: 5| Step: 4
Training loss: 1.7308305501937866
Validation loss: 2.0826774489495063

Epoch: 5| Step: 5
Training loss: 1.7702398300170898
Validation loss: 2.0519288098940285

Epoch: 5| Step: 6
Training loss: 1.535448431968689
Validation loss: 2.0482744016954975

Epoch: 5| Step: 7
Training loss: 2.3629462718963623
Validation loss: 2.0595830871212866

Epoch: 5| Step: 8
Training loss: 2.131598949432373
Validation loss: 2.037151095687702

Epoch: 5| Step: 9
Training loss: 1.4870071411132812
Validation loss: 2.0363513551732546

Epoch: 5| Step: 10
Training loss: 1.8484601974487305
Validation loss: 2.0378513874546176

Epoch: 211| Step: 0
Training loss: 1.666052222251892
Validation loss: 2.0378755805312947

Epoch: 5| Step: 1
Training loss: 1.1900520324707031
Validation loss: 1.9737295360975369

Epoch: 5| Step: 2
Training loss: 1.9982004165649414
Validation loss: 2.0781969613926385

Epoch: 5| Step: 3
Training loss: 2.1920666694641113
Validation loss: 2.045979433162238

Epoch: 5| Step: 4
Training loss: 2.3603732585906982
Validation loss: 2.0358441388735207

Epoch: 5| Step: 5
Training loss: 1.6889537572860718
Validation loss: 2.008858093651392

Epoch: 5| Step: 6
Training loss: 1.7569137811660767
Validation loss: 2.044784225443358

Epoch: 5| Step: 7
Training loss: 1.6482250690460205
Validation loss: 2.0394245091304986

Epoch: 5| Step: 8
Training loss: 1.7798248529434204
Validation loss: 2.0119987469847485

Epoch: 5| Step: 9
Training loss: 2.3401377201080322
Validation loss: 2.0060481550872966

Epoch: 5| Step: 10
Training loss: 1.684861421585083
Validation loss: 2.0327256520589194

Epoch: 212| Step: 0
Training loss: 1.3605101108551025
Validation loss: 2.0407066627215316

Epoch: 5| Step: 1
Training loss: 1.8100684881210327
Validation loss: 1.9972072224463187

Epoch: 5| Step: 2
Training loss: 1.1426752805709839
Validation loss: 2.044478408751949

Epoch: 5| Step: 3
Training loss: 2.3331594467163086
Validation loss: 2.0548630196561097

Epoch: 5| Step: 4
Training loss: 2.3300461769104004
Validation loss: 2.0410294750685334

Epoch: 5| Step: 5
Training loss: 2.1177115440368652
Validation loss: 2.044389593985773

Epoch: 5| Step: 6
Training loss: 1.7783033847808838
Validation loss: 2.0158388025017193

Epoch: 5| Step: 7
Training loss: 1.7319066524505615
Validation loss: 2.039539237176218

Epoch: 5| Step: 8
Training loss: 2.095280647277832
Validation loss: 2.0020578022926085

Epoch: 5| Step: 9
Training loss: 2.190476894378662
Validation loss: 2.0210809143640662

Epoch: 5| Step: 10
Training loss: 1.3340272903442383
Validation loss: 2.047395428021749

Epoch: 213| Step: 0
Training loss: 1.6978490352630615
Validation loss: 2.030732706028928

Epoch: 5| Step: 1
Training loss: 1.720285415649414
Validation loss: 2.0565393688858196

Epoch: 5| Step: 2
Training loss: 1.569658875465393
Validation loss: 2.017402337443444

Epoch: 5| Step: 3
Training loss: 0.9947800636291504
Validation loss: 2.0353811505020305

Epoch: 5| Step: 4
Training loss: 2.1791021823883057
Validation loss: 2.0393634137286933

Epoch: 5| Step: 5
Training loss: 2.6732640266418457
Validation loss: 2.0340755831810737

Epoch: 5| Step: 6
Training loss: 1.9968044757843018
Validation loss: 2.0446110207547425

Epoch: 5| Step: 7
Training loss: 1.8644342422485352
Validation loss: 2.012077034160655

Epoch: 5| Step: 8
Training loss: 2.0727646350860596
Validation loss: 1.9962442510871476

Epoch: 5| Step: 9
Training loss: 1.6505969762802124
Validation loss: 2.0276632590960433

Epoch: 5| Step: 10
Training loss: 1.8902941942214966
Validation loss: 2.0459708347115466

Epoch: 214| Step: 0
Training loss: 1.940352201461792
Validation loss: 1.9996807677771455

Epoch: 5| Step: 1
Training loss: 2.447880506515503
Validation loss: 2.026722255573478

Epoch: 5| Step: 2
Training loss: 1.8950049877166748
Validation loss: 2.0275170597978818

Epoch: 5| Step: 3
Training loss: 2.110563278198242
Validation loss: 2.041319006232805

Epoch: 5| Step: 4
Training loss: 1.9064357280731201
Validation loss: 2.0743715186272897

Epoch: 5| Step: 5
Training loss: 1.9193942546844482
Validation loss: 2.057398165425947

Epoch: 5| Step: 6
Training loss: 1.6803617477416992
Validation loss: 2.0489296810601347

Epoch: 5| Step: 7
Training loss: 1.3312662839889526
Validation loss: 2.058497513494184

Epoch: 5| Step: 8
Training loss: 1.2876981496810913
Validation loss: 2.0091026559952767

Epoch: 5| Step: 9
Training loss: 2.3087031841278076
Validation loss: 2.066223734168596

Epoch: 5| Step: 10
Training loss: 1.7579419612884521
Validation loss: 2.059629932526619

Epoch: 215| Step: 0
Training loss: 1.909463882446289
Validation loss: 2.052500206937072

Epoch: 5| Step: 1
Training loss: 1.6088199615478516
Validation loss: 2.0479691284959034

Epoch: 5| Step: 2
Training loss: 2.195192575454712
Validation loss: 2.060133590493151

Epoch: 5| Step: 3
Training loss: 1.5531909465789795
Validation loss: 2.0415236873011433

Epoch: 5| Step: 4
Training loss: 2.0924556255340576
Validation loss: 2.051434301560925

Epoch: 5| Step: 5
Training loss: 2.0402023792266846
Validation loss: 2.0561453552656275

Epoch: 5| Step: 6
Training loss: 1.9377243518829346
Validation loss: 2.0352234186664706

Epoch: 5| Step: 7
Training loss: 1.9469058513641357
Validation loss: 2.0157379309336343

Epoch: 5| Step: 8
Training loss: 1.3744723796844482
Validation loss: 2.065172359507571

Epoch: 5| Step: 9
Training loss: 1.8538868427276611
Validation loss: 2.1038904754064416

Epoch: 5| Step: 10
Training loss: 2.0971436500549316
Validation loss: 2.040762289877861

Epoch: 216| Step: 0
Training loss: 2.0543887615203857
Validation loss: 2.046167896639916

Epoch: 5| Step: 1
Training loss: 1.6902897357940674
Validation loss: 2.0108723281532206

Epoch: 5| Step: 2
Training loss: 1.7986942529678345
Validation loss: 2.0183697439009145

Epoch: 5| Step: 3
Training loss: 1.8989883661270142
Validation loss: 1.9875628845666045

Epoch: 5| Step: 4
Training loss: 1.306657075881958
Validation loss: 2.0022917639824653

Epoch: 5| Step: 5
Training loss: 1.8302009105682373
Validation loss: 2.022890216560774

Epoch: 5| Step: 6
Training loss: 2.4105632305145264
Validation loss: 2.0162190929535897

Epoch: 5| Step: 7
Training loss: 1.7069613933563232
Validation loss: 2.052698363539993

Epoch: 5| Step: 8
Training loss: 1.7518413066864014
Validation loss: 2.012561002085286

Epoch: 5| Step: 9
Training loss: 2.0683882236480713
Validation loss: 2.02131256493189

Epoch: 5| Step: 10
Training loss: 1.9310722351074219
Validation loss: 2.013328362536687

Epoch: 217| Step: 0
Training loss: 1.5793472528457642
Validation loss: 2.002315454585578

Epoch: 5| Step: 1
Training loss: 1.8597030639648438
Validation loss: 1.9979820097646406

Epoch: 5| Step: 2
Training loss: 1.647491455078125
Validation loss: 2.034698074863803

Epoch: 5| Step: 3
Training loss: 2.134610414505005
Validation loss: 1.9897515543045536

Epoch: 5| Step: 4
Training loss: 2.049649238586426
Validation loss: 2.007521854933872

Epoch: 5| Step: 5
Training loss: 1.6102192401885986
Validation loss: 2.0281296225004297

Epoch: 5| Step: 6
Training loss: 1.8742374181747437
Validation loss: 2.0118738323129635

Epoch: 5| Step: 7
Training loss: 2.288167715072632
Validation loss: 2.059411141180223

Epoch: 5| Step: 8
Training loss: 1.772970199584961
Validation loss: 2.034906182237851

Epoch: 5| Step: 9
Training loss: 1.5058506727218628
Validation loss: 1.9920109266875892

Epoch: 5| Step: 10
Training loss: 1.8890759944915771
Validation loss: 2.0148139076848186

Epoch: 218| Step: 0
Training loss: 2.8053460121154785
Validation loss: 2.0005387644613943

Epoch: 5| Step: 1
Training loss: 1.8246421813964844
Validation loss: 2.0385566680662093

Epoch: 5| Step: 2
Training loss: 1.739177942276001
Validation loss: 1.9823637111212618

Epoch: 5| Step: 3
Training loss: 1.6551685333251953
Validation loss: 2.0092749339278027

Epoch: 5| Step: 4
Training loss: 1.5721492767333984
Validation loss: 2.046680647839782

Epoch: 5| Step: 5
Training loss: 2.385823965072632
Validation loss: 2.00085271686636

Epoch: 5| Step: 6
Training loss: 1.7581720352172852
Validation loss: 2.0233752804417766

Epoch: 5| Step: 7
Training loss: 1.9837229251861572
Validation loss: 2.0207877748756

Epoch: 5| Step: 8
Training loss: 1.6431472301483154
Validation loss: 2.0359087631266606

Epoch: 5| Step: 9
Training loss: 1.635210394859314
Validation loss: 2.01567691885015

Epoch: 5| Step: 10
Training loss: 1.3571586608886719
Validation loss: 1.9914988599797732

Epoch: 219| Step: 0
Training loss: 1.8407726287841797
Validation loss: 2.0212880001273206

Epoch: 5| Step: 1
Training loss: 1.1350290775299072
Validation loss: 2.0709941182085263

Epoch: 5| Step: 2
Training loss: 1.5487557649612427
Validation loss: 1.972492148799281

Epoch: 5| Step: 3
Training loss: 1.9548906087875366
Validation loss: 2.028612703405401

Epoch: 5| Step: 4
Training loss: 2.1223864555358887
Validation loss: 2.0475858565299743

Epoch: 5| Step: 5
Training loss: 1.5298181772232056
Validation loss: 1.9910104966932727

Epoch: 5| Step: 6
Training loss: 1.6343940496444702
Validation loss: 2.0188030530047674

Epoch: 5| Step: 7
Training loss: 1.7944209575653076
Validation loss: 1.994596645396243

Epoch: 5| Step: 8
Training loss: 1.3428001403808594
Validation loss: 2.026932966324591

Epoch: 5| Step: 9
Training loss: 2.2972168922424316
Validation loss: 2.045838213736011

Epoch: 5| Step: 10
Training loss: 2.9882094860076904
Validation loss: 2.013192069145941

Epoch: 220| Step: 0
Training loss: 2.265470504760742
Validation loss: 2.040289250753259

Epoch: 5| Step: 1
Training loss: 1.6698787212371826
Validation loss: 1.9724269925907094

Epoch: 5| Step: 2
Training loss: 1.6090996265411377
Validation loss: 1.9913490036482453

Epoch: 5| Step: 3
Training loss: 1.8068469762802124
Validation loss: 2.0063854250856625

Epoch: 5| Step: 4
Training loss: 2.009227991104126
Validation loss: 2.0268004325128373

Epoch: 5| Step: 5
Training loss: 1.457139492034912
Validation loss: 2.0414622445260324

Epoch: 5| Step: 6
Training loss: 1.3162561655044556
Validation loss: 1.9927291511207499

Epoch: 5| Step: 7
Training loss: 1.758002519607544
Validation loss: 2.0103455282026723

Epoch: 5| Step: 8
Training loss: 1.6819006204605103
Validation loss: 2.045295541004468

Epoch: 5| Step: 9
Training loss: 2.6444897651672363
Validation loss: 2.009954875515353

Epoch: 5| Step: 10
Training loss: 1.7728846073150635
Validation loss: 1.9817917628954815

Epoch: 221| Step: 0
Training loss: 1.9595401287078857
Validation loss: 2.026789911331669

Epoch: 5| Step: 1
Training loss: 1.5647447109222412
Validation loss: 2.0450450040960826

Epoch: 5| Step: 2
Training loss: 1.8977305889129639
Validation loss: 2.0239192106390513

Epoch: 5| Step: 3
Training loss: 1.8942670822143555
Validation loss: 2.016568778663553

Epoch: 5| Step: 4
Training loss: 1.114800214767456
Validation loss: 2.01785478027918

Epoch: 5| Step: 5
Training loss: 1.8409178256988525
Validation loss: 2.0316769781933037

Epoch: 5| Step: 6
Training loss: 1.5540283918380737
Validation loss: 1.9916190575527888

Epoch: 5| Step: 7
Training loss: 2.569436550140381
Validation loss: 2.047777583522181

Epoch: 5| Step: 8
Training loss: 2.334150791168213
Validation loss: 2.010495251224887

Epoch: 5| Step: 9
Training loss: 1.650155782699585
Validation loss: 2.007563724312731

Epoch: 5| Step: 10
Training loss: 1.973729133605957
Validation loss: 2.0749231128282446

Epoch: 222| Step: 0
Training loss: 1.7430168390274048
Validation loss: 1.9916339228230138

Epoch: 5| Step: 1
Training loss: 1.9712568521499634
Validation loss: 1.9983090328913864

Epoch: 5| Step: 2
Training loss: 1.7645235061645508
Validation loss: 1.987185937102123

Epoch: 5| Step: 3
Training loss: 1.9207843542099
Validation loss: 2.002519599853023

Epoch: 5| Step: 4
Training loss: 2.019437789916992
Validation loss: 2.003560940424601

Epoch: 5| Step: 5
Training loss: 2.550114154815674
Validation loss: 2.0155109590099705

Epoch: 5| Step: 6
Training loss: 1.9750282764434814
Validation loss: 2.023040692011515

Epoch: 5| Step: 7
Training loss: 1.5304855108261108
Validation loss: 2.0316277973113523

Epoch: 5| Step: 8
Training loss: 1.4786782264709473
Validation loss: 2.007785439491272

Epoch: 5| Step: 9
Training loss: 1.4925678968429565
Validation loss: 2.02224075922402

Epoch: 5| Step: 10
Training loss: 1.4600340127944946
Validation loss: 2.061166663323679

Epoch: 223| Step: 0
Training loss: 2.107189893722534
Validation loss: 2.0250311077281995

Epoch: 5| Step: 1
Training loss: 1.6364446878433228
Validation loss: 2.0318223122627503

Epoch: 5| Step: 2
Training loss: 2.5016531944274902
Validation loss: 2.0262658134583504

Epoch: 5| Step: 3
Training loss: 2.0730655193328857
Validation loss: 2.0282592824710313

Epoch: 5| Step: 4
Training loss: 1.455775499343872
Validation loss: 1.965174815988028

Epoch: 5| Step: 5
Training loss: 1.2344543933868408
Validation loss: 2.042890146214475

Epoch: 5| Step: 6
Training loss: 0.8256739377975464
Validation loss: 2.0591590032782605

Epoch: 5| Step: 7
Training loss: 2.3404040336608887
Validation loss: 2.0053145552194245

Epoch: 5| Step: 8
Training loss: 1.5102005004882812
Validation loss: 2.037190430907793

Epoch: 5| Step: 9
Training loss: 2.2510600090026855
Validation loss: 2.0338833690971456

Epoch: 5| Step: 10
Training loss: 2.0458648204803467
Validation loss: 1.977924713524439

Epoch: 224| Step: 0
Training loss: 2.1093544960021973
Validation loss: 2.0228836869680755

Epoch: 5| Step: 1
Training loss: 1.8212417364120483
Validation loss: 2.0233452191916843

Epoch: 5| Step: 2
Training loss: 2.0263144969940186
Validation loss: 2.0187481500769175

Epoch: 5| Step: 3
Training loss: 1.5711551904678345
Validation loss: 2.0149659956655195

Epoch: 5| Step: 4
Training loss: 2.184723377227783
Validation loss: 1.9713616576246036

Epoch: 5| Step: 5
Training loss: 1.4532582759857178
Validation loss: 2.0054254583133164

Epoch: 5| Step: 6
Training loss: 1.5578727722167969
Validation loss: 2.004084203832893

Epoch: 5| Step: 7
Training loss: 2.132281541824341
Validation loss: 2.0360227092619865

Epoch: 5| Step: 8
Training loss: 1.508218765258789
Validation loss: 2.0035208015031714

Epoch: 5| Step: 9
Training loss: 1.8528093099594116
Validation loss: 1.9984848704389346

Epoch: 5| Step: 10
Training loss: 1.79087495803833
Validation loss: 2.029780727560802

Epoch: 225| Step: 0
Training loss: 1.565199613571167
Validation loss: 2.0163467084207842

Epoch: 5| Step: 1
Training loss: 1.8979251384735107
Validation loss: 2.03803018728892

Epoch: 5| Step: 2
Training loss: 1.4204992055892944
Validation loss: 2.005417540509214

Epoch: 5| Step: 3
Training loss: 2.0688891410827637
Validation loss: 1.9766562420834777

Epoch: 5| Step: 4
Training loss: 1.9759502410888672
Validation loss: 2.000369147587848

Epoch: 5| Step: 5
Training loss: 1.7746002674102783
Validation loss: 1.9693339717003606

Epoch: 5| Step: 6
Training loss: 2.122236967086792
Validation loss: 1.9905979620513095

Epoch: 5| Step: 7
Training loss: 1.988338828086853
Validation loss: 2.0374892232238606

Epoch: 5| Step: 8
Training loss: 1.6261783838272095
Validation loss: 2.025069764865342

Epoch: 5| Step: 9
Training loss: 1.727341890335083
Validation loss: 2.0172963539759317

Epoch: 5| Step: 10
Training loss: 1.8473505973815918
Validation loss: 2.0378104973864812

Epoch: 226| Step: 0
Training loss: 1.5003774166107178
Validation loss: 1.9831499784223494

Epoch: 5| Step: 1
Training loss: 2.003923177719116
Validation loss: 1.9840430995469451

Epoch: 5| Step: 2
Training loss: 1.2978076934814453
Validation loss: 2.010432799657186

Epoch: 5| Step: 3
Training loss: 2.2277235984802246
Validation loss: 1.9867824021206106

Epoch: 5| Step: 4
Training loss: 1.8426307439804077
Validation loss: 2.017943916782256

Epoch: 5| Step: 5
Training loss: 1.2160186767578125
Validation loss: 2.0095820978123653

Epoch: 5| Step: 6
Training loss: 2.009324789047241
Validation loss: 1.9935403177815099

Epoch: 5| Step: 7
Training loss: 1.6113837957382202
Validation loss: 1.9833998590387323

Epoch: 5| Step: 8
Training loss: 1.6508045196533203
Validation loss: 2.051609892998972

Epoch: 5| Step: 9
Training loss: 2.832984447479248
Validation loss: 2.01067719920989

Epoch: 5| Step: 10
Training loss: 1.3783974647521973
Validation loss: 2.0199803562574488

Epoch: 227| Step: 0
Training loss: 1.7217649221420288
Validation loss: 2.037545624599662

Epoch: 5| Step: 1
Training loss: 2.1232829093933105
Validation loss: 1.99365359480663

Epoch: 5| Step: 2
Training loss: 2.9073290824890137
Validation loss: 2.022158835523872

Epoch: 5| Step: 3
Training loss: 1.7484136819839478
Validation loss: 2.008749218397243

Epoch: 5| Step: 4
Training loss: 1.2673838138580322
Validation loss: 2.0032304794557634

Epoch: 5| Step: 5
Training loss: 1.6091639995574951
Validation loss: 2.009311681152672

Epoch: 5| Step: 6
Training loss: 2.208176374435425
Validation loss: 2.0108206195216023

Epoch: 5| Step: 7
Training loss: 1.8926407098770142
Validation loss: 2.002463653523435

Epoch: 5| Step: 8
Training loss: 1.7664821147918701
Validation loss: 2.026823664224276

Epoch: 5| Step: 9
Training loss: 1.157464861869812
Validation loss: 2.0131580765529344

Epoch: 5| Step: 10
Training loss: 1.7507694959640503
Validation loss: 2.017121466257239

Epoch: 228| Step: 0
Training loss: 2.2382798194885254
Validation loss: 2.0457012986624115

Epoch: 5| Step: 1
Training loss: 1.3643696308135986
Validation loss: 2.0173002981370494

Epoch: 5| Step: 2
Training loss: 2.546875476837158
Validation loss: 2.0592905987975416

Epoch: 5| Step: 3
Training loss: 1.6643297672271729
Validation loss: 1.9354796524970763

Epoch: 5| Step: 4
Training loss: 1.2621642351150513
Validation loss: 1.9903202774704143

Epoch: 5| Step: 5
Training loss: 1.5040333271026611
Validation loss: 2.033639900145992

Epoch: 5| Step: 6
Training loss: 1.8108896017074585
Validation loss: 2.0313961582799114

Epoch: 5| Step: 7
Training loss: 1.7312061786651611
Validation loss: 2.0092166085397043

Epoch: 5| Step: 8
Training loss: 1.9206676483154297
Validation loss: 1.9943695581087502

Epoch: 5| Step: 9
Training loss: 2.304733991622925
Validation loss: 1.9771978726951025

Epoch: 5| Step: 10
Training loss: 1.2684869766235352
Validation loss: 2.0136475075957594

Epoch: 229| Step: 0
Training loss: 1.6450027227401733
Validation loss: 2.0589680107690955

Epoch: 5| Step: 1
Training loss: 1.8524192571640015
Validation loss: 1.990273969147795

Epoch: 5| Step: 2
Training loss: 2.256385326385498
Validation loss: 2.0098313016276204

Epoch: 5| Step: 3
Training loss: 1.5282484292984009
Validation loss: 1.999758953689247

Epoch: 5| Step: 4
Training loss: 1.812485933303833
Validation loss: 1.9843500198856476

Epoch: 5| Step: 5
Training loss: 1.9094765186309814
Validation loss: 1.9939922389163767

Epoch: 5| Step: 6
Training loss: 1.6790624856948853
Validation loss: 2.03607794930858

Epoch: 5| Step: 7
Training loss: 2.044128656387329
Validation loss: 2.002627331723449

Epoch: 5| Step: 8
Training loss: 2.114534854888916
Validation loss: 2.000805711233488

Epoch: 5| Step: 9
Training loss: 2.056415557861328
Validation loss: 1.9580693565389162

Epoch: 5| Step: 10
Training loss: 1.0494272708892822
Validation loss: 2.0126905184920116

Epoch: 230| Step: 0
Training loss: 1.4087201356887817
Validation loss: 2.009674100465672

Epoch: 5| Step: 1
Training loss: 2.3190760612487793
Validation loss: 1.9667225063488047

Epoch: 5| Step: 2
Training loss: 1.6138801574707031
Validation loss: 2.009834493360212

Epoch: 5| Step: 3
Training loss: 1.9668442010879517
Validation loss: 2.0310363013257264

Epoch: 5| Step: 4
Training loss: 1.8618965148925781
Validation loss: 2.0362260854372414

Epoch: 5| Step: 5
Training loss: 1.322429895401001
Validation loss: 2.017197346174589

Epoch: 5| Step: 6
Training loss: 1.6970570087432861
Validation loss: 2.021526105942265

Epoch: 5| Step: 7
Training loss: 1.6582183837890625
Validation loss: 2.0081926468879945

Epoch: 5| Step: 8
Training loss: 2.489468812942505
Validation loss: 2.035193166425151

Epoch: 5| Step: 9
Training loss: 1.910550832748413
Validation loss: 1.9746287074140323

Epoch: 5| Step: 10
Training loss: 1.6280044317245483
Validation loss: 2.0128696836451048

Epoch: 231| Step: 0
Training loss: 1.0640108585357666
Validation loss: 2.0290596946593253

Epoch: 5| Step: 1
Training loss: 1.712902307510376
Validation loss: 2.005636117791617

Epoch: 5| Step: 2
Training loss: 2.6496119499206543
Validation loss: 1.9848871513079571

Epoch: 5| Step: 3
Training loss: 2.462292194366455
Validation loss: 1.9939273018990793

Epoch: 5| Step: 4
Training loss: 1.4965745210647583
Validation loss: 1.9791810948361632

Epoch: 5| Step: 5
Training loss: 1.8535983562469482
Validation loss: 2.0163165676978325

Epoch: 5| Step: 6
Training loss: 1.7726821899414062
Validation loss: 1.9910176646324895

Epoch: 5| Step: 7
Training loss: 1.5733665227890015
Validation loss: 2.0166840899375176

Epoch: 5| Step: 8
Training loss: 1.6278022527694702
Validation loss: 2.0037676954782135

Epoch: 5| Step: 9
Training loss: 1.6465343236923218
Validation loss: 2.004329207122967

Epoch: 5| Step: 10
Training loss: 1.8940095901489258
Validation loss: 1.9745526185599707

Epoch: 232| Step: 0
Training loss: 1.9163296222686768
Validation loss: 2.0106498631097938

Epoch: 5| Step: 1
Training loss: 1.8914754390716553
Validation loss: 1.9990720338718866

Epoch: 5| Step: 2
Training loss: 1.4760239124298096
Validation loss: 2.018820554979386

Epoch: 5| Step: 3
Training loss: 1.6186355352401733
Validation loss: 1.9942824776454637

Epoch: 5| Step: 4
Training loss: 1.5042803287506104
Validation loss: 1.972145233103024

Epoch: 5| Step: 5
Training loss: 2.2924270629882812
Validation loss: 2.0170619064761746

Epoch: 5| Step: 6
Training loss: 1.598988652229309
Validation loss: 1.9859840716085126

Epoch: 5| Step: 7
Training loss: 1.4193261861801147
Validation loss: 2.0011849941745883

Epoch: 5| Step: 8
Training loss: 2.1801371574401855
Validation loss: 2.0310554324939685

Epoch: 5| Step: 9
Training loss: 1.8276958465576172
Validation loss: 1.9861863941274664

Epoch: 5| Step: 10
Training loss: 1.9679527282714844
Validation loss: 2.010447052217299

Epoch: 233| Step: 0
Training loss: 1.541571021080017
Validation loss: 1.9982857601616972

Epoch: 5| Step: 1
Training loss: 1.829087257385254
Validation loss: 2.002524919407342

Epoch: 5| Step: 2
Training loss: 1.612046241760254
Validation loss: 1.9897736849323395

Epoch: 5| Step: 3
Training loss: 2.1732239723205566
Validation loss: 1.9922993298499816

Epoch: 5| Step: 4
Training loss: 1.8895343542099
Validation loss: 2.0252959676968154

Epoch: 5| Step: 5
Training loss: 2.1351442337036133
Validation loss: 1.9996239075096705

Epoch: 5| Step: 6
Training loss: 1.4852256774902344
Validation loss: 2.0152586454986245

Epoch: 5| Step: 7
Training loss: 1.6411864757537842
Validation loss: 2.01339768081583

Epoch: 5| Step: 8
Training loss: 2.224668502807617
Validation loss: 2.024559751633675

Epoch: 5| Step: 9
Training loss: 1.1617774963378906
Validation loss: 1.9841086531198153

Epoch: 5| Step: 10
Training loss: 1.7103103399276733
Validation loss: 2.030228419970441

Epoch: 234| Step: 0
Training loss: 1.8788611888885498
Validation loss: 1.98809866879576

Epoch: 5| Step: 1
Training loss: 2.0535709857940674
Validation loss: 2.044068210868425

Epoch: 5| Step: 2
Training loss: 1.7600587606430054
Validation loss: 2.0190418574117843

Epoch: 5| Step: 3
Training loss: 2.035186290740967
Validation loss: 2.01091944274082

Epoch: 5| Step: 4
Training loss: 2.4442620277404785
Validation loss: 1.996978936656829

Epoch: 5| Step: 5
Training loss: 1.1340982913970947
Validation loss: 2.009663630557317

Epoch: 5| Step: 6
Training loss: 1.584991455078125
Validation loss: 2.028170662541543

Epoch: 5| Step: 7
Training loss: 1.6140168905258179
Validation loss: 2.03714551976932

Epoch: 5| Step: 8
Training loss: 1.9082672595977783
Validation loss: 1.9796058926531064

Epoch: 5| Step: 9
Training loss: 1.5944029092788696
Validation loss: 2.000757210998125

Epoch: 5| Step: 10
Training loss: 1.8174158334732056
Validation loss: 1.998510294063117

Epoch: 235| Step: 0
Training loss: 1.3369615077972412
Validation loss: 1.978940757372046

Epoch: 5| Step: 1
Training loss: 1.8657569885253906
Validation loss: 2.0451819358333463

Epoch: 5| Step: 2
Training loss: 1.3013066053390503
Validation loss: 2.0420969942564606

Epoch: 5| Step: 3
Training loss: 1.246895432472229
Validation loss: 1.9776899430059618

Epoch: 5| Step: 4
Training loss: 1.4312570095062256
Validation loss: 2.0130615772739535

Epoch: 5| Step: 5
Training loss: 1.8468282222747803
Validation loss: 1.9803482409446471

Epoch: 5| Step: 6
Training loss: 1.9143749475479126
Validation loss: 2.0089193569716586

Epoch: 5| Step: 7
Training loss: 2.215549945831299
Validation loss: 1.9949181131137315

Epoch: 5| Step: 8
Training loss: 2.175395965576172
Validation loss: 2.0125445704306326

Epoch: 5| Step: 9
Training loss: 2.337380886077881
Validation loss: 2.001598587600134

Epoch: 5| Step: 10
Training loss: 1.9292858839035034
Validation loss: 2.0158214876728673

Epoch: 236| Step: 0
Training loss: 1.363369345664978
Validation loss: 2.0401642809632006

Epoch: 5| Step: 1
Training loss: 1.6028525829315186
Validation loss: 2.032299221202891

Epoch: 5| Step: 2
Training loss: 1.7307008504867554
Validation loss: 2.0255572744595107

Epoch: 5| Step: 3
Training loss: 1.986554503440857
Validation loss: 2.0447782290879117

Epoch: 5| Step: 4
Training loss: 1.6239382028579712
Validation loss: 2.028573957822656

Epoch: 5| Step: 5
Training loss: 1.5325686931610107
Validation loss: 1.9901888191059072

Epoch: 5| Step: 6
Training loss: 2.3247756958007812
Validation loss: 2.022957376254502

Epoch: 5| Step: 7
Training loss: 1.3931677341461182
Validation loss: 1.9312668538862658

Epoch: 5| Step: 8
Training loss: 2.0007526874542236
Validation loss: 1.9509939070670836

Epoch: 5| Step: 9
Training loss: 1.4696004390716553
Validation loss: 1.9880198855553903

Epoch: 5| Step: 10
Training loss: 2.730189085006714
Validation loss: 2.0070466867057224

Epoch: 237| Step: 0
Training loss: 1.7958252429962158
Validation loss: 1.9953961756921583

Epoch: 5| Step: 1
Training loss: 1.538321852684021
Validation loss: 1.9849596433742072

Epoch: 5| Step: 2
Training loss: 1.3496736288070679
Validation loss: 2.0572745338562997

Epoch: 5| Step: 3
Training loss: 2.069476366043091
Validation loss: 2.0220415143556494

Epoch: 5| Step: 4
Training loss: 1.722185492515564
Validation loss: 1.9764161802107287

Epoch: 5| Step: 5
Training loss: 1.972158432006836
Validation loss: 1.9837224304035146

Epoch: 5| Step: 6
Training loss: 2.2069127559661865
Validation loss: 2.018003673963649

Epoch: 5| Step: 7
Training loss: 1.5464210510253906
Validation loss: 2.0026746296113536

Epoch: 5| Step: 8
Training loss: 2.0758564472198486
Validation loss: 2.0176313692523586

Epoch: 5| Step: 9
Training loss: 1.769289255142212
Validation loss: 2.047397880144017

Epoch: 5| Step: 10
Training loss: 1.32767915725708
Validation loss: 1.9923820085422967

Epoch: 238| Step: 0
Training loss: 2.0981926918029785
Validation loss: 2.009641775520899

Epoch: 5| Step: 1
Training loss: 1.7150710821151733
Validation loss: 1.9682191289881223

Epoch: 5| Step: 2
Training loss: 2.069298267364502
Validation loss: 2.027452407344695

Epoch: 5| Step: 3
Training loss: 1.3233685493469238
Validation loss: 2.001379910335746

Epoch: 5| Step: 4
Training loss: 1.9755384922027588
Validation loss: 2.0331613632940475

Epoch: 5| Step: 5
Training loss: 2.2072174549102783
Validation loss: 2.0343855965522026

Epoch: 5| Step: 6
Training loss: 1.6524168252944946
Validation loss: 1.9981867510785338

Epoch: 5| Step: 7
Training loss: 1.2544581890106201
Validation loss: 2.0054599828617548

Epoch: 5| Step: 8
Training loss: 1.5753209590911865
Validation loss: 1.98839694710188

Epoch: 5| Step: 9
Training loss: 2.1870169639587402
Validation loss: 1.981015721956889

Epoch: 5| Step: 10
Training loss: 1.6050018072128296
Validation loss: 2.000141412981095

Epoch: 239| Step: 0
Training loss: 1.378560185432434
Validation loss: 2.0049437784379527

Epoch: 5| Step: 1
Training loss: 1.5991753339767456
Validation loss: 2.030064845597872

Epoch: 5| Step: 2
Training loss: 1.6704914569854736
Validation loss: 1.9655656891484414

Epoch: 5| Step: 3
Training loss: 1.9288380146026611
Validation loss: 2.0347851284088625

Epoch: 5| Step: 4
Training loss: 1.8816817998886108
Validation loss: 1.9654330015182495

Epoch: 5| Step: 5
Training loss: 1.6895387172698975
Validation loss: 1.9519078475172802

Epoch: 5| Step: 6
Training loss: 2.1875967979431152
Validation loss: 1.946896678657942

Epoch: 5| Step: 7
Training loss: 1.6841129064559937
Validation loss: 2.0244880466051

Epoch: 5| Step: 8
Training loss: 1.8214695453643799
Validation loss: 1.9949994241037676

Epoch: 5| Step: 9
Training loss: 2.2115771770477295
Validation loss: 2.022025330092317

Epoch: 5| Step: 10
Training loss: 1.3442010879516602
Validation loss: 1.9817580664029686

Epoch: 240| Step: 0
Training loss: 1.4623496532440186
Validation loss: 1.9723039339947444

Epoch: 5| Step: 1
Training loss: 1.6755473613739014
Validation loss: 1.9532299451930548

Epoch: 5| Step: 2
Training loss: 1.2453558444976807
Validation loss: 2.0052499976209415

Epoch: 5| Step: 3
Training loss: 2.51274037361145
Validation loss: 2.010488925441619

Epoch: 5| Step: 4
Training loss: 1.917494773864746
Validation loss: 1.9943955547066146

Epoch: 5| Step: 5
Training loss: 1.8033668994903564
Validation loss: 1.9792330829046105

Epoch: 5| Step: 6
Training loss: 2.2096149921417236
Validation loss: 1.9969814259518859

Epoch: 5| Step: 7
Training loss: 2.027700662612915
Validation loss: 2.0069640836408063

Epoch: 5| Step: 8
Training loss: 0.8304001688957214
Validation loss: 2.0365291949241393

Epoch: 5| Step: 9
Training loss: 1.9190797805786133
Validation loss: 1.9753567531544676

Epoch: 5| Step: 10
Training loss: 1.6710076332092285
Validation loss: 2.0244791507720947

Epoch: 241| Step: 0
Training loss: 1.4767124652862549
Validation loss: 1.9574015550715949

Epoch: 5| Step: 1
Training loss: 1.213663101196289
Validation loss: 1.9486319762404247

Epoch: 5| Step: 2
Training loss: 1.5948082208633423
Validation loss: 1.9451704948179183

Epoch: 5| Step: 3
Training loss: 1.587707281112671
Validation loss: 1.9962643987389022

Epoch: 5| Step: 4
Training loss: 2.0763092041015625
Validation loss: 1.9951748514688143

Epoch: 5| Step: 5
Training loss: 2.4275906085968018
Validation loss: 1.991970331438126

Epoch: 5| Step: 6
Training loss: 2.0833818912506104
Validation loss: 1.9802358432482647

Epoch: 5| Step: 7
Training loss: 1.400386095046997
Validation loss: 1.944467426628195

Epoch: 5| Step: 8
Training loss: 1.9262834787368774
Validation loss: 2.0073692234613563

Epoch: 5| Step: 9
Training loss: 1.3850626945495605
Validation loss: 1.974863108768258

Epoch: 5| Step: 10
Training loss: 2.5108108520507812
Validation loss: 2.010459912720547

Epoch: 242| Step: 0
Training loss: 1.8345587253570557
Validation loss: 1.9816832516783027

Epoch: 5| Step: 1
Training loss: 2.255070209503174
Validation loss: 1.9915595695536623

Epoch: 5| Step: 2
Training loss: 1.2131428718566895
Validation loss: 1.9937532973545853

Epoch: 5| Step: 3
Training loss: 1.6414191722869873
Validation loss: 2.0115863251429733

Epoch: 5| Step: 4
Training loss: 1.9792530536651611
Validation loss: 1.9415982923200052

Epoch: 5| Step: 5
Training loss: 1.5437355041503906
Validation loss: 1.9952118960759972

Epoch: 5| Step: 6
Training loss: 1.6595942974090576
Validation loss: 1.988227464819467

Epoch: 5| Step: 7
Training loss: 1.872232437133789
Validation loss: 1.9798970068654707

Epoch: 5| Step: 8
Training loss: 1.5129098892211914
Validation loss: 1.9911517789286952

Epoch: 5| Step: 9
Training loss: 2.195793628692627
Validation loss: 2.0583737883516537

Epoch: 5| Step: 10
Training loss: 1.6006489992141724
Validation loss: 1.9997945857304398

Epoch: 243| Step: 0
Training loss: 1.4380931854248047
Validation loss: 2.049919505273142

Epoch: 5| Step: 1
Training loss: 1.45756995677948
Validation loss: 1.962407369767466

Epoch: 5| Step: 2
Training loss: 1.3291082382202148
Validation loss: 1.9863773212637952

Epoch: 5| Step: 3
Training loss: 1.9817063808441162
Validation loss: 1.986365274716449

Epoch: 5| Step: 4
Training loss: 1.186287522315979
Validation loss: 2.0156030680543635

Epoch: 5| Step: 5
Training loss: 1.6738132238388062
Validation loss: 1.9902297886469031

Epoch: 5| Step: 6
Training loss: 1.7947591543197632
Validation loss: 1.978414802141087

Epoch: 5| Step: 7
Training loss: 1.2836809158325195
Validation loss: 2.0005967668307725

Epoch: 5| Step: 8
Training loss: 2.3860902786254883
Validation loss: 1.9465244970014017

Epoch: 5| Step: 9
Training loss: 2.608076333999634
Validation loss: 1.9758339620405627

Epoch: 5| Step: 10
Training loss: 2.2257165908813477
Validation loss: 1.9629796628029115

Epoch: 244| Step: 0
Training loss: 1.3059654235839844
Validation loss: 1.9772325138891897

Epoch: 5| Step: 1
Training loss: 1.8238449096679688
Validation loss: 2.0128763619289605

Epoch: 5| Step: 2
Training loss: 1.5637279748916626
Validation loss: 1.968771808890886

Epoch: 5| Step: 3
Training loss: 1.284363031387329
Validation loss: 1.9745501472103981

Epoch: 5| Step: 4
Training loss: 1.734328031539917
Validation loss: 1.9834637872634395

Epoch: 5| Step: 5
Training loss: 1.9747737646102905
Validation loss: 1.9659764484692646

Epoch: 5| Step: 6
Training loss: 2.157351016998291
Validation loss: 2.0136809938697406

Epoch: 5| Step: 7
Training loss: 2.027841806411743
Validation loss: 1.980130208435879

Epoch: 5| Step: 8
Training loss: 1.5477344989776611
Validation loss: 1.9827096385340537

Epoch: 5| Step: 9
Training loss: 1.683896780014038
Validation loss: 1.9832997193900488

Epoch: 5| Step: 10
Training loss: 2.2665112018585205
Validation loss: 1.9807042191105504

Epoch: 245| Step: 0
Training loss: 1.5213767290115356
Validation loss: 1.9828392574864049

Epoch: 5| Step: 1
Training loss: 1.819051742553711
Validation loss: 2.0349936716018187

Epoch: 5| Step: 2
Training loss: 1.5966765880584717
Validation loss: 1.9679244090152044

Epoch: 5| Step: 3
Training loss: 2.0782713890075684
Validation loss: 2.0024582583417176

Epoch: 5| Step: 4
Training loss: 2.205498695373535
Validation loss: 1.9784867443064207

Epoch: 5| Step: 5
Training loss: 1.612099051475525
Validation loss: 1.9629664395445137

Epoch: 5| Step: 6
Training loss: 2.234949827194214
Validation loss: 1.9506602441110918

Epoch: 5| Step: 7
Training loss: 1.5778239965438843
Validation loss: 1.9675357264857138

Epoch: 5| Step: 8
Training loss: 1.3512651920318604
Validation loss: 2.001277418546779

Epoch: 5| Step: 9
Training loss: 2.1433634757995605
Validation loss: 1.9615057770923903

Epoch: 5| Step: 10
Training loss: 1.521128535270691
Validation loss: 2.0003512751671577

Epoch: 246| Step: 0
Training loss: 2.407583713531494
Validation loss: 1.9874772564057381

Epoch: 5| Step: 1
Training loss: 1.162844181060791
Validation loss: 1.9942653909806283

Epoch: 5| Step: 2
Training loss: 1.188192367553711
Validation loss: 1.9918616343570013

Epoch: 5| Step: 3
Training loss: 1.7216789722442627
Validation loss: 1.9888626478051628

Epoch: 5| Step: 4
Training loss: 1.6665809154510498
Validation loss: 2.016901680218276

Epoch: 5| Step: 5
Training loss: 1.4607056379318237
Validation loss: 2.003755856585759

Epoch: 5| Step: 6
Training loss: 2.208164930343628
Validation loss: 1.949800081150506

Epoch: 5| Step: 7
Training loss: 2.414046287536621
Validation loss: 1.9993560429542296

Epoch: 5| Step: 8
Training loss: 1.3280961513519287
Validation loss: 2.008105147269464

Epoch: 5| Step: 9
Training loss: 1.6586220264434814
Validation loss: 2.0246211123722855

Epoch: 5| Step: 10
Training loss: 1.9571861028671265
Validation loss: 2.0198242331063874

Epoch: 247| Step: 0
Training loss: 2.0059685707092285
Validation loss: 1.9777798614194315

Epoch: 5| Step: 1
Training loss: 1.3884637355804443
Validation loss: 1.9968305903096353

Epoch: 5| Step: 2
Training loss: 1.651808500289917
Validation loss: 1.9867619006864485

Epoch: 5| Step: 3
Training loss: 0.8227956891059875
Validation loss: 1.9827538036531018

Epoch: 5| Step: 4
Training loss: 1.6396173238754272
Validation loss: 1.9734364081454534

Epoch: 5| Step: 5
Training loss: 1.8087373971939087
Validation loss: 2.02474796131093

Epoch: 5| Step: 6
Training loss: 1.5974617004394531
Validation loss: 1.9484324121987948

Epoch: 5| Step: 7
Training loss: 1.6711704730987549
Validation loss: 1.9544438367248864

Epoch: 5| Step: 8
Training loss: 2.6706314086914062
Validation loss: 1.9732084774201917

Epoch: 5| Step: 9
Training loss: 1.363419771194458
Validation loss: 1.9854437151262838

Epoch: 5| Step: 10
Training loss: 2.9190542697906494
Validation loss: 1.9478762316447433

Epoch: 248| Step: 0
Training loss: 1.7032676935195923
Validation loss: 2.0793550937406478

Epoch: 5| Step: 1
Training loss: 1.2033287286758423
Validation loss: 1.9648321584988666

Epoch: 5| Step: 2
Training loss: 1.703645944595337
Validation loss: 1.9505693117777507

Epoch: 5| Step: 3
Training loss: 1.7189276218414307
Validation loss: 1.9604223389779367

Epoch: 5| Step: 4
Training loss: 2.2350106239318848
Validation loss: 2.005167450956119

Epoch: 5| Step: 5
Training loss: 1.6265605688095093
Validation loss: 1.9614335926630164

Epoch: 5| Step: 6
Training loss: 2.266634941101074
Validation loss: 1.9415287381859236

Epoch: 5| Step: 7
Training loss: 1.4702898263931274
Validation loss: 1.9417830897915749

Epoch: 5| Step: 8
Training loss: 1.537536859512329
Validation loss: 1.9950318285214004

Epoch: 5| Step: 9
Training loss: 2.3982529640197754
Validation loss: 1.9658173950769569

Epoch: 5| Step: 10
Training loss: 1.8372128009796143
Validation loss: 2.026114515078965

Epoch: 249| Step: 0
Training loss: 1.9197146892547607
Validation loss: 1.988163491731049

Epoch: 5| Step: 1
Training loss: 1.5677087306976318
Validation loss: 2.0047712031231133

Epoch: 5| Step: 2
Training loss: 1.651964783668518
Validation loss: 1.9784457247744325

Epoch: 5| Step: 3
Training loss: 1.704744577407837
Validation loss: 1.9990017773002706

Epoch: 5| Step: 4
Training loss: 1.7245237827301025
Validation loss: 1.9790107421977545

Epoch: 5| Step: 5
Training loss: 2.339824676513672
Validation loss: 1.9603187884053876

Epoch: 5| Step: 6
Training loss: 1.8178383111953735
Validation loss: 1.9753609934160787

Epoch: 5| Step: 7
Training loss: 1.7506402730941772
Validation loss: 2.0094314031703497

Epoch: 5| Step: 8
Training loss: 2.0786242485046387
Validation loss: 1.963929622404037

Epoch: 5| Step: 9
Training loss: 0.9815009832382202
Validation loss: 1.973129459606704

Epoch: 5| Step: 10
Training loss: 1.6942945718765259
Validation loss: 2.003028873474367

Epoch: 250| Step: 0
Training loss: 2.031106472015381
Validation loss: 1.965046049446188

Epoch: 5| Step: 1
Training loss: 2.208622932434082
Validation loss: 2.0149331785017446

Epoch: 5| Step: 2
Training loss: 1.3016481399536133
Validation loss: 1.9805772612171788

Epoch: 5| Step: 3
Training loss: 1.6786073446273804
Validation loss: 1.9867825444026659

Epoch: 5| Step: 4
Training loss: 1.6960080862045288
Validation loss: 1.9897988419378958

Epoch: 5| Step: 5
Training loss: 1.044980764389038
Validation loss: 2.0611317439745833

Epoch: 5| Step: 6
Training loss: 2.0453176498413086
Validation loss: 1.9848003720724454

Epoch: 5| Step: 7
Training loss: 1.9610302448272705
Validation loss: 2.002550099485664

Epoch: 5| Step: 8
Training loss: 1.8549959659576416
Validation loss: 2.0453575426532375

Epoch: 5| Step: 9
Training loss: 1.7316348552703857
Validation loss: 2.0136705008886193

Epoch: 5| Step: 10
Training loss: 1.8262463808059692
Validation loss: 1.9990646787869033

Epoch: 251| Step: 0
Training loss: 1.626638412475586
Validation loss: 2.0218293038747643

Epoch: 5| Step: 1
Training loss: 1.7713613510131836
Validation loss: 2.0257851128937094

Epoch: 5| Step: 2
Training loss: 1.7834850549697876
Validation loss: 1.9776381061923118

Epoch: 5| Step: 3
Training loss: 1.8322089910507202
Validation loss: 1.9934482100189372

Epoch: 5| Step: 4
Training loss: 2.34782075881958
Validation loss: 1.9855649253373504

Epoch: 5| Step: 5
Training loss: 1.339148759841919
Validation loss: 1.958742028923445

Epoch: 5| Step: 6
Training loss: 1.8056141138076782
Validation loss: 2.0237609365934968

Epoch: 5| Step: 7
Training loss: 1.687925100326538
Validation loss: 1.9708148343588716

Epoch: 5| Step: 8
Training loss: 1.6385570764541626
Validation loss: 1.9989863980200984

Epoch: 5| Step: 9
Training loss: 1.4675043821334839
Validation loss: 1.9941678047180176

Epoch: 5| Step: 10
Training loss: 1.3762891292572021
Validation loss: 2.0206831834649526

Epoch: 252| Step: 0
Training loss: 1.849344253540039
Validation loss: 1.9706842002048288

Epoch: 5| Step: 1
Training loss: 1.4471170902252197
Validation loss: 2.032013894409262

Epoch: 5| Step: 2
Training loss: 2.43233585357666
Validation loss: 2.040467059740456

Epoch: 5| Step: 3
Training loss: 2.079285144805908
Validation loss: 1.9833649896806287

Epoch: 5| Step: 4
Training loss: 1.6959497928619385
Validation loss: 1.9275363696518766

Epoch: 5| Step: 5
Training loss: 1.551673173904419
Validation loss: 2.0179074836033646

Epoch: 5| Step: 6
Training loss: 1.1080868244171143
Validation loss: 1.9382147865910684

Epoch: 5| Step: 7
Training loss: 1.4792892932891846
Validation loss: 1.9610894969714585

Epoch: 5| Step: 8
Training loss: 2.4235854148864746
Validation loss: 1.9877923457853255

Epoch: 5| Step: 9
Training loss: 1.2657856941223145
Validation loss: 1.980245462027929

Epoch: 5| Step: 10
Training loss: 1.7503794431686401
Validation loss: 1.988350050423735

Epoch: 253| Step: 0
Training loss: 1.7701839208602905
Validation loss: 1.986415345181701

Epoch: 5| Step: 1
Training loss: 1.1144505739212036
Validation loss: 2.0049543649919572

Epoch: 5| Step: 2
Training loss: 1.8066437244415283
Validation loss: 1.9596883532821492

Epoch: 5| Step: 3
Training loss: 1.5109305381774902
Validation loss: 1.9224626864156416

Epoch: 5| Step: 4
Training loss: 1.692151665687561
Validation loss: 2.0094700808166177

Epoch: 5| Step: 5
Training loss: 1.8573219776153564
Validation loss: 1.9347569622019285

Epoch: 5| Step: 6
Training loss: 1.9086923599243164
Validation loss: 1.9737375205562961

Epoch: 5| Step: 7
Training loss: 1.7386459112167358
Validation loss: 1.9749504340592252

Epoch: 5| Step: 8
Training loss: 1.6144640445709229
Validation loss: 2.046236885491238

Epoch: 5| Step: 9
Training loss: 1.6716417074203491
Validation loss: 1.9537880625776065

Epoch: 5| Step: 10
Training loss: 2.1439132690429688
Validation loss: 1.9924153166432534

Epoch: 254| Step: 0
Training loss: 1.85115647315979
Validation loss: 1.9977739087996944

Epoch: 5| Step: 1
Training loss: 1.7633241415023804
Validation loss: 1.973693440037389

Epoch: 5| Step: 2
Training loss: 2.021308422088623
Validation loss: 1.9545624115133797

Epoch: 5| Step: 3
Training loss: 1.746180772781372
Validation loss: 2.0191200702421126

Epoch: 5| Step: 4
Training loss: 1.3617007732391357
Validation loss: 1.9379729391426168

Epoch: 5| Step: 5
Training loss: 1.5852999687194824
Validation loss: 2.010531594676356

Epoch: 5| Step: 6
Training loss: 2.096235752105713
Validation loss: 1.9300145795268397

Epoch: 5| Step: 7
Training loss: 1.750282883644104
Validation loss: 1.940017633540656

Epoch: 5| Step: 8
Training loss: 1.9692147970199585
Validation loss: 2.0127824224451536

Epoch: 5| Step: 9
Training loss: 1.310281753540039
Validation loss: 1.9765920023764334

Epoch: 5| Step: 10
Training loss: 1.539359450340271
Validation loss: 1.9591973340639504

Epoch: 255| Step: 0
Training loss: 1.6418569087982178
Validation loss: 1.9726940701084752

Epoch: 5| Step: 1
Training loss: 1.3613921403884888
Validation loss: 1.9390561285839285

Epoch: 5| Step: 2
Training loss: 2.486511468887329
Validation loss: 1.9915039359882314

Epoch: 5| Step: 3
Training loss: 1.3890745639801025
Validation loss: 1.9230882890762822

Epoch: 5| Step: 4
Training loss: 1.8781846761703491
Validation loss: 1.9623549010163994

Epoch: 5| Step: 5
Training loss: 1.3415729999542236
Validation loss: 1.9194122950236003

Epoch: 5| Step: 6
Training loss: 1.320149540901184
Validation loss: 1.984920188944827

Epoch: 5| Step: 7
Training loss: 1.1812189817428589
Validation loss: 2.02405745239668

Epoch: 5| Step: 8
Training loss: 1.7495819330215454
Validation loss: 1.9865769763146677

Epoch: 5| Step: 9
Training loss: 2.1912150382995605
Validation loss: 1.9510938134244693

Epoch: 5| Step: 10
Training loss: 2.4450511932373047
Validation loss: 1.9553512962915565

Epoch: 256| Step: 0
Training loss: 1.7696752548217773
Validation loss: 2.0282042475156885

Epoch: 5| Step: 1
Training loss: 1.2136811017990112
Validation loss: 2.002420976597776

Epoch: 5| Step: 2
Training loss: 1.7434924840927124
Validation loss: 1.9720641823225125

Epoch: 5| Step: 3
Training loss: 1.8103071451187134
Validation loss: 1.9800408399233254

Epoch: 5| Step: 4
Training loss: 1.1505169868469238
Validation loss: 1.9469465081409743

Epoch: 5| Step: 5
Training loss: 1.8085277080535889
Validation loss: 2.0312190389120452

Epoch: 5| Step: 6
Training loss: 1.649147391319275
Validation loss: 1.9665899302369805

Epoch: 5| Step: 7
Training loss: 2.301846981048584
Validation loss: 1.979006213526572

Epoch: 5| Step: 8
Training loss: 1.4270766973495483
Validation loss: 1.9861477216084797

Epoch: 5| Step: 9
Training loss: 1.9658944606781006
Validation loss: 1.9848061018092658

Epoch: 5| Step: 10
Training loss: 2.3096389770507812
Validation loss: 2.0155661439382904

Epoch: 257| Step: 0
Training loss: 1.8496339321136475
Validation loss: 1.9667121928225282

Epoch: 5| Step: 1
Training loss: 2.041860818862915
Validation loss: 2.024509943941588

Epoch: 5| Step: 2
Training loss: 1.476784586906433
Validation loss: 1.9553518936198244

Epoch: 5| Step: 3
Training loss: 1.4973469972610474
Validation loss: 2.0363425208676245

Epoch: 5| Step: 4
Training loss: 1.4838144779205322
Validation loss: 1.9807317731201008

Epoch: 5| Step: 5
Training loss: 1.6816997528076172
Validation loss: 1.9289536078770955

Epoch: 5| Step: 6
Training loss: 1.9998953342437744
Validation loss: 1.9563733198309456

Epoch: 5| Step: 7
Training loss: 1.6436331272125244
Validation loss: 2.0062277509320166

Epoch: 5| Step: 8
Training loss: 1.8438291549682617
Validation loss: 1.9595620273261942

Epoch: 5| Step: 9
Training loss: 2.2779741287231445
Validation loss: 1.9795650333486579

Epoch: 5| Step: 10
Training loss: 1.3771281242370605
Validation loss: 1.9805210316053001

Epoch: 258| Step: 0
Training loss: 1.890014410018921
Validation loss: 1.9907450675964355

Epoch: 5| Step: 1
Training loss: 1.5797383785247803
Validation loss: 1.9956466690186532

Epoch: 5| Step: 2
Training loss: 1.8271839618682861
Validation loss: 2.0006593901623964

Epoch: 5| Step: 3
Training loss: 1.6376718282699585
Validation loss: 1.9784378287612752

Epoch: 5| Step: 4
Training loss: 1.7776834964752197
Validation loss: 1.9987335128168906

Epoch: 5| Step: 5
Training loss: 1.3812440633773804
Validation loss: 2.0144861487932104

Epoch: 5| Step: 6
Training loss: 1.4953349828720093
Validation loss: 1.9692778459159277

Epoch: 5| Step: 7
Training loss: 2.118889808654785
Validation loss: 1.93883176003733

Epoch: 5| Step: 8
Training loss: 1.727379560470581
Validation loss: 2.038184876083046

Epoch: 5| Step: 9
Training loss: 2.1814849376678467
Validation loss: 1.984011471912425

Epoch: 5| Step: 10
Training loss: 1.4002355337142944
Validation loss: 1.9513367196565032

Epoch: 259| Step: 0
Training loss: 1.8956184387207031
Validation loss: 1.9763210793977142

Epoch: 5| Step: 1
Training loss: 1.231279730796814
Validation loss: 2.0182412606413647

Epoch: 5| Step: 2
Training loss: 1.2129091024398804
Validation loss: 2.0057000960073164

Epoch: 5| Step: 3
Training loss: 2.2660861015319824
Validation loss: 2.001382743158648

Epoch: 5| Step: 4
Training loss: 1.4930851459503174
Validation loss: 1.9551279647375948

Epoch: 5| Step: 5
Training loss: 2.07509183883667
Validation loss: 1.9750379067595287

Epoch: 5| Step: 6
Training loss: 1.3259143829345703
Validation loss: 1.9924408312766784

Epoch: 5| Step: 7
Training loss: 2.287571430206299
Validation loss: 1.9879607180113434

Epoch: 5| Step: 8
Training loss: 1.7922532558441162
Validation loss: 1.9837956748982912

Epoch: 5| Step: 9
Training loss: 1.7613525390625
Validation loss: 1.952677913891372

Epoch: 5| Step: 10
Training loss: 1.4354753494262695
Validation loss: 1.9739265390621719

Epoch: 260| Step: 0
Training loss: 1.1876888275146484
Validation loss: 2.0167609299382856

Epoch: 5| Step: 1
Training loss: 1.7372663021087646
Validation loss: 1.976737488982498

Epoch: 5| Step: 2
Training loss: 2.3987479209899902
Validation loss: 1.9508471899135138

Epoch: 5| Step: 3
Training loss: 1.8542553186416626
Validation loss: 1.9342409103147444

Epoch: 5| Step: 4
Training loss: 1.759831428527832
Validation loss: 1.9813657960584086

Epoch: 5| Step: 5
Training loss: 1.8266559839248657
Validation loss: 1.9668611659798572

Epoch: 5| Step: 6
Training loss: 1.375029444694519
Validation loss: 1.9490959887863488

Epoch: 5| Step: 7
Training loss: 1.7286584377288818
Validation loss: 1.9599250952402751

Epoch: 5| Step: 8
Training loss: 1.7776906490325928
Validation loss: 1.9338732675839496

Epoch: 5| Step: 9
Training loss: 1.7611541748046875
Validation loss: 1.9900501069202219

Epoch: 5| Step: 10
Training loss: 1.4001480340957642
Validation loss: 1.973409786019274

Epoch: 261| Step: 0
Training loss: 1.6091766357421875
Validation loss: 1.9458250435449744

Epoch: 5| Step: 1
Training loss: 1.6786648035049438
Validation loss: 1.9715297837411203

Epoch: 5| Step: 2
Training loss: 1.7415968179702759
Validation loss: 1.9801862432110695

Epoch: 5| Step: 3
Training loss: 2.1687207221984863
Validation loss: 1.9933450952652962

Epoch: 5| Step: 4
Training loss: 1.9469207525253296
Validation loss: 1.958767088510657

Epoch: 5| Step: 5
Training loss: 2.0246078968048096
Validation loss: 2.013044754664103

Epoch: 5| Step: 6
Training loss: 1.1064538955688477
Validation loss: 2.0025802004721855

Epoch: 5| Step: 7
Training loss: 1.8556327819824219
Validation loss: 2.006410798718852

Epoch: 5| Step: 8
Training loss: 1.6576623916625977
Validation loss: 1.976896656456814

Epoch: 5| Step: 9
Training loss: 1.8578064441680908
Validation loss: 1.9979886265211209

Epoch: 5| Step: 10
Training loss: 1.243327021598816
Validation loss: 1.9708788112927509

Epoch: 262| Step: 0
Training loss: 1.541057825088501
Validation loss: 1.9622888308699413

Epoch: 5| Step: 1
Training loss: 1.6567636728286743
Validation loss: 1.9728126833515782

Epoch: 5| Step: 2
Training loss: 1.2648348808288574
Validation loss: 1.9826227875166043

Epoch: 5| Step: 3
Training loss: 1.7390928268432617
Validation loss: 1.929062512613112

Epoch: 5| Step: 4
Training loss: 2.2986044883728027
Validation loss: 1.9997938768838042

Epoch: 5| Step: 5
Training loss: 1.7596241235733032
Validation loss: 1.9947782101169709

Epoch: 5| Step: 6
Training loss: 1.592751145362854
Validation loss: 2.026739121765219

Epoch: 5| Step: 7
Training loss: 1.8881820440292358
Validation loss: 2.00059526453736

Epoch: 5| Step: 8
Training loss: 1.6938273906707764
Validation loss: 1.9919021180880967

Epoch: 5| Step: 9
Training loss: 1.9413211345672607
Validation loss: 1.9665673676357474

Epoch: 5| Step: 10
Training loss: 1.3750388622283936
Validation loss: 1.987571108725763

Epoch: 263| Step: 0
Training loss: 1.751824975013733
Validation loss: 1.9321359729254117

Epoch: 5| Step: 1
Training loss: 0.9276437759399414
Validation loss: 1.935333259644047

Epoch: 5| Step: 2
Training loss: 1.4769694805145264
Validation loss: 2.001745826454573

Epoch: 5| Step: 3
Training loss: 1.7840392589569092
Validation loss: 1.9519304716458885

Epoch: 5| Step: 4
Training loss: 1.7285115718841553
Validation loss: 1.9785584903532458

Epoch: 5| Step: 5
Training loss: 1.8438985347747803
Validation loss: 1.9593672419107089

Epoch: 5| Step: 6
Training loss: 2.2193539142608643
Validation loss: 2.012786260215185

Epoch: 5| Step: 7
Training loss: 1.757885217666626
Validation loss: 1.994552780223149

Epoch: 5| Step: 8
Training loss: 2.003635883331299
Validation loss: 2.0039902297399377

Epoch: 5| Step: 9
Training loss: 1.807582139968872
Validation loss: 1.9826330984792402

Epoch: 5| Step: 10
Training loss: 0.916885256767273
Validation loss: 1.9556119390713271

Epoch: 264| Step: 0
Training loss: 2.0375189781188965
Validation loss: 1.962975981414959

Epoch: 5| Step: 1
Training loss: 1.2498221397399902
Validation loss: 1.9177685091572423

Epoch: 5| Step: 2
Training loss: 1.5715768337249756
Validation loss: 1.9936104307892502

Epoch: 5| Step: 3
Training loss: 1.6959526538848877
Validation loss: 1.9630803677343553

Epoch: 5| Step: 4
Training loss: 1.2303415536880493
Validation loss: 2.00099160978871

Epoch: 5| Step: 5
Training loss: 0.9788589477539062
Validation loss: 1.9362083532476937

Epoch: 5| Step: 6
Training loss: 1.8156448602676392
Validation loss: 1.978364190747661

Epoch: 5| Step: 7
Training loss: 2.0050911903381348
Validation loss: 1.952220920593508

Epoch: 5| Step: 8
Training loss: 1.7610223293304443
Validation loss: 1.9627984441736692

Epoch: 5| Step: 9
Training loss: 2.152249813079834
Validation loss: 1.9667469057985532

Epoch: 5| Step: 10
Training loss: 1.889123558998108
Validation loss: 1.9356242341379966

Epoch: 265| Step: 0
Training loss: 1.7376295328140259
Validation loss: 1.9903663512199157

Epoch: 5| Step: 1
Training loss: 1.9368658065795898
Validation loss: 1.9658362570629324

Epoch: 5| Step: 2
Training loss: 2.7876224517822266
Validation loss: 2.046781906517603

Epoch: 5| Step: 3
Training loss: 1.5737099647521973
Validation loss: 1.9326586915600685

Epoch: 5| Step: 4
Training loss: 1.5773837566375732
Validation loss: 1.9572707042899182

Epoch: 5| Step: 5
Training loss: 2.1393373012542725
Validation loss: 1.998147597876928

Epoch: 5| Step: 6
Training loss: 1.3760178089141846
Validation loss: 1.967605721565985

Epoch: 5| Step: 7
Training loss: 1.2261064052581787
Validation loss: 1.9866676497203049

Epoch: 5| Step: 8
Training loss: 1.3546634912490845
Validation loss: 1.980134762743468

Epoch: 5| Step: 9
Training loss: 1.4829614162445068
Validation loss: 2.030000748172883

Epoch: 5| Step: 10
Training loss: 1.675150990486145
Validation loss: 1.9779637321349113

Epoch: 266| Step: 0
Training loss: 1.9556896686553955
Validation loss: 2.0095638472546815

Epoch: 5| Step: 1
Training loss: 1.818864107131958
Validation loss: 2.008798700506969

Epoch: 5| Step: 2
Training loss: 1.2965165376663208
Validation loss: 1.9900062763562767

Epoch: 5| Step: 3
Training loss: 1.5029582977294922
Validation loss: 1.9360565011219313

Epoch: 5| Step: 4
Training loss: 1.8650147914886475
Validation loss: 1.9830511795577181

Epoch: 5| Step: 5
Training loss: 1.7901256084442139
Validation loss: 1.941770020351615

Epoch: 5| Step: 6
Training loss: 1.6598936319351196
Validation loss: 2.013060305708198

Epoch: 5| Step: 7
Training loss: 2.1230521202087402
Validation loss: 1.8951433474017727

Epoch: 5| Step: 8
Training loss: 1.6106078624725342
Validation loss: 1.9333549955839753

Epoch: 5| Step: 9
Training loss: 1.3294122219085693
Validation loss: 1.9700162910646009

Epoch: 5| Step: 10
Training loss: 1.4726057052612305
Validation loss: 1.9211174890559206

Epoch: 267| Step: 0
Training loss: 1.9154345989227295
Validation loss: 2.000144858514109

Epoch: 5| Step: 1
Training loss: 1.7954940795898438
Validation loss: 1.956315032897457

Epoch: 5| Step: 2
Training loss: 1.6121540069580078
Validation loss: 1.9797429705178866

Epoch: 5| Step: 3
Training loss: 1.6758215427398682
Validation loss: 1.971282861566031

Epoch: 5| Step: 4
Training loss: 2.0459208488464355
Validation loss: 1.9847493043509863

Epoch: 5| Step: 5
Training loss: 1.4731433391571045
Validation loss: 1.9501422066842355

Epoch: 5| Step: 6
Training loss: 1.7359726428985596
Validation loss: 1.9716651760121828

Epoch: 5| Step: 7
Training loss: 1.905066728591919
Validation loss: 1.9568934286794355

Epoch: 5| Step: 8
Training loss: 1.4471123218536377
Validation loss: 1.960743647749706

Epoch: 5| Step: 9
Training loss: 1.4602973461151123
Validation loss: 1.9806194587420392

Epoch: 5| Step: 10
Training loss: 1.4905058145523071
Validation loss: 2.0082153658713064

Epoch: 268| Step: 0
Training loss: 1.4987930059432983
Validation loss: 1.9707183876345236

Epoch: 5| Step: 1
Training loss: 2.5255417823791504
Validation loss: 1.9465593625140447

Epoch: 5| Step: 2
Training loss: 1.5529663562774658
Validation loss: 1.941844464630209

Epoch: 5| Step: 3
Training loss: 1.660845398902893
Validation loss: 1.995705932699224

Epoch: 5| Step: 4
Training loss: 1.7415084838867188
Validation loss: 2.0336424766048307

Epoch: 5| Step: 5
Training loss: 1.8887879848480225
Validation loss: 1.9568087003564323

Epoch: 5| Step: 6
Training loss: 1.2351343631744385
Validation loss: 2.0172465796111734

Epoch: 5| Step: 7
Training loss: 1.5134646892547607
Validation loss: 1.9675096927150604

Epoch: 5| Step: 8
Training loss: 2.1520886421203613
Validation loss: 1.9275143108060282

Epoch: 5| Step: 9
Training loss: 1.3102538585662842
Validation loss: 1.9760600059263167

Epoch: 5| Step: 10
Training loss: 1.828620195388794
Validation loss: 2.017852644766531

Epoch: 269| Step: 0
Training loss: 1.2460262775421143
Validation loss: 2.0070014410121466

Epoch: 5| Step: 1
Training loss: 1.193173885345459
Validation loss: 1.9762227355792958

Epoch: 5| Step: 2
Training loss: 1.2413170337677002
Validation loss: 1.996769916626715

Epoch: 5| Step: 3
Training loss: 2.23750901222229
Validation loss: 1.9387750766610587

Epoch: 5| Step: 4
Training loss: 2.1649398803710938
Validation loss: 1.9586446054520146

Epoch: 5| Step: 5
Training loss: 2.256218910217285
Validation loss: 1.9873748492169123

Epoch: 5| Step: 6
Training loss: 1.3978586196899414
Validation loss: 1.9648255942970194

Epoch: 5| Step: 7
Training loss: 1.3837791681289673
Validation loss: 1.994221971881005

Epoch: 5| Step: 8
Training loss: 1.8770252466201782
Validation loss: 1.9976578938063754

Epoch: 5| Step: 9
Training loss: 1.611792802810669
Validation loss: 1.973857759147562

Epoch: 5| Step: 10
Training loss: 1.7774633169174194
Validation loss: 1.961217991767391

Epoch: 270| Step: 0
Training loss: 1.892804741859436
Validation loss: 1.9762052630865445

Epoch: 5| Step: 1
Training loss: 1.4978094100952148
Validation loss: 1.9809610741112822

Epoch: 5| Step: 2
Training loss: 1.7604191303253174
Validation loss: 2.0311061079784105

Epoch: 5| Step: 3
Training loss: 1.4308545589447021
Validation loss: 2.0256183660158547

Epoch: 5| Step: 4
Training loss: 1.678163766860962
Validation loss: 2.0341988430228284

Epoch: 5| Step: 5
Training loss: 1.4898862838745117
Validation loss: 1.9708538427147815

Epoch: 5| Step: 6
Training loss: 1.7116165161132812
Validation loss: 1.9996941371630597

Epoch: 5| Step: 7
Training loss: 1.6579097509384155
Validation loss: 2.0013216772387104

Epoch: 5| Step: 8
Training loss: 1.7879451513290405
Validation loss: 1.9860519286124938

Epoch: 5| Step: 9
Training loss: 1.7566261291503906
Validation loss: 2.007808220001959

Epoch: 5| Step: 10
Training loss: 1.802709937095642
Validation loss: 1.9508792738760672

Epoch: 271| Step: 0
Training loss: 1.6039259433746338
Validation loss: 1.9589341507163098

Epoch: 5| Step: 1
Training loss: 1.5012692213058472
Validation loss: 1.9940624083242109

Epoch: 5| Step: 2
Training loss: 1.932241439819336
Validation loss: 1.9962810444575485

Epoch: 5| Step: 3
Training loss: 2.009827136993408
Validation loss: 2.0292923501742783

Epoch: 5| Step: 4
Training loss: 1.1971492767333984
Validation loss: 1.9451117182290683

Epoch: 5| Step: 5
Training loss: 1.7279155254364014
Validation loss: 2.007579093338341

Epoch: 5| Step: 6
Training loss: 1.2991993427276611
Validation loss: 1.9697195329973776

Epoch: 5| Step: 7
Training loss: 1.881890058517456
Validation loss: 1.9406927529201712

Epoch: 5| Step: 8
Training loss: 1.6370916366577148
Validation loss: 1.9478142825506066

Epoch: 5| Step: 9
Training loss: 1.8389832973480225
Validation loss: 2.004968591915664

Epoch: 5| Step: 10
Training loss: 2.106200933456421
Validation loss: 1.9433257772076515

Epoch: 272| Step: 0
Training loss: 1.4124672412872314
Validation loss: 1.9943433166832052

Epoch: 5| Step: 1
Training loss: 2.2026524543762207
Validation loss: 1.974710141458819

Epoch: 5| Step: 2
Training loss: 1.7427278757095337
Validation loss: 1.9772564518836238

Epoch: 5| Step: 3
Training loss: 1.4970149993896484
Validation loss: 1.9338818468073362

Epoch: 5| Step: 4
Training loss: 1.6401469707489014
Validation loss: 1.952117702012421

Epoch: 5| Step: 5
Training loss: 1.6877663135528564
Validation loss: 1.9936173974826772

Epoch: 5| Step: 6
Training loss: 2.2064692974090576
Validation loss: 1.9657564240117227

Epoch: 5| Step: 7
Training loss: 1.0391128063201904
Validation loss: 1.9680949308538949

Epoch: 5| Step: 8
Training loss: 1.508193016052246
Validation loss: 1.9460917442075667

Epoch: 5| Step: 9
Training loss: 1.9441436529159546
Validation loss: 1.9689530390565113

Epoch: 5| Step: 10
Training loss: 1.7832704782485962
Validation loss: 2.0143634068068637

Epoch: 273| Step: 0
Training loss: 1.280740737915039
Validation loss: 1.9858951325057654

Epoch: 5| Step: 1
Training loss: 1.8118464946746826
Validation loss: 1.9560691066967544

Epoch: 5| Step: 2
Training loss: 1.3691291809082031
Validation loss: 1.9851256288507932

Epoch: 5| Step: 3
Training loss: 1.8830718994140625
Validation loss: 1.962262838117538

Epoch: 5| Step: 4
Training loss: 1.8607885837554932
Validation loss: 2.020766729949623

Epoch: 5| Step: 5
Training loss: 1.544722318649292
Validation loss: 1.9473246861529607

Epoch: 5| Step: 6
Training loss: 2.3171727657318115
Validation loss: 1.9556428540137507

Epoch: 5| Step: 7
Training loss: 1.5471036434173584
Validation loss: 2.0383224077122186

Epoch: 5| Step: 8
Training loss: 1.6877902746200562
Validation loss: 1.9549149902918006

Epoch: 5| Step: 9
Training loss: 1.551043152809143
Validation loss: 1.9662139056831278

Epoch: 5| Step: 10
Training loss: 1.5320518016815186
Validation loss: 2.040700718279808

Epoch: 274| Step: 0
Training loss: 1.7340259552001953
Validation loss: 1.9723213898238314

Epoch: 5| Step: 1
Training loss: 1.2131494283676147
Validation loss: 2.017715843774939

Epoch: 5| Step: 2
Training loss: 1.982946753501892
Validation loss: 2.037648923935429

Epoch: 5| Step: 3
Training loss: 1.4200788736343384
Validation loss: 1.9614085023121168

Epoch: 5| Step: 4
Training loss: 1.807321548461914
Validation loss: 1.9659573929284209

Epoch: 5| Step: 5
Training loss: 1.6549476385116577
Validation loss: 2.014176699423021

Epoch: 5| Step: 6
Training loss: 2.111778736114502
Validation loss: 2.008544296346685

Epoch: 5| Step: 7
Training loss: 2.0742976665496826
Validation loss: 1.9809168410557572

Epoch: 5| Step: 8
Training loss: 1.1048214435577393
Validation loss: 1.9906692517701017

Epoch: 5| Step: 9
Training loss: 1.6106199026107788
Validation loss: 1.9955701315274803

Epoch: 5| Step: 10
Training loss: 1.5558823347091675
Validation loss: 1.9411340067463536

Epoch: 275| Step: 0
Training loss: 1.2300021648406982
Validation loss: 1.9458186229070027

Epoch: 5| Step: 1
Training loss: 1.2059352397918701
Validation loss: 1.9392854962297665

Epoch: 5| Step: 2
Training loss: 1.7284924983978271
Validation loss: 1.9606303399608982

Epoch: 5| Step: 3
Training loss: 2.43464994430542
Validation loss: 1.9622769227591894

Epoch: 5| Step: 4
Training loss: 1.4691190719604492
Validation loss: 1.9317673560111754

Epoch: 5| Step: 5
Training loss: 2.019510269165039
Validation loss: 1.9371399469273065

Epoch: 5| Step: 6
Training loss: 1.6558630466461182
Validation loss: 1.9392215615959578

Epoch: 5| Step: 7
Training loss: 1.3508213758468628
Validation loss: 2.0016987093033327

Epoch: 5| Step: 8
Training loss: 1.9748626947402954
Validation loss: 2.0322432979460685

Epoch: 5| Step: 9
Training loss: 1.2800124883651733
Validation loss: 1.9879493918470157

Epoch: 5| Step: 10
Training loss: 2.3995416164398193
Validation loss: 1.99699773967907

Epoch: 276| Step: 0
Training loss: 1.5410900115966797
Validation loss: 1.9928549835758824

Epoch: 5| Step: 1
Training loss: 1.9154589176177979
Validation loss: 1.990795015006937

Epoch: 5| Step: 2
Training loss: 2.1910979747772217
Validation loss: 2.0127239124749297

Epoch: 5| Step: 3
Training loss: 1.6895291805267334
Validation loss: 1.9876904846519552

Epoch: 5| Step: 4
Training loss: 2.0385899543762207
Validation loss: 1.9812933360376666

Epoch: 5| Step: 5
Training loss: 1.5025848150253296
Validation loss: 1.9860549793448499

Epoch: 5| Step: 6
Training loss: 1.3280292749404907
Validation loss: 2.0124779747378443

Epoch: 5| Step: 7
Training loss: 1.6011863946914673
Validation loss: 1.9762674326537757

Epoch: 5| Step: 8
Training loss: 1.5377050638198853
Validation loss: 1.995807659241461

Epoch: 5| Step: 9
Training loss: 1.549454927444458
Validation loss: 2.0094276064185688

Epoch: 5| Step: 10
Training loss: 1.6590656042099
Validation loss: 1.9635270859605523

Epoch: 277| Step: 0
Training loss: 1.367848515510559
Validation loss: 2.0009541075716735

Epoch: 5| Step: 1
Training loss: 1.8116174936294556
Validation loss: 1.995904363611693

Epoch: 5| Step: 2
Training loss: 1.9344074726104736
Validation loss: 1.9601395796704035

Epoch: 5| Step: 3
Training loss: 1.6850671768188477
Validation loss: 1.965676421760231

Epoch: 5| Step: 4
Training loss: 2.0499496459960938
Validation loss: 2.0195130763515348

Epoch: 5| Step: 5
Training loss: 1.36203932762146
Validation loss: 1.9411223037268526

Epoch: 5| Step: 6
Training loss: 1.693671464920044
Validation loss: 1.9105533989526893

Epoch: 5| Step: 7
Training loss: 1.3831924200057983
Validation loss: 1.9561852883267146

Epoch: 5| Step: 8
Training loss: 1.6199901103973389
Validation loss: 1.9313056520236436

Epoch: 5| Step: 9
Training loss: 1.6072635650634766
Validation loss: 1.9625247114448137

Epoch: 5| Step: 10
Training loss: 1.918965458869934
Validation loss: 1.988247698353183

Epoch: 278| Step: 0
Training loss: 1.27419114112854
Validation loss: 2.0015719321466263

Epoch: 5| Step: 1
Training loss: 1.656663179397583
Validation loss: 1.9703231293668029

Epoch: 5| Step: 2
Training loss: 1.5381741523742676
Validation loss: 1.9497054276927825

Epoch: 5| Step: 3
Training loss: 1.8937908411026
Validation loss: 1.9925059028851089

Epoch: 5| Step: 4
Training loss: 2.2091362476348877
Validation loss: 1.9527738542966946

Epoch: 5| Step: 5
Training loss: 2.0272209644317627
Validation loss: 1.9807628534173454

Epoch: 5| Step: 6
Training loss: 1.4696508646011353
Validation loss: 1.9255249243910595

Epoch: 5| Step: 7
Training loss: 2.00447678565979
Validation loss: 1.9375042620525564

Epoch: 5| Step: 8
Training loss: 1.5154693126678467
Validation loss: 2.0331154433629846

Epoch: 5| Step: 9
Training loss: 0.9695218205451965
Validation loss: 1.9460896458677066

Epoch: 5| Step: 10
Training loss: 1.518905520439148
Validation loss: 1.9668490015050417

Epoch: 279| Step: 0
Training loss: 1.8437778949737549
Validation loss: 1.9754280954278924

Epoch: 5| Step: 1
Training loss: 2.1399788856506348
Validation loss: 1.951963714374009

Epoch: 5| Step: 2
Training loss: 1.508501648902893
Validation loss: 1.9203555378862607

Epoch: 5| Step: 3
Training loss: 1.5556305646896362
Validation loss: 1.9930222675364504

Epoch: 5| Step: 4
Training loss: 1.6800695657730103
Validation loss: 1.9455655672216927

Epoch: 5| Step: 5
Training loss: 1.294697880744934
Validation loss: 1.934843018490781

Epoch: 5| Step: 6
Training loss: 1.9398720264434814
Validation loss: 1.9237761292406308

Epoch: 5| Step: 7
Training loss: 1.5075852870941162
Validation loss: 1.922971151208365

Epoch: 5| Step: 8
Training loss: 1.626570463180542
Validation loss: 1.9559869702144335

Epoch: 5| Step: 9
Training loss: 1.5637634992599487
Validation loss: 1.9921551135278517

Epoch: 5| Step: 10
Training loss: 1.3888812065124512
Validation loss: 1.91274122781651

Epoch: 280| Step: 0
Training loss: 1.702946424484253
Validation loss: 1.9244328967986568

Epoch: 5| Step: 1
Training loss: 1.5648797750473022
Validation loss: 1.9797773591933712

Epoch: 5| Step: 2
Training loss: 1.516520380973816
Validation loss: 1.9579068396681099

Epoch: 5| Step: 3
Training loss: 1.4639005661010742
Validation loss: 1.9408998566289102

Epoch: 5| Step: 4
Training loss: 1.6506471633911133
Validation loss: 2.008663155699289

Epoch: 5| Step: 5
Training loss: 1.383654236793518
Validation loss: 1.904672149688967

Epoch: 5| Step: 6
Training loss: 1.6270357370376587
Validation loss: 1.9441147440223283

Epoch: 5| Step: 7
Training loss: 1.9764829874038696
Validation loss: 2.020961570483382

Epoch: 5| Step: 8
Training loss: 2.0387027263641357
Validation loss: 1.9735401958547614

Epoch: 5| Step: 9
Training loss: 1.3704912662506104
Validation loss: 1.97770817049088

Epoch: 5| Step: 10
Training loss: 1.805550456047058
Validation loss: 1.9396261861247401

Epoch: 281| Step: 0
Training loss: 1.1907542943954468
Validation loss: 2.0054471287676083

Epoch: 5| Step: 1
Training loss: 1.1583349704742432
Validation loss: 1.9495674269173735

Epoch: 5| Step: 2
Training loss: 1.4176981449127197
Validation loss: 1.9403366081176265

Epoch: 5| Step: 3
Training loss: 1.9043858051300049
Validation loss: 2.0035386008601033

Epoch: 5| Step: 4
Training loss: 2.6733429431915283
Validation loss: 1.957629483233216

Epoch: 5| Step: 5
Training loss: 1.2740886211395264
Validation loss: 1.9486646780403711

Epoch: 5| Step: 6
Training loss: 2.0940191745758057
Validation loss: 1.9374963903939852

Epoch: 5| Step: 7
Training loss: 1.0805728435516357
Validation loss: 1.9414339386006838

Epoch: 5| Step: 8
Training loss: 1.8545929193496704
Validation loss: 1.954009218882489

Epoch: 5| Step: 9
Training loss: 2.000321865081787
Validation loss: 1.9428350169171569

Epoch: 5| Step: 10
Training loss: 1.4474711418151855
Validation loss: 1.9004918529141335

Epoch: 282| Step: 0
Training loss: 2.017533302307129
Validation loss: 1.9557177482112762

Epoch: 5| Step: 1
Training loss: 1.0702831745147705
Validation loss: 1.9116948214910363

Epoch: 5| Step: 2
Training loss: 1.6691277027130127
Validation loss: 1.9860293416566746

Epoch: 5| Step: 3
Training loss: 1.5170650482177734
Validation loss: 1.9351972687628962

Epoch: 5| Step: 4
Training loss: 1.2997291088104248
Validation loss: 1.9552486827296596

Epoch: 5| Step: 5
Training loss: 1.447609543800354
Validation loss: 1.9269099953354045

Epoch: 5| Step: 6
Training loss: 1.5617724657058716
Validation loss: 1.918072073690353

Epoch: 5| Step: 7
Training loss: 2.226430654525757
Validation loss: 1.8949174509253552

Epoch: 5| Step: 8
Training loss: 1.6087127923965454
Validation loss: 1.9573185161877704

Epoch: 5| Step: 9
Training loss: 1.7820103168487549
Validation loss: 2.011074222544188

Epoch: 5| Step: 10
Training loss: 1.9727071523666382
Validation loss: 1.9062739995218092

Epoch: 283| Step: 0
Training loss: 1.6535561084747314
Validation loss: 2.0031321510191886

Epoch: 5| Step: 1
Training loss: 1.4156014919281006
Validation loss: 1.9529686717576877

Epoch: 5| Step: 2
Training loss: 1.423228144645691
Validation loss: 1.9934117050581082

Epoch: 5| Step: 3
Training loss: 1.83676016330719
Validation loss: 2.0126445754881828

Epoch: 5| Step: 4
Training loss: 1.7719157934188843
Validation loss: 1.9634803854009157

Epoch: 5| Step: 5
Training loss: 1.9868987798690796
Validation loss: 2.0337392155842116

Epoch: 5| Step: 6
Training loss: 1.6278927326202393
Validation loss: 1.9872231188640799

Epoch: 5| Step: 7
Training loss: 1.4836324453353882
Validation loss: 2.016178584867908

Epoch: 5| Step: 8
Training loss: 1.3914953470230103
Validation loss: 1.9721762236728464

Epoch: 5| Step: 9
Training loss: 1.9357478618621826
Validation loss: 2.0082155043079006

Epoch: 5| Step: 10
Training loss: 1.6037901639938354
Validation loss: 1.9930904834501204

Epoch: 284| Step: 0
Training loss: 1.287369966506958
Validation loss: 1.9855184772963166

Epoch: 5| Step: 1
Training loss: 2.018683910369873
Validation loss: 2.038247157168645

Epoch: 5| Step: 2
Training loss: 1.8374578952789307
Validation loss: 1.9869724242917952

Epoch: 5| Step: 3
Training loss: 1.5781303644180298
Validation loss: 2.0044619755078386

Epoch: 5| Step: 4
Training loss: 1.0175511837005615
Validation loss: 1.9780377008581673

Epoch: 5| Step: 5
Training loss: 1.5030094385147095
Validation loss: 1.9581447724373109

Epoch: 5| Step: 6
Training loss: 2.0640134811401367
Validation loss: 1.947226675607825

Epoch: 5| Step: 7
Training loss: 1.7774244546890259
Validation loss: 1.9520349848654963

Epoch: 5| Step: 8
Training loss: 1.3722809553146362
Validation loss: 1.9207015447719122

Epoch: 5| Step: 9
Training loss: 1.815239667892456
Validation loss: 1.9095203081766765

Epoch: 5| Step: 10
Training loss: 1.6421794891357422
Validation loss: 1.9969950388836604

Epoch: 285| Step: 0
Training loss: 1.6874459981918335
Validation loss: 1.961932050284519

Epoch: 5| Step: 1
Training loss: 1.311187744140625
Validation loss: 1.9527344178127986

Epoch: 5| Step: 2
Training loss: 2.2015323638916016
Validation loss: 1.9189712616705126

Epoch: 5| Step: 3
Training loss: 1.9900217056274414
Validation loss: 1.9734086580173944

Epoch: 5| Step: 4
Training loss: 1.1623073816299438
Validation loss: 1.9601570995905067

Epoch: 5| Step: 5
Training loss: 0.7271625995635986
Validation loss: 1.881597972685291

Epoch: 5| Step: 6
Training loss: 1.6854454278945923
Validation loss: 2.057217367233769

Epoch: 5| Step: 7
Training loss: 1.499526023864746
Validation loss: 1.962490309951126

Epoch: 5| Step: 8
Training loss: 1.9533443450927734
Validation loss: 1.932380937760876

Epoch: 5| Step: 9
Training loss: 1.8188470602035522
Validation loss: 1.9464140335718791

Epoch: 5| Step: 10
Training loss: 1.7021163702011108
Validation loss: 1.9847402072721911

Epoch: 286| Step: 0
Training loss: 1.4917186498641968
Validation loss: 1.9443325073488298

Epoch: 5| Step: 1
Training loss: 1.0351903438568115
Validation loss: 1.946491414500821

Epoch: 5| Step: 2
Training loss: 1.80497145652771
Validation loss: 1.933449870796614

Epoch: 5| Step: 3
Training loss: 2.2309908866882324
Validation loss: 1.9222516923822381

Epoch: 5| Step: 4
Training loss: 1.3408355712890625
Validation loss: 1.9267585931285736

Epoch: 5| Step: 5
Training loss: 2.328131675720215
Validation loss: 1.9481434104263142

Epoch: 5| Step: 6
Training loss: 1.7084038257598877
Validation loss: 1.9704583370557396

Epoch: 5| Step: 7
Training loss: 1.130568504333496
Validation loss: 1.95267669616207

Epoch: 5| Step: 8
Training loss: 1.5087432861328125
Validation loss: 1.9684440282083326

Epoch: 5| Step: 9
Training loss: 1.1644644737243652
Validation loss: 1.9368151990316247

Epoch: 5| Step: 10
Training loss: 1.9115699529647827
Validation loss: 1.966715035899993

Epoch: 287| Step: 0
Training loss: 1.499873399734497
Validation loss: 1.9750246591465448

Epoch: 5| Step: 1
Training loss: 1.22265625
Validation loss: 2.0135822526870237

Epoch: 5| Step: 2
Training loss: 1.4333840608596802
Validation loss: 1.9624781506035918

Epoch: 5| Step: 3
Training loss: 1.537108063697815
Validation loss: 1.9536785259041736

Epoch: 5| Step: 4
Training loss: 1.1597263813018799
Validation loss: 1.9968847484998806

Epoch: 5| Step: 5
Training loss: 2.0464587211608887
Validation loss: 2.0339880451079337

Epoch: 5| Step: 6
Training loss: 1.964251160621643
Validation loss: 1.98970288871437

Epoch: 5| Step: 7
Training loss: 1.5869060754776
Validation loss: 2.035290345068901

Epoch: 5| Step: 8
Training loss: 1.5391192436218262
Validation loss: 1.9731918073469592

Epoch: 5| Step: 9
Training loss: 2.6565937995910645
Validation loss: 1.9634667545236566

Epoch: 5| Step: 10
Training loss: 1.2241911888122559
Validation loss: 1.9867311164896975

Epoch: 288| Step: 0
Training loss: 1.7469419240951538
Validation loss: 1.9973448604665778

Epoch: 5| Step: 1
Training loss: 1.320941686630249
Validation loss: 2.0094703294897593

Epoch: 5| Step: 2
Training loss: 1.1141239404678345
Validation loss: 1.938863936290946

Epoch: 5| Step: 3
Training loss: 2.014256000518799
Validation loss: 1.9751489623900382

Epoch: 5| Step: 4
Training loss: 1.563571572303772
Validation loss: 1.9721690083062777

Epoch: 5| Step: 5
Training loss: 1.5431865453720093
Validation loss: 1.9469534504798152

Epoch: 5| Step: 6
Training loss: 1.9500213861465454
Validation loss: 1.9753047189404886

Epoch: 5| Step: 7
Training loss: 1.63330078125
Validation loss: 1.9538959944120018

Epoch: 5| Step: 8
Training loss: 1.5572551488876343
Validation loss: 1.9488715702487576

Epoch: 5| Step: 9
Training loss: 1.4489730596542358
Validation loss: 1.9638365417398431

Epoch: 5| Step: 10
Training loss: 1.9503285884857178
Validation loss: 1.9500364629171227

Epoch: 289| Step: 0
Training loss: 1.341718077659607
Validation loss: 1.9802437456705237

Epoch: 5| Step: 1
Training loss: 2.1086106300354004
Validation loss: 1.9676261948001

Epoch: 5| Step: 2
Training loss: 1.3281781673431396
Validation loss: 2.012783727338237

Epoch: 5| Step: 3
Training loss: 1.7377961874008179
Validation loss: 1.96119600213984

Epoch: 5| Step: 4
Training loss: 1.6994434595108032
Validation loss: 1.9521399082676056

Epoch: 5| Step: 5
Training loss: 1.883301019668579
Validation loss: 1.9755134031336794

Epoch: 5| Step: 6
Training loss: 1.856205701828003
Validation loss: 1.9947456403445172

Epoch: 5| Step: 7
Training loss: 1.6469961404800415
Validation loss: 1.9727732109767135

Epoch: 5| Step: 8
Training loss: 1.0256805419921875
Validation loss: 1.955849975667974

Epoch: 5| Step: 9
Training loss: 1.3694195747375488
Validation loss: 1.9038551071638703

Epoch: 5| Step: 10
Training loss: 1.5126914978027344
Validation loss: 1.9134331287876252

Epoch: 290| Step: 0
Training loss: 1.064894437789917
Validation loss: 1.9244018062468498

Epoch: 5| Step: 1
Training loss: 1.3140846490859985
Validation loss: 1.9562039977760726

Epoch: 5| Step: 2
Training loss: 2.3254685401916504
Validation loss: 1.9264950585621659

Epoch: 5| Step: 3
Training loss: 1.7461726665496826
Validation loss: 1.9821109412818827

Epoch: 5| Step: 4
Training loss: 1.27345871925354
Validation loss: 1.9768062676152875

Epoch: 5| Step: 5
Training loss: 1.2829158306121826
Validation loss: 2.0030112381904357

Epoch: 5| Step: 6
Training loss: 1.9119771718978882
Validation loss: 1.9450204128860145

Epoch: 5| Step: 7
Training loss: 1.4741843938827515
Validation loss: 1.9575372178067443

Epoch: 5| Step: 8
Training loss: 1.9437309503555298
Validation loss: 1.944975870911793

Epoch: 5| Step: 9
Training loss: 2.2077317237854004
Validation loss: 1.9506120733035508

Epoch: 5| Step: 10
Training loss: 1.5260021686553955
Validation loss: 1.924145995929677

Epoch: 291| Step: 0
Training loss: 2.3771960735321045
Validation loss: 1.942577322324117

Epoch: 5| Step: 1
Training loss: 1.6121842861175537
Validation loss: 1.9727582111153552

Epoch: 5| Step: 2
Training loss: 1.2911956310272217
Validation loss: 1.9242662640028103

Epoch: 5| Step: 3
Training loss: 1.2292786836624146
Validation loss: 1.9670832054589384

Epoch: 5| Step: 4
Training loss: 1.6185859441757202
Validation loss: 1.9544993664628716

Epoch: 5| Step: 5
Training loss: 1.1789467334747314
Validation loss: 1.9366380796637586

Epoch: 5| Step: 6
Training loss: 1.4783718585968018
Validation loss: 1.9680314487026584

Epoch: 5| Step: 7
Training loss: 1.492371916770935
Validation loss: 1.9812048840266403

Epoch: 5| Step: 8
Training loss: 1.849582314491272
Validation loss: 1.9820278036978938

Epoch: 5| Step: 9
Training loss: 1.5188162326812744
Validation loss: 1.9722481837836645

Epoch: 5| Step: 10
Training loss: 2.1787290573120117
Validation loss: 1.9438195843850412

Epoch: 292| Step: 0
Training loss: 1.670279860496521
Validation loss: 1.960986170717465

Epoch: 5| Step: 1
Training loss: 1.1097900867462158
Validation loss: 1.9413874098049697

Epoch: 5| Step: 2
Training loss: 1.687983512878418
Validation loss: 1.945124235204471

Epoch: 5| Step: 3
Training loss: 1.5913479328155518
Validation loss: 1.9959864013938493

Epoch: 5| Step: 4
Training loss: 1.2649582624435425
Validation loss: 1.9934558278770858

Epoch: 5| Step: 5
Training loss: 1.7483007907867432
Validation loss: 1.9681588090876097

Epoch: 5| Step: 6
Training loss: 1.597393274307251
Validation loss: 2.00105615328717

Epoch: 5| Step: 7
Training loss: 1.8451000452041626
Validation loss: 1.9472491356634325

Epoch: 5| Step: 8
Training loss: 1.8444576263427734
Validation loss: 1.9869228973183581

Epoch: 5| Step: 9
Training loss: 1.9264968633651733
Validation loss: 2.0186846717711417

Epoch: 5| Step: 10
Training loss: 1.7296795845031738
Validation loss: 1.9606790593875352

Epoch: 293| Step: 0
Training loss: 2.296935558319092
Validation loss: 1.9606945463406142

Epoch: 5| Step: 1
Training loss: 1.1826450824737549
Validation loss: 1.9688188183692195

Epoch: 5| Step: 2
Training loss: 1.228495717048645
Validation loss: 1.9215839268058859

Epoch: 5| Step: 3
Training loss: 1.8917572498321533
Validation loss: 1.975270563556302

Epoch: 5| Step: 4
Training loss: 1.045628547668457
Validation loss: 1.927851064230806

Epoch: 5| Step: 5
Training loss: 1.7710838317871094
Validation loss: 1.9408957701857372

Epoch: 5| Step: 6
Training loss: 1.794000267982483
Validation loss: 2.03362875856379

Epoch: 5| Step: 7
Training loss: 1.3508524894714355
Validation loss: 1.9380464989651915

Epoch: 5| Step: 8
Training loss: 1.8905197381973267
Validation loss: 1.9961863333179104

Epoch: 5| Step: 9
Training loss: 1.6072683334350586
Validation loss: 1.9777257878293273

Epoch: 5| Step: 10
Training loss: 1.569351315498352
Validation loss: 2.012985799902229

Epoch: 294| Step: 0
Training loss: 1.4120250940322876
Validation loss: 1.9629492144430838

Epoch: 5| Step: 1
Training loss: 1.2807267904281616
Validation loss: 1.9559742866023895

Epoch: 5| Step: 2
Training loss: 1.7717349529266357
Validation loss: 1.936578199427615

Epoch: 5| Step: 3
Training loss: 1.5644519329071045
Validation loss: 1.9361643778380526

Epoch: 5| Step: 4
Training loss: 2.043994426727295
Validation loss: 1.9694914279445526

Epoch: 5| Step: 5
Training loss: 1.383603811264038
Validation loss: 1.9487598788353704

Epoch: 5| Step: 6
Training loss: 1.464890480041504
Validation loss: 1.950898947254304

Epoch: 5| Step: 7
Training loss: 2.1521360874176025
Validation loss: 1.9672857997237996

Epoch: 5| Step: 8
Training loss: 1.8174289464950562
Validation loss: 2.007892563778867

Epoch: 5| Step: 9
Training loss: 1.7350009679794312
Validation loss: 1.9395174262344197

Epoch: 5| Step: 10
Training loss: 0.8746285438537598
Validation loss: 1.9472121833473124

Epoch: 295| Step: 0
Training loss: 1.6059004068374634
Validation loss: 1.9243174291426135

Epoch: 5| Step: 1
Training loss: 2.298060894012451
Validation loss: 1.974996066862537

Epoch: 5| Step: 2
Training loss: 1.9897648096084595
Validation loss: 1.9769453502470447

Epoch: 5| Step: 3
Training loss: 1.5844614505767822
Validation loss: 2.011127728287892

Epoch: 5| Step: 4
Training loss: 1.1912083625793457
Validation loss: 1.9649450471324306

Epoch: 5| Step: 5
Training loss: 1.3003056049346924
Validation loss: 2.0465147700361026

Epoch: 5| Step: 6
Training loss: 1.5092946290969849
Validation loss: 1.9685788385329708

Epoch: 5| Step: 7
Training loss: 1.6545836925506592
Validation loss: 1.9634238289248558

Epoch: 5| Step: 8
Training loss: 1.3258990049362183
Validation loss: 1.9699176447365874

Epoch: 5| Step: 9
Training loss: 1.5823394060134888
Validation loss: 1.930544073863696

Epoch: 5| Step: 10
Training loss: 1.614330530166626
Validation loss: 1.9692646534212175

Epoch: 296| Step: 0
Training loss: 1.4375642538070679
Validation loss: 1.956523553017647

Epoch: 5| Step: 1
Training loss: 1.40847647190094
Validation loss: 1.9625232129968622

Epoch: 5| Step: 2
Training loss: 1.9253383874893188
Validation loss: 1.9379876570035053

Epoch: 5| Step: 3
Training loss: 2.1200027465820312
Validation loss: 1.9597904835977862

Epoch: 5| Step: 4
Training loss: 1.8351974487304688
Validation loss: 1.9316793616100023

Epoch: 5| Step: 5
Training loss: 1.4393885135650635
Validation loss: 2.000233224643174

Epoch: 5| Step: 6
Training loss: 1.3885505199432373
Validation loss: 1.9862357403642388

Epoch: 5| Step: 7
Training loss: 1.194835901260376
Validation loss: 1.934423928619713

Epoch: 5| Step: 8
Training loss: 2.245976448059082
Validation loss: 2.00163407223199

Epoch: 5| Step: 9
Training loss: 1.3642851114273071
Validation loss: 1.9458011798961188

Epoch: 5| Step: 10
Training loss: 1.4253824949264526
Validation loss: 1.9352833917064052

Epoch: 297| Step: 0
Training loss: 1.1317752599716187
Validation loss: 2.013362196183974

Epoch: 5| Step: 1
Training loss: 1.2517322301864624
Validation loss: 1.939663790887402

Epoch: 5| Step: 2
Training loss: 2.25956392288208
Validation loss: 1.901257025298252

Epoch: 5| Step: 3
Training loss: 1.5671024322509766
Validation loss: 1.9146383141958585

Epoch: 5| Step: 4
Training loss: 1.9174522161483765
Validation loss: 1.9782674697137648

Epoch: 5| Step: 5
Training loss: 1.7680575847625732
Validation loss: 2.003297536603866

Epoch: 5| Step: 6
Training loss: 1.131954312324524
Validation loss: 1.9886520575451594

Epoch: 5| Step: 7
Training loss: 1.6327139139175415
Validation loss: 1.9988520222325479

Epoch: 5| Step: 8
Training loss: 1.3718111515045166
Validation loss: 1.9580366265389226

Epoch: 5| Step: 9
Training loss: 1.4498742818832397
Validation loss: 1.919289755564864

Epoch: 5| Step: 10
Training loss: 1.7320805788040161
Validation loss: 1.9784080008024811

Epoch: 298| Step: 0
Training loss: 1.7798292636871338
Validation loss: 1.9299690556782547

Epoch: 5| Step: 1
Training loss: 1.714086890220642
Validation loss: 2.0079445044199624

Epoch: 5| Step: 2
Training loss: 1.4862340688705444
Validation loss: 2.0221561257557203

Epoch: 5| Step: 3
Training loss: 1.8989732265472412
Validation loss: 1.907397945721944

Epoch: 5| Step: 4
Training loss: 1.8257017135620117
Validation loss: 1.9138542106074672

Epoch: 5| Step: 5
Training loss: 1.164806604385376
Validation loss: 1.9582805248998827

Epoch: 5| Step: 6
Training loss: 1.4172163009643555
Validation loss: 1.946985972824917

Epoch: 5| Step: 7
Training loss: 2.3068459033966064
Validation loss: 1.9557700080256308

Epoch: 5| Step: 8
Training loss: 1.4514819383621216
Validation loss: 1.9733443978012248

Epoch: 5| Step: 9
Training loss: 1.2031818628311157
Validation loss: 1.9618114066380326

Epoch: 5| Step: 10
Training loss: 1.1787699460983276
Validation loss: 1.9676561996500979

Epoch: 299| Step: 0
Training loss: 1.6246843338012695
Validation loss: 1.9847977494680753

Epoch: 5| Step: 1
Training loss: 1.5677753686904907
Validation loss: 2.0310902582701815

Epoch: 5| Step: 2
Training loss: 1.3520848751068115
Validation loss: 1.9501870460407709

Epoch: 5| Step: 3
Training loss: 1.746363639831543
Validation loss: 1.9356904440028693

Epoch: 5| Step: 4
Training loss: 1.962578535079956
Validation loss: 2.0176178255388812

Epoch: 5| Step: 5
Training loss: 1.38089919090271
Validation loss: 2.0390673298989572

Epoch: 5| Step: 6
Training loss: 1.7733062505722046
Validation loss: 1.9640342522692937

Epoch: 5| Step: 7
Training loss: 0.9192554354667664
Validation loss: 1.9056310499868085

Epoch: 5| Step: 8
Training loss: 1.2959966659545898
Validation loss: 1.9502625055210565

Epoch: 5| Step: 9
Training loss: 1.9679511785507202
Validation loss: 1.9522181044342697

Epoch: 5| Step: 10
Training loss: 1.6625077724456787
Validation loss: 1.9848094883785452

Epoch: 300| Step: 0
Training loss: 2.01353120803833
Validation loss: 1.9933640392877723

Epoch: 5| Step: 1
Training loss: 2.0064377784729004
Validation loss: 1.9420796722494147

Epoch: 5| Step: 2
Training loss: 1.5211039781570435
Validation loss: 1.9430701168634559

Epoch: 5| Step: 3
Training loss: 1.3602802753448486
Validation loss: 1.9378631999415736

Epoch: 5| Step: 4
Training loss: 1.6968873739242554
Validation loss: 1.98836197135269

Epoch: 5| Step: 5
Training loss: 1.3305532932281494
Validation loss: 1.9425903071639359

Epoch: 5| Step: 6
Training loss: 0.8945237994194031
Validation loss: 1.9793761378975325

Epoch: 5| Step: 7
Training loss: 1.1123945713043213
Validation loss: 1.98677703385712

Epoch: 5| Step: 8
Training loss: 2.1263413429260254
Validation loss: 1.9429327031617523

Epoch: 5| Step: 9
Training loss: 2.056818723678589
Validation loss: 1.9456396846361057

Epoch: 5| Step: 10
Training loss: 1.4971486330032349
Validation loss: 1.9127556970042567

Epoch: 301| Step: 0
Training loss: 1.3872110843658447
Validation loss: 1.9451186605679092

Epoch: 5| Step: 1
Training loss: 2.138275623321533
Validation loss: 1.911303427911574

Epoch: 5| Step: 2
Training loss: 1.3147286176681519
Validation loss: 1.9317840581299157

Epoch: 5| Step: 3
Training loss: 1.4575961828231812
Validation loss: 1.8962985315630514

Epoch: 5| Step: 4
Training loss: 1.8678033351898193
Validation loss: 1.9132399584657402

Epoch: 5| Step: 5
Training loss: 1.1986877918243408
Validation loss: 1.9543852601000058

Epoch: 5| Step: 6
Training loss: 1.470228910446167
Validation loss: 1.9057534356271066

Epoch: 5| Step: 7
Training loss: 1.4909852743148804
Validation loss: 1.8896175174302952

Epoch: 5| Step: 8
Training loss: 1.6887508630752563
Validation loss: 1.9088963821370115

Epoch: 5| Step: 9
Training loss: 1.639325737953186
Validation loss: 1.930298710382113

Epoch: 5| Step: 10
Training loss: 2.051466464996338
Validation loss: 1.9223493863177556

Epoch: 302| Step: 0
Training loss: 1.1226413249969482
Validation loss: 1.9642664873471825

Epoch: 5| Step: 1
Training loss: 1.47296941280365
Validation loss: 1.9596117004271476

Epoch: 5| Step: 2
Training loss: 2.404052734375
Validation loss: 1.9219722542711484

Epoch: 5| Step: 3
Training loss: 1.9718650579452515
Validation loss: 1.9695634559918476

Epoch: 5| Step: 4
Training loss: 1.225267767906189
Validation loss: 1.96317107190368

Epoch: 5| Step: 5
Training loss: 1.287804126739502
Validation loss: 1.9346001699406614

Epoch: 5| Step: 6
Training loss: 1.9672482013702393
Validation loss: 1.9054764611746675

Epoch: 5| Step: 7
Training loss: 1.3544647693634033
Validation loss: 1.9141285932192238

Epoch: 5| Step: 8
Training loss: 1.4534260034561157
Validation loss: 1.9428508038161902

Epoch: 5| Step: 9
Training loss: 1.412663221359253
Validation loss: 1.9472887798022198

Epoch: 5| Step: 10
Training loss: 1.4733614921569824
Validation loss: 1.9477870195142684

Epoch: 303| Step: 0
Training loss: 1.094979166984558
Validation loss: 1.9056577297949022

Epoch: 5| Step: 1
Training loss: 1.7782256603240967
Validation loss: 1.9668568180453392

Epoch: 5| Step: 2
Training loss: 1.4917995929718018
Validation loss: 1.9560034249418525

Epoch: 5| Step: 3
Training loss: 1.664859414100647
Validation loss: 1.9189873651791645

Epoch: 5| Step: 4
Training loss: 1.9391040802001953
Validation loss: 1.8840672649363035

Epoch: 5| Step: 5
Training loss: 2.107052803039551
Validation loss: 1.9137321261949436

Epoch: 5| Step: 6
Training loss: 1.5246835947036743
Validation loss: 1.9990452028089953

Epoch: 5| Step: 7
Training loss: 1.5647467374801636
Validation loss: 1.9289393719806467

Epoch: 5| Step: 8
Training loss: 1.4585435390472412
Validation loss: 1.9332018436924103

Epoch: 5| Step: 9
Training loss: 1.2527401447296143
Validation loss: 1.9588253344258955

Epoch: 5| Step: 10
Training loss: 1.7147032022476196
Validation loss: 1.947087218684535

Epoch: 304| Step: 0
Training loss: 1.7317463159561157
Validation loss: 1.9777641898842269

Epoch: 5| Step: 1
Training loss: 1.7330920696258545
Validation loss: 1.9260879690929125

Epoch: 5| Step: 2
Training loss: 1.778586983680725
Validation loss: 1.9765682874187347

Epoch: 5| Step: 3
Training loss: 1.7574936151504517
Validation loss: 1.9524284203847249

Epoch: 5| Step: 4
Training loss: 1.2420305013656616
Validation loss: 1.9523771206537883

Epoch: 5| Step: 5
Training loss: 1.4173095226287842
Validation loss: 1.949884424927414

Epoch: 5| Step: 6
Training loss: 1.5458790063858032
Validation loss: 1.9548426648621917

Epoch: 5| Step: 7
Training loss: 1.3844444751739502
Validation loss: 1.9206244868616904

Epoch: 5| Step: 8
Training loss: 1.7817726135253906
Validation loss: 2.0211437979052143

Epoch: 5| Step: 9
Training loss: 1.1584293842315674
Validation loss: 1.9532402817920973

Epoch: 5| Step: 10
Training loss: 1.9577778577804565
Validation loss: 1.9035614844291442

Epoch: 305| Step: 0
Training loss: 1.6068313121795654
Validation loss: 1.9661503273953673

Epoch: 5| Step: 1
Training loss: 1.6542097330093384
Validation loss: 1.9683741331100464

Epoch: 5| Step: 2
Training loss: 1.7206993103027344
Validation loss: 1.9024012460503528

Epoch: 5| Step: 3
Training loss: 1.759454369544983
Validation loss: 1.9317538853614562

Epoch: 5| Step: 4
Training loss: 1.2044169902801514
Validation loss: 1.950801331509826

Epoch: 5| Step: 5
Training loss: 1.3072177171707153
Validation loss: 1.934613566244802

Epoch: 5| Step: 6
Training loss: 2.1482112407684326
Validation loss: 1.988316192421862

Epoch: 5| Step: 7
Training loss: 1.6969330310821533
Validation loss: 1.9065807263056438

Epoch: 5| Step: 8
Training loss: 1.4037964344024658
Validation loss: 1.8933555605590984

Epoch: 5| Step: 9
Training loss: 1.4858076572418213
Validation loss: 1.9568328344693748

Epoch: 5| Step: 10
Training loss: 1.3141167163848877
Validation loss: 1.9050374646340646

Epoch: 306| Step: 0
Training loss: 1.1965632438659668
Validation loss: 1.8868208700610745

Epoch: 5| Step: 1
Training loss: 1.084162950515747
Validation loss: 1.9757208824157715

Epoch: 5| Step: 2
Training loss: 1.5986497402191162
Validation loss: 1.9587862299334617

Epoch: 5| Step: 3
Training loss: 1.7951915264129639
Validation loss: 1.9556974262319586

Epoch: 5| Step: 4
Training loss: 2.2401654720306396
Validation loss: 2.024544697935863

Epoch: 5| Step: 5
Training loss: 1.9841697216033936
Validation loss: 1.9206310651635612

Epoch: 5| Step: 6
Training loss: 1.5344289541244507
Validation loss: 1.9541579856667468

Epoch: 5| Step: 7
Training loss: 1.486671805381775
Validation loss: 1.962292250766549

Epoch: 5| Step: 8
Training loss: 1.4725266695022583
Validation loss: 2.0108254571114816

Epoch: 5| Step: 9
Training loss: 1.0736488103866577
Validation loss: 1.9817878277071062

Epoch: 5| Step: 10
Training loss: 1.474732756614685
Validation loss: 1.9945768002540833

Epoch: 307| Step: 0
Training loss: 1.694122314453125
Validation loss: 1.9890648575239285

Epoch: 5| Step: 1
Training loss: 2.059558391571045
Validation loss: 1.9552515501617103

Epoch: 5| Step: 2
Training loss: 1.761664628982544
Validation loss: 1.9694247937971545

Epoch: 5| Step: 3
Training loss: 2.0240492820739746
Validation loss: 1.9656534989674885

Epoch: 5| Step: 4
Training loss: 1.113685131072998
Validation loss: 1.9716571953988844

Epoch: 5| Step: 5
Training loss: 1.71429443359375
Validation loss: 1.9151695492447063

Epoch: 5| Step: 6
Training loss: 1.731985330581665
Validation loss: 1.8978966897533787

Epoch: 5| Step: 7
Training loss: 1.1524055004119873
Validation loss: 1.9148550866752543

Epoch: 5| Step: 8
Training loss: 1.4801297187805176
Validation loss: 1.9823068175264584

Epoch: 5| Step: 9
Training loss: 1.690418004989624
Validation loss: 1.962824821472168

Epoch: 5| Step: 10
Training loss: 0.921911358833313
Validation loss: 1.962712534012333

Epoch: 308| Step: 0
Training loss: 1.5732042789459229
Validation loss: 1.9045614632227088

Epoch: 5| Step: 1
Training loss: 1.7022531032562256
Validation loss: 1.9040833147623206

Epoch: 5| Step: 2
Training loss: 1.7891765832901
Validation loss: 1.9380890605270222

Epoch: 5| Step: 3
Training loss: 0.8846641778945923
Validation loss: 1.951626185447939

Epoch: 5| Step: 4
Training loss: 1.631517767906189
Validation loss: 1.9535842172561153

Epoch: 5| Step: 5
Training loss: 1.3568062782287598
Validation loss: 1.9105387695374028

Epoch: 5| Step: 6
Training loss: 2.149350643157959
Validation loss: 1.928617295398507

Epoch: 5| Step: 7
Training loss: 1.5110218524932861
Validation loss: 1.9049633613196753

Epoch: 5| Step: 8
Training loss: 1.3958600759506226
Validation loss: 1.9026629309500418

Epoch: 5| Step: 9
Training loss: 1.953197717666626
Validation loss: 1.9830252983236825

Epoch: 5| Step: 10
Training loss: 1.4304016828536987
Validation loss: 1.9457903959417855

Epoch: 309| Step: 0
Training loss: 1.5422979593276978
Validation loss: 1.9229471350228915

Epoch: 5| Step: 1
Training loss: 1.5911847352981567
Validation loss: 1.9574478146850423

Epoch: 5| Step: 2
Training loss: 1.5455549955368042
Validation loss: 1.9317450241375995

Epoch: 5| Step: 3
Training loss: 1.3058909177780151
Validation loss: 1.9586637417475383

Epoch: 5| Step: 4
Training loss: 1.411423683166504
Validation loss: 1.9258721464423723

Epoch: 5| Step: 5
Training loss: 1.10285222530365
Validation loss: 1.9114971737707815

Epoch: 5| Step: 6
Training loss: 1.4109795093536377
Validation loss: 1.9665618609356623

Epoch: 5| Step: 7
Training loss: 1.5877625942230225
Validation loss: 1.8728907172397902

Epoch: 5| Step: 8
Training loss: 1.745821237564087
Validation loss: 1.9537642604561263

Epoch: 5| Step: 9
Training loss: 1.801195502281189
Validation loss: 1.9343193025999172

Epoch: 5| Step: 10
Training loss: 1.8598397970199585
Validation loss: 1.9251707523099837

Epoch: 310| Step: 0
Training loss: 1.0772758722305298
Validation loss: 1.8878350591146817

Epoch: 5| Step: 1
Training loss: 1.48288094997406
Validation loss: 1.9664400469872259

Epoch: 5| Step: 2
Training loss: 1.4166185855865479
Validation loss: 1.9587216402894707

Epoch: 5| Step: 3
Training loss: 1.9269806146621704
Validation loss: 1.9427970096629152

Epoch: 5| Step: 4
Training loss: 1.7021095752716064
Validation loss: 1.9564088390719505

Epoch: 5| Step: 5
Training loss: 1.2601964473724365
Validation loss: 1.9749184846878052

Epoch: 5| Step: 6
Training loss: 2.0898826122283936
Validation loss: 1.9015846329350625

Epoch: 5| Step: 7
Training loss: 1.441735029220581
Validation loss: 1.9695087286733812

Epoch: 5| Step: 8
Training loss: 1.5617482662200928
Validation loss: 2.0048682484575497

Epoch: 5| Step: 9
Training loss: 1.4846200942993164
Validation loss: 1.9562851152112406

Epoch: 5| Step: 10
Training loss: 1.5527898073196411
Validation loss: 1.987712739616312

Epoch: 311| Step: 0
Training loss: 2.1355037689208984
Validation loss: 2.010855887525825

Epoch: 5| Step: 1
Training loss: 2.0738308429718018
Validation loss: 1.9143119550520373

Epoch: 5| Step: 2
Training loss: 1.167323112487793
Validation loss: 1.9352490081582019

Epoch: 5| Step: 3
Training loss: 1.609805703163147
Validation loss: 1.8903241836896507

Epoch: 5| Step: 4
Training loss: 1.5389435291290283
Validation loss: 2.019223828469553

Epoch: 5| Step: 5
Training loss: 1.4745113849639893
Validation loss: 1.9098933281437043

Epoch: 5| Step: 6
Training loss: 1.6289777755737305
Validation loss: 1.9581367328602781

Epoch: 5| Step: 7
Training loss: 1.6501935720443726
Validation loss: 1.95686186000865

Epoch: 5| Step: 8
Training loss: 1.1422388553619385
Validation loss: 1.9966051757976573

Epoch: 5| Step: 9
Training loss: 1.5701507329940796
Validation loss: 2.001539727692963

Epoch: 5| Step: 10
Training loss: 1.379935622215271
Validation loss: 1.948970393467975

Epoch: 312| Step: 0
Training loss: 1.7154080867767334
Validation loss: 1.9574374473223122

Epoch: 5| Step: 1
Training loss: 2.126558303833008
Validation loss: 1.9343687206186273

Epoch: 5| Step: 2
Training loss: 1.7700107097625732
Validation loss: 1.9455778060420867

Epoch: 5| Step: 3
Training loss: 0.9527685046195984
Validation loss: 1.9753050188864432

Epoch: 5| Step: 4
Training loss: 1.6153366565704346
Validation loss: 1.9464225961316017

Epoch: 5| Step: 5
Training loss: 2.197828531265259
Validation loss: 1.8983488416159024

Epoch: 5| Step: 6
Training loss: 1.2109346389770508
Validation loss: 1.9024787179885372

Epoch: 5| Step: 7
Training loss: 1.1849470138549805
Validation loss: 1.9486087624744703

Epoch: 5| Step: 8
Training loss: 1.1559689044952393
Validation loss: 1.9435133985293809

Epoch: 5| Step: 9
Training loss: 1.728009819984436
Validation loss: 1.8941302966046076

Epoch: 5| Step: 10
Training loss: 1.4902467727661133
Validation loss: 1.9629185353555987

Epoch: 313| Step: 0
Training loss: 1.6696631908416748
Validation loss: 1.9526180939007831

Epoch: 5| Step: 1
Training loss: 1.6113674640655518
Validation loss: 1.986273652763777

Epoch: 5| Step: 2
Training loss: 1.6003280878067017
Validation loss: 1.962000343107408

Epoch: 5| Step: 3
Training loss: 1.1057155132293701
Validation loss: 1.9232566523295578

Epoch: 5| Step: 4
Training loss: 1.6548179388046265
Validation loss: 1.9147477008963143

Epoch: 5| Step: 5
Training loss: 1.671950101852417
Validation loss: 1.9895054268580612

Epoch: 5| Step: 6
Training loss: 1.2594375610351562
Validation loss: 1.9824532244795112

Epoch: 5| Step: 7
Training loss: 1.6687424182891846
Validation loss: 1.924338884251092

Epoch: 5| Step: 8
Training loss: 1.9088436365127563
Validation loss: 1.936379035313924

Epoch: 5| Step: 9
Training loss: 1.2323710918426514
Validation loss: 1.9843030591164865

Epoch: 5| Step: 10
Training loss: 1.7301677465438843
Validation loss: 1.932086811270765

Epoch: 314| Step: 0
Training loss: 1.6422138214111328
Validation loss: 1.897822569775325

Epoch: 5| Step: 1
Training loss: 2.136401653289795
Validation loss: 1.9475716621645036

Epoch: 5| Step: 2
Training loss: 1.616695761680603
Validation loss: 1.9744552745614001

Epoch: 5| Step: 3
Training loss: 1.4649004936218262
Validation loss: 1.9072201380165674

Epoch: 5| Step: 4
Training loss: 1.1766226291656494
Validation loss: 1.8791625999635266

Epoch: 5| Step: 5
Training loss: 1.2390649318695068
Validation loss: 1.9688624156418668

Epoch: 5| Step: 6
Training loss: 1.6401304006576538
Validation loss: 1.9487872508264357

Epoch: 5| Step: 7
Training loss: 1.8804060220718384
Validation loss: 1.9120236417298675

Epoch: 5| Step: 8
Training loss: 1.4350696802139282
Validation loss: 1.9380746810666976

Epoch: 5| Step: 9
Training loss: 1.1978014707565308
Validation loss: 1.9778372126240884

Epoch: 5| Step: 10
Training loss: 1.6674195528030396
Validation loss: 1.9878420932318575

Epoch: 315| Step: 0
Training loss: 1.4414527416229248
Validation loss: 1.9882587463625017

Epoch: 5| Step: 1
Training loss: 1.2514097690582275
Validation loss: 1.957441206901304

Epoch: 5| Step: 2
Training loss: 1.4547346830368042
Validation loss: 1.9804820373494139

Epoch: 5| Step: 3
Training loss: 1.3975157737731934
Validation loss: 2.004125800184024

Epoch: 5| Step: 4
Training loss: 1.407208800315857
Validation loss: 1.9654747645060222

Epoch: 5| Step: 5
Training loss: 1.6044095754623413
Validation loss: 1.9090922673543294

Epoch: 5| Step: 6
Training loss: 2.0040674209594727
Validation loss: 1.9642609370652067

Epoch: 5| Step: 7
Training loss: 1.868096113204956
Validation loss: 1.9219343175170243

Epoch: 5| Step: 8
Training loss: 2.0327343940734863
Validation loss: 1.9562008432162705

Epoch: 5| Step: 9
Training loss: 1.347360372543335
Validation loss: 1.9707167533136183

Epoch: 5| Step: 10
Training loss: 1.2518140077590942
Validation loss: 1.9639644853530391

Epoch: 316| Step: 0
Training loss: 1.9011751413345337
Validation loss: 1.9677933928787068

Epoch: 5| Step: 1
Training loss: 1.5194026231765747
Validation loss: 1.9629825738168531

Epoch: 5| Step: 2
Training loss: 1.958266019821167
Validation loss: 1.9142072239229757

Epoch: 5| Step: 3
Training loss: 1.234779953956604
Validation loss: 1.9814826147530669

Epoch: 5| Step: 4
Training loss: 1.280787706375122
Validation loss: 1.9443318382386239

Epoch: 5| Step: 5
Training loss: 2.1979849338531494
Validation loss: 1.893185656557801

Epoch: 5| Step: 6
Training loss: 1.5455776453018188
Validation loss: 1.9749330564211773

Epoch: 5| Step: 7
Training loss: 1.8039013147354126
Validation loss: 1.9145032180252897

Epoch: 5| Step: 8
Training loss: 1.7486896514892578
Validation loss: 1.9251600170648226

Epoch: 5| Step: 9
Training loss: 1.2092981338500977
Validation loss: 1.940581040997659

Epoch: 5| Step: 10
Training loss: 0.9075213670730591
Validation loss: 1.9578028776312386

Epoch: 317| Step: 0
Training loss: 1.5845943689346313
Validation loss: 1.9624533294349589

Epoch: 5| Step: 1
Training loss: 1.6532186269760132
Validation loss: 1.9494314437271447

Epoch: 5| Step: 2
Training loss: 1.3613957166671753
Validation loss: 1.9903077117858394

Epoch: 5| Step: 3
Training loss: 1.4121031761169434
Validation loss: 1.9415074343322425

Epoch: 5| Step: 4
Training loss: 1.755210280418396
Validation loss: 2.01014547194204

Epoch: 5| Step: 5
Training loss: 1.476243019104004
Validation loss: 1.9348772289932414

Epoch: 5| Step: 6
Training loss: 1.557155966758728
Validation loss: 1.9355369165379515

Epoch: 5| Step: 7
Training loss: 1.630136489868164
Validation loss: 1.9828302680805165

Epoch: 5| Step: 8
Training loss: 0.8076101541519165
Validation loss: 1.9090325281184206

Epoch: 5| Step: 9
Training loss: 1.9256378412246704
Validation loss: 1.9746911884636007

Epoch: 5| Step: 10
Training loss: 1.4117556810379028
Validation loss: 1.943338253164804

Epoch: 318| Step: 0
Training loss: 1.3624080419540405
Validation loss: 1.9329959500220515

Epoch: 5| Step: 1
Training loss: 1.6626756191253662
Validation loss: 1.996357355066525

Epoch: 5| Step: 2
Training loss: 1.496577501296997
Validation loss: 1.9518306985978158

Epoch: 5| Step: 3
Training loss: 2.128068447113037
Validation loss: 1.8629331011925974

Epoch: 5| Step: 4
Training loss: 1.5877835750579834
Validation loss: 1.9700191661875734

Epoch: 5| Step: 5
Training loss: 1.257043480873108
Validation loss: 1.951746782948894

Epoch: 5| Step: 6
Training loss: 1.7237670421600342
Validation loss: 1.9646013449597102

Epoch: 5| Step: 7
Training loss: 0.771828293800354
Validation loss: 1.9387530652425622

Epoch: 5| Step: 8
Training loss: 1.4517197608947754
Validation loss: 1.9956683651093514

Epoch: 5| Step: 9
Training loss: 1.6042070388793945
Validation loss: 1.9494692023082445

Epoch: 5| Step: 10
Training loss: 1.8561290502548218
Validation loss: 1.9481749688425372

Epoch: 319| Step: 0
Training loss: 1.2082544565200806
Validation loss: 1.9417306133495864

Epoch: 5| Step: 1
Training loss: 1.6058120727539062
Validation loss: 1.987172358779497

Epoch: 5| Step: 2
Training loss: 0.9593249559402466
Validation loss: 1.9941992772522794

Epoch: 5| Step: 3
Training loss: 1.2622896432876587
Validation loss: 1.945304798823531

Epoch: 5| Step: 4
Training loss: 1.7949049472808838
Validation loss: 1.9741248956290625

Epoch: 5| Step: 5
Training loss: 1.4795472621917725
Validation loss: 1.9342160276187363

Epoch: 5| Step: 6
Training loss: 2.002485990524292
Validation loss: 1.9152973544213079

Epoch: 5| Step: 7
Training loss: 1.706825613975525
Validation loss: 1.9522398723069059

Epoch: 5| Step: 8
Training loss: 1.3354357481002808
Validation loss: 1.96286726767017

Epoch: 5| Step: 9
Training loss: 2.3158700466156006
Validation loss: 1.9182762599760486

Epoch: 5| Step: 10
Training loss: 1.6971099376678467
Validation loss: 1.9032840882578204

Epoch: 320| Step: 0
Training loss: 1.5255508422851562
Validation loss: 1.940863770823325

Epoch: 5| Step: 1
Training loss: 0.8741563558578491
Validation loss: 1.9494766189206032

Epoch: 5| Step: 2
Training loss: 1.4081995487213135
Validation loss: 1.9383235682723343

Epoch: 5| Step: 3
Training loss: 1.336814522743225
Validation loss: 1.8887740732521139

Epoch: 5| Step: 4
Training loss: 2.3253226280212402
Validation loss: 1.9474760204233148

Epoch: 5| Step: 5
Training loss: 1.4378055334091187
Validation loss: 1.9355262120564778

Epoch: 5| Step: 6
Training loss: 1.8094524145126343
Validation loss: 1.9374886353810628

Epoch: 5| Step: 7
Training loss: 1.8116286993026733
Validation loss: 1.9223680624397852

Epoch: 5| Step: 8
Training loss: 1.2422796487808228
Validation loss: 1.910096178772629

Epoch: 5| Step: 9
Training loss: 1.8218917846679688
Validation loss: 1.919652456878334

Epoch: 5| Step: 10
Training loss: 1.5257264375686646
Validation loss: 1.939280084384385

Epoch: 321| Step: 0
Training loss: 1.6712528467178345
Validation loss: 1.9246754748846895

Epoch: 5| Step: 1
Training loss: 1.310923457145691
Validation loss: 1.9537465469811552

Epoch: 5| Step: 2
Training loss: 1.34555983543396
Validation loss: 1.9471716855161934

Epoch: 5| Step: 3
Training loss: 1.3049534559249878
Validation loss: 1.9818684388232488

Epoch: 5| Step: 4
Training loss: 1.7793115377426147
Validation loss: 1.966408230925119

Epoch: 5| Step: 5
Training loss: 1.2000186443328857
Validation loss: 1.9464263749378983

Epoch: 5| Step: 6
Training loss: 1.4774363040924072
Validation loss: 1.946958750806829

Epoch: 5| Step: 7
Training loss: 1.3819966316223145
Validation loss: 1.9353219744979695

Epoch: 5| Step: 8
Training loss: 1.5269501209259033
Validation loss: 1.8700479563846384

Epoch: 5| Step: 9
Training loss: 2.0281975269317627
Validation loss: 1.9481652372626848

Epoch: 5| Step: 10
Training loss: 1.584261417388916
Validation loss: 1.9482156089557114

Epoch: 322| Step: 0
Training loss: 1.8537471294403076
Validation loss: 1.9586084555554133

Epoch: 5| Step: 1
Training loss: 2.2986297607421875
Validation loss: 1.8997482381841189

Epoch: 5| Step: 2
Training loss: 1.9476737976074219
Validation loss: 1.904136005268302

Epoch: 5| Step: 3
Training loss: 1.5304988622665405
Validation loss: 1.9118160073475172

Epoch: 5| Step: 4
Training loss: 1.2689489126205444
Validation loss: 1.9391126581417617

Epoch: 5| Step: 5
Training loss: 1.755394697189331
Validation loss: 1.9152089190739456

Epoch: 5| Step: 6
Training loss: 1.6185944080352783
Validation loss: 1.9328365402836953

Epoch: 5| Step: 7
Training loss: 1.3008662462234497
Validation loss: 1.9248624463235178

Epoch: 5| Step: 8
Training loss: 1.4073702096939087
Validation loss: 1.940991896455006

Epoch: 5| Step: 9
Training loss: 0.9118515849113464
Validation loss: 1.8985973096662951

Epoch: 5| Step: 10
Training loss: 0.9658042788505554
Validation loss: 1.9672632730135353

Epoch: 323| Step: 0
Training loss: 1.6720186471939087
Validation loss: 1.9646483672562467

Epoch: 5| Step: 1
Training loss: 1.536001205444336
Validation loss: 1.9079165227951542

Epoch: 5| Step: 2
Training loss: 1.143040418624878
Validation loss: 1.9631904325177592

Epoch: 5| Step: 3
Training loss: 1.433717131614685
Validation loss: 1.9856975783583939

Epoch: 5| Step: 4
Training loss: 1.5874465703964233
Validation loss: 1.9547703599417081

Epoch: 5| Step: 5
Training loss: 1.3758995532989502
Validation loss: 1.9065065460820352

Epoch: 5| Step: 6
Training loss: 1.304206132888794
Validation loss: 1.9572833199654855

Epoch: 5| Step: 7
Training loss: 2.0165183544158936
Validation loss: 1.9076095601563812

Epoch: 5| Step: 8
Training loss: 1.0642728805541992
Validation loss: 1.9175383429373465

Epoch: 5| Step: 9
Training loss: 1.8183562755584717
Validation loss: 1.9047068934286795

Epoch: 5| Step: 10
Training loss: 1.6853951215744019
Validation loss: 1.8713666892820788

Epoch: 324| Step: 0
Training loss: 1.769004464149475
Validation loss: 1.9313539843405447

Epoch: 5| Step: 1
Training loss: 1.9301517009735107
Validation loss: 1.8819336237445954

Epoch: 5| Step: 2
Training loss: 1.3808542490005493
Validation loss: 1.9096169407649706

Epoch: 5| Step: 3
Training loss: 1.2624022960662842
Validation loss: 1.8907932209712204

Epoch: 5| Step: 4
Training loss: 1.098601222038269
Validation loss: 1.8950708309809368

Epoch: 5| Step: 5
Training loss: 1.4269040822982788
Validation loss: 1.9001961702941566

Epoch: 5| Step: 6
Training loss: 1.8322744369506836
Validation loss: 1.8350297968874696

Epoch: 5| Step: 7
Training loss: 1.5366463661193848
Validation loss: 1.9065034081858974

Epoch: 5| Step: 8
Training loss: 1.42872154712677
Validation loss: 1.9759942254712504

Epoch: 5| Step: 9
Training loss: 1.6420295238494873
Validation loss: 1.893600530521844

Epoch: 5| Step: 10
Training loss: 1.2893402576446533
Validation loss: 1.901322828826084

Epoch: 325| Step: 0
Training loss: 1.7183396816253662
Validation loss: 1.936648266289824

Epoch: 5| Step: 1
Training loss: 1.723732590675354
Validation loss: 1.9565497957250124

Epoch: 5| Step: 2
Training loss: 1.3248249292373657
Validation loss: 1.9553963163847565

Epoch: 5| Step: 3
Training loss: 0.6455410718917847
Validation loss: 1.9183459205012168

Epoch: 5| Step: 4
Training loss: 1.8535406589508057
Validation loss: 1.902115374483088

Epoch: 5| Step: 5
Training loss: 1.4112147092819214
Validation loss: 1.9110917032405894

Epoch: 5| Step: 6
Training loss: 1.687668800354004
Validation loss: 1.960348121581539

Epoch: 5| Step: 7
Training loss: 1.2343921661376953
Validation loss: 1.9342299302419026

Epoch: 5| Step: 8
Training loss: 1.7810472249984741
Validation loss: 1.888344692927535

Epoch: 5| Step: 9
Training loss: 1.7530381679534912
Validation loss: 1.9422314243931924

Epoch: 5| Step: 10
Training loss: 1.4094525575637817
Validation loss: 1.8985980531220794

Epoch: 326| Step: 0
Training loss: 1.1375900506973267
Validation loss: 1.8948865129101662

Epoch: 5| Step: 1
Training loss: 1.6017814874649048
Validation loss: 1.9284880712468138

Epoch: 5| Step: 2
Training loss: 1.4995139837265015
Validation loss: 1.929044485092163

Epoch: 5| Step: 3
Training loss: 1.7026948928833008
Validation loss: 1.9175601069645216

Epoch: 5| Step: 4
Training loss: 1.408660650253296
Validation loss: 1.9168121737818564

Epoch: 5| Step: 5
Training loss: 1.6316947937011719
Validation loss: 1.9502492117625412

Epoch: 5| Step: 6
Training loss: 1.0962612628936768
Validation loss: 1.9315832148316086

Epoch: 5| Step: 7
Training loss: 1.1587913036346436
Validation loss: 1.9049478653938539

Epoch: 5| Step: 8
Training loss: 1.8221282958984375
Validation loss: 1.9081438702921714

Epoch: 5| Step: 9
Training loss: 1.5246902704238892
Validation loss: 1.9076641733928392

Epoch: 5| Step: 10
Training loss: 1.8661928176879883
Validation loss: 1.9517926682708084

Epoch: 327| Step: 0
Training loss: 1.9820626974105835
Validation loss: 1.897168646576584

Epoch: 5| Step: 1
Training loss: 1.0654795169830322
Validation loss: 1.9221477047089608

Epoch: 5| Step: 2
Training loss: 1.395377516746521
Validation loss: 1.9288145419090026

Epoch: 5| Step: 3
Training loss: 1.396116018295288
Validation loss: 1.9445295949136057

Epoch: 5| Step: 4
Training loss: 1.3726780414581299
Validation loss: 1.9169081090598978

Epoch: 5| Step: 5
Training loss: 1.4776321649551392
Validation loss: 1.9654801584059192

Epoch: 5| Step: 6
Training loss: 2.084488868713379
Validation loss: 1.9573466982892764

Epoch: 5| Step: 7
Training loss: 1.4911017417907715
Validation loss: 1.8818244062444216

Epoch: 5| Step: 8
Training loss: 1.5791690349578857
Validation loss: 1.92179093053264

Epoch: 5| Step: 9
Training loss: 1.5690124034881592
Validation loss: 1.966820527148503

Epoch: 5| Step: 10
Training loss: 1.3797881603240967
Validation loss: 1.8701911203322872

Epoch: 328| Step: 0
Training loss: 1.7806488275527954
Validation loss: 1.9255751589293122

Epoch: 5| Step: 1
Training loss: 1.6568584442138672
Validation loss: 1.9353569976745113

Epoch: 5| Step: 2
Training loss: 1.3086495399475098
Validation loss: 1.9130914095909364

Epoch: 5| Step: 3
Training loss: 1.5649118423461914
Validation loss: 1.8940479088855047

Epoch: 5| Step: 4
Training loss: 1.386512041091919
Validation loss: 1.915522490778277

Epoch: 5| Step: 5
Training loss: 1.76593816280365
Validation loss: 1.9389481852131505

Epoch: 5| Step: 6
Training loss: 1.5844870805740356
Validation loss: 1.9357570576411423

Epoch: 5| Step: 7
Training loss: 1.4207656383514404
Validation loss: 1.8965452076286398

Epoch: 5| Step: 8
Training loss: 1.195192575454712
Validation loss: 1.9269131563043083

Epoch: 5| Step: 9
Training loss: 1.715531349182129
Validation loss: 1.9885260417897215

Epoch: 5| Step: 10
Training loss: 1.134272575378418
Validation loss: 1.8823092124795402

Epoch: 329| Step: 0
Training loss: 1.6030118465423584
Validation loss: 1.952637682678879

Epoch: 5| Step: 1
Training loss: 1.5085887908935547
Validation loss: 1.9396255247054561

Epoch: 5| Step: 2
Training loss: 1.3179086446762085
Validation loss: 1.9071192305575135

Epoch: 5| Step: 3
Training loss: 1.883191704750061
Validation loss: 1.9261323239213677

Epoch: 5| Step: 4
Training loss: 1.0859178304672241
Validation loss: 1.9757793641859485

Epoch: 5| Step: 5
Training loss: 1.4803376197814941
Validation loss: 1.957547196777918

Epoch: 5| Step: 6
Training loss: 1.7966978549957275
Validation loss: 1.935812868097777

Epoch: 5| Step: 7
Training loss: 1.188401460647583
Validation loss: 1.9188274670672674

Epoch: 5| Step: 8
Training loss: 1.7920255661010742
Validation loss: 1.9310248782557826

Epoch: 5| Step: 9
Training loss: 1.69148850440979
Validation loss: 1.9354823379106418

Epoch: 5| Step: 10
Training loss: 1.0192726850509644
Validation loss: 1.9513890999619679

Epoch: 330| Step: 0
Training loss: 0.76478511095047
Validation loss: 1.9081921141634706

Epoch: 5| Step: 1
Training loss: 1.9538991451263428
Validation loss: 1.8816812961332259

Epoch: 5| Step: 2
Training loss: 1.2091630697250366
Validation loss: 1.8935849615322646

Epoch: 5| Step: 3
Training loss: 1.4932968616485596
Validation loss: 1.9424578220613542

Epoch: 5| Step: 4
Training loss: 1.768151044845581
Validation loss: 1.960605534174109

Epoch: 5| Step: 5
Training loss: 1.4994451999664307
Validation loss: 1.9475589593251545

Epoch: 5| Step: 6
Training loss: 1.695678472518921
Validation loss: 1.8886992341728621

Epoch: 5| Step: 7
Training loss: 1.172912836074829
Validation loss: 1.9232670799378426

Epoch: 5| Step: 8
Training loss: 1.7595176696777344
Validation loss: 1.9194516520346365

Epoch: 5| Step: 9
Training loss: 1.8220685720443726
Validation loss: 1.9539927872278358

Epoch: 5| Step: 10
Training loss: 0.9281593561172485
Validation loss: 1.8941049434805428

Epoch: 331| Step: 0
Training loss: 1.5663179159164429
Validation loss: 1.9197143534178376

Epoch: 5| Step: 1
Training loss: 1.2175778150558472
Validation loss: 1.8997317232111448

Epoch: 5| Step: 2
Training loss: 1.2303593158721924
Validation loss: 1.904519848926093

Epoch: 5| Step: 3
Training loss: 1.3960649967193604
Validation loss: 1.9350835918098368

Epoch: 5| Step: 4
Training loss: 1.4723314046859741
Validation loss: 1.8880512176021453

Epoch: 5| Step: 5
Training loss: 1.2660108804702759
Validation loss: 1.8834780813545309

Epoch: 5| Step: 6
Training loss: 1.6722526550292969
Validation loss: 1.889491045346824

Epoch: 5| Step: 7
Training loss: 1.299293041229248
Validation loss: 1.876031724355554

Epoch: 5| Step: 8
Training loss: 1.6182082891464233
Validation loss: 1.9450035531033751

Epoch: 5| Step: 9
Training loss: 1.8574097156524658
Validation loss: 1.9069536706452728

Epoch: 5| Step: 10
Training loss: 1.7181044816970825
Validation loss: 1.9499072387654295

Epoch: 332| Step: 0
Training loss: 1.2868250608444214
Validation loss: 1.8970188774088377

Epoch: 5| Step: 1
Training loss: 0.9895051717758179
Validation loss: 1.901187627546249

Epoch: 5| Step: 2
Training loss: 1.151203989982605
Validation loss: 1.8916010728446386

Epoch: 5| Step: 3
Training loss: 2.5351057052612305
Validation loss: 1.9399895129665252

Epoch: 5| Step: 4
Training loss: 1.4983948469161987
Validation loss: 1.8614178319131174

Epoch: 5| Step: 5
Training loss: 1.7868191003799438
Validation loss: 1.9492813323133735

Epoch: 5| Step: 6
Training loss: 1.4555754661560059
Validation loss: 1.905585213374066

Epoch: 5| Step: 7
Training loss: 1.9705390930175781
Validation loss: 1.8652425004589943

Epoch: 5| Step: 8
Training loss: 1.0499337911605835
Validation loss: 1.9241374974609704

Epoch: 5| Step: 9
Training loss: 1.489331841468811
Validation loss: 1.9245236368589504

Epoch: 5| Step: 10
Training loss: 1.4983865022659302
Validation loss: 1.9123534002611715

Epoch: 333| Step: 0
Training loss: 1.3743696212768555
Validation loss: 1.9349031640637306

Epoch: 5| Step: 1
Training loss: 1.3458740711212158
Validation loss: 1.9007125695546467

Epoch: 5| Step: 2
Training loss: 1.0296062231063843
Validation loss: 1.958346805264873

Epoch: 5| Step: 3
Training loss: 1.396417260169983
Validation loss: 1.8857727486600158

Epoch: 5| Step: 4
Training loss: 1.8509842157363892
Validation loss: 1.9353097946413103

Epoch: 5| Step: 5
Training loss: 1.3312633037567139
Validation loss: 1.9594683711246779

Epoch: 5| Step: 6
Training loss: 2.1010913848876953
Validation loss: 1.92030922443636

Epoch: 5| Step: 7
Training loss: 1.5816401243209839
Validation loss: 1.9109645633287327

Epoch: 5| Step: 8
Training loss: 1.7581236362457275
Validation loss: 1.8571607656376337

Epoch: 5| Step: 9
Training loss: 1.5099785327911377
Validation loss: 1.8166352959089382

Epoch: 5| Step: 10
Training loss: 1.4337323904037476
Validation loss: 1.894126767753273

Epoch: 334| Step: 0
Training loss: 1.4627994298934937
Validation loss: 1.8101219541283065

Epoch: 5| Step: 1
Training loss: 2.05729603767395
Validation loss: 1.9286087328387844

Epoch: 5| Step: 2
Training loss: 1.2138071060180664
Validation loss: 1.920371699076827

Epoch: 5| Step: 3
Training loss: 1.4039617776870728
Validation loss: 1.8919458517464258

Epoch: 5| Step: 4
Training loss: 1.4785972833633423
Validation loss: 1.873773297955913

Epoch: 5| Step: 5
Training loss: 1.197535514831543
Validation loss: 1.9147776070461477

Epoch: 5| Step: 6
Training loss: 1.3160789012908936
Validation loss: 1.9745649419805056

Epoch: 5| Step: 7
Training loss: 1.7543290853500366
Validation loss: 1.9705466070482809

Epoch: 5| Step: 8
Training loss: 2.1334164142608643
Validation loss: 1.9359971272048129

Epoch: 5| Step: 9
Training loss: 0.9513673782348633
Validation loss: 1.8992146048494565

Epoch: 5| Step: 10
Training loss: 1.5033559799194336
Validation loss: 1.8989665969725578

Epoch: 335| Step: 0
Training loss: 1.4076907634735107
Validation loss: 1.8787183582141835

Epoch: 5| Step: 1
Training loss: 1.7028615474700928
Validation loss: 1.9206934949403167

Epoch: 5| Step: 2
Training loss: 1.4960097074508667
Validation loss: 1.9586212353039814

Epoch: 5| Step: 3
Training loss: 0.8698743581771851
Validation loss: 1.9712437532281364

Epoch: 5| Step: 4
Training loss: 1.328058123588562
Validation loss: 1.8949097382125033

Epoch: 5| Step: 5
Training loss: 1.8835359811782837
Validation loss: 1.9376364574637464

Epoch: 5| Step: 6
Training loss: 2.102879762649536
Validation loss: 1.9311713890362812

Epoch: 5| Step: 7
Training loss: 1.6761096715927124
Validation loss: 1.9105448184474823

Epoch: 5| Step: 8
Training loss: 1.1276614665985107
Validation loss: 1.940689609896752

Epoch: 5| Step: 9
Training loss: 1.428866982460022
Validation loss: 1.940854303298458

Epoch: 5| Step: 10
Training loss: 1.4063754081726074
Validation loss: 1.9126335536279986

Epoch: 336| Step: 0
Training loss: 1.6950509548187256
Validation loss: 1.9760585228602092

Epoch: 5| Step: 1
Training loss: 1.637101173400879
Validation loss: 2.0069673458735147

Epoch: 5| Step: 2
Training loss: 2.017383098602295
Validation loss: 1.9065862714603383

Epoch: 5| Step: 3
Training loss: 1.8264455795288086
Validation loss: 1.9648778989750852

Epoch: 5| Step: 4
Training loss: 1.2859218120574951
Validation loss: 1.8981276917201217

Epoch: 5| Step: 5
Training loss: 1.4225842952728271
Validation loss: 1.9255689626098962

Epoch: 5| Step: 6
Training loss: 1.5542465448379517
Validation loss: 1.9051829281673636

Epoch: 5| Step: 7
Training loss: 1.6286016702651978
Validation loss: 1.934998381522394

Epoch: 5| Step: 8
Training loss: 1.243743658065796
Validation loss: 1.9276056494764102

Epoch: 5| Step: 9
Training loss: 1.1816027164459229
Validation loss: 1.9330609306212394

Epoch: 5| Step: 10
Training loss: 1.0932605266571045
Validation loss: 1.8569392337593982

Epoch: 337| Step: 0
Training loss: 0.8476068377494812
Validation loss: 1.9450551643166492

Epoch: 5| Step: 1
Training loss: 1.4319875240325928
Validation loss: 1.8901788201383365

Epoch: 5| Step: 2
Training loss: 1.9286359548568726
Validation loss: 1.9445136106142433

Epoch: 5| Step: 3
Training loss: 1.5402004718780518
Validation loss: 1.9338063732270272

Epoch: 5| Step: 4
Training loss: 1.5973424911499023
Validation loss: 1.9341312916048112

Epoch: 5| Step: 5
Training loss: 1.457083821296692
Validation loss: 1.8956034080956572

Epoch: 5| Step: 6
Training loss: 1.2406610250473022
Validation loss: 1.8919380493061517

Epoch: 5| Step: 7
Training loss: 1.915704369544983
Validation loss: 1.9434857342832832

Epoch: 5| Step: 8
Training loss: 1.4201123714447021
Validation loss: 1.9601409614727061

Epoch: 5| Step: 9
Training loss: 1.5747437477111816
Validation loss: 1.9464605931312806

Epoch: 5| Step: 10
Training loss: 1.1982345581054688
Validation loss: 1.9202744883875693

Epoch: 338| Step: 0
Training loss: 1.058311104774475
Validation loss: 1.9685802946808517

Epoch: 5| Step: 1
Training loss: 1.783684492111206
Validation loss: 1.8930411954079904

Epoch: 5| Step: 2
Training loss: 1.3940789699554443
Validation loss: 1.8865967783876645

Epoch: 5| Step: 3
Training loss: 1.3867217302322388
Validation loss: 1.97668287574604

Epoch: 5| Step: 4
Training loss: 1.0873435735702515
Validation loss: 1.8779528397385792

Epoch: 5| Step: 5
Training loss: 2.0360629558563232
Validation loss: 1.9407780708805207

Epoch: 5| Step: 6
Training loss: 1.6391245126724243
Validation loss: 1.9147014271828435

Epoch: 5| Step: 7
Training loss: 1.2797305583953857
Validation loss: 1.9127875733119186

Epoch: 5| Step: 8
Training loss: 0.9320322871208191
Validation loss: 1.9324841896692913

Epoch: 5| Step: 9
Training loss: 1.9203981161117554
Validation loss: 1.9317408210487776

Epoch: 5| Step: 10
Training loss: 1.6101951599121094
Validation loss: 1.9065033005129906

Epoch: 339| Step: 0
Training loss: 0.9443547129631042
Validation loss: 1.8962059943906722

Epoch: 5| Step: 1
Training loss: 1.443351149559021
Validation loss: 1.9042911862814298

Epoch: 5| Step: 2
Training loss: 1.2014715671539307
Validation loss: 1.9307398155171385

Epoch: 5| Step: 3
Training loss: 1.204293966293335
Validation loss: 1.8743600076244724

Epoch: 5| Step: 4
Training loss: 0.9273370504379272
Validation loss: 1.897903896147205

Epoch: 5| Step: 5
Training loss: 2.4123945236206055
Validation loss: 1.9194633665905203

Epoch: 5| Step: 6
Training loss: 1.082139253616333
Validation loss: 1.8161990219546902

Epoch: 5| Step: 7
Training loss: 1.6851212978363037
Validation loss: 1.8888395435066634

Epoch: 5| Step: 8
Training loss: 2.0208210945129395
Validation loss: 1.8965765148080804

Epoch: 5| Step: 9
Training loss: 1.6067256927490234
Validation loss: 1.9048885196767829

Epoch: 5| Step: 10
Training loss: 2.1326746940612793
Validation loss: 1.8715904156366985

Epoch: 340| Step: 0
Training loss: 1.4918705224990845
Validation loss: 1.9069358494973951

Epoch: 5| Step: 1
Training loss: 1.0990703105926514
Validation loss: 1.8929116469557568

Epoch: 5| Step: 2
Training loss: 1.5901200771331787
Validation loss: 1.9696171463176768

Epoch: 5| Step: 3
Training loss: 1.646268606185913
Validation loss: 1.9157062961209206

Epoch: 5| Step: 4
Training loss: 2.077638864517212
Validation loss: 1.868873521845828

Epoch: 5| Step: 5
Training loss: 1.0519225597381592
Validation loss: 1.9373979901754728

Epoch: 5| Step: 6
Training loss: 1.1453211307525635
Validation loss: 1.9159843383296844

Epoch: 5| Step: 7
Training loss: 1.4850642681121826
Validation loss: 1.972171014355075

Epoch: 5| Step: 8
Training loss: 1.7742077112197876
Validation loss: 1.9223933232727872

Epoch: 5| Step: 9
Training loss: 1.32216477394104
Validation loss: 1.9739395059565061

Epoch: 5| Step: 10
Training loss: 1.3612909317016602
Validation loss: 1.8837940987720285

Epoch: 341| Step: 0
Training loss: 1.8071067333221436
Validation loss: 1.9062863947242819

Epoch: 5| Step: 1
Training loss: 1.7304561138153076
Validation loss: 1.9289427880317933

Epoch: 5| Step: 2
Training loss: 0.887241005897522
Validation loss: 1.9661712851575626

Epoch: 5| Step: 3
Training loss: 1.6304975748062134
Validation loss: 1.9195451121176443

Epoch: 5| Step: 4
Training loss: 1.3763900995254517
Validation loss: 1.882780719828862

Epoch: 5| Step: 5
Training loss: 1.0706318616867065
Validation loss: 1.9161237824347712

Epoch: 5| Step: 6
Training loss: 1.4358292818069458
Validation loss: 1.8804037058225243

Epoch: 5| Step: 7
Training loss: 1.8227201700210571
Validation loss: 1.920067851261426

Epoch: 5| Step: 8
Training loss: 1.663620948791504
Validation loss: 1.9042980594019736

Epoch: 5| Step: 9
Training loss: 1.25894033908844
Validation loss: 1.9180126138912734

Epoch: 5| Step: 10
Training loss: 1.2009989023208618
Validation loss: 1.9921811908803961

Epoch: 342| Step: 0
Training loss: 1.7092597484588623
Validation loss: 1.893784353809972

Epoch: 5| Step: 1
Training loss: 2.0343518257141113
Validation loss: 1.911220867146728

Epoch: 5| Step: 2
Training loss: 1.0733917951583862
Validation loss: 1.9701706517127253

Epoch: 5| Step: 3
Training loss: 1.293487310409546
Validation loss: 1.9538371421957528

Epoch: 5| Step: 4
Training loss: 1.2475227117538452
Validation loss: 1.9513930915504374

Epoch: 5| Step: 5
Training loss: 2.23772931098938
Validation loss: 1.8827707895668604

Epoch: 5| Step: 6
Training loss: 1.129980206489563
Validation loss: 1.8994067022877354

Epoch: 5| Step: 7
Training loss: 1.8248345851898193
Validation loss: 1.9490322656528924

Epoch: 5| Step: 8
Training loss: 1.1176658868789673
Validation loss: 1.9575633630957654

Epoch: 5| Step: 9
Training loss: 1.4704262018203735
Validation loss: 1.9270123461241364

Epoch: 5| Step: 10
Training loss: 1.1947463750839233
Validation loss: 1.885454693148213

Epoch: 343| Step: 0
Training loss: 1.2518997192382812
Validation loss: 1.9354410709873322

Epoch: 5| Step: 1
Training loss: 1.3162684440612793
Validation loss: 1.953483171360467

Epoch: 5| Step: 2
Training loss: 1.3663570880889893
Validation loss: 1.9114011103107083

Epoch: 5| Step: 3
Training loss: 1.3500763177871704
Validation loss: 1.8923708777273855

Epoch: 5| Step: 4
Training loss: 1.6441043615341187
Validation loss: 1.955375022785638

Epoch: 5| Step: 5
Training loss: 1.5979284048080444
Validation loss: 1.9318231318586616

Epoch: 5| Step: 6
Training loss: 1.4570757150650024
Validation loss: 1.851430598125663

Epoch: 5| Step: 7
Training loss: 1.506539225578308
Validation loss: 1.924577272066506

Epoch: 5| Step: 8
Training loss: 1.631401777267456
Validation loss: 1.9236443388846614

Epoch: 5| Step: 9
Training loss: 1.3156388998031616
Validation loss: 1.8831359596662625

Epoch: 5| Step: 10
Training loss: 1.522409439086914
Validation loss: 1.9819394644870554

Epoch: 344| Step: 0
Training loss: 1.136887550354004
Validation loss: 1.8825841078194239

Epoch: 5| Step: 1
Training loss: 1.6290779113769531
Validation loss: 1.965934826481727

Epoch: 5| Step: 2
Training loss: 1.3335704803466797
Validation loss: 1.937040857089463

Epoch: 5| Step: 3
Training loss: 1.768170714378357
Validation loss: 1.9025822134428128

Epoch: 5| Step: 4
Training loss: 1.7741018533706665
Validation loss: 1.97322666516868

Epoch: 5| Step: 5
Training loss: 1.3051536083221436
Validation loss: 1.9238873540714223

Epoch: 5| Step: 6
Training loss: 1.6230895519256592
Validation loss: 1.9015978972117107

Epoch: 5| Step: 7
Training loss: 1.3949785232543945
Validation loss: 1.9040513974364086

Epoch: 5| Step: 8
Training loss: 1.5700023174285889
Validation loss: 1.9104687347207019

Epoch: 5| Step: 9
Training loss: 1.244175910949707
Validation loss: 1.9013259782586047

Epoch: 5| Step: 10
Training loss: 1.6014569997787476
Validation loss: 1.9246339592882382

Epoch: 345| Step: 0
Training loss: 1.3438385725021362
Validation loss: 1.927262850987014

Epoch: 5| Step: 1
Training loss: 1.318192720413208
Validation loss: 1.8789133448754587

Epoch: 5| Step: 2
Training loss: 2.2906014919281006
Validation loss: 1.9766415216589486

Epoch: 5| Step: 3
Training loss: 1.2079546451568604
Validation loss: 1.8910920273873113

Epoch: 5| Step: 4
Training loss: 1.4787726402282715
Validation loss: 1.9192975362141926

Epoch: 5| Step: 5
Training loss: 1.4444241523742676
Validation loss: 1.9143003084326302

Epoch: 5| Step: 6
Training loss: 1.4529410600662231
Validation loss: 1.8946843762551584

Epoch: 5| Step: 7
Training loss: 1.8163655996322632
Validation loss: 1.8789555129184519

Epoch: 5| Step: 8
Training loss: 1.2836145162582397
Validation loss: 1.8773720713071926

Epoch: 5| Step: 9
Training loss: 1.4229954481124878
Validation loss: 1.9114063042466358

Epoch: 5| Step: 10
Training loss: 1.2065669298171997
Validation loss: 1.954438356943028

Epoch: 346| Step: 0
Training loss: 1.3081018924713135
Validation loss: 1.974218713339939

Epoch: 5| Step: 1
Training loss: 1.6431154012680054
Validation loss: 1.9093310756068076

Epoch: 5| Step: 2
Training loss: 1.1350209712982178
Validation loss: 1.9204420633213495

Epoch: 5| Step: 3
Training loss: 1.2987353801727295
Validation loss: 1.9208246008042367

Epoch: 5| Step: 4
Training loss: 1.6315780878067017
Validation loss: 1.9035548010180074

Epoch: 5| Step: 5
Training loss: 1.5104312896728516
Validation loss: 1.9118811315105808

Epoch: 5| Step: 6
Training loss: 1.3238543272018433
Validation loss: 1.8279787263562601

Epoch: 5| Step: 7
Training loss: 1.414950966835022
Validation loss: 1.8994039412467711

Epoch: 5| Step: 8
Training loss: 1.927950143814087
Validation loss: 1.8865485665618733

Epoch: 5| Step: 9
Training loss: 1.2167575359344482
Validation loss: 1.9162214007428897

Epoch: 5| Step: 10
Training loss: 1.8839988708496094
Validation loss: 1.9120378545535508

Epoch: 347| Step: 0
Training loss: 1.0504205226898193
Validation loss: 1.9253732594110633

Epoch: 5| Step: 1
Training loss: 1.8881168365478516
Validation loss: 1.9077064593633015

Epoch: 5| Step: 2
Training loss: 0.9755274057388306
Validation loss: 1.845541633585448

Epoch: 5| Step: 3
Training loss: 1.3624999523162842
Validation loss: 1.9288303877717705

Epoch: 5| Step: 4
Training loss: 1.5839335918426514
Validation loss: 1.9104124371723463

Epoch: 5| Step: 5
Training loss: 1.343135952949524
Validation loss: 1.935957206192837

Epoch: 5| Step: 6
Training loss: 1.7880394458770752
Validation loss: 1.8498343613839918

Epoch: 5| Step: 7
Training loss: 1.2743428945541382
Validation loss: 1.917185252712619

Epoch: 5| Step: 8
Training loss: 1.5851621627807617
Validation loss: 1.9303754298917708

Epoch: 5| Step: 9
Training loss: 1.6702611446380615
Validation loss: 1.9402261459699242

Epoch: 5| Step: 10
Training loss: 1.837765097618103
Validation loss: 1.9095361412212413

Epoch: 348| Step: 0
Training loss: 1.6958997249603271
Validation loss: 1.8910316818503923

Epoch: 5| Step: 1
Training loss: 1.4224233627319336
Validation loss: 1.9179126062700826

Epoch: 5| Step: 2
Training loss: 1.9874541759490967
Validation loss: 1.8938397117840347

Epoch: 5| Step: 3
Training loss: 1.4146066904067993
Validation loss: 1.9430802111984582

Epoch: 5| Step: 4
Training loss: 0.8779829144477844
Validation loss: 1.9382301709985221

Epoch: 5| Step: 5
Training loss: 1.0593324899673462
Validation loss: 1.8553466155964842

Epoch: 5| Step: 6
Training loss: 0.7772963643074036
Validation loss: 1.9582297596880185

Epoch: 5| Step: 7
Training loss: 1.2256910800933838
Validation loss: 1.9221483225463538

Epoch: 5| Step: 8
Training loss: 1.7443338632583618
Validation loss: 1.880542084734927

Epoch: 5| Step: 9
Training loss: 1.882309913635254
Validation loss: 1.8991775871605001

Epoch: 5| Step: 10
Training loss: 1.8148012161254883
Validation loss: 1.9266305200515255

Epoch: 349| Step: 0
Training loss: 0.8935849070549011
Validation loss: 1.953311235673966

Epoch: 5| Step: 1
Training loss: 1.5760554075241089
Validation loss: 1.933569013431508

Epoch: 5| Step: 2
Training loss: 1.3182852268218994
Validation loss: 1.8925183293639973

Epoch: 5| Step: 3
Training loss: 1.7670530080795288
Validation loss: 1.9173734226534445

Epoch: 5| Step: 4
Training loss: 1.7156124114990234
Validation loss: 1.9387402393484627

Epoch: 5| Step: 5
Training loss: 1.5383117198944092
Validation loss: 1.9154145627893426

Epoch: 5| Step: 6
Training loss: 0.8192286491394043
Validation loss: 1.9148107754286898

Epoch: 5| Step: 7
Training loss: 1.312855839729309
Validation loss: 2.013383073191489

Epoch: 5| Step: 8
Training loss: 1.5911372900009155
Validation loss: 1.9303368471002067

Epoch: 5| Step: 9
Training loss: 1.5524044036865234
Validation loss: 1.9100915026921097

Epoch: 5| Step: 10
Training loss: 1.610701322555542
Validation loss: 1.9449418885733492

Epoch: 350| Step: 0
Training loss: 0.9424129724502563
Validation loss: 1.9940905788893342

Epoch: 5| Step: 1
Training loss: 1.154528021812439
Validation loss: 1.9446926014397734

Epoch: 5| Step: 2
Training loss: 1.6565519571304321
Validation loss: 1.9901313704829062

Epoch: 5| Step: 3
Training loss: 1.307469129562378
Validation loss: 1.905052133785781

Epoch: 5| Step: 4
Training loss: 1.6057647466659546
Validation loss: 1.912534088216802

Epoch: 5| Step: 5
Training loss: 1.274266004562378
Validation loss: 1.86520718502742

Epoch: 5| Step: 6
Training loss: 1.8152137994766235
Validation loss: 1.9033469820535311

Epoch: 5| Step: 7
Training loss: 1.4752143621444702
Validation loss: 1.911295106334071

Epoch: 5| Step: 8
Training loss: 1.864168405532837
Validation loss: 1.9044326761717438

Epoch: 5| Step: 9
Training loss: 1.2512098550796509
Validation loss: 1.9321513868147326

Epoch: 5| Step: 10
Training loss: 1.5985915660858154
Validation loss: 1.85978748080551

Epoch: 351| Step: 0
Training loss: 1.234315276145935
Validation loss: 1.8879479054481751

Epoch: 5| Step: 1
Training loss: 0.7909392714500427
Validation loss: 1.9201755062226327

Epoch: 5| Step: 2
Training loss: 1.8073110580444336
Validation loss: 1.9029973694073257

Epoch: 5| Step: 3
Training loss: 1.5539127588272095
Validation loss: 1.866933399631131

Epoch: 5| Step: 4
Training loss: 1.4777858257293701
Validation loss: 1.904723886520632

Epoch: 5| Step: 5
Training loss: 1.5978147983551025
Validation loss: 1.965139627456665

Epoch: 5| Step: 6
Training loss: 1.257251501083374
Validation loss: 1.8751881994226927

Epoch: 5| Step: 7
Training loss: 1.7626447677612305
Validation loss: 1.8753992357561666

Epoch: 5| Step: 8
Training loss: 1.279013991355896
Validation loss: 1.9088686653362807

Epoch: 5| Step: 9
Training loss: 1.2841931581497192
Validation loss: 1.8510045800157773

Epoch: 5| Step: 10
Training loss: 1.855307936668396
Validation loss: 1.893083606996844

Epoch: 352| Step: 0
Training loss: 1.4427788257598877
Validation loss: 1.9056656616990284

Epoch: 5| Step: 1
Training loss: 1.2007378339767456
Validation loss: 1.8977173425818001

Epoch: 5| Step: 2
Training loss: 1.2335457801818848
Validation loss: 1.921033646470757

Epoch: 5| Step: 3
Training loss: 1.2999566793441772
Validation loss: 1.8892545277072537

Epoch: 5| Step: 4
Training loss: 1.8254314661026
Validation loss: 1.8617555159394459

Epoch: 5| Step: 5
Training loss: 1.4329115152359009
Validation loss: 1.926308649842457

Epoch: 5| Step: 6
Training loss: 1.5654428005218506
Validation loss: 1.9874942687249952

Epoch: 5| Step: 7
Training loss: 1.561279296875
Validation loss: 1.875665351908694

Epoch: 5| Step: 8
Training loss: 1.3306139707565308
Validation loss: 1.874272228569113

Epoch: 5| Step: 9
Training loss: 1.3736720085144043
Validation loss: 1.8916018342459073

Epoch: 5| Step: 10
Training loss: 1.3630462884902954
Validation loss: 1.9159443660448956

Epoch: 353| Step: 0
Training loss: 1.41338312625885
Validation loss: 1.9058807947302376

Epoch: 5| Step: 1
Training loss: 1.577284574508667
Validation loss: 1.8647973396444832

Epoch: 5| Step: 2
Training loss: 1.0763189792633057
Validation loss: 1.9219603230876308

Epoch: 5| Step: 3
Training loss: 1.40313720703125
Validation loss: 1.8740369478861492

Epoch: 5| Step: 4
Training loss: 1.3969240188598633
Validation loss: 1.9377688233570387

Epoch: 5| Step: 5
Training loss: 1.5880613327026367
Validation loss: 1.9780013304884716

Epoch: 5| Step: 6
Training loss: 1.7017666101455688
Validation loss: 1.8831332627163138

Epoch: 5| Step: 7
Training loss: 1.554253101348877
Validation loss: 1.9678150415420532

Epoch: 5| Step: 8
Training loss: 1.2549415826797485
Validation loss: 1.919608021295199

Epoch: 5| Step: 9
Training loss: 1.1871836185455322
Validation loss: 1.9207007782433623

Epoch: 5| Step: 10
Training loss: 1.4046707153320312
Validation loss: 1.9181267522996472

Epoch: 354| Step: 0
Training loss: 1.2540298700332642
Validation loss: 1.9004231383723598

Epoch: 5| Step: 1
Training loss: 1.5862247943878174
Validation loss: 1.890184260183765

Epoch: 5| Step: 2
Training loss: 1.20327627658844
Validation loss: 1.9322909001381166

Epoch: 5| Step: 3
Training loss: 1.9299474954605103
Validation loss: 1.8966777504131358

Epoch: 5| Step: 4
Training loss: 1.3505265712738037
Validation loss: 1.9447608429898497

Epoch: 5| Step: 5
Training loss: 2.0234081745147705
Validation loss: 1.9628488838031728

Epoch: 5| Step: 6
Training loss: 1.322339415550232
Validation loss: 1.9186031305661766

Epoch: 5| Step: 7
Training loss: 1.426579236984253
Validation loss: 1.9394484591740433

Epoch: 5| Step: 8
Training loss: 1.501680612564087
Validation loss: 1.9113247420198174

Epoch: 5| Step: 9
Training loss: 1.0118929147720337
Validation loss: 1.9097284655417166

Epoch: 5| Step: 10
Training loss: 1.1949644088745117
Validation loss: 1.9213375250498455

Epoch: 355| Step: 0
Training loss: 1.7025378942489624
Validation loss: 1.9261667138786727

Epoch: 5| Step: 1
Training loss: 1.8806297779083252
Validation loss: 1.9059351400662494

Epoch: 5| Step: 2
Training loss: 1.0211526155471802
Validation loss: 1.8846429304410053

Epoch: 5| Step: 3
Training loss: 1.6467952728271484
Validation loss: 1.9518205683718446

Epoch: 5| Step: 4
Training loss: 1.398983120918274
Validation loss: 1.9321595135555472

Epoch: 5| Step: 5
Training loss: 1.748939871788025
Validation loss: 1.9197772395226262

Epoch: 5| Step: 6
Training loss: 1.597115397453308
Validation loss: 1.8267686533671554

Epoch: 5| Step: 7
Training loss: 0.9554793238639832
Validation loss: 1.9015238977247668

Epoch: 5| Step: 8
Training loss: 1.1037113666534424
Validation loss: 1.8813388975717689

Epoch: 5| Step: 9
Training loss: 1.2055130004882812
Validation loss: 1.8606197962196924

Epoch: 5| Step: 10
Training loss: 1.7258445024490356
Validation loss: 1.8912944024608982

Epoch: 356| Step: 0
Training loss: 1.7208795547485352
Validation loss: 1.9098056362521263

Epoch: 5| Step: 1
Training loss: 1.3719313144683838
Validation loss: 1.9283501576351862

Epoch: 5| Step: 2
Training loss: 1.9105031490325928
Validation loss: 1.9298790295918782

Epoch: 5| Step: 3
Training loss: 1.0906765460968018
Validation loss: 1.9744458890730334

Epoch: 5| Step: 4
Training loss: 1.4723840951919556
Validation loss: 1.9531170962959208

Epoch: 5| Step: 5
Training loss: 1.5115493535995483
Validation loss: 1.987389959314818

Epoch: 5| Step: 6
Training loss: 1.7215321063995361
Validation loss: 1.9267537247750066

Epoch: 5| Step: 7
Training loss: 1.2708781957626343
Validation loss: 1.9947402964356125

Epoch: 5| Step: 8
Training loss: 1.121347427368164
Validation loss: 1.8709591152847453

Epoch: 5| Step: 9
Training loss: 1.2131335735321045
Validation loss: 1.8753633447872695

Epoch: 5| Step: 10
Training loss: 1.7764747142791748
Validation loss: 1.9262659190803446

Epoch: 357| Step: 0
Training loss: 1.1829338073730469
Validation loss: 1.8979145275649203

Epoch: 5| Step: 1
Training loss: 1.2229593992233276
Validation loss: 1.917400578016876

Epoch: 5| Step: 2
Training loss: 1.326677918434143
Validation loss: 1.8822342503455378

Epoch: 5| Step: 3
Training loss: 1.4825646877288818
Validation loss: 1.90519392618569

Epoch: 5| Step: 4
Training loss: 1.5857394933700562
Validation loss: 1.9121807570098548

Epoch: 5| Step: 5
Training loss: 1.562009572982788
Validation loss: 1.9278231449024652

Epoch: 5| Step: 6
Training loss: 1.2709319591522217
Validation loss: 1.9375141794963548

Epoch: 5| Step: 7
Training loss: 1.2359669208526611
Validation loss: 1.9815773810109785

Epoch: 5| Step: 8
Training loss: 1.5620131492614746
Validation loss: 1.8465694227526266

Epoch: 5| Step: 9
Training loss: 1.5911767482757568
Validation loss: 1.8412835559537333

Epoch: 5| Step: 10
Training loss: 1.7870773077011108
Validation loss: 1.9436592491724158

Epoch: 358| Step: 0
Training loss: 1.1878845691680908
Validation loss: 1.9073959512095298

Epoch: 5| Step: 1
Training loss: 1.8396871089935303
Validation loss: 1.8794673745350172

Epoch: 5| Step: 2
Training loss: 1.2633908987045288
Validation loss: 1.8927399099514048

Epoch: 5| Step: 3
Training loss: 1.1525075435638428
Validation loss: 1.934613271426129

Epoch: 5| Step: 4
Training loss: 1.5268787145614624
Validation loss: 1.87782322975897

Epoch: 5| Step: 5
Training loss: 1.4814178943634033
Validation loss: 1.912281132513477

Epoch: 5| Step: 6
Training loss: 1.728515863418579
Validation loss: 1.9142203856539983

Epoch: 5| Step: 7
Training loss: 1.7722008228302002
Validation loss: 1.8670301796287618

Epoch: 5| Step: 8
Training loss: 1.5708786249160767
Validation loss: 1.9508659108992545

Epoch: 5| Step: 9
Training loss: 1.4840108156204224
Validation loss: 1.9233370980908793

Epoch: 5| Step: 10
Training loss: 0.7282165884971619
Validation loss: 1.8885273574500956

Epoch: 359| Step: 0
Training loss: 1.912362813949585
Validation loss: 1.92724129333291

Epoch: 5| Step: 1
Training loss: 1.8277511596679688
Validation loss: 1.9696254114950857

Epoch: 5| Step: 2
Training loss: 1.5193555355072021
Validation loss: 1.9459522296023626

Epoch: 5| Step: 3
Training loss: 0.7862645387649536
Validation loss: 1.9147807628877702

Epoch: 5| Step: 4
Training loss: 0.7347366213798523
Validation loss: 1.9557297422039894

Epoch: 5| Step: 5
Training loss: 1.3495523929595947
Validation loss: 1.8034184837854037

Epoch: 5| Step: 6
Training loss: 1.3802049160003662
Validation loss: 2.0105977827502834

Epoch: 5| Step: 7
Training loss: 1.293664574623108
Validation loss: 1.8921478012556672

Epoch: 5| Step: 8
Training loss: 1.631298303604126
Validation loss: 1.9454403602948753

Epoch: 5| Step: 9
Training loss: 1.6178333759307861
Validation loss: 1.8646416266759236

Epoch: 5| Step: 10
Training loss: 1.8270444869995117
Validation loss: 1.8412472060931626

Epoch: 360| Step: 0
Training loss: 1.6972777843475342
Validation loss: 1.8632564313950077

Epoch: 5| Step: 1
Training loss: 1.4366408586502075
Validation loss: 1.8953291664841354

Epoch: 5| Step: 2
Training loss: 1.1960965394973755
Validation loss: 1.8918146548732635

Epoch: 5| Step: 3
Training loss: 0.8488478660583496
Validation loss: 1.92517226998524

Epoch: 5| Step: 4
Training loss: 1.229823350906372
Validation loss: 1.8807014547368532

Epoch: 5| Step: 5
Training loss: 1.2051746845245361
Validation loss: 1.8607457350659113

Epoch: 5| Step: 6
Training loss: 1.4619313478469849
Validation loss: 1.8736916883017427

Epoch: 5| Step: 7
Training loss: 1.8211021423339844
Validation loss: 1.8843490359603718

Epoch: 5| Step: 8
Training loss: 1.5401217937469482
Validation loss: 1.866227121763332

Epoch: 5| Step: 9
Training loss: 1.2015858888626099
Validation loss: 1.9261086833092473

Epoch: 5| Step: 10
Training loss: 2.3277201652526855
Validation loss: 1.9595099046666136

Epoch: 361| Step: 0
Training loss: 1.2033284902572632
Validation loss: 1.8677593251710296

Epoch: 5| Step: 1
Training loss: 1.5677438974380493
Validation loss: 1.9665438052146667

Epoch: 5| Step: 2
Training loss: 1.4495506286621094
Validation loss: 1.942789384113845

Epoch: 5| Step: 3
Training loss: 1.1726329326629639
Validation loss: 1.920896162268936

Epoch: 5| Step: 4
Training loss: 1.787466049194336
Validation loss: 1.969306722764046

Epoch: 5| Step: 5
Training loss: 1.385837435722351
Validation loss: 1.8838822482734598

Epoch: 5| Step: 6
Training loss: 1.242968201637268
Validation loss: 1.9070513344580127

Epoch: 5| Step: 7
Training loss: 1.146031141281128
Validation loss: 1.9174451328093005

Epoch: 5| Step: 8
Training loss: 1.6953058242797852
Validation loss: 1.9735683100197905

Epoch: 5| Step: 9
Training loss: 1.126920461654663
Validation loss: 1.9002469380696614

Epoch: 5| Step: 10
Training loss: 1.6584665775299072
Validation loss: 1.9388865617013746

Epoch: 362| Step: 0
Training loss: 1.6386492252349854
Validation loss: 1.8993257373891852

Epoch: 5| Step: 1
Training loss: 0.8246554136276245
Validation loss: 1.8632495890381515

Epoch: 5| Step: 2
Training loss: 1.3873450756072998
Validation loss: 1.9504612286885579

Epoch: 5| Step: 3
Training loss: 1.3752250671386719
Validation loss: 1.946814747266872

Epoch: 5| Step: 4
Training loss: 1.513102650642395
Validation loss: 1.858954918000006

Epoch: 5| Step: 5
Training loss: 1.6878719329833984
Validation loss: 1.9353266864694574

Epoch: 5| Step: 6
Training loss: 1.6808292865753174
Validation loss: 1.8930166934126167

Epoch: 5| Step: 7
Training loss: 1.7599010467529297
Validation loss: 1.8832003480644637

Epoch: 5| Step: 8
Training loss: 0.9580461382865906
Validation loss: 1.918230087526383

Epoch: 5| Step: 9
Training loss: 1.1896157264709473
Validation loss: 1.925278708498965

Epoch: 5| Step: 10
Training loss: 1.3662176132202148
Validation loss: 1.8762500222011278

Epoch: 363| Step: 0
Training loss: 1.0392088890075684
Validation loss: 1.8456105493730115

Epoch: 5| Step: 1
Training loss: 1.8647575378417969
Validation loss: 1.8957074842145365

Epoch: 5| Step: 2
Training loss: 1.7834908962249756
Validation loss: 1.8660199590908584

Epoch: 5| Step: 3
Training loss: 1.0920331478118896
Validation loss: 1.9235702432611936

Epoch: 5| Step: 4
Training loss: 1.3609740734100342
Validation loss: 1.930857035421556

Epoch: 5| Step: 5
Training loss: 1.539658784866333
Validation loss: 1.9144336869639735

Epoch: 5| Step: 6
Training loss: 1.3552837371826172
Validation loss: 1.9316176073525542

Epoch: 5| Step: 7
Training loss: 1.417833685874939
Validation loss: 1.9509829218669603

Epoch: 5| Step: 8
Training loss: 1.2862948179244995
Validation loss: 1.8967360770830544

Epoch: 5| Step: 9
Training loss: 1.3394415378570557
Validation loss: 1.9119680158553585

Epoch: 5| Step: 10
Training loss: 1.4066998958587646
Validation loss: 1.9172926615643244

Epoch: 364| Step: 0
Training loss: 1.7981548309326172
Validation loss: 1.907384991645813

Epoch: 5| Step: 1
Training loss: 1.1515469551086426
Validation loss: 1.867802736579731

Epoch: 5| Step: 2
Training loss: 1.0775526762008667
Validation loss: 1.8932572180225002

Epoch: 5| Step: 3
Training loss: 1.091489315032959
Validation loss: 1.8639715102411085

Epoch: 5| Step: 4
Training loss: 1.4290677309036255
Validation loss: 1.8941337959740752

Epoch: 5| Step: 5
Training loss: 1.3360929489135742
Validation loss: 1.8695987885998142

Epoch: 5| Step: 6
Training loss: 1.3597137928009033
Validation loss: 1.9363985523100822

Epoch: 5| Step: 7
Training loss: 1.2214479446411133
Validation loss: 1.9584751385514454

Epoch: 5| Step: 8
Training loss: 1.718189001083374
Validation loss: 1.8541498927659885

Epoch: 5| Step: 9
Training loss: 1.4774852991104126
Validation loss: 1.863422768090361

Epoch: 5| Step: 10
Training loss: 1.8783729076385498
Validation loss: 1.930553452942961

Epoch: 365| Step: 0
Training loss: 1.7900711297988892
Validation loss: 1.886428153643044

Epoch: 5| Step: 1
Training loss: 0.99702388048172
Validation loss: 1.9140198384561846

Epoch: 5| Step: 2
Training loss: 1.401065468788147
Validation loss: 1.9101080458651307

Epoch: 5| Step: 3
Training loss: 1.0400760173797607
Validation loss: 1.914351119790026

Epoch: 5| Step: 4
Training loss: 1.3411033153533936
Validation loss: 1.862588349209037

Epoch: 5| Step: 5
Training loss: 1.6413987874984741
Validation loss: 1.8623672813497565

Epoch: 5| Step: 6
Training loss: 1.6506764888763428
Validation loss: 1.8697808980941772

Epoch: 5| Step: 7
Training loss: 1.2798511981964111
Validation loss: 1.8731634975761495

Epoch: 5| Step: 8
Training loss: 1.6555677652359009
Validation loss: 1.8551244466535506

Epoch: 5| Step: 9
Training loss: 1.278893232345581
Validation loss: 1.8918990345411404

Epoch: 5| Step: 10
Training loss: 1.826849102973938
Validation loss: 1.9049435943685553

Epoch: 366| Step: 0
Training loss: 1.3881945610046387
Validation loss: 1.9078929373013076

Epoch: 5| Step: 1
Training loss: 0.900346577167511
Validation loss: 1.8636194070180256

Epoch: 5| Step: 2
Training loss: 1.9939587116241455
Validation loss: 1.9004827776262838

Epoch: 5| Step: 3
Training loss: 1.1267963647842407
Validation loss: 1.8929697762253463

Epoch: 5| Step: 4
Training loss: 1.1925413608551025
Validation loss: 1.894382671643329

Epoch: 5| Step: 5
Training loss: 1.287786841392517
Validation loss: 1.9355089690095635

Epoch: 5| Step: 6
Training loss: 1.6453545093536377
Validation loss: 2.0300167491359096

Epoch: 5| Step: 7
Training loss: 1.3624632358551025
Validation loss: 2.0073763606368855

Epoch: 5| Step: 8
Training loss: 1.211382269859314
Validation loss: 2.0258501011838197

Epoch: 5| Step: 9
Training loss: 1.8668804168701172
Validation loss: 1.98771406245488

Epoch: 5| Step: 10
Training loss: 1.6108916997909546
Validation loss: 1.9316245561004968

Epoch: 367| Step: 0
Training loss: 1.6958757638931274
Validation loss: 1.9705781552099413

Epoch: 5| Step: 1
Training loss: 1.5190715789794922
Validation loss: 1.9725149652009368

Epoch: 5| Step: 2
Training loss: 1.1466717720031738
Validation loss: 1.996141892607494

Epoch: 5| Step: 3
Training loss: 1.0279371738433838
Validation loss: 1.9393601468814317

Epoch: 5| Step: 4
Training loss: 1.3325695991516113
Validation loss: 1.9058523139645975

Epoch: 5| Step: 5
Training loss: 1.4673430919647217
Validation loss: 1.9308908216414913

Epoch: 5| Step: 6
Training loss: 1.6616321802139282
Validation loss: 1.8860829825042396

Epoch: 5| Step: 7
Training loss: 0.934577465057373
Validation loss: 1.893319631135592

Epoch: 5| Step: 8
Training loss: 1.402916431427002
Validation loss: 1.89128355826101

Epoch: 5| Step: 9
Training loss: 1.2018858194351196
Validation loss: 1.8669597179658952

Epoch: 5| Step: 10
Training loss: 1.7038644552230835
Validation loss: 1.869093136120868

Epoch: 368| Step: 0
Training loss: 1.2886592149734497
Validation loss: 1.8522659745267642

Epoch: 5| Step: 1
Training loss: 1.7739101648330688
Validation loss: 1.9164381360494962

Epoch: 5| Step: 2
Training loss: 1.9714939594268799
Validation loss: 1.8526375357822706

Epoch: 5| Step: 3
Training loss: 1.0840628147125244
Validation loss: 1.839707710409677

Epoch: 5| Step: 4
Training loss: 1.6032450199127197
Validation loss: 1.911248863384288

Epoch: 5| Step: 5
Training loss: 1.918707251548767
Validation loss: 1.8647227928202639

Epoch: 5| Step: 6
Training loss: 1.1845636367797852
Validation loss: 1.8538320449090773

Epoch: 5| Step: 7
Training loss: 0.9093425869941711
Validation loss: 1.8958334781790291

Epoch: 5| Step: 8
Training loss: 1.0163599252700806
Validation loss: 1.8772890208869852

Epoch: 5| Step: 9
Training loss: 1.345338225364685
Validation loss: 1.922572273080067

Epoch: 5| Step: 10
Training loss: 1.2887786626815796
Validation loss: 1.8993137421146515

Epoch: 369| Step: 0
Training loss: 1.7160999774932861
Validation loss: 1.892117343923097

Epoch: 5| Step: 1
Training loss: 1.1150912046432495
Validation loss: 1.932953421787549

Epoch: 5| Step: 2
Training loss: 0.7302191853523254
Validation loss: 1.9232011495097991

Epoch: 5| Step: 3
Training loss: 1.7907310724258423
Validation loss: 1.950650340767317

Epoch: 5| Step: 4
Training loss: 1.5374115705490112
Validation loss: 1.8782341967346847

Epoch: 5| Step: 5
Training loss: 1.169222116470337
Validation loss: 1.9018301745896697

Epoch: 5| Step: 6
Training loss: 1.3639425039291382
Validation loss: 1.9330040524082799

Epoch: 5| Step: 7
Training loss: 1.299621820449829
Validation loss: 1.9825452630237868

Epoch: 5| Step: 8
Training loss: 1.605254888534546
Validation loss: 1.8984991222299554

Epoch: 5| Step: 9
Training loss: 1.975450873374939
Validation loss: 1.9220272302627563

Epoch: 5| Step: 10
Training loss: 1.2500736713409424
Validation loss: 1.8863987192030875

Epoch: 370| Step: 0
Training loss: 1.2572284936904907
Validation loss: 1.9111214132719143

Epoch: 5| Step: 1
Training loss: 1.815700888633728
Validation loss: 1.9459286658994612

Epoch: 5| Step: 2
Training loss: 0.9880638122558594
Validation loss: 1.915272681943832

Epoch: 5| Step: 3
Training loss: 1.6380064487457275
Validation loss: 1.952265642022574

Epoch: 5| Step: 4
Training loss: 0.9556692242622375
Validation loss: 1.872476952050322

Epoch: 5| Step: 5
Training loss: 0.910069465637207
Validation loss: 1.8683490189172889

Epoch: 5| Step: 6
Training loss: 1.4380336999893188
Validation loss: 1.8610854200137559

Epoch: 5| Step: 7
Training loss: 1.995231032371521
Validation loss: 1.872046677015161

Epoch: 5| Step: 8
Training loss: 1.5501312017440796
Validation loss: 1.9101142767936952

Epoch: 5| Step: 9
Training loss: 1.3489079475402832
Validation loss: 1.8970997256617392

Epoch: 5| Step: 10
Training loss: 1.2108137607574463
Validation loss: 1.908110766000645

Epoch: 371| Step: 0
Training loss: 1.5062758922576904
Validation loss: 1.8443434212797432

Epoch: 5| Step: 1
Training loss: 1.6331493854522705
Validation loss: 1.8806097353658369

Epoch: 5| Step: 2
Training loss: 1.7788946628570557
Validation loss: 1.9266763220551193

Epoch: 5| Step: 3
Training loss: 1.4850647449493408
Validation loss: 1.9120508740025182

Epoch: 5| Step: 4
Training loss: 1.6216093301773071
Validation loss: 1.8739269382210189

Epoch: 5| Step: 5
Training loss: 1.1210625171661377
Validation loss: 1.8830608321774391

Epoch: 5| Step: 6
Training loss: 1.3945457935333252
Validation loss: 1.8633802603649836

Epoch: 5| Step: 7
Training loss: 1.0638129711151123
Validation loss: 1.8938678259490638

Epoch: 5| Step: 8
Training loss: 1.625520944595337
Validation loss: 1.890389447571129

Epoch: 5| Step: 9
Training loss: 0.8849560618400574
Validation loss: 1.9592012461795603

Epoch: 5| Step: 10
Training loss: 1.2421365976333618
Validation loss: 1.888474516971137

Epoch: 372| Step: 0
Training loss: 1.8064390420913696
Validation loss: 2.012981491704141

Epoch: 5| Step: 1
Training loss: 1.1245322227478027
Validation loss: 1.8877691607321463

Epoch: 5| Step: 2
Training loss: 1.3791816234588623
Validation loss: 1.8927449885235037

Epoch: 5| Step: 3
Training loss: 1.6684274673461914
Validation loss: 1.958057168991335

Epoch: 5| Step: 4
Training loss: 1.688348412513733
Validation loss: 1.9328457796445457

Epoch: 5| Step: 5
Training loss: 0.9030478596687317
Validation loss: 1.9079832876882246

Epoch: 5| Step: 6
Training loss: 1.2969319820404053
Validation loss: 2.0018835272840274

Epoch: 5| Step: 7
Training loss: 0.8639667630195618
Validation loss: 1.9268490229883501

Epoch: 5| Step: 8
Training loss: 1.0988166332244873
Validation loss: 1.846050912334073

Epoch: 5| Step: 9
Training loss: 1.0971527099609375
Validation loss: 1.870258697899439

Epoch: 5| Step: 10
Training loss: 2.1434097290039062
Validation loss: 1.8729323341000466

Epoch: 373| Step: 0
Training loss: 1.1888009309768677
Validation loss: 1.9140301801825081

Epoch: 5| Step: 1
Training loss: 1.3657582998275757
Validation loss: 1.8548659893774218

Epoch: 5| Step: 2
Training loss: 1.5144609212875366
Validation loss: 1.8499173336131598

Epoch: 5| Step: 3
Training loss: 1.0643136501312256
Validation loss: 1.908449206300961

Epoch: 5| Step: 4
Training loss: 1.6240100860595703
Validation loss: 1.8699673362957534

Epoch: 5| Step: 5
Training loss: 1.3835852146148682
Validation loss: 1.8950361051867086

Epoch: 5| Step: 6
Training loss: 1.751302719116211
Validation loss: 1.8656622568766277

Epoch: 5| Step: 7
Training loss: 1.5618953704833984
Validation loss: 1.820426087225637

Epoch: 5| Step: 8
Training loss: 0.949812114238739
Validation loss: 1.8314508340692008

Epoch: 5| Step: 9
Training loss: 1.600756287574768
Validation loss: 1.8945189573431527

Epoch: 5| Step: 10
Training loss: 1.0975449085235596
Validation loss: 1.8558288466545843

Epoch: 374| Step: 0
Training loss: 1.8936541080474854
Validation loss: 1.8715693899380264

Epoch: 5| Step: 1
Training loss: 1.0676116943359375
Validation loss: 1.9462581347393733

Epoch: 5| Step: 2
Training loss: 1.280514121055603
Validation loss: 1.844441706134427

Epoch: 5| Step: 3
Training loss: 1.0775903463363647
Validation loss: 1.8219385480368009

Epoch: 5| Step: 4
Training loss: 1.424628496170044
Validation loss: 1.8663341101779733

Epoch: 5| Step: 5
Training loss: 1.3002222776412964
Validation loss: 1.8839136720985494

Epoch: 5| Step: 6
Training loss: 1.357777714729309
Validation loss: 1.8366286767426359

Epoch: 5| Step: 7
Training loss: 1.286726713180542
Validation loss: 1.8541355286875079

Epoch: 5| Step: 8
Training loss: 1.1548054218292236
Validation loss: 1.8418057400693175

Epoch: 5| Step: 9
Training loss: 1.3716233968734741
Validation loss: 1.8849153223858084

Epoch: 5| Step: 10
Training loss: 1.9551057815551758
Validation loss: 1.911306570934993

Epoch: 375| Step: 0
Training loss: 1.4480934143066406
Validation loss: 1.8876309446109238

Epoch: 5| Step: 1
Training loss: 0.9081800580024719
Validation loss: 1.9095686571572417

Epoch: 5| Step: 2
Training loss: 1.5111932754516602
Validation loss: 1.890496729522623

Epoch: 5| Step: 3
Training loss: 0.7367805242538452
Validation loss: 1.8887201688622917

Epoch: 5| Step: 4
Training loss: 1.5427299737930298
Validation loss: 1.9027893209970126

Epoch: 5| Step: 5
Training loss: 1.209519624710083
Validation loss: 1.90697100598325

Epoch: 5| Step: 6
Training loss: 1.5761054754257202
Validation loss: 1.8469419671643166

Epoch: 5| Step: 7
Training loss: 1.5215222835540771
Validation loss: 1.982764672207576

Epoch: 5| Step: 8
Training loss: 1.648537039756775
Validation loss: 1.8675912452000443

Epoch: 5| Step: 9
Training loss: 1.415029525756836
Validation loss: 1.9357727099490423

Epoch: 5| Step: 10
Training loss: 1.5251590013504028
Validation loss: 1.8823045428081224

Epoch: 376| Step: 0
Training loss: 1.5443580150604248
Validation loss: 1.8976492779229277

Epoch: 5| Step: 1
Training loss: 1.8479735851287842
Validation loss: 1.896890478749429

Epoch: 5| Step: 2
Training loss: 1.3635598421096802
Validation loss: 1.9660465973679737

Epoch: 5| Step: 3
Training loss: 1.6077896356582642
Validation loss: 1.9852902568796629

Epoch: 5| Step: 4
Training loss: 1.4607367515563965
Validation loss: 1.9891293510313957

Epoch: 5| Step: 5
Training loss: 0.9604722857475281
Validation loss: 1.8736009777233165

Epoch: 5| Step: 6
Training loss: 1.5347867012023926
Validation loss: 1.915624628784836

Epoch: 5| Step: 7
Training loss: 0.8314081430435181
Validation loss: 1.9002717887201617

Epoch: 5| Step: 8
Training loss: 1.4074938297271729
Validation loss: 1.9221026923066826

Epoch: 5| Step: 9
Training loss: 1.397222876548767
Validation loss: 1.9174667789090065

Epoch: 5| Step: 10
Training loss: 1.0416712760925293
Validation loss: 1.8715545926042783

Epoch: 377| Step: 0
Training loss: 1.4758579730987549
Validation loss: 1.9035797324231876

Epoch: 5| Step: 1
Training loss: 1.432358980178833
Validation loss: 1.9462428823594125

Epoch: 5| Step: 2
Training loss: 1.6421842575073242
Validation loss: 1.8842282243954238

Epoch: 5| Step: 3
Training loss: 1.868711233139038
Validation loss: 1.900270995273385

Epoch: 5| Step: 4
Training loss: 0.7677723169326782
Validation loss: 1.8862178197471045

Epoch: 5| Step: 5
Training loss: 1.532509446144104
Validation loss: 1.8379685609571395

Epoch: 5| Step: 6
Training loss: 1.2285971641540527
Validation loss: 1.8657245994896017

Epoch: 5| Step: 7
Training loss: 0.9444897770881653
Validation loss: 1.9003170664592455

Epoch: 5| Step: 8
Training loss: 1.162400245666504
Validation loss: 1.884703182405041

Epoch: 5| Step: 9
Training loss: 1.5466506481170654
Validation loss: 1.91965050466599

Epoch: 5| Step: 10
Training loss: 1.4575955867767334
Validation loss: 1.8626464707877046

Epoch: 378| Step: 0
Training loss: 0.9852530360221863
Validation loss: 1.9443756277843187

Epoch: 5| Step: 1
Training loss: 1.5819944143295288
Validation loss: 1.9481999425477878

Epoch: 5| Step: 2
Training loss: 0.9143959283828735
Validation loss: 1.9169423528896865

Epoch: 5| Step: 3
Training loss: 1.6840022802352905
Validation loss: 1.8556923199725408

Epoch: 5| Step: 4
Training loss: 1.2978057861328125
Validation loss: 1.9112375461927025

Epoch: 5| Step: 5
Training loss: 1.336425542831421
Validation loss: 1.9402464538492181

Epoch: 5| Step: 6
Training loss: 1.7427088022232056
Validation loss: 1.9434998830159504

Epoch: 5| Step: 7
Training loss: 1.4024633169174194
Validation loss: 1.896189690918051

Epoch: 5| Step: 8
Training loss: 1.2883071899414062
Validation loss: 1.838725177190637

Epoch: 5| Step: 9
Training loss: 1.3034273386001587
Validation loss: 1.9264425052109586

Epoch: 5| Step: 10
Training loss: 1.2945530414581299
Validation loss: 1.9031700267586658

Epoch: 379| Step: 0
Training loss: 1.0261952877044678
Validation loss: 1.8879965018200617

Epoch: 5| Step: 1
Training loss: 1.6332330703735352
Validation loss: 1.9308724480290567

Epoch: 5| Step: 2
Training loss: 1.6549708843231201
Validation loss: 1.9246808072572112

Epoch: 5| Step: 3
Training loss: 1.3053193092346191
Validation loss: 1.8629769304747223

Epoch: 5| Step: 4
Training loss: 1.6114600896835327
Validation loss: 1.8397663895801832

Epoch: 5| Step: 5
Training loss: 0.7658637166023254
Validation loss: 1.9700055673558226

Epoch: 5| Step: 6
Training loss: 1.142976999282837
Validation loss: 1.9358236123156805

Epoch: 5| Step: 7
Training loss: 1.0097259283065796
Validation loss: 1.8949847811011857

Epoch: 5| Step: 8
Training loss: 1.4047127962112427
Validation loss: 1.9088666990239134

Epoch: 5| Step: 9
Training loss: 1.3932610750198364
Validation loss: 1.867173974232007

Epoch: 5| Step: 10
Training loss: 1.9102531671524048
Validation loss: 1.8791421216021302

Epoch: 380| Step: 0
Training loss: 0.8565486669540405
Validation loss: 1.917218949205132

Epoch: 5| Step: 1
Training loss: 0.8099158406257629
Validation loss: 1.9143308080652708

Epoch: 5| Step: 2
Training loss: 1.7744220495224
Validation loss: 1.916507726074547

Epoch: 5| Step: 3
Training loss: 1.589989423751831
Validation loss: 1.8827320157840688

Epoch: 5| Step: 4
Training loss: 1.4576575756072998
Validation loss: 1.859915194972869

Epoch: 5| Step: 5
Training loss: 1.2605375051498413
Validation loss: 1.955003289766209

Epoch: 5| Step: 6
Training loss: 1.2931005954742432
Validation loss: 1.9078893417953162

Epoch: 5| Step: 7
Training loss: 2.11358380317688
Validation loss: 1.9174406477200088

Epoch: 5| Step: 8
Training loss: 1.4185231924057007
Validation loss: 1.9438344906735163

Epoch: 5| Step: 9
Training loss: 1.0196492671966553
Validation loss: 1.941663686947156

Epoch: 5| Step: 10
Training loss: 1.4433012008666992
Validation loss: 1.913123519189896

Epoch: 381| Step: 0
Training loss: 0.8862774968147278
Validation loss: 1.8590819476753153

Epoch: 5| Step: 1
Training loss: 1.5355677604675293
Validation loss: 1.891165194972869

Epoch: 5| Step: 2
Training loss: 1.3882519006729126
Validation loss: 1.87786816781567

Epoch: 5| Step: 3
Training loss: 0.9419177174568176
Validation loss: 1.8631173641450944

Epoch: 5| Step: 4
Training loss: 0.9848495721817017
Validation loss: 1.8263686549278997

Epoch: 5| Step: 5
Training loss: 1.323743462562561
Validation loss: 1.8370568124196862

Epoch: 5| Step: 6
Training loss: 1.5437686443328857
Validation loss: 1.825797616794545

Epoch: 5| Step: 7
Training loss: 1.4543726444244385
Validation loss: 1.8326789268883326

Epoch: 5| Step: 8
Training loss: 1.7913967370986938
Validation loss: 1.9329833125555387

Epoch: 5| Step: 9
Training loss: 1.5857642889022827
Validation loss: 1.8767465993922243

Epoch: 5| Step: 10
Training loss: 1.469027042388916
Validation loss: 1.9114380677541096

Epoch: 382| Step: 0
Training loss: 1.3486177921295166
Validation loss: 1.893696440163479

Epoch: 5| Step: 1
Training loss: 2.002478837966919
Validation loss: 1.9249001779863912

Epoch: 5| Step: 2
Training loss: 0.8305211067199707
Validation loss: 1.8633436592676307

Epoch: 5| Step: 3
Training loss: 1.0486443042755127
Validation loss: 1.8767886443804669

Epoch: 5| Step: 4
Training loss: 1.2317254543304443
Validation loss: 1.9430291242496942

Epoch: 5| Step: 5
Training loss: 1.6633154153823853
Validation loss: 1.8898079023566297

Epoch: 5| Step: 6
Training loss: 1.497053861618042
Validation loss: 1.9492024144818705

Epoch: 5| Step: 7
Training loss: 1.4952439069747925
Validation loss: 1.970558063958281

Epoch: 5| Step: 8
Training loss: 1.7226142883300781
Validation loss: 1.8940379696507608

Epoch: 5| Step: 9
Training loss: 1.5267605781555176
Validation loss: 1.9507898284542946

Epoch: 5| Step: 10
Training loss: 0.6391768455505371
Validation loss: 1.792384393753544

Epoch: 383| Step: 0
Training loss: 1.5032576322555542
Validation loss: 1.8982713632686163

Epoch: 5| Step: 1
Training loss: 1.3886545896530151
Validation loss: 1.9310730400905813

Epoch: 5| Step: 2
Training loss: 2.0142900943756104
Validation loss: 1.9121760911838983

Epoch: 5| Step: 3
Training loss: 1.255433201789856
Validation loss: 1.8686439837178876

Epoch: 5| Step: 4
Training loss: 1.34380042552948
Validation loss: 1.8478603439946328

Epoch: 5| Step: 5
Training loss: 1.3403027057647705
Validation loss: 1.9311216736352572

Epoch: 5| Step: 6
Training loss: 0.922059178352356
Validation loss: 1.8369035079915037

Epoch: 5| Step: 7
Training loss: 1.548514485359192
Validation loss: 1.8140372730070544

Epoch: 5| Step: 8
Training loss: 0.8278293609619141
Validation loss: 1.8906668898879841

Epoch: 5| Step: 9
Training loss: 1.3784135580062866
Validation loss: 1.8357593628668016

Epoch: 5| Step: 10
Training loss: 1.6134612560272217
Validation loss: 1.881332259024343

Epoch: 384| Step: 0
Training loss: 1.4099138975143433
Validation loss: 1.8484433030569425

Epoch: 5| Step: 1
Training loss: 0.971417248249054
Validation loss: 1.9071250423308341

Epoch: 5| Step: 2
Training loss: 1.1754295825958252
Validation loss: 1.9294023052338631

Epoch: 5| Step: 3
Training loss: 1.2637388706207275
Validation loss: 1.9667618620780207

Epoch: 5| Step: 4
Training loss: 1.5093008279800415
Validation loss: 1.8866150122816845

Epoch: 5| Step: 5
Training loss: 1.6706956624984741
Validation loss: 1.9161591824664865

Epoch: 5| Step: 6
Training loss: 1.2682790756225586
Validation loss: 1.917578984332341

Epoch: 5| Step: 7
Training loss: 1.6319968700408936
Validation loss: 1.9028224278521795

Epoch: 5| Step: 8
Training loss: 1.298084020614624
Validation loss: 1.8769924320200437

Epoch: 5| Step: 9
Training loss: 1.3081426620483398
Validation loss: 1.9031460477459816

Epoch: 5| Step: 10
Training loss: 1.3853102922439575
Validation loss: 1.9018669359145626

Epoch: 385| Step: 0
Training loss: 1.0349667072296143
Validation loss: 1.8596944014231365

Epoch: 5| Step: 1
Training loss: 1.5828580856323242
Validation loss: 1.8590422830274027

Epoch: 5| Step: 2
Training loss: 1.1828224658966064
Validation loss: 1.8432728039321078

Epoch: 5| Step: 3
Training loss: 1.2218315601348877
Validation loss: 1.9398761039139123

Epoch: 5| Step: 4
Training loss: 1.966320276260376
Validation loss: 1.8794666644065612

Epoch: 5| Step: 5
Training loss: 1.3640124797821045
Validation loss: 1.8454621171438566

Epoch: 5| Step: 6
Training loss: 1.5209324359893799
Validation loss: 1.870542239117366

Epoch: 5| Step: 7
Training loss: 1.5317360162734985
Validation loss: 1.869061900723365

Epoch: 5| Step: 8
Training loss: 0.996806800365448
Validation loss: 1.8293282947232645

Epoch: 5| Step: 9
Training loss: 1.331117033958435
Validation loss: 1.8601543723895986

Epoch: 5| Step: 10
Training loss: 1.5273538827896118
Validation loss: 1.927498717461863

Epoch: 386| Step: 0
Training loss: 1.357176423072815
Validation loss: 1.907877246538798

Epoch: 5| Step: 1
Training loss: 1.377041220664978
Validation loss: 1.9336738829971643

Epoch: 5| Step: 2
Training loss: 1.4181514978408813
Validation loss: 1.9992911072187527

Epoch: 5| Step: 3
Training loss: 1.4522813558578491
Validation loss: 1.9531569275804745

Epoch: 5| Step: 4
Training loss: 1.1772048473358154
Validation loss: 1.9884750881502706

Epoch: 5| Step: 5
Training loss: 2.054673671722412
Validation loss: 1.9255126983888688

Epoch: 5| Step: 6
Training loss: 0.9809175729751587
Validation loss: 1.911252312762763

Epoch: 5| Step: 7
Training loss: 0.9465397000312805
Validation loss: 1.9153968877689813

Epoch: 5| Step: 8
Training loss: 1.445340871810913
Validation loss: 1.9677161503863592

Epoch: 5| Step: 9
Training loss: 1.2828435897827148
Validation loss: 1.8797236514347855

Epoch: 5| Step: 10
Training loss: 1.4834175109863281
Validation loss: 1.9425461407630675

Epoch: 387| Step: 0
Training loss: 1.0956966876983643
Validation loss: 1.8786489232893913

Epoch: 5| Step: 1
Training loss: 1.423885703086853
Validation loss: 1.9146965421656126

Epoch: 5| Step: 2
Training loss: 0.865390419960022
Validation loss: 1.8187280765143774

Epoch: 5| Step: 3
Training loss: 1.8432881832122803
Validation loss: 1.8833663796865812

Epoch: 5| Step: 4
Training loss: 1.6828724145889282
Validation loss: 1.8742213864480295

Epoch: 5| Step: 5
Training loss: 1.1545120477676392
Validation loss: 1.9126796824957735

Epoch: 5| Step: 6
Training loss: 1.4194620847702026
Validation loss: 1.83748116929044

Epoch: 5| Step: 7
Training loss: 0.8590354919433594
Validation loss: 1.8837347594640588

Epoch: 5| Step: 8
Training loss: 1.7703044414520264
Validation loss: 1.9308145738417102

Epoch: 5| Step: 9
Training loss: 1.433382511138916
Validation loss: 1.8501496238093222

Epoch: 5| Step: 10
Training loss: 1.2762764692306519
Validation loss: 1.9087582108795003

Epoch: 388| Step: 0
Training loss: 1.0209856033325195
Validation loss: 1.8575985329125517

Epoch: 5| Step: 1
Training loss: 1.2136297225952148
Validation loss: 1.9198583159395444

Epoch: 5| Step: 2
Training loss: 1.4980475902557373
Validation loss: 1.8905405934138964

Epoch: 5| Step: 3
Training loss: 1.3797885179519653
Validation loss: 1.8520079569150043

Epoch: 5| Step: 4
Training loss: 1.2912445068359375
Validation loss: 1.8817404290681243

Epoch: 5| Step: 5
Training loss: 1.046126127243042
Validation loss: 1.8226534743462839

Epoch: 5| Step: 6
Training loss: 1.552083969116211
Validation loss: 1.856273175567709

Epoch: 5| Step: 7
Training loss: 1.945347547531128
Validation loss: 1.8640330811982513

Epoch: 5| Step: 8
Training loss: 1.952880620956421
Validation loss: 1.8949860629215036

Epoch: 5| Step: 9
Training loss: 0.7380053400993347
Validation loss: 1.8870391781612108

Epoch: 5| Step: 10
Training loss: 1.1687707901000977
Validation loss: 1.8037720828927972

Epoch: 389| Step: 0
Training loss: 1.2584422826766968
Validation loss: 1.8703577672281573

Epoch: 5| Step: 1
Training loss: 1.8300539255142212
Validation loss: 1.858731815891881

Epoch: 5| Step: 2
Training loss: 1.4009504318237305
Validation loss: 1.859812621147402

Epoch: 5| Step: 3
Training loss: 1.3244428634643555
Validation loss: 1.9039818497114285

Epoch: 5| Step: 4
Training loss: 1.470137357711792
Validation loss: 1.8596670755776026

Epoch: 5| Step: 5
Training loss: 1.2952687740325928
Validation loss: 1.8608890848775064

Epoch: 5| Step: 6
Training loss: 1.2372349500656128
Validation loss: 1.8573535642316263

Epoch: 5| Step: 7
Training loss: 1.2952402830123901
Validation loss: 1.924844484175405

Epoch: 5| Step: 8
Training loss: 1.1878855228424072
Validation loss: 1.9264116030867382

Epoch: 5| Step: 9
Training loss: 1.732805609703064
Validation loss: 1.8913384945161882

Epoch: 5| Step: 10
Training loss: 0.6568427085876465
Validation loss: 1.8719786764473043

Epoch: 390| Step: 0
Training loss: 1.1668401956558228
Validation loss: 1.9048544822200653

Epoch: 5| Step: 1
Training loss: 1.2022168636322021
Validation loss: 1.8326633425169094

Epoch: 5| Step: 2
Training loss: 1.3186709880828857
Validation loss: 1.8163064167063723

Epoch: 5| Step: 3
Training loss: 1.3929312229156494
Validation loss: 1.8796792363607755

Epoch: 5| Step: 4
Training loss: 1.3505280017852783
Validation loss: 1.917076438985845

Epoch: 5| Step: 5
Training loss: 1.2234041690826416
Validation loss: 1.8866975615101476

Epoch: 5| Step: 6
Training loss: 1.7686595916748047
Validation loss: 1.9339281269299087

Epoch: 5| Step: 7
Training loss: 1.5138496160507202
Validation loss: 1.812021473402618

Epoch: 5| Step: 8
Training loss: 0.8952262997627258
Validation loss: 1.8909924581486692

Epoch: 5| Step: 9
Training loss: 1.5419538021087646
Validation loss: 1.8209668897813367

Epoch: 5| Step: 10
Training loss: 1.4486112594604492
Validation loss: 1.9214587493609356

Epoch: 391| Step: 0
Training loss: 1.886461615562439
Validation loss: 1.829338747967956

Epoch: 5| Step: 1
Training loss: 1.476952314376831
Validation loss: 1.848133280713071

Epoch: 5| Step: 2
Training loss: 0.9421420097351074
Validation loss: 1.8302118470591884

Epoch: 5| Step: 3
Training loss: 0.9344323873519897
Validation loss: 1.8739010492960613

Epoch: 5| Step: 4
Training loss: 1.1783411502838135
Validation loss: 1.8694269464861961

Epoch: 5| Step: 5
Training loss: 1.1204261779785156
Validation loss: 1.8669374706924602

Epoch: 5| Step: 6
Training loss: 1.361154556274414
Validation loss: 1.8706835200709682

Epoch: 5| Step: 7
Training loss: 1.706825613975525
Validation loss: 1.8730107353579613

Epoch: 5| Step: 8
Training loss: 1.5701957941055298
Validation loss: 1.9034767317515549

Epoch: 5| Step: 9
Training loss: 1.2723469734191895
Validation loss: 1.8864873263143724

Epoch: 5| Step: 10
Training loss: 1.1477010250091553
Validation loss: 1.903873493594508

Epoch: 392| Step: 0
Training loss: 1.1650428771972656
Validation loss: 1.8562581218698972

Epoch: 5| Step: 1
Training loss: 1.9636318683624268
Validation loss: 1.926262209492345

Epoch: 5| Step: 2
Training loss: 1.2980225086212158
Validation loss: 1.8977979844616306

Epoch: 5| Step: 3
Training loss: 0.9767297506332397
Validation loss: 1.9500292167868665

Epoch: 5| Step: 4
Training loss: 1.902382254600525
Validation loss: 1.9009849115084576

Epoch: 5| Step: 5
Training loss: 1.2893421649932861
Validation loss: 1.9555440295127131

Epoch: 5| Step: 6
Training loss: 1.237723469734192
Validation loss: 1.8571415511510705

Epoch: 5| Step: 7
Training loss: 1.1416122913360596
Validation loss: 1.9047735070669523

Epoch: 5| Step: 8
Training loss: 1.2463053464889526
Validation loss: 1.9124391924950384

Epoch: 5| Step: 9
Training loss: 1.4383032321929932
Validation loss: 1.8506516384822067

Epoch: 5| Step: 10
Training loss: 1.4393534660339355
Validation loss: 1.8334115230908958

Epoch: 393| Step: 0
Training loss: 1.448382019996643
Validation loss: 1.8300817628060617

Epoch: 5| Step: 1
Training loss: 1.2258734703063965
Validation loss: 1.8006410444936445

Epoch: 5| Step: 2
Training loss: 1.4841601848602295
Validation loss: 1.8961863069124119

Epoch: 5| Step: 3
Training loss: 1.159918189048767
Validation loss: 1.8171961922799387

Epoch: 5| Step: 4
Training loss: 0.7444378733634949
Validation loss: 1.8769988731671405

Epoch: 5| Step: 5
Training loss: 1.407057523727417
Validation loss: 1.8632953846326439

Epoch: 5| Step: 6
Training loss: 1.7401549816131592
Validation loss: 1.8626764564103977

Epoch: 5| Step: 7
Training loss: 0.9410978555679321
Validation loss: 1.876634966942572

Epoch: 5| Step: 8
Training loss: 1.8395793437957764
Validation loss: 1.8340470995954288

Epoch: 5| Step: 9
Training loss: 1.3323688507080078
Validation loss: 1.8335138367068382

Epoch: 5| Step: 10
Training loss: 1.0636008977890015
Validation loss: 1.8400972850861088

Epoch: 394| Step: 0
Training loss: 1.4346764087677002
Validation loss: 1.8395051135811755

Epoch: 5| Step: 1
Training loss: 1.7738122940063477
Validation loss: 1.8705510759866366

Epoch: 5| Step: 2
Training loss: 1.155898094177246
Validation loss: 1.8279532488956247

Epoch: 5| Step: 3
Training loss: 1.2374470233917236
Validation loss: 1.8585757722136795

Epoch: 5| Step: 4
Training loss: 1.2085117101669312
Validation loss: 1.8739701522293912

Epoch: 5| Step: 5
Training loss: 1.2586700916290283
Validation loss: 1.9170512089165308

Epoch: 5| Step: 6
Training loss: 1.4423495531082153
Validation loss: 1.8895962648494269

Epoch: 5| Step: 7
Training loss: 1.16115403175354
Validation loss: 1.9161993098515335

Epoch: 5| Step: 8
Training loss: 1.8242390155792236
Validation loss: 1.9145394102219613

Epoch: 5| Step: 9
Training loss: 0.7001504302024841
Validation loss: 1.9620864237508466

Epoch: 5| Step: 10
Training loss: 1.153306007385254
Validation loss: 1.9294320011651644

Epoch: 395| Step: 0
Training loss: 1.7598321437835693
Validation loss: 1.9014669105570803

Epoch: 5| Step: 1
Training loss: 0.8837512135505676
Validation loss: 1.8871320806523806

Epoch: 5| Step: 2
Training loss: 1.0601413249969482
Validation loss: 1.8980252576130692

Epoch: 5| Step: 3
Training loss: 1.6498161554336548
Validation loss: 1.8899513726593347

Epoch: 5| Step: 4
Training loss: 1.433873176574707
Validation loss: 1.9008410002595635

Epoch: 5| Step: 5
Training loss: 1.1271352767944336
Validation loss: 1.8353569917781378

Epoch: 5| Step: 6
Training loss: 1.1083166599273682
Validation loss: 1.8629963833798644

Epoch: 5| Step: 7
Training loss: 1.1345053911209106
Validation loss: 1.8602409029519686

Epoch: 5| Step: 8
Training loss: 1.1468719244003296
Validation loss: 1.8302627225075998

Epoch: 5| Step: 9
Training loss: 1.9806197881698608
Validation loss: 1.83809793508181

Epoch: 5| Step: 10
Training loss: 1.5639854669570923
Validation loss: 1.8667202072758828

Epoch: 396| Step: 0
Training loss: 1.5117977857589722
Validation loss: 1.873513190977035

Epoch: 5| Step: 1
Training loss: 0.986706554889679
Validation loss: 1.8598642323606758

Epoch: 5| Step: 2
Training loss: 1.1889925003051758
Validation loss: 1.8317272701571066

Epoch: 5| Step: 3
Training loss: 1.6821321249008179
Validation loss: 1.8859633207321167

Epoch: 5| Step: 4
Training loss: 1.2376551628112793
Validation loss: 1.8484860645827426

Epoch: 5| Step: 5
Training loss: 1.5533393621444702
Validation loss: 1.79946223638391

Epoch: 5| Step: 6
Training loss: 1.298504114151001
Validation loss: 1.9322819004776657

Epoch: 5| Step: 7
Training loss: 1.1899964809417725
Validation loss: 1.8341877178479267

Epoch: 5| Step: 8
Training loss: 1.6300315856933594
Validation loss: 1.8514230238494052

Epoch: 5| Step: 9
Training loss: 1.0871256589889526
Validation loss: 1.864416822310417

Epoch: 5| Step: 10
Training loss: 1.4705491065979004
Validation loss: 1.8632617060856154

Epoch: 397| Step: 0
Training loss: 1.250581979751587
Validation loss: 1.8254729393989808

Epoch: 5| Step: 1
Training loss: 1.129887580871582
Validation loss: 1.882834739582513

Epoch: 5| Step: 2
Training loss: 1.751477837562561
Validation loss: 1.8889919096423733

Epoch: 5| Step: 3
Training loss: 1.0953452587127686
Validation loss: 1.8116293876401839

Epoch: 5| Step: 4
Training loss: 1.578494668006897
Validation loss: 1.8443810388606081

Epoch: 5| Step: 5
Training loss: 1.4785168170928955
Validation loss: 1.8464952976472917

Epoch: 5| Step: 6
Training loss: 1.3851356506347656
Validation loss: 1.904171621927651

Epoch: 5| Step: 7
Training loss: 1.4485325813293457
Validation loss: 1.8578302591077742

Epoch: 5| Step: 8
Training loss: 1.129298210144043
Validation loss: 1.8823746814522693

Epoch: 5| Step: 9
Training loss: 1.0521202087402344
Validation loss: 1.8771431997258177

Epoch: 5| Step: 10
Training loss: 1.0956315994262695
Validation loss: 1.8860363268083142

Epoch: 398| Step: 0
Training loss: 1.4780426025390625
Validation loss: 1.8614858222264115

Epoch: 5| Step: 1
Training loss: 1.0290192365646362
Validation loss: 1.8892536586330784

Epoch: 5| Step: 2
Training loss: 1.6662437915802002
Validation loss: 1.9272444286654073

Epoch: 5| Step: 3
Training loss: 1.308114767074585
Validation loss: 1.9354657152647614

Epoch: 5| Step: 4
Training loss: 0.9877426028251648
Validation loss: 1.9330807283360472

Epoch: 5| Step: 5
Training loss: 1.4751601219177246
Validation loss: 1.9438828306813394

Epoch: 5| Step: 6
Training loss: 1.7350289821624756
Validation loss: 1.9298311074574788

Epoch: 5| Step: 7
Training loss: 1.7017223834991455
Validation loss: 1.884524332579746

Epoch: 5| Step: 8
Training loss: 0.8215053677558899
Validation loss: 1.8795507774558118

Epoch: 5| Step: 9
Training loss: 1.1919671297073364
Validation loss: 1.938710072989105

Epoch: 5| Step: 10
Training loss: 1.098592758178711
Validation loss: 1.8800921670852169

Epoch: 399| Step: 0
Training loss: 1.5352115631103516
Validation loss: 1.8665119704379831

Epoch: 5| Step: 1
Training loss: 1.2815333604812622
Validation loss: 1.882406065540929

Epoch: 5| Step: 2
Training loss: 1.2482621669769287
Validation loss: 1.933012814931972

Epoch: 5| Step: 3
Training loss: 1.8208211660385132
Validation loss: 1.9080079576020599

Epoch: 5| Step: 4
Training loss: 0.8209394216537476
Validation loss: 1.8461930956891788

Epoch: 5| Step: 5
Training loss: 1.2818115949630737
Validation loss: 1.8882012315975722

Epoch: 5| Step: 6
Training loss: 1.950256586074829
Validation loss: 1.8536583236468736

Epoch: 5| Step: 7
Training loss: 1.0750399827957153
Validation loss: 1.9116405748551892

Epoch: 5| Step: 8
Training loss: 1.0134745836257935
Validation loss: 1.8900287625610188

Epoch: 5| Step: 9
Training loss: 1.7895501852035522
Validation loss: 1.8502816513020506

Epoch: 5| Step: 10
Training loss: 0.7950370907783508
Validation loss: 1.8182047067149993

Epoch: 400| Step: 0
Training loss: 1.2750924825668335
Validation loss: 1.872411407450194

Epoch: 5| Step: 1
Training loss: 1.0148828029632568
Validation loss: 1.9035548343453357

Epoch: 5| Step: 2
Training loss: 1.6219093799591064
Validation loss: 1.843623681734967

Epoch: 5| Step: 3
Training loss: 1.2138035297393799
Validation loss: 1.8902984690922562

Epoch: 5| Step: 4
Training loss: 0.9439805150032043
Validation loss: 1.8388483344867665

Epoch: 5| Step: 5
Training loss: 1.4143697023391724
Validation loss: 1.887245806314612

Epoch: 5| Step: 6
Training loss: 1.4178390502929688
Validation loss: 1.9013508071181595

Epoch: 5| Step: 7
Training loss: 1.4949010610580444
Validation loss: 1.9287854522787116

Epoch: 5| Step: 8
Training loss: 1.427027702331543
Validation loss: 1.9333131518415225

Epoch: 5| Step: 9
Training loss: 1.3571584224700928
Validation loss: 1.9668094470936766

Epoch: 5| Step: 10
Training loss: 1.4858052730560303
Validation loss: 1.925883925089272

Epoch: 401| Step: 0
Training loss: 1.5008370876312256
Validation loss: 1.9043690286656862

Epoch: 5| Step: 1
Training loss: 1.6975679397583008
Validation loss: 1.9234130664538311

Epoch: 5| Step: 2
Training loss: 0.5826924443244934
Validation loss: 1.866922358030914

Epoch: 5| Step: 3
Training loss: 1.6074237823486328
Validation loss: 1.8859394327286751

Epoch: 5| Step: 4
Training loss: 1.2020354270935059
Validation loss: 1.9452571304895545

Epoch: 5| Step: 5
Training loss: 0.6908594369888306
Validation loss: 1.9198922508506364

Epoch: 5| Step: 6
Training loss: 1.3743139505386353
Validation loss: 1.8312011495713265

Epoch: 5| Step: 7
Training loss: 1.654954195022583
Validation loss: 1.8722502531543854

Epoch: 5| Step: 8
Training loss: 0.9555673599243164
Validation loss: 1.9088047806934645

Epoch: 5| Step: 9
Training loss: 1.5910451412200928
Validation loss: 1.8399764850575437

Epoch: 5| Step: 10
Training loss: 1.6519168615341187
Validation loss: 1.8033800919850667

Epoch: 402| Step: 0
Training loss: 1.3326141834259033
Validation loss: 1.8087098726662256

Epoch: 5| Step: 1
Training loss: 0.9043623208999634
Validation loss: 1.8171029270336192

Epoch: 5| Step: 2
Training loss: 1.9632219076156616
Validation loss: 1.8623473900620655

Epoch: 5| Step: 3
Training loss: 1.1438634395599365
Validation loss: 1.8287417440004246

Epoch: 5| Step: 4
Training loss: 1.0637919902801514
Validation loss: 1.8439803559293029

Epoch: 5| Step: 5
Training loss: 1.5340793132781982
Validation loss: 1.91851725885945

Epoch: 5| Step: 6
Training loss: 1.0024712085723877
Validation loss: 1.9273762228668376

Epoch: 5| Step: 7
Training loss: 1.7101945877075195
Validation loss: 1.8646557049084735

Epoch: 5| Step: 8
Training loss: 1.4984633922576904
Validation loss: 1.8898955122117074

Epoch: 5| Step: 9
Training loss: 0.8860437273979187
Validation loss: 1.921203117216787

Epoch: 5| Step: 10
Training loss: 1.4462214708328247
Validation loss: 1.885210729414417

Epoch: 403| Step: 0
Training loss: 1.6645972728729248
Validation loss: 1.9088850085453322

Epoch: 5| Step: 1
Training loss: 1.708382248878479
Validation loss: 1.8538962423160512

Epoch: 5| Step: 2
Training loss: 1.3357387781143188
Validation loss: 1.8053757503468504

Epoch: 5| Step: 3
Training loss: 1.5431609153747559
Validation loss: 1.8378853695366972

Epoch: 5| Step: 4
Training loss: 0.8512774705886841
Validation loss: 1.8362053901918474

Epoch: 5| Step: 5
Training loss: 1.088138461112976
Validation loss: 1.850173113166645

Epoch: 5| Step: 6
Training loss: 1.293230414390564
Validation loss: 1.8643345166278142

Epoch: 5| Step: 7
Training loss: 1.3259680271148682
Validation loss: 1.901952015456333

Epoch: 5| Step: 8
Training loss: 0.9283746480941772
Validation loss: 1.8755212176230647

Epoch: 5| Step: 9
Training loss: 0.8498362302780151
Validation loss: 1.8801731935111425

Epoch: 5| Step: 10
Training loss: 1.5811585187911987
Validation loss: 1.8939297968341458

Epoch: 404| Step: 0
Training loss: 1.2794015407562256
Validation loss: 1.866836593997094

Epoch: 5| Step: 1
Training loss: 1.3693962097167969
Validation loss: 1.8816616535186768

Epoch: 5| Step: 2
Training loss: 1.083173394203186
Validation loss: 1.9060287065403436

Epoch: 5| Step: 3
Training loss: 0.7734554409980774
Validation loss: 1.9174365074403825

Epoch: 5| Step: 4
Training loss: 1.756425142288208
Validation loss: 1.8904884502451906

Epoch: 5| Step: 5
Training loss: 1.5487232208251953
Validation loss: 1.8952959455469602

Epoch: 5| Step: 6
Training loss: 1.9057528972625732
Validation loss: 1.8739912612463838

Epoch: 5| Step: 7
Training loss: 1.1614123582839966
Validation loss: 1.9089427301960606

Epoch: 5| Step: 8
Training loss: 1.2219188213348389
Validation loss: 1.894612478953536

Epoch: 5| Step: 9
Training loss: 1.3253520727157593
Validation loss: 1.825022098838642

Epoch: 5| Step: 10
Training loss: 0.788824200630188
Validation loss: 1.8751441753038796

Epoch: 405| Step: 0
Training loss: 2.0670993328094482
Validation loss: 1.8501819948996268

Epoch: 5| Step: 1
Training loss: 1.2773640155792236
Validation loss: 1.8593614562865226

Epoch: 5| Step: 2
Training loss: 1.3042770624160767
Validation loss: 1.906445937771951

Epoch: 5| Step: 3
Training loss: 1.3925116062164307
Validation loss: 1.9042481401915192

Epoch: 5| Step: 4
Training loss: 0.9241863489151001
Validation loss: 1.8247444527123564

Epoch: 5| Step: 5
Training loss: 1.3047841787338257
Validation loss: 1.8250869089557278

Epoch: 5| Step: 6
Training loss: 1.305011510848999
Validation loss: 1.8701515582300001

Epoch: 5| Step: 7
Training loss: 1.3155460357666016
Validation loss: 1.8370455541918356

Epoch: 5| Step: 8
Training loss: 1.578870415687561
Validation loss: 1.792921450830275

Epoch: 5| Step: 9
Training loss: 0.6990472674369812
Validation loss: 1.830228623523507

Epoch: 5| Step: 10
Training loss: 0.8784120678901672
Validation loss: 1.8746930886340398

Epoch: 406| Step: 0
Training loss: 1.4171262979507446
Validation loss: 1.8843161495782996

Epoch: 5| Step: 1
Training loss: 1.4965038299560547
Validation loss: 1.9075600818921161

Epoch: 5| Step: 2
Training loss: 1.1836774349212646
Validation loss: 1.863640090470673

Epoch: 5| Step: 3
Training loss: 0.8964546918869019
Validation loss: 1.837500306867784

Epoch: 5| Step: 4
Training loss: 1.2293412685394287
Validation loss: 1.8405658378395984

Epoch: 5| Step: 5
Training loss: 1.5182483196258545
Validation loss: 1.8965499977911673

Epoch: 5| Step: 6
Training loss: 1.565450668334961
Validation loss: 1.893140495464366

Epoch: 5| Step: 7
Training loss: 0.9699252247810364
Validation loss: 1.9143462668183029

Epoch: 5| Step: 8
Training loss: 1.6967731714248657
Validation loss: 1.8158445050639491

Epoch: 5| Step: 9
Training loss: 1.238120198249817
Validation loss: 1.8983426811874553

Epoch: 5| Step: 10
Training loss: 1.1177382469177246
Validation loss: 1.9187955266685897

Epoch: 407| Step: 0
Training loss: 1.5249286890029907
Validation loss: 1.8982593833759267

Epoch: 5| Step: 1
Training loss: 1.181107521057129
Validation loss: 1.9312773955765592

Epoch: 5| Step: 2
Training loss: 2.20318341255188
Validation loss: 1.8826333630469538

Epoch: 5| Step: 3
Training loss: 1.20941162109375
Validation loss: 1.876159414168327

Epoch: 5| Step: 4
Training loss: 1.1338690519332886
Validation loss: 1.9330913097627702

Epoch: 5| Step: 5
Training loss: 1.6896775960922241
Validation loss: 1.8411594449832875

Epoch: 5| Step: 6
Training loss: 0.9081325531005859
Validation loss: 1.8795766676625898

Epoch: 5| Step: 7
Training loss: 1.4367401599884033
Validation loss: 1.8134618651482366

Epoch: 5| Step: 8
Training loss: 0.9326747059822083
Validation loss: 1.8983971367600143

Epoch: 5| Step: 9
Training loss: 1.0382357835769653
Validation loss: 1.919626510271462

Epoch: 5| Step: 10
Training loss: 1.1805565357208252
Validation loss: 1.8948990901311238

Epoch: 408| Step: 0
Training loss: 1.5269877910614014
Validation loss: 1.850887575457173

Epoch: 5| Step: 1
Training loss: 1.4222235679626465
Validation loss: 1.8545037238828597

Epoch: 5| Step: 2
Training loss: 1.4932204484939575
Validation loss: 1.8859806855519612

Epoch: 5| Step: 3
Training loss: 1.592375636100769
Validation loss: 1.9067845331725253

Epoch: 5| Step: 4
Training loss: 0.9311810731887817
Validation loss: 1.9023742483508201

Epoch: 5| Step: 5
Training loss: 0.9839173555374146
Validation loss: 1.8721632214002712

Epoch: 5| Step: 6
Training loss: 1.8986740112304688
Validation loss: 1.8939223392035371

Epoch: 5| Step: 7
Training loss: 0.8654991984367371
Validation loss: 1.9086490613158031

Epoch: 5| Step: 8
Training loss: 1.347306728363037
Validation loss: 1.8836817536302792

Epoch: 5| Step: 9
Training loss: 0.9935385584831238
Validation loss: 1.9073603973593762

Epoch: 5| Step: 10
Training loss: 1.0884689092636108
Validation loss: 1.8671738601499988

Epoch: 409| Step: 0
Training loss: 1.1845077276229858
Validation loss: 1.9033263421827746

Epoch: 5| Step: 1
Training loss: 1.3380874395370483
Validation loss: 1.8738793160325737

Epoch: 5| Step: 2
Training loss: 0.9869581460952759
Validation loss: 1.9322083188641457

Epoch: 5| Step: 3
Training loss: 1.166110873222351
Validation loss: 1.8078749743841027

Epoch: 5| Step: 4
Training loss: 1.7921546697616577
Validation loss: 1.8717428740634714

Epoch: 5| Step: 5
Training loss: 1.1034332513809204
Validation loss: 1.8396439167761034

Epoch: 5| Step: 6
Training loss: 1.3984551429748535
Validation loss: 1.7648451917914934

Epoch: 5| Step: 7
Training loss: 1.1976392269134521
Validation loss: 1.8567664905260968

Epoch: 5| Step: 8
Training loss: 1.6411504745483398
Validation loss: 1.8744299450228292

Epoch: 5| Step: 9
Training loss: 1.0867260694503784
Validation loss: 1.867745109783706

Epoch: 5| Step: 10
Training loss: 1.0837986469268799
Validation loss: 1.85748718630883

Epoch: 410| Step: 0
Training loss: 0.8426500558853149
Validation loss: 1.8555779418637675

Epoch: 5| Step: 1
Training loss: 1.7296355962753296
Validation loss: 1.8711160075279973

Epoch: 5| Step: 2
Training loss: 1.4313642978668213
Validation loss: 1.8741449515024822

Epoch: 5| Step: 3
Training loss: 1.1936862468719482
Validation loss: 1.8816547624526485

Epoch: 5| Step: 4
Training loss: 1.1538153886795044
Validation loss: 1.8325425706883913

Epoch: 5| Step: 5
Training loss: 0.9444228410720825
Validation loss: 1.9383318193497197

Epoch: 5| Step: 6
Training loss: 1.5853838920593262
Validation loss: 1.8544719975481752

Epoch: 5| Step: 7
Training loss: 1.472240924835205
Validation loss: 1.8193853644914524

Epoch: 5| Step: 8
Training loss: 0.9903896450996399
Validation loss: 1.8756800672059417

Epoch: 5| Step: 9
Training loss: 1.3996416330337524
Validation loss: 1.9156206833418978

Epoch: 5| Step: 10
Training loss: 1.5128540992736816
Validation loss: 1.904993377706056

Epoch: 411| Step: 0
Training loss: 1.216774344444275
Validation loss: 1.9445587242803266

Epoch: 5| Step: 1
Training loss: 1.4496498107910156
Validation loss: 1.88770507484354

Epoch: 5| Step: 2
Training loss: 1.2596811056137085
Validation loss: 1.9338068359641618

Epoch: 5| Step: 3
Training loss: 0.6664283275604248
Validation loss: 1.9339135949329664

Epoch: 5| Step: 4
Training loss: 1.3626796007156372
Validation loss: 1.8748218936304892

Epoch: 5| Step: 5
Training loss: 1.0827646255493164
Validation loss: 1.8068036712625974

Epoch: 5| Step: 6
Training loss: 1.6739495992660522
Validation loss: 1.8251176162432599

Epoch: 5| Step: 7
Training loss: 1.5379691123962402
Validation loss: 1.801691742353542

Epoch: 5| Step: 8
Training loss: 1.3986886739730835
Validation loss: 1.8744160154814362

Epoch: 5| Step: 9
Training loss: 1.3944284915924072
Validation loss: 1.8480591209985877

Epoch: 5| Step: 10
Training loss: 1.7672028541564941
Validation loss: 1.8777628406401603

Epoch: 412| Step: 0
Training loss: 1.293878436088562
Validation loss: 1.9165852492855442

Epoch: 5| Step: 1
Training loss: 1.5487043857574463
Validation loss: 1.8112435904882287

Epoch: 5| Step: 2
Training loss: 1.6527040004730225
Validation loss: 1.8584984105120423

Epoch: 5| Step: 3
Training loss: 1.3269773721694946
Validation loss: 1.889396140652318

Epoch: 5| Step: 4
Training loss: 0.7387101054191589
Validation loss: 1.8223655813483781

Epoch: 5| Step: 5
Training loss: 1.0606292486190796
Validation loss: 1.8555212789966213

Epoch: 5| Step: 6
Training loss: 1.558609962463379
Validation loss: 1.8280462462414977

Epoch: 5| Step: 7
Training loss: 1.4362845420837402
Validation loss: 1.8752563307362218

Epoch: 5| Step: 8
Training loss: 1.3259227275848389
Validation loss: 1.8544520101239603

Epoch: 5| Step: 9
Training loss: 1.0676422119140625
Validation loss: 1.903533689437374

Epoch: 5| Step: 10
Training loss: 1.0707675218582153
Validation loss: 1.8587636178539646

Epoch: 413| Step: 0
Training loss: 1.7238470315933228
Validation loss: 1.9733903959233274

Epoch: 5| Step: 1
Training loss: 1.1432582139968872
Validation loss: 1.9185258585919616

Epoch: 5| Step: 2
Training loss: 1.0571244955062866
Validation loss: 1.9376204334279543

Epoch: 5| Step: 3
Training loss: 1.7856366634368896
Validation loss: 1.9425118994969193

Epoch: 5| Step: 4
Training loss: 1.3933777809143066
Validation loss: 1.8691740177010978

Epoch: 5| Step: 5
Training loss: 1.0396442413330078
Validation loss: 1.900842261570756

Epoch: 5| Step: 6
Training loss: 0.7684102654457092
Validation loss: 1.8750436229090537

Epoch: 5| Step: 7
Training loss: 1.3553276062011719
Validation loss: 1.8798473394045265

Epoch: 5| Step: 8
Training loss: 1.5291988849639893
Validation loss: 1.9011527363971998

Epoch: 5| Step: 9
Training loss: 1.361713171005249
Validation loss: 1.854622737053902

Epoch: 5| Step: 10
Training loss: 1.1849784851074219
Validation loss: 1.8430191804003972

Epoch: 414| Step: 0
Training loss: 1.0475571155548096
Validation loss: 1.8224042897583337

Epoch: 5| Step: 1
Training loss: 1.0310860872268677
Validation loss: 1.8564979107149187

Epoch: 5| Step: 2
Training loss: 1.3559682369232178
Validation loss: 1.881826489202438

Epoch: 5| Step: 3
Training loss: 0.9731682538986206
Validation loss: 1.833075972013576

Epoch: 5| Step: 4
Training loss: 0.7206693291664124
Validation loss: 1.8844113772915256

Epoch: 5| Step: 5
Training loss: 1.6361936330795288
Validation loss: 1.8514005214937272

Epoch: 5| Step: 6
Training loss: 1.3208421468734741
Validation loss: 1.88014022509257

Epoch: 5| Step: 7
Training loss: 1.7527660131454468
Validation loss: 1.841167184614366

Epoch: 5| Step: 8
Training loss: 2.197003126144409
Validation loss: 1.8533874122045373

Epoch: 5| Step: 9
Training loss: 1.3701775074005127
Validation loss: 1.869655829603954

Epoch: 5| Step: 10
Training loss: 1.0164967775344849
Validation loss: 1.8812331922592656

Epoch: 415| Step: 0
Training loss: 1.8013153076171875
Validation loss: 1.8915295703436739

Epoch: 5| Step: 1
Training loss: 1.150350570678711
Validation loss: 1.8933242392796341

Epoch: 5| Step: 2
Training loss: 1.2048295736312866
Validation loss: 1.8771334643005042

Epoch: 5| Step: 3
Training loss: 0.8435182571411133
Validation loss: 1.8703548485232937

Epoch: 5| Step: 4
Training loss: 1.6072123050689697
Validation loss: 1.866654420411715

Epoch: 5| Step: 5
Training loss: 1.6633497476577759
Validation loss: 1.8754715970767442

Epoch: 5| Step: 6
Training loss: 1.5225244760513306
Validation loss: 1.9038621084664458

Epoch: 5| Step: 7
Training loss: 1.0160270929336548
Validation loss: 1.904326908050045

Epoch: 5| Step: 8
Training loss: 1.1317036151885986
Validation loss: 1.864262362962128

Epoch: 5| Step: 9
Training loss: 0.939422607421875
Validation loss: 1.8446255524953206

Epoch: 5| Step: 10
Training loss: 1.3484935760498047
Validation loss: 1.8389927238546393

Epoch: 416| Step: 0
Training loss: 1.5549410581588745
Validation loss: 1.851355052763416

Epoch: 5| Step: 1
Training loss: 1.394941806793213
Validation loss: 1.8593850174257833

Epoch: 5| Step: 2
Training loss: 1.352080225944519
Validation loss: 1.8662740158778366

Epoch: 5| Step: 3
Training loss: 0.7816712856292725
Validation loss: 1.8732230124935028

Epoch: 5| Step: 4
Training loss: 1.8002506494522095
Validation loss: 1.8815549099317161

Epoch: 5| Step: 5
Training loss: 1.3315231800079346
Validation loss: 1.9059646616699875

Epoch: 5| Step: 6
Training loss: 0.786044716835022
Validation loss: 1.8660982513940463

Epoch: 5| Step: 7
Training loss: 1.0698347091674805
Validation loss: 1.868514589084092

Epoch: 5| Step: 8
Training loss: 1.5703388452529907
Validation loss: 1.8664563317452707

Epoch: 5| Step: 9
Training loss: 1.0348405838012695
Validation loss: 1.8132888937509188

Epoch: 5| Step: 10
Training loss: 1.4986923933029175
Validation loss: 1.9329713467628724

Epoch: 417| Step: 0
Training loss: 1.3410857915878296
Validation loss: 1.933929649732446

Epoch: 5| Step: 1
Training loss: 1.3203072547912598
Validation loss: 1.8550238250404276

Epoch: 5| Step: 2
Training loss: 1.7172515392303467
Validation loss: 1.9107807938770582

Epoch: 5| Step: 3
Training loss: 1.2104824781417847
Validation loss: 1.9116350079095492

Epoch: 5| Step: 4
Training loss: 0.7465531826019287
Validation loss: 1.8990188465323499

Epoch: 5| Step: 5
Training loss: 1.0332448482513428
Validation loss: 1.8882411936277985

Epoch: 5| Step: 6
Training loss: 0.9536410570144653
Validation loss: 1.893813366531044

Epoch: 5| Step: 7
Training loss: 1.4515964984893799
Validation loss: 1.879236654568744

Epoch: 5| Step: 8
Training loss: 1.6339809894561768
Validation loss: 1.8375561814154349

Epoch: 5| Step: 9
Training loss: 0.930394172668457
Validation loss: 1.908763022832973

Epoch: 5| Step: 10
Training loss: 2.2310235500335693
Validation loss: 1.8823649896088468

Epoch: 418| Step: 0
Training loss: 0.6953011155128479
Validation loss: 1.8871188048393495

Epoch: 5| Step: 1
Training loss: 1.0640376806259155
Validation loss: 1.8789688271860923

Epoch: 5| Step: 2
Training loss: 1.710040807723999
Validation loss: 1.8718314555383497

Epoch: 5| Step: 3
Training loss: 0.9269935488700867
Validation loss: 1.824654988063279

Epoch: 5| Step: 4
Training loss: 1.1950393915176392
Validation loss: 1.86765718460083

Epoch: 5| Step: 5
Training loss: 1.6007999181747437
Validation loss: 1.8827771191955895

Epoch: 5| Step: 6
Training loss: 2.058255434036255
Validation loss: 1.8872275980569984

Epoch: 5| Step: 7
Training loss: 1.4029821157455444
Validation loss: 1.9335073963288338

Epoch: 5| Step: 8
Training loss: 0.8924522399902344
Validation loss: 1.857091857540992

Epoch: 5| Step: 9
Training loss: 1.4990431070327759
Validation loss: 1.8859286923562326

Epoch: 5| Step: 10
Training loss: 1.2207599878311157
Validation loss: 1.86486449292911

Epoch: 419| Step: 0
Training loss: 1.1516735553741455
Validation loss: 1.9271954028837142

Epoch: 5| Step: 1
Training loss: 1.2120122909545898
Validation loss: 1.9250731929655998

Epoch: 5| Step: 2
Training loss: 1.5357873439788818
Validation loss: 1.8185993984181394

Epoch: 5| Step: 3
Training loss: 1.1624610424041748
Validation loss: 1.891598528431308

Epoch: 5| Step: 4
Training loss: 1.3979482650756836
Validation loss: 1.9050908947503695

Epoch: 5| Step: 5
Training loss: 1.459869623184204
Validation loss: 1.89052886860345

Epoch: 5| Step: 6
Training loss: 1.0919972658157349
Validation loss: 1.8453435372280818

Epoch: 5| Step: 7
Training loss: 1.0146461725234985
Validation loss: 1.8864339718254663

Epoch: 5| Step: 8
Training loss: 1.4659404754638672
Validation loss: 1.871523630234503

Epoch: 5| Step: 9
Training loss: 1.55122709274292
Validation loss: 1.852685797599054

Epoch: 5| Step: 10
Training loss: 1.29849374294281
Validation loss: 1.88752963337847

Epoch: 420| Step: 0
Training loss: 1.0481557846069336
Validation loss: 1.8585027853647869

Epoch: 5| Step: 1
Training loss: 1.4773733615875244
Validation loss: 1.8974355664304507

Epoch: 5| Step: 2
Training loss: 1.364641785621643
Validation loss: 1.8821961828457412

Epoch: 5| Step: 3
Training loss: 1.037645936012268
Validation loss: 1.8813640122772546

Epoch: 5| Step: 4
Training loss: 1.7409347295761108
Validation loss: 1.9164777391700334

Epoch: 5| Step: 5
Training loss: 1.3685613870620728
Validation loss: 1.8929936860197334

Epoch: 5| Step: 6
Training loss: 0.7620854377746582
Validation loss: 1.8466017989702121

Epoch: 5| Step: 7
Training loss: 0.9271508455276489
Validation loss: 1.845967633749849

Epoch: 5| Step: 8
Training loss: 1.7682660818099976
Validation loss: 1.9110576850111767

Epoch: 5| Step: 9
Training loss: 1.2102235555648804
Validation loss: 1.848770801739026

Epoch: 5| Step: 10
Training loss: 1.346875548362732
Validation loss: 1.8334449632193452

Epoch: 421| Step: 0
Training loss: 1.7084823846817017
Validation loss: 1.8961381950686056

Epoch: 5| Step: 1
Training loss: 1.3337173461914062
Validation loss: 1.9796607750718311

Epoch: 5| Step: 2
Training loss: 1.6108043193817139
Validation loss: 1.9601552383874052

Epoch: 5| Step: 3
Training loss: 0.8183452486991882
Validation loss: 1.9500340697585896

Epoch: 5| Step: 4
Training loss: 1.5025156736373901
Validation loss: 1.967199694725775

Epoch: 5| Step: 5
Training loss: 1.0796715021133423
Validation loss: 2.011563583086896

Epoch: 5| Step: 6
Training loss: 0.8356934785842896
Validation loss: 1.9441600256068732

Epoch: 5| Step: 7
Training loss: 1.1639584302902222
Validation loss: 1.9132546852993708

Epoch: 5| Step: 8
Training loss: 0.8220661282539368
Validation loss: 1.9136848872707737

Epoch: 5| Step: 9
Training loss: 1.5154552459716797
Validation loss: 1.869185575874903

Epoch: 5| Step: 10
Training loss: 1.7128677368164062
Validation loss: 1.8782333507332751

Epoch: 422| Step: 0
Training loss: 1.5324890613555908
Validation loss: 1.9017936593742781

Epoch: 5| Step: 1
Training loss: 1.1919372081756592
Validation loss: 1.860191716942736

Epoch: 5| Step: 2
Training loss: 1.011521816253662
Validation loss: 1.888222453414753

Epoch: 5| Step: 3
Training loss: 1.1159088611602783
Validation loss: 1.9013862879045549

Epoch: 5| Step: 4
Training loss: 1.3206828832626343
Validation loss: 1.8903643162019792

Epoch: 5| Step: 5
Training loss: 1.1134700775146484
Validation loss: 1.9093356363234981

Epoch: 5| Step: 6
Training loss: 1.5848218202590942
Validation loss: 1.8529591957728069

Epoch: 5| Step: 7
Training loss: 1.155221700668335
Validation loss: 1.8715346910620247

Epoch: 5| Step: 8
Training loss: 1.3724462985992432
Validation loss: 1.8795105167614516

Epoch: 5| Step: 9
Training loss: 1.140397071838379
Validation loss: 1.85591031659034

Epoch: 5| Step: 10
Training loss: 1.3976346254348755
Validation loss: 1.8681310607540993

Epoch: 423| Step: 0
Training loss: 1.003900170326233
Validation loss: 1.872484053334882

Epoch: 5| Step: 1
Training loss: 1.7107574939727783
Validation loss: 1.9357480438806678

Epoch: 5| Step: 2
Training loss: 1.301041841506958
Validation loss: 1.908449108882617

Epoch: 5| Step: 3
Training loss: 1.3981680870056152
Validation loss: 1.8941199048872916

Epoch: 5| Step: 4
Training loss: 1.085939884185791
Validation loss: 1.9391253071446573

Epoch: 5| Step: 5
Training loss: 1.048961877822876
Validation loss: 1.9019754381589993

Epoch: 5| Step: 6
Training loss: 1.6926307678222656
Validation loss: 1.8944505068563646

Epoch: 5| Step: 7
Training loss: 0.858626663684845
Validation loss: 1.8540105371065037

Epoch: 5| Step: 8
Training loss: 1.4010957479476929
Validation loss: 1.8574389462829919

Epoch: 5| Step: 9
Training loss: 1.1960340738296509
Validation loss: 1.8683777291287658

Epoch: 5| Step: 10
Training loss: 1.133744239807129
Validation loss: 1.8849463309011152

Epoch: 424| Step: 0
Training loss: 1.5963410139083862
Validation loss: 1.9023309433332054

Epoch: 5| Step: 1
Training loss: 1.380311369895935
Validation loss: 1.9235533924512966

Epoch: 5| Step: 2
Training loss: 1.8044229745864868
Validation loss: 1.9000133711804625

Epoch: 5| Step: 3
Training loss: 1.3128087520599365
Validation loss: 1.8888397178342264

Epoch: 5| Step: 4
Training loss: 1.3523139953613281
Validation loss: 1.9154902888882546

Epoch: 5| Step: 5
Training loss: 0.8934640884399414
Validation loss: 1.8610449478190432

Epoch: 5| Step: 6
Training loss: 0.8157351613044739
Validation loss: 1.8558174038446078

Epoch: 5| Step: 7
Training loss: 1.2131046056747437
Validation loss: 1.9098085177842008

Epoch: 5| Step: 8
Training loss: 1.3143186569213867
Validation loss: 1.8597270045229184

Epoch: 5| Step: 9
Training loss: 0.8819431066513062
Validation loss: 1.8569096416555426

Epoch: 5| Step: 10
Training loss: 1.2118502855300903
Validation loss: 1.9458050394570956

Epoch: 425| Step: 0
Training loss: 0.8714092969894409
Validation loss: 1.8549619464464084

Epoch: 5| Step: 1
Training loss: 1.559913992881775
Validation loss: 1.912353164406233

Epoch: 5| Step: 2
Training loss: 1.253035068511963
Validation loss: 1.9073690393919587

Epoch: 5| Step: 3
Training loss: 1.3311128616333008
Validation loss: 1.869844368709031

Epoch: 5| Step: 4
Training loss: 1.3828701972961426
Validation loss: 1.9043660022879159

Epoch: 5| Step: 5
Training loss: 1.6194273233413696
Validation loss: 1.8962422160692112

Epoch: 5| Step: 6
Training loss: 1.597530722618103
Validation loss: 1.8905335152021019

Epoch: 5| Step: 7
Training loss: 0.9745219349861145
Validation loss: 1.836410217387702

Epoch: 5| Step: 8
Training loss: 1.3188230991363525
Validation loss: 1.892379560778218

Epoch: 5| Step: 9
Training loss: 1.137939691543579
Validation loss: 1.854790702942879

Epoch: 5| Step: 10
Training loss: 1.185367465019226
Validation loss: 1.9120335886555333

Epoch: 426| Step: 0
Training loss: 1.3198832273483276
Validation loss: 1.9012202908915858

Epoch: 5| Step: 1
Training loss: 1.475243330001831
Validation loss: 1.925365246752257

Epoch: 5| Step: 2
Training loss: 0.9223510026931763
Validation loss: 1.8208182524609309

Epoch: 5| Step: 3
Training loss: 1.3319557905197144
Validation loss: 1.9067596338128532

Epoch: 5| Step: 4
Training loss: 1.5793720483779907
Validation loss: 1.8770732700183828

Epoch: 5| Step: 5
Training loss: 0.8886755704879761
Validation loss: 1.811703292272424

Epoch: 5| Step: 6
Training loss: 0.938834011554718
Validation loss: 1.9269358393966511

Epoch: 5| Step: 7
Training loss: 1.5564783811569214
Validation loss: 1.9286190053468109

Epoch: 5| Step: 8
Training loss: 1.3041530847549438
Validation loss: 1.8591705086410686

Epoch: 5| Step: 9
Training loss: 1.376384973526001
Validation loss: 1.8980860594780213

Epoch: 5| Step: 10
Training loss: 1.1203057765960693
Validation loss: 1.864665554415795

Epoch: 427| Step: 0
Training loss: 1.3688796758651733
Validation loss: 1.8599829263584589

Epoch: 5| Step: 1
Training loss: 1.4306576251983643
Validation loss: 1.9024176571958809

Epoch: 5| Step: 2
Training loss: 0.8810235857963562
Validation loss: 1.8804639667593024

Epoch: 5| Step: 3
Training loss: 1.4191745519638062
Validation loss: 1.8878678737148162

Epoch: 5| Step: 4
Training loss: 1.3524436950683594
Validation loss: 1.9550960294661983

Epoch: 5| Step: 5
Training loss: 1.3047429323196411
Validation loss: 1.8709078142719884

Epoch: 5| Step: 6
Training loss: 1.081270694732666
Validation loss: 1.9046988653880295

Epoch: 5| Step: 7
Training loss: 1.456811547279358
Validation loss: 1.8741633994604951

Epoch: 5| Step: 8
Training loss: 0.814060389995575
Validation loss: 1.9138640037146948

Epoch: 5| Step: 9
Training loss: 0.941321849822998
Validation loss: 1.859167887318519

Epoch: 5| Step: 10
Training loss: 1.1181970834732056
Validation loss: 1.8595932196545344

Epoch: 428| Step: 0
Training loss: 1.764442801475525
Validation loss: 1.8578853478995703

Epoch: 5| Step: 1
Training loss: 1.3457969427108765
Validation loss: 1.899817584663309

Epoch: 5| Step: 2
Training loss: 1.2297133207321167
Validation loss: 1.9339530288532216

Epoch: 5| Step: 3
Training loss: 1.0668087005615234
Validation loss: 1.843433387817875

Epoch: 5| Step: 4
Training loss: 1.4759820699691772
Validation loss: 1.7867439075182843

Epoch: 5| Step: 5
Training loss: 1.5089727640151978
Validation loss: 1.8576412444473596

Epoch: 5| Step: 6
Training loss: 1.1301519870758057
Validation loss: 1.8189354878599926

Epoch: 5| Step: 7
Training loss: 1.0134103298187256
Validation loss: 1.8780083297401347

Epoch: 5| Step: 8
Training loss: 1.3131998777389526
Validation loss: 1.9073143133553125

Epoch: 5| Step: 9
Training loss: 1.1264342069625854
Validation loss: 1.8917491205276982

Epoch: 5| Step: 10
Training loss: 1.2124814987182617
Validation loss: 1.884657463719768

Epoch: 429| Step: 0
Training loss: 1.136455774307251
Validation loss: 1.8401213794626214

Epoch: 5| Step: 1
Training loss: 1.5159400701522827
Validation loss: 1.9315662178941952

Epoch: 5| Step: 2
Training loss: 1.2907218933105469
Validation loss: 1.9040326174869333

Epoch: 5| Step: 3
Training loss: 1.0310122966766357
Validation loss: 1.907345187279486

Epoch: 5| Step: 4
Training loss: 1.2995063066482544
Validation loss: 1.9220299618218535

Epoch: 5| Step: 5
Training loss: 1.5887855291366577
Validation loss: 1.8563593843931794

Epoch: 5| Step: 6
Training loss: 1.2431414127349854
Validation loss: 1.8762389216371762

Epoch: 5| Step: 7
Training loss: 1.229950189590454
Validation loss: 1.8814734643505466

Epoch: 5| Step: 8
Training loss: 0.7370527982711792
Validation loss: 1.8182148113045642

Epoch: 5| Step: 9
Training loss: 1.3888137340545654
Validation loss: 1.8812943479066253

Epoch: 5| Step: 10
Training loss: 1.0438593626022339
Validation loss: 1.8934664277620212

Epoch: 430| Step: 0
Training loss: 1.351259469985962
Validation loss: 1.8701104630706131

Epoch: 5| Step: 1
Training loss: 1.506707787513733
Validation loss: 1.855545497709705

Epoch: 5| Step: 2
Training loss: 0.9912271499633789
Validation loss: 1.8646489445881178

Epoch: 5| Step: 3
Training loss: 1.0292519330978394
Validation loss: 1.8982818613770187

Epoch: 5| Step: 4
Training loss: 1.4076356887817383
Validation loss: 1.827943621143218

Epoch: 5| Step: 5
Training loss: 0.9841585159301758
Validation loss: 1.875102166206606

Epoch: 5| Step: 6
Training loss: 1.086789608001709
Validation loss: 1.8324317727037656

Epoch: 5| Step: 7
Training loss: 1.4410983324050903
Validation loss: 1.9103885312234201

Epoch: 5| Step: 8
Training loss: 1.5063117742538452
Validation loss: 1.817821305285218

Epoch: 5| Step: 9
Training loss: 0.8014087677001953
Validation loss: 1.8852868797958537

Epoch: 5| Step: 10
Training loss: 1.8353602886199951
Validation loss: 1.9138844064486924

Epoch: 431| Step: 0
Training loss: 1.4009363651275635
Validation loss: 1.9482066323680263

Epoch: 5| Step: 1
Training loss: 1.5709354877471924
Validation loss: 1.9104032439570273

Epoch: 5| Step: 2
Training loss: 1.300890564918518
Validation loss: 1.8418282334522535

Epoch: 5| Step: 3
Training loss: 0.9797636270523071
Validation loss: 1.860460888954901

Epoch: 5| Step: 4
Training loss: 1.095245122909546
Validation loss: 1.8493951982067478

Epoch: 5| Step: 5
Training loss: 0.818191647529602
Validation loss: 1.817753239344525

Epoch: 5| Step: 6
Training loss: 1.178847074508667
Validation loss: 1.8682546333600116

Epoch: 5| Step: 7
Training loss: 1.3469464778900146
Validation loss: 1.8453449638940955

Epoch: 5| Step: 8
Training loss: 1.262420415878296
Validation loss: 1.8906712070588143

Epoch: 5| Step: 9
Training loss: 1.6344932317733765
Validation loss: 1.8630017272887691

Epoch: 5| Step: 10
Training loss: 1.3917943239212036
Validation loss: 1.8602113493027226

Epoch: 432| Step: 0
Training loss: 1.0514452457427979
Validation loss: 1.865157893908921

Epoch: 5| Step: 1
Training loss: 1.5757168531417847
Validation loss: 1.8707186778386433

Epoch: 5| Step: 2
Training loss: 1.2727136611938477
Validation loss: 1.9007974286233225

Epoch: 5| Step: 3
Training loss: 1.0704811811447144
Validation loss: 1.8685033321380615

Epoch: 5| Step: 4
Training loss: 1.164411187171936
Validation loss: 1.8748412593718498

Epoch: 5| Step: 5
Training loss: 0.7512263655662537
Validation loss: 1.8591536142492806

Epoch: 5| Step: 6
Training loss: 1.1909878253936768
Validation loss: 1.873053494320121

Epoch: 5| Step: 7
Training loss: 1.1847429275512695
Validation loss: 1.8156371449911466

Epoch: 5| Step: 8
Training loss: 1.6697533130645752
Validation loss: 1.8411496916124899

Epoch: 5| Step: 9
Training loss: 1.25297212600708
Validation loss: 1.849639332422646

Epoch: 5| Step: 10
Training loss: 1.1747345924377441
Validation loss: 1.8666847559713549

Epoch: 433| Step: 0
Training loss: 1.031341791152954
Validation loss: 1.8558841469467326

Epoch: 5| Step: 1
Training loss: 1.2169666290283203
Validation loss: 1.77402913442222

Epoch: 5| Step: 2
Training loss: 1.306448221206665
Validation loss: 1.8366550412229312

Epoch: 5| Step: 3
Training loss: 1.3504374027252197
Validation loss: 1.8789336014819402

Epoch: 5| Step: 4
Training loss: 1.2874815464019775
Validation loss: 1.8302417916636313

Epoch: 5| Step: 5
Training loss: 1.1526031494140625
Validation loss: 1.8186070688309208

Epoch: 5| Step: 6
Training loss: 1.4767414331436157
Validation loss: 1.8877296050389607

Epoch: 5| Step: 7
Training loss: 1.3999645709991455
Validation loss: 1.88660083534897

Epoch: 5| Step: 8
Training loss: 0.925131618976593
Validation loss: 1.8926080273043724

Epoch: 5| Step: 9
Training loss: 0.9578200578689575
Validation loss: 1.824290471692239

Epoch: 5| Step: 10
Training loss: 1.2847503423690796
Validation loss: 1.915625842668677

Epoch: 434| Step: 0
Training loss: 1.3068866729736328
Validation loss: 1.8919219522066013

Epoch: 5| Step: 1
Training loss: 1.4334863424301147
Validation loss: 1.8694622055176766

Epoch: 5| Step: 2
Training loss: 1.2287458181381226
Validation loss: 1.8644562075215

Epoch: 5| Step: 3
Training loss: 1.0833256244659424
Validation loss: 1.9062337734365975

Epoch: 5| Step: 4
Training loss: 0.7787373065948486
Validation loss: 1.9082523187001545

Epoch: 5| Step: 5
Training loss: 1.7226111888885498
Validation loss: 1.8697068024707097

Epoch: 5| Step: 6
Training loss: 1.1883571147918701
Validation loss: 1.8397055018332698

Epoch: 5| Step: 7
Training loss: 1.8245532512664795
Validation loss: 1.9317510538203742

Epoch: 5| Step: 8
Training loss: 0.6967760324478149
Validation loss: 1.8771059154182352

Epoch: 5| Step: 9
Training loss: 1.270858645439148
Validation loss: 1.9060896058236398

Epoch: 5| Step: 10
Training loss: 1.6422948837280273
Validation loss: 1.8757075827608827

Epoch: 435| Step: 0
Training loss: 1.655718207359314
Validation loss: 1.847510673666513

Epoch: 5| Step: 1
Training loss: 1.3290722370147705
Validation loss: 1.8958024286454724

Epoch: 5| Step: 2
Training loss: 1.3734474182128906
Validation loss: 1.865610517481322

Epoch: 5| Step: 3
Training loss: 0.8888546228408813
Validation loss: 1.8495185016303934

Epoch: 5| Step: 4
Training loss: 1.2484817504882812
Validation loss: 1.8237447764283867

Epoch: 5| Step: 5
Training loss: 1.398388385772705
Validation loss: 1.8351815900494974

Epoch: 5| Step: 6
Training loss: 1.0888608694076538
Validation loss: 1.8743932862435617

Epoch: 5| Step: 7
Training loss: 1.4059760570526123
Validation loss: 1.8035789830710298

Epoch: 5| Step: 8
Training loss: 1.2307560443878174
Validation loss: 1.8286575399419314

Epoch: 5| Step: 9
Training loss: 1.031347393989563
Validation loss: 1.9298176855169318

Epoch: 5| Step: 10
Training loss: 1.2631996870040894
Validation loss: 1.8958993175978303

Epoch: 436| Step: 0
Training loss: 2.1219229698181152
Validation loss: 1.9038670806474582

Epoch: 5| Step: 1
Training loss: 1.0186398029327393
Validation loss: 1.8892397624190136

Epoch: 5| Step: 2
Training loss: 1.1596620082855225
Validation loss: 1.9001871937064714

Epoch: 5| Step: 3
Training loss: 0.8963872790336609
Validation loss: 1.8511557412403885

Epoch: 5| Step: 4
Training loss: 1.8632266521453857
Validation loss: 1.933951440677848

Epoch: 5| Step: 5
Training loss: 0.8502824902534485
Validation loss: 1.8725576067483554

Epoch: 5| Step: 6
Training loss: 1.344370722770691
Validation loss: 1.8708922952734015

Epoch: 5| Step: 7
Training loss: 0.885640025138855
Validation loss: 1.8771893824300458

Epoch: 5| Step: 8
Training loss: 1.1762350797653198
Validation loss: 1.8980617997466878

Epoch: 5| Step: 9
Training loss: 1.458479642868042
Validation loss: 1.861015571061001

Epoch: 5| Step: 10
Training loss: 1.2859220504760742
Validation loss: 1.834919378321658

Epoch: 437| Step: 0
Training loss: 1.3976695537567139
Validation loss: 1.8212060389980194

Epoch: 5| Step: 1
Training loss: 1.4402425289154053
Validation loss: 1.7984432058949624

Epoch: 5| Step: 2
Training loss: 1.3099058866500854
Validation loss: 1.8304418440788024

Epoch: 5| Step: 3
Training loss: 1.5043960809707642
Validation loss: 1.9021783592880412

Epoch: 5| Step: 4
Training loss: 0.8556476831436157
Validation loss: 1.864314268994075

Epoch: 5| Step: 5
Training loss: 1.5507529973983765
Validation loss: 1.8368339154028124

Epoch: 5| Step: 6
Training loss: 0.965536892414093
Validation loss: 1.8408476639819402

Epoch: 5| Step: 7
Training loss: 1.6964833736419678
Validation loss: 1.8074794866705453

Epoch: 5| Step: 8
Training loss: 1.5869312286376953
Validation loss: 1.8307034943693428

Epoch: 5| Step: 9
Training loss: 0.9280712008476257
Validation loss: 1.888259082712153

Epoch: 5| Step: 10
Training loss: 1.1738864183425903
Validation loss: 1.883343514575753

Epoch: 438| Step: 0
Training loss: 1.465049386024475
Validation loss: 1.8237770718912925

Epoch: 5| Step: 1
Training loss: 1.1661914587020874
Validation loss: 1.8838080154952181

Epoch: 5| Step: 2
Training loss: 0.9580256342887878
Validation loss: 1.8522083733671455

Epoch: 5| Step: 3
Training loss: 1.0055983066558838
Validation loss: 1.9293152260523971

Epoch: 5| Step: 4
Training loss: 1.0309182405471802
Validation loss: 1.9308747873511365

Epoch: 5| Step: 5
Training loss: 1.378568410873413
Validation loss: 1.8599276478572557

Epoch: 5| Step: 6
Training loss: 1.5839462280273438
Validation loss: 1.8886091234863445

Epoch: 5| Step: 7
Training loss: 1.2241852283477783
Validation loss: 1.8377972033716017

Epoch: 5| Step: 8
Training loss: 0.9832404851913452
Validation loss: 1.8755645636589295

Epoch: 5| Step: 9
Training loss: 1.4332196712493896
Validation loss: 1.870154228261722

Epoch: 5| Step: 10
Training loss: 1.6244155168533325
Validation loss: 1.8564323404783845

Epoch: 439| Step: 0
Training loss: 1.2481930255889893
Validation loss: 1.8644354792051419

Epoch: 5| Step: 1
Training loss: 0.9533227682113647
Validation loss: 1.8550679888776553

Epoch: 5| Step: 2
Training loss: 0.9430214762687683
Validation loss: 1.881752816579675

Epoch: 5| Step: 3
Training loss: 1.6057627201080322
Validation loss: 1.876727678442514

Epoch: 5| Step: 4
Training loss: 1.1266114711761475
Validation loss: 1.8617674919866747

Epoch: 5| Step: 5
Training loss: 1.8354860544204712
Validation loss: 1.9236369184268418

Epoch: 5| Step: 6
Training loss: 0.9018867611885071
Validation loss: 1.8823208847353536

Epoch: 5| Step: 7
Training loss: 1.2780895233154297
Validation loss: 1.885109395109197

Epoch: 5| Step: 8
Training loss: 1.4275764226913452
Validation loss: 1.888959171951458

Epoch: 5| Step: 9
Training loss: 1.1697367429733276
Validation loss: 1.822125978367303

Epoch: 5| Step: 10
Training loss: 0.6779703497886658
Validation loss: 1.8729369871077999

Epoch: 440| Step: 0
Training loss: 0.9601520299911499
Validation loss: 1.9268037247401413

Epoch: 5| Step: 1
Training loss: 1.0822428464889526
Validation loss: 1.842930850162301

Epoch: 5| Step: 2
Training loss: 1.6310945749282837
Validation loss: 1.8713217281526136

Epoch: 5| Step: 3
Training loss: 1.3558261394500732
Validation loss: 1.7838608654596473

Epoch: 5| Step: 4
Training loss: 1.0017352104187012
Validation loss: 1.8791675183080858

Epoch: 5| Step: 5
Training loss: 0.9496973752975464
Validation loss: 1.8208257895643993

Epoch: 5| Step: 6
Training loss: 1.7474238872528076
Validation loss: 1.8395734704950804

Epoch: 5| Step: 7
Training loss: 1.3292502164840698
Validation loss: 1.8530758837217927

Epoch: 5| Step: 8
Training loss: 1.3359394073486328
Validation loss: 1.8999730592132897

Epoch: 5| Step: 9
Training loss: 1.1015634536743164
Validation loss: 1.8325633233593357

Epoch: 5| Step: 10
Training loss: 1.177691102027893
Validation loss: 1.9040924169683968

Epoch: 441| Step: 0
Training loss: 0.8975852727890015
Validation loss: 1.830674753394178

Epoch: 5| Step: 1
Training loss: 1.2694008350372314
Validation loss: 1.877892094273721

Epoch: 5| Step: 2
Training loss: 0.8164931535720825
Validation loss: 1.8954243429245488

Epoch: 5| Step: 3
Training loss: 0.764583945274353
Validation loss: 1.8597635876747869

Epoch: 5| Step: 4
Training loss: 1.0928579568862915
Validation loss: 1.8629044563539567

Epoch: 5| Step: 5
Training loss: 0.9833930134773254
Validation loss: 1.8407730325575797

Epoch: 5| Step: 6
Training loss: 1.0241453647613525
Validation loss: 1.8740577313207811

Epoch: 5| Step: 7
Training loss: 1.514925241470337
Validation loss: 1.9207230690986878

Epoch: 5| Step: 8
Training loss: 1.3107573986053467
Validation loss: 1.754829106792327

Epoch: 5| Step: 9
Training loss: 2.1162989139556885
Validation loss: 1.814756292168812

Epoch: 5| Step: 10
Training loss: 1.1703332662582397
Validation loss: 1.8890024000598538

Epoch: 442| Step: 0
Training loss: 0.7566809058189392
Validation loss: 1.8070521047038417

Epoch: 5| Step: 1
Training loss: 1.0491546392440796
Validation loss: 1.8267133082112958

Epoch: 5| Step: 2
Training loss: 1.213104486465454
Validation loss: 1.819747099312403

Epoch: 5| Step: 3
Training loss: 0.9924095273017883
Validation loss: 1.8471266120992682

Epoch: 5| Step: 4
Training loss: 1.1290496587753296
Validation loss: 1.8682633420472503

Epoch: 5| Step: 5
Training loss: 1.2258985042572021
Validation loss: 1.8738877773284912

Epoch: 5| Step: 6
Training loss: 1.5168468952178955
Validation loss: 1.8659617067665182

Epoch: 5| Step: 7
Training loss: 1.6508729457855225
Validation loss: 1.8729161600912771

Epoch: 5| Step: 8
Training loss: 0.9648284912109375
Validation loss: 1.8521095424570062

Epoch: 5| Step: 9
Training loss: 1.7047935724258423
Validation loss: 1.8828773447262344

Epoch: 5| Step: 10
Training loss: 0.871178150177002
Validation loss: 1.8794138764822355

Epoch: 443| Step: 0
Training loss: 1.3815251588821411
Validation loss: 1.80131866598642

Epoch: 5| Step: 1
Training loss: 1.5378230810165405
Validation loss: 1.865438179303241

Epoch: 5| Step: 2
Training loss: 0.8906224966049194
Validation loss: 1.881123145421346

Epoch: 5| Step: 3
Training loss: 1.0908796787261963
Validation loss: 1.891590738809237

Epoch: 5| Step: 4
Training loss: 0.808741569519043
Validation loss: 1.8629836561859294

Epoch: 5| Step: 5
Training loss: 1.440597653388977
Validation loss: 1.8402886723959317

Epoch: 5| Step: 6
Training loss: 1.1207096576690674
Validation loss: 1.836957162426364

Epoch: 5| Step: 7
Training loss: 1.2900434732437134
Validation loss: 1.896945156076903

Epoch: 5| Step: 8
Training loss: 1.3995592594146729
Validation loss: 1.8202053795578659

Epoch: 5| Step: 9
Training loss: 1.3763201236724854
Validation loss: 1.917055312023368

Epoch: 5| Step: 10
Training loss: 0.9399893283843994
Validation loss: 1.8975816131919943

Epoch: 444| Step: 0
Training loss: 0.9934202432632446
Validation loss: 1.8191912110133837

Epoch: 5| Step: 1
Training loss: 1.0103155374526978
Validation loss: 1.8249198621319187

Epoch: 5| Step: 2
Training loss: 1.2613747119903564
Validation loss: 1.9060941075765958

Epoch: 5| Step: 3
Training loss: 1.2440040111541748
Validation loss: 1.8526490888287943

Epoch: 5| Step: 4
Training loss: 1.5416157245635986
Validation loss: 1.887141405895192

Epoch: 5| Step: 5
Training loss: 1.2967498302459717
Validation loss: 1.8971834259648477

Epoch: 5| Step: 6
Training loss: 1.2787182331085205
Validation loss: 1.9250295392928585

Epoch: 5| Step: 7
Training loss: 0.6756492853164673
Validation loss: 1.8626706266915927

Epoch: 5| Step: 8
Training loss: 2.222111225128174
Validation loss: 1.929976414608699

Epoch: 5| Step: 9
Training loss: 0.8375036120414734
Validation loss: 1.8785831312979422

Epoch: 5| Step: 10
Training loss: 1.0561742782592773
Validation loss: 1.841492674684012

Epoch: 445| Step: 0
Training loss: 1.2112280130386353
Validation loss: 1.913818044047202

Epoch: 5| Step: 1
Training loss: 1.4040606021881104
Validation loss: 1.9086105810698641

Epoch: 5| Step: 2
Training loss: 1.2532942295074463
Validation loss: 1.8693764889112083

Epoch: 5| Step: 3
Training loss: 1.2304950952529907
Validation loss: 1.852448268603253

Epoch: 5| Step: 4
Training loss: 0.7812997102737427
Validation loss: 1.8611861736543718

Epoch: 5| Step: 5
Training loss: 1.1516822576522827
Validation loss: 1.8935440804368706

Epoch: 5| Step: 6
Training loss: 1.4064786434173584
Validation loss: 1.8920647200717722

Epoch: 5| Step: 7
Training loss: 1.4576160907745361
Validation loss: 1.861817136887581

Epoch: 5| Step: 8
Training loss: 1.3673992156982422
Validation loss: 1.80599675127255

Epoch: 5| Step: 9
Training loss: 1.0918304920196533
Validation loss: 1.8027990210440852

Epoch: 5| Step: 10
Training loss: 0.905333936214447
Validation loss: 1.911892649947956

Epoch: 446| Step: 0
Training loss: 1.4224342107772827
Validation loss: 1.8418110519327142

Epoch: 5| Step: 1
Training loss: 1.1545345783233643
Validation loss: 1.8131364327605053

Epoch: 5| Step: 2
Training loss: 1.1267496347427368
Validation loss: 1.8919172376714728

Epoch: 5| Step: 3
Training loss: 0.8590776324272156
Validation loss: 1.8239104337589715

Epoch: 5| Step: 4
Training loss: 1.193028211593628
Validation loss: 1.844104584827218

Epoch: 5| Step: 5
Training loss: 1.1820576190948486
Validation loss: 1.8707035997862458

Epoch: 5| Step: 6
Training loss: 1.8738372325897217
Validation loss: 1.9281648948628416

Epoch: 5| Step: 7
Training loss: 1.1295839548110962
Validation loss: 1.8503191804373136

Epoch: 5| Step: 8
Training loss: 0.8961679339408875
Validation loss: 1.8299871644666117

Epoch: 5| Step: 9
Training loss: 0.897193431854248
Validation loss: 1.8610334242543867

Epoch: 5| Step: 10
Training loss: 1.2602992057800293
Validation loss: 1.8644164146915558

Epoch: 447| Step: 0
Training loss: 1.0138753652572632
Validation loss: 1.8902382094372985

Epoch: 5| Step: 1
Training loss: 1.344308614730835
Validation loss: 1.8767226767796341

Epoch: 5| Step: 2
Training loss: 1.6536449193954468
Validation loss: 1.9254691767436203

Epoch: 5| Step: 3
Training loss: 1.025007963180542
Validation loss: 1.8451600420859553

Epoch: 5| Step: 4
Training loss: 1.2890163660049438
Validation loss: 1.8978538308092343

Epoch: 5| Step: 5
Training loss: 1.1478264331817627
Validation loss: 1.901748744390344

Epoch: 5| Step: 6
Training loss: 1.4295313358306885
Validation loss: 1.8627255219285206

Epoch: 5| Step: 7
Training loss: 1.3892282247543335
Validation loss: 1.9393469915595105

Epoch: 5| Step: 8
Training loss: 0.8435459136962891
Validation loss: 1.8879416014558525

Epoch: 5| Step: 9
Training loss: 1.2806806564331055
Validation loss: 1.8577833150022773

Epoch: 5| Step: 10
Training loss: 1.0647132396697998
Validation loss: 1.8876291295533538

Epoch: 448| Step: 0
Training loss: 1.5472043752670288
Validation loss: 1.9103747337095198

Epoch: 5| Step: 1
Training loss: 1.1063165664672852
Validation loss: 1.8601160357075353

Epoch: 5| Step: 2
Training loss: 0.7916289567947388
Validation loss: 1.7997394607913109

Epoch: 5| Step: 3
Training loss: 1.1788485050201416
Validation loss: 1.873670563902906

Epoch: 5| Step: 4
Training loss: 1.295250654220581
Validation loss: 1.8831332665617748

Epoch: 5| Step: 5
Training loss: 0.9266551733016968
Validation loss: 1.8595823959637714

Epoch: 5| Step: 6
Training loss: 1.2780431509017944
Validation loss: 1.8820534867625083

Epoch: 5| Step: 7
Training loss: 1.048360824584961
Validation loss: 1.8745195839994697

Epoch: 5| Step: 8
Training loss: 1.3027315139770508
Validation loss: 1.8805948918865574

Epoch: 5| Step: 9
Training loss: 1.7150013446807861
Validation loss: 1.8338475445265412

Epoch: 5| Step: 10
Training loss: 1.244078278541565
Validation loss: 1.7658235847309072

Epoch: 449| Step: 0
Training loss: 1.1105619668960571
Validation loss: 1.8544589011899886

Epoch: 5| Step: 1
Training loss: 1.0752675533294678
Validation loss: 1.8091713254169752

Epoch: 5| Step: 2
Training loss: 1.4646562337875366
Validation loss: 1.8259153545543712

Epoch: 5| Step: 3
Training loss: 1.194000482559204
Validation loss: 1.8090242519173572

Epoch: 5| Step: 4
Training loss: 1.2675776481628418
Validation loss: 1.900949978059338

Epoch: 5| Step: 5
Training loss: 0.7918834686279297
Validation loss: 1.858779611126069

Epoch: 5| Step: 6
Training loss: 1.2559678554534912
Validation loss: 1.9543711036764166

Epoch: 5| Step: 7
Training loss: 1.4410849809646606
Validation loss: 1.8355429633971183

Epoch: 5| Step: 8
Training loss: 1.4601970911026
Validation loss: 1.860405324607767

Epoch: 5| Step: 9
Training loss: 0.952429473400116
Validation loss: 1.9071189383024811

Epoch: 5| Step: 10
Training loss: 1.4089460372924805
Validation loss: 1.8583977183988016

Epoch: 450| Step: 0
Training loss: 0.9793055653572083
Validation loss: 1.9440939285421883

Epoch: 5| Step: 1
Training loss: 1.1904594898223877
Validation loss: 1.8228580080052859

Epoch: 5| Step: 2
Training loss: 1.6199897527694702
Validation loss: 1.881835679854116

Epoch: 5| Step: 3
Training loss: 0.8299455642700195
Validation loss: 1.9187787053405598

Epoch: 5| Step: 4
Training loss: 0.8964360952377319
Validation loss: 1.862443552222303

Epoch: 5| Step: 5
Training loss: 0.760286271572113
Validation loss: 1.8285378973971131

Epoch: 5| Step: 6
Training loss: 1.32568359375
Validation loss: 1.8325951868487942

Epoch: 5| Step: 7
Training loss: 1.5126333236694336
Validation loss: 1.8045910173846829

Epoch: 5| Step: 8
Training loss: 1.1757748126983643
Validation loss: 1.84347015811551

Epoch: 5| Step: 9
Training loss: 1.6688191890716553
Validation loss: 1.876468623838117

Epoch: 5| Step: 10
Training loss: 1.2599865198135376
Validation loss: 1.8196972095838158

Epoch: 451| Step: 0
Training loss: 1.7953733205795288
Validation loss: 1.876412913363467

Epoch: 5| Step: 1
Training loss: 1.4253942966461182
Validation loss: 1.8486225335828719

Epoch: 5| Step: 2
Training loss: 1.583899736404419
Validation loss: 1.8445471358555618

Epoch: 5| Step: 3
Training loss: 1.0617790222167969
Validation loss: 1.8796703520641531

Epoch: 5| Step: 4
Training loss: 1.0556042194366455
Validation loss: 1.8668831292019095

Epoch: 5| Step: 5
Training loss: 1.3352113962173462
Validation loss: 1.8501099501886675

Epoch: 5| Step: 6
Training loss: 1.7004047632217407
Validation loss: 1.9037994697529783

Epoch: 5| Step: 7
Training loss: 0.8690688014030457
Validation loss: 1.827009431777462

Epoch: 5| Step: 8
Training loss: 0.6294124126434326
Validation loss: 1.8473505076541696

Epoch: 5| Step: 9
Training loss: 0.7075427174568176
Validation loss: 1.8348419320198797

Epoch: 5| Step: 10
Training loss: 1.1341733932495117
Validation loss: 1.833056631908622

Epoch: 452| Step: 0
Training loss: 1.2331266403198242
Validation loss: 1.8776028989463724

Epoch: 5| Step: 1
Training loss: 1.7719123363494873
Validation loss: 1.8454715615959578

Epoch: 5| Step: 2
Training loss: 1.3493115901947021
Validation loss: 1.8885916151026243

Epoch: 5| Step: 3
Training loss: 1.3393964767456055
Validation loss: 1.908020568150346

Epoch: 5| Step: 4
Training loss: 1.3873673677444458
Validation loss: 1.8987617210675312

Epoch: 5| Step: 5
Training loss: 1.5010510683059692
Validation loss: 1.894651516791313

Epoch: 5| Step: 6
Training loss: 1.0874059200286865
Validation loss: 1.9203998722055906

Epoch: 5| Step: 7
Training loss: 0.8836160898208618
Validation loss: 1.8408120844953804

Epoch: 5| Step: 8
Training loss: 0.9123233556747437
Validation loss: 1.8663975731019051

Epoch: 5| Step: 9
Training loss: 1.1194499731063843
Validation loss: 1.9099479298437796

Epoch: 5| Step: 10
Training loss: 0.5599669814109802
Validation loss: 1.848849065842167

Epoch: 453| Step: 0
Training loss: 1.3558193445205688
Validation loss: 1.8184797610006025

Epoch: 5| Step: 1
Training loss: 0.9283323287963867
Validation loss: 1.8706677536810599

Epoch: 5| Step: 2
Training loss: 0.9851690530776978
Validation loss: 1.8798808590058358

Epoch: 5| Step: 3
Training loss: 1.0355093479156494
Validation loss: 1.870517151330107

Epoch: 5| Step: 4
Training loss: 1.1296205520629883
Validation loss: 1.9162639161591888

Epoch: 5| Step: 5
Training loss: 1.2210813760757446
Validation loss: 1.9125569789640364

Epoch: 5| Step: 6
Training loss: 1.4551045894622803
Validation loss: 1.8552992728448683

Epoch: 5| Step: 7
Training loss: 0.6570457220077515
Validation loss: 1.9074311576863772

Epoch: 5| Step: 8
Training loss: 1.267139196395874
Validation loss: 1.8556846034142278

Epoch: 5| Step: 9
Training loss: 1.4595695734024048
Validation loss: 1.8835886768115464

Epoch: 5| Step: 10
Training loss: 1.7679346799850464
Validation loss: 1.8250962508622037

Epoch: 454| Step: 0
Training loss: 1.548142671585083
Validation loss: 1.8630115024505123

Epoch: 5| Step: 1
Training loss: 0.9547093510627747
Validation loss: 1.8716367483139038

Epoch: 5| Step: 2
Training loss: 1.006361722946167
Validation loss: 1.9259698160233036

Epoch: 5| Step: 3
Training loss: 1.3408974409103394
Validation loss: 1.8602832517316263

Epoch: 5| Step: 4
Training loss: 1.1156842708587646
Validation loss: 1.8680867148983864

Epoch: 5| Step: 5
Training loss: 1.4414023160934448
Validation loss: 1.797010152570663

Epoch: 5| Step: 6
Training loss: 1.0411063432693481
Validation loss: 1.8728606572715185

Epoch: 5| Step: 7
Training loss: 0.38574033975601196
Validation loss: 1.8438402965504637

Epoch: 5| Step: 8
Training loss: 1.5431578159332275
Validation loss: 1.848733760977304

Epoch: 5| Step: 9
Training loss: 1.894730567932129
Validation loss: 1.8354013043065225

Epoch: 5| Step: 10
Training loss: 1.2952359914779663
Validation loss: 1.8499628318253385

Epoch: 455| Step: 0
Training loss: 1.5555181503295898
Validation loss: 1.8433580014013475

Epoch: 5| Step: 1
Training loss: 0.5519628524780273
Validation loss: 1.8373572570021435

Epoch: 5| Step: 2
Training loss: 1.5854202508926392
Validation loss: 1.8534472347587667

Epoch: 5| Step: 3
Training loss: 1.4377912282943726
Validation loss: 1.8057278792063396

Epoch: 5| Step: 4
Training loss: 1.0778989791870117
Validation loss: 1.799062418681319

Epoch: 5| Step: 5
Training loss: 0.9064325094223022
Validation loss: 1.8697487205587409

Epoch: 5| Step: 6
Training loss: 1.110266089439392
Validation loss: 1.8433405571086432

Epoch: 5| Step: 7
Training loss: 1.1948769092559814
Validation loss: 1.892814620848625

Epoch: 5| Step: 8
Training loss: 1.0995514392852783
Validation loss: 1.843805391301391

Epoch: 5| Step: 9
Training loss: 1.2549009323120117
Validation loss: 1.8813912894136162

Epoch: 5| Step: 10
Training loss: 1.071974754333496
Validation loss: 1.8400606455341462

Epoch: 456| Step: 0
Training loss: 1.754992127418518
Validation loss: 1.9161964001194123

Epoch: 5| Step: 1
Training loss: 1.3825905323028564
Validation loss: 1.8371698471807665

Epoch: 5| Step: 2
Training loss: 0.7024357318878174
Validation loss: 1.8068618633413827

Epoch: 5| Step: 3
Training loss: 0.9078719019889832
Validation loss: 1.9200798555087017

Epoch: 5| Step: 4
Training loss: 1.1310409307479858
Validation loss: 1.872144518360015

Epoch: 5| Step: 5
Training loss: 0.9374715685844421
Validation loss: 1.8593981317294541

Epoch: 5| Step: 6
Training loss: 0.6251541376113892
Validation loss: 1.866864768407678

Epoch: 5| Step: 7
Training loss: 1.6537048816680908
Validation loss: 1.8643973758143764

Epoch: 5| Step: 8
Training loss: 1.3286559581756592
Validation loss: 1.8749280091254943

Epoch: 5| Step: 9
Training loss: 1.2733882665634155
Validation loss: 1.8784933013300742

Epoch: 5| Step: 10
Training loss: 1.4100643396377563
Validation loss: 1.855218364346412

Epoch: 457| Step: 0
Training loss: 1.525763750076294
Validation loss: 1.8859597585534538

Epoch: 5| Step: 1
Training loss: 1.0975251197814941
Validation loss: 1.7996376842580817

Epoch: 5| Step: 2
Training loss: 0.7138343453407288
Validation loss: 1.8687121522042058

Epoch: 5| Step: 3
Training loss: 1.5208561420440674
Validation loss: 1.8391342829632502

Epoch: 5| Step: 4
Training loss: 0.9906673431396484
Validation loss: 1.8673920733954317

Epoch: 5| Step: 5
Training loss: 0.8870477676391602
Validation loss: 1.8739532924467517

Epoch: 5| Step: 6
Training loss: 1.0230028629302979
Validation loss: 1.858680079060216

Epoch: 5| Step: 7
Training loss: 1.4775359630584717
Validation loss: 1.8503021270998063

Epoch: 5| Step: 8
Training loss: 1.0107133388519287
Validation loss: 1.8588851446746497

Epoch: 5| Step: 9
Training loss: 1.0481027364730835
Validation loss: 1.860822380229991

Epoch: 5| Step: 10
Training loss: 1.5242515802383423
Validation loss: 1.8278814900305964

Epoch: 458| Step: 0
Training loss: 0.7960816621780396
Validation loss: 1.8203549602980256

Epoch: 5| Step: 1
Training loss: 1.8479888439178467
Validation loss: 1.8834648798870783

Epoch: 5| Step: 2
Training loss: 1.1734228134155273
Validation loss: 1.7803039858418126

Epoch: 5| Step: 3
Training loss: 1.2514512538909912
Validation loss: 1.8925828792715584

Epoch: 5| Step: 4
Training loss: 0.9621304273605347
Validation loss: 1.8830422739828787

Epoch: 5| Step: 5
Training loss: 1.0390511751174927
Validation loss: 1.8109188964290004

Epoch: 5| Step: 6
Training loss: 1.5364434719085693
Validation loss: 1.9307910434661373

Epoch: 5| Step: 7
Training loss: 1.2260053157806396
Validation loss: 1.8882059512599823

Epoch: 5| Step: 8
Training loss: 1.0434292554855347
Validation loss: 1.9009444700774325

Epoch: 5| Step: 9
Training loss: 0.9160066843032837
Validation loss: 1.8380540622177945

Epoch: 5| Step: 10
Training loss: 1.0654337406158447
Validation loss: 1.9119446533982472

Epoch: 459| Step: 0
Training loss: 0.955197811126709
Validation loss: 1.8523438463928878

Epoch: 5| Step: 1
Training loss: 1.4504261016845703
Validation loss: 1.9086776164270216

Epoch: 5| Step: 2
Training loss: 1.0633275508880615
Validation loss: 1.9188897686619912

Epoch: 5| Step: 3
Training loss: 1.5260300636291504
Validation loss: 1.8683159633349347

Epoch: 5| Step: 4
Training loss: 1.202887773513794
Validation loss: 1.833311641088096

Epoch: 5| Step: 5
Training loss: 0.9448682069778442
Validation loss: 1.8754909346180577

Epoch: 5| Step: 6
Training loss: 0.9316016435623169
Validation loss: 1.822439443680548

Epoch: 5| Step: 7
Training loss: 1.184988260269165
Validation loss: 1.7118386530107068

Epoch: 5| Step: 8
Training loss: 1.414306879043579
Validation loss: 1.864281326211909

Epoch: 5| Step: 9
Training loss: 0.9704256057739258
Validation loss: 1.8458334399807839

Epoch: 5| Step: 10
Training loss: 1.4967900514602661
Validation loss: 1.8662324002994004

Epoch: 460| Step: 0
Training loss: 1.0531394481658936
Validation loss: 1.8238159213014828

Epoch: 5| Step: 1
Training loss: 1.2522612810134888
Validation loss: 1.844542170083651

Epoch: 5| Step: 2
Training loss: 0.9654213190078735
Validation loss: 1.8541285760941044

Epoch: 5| Step: 3
Training loss: 1.3530590534210205
Validation loss: 1.785070805139439

Epoch: 5| Step: 4
Training loss: 0.7889015078544617
Validation loss: 1.897582107974637

Epoch: 5| Step: 5
Training loss: 1.717990517616272
Validation loss: 1.8904560201911516

Epoch: 5| Step: 6
Training loss: 0.9600761532783508
Validation loss: 1.859634368650375

Epoch: 5| Step: 7
Training loss: 1.446305513381958
Validation loss: 1.8695602038855195

Epoch: 5| Step: 8
Training loss: 1.1233000755310059
Validation loss: 1.903834983866702

Epoch: 5| Step: 9
Training loss: 1.3415706157684326
Validation loss: 1.8051373061313425

Epoch: 5| Step: 10
Training loss: 0.7181859016418457
Validation loss: 1.7986106436739686

Epoch: 461| Step: 0
Training loss: 1.4327257871627808
Validation loss: 1.8433986351054201

Epoch: 5| Step: 1
Training loss: 1.7631248235702515
Validation loss: 1.8312019071271342

Epoch: 5| Step: 2
Training loss: 1.351330041885376
Validation loss: 1.8554472064459195

Epoch: 5| Step: 3
Training loss: 0.7719731330871582
Validation loss: 1.8328619926206526

Epoch: 5| Step: 4
Training loss: 1.2374427318572998
Validation loss: 1.9189942318906066

Epoch: 5| Step: 5
Training loss: 1.0357993841171265
Validation loss: 1.902798411666706

Epoch: 5| Step: 6
Training loss: 1.1317479610443115
Validation loss: 1.7703686798772504

Epoch: 5| Step: 7
Training loss: 1.0711222887039185
Validation loss: 1.8145715908337665

Epoch: 5| Step: 8
Training loss: 1.0868728160858154
Validation loss: 1.8253102469187912

Epoch: 5| Step: 9
Training loss: 0.7944917678833008
Validation loss: 1.8513665635098693

Epoch: 5| Step: 10
Training loss: 1.4323865175247192
Validation loss: 1.8590730454332085

Epoch: 462| Step: 0
Training loss: 1.0595821142196655
Validation loss: 1.8215768465431788

Epoch: 5| Step: 1
Training loss: 1.2105103731155396
Validation loss: 1.8104183673858643

Epoch: 5| Step: 2
Training loss: 1.1204954385757446
Validation loss: 1.866872323456631

Epoch: 5| Step: 3
Training loss: 0.7772349119186401
Validation loss: 1.8387324528027607

Epoch: 5| Step: 4
Training loss: 1.2252440452575684
Validation loss: 1.8022524861879246

Epoch: 5| Step: 5
Training loss: 1.0536541938781738
Validation loss: 1.821520556685745

Epoch: 5| Step: 6
Training loss: 0.9212819933891296
Validation loss: 1.8325250687137726

Epoch: 5| Step: 7
Training loss: 1.1987053155899048
Validation loss: 1.9038011079193444

Epoch: 5| Step: 8
Training loss: 1.2775964736938477
Validation loss: 1.8592812309982956

Epoch: 5| Step: 9
Training loss: 1.762813925743103
Validation loss: 1.9132376024799962

Epoch: 5| Step: 10
Training loss: 1.5171724557876587
Validation loss: 1.8432091500169487

Epoch: 463| Step: 0
Training loss: 1.3380800485610962
Validation loss: 1.84676476575995

Epoch: 5| Step: 1
Training loss: 1.133103609085083
Validation loss: 1.8790254938986994

Epoch: 5| Step: 2
Training loss: 1.6752221584320068
Validation loss: 1.849563685796594

Epoch: 5| Step: 3
Training loss: 1.1480087041854858
Validation loss: 1.8379306434303202

Epoch: 5| Step: 4
Training loss: 0.9906218647956848
Validation loss: 1.8353802939896942

Epoch: 5| Step: 5
Training loss: 1.5294145345687866
Validation loss: 1.831438749067245

Epoch: 5| Step: 6
Training loss: 0.9387091398239136
Validation loss: 1.8725291323918167

Epoch: 5| Step: 7
Training loss: 1.0544029474258423
Validation loss: 1.8363476773743987

Epoch: 5| Step: 8
Training loss: 0.6638861894607544
Validation loss: 1.7934468830785444

Epoch: 5| Step: 9
Training loss: 1.181398868560791
Validation loss: 1.8973209832304267

Epoch: 5| Step: 10
Training loss: 0.9864351749420166
Validation loss: 1.9214568086849746

Epoch: 464| Step: 0
Training loss: 1.0325307846069336
Validation loss: 1.8740973216231152

Epoch: 5| Step: 1
Training loss: 0.794582188129425
Validation loss: 1.807180453372258

Epoch: 5| Step: 2
Training loss: 1.3892790079116821
Validation loss: 1.9011104670904015

Epoch: 5| Step: 3
Training loss: 1.3013125658035278
Validation loss: 1.8321764866511028

Epoch: 5| Step: 4
Training loss: 1.1673452854156494
Validation loss: 1.884052853430471

Epoch: 5| Step: 5
Training loss: 1.323136329650879
Validation loss: 1.84319172879701

Epoch: 5| Step: 6
Training loss: 1.13983154296875
Validation loss: 1.9077495554442048

Epoch: 5| Step: 7
Training loss: 1.2890642881393433
Validation loss: 1.8473176340903006

Epoch: 5| Step: 8
Training loss: 0.7698478698730469
Validation loss: 1.9265100802144697

Epoch: 5| Step: 9
Training loss: 1.2209476232528687
Validation loss: 1.884713743322639

Epoch: 5| Step: 10
Training loss: 1.4449303150177002
Validation loss: 1.8745244087711457

Epoch: 465| Step: 0
Training loss: 0.8567358255386353
Validation loss: 1.9063035531710553

Epoch: 5| Step: 1
Training loss: 0.7155014276504517
Validation loss: 1.827421990774011

Epoch: 5| Step: 2
Training loss: 1.0414600372314453
Validation loss: 1.9191212590022753

Epoch: 5| Step: 3
Training loss: 1.7465438842773438
Validation loss: 1.8675445023403372

Epoch: 5| Step: 4
Training loss: 1.0219064950942993
Validation loss: 1.8588541861503356

Epoch: 5| Step: 5
Training loss: 1.319381594657898
Validation loss: 1.8544655961375083

Epoch: 5| Step: 6
Training loss: 1.0320302248001099
Validation loss: 1.861537689803749

Epoch: 5| Step: 7
Training loss: 1.503922462463379
Validation loss: 1.8499908113992343

Epoch: 5| Step: 8
Training loss: 1.1650736331939697
Validation loss: 1.8499357520893056

Epoch: 5| Step: 9
Training loss: 1.5745162963867188
Validation loss: 1.819787327961255

Epoch: 5| Step: 10
Training loss: 1.0532411336898804
Validation loss: 1.793249660922635

Epoch: 466| Step: 0
Training loss: 0.9108380079269409
Validation loss: 1.7950169283856627

Epoch: 5| Step: 1
Training loss: 1.1105666160583496
Validation loss: 1.8362844105689757

Epoch: 5| Step: 2
Training loss: 1.0756360292434692
Validation loss: 1.873368118398933

Epoch: 5| Step: 3
Training loss: 1.4538214206695557
Validation loss: 1.8998565827646563

Epoch: 5| Step: 4
Training loss: 1.4836667776107788
Validation loss: 1.8703554996880152

Epoch: 5| Step: 5
Training loss: 0.8527362942695618
Validation loss: 1.846509927062578

Epoch: 5| Step: 6
Training loss: 1.0522676706314087
Validation loss: 1.8755921830413163

Epoch: 5| Step: 7
Training loss: 1.0930068492889404
Validation loss: 1.8469478725105204

Epoch: 5| Step: 8
Training loss: 1.7290422916412354
Validation loss: 1.8636645911842264

Epoch: 5| Step: 9
Training loss: 0.9391342997550964
Validation loss: 1.837250159632775

Epoch: 5| Step: 10
Training loss: 1.3376694917678833
Validation loss: 1.8510728151567521

Epoch: 467| Step: 0
Training loss: 1.4277634620666504
Validation loss: 1.8438876085383917

Epoch: 5| Step: 1
Training loss: 1.1849825382232666
Validation loss: 1.8459038478071972

Epoch: 5| Step: 2
Training loss: 0.7901355624198914
Validation loss: 1.7773157319714945

Epoch: 5| Step: 3
Training loss: 1.7619333267211914
Validation loss: 1.8290528174369567

Epoch: 5| Step: 4
Training loss: 0.9070947766304016
Validation loss: 1.8907754946780462

Epoch: 5| Step: 5
Training loss: 1.0684645175933838
Validation loss: 1.85665714099843

Epoch: 5| Step: 6
Training loss: 1.206720232963562
Validation loss: 1.8477419640428276

Epoch: 5| Step: 7
Training loss: 1.0886307954788208
Validation loss: 1.827552842837508

Epoch: 5| Step: 8
Training loss: 1.3901861906051636
Validation loss: 1.8256837270593131

Epoch: 5| Step: 9
Training loss: 1.1210790872573853
Validation loss: 1.8533374032666605

Epoch: 5| Step: 10
Training loss: 1.0789973735809326
Validation loss: 1.8521561725165254

Epoch: 468| Step: 0
Training loss: 1.0708674192428589
Validation loss: 1.9119172724344398

Epoch: 5| Step: 1
Training loss: 1.1854642629623413
Validation loss: 1.8820178701031594

Epoch: 5| Step: 2
Training loss: 1.5341815948486328
Validation loss: 1.9137192490280315

Epoch: 5| Step: 3
Training loss: 0.7863331437110901
Validation loss: 1.857874047371649

Epoch: 5| Step: 4
Training loss: 0.909075140953064
Validation loss: 1.8357219747317735

Epoch: 5| Step: 5
Training loss: 1.288878083229065
Validation loss: 1.803050418053904

Epoch: 5| Step: 6
Training loss: 1.194689154624939
Validation loss: 1.789106979165026

Epoch: 5| Step: 7
Training loss: 1.1342958211898804
Validation loss: 1.8121065862717167

Epoch: 5| Step: 8
Training loss: 1.2946670055389404
Validation loss: 1.8636073809798046

Epoch: 5| Step: 9
Training loss: 1.3068944215774536
Validation loss: 1.8192845313779769

Epoch: 5| Step: 10
Training loss: 1.4807885885238647
Validation loss: 1.8119135697682698

Epoch: 469| Step: 0
Training loss: 0.671212911605835
Validation loss: 1.904318222435572

Epoch: 5| Step: 1
Training loss: 1.475408673286438
Validation loss: 1.9497030088978429

Epoch: 5| Step: 2
Training loss: 1.444718599319458
Validation loss: 1.8049760300626037

Epoch: 5| Step: 3
Training loss: 0.7741312980651855
Validation loss: 1.844347410304572

Epoch: 5| Step: 4
Training loss: 1.00788152217865
Validation loss: 1.8954029121706564

Epoch: 5| Step: 5
Training loss: 1.1494500637054443
Validation loss: 1.844886690057734

Epoch: 5| Step: 6
Training loss: 1.1302971839904785
Validation loss: 1.8565667854842318

Epoch: 5| Step: 7
Training loss: 1.091688871383667
Validation loss: 1.89103058333038

Epoch: 5| Step: 8
Training loss: 1.066629409790039
Validation loss: 1.851120912900535

Epoch: 5| Step: 9
Training loss: 1.557201623916626
Validation loss: 1.7890892797900784

Epoch: 5| Step: 10
Training loss: 1.4674476385116577
Validation loss: 1.8674123300019132

Epoch: 470| Step: 0
Training loss: 1.2975932359695435
Validation loss: 1.8369609643054265

Epoch: 5| Step: 1
Training loss: 1.0966265201568604
Validation loss: 1.8844584059971634

Epoch: 5| Step: 2
Training loss: 1.117765188217163
Validation loss: 1.7964940878652758

Epoch: 5| Step: 3
Training loss: 1.4116541147232056
Validation loss: 1.9200777289687947

Epoch: 5| Step: 4
Training loss: 1.0097792148590088
Validation loss: 1.8455277694168912

Epoch: 5| Step: 5
Training loss: 1.137131690979004
Validation loss: 1.8404787868581793

Epoch: 5| Step: 6
Training loss: 1.556713581085205
Validation loss: 1.863319827664283

Epoch: 5| Step: 7
Training loss: 1.0364073514938354
Validation loss: 1.8945616035051243

Epoch: 5| Step: 8
Training loss: 0.5959845185279846
Validation loss: 1.9294821780215028

Epoch: 5| Step: 9
Training loss: 1.3467013835906982
Validation loss: 1.8428192753945627

Epoch: 5| Step: 10
Training loss: 1.218379020690918
Validation loss: 1.8756477243156844

Epoch: 471| Step: 0
Training loss: 0.6735816597938538
Validation loss: 1.8438734546784432

Epoch: 5| Step: 1
Training loss: 1.8354038000106812
Validation loss: 1.788165012995402

Epoch: 5| Step: 2
Training loss: 0.9528972506523132
Validation loss: 1.853754089724633

Epoch: 5| Step: 3
Training loss: 1.0100334882736206
Validation loss: 1.8794709661955475

Epoch: 5| Step: 4
Training loss: 1.2949321269989014
Validation loss: 1.7864859757884857

Epoch: 5| Step: 5
Training loss: 0.9555435180664062
Validation loss: 1.8617298910694737

Epoch: 5| Step: 6
Training loss: 1.1827417612075806
Validation loss: 1.8216165957912323

Epoch: 5| Step: 7
Training loss: 1.0578473806381226
Validation loss: 1.8325257942240725

Epoch: 5| Step: 8
Training loss: 1.421753168106079
Validation loss: 1.9143942068981867

Epoch: 5| Step: 9
Training loss: 1.4452855587005615
Validation loss: 1.8372417457642094

Epoch: 5| Step: 10
Training loss: 0.9362872242927551
Validation loss: 1.8533741274187643

Epoch: 472| Step: 0
Training loss: 1.2816823720932007
Validation loss: 1.8553367186618108

Epoch: 5| Step: 1
Training loss: 1.2905964851379395
Validation loss: 1.8091601248710387

Epoch: 5| Step: 2
Training loss: 0.7191664576530457
Validation loss: 1.7811253506650206

Epoch: 5| Step: 3
Training loss: 1.2972546815872192
Validation loss: 1.8316732657852994

Epoch: 5| Step: 4
Training loss: 1.1620490550994873
Validation loss: 1.8559498940744708

Epoch: 5| Step: 5
Training loss: 1.1024223566055298
Validation loss: 1.840471831701135

Epoch: 5| Step: 6
Training loss: 1.067112922668457
Validation loss: 1.8523945731501426

Epoch: 5| Step: 7
Training loss: 0.8517156839370728
Validation loss: 1.794883842109352

Epoch: 5| Step: 8
Training loss: 1.3209445476531982
Validation loss: 1.784046511496267

Epoch: 5| Step: 9
Training loss: 1.2317845821380615
Validation loss: 1.8821632092998875

Epoch: 5| Step: 10
Training loss: 1.128623604774475
Validation loss: 1.7861671011934999

Epoch: 473| Step: 0
Training loss: 1.313544511795044
Validation loss: 1.8312865816136843

Epoch: 5| Step: 1
Training loss: 1.0647764205932617
Validation loss: 1.8550616765535006

Epoch: 5| Step: 2
Training loss: 1.1551926136016846
Validation loss: 1.8882369790025937

Epoch: 5| Step: 3
Training loss: 0.8091421127319336
Validation loss: 1.8922887335541427

Epoch: 5| Step: 4
Training loss: 0.997031033039093
Validation loss: 1.8947444474825295

Epoch: 5| Step: 5
Training loss: 0.9703275561332703
Validation loss: 1.8727535214475406

Epoch: 5| Step: 6
Training loss: 1.1967923641204834
Validation loss: 1.785648984293784

Epoch: 5| Step: 7
Training loss: 0.8730255365371704
Validation loss: 1.8811459451593378

Epoch: 5| Step: 8
Training loss: 1.5980838537216187
Validation loss: 1.8023366723009335

Epoch: 5| Step: 9
Training loss: 1.6087009906768799
Validation loss: 1.797838795569635

Epoch: 5| Step: 10
Training loss: 1.353478193283081
Validation loss: 1.8469095371102775

Epoch: 474| Step: 0
Training loss: 1.1183764934539795
Validation loss: 1.8285910519220496

Epoch: 5| Step: 1
Training loss: 1.4850608110427856
Validation loss: 1.8260051665767547

Epoch: 5| Step: 2
Training loss: 1.0087770223617554
Validation loss: 1.8539555591921653

Epoch: 5| Step: 3
Training loss: 1.125711441040039
Validation loss: 1.8475840091705322

Epoch: 5| Step: 4
Training loss: 1.090815782546997
Validation loss: 1.8303606356343916

Epoch: 5| Step: 5
Training loss: 1.3777559995651245
Validation loss: 1.8058941518106768

Epoch: 5| Step: 6
Training loss: 1.3565102815628052
Validation loss: 1.8327481515945927

Epoch: 5| Step: 7
Training loss: 1.1103839874267578
Validation loss: 1.8438911412351875

Epoch: 5| Step: 8
Training loss: 0.982730507850647
Validation loss: 1.8666950976976784

Epoch: 5| Step: 9
Training loss: 1.1243420839309692
Validation loss: 1.8742498787500526

Epoch: 5| Step: 10
Training loss: 0.7546195983886719
Validation loss: 1.8324101778768724

Epoch: 475| Step: 0
Training loss: 1.1720341444015503
Validation loss: 1.8084483313304123

Epoch: 5| Step: 1
Training loss: 0.876705527305603
Validation loss: 1.8012743662762385

Epoch: 5| Step: 2
Training loss: 0.3270402252674103
Validation loss: 1.8522756663701867

Epoch: 5| Step: 3
Training loss: 1.6946258544921875
Validation loss: 1.8674639886425388

Epoch: 5| Step: 4
Training loss: 0.9474071264266968
Validation loss: 1.8337120266370877

Epoch: 5| Step: 5
Training loss: 0.987469494342804
Validation loss: 1.8130642188492643

Epoch: 5| Step: 6
Training loss: 1.2001323699951172
Validation loss: 1.8424092800386491

Epoch: 5| Step: 7
Training loss: 1.370197057723999
Validation loss: 1.8608273921474334

Epoch: 5| Step: 8
Training loss: 1.4826741218566895
Validation loss: 1.806131705161064

Epoch: 5| Step: 9
Training loss: 1.0635182857513428
Validation loss: 1.8515343294348767

Epoch: 5| Step: 10
Training loss: 1.3961575031280518
Validation loss: 1.809115263723558

Epoch: 476| Step: 0
Training loss: 1.4559173583984375
Validation loss: 1.797859827677409

Epoch: 5| Step: 1
Training loss: 0.7169870734214783
Validation loss: 1.847671522889086

Epoch: 5| Step: 2
Training loss: 1.0586801767349243
Validation loss: 1.8272221703683176

Epoch: 5| Step: 3
Training loss: 0.7914358377456665
Validation loss: 1.8623275436380857

Epoch: 5| Step: 4
Training loss: 1.545241117477417
Validation loss: 1.885391157160523

Epoch: 5| Step: 5
Training loss: 1.4648325443267822
Validation loss: 1.9047153008881437

Epoch: 5| Step: 6
Training loss: 1.3008029460906982
Validation loss: 1.8899119348936184

Epoch: 5| Step: 7
Training loss: 0.9356731176376343
Validation loss: 1.8763520256165536

Epoch: 5| Step: 8
Training loss: 0.9105741381645203
Validation loss: 1.910208507250714

Epoch: 5| Step: 9
Training loss: 1.2293273210525513
Validation loss: 1.8787263016546927

Epoch: 5| Step: 10
Training loss: 1.11931574344635
Validation loss: 1.8908149657710906

Epoch: 477| Step: 0
Training loss: 1.1458368301391602
Validation loss: 1.8072344897895731

Epoch: 5| Step: 1
Training loss: 0.9535226821899414
Validation loss: 1.8498249899956487

Epoch: 5| Step: 2
Training loss: 1.479751706123352
Validation loss: 1.9168367680682932

Epoch: 5| Step: 3
Training loss: 1.4213699102401733
Validation loss: 1.8293444789865965

Epoch: 5| Step: 4
Training loss: 0.9479579925537109
Validation loss: 1.8171269227099676

Epoch: 5| Step: 5
Training loss: 1.0647897720336914
Validation loss: 1.7859930351216307

Epoch: 5| Step: 6
Training loss: 0.7554929852485657
Validation loss: 1.7701749199180192

Epoch: 5| Step: 7
Training loss: 1.398087501525879
Validation loss: 1.8287966456464542

Epoch: 5| Step: 8
Training loss: 0.9728506207466125
Validation loss: 1.8447184934410998

Epoch: 5| Step: 9
Training loss: 1.497380018234253
Validation loss: 1.7855938339746127

Epoch: 5| Step: 10
Training loss: 0.8294019103050232
Validation loss: 1.892789029305981

Epoch: 478| Step: 0
Training loss: 1.0718767642974854
Validation loss: 1.8378196352271623

Epoch: 5| Step: 1
Training loss: 0.9195384979248047
Validation loss: 1.8466977816756054

Epoch: 5| Step: 2
Training loss: 1.1788904666900635
Validation loss: 1.8047655500391477

Epoch: 5| Step: 3
Training loss: 0.9772977828979492
Validation loss: 1.7937703568448302

Epoch: 5| Step: 4
Training loss: 1.096230387687683
Validation loss: 1.830532737957534

Epoch: 5| Step: 5
Training loss: 1.1942553520202637
Validation loss: 1.863244359211255

Epoch: 5| Step: 6
Training loss: 1.166091799736023
Validation loss: 1.8343943293376634

Epoch: 5| Step: 7
Training loss: 0.8994209170341492
Validation loss: 1.8570177503811416

Epoch: 5| Step: 8
Training loss: 1.2336333990097046
Validation loss: 1.8429516028332453

Epoch: 5| Step: 9
Training loss: 1.1957021951675415
Validation loss: 1.8721863403115222

Epoch: 5| Step: 10
Training loss: 1.3671438694000244
Validation loss: 1.8131066253108363

Epoch: 479| Step: 0
Training loss: 0.38101550936698914
Validation loss: 1.8445892962076331

Epoch: 5| Step: 1
Training loss: 1.0930100679397583
Validation loss: 1.853696543683288

Epoch: 5| Step: 2
Training loss: 1.0247305631637573
Validation loss: 1.821215687259551

Epoch: 5| Step: 3
Training loss: 1.4509161710739136
Validation loss: 1.8381800831005137

Epoch: 5| Step: 4
Training loss: 1.4591434001922607
Validation loss: 1.8131715495099303

Epoch: 5| Step: 5
Training loss: 1.2371234893798828
Validation loss: 1.8594249807378298

Epoch: 5| Step: 6
Training loss: 1.567629098892212
Validation loss: 1.847777828093498

Epoch: 5| Step: 7
Training loss: 1.2384109497070312
Validation loss: 1.8334019491749425

Epoch: 5| Step: 8
Training loss: 0.950474739074707
Validation loss: 1.8257209959850516

Epoch: 5| Step: 9
Training loss: 0.6041990518569946
Validation loss: 1.8582554042980235

Epoch: 5| Step: 10
Training loss: 1.039720058441162
Validation loss: 1.8850254371602049

Epoch: 480| Step: 0
Training loss: 0.7015803456306458
Validation loss: 1.9096105047451553

Epoch: 5| Step: 1
Training loss: 1.061192512512207
Validation loss: 1.8762074260301487

Epoch: 5| Step: 2
Training loss: 0.8300789594650269
Validation loss: 1.8834848775658557

Epoch: 5| Step: 3
Training loss: 1.0747827291488647
Validation loss: 1.805799312489007

Epoch: 5| Step: 4
Training loss: 0.9872760772705078
Validation loss: 1.876672875496649

Epoch: 5| Step: 5
Training loss: 1.2710319757461548
Validation loss: 1.7939080487015426

Epoch: 5| Step: 6
Training loss: 1.5110529661178589
Validation loss: 1.888481996392691

Epoch: 5| Step: 7
Training loss: 1.2515804767608643
Validation loss: 1.841308847550423

Epoch: 5| Step: 8
Training loss: 1.6639997959136963
Validation loss: 1.8705924839101813

Epoch: 5| Step: 9
Training loss: 0.8909805417060852
Validation loss: 1.896638096019786

Epoch: 5| Step: 10
Training loss: 0.9611549377441406
Validation loss: 1.850964153966596

Epoch: 481| Step: 0
Training loss: 1.1321494579315186
Validation loss: 1.8862876328088904

Epoch: 5| Step: 1
Training loss: 1.7218191623687744
Validation loss: 1.8158187744438008

Epoch: 5| Step: 2
Training loss: 1.1323035955429077
Validation loss: 1.890389714189755

Epoch: 5| Step: 3
Training loss: 1.2156728506088257
Validation loss: 1.877539668031918

Epoch: 5| Step: 4
Training loss: 1.3628208637237549
Validation loss: 1.9034706469505065

Epoch: 5| Step: 5
Training loss: 1.046919584274292
Validation loss: 1.8330805391393683

Epoch: 5| Step: 6
Training loss: 0.8935493230819702
Validation loss: 1.847144406328919

Epoch: 5| Step: 7
Training loss: 0.8763427734375
Validation loss: 1.8446591079875987

Epoch: 5| Step: 8
Training loss: 1.0606822967529297
Validation loss: 1.8453631849699124

Epoch: 5| Step: 9
Training loss: 1.2379653453826904
Validation loss: 1.8220255528726885

Epoch: 5| Step: 10
Training loss: 0.9088872075080872
Validation loss: 1.8131179732661094

Epoch: 482| Step: 0
Training loss: 1.205132246017456
Validation loss: 1.8547863716720252

Epoch: 5| Step: 1
Training loss: 1.1271432638168335
Validation loss: 1.835769348247077

Epoch: 5| Step: 2
Training loss: 1.8260749578475952
Validation loss: 1.8831097579771472

Epoch: 5| Step: 3
Training loss: 0.6652592420578003
Validation loss: 1.797786424877823

Epoch: 5| Step: 4
Training loss: 1.4907166957855225
Validation loss: 1.8221710625515188

Epoch: 5| Step: 5
Training loss: 0.8292891383171082
Validation loss: 1.8630810501754924

Epoch: 5| Step: 6
Training loss: 1.0696837902069092
Validation loss: 1.9205990299101798

Epoch: 5| Step: 7
Training loss: 1.4728161096572876
Validation loss: 1.8270231498185026

Epoch: 5| Step: 8
Training loss: 0.8740040063858032
Validation loss: 1.8830012147144606

Epoch: 5| Step: 9
Training loss: 0.9989725351333618
Validation loss: 1.827083949119814

Epoch: 5| Step: 10
Training loss: 1.2974642515182495
Validation loss: 1.8379391841990973

Epoch: 483| Step: 0
Training loss: 1.0069090127944946
Validation loss: 1.8555321719056816

Epoch: 5| Step: 1
Training loss: 1.2066357135772705
Validation loss: 1.8473461315196047

Epoch: 5| Step: 2
Training loss: 1.5334750413894653
Validation loss: 1.7903541313704623

Epoch: 5| Step: 3
Training loss: 0.876835823059082
Validation loss: 1.8993218265553957

Epoch: 5| Step: 4
Training loss: 0.7942110300064087
Validation loss: 1.8835936079743087

Epoch: 5| Step: 5
Training loss: 1.1401126384735107
Validation loss: 1.8302426248468378

Epoch: 5| Step: 6
Training loss: 1.6486139297485352
Validation loss: 1.8495294060758365

Epoch: 5| Step: 7
Training loss: 1.7237167358398438
Validation loss: 1.845120846584279

Epoch: 5| Step: 8
Training loss: 1.165808081626892
Validation loss: 1.8200948738282727

Epoch: 5| Step: 9
Training loss: 0.9161089658737183
Validation loss: 1.8583463109949583

Epoch: 5| Step: 10
Training loss: 0.6470280885696411
Validation loss: 1.840791094687677

Epoch: 484| Step: 0
Training loss: 0.8217788934707642
Validation loss: 1.8520387065026067

Epoch: 5| Step: 1
Training loss: 1.5507625341415405
Validation loss: 1.9454836742852324

Epoch: 5| Step: 2
Training loss: 1.3043880462646484
Validation loss: 1.8288762197699597

Epoch: 5| Step: 3
Training loss: 0.768218994140625
Validation loss: 1.8922251321936165

Epoch: 5| Step: 4
Training loss: 1.0044763088226318
Validation loss: 1.8660043119102396

Epoch: 5| Step: 5
Training loss: 1.1091493368148804
Validation loss: 1.8301867464537263

Epoch: 5| Step: 6
Training loss: 0.9083746075630188
Validation loss: 1.8697117246607298

Epoch: 5| Step: 7
Training loss: 0.9297391772270203
Validation loss: 1.8090986244140133

Epoch: 5| Step: 8
Training loss: 1.2830522060394287
Validation loss: 1.865278572164556

Epoch: 5| Step: 9
Training loss: 1.2597978115081787
Validation loss: 1.8069729676810644

Epoch: 5| Step: 10
Training loss: 1.4772489070892334
Validation loss: 1.8568031070052937

Epoch: 485| Step: 0
Training loss: 0.8764591217041016
Validation loss: 1.8785847899734334

Epoch: 5| Step: 1
Training loss: 1.0925525426864624
Validation loss: 1.8346715152904551

Epoch: 5| Step: 2
Training loss: 1.2207746505737305
Validation loss: 1.8581438897758402

Epoch: 5| Step: 3
Training loss: 0.921269416809082
Validation loss: 1.8459006624837075

Epoch: 5| Step: 4
Training loss: 0.9188112020492554
Validation loss: 1.8229348274969286

Epoch: 5| Step: 5
Training loss: 1.03555166721344
Validation loss: 1.9433342769581785

Epoch: 5| Step: 6
Training loss: 1.0261160135269165
Validation loss: 1.835935144014256

Epoch: 5| Step: 7
Training loss: 1.1653375625610352
Validation loss: 1.8532066665669924

Epoch: 5| Step: 8
Training loss: 1.4427284002304077
Validation loss: 1.861992246361189

Epoch: 5| Step: 9
Training loss: 1.1129496097564697
Validation loss: 1.9173376547392977

Epoch: 5| Step: 10
Training loss: 1.3217908143997192
Validation loss: 1.8535543231553928

Epoch: 486| Step: 0
Training loss: 1.1121714115142822
Validation loss: 1.829155425871572

Epoch: 5| Step: 1
Training loss: 0.9781425595283508
Validation loss: 1.8672505886323991

Epoch: 5| Step: 2
Training loss: 1.0121691226959229
Validation loss: 1.8625049462882421

Epoch: 5| Step: 3
Training loss: 0.9521095156669617
Validation loss: 1.8563509448882072

Epoch: 5| Step: 4
Training loss: 1.8711429834365845
Validation loss: 1.8797900061453543

Epoch: 5| Step: 5
Training loss: 1.490587830543518
Validation loss: 1.8494138128014022

Epoch: 5| Step: 6
Training loss: 1.2987053394317627
Validation loss: 1.848380111878918

Epoch: 5| Step: 7
Training loss: 0.8391321301460266
Validation loss: 1.8726372000991658

Epoch: 5| Step: 8
Training loss: 0.8826322555541992
Validation loss: 1.8991899221174178

Epoch: 5| Step: 9
Training loss: 1.093427062034607
Validation loss: 1.8219642305886874

Epoch: 5| Step: 10
Training loss: 1.1391310691833496
Validation loss: 1.8713935190631497

Epoch: 487| Step: 0
Training loss: 0.9015209078788757
Validation loss: 1.8767651960413942

Epoch: 5| Step: 1
Training loss: 0.7181512713432312
Validation loss: 1.8539825716326315

Epoch: 5| Step: 2
Training loss: 0.9258723258972168
Validation loss: 1.8248908929927374

Epoch: 5| Step: 3
Training loss: 1.5253779888153076
Validation loss: 1.8593703546831686

Epoch: 5| Step: 4
Training loss: 1.037358283996582
Validation loss: 1.8740646762232627

Epoch: 5| Step: 5
Training loss: 1.076955795288086
Validation loss: 1.8755462605466124

Epoch: 5| Step: 6
Training loss: 1.1758514642715454
Validation loss: 1.8206131509555283

Epoch: 5| Step: 7
Training loss: 0.881913959980011
Validation loss: 1.8196801165098786

Epoch: 5| Step: 8
Training loss: 1.3925468921661377
Validation loss: 1.842942023790011

Epoch: 5| Step: 9
Training loss: 1.6118278503417969
Validation loss: 1.8067175931827997

Epoch: 5| Step: 10
Training loss: 1.1729364395141602
Validation loss: 1.810242752875051

Epoch: 488| Step: 0
Training loss: 0.9862397909164429
Validation loss: 1.7933647914599347

Epoch: 5| Step: 1
Training loss: 1.1555287837982178
Validation loss: 1.8082853094224007

Epoch: 5| Step: 2
Training loss: 1.0308477878570557
Validation loss: 1.8625196359490837

Epoch: 5| Step: 3
Training loss: 1.2586853504180908
Validation loss: 1.816338135350135

Epoch: 5| Step: 4
Training loss: 1.120750069618225
Validation loss: 1.8698039567598732

Epoch: 5| Step: 5
Training loss: 1.3234223127365112
Validation loss: 1.810540815835358

Epoch: 5| Step: 6
Training loss: 1.0682251453399658
Validation loss: 1.8616854029317056

Epoch: 5| Step: 7
Training loss: 0.8240453600883484
Validation loss: 1.8780712517358924

Epoch: 5| Step: 8
Training loss: 1.1926822662353516
Validation loss: 1.914648853322511

Epoch: 5| Step: 9
Training loss: 1.5503166913986206
Validation loss: 1.816356985799728

Epoch: 5| Step: 10
Training loss: 0.8170562982559204
Validation loss: 1.863530671724709

Epoch: 489| Step: 0
Training loss: 1.371978759765625
Validation loss: 1.8276762423976776

Epoch: 5| Step: 1
Training loss: 0.7802968621253967
Validation loss: 1.8847258962610716

Epoch: 5| Step: 2
Training loss: 0.6243435144424438
Validation loss: 1.858204395540299

Epoch: 5| Step: 3
Training loss: 1.1368683576583862
Validation loss: 1.8404616399477887

Epoch: 5| Step: 4
Training loss: 1.0498746633529663
Validation loss: 1.895097098042888

Epoch: 5| Step: 5
Training loss: 1.2774548530578613
Validation loss: 1.844820785266097

Epoch: 5| Step: 6
Training loss: 1.202242136001587
Validation loss: 1.8666481459012596

Epoch: 5| Step: 7
Training loss: 1.0818606615066528
Validation loss: 1.8744682855503534

Epoch: 5| Step: 8
Training loss: 1.0310492515563965
Validation loss: 1.8288939229903682

Epoch: 5| Step: 9
Training loss: 1.647658109664917
Validation loss: 1.8701608001544912

Epoch: 5| Step: 10
Training loss: 1.32331120967865
Validation loss: 1.7253855761661325

Epoch: 490| Step: 0
Training loss: 1.5715315341949463
Validation loss: 1.8310548387547976

Epoch: 5| Step: 1
Training loss: 1.1124374866485596
Validation loss: 1.8433376127673733

Epoch: 5| Step: 2
Training loss: 1.1911754608154297
Validation loss: 1.8092957273606332

Epoch: 5| Step: 3
Training loss: 0.671000599861145
Validation loss: 1.8463430635390743

Epoch: 5| Step: 4
Training loss: 1.405112624168396
Validation loss: 1.8329606017758768

Epoch: 5| Step: 5
Training loss: 0.8611167669296265
Validation loss: 1.8679497113791845

Epoch: 5| Step: 6
Training loss: 1.3454071283340454
Validation loss: 1.884074943040007

Epoch: 5| Step: 7
Training loss: 1.3469572067260742
Validation loss: 1.8239521582921345

Epoch: 5| Step: 8
Training loss: 1.356755018234253
Validation loss: 1.779791001350649

Epoch: 5| Step: 9
Training loss: 0.8127685785293579
Validation loss: 1.8699180797864032

Epoch: 5| Step: 10
Training loss: 0.8721276521682739
Validation loss: 1.9082567461075322

Epoch: 491| Step: 0
Training loss: 1.0062319040298462
Validation loss: 1.880546869770173

Epoch: 5| Step: 1
Training loss: 0.8879712224006653
Validation loss: 1.8568494268642959

Epoch: 5| Step: 2
Training loss: 1.1096372604370117
Validation loss: 1.9226625196395382

Epoch: 5| Step: 3
Training loss: 1.2713589668273926
Validation loss: 1.9005132913589478

Epoch: 5| Step: 4
Training loss: 1.7809385061264038
Validation loss: 1.8648432044572727

Epoch: 5| Step: 5
Training loss: 1.746026635169983
Validation loss: 1.8562197480150449

Epoch: 5| Step: 6
Training loss: 1.2401212453842163
Validation loss: 1.8626501893484464

Epoch: 5| Step: 7
Training loss: 0.7856347560882568
Validation loss: 1.8456104827183548

Epoch: 5| Step: 8
Training loss: 1.180081844329834
Validation loss: 1.8289214026543401

Epoch: 5| Step: 9
Training loss: 0.9070137143135071
Validation loss: 1.862098442610874

Epoch: 5| Step: 10
Training loss: 0.8812875151634216
Validation loss: 1.846198776716827

Epoch: 492| Step: 0
Training loss: 0.7564122676849365
Validation loss: 1.8496437277845157

Epoch: 5| Step: 1
Training loss: 1.2316815853118896
Validation loss: 1.8322364489237468

Epoch: 5| Step: 2
Training loss: 1.1132588386535645
Validation loss: 1.790387245916551

Epoch: 5| Step: 3
Training loss: 1.3366903066635132
Validation loss: 1.8284733756895988

Epoch: 5| Step: 4
Training loss: 1.6894546747207642
Validation loss: 1.8231671292294738

Epoch: 5| Step: 5
Training loss: 1.0078325271606445
Validation loss: 1.8545113430228284

Epoch: 5| Step: 6
Training loss: 1.022865891456604
Validation loss: 1.8891855901287449

Epoch: 5| Step: 7
Training loss: 0.6770002245903015
Validation loss: 1.837685433767175

Epoch: 5| Step: 8
Training loss: 0.6860905289649963
Validation loss: 1.8541153861630348

Epoch: 5| Step: 9
Training loss: 1.2039588689804077
Validation loss: 1.8280882707206152

Epoch: 5| Step: 10
Training loss: 1.9815586805343628
Validation loss: 1.87963314594761

Epoch: 493| Step: 0
Training loss: 0.7389826774597168
Validation loss: 1.8727534612019856

Epoch: 5| Step: 1
Training loss: 0.9340665936470032
Validation loss: 1.893233701746951

Epoch: 5| Step: 2
Training loss: 1.183538556098938
Validation loss: 1.807046721058507

Epoch: 5| Step: 3
Training loss: 1.1136311292648315
Validation loss: 1.8040245489407611

Epoch: 5| Step: 4
Training loss: 0.8090869784355164
Validation loss: 1.8497346754997008

Epoch: 5| Step: 5
Training loss: 1.0402966737747192
Validation loss: 1.7969667475710633

Epoch: 5| Step: 6
Training loss: 1.2187150716781616
Validation loss: 1.7969009850614814

Epoch: 5| Step: 7
Training loss: 1.4670953750610352
Validation loss: 1.871115046162759

Epoch: 5| Step: 8
Training loss: 0.9200980067253113
Validation loss: 1.8224421598578011

Epoch: 5| Step: 9
Training loss: 0.6729801297187805
Validation loss: 1.8566883571686283

Epoch: 5| Step: 10
Training loss: 1.9012998342514038
Validation loss: 1.8281282686418103

Epoch: 494| Step: 0
Training loss: 1.0501439571380615
Validation loss: 1.8312173556256037

Epoch: 5| Step: 1
Training loss: 1.0587961673736572
Validation loss: 1.8384088380362398

Epoch: 5| Step: 2
Training loss: 0.9178573489189148
Validation loss: 1.8306964123120872

Epoch: 5| Step: 3
Training loss: 1.2513329982757568
Validation loss: 1.835379272378901

Epoch: 5| Step: 4
Training loss: 0.8499120473861694
Validation loss: 1.8281813052392775

Epoch: 5| Step: 5
Training loss: 0.7566419839859009
Validation loss: 1.8615889292891308

Epoch: 5| Step: 6
Training loss: 1.150593876838684
Validation loss: 1.8221850190111386

Epoch: 5| Step: 7
Training loss: 1.4493483304977417
Validation loss: 1.8797050112037248

Epoch: 5| Step: 8
Training loss: 1.1144996881484985
Validation loss: 1.7965655326843262

Epoch: 5| Step: 9
Training loss: 1.2870426177978516
Validation loss: 1.835958767962712

Epoch: 5| Step: 10
Training loss: 1.0323925018310547
Validation loss: 1.9056007592908797

Epoch: 495| Step: 0
Training loss: 0.9789319038391113
Validation loss: 1.9242571284694057

Epoch: 5| Step: 1
Training loss: 1.6861299276351929
Validation loss: 1.8961933133422688

Epoch: 5| Step: 2
Training loss: 1.6020240783691406
Validation loss: 1.8948259597183557

Epoch: 5| Step: 3
Training loss: 1.0963280200958252
Validation loss: 1.860254777375088

Epoch: 5| Step: 4
Training loss: 1.2054283618927002
Validation loss: 1.9182531167102117

Epoch: 5| Step: 5
Training loss: 1.563470721244812
Validation loss: 1.801456456543297

Epoch: 5| Step: 6
Training loss: 1.0875335931777954
Validation loss: 1.8278201600556732

Epoch: 5| Step: 7
Training loss: 0.9871789813041687
Validation loss: 1.8429374194914294

Epoch: 5| Step: 8
Training loss: 0.5429984331130981
Validation loss: 1.8341573258881927

Epoch: 5| Step: 9
Training loss: 1.1277012825012207
Validation loss: 1.818163905092465

Epoch: 5| Step: 10
Training loss: 0.4717896282672882
Validation loss: 1.8477304853418821

Epoch: 496| Step: 0
Training loss: 1.0128521919250488
Validation loss: 1.8316033796597553

Epoch: 5| Step: 1
Training loss: 1.1296087503433228
Validation loss: 1.8082602857261576

Epoch: 5| Step: 2
Training loss: 1.062587022781372
Validation loss: 1.809829226104162

Epoch: 5| Step: 3
Training loss: 1.306937575340271
Validation loss: 1.765066482687509

Epoch: 5| Step: 4
Training loss: 1.1323333978652954
Validation loss: 1.807475092590496

Epoch: 5| Step: 5
Training loss: 1.8582403659820557
Validation loss: 1.7961248018408333

Epoch: 5| Step: 6
Training loss: 1.0370900630950928
Validation loss: 1.8364866061877179

Epoch: 5| Step: 7
Training loss: 0.967629075050354
Validation loss: 1.7995157216184883

Epoch: 5| Step: 8
Training loss: 1.4196364879608154
Validation loss: 1.8424409448459584

Epoch: 5| Step: 9
Training loss: 0.6884966492652893
Validation loss: 1.9117607839645878

Epoch: 5| Step: 10
Training loss: 0.6860842108726501
Validation loss: 1.8368106811277327

Epoch: 497| Step: 0
Training loss: 1.2812303304672241
Validation loss: 1.8670887895809707

Epoch: 5| Step: 1
Training loss: 1.0068668127059937
Validation loss: 1.9524397773127402

Epoch: 5| Step: 2
Training loss: 0.8713222742080688
Validation loss: 1.8586120759287188

Epoch: 5| Step: 3
Training loss: 0.7128924131393433
Validation loss: 1.8816627622932516

Epoch: 5| Step: 4
Training loss: 1.1981329917907715
Validation loss: 1.8413172050188946

Epoch: 5| Step: 5
Training loss: 0.8870490193367004
Validation loss: 1.8895097983780729

Epoch: 5| Step: 6
Training loss: 1.240051507949829
Validation loss: 1.9073102781849522

Epoch: 5| Step: 7
Training loss: 1.6532090902328491
Validation loss: 1.8742630109992078

Epoch: 5| Step: 8
Training loss: 1.1408040523529053
Validation loss: 1.816072961335541

Epoch: 5| Step: 9
Training loss: 1.0434976816177368
Validation loss: 1.8335201919719737

Epoch: 5| Step: 10
Training loss: 1.0999274253845215
Validation loss: 1.7853362508999404

Epoch: 498| Step: 0
Training loss: 0.947503387928009
Validation loss: 1.787505006277433

Epoch: 5| Step: 1
Training loss: 1.5789241790771484
Validation loss: 1.8222272524269678

Epoch: 5| Step: 2
Training loss: 0.7950210571289062
Validation loss: 1.8189355519510084

Epoch: 5| Step: 3
Training loss: 1.0430288314819336
Validation loss: 1.8701316310513405

Epoch: 5| Step: 4
Training loss: 0.7591830492019653
Validation loss: 1.8064015719198412

Epoch: 5| Step: 5
Training loss: 0.9503520131111145
Validation loss: 1.8309690657482351

Epoch: 5| Step: 6
Training loss: 0.8546568155288696
Validation loss: 1.8648777661785003

Epoch: 5| Step: 7
Training loss: 1.2805297374725342
Validation loss: 1.8249474827961256

Epoch: 5| Step: 8
Training loss: 1.3687618970870972
Validation loss: 1.8596272648021739

Epoch: 5| Step: 9
Training loss: 0.9051502346992493
Validation loss: 1.860406389800451

Epoch: 5| Step: 10
Training loss: 1.7407506704330444
Validation loss: 1.8934739571745678

Epoch: 499| Step: 0
Training loss: 1.5056909322738647
Validation loss: 1.8919671889274352

Epoch: 5| Step: 1
Training loss: 1.0012550354003906
Validation loss: 1.8533796520643337

Epoch: 5| Step: 2
Training loss: 1.2816921472549438
Validation loss: 1.8629683243331088

Epoch: 5| Step: 3
Training loss: 0.9416197538375854
Validation loss: 1.7751014591545187

Epoch: 5| Step: 4
Training loss: 0.7744247317314148
Validation loss: 1.8466420506918302

Epoch: 5| Step: 5
Training loss: 0.6849938035011292
Validation loss: 1.8734681170473817

Epoch: 5| Step: 6
Training loss: 1.2574894428253174
Validation loss: 1.8347936163666427

Epoch: 5| Step: 7
Training loss: 0.8888531923294067
Validation loss: 1.851039691637921

Epoch: 5| Step: 8
Training loss: 1.4428861141204834
Validation loss: 1.8537611012817712

Epoch: 5| Step: 9
Training loss: 1.0744539499282837
Validation loss: 1.8253601661292456

Epoch: 5| Step: 10
Training loss: 1.190618634223938
Validation loss: 1.8176957407305319

Epoch: 500| Step: 0
Training loss: 1.3837798833847046
Validation loss: 1.8636827212508007

Epoch: 5| Step: 1
Training loss: 1.3278526067733765
Validation loss: 1.80160722168543

Epoch: 5| Step: 2
Training loss: 0.9190016984939575
Validation loss: 1.819376378931025

Epoch: 5| Step: 3
Training loss: 0.954245388507843
Validation loss: 1.8798134455116846

Epoch: 5| Step: 4
Training loss: 1.0454366207122803
Validation loss: 1.7792733753881147

Epoch: 5| Step: 5
Training loss: 1.4196662902832031
Validation loss: 1.8862910783419045

Epoch: 5| Step: 6
Training loss: 1.3569961786270142
Validation loss: 1.8388439686067644

Epoch: 5| Step: 7
Training loss: 1.222076654434204
Validation loss: 1.868729801588161

Epoch: 5| Step: 8
Training loss: 0.6287537217140198
Validation loss: 1.8485428992138113

Epoch: 5| Step: 9
Training loss: 0.7937915325164795
Validation loss: 1.8730041634651922

Epoch: 5| Step: 10
Training loss: 0.8972479701042175
Validation loss: 1.8267417107858965

Testing loss: 2.4565114974975586
