Epoch: 1| Step: 0
Training loss: 5.097482635932447
Validation loss: 4.350483992575804

Epoch: 5| Step: 1
Training loss: 5.181629950163336
Validation loss: 4.344899836655118

Epoch: 5| Step: 2
Training loss: 4.939310635177874
Validation loss: 4.341471658471203

Epoch: 5| Step: 3
Training loss: 3.5435627667517307
Validation loss: 4.334610922652258

Epoch: 5| Step: 4
Training loss: 3.0014457397945185
Validation loss: 4.327517055581347

Epoch: 5| Step: 5
Training loss: 4.4698028391254905
Validation loss: 4.322898259613585

Epoch: 5| Step: 6
Training loss: 4.3500599210273325
Validation loss: 4.316376883654149

Epoch: 5| Step: 7
Training loss: 4.958381438890142
Validation loss: 4.313764812601075

Epoch: 5| Step: 8
Training loss: 4.035000734388245
Validation loss: 4.305512076343687

Epoch: 5| Step: 9
Training loss: 4.026333435198392
Validation loss: 4.301895960269767

Epoch: 5| Step: 10
Training loss: 4.858591488783844
Validation loss: 4.294727383728977

Epoch: 2| Step: 0
Training loss: 3.564499812408284
Validation loss: 4.290807618708286

Epoch: 5| Step: 1
Training loss: 5.014309624477914
Validation loss: 4.284776296920511

Epoch: 5| Step: 2
Training loss: 4.113415258530474
Validation loss: 4.281171025068058

Epoch: 5| Step: 3
Training loss: 4.250411069849046
Validation loss: 4.278099603341694

Epoch: 5| Step: 4
Training loss: 3.828033944428877
Validation loss: 4.271530050518548

Epoch: 5| Step: 5
Training loss: 4.852808400749987
Validation loss: 4.266169908725776

Epoch: 5| Step: 6
Training loss: 4.762404257144881
Validation loss: 4.261146629498387

Epoch: 5| Step: 7
Training loss: 5.075457156783199
Validation loss: 4.254631361332416

Epoch: 5| Step: 8
Training loss: 4.172434337138152
Validation loss: 4.250805227785647

Epoch: 5| Step: 9
Training loss: 4.3300948635220005
Validation loss: 4.245679296165473

Epoch: 5| Step: 10
Training loss: 4.044448891195943
Validation loss: 4.238175799197459

Epoch: 3| Step: 0
Training loss: 4.751627994425922
Validation loss: 4.236757428960809

Epoch: 5| Step: 1
Training loss: 3.408743968996057
Validation loss: 4.228433384294862

Epoch: 5| Step: 2
Training loss: 3.624846751163611
Validation loss: 4.223955976831675

Epoch: 5| Step: 3
Training loss: 5.057567878301579
Validation loss: 4.218791744826259

Epoch: 5| Step: 4
Training loss: 4.054377490707815
Validation loss: 4.21587344673325

Epoch: 5| Step: 5
Training loss: 3.4169621843763514
Validation loss: 4.207855508571569

Epoch: 5| Step: 6
Training loss: 4.582030833732931
Validation loss: 4.20340777914829

Epoch: 5| Step: 7
Training loss: 4.932023113261544
Validation loss: 4.199034486025028

Epoch: 5| Step: 8
Training loss: 4.86586492457748
Validation loss: 4.191544278229451

Epoch: 5| Step: 9
Training loss: 3.960870806190851
Validation loss: 4.1864928539054045

Epoch: 5| Step: 10
Training loss: 4.707826412672875
Validation loss: 4.180048754121654

Epoch: 4| Step: 0
Training loss: 4.401982831672767
Validation loss: 4.176673169154842

Epoch: 5| Step: 1
Training loss: 5.232784929313938
Validation loss: 4.1713109403423205

Epoch: 5| Step: 2
Training loss: 4.830695890601642
Validation loss: 4.163249586382872

Epoch: 5| Step: 3
Training loss: 3.5022137316758477
Validation loss: 4.155921971818944

Epoch: 5| Step: 4
Training loss: 4.312483635470536
Validation loss: 4.149445041714644

Epoch: 5| Step: 5
Training loss: 4.991858911819104
Validation loss: 4.1458223989664775

Epoch: 5| Step: 6
Training loss: 2.8363563081228738
Validation loss: 4.141620888792006

Epoch: 5| Step: 7
Training loss: 4.62794030005773
Validation loss: 4.13324144334366

Epoch: 5| Step: 8
Training loss: 4.2767421630316615
Validation loss: 4.129393280593323

Epoch: 5| Step: 9
Training loss: 4.05154114587749
Validation loss: 4.123275242126183

Epoch: 5| Step: 10
Training loss: 3.2864750994190666
Validation loss: 4.116777720520048

Epoch: 5| Step: 0
Training loss: 4.237394375455233
Validation loss: 4.111305108260605

Epoch: 5| Step: 1
Training loss: 4.796580153359531
Validation loss: 4.106747344920804

Epoch: 5| Step: 2
Training loss: 4.621182696404656
Validation loss: 4.101029973850286

Epoch: 5| Step: 3
Training loss: 3.421941887188746
Validation loss: 4.092088249503444

Epoch: 5| Step: 4
Training loss: 4.116835635240131
Validation loss: 4.08783806862298

Epoch: 5| Step: 5
Training loss: 4.5122913344051545
Validation loss: 4.078869653706565

Epoch: 5| Step: 6
Training loss: 4.179938249998881
Validation loss: 4.07430154137026

Epoch: 5| Step: 7
Training loss: 4.060964206022108
Validation loss: 4.068459653165716

Epoch: 5| Step: 8
Training loss: 4.120305482224067
Validation loss: 4.067264206121176

Epoch: 5| Step: 9
Training loss: 4.213130570936969
Validation loss: 4.057410832042737

Epoch: 5| Step: 10
Training loss: 4.006116244125998
Validation loss: 4.050956252779374

Epoch: 6| Step: 0
Training loss: 4.649654350970198
Validation loss: 4.04288102785446

Epoch: 5| Step: 1
Training loss: 4.253617037775349
Validation loss: 4.03632895789944

Epoch: 5| Step: 2
Training loss: 3.66705135292649
Validation loss: 4.031545063682238

Epoch: 5| Step: 3
Training loss: 4.419443061573178
Validation loss: 4.0230085654622165

Epoch: 5| Step: 4
Training loss: 3.7364192458994654
Validation loss: 4.0193890470572144

Epoch: 5| Step: 5
Training loss: 3.7028790484811496
Validation loss: 4.011511609438455

Epoch: 5| Step: 6
Training loss: 4.560656240324108
Validation loss: 4.005444464331724

Epoch: 5| Step: 7
Training loss: 3.8968131861185396
Validation loss: 4.000093032154969

Epoch: 5| Step: 8
Training loss: 4.597276644402207
Validation loss: 3.9898369024538645

Epoch: 5| Step: 9
Training loss: 4.042301141286446
Validation loss: 3.9824327104016293

Epoch: 5| Step: 10
Training loss: 4.053850326402304
Validation loss: 3.97841485696552

Epoch: 7| Step: 0
Training loss: 4.019795549042701
Validation loss: 3.966747248544521

Epoch: 5| Step: 1
Training loss: 4.1020358729809585
Validation loss: 3.962864776908547

Epoch: 5| Step: 2
Training loss: 4.169835424308771
Validation loss: 3.9593311164061475

Epoch: 5| Step: 3
Training loss: 3.7752711419757086
Validation loss: 3.947965486524265

Epoch: 5| Step: 4
Training loss: 3.7991331316340946
Validation loss: 3.9434080449765103

Epoch: 5| Step: 5
Training loss: 3.7662125125187935
Validation loss: 3.9355613257742514

Epoch: 5| Step: 6
Training loss: 4.28223491393855
Validation loss: 3.926744892290997

Epoch: 5| Step: 7
Training loss: 4.2091121645334
Validation loss: 3.9200956057370075

Epoch: 5| Step: 8
Training loss: 4.3548481725774515
Validation loss: 3.9110883803777594

Epoch: 5| Step: 9
Training loss: 4.331651703673045
Validation loss: 3.9082346163938295

Epoch: 5| Step: 10
Training loss: 4.11604493011182
Validation loss: 3.898035731265562

Epoch: 8| Step: 0
Training loss: 4.1310800768465334
Validation loss: 3.8914260998244634

Epoch: 5| Step: 1
Training loss: 4.432605246699878
Validation loss: 3.882640283574683

Epoch: 5| Step: 2
Training loss: 4.057391902026579
Validation loss: 3.87275391211504

Epoch: 5| Step: 3
Training loss: 3.96360168545262
Validation loss: 3.8647016122359736

Epoch: 5| Step: 4
Training loss: 4.3426323420201
Validation loss: 3.853477573846715

Epoch: 5| Step: 5
Training loss: 3.9296434525131403
Validation loss: 3.8477055202236423

Epoch: 5| Step: 6
Training loss: 3.4624674495998624
Validation loss: 3.839311679976725

Epoch: 5| Step: 7
Training loss: 3.2283363177105673
Validation loss: 3.8312198373217856

Epoch: 5| Step: 8
Training loss: 2.8022575371537344
Validation loss: 3.824738251284209

Epoch: 5| Step: 9
Training loss: 4.75025798699325
Validation loss: 3.8184871480474616

Epoch: 5| Step: 10
Training loss: 4.696303581965754
Validation loss: 3.8031182368968097

Epoch: 9| Step: 0
Training loss: 4.8797423941987175
Validation loss: 3.7985987661225

Epoch: 5| Step: 1
Training loss: 3.340340275134634
Validation loss: 3.783767613273138

Epoch: 5| Step: 2
Training loss: 3.598490631731609
Validation loss: 3.7775742338054816

Epoch: 5| Step: 3
Training loss: 4.247915991158998
Validation loss: 3.767666625736644

Epoch: 5| Step: 4
Training loss: 4.208345822356675
Validation loss: 3.753421688106139

Epoch: 5| Step: 5
Training loss: 5.167296443006461
Validation loss: 3.7479413962076604

Epoch: 5| Step: 6
Training loss: 3.471575436857731
Validation loss: 3.7400214712419255

Epoch: 5| Step: 7
Training loss: 3.161039740530153
Validation loss: 3.7338849579954685

Epoch: 5| Step: 8
Training loss: 3.824656008542363
Validation loss: 3.718878384217508

Epoch: 5| Step: 9
Training loss: 3.2507280854652123
Validation loss: 3.713288431951227

Epoch: 5| Step: 10
Training loss: 3.314252713584091
Validation loss: 3.7009112164221953

Epoch: 10| Step: 0
Training loss: 3.720811544926247
Validation loss: 3.6905694099260122

Epoch: 5| Step: 1
Training loss: 3.6591653530877495
Validation loss: 3.680065780642926

Epoch: 5| Step: 2
Training loss: 4.110055613269124
Validation loss: 3.670757319610927

Epoch: 5| Step: 3
Training loss: 2.951989010901531
Validation loss: 3.6602573021642506

Epoch: 5| Step: 4
Training loss: 4.265255866654687
Validation loss: 3.6543294081372064

Epoch: 5| Step: 5
Training loss: 3.7222906615637954
Validation loss: 3.6462679574324075

Epoch: 5| Step: 6
Training loss: 3.5414458411692618
Validation loss: 3.6357633622423577

Epoch: 5| Step: 7
Training loss: 3.882970426790185
Validation loss: 3.6245676305425607

Epoch: 5| Step: 8
Training loss: 3.090061184916227
Validation loss: 3.6120338343831246

Epoch: 5| Step: 9
Training loss: 4.548328285386884
Validation loss: 3.603321661838097

Epoch: 5| Step: 10
Training loss: 4.275674126550127
Validation loss: 3.5940405244461964

Epoch: 11| Step: 0
Training loss: 3.7998838708098206
Validation loss: 3.5838934915325726

Epoch: 5| Step: 1
Training loss: 3.4240994125622835
Validation loss: 3.5728394788138482

Epoch: 5| Step: 2
Training loss: 3.824516744566269
Validation loss: 3.5633876754615432

Epoch: 5| Step: 3
Training loss: 3.295572900589976
Validation loss: 3.551603642427273

Epoch: 5| Step: 4
Training loss: 4.043598277150877
Validation loss: 3.5427082684760136

Epoch: 5| Step: 5
Training loss: 3.991388946513616
Validation loss: 3.5260684189466467

Epoch: 5| Step: 6
Training loss: 4.231552027596478
Validation loss: 3.5166663563859464

Epoch: 5| Step: 7
Training loss: 3.0939765616024175
Validation loss: 3.5059400625224555

Epoch: 5| Step: 8
Training loss: 3.7745582069419426
Validation loss: 3.497517489087327

Epoch: 5| Step: 9
Training loss: 3.2531567428168846
Validation loss: 3.4823170109892563

Epoch: 5| Step: 10
Training loss: 4.022879967438984
Validation loss: 3.4706527249537777

Epoch: 12| Step: 0
Training loss: 3.711262963729424
Validation loss: 3.460614224794561

Epoch: 5| Step: 1
Training loss: 3.14223973910377
Validation loss: 3.4494555064611285

Epoch: 5| Step: 2
Training loss: 3.1930486218734515
Validation loss: 3.4376966492905954

Epoch: 5| Step: 3
Training loss: 3.1677894776745696
Validation loss: 3.4225680625734265

Epoch: 5| Step: 4
Training loss: 3.5399929953899156
Validation loss: 3.4120540116057887

Epoch: 5| Step: 5
Training loss: 3.5204788270304688
Validation loss: 3.404755186736272

Epoch: 5| Step: 6
Training loss: 3.459527204106386
Validation loss: 3.393150315011412

Epoch: 5| Step: 7
Training loss: 3.803814484309465
Validation loss: 3.38412988078607

Epoch: 5| Step: 8
Training loss: 3.7160257570915953
Validation loss: 3.3708956930506844

Epoch: 5| Step: 9
Training loss: 4.103371996683223
Validation loss: 3.359481178736753

Epoch: 5| Step: 10
Training loss: 4.199970408744111
Validation loss: 3.348624763200018

Epoch: 13| Step: 0
Training loss: 3.4705926623178316
Validation loss: 3.338654906856181

Epoch: 5| Step: 1
Training loss: 3.9986090625897406
Validation loss: 3.3210224285881447

Epoch: 5| Step: 2
Training loss: 3.4017278768616652
Validation loss: 3.3040391533323006

Epoch: 5| Step: 3
Training loss: 3.274564489862217
Validation loss: 3.2964058235871767

Epoch: 5| Step: 4
Training loss: 2.185980786978147
Validation loss: 3.2866094023517785

Epoch: 5| Step: 5
Training loss: 4.30278513112653
Validation loss: 3.2715860841821707

Epoch: 5| Step: 6
Training loss: 3.3799867875783334
Validation loss: 3.259748052527821

Epoch: 5| Step: 7
Training loss: 3.415158582498875
Validation loss: 3.2397969717574315

Epoch: 5| Step: 8
Training loss: 3.659517572428781
Validation loss: 3.232947828638653

Epoch: 5| Step: 9
Training loss: 3.5706893755376075
Validation loss: 3.222049517353146

Epoch: 5| Step: 10
Training loss: 3.342626222382789
Validation loss: 3.2121697208618945

Epoch: 14| Step: 0
Training loss: 2.6662886371486745
Validation loss: 3.192132489021111

Epoch: 5| Step: 1
Training loss: 3.6766920592975105
Validation loss: 3.1818525313675523

Epoch: 5| Step: 2
Training loss: 3.201580884963531
Validation loss: 3.167745228156404

Epoch: 5| Step: 3
Training loss: 3.125314010102531
Validation loss: 3.1602539070125406

Epoch: 5| Step: 4
Training loss: 3.1729938807436
Validation loss: 3.1453992276131437

Epoch: 5| Step: 5
Training loss: 3.027051082123356
Validation loss: 3.1273057761862564

Epoch: 5| Step: 6
Training loss: 3.329337888539103
Validation loss: 3.1222652027660174

Epoch: 5| Step: 7
Training loss: 3.9095015763756376
Validation loss: 3.109852099225977

Epoch: 5| Step: 8
Training loss: 3.580294288814684
Validation loss: 3.091355560721501

Epoch: 5| Step: 9
Training loss: 3.741615841073593
Validation loss: 3.0785499647108363

Epoch: 5| Step: 10
Training loss: 3.38401635577711
Validation loss: 3.077215942984099

Epoch: 15| Step: 0
Training loss: 3.3021010790487444
Validation loss: 3.0568269576040663

Epoch: 5| Step: 1
Training loss: 3.0167804935400278
Validation loss: 3.0456001974161535

Epoch: 5| Step: 2
Training loss: 3.1947780619206085
Validation loss: 3.0322231163837707

Epoch: 5| Step: 3
Training loss: 2.9924378452204023
Validation loss: 3.015902789149335

Epoch: 5| Step: 4
Training loss: 3.2562323747329946
Validation loss: 3.0061312458463156

Epoch: 5| Step: 5
Training loss: 3.450524917696089
Validation loss: 2.992298289634903

Epoch: 5| Step: 6
Training loss: 3.599054816462152
Validation loss: 2.9842292446387537

Epoch: 5| Step: 7
Training loss: 3.4118944350410754
Validation loss: 2.963491351192153

Epoch: 5| Step: 8
Training loss: 3.429558892760638
Validation loss: 2.946866951747252

Epoch: 5| Step: 9
Training loss: 3.276321342590954
Validation loss: 2.9369357196983468

Epoch: 5| Step: 10
Training loss: 2.6004617097687457
Validation loss: 2.9207862113863774

Epoch: 16| Step: 0
Training loss: 3.5477100347235986
Validation loss: 2.9125376886975456

Epoch: 5| Step: 1
Training loss: 3.6104362215780808
Validation loss: 2.894201799236406

Epoch: 5| Step: 2
Training loss: 2.9204161566905626
Validation loss: 2.88023729429757

Epoch: 5| Step: 3
Training loss: 3.3549831336517033
Validation loss: 2.8766928615919043

Epoch: 5| Step: 4
Training loss: 3.446799028930669
Validation loss: 2.859805296137596

Epoch: 5| Step: 5
Training loss: 2.8908424089483025
Validation loss: 2.84619602742466

Epoch: 5| Step: 6
Training loss: 2.4495099881667977
Validation loss: 2.8352884234411975

Epoch: 5| Step: 7
Training loss: 2.725506509725872
Validation loss: 2.821202102583056

Epoch: 5| Step: 8
Training loss: 3.410387798195688
Validation loss: 2.8109372718482293

Epoch: 5| Step: 9
Training loss: 3.0384630725117554
Validation loss: 2.7904024605879094

Epoch: 5| Step: 10
Training loss: 2.8754303651542448
Validation loss: 2.783641865605619

Epoch: 17| Step: 0
Training loss: 3.4075421323571424
Validation loss: 2.7692107776807737

Epoch: 5| Step: 1
Training loss: 3.2258589672613023
Validation loss: 2.7707669258409773

Epoch: 5| Step: 2
Training loss: 3.1800757318751742
Validation loss: 2.7528810260095353

Epoch: 5| Step: 3
Training loss: 2.9929086797148194
Validation loss: 2.7396823530309358

Epoch: 5| Step: 4
Training loss: 2.9486835322503255
Validation loss: 2.7297519362197606

Epoch: 5| Step: 5
Training loss: 3.5481331228163584
Validation loss: 2.719753585100596

Epoch: 5| Step: 6
Training loss: 2.848013228867914
Validation loss: 2.702504099217382

Epoch: 5| Step: 7
Training loss: 3.205864455929171
Validation loss: 2.699796798728512

Epoch: 5| Step: 8
Training loss: 2.678452988685382
Validation loss: 2.6893150808960646

Epoch: 5| Step: 9
Training loss: 2.0636244511900212
Validation loss: 2.672870998455849

Epoch: 5| Step: 10
Training loss: 2.97475139957648
Validation loss: 2.6724167083770327

Epoch: 18| Step: 0
Training loss: 3.088011534782964
Validation loss: 2.6579210028391254

Epoch: 5| Step: 1
Training loss: 2.627593167410829
Validation loss: 2.6496251222458618

Epoch: 5| Step: 2
Training loss: 2.8626621716799696
Validation loss: 2.6387681980595317

Epoch: 5| Step: 3
Training loss: 2.914237909432488
Validation loss: 2.628330892976767

Epoch: 5| Step: 4
Training loss: 3.5454870524839115
Validation loss: 2.618143923731582

Epoch: 5| Step: 5
Training loss: 2.6538635304370106
Validation loss: 2.6075503182592197

Epoch: 5| Step: 6
Training loss: 3.3036803385924083
Validation loss: 2.6075276838385317

Epoch: 5| Step: 7
Training loss: 2.5838997640330534
Validation loss: 2.5915590331630733

Epoch: 5| Step: 8
Training loss: 2.923468986272351
Validation loss: 2.5907771596427143

Epoch: 5| Step: 9
Training loss: 3.1126308551535793
Validation loss: 2.5795310165573735

Epoch: 5| Step: 10
Training loss: 2.5597579986211834
Validation loss: 2.578305763328806

Epoch: 19| Step: 0
Training loss: 2.908482012368647
Validation loss: 2.5683053538642953

Epoch: 5| Step: 1
Training loss: 2.848136118368447
Validation loss: 2.5681054038893603

Epoch: 5| Step: 2
Training loss: 2.6830165636572905
Validation loss: 2.560937391525621

Epoch: 5| Step: 3
Training loss: 3.2204822212371687
Validation loss: 2.553297362247561

Epoch: 5| Step: 4
Training loss: 3.115346876642182
Validation loss: 2.5449492618222136

Epoch: 5| Step: 5
Training loss: 3.171155274765391
Validation loss: 2.5520493954445964

Epoch: 5| Step: 6
Training loss: 2.74513490522564
Validation loss: 2.5385441793589347

Epoch: 5| Step: 7
Training loss: 3.327518891496576
Validation loss: 2.5342142878886365

Epoch: 5| Step: 8
Training loss: 2.461468158002229
Validation loss: 2.5308266233354133

Epoch: 5| Step: 9
Training loss: 2.3556499253369005
Validation loss: 2.513558794415276

Epoch: 5| Step: 10
Training loss: 2.8248851617748243
Validation loss: 2.5251138241346003

Epoch: 20| Step: 0
Training loss: 2.8017254758067693
Validation loss: 2.517047638536953

Epoch: 5| Step: 1
Training loss: 3.2514024789526075
Validation loss: 2.51392832369904

Epoch: 5| Step: 2
Training loss: 2.21016720134979
Validation loss: 2.5076285025027074

Epoch: 5| Step: 3
Training loss: 2.7587866426980536
Validation loss: 2.5073745064446777

Epoch: 5| Step: 4
Training loss: 2.9446651647919593
Validation loss: 2.4948747160230034

Epoch: 5| Step: 5
Training loss: 2.7473800489987683
Validation loss: 2.4950728500219195

Epoch: 5| Step: 6
Training loss: 2.51800112133895
Validation loss: 2.480644904920912

Epoch: 5| Step: 7
Training loss: 3.0578880616502313
Validation loss: 2.4942682692434253

Epoch: 5| Step: 8
Training loss: 3.2491226479254682
Validation loss: 2.4904682386925203

Epoch: 5| Step: 9
Training loss: 3.0756982832365716
Validation loss: 2.4868129841996534

Epoch: 5| Step: 10
Training loss: 2.8521418570808494
Validation loss: 2.486355763349341

Epoch: 21| Step: 0
Training loss: 2.7313705941469753
Validation loss: 2.483403609374966

Epoch: 5| Step: 1
Training loss: 2.4030679247047155
Validation loss: 2.480945044107674

Epoch: 5| Step: 2
Training loss: 3.0401242321128406
Validation loss: 2.478065425722232

Epoch: 5| Step: 3
Training loss: 2.4699126777194134
Validation loss: 2.4697275252690214

Epoch: 5| Step: 4
Training loss: 3.14455384429965
Validation loss: 2.466205946037458

Epoch: 5| Step: 5
Training loss: 3.506998150270538
Validation loss: 2.4797160476693487

Epoch: 5| Step: 6
Training loss: 2.8551272332856747
Validation loss: 2.47267580700962

Epoch: 5| Step: 7
Training loss: 2.480137215633022
Validation loss: 2.4648041989887983

Epoch: 5| Step: 8
Training loss: 2.7386954915251702
Validation loss: 2.478023939564277

Epoch: 5| Step: 9
Training loss: 2.5974557899626602
Validation loss: 2.4606897487570567

Epoch: 5| Step: 10
Training loss: 3.3802431141024476
Validation loss: 2.4675231965401134

Epoch: 22| Step: 0
Training loss: 3.0700699028481457
Validation loss: 2.466559386671169

Epoch: 5| Step: 1
Training loss: 2.4612145646364745
Validation loss: 2.4588681475788916

Epoch: 5| Step: 2
Training loss: 2.753091634836132
Validation loss: 2.461919780382113

Epoch: 5| Step: 3
Training loss: 2.662169827329706
Validation loss: 2.458392575486795

Epoch: 5| Step: 4
Training loss: 2.941318059766903
Validation loss: 2.4573262350259313

Epoch: 5| Step: 5
Training loss: 2.929148062316359
Validation loss: 2.466656556506447

Epoch: 5| Step: 6
Training loss: 2.721192413828205
Validation loss: 2.449943523036465

Epoch: 5| Step: 7
Training loss: 2.6868074988692854
Validation loss: 2.4518244854236286

Epoch: 5| Step: 8
Training loss: 3.454353493736908
Validation loss: 2.4600080556359942

Epoch: 5| Step: 9
Training loss: 3.0233804071442467
Validation loss: 2.4594361709909736

Epoch: 5| Step: 10
Training loss: 2.44744244033415
Validation loss: 2.4691227000335894

Epoch: 23| Step: 0
Training loss: 3.2717672743820403
Validation loss: 2.4436901101451016

Epoch: 5| Step: 1
Training loss: 2.3595011090055538
Validation loss: 2.462981977487119

Epoch: 5| Step: 2
Training loss: 2.818762017539515
Validation loss: 2.454083103728332

Epoch: 5| Step: 3
Training loss: 2.8848520729578357
Validation loss: 2.4604485816035635

Epoch: 5| Step: 4
Training loss: 3.1539109126773033
Validation loss: 2.4455275708506825

Epoch: 5| Step: 5
Training loss: 2.543085004783115
Validation loss: 2.4590914509573736

Epoch: 5| Step: 6
Training loss: 2.84116606642491
Validation loss: 2.453163128387954

Epoch: 5| Step: 7
Training loss: 2.762494227890958
Validation loss: 2.4534589175600847

Epoch: 5| Step: 8
Training loss: 2.9517404045258533
Validation loss: 2.4502937381058416

Epoch: 5| Step: 9
Training loss: 2.916770515409635
Validation loss: 2.4492662872700808

Epoch: 5| Step: 10
Training loss: 2.544431204347252
Validation loss: 2.453173448084078

Epoch: 24| Step: 0
Training loss: 2.445713388165257
Validation loss: 2.4547885395677933

Epoch: 5| Step: 1
Training loss: 3.0148886933032557
Validation loss: 2.4535136696440194

Epoch: 5| Step: 2
Training loss: 3.14386138415341
Validation loss: 2.4601288664441405

Epoch: 5| Step: 3
Training loss: 2.8384124633128374
Validation loss: 2.463992294441374

Epoch: 5| Step: 4
Training loss: 3.0681787895418884
Validation loss: 2.4620846623115074

Epoch: 5| Step: 5
Training loss: 2.7754687970056255
Validation loss: 2.4602202995976383

Epoch: 5| Step: 6
Training loss: 2.9537998619181325
Validation loss: 2.4536606816616215

Epoch: 5| Step: 7
Training loss: 2.7108156028407726
Validation loss: 2.4435458230148286

Epoch: 5| Step: 8
Training loss: 2.772232524603806
Validation loss: 2.4533426640078098

Epoch: 5| Step: 9
Training loss: 2.392940621455129
Validation loss: 2.455068805322607

Epoch: 5| Step: 10
Training loss: 3.069907901885985
Validation loss: 2.439513227785969

Epoch: 25| Step: 0
Training loss: 2.351318650893743
Validation loss: 2.453137626273201

Epoch: 5| Step: 1
Training loss: 2.980102836575433
Validation loss: 2.4470310739590198

Epoch: 5| Step: 2
Training loss: 2.9248553900551006
Validation loss: 2.445058535355335

Epoch: 5| Step: 3
Training loss: 2.5791649772708354
Validation loss: 2.4515263683701876

Epoch: 5| Step: 4
Training loss: 2.884227539789768
Validation loss: 2.447203713830037

Epoch: 5| Step: 5
Training loss: 2.4611275735748936
Validation loss: 2.4439567218106144

Epoch: 5| Step: 6
Training loss: 2.1033321148263795
Validation loss: 2.4557064627210092

Epoch: 5| Step: 7
Training loss: 2.7960809187742575
Validation loss: 2.450536971716745

Epoch: 5| Step: 8
Training loss: 3.4184635523546034
Validation loss: 2.4490117413112023

Epoch: 5| Step: 9
Training loss: 3.378407488929493
Validation loss: 2.4483363545598644

Epoch: 5| Step: 10
Training loss: 3.1074580892374377
Validation loss: 2.4592310658650725

Epoch: 26| Step: 0
Training loss: 3.0601573469809114
Validation loss: 2.446034090380032

Epoch: 5| Step: 1
Training loss: 3.4236857879177007
Validation loss: 2.4487914833853677

Epoch: 5| Step: 2
Training loss: 3.134933248536294
Validation loss: 2.454367805697136

Epoch: 5| Step: 3
Training loss: 2.346606129205018
Validation loss: 2.446750114356314

Epoch: 5| Step: 4
Training loss: 2.599135082607832
Validation loss: 2.4466419628512064

Epoch: 5| Step: 5
Training loss: 2.742793698158941
Validation loss: 2.4513671446849337

Epoch: 5| Step: 6
Training loss: 3.179838359731286
Validation loss: 2.45296549077625

Epoch: 5| Step: 7
Training loss: 2.6196275865706133
Validation loss: 2.4472191446285816

Epoch: 5| Step: 8
Training loss: 2.729490353169106
Validation loss: 2.4462189359738917

Epoch: 5| Step: 9
Training loss: 2.333154149214445
Validation loss: 2.45604772949016

Epoch: 5| Step: 10
Training loss: 2.7785235982582335
Validation loss: 2.4553019035868617

Epoch: 27| Step: 0
Training loss: 2.7110430342390535
Validation loss: 2.44897719436985

Epoch: 5| Step: 1
Training loss: 2.58118068057033
Validation loss: 2.4528091454099235

Epoch: 5| Step: 2
Training loss: 2.4908311555133316
Validation loss: 2.449879745205013

Epoch: 5| Step: 3
Training loss: 2.867046799702539
Validation loss: 2.4399938223646456

Epoch: 5| Step: 4
Training loss: 2.670535727914188
Validation loss: 2.4534696639003575

Epoch: 5| Step: 5
Training loss: 2.5087335624213343
Validation loss: 2.4483582607353354

Epoch: 5| Step: 6
Training loss: 2.9830538236933086
Validation loss: 2.4434229384931196

Epoch: 5| Step: 7
Training loss: 2.513896561593933
Validation loss: 2.4447159227969464

Epoch: 5| Step: 8
Training loss: 3.0084969670675243
Validation loss: 2.450572232105374

Epoch: 5| Step: 9
Training loss: 2.957347616105579
Validation loss: 2.445074264881867

Epoch: 5| Step: 10
Training loss: 3.746773412502906
Validation loss: 2.4529553154773764

Epoch: 28| Step: 0
Training loss: 3.3084496260669676
Validation loss: 2.449198305424405

Epoch: 5| Step: 1
Training loss: 2.795817766747912
Validation loss: 2.460252728618084

Epoch: 5| Step: 2
Training loss: 2.474607255388299
Validation loss: 2.4439127821027915

Epoch: 5| Step: 3
Training loss: 3.278889560906941
Validation loss: 2.4480693464942123

Epoch: 5| Step: 4
Training loss: 3.1086115067466906
Validation loss: 2.4494627130931987

Epoch: 5| Step: 5
Training loss: 2.6107741390969075
Validation loss: 2.442169604073405

Epoch: 5| Step: 6
Training loss: 2.943479255811824
Validation loss: 2.4552740848227845

Epoch: 5| Step: 7
Training loss: 2.57642229669189
Validation loss: 2.4628519404202387

Epoch: 5| Step: 8
Training loss: 2.484238626827784
Validation loss: 2.4510643495250526

Epoch: 5| Step: 9
Training loss: 2.7963398682533134
Validation loss: 2.4440074789102892

Epoch: 5| Step: 10
Training loss: 2.586436889002366
Validation loss: 2.454719405192333

Epoch: 29| Step: 0
Training loss: 2.859355655458813
Validation loss: 2.457564783555688

Epoch: 5| Step: 1
Training loss: 2.5093207176484587
Validation loss: 2.4423425141066626

Epoch: 5| Step: 2
Training loss: 2.6780427828869082
Validation loss: 2.447852768824414

Epoch: 5| Step: 3
Training loss: 2.8369821353171045
Validation loss: 2.442466508895604

Epoch: 5| Step: 4
Training loss: 3.0823559801500378
Validation loss: 2.458265146846647

Epoch: 5| Step: 5
Training loss: 2.3388896136711894
Validation loss: 2.445733415335111

Epoch: 5| Step: 6
Training loss: 2.486235491756803
Validation loss: 2.44680163337496

Epoch: 5| Step: 7
Training loss: 3.066697960845939
Validation loss: 2.4468893982959177

Epoch: 5| Step: 8
Training loss: 3.020257110008862
Validation loss: 2.445270921556203

Epoch: 5| Step: 9
Training loss: 2.758397372636628
Validation loss: 2.442360380383568

Epoch: 5| Step: 10
Training loss: 3.3111378010122867
Validation loss: 2.445183244277171

Epoch: 30| Step: 0
Training loss: 2.8299340632005876
Validation loss: 2.446187627258569

Epoch: 5| Step: 1
Training loss: 2.73052070360869
Validation loss: 2.4408264936631543

Epoch: 5| Step: 2
Training loss: 2.753501483579492
Validation loss: 2.4411187918806947

Epoch: 5| Step: 3
Training loss: 2.869476651846668
Validation loss: 2.445920079622221

Epoch: 5| Step: 4
Training loss: 2.7680267422657674
Validation loss: 2.4415360285567096

Epoch: 5| Step: 5
Training loss: 2.6152152302207208
Validation loss: 2.442192864079013

Epoch: 5| Step: 6
Training loss: 2.9513370005715007
Validation loss: 2.4412823011210643

Epoch: 5| Step: 7
Training loss: 2.6424232093530895
Validation loss: 2.4420245751774527

Epoch: 5| Step: 8
Training loss: 3.0771264329981247
Validation loss: 2.4394159919365612

Epoch: 5| Step: 9
Training loss: 3.2865218183105744
Validation loss: 2.445005051901452

Epoch: 5| Step: 10
Training loss: 2.3879587102288458
Validation loss: 2.444212924884028

Epoch: 31| Step: 0
Training loss: 2.9011236118726043
Validation loss: 2.441465878388088

Epoch: 5| Step: 1
Training loss: 2.5972689920748686
Validation loss: 2.453253092732079

Epoch: 5| Step: 2
Training loss: 3.220480888661791
Validation loss: 2.454438925110388

Epoch: 5| Step: 3
Training loss: 2.8704607414959082
Validation loss: 2.4512744824074577

Epoch: 5| Step: 4
Training loss: 2.9994757512112833
Validation loss: 2.4436252684377497

Epoch: 5| Step: 5
Training loss: 2.9734825559841758
Validation loss: 2.454685172522599

Epoch: 5| Step: 6
Training loss: 2.270145930502347
Validation loss: 2.4530966685048803

Epoch: 5| Step: 7
Training loss: 2.746280756045862
Validation loss: 2.44973972031257

Epoch: 5| Step: 8
Training loss: 2.4339505296881527
Validation loss: 2.445518611034849

Epoch: 5| Step: 9
Training loss: 3.1445865981639067
Validation loss: 2.440554445447079

Epoch: 5| Step: 10
Training loss: 2.567582184721469
Validation loss: 2.4499794449152175

Epoch: 32| Step: 0
Training loss: 2.644867147415542
Validation loss: 2.4335445697403872

Epoch: 5| Step: 1
Training loss: 2.7583589957926815
Validation loss: 2.444629439463271

Epoch: 5| Step: 2
Training loss: 3.010845606955112
Validation loss: 2.4402059843592996

Epoch: 5| Step: 3
Training loss: 2.523426351138781
Validation loss: 2.4478205850282193

Epoch: 5| Step: 4
Training loss: 2.470839955758992
Validation loss: 2.450783229377554

Epoch: 5| Step: 5
Training loss: 2.933775468219203
Validation loss: 2.4423759645911187

Epoch: 5| Step: 6
Training loss: 3.2089833348389214
Validation loss: 2.442074885862817

Epoch: 5| Step: 7
Training loss: 2.580287604307156
Validation loss: 2.441660930516632

Epoch: 5| Step: 8
Training loss: 2.921279112083575
Validation loss: 2.448271624388494

Epoch: 5| Step: 9
Training loss: 2.7405710700023613
Validation loss: 2.446272389220405

Epoch: 5| Step: 10
Training loss: 3.1081437783486154
Validation loss: 2.440752426311874

Epoch: 33| Step: 0
Training loss: 2.3497343846628276
Validation loss: 2.44361755848934

Epoch: 5| Step: 1
Training loss: 3.2703459714734042
Validation loss: 2.446083379013251

Epoch: 5| Step: 2
Training loss: 2.2958143211542166
Validation loss: 2.451237849499895

Epoch: 5| Step: 3
Training loss: 3.2138345462297138
Validation loss: 2.4520249626300754

Epoch: 5| Step: 4
Training loss: 2.60366488899532
Validation loss: 2.4447915415601265

Epoch: 5| Step: 5
Training loss: 2.4578527099269127
Validation loss: 2.4434391685221737

Epoch: 5| Step: 6
Training loss: 3.038571197885872
Validation loss: 2.4374573601042444

Epoch: 5| Step: 7
Training loss: 2.698693672924588
Validation loss: 2.435095981182644

Epoch: 5| Step: 8
Training loss: 2.981325358911858
Validation loss: 2.4371583361006195

Epoch: 5| Step: 9
Training loss: 2.767037327384015
Validation loss: 2.4369912185789797

Epoch: 5| Step: 10
Training loss: 3.0234195205981886
Validation loss: 2.4386459509181164

Epoch: 34| Step: 0
Training loss: 2.667447532130655
Validation loss: 2.4523997810579887

Epoch: 5| Step: 1
Training loss: 2.666192866990627
Validation loss: 2.4456576621685735

Epoch: 5| Step: 2
Training loss: 2.619397133051269
Validation loss: 2.449736668730932

Epoch: 5| Step: 3
Training loss: 2.7419365662096697
Validation loss: 2.4416226456097507

Epoch: 5| Step: 4
Training loss: 2.7744691461279873
Validation loss: 2.4551863517965655

Epoch: 5| Step: 5
Training loss: 3.12264361232236
Validation loss: 2.438091786803893

Epoch: 5| Step: 6
Training loss: 3.1605661925566024
Validation loss: 2.4437217430250002

Epoch: 5| Step: 7
Training loss: 3.0915473263749047
Validation loss: 2.4412579749580576

Epoch: 5| Step: 8
Training loss: 2.4368177584010446
Validation loss: 2.44808403146417

Epoch: 5| Step: 9
Training loss: 2.6546159093587725
Validation loss: 2.43767102432709

Epoch: 5| Step: 10
Training loss: 2.7836318371843953
Validation loss: 2.4422248102722595

Epoch: 35| Step: 0
Training loss: 2.7142321878906186
Validation loss: 2.4373635484456537

Epoch: 5| Step: 1
Training loss: 3.071953022180417
Validation loss: 2.4416489420704592

Epoch: 5| Step: 2
Training loss: 3.5863910463026074
Validation loss: 2.4311201724432427

Epoch: 5| Step: 3
Training loss: 2.464970846874247
Validation loss: 2.447111837281144

Epoch: 5| Step: 4
Training loss: 2.9906395476335206
Validation loss: 2.447823222691086

Epoch: 5| Step: 5
Training loss: 2.6674913283603083
Validation loss: 2.4467789976419594

Epoch: 5| Step: 6
Training loss: 2.7075534773711687
Validation loss: 2.451853786245399

Epoch: 5| Step: 7
Training loss: 2.685519708669414
Validation loss: 2.4449685368636875

Epoch: 5| Step: 8
Training loss: 2.033975269523622
Validation loss: 2.4560545591120584

Epoch: 5| Step: 9
Training loss: 2.9883343860165525
Validation loss: 2.4507943446746117

Epoch: 5| Step: 10
Training loss: 2.586357612712554
Validation loss: 2.4383864861388074

Epoch: 36| Step: 0
Training loss: 2.723195442652671
Validation loss: 2.4565241980225805

Epoch: 5| Step: 1
Training loss: 2.8862307578693183
Validation loss: 2.4419038954336334

Epoch: 5| Step: 2
Training loss: 3.5075591065911444
Validation loss: 2.447992936732854

Epoch: 5| Step: 3
Training loss: 2.598512253227947
Validation loss: 2.445437778845435

Epoch: 5| Step: 4
Training loss: 2.5273951623984887
Validation loss: 2.4368953833175837

Epoch: 5| Step: 5
Training loss: 3.106256502632074
Validation loss: 2.450537643347935

Epoch: 5| Step: 6
Training loss: 2.0588674055761573
Validation loss: 2.44042256518504

Epoch: 5| Step: 7
Training loss: 2.5187559369114276
Validation loss: 2.4391293082655245

Epoch: 5| Step: 8
Training loss: 3.1259893758523707
Validation loss: 2.4450084616913528

Epoch: 5| Step: 9
Training loss: 2.7034392422282543
Validation loss: 2.4428618644541045

Epoch: 5| Step: 10
Training loss: 2.720365285607779
Validation loss: 2.4356330514046003

Epoch: 37| Step: 0
Training loss: 2.5504939105842315
Validation loss: 2.4349393917809503

Epoch: 5| Step: 1
Training loss: 2.6304154619802005
Validation loss: 2.4528821254492823

Epoch: 5| Step: 2
Training loss: 2.532474362995795
Validation loss: 2.439719161498035

Epoch: 5| Step: 3
Training loss: 2.689043710610834
Validation loss: 2.4399966255640737

Epoch: 5| Step: 4
Training loss: 3.2734331299381627
Validation loss: 2.452808479104055

Epoch: 5| Step: 5
Training loss: 2.7942910645467416
Validation loss: 2.448037603284458

Epoch: 5| Step: 6
Training loss: 2.3548982096903743
Validation loss: 2.451911209528865

Epoch: 5| Step: 7
Training loss: 2.7688361023201122
Validation loss: 2.4405479768677836

Epoch: 5| Step: 8
Training loss: 3.0159118199700337
Validation loss: 2.44927111829713

Epoch: 5| Step: 9
Training loss: 3.2406802431141446
Validation loss: 2.4466125592706782

Epoch: 5| Step: 10
Training loss: 2.715346299456196
Validation loss: 2.4409098170094365

Epoch: 38| Step: 0
Training loss: 2.384633053555591
Validation loss: 2.4360666564838915

Epoch: 5| Step: 1
Training loss: 2.5523363779438513
Validation loss: 2.436647405932777

Epoch: 5| Step: 2
Training loss: 2.3328182355806395
Validation loss: 2.439475872847005

Epoch: 5| Step: 3
Training loss: 2.2120394168052804
Validation loss: 2.435957024545688

Epoch: 5| Step: 4
Training loss: 3.3854026129015184
Validation loss: 2.4439619393886494

Epoch: 5| Step: 5
Training loss: 2.423612795601168
Validation loss: 2.4390838626525864

Epoch: 5| Step: 6
Training loss: 2.578010787745974
Validation loss: 2.4569440941283127

Epoch: 5| Step: 7
Training loss: 3.387703194805618
Validation loss: 2.4392847059357754

Epoch: 5| Step: 8
Training loss: 2.994977720811415
Validation loss: 2.4288461320008565

Epoch: 5| Step: 9
Training loss: 2.811706854987733
Validation loss: 2.4415685597928247

Epoch: 5| Step: 10
Training loss: 3.303124890286851
Validation loss: 2.4339593740960574

Epoch: 39| Step: 0
Training loss: 2.780819720298851
Validation loss: 2.445567948843548

Epoch: 5| Step: 1
Training loss: 3.020549173253836
Validation loss: 2.43578485580006

Epoch: 5| Step: 2
Training loss: 3.3396559991544024
Validation loss: 2.446360718581501

Epoch: 5| Step: 3
Training loss: 2.5936835406877647
Validation loss: 2.4412086466570555

Epoch: 5| Step: 4
Training loss: 2.5314945997571976
Validation loss: 2.448576301363557

Epoch: 5| Step: 5
Training loss: 2.850612199851188
Validation loss: 2.439523078734315

Epoch: 5| Step: 6
Training loss: 2.7488090363772524
Validation loss: 2.4396949700139268

Epoch: 5| Step: 7
Training loss: 2.634492513585526
Validation loss: 2.4395631457484375

Epoch: 5| Step: 8
Training loss: 2.5664855851869044
Validation loss: 2.4466538288611974

Epoch: 5| Step: 9
Training loss: 2.943463055987435
Validation loss: 2.438756050654916

Epoch: 5| Step: 10
Training loss: 2.4770101148747647
Validation loss: 2.436291712001851

Epoch: 40| Step: 0
Training loss: 2.605269348658376
Validation loss: 2.441774919660773

Epoch: 5| Step: 1
Training loss: 2.473500955699075
Validation loss: 2.436305277849854

Epoch: 5| Step: 2
Training loss: 2.6293345494986475
Validation loss: 2.441215153391427

Epoch: 5| Step: 3
Training loss: 2.510319582590687
Validation loss: 2.4431293178216906

Epoch: 5| Step: 4
Training loss: 3.0963429075677515
Validation loss: 2.4270996444585715

Epoch: 5| Step: 5
Training loss: 2.5780882861673287
Validation loss: 2.4504987888670433

Epoch: 5| Step: 6
Training loss: 2.9910934479966413
Validation loss: 2.4332131730637334

Epoch: 5| Step: 7
Training loss: 2.982062117606976
Validation loss: 2.4258107449148945

Epoch: 5| Step: 8
Training loss: 3.142418496373081
Validation loss: 2.434241303961014

Epoch: 5| Step: 9
Training loss: 3.0342420774785275
Validation loss: 2.4362272363617627

Epoch: 5| Step: 10
Training loss: 2.403966836100753
Validation loss: 2.4424319522957836

Epoch: 41| Step: 0
Training loss: 3.1766150624532528
Validation loss: 2.437173060516625

Epoch: 5| Step: 1
Training loss: 2.9596432396108026
Validation loss: 2.4411564976420124

Epoch: 5| Step: 2
Training loss: 2.6796478179573695
Validation loss: 2.435304227496418

Epoch: 5| Step: 3
Training loss: 2.5032758231568804
Validation loss: 2.4433091594896545

Epoch: 5| Step: 4
Training loss: 3.0389969139572997
Validation loss: 2.4253204332322382

Epoch: 5| Step: 5
Training loss: 3.083087773897723
Validation loss: 2.4408607810084253

Epoch: 5| Step: 6
Training loss: 2.4815704061960853
Validation loss: 2.436481154830359

Epoch: 5| Step: 7
Training loss: 2.5490563535271304
Validation loss: 2.438885402086749

Epoch: 5| Step: 8
Training loss: 2.932204973058384
Validation loss: 2.4323155874790694

Epoch: 5| Step: 9
Training loss: 2.6377580417036484
Validation loss: 2.447810601995754

Epoch: 5| Step: 10
Training loss: 2.276177187681504
Validation loss: 2.4340074832361145

Epoch: 42| Step: 0
Training loss: 2.8733472634646793
Validation loss: 2.4404175879561407

Epoch: 5| Step: 1
Training loss: 3.011330189854494
Validation loss: 2.443953284329011

Epoch: 5| Step: 2
Training loss: 2.4955147562723794
Validation loss: 2.4348026988035425

Epoch: 5| Step: 3
Training loss: 3.334415419100294
Validation loss: 2.445374942346476

Epoch: 5| Step: 4
Training loss: 2.4757829757015126
Validation loss: 2.42932710354348

Epoch: 5| Step: 5
Training loss: 2.2302483284393126
Validation loss: 2.4421130277356022

Epoch: 5| Step: 6
Training loss: 2.443690825621524
Validation loss: 2.433125922637139

Epoch: 5| Step: 7
Training loss: 2.64237836602941
Validation loss: 2.4430553528164136

Epoch: 5| Step: 8
Training loss: 3.1475591073156055
Validation loss: 2.437159335402991

Epoch: 5| Step: 9
Training loss: 2.5242431110515895
Validation loss: 2.446170688400044

Epoch: 5| Step: 10
Training loss: 3.1909242076856565
Validation loss: 2.4532337048373707

Epoch: 43| Step: 0
Training loss: 2.1541452501463376
Validation loss: 2.440726621213657

Epoch: 5| Step: 1
Training loss: 3.22749606982523
Validation loss: 2.4407702569627805

Epoch: 5| Step: 2
Training loss: 2.38621583125818
Validation loss: 2.4384514261501926

Epoch: 5| Step: 3
Training loss: 2.918169742387468
Validation loss: 2.435473148661492

Epoch: 5| Step: 4
Training loss: 2.4067259478818954
Validation loss: 2.4325211493495273

Epoch: 5| Step: 5
Training loss: 3.222291202099135
Validation loss: 2.443214178539841

Epoch: 5| Step: 6
Training loss: 2.2951066872060566
Validation loss: 2.4336143151337755

Epoch: 5| Step: 7
Training loss: 3.1209284388910157
Validation loss: 2.4352596911082878

Epoch: 5| Step: 8
Training loss: 2.9427540643340038
Validation loss: 2.4372737138969014

Epoch: 5| Step: 9
Training loss: 2.932725150464411
Validation loss: 2.424725963956714

Epoch: 5| Step: 10
Training loss: 2.634579210070508
Validation loss: 2.432127552293265

Epoch: 44| Step: 0
Training loss: 2.2498918083457866
Validation loss: 2.4346695203479456

Epoch: 5| Step: 1
Training loss: 3.0604605598669257
Validation loss: 2.4421158348010583

Epoch: 5| Step: 2
Training loss: 2.7737623427444356
Validation loss: 2.422182286060516

Epoch: 5| Step: 3
Training loss: 3.6409128754712685
Validation loss: 2.439010703085715

Epoch: 5| Step: 4
Training loss: 2.1122559265349756
Validation loss: 2.43340504556504

Epoch: 5| Step: 5
Training loss: 2.861309626913329
Validation loss: 2.4435139738286074

Epoch: 5| Step: 6
Training loss: 2.640124121117878
Validation loss: 2.4384757655926403

Epoch: 5| Step: 7
Training loss: 2.788055665608427
Validation loss: 2.4432278591468544

Epoch: 5| Step: 8
Training loss: 2.8888446996031636
Validation loss: 2.435594169668735

Epoch: 5| Step: 9
Training loss: 2.769441546667435
Validation loss: 2.4392556461521284

Epoch: 5| Step: 10
Training loss: 2.2584844203206393
Validation loss: 2.437944088330574

Epoch: 45| Step: 0
Training loss: 2.7037470107430184
Validation loss: 2.442764497429587

Epoch: 5| Step: 1
Training loss: 2.822840521842382
Validation loss: 2.42498835772405

Epoch: 5| Step: 2
Training loss: 2.963766955420085
Validation loss: 2.439048573872786

Epoch: 5| Step: 3
Training loss: 2.422413723002709
Validation loss: 2.4373223455879525

Epoch: 5| Step: 4
Training loss: 2.9822119418480426
Validation loss: 2.437857762268319

Epoch: 5| Step: 5
Training loss: 3.079001674610759
Validation loss: 2.4471088421368474

Epoch: 5| Step: 6
Training loss: 2.4802679506261165
Validation loss: 2.4422550628784876

Epoch: 5| Step: 7
Training loss: 2.7642715504432345
Validation loss: 2.4316772716475703

Epoch: 5| Step: 8
Training loss: 2.539364652995183
Validation loss: 2.431783769406072

Epoch: 5| Step: 9
Training loss: 2.8865413378965736
Validation loss: 2.427609215885687

Epoch: 5| Step: 10
Training loss: 2.5761703942376335
Validation loss: 2.442137006311223

Epoch: 46| Step: 0
Training loss: 2.423793008628323
Validation loss: 2.442366252157689

Epoch: 5| Step: 1
Training loss: 3.0141395507582778
Validation loss: 2.453578909331848

Epoch: 5| Step: 2
Training loss: 2.8223374301527295
Validation loss: 2.4305547374561844

Epoch: 5| Step: 3
Training loss: 2.7082818735564658
Validation loss: 2.4369735212304295

Epoch: 5| Step: 4
Training loss: 3.1300330258415623
Validation loss: 2.440047701437104

Epoch: 5| Step: 5
Training loss: 2.329790172706618
Validation loss: 2.4314322072480863

Epoch: 5| Step: 6
Training loss: 2.5420045680163357
Validation loss: 2.4375507800647616

Epoch: 5| Step: 7
Training loss: 2.9419171825502457
Validation loss: 2.43700183187699

Epoch: 5| Step: 8
Training loss: 2.9638781275539445
Validation loss: 2.450102893124464

Epoch: 5| Step: 9
Training loss: 2.689219789487627
Validation loss: 2.4361830130750564

Epoch: 5| Step: 10
Training loss: 2.8048731495398798
Validation loss: 2.4416464305580754

Epoch: 47| Step: 0
Training loss: 2.894949817123701
Validation loss: 2.4231736780888244

Epoch: 5| Step: 1
Training loss: 2.823321314639377
Validation loss: 2.435015793712685

Epoch: 5| Step: 2
Training loss: 3.0592246154046223
Validation loss: 2.435950452197652

Epoch: 5| Step: 3
Training loss: 2.3738659610717816
Validation loss: 2.442847672815388

Epoch: 5| Step: 4
Training loss: 2.052978384975357
Validation loss: 2.439869967747456

Epoch: 5| Step: 5
Training loss: 2.4686920545513726
Validation loss: 2.4367758824633383

Epoch: 5| Step: 6
Training loss: 2.9790501249411063
Validation loss: 2.4376993952312356

Epoch: 5| Step: 7
Training loss: 2.994978516872587
Validation loss: 2.449337225111852

Epoch: 5| Step: 8
Training loss: 2.753287690948924
Validation loss: 2.4337547995712674

Epoch: 5| Step: 9
Training loss: 2.8834915808615453
Validation loss: 2.4490532970705283

Epoch: 5| Step: 10
Training loss: 2.9639746556916644
Validation loss: 2.4267634875044526

Epoch: 48| Step: 0
Training loss: 2.5979837082138393
Validation loss: 2.4367375818254025

Epoch: 5| Step: 1
Training loss: 2.74104889709102
Validation loss: 2.444266914429265

Epoch: 5| Step: 2
Training loss: 2.6492917643919016
Validation loss: 2.4339732173152226

Epoch: 5| Step: 3
Training loss: 2.8015400431935547
Validation loss: 2.4407795776694288

Epoch: 5| Step: 4
Training loss: 2.8311853868804238
Validation loss: 2.436749153615737

Epoch: 5| Step: 5
Training loss: 2.6487464387013726
Validation loss: 2.437606130834171

Epoch: 5| Step: 6
Training loss: 2.6686831142075293
Validation loss: 2.4462765696026882

Epoch: 5| Step: 7
Training loss: 2.3847421305980787
Validation loss: 2.4449441613962586

Epoch: 5| Step: 8
Training loss: 3.1357657575122424
Validation loss: 2.441041608983881

Epoch: 5| Step: 9
Training loss: 3.0441328180037512
Validation loss: 2.4598289001986564

Epoch: 5| Step: 10
Training loss: 2.7068410919468477
Validation loss: 2.4474443200316163

Epoch: 49| Step: 0
Training loss: 3.115893714512213
Validation loss: 2.430379734584797

Epoch: 5| Step: 1
Training loss: 2.7394567733559763
Validation loss: 2.421568509177945

Epoch: 5| Step: 2
Training loss: 2.9141132258277707
Validation loss: 2.4479968638866163

Epoch: 5| Step: 3
Training loss: 2.6587675842076712
Validation loss: 2.429306147536673

Epoch: 5| Step: 4
Training loss: 2.1903082124698323
Validation loss: 2.440964324922371

Epoch: 5| Step: 5
Training loss: 2.854769974776728
Validation loss: 2.444922117678085

Epoch: 5| Step: 6
Training loss: 2.6308444220239036
Validation loss: 2.4507088740032446

Epoch: 5| Step: 7
Training loss: 3.0040005395027825
Validation loss: 2.4284984194266066

Epoch: 5| Step: 8
Training loss: 2.8473236768888217
Validation loss: 2.4416834184065728

Epoch: 5| Step: 9
Training loss: 2.659878574840955
Validation loss: 2.4566964911458484

Epoch: 5| Step: 10
Training loss: 2.5942183841492996
Validation loss: 2.440929056501848

Epoch: 50| Step: 0
Training loss: 2.3899856410532925
Validation loss: 2.4381392855121002

Epoch: 5| Step: 1
Training loss: 2.085622699428772
Validation loss: 2.4454614370553007

Epoch: 5| Step: 2
Training loss: 3.0659219736023573
Validation loss: 2.4338636058913306

Epoch: 5| Step: 3
Training loss: 2.723571273310916
Validation loss: 2.4406919885112432

Epoch: 5| Step: 4
Training loss: 2.94385814427608
Validation loss: 2.44249470339368

Epoch: 5| Step: 5
Training loss: 2.615404119246243
Validation loss: 2.4542729889676336

Epoch: 5| Step: 6
Training loss: 2.3553330111891633
Validation loss: 2.4342902531982524

Epoch: 5| Step: 7
Training loss: 3.1452332654846957
Validation loss: 2.436793174101969

Epoch: 5| Step: 8
Training loss: 3.1633464238412152
Validation loss: 2.442048145203062

Epoch: 5| Step: 9
Training loss: 2.6761480595123817
Validation loss: 2.4321461713721892

Epoch: 5| Step: 10
Training loss: 2.984613059570109
Validation loss: 2.442799709440712

Epoch: 51| Step: 0
Training loss: 3.0020657420828742
Validation loss: 2.4397596794899012

Epoch: 5| Step: 1
Training loss: 2.626892316036436
Validation loss: 2.443773933811468

Epoch: 5| Step: 2
Training loss: 3.1578316832822813
Validation loss: 2.4440347629857

Epoch: 5| Step: 3
Training loss: 2.6198147013708897
Validation loss: 2.44091304557038

Epoch: 5| Step: 4
Training loss: 2.7365016841370946
Validation loss: 2.4306500390630537

Epoch: 5| Step: 5
Training loss: 3.213365513916117
Validation loss: 2.443666027212418

Epoch: 5| Step: 6
Training loss: 2.5383730847390975
Validation loss: 2.442072581070403

Epoch: 5| Step: 7
Training loss: 2.4948422633212224
Validation loss: 2.447141923663668

Epoch: 5| Step: 8
Training loss: 2.895839297793899
Validation loss: 2.4454795719783236

Epoch: 5| Step: 9
Training loss: 2.5473140033959245
Validation loss: 2.4451077597756474

Epoch: 5| Step: 10
Training loss: 2.1642172857902984
Validation loss: 2.4419012204061974

Epoch: 52| Step: 0
Training loss: 2.6589026277007117
Validation loss: 2.4322899605879287

Epoch: 5| Step: 1
Training loss: 1.9366786200153943
Validation loss: 2.442924772415224

Epoch: 5| Step: 2
Training loss: 2.892511855144819
Validation loss: 2.4521871926609533

Epoch: 5| Step: 3
Training loss: 3.274967391455997
Validation loss: 2.441159372493385

Epoch: 5| Step: 4
Training loss: 3.2224446545117886
Validation loss: 2.4524004040924696

Epoch: 5| Step: 5
Training loss: 2.4499400657018136
Validation loss: 2.436775621551813

Epoch: 5| Step: 6
Training loss: 2.5967693908737184
Validation loss: 2.4458224095724277

Epoch: 5| Step: 7
Training loss: 2.8364454082559236
Validation loss: 2.4253982591152394

Epoch: 5| Step: 8
Training loss: 2.3742340258112864
Validation loss: 2.451478523553003

Epoch: 5| Step: 9
Training loss: 3.2641659630300817
Validation loss: 2.437920223621189

Epoch: 5| Step: 10
Training loss: 2.400741712875864
Validation loss: 2.4333973422153523

Epoch: 53| Step: 0
Training loss: 2.56127528254931
Validation loss: 2.444908054388771

Epoch: 5| Step: 1
Training loss: 2.3818235252341613
Validation loss: 2.4305757512563693

Epoch: 5| Step: 2
Training loss: 2.009151027412362
Validation loss: 2.445008688171695

Epoch: 5| Step: 3
Training loss: 3.081956366921411
Validation loss: 2.442295485527922

Epoch: 5| Step: 4
Training loss: 2.6812757228515545
Validation loss: 2.438769096115197

Epoch: 5| Step: 5
Training loss: 2.8839982238213815
Validation loss: 2.437510539564007

Epoch: 5| Step: 6
Training loss: 3.490574952998781
Validation loss: 2.442679299936061

Epoch: 5| Step: 7
Training loss: 2.9647532010732234
Validation loss: 2.43992170611539

Epoch: 5| Step: 8
Training loss: 2.565425505415082
Validation loss: 2.444550788043166

Epoch: 5| Step: 9
Training loss: 2.9189132938817672
Validation loss: 2.4315801810731728

Epoch: 5| Step: 10
Training loss: 2.221240727582908
Validation loss: 2.4442884543255166

Epoch: 54| Step: 0
Training loss: 2.3855444084068527
Validation loss: 2.4342723413817433

Epoch: 5| Step: 1
Training loss: 2.9110458345673895
Validation loss: 2.4447889200257684

Epoch: 5| Step: 2
Training loss: 3.170466669431732
Validation loss: 2.443190719446751

Epoch: 5| Step: 3
Training loss: 3.127005429518438
Validation loss: 2.437074461614293

Epoch: 5| Step: 4
Training loss: 2.8331603016096176
Validation loss: 2.4371854254650613

Epoch: 5| Step: 5
Training loss: 2.645190203341345
Validation loss: 2.435935545688765

Epoch: 5| Step: 6
Training loss: 2.7378205307685
Validation loss: 2.43293525676461

Epoch: 5| Step: 7
Training loss: 2.8995183281606196
Validation loss: 2.4372164501120452

Epoch: 5| Step: 8
Training loss: 2.528814203462715
Validation loss: 2.4312140214983007

Epoch: 5| Step: 9
Training loss: 2.4889791758468114
Validation loss: 2.446893649392371

Epoch: 5| Step: 10
Training loss: 2.2821358828797305
Validation loss: 2.4523313414291597

Epoch: 55| Step: 0
Training loss: 2.7492732908492563
Validation loss: 2.4430167077892784

Epoch: 5| Step: 1
Training loss: 3.0068138941929083
Validation loss: 2.4360503194552767

Epoch: 5| Step: 2
Training loss: 2.584548438824352
Validation loss: 2.436931548029777

Epoch: 5| Step: 3
Training loss: 2.998959360832488
Validation loss: 2.4221204502979723

Epoch: 5| Step: 4
Training loss: 3.258458208453844
Validation loss: 2.441233164437393

Epoch: 5| Step: 5
Training loss: 3.0969797865368403
Validation loss: 2.445998176589925

Epoch: 5| Step: 6
Training loss: 2.4598174922200506
Validation loss: 2.425367848040743

Epoch: 5| Step: 7
Training loss: 2.0718265395445
Validation loss: 2.421998750222302

Epoch: 5| Step: 8
Training loss: 2.512322574253165
Validation loss: 2.450136575623543

Epoch: 5| Step: 9
Training loss: 2.4265785074289403
Validation loss: 2.4455902875941264

Epoch: 5| Step: 10
Training loss: 2.772203713658719
Validation loss: 2.4432400853769347

Epoch: 56| Step: 0
Training loss: 2.811560749470199
Validation loss: 2.4349781628957965

Epoch: 5| Step: 1
Training loss: 2.684339661193511
Validation loss: 2.441985360583888

Epoch: 5| Step: 2
Training loss: 2.6096147438516906
Validation loss: 2.4510663033206757

Epoch: 5| Step: 3
Training loss: 2.2515241970428352
Validation loss: 2.4387384218277792

Epoch: 5| Step: 4
Training loss: 2.968978873013562
Validation loss: 2.4428960424260007

Epoch: 5| Step: 5
Training loss: 2.820233795674033
Validation loss: 2.435001071517745

Epoch: 5| Step: 6
Training loss: 2.681524420079858
Validation loss: 2.4402150067554484

Epoch: 5| Step: 7
Training loss: 2.7673593890989
Validation loss: 2.431790864838792

Epoch: 5| Step: 8
Training loss: 2.8282005342123018
Validation loss: 2.4322011339268377

Epoch: 5| Step: 9
Training loss: 2.36608357387829
Validation loss: 2.4488889007587464

Epoch: 5| Step: 10
Training loss: 3.143444560629233
Validation loss: 2.435467830266395

Epoch: 57| Step: 0
Training loss: 3.023706389700515
Validation loss: 2.4303687432177083

Epoch: 5| Step: 1
Training loss: 2.3681084883943084
Validation loss: 2.4396268296928607

Epoch: 5| Step: 2
Training loss: 3.256231642541374
Validation loss: 2.441335902884352

Epoch: 5| Step: 3
Training loss: 2.253371891034185
Validation loss: 2.4264478887208702

Epoch: 5| Step: 4
Training loss: 2.4352829460544725
Validation loss: 2.4325291294877704

Epoch: 5| Step: 5
Training loss: 2.6682491574024723
Validation loss: 2.442683534220594

Epoch: 5| Step: 6
Training loss: 2.4264419319378243
Validation loss: 2.4499441812270426

Epoch: 5| Step: 7
Training loss: 3.2414655869855116
Validation loss: 2.444995906678859

Epoch: 5| Step: 8
Training loss: 2.8282898069804103
Validation loss: 2.4339336676095695

Epoch: 5| Step: 9
Training loss: 2.770506521661005
Validation loss: 2.4349034764909816

Epoch: 5| Step: 10
Training loss: 2.5546964592732806
Validation loss: 2.4347678797036614

Epoch: 58| Step: 0
Training loss: 2.3869787595880205
Validation loss: 2.444884440631267

Epoch: 5| Step: 1
Training loss: 2.728622401666538
Validation loss: 2.4389517031588905

Epoch: 5| Step: 2
Training loss: 2.7684532402599578
Validation loss: 2.436824955952624

Epoch: 5| Step: 3
Training loss: 2.5712752466812177
Validation loss: 2.431808600430935

Epoch: 5| Step: 4
Training loss: 2.9394159764575356
Validation loss: 2.4422986534748254

Epoch: 5| Step: 5
Training loss: 2.5691862566565358
Validation loss: 2.4393652391393577

Epoch: 5| Step: 6
Training loss: 3.128445671176804
Validation loss: 2.454115205396507

Epoch: 5| Step: 7
Training loss: 2.453377388769378
Validation loss: 2.4360129261479777

Epoch: 5| Step: 8
Training loss: 2.894285781068469
Validation loss: 2.431485536936214

Epoch: 5| Step: 9
Training loss: 1.8615076352766424
Validation loss: 2.4392661928441908

Epoch: 5| Step: 10
Training loss: 3.558781741355457
Validation loss: 2.4478742865928274

Epoch: 59| Step: 0
Training loss: 2.5003759101538385
Validation loss: 2.4415850551962297

Epoch: 5| Step: 1
Training loss: 3.3610350299838174
Validation loss: 2.4399131512512753

Epoch: 5| Step: 2
Training loss: 2.5635302263728237
Validation loss: 2.448466731163449

Epoch: 5| Step: 3
Training loss: 2.5734188706836045
Validation loss: 2.446026787344197

Epoch: 5| Step: 4
Training loss: 2.565581353172909
Validation loss: 2.4409500035716243

Epoch: 5| Step: 5
Training loss: 3.057022646105401
Validation loss: 2.435759371712137

Epoch: 5| Step: 6
Training loss: 2.466211099912385
Validation loss: 2.432903623784659

Epoch: 5| Step: 7
Training loss: 2.434077966317443
Validation loss: 2.4393980694140596

Epoch: 5| Step: 8
Training loss: 3.251925411621777
Validation loss: 2.4390811855833876

Epoch: 5| Step: 9
Training loss: 2.495282108358285
Validation loss: 2.453132954915007

Epoch: 5| Step: 10
Training loss: 2.4449794164621976
Validation loss: 2.436188124181011

Epoch: 60| Step: 0
Training loss: 2.419329480684348
Validation loss: 2.441848895104431

Epoch: 5| Step: 1
Training loss: 2.7926780709478276
Validation loss: 2.443578467029443

Epoch: 5| Step: 2
Training loss: 2.7182768486729776
Validation loss: 2.4549553718317463

Epoch: 5| Step: 3
Training loss: 2.1358501335532107
Validation loss: 2.442329735455608

Epoch: 5| Step: 4
Training loss: 2.598909508826885
Validation loss: 2.4342924374029855

Epoch: 5| Step: 5
Training loss: 3.112852212977884
Validation loss: 2.440181491978551

Epoch: 5| Step: 6
Training loss: 2.997607707807956
Validation loss: 2.435781187867599

Epoch: 5| Step: 7
Training loss: 3.364010473718112
Validation loss: 2.4425246997067656

Epoch: 5| Step: 8
Training loss: 2.5249055070475497
Validation loss: 2.436471601717328

Epoch: 5| Step: 9
Training loss: 2.5631260921138286
Validation loss: 2.4390164189529817

Epoch: 5| Step: 10
Training loss: 2.5606195947256247
Validation loss: 2.439483481337609

Epoch: 61| Step: 0
Training loss: 2.4794402626012397
Validation loss: 2.4384402603720208

Epoch: 5| Step: 1
Training loss: 2.567868726155854
Validation loss: 2.4433753798687787

Epoch: 5| Step: 2
Training loss: 2.6006727558675222
Validation loss: 2.44189496431607

Epoch: 5| Step: 3
Training loss: 3.090373036110582
Validation loss: 2.4525435190724836

Epoch: 5| Step: 4
Training loss: 3.3739731250771214
Validation loss: 2.4490304492364654

Epoch: 5| Step: 5
Training loss: 2.3740523606064126
Validation loss: 2.4400534726608996

Epoch: 5| Step: 6
Training loss: 2.5505905664274753
Validation loss: 2.4444593781104893

Epoch: 5| Step: 7
Training loss: 2.3107947170673273
Validation loss: 2.435543186709834

Epoch: 5| Step: 8
Training loss: 2.9576155817143004
Validation loss: 2.4301693499227124

Epoch: 5| Step: 9
Training loss: 2.955057793324802
Validation loss: 2.4241425113164516

Epoch: 5| Step: 10
Training loss: 2.370166075476948
Validation loss: 2.4416328271877497

Epoch: 62| Step: 0
Training loss: 3.072855820565282
Validation loss: 2.4393076319164475

Epoch: 5| Step: 1
Training loss: 2.379197477106682
Validation loss: 2.44182102491442

Epoch: 5| Step: 2
Training loss: 2.9470303734183987
Validation loss: 2.450493485820781

Epoch: 5| Step: 3
Training loss: 2.388361438906181
Validation loss: 2.431630689404066

Epoch: 5| Step: 4
Training loss: 2.49314369345748
Validation loss: 2.451356684044542

Epoch: 5| Step: 5
Training loss: 2.887378415937421
Validation loss: 2.434533679916031

Epoch: 5| Step: 6
Training loss: 2.6250989986098507
Validation loss: 2.4363505490592234

Epoch: 5| Step: 7
Training loss: 2.5963550033236387
Validation loss: 2.4480374524843795

Epoch: 5| Step: 8
Training loss: 2.544895455961777
Validation loss: 2.441798303114498

Epoch: 5| Step: 9
Training loss: 2.892638788611007
Validation loss: 2.4562442120989005

Epoch: 5| Step: 10
Training loss: 3.0193976487463328
Validation loss: 2.448851586243184

Epoch: 63| Step: 0
Training loss: 2.9423272260244753
Validation loss: 2.436018511186181

Epoch: 5| Step: 1
Training loss: 2.2266649724569367
Validation loss: 2.4555102659544623

Epoch: 5| Step: 2
Training loss: 2.163206516461461
Validation loss: 2.45123478409545

Epoch: 5| Step: 3
Training loss: 2.857445738269716
Validation loss: 2.4319564227481725

Epoch: 5| Step: 4
Training loss: 3.4368456130948783
Validation loss: 2.434867697546566

Epoch: 5| Step: 5
Training loss: 2.87052203863548
Validation loss: 2.4449856269129264

Epoch: 5| Step: 6
Training loss: 2.226935318636604
Validation loss: 2.4545146924000507

Epoch: 5| Step: 7
Training loss: 2.812216341761183
Validation loss: 2.446558227494256

Epoch: 5| Step: 8
Training loss: 2.9275591227150626
Validation loss: 2.4360814937869475

Epoch: 5| Step: 9
Training loss: 2.6005062674087664
Validation loss: 2.436627935885036

Epoch: 5| Step: 10
Training loss: 2.5817409242507607
Validation loss: 2.449360184693257

Epoch: 64| Step: 0
Training loss: 3.062422615163483
Validation loss: 2.4404788813290863

Epoch: 5| Step: 1
Training loss: 2.934486466668245
Validation loss: 2.4546460943930355

Epoch: 5| Step: 2
Training loss: 1.9102851808561168
Validation loss: 2.440754090063322

Epoch: 5| Step: 3
Training loss: 2.6423052797059823
Validation loss: 2.4500037901670946

Epoch: 5| Step: 4
Training loss: 2.3964193097447857
Validation loss: 2.451123793164357

Epoch: 5| Step: 5
Training loss: 2.1940264753136964
Validation loss: 2.445960228935773

Epoch: 5| Step: 6
Training loss: 3.174711715946838
Validation loss: 2.453336613692132

Epoch: 5| Step: 7
Training loss: 2.7338396692766733
Validation loss: 2.430725898184047

Epoch: 5| Step: 8
Training loss: 3.121027443268601
Validation loss: 2.443445327805194

Epoch: 5| Step: 9
Training loss: 2.8552705249788484
Validation loss: 2.4423105484594516

Epoch: 5| Step: 10
Training loss: 2.4656325346199437
Validation loss: 2.4333061127679025

Epoch: 65| Step: 0
Training loss: 2.292320042726079
Validation loss: 2.431818194791031

Epoch: 5| Step: 1
Training loss: 3.372112451771165
Validation loss: 2.450377796210179

Epoch: 5| Step: 2
Training loss: 1.888619233811052
Validation loss: 2.442642103616614

Epoch: 5| Step: 3
Training loss: 2.7233949641518804
Validation loss: 2.429710976569956

Epoch: 5| Step: 4
Training loss: 2.3746181984241916
Validation loss: 2.451626267245622

Epoch: 5| Step: 5
Training loss: 2.546429179670551
Validation loss: 2.436931484910056

Epoch: 5| Step: 6
Training loss: 3.033371487751317
Validation loss: 2.43022374745409

Epoch: 5| Step: 7
Training loss: 2.6013604162961372
Validation loss: 2.4449855126231603

Epoch: 5| Step: 8
Training loss: 2.686967930132821
Validation loss: 2.443909120075149

Epoch: 5| Step: 9
Training loss: 3.203545072969303
Validation loss: 2.443415564700687

Epoch: 5| Step: 10
Training loss: 2.804687840028705
Validation loss: 2.4310227126716435

Epoch: 66| Step: 0
Training loss: 2.5750808777190732
Validation loss: 2.432608393013188

Epoch: 5| Step: 1
Training loss: 2.38642814103177
Validation loss: 2.449725614564386

Epoch: 5| Step: 2
Training loss: 2.151367963253094
Validation loss: 2.449477142710415

Epoch: 5| Step: 3
Training loss: 2.0998784802108985
Validation loss: 2.4374931530978556

Epoch: 5| Step: 4
Training loss: 1.934807660304519
Validation loss: 2.4456588110413366

Epoch: 5| Step: 5
Training loss: 3.083242277570757
Validation loss: 2.442563261205638

Epoch: 5| Step: 6
Training loss: 3.4785124721437843
Validation loss: 2.4435938819029808

Epoch: 5| Step: 7
Training loss: 2.976886401237713
Validation loss: 2.447424764089252

Epoch: 5| Step: 8
Training loss: 2.7067850724834774
Validation loss: 2.4325847568160617

Epoch: 5| Step: 9
Training loss: 2.983656232468782
Validation loss: 2.4530214060912168

Epoch: 5| Step: 10
Training loss: 2.9665612434200503
Validation loss: 2.453722357821455

Epoch: 67| Step: 0
Training loss: 2.5836029117169166
Validation loss: 2.4521135395582454

Epoch: 5| Step: 1
Training loss: 2.3406484808972725
Validation loss: 2.455300774888122

Epoch: 5| Step: 2
Training loss: 2.9816015648029417
Validation loss: 2.444600441116871

Epoch: 5| Step: 3
Training loss: 3.0578298966853907
Validation loss: 2.4461209055396407

Epoch: 5| Step: 4
Training loss: 2.2736474428540965
Validation loss: 2.4438740572725934

Epoch: 5| Step: 5
Training loss: 3.182181615013923
Validation loss: 2.4510362389612337

Epoch: 5| Step: 6
Training loss: 2.7689623335800646
Validation loss: 2.4453963204715325

Epoch: 5| Step: 7
Training loss: 2.7498035360729887
Validation loss: 2.4608456340726956

Epoch: 5| Step: 8
Training loss: 2.1172770238438385
Validation loss: 2.4558831729701236

Epoch: 5| Step: 9
Training loss: 2.779553957085183
Validation loss: 2.4465950907894323

Epoch: 5| Step: 10
Training loss: 2.7954503698663196
Validation loss: 2.4499912848201437

Epoch: 68| Step: 0
Training loss: 3.0150536504878027
Validation loss: 2.4532741002046436

Epoch: 5| Step: 1
Training loss: 2.5400995102861152
Validation loss: 2.4342562545456756

Epoch: 5| Step: 2
Training loss: 2.7231043880541463
Validation loss: 2.4467169452805693

Epoch: 5| Step: 3
Training loss: 2.509875628365047
Validation loss: 2.448877886733663

Epoch: 5| Step: 4
Training loss: 2.423111532241276
Validation loss: 2.450930718968769

Epoch: 5| Step: 5
Training loss: 2.7710276275050454
Validation loss: 2.444814744638183

Epoch: 5| Step: 6
Training loss: 2.7186068793148106
Validation loss: 2.441715030036493

Epoch: 5| Step: 7
Training loss: 2.897156630306229
Validation loss: 2.4550354129151963

Epoch: 5| Step: 8
Training loss: 2.6414990304731747
Validation loss: 2.4453763848935526

Epoch: 5| Step: 9
Training loss: 3.3002141883004605
Validation loss: 2.456474541757013

Epoch: 5| Step: 10
Training loss: 1.8945145753736234
Validation loss: 2.4314906969274075

Epoch: 69| Step: 0
Training loss: 2.9621152925790653
Validation loss: 2.445301154299473

Epoch: 5| Step: 1
Training loss: 2.4650072143325312
Validation loss: 2.45221725754575

Epoch: 5| Step: 2
Training loss: 3.2919974020093674
Validation loss: 2.448315051320403

Epoch: 5| Step: 3
Training loss: 2.8240222150236822
Validation loss: 2.428364258635265

Epoch: 5| Step: 4
Training loss: 2.689166771985566
Validation loss: 2.442930883148112

Epoch: 5| Step: 5
Training loss: 2.751457521687795
Validation loss: 2.440072976837789

Epoch: 5| Step: 6
Training loss: 2.4423633865993257
Validation loss: 2.4508983088603626

Epoch: 5| Step: 7
Training loss: 2.3279699491547308
Validation loss: 2.433929638767832

Epoch: 5| Step: 8
Training loss: 2.631574390558012
Validation loss: 2.441642966724676

Epoch: 5| Step: 9
Training loss: 2.624568812969096
Validation loss: 2.436923978911542

Epoch: 5| Step: 10
Training loss: 2.631049225094777
Validation loss: 2.442886765999976

Epoch: 70| Step: 0
Training loss: 2.962898510876536
Validation loss: 2.4499417300156074

Epoch: 5| Step: 1
Training loss: 2.995966902413791
Validation loss: 2.4436191416063267

Epoch: 5| Step: 2
Training loss: 2.368578008280714
Validation loss: 2.450742033508884

Epoch: 5| Step: 3
Training loss: 2.5025131944733445
Validation loss: 2.443471888453405

Epoch: 5| Step: 4
Training loss: 3.1575047482223026
Validation loss: 2.4428649728978695

Epoch: 5| Step: 5
Training loss: 2.5595524280422493
Validation loss: 2.4498635792960117

Epoch: 5| Step: 6
Training loss: 1.9751332057021709
Validation loss: 2.446944938564016

Epoch: 5| Step: 7
Training loss: 2.7654054198947136
Validation loss: 2.4382484692032347

Epoch: 5| Step: 8
Training loss: 2.3339799825076346
Validation loss: 2.4480963454918045

Epoch: 5| Step: 9
Training loss: 2.951561569447974
Validation loss: 2.4569298137514064

Epoch: 5| Step: 10
Training loss: 2.7380141972855716
Validation loss: 2.4453056739246106

Epoch: 71| Step: 0
Training loss: 2.6491081716441895
Validation loss: 2.444490073947497

Epoch: 5| Step: 1
Training loss: 2.5790268678837203
Validation loss: 2.453979763381718

Epoch: 5| Step: 2
Training loss: 2.7391718179460702
Validation loss: 2.4503592916011345

Epoch: 5| Step: 3
Training loss: 2.5867823577682723
Validation loss: 2.4484542462362557

Epoch: 5| Step: 4
Training loss: 3.1197118648115247
Validation loss: 2.442713156165219

Epoch: 5| Step: 5
Training loss: 2.327162473238464
Validation loss: 2.446896944445416

Epoch: 5| Step: 6
Training loss: 3.109777069933248
Validation loss: 2.4498533618130565

Epoch: 5| Step: 7
Training loss: 2.150725322180521
Validation loss: 2.4407423639525585

Epoch: 5| Step: 8
Training loss: 2.209324224554948
Validation loss: 2.4512112229195986

Epoch: 5| Step: 9
Training loss: 2.987993533177253
Validation loss: 2.42846237932049

Epoch: 5| Step: 10
Training loss: 2.977598475598207
Validation loss: 2.4456097706756945

Epoch: 72| Step: 0
Training loss: 2.9495349840804486
Validation loss: 2.4486495541340014

Epoch: 5| Step: 1
Training loss: 2.4800935716819428
Validation loss: 2.4373573953559116

Epoch: 5| Step: 2
Training loss: 3.0390805437586934
Validation loss: 2.4418925422946622

Epoch: 5| Step: 3
Training loss: 2.617341449821481
Validation loss: 2.4490049757934904

Epoch: 5| Step: 4
Training loss: 2.5478396782793458
Validation loss: 2.460135098049238

Epoch: 5| Step: 5
Training loss: 2.9182166386193042
Validation loss: 2.4395442685421593

Epoch: 5| Step: 6
Training loss: 2.3810686578059936
Validation loss: 2.449691594669276

Epoch: 5| Step: 7
Training loss: 2.8443705122829934
Validation loss: 2.4483521384182803

Epoch: 5| Step: 8
Training loss: 2.191299408672787
Validation loss: 2.4322506153960086

Epoch: 5| Step: 9
Training loss: 2.944344844773011
Validation loss: 2.430962844999413

Epoch: 5| Step: 10
Training loss: 2.649042111140912
Validation loss: 2.444809642653849

Epoch: 73| Step: 0
Training loss: 2.7997811845019798
Validation loss: 2.4396369612792004

Epoch: 5| Step: 1
Training loss: 2.586065099051685
Validation loss: 2.432672137305075

Epoch: 5| Step: 2
Training loss: 3.038110422092754
Validation loss: 2.4502539579887417

Epoch: 5| Step: 3
Training loss: 2.137813085637642
Validation loss: 2.4345338357646873

Epoch: 5| Step: 4
Training loss: 3.1010554209028163
Validation loss: 2.4459252343169577

Epoch: 5| Step: 5
Training loss: 2.5431392864464453
Validation loss: 2.4563590117322405

Epoch: 5| Step: 6
Training loss: 2.799550401831083
Validation loss: 2.4552013565245505

Epoch: 5| Step: 7
Training loss: 2.6194899722156935
Validation loss: 2.445604029860219

Epoch: 5| Step: 8
Training loss: 2.031819659828578
Validation loss: 2.430463729350446

Epoch: 5| Step: 9
Training loss: 2.821841599445231
Validation loss: 2.4418331584495605

Epoch: 5| Step: 10
Training loss: 2.993022433690436
Validation loss: 2.4573239200214485

Epoch: 74| Step: 0
Training loss: 2.481340678597548
Validation loss: 2.4376321298753507

Epoch: 5| Step: 1
Training loss: 2.7458015818248245
Validation loss: 2.4498671173145374

Epoch: 5| Step: 2
Training loss: 3.4958320050848952
Validation loss: 2.4480080536221873

Epoch: 5| Step: 3
Training loss: 2.1989614766464523
Validation loss: 2.4443455288361395

Epoch: 5| Step: 4
Training loss: 2.502816521046819
Validation loss: 2.435362535757567

Epoch: 5| Step: 5
Training loss: 2.2262032202250714
Validation loss: 2.4373480468370157

Epoch: 5| Step: 6
Training loss: 2.5488862129695513
Validation loss: 2.4395804517837942

Epoch: 5| Step: 7
Training loss: 3.0658379872535524
Validation loss: 2.4422459745394933

Epoch: 5| Step: 8
Training loss: 2.8071083947953657
Validation loss: 2.4396740484214585

Epoch: 5| Step: 9
Training loss: 2.548224717547612
Validation loss: 2.4432253419125205

Epoch: 5| Step: 10
Training loss: 2.779426834381406
Validation loss: 2.454644482878118

Epoch: 75| Step: 0
Training loss: 2.617664532814272
Validation loss: 2.442458706072164

Epoch: 5| Step: 1
Training loss: 2.8428368412286993
Validation loss: 2.4404142536903266

Epoch: 5| Step: 2
Training loss: 3.263164706862614
Validation loss: 2.4543386873906754

Epoch: 5| Step: 3
Training loss: 2.6851382856791965
Validation loss: 2.4501507941009373

Epoch: 5| Step: 4
Training loss: 2.725332162893508
Validation loss: 2.448456329853992

Epoch: 5| Step: 5
Training loss: 2.538727160097025
Validation loss: 2.451974592105561

Epoch: 5| Step: 6
Training loss: 2.751174935855487
Validation loss: 2.4357147178699523

Epoch: 5| Step: 7
Training loss: 2.832406696557214
Validation loss: 2.4438309049456843

Epoch: 5| Step: 8
Training loss: 2.591124343143976
Validation loss: 2.453865714346488

Epoch: 5| Step: 9
Training loss: 2.1778742860745712
Validation loss: 2.4462033222766304

Epoch: 5| Step: 10
Training loss: 2.2629952789608017
Validation loss: 2.4370751053976023

Epoch: 76| Step: 0
Training loss: 2.618620158688912
Validation loss: 2.449101517951237

Epoch: 5| Step: 1
Training loss: 2.6839993765840218
Validation loss: 2.4763464110890747

Epoch: 5| Step: 2
Training loss: 2.6199917928552576
Validation loss: 2.460304230080001

Epoch: 5| Step: 3
Training loss: 2.829765897577963
Validation loss: 2.4479915360464877

Epoch: 5| Step: 4
Training loss: 2.617092757147083
Validation loss: 2.44280734431

Epoch: 5| Step: 5
Training loss: 3.181024143917649
Validation loss: 2.444823377249025

Epoch: 5| Step: 6
Training loss: 2.7193534444464467
Validation loss: 2.4442869964527603

Epoch: 5| Step: 7
Training loss: 3.0081862972885065
Validation loss: 2.4572534130583117

Epoch: 5| Step: 8
Training loss: 2.098748347251655
Validation loss: 2.434445730190143

Epoch: 5| Step: 9
Training loss: 2.174336308033357
Validation loss: 2.444781221087415

Epoch: 5| Step: 10
Training loss: 2.853716812508924
Validation loss: 2.446456664566296

Epoch: 77| Step: 0
Training loss: 2.804183107037882
Validation loss: 2.4331982592679315

Epoch: 5| Step: 1
Training loss: 2.6192571399325977
Validation loss: 2.442658175107336

Epoch: 5| Step: 2
Training loss: 2.2768998146851525
Validation loss: 2.440360030787431

Epoch: 5| Step: 3
Training loss: 2.573155462841238
Validation loss: 2.457313030394718

Epoch: 5| Step: 4
Training loss: 2.815380740393545
Validation loss: 2.449315961977876

Epoch: 5| Step: 5
Training loss: 2.4559532432765083
Validation loss: 2.4405813311495335

Epoch: 5| Step: 6
Training loss: 2.808884140091448
Validation loss: 2.450536020761988

Epoch: 5| Step: 7
Training loss: 2.55809367876709
Validation loss: 2.450599743329942

Epoch: 5| Step: 8
Training loss: 1.928936151803469
Validation loss: 2.459279908622142

Epoch: 5| Step: 9
Training loss: 3.230399226740177
Validation loss: 2.4452913538866925

Epoch: 5| Step: 10
Training loss: 3.3047566147378853
Validation loss: 2.4649533036062694

Epoch: 78| Step: 0
Training loss: 2.206364407693374
Validation loss: 2.4540554685878924

Epoch: 5| Step: 1
Training loss: 2.5132692098996166
Validation loss: 2.434643391742174

Epoch: 5| Step: 2
Training loss: 2.3924825594753663
Validation loss: 2.439138601609358

Epoch: 5| Step: 3
Training loss: 2.5309009075804805
Validation loss: 2.4516200056469706

Epoch: 5| Step: 4
Training loss: 2.704670723213512
Validation loss: 2.4414000377945158

Epoch: 5| Step: 5
Training loss: 2.9821884373688667
Validation loss: 2.450115549620287

Epoch: 5| Step: 6
Training loss: 3.055688562291923
Validation loss: 2.4677933386241797

Epoch: 5| Step: 7
Training loss: 2.824528551851117
Validation loss: 2.4526688074691507

Epoch: 5| Step: 8
Training loss: 3.1306609187823446
Validation loss: 2.450172194380895

Epoch: 5| Step: 9
Training loss: 2.559037823760145
Validation loss: 2.4248057849320492

Epoch: 5| Step: 10
Training loss: 2.339216093984626
Validation loss: 2.453125678237979

Epoch: 79| Step: 0
Training loss: 2.5830152890073745
Validation loss: 2.4494515001742734

Epoch: 5| Step: 1
Training loss: 2.9912083868949297
Validation loss: 2.4457335411202297

Epoch: 5| Step: 2
Training loss: 1.9780228237382014
Validation loss: 2.4419285700088906

Epoch: 5| Step: 3
Training loss: 2.738698625522346
Validation loss: 2.4464971430159945

Epoch: 5| Step: 4
Training loss: 3.2393702756894
Validation loss: 2.4424995488638617

Epoch: 5| Step: 5
Training loss: 3.0709644042933033
Validation loss: 2.4491734622929613

Epoch: 5| Step: 6
Training loss: 2.2781413597074196
Validation loss: 2.449494313812741

Epoch: 5| Step: 7
Training loss: 2.4314090235463706
Validation loss: 2.4343380793562783

Epoch: 5| Step: 8
Training loss: 2.2882547352909692
Validation loss: 2.4425593379105717

Epoch: 5| Step: 9
Training loss: 3.146043648331509
Validation loss: 2.4474861207992706

Epoch: 5| Step: 10
Training loss: 2.4022673307840336
Validation loss: 2.439056420189077

Epoch: 80| Step: 0
Training loss: 2.930791133272741
Validation loss: 2.463323375385324

Epoch: 5| Step: 1
Training loss: 2.483874864439351
Validation loss: 2.440104971797438

Epoch: 5| Step: 2
Training loss: 2.7959225700528103
Validation loss: 2.4419960540084924

Epoch: 5| Step: 3
Training loss: 3.2863040329650755
Validation loss: 2.441241272567646

Epoch: 5| Step: 4
Training loss: 2.320916607753601
Validation loss: 2.4434325103307817

Epoch: 5| Step: 5
Training loss: 2.75531714259991
Validation loss: 2.442067748400222

Epoch: 5| Step: 6
Training loss: 2.929276338335632
Validation loss: 2.438143402293116

Epoch: 5| Step: 7
Training loss: 2.142151337143762
Validation loss: 2.432709305862678

Epoch: 5| Step: 8
Training loss: 2.0858984097021946
Validation loss: 2.4545249145016874

Epoch: 5| Step: 9
Training loss: 2.7717270425661384
Validation loss: 2.4585357076593075

Epoch: 5| Step: 10
Training loss: 2.806835998658322
Validation loss: 2.456037935948312

Epoch: 81| Step: 0
Training loss: 2.962595130906005
Validation loss: 2.44657201723991

Epoch: 5| Step: 1
Training loss: 2.2583537261530133
Validation loss: 2.4493722798347655

Epoch: 5| Step: 2
Training loss: 2.711159293036696
Validation loss: 2.449702684570707

Epoch: 5| Step: 3
Training loss: 2.782716685835173
Validation loss: 2.4326505419752826

Epoch: 5| Step: 4
Training loss: 2.953220264977145
Validation loss: 2.454818382525066

Epoch: 5| Step: 5
Training loss: 3.138128550515505
Validation loss: 2.446908309987021

Epoch: 5| Step: 6
Training loss: 2.6648493972221936
Validation loss: 2.4343013090032213

Epoch: 5| Step: 7
Training loss: 2.828658417193937
Validation loss: 2.431226743110324

Epoch: 5| Step: 8
Training loss: 2.5699191734576923
Validation loss: 2.4395338649201648

Epoch: 5| Step: 9
Training loss: 2.0453056550986015
Validation loss: 2.451642453424948

Epoch: 5| Step: 10
Training loss: 2.097279889603019
Validation loss: 2.4520866914327937

Epoch: 82| Step: 0
Training loss: 1.9410344771438712
Validation loss: 2.4520634520937126

Epoch: 5| Step: 1
Training loss: 2.0142409429821195
Validation loss: 2.4526631505948604

Epoch: 5| Step: 2
Training loss: 3.058399803277762
Validation loss: 2.4589512182163924

Epoch: 5| Step: 3
Training loss: 2.6039744700397693
Validation loss: 2.452564645514203

Epoch: 5| Step: 4
Training loss: 3.003880216686606
Validation loss: 2.450509824899499

Epoch: 5| Step: 5
Training loss: 2.7430363832815092
Validation loss: 2.449272753758033

Epoch: 5| Step: 6
Training loss: 2.9096685833009293
Validation loss: 2.43524552096237

Epoch: 5| Step: 7
Training loss: 2.752747810150182
Validation loss: 2.421200871003543

Epoch: 5| Step: 8
Training loss: 2.7888693862864695
Validation loss: 2.4542992120376828

Epoch: 5| Step: 9
Training loss: 2.928812694912374
Validation loss: 2.4396207506157763

Epoch: 5| Step: 10
Training loss: 2.185676904923242
Validation loss: 2.449503301473355

Epoch: 83| Step: 0
Training loss: 2.734124046798845
Validation loss: 2.45703171222151

Epoch: 5| Step: 1
Training loss: 3.30848781952065
Validation loss: 2.437083824857732

Epoch: 5| Step: 2
Training loss: 2.2700235748747324
Validation loss: 2.447415725324826

Epoch: 5| Step: 3
Training loss: 2.4492591477367633
Validation loss: 2.440629708911585

Epoch: 5| Step: 4
Training loss: 2.428541397662373
Validation loss: 2.4532598329495614

Epoch: 5| Step: 5
Training loss: 2.7609876989735134
Validation loss: 2.4392091739514834

Epoch: 5| Step: 6
Training loss: 3.010217750251743
Validation loss: 2.447888219733976

Epoch: 5| Step: 7
Training loss: 2.648172731021142
Validation loss: 2.437498311940659

Epoch: 5| Step: 8
Training loss: 2.9455938634880003
Validation loss: 2.4540439099784903

Epoch: 5| Step: 9
Training loss: 2.3495024215188938
Validation loss: 2.4360764340231396

Epoch: 5| Step: 10
Training loss: 1.8971532551579797
Validation loss: 2.4609896902868016

Epoch: 84| Step: 0
Training loss: 2.7102026919193003
Validation loss: 2.4399368604025

Epoch: 5| Step: 1
Training loss: 2.9208133829245395
Validation loss: 2.458285949845494

Epoch: 5| Step: 2
Training loss: 2.2553385872407103
Validation loss: 2.441364219648291

Epoch: 5| Step: 3
Training loss: 1.8531447462602701
Validation loss: 2.4370857667190164

Epoch: 5| Step: 4
Training loss: 2.613132900252554
Validation loss: 2.440336454962419

Epoch: 5| Step: 5
Training loss: 2.659945979609533
Validation loss: 2.443948299604957

Epoch: 5| Step: 6
Training loss: 3.135887710487747
Validation loss: 2.4502216027521815

Epoch: 5| Step: 7
Training loss: 2.33803400477994
Validation loss: 2.4352155950023384

Epoch: 5| Step: 8
Training loss: 3.0841437812566967
Validation loss: 2.444291201207146

Epoch: 5| Step: 9
Training loss: 3.102063808717037
Validation loss: 2.4392689443304443

Epoch: 5| Step: 10
Training loss: 2.39167034755871
Validation loss: 2.4389183654827113

Epoch: 85| Step: 0
Training loss: 2.353760968474987
Validation loss: 2.4416632918703027

Epoch: 5| Step: 1
Training loss: 2.518586873340289
Validation loss: 2.443572454961105

Epoch: 5| Step: 2
Training loss: 3.0347758758092898
Validation loss: 2.446879551334706

Epoch: 5| Step: 3
Training loss: 2.53100283322577
Validation loss: 2.432422087854869

Epoch: 5| Step: 4
Training loss: 2.6409055120688314
Validation loss: 2.4364803117631304

Epoch: 5| Step: 5
Training loss: 3.066978760746815
Validation loss: 2.4560589253421186

Epoch: 5| Step: 6
Training loss: 2.85526484689008
Validation loss: 2.438558805513692

Epoch: 5| Step: 7
Training loss: 1.9775992226574428
Validation loss: 2.449153647480213

Epoch: 5| Step: 8
Training loss: 2.985987681910868
Validation loss: 2.4352230546826057

Epoch: 5| Step: 9
Training loss: 2.60081530772421
Validation loss: 2.4577284743705934

Epoch: 5| Step: 10
Training loss: 2.4442398594968484
Validation loss: 2.451675631673763

Epoch: 86| Step: 0
Training loss: 2.3930526076072542
Validation loss: 2.44855836003706

Epoch: 5| Step: 1
Training loss: 2.569143011838208
Validation loss: 2.457070726325038

Epoch: 5| Step: 2
Training loss: 2.721683191489492
Validation loss: 2.4421293693462465

Epoch: 5| Step: 3
Training loss: 2.477800414871032
Validation loss: 2.4513296195122023

Epoch: 5| Step: 4
Training loss: 2.8593711644548216
Validation loss: 2.4482764495248435

Epoch: 5| Step: 5
Training loss: 2.6820694815946813
Validation loss: 2.4508316965570454

Epoch: 5| Step: 6
Training loss: 3.0341081810350192
Validation loss: 2.4527191752343014

Epoch: 5| Step: 7
Training loss: 2.867505796471535
Validation loss: 2.440872639937998

Epoch: 5| Step: 8
Training loss: 2.4265541405665836
Validation loss: 2.4374966207248936

Epoch: 5| Step: 9
Training loss: 2.5376555785042076
Validation loss: 2.449570970303576

Epoch: 5| Step: 10
Training loss: 2.62585435315525
Validation loss: 2.438280344060323

Epoch: 87| Step: 0
Training loss: 2.8199281721233715
Validation loss: 2.4566082234758757

Epoch: 5| Step: 1
Training loss: 2.979366553654511
Validation loss: 2.452026705510954

Epoch: 5| Step: 2
Training loss: 2.9188015526868702
Validation loss: 2.440677763247888

Epoch: 5| Step: 3
Training loss: 2.563037629832472
Validation loss: 2.4465459612615654

Epoch: 5| Step: 4
Training loss: 2.5571242910230216
Validation loss: 2.4481793481086536

Epoch: 5| Step: 5
Training loss: 2.7793577808132386
Validation loss: 2.460267763926152

Epoch: 5| Step: 6
Training loss: 2.959833991318525
Validation loss: 2.43892128554331

Epoch: 5| Step: 7
Training loss: 2.2857557765566856
Validation loss: 2.454768143468983

Epoch: 5| Step: 8
Training loss: 2.4525816491832937
Validation loss: 2.4497943561664495

Epoch: 5| Step: 9
Training loss: 2.2332575211064696
Validation loss: 2.4437928753818325

Epoch: 5| Step: 10
Training loss: 2.7025960062849306
Validation loss: 2.448242985416912

Epoch: 88| Step: 0
Training loss: 2.2639563367764675
Validation loss: 2.454470568821395

Epoch: 5| Step: 1
Training loss: 2.5802624713842834
Validation loss: 2.4556223442943503

Epoch: 5| Step: 2
Training loss: 3.2299305330252763
Validation loss: 2.456117680286396

Epoch: 5| Step: 3
Training loss: 2.287120737622554
Validation loss: 2.4483815153485993

Epoch: 5| Step: 4
Training loss: 2.9100984093979316
Validation loss: 2.4599943453759368

Epoch: 5| Step: 5
Training loss: 2.7486108392354756
Validation loss: 2.432436337158082

Epoch: 5| Step: 6
Training loss: 3.0089952397611524
Validation loss: 2.428747983014215

Epoch: 5| Step: 7
Training loss: 2.2553343587172603
Validation loss: 2.423839211602803

Epoch: 5| Step: 8
Training loss: 2.5586617730103662
Validation loss: 2.4396655946181074

Epoch: 5| Step: 9
Training loss: 2.4357467606053214
Validation loss: 2.445006067918682

Epoch: 5| Step: 10
Training loss: 2.650229418918368
Validation loss: 2.454158026989265

Epoch: 89| Step: 0
Training loss: 2.603354630067717
Validation loss: 2.448663212749378

Epoch: 5| Step: 1
Training loss: 2.4451488891077338
Validation loss: 2.465289155212736

Epoch: 5| Step: 2
Training loss: 2.841153982531326
Validation loss: 2.431165475881563

Epoch: 5| Step: 3
Training loss: 2.857881249653593
Validation loss: 2.4508342289915577

Epoch: 5| Step: 4
Training loss: 2.505012827096104
Validation loss: 2.4433864218450987

Epoch: 5| Step: 5
Training loss: 2.6112540783081055
Validation loss: 2.4446893971621786

Epoch: 5| Step: 6
Training loss: 2.772203455648903
Validation loss: 2.4482638798572336

Epoch: 5| Step: 7
Training loss: 2.682926455939662
Validation loss: 2.4365386066099797

Epoch: 5| Step: 8
Training loss: 2.356947603849882
Validation loss: 2.4526902746239463

Epoch: 5| Step: 9
Training loss: 2.740593688855577
Validation loss: 2.4645108033731367

Epoch: 5| Step: 10
Training loss: 2.7215598483439005
Validation loss: 2.4427282417091822

Epoch: 90| Step: 0
Training loss: 2.713378247241575
Validation loss: 2.4523917307274146

Epoch: 5| Step: 1
Training loss: 2.751369308803399
Validation loss: 2.448987743161854

Epoch: 5| Step: 2
Training loss: 2.5139356354733864
Validation loss: 2.4393333069933836

Epoch: 5| Step: 3
Training loss: 3.1816103508189806
Validation loss: 2.4530608737899127

Epoch: 5| Step: 4
Training loss: 2.551085379493277
Validation loss: 2.448889411625736

Epoch: 5| Step: 5
Training loss: 2.0031358453751595
Validation loss: 2.4423187852719885

Epoch: 5| Step: 6
Training loss: 2.7776328578868896
Validation loss: 2.4405855927083864

Epoch: 5| Step: 7
Training loss: 3.0358697354562465
Validation loss: 2.435381295372668

Epoch: 5| Step: 8
Training loss: 2.0384114713292147
Validation loss: 2.4428438055979083

Epoch: 5| Step: 9
Training loss: 3.1242354411399287
Validation loss: 2.457092119546728

Epoch: 5| Step: 10
Training loss: 1.9558712382382504
Validation loss: 2.4422276340046585

Epoch: 91| Step: 0
Training loss: 2.536201625943601
Validation loss: 2.445092324040181

Epoch: 5| Step: 1
Training loss: 2.716529377781798
Validation loss: 2.4485770897486634

Epoch: 5| Step: 2
Training loss: 2.431779261547415
Validation loss: 2.4399592181364373

Epoch: 5| Step: 3
Training loss: 2.631414478081426
Validation loss: 2.4601831256880518

Epoch: 5| Step: 4
Training loss: 3.088651057981654
Validation loss: 2.437939903650247

Epoch: 5| Step: 5
Training loss: 3.1598998768553552
Validation loss: 2.451800399787626

Epoch: 5| Step: 6
Training loss: 2.393199058456784
Validation loss: 2.445026694864491

Epoch: 5| Step: 7
Training loss: 2.509960644933986
Validation loss: 2.4448956540488136

Epoch: 5| Step: 8
Training loss: 2.672540949765565
Validation loss: 2.4441712616556734

Epoch: 5| Step: 9
Training loss: 2.2170162680531913
Validation loss: 2.44885608361253

Epoch: 5| Step: 10
Training loss: 2.5574730668276504
Validation loss: 2.4556453286299598

Epoch: 92| Step: 0
Training loss: 2.5655338656818962
Validation loss: 2.444710608255187

Epoch: 5| Step: 1
Training loss: 2.3101342962290676
Validation loss: 2.4613127110367414

Epoch: 5| Step: 2
Training loss: 3.0606549991869145
Validation loss: 2.434065611914098

Epoch: 5| Step: 3
Training loss: 2.1839009787081114
Validation loss: 2.444399133696105

Epoch: 5| Step: 4
Training loss: 3.187130476531903
Validation loss: 2.431108838015633

Epoch: 5| Step: 5
Training loss: 2.772680216814914
Validation loss: 2.4536312164367833

Epoch: 5| Step: 6
Training loss: 2.0139283128876966
Validation loss: 2.4522575232977943

Epoch: 5| Step: 7
Training loss: 2.152594079277745
Validation loss: 2.459302459525519

Epoch: 5| Step: 8
Training loss: 2.661550730515422
Validation loss: 2.4475247287750594

Epoch: 5| Step: 9
Training loss: 2.729177275969484
Validation loss: 2.4520856020283515

Epoch: 5| Step: 10
Training loss: 3.2635650708605035
Validation loss: 2.440190808630542

Epoch: 93| Step: 0
Training loss: 2.5481046738795152
Validation loss: 2.444133719879548

Epoch: 5| Step: 1
Training loss: 2.9661124308209406
Validation loss: 2.4585649060788213

Epoch: 5| Step: 2
Training loss: 2.6054523701989343
Validation loss: 2.444169939018522

Epoch: 5| Step: 3
Training loss: 2.2399097530032592
Validation loss: 2.431561841272011

Epoch: 5| Step: 4
Training loss: 3.0799166504617466
Validation loss: 2.4510813792908475

Epoch: 5| Step: 5
Training loss: 2.7958446288318877
Validation loss: 2.4478506092871295

Epoch: 5| Step: 6
Training loss: 2.8482862908451985
Validation loss: 2.454081964022599

Epoch: 5| Step: 7
Training loss: 2.235508131257731
Validation loss: 2.4416441752345532

Epoch: 5| Step: 8
Training loss: 2.707777132484604
Validation loss: 2.4596386908285073

Epoch: 5| Step: 9
Training loss: 2.2962488891067268
Validation loss: 2.437873584525231

Epoch: 5| Step: 10
Training loss: 2.6217294936787248
Validation loss: 2.445748847024489

Epoch: 94| Step: 0
Training loss: 3.088748935651422
Validation loss: 2.457313703303689

Epoch: 5| Step: 1
Training loss: 2.476162562282831
Validation loss: 2.4314738035562637

Epoch: 5| Step: 2
Training loss: 2.8540683553057753
Validation loss: 2.454271098831721

Epoch: 5| Step: 3
Training loss: 2.407899563630658
Validation loss: 2.462329072726699

Epoch: 5| Step: 4
Training loss: 2.899927296220417
Validation loss: 2.42895494236774

Epoch: 5| Step: 5
Training loss: 2.497588234107476
Validation loss: 2.4426842610117854

Epoch: 5| Step: 6
Training loss: 2.6688020223152495
Validation loss: 2.4465127406917673

Epoch: 5| Step: 7
Training loss: 2.1606235102261326
Validation loss: 2.43854194586409

Epoch: 5| Step: 8
Training loss: 2.8707574141327825
Validation loss: 2.4492966915472136

Epoch: 5| Step: 9
Training loss: 2.525074997345231
Validation loss: 2.443616345709828

Epoch: 5| Step: 10
Training loss: 2.3834431798558913
Validation loss: 2.452122065449359

Epoch: 95| Step: 0
Training loss: 2.490388322447331
Validation loss: 2.438777262895226

Epoch: 5| Step: 1
Training loss: 2.81473215322904
Validation loss: 2.4386030403824246

Epoch: 5| Step: 2
Training loss: 2.3696081293037468
Validation loss: 2.447653040744666

Epoch: 5| Step: 3
Training loss: 2.3384157641077508
Validation loss: 2.44721260985965

Epoch: 5| Step: 4
Training loss: 2.659518575770924
Validation loss: 2.473215948782708

Epoch: 5| Step: 5
Training loss: 3.321358980308244
Validation loss: 2.450258214233697

Epoch: 5| Step: 6
Training loss: 2.7689193673784027
Validation loss: 2.4514981444121995

Epoch: 5| Step: 7
Training loss: 2.984217454836196
Validation loss: 2.4541288335924425

Epoch: 5| Step: 8
Training loss: 2.3953951448738993
Validation loss: 2.432876947231789

Epoch: 5| Step: 9
Training loss: 2.324429645106263
Validation loss: 2.4275439171867292

Epoch: 5| Step: 10
Training loss: 2.206244026154381
Validation loss: 2.4417561209738405

Epoch: 96| Step: 0
Training loss: 2.7524404967318215
Validation loss: 2.4418180736751163

Epoch: 5| Step: 1
Training loss: 2.388172562222145
Validation loss: 2.450321044254118

Epoch: 5| Step: 2
Training loss: 2.355832199979801
Validation loss: 2.4350082549619163

Epoch: 5| Step: 3
Training loss: 2.719647664923838
Validation loss: 2.437879561748825

Epoch: 5| Step: 4
Training loss: 2.68545330092659
Validation loss: 2.430297899394118

Epoch: 5| Step: 5
Training loss: 2.728143534209575
Validation loss: 2.436669522931284

Epoch: 5| Step: 6
Training loss: 2.463869896946588
Validation loss: 2.438428942097072

Epoch: 5| Step: 7
Training loss: 2.5904692157800393
Validation loss: 2.460228881799586

Epoch: 5| Step: 8
Training loss: 2.9368847141726246
Validation loss: 2.4344583164447013

Epoch: 5| Step: 9
Training loss: 2.9092677046415836
Validation loss: 2.449154494820574

Epoch: 5| Step: 10
Training loss: 2.427496311487446
Validation loss: 2.4530375579827095

Epoch: 97| Step: 0
Training loss: 2.637269907673079
Validation loss: 2.4538452249082283

Epoch: 5| Step: 1
Training loss: 2.3738941830622333
Validation loss: 2.4489352060215563

Epoch: 5| Step: 2
Training loss: 2.153482734626907
Validation loss: 2.44125615087986

Epoch: 5| Step: 3
Training loss: 2.9902359696476806
Validation loss: 2.458086567321641

Epoch: 5| Step: 4
Training loss: 3.082383980528378
Validation loss: 2.4439741577505627

Epoch: 5| Step: 5
Training loss: 2.6347585668108757
Validation loss: 2.460086309786546

Epoch: 5| Step: 6
Training loss: 2.3777347680635663
Validation loss: 2.44411470018511

Epoch: 5| Step: 7
Training loss: 2.86846280125141
Validation loss: 2.45358014853268

Epoch: 5| Step: 8
Training loss: 2.3087137517061085
Validation loss: 2.462147169715659

Epoch: 5| Step: 9
Training loss: 2.1299791904561234
Validation loss: 2.4419184453058804

Epoch: 5| Step: 10
Training loss: 3.187069134482142
Validation loss: 2.4488209272804036

Epoch: 98| Step: 0
Training loss: 2.780053727982384
Validation loss: 2.4280828658567897

Epoch: 5| Step: 1
Training loss: 2.991376084548953
Validation loss: 2.4501548276594183

Epoch: 5| Step: 2
Training loss: 2.7112367668198245
Validation loss: 2.4320189529162395

Epoch: 5| Step: 3
Training loss: 2.5957562144801285
Validation loss: 2.4426194797154794

Epoch: 5| Step: 4
Training loss: 2.7338292040381393
Validation loss: 2.4530355252852947

Epoch: 5| Step: 5
Training loss: 2.031914822280014
Validation loss: 2.426543648498936

Epoch: 5| Step: 6
Training loss: 1.8608023670499643
Validation loss: 2.4432382596307054

Epoch: 5| Step: 7
Training loss: 2.3086372281029055
Validation loss: 2.453364756415476

Epoch: 5| Step: 8
Training loss: 2.8248732614360366
Validation loss: 2.433829699239089

Epoch: 5| Step: 9
Training loss: 3.3611534911146976
Validation loss: 2.4414242848376215

Epoch: 5| Step: 10
Training loss: 2.3757599066666555
Validation loss: 2.451369077846132

Epoch: 99| Step: 0
Training loss: 3.1145488690326846
Validation loss: 2.446781181175783

Epoch: 5| Step: 1
Training loss: 2.5980970424591363
Validation loss: 2.4564501364423834

Epoch: 5| Step: 2
Training loss: 2.517524144531357
Validation loss: 2.446020776053148

Epoch: 5| Step: 3
Training loss: 2.228160405245526
Validation loss: 2.441269048564152

Epoch: 5| Step: 4
Training loss: 2.2869078614990337
Validation loss: 2.4506652467958254

Epoch: 5| Step: 5
Training loss: 3.077731344543739
Validation loss: 2.441026130732574

Epoch: 5| Step: 6
Training loss: 2.348464496632504
Validation loss: 2.450003317725434

Epoch: 5| Step: 7
Training loss: 2.342486333328815
Validation loss: 2.4323804924808945

Epoch: 5| Step: 8
Training loss: 3.1415742417019987
Validation loss: 2.4458839671068335

Epoch: 5| Step: 9
Training loss: 2.260070305464972
Validation loss: 2.438751559888865

Epoch: 5| Step: 10
Training loss: 2.703197764922226
Validation loss: 2.437045551150291

Epoch: 100| Step: 0
Training loss: 2.7051865318417705
Validation loss: 2.4688252958978203

Epoch: 5| Step: 1
Training loss: 2.3639784612045562
Validation loss: 2.447888413481997

Epoch: 5| Step: 2
Training loss: 2.2834917315188683
Validation loss: 2.4619196762503415

Epoch: 5| Step: 3
Training loss: 2.5648749905884674
Validation loss: 2.4396919857294375

Epoch: 5| Step: 4
Training loss: 2.927458787688271
Validation loss: 2.452457927995979

Epoch: 5| Step: 5
Training loss: 3.0968324352307106
Validation loss: 2.458282853601202

Epoch: 5| Step: 6
Training loss: 3.4084675421247264
Validation loss: 2.4416404405066157

Epoch: 5| Step: 7
Training loss: 2.251825863368015
Validation loss: 2.4402319430939063

Epoch: 5| Step: 8
Training loss: 2.1216696278845335
Validation loss: 2.4599324721352094

Epoch: 5| Step: 9
Training loss: 2.3744335502922413
Validation loss: 2.434753102836365

Epoch: 5| Step: 10
Training loss: 2.457756384265327
Validation loss: 2.4658670015807655

Epoch: 101| Step: 0
Training loss: 2.3261746423354133
Validation loss: 2.450439080025224

Epoch: 5| Step: 1
Training loss: 2.7216398293020174
Validation loss: 2.430580378423721

Epoch: 5| Step: 2
Training loss: 3.224847591850136
Validation loss: 2.43450734661507

Epoch: 5| Step: 3
Training loss: 2.377319006864748
Validation loss: 2.4594951537900505

Epoch: 5| Step: 4
Training loss: 2.420466745779734
Validation loss: 2.4589730433809165

Epoch: 5| Step: 5
Training loss: 2.757228713883573
Validation loss: 2.4548433857480947

Epoch: 5| Step: 6
Training loss: 2.174519637106238
Validation loss: 2.4544752334559377

Epoch: 5| Step: 7
Training loss: 2.6993634285913966
Validation loss: 2.4444257851867643

Epoch: 5| Step: 8
Training loss: 2.145163743320481
Validation loss: 2.437844661454421

Epoch: 5| Step: 9
Training loss: 2.778681737256077
Validation loss: 2.4508653679940884

Epoch: 5| Step: 10
Training loss: 3.0188102700355595
Validation loss: 2.4376191445873543

Epoch: 102| Step: 0
Training loss: 2.6054594162712315
Validation loss: 2.4369609795257134

Epoch: 5| Step: 1
Training loss: 2.8215571058633473
Validation loss: 2.4600147961037235

Epoch: 5| Step: 2
Training loss: 2.2516708527965394
Validation loss: 2.450252826964687

Epoch: 5| Step: 3
Training loss: 2.7038415389100376
Validation loss: 2.44704601659507

Epoch: 5| Step: 4
Training loss: 2.9102555430837693
Validation loss: 2.4328066875305

Epoch: 5| Step: 5
Training loss: 2.7079745323978277
Validation loss: 2.441710429219563

Epoch: 5| Step: 6
Training loss: 2.362299742108042
Validation loss: 2.433483293443889

Epoch: 5| Step: 7
Training loss: 2.244796988944864
Validation loss: 2.4398796396830873

Epoch: 5| Step: 8
Training loss: 2.803247703835035
Validation loss: 2.445760765060571

Epoch: 5| Step: 9
Training loss: 2.3924189798793325
Validation loss: 2.4453806821272206

Epoch: 5| Step: 10
Training loss: 2.958838048155871
Validation loss: 2.4459289656467518

Epoch: 103| Step: 0
Training loss: 3.1475759231342666
Validation loss: 2.4606620482064647

Epoch: 5| Step: 1
Training loss: 2.879742235728448
Validation loss: 2.4425145438879268

Epoch: 5| Step: 2
Training loss: 3.030278000872732
Validation loss: 2.4376148799458113

Epoch: 5| Step: 3
Training loss: 2.420711311596109
Validation loss: 2.4409092666622523

Epoch: 5| Step: 4
Training loss: 2.7179547604746057
Validation loss: 2.4484778679705204

Epoch: 5| Step: 5
Training loss: 1.7633668080176994
Validation loss: 2.4717192010968883

Epoch: 5| Step: 6
Training loss: 2.4988402537638468
Validation loss: 2.456430938676849

Epoch: 5| Step: 7
Training loss: 2.6741093445179067
Validation loss: 2.4506598782053297

Epoch: 5| Step: 8
Training loss: 2.378736067073107
Validation loss: 2.4387020978426226

Epoch: 5| Step: 9
Training loss: 2.731008495416771
Validation loss: 2.4436378703584722

Epoch: 5| Step: 10
Training loss: 2.2148947735111597
Validation loss: 2.4470578424068337

Epoch: 104| Step: 0
Training loss: 2.302226262093137
Validation loss: 2.4462891463376994

Epoch: 5| Step: 1
Training loss: 2.386871982281883
Validation loss: 2.45084491414182

Epoch: 5| Step: 2
Training loss: 3.0877825279545523
Validation loss: 2.4508292969657126

Epoch: 5| Step: 3
Training loss: 2.077877861758537
Validation loss: 2.4505235720083403

Epoch: 5| Step: 4
Training loss: 2.5992872581706474
Validation loss: 2.439990597840781

Epoch: 5| Step: 5
Training loss: 2.8912362766888493
Validation loss: 2.4380289413091214

Epoch: 5| Step: 6
Training loss: 2.4618854937168755
Validation loss: 2.4382794303819044

Epoch: 5| Step: 7
Training loss: 2.6999304091350877
Validation loss: 2.4513418021967817

Epoch: 5| Step: 8
Training loss: 1.8491301837271625
Validation loss: 2.4284883791332743

Epoch: 5| Step: 9
Training loss: 3.2551501622406533
Validation loss: 2.4369843734032908

Epoch: 5| Step: 10
Training loss: 2.7724578416678733
Validation loss: 2.432027161864501

Epoch: 105| Step: 0
Training loss: 2.274973556867913
Validation loss: 2.448946879294301

Epoch: 5| Step: 1
Training loss: 2.7330652206237422
Validation loss: 2.449073143051804

Epoch: 5| Step: 2
Training loss: 2.0095584862733946
Validation loss: 2.4588286917703135

Epoch: 5| Step: 3
Training loss: 2.738309285976751
Validation loss: 2.4509284711425825

Epoch: 5| Step: 4
Training loss: 2.388622367639043
Validation loss: 2.4283993532424795

Epoch: 5| Step: 5
Training loss: 2.910597472057609
Validation loss: 2.4315567721033746

Epoch: 5| Step: 6
Training loss: 2.9713415780275803
Validation loss: 2.4387421883314855

Epoch: 5| Step: 7
Training loss: 1.8439833929758036
Validation loss: 2.4371266432763248

Epoch: 5| Step: 8
Training loss: 3.0462780489939236
Validation loss: 2.443434935022499

Epoch: 5| Step: 9
Training loss: 2.947210939581301
Validation loss: 2.4435822103357885

Epoch: 5| Step: 10
Training loss: 2.5957419777883715
Validation loss: 2.449138832845905

Epoch: 106| Step: 0
Training loss: 2.3371193234134533
Validation loss: 2.4342643480015287

Epoch: 5| Step: 1
Training loss: 2.593390934001285
Validation loss: 2.444801041977088

Epoch: 5| Step: 2
Training loss: 2.9590639814992925
Validation loss: 2.436769965656404

Epoch: 5| Step: 3
Training loss: 2.1990676204594135
Validation loss: 2.450843347198568

Epoch: 5| Step: 4
Training loss: 2.6884031330782263
Validation loss: 2.4556154852826064

Epoch: 5| Step: 5
Training loss: 2.840249054962235
Validation loss: 2.4425646812731654

Epoch: 5| Step: 6
Training loss: 2.719038323208441
Validation loss: 2.444247980727826

Epoch: 5| Step: 7
Training loss: 2.4982710581884193
Validation loss: 2.450878675354031

Epoch: 5| Step: 8
Training loss: 2.417057488069898
Validation loss: 2.4394204919886686

Epoch: 5| Step: 9
Training loss: 2.984789914353221
Validation loss: 2.4345196113746366

Epoch: 5| Step: 10
Training loss: 2.279234426863836
Validation loss: 2.4600356728866655

Epoch: 107| Step: 0
Training loss: 2.455792574234146
Validation loss: 2.453026476887369

Epoch: 5| Step: 1
Training loss: 2.7098101379776995
Validation loss: 2.446570211269665

Epoch: 5| Step: 2
Training loss: 2.2858040698333055
Validation loss: 2.4505137828047086

Epoch: 5| Step: 3
Training loss: 2.3888701935955763
Validation loss: 2.4211730765509

Epoch: 5| Step: 4
Training loss: 2.069174860634508
Validation loss: 2.42955959724516

Epoch: 5| Step: 5
Training loss: 2.625570507723575
Validation loss: 2.4321203635029582

Epoch: 5| Step: 6
Training loss: 2.3235762020492756
Validation loss: 2.4491006365725814

Epoch: 5| Step: 7
Training loss: 2.566019479066646
Validation loss: 2.440589660982794

Epoch: 5| Step: 8
Training loss: 2.918779334629505
Validation loss: 2.439163845965675

Epoch: 5| Step: 9
Training loss: 3.346188093089433
Validation loss: 2.4503337634438704

Epoch: 5| Step: 10
Training loss: 2.6866091649012964
Validation loss: 2.425338820229355

Epoch: 108| Step: 0
Training loss: 2.333398159579794
Validation loss: 2.4599448070975836

Epoch: 5| Step: 1
Training loss: 2.658163391309624
Validation loss: 2.4472464148962794

Epoch: 5| Step: 2
Training loss: 2.7119328762963715
Validation loss: 2.4368684222317256

Epoch: 5| Step: 3
Training loss: 2.328514015416058
Validation loss: 2.454488023032042

Epoch: 5| Step: 4
Training loss: 3.5764489392091856
Validation loss: 2.4589622163136235

Epoch: 5| Step: 5
Training loss: 1.990936724390643
Validation loss: 2.4387760834494716

Epoch: 5| Step: 6
Training loss: 2.497112132092618
Validation loss: 2.442321455643379

Epoch: 5| Step: 7
Training loss: 2.199224387342908
Validation loss: 2.4431325833239574

Epoch: 5| Step: 8
Training loss: 2.6632212991588697
Validation loss: 2.445994413922786

Epoch: 5| Step: 9
Training loss: 2.5548032215285037
Validation loss: 2.4336443166154402

Epoch: 5| Step: 10
Training loss: 2.723477867645823
Validation loss: 2.4671384703022814

Epoch: 109| Step: 0
Training loss: 2.587252556215248
Validation loss: 2.4466865393318935

Epoch: 5| Step: 1
Training loss: 2.8326248704366432
Validation loss: 2.4280565692339184

Epoch: 5| Step: 2
Training loss: 1.96086862146757
Validation loss: 2.4379929306268444

Epoch: 5| Step: 3
Training loss: 2.7993804961565982
Validation loss: 2.44064697849837

Epoch: 5| Step: 4
Training loss: 2.9310032852555303
Validation loss: 2.431661078030211

Epoch: 5| Step: 5
Training loss: 2.653515384201787
Validation loss: 2.443099188320594

Epoch: 5| Step: 6
Training loss: 2.467026313990862
Validation loss: 2.432176914043456

Epoch: 5| Step: 7
Training loss: 2.467731217331505
Validation loss: 2.416113903391713

Epoch: 5| Step: 8
Training loss: 2.914822313183368
Validation loss: 2.4436140460432183

Epoch: 5| Step: 9
Training loss: 2.4500982965485782
Validation loss: 2.4319360354512423

Epoch: 5| Step: 10
Training loss: 2.5250399671356343
Validation loss: 2.436834121845716

Epoch: 110| Step: 0
Training loss: 3.121045318724283
Validation loss: 2.4507652581808075

Epoch: 5| Step: 1
Training loss: 3.0818807084095092
Validation loss: 2.4381242672593744

Epoch: 5| Step: 2
Training loss: 2.876290239154588
Validation loss: 2.4534668854986474

Epoch: 5| Step: 3
Training loss: 1.9835409980000591
Validation loss: 2.4423290878090356

Epoch: 5| Step: 4
Training loss: 2.5598364221942647
Validation loss: 2.4478376394557113

Epoch: 5| Step: 5
Training loss: 2.8797006740258375
Validation loss: 2.4403682500216015

Epoch: 5| Step: 6
Training loss: 2.7945906191548366
Validation loss: 2.4459374061872197

Epoch: 5| Step: 7
Training loss: 2.131538989031511
Validation loss: 2.4710641323790536

Epoch: 5| Step: 8
Training loss: 1.9921188641860756
Validation loss: 2.445546369898938

Epoch: 5| Step: 9
Training loss: 2.4554306177812872
Validation loss: 2.4406854646264833

Epoch: 5| Step: 10
Training loss: 2.273009479514686
Validation loss: 2.442501499539439

Epoch: 111| Step: 0
Training loss: 2.3282804501243297
Validation loss: 2.4549300209589298

Epoch: 5| Step: 1
Training loss: 2.7273673806960197
Validation loss: 2.433344696036373

Epoch: 5| Step: 2
Training loss: 2.4587214104328887
Validation loss: 2.443606954516613

Epoch: 5| Step: 3
Training loss: 2.0757341901435993
Validation loss: 2.4469029383922165

Epoch: 5| Step: 4
Training loss: 2.3535912972468944
Validation loss: 2.4389556501262635

Epoch: 5| Step: 5
Training loss: 2.5467890625479312
Validation loss: 2.4501382403270155

Epoch: 5| Step: 6
Training loss: 3.1339643458496984
Validation loss: 2.4529234191534814

Epoch: 5| Step: 7
Training loss: 2.858809618476261
Validation loss: 2.4648455597427343

Epoch: 5| Step: 8
Training loss: 2.6281939557585345
Validation loss: 2.43846904443617

Epoch: 5| Step: 9
Training loss: 2.513786259963008
Validation loss: 2.4521268119166675

Epoch: 5| Step: 10
Training loss: 2.809213795349107
Validation loss: 2.464464314331944

Epoch: 112| Step: 0
Training loss: 3.077817949965508
Validation loss: 2.447235139968036

Epoch: 5| Step: 1
Training loss: 2.9269248041594955
Validation loss: 2.432510517555738

Epoch: 5| Step: 2
Training loss: 2.490882077225665
Validation loss: 2.4440423604309345

Epoch: 5| Step: 3
Training loss: 2.5374178680507615
Validation loss: 2.4440015628274585

Epoch: 5| Step: 4
Training loss: 2.159762189630904
Validation loss: 2.421773067238607

Epoch: 5| Step: 5
Training loss: 2.5338678833347474
Validation loss: 2.4380646118229583

Epoch: 5| Step: 6
Training loss: 2.4511658444273423
Validation loss: 2.4535474045824297

Epoch: 5| Step: 7
Training loss: 2.707487786178303
Validation loss: 2.4489184513076583

Epoch: 5| Step: 8
Training loss: 2.7139075112547175
Validation loss: 2.4421315465397955

Epoch: 5| Step: 9
Training loss: 2.157424827848559
Validation loss: 2.417965534273073

Epoch: 5| Step: 10
Training loss: 2.4268981033392603
Validation loss: 2.4556719311429798

Epoch: 113| Step: 0
Training loss: 2.5783242813309823
Validation loss: 2.428689395615658

Epoch: 5| Step: 1
Training loss: 2.4119055534457967
Validation loss: 2.448333428974823

Epoch: 5| Step: 2
Training loss: 2.1500874789871607
Validation loss: 2.4363505448502383

Epoch: 5| Step: 3
Training loss: 2.8343883308004627
Validation loss: 2.4224092929545256

Epoch: 5| Step: 4
Training loss: 2.857186402261509
Validation loss: 2.443618650619856

Epoch: 5| Step: 5
Training loss: 1.9200349388321192
Validation loss: 2.4388939284958404

Epoch: 5| Step: 6
Training loss: 2.814742741187223
Validation loss: 2.4524106412789837

Epoch: 5| Step: 7
Training loss: 3.0842833902500058
Validation loss: 2.441745198665527

Epoch: 5| Step: 8
Training loss: 2.5214978017530782
Validation loss: 2.44672922899226

Epoch: 5| Step: 9
Training loss: 2.503210676348586
Validation loss: 2.4467255696083328

Epoch: 5| Step: 10
Training loss: 2.5392555515551236
Validation loss: 2.4301003374869015

Epoch: 114| Step: 0
Training loss: 2.2173063927805132
Validation loss: 2.461301669280359

Epoch: 5| Step: 1
Training loss: 2.612719739223857
Validation loss: 2.439121440111636

Epoch: 5| Step: 2
Training loss: 2.623128768994539
Validation loss: 2.444052199417831

Epoch: 5| Step: 3
Training loss: 2.169395843115589
Validation loss: 2.4341086877498825

Epoch: 5| Step: 4
Training loss: 3.1313433543773077
Validation loss: 2.43982986847051

Epoch: 5| Step: 5
Training loss: 3.085358461547487
Validation loss: 2.4543189571053423

Epoch: 5| Step: 6
Training loss: 2.391117818063518
Validation loss: 2.4396271470444373

Epoch: 5| Step: 7
Training loss: 2.1478073028141917
Validation loss: 2.4577379685894374

Epoch: 5| Step: 8
Training loss: 2.5629981882518327
Validation loss: 2.457429812291783

Epoch: 5| Step: 9
Training loss: 2.8670606039379134
Validation loss: 2.451221637639871

Epoch: 5| Step: 10
Training loss: 2.5129009211628897
Validation loss: 2.449363062999049

Epoch: 115| Step: 0
Training loss: 2.594286483985998
Validation loss: 2.4314701075061294

Epoch: 5| Step: 1
Training loss: 2.4804545244424756
Validation loss: 2.4511867202278523

Epoch: 5| Step: 2
Training loss: 2.703046852702119
Validation loss: 2.4433173478181422

Epoch: 5| Step: 3
Training loss: 2.259176086702575
Validation loss: 2.4332259374302834

Epoch: 5| Step: 4
Training loss: 2.3754563144207035
Validation loss: 2.44312799881777

Epoch: 5| Step: 5
Training loss: 1.814325071482946
Validation loss: 2.451373396994396

Epoch: 5| Step: 6
Training loss: 3.0930427744756988
Validation loss: 2.409493378379385

Epoch: 5| Step: 7
Training loss: 2.8954875565796545
Validation loss: 2.4382731755131997

Epoch: 5| Step: 8
Training loss: 2.488762106911503
Validation loss: 2.430449985334633

Epoch: 5| Step: 9
Training loss: 3.089708250525324
Validation loss: 2.456812531216052

Epoch: 5| Step: 10
Training loss: 2.1885014012981316
Validation loss: 2.4426361674342187

Epoch: 116| Step: 0
Training loss: 2.3376653398594973
Validation loss: 2.4335615951664726

Epoch: 5| Step: 1
Training loss: 2.787175328116598
Validation loss: 2.4318378245799237

Epoch: 5| Step: 2
Training loss: 2.311313634133635
Validation loss: 2.4511159216768146

Epoch: 5| Step: 3
Training loss: 2.3941968774621096
Validation loss: 2.445728067365156

Epoch: 5| Step: 4
Training loss: 2.1393050976454404
Validation loss: 2.444092644790222

Epoch: 5| Step: 5
Training loss: 2.628367670673883
Validation loss: 2.4337690526586653

Epoch: 5| Step: 6
Training loss: 3.1951477455997144
Validation loss: 2.438552762672077

Epoch: 5| Step: 7
Training loss: 2.1722274604055603
Validation loss: 2.4505669972172632

Epoch: 5| Step: 8
Training loss: 3.075850367623365
Validation loss: 2.4571656348940474

Epoch: 5| Step: 9
Training loss: 2.5123281733273592
Validation loss: 2.423626463092655

Epoch: 5| Step: 10
Training loss: 2.671428710071977
Validation loss: 2.4474240360870954

Epoch: 117| Step: 0
Training loss: 2.608332260017865
Validation loss: 2.455788178300837

Epoch: 5| Step: 1
Training loss: 1.657043770648823
Validation loss: 2.4562568933107936

Epoch: 5| Step: 2
Training loss: 2.7849968520853823
Validation loss: 2.4501079689144953

Epoch: 5| Step: 3
Training loss: 2.6057750058658304
Validation loss: 2.4530670376538564

Epoch: 5| Step: 4
Training loss: 2.6287221404815515
Validation loss: 2.413556402274924

Epoch: 5| Step: 5
Training loss: 2.3705815825746925
Validation loss: 2.45694184762998

Epoch: 5| Step: 6
Training loss: 2.331101633213648
Validation loss: 2.4311156907714326

Epoch: 5| Step: 7
Training loss: 2.9946416048794227
Validation loss: 2.4347293463650677

Epoch: 5| Step: 8
Training loss: 2.5721338190532927
Validation loss: 2.4539109023975696

Epoch: 5| Step: 9
Training loss: 2.4753695241020623
Validation loss: 2.419313436482068

Epoch: 5| Step: 10
Training loss: 3.0880178658161306
Validation loss: 2.4355313691968457

Epoch: 118| Step: 0
Training loss: 2.9507336496276517
Validation loss: 2.428933451198577

Epoch: 5| Step: 1
Training loss: 2.8114939267728754
Validation loss: 2.434378927807582

Epoch: 5| Step: 2
Training loss: 1.7133119036797624
Validation loss: 2.445225712753863

Epoch: 5| Step: 3
Training loss: 2.994005890742988
Validation loss: 2.458692482884582

Epoch: 5| Step: 4
Training loss: 2.1670561098123304
Validation loss: 2.4171730685963784

Epoch: 5| Step: 5
Training loss: 2.841403202435986
Validation loss: 2.4473907802986954

Epoch: 5| Step: 6
Training loss: 2.5136773762201847
Validation loss: 2.4334979189463883

Epoch: 5| Step: 7
Training loss: 2.7202394286129876
Validation loss: 2.436346047545771

Epoch: 5| Step: 8
Training loss: 2.2292594771509404
Validation loss: 2.4408148477246763

Epoch: 5| Step: 9
Training loss: 2.385286841267631
Validation loss: 2.4489168904596834

Epoch: 5| Step: 10
Training loss: 2.7907009067442754
Validation loss: 2.4551306758318914

Epoch: 119| Step: 0
Training loss: 2.7552608107609236
Validation loss: 2.4426281132626917

Epoch: 5| Step: 1
Training loss: 2.65602039017951
Validation loss: 2.4461627975678635

Epoch: 5| Step: 2
Training loss: 2.8054257752099594
Validation loss: 2.4658551755243976

Epoch: 5| Step: 3
Training loss: 2.728253209268351
Validation loss: 2.441711519053294

Epoch: 5| Step: 4
Training loss: 2.451187534966161
Validation loss: 2.446445560474391

Epoch: 5| Step: 5
Training loss: 2.387415008629919
Validation loss: 2.4318465949714323

Epoch: 5| Step: 6
Training loss: 2.0249494993718
Validation loss: 2.4564506895695826

Epoch: 5| Step: 7
Training loss: 3.022617593628008
Validation loss: 2.4200042157334325

Epoch: 5| Step: 8
Training loss: 2.276113187479484
Validation loss: 2.4343329469895316

Epoch: 5| Step: 9
Training loss: 2.6388477009910742
Validation loss: 2.433212049922704

Epoch: 5| Step: 10
Training loss: 2.4288311887512744
Validation loss: 2.4552101024531323

Epoch: 120| Step: 0
Training loss: 2.382777279452816
Validation loss: 2.434978330297235

Epoch: 5| Step: 1
Training loss: 2.4430282697755685
Validation loss: 2.457223722784784

Epoch: 5| Step: 2
Training loss: 3.0115968355472034
Validation loss: 2.4414385645542866

Epoch: 5| Step: 3
Training loss: 2.4976414999527807
Validation loss: 2.443271007959491

Epoch: 5| Step: 4
Training loss: 2.700211117579196
Validation loss: 2.444709723196202

Epoch: 5| Step: 5
Training loss: 2.610562539699373
Validation loss: 2.4266363312622414

Epoch: 5| Step: 6
Training loss: 2.972489100404973
Validation loss: 2.436418814680308

Epoch: 5| Step: 7
Training loss: 2.634745536258202
Validation loss: 2.4365255129074934

Epoch: 5| Step: 8
Training loss: 2.1866463221596013
Validation loss: 2.4399020252599386

Epoch: 5| Step: 9
Training loss: 2.1708761429424817
Validation loss: 2.44178467329275

Epoch: 5| Step: 10
Training loss: 2.4784221225714087
Validation loss: 2.4224509071489115

Epoch: 121| Step: 0
Training loss: 2.4977147147716288
Validation loss: 2.4323500548740458

Epoch: 5| Step: 1
Training loss: 2.8491090017550813
Validation loss: 2.450434815724835

Epoch: 5| Step: 2
Training loss: 2.790958646882755
Validation loss: 2.450297191802695

Epoch: 5| Step: 3
Training loss: 2.824172994366991
Validation loss: 2.4468535740677453

Epoch: 5| Step: 4
Training loss: 2.862214892985488
Validation loss: 2.433438580979354

Epoch: 5| Step: 5
Training loss: 1.982017137524588
Validation loss: 2.4441531191231336

Epoch: 5| Step: 6
Training loss: 2.8085665854040984
Validation loss: 2.4315740302176505

Epoch: 5| Step: 7
Training loss: 2.642337582305627
Validation loss: 2.4449653147065327

Epoch: 5| Step: 8
Training loss: 2.3246989803899925
Validation loss: 2.445181154200772

Epoch: 5| Step: 9
Training loss: 1.9656087246995808
Validation loss: 2.4559809687532677

Epoch: 5| Step: 10
Training loss: 2.4698776373882683
Validation loss: 2.449040007008666

Epoch: 122| Step: 0
Training loss: 2.5701802228382062
Validation loss: 2.4392913628371153

Epoch: 5| Step: 1
Training loss: 2.8815354410640017
Validation loss: 2.4317995763636

Epoch: 5| Step: 2
Training loss: 1.9702034686397154
Validation loss: 2.4388736832842723

Epoch: 5| Step: 3
Training loss: 2.582190065794668
Validation loss: 2.4448762890085587

Epoch: 5| Step: 4
Training loss: 2.3106295263706786
Validation loss: 2.4492600824400808

Epoch: 5| Step: 5
Training loss: 2.911065982229373
Validation loss: 2.420950056076229

Epoch: 5| Step: 6
Training loss: 2.437660212019948
Validation loss: 2.4309125484768024

Epoch: 5| Step: 7
Training loss: 2.2373346320903647
Validation loss: 2.4399095767339505

Epoch: 5| Step: 8
Training loss: 2.651356037039168
Validation loss: 2.4474919635169368

Epoch: 5| Step: 9
Training loss: 2.7083865429468568
Validation loss: 2.4509026079182767

Epoch: 5| Step: 10
Training loss: 2.8110988093556393
Validation loss: 2.445648823377587

Epoch: 123| Step: 0
Training loss: 2.2142263154004307
Validation loss: 2.4527221948842115

Epoch: 5| Step: 1
Training loss: 2.799810903839672
Validation loss: 2.4238723336107415

Epoch: 5| Step: 2
Training loss: 2.6204615824080895
Validation loss: 2.4442125923949356

Epoch: 5| Step: 3
Training loss: 2.715586696481926
Validation loss: 2.457149647858948

Epoch: 5| Step: 4
Training loss: 2.6836515861842147
Validation loss: 2.4396884902239666

Epoch: 5| Step: 5
Training loss: 1.872578392272291
Validation loss: 2.452437511991583

Epoch: 5| Step: 6
Training loss: 2.4664898920723988
Validation loss: 2.4350186405444156

Epoch: 5| Step: 7
Training loss: 2.7371474679196437
Validation loss: 2.4528052625425927

Epoch: 5| Step: 8
Training loss: 2.580341472945857
Validation loss: 2.4366608545942086

Epoch: 5| Step: 9
Training loss: 2.394249456107038
Validation loss: 2.4291841415322413

Epoch: 5| Step: 10
Training loss: 2.953661995963886
Validation loss: 2.429594807010246

Epoch: 124| Step: 0
Training loss: 2.7425928060847444
Validation loss: 2.44191216826289

Epoch: 5| Step: 1
Training loss: 2.648108087719303
Validation loss: 2.42500196460424

Epoch: 5| Step: 2
Training loss: 2.5628486024015906
Validation loss: 2.443187566297462

Epoch: 5| Step: 3
Training loss: 2.135655335525422
Validation loss: 2.4400314257349893

Epoch: 5| Step: 4
Training loss: 2.6530644781715527
Validation loss: 2.4344565804679275

Epoch: 5| Step: 5
Training loss: 2.4920070666584953
Validation loss: 2.444484168471337

Epoch: 5| Step: 6
Training loss: 2.754023556206161
Validation loss: 2.4318343894705485

Epoch: 5| Step: 7
Training loss: 2.838944115529764
Validation loss: 2.4281036064757635

Epoch: 5| Step: 8
Training loss: 2.504772018748565
Validation loss: 2.446096353429966

Epoch: 5| Step: 9
Training loss: 1.9580379493277678
Validation loss: 2.4466378721581012

Epoch: 5| Step: 10
Training loss: 2.855772156258176
Validation loss: 2.4496455035926243

Epoch: 125| Step: 0
Training loss: 2.7213573887758784
Validation loss: 2.4420362814839733

Epoch: 5| Step: 1
Training loss: 2.1749512546382483
Validation loss: 2.4675033228475596

Epoch: 5| Step: 2
Training loss: 2.4142098489870945
Validation loss: 2.4441788083305673

Epoch: 5| Step: 3
Training loss: 3.1276546646772005
Validation loss: 2.4456109971423317

Epoch: 5| Step: 4
Training loss: 2.0511027928729346
Validation loss: 2.4384944381780467

Epoch: 5| Step: 5
Training loss: 2.8955155525297056
Validation loss: 2.4411891494534164

Epoch: 5| Step: 6
Training loss: 2.6678214751628047
Validation loss: 2.4418746977915404

Epoch: 5| Step: 7
Training loss: 2.064713301996114
Validation loss: 2.442173239316796

Epoch: 5| Step: 8
Training loss: 2.319411285782659
Validation loss: 2.446981014468102

Epoch: 5| Step: 9
Training loss: 3.0716692617912185
Validation loss: 2.457973235550448

Epoch: 5| Step: 10
Training loss: 2.1935598089908828
Validation loss: 2.448366481390442

Epoch: 126| Step: 0
Training loss: 2.3543771520270105
Validation loss: 2.4379744539939825

Epoch: 5| Step: 1
Training loss: 2.199901088745231
Validation loss: 2.4275818506928957

Epoch: 5| Step: 2
Training loss: 2.3532376327003255
Validation loss: 2.448005744467093

Epoch: 5| Step: 3
Training loss: 2.8046906452639484
Validation loss: 2.4547577479727782

Epoch: 5| Step: 4
Training loss: 3.0485860079632356
Validation loss: 2.437464920729685

Epoch: 5| Step: 5
Training loss: 2.6884903081230065
Validation loss: 2.4448822092661886

Epoch: 5| Step: 6
Training loss: 2.6260477427364775
Validation loss: 2.4475543167428935

Epoch: 5| Step: 7
Training loss: 2.4451084234618574
Validation loss: 2.42603196595263

Epoch: 5| Step: 8
Training loss: 2.7700227589137065
Validation loss: 2.437730612624779

Epoch: 5| Step: 9
Training loss: 2.1265739894671483
Validation loss: 2.4453315004183716

Epoch: 5| Step: 10
Training loss: 2.4851402207846682
Validation loss: 2.458838707222741

Epoch: 127| Step: 0
Training loss: 2.37998729878731
Validation loss: 2.4463693242542903

Epoch: 5| Step: 1
Training loss: 2.4140453152831913
Validation loss: 2.435392993610645

Epoch: 5| Step: 2
Training loss: 3.3454220593047466
Validation loss: 2.4526774808996255

Epoch: 5| Step: 3
Training loss: 2.654740027794311
Validation loss: 2.4554932726468928

Epoch: 5| Step: 4
Training loss: 2.1669375054713527
Validation loss: 2.434195108854553

Epoch: 5| Step: 5
Training loss: 2.531843986989875
Validation loss: 2.4509681252553204

Epoch: 5| Step: 6
Training loss: 2.702540163488068
Validation loss: 2.4295417513229873

Epoch: 5| Step: 7
Training loss: 1.824431184411246
Validation loss: 2.4379917881312414

Epoch: 5| Step: 8
Training loss: 2.515773318639338
Validation loss: 2.4538166603900304

Epoch: 5| Step: 9
Training loss: 2.5903093428701243
Validation loss: 2.455665095759063

Epoch: 5| Step: 10
Training loss: 2.7382589603229754
Validation loss: 2.446498006994658

Epoch: 128| Step: 0
Training loss: 2.0725438023851694
Validation loss: 2.4271790536060913

Epoch: 5| Step: 1
Training loss: 2.6045851917918275
Validation loss: 2.4350159353173746

Epoch: 5| Step: 2
Training loss: 1.9505244527935133
Validation loss: 2.4405423874888523

Epoch: 5| Step: 3
Training loss: 2.3008663245956833
Validation loss: 2.4365475847173568

Epoch: 5| Step: 4
Training loss: 3.130158248898444
Validation loss: 2.4490308642919114

Epoch: 5| Step: 5
Training loss: 2.112984966161407
Validation loss: 2.45453027463851

Epoch: 5| Step: 6
Training loss: 2.8870031812892782
Validation loss: 2.4291115597743964

Epoch: 5| Step: 7
Training loss: 2.919891990074909
Validation loss: 2.4185753930610074

Epoch: 5| Step: 8
Training loss: 2.0766580322886212
Validation loss: 2.445854738365453

Epoch: 5| Step: 9
Training loss: 2.969040384646875
Validation loss: 2.4536890557504734

Epoch: 5| Step: 10
Training loss: 2.5595654688050318
Validation loss: 2.4226215557563298

Epoch: 129| Step: 0
Training loss: 2.066226367296048
Validation loss: 2.4269892504316393

Epoch: 5| Step: 1
Training loss: 2.644995238763169
Validation loss: 2.437277375375831

Epoch: 5| Step: 2
Training loss: 2.309168503631041
Validation loss: 2.442865306619821

Epoch: 5| Step: 3
Training loss: 2.888069466587577
Validation loss: 2.4463377004586833

Epoch: 5| Step: 4
Training loss: 2.609062130382355
Validation loss: 2.4296050991370333

Epoch: 5| Step: 5
Training loss: 2.4425445588497565
Validation loss: 2.4397173520312405

Epoch: 5| Step: 6
Training loss: 2.9380911374326617
Validation loss: 2.432633172412711

Epoch: 5| Step: 7
Training loss: 2.4064132833195377
Validation loss: 2.4390655046467247

Epoch: 5| Step: 8
Training loss: 2.243857795017379
Validation loss: 2.4424734772555947

Epoch: 5| Step: 9
Training loss: 2.395545533074146
Validation loss: 2.4359790546743882

Epoch: 5| Step: 10
Training loss: 2.947989059655685
Validation loss: 2.434851728356509

Epoch: 130| Step: 0
Training loss: 2.2895338595190675
Validation loss: 2.4294119366942133

Epoch: 5| Step: 1
Training loss: 2.627427749584119
Validation loss: 2.4236290451091302

Epoch: 5| Step: 2
Training loss: 2.3273157338956048
Validation loss: 2.4412452273847802

Epoch: 5| Step: 3
Training loss: 2.452200940298148
Validation loss: 2.4479077693556714

Epoch: 5| Step: 4
Training loss: 2.2047327546598963
Validation loss: 2.4483008598779197

Epoch: 5| Step: 5
Training loss: 2.8495307268319077
Validation loss: 2.4183700323699457

Epoch: 5| Step: 6
Training loss: 2.820834716465966
Validation loss: 2.441059039490415

Epoch: 5| Step: 7
Training loss: 2.682377124400315
Validation loss: 2.4244744457302314

Epoch: 5| Step: 8
Training loss: 2.4649102977347686
Validation loss: 2.4501002228633553

Epoch: 5| Step: 9
Training loss: 2.54182298106647
Validation loss: 2.438654441896217

Epoch: 5| Step: 10
Training loss: 2.735293337696985
Validation loss: 2.452555810709495

Epoch: 131| Step: 0
Training loss: 2.0927620449993225
Validation loss: 2.447413700528079

Epoch: 5| Step: 1
Training loss: 2.490551737589702
Validation loss: 2.4352546659558394

Epoch: 5| Step: 2
Training loss: 2.363240088742787
Validation loss: 2.4309701384519125

Epoch: 5| Step: 3
Training loss: 2.346219808702303
Validation loss: 2.436610471575946

Epoch: 5| Step: 4
Training loss: 2.3661621693282266
Validation loss: 2.4449457221590474

Epoch: 5| Step: 5
Training loss: 3.0075025522628698
Validation loss: 2.4163553173844647

Epoch: 5| Step: 6
Training loss: 2.7279174411116696
Validation loss: 2.4200029656956388

Epoch: 5| Step: 7
Training loss: 2.55296281465195
Validation loss: 2.4279947014674295

Epoch: 5| Step: 8
Training loss: 2.2616038449735445
Validation loss: 2.449638452027229

Epoch: 5| Step: 9
Training loss: 2.8507523731495126
Validation loss: 2.41740541195821

Epoch: 5| Step: 10
Training loss: 2.5577172095574134
Validation loss: 2.4412402182286987

Epoch: 132| Step: 0
Training loss: 2.6399833305872993
Validation loss: 2.43209842596634

Epoch: 5| Step: 1
Training loss: 2.77676518633732
Validation loss: 2.442909762593771

Epoch: 5| Step: 2
Training loss: 2.3696657811079715
Validation loss: 2.4299876010561063

Epoch: 5| Step: 3
Training loss: 2.4243309120443417
Validation loss: 2.4343073139545472

Epoch: 5| Step: 4
Training loss: 2.6673900596607907
Validation loss: 2.416843401125706

Epoch: 5| Step: 5
Training loss: 2.270248536103466
Validation loss: 2.4521375917998127

Epoch: 5| Step: 6
Training loss: 2.7072334599350305
Validation loss: 2.42971078453781

Epoch: 5| Step: 7
Training loss: 2.4975453724142964
Validation loss: 2.4373831930010277

Epoch: 5| Step: 8
Training loss: 2.3556906119601835
Validation loss: 2.429853481340411

Epoch: 5| Step: 9
Training loss: 2.461581966240364
Validation loss: 2.4486129238348013

Epoch: 5| Step: 10
Training loss: 2.6810534140627666
Validation loss: 2.443591812498841

Epoch: 133| Step: 0
Training loss: 3.081916603885982
Validation loss: 2.428387840899026

Epoch: 5| Step: 1
Training loss: 2.48749466325197
Validation loss: 2.4358169733911015

Epoch: 5| Step: 2
Training loss: 2.4504630838387156
Validation loss: 2.4293583504311145

Epoch: 5| Step: 3
Training loss: 2.9031074515182924
Validation loss: 2.4478849689540785

Epoch: 5| Step: 4
Training loss: 2.2783858203586003
Validation loss: 2.420700134416244

Epoch: 5| Step: 5
Training loss: 2.5298720011542324
Validation loss: 2.4469502409192074

Epoch: 5| Step: 6
Training loss: 2.463015693072476
Validation loss: 2.432304781931339

Epoch: 5| Step: 7
Training loss: 2.232366552860566
Validation loss: 2.447442768194553

Epoch: 5| Step: 8
Training loss: 2.9222095318395005
Validation loss: 2.427628092440405

Epoch: 5| Step: 9
Training loss: 2.438892260321988
Validation loss: 2.4285187637986616

Epoch: 5| Step: 10
Training loss: 1.4517545903525642
Validation loss: 2.422898288135434

Epoch: 134| Step: 0
Training loss: 2.8131260493000467
Validation loss: 2.4397841159488034

Epoch: 5| Step: 1
Training loss: 2.443470318880356
Validation loss: 2.4247783521536137

Epoch: 5| Step: 2
Training loss: 2.5149291598465813
Validation loss: 2.439167266548762

Epoch: 5| Step: 3
Training loss: 2.256994607482066
Validation loss: 2.4253603770750773

Epoch: 5| Step: 4
Training loss: 2.2515519405967153
Validation loss: 2.444693664143765

Epoch: 5| Step: 5
Training loss: 2.9141182983619838
Validation loss: 2.428207095758266

Epoch: 5| Step: 6
Training loss: 2.616439120204934
Validation loss: 2.4265988980068864

Epoch: 5| Step: 7
Training loss: 1.9677687121919072
Validation loss: 2.4154037878827648

Epoch: 5| Step: 8
Training loss: 2.7096730562180813
Validation loss: 2.450784024375065

Epoch: 5| Step: 9
Training loss: 2.8589917535813036
Validation loss: 2.418665983582957

Epoch: 5| Step: 10
Training loss: 2.325359570990993
Validation loss: 2.4380062009921364

Epoch: 135| Step: 0
Training loss: 2.6061932015576312
Validation loss: 2.436601579975588

Epoch: 5| Step: 1
Training loss: 1.6223364054254514
Validation loss: 2.4396938099263057

Epoch: 5| Step: 2
Training loss: 2.7061396199681256
Validation loss: 2.42668357985326

Epoch: 5| Step: 3
Training loss: 2.2517258065356454
Validation loss: 2.4261896237082574

Epoch: 5| Step: 4
Training loss: 2.247031478844688
Validation loss: 2.4487633038067886

Epoch: 5| Step: 5
Training loss: 2.525674118096785
Validation loss: 2.44081376326735

Epoch: 5| Step: 6
Training loss: 2.676934521369856
Validation loss: 2.422369680386227

Epoch: 5| Step: 7
Training loss: 2.3459237762777425
Validation loss: 2.422763344773527

Epoch: 5| Step: 8
Training loss: 2.6385610968025848
Validation loss: 2.4459585582444348

Epoch: 5| Step: 9
Training loss: 3.23722279072503
Validation loss: 2.436152828182067

Epoch: 5| Step: 10
Training loss: 2.505243429359778
Validation loss: 2.438827253210619

Epoch: 136| Step: 0
Training loss: 2.8352436656620466
Validation loss: 2.429931783449117

Epoch: 5| Step: 1
Training loss: 1.9766091804872492
Validation loss: 2.44477476893476

Epoch: 5| Step: 2
Training loss: 1.6112128569092836
Validation loss: 2.443788989728282

Epoch: 5| Step: 3
Training loss: 2.9691927930988804
Validation loss: 2.435909879000942

Epoch: 5| Step: 4
Training loss: 2.8384899076356627
Validation loss: 2.4230669182843525

Epoch: 5| Step: 5
Training loss: 2.505033194803588
Validation loss: 2.4604282105436157

Epoch: 5| Step: 6
Training loss: 2.3066340098338673
Validation loss: 2.423993152758393

Epoch: 5| Step: 7
Training loss: 2.5275904256490533
Validation loss: 2.4242653494991484

Epoch: 5| Step: 8
Training loss: 2.424734285878908
Validation loss: 2.4376654451783866

Epoch: 5| Step: 9
Training loss: 2.5411319691370444
Validation loss: 2.4345119262942614

Epoch: 5| Step: 10
Training loss: 2.8890110768455406
Validation loss: 2.433450132111671

Epoch: 137| Step: 0
Training loss: 2.5260235553105286
Validation loss: 2.4525067807280148

Epoch: 5| Step: 1
Training loss: 2.1714852621451013
Validation loss: 2.4303787346045107

Epoch: 5| Step: 2
Training loss: 3.4588239084390873
Validation loss: 2.4106564787391362

Epoch: 5| Step: 3
Training loss: 1.9304617745409691
Validation loss: 2.4623603932807234

Epoch: 5| Step: 4
Training loss: 2.596798220163888
Validation loss: 2.4263978969322713

Epoch: 5| Step: 5
Training loss: 2.577298303476914
Validation loss: 2.436453618604466

Epoch: 5| Step: 6
Training loss: 2.3149875973396017
Validation loss: 2.4405955422691292

Epoch: 5| Step: 7
Training loss: 2.3802863065829185
Validation loss: 2.4176123200634865

Epoch: 5| Step: 8
Training loss: 2.8161919839016036
Validation loss: 2.4340377674078497

Epoch: 5| Step: 9
Training loss: 2.598593452439375
Validation loss: 2.458311964817799

Epoch: 5| Step: 10
Training loss: 1.9633114491761272
Validation loss: 2.444865476060349

Epoch: 138| Step: 0
Training loss: 2.3592469641700413
Validation loss: 2.438280349843097

Epoch: 5| Step: 1
Training loss: 2.245024902783359
Validation loss: 2.4232879676955914

Epoch: 5| Step: 2
Training loss: 2.8057911860993285
Validation loss: 2.4305082950792536

Epoch: 5| Step: 3
Training loss: 2.2988477266913345
Validation loss: 2.410202660140943

Epoch: 5| Step: 4
Training loss: 2.2371640171566867
Validation loss: 2.4566442200875285

Epoch: 5| Step: 5
Training loss: 2.5828542162508485
Validation loss: 2.425720829695301

Epoch: 5| Step: 6
Training loss: 2.893046421674119
Validation loss: 2.4232586124013924

Epoch: 5| Step: 7
Training loss: 2.1228991951065947
Validation loss: 2.4333662630815045

Epoch: 5| Step: 8
Training loss: 2.4432974120652875
Validation loss: 2.4364593594101693

Epoch: 5| Step: 9
Training loss: 2.357202502317604
Validation loss: 2.424693333097526

Epoch: 5| Step: 10
Training loss: 3.0517271873463345
Validation loss: 2.4334610447708744

Epoch: 139| Step: 0
Training loss: 2.3597074362885513
Validation loss: 2.4292386476620234

Epoch: 5| Step: 1
Training loss: 1.9395165562701182
Validation loss: 2.4466660725490943

Epoch: 5| Step: 2
Training loss: 2.9060219295800565
Validation loss: 2.423432244411329

Epoch: 5| Step: 3
Training loss: 2.2626033232474403
Validation loss: 2.411666769327379

Epoch: 5| Step: 4
Training loss: 2.303942233348248
Validation loss: 2.417273038703712

Epoch: 5| Step: 5
Training loss: 3.1365591272235465
Validation loss: 2.4335557226905125

Epoch: 5| Step: 6
Training loss: 2.454570465891657
Validation loss: 2.426533402551212

Epoch: 5| Step: 7
Training loss: 2.909810172375135
Validation loss: 2.426877562632154

Epoch: 5| Step: 8
Training loss: 2.497040427293545
Validation loss: 2.42363749244082

Epoch: 5| Step: 9
Training loss: 2.506087901516903
Validation loss: 2.444770797806174

Epoch: 5| Step: 10
Training loss: 1.9841768661465446
Validation loss: 2.4196972516827713

Epoch: 140| Step: 0
Training loss: 3.5521636387015283
Validation loss: 2.4364873103960005

Epoch: 5| Step: 1
Training loss: 2.6371271565939263
Validation loss: 2.443010556345337

Epoch: 5| Step: 2
Training loss: 2.4444369860255963
Validation loss: 2.4396029084107895

Epoch: 5| Step: 3
Training loss: 2.5829467996988367
Validation loss: 2.430615252236837

Epoch: 5| Step: 4
Training loss: 2.2647287634997046
Validation loss: 2.420235044271573

Epoch: 5| Step: 5
Training loss: 2.490585146863945
Validation loss: 2.443996221557396

Epoch: 5| Step: 6
Training loss: 2.327379452936379
Validation loss: 2.443014664655317

Epoch: 5| Step: 7
Training loss: 2.517625380635582
Validation loss: 2.416852357460894

Epoch: 5| Step: 8
Training loss: 1.8299263450516825
Validation loss: 2.4291339527666254

Epoch: 5| Step: 9
Training loss: 2.0451065461026987
Validation loss: 2.4280636042894543

Epoch: 5| Step: 10
Training loss: 2.4428691905942768
Validation loss: 2.4265310592256806

Epoch: 141| Step: 0
Training loss: 2.3942369090353015
Validation loss: 2.424924408276081

Epoch: 5| Step: 1
Training loss: 2.635043141628966
Validation loss: 2.4107287664586754

Epoch: 5| Step: 2
Training loss: 2.9553992178288135
Validation loss: 2.4339880352549756

Epoch: 5| Step: 3
Training loss: 2.4721441959064614
Validation loss: 2.44549938511121

Epoch: 5| Step: 4
Training loss: 1.8946176410916449
Validation loss: 2.435321543269297

Epoch: 5| Step: 5
Training loss: 2.011070487746103
Validation loss: 2.433411481509586

Epoch: 5| Step: 6
Training loss: 2.6190763575145533
Validation loss: 2.4472808249479425

Epoch: 5| Step: 7
Training loss: 2.797523636432573
Validation loss: 2.4362174194402058

Epoch: 5| Step: 8
Training loss: 2.354358316458094
Validation loss: 2.4218366447214037

Epoch: 5| Step: 9
Training loss: 2.3796677145883725
Validation loss: 2.4180433890752995

Epoch: 5| Step: 10
Training loss: 2.7091083787013854
Validation loss: 2.4130348444540473

Epoch: 142| Step: 0
Training loss: 2.6456064041821508
Validation loss: 2.4252388110402467

Epoch: 5| Step: 1
Training loss: 2.879924702719667
Validation loss: 2.4522459253737607

Epoch: 5| Step: 2
Training loss: 2.400471970721687
Validation loss: 2.423848923179811

Epoch: 5| Step: 3
Training loss: 1.964360445012961
Validation loss: 2.415483913730472

Epoch: 5| Step: 4
Training loss: 2.8644838812932716
Validation loss: 2.4379301509354256

Epoch: 5| Step: 5
Training loss: 3.0074830506466297
Validation loss: 2.4271171412902963

Epoch: 5| Step: 6
Training loss: 2.666937387155547
Validation loss: 2.4419092843241983

Epoch: 5| Step: 7
Training loss: 1.8670656172424003
Validation loss: 2.446335514433118

Epoch: 5| Step: 8
Training loss: 2.323381545644328
Validation loss: 2.4338180535275233

Epoch: 5| Step: 9
Training loss: 1.977950261068263
Validation loss: 2.446167122764682

Epoch: 5| Step: 10
Training loss: 2.611866749213944
Validation loss: 2.4322329320392773

Epoch: 143| Step: 0
Training loss: 2.209233142663716
Validation loss: 2.4246437127326357

Epoch: 5| Step: 1
Training loss: 2.6344359511884714
Validation loss: 2.424361806691271

Epoch: 5| Step: 2
Training loss: 2.632736612465758
Validation loss: 2.4258167655999814

Epoch: 5| Step: 3
Training loss: 2.00816371829346
Validation loss: 2.444658257094401

Epoch: 5| Step: 4
Training loss: 1.9263736208410205
Validation loss: 2.4408202138119983

Epoch: 5| Step: 5
Training loss: 3.0068835124321702
Validation loss: 2.447504817865687

Epoch: 5| Step: 6
Training loss: 2.8594088526321713
Validation loss: 2.457695709541765

Epoch: 5| Step: 7
Training loss: 2.22158664382777
Validation loss: 2.4596004580119573

Epoch: 5| Step: 8
Training loss: 2.372397552947431
Validation loss: 2.422994142702182

Epoch: 5| Step: 9
Training loss: 2.882965331949833
Validation loss: 2.437125270531917

Epoch: 5| Step: 10
Training loss: 2.2882669257604222
Validation loss: 2.4303747468098367

Epoch: 144| Step: 0
Training loss: 2.4434999811224394
Validation loss: 2.421155183107591

Epoch: 5| Step: 1
Training loss: 2.5709530110585064
Validation loss: 2.4237858194454267

Epoch: 5| Step: 2
Training loss: 2.760080760935224
Validation loss: 2.4143687130117395

Epoch: 5| Step: 3
Training loss: 2.0880267363842515
Validation loss: 2.429372300068581

Epoch: 5| Step: 4
Training loss: 3.0568599536925563
Validation loss: 2.419971889336651

Epoch: 5| Step: 5
Training loss: 2.62791399205063
Validation loss: 2.4470242945839193

Epoch: 5| Step: 6
Training loss: 2.682352059187513
Validation loss: 2.4489193589230256

Epoch: 5| Step: 7
Training loss: 2.2216544684351613
Validation loss: 2.4289414009057455

Epoch: 5| Step: 8
Training loss: 2.260576397808663
Validation loss: 2.425946887796362

Epoch: 5| Step: 9
Training loss: 2.458799953680502
Validation loss: 2.417343150694312

Epoch: 5| Step: 10
Training loss: 1.885702297711352
Validation loss: 2.432492333370906

Epoch: 145| Step: 0
Training loss: 2.4470885046015454
Validation loss: 2.4500167574256055

Epoch: 5| Step: 1
Training loss: 2.459247990083004
Validation loss: 2.4353180104363386

Epoch: 5| Step: 2
Training loss: 2.2769871427619486
Validation loss: 2.4250376697477734

Epoch: 5| Step: 3
Training loss: 1.8411087902898338
Validation loss: 2.423517554708014

Epoch: 5| Step: 4
Training loss: 2.4042848761822344
Validation loss: 2.4244070545411613

Epoch: 5| Step: 5
Training loss: 2.304666189321495
Validation loss: 2.4285191522740126

Epoch: 5| Step: 6
Training loss: 2.1132494347622455
Validation loss: 2.4290755540949647

Epoch: 5| Step: 7
Training loss: 2.8046292694762496
Validation loss: 2.430027703443334

Epoch: 5| Step: 8
Training loss: 2.8921827912871922
Validation loss: 2.423331542957707

Epoch: 5| Step: 9
Training loss: 2.8386355509966115
Validation loss: 2.4324231955514763

Epoch: 5| Step: 10
Training loss: 2.719608916609474
Validation loss: 2.4190102275720404

Epoch: 146| Step: 0
Training loss: 2.263411078187589
Validation loss: 2.432507636171424

Epoch: 5| Step: 1
Training loss: 2.100075007416088
Validation loss: 2.439170279853041

Epoch: 5| Step: 2
Training loss: 2.4623933875537354
Validation loss: 2.4353519384743905

Epoch: 5| Step: 3
Training loss: 1.8326980906336847
Validation loss: 2.4563906849787154

Epoch: 5| Step: 4
Training loss: 2.5026908698065835
Validation loss: 2.431392930945617

Epoch: 5| Step: 5
Training loss: 2.934662280172871
Validation loss: 2.4314446973388555

Epoch: 5| Step: 6
Training loss: 2.406170534085047
Validation loss: 2.443269392614304

Epoch: 5| Step: 7
Training loss: 2.879856651500369
Validation loss: 2.434482811645302

Epoch: 5| Step: 8
Training loss: 2.083815048474792
Validation loss: 2.430770416919782

Epoch: 5| Step: 9
Training loss: 2.7415735149694926
Validation loss: 2.4470696073985025

Epoch: 5| Step: 10
Training loss: 2.8470875364458936
Validation loss: 2.430234946236222

Epoch: 147| Step: 0
Training loss: 3.171501250397738
Validation loss: 2.4359275209312634

Epoch: 5| Step: 1
Training loss: 2.591606817341496
Validation loss: 2.4474356704783733

Epoch: 5| Step: 2
Training loss: 2.2729030125036234
Validation loss: 2.4415069840189343

Epoch: 5| Step: 3
Training loss: 1.6773773630627171
Validation loss: 2.430180388608014

Epoch: 5| Step: 4
Training loss: 2.074556887089625
Validation loss: 2.4350143876671613

Epoch: 5| Step: 5
Training loss: 2.5874675361697625
Validation loss: 2.437696148742383

Epoch: 5| Step: 6
Training loss: 2.4125697387735348
Validation loss: 2.433617493327912

Epoch: 5| Step: 7
Training loss: 2.9646472086741475
Validation loss: 2.4316143162462165

Epoch: 5| Step: 8
Training loss: 2.666466576301484
Validation loss: 2.450266551974326

Epoch: 5| Step: 9
Training loss: 1.8943458073102573
Validation loss: 2.4345044818102206

Epoch: 5| Step: 10
Training loss: 2.4926897935912473
Validation loss: 2.4211064342127373

Epoch: 148| Step: 0
Training loss: 2.4142779899144693
Validation loss: 2.4167928245494834

Epoch: 5| Step: 1
Training loss: 2.51487370046869
Validation loss: 2.4214273283133982

Epoch: 5| Step: 2
Training loss: 2.0482641267479065
Validation loss: 2.434079494551726

Epoch: 5| Step: 3
Training loss: 2.5880557140738665
Validation loss: 2.428696720701111

Epoch: 5| Step: 4
Training loss: 2.2868982701396074
Validation loss: 2.4255008153299795

Epoch: 5| Step: 5
Training loss: 2.158245876803658
Validation loss: 2.426690439295199

Epoch: 5| Step: 6
Training loss: 2.8193844776844132
Validation loss: 2.4190903648457707

Epoch: 5| Step: 7
Training loss: 1.8483981362905313
Validation loss: 2.429652828120447

Epoch: 5| Step: 8
Training loss: 2.554994897109458
Validation loss: 2.4155272423942082

Epoch: 5| Step: 9
Training loss: 3.047963109491532
Validation loss: 2.4394448627478575

Epoch: 5| Step: 10
Training loss: 2.762667437696288
Validation loss: 2.4203039550969363

Epoch: 149| Step: 0
Training loss: 1.9222737340633993
Validation loss: 2.433982425018859

Epoch: 5| Step: 1
Training loss: 2.5512465889369174
Validation loss: 2.433346259498174

Epoch: 5| Step: 2
Training loss: 2.0723025564054165
Validation loss: 2.433994666618491

Epoch: 5| Step: 3
Training loss: 2.5821578417518283
Validation loss: 2.4495841517820147

Epoch: 5| Step: 4
Training loss: 1.9592699962752564
Validation loss: 2.3978289941599025

Epoch: 5| Step: 5
Training loss: 1.986103236428087
Validation loss: 2.41088301519621

Epoch: 5| Step: 6
Training loss: 2.4754989699036227
Validation loss: 2.422006688819815

Epoch: 5| Step: 7
Training loss: 3.221156433665028
Validation loss: 2.4474245064079376

Epoch: 5| Step: 8
Training loss: 2.301878792031754
Validation loss: 2.443838484142278

Epoch: 5| Step: 9
Training loss: 2.739382447587929
Validation loss: 2.4189081793883433

Epoch: 5| Step: 10
Training loss: 3.0619623140374292
Validation loss: 2.450872357452801

Epoch: 150| Step: 0
Training loss: 2.4114652321856185
Validation loss: 2.4180313747136113

Epoch: 5| Step: 1
Training loss: 2.1683103000239474
Validation loss: 2.4355451497987595

Epoch: 5| Step: 2
Training loss: 2.6946602294702795
Validation loss: 2.4305980474348803

Epoch: 5| Step: 3
Training loss: 2.519747466043583
Validation loss: 2.4295617355814523

Epoch: 5| Step: 4
Training loss: 2.718969138949236
Validation loss: 2.435382697522036

Epoch: 5| Step: 5
Training loss: 2.196914685516261
Validation loss: 2.4224348592796856

Epoch: 5| Step: 6
Training loss: 2.271465901687564
Validation loss: 2.4094087398122292

Epoch: 5| Step: 7
Training loss: 2.4509794729642453
Validation loss: 2.45190029272594

Epoch: 5| Step: 8
Training loss: 2.6344402952236172
Validation loss: 2.4294482391857235

Epoch: 5| Step: 9
Training loss: 2.6975960166607607
Validation loss: 2.406703721349391

Epoch: 5| Step: 10
Training loss: 2.360625687109999
Validation loss: 2.423351940227413

Epoch: 151| Step: 0
Training loss: 2.430167785471953
Validation loss: 2.4370341448717134

Epoch: 5| Step: 1
Training loss: 2.400929997978719
Validation loss: 2.4308457565705908

Epoch: 5| Step: 2
Training loss: 2.709488451209255
Validation loss: 2.4307784787409994

Epoch: 5| Step: 3
Training loss: 2.4206924012263475
Validation loss: 2.418141845856143

Epoch: 5| Step: 4
Training loss: 2.9388784867094375
Validation loss: 2.4202442417457584

Epoch: 5| Step: 5
Training loss: 2.6138989184740398
Validation loss: 2.4007293097244795

Epoch: 5| Step: 6
Training loss: 2.1734651740675583
Validation loss: 2.4189167990012406

Epoch: 5| Step: 7
Training loss: 2.5723451502157286
Validation loss: 2.430048575159507

Epoch: 5| Step: 8
Training loss: 2.111000169660958
Validation loss: 2.4078431956588005

Epoch: 5| Step: 9
Training loss: 2.0243358606157003
Validation loss: 2.434237638968512

Epoch: 5| Step: 10
Training loss: 2.548397147621064
Validation loss: 2.438680290471812

Epoch: 152| Step: 0
Training loss: 2.651115661267944
Validation loss: 2.437775220076218

Epoch: 5| Step: 1
Training loss: 2.0750844409720552
Validation loss: 2.452383243407026

Epoch: 5| Step: 2
Training loss: 2.4735073173727784
Validation loss: 2.421357784556565

Epoch: 5| Step: 3
Training loss: 2.7868111550443087
Validation loss: 2.42817430316164

Epoch: 5| Step: 4
Training loss: 2.398836481663408
Validation loss: 2.419154740334188

Epoch: 5| Step: 5
Training loss: 2.4995689020398943
Validation loss: 2.4293793170679048

Epoch: 5| Step: 6
Training loss: 2.136843717780678
Validation loss: 2.4243720110592824

Epoch: 5| Step: 7
Training loss: 2.1919051365756186
Validation loss: 2.400828201050921

Epoch: 5| Step: 8
Training loss: 2.312478348914164
Validation loss: 2.427022223821382

Epoch: 5| Step: 9
Training loss: 2.793158165971024
Validation loss: 2.421860102125718

Epoch: 5| Step: 10
Training loss: 2.6504630386029238
Validation loss: 2.4260886383324554

Epoch: 153| Step: 0
Training loss: 2.7630647349607536
Validation loss: 2.421549180972406

Epoch: 5| Step: 1
Training loss: 2.6173201342324544
Validation loss: 2.423601529197589

Epoch: 5| Step: 2
Training loss: 2.6065151967026954
Validation loss: 2.425330839687222

Epoch: 5| Step: 3
Training loss: 2.9664463139968813
Validation loss: 2.423909675181015

Epoch: 5| Step: 4
Training loss: 1.9171955235942153
Validation loss: 2.4210851084465244

Epoch: 5| Step: 5
Training loss: 2.3636791051988246
Validation loss: 2.4402765384395546

Epoch: 5| Step: 6
Training loss: 2.646776787062836
Validation loss: 2.4074473795882296

Epoch: 5| Step: 7
Training loss: 2.8275667767181973
Validation loss: 2.4107217826396807

Epoch: 5| Step: 8
Training loss: 1.844848111834781
Validation loss: 2.4244219135013134

Epoch: 5| Step: 9
Training loss: 2.0908619334440384
Validation loss: 2.4218772694990234

Epoch: 5| Step: 10
Training loss: 2.0706417181858265
Validation loss: 2.4369805957669803

Epoch: 154| Step: 0
Training loss: 2.4480967895035497
Validation loss: 2.423306748846013

Epoch: 5| Step: 1
Training loss: 2.9617748032812288
Validation loss: 2.4308682627783864

Epoch: 5| Step: 2
Training loss: 1.9625221324085702
Validation loss: 2.418977245651083

Epoch: 5| Step: 3
Training loss: 1.7716548211008838
Validation loss: 2.415581965412365

Epoch: 5| Step: 4
Training loss: 2.9970609255208975
Validation loss: 2.4202578668237997

Epoch: 5| Step: 5
Training loss: 2.105220857935636
Validation loss: 2.4172685112084946

Epoch: 5| Step: 6
Training loss: 2.0972759108025616
Validation loss: 2.415812847197444

Epoch: 5| Step: 7
Training loss: 2.9380721488699577
Validation loss: 2.420194175836771

Epoch: 5| Step: 8
Training loss: 2.5544461477520204
Validation loss: 2.424826357990647

Epoch: 5| Step: 9
Training loss: 2.8171792841075862
Validation loss: 2.4209217885692316

Epoch: 5| Step: 10
Training loss: 1.921202751377859
Validation loss: 2.416504885980114

Epoch: 155| Step: 0
Training loss: 2.2330521088604787
Validation loss: 2.4123484511256845

Epoch: 5| Step: 1
Training loss: 2.478500041506861
Validation loss: 2.4242585677949946

Epoch: 5| Step: 2
Training loss: 2.61407595469677
Validation loss: 2.406734832685373

Epoch: 5| Step: 3
Training loss: 2.881007014225343
Validation loss: 2.434077515535542

Epoch: 5| Step: 4
Training loss: 2.3267039628122883
Validation loss: 2.4208951605383593

Epoch: 5| Step: 5
Training loss: 2.9040399167073425
Validation loss: 2.4447698089553542

Epoch: 5| Step: 6
Training loss: 2.299266996924135
Validation loss: 2.4327655876941767

Epoch: 5| Step: 7
Training loss: 1.9297313607980289
Validation loss: 2.4273648391664513

Epoch: 5| Step: 8
Training loss: 2.087439635540426
Validation loss: 2.43104620376557

Epoch: 5| Step: 9
Training loss: 2.502263856125122
Validation loss: 2.4281782903469495

Epoch: 5| Step: 10
Training loss: 2.6075373591876545
Validation loss: 2.4197910993257543

Epoch: 156| Step: 0
Training loss: 1.8801013215134161
Validation loss: 2.4210362511915586

Epoch: 5| Step: 1
Training loss: 2.1961731224956216
Validation loss: 2.4369867519120376

Epoch: 5| Step: 2
Training loss: 2.5561695524581904
Validation loss: 2.4138088850408868

Epoch: 5| Step: 3
Training loss: 2.7754581451256364
Validation loss: 2.4102353313570855

Epoch: 5| Step: 4
Training loss: 2.4691375235121815
Validation loss: 2.4276851240887485

Epoch: 5| Step: 5
Training loss: 2.2426295891341614
Validation loss: 2.4015270644111775

Epoch: 5| Step: 6
Training loss: 2.677309276580384
Validation loss: 2.417846794299202

Epoch: 5| Step: 7
Training loss: 1.9853096510501778
Validation loss: 2.428487675012733

Epoch: 5| Step: 8
Training loss: 2.060647305757486
Validation loss: 2.4124340354185128

Epoch: 5| Step: 9
Training loss: 2.5124189904661174
Validation loss: 2.4039211885843392

Epoch: 5| Step: 10
Training loss: 3.334926478820879
Validation loss: 2.419212505826451

Epoch: 157| Step: 0
Training loss: 2.3815434312626413
Validation loss: 2.4291163786438648

Epoch: 5| Step: 1
Training loss: 2.4520208704621846
Validation loss: 2.441140287092513

Epoch: 5| Step: 2
Training loss: 2.9551237900780163
Validation loss: 2.4226872643710626

Epoch: 5| Step: 3
Training loss: 2.0475339338497207
Validation loss: 2.406736591853398

Epoch: 5| Step: 4
Training loss: 2.268989117424373
Validation loss: 2.4433206476941742

Epoch: 5| Step: 5
Training loss: 2.5894638864636277
Validation loss: 2.4414353597894944

Epoch: 5| Step: 6
Training loss: 2.629467477734072
Validation loss: 2.44787401220215

Epoch: 5| Step: 7
Training loss: 2.1708068416489756
Validation loss: 2.41087651698417

Epoch: 5| Step: 8
Training loss: 2.025170603971233
Validation loss: 2.4202334733992297

Epoch: 5| Step: 9
Training loss: 2.7650354478988524
Validation loss: 2.450953988921702

Epoch: 5| Step: 10
Training loss: 2.3431225763381143
Validation loss: 2.423319102030526

Epoch: 158| Step: 0
Training loss: 2.301046514844183
Validation loss: 2.413251408776911

Epoch: 5| Step: 1
Training loss: 2.620467314357818
Validation loss: 2.433293011680064

Epoch: 5| Step: 2
Training loss: 2.0121544819750485
Validation loss: 2.42034588511937

Epoch: 5| Step: 3
Training loss: 2.4811264007301497
Validation loss: 2.427311976598681

Epoch: 5| Step: 4
Training loss: 2.2954594408630307
Validation loss: 2.4421659100391313

Epoch: 5| Step: 5
Training loss: 2.693230042869019
Validation loss: 2.413452661328434

Epoch: 5| Step: 6
Training loss: 2.1976321308915763
Validation loss: 2.408194343552148

Epoch: 5| Step: 7
Training loss: 2.3773613283809327
Validation loss: 2.4285333474162836

Epoch: 5| Step: 8
Training loss: 2.933592449650178
Validation loss: 2.422611152478467

Epoch: 5| Step: 9
Training loss: 2.1121468875263636
Validation loss: 2.422025685248795

Epoch: 5| Step: 10
Training loss: 2.716127204770181
Validation loss: 2.426287357919102

Epoch: 159| Step: 0
Training loss: 2.009390956405954
Validation loss: 2.4223550808271974

Epoch: 5| Step: 1
Training loss: 2.4470579115512066
Validation loss: 2.3986366474952443

Epoch: 5| Step: 2
Training loss: 2.8021168098198985
Validation loss: 2.4291175100108693

Epoch: 5| Step: 3
Training loss: 2.1566862687758435
Validation loss: 2.420709889828653

Epoch: 5| Step: 4
Training loss: 2.765632069034486
Validation loss: 2.4030880064382316

Epoch: 5| Step: 5
Training loss: 2.5885113126534454
Validation loss: 2.411639256187397

Epoch: 5| Step: 6
Training loss: 2.3295869269559657
Validation loss: 2.4117887728527463

Epoch: 5| Step: 7
Training loss: 2.6779416461082453
Validation loss: 2.4219035659994845

Epoch: 5| Step: 8
Training loss: 2.288105943814584
Validation loss: 2.411626258506073

Epoch: 5| Step: 9
Training loss: 1.9240726218763549
Validation loss: 2.4169228693424234

Epoch: 5| Step: 10
Training loss: 2.5693706421663207
Validation loss: 2.416794222632656

Epoch: 160| Step: 0
Training loss: 3.095632731603051
Validation loss: 2.416355054267982

Epoch: 5| Step: 1
Training loss: 2.8913998776653975
Validation loss: 2.400329740194975

Epoch: 5| Step: 2
Training loss: 2.3445475937789424
Validation loss: 2.4179785689142106

Epoch: 5| Step: 3
Training loss: 2.3301067750229416
Validation loss: 2.419292405392802

Epoch: 5| Step: 4
Training loss: 2.12736065956257
Validation loss: 2.4168332848343903

Epoch: 5| Step: 5
Training loss: 2.2998528931054563
Validation loss: 2.4216122328907383

Epoch: 5| Step: 6
Training loss: 2.1792765130778795
Validation loss: 2.4099446338728554

Epoch: 5| Step: 7
Training loss: 2.1343354876367022
Validation loss: 2.4044349717185414

Epoch: 5| Step: 8
Training loss: 2.4338934210244307
Validation loss: 2.405873063897304

Epoch: 5| Step: 9
Training loss: 2.622743181385038
Validation loss: 2.410916937258809

Epoch: 5| Step: 10
Training loss: 1.9468398628309336
Validation loss: 2.4176529087253122

Epoch: 161| Step: 0
Training loss: 2.8322533250752664
Validation loss: 2.414222200933881

Epoch: 5| Step: 1
Training loss: 2.6387578920565304
Validation loss: 2.4408568250432374

Epoch: 5| Step: 2
Training loss: 2.2074406336991608
Validation loss: 2.420140069806181

Epoch: 5| Step: 3
Training loss: 2.475906718461285
Validation loss: 2.4193693623739216

Epoch: 5| Step: 4
Training loss: 2.1878980002051645
Validation loss: 2.423128673820649

Epoch: 5| Step: 5
Training loss: 2.0324986068138986
Validation loss: 2.4076319368442682

Epoch: 5| Step: 6
Training loss: 1.8641359939859798
Validation loss: 2.412205651912512

Epoch: 5| Step: 7
Training loss: 2.452770426206227
Validation loss: 2.436713159791313

Epoch: 5| Step: 8
Training loss: 2.5318592421531685
Validation loss: 2.4307676167911643

Epoch: 5| Step: 9
Training loss: 2.439083465349216
Validation loss: 2.414374736745854

Epoch: 5| Step: 10
Training loss: 2.982573759537072
Validation loss: 2.4488006981848187

Epoch: 162| Step: 0
Training loss: 2.303787521247174
Validation loss: 2.4301618177634805

Epoch: 5| Step: 1
Training loss: 3.23383050288269
Validation loss: 2.4052316412219645

Epoch: 5| Step: 2
Training loss: 2.071988560943252
Validation loss: 2.424555094444343

Epoch: 5| Step: 3
Training loss: 2.4195908142187914
Validation loss: 2.4353352524232763

Epoch: 5| Step: 4
Training loss: 2.345496378989953
Validation loss: 2.420868135098724

Epoch: 5| Step: 5
Training loss: 2.597621005400001
Validation loss: 2.4169643955615423

Epoch: 5| Step: 6
Training loss: 2.6965128561541367
Validation loss: 2.4186724205895413

Epoch: 5| Step: 7
Training loss: 2.203848861926194
Validation loss: 2.421245339346497

Epoch: 5| Step: 8
Training loss: 1.8642228984011262
Validation loss: 2.4129988921156094

Epoch: 5| Step: 9
Training loss: 2.3191694019158486
Validation loss: 2.4216538554888065

Epoch: 5| Step: 10
Training loss: 2.318373258271141
Validation loss: 2.4182157099292336

Epoch: 163| Step: 0
Training loss: 1.8579473704797933
Validation loss: 2.418940359967633

Epoch: 5| Step: 1
Training loss: 2.557753190440631
Validation loss: 2.4047174483493676

Epoch: 5| Step: 2
Training loss: 1.7820551207138149
Validation loss: 2.430777506345876

Epoch: 5| Step: 3
Training loss: 2.875203996138218
Validation loss: 2.422238829426192

Epoch: 5| Step: 4
Training loss: 2.554739015392292
Validation loss: 2.430149184993029

Epoch: 5| Step: 5
Training loss: 2.5788593517940153
Validation loss: 2.4186925306925695

Epoch: 5| Step: 6
Training loss: 2.789775853330983
Validation loss: 2.4111836715369646

Epoch: 5| Step: 7
Training loss: 2.0712133211192976
Validation loss: 2.414577117195322

Epoch: 5| Step: 8
Training loss: 1.773286048371084
Validation loss: 2.3995405907661893

Epoch: 5| Step: 9
Training loss: 2.6163162831067486
Validation loss: 2.429206700599227

Epoch: 5| Step: 10
Training loss: 2.7304964296086736
Validation loss: 2.4296203589232648

Epoch: 164| Step: 0
Training loss: 2.8669160719616253
Validation loss: 2.4186155044773163

Epoch: 5| Step: 1
Training loss: 2.1664045860044774
Validation loss: 2.419438812822085

Epoch: 5| Step: 2
Training loss: 2.5881734441568196
Validation loss: 2.4214783734409364

Epoch: 5| Step: 3
Training loss: 2.3786867538439354
Validation loss: 2.4259760626168974

Epoch: 5| Step: 4
Training loss: 2.621843620176163
Validation loss: 2.4143023553775307

Epoch: 5| Step: 5
Training loss: 2.0691200132893526
Validation loss: 2.425473145196624

Epoch: 5| Step: 6
Training loss: 2.8997531588504537
Validation loss: 2.419274873163994

Epoch: 5| Step: 7
Training loss: 2.70276141064262
Validation loss: 2.4132753278125647

Epoch: 5| Step: 8
Training loss: 1.8851322430229378
Validation loss: 2.4365290555635

Epoch: 5| Step: 9
Training loss: 2.178789726416029
Validation loss: 2.4438349279546925

Epoch: 5| Step: 10
Training loss: 1.7675390081134381
Validation loss: 2.4281377799650308

Epoch: 165| Step: 0
Training loss: 2.3038311935415234
Validation loss: 2.4249482417738473

Epoch: 5| Step: 1
Training loss: 2.559457321613011
Validation loss: 2.413790237095546

Epoch: 5| Step: 2
Training loss: 2.3460452221790775
Validation loss: 2.4275309222900234

Epoch: 5| Step: 3
Training loss: 2.584465045582621
Validation loss: 2.4083557679336782

Epoch: 5| Step: 4
Training loss: 2.1219138005660056
Validation loss: 2.429720601370512

Epoch: 5| Step: 5
Training loss: 2.216433968436233
Validation loss: 2.4088890839861588

Epoch: 5| Step: 6
Training loss: 2.4128870401576594
Validation loss: 2.4087530679060234

Epoch: 5| Step: 7
Training loss: 2.2869530029004936
Validation loss: 2.411000602054334

Epoch: 5| Step: 8
Training loss: 2.4995943694059966
Validation loss: 2.425569196061573

Epoch: 5| Step: 9
Training loss: 2.5098836076962074
Validation loss: 2.4156447220460344

Epoch: 5| Step: 10
Training loss: 2.5891005426350375
Validation loss: 2.418693747489939

Epoch: 166| Step: 0
Training loss: 2.141356071877959
Validation loss: 2.4212008921801473

Epoch: 5| Step: 1
Training loss: 3.171525005705679
Validation loss: 2.4245564224949048

Epoch: 5| Step: 2
Training loss: 2.4865381192618945
Validation loss: 2.395193652502045

Epoch: 5| Step: 3
Training loss: 2.448644738108572
Validation loss: 2.4150149900245954

Epoch: 5| Step: 4
Training loss: 2.3823273712093562
Validation loss: 2.4271586335745234

Epoch: 5| Step: 5
Training loss: 2.7054226321972195
Validation loss: 2.4136531716569696

Epoch: 5| Step: 6
Training loss: 2.09559663784677
Validation loss: 2.4153503355634185

Epoch: 5| Step: 7
Training loss: 2.3744793371384723
Validation loss: 2.4420618323422785

Epoch: 5| Step: 8
Training loss: 2.402232395475625
Validation loss: 2.4188381434974437

Epoch: 5| Step: 9
Training loss: 1.9210631974293444
Validation loss: 2.4102804125685022

Epoch: 5| Step: 10
Training loss: 1.828936861182078
Validation loss: 2.4129882444260398

Epoch: 167| Step: 0
Training loss: 2.63731375303351
Validation loss: 2.4213325768998644

Epoch: 5| Step: 1
Training loss: 2.454177047716172
Validation loss: 2.414308272030052

Epoch: 5| Step: 2
Training loss: 2.4154927482772495
Validation loss: 2.4362042245682196

Epoch: 5| Step: 3
Training loss: 2.4423215081270646
Validation loss: 2.4119290904293065

Epoch: 5| Step: 4
Training loss: 2.354726392884205
Validation loss: 2.3999632709095686

Epoch: 5| Step: 5
Training loss: 2.629203246799718
Validation loss: 2.4216095238029802

Epoch: 5| Step: 6
Training loss: 2.0188603421221716
Validation loss: 2.411738135984222

Epoch: 5| Step: 7
Training loss: 2.4413716794427387
Validation loss: 2.410293394107718

Epoch: 5| Step: 8
Training loss: 2.356225039403031
Validation loss: 2.41658142146003

Epoch: 5| Step: 9
Training loss: 1.7487008176899297
Validation loss: 2.416525858580704

Epoch: 5| Step: 10
Training loss: 2.677814952659129
Validation loss: 2.4340546392976616

Epoch: 168| Step: 0
Training loss: 2.3061181751815827
Validation loss: 2.3996793500701945

Epoch: 5| Step: 1
Training loss: 2.5387820983991234
Validation loss: 2.4096638956135368

Epoch: 5| Step: 2
Training loss: 2.6814992579840196
Validation loss: 2.4173850546558704

Epoch: 5| Step: 3
Training loss: 2.6058133425025582
Validation loss: 2.4144860409252993

Epoch: 5| Step: 4
Training loss: 2.5245641313288396
Validation loss: 2.4204858443216346

Epoch: 5| Step: 5
Training loss: 2.289643614244152
Validation loss: 2.3925762230918077

Epoch: 5| Step: 6
Training loss: 1.7263676460059212
Validation loss: 2.4209924916622834

Epoch: 5| Step: 7
Training loss: 1.9719719332463823
Validation loss: 2.4138051592868117

Epoch: 5| Step: 8
Training loss: 2.6973240519389234
Validation loss: 2.4115270126755415

Epoch: 5| Step: 9
Training loss: 2.5745961400326927
Validation loss: 2.418927199090853

Epoch: 5| Step: 10
Training loss: 2.4112537426323764
Validation loss: 2.4416928511212346

Epoch: 169| Step: 0
Training loss: 2.1122885468422274
Validation loss: 2.4213700079283527

Epoch: 5| Step: 1
Training loss: 2.7235619066267827
Validation loss: 2.415772487616109

Epoch: 5| Step: 2
Training loss: 2.920490773384137
Validation loss: 2.4158331158746247

Epoch: 5| Step: 3
Training loss: 2.2266054383537934
Validation loss: 2.430674747722443

Epoch: 5| Step: 4
Training loss: 2.357472340976763
Validation loss: 2.4286486863370036

Epoch: 5| Step: 5
Training loss: 2.235146769370513
Validation loss: 2.414651920564374

Epoch: 5| Step: 6
Training loss: 2.006900684212531
Validation loss: 2.436541389584807

Epoch: 5| Step: 7
Training loss: 2.042638806747371
Validation loss: 2.40030785281584

Epoch: 5| Step: 8
Training loss: 1.9062723877639622
Validation loss: 2.421460647413425

Epoch: 5| Step: 9
Training loss: 3.154051061919621
Validation loss: 2.4083529955003167

Epoch: 5| Step: 10
Training loss: 2.1644447622531775
Validation loss: 2.4022381049403405

Epoch: 170| Step: 0
Training loss: 2.3033809773237204
Validation loss: 2.411306677626437

Epoch: 5| Step: 1
Training loss: 2.7451653898682884
Validation loss: 2.4016001894822114

Epoch: 5| Step: 2
Training loss: 2.5285268193113084
Validation loss: 2.3930646541733407

Epoch: 5| Step: 3
Training loss: 2.241707142271855
Validation loss: 2.418289811329922

Epoch: 5| Step: 4
Training loss: 2.771847895303728
Validation loss: 2.4115237564662904

Epoch: 5| Step: 5
Training loss: 2.5015367553072405
Validation loss: 2.413156214699664

Epoch: 5| Step: 6
Training loss: 2.271022707074362
Validation loss: 2.42313285392694

Epoch: 5| Step: 7
Training loss: 2.5382273077993527
Validation loss: 2.4174546299808632

Epoch: 5| Step: 8
Training loss: 2.376787015303071
Validation loss: 2.428219474689983

Epoch: 5| Step: 9
Training loss: 1.9948658012246412
Validation loss: 2.4263694889743848

Epoch: 5| Step: 10
Training loss: 1.8458492806508533
Validation loss: 2.3908473654099303

Epoch: 171| Step: 0
Training loss: 2.8798869518768995
Validation loss: 2.4143890532741383

Epoch: 5| Step: 1
Training loss: 2.0786240057459127
Validation loss: 2.4159756104868713

Epoch: 5| Step: 2
Training loss: 2.39047609750606
Validation loss: 2.4016615896790503

Epoch: 5| Step: 3
Training loss: 2.49030273343676
Validation loss: 2.409348700039759

Epoch: 5| Step: 4
Training loss: 2.4993359637520904
Validation loss: 2.394018409408959

Epoch: 5| Step: 5
Training loss: 2.188961521735852
Validation loss: 2.421640017009759

Epoch: 5| Step: 6
Training loss: 2.1361143383613
Validation loss: 2.409836653961102

Epoch: 5| Step: 7
Training loss: 2.935738055411735
Validation loss: 2.416757930550029

Epoch: 5| Step: 8
Training loss: 2.0691737083943083
Validation loss: 2.4053784504547586

Epoch: 5| Step: 9
Training loss: 1.7931685990796689
Validation loss: 2.4219366636705844

Epoch: 5| Step: 10
Training loss: 2.421108592191921
Validation loss: 2.4010938534145687

Epoch: 172| Step: 0
Training loss: 1.9026105564391986
Validation loss: 2.4123495786668063

Epoch: 5| Step: 1
Training loss: 2.0430589586695374
Validation loss: 2.4108296264047357

Epoch: 5| Step: 2
Training loss: 2.211512622235764
Validation loss: 2.4185724134564492

Epoch: 5| Step: 3
Training loss: 2.0088669201307017
Validation loss: 2.4330670634453275

Epoch: 5| Step: 4
Training loss: 2.768798214598099
Validation loss: 2.408441934252803

Epoch: 5| Step: 5
Training loss: 2.2836614953040386
Validation loss: 2.402883022770444

Epoch: 5| Step: 6
Training loss: 2.7254525360078268
Validation loss: 2.4171131744879752

Epoch: 5| Step: 7
Training loss: 2.2953859030540396
Validation loss: 2.389782322682

Epoch: 5| Step: 8
Training loss: 2.620452847984394
Validation loss: 2.4302592635345786

Epoch: 5| Step: 9
Training loss: 2.557041029032916
Validation loss: 2.3957902106371884

Epoch: 5| Step: 10
Training loss: 2.684033131618076
Validation loss: 2.399003174100962

Epoch: 173| Step: 0
Training loss: 2.7350173631636494
Validation loss: 2.4170626576495033

Epoch: 5| Step: 1
Training loss: 2.3406853539461427
Validation loss: 2.415633720941817

Epoch: 5| Step: 2
Training loss: 2.055472452471366
Validation loss: 2.402583953670033

Epoch: 5| Step: 3
Training loss: 2.092501823397153
Validation loss: 2.4141396369720565

Epoch: 5| Step: 4
Training loss: 2.3621741862400656
Validation loss: 2.3871652725106522

Epoch: 5| Step: 5
Training loss: 2.633987119453468
Validation loss: 2.404493940056493

Epoch: 5| Step: 6
Training loss: 2.1063515930124845
Validation loss: 2.4092829191956313

Epoch: 5| Step: 7
Training loss: 2.0475907566697296
Validation loss: 2.408964240639183

Epoch: 5| Step: 8
Training loss: 2.4162375518588686
Validation loss: 2.4058941041365345

Epoch: 5| Step: 9
Training loss: 2.8363105801753017
Validation loss: 2.4148007580960305

Epoch: 5| Step: 10
Training loss: 2.2159843938877044
Validation loss: 2.4228264534473225

Epoch: 174| Step: 0
Training loss: 2.2393674761224953
Validation loss: 2.420004660132306

Epoch: 5| Step: 1
Training loss: 2.6560746078927964
Validation loss: 2.423326713642793

Epoch: 5| Step: 2
Training loss: 1.9589970322995882
Validation loss: 2.4184934181475692

Epoch: 5| Step: 3
Training loss: 2.5289697619674696
Validation loss: 2.409747891156731

Epoch: 5| Step: 4
Training loss: 2.507960995469699
Validation loss: 2.401898772691382

Epoch: 5| Step: 5
Training loss: 2.4426813076668834
Validation loss: 2.408450966004699

Epoch: 5| Step: 6
Training loss: 2.33033565559357
Validation loss: 2.419155375109845

Epoch: 5| Step: 7
Training loss: 2.4526668047782665
Validation loss: 2.4175836413246965

Epoch: 5| Step: 8
Training loss: 1.9657387486766156
Validation loss: 2.4154190577856367

Epoch: 5| Step: 9
Training loss: 2.702095320730646
Validation loss: 2.427355174396747

Epoch: 5| Step: 10
Training loss: 2.0395651011549902
Validation loss: 2.3949626722725297

Epoch: 175| Step: 0
Training loss: 2.677773818289686
Validation loss: 2.3736685035865124

Epoch: 5| Step: 1
Training loss: 2.345010443950894
Validation loss: 2.4012845471982356

Epoch: 5| Step: 2
Training loss: 2.2703977627899783
Validation loss: 2.4010513245321587

Epoch: 5| Step: 3
Training loss: 2.615413964439148
Validation loss: 2.439491249539997

Epoch: 5| Step: 4
Training loss: 2.7635781855254624
Validation loss: 2.413678804176037

Epoch: 5| Step: 5
Training loss: 2.1542448589170196
Validation loss: 2.404459448653539

Epoch: 5| Step: 6
Training loss: 1.9796491202207207
Validation loss: 2.4032238033699542

Epoch: 5| Step: 7
Training loss: 2.2650343552567067
Validation loss: 2.407847161678481

Epoch: 5| Step: 8
Training loss: 2.433319909132764
Validation loss: 2.4149820066176737

Epoch: 5| Step: 9
Training loss: 2.2200781916689385
Validation loss: 2.403386941348631

Epoch: 5| Step: 10
Training loss: 2.221753411379801
Validation loss: 2.3891614851973437

Epoch: 176| Step: 0
Training loss: 2.033438222816706
Validation loss: 2.4112084212568403

Epoch: 5| Step: 1
Training loss: 2.9691205245237096
Validation loss: 2.4203708228956384

Epoch: 5| Step: 2
Training loss: 2.579703477778824
Validation loss: 2.394469332920365

Epoch: 5| Step: 3
Training loss: 1.9473782643575406
Validation loss: 2.4121062694348723

Epoch: 5| Step: 4
Training loss: 2.0767692790185306
Validation loss: 2.404112595431585

Epoch: 5| Step: 5
Training loss: 2.521162016907447
Validation loss: 2.408702943018906

Epoch: 5| Step: 6
Training loss: 2.120549984073668
Validation loss: 2.4014661080705495

Epoch: 5| Step: 7
Training loss: 2.769947015413956
Validation loss: 2.396025272151602

Epoch: 5| Step: 8
Training loss: 2.3715329211284617
Validation loss: 2.4139351282030033

Epoch: 5| Step: 9
Training loss: 2.4069688392083353
Validation loss: 2.3976055194815005

Epoch: 5| Step: 10
Training loss: 1.9597297383840238
Validation loss: 2.40316775776901

Epoch: 177| Step: 0
Training loss: 2.7855356180094373
Validation loss: 2.4223798878545724

Epoch: 5| Step: 1
Training loss: 2.162164730476452
Validation loss: 2.401001038858354

Epoch: 5| Step: 2
Training loss: 2.1925371213443343
Validation loss: 2.397648266661749

Epoch: 5| Step: 3
Training loss: 2.088966713237938
Validation loss: 2.4352941710487346

Epoch: 5| Step: 4
Training loss: 2.106391322434832
Validation loss: 2.4010909332615755

Epoch: 5| Step: 5
Training loss: 2.531713655180979
Validation loss: 2.3881248479827746

Epoch: 5| Step: 6
Training loss: 1.8853639907925206
Validation loss: 2.422503833461881

Epoch: 5| Step: 7
Training loss: 2.2375283564470285
Validation loss: 2.4240042100510597

Epoch: 5| Step: 8
Training loss: 2.5361694756326636
Validation loss: 2.4154316412932912

Epoch: 5| Step: 9
Training loss: 2.4726950113593995
Validation loss: 2.4219370812521666

Epoch: 5| Step: 10
Training loss: 2.791942744102471
Validation loss: 2.4057224218964173

Epoch: 178| Step: 0
Training loss: 2.9140202823475025
Validation loss: 2.3996743844842707

Epoch: 5| Step: 1
Training loss: 2.241597699471708
Validation loss: 2.4010406921938534

Epoch: 5| Step: 2
Training loss: 1.9043175955403153
Validation loss: 2.415477611507607

Epoch: 5| Step: 3
Training loss: 2.3971790901666132
Validation loss: 2.4087101681723455

Epoch: 5| Step: 4
Training loss: 2.306739230071166
Validation loss: 2.4134773808758596

Epoch: 5| Step: 5
Training loss: 2.270938299243766
Validation loss: 2.406258551490908

Epoch: 5| Step: 6
Training loss: 2.35853955970115
Validation loss: 2.398918981878887

Epoch: 5| Step: 7
Training loss: 2.376158983633656
Validation loss: 2.414077861219442

Epoch: 5| Step: 8
Training loss: 2.4121609701592206
Validation loss: 2.412698896564652

Epoch: 5| Step: 9
Training loss: 2.4567015021799024
Validation loss: 2.3937581341943504

Epoch: 5| Step: 10
Training loss: 2.087802239198541
Validation loss: 2.4155536945195335

Epoch: 179| Step: 0
Training loss: 2.109218224244844
Validation loss: 2.392652965762217

Epoch: 5| Step: 1
Training loss: 2.58133622364928
Validation loss: 2.410163812769559

Epoch: 5| Step: 2
Training loss: 2.736690129711135
Validation loss: 2.4214241187676704

Epoch: 5| Step: 3
Training loss: 1.723090638214851
Validation loss: 2.3973679716011977

Epoch: 5| Step: 4
Training loss: 2.444043595026666
Validation loss: 2.398913049712411

Epoch: 5| Step: 5
Training loss: 2.5099337629112166
Validation loss: 2.39906669274263

Epoch: 5| Step: 6
Training loss: 2.036995728231229
Validation loss: 2.40218165961562

Epoch: 5| Step: 7
Training loss: 2.4707453908810715
Validation loss: 2.4178229485863483

Epoch: 5| Step: 8
Training loss: 2.46727264238057
Validation loss: 2.3973317254941087

Epoch: 5| Step: 9
Training loss: 2.142458833278932
Validation loss: 2.4099591575592654

Epoch: 5| Step: 10
Training loss: 2.4334484565187418
Validation loss: 2.416292698036453

Epoch: 180| Step: 0
Training loss: 2.826329794309428
Validation loss: 2.389302531828218

Epoch: 5| Step: 1
Training loss: 2.1338952079577203
Validation loss: 2.398119844323897

Epoch: 5| Step: 2
Training loss: 2.0147666582118724
Validation loss: 2.3838897158337478

Epoch: 5| Step: 3
Training loss: 2.402732854826224
Validation loss: 2.417078047530721

Epoch: 5| Step: 4
Training loss: 2.8014398755428855
Validation loss: 2.405107578292299

Epoch: 5| Step: 5
Training loss: 2.3676590150887344
Validation loss: 2.40655667870761

Epoch: 5| Step: 6
Training loss: 2.423915667801134
Validation loss: 2.3846738837184622

Epoch: 5| Step: 7
Training loss: 2.2904169547617648
Validation loss: 2.3948464399881275

Epoch: 5| Step: 8
Training loss: 1.840160043017247
Validation loss: 2.3892969180629526

Epoch: 5| Step: 9
Training loss: 2.0914012203505195
Validation loss: 2.395203998796448

Epoch: 5| Step: 10
Training loss: 2.2713335402077792
Validation loss: 2.3867445471846893

Epoch: 181| Step: 0
Training loss: 2.857021009026799
Validation loss: 2.3965844117106494

Epoch: 5| Step: 1
Training loss: 2.4478646996575586
Validation loss: 2.4228639000175622

Epoch: 5| Step: 2
Training loss: 2.601263538858797
Validation loss: 2.422885053529259

Epoch: 5| Step: 3
Training loss: 1.6982857082728537
Validation loss: 2.393831024302301

Epoch: 5| Step: 4
Training loss: 2.5138763605394563
Validation loss: 2.430086518096206

Epoch: 5| Step: 5
Training loss: 2.164034295845089
Validation loss: 2.3981439452827527

Epoch: 5| Step: 6
Training loss: 2.325452871208827
Validation loss: 2.3908571514877517

Epoch: 5| Step: 7
Training loss: 1.8686037956890893
Validation loss: 2.4133699934944306

Epoch: 5| Step: 8
Training loss: 2.781493444182333
Validation loss: 2.433504591677602

Epoch: 5| Step: 9
Training loss: 1.813414638860981
Validation loss: 2.406889350161047

Epoch: 5| Step: 10
Training loss: 2.2182098590852197
Validation loss: 2.390351268740966

Epoch: 182| Step: 0
Training loss: 2.063809181626364
Validation loss: 2.413436139885216

Epoch: 5| Step: 1
Training loss: 2.822924220977097
Validation loss: 2.4090373389595974

Epoch: 5| Step: 2
Training loss: 2.216502165845161
Validation loss: 2.4126499544917306

Epoch: 5| Step: 3
Training loss: 2.702688016464953
Validation loss: 2.4036892520255297

Epoch: 5| Step: 4
Training loss: 1.9222307573740274
Validation loss: 2.406114219368553

Epoch: 5| Step: 5
Training loss: 2.7540320401513
Validation loss: 2.4173985707105405

Epoch: 5| Step: 6
Training loss: 1.6939033241834338
Validation loss: 2.4084590993423904

Epoch: 5| Step: 7
Training loss: 1.9921203601967674
Validation loss: 2.4098778086819443

Epoch: 5| Step: 8
Training loss: 2.6909713504475374
Validation loss: 2.405075911876182

Epoch: 5| Step: 9
Training loss: 2.371366230675429
Validation loss: 2.4034790291198918

Epoch: 5| Step: 10
Training loss: 2.012682637522256
Validation loss: 2.408428662785032

Epoch: 183| Step: 0
Training loss: 2.3960371400696228
Validation loss: 2.415223259895033

Epoch: 5| Step: 1
Training loss: 2.1926211764908663
Validation loss: 2.4144004120405103

Epoch: 5| Step: 2
Training loss: 2.3543775570913534
Validation loss: 2.395852049709438

Epoch: 5| Step: 3
Training loss: 2.0454024048141797
Validation loss: 2.3720210617185353

Epoch: 5| Step: 4
Training loss: 2.1628326336590873
Validation loss: 2.421616375386011

Epoch: 5| Step: 5
Training loss: 2.241506865334958
Validation loss: 2.3695786272308887

Epoch: 5| Step: 6
Training loss: 2.3556827175956876
Validation loss: 2.4159889434259796

Epoch: 5| Step: 7
Training loss: 2.152294123747307
Validation loss: 2.410214343374456

Epoch: 5| Step: 8
Training loss: 2.743075148328726
Validation loss: 2.3838865788829886

Epoch: 5| Step: 9
Training loss: 2.527971098450944
Validation loss: 2.4007772368981217

Epoch: 5| Step: 10
Training loss: 2.1940324519981793
Validation loss: 2.410424017154251

Epoch: 184| Step: 0
Training loss: 2.072891069059296
Validation loss: 2.4047827965292923

Epoch: 5| Step: 1
Training loss: 2.7801005527781055
Validation loss: 2.3661796519644587

Epoch: 5| Step: 2
Training loss: 1.7242848835176825
Validation loss: 2.4172724532796495

Epoch: 5| Step: 3
Training loss: 1.9814230521405456
Validation loss: 2.4095241573826045

Epoch: 5| Step: 4
Training loss: 2.5474153659227436
Validation loss: 2.4115101628348317

Epoch: 5| Step: 5
Training loss: 2.707199818040287
Validation loss: 2.381566502957605

Epoch: 5| Step: 6
Training loss: 2.1140459126274957
Validation loss: 2.398661924263043

Epoch: 5| Step: 7
Training loss: 2.5349510356681177
Validation loss: 2.3939506376742665

Epoch: 5| Step: 8
Training loss: 2.225226607195128
Validation loss: 2.385646653327028

Epoch: 5| Step: 9
Training loss: 2.4675987553183227
Validation loss: 2.3980414474515124

Epoch: 5| Step: 10
Training loss: 2.131898229914745
Validation loss: 2.3736072724782287

Epoch: 185| Step: 0
Training loss: 2.751347818399204
Validation loss: 2.4030239862594382

Epoch: 5| Step: 1
Training loss: 1.973081456049192
Validation loss: 2.39066992180039

Epoch: 5| Step: 2
Training loss: 2.152782471627755
Validation loss: 2.409777451993306

Epoch: 5| Step: 3
Training loss: 1.6303790635802133
Validation loss: 2.4167304371817053

Epoch: 5| Step: 4
Training loss: 2.7305639247651765
Validation loss: 2.401481878661117

Epoch: 5| Step: 5
Training loss: 2.11081177558036
Validation loss: 2.3984627093901265

Epoch: 5| Step: 6
Training loss: 1.9286208815011772
Validation loss: 2.4278270228664964

Epoch: 5| Step: 7
Training loss: 2.678339315984185
Validation loss: 2.3912111974222814

Epoch: 5| Step: 8
Training loss: 2.701102674457042
Validation loss: 2.4039561036161943

Epoch: 5| Step: 9
Training loss: 2.2096048928832976
Validation loss: 2.3866006134416575

Epoch: 5| Step: 10
Training loss: 2.1782616768073813
Validation loss: 2.3966344996340916

Epoch: 186| Step: 0
Training loss: 2.7344807631610615
Validation loss: 2.3875752389128886

Epoch: 5| Step: 1
Training loss: 2.144284760531312
Validation loss: 2.3955496564350804

Epoch: 5| Step: 2
Training loss: 2.2337110906882782
Validation loss: 2.385170667356785

Epoch: 5| Step: 3
Training loss: 1.897882827920529
Validation loss: 2.396810342215249

Epoch: 5| Step: 4
Training loss: 1.970595025083518
Validation loss: 2.4021986591989055

Epoch: 5| Step: 5
Training loss: 2.2217651082479506
Validation loss: 2.402206949240205

Epoch: 5| Step: 6
Training loss: 2.5354430707958286
Validation loss: 2.407024750506368

Epoch: 5| Step: 7
Training loss: 2.135439194971358
Validation loss: 2.4097399706867235

Epoch: 5| Step: 8
Training loss: 1.7810954645949932
Validation loss: 2.40001835841674

Epoch: 5| Step: 9
Training loss: 2.782135468876632
Validation loss: 2.375015727208584

Epoch: 5| Step: 10
Training loss: 2.8078214939251476
Validation loss: 2.384646797174297

Epoch: 187| Step: 0
Training loss: 1.8941721782388763
Validation loss: 2.377666244035189

Epoch: 5| Step: 1
Training loss: 2.2098603876816365
Validation loss: 2.3772410024305346

Epoch: 5| Step: 2
Training loss: 2.0112479538607815
Validation loss: 2.3788418366003685

Epoch: 5| Step: 3
Training loss: 2.1037342521091666
Validation loss: 2.4027120179050665

Epoch: 5| Step: 4
Training loss: 2.274484819201821
Validation loss: 2.40872453167257

Epoch: 5| Step: 5
Training loss: 2.5443778872865934
Validation loss: 2.4107363130759256

Epoch: 5| Step: 6
Training loss: 2.1540125419726186
Validation loss: 2.405792452786759

Epoch: 5| Step: 7
Training loss: 3.1202139252902508
Validation loss: 2.3940760152269553

Epoch: 5| Step: 8
Training loss: 2.6759278194631495
Validation loss: 2.4067909826916853

Epoch: 5| Step: 9
Training loss: 2.1315640439088175
Validation loss: 2.376263210210737

Epoch: 5| Step: 10
Training loss: 2.0147286721329136
Validation loss: 2.3965894377188453

Epoch: 188| Step: 0
Training loss: 2.3233977590829387
Validation loss: 2.40918972313354

Epoch: 5| Step: 1
Training loss: 1.9755306641581893
Validation loss: 2.3986031609788485

Epoch: 5| Step: 2
Training loss: 2.5674193079673575
Validation loss: 2.4112286116855945

Epoch: 5| Step: 3
Training loss: 1.5955999520797894
Validation loss: 2.4108276017183927

Epoch: 5| Step: 4
Training loss: 2.1068079268903714
Validation loss: 2.3787080189252645

Epoch: 5| Step: 5
Training loss: 2.2083272993857044
Validation loss: 2.41304276367079

Epoch: 5| Step: 6
Training loss: 2.3773478898768587
Validation loss: 2.4045962310781785

Epoch: 5| Step: 7
Training loss: 2.8150878021206873
Validation loss: 2.396068700185508

Epoch: 5| Step: 8
Training loss: 2.4651491970385218
Validation loss: 2.3867979586190304

Epoch: 5| Step: 9
Training loss: 2.6223453540861876
Validation loss: 2.4044061528655405

Epoch: 5| Step: 10
Training loss: 2.112627813321222
Validation loss: 2.412978020602465

Epoch: 189| Step: 0
Training loss: 1.9382659259576311
Validation loss: 2.3776599688028157

Epoch: 5| Step: 1
Training loss: 2.345021017667693
Validation loss: 2.3969702727951945

Epoch: 5| Step: 2
Training loss: 2.701256431420122
Validation loss: 2.3857173422991704

Epoch: 5| Step: 3
Training loss: 2.1936400209338975
Validation loss: 2.4157699693647294

Epoch: 5| Step: 4
Training loss: 2.0832696777791404
Validation loss: 2.3974538490012343

Epoch: 5| Step: 5
Training loss: 2.387246630740667
Validation loss: 2.3628281036419465

Epoch: 5| Step: 6
Training loss: 2.3142316366198368
Validation loss: 2.397943052724356

Epoch: 5| Step: 7
Training loss: 1.8175198986533083
Validation loss: 2.3833798313259065

Epoch: 5| Step: 8
Training loss: 2.1378733080304277
Validation loss: 2.383851098897485

Epoch: 5| Step: 9
Training loss: 2.484182098385103
Validation loss: 2.390952152046773

Epoch: 5| Step: 10
Training loss: 2.7496479849496547
Validation loss: 2.395805798158786

Epoch: 190| Step: 0
Training loss: 2.326205697762608
Validation loss: 2.3797208329364765

Epoch: 5| Step: 1
Training loss: 2.174364707507943
Validation loss: 2.3734122637749184

Epoch: 5| Step: 2
Training loss: 2.494416677900523
Validation loss: 2.3867416395507597

Epoch: 5| Step: 3
Training loss: 1.8448879157241729
Validation loss: 2.408156315436147

Epoch: 5| Step: 4
Training loss: 1.7301628582984179
Validation loss: 2.3885420608854697

Epoch: 5| Step: 5
Training loss: 2.5106829321333204
Validation loss: 2.400166928474753

Epoch: 5| Step: 6
Training loss: 2.30872965507858
Validation loss: 2.3882824104150053

Epoch: 5| Step: 7
Training loss: 2.8428353316325445
Validation loss: 2.4049169275454414

Epoch: 5| Step: 8
Training loss: 2.2744125949302907
Validation loss: 2.4207249065102445

Epoch: 5| Step: 9
Training loss: 2.0998784802108985
Validation loss: 2.3838572287823765

Epoch: 5| Step: 10
Training loss: 2.445055378323785
Validation loss: 2.4003569536198692

Epoch: 191| Step: 0
Training loss: 1.8522347304345115
Validation loss: 2.4040950964608565

Epoch: 5| Step: 1
Training loss: 2.4820639939830422
Validation loss: 2.384771143006474

Epoch: 5| Step: 2
Training loss: 2.407220223749261
Validation loss: 2.4156199816957704

Epoch: 5| Step: 3
Training loss: 2.1318513709788345
Validation loss: 2.3943102246346655

Epoch: 5| Step: 4
Training loss: 2.00665059591218
Validation loss: 2.4074469483121157

Epoch: 5| Step: 5
Training loss: 2.6251818276056085
Validation loss: 2.377461171758158

Epoch: 5| Step: 6
Training loss: 2.1182823587802866
Validation loss: 2.3559159335462865

Epoch: 5| Step: 7
Training loss: 2.1081818773754986
Validation loss: 2.3870915205259413

Epoch: 5| Step: 8
Training loss: 2.4096275503987385
Validation loss: 2.3938662632031944

Epoch: 5| Step: 9
Training loss: 2.283455918727089
Validation loss: 2.3887113294682765

Epoch: 5| Step: 10
Training loss: 2.7271977862263226
Validation loss: 2.3986860657323694

Epoch: 192| Step: 0
Training loss: 2.6766445131758814
Validation loss: 2.3946092703923925

Epoch: 5| Step: 1
Training loss: 2.011747667419591
Validation loss: 2.398863902255009

Epoch: 5| Step: 2
Training loss: 2.185107203108055
Validation loss: 2.422216648928492

Epoch: 5| Step: 3
Training loss: 2.6486234796541197
Validation loss: 2.4130355275857887

Epoch: 5| Step: 4
Training loss: 2.2405766140064083
Validation loss: 2.349843397182909

Epoch: 5| Step: 5
Training loss: 2.593390566268688
Validation loss: 2.3977603141404447

Epoch: 5| Step: 6
Training loss: 1.8511989574620666
Validation loss: 2.386785003422998

Epoch: 5| Step: 7
Training loss: 2.691040279936093
Validation loss: 2.4101036035313577

Epoch: 5| Step: 8
Training loss: 1.8305518840906696
Validation loss: 2.4040651751651727

Epoch: 5| Step: 9
Training loss: 2.2649478294983134
Validation loss: 2.4144367804388334

Epoch: 5| Step: 10
Training loss: 1.8266095784355427
Validation loss: 2.386883105207938

Epoch: 193| Step: 0
Training loss: 2.592003843528347
Validation loss: 2.4009985392818214

Epoch: 5| Step: 1
Training loss: 2.2077460557748827
Validation loss: 2.3951442157245446

Epoch: 5| Step: 2
Training loss: 2.159129114132395
Validation loss: 2.397047273711191

Epoch: 5| Step: 3
Training loss: 2.121387215505253
Validation loss: 2.429455210063089

Epoch: 5| Step: 4
Training loss: 2.0713171482655017
Validation loss: 2.3794943227132626

Epoch: 5| Step: 5
Training loss: 2.3175606898454553
Validation loss: 2.398508813510046

Epoch: 5| Step: 6
Training loss: 2.2450172564686537
Validation loss: 2.3970980765336223

Epoch: 5| Step: 7
Training loss: 2.160301493337043
Validation loss: 2.397495731684137

Epoch: 5| Step: 8
Training loss: 1.977622369965939
Validation loss: 2.384822459962678

Epoch: 5| Step: 9
Training loss: 2.7131877431620497
Validation loss: 2.3998388469591774

Epoch: 5| Step: 10
Training loss: 2.4213354678767764
Validation loss: 2.3788229608839644

Epoch: 194| Step: 0
Training loss: 2.4500737743558614
Validation loss: 2.377401419682399

Epoch: 5| Step: 1
Training loss: 2.3793147195244893
Validation loss: 2.3855817814407376

Epoch: 5| Step: 2
Training loss: 2.514833598310465
Validation loss: 2.3847358417346833

Epoch: 5| Step: 3
Training loss: 2.3593467053870447
Validation loss: 2.3887517523968818

Epoch: 5| Step: 4
Training loss: 2.436526568760513
Validation loss: 2.36846898671532

Epoch: 5| Step: 5
Training loss: 2.0748587732627963
Validation loss: 2.3760303276631487

Epoch: 5| Step: 6
Training loss: 2.1059548236243644
Validation loss: 2.386821758768345

Epoch: 5| Step: 7
Training loss: 1.9561177023128014
Validation loss: 2.365402820895497

Epoch: 5| Step: 8
Training loss: 1.7570770759763588
Validation loss: 2.3761626313956095

Epoch: 5| Step: 9
Training loss: 2.31440512048054
Validation loss: 2.4027863701769423

Epoch: 5| Step: 10
Training loss: 2.6011757319717237
Validation loss: 2.3755441591690287

Epoch: 195| Step: 0
Training loss: 2.2923778701914856
Validation loss: 2.373818719562076

Epoch: 5| Step: 1
Training loss: 2.1093169027734273
Validation loss: 2.3948487822021725

Epoch: 5| Step: 2
Training loss: 1.757084131865591
Validation loss: 2.3813012204130466

Epoch: 5| Step: 3
Training loss: 2.34283073199402
Validation loss: 2.346916727762562

Epoch: 5| Step: 4
Training loss: 2.264406600087272
Validation loss: 2.417283206181978

Epoch: 5| Step: 5
Training loss: 2.2407497355324666
Validation loss: 2.3793582058231575

Epoch: 5| Step: 6
Training loss: 2.319267474318484
Validation loss: 2.3926770789297365

Epoch: 5| Step: 7
Training loss: 2.9649473230015113
Validation loss: 2.387533389438229

Epoch: 5| Step: 8
Training loss: 2.371897930290747
Validation loss: 2.3735407203467522

Epoch: 5| Step: 9
Training loss: 1.8736108084111982
Validation loss: 2.3963269603059674

Epoch: 5| Step: 10
Training loss: 2.2766248245452827
Validation loss: 2.3860569499551287

Epoch: 196| Step: 0
Training loss: 1.944525134213778
Validation loss: 2.3870832864609786

Epoch: 5| Step: 1
Training loss: 2.3758143986224303
Validation loss: 2.374267086159016

Epoch: 5| Step: 2
Training loss: 1.5579179335931914
Validation loss: 2.3824595458416074

Epoch: 5| Step: 3
Training loss: 2.1047572701379917
Validation loss: 2.4086231482537426

Epoch: 5| Step: 4
Training loss: 2.220534560651193
Validation loss: 2.3613978993714766

Epoch: 5| Step: 5
Training loss: 1.8538319003327033
Validation loss: 2.373678067260657

Epoch: 5| Step: 6
Training loss: 2.420143837713153
Validation loss: 2.4099910278776235

Epoch: 5| Step: 7
Training loss: 2.690541786032411
Validation loss: 2.369681615121056

Epoch: 5| Step: 8
Training loss: 2.3230942001127843
Validation loss: 2.400343324517341

Epoch: 5| Step: 9
Training loss: 2.9272545236143213
Validation loss: 2.3847346237358042

Epoch: 5| Step: 10
Training loss: 2.1226883825089073
Validation loss: 2.414477701730961

Epoch: 197| Step: 0
Training loss: 1.780374880865096
Validation loss: 2.389485435505637

Epoch: 5| Step: 1
Training loss: 1.8202091564263783
Validation loss: 2.3792992189881317

Epoch: 5| Step: 2
Training loss: 2.592528457706128
Validation loss: 2.3959040778916414

Epoch: 5| Step: 3
Training loss: 2.496199675746616
Validation loss: 2.380371087288048

Epoch: 5| Step: 4
Training loss: 2.062392838902023
Validation loss: 2.3890302576028426

Epoch: 5| Step: 5
Training loss: 2.0596198577492544
Validation loss: 2.3964900981589596

Epoch: 5| Step: 6
Training loss: 2.3317608189291446
Validation loss: 2.377108911860165

Epoch: 5| Step: 7
Training loss: 1.8882496942827727
Validation loss: 2.3648838050891676

Epoch: 5| Step: 8
Training loss: 2.666012763276852
Validation loss: 2.376230648561153

Epoch: 5| Step: 9
Training loss: 1.944515202763737
Validation loss: 2.376614665623613

Epoch: 5| Step: 10
Training loss: 2.85064615654533
Validation loss: 2.3961070078749187

Epoch: 198| Step: 0
Training loss: 2.277533652499792
Validation loss: 2.3860294874791226

Epoch: 5| Step: 1
Training loss: 2.4670017667778747
Validation loss: 2.3753005767494995

Epoch: 5| Step: 2
Training loss: 2.2077787770627033
Validation loss: 2.408890603723077

Epoch: 5| Step: 3
Training loss: 2.231514974295573
Validation loss: 2.3928304353449663

Epoch: 5| Step: 4
Training loss: 2.404194536053083
Validation loss: 2.37953405540468

Epoch: 5| Step: 5
Training loss: 2.6993357830374087
Validation loss: 2.3774475467305636

Epoch: 5| Step: 6
Training loss: 2.1471433868784633
Validation loss: 2.389164000377052

Epoch: 5| Step: 7
Training loss: 1.6323799399936438
Validation loss: 2.3955681162272375

Epoch: 5| Step: 8
Training loss: 2.0719009927123193
Validation loss: 2.384635942259245

Epoch: 5| Step: 9
Training loss: 2.358457576413023
Validation loss: 2.388621900765836

Epoch: 5| Step: 10
Training loss: 2.2263762814466324
Validation loss: 2.3861324319935022

Epoch: 199| Step: 0
Training loss: 2.205266682593609
Validation loss: 2.388596895010856

Epoch: 5| Step: 1
Training loss: 2.433291788486839
Validation loss: 2.37464301886566

Epoch: 5| Step: 2
Training loss: 1.8631058776345066
Validation loss: 2.4157878369010857

Epoch: 5| Step: 3
Training loss: 2.1880689698460096
Validation loss: 2.407112811761753

Epoch: 5| Step: 4
Training loss: 2.5278038773452693
Validation loss: 2.389475547786453

Epoch: 5| Step: 5
Training loss: 2.1524681429216845
Validation loss: 2.3906588256081482

Epoch: 5| Step: 6
Training loss: 1.7877248902667935
Validation loss: 2.4165044154763136

Epoch: 5| Step: 7
Training loss: 2.3039347825687955
Validation loss: 2.397261339431849

Epoch: 5| Step: 8
Training loss: 3.07938572195179
Validation loss: 2.4026542136817315

Epoch: 5| Step: 9
Training loss: 1.8865880190336737
Validation loss: 2.399799859596022

Epoch: 5| Step: 10
Training loss: 1.8786471182241788
Validation loss: 2.3842551138548322

Epoch: 200| Step: 0
Training loss: 2.364900296067332
Validation loss: 2.384305693568085

Epoch: 5| Step: 1
Training loss: 1.7819405271322408
Validation loss: 2.370654811121518

Epoch: 5| Step: 2
Training loss: 1.626973494348404
Validation loss: 2.3878905740683907

Epoch: 5| Step: 3
Training loss: 2.0356071104552536
Validation loss: 2.387703713022857

Epoch: 5| Step: 4
Training loss: 2.245087877690369
Validation loss: 2.40087386679772

Epoch: 5| Step: 5
Training loss: 2.6364939501971687
Validation loss: 2.3783956571424794

Epoch: 5| Step: 6
Training loss: 2.8845680907847426
Validation loss: 2.387048487637736

Epoch: 5| Step: 7
Training loss: 2.170398457241389
Validation loss: 2.405359493082098

Epoch: 5| Step: 8
Training loss: 2.019798748075424
Validation loss: 2.3606855358379266

Epoch: 5| Step: 9
Training loss: 2.680365207043145
Validation loss: 2.384129890551406

Epoch: 5| Step: 10
Training loss: 1.656240931072238
Validation loss: 2.3756375711856608

Epoch: 201| Step: 0
Training loss: 2.138363945797127
Validation loss: 2.3781999210631164

Epoch: 5| Step: 1
Training loss: 2.3583515296836124
Validation loss: 2.377165156101171

Epoch: 5| Step: 2
Training loss: 2.1646787131048426
Validation loss: 2.3658421912984644

Epoch: 5| Step: 3
Training loss: 2.2623624264530893
Validation loss: 2.350400694441432

Epoch: 5| Step: 4
Training loss: 2.222666976715109
Validation loss: 2.3570647359249715

Epoch: 5| Step: 5
Training loss: 2.7041321570531345
Validation loss: 2.3751675061501074

Epoch: 5| Step: 6
Training loss: 1.996274339005605
Validation loss: 2.3763194631406503

Epoch: 5| Step: 7
Training loss: 2.06526415005962
Validation loss: 2.4049956791131795

Epoch: 5| Step: 8
Training loss: 2.404421222858248
Validation loss: 2.37598300618356

Epoch: 5| Step: 9
Training loss: 1.9932689050428367
Validation loss: 2.385301372147196

Epoch: 5| Step: 10
Training loss: 2.030143906138816
Validation loss: 2.374455902908616

Epoch: 202| Step: 0
Training loss: 1.6321174565944576
Validation loss: 2.378428197236254

Epoch: 5| Step: 1
Training loss: 2.4952026113679313
Validation loss: 2.3833087987287365

Epoch: 5| Step: 2
Training loss: 2.3326505161470195
Validation loss: 2.3719064889017596

Epoch: 5| Step: 3
Training loss: 1.6393210906204667
Validation loss: 2.4265516968940206

Epoch: 5| Step: 4
Training loss: 2.484786665296176
Validation loss: 2.3955410019706598

Epoch: 5| Step: 5
Training loss: 2.680456824013472
Validation loss: 2.37445239396233

Epoch: 5| Step: 6
Training loss: 2.096117417766701
Validation loss: 2.3771620690518485

Epoch: 5| Step: 7
Training loss: 2.0094839775469886
Validation loss: 2.42409490227247

Epoch: 5| Step: 8
Training loss: 2.1784305571633014
Validation loss: 2.369453550655604

Epoch: 5| Step: 9
Training loss: 2.113144734427847
Validation loss: 2.3971944932700344

Epoch: 5| Step: 10
Training loss: 2.7017803927219597
Validation loss: 2.382433268606523

Epoch: 203| Step: 0
Training loss: 2.0934586962845283
Validation loss: 2.380445615583721

Epoch: 5| Step: 1
Training loss: 2.15485370042025
Validation loss: 2.392452830486364

Epoch: 5| Step: 2
Training loss: 2.5428890561509148
Validation loss: 2.389726500375128

Epoch: 5| Step: 3
Training loss: 2.4881193147243157
Validation loss: 2.3722072841706168

Epoch: 5| Step: 4
Training loss: 1.9062640080171789
Validation loss: 2.3596700999773947

Epoch: 5| Step: 5
Training loss: 2.601002859229159
Validation loss: 2.3944780993935075

Epoch: 5| Step: 6
Training loss: 1.7911065431104856
Validation loss: 2.3686587169848115

Epoch: 5| Step: 7
Training loss: 2.380897928478098
Validation loss: 2.3899309455230937

Epoch: 5| Step: 8
Training loss: 2.143027078611436
Validation loss: 2.394929807695665

Epoch: 5| Step: 9
Training loss: 1.8994662162465505
Validation loss: 2.3802801998129013

Epoch: 5| Step: 10
Training loss: 2.313738826186837
Validation loss: 2.3990699559750737

Epoch: 204| Step: 0
Training loss: 2.1486488931867456
Validation loss: 2.3951052065311917

Epoch: 5| Step: 1
Training loss: 1.777196186353673
Validation loss: 2.3735938424217764

Epoch: 5| Step: 2
Training loss: 1.6819328027699108
Validation loss: 2.3972369911201117

Epoch: 5| Step: 3
Training loss: 2.2406389690905426
Validation loss: 2.369775297173063

Epoch: 5| Step: 4
Training loss: 2.41657183450129
Validation loss: 2.373221279136183

Epoch: 5| Step: 5
Training loss: 2.2159777232747735
Validation loss: 2.344954350635431

Epoch: 5| Step: 6
Training loss: 2.2927825176248664
Validation loss: 2.375491660780433

Epoch: 5| Step: 7
Training loss: 2.799656427966571
Validation loss: 2.3803079822588864

Epoch: 5| Step: 8
Training loss: 2.355522800413752
Validation loss: 2.3780500594571516

Epoch: 5| Step: 9
Training loss: 2.3673648578940774
Validation loss: 2.3787039418124962

Epoch: 5| Step: 10
Training loss: 1.919988931782927
Validation loss: 2.3721764570482273

Epoch: 205| Step: 0
Training loss: 1.6461510009658764
Validation loss: 2.3717646855359

Epoch: 5| Step: 1
Training loss: 2.197784010031135
Validation loss: 2.3900492617826234

Epoch: 5| Step: 2
Training loss: 2.3919714832009458
Validation loss: 2.3943729724046143

Epoch: 5| Step: 3
Training loss: 1.7293476408354564
Validation loss: 2.3848802373822027

Epoch: 5| Step: 4
Training loss: 2.6887263671460646
Validation loss: 2.3817375966115955

Epoch: 5| Step: 5
Training loss: 2.2924155196636846
Validation loss: 2.383405686162349

Epoch: 5| Step: 6
Training loss: 2.123170177034091
Validation loss: 2.371513277011292

Epoch: 5| Step: 7
Training loss: 2.5347610424210196
Validation loss: 2.3950338227183474

Epoch: 5| Step: 8
Training loss: 2.336838564388474
Validation loss: 2.368722294704855

Epoch: 5| Step: 9
Training loss: 2.0383355609739184
Validation loss: 2.3687360169995872

Epoch: 5| Step: 10
Training loss: 2.191669958230606
Validation loss: 2.4045056595575165

Epoch: 206| Step: 0
Training loss: 2.4346736269381677
Validation loss: 2.3794156569439333

Epoch: 5| Step: 1
Training loss: 2.076542761072358
Validation loss: 2.382501830921417

Epoch: 5| Step: 2
Training loss: 1.8559203551978318
Validation loss: 2.385050612851838

Epoch: 5| Step: 3
Training loss: 2.1765921980234566
Validation loss: 2.376679693818387

Epoch: 5| Step: 4
Training loss: 2.7914281904552483
Validation loss: 2.3938540600321363

Epoch: 5| Step: 5
Training loss: 2.039029526717952
Validation loss: 2.3752423261580424

Epoch: 5| Step: 6
Training loss: 2.144502010736748
Validation loss: 2.3612392258877506

Epoch: 5| Step: 7
Training loss: 2.2695293590649395
Validation loss: 2.372757044154023

Epoch: 5| Step: 8
Training loss: 1.7403270555470787
Validation loss: 2.3632827968960157

Epoch: 5| Step: 9
Training loss: 2.317962586819305
Validation loss: 2.361276915754835

Epoch: 5| Step: 10
Training loss: 2.0939310479529984
Validation loss: 2.3860360893539845

Epoch: 207| Step: 0
Training loss: 1.9134919230876517
Validation loss: 2.3953406606264807

Epoch: 5| Step: 1
Training loss: 1.9774453826190637
Validation loss: 2.419362577542196

Epoch: 5| Step: 2
Training loss: 2.050293724603189
Validation loss: 2.364495441696464

Epoch: 5| Step: 3
Training loss: 1.948171942264331
Validation loss: 2.363099414322106

Epoch: 5| Step: 4
Training loss: 2.822196014496208
Validation loss: 2.379277476476581

Epoch: 5| Step: 5
Training loss: 2.006425073893475
Validation loss: 2.3746851111632736

Epoch: 5| Step: 6
Training loss: 2.496322788481977
Validation loss: 2.3731610249306825

Epoch: 5| Step: 7
Training loss: 2.3680048875307214
Validation loss: 2.388734322272791

Epoch: 5| Step: 8
Training loss: 2.0425736754633954
Validation loss: 2.3725237888130013

Epoch: 5| Step: 9
Training loss: 2.3307574449809194
Validation loss: 2.3647892620025264

Epoch: 5| Step: 10
Training loss: 2.215435292202313
Validation loss: 2.3775379672312607

Epoch: 208| Step: 0
Training loss: 2.3017877472398505
Validation loss: 2.3713037400865553

Epoch: 5| Step: 1
Training loss: 2.611891669306674
Validation loss: 2.3727036748241774

Epoch: 5| Step: 2
Training loss: 2.2170957389053845
Validation loss: 2.400461629511272

Epoch: 5| Step: 3
Training loss: 2.080175205884474
Validation loss: 2.3742970612106205

Epoch: 5| Step: 4
Training loss: 2.5032097238972937
Validation loss: 2.363152087119454

Epoch: 5| Step: 5
Training loss: 2.2323163559106516
Validation loss: 2.3755444996504127

Epoch: 5| Step: 6
Training loss: 2.2560523540969233
Validation loss: 2.394099120344219

Epoch: 5| Step: 7
Training loss: 1.9528730306219266
Validation loss: 2.366426576071206

Epoch: 5| Step: 8
Training loss: 1.713322340389466
Validation loss: 2.351804678901777

Epoch: 5| Step: 9
Training loss: 2.1497622203193436
Validation loss: 2.3612476206467146

Epoch: 5| Step: 10
Training loss: 2.0334261461348104
Validation loss: 2.3681648072898174

Epoch: 209| Step: 0
Training loss: 2.0613467142099315
Validation loss: 2.371736044213126

Epoch: 5| Step: 1
Training loss: 1.6792920733904735
Validation loss: 2.357992888634649

Epoch: 5| Step: 2
Training loss: 1.7404082240340628
Validation loss: 2.3789560759429564

Epoch: 5| Step: 3
Training loss: 2.414676921392299
Validation loss: 2.365304531628803

Epoch: 5| Step: 4
Training loss: 2.0476331398775764
Validation loss: 2.377666471539007

Epoch: 5| Step: 5
Training loss: 1.7949374159844753
Validation loss: 2.3967731239462093

Epoch: 5| Step: 6
Training loss: 2.6331005448247686
Validation loss: 2.374412800812435

Epoch: 5| Step: 7
Training loss: 2.1069600162197504
Validation loss: 2.3934439651847113

Epoch: 5| Step: 8
Training loss: 2.992057777560904
Validation loss: 2.3522209957369546

Epoch: 5| Step: 9
Training loss: 1.9611958489318275
Validation loss: 2.3683317934292067

Epoch: 5| Step: 10
Training loss: 2.2425317799029094
Validation loss: 2.3722077294183195

Epoch: 210| Step: 0
Training loss: 2.829428525182032
Validation loss: 2.3934529956921047

Epoch: 5| Step: 1
Training loss: 2.286358691385459
Validation loss: 2.389451710769174

Epoch: 5| Step: 2
Training loss: 1.9942124790020421
Validation loss: 2.3816136295343457

Epoch: 5| Step: 3
Training loss: 2.2927824136382986
Validation loss: 2.3616942272169794

Epoch: 5| Step: 4
Training loss: 2.1615425062833546
Validation loss: 2.3706449508399547

Epoch: 5| Step: 5
Training loss: 1.9689426025154015
Validation loss: 2.401729161172425

Epoch: 5| Step: 6
Training loss: 2.0284213985402917
Validation loss: 2.356315014400469

Epoch: 5| Step: 7
Training loss: 2.0979931097362967
Validation loss: 2.4106188547687344

Epoch: 5| Step: 8
Training loss: 2.341683455799594
Validation loss: 2.34215599081059

Epoch: 5| Step: 9
Training loss: 1.5225231067426155
Validation loss: 2.3679669599309485

Epoch: 5| Step: 10
Training loss: 2.226393522576502
Validation loss: 2.383145132908819

Epoch: 211| Step: 0
Training loss: 2.07784997941545
Validation loss: 2.379957188584607

Epoch: 5| Step: 1
Training loss: 1.7438449929454098
Validation loss: 2.363893262304339

Epoch: 5| Step: 2
Training loss: 2.582940707569963
Validation loss: 2.3962869978833172

Epoch: 5| Step: 3
Training loss: 1.8197572049431834
Validation loss: 2.3583125500046043

Epoch: 5| Step: 4
Training loss: 1.8850727364751096
Validation loss: 2.381366112019283

Epoch: 5| Step: 5
Training loss: 2.4787934179923163
Validation loss: 2.3991679849880208

Epoch: 5| Step: 6
Training loss: 1.5755492236729485
Validation loss: 2.3968578279341655

Epoch: 5| Step: 7
Training loss: 2.3028600656828235
Validation loss: 2.34899100327838

Epoch: 5| Step: 8
Training loss: 2.128899082556742
Validation loss: 2.3533877812920276

Epoch: 5| Step: 9
Training loss: 2.363533952301693
Validation loss: 2.373481417194159

Epoch: 5| Step: 10
Training loss: 2.9083031405946618
Validation loss: 2.4156996334263883

Epoch: 212| Step: 0
Training loss: 2.914273251846124
Validation loss: 2.3792752288375625

Epoch: 5| Step: 1
Training loss: 2.4753401474383314
Validation loss: 2.365449184629817

Epoch: 5| Step: 2
Training loss: 2.112122618244095
Validation loss: 2.3555782894450026

Epoch: 5| Step: 3
Training loss: 2.3290703409529496
Validation loss: 2.351809167821353

Epoch: 5| Step: 4
Training loss: 1.9121482775026235
Validation loss: 2.3857079837763946

Epoch: 5| Step: 5
Training loss: 1.9703716078626612
Validation loss: 2.37376243328983

Epoch: 5| Step: 6
Training loss: 1.8463393956406426
Validation loss: 2.3775272728720713

Epoch: 5| Step: 7
Training loss: 1.3238821586506826
Validation loss: 2.3957606189994682

Epoch: 5| Step: 8
Training loss: 2.3117091914498547
Validation loss: 2.393501778694346

Epoch: 5| Step: 9
Training loss: 2.107479458818529
Validation loss: 2.3789160825055133

Epoch: 5| Step: 10
Training loss: 2.338061639558974
Validation loss: 2.3904987644767246

Epoch: 213| Step: 0
Training loss: 2.0745382691460206
Validation loss: 2.359575204029741

Epoch: 5| Step: 1
Training loss: 1.843488642385212
Validation loss: 2.3836473304019474

Epoch: 5| Step: 2
Training loss: 1.933599052036607
Validation loss: 2.3884017625662377

Epoch: 5| Step: 3
Training loss: 2.208042365524643
Validation loss: 2.3727848687685764

Epoch: 5| Step: 4
Training loss: 2.0595902233508876
Validation loss: 2.347371428201292

Epoch: 5| Step: 5
Training loss: 2.234073965427669
Validation loss: 2.3774676842037015

Epoch: 5| Step: 6
Training loss: 2.3535641487152885
Validation loss: 2.3482317399063426

Epoch: 5| Step: 7
Training loss: 2.4455425897639995
Validation loss: 2.345480108452421

Epoch: 5| Step: 8
Training loss: 2.5788371634163876
Validation loss: 2.3616642930276255

Epoch: 5| Step: 9
Training loss: 2.130723649972584
Validation loss: 2.35689380039187

Epoch: 5| Step: 10
Training loss: 2.0199145427416596
Validation loss: 2.3512337455883956

Epoch: 214| Step: 0
Training loss: 1.7716836869770065
Validation loss: 2.3939817045867664

Epoch: 5| Step: 1
Training loss: 1.8664242768724446
Validation loss: 2.3856598333868217

Epoch: 5| Step: 2
Training loss: 1.9036737762640812
Validation loss: 2.3683519088250926

Epoch: 5| Step: 3
Training loss: 2.037615266125527
Validation loss: 2.3716669577250036

Epoch: 5| Step: 4
Training loss: 2.820416900308646
Validation loss: 2.3798342911015085

Epoch: 5| Step: 5
Training loss: 2.31681925547828
Validation loss: 2.356030787795241

Epoch: 5| Step: 6
Training loss: 2.0771392549456174
Validation loss: 2.4008676009696455

Epoch: 5| Step: 7
Training loss: 2.0951875904011428
Validation loss: 2.3880695344269145

Epoch: 5| Step: 8
Training loss: 2.1584151081908125
Validation loss: 2.3506976053720927

Epoch: 5| Step: 9
Training loss: 2.1658999357982514
Validation loss: 2.356861039124078

Epoch: 5| Step: 10
Training loss: 2.3732139497191054
Validation loss: 2.3886850544661646

Epoch: 215| Step: 0
Training loss: 2.1949094354806893
Validation loss: 2.3651044689714222

Epoch: 5| Step: 1
Training loss: 1.7170682135014015
Validation loss: 2.3779075173946085

Epoch: 5| Step: 2
Training loss: 2.157811028261118
Validation loss: 2.3503393310918703

Epoch: 5| Step: 3
Training loss: 2.934768868074792
Validation loss: 2.3710988143631924

Epoch: 5| Step: 4
Training loss: 2.2475487814288577
Validation loss: 2.3680598199260836

Epoch: 5| Step: 5
Training loss: 2.116426563411882
Validation loss: 2.3631912912651067

Epoch: 5| Step: 6
Training loss: 1.9241185932368732
Validation loss: 2.3473773743091786

Epoch: 5| Step: 7
Training loss: 2.2713738477717738
Validation loss: 2.397463663182059

Epoch: 5| Step: 8
Training loss: 2.1970530496129856
Validation loss: 2.362903246560566

Epoch: 5| Step: 9
Training loss: 1.71513534534549
Validation loss: 2.3364841810446055

Epoch: 5| Step: 10
Training loss: 2.0265810786964025
Validation loss: 2.3687243175009898

Epoch: 216| Step: 0
Training loss: 2.096283134694463
Validation loss: 2.3761361733962763

Epoch: 5| Step: 1
Training loss: 1.9078348794260318
Validation loss: 2.3722346418930633

Epoch: 5| Step: 2
Training loss: 1.2024499559993087
Validation loss: 2.382164319183609

Epoch: 5| Step: 3
Training loss: 2.84552181506739
Validation loss: 2.32654846244911

Epoch: 5| Step: 4
Training loss: 2.323439934016725
Validation loss: 2.3728736637662884

Epoch: 5| Step: 5
Training loss: 2.3181344544235136
Validation loss: 2.367910362416959

Epoch: 5| Step: 6
Training loss: 1.632216130180292
Validation loss: 2.3730358773570885

Epoch: 5| Step: 7
Training loss: 2.479869571916935
Validation loss: 2.3442575065215636

Epoch: 5| Step: 8
Training loss: 2.030159055745627
Validation loss: 2.3567790648885962

Epoch: 5| Step: 9
Training loss: 2.33540149267498
Validation loss: 2.3680771543123478

Epoch: 5| Step: 10
Training loss: 2.1509014635061483
Validation loss: 2.35956552995664

Epoch: 217| Step: 0
Training loss: 2.120409663763443
Validation loss: 2.3686917891278996

Epoch: 5| Step: 1
Training loss: 1.9669900323899363
Validation loss: 2.3537763017292113

Epoch: 5| Step: 2
Training loss: 1.7957283673805688
Validation loss: 2.380785904695546

Epoch: 5| Step: 3
Training loss: 1.9233523017613476
Validation loss: 2.4028311857120954

Epoch: 5| Step: 4
Training loss: 2.3907713003832223
Validation loss: 2.382731729527408

Epoch: 5| Step: 5
Training loss: 1.5328434807838083
Validation loss: 2.3661187460440947

Epoch: 5| Step: 6
Training loss: 1.6832405303956128
Validation loss: 2.3747864504683367

Epoch: 5| Step: 7
Training loss: 2.4616012404762593
Validation loss: 2.3803988040544874

Epoch: 5| Step: 8
Training loss: 2.7976761847848133
Validation loss: 2.3667199670727768

Epoch: 5| Step: 9
Training loss: 2.071086120015828
Validation loss: 2.399620575911498

Epoch: 5| Step: 10
Training loss: 2.3357192738131034
Validation loss: 2.3470991077316334

Epoch: 218| Step: 0
Training loss: 2.7859176729173885
Validation loss: 2.372264907930905

Epoch: 5| Step: 1
Training loss: 2.0751553304971937
Validation loss: 2.3895200357633652

Epoch: 5| Step: 2
Training loss: 1.9244002832360576
Validation loss: 2.3473320149926096

Epoch: 5| Step: 3
Training loss: 2.2563074500887885
Validation loss: 2.389837094022701

Epoch: 5| Step: 4
Training loss: 1.8072572058068197
Validation loss: 2.3802873125290693

Epoch: 5| Step: 5
Training loss: 1.9870289754228352
Validation loss: 2.397456915803393

Epoch: 5| Step: 6
Training loss: 2.4031905503875817
Validation loss: 2.358035001456002

Epoch: 5| Step: 7
Training loss: 1.5923454228810605
Validation loss: 2.3520495185313135

Epoch: 5| Step: 8
Training loss: 2.2227134227941723
Validation loss: 2.4092313868998034

Epoch: 5| Step: 9
Training loss: 1.9616276108001154
Validation loss: 2.354250583428952

Epoch: 5| Step: 10
Training loss: 2.2672719296930017
Validation loss: 2.3662548607144234

Epoch: 219| Step: 0
Training loss: 2.1262648688799466
Validation loss: 2.36779518900563

Epoch: 5| Step: 1
Training loss: 2.474498574682547
Validation loss: 2.3688016229508198

Epoch: 5| Step: 2
Training loss: 1.8900308857770776
Validation loss: 2.37127434235606

Epoch: 5| Step: 3
Training loss: 2.3083620939517293
Validation loss: 2.3846802146720427

Epoch: 5| Step: 4
Training loss: 2.42347339674867
Validation loss: 2.350571880212229

Epoch: 5| Step: 5
Training loss: 2.4058336170153645
Validation loss: 2.3959340556312325

Epoch: 5| Step: 6
Training loss: 1.6879972502338014
Validation loss: 2.350445611700987

Epoch: 5| Step: 7
Training loss: 1.5164583412432793
Validation loss: 2.3640109069476414

Epoch: 5| Step: 8
Training loss: 2.123430345535857
Validation loss: 2.3641686440213627

Epoch: 5| Step: 9
Training loss: 2.3896344694626506
Validation loss: 2.3677977609869614

Epoch: 5| Step: 10
Training loss: 1.8009252925037418
Validation loss: 2.3525367500843686

Epoch: 220| Step: 0
Training loss: 2.049672202908011
Validation loss: 2.375257572008615

Epoch: 5| Step: 1
Training loss: 2.2376516365369703
Validation loss: 2.3488157790377167

Epoch: 5| Step: 2
Training loss: 1.6328960196567148
Validation loss: 2.33952288886264

Epoch: 5| Step: 3
Training loss: 1.7309135054911962
Validation loss: 2.3629173270478168

Epoch: 5| Step: 4
Training loss: 2.914272924603519
Validation loss: 2.372714824191814

Epoch: 5| Step: 5
Training loss: 2.0834557560872855
Validation loss: 2.3721684954262323

Epoch: 5| Step: 6
Training loss: 2.125280025207708
Validation loss: 2.379452843958669

Epoch: 5| Step: 7
Training loss: 2.2913489265958304
Validation loss: 2.3789769840788977

Epoch: 5| Step: 8
Training loss: 1.9256198033872798
Validation loss: 2.339720745155168

Epoch: 5| Step: 9
Training loss: 2.5248285480869996
Validation loss: 2.3425828046845205

Epoch: 5| Step: 10
Training loss: 1.58247742189328
Validation loss: 2.368904630552503

Epoch: 221| Step: 0
Training loss: 2.2904658784021454
Validation loss: 2.3744811380178867

Epoch: 5| Step: 1
Training loss: 2.0744392004879284
Validation loss: 2.3839353490208914

Epoch: 5| Step: 2
Training loss: 1.8637565470426354
Validation loss: 2.3763951972972035

Epoch: 5| Step: 3
Training loss: 2.6115392058948266
Validation loss: 2.370160707345569

Epoch: 5| Step: 4
Training loss: 1.9998353651949756
Validation loss: 2.3606236117621644

Epoch: 5| Step: 5
Training loss: 2.133140007835816
Validation loss: 2.3451407940410913

Epoch: 5| Step: 6
Training loss: 2.3165784389061246
Validation loss: 2.371827210998147

Epoch: 5| Step: 7
Training loss: 1.7974663466272993
Validation loss: 2.3515488442898755

Epoch: 5| Step: 8
Training loss: 1.7963425884129922
Validation loss: 2.343898391674749

Epoch: 5| Step: 9
Training loss: 1.4903462019293452
Validation loss: 2.3617935133931627

Epoch: 5| Step: 10
Training loss: 2.504188081350389
Validation loss: 2.359862407280186

Epoch: 222| Step: 0
Training loss: 2.0647660724694687
Validation loss: 2.3969790996410874

Epoch: 5| Step: 1
Training loss: 2.4527264897000576
Validation loss: 2.3832336699098566

Epoch: 5| Step: 2
Training loss: 2.032513856171959
Validation loss: 2.389030367057856

Epoch: 5| Step: 3
Training loss: 1.7631917745716819
Validation loss: 2.3567333687334875

Epoch: 5| Step: 4
Training loss: 2.3566120466551004
Validation loss: 2.3477592888592294

Epoch: 5| Step: 5
Training loss: 1.5904457395976286
Validation loss: 2.340973875958401

Epoch: 5| Step: 6
Training loss: 1.693913317474634
Validation loss: 2.3320314083015834

Epoch: 5| Step: 7
Training loss: 2.3149885242416657
Validation loss: 2.3912835369277023

Epoch: 5| Step: 8
Training loss: 2.16663700474707
Validation loss: 2.3458208819226662

Epoch: 5| Step: 9
Training loss: 2.0758055169033414
Validation loss: 2.386633847291063

Epoch: 5| Step: 10
Training loss: 2.4894327945498596
Validation loss: 2.35725292405093

Epoch: 223| Step: 0
Training loss: 2.4892907602517442
Validation loss: 2.3562381979862534

Epoch: 5| Step: 1
Training loss: 1.5336425151640938
Validation loss: 2.3688864315807963

Epoch: 5| Step: 2
Training loss: 2.0904519595392768
Validation loss: 2.3603119063267646

Epoch: 5| Step: 3
Training loss: 2.098861262977333
Validation loss: 2.396972140200417

Epoch: 5| Step: 4
Training loss: 2.2689852295718853
Validation loss: 2.407241596731676

Epoch: 5| Step: 5
Training loss: 2.284501984663644
Validation loss: 2.352852326948382

Epoch: 5| Step: 6
Training loss: 2.016031268672048
Validation loss: 2.3552780475508768

Epoch: 5| Step: 7
Training loss: 1.4877836742304853
Validation loss: 2.3765342821241786

Epoch: 5| Step: 8
Training loss: 1.8975348818943965
Validation loss: 2.362304052641177

Epoch: 5| Step: 9
Training loss: 2.092693688692835
Validation loss: 2.3669120167734836

Epoch: 5| Step: 10
Training loss: 2.5266584973802915
Validation loss: 2.3667214391466125

Epoch: 224| Step: 0
Training loss: 2.33541507045976
Validation loss: 2.3774284054594226

Epoch: 5| Step: 1
Training loss: 1.814358186239824
Validation loss: 2.390533617098654

Epoch: 5| Step: 2
Training loss: 2.1843345627432234
Validation loss: 2.3710923779492714

Epoch: 5| Step: 3
Training loss: 1.7029130436306725
Validation loss: 2.3696002250475576

Epoch: 5| Step: 4
Training loss: 2.1639565121693316
Validation loss: 2.370558107650556

Epoch: 5| Step: 5
Training loss: 2.432376465282433
Validation loss: 2.382605190931875

Epoch: 5| Step: 6
Training loss: 1.9641365613910895
Validation loss: 2.3693244899999497

Epoch: 5| Step: 7
Training loss: 1.8284660086514326
Validation loss: 2.389788813887609

Epoch: 5| Step: 8
Training loss: 1.9627816696673073
Validation loss: 2.384466935920655

Epoch: 5| Step: 9
Training loss: 2.366548659736141
Validation loss: 2.3778661565073653

Epoch: 5| Step: 10
Training loss: 2.3796358539990816
Validation loss: 2.413859129055525

Epoch: 225| Step: 0
Training loss: 2.0735774943761096
Validation loss: 2.36929031760914

Epoch: 5| Step: 1
Training loss: 1.813130762248201
Validation loss: 2.3847226533430246

Epoch: 5| Step: 2
Training loss: 1.9874025212980855
Validation loss: 2.3663006985583914

Epoch: 5| Step: 3
Training loss: 1.844485378704819
Validation loss: 2.356975365475257

Epoch: 5| Step: 4
Training loss: 2.3316749287754983
Validation loss: 2.3738645053077696

Epoch: 5| Step: 5
Training loss: 1.7536468653897257
Validation loss: 2.3764219501564647

Epoch: 5| Step: 6
Training loss: 2.2254914501799865
Validation loss: 2.356018337510717

Epoch: 5| Step: 7
Training loss: 1.5384327331010392
Validation loss: 2.3677897402504327

Epoch: 5| Step: 8
Training loss: 2.92362947878551
Validation loss: 2.3684332833456745

Epoch: 5| Step: 9
Training loss: 2.020788395437717
Validation loss: 2.375607453333971

Epoch: 5| Step: 10
Training loss: 1.9531632686680591
Validation loss: 2.3819609886537303

Epoch: 226| Step: 0
Training loss: 1.892705104099417
Validation loss: 2.3324971356072233

Epoch: 5| Step: 1
Training loss: 2.5659322315404025
Validation loss: 2.3895774024231553

Epoch: 5| Step: 2
Training loss: 2.247727199862662
Validation loss: 2.375339916582221

Epoch: 5| Step: 3
Training loss: 2.104893763346351
Validation loss: 2.35946922817641

Epoch: 5| Step: 4
Training loss: 1.7478066732226623
Validation loss: 2.3794564263363225

Epoch: 5| Step: 5
Training loss: 1.982850457828414
Validation loss: 2.3636428066929276

Epoch: 5| Step: 6
Training loss: 2.479167927546675
Validation loss: 2.378227090195923

Epoch: 5| Step: 7
Training loss: 1.8604873407430935
Validation loss: 2.328974789301378

Epoch: 5| Step: 8
Training loss: 1.6643904241978134
Validation loss: 2.3713536846891152

Epoch: 5| Step: 9
Training loss: 2.1191252114574817
Validation loss: 2.356647951961763

Epoch: 5| Step: 10
Training loss: 2.000524809645601
Validation loss: 2.372121720492451

Epoch: 227| Step: 0
Training loss: 1.6858806611132429
Validation loss: 2.3811549195635022

Epoch: 5| Step: 1
Training loss: 1.5729308811918075
Validation loss: 2.3434870177910256

Epoch: 5| Step: 2
Training loss: 2.545516324532112
Validation loss: 2.381440303985064

Epoch: 5| Step: 3
Training loss: 1.8744408091522604
Validation loss: 2.3113782279868023

Epoch: 5| Step: 4
Training loss: 1.8421006665136594
Validation loss: 2.3435929954745407

Epoch: 5| Step: 5
Training loss: 1.979450633775431
Validation loss: 2.3459220682206383

Epoch: 5| Step: 6
Training loss: 2.245824011486668
Validation loss: 2.38508600190297

Epoch: 5| Step: 7
Training loss: 2.1048280664754087
Validation loss: 2.353082811006015

Epoch: 5| Step: 8
Training loss: 2.1029776307574717
Validation loss: 2.385594187047947

Epoch: 5| Step: 9
Training loss: 2.3669950199244028
Validation loss: 2.4094376850301096

Epoch: 5| Step: 10
Training loss: 2.378934813078986
Validation loss: 2.3638014809718704

Epoch: 228| Step: 0
Training loss: 2.310895414659148
Validation loss: 2.363099171312638

Epoch: 5| Step: 1
Training loss: 1.843664458278634
Validation loss: 2.353093852332288

Epoch: 5| Step: 2
Training loss: 1.9543456878757417
Validation loss: 2.3521623103701224

Epoch: 5| Step: 3
Training loss: 2.0096652614790855
Validation loss: 2.349582081168244

Epoch: 5| Step: 4
Training loss: 2.3115298323871194
Validation loss: 2.3560139512778693

Epoch: 5| Step: 5
Training loss: 1.8522211504859827
Validation loss: 2.4011308349497753

Epoch: 5| Step: 6
Training loss: 2.7059070184807856
Validation loss: 2.3790098330381304

Epoch: 5| Step: 7
Training loss: 1.695412276887246
Validation loss: 2.352160289679731

Epoch: 5| Step: 8
Training loss: 1.8691832917225666
Validation loss: 2.3507253093945746

Epoch: 5| Step: 9
Training loss: 2.0376663982570693
Validation loss: 2.3282696484303282

Epoch: 5| Step: 10
Training loss: 2.002580289528867
Validation loss: 2.343622687925714

Epoch: 229| Step: 0
Training loss: 2.3714707905922694
Validation loss: 2.344994844570519

Epoch: 5| Step: 1
Training loss: 2.206934347810477
Validation loss: 2.363790922395209

Epoch: 5| Step: 2
Training loss: 2.3033110047880707
Validation loss: 2.3744298923161478

Epoch: 5| Step: 3
Training loss: 1.8116678103268173
Validation loss: 2.354581020159551

Epoch: 5| Step: 4
Training loss: 2.025824475516827
Validation loss: 2.3785127666305055

Epoch: 5| Step: 5
Training loss: 1.9086593660371993
Validation loss: 2.3651044223618327

Epoch: 5| Step: 6
Training loss: 1.6915227484282667
Validation loss: 2.3659807240938915

Epoch: 5| Step: 7
Training loss: 2.2840803172859285
Validation loss: 2.375811354598928

Epoch: 5| Step: 8
Training loss: 2.0423821214257223
Validation loss: 2.3867879233562115

Epoch: 5| Step: 9
Training loss: 1.589306639874929
Validation loss: 2.3841844535719536

Epoch: 5| Step: 10
Training loss: 2.160351487454512
Validation loss: 2.382460971604673

Epoch: 230| Step: 0
Training loss: 1.8320136811607617
Validation loss: 2.3655610081066794

Epoch: 5| Step: 1
Training loss: 1.7084489256046071
Validation loss: 2.375745361131294

Epoch: 5| Step: 2
Training loss: 2.1325900342568014
Validation loss: 2.3818686695360087

Epoch: 5| Step: 3
Training loss: 1.8929973252202486
Validation loss: 2.354723309623638

Epoch: 5| Step: 4
Training loss: 2.1981944651361434
Validation loss: 2.3886227336246426

Epoch: 5| Step: 5
Training loss: 2.5188276861056775
Validation loss: 2.344384548467558

Epoch: 5| Step: 6
Training loss: 2.1520859690302623
Validation loss: 2.3759490995016637

Epoch: 5| Step: 7
Training loss: 2.3453041518721656
Validation loss: 2.400306311090081

Epoch: 5| Step: 8
Training loss: 1.8790444305429144
Validation loss: 2.356185311873573

Epoch: 5| Step: 9
Training loss: 2.4139323276620117
Validation loss: 2.3608563879514843

Epoch: 5| Step: 10
Training loss: 1.5691799805586701
Validation loss: 2.3999792286955035

Epoch: 231| Step: 0
Training loss: 2.846622734743317
Validation loss: 2.3623005614572166

Epoch: 5| Step: 1
Training loss: 1.8765665503719429
Validation loss: 2.3404337927745757

Epoch: 5| Step: 2
Training loss: 1.9882897637265537
Validation loss: 2.3628177864665294

Epoch: 5| Step: 3
Training loss: 1.6626624006529171
Validation loss: 2.331489227780271

Epoch: 5| Step: 4
Training loss: 1.933781470231946
Validation loss: 2.3516247444389804

Epoch: 5| Step: 5
Training loss: 2.1996243849797534
Validation loss: 2.3636028491667536

Epoch: 5| Step: 6
Training loss: 2.1004008092308775
Validation loss: 2.3348165400110314

Epoch: 5| Step: 7
Training loss: 2.4629237318725474
Validation loss: 2.3632297896380345

Epoch: 5| Step: 8
Training loss: 1.811561209806674
Validation loss: 2.3905027421132528

Epoch: 5| Step: 9
Training loss: 1.5331133968071253
Validation loss: 2.344721722170646

Epoch: 5| Step: 10
Training loss: 1.707176359455559
Validation loss: 2.343482213189538

Epoch: 232| Step: 0
Training loss: 1.8455469458972042
Validation loss: 2.326873183977798

Epoch: 5| Step: 1
Training loss: 2.2972041302970143
Validation loss: 2.360241364780365

Epoch: 5| Step: 2
Training loss: 1.5575684351451535
Validation loss: 2.3877276195638224

Epoch: 5| Step: 3
Training loss: 1.9542466261825924
Validation loss: 2.3276650997986583

Epoch: 5| Step: 4
Training loss: 2.361559734234333
Validation loss: 2.3653811966751688

Epoch: 5| Step: 5
Training loss: 1.4855154374693373
Validation loss: 2.373918551567974

Epoch: 5| Step: 6
Training loss: 2.164559427765129
Validation loss: 2.4015741985365784

Epoch: 5| Step: 7
Training loss: 1.7778959317812684
Validation loss: 2.3808154229503957

Epoch: 5| Step: 8
Training loss: 2.381535122039166
Validation loss: 2.3631779918589504

Epoch: 5| Step: 9
Training loss: 2.036221567684882
Validation loss: 2.344146379977152

Epoch: 5| Step: 10
Training loss: 2.4241334290999905
Validation loss: 2.3622247416963447

Epoch: 233| Step: 0
Training loss: 2.173786228046949
Validation loss: 2.3355194012850693

Epoch: 5| Step: 1
Training loss: 2.5582517439002084
Validation loss: 2.379231276616401

Epoch: 5| Step: 2
Training loss: 1.5790954476487589
Validation loss: 2.3539309694471964

Epoch: 5| Step: 3
Training loss: 2.0562944401631778
Validation loss: 2.39485072405431

Epoch: 5| Step: 4
Training loss: 2.2499264599120137
Validation loss: 2.360129706369433

Epoch: 5| Step: 5
Training loss: 2.082798113419111
Validation loss: 2.385382004023123

Epoch: 5| Step: 6
Training loss: 1.8297906444219076
Validation loss: 2.3556880871594177

Epoch: 5| Step: 7
Training loss: 1.8799780566375557
Validation loss: 2.3532743934646123

Epoch: 5| Step: 8
Training loss: 1.9792754360895173
Validation loss: 2.4126796922853724

Epoch: 5| Step: 9
Training loss: 1.980951314367367
Validation loss: 2.3533006324379664

Epoch: 5| Step: 10
Training loss: 1.8684175023298983
Validation loss: 2.3715007512612662

Epoch: 234| Step: 0
Training loss: 1.9892804046681318
Validation loss: 2.3700168275925857

Epoch: 5| Step: 1
Training loss: 2.2668401156240034
Validation loss: 2.336321783329884

Epoch: 5| Step: 2
Training loss: 1.8311042311005725
Validation loss: 2.3619751896567918

Epoch: 5| Step: 3
Training loss: 1.6725515975177725
Validation loss: 2.3729282468502966

Epoch: 5| Step: 4
Training loss: 1.721158022725899
Validation loss: 2.378094857119324

Epoch: 5| Step: 5
Training loss: 2.009373277156204
Validation loss: 2.383519091539194

Epoch: 5| Step: 6
Training loss: 1.8636043116568564
Validation loss: 2.3909926217956814

Epoch: 5| Step: 7
Training loss: 2.2017133803204336
Validation loss: 2.370680961540227

Epoch: 5| Step: 8
Training loss: 2.0360379642926643
Validation loss: 2.3479785316802193

Epoch: 5| Step: 9
Training loss: 1.8466870465628753
Validation loss: 2.3719943056974615

Epoch: 5| Step: 10
Training loss: 2.964061850073647
Validation loss: 2.369137428482467

Epoch: 235| Step: 0
Training loss: 2.084759669003226
Validation loss: 2.398522621913771

Epoch: 5| Step: 1
Training loss: 2.1695355226765183
Validation loss: 2.348399915257912

Epoch: 5| Step: 2
Training loss: 2.3670380296508706
Validation loss: 2.336466599650043

Epoch: 5| Step: 3
Training loss: 1.8162165717076417
Validation loss: 2.4053681676413765

Epoch: 5| Step: 4
Training loss: 1.9868774254691988
Validation loss: 2.369294539682211

Epoch: 5| Step: 5
Training loss: 1.9942250920414328
Validation loss: 2.349323419411283

Epoch: 5| Step: 6
Training loss: 1.7823802641342676
Validation loss: 2.3852444669117507

Epoch: 5| Step: 7
Training loss: 1.7812853357926028
Validation loss: 2.3721476645323447

Epoch: 5| Step: 8
Training loss: 1.9196440611166996
Validation loss: 2.3389979183094445

Epoch: 5| Step: 9
Training loss: 1.505438957454058
Validation loss: 2.350870443996472

Epoch: 5| Step: 10
Training loss: 2.7053674646420762
Validation loss: 2.369974282977002

Epoch: 236| Step: 0
Training loss: 2.017141200685921
Validation loss: 2.3368083540387268

Epoch: 5| Step: 1
Training loss: 1.7059690195202093
Validation loss: 2.3494916099140832

Epoch: 5| Step: 2
Training loss: 2.0434894080656414
Validation loss: 2.353559038996362

Epoch: 5| Step: 3
Training loss: 1.4691732080969946
Validation loss: 2.358093118849744

Epoch: 5| Step: 4
Training loss: 2.229883334268464
Validation loss: 2.36735225280013

Epoch: 5| Step: 5
Training loss: 1.801390836399777
Validation loss: 2.3710212745773047

Epoch: 5| Step: 6
Training loss: 2.4823715480982327
Validation loss: 2.36645467661753

Epoch: 5| Step: 7
Training loss: 1.9708866453588243
Validation loss: 2.3750859494894336

Epoch: 5| Step: 8
Training loss: 2.4428774863904215
Validation loss: 2.3330447293885337

Epoch: 5| Step: 9
Training loss: 2.372396949966006
Validation loss: 2.355236714859754

Epoch: 5| Step: 10
Training loss: 1.6942555872968723
Validation loss: 2.373560295840393

Epoch: 237| Step: 0
Training loss: 1.928455716400825
Validation loss: 2.347023779958153

Epoch: 5| Step: 1
Training loss: 1.8892538600073019
Validation loss: 2.3834031412422725

Epoch: 5| Step: 2
Training loss: 1.840138016997731
Validation loss: 2.406112663782992

Epoch: 5| Step: 3
Training loss: 1.6879755692228164
Validation loss: 2.3758675556433935

Epoch: 5| Step: 4
Training loss: 2.205906296020416
Validation loss: 2.439321558288277

Epoch: 5| Step: 5
Training loss: 2.180906986931018
Validation loss: 2.3977069603277585

Epoch: 5| Step: 6
Training loss: 1.9609137909812355
Validation loss: 2.4024551356441872

Epoch: 5| Step: 7
Training loss: 1.8773258406808373
Validation loss: 2.4457732778877603

Epoch: 5| Step: 8
Training loss: 2.5137081069528437
Validation loss: 2.411407460244164

Epoch: 5| Step: 9
Training loss: 2.141953216362394
Validation loss: 2.4059349474941536

Epoch: 5| Step: 10
Training loss: 2.378791593347361
Validation loss: 2.3781914761900764

Epoch: 238| Step: 0
Training loss: 1.4847815508993205
Validation loss: 2.38793644965285

Epoch: 5| Step: 1
Training loss: 1.5830400429515012
Validation loss: 2.36565495574729

Epoch: 5| Step: 2
Training loss: 1.679577917028596
Validation loss: 2.3631000348640274

Epoch: 5| Step: 3
Training loss: 2.3077031465422575
Validation loss: 2.3779959270591067

Epoch: 5| Step: 4
Training loss: 1.8396631626018134
Validation loss: 2.3613967952699033

Epoch: 5| Step: 5
Training loss: 2.2907686612614824
Validation loss: 2.3824015579896236

Epoch: 5| Step: 6
Training loss: 2.1958171223784597
Validation loss: 2.3452570996652264

Epoch: 5| Step: 7
Training loss: 2.2983858498190504
Validation loss: 2.346184349154018

Epoch: 5| Step: 8
Training loss: 2.0789170440886746
Validation loss: 2.3613245460616605

Epoch: 5| Step: 9
Training loss: 2.056441685980158
Validation loss: 2.363904242834451

Epoch: 5| Step: 10
Training loss: 2.177355978896857
Validation loss: 2.343229961605508

Epoch: 239| Step: 0
Training loss: 2.071344543030537
Validation loss: 2.375935875823914

Epoch: 5| Step: 1
Training loss: 2.2638300658568955
Validation loss: 2.3996595282615845

Epoch: 5| Step: 2
Training loss: 1.9976613557501908
Validation loss: 2.379192889008192

Epoch: 5| Step: 3
Training loss: 1.9313683853159587
Validation loss: 2.331637920930247

Epoch: 5| Step: 4
Training loss: 2.3337062015520194
Validation loss: 2.359357285482307

Epoch: 5| Step: 5
Training loss: 1.7414310335472492
Validation loss: 2.3894656943589245

Epoch: 5| Step: 6
Training loss: 1.9531041258650157
Validation loss: 2.3548194418725887

Epoch: 5| Step: 7
Training loss: 2.3321693673439103
Validation loss: 2.359191519590901

Epoch: 5| Step: 8
Training loss: 1.4175764229439183
Validation loss: 2.3534092902220194

Epoch: 5| Step: 9
Training loss: 2.4013444512381876
Validation loss: 2.359133324390989

Epoch: 5| Step: 10
Training loss: 1.5744119908922918
Validation loss: 2.3401996074127234

Epoch: 240| Step: 0
Training loss: 2.6391342740549786
Validation loss: 2.378065030195594

Epoch: 5| Step: 1
Training loss: 2.0029257593437224
Validation loss: 2.3505407617089364

Epoch: 5| Step: 2
Training loss: 2.0906150464104654
Validation loss: 2.381675950793371

Epoch: 5| Step: 3
Training loss: 1.818879181249449
Validation loss: 2.3552392412328724

Epoch: 5| Step: 4
Training loss: 1.8011157869083103
Validation loss: 2.3599619285805593

Epoch: 5| Step: 5
Training loss: 2.161159068765604
Validation loss: 2.3817382284431017

Epoch: 5| Step: 6
Training loss: 1.9358436518621425
Validation loss: 2.38351439021991

Epoch: 5| Step: 7
Training loss: 1.9666477059673388
Validation loss: 2.3937931107137578

Epoch: 5| Step: 8
Training loss: 2.0025132600533393
Validation loss: 2.3758976345902667

Epoch: 5| Step: 9
Training loss: 1.821299796801477
Validation loss: 2.3893423878948

Epoch: 5| Step: 10
Training loss: 1.5881306934817605
Validation loss: 2.374754403481798

Epoch: 241| Step: 0
Training loss: 2.2881901351381306
Validation loss: 2.378430730233589

Epoch: 5| Step: 1
Training loss: 2.5446863424079975
Validation loss: 2.354205935324302

Epoch: 5| Step: 2
Training loss: 1.538592349048208
Validation loss: 2.3154462024162394

Epoch: 5| Step: 3
Training loss: 1.4785245746457585
Validation loss: 2.4100970925807483

Epoch: 5| Step: 4
Training loss: 1.7884545771776497
Validation loss: 2.3607818357829995

Epoch: 5| Step: 5
Training loss: 2.1733268440867395
Validation loss: 2.3291119277629555

Epoch: 5| Step: 6
Training loss: 1.900106379391949
Validation loss: 2.3681960795904073

Epoch: 5| Step: 7
Training loss: 2.0069751700484284
Validation loss: 2.3664622403839055

Epoch: 5| Step: 8
Training loss: 2.254747679945525
Validation loss: 2.353576660998719

Epoch: 5| Step: 9
Training loss: 2.1875920957524695
Validation loss: 2.375783991663115

Epoch: 5| Step: 10
Training loss: 1.926340327635952
Validation loss: 2.3658349766391606

Epoch: 242| Step: 0
Training loss: 2.4464494785851456
Validation loss: 2.3098177221658025

Epoch: 5| Step: 1
Training loss: 1.8923725217267156
Validation loss: 2.351908248892157

Epoch: 5| Step: 2
Training loss: 1.9525985618654
Validation loss: 2.3896176154471402

Epoch: 5| Step: 3
Training loss: 1.7329943548595939
Validation loss: 2.360975448922239

Epoch: 5| Step: 4
Training loss: 1.6320353579617848
Validation loss: 2.360236086495786

Epoch: 5| Step: 5
Training loss: 1.5432672525736464
Validation loss: 2.3555597268579898

Epoch: 5| Step: 6
Training loss: 1.7437402622402205
Validation loss: 2.3370524008102893

Epoch: 5| Step: 7
Training loss: 1.7881215382088809
Validation loss: 2.360320401865003

Epoch: 5| Step: 8
Training loss: 2.450356835050681
Validation loss: 2.434199907128603

Epoch: 5| Step: 9
Training loss: 2.1328217782178567
Validation loss: 2.394885835552322

Epoch: 5| Step: 10
Training loss: 2.2731379675423184
Validation loss: 2.36172349344718

Epoch: 243| Step: 0
Training loss: 2.093596381629846
Validation loss: 2.3274499806962425

Epoch: 5| Step: 1
Training loss: 1.929589025787917
Validation loss: 2.349706381466002

Epoch: 5| Step: 2
Training loss: 1.1307848970070546
Validation loss: 2.3763564833840745

Epoch: 5| Step: 3
Training loss: 2.324008861649602
Validation loss: 2.3814769125269

Epoch: 5| Step: 4
Training loss: 2.385971226981559
Validation loss: 2.362971483738643

Epoch: 5| Step: 5
Training loss: 1.82520171317932
Validation loss: 2.36320959158993

Epoch: 5| Step: 6
Training loss: 2.1736603129718692
Validation loss: 2.412894138566166

Epoch: 5| Step: 7
Training loss: 1.9079724019091953
Validation loss: 2.3592145306050107

Epoch: 5| Step: 8
Training loss: 1.92824485072454
Validation loss: 2.3845424032464537

Epoch: 5| Step: 9
Training loss: 2.0502137189040495
Validation loss: 2.376313592689322

Epoch: 5| Step: 10
Training loss: 1.9120396727033293
Validation loss: 2.3705409601135248

Epoch: 244| Step: 0
Training loss: 2.194649918777756
Validation loss: 2.3792225293907148

Epoch: 5| Step: 1
Training loss: 2.0450098989755428
Validation loss: 2.3390210194787184

Epoch: 5| Step: 2
Training loss: 1.4358079322579886
Validation loss: 2.3641729625328747

Epoch: 5| Step: 3
Training loss: 1.801521662094567
Validation loss: 2.3789794356702667

Epoch: 5| Step: 4
Training loss: 1.7704695009945883
Validation loss: 2.404017424979453

Epoch: 5| Step: 5
Training loss: 2.5459501307323893
Validation loss: 2.3497926844444796

Epoch: 5| Step: 6
Training loss: 2.536867008276525
Validation loss: 2.3586365428937923

Epoch: 5| Step: 7
Training loss: 1.282429082817112
Validation loss: 2.3741469543270104

Epoch: 5| Step: 8
Training loss: 2.6183326151859196
Validation loss: 2.3730390837478295

Epoch: 5| Step: 9
Training loss: 1.3527386790027274
Validation loss: 2.3534702854063823

Epoch: 5| Step: 10
Training loss: 1.8643795591139414
Validation loss: 2.363260581593047

Epoch: 245| Step: 0
Training loss: 2.1747913128938765
Validation loss: 2.3771806225623355

Epoch: 5| Step: 1
Training loss: 1.8114501280230426
Validation loss: 2.383135398532524

Epoch: 5| Step: 2
Training loss: 2.004301214427187
Validation loss: 2.38957295548609

Epoch: 5| Step: 3
Training loss: 2.0534722393083045
Validation loss: 2.3869323060268868

Epoch: 5| Step: 4
Training loss: 1.7706790258457885
Validation loss: 2.358995777260809

Epoch: 5| Step: 5
Training loss: 1.8192734925164826
Validation loss: 2.354003766306379

Epoch: 5| Step: 6
Training loss: 1.5738376506366607
Validation loss: 2.3144257189698396

Epoch: 5| Step: 7
Training loss: 1.8208325343126628
Validation loss: 2.3483843045509376

Epoch: 5| Step: 8
Training loss: 2.0367054378775373
Validation loss: 2.3607472997414796

Epoch: 5| Step: 9
Training loss: 2.073524603203524
Validation loss: 2.3428387812772486

Epoch: 5| Step: 10
Training loss: 2.6988691222212675
Validation loss: 2.358292184828226

Epoch: 246| Step: 0
Training loss: 2.1258562270361945
Validation loss: 2.384331034094507

Epoch: 5| Step: 1
Training loss: 1.6593503903505562
Validation loss: 2.3600075524454187

Epoch: 5| Step: 2
Training loss: 1.858568673848609
Validation loss: 2.360992247344

Epoch: 5| Step: 3
Training loss: 1.9401982500105168
Validation loss: 2.371426827773709

Epoch: 5| Step: 4
Training loss: 2.264491356669562
Validation loss: 2.363929175226521

Epoch: 5| Step: 5
Training loss: 2.558989562656931
Validation loss: 2.3335439928242803

Epoch: 5| Step: 6
Training loss: 1.6849737684885142
Validation loss: 2.3639315675944648

Epoch: 5| Step: 7
Training loss: 1.826848684950754
Validation loss: 2.3865602679427225

Epoch: 5| Step: 8
Training loss: 1.710328782023444
Validation loss: 2.3619070316934967

Epoch: 5| Step: 9
Training loss: 1.7428339968937834
Validation loss: 2.3731319472840267

Epoch: 5| Step: 10
Training loss: 1.99338821429143
Validation loss: 2.3671968981694613

Epoch: 247| Step: 0
Training loss: 2.0420248794310347
Validation loss: 2.3823082271778917

Epoch: 5| Step: 1
Training loss: 1.731871438988143
Validation loss: 2.3491222309041904

Epoch: 5| Step: 2
Training loss: 2.312362563714461
Validation loss: 2.3504361432797345

Epoch: 5| Step: 3
Training loss: 1.9572039316709733
Validation loss: 2.378566826908803

Epoch: 5| Step: 4
Training loss: 2.1216703021229866
Validation loss: 2.3514967112573877

Epoch: 5| Step: 5
Training loss: 2.3045768064651204
Validation loss: 2.326470710573816

Epoch: 5| Step: 6
Training loss: 2.1551059507447765
Validation loss: 2.329359399164879

Epoch: 5| Step: 7
Training loss: 1.6355021104137177
Validation loss: 2.362575661139514

Epoch: 5| Step: 8
Training loss: 1.4094410189371998
Validation loss: 2.344152958182727

Epoch: 5| Step: 9
Training loss: 1.8993982466404513
Validation loss: 2.3894710674002275

Epoch: 5| Step: 10
Training loss: 1.5526100732724477
Validation loss: 2.40082478083668

Epoch: 248| Step: 0
Training loss: 1.888948438054792
Validation loss: 2.372013405437626

Epoch: 5| Step: 1
Training loss: 1.7787226096729825
Validation loss: 2.368656924666455

Epoch: 5| Step: 2
Training loss: 1.9214593081110098
Validation loss: 2.3625489793631025

Epoch: 5| Step: 3
Training loss: 1.8000480168613813
Validation loss: 2.3598192852401776

Epoch: 5| Step: 4
Training loss: 1.8011912377730794
Validation loss: 2.358025130804366

Epoch: 5| Step: 5
Training loss: 1.858022502454937
Validation loss: 2.3670544070631787

Epoch: 5| Step: 6
Training loss: 2.3125975304733983
Validation loss: 2.337086612931805

Epoch: 5| Step: 7
Training loss: 1.7083774731523873
Validation loss: 2.379123737275542

Epoch: 5| Step: 8
Training loss: 2.6227959962396286
Validation loss: 2.3596717437609604

Epoch: 5| Step: 9
Training loss: 1.8428348921174986
Validation loss: 2.352110303742702

Epoch: 5| Step: 10
Training loss: 1.9744144271773267
Validation loss: 2.3604381148855222

Epoch: 249| Step: 0
Training loss: 1.544338651543516
Validation loss: 2.3620272097193618

Epoch: 5| Step: 1
Training loss: 1.6872681352480372
Validation loss: 2.370748323871918

Epoch: 5| Step: 2
Training loss: 2.5349031624741283
Validation loss: 2.3332393157786404

Epoch: 5| Step: 3
Training loss: 1.9214410679654437
Validation loss: 2.3681398361348807

Epoch: 5| Step: 4
Training loss: 2.267354581264293
Validation loss: 2.3621398181570257

Epoch: 5| Step: 5
Training loss: 1.7867692133787316
Validation loss: 2.4222072917181667

Epoch: 5| Step: 6
Training loss: 1.491611789070408
Validation loss: 2.3728766208053225

Epoch: 5| Step: 7
Training loss: 2.046870107863309
Validation loss: 2.394191176661511

Epoch: 5| Step: 8
Training loss: 1.8104643077603249
Validation loss: 2.38587181870748

Epoch: 5| Step: 9
Training loss: 2.0442062335326208
Validation loss: 2.351860933666964

Epoch: 5| Step: 10
Training loss: 2.1060155041840325
Validation loss: 2.3885118009292174

Epoch: 250| Step: 0
Training loss: 1.8008923279106097
Validation loss: 2.3730085969328623

Epoch: 5| Step: 1
Training loss: 2.3438653536066023
Validation loss: 2.3889058211784495

Epoch: 5| Step: 2
Training loss: 2.0548524971625617
Validation loss: 2.4100012904346557

Epoch: 5| Step: 3
Training loss: 2.038312401319664
Validation loss: 2.398290016818834

Epoch: 5| Step: 4
Training loss: 1.549230920048407
Validation loss: 2.3404051388190075

Epoch: 5| Step: 5
Training loss: 1.923220093972983
Validation loss: 2.3764847570788947

Epoch: 5| Step: 6
Training loss: 1.7896222567368403
Validation loss: 2.390122149157208

Epoch: 5| Step: 7
Training loss: 1.9679046511385911
Validation loss: 2.381004491329533

Epoch: 5| Step: 8
Training loss: 1.6204533426547107
Validation loss: 2.3496139848603343

Epoch: 5| Step: 9
Training loss: 1.615207731864414
Validation loss: 2.3401579174745057

Epoch: 5| Step: 10
Training loss: 2.383636032124573
Validation loss: 2.3808070110441926

Testing loss: 2.642314653716445
