Epoch: 1| Step: 0
Training loss: 8.019366264343262
Validation loss: 7.773459752400716

Epoch: 6| Step: 1
Training loss: 7.383200645446777
Validation loss: 7.770823765826481

Epoch: 6| Step: 2
Training loss: 6.226130485534668
Validation loss: 7.7628372356455815

Epoch: 6| Step: 3
Training loss: 7.193286418914795
Validation loss: 7.758799368335355

Epoch: 6| Step: 4
Training loss: 6.988149166107178
Validation loss: 7.7523778433440835

Epoch: 6| Step: 5
Training loss: 7.9084014892578125
Validation loss: 7.745463484077043

Epoch: 6| Step: 6
Training loss: 8.482662200927734
Validation loss: 7.740328404211229

Epoch: 6| Step: 7
Training loss: 7.498887062072754
Validation loss: 7.738344612941947

Epoch: 6| Step: 8
Training loss: 9.100269317626953
Validation loss: 7.729806054023005

Epoch: 6| Step: 9
Training loss: 6.583151340484619
Validation loss: 7.724283105583601

Epoch: 6| Step: 10
Training loss: 6.900701522827148
Validation loss: 7.721234900977022

Epoch: 6| Step: 11
Training loss: 6.534465789794922
Validation loss: 7.713119763200001

Epoch: 6| Step: 12
Training loss: 8.414856910705566
Validation loss: 7.7048398807484615

Epoch: 6| Step: 13
Training loss: 8.793994903564453
Validation loss: 7.70149205833353

Epoch: 2| Step: 0
Training loss: 7.058598518371582
Validation loss: 7.695023300827191

Epoch: 6| Step: 1
Training loss: 9.534713745117188
Validation loss: 7.691706734318887

Epoch: 6| Step: 2
Training loss: 6.77671480178833
Validation loss: 7.68498105900262

Epoch: 6| Step: 3
Training loss: 7.757512092590332
Validation loss: 7.678221482102589

Epoch: 6| Step: 4
Training loss: 7.478001594543457
Validation loss: 7.673189429826634

Epoch: 6| Step: 5
Training loss: 9.000965118408203
Validation loss: 7.666484519999514

Epoch: 6| Step: 6
Training loss: 7.056833267211914
Validation loss: 7.663567635320848

Epoch: 6| Step: 7
Training loss: 7.02829647064209
Validation loss: 7.657739998191915

Epoch: 6| Step: 8
Training loss: 7.9631524085998535
Validation loss: 7.648835089898879

Epoch: 6| Step: 9
Training loss: 6.661055564880371
Validation loss: 7.64447679314562

Epoch: 6| Step: 10
Training loss: 6.191062927246094
Validation loss: 7.639625226297686

Epoch: 6| Step: 11
Training loss: 7.792422294616699
Validation loss: 7.635452655053908

Epoch: 6| Step: 12
Training loss: 7.245699882507324
Validation loss: 7.6255576841292845

Epoch: 6| Step: 13
Training loss: 6.3467206954956055
Validation loss: 7.622234954628893

Epoch: 3| Step: 0
Training loss: 6.754549026489258
Validation loss: 7.615726414547171

Epoch: 6| Step: 1
Training loss: 6.554821968078613
Validation loss: 7.610241033697641

Epoch: 6| Step: 2
Training loss: 8.074966430664062
Validation loss: 7.6035289149130545

Epoch: 6| Step: 3
Training loss: 7.078960418701172
Validation loss: 7.601263989684402

Epoch: 6| Step: 4
Training loss: 7.771330833435059
Validation loss: 7.595527484852781

Epoch: 6| Step: 5
Training loss: 6.582963943481445
Validation loss: 7.586555404047812

Epoch: 6| Step: 6
Training loss: 7.688552379608154
Validation loss: 7.58219632282052

Epoch: 6| Step: 7
Training loss: 8.597396850585938
Validation loss: 7.573862696206698

Epoch: 6| Step: 8
Training loss: 6.55799674987793
Validation loss: 7.5671750396810555

Epoch: 6| Step: 9
Training loss: 7.305239677429199
Validation loss: 7.561403602682134

Epoch: 6| Step: 10
Training loss: 6.653231620788574
Validation loss: 7.555952025998023

Epoch: 6| Step: 11
Training loss: 7.9520978927612305
Validation loss: 7.548082679830571

Epoch: 6| Step: 12
Training loss: 7.727025032043457
Validation loss: 7.544949162390925

Epoch: 6| Step: 13
Training loss: 8.245747566223145
Validation loss: 7.536838136693483

Epoch: 4| Step: 0
Training loss: 6.7921366691589355
Validation loss: 7.5343359619058585

Epoch: 6| Step: 1
Training loss: 7.287376880645752
Validation loss: 7.5236663818359375

Epoch: 6| Step: 2
Training loss: 7.132494926452637
Validation loss: 7.517841595475391

Epoch: 6| Step: 3
Training loss: 7.116697788238525
Validation loss: 7.5097399527026765

Epoch: 6| Step: 4
Training loss: 7.804917335510254
Validation loss: 7.503232920041648

Epoch: 6| Step: 5
Training loss: 7.003975868225098
Validation loss: 7.498025760855726

Epoch: 6| Step: 6
Training loss: 8.270658493041992
Validation loss: 7.489886104419667

Epoch: 6| Step: 7
Training loss: 8.392854690551758
Validation loss: 7.482613317428097

Epoch: 6| Step: 8
Training loss: 5.841382026672363
Validation loss: 7.479423620367563

Epoch: 6| Step: 9
Training loss: 6.665711402893066
Validation loss: 7.468633856824649

Epoch: 6| Step: 10
Training loss: 6.875895023345947
Validation loss: 7.460027638302054

Epoch: 6| Step: 11
Training loss: 6.813697814941406
Validation loss: 7.4541113966254775

Epoch: 6| Step: 12
Training loss: 8.573806762695312
Validation loss: 7.447324475934429

Epoch: 6| Step: 13
Training loss: 7.343208312988281
Validation loss: 7.438042558649535

Epoch: 5| Step: 0
Training loss: 7.125969886779785
Validation loss: 7.43253178750315

Epoch: 6| Step: 1
Training loss: 6.587632179260254
Validation loss: 7.425468296133062

Epoch: 6| Step: 2
Training loss: 7.942842483520508
Validation loss: 7.417491574441233

Epoch: 6| Step: 3
Training loss: 8.08340072631836
Validation loss: 7.409739196941417

Epoch: 6| Step: 4
Training loss: 7.45974063873291
Validation loss: 7.401542632810531

Epoch: 6| Step: 5
Training loss: 5.630720138549805
Validation loss: 7.3913945587732455

Epoch: 6| Step: 6
Training loss: 6.584632873535156
Validation loss: 7.384442954935054

Epoch: 6| Step: 7
Training loss: 8.39057731628418
Validation loss: 7.3790379801104145

Epoch: 6| Step: 8
Training loss: 7.118924140930176
Validation loss: 7.368633618918798

Epoch: 6| Step: 9
Training loss: 7.394012451171875
Validation loss: 7.358481268728933

Epoch: 6| Step: 10
Training loss: 6.884798049926758
Validation loss: 7.349611405403383

Epoch: 6| Step: 11
Training loss: 6.434047698974609
Validation loss: 7.344329885257188

Epoch: 6| Step: 12
Training loss: 7.3372979164123535
Validation loss: 7.334030582058814

Epoch: 6| Step: 13
Training loss: 7.519927978515625
Validation loss: 7.325274175213229

Epoch: 6| Step: 0
Training loss: 6.777652263641357
Validation loss: 7.31396342862037

Epoch: 6| Step: 1
Training loss: 7.476225852966309
Validation loss: 7.305803837314729

Epoch: 6| Step: 2
Training loss: 5.384197235107422
Validation loss: 7.297212231543757

Epoch: 6| Step: 3
Training loss: 6.2115559577941895
Validation loss: 7.290144330711775

Epoch: 6| Step: 4
Training loss: 6.983169078826904
Validation loss: 7.283280890475037

Epoch: 6| Step: 5
Training loss: 6.2742695808410645
Validation loss: 7.2733379281977175

Epoch: 6| Step: 6
Training loss: 7.897747993469238
Validation loss: 7.2633944275558635

Epoch: 6| Step: 7
Training loss: 7.588459014892578
Validation loss: 7.254720267429147

Epoch: 6| Step: 8
Training loss: 7.133766174316406
Validation loss: 7.24365266676872

Epoch: 6| Step: 9
Training loss: 7.681595325469971
Validation loss: 7.237481060848441

Epoch: 6| Step: 10
Training loss: 7.797532558441162
Validation loss: 7.225681879187143

Epoch: 6| Step: 11
Training loss: 6.945326328277588
Validation loss: 7.214981766157253

Epoch: 6| Step: 12
Training loss: 7.855042457580566
Validation loss: 7.205433399446549

Epoch: 6| Step: 13
Training loss: 6.243799209594727
Validation loss: 7.1987509573659585

Epoch: 7| Step: 0
Training loss: 8.534262657165527
Validation loss: 7.185179520678776

Epoch: 6| Step: 1
Training loss: 7.80351448059082
Validation loss: 7.175315441623811

Epoch: 6| Step: 2
Training loss: 6.088910102844238
Validation loss: 7.169223846927766

Epoch: 6| Step: 3
Training loss: 5.666415214538574
Validation loss: 7.159652551015218

Epoch: 6| Step: 4
Training loss: 7.399041175842285
Validation loss: 7.14856799956291

Epoch: 6| Step: 5
Training loss: 8.03067398071289
Validation loss: 7.134211319749073

Epoch: 6| Step: 6
Training loss: 7.108891487121582
Validation loss: 7.127754801063127

Epoch: 6| Step: 7
Training loss: 7.415232181549072
Validation loss: 7.117720803906841

Epoch: 6| Step: 8
Training loss: 5.443123817443848
Validation loss: 7.1048192054994646

Epoch: 6| Step: 9
Training loss: 5.888347625732422
Validation loss: 7.092384348633469

Epoch: 6| Step: 10
Training loss: 7.652564525604248
Validation loss: 7.081905067607921

Epoch: 6| Step: 11
Training loss: 6.61091423034668
Validation loss: 7.073926028384958

Epoch: 6| Step: 12
Training loss: 6.411752700805664
Validation loss: 7.06210547108804

Epoch: 6| Step: 13
Training loss: 6.375627517700195
Validation loss: 7.0523931800678215

Epoch: 8| Step: 0
Training loss: 7.277437210083008
Validation loss: 7.036544358858499

Epoch: 6| Step: 1
Training loss: 6.73883056640625
Validation loss: 7.0313840681506745

Epoch: 6| Step: 2
Training loss: 6.230611324310303
Validation loss: 7.017528159644014

Epoch: 6| Step: 3
Training loss: 7.301612854003906
Validation loss: 7.005166884391539

Epoch: 6| Step: 4
Training loss: 5.970305442810059
Validation loss: 6.990592525851342

Epoch: 6| Step: 5
Training loss: 8.273768424987793
Validation loss: 6.980388743903047

Epoch: 6| Step: 6
Training loss: 6.937769889831543
Validation loss: 6.967625438526112

Epoch: 6| Step: 7
Training loss: 7.579705238342285
Validation loss: 6.960310300191243

Epoch: 6| Step: 8
Training loss: 7.225991725921631
Validation loss: 6.94299005693005

Epoch: 6| Step: 9
Training loss: 6.423648834228516
Validation loss: 6.92910780445222

Epoch: 6| Step: 10
Training loss: 5.0691633224487305
Validation loss: 6.921160236481698

Epoch: 6| Step: 11
Training loss: 6.845003128051758
Validation loss: 6.910613603489374

Epoch: 6| Step: 12
Training loss: 6.386753082275391
Validation loss: 6.8970399569439635

Epoch: 6| Step: 13
Training loss: 5.664939880371094
Validation loss: 6.8841990809286795

Epoch: 9| Step: 0
Training loss: 7.469078063964844
Validation loss: 6.868589267935804

Epoch: 6| Step: 1
Training loss: 5.121916770935059
Validation loss: 6.858204810850082

Epoch: 6| Step: 2
Training loss: 6.672698020935059
Validation loss: 6.8377043303623

Epoch: 6| Step: 3
Training loss: 6.378054618835449
Validation loss: 6.827705870392502

Epoch: 6| Step: 4
Training loss: 7.1057634353637695
Validation loss: 6.817888659815634

Epoch: 6| Step: 5
Training loss: 7.176267623901367
Validation loss: 6.7991941718644995

Epoch: 6| Step: 6
Training loss: 6.220715522766113
Validation loss: 6.783014917886385

Epoch: 6| Step: 7
Training loss: 6.663529396057129
Validation loss: 6.778107520072691

Epoch: 6| Step: 8
Training loss: 6.113683700561523
Validation loss: 6.764164981021676

Epoch: 6| Step: 9
Training loss: 6.6780266761779785
Validation loss: 6.741753250040034

Epoch: 6| Step: 10
Training loss: 6.426187992095947
Validation loss: 6.7298507536611245

Epoch: 6| Step: 11
Training loss: 6.432106971740723
Validation loss: 6.714640120024322

Epoch: 6| Step: 12
Training loss: 6.963627815246582
Validation loss: 6.697346015643048

Epoch: 6| Step: 13
Training loss: 6.1925225257873535
Validation loss: 6.686435632808234

Epoch: 10| Step: 0
Training loss: 6.292909145355225
Validation loss: 6.670734523445048

Epoch: 6| Step: 1
Training loss: 7.939673900604248
Validation loss: 6.653341426644274

Epoch: 6| Step: 2
Training loss: 6.073987007141113
Validation loss: 6.643442148803382

Epoch: 6| Step: 3
Training loss: 7.187000274658203
Validation loss: 6.622523584673481

Epoch: 6| Step: 4
Training loss: 6.541300296783447
Validation loss: 6.606982436231387

Epoch: 6| Step: 5
Training loss: 6.459000587463379
Validation loss: 6.590496345232892

Epoch: 6| Step: 6
Training loss: 6.483213424682617
Validation loss: 6.5738854510809785

Epoch: 6| Step: 7
Training loss: 7.151001453399658
Validation loss: 6.556333977689025

Epoch: 6| Step: 8
Training loss: 5.978715896606445
Validation loss: 6.535334053859915

Epoch: 6| Step: 9
Training loss: 5.550515174865723
Validation loss: 6.518154851851925

Epoch: 6| Step: 10
Training loss: 6.025848388671875
Validation loss: 6.5061661146020375

Epoch: 6| Step: 11
Training loss: 6.269482612609863
Validation loss: 6.492233178948843

Epoch: 6| Step: 12
Training loss: 5.097005844116211
Validation loss: 6.471595466777843

Epoch: 6| Step: 13
Training loss: 5.1587677001953125
Validation loss: 6.456729617170108

Epoch: 11| Step: 0
Training loss: 6.55612850189209
Validation loss: 6.437546053240376

Epoch: 6| Step: 1
Training loss: 5.721227645874023
Validation loss: 6.415367536647345

Epoch: 6| Step: 2
Training loss: 4.857869625091553
Validation loss: 6.403359674638318

Epoch: 6| Step: 3
Training loss: 6.135988712310791
Validation loss: 6.381740703377672

Epoch: 6| Step: 4
Training loss: 8.256997108459473
Validation loss: 6.358046977750717

Epoch: 6| Step: 5
Training loss: 5.618243217468262
Validation loss: 6.341907116674608

Epoch: 6| Step: 6
Training loss: 5.6299004554748535
Validation loss: 6.322948563483454

Epoch: 6| Step: 7
Training loss: 6.4340081214904785
Validation loss: 6.309979402890769

Epoch: 6| Step: 8
Training loss: 5.177145957946777
Validation loss: 6.287211930879983

Epoch: 6| Step: 9
Training loss: 6.426228046417236
Validation loss: 6.258623036005163

Epoch: 6| Step: 10
Training loss: 6.836179256439209
Validation loss: 6.248126301714169

Epoch: 6| Step: 11
Training loss: 5.311027526855469
Validation loss: 6.230318725750011

Epoch: 6| Step: 12
Training loss: 5.806396961212158
Validation loss: 6.205717507229056

Epoch: 6| Step: 13
Training loss: 6.523559093475342
Validation loss: 6.180444430279476

Epoch: 12| Step: 0
Training loss: 7.047010898590088
Validation loss: 6.161270572293189

Epoch: 6| Step: 1
Training loss: 7.184673309326172
Validation loss: 6.146001431249803

Epoch: 6| Step: 2
Training loss: 5.351675033569336
Validation loss: 6.120202664406069

Epoch: 6| Step: 3
Training loss: 6.049614906311035
Validation loss: 6.099817091418851

Epoch: 6| Step: 4
Training loss: 4.762406826019287
Validation loss: 6.079345118614935

Epoch: 6| Step: 5
Training loss: 6.00457763671875
Validation loss: 6.049468922358687

Epoch: 6| Step: 6
Training loss: 6.414374351501465
Validation loss: 6.03708864027454

Epoch: 6| Step: 7
Training loss: 5.378092288970947
Validation loss: 6.006872536033712

Epoch: 6| Step: 8
Training loss: 5.81148624420166
Validation loss: 5.98842893620973

Epoch: 6| Step: 9
Training loss: 6.284430503845215
Validation loss: 5.968253904773343

Epoch: 6| Step: 10
Training loss: 4.223345756530762
Validation loss: 5.937805242435907

Epoch: 6| Step: 11
Training loss: 5.508803367614746
Validation loss: 5.9167187649716615

Epoch: 6| Step: 12
Training loss: 5.275283336639404
Validation loss: 5.893757594529019

Epoch: 6| Step: 13
Training loss: 5.372439384460449
Validation loss: 5.869287280626194

Epoch: 13| Step: 0
Training loss: 5.080832481384277
Validation loss: 5.84390946357481

Epoch: 6| Step: 1
Training loss: 5.492830753326416
Validation loss: 5.817774562425511

Epoch: 6| Step: 2
Training loss: 5.72194766998291
Validation loss: 5.7964914742336475

Epoch: 6| Step: 3
Training loss: 5.10146427154541
Validation loss: 5.760422598931097

Epoch: 6| Step: 4
Training loss: 6.011017799377441
Validation loss: 5.736838130540745

Epoch: 6| Step: 5
Training loss: 5.078158378601074
Validation loss: 5.7133529724613314

Epoch: 6| Step: 6
Training loss: 5.702438831329346
Validation loss: 5.689787864685059

Epoch: 6| Step: 7
Training loss: 5.01296329498291
Validation loss: 5.653344682467881

Epoch: 6| Step: 8
Training loss: 5.9376678466796875
Validation loss: 5.629202504311839

Epoch: 6| Step: 9
Training loss: 6.72255802154541
Validation loss: 5.593259990856212

Epoch: 6| Step: 10
Training loss: 4.748972415924072
Validation loss: 5.586219638906499

Epoch: 6| Step: 11
Training loss: 4.816550254821777
Validation loss: 5.5491090948863695

Epoch: 6| Step: 12
Training loss: 5.268489360809326
Validation loss: 5.523138205210368

Epoch: 6| Step: 13
Training loss: 5.051560401916504
Validation loss: 5.496157830761325

Epoch: 14| Step: 0
Training loss: 5.053642272949219
Validation loss: 5.47289841662171

Epoch: 6| Step: 1
Training loss: 3.536111831665039
Validation loss: 5.440402236036075

Epoch: 6| Step: 2
Training loss: 5.466893672943115
Validation loss: 5.417404810587565

Epoch: 6| Step: 3
Training loss: 5.930582523345947
Validation loss: 5.376276841727636

Epoch: 6| Step: 4
Training loss: 4.577204704284668
Validation loss: 5.341839046888454

Epoch: 6| Step: 5
Training loss: 6.116870403289795
Validation loss: 5.3145165545966035

Epoch: 6| Step: 6
Training loss: 5.697126865386963
Validation loss: 5.283837590166318

Epoch: 6| Step: 7
Training loss: 5.436822414398193
Validation loss: 5.244707640781198

Epoch: 6| Step: 8
Training loss: 3.920337677001953
Validation loss: 5.217596976987777

Epoch: 6| Step: 9
Training loss: 5.161718845367432
Validation loss: 5.1866739796053976

Epoch: 6| Step: 10
Training loss: 4.871379375457764
Validation loss: 5.151454828118765

Epoch: 6| Step: 11
Training loss: 4.590365409851074
Validation loss: 5.121847819256526

Epoch: 6| Step: 12
Training loss: 4.201328277587891
Validation loss: 5.083122145745062

Epoch: 6| Step: 13
Training loss: 6.307666301727295
Validation loss: 5.05958616605369

Epoch: 15| Step: 0
Training loss: 4.726162433624268
Validation loss: 5.02040837400703

Epoch: 6| Step: 1
Training loss: 4.079334735870361
Validation loss: 4.995390645919308

Epoch: 6| Step: 2
Training loss: 4.560851573944092
Validation loss: 4.95631383567728

Epoch: 6| Step: 3
Training loss: 5.284614562988281
Validation loss: 4.9359177568907375

Epoch: 6| Step: 4
Training loss: 3.720926523208618
Validation loss: 4.900151370674052

Epoch: 6| Step: 5
Training loss: 5.575525283813477
Validation loss: 4.871538408340946

Epoch: 6| Step: 6
Training loss: 3.4961531162261963
Validation loss: 4.827278439716626

Epoch: 6| Step: 7
Training loss: 6.3458356857299805
Validation loss: 4.793284693071919

Epoch: 6| Step: 8
Training loss: 3.9259986877441406
Validation loss: 4.760424634461762

Epoch: 6| Step: 9
Training loss: 4.294863224029541
Validation loss: 4.720764272956438

Epoch: 6| Step: 10
Training loss: 4.024725914001465
Validation loss: 4.694076681649813

Epoch: 6| Step: 11
Training loss: 4.214011192321777
Validation loss: 4.662315589125439

Epoch: 6| Step: 12
Training loss: 4.632563591003418
Validation loss: 4.621418968323739

Epoch: 6| Step: 13
Training loss: 4.797247409820557
Validation loss: 4.5893990147498345

Epoch: 16| Step: 0
Training loss: 3.18105149269104
Validation loss: 4.56253408616589

Epoch: 6| Step: 1
Training loss: 4.842547416687012
Validation loss: 4.524636078906315

Epoch: 6| Step: 2
Training loss: 5.4849042892456055
Validation loss: 4.480062905178275

Epoch: 6| Step: 3
Training loss: 4.574496269226074
Validation loss: 4.453376385473436

Epoch: 6| Step: 4
Training loss: 3.517040252685547
Validation loss: 4.404129492339267

Epoch: 6| Step: 5
Training loss: 3.808159589767456
Validation loss: 4.381879996227962

Epoch: 6| Step: 6
Training loss: 2.5227208137512207
Validation loss: 4.340284324461414

Epoch: 6| Step: 7
Training loss: 5.47607421875
Validation loss: 4.314566155915619

Epoch: 6| Step: 8
Training loss: 4.14229154586792
Validation loss: 4.266945474891252

Epoch: 6| Step: 9
Training loss: 4.516068458557129
Validation loss: 4.248734007599533

Epoch: 6| Step: 10
Training loss: 4.377174377441406
Validation loss: 4.1961350646070255

Epoch: 6| Step: 11
Training loss: 3.358185052871704
Validation loss: 4.175602694993378

Epoch: 6| Step: 12
Training loss: 3.688082218170166
Validation loss: 4.1192235023744646

Epoch: 6| Step: 13
Training loss: 3.7628278732299805
Validation loss: 4.0805655987032

Epoch: 17| Step: 0
Training loss: 3.6678218841552734
Validation loss: 4.075682214511338

Epoch: 6| Step: 1
Training loss: 3.9721851348876953
Validation loss: 4.017629144012287

Epoch: 6| Step: 2
Training loss: 2.3846237659454346
Validation loss: 3.9973300862055954

Epoch: 6| Step: 3
Training loss: 3.5143253803253174
Validation loss: 3.9640471294362056

Epoch: 6| Step: 4
Training loss: 2.819869041442871
Validation loss: 3.9282842579708306

Epoch: 6| Step: 5
Training loss: 4.8303351402282715
Validation loss: 3.9020799898332164

Epoch: 6| Step: 6
Training loss: 3.7111477851867676
Validation loss: 3.87709568905574

Epoch: 6| Step: 7
Training loss: 3.238750696182251
Validation loss: 3.832510153452555

Epoch: 6| Step: 8
Training loss: 4.631526470184326
Validation loss: 3.8011696774472474

Epoch: 6| Step: 9
Training loss: 2.9583237171173096
Validation loss: 3.7560841396290767

Epoch: 6| Step: 10
Training loss: 3.6121490001678467
Validation loss: 3.7015145517164663

Epoch: 6| Step: 11
Training loss: 3.8978641033172607
Validation loss: 3.68615714708964

Epoch: 6| Step: 12
Training loss: 3.7990803718566895
Validation loss: 3.656003875117148

Epoch: 6| Step: 13
Training loss: 3.19704270362854
Validation loss: 3.6187025885428152

Epoch: 18| Step: 0
Training loss: 2.9309539794921875
Validation loss: 3.5939953327178955

Epoch: 6| Step: 1
Training loss: 3.575284957885742
Validation loss: 3.542906330477807

Epoch: 6| Step: 2
Training loss: 3.062112808227539
Validation loss: 3.5098625536887877

Epoch: 6| Step: 3
Training loss: 4.4568376541137695
Validation loss: 3.4826704020141275

Epoch: 6| Step: 4
Training loss: 1.8784798383712769
Validation loss: 3.4380419485030638

Epoch: 6| Step: 5
Training loss: 2.539945602416992
Validation loss: 3.4234087928648917

Epoch: 6| Step: 6
Training loss: 4.144888877868652
Validation loss: 3.367727630881853

Epoch: 6| Step: 7
Training loss: 1.9791765213012695
Validation loss: 3.3542883011602584

Epoch: 6| Step: 8
Training loss: 3.119049549102783
Validation loss: 3.3173811717699935

Epoch: 6| Step: 9
Training loss: 3.291558265686035
Validation loss: 3.28721341266427

Epoch: 6| Step: 10
Training loss: 3.8485798835754395
Validation loss: 3.264826441323885

Epoch: 6| Step: 11
Training loss: 2.903048276901245
Validation loss: 3.2386400391978603

Epoch: 6| Step: 12
Training loss: 3.2618372440338135
Validation loss: 3.199722654076033

Epoch: 6| Step: 13
Training loss: 4.216882705688477
Validation loss: 3.1757355095237814

Epoch: 19| Step: 0
Training loss: 2.7617669105529785
Validation loss: 3.1531606387066584

Epoch: 6| Step: 1
Training loss: 3.551269292831421
Validation loss: 3.132919278196109

Epoch: 6| Step: 2
Training loss: 3.273059606552124
Validation loss: 3.10477509549869

Epoch: 6| Step: 3
Training loss: 3.1402416229248047
Validation loss: 3.070448378080963

Epoch: 6| Step: 4
Training loss: 3.4154839515686035
Validation loss: 3.0471366656723844

Epoch: 6| Step: 5
Training loss: 2.9560842514038086
Validation loss: 3.0020211845315914

Epoch: 6| Step: 6
Training loss: 2.556164026260376
Validation loss: 3.0028504017860658

Epoch: 6| Step: 7
Training loss: 1.7979588508605957
Validation loss: 2.940955105648246

Epoch: 6| Step: 8
Training loss: 2.591712474822998
Validation loss: 2.920088291168213

Epoch: 6| Step: 9
Training loss: 2.1642541885375977
Validation loss: 2.8938923446081017

Epoch: 6| Step: 10
Training loss: 3.284332036972046
Validation loss: 2.8672297385431107

Epoch: 6| Step: 11
Training loss: 3.304932117462158
Validation loss: 2.869066228148758

Epoch: 6| Step: 12
Training loss: 3.5756735801696777
Validation loss: 2.8164254055228284

Epoch: 6| Step: 13
Training loss: 2.7511980533599854
Validation loss: 2.799819543797483

Epoch: 20| Step: 0
Training loss: 1.8995821475982666
Validation loss: 2.7923674327070995

Epoch: 6| Step: 1
Training loss: 2.4235944747924805
Validation loss: 2.7696039369029384

Epoch: 6| Step: 2
Training loss: 3.141510486602783
Validation loss: 2.7402668665814143

Epoch: 6| Step: 3
Training loss: 2.483889579772949
Validation loss: 2.7175993868099746

Epoch: 6| Step: 4
Training loss: 2.469050884246826
Validation loss: 2.6958888141057824

Epoch: 6| Step: 5
Training loss: 1.9850318431854248
Validation loss: 2.7027729275406047

Epoch: 6| Step: 6
Training loss: 2.833273410797119
Validation loss: 2.6774619317823842

Epoch: 6| Step: 7
Training loss: 2.471485137939453
Validation loss: 2.663695109787808

Epoch: 6| Step: 8
Training loss: 2.1519064903259277
Validation loss: 2.6664073185254167

Epoch: 6| Step: 9
Training loss: 4.038478374481201
Validation loss: 2.652723063704788

Epoch: 6| Step: 10
Training loss: 3.1497931480407715
Validation loss: 2.6436626372798795

Epoch: 6| Step: 11
Training loss: 2.806535243988037
Validation loss: 2.6117914338265695

Epoch: 6| Step: 12
Training loss: 3.2057743072509766
Validation loss: 2.5938644562998125

Epoch: 6| Step: 13
Training loss: 2.4830386638641357
Validation loss: 2.5872878925774687

Epoch: 21| Step: 0
Training loss: 2.3462724685668945
Validation loss: 2.5989919990621586

Epoch: 6| Step: 1
Training loss: 2.844740390777588
Validation loss: 2.572632663993425

Epoch: 6| Step: 2
Training loss: 2.2416114807128906
Validation loss: 2.544215238222512

Epoch: 6| Step: 3
Training loss: 3.337770462036133
Validation loss: 2.547352462686518

Epoch: 6| Step: 4
Training loss: 2.5358352661132812
Validation loss: 2.5315934893905476

Epoch: 6| Step: 5
Training loss: 2.7331156730651855
Validation loss: 2.5010935952586513

Epoch: 6| Step: 6
Training loss: 2.5992343425750732
Validation loss: 2.4972321371878348

Epoch: 6| Step: 7
Training loss: 2.9397776126861572
Validation loss: 2.484814974569505

Epoch: 6| Step: 8
Training loss: 2.514662742614746
Validation loss: 2.473349573791668

Epoch: 6| Step: 9
Training loss: 2.535107374191284
Validation loss: 2.489144068892284

Epoch: 6| Step: 10
Training loss: 2.305565357208252
Validation loss: 2.432676169180101

Epoch: 6| Step: 11
Training loss: 2.07535457611084
Validation loss: 2.468144337336222

Epoch: 6| Step: 12
Training loss: 2.400887966156006
Validation loss: 2.4454129485673803

Epoch: 6| Step: 13
Training loss: 2.2270843982696533
Validation loss: 2.443685413688742

Epoch: 22| Step: 0
Training loss: 1.79624342918396
Validation loss: 2.4392545197599675

Epoch: 6| Step: 1
Training loss: 2.61067533493042
Validation loss: 2.4107203304126696

Epoch: 6| Step: 2
Training loss: 2.28939151763916
Validation loss: 2.4167905751095025

Epoch: 6| Step: 3
Training loss: 1.9712013006210327
Validation loss: 2.412449226584486

Epoch: 6| Step: 4
Training loss: 2.6189866065979004
Validation loss: 2.3861195707833893

Epoch: 6| Step: 5
Training loss: 3.516188859939575
Validation loss: 2.3940395514170327

Epoch: 6| Step: 6
Training loss: 2.734835624694824
Validation loss: 2.393731265939692

Epoch: 6| Step: 7
Training loss: 3.240229606628418
Validation loss: 2.395191800209784

Epoch: 6| Step: 8
Training loss: 1.7347716093063354
Validation loss: 2.3605778140406453

Epoch: 6| Step: 9
Training loss: 2.000433921813965
Validation loss: 2.3677332606366885

Epoch: 6| Step: 10
Training loss: 2.132516860961914
Validation loss: 2.371800007358674

Epoch: 6| Step: 11
Training loss: 2.7840781211853027
Validation loss: 2.3600578256832656

Epoch: 6| Step: 12
Training loss: 3.0470588207244873
Validation loss: 2.3642594378481627

Epoch: 6| Step: 13
Training loss: 3.38621187210083
Validation loss: 2.3596566261783725

Epoch: 23| Step: 0
Training loss: 2.1311964988708496
Validation loss: 2.3746285464174006

Epoch: 6| Step: 1
Training loss: 2.2985119819641113
Validation loss: 2.3543381690979004

Epoch: 6| Step: 2
Training loss: 2.4176535606384277
Validation loss: 2.340973800228488

Epoch: 6| Step: 3
Training loss: 2.865126609802246
Validation loss: 2.3776739028192337

Epoch: 6| Step: 4
Training loss: 2.813005208969116
Validation loss: 2.3711639758079284

Epoch: 6| Step: 5
Training loss: 2.7353434562683105
Validation loss: 2.341836693466351

Epoch: 6| Step: 6
Training loss: 2.463322639465332
Validation loss: 2.376610925120692

Epoch: 6| Step: 7
Training loss: 2.2404685020446777
Validation loss: 2.368731719191356

Epoch: 6| Step: 8
Training loss: 2.27459979057312
Validation loss: 2.3600364936295377

Epoch: 6| Step: 9
Training loss: 2.0859086513519287
Validation loss: 2.3547595342000327

Epoch: 6| Step: 10
Training loss: 2.5219202041625977
Validation loss: 2.3700993419975362

Epoch: 6| Step: 11
Training loss: 2.4157838821411133
Validation loss: 2.359381042500978

Epoch: 6| Step: 12
Training loss: 3.166959285736084
Validation loss: 2.372005434446437

Epoch: 6| Step: 13
Training loss: 3.1806576251983643
Validation loss: 2.3571728916578394

Epoch: 24| Step: 0
Training loss: 2.875199317932129
Validation loss: 2.339167059108775

Epoch: 6| Step: 1
Training loss: 2.146514892578125
Validation loss: 2.3455541082607803

Epoch: 6| Step: 2
Training loss: 3.1113057136535645
Validation loss: 2.37647670315158

Epoch: 6| Step: 3
Training loss: 2.641716480255127
Validation loss: 2.3560348736342562

Epoch: 6| Step: 4
Training loss: 2.658118963241577
Validation loss: 2.331917790956395

Epoch: 6| Step: 5
Training loss: 2.4964609146118164
Validation loss: 2.342671263602472

Epoch: 6| Step: 6
Training loss: 2.426673173904419
Validation loss: 2.3437884469186105

Epoch: 6| Step: 7
Training loss: 2.8400959968566895
Validation loss: 2.3524711029503935

Epoch: 6| Step: 8
Training loss: 1.981229543685913
Validation loss: 2.3225196638414936

Epoch: 6| Step: 9
Training loss: 2.540919780731201
Validation loss: 2.3452941704821844

Epoch: 6| Step: 10
Training loss: 2.516348123550415
Validation loss: 2.3228067736471854

Epoch: 6| Step: 11
Training loss: 2.2462029457092285
Validation loss: 2.3285306038395053

Epoch: 6| Step: 12
Training loss: 2.4625096321105957
Validation loss: 2.3703393564429334

Epoch: 6| Step: 13
Training loss: 2.2545576095581055
Validation loss: 2.3216610647016958

Epoch: 25| Step: 0
Training loss: 1.5254725217819214
Validation loss: 2.341468118852185

Epoch: 6| Step: 1
Training loss: 2.360427141189575
Validation loss: 2.3530674121713124

Epoch: 6| Step: 2
Training loss: 2.4436469078063965
Validation loss: 2.3692409146216606

Epoch: 6| Step: 3
Training loss: 2.4087629318237305
Validation loss: 2.379287694090156

Epoch: 6| Step: 4
Training loss: 1.4992995262145996
Validation loss: 2.3568795598963255

Epoch: 6| Step: 5
Training loss: 3.2243027687072754
Validation loss: 2.364201158605596

Epoch: 6| Step: 6
Training loss: 3.266573667526245
Validation loss: 2.3378198505729757

Epoch: 6| Step: 7
Training loss: 2.2640793323516846
Validation loss: 2.3520660118390153

Epoch: 6| Step: 8
Training loss: 2.0663464069366455
Validation loss: 2.341447480263249

Epoch: 6| Step: 9
Training loss: 2.6639022827148438
Validation loss: 2.3399612313957623

Epoch: 6| Step: 10
Training loss: 2.7471604347229004
Validation loss: 2.352374658789686

Epoch: 6| Step: 11
Training loss: 3.475144624710083
Validation loss: 2.313211993504596

Epoch: 6| Step: 12
Training loss: 2.6192996501922607
Validation loss: 2.3537997007369995

Epoch: 6| Step: 13
Training loss: 2.2868356704711914
Validation loss: 2.360866767103954

Epoch: 26| Step: 0
Training loss: 2.273530960083008
Validation loss: 2.3744209915079098

Epoch: 6| Step: 1
Training loss: 2.7155165672302246
Validation loss: 2.373335903690707

Epoch: 6| Step: 2
Training loss: 2.931837797164917
Validation loss: 2.362872733864733

Epoch: 6| Step: 3
Training loss: 2.461477041244507
Validation loss: 2.351328031991118

Epoch: 6| Step: 4
Training loss: 2.0922021865844727
Validation loss: 2.3775428033644155

Epoch: 6| Step: 5
Training loss: 3.556140184402466
Validation loss: 2.386443340650169

Epoch: 6| Step: 6
Training loss: 2.691493511199951
Validation loss: 2.363317366569273

Epoch: 6| Step: 7
Training loss: 2.4301276206970215
Validation loss: 2.34690466619307

Epoch: 6| Step: 8
Training loss: 2.3525748252868652
Validation loss: 2.3451093704469743

Epoch: 6| Step: 9
Training loss: 2.182037115097046
Validation loss: 2.368274739993516

Epoch: 6| Step: 10
Training loss: 1.7753775119781494
Validation loss: 2.373239019865631

Epoch: 6| Step: 11
Training loss: 2.4496705532073975
Validation loss: 2.3647083005597516

Epoch: 6| Step: 12
Training loss: 2.4556403160095215
Validation loss: 2.3589757796256774

Epoch: 6| Step: 13
Training loss: 2.6633076667785645
Validation loss: 2.371509341783421

Epoch: 27| Step: 0
Training loss: 2.3297080993652344
Validation loss: 2.3455309739676853

Epoch: 6| Step: 1
Training loss: 3.002359390258789
Validation loss: 2.3348650419583885

Epoch: 6| Step: 2
Training loss: 2.1761422157287598
Validation loss: 2.367035286400908

Epoch: 6| Step: 3
Training loss: 2.4639432430267334
Validation loss: 2.37420218734331

Epoch: 6| Step: 4
Training loss: 2.4665122032165527
Validation loss: 2.3677660598549792

Epoch: 6| Step: 5
Training loss: 2.9533262252807617
Validation loss: 2.359580393760435

Epoch: 6| Step: 6
Training loss: 2.3268558979034424
Validation loss: 2.338707349633658

Epoch: 6| Step: 7
Training loss: 2.6794185638427734
Validation loss: 2.355825719013009

Epoch: 6| Step: 8
Training loss: 2.06425142288208
Validation loss: 2.3501006582731843

Epoch: 6| Step: 9
Training loss: 2.60817551612854
Validation loss: 2.357265564703172

Epoch: 6| Step: 10
Training loss: 2.247457504272461
Validation loss: 2.3789970233876216

Epoch: 6| Step: 11
Training loss: 2.2670631408691406
Validation loss: 2.3427206495756745

Epoch: 6| Step: 12
Training loss: 2.528764247894287
Validation loss: 2.374636383466823

Epoch: 6| Step: 13
Training loss: 2.905228853225708
Validation loss: 2.358585569166368

Epoch: 28| Step: 0
Training loss: 2.2112693786621094
Validation loss: 2.3836681842803955

Epoch: 6| Step: 1
Training loss: 2.4902472496032715
Validation loss: 2.3451621609349407

Epoch: 6| Step: 2
Training loss: 2.922677993774414
Validation loss: 2.365514098957021

Epoch: 6| Step: 3
Training loss: 3.195202112197876
Validation loss: 2.336733166889478

Epoch: 6| Step: 4
Training loss: 2.2256197929382324
Validation loss: 2.372968483996648

Epoch: 6| Step: 5
Training loss: 1.8725783824920654
Validation loss: 2.3602753890457975

Epoch: 6| Step: 6
Training loss: 2.5499489307403564
Validation loss: 2.360916481223158

Epoch: 6| Step: 7
Training loss: 2.996058940887451
Validation loss: 2.328226258677821

Epoch: 6| Step: 8
Training loss: 2.430736541748047
Validation loss: 2.334798296292623

Epoch: 6| Step: 9
Training loss: 2.4564952850341797
Validation loss: 2.382272251190678

Epoch: 6| Step: 10
Training loss: 2.880490779876709
Validation loss: 2.3435036777168192

Epoch: 6| Step: 11
Training loss: 2.652912139892578
Validation loss: 2.3626007649206344

Epoch: 6| Step: 12
Training loss: 1.6710973978042603
Validation loss: 2.3263595360581593

Epoch: 6| Step: 13
Training loss: 2.1669187545776367
Validation loss: 2.351543923859955

Epoch: 29| Step: 0
Training loss: 1.7314993143081665
Validation loss: 2.3414265750556864

Epoch: 6| Step: 1
Training loss: 1.6444309949874878
Validation loss: 2.339581371635519

Epoch: 6| Step: 2
Training loss: 2.2000606060028076
Validation loss: 2.347356419409475

Epoch: 6| Step: 3
Training loss: 2.272705554962158
Validation loss: 2.348243208341701

Epoch: 6| Step: 4
Training loss: 2.7577364444732666
Validation loss: 2.324438518093478

Epoch: 6| Step: 5
Training loss: 2.230010509490967
Validation loss: 2.323201464068505

Epoch: 6| Step: 6
Training loss: 4.131298065185547
Validation loss: 2.3245083491007485

Epoch: 6| Step: 7
Training loss: 1.6061124801635742
Validation loss: 2.3234081870766095

Epoch: 6| Step: 8
Training loss: 2.960562229156494
Validation loss: 2.334625240295164

Epoch: 6| Step: 9
Training loss: 2.3999202251434326
Validation loss: 2.334497636364352

Epoch: 6| Step: 10
Training loss: 2.0817112922668457
Validation loss: 2.3543524588308027

Epoch: 6| Step: 11
Training loss: 3.048365354537964
Validation loss: 2.3483182281576176

Epoch: 6| Step: 12
Training loss: 3.2512407302856445
Validation loss: 2.3335640763723724

Epoch: 6| Step: 13
Training loss: 2.1894848346710205
Validation loss: 2.3303756226775465

Epoch: 30| Step: 0
Training loss: 2.8871779441833496
Validation loss: 2.311479389026601

Epoch: 6| Step: 1
Training loss: 1.386610746383667
Validation loss: 2.3590786854426065

Epoch: 6| Step: 2
Training loss: 3.1211187839508057
Validation loss: 2.3309126259178243

Epoch: 6| Step: 3
Training loss: 2.0095508098602295
Validation loss: 2.3506469547107653

Epoch: 6| Step: 4
Training loss: 2.1929869651794434
Validation loss: 2.3441675298957416

Epoch: 6| Step: 5
Training loss: 2.0009777545928955
Validation loss: 2.3553848522965626

Epoch: 6| Step: 6
Training loss: 1.8413209915161133
Validation loss: 2.329205451473113

Epoch: 6| Step: 7
Training loss: 3.1312789916992188
Validation loss: 2.3358652796796573

Epoch: 6| Step: 8
Training loss: 2.066840171813965
Validation loss: 2.3349583533502396

Epoch: 6| Step: 9
Training loss: 3.340933084487915
Validation loss: 2.340195120021861

Epoch: 6| Step: 10
Training loss: 2.3856754302978516
Validation loss: 2.3535404051503828

Epoch: 6| Step: 11
Training loss: 2.9680848121643066
Validation loss: 2.340522976331813

Epoch: 6| Step: 12
Training loss: 2.780073642730713
Validation loss: 2.336038943259947

Epoch: 6| Step: 13
Training loss: 2.4728634357452393
Validation loss: 2.3102526587824666

Epoch: 31| Step: 0
Training loss: 2.2324488162994385
Validation loss: 2.3263420904836347

Epoch: 6| Step: 1
Training loss: 2.8577170372009277
Validation loss: 2.34733905330781

Epoch: 6| Step: 2
Training loss: 3.347421646118164
Validation loss: 2.3397913004762385

Epoch: 6| Step: 3
Training loss: 3.0009777545928955
Validation loss: 2.3119676574583976

Epoch: 6| Step: 4
Training loss: 1.9668046236038208
Validation loss: 2.3556234144395396

Epoch: 6| Step: 5
Training loss: 2.4804041385650635
Validation loss: 2.337594950070945

Epoch: 6| Step: 6
Training loss: 2.262349843978882
Validation loss: 2.3548018393977994

Epoch: 6| Step: 7
Training loss: 2.4891552925109863
Validation loss: 2.3322826303461546

Epoch: 6| Step: 8
Training loss: 2.6774754524230957
Validation loss: 2.342419344891784

Epoch: 6| Step: 9
Training loss: 2.3646888732910156
Validation loss: 2.3452703491333993

Epoch: 6| Step: 10
Training loss: 2.2260513305664062
Validation loss: 2.314088959847727

Epoch: 6| Step: 11
Training loss: 1.924789309501648
Validation loss: 2.3238762937566286

Epoch: 6| Step: 12
Training loss: 2.057755947113037
Validation loss: 2.3445773739968576

Epoch: 6| Step: 13
Training loss: 2.7923359870910645
Validation loss: 2.3378466918904293

Epoch: 32| Step: 0
Training loss: 2.2339487075805664
Validation loss: 2.3295067510297223

Epoch: 6| Step: 1
Training loss: 2.9175097942352295
Validation loss: 2.310885303763933

Epoch: 6| Step: 2
Training loss: 2.7051169872283936
Validation loss: 2.333076379632437

Epoch: 6| Step: 3
Training loss: 2.875946044921875
Validation loss: 2.3359206722628687

Epoch: 6| Step: 4
Training loss: 1.915915846824646
Validation loss: 2.3470711502977597

Epoch: 6| Step: 5
Training loss: 2.3071250915527344
Validation loss: 2.3512308341200634

Epoch: 6| Step: 6
Training loss: 2.7268683910369873
Validation loss: 2.323128479783253

Epoch: 6| Step: 7
Training loss: 2.410595178604126
Validation loss: 2.3313798673691286

Epoch: 6| Step: 8
Training loss: 2.1317341327667236
Validation loss: 2.319812984876735

Epoch: 6| Step: 9
Training loss: 1.948133945465088
Validation loss: 2.3128491037635395

Epoch: 6| Step: 10
Training loss: 2.518308639526367
Validation loss: 2.334217738079768

Epoch: 6| Step: 11
Training loss: 2.855079174041748
Validation loss: 2.319854986283087

Epoch: 6| Step: 12
Training loss: 1.9541394710540771
Validation loss: 2.3050451201777302

Epoch: 6| Step: 13
Training loss: 3.134658098220825
Validation loss: 2.3273860895505516

Epoch: 33| Step: 0
Training loss: 3.2087533473968506
Validation loss: 2.3157523537194855

Epoch: 6| Step: 1
Training loss: 2.654263973236084
Validation loss: 2.323729427911902

Epoch: 6| Step: 2
Training loss: 2.114900588989258
Validation loss: 2.3273148126499628

Epoch: 6| Step: 3
Training loss: 2.340118408203125
Validation loss: 2.327195490560224

Epoch: 6| Step: 4
Training loss: 2.8760952949523926
Validation loss: 2.3153941964590423

Epoch: 6| Step: 5
Training loss: 3.1945157051086426
Validation loss: 2.343279343779369

Epoch: 6| Step: 6
Training loss: 2.5849761962890625
Validation loss: 2.3411782377509662

Epoch: 6| Step: 7
Training loss: 2.317998170852661
Validation loss: 2.3110988947653

Epoch: 6| Step: 8
Training loss: 2.7402737140655518
Validation loss: 2.318210071133029

Epoch: 6| Step: 9
Training loss: 2.172924518585205
Validation loss: 2.3224815450688845

Epoch: 6| Step: 10
Training loss: 1.5273756980895996
Validation loss: 2.3401419860060497

Epoch: 6| Step: 11
Training loss: 1.6061033010482788
Validation loss: 2.327337590597009

Epoch: 6| Step: 12
Training loss: 2.0871057510375977
Validation loss: 2.344385349622337

Epoch: 6| Step: 13
Training loss: 3.28106951713562
Validation loss: 2.303695588983515

Epoch: 34| Step: 0
Training loss: 1.6887544393539429
Validation loss: 2.321992266562677

Epoch: 6| Step: 1
Training loss: 2.804569721221924
Validation loss: 2.3191835572642665

Epoch: 6| Step: 2
Training loss: 2.9344518184661865
Validation loss: 2.3098463371235836

Epoch: 6| Step: 3
Training loss: 2.624302864074707
Validation loss: 2.2878138557557137

Epoch: 6| Step: 4
Training loss: 3.050746202468872
Validation loss: 2.315680573063512

Epoch: 6| Step: 5
Training loss: 1.8982830047607422
Validation loss: 2.316692380494969

Epoch: 6| Step: 6
Training loss: 1.992621660232544
Validation loss: 2.304618250939154

Epoch: 6| Step: 7
Training loss: 3.282099723815918
Validation loss: 2.3204279202286915

Epoch: 6| Step: 8
Training loss: 2.3661348819732666
Validation loss: 2.306443065725347

Epoch: 6| Step: 9
Training loss: 2.4874062538146973
Validation loss: 2.274285824068131

Epoch: 6| Step: 10
Training loss: 2.0406036376953125
Validation loss: 2.319505271091256

Epoch: 6| Step: 11
Training loss: 2.335475444793701
Validation loss: 2.3355027398755475

Epoch: 6| Step: 12
Training loss: 2.2626919746398926
Validation loss: 2.3288798716760453

Epoch: 6| Step: 13
Training loss: 2.32621693611145
Validation loss: 2.303680245594312

Epoch: 35| Step: 0
Training loss: 2.3653645515441895
Validation loss: 2.3208981367849533

Epoch: 6| Step: 1
Training loss: 2.960635185241699
Validation loss: 2.2955691609331357

Epoch: 6| Step: 2
Training loss: 1.8955063819885254
Validation loss: 2.322522219791207

Epoch: 6| Step: 3
Training loss: 3.073667526245117
Validation loss: 2.347332541660596

Epoch: 6| Step: 4
Training loss: 2.2946693897247314
Validation loss: 2.334117002384637

Epoch: 6| Step: 5
Training loss: 3.0503525733947754
Validation loss: 2.3231612636196997

Epoch: 6| Step: 6
Training loss: 1.783750295639038
Validation loss: 2.3355146044044086

Epoch: 6| Step: 7
Training loss: 2.573618173599243
Validation loss: 2.3580530240971553

Epoch: 6| Step: 8
Training loss: 2.442331314086914
Validation loss: 2.31593277377467

Epoch: 6| Step: 9
Training loss: 2.669783115386963
Validation loss: 2.35055741699793

Epoch: 6| Step: 10
Training loss: 1.7100448608398438
Validation loss: 2.322377097222113

Epoch: 6| Step: 11
Training loss: 3.069767475128174
Validation loss: 2.3398180674481135

Epoch: 6| Step: 12
Training loss: 1.8081555366516113
Validation loss: 2.3345482605759815

Epoch: 6| Step: 13
Training loss: 2.2913835048675537
Validation loss: 2.3276838307739585

Epoch: 36| Step: 0
Training loss: 3.0141046047210693
Validation loss: 2.307763639316764

Epoch: 6| Step: 1
Training loss: 2.6446480751037598
Validation loss: 2.3185312209590787

Epoch: 6| Step: 2
Training loss: 2.7278542518615723
Validation loss: 2.348486787529402

Epoch: 6| Step: 3
Training loss: 1.8765146732330322
Validation loss: 2.292166402263026

Epoch: 6| Step: 4
Training loss: 2.1975927352905273
Validation loss: 2.307928982601371

Epoch: 6| Step: 5
Training loss: 2.734680414199829
Validation loss: 2.306864784609887

Epoch: 6| Step: 6
Training loss: 1.9550647735595703
Validation loss: 2.3139420991302817

Epoch: 6| Step: 7
Training loss: 2.665691614151001
Validation loss: 2.326759707543158

Epoch: 6| Step: 8
Training loss: 2.5994200706481934
Validation loss: 2.3194424926593737

Epoch: 6| Step: 9
Training loss: 2.006580114364624
Validation loss: 2.3196461251986924

Epoch: 6| Step: 10
Training loss: 2.3145008087158203
Validation loss: 2.3084586487021497

Epoch: 6| Step: 11
Training loss: 2.3029227256774902
Validation loss: 2.307480248071814

Epoch: 6| Step: 12
Training loss: 2.1039044857025146
Validation loss: 2.3224138213742163

Epoch: 6| Step: 13
Training loss: 3.045283794403076
Validation loss: 2.3147310890177244

Epoch: 37| Step: 0
Training loss: 2.318835973739624
Validation loss: 2.3157276491965018

Epoch: 6| Step: 1
Training loss: 2.626089334487915
Validation loss: 2.320685577648942

Epoch: 6| Step: 2
Training loss: 2.871124744415283
Validation loss: 2.29820220188428

Epoch: 6| Step: 3
Training loss: 2.011430263519287
Validation loss: 2.2865889328782276

Epoch: 6| Step: 4
Training loss: 2.628941535949707
Validation loss: 2.308716333040627

Epoch: 6| Step: 5
Training loss: 2.5743374824523926
Validation loss: 2.297438140838377

Epoch: 6| Step: 6
Training loss: 2.7014122009277344
Validation loss: 2.277970338380465

Epoch: 6| Step: 7
Training loss: 2.39506459236145
Validation loss: 2.30994334015795

Epoch: 6| Step: 8
Training loss: 2.2222580909729004
Validation loss: 2.2930773035172494

Epoch: 6| Step: 9
Training loss: 2.431330680847168
Validation loss: 2.278507068593015

Epoch: 6| Step: 10
Training loss: 1.9807000160217285
Validation loss: 2.3048205144943728

Epoch: 6| Step: 11
Training loss: 2.5684773921966553
Validation loss: 2.3143723728836223

Epoch: 6| Step: 12
Training loss: 2.2857024669647217
Validation loss: 2.2976820263811337

Epoch: 6| Step: 13
Training loss: 1.9425697326660156
Validation loss: 2.2852113041826474

Epoch: 38| Step: 0
Training loss: 2.2957773208618164
Validation loss: 2.3012099496779905

Epoch: 6| Step: 1
Training loss: 1.7547109127044678
Validation loss: 2.3270859333776657

Epoch: 6| Step: 2
Training loss: 2.2679178714752197
Validation loss: 2.321168033025598

Epoch: 6| Step: 3
Training loss: 3.0263991355895996
Validation loss: 2.327953415532266

Epoch: 6| Step: 4
Training loss: 1.6058509349822998
Validation loss: 2.29637602836855

Epoch: 6| Step: 5
Training loss: 2.6954894065856934
Validation loss: 2.2927267807786182

Epoch: 6| Step: 6
Training loss: 2.5074856281280518
Validation loss: 2.3117985930494083

Epoch: 6| Step: 7
Training loss: 2.1498751640319824
Validation loss: 2.2887121887617212

Epoch: 6| Step: 8
Training loss: 3.0272278785705566
Validation loss: 2.284969537488876

Epoch: 6| Step: 9
Training loss: 1.8271304368972778
Validation loss: 2.271035773779756

Epoch: 6| Step: 10
Training loss: 2.7523186206817627
Validation loss: 2.3087584164834793

Epoch: 6| Step: 11
Training loss: 2.467933177947998
Validation loss: 2.2848114095708376

Epoch: 6| Step: 12
Training loss: 2.3962655067443848
Validation loss: 2.2888820068810576

Epoch: 6| Step: 13
Training loss: 3.918241262435913
Validation loss: 2.322820076378443

Epoch: 39| Step: 0
Training loss: 2.527454376220703
Validation loss: 2.3162867920373076

Epoch: 6| Step: 1
Training loss: 2.4278111457824707
Validation loss: 2.3201596249816236

Epoch: 6| Step: 2
Training loss: 2.488659381866455
Validation loss: 2.3175564478802424

Epoch: 6| Step: 3
Training loss: 2.4331228733062744
Validation loss: 2.304844053842688

Epoch: 6| Step: 4
Training loss: 2.629608631134033
Validation loss: 2.290281759795322

Epoch: 6| Step: 5
Training loss: 3.00871205329895
Validation loss: 2.3073313723328295

Epoch: 6| Step: 6
Training loss: 2.5018460750579834
Validation loss: 2.2769940719809583

Epoch: 6| Step: 7
Training loss: 2.4509830474853516
Validation loss: 2.283212596370328

Epoch: 6| Step: 8
Training loss: 2.157729148864746
Validation loss: 2.3172510464986167

Epoch: 6| Step: 9
Training loss: 1.941209316253662
Validation loss: 2.3097812014241375

Epoch: 6| Step: 10
Training loss: 2.7288448810577393
Validation loss: 2.3112922894057406

Epoch: 6| Step: 11
Training loss: 2.2630720138549805
Validation loss: 2.3012441460804274

Epoch: 6| Step: 12
Training loss: 2.018223524093628
Validation loss: 2.306975769740279

Epoch: 6| Step: 13
Training loss: 2.1169497966766357
Validation loss: 2.2743999419673795

Epoch: 40| Step: 0
Training loss: 3.0272457599639893
Validation loss: 2.2953115419674943

Epoch: 6| Step: 1
Training loss: 2.5382344722747803
Validation loss: 2.3245419815022457

Epoch: 6| Step: 2
Training loss: 2.611328601837158
Validation loss: 2.2921835530188774

Epoch: 6| Step: 3
Training loss: 2.297778844833374
Validation loss: 2.283883353715302

Epoch: 6| Step: 4
Training loss: 2.6008493900299072
Validation loss: 2.2699131965637207

Epoch: 6| Step: 5
Training loss: 3.2679929733276367
Validation loss: 2.2990561967254965

Epoch: 6| Step: 6
Training loss: 2.2711682319641113
Validation loss: 2.2953035011086413

Epoch: 6| Step: 7
Training loss: 2.1145219802856445
Validation loss: 2.2800650570982244

Epoch: 6| Step: 8
Training loss: 2.062389850616455
Validation loss: 2.280052092767531

Epoch: 6| Step: 9
Training loss: 1.8608603477478027
Validation loss: 2.3053749915092223

Epoch: 6| Step: 10
Training loss: 1.8007845878601074
Validation loss: 2.28548014292153

Epoch: 6| Step: 11
Training loss: 2.370666265487671
Validation loss: 2.300570341848558

Epoch: 6| Step: 12
Training loss: 2.433485507965088
Validation loss: 2.2921115531716296

Epoch: 6| Step: 13
Training loss: 1.8886858224868774
Validation loss: 2.267659133480441

Epoch: 41| Step: 0
Training loss: 2.4753589630126953
Validation loss: 2.289749922290925

Epoch: 6| Step: 1
Training loss: 2.0932319164276123
Validation loss: 2.291733108541017

Epoch: 6| Step: 2
Training loss: 2.5696163177490234
Validation loss: 2.2823035024827525

Epoch: 6| Step: 3
Training loss: 2.1075658798217773
Validation loss: 2.3040974293985674

Epoch: 6| Step: 4
Training loss: 2.5305697917938232
Validation loss: 2.284366894793767

Epoch: 6| Step: 5
Training loss: 2.586229085922241
Validation loss: 2.3094935545357327

Epoch: 6| Step: 6
Training loss: 2.2183053493499756
Validation loss: 2.2682718179559194

Epoch: 6| Step: 7
Training loss: 2.5161328315734863
Validation loss: 2.297492624610983

Epoch: 6| Step: 8
Training loss: 2.2321557998657227
Validation loss: 2.2770155783622497

Epoch: 6| Step: 9
Training loss: 2.4641780853271484
Validation loss: 2.301091847881194

Epoch: 6| Step: 10
Training loss: 2.2472729682922363
Validation loss: 2.311294489009406

Epoch: 6| Step: 11
Training loss: 2.815311908721924
Validation loss: 2.272000889624319

Epoch: 6| Step: 12
Training loss: 2.65763521194458
Validation loss: 2.2862239960701234

Epoch: 6| Step: 13
Training loss: 2.2645716667175293
Validation loss: 2.269984324773153

Epoch: 42| Step: 0
Training loss: 3.2723379135131836
Validation loss: 2.285457444447343

Epoch: 6| Step: 1
Training loss: 2.211174488067627
Validation loss: 2.268655461649741

Epoch: 6| Step: 2
Training loss: 1.9113677740097046
Validation loss: 2.284252899949269

Epoch: 6| Step: 3
Training loss: 1.7848279476165771
Validation loss: 2.3029436834396853

Epoch: 6| Step: 4
Training loss: 2.060140609741211
Validation loss: 2.2689187859976165

Epoch: 6| Step: 5
Training loss: 2.213454246520996
Validation loss: 2.291596522895239

Epoch: 6| Step: 6
Training loss: 3.258399724960327
Validation loss: 2.292030098617718

Epoch: 6| Step: 7
Training loss: 3.1270503997802734
Validation loss: 2.271795472791118

Epoch: 6| Step: 8
Training loss: 2.3084475994110107
Validation loss: 2.290346796794604

Epoch: 6| Step: 9
Training loss: 1.6387672424316406
Validation loss: 2.276072004789947

Epoch: 6| Step: 10
Training loss: 1.857609748840332
Validation loss: 2.296784767540552

Epoch: 6| Step: 11
Training loss: 1.9545671939849854
Validation loss: 2.2903114954630532

Epoch: 6| Step: 12
Training loss: 2.756179094314575
Validation loss: 2.3016281691930627

Epoch: 6| Step: 13
Training loss: 3.2970309257507324
Validation loss: 2.306810843047275

Epoch: 43| Step: 0
Training loss: 2.0193188190460205
Validation loss: 2.286361325171686

Epoch: 6| Step: 1
Training loss: 2.5044002532958984
Validation loss: 2.3024664155898558

Epoch: 6| Step: 2
Training loss: 2.077643632888794
Validation loss: 2.2801155556914625

Epoch: 6| Step: 3
Training loss: 2.815904140472412
Validation loss: 2.2718019895656134

Epoch: 6| Step: 4
Training loss: 1.7429884672164917
Validation loss: 2.240918879867882

Epoch: 6| Step: 5
Training loss: 1.8601644039154053
Validation loss: 2.288582303190744

Epoch: 6| Step: 6
Training loss: 2.6566944122314453
Validation loss: 2.2856012159778225

Epoch: 6| Step: 7
Training loss: 2.9806618690490723
Validation loss: 2.27678850389296

Epoch: 6| Step: 8
Training loss: 1.7602849006652832
Validation loss: 2.2964606900368967

Epoch: 6| Step: 9
Training loss: 2.840083360671997
Validation loss: 2.280909962551568

Epoch: 6| Step: 10
Training loss: 2.839712142944336
Validation loss: 2.273714757734729

Epoch: 6| Step: 11
Training loss: 2.4600882530212402
Validation loss: 2.291901998622443

Epoch: 6| Step: 12
Training loss: 2.708770990371704
Validation loss: 2.292053158565234

Epoch: 6| Step: 13
Training loss: 1.7342191934585571
Validation loss: 2.270494886623916

Epoch: 44| Step: 0
Training loss: 2.6099088191986084
Validation loss: 2.265051088025493

Epoch: 6| Step: 1
Training loss: 1.553273320198059
Validation loss: 2.2677918172651723

Epoch: 6| Step: 2
Training loss: 2.6131591796875
Validation loss: 2.2514315125762776

Epoch: 6| Step: 3
Training loss: 2.119354009628296
Validation loss: 2.2889627384883102

Epoch: 6| Step: 4
Training loss: 2.0680878162384033
Validation loss: 2.258727373615388

Epoch: 6| Step: 5
Training loss: 2.448093891143799
Validation loss: 2.2872187322185886

Epoch: 6| Step: 6
Training loss: 3.092336416244507
Validation loss: 2.2621377898800756

Epoch: 6| Step: 7
Training loss: 2.723532199859619
Validation loss: 2.280799901613625

Epoch: 6| Step: 8
Training loss: 2.08927845954895
Validation loss: 2.2669109041972826

Epoch: 6| Step: 9
Training loss: 2.9528980255126953
Validation loss: 2.2653041706290296

Epoch: 6| Step: 10
Training loss: 1.9666446447372437
Validation loss: 2.253682851791382

Epoch: 6| Step: 11
Training loss: 2.2488605976104736
Validation loss: 2.286962970610588

Epoch: 6| Step: 12
Training loss: 2.2720651626586914
Validation loss: 2.243728922259423

Epoch: 6| Step: 13
Training loss: 2.7292823791503906
Validation loss: 2.2622471394077426

Epoch: 45| Step: 0
Training loss: 2.1240668296813965
Validation loss: 2.275685489818614

Epoch: 6| Step: 1
Training loss: 2.029590129852295
Validation loss: 2.261728517470821

Epoch: 6| Step: 2
Training loss: 1.4250853061676025
Validation loss: 2.279062089099679

Epoch: 6| Step: 3
Training loss: 2.417731761932373
Validation loss: 2.25470636224234

Epoch: 6| Step: 4
Training loss: 2.3265154361724854
Validation loss: 2.2737285578122703

Epoch: 6| Step: 5
Training loss: 3.2365500926971436
Validation loss: 2.2822382962831886

Epoch: 6| Step: 6
Training loss: 3.110626697540283
Validation loss: 2.2632250350008727

Epoch: 6| Step: 7
Training loss: 1.7516473531723022
Validation loss: 2.258071408476881

Epoch: 6| Step: 8
Training loss: 1.6516865491867065
Validation loss: 2.269191021560341

Epoch: 6| Step: 9
Training loss: 2.482628107070923
Validation loss: 2.2637515734600764

Epoch: 6| Step: 10
Training loss: 2.408881664276123
Validation loss: 2.2663390098079557

Epoch: 6| Step: 11
Training loss: 2.146623373031616
Validation loss: 2.2640564774954193

Epoch: 6| Step: 12
Training loss: 2.9161221981048584
Validation loss: 2.2861320972442627

Epoch: 6| Step: 13
Training loss: 3.525226593017578
Validation loss: 2.2414640559945056

Epoch: 46| Step: 0
Training loss: 2.705965995788574
Validation loss: 2.240730870154596

Epoch: 6| Step: 1
Training loss: 2.005324602127075
Validation loss: 2.282001041596936

Epoch: 6| Step: 2
Training loss: 2.7237892150878906
Validation loss: 2.268615222746326

Epoch: 6| Step: 3
Training loss: 3.1063413619995117
Validation loss: 2.265436885177448

Epoch: 6| Step: 4
Training loss: 2.1155593395233154
Validation loss: 2.242055731434976

Epoch: 6| Step: 5
Training loss: 2.577150344848633
Validation loss: 2.2757671571546987

Epoch: 6| Step: 6
Training loss: 2.8086400032043457
Validation loss: 2.2336618336298133

Epoch: 6| Step: 7
Training loss: 1.039157509803772
Validation loss: 2.2641612470790906

Epoch: 6| Step: 8
Training loss: 1.7572791576385498
Validation loss: 2.274294727592058

Epoch: 6| Step: 9
Training loss: 2.47898006439209
Validation loss: 2.2752703876905542

Epoch: 6| Step: 10
Training loss: 1.855063796043396
Validation loss: 2.251850514001744

Epoch: 6| Step: 11
Training loss: 2.6555769443511963
Validation loss: 2.2487441185981996

Epoch: 6| Step: 12
Training loss: 3.0820870399475098
Validation loss: 2.263562474199521

Epoch: 6| Step: 13
Training loss: 2.086864471435547
Validation loss: 2.2652099978539253

Epoch: 47| Step: 0
Training loss: 2.6177053451538086
Validation loss: 2.2878896600456646

Epoch: 6| Step: 1
Training loss: 2.924226999282837
Validation loss: 2.2614771986520417

Epoch: 6| Step: 2
Training loss: 3.9626309871673584
Validation loss: 2.3040731773581555

Epoch: 6| Step: 3
Training loss: 2.223811149597168
Validation loss: 2.2803132662209133

Epoch: 6| Step: 4
Training loss: 2.086463689804077
Validation loss: 2.2591728805213847

Epoch: 6| Step: 5
Training loss: 2.0969202518463135
Validation loss: 2.254486027584281

Epoch: 6| Step: 6
Training loss: 1.838991403579712
Validation loss: 2.2521887825381373

Epoch: 6| Step: 7
Training loss: 2.8526031970977783
Validation loss: 2.2830767118802635

Epoch: 6| Step: 8
Training loss: 2.3513429164886475
Validation loss: 2.285340747525615

Epoch: 6| Step: 9
Training loss: 2.1032168865203857
Validation loss: 2.2675246436108827

Epoch: 6| Step: 10
Training loss: 2.3724865913391113
Validation loss: 2.2674202919006348

Epoch: 6| Step: 11
Training loss: 1.3755695819854736
Validation loss: 2.265412022990565

Epoch: 6| Step: 12
Training loss: 1.9395644664764404
Validation loss: 2.2932501146870274

Epoch: 6| Step: 13
Training loss: 1.9120652675628662
Validation loss: 2.25850849510521

Epoch: 48| Step: 0
Training loss: 2.265350818634033
Validation loss: 2.2528207071365847

Epoch: 6| Step: 1
Training loss: 3.23311185836792
Validation loss: 2.261390842417235

Epoch: 6| Step: 2
Training loss: 2.273648738861084
Validation loss: 2.266347614667749

Epoch: 6| Step: 3
Training loss: 2.8066821098327637
Validation loss: 2.2660129147191204

Epoch: 6| Step: 4
Training loss: 2.5105223655700684
Validation loss: 2.2667459518678728

Epoch: 6| Step: 5
Training loss: 2.392204523086548
Validation loss: 2.2649104543911514

Epoch: 6| Step: 6
Training loss: 1.4755043983459473
Validation loss: 2.2822681268056235

Epoch: 6| Step: 7
Training loss: 2.5713815689086914
Validation loss: 2.246344763745544

Epoch: 6| Step: 8
Training loss: 2.153806686401367
Validation loss: 2.249709552334201

Epoch: 6| Step: 9
Training loss: 2.625356674194336
Validation loss: 2.277027410845603

Epoch: 6| Step: 10
Training loss: 2.49019455909729
Validation loss: 2.240231554995301

Epoch: 6| Step: 11
Training loss: 2.00118350982666
Validation loss: 2.2293392676179127

Epoch: 6| Step: 12
Training loss: 2.1563289165496826
Validation loss: 2.2740889646673716

Epoch: 6| Step: 13
Training loss: 2.0178568363189697
Validation loss: 2.2480567757801344

Epoch: 49| Step: 0
Training loss: 2.3078112602233887
Validation loss: 2.2686388210583757

Epoch: 6| Step: 1
Training loss: 3.1300101280212402
Validation loss: 2.251737333113147

Epoch: 6| Step: 2
Training loss: 2.2491555213928223
Validation loss: 2.279982982143279

Epoch: 6| Step: 3
Training loss: 2.768496036529541
Validation loss: 2.2808211259944464

Epoch: 6| Step: 4
Training loss: 2.137355327606201
Validation loss: 2.243660262835923

Epoch: 6| Step: 5
Training loss: 2.160003423690796
Validation loss: 2.2225126963789745

Epoch: 6| Step: 6
Training loss: 2.0676519870758057
Validation loss: 2.2608631631379486

Epoch: 6| Step: 7
Training loss: 2.364436149597168
Validation loss: 2.2626163395502235

Epoch: 6| Step: 8
Training loss: 2.732196807861328
Validation loss: 2.261995671897806

Epoch: 6| Step: 9
Training loss: 1.1828628778457642
Validation loss: 2.2294485338272585

Epoch: 6| Step: 10
Training loss: 2.023517608642578
Validation loss: 2.271759010130359

Epoch: 6| Step: 11
Training loss: 2.785045623779297
Validation loss: 2.24618209561994

Epoch: 6| Step: 12
Training loss: 1.9832541942596436
Validation loss: 2.2788428414252495

Epoch: 6| Step: 13
Training loss: 2.932356595993042
Validation loss: 2.2271807962848293

Epoch: 50| Step: 0
Training loss: 1.8946738243103027
Validation loss: 2.2496412082384993

Epoch: 6| Step: 1
Training loss: 1.585030198097229
Validation loss: 2.2497219629185174

Epoch: 6| Step: 2
Training loss: 2.965327024459839
Validation loss: 2.2423850977292625

Epoch: 6| Step: 3
Training loss: 2.416708469390869
Validation loss: 2.2192998060616116

Epoch: 6| Step: 4
Training loss: 2.228821277618408
Validation loss: 2.2530498966093986

Epoch: 6| Step: 5
Training loss: 1.4942634105682373
Validation loss: 2.260509357657484

Epoch: 6| Step: 6
Training loss: 2.247802257537842
Validation loss: 2.2812570538572086

Epoch: 6| Step: 7
Training loss: 2.6745619773864746
Validation loss: 2.2677145875910276

Epoch: 6| Step: 8
Training loss: 2.00581693649292
Validation loss: 2.2650100236297934

Epoch: 6| Step: 9
Training loss: 2.6873276233673096
Validation loss: 2.2641474354651665

Epoch: 6| Step: 10
Training loss: 2.528221845626831
Validation loss: 2.2385229192754275

Epoch: 6| Step: 11
Training loss: 3.2183520793914795
Validation loss: 2.269037180049445

Epoch: 6| Step: 12
Training loss: 2.2536096572875977
Validation loss: 2.2558044413084626

Epoch: 6| Step: 13
Training loss: 2.442417860031128
Validation loss: 2.265593683847817

Testing loss: 2.043372705247667
