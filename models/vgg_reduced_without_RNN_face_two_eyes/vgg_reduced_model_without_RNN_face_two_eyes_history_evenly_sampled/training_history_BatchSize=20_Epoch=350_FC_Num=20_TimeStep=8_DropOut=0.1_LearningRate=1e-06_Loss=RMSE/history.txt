Epoch: 1| Step: 0
Training loss: 2.891513172513459
Validation loss: 3.004489117299338

Epoch: 5| Step: 1
Training loss: 3.425383698070029
Validation loss: 3.0026415360878143

Epoch: 5| Step: 2
Training loss: 3.80819984942225
Validation loss: 2.9995971891224267

Epoch: 5| Step: 3
Training loss: 3.883768067700043
Validation loss: 2.993870345503899

Epoch: 5| Step: 4
Training loss: 2.794862332033027
Validation loss: 2.9923738228667123

Epoch: 5| Step: 5
Training loss: 3.4246541760571882
Validation loss: 2.987229799331468

Epoch: 5| Step: 6
Training loss: 3.2821144055331617
Validation loss: 2.9855503163964685

Epoch: 5| Step: 7
Training loss: 3.052018113898723
Validation loss: 2.9830184668507336

Epoch: 5| Step: 8
Training loss: 3.082573479165674
Validation loss: 2.980846342565559

Epoch: 5| Step: 9
Training loss: 3.466830710662348
Validation loss: 2.97495251103483

Epoch: 5| Step: 10
Training loss: 2.78435428838594
Validation loss: 2.972195631000339

Epoch: 2| Step: 0
Training loss: 3.6211761827355393
Validation loss: 2.967663040178028

Epoch: 5| Step: 1
Training loss: 3.402284326045357
Validation loss: 2.967720107842722

Epoch: 5| Step: 2
Training loss: 2.8510715009647303
Validation loss: 2.9607093821215535

Epoch: 5| Step: 3
Training loss: 2.7455079062866794
Validation loss: 2.9596884479346843

Epoch: 5| Step: 4
Training loss: 3.3633841787930314
Validation loss: 2.9571179243562327

Epoch: 5| Step: 5
Training loss: 3.273066606654481
Validation loss: 2.953962908719545

Epoch: 5| Step: 6
Training loss: 3.650485458489268
Validation loss: 2.949346368651645

Epoch: 5| Step: 7
Training loss: 3.301819767747253
Validation loss: 2.948227466001032

Epoch: 5| Step: 8
Training loss: 3.0769561252286377
Validation loss: 2.944054126376472

Epoch: 5| Step: 9
Training loss: 3.1332050182230753
Validation loss: 2.9416270364720685

Epoch: 5| Step: 10
Training loss: 3.353694353356439
Validation loss: 2.940418858988964

Epoch: 3| Step: 0
Training loss: 3.24364613273011
Validation loss: 2.9365269452880836

Epoch: 5| Step: 1
Training loss: 2.9581253265180796
Validation loss: 2.9349066694105663

Epoch: 5| Step: 2
Training loss: 3.2639347064181954
Validation loss: 2.9327047442442127

Epoch: 5| Step: 3
Training loss: 3.0405398506874013
Validation loss: 2.9306232614541163

Epoch: 5| Step: 4
Training loss: 2.9284089006788645
Validation loss: 2.9250629707151186

Epoch: 5| Step: 5
Training loss: 3.3991452937955624
Validation loss: 2.9214052168459004

Epoch: 5| Step: 6
Training loss: 3.507566447644799
Validation loss: 2.9186411284717457

Epoch: 5| Step: 7
Training loss: 3.5520472520056594
Validation loss: 2.9158549912397356

Epoch: 5| Step: 8
Training loss: 3.501734031550964
Validation loss: 2.9128039633838583

Epoch: 5| Step: 9
Training loss: 2.8604100756327315
Validation loss: 2.9092675248772033

Epoch: 5| Step: 10
Training loss: 3.2505652596342554
Validation loss: 2.9060794419931772

Epoch: 4| Step: 0
Training loss: 3.0770302001938936
Validation loss: 2.903486898604643

Epoch: 5| Step: 1
Training loss: 3.265790579216586
Validation loss: 2.9027689748685086

Epoch: 5| Step: 2
Training loss: 3.54004094827536
Validation loss: 2.898498529206794

Epoch: 5| Step: 3
Training loss: 3.0977813964809235
Validation loss: 2.898225600155351

Epoch: 5| Step: 4
Training loss: 3.4081208577105535
Validation loss: 2.892947041274943

Epoch: 5| Step: 5
Training loss: 3.357169771521377
Validation loss: 2.8916349509689336

Epoch: 5| Step: 6
Training loss: 3.053507467187996
Validation loss: 2.887634427846591

Epoch: 5| Step: 7
Training loss: 3.446053976600418
Validation loss: 2.8848303878965824

Epoch: 5| Step: 8
Training loss: 2.984375479333649
Validation loss: 2.8813822823683486

Epoch: 5| Step: 9
Training loss: 2.593750735363224
Validation loss: 2.8807365723624225

Epoch: 5| Step: 10
Training loss: 3.4141236742767296
Validation loss: 2.877861010967045

Epoch: 5| Step: 0
Training loss: 2.931386551594341
Validation loss: 2.873329552962335

Epoch: 5| Step: 1
Training loss: 3.184791012169987
Validation loss: 2.872589195558272

Epoch: 5| Step: 2
Training loss: 2.8377086478668354
Validation loss: 2.86983848456018

Epoch: 5| Step: 3
Training loss: 3.0402418657759767
Validation loss: 2.867830847023706

Epoch: 5| Step: 4
Training loss: 2.892608786658052
Validation loss: 2.862393340854209

Epoch: 5| Step: 5
Training loss: 3.3611442697393925
Validation loss: 2.8646117971727043

Epoch: 5| Step: 6
Training loss: 3.8374351172910983
Validation loss: 2.86115916670712

Epoch: 5| Step: 7
Training loss: 3.6906348658727812
Validation loss: 2.8582359899628016

Epoch: 5| Step: 8
Training loss: 3.5463423139882306
Validation loss: 2.855160019298015

Epoch: 5| Step: 9
Training loss: 2.918877517561231
Validation loss: 2.8517872360928442

Epoch: 5| Step: 10
Training loss: 2.4397851062949543
Validation loss: 2.84845150994577

Epoch: 6| Step: 0
Training loss: 3.4249724561043178
Validation loss: 2.8473960538940153

Epoch: 5| Step: 1
Training loss: 3.382723694796386
Validation loss: 2.843337008184843

Epoch: 5| Step: 2
Training loss: 2.4904735255876203
Validation loss: 2.8412825526316805

Epoch: 5| Step: 3
Training loss: 3.13767160501081
Validation loss: 2.8415827443369808

Epoch: 5| Step: 4
Training loss: 2.8405099373354714
Validation loss: 2.8389302197301145

Epoch: 5| Step: 5
Training loss: 3.1521495206195085
Validation loss: 2.8327467007679648

Epoch: 5| Step: 6
Training loss: 2.478783607274321
Validation loss: 2.8286684219293114

Epoch: 5| Step: 7
Training loss: 3.25772233650711
Validation loss: 2.8275723082431634

Epoch: 5| Step: 8
Training loss: 3.340128140304252
Validation loss: 2.824993059340552

Epoch: 5| Step: 9
Training loss: 3.772018639737915
Validation loss: 2.8255190235395076

Epoch: 5| Step: 10
Training loss: 3.287672460405565
Validation loss: 2.818853114393275

Epoch: 7| Step: 0
Training loss: 3.764070435322037
Validation loss: 2.8172588854654648

Epoch: 5| Step: 1
Training loss: 3.108919810039157
Validation loss: 2.812797450444049

Epoch: 5| Step: 2
Training loss: 2.907551791778609
Validation loss: 2.810695647305836

Epoch: 5| Step: 3
Training loss: 3.1992425975912155
Validation loss: 2.806738016678064

Epoch: 5| Step: 4
Training loss: 3.4454716582958738
Validation loss: 2.8046913810778764

Epoch: 5| Step: 5
Training loss: 2.8375826180819685
Validation loss: 2.8028161793466073

Epoch: 5| Step: 6
Training loss: 2.8791459086029145
Validation loss: 2.798358394845248

Epoch: 5| Step: 7
Training loss: 3.221753395072265
Validation loss: 2.795365900381736

Epoch: 5| Step: 8
Training loss: 3.3712306696557186
Validation loss: 2.792035769172609

Epoch: 5| Step: 9
Training loss: 2.68390814703893
Validation loss: 2.7917257381379548

Epoch: 5| Step: 10
Training loss: 2.8878937886222187
Validation loss: 2.7844942322614425

Epoch: 8| Step: 0
Training loss: 2.8574989709994116
Validation loss: 2.786433158594416

Epoch: 5| Step: 1
Training loss: 2.8998042994270468
Validation loss: 2.780595402583707

Epoch: 5| Step: 2
Training loss: 3.0607582900516057
Validation loss: 2.7745502260042816

Epoch: 5| Step: 3
Training loss: 2.7471617877699877
Validation loss: 2.7760795592676466

Epoch: 5| Step: 4
Training loss: 3.3841223174189388
Validation loss: 2.7730279213627105

Epoch: 5| Step: 5
Training loss: 2.8845254414547816
Validation loss: 2.7666868490300134

Epoch: 5| Step: 6
Training loss: 3.3305520534276027
Validation loss: 2.7636648232146013

Epoch: 5| Step: 7
Training loss: 3.54847580331801
Validation loss: 2.763063945381536

Epoch: 5| Step: 8
Training loss: 3.257703308178357
Validation loss: 2.7621757736148242

Epoch: 5| Step: 9
Training loss: 3.1445614262430186
Validation loss: 2.7559406014501495

Epoch: 5| Step: 10
Training loss: 2.96695839879796
Validation loss: 2.753180968586697

Epoch: 9| Step: 0
Training loss: 2.9525242754578613
Validation loss: 2.753138951719508

Epoch: 5| Step: 1
Training loss: 3.206123995024548
Validation loss: 2.744832515247198

Epoch: 5| Step: 2
Training loss: 2.975544592755101
Validation loss: 2.744193578145025

Epoch: 5| Step: 3
Training loss: 2.8769077108389434
Validation loss: 2.7365631854889294

Epoch: 5| Step: 4
Training loss: 2.7526303629619613
Validation loss: 2.7357738604831665

Epoch: 5| Step: 5
Training loss: 3.3793291654136524
Validation loss: 2.729304254691607

Epoch: 5| Step: 6
Training loss: 2.891892603714892
Validation loss: 2.727152070430797

Epoch: 5| Step: 7
Training loss: 3.586834830580811
Validation loss: 2.722794617696304

Epoch: 5| Step: 8
Training loss: 2.639002374807708
Validation loss: 2.7203360921438877

Epoch: 5| Step: 9
Training loss: 3.4336051376553196
Validation loss: 2.7163799376406943

Epoch: 5| Step: 10
Training loss: 3.053222773381275
Validation loss: 2.7135073975524118

Epoch: 10| Step: 0
Training loss: 3.060687560333459
Validation loss: 2.7096428307693015

Epoch: 5| Step: 1
Training loss: 3.2221901296427844
Validation loss: 2.7057617536739156

Epoch: 5| Step: 2
Training loss: 3.1929624538298884
Validation loss: 2.7009286554260616

Epoch: 5| Step: 3
Training loss: 2.7706935149364567
Validation loss: 2.696501320990012

Epoch: 5| Step: 4
Training loss: 2.7936761560431
Validation loss: 2.6931294221677327

Epoch: 5| Step: 5
Training loss: 2.4635152244089693
Validation loss: 2.6871822881953773

Epoch: 5| Step: 6
Training loss: 3.169358180442839
Validation loss: 2.6850308529469524

Epoch: 5| Step: 7
Training loss: 3.1066853761177815
Validation loss: 2.687253116028906

Epoch: 5| Step: 8
Training loss: 3.6016408783499725
Validation loss: 2.6804729118942148

Epoch: 5| Step: 9
Training loss: 2.3197669213055327
Validation loss: 2.675775357736846

Epoch: 5| Step: 10
Training loss: 3.650192982000701
Validation loss: 2.671714199782694

Epoch: 11| Step: 0
Training loss: 2.9693188574029414
Validation loss: 2.666213662050314

Epoch: 5| Step: 1
Training loss: 2.4909483121810294
Validation loss: 2.6623280513735184

Epoch: 5| Step: 2
Training loss: 3.4925214705902925
Validation loss: 2.662314181266157

Epoch: 5| Step: 3
Training loss: 3.202449820465591
Validation loss: 2.657087169272415

Epoch: 5| Step: 4
Training loss: 3.634347374008288
Validation loss: 2.652393318430878

Epoch: 5| Step: 5
Training loss: 2.8796405658012265
Validation loss: 2.6514171812503924

Epoch: 5| Step: 6
Training loss: 2.623881237860572
Validation loss: 2.6482124984433

Epoch: 5| Step: 7
Training loss: 3.3903846479740705
Validation loss: 2.6426778911426996

Epoch: 5| Step: 8
Training loss: 2.882665284075598
Validation loss: 2.6378938342105456

Epoch: 5| Step: 9
Training loss: 2.9599762415576816
Validation loss: 2.6336816522955497

Epoch: 5| Step: 10
Training loss: 2.2233480171431714
Validation loss: 2.6295074422499285

Epoch: 12| Step: 0
Training loss: 3.0614893277107016
Validation loss: 2.6215871852579715

Epoch: 5| Step: 1
Training loss: 2.834859679986366
Validation loss: 2.6208572541416584

Epoch: 5| Step: 2
Training loss: 2.845860128057814
Validation loss: 2.6176265626820956

Epoch: 5| Step: 3
Training loss: 2.8943521750548307
Validation loss: 2.6130119091858077

Epoch: 5| Step: 4
Training loss: 2.829995564164099
Validation loss: 2.606049197758928

Epoch: 5| Step: 5
Training loss: 3.3461292394109377
Validation loss: 2.5978984420395936

Epoch: 5| Step: 6
Training loss: 2.241090619217282
Validation loss: 2.597236439869225

Epoch: 5| Step: 7
Training loss: 3.221489638510084
Validation loss: 2.5990954687683976

Epoch: 5| Step: 8
Training loss: 3.4245106201274544
Validation loss: 2.5929182389105496

Epoch: 5| Step: 9
Training loss: 2.838649829355275
Validation loss: 2.5860876011246745

Epoch: 5| Step: 10
Training loss: 3.0496040837703875
Validation loss: 2.584558261199035

Epoch: 13| Step: 0
Training loss: 3.0284119524186677
Validation loss: 2.576825736996269

Epoch: 5| Step: 1
Training loss: 2.739930356943563
Validation loss: 2.577416539851947

Epoch: 5| Step: 2
Training loss: 2.873184626095212
Validation loss: 2.565112774071755

Epoch: 5| Step: 3
Training loss: 2.9171706899476333
Validation loss: 2.5682644270068087

Epoch: 5| Step: 4
Training loss: 3.198658578571728
Validation loss: 2.5610596445209617

Epoch: 5| Step: 5
Training loss: 3.2379499203801236
Validation loss: 2.5560080717778004

Epoch: 5| Step: 6
Training loss: 2.929713216032969
Validation loss: 2.55224801679659

Epoch: 5| Step: 7
Training loss: 2.841491640877767
Validation loss: 2.5441955013829824

Epoch: 5| Step: 8
Training loss: 3.2346265022423824
Validation loss: 2.54104112390984

Epoch: 5| Step: 9
Training loss: 2.6292367985274194
Validation loss: 2.5419595486764264

Epoch: 5| Step: 10
Training loss: 2.574764211284866
Validation loss: 2.5402215348965913

Epoch: 14| Step: 0
Training loss: 3.2020899146928
Validation loss: 2.5336203405539424

Epoch: 5| Step: 1
Training loss: 3.1591932718023243
Validation loss: 2.5259366384799904

Epoch: 5| Step: 2
Training loss: 2.8587323910229663
Validation loss: 2.522939311985622

Epoch: 5| Step: 3
Training loss: 2.6142500605448666
Validation loss: 2.5223878524955636

Epoch: 5| Step: 4
Training loss: 2.70828116929119
Validation loss: 2.5097253850398156

Epoch: 5| Step: 5
Training loss: 2.9797909667159987
Validation loss: 2.5135742268481525

Epoch: 5| Step: 6
Training loss: 2.418173046448157
Validation loss: 2.5055210901627847

Epoch: 5| Step: 7
Training loss: 2.7900346189149072
Validation loss: 2.5041733271480364

Epoch: 5| Step: 8
Training loss: 3.1651140890906997
Validation loss: 2.498209994412514

Epoch: 5| Step: 9
Training loss: 2.9915495110172716
Validation loss: 2.5004075774335215

Epoch: 5| Step: 10
Training loss: 2.9394852443220247
Validation loss: 2.497108900220953

Epoch: 15| Step: 0
Training loss: 2.4208771649680556
Validation loss: 2.4956472219778596

Epoch: 5| Step: 1
Training loss: 2.9540571729619467
Validation loss: 2.4790869903652584

Epoch: 5| Step: 2
Training loss: 3.0069478959750677
Validation loss: 2.482768973952875

Epoch: 5| Step: 3
Training loss: 3.2103862057147814
Validation loss: 2.4785898784922655

Epoch: 5| Step: 4
Training loss: 2.861488436742039
Validation loss: 2.4727118050641663

Epoch: 5| Step: 5
Training loss: 2.7841863668917597
Validation loss: 2.472927261972449

Epoch: 5| Step: 6
Training loss: 2.444965862043648
Validation loss: 2.4685798016249447

Epoch: 5| Step: 7
Training loss: 3.1836180141905093
Validation loss: 2.462788365192614

Epoch: 5| Step: 8
Training loss: 2.5707675333943354
Validation loss: 2.4576287609524647

Epoch: 5| Step: 9
Training loss: 3.251198180950587
Validation loss: 2.463186070875732

Epoch: 5| Step: 10
Training loss: 2.6314061424337347
Validation loss: 2.4540685350943803

Epoch: 16| Step: 0
Training loss: 2.4120813036068998
Validation loss: 2.453141154344545

Epoch: 5| Step: 1
Training loss: 3.3362219374310063
Validation loss: 2.4592559304043036

Epoch: 5| Step: 2
Training loss: 2.697908516850675
Validation loss: 2.4508723177043645

Epoch: 5| Step: 3
Training loss: 3.1032170799707783
Validation loss: 2.451204520995465

Epoch: 5| Step: 4
Training loss: 3.006404081270169
Validation loss: 2.4528591622536715

Epoch: 5| Step: 5
Training loss: 2.887802973453828
Validation loss: 2.44551433710622

Epoch: 5| Step: 6
Training loss: 2.528300698190623
Validation loss: 2.438630729738269

Epoch: 5| Step: 7
Training loss: 2.7544019320638253
Validation loss: 2.438141313805052

Epoch: 5| Step: 8
Training loss: 2.4850656760918306
Validation loss: 2.4435192322200785

Epoch: 5| Step: 9
Training loss: 2.947101889297083
Validation loss: 2.4355565419988627

Epoch: 5| Step: 10
Training loss: 2.983433599935995
Validation loss: 2.4348371836361467

Epoch: 17| Step: 0
Training loss: 2.73239997380541
Validation loss: 2.433829217864453

Epoch: 5| Step: 1
Training loss: 2.9856908004629745
Validation loss: 2.427079726541342

Epoch: 5| Step: 2
Training loss: 1.726485928179557
Validation loss: 2.423820140541517

Epoch: 5| Step: 3
Training loss: 2.927618247102761
Validation loss: 2.4259195376686096

Epoch: 5| Step: 4
Training loss: 3.0731529705333336
Validation loss: 2.4231603561169366

Epoch: 5| Step: 5
Training loss: 2.725630811419608
Validation loss: 2.4253952530116196

Epoch: 5| Step: 6
Training loss: 3.0432172681132026
Validation loss: 2.4224093860851013

Epoch: 5| Step: 7
Training loss: 3.0498087525989557
Validation loss: 2.4409007887792646

Epoch: 5| Step: 8
Training loss: 2.2978437806989462
Validation loss: 2.4303822408626936

Epoch: 5| Step: 9
Training loss: 2.7552791555108316
Validation loss: 2.4212921340949727

Epoch: 5| Step: 10
Training loss: 3.5877533348035566
Validation loss: 2.408777185932223

Epoch: 18| Step: 0
Training loss: 2.550704697866649
Validation loss: 2.425264942131595

Epoch: 5| Step: 1
Training loss: 2.770199457004079
Validation loss: 2.4158246401924512

Epoch: 5| Step: 2
Training loss: 2.519314258309749
Validation loss: 2.4105666921931665

Epoch: 5| Step: 3
Training loss: 2.7873504256416535
Validation loss: 2.4206504083665825

Epoch: 5| Step: 4
Training loss: 3.159034482752636
Validation loss: 2.405900461831836

Epoch: 5| Step: 5
Training loss: 2.5995393968617173
Validation loss: 2.4186788803675814

Epoch: 5| Step: 6
Training loss: 3.2860207888595125
Validation loss: 2.426818415621931

Epoch: 5| Step: 7
Training loss: 2.97874166662769
Validation loss: 2.418914566998192

Epoch: 5| Step: 8
Training loss: 2.689142036037541
Validation loss: 2.4247393175036915

Epoch: 5| Step: 9
Training loss: 2.7259967730776635
Validation loss: 2.4101776384295537

Epoch: 5| Step: 10
Training loss: 2.796822659306425
Validation loss: 2.4083674414983847

Epoch: 19| Step: 0
Training loss: 2.9184664668185474
Validation loss: 2.422922365876014

Epoch: 5| Step: 1
Training loss: 2.757861431433384
Validation loss: 2.412958522653198

Epoch: 5| Step: 2
Training loss: 2.7475450134755244
Validation loss: 2.4171843389783203

Epoch: 5| Step: 3
Training loss: 2.978373619821813
Validation loss: 2.4124671344238866

Epoch: 5| Step: 4
Training loss: 2.75629285921782
Validation loss: 2.4149970355616834

Epoch: 5| Step: 5
Training loss: 2.677421657295883
Validation loss: 2.4110575416232654

Epoch: 5| Step: 6
Training loss: 3.1074927685776994
Validation loss: 2.4120228576887217

Epoch: 5| Step: 7
Training loss: 2.805187722654631
Validation loss: 2.4187448662054756

Epoch: 5| Step: 8
Training loss: 2.95451830738107
Validation loss: 2.4149533199971667

Epoch: 5| Step: 9
Training loss: 2.610642450852868
Validation loss: 2.4245595639237134

Epoch: 5| Step: 10
Training loss: 2.455414402281695
Validation loss: 2.4086765987242704

Epoch: 20| Step: 0
Training loss: 2.3733680539145294
Validation loss: 2.4169547220845864

Epoch: 5| Step: 1
Training loss: 2.6906707157234346
Validation loss: 2.4075671978788313

Epoch: 5| Step: 2
Training loss: 2.477426660955395
Validation loss: 2.4246389611016044

Epoch: 5| Step: 3
Training loss: 2.7056647040013138
Validation loss: 2.4099597266757895

Epoch: 5| Step: 4
Training loss: 2.4895001215309347
Validation loss: 2.408897075365143

Epoch: 5| Step: 5
Training loss: 2.740074278110093
Validation loss: 2.40888152892124

Epoch: 5| Step: 6
Training loss: 3.2043829703934055
Validation loss: 2.4148951399833662

Epoch: 5| Step: 7
Training loss: 2.9089838111193558
Validation loss: 2.4151592206584707

Epoch: 5| Step: 8
Training loss: 3.3227281825900863
Validation loss: 2.415012312813359

Epoch: 5| Step: 9
Training loss: 3.047073592536373
Validation loss: 2.41264744573215

Epoch: 5| Step: 10
Training loss: 2.766073675452888
Validation loss: 2.4071858267896458

Epoch: 21| Step: 0
Training loss: 2.7104292071494864
Validation loss: 2.4075748198927207

Epoch: 5| Step: 1
Training loss: 2.60798653764117
Validation loss: 2.418519537319736

Epoch: 5| Step: 2
Training loss: 2.5062329793528084
Validation loss: 2.4086185310583366

Epoch: 5| Step: 3
Training loss: 3.312570103317376
Validation loss: 2.4134703622560605

Epoch: 5| Step: 4
Training loss: 2.6868876269643436
Validation loss: 2.413286892065002

Epoch: 5| Step: 5
Training loss: 2.946938468112096
Validation loss: 2.414425256733413

Epoch: 5| Step: 6
Training loss: 3.0599289046860876
Validation loss: 2.415209577755605

Epoch: 5| Step: 7
Training loss: 3.0242275418247626
Validation loss: 2.4153655150555196

Epoch: 5| Step: 8
Training loss: 2.5913142521754926
Validation loss: 2.416141300853996

Epoch: 5| Step: 9
Training loss: 2.3980515756668175
Validation loss: 2.4209244539506405

Epoch: 5| Step: 10
Training loss: 2.890652713127289
Validation loss: 2.4185569090656935

Epoch: 22| Step: 0
Training loss: 2.9594740660701353
Validation loss: 2.406249252082699

Epoch: 5| Step: 1
Training loss: 3.07568169457643
Validation loss: 2.4091931570110616

Epoch: 5| Step: 2
Training loss: 3.074142125494405
Validation loss: 2.4198501214626975

Epoch: 5| Step: 3
Training loss: 2.565810879143141
Validation loss: 2.3990138379105472

Epoch: 5| Step: 4
Training loss: 2.917582086684785
Validation loss: 2.4096194571782483

Epoch: 5| Step: 5
Training loss: 2.826082957146918
Validation loss: 2.4085696699874783

Epoch: 5| Step: 6
Training loss: 2.7018249560735277
Validation loss: 2.414710361240615

Epoch: 5| Step: 7
Training loss: 2.943126403458302
Validation loss: 2.416707775443834

Epoch: 5| Step: 8
Training loss: 2.4215194933443605
Validation loss: 2.4113632798599784

Epoch: 5| Step: 9
Training loss: 2.540449778765598
Validation loss: 2.421373071967009

Epoch: 5| Step: 10
Training loss: 2.6345926939229742
Validation loss: 2.41717443305091

Epoch: 23| Step: 0
Training loss: 3.3284135433714126
Validation loss: 2.4117114155908745

Epoch: 5| Step: 1
Training loss: 2.679994081803805
Validation loss: 2.4099270081081694

Epoch: 5| Step: 2
Training loss: 2.9965576449354994
Validation loss: 2.4210618171915153

Epoch: 5| Step: 3
Training loss: 2.914474335478123
Validation loss: 2.401615614401139

Epoch: 5| Step: 4
Training loss: 2.927666620713673
Validation loss: 2.4152929452569505

Epoch: 5| Step: 5
Training loss: 2.6813513925583785
Validation loss: 2.409018545531415

Epoch: 5| Step: 6
Training loss: 2.569593056399084
Validation loss: 2.4058106618909334

Epoch: 5| Step: 7
Training loss: 2.8982981522369733
Validation loss: 2.4116057822588166

Epoch: 5| Step: 8
Training loss: 2.6538829354381415
Validation loss: 2.4069671840564895

Epoch: 5| Step: 9
Training loss: 2.1377495157158517
Validation loss: 2.402556210072106

Epoch: 5| Step: 10
Training loss: 2.831387319034721
Validation loss: 2.4140896435748895

Epoch: 24| Step: 0
Training loss: 2.9386425636996925
Validation loss: 2.4050605805676764

Epoch: 5| Step: 1
Training loss: 2.3658162290414584
Validation loss: 2.412148565145289

Epoch: 5| Step: 2
Training loss: 2.401376718794627
Validation loss: 2.408064290488809

Epoch: 5| Step: 3
Training loss: 2.997464220916785
Validation loss: 2.405471134476693

Epoch: 5| Step: 4
Training loss: 2.7316169125686804
Validation loss: 2.4097703651491695

Epoch: 5| Step: 5
Training loss: 2.9991170855514593
Validation loss: 2.4109994228434464

Epoch: 5| Step: 6
Training loss: 3.079112867436827
Validation loss: 2.4158002147379594

Epoch: 5| Step: 7
Training loss: 2.9857078891145887
Validation loss: 2.4128515361144456

Epoch: 5| Step: 8
Training loss: 2.9941280436889124
Validation loss: 2.423941098725375

Epoch: 5| Step: 9
Training loss: 2.3482604304581236
Validation loss: 2.418905889086428

Epoch: 5| Step: 10
Training loss: 2.707741824381731
Validation loss: 2.4117512095970848

Epoch: 25| Step: 0
Training loss: 2.8285294554432445
Validation loss: 2.4221538635879627

Epoch: 5| Step: 1
Training loss: 2.512506198400946
Validation loss: 2.4038648371700067

Epoch: 5| Step: 2
Training loss: 2.6837600589842636
Validation loss: 2.4019654761937526

Epoch: 5| Step: 3
Training loss: 2.325614856102218
Validation loss: 2.412173570663235

Epoch: 5| Step: 4
Training loss: 3.2316811072932055
Validation loss: 2.4014640466664035

Epoch: 5| Step: 5
Training loss: 3.1858041777504416
Validation loss: 2.416582791022459

Epoch: 5| Step: 6
Training loss: 2.8007220018576375
Validation loss: 2.4163121574105597

Epoch: 5| Step: 7
Training loss: 2.8099172813485525
Validation loss: 2.4147133572891275

Epoch: 5| Step: 8
Training loss: 2.9514769138349006
Validation loss: 2.4109303003001

Epoch: 5| Step: 9
Training loss: 2.6654612876644066
Validation loss: 2.4020338737509372

Epoch: 5| Step: 10
Training loss: 2.454888457116442
Validation loss: 2.4086275600193234

Epoch: 26| Step: 0
Training loss: 2.296727182212053
Validation loss: 2.417256297852798

Epoch: 5| Step: 1
Training loss: 2.3893069953630532
Validation loss: 2.4210102412368717

Epoch: 5| Step: 2
Training loss: 3.1800770813818766
Validation loss: 2.4037406674345223

Epoch: 5| Step: 3
Training loss: 3.0825682197688358
Validation loss: 2.414438198467705

Epoch: 5| Step: 4
Training loss: 3.2212641998203044
Validation loss: 2.4179852473646606

Epoch: 5| Step: 5
Training loss: 2.7649214544746226
Validation loss: 2.4098821107064863

Epoch: 5| Step: 6
Training loss: 3.1066129292054936
Validation loss: 2.4023917516779387

Epoch: 5| Step: 7
Training loss: 2.6626984356643826
Validation loss: 2.422771914164761

Epoch: 5| Step: 8
Training loss: 2.5426524913448048
Validation loss: 2.4164805814480457

Epoch: 5| Step: 9
Training loss: 2.967413029026945
Validation loss: 2.4163804098654493

Epoch: 5| Step: 10
Training loss: 2.0729956172560033
Validation loss: 2.413523119576634

Epoch: 27| Step: 0
Training loss: 2.9233964029234025
Validation loss: 2.4220482411316215

Epoch: 5| Step: 1
Training loss: 2.53934136839971
Validation loss: 2.404227677049202

Epoch: 5| Step: 2
Training loss: 2.7319811123967224
Validation loss: 2.395452900590308

Epoch: 5| Step: 3
Training loss: 2.3356884469552512
Validation loss: 2.408624373331075

Epoch: 5| Step: 4
Training loss: 2.8655801784125905
Validation loss: 2.409874413013233

Epoch: 5| Step: 5
Training loss: 2.6536567146195473
Validation loss: 2.4194961747208503

Epoch: 5| Step: 6
Training loss: 2.623150673614067
Validation loss: 2.4114586526200803

Epoch: 5| Step: 7
Training loss: 3.3650735472397213
Validation loss: 2.410873088694406

Epoch: 5| Step: 8
Training loss: 3.1101608433482313
Validation loss: 2.415678821330224

Epoch: 5| Step: 9
Training loss: 2.468485467958781
Validation loss: 2.4184130994354973

Epoch: 5| Step: 10
Training loss: 2.8035879716046663
Validation loss: 2.4115694631213787

Epoch: 28| Step: 0
Training loss: 3.1535283808909145
Validation loss: 2.399182776935954

Epoch: 5| Step: 1
Training loss: 2.7613368006300267
Validation loss: 2.407944692830637

Epoch: 5| Step: 2
Training loss: 2.715460354606372
Validation loss: 2.4156391387212817

Epoch: 5| Step: 3
Training loss: 2.7264564296781546
Validation loss: 2.412588370649997

Epoch: 5| Step: 4
Training loss: 2.48767120692274
Validation loss: 2.4262569505923404

Epoch: 5| Step: 5
Training loss: 2.490477450605871
Validation loss: 2.4045058962499075

Epoch: 5| Step: 6
Training loss: 2.8464398081821445
Validation loss: 2.4244438211018093

Epoch: 5| Step: 7
Training loss: 2.6747922085780464
Validation loss: 2.4124549838994604

Epoch: 5| Step: 8
Training loss: 2.5503657471396823
Validation loss: 2.417339306306439

Epoch: 5| Step: 9
Training loss: 2.8153450880727395
Validation loss: 2.393347194909248

Epoch: 5| Step: 10
Training loss: 3.2439288139670155
Validation loss: 2.4037116088193797

Epoch: 29| Step: 0
Training loss: 2.9604913783103313
Validation loss: 2.4116697287624222

Epoch: 5| Step: 1
Training loss: 2.7669384956872487
Validation loss: 2.4036636996257106

Epoch: 5| Step: 2
Training loss: 2.727660299707756
Validation loss: 2.416353974216958

Epoch: 5| Step: 3
Training loss: 2.9866113721747127
Validation loss: 2.4047293170788024

Epoch: 5| Step: 4
Training loss: 2.853620063807881
Validation loss: 2.4197444249341182

Epoch: 5| Step: 5
Training loss: 2.706727378270808
Validation loss: 2.4177608884051445

Epoch: 5| Step: 6
Training loss: 2.366992199587167
Validation loss: 2.4100052247135246

Epoch: 5| Step: 7
Training loss: 3.052948986278248
Validation loss: 2.4133321085462023

Epoch: 5| Step: 8
Training loss: 2.8065830296478187
Validation loss: 2.4170441429940444

Epoch: 5| Step: 9
Training loss: 2.5085898647319844
Validation loss: 2.4135386605528413

Epoch: 5| Step: 10
Training loss: 2.685138196887277
Validation loss: 2.4092659642779273

Epoch: 30| Step: 0
Training loss: 2.841528223716808
Validation loss: 2.4183771692782265

Epoch: 5| Step: 1
Training loss: 2.7112031746000116
Validation loss: 2.409894613554694

Epoch: 5| Step: 2
Training loss: 2.5746812419442584
Validation loss: 2.41105087162901

Epoch: 5| Step: 3
Training loss: 2.9823102749052897
Validation loss: 2.4188310392153896

Epoch: 5| Step: 4
Training loss: 2.6075340675476575
Validation loss: 2.4070176880422243

Epoch: 5| Step: 5
Training loss: 2.575399541875584
Validation loss: 2.4043533314435095

Epoch: 5| Step: 6
Training loss: 2.908626282228504
Validation loss: 2.4173863983109807

Epoch: 5| Step: 7
Training loss: 3.050334668168329
Validation loss: 2.4127022149415165

Epoch: 5| Step: 8
Training loss: 3.0933746726737694
Validation loss: 2.395887263164998

Epoch: 5| Step: 9
Training loss: 2.2266162531203415
Validation loss: 2.400618427082214

Epoch: 5| Step: 10
Training loss: 2.7293677996030974
Validation loss: 2.4217468725337996

Epoch: 31| Step: 0
Training loss: 2.5964899872532246
Validation loss: 2.4126670843301854

Epoch: 5| Step: 1
Training loss: 2.4213439359152704
Validation loss: 2.3994218386260977

Epoch: 5| Step: 2
Training loss: 2.4009488653976265
Validation loss: 2.409270757932818

Epoch: 5| Step: 3
Training loss: 2.37956591951169
Validation loss: 2.4112312122940907

Epoch: 5| Step: 4
Training loss: 2.949949141241775
Validation loss: 2.4254230614419123

Epoch: 5| Step: 5
Training loss: 2.67871075949006
Validation loss: 2.415717020744096

Epoch: 5| Step: 6
Training loss: 2.5537856257003426
Validation loss: 2.4008353489946432

Epoch: 5| Step: 7
Training loss: 2.658898323631454
Validation loss: 2.4179824663579272

Epoch: 5| Step: 8
Training loss: 2.9216381935811104
Validation loss: 2.410354888745752

Epoch: 5| Step: 9
Training loss: 3.3775400563991194
Validation loss: 2.406332428224466

Epoch: 5| Step: 10
Training loss: 3.313775446796598
Validation loss: 2.407442752683667

Epoch: 32| Step: 0
Training loss: 2.7948183137806035
Validation loss: 2.410255016199838

Epoch: 5| Step: 1
Training loss: 2.8048491789989622
Validation loss: 2.4036825007917755

Epoch: 5| Step: 2
Training loss: 3.061444314667357
Validation loss: 2.4162278775939803

Epoch: 5| Step: 3
Training loss: 2.517604357195812
Validation loss: 2.406667851259805

Epoch: 5| Step: 4
Training loss: 3.0082376551185
Validation loss: 2.4272845108865884

Epoch: 5| Step: 5
Training loss: 2.9132677891717713
Validation loss: 2.4185552936438617

Epoch: 5| Step: 6
Training loss: 2.6461871553868272
Validation loss: 2.4005487931036535

Epoch: 5| Step: 7
Training loss: 2.7208998500137653
Validation loss: 2.399132545063079

Epoch: 5| Step: 8
Training loss: 2.812672673328921
Validation loss: 2.414249561991242

Epoch: 5| Step: 9
Training loss: 2.576373713455223
Validation loss: 2.410373649419294

Epoch: 5| Step: 10
Training loss: 2.511439947195218
Validation loss: 2.405205423050306

Epoch: 33| Step: 0
Training loss: 2.8030092961854325
Validation loss: 2.4150599055859123

Epoch: 5| Step: 1
Training loss: 2.9288997964490284
Validation loss: 2.4060314437721217

Epoch: 5| Step: 2
Training loss: 2.673824736632714
Validation loss: 2.406471190070117

Epoch: 5| Step: 3
Training loss: 3.2450616437467423
Validation loss: 2.403507906020895

Epoch: 5| Step: 4
Training loss: 2.741049853879465
Validation loss: 2.4124777578469536

Epoch: 5| Step: 5
Training loss: 2.6557316891486864
Validation loss: 2.40982948165303

Epoch: 5| Step: 6
Training loss: 2.8534706733604303
Validation loss: 2.418864662221275

Epoch: 5| Step: 7
Training loss: 3.0187418746049097
Validation loss: 2.422552385976869

Epoch: 5| Step: 8
Training loss: 2.4298072123090875
Validation loss: 2.4065418383391584

Epoch: 5| Step: 9
Training loss: 2.459789480645248
Validation loss: 2.4021984991180116

Epoch: 5| Step: 10
Training loss: 2.427186224288674
Validation loss: 2.4070178051998443

Epoch: 34| Step: 0
Training loss: 2.664491501439379
Validation loss: 2.4090244666477103

Epoch: 5| Step: 1
Training loss: 2.5128554742727482
Validation loss: 2.4148014311734807

Epoch: 5| Step: 2
Training loss: 2.3681698010561916
Validation loss: 2.4129374414869784

Epoch: 5| Step: 3
Training loss: 2.894188740963995
Validation loss: 2.396574816428955

Epoch: 5| Step: 4
Training loss: 2.6996735163495513
Validation loss: 2.4201565756740266

Epoch: 5| Step: 5
Training loss: 3.2469190519279887
Validation loss: 2.4007801552970016

Epoch: 5| Step: 6
Training loss: 2.5777792958916472
Validation loss: 2.425329911617174

Epoch: 5| Step: 7
Training loss: 2.70833460489879
Validation loss: 2.40842233997149

Epoch: 5| Step: 8
Training loss: 2.6425310287169634
Validation loss: 2.3999675912403604

Epoch: 5| Step: 9
Training loss: 2.7782647045181967
Validation loss: 2.4177518087248138

Epoch: 5| Step: 10
Training loss: 3.1620543335523825
Validation loss: 2.4102797424830564

Epoch: 35| Step: 0
Training loss: 3.454878556012062
Validation loss: 2.416738643430106

Epoch: 5| Step: 1
Training loss: 2.7731392713501504
Validation loss: 2.4084576538434703

Epoch: 5| Step: 2
Training loss: 2.9961395856989355
Validation loss: 2.4124537193232607

Epoch: 5| Step: 3
Training loss: 2.8022992264821456
Validation loss: 2.410056046913385

Epoch: 5| Step: 4
Training loss: 2.4677806834517186
Validation loss: 2.415060625298118

Epoch: 5| Step: 5
Training loss: 2.341762768367404
Validation loss: 2.4024203802066224

Epoch: 5| Step: 6
Training loss: 2.646228330268484
Validation loss: 2.402030860820049

Epoch: 5| Step: 7
Training loss: 2.1496262469453606
Validation loss: 2.4088476377940253

Epoch: 5| Step: 8
Training loss: 2.487463896216234
Validation loss: 2.411840914843685

Epoch: 5| Step: 9
Training loss: 3.072056864480388
Validation loss: 2.414068996007733

Epoch: 5| Step: 10
Training loss: 2.98270917007091
Validation loss: 2.4079504664709286

Epoch: 36| Step: 0
Training loss: 3.0715101395988733
Validation loss: 2.412128308020005

Epoch: 5| Step: 1
Training loss: 2.4257358417775983
Validation loss: 2.3990266260842676

Epoch: 5| Step: 2
Training loss: 2.5314544783524076
Validation loss: 2.4069746865503383

Epoch: 5| Step: 3
Training loss: 2.677450686729936
Validation loss: 2.3995553318058516

Epoch: 5| Step: 4
Training loss: 3.391712488963073
Validation loss: 2.422530457038616

Epoch: 5| Step: 5
Training loss: 2.656319920236687
Validation loss: 2.4130834472543534

Epoch: 5| Step: 6
Training loss: 2.7740421119689316
Validation loss: 2.40540272061899

Epoch: 5| Step: 7
Training loss: 2.6209513004440423
Validation loss: 2.3989985506798606

Epoch: 5| Step: 8
Training loss: 2.773719880678463
Validation loss: 2.414618295168014

Epoch: 5| Step: 9
Training loss: 2.4853028298267446
Validation loss: 2.413426273278711

Epoch: 5| Step: 10
Training loss: 2.753181784279123
Validation loss: 2.407018805299657

Epoch: 37| Step: 0
Training loss: 3.566969092788881
Validation loss: 2.4012982179333138

Epoch: 5| Step: 1
Training loss: 2.6672986195708113
Validation loss: 2.413030340879298

Epoch: 5| Step: 2
Training loss: 3.2819419494553412
Validation loss: 2.4113086444991225

Epoch: 5| Step: 3
Training loss: 2.831682023187691
Validation loss: 2.4168460540330923

Epoch: 5| Step: 4
Training loss: 2.591615097007107
Validation loss: 2.4000102894059983

Epoch: 5| Step: 5
Training loss: 2.7900233390132723
Validation loss: 2.4075801461306297

Epoch: 5| Step: 6
Training loss: 2.3363146015050735
Validation loss: 2.4205468809039377

Epoch: 5| Step: 7
Training loss: 2.2225100397112794
Validation loss: 2.4140924141988376

Epoch: 5| Step: 8
Training loss: 2.7049272295458655
Validation loss: 2.4063997833336948

Epoch: 5| Step: 9
Training loss: 2.340483563661061
Validation loss: 2.4037064243910473

Epoch: 5| Step: 10
Training loss: 2.6465654536703838
Validation loss: 2.4034652150591564

Epoch: 38| Step: 0
Training loss: 2.4541008824424546
Validation loss: 2.403993042186732

Epoch: 5| Step: 1
Training loss: 2.92393135698896
Validation loss: 2.3940807359620226

Epoch: 5| Step: 2
Training loss: 2.8745818455991716
Validation loss: 2.4107315707212362

Epoch: 5| Step: 3
Training loss: 3.1259295797586137
Validation loss: 2.4168383382120044

Epoch: 5| Step: 4
Training loss: 2.4949670675546747
Validation loss: 2.410331485294805

Epoch: 5| Step: 5
Training loss: 3.006089388230859
Validation loss: 2.3973875118699324

Epoch: 5| Step: 6
Training loss: 2.442536749978165
Validation loss: 2.4060232372318873

Epoch: 5| Step: 7
Training loss: 2.668726175456495
Validation loss: 2.402591819837539

Epoch: 5| Step: 8
Training loss: 2.3689937939157995
Validation loss: 2.4047831291397155

Epoch: 5| Step: 9
Training loss: 2.8735633245884666
Validation loss: 2.4116922741381193

Epoch: 5| Step: 10
Training loss: 2.889484737357911
Validation loss: 2.429654263119799

Epoch: 39| Step: 0
Training loss: 2.585408413054402
Validation loss: 2.4107985615316405

Epoch: 5| Step: 1
Training loss: 2.86383176249786
Validation loss: 2.408060439804411

Epoch: 5| Step: 2
Training loss: 3.144102837421625
Validation loss: 2.412167100372162

Epoch: 5| Step: 3
Training loss: 1.9930711170376185
Validation loss: 2.408701637092859

Epoch: 5| Step: 4
Training loss: 2.979244435680251
Validation loss: 2.4118103689619006

Epoch: 5| Step: 5
Training loss: 2.8581270089675246
Validation loss: 2.40888646807821

Epoch: 5| Step: 6
Training loss: 2.691774207487366
Validation loss: 2.4102127191701275

Epoch: 5| Step: 7
Training loss: 3.1820212757638915
Validation loss: 2.4088990782608746

Epoch: 5| Step: 8
Training loss: 2.5174133388903863
Validation loss: 2.409146663575224

Epoch: 5| Step: 9
Training loss: 2.6251336926520286
Validation loss: 2.4078808209446785

Epoch: 5| Step: 10
Training loss: 2.4968340854849473
Validation loss: 2.41585748581552

Epoch: 40| Step: 0
Training loss: 2.7913732706636596
Validation loss: 2.407588833985212

Epoch: 5| Step: 1
Training loss: 2.8200268376202877
Validation loss: 2.4150284376053706

Epoch: 5| Step: 2
Training loss: 2.2791910155098156
Validation loss: 2.4235027928120436

Epoch: 5| Step: 3
Training loss: 3.068823378048854
Validation loss: 2.4064118056969375

Epoch: 5| Step: 4
Training loss: 2.684359289973765
Validation loss: 2.400277723032219

Epoch: 5| Step: 5
Training loss: 3.0594499931456767
Validation loss: 2.4028481454918613

Epoch: 5| Step: 6
Training loss: 2.4932108246018556
Validation loss: 2.407373211739358

Epoch: 5| Step: 7
Training loss: 2.826502044520439
Validation loss: 2.412970419905801

Epoch: 5| Step: 8
Training loss: 2.6016934565212178
Validation loss: 2.4041863584313576

Epoch: 5| Step: 9
Training loss: 3.0698696914006263
Validation loss: 2.394165462926777

Epoch: 5| Step: 10
Training loss: 2.190575209200055
Validation loss: 2.3974336601917554

Epoch: 41| Step: 0
Training loss: 2.4340194893074734
Validation loss: 2.4172166697762787

Epoch: 5| Step: 1
Training loss: 2.780911199957809
Validation loss: 2.4047418072728006

Epoch: 5| Step: 2
Training loss: 2.392806310866135
Validation loss: 2.4150826793840876

Epoch: 5| Step: 3
Training loss: 2.956141792881658
Validation loss: 2.4015270612086645

Epoch: 5| Step: 4
Training loss: 3.056164630719529
Validation loss: 2.4080050103460415

Epoch: 5| Step: 5
Training loss: 2.8733844364280317
Validation loss: 2.4308123035058324

Epoch: 5| Step: 6
Training loss: 2.9203967266478754
Validation loss: 2.4140833355882285

Epoch: 5| Step: 7
Training loss: 2.854208692997692
Validation loss: 2.422448573631932

Epoch: 5| Step: 8
Training loss: 2.42888537349177
Validation loss: 2.396377226382991

Epoch: 5| Step: 9
Training loss: 2.5858239094198474
Validation loss: 2.4218863654688687

Epoch: 5| Step: 10
Training loss: 2.697632871648582
Validation loss: 2.4145345704513197

Epoch: 42| Step: 0
Training loss: 2.4271350467613635
Validation loss: 2.3991320759608814

Epoch: 5| Step: 1
Training loss: 2.77967798618449
Validation loss: 2.408077354238407

Epoch: 5| Step: 2
Training loss: 2.6321944691433177
Validation loss: 2.4035530814142425

Epoch: 5| Step: 3
Training loss: 2.243724123664769
Validation loss: 2.4067721275178067

Epoch: 5| Step: 4
Training loss: 2.7230020355485975
Validation loss: 2.4099002006143664

Epoch: 5| Step: 5
Training loss: 2.8539776333398277
Validation loss: 2.4015768490964438

Epoch: 5| Step: 6
Training loss: 2.614082795113937
Validation loss: 2.4153899788699613

Epoch: 5| Step: 7
Training loss: 3.042082475084672
Validation loss: 2.414873197776374

Epoch: 5| Step: 8
Training loss: 2.7408375256387347
Validation loss: 2.403329505370641

Epoch: 5| Step: 9
Training loss: 2.6208228526994977
Validation loss: 2.412583349281007

Epoch: 5| Step: 10
Training loss: 3.3701931666583773
Validation loss: 2.4036685972433793

Epoch: 43| Step: 0
Training loss: 2.6588835283402417
Validation loss: 2.4104372063775235

Epoch: 5| Step: 1
Training loss: 2.487907728968035
Validation loss: 2.4209545851579892

Epoch: 5| Step: 2
Training loss: 2.819843623106937
Validation loss: 2.4074738395611393

Epoch: 5| Step: 3
Training loss: 2.9587150828884194
Validation loss: 2.4169426360177724

Epoch: 5| Step: 4
Training loss: 3.0857786499859294
Validation loss: 2.412826362309291

Epoch: 5| Step: 5
Training loss: 2.7966818289938726
Validation loss: 2.4067127159509627

Epoch: 5| Step: 6
Training loss: 2.5317565976163614
Validation loss: 2.412180205669385

Epoch: 5| Step: 7
Training loss: 2.4802682390045137
Validation loss: 2.404321805436652

Epoch: 5| Step: 8
Training loss: 2.6516570830236903
Validation loss: 2.4017698026372956

Epoch: 5| Step: 9
Training loss: 2.6018252311673087
Validation loss: 2.4126035361728846

Epoch: 5| Step: 10
Training loss: 2.8972525835097307
Validation loss: 2.4126881885787235

Epoch: 44| Step: 0
Training loss: 2.477053909405057
Validation loss: 2.402493963606722

Epoch: 5| Step: 1
Training loss: 2.463812901174399
Validation loss: 2.4071633696698753

Epoch: 5| Step: 2
Training loss: 2.2009381201441385
Validation loss: 2.414772165932425

Epoch: 5| Step: 3
Training loss: 2.687077245064079
Validation loss: 2.4120352846062367

Epoch: 5| Step: 4
Training loss: 2.857926131920259
Validation loss: 2.4143711637060146

Epoch: 5| Step: 5
Training loss: 2.811928924226632
Validation loss: 2.4030803957967546

Epoch: 5| Step: 6
Training loss: 3.0429762716530915
Validation loss: 2.40737674617971

Epoch: 5| Step: 7
Training loss: 3.1371425470634424
Validation loss: 2.4249691476942976

Epoch: 5| Step: 8
Training loss: 2.815481428239229
Validation loss: 2.416146821477721

Epoch: 5| Step: 9
Training loss: 2.5139984179592694
Validation loss: 2.400229820063014

Epoch: 5| Step: 10
Training loss: 2.8420816075677187
Validation loss: 2.4289780703347574

Epoch: 45| Step: 0
Training loss: 2.175524931077216
Validation loss: 2.4123072301559247

Epoch: 5| Step: 1
Training loss: 2.8425263507463745
Validation loss: 2.4023475949076314

Epoch: 5| Step: 2
Training loss: 2.9764742300006413
Validation loss: 2.3966764880917335

Epoch: 5| Step: 3
Training loss: 2.7360511220260646
Validation loss: 2.4069354047073106

Epoch: 5| Step: 4
Training loss: 2.6700667123639668
Validation loss: 2.4062179469538836

Epoch: 5| Step: 5
Training loss: 2.840618715184879
Validation loss: 2.4141605393263452

Epoch: 5| Step: 6
Training loss: 2.8788187953134527
Validation loss: 2.4121192475245947

Epoch: 5| Step: 7
Training loss: 2.710133370077192
Validation loss: 2.411888765773057

Epoch: 5| Step: 8
Training loss: 2.348584389930921
Validation loss: 2.4036979720744287

Epoch: 5| Step: 9
Training loss: 2.6571555893969454
Validation loss: 2.413093775807619

Epoch: 5| Step: 10
Training loss: 3.007501918065957
Validation loss: 2.407675513822853

Epoch: 46| Step: 0
Training loss: 2.4121313179037354
Validation loss: 2.409543307015316

Epoch: 5| Step: 1
Training loss: 3.495409270896519
Validation loss: 2.4013393951477022

Epoch: 5| Step: 2
Training loss: 2.8270743088565307
Validation loss: 2.4072212610392505

Epoch: 5| Step: 3
Training loss: 3.0119719046388025
Validation loss: 2.413300524022996

Epoch: 5| Step: 4
Training loss: 2.665110272958477
Validation loss: 2.398251621602819

Epoch: 5| Step: 5
Training loss: 2.1106380495905483
Validation loss: 2.3969249193216737

Epoch: 5| Step: 6
Training loss: 2.7410073199614544
Validation loss: 2.413950798215988

Epoch: 5| Step: 7
Training loss: 2.405110275056149
Validation loss: 2.418539557004391

Epoch: 5| Step: 8
Training loss: 2.622900441073851
Validation loss: 2.4008547435844503

Epoch: 5| Step: 9
Training loss: 2.7432341140597196
Validation loss: 2.400730411754816

Epoch: 5| Step: 10
Training loss: 2.645154330216682
Validation loss: 2.4214316024074383

Epoch: 47| Step: 0
Training loss: 2.5281697121946634
Validation loss: 2.39194417544537

Epoch: 5| Step: 1
Training loss: 2.8139395526502056
Validation loss: 2.4122630115191472

Epoch: 5| Step: 2
Training loss: 2.9400659270906915
Validation loss: 2.4126486379511323

Epoch: 5| Step: 3
Training loss: 2.900931793999559
Validation loss: 2.409515989869267

Epoch: 5| Step: 4
Training loss: 2.931016300214658
Validation loss: 2.4155927842106877

Epoch: 5| Step: 5
Training loss: 3.0532640033108134
Validation loss: 2.401209283096522

Epoch: 5| Step: 6
Training loss: 2.607320650686138
Validation loss: 2.4016498200063237

Epoch: 5| Step: 7
Training loss: 2.344740391332606
Validation loss: 2.4137825858522337

Epoch: 5| Step: 8
Training loss: 2.3660076965632495
Validation loss: 2.4054749253609082

Epoch: 5| Step: 9
Training loss: 2.6194794142020323
Validation loss: 2.397728143326662

Epoch: 5| Step: 10
Training loss: 2.686705627143139
Validation loss: 2.391771431314427

Epoch: 48| Step: 0
Training loss: 2.2495182369295894
Validation loss: 2.4077713387684234

Epoch: 5| Step: 1
Training loss: 2.42722914971266
Validation loss: 2.4154272440780526

Epoch: 5| Step: 2
Training loss: 2.997382293502669
Validation loss: 2.4052959612934384

Epoch: 5| Step: 3
Training loss: 2.6721482165110935
Validation loss: 2.407961865723403

Epoch: 5| Step: 4
Training loss: 3.204815971816168
Validation loss: 2.394809221171611

Epoch: 5| Step: 5
Training loss: 2.838626815965315
Validation loss: 2.406668360436879

Epoch: 5| Step: 6
Training loss: 2.6221353249330903
Validation loss: 2.40099263520979

Epoch: 5| Step: 7
Training loss: 2.7287594052133888
Validation loss: 2.3969423021850296

Epoch: 5| Step: 8
Training loss: 3.2046966418689693
Validation loss: 2.4085666567172916

Epoch: 5| Step: 9
Training loss: 2.4008029866002647
Validation loss: 2.3983467199508137

Epoch: 5| Step: 10
Training loss: 2.2593341702350602
Validation loss: 2.4053425435488633

Epoch: 49| Step: 0
Training loss: 2.7562066176410682
Validation loss: 2.4131516646074957

Epoch: 5| Step: 1
Training loss: 2.24447058367642
Validation loss: 2.3962621496801724

Epoch: 5| Step: 2
Training loss: 2.5287985528045733
Validation loss: 2.3991267555448

Epoch: 5| Step: 3
Training loss: 3.07171365929305
Validation loss: 2.40480305902965

Epoch: 5| Step: 4
Training loss: 2.308745145271125
Validation loss: 2.402833243809517

Epoch: 5| Step: 5
Training loss: 2.3463207133819464
Validation loss: 2.408937975825975

Epoch: 5| Step: 6
Training loss: 2.8977806807167372
Validation loss: 2.4141582954924776

Epoch: 5| Step: 7
Training loss: 2.7457321167632407
Validation loss: 2.395437642004859

Epoch: 5| Step: 8
Training loss: 2.8183964272837283
Validation loss: 2.401207067196962

Epoch: 5| Step: 9
Training loss: 2.9027127304779423
Validation loss: 2.4191445934385984

Epoch: 5| Step: 10
Training loss: 3.104950176582558
Validation loss: 2.40932102423015

Epoch: 50| Step: 0
Training loss: 2.7109154252354575
Validation loss: 2.3959995588408725

Epoch: 5| Step: 1
Training loss: 2.2398942125408565
Validation loss: 2.4158897754759097

Epoch: 5| Step: 2
Training loss: 2.7517497824814963
Validation loss: 2.40165957114051

Epoch: 5| Step: 3
Training loss: 2.8473343948556393
Validation loss: 2.4114373510339067

Epoch: 5| Step: 4
Training loss: 3.0911555344971156
Validation loss: 2.4009814948979744

Epoch: 5| Step: 5
Training loss: 3.070387977662436
Validation loss: 2.4270902595982773

Epoch: 5| Step: 6
Training loss: 2.232359717597601
Validation loss: 2.4121740106594025

Epoch: 5| Step: 7
Training loss: 2.148037294046304
Validation loss: 2.4066726341113354

Epoch: 5| Step: 8
Training loss: 2.966964184561914
Validation loss: 2.400142842489019

Epoch: 5| Step: 9
Training loss: 2.8254120180239624
Validation loss: 2.4071790768424886

Epoch: 5| Step: 10
Training loss: 2.8175342010074047
Validation loss: 2.4062290379847453

Epoch: 51| Step: 0
Training loss: 2.662671215301179
Validation loss: 2.4262619927954745

Epoch: 5| Step: 1
Training loss: 2.472115938233207
Validation loss: 2.40146784921374

Epoch: 5| Step: 2
Training loss: 2.7672460945081845
Validation loss: 2.425856514217014

Epoch: 5| Step: 3
Training loss: 2.665731315683974
Validation loss: 2.4114112577430484

Epoch: 5| Step: 4
Training loss: 2.927220315318624
Validation loss: 2.4214392368925344

Epoch: 5| Step: 5
Training loss: 2.865686507069347
Validation loss: 2.4161162928965494

Epoch: 5| Step: 6
Training loss: 2.8311127955725963
Validation loss: 2.4118874318102588

Epoch: 5| Step: 7
Training loss: 2.4988345290557104
Validation loss: 2.4095564999953965

Epoch: 5| Step: 8
Training loss: 2.609151773555442
Validation loss: 2.4127503611755303

Epoch: 5| Step: 9
Training loss: 2.8525950613405286
Validation loss: 2.4074910616015277

Epoch: 5| Step: 10
Training loss: 2.632640980190541
Validation loss: 2.4132724362096423

Epoch: 52| Step: 0
Training loss: 2.6111939994245192
Validation loss: 2.4100192970078935

Epoch: 5| Step: 1
Training loss: 2.422703853411355
Validation loss: 2.4074475728637963

Epoch: 5| Step: 2
Training loss: 2.590009266899351
Validation loss: 2.4088368264826627

Epoch: 5| Step: 3
Training loss: 3.299181813623381
Validation loss: 2.4209728803594666

Epoch: 5| Step: 4
Training loss: 3.3662620741963707
Validation loss: 2.4094935635110217

Epoch: 5| Step: 5
Training loss: 2.963085029878
Validation loss: 2.4106121511244885

Epoch: 5| Step: 6
Training loss: 2.3681523839918226
Validation loss: 2.4118191946430256

Epoch: 5| Step: 7
Training loss: 2.6425293144686073
Validation loss: 2.403295778094295

Epoch: 5| Step: 8
Training loss: 2.790238076583669
Validation loss: 2.411654217200449

Epoch: 5| Step: 9
Training loss: 1.6716299144752789
Validation loss: 2.4084374242185818

Epoch: 5| Step: 10
Training loss: 2.571067073177087
Validation loss: 2.413508007631275

Epoch: 53| Step: 0
Training loss: 2.634522197045619
Validation loss: 2.408449367222093

Epoch: 5| Step: 1
Training loss: 2.5997993978727836
Validation loss: 2.4172252826940905

Epoch: 5| Step: 2
Training loss: 2.895687145321314
Validation loss: 2.4113623703350653

Epoch: 5| Step: 3
Training loss: 3.0731134039190886
Validation loss: 2.407396516160893

Epoch: 5| Step: 4
Training loss: 2.5605779743415558
Validation loss: 2.402010652846552

Epoch: 5| Step: 5
Training loss: 2.173559729226435
Validation loss: 2.4043126973963984

Epoch: 5| Step: 6
Training loss: 2.868651637300445
Validation loss: 2.411308459506841

Epoch: 5| Step: 7
Training loss: 2.8904540965103047
Validation loss: 2.420566374919898

Epoch: 5| Step: 8
Training loss: 2.9163472318566273
Validation loss: 2.4184192636227904

Epoch: 5| Step: 9
Training loss: 2.3240650799382907
Validation loss: 2.41324615242126

Epoch: 5| Step: 10
Training loss: 2.7154755440377905
Validation loss: 2.406186722391002

Epoch: 54| Step: 0
Training loss: 3.120787871725282
Validation loss: 2.4031672307818246

Epoch: 5| Step: 1
Training loss: 2.7814523001830103
Validation loss: 2.4021206174309393

Epoch: 5| Step: 2
Training loss: 2.20716995208518
Validation loss: 2.401908051052841

Epoch: 5| Step: 3
Training loss: 2.276523867811478
Validation loss: 2.4043074849417767

Epoch: 5| Step: 4
Training loss: 2.2863273032724796
Validation loss: 2.4008560398973153

Epoch: 5| Step: 5
Training loss: 2.5275252452461174
Validation loss: 2.402719494207616

Epoch: 5| Step: 6
Training loss: 2.973266057791505
Validation loss: 2.427716212064083

Epoch: 5| Step: 7
Training loss: 2.625846817028793
Validation loss: 2.406628524994567

Epoch: 5| Step: 8
Training loss: 2.8563231143733745
Validation loss: 2.408627078929718

Epoch: 5| Step: 9
Training loss: 2.788286373596529
Validation loss: 2.398922926317977

Epoch: 5| Step: 10
Training loss: 3.220481925109355
Validation loss: 2.4098556548360364

Epoch: 55| Step: 0
Training loss: 2.5965872264294894
Validation loss: 2.4123292435251864

Epoch: 5| Step: 1
Training loss: 2.860054644082639
Validation loss: 2.403911488215467

Epoch: 5| Step: 2
Training loss: 2.831820270966734
Validation loss: 2.420398912539794

Epoch: 5| Step: 3
Training loss: 2.7682436167835363
Validation loss: 2.414755797371514

Epoch: 5| Step: 4
Training loss: 2.4722765108165103
Validation loss: 2.4176820383606605

Epoch: 5| Step: 5
Training loss: 2.8409352887419552
Validation loss: 2.405653400291597

Epoch: 5| Step: 6
Training loss: 2.746186820524535
Validation loss: 2.411493184242182

Epoch: 5| Step: 7
Training loss: 2.401382377982912
Validation loss: 2.4049057238628806

Epoch: 5| Step: 8
Training loss: 2.411246326813538
Validation loss: 2.4047191146444775

Epoch: 5| Step: 9
Training loss: 2.470131885698689
Validation loss: 2.4158494272609197

Epoch: 5| Step: 10
Training loss: 3.304547967512695
Validation loss: 2.411741013481972

Epoch: 56| Step: 0
Training loss: 2.9264930500969286
Validation loss: 2.4048138293100867

Epoch: 5| Step: 1
Training loss: 2.843173461152203
Validation loss: 2.414294752478991

Epoch: 5| Step: 2
Training loss: 2.5140373954207065
Validation loss: 2.4218314895664474

Epoch: 5| Step: 3
Training loss: 2.6090984083677484
Validation loss: 2.4135740950064917

Epoch: 5| Step: 4
Training loss: 2.7488419955663796
Validation loss: 2.4225406447811193

Epoch: 5| Step: 5
Training loss: 2.4907224169433575
Validation loss: 2.39875862868704

Epoch: 5| Step: 6
Training loss: 3.173495926124286
Validation loss: 2.4013833153080375

Epoch: 5| Step: 7
Training loss: 2.4402908584899343
Validation loss: 2.406965391506585

Epoch: 5| Step: 8
Training loss: 2.883866941729049
Validation loss: 2.4159427569195384

Epoch: 5| Step: 9
Training loss: 2.7776339737438316
Validation loss: 2.41182376850794

Epoch: 5| Step: 10
Training loss: 1.93693675806555
Validation loss: 2.4109909939675838

Epoch: 57| Step: 0
Training loss: 2.7564533980353763
Validation loss: 2.406855894318134

Epoch: 5| Step: 1
Training loss: 2.4970623877037426
Validation loss: 2.4046424510808926

Epoch: 5| Step: 2
Training loss: 3.155094048357274
Validation loss: 2.426659117909148

Epoch: 5| Step: 3
Training loss: 3.077272248629864
Validation loss: 2.415322674391377

Epoch: 5| Step: 4
Training loss: 2.896952040222974
Validation loss: 2.4002551334568274

Epoch: 5| Step: 5
Training loss: 2.066527162991297
Validation loss: 2.4157056771890124

Epoch: 5| Step: 6
Training loss: 2.03298230763105
Validation loss: 2.40386064915353

Epoch: 5| Step: 7
Training loss: 2.7337848135393323
Validation loss: 2.4072933143253716

Epoch: 5| Step: 8
Training loss: 2.2709781938830425
Validation loss: 2.4208420725063853

Epoch: 5| Step: 9
Training loss: 2.7536786357344147
Validation loss: 2.4043412934560586

Epoch: 5| Step: 10
Training loss: 3.1602540254497096
Validation loss: 2.4101035652379568

Epoch: 58| Step: 0
Training loss: 3.012264929499589
Validation loss: 2.408201585667414

Epoch: 5| Step: 1
Training loss: 2.5568858729177695
Validation loss: 2.4151713416560043

Epoch: 5| Step: 2
Training loss: 2.72638568468813
Validation loss: 2.4097395759923725

Epoch: 5| Step: 3
Training loss: 2.92422505081725
Validation loss: 2.4070441367627513

Epoch: 5| Step: 4
Training loss: 2.6576180020794573
Validation loss: 2.406671349453261

Epoch: 5| Step: 5
Training loss: 2.6599368370415832
Validation loss: 2.4121953801351133

Epoch: 5| Step: 6
Training loss: 2.989568056783069
Validation loss: 2.4088092464303954

Epoch: 5| Step: 7
Training loss: 2.2642750894951353
Validation loss: 2.4225830461560007

Epoch: 5| Step: 8
Training loss: 2.495602459384191
Validation loss: 2.4081291289358924

Epoch: 5| Step: 9
Training loss: 2.5349111570782488
Validation loss: 2.400717725561035

Epoch: 5| Step: 10
Training loss: 2.713038529057438
Validation loss: 2.4107286303396664

Epoch: 59| Step: 0
Training loss: 2.468240516337595
Validation loss: 2.4098047847926196

Epoch: 5| Step: 1
Training loss: 3.096214160796472
Validation loss: 2.404016564928889

Epoch: 5| Step: 2
Training loss: 2.5657133098834684
Validation loss: 2.402939668196068

Epoch: 5| Step: 3
Training loss: 2.242281921737928
Validation loss: 2.424777593035048

Epoch: 5| Step: 4
Training loss: 2.0866008946632846
Validation loss: 2.4024871300503317

Epoch: 5| Step: 5
Training loss: 2.9622799691042787
Validation loss: 2.4165090393524165

Epoch: 5| Step: 6
Training loss: 2.9524412625096095
Validation loss: 2.407835370070604

Epoch: 5| Step: 7
Training loss: 3.139182143639458
Validation loss: 2.4037643707536747

Epoch: 5| Step: 8
Training loss: 2.771631904960588
Validation loss: 2.4105345157487896

Epoch: 5| Step: 9
Training loss: 2.2473656809623317
Validation loss: 2.403065839070945

Epoch: 5| Step: 10
Training loss: 2.6212545649716597
Validation loss: 2.420411436264001

Epoch: 60| Step: 0
Training loss: 2.14225740214349
Validation loss: 2.4015953212718326

Epoch: 5| Step: 1
Training loss: 2.828569071770109
Validation loss: 2.4116725558486496

Epoch: 5| Step: 2
Training loss: 2.526982041289473
Validation loss: 2.417872029284672

Epoch: 5| Step: 3
Training loss: 3.100305412998795
Validation loss: 2.4147206170113886

Epoch: 5| Step: 4
Training loss: 2.7919043159867143
Validation loss: 2.401077111867691

Epoch: 5| Step: 5
Training loss: 2.9023306064641825
Validation loss: 2.4049453575884217

Epoch: 5| Step: 6
Training loss: 2.482245630330168
Validation loss: 2.4147397047321335

Epoch: 5| Step: 7
Training loss: 2.482749743235637
Validation loss: 2.412037315718809

Epoch: 5| Step: 8
Training loss: 2.9829767756438805
Validation loss: 2.407926688842768

Epoch: 5| Step: 9
Training loss: 2.587841704284071
Validation loss: 2.4174473784689874

Epoch: 5| Step: 10
Training loss: 2.4745269978457753
Validation loss: 2.4022159094534956

Epoch: 61| Step: 0
Training loss: 2.671428353081586
Validation loss: 2.416310687167536

Epoch: 5| Step: 1
Training loss: 2.794160857914652
Validation loss: 2.4090336196602773

Epoch: 5| Step: 2
Training loss: 2.7867968677451134
Validation loss: 2.4192034511988187

Epoch: 5| Step: 3
Training loss: 2.3928449707697705
Validation loss: 2.418653907657272

Epoch: 5| Step: 4
Training loss: 3.0954531210663228
Validation loss: 2.417027997708406

Epoch: 5| Step: 5
Training loss: 2.486609935147444
Validation loss: 2.4048652825052113

Epoch: 5| Step: 6
Training loss: 2.2893924410252247
Validation loss: 2.408595013877994

Epoch: 5| Step: 7
Training loss: 1.8734554923039075
Validation loss: 2.415966718282841

Epoch: 5| Step: 8
Training loss: 2.4704962240443877
Validation loss: 2.4181021983660784

Epoch: 5| Step: 9
Training loss: 2.9525013421529613
Validation loss: 2.4021959100748767

Epoch: 5| Step: 10
Training loss: 3.4239462240755665
Validation loss: 2.4218561717560836

Epoch: 62| Step: 0
Training loss: 2.6571419508591143
Validation loss: 2.4085597339515843

Epoch: 5| Step: 1
Training loss: 2.783622073046292
Validation loss: 2.4157797733387225

Epoch: 5| Step: 2
Training loss: 2.7723561932595686
Validation loss: 2.407471402078211

Epoch: 5| Step: 3
Training loss: 2.286289970670075
Validation loss: 2.413236915527641

Epoch: 5| Step: 4
Training loss: 2.7407299200002844
Validation loss: 2.4147580820547287

Epoch: 5| Step: 5
Training loss: 2.960521336601487
Validation loss: 2.395261248055159

Epoch: 5| Step: 6
Training loss: 2.4767120990034543
Validation loss: 2.407605195901995

Epoch: 5| Step: 7
Training loss: 2.73178151979832
Validation loss: 2.4125028757814295

Epoch: 5| Step: 8
Training loss: 2.013028860795834
Validation loss: 2.4190811025782777

Epoch: 5| Step: 9
Training loss: 2.7648329813009944
Validation loss: 2.4185150275280702

Epoch: 5| Step: 10
Training loss: 3.227055768231224
Validation loss: 2.4208325352493683

Epoch: 63| Step: 0
Training loss: 2.7973170437273356
Validation loss: 2.394452944411663

Epoch: 5| Step: 1
Training loss: 2.3785286840217235
Validation loss: 2.4098407284013

Epoch: 5| Step: 2
Training loss: 2.6342653516438115
Validation loss: 2.4061030787966198

Epoch: 5| Step: 3
Training loss: 2.3810518357531523
Validation loss: 2.4044051676724068

Epoch: 5| Step: 4
Training loss: 2.6463991496309625
Validation loss: 2.4189490499436164

Epoch: 5| Step: 5
Training loss: 2.1074754992743103
Validation loss: 2.4056347232285633

Epoch: 5| Step: 6
Training loss: 2.9547116492952332
Validation loss: 2.418023243887314

Epoch: 5| Step: 7
Training loss: 2.6503500545266734
Validation loss: 2.4264017311939674

Epoch: 5| Step: 8
Training loss: 2.687617632043624
Validation loss: 2.428100664959134

Epoch: 5| Step: 9
Training loss: 3.090775109513452
Validation loss: 2.401184394012239

Epoch: 5| Step: 10
Training loss: 3.0411950011323032
Validation loss: 2.4179116370778186

Epoch: 64| Step: 0
Training loss: 2.578145992309185
Validation loss: 2.404181538643887

Epoch: 5| Step: 1
Training loss: 2.0470231563151
Validation loss: 2.4186426075549408

Epoch: 5| Step: 2
Training loss: 2.6685248894191
Validation loss: 2.411886420974213

Epoch: 5| Step: 3
Training loss: 2.7572444514454744
Validation loss: 2.413105373863957

Epoch: 5| Step: 4
Training loss: 2.4347656759197513
Validation loss: 2.4093453951328043

Epoch: 5| Step: 5
Training loss: 2.2587716464349654
Validation loss: 2.4013595041472557

Epoch: 5| Step: 6
Training loss: 3.08260611816306
Validation loss: 2.425230474993213

Epoch: 5| Step: 7
Training loss: 2.6577496054158094
Validation loss: 2.41466256941138

Epoch: 5| Step: 8
Training loss: 2.791870242614997
Validation loss: 2.423504755075701

Epoch: 5| Step: 9
Training loss: 2.9700736859361143
Validation loss: 2.4096162058386876

Epoch: 5| Step: 10
Training loss: 2.912618570820236
Validation loss: 2.416955960970639

Epoch: 65| Step: 0
Training loss: 2.846596435585811
Validation loss: 2.4137912768725753

Epoch: 5| Step: 1
Training loss: 2.5290731795083254
Validation loss: 2.4085134986478853

Epoch: 5| Step: 2
Training loss: 3.1852483837583767
Validation loss: 2.4102930058857237

Epoch: 5| Step: 3
Training loss: 2.219667701595302
Validation loss: 2.4080091049195405

Epoch: 5| Step: 4
Training loss: 2.3159196673875018
Validation loss: 2.398994424163475

Epoch: 5| Step: 5
Training loss: 2.478303604135793
Validation loss: 2.3934448102899797

Epoch: 5| Step: 6
Training loss: 2.5416068606818674
Validation loss: 2.415131613025819

Epoch: 5| Step: 7
Training loss: 3.0232446101361505
Validation loss: 2.4031838542915582

Epoch: 5| Step: 8
Training loss: 2.349024825977078
Validation loss: 2.4156811921629355

Epoch: 5| Step: 9
Training loss: 2.947798673786797
Validation loss: 2.4100962490598024

Epoch: 5| Step: 10
Training loss: 2.7647967633956934
Validation loss: 2.410857735234552

Epoch: 66| Step: 0
Training loss: 2.932829044805491
Validation loss: 2.402527343607031

Epoch: 5| Step: 1
Training loss: 2.9456359523777595
Validation loss: 2.4042497697265266

Epoch: 5| Step: 2
Training loss: 2.0376035652285216
Validation loss: 2.4110786328466594

Epoch: 5| Step: 3
Training loss: 2.7005318788886834
Validation loss: 2.404598496628508

Epoch: 5| Step: 4
Training loss: 2.5790744767072136
Validation loss: 2.408509385772504

Epoch: 5| Step: 5
Training loss: 2.5818910777123056
Validation loss: 2.4090946973836553

Epoch: 5| Step: 6
Training loss: 2.8454443945524983
Validation loss: 2.4014129657661636

Epoch: 5| Step: 7
Training loss: 2.698549665230442
Validation loss: 2.424992583254725

Epoch: 5| Step: 8
Training loss: 2.7417829166181504
Validation loss: 2.4019273024978802

Epoch: 5| Step: 9
Training loss: 2.5554489260924758
Validation loss: 2.417699256608447

Epoch: 5| Step: 10
Training loss: 2.5336098678974865
Validation loss: 2.4242490947387836

Epoch: 67| Step: 0
Training loss: 2.9019402163109715
Validation loss: 2.411101610118906

Epoch: 5| Step: 1
Training loss: 3.208390685390434
Validation loss: 2.4193375318858457

Epoch: 5| Step: 2
Training loss: 2.518294156382222
Validation loss: 2.4215175951108447

Epoch: 5| Step: 3
Training loss: 2.413549868773209
Validation loss: 2.4072038017065034

Epoch: 5| Step: 4
Training loss: 2.2274830839154847
Validation loss: 2.4155363930538676

Epoch: 5| Step: 5
Training loss: 2.5848235067476377
Validation loss: 2.4138971703476813

Epoch: 5| Step: 6
Training loss: 2.722835058746878
Validation loss: 2.4048900386196093

Epoch: 5| Step: 7
Training loss: 2.1921310450162803
Validation loss: 2.412538994375102

Epoch: 5| Step: 8
Training loss: 3.508085992087546
Validation loss: 2.4091231121772387

Epoch: 5| Step: 9
Training loss: 2.142654014224044
Validation loss: 2.404352767397436

Epoch: 5| Step: 10
Training loss: 2.6361696476852456
Validation loss: 2.418219880505714

Epoch: 68| Step: 0
Training loss: 2.471721165013992
Validation loss: 2.4053612804339517

Epoch: 5| Step: 1
Training loss: 2.486016073369845
Validation loss: 2.3976081637362556

Epoch: 5| Step: 2
Training loss: 2.7006922011168433
Validation loss: 2.4131168295059924

Epoch: 5| Step: 3
Training loss: 2.6842269483601298
Validation loss: 2.415263476869153

Epoch: 5| Step: 4
Training loss: 2.9191597955136275
Validation loss: 2.401897350995191

Epoch: 5| Step: 5
Training loss: 2.541314355998852
Validation loss: 2.405641661871386

Epoch: 5| Step: 6
Training loss: 2.3266832636739467
Validation loss: 2.415733996180859

Epoch: 5| Step: 7
Training loss: 2.5927969778827777
Validation loss: 2.4079217557021093

Epoch: 5| Step: 8
Training loss: 3.16757572243134
Validation loss: 2.418793231323071

Epoch: 5| Step: 9
Training loss: 2.9506365267143226
Validation loss: 2.408699854348335

Epoch: 5| Step: 10
Training loss: 2.379940415766512
Validation loss: 2.414744361979327

Epoch: 69| Step: 0
Training loss: 2.0077270014626847
Validation loss: 2.4115459991688573

Epoch: 5| Step: 1
Training loss: 3.0290968021554896
Validation loss: 2.418363410105874

Epoch: 5| Step: 2
Training loss: 2.777225797699692
Validation loss: 2.4076454693185534

Epoch: 5| Step: 3
Training loss: 2.562129575426113
Validation loss: 2.407141518333925

Epoch: 5| Step: 4
Training loss: 2.638835684479774
Validation loss: 2.418555021226819

Epoch: 5| Step: 5
Training loss: 2.1600425648910515
Validation loss: 2.409773634366205

Epoch: 5| Step: 6
Training loss: 2.683037357316218
Validation loss: 2.4086208843602823

Epoch: 5| Step: 7
Training loss: 2.63076947461469
Validation loss: 2.4042098456932472

Epoch: 5| Step: 8
Training loss: 2.2339295696880552
Validation loss: 2.403013819258576

Epoch: 5| Step: 9
Training loss: 2.825789440882473
Validation loss: 2.402982053771489

Epoch: 5| Step: 10
Training loss: 3.4992751324576807
Validation loss: 2.4154925625440784

Epoch: 70| Step: 0
Training loss: 2.4873296094648585
Validation loss: 2.416308118285057

Epoch: 5| Step: 1
Training loss: 2.765583102668606
Validation loss: 2.4144343998898026

Epoch: 5| Step: 2
Training loss: 2.6406576843044745
Validation loss: 2.425043265262597

Epoch: 5| Step: 3
Training loss: 2.9028746990792915
Validation loss: 2.4103944078774937

Epoch: 5| Step: 4
Training loss: 2.543710439313458
Validation loss: 2.4025633512742064

Epoch: 5| Step: 5
Training loss: 2.41432973623247
Validation loss: 2.415833491533319

Epoch: 5| Step: 6
Training loss: 2.996470123086056
Validation loss: 2.4177352196377138

Epoch: 5| Step: 7
Training loss: 2.638325158076614
Validation loss: 2.402451351199458

Epoch: 5| Step: 8
Training loss: 2.783806643721231
Validation loss: 2.424055131114781

Epoch: 5| Step: 9
Training loss: 2.541860406297671
Validation loss: 2.4218106285429566

Epoch: 5| Step: 10
Training loss: 2.365010081586258
Validation loss: 2.41552275938615

Epoch: 71| Step: 0
Training loss: 2.7436375275588785
Validation loss: 2.427863625708572

Epoch: 5| Step: 1
Training loss: 2.855825086243514
Validation loss: 2.407084308269845

Epoch: 5| Step: 2
Training loss: 2.1261785268460502
Validation loss: 2.394430777402063

Epoch: 5| Step: 3
Training loss: 2.272745453154934
Validation loss: 2.407807240863667

Epoch: 5| Step: 4
Training loss: 3.029171260391243
Validation loss: 2.399990937128696

Epoch: 5| Step: 5
Training loss: 2.901951061191048
Validation loss: 2.3936048682761597

Epoch: 5| Step: 6
Training loss: 2.624239584365094
Validation loss: 2.4161426335292617

Epoch: 5| Step: 7
Training loss: 2.8076736577201444
Validation loss: 2.409316392411351

Epoch: 5| Step: 8
Training loss: 2.5465924627002146
Validation loss: 2.400961614435459

Epoch: 5| Step: 9
Training loss: 1.935272412900517
Validation loss: 2.420516788045691

Epoch: 5| Step: 10
Training loss: 3.213627266426449
Validation loss: 2.4253982527732525

Epoch: 72| Step: 0
Training loss: 2.8182926289036363
Validation loss: 2.4060252046943895

Epoch: 5| Step: 1
Training loss: 2.264599903634472
Validation loss: 2.418859065131834

Epoch: 5| Step: 2
Training loss: 2.5377041513786267
Validation loss: 2.4197504977943476

Epoch: 5| Step: 3
Training loss: 2.38517529017386
Validation loss: 2.4157913648669687

Epoch: 5| Step: 4
Training loss: 2.7529960264377484
Validation loss: 2.4101067255051936

Epoch: 5| Step: 5
Training loss: 3.063372118029494
Validation loss: 2.4108718573161854

Epoch: 5| Step: 6
Training loss: 2.4311917177878293
Validation loss: 2.4076001401816725

Epoch: 5| Step: 7
Training loss: 2.5873171534410377
Validation loss: 2.4103674827374513

Epoch: 5| Step: 8
Training loss: 3.0440383617876217
Validation loss: 2.4341505569128428

Epoch: 5| Step: 9
Training loss: 2.3952605737680313
Validation loss: 2.4136212817169285

Epoch: 5| Step: 10
Training loss: 2.76643463180535
Validation loss: 2.4202070920188636

Epoch: 73| Step: 0
Training loss: 2.7348141562802524
Validation loss: 2.4071096901649844

Epoch: 5| Step: 1
Training loss: 3.019547989220258
Validation loss: 2.404179842119051

Epoch: 5| Step: 2
Training loss: 2.8555225205479373
Validation loss: 2.4020050789209173

Epoch: 5| Step: 3
Training loss: 2.4615665661142745
Validation loss: 2.4288766636528103

Epoch: 5| Step: 4
Training loss: 3.126093101057141
Validation loss: 2.39288414001628

Epoch: 5| Step: 5
Training loss: 2.1902411588506276
Validation loss: 2.419123821577352

Epoch: 5| Step: 6
Training loss: 2.3713519538675247
Validation loss: 2.4128134570862225

Epoch: 5| Step: 7
Training loss: 2.6831106670075897
Validation loss: 2.4040970212472352

Epoch: 5| Step: 8
Training loss: 2.459283278813744
Validation loss: 2.4165363262474475

Epoch: 5| Step: 9
Training loss: 2.7435127381643802
Validation loss: 2.4064973571660837

Epoch: 5| Step: 10
Training loss: 2.1609100626915847
Validation loss: 2.414839379061581

Epoch: 74| Step: 0
Training loss: 2.807791604636704
Validation loss: 2.424747368715996

Epoch: 5| Step: 1
Training loss: 2.41060363475222
Validation loss: 2.4075573088175832

Epoch: 5| Step: 2
Training loss: 2.7551094619134906
Validation loss: 2.424517390616214

Epoch: 5| Step: 3
Training loss: 2.7742470862559028
Validation loss: 2.4143556779946653

Epoch: 5| Step: 4
Training loss: 2.7846865906712304
Validation loss: 2.4045940657431393

Epoch: 5| Step: 5
Training loss: 2.3037327744765688
Validation loss: 2.416227423481889

Epoch: 5| Step: 6
Training loss: 2.786841782660442
Validation loss: 2.420432040318449

Epoch: 5| Step: 7
Training loss: 2.78162347236255
Validation loss: 2.407620988038361

Epoch: 5| Step: 8
Training loss: 2.5120599731466013
Validation loss: 2.422953959876451

Epoch: 5| Step: 9
Training loss: 2.7992782922875175
Validation loss: 2.3955433178215046

Epoch: 5| Step: 10
Training loss: 2.0659157183388537
Validation loss: 2.393352116851469

Epoch: 75| Step: 0
Training loss: 2.866507550932106
Validation loss: 2.4058462463962353

Epoch: 5| Step: 1
Training loss: 2.6222953486707787
Validation loss: 2.4167591949955907

Epoch: 5| Step: 2
Training loss: 1.8674085159056921
Validation loss: 2.4221390034151735

Epoch: 5| Step: 3
Training loss: 2.6326186111551624
Validation loss: 2.4071743897822153

Epoch: 5| Step: 4
Training loss: 2.231549590698049
Validation loss: 2.413887014096092

Epoch: 5| Step: 5
Training loss: 2.2866596199942837
Validation loss: 2.419806102109469

Epoch: 5| Step: 6
Training loss: 2.9177888255585254
Validation loss: 2.4037599767252082

Epoch: 5| Step: 7
Training loss: 3.0891410327551356
Validation loss: 2.4062122405399893

Epoch: 5| Step: 8
Training loss: 2.491215148467629
Validation loss: 2.4127851665047277

Epoch: 5| Step: 9
Training loss: 2.7429405113163874
Validation loss: 2.418517843962587

Epoch: 5| Step: 10
Training loss: 3.067256736654075
Validation loss: 2.427637245008532

Epoch: 76| Step: 0
Training loss: 2.408626621255889
Validation loss: 2.413618756972461

Epoch: 5| Step: 1
Training loss: 3.195149387216256
Validation loss: 2.404866745087713

Epoch: 5| Step: 2
Training loss: 2.6208533277693986
Validation loss: 2.4159881359177935

Epoch: 5| Step: 3
Training loss: 2.204966215363577
Validation loss: 2.419017673638691

Epoch: 5| Step: 4
Training loss: 3.0616215594323792
Validation loss: 2.409255384153032

Epoch: 5| Step: 5
Training loss: 2.7669842499456014
Validation loss: 2.429525093955488

Epoch: 5| Step: 6
Training loss: 2.4754878940767826
Validation loss: 2.406276840701639

Epoch: 5| Step: 7
Training loss: 2.566946033863077
Validation loss: 2.417676798000038

Epoch: 5| Step: 8
Training loss: 2.5571682985049424
Validation loss: 2.3880752369588554

Epoch: 5| Step: 9
Training loss: 2.305927421526087
Validation loss: 2.3954274786574543

Epoch: 5| Step: 10
Training loss: 2.6876193175332297
Validation loss: 2.425084915129083

Epoch: 77| Step: 0
Training loss: 2.795381370962602
Validation loss: 2.411415201947484

Epoch: 5| Step: 1
Training loss: 2.3653543254446894
Validation loss: 2.421164835566719

Epoch: 5| Step: 2
Training loss: 3.2895445119360067
Validation loss: 2.415186385343847

Epoch: 5| Step: 3
Training loss: 2.323489496281628
Validation loss: 2.41980795189191

Epoch: 5| Step: 4
Training loss: 2.2726065568943
Validation loss: 2.428018480542398

Epoch: 5| Step: 5
Training loss: 2.270165884871946
Validation loss: 2.413987664560373

Epoch: 5| Step: 6
Training loss: 2.9924569668460217
Validation loss: 2.4073177877560163

Epoch: 5| Step: 7
Training loss: 2.67825341289598
Validation loss: 2.4094159431650155

Epoch: 5| Step: 8
Training loss: 2.934125544758156
Validation loss: 2.4153608953586385

Epoch: 5| Step: 9
Training loss: 2.205745572356037
Validation loss: 2.41232855381709

Epoch: 5| Step: 10
Training loss: 2.583368321663788
Validation loss: 2.4198664025936645

Epoch: 78| Step: 0
Training loss: 2.979085818885414
Validation loss: 2.4206198052576733

Epoch: 5| Step: 1
Training loss: 2.8624641116362093
Validation loss: 2.3991379691173615

Epoch: 5| Step: 2
Training loss: 2.669632355313484
Validation loss: 2.415026004562676

Epoch: 5| Step: 3
Training loss: 2.5811975838647965
Validation loss: 2.4022293475763816

Epoch: 5| Step: 4
Training loss: 2.5949067443378966
Validation loss: 2.4056665005779974

Epoch: 5| Step: 5
Training loss: 2.121486451835086
Validation loss: 2.411740198173575

Epoch: 5| Step: 6
Training loss: 2.9929531303123644
Validation loss: 2.4006781523214658

Epoch: 5| Step: 7
Training loss: 2.266963274099186
Validation loss: 2.394501353731994

Epoch: 5| Step: 8
Training loss: 2.7554440797112933
Validation loss: 2.4056218673443577

Epoch: 5| Step: 9
Training loss: 2.3134926392434223
Validation loss: 2.4095956529303497

Epoch: 5| Step: 10
Training loss: 2.636388958686786
Validation loss: 2.4120513240781487

Epoch: 79| Step: 0
Training loss: 2.6010604236452513
Validation loss: 2.4141855632953364

Epoch: 5| Step: 1
Training loss: 2.999422335639678
Validation loss: 2.4026164905412024

Epoch: 5| Step: 2
Training loss: 1.8959816326225487
Validation loss: 2.4101556532741344

Epoch: 5| Step: 3
Training loss: 2.3049632796467754
Validation loss: 2.4118975130431024

Epoch: 5| Step: 4
Training loss: 2.887860269901673
Validation loss: 2.4071459637003687

Epoch: 5| Step: 5
Training loss: 3.0014980072924855
Validation loss: 2.4151857044126737

Epoch: 5| Step: 6
Training loss: 2.4410470438873544
Validation loss: 2.4230480093702544

Epoch: 5| Step: 7
Training loss: 2.449233935733425
Validation loss: 2.4092215727715844

Epoch: 5| Step: 8
Training loss: 3.0494657017220255
Validation loss: 2.4104054435296898

Epoch: 5| Step: 9
Training loss: 2.8068496743051146
Validation loss: 2.4181855880609735

Epoch: 5| Step: 10
Training loss: 2.055935672748181
Validation loss: 2.410651992522133

Epoch: 80| Step: 0
Training loss: 2.9160654992490556
Validation loss: 2.4090950698364915

Epoch: 5| Step: 1
Training loss: 2.5255294018206262
Validation loss: 2.410725955812267

Epoch: 5| Step: 2
Training loss: 2.6179868473803762
Validation loss: 2.396609173136359

Epoch: 5| Step: 3
Training loss: 2.5585390507332884
Validation loss: 2.4275229167442633

Epoch: 5| Step: 4
Training loss: 2.183692452207975
Validation loss: 2.405858316280036

Epoch: 5| Step: 5
Training loss: 2.666928536749606
Validation loss: 2.412969322403172

Epoch: 5| Step: 6
Training loss: 2.516664657423552
Validation loss: 2.4023789397993096

Epoch: 5| Step: 7
Training loss: 2.6400935072667058
Validation loss: 2.4130772226913892

Epoch: 5| Step: 8
Training loss: 2.972630905464395
Validation loss: 2.4121519469845762

Epoch: 5| Step: 9
Training loss: 2.5651887882945936
Validation loss: 2.4267933486690745

Epoch: 5| Step: 10
Training loss: 2.521356060802492
Validation loss: 2.3985901097574223

Epoch: 81| Step: 0
Training loss: 2.5515563628385127
Validation loss: 2.3973525204216743

Epoch: 5| Step: 1
Training loss: 2.0984810285676403
Validation loss: 2.4000579275810794

Epoch: 5| Step: 2
Training loss: 2.5139085114370676
Validation loss: 2.399077661620708

Epoch: 5| Step: 3
Training loss: 2.3473936114918925
Validation loss: 2.4195128057721984

Epoch: 5| Step: 4
Training loss: 2.665395990263381
Validation loss: 2.4123601096203844

Epoch: 5| Step: 5
Training loss: 2.773683005199058
Validation loss: 2.398874002418097

Epoch: 5| Step: 6
Training loss: 2.869988925659931
Validation loss: 2.4089955952152344

Epoch: 5| Step: 7
Training loss: 2.53394710818567
Validation loss: 2.413618337420642

Epoch: 5| Step: 8
Training loss: 2.70363299056219
Validation loss: 2.3997115609612156

Epoch: 5| Step: 9
Training loss: 2.5664682134060386
Validation loss: 2.4093047144000064

Epoch: 5| Step: 10
Training loss: 3.103495804835625
Validation loss: 2.4138578609667265

Epoch: 82| Step: 0
Training loss: 2.873646624922201
Validation loss: 2.414293452763213

Epoch: 5| Step: 1
Training loss: 2.8710814599014163
Validation loss: 2.4265817244196692

Epoch: 5| Step: 2
Training loss: 2.6655561002209827
Validation loss: 2.41612758889852

Epoch: 5| Step: 3
Training loss: 2.507289653714403
Validation loss: 2.411283060144472

Epoch: 5| Step: 4
Training loss: 2.5357039084884176
Validation loss: 2.4028479577143815

Epoch: 5| Step: 5
Training loss: 2.117350329229202
Validation loss: 2.411015872198417

Epoch: 5| Step: 6
Training loss: 2.542082320032156
Validation loss: 2.3962586041952374

Epoch: 5| Step: 7
Training loss: 2.664680744823341
Validation loss: 2.424400457226714

Epoch: 5| Step: 8
Training loss: 2.723057633836872
Validation loss: 2.4162552933923833

Epoch: 5| Step: 9
Training loss: 2.3819834783511187
Validation loss: 2.4030052258155936

Epoch: 5| Step: 10
Training loss: 2.8785368683696717
Validation loss: 2.416166992921047

Epoch: 83| Step: 0
Training loss: 2.498980982048266
Validation loss: 2.405902220011599

Epoch: 5| Step: 1
Training loss: 2.1476017106542313
Validation loss: 2.419241947305529

Epoch: 5| Step: 2
Training loss: 3.155060345636345
Validation loss: 2.4083838226082146

Epoch: 5| Step: 3
Training loss: 2.3211407451565025
Validation loss: 2.405701658823654

Epoch: 5| Step: 4
Training loss: 2.4017707451482035
Validation loss: 2.4080450966236775

Epoch: 5| Step: 5
Training loss: 2.492915701832224
Validation loss: 2.4173153617303553

Epoch: 5| Step: 6
Training loss: 2.5459085514758826
Validation loss: 2.418439487135018

Epoch: 5| Step: 7
Training loss: 2.839844421638504
Validation loss: 2.4291666585333735

Epoch: 5| Step: 8
Training loss: 2.4961373052244546
Validation loss: 2.4119941900805704

Epoch: 5| Step: 9
Training loss: 2.9871808188808964
Validation loss: 2.417813452965998

Epoch: 5| Step: 10
Training loss: 2.6712859993607685
Validation loss: 2.4129242064322973

Epoch: 84| Step: 0
Training loss: 3.2401213531373543
Validation loss: 2.4241020440059446

Epoch: 5| Step: 1
Training loss: 2.670866569593933
Validation loss: 2.4161687404470307

Epoch: 5| Step: 2
Training loss: 2.7512518027688357
Validation loss: 2.401596698846673

Epoch: 5| Step: 3
Training loss: 2.3700194085207693
Validation loss: 2.4027501439240604

Epoch: 5| Step: 4
Training loss: 2.4716100422946727
Validation loss: 2.4137247923731437

Epoch: 5| Step: 5
Training loss: 2.8553927681516247
Validation loss: 2.4105108970825633

Epoch: 5| Step: 6
Training loss: 2.6617290759747054
Validation loss: 2.4037886188206707

Epoch: 5| Step: 7
Training loss: 1.8090675343126976
Validation loss: 2.413918260124817

Epoch: 5| Step: 8
Training loss: 2.779160046509994
Validation loss: 2.4145891370654637

Epoch: 5| Step: 9
Training loss: 2.1288760121849153
Validation loss: 2.4099449785361706

Epoch: 5| Step: 10
Training loss: 2.7179282689513338
Validation loss: 2.402600268576394

Epoch: 85| Step: 0
Training loss: 2.679591852822213
Validation loss: 2.3972361291716555

Epoch: 5| Step: 1
Training loss: 2.5186607098903595
Validation loss: 2.3988954262503945

Epoch: 5| Step: 2
Training loss: 2.538881266067974
Validation loss: 2.412568587957695

Epoch: 5| Step: 3
Training loss: 2.260119042088629
Validation loss: 2.4279020077320532

Epoch: 5| Step: 4
Training loss: 2.789094470612894
Validation loss: 2.4158263890272664

Epoch: 5| Step: 5
Training loss: 2.880367244776734
Validation loss: 2.4173338880953295

Epoch: 5| Step: 6
Training loss: 1.88913030889206
Validation loss: 2.4329805195559864

Epoch: 5| Step: 7
Training loss: 2.316093024808514
Validation loss: 2.4169389707810387

Epoch: 5| Step: 8
Training loss: 3.179811067546776
Validation loss: 2.4078431317765507

Epoch: 5| Step: 9
Training loss: 2.8885206656249123
Validation loss: 2.4230514267822834

Epoch: 5| Step: 10
Training loss: 2.472455394716662
Validation loss: 2.41361586578098

Epoch: 86| Step: 0
Training loss: 2.2203931499869642
Validation loss: 2.409906924855414

Epoch: 5| Step: 1
Training loss: 2.5985660193172864
Validation loss: 2.4160058564690527

Epoch: 5| Step: 2
Training loss: 2.78945586692249
Validation loss: 2.4022479465315896

Epoch: 5| Step: 3
Training loss: 2.678808040159229
Validation loss: 2.413619447374029

Epoch: 5| Step: 4
Training loss: 2.2989087086622075
Validation loss: 2.4081251596545643

Epoch: 5| Step: 5
Training loss: 2.607680815794093
Validation loss: 2.419534790668394

Epoch: 5| Step: 6
Training loss: 2.1520841964715025
Validation loss: 2.4179918123514748

Epoch: 5| Step: 7
Training loss: 3.0823824335527874
Validation loss: 2.4160703369564875

Epoch: 5| Step: 8
Training loss: 2.805085560382805
Validation loss: 2.4220843057630193

Epoch: 5| Step: 9
Training loss: 2.197415467980991
Validation loss: 2.3829194323132996

Epoch: 5| Step: 10
Training loss: 3.0344430682073926
Validation loss: 2.4169981155994016

Epoch: 87| Step: 0
Training loss: 1.965673191953509
Validation loss: 2.4130163063308276

Epoch: 5| Step: 1
Training loss: 3.197586854376935
Validation loss: 2.406421790018879

Epoch: 5| Step: 2
Training loss: 2.685691047266455
Validation loss: 2.4156866013459566

Epoch: 5| Step: 3
Training loss: 2.1522683132126734
Validation loss: 2.4147378489438913

Epoch: 5| Step: 4
Training loss: 2.5034992524015065
Validation loss: 2.4101683865849215

Epoch: 5| Step: 5
Training loss: 2.6650556128390916
Validation loss: 2.4179497163967625

Epoch: 5| Step: 6
Training loss: 2.497589188702514
Validation loss: 2.4061835942656042

Epoch: 5| Step: 7
Training loss: 2.291576164076896
Validation loss: 2.400153094283135

Epoch: 5| Step: 8
Training loss: 2.742815255586062
Validation loss: 2.4285427377840163

Epoch: 5| Step: 9
Training loss: 2.8488279844007063
Validation loss: 2.406043219181469

Epoch: 5| Step: 10
Training loss: 2.812648260659284
Validation loss: 2.403956202793785

Epoch: 88| Step: 0
Training loss: 2.3891650959387163
Validation loss: 2.4111006850779324

Epoch: 5| Step: 1
Training loss: 2.5861130392648093
Validation loss: 2.4142248450408257

Epoch: 5| Step: 2
Training loss: 2.47717643372475
Validation loss: 2.3996927318885044

Epoch: 5| Step: 3
Training loss: 2.2800627453853735
Validation loss: 2.413244081957898

Epoch: 5| Step: 4
Training loss: 3.075414713364636
Validation loss: 2.4380047893105137

Epoch: 5| Step: 5
Training loss: 2.637911875596971
Validation loss: 2.4328142799964576

Epoch: 5| Step: 6
Training loss: 2.8666063598085327
Validation loss: 2.405639753240407

Epoch: 5| Step: 7
Training loss: 2.6580666108291906
Validation loss: 2.393689414485276

Epoch: 5| Step: 8
Training loss: 2.5226074365244773
Validation loss: 2.41114187138596

Epoch: 5| Step: 9
Training loss: 2.1786102586274083
Validation loss: 2.423621925252856

Epoch: 5| Step: 10
Training loss: 2.7951148264436956
Validation loss: 2.407748404247443

Epoch: 89| Step: 0
Training loss: 2.100713622230725
Validation loss: 2.403094301681491

Epoch: 5| Step: 1
Training loss: 2.5643254732783145
Validation loss: 2.4155878534596824

Epoch: 5| Step: 2
Training loss: 3.486370250970982
Validation loss: 2.4069092913690415

Epoch: 5| Step: 3
Training loss: 2.4327017678679685
Validation loss: 2.3935342515883433

Epoch: 5| Step: 4
Training loss: 2.7836953032472502
Validation loss: 2.4287499811506046

Epoch: 5| Step: 5
Training loss: 2.4221027882418786
Validation loss: 2.4031451473546066

Epoch: 5| Step: 6
Training loss: 2.487363637129032
Validation loss: 2.390296752107834

Epoch: 5| Step: 7
Training loss: 2.356941028723124
Validation loss: 2.4094223570036992

Epoch: 5| Step: 8
Training loss: 2.4899431125622904
Validation loss: 2.4235967459053462

Epoch: 5| Step: 9
Training loss: 2.4181428763408395
Validation loss: 2.4137932884521955

Epoch: 5| Step: 10
Training loss: 2.713592548344835
Validation loss: 2.4139176850384136

Epoch: 90| Step: 0
Training loss: 2.5299653926186223
Validation loss: 2.41368412225502

Epoch: 5| Step: 1
Training loss: 2.5034876338104013
Validation loss: 2.4215658603854973

Epoch: 5| Step: 2
Training loss: 2.6857767124660334
Validation loss: 2.408444488906156

Epoch: 5| Step: 3
Training loss: 2.2630154017363853
Validation loss: 2.420052806744556

Epoch: 5| Step: 4
Training loss: 2.064929802465771
Validation loss: 2.407031350712383

Epoch: 5| Step: 5
Training loss: 2.5545814795469983
Validation loss: 2.417187861193904

Epoch: 5| Step: 6
Training loss: 3.066953107337943
Validation loss: 2.400804475149703

Epoch: 5| Step: 7
Training loss: 2.522506683915416
Validation loss: 2.4086036230339967

Epoch: 5| Step: 8
Training loss: 2.132256180306914
Validation loss: 2.4197185059817876

Epoch: 5| Step: 9
Training loss: 2.8281866246037666
Validation loss: 2.402333098303825

Epoch: 5| Step: 10
Training loss: 3.2339148447483117
Validation loss: 2.4109998896366442

Epoch: 91| Step: 0
Training loss: 2.5559820692302044
Validation loss: 2.4052771231776395

Epoch: 5| Step: 1
Training loss: 2.6436795056190485
Validation loss: 2.3993830485625467

Epoch: 5| Step: 2
Training loss: 2.263578450839884
Validation loss: 2.4163008686372955

Epoch: 5| Step: 3
Training loss: 2.577359912517525
Validation loss: 2.406138572675222

Epoch: 5| Step: 4
Training loss: 2.6066890758354426
Validation loss: 2.4001968097147297

Epoch: 5| Step: 5
Training loss: 2.342725300900585
Validation loss: 2.4031280627225087

Epoch: 5| Step: 6
Training loss: 2.619261327091508
Validation loss: 2.4035044928197826

Epoch: 5| Step: 7
Training loss: 2.455013641505983
Validation loss: 2.42373683047178

Epoch: 5| Step: 8
Training loss: 3.269061457016894
Validation loss: 2.4089202330802064

Epoch: 5| Step: 9
Training loss: 2.7073245199298475
Validation loss: 2.4159818816993894

Epoch: 5| Step: 10
Training loss: 2.18585611973107
Validation loss: 2.413661464841727

Epoch: 92| Step: 0
Training loss: 2.542044522907754
Validation loss: 2.414351274572457

Epoch: 5| Step: 1
Training loss: 2.5565038167953724
Validation loss: 2.399362100278468

Epoch: 5| Step: 2
Training loss: 2.2037338605907495
Validation loss: 2.39517997903453

Epoch: 5| Step: 3
Training loss: 2.768145258802024
Validation loss: 2.418086926323401

Epoch: 5| Step: 4
Training loss: 3.245538583740357
Validation loss: 2.4149242338810124

Epoch: 5| Step: 5
Training loss: 2.2735267438118867
Validation loss: 2.4102990195969345

Epoch: 5| Step: 6
Training loss: 2.3714143891329016
Validation loss: 2.418341149540218

Epoch: 5| Step: 7
Training loss: 2.3964449779004924
Validation loss: 2.398853877926667

Epoch: 5| Step: 8
Training loss: 2.4289868684667355
Validation loss: 2.4006688467809574

Epoch: 5| Step: 9
Training loss: 2.8474958293505797
Validation loss: 2.411611538629769

Epoch: 5| Step: 10
Training loss: 2.591637451972131
Validation loss: 2.4096235287939525

Epoch: 93| Step: 0
Training loss: 2.7406426667325836
Validation loss: 2.414296619757338

Epoch: 5| Step: 1
Training loss: 2.759136800540024
Validation loss: 2.4043882359351185

Epoch: 5| Step: 2
Training loss: 2.9134749978522816
Validation loss: 2.4071405843160214

Epoch: 5| Step: 3
Training loss: 2.403174280025946
Validation loss: 2.4248050987727625

Epoch: 5| Step: 4
Training loss: 2.5860092291434946
Validation loss: 2.395971628257596

Epoch: 5| Step: 5
Training loss: 2.2924366322186613
Validation loss: 2.421231832059863

Epoch: 5| Step: 6
Training loss: 2.2749770152848714
Validation loss: 2.4171295090545297

Epoch: 5| Step: 7
Training loss: 2.6585700281493385
Validation loss: 2.39305493657905

Epoch: 5| Step: 8
Training loss: 2.047059727843306
Validation loss: 2.4010456335997574

Epoch: 5| Step: 9
Training loss: 3.0211845106130095
Validation loss: 2.4118322869494775

Epoch: 5| Step: 10
Training loss: 2.4640581961856043
Validation loss: 2.412634976276385

Epoch: 94| Step: 0
Training loss: 2.470742109993813
Validation loss: 2.403671828897657

Epoch: 5| Step: 1
Training loss: 2.6555682036587664
Validation loss: 2.401345975749868

Epoch: 5| Step: 2
Training loss: 2.778831544847343
Validation loss: 2.400892459168825

Epoch: 5| Step: 3
Training loss: 2.7171427919944513
Validation loss: 2.410265264337419

Epoch: 5| Step: 4
Training loss: 2.66995812972596
Validation loss: 2.396178065497827

Epoch: 5| Step: 5
Training loss: 2.19116046363535
Validation loss: 2.4025634857217377

Epoch: 5| Step: 6
Training loss: 2.760576025243627
Validation loss: 2.404698444187952

Epoch: 5| Step: 7
Training loss: 2.2784228639050164
Validation loss: 2.4355881763107607

Epoch: 5| Step: 8
Training loss: 2.8934592708597133
Validation loss: 2.4005989985456795

Epoch: 5| Step: 9
Training loss: 2.7638329341044443
Validation loss: 2.401019686834386

Epoch: 5| Step: 10
Training loss: 1.8581110400802388
Validation loss: 2.4155215378074644

Epoch: 95| Step: 0
Training loss: 2.4320721959515925
Validation loss: 2.4098692322688557

Epoch: 5| Step: 1
Training loss: 3.3071329073710665
Validation loss: 2.399759025593567

Epoch: 5| Step: 2
Training loss: 2.825015133842509
Validation loss: 2.4050353806428713

Epoch: 5| Step: 3
Training loss: 2.4303666419833307
Validation loss: 2.4244134911087354

Epoch: 5| Step: 4
Training loss: 2.4472682554043623
Validation loss: 2.4190886199602177

Epoch: 5| Step: 5
Training loss: 2.5968187860861174
Validation loss: 2.427994454394428

Epoch: 5| Step: 6
Training loss: 2.617844957357895
Validation loss: 2.384053167087927

Epoch: 5| Step: 7
Training loss: 2.50226871545908
Validation loss: 2.4166377542850377

Epoch: 5| Step: 8
Training loss: 2.415378643862096
Validation loss: 2.3941121371531646

Epoch: 5| Step: 9
Training loss: 1.8779387649895987
Validation loss: 2.4136347519328494

Epoch: 5| Step: 10
Training loss: 2.7254870023303774
Validation loss: 2.393914008649979

Epoch: 96| Step: 0
Training loss: 2.4473592461703846
Validation loss: 2.4133505082724622

Epoch: 5| Step: 1
Training loss: 2.7997734352818466
Validation loss: 2.4048515099873606

Epoch: 5| Step: 2
Training loss: 2.3316918003053764
Validation loss: 2.404208952655797

Epoch: 5| Step: 3
Training loss: 2.3162058442832842
Validation loss: 2.3933670711387403

Epoch: 5| Step: 4
Training loss: 2.7122312421421686
Validation loss: 2.4122417127849096

Epoch: 5| Step: 5
Training loss: 2.3326355935413186
Validation loss: 2.4217953036688855

Epoch: 5| Step: 6
Training loss: 3.0257674512639627
Validation loss: 2.408570201114542

Epoch: 5| Step: 7
Training loss: 2.7733207570610023
Validation loss: 2.413990686993664

Epoch: 5| Step: 8
Training loss: 2.4430368578047545
Validation loss: 2.4082346656654754

Epoch: 5| Step: 9
Training loss: 2.6402743857295774
Validation loss: 2.4033656258221487

Epoch: 5| Step: 10
Training loss: 2.3863290321846677
Validation loss: 2.4114957245006874

Epoch: 97| Step: 0
Training loss: 1.9646728926707653
Validation loss: 2.408652966629319

Epoch: 5| Step: 1
Training loss: 3.023283094460472
Validation loss: 2.4047897685458404

Epoch: 5| Step: 2
Training loss: 3.084999579332221
Validation loss: 2.4102934451615643

Epoch: 5| Step: 3
Training loss: 2.367244908609252
Validation loss: 2.3919982247571854

Epoch: 5| Step: 4
Training loss: 2.4540825208174915
Validation loss: 2.3927900009649847

Epoch: 5| Step: 5
Training loss: 2.912145070727739
Validation loss: 2.3990336810833264

Epoch: 5| Step: 6
Training loss: 2.3271054077012168
Validation loss: 2.4116797604123086

Epoch: 5| Step: 7
Training loss: 2.6493430600914882
Validation loss: 2.3928422730393124

Epoch: 5| Step: 8
Training loss: 2.8060640235225685
Validation loss: 2.405500186757015

Epoch: 5| Step: 9
Training loss: 2.682844965387841
Validation loss: 2.40728898850535

Epoch: 5| Step: 10
Training loss: 1.4121971683462462
Validation loss: 2.4102298822851003

Epoch: 98| Step: 0
Training loss: 2.690228607362093
Validation loss: 2.4017644987383253

Epoch: 5| Step: 1
Training loss: 2.5027281181027417
Validation loss: 2.411334326924871

Epoch: 5| Step: 2
Training loss: 2.1066416797886407
Validation loss: 2.424187381492751

Epoch: 5| Step: 3
Training loss: 2.794143280407745
Validation loss: 2.398777848765264

Epoch: 5| Step: 4
Training loss: 2.7929373359247327
Validation loss: 2.3911885532868324

Epoch: 5| Step: 5
Training loss: 2.541820167117039
Validation loss: 2.4067410299788228

Epoch: 5| Step: 6
Training loss: 2.536739472168595
Validation loss: 2.41333018156485

Epoch: 5| Step: 7
Training loss: 2.17650730476582
Validation loss: 2.4089870060835246

Epoch: 5| Step: 8
Training loss: 2.607328423243384
Validation loss: 2.39571192372689

Epoch: 5| Step: 9
Training loss: 2.7877783289973395
Validation loss: 2.3919966589198216

Epoch: 5| Step: 10
Training loss: 2.5814295080543475
Validation loss: 2.416962502236041

Epoch: 99| Step: 0
Training loss: 2.853003234604728
Validation loss: 2.4006124158181823

Epoch: 5| Step: 1
Training loss: 2.347989939302534
Validation loss: 2.4311124903254484

Epoch: 5| Step: 2
Training loss: 2.9084231547682986
Validation loss: 2.4127067106282847

Epoch: 5| Step: 3
Training loss: 2.501916151049008
Validation loss: 2.420854078743372

Epoch: 5| Step: 4
Training loss: 2.4497899997005983
Validation loss: 2.403492543377824

Epoch: 5| Step: 5
Training loss: 2.315983185240957
Validation loss: 2.398674710037843

Epoch: 5| Step: 6
Training loss: 3.13016419001389
Validation loss: 2.4157673853156

Epoch: 5| Step: 7
Training loss: 2.548096346400495
Validation loss: 2.4118816601539526

Epoch: 5| Step: 8
Training loss: 1.7546466717339286
Validation loss: 2.4124228581451557

Epoch: 5| Step: 9
Training loss: 2.6789915554629773
Validation loss: 2.3795524853778085

Epoch: 5| Step: 10
Training loss: 2.4535925352823185
Validation loss: 2.4100096786264507

Epoch: 100| Step: 0
Training loss: 2.5168875612069077
Validation loss: 2.398713241160667

Epoch: 5| Step: 1
Training loss: 1.9505237805115487
Validation loss: 2.423522209103004

Epoch: 5| Step: 2
Training loss: 2.5153545921425566
Validation loss: 2.411957402743746

Epoch: 5| Step: 3
Training loss: 2.661037752745967
Validation loss: 2.4133201312804995

Epoch: 5| Step: 4
Training loss: 2.611775829936376
Validation loss: 2.4014594007609804

Epoch: 5| Step: 5
Training loss: 2.302764814724064
Validation loss: 2.412608260502819

Epoch: 5| Step: 6
Training loss: 2.9055161728954517
Validation loss: 2.4009983887305673

Epoch: 5| Step: 7
Training loss: 2.876835278740912
Validation loss: 2.4200582580635586

Epoch: 5| Step: 8
Training loss: 2.6443976364302904
Validation loss: 2.4110112383190825

Epoch: 5| Step: 9
Training loss: 2.61576408280792
Validation loss: 2.4063564107075552

Epoch: 5| Step: 10
Training loss: 2.296021387206629
Validation loss: 2.4061104449408885

Epoch: 101| Step: 0
Training loss: 2.5002950494226637
Validation loss: 2.4001479224624873

Epoch: 5| Step: 1
Training loss: 2.3200728681236114
Validation loss: 2.4105068609986073

Epoch: 5| Step: 2
Training loss: 2.0432690022326034
Validation loss: 2.3972185382973064

Epoch: 5| Step: 3
Training loss: 2.7071947100720677
Validation loss: 2.4043990166035507

Epoch: 5| Step: 4
Training loss: 2.7198203599736774
Validation loss: 2.4109962361002273

Epoch: 5| Step: 5
Training loss: 2.697295589957332
Validation loss: 2.397777293749515

Epoch: 5| Step: 6
Training loss: 2.4276199620754757
Validation loss: 2.4119814664085486

Epoch: 5| Step: 7
Training loss: 2.816268938714564
Validation loss: 2.403448731093425

Epoch: 5| Step: 8
Training loss: 2.56845118137368
Validation loss: 2.4220718647801243

Epoch: 5| Step: 9
Training loss: 2.4629076625104593
Validation loss: 2.397829726528045

Epoch: 5| Step: 10
Training loss: 2.769423295729668
Validation loss: 2.4187738470239704

Epoch: 102| Step: 0
Training loss: 2.7212526926107055
Validation loss: 2.4078710790342557

Epoch: 5| Step: 1
Training loss: 2.086852369525651
Validation loss: 2.4177308499397747

Epoch: 5| Step: 2
Training loss: 3.3845024556880725
Validation loss: 2.3977080498475614

Epoch: 5| Step: 3
Training loss: 2.974539322006287
Validation loss: 2.4222361178641014

Epoch: 5| Step: 4
Training loss: 2.3747820503215746
Validation loss: 2.4077364407309507

Epoch: 5| Step: 5
Training loss: 3.0166415541922595
Validation loss: 2.3907757536697587

Epoch: 5| Step: 6
Training loss: 2.266529612979109
Validation loss: 2.3875558448998886

Epoch: 5| Step: 7
Training loss: 2.2126592934372495
Validation loss: 2.407111993820719

Epoch: 5| Step: 8
Training loss: 2.3193154809953134
Validation loss: 2.4101798450179723

Epoch: 5| Step: 9
Training loss: 2.1341575321874395
Validation loss: 2.4131283966427337

Epoch: 5| Step: 10
Training loss: 2.220032334822507
Validation loss: 2.394741712418495

Epoch: 103| Step: 0
Training loss: 2.2218213382040704
Validation loss: 2.4115231483849375

Epoch: 5| Step: 1
Training loss: 2.5112864358099625
Validation loss: 2.4151969899065824

Epoch: 5| Step: 2
Training loss: 2.8441693342635794
Validation loss: 2.4107101627472374

Epoch: 5| Step: 3
Training loss: 2.3086575726821925
Validation loss: 2.4116435231789803

Epoch: 5| Step: 4
Training loss: 2.510550742044731
Validation loss: 2.430982322455076

Epoch: 5| Step: 5
Training loss: 2.1400439733818115
Validation loss: 2.4002021160098415

Epoch: 5| Step: 6
Training loss: 2.360751123349101
Validation loss: 2.4173431634205516

Epoch: 5| Step: 7
Training loss: 2.7595831614310007
Validation loss: 2.3934612490812013

Epoch: 5| Step: 8
Training loss: 2.936946086197774
Validation loss: 2.3968023811310513

Epoch: 5| Step: 9
Training loss: 2.3989919214275623
Validation loss: 2.417024441849078

Epoch: 5| Step: 10
Training loss: 2.911183753170961
Validation loss: 2.4077602058638887

Epoch: 104| Step: 0
Training loss: 2.343568209909473
Validation loss: 2.4024987654382794

Epoch: 5| Step: 1
Training loss: 2.7789701911834763
Validation loss: 2.387272896875276

Epoch: 5| Step: 2
Training loss: 1.9614406715228612
Validation loss: 2.408001165954653

Epoch: 5| Step: 3
Training loss: 2.338544634595544
Validation loss: 2.3961883556524044

Epoch: 5| Step: 4
Training loss: 2.575007547904498
Validation loss: 2.412679184908228

Epoch: 5| Step: 5
Training loss: 2.2643670108326774
Validation loss: 2.418135474758136

Epoch: 5| Step: 6
Training loss: 2.957778735403888
Validation loss: 2.3947513707123527

Epoch: 5| Step: 7
Training loss: 2.811975557386542
Validation loss: 2.4124403434670203

Epoch: 5| Step: 8
Training loss: 3.2030651552145804
Validation loss: 2.406870691209929

Epoch: 5| Step: 9
Training loss: 2.4090653830365154
Validation loss: 2.408631427891112

Epoch: 5| Step: 10
Training loss: 2.061153781697086
Validation loss: 2.42472719464298

Epoch: 105| Step: 0
Training loss: 2.960044222836453
Validation loss: 2.401374069081436

Epoch: 5| Step: 1
Training loss: 2.3039017711866223
Validation loss: 2.429968830396398

Epoch: 5| Step: 2
Training loss: 2.743434177026888
Validation loss: 2.396135976829151

Epoch: 5| Step: 3
Training loss: 2.0549185155227523
Validation loss: 2.397133422479274

Epoch: 5| Step: 4
Training loss: 2.5742878419810755
Validation loss: 2.384375817773671

Epoch: 5| Step: 5
Training loss: 2.1977441970146288
Validation loss: 2.4232523981061767

Epoch: 5| Step: 6
Training loss: 2.475450910087282
Validation loss: 2.420368139957443

Epoch: 5| Step: 7
Training loss: 2.830301701130356
Validation loss: 2.4117099550333316

Epoch: 5| Step: 8
Training loss: 2.7602804666182985
Validation loss: 2.389711851309187

Epoch: 5| Step: 9
Training loss: 2.4133558504448667
Validation loss: 2.414819968332166

Epoch: 5| Step: 10
Training loss: 2.361749931631837
Validation loss: 2.403043113546677

Epoch: 106| Step: 0
Training loss: 2.374842487934469
Validation loss: 2.4119921971950995

Epoch: 5| Step: 1
Training loss: 2.660734363088813
Validation loss: 2.417889032002842

Epoch: 5| Step: 2
Training loss: 2.945600014978644
Validation loss: 2.3948117775216184

Epoch: 5| Step: 3
Training loss: 2.7127565113200767
Validation loss: 2.402288462898653

Epoch: 5| Step: 4
Training loss: 2.2747277862004185
Validation loss: 2.394730033988316

Epoch: 5| Step: 5
Training loss: 2.4514078338246406
Validation loss: 2.394592031717754

Epoch: 5| Step: 6
Training loss: 2.2812293064798803
Validation loss: 2.3958716002016924

Epoch: 5| Step: 7
Training loss: 2.7216617294830496
Validation loss: 2.4131956332455045

Epoch: 5| Step: 8
Training loss: 2.569276177564242
Validation loss: 2.399221681364586

Epoch: 5| Step: 9
Training loss: 2.654428373536264
Validation loss: 2.4177606286226356

Epoch: 5| Step: 10
Training loss: 1.8294652606786244
Validation loss: 2.4034701386806754

Epoch: 107| Step: 0
Training loss: 2.8300924465325172
Validation loss: 2.4059072974144278

Epoch: 5| Step: 1
Training loss: 2.439041237307725
Validation loss: 2.3887306400475565

Epoch: 5| Step: 2
Training loss: 2.4404341814809563
Validation loss: 2.419173886324027

Epoch: 5| Step: 3
Training loss: 2.618250024815019
Validation loss: 2.392300824755667

Epoch: 5| Step: 4
Training loss: 2.278918289607863
Validation loss: 2.406623043255446

Epoch: 5| Step: 5
Training loss: 2.558247829669325
Validation loss: 2.4177645147539866

Epoch: 5| Step: 6
Training loss: 2.3224962022173394
Validation loss: 2.401316825168012

Epoch: 5| Step: 7
Training loss: 2.965281658979065
Validation loss: 2.395869816470657

Epoch: 5| Step: 8
Training loss: 2.5380040236637336
Validation loss: 2.4157418587942874

Epoch: 5| Step: 9
Training loss: 2.036262197065735
Validation loss: 2.398351631098456

Epoch: 5| Step: 10
Training loss: 2.7384137653496317
Validation loss: 2.4110745424226656

Epoch: 108| Step: 0
Training loss: 2.4131133055977867
Validation loss: 2.406796691461491

Epoch: 5| Step: 1
Training loss: 2.792027027917456
Validation loss: 2.395354397392089

Epoch: 5| Step: 2
Training loss: 2.3466466678323523
Validation loss: 2.401098352151543

Epoch: 5| Step: 3
Training loss: 2.951786444323272
Validation loss: 2.4069516357984497

Epoch: 5| Step: 4
Training loss: 2.479945811018043
Validation loss: 2.409754229641713

Epoch: 5| Step: 5
Training loss: 2.25054469403083
Validation loss: 2.4049782196130436

Epoch: 5| Step: 6
Training loss: 2.606273887030822
Validation loss: 2.4070334574065715

Epoch: 5| Step: 7
Training loss: 2.3941478826855036
Validation loss: 2.398461934460521

Epoch: 5| Step: 8
Training loss: 2.8670333280352605
Validation loss: 2.416355689779115

Epoch: 5| Step: 9
Training loss: 2.5248935148239324
Validation loss: 2.3938988687644356

Epoch: 5| Step: 10
Training loss: 2.111234396407634
Validation loss: 2.402232143618551

Epoch: 109| Step: 0
Training loss: 2.9965011538524498
Validation loss: 2.406490651095853

Epoch: 5| Step: 1
Training loss: 2.1816660880410303
Validation loss: 2.393128960063353

Epoch: 5| Step: 2
Training loss: 2.586005910101065
Validation loss: 2.414030936183775

Epoch: 5| Step: 3
Training loss: 2.8142886937729386
Validation loss: 2.4174783207879043

Epoch: 5| Step: 4
Training loss: 2.490816414823364
Validation loss: 2.394399996567196

Epoch: 5| Step: 5
Training loss: 2.6761224905014123
Validation loss: 2.401724837072218

Epoch: 5| Step: 6
Training loss: 2.2586486746391565
Validation loss: 2.4089976448535872

Epoch: 5| Step: 7
Training loss: 2.549778132042873
Validation loss: 2.4003140699070333

Epoch: 5| Step: 8
Training loss: 2.130711117629692
Validation loss: 2.388225775871672

Epoch: 5| Step: 9
Training loss: 2.5010703656510724
Validation loss: 2.417582452599802

Epoch: 5| Step: 10
Training loss: 2.473816224416988
Validation loss: 2.4030072357558487

Epoch: 110| Step: 0
Training loss: 2.3563271345469925
Validation loss: 2.398720549307243

Epoch: 5| Step: 1
Training loss: 2.146451718999202
Validation loss: 2.4030968353495608

Epoch: 5| Step: 2
Training loss: 2.167593378785702
Validation loss: 2.409498121575115

Epoch: 5| Step: 3
Training loss: 2.88024192270809
Validation loss: 2.413904119225513

Epoch: 5| Step: 4
Training loss: 2.6423894641461754
Validation loss: 2.400903266212005

Epoch: 5| Step: 5
Training loss: 2.8907317270732187
Validation loss: 2.403323345148495

Epoch: 5| Step: 6
Training loss: 2.640307887070254
Validation loss: 2.415152152259904

Epoch: 5| Step: 7
Training loss: 2.8605586035942645
Validation loss: 2.3963417355566947

Epoch: 5| Step: 8
Training loss: 2.1826178429109753
Validation loss: 2.404915192097363

Epoch: 5| Step: 9
Training loss: 2.515450702576193
Validation loss: 2.414463507833571

Epoch: 5| Step: 10
Training loss: 2.2592849945670923
Validation loss: 2.39326449244776

Epoch: 111| Step: 0
Training loss: 2.4294760265498243
Validation loss: 2.395397420196789

Epoch: 5| Step: 1
Training loss: 1.9256417802366168
Validation loss: 2.405558810866995

Epoch: 5| Step: 2
Training loss: 2.3480204015752033
Validation loss: 2.4022832860706766

Epoch: 5| Step: 3
Training loss: 2.9144852973277877
Validation loss: 2.4050370968171877

Epoch: 5| Step: 4
Training loss: 2.4883497579057647
Validation loss: 2.391779348048505

Epoch: 5| Step: 5
Training loss: 2.64537551002694
Validation loss: 2.41553521817988

Epoch: 5| Step: 6
Training loss: 2.6341091325030623
Validation loss: 2.4045415043289355

Epoch: 5| Step: 7
Training loss: 1.9499795227931866
Validation loss: 2.423548749561806

Epoch: 5| Step: 8
Training loss: 2.6064145774930103
Validation loss: 2.4144188312323926

Epoch: 5| Step: 9
Training loss: 2.8626796616056613
Validation loss: 2.3991132519573766

Epoch: 5| Step: 10
Training loss: 2.655862218936924
Validation loss: 2.4135916410291367

Epoch: 112| Step: 0
Training loss: 2.013493912063614
Validation loss: 2.3966628145267403

Epoch: 5| Step: 1
Training loss: 2.868003292597925
Validation loss: 2.4069607061603926

Epoch: 5| Step: 2
Training loss: 2.3100782549595293
Validation loss: 2.4125573050453433

Epoch: 5| Step: 3
Training loss: 2.3161951390216644
Validation loss: 2.413454508013729

Epoch: 5| Step: 4
Training loss: 2.3323381436072874
Validation loss: 2.3815168543478618

Epoch: 5| Step: 5
Training loss: 2.7363352697198837
Validation loss: 2.4230297520557893

Epoch: 5| Step: 6
Training loss: 2.3911135305256916
Validation loss: 2.408830146614362

Epoch: 5| Step: 7
Training loss: 3.130325205182004
Validation loss: 2.384791987260157

Epoch: 5| Step: 8
Training loss: 2.286281315259004
Validation loss: 2.3952999817859886

Epoch: 5| Step: 9
Training loss: 2.346159446728866
Validation loss: 2.395575271839884

Epoch: 5| Step: 10
Training loss: 2.6809663529182415
Validation loss: 2.370924407641661

Epoch: 113| Step: 0
Training loss: 2.194356472596671
Validation loss: 2.3839909499119742

Epoch: 5| Step: 1
Training loss: 2.3764852597778523
Validation loss: 2.4132495560934446

Epoch: 5| Step: 2
Training loss: 2.0655796294199975
Validation loss: 2.3990432590502087

Epoch: 5| Step: 3
Training loss: 3.2816632691755347
Validation loss: 2.383766443575154

Epoch: 5| Step: 4
Training loss: 2.0592400189679188
Validation loss: 2.397091277860347

Epoch: 5| Step: 5
Training loss: 2.8112087252492874
Validation loss: 2.390004772930311

Epoch: 5| Step: 6
Training loss: 2.783129967514392
Validation loss: 2.3925220036072115

Epoch: 5| Step: 7
Training loss: 2.737145900033476
Validation loss: 2.4124162153048996

Epoch: 5| Step: 8
Training loss: 2.6848363761842777
Validation loss: 2.392267889318431

Epoch: 5| Step: 9
Training loss: 1.8634006933799143
Validation loss: 2.405880980048507

Epoch: 5| Step: 10
Training loss: 2.186189531435552
Validation loss: 2.425538130772565

Epoch: 114| Step: 0
Training loss: 2.114179437959875
Validation loss: 2.407489348241376

Epoch: 5| Step: 1
Training loss: 2.7792104036091434
Validation loss: 2.3985950690375444

Epoch: 5| Step: 2
Training loss: 2.144117304973441
Validation loss: 2.4155427577406843

Epoch: 5| Step: 3
Training loss: 2.148174810822616
Validation loss: 2.3973014823794974

Epoch: 5| Step: 4
Training loss: 2.3383005495100213
Validation loss: 2.4210069173048443

Epoch: 5| Step: 5
Training loss: 2.2348347437651173
Validation loss: 2.3860653836438575

Epoch: 5| Step: 6
Training loss: 2.44592647949169
Validation loss: 2.4167027769548612

Epoch: 5| Step: 7
Training loss: 2.1278771389148976
Validation loss: 2.411856465596371

Epoch: 5| Step: 8
Training loss: 2.4599892378780996
Validation loss: 2.414723881118942

Epoch: 5| Step: 9
Training loss: 3.4672411137029044
Validation loss: 2.428017965284062

Epoch: 5| Step: 10
Training loss: 3.0213664844991555
Validation loss: 2.4031143181198313

Epoch: 115| Step: 0
Training loss: 2.4875836075577125
Validation loss: 2.402467908701372

Epoch: 5| Step: 1
Training loss: 2.145329116790276
Validation loss: 2.400039371471757

Epoch: 5| Step: 2
Training loss: 2.5479754545385935
Validation loss: 2.3737636493587067

Epoch: 5| Step: 3
Training loss: 2.2140162299577013
Validation loss: 2.400483218593041

Epoch: 5| Step: 4
Training loss: 1.9090587372773207
Validation loss: 2.415165198900429

Epoch: 5| Step: 5
Training loss: 3.025746018657446
Validation loss: 2.4012774518371898

Epoch: 5| Step: 6
Training loss: 2.700345059703905
Validation loss: 2.4022454439837446

Epoch: 5| Step: 7
Training loss: 2.4512492011894236
Validation loss: 2.37420909959413

Epoch: 5| Step: 8
Training loss: 2.759864022457417
Validation loss: 2.420935671393751

Epoch: 5| Step: 9
Training loss: 2.6647070499319034
Validation loss: 2.414792424235091

Epoch: 5| Step: 10
Training loss: 2.566203627578494
Validation loss: 2.4076818407271863

Epoch: 116| Step: 0
Training loss: 2.9398620523799965
Validation loss: 2.412821055089817

Epoch: 5| Step: 1
Training loss: 2.521548860583716
Validation loss: 2.4014878738709773

Epoch: 5| Step: 2
Training loss: 1.934328868112511
Validation loss: 2.4068929811731388

Epoch: 5| Step: 3
Training loss: 2.439166062066833
Validation loss: 2.417210933116911

Epoch: 5| Step: 4
Training loss: 2.4268363095642007
Validation loss: 2.401706040862135

Epoch: 5| Step: 5
Training loss: 2.6036517028274404
Validation loss: 2.4104731426829766

Epoch: 5| Step: 6
Training loss: 2.3859096722831805
Validation loss: 2.3993701789482986

Epoch: 5| Step: 7
Training loss: 2.338197871186388
Validation loss: 2.411372933773342

Epoch: 5| Step: 8
Training loss: 2.0709117094235427
Validation loss: 2.404302059754545

Epoch: 5| Step: 9
Training loss: 2.86676970304094
Validation loss: 2.3802867379335417

Epoch: 5| Step: 10
Training loss: 2.9233479586517777
Validation loss: 2.416782345264503

Epoch: 117| Step: 0
Training loss: 2.2165816551294024
Validation loss: 2.4012306022839565

Epoch: 5| Step: 1
Training loss: 2.285478513768124
Validation loss: 2.3803518085145505

Epoch: 5| Step: 2
Training loss: 2.325830750071577
Validation loss: 2.40277886954267

Epoch: 5| Step: 3
Training loss: 2.295623853741865
Validation loss: 2.3879906401318607

Epoch: 5| Step: 4
Training loss: 1.9709499117652636
Validation loss: 2.3795141018741335

Epoch: 5| Step: 5
Training loss: 2.5678384578971696
Validation loss: 2.4018599564542447

Epoch: 5| Step: 6
Training loss: 3.008364460820194
Validation loss: 2.3916567418445376

Epoch: 5| Step: 7
Training loss: 3.0135690272267452
Validation loss: 2.390921874342314

Epoch: 5| Step: 8
Training loss: 2.669236157199814
Validation loss: 2.3921812266804197

Epoch: 5| Step: 9
Training loss: 2.303528368136598
Validation loss: 2.3960524905972767

Epoch: 5| Step: 10
Training loss: 2.636969841198396
Validation loss: 2.406687255304087

Epoch: 118| Step: 0
Training loss: 2.1310240684521293
Validation loss: 2.4003927516735093

Epoch: 5| Step: 1
Training loss: 2.932182693940978
Validation loss: 2.406963954696458

Epoch: 5| Step: 2
Training loss: 1.510316341181361
Validation loss: 2.4014276659547638

Epoch: 5| Step: 3
Training loss: 2.7330512630094943
Validation loss: 2.4046228951376074

Epoch: 5| Step: 4
Training loss: 2.2708816056559926
Validation loss: 2.4228157769950456

Epoch: 5| Step: 5
Training loss: 2.458871513121821
Validation loss: 2.392670309481159

Epoch: 5| Step: 6
Training loss: 2.1546680341675324
Validation loss: 2.3868480521339284

Epoch: 5| Step: 7
Training loss: 2.710039413278153
Validation loss: 2.401510404880198

Epoch: 5| Step: 8
Training loss: 2.6228201761795846
Validation loss: 2.3934094420045366

Epoch: 5| Step: 9
Training loss: 2.867949423520928
Validation loss: 2.4025165598752762

Epoch: 5| Step: 10
Training loss: 2.5951569199938738
Validation loss: 2.4153963455346488

Epoch: 119| Step: 0
Training loss: 2.7427948281895707
Validation loss: 2.390166513550845

Epoch: 5| Step: 1
Training loss: 2.5982367074979327
Validation loss: 2.424604003444374

Epoch: 5| Step: 2
Training loss: 2.5035762956290926
Validation loss: 2.3881327113223962

Epoch: 5| Step: 3
Training loss: 2.6497106502118664
Validation loss: 2.41891131967384

Epoch: 5| Step: 4
Training loss: 2.289268302128621
Validation loss: 2.411103607993545

Epoch: 5| Step: 5
Training loss: 2.1210361985746644
Validation loss: 2.3903108315702677

Epoch: 5| Step: 6
Training loss: 1.9127799583425338
Validation loss: 2.3935527392411036

Epoch: 5| Step: 7
Training loss: 2.8620566212126803
Validation loss: 2.411504517846095

Epoch: 5| Step: 8
Training loss: 2.7022003179876792
Validation loss: 2.3975947777680253

Epoch: 5| Step: 9
Training loss: 2.652541320363887
Validation loss: 2.397852053492113

Epoch: 5| Step: 10
Training loss: 1.9880445897841046
Validation loss: 2.4131602537890027

Epoch: 120| Step: 0
Training loss: 2.480438472532977
Validation loss: 2.3972212792268826

Epoch: 5| Step: 1
Training loss: 2.69647227227519
Validation loss: 2.3990711421182267

Epoch: 5| Step: 2
Training loss: 2.2776937068631367
Validation loss: 2.4019126598011398

Epoch: 5| Step: 3
Training loss: 2.7770212149821063
Validation loss: 2.3935633030909726

Epoch: 5| Step: 4
Training loss: 3.1116134790479943
Validation loss: 2.4018180377999143

Epoch: 5| Step: 5
Training loss: 1.9647875677308768
Validation loss: 2.3773661281363645

Epoch: 5| Step: 6
Training loss: 2.4958508392722014
Validation loss: 2.400610722110587

Epoch: 5| Step: 7
Training loss: 2.563758820026167
Validation loss: 2.41121212337971

Epoch: 5| Step: 8
Training loss: 2.2072332509189874
Validation loss: 2.3966819562122925

Epoch: 5| Step: 9
Training loss: 2.109306390847468
Validation loss: 2.4047912850100657

Epoch: 5| Step: 10
Training loss: 2.7181938742628042
Validation loss: 2.402543677037708

Epoch: 121| Step: 0
Training loss: 2.7656387932212536
Validation loss: 2.3868514735797906

Epoch: 5| Step: 1
Training loss: 2.540620202767323
Validation loss: 2.400203462341508

Epoch: 5| Step: 2
Training loss: 2.3808569716456285
Validation loss: 2.3824654888468495

Epoch: 5| Step: 3
Training loss: 2.5390672889077432
Validation loss: 2.390904946838987

Epoch: 5| Step: 4
Training loss: 2.841748717643936
Validation loss: 2.3768732361494425

Epoch: 5| Step: 5
Training loss: 2.4271088190882675
Validation loss: 2.399411181972037

Epoch: 5| Step: 6
Training loss: 2.268322936498325
Validation loss: 2.3983493681985064

Epoch: 5| Step: 7
Training loss: 2.7089081569915097
Validation loss: 2.398244201389343

Epoch: 5| Step: 8
Training loss: 2.2634958720471876
Validation loss: 2.4064984214001335

Epoch: 5| Step: 9
Training loss: 2.1865727230376595
Validation loss: 2.394108158017697

Epoch: 5| Step: 10
Training loss: 2.125779962451661
Validation loss: 2.391199944532761

Epoch: 122| Step: 0
Training loss: 2.5002064619641935
Validation loss: 2.398093800691238

Epoch: 5| Step: 1
Training loss: 2.246585692560454
Validation loss: 2.3865547390341035

Epoch: 5| Step: 2
Training loss: 1.951224172691269
Validation loss: 2.3940141602624077

Epoch: 5| Step: 3
Training loss: 2.489394293807778
Validation loss: 2.398072797314255

Epoch: 5| Step: 4
Training loss: 2.936255333360917
Validation loss: 2.412093703652607

Epoch: 5| Step: 5
Training loss: 2.5539270604949484
Validation loss: 2.3839233918209093

Epoch: 5| Step: 6
Training loss: 2.944705485722476
Validation loss: 2.3775015201660574

Epoch: 5| Step: 7
Training loss: 2.313315582793602
Validation loss: 2.3911773496084923

Epoch: 5| Step: 8
Training loss: 2.128423849624102
Validation loss: 2.400431592437111

Epoch: 5| Step: 9
Training loss: 2.5578610368433368
Validation loss: 2.3820219167732883

Epoch: 5| Step: 10
Training loss: 2.4792731339703473
Validation loss: 2.408637208400086

Epoch: 123| Step: 0
Training loss: 2.2399306153722995
Validation loss: 2.409489275688423

Epoch: 5| Step: 1
Training loss: 2.089904442021746
Validation loss: 2.4005103934335272

Epoch: 5| Step: 2
Training loss: 2.698115917099507
Validation loss: 2.3924436697599862

Epoch: 5| Step: 3
Training loss: 3.095234832482487
Validation loss: 2.3982610952627352

Epoch: 5| Step: 4
Training loss: 2.7196186475729127
Validation loss: 2.4070768891910337

Epoch: 5| Step: 5
Training loss: 2.127174947361723
Validation loss: 2.3806047696208785

Epoch: 5| Step: 6
Training loss: 1.84255360725917
Validation loss: 2.3784685459462347

Epoch: 5| Step: 7
Training loss: 1.9785421356503745
Validation loss: 2.3921635032548627

Epoch: 5| Step: 8
Training loss: 2.6916627803179987
Validation loss: 2.3932274455956164

Epoch: 5| Step: 9
Training loss: 2.320690291246758
Validation loss: 2.408324702552886

Epoch: 5| Step: 10
Training loss: 3.0499715084558705
Validation loss: 2.399846931501885

Epoch: 124| Step: 0
Training loss: 2.6574723068043222
Validation loss: 2.382469122648835

Epoch: 5| Step: 1
Training loss: 2.29720848932227
Validation loss: 2.407184314496409

Epoch: 5| Step: 2
Training loss: 2.502006202629079
Validation loss: 2.393857910543596

Epoch: 5| Step: 3
Training loss: 2.25912659098634
Validation loss: 2.403945230314891

Epoch: 5| Step: 4
Training loss: 2.277311818862496
Validation loss: 2.385217981750943

Epoch: 5| Step: 5
Training loss: 2.350454785595162
Validation loss: 2.4116567110479408

Epoch: 5| Step: 6
Training loss: 2.8595754417663684
Validation loss: 2.3966452215837397

Epoch: 5| Step: 7
Training loss: 2.644030660246628
Validation loss: 2.3879591106703915

Epoch: 5| Step: 8
Training loss: 2.572148742569167
Validation loss: 2.3920044130736016

Epoch: 5| Step: 9
Training loss: 2.117725486954847
Validation loss: 2.404221158716268

Epoch: 5| Step: 10
Training loss: 2.6583911120155665
Validation loss: 2.376806834790458

Epoch: 125| Step: 0
Training loss: 2.2682988666697246
Validation loss: 2.4037720240229126

Epoch: 5| Step: 1
Training loss: 2.8918919441645174
Validation loss: 2.3921051429809026

Epoch: 5| Step: 2
Training loss: 2.1172559663745045
Validation loss: 2.4030021628938503

Epoch: 5| Step: 3
Training loss: 2.6025865160425172
Validation loss: 2.3729212881765287

Epoch: 5| Step: 4
Training loss: 2.4420708079901763
Validation loss: 2.401116049664315

Epoch: 5| Step: 5
Training loss: 2.4705220876114375
Validation loss: 2.381783494913242

Epoch: 5| Step: 6
Training loss: 2.8108985580113304
Validation loss: 2.3871581244435225

Epoch: 5| Step: 7
Training loss: 2.1822160390588023
Validation loss: 2.40544648772196

Epoch: 5| Step: 8
Training loss: 2.4090782487448266
Validation loss: 2.403839226913884

Epoch: 5| Step: 9
Training loss: 2.247978361860511
Validation loss: 2.4022970567713

Epoch: 5| Step: 10
Training loss: 2.357099231299745
Validation loss: 2.4199185103755454

Epoch: 126| Step: 0
Training loss: 2.2987881951117437
Validation loss: 2.3914315572661478

Epoch: 5| Step: 1
Training loss: 2.712538804159049
Validation loss: 2.400254097962684

Epoch: 5| Step: 2
Training loss: 2.636255565509013
Validation loss: 2.396720826359985

Epoch: 5| Step: 3
Training loss: 2.1813384336017094
Validation loss: 2.395078962068545

Epoch: 5| Step: 4
Training loss: 2.3315001734455985
Validation loss: 2.3861560233675783

Epoch: 5| Step: 5
Training loss: 2.5133384596100328
Validation loss: 2.384129361506685

Epoch: 5| Step: 6
Training loss: 2.7194514630280913
Validation loss: 2.3850496631961198

Epoch: 5| Step: 7
Training loss: 2.087055835183521
Validation loss: 2.411032601087951

Epoch: 5| Step: 8
Training loss: 2.69441097496543
Validation loss: 2.4011646727102924

Epoch: 5| Step: 9
Training loss: 2.6270768260547497
Validation loss: 2.385053301122511

Epoch: 5| Step: 10
Training loss: 2.1281751584767337
Validation loss: 2.3983197482767293

Epoch: 127| Step: 0
Training loss: 2.8635650119452007
Validation loss: 2.4076411052662867

Epoch: 5| Step: 1
Training loss: 2.3906643932811837
Validation loss: 2.3974724721717764

Epoch: 5| Step: 2
Training loss: 1.920452801240372
Validation loss: 2.399772289990383

Epoch: 5| Step: 3
Training loss: 2.389052528375507
Validation loss: 2.403076335497932

Epoch: 5| Step: 4
Training loss: 2.0246608968247863
Validation loss: 2.3861360086404497

Epoch: 5| Step: 5
Training loss: 2.9476411149247834
Validation loss: 2.408773787647662

Epoch: 5| Step: 6
Training loss: 2.512161619259744
Validation loss: 2.3976561618528613

Epoch: 5| Step: 7
Training loss: 2.3697224254064273
Validation loss: 2.4039149317655824

Epoch: 5| Step: 8
Training loss: 2.3533519133932104
Validation loss: 2.3899263941206383

Epoch: 5| Step: 9
Training loss: 2.1668359494713454
Validation loss: 2.3936655182207778

Epoch: 5| Step: 10
Training loss: 2.8171278284473966
Validation loss: 2.3967336695540267

Epoch: 128| Step: 0
Training loss: 2.5423963989635627
Validation loss: 2.404706300240352

Epoch: 5| Step: 1
Training loss: 2.574449450700605
Validation loss: 2.394891983222935

Epoch: 5| Step: 2
Training loss: 3.191617213995724
Validation loss: 2.3989172185810705

Epoch: 5| Step: 3
Training loss: 2.018561065619459
Validation loss: 2.391583168030297

Epoch: 5| Step: 4
Training loss: 2.2208751118674384
Validation loss: 2.403130519545954

Epoch: 5| Step: 5
Training loss: 2.504589636229984
Validation loss: 2.407492351146493

Epoch: 5| Step: 6
Training loss: 2.558022937728485
Validation loss: 2.4152545767360865

Epoch: 5| Step: 7
Training loss: 2.3497669550818396
Validation loss: 2.3934694553135207

Epoch: 5| Step: 8
Training loss: 2.368472515350186
Validation loss: 2.4022538485855964

Epoch: 5| Step: 9
Training loss: 2.382149225693403
Validation loss: 2.3857390927440547

Epoch: 5| Step: 10
Training loss: 2.206251374587368
Validation loss: 2.4131893261089705

Epoch: 129| Step: 0
Training loss: 2.581258638011897
Validation loss: 2.3955062692902604

Epoch: 5| Step: 1
Training loss: 2.687666067271036
Validation loss: 2.3943395697327263

Epoch: 5| Step: 2
Training loss: 2.1933848106967937
Validation loss: 2.3665836159194247

Epoch: 5| Step: 3
Training loss: 2.1700793191151377
Validation loss: 2.37332126157515

Epoch: 5| Step: 4
Training loss: 2.335085097728829
Validation loss: 2.387262964553926

Epoch: 5| Step: 5
Training loss: 2.3821361144577686
Validation loss: 2.388891464611031

Epoch: 5| Step: 6
Training loss: 2.091487516150264
Validation loss: 2.419327807497626

Epoch: 5| Step: 7
Training loss: 2.7154810754281278
Validation loss: 2.4044295430872062

Epoch: 5| Step: 8
Training loss: 2.845529858636455
Validation loss: 2.383835372982103

Epoch: 5| Step: 9
Training loss: 1.9405487438705697
Validation loss: 2.3897978174427337

Epoch: 5| Step: 10
Training loss: 2.8856828660886658
Validation loss: 2.375949744741451

Epoch: 130| Step: 0
Training loss: 2.8436284301259556
Validation loss: 2.3966008471515585

Epoch: 5| Step: 1
Training loss: 2.4571487568470793
Validation loss: 2.3969193153869393

Epoch: 5| Step: 2
Training loss: 2.315428348896439
Validation loss: 2.4021790620166183

Epoch: 5| Step: 3
Training loss: 2.4521722583532855
Validation loss: 2.389710620559348

Epoch: 5| Step: 4
Training loss: 2.3172105804754946
Validation loss: 2.3902627669307877

Epoch: 5| Step: 5
Training loss: 2.1376188010947943
Validation loss: 2.4054995430492494

Epoch: 5| Step: 6
Training loss: 1.9104590926733926
Validation loss: 2.391609561799109

Epoch: 5| Step: 7
Training loss: 2.8959776112866003
Validation loss: 2.3896783000746464

Epoch: 5| Step: 8
Training loss: 2.394381893409917
Validation loss: 2.3955090116439135

Epoch: 5| Step: 9
Training loss: 2.4947032129671407
Validation loss: 2.3864551348458507

Epoch: 5| Step: 10
Training loss: 2.5086110587578765
Validation loss: 2.4086847195924204

Epoch: 131| Step: 0
Training loss: 2.9493543985257227
Validation loss: 2.3910962462773573

Epoch: 5| Step: 1
Training loss: 2.053299467666238
Validation loss: 2.3990588863459674

Epoch: 5| Step: 2
Training loss: 2.352423323416453
Validation loss: 2.372189304523066

Epoch: 5| Step: 3
Training loss: 2.530803405547922
Validation loss: 2.382266979284302

Epoch: 5| Step: 4
Training loss: 2.1954609559387555
Validation loss: 2.4003103659281684

Epoch: 5| Step: 5
Training loss: 2.588531483886667
Validation loss: 2.4170584034066085

Epoch: 5| Step: 6
Training loss: 2.8907373354966848
Validation loss: 2.3989908271476748

Epoch: 5| Step: 7
Training loss: 2.099657294147941
Validation loss: 2.387439569860546

Epoch: 5| Step: 8
Training loss: 1.9344862602418382
Validation loss: 2.409790368687887

Epoch: 5| Step: 9
Training loss: 2.6106628163899965
Validation loss: 2.3998336082293292

Epoch: 5| Step: 10
Training loss: 2.4984393016624993
Validation loss: 2.3829556609582854

Epoch: 132| Step: 0
Training loss: 2.6685330197752126
Validation loss: 2.4007515445836543

Epoch: 5| Step: 1
Training loss: 3.0714601502426837
Validation loss: 2.4063842676314233

Epoch: 5| Step: 2
Training loss: 2.706173451246239
Validation loss: 2.3909313582809957

Epoch: 5| Step: 3
Training loss: 1.950932240782283
Validation loss: 2.4050786587741544

Epoch: 5| Step: 4
Training loss: 2.5003350033419056
Validation loss: 2.400946822769109

Epoch: 5| Step: 5
Training loss: 2.096715051772963
Validation loss: 2.383128091000796

Epoch: 5| Step: 6
Training loss: 2.3297680682879487
Validation loss: 2.390388427198756

Epoch: 5| Step: 7
Training loss: 2.2190521464329915
Validation loss: 2.4037529963891995

Epoch: 5| Step: 8
Training loss: 1.9937319883292317
Validation loss: 2.401021184859042

Epoch: 5| Step: 9
Training loss: 2.2062641262218174
Validation loss: 2.3821838324225757

Epoch: 5| Step: 10
Training loss: 3.042870966817871
Validation loss: 2.384114895529017

Epoch: 133| Step: 0
Training loss: 2.6383950111503927
Validation loss: 2.404731924715991

Epoch: 5| Step: 1
Training loss: 2.1291743398429825
Validation loss: 2.3973809257488803

Epoch: 5| Step: 2
Training loss: 2.5138560644808696
Validation loss: 2.412336193731361

Epoch: 5| Step: 3
Training loss: 2.6912463490859593
Validation loss: 2.410638645485328

Epoch: 5| Step: 4
Training loss: 2.0510367679359853
Validation loss: 2.3957845307489563

Epoch: 5| Step: 5
Training loss: 1.7979996188739378
Validation loss: 2.404348405365585

Epoch: 5| Step: 6
Training loss: 2.569428358514511
Validation loss: 2.3923504403095905

Epoch: 5| Step: 7
Training loss: 2.0514875085958493
Validation loss: 2.386713733818538

Epoch: 5| Step: 8
Training loss: 2.176299822662617
Validation loss: 2.388526114699432

Epoch: 5| Step: 9
Training loss: 2.890994816398394
Validation loss: 2.384283106424975

Epoch: 5| Step: 10
Training loss: 3.0637402261417024
Validation loss: 2.407547651317306

Epoch: 134| Step: 0
Training loss: 2.5306079191430837
Validation loss: 2.369801273391834

Epoch: 5| Step: 1
Training loss: 2.7911759604761732
Validation loss: 2.387103568178002

Epoch: 5| Step: 2
Training loss: 2.07904158721181
Validation loss: 2.3909682037495528

Epoch: 5| Step: 3
Training loss: 2.577588852128845
Validation loss: 2.400149613292314

Epoch: 5| Step: 4
Training loss: 2.2362202314311337
Validation loss: 2.3905019570962684

Epoch: 5| Step: 5
Training loss: 2.676408012104941
Validation loss: 2.401614130624317

Epoch: 5| Step: 6
Training loss: 2.83423624424567
Validation loss: 2.409804312448735

Epoch: 5| Step: 7
Training loss: 2.1285193975495336
Validation loss: 2.395727793191131

Epoch: 5| Step: 8
Training loss: 1.8962183411180218
Validation loss: 2.3855101287697815

Epoch: 5| Step: 9
Training loss: 2.1811168728402155
Validation loss: 2.3867155576904477

Epoch: 5| Step: 10
Training loss: 2.7149566846451734
Validation loss: 2.376204465894261

Epoch: 135| Step: 0
Training loss: 2.255715633948622
Validation loss: 2.3786008283050073

Epoch: 5| Step: 1
Training loss: 2.5561190919070493
Validation loss: 2.3798902334085885

Epoch: 5| Step: 2
Training loss: 2.711893754003226
Validation loss: 2.400041512075617

Epoch: 5| Step: 3
Training loss: 2.220711928646248
Validation loss: 2.3924749568873613

Epoch: 5| Step: 4
Training loss: 2.122813502367205
Validation loss: 2.3838823740505046

Epoch: 5| Step: 5
Training loss: 2.3494018564518426
Validation loss: 2.397225571882044

Epoch: 5| Step: 6
Training loss: 2.003824154248546
Validation loss: 2.411176351193526

Epoch: 5| Step: 7
Training loss: 2.927358775002307
Validation loss: 2.3919068171505025

Epoch: 5| Step: 8
Training loss: 2.8018722643765486
Validation loss: 2.4058761679182377

Epoch: 5| Step: 9
Training loss: 2.4720265338424254
Validation loss: 2.3736573716588865

Epoch: 5| Step: 10
Training loss: 2.180234997533572
Validation loss: 2.3780764207007903

Epoch: 136| Step: 0
Training loss: 1.9978300482225235
Validation loss: 2.3996085638601263

Epoch: 5| Step: 1
Training loss: 2.647780165216555
Validation loss: 2.4049906530840968

Epoch: 5| Step: 2
Training loss: 2.151454180925276
Validation loss: 2.395461297453034

Epoch: 5| Step: 3
Training loss: 2.3138177570992116
Validation loss: 2.3807121715290407

Epoch: 5| Step: 4
Training loss: 2.565048253310078
Validation loss: 2.372735731140783

Epoch: 5| Step: 5
Training loss: 2.229286856099902
Validation loss: 2.394979063180561

Epoch: 5| Step: 6
Training loss: 2.602507090416886
Validation loss: 2.3743043214197828

Epoch: 5| Step: 7
Training loss: 1.970581958323689
Validation loss: 2.3858272874172646

Epoch: 5| Step: 8
Training loss: 2.5023477974107724
Validation loss: 2.378288326325513

Epoch: 5| Step: 9
Training loss: 3.1170385033509085
Validation loss: 2.3653648797521534

Epoch: 5| Step: 10
Training loss: 2.4124457120963894
Validation loss: 2.379464156173129

Epoch: 137| Step: 0
Training loss: 2.881512604701261
Validation loss: 2.3883518771388026

Epoch: 5| Step: 1
Training loss: 1.959300661273892
Validation loss: 2.406281725542894

Epoch: 5| Step: 2
Training loss: 2.002802792253447
Validation loss: 2.378290901511244

Epoch: 5| Step: 3
Training loss: 2.5463816159015265
Validation loss: 2.3865289064970767

Epoch: 5| Step: 4
Training loss: 2.6686469315005543
Validation loss: 2.403893884868049

Epoch: 5| Step: 5
Training loss: 2.292267726334146
Validation loss: 2.377902478313425

Epoch: 5| Step: 6
Training loss: 2.145096167696113
Validation loss: 2.375382588501424

Epoch: 5| Step: 7
Training loss: 1.9797312550274515
Validation loss: 2.38554130802104

Epoch: 5| Step: 8
Training loss: 2.653368115828119
Validation loss: 2.388314939246779

Epoch: 5| Step: 9
Training loss: 2.7240653858823762
Validation loss: 2.3934224711333036

Epoch: 5| Step: 10
Training loss: 2.7263406482932186
Validation loss: 2.40636720812702

Epoch: 138| Step: 0
Training loss: 2.2284145215275006
Validation loss: 2.3813832478149055

Epoch: 5| Step: 1
Training loss: 2.596160595768254
Validation loss: 2.405474814522658

Epoch: 5| Step: 2
Training loss: 2.09236212892617
Validation loss: 2.3738757096999175

Epoch: 5| Step: 3
Training loss: 2.3223874867823904
Validation loss: 2.3820761417150056

Epoch: 5| Step: 4
Training loss: 2.167082294311548
Validation loss: 2.3729938265675563

Epoch: 5| Step: 5
Training loss: 2.447707980303623
Validation loss: 2.393983151597976

Epoch: 5| Step: 6
Training loss: 2.6172303153564087
Validation loss: 2.3931548209823514

Epoch: 5| Step: 7
Training loss: 2.3579565167288252
Validation loss: 2.419318939270785

Epoch: 5| Step: 8
Training loss: 2.5507877928108087
Validation loss: 2.3901667495180505

Epoch: 5| Step: 9
Training loss: 2.765697155027357
Validation loss: 2.3860133004792528

Epoch: 5| Step: 10
Training loss: 2.355007246617792
Validation loss: 2.3965008598002897

Epoch: 139| Step: 0
Training loss: 2.9225613201094354
Validation loss: 2.3959593844503653

Epoch: 5| Step: 1
Training loss: 2.120037455137938
Validation loss: 2.3894834045354063

Epoch: 5| Step: 2
Training loss: 2.620825763766259
Validation loss: 2.392805204114879

Epoch: 5| Step: 3
Training loss: 2.4259214990341955
Validation loss: 2.37698396459209

Epoch: 5| Step: 4
Training loss: 2.297746765366868
Validation loss: 2.408807816041483

Epoch: 5| Step: 5
Training loss: 1.9570515340336347
Validation loss: 2.3941052218483723

Epoch: 5| Step: 6
Training loss: 1.757309498345022
Validation loss: 2.3954913476208133

Epoch: 5| Step: 7
Training loss: 2.5860446319976926
Validation loss: 2.3960954602103266

Epoch: 5| Step: 8
Training loss: 2.8308163477092623
Validation loss: 2.3929362043375453

Epoch: 5| Step: 9
Training loss: 2.191184619161015
Validation loss: 2.369506730821232

Epoch: 5| Step: 10
Training loss: 2.6346100689868113
Validation loss: 2.4082802287612264

Epoch: 140| Step: 0
Training loss: 3.3272930412790434
Validation loss: 2.381607924447898

Epoch: 5| Step: 1
Training loss: 2.2123098259353675
Validation loss: 2.3877330652312296

Epoch: 5| Step: 2
Training loss: 2.9384630937606744
Validation loss: 2.3658577128189355

Epoch: 5| Step: 3
Training loss: 2.2901935582213686
Validation loss: 2.3882534299269733

Epoch: 5| Step: 4
Training loss: 1.7861137243119591
Validation loss: 2.395267571360767

Epoch: 5| Step: 5
Training loss: 2.410709064215601
Validation loss: 2.4069162572258587

Epoch: 5| Step: 6
Training loss: 2.1174929915743417
Validation loss: 2.3854783451374337

Epoch: 5| Step: 7
Training loss: 2.2298202507208744
Validation loss: 2.3813214254181565

Epoch: 5| Step: 8
Training loss: 2.442469397424405
Validation loss: 2.4028204236156334

Epoch: 5| Step: 9
Training loss: 2.0698773772551258
Validation loss: 2.381427288962211

Epoch: 5| Step: 10
Training loss: 2.215883149037419
Validation loss: 2.368717538042611

Epoch: 141| Step: 0
Training loss: 2.8397090832710847
Validation loss: 2.369798639218038

Epoch: 5| Step: 1
Training loss: 2.6980666974351455
Validation loss: 2.382759014829176

Epoch: 5| Step: 2
Training loss: 2.402690384830652
Validation loss: 2.3886035230613287

Epoch: 5| Step: 3
Training loss: 2.2843723615430216
Validation loss: 2.3927358495387687

Epoch: 5| Step: 4
Training loss: 2.7037402208127586
Validation loss: 2.3842536703479795

Epoch: 5| Step: 5
Training loss: 2.0440245137769613
Validation loss: 2.382660960585529

Epoch: 5| Step: 6
Training loss: 1.8179577835729281
Validation loss: 2.404841125246736

Epoch: 5| Step: 7
Training loss: 2.477293754946538
Validation loss: 2.3788787620905953

Epoch: 5| Step: 8
Training loss: 2.691980220455607
Validation loss: 2.3979077529246196

Epoch: 5| Step: 9
Training loss: 2.264419445388177
Validation loss: 2.3938090635809828

Epoch: 5| Step: 10
Training loss: 1.9644242250232393
Validation loss: 2.377826056330344

Epoch: 142| Step: 0
Training loss: 2.564240213636386
Validation loss: 2.360562385465131

Epoch: 5| Step: 1
Training loss: 1.8855303384084585
Validation loss: 2.3662649240114098

Epoch: 5| Step: 2
Training loss: 2.440335116589975
Validation loss: 2.3735558388762987

Epoch: 5| Step: 3
Training loss: 2.384609857794176
Validation loss: 2.3912462551513305

Epoch: 5| Step: 4
Training loss: 2.4528145563294625
Validation loss: 2.39923802981975

Epoch: 5| Step: 5
Training loss: 2.5700640804747614
Validation loss: 2.3835596003721693

Epoch: 5| Step: 6
Training loss: 2.6267694231772727
Validation loss: 2.4033735758326884

Epoch: 5| Step: 7
Training loss: 2.735559348699338
Validation loss: 2.3811553566782795

Epoch: 5| Step: 8
Training loss: 2.0606490412690266
Validation loss: 2.4028491014497138

Epoch: 5| Step: 9
Training loss: 2.4859594894386117
Validation loss: 2.3741659849187755

Epoch: 5| Step: 10
Training loss: 2.0150604640322967
Validation loss: 2.398323380504788

Epoch: 143| Step: 0
Training loss: 2.4463001730660863
Validation loss: 2.3857220586196783

Epoch: 5| Step: 1
Training loss: 3.426485761278049
Validation loss: 2.388439906638649

Epoch: 5| Step: 2
Training loss: 2.553234468725663
Validation loss: 2.392056928450045

Epoch: 5| Step: 3
Training loss: 1.965538493619627
Validation loss: 2.3776514928999446

Epoch: 5| Step: 4
Training loss: 1.4328552339560405
Validation loss: 2.388912918944223

Epoch: 5| Step: 5
Training loss: 2.775360815974023
Validation loss: 2.3951028709901148

Epoch: 5| Step: 6
Training loss: 1.8475095275302873
Validation loss: 2.3836108476897686

Epoch: 5| Step: 7
Training loss: 2.3490486776116026
Validation loss: 2.4081743831775824

Epoch: 5| Step: 8
Training loss: 2.578452904395965
Validation loss: 2.40360191007423

Epoch: 5| Step: 9
Training loss: 2.3425823100314878
Validation loss: 2.389870613796568

Epoch: 5| Step: 10
Training loss: 2.0827033298324595
Validation loss: 2.392716877714233

Epoch: 144| Step: 0
Training loss: 2.2016322713047556
Validation loss: 2.365228736626644

Epoch: 5| Step: 1
Training loss: 2.218587197791721
Validation loss: 2.3756223013347304

Epoch: 5| Step: 2
Training loss: 1.8622008576276539
Validation loss: 2.4086943560366154

Epoch: 5| Step: 3
Training loss: 2.3601044796591584
Validation loss: 2.398481541305042

Epoch: 5| Step: 4
Training loss: 2.6462822981256724
Validation loss: 2.393794801748424

Epoch: 5| Step: 5
Training loss: 2.655140813480596
Validation loss: 2.404494941206055

Epoch: 5| Step: 6
Training loss: 2.2789858726006678
Validation loss: 2.378146942301772

Epoch: 5| Step: 7
Training loss: 2.6503603996065768
Validation loss: 2.3893388637938093

Epoch: 5| Step: 8
Training loss: 2.479761698717838
Validation loss: 2.3817593769416963

Epoch: 5| Step: 9
Training loss: 1.708364145264682
Validation loss: 2.388267942756997

Epoch: 5| Step: 10
Training loss: 3.033072012519631
Validation loss: 2.360490129723611

Epoch: 145| Step: 0
Training loss: 1.9725189463354575
Validation loss: 2.3834993848718273

Epoch: 5| Step: 1
Training loss: 2.533027495779025
Validation loss: 2.3677746016858277

Epoch: 5| Step: 2
Training loss: 2.7832618037948094
Validation loss: 2.4078703220382542

Epoch: 5| Step: 3
Training loss: 2.57096988886171
Validation loss: 2.3743074969445033

Epoch: 5| Step: 4
Training loss: 2.249980926432827
Validation loss: 2.3753549162733423

Epoch: 5| Step: 5
Training loss: 1.9531591793884329
Validation loss: 2.361607291533064

Epoch: 5| Step: 6
Training loss: 2.442964932127953
Validation loss: 2.370693274262583

Epoch: 5| Step: 7
Training loss: 1.7952365869154623
Validation loss: 2.380549615173794

Epoch: 5| Step: 8
Training loss: 3.0905250155145154
Validation loss: 2.391672439914095

Epoch: 5| Step: 9
Training loss: 2.2070420526560843
Validation loss: 2.385819224675207

Epoch: 5| Step: 10
Training loss: 2.42767554877065
Validation loss: 2.3807516782230334

Epoch: 146| Step: 0
Training loss: 2.5972707361959033
Validation loss: 2.3905763556136974

Epoch: 5| Step: 1
Training loss: 2.5509557503661107
Validation loss: 2.398212691282319

Epoch: 5| Step: 2
Training loss: 1.7421902370003726
Validation loss: 2.389356276096053

Epoch: 5| Step: 3
Training loss: 2.182422521730037
Validation loss: 2.383728256982924

Epoch: 5| Step: 4
Training loss: 2.424208863976126
Validation loss: 2.3780293205111476

Epoch: 5| Step: 5
Training loss: 2.230269174281929
Validation loss: 2.3978015007910902

Epoch: 5| Step: 6
Training loss: 2.6066229464221427
Validation loss: 2.3856357427829806

Epoch: 5| Step: 7
Training loss: 2.771831638551809
Validation loss: 2.3872121328443177

Epoch: 5| Step: 8
Training loss: 2.046849490873072
Validation loss: 2.3803907439265095

Epoch: 5| Step: 9
Training loss: 2.2823265357395655
Validation loss: 2.3763417295125846

Epoch: 5| Step: 10
Training loss: 2.545666741530703
Validation loss: 2.392514967981567

Epoch: 147| Step: 0
Training loss: 2.841988657349536
Validation loss: 2.3699914178476105

Epoch: 5| Step: 1
Training loss: 2.659563936902562
Validation loss: 2.3840484291852575

Epoch: 5| Step: 2
Training loss: 2.1977169675335277
Validation loss: 2.3843049634971623

Epoch: 5| Step: 3
Training loss: 2.7061360077493783
Validation loss: 2.387807207530368

Epoch: 5| Step: 4
Training loss: 2.3156807134724007
Validation loss: 2.394895466503442

Epoch: 5| Step: 5
Training loss: 1.9739733236610961
Validation loss: 2.3749702345964154

Epoch: 5| Step: 6
Training loss: 2.170675481620592
Validation loss: 2.382940677911827

Epoch: 5| Step: 7
Training loss: 2.0477429362508097
Validation loss: 2.3922079262404896

Epoch: 5| Step: 8
Training loss: 2.3352027171193304
Validation loss: 2.3958628837685567

Epoch: 5| Step: 9
Training loss: 1.9163965435692007
Validation loss: 2.3864151338748085

Epoch: 5| Step: 10
Training loss: 2.7538255612071034
Validation loss: 2.3733325344232754

Epoch: 148| Step: 0
Training loss: 2.585919982297633
Validation loss: 2.3766880167811144

Epoch: 5| Step: 1
Training loss: 1.9996785859286197
Validation loss: 2.3905126513218717

Epoch: 5| Step: 2
Training loss: 2.505275881379392
Validation loss: 2.379045804946147

Epoch: 5| Step: 3
Training loss: 2.353451600529562
Validation loss: 2.402524869093802

Epoch: 5| Step: 4
Training loss: 2.3937883578182864
Validation loss: 2.374191971407621

Epoch: 5| Step: 5
Training loss: 2.3713051012038933
Validation loss: 2.392332583115147

Epoch: 5| Step: 6
Training loss: 2.4278410245958133
Validation loss: 2.376075683453252

Epoch: 5| Step: 7
Training loss: 2.3318102043349342
Validation loss: 2.3764609229852556

Epoch: 5| Step: 8
Training loss: 2.219320626824168
Validation loss: 2.4140527129460234

Epoch: 5| Step: 9
Training loss: 2.514979498838437
Validation loss: 2.363182869238666

Epoch: 5| Step: 10
Training loss: 2.4516504800738894
Validation loss: 2.416432921704078

Epoch: 149| Step: 0
Training loss: 1.9778591320840846
Validation loss: 2.3790260262022715

Epoch: 5| Step: 1
Training loss: 2.1562828393176963
Validation loss: 2.384559087789275

Epoch: 5| Step: 2
Training loss: 2.8895329242499916
Validation loss: 2.3937192261116764

Epoch: 5| Step: 3
Training loss: 2.476109797260287
Validation loss: 2.3784993443326052

Epoch: 5| Step: 4
Training loss: 2.7022207875659268
Validation loss: 2.3855507907828475

Epoch: 5| Step: 5
Training loss: 2.44594928871668
Validation loss: 2.3926734000936047

Epoch: 5| Step: 6
Training loss: 2.7680030555763357
Validation loss: 2.4003257190328333

Epoch: 5| Step: 7
Training loss: 1.9847057997950508
Validation loss: 2.389416023195721

Epoch: 5| Step: 8
Training loss: 2.256062076593821
Validation loss: 2.4084680565199643

Epoch: 5| Step: 9
Training loss: 2.0287030023853188
Validation loss: 2.3871217909685205

Epoch: 5| Step: 10
Training loss: 2.1416335131779305
Validation loss: 2.4056278314558526

Epoch: 150| Step: 0
Training loss: 2.1834449239658946
Validation loss: 2.3951473839560076

Epoch: 5| Step: 1
Training loss: 2.198418208988578
Validation loss: 2.4053361572006393

Epoch: 5| Step: 2
Training loss: 1.5577015247054167
Validation loss: 2.4045326967146607

Epoch: 5| Step: 3
Training loss: 2.4784881133348
Validation loss: 2.3815569628878186

Epoch: 5| Step: 4
Training loss: 1.7945091262802144
Validation loss: 2.388822954758761

Epoch: 5| Step: 5
Training loss: 2.5998248004572364
Validation loss: 2.370938530238952

Epoch: 5| Step: 6
Training loss: 2.7695137744346834
Validation loss: 2.388790587385015

Epoch: 5| Step: 7
Training loss: 2.8847251274556682
Validation loss: 2.4095810270429188

Epoch: 5| Step: 8
Training loss: 2.161269826980113
Validation loss: 2.3905527022301585

Epoch: 5| Step: 9
Training loss: 2.645819346073054
Validation loss: 2.3703677588180363

Epoch: 5| Step: 10
Training loss: 2.5101197464179714
Validation loss: 2.3910946728802696

Epoch: 151| Step: 0
Training loss: 2.6015935672588983
Validation loss: 2.394391815473148

Epoch: 5| Step: 1
Training loss: 2.2591273297363452
Validation loss: 2.3905102657158235

Epoch: 5| Step: 2
Training loss: 1.9788886694836922
Validation loss: 2.361935636450282

Epoch: 5| Step: 3
Training loss: 2.737312352268077
Validation loss: 2.383139533684081

Epoch: 5| Step: 4
Training loss: 2.470882798247084
Validation loss: 2.381507500848144

Epoch: 5| Step: 5
Training loss: 2.126953461281826
Validation loss: 2.381151320361681

Epoch: 5| Step: 6
Training loss: 2.6708151516664977
Validation loss: 2.3816120105829013

Epoch: 5| Step: 7
Training loss: 1.9341235735408533
Validation loss: 2.3705994176083514

Epoch: 5| Step: 8
Training loss: 2.74130582628229
Validation loss: 2.395626980177521

Epoch: 5| Step: 9
Training loss: 2.0430372529370158
Validation loss: 2.3910244682959014

Epoch: 5| Step: 10
Training loss: 2.4266263561603605
Validation loss: 2.3584579068606453

Epoch: 152| Step: 0
Training loss: 2.4066372844596704
Validation loss: 2.3687049130895605

Epoch: 5| Step: 1
Training loss: 1.6083909516892814
Validation loss: 2.3642659438924243

Epoch: 5| Step: 2
Training loss: 2.608721439952823
Validation loss: 2.3867530197970868

Epoch: 5| Step: 3
Training loss: 2.329719458296216
Validation loss: 2.3736550474155416

Epoch: 5| Step: 4
Training loss: 2.588620180184003
Validation loss: 2.4106072633600673

Epoch: 5| Step: 5
Training loss: 2.3736713105909706
Validation loss: 2.3923653697819987

Epoch: 5| Step: 6
Training loss: 3.0133493959229454
Validation loss: 2.3779776354138353

Epoch: 5| Step: 7
Training loss: 2.380352513949924
Validation loss: 2.4048430568982355

Epoch: 5| Step: 8
Training loss: 1.914209103322167
Validation loss: 2.3841088189964976

Epoch: 5| Step: 9
Training loss: 2.4486862163405485
Validation loss: 2.3920861800865105

Epoch: 5| Step: 10
Training loss: 2.308906546894278
Validation loss: 2.388146001112619

Epoch: 153| Step: 0
Training loss: 2.3439556794517014
Validation loss: 2.3550045360236465

Epoch: 5| Step: 1
Training loss: 2.643870779755078
Validation loss: 2.415057638172605

Epoch: 5| Step: 2
Training loss: 2.650494522161028
Validation loss: 2.3902670988959955

Epoch: 5| Step: 3
Training loss: 2.1443506939588124
Validation loss: 2.380680394913079

Epoch: 5| Step: 4
Training loss: 2.5078012816751616
Validation loss: 2.384628054488153

Epoch: 5| Step: 5
Training loss: 2.421019372231502
Validation loss: 2.366180646572627

Epoch: 5| Step: 6
Training loss: 2.2016941050172867
Validation loss: 2.391467653743899

Epoch: 5| Step: 7
Training loss: 2.255584356544828
Validation loss: 2.380964786406397

Epoch: 5| Step: 8
Training loss: 2.420056651059214
Validation loss: 2.3911095705236227

Epoch: 5| Step: 9
Training loss: 2.153284106307007
Validation loss: 2.386066983457363

Epoch: 5| Step: 10
Training loss: 1.9582274658589676
Validation loss: 2.394833096389551

Epoch: 154| Step: 0
Training loss: 2.5276221191305317
Validation loss: 2.3710760646485625

Epoch: 5| Step: 1
Training loss: 2.45802915167535
Validation loss: 2.3758456705855653

Epoch: 5| Step: 2
Training loss: 2.023441977477551
Validation loss: 2.377892063747228

Epoch: 5| Step: 3
Training loss: 1.8909996229037227
Validation loss: 2.3698077241303306

Epoch: 5| Step: 4
Training loss: 1.894450329497672
Validation loss: 2.3887223182620105

Epoch: 5| Step: 5
Training loss: 2.8214651695209394
Validation loss: 2.3960816544030084

Epoch: 5| Step: 6
Training loss: 2.688540501220482
Validation loss: 2.373243725267658

Epoch: 5| Step: 7
Training loss: 1.9671424478791064
Validation loss: 2.409936298643633

Epoch: 5| Step: 8
Training loss: 2.5872805700461687
Validation loss: 2.394410108065306

Epoch: 5| Step: 9
Training loss: 2.0021398540964435
Validation loss: 2.373583009864004

Epoch: 5| Step: 10
Training loss: 2.99026578940267
Validation loss: 2.380348451500908

Epoch: 155| Step: 0
Training loss: 2.3203745618541425
Validation loss: 2.3569324522068076

Epoch: 5| Step: 1
Training loss: 2.3554131800231373
Validation loss: 2.372870381524273

Epoch: 5| Step: 2
Training loss: 1.6724002048843576
Validation loss: 2.381147069786686

Epoch: 5| Step: 3
Training loss: 1.8026562774041872
Validation loss: 2.3829650120012142

Epoch: 5| Step: 4
Training loss: 2.349588471761236
Validation loss: 2.3705806395592335

Epoch: 5| Step: 5
Training loss: 2.7405930798888973
Validation loss: 2.4089209503698483

Epoch: 5| Step: 6
Training loss: 2.2738037863016793
Validation loss: 2.3677842595425407

Epoch: 5| Step: 7
Training loss: 2.869305818189462
Validation loss: 2.3819410689071407

Epoch: 5| Step: 8
Training loss: 3.082436113151836
Validation loss: 2.3760840732678217

Epoch: 5| Step: 9
Training loss: 2.4417931334082876
Validation loss: 2.3923828623929797

Epoch: 5| Step: 10
Training loss: 1.2680406005959852
Validation loss: 2.3875502275645744

Epoch: 156| Step: 0
Training loss: 2.33940240076005
Validation loss: 2.3540629350345226

Epoch: 5| Step: 1
Training loss: 2.360619122227953
Validation loss: 2.3763989342363243

Epoch: 5| Step: 2
Training loss: 1.3524522443650142
Validation loss: 2.380546093671438

Epoch: 5| Step: 3
Training loss: 2.586568334798026
Validation loss: 2.3925976058103258

Epoch: 5| Step: 4
Training loss: 2.321753365987517
Validation loss: 2.3731848349120517

Epoch: 5| Step: 5
Training loss: 2.273715497091192
Validation loss: 2.388640207493551

Epoch: 5| Step: 6
Training loss: 2.4170734676989847
Validation loss: 2.3801842563065083

Epoch: 5| Step: 7
Training loss: 2.7972011269467707
Validation loss: 2.3756919569570467

Epoch: 5| Step: 8
Training loss: 2.0272488434026528
Validation loss: 2.3704882460170436

Epoch: 5| Step: 9
Training loss: 2.2671743422796173
Validation loss: 2.377976084061954

Epoch: 5| Step: 10
Training loss: 2.9228892478463466
Validation loss: 2.385603097896474

Epoch: 157| Step: 0
Training loss: 1.9606774754261427
Validation loss: 2.3685168349893906

Epoch: 5| Step: 1
Training loss: 2.234981001190747
Validation loss: 2.3733580731240487

Epoch: 5| Step: 2
Training loss: 2.2152082086187153
Validation loss: 2.3785640989727637

Epoch: 5| Step: 3
Training loss: 2.072894404561742
Validation loss: 2.3758096701872247

Epoch: 5| Step: 4
Training loss: 2.1243915808833886
Validation loss: 2.401117122689612

Epoch: 5| Step: 5
Training loss: 2.559314981392621
Validation loss: 2.365852669202833

Epoch: 5| Step: 6
Training loss: 2.11136313099738
Validation loss: 2.3660131423794333

Epoch: 5| Step: 7
Training loss: 2.1382749703049915
Validation loss: 2.3836389376314804

Epoch: 5| Step: 8
Training loss: 2.6648479657348103
Validation loss: 2.3835188172689348

Epoch: 5| Step: 9
Training loss: 2.961477426705995
Validation loss: 2.3825530762428855

Epoch: 5| Step: 10
Training loss: 2.605253882749069
Validation loss: 2.374639007645973

Epoch: 158| Step: 0
Training loss: 2.131035480162731
Validation loss: 2.3984625608174355

Epoch: 5| Step: 1
Training loss: 2.1449412247579223
Validation loss: 2.369824735259079

Epoch: 5| Step: 2
Training loss: 2.634055548833088
Validation loss: 2.3804835877531465

Epoch: 5| Step: 3
Training loss: 2.194798202275589
Validation loss: 2.362190380317895

Epoch: 5| Step: 4
Training loss: 2.1565269624053625
Validation loss: 2.373495554820053

Epoch: 5| Step: 5
Training loss: 2.562368994364639
Validation loss: 2.3892611106855917

Epoch: 5| Step: 6
Training loss: 2.2789548014117003
Validation loss: 2.3769595876069585

Epoch: 5| Step: 7
Training loss: 2.277809579622069
Validation loss: 2.3761908002152548

Epoch: 5| Step: 8
Training loss: 2.4527490412794113
Validation loss: 2.38316712089945

Epoch: 5| Step: 9
Training loss: 2.666093426921078
Validation loss: 2.398033199670167

Epoch: 5| Step: 10
Training loss: 2.2431002895538534
Validation loss: 2.393763346594555

Epoch: 159| Step: 0
Training loss: 2.153355853767064
Validation loss: 2.404820188262279

Epoch: 5| Step: 1
Training loss: 2.6640784299491655
Validation loss: 2.3653821937867088

Epoch: 5| Step: 2
Training loss: 2.5190615667169394
Validation loss: 2.3682569190966944

Epoch: 5| Step: 3
Training loss: 2.536454489911958
Validation loss: 2.3646323859536174

Epoch: 5| Step: 4
Training loss: 2.2462113590132944
Validation loss: 2.3719621626232117

Epoch: 5| Step: 5
Training loss: 1.9419357222537605
Validation loss: 2.369916900459333

Epoch: 5| Step: 6
Training loss: 2.3725444748531586
Validation loss: 2.3762528278383437

Epoch: 5| Step: 7
Training loss: 2.32671984568962
Validation loss: 2.387390513723786

Epoch: 5| Step: 8
Training loss: 1.9753969397207256
Validation loss: 2.3761569056691525

Epoch: 5| Step: 9
Training loss: 1.9512099986891147
Validation loss: 2.3710632662839064

Epoch: 5| Step: 10
Training loss: 2.982854325893974
Validation loss: 2.3974360608297545

Epoch: 160| Step: 0
Training loss: 1.742205222001196
Validation loss: 2.377238382971032

Epoch: 5| Step: 1
Training loss: 1.5986867999245287
Validation loss: 2.3639693896772926

Epoch: 5| Step: 2
Training loss: 2.4669974178367187
Validation loss: 2.3798648832997715

Epoch: 5| Step: 3
Training loss: 2.6826812658721635
Validation loss: 2.365268763150295

Epoch: 5| Step: 4
Training loss: 2.394063434050427
Validation loss: 2.3840130806500945

Epoch: 5| Step: 5
Training loss: 2.472044087063131
Validation loss: 2.384467100417381

Epoch: 5| Step: 6
Training loss: 2.292175675708148
Validation loss: 2.400594943661161

Epoch: 5| Step: 7
Training loss: 2.3106279786193653
Validation loss: 2.3768234733247486

Epoch: 5| Step: 8
Training loss: 2.464289825151699
Validation loss: 2.3753979958784064

Epoch: 5| Step: 9
Training loss: 2.7380260397576333
Validation loss: 2.3777789430951177

Epoch: 5| Step: 10
Training loss: 2.403744272273833
Validation loss: 2.37697004940007

Epoch: 161| Step: 0
Training loss: 2.32392104349921
Validation loss: 2.388418074526105

Epoch: 5| Step: 1
Training loss: 2.213491629240668
Validation loss: 2.3703118259270175

Epoch: 5| Step: 2
Training loss: 2.6869986310415186
Validation loss: 2.36844837765084

Epoch: 5| Step: 3
Training loss: 2.0412741173407465
Validation loss: 2.3654121156078816

Epoch: 5| Step: 4
Training loss: 2.1358270266357056
Validation loss: 2.3556359771703557

Epoch: 5| Step: 5
Training loss: 2.6101560052016963
Validation loss: 2.36890326048047

Epoch: 5| Step: 6
Training loss: 2.1242333319424107
Validation loss: 2.4009475680671177

Epoch: 5| Step: 7
Training loss: 2.096318960585263
Validation loss: 2.401184225856301

Epoch: 5| Step: 8
Training loss: 2.4941189256409726
Validation loss: 2.3909539909133497

Epoch: 5| Step: 9
Training loss: 2.8272438995109312
Validation loss: 2.3684637186485142

Epoch: 5| Step: 10
Training loss: 2.0576497470504704
Validation loss: 2.390951910259838

Epoch: 162| Step: 0
Training loss: 1.8561237664761638
Validation loss: 2.3752419748401667

Epoch: 5| Step: 1
Training loss: 2.0358536416830173
Validation loss: 2.3739221903535155

Epoch: 5| Step: 2
Training loss: 2.2933619615335226
Validation loss: 2.376183687104638

Epoch: 5| Step: 3
Training loss: 2.7200551024633697
Validation loss: 2.3749313398538905

Epoch: 5| Step: 4
Training loss: 2.232889708778426
Validation loss: 2.3967630170690932

Epoch: 5| Step: 5
Training loss: 2.4179863998434485
Validation loss: 2.3707854576026817

Epoch: 5| Step: 6
Training loss: 2.4859189208443553
Validation loss: 2.3675667165146868

Epoch: 5| Step: 7
Training loss: 2.423157776774971
Validation loss: 2.3969403673750938

Epoch: 5| Step: 8
Training loss: 2.1615042317737503
Validation loss: 2.3651004204373747

Epoch: 5| Step: 9
Training loss: 2.1562064346114145
Validation loss: 2.374294527042558

Epoch: 5| Step: 10
Training loss: 2.716218493261764
Validation loss: 2.395407996245932

Epoch: 163| Step: 0
Training loss: 1.6761831232963438
Validation loss: 2.3657771935545244

Epoch: 5| Step: 1
Training loss: 2.848340866617591
Validation loss: 2.38459960368201

Epoch: 5| Step: 2
Training loss: 2.299810492959764
Validation loss: 2.3699171957751095

Epoch: 5| Step: 3
Training loss: 2.2907535699044073
Validation loss: 2.3906586347285272

Epoch: 5| Step: 4
Training loss: 2.1840979142510175
Validation loss: 2.3502792298106514

Epoch: 5| Step: 5
Training loss: 2.0517798907813782
Validation loss: 2.3527350505350015

Epoch: 5| Step: 6
Training loss: 2.047950753141413
Validation loss: 2.365014438126767

Epoch: 5| Step: 7
Training loss: 2.5317379516483633
Validation loss: 2.376368300655554

Epoch: 5| Step: 8
Training loss: 2.267087267205218
Validation loss: 2.377737618785971

Epoch: 5| Step: 9
Training loss: 2.6501157051593847
Validation loss: 2.371932517978849

Epoch: 5| Step: 10
Training loss: 2.6177191806320024
Validation loss: 2.365463962005339

Epoch: 164| Step: 0
Training loss: 2.196036114338404
Validation loss: 2.373758799119358

Epoch: 5| Step: 1
Training loss: 2.1316526284350856
Validation loss: 2.376565589920845

Epoch: 5| Step: 2
Training loss: 2.3291150746463396
Validation loss: 2.3790439003015926

Epoch: 5| Step: 3
Training loss: 2.664043616622271
Validation loss: 2.385199009244102

Epoch: 5| Step: 4
Training loss: 2.268730403090402
Validation loss: 2.359675497406515

Epoch: 5| Step: 5
Training loss: 2.689975042404625
Validation loss: 2.3738870954680484

Epoch: 5| Step: 6
Training loss: 1.871682729383224
Validation loss: 2.4177997239857283

Epoch: 5| Step: 7
Training loss: 2.202591743593563
Validation loss: 2.395700289619972

Epoch: 5| Step: 8
Training loss: 2.3173948497435477
Validation loss: 2.3967691556462745

Epoch: 5| Step: 9
Training loss: 2.8347343646004433
Validation loss: 2.3873520538194533

Epoch: 5| Step: 10
Training loss: 1.8764841563620405
Validation loss: 2.3967057175756343

Epoch: 165| Step: 0
Training loss: 1.8215005296763451
Validation loss: 2.390167175867828

Epoch: 5| Step: 1
Training loss: 2.8342167281235033
Validation loss: 2.3841994701997535

Epoch: 5| Step: 2
Training loss: 2.0633743051375353
Validation loss: 2.394462236635991

Epoch: 5| Step: 3
Training loss: 2.12243901932354
Validation loss: 2.3770309803408907

Epoch: 5| Step: 4
Training loss: 2.135923359621091
Validation loss: 2.393030511187098

Epoch: 5| Step: 5
Training loss: 2.1153263484159446
Validation loss: 2.385877192320714

Epoch: 5| Step: 6
Training loss: 2.1955064572487144
Validation loss: 2.391171421822899

Epoch: 5| Step: 7
Training loss: 2.2954173750318576
Validation loss: 2.369165729523977

Epoch: 5| Step: 8
Training loss: 2.605776195316498
Validation loss: 2.3762825577569076

Epoch: 5| Step: 9
Training loss: 2.3116599954381867
Validation loss: 2.398484180719397

Epoch: 5| Step: 10
Training loss: 2.714256519504801
Validation loss: 2.3586587137094135

Epoch: 166| Step: 0
Training loss: 2.661722447577781
Validation loss: 2.377782731767754

Epoch: 5| Step: 1
Training loss: 1.8024779826603885
Validation loss: 2.3700832234018705

Epoch: 5| Step: 2
Training loss: 2.259184634893433
Validation loss: 2.386051383886891

Epoch: 5| Step: 3
Training loss: 2.354225956893182
Validation loss: 2.3820495540621502

Epoch: 5| Step: 4
Training loss: 2.1955472881703746
Validation loss: 2.349583531246273

Epoch: 5| Step: 5
Training loss: 2.539394509543103
Validation loss: 2.393347554816574

Epoch: 5| Step: 6
Training loss: 2.292997967665479
Validation loss: 2.3562753939245553

Epoch: 5| Step: 7
Training loss: 2.1449994686099374
Validation loss: 2.3833024426188096

Epoch: 5| Step: 8
Training loss: 2.599658257693348
Validation loss: 2.373533721884984

Epoch: 5| Step: 9
Training loss: 2.3584325057386644
Validation loss: 2.3688586926656687

Epoch: 5| Step: 10
Training loss: 1.964054684862416
Validation loss: 2.3525282436008967

Epoch: 167| Step: 0
Training loss: 2.120957400047479
Validation loss: 2.360021823470519

Epoch: 5| Step: 1
Training loss: 2.0941961012488397
Validation loss: 2.390431492192399

Epoch: 5| Step: 2
Training loss: 2.563247943674578
Validation loss: 2.367437299064064

Epoch: 5| Step: 3
Training loss: 2.787368302591312
Validation loss: 2.37858760697476

Epoch: 5| Step: 4
Training loss: 2.141149080818873
Validation loss: 2.3635652186247746

Epoch: 5| Step: 5
Training loss: 2.374613077870221
Validation loss: 2.374354992181123

Epoch: 5| Step: 6
Training loss: 2.2420843545934646
Validation loss: 2.3623005511475266

Epoch: 5| Step: 7
Training loss: 2.4403974478287633
Validation loss: 2.374108096848937

Epoch: 5| Step: 8
Training loss: 1.990107508875112
Validation loss: 2.378759931718049

Epoch: 5| Step: 9
Training loss: 2.178694632215712
Validation loss: 2.4077182302196762

Epoch: 5| Step: 10
Training loss: 2.362889583699039
Validation loss: 2.3779096725311186

Epoch: 168| Step: 0
Training loss: 2.57140264611572
Validation loss: 2.385268586187334

Epoch: 5| Step: 1
Training loss: 2.419738811868664
Validation loss: 2.390949694503927

Epoch: 5| Step: 2
Training loss: 1.7615892316147832
Validation loss: 2.3560464566492247

Epoch: 5| Step: 3
Training loss: 2.466758020960339
Validation loss: 2.368456876746848

Epoch: 5| Step: 4
Training loss: 2.334711065447876
Validation loss: 2.364331746528128

Epoch: 5| Step: 5
Training loss: 1.959185908439555
Validation loss: 2.365594682756457

Epoch: 5| Step: 6
Training loss: 2.491486549459028
Validation loss: 2.364216197636474

Epoch: 5| Step: 7
Training loss: 2.6548611768790766
Validation loss: 2.3483257809425706

Epoch: 5| Step: 8
Training loss: 2.2910174982009606
Validation loss: 2.3820339663886827

Epoch: 5| Step: 9
Training loss: 2.1259580584217113
Validation loss: 2.373613307851403

Epoch: 5| Step: 10
Training loss: 2.091043117434389
Validation loss: 2.383111764347037

Epoch: 169| Step: 0
Training loss: 2.1317509395274743
Validation loss: 2.3703250415036585

Epoch: 5| Step: 1
Training loss: 2.433568081789292
Validation loss: 2.365863628177521

Epoch: 5| Step: 2
Training loss: 2.0437604198131862
Validation loss: 2.3665393077402523

Epoch: 5| Step: 3
Training loss: 2.2117282275687744
Validation loss: 2.380526579392482

Epoch: 5| Step: 4
Training loss: 2.7442182971102764
Validation loss: 2.3743746203456704

Epoch: 5| Step: 5
Training loss: 2.1082125250942694
Validation loss: 2.379805960731352

Epoch: 5| Step: 6
Training loss: 2.0804911745118457
Validation loss: 2.340127139227975

Epoch: 5| Step: 7
Training loss: 2.6273431764908866
Validation loss: 2.3892734360291428

Epoch: 5| Step: 8
Training loss: 2.0807793666495638
Validation loss: 2.349937475180401

Epoch: 5| Step: 9
Training loss: 2.2539488790040956
Validation loss: 2.364255618895147

Epoch: 5| Step: 10
Training loss: 2.5051865183514255
Validation loss: 2.356621992303594

Epoch: 170| Step: 0
Training loss: 1.8651969226851859
Validation loss: 2.3654290759794856

Epoch: 5| Step: 1
Training loss: 2.5533310208256195
Validation loss: 2.395259590164722

Epoch: 5| Step: 2
Training loss: 2.203971321473232
Validation loss: 2.339280147516568

Epoch: 5| Step: 3
Training loss: 2.0459556553380183
Validation loss: 2.380276705914861

Epoch: 5| Step: 4
Training loss: 2.5081705093342523
Validation loss: 2.3611877579365883

Epoch: 5| Step: 5
Training loss: 2.261780416804229
Validation loss: 2.392777507310513

Epoch: 5| Step: 6
Training loss: 2.6868271096206
Validation loss: 2.360484798235064

Epoch: 5| Step: 7
Training loss: 2.263493449409567
Validation loss: 2.3712513856665756

Epoch: 5| Step: 8
Training loss: 2.096040184880653
Validation loss: 2.372357728828913

Epoch: 5| Step: 9
Training loss: 2.244739953763458
Validation loss: 2.3732400319705644

Epoch: 5| Step: 10
Training loss: 2.4486118276499695
Validation loss: 2.382798513408074

Epoch: 171| Step: 0
Training loss: 2.315268225733745
Validation loss: 2.3931768005620038

Epoch: 5| Step: 1
Training loss: 2.49741229601152
Validation loss: 2.3687098007347465

Epoch: 5| Step: 2
Training loss: 2.106119540104957
Validation loss: 2.353356344893755

Epoch: 5| Step: 3
Training loss: 2.185079597926282
Validation loss: 2.3673687357879163

Epoch: 5| Step: 4
Training loss: 2.2333304357747124
Validation loss: 2.3811863410210807

Epoch: 5| Step: 5
Training loss: 2.270726845953856
Validation loss: 2.3860787956133414

Epoch: 5| Step: 6
Training loss: 2.3980220472135194
Validation loss: 2.3681727033465294

Epoch: 5| Step: 7
Training loss: 2.4106027446151703
Validation loss: 2.3555872006537335

Epoch: 5| Step: 8
Training loss: 2.490437817210625
Validation loss: 2.3641016830405843

Epoch: 5| Step: 9
Training loss: 1.9269438478318832
Validation loss: 2.3226238842255515

Epoch: 5| Step: 10
Training loss: 2.1257047045692476
Validation loss: 2.3687596918026266

Epoch: 172| Step: 0
Training loss: 2.0338063513247078
Validation loss: 2.3757521696334494

Epoch: 5| Step: 1
Training loss: 2.4807114369775105
Validation loss: 2.3695783362005067

Epoch: 5| Step: 2
Training loss: 2.3708611614647825
Validation loss: 2.352433943367953

Epoch: 5| Step: 3
Training loss: 1.8808825720191418
Validation loss: 2.3653531971779818

Epoch: 5| Step: 4
Training loss: 2.459491413856032
Validation loss: 2.3848524324156486

Epoch: 5| Step: 5
Training loss: 1.367354333780151
Validation loss: 2.3874152931907204

Epoch: 5| Step: 6
Training loss: 2.747455460080646
Validation loss: 2.3613375475755616

Epoch: 5| Step: 7
Training loss: 2.4601272460158143
Validation loss: 2.372806104630231

Epoch: 5| Step: 8
Training loss: 2.697682629502411
Validation loss: 2.367962006876969

Epoch: 5| Step: 9
Training loss: 1.8859779688578904
Validation loss: 2.3732119453329403

Epoch: 5| Step: 10
Training loss: 2.4259174695675103
Validation loss: 2.358236063910115

Epoch: 173| Step: 0
Training loss: 2.222389674500385
Validation loss: 2.3673872122783637

Epoch: 5| Step: 1
Training loss: 2.5394020205690775
Validation loss: 2.370506238566662

Epoch: 5| Step: 2
Training loss: 1.8512439695230434
Validation loss: 2.393304361266344

Epoch: 5| Step: 3
Training loss: 2.9228869638997934
Validation loss: 2.3975923676656388

Epoch: 5| Step: 4
Training loss: 2.3175382630318007
Validation loss: 2.3931242165613633

Epoch: 5| Step: 5
Training loss: 2.105595232786272
Validation loss: 2.3967061507845826

Epoch: 5| Step: 6
Training loss: 1.9810433240848735
Validation loss: 2.374017216351203

Epoch: 5| Step: 7
Training loss: 2.2142871513889415
Validation loss: 2.377052593489897

Epoch: 5| Step: 8
Training loss: 2.0972977372722
Validation loss: 2.3820300709342104

Epoch: 5| Step: 9
Training loss: 2.3358022593258254
Validation loss: 2.3970660449565178

Epoch: 5| Step: 10
Training loss: 2.296728739331028
Validation loss: 2.3632843741648237

Epoch: 174| Step: 0
Training loss: 1.895810417064737
Validation loss: 2.354150526111391

Epoch: 5| Step: 1
Training loss: 2.987733878074868
Validation loss: 2.3605995089232135

Epoch: 5| Step: 2
Training loss: 1.8709401364273655
Validation loss: 2.3492999017562686

Epoch: 5| Step: 3
Training loss: 2.436530874237148
Validation loss: 2.37033830135019

Epoch: 5| Step: 4
Training loss: 2.120106954035931
Validation loss: 2.3684547627998116

Epoch: 5| Step: 5
Training loss: 2.182813911191775
Validation loss: 2.3875075019899388

Epoch: 5| Step: 6
Training loss: 2.4345208571177728
Validation loss: 2.3428698324741157

Epoch: 5| Step: 7
Training loss: 2.3980573421236784
Validation loss: 2.3469143611978813

Epoch: 5| Step: 8
Training loss: 2.6332300234299177
Validation loss: 2.3828062985704492

Epoch: 5| Step: 9
Training loss: 2.325321429604209
Validation loss: 2.3683474696621203

Epoch: 5| Step: 10
Training loss: 1.55644977313798
Validation loss: 2.3960483552623266

Epoch: 175| Step: 0
Training loss: 2.114046927632271
Validation loss: 2.3539143596902488

Epoch: 5| Step: 1
Training loss: 2.168855612873902
Validation loss: 2.3716759273864882

Epoch: 5| Step: 2
Training loss: 2.3385426975126196
Validation loss: 2.367686660865413

Epoch: 5| Step: 3
Training loss: 2.1074628286828183
Validation loss: 2.3450787404438285

Epoch: 5| Step: 4
Training loss: 1.678068010154565
Validation loss: 2.376527997430453

Epoch: 5| Step: 5
Training loss: 2.1302629260192667
Validation loss: 2.3841323561993395

Epoch: 5| Step: 6
Training loss: 2.3105038455880775
Validation loss: 2.3934496956138256

Epoch: 5| Step: 7
Training loss: 2.167305509823799
Validation loss: 2.3773384045894463

Epoch: 5| Step: 8
Training loss: 2.338990936509635
Validation loss: 2.350444607162308

Epoch: 5| Step: 9
Training loss: 2.5528193651570033
Validation loss: 2.379957183198711

Epoch: 5| Step: 10
Training loss: 2.905523393921817
Validation loss: 2.374559686557554

Epoch: 176| Step: 0
Training loss: 2.3288788055164424
Validation loss: 2.3717860834777844

Epoch: 5| Step: 1
Training loss: 2.4953724948882137
Validation loss: 2.3734175089762513

Epoch: 5| Step: 2
Training loss: 2.4582126609366326
Validation loss: 2.3770149385981467

Epoch: 5| Step: 3
Training loss: 2.8936700402040842
Validation loss: 2.395547458308956

Epoch: 5| Step: 4
Training loss: 1.7927767249772397
Validation loss: 2.3434309777156668

Epoch: 5| Step: 5
Training loss: 1.9350754734470699
Validation loss: 2.360178245086235

Epoch: 5| Step: 6
Training loss: 1.6404674636046603
Validation loss: 2.347867560781903

Epoch: 5| Step: 7
Training loss: 2.6186414636958153
Validation loss: 2.3677692887651203

Epoch: 5| Step: 8
Training loss: 1.6983876267509381
Validation loss: 2.368209921846665

Epoch: 5| Step: 9
Training loss: 2.75979741666048
Validation loss: 2.372705781744259

Epoch: 5| Step: 10
Training loss: 1.983601577100302
Validation loss: 2.360731819551338

Epoch: 177| Step: 0
Training loss: 2.2869785444073027
Validation loss: 2.3794897470384466

Epoch: 5| Step: 1
Training loss: 2.3260507239783097
Validation loss: 2.3618688042827656

Epoch: 5| Step: 2
Training loss: 2.0870679442491453
Validation loss: 2.3521454973884643

Epoch: 5| Step: 3
Training loss: 1.7507644754650509
Validation loss: 2.3548802470320984

Epoch: 5| Step: 4
Training loss: 2.623074052091852
Validation loss: 2.3991099778308795

Epoch: 5| Step: 5
Training loss: 2.376654400073796
Validation loss: 2.3810394581606507

Epoch: 5| Step: 6
Training loss: 2.7158041593146014
Validation loss: 2.389111298009796

Epoch: 5| Step: 7
Training loss: 1.9377427718128986
Validation loss: 2.366088946925809

Epoch: 5| Step: 8
Training loss: 2.287749555138974
Validation loss: 2.38550234813274

Epoch: 5| Step: 9
Training loss: 2.430265498943526
Validation loss: 2.4074567047173088

Epoch: 5| Step: 10
Training loss: 2.187384575114642
Validation loss: 2.3810774962268635

Epoch: 178| Step: 0
Training loss: 2.566959315703894
Validation loss: 2.3583235619542315

Epoch: 5| Step: 1
Training loss: 2.7658337013249747
Validation loss: 2.349052654497504

Epoch: 5| Step: 2
Training loss: 1.9774505670785447
Validation loss: 2.3678258436364854

Epoch: 5| Step: 3
Training loss: 1.9987647891377196
Validation loss: 2.3625423123985545

Epoch: 5| Step: 4
Training loss: 3.0585354425516678
Validation loss: 2.3747691337494543

Epoch: 5| Step: 5
Training loss: 2.3787248413872324
Validation loss: 2.3827412632797578

Epoch: 5| Step: 6
Training loss: 2.687887917844199
Validation loss: 2.3665732154553716

Epoch: 5| Step: 7
Training loss: 1.5700233914521884
Validation loss: 2.405949566776647

Epoch: 5| Step: 8
Training loss: 1.7968369189663806
Validation loss: 2.3766424893008926

Epoch: 5| Step: 9
Training loss: 1.8033873924125194
Validation loss: 2.386504808552746

Epoch: 5| Step: 10
Training loss: 1.596076538769897
Validation loss: 2.356085192546945

Epoch: 179| Step: 0
Training loss: 2.231677794918987
Validation loss: 2.3765833617095686

Epoch: 5| Step: 1
Training loss: 2.152768738703739
Validation loss: 2.3792661746882198

Epoch: 5| Step: 2
Training loss: 2.2930773005875156
Validation loss: 2.401031767634538

Epoch: 5| Step: 3
Training loss: 2.3272365436531683
Validation loss: 2.3687477846238356

Epoch: 5| Step: 4
Training loss: 2.032556436466017
Validation loss: 2.3799686669796247

Epoch: 5| Step: 5
Training loss: 2.341051608273273
Validation loss: 2.366336074422497

Epoch: 5| Step: 6
Training loss: 1.800711144263925
Validation loss: 2.3849594861004695

Epoch: 5| Step: 7
Training loss: 2.3798327215696924
Validation loss: 2.3470244981415282

Epoch: 5| Step: 8
Training loss: 2.4524725757119366
Validation loss: 2.3632702220990645

Epoch: 5| Step: 9
Training loss: 2.412009640998614
Validation loss: 2.3859618726780067

Epoch: 5| Step: 10
Training loss: 2.4123687234056934
Validation loss: 2.3601491052481585

Epoch: 180| Step: 0
Training loss: 2.6108720334039335
Validation loss: 2.369316557747091

Epoch: 5| Step: 1
Training loss: 1.9444629085511822
Validation loss: 2.3766722143451604

Epoch: 5| Step: 2
Training loss: 2.4484089998827376
Validation loss: 2.352724484245755

Epoch: 5| Step: 3
Training loss: 2.0528425048456413
Validation loss: 2.3596609499596473

Epoch: 5| Step: 4
Training loss: 1.6675250068402272
Validation loss: 2.3693844479269024

Epoch: 5| Step: 5
Training loss: 2.319268091112925
Validation loss: 2.37600212349287

Epoch: 5| Step: 6
Training loss: 2.383404567516496
Validation loss: 2.370727027404074

Epoch: 5| Step: 7
Training loss: 2.4842839254324103
Validation loss: 2.35759514168354

Epoch: 5| Step: 8
Training loss: 2.268069086802103
Validation loss: 2.3623656081930213

Epoch: 5| Step: 9
Training loss: 2.41169953976547
Validation loss: 2.360821868203318

Epoch: 5| Step: 10
Training loss: 2.1097990386865235
Validation loss: 2.3558854253718615

Epoch: 181| Step: 0
Training loss: 2.2453643941490227
Validation loss: 2.3654397816840653

Epoch: 5| Step: 1
Training loss: 2.45265863930143
Validation loss: 2.3739821633664095

Epoch: 5| Step: 2
Training loss: 2.063404809559087
Validation loss: 2.366875918944667

Epoch: 5| Step: 3
Training loss: 2.006283664123839
Validation loss: 2.347638312739402

Epoch: 5| Step: 4
Training loss: 2.4304619931574956
Validation loss: 2.3464556908763705

Epoch: 5| Step: 5
Training loss: 2.060559718376739
Validation loss: 2.3607742201530826

Epoch: 5| Step: 6
Training loss: 2.255297887373421
Validation loss: 2.3632157782707304

Epoch: 5| Step: 7
Training loss: 2.064457744495778
Validation loss: 2.3818989014139995

Epoch: 5| Step: 8
Training loss: 2.157214847254857
Validation loss: 2.3429986582108264

Epoch: 5| Step: 9
Training loss: 2.501804749424292
Validation loss: 2.3628844735320076

Epoch: 5| Step: 10
Training loss: 2.4477609679574726
Validation loss: 2.3593184647648715

Epoch: 182| Step: 0
Training loss: 1.7748478058591426
Validation loss: 2.3884123094841225

Epoch: 5| Step: 1
Training loss: 1.805212563760874
Validation loss: 2.3761051954874484

Epoch: 5| Step: 2
Training loss: 2.47187221444958
Validation loss: 2.370781927003622

Epoch: 5| Step: 3
Training loss: 2.476380254255346
Validation loss: 2.3512370787507755

Epoch: 5| Step: 4
Training loss: 2.339132618028341
Validation loss: 2.408048000891312

Epoch: 5| Step: 5
Training loss: 2.2241282223232357
Validation loss: 2.3526321113691337

Epoch: 5| Step: 6
Training loss: 2.0499520505554307
Validation loss: 2.377914612411437

Epoch: 5| Step: 7
Training loss: 2.412650179759299
Validation loss: 2.3636328596748446

Epoch: 5| Step: 8
Training loss: 1.9533310438192617
Validation loss: 2.3752289495988035

Epoch: 5| Step: 9
Training loss: 2.796608597838749
Validation loss: 2.3560888545222762

Epoch: 5| Step: 10
Training loss: 2.1262080180908565
Validation loss: 2.3539818674774913

Epoch: 183| Step: 0
Training loss: 2.1804115979513394
Validation loss: 2.381316593802096

Epoch: 5| Step: 1
Training loss: 2.4152244561497764
Validation loss: 2.368415818427217

Epoch: 5| Step: 2
Training loss: 1.8299133161432508
Validation loss: 2.362817171275448

Epoch: 5| Step: 3
Training loss: 2.6851950231155106
Validation loss: 2.392546888511258

Epoch: 5| Step: 4
Training loss: 2.271782131474531
Validation loss: 2.3590831042248306

Epoch: 5| Step: 5
Training loss: 2.2987444270088715
Validation loss: 2.362355733931894

Epoch: 5| Step: 6
Training loss: 2.248849998740133
Validation loss: 2.3439283077544837

Epoch: 5| Step: 7
Training loss: 1.756913629227281
Validation loss: 2.370799306367284

Epoch: 5| Step: 8
Training loss: 2.417157901516121
Validation loss: 2.3700290572299054

Epoch: 5| Step: 9
Training loss: 2.295321815217334
Validation loss: 2.336600967477641

Epoch: 5| Step: 10
Training loss: 2.1827588609291224
Validation loss: 2.3534074939152574

Epoch: 184| Step: 0
Training loss: 3.010114309225158
Validation loss: 2.3635579319359197

Epoch: 5| Step: 1
Training loss: 1.9424905799823875
Validation loss: 2.3493096535665727

Epoch: 5| Step: 2
Training loss: 1.9840787531273678
Validation loss: 2.3483167679436607

Epoch: 5| Step: 3
Training loss: 2.351517686385183
Validation loss: 2.3970620348965435

Epoch: 5| Step: 4
Training loss: 1.8210231719870613
Validation loss: 2.362321689172858

Epoch: 5| Step: 5
Training loss: 2.0849954713914025
Validation loss: 2.3726182668125206

Epoch: 5| Step: 6
Training loss: 2.041948636364545
Validation loss: 2.351972128440773

Epoch: 5| Step: 7
Training loss: 2.5871480545776526
Validation loss: 2.3450003178669285

Epoch: 5| Step: 8
Training loss: 2.537161059363379
Validation loss: 2.380096338848338

Epoch: 5| Step: 9
Training loss: 2.1634954818279923
Validation loss: 2.3506573465474743

Epoch: 5| Step: 10
Training loss: 1.6072455085790136
Validation loss: 2.34814708163018

Epoch: 185| Step: 0
Training loss: 2.6334946651372113
Validation loss: 2.37805620968551

Epoch: 5| Step: 1
Training loss: 1.8672234439981426
Validation loss: 2.3547176362829996

Epoch: 5| Step: 2
Training loss: 2.0770968998880766
Validation loss: 2.349965263983579

Epoch: 5| Step: 3
Training loss: 2.0178397379243918
Validation loss: 2.3672073186359297

Epoch: 5| Step: 4
Training loss: 2.306009618125371
Validation loss: 2.3728086371466603

Epoch: 5| Step: 5
Training loss: 2.275836216596381
Validation loss: 2.3277391233817855

Epoch: 5| Step: 6
Training loss: 2.340281857852668
Validation loss: 2.3864578865262014

Epoch: 5| Step: 7
Training loss: 2.471660781239426
Validation loss: 2.3563969634372426

Epoch: 5| Step: 8
Training loss: 2.5061796107122696
Validation loss: 2.349191586992968

Epoch: 5| Step: 9
Training loss: 2.1359152111126742
Validation loss: 2.3843930843457026

Epoch: 5| Step: 10
Training loss: 2.059066110232348
Validation loss: 2.3601839672144362

Epoch: 186| Step: 0
Training loss: 2.1058551950330084
Validation loss: 2.354430738058855

Epoch: 5| Step: 1
Training loss: 2.140248397778425
Validation loss: 2.3452333586813623

Epoch: 5| Step: 2
Training loss: 2.1300936965750976
Validation loss: 2.3766294231941814

Epoch: 5| Step: 3
Training loss: 2.1180670343584813
Validation loss: 2.3664476328248116

Epoch: 5| Step: 4
Training loss: 2.181771980504505
Validation loss: 2.340790940442181

Epoch: 5| Step: 5
Training loss: 2.1645677988806282
Validation loss: 2.380960131726343

Epoch: 5| Step: 6
Training loss: 2.710460697865149
Validation loss: 2.362531784546108

Epoch: 5| Step: 7
Training loss: 2.1563019677133246
Validation loss: 2.372991507076004

Epoch: 5| Step: 8
Training loss: 2.091233520442881
Validation loss: 2.388640579915998

Epoch: 5| Step: 9
Training loss: 2.221847091907293
Validation loss: 2.3351085977082224

Epoch: 5| Step: 10
Training loss: 2.452611978912279
Validation loss: 2.357986386004443

Epoch: 187| Step: 0
Training loss: 2.3002627554366635
Validation loss: 2.3429127379702406

Epoch: 5| Step: 1
Training loss: 2.188454773848474
Validation loss: 2.3505187826271574

Epoch: 5| Step: 2
Training loss: 2.440169804089569
Validation loss: 2.376652632122779

Epoch: 5| Step: 3
Training loss: 2.4237986154781
Validation loss: 2.363489979606458

Epoch: 5| Step: 4
Training loss: 2.230869771578821
Validation loss: 2.3621074064053547

Epoch: 5| Step: 5
Training loss: 2.3209233876625324
Validation loss: 2.3710844364737826

Epoch: 5| Step: 6
Training loss: 2.1221880539989013
Validation loss: 2.3741079078781273

Epoch: 5| Step: 7
Training loss: 2.4121732263183526
Validation loss: 2.363295385728116

Epoch: 5| Step: 8
Training loss: 2.1053723824551636
Validation loss: 2.3573611103859795

Epoch: 5| Step: 9
Training loss: 1.934488355430485
Validation loss: 2.3820144594557697

Epoch: 5| Step: 10
Training loss: 2.0486707890613185
Validation loss: 2.3788311825889554

Epoch: 188| Step: 0
Training loss: 2.091279579404877
Validation loss: 2.3532348024114147

Epoch: 5| Step: 1
Training loss: 2.1244813622752226
Validation loss: 2.3826558164297666

Epoch: 5| Step: 2
Training loss: 2.3295797628849426
Validation loss: 2.360296777638118

Epoch: 5| Step: 3
Training loss: 2.7486316571124463
Validation loss: 2.384853990044128

Epoch: 5| Step: 4
Training loss: 2.2979948466868176
Validation loss: 2.379884933531395

Epoch: 5| Step: 5
Training loss: 2.1612875874804627
Validation loss: 2.3749568181842875

Epoch: 5| Step: 6
Training loss: 2.1792090106105633
Validation loss: 2.3723199043205008

Epoch: 5| Step: 7
Training loss: 2.1615593821486683
Validation loss: 2.3582123334643574

Epoch: 5| Step: 8
Training loss: 1.7553744893047827
Validation loss: 2.365315929391589

Epoch: 5| Step: 9
Training loss: 2.123884693744408
Validation loss: 2.372242699473784

Epoch: 5| Step: 10
Training loss: 2.281061556623091
Validation loss: 2.3669273092410306

Epoch: 189| Step: 0
Training loss: 2.070397486831696
Validation loss: 2.3329091067320107

Epoch: 5| Step: 1
Training loss: 2.6118088752608055
Validation loss: 2.345665951036774

Epoch: 5| Step: 2
Training loss: 2.044982034842152
Validation loss: 2.381336974155266

Epoch: 5| Step: 3
Training loss: 2.253721127105616
Validation loss: 2.3672483340213986

Epoch: 5| Step: 4
Training loss: 2.1398432062767427
Validation loss: 2.3402354720404093

Epoch: 5| Step: 5
Training loss: 2.368398023236839
Validation loss: 2.339596714785107

Epoch: 5| Step: 6
Training loss: 2.285128497093759
Validation loss: 2.342961289792848

Epoch: 5| Step: 7
Training loss: 1.6665428910388473
Validation loss: 2.368599570845295

Epoch: 5| Step: 8
Training loss: 2.5739303218892537
Validation loss: 2.353215064374317

Epoch: 5| Step: 9
Training loss: 2.5415396945276822
Validation loss: 2.3620988171732042

Epoch: 5| Step: 10
Training loss: 1.2662901366821444
Validation loss: 2.3742927119848614

Epoch: 190| Step: 0
Training loss: 2.1036129843053444
Validation loss: 2.3679589376022547

Epoch: 5| Step: 1
Training loss: 2.4081823343460815
Validation loss: 2.374402226260156

Epoch: 5| Step: 2
Training loss: 2.4482885416433433
Validation loss: 2.3714679496331263

Epoch: 5| Step: 3
Training loss: 1.38906258238716
Validation loss: 2.3536105376150678

Epoch: 5| Step: 4
Training loss: 2.4613504699070528
Validation loss: 2.351333704605384

Epoch: 5| Step: 5
Training loss: 2.379214312270624
Validation loss: 2.371658706860376

Epoch: 5| Step: 6
Training loss: 2.111871668803672
Validation loss: 2.373697274414834

Epoch: 5| Step: 7
Training loss: 1.857041698100637
Validation loss: 2.3682939728182553

Epoch: 5| Step: 8
Training loss: 2.116441208053273
Validation loss: 2.3429615699050146

Epoch: 5| Step: 9
Training loss: 2.199786531322126
Validation loss: 2.3581282199441382

Epoch: 5| Step: 10
Training loss: 2.553295071002271
Validation loss: 2.3656492614824107

Epoch: 191| Step: 0
Training loss: 1.920549447298781
Validation loss: 2.3545698529742616

Epoch: 5| Step: 1
Training loss: 1.8675513132544845
Validation loss: 2.369181161099565

Epoch: 5| Step: 2
Training loss: 2.048394141767662
Validation loss: 2.334230610459259

Epoch: 5| Step: 3
Training loss: 1.799384711326477
Validation loss: 2.375165448905238

Epoch: 5| Step: 4
Training loss: 2.742646094771575
Validation loss: 2.3547731769485223

Epoch: 5| Step: 5
Training loss: 2.53822683814362
Validation loss: 2.3822098767299136

Epoch: 5| Step: 6
Training loss: 2.3591675319780085
Validation loss: 2.339362480694205

Epoch: 5| Step: 7
Training loss: 2.3062635302469805
Validation loss: 2.386612595898772

Epoch: 5| Step: 8
Training loss: 2.1861378379565664
Validation loss: 2.3834202059227607

Epoch: 5| Step: 9
Training loss: 1.9138643123240344
Validation loss: 2.368990490065727

Epoch: 5| Step: 10
Training loss: 2.4547243189584815
Validation loss: 2.3570625584663536

Epoch: 192| Step: 0
Training loss: 2.394976277403125
Validation loss: 2.370253173142782

Epoch: 5| Step: 1
Training loss: 1.836007948802122
Validation loss: 2.3423297125396307

Epoch: 5| Step: 2
Training loss: 2.0421890317156652
Validation loss: 2.3366408524361404

Epoch: 5| Step: 3
Training loss: 1.8486842709012763
Validation loss: 2.371207009022748

Epoch: 5| Step: 4
Training loss: 2.916773948512917
Validation loss: 2.3800040206485717

Epoch: 5| Step: 5
Training loss: 2.0231522171221425
Validation loss: 2.3351875286805384

Epoch: 5| Step: 6
Training loss: 2.061566459463451
Validation loss: 2.3792257759319146

Epoch: 5| Step: 7
Training loss: 2.1971680750915294
Validation loss: 2.3373465180931605

Epoch: 5| Step: 8
Training loss: 2.1745778562037392
Validation loss: 2.364398641358678

Epoch: 5| Step: 9
Training loss: 2.494563772561198
Validation loss: 2.341334391426818

Epoch: 5| Step: 10
Training loss: 2.2457629681700833
Validation loss: 2.313846387974567

Epoch: 193| Step: 0
Training loss: 2.1299336325465013
Validation loss: 2.346906603349454

Epoch: 5| Step: 1
Training loss: 2.0505396528077227
Validation loss: 2.3531303495145757

Epoch: 5| Step: 2
Training loss: 2.1682013309575665
Validation loss: 2.3652077243002885

Epoch: 5| Step: 3
Training loss: 2.2817313326618196
Validation loss: 2.356871579254276

Epoch: 5| Step: 4
Training loss: 2.535659716535143
Validation loss: 2.360601781946336

Epoch: 5| Step: 5
Training loss: 2.3243017358149842
Validation loss: 2.362446760814904

Epoch: 5| Step: 6
Training loss: 1.936400070531474
Validation loss: 2.3599422875444755

Epoch: 5| Step: 7
Training loss: 1.9890627421268816
Validation loss: 2.352562098263756

Epoch: 5| Step: 8
Training loss: 1.901418786115321
Validation loss: 2.3535614952791746

Epoch: 5| Step: 9
Training loss: 2.588816719613705
Validation loss: 2.3636726507498182

Epoch: 5| Step: 10
Training loss: 2.3292803873632995
Validation loss: 2.3615480773447417

Epoch: 194| Step: 0
Training loss: 2.0747574216307942
Validation loss: 2.3370176078903264

Epoch: 5| Step: 1
Training loss: 2.2376935097326793
Validation loss: 2.332933616534045

Epoch: 5| Step: 2
Training loss: 2.3901350728575794
Validation loss: 2.3509754547473194

Epoch: 5| Step: 3
Training loss: 1.9537417239198738
Validation loss: 2.367812511795413

Epoch: 5| Step: 4
Training loss: 2.582673562819386
Validation loss: 2.346936682073539

Epoch: 5| Step: 5
Training loss: 1.8159759996357474
Validation loss: 2.337626550422857

Epoch: 5| Step: 6
Training loss: 2.434106763524676
Validation loss: 2.336316995814897

Epoch: 5| Step: 7
Training loss: 2.0270752480931447
Validation loss: 2.370576029376195

Epoch: 5| Step: 8
Training loss: 2.3856657361816764
Validation loss: 2.3643080555782614

Epoch: 5| Step: 9
Training loss: 1.8747154655729814
Validation loss: 2.35597359777015

Epoch: 5| Step: 10
Training loss: 2.1373685026712024
Validation loss: 2.3479607420988646

Epoch: 195| Step: 0
Training loss: 2.2879271311727023
Validation loss: 2.332091968861924

Epoch: 5| Step: 1
Training loss: 2.105598969404786
Validation loss: 2.364358880934651

Epoch: 5| Step: 2
Training loss: 2.2179113603015206
Validation loss: 2.3347204065811664

Epoch: 5| Step: 3
Training loss: 2.337449416974944
Validation loss: 2.368117494267983

Epoch: 5| Step: 4
Training loss: 2.9054705487230583
Validation loss: 2.3386808282220626

Epoch: 5| Step: 5
Training loss: 2.39860539050642
Validation loss: 2.337492502027323

Epoch: 5| Step: 6
Training loss: 2.2428279586712097
Validation loss: 2.3762062233899273

Epoch: 5| Step: 7
Training loss: 1.7978384337601165
Validation loss: 2.338868713275649

Epoch: 5| Step: 8
Training loss: 1.8372495467584715
Validation loss: 2.335774000745951

Epoch: 5| Step: 9
Training loss: 1.78997945816358
Validation loss: 2.3559965607798934

Epoch: 5| Step: 10
Training loss: 1.7939443157361479
Validation loss: 2.3719722746608474

Epoch: 196| Step: 0
Training loss: 2.3334402559396183
Validation loss: 2.3488474977694

Epoch: 5| Step: 1
Training loss: 1.7316024889663075
Validation loss: 2.3290411542341856

Epoch: 5| Step: 2
Training loss: 2.5977019571284248
Validation loss: 2.3538258155428373

Epoch: 5| Step: 3
Training loss: 2.0942504057085207
Validation loss: 2.3350934761765476

Epoch: 5| Step: 4
Training loss: 2.060689651821809
Validation loss: 2.352748242802507

Epoch: 5| Step: 5
Training loss: 2.14744361776781
Validation loss: 2.3647877323532827

Epoch: 5| Step: 6
Training loss: 2.00197694345587
Validation loss: 2.3122916932920528

Epoch: 5| Step: 7
Training loss: 2.0864638903793504
Validation loss: 2.347130651419749

Epoch: 5| Step: 8
Training loss: 1.7512584657212584
Validation loss: 2.3804630827061137

Epoch: 5| Step: 9
Training loss: 2.5066791956500505
Validation loss: 2.360911026265717

Epoch: 5| Step: 10
Training loss: 2.6871613577467093
Validation loss: 2.3271629039704855

Epoch: 197| Step: 0
Training loss: 2.4358377902390065
Validation loss: 2.3515970989801693

Epoch: 5| Step: 1
Training loss: 1.566960339042466
Validation loss: 2.3829661238605846

Epoch: 5| Step: 2
Training loss: 1.8854436573885647
Validation loss: 2.3308374856946497

Epoch: 5| Step: 3
Training loss: 2.45402986396706
Validation loss: 2.3662399246811456

Epoch: 5| Step: 4
Training loss: 1.8789125311542296
Validation loss: 2.3607673787705954

Epoch: 5| Step: 5
Training loss: 2.176481781371283
Validation loss: 2.351404114071871

Epoch: 5| Step: 6
Training loss: 2.0835704159940844
Validation loss: 2.3566872158977246

Epoch: 5| Step: 7
Training loss: 1.9826329311527038
Validation loss: 2.3404981415831148

Epoch: 5| Step: 8
Training loss: 2.5743526719123633
Validation loss: 2.3230002445382576

Epoch: 5| Step: 9
Training loss: 2.323508992535022
Validation loss: 2.358338344845052

Epoch: 5| Step: 10
Training loss: 2.3008520248226776
Validation loss: 2.3409603386286295

Epoch: 198| Step: 0
Training loss: 1.8725456068242612
Validation loss: 2.3377217440572418

Epoch: 5| Step: 1
Training loss: 1.9329202731406474
Validation loss: 2.3662493157799522

Epoch: 5| Step: 2
Training loss: 2.122933336466391
Validation loss: 2.3653624617382434

Epoch: 5| Step: 3
Training loss: 2.508365843383726
Validation loss: 2.365207945415187

Epoch: 5| Step: 4
Training loss: 2.062254226375027
Validation loss: 2.3565678599457467

Epoch: 5| Step: 5
Training loss: 2.7631311757127195
Validation loss: 2.35970590660435

Epoch: 5| Step: 6
Training loss: 1.974977060981519
Validation loss: 2.3556664956492415

Epoch: 5| Step: 7
Training loss: 1.9059396710049608
Validation loss: 2.377559325613889

Epoch: 5| Step: 8
Training loss: 2.197000200982621
Validation loss: 2.331966616984213

Epoch: 5| Step: 9
Training loss: 2.273531777436039
Validation loss: 2.359320355451943

Epoch: 5| Step: 10
Training loss: 2.065452196796672
Validation loss: 2.342231327374079

Epoch: 199| Step: 0
Training loss: 2.4015659468755763
Validation loss: 2.3797425886337256

Epoch: 5| Step: 1
Training loss: 1.501228306444449
Validation loss: 2.3596450291483926

Epoch: 5| Step: 2
Training loss: 2.2789611830709386
Validation loss: 2.336931423868413

Epoch: 5| Step: 3
Training loss: 2.4609397282666
Validation loss: 2.347522452162743

Epoch: 5| Step: 4
Training loss: 1.7591893208230327
Validation loss: 2.345252570330156

Epoch: 5| Step: 5
Training loss: 2.1920640471561765
Validation loss: 2.353767651599067

Epoch: 5| Step: 6
Training loss: 1.9832103044621499
Validation loss: 2.3675594865369463

Epoch: 5| Step: 7
Training loss: 2.1125072817705144
Validation loss: 2.3599830261768577

Epoch: 5| Step: 8
Training loss: 2.1139510639196386
Validation loss: 2.3522272167686618

Epoch: 5| Step: 9
Training loss: 2.6758705291332916
Validation loss: 2.353727109272321

Epoch: 5| Step: 10
Training loss: 2.0714902586748187
Validation loss: 2.3506604880355044

Epoch: 200| Step: 0
Training loss: 2.5544058268240764
Validation loss: 2.3448947159206415

Epoch: 5| Step: 1
Training loss: 2.2731627203198097
Validation loss: 2.34144880308749

Epoch: 5| Step: 2
Training loss: 2.0805606192897987
Validation loss: 2.359747797647449

Epoch: 5| Step: 3
Training loss: 1.4121568600596872
Validation loss: 2.33704508356245

Epoch: 5| Step: 4
Training loss: 1.7819477521641511
Validation loss: 2.3462589237255997

Epoch: 5| Step: 5
Training loss: 1.8225089643595442
Validation loss: 2.3521709783928677

Epoch: 5| Step: 6
Training loss: 2.7964761971808247
Validation loss: 2.369910477602524

Epoch: 5| Step: 7
Training loss: 2.2784952749739493
Validation loss: 2.3598980306576114

Epoch: 5| Step: 8
Training loss: 2.3544592773972792
Validation loss: 2.3807385288704785

Epoch: 5| Step: 9
Training loss: 2.147857920758753
Validation loss: 2.3510142142219177

Epoch: 5| Step: 10
Training loss: 1.8992946243978903
Validation loss: 2.339783758225394

Epoch: 201| Step: 0
Training loss: 2.47160415805307
Validation loss: 2.372591638004561

Epoch: 5| Step: 1
Training loss: 2.6308813965009588
Validation loss: 2.3587991714945296

Epoch: 5| Step: 2
Training loss: 1.7189054938984707
Validation loss: 2.3660136743914446

Epoch: 5| Step: 3
Training loss: 1.742856568642372
Validation loss: 2.345785646939843

Epoch: 5| Step: 4
Training loss: 2.4028909199658637
Validation loss: 2.3547011431258578

Epoch: 5| Step: 5
Training loss: 2.015399535824464
Validation loss: 2.348250704313006

Epoch: 5| Step: 6
Training loss: 2.224755340154814
Validation loss: 2.3527563540435006

Epoch: 5| Step: 7
Training loss: 2.637119743090593
Validation loss: 2.3650032914807446

Epoch: 5| Step: 8
Training loss: 1.5283438683787711
Validation loss: 2.3575343967593496

Epoch: 5| Step: 9
Training loss: 2.1087516711397454
Validation loss: 2.3235883241592217

Epoch: 5| Step: 10
Training loss: 1.7093853463761164
Validation loss: 2.3573220653913083

Epoch: 202| Step: 0
Training loss: 2.1382450879808923
Validation loss: 2.382244803269219

Epoch: 5| Step: 1
Training loss: 1.7215400937807486
Validation loss: 2.3465884805302495

Epoch: 5| Step: 2
Training loss: 1.6574542867533337
Validation loss: 2.3625167739740593

Epoch: 5| Step: 3
Training loss: 2.265953408478593
Validation loss: 2.3555259022181576

Epoch: 5| Step: 4
Training loss: 1.3369453599274423
Validation loss: 2.355633538286889

Epoch: 5| Step: 5
Training loss: 2.749774750241006
Validation loss: 2.32718555529503

Epoch: 5| Step: 6
Training loss: 2.1801056272832424
Validation loss: 2.3344457131183383

Epoch: 5| Step: 7
Training loss: 2.5819051137519473
Validation loss: 2.3557113805203556

Epoch: 5| Step: 8
Training loss: 2.179412277511121
Validation loss: 2.33614492515753

Epoch: 5| Step: 9
Training loss: 2.297772083131943
Validation loss: 2.327977677054443

Epoch: 5| Step: 10
Training loss: 2.2241980060967386
Validation loss: 2.3303995593829967

Epoch: 203| Step: 0
Training loss: 2.2503632146341
Validation loss: 2.3324819987940395

Epoch: 5| Step: 1
Training loss: 2.312980808071234
Validation loss: 2.348695981597741

Epoch: 5| Step: 2
Training loss: 2.3842473947119402
Validation loss: 2.3707700840491737

Epoch: 5| Step: 3
Training loss: 2.041272365356439
Validation loss: 2.3422752821607244

Epoch: 5| Step: 4
Training loss: 1.7388022338568514
Validation loss: 2.333173042789162

Epoch: 5| Step: 5
Training loss: 1.7291310394783914
Validation loss: 2.3418648388253653

Epoch: 5| Step: 6
Training loss: 2.475257216680078
Validation loss: 2.3784527682744407

Epoch: 5| Step: 7
Training loss: 2.3758000481917745
Validation loss: 2.3731179090386467

Epoch: 5| Step: 8
Training loss: 1.9516679135173896
Validation loss: 2.3205701985217497

Epoch: 5| Step: 9
Training loss: 1.7730735371718214
Validation loss: 2.369032581074082

Epoch: 5| Step: 10
Training loss: 2.7249601623702917
Validation loss: 2.3650598404108303

Epoch: 204| Step: 0
Training loss: 2.9545675316899436
Validation loss: 2.3469777251028243

Epoch: 5| Step: 1
Training loss: 1.8374616424293846
Validation loss: 2.3721570225165918

Epoch: 5| Step: 2
Training loss: 1.991210698029044
Validation loss: 2.357629910929294

Epoch: 5| Step: 3
Training loss: 2.191464782041951
Validation loss: 2.370086103879145

Epoch: 5| Step: 4
Training loss: 2.0824697866457704
Validation loss: 2.3520517202501203

Epoch: 5| Step: 5
Training loss: 1.8253456572225066
Validation loss: 2.370910047076523

Epoch: 5| Step: 6
Training loss: 2.22343122919717
Validation loss: 2.334558868997163

Epoch: 5| Step: 7
Training loss: 2.073356722283784
Validation loss: 2.3433042128274106

Epoch: 5| Step: 8
Training loss: 1.9855740146256857
Validation loss: 2.3605743230723664

Epoch: 5| Step: 9
Training loss: 2.373889864416398
Validation loss: 2.345701931542799

Epoch: 5| Step: 10
Training loss: 2.0127015907304435
Validation loss: 2.3175476551298977

Epoch: 205| Step: 0
Training loss: 2.174668854684078
Validation loss: 2.3583955590531533

Epoch: 5| Step: 1
Training loss: 1.8750411982778559
Validation loss: 2.3568824880762325

Epoch: 5| Step: 2
Training loss: 2.2607510461489504
Validation loss: 2.3631600585063657

Epoch: 5| Step: 3
Training loss: 2.1227344328655775
Validation loss: 2.352764497400589

Epoch: 5| Step: 4
Training loss: 1.841718038932784
Validation loss: 2.335214016990226

Epoch: 5| Step: 5
Training loss: 1.9227316583123888
Validation loss: 2.3586069916267913

Epoch: 5| Step: 6
Training loss: 1.7157590330815193
Validation loss: 2.331511481365135

Epoch: 5| Step: 7
Training loss: 2.6274274773574993
Validation loss: 2.3519990877067825

Epoch: 5| Step: 8
Training loss: 2.2412358301313695
Validation loss: 2.3415066610051154

Epoch: 5| Step: 9
Training loss: 2.3772502077210684
Validation loss: 2.3732038440523957

Epoch: 5| Step: 10
Training loss: 2.125266563301623
Validation loss: 2.3620191948936586

Epoch: 206| Step: 0
Training loss: 2.0719031790863927
Validation loss: 2.3376443040451473

Epoch: 5| Step: 1
Training loss: 1.4616621535582048
Validation loss: 2.3609454556703127

Epoch: 5| Step: 2
Training loss: 2.008600814967155
Validation loss: 2.352106939119755

Epoch: 5| Step: 3
Training loss: 2.4092041311272636
Validation loss: 2.325360539511241

Epoch: 5| Step: 4
Training loss: 2.2432630132656737
Validation loss: 2.3685263047329665

Epoch: 5| Step: 5
Training loss: 1.612434072403551
Validation loss: 2.3295057592731374

Epoch: 5| Step: 6
Training loss: 2.41548435843032
Validation loss: 2.3462971071740477

Epoch: 5| Step: 7
Training loss: 2.515304450231812
Validation loss: 2.34499884582312

Epoch: 5| Step: 8
Training loss: 2.3065758162267715
Validation loss: 2.3413136456189645

Epoch: 5| Step: 9
Training loss: 2.1085744963618818
Validation loss: 2.3525343635644385

Epoch: 5| Step: 10
Training loss: 2.1552181262725973
Validation loss: 2.327345488611377

Epoch: 207| Step: 0
Training loss: 2.0435993104029695
Validation loss: 2.341446403076375

Epoch: 5| Step: 1
Training loss: 2.577453433336728
Validation loss: 2.3284500466662124

Epoch: 5| Step: 2
Training loss: 2.2401061283242822
Validation loss: 2.3213691823052396

Epoch: 5| Step: 3
Training loss: 1.6903823678430778
Validation loss: 2.3595648082565934

Epoch: 5| Step: 4
Training loss: 2.186211015496575
Validation loss: 2.3388837840930714

Epoch: 5| Step: 5
Training loss: 2.3376793124530777
Validation loss: 2.350128375914732

Epoch: 5| Step: 6
Training loss: 1.9568302866074274
Validation loss: 2.3477834885764746

Epoch: 5| Step: 7
Training loss: 1.7615267697632788
Validation loss: 2.3305571744183777

Epoch: 5| Step: 8
Training loss: 2.3399264873466694
Validation loss: 2.3471763696002688

Epoch: 5| Step: 9
Training loss: 2.060465184621806
Validation loss: 2.3543730638132274

Epoch: 5| Step: 10
Training loss: 2.3300149913845845
Validation loss: 2.371754201322413

Epoch: 208| Step: 0
Training loss: 2.0337619215153384
Validation loss: 2.3725898637845773

Epoch: 5| Step: 1
Training loss: 2.174309881934266
Validation loss: 2.3455109869640705

Epoch: 5| Step: 2
Training loss: 2.3498698381129532
Validation loss: 2.3396833879355987

Epoch: 5| Step: 3
Training loss: 2.0577715221545216
Validation loss: 2.329203029362445

Epoch: 5| Step: 4
Training loss: 1.9251125946804424
Validation loss: 2.324545924383468

Epoch: 5| Step: 5
Training loss: 1.9975496421059509
Validation loss: 2.3089989919567233

Epoch: 5| Step: 6
Training loss: 1.9056139025391625
Validation loss: 2.313479683001533

Epoch: 5| Step: 7
Training loss: 2.134270361908764
Validation loss: 2.334016605579771

Epoch: 5| Step: 8
Training loss: 2.4180801686390243
Validation loss: 2.342806975723617

Epoch: 5| Step: 9
Training loss: 2.078464222232802
Validation loss: 2.3535050622152176

Epoch: 5| Step: 10
Training loss: 2.2268770765305055
Validation loss: 2.334757951916007

Epoch: 209| Step: 0
Training loss: 2.0251168017198196
Validation loss: 2.3539529754793276

Epoch: 5| Step: 1
Training loss: 1.9767269020916574
Validation loss: 2.364944301076723

Epoch: 5| Step: 2
Training loss: 2.1046695926530323
Validation loss: 2.3366383224116825

Epoch: 5| Step: 3
Training loss: 1.91540150419879
Validation loss: 2.35665309523303

Epoch: 5| Step: 4
Training loss: 1.7139863323303255
Validation loss: 2.3385910561379277

Epoch: 5| Step: 5
Training loss: 2.0248129157782917
Validation loss: 2.3722599389951227

Epoch: 5| Step: 6
Training loss: 2.382970085561382
Validation loss: 2.349274036592514

Epoch: 5| Step: 7
Training loss: 2.280924525623186
Validation loss: 2.3469632322132625

Epoch: 5| Step: 8
Training loss: 2.2457681701869525
Validation loss: 2.3304917524921525

Epoch: 5| Step: 9
Training loss: 2.2090333752716287
Validation loss: 2.365275721576723

Epoch: 5| Step: 10
Training loss: 2.4953262510261176
Validation loss: 2.3341304143490387

Epoch: 210| Step: 0
Training loss: 2.137922599911627
Validation loss: 2.339167086319422

Epoch: 5| Step: 1
Training loss: 2.040226279032137
Validation loss: 2.3540407459828416

Epoch: 5| Step: 2
Training loss: 2.2593888320604973
Validation loss: 2.352212882649861

Epoch: 5| Step: 3
Training loss: 1.5935703999169843
Validation loss: 2.369349006130705

Epoch: 5| Step: 4
Training loss: 1.6748540843207413
Validation loss: 2.338118012267384

Epoch: 5| Step: 5
Training loss: 2.5084307612595573
Validation loss: 2.3511697418483055

Epoch: 5| Step: 6
Training loss: 1.8627138693478043
Validation loss: 2.3418804366136508

Epoch: 5| Step: 7
Training loss: 1.585346055265051
Validation loss: 2.3506877257222105

Epoch: 5| Step: 8
Training loss: 2.6153389394879776
Validation loss: 2.3371488403360794

Epoch: 5| Step: 9
Training loss: 2.601219819098672
Validation loss: 2.3478061435094024

Epoch: 5| Step: 10
Training loss: 2.0026126724148514
Validation loss: 2.355994062422248

Epoch: 211| Step: 0
Training loss: 1.6507054497014888
Validation loss: 2.3324312910730725

Epoch: 5| Step: 1
Training loss: 2.223846385082792
Validation loss: 2.3628616458143905

Epoch: 5| Step: 2
Training loss: 2.186595075625516
Validation loss: 2.340726482493046

Epoch: 5| Step: 3
Training loss: 1.7475873119278702
Validation loss: 2.367480863840839

Epoch: 5| Step: 4
Training loss: 2.4740612985700317
Validation loss: 2.337128381788492

Epoch: 5| Step: 5
Training loss: 1.9188637441911716
Validation loss: 2.3262723444683098

Epoch: 5| Step: 6
Training loss: 1.7347921608654295
Validation loss: 2.315761369388549

Epoch: 5| Step: 7
Training loss: 2.3997181011583124
Validation loss: 2.3728897832036386

Epoch: 5| Step: 8
Training loss: 2.142829706379677
Validation loss: 2.372198560757028

Epoch: 5| Step: 9
Training loss: 2.3653126962737008
Validation loss: 2.344680024074297

Epoch: 5| Step: 10
Training loss: 2.2971938554190414
Validation loss: 2.321058108012005

Epoch: 212| Step: 0
Training loss: 2.201943912862416
Validation loss: 2.3818465705368554

Epoch: 5| Step: 1
Training loss: 1.855552012934447
Validation loss: 2.349737989437145

Epoch: 5| Step: 2
Training loss: 1.533549159174673
Validation loss: 2.348966092409118

Epoch: 5| Step: 3
Training loss: 1.8560143240877405
Validation loss: 2.34548379736895

Epoch: 5| Step: 4
Training loss: 2.208785772460301
Validation loss: 2.3467652666351837

Epoch: 5| Step: 5
Training loss: 2.238939012208824
Validation loss: 2.3190241930461095

Epoch: 5| Step: 6
Training loss: 2.0883495087033945
Validation loss: 2.3749017144609064

Epoch: 5| Step: 7
Training loss: 2.143810825207897
Validation loss: 2.3340437755353425

Epoch: 5| Step: 8
Training loss: 1.9576018029021085
Validation loss: 2.361428347184506

Epoch: 5| Step: 9
Training loss: 2.3613101526275315
Validation loss: 2.3801069139529805

Epoch: 5| Step: 10
Training loss: 2.7025227840567685
Validation loss: 2.3592948158360554

Epoch: 213| Step: 0
Training loss: 2.5119888848587304
Validation loss: 2.3394810476965664

Epoch: 5| Step: 1
Training loss: 1.6870982786901385
Validation loss: 2.345851619343701

Epoch: 5| Step: 2
Training loss: 2.123998518172787
Validation loss: 2.3604198669279253

Epoch: 5| Step: 3
Training loss: 2.058075870468515
Validation loss: 2.3875897827086527

Epoch: 5| Step: 4
Training loss: 2.570971187149675
Validation loss: 2.3731854922460642

Epoch: 5| Step: 5
Training loss: 1.5638245118560574
Validation loss: 2.3500526068879255

Epoch: 5| Step: 6
Training loss: 1.9961818369560518
Validation loss: 2.3505416309647447

Epoch: 5| Step: 7
Training loss: 2.2195195757334987
Validation loss: 2.3671028817633473

Epoch: 5| Step: 8
Training loss: 2.2624003646577813
Validation loss: 2.3411856916003275

Epoch: 5| Step: 9
Training loss: 2.1493867753691602
Validation loss: 2.371358456604183

Epoch: 5| Step: 10
Training loss: 1.3802857671165123
Validation loss: 2.3526334527776385

Epoch: 214| Step: 0
Training loss: 2.3775791418980714
Validation loss: 2.3379997325072384

Epoch: 5| Step: 1
Training loss: 2.0439096184323593
Validation loss: 2.35275434094593

Epoch: 5| Step: 2
Training loss: 2.129778482084807
Validation loss: 2.3617970889072004

Epoch: 5| Step: 3
Training loss: 1.7105526425965007
Validation loss: 2.3257751851220796

Epoch: 5| Step: 4
Training loss: 2.3209327356863065
Validation loss: 2.3384330003110585

Epoch: 5| Step: 5
Training loss: 2.5655142570877114
Validation loss: 2.3153028090226604

Epoch: 5| Step: 6
Training loss: 1.94424212932134
Validation loss: 2.3098516778517233

Epoch: 5| Step: 7
Training loss: 1.6663041038343145
Validation loss: 2.3406438873329405

Epoch: 5| Step: 8
Training loss: 2.142473745107305
Validation loss: 2.361378520251151

Epoch: 5| Step: 9
Training loss: 2.2018485192799866
Validation loss: 2.306031025336579

Epoch: 5| Step: 10
Training loss: 1.6717603412420707
Validation loss: 2.3271223376975305

Epoch: 215| Step: 0
Training loss: 1.9903330829913872
Validation loss: 2.3513026790478153

Epoch: 5| Step: 1
Training loss: 2.2411810447012472
Validation loss: 2.339182829775294

Epoch: 5| Step: 2
Training loss: 2.195553369306505
Validation loss: 2.3504392147128104

Epoch: 5| Step: 3
Training loss: 2.0271326443933284
Validation loss: 2.332675645212428

Epoch: 5| Step: 4
Training loss: 2.374719502800274
Validation loss: 2.3448353721506328

Epoch: 5| Step: 5
Training loss: 2.16525676288348
Validation loss: 2.30497443636116

Epoch: 5| Step: 6
Training loss: 2.374221473383495
Validation loss: 2.3404939606675774

Epoch: 5| Step: 7
Training loss: 1.481097648930179
Validation loss: 2.3568830107281658

Epoch: 5| Step: 8
Training loss: 1.5813931155368388
Validation loss: 2.329454268117451

Epoch: 5| Step: 9
Training loss: 2.0283391195866165
Validation loss: 2.358847558264998

Epoch: 5| Step: 10
Training loss: 2.4337725382321134
Validation loss: 2.3479270591177914

Epoch: 216| Step: 0
Training loss: 1.9287501232174373
Validation loss: 2.341843841280732

Epoch: 5| Step: 1
Training loss: 2.1879823425389446
Validation loss: 2.3340075664318007

Epoch: 5| Step: 2
Training loss: 2.2808430975065153
Validation loss: 2.3384609636483478

Epoch: 5| Step: 3
Training loss: 1.7079186129956379
Validation loss: 2.338104049970719

Epoch: 5| Step: 4
Training loss: 2.2530587915435887
Validation loss: 2.3533817310870826

Epoch: 5| Step: 5
Training loss: 2.154225490905658
Validation loss: 2.362393852540855

Epoch: 5| Step: 6
Training loss: 1.2758000462975907
Validation loss: 2.323856908604143

Epoch: 5| Step: 7
Training loss: 2.0785864984437024
Validation loss: 2.3516656751248255

Epoch: 5| Step: 8
Training loss: 1.9506516321497658
Validation loss: 2.3565810231419277

Epoch: 5| Step: 9
Training loss: 2.577818696292862
Validation loss: 2.343486807754008

Epoch: 5| Step: 10
Training loss: 2.295046539167204
Validation loss: 2.302109739654846

Epoch: 217| Step: 0
Training loss: 1.515643090208969
Validation loss: 2.362392596978409

Epoch: 5| Step: 1
Training loss: 2.1160081344621204
Validation loss: 2.3737207474544166

Epoch: 5| Step: 2
Training loss: 1.7699500929267513
Validation loss: 2.338628446153407

Epoch: 5| Step: 3
Training loss: 2.2481925910501164
Validation loss: 2.349992668456347

Epoch: 5| Step: 4
Training loss: 2.2784638831746165
Validation loss: 2.3138780476086613

Epoch: 5| Step: 5
Training loss: 2.108356371164417
Validation loss: 2.3427589908243287

Epoch: 5| Step: 6
Training loss: 1.9301230367666966
Validation loss: 2.3134033447517703

Epoch: 5| Step: 7
Training loss: 2.1841629733108134
Validation loss: 2.335558402440369

Epoch: 5| Step: 8
Training loss: 2.8178461761509856
Validation loss: 2.3445634290379083

Epoch: 5| Step: 9
Training loss: 1.7519121622423444
Validation loss: 2.3532485921395168

Epoch: 5| Step: 10
Training loss: 2.0265717846636413
Validation loss: 2.350074605601883

Epoch: 218| Step: 0
Training loss: 2.0844314224407574
Validation loss: 2.354247594283251

Epoch: 5| Step: 1
Training loss: 2.380787774027176
Validation loss: 2.3507962207384763

Epoch: 5| Step: 2
Training loss: 1.498016078587661
Validation loss: 2.324766667178322

Epoch: 5| Step: 3
Training loss: 2.395049146494396
Validation loss: 2.3297165081019893

Epoch: 5| Step: 4
Training loss: 1.9463093972376002
Validation loss: 2.3309563279569465

Epoch: 5| Step: 5
Training loss: 2.405682880897564
Validation loss: 2.3302834412807014

Epoch: 5| Step: 6
Training loss: 2.1066913629042
Validation loss: 2.3371992296189275

Epoch: 5| Step: 7
Training loss: 1.4053207294069618
Validation loss: 2.3352629605097004

Epoch: 5| Step: 8
Training loss: 2.1748114843994597
Validation loss: 2.3329330198359504

Epoch: 5| Step: 9
Training loss: 2.2165738031348408
Validation loss: 2.346462880994317

Epoch: 5| Step: 10
Training loss: 2.191678552148112
Validation loss: 2.3229567063876555

Epoch: 219| Step: 0
Training loss: 1.7877932381354948
Validation loss: 2.3325216354500795

Epoch: 5| Step: 1
Training loss: 1.9331224888348357
Validation loss: 2.342230248168016

Epoch: 5| Step: 2
Training loss: 1.8091642003311268
Validation loss: 2.3667584118384024

Epoch: 5| Step: 3
Training loss: 1.8113841864437366
Validation loss: 2.3225475109735183

Epoch: 5| Step: 4
Training loss: 1.8330540516568998
Validation loss: 2.346060551224317

Epoch: 5| Step: 5
Training loss: 2.0958141571239497
Validation loss: 2.3299733541256233

Epoch: 5| Step: 6
Training loss: 2.2106836395639786
Validation loss: 2.3773902184272746

Epoch: 5| Step: 7
Training loss: 2.518798532326028
Validation loss: 2.35085164576194

Epoch: 5| Step: 8
Training loss: 2.627270125651504
Validation loss: 2.3100721534714963

Epoch: 5| Step: 9
Training loss: 1.6808393210797883
Validation loss: 2.3390806274864637

Epoch: 5| Step: 10
Training loss: 2.4038652765540474
Validation loss: 2.3453247522532252

Epoch: 220| Step: 0
Training loss: 1.6288232576373538
Validation loss: 2.338907613641889

Epoch: 5| Step: 1
Training loss: 2.0415999602754282
Validation loss: 2.342949920055501

Epoch: 5| Step: 2
Training loss: 2.1840562143042956
Validation loss: 2.3495661804420265

Epoch: 5| Step: 3
Training loss: 2.04313516030246
Validation loss: 2.3207711055601554

Epoch: 5| Step: 4
Training loss: 1.986725743949361
Validation loss: 2.3674189133853543

Epoch: 5| Step: 5
Training loss: 2.313465329324512
Validation loss: 2.3450595557943914

Epoch: 5| Step: 6
Training loss: 2.4022038116635724
Validation loss: 2.372085998610551

Epoch: 5| Step: 7
Training loss: 1.7280734256270827
Validation loss: 2.3437060258356515

Epoch: 5| Step: 8
Training loss: 2.2857652684043592
Validation loss: 2.3369279606005566

Epoch: 5| Step: 9
Training loss: 1.6207258059702194
Validation loss: 2.3742079620380245

Epoch: 5| Step: 10
Training loss: 2.3165869811187463
Validation loss: 2.360940797354658

Epoch: 221| Step: 0
Training loss: 2.397139605025169
Validation loss: 2.3586801984852097

Epoch: 5| Step: 1
Training loss: 2.6673710210734654
Validation loss: 2.3523891256480987

Epoch: 5| Step: 2
Training loss: 2.155590232862953
Validation loss: 2.328374807011739

Epoch: 5| Step: 3
Training loss: 1.5310885285857716
Validation loss: 2.3421637764344356

Epoch: 5| Step: 4
Training loss: 2.093676437679853
Validation loss: 2.3114970991624006

Epoch: 5| Step: 5
Training loss: 1.4232642125864563
Validation loss: 2.3277690070477806

Epoch: 5| Step: 6
Training loss: 1.8603789880688415
Validation loss: 2.338029349061095

Epoch: 5| Step: 7
Training loss: 1.756738631398841
Validation loss: 2.3619921144692118

Epoch: 5| Step: 8
Training loss: 2.141673256038914
Validation loss: 2.357386776438159

Epoch: 5| Step: 9
Training loss: 1.8899585400428907
Validation loss: 2.356692095832536

Epoch: 5| Step: 10
Training loss: 2.466771552287385
Validation loss: 2.3234809187609984

Epoch: 222| Step: 0
Training loss: 1.6190917372369198
Validation loss: 2.342370190558383

Epoch: 5| Step: 1
Training loss: 1.9481978867926932
Validation loss: 2.386774611503697

Epoch: 5| Step: 2
Training loss: 2.2990050527310526
Validation loss: 2.342181085754822

Epoch: 5| Step: 3
Training loss: 1.8965648315837744
Validation loss: 2.3179397325542914

Epoch: 5| Step: 4
Training loss: 1.951159777904504
Validation loss: 2.3537703527259706

Epoch: 5| Step: 5
Training loss: 2.179697125594786
Validation loss: 2.327469524732423

Epoch: 5| Step: 6
Training loss: 2.200417010926033
Validation loss: 2.311674612621783

Epoch: 5| Step: 7
Training loss: 2.1710214378391406
Validation loss: 2.313917978570018

Epoch: 5| Step: 8
Training loss: 2.0450644602794306
Validation loss: 2.35422971704374

Epoch: 5| Step: 9
Training loss: 2.350433382694948
Validation loss: 2.318487266030942

Epoch: 5| Step: 10
Training loss: 1.9728336065653702
Validation loss: 2.328669192969272

Epoch: 223| Step: 0
Training loss: 2.2404476420118993
Validation loss: 2.355677949839442

Epoch: 5| Step: 1
Training loss: 2.5606112148369156
Validation loss: 2.336840717906618

Epoch: 5| Step: 2
Training loss: 2.224303159997959
Validation loss: 2.3632703441374

Epoch: 5| Step: 3
Training loss: 1.8197480337512533
Validation loss: 2.3257300350051686

Epoch: 5| Step: 4
Training loss: 1.6954932050599734
Validation loss: 2.3518251351375214

Epoch: 5| Step: 5
Training loss: 2.2146209120290954
Validation loss: 2.3657383784888126

Epoch: 5| Step: 6
Training loss: 1.960369985459101
Validation loss: 2.362705848347548

Epoch: 5| Step: 7
Training loss: 1.918115738404786
Validation loss: 2.3360349134320977

Epoch: 5| Step: 8
Training loss: 2.2140210758229544
Validation loss: 2.3469021891637616

Epoch: 5| Step: 9
Training loss: 2.054997757959187
Validation loss: 2.364092266060013

Epoch: 5| Step: 10
Training loss: 1.8463532771084628
Validation loss: 2.3414288332120488

Epoch: 224| Step: 0
Training loss: 1.9327814418853875
Validation loss: 2.3424334322318487

Epoch: 5| Step: 1
Training loss: 2.0274017266893742
Validation loss: 2.3619161654121172

Epoch: 5| Step: 2
Training loss: 1.9935308975798978
Validation loss: 2.358738983622616

Epoch: 5| Step: 3
Training loss: 2.227573312565493
Validation loss: 2.331817634758558

Epoch: 5| Step: 4
Training loss: 2.1308420322177497
Validation loss: 2.354794674857206

Epoch: 5| Step: 5
Training loss: 2.4426729135988694
Validation loss: 2.3436889006057875

Epoch: 5| Step: 6
Training loss: 2.261484822510978
Validation loss: 2.3112596790196216

Epoch: 5| Step: 7
Training loss: 2.2172911240044386
Validation loss: 2.3306899552728497

Epoch: 5| Step: 8
Training loss: 1.7179252726564216
Validation loss: 2.312944120703263

Epoch: 5| Step: 9
Training loss: 1.6485260130635095
Validation loss: 2.3286975410681587

Epoch: 5| Step: 10
Training loss: 1.7696828882452698
Validation loss: 2.3231236778387343

Epoch: 225| Step: 0
Training loss: 2.3772205211782595
Validation loss: 2.3178247743073923

Epoch: 5| Step: 1
Training loss: 1.5897539193083623
Validation loss: 2.33570719710031

Epoch: 5| Step: 2
Training loss: 2.347692200548885
Validation loss: 2.3269209830617195

Epoch: 5| Step: 3
Training loss: 2.248637952743191
Validation loss: 2.322163803120523

Epoch: 5| Step: 4
Training loss: 1.9765375912269114
Validation loss: 2.3014617720774804

Epoch: 5| Step: 5
Training loss: 1.107106051074928
Validation loss: 2.316495885800587

Epoch: 5| Step: 6
Training loss: 2.0249506767765197
Validation loss: 2.3557264170438894

Epoch: 5| Step: 7
Training loss: 2.1056492432636396
Validation loss: 2.3367590089875625

Epoch: 5| Step: 8
Training loss: 2.2720487882318805
Validation loss: 2.3703211533045794

Epoch: 5| Step: 9
Training loss: 2.063416248600906
Validation loss: 2.345125698389877

Epoch: 5| Step: 10
Training loss: 2.109823899717079
Validation loss: 2.328355742375238

Epoch: 226| Step: 0
Training loss: 2.3352020024360627
Validation loss: 2.341883924303652

Epoch: 5| Step: 1
Training loss: 1.8772862165622624
Validation loss: 2.3134853377917053

Epoch: 5| Step: 2
Training loss: 2.298121107822802
Validation loss: 2.3716430665667043

Epoch: 5| Step: 3
Training loss: 2.0086384421457906
Validation loss: 2.3216013912008573

Epoch: 5| Step: 4
Training loss: 1.4004377413049904
Validation loss: 2.3613727784902347

Epoch: 5| Step: 5
Training loss: 2.146697737526187
Validation loss: 2.3686696570242165

Epoch: 5| Step: 6
Training loss: 2.143734865719059
Validation loss: 2.3267715560171647

Epoch: 5| Step: 7
Training loss: 1.938145560727855
Validation loss: 2.3561062617483675

Epoch: 5| Step: 8
Training loss: 1.765944257921402
Validation loss: 2.331463487753598

Epoch: 5| Step: 9
Training loss: 2.1913125737205656
Validation loss: 2.3392798647717563

Epoch: 5| Step: 10
Training loss: 2.3780265396729012
Validation loss: 2.324614807781276

Epoch: 227| Step: 0
Training loss: 1.9673980430544433
Validation loss: 2.343203939178304

Epoch: 5| Step: 1
Training loss: 2.0227669448001353
Validation loss: 2.360830719441071

Epoch: 5| Step: 2
Training loss: 1.744779839167196
Validation loss: 2.3462608271217382

Epoch: 5| Step: 3
Training loss: 2.0759362188401607
Validation loss: 2.321547147890562

Epoch: 5| Step: 4
Training loss: 2.068190613688879
Validation loss: 2.3274862896143467

Epoch: 5| Step: 5
Training loss: 1.905712927531651
Validation loss: 2.329131584982671

Epoch: 5| Step: 6
Training loss: 1.6932351177873308
Validation loss: 2.3535982575205225

Epoch: 5| Step: 7
Training loss: 2.0248357588484254
Validation loss: 2.3539558245081373

Epoch: 5| Step: 8
Training loss: 2.2069353200943786
Validation loss: 2.3450289257862296

Epoch: 5| Step: 9
Training loss: 2.21912047825743
Validation loss: 2.320957660251949

Epoch: 5| Step: 10
Training loss: 2.1701296372958176
Validation loss: 2.339664164524298

Epoch: 228| Step: 0
Training loss: 1.8990177476564842
Validation loss: 2.3323650341441287

Epoch: 5| Step: 1
Training loss: 1.5598625812159967
Validation loss: 2.354862483461287

Epoch: 5| Step: 2
Training loss: 1.311647183509065
Validation loss: 2.345115277097536

Epoch: 5| Step: 3
Training loss: 2.048866991632657
Validation loss: 2.3552396483259175

Epoch: 5| Step: 4
Training loss: 1.941295904634947
Validation loss: 2.359461237800892

Epoch: 5| Step: 5
Training loss: 2.4423887671421314
Validation loss: 2.3211703465395788

Epoch: 5| Step: 6
Training loss: 1.9526340935802247
Validation loss: 2.3557263658957126

Epoch: 5| Step: 7
Training loss: 1.9778365299996976
Validation loss: 2.330727526486048

Epoch: 5| Step: 8
Training loss: 2.131100480995985
Validation loss: 2.33205448284103

Epoch: 5| Step: 9
Training loss: 2.669337445180027
Validation loss: 2.3365714288220314

Epoch: 5| Step: 10
Training loss: 1.9405148952534639
Validation loss: 2.3342222591172033

Epoch: 229| Step: 0
Training loss: 1.4255087396092212
Validation loss: 2.3456796333445635

Epoch: 5| Step: 1
Training loss: 1.8277829494164815
Validation loss: 2.3457364880033147

Epoch: 5| Step: 2
Training loss: 2.066196827651452
Validation loss: 2.331156315139406

Epoch: 5| Step: 3
Training loss: 2.269126764124799
Validation loss: 2.337305367362916

Epoch: 5| Step: 4
Training loss: 2.331082098184043
Validation loss: 2.3443729199051075

Epoch: 5| Step: 5
Training loss: 1.7976587327843023
Validation loss: 2.321385607479042

Epoch: 5| Step: 6
Training loss: 1.695869459787484
Validation loss: 2.355209364329819

Epoch: 5| Step: 7
Training loss: 2.190771000631849
Validation loss: 2.3269984136211193

Epoch: 5| Step: 8
Training loss: 2.079804165130797
Validation loss: 2.3464942873809784

Epoch: 5| Step: 9
Training loss: 2.1681848366761614
Validation loss: 2.329981273431689

Epoch: 5| Step: 10
Training loss: 2.065953571082233
Validation loss: 2.344146830554748

Epoch: 230| Step: 0
Training loss: 1.5453904860270684
Validation loss: 2.3061134822651175

Epoch: 5| Step: 1
Training loss: 2.3355896349468357
Validation loss: 2.36826942519847

Epoch: 5| Step: 2
Training loss: 1.9233173447489265
Validation loss: 2.3207692364909946

Epoch: 5| Step: 3
Training loss: 2.3756972845331195
Validation loss: 2.3677360185883027

Epoch: 5| Step: 4
Training loss: 2.073797668129913
Validation loss: 2.340999215736953

Epoch: 5| Step: 5
Training loss: 1.932430711320793
Validation loss: 2.357863138146906

Epoch: 5| Step: 6
Training loss: 1.7277025282372167
Validation loss: 2.3218026705482444

Epoch: 5| Step: 7
Training loss: 2.274476118866806
Validation loss: 2.3240899477467623

Epoch: 5| Step: 8
Training loss: 1.9121991488118586
Validation loss: 2.3538048136052305

Epoch: 5| Step: 9
Training loss: 2.408469130527493
Validation loss: 2.333288399605029

Epoch: 5| Step: 10
Training loss: 1.5929673461009861
Validation loss: 2.360333004867829

Epoch: 231| Step: 0
Training loss: 2.297149330416752
Validation loss: 2.346919372326133

Epoch: 5| Step: 1
Training loss: 1.773425534917993
Validation loss: 2.32710124238327

Epoch: 5| Step: 2
Training loss: 1.8849658602752137
Validation loss: 2.290061236946142

Epoch: 5| Step: 3
Training loss: 1.6297923360663351
Validation loss: 2.3498549610352435

Epoch: 5| Step: 4
Training loss: 1.945736880910445
Validation loss: 2.326907599196848

Epoch: 5| Step: 5
Training loss: 1.8504910487505033
Validation loss: 2.3134532361744555

Epoch: 5| Step: 6
Training loss: 2.14416211673962
Validation loss: 2.347889962403762

Epoch: 5| Step: 7
Training loss: 1.9392831656828895
Validation loss: 2.3391956924234

Epoch: 5| Step: 8
Training loss: 2.704832915612237
Validation loss: 2.343916714115782

Epoch: 5| Step: 9
Training loss: 1.9348510353649282
Validation loss: 2.3491459271297215

Epoch: 5| Step: 10
Training loss: 1.8245896936366603
Validation loss: 2.3364867408609205

Epoch: 232| Step: 0
Training loss: 1.598218301340281
Validation loss: 2.3330224536171293

Epoch: 5| Step: 1
Training loss: 2.0124319645535316
Validation loss: 2.3382712565350214

Epoch: 5| Step: 2
Training loss: 2.0906401355691604
Validation loss: 2.359612961218582

Epoch: 5| Step: 3
Training loss: 2.1495005803805105
Validation loss: 2.3803045374061336

Epoch: 5| Step: 4
Training loss: 2.3749800229487232
Validation loss: 2.3103753273275927

Epoch: 5| Step: 5
Training loss: 2.2346127256895043
Validation loss: 2.3411999278869606

Epoch: 5| Step: 6
Training loss: 1.740403292385907
Validation loss: 2.3438547265503837

Epoch: 5| Step: 7
Training loss: 2.4872985528241975
Validation loss: 2.3619792961884585

Epoch: 5| Step: 8
Training loss: 1.7556444148955548
Validation loss: 2.345256582074223

Epoch: 5| Step: 9
Training loss: 2.0645229937694998
Validation loss: 2.355854016316926

Epoch: 5| Step: 10
Training loss: 1.8051805359434947
Validation loss: 2.368652033665199

Epoch: 233| Step: 0
Training loss: 2.0186409085208075
Validation loss: 2.315012134095047

Epoch: 5| Step: 1
Training loss: 1.9866816413344899
Validation loss: 2.3268208220034756

Epoch: 5| Step: 2
Training loss: 1.8428999670889055
Validation loss: 2.350181392327049

Epoch: 5| Step: 3
Training loss: 2.0858956664958934
Validation loss: 2.335777972794432

Epoch: 5| Step: 4
Training loss: 1.9624964379928238
Validation loss: 2.317109669409312

Epoch: 5| Step: 5
Training loss: 2.610266436135351
Validation loss: 2.3311129397672015

Epoch: 5| Step: 6
Training loss: 1.6155697014381887
Validation loss: 2.3309195396691194

Epoch: 5| Step: 7
Training loss: 2.2525494225231606
Validation loss: 2.308497299712268

Epoch: 5| Step: 8
Training loss: 1.8204999180526318
Validation loss: 2.36377065973034

Epoch: 5| Step: 9
Training loss: 1.8282672142074912
Validation loss: 2.3253827514229606

Epoch: 5| Step: 10
Training loss: 2.0752993999631246
Validation loss: 2.342617534647594

Epoch: 234| Step: 0
Training loss: 1.847958562204719
Validation loss: 2.324212204718945

Epoch: 5| Step: 1
Training loss: 1.7006854162170826
Validation loss: 2.3181490379704925

Epoch: 5| Step: 2
Training loss: 1.416746090551219
Validation loss: 2.341720056375864

Epoch: 5| Step: 3
Training loss: 2.1759199718036157
Validation loss: 2.3153486623919552

Epoch: 5| Step: 4
Training loss: 2.2217479385120886
Validation loss: 2.3546225461851136

Epoch: 5| Step: 5
Training loss: 2.527217714448184
Validation loss: 2.3222924886591545

Epoch: 5| Step: 6
Training loss: 2.0369210526491552
Validation loss: 2.3423821836678753

Epoch: 5| Step: 7
Training loss: 2.0410009064212113
Validation loss: 2.3231092160107134

Epoch: 5| Step: 8
Training loss: 1.9116134234161248
Validation loss: 2.3771143775398142

Epoch: 5| Step: 9
Training loss: 1.6157692850347007
Validation loss: 2.380027289842918

Epoch: 5| Step: 10
Training loss: 2.3495585371877055
Validation loss: 2.344194246800793

Epoch: 235| Step: 0
Training loss: 2.333440562463725
Validation loss: 2.339430304293096

Epoch: 5| Step: 1
Training loss: 1.787621796733338
Validation loss: 2.3550393750852123

Epoch: 5| Step: 2
Training loss: 2.191704116133887
Validation loss: 2.327985274983699

Epoch: 5| Step: 3
Training loss: 1.8014018216237095
Validation loss: 2.357617336428423

Epoch: 5| Step: 4
Training loss: 1.9259017070989095
Validation loss: 2.335851234420503

Epoch: 5| Step: 5
Training loss: 2.1508919307388004
Validation loss: 2.3467638186391873

Epoch: 5| Step: 6
Training loss: 1.7769328218727027
Validation loss: 2.317121298707422

Epoch: 5| Step: 7
Training loss: 1.5863132877214885
Validation loss: 2.317829358898964

Epoch: 5| Step: 8
Training loss: 2.5402845992194925
Validation loss: 2.359096811409268

Epoch: 5| Step: 9
Training loss: 2.2095146858053583
Validation loss: 2.3553934564312513

Epoch: 5| Step: 10
Training loss: 1.3221603644662547
Validation loss: 2.305280310167597

Epoch: 236| Step: 0
Training loss: 1.5899149810805007
Validation loss: 2.3192031090377814

Epoch: 5| Step: 1
Training loss: 2.134666447547522
Validation loss: 2.3517685808312434

Epoch: 5| Step: 2
Training loss: 2.1532743626404054
Validation loss: 2.312473350178446

Epoch: 5| Step: 3
Training loss: 2.1974903313919905
Validation loss: 2.3418151460104997

Epoch: 5| Step: 4
Training loss: 2.242977415232195
Validation loss: 2.3565214900977205

Epoch: 5| Step: 5
Training loss: 1.731527310412958
Validation loss: 2.331325629344572

Epoch: 5| Step: 6
Training loss: 1.3430779573022462
Validation loss: 2.365605648886729

Epoch: 5| Step: 7
Training loss: 2.2674698257541523
Validation loss: 2.32510953815632

Epoch: 5| Step: 8
Training loss: 2.297755066304188
Validation loss: 2.338225639982871

Epoch: 5| Step: 9
Training loss: 2.1104749284279474
Validation loss: 2.2909898146189964

Epoch: 5| Step: 10
Training loss: 1.4429545370330328
Validation loss: 2.32729595861868

Epoch: 237| Step: 0
Training loss: 1.7969365648420665
Validation loss: 2.353017027726843

Epoch: 5| Step: 1
Training loss: 2.1452479875815422
Validation loss: 2.3508097477752616

Epoch: 5| Step: 2
Training loss: 2.2879534954533445
Validation loss: 2.3551912244411257

Epoch: 5| Step: 3
Training loss: 1.8956017684644928
Validation loss: 2.3129759323424763

Epoch: 5| Step: 4
Training loss: 1.8511116348063346
Validation loss: 2.344936955739265

Epoch: 5| Step: 5
Training loss: 1.827225031590405
Validation loss: 2.3526943983377695

Epoch: 5| Step: 6
Training loss: 1.6573130956479605
Validation loss: 2.363221544030032

Epoch: 5| Step: 7
Training loss: 2.0421507384793793
Validation loss: 2.3404296774663944

Epoch: 5| Step: 8
Training loss: 1.9405201783795922
Validation loss: 2.3473706822746734

Epoch: 5| Step: 9
Training loss: 2.0602842045997307
Validation loss: 2.3453638614356294

Epoch: 5| Step: 10
Training loss: 2.164886097543733
Validation loss: 2.2975828726153256

Epoch: 238| Step: 0
Training loss: 1.1761464917228914
Validation loss: 2.3339983092183987

Epoch: 5| Step: 1
Training loss: 2.003857111932566
Validation loss: 2.3603231297064133

Epoch: 5| Step: 2
Training loss: 1.9124562900509885
Validation loss: 2.3366014699799087

Epoch: 5| Step: 3
Training loss: 2.4355187800667566
Validation loss: 2.297710260969664

Epoch: 5| Step: 4
Training loss: 2.100740747142908
Validation loss: 2.3107798863003457

Epoch: 5| Step: 5
Training loss: 2.112355478974991
Validation loss: 2.3382264145923775

Epoch: 5| Step: 6
Training loss: 1.8191593430506094
Validation loss: 2.319347675010976

Epoch: 5| Step: 7
Training loss: 1.5910452536735278
Validation loss: 2.3490902577817745

Epoch: 5| Step: 8
Training loss: 1.9934832977521402
Validation loss: 2.3439043854212227

Epoch: 5| Step: 9
Training loss: 2.2088128654890067
Validation loss: 2.3258758976822853

Epoch: 5| Step: 10
Training loss: 1.9198569270312242
Validation loss: 2.3722443702079916

Epoch: 239| Step: 0
Training loss: 1.915972010187046
Validation loss: 2.364598984906172

Epoch: 5| Step: 1
Training loss: 1.679492531040093
Validation loss: 2.329705076476729

Epoch: 5| Step: 2
Training loss: 1.7763720864117785
Validation loss: 2.3450733881293586

Epoch: 5| Step: 3
Training loss: 1.992878334090954
Validation loss: 2.3558024198311727

Epoch: 5| Step: 4
Training loss: 2.463090808304894
Validation loss: 2.3474708860553486

Epoch: 5| Step: 5
Training loss: 1.8364177319269883
Validation loss: 2.3328737042068357

Epoch: 5| Step: 6
Training loss: 1.7498497217231261
Validation loss: 2.351142520649503

Epoch: 5| Step: 7
Training loss: 1.926081821593174
Validation loss: 2.358603150413136

Epoch: 5| Step: 8
Training loss: 2.01505715111647
Validation loss: 2.3646398568906712

Epoch: 5| Step: 9
Training loss: 2.279065170213293
Validation loss: 2.3487775252038174

Epoch: 5| Step: 10
Training loss: 1.808142982812799
Validation loss: 2.2835831700903735

Epoch: 240| Step: 0
Training loss: 1.5895409447987334
Validation loss: 2.315043173155535

Epoch: 5| Step: 1
Training loss: 1.9197740313554288
Validation loss: 2.354013828068195

Epoch: 5| Step: 2
Training loss: 1.9192634765263161
Validation loss: 2.363212400169281

Epoch: 5| Step: 3
Training loss: 1.9750602350827684
Validation loss: 2.3144248372572327

Epoch: 5| Step: 4
Training loss: 2.187544250040723
Validation loss: 2.3012128869690542

Epoch: 5| Step: 5
Training loss: 1.9959295097013154
Validation loss: 2.33479224212816

Epoch: 5| Step: 6
Training loss: 1.9111192144300984
Validation loss: 2.2942562425226796

Epoch: 5| Step: 7
Training loss: 2.447016600583305
Validation loss: 2.343687796912371

Epoch: 5| Step: 8
Training loss: 1.7146706461160697
Validation loss: 2.366992371796795

Epoch: 5| Step: 9
Training loss: 2.0482968349738324
Validation loss: 2.3124239586741746

Epoch: 5| Step: 10
Training loss: 1.9770145427070573
Validation loss: 2.3755609123060895

Epoch: 241| Step: 0
Training loss: 1.574853508812407
Validation loss: 2.348539106868555

Epoch: 5| Step: 1
Training loss: 1.8405803007906085
Validation loss: 2.2978895891887783

Epoch: 5| Step: 2
Training loss: 2.3051064320648997
Validation loss: 2.3485948018335563

Epoch: 5| Step: 3
Training loss: 2.197698525063861
Validation loss: 2.360597667045251

Epoch: 5| Step: 4
Training loss: 1.7440236085466185
Validation loss: 2.3173150162401916

Epoch: 5| Step: 5
Training loss: 2.2964913184003724
Validation loss: 2.3260133544159296

Epoch: 5| Step: 6
Training loss: 1.4586240024626986
Validation loss: 2.324576677334184

Epoch: 5| Step: 7
Training loss: 2.0364910880834373
Validation loss: 2.3554809659242735

Epoch: 5| Step: 8
Training loss: 1.8698094047477158
Validation loss: 2.3930137764358252

Epoch: 5| Step: 9
Training loss: 2.155965813969094
Validation loss: 2.341763106370894

Epoch: 5| Step: 10
Training loss: 2.0044127896739963
Validation loss: 2.3213302519814825

Epoch: 242| Step: 0
Training loss: 1.9077578974977638
Validation loss: 2.3554875026802544

Epoch: 5| Step: 1
Training loss: 1.7460015803851026
Validation loss: 2.3481251811327426

Epoch: 5| Step: 2
Training loss: 2.1789678664059253
Validation loss: 2.3085838778369228

Epoch: 5| Step: 3
Training loss: 1.6528654965685212
Validation loss: 2.335548923060434

Epoch: 5| Step: 4
Training loss: 2.0702322314554427
Validation loss: 2.3728096630095212

Epoch: 5| Step: 5
Training loss: 2.095975916760528
Validation loss: 2.343783541203525

Epoch: 5| Step: 6
Training loss: 1.9816941903558092
Validation loss: 2.330133405805551

Epoch: 5| Step: 7
Training loss: 2.0277500223266314
Validation loss: 2.3838251381225226

Epoch: 5| Step: 8
Training loss: 2.15124871563693
Validation loss: 2.3095698163265426

Epoch: 5| Step: 9
Training loss: 1.8759891444056862
Validation loss: 2.317018137128301

Epoch: 5| Step: 10
Training loss: 1.6836670330764432
Validation loss: 2.364708196817978

Epoch: 243| Step: 0
Training loss: 2.5645597599866385
Validation loss: 2.354563668073976

Epoch: 5| Step: 1
Training loss: 2.0912198393676693
Validation loss: 2.3630691052073214

Epoch: 5| Step: 2
Training loss: 1.36715759244632
Validation loss: 2.338338968162906

Epoch: 5| Step: 3
Training loss: 1.9982729846324951
Validation loss: 2.3321519254554084

Epoch: 5| Step: 4
Training loss: 1.8527111241013523
Validation loss: 2.3185315360606764

Epoch: 5| Step: 5
Training loss: 1.424581529843592
Validation loss: 2.3303852769187596

Epoch: 5| Step: 6
Training loss: 1.4008286986689438
Validation loss: 2.2965671432607784

Epoch: 5| Step: 7
Training loss: 2.3907781813668953
Validation loss: 2.363489689995714

Epoch: 5| Step: 8
Training loss: 2.0586810735896774
Validation loss: 2.3556444490330857

Epoch: 5| Step: 9
Training loss: 2.0210927685299125
Validation loss: 2.3161020990056786

Epoch: 5| Step: 10
Training loss: 1.8405417638847215
Validation loss: 2.333470455511946

Epoch: 244| Step: 0
Training loss: 1.4313439950520737
Validation loss: 2.3395144742273586

Epoch: 5| Step: 1
Training loss: 2.4647476008262608
Validation loss: 2.3307703898726837

Epoch: 5| Step: 2
Training loss: 1.5570399443464529
Validation loss: 2.320334455846757

Epoch: 5| Step: 3
Training loss: 2.0175657170404397
Validation loss: 2.3467751955704617

Epoch: 5| Step: 4
Training loss: 2.074547693064283
Validation loss: 2.2810365130561148

Epoch: 5| Step: 5
Training loss: 1.8589442419315851
Validation loss: 2.32765711919531

Epoch: 5| Step: 6
Training loss: 2.008628115513946
Validation loss: 2.3276167283979974

Epoch: 5| Step: 7
Training loss: 2.2954254766592803
Validation loss: 2.289865934801364

Epoch: 5| Step: 8
Training loss: 2.268415009118695
Validation loss: 2.3172784356596887

Epoch: 5| Step: 9
Training loss: 1.6181290691231742
Validation loss: 2.309150704823807

Epoch: 5| Step: 10
Training loss: 1.5196964595780798
Validation loss: 2.340728797814235

Epoch: 245| Step: 0
Training loss: 1.9970786693743243
Validation loss: 2.3307459002194477

Epoch: 5| Step: 1
Training loss: 2.5585549853933665
Validation loss: 2.320776169271878

Epoch: 5| Step: 2
Training loss: 1.7079456944017966
Validation loss: 2.3481500992853426

Epoch: 5| Step: 3
Training loss: 2.249069339285434
Validation loss: 2.3424135068673633

Epoch: 5| Step: 4
Training loss: 1.4382287541661454
Validation loss: 2.2955912711783624

Epoch: 5| Step: 5
Training loss: 1.8770696661391972
Validation loss: 2.314863345914704

Epoch: 5| Step: 6
Training loss: 1.4354445648066012
Validation loss: 2.384246433446261

Epoch: 5| Step: 7
Training loss: 1.8406477222432576
Validation loss: 2.351900387613057

Epoch: 5| Step: 8
Training loss: 1.762065641841023
Validation loss: 2.335898422862029

Epoch: 5| Step: 9
Training loss: 2.0931430904942774
Validation loss: 2.352226112722014

Epoch: 5| Step: 10
Training loss: 2.1457241610807194
Validation loss: 2.3404951973080306

Epoch: 246| Step: 0
Training loss: 1.6147996162839315
Validation loss: 2.3403901451647715

Epoch: 5| Step: 1
Training loss: 1.757588554528066
Validation loss: 2.3343844646427763

Epoch: 5| Step: 2
Training loss: 2.317345157129276
Validation loss: 2.3167173593833565

Epoch: 5| Step: 3
Training loss: 2.004559802584156
Validation loss: 2.324032368282792

Epoch: 5| Step: 4
Training loss: 1.9700984877932435
Validation loss: 2.3062045335894146

Epoch: 5| Step: 5
Training loss: 2.0666390704291633
Validation loss: 2.330276361861839

Epoch: 5| Step: 6
Training loss: 1.7910982901196084
Validation loss: 2.3291921725114766

Epoch: 5| Step: 7
Training loss: 1.8102966596587642
Validation loss: 2.341246808141116

Epoch: 5| Step: 8
Training loss: 1.8380941507344262
Validation loss: 2.344717792607458

Epoch: 5| Step: 9
Training loss: 2.1956000631834507
Validation loss: 2.3096599144616565

Epoch: 5| Step: 10
Training loss: 1.7229190548100308
Validation loss: 2.333091365849036

Epoch: 247| Step: 0
Training loss: 2.1063287284467904
Validation loss: 2.317369077066955

Epoch: 5| Step: 1
Training loss: 1.358247223369387
Validation loss: 2.3247894289668727

Epoch: 5| Step: 2
Training loss: 2.110471426381093
Validation loss: 2.301147444052368

Epoch: 5| Step: 3
Training loss: 1.5851975391889594
Validation loss: 2.345746631127838

Epoch: 5| Step: 4
Training loss: 1.8815386883328653
Validation loss: 2.336613975449132

Epoch: 5| Step: 5
Training loss: 2.343173757286458
Validation loss: 2.3465208141205194

Epoch: 5| Step: 6
Training loss: 1.9990456211366818
Validation loss: 2.282557786477505

Epoch: 5| Step: 7
Training loss: 1.5983937993046768
Validation loss: 2.32185263323116

Epoch: 5| Step: 8
Training loss: 2.0393037032192196
Validation loss: 2.3107536249144505

Epoch: 5| Step: 9
Training loss: 1.8198557268326507
Validation loss: 2.309559563161236

Epoch: 5| Step: 10
Training loss: 2.1546029697404476
Validation loss: 2.3594597204522523

Epoch: 248| Step: 0
Training loss: 2.1218154831462237
Validation loss: 2.349322147042496

Epoch: 5| Step: 1
Training loss: 2.2185580748169405
Validation loss: 2.332286996377887

Epoch: 5| Step: 2
Training loss: 2.1183936705601343
Validation loss: 2.3285943754497618

Epoch: 5| Step: 3
Training loss: 2.0424805271149586
Validation loss: 2.327785322085557

Epoch: 5| Step: 4
Training loss: 1.5574902904324186
Validation loss: 2.3489142518522614

Epoch: 5| Step: 5
Training loss: 1.4404033697277971
Validation loss: 2.323601931806009

Epoch: 5| Step: 6
Training loss: 2.14056474364183
Validation loss: 2.3329519838816704

Epoch: 5| Step: 7
Training loss: 2.198110080784421
Validation loss: 2.3141045534223825

Epoch: 5| Step: 8
Training loss: 1.4690825714836993
Validation loss: 2.340176441741363

Epoch: 5| Step: 9
Training loss: 2.034651153619472
Validation loss: 2.34357443750152

Epoch: 5| Step: 10
Training loss: 1.5612084200402083
Validation loss: 2.3039336453658694

Epoch: 249| Step: 0
Training loss: 1.9617888893462274
Validation loss: 2.2964040342996146

Epoch: 5| Step: 1
Training loss: 1.7674020921926794
Validation loss: 2.279013996155461

Epoch: 5| Step: 2
Training loss: 2.37874709224874
Validation loss: 2.3078006653407934

Epoch: 5| Step: 3
Training loss: 1.8822491701357082
Validation loss: 2.363222519271842

Epoch: 5| Step: 4
Training loss: 1.7678337123138337
Validation loss: 2.2684983976847137

Epoch: 5| Step: 5
Training loss: 2.1434568065636417
Validation loss: 2.3318451084851923

Epoch: 5| Step: 6
Training loss: 1.6078912506243164
Validation loss: 2.328460475384559

Epoch: 5| Step: 7
Training loss: 1.6710091603802497
Validation loss: 2.365887845343145

Epoch: 5| Step: 8
Training loss: 1.5622344745091008
Validation loss: 2.3234781724912694

Epoch: 5| Step: 9
Training loss: 1.7434960484592565
Validation loss: 2.3719000195523052

Epoch: 5| Step: 10
Training loss: 2.2594714554369943
Validation loss: 2.307510826305777

Epoch: 250| Step: 0
Training loss: 2.033470700527742
Validation loss: 2.3576526348960893

Epoch: 5| Step: 1
Training loss: 2.1970306949059974
Validation loss: 2.346510009536012

Epoch: 5| Step: 2
Training loss: 1.658282130934962
Validation loss: 2.3472399273959232

Epoch: 5| Step: 3
Training loss: 1.6614292425241675
Validation loss: 2.312015385111624

Epoch: 5| Step: 4
Training loss: 2.163555209748502
Validation loss: 2.324363193726886

Epoch: 5| Step: 5
Training loss: 1.3853102717262278
Validation loss: 2.307924557761472

Epoch: 5| Step: 6
Training loss: 2.0976460206192615
Validation loss: 2.3160026207073696

Epoch: 5| Step: 7
Training loss: 1.9796443028242083
Validation loss: 2.308575468697339

Epoch: 5| Step: 8
Training loss: 1.9828200367933864
Validation loss: 2.3463824686333394

Epoch: 5| Step: 9
Training loss: 1.930817801992453
Validation loss: 2.3031061012952088

Epoch: 5| Step: 10
Training loss: 1.5652313773133886
Validation loss: 2.327250644954749

Epoch: 251| Step: 0
Training loss: 2.0107953072451608
Validation loss: 2.282486225371401

Epoch: 5| Step: 1
Training loss: 2.115785254039487
Validation loss: 2.3311294167080745

Epoch: 5| Step: 2
Training loss: 1.378272367456795
Validation loss: 2.3159062481726305

Epoch: 5| Step: 3
Training loss: 1.9588794014551254
Validation loss: 2.332342463349

Epoch: 5| Step: 4
Training loss: 1.9421288970183381
Validation loss: 2.3212656158873215

Epoch: 5| Step: 5
Training loss: 1.7060482590570072
Validation loss: 2.3541943781429864

Epoch: 5| Step: 6
Training loss: 1.9319327570347415
Validation loss: 2.3163143960734813

Epoch: 5| Step: 7
Training loss: 1.8484339297236758
Validation loss: 2.3332337901714153

Epoch: 5| Step: 8
Training loss: 2.233086274369366
Validation loss: 2.3465964399029002

Epoch: 5| Step: 9
Training loss: 1.7473900269489115
Validation loss: 2.328029917203895

Epoch: 5| Step: 10
Training loss: 2.0125366918405834
Validation loss: 2.3135193526752906

Epoch: 252| Step: 0
Training loss: 1.4174581822277008
Validation loss: 2.3320268813117897

Epoch: 5| Step: 1
Training loss: 2.20998380870843
Validation loss: 2.3099176410663396

Epoch: 5| Step: 2
Training loss: 2.1807308639496683
Validation loss: 2.3066249517379083

Epoch: 5| Step: 3
Training loss: 2.0020191014280835
Validation loss: 2.317401299228886

Epoch: 5| Step: 4
Training loss: 1.9004680308057018
Validation loss: 2.320524795226631

Epoch: 5| Step: 5
Training loss: 1.9055384574298522
Validation loss: 2.319167506131313

Epoch: 5| Step: 6
Training loss: 1.9921679925898474
Validation loss: 2.297932027566978

Epoch: 5| Step: 7
Training loss: 1.8059017835716726
Validation loss: 2.3046293473454607

Epoch: 5| Step: 8
Training loss: 1.509176161406357
Validation loss: 2.3026585667376605

Epoch: 5| Step: 9
Training loss: 1.8409925628130626
Validation loss: 2.321934977943578

Epoch: 5| Step: 10
Training loss: 2.0971818952353374
Validation loss: 2.3198337938799884

Epoch: 253| Step: 0
Training loss: 1.9288843622584242
Validation loss: 2.3461057029198544

Epoch: 5| Step: 1
Training loss: 1.5091452761390463
Validation loss: 2.3170752580285434

Epoch: 5| Step: 2
Training loss: 1.9268913860781218
Validation loss: 2.3215548397478134

Epoch: 5| Step: 3
Training loss: 2.008261070164918
Validation loss: 2.353917085698002

Epoch: 5| Step: 4
Training loss: 1.7024726668304933
Validation loss: 2.3304975766613945

Epoch: 5| Step: 5
Training loss: 1.3358899381324754
Validation loss: 2.3289403297768727

Epoch: 5| Step: 6
Training loss: 2.0824226169015985
Validation loss: 2.3229521186720876

Epoch: 5| Step: 7
Training loss: 2.6425216454491873
Validation loss: 2.3660674438274953

Epoch: 5| Step: 8
Training loss: 1.9232680691577226
Validation loss: 2.354732418948551

Epoch: 5| Step: 9
Training loss: 1.8216248067296734
Validation loss: 2.3624367062125105

Epoch: 5| Step: 10
Training loss: 1.885991495366101
Validation loss: 2.290536637307176

Epoch: 254| Step: 0
Training loss: 1.7733080308347167
Validation loss: 2.3257771025262537

Epoch: 5| Step: 1
Training loss: 2.1725409056364895
Validation loss: 2.309919540003014

Epoch: 5| Step: 2
Training loss: 1.5360451180368289
Validation loss: 2.3493467376842876

Epoch: 5| Step: 3
Training loss: 1.4634702219329982
Validation loss: 2.3072137984547045

Epoch: 5| Step: 4
Training loss: 1.8145377444275301
Validation loss: 2.299888745961495

Epoch: 5| Step: 5
Training loss: 1.6656533816784116
Validation loss: 2.313442093753998

Epoch: 5| Step: 6
Training loss: 2.095897654866595
Validation loss: 2.2713494107192655

Epoch: 5| Step: 7
Training loss: 1.4380370256487978
Validation loss: 2.35011167110371

Epoch: 5| Step: 8
Training loss: 2.7897003042944886
Validation loss: 2.3534099993761006

Epoch: 5| Step: 9
Training loss: 1.8151964978706736
Validation loss: 2.3267143244325204

Epoch: 5| Step: 10
Training loss: 1.8381782006765903
Validation loss: 2.314125427665396

Epoch: 255| Step: 0
Training loss: 2.081430888978364
Validation loss: 2.306813551738483

Epoch: 5| Step: 1
Training loss: 1.3258512443628998
Validation loss: 2.3305090330001788

Epoch: 5| Step: 2
Training loss: 1.8538047637361335
Validation loss: 2.32332050755434

Epoch: 5| Step: 3
Training loss: 1.4531514975480189
Validation loss: 2.3500255134749257

Epoch: 5| Step: 4
Training loss: 1.875009536718911
Validation loss: 2.341155927724994

Epoch: 5| Step: 5
Training loss: 1.720271875939509
Validation loss: 2.3330013391277915

Epoch: 5| Step: 6
Training loss: 2.2633814785892477
Validation loss: 2.3721942552348305

Epoch: 5| Step: 7
Training loss: 1.9280844759894504
Validation loss: 2.323353037788641

Epoch: 5| Step: 8
Training loss: 1.4829607199098884
Validation loss: 2.3144433044139396

Epoch: 5| Step: 9
Training loss: 2.437645834448245
Validation loss: 2.331791344794299

Epoch: 5| Step: 10
Training loss: 2.0411746022490225
Validation loss: 2.3440727946817157

Epoch: 256| Step: 0
Training loss: 1.723294371318817
Validation loss: 2.3247138160946195

Epoch: 5| Step: 1
Training loss: 1.3556324093212992
Validation loss: 2.3078362814202227

Epoch: 5| Step: 2
Training loss: 2.3157814045131224
Validation loss: 2.3277906177852317

Epoch: 5| Step: 3
Training loss: 1.930860525814256
Validation loss: 2.3282036832363917

Epoch: 5| Step: 4
Training loss: 2.1691146983680953
Validation loss: 2.309730926127228

Epoch: 5| Step: 5
Training loss: 1.3773934600393438
Validation loss: 2.3448184076872467

Epoch: 5| Step: 6
Training loss: 1.7691885845870847
Validation loss: 2.274607635887517

Epoch: 5| Step: 7
Training loss: 2.2733994313621664
Validation loss: 2.3250679299271693

Epoch: 5| Step: 8
Training loss: 1.9283113089743154
Validation loss: 2.3490243097619485

Epoch: 5| Step: 9
Training loss: 1.7043111327976268
Validation loss: 2.349481921054645

Epoch: 5| Step: 10
Training loss: 1.753576642778695
Validation loss: 2.295684231216883

Epoch: 257| Step: 0
Training loss: 1.6266526841255786
Validation loss: 2.306280479848903

Epoch: 5| Step: 1
Training loss: 1.7055271951234503
Validation loss: 2.345324010048008

Epoch: 5| Step: 2
Training loss: 1.9388692386048005
Validation loss: 2.324530531764015

Epoch: 5| Step: 3
Training loss: 2.058744073985499
Validation loss: 2.2955269109924723

Epoch: 5| Step: 4
Training loss: 1.5870735346554319
Validation loss: 2.342611211491823

Epoch: 5| Step: 5
Training loss: 1.801863074393872
Validation loss: 2.3216981738476075

Epoch: 5| Step: 6
Training loss: 1.7416348799705421
Validation loss: 2.3236730204937164

Epoch: 5| Step: 7
Training loss: 2.8350611822398926
Validation loss: 2.337440074683122

Epoch: 5| Step: 8
Training loss: 1.5173397785300171
Validation loss: 2.300624037066456

Epoch: 5| Step: 9
Training loss: 1.7011043916230835
Validation loss: 2.322915867454435

Epoch: 5| Step: 10
Training loss: 1.9092907026946526
Validation loss: 2.3908644016197234

Epoch: 258| Step: 0
Training loss: 2.360199133828428
Validation loss: 2.3324095249389183

Epoch: 5| Step: 1
Training loss: 1.732262846002942
Validation loss: 2.319028335838034

Epoch: 5| Step: 2
Training loss: 1.9225877510154417
Validation loss: 2.333001718234281

Epoch: 5| Step: 3
Training loss: 1.780999082326251
Validation loss: 2.3378809412461505

Epoch: 5| Step: 4
Training loss: 1.6159545326257394
Validation loss: 2.302949726677686

Epoch: 5| Step: 5
Training loss: 1.818686090244447
Validation loss: 2.3048840688697867

Epoch: 5| Step: 6
Training loss: 1.6812650148082873
Validation loss: 2.290707861007342

Epoch: 5| Step: 7
Training loss: 1.8544958515341963
Validation loss: 2.325980772111479

Epoch: 5| Step: 8
Training loss: 1.9403890174477856
Validation loss: 2.3014917674769295

Epoch: 5| Step: 9
Training loss: 2.0455852842452815
Validation loss: 2.3042406152583115

Epoch: 5| Step: 10
Training loss: 1.5598981939010292
Validation loss: 2.276002281296675

Epoch: 259| Step: 0
Training loss: 1.9879128465180667
Validation loss: 2.311374919421637

Epoch: 5| Step: 1
Training loss: 1.3039518555196206
Validation loss: 2.298744403588933

Epoch: 5| Step: 2
Training loss: 1.9853665135050977
Validation loss: 2.2962460187191898

Epoch: 5| Step: 3
Training loss: 2.043221160875581
Validation loss: 2.308485318242505

Epoch: 5| Step: 4
Training loss: 1.9096366315985462
Validation loss: 2.370120024129167

Epoch: 5| Step: 5
Training loss: 2.04902605786191
Validation loss: 2.312305642928802

Epoch: 5| Step: 6
Training loss: 1.7032560245615096
Validation loss: 2.353956742600402

Epoch: 5| Step: 7
Training loss: 1.8190943362502827
Validation loss: 2.3086507234382494

Epoch: 5| Step: 8
Training loss: 2.0822341562420155
Validation loss: 2.370413426822281

Epoch: 5| Step: 9
Training loss: 1.658061063003248
Validation loss: 2.2942950579042347

Epoch: 5| Step: 10
Training loss: 1.7686903684019863
Validation loss: 2.3125398328122584

Epoch: 260| Step: 0
Training loss: 1.8843827407197136
Validation loss: 2.3190931155386068

Epoch: 5| Step: 1
Training loss: 1.26263210436404
Validation loss: 2.340042707582713

Epoch: 5| Step: 2
Training loss: 1.8141896494909424
Validation loss: 2.2812654666373513

Epoch: 5| Step: 3
Training loss: 2.1744031942348303
Validation loss: 2.36702752775092

Epoch: 5| Step: 4
Training loss: 2.038768761768937
Validation loss: 2.3288040288571974

Epoch: 5| Step: 5
Training loss: 1.7253006686907195
Validation loss: 2.3440680306530637

Epoch: 5| Step: 6
Training loss: 2.1711588165866726
Validation loss: 2.3493920188199895

Epoch: 5| Step: 7
Training loss: 2.0679113895313823
Validation loss: 2.357992801113997

Epoch: 5| Step: 8
Training loss: 1.848891637611078
Validation loss: 2.316895039686067

Epoch: 5| Step: 9
Training loss: 1.8466644528555884
Validation loss: 2.325453808271078

Epoch: 5| Step: 10
Training loss: 1.399450265718247
Validation loss: 2.353880362198512

Epoch: 261| Step: 0
Training loss: 2.187984412917106
Validation loss: 2.3276268353872323

Epoch: 5| Step: 1
Training loss: 1.7230107295210904
Validation loss: 2.3136631541116093

Epoch: 5| Step: 2
Training loss: 1.4344994285319093
Validation loss: 2.300850697793888

Epoch: 5| Step: 3
Training loss: 1.7547273137101236
Validation loss: 2.3451058232301203

Epoch: 5| Step: 4
Training loss: 1.9745759291415128
Validation loss: 2.323082861152954

Epoch: 5| Step: 5
Training loss: 1.5902921526988898
Validation loss: 2.3071688834622073

Epoch: 5| Step: 6
Training loss: 2.1592941909442667
Validation loss: 2.340376877759996

Epoch: 5| Step: 7
Training loss: 2.0876816447828865
Validation loss: 2.3255749606251914

Epoch: 5| Step: 8
Training loss: 2.0251992115884927
Validation loss: 2.2929762364123953

Epoch: 5| Step: 9
Training loss: 1.67116717034156
Validation loss: 2.30940730212899

Epoch: 5| Step: 10
Training loss: 1.790987403505843
Validation loss: 2.279254720080669

Epoch: 262| Step: 0
Training loss: 1.9274584293459327
Validation loss: 2.2651491711456226

Epoch: 5| Step: 1
Training loss: 1.7294857772458492
Validation loss: 2.274669357878046

Epoch: 5| Step: 2
Training loss: 2.621611360700971
Validation loss: 2.2992836323909875

Epoch: 5| Step: 3
Training loss: 1.5535587065979166
Validation loss: 2.306462979197274

Epoch: 5| Step: 4
Training loss: 1.964476776739205
Validation loss: 2.30533393705362

Epoch: 5| Step: 5
Training loss: 1.3718672524061821
Validation loss: 2.3089693849799726

Epoch: 5| Step: 6
Training loss: 1.780396775803296
Validation loss: 2.332141697920695

Epoch: 5| Step: 7
Training loss: 1.5178957573603011
Validation loss: 2.340645323233489

Epoch: 5| Step: 8
Training loss: 2.0831891073531055
Validation loss: 2.3196950061611985

Epoch: 5| Step: 9
Training loss: 1.7477520401017443
Validation loss: 2.3331695283431273

Epoch: 5| Step: 10
Training loss: 1.8129133871170549
Validation loss: 2.3485114152627977

Epoch: 263| Step: 0
Training loss: 1.9951601476614063
Validation loss: 2.314503323870905

Epoch: 5| Step: 1
Training loss: 1.970396776083486
Validation loss: 2.30465493100115

Epoch: 5| Step: 2
Training loss: 1.8222590177524576
Validation loss: 2.335473504858162

Epoch: 5| Step: 3
Training loss: 1.7087531930688522
Validation loss: 2.2908406255790683

Epoch: 5| Step: 4
Training loss: 2.236301045482882
Validation loss: 2.3043849704098784

Epoch: 5| Step: 5
Training loss: 1.8678001771277533
Validation loss: 2.303853944068622

Epoch: 5| Step: 6
Training loss: 2.1279146737509587
Validation loss: 2.308667404554239

Epoch: 5| Step: 7
Training loss: 1.8381706778445388
Validation loss: 2.323074340619323

Epoch: 5| Step: 8
Training loss: 1.590444165575795
Validation loss: 2.287462655312936

Epoch: 5| Step: 9
Training loss: 1.3415966967390198
Validation loss: 2.3188174774007684

Epoch: 5| Step: 10
Training loss: 1.3885273918606675
Validation loss: 2.3352763052708907

Epoch: 264| Step: 0
Training loss: 1.5715285569744994
Validation loss: 2.2992107855493664

Epoch: 5| Step: 1
Training loss: 1.629967798722363
Validation loss: 2.3100583240751473

Epoch: 5| Step: 2
Training loss: 1.416450465291243
Validation loss: 2.3406530941673998

Epoch: 5| Step: 3
Training loss: 2.025261605401263
Validation loss: 2.29401039205106

Epoch: 5| Step: 4
Training loss: 2.0961225361932114
Validation loss: 2.3565298222470337

Epoch: 5| Step: 5
Training loss: 1.8755734520412883
Validation loss: 2.3283165071593968

Epoch: 5| Step: 6
Training loss: 1.513732672670139
Validation loss: 2.3340070831420237

Epoch: 5| Step: 7
Training loss: 1.8139325104369357
Validation loss: 2.326959822055285

Epoch: 5| Step: 8
Training loss: 2.098939755139038
Validation loss: 2.3056576102038195

Epoch: 5| Step: 9
Training loss: 1.4903130066851384
Validation loss: 2.279173387530792

Epoch: 5| Step: 10
Training loss: 2.561545589698819
Validation loss: 2.306059138119327

Epoch: 265| Step: 0
Training loss: 2.1002185026662463
Validation loss: 2.306270604453275

Epoch: 5| Step: 1
Training loss: 1.5751580022850011
Validation loss: 2.2972533468497276

Epoch: 5| Step: 2
Training loss: 2.1277932153489814
Validation loss: 2.330770189688823

Epoch: 5| Step: 3
Training loss: 1.8125399881095297
Validation loss: 2.3514044406045636

Epoch: 5| Step: 4
Training loss: 1.7214907208718058
Validation loss: 2.3320385076768164

Epoch: 5| Step: 5
Training loss: 1.7079845010290975
Validation loss: 2.348014780824302

Epoch: 5| Step: 6
Training loss: 2.1838008666378386
Validation loss: 2.3468697603195974

Epoch: 5| Step: 7
Training loss: 1.4775676232884845
Validation loss: 2.3774983704733264

Epoch: 5| Step: 8
Training loss: 1.8551670190522205
Validation loss: 2.3090485433226147

Epoch: 5| Step: 9
Training loss: 1.6420808418111121
Validation loss: 2.3140154758678624

Epoch: 5| Step: 10
Training loss: 1.7987600638801937
Validation loss: 2.2982234126197016

Epoch: 266| Step: 0
Training loss: 2.523964841558483
Validation loss: 2.305531776255515

Epoch: 5| Step: 1
Training loss: 1.881733945528472
Validation loss: 2.324889042114542

Epoch: 5| Step: 2
Training loss: 1.6989487707577235
Validation loss: 2.3093599931108133

Epoch: 5| Step: 3
Training loss: 1.7126342860009722
Validation loss: 2.3072834137429363

Epoch: 5| Step: 4
Training loss: 1.661715289328863
Validation loss: 2.2822113438886213

Epoch: 5| Step: 5
Training loss: 1.6534792197888177
Validation loss: 2.3026256294676335

Epoch: 5| Step: 6
Training loss: 1.3398551384355653
Validation loss: 2.295106021472281

Epoch: 5| Step: 7
Training loss: 1.8151943963353971
Validation loss: 2.273761076291444

Epoch: 5| Step: 8
Training loss: 1.9379721650721933
Validation loss: 2.3198876976598366

Epoch: 5| Step: 9
Training loss: 1.6879782528809715
Validation loss: 2.3008444191880204

Epoch: 5| Step: 10
Training loss: 1.6079887419586454
Validation loss: 2.314903171284105

Epoch: 267| Step: 0
Training loss: 2.2256191463763058
Validation loss: 2.361425604878133

Epoch: 5| Step: 1
Training loss: 1.7840502628849553
Validation loss: 2.301909148405117

Epoch: 5| Step: 2
Training loss: 2.1265875552100755
Validation loss: 2.322452954864974

Epoch: 5| Step: 3
Training loss: 1.560424723517377
Validation loss: 2.320977838847261

Epoch: 5| Step: 4
Training loss: 1.637788846114974
Validation loss: 2.3148189248854085

Epoch: 5| Step: 5
Training loss: 1.5457255398713563
Validation loss: 2.3027737488436313

Epoch: 5| Step: 6
Training loss: 1.251372251683457
Validation loss: 2.335718433066057

Epoch: 5| Step: 7
Training loss: 1.341772976014194
Validation loss: 2.3297036464879883

Epoch: 5| Step: 8
Training loss: 2.0950634380923523
Validation loss: 2.300689225769798

Epoch: 5| Step: 9
Training loss: 2.3890006337410497
Validation loss: 2.3797707947957223

Epoch: 5| Step: 10
Training loss: 1.7606807111945257
Validation loss: 2.3338591610127066

Epoch: 268| Step: 0
Training loss: 1.71965793557171
Validation loss: 2.319672717130701

Epoch: 5| Step: 1
Training loss: 1.9879158448688208
Validation loss: 2.2871133654312406

Epoch: 5| Step: 2
Training loss: 1.4862081351451686
Validation loss: 2.338366001833491

Epoch: 5| Step: 3
Training loss: 1.491878457546822
Validation loss: 2.2837179771513267

Epoch: 5| Step: 4
Training loss: 1.5384764354241331
Validation loss: 2.291399570087809

Epoch: 5| Step: 5
Training loss: 1.9051488603917741
Validation loss: 2.3248938683244393

Epoch: 5| Step: 6
Training loss: 2.400548248454498
Validation loss: 2.334419516995424

Epoch: 5| Step: 7
Training loss: 1.6736633148423177
Validation loss: 2.3097802309304587

Epoch: 5| Step: 8
Training loss: 1.6581351150566517
Validation loss: 2.2997214832176756

Epoch: 5| Step: 9
Training loss: 1.9007796921353242
Validation loss: 2.322129405916176

Epoch: 5| Step: 10
Training loss: 1.7781311303219098
Validation loss: 2.292203140856909

Epoch: 269| Step: 0
Training loss: 2.069345154680983
Validation loss: 2.3008722777942885

Epoch: 5| Step: 1
Training loss: 1.2857454566734368
Validation loss: 2.2729042611048125

Epoch: 5| Step: 2
Training loss: 1.6992587380801225
Validation loss: 2.3394910064506798

Epoch: 5| Step: 3
Training loss: 2.0220029009261484
Validation loss: 2.2673267879772543

Epoch: 5| Step: 4
Training loss: 1.9688882325099333
Validation loss: 2.3248834434559162

Epoch: 5| Step: 5
Training loss: 1.7940105661019392
Validation loss: 2.3313231100466263

Epoch: 5| Step: 6
Training loss: 2.2634555295262744
Validation loss: 2.306206959159586

Epoch: 5| Step: 7
Training loss: 1.689521991009726
Validation loss: 2.329606513039531

Epoch: 5| Step: 8
Training loss: 2.0305223775653043
Validation loss: 2.302377024944382

Epoch: 5| Step: 9
Training loss: 1.6728892592120483
Validation loss: 2.269717209667409

Epoch: 5| Step: 10
Training loss: 1.5329123057187342
Validation loss: 2.3658947201383356

Epoch: 270| Step: 0
Training loss: 1.4888288636863065
Validation loss: 2.3082258484739513

Epoch: 5| Step: 1
Training loss: 1.6958161058730261
Validation loss: 2.321484986523156

Epoch: 5| Step: 2
Training loss: 1.890262159098798
Validation loss: 2.3008028039100763

Epoch: 5| Step: 3
Training loss: 1.5628989663982447
Validation loss: 2.353388515507414

Epoch: 5| Step: 4
Training loss: 2.1512563627549035
Validation loss: 2.334085804235378

Epoch: 5| Step: 5
Training loss: 2.152695864141052
Validation loss: 2.36404359298897

Epoch: 5| Step: 6
Training loss: 1.8193612294018298
Validation loss: 2.3388826710075463

Epoch: 5| Step: 7
Training loss: 1.681897931234987
Validation loss: 2.335416277955595

Epoch: 5| Step: 8
Training loss: 2.1041725712557997
Validation loss: 2.341760689439601

Epoch: 5| Step: 9
Training loss: 1.3245033250956346
Validation loss: 2.3697186855115877

Epoch: 5| Step: 10
Training loss: 1.8391417765809233
Validation loss: 2.3516085969751668

Epoch: 271| Step: 0
Training loss: 1.3165006518827767
Validation loss: 2.382281834204135

Epoch: 5| Step: 1
Training loss: 1.8400272350783502
Validation loss: 2.3326376058676295

Epoch: 5| Step: 2
Training loss: 1.6347027656018862
Validation loss: 2.3262013985850376

Epoch: 5| Step: 3
Training loss: 2.0097079699729394
Validation loss: 2.326888447620492

Epoch: 5| Step: 4
Training loss: 1.8840786803717027
Validation loss: 2.276042904910623

Epoch: 5| Step: 5
Training loss: 1.6158557513083447
Validation loss: 2.277534545117393

Epoch: 5| Step: 6
Training loss: 1.4840712387075083
Validation loss: 2.327115387468632

Epoch: 5| Step: 7
Training loss: 2.070306741958384
Validation loss: 2.338639406637904

Epoch: 5| Step: 8
Training loss: 1.8196641807103593
Validation loss: 2.3425618223303704

Epoch: 5| Step: 9
Training loss: 2.239216820349556
Validation loss: 2.3106381282986916

Epoch: 5| Step: 10
Training loss: 1.8664645786679803
Validation loss: 2.300784172670339

Epoch: 272| Step: 0
Training loss: 2.0644667524828133
Validation loss: 2.2789812683633857

Epoch: 5| Step: 1
Training loss: 1.6826265393493742
Validation loss: 2.303460351083817

Epoch: 5| Step: 2
Training loss: 1.8092977583083456
Validation loss: 2.3261662091707898

Epoch: 5| Step: 3
Training loss: 1.879158367919642
Validation loss: 2.2850521372793295

Epoch: 5| Step: 4
Training loss: 1.97606064528094
Validation loss: 2.2621629083919426

Epoch: 5| Step: 5
Training loss: 1.226818179555498
Validation loss: 2.3109783175852905

Epoch: 5| Step: 6
Training loss: 1.607657024847914
Validation loss: 2.3363171461449914

Epoch: 5| Step: 7
Training loss: 1.769642201159981
Validation loss: 2.2877503406759105

Epoch: 5| Step: 8
Training loss: 2.1941147112559776
Validation loss: 2.3040459119600856

Epoch: 5| Step: 9
Training loss: 1.6542075176944033
Validation loss: 2.290119834528627

Epoch: 5| Step: 10
Training loss: 1.5637276213803342
Validation loss: 2.3499928026388033

Epoch: 273| Step: 0
Training loss: 1.7450574150586553
Validation loss: 2.33929139591033

Epoch: 5| Step: 1
Training loss: 1.8078901928665057
Validation loss: 2.303778976087185

Epoch: 5| Step: 2
Training loss: 1.7750582242200783
Validation loss: 2.3308196026833934

Epoch: 5| Step: 3
Training loss: 1.5373037910870766
Validation loss: 2.303018770678689

Epoch: 5| Step: 4
Training loss: 1.9995385472101244
Validation loss: 2.3403476792365074

Epoch: 5| Step: 5
Training loss: 1.6823365369861611
Validation loss: 2.3473618294290897

Epoch: 5| Step: 6
Training loss: 1.3525761678405326
Validation loss: 2.314821248399916

Epoch: 5| Step: 7
Training loss: 1.8625420277609257
Validation loss: 2.3709557841087805

Epoch: 5| Step: 8
Training loss: 1.6695312757050258
Validation loss: 2.323021591739963

Epoch: 5| Step: 9
Training loss: 2.267702925580267
Validation loss: 2.3115929085828744

Epoch: 5| Step: 10
Training loss: 1.6480201807638262
Validation loss: 2.36093020481014

Epoch: 274| Step: 0
Training loss: 1.7245571867324867
Validation loss: 2.3215659675249083

Epoch: 5| Step: 1
Training loss: 1.5365165139082682
Validation loss: 2.3073614477475095

Epoch: 5| Step: 2
Training loss: 2.100978160296176
Validation loss: 2.306085171709072

Epoch: 5| Step: 3
Training loss: 2.02715334429957
Validation loss: 2.285601852383094

Epoch: 5| Step: 4
Training loss: 1.8542167856822094
Validation loss: 2.3092471966508814

Epoch: 5| Step: 5
Training loss: 1.634338760703594
Validation loss: 2.317036224579167

Epoch: 5| Step: 6
Training loss: 1.594003545003321
Validation loss: 2.329678835300826

Epoch: 5| Step: 7
Training loss: 1.728887244325644
Validation loss: 2.3147173690748795

Epoch: 5| Step: 8
Training loss: 1.9085165838131188
Validation loss: 2.321082737433832

Epoch: 5| Step: 9
Training loss: 1.5910140845096734
Validation loss: 2.267307758407637

Epoch: 5| Step: 10
Training loss: 1.7150796019873114
Validation loss: 2.302571971793203

Epoch: 275| Step: 0
Training loss: 1.832884957652856
Validation loss: 2.3071618886806897

Epoch: 5| Step: 1
Training loss: 2.0779367232541968
Validation loss: 2.3526780005087207

Epoch: 5| Step: 2
Training loss: 1.9575706241188555
Validation loss: 2.2905339500308943

Epoch: 5| Step: 3
Training loss: 1.649159133390184
Validation loss: 2.2998540384570156

Epoch: 5| Step: 4
Training loss: 1.7714349809214225
Validation loss: 2.3126266741902537

Epoch: 5| Step: 5
Training loss: 1.618758539597068
Validation loss: 2.2979063991844235

Epoch: 5| Step: 6
Training loss: 2.2758527687534458
Validation loss: 2.3105061490316823

Epoch: 5| Step: 7
Training loss: 1.5993924209224346
Validation loss: 2.2927192314222786

Epoch: 5| Step: 8
Training loss: 1.5957107450380328
Validation loss: 2.2549647207451513

Epoch: 5| Step: 9
Training loss: 1.8356638603006585
Validation loss: 2.276276340909191

Epoch: 5| Step: 10
Training loss: 1.1236514379879585
Validation loss: 2.326000925315885

Epoch: 276| Step: 0
Training loss: 1.7109358278031213
Validation loss: 2.3633215991387457

Epoch: 5| Step: 1
Training loss: 1.7929293892057585
Validation loss: 2.3296045162525623

Epoch: 5| Step: 2
Training loss: 1.493757450611894
Validation loss: 2.340857542058492

Epoch: 5| Step: 3
Training loss: 1.3840713805247309
Validation loss: 2.361802274152762

Epoch: 5| Step: 4
Training loss: 1.485125622942726
Validation loss: 2.309976536232498

Epoch: 5| Step: 5
Training loss: 1.6856854891222457
Validation loss: 2.3917327283331073

Epoch: 5| Step: 6
Training loss: 2.1411546483496737
Validation loss: 2.364749094017545

Epoch: 5| Step: 7
Training loss: 1.818698347479022
Validation loss: 2.335618198702778

Epoch: 5| Step: 8
Training loss: 2.0798284676321144
Validation loss: 2.280749625859862

Epoch: 5| Step: 9
Training loss: 1.5657341102452855
Validation loss: 2.3293210029998153

Epoch: 5| Step: 10
Training loss: 2.457775882513654
Validation loss: 2.3157377549963503

Epoch: 277| Step: 0
Training loss: 1.4507040550717474
Validation loss: 2.3406999568973306

Epoch: 5| Step: 1
Training loss: 1.8274536856485057
Validation loss: 2.2979354971719363

Epoch: 5| Step: 2
Training loss: 1.7580505209944612
Validation loss: 2.28500551775399

Epoch: 5| Step: 3
Training loss: 1.5351494165321828
Validation loss: 2.3184295601376252

Epoch: 5| Step: 4
Training loss: 1.7768309807197222
Validation loss: 2.320261972699731

Epoch: 5| Step: 5
Training loss: 1.8014189610862894
Validation loss: 2.3097921035722933

Epoch: 5| Step: 6
Training loss: 1.7095711883155673
Validation loss: 2.290081763342235

Epoch: 5| Step: 7
Training loss: 2.2309158331410277
Validation loss: 2.2963095013415242

Epoch: 5| Step: 8
Training loss: 1.8687484154327718
Validation loss: 2.315959712585583

Epoch: 5| Step: 9
Training loss: 1.4564880503967366
Validation loss: 2.2949524876061087

Epoch: 5| Step: 10
Training loss: 1.8355802147778868
Validation loss: 2.279645093695923

Epoch: 278| Step: 0
Training loss: 1.9090303874846952
Validation loss: 2.3060941418790852

Epoch: 5| Step: 1
Training loss: 1.837112310603086
Validation loss: 2.300665383130689

Epoch: 5| Step: 2
Training loss: 1.5376097508158022
Validation loss: 2.330919283406176

Epoch: 5| Step: 3
Training loss: 2.3157545334060083
Validation loss: 2.2519303197335403

Epoch: 5| Step: 4
Training loss: 1.5014838191128193
Validation loss: 2.3219549766361376

Epoch: 5| Step: 5
Training loss: 1.7205728747879454
Validation loss: 2.313830666021547

Epoch: 5| Step: 6
Training loss: 1.556955111910668
Validation loss: 2.3340314869539394

Epoch: 5| Step: 7
Training loss: 1.751525486496326
Validation loss: 2.3312924273963254

Epoch: 5| Step: 8
Training loss: 1.3855253000141752
Validation loss: 2.3674074515693486

Epoch: 5| Step: 9
Training loss: 2.1128669374943234
Validation loss: 2.3378214819428087

Epoch: 5| Step: 10
Training loss: 1.458104124676018
Validation loss: 2.3247614842390667

Epoch: 279| Step: 0
Training loss: 1.7407390920069097
Validation loss: 2.3205242837191706

Epoch: 5| Step: 1
Training loss: 1.3503272525305474
Validation loss: 2.3091500975392285

Epoch: 5| Step: 2
Training loss: 1.6771148141627135
Validation loss: 2.2643687600293547

Epoch: 5| Step: 3
Training loss: 1.136025863212012
Validation loss: 2.272992434074908

Epoch: 5| Step: 4
Training loss: 1.4913971890173776
Validation loss: 2.322947876379049

Epoch: 5| Step: 5
Training loss: 1.939309720887105
Validation loss: 2.2990425925604114

Epoch: 5| Step: 6
Training loss: 1.4697909623037804
Validation loss: 2.2841829125598347

Epoch: 5| Step: 7
Training loss: 1.884188580504371
Validation loss: 2.3249885363190876

Epoch: 5| Step: 8
Training loss: 2.3860380759834334
Validation loss: 2.274228345978861

Epoch: 5| Step: 9
Training loss: 2.176699104047913
Validation loss: 2.303001463119201

Epoch: 5| Step: 10
Training loss: 1.5349955778027184
Validation loss: 2.2762247916134117

Epoch: 280| Step: 0
Training loss: 1.6332506385940946
Validation loss: 2.3089926536241316

Epoch: 5| Step: 1
Training loss: 1.6271673567499314
Validation loss: 2.3161187408447823

Epoch: 5| Step: 2
Training loss: 1.4300441609746346
Validation loss: 2.30490941946196

Epoch: 5| Step: 3
Training loss: 1.6742941208827846
Validation loss: 2.3168078371197502

Epoch: 5| Step: 4
Training loss: 2.2842951268793117
Validation loss: 2.3011664734130246

Epoch: 5| Step: 5
Training loss: 1.7982349722510225
Validation loss: 2.334237453836821

Epoch: 5| Step: 6
Training loss: 1.8174551611699143
Validation loss: 2.32596574058397

Epoch: 5| Step: 7
Training loss: 1.768741861061808
Validation loss: 2.3100073738292974

Epoch: 5| Step: 8
Training loss: 1.7903710123582486
Validation loss: 2.2842466030513293

Epoch: 5| Step: 9
Training loss: 1.3751026462041502
Validation loss: 2.332316881128416

Epoch: 5| Step: 10
Training loss: 1.8458093037415346
Validation loss: 2.3198242093566392

Epoch: 281| Step: 0
Training loss: 1.6343486805651104
Validation loss: 2.2989964053252616

Epoch: 5| Step: 1
Training loss: 1.6987425388961095
Validation loss: 2.342079708278708

Epoch: 5| Step: 2
Training loss: 1.1850925938931793
Validation loss: 2.346989810452702

Epoch: 5| Step: 3
Training loss: 1.6727366856170698
Validation loss: 2.354865654720838

Epoch: 5| Step: 4
Training loss: 2.097454949350971
Validation loss: 2.3184380557224182

Epoch: 5| Step: 5
Training loss: 2.4765201408542272
Validation loss: 2.3218115280994094

Epoch: 5| Step: 6
Training loss: 1.6929573541036764
Validation loss: 2.3498493490364627

Epoch: 5| Step: 7
Training loss: 1.6531473284477198
Validation loss: 2.3665265736704444

Epoch: 5| Step: 8
Training loss: 1.6309152924779395
Validation loss: 2.2666280283596474

Epoch: 5| Step: 9
Training loss: 1.7899269114655694
Validation loss: 2.266473438577613

Epoch: 5| Step: 10
Training loss: 1.3815430239737212
Validation loss: 2.2733738196138344

Epoch: 282| Step: 0
Training loss: 2.0940172394969205
Validation loss: 2.2920626688777612

Epoch: 5| Step: 1
Training loss: 1.7253547690640554
Validation loss: 2.293229920336598

Epoch: 5| Step: 2
Training loss: 1.7200626562593961
Validation loss: 2.2656175227849826

Epoch: 5| Step: 3
Training loss: 1.2485405030805534
Validation loss: 2.269311709141772

Epoch: 5| Step: 4
Training loss: 1.8451355076471214
Validation loss: 2.287880876135225

Epoch: 5| Step: 5
Training loss: 1.9214644575085187
Validation loss: 2.292228472878536

Epoch: 5| Step: 6
Training loss: 1.517237326749633
Validation loss: 2.3388490184169246

Epoch: 5| Step: 7
Training loss: 1.6254506586636213
Validation loss: 2.3276825070230664

Epoch: 5| Step: 8
Training loss: 1.7940243873342006
Validation loss: 2.350205604191982

Epoch: 5| Step: 9
Training loss: 1.7160544325280507
Validation loss: 2.3558715830660524

Epoch: 5| Step: 10
Training loss: 1.8160021917019025
Validation loss: 2.2879768363673034

Epoch: 283| Step: 0
Training loss: 1.7836043876768504
Validation loss: 2.299514179541287

Epoch: 5| Step: 1
Training loss: 1.9660053800895398
Validation loss: 2.3186725383831077

Epoch: 5| Step: 2
Training loss: 1.7382945542415729
Validation loss: 2.31692330888777

Epoch: 5| Step: 3
Training loss: 1.897565099632297
Validation loss: 2.301542009563547

Epoch: 5| Step: 4
Training loss: 1.4255661893669171
Validation loss: 2.3176059686929547

Epoch: 5| Step: 5
Training loss: 1.7561521020938011
Validation loss: 2.3137531820451875

Epoch: 5| Step: 6
Training loss: 2.005686068082124
Validation loss: 2.3303654262052613

Epoch: 5| Step: 7
Training loss: 1.632717367074804
Validation loss: 2.2917691749474844

Epoch: 5| Step: 8
Training loss: 1.5288669961247772
Validation loss: 2.322966389450621

Epoch: 5| Step: 9
Training loss: 1.3749837007423502
Validation loss: 2.2860472310938116

Epoch: 5| Step: 10
Training loss: 2.015512980815599
Validation loss: 2.319770728470236

Epoch: 284| Step: 0
Training loss: 1.4694899460434656
Validation loss: 2.322625947169213

Epoch: 5| Step: 1
Training loss: 2.0470601937184316
Validation loss: 2.314354066540546

Epoch: 5| Step: 2
Training loss: 1.4353606018869756
Validation loss: 2.291157198420726

Epoch: 5| Step: 3
Training loss: 1.7575777024175632
Validation loss: 2.309762409089254

Epoch: 5| Step: 4
Training loss: 1.6758872401013214
Validation loss: 2.2618869335913137

Epoch: 5| Step: 5
Training loss: 1.3832590707508754
Validation loss: 2.317137620120324

Epoch: 5| Step: 6
Training loss: 2.399182728851318
Validation loss: 2.311221875082876

Epoch: 5| Step: 7
Training loss: 1.7379941553208524
Validation loss: 2.2863831160244676

Epoch: 5| Step: 8
Training loss: 1.7480693794378899
Validation loss: 2.3175395605938176

Epoch: 5| Step: 9
Training loss: 1.538611486353433
Validation loss: 2.33402843347087

Epoch: 5| Step: 10
Training loss: 1.6855334373106445
Validation loss: 2.272411376901168

Epoch: 285| Step: 0
Training loss: 1.776499990203969
Validation loss: 2.281240421375635

Epoch: 5| Step: 1
Training loss: 1.756548889357169
Validation loss: 2.3271258497089304

Epoch: 5| Step: 2
Training loss: 1.6988492015760064
Validation loss: 2.2815107656452867

Epoch: 5| Step: 3
Training loss: 1.904320537713561
Validation loss: 2.2932265341636073

Epoch: 5| Step: 4
Training loss: 1.6252525573485024
Validation loss: 2.3214052660715545

Epoch: 5| Step: 5
Training loss: 1.6197947249634095
Validation loss: 2.3108245436171133

Epoch: 5| Step: 6
Training loss: 1.435797138846459
Validation loss: 2.2912931945251342

Epoch: 5| Step: 7
Training loss: 1.8050890719344537
Validation loss: 2.3315849155337256

Epoch: 5| Step: 8
Training loss: 1.7044685034288278
Validation loss: 2.299375709530215

Epoch: 5| Step: 9
Training loss: 1.2340592089039437
Validation loss: 2.2731301135429205

Epoch: 5| Step: 10
Training loss: 1.9497202379107559
Validation loss: 2.2779355798162424

Epoch: 286| Step: 0
Training loss: 1.358104726163442
Validation loss: 2.317243489660995

Epoch: 5| Step: 1
Training loss: 1.9281963811239995
Validation loss: 2.300595549753565

Epoch: 5| Step: 2
Training loss: 1.565352925246768
Validation loss: 2.2845471949250635

Epoch: 5| Step: 3
Training loss: 1.5285385414782395
Validation loss: 2.29909309334102

Epoch: 5| Step: 4
Training loss: 2.135535322164711
Validation loss: 2.3020648464636753

Epoch: 5| Step: 5
Training loss: 1.6349033675962514
Validation loss: 2.323954031954502

Epoch: 5| Step: 6
Training loss: 1.9335365364010209
Validation loss: 2.293947790147653

Epoch: 5| Step: 7
Training loss: 1.9374406251731089
Validation loss: 2.28716377541155

Epoch: 5| Step: 8
Training loss: 1.895956105319675
Validation loss: 2.252298345699984

Epoch: 5| Step: 9
Training loss: 1.1674091950745065
Validation loss: 2.305572772448767

Epoch: 5| Step: 10
Training loss: 1.5187108980647483
Validation loss: 2.297775646697668

Epoch: 287| Step: 0
Training loss: 1.6849146217426734
Validation loss: 2.2927584798302365

Epoch: 5| Step: 1
Training loss: 1.98373607051312
Validation loss: 2.3293154967131153

Epoch: 5| Step: 2
Training loss: 1.6864749479584784
Validation loss: 2.330412270845558

Epoch: 5| Step: 3
Training loss: 1.084678413970707
Validation loss: 2.2896922688991754

Epoch: 5| Step: 4
Training loss: 1.7162658772911483
Validation loss: 2.3034894328905513

Epoch: 5| Step: 5
Training loss: 2.000467841742513
Validation loss: 2.3261657363748474

Epoch: 5| Step: 6
Training loss: 2.0911204208660457
Validation loss: 2.3373062470252104

Epoch: 5| Step: 7
Training loss: 1.8197532744380158
Validation loss: 2.2719024210594716

Epoch: 5| Step: 8
Training loss: 1.8337556901569143
Validation loss: 2.270660206010253

Epoch: 5| Step: 9
Training loss: 1.6090042279734993
Validation loss: 2.2989767538847485

Epoch: 5| Step: 10
Training loss: 1.3330590095050447
Validation loss: 2.3346997384363593

Epoch: 288| Step: 0
Training loss: 1.29351900959534
Validation loss: 2.306386777179645

Epoch: 5| Step: 1
Training loss: 2.2339155885258815
Validation loss: 2.2842202375121183

Epoch: 5| Step: 2
Training loss: 1.935152169486261
Validation loss: 2.2659981708464016

Epoch: 5| Step: 3
Training loss: 1.486281365399701
Validation loss: 2.348521012611257

Epoch: 5| Step: 4
Training loss: 1.30650353959922
Validation loss: 2.3218062060644917

Epoch: 5| Step: 5
Training loss: 1.8719977184183938
Validation loss: 2.2846396785883956

Epoch: 5| Step: 6
Training loss: 2.3183987621377784
Validation loss: 2.2930550569233086

Epoch: 5| Step: 7
Training loss: 1.346041831921003
Validation loss: 2.3210044998172195

Epoch: 5| Step: 8
Training loss: 1.515866604454363
Validation loss: 2.3102680600090926

Epoch: 5| Step: 9
Training loss: 1.402850046384064
Validation loss: 2.31921891616395

Epoch: 5| Step: 10
Training loss: 1.8280126423012528
Validation loss: 2.3209226012029487

Epoch: 289| Step: 0
Training loss: 1.8033177846260577
Validation loss: 2.278627431956349

Epoch: 5| Step: 1
Training loss: 1.314583215043455
Validation loss: 2.301217176014759

Epoch: 5| Step: 2
Training loss: 2.0726849475977507
Validation loss: 2.290851710628195

Epoch: 5| Step: 3
Training loss: 1.5942234009403178
Validation loss: 2.331084845943274

Epoch: 5| Step: 4
Training loss: 1.412921339676214
Validation loss: 2.3009126489435037

Epoch: 5| Step: 5
Training loss: 1.6596225733439391
Validation loss: 2.278685028629752

Epoch: 5| Step: 6
Training loss: 1.6455141876731103
Validation loss: 2.283954422610878

Epoch: 5| Step: 7
Training loss: 2.0286745617015365
Validation loss: 2.290387104224074

Epoch: 5| Step: 8
Training loss: 1.8044548380108199
Validation loss: 2.3298955377410633

Epoch: 5| Step: 9
Training loss: 1.149348202798014
Validation loss: 2.2831775030817125

Epoch: 5| Step: 10
Training loss: 1.9146473516554352
Validation loss: 2.3217301813409583

Epoch: 290| Step: 0
Training loss: 1.6800783634074756
Validation loss: 2.3389109018934024

Epoch: 5| Step: 1
Training loss: 1.2510263997379059
Validation loss: 2.272585899168762

Epoch: 5| Step: 2
Training loss: 1.5158542577646048
Validation loss: 2.2897076079731375

Epoch: 5| Step: 3
Training loss: 1.8136629780163536
Validation loss: 2.2808293488419094

Epoch: 5| Step: 4
Training loss: 1.7788197854480825
Validation loss: 2.295986689351904

Epoch: 5| Step: 5
Training loss: 1.521354229004295
Validation loss: 2.3321270985428435

Epoch: 5| Step: 6
Training loss: 1.6116652997131757
Validation loss: 2.3110140721665857

Epoch: 5| Step: 7
Training loss: 1.4028177974309428
Validation loss: 2.2994303136440357

Epoch: 5| Step: 8
Training loss: 2.1901903230017385
Validation loss: 2.2979163774638125

Epoch: 5| Step: 9
Training loss: 1.8680293527661767
Validation loss: 2.2549315168559505

Epoch: 5| Step: 10
Training loss: 1.7054456946037395
Validation loss: 2.343847207955569

Epoch: 291| Step: 0
Training loss: 1.7968684984172458
Validation loss: 2.32849660890286

Epoch: 5| Step: 1
Training loss: 1.3316910384760414
Validation loss: 2.3271509888578596

Epoch: 5| Step: 2
Training loss: 2.4446397532360074
Validation loss: 2.297975640455052

Epoch: 5| Step: 3
Training loss: 1.3180551587662381
Validation loss: 2.3057540236182263

Epoch: 5| Step: 4
Training loss: 1.0788484992965923
Validation loss: 2.3088661484134363

Epoch: 5| Step: 5
Training loss: 1.8764664954943289
Validation loss: 2.355662741056961

Epoch: 5| Step: 6
Training loss: 1.8398256078258923
Validation loss: 2.255479314685214

Epoch: 5| Step: 7
Training loss: 1.8517501027800032
Validation loss: 2.3345824648681024

Epoch: 5| Step: 8
Training loss: 1.928599742146702
Validation loss: 2.287832656952346

Epoch: 5| Step: 9
Training loss: 1.3088860939626064
Validation loss: 2.3377319318264527

Epoch: 5| Step: 10
Training loss: 1.3454302551270105
Validation loss: 2.319056914544173

Epoch: 292| Step: 0
Training loss: 1.6573363286331702
Validation loss: 2.3045623072316546

Epoch: 5| Step: 1
Training loss: 2.0682633533468624
Validation loss: 2.304666373974843

Epoch: 5| Step: 2
Training loss: 1.550483809612025
Validation loss: 2.2524530672468495

Epoch: 5| Step: 3
Training loss: 1.9724071383162771
Validation loss: 2.2766978895998453

Epoch: 5| Step: 4
Training loss: 1.2882966974649737
Validation loss: 2.347567636895271

Epoch: 5| Step: 5
Training loss: 1.5176769406072643
Validation loss: 2.2869236631647505

Epoch: 5| Step: 6
Training loss: 1.7733596583016233
Validation loss: 2.370113020975045

Epoch: 5| Step: 7
Training loss: 1.5772114744078114
Validation loss: 2.2985483324208937

Epoch: 5| Step: 8
Training loss: 1.5201498699338616
Validation loss: 2.294246032661997

Epoch: 5| Step: 9
Training loss: 1.6642560532883701
Validation loss: 2.2526134776479516

Epoch: 5| Step: 10
Training loss: 1.8714857228432906
Validation loss: 2.2721497102478176

Epoch: 293| Step: 0
Training loss: 1.3018885759295002
Validation loss: 2.2689960321586313

Epoch: 5| Step: 1
Training loss: 1.3143876896933582
Validation loss: 2.293409418077406

Epoch: 5| Step: 2
Training loss: 1.7366921007974938
Validation loss: 2.3070740348635366

Epoch: 5| Step: 3
Training loss: 1.8933076348150155
Validation loss: 2.348175774853973

Epoch: 5| Step: 4
Training loss: 1.640907626558456
Validation loss: 2.2932228970125026

Epoch: 5| Step: 5
Training loss: 1.5137378702851108
Validation loss: 2.313084121449597

Epoch: 5| Step: 6
Training loss: 1.5958306437868939
Validation loss: 2.293411621597691

Epoch: 5| Step: 7
Training loss: 1.8578463128608602
Validation loss: 2.336112587315686

Epoch: 5| Step: 8
Training loss: 1.6902262952632168
Validation loss: 2.3168489795729186

Epoch: 5| Step: 9
Training loss: 2.2931303263051603
Validation loss: 2.3053046355301796

Epoch: 5| Step: 10
Training loss: 1.3111091237717634
Validation loss: 2.3227406898683407

Epoch: 294| Step: 0
Training loss: 1.6550088226451989
Validation loss: 2.309731701968467

Epoch: 5| Step: 1
Training loss: 1.600988219971359
Validation loss: 2.2854108737457057

Epoch: 5| Step: 2
Training loss: 1.6850463548391015
Validation loss: 2.2797374658549554

Epoch: 5| Step: 3
Training loss: 1.9282976465816308
Validation loss: 2.275662447727973

Epoch: 5| Step: 4
Training loss: 1.5504775818966592
Validation loss: 2.262595676852739

Epoch: 5| Step: 5
Training loss: 1.6940144434496682
Validation loss: 2.29631704105627

Epoch: 5| Step: 6
Training loss: 1.1114623620562962
Validation loss: 2.273403311665723

Epoch: 5| Step: 7
Training loss: 1.6264989981591054
Validation loss: 2.3139610298026168

Epoch: 5| Step: 8
Training loss: 2.113624756371928
Validation loss: 2.2996294823523575

Epoch: 5| Step: 9
Training loss: 1.8826133021166074
Validation loss: 2.2969568782228804

Epoch: 5| Step: 10
Training loss: 1.8628494754085165
Validation loss: 2.351943736593908

Epoch: 295| Step: 0
Training loss: 1.93398501358222
Validation loss: 2.3046598137662433

Epoch: 5| Step: 1
Training loss: 1.4099919865427846
Validation loss: 2.304050477236781

Epoch: 5| Step: 2
Training loss: 1.7237233427225798
Validation loss: 2.3214240167305595

Epoch: 5| Step: 3
Training loss: 1.8835284506175871
Validation loss: 2.2975809417243718

Epoch: 5| Step: 4
Training loss: 1.403927856686625
Validation loss: 2.3225580186258736

Epoch: 5| Step: 5
Training loss: 1.6113474341882825
Validation loss: 2.332892955000942

Epoch: 5| Step: 6
Training loss: 1.5273805111414835
Validation loss: 2.327595265287346

Epoch: 5| Step: 7
Training loss: 1.868180015164834
Validation loss: 2.332450032230005

Epoch: 5| Step: 8
Training loss: 1.6676734823778587
Validation loss: 2.303161308200625

Epoch: 5| Step: 9
Training loss: 1.979749560267817
Validation loss: 2.297797132851289

Epoch: 5| Step: 10
Training loss: 1.0770755027225638
Validation loss: 2.3326794653781553

Epoch: 296| Step: 0
Training loss: 1.7494300867956443
Validation loss: 2.331041085416764

Epoch: 5| Step: 1
Training loss: 1.3539157732822888
Validation loss: 2.2953763672242764

Epoch: 5| Step: 2
Training loss: 1.5298769497475992
Validation loss: 2.3019383450294604

Epoch: 5| Step: 3
Training loss: 2.0441523491282476
Validation loss: 2.2826024495386292

Epoch: 5| Step: 4
Training loss: 0.9772801623253135
Validation loss: 2.253468037514123

Epoch: 5| Step: 5
Training loss: 1.8844631446479332
Validation loss: 2.2937977837072268

Epoch: 5| Step: 6
Training loss: 1.7176589277051044
Validation loss: 2.2652528043378304

Epoch: 5| Step: 7
Training loss: 1.8780648931193336
Validation loss: 2.3080153943513086

Epoch: 5| Step: 8
Training loss: 1.7353631031552101
Validation loss: 2.323421009291885

Epoch: 5| Step: 9
Training loss: 1.6797099267216486
Validation loss: 2.2918260408918836

Epoch: 5| Step: 10
Training loss: 1.352898086656803
Validation loss: 2.2639814367938125

Epoch: 297| Step: 0
Training loss: 1.7574393321346922
Validation loss: 2.3178894787014217

Epoch: 5| Step: 1
Training loss: 1.5312152780761172
Validation loss: 2.28715022502929

Epoch: 5| Step: 2
Training loss: 1.8849866035855591
Validation loss: 2.3209113300590722

Epoch: 5| Step: 3
Training loss: 1.896368586956775
Validation loss: 2.305249197483494

Epoch: 5| Step: 4
Training loss: 1.2994277373121426
Validation loss: 2.315422887629476

Epoch: 5| Step: 5
Training loss: 1.807531782427483
Validation loss: 2.3106465182819833

Epoch: 5| Step: 6
Training loss: 1.3350092468227226
Validation loss: 2.242071231541417

Epoch: 5| Step: 7
Training loss: 1.7681508185024335
Validation loss: 2.292184255177305

Epoch: 5| Step: 8
Training loss: 1.4239203026843203
Validation loss: 2.342544863837022

Epoch: 5| Step: 9
Training loss: 1.5274954718040366
Validation loss: 2.300790077054791

Epoch: 5| Step: 10
Training loss: 1.953659411750726
Validation loss: 2.3361612618086887

Epoch: 298| Step: 0
Training loss: 1.717549338152662
Validation loss: 2.308219040153924

Epoch: 5| Step: 1
Training loss: 1.7798039774167729
Validation loss: 2.269558555423659

Epoch: 5| Step: 2
Training loss: 1.3393882221774394
Validation loss: 2.328178337429331

Epoch: 5| Step: 3
Training loss: 1.1519986427915048
Validation loss: 2.2844329668167984

Epoch: 5| Step: 4
Training loss: 1.7472372044640447
Validation loss: 2.3214128142819046

Epoch: 5| Step: 5
Training loss: 1.858274631114781
Validation loss: 2.293051765522422

Epoch: 5| Step: 6
Training loss: 2.2282344496972
Validation loss: 2.312654461811339

Epoch: 5| Step: 7
Training loss: 1.3160568815101337
Validation loss: 2.2696201650935097

Epoch: 5| Step: 8
Training loss: 1.3694269640006567
Validation loss: 2.2986385530654285

Epoch: 5| Step: 9
Training loss: 1.3987850417996814
Validation loss: 2.322111035213489

Epoch: 5| Step: 10
Training loss: 1.7182408358927437
Validation loss: 2.2580030482725824

Epoch: 299| Step: 0
Training loss: 1.348748778730658
Validation loss: 2.311215897518628

Epoch: 5| Step: 1
Training loss: 1.91917651775889
Validation loss: 2.3181745619981373

Epoch: 5| Step: 2
Training loss: 2.3073020458346782
Validation loss: 2.3183240411193466

Epoch: 5| Step: 3
Training loss: 1.2809196139238792
Validation loss: 2.2673652333263448

Epoch: 5| Step: 4
Training loss: 1.1389448777576168
Validation loss: 2.310676370043743

Epoch: 5| Step: 5
Training loss: 1.6053260312838415
Validation loss: 2.2611694955523767

Epoch: 5| Step: 6
Training loss: 1.2141607885451884
Validation loss: 2.3173994462482295

Epoch: 5| Step: 7
Training loss: 1.6667916568936365
Validation loss: 2.297671130619834

Epoch: 5| Step: 8
Training loss: 1.6030536687794275
Validation loss: 2.299428799605924

Epoch: 5| Step: 9
Training loss: 1.6762821898189382
Validation loss: 2.317910039590315

Epoch: 5| Step: 10
Training loss: 1.8378657826803062
Validation loss: 2.337595712525972

Epoch: 300| Step: 0
Training loss: 1.672250366854189
Validation loss: 2.3215788444067034

Epoch: 5| Step: 1
Training loss: 1.4161291879300237
Validation loss: 2.3007685141114558

Epoch: 5| Step: 2
Training loss: 1.286729863760965
Validation loss: 2.300034422257956

Epoch: 5| Step: 3
Training loss: 1.796518837833988
Validation loss: 2.296657250296633

Epoch: 5| Step: 4
Training loss: 1.7437164713599702
Validation loss: 2.3040552405587325

Epoch: 5| Step: 5
Training loss: 1.5892538339959572
Validation loss: 2.318731848015459

Epoch: 5| Step: 6
Training loss: 1.4453753483484924
Validation loss: 2.267989380421535

Epoch: 5| Step: 7
Training loss: 1.6994515095162384
Validation loss: 2.2862403768174766

Epoch: 5| Step: 8
Training loss: 1.6742609414797907
Validation loss: 2.2876604918792034

Epoch: 5| Step: 9
Training loss: 1.3595848360013398
Validation loss: 2.2851881601527992

Epoch: 5| Step: 10
Training loss: 2.0898948591881212
Validation loss: 2.315665773398073

Epoch: 301| Step: 0
Training loss: 2.0018320037673925
Validation loss: 2.339162401072799

Epoch: 5| Step: 1
Training loss: 1.608011279038115
Validation loss: 2.2857536915526078

Epoch: 5| Step: 2
Training loss: 1.682011331953234
Validation loss: 2.3398391307515616

Epoch: 5| Step: 3
Training loss: 1.2873379355344552
Validation loss: 2.302342407841264

Epoch: 5| Step: 4
Training loss: 1.371374726373765
Validation loss: 2.278530083360607

Epoch: 5| Step: 5
Training loss: 1.6283546446879908
Validation loss: 2.3217569247666523

Epoch: 5| Step: 6
Training loss: 2.213275226190289
Validation loss: 2.293571111720014

Epoch: 5| Step: 7
Training loss: 1.6256458759544061
Validation loss: 2.299789073549618

Epoch: 5| Step: 8
Training loss: 1.6122607682067087
Validation loss: 2.2937397433580258

Epoch: 5| Step: 9
Training loss: 1.515443299403602
Validation loss: 2.3461596696389777

Epoch: 5| Step: 10
Training loss: 1.4253363764426776
Validation loss: 2.2661024869814237

Epoch: 302| Step: 0
Training loss: 1.2243043072374922
Validation loss: 2.3485709330364473

Epoch: 5| Step: 1
Training loss: 1.1795326788152443
Validation loss: 2.26337745651163

Epoch: 5| Step: 2
Training loss: 1.4309153469592721
Validation loss: 2.303197435688184

Epoch: 5| Step: 3
Training loss: 2.130263821377398
Validation loss: 2.3321034410029133

Epoch: 5| Step: 4
Training loss: 1.6027028559747314
Validation loss: 2.3169298365861906

Epoch: 5| Step: 5
Training loss: 1.5468468711684515
Validation loss: 2.2809919744333493

Epoch: 5| Step: 6
Training loss: 1.6839203484560836
Validation loss: 2.3227799055874607

Epoch: 5| Step: 7
Training loss: 1.3404572975531206
Validation loss: 2.3218659457584447

Epoch: 5| Step: 8
Training loss: 1.8654198359613832
Validation loss: 2.299572924763877

Epoch: 5| Step: 9
Training loss: 1.8484932614555252
Validation loss: 2.347003173190066

Epoch: 5| Step: 10
Training loss: 1.5255150347393567
Validation loss: 2.239488988226052

Epoch: 303| Step: 0
Training loss: 1.6878581196878026
Validation loss: 2.263388384403958

Epoch: 5| Step: 1
Training loss: 1.5912430437509817
Validation loss: 2.3042764243208733

Epoch: 5| Step: 2
Training loss: 1.4928484346705513
Validation loss: 2.2561871005794774

Epoch: 5| Step: 3
Training loss: 1.3361757746351117
Validation loss: 2.343706807931498

Epoch: 5| Step: 4
Training loss: 1.6652459606149725
Validation loss: 2.329590453409563

Epoch: 5| Step: 5
Training loss: 1.7726841473391184
Validation loss: 2.306589739302306

Epoch: 5| Step: 6
Training loss: 1.6668801965621771
Validation loss: 2.266610605795544

Epoch: 5| Step: 7
Training loss: 2.209534971928549
Validation loss: 2.347573424706623

Epoch: 5| Step: 8
Training loss: 1.270507531015774
Validation loss: 2.305178398631659

Epoch: 5| Step: 9
Training loss: 1.5749519098599747
Validation loss: 2.310983690070645

Epoch: 5| Step: 10
Training loss: 1.1742128576358
Validation loss: 2.3202852051633074

Epoch: 304| Step: 0
Training loss: 1.2583742960310906
Validation loss: 2.3100705631755876

Epoch: 5| Step: 1
Training loss: 1.14968606976241
Validation loss: 2.3385054870111848

Epoch: 5| Step: 2
Training loss: 1.7211808787355352
Validation loss: 2.289371250565601

Epoch: 5| Step: 3
Training loss: 1.8625699970993972
Validation loss: 2.2776372078778517

Epoch: 5| Step: 4
Training loss: 1.6051335414103396
Validation loss: 2.314555641632541

Epoch: 5| Step: 5
Training loss: 1.1886681783858732
Validation loss: 2.3402113027223663

Epoch: 5| Step: 6
Training loss: 2.2454628232410934
Validation loss: 2.3098315291402156

Epoch: 5| Step: 7
Training loss: 1.605579233196626
Validation loss: 2.2632283604927355

Epoch: 5| Step: 8
Training loss: 1.3601621343933463
Validation loss: 2.328642750212087

Epoch: 5| Step: 9
Training loss: 1.6051633224101272
Validation loss: 2.3306922134675374

Epoch: 5| Step: 10
Training loss: 1.8922788464069464
Validation loss: 2.2278625642084546

Epoch: 305| Step: 0
Training loss: 1.0706194694986373
Validation loss: 2.3104022709839738

Epoch: 5| Step: 1
Training loss: 1.4560957863813189
Validation loss: 2.25632788531354

Epoch: 5| Step: 2
Training loss: 1.1642625368019555
Validation loss: 2.288356002387502

Epoch: 5| Step: 3
Training loss: 2.0248534208393973
Validation loss: 2.2764083507983353

Epoch: 5| Step: 4
Training loss: 1.6922572155907245
Validation loss: 2.319609899327981

Epoch: 5| Step: 5
Training loss: 1.3077581670087137
Validation loss: 2.2903502575422348

Epoch: 5| Step: 6
Training loss: 1.8931271098324445
Validation loss: 2.2906727530721978

Epoch: 5| Step: 7
Training loss: 1.8374404923541074
Validation loss: 2.3178543212602873

Epoch: 5| Step: 8
Training loss: 1.6970487221156543
Validation loss: 2.2788336128644144

Epoch: 5| Step: 9
Training loss: 1.6532428000002188
Validation loss: 2.3068664611940557

Epoch: 5| Step: 10
Training loss: 1.675418627792434
Validation loss: 2.3272894134549205

Epoch: 306| Step: 0
Training loss: 1.1723272849534232
Validation loss: 2.2962160831879497

Epoch: 5| Step: 1
Training loss: 1.9589782288779147
Validation loss: 2.282971830144148

Epoch: 5| Step: 2
Training loss: 1.472308049409276
Validation loss: 2.2665095338458445

Epoch: 5| Step: 3
Training loss: 1.5480114393969788
Validation loss: 2.2817221577290745

Epoch: 5| Step: 4
Training loss: 1.7416056529526793
Validation loss: 2.3031854617100103

Epoch: 5| Step: 5
Training loss: 2.0533698320654095
Validation loss: 2.3371065617729654

Epoch: 5| Step: 6
Training loss: 1.3495617649717833
Validation loss: 2.287461738551101

Epoch: 5| Step: 7
Training loss: 1.8992779288257637
Validation loss: 2.2823330719662027

Epoch: 5| Step: 8
Training loss: 1.6478893941687405
Validation loss: 2.3324315043039023

Epoch: 5| Step: 9
Training loss: 1.3367762470197668
Validation loss: 2.314552943476525

Epoch: 5| Step: 10
Training loss: 1.229170001828254
Validation loss: 2.3636793383872927

Epoch: 307| Step: 0
Training loss: 1.4109488502628884
Validation loss: 2.3161602458563872

Epoch: 5| Step: 1
Training loss: 1.5602003340588864
Validation loss: 2.350193682639452

Epoch: 5| Step: 2
Training loss: 1.3715617802049405
Validation loss: 2.2944313685852293

Epoch: 5| Step: 3
Training loss: 1.1875225868084776
Validation loss: 2.3203438228159814

Epoch: 5| Step: 4
Training loss: 1.5934942451662797
Validation loss: 2.317176561139823

Epoch: 5| Step: 5
Training loss: 1.6194563719999242
Validation loss: 2.3043913069535815

Epoch: 5| Step: 6
Training loss: 1.7948090327908488
Validation loss: 2.2913598363267913

Epoch: 5| Step: 7
Training loss: 1.9606119318761581
Validation loss: 2.2539909532987474

Epoch: 5| Step: 8
Training loss: 1.7604441969786089
Validation loss: 2.289477757417782

Epoch: 5| Step: 9
Training loss: 1.4246631157175835
Validation loss: 2.28764862988894

Epoch: 5| Step: 10
Training loss: 1.633296985935426
Validation loss: 2.2723042754526963

Epoch: 308| Step: 0
Training loss: 1.283609682937338
Validation loss: 2.2582566660768495

Epoch: 5| Step: 1
Training loss: 1.3342089261556538
Validation loss: 2.2911610643147506

Epoch: 5| Step: 2
Training loss: 1.6743332802764097
Validation loss: 2.303335959766011

Epoch: 5| Step: 3
Training loss: 2.035840174002078
Validation loss: 2.280589200301419

Epoch: 5| Step: 4
Training loss: 1.6348171066509203
Validation loss: 2.3275474145153074

Epoch: 5| Step: 5
Training loss: 1.5676073905747245
Validation loss: 2.3187195794499513

Epoch: 5| Step: 6
Training loss: 1.702316372193012
Validation loss: 2.2971628452528834

Epoch: 5| Step: 7
Training loss: 1.6388326390988892
Validation loss: 2.268768574366216

Epoch: 5| Step: 8
Training loss: 1.3207666643005909
Validation loss: 2.287150676747355

Epoch: 5| Step: 9
Training loss: 1.587750906152216
Validation loss: 2.2971288504338467

Epoch: 5| Step: 10
Training loss: 1.4680721260770881
Validation loss: 2.3405419843364164

Epoch: 309| Step: 0
Training loss: 1.2812608857971723
Validation loss: 2.3101624289909295

Epoch: 5| Step: 1
Training loss: 1.773725175421718
Validation loss: 2.2175731030483714

Epoch: 5| Step: 2
Training loss: 1.7889087727562472
Validation loss: 2.2444491604180414

Epoch: 5| Step: 3
Training loss: 1.5906223199668146
Validation loss: 2.2983324846789657

Epoch: 5| Step: 4
Training loss: 1.1423998049618316
Validation loss: 2.253806994738998

Epoch: 5| Step: 5
Training loss: 1.2848561409008672
Validation loss: 2.335439020474167

Epoch: 5| Step: 6
Training loss: 1.0915260593240979
Validation loss: 2.2896156366495415

Epoch: 5| Step: 7
Training loss: 2.2947915937089207
Validation loss: 2.242965353794897

Epoch: 5| Step: 8
Training loss: 1.614748825287794
Validation loss: 2.314787136359047

Epoch: 5| Step: 9
Training loss: 1.627722953022118
Validation loss: 2.292527040826274

Epoch: 5| Step: 10
Training loss: 1.6298148642170758
Validation loss: 2.32891059763875

Epoch: 310| Step: 0
Training loss: 2.0689533882772153
Validation loss: 2.278425335928761

Epoch: 5| Step: 1
Training loss: 1.6980020310487496
Validation loss: 2.2963336705417174

Epoch: 5| Step: 2
Training loss: 1.0768070181334501
Validation loss: 2.326050046711308

Epoch: 5| Step: 3
Training loss: 1.6820430827843054
Validation loss: 2.3040898208014333

Epoch: 5| Step: 4
Training loss: 1.5460131777933346
Validation loss: 2.31705580168603

Epoch: 5| Step: 5
Training loss: 1.2172036753841875
Validation loss: 2.2693989790208104

Epoch: 5| Step: 6
Training loss: 1.2631548099312844
Validation loss: 2.281477278107083

Epoch: 5| Step: 7
Training loss: 1.7079230102634682
Validation loss: 2.283935712298462

Epoch: 5| Step: 8
Training loss: 1.787725557087891
Validation loss: 2.320013210439712

Epoch: 5| Step: 9
Training loss: 1.6779227278721267
Validation loss: 2.2297382647352912

Epoch: 5| Step: 10
Training loss: 1.6357588035536659
Validation loss: 2.2804910720927536

Epoch: 311| Step: 0
Training loss: 1.3263657530696944
Validation loss: 2.297108606866587

Epoch: 5| Step: 1
Training loss: 1.8783003054030583
Validation loss: 2.300951260117653

Epoch: 5| Step: 2
Training loss: 2.018317501637082
Validation loss: 2.2645592728584436

Epoch: 5| Step: 3
Training loss: 0.9751587506191745
Validation loss: 2.2957808792211187

Epoch: 5| Step: 4
Training loss: 1.7067236022964059
Validation loss: 2.2838947643644874

Epoch: 5| Step: 5
Training loss: 1.4136231303606177
Validation loss: 2.2236839819351473

Epoch: 5| Step: 6
Training loss: 1.5281108676124289
Validation loss: 2.259516717796678

Epoch: 5| Step: 7
Training loss: 1.295678103472461
Validation loss: 2.268286801709076

Epoch: 5| Step: 8
Training loss: 1.6651400090825432
Validation loss: 2.302555692430595

Epoch: 5| Step: 9
Training loss: 1.677396125135657
Validation loss: 2.3253002672370218

Epoch: 5| Step: 10
Training loss: 1.4622319652418938
Validation loss: 2.2815747751191995

Epoch: 312| Step: 0
Training loss: 1.2420433968504196
Validation loss: 2.3436492241964246

Epoch: 5| Step: 1
Training loss: 1.4109485123078906
Validation loss: 2.3212093618261167

Epoch: 5| Step: 2
Training loss: 1.4259399325759474
Validation loss: 2.325605701070666

Epoch: 5| Step: 3
Training loss: 1.6312964304896942
Validation loss: 2.2759771544637077

Epoch: 5| Step: 4
Training loss: 1.8091153078712456
Validation loss: 2.262428085887522

Epoch: 5| Step: 5
Training loss: 1.43827715888159
Validation loss: 2.255905336848365

Epoch: 5| Step: 6
Training loss: 1.3490060432078153
Validation loss: 2.26847597234183

Epoch: 5| Step: 7
Training loss: 1.3623518084508563
Validation loss: 2.3131675953864095

Epoch: 5| Step: 8
Training loss: 1.9563687053898693
Validation loss: 2.320981620277837

Epoch: 5| Step: 9
Training loss: 1.9278310270342098
Validation loss: 2.28139914422494

Epoch: 5| Step: 10
Training loss: 1.4582175163419313
Validation loss: 2.3093622527359803

Epoch: 313| Step: 0
Training loss: 1.9551254403927383
Validation loss: 2.2564105452186975

Epoch: 5| Step: 1
Training loss: 1.440281292011744
Validation loss: 2.255952756316495

Epoch: 5| Step: 2
Training loss: 1.7006106934651886
Validation loss: 2.2472012476390093

Epoch: 5| Step: 3
Training loss: 1.418794417841308
Validation loss: 2.2548926957981834

Epoch: 5| Step: 4
Training loss: 1.5401468088101173
Validation loss: 2.2909285989156656

Epoch: 5| Step: 5
Training loss: 1.516297260123403
Validation loss: 2.2814405381097416

Epoch: 5| Step: 6
Training loss: 1.2414435792163503
Validation loss: 2.3083992772693045

Epoch: 5| Step: 7
Training loss: 1.7365145159509252
Validation loss: 2.3177716620654762

Epoch: 5| Step: 8
Training loss: 1.6631798350896625
Validation loss: 2.2423479153517323

Epoch: 5| Step: 9
Training loss: 1.7500839894439444
Validation loss: 2.284231925950322

Epoch: 5| Step: 10
Training loss: 1.0943249417483956
Validation loss: 2.335664615844766

Epoch: 314| Step: 0
Training loss: 1.9476185806861004
Validation loss: 2.2711499450581565

Epoch: 5| Step: 1
Training loss: 1.1741056447431382
Validation loss: 2.2296324967627803

Epoch: 5| Step: 2
Training loss: 1.5493264088276228
Validation loss: 2.3446669624471155

Epoch: 5| Step: 3
Training loss: 1.4010063743636896
Validation loss: 2.2538836626932994

Epoch: 5| Step: 4
Training loss: 1.585527789933102
Validation loss: 2.2838671072565235

Epoch: 5| Step: 5
Training loss: 1.7470248681816656
Validation loss: 2.3068652154167313

Epoch: 5| Step: 6
Training loss: 1.0322324523469026
Validation loss: 2.296622145123442

Epoch: 5| Step: 7
Training loss: 1.2839580852345929
Validation loss: 2.251918027049839

Epoch: 5| Step: 8
Training loss: 1.6795431385547552
Validation loss: 2.3181205028144083

Epoch: 5| Step: 9
Training loss: 1.862315505445933
Validation loss: 2.2970379611221268

Epoch: 5| Step: 10
Training loss: 1.6104948721481023
Validation loss: 2.294429444539435

Epoch: 315| Step: 0
Training loss: 1.6221689358470042
Validation loss: 2.298631921562104

Epoch: 5| Step: 1
Training loss: 1.2913901843244573
Validation loss: 2.285206847870439

Epoch: 5| Step: 2
Training loss: 1.5730732804027179
Validation loss: 2.2495942587404145

Epoch: 5| Step: 3
Training loss: 1.6829024663623415
Validation loss: 2.274924040865803

Epoch: 5| Step: 4
Training loss: 1.4745527850275553
Validation loss: 2.2340867246465974

Epoch: 5| Step: 5
Training loss: 2.038721282588332
Validation loss: 2.2744590314427167

Epoch: 5| Step: 6
Training loss: 1.6466899847523786
Validation loss: 2.2695915117163903

Epoch: 5| Step: 7
Training loss: 1.1850723749906857
Validation loss: 2.2755298628058145

Epoch: 5| Step: 8
Training loss: 1.8790363100207033
Validation loss: 2.243795692768566

Epoch: 5| Step: 9
Training loss: 1.2035302804799324
Validation loss: 2.290623894846082

Epoch: 5| Step: 10
Training loss: 0.9687508921465303
Validation loss: 2.2733321491608014

Epoch: 316| Step: 0
Training loss: 1.187196994069759
Validation loss: 2.282474640312027

Epoch: 5| Step: 1
Training loss: 1.3451011872783547
Validation loss: 2.263811620678782

Epoch: 5| Step: 2
Training loss: 1.3923810094403521
Validation loss: 2.33775991999898

Epoch: 5| Step: 3
Training loss: 2.361407888373162
Validation loss: 2.316820429511178

Epoch: 5| Step: 4
Training loss: 1.4679395184491864
Validation loss: 2.2561753219605016

Epoch: 5| Step: 5
Training loss: 1.7906036402308807
Validation loss: 2.319776604421608

Epoch: 5| Step: 6
Training loss: 1.7363264772559672
Validation loss: 2.229129590460361

Epoch: 5| Step: 7
Training loss: 1.4116580817101543
Validation loss: 2.285784649013116

Epoch: 5| Step: 8
Training loss: 1.0490174078319716
Validation loss: 2.2708869217277736

Epoch: 5| Step: 9
Training loss: 1.5357974511500083
Validation loss: 2.2218964482991064

Epoch: 5| Step: 10
Training loss: 1.6291655921769888
Validation loss: 2.2928457115142082

Epoch: 317| Step: 0
Training loss: 1.5198498860067968
Validation loss: 2.272668695328859

Epoch: 5| Step: 1
Training loss: 1.4985007900201588
Validation loss: 2.2903287865969024

Epoch: 5| Step: 2
Training loss: 1.704152418541824
Validation loss: 2.300763654844411

Epoch: 5| Step: 3
Training loss: 1.5135047475780055
Validation loss: 2.2909829824929266

Epoch: 5| Step: 4
Training loss: 2.2926515948011033
Validation loss: 2.314969084691019

Epoch: 5| Step: 5
Training loss: 1.454473136735089
Validation loss: 2.2288260312248593

Epoch: 5| Step: 6
Training loss: 1.2729814332925073
Validation loss: 2.3277758105007154

Epoch: 5| Step: 7
Training loss: 1.557068348398121
Validation loss: 2.2925177257039224

Epoch: 5| Step: 8
Training loss: 1.3399360113380754
Validation loss: 2.3205094372488575

Epoch: 5| Step: 9
Training loss: 1.250099988752975
Validation loss: 2.242996492349775

Epoch: 5| Step: 10
Training loss: 1.4211529585723472
Validation loss: 2.3513895999476992

Epoch: 318| Step: 0
Training loss: 1.3958184635262307
Validation loss: 2.284314467775038

Epoch: 5| Step: 1
Training loss: 1.668919169677121
Validation loss: 2.263922369609766

Epoch: 5| Step: 2
Training loss: 1.2861822606851296
Validation loss: 2.2800028374509815

Epoch: 5| Step: 3
Training loss: 1.4786486546927429
Validation loss: 2.3054531287740763

Epoch: 5| Step: 4
Training loss: 1.2335171193147576
Validation loss: 2.298540255184561

Epoch: 5| Step: 5
Training loss: 1.3353156711675518
Validation loss: 2.3682105161514686

Epoch: 5| Step: 6
Training loss: 1.3095273459580796
Validation loss: 2.3307444098235313

Epoch: 5| Step: 7
Training loss: 1.5256311517612522
Validation loss: 2.2574445365957305

Epoch: 5| Step: 8
Training loss: 1.6147271205086184
Validation loss: 2.2789637400043077

Epoch: 5| Step: 9
Training loss: 2.1615111807984704
Validation loss: 2.2935016765565415

Epoch: 5| Step: 10
Training loss: 2.044463856001395
Validation loss: 2.292944953421689

Epoch: 319| Step: 0
Training loss: 1.2779311016715678
Validation loss: 2.287974874399592

Epoch: 5| Step: 1
Training loss: 1.5826090946529632
Validation loss: 2.326624966612145

Epoch: 5| Step: 2
Training loss: 1.8179680785344698
Validation loss: 2.2644511745314806

Epoch: 5| Step: 3
Training loss: 1.322636021359682
Validation loss: 2.2631793430694342

Epoch: 5| Step: 4
Training loss: 1.3553695422538223
Validation loss: 2.355008412498893

Epoch: 5| Step: 5
Training loss: 1.4107344860472455
Validation loss: 2.2668573803568077

Epoch: 5| Step: 6
Training loss: 1.9901620179744377
Validation loss: 2.320324166279184

Epoch: 5| Step: 7
Training loss: 1.3281280966329938
Validation loss: 2.3264318160303117

Epoch: 5| Step: 8
Training loss: 1.3158703174350117
Validation loss: 2.295030227648124

Epoch: 5| Step: 9
Training loss: 1.4395785024794672
Validation loss: 2.3270199946085603

Epoch: 5| Step: 10
Training loss: 1.9653009751040045
Validation loss: 2.264198405706152

Epoch: 320| Step: 0
Training loss: 1.0956153222465588
Validation loss: 2.256886065043318

Epoch: 5| Step: 1
Training loss: 1.2895940898309028
Validation loss: 2.310305422375702

Epoch: 5| Step: 2
Training loss: 1.6216456197775762
Validation loss: 2.306445805299714

Epoch: 5| Step: 3
Training loss: 1.402900733951695
Validation loss: 2.2833746516159485

Epoch: 5| Step: 4
Training loss: 1.2254423627306998
Validation loss: 2.2886335085805167

Epoch: 5| Step: 5
Training loss: 1.6104492009846278
Validation loss: 2.2845208098503043

Epoch: 5| Step: 6
Training loss: 1.160647612532721
Validation loss: 2.2933052275765258

Epoch: 5| Step: 7
Training loss: 1.5383826753687242
Validation loss: 2.295235107661141

Epoch: 5| Step: 8
Training loss: 1.30596139813401
Validation loss: 2.2620582927154826

Epoch: 5| Step: 9
Training loss: 2.6033317346441787
Validation loss: 2.2788327950043183

Epoch: 5| Step: 10
Training loss: 1.640173277656146
Validation loss: 2.307736347942802

Epoch: 321| Step: 0
Training loss: 2.1200403790857045
Validation loss: 2.2519905578088064

Epoch: 5| Step: 1
Training loss: 1.8173636589701336
Validation loss: 2.325776492418227

Epoch: 5| Step: 2
Training loss: 1.2604992526822747
Validation loss: 2.301705452778134

Epoch: 5| Step: 3
Training loss: 1.443936079179697
Validation loss: 2.3546257477089316

Epoch: 5| Step: 4
Training loss: 1.4989967965110258
Validation loss: 2.333247704699971

Epoch: 5| Step: 5
Training loss: 1.431995134579795
Validation loss: 2.294858059071111

Epoch: 5| Step: 6
Training loss: 1.231455912533061
Validation loss: 2.345227843843291

Epoch: 5| Step: 7
Training loss: 2.0664687841288116
Validation loss: 2.3296972915831984

Epoch: 5| Step: 8
Training loss: 1.655302748519062
Validation loss: 2.240589223779649

Epoch: 5| Step: 9
Training loss: 1.156954421867547
Validation loss: 2.295895269653643

Epoch: 5| Step: 10
Training loss: 0.7613043024398267
Validation loss: 2.301272070080722

Epoch: 322| Step: 0
Training loss: 1.2162392013399743
Validation loss: 2.278635671472817

Epoch: 5| Step: 1
Training loss: 1.4738897121168486
Validation loss: 2.312143744575996

Epoch: 5| Step: 2
Training loss: 1.587112968303679
Validation loss: 2.3042145497024324

Epoch: 5| Step: 3
Training loss: 1.1714245757091308
Validation loss: 2.2320685127405766

Epoch: 5| Step: 4
Training loss: 1.3158119286327692
Validation loss: 2.3185846154163308

Epoch: 5| Step: 5
Training loss: 1.3881461520517848
Validation loss: 2.289139159446024

Epoch: 5| Step: 6
Training loss: 1.8488791292087832
Validation loss: 2.2470420926223458

Epoch: 5| Step: 7
Training loss: 1.9633030700078244
Validation loss: 2.273553303270222

Epoch: 5| Step: 8
Training loss: 1.5110459518564703
Validation loss: 2.310499137723895

Epoch: 5| Step: 9
Training loss: 1.2131456484798762
Validation loss: 2.243449530499502

Epoch: 5| Step: 10
Training loss: 1.6736647393730193
Validation loss: 2.280883725944665

Epoch: 323| Step: 0
Training loss: 1.0804201105496656
Validation loss: 2.290302997018944

Epoch: 5| Step: 1
Training loss: 1.23376246839289
Validation loss: 2.3049163298746893

Epoch: 5| Step: 2
Training loss: 1.381790516244994
Validation loss: 2.290402999412389

Epoch: 5| Step: 3
Training loss: 1.3825779947695875
Validation loss: 2.2706270179678487

Epoch: 5| Step: 4
Training loss: 1.5020127303222737
Validation loss: 2.2775694357232337

Epoch: 5| Step: 5
Training loss: 1.4981185716881813
Validation loss: 2.306657276196096

Epoch: 5| Step: 6
Training loss: 1.5578310828597557
Validation loss: 2.2835840120698325

Epoch: 5| Step: 7
Training loss: 1.5568477631601814
Validation loss: 2.3125517389550874

Epoch: 5| Step: 8
Training loss: 2.201058033636947
Validation loss: 2.2675853040656677

Epoch: 5| Step: 9
Training loss: 1.4191360922965994
Validation loss: 2.258001960599861

Epoch: 5| Step: 10
Training loss: 1.5210470371685336
Validation loss: 2.317859362587174

Epoch: 324| Step: 0
Training loss: 1.690826880623036
Validation loss: 2.31292204039081

Epoch: 5| Step: 1
Training loss: 1.0772044356619206
Validation loss: 2.2530171618164108

Epoch: 5| Step: 2
Training loss: 1.350856795219988
Validation loss: 2.2580593119142334

Epoch: 5| Step: 3
Training loss: 2.1950672596421796
Validation loss: 2.3323464115639445

Epoch: 5| Step: 4
Training loss: 1.6333031898104438
Validation loss: 2.3088535126396894

Epoch: 5| Step: 5
Training loss: 1.3282565332241636
Validation loss: 2.2962243952410386

Epoch: 5| Step: 6
Training loss: 1.8808625440085582
Validation loss: 2.27045627506834

Epoch: 5| Step: 7
Training loss: 1.1808911177002743
Validation loss: 2.3613943167391223

Epoch: 5| Step: 8
Training loss: 1.3961096200750764
Validation loss: 2.283438789036348

Epoch: 5| Step: 9
Training loss: 1.2714109619323344
Validation loss: 2.264039789918171

Epoch: 5| Step: 10
Training loss: 1.5451268037282926
Validation loss: 2.2816323928969195

Epoch: 325| Step: 0
Training loss: 1.7374863082016947
Validation loss: 2.247827546452465

Epoch: 5| Step: 1
Training loss: 1.3777523670151974
Validation loss: 2.289909260215704

Epoch: 5| Step: 2
Training loss: 1.3595171448502308
Validation loss: 2.34525188822367

Epoch: 5| Step: 3
Training loss: 1.5451429283670302
Validation loss: 2.325244149373539

Epoch: 5| Step: 4
Training loss: 1.342221699502105
Validation loss: 2.3217790767467004

Epoch: 5| Step: 5
Training loss: 1.4232325518362927
Validation loss: 2.3075758443440577

Epoch: 5| Step: 6
Training loss: 1.8390708644420686
Validation loss: 2.276758752083402

Epoch: 5| Step: 7
Training loss: 1.8675560368067683
Validation loss: 2.3096166415331867

Epoch: 5| Step: 8
Training loss: 1.345449171755578
Validation loss: 2.299297965889909

Epoch: 5| Step: 9
Training loss: 1.0887983770823664
Validation loss: 2.324326485280626

Epoch: 5| Step: 10
Training loss: 1.6117561280524721
Validation loss: 2.3148348992774177

Epoch: 326| Step: 0
Training loss: 1.485827809165032
Validation loss: 2.2646707643363304

Epoch: 5| Step: 1
Training loss: 1.1445478106137112
Validation loss: 2.3140393482421158

Epoch: 5| Step: 2
Training loss: 1.7770138612548978
Validation loss: 2.313849380562543

Epoch: 5| Step: 3
Training loss: 1.1963351992059972
Validation loss: 2.324618011482332

Epoch: 5| Step: 4
Training loss: 1.9524411034096074
Validation loss: 2.3679106493217077

Epoch: 5| Step: 5
Training loss: 1.3118696061269253
Validation loss: 2.265176696893532

Epoch: 5| Step: 6
Training loss: 1.5876824311691058
Validation loss: 2.2608422041888083

Epoch: 5| Step: 7
Training loss: 0.980768682190582
Validation loss: 2.2383671722072838

Epoch: 5| Step: 8
Training loss: 1.4153661461768579
Validation loss: 2.264087197822771

Epoch: 5| Step: 9
Training loss: 2.101440199232352
Validation loss: 2.2433731256180676

Epoch: 5| Step: 10
Training loss: 1.8203914772550014
Validation loss: 2.229457389666309

Epoch: 327| Step: 0
Training loss: 1.3405203487213457
Validation loss: 2.2754197585450022

Epoch: 5| Step: 1
Training loss: 1.075787761283456
Validation loss: 2.291914008283007

Epoch: 5| Step: 2
Training loss: 1.3918401145588668
Validation loss: 2.331257981236079

Epoch: 5| Step: 3
Training loss: 1.5182678147942759
Validation loss: 2.305027725582924

Epoch: 5| Step: 4
Training loss: 1.5228666360815326
Validation loss: 2.3037365168882538

Epoch: 5| Step: 5
Training loss: 1.0724582742252604
Validation loss: 2.2875497196755674

Epoch: 5| Step: 6
Training loss: 1.8039084069795464
Validation loss: 2.3336673831091956

Epoch: 5| Step: 7
Training loss: 1.3441448962125178
Validation loss: 2.3436150252878236

Epoch: 5| Step: 8
Training loss: 1.292851560877166
Validation loss: 2.279990865345121

Epoch: 5| Step: 9
Training loss: 1.5901476220512236
Validation loss: 2.285247056571622

Epoch: 5| Step: 10
Training loss: 2.2807134755086933
Validation loss: 2.289476741805132

Epoch: 328| Step: 0
Training loss: 1.019846666442058
Validation loss: 2.2923978345760365

Epoch: 5| Step: 1
Training loss: 1.868538850318651
Validation loss: 2.25554859847747

Epoch: 5| Step: 2
Training loss: 1.6685418388464093
Validation loss: 2.240409060875729

Epoch: 5| Step: 3
Training loss: 1.0943054968409232
Validation loss: 2.2568769901650905

Epoch: 5| Step: 4
Training loss: 1.7301236534027973
Validation loss: 2.2252703184358262

Epoch: 5| Step: 5
Training loss: 1.6895859153467558
Validation loss: 2.237607160660164

Epoch: 5| Step: 6
Training loss: 1.4226895189663515
Validation loss: 2.357021056938714

Epoch: 5| Step: 7
Training loss: 1.4249729321234652
Validation loss: 2.2432816559730444

Epoch: 5| Step: 8
Training loss: 1.5566243897169352
Validation loss: 2.3281543639267164

Epoch: 5| Step: 9
Training loss: 1.5745266975230265
Validation loss: 2.2276555715678783

Epoch: 5| Step: 10
Training loss: 1.1954844232722655
Validation loss: 2.32941168811746

Epoch: 329| Step: 0
Training loss: 1.310903850209938
Validation loss: 2.278334308101984

Epoch: 5| Step: 1
Training loss: 2.014713998191018
Validation loss: 2.3096521940903023

Epoch: 5| Step: 2
Training loss: 1.446198887560626
Validation loss: 2.317309021204352

Epoch: 5| Step: 3
Training loss: 1.3668917962862008
Validation loss: 2.3082400437010917

Epoch: 5| Step: 4
Training loss: 1.1775581392485148
Validation loss: 2.3179028023773083

Epoch: 5| Step: 5
Training loss: 1.543951643774574
Validation loss: 2.3684968952592245

Epoch: 5| Step: 6
Training loss: 1.3495062914288614
Validation loss: 2.3564045725429805

Epoch: 5| Step: 7
Training loss: 1.669352616217538
Validation loss: 2.3784175618516183

Epoch: 5| Step: 8
Training loss: 1.8946129850079714
Validation loss: 2.2954426068051927

Epoch: 5| Step: 9
Training loss: 1.3836157238603053
Validation loss: 2.3218159513415544

Epoch: 5| Step: 10
Training loss: 1.4307403856561332
Validation loss: 2.2982583817869378

Epoch: 330| Step: 0
Training loss: 1.4590427943614945
Validation loss: 2.2915403892501867

Epoch: 5| Step: 1
Training loss: 1.5456642267453207
Validation loss: 2.316042795086018

Epoch: 5| Step: 2
Training loss: 1.2980079757551188
Validation loss: 2.2544486578460474

Epoch: 5| Step: 3
Training loss: 1.2354651357439408
Validation loss: 2.2671341415432194

Epoch: 5| Step: 4
Training loss: 1.6932798232737571
Validation loss: 2.2893158230954582

Epoch: 5| Step: 5
Training loss: 1.9126483286265155
Validation loss: 2.3368737148661647

Epoch: 5| Step: 6
Training loss: 1.2175348043460632
Validation loss: 2.2661245359016275

Epoch: 5| Step: 7
Training loss: 1.316386961300405
Validation loss: 2.3094033302379886

Epoch: 5| Step: 8
Training loss: 1.536864749584167
Validation loss: 2.2401798134112365

Epoch: 5| Step: 9
Training loss: 1.0886102073786599
Validation loss: 2.27068641682573

Epoch: 5| Step: 10
Training loss: 1.389537471756024
Validation loss: 2.219267423022759

Epoch: 331| Step: 0
Training loss: 1.4800151039332279
Validation loss: 2.305629593708539

Epoch: 5| Step: 1
Training loss: 1.1571782999396667
Validation loss: 2.2586529900302548

Epoch: 5| Step: 2
Training loss: 1.1555940984346165
Validation loss: 2.2580378472786657

Epoch: 5| Step: 3
Training loss: 1.4741300700755604
Validation loss: 2.2613895304239717

Epoch: 5| Step: 4
Training loss: 1.2399820386447131
Validation loss: 2.3365162427335493

Epoch: 5| Step: 5
Training loss: 1.5118045437541272
Validation loss: 2.2973048968831518

Epoch: 5| Step: 6
Training loss: 1.5763446850210974
Validation loss: 2.3356056234158857

Epoch: 5| Step: 7
Training loss: 1.4937287205413399
Validation loss: 2.3044859294505105

Epoch: 5| Step: 8
Training loss: 1.1224279140953297
Validation loss: 2.265445054559921

Epoch: 5| Step: 9
Training loss: 1.4686397754621723
Validation loss: 2.2838311431985594

Epoch: 5| Step: 10
Training loss: 2.1594469999684196
Validation loss: 2.2502202990913793

Epoch: 332| Step: 0
Training loss: 1.4074004659472235
Validation loss: 2.262002843119217

Epoch: 5| Step: 1
Training loss: 1.5911105870548525
Validation loss: 2.3235389455008963

Epoch: 5| Step: 2
Training loss: 1.4685868517578407
Validation loss: 2.303201230171276

Epoch: 5| Step: 3
Training loss: 1.6079683545258265
Validation loss: 2.2991848229765655

Epoch: 5| Step: 4
Training loss: 1.5119822664280558
Validation loss: 2.322482509167679

Epoch: 5| Step: 5
Training loss: 1.5804068054942884
Validation loss: 2.2463014859174715

Epoch: 5| Step: 6
Training loss: 1.0476518851352143
Validation loss: 2.31092625386115

Epoch: 5| Step: 7
Training loss: 1.2349165682082255
Validation loss: 2.2836804009489073

Epoch: 5| Step: 8
Training loss: 1.8885516944053733
Validation loss: 2.303949780909856

Epoch: 5| Step: 9
Training loss: 1.3543191041489195
Validation loss: 2.2984441933432973

Epoch: 5| Step: 10
Training loss: 1.6541483518545843
Validation loss: 2.314808380441599

Epoch: 333| Step: 0
Training loss: 1.064446069536537
Validation loss: 2.284224920414148

Epoch: 5| Step: 1
Training loss: 1.415915187036029
Validation loss: 2.312135085049137

Epoch: 5| Step: 2
Training loss: 1.205405464414797
Validation loss: 2.2740222508867722

Epoch: 5| Step: 3
Training loss: 1.6290769784863164
Validation loss: 2.260077261098232

Epoch: 5| Step: 4
Training loss: 1.8580286617306256
Validation loss: 2.310826116753072

Epoch: 5| Step: 5
Training loss: 2.0764825970595355
Validation loss: 2.325279836742953

Epoch: 5| Step: 6
Training loss: 1.6662819974764582
Validation loss: 2.2992104566216987

Epoch: 5| Step: 7
Training loss: 1.5601395133796516
Validation loss: 2.324725067148452

Epoch: 5| Step: 8
Training loss: 1.3183181417163008
Validation loss: 2.230464588691047

Epoch: 5| Step: 9
Training loss: 1.31901504601146
Validation loss: 2.2945089715380425

Epoch: 5| Step: 10
Training loss: 1.0031469419937666
Validation loss: 2.2966167323444537

Epoch: 334| Step: 0
Training loss: 1.2676071845486905
Validation loss: 2.237279512787785

Epoch: 5| Step: 1
Training loss: 2.431987103515864
Validation loss: 2.2338279595445405

Epoch: 5| Step: 2
Training loss: 0.9800001141489703
Validation loss: 2.31305990006687

Epoch: 5| Step: 3
Training loss: 1.6085367334385139
Validation loss: 2.269890532961018

Epoch: 5| Step: 4
Training loss: 1.345242979444309
Validation loss: 2.2781753469656714

Epoch: 5| Step: 5
Training loss: 1.3558085342762123
Validation loss: 2.3213070973452186

Epoch: 5| Step: 6
Training loss: 1.453581707463821
Validation loss: 2.268200099375434

Epoch: 5| Step: 7
Training loss: 0.93559937140683
Validation loss: 2.268972726482369

Epoch: 5| Step: 8
Training loss: 1.3952715962769826
Validation loss: 2.2858793402149917

Epoch: 5| Step: 9
Training loss: 1.3259447490378005
Validation loss: 2.3272766843846955

Epoch: 5| Step: 10
Training loss: 1.6715143830881274
Validation loss: 2.2501839695854975

Epoch: 335| Step: 0
Training loss: 1.2357017051031172
Validation loss: 2.279489082282443

Epoch: 5| Step: 1
Training loss: 1.2397485938090191
Validation loss: 2.284998130884638

Epoch: 5| Step: 2
Training loss: 1.6352374308665414
Validation loss: 2.3001385690287117

Epoch: 5| Step: 3
Training loss: 1.5328778547533994
Validation loss: 2.294614763414015

Epoch: 5| Step: 4
Training loss: 1.3230884420455604
Validation loss: 2.2800582939889353

Epoch: 5| Step: 5
Training loss: 1.6968846919729617
Validation loss: 2.263978708938402

Epoch: 5| Step: 6
Training loss: 1.6679491671768323
Validation loss: 2.3594610911184666

Epoch: 5| Step: 7
Training loss: 1.3222353324631975
Validation loss: 2.314870174561791

Epoch: 5| Step: 8
Training loss: 1.243503041885269
Validation loss: 2.244967727222704

Epoch: 5| Step: 9
Training loss: 1.662390930498733
Validation loss: 2.2747718631288643

Epoch: 5| Step: 10
Training loss: 1.1643404020860617
Validation loss: 2.25656995856951

Epoch: 336| Step: 0
Training loss: 1.3378554736343664
Validation loss: 2.276011495056311

Epoch: 5| Step: 1
Training loss: 0.969669582387038
Validation loss: 2.304823497488163

Epoch: 5| Step: 2
Training loss: 1.3726183465404356
Validation loss: 2.3296553262178463

Epoch: 5| Step: 3
Training loss: 1.609463661492295
Validation loss: 2.2862455220558946

Epoch: 5| Step: 4
Training loss: 1.3803653507767648
Validation loss: 2.2340785107428127

Epoch: 5| Step: 5
Training loss: 1.6114933923295276
Validation loss: 2.2338739388791407

Epoch: 5| Step: 6
Training loss: 1.0587425549638332
Validation loss: 2.2930719029188227

Epoch: 5| Step: 7
Training loss: 1.7071656756862625
Validation loss: 2.336047876817537

Epoch: 5| Step: 8
Training loss: 1.6039551517038648
Validation loss: 2.292804793004346

Epoch: 5| Step: 9
Training loss: 1.958448190229258
Validation loss: 2.2854399233053986

Epoch: 5| Step: 10
Training loss: 1.3858548764412197
Validation loss: 2.263272199789947

Epoch: 337| Step: 0
Training loss: 1.7880304683163095
Validation loss: 2.333958892058438

Epoch: 5| Step: 1
Training loss: 1.049259601402753
Validation loss: 2.3217286122806926

Epoch: 5| Step: 2
Training loss: 1.8490402490083884
Validation loss: 2.3033981128583103

Epoch: 5| Step: 3
Training loss: 1.20776290693041
Validation loss: 2.2656973086463563

Epoch: 5| Step: 4
Training loss: 1.5257532760782462
Validation loss: 2.258814488919341

Epoch: 5| Step: 5
Training loss: 1.5163110183300397
Validation loss: 2.337263714645232

Epoch: 5| Step: 6
Training loss: 1.675504434837544
Validation loss: 2.2783975010340067

Epoch: 5| Step: 7
Training loss: 1.1984887899193626
Validation loss: 2.231185524078057

Epoch: 5| Step: 8
Training loss: 1.3052297595985916
Validation loss: 2.3167011155141695

Epoch: 5| Step: 9
Training loss: 1.4302741342824417
Validation loss: 2.303243383686391

Epoch: 5| Step: 10
Training loss: 1.1107312361055097
Validation loss: 2.33243225720642

Epoch: 338| Step: 0
Training loss: 1.1966845049542436
Validation loss: 2.290689608753352

Epoch: 5| Step: 1
Training loss: 1.6405208009600392
Validation loss: 2.3157009053915294

Epoch: 5| Step: 2
Training loss: 1.3183695022759174
Validation loss: 2.3074446798511414

Epoch: 5| Step: 3
Training loss: 1.2020550218197907
Validation loss: 2.313202900529461

Epoch: 5| Step: 4
Training loss: 1.495622366405931
Validation loss: 2.2799684445335315

Epoch: 5| Step: 5
Training loss: 1.1395540827612536
Validation loss: 2.2645151822474365

Epoch: 5| Step: 6
Training loss: 1.5510518873231092
Validation loss: 2.274329162824155

Epoch: 5| Step: 7
Training loss: 2.176132968163801
Validation loss: 2.283165323053689

Epoch: 5| Step: 8
Training loss: 1.3141808872667005
Validation loss: 2.290006348978661

Epoch: 5| Step: 9
Training loss: 1.3131561001812764
Validation loss: 2.263928692011445

Epoch: 5| Step: 10
Training loss: 1.1338823725297
Validation loss: 2.3469457801125397

Epoch: 339| Step: 0
Training loss: 1.3784416215619217
Validation loss: 2.2352914798656496

Epoch: 5| Step: 1
Training loss: 2.04831848497133
Validation loss: 2.3105905770878077

Epoch: 5| Step: 2
Training loss: 0.9764804042641123
Validation loss: 2.22586165060699

Epoch: 5| Step: 3
Training loss: 1.3139484224459286
Validation loss: 2.303075573691484

Epoch: 5| Step: 4
Training loss: 1.500312534197994
Validation loss: 2.2916790653314725

Epoch: 5| Step: 5
Training loss: 1.087645525348553
Validation loss: 2.328553318866267

Epoch: 5| Step: 6
Training loss: 1.267976342705577
Validation loss: 2.2589032436404133

Epoch: 5| Step: 7
Training loss: 1.8226127007780215
Validation loss: 2.2918476711919804

Epoch: 5| Step: 8
Training loss: 1.3041773272597617
Validation loss: 2.273234799350835

Epoch: 5| Step: 9
Training loss: 1.514716672559351
Validation loss: 2.251401578646323

Epoch: 5| Step: 10
Training loss: 1.184223372685316
Validation loss: 2.2678798093181785

Epoch: 340| Step: 0
Training loss: 1.4768673213802712
Validation loss: 2.270471110660918

Epoch: 5| Step: 1
Training loss: 1.3087037908490282
Validation loss: 2.319285889099051

Epoch: 5| Step: 2
Training loss: 1.4913407564644943
Validation loss: 2.239761378276453

Epoch: 5| Step: 3
Training loss: 1.5854535797406915
Validation loss: 2.29131158910021

Epoch: 5| Step: 4
Training loss: 1.509079001015166
Validation loss: 2.261403995844212

Epoch: 5| Step: 5
Training loss: 1.2188995954206958
Validation loss: 2.278629424474089

Epoch: 5| Step: 6
Training loss: 1.0162663708784077
Validation loss: 2.33131817261063

Epoch: 5| Step: 7
Training loss: 1.5946052350939979
Validation loss: 2.2810768627004636

Epoch: 5| Step: 8
Training loss: 1.1966256800798751
Validation loss: 2.298361280570111

Epoch: 5| Step: 9
Training loss: 1.4929738793716667
Validation loss: 2.29076349316834

Epoch: 5| Step: 10
Training loss: 1.8681867790536
Validation loss: 2.3216403501051315

Epoch: 341| Step: 0
Training loss: 1.832615220427512
Validation loss: 2.2918339639344314

Epoch: 5| Step: 1
Training loss: 0.9212937543149889
Validation loss: 2.2240200054826738

Epoch: 5| Step: 2
Training loss: 1.3544453652009936
Validation loss: 2.313645962190655

Epoch: 5| Step: 3
Training loss: 1.6973950651654213
Validation loss: 2.2530431289980135

Epoch: 5| Step: 4
Training loss: 1.521390116248453
Validation loss: 2.2524803065448538

Epoch: 5| Step: 5
Training loss: 1.3872385689447828
Validation loss: 2.2692698884052067

Epoch: 5| Step: 6
Training loss: 1.4187576159302229
Validation loss: 2.277948675198287

Epoch: 5| Step: 7
Training loss: 1.7467134131419917
Validation loss: 2.303798342029371

Epoch: 5| Step: 8
Training loss: 1.3932999589944541
Validation loss: 2.2958114781398495

Epoch: 5| Step: 9
Training loss: 1.2787466948197086
Validation loss: 2.300669087074198

Epoch: 5| Step: 10
Training loss: 1.0683964752506168
Validation loss: 2.325648947116466

Epoch: 342| Step: 0
Training loss: 1.363766865193308
Validation loss: 2.2859658351755288

Epoch: 5| Step: 1
Training loss: 1.5978904496503703
Validation loss: 2.310640278498318

Epoch: 5| Step: 2
Training loss: 1.4092948586289686
Validation loss: 2.3291544923301464

Epoch: 5| Step: 3
Training loss: 1.3407995968390156
Validation loss: 2.305749908676927

Epoch: 5| Step: 4
Training loss: 1.5042148818357317
Validation loss: 2.3095319880590925

Epoch: 5| Step: 5
Training loss: 0.9849105165470673
Validation loss: 2.2904440229498677

Epoch: 5| Step: 6
Training loss: 1.2475899828640467
Validation loss: 2.34537061712859

Epoch: 5| Step: 7
Training loss: 1.7196248688922025
Validation loss: 2.261362546953128

Epoch: 5| Step: 8
Training loss: 1.6384929791213647
Validation loss: 2.2676249976704725

Epoch: 5| Step: 9
Training loss: 1.1202089227229426
Validation loss: 2.259836579431959

Epoch: 5| Step: 10
Training loss: 1.6177119634734536
Validation loss: 2.2477009465767783

Epoch: 343| Step: 0
Training loss: 1.5404599424389565
Validation loss: 2.251009415013598

Epoch: 5| Step: 1
Training loss: 1.1285645914991613
Validation loss: 2.2545269200951408

Epoch: 5| Step: 2
Training loss: 1.646386556559174
Validation loss: 2.2683186903626766

Epoch: 5| Step: 3
Training loss: 1.6025578081056273
Validation loss: 2.2404562931257392

Epoch: 5| Step: 4
Training loss: 1.954220395952573
Validation loss: 2.217157492868572

Epoch: 5| Step: 5
Training loss: 1.0779349670999703
Validation loss: 2.3064436328498044

Epoch: 5| Step: 6
Training loss: 1.2266056028920143
Validation loss: 2.2974723958176146

Epoch: 5| Step: 7
Training loss: 0.9564232899843464
Validation loss: 2.3164598716455083

Epoch: 5| Step: 8
Training loss: 1.5748138438822858
Validation loss: 2.2783401089151107

Epoch: 5| Step: 9
Training loss: 1.413027474143704
Validation loss: 2.282313319452334

Epoch: 5| Step: 10
Training loss: 1.280936970502414
Validation loss: 2.287515538287992

Epoch: 344| Step: 0
Training loss: 1.4547872572639977
Validation loss: 2.2882153592164336

Epoch: 5| Step: 1
Training loss: 1.4679944956309887
Validation loss: 2.219294176120118

Epoch: 5| Step: 2
Training loss: 1.5885401074344507
Validation loss: 2.3458704587379273

Epoch: 5| Step: 3
Training loss: 1.4124166278371337
Validation loss: 2.3233900374662206

Epoch: 5| Step: 4
Training loss: 0.7640520793305596
Validation loss: 2.2341763426515744

Epoch: 5| Step: 5
Training loss: 1.2628398437862487
Validation loss: 2.301605964298526

Epoch: 5| Step: 6
Training loss: 1.75396001176912
Validation loss: 2.235620642655362

Epoch: 5| Step: 7
Training loss: 1.4944566978289437
Validation loss: 2.2719233292984513

Epoch: 5| Step: 8
Training loss: 1.3667405624105675
Validation loss: 2.280591920653965

Epoch: 5| Step: 9
Training loss: 1.3329274583009807
Validation loss: 2.2709483068358547

Epoch: 5| Step: 10
Training loss: 1.4546738440572267
Validation loss: 2.270073163888704

Epoch: 345| Step: 0
Training loss: 1.3327875758855938
Validation loss: 2.280431061305285

Epoch: 5| Step: 1
Training loss: 1.498750881802488
Validation loss: 2.291586084897465

Epoch: 5| Step: 2
Training loss: 1.3476842020425477
Validation loss: 2.256455441222105

Epoch: 5| Step: 3
Training loss: 1.2694873978303691
Validation loss: 2.285062173933804

Epoch: 5| Step: 4
Training loss: 1.2810934017593612
Validation loss: 2.2472299400910374

Epoch: 5| Step: 5
Training loss: 1.206147892242413
Validation loss: 2.2884112525769127

Epoch: 5| Step: 6
Training loss: 1.697006504309378
Validation loss: 2.242096526249912

Epoch: 5| Step: 7
Training loss: 1.488271798331618
Validation loss: 2.3313513362547438

Epoch: 5| Step: 8
Training loss: 2.036007518252298
Validation loss: 2.2901685750558682

Epoch: 5| Step: 9
Training loss: 1.4089476671294117
Validation loss: 2.3058173556523074

Epoch: 5| Step: 10
Training loss: 0.9186683423869496
Validation loss: 2.2933883650599842

Epoch: 346| Step: 0
Training loss: 1.2722962771346178
Validation loss: 2.2667179785294564

Epoch: 5| Step: 1
Training loss: 1.1017891941426308
Validation loss: 2.3160744025584643

Epoch: 5| Step: 2
Training loss: 1.2661460463245024
Validation loss: 2.3038024905017047

Epoch: 5| Step: 3
Training loss: 1.5364033144997795
Validation loss: 2.2441778054331873

Epoch: 5| Step: 4
Training loss: 1.329526139721479
Validation loss: 2.2806183753512057

Epoch: 5| Step: 5
Training loss: 1.4832587612709263
Validation loss: 2.2883537293017464

Epoch: 5| Step: 6
Training loss: 2.1435929488327874
Validation loss: 2.3389057196069194

Epoch: 5| Step: 7
Training loss: 0.6995198331492989
Validation loss: 2.279916526689994

Epoch: 5| Step: 8
Training loss: 1.3510936298637208
Validation loss: 2.313258030489625

Epoch: 5| Step: 9
Training loss: 1.296866543294152
Validation loss: 2.322888671082381

Epoch: 5| Step: 10
Training loss: 1.3003144214105289
Validation loss: 2.394226500205375

Epoch: 347| Step: 0
Training loss: 1.4766525160382007
Validation loss: 2.2988634027942467

Epoch: 5| Step: 1
Training loss: 1.6319160738523837
Validation loss: 2.257776866355877

Epoch: 5| Step: 2
Training loss: 1.1380453332610485
Validation loss: 2.2933483113947797

Epoch: 5| Step: 3
Training loss: 1.0697520661321853
Validation loss: 2.250350799468169

Epoch: 5| Step: 4
Training loss: 1.3744883018653602
Validation loss: 2.3009617956430124

Epoch: 5| Step: 5
Training loss: 1.6164232742644675
Validation loss: 2.333622256056886

Epoch: 5| Step: 6
Training loss: 1.9241405872324986
Validation loss: 2.2757334325985368

Epoch: 5| Step: 7
Training loss: 1.0148273563602643
Validation loss: 2.293296490766741

Epoch: 5| Step: 8
Training loss: 1.349793660324861
Validation loss: 2.290961217579089

Epoch: 5| Step: 9
Training loss: 0.7821871667816269
Validation loss: 2.2863524211977824

Epoch: 5| Step: 10
Training loss: 1.3991333918943911
Validation loss: 2.3277246428708125

Epoch: 348| Step: 0
Training loss: 1.478248400708757
Validation loss: 2.250885054458205

Epoch: 5| Step: 1
Training loss: 1.324693127849887
Validation loss: 2.2620413449534382

Epoch: 5| Step: 2
Training loss: 1.200308487897115
Validation loss: 2.3240349500874418

Epoch: 5| Step: 3
Training loss: 1.4141535439872432
Validation loss: 2.2749098124224325

Epoch: 5| Step: 4
Training loss: 0.8838115878949194
Validation loss: 2.331064869214439

Epoch: 5| Step: 5
Training loss: 1.306456548614248
Validation loss: 2.2146797467423642

Epoch: 5| Step: 6
Training loss: 1.1176789276625383
Validation loss: 2.2808440315404845

Epoch: 5| Step: 7
Training loss: 2.1003218040947
Validation loss: 2.2923300990033875

Epoch: 5| Step: 8
Training loss: 1.204072207845625
Validation loss: 2.275216013080402

Epoch: 5| Step: 9
Training loss: 1.587569951596322
Validation loss: 2.3560458810383076

Epoch: 5| Step: 10
Training loss: 1.792629500729581
Validation loss: 2.2901925317321528

Epoch: 349| Step: 0
Training loss: 1.3387142569848702
Validation loss: 2.309147411940614

Epoch: 5| Step: 1
Training loss: 1.4770053421471439
Validation loss: 2.327296175900066

Epoch: 5| Step: 2
Training loss: 1.3264940008264325
Validation loss: 2.2483128816088915

Epoch: 5| Step: 3
Training loss: 1.229321383852265
Validation loss: 2.2247821015837936

Epoch: 5| Step: 4
Training loss: 1.2109161867296492
Validation loss: 2.237625367005013

Epoch: 5| Step: 5
Training loss: 1.591454966515285
Validation loss: 2.2910199756579432

Epoch: 5| Step: 6
Training loss: 1.3966218893995874
Validation loss: 2.2314635955427033

Epoch: 5| Step: 7
Training loss: 1.6743196101921445
Validation loss: 2.2612460649491797

Epoch: 5| Step: 8
Training loss: 1.43643107269659
Validation loss: 2.2428268047726783

Epoch: 5| Step: 9
Training loss: 1.8310251299697693
Validation loss: 2.2873264039989643

Epoch: 5| Step: 10
Training loss: 0.7250639936551615
Validation loss: 2.299725460125369

Epoch: 350| Step: 0
Training loss: 1.5023151650885798
Validation loss: 2.2733694554838806

Epoch: 5| Step: 1
Training loss: 1.2511047726399647
Validation loss: 2.2877292543504946

Epoch: 5| Step: 2
Training loss: 1.1919499391822121
Validation loss: 2.2778624824326443

Epoch: 5| Step: 3
Training loss: 1.1543655504171406
Validation loss: 2.29609593297935

Epoch: 5| Step: 4
Training loss: 1.2079761349865914
Validation loss: 2.2617329101073893

Epoch: 5| Step: 5
Training loss: 1.4871584844834769
Validation loss: 2.208350007576041

Epoch: 5| Step: 6
Training loss: 1.2053302519689968
Validation loss: 2.3038336983916836

Epoch: 5| Step: 7
Training loss: 1.3736419907405226
Validation loss: 2.2629230810974277

Epoch: 5| Step: 8
Training loss: 1.8984439049129995
Validation loss: 2.3225405073172825

Epoch: 5| Step: 9
Training loss: 1.3726617699014387
Validation loss: 2.2823429756786444

Epoch: 5| Step: 10
Training loss: 1.3437717790834758
Validation loss: 2.288597541011358

Testing loss: 2.8825524593923615
