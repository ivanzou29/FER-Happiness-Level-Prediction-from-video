Epoch: 1| Step: 0
Training loss: 4.148296356201172
Validation loss: 3.866896221714635

Epoch: 6| Step: 1
Training loss: 3.4847168922424316
Validation loss: 3.859704525240006

Epoch: 6| Step: 2
Training loss: 3.395073890686035
Validation loss: 3.853165395798222

Epoch: 6| Step: 3
Training loss: 2.7212488651275635
Validation loss: 3.8429180345227643

Epoch: 6| Step: 4
Training loss: 4.342696189880371
Validation loss: 3.8380905633331626

Epoch: 6| Step: 5
Training loss: 3.570380926132202
Validation loss: 3.8286700299991074

Epoch: 6| Step: 6
Training loss: 4.5659990310668945
Validation loss: 3.8218659944431757

Epoch: 6| Step: 7
Training loss: 3.571744918823242
Validation loss: 3.815484969846664

Epoch: 6| Step: 8
Training loss: 4.112741947174072
Validation loss: 3.8105813969847975

Epoch: 6| Step: 9
Training loss: 3.0762810707092285
Validation loss: 3.804150458305113

Epoch: 6| Step: 10
Training loss: 4.453471660614014
Validation loss: 3.7985724864467496

Epoch: 6| Step: 11
Training loss: 2.6850175857543945
Validation loss: 3.790956917629447

Epoch: 6| Step: 12
Training loss: 4.12326717376709
Validation loss: 3.7849679711044475

Epoch: 6| Step: 13
Training loss: 3.4950907230377197
Validation loss: 3.77584941669177

Epoch: 2| Step: 0
Training loss: 4.060451030731201
Validation loss: 3.7706764744174097

Epoch: 6| Step: 1
Training loss: 3.817014694213867
Validation loss: 3.766911209270518

Epoch: 6| Step: 2
Training loss: 4.461584091186523
Validation loss: 3.758469707222395

Epoch: 6| Step: 3
Training loss: 4.28346586227417
Validation loss: 3.750041643778483

Epoch: 6| Step: 4
Training loss: 3.1629531383514404
Validation loss: 3.7452323770010345

Epoch: 6| Step: 5
Training loss: 3.78145170211792
Validation loss: 3.7401744909183954

Epoch: 6| Step: 6
Training loss: 4.098844528198242
Validation loss: 3.7330158064442296

Epoch: 6| Step: 7
Training loss: 2.947913646697998
Validation loss: 3.727183759853404

Epoch: 6| Step: 8
Training loss: 2.9438748359680176
Validation loss: 3.721609438619306

Epoch: 6| Step: 9
Training loss: 4.012782096862793
Validation loss: 3.7153766027060886

Epoch: 6| Step: 10
Training loss: 2.75276517868042
Validation loss: 3.7074197133382163

Epoch: 6| Step: 11
Training loss: 3.6242103576660156
Validation loss: 3.7068243821461997

Epoch: 6| Step: 12
Training loss: 3.753016948699951
Validation loss: 3.6968851781660512

Epoch: 6| Step: 13
Training loss: 2.6737029552459717
Validation loss: 3.692589388098768

Epoch: 3| Step: 0
Training loss: 3.403902530670166
Validation loss: 3.6848566045043287

Epoch: 6| Step: 1
Training loss: 4.849260330200195
Validation loss: 3.6796735230312554

Epoch: 6| Step: 2
Training loss: 2.4765162467956543
Validation loss: 3.6748936099390828

Epoch: 6| Step: 3
Training loss: 3.5548107624053955
Validation loss: 3.6681104552361274

Epoch: 6| Step: 4
Training loss: 3.4550015926361084
Validation loss: 3.661905506605743

Epoch: 6| Step: 5
Training loss: 3.576920509338379
Validation loss: 3.6567428829849407

Epoch: 6| Step: 6
Training loss: 4.279848098754883
Validation loss: 3.651251151997556

Epoch: 6| Step: 7
Training loss: 4.092459201812744
Validation loss: 3.6449918952039493

Epoch: 6| Step: 8
Training loss: 3.779421806335449
Validation loss: 3.6357058068757415

Epoch: 6| Step: 9
Training loss: 3.570603609085083
Validation loss: 3.6351608102039625

Epoch: 6| Step: 10
Training loss: 3.850010871887207
Validation loss: 3.6300596473037556

Epoch: 6| Step: 11
Training loss: 2.902425765991211
Validation loss: 3.623009502246816

Epoch: 6| Step: 12
Training loss: 3.0596923828125
Validation loss: 3.6181908474173596

Epoch: 6| Step: 13
Training loss: 2.483588695526123
Validation loss: 3.6082173726891957

Epoch: 4| Step: 0
Training loss: 2.44041109085083
Validation loss: 3.607712104756345

Epoch: 6| Step: 1
Training loss: 3.128831386566162
Validation loss: 3.5982264395683043

Epoch: 6| Step: 2
Training loss: 3.695788860321045
Validation loss: 3.592248116770098

Epoch: 6| Step: 3
Training loss: 3.953972816467285
Validation loss: 3.5841552519029185

Epoch: 6| Step: 4
Training loss: 4.7319016456604
Validation loss: 3.5790626771988405

Epoch: 6| Step: 5
Training loss: 3.019740104675293
Validation loss: 3.5754106275496946

Epoch: 6| Step: 6
Training loss: 4.093171119689941
Validation loss: 3.5668096901268087

Epoch: 6| Step: 7
Training loss: 3.1044862270355225
Validation loss: 3.5641605264397076

Epoch: 6| Step: 8
Training loss: 3.696213722229004
Validation loss: 3.557387310971496

Epoch: 6| Step: 9
Training loss: 3.4060685634613037
Validation loss: 3.551118004706598

Epoch: 6| Step: 10
Training loss: 3.06713604927063
Validation loss: 3.543959950888029

Epoch: 6| Step: 11
Training loss: 3.45831561088562
Validation loss: 3.5357095349219536

Epoch: 6| Step: 12
Training loss: 4.021577835083008
Validation loss: 3.531895109402236

Epoch: 6| Step: 13
Training loss: 2.4523870944976807
Validation loss: 3.5242169800625054

Epoch: 5| Step: 0
Training loss: 4.153823375701904
Validation loss: 3.5199817175506265

Epoch: 6| Step: 1
Training loss: 3.0749363899230957
Validation loss: 3.511646034897015

Epoch: 6| Step: 2
Training loss: 3.3842601776123047
Validation loss: 3.505046547100108

Epoch: 6| Step: 3
Training loss: 2.17860746383667
Validation loss: 3.4988976345267346

Epoch: 6| Step: 4
Training loss: 3.6449828147888184
Validation loss: 3.490848159277311

Epoch: 6| Step: 5
Training loss: 4.612029075622559
Validation loss: 3.482349318842734

Epoch: 6| Step: 6
Training loss: 2.690336227416992
Validation loss: 3.478315950721823

Epoch: 6| Step: 7
Training loss: 3.684394359588623
Validation loss: 3.471707610673802

Epoch: 6| Step: 8
Training loss: 4.5292134284973145
Validation loss: 3.466172592614287

Epoch: 6| Step: 9
Training loss: 2.850538969039917
Validation loss: 3.458713803240048

Epoch: 6| Step: 10
Training loss: 3.8519396781921387
Validation loss: 3.451417712755101

Epoch: 6| Step: 11
Training loss: 3.13895320892334
Validation loss: 3.4428926411495415

Epoch: 6| Step: 12
Training loss: 2.8574798107147217
Validation loss: 3.436706758314563

Epoch: 6| Step: 13
Training loss: 2.6969034671783447
Validation loss: 3.4275731681495585

Epoch: 6| Step: 0
Training loss: 3.0132641792297363
Validation loss: 3.4159955952757146

Epoch: 6| Step: 1
Training loss: 2.0441317558288574
Validation loss: 3.4130164372023715

Epoch: 6| Step: 2
Training loss: 2.9642677307128906
Validation loss: 3.408956455928023

Epoch: 6| Step: 3
Training loss: 4.211477756500244
Validation loss: 3.399037709800146

Epoch: 6| Step: 4
Training loss: 4.490511417388916
Validation loss: 3.389661799194992

Epoch: 6| Step: 5
Training loss: 3.3208706378936768
Validation loss: 3.38185058101531

Epoch: 6| Step: 6
Training loss: 3.7040843963623047
Validation loss: 3.3752183786002536

Epoch: 6| Step: 7
Training loss: 3.3916261196136475
Validation loss: 3.366614874973092

Epoch: 6| Step: 8
Training loss: 3.1511826515197754
Validation loss: 3.3568781114393667

Epoch: 6| Step: 9
Training loss: 3.336585521697998
Validation loss: 3.351443721402076

Epoch: 6| Step: 10
Training loss: 3.5454015731811523
Validation loss: 3.3405022057153846

Epoch: 6| Step: 11
Training loss: 3.2227976322174072
Validation loss: 3.333036458620461

Epoch: 6| Step: 12
Training loss: 3.1323485374450684
Validation loss: 3.3282124252729517

Epoch: 6| Step: 13
Training loss: 2.505570411682129
Validation loss: 3.3166448070156958

Epoch: 7| Step: 0
Training loss: 3.456104040145874
Validation loss: 3.3113330846191733

Epoch: 6| Step: 1
Training loss: 2.327214241027832
Validation loss: 3.303141645205918

Epoch: 6| Step: 2
Training loss: 3.3691184520721436
Validation loss: 3.2904321532095633

Epoch: 6| Step: 3
Training loss: 3.096360921859741
Validation loss: 3.2815146882046937

Epoch: 6| Step: 4
Training loss: 3.091904640197754
Validation loss: 3.2755810214627172

Epoch: 6| Step: 5
Training loss: 3.259645938873291
Validation loss: 3.2711736463731333

Epoch: 6| Step: 6
Training loss: 3.5164883136749268
Validation loss: 3.2571515831896054

Epoch: 6| Step: 7
Training loss: 2.6897318363189697
Validation loss: 3.251535092630694

Epoch: 6| Step: 8
Training loss: 3.232844829559326
Validation loss: 3.2398933697772283

Epoch: 6| Step: 9
Training loss: 3.238668203353882
Validation loss: 3.233745751842376

Epoch: 6| Step: 10
Training loss: 3.779000759124756
Validation loss: 3.2234462896982827

Epoch: 6| Step: 11
Training loss: 2.6881914138793945
Validation loss: 3.217097710537654

Epoch: 6| Step: 12
Training loss: 3.8280913829803467
Validation loss: 3.2071296656003563

Epoch: 6| Step: 13
Training loss: 3.6380581855773926
Validation loss: 3.1940959704819547

Epoch: 8| Step: 0
Training loss: 3.7615153789520264
Validation loss: 3.1882094260184997

Epoch: 6| Step: 1
Training loss: 3.836848258972168
Validation loss: 3.1734227493245113

Epoch: 6| Step: 2
Training loss: 2.5450809001922607
Validation loss: 3.1656980232525895

Epoch: 6| Step: 3
Training loss: 2.6138052940368652
Validation loss: 3.160493722525976

Epoch: 6| Step: 4
Training loss: 3.672477960586548
Validation loss: 3.1482842071082002

Epoch: 6| Step: 5
Training loss: 2.5732359886169434
Validation loss: 3.1378665149852796

Epoch: 6| Step: 6
Training loss: 2.986762523651123
Validation loss: 3.127462274284773

Epoch: 6| Step: 7
Training loss: 2.509228229522705
Validation loss: 3.119296686623686

Epoch: 6| Step: 8
Training loss: 2.8090929985046387
Validation loss: 3.113287318137384

Epoch: 6| Step: 9
Training loss: 3.245640516281128
Validation loss: 3.100095425882647

Epoch: 6| Step: 10
Training loss: 2.438587188720703
Validation loss: 3.0903740826473443

Epoch: 6| Step: 11
Training loss: 3.426802635192871
Validation loss: 3.081230343029063

Epoch: 6| Step: 12
Training loss: 3.2107720375061035
Validation loss: 3.0717909130998837

Epoch: 6| Step: 13
Training loss: 4.626623630523682
Validation loss: 3.066859186336558

Epoch: 9| Step: 0
Training loss: 3.1665635108947754
Validation loss: 3.0521153685867146

Epoch: 6| Step: 1
Training loss: 3.4177651405334473
Validation loss: 3.042399555124262

Epoch: 6| Step: 2
Training loss: 3.1218981742858887
Validation loss: 3.0324745690950783

Epoch: 6| Step: 3
Training loss: 3.3697409629821777
Validation loss: 3.018130927957514

Epoch: 6| Step: 4
Training loss: 3.1409966945648193
Validation loss: 3.0021564601570048

Epoch: 6| Step: 5
Training loss: 3.3170006275177
Validation loss: 2.9979639002071914

Epoch: 6| Step: 6
Training loss: 3.2649269104003906
Validation loss: 2.981187874271024

Epoch: 6| Step: 7
Training loss: 1.5659890174865723
Validation loss: 2.9775688276495984

Epoch: 6| Step: 8
Training loss: 3.157177209854126
Validation loss: 2.9652527839906755

Epoch: 6| Step: 9
Training loss: 2.9176626205444336
Validation loss: 2.948028387561921

Epoch: 6| Step: 10
Training loss: 3.2923390865325928
Validation loss: 2.9376747454366376

Epoch: 6| Step: 11
Training loss: 2.992928981781006
Validation loss: 2.933861924755958

Epoch: 6| Step: 12
Training loss: 2.536285638809204
Validation loss: 2.923593472408992

Epoch: 6| Step: 13
Training loss: 2.8082923889160156
Validation loss: 2.913764158884684

Epoch: 10| Step: 0
Training loss: 2.578589677810669
Validation loss: 2.9057178958769767

Epoch: 6| Step: 1
Training loss: 2.772268772125244
Validation loss: 2.893177242689235

Epoch: 6| Step: 2
Training loss: 2.599177837371826
Validation loss: 2.8789723611647084

Epoch: 6| Step: 3
Training loss: 3.2075281143188477
Validation loss: 2.8688733449546238

Epoch: 6| Step: 4
Training loss: 2.716175079345703
Validation loss: 2.857194028874879

Epoch: 6| Step: 5
Training loss: 2.5622830390930176
Validation loss: 2.8425943082378757

Epoch: 6| Step: 6
Training loss: 3.2369658946990967
Validation loss: 2.8358746190224924

Epoch: 6| Step: 7
Training loss: 2.783585548400879
Validation loss: 2.817093377472252

Epoch: 6| Step: 8
Training loss: 2.4692137241363525
Validation loss: 2.8113267908814135

Epoch: 6| Step: 9
Training loss: 2.9401156902313232
Validation loss: 2.8016039145890104

Epoch: 6| Step: 10
Training loss: 3.244924783706665
Validation loss: 2.7910931853837866

Epoch: 6| Step: 11
Training loss: 3.67549991607666
Validation loss: 2.7818528554772817

Epoch: 6| Step: 12
Training loss: 3.601705312728882
Validation loss: 2.7675672064545336

Epoch: 6| Step: 13
Training loss: 2.019547700881958
Validation loss: 2.7696233282807055

Epoch: 11| Step: 0
Training loss: 2.537705183029175
Validation loss: 2.748881527172622

Epoch: 6| Step: 1
Training loss: 4.046999931335449
Validation loss: 2.7445530686327206

Epoch: 6| Step: 2
Training loss: 2.3204221725463867
Validation loss: 2.729184772378655

Epoch: 6| Step: 3
Training loss: 3.3946330547332764
Validation loss: 2.715568418143898

Epoch: 6| Step: 4
Training loss: 2.8251900672912598
Validation loss: 2.709663498786188

Epoch: 6| Step: 5
Training loss: 2.7339065074920654
Validation loss: 2.7027419356889624

Epoch: 6| Step: 6
Training loss: 2.9252071380615234
Validation loss: 2.690983731259582

Epoch: 6| Step: 7
Training loss: 3.1552162170410156
Validation loss: 2.6804508624538297

Epoch: 6| Step: 8
Training loss: 2.158813714981079
Validation loss: 2.666624620396604

Epoch: 6| Step: 9
Training loss: 2.959402561187744
Validation loss: 2.6547997638743412

Epoch: 6| Step: 10
Training loss: 3.019160509109497
Validation loss: 2.639818840129401

Epoch: 6| Step: 11
Training loss: 2.3493387699127197
Validation loss: 2.6279383295325824

Epoch: 6| Step: 12
Training loss: 2.7278008460998535
Validation loss: 2.6138732330773466

Epoch: 6| Step: 13
Training loss: 1.9651751518249512
Validation loss: 2.6087564781147945

Epoch: 12| Step: 0
Training loss: 2.5626869201660156
Validation loss: 2.596143573843023

Epoch: 6| Step: 1
Training loss: 3.0769295692443848
Validation loss: 2.5876414904030423

Epoch: 6| Step: 2
Training loss: 2.7220940589904785
Validation loss: 2.570688223326078

Epoch: 6| Step: 3
Training loss: 3.298246383666992
Validation loss: 2.5642638565391622

Epoch: 6| Step: 4
Training loss: 1.9646556377410889
Validation loss: 2.545532893109065

Epoch: 6| Step: 5
Training loss: 2.2705113887786865
Validation loss: 2.5342836021095194

Epoch: 6| Step: 6
Training loss: 2.9786715507507324
Validation loss: 2.524701979852492

Epoch: 6| Step: 7
Training loss: 1.9513347148895264
Validation loss: 2.5117530797117498

Epoch: 6| Step: 8
Training loss: 2.623690366744995
Validation loss: 2.5042583762958484

Epoch: 6| Step: 9
Training loss: 2.91078519821167
Validation loss: 2.49307260974761

Epoch: 6| Step: 10
Training loss: 2.6648290157318115
Validation loss: 2.480402736253636

Epoch: 6| Step: 11
Training loss: 3.3130650520324707
Validation loss: 2.4675202984963693

Epoch: 6| Step: 12
Training loss: 2.9477643966674805
Validation loss: 2.45874725362306

Epoch: 6| Step: 13
Training loss: 3.0262701511383057
Validation loss: 2.4465095817401843

Epoch: 13| Step: 0
Training loss: 3.3893513679504395
Validation loss: 2.42932802631009

Epoch: 6| Step: 1
Training loss: 2.3971848487854004
Validation loss: 2.4275102820447696

Epoch: 6| Step: 2
Training loss: 2.724534511566162
Validation loss: 2.414886474609375

Epoch: 6| Step: 3
Training loss: 3.2153282165527344
Validation loss: 2.395622126517757

Epoch: 6| Step: 4
Training loss: 2.4471092224121094
Validation loss: 2.388971515881118

Epoch: 6| Step: 5
Training loss: 2.888648271560669
Validation loss: 2.3788681901911253

Epoch: 6| Step: 6
Training loss: 3.1078176498413086
Validation loss: 2.366126852650796

Epoch: 6| Step: 7
Training loss: 2.455970048904419
Validation loss: 2.352658297425957

Epoch: 6| Step: 8
Training loss: 2.501810073852539
Validation loss: 2.3456360934883036

Epoch: 6| Step: 9
Training loss: 2.7009620666503906
Validation loss: 2.332841416840912

Epoch: 6| Step: 10
Training loss: 2.084763526916504
Validation loss: 2.330960460888442

Epoch: 6| Step: 11
Training loss: 2.7580199241638184
Validation loss: 2.3170684101761028

Epoch: 6| Step: 12
Training loss: 1.82863187789917
Validation loss: 2.314975115560716

Epoch: 6| Step: 13
Training loss: 2.0133118629455566
Validation loss: 2.3029863603653444

Epoch: 14| Step: 0
Training loss: 3.0965676307678223
Validation loss: 2.293104015370851

Epoch: 6| Step: 1
Training loss: 2.905913829803467
Validation loss: 2.2895350584419827

Epoch: 6| Step: 2
Training loss: 2.372612237930298
Validation loss: 2.2706680259396954

Epoch: 6| Step: 3
Training loss: 1.8953297138214111
Validation loss: 2.2621744730139293

Epoch: 6| Step: 4
Training loss: 2.2593226432800293
Validation loss: 2.264467062488679

Epoch: 6| Step: 5
Training loss: 3.0327320098876953
Validation loss: 2.2464423769263813

Epoch: 6| Step: 6
Training loss: 2.3747920989990234
Validation loss: 2.241897362534718

Epoch: 6| Step: 7
Training loss: 2.470109701156616
Validation loss: 2.2456253062012377

Epoch: 6| Step: 8
Training loss: 2.424386739730835
Validation loss: 2.2286887348339124

Epoch: 6| Step: 9
Training loss: 2.135793685913086
Validation loss: 2.218266628121817

Epoch: 6| Step: 10
Training loss: 2.9641404151916504
Validation loss: 2.219092704916513

Epoch: 6| Step: 11
Training loss: 2.45428204536438
Validation loss: 2.2086524912106094

Epoch: 6| Step: 12
Training loss: 2.7922983169555664
Validation loss: 2.200095781715967

Epoch: 6| Step: 13
Training loss: 2.183070421218872
Validation loss: 2.196677093864769

Epoch: 15| Step: 0
Training loss: 2.681889057159424
Validation loss: 2.1857823351378083

Epoch: 6| Step: 1
Training loss: 2.8404109477996826
Validation loss: 2.173752698847043

Epoch: 6| Step: 2
Training loss: 2.632378101348877
Validation loss: 2.1770746836098294

Epoch: 6| Step: 3
Training loss: 2.1541435718536377
Validation loss: 2.1638950276118454

Epoch: 6| Step: 4
Training loss: 2.791349411010742
Validation loss: 2.1580754377508677

Epoch: 6| Step: 5
Training loss: 2.2921676635742188
Validation loss: 2.1538237551207184

Epoch: 6| Step: 6
Training loss: 1.8448538780212402
Validation loss: 2.1514547153185775

Epoch: 6| Step: 7
Training loss: 2.219837188720703
Validation loss: 2.1442248436712448

Epoch: 6| Step: 8
Training loss: 3.034731388092041
Validation loss: 2.1446630236923054

Epoch: 6| Step: 9
Training loss: 2.4581470489501953
Validation loss: 2.125241241147441

Epoch: 6| Step: 10
Training loss: 2.069568157196045
Validation loss: 2.123787340297494

Epoch: 6| Step: 11
Training loss: 3.0409440994262695
Validation loss: 2.126795627737558

Epoch: 6| Step: 12
Training loss: 2.7989206314086914
Validation loss: 2.1154403840341875

Epoch: 6| Step: 13
Training loss: 1.722745418548584
Validation loss: 2.117523362559657

Epoch: 16| Step: 0
Training loss: 3.172534465789795
Validation loss: 2.1087845192160657

Epoch: 6| Step: 1
Training loss: 1.8118900060653687
Validation loss: 2.1129570955871255

Epoch: 6| Step: 2
Training loss: 2.3054776191711426
Validation loss: 2.1148592554112917

Epoch: 6| Step: 3
Training loss: 2.3102378845214844
Validation loss: 2.1088200653752973

Epoch: 6| Step: 4
Training loss: 2.979557991027832
Validation loss: 2.115501126935405

Epoch: 6| Step: 5
Training loss: 2.3865954875946045
Validation loss: 2.1031855152499292

Epoch: 6| Step: 6
Training loss: 2.366305351257324
Validation loss: 2.091297668795432

Epoch: 6| Step: 7
Training loss: 2.0104129314422607
Validation loss: 2.0812738941561792

Epoch: 6| Step: 8
Training loss: 2.467542886734009
Validation loss: 2.07408163239879

Epoch: 6| Step: 9
Training loss: 2.3340554237365723
Validation loss: 2.073268363552709

Epoch: 6| Step: 10
Training loss: 2.4440243244171143
Validation loss: 2.077826629402817

Epoch: 6| Step: 11
Training loss: 2.2161669731140137
Validation loss: 2.077659877397681

Epoch: 6| Step: 12
Training loss: 2.537942886352539
Validation loss: 2.0786394406390447

Epoch: 6| Step: 13
Training loss: 3.7159886360168457
Validation loss: 2.0688258499227543

Epoch: 17| Step: 0
Training loss: 2.4086031913757324
Validation loss: 2.0839121239159697

Epoch: 6| Step: 1
Training loss: 2.5651817321777344
Validation loss: 2.0690623034713087

Epoch: 6| Step: 2
Training loss: 2.466370105743408
Validation loss: 2.066685443283409

Epoch: 6| Step: 3
Training loss: 2.2038660049438477
Validation loss: 2.0634695945247525

Epoch: 6| Step: 4
Training loss: 3.167046546936035
Validation loss: 2.068963227733489

Epoch: 6| Step: 5
Training loss: 2.314554214477539
Validation loss: 2.0703783368551605

Epoch: 6| Step: 6
Training loss: 2.237699031829834
Validation loss: 2.060901758491352

Epoch: 6| Step: 7
Training loss: 1.6591830253601074
Validation loss: 2.050353337359685

Epoch: 6| Step: 8
Training loss: 2.794157028198242
Validation loss: 2.062107665564424

Epoch: 6| Step: 9
Training loss: 2.8915767669677734
Validation loss: 2.0785290156641314

Epoch: 6| Step: 10
Training loss: 2.3562610149383545
Validation loss: 2.073101706402276

Epoch: 6| Step: 11
Training loss: 2.408665418624878
Validation loss: 2.0736606941428235

Epoch: 6| Step: 12
Training loss: 1.8668643236160278
Validation loss: 2.0782048574057956

Epoch: 6| Step: 13
Training loss: 3.2668087482452393
Validation loss: 2.075694722513999

Epoch: 18| Step: 0
Training loss: 2.19670033454895
Validation loss: 2.0668969282539944

Epoch: 6| Step: 1
Training loss: 2.8234806060791016
Validation loss: 2.059057363899805

Epoch: 6| Step: 2
Training loss: 2.0654656887054443
Validation loss: 2.03866385644482

Epoch: 6| Step: 3
Training loss: 2.9904732704162598
Validation loss: 2.0554665762891053

Epoch: 6| Step: 4
Training loss: 3.087714672088623
Validation loss: 2.0581190304089616

Epoch: 6| Step: 5
Training loss: 2.0216903686523438
Validation loss: 2.0671811001275175

Epoch: 6| Step: 6
Training loss: 2.658255100250244
Validation loss: 2.0559901793797812

Epoch: 6| Step: 7
Training loss: 2.4204678535461426
Validation loss: 2.0431736374414093

Epoch: 6| Step: 8
Training loss: 1.9760103225708008
Validation loss: 2.0563465023553498

Epoch: 6| Step: 9
Training loss: 2.5498576164245605
Validation loss: 2.049300644987373

Epoch: 6| Step: 10
Training loss: 2.794543981552124
Validation loss: 2.051309561216703

Epoch: 6| Step: 11
Training loss: 2.163827896118164
Validation loss: 2.0547971276826758

Epoch: 6| Step: 12
Training loss: 2.1947107315063477
Validation loss: 2.0512715872897895

Epoch: 6| Step: 13
Training loss: 1.9237515926361084
Validation loss: 2.041878879711192

Epoch: 19| Step: 0
Training loss: 1.9975804090499878
Validation loss: 2.0537610015561505

Epoch: 6| Step: 1
Training loss: 2.0106277465820312
Validation loss: 2.0381197288472164

Epoch: 6| Step: 2
Training loss: 2.069558620452881
Validation loss: 2.048070312828146

Epoch: 6| Step: 3
Training loss: 3.308641195297241
Validation loss: 2.046418248966176

Epoch: 6| Step: 4
Training loss: 2.2545437812805176
Validation loss: 2.0375630983742337

Epoch: 6| Step: 5
Training loss: 2.629610061645508
Validation loss: 2.0301880016121814

Epoch: 6| Step: 6
Training loss: 2.266341209411621
Validation loss: 2.043265401676137

Epoch: 6| Step: 7
Training loss: 2.4859132766723633
Validation loss: 2.0407714177203435

Epoch: 6| Step: 8
Training loss: 2.3718295097351074
Validation loss: 2.041009420989662

Epoch: 6| Step: 9
Training loss: 2.727095603942871
Validation loss: 2.040544168923491

Epoch: 6| Step: 10
Training loss: 2.181077480316162
Validation loss: 2.0363582641847673

Epoch: 6| Step: 11
Training loss: 2.4133780002593994
Validation loss: 2.0401408749241985

Epoch: 6| Step: 12
Training loss: 2.8996663093566895
Validation loss: 2.0289624224426928

Epoch: 6| Step: 13
Training loss: 2.4250094890594482
Validation loss: 2.0221534685422013

Epoch: 20| Step: 0
Training loss: 2.85825777053833
Validation loss: 2.0281962476750857

Epoch: 6| Step: 1
Training loss: 1.9043350219726562
Validation loss: 2.016547014636378

Epoch: 6| Step: 2
Training loss: 1.9711402654647827
Validation loss: 2.0299882094065347

Epoch: 6| Step: 3
Training loss: 2.8346831798553467
Validation loss: 2.027597322258898

Epoch: 6| Step: 4
Training loss: 2.181175708770752
Validation loss: 2.007336949789396

Epoch: 6| Step: 5
Training loss: 2.340273380279541
Validation loss: 2.013767082204101

Epoch: 6| Step: 6
Training loss: 2.395932197570801
Validation loss: 2.0023387580789547

Epoch: 6| Step: 7
Training loss: 2.6532034873962402
Validation loss: 1.9991082094048942

Epoch: 6| Step: 8
Training loss: 2.5447263717651367
Validation loss: 2.00262027658442

Epoch: 6| Step: 9
Training loss: 2.7162508964538574
Validation loss: 2.012672314079859

Epoch: 6| Step: 10
Training loss: 2.441232442855835
Validation loss: 1.9940743048985798

Epoch: 6| Step: 11
Training loss: 1.6226160526275635
Validation loss: 1.9976970354715984

Epoch: 6| Step: 12
Training loss: 2.6425812244415283
Validation loss: 2.0015559414381623

Epoch: 6| Step: 13
Training loss: 3.451286554336548
Validation loss: 2.003812707880492

Epoch: 21| Step: 0
Training loss: 2.67979097366333
Validation loss: 2.012980866175826

Epoch: 6| Step: 1
Training loss: 2.3989651203155518
Validation loss: 2.0089488414026078

Epoch: 6| Step: 2
Training loss: 2.8499886989593506
Validation loss: 2.0215811575612714

Epoch: 6| Step: 3
Training loss: 2.319754123687744
Validation loss: 2.0142808973148303

Epoch: 6| Step: 4
Training loss: 2.0591282844543457
Validation loss: 2.015434113881921

Epoch: 6| Step: 5
Training loss: 2.8486886024475098
Validation loss: 2.0167978399543354

Epoch: 6| Step: 6
Training loss: 1.8495161533355713
Validation loss: 2.0119467473799184

Epoch: 6| Step: 7
Training loss: 2.205577850341797
Validation loss: 2.0167507894577517

Epoch: 6| Step: 8
Training loss: 2.4946224689483643
Validation loss: 2.0134391451394684

Epoch: 6| Step: 9
Training loss: 2.4601693153381348
Validation loss: 2.0060758757334884

Epoch: 6| Step: 10
Training loss: 2.0808584690093994
Validation loss: 2.0226049192490114

Epoch: 6| Step: 11
Training loss: 1.7944386005401611
Validation loss: 2.0150277935048586

Epoch: 6| Step: 12
Training loss: 2.8709049224853516
Validation loss: 2.008158483812886

Epoch: 6| Step: 13
Training loss: 3.2034640312194824
Validation loss: 2.022844317138836

Epoch: 22| Step: 0
Training loss: 2.675257682800293
Validation loss: 2.0110841745971353

Epoch: 6| Step: 1
Training loss: 2.9390954971313477
Validation loss: 2.0299424586757535

Epoch: 6| Step: 2
Training loss: 2.3652501106262207
Validation loss: 2.0353886171053817

Epoch: 6| Step: 3
Training loss: 2.382215738296509
Validation loss: 2.0169620783098283

Epoch: 6| Step: 4
Training loss: 2.2905893325805664
Validation loss: 2.0243179105943248

Epoch: 6| Step: 5
Training loss: 2.422743558883667
Validation loss: 2.016448005553215

Epoch: 6| Step: 6
Training loss: 2.2410948276519775
Validation loss: 2.016770153917292

Epoch: 6| Step: 7
Training loss: 2.1278204917907715
Validation loss: 2.015896035778907

Epoch: 6| Step: 8
Training loss: 1.8737573623657227
Validation loss: 2.014779270336192

Epoch: 6| Step: 9
Training loss: 2.680814266204834
Validation loss: 2.0127868908707813

Epoch: 6| Step: 10
Training loss: 2.3040642738342285
Validation loss: 2.0214242960817073

Epoch: 6| Step: 11
Training loss: 2.461148738861084
Validation loss: 2.0041937802427556

Epoch: 6| Step: 12
Training loss: 2.5506739616394043
Validation loss: 2.0161257636162544

Epoch: 6| Step: 13
Training loss: 2.166680335998535
Validation loss: 2.0336954106566725

Epoch: 23| Step: 0
Training loss: 2.8686866760253906
Validation loss: 2.0315930920262493

Epoch: 6| Step: 1
Training loss: 2.040074348449707
Validation loss: 2.005097516121403

Epoch: 6| Step: 2
Training loss: 2.6851959228515625
Validation loss: 2.0265345855425765

Epoch: 6| Step: 3
Training loss: 1.9760708808898926
Validation loss: 2.0288339789195726

Epoch: 6| Step: 4
Training loss: 2.283479928970337
Validation loss: 2.0160165602161038

Epoch: 6| Step: 5
Training loss: 2.327755928039551
Validation loss: 2.0292672136778473

Epoch: 6| Step: 6
Training loss: 3.20944881439209
Validation loss: 2.0267979739814677

Epoch: 6| Step: 7
Training loss: 2.582550048828125
Validation loss: 2.031296019913048

Epoch: 6| Step: 8
Training loss: 1.6887445449829102
Validation loss: 2.0363642964311826

Epoch: 6| Step: 9
Training loss: 2.634706497192383
Validation loss: 2.031497552830686

Epoch: 6| Step: 10
Training loss: 2.9344234466552734
Validation loss: 2.0393944401894846

Epoch: 6| Step: 11
Training loss: 2.078864097595215
Validation loss: 2.0195689829446937

Epoch: 6| Step: 12
Training loss: 1.8979352712631226
Validation loss: 2.046601897926741

Epoch: 6| Step: 13
Training loss: 2.445906639099121
Validation loss: 2.027491973292443

Epoch: 24| Step: 0
Training loss: 2.0645999908447266
Validation loss: 2.0250811474297636

Epoch: 6| Step: 1
Training loss: 2.4054789543151855
Validation loss: 2.0192594579471055

Epoch: 6| Step: 2
Training loss: 2.4365622997283936
Validation loss: 2.037906236546014

Epoch: 6| Step: 3
Training loss: 3.2031028270721436
Validation loss: 2.0309017832561205

Epoch: 6| Step: 4
Training loss: 2.4104933738708496
Validation loss: 2.018806116555327

Epoch: 6| Step: 5
Training loss: 1.639840841293335
Validation loss: 2.034385476061093

Epoch: 6| Step: 6
Training loss: 2.0909159183502197
Validation loss: 2.0319438775380454

Epoch: 6| Step: 7
Training loss: 1.724385380744934
Validation loss: 2.0273634746510494

Epoch: 6| Step: 8
Training loss: 2.3086018562316895
Validation loss: 2.014652411142985

Epoch: 6| Step: 9
Training loss: 2.862123489379883
Validation loss: 2.0304923057556152

Epoch: 6| Step: 10
Training loss: 2.552798271179199
Validation loss: 2.0183202823003135

Epoch: 6| Step: 11
Training loss: 2.442209482192993
Validation loss: 2.015436722386268

Epoch: 6| Step: 12
Training loss: 2.8155136108398438
Validation loss: 2.008651371925108

Epoch: 6| Step: 13
Training loss: 2.731100082397461
Validation loss: 2.017067963077176

Epoch: 25| Step: 0
Training loss: 2.3022165298461914
Validation loss: 2.015104523269079

Epoch: 6| Step: 1
Training loss: 2.3711633682250977
Validation loss: 2.009379986793764

Epoch: 6| Step: 2
Training loss: 1.805821180343628
Validation loss: 2.029782692591349

Epoch: 6| Step: 3
Training loss: 2.222837448120117
Validation loss: 2.0175978342692056

Epoch: 6| Step: 4
Training loss: 2.557715892791748
Validation loss: 2.0027917251792005

Epoch: 6| Step: 5
Training loss: 2.956655502319336
Validation loss: 2.02221776593116

Epoch: 6| Step: 6
Training loss: 3.14569354057312
Validation loss: 2.016896519609677

Epoch: 6| Step: 7
Training loss: 2.3048152923583984
Validation loss: 2.0229878156415877

Epoch: 6| Step: 8
Training loss: 2.382040023803711
Validation loss: 2.0066942066274662

Epoch: 6| Step: 9
Training loss: 2.268387794494629
Validation loss: 2.0052085717519126

Epoch: 6| Step: 10
Training loss: 2.249418258666992
Validation loss: 2.006279380090775

Epoch: 6| Step: 11
Training loss: 2.6470091342926025
Validation loss: 2.0226713995779715

Epoch: 6| Step: 12
Training loss: 2.1807308197021484
Validation loss: 2.0143296154596473

Epoch: 6| Step: 13
Training loss: 1.8597346544265747
Validation loss: 2.0095687425264748

Epoch: 26| Step: 0
Training loss: 2.568711757659912
Validation loss: 2.007849174161111

Epoch: 6| Step: 1
Training loss: 1.929878830909729
Validation loss: 1.9853615376257128

Epoch: 6| Step: 2
Training loss: 2.8970866203308105
Validation loss: 2.009416364854382

Epoch: 6| Step: 3
Training loss: 2.420365333557129
Validation loss: 2.0020901951738583

Epoch: 6| Step: 4
Training loss: 2.018979787826538
Validation loss: 2.0004155584560928

Epoch: 6| Step: 5
Training loss: 2.682152271270752
Validation loss: 2.006752972961754

Epoch: 6| Step: 6
Training loss: 1.7948331832885742
Validation loss: 2.0090344887907787

Epoch: 6| Step: 7
Training loss: 2.580728769302368
Validation loss: 2.01854399711855

Epoch: 6| Step: 8
Training loss: 2.436263084411621
Validation loss: 2.007292333469596

Epoch: 6| Step: 9
Training loss: 2.400479316711426
Validation loss: 2.0088393303655807

Epoch: 6| Step: 10
Training loss: 2.5971875190734863
Validation loss: 2.0079629959598666

Epoch: 6| Step: 11
Training loss: 2.372720241546631
Validation loss: 2.0152759603274766

Epoch: 6| Step: 12
Training loss: 2.432615041732788
Validation loss: 2.010177250831358

Epoch: 6| Step: 13
Training loss: 2.378422975540161
Validation loss: 2.0198555941222818

Epoch: 27| Step: 0
Training loss: 2.610095500946045
Validation loss: 1.9971037885194183

Epoch: 6| Step: 1
Training loss: 2.183779716491699
Validation loss: 2.0092041518098567

Epoch: 6| Step: 2
Training loss: 1.9321928024291992
Validation loss: 2.004582614027044

Epoch: 6| Step: 3
Training loss: 2.270057201385498
Validation loss: 2.0059079482991207

Epoch: 6| Step: 4
Training loss: 2.986050605773926
Validation loss: 2.0164341477937597

Epoch: 6| Step: 5
Training loss: 2.040839433670044
Validation loss: 2.001554863427275

Epoch: 6| Step: 6
Training loss: 2.1705431938171387
Validation loss: 1.998083201787805

Epoch: 6| Step: 7
Training loss: 2.599308729171753
Validation loss: 2.010066227246356

Epoch: 6| Step: 8
Training loss: 2.5987343788146973
Validation loss: 2.0025907972807526

Epoch: 6| Step: 9
Training loss: 2.0752744674682617
Validation loss: 2.005481791752641

Epoch: 6| Step: 10
Training loss: 2.8838672637939453
Validation loss: 1.996475511981595

Epoch: 6| Step: 11
Training loss: 2.399005651473999
Validation loss: 2.0110481759553314

Epoch: 6| Step: 12
Training loss: 2.1658880710601807
Validation loss: 2.016041418557526

Epoch: 6| Step: 13
Training loss: 2.479990005493164
Validation loss: 2.0120282160338534

Epoch: 28| Step: 0
Training loss: 2.9280407428741455
Validation loss: 2.005320038846744

Epoch: 6| Step: 1
Training loss: 2.230926036834717
Validation loss: 2.0106207311794324

Epoch: 6| Step: 2
Training loss: 1.9922873973846436
Validation loss: 2.0006627267406834

Epoch: 6| Step: 3
Training loss: 2.896522045135498
Validation loss: 2.0093063500619706

Epoch: 6| Step: 4
Training loss: 2.477768898010254
Validation loss: 2.014925572179979

Epoch: 6| Step: 5
Training loss: 2.325307607650757
Validation loss: 2.024081632655154

Epoch: 6| Step: 6
Training loss: 2.4132652282714844
Validation loss: 2.0073795267330703

Epoch: 6| Step: 7
Training loss: 3.080821990966797
Validation loss: 2.012587216592604

Epoch: 6| Step: 8
Training loss: 1.6802928447723389
Validation loss: 2.029115446152226

Epoch: 6| Step: 9
Training loss: 2.0878634452819824
Validation loss: 2.0242808121506886

Epoch: 6| Step: 10
Training loss: 2.126237154006958
Validation loss: 2.029984716446169

Epoch: 6| Step: 11
Training loss: 2.7219443321228027
Validation loss: 2.000889755064441

Epoch: 6| Step: 12
Training loss: 2.025529384613037
Validation loss: 2.0039405656117264

Epoch: 6| Step: 13
Training loss: 2.16091251373291
Validation loss: 2.019456668566632

Epoch: 29| Step: 0
Training loss: 2.6181483268737793
Validation loss: 2.004207644411313

Epoch: 6| Step: 1
Training loss: 2.1406352519989014
Validation loss: 2.014069080352783

Epoch: 6| Step: 2
Training loss: 2.714019298553467
Validation loss: 2.0157878655259327

Epoch: 6| Step: 3
Training loss: 2.0598301887512207
Validation loss: 2.0009255383604314

Epoch: 6| Step: 4
Training loss: 2.246150016784668
Validation loss: 2.006469499680304

Epoch: 6| Step: 5
Training loss: 2.1339921951293945
Validation loss: 2.0208352022273566

Epoch: 6| Step: 6
Training loss: 2.836686849594116
Validation loss: 2.011561091228198

Epoch: 6| Step: 7
Training loss: 2.383650779724121
Validation loss: 2.0087083001290598

Epoch: 6| Step: 8
Training loss: 2.057682514190674
Validation loss: 2.0145294512471845

Epoch: 6| Step: 9
Training loss: 1.943957805633545
Validation loss: 2.0100456335211314

Epoch: 6| Step: 10
Training loss: 3.275862693786621
Validation loss: 2.0184677454733078

Epoch: 6| Step: 11
Training loss: 1.8302066326141357
Validation loss: 2.0133557409368534

Epoch: 6| Step: 12
Training loss: 2.0736823081970215
Validation loss: 2.0088954792227796

Epoch: 6| Step: 13
Training loss: 3.147059917449951
Validation loss: 2.0057911052498767

Epoch: 30| Step: 0
Training loss: 2.7475757598876953
Validation loss: 2.015275868036414

Epoch: 6| Step: 1
Training loss: 2.2831714153289795
Validation loss: 2.014604599245133

Epoch: 6| Step: 2
Training loss: 2.3184995651245117
Validation loss: 2.0134927085650864

Epoch: 6| Step: 3
Training loss: 2.7725419998168945
Validation loss: 1.9977058210680563

Epoch: 6| Step: 4
Training loss: 1.6984238624572754
Validation loss: 1.9949535669819

Epoch: 6| Step: 5
Training loss: 1.9808602333068848
Validation loss: 1.9974068903153943

Epoch: 6| Step: 6
Training loss: 2.8768575191497803
Validation loss: 2.005186688515448

Epoch: 6| Step: 7
Training loss: 2.444542407989502
Validation loss: 2.0050905250733897

Epoch: 6| Step: 8
Training loss: 3.1291093826293945
Validation loss: 2.003028526101061

Epoch: 6| Step: 9
Training loss: 2.2366442680358887
Validation loss: 2.0024466732496857

Epoch: 6| Step: 10
Training loss: 2.318972110748291
Validation loss: 2.0048357158578853

Epoch: 6| Step: 11
Training loss: 1.6040544509887695
Validation loss: 1.9979585268164193

Epoch: 6| Step: 12
Training loss: 2.1848998069763184
Validation loss: 2.0065233745882587

Epoch: 6| Step: 13
Training loss: 2.6748716831207275
Validation loss: 2.002906407079389

Epoch: 31| Step: 0
Training loss: 1.928880214691162
Validation loss: 2.010711672485516

Epoch: 6| Step: 1
Training loss: 2.066833257675171
Validation loss: 2.0030392139188704

Epoch: 6| Step: 2
Training loss: 2.3896470069885254
Validation loss: 2.0100043204522904

Epoch: 6| Step: 3
Training loss: 2.9661946296691895
Validation loss: 1.9953572750091553

Epoch: 6| Step: 4
Training loss: 3.3717856407165527
Validation loss: 2.0020684080739177

Epoch: 6| Step: 5
Training loss: 2.9658360481262207
Validation loss: 2.0098505148323635

Epoch: 6| Step: 6
Training loss: 1.649643898010254
Validation loss: 1.9903734422499133

Epoch: 6| Step: 7
Training loss: 2.285649299621582
Validation loss: 1.9857084379401257

Epoch: 6| Step: 8
Training loss: 2.157472610473633
Validation loss: 1.997920391380146

Epoch: 6| Step: 9
Training loss: 2.190720796585083
Validation loss: 2.0046310347895466

Epoch: 6| Step: 10
Training loss: 2.549699306488037
Validation loss: 1.991794527217906

Epoch: 6| Step: 11
Training loss: 2.2473530769348145
Validation loss: 1.9885609816479426

Epoch: 6| Step: 12
Training loss: 2.1766648292541504
Validation loss: 1.9975919979874805

Epoch: 6| Step: 13
Training loss: 1.9861197471618652
Validation loss: 1.9907448689142864

Epoch: 32| Step: 0
Training loss: 2.5593202114105225
Validation loss: 1.9868495028506044

Epoch: 6| Step: 1
Training loss: 1.783405065536499
Validation loss: 1.9973831484394688

Epoch: 6| Step: 2
Training loss: 2.7985141277313232
Validation loss: 1.9850670265895065

Epoch: 6| Step: 3
Training loss: 1.8862226009368896
Validation loss: 1.9965527544739425

Epoch: 6| Step: 4
Training loss: 2.610363006591797
Validation loss: 1.9960757327336136

Epoch: 6| Step: 5
Training loss: 2.6082088947296143
Validation loss: 1.9851957328857914

Epoch: 6| Step: 6
Training loss: 2.061624526977539
Validation loss: 1.9840068637683828

Epoch: 6| Step: 7
Training loss: 2.3903751373291016
Validation loss: 1.9978772927356023

Epoch: 6| Step: 8
Training loss: 2.625430107116699
Validation loss: 1.9897108103639336

Epoch: 6| Step: 9
Training loss: 2.130563259124756
Validation loss: 1.981598642564589

Epoch: 6| Step: 10
Training loss: 2.2625982761383057
Validation loss: 1.9705044505416707

Epoch: 6| Step: 11
Training loss: 2.5895986557006836
Validation loss: 1.9929445225705382

Epoch: 6| Step: 12
Training loss: 2.3440194129943848
Validation loss: 1.974659740283925

Epoch: 6| Step: 13
Training loss: 2.1546714305877686
Validation loss: 1.9790973919694141

Epoch: 33| Step: 0
Training loss: 2.279848098754883
Validation loss: 1.967878205801851

Epoch: 6| Step: 1
Training loss: 3.223386764526367
Validation loss: 1.9801055692857312

Epoch: 6| Step: 2
Training loss: 2.1066975593566895
Validation loss: 1.9784071753101964

Epoch: 6| Step: 3
Training loss: 1.9475586414337158
Validation loss: 1.9805470294849847

Epoch: 6| Step: 4
Training loss: 2.4066107273101807
Validation loss: 1.9646979224297307

Epoch: 6| Step: 5
Training loss: 2.0887413024902344
Validation loss: 1.9726244993107294

Epoch: 6| Step: 6
Training loss: 2.993708848953247
Validation loss: 1.9692965399834417

Epoch: 6| Step: 7
Training loss: 1.6446607112884521
Validation loss: 1.9714351648925452

Epoch: 6| Step: 8
Training loss: 2.513988733291626
Validation loss: 1.9597677364144275

Epoch: 6| Step: 9
Training loss: 2.4563088417053223
Validation loss: 1.983649956282749

Epoch: 6| Step: 10
Training loss: 2.3707332611083984
Validation loss: 1.9734997903147051

Epoch: 6| Step: 11
Training loss: 1.7272206544876099
Validation loss: 1.9784116616813086

Epoch: 6| Step: 12
Training loss: 2.9252219200134277
Validation loss: 1.971695803826855

Epoch: 6| Step: 13
Training loss: 2.0065650939941406
Validation loss: 1.9742259415247108

Epoch: 34| Step: 0
Training loss: 2.133422374725342
Validation loss: 1.9807736258352957

Epoch: 6| Step: 1
Training loss: 2.448367118835449
Validation loss: 1.975005502341896

Epoch: 6| Step: 2
Training loss: 2.507202625274658
Validation loss: 1.9704210181390085

Epoch: 6| Step: 3
Training loss: 1.8982905149459839
Validation loss: 1.9820009354622132

Epoch: 6| Step: 4
Training loss: 2.535753011703491
Validation loss: 1.9806559778028918

Epoch: 6| Step: 5
Training loss: 1.7205778360366821
Validation loss: 1.9806018144853654

Epoch: 6| Step: 6
Training loss: 2.008495807647705
Validation loss: 1.9831590267919725

Epoch: 6| Step: 7
Training loss: 2.635335922241211
Validation loss: 1.9752911201087378

Epoch: 6| Step: 8
Training loss: 2.7451119422912598
Validation loss: 1.9893249593755251

Epoch: 6| Step: 9
Training loss: 2.5118653774261475
Validation loss: 1.9858943147044028

Epoch: 6| Step: 10
Training loss: 2.063535690307617
Validation loss: 1.9721875370189708

Epoch: 6| Step: 11
Training loss: 2.3678877353668213
Validation loss: 1.9830534611978838

Epoch: 6| Step: 12
Training loss: 2.7080788612365723
Validation loss: 1.9884846838571693

Epoch: 6| Step: 13
Training loss: 2.5335946083068848
Validation loss: 1.9851729639114872

Epoch: 35| Step: 0
Training loss: 2.1683907508850098
Validation loss: 1.9708332015622048

Epoch: 6| Step: 1
Training loss: 2.5854263305664062
Validation loss: 1.9712792340145315

Epoch: 6| Step: 2
Training loss: 2.1715869903564453
Validation loss: 1.9802692321039015

Epoch: 6| Step: 3
Training loss: 2.450772285461426
Validation loss: 1.986449505693169

Epoch: 6| Step: 4
Training loss: 1.4749892950057983
Validation loss: 1.9841431392136442

Epoch: 6| Step: 5
Training loss: 2.1198487281799316
Validation loss: 1.9713622434164888

Epoch: 6| Step: 6
Training loss: 2.8261497020721436
Validation loss: 1.9803724929850588

Epoch: 6| Step: 7
Training loss: 2.593013286590576
Validation loss: 1.9880108628221738

Epoch: 6| Step: 8
Training loss: 2.398606300354004
Validation loss: 1.9830150142792733

Epoch: 6| Step: 9
Training loss: 2.012741804122925
Validation loss: 1.9882760124821817

Epoch: 6| Step: 10
Training loss: 2.541867733001709
Validation loss: 1.983799126840407

Epoch: 6| Step: 11
Training loss: 2.3642609119415283
Validation loss: 1.9893020263282202

Epoch: 6| Step: 12
Training loss: 2.4379706382751465
Validation loss: 1.9993969304587251

Epoch: 6| Step: 13
Training loss: 2.6580777168273926
Validation loss: 1.9830093076152187

Epoch: 36| Step: 0
Training loss: 1.93305242061615
Validation loss: 1.9790752677507297

Epoch: 6| Step: 1
Training loss: 2.0159037113189697
Validation loss: 1.9861524387072491

Epoch: 6| Step: 2
Training loss: 2.1682751178741455
Validation loss: 1.9595381547045965

Epoch: 6| Step: 3
Training loss: 2.4704649448394775
Validation loss: 1.968113504430299

Epoch: 6| Step: 4
Training loss: 2.5003247261047363
Validation loss: 1.9675536886338265

Epoch: 6| Step: 5
Training loss: 2.2170462608337402
Validation loss: 1.9708676466377832

Epoch: 6| Step: 6
Training loss: 2.513582229614258
Validation loss: 1.9701855592830206

Epoch: 6| Step: 7
Training loss: 2.3568496704101562
Validation loss: 1.9819592634836833

Epoch: 6| Step: 8
Training loss: 2.9581215381622314
Validation loss: 1.9669608557096092

Epoch: 6| Step: 9
Training loss: 1.9315779209136963
Validation loss: 1.9771666244793964

Epoch: 6| Step: 10
Training loss: 2.8978357315063477
Validation loss: 1.98618451241524

Epoch: 6| Step: 11
Training loss: 2.305821657180786
Validation loss: 1.9811069990998955

Epoch: 6| Step: 12
Training loss: 1.938629150390625
Validation loss: 1.975856283659576

Epoch: 6| Step: 13
Training loss: 2.5096940994262695
Validation loss: 1.977181116739909

Epoch: 37| Step: 0
Training loss: 1.721158504486084
Validation loss: 1.9777097163661834

Epoch: 6| Step: 1
Training loss: 2.02085542678833
Validation loss: 1.9663623609850485

Epoch: 6| Step: 2
Training loss: 2.8212203979492188
Validation loss: 1.9750295992820495

Epoch: 6| Step: 3
Training loss: 2.4309158325195312
Validation loss: 1.9581478975152458

Epoch: 6| Step: 4
Training loss: 2.5307464599609375
Validation loss: 1.9962558695065078

Epoch: 6| Step: 5
Training loss: 1.9983205795288086
Validation loss: 1.973192721284846

Epoch: 6| Step: 6
Training loss: 2.4655721187591553
Validation loss: 1.978387132767708

Epoch: 6| Step: 7
Training loss: 2.612105131149292
Validation loss: 1.9874695885565974

Epoch: 6| Step: 8
Training loss: 2.072728157043457
Validation loss: 1.971466870718105

Epoch: 6| Step: 9
Training loss: 2.4661216735839844
Validation loss: 1.9855445636216031

Epoch: 6| Step: 10
Training loss: 2.5707342624664307
Validation loss: 1.9818980847635577

Epoch: 6| Step: 11
Training loss: 2.371890068054199
Validation loss: 1.9721566323311097

Epoch: 6| Step: 12
Training loss: 2.775280475616455
Validation loss: 1.9789482188481156

Epoch: 6| Step: 13
Training loss: 1.372933030128479
Validation loss: 1.978503224670246

Epoch: 38| Step: 0
Training loss: 2.1037449836730957
Validation loss: 1.970233344262646

Epoch: 6| Step: 1
Training loss: 2.0427184104919434
Validation loss: 1.9777155332667853

Epoch: 6| Step: 2
Training loss: 2.1940367221832275
Validation loss: 1.9896781611186203

Epoch: 6| Step: 3
Training loss: 2.819089889526367
Validation loss: 1.9783521236911896

Epoch: 6| Step: 4
Training loss: 2.2109031677246094
Validation loss: 1.962334689273629

Epoch: 6| Step: 5
Training loss: 2.1520237922668457
Validation loss: 1.9777464764092558

Epoch: 6| Step: 6
Training loss: 2.615694522857666
Validation loss: 1.982960561270355

Epoch: 6| Step: 7
Training loss: 1.9481743574142456
Validation loss: 1.97962688502445

Epoch: 6| Step: 8
Training loss: 3.016352415084839
Validation loss: 1.9776748880263297

Epoch: 6| Step: 9
Training loss: 1.9897570610046387
Validation loss: 1.9762229227250623

Epoch: 6| Step: 10
Training loss: 2.219095230102539
Validation loss: 1.9809807936350505

Epoch: 6| Step: 11
Training loss: 1.9902809858322144
Validation loss: 1.974427173214574

Epoch: 6| Step: 12
Training loss: 2.9215400218963623
Validation loss: 1.961738149325053

Epoch: 6| Step: 13
Training loss: 2.382798910140991
Validation loss: 1.984674451171711

Epoch: 39| Step: 0
Training loss: 2.2186474800109863
Validation loss: 1.9833190723132061

Epoch: 6| Step: 1
Training loss: 2.472651958465576
Validation loss: 1.9815029277596423

Epoch: 6| Step: 2
Training loss: 2.4728541374206543
Validation loss: 1.993218478336129

Epoch: 6| Step: 3
Training loss: 1.8434581756591797
Validation loss: 1.9715258434254637

Epoch: 6| Step: 4
Training loss: 2.704447031021118
Validation loss: 1.9729126704636442

Epoch: 6| Step: 5
Training loss: 2.436624050140381
Validation loss: 1.9851560451651131

Epoch: 6| Step: 6
Training loss: 2.294269323348999
Validation loss: 1.9778632681856874

Epoch: 6| Step: 7
Training loss: 2.2248458862304688
Validation loss: 1.968893930476199

Epoch: 6| Step: 8
Training loss: 2.7096168994903564
Validation loss: 1.9677343009620585

Epoch: 6| Step: 9
Training loss: 2.3641304969787598
Validation loss: 1.963072935740153

Epoch: 6| Step: 10
Training loss: 1.989645004272461
Validation loss: 1.952418424749887

Epoch: 6| Step: 11
Training loss: 2.1506710052490234
Validation loss: 1.9794926412643925

Epoch: 6| Step: 12
Training loss: 2.2063539028167725
Validation loss: 1.9709872238097652

Epoch: 6| Step: 13
Training loss: 2.432184934616089
Validation loss: 1.9680267431402718

Epoch: 40| Step: 0
Training loss: 2.677870750427246
Validation loss: 1.9668729100176083

Epoch: 6| Step: 1
Training loss: 2.1926143169403076
Validation loss: 1.9629148744767713

Epoch: 6| Step: 2
Training loss: 2.1482982635498047
Validation loss: 1.9748190128675072

Epoch: 6| Step: 3
Training loss: 2.116528272628784
Validation loss: 1.9603628830243183

Epoch: 6| Step: 4
Training loss: 2.2981982231140137
Validation loss: 1.9678562020742765

Epoch: 6| Step: 5
Training loss: 2.05145263671875
Validation loss: 1.9561491986756683

Epoch: 6| Step: 6
Training loss: 2.4010887145996094
Validation loss: 1.9833890648298367

Epoch: 6| Step: 7
Training loss: 1.9662020206451416
Validation loss: 1.9697348046046432

Epoch: 6| Step: 8
Training loss: 2.724813222885132
Validation loss: 1.9598833078979163

Epoch: 6| Step: 9
Training loss: 1.7001888751983643
Validation loss: 1.9612047185180008

Epoch: 6| Step: 10
Training loss: 2.7890965938568115
Validation loss: 1.9535786259558894

Epoch: 6| Step: 11
Training loss: 2.303851842880249
Validation loss: 1.965477547337932

Epoch: 6| Step: 12
Training loss: 2.625070095062256
Validation loss: 1.95690086964638

Epoch: 6| Step: 13
Training loss: 2.5488319396972656
Validation loss: 1.9640248193535754

Epoch: 41| Step: 0
Training loss: 1.8907665014266968
Validation loss: 1.956442500955315

Epoch: 6| Step: 1
Training loss: 2.611666202545166
Validation loss: 1.9511537513425272

Epoch: 6| Step: 2
Training loss: 2.343780517578125
Validation loss: 1.9639613295114169

Epoch: 6| Step: 3
Training loss: 2.2783827781677246
Validation loss: 1.9599923984978789

Epoch: 6| Step: 4
Training loss: 2.18143367767334
Validation loss: 1.9784636561588576

Epoch: 6| Step: 5
Training loss: 2.154096841812134
Validation loss: 1.961356548852818

Epoch: 6| Step: 6
Training loss: 2.646299362182617
Validation loss: 1.9646141862356534

Epoch: 6| Step: 7
Training loss: 1.9320467710494995
Validation loss: 1.9846421287905784

Epoch: 6| Step: 8
Training loss: 2.088228702545166
Validation loss: 1.9705876483712146

Epoch: 6| Step: 9
Training loss: 2.2412257194519043
Validation loss: 1.9698446322512884

Epoch: 6| Step: 10
Training loss: 2.2736310958862305
Validation loss: 1.948006578671035

Epoch: 6| Step: 11
Training loss: 2.7980544567108154
Validation loss: 1.9588426877093572

Epoch: 6| Step: 12
Training loss: 2.754948377609253
Validation loss: 1.9486582612478605

Epoch: 6| Step: 13
Training loss: 2.2218070030212402
Validation loss: 1.9509898821512859

Epoch: 42| Step: 0
Training loss: 2.0610299110412598
Validation loss: 1.9510527003195979

Epoch: 6| Step: 1
Training loss: 1.8878775835037231
Validation loss: 1.963987474800438

Epoch: 6| Step: 2
Training loss: 2.2597079277038574
Validation loss: 1.9576662112307806

Epoch: 6| Step: 3
Training loss: 2.1603615283966064
Validation loss: 1.96281958523617

Epoch: 6| Step: 4
Training loss: 1.9860173463821411
Validation loss: 1.9627189584957656

Epoch: 6| Step: 5
Training loss: 3.051481246948242
Validation loss: 1.9613652536945958

Epoch: 6| Step: 6
Training loss: 2.1084747314453125
Validation loss: 1.954388008322767

Epoch: 6| Step: 7
Training loss: 2.0486855506896973
Validation loss: 1.973920109451458

Epoch: 6| Step: 8
Training loss: 2.235015630722046
Validation loss: 1.9570530435090423

Epoch: 6| Step: 9
Training loss: 2.7695462703704834
Validation loss: 1.9557054504271476

Epoch: 6| Step: 10
Training loss: 2.5492706298828125
Validation loss: 1.9512196458796018

Epoch: 6| Step: 11
Training loss: 2.5562403202056885
Validation loss: 1.980018384994999

Epoch: 6| Step: 12
Training loss: 2.4360804557800293
Validation loss: 1.9674043527213476

Epoch: 6| Step: 13
Training loss: 2.1242055892944336
Validation loss: 1.9632422129313152

Epoch: 43| Step: 0
Training loss: 2.8003923892974854
Validation loss: 1.960202306829473

Epoch: 6| Step: 1
Training loss: 1.7484087944030762
Validation loss: 1.9614168649078698

Epoch: 6| Step: 2
Training loss: 2.559278964996338
Validation loss: 1.9754187522395965

Epoch: 6| Step: 3
Training loss: 1.6144053936004639
Validation loss: 1.9607824151233961

Epoch: 6| Step: 4
Training loss: 2.9931859970092773
Validation loss: 1.9806604628921838

Epoch: 6| Step: 5
Training loss: 2.6568822860717773
Validation loss: 1.9621841484500515

Epoch: 6| Step: 6
Training loss: 2.0430779457092285
Validation loss: 1.9801605375864173

Epoch: 6| Step: 7
Training loss: 1.999964952468872
Validation loss: 1.9621865390449442

Epoch: 6| Step: 8
Training loss: 1.9465466737747192
Validation loss: 1.9785569534506848

Epoch: 6| Step: 9
Training loss: 2.6104018688201904
Validation loss: 1.9802761744427424

Epoch: 6| Step: 10
Training loss: 2.2714035511016846
Validation loss: 1.9677486086404452

Epoch: 6| Step: 11
Training loss: 2.260418653488159
Validation loss: 1.9820038516034362

Epoch: 6| Step: 12
Training loss: 2.352367877960205
Validation loss: 1.9703534469809583

Epoch: 6| Step: 13
Training loss: 2.323941707611084
Validation loss: 1.9547169118799188

Epoch: 44| Step: 0
Training loss: 2.487022876739502
Validation loss: 1.9595672007529967

Epoch: 6| Step: 1
Training loss: 2.8408966064453125
Validation loss: 1.949102855497791

Epoch: 6| Step: 2
Training loss: 2.1246397495269775
Validation loss: 1.9592772324879963

Epoch: 6| Step: 3
Training loss: 2.1019654273986816
Validation loss: 1.977185950484327

Epoch: 6| Step: 4
Training loss: 2.541471004486084
Validation loss: 1.9649528893091346

Epoch: 6| Step: 5
Training loss: 2.1477887630462646
Validation loss: 1.9574911184208368

Epoch: 6| Step: 6
Training loss: 2.847646713256836
Validation loss: 1.9505228714276386

Epoch: 6| Step: 7
Training loss: 1.8778820037841797
Validation loss: 1.9453265026051512

Epoch: 6| Step: 8
Training loss: 1.7991571426391602
Validation loss: 1.9656155699042863

Epoch: 6| Step: 9
Training loss: 2.337799072265625
Validation loss: 1.9389258097576838

Epoch: 6| Step: 10
Training loss: 2.265968084335327
Validation loss: 1.951890436551904

Epoch: 6| Step: 11
Training loss: 2.644097328186035
Validation loss: 1.9421081004604217

Epoch: 6| Step: 12
Training loss: 2.11795711517334
Validation loss: 1.9695765587591356

Epoch: 6| Step: 13
Training loss: 1.8306909799575806
Validation loss: 1.9581192642129877

Epoch: 45| Step: 0
Training loss: 2.036510944366455
Validation loss: 1.9651067551746164

Epoch: 6| Step: 1
Training loss: 1.9450905323028564
Validation loss: 1.9591652885560067

Epoch: 6| Step: 2
Training loss: 2.8680777549743652
Validation loss: 1.9538214424605012

Epoch: 6| Step: 3
Training loss: 2.320319652557373
Validation loss: 1.960668404897054

Epoch: 6| Step: 4
Training loss: 2.759352922439575
Validation loss: 1.9483159575411069

Epoch: 6| Step: 5
Training loss: 1.6914117336273193
Validation loss: 1.9293935439919914

Epoch: 6| Step: 6
Training loss: 2.3469672203063965
Validation loss: 1.9461231334235078

Epoch: 6| Step: 7
Training loss: 2.139699935913086
Validation loss: 1.9448356525872343

Epoch: 6| Step: 8
Training loss: 2.1617889404296875
Validation loss: 1.9394348449604486

Epoch: 6| Step: 9
Training loss: 2.2583112716674805
Validation loss: 1.9404713825512958

Epoch: 6| Step: 10
Training loss: 2.373042583465576
Validation loss: 1.932518848808863

Epoch: 6| Step: 11
Training loss: 2.1950974464416504
Validation loss: 1.93440245556575

Epoch: 6| Step: 12
Training loss: 1.9213100671768188
Validation loss: 1.9367365721733338

Epoch: 6| Step: 13
Training loss: 3.578834056854248
Validation loss: 1.9411386661632086

Epoch: 46| Step: 0
Training loss: 2.9604651927948
Validation loss: 1.9463742407419349

Epoch: 6| Step: 1
Training loss: 2.042008399963379
Validation loss: 1.9556583896760018

Epoch: 6| Step: 2
Training loss: 1.8949947357177734
Validation loss: 1.938742672243426

Epoch: 6| Step: 3
Training loss: 1.5967137813568115
Validation loss: 1.9643236667879167

Epoch: 6| Step: 4
Training loss: 2.325929641723633
Validation loss: 1.9397615271229898

Epoch: 6| Step: 5
Training loss: 2.551943778991699
Validation loss: 1.9400951029151998

Epoch: 6| Step: 6
Training loss: 2.9083220958709717
Validation loss: 1.9500127453957834

Epoch: 6| Step: 7
Training loss: 2.389648914337158
Validation loss: 1.9577809636310866

Epoch: 6| Step: 8
Training loss: 1.6738957166671753
Validation loss: 1.9637141625086467

Epoch: 6| Step: 9
Training loss: 2.321168899536133
Validation loss: 1.9476119497770905

Epoch: 6| Step: 10
Training loss: 2.3020668029785156
Validation loss: 1.9566328320451962

Epoch: 6| Step: 11
Training loss: 2.7598206996917725
Validation loss: 1.9636307121605001

Epoch: 6| Step: 12
Training loss: 2.224487781524658
Validation loss: 1.9385889896782496

Epoch: 6| Step: 13
Training loss: 2.118673801422119
Validation loss: 1.9555111995307348

Epoch: 47| Step: 0
Training loss: 1.9370579719543457
Validation loss: 1.9424071491405528

Epoch: 6| Step: 1
Training loss: 2.2731332778930664
Validation loss: 1.9620175874361427

Epoch: 6| Step: 2
Training loss: 2.3260021209716797
Validation loss: 1.9666782040749826

Epoch: 6| Step: 3
Training loss: 2.7403945922851562
Validation loss: 1.9597452622587963

Epoch: 6| Step: 4
Training loss: 2.6708362102508545
Validation loss: 1.9653730802638556

Epoch: 6| Step: 5
Training loss: 2.3671064376831055
Validation loss: 1.9309657504481654

Epoch: 6| Step: 6
Training loss: 1.8913427591323853
Validation loss: 1.9637502188323646

Epoch: 6| Step: 7
Training loss: 2.2796669006347656
Validation loss: 1.957772393380442

Epoch: 6| Step: 8
Training loss: 2.6296873092651367
Validation loss: 1.9666625376670592

Epoch: 6| Step: 9
Training loss: 2.313920259475708
Validation loss: 1.934845955141129

Epoch: 6| Step: 10
Training loss: 1.6410281658172607
Validation loss: 1.954838316927674

Epoch: 6| Step: 11
Training loss: 1.8958848714828491
Validation loss: 1.9463936257106003

Epoch: 6| Step: 12
Training loss: 2.6268393993377686
Validation loss: 1.95772296895263

Epoch: 6| Step: 13
Training loss: 2.380671262741089
Validation loss: 1.9395615759716238

Epoch: 48| Step: 0
Training loss: 2.8254218101501465
Validation loss: 1.9636989575560375

Epoch: 6| Step: 1
Training loss: 1.8088287115097046
Validation loss: 1.951733059780572

Epoch: 6| Step: 2
Training loss: 2.285193920135498
Validation loss: 1.9556938691805767

Epoch: 6| Step: 3
Training loss: 1.8542678356170654
Validation loss: 1.9496947129567463

Epoch: 6| Step: 4
Training loss: 2.7532882690429688
Validation loss: 1.943542403559531

Epoch: 6| Step: 5
Training loss: 1.7789109945297241
Validation loss: 1.9605888782009002

Epoch: 6| Step: 6
Training loss: 2.1647496223449707
Validation loss: 1.9369269545360277

Epoch: 6| Step: 7
Training loss: 2.149829864501953
Validation loss: 1.943023850840907

Epoch: 6| Step: 8
Training loss: 2.1954944133758545
Validation loss: 1.9575293448663527

Epoch: 6| Step: 9
Training loss: 2.4370999336242676
Validation loss: 1.9514598449071248

Epoch: 6| Step: 10
Training loss: 2.670126438140869
Validation loss: 1.9613300433722876

Epoch: 6| Step: 11
Training loss: 2.1437621116638184
Validation loss: 1.9518900148330196

Epoch: 6| Step: 12
Training loss: 2.167832851409912
Validation loss: 1.9542294804767897

Epoch: 6| Step: 13
Training loss: 2.828545093536377
Validation loss: 1.9447768529256184

Epoch: 49| Step: 0
Training loss: 2.8871142864227295
Validation loss: 1.9414283562732

Epoch: 6| Step: 1
Training loss: 1.6193784475326538
Validation loss: 1.957272316819878

Epoch: 6| Step: 2
Training loss: 1.5224096775054932
Validation loss: 1.9464120185503395

Epoch: 6| Step: 3
Training loss: 2.333421230316162
Validation loss: 1.9496819088535924

Epoch: 6| Step: 4
Training loss: 2.2538185119628906
Validation loss: 1.9576873715205858

Epoch: 6| Step: 5
Training loss: 2.374000072479248
Validation loss: 1.9647070028448617

Epoch: 6| Step: 6
Training loss: 2.0079140663146973
Validation loss: 1.962808075771537

Epoch: 6| Step: 7
Training loss: 1.9912514686584473
Validation loss: 1.9715245718597083

Epoch: 6| Step: 8
Training loss: 2.2621350288391113
Validation loss: 1.958983459780293

Epoch: 6| Step: 9
Training loss: 1.8516631126403809
Validation loss: 1.9735408906013734

Epoch: 6| Step: 10
Training loss: 3.0274319648742676
Validation loss: 1.9515621739049112

Epoch: 6| Step: 11
Training loss: 2.8180501461029053
Validation loss: 1.97536773579095

Epoch: 6| Step: 12
Training loss: 2.6501660346984863
Validation loss: 1.9681366464143157

Epoch: 6| Step: 13
Training loss: 2.1943647861480713
Validation loss: 1.9632215602423555

Epoch: 50| Step: 0
Training loss: 2.6535627841949463
Validation loss: 1.9778871267072615

Epoch: 6| Step: 1
Training loss: 2.432738780975342
Validation loss: 1.9687869330888152

Epoch: 6| Step: 2
Training loss: 2.3481502532958984
Validation loss: 1.957896440259872

Epoch: 6| Step: 3
Training loss: 2.744716167449951
Validation loss: 1.9555654756484493

Epoch: 6| Step: 4
Training loss: 2.0881500244140625
Validation loss: 1.9455505109602405

Epoch: 6| Step: 5
Training loss: 2.3344106674194336
Validation loss: 1.9497363413533857

Epoch: 6| Step: 6
Training loss: 2.091672897338867
Validation loss: 1.951500629865995

Epoch: 6| Step: 7
Training loss: 1.8877694606781006
Validation loss: 1.9491836435051375

Epoch: 6| Step: 8
Training loss: 2.128908634185791
Validation loss: 1.956027074526715

Epoch: 6| Step: 9
Training loss: 1.867445707321167
Validation loss: 1.9499746073958695

Epoch: 6| Step: 10
Training loss: 1.6770014762878418
Validation loss: 1.9550771097983084

Epoch: 6| Step: 11
Training loss: 2.1165695190429688
Validation loss: 1.9555075309609855

Epoch: 6| Step: 12
Training loss: 2.3358640670776367
Validation loss: 1.9459035473485147

Epoch: 6| Step: 13
Training loss: 3.640763282775879
Validation loss: 1.9558959468718498

Epoch: 51| Step: 0
Training loss: 1.6811869144439697
Validation loss: 1.955554114874973

Epoch: 6| Step: 1
Training loss: 2.2436838150024414
Validation loss: 1.938295961708151

Epoch: 6| Step: 2
Training loss: 2.4792675971984863
Validation loss: 1.9514728694833734

Epoch: 6| Step: 3
Training loss: 2.3694851398468018
Validation loss: 1.939051543512652

Epoch: 6| Step: 4
Training loss: 2.6626029014587402
Validation loss: 1.9504072268803914

Epoch: 6| Step: 5
Training loss: 2.146515130996704
Validation loss: 1.932428680440431

Epoch: 6| Step: 6
Training loss: 2.6917357444763184
Validation loss: 1.9362429803417576

Epoch: 6| Step: 7
Training loss: 1.8070471286773682
Validation loss: 1.9532746807221444

Epoch: 6| Step: 8
Training loss: 2.1065478324890137
Validation loss: 1.9434202178832023

Epoch: 6| Step: 9
Training loss: 1.6812633275985718
Validation loss: 1.9269884376115696

Epoch: 6| Step: 10
Training loss: 2.3314104080200195
Validation loss: 1.9281360949239423

Epoch: 6| Step: 11
Training loss: 2.975998640060425
Validation loss: 1.93859770477459

Epoch: 6| Step: 12
Training loss: 2.2786340713500977
Validation loss: 1.92755598919366

Epoch: 6| Step: 13
Training loss: 2.07369065284729
Validation loss: 1.944849197582532

Epoch: 52| Step: 0
Training loss: 1.9559955596923828
Validation loss: 1.9359787087286673

Epoch: 6| Step: 1
Training loss: 1.7756626605987549
Validation loss: 1.9518990747390255

Epoch: 6| Step: 2
Training loss: 2.2287051677703857
Validation loss: 1.9427942537492322

Epoch: 6| Step: 3
Training loss: 1.7213287353515625
Validation loss: 1.9457280379469677

Epoch: 6| Step: 4
Training loss: 2.1883625984191895
Validation loss: 1.949036176486682

Epoch: 6| Step: 5
Training loss: 2.1958112716674805
Validation loss: 1.9431446277967064

Epoch: 6| Step: 6
Training loss: 2.555990695953369
Validation loss: 1.9300402582332652

Epoch: 6| Step: 7
Training loss: 2.4157280921936035
Validation loss: 1.930624000487789

Epoch: 6| Step: 8
Training loss: 1.8703410625457764
Validation loss: 1.9412949879964192

Epoch: 6| Step: 9
Training loss: 2.3744699954986572
Validation loss: 1.925713421196066

Epoch: 6| Step: 10
Training loss: 2.371610641479492
Validation loss: 1.9449553066684353

Epoch: 6| Step: 11
Training loss: 2.6543445587158203
Validation loss: 1.9481535932069183

Epoch: 6| Step: 12
Training loss: 3.081904172897339
Validation loss: 1.941108508776593

Epoch: 6| Step: 13
Training loss: 2.3240561485290527
Validation loss: 1.943822164689341

Epoch: 53| Step: 0
Training loss: 1.628170132637024
Validation loss: 1.946317336892569

Epoch: 6| Step: 1
Training loss: 2.2418980598449707
Validation loss: 1.9335801985956007

Epoch: 6| Step: 2
Training loss: 2.2586259841918945
Validation loss: 1.9440787876805952

Epoch: 6| Step: 3
Training loss: 2.6653590202331543
Validation loss: 1.9354423963895409

Epoch: 6| Step: 4
Training loss: 2.484462261199951
Validation loss: 1.9448343092395413

Epoch: 6| Step: 5
Training loss: 2.8938822746276855
Validation loss: 1.949074440104987

Epoch: 6| Step: 6
Training loss: 1.7842086553573608
Validation loss: 1.943649717556533

Epoch: 6| Step: 7
Training loss: 2.0801520347595215
Validation loss: 1.9262274657526324

Epoch: 6| Step: 8
Training loss: 2.4903671741485596
Validation loss: 1.953746493144702

Epoch: 6| Step: 9
Training loss: 2.618319511413574
Validation loss: 1.9295879012794905

Epoch: 6| Step: 10
Training loss: 1.8823246955871582
Validation loss: 1.9302635244143906

Epoch: 6| Step: 11
Training loss: 2.4530279636383057
Validation loss: 1.918049253443236

Epoch: 6| Step: 12
Training loss: 2.183838129043579
Validation loss: 1.934304137383738

Epoch: 6| Step: 13
Training loss: 1.47303307056427
Validation loss: 1.933505505643865

Epoch: 54| Step: 0
Training loss: 2.852933883666992
Validation loss: 1.9335285655913814

Epoch: 6| Step: 1
Training loss: 2.3149971961975098
Validation loss: 1.9271715302621164

Epoch: 6| Step: 2
Training loss: 2.5554327964782715
Validation loss: 1.9205311382970502

Epoch: 6| Step: 3
Training loss: 1.6522409915924072
Validation loss: 1.9339010689848213

Epoch: 6| Step: 4
Training loss: 2.3068952560424805
Validation loss: 1.9238899997485581

Epoch: 6| Step: 5
Training loss: 2.1397194862365723
Validation loss: 1.9317049826345136

Epoch: 6| Step: 6
Training loss: 1.912852168083191
Validation loss: 1.9223659064180108

Epoch: 6| Step: 7
Training loss: 2.385097026824951
Validation loss: 1.9283884366353352

Epoch: 6| Step: 8
Training loss: 2.2480788230895996
Validation loss: 1.9224086474346858

Epoch: 6| Step: 9
Training loss: 2.152620792388916
Validation loss: 1.9179698421109108

Epoch: 6| Step: 10
Training loss: 2.28743839263916
Validation loss: 1.9273567532980314

Epoch: 6| Step: 11
Training loss: 2.6819992065429688
Validation loss: 1.9337054914043796

Epoch: 6| Step: 12
Training loss: 1.9452579021453857
Validation loss: 1.9387524358687862

Epoch: 6| Step: 13
Training loss: 1.8485018014907837
Validation loss: 1.9122265538861674

Epoch: 55| Step: 0
Training loss: 1.8719977140426636
Validation loss: 1.935197353363037

Epoch: 6| Step: 1
Training loss: 2.427525520324707
Validation loss: 1.9382395385414042

Epoch: 6| Step: 2
Training loss: 1.7751514911651611
Validation loss: 1.9343717918601087

Epoch: 6| Step: 3
Training loss: 3.121441602706909
Validation loss: 1.9286488525329097

Epoch: 6| Step: 4
Training loss: 2.2269320487976074
Validation loss: 1.9312368387817054

Epoch: 6| Step: 5
Training loss: 2.813462734222412
Validation loss: 1.9166392818573983

Epoch: 6| Step: 6
Training loss: 1.8464878797531128
Validation loss: 1.9449627027716687

Epoch: 6| Step: 7
Training loss: 2.2991690635681152
Validation loss: 1.9598863740121164

Epoch: 6| Step: 8
Training loss: 2.3122644424438477
Validation loss: 1.9235315835604103

Epoch: 6| Step: 9
Training loss: 2.1541571617126465
Validation loss: 1.9368004965525802

Epoch: 6| Step: 10
Training loss: 2.421903133392334
Validation loss: 1.9364761280757126

Epoch: 6| Step: 11
Training loss: 2.122598171234131
Validation loss: 1.9365505556906424

Epoch: 6| Step: 12
Training loss: 1.8791611194610596
Validation loss: 1.9287579033964424

Epoch: 6| Step: 13
Training loss: 2.3623111248016357
Validation loss: 1.9496995108101958

Epoch: 56| Step: 0
Training loss: 1.9956215620040894
Validation loss: 1.9108617856938352

Epoch: 6| Step: 1
Training loss: 1.8665220737457275
Validation loss: 1.93267547956077

Epoch: 6| Step: 2
Training loss: 2.088700294494629
Validation loss: 1.9334691519378333

Epoch: 6| Step: 3
Training loss: 2.328826904296875
Validation loss: 1.934179429085024

Epoch: 6| Step: 4
Training loss: 2.1122334003448486
Validation loss: 1.9363910933976531

Epoch: 6| Step: 5
Training loss: 2.673035144805908
Validation loss: 1.934791422659351

Epoch: 6| Step: 6
Training loss: 2.427700996398926
Validation loss: 1.9276938156415058

Epoch: 6| Step: 7
Training loss: 2.2666239738464355
Validation loss: 1.9201585092852194

Epoch: 6| Step: 8
Training loss: 1.7887325286865234
Validation loss: 1.9276636646639915

Epoch: 6| Step: 9
Training loss: 2.564802408218384
Validation loss: 1.9283020496368408

Epoch: 6| Step: 10
Training loss: 2.4218292236328125
Validation loss: 1.9359530941132577

Epoch: 6| Step: 11
Training loss: 2.1112422943115234
Validation loss: 1.9150632478857552

Epoch: 6| Step: 12
Training loss: 2.4505369663238525
Validation loss: 1.9370817035757086

Epoch: 6| Step: 13
Training loss: 2.3001320362091064
Validation loss: 1.9435565446012764

Epoch: 57| Step: 0
Training loss: 2.052077293395996
Validation loss: 1.9446958290633334

Epoch: 6| Step: 1
Training loss: 2.0245742797851562
Validation loss: 1.9241224681177447

Epoch: 6| Step: 2
Training loss: 2.5526723861694336
Validation loss: 1.9359284011266564

Epoch: 6| Step: 3
Training loss: 2.340717315673828
Validation loss: 1.9210807610583562

Epoch: 6| Step: 4
Training loss: 2.1851985454559326
Validation loss: 1.9458620253429617

Epoch: 6| Step: 5
Training loss: 2.5290870666503906
Validation loss: 1.9275117407562912

Epoch: 6| Step: 6
Training loss: 2.183596611022949
Validation loss: 1.936991778753137

Epoch: 6| Step: 7
Training loss: 2.1304399967193604
Validation loss: 1.9418881388120754

Epoch: 6| Step: 8
Training loss: 2.5406107902526855
Validation loss: 1.9362312568131315

Epoch: 6| Step: 9
Training loss: 1.9291797876358032
Validation loss: 1.9347375592877787

Epoch: 6| Step: 10
Training loss: 2.6413938999176025
Validation loss: 1.9189210643050492

Epoch: 6| Step: 11
Training loss: 1.5251243114471436
Validation loss: 1.9323769769360941

Epoch: 6| Step: 12
Training loss: 2.2604126930236816
Validation loss: 1.9445589691080072

Epoch: 6| Step: 13
Training loss: 2.335205078125
Validation loss: 1.9294468895081551

Epoch: 58| Step: 0
Training loss: 2.8731637001037598
Validation loss: 1.9339148267622916

Epoch: 6| Step: 1
Training loss: 1.97005033493042
Validation loss: 1.9358646587658954

Epoch: 6| Step: 2
Training loss: 1.9481894969940186
Validation loss: 1.9405150105876308

Epoch: 6| Step: 3
Training loss: 2.027141809463501
Validation loss: 1.928426802799266

Epoch: 6| Step: 4
Training loss: 2.007791042327881
Validation loss: 1.9499849311767086

Epoch: 6| Step: 5
Training loss: 1.5431605577468872
Validation loss: 1.9411659368904688

Epoch: 6| Step: 6
Training loss: 2.2670326232910156
Validation loss: 1.935390732621634

Epoch: 6| Step: 7
Training loss: 2.8519535064697266
Validation loss: 1.9379319760107225

Epoch: 6| Step: 8
Training loss: 2.0446057319641113
Validation loss: 1.9231660904422883

Epoch: 6| Step: 9
Training loss: 1.9913699626922607
Validation loss: 1.9236257768446399

Epoch: 6| Step: 10
Training loss: 2.5774450302124023
Validation loss: 1.936652034841558

Epoch: 6| Step: 11
Training loss: 2.8238043785095215
Validation loss: 1.9271629138659405

Epoch: 6| Step: 12
Training loss: 2.3136541843414307
Validation loss: 1.9299552466279717

Epoch: 6| Step: 13
Training loss: 2.0155177116394043
Validation loss: 1.9247919667151667

Epoch: 59| Step: 0
Training loss: 1.9177775382995605
Validation loss: 1.9396181427022463

Epoch: 6| Step: 1
Training loss: 2.414607048034668
Validation loss: 1.9133559337226294

Epoch: 6| Step: 2
Training loss: 2.566460371017456
Validation loss: 1.9276486571117113

Epoch: 6| Step: 3
Training loss: 2.2176880836486816
Validation loss: 1.9492394924163818

Epoch: 6| Step: 4
Training loss: 2.4620673656463623
Validation loss: 1.9267830361602127

Epoch: 6| Step: 5
Training loss: 2.140399694442749
Validation loss: 1.9374715576889694

Epoch: 6| Step: 6
Training loss: 2.3226001262664795
Validation loss: 1.9355892212160173

Epoch: 6| Step: 7
Training loss: 2.3653130531311035
Validation loss: 1.911278800297809

Epoch: 6| Step: 8
Training loss: 2.4331634044647217
Validation loss: 1.9214869391533635

Epoch: 6| Step: 9
Training loss: 1.959809422492981
Validation loss: 1.9478708390266664

Epoch: 6| Step: 10
Training loss: 1.874146819114685
Validation loss: 1.9319717396972

Epoch: 6| Step: 11
Training loss: 2.03765869140625
Validation loss: 1.9480731666729014

Epoch: 6| Step: 12
Training loss: 1.996172308921814
Validation loss: 1.9550152453043128

Epoch: 6| Step: 13
Training loss: 2.628417491912842
Validation loss: 1.9388198698720625

Epoch: 60| Step: 0
Training loss: 1.6072548627853394
Validation loss: 1.9379900706711637

Epoch: 6| Step: 1
Training loss: 2.604163646697998
Validation loss: 1.9264307791186916

Epoch: 6| Step: 2
Training loss: 2.247676134109497
Validation loss: 1.938053479758642

Epoch: 6| Step: 3
Training loss: 2.213545083999634
Validation loss: 1.9360869687090638

Epoch: 6| Step: 4
Training loss: 2.7949843406677246
Validation loss: 1.9304437342510428

Epoch: 6| Step: 5
Training loss: 1.8850449323654175
Validation loss: 1.932475600191342

Epoch: 6| Step: 6
Training loss: 2.6309268474578857
Validation loss: 1.9435643816506991

Epoch: 6| Step: 7
Training loss: 2.0186338424682617
Validation loss: 1.9443754278203493

Epoch: 6| Step: 8
Training loss: 2.8194665908813477
Validation loss: 1.9325975987219042

Epoch: 6| Step: 9
Training loss: 1.7835335731506348
Validation loss: 1.9153274977079002

Epoch: 6| Step: 10
Training loss: 1.9291855096817017
Validation loss: 1.937172019353477

Epoch: 6| Step: 11
Training loss: 2.462409734725952
Validation loss: 1.9187932200329278

Epoch: 6| Step: 12
Training loss: 2.2385408878326416
Validation loss: 1.935036418258503

Epoch: 6| Step: 13
Training loss: 1.700947880744934
Validation loss: 1.9351517308142878

Epoch: 61| Step: 0
Training loss: 1.6476677656173706
Validation loss: 1.9341719740180559

Epoch: 6| Step: 1
Training loss: 2.241712808609009
Validation loss: 1.9340627577997023

Epoch: 6| Step: 2
Training loss: 2.5191831588745117
Validation loss: 1.9291947298152472

Epoch: 6| Step: 3
Training loss: 2.468963623046875
Validation loss: 1.9257617278765606

Epoch: 6| Step: 4
Training loss: 1.6380993127822876
Validation loss: 1.910598893319407

Epoch: 6| Step: 5
Training loss: 1.7891901731491089
Validation loss: 1.9250069843825472

Epoch: 6| Step: 6
Training loss: 2.1956303119659424
Validation loss: 1.9084571433323685

Epoch: 6| Step: 7
Training loss: 3.0145068168640137
Validation loss: 1.9113317253769084

Epoch: 6| Step: 8
Training loss: 2.3998594284057617
Validation loss: 1.934989244707169

Epoch: 6| Step: 9
Training loss: 2.2931411266326904
Validation loss: 1.906355106702415

Epoch: 6| Step: 10
Training loss: 2.037599802017212
Validation loss: 1.9126903472408172

Epoch: 6| Step: 11
Training loss: 2.044063091278076
Validation loss: 1.9193771910923783

Epoch: 6| Step: 12
Training loss: 2.6959869861602783
Validation loss: 1.9045828068128197

Epoch: 6| Step: 13
Training loss: 2.0602314472198486
Validation loss: 1.917489710674491

Epoch: 62| Step: 0
Training loss: 1.9743304252624512
Validation loss: 1.9115917733920518

Epoch: 6| Step: 1
Training loss: 1.7112488746643066
Validation loss: 1.9135230971920876

Epoch: 6| Step: 2
Training loss: 2.6997392177581787
Validation loss: 1.9287331963098178

Epoch: 6| Step: 3
Training loss: 2.4080235958099365
Validation loss: 1.9189272003789102

Epoch: 6| Step: 4
Training loss: 1.7020740509033203
Validation loss: 1.8995336550538258

Epoch: 6| Step: 5
Training loss: 1.9178483486175537
Validation loss: 1.9108488944268995

Epoch: 6| Step: 6
Training loss: 2.792793035507202
Validation loss: 1.9247253710223782

Epoch: 6| Step: 7
Training loss: 2.5607123374938965
Validation loss: 1.9219835829991165

Epoch: 6| Step: 8
Training loss: 2.3663759231567383
Validation loss: 1.908919165211339

Epoch: 6| Step: 9
Training loss: 2.6381068229675293
Validation loss: 1.9217894525938137

Epoch: 6| Step: 10
Training loss: 1.7057509422302246
Validation loss: 1.9181118857476018

Epoch: 6| Step: 11
Training loss: 1.3640550374984741
Validation loss: 1.8892120187000563

Epoch: 6| Step: 12
Training loss: 2.428393602371216
Validation loss: 1.9214666581922961

Epoch: 6| Step: 13
Training loss: 3.1623568534851074
Validation loss: 1.927623269378498

Epoch: 63| Step: 0
Training loss: 2.441453218460083
Validation loss: 1.9156542695978636

Epoch: 6| Step: 1
Training loss: 2.67421817779541
Validation loss: 1.9151454535863732

Epoch: 6| Step: 2
Training loss: 2.610405921936035
Validation loss: 1.9163149928533902

Epoch: 6| Step: 3
Training loss: 1.2231228351593018
Validation loss: 1.921222852122399

Epoch: 6| Step: 4
Training loss: 1.9647789001464844
Validation loss: 1.9184172871292278

Epoch: 6| Step: 5
Training loss: 2.079990863800049
Validation loss: 1.9402750563877884

Epoch: 6| Step: 6
Training loss: 1.9308691024780273
Validation loss: 1.925006979255266

Epoch: 6| Step: 7
Training loss: 1.6359153985977173
Validation loss: 1.9122114745519494

Epoch: 6| Step: 8
Training loss: 2.3992691040039062
Validation loss: 1.9119516944372525

Epoch: 6| Step: 9
Training loss: 2.641474723815918
Validation loss: 1.924362144162578

Epoch: 6| Step: 10
Training loss: 2.132035970687866
Validation loss: 1.924116555080619

Epoch: 6| Step: 11
Training loss: 2.6008810997009277
Validation loss: 1.921710434780326

Epoch: 6| Step: 12
Training loss: 2.629058361053467
Validation loss: 1.915607636974704

Epoch: 6| Step: 13
Training loss: 2.0892579555511475
Validation loss: 1.918462340549756

Epoch: 64| Step: 0
Training loss: 1.5610034465789795
Validation loss: 1.925313667584491

Epoch: 6| Step: 1
Training loss: 2.232180118560791
Validation loss: 1.9344747938135618

Epoch: 6| Step: 2
Training loss: 2.2514448165893555
Validation loss: 1.9295528293937765

Epoch: 6| Step: 3
Training loss: 3.034029960632324
Validation loss: 1.9288803864550847

Epoch: 6| Step: 4
Training loss: 2.2152247428894043
Validation loss: 1.9146530397476689

Epoch: 6| Step: 5
Training loss: 2.3560242652893066
Validation loss: 1.9272792723871046

Epoch: 6| Step: 6
Training loss: 2.0603694915771484
Validation loss: 1.9250101863697011

Epoch: 6| Step: 7
Training loss: 2.723525285720825
Validation loss: 1.9371694800674275

Epoch: 6| Step: 8
Training loss: 1.7528698444366455
Validation loss: 1.9233260000905683

Epoch: 6| Step: 9
Training loss: 2.424377679824829
Validation loss: 1.927485586494528

Epoch: 6| Step: 10
Training loss: 2.940112590789795
Validation loss: 1.9373283450321486

Epoch: 6| Step: 11
Training loss: 1.4798164367675781
Validation loss: 1.9289666503988288

Epoch: 6| Step: 12
Training loss: 1.8430498838424683
Validation loss: 1.934405255061324

Epoch: 6| Step: 13
Training loss: 2.0797135829925537
Validation loss: 1.9464935307861657

Epoch: 65| Step: 0
Training loss: 2.099316120147705
Validation loss: 1.9380582583847867

Epoch: 6| Step: 1
Training loss: 2.4743075370788574
Validation loss: 1.9345205060897335

Epoch: 6| Step: 2
Training loss: 1.9830553531646729
Validation loss: 1.9388309089086389

Epoch: 6| Step: 3
Training loss: 2.2093405723571777
Validation loss: 1.9283243622831119

Epoch: 6| Step: 4
Training loss: 2.4837605953216553
Validation loss: 1.9316752828577513

Epoch: 6| Step: 5
Training loss: 2.3843016624450684
Validation loss: 1.9438383886891026

Epoch: 6| Step: 6
Training loss: 2.479830741882324
Validation loss: 1.940728135006402

Epoch: 6| Step: 7
Training loss: 2.005222797393799
Validation loss: 1.9611313650684972

Epoch: 6| Step: 8
Training loss: 1.9232525825500488
Validation loss: 1.9302075832120833

Epoch: 6| Step: 9
Training loss: 2.914494037628174
Validation loss: 1.9389031112834971

Epoch: 6| Step: 10
Training loss: 2.3289380073547363
Validation loss: 1.934426264096332

Epoch: 6| Step: 11
Training loss: 1.5905154943466187
Validation loss: 1.9522184184802476

Epoch: 6| Step: 12
Training loss: 1.7329599857330322
Validation loss: 1.9180286545907297

Epoch: 6| Step: 13
Training loss: 2.164017677307129
Validation loss: 1.9222821958603398

Epoch: 66| Step: 0
Training loss: 2.245715618133545
Validation loss: 1.929004881971626

Epoch: 6| Step: 1
Training loss: 2.165738821029663
Validation loss: 1.9127326280839982

Epoch: 6| Step: 2
Training loss: 1.8948500156402588
Validation loss: 1.9289189782193912

Epoch: 6| Step: 3
Training loss: 2.1884570121765137
Validation loss: 1.911946173637144

Epoch: 6| Step: 4
Training loss: 2.068854331970215
Validation loss: 1.904747337423345

Epoch: 6| Step: 5
Training loss: 2.536351203918457
Validation loss: 1.9145527514078284

Epoch: 6| Step: 6
Training loss: 2.7599403858184814
Validation loss: 1.9176876621861612

Epoch: 6| Step: 7
Training loss: 1.80736243724823
Validation loss: 1.900496902004365

Epoch: 6| Step: 8
Training loss: 2.6609435081481934
Validation loss: 1.9228199528109642

Epoch: 6| Step: 9
Training loss: 2.119385242462158
Validation loss: 1.9169629671240365

Epoch: 6| Step: 10
Training loss: 2.376262664794922
Validation loss: 1.893603653036138

Epoch: 6| Step: 11
Training loss: 2.0569252967834473
Validation loss: 1.900160220361525

Epoch: 6| Step: 12
Training loss: 1.8516123294830322
Validation loss: 1.9176199513096963

Epoch: 6| Step: 13
Training loss: 1.8782073259353638
Validation loss: 1.9143248450371526

Epoch: 67| Step: 0
Training loss: 2.261524200439453
Validation loss: 1.9157625385510024

Epoch: 6| Step: 1
Training loss: 2.665375232696533
Validation loss: 1.9089072981188375

Epoch: 6| Step: 2
Training loss: 2.1966400146484375
Validation loss: 1.9025908606026762

Epoch: 6| Step: 3
Training loss: 1.7871497869491577
Validation loss: 1.905898940178656

Epoch: 6| Step: 4
Training loss: 2.1820268630981445
Validation loss: 1.9006254198730632

Epoch: 6| Step: 5
Training loss: 2.951239585876465
Validation loss: 1.9098011947447253

Epoch: 6| Step: 6
Training loss: 1.7381283044815063
Validation loss: 1.9088039090556483

Epoch: 6| Step: 7
Training loss: 2.3326303958892822
Validation loss: 1.9029980090356642

Epoch: 6| Step: 8
Training loss: 1.8632012605667114
Validation loss: 1.9187732858042563

Epoch: 6| Step: 9
Training loss: 2.1717123985290527
Validation loss: 1.9063259017082952

Epoch: 6| Step: 10
Training loss: 2.1422677040100098
Validation loss: 1.9066306570524811

Epoch: 6| Step: 11
Training loss: 2.397128105163574
Validation loss: 1.9167120379786338

Epoch: 6| Step: 12
Training loss: 1.7057877779006958
Validation loss: 1.9113491645423315

Epoch: 6| Step: 13
Training loss: 2.646084785461426
Validation loss: 1.9259059813714796

Epoch: 68| Step: 0
Training loss: 2.1542935371398926
Validation loss: 1.9187580411152174

Epoch: 6| Step: 1
Training loss: 2.3478729724884033
Validation loss: 1.9182303836268764

Epoch: 6| Step: 2
Training loss: 1.9313989877700806
Validation loss: 1.912454967857689

Epoch: 6| Step: 3
Training loss: 2.4377527236938477
Validation loss: 1.9202555841015232

Epoch: 6| Step: 4
Training loss: 3.050416946411133
Validation loss: 1.9189211706961355

Epoch: 6| Step: 5
Training loss: 2.0080175399780273
Validation loss: 1.9247875457168908

Epoch: 6| Step: 6
Training loss: 1.3701635599136353
Validation loss: 1.922684060629978

Epoch: 6| Step: 7
Training loss: 1.6289052963256836
Validation loss: 1.9262827545083978

Epoch: 6| Step: 8
Training loss: 2.840822696685791
Validation loss: 1.9125197779747747

Epoch: 6| Step: 9
Training loss: 2.3585686683654785
Validation loss: 1.9254795210335844

Epoch: 6| Step: 10
Training loss: 1.9936938285827637
Validation loss: 1.9391602957120506

Epoch: 6| Step: 11
Training loss: 2.3746085166931152
Validation loss: 1.9191059425312986

Epoch: 6| Step: 12
Training loss: 2.4582934379577637
Validation loss: 1.929690004676901

Epoch: 6| Step: 13
Training loss: 1.5240994691848755
Validation loss: 1.914882190765873

Epoch: 69| Step: 0
Training loss: 1.9961096048355103
Validation loss: 1.9179261730563255

Epoch: 6| Step: 1
Training loss: 2.5986742973327637
Validation loss: 1.8996200715341875

Epoch: 6| Step: 2
Training loss: 1.6515247821807861
Validation loss: 1.9118121195864934

Epoch: 6| Step: 3
Training loss: 2.0368781089782715
Validation loss: 1.9276898458439817

Epoch: 6| Step: 4
Training loss: 2.0799062252044678
Validation loss: 1.9163983445013724

Epoch: 6| Step: 5
Training loss: 1.7825826406478882
Validation loss: 1.910561095001877

Epoch: 6| Step: 6
Training loss: 2.584934711456299
Validation loss: 1.9034311873938448

Epoch: 6| Step: 7
Training loss: 1.757548213005066
Validation loss: 1.9023060068007438

Epoch: 6| Step: 8
Training loss: 1.9786901473999023
Validation loss: 1.913844875110093

Epoch: 6| Step: 9
Training loss: 2.828725814819336
Validation loss: 1.9343892194891488

Epoch: 6| Step: 10
Training loss: 2.4003233909606934
Validation loss: 1.9008538697355537

Epoch: 6| Step: 11
Training loss: 2.5649118423461914
Validation loss: 1.908253223665299

Epoch: 6| Step: 12
Training loss: 2.0589475631713867
Validation loss: 1.9157566421775407

Epoch: 6| Step: 13
Training loss: 2.48671817779541
Validation loss: 1.9165737129026843

Epoch: 70| Step: 0
Training loss: 2.2070083618164062
Validation loss: 1.9175875520193448

Epoch: 6| Step: 1
Training loss: 2.324096918106079
Validation loss: 1.904376842642343

Epoch: 6| Step: 2
Training loss: 1.916085124015808
Validation loss: 1.9082361267459007

Epoch: 6| Step: 3
Training loss: 2.0068984031677246
Validation loss: 1.9124005481760988

Epoch: 6| Step: 4
Training loss: 2.7196481227874756
Validation loss: 1.8895890815283662

Epoch: 6| Step: 5
Training loss: 2.080845355987549
Validation loss: 1.9221353197610507

Epoch: 6| Step: 6
Training loss: 2.1388070583343506
Validation loss: 1.9097182699429092

Epoch: 6| Step: 7
Training loss: 1.8741233348846436
Validation loss: 1.9156156547607914

Epoch: 6| Step: 8
Training loss: 2.7044126987457275
Validation loss: 1.9039525396080428

Epoch: 6| Step: 9
Training loss: 1.9465447664260864
Validation loss: 1.9265586253135436

Epoch: 6| Step: 10
Training loss: 1.9781259298324585
Validation loss: 1.9143397551710888

Epoch: 6| Step: 11
Training loss: 2.8024039268493652
Validation loss: 1.9287271653452227

Epoch: 6| Step: 12
Training loss: 1.7663074731826782
Validation loss: 1.8941551459732877

Epoch: 6| Step: 13
Training loss: 2.0984153747558594
Validation loss: 1.9176969297470585

Epoch: 71| Step: 0
Training loss: 3.2946877479553223
Validation loss: 1.9243776285520164

Epoch: 6| Step: 1
Training loss: 1.6879658699035645
Validation loss: 1.889366747230612

Epoch: 6| Step: 2
Training loss: 2.566965341567993
Validation loss: 1.912701032494986

Epoch: 6| Step: 3
Training loss: 2.155911684036255
Validation loss: 1.9069494380745837

Epoch: 6| Step: 4
Training loss: 2.3247976303100586
Validation loss: 1.9177084289571291

Epoch: 6| Step: 5
Training loss: 2.4812889099121094
Validation loss: 1.9085219649858371

Epoch: 6| Step: 6
Training loss: 1.9886473417282104
Validation loss: 1.918552001317342

Epoch: 6| Step: 7
Training loss: 2.305116653442383
Validation loss: 1.8965762892077047

Epoch: 6| Step: 8
Training loss: 1.5515999794006348
Validation loss: 1.9304989281521048

Epoch: 6| Step: 9
Training loss: 1.8872673511505127
Validation loss: 1.9112023768886444

Epoch: 6| Step: 10
Training loss: 1.8553223609924316
Validation loss: 1.89621820885648

Epoch: 6| Step: 11
Training loss: 1.705566644668579
Validation loss: 1.9005420810432845

Epoch: 6| Step: 12
Training loss: 2.7525715827941895
Validation loss: 1.8888090438740228

Epoch: 6| Step: 13
Training loss: 1.7017178535461426
Validation loss: 1.9171009166266328

Epoch: 72| Step: 0
Training loss: 2.564695119857788
Validation loss: 1.8938005816551946

Epoch: 6| Step: 1
Training loss: 2.435173749923706
Validation loss: 1.938054528287662

Epoch: 6| Step: 2
Training loss: 2.1505470275878906
Validation loss: 1.9193281460833806

Epoch: 6| Step: 3
Training loss: 2.2958600521087646
Validation loss: 1.9102646984079832

Epoch: 6| Step: 4
Training loss: 2.9324820041656494
Validation loss: 1.9098556323718

Epoch: 6| Step: 5
Training loss: 2.0482594966888428
Validation loss: 1.9095211439235236

Epoch: 6| Step: 6
Training loss: 1.9275248050689697
Validation loss: 1.9080106814702351

Epoch: 6| Step: 7
Training loss: 2.140472650527954
Validation loss: 1.9180024259833879

Epoch: 6| Step: 8
Training loss: 2.2891626358032227
Validation loss: 1.9211781883752475

Epoch: 6| Step: 9
Training loss: 1.959916591644287
Validation loss: 1.9174138961299774

Epoch: 6| Step: 10
Training loss: 1.7650119066238403
Validation loss: 1.912048488534907

Epoch: 6| Step: 11
Training loss: 2.1075801849365234
Validation loss: 1.9225133426727787

Epoch: 6| Step: 12
Training loss: 1.9511969089508057
Validation loss: 1.9048829360674786

Epoch: 6| Step: 13
Training loss: 1.654220461845398
Validation loss: 1.8942020426514328

Epoch: 73| Step: 0
Training loss: 2.154121160507202
Validation loss: 1.9199328807092482

Epoch: 6| Step: 1
Training loss: 2.0513720512390137
Validation loss: 1.9133873678022815

Epoch: 6| Step: 2
Training loss: 2.6198503971099854
Validation loss: 1.9314050212983163

Epoch: 6| Step: 3
Training loss: 2.116988182067871
Validation loss: 1.9183764765339513

Epoch: 6| Step: 4
Training loss: 2.7028772830963135
Validation loss: 1.9196989228648524

Epoch: 6| Step: 5
Training loss: 1.543600082397461
Validation loss: 1.8986058619714552

Epoch: 6| Step: 6
Training loss: 2.3392632007598877
Validation loss: 1.9146119394610006

Epoch: 6| Step: 7
Training loss: 2.0338590145111084
Validation loss: 1.921208058634112

Epoch: 6| Step: 8
Training loss: 2.1327271461486816
Validation loss: 1.9138360792590725

Epoch: 6| Step: 9
Training loss: 2.2442569732666016
Validation loss: 1.8988939997970418

Epoch: 6| Step: 10
Training loss: 2.323972225189209
Validation loss: 1.912325821897035

Epoch: 6| Step: 11
Training loss: 1.7382454872131348
Validation loss: 1.911509524109543

Epoch: 6| Step: 12
Training loss: 2.4248085021972656
Validation loss: 1.9221243948064826

Epoch: 6| Step: 13
Training loss: 1.96590256690979
Validation loss: 1.9081938407754386

Epoch: 74| Step: 0
Training loss: 2.373830795288086
Validation loss: 1.9112344659784788

Epoch: 6| Step: 1
Training loss: 2.2373452186584473
Validation loss: 1.9102988127739198

Epoch: 6| Step: 2
Training loss: 2.055331230163574
Validation loss: 1.910156488418579

Epoch: 6| Step: 3
Training loss: 2.8577661514282227
Validation loss: 1.9063214896827616

Epoch: 6| Step: 4
Training loss: 2.0037734508514404
Validation loss: 1.9100448341779812

Epoch: 6| Step: 5
Training loss: 2.051710844039917
Validation loss: 1.9166366618166688

Epoch: 6| Step: 6
Training loss: 1.2753984928131104
Validation loss: 1.9161340959610478

Epoch: 6| Step: 7
Training loss: 1.8573858737945557
Validation loss: 1.9033310772270284

Epoch: 6| Step: 8
Training loss: 2.2845067977905273
Validation loss: 1.919530548075194

Epoch: 6| Step: 9
Training loss: 1.6983733177185059
Validation loss: 1.9131310524479035

Epoch: 6| Step: 10
Training loss: 2.5012192726135254
Validation loss: 1.8923549485462967

Epoch: 6| Step: 11
Training loss: 2.2908520698547363
Validation loss: 1.9040629876557218

Epoch: 6| Step: 12
Training loss: 2.6333985328674316
Validation loss: 1.8992551526715677

Epoch: 6| Step: 13
Training loss: 2.805535078048706
Validation loss: 1.9092383602614045

Epoch: 75| Step: 0
Training loss: 1.9638540744781494
Validation loss: 1.914337073602984

Epoch: 6| Step: 1
Training loss: 1.7515904903411865
Validation loss: 1.9013342600996777

Epoch: 6| Step: 2
Training loss: 1.7306427955627441
Validation loss: 1.9088777931787635

Epoch: 6| Step: 3
Training loss: 1.903831124305725
Validation loss: 1.909903431451449

Epoch: 6| Step: 4
Training loss: 2.023613452911377
Validation loss: 1.8816930965710712

Epoch: 6| Step: 5
Training loss: 1.7358169555664062
Validation loss: 1.9091255895553096

Epoch: 6| Step: 6
Training loss: 1.9850096702575684
Validation loss: 1.916241789376864

Epoch: 6| Step: 7
Training loss: 2.5694420337677
Validation loss: 1.893682764422509

Epoch: 6| Step: 8
Training loss: 2.51786732673645
Validation loss: 1.8837682406107585

Epoch: 6| Step: 9
Training loss: 3.094285488128662
Validation loss: 1.8997876374952254

Epoch: 6| Step: 10
Training loss: 2.6937060356140137
Validation loss: 1.8949471289111721

Epoch: 6| Step: 11
Training loss: 2.2748727798461914
Validation loss: 1.9047222034905547

Epoch: 6| Step: 12
Training loss: 1.9091854095458984
Validation loss: 1.8982360978280344

Epoch: 6| Step: 13
Training loss: 2.362067937850952
Validation loss: 1.900210170335667

Epoch: 76| Step: 0
Training loss: 2.375514030456543
Validation loss: 1.903811293263589

Epoch: 6| Step: 1
Training loss: 2.772251844406128
Validation loss: 1.8917165417825021

Epoch: 6| Step: 2
Training loss: 1.4929108619689941
Validation loss: 1.8817154617719754

Epoch: 6| Step: 3
Training loss: 1.6137970685958862
Validation loss: 1.9086040143043763

Epoch: 6| Step: 4
Training loss: 1.7939541339874268
Validation loss: 1.9068158570156302

Epoch: 6| Step: 5
Training loss: 2.284130573272705
Validation loss: 1.9082174429329493

Epoch: 6| Step: 6
Training loss: 2.7659668922424316
Validation loss: 1.9046224817152946

Epoch: 6| Step: 7
Training loss: 2.0545926094055176
Validation loss: 1.8904934096080002

Epoch: 6| Step: 8
Training loss: 1.6478999853134155
Validation loss: 1.9050347253840456

Epoch: 6| Step: 9
Training loss: 2.5398499965667725
Validation loss: 1.8995214354607366

Epoch: 6| Step: 10
Training loss: 2.446300506591797
Validation loss: 1.9016547151791152

Epoch: 6| Step: 11
Training loss: 1.9150103330612183
Validation loss: 1.891128550293625

Epoch: 6| Step: 12
Training loss: 2.6817007064819336
Validation loss: 1.8923967653705227

Epoch: 6| Step: 13
Training loss: 1.7708665132522583
Validation loss: 1.908490014332597

Epoch: 77| Step: 0
Training loss: 1.636687159538269
Validation loss: 1.8783133927211966

Epoch: 6| Step: 1
Training loss: 2.2657175064086914
Validation loss: 1.8855745061751334

Epoch: 6| Step: 2
Training loss: 2.690704822540283
Validation loss: 1.8907736334749448

Epoch: 6| Step: 3
Training loss: 2.560044288635254
Validation loss: 1.8944635160507695

Epoch: 6| Step: 4
Training loss: 1.9170427322387695
Validation loss: 1.902603426287251

Epoch: 6| Step: 5
Training loss: 1.6558303833007812
Validation loss: 1.9089647992964713

Epoch: 6| Step: 6
Training loss: 2.555678367614746
Validation loss: 1.9073645402026433

Epoch: 6| Step: 7
Training loss: 1.596691608428955
Validation loss: 1.9176549437225505

Epoch: 6| Step: 8
Training loss: 2.2631173133850098
Validation loss: 1.9047563768202258

Epoch: 6| Step: 9
Training loss: 2.404226303100586
Validation loss: 1.9134966942571825

Epoch: 6| Step: 10
Training loss: 2.2593793869018555
Validation loss: 1.9057573233881304

Epoch: 6| Step: 11
Training loss: 2.0928330421447754
Validation loss: 1.9221128930327713

Epoch: 6| Step: 12
Training loss: 2.25462007522583
Validation loss: 1.9156339463367258

Epoch: 6| Step: 13
Training loss: 1.9272888898849487
Validation loss: 1.9306390746947257

Epoch: 78| Step: 0
Training loss: 1.9013341665267944
Validation loss: 1.9259383165708153

Epoch: 6| Step: 1
Training loss: 2.2665228843688965
Validation loss: 1.9272759114542315

Epoch: 6| Step: 2
Training loss: 2.7255234718322754
Validation loss: 1.9177428137871526

Epoch: 6| Step: 3
Training loss: 2.5686776638031006
Validation loss: 1.9025210436954294

Epoch: 6| Step: 4
Training loss: 2.7327160835266113
Validation loss: 1.9075926350009056

Epoch: 6| Step: 5
Training loss: 2.322066307067871
Validation loss: 1.902713861516727

Epoch: 6| Step: 6
Training loss: 1.415510892868042
Validation loss: 1.9170723756154378

Epoch: 6| Step: 7
Training loss: 2.4465057849884033
Validation loss: 1.9221944526959491

Epoch: 6| Step: 8
Training loss: 1.4782679080963135
Validation loss: 1.9182628175263763

Epoch: 6| Step: 9
Training loss: 1.5097557306289673
Validation loss: 1.930199324443776

Epoch: 6| Step: 10
Training loss: 1.5908581018447876
Validation loss: 1.9109043831466346

Epoch: 6| Step: 11
Training loss: 2.545213222503662
Validation loss: 1.908872422351632

Epoch: 6| Step: 12
Training loss: 2.310647964477539
Validation loss: 1.9162475562864734

Epoch: 6| Step: 13
Training loss: 2.4673590660095215
Validation loss: 1.9041164190538469

Epoch: 79| Step: 0
Training loss: 1.9889285564422607
Validation loss: 1.9189278592345536

Epoch: 6| Step: 1
Training loss: 2.0230369567871094
Validation loss: 1.8995799479946014

Epoch: 6| Step: 2
Training loss: 2.086153030395508
Validation loss: 1.8952341797531291

Epoch: 6| Step: 3
Training loss: 2.2717490196228027
Validation loss: 1.900178914429039

Epoch: 6| Step: 4
Training loss: 2.1006033420562744
Validation loss: 1.9065540605975735

Epoch: 6| Step: 5
Training loss: 2.2142248153686523
Validation loss: 1.9056743229589155

Epoch: 6| Step: 6
Training loss: 2.2369847297668457
Validation loss: 1.8914053029911493

Epoch: 6| Step: 7
Training loss: 1.973511815071106
Validation loss: 1.9080012459908762

Epoch: 6| Step: 8
Training loss: 2.312255382537842
Validation loss: 1.8990156906907276

Epoch: 6| Step: 9
Training loss: 1.5730032920837402
Validation loss: 1.89815608404016

Epoch: 6| Step: 10
Training loss: 2.226813793182373
Validation loss: 1.9000736385263421

Epoch: 6| Step: 11
Training loss: 2.8318569660186768
Validation loss: 1.9050498393274122

Epoch: 6| Step: 12
Training loss: 2.062559127807617
Validation loss: 1.9013139022293912

Epoch: 6| Step: 13
Training loss: 2.030272960662842
Validation loss: 1.9009816800394366

Epoch: 80| Step: 0
Training loss: 2.163630247116089
Validation loss: 1.9072440324291107

Epoch: 6| Step: 1
Training loss: 2.100957155227661
Validation loss: 1.9069018915135374

Epoch: 6| Step: 2
Training loss: 2.5925328731536865
Validation loss: 1.8800736934907976

Epoch: 6| Step: 3
Training loss: 2.305879592895508
Validation loss: 1.8909074068069458

Epoch: 6| Step: 4
Training loss: 2.3215668201446533
Validation loss: 1.8946055263601325

Epoch: 6| Step: 5
Training loss: 1.6706480979919434
Validation loss: 1.8949707144050187

Epoch: 6| Step: 6
Training loss: 1.803715705871582
Validation loss: 1.8821236036157096

Epoch: 6| Step: 7
Training loss: 1.8391075134277344
Validation loss: 1.9100997396694717

Epoch: 6| Step: 8
Training loss: 2.418074607849121
Validation loss: 1.8895572616207985

Epoch: 6| Step: 9
Training loss: 2.29750919342041
Validation loss: 1.90455126249662

Epoch: 6| Step: 10
Training loss: 1.9344334602355957
Validation loss: 1.9083594660605154

Epoch: 6| Step: 11
Training loss: 1.769995927810669
Validation loss: 1.8970392314336633

Epoch: 6| Step: 12
Training loss: 2.3918261528015137
Validation loss: 1.9073618599163589

Epoch: 6| Step: 13
Training loss: 2.728692054748535
Validation loss: 1.891716077763547

Epoch: 81| Step: 0
Training loss: 2.694607973098755
Validation loss: 1.9233746810625958

Epoch: 6| Step: 1
Training loss: 2.6258440017700195
Validation loss: 1.9173743596640966

Epoch: 6| Step: 2
Training loss: 2.344595193862915
Validation loss: 1.899511189870937

Epoch: 6| Step: 3
Training loss: 2.352867603302002
Validation loss: 1.920338297402987

Epoch: 6| Step: 4
Training loss: 2.288337230682373
Validation loss: 1.9090986495376916

Epoch: 6| Step: 5
Training loss: 2.305027723312378
Validation loss: 1.9003381754762383

Epoch: 6| Step: 6
Training loss: 2.3212432861328125
Validation loss: 1.8947506079109766

Epoch: 6| Step: 7
Training loss: 2.1004180908203125
Validation loss: 1.901644064534095

Epoch: 6| Step: 8
Training loss: 1.6378331184387207
Validation loss: 1.898327830017254

Epoch: 6| Step: 9
Training loss: 1.2755578756332397
Validation loss: 1.893513911513872

Epoch: 6| Step: 10
Training loss: 1.8234758377075195
Validation loss: 1.9035085196136146

Epoch: 6| Step: 11
Training loss: 1.5913023948669434
Validation loss: 1.887059339912989

Epoch: 6| Step: 12
Training loss: 2.5755717754364014
Validation loss: 1.8973095865659817

Epoch: 6| Step: 13
Training loss: 2.18678879737854
Validation loss: 1.9011558486569313

Epoch: 82| Step: 0
Training loss: 1.9286730289459229
Validation loss: 1.905924512493995

Epoch: 6| Step: 1
Training loss: 2.056673049926758
Validation loss: 1.8943275072241341

Epoch: 6| Step: 2
Training loss: 2.525669574737549
Validation loss: 1.8991760643579627

Epoch: 6| Step: 3
Training loss: 1.9480350017547607
Validation loss: 1.905745966460115

Epoch: 6| Step: 4
Training loss: 2.101027488708496
Validation loss: 1.915036903914585

Epoch: 6| Step: 5
Training loss: 1.9941450357437134
Validation loss: 1.8936947686697847

Epoch: 6| Step: 6
Training loss: 2.1566343307495117
Validation loss: 1.9126112435453682

Epoch: 6| Step: 7
Training loss: 2.8317017555236816
Validation loss: 1.88710057350897

Epoch: 6| Step: 8
Training loss: 2.664189338684082
Validation loss: 1.9058637388290898

Epoch: 6| Step: 9
Training loss: 2.0545144081115723
Validation loss: 1.9327368582448652

Epoch: 6| Step: 10
Training loss: 2.2696776390075684
Validation loss: 1.9074071876464351

Epoch: 6| Step: 11
Training loss: 1.5238926410675049
Validation loss: 1.917497597714906

Epoch: 6| Step: 12
Training loss: 1.8460651636123657
Validation loss: 1.894361008879959

Epoch: 6| Step: 13
Training loss: 2.2209784984588623
Validation loss: 1.9183277071163218

Epoch: 83| Step: 0
Training loss: 2.5810844898223877
Validation loss: 1.9133113276573919

Epoch: 6| Step: 1
Training loss: 2.1459951400756836
Validation loss: 1.9006711539401804

Epoch: 6| Step: 2
Training loss: 2.123366355895996
Validation loss: 1.9215411755346483

Epoch: 6| Step: 3
Training loss: 1.8992717266082764
Validation loss: 1.9272468538694485

Epoch: 6| Step: 4
Training loss: 2.6537389755249023
Validation loss: 1.9170426771204958

Epoch: 6| Step: 5
Training loss: 1.595021367073059
Validation loss: 1.9333023896781347

Epoch: 6| Step: 6
Training loss: 2.229904890060425
Validation loss: 1.9335803370321951

Epoch: 6| Step: 7
Training loss: 2.2801873683929443
Validation loss: 1.9373122979235906

Epoch: 6| Step: 8
Training loss: 2.447643280029297
Validation loss: 1.9396595121711813

Epoch: 6| Step: 9
Training loss: 1.7302911281585693
Validation loss: 1.9332123046280236

Epoch: 6| Step: 10
Training loss: 1.7733659744262695
Validation loss: 1.9087898679958877

Epoch: 6| Step: 11
Training loss: 1.8621958494186401
Validation loss: 1.9206833531779628

Epoch: 6| Step: 12
Training loss: 2.5171217918395996
Validation loss: 1.9347387308715491

Epoch: 6| Step: 13
Training loss: 2.026742458343506
Validation loss: 1.9057924157829695

Epoch: 84| Step: 0
Training loss: 2.370945930480957
Validation loss: 1.8973264296849568

Epoch: 6| Step: 1
Training loss: 2.784134864807129
Validation loss: 1.9035825697324609

Epoch: 6| Step: 2
Training loss: 2.5110714435577393
Validation loss: 1.8982404829353414

Epoch: 6| Step: 3
Training loss: 2.176583766937256
Validation loss: 1.9141975269522717

Epoch: 6| Step: 4
Training loss: 2.394179105758667
Validation loss: 1.9078665215481994

Epoch: 6| Step: 5
Training loss: 1.9004942178726196
Validation loss: 1.8906502544239003

Epoch: 6| Step: 6
Training loss: 2.2454833984375
Validation loss: 1.8976721148337088

Epoch: 6| Step: 7
Training loss: 1.721848726272583
Validation loss: 1.920755741416767

Epoch: 6| Step: 8
Training loss: 1.932205319404602
Validation loss: 1.9213970489399408

Epoch: 6| Step: 9
Training loss: 2.085944652557373
Validation loss: 1.9161385002956595

Epoch: 6| Step: 10
Training loss: 1.479614496231079
Validation loss: 1.9038262162157285

Epoch: 6| Step: 11
Training loss: 2.353543281555176
Validation loss: 1.927471132688625

Epoch: 6| Step: 12
Training loss: 2.079606771469116
Validation loss: 1.9140709959050661

Epoch: 6| Step: 13
Training loss: 1.4786646366119385
Validation loss: 1.9153208553150136

Epoch: 85| Step: 0
Training loss: 2.3493666648864746
Validation loss: 1.9122030555561025

Epoch: 6| Step: 1
Training loss: 2.4238200187683105
Validation loss: 1.881329837665763

Epoch: 6| Step: 2
Training loss: 2.2453253269195557
Validation loss: 1.926376328673414

Epoch: 6| Step: 3
Training loss: 1.948594570159912
Validation loss: 1.8859588740974345

Epoch: 6| Step: 4
Training loss: 2.001368522644043
Validation loss: 1.9070632919188468

Epoch: 6| Step: 5
Training loss: 2.170006513595581
Validation loss: 1.9210974016497213

Epoch: 6| Step: 6
Training loss: 1.972813367843628
Validation loss: 1.9079625311718191

Epoch: 6| Step: 7
Training loss: 2.05975341796875
Validation loss: 1.9161600541043025

Epoch: 6| Step: 8
Training loss: 2.1215767860412598
Validation loss: 1.9023272093906198

Epoch: 6| Step: 9
Training loss: 2.572193145751953
Validation loss: 1.9074700852876068

Epoch: 6| Step: 10
Training loss: 1.8899719715118408
Validation loss: 1.902041608287442

Epoch: 6| Step: 11
Training loss: 1.8823025226593018
Validation loss: 1.8833771521045315

Epoch: 6| Step: 12
Training loss: 2.394814968109131
Validation loss: 1.9048149419087235

Epoch: 6| Step: 13
Training loss: 1.670271396636963
Validation loss: 1.9148616636953046

Epoch: 86| Step: 0
Training loss: 2.226205348968506
Validation loss: 1.8924358301265265

Epoch: 6| Step: 1
Training loss: 2.108116626739502
Validation loss: 1.904656466617379

Epoch: 6| Step: 2
Training loss: 1.6791123151779175
Validation loss: 1.9189757108688354

Epoch: 6| Step: 3
Training loss: 1.7067351341247559
Validation loss: 1.9234134740726923

Epoch: 6| Step: 4
Training loss: 2.8187990188598633
Validation loss: 1.902719610480852

Epoch: 6| Step: 5
Training loss: 1.5626556873321533
Validation loss: 1.9112564838060768

Epoch: 6| Step: 6
Training loss: 2.4234721660614014
Validation loss: 1.9194057846582064

Epoch: 6| Step: 7
Training loss: 2.3970956802368164
Validation loss: 1.915521998559275

Epoch: 6| Step: 8
Training loss: 1.8421704769134521
Validation loss: 1.9146273584776028

Epoch: 6| Step: 9
Training loss: 2.5369980335235596
Validation loss: 1.8916192849477131

Epoch: 6| Step: 10
Training loss: 2.600667953491211
Validation loss: 1.881438410410317

Epoch: 6| Step: 11
Training loss: 2.128948211669922
Validation loss: 1.8870342418711672

Epoch: 6| Step: 12
Training loss: 1.6016684770584106
Validation loss: 1.90248453745278

Epoch: 6| Step: 13
Training loss: 2.3068721294403076
Validation loss: 1.8856363258054178

Epoch: 87| Step: 0
Training loss: 1.5027494430541992
Validation loss: 1.8946890446447557

Epoch: 6| Step: 1
Training loss: 2.3891501426696777
Validation loss: 1.8874776465918428

Epoch: 6| Step: 2
Training loss: 2.0207114219665527
Validation loss: 1.8770054540326517

Epoch: 6| Step: 3
Training loss: 1.9263503551483154
Validation loss: 1.9022094741944344

Epoch: 6| Step: 4
Training loss: 2.511026382446289
Validation loss: 1.8949451651624454

Epoch: 6| Step: 5
Training loss: 1.9082987308502197
Validation loss: 1.8867597259500974

Epoch: 6| Step: 6
Training loss: 1.9451916217803955
Validation loss: 1.8995244938840148

Epoch: 6| Step: 7
Training loss: 2.430983543395996
Validation loss: 1.901330219802036

Epoch: 6| Step: 8
Training loss: 2.224522113800049
Validation loss: 1.8892209914422804

Epoch: 6| Step: 9
Training loss: 2.20330810546875
Validation loss: 1.8916767515161985

Epoch: 6| Step: 10
Training loss: 2.05611515045166
Validation loss: 1.902998024417508

Epoch: 6| Step: 11
Training loss: 1.772961974143982
Validation loss: 1.8948369615821428

Epoch: 6| Step: 12
Training loss: 2.4017410278320312
Validation loss: 1.8909447962237942

Epoch: 6| Step: 13
Training loss: 2.6478095054626465
Validation loss: 1.891272508969871

Epoch: 88| Step: 0
Training loss: 1.9324603080749512
Validation loss: 1.900754641461116

Epoch: 6| Step: 1
Training loss: 2.533092975616455
Validation loss: 1.8849436826603387

Epoch: 6| Step: 2
Training loss: 1.4787933826446533
Validation loss: 1.8981893062591553

Epoch: 6| Step: 3
Training loss: 1.9752070903778076
Validation loss: 1.9121333065853323

Epoch: 6| Step: 4
Training loss: 1.940936803817749
Validation loss: 1.909653050925142

Epoch: 6| Step: 5
Training loss: 1.838547706604004
Validation loss: 1.8779078004180745

Epoch: 6| Step: 6
Training loss: 1.2489383220672607
Validation loss: 1.8930851874812957

Epoch: 6| Step: 7
Training loss: 2.675309181213379
Validation loss: 1.8940703125410183

Epoch: 6| Step: 8
Training loss: 2.132693290710449
Validation loss: 1.9084118156022922

Epoch: 6| Step: 9
Training loss: 2.799553632736206
Validation loss: 1.8910922786240936

Epoch: 6| Step: 10
Training loss: 2.079127788543701
Validation loss: 1.8948455728510374

Epoch: 6| Step: 11
Training loss: 2.3508996963500977
Validation loss: 1.9012804646645822

Epoch: 6| Step: 12
Training loss: 2.3501973152160645
Validation loss: 1.9003246009990733

Epoch: 6| Step: 13
Training loss: 2.2710084915161133
Validation loss: 1.9062882802819694

Epoch: 89| Step: 0
Training loss: 1.9923005104064941
Validation loss: 1.9074061070719073

Epoch: 6| Step: 1
Training loss: 1.8604021072387695
Validation loss: 1.897200907430341

Epoch: 6| Step: 2
Training loss: 2.772000789642334
Validation loss: 1.8762610253467356

Epoch: 6| Step: 3
Training loss: 2.55722713470459
Validation loss: 1.8941618242571432

Epoch: 6| Step: 4
Training loss: 2.4784884452819824
Validation loss: 1.9179574315265944

Epoch: 6| Step: 5
Training loss: 2.0284230709075928
Validation loss: 1.9075225322477278

Epoch: 6| Step: 6
Training loss: 1.1713974475860596
Validation loss: 1.904151766530929

Epoch: 6| Step: 7
Training loss: 2.133866548538208
Validation loss: 1.9046643703214583

Epoch: 6| Step: 8
Training loss: 1.970760464668274
Validation loss: 1.890892424891072

Epoch: 6| Step: 9
Training loss: 2.2023229598999023
Validation loss: 1.9071963064132198

Epoch: 6| Step: 10
Training loss: 2.4143271446228027
Validation loss: 1.9092105844969391

Epoch: 6| Step: 11
Training loss: 1.667273759841919
Validation loss: 1.921927693069622

Epoch: 6| Step: 12
Training loss: 1.863683819770813
Validation loss: 1.9117201630787184

Epoch: 6| Step: 13
Training loss: 2.537567615509033
Validation loss: 1.894575999629113

Epoch: 90| Step: 0
Training loss: 1.5636258125305176
Validation loss: 1.9015354161621423

Epoch: 6| Step: 1
Training loss: 2.304425001144409
Validation loss: 1.9172793511421449

Epoch: 6| Step: 2
Training loss: 1.9122207164764404
Validation loss: 1.8945359542805662

Epoch: 6| Step: 3
Training loss: 1.7116179466247559
Validation loss: 1.890591803417411

Epoch: 6| Step: 4
Training loss: 1.655853271484375
Validation loss: 1.9131227334340413

Epoch: 6| Step: 5
Training loss: 2.585083246231079
Validation loss: 1.9135938870009555

Epoch: 6| Step: 6
Training loss: 1.931655764579773
Validation loss: 1.899494646697916

Epoch: 6| Step: 7
Training loss: 1.828843355178833
Validation loss: 1.8731218102157756

Epoch: 6| Step: 8
Training loss: 1.433281660079956
Validation loss: 1.888133728375999

Epoch: 6| Step: 9
Training loss: 2.559183120727539
Validation loss: 1.8949546544782576

Epoch: 6| Step: 10
Training loss: 3.3207335472106934
Validation loss: 1.8946004080516037

Epoch: 6| Step: 11
Training loss: 1.9977507591247559
Validation loss: 1.8886593157245266

Epoch: 6| Step: 12
Training loss: 2.312763214111328
Validation loss: 1.9014695921251852

Epoch: 6| Step: 13
Training loss: 2.627333641052246
Validation loss: 1.9104433739057152

Epoch: 91| Step: 0
Training loss: 1.3768055438995361
Validation loss: 1.884303459557154

Epoch: 6| Step: 1
Training loss: 2.3029327392578125
Validation loss: 1.904680707121408

Epoch: 6| Step: 2
Training loss: 2.923815965652466
Validation loss: 1.8938686924595987

Epoch: 6| Step: 3
Training loss: 1.6464476585388184
Validation loss: 1.8911761430002028

Epoch: 6| Step: 4
Training loss: 2.086369514465332
Validation loss: 1.9009652009574316

Epoch: 6| Step: 5
Training loss: 2.4731907844543457
Validation loss: 1.8836705210388347

Epoch: 6| Step: 6
Training loss: 2.0552217960357666
Validation loss: 1.907194027336695

Epoch: 6| Step: 7
Training loss: 2.823166847229004
Validation loss: 1.8911967303163262

Epoch: 6| Step: 8
Training loss: 1.575083613395691
Validation loss: 1.918854291721057

Epoch: 6| Step: 9
Training loss: 1.679621934890747
Validation loss: 1.8950542737078924

Epoch: 6| Step: 10
Training loss: 2.271030902862549
Validation loss: 1.8987315239444855

Epoch: 6| Step: 11
Training loss: 2.1392102241516113
Validation loss: 1.8932555516560872

Epoch: 6| Step: 12
Training loss: 2.136850357055664
Validation loss: 1.8977534117237214

Epoch: 6| Step: 13
Training loss: 1.667284607887268
Validation loss: 1.9047485346435218

Epoch: 92| Step: 0
Training loss: 2.5913078784942627
Validation loss: 1.8817285645392634

Epoch: 6| Step: 1
Training loss: 2.2286453247070312
Validation loss: 1.8820014410121466

Epoch: 6| Step: 2
Training loss: 2.707289218902588
Validation loss: 1.8752474913033106

Epoch: 6| Step: 3
Training loss: 1.416980266571045
Validation loss: 1.9024078487068095

Epoch: 6| Step: 4
Training loss: 2.049266815185547
Validation loss: 1.8826449968481576

Epoch: 6| Step: 5
Training loss: 2.0823326110839844
Validation loss: 1.9116748084304154

Epoch: 6| Step: 6
Training loss: 1.9006702899932861
Validation loss: 1.9006559489875712

Epoch: 6| Step: 7
Training loss: 2.0497348308563232
Validation loss: 1.9180459002012848

Epoch: 6| Step: 8
Training loss: 2.0926015377044678
Validation loss: 1.9168387100260744

Epoch: 6| Step: 9
Training loss: 1.565858006477356
Validation loss: 1.9233200114260438

Epoch: 6| Step: 10
Training loss: 1.7826813459396362
Validation loss: 1.9081398620400378

Epoch: 6| Step: 11
Training loss: 2.333946704864502
Validation loss: 1.90323458948443

Epoch: 6| Step: 12
Training loss: 2.2286596298217773
Validation loss: 1.8995861314958142

Epoch: 6| Step: 13
Training loss: 2.5691723823547363
Validation loss: 1.900417133044171

Epoch: 93| Step: 0
Training loss: 1.709214687347412
Validation loss: 1.8949730960271691

Epoch: 6| Step: 1
Training loss: 3.1319456100463867
Validation loss: 1.9110999940544047

Epoch: 6| Step: 2
Training loss: 2.3457891941070557
Validation loss: 1.9094386203314668

Epoch: 6| Step: 3
Training loss: 1.233046293258667
Validation loss: 1.917758749377343

Epoch: 6| Step: 4
Training loss: 2.07108211517334
Validation loss: 1.9076429746484245

Epoch: 6| Step: 5
Training loss: 1.7082606554031372
Validation loss: 1.8971256350958219

Epoch: 6| Step: 6
Training loss: 2.352882146835327
Validation loss: 1.9027847525894002

Epoch: 6| Step: 7
Training loss: 1.8968429565429688
Validation loss: 1.8842867177019837

Epoch: 6| Step: 8
Training loss: 2.7746946811676025
Validation loss: 1.8716564383558048

Epoch: 6| Step: 9
Training loss: 1.9861582517623901
Validation loss: 1.9157343859313636

Epoch: 6| Step: 10
Training loss: 2.2820916175842285
Validation loss: 1.9029735724131267

Epoch: 6| Step: 11
Training loss: 2.179753303527832
Validation loss: 1.9098570026377195

Epoch: 6| Step: 12
Training loss: 1.7870686054229736
Validation loss: 1.9140494587600871

Epoch: 6| Step: 13
Training loss: 1.5507569313049316
Validation loss: 1.9027621387153544

Epoch: 94| Step: 0
Training loss: 2.0738320350646973
Validation loss: 1.9116251827568136

Epoch: 6| Step: 1
Training loss: 1.5837644338607788
Validation loss: 1.9065841897841422

Epoch: 6| Step: 2
Training loss: 2.6918792724609375
Validation loss: 1.9088145391915434

Epoch: 6| Step: 3
Training loss: 1.753529667854309
Validation loss: 1.900990116980768

Epoch: 6| Step: 4
Training loss: 2.1247634887695312
Validation loss: 1.893159011358856

Epoch: 6| Step: 5
Training loss: 2.442878484725952
Validation loss: 1.8953819428720782

Epoch: 6| Step: 6
Training loss: 2.365621566772461
Validation loss: 1.9094482134747248

Epoch: 6| Step: 7
Training loss: 1.695833444595337
Validation loss: 1.905376693253876

Epoch: 6| Step: 8
Training loss: 1.4566090106964111
Validation loss: 1.902526109449325

Epoch: 6| Step: 9
Training loss: 1.797255516052246
Validation loss: 1.89625899253353

Epoch: 6| Step: 10
Training loss: 2.382363796234131
Validation loss: 1.9245171982754943

Epoch: 6| Step: 11
Training loss: 2.2009246349334717
Validation loss: 1.9132785604846092

Epoch: 6| Step: 12
Training loss: 2.105565071105957
Validation loss: 1.894673151354636

Epoch: 6| Step: 13
Training loss: 2.704310417175293
Validation loss: 1.9065770513267928

Epoch: 95| Step: 0
Training loss: 2.809345245361328
Validation loss: 1.9133129158327657

Epoch: 6| Step: 1
Training loss: 1.963594675064087
Validation loss: 1.9057502182581092

Epoch: 6| Step: 2
Training loss: 2.076047897338867
Validation loss: 1.9252590466571111

Epoch: 6| Step: 3
Training loss: 2.207164764404297
Validation loss: 1.9151752405269171

Epoch: 6| Step: 4
Training loss: 2.191009759902954
Validation loss: 1.935564684611495

Epoch: 6| Step: 5
Training loss: 1.8967351913452148
Validation loss: 1.9506276807477396

Epoch: 6| Step: 6
Training loss: 2.0616044998168945
Validation loss: 1.9320026443850609

Epoch: 6| Step: 7
Training loss: 2.177475690841675
Validation loss: 1.9131681931916105

Epoch: 6| Step: 8
Training loss: 2.0346879959106445
Validation loss: 1.918583866088621

Epoch: 6| Step: 9
Training loss: 1.944266676902771
Validation loss: 1.9335512166382165

Epoch: 6| Step: 10
Training loss: 2.0319995880126953
Validation loss: 1.9173998345610916

Epoch: 6| Step: 11
Training loss: 1.9435542821884155
Validation loss: 1.895341601423038

Epoch: 6| Step: 12
Training loss: 2.1377270221710205
Validation loss: 1.9042438166115874

Epoch: 6| Step: 13
Training loss: 1.7398457527160645
Validation loss: 1.907532024127181

Epoch: 96| Step: 0
Training loss: 1.9763896465301514
Validation loss: 1.9227309137262323

Epoch: 6| Step: 1
Training loss: 2.1514999866485596
Validation loss: 1.917255950230424

Epoch: 6| Step: 2
Training loss: 2.0182716846466064
Validation loss: 1.8971678339025027

Epoch: 6| Step: 3
Training loss: 2.2121927738189697
Validation loss: 1.9085870814579788

Epoch: 6| Step: 4
Training loss: 1.904421329498291
Validation loss: 1.8958772715701853

Epoch: 6| Step: 5
Training loss: 2.6915321350097656
Validation loss: 1.9047595095890824

Epoch: 6| Step: 6
Training loss: 2.2215588092803955
Validation loss: 1.8908746434796242

Epoch: 6| Step: 7
Training loss: 2.076897144317627
Validation loss: 1.8930084833534815

Epoch: 6| Step: 8
Training loss: 2.1753506660461426
Validation loss: 1.9222413263013285

Epoch: 6| Step: 9
Training loss: 1.3900269269943237
Validation loss: 1.882789687443805

Epoch: 6| Step: 10
Training loss: 2.1627960205078125
Validation loss: 1.891116435809802

Epoch: 6| Step: 11
Training loss: 2.205301284790039
Validation loss: 1.8910657193071099

Epoch: 6| Step: 12
Training loss: 2.1414711475372314
Validation loss: 1.8850001660726403

Epoch: 6| Step: 13
Training loss: 1.756778359413147
Validation loss: 1.8882409795638053

Epoch: 97| Step: 0
Training loss: 1.731194019317627
Validation loss: 1.875075158252511

Epoch: 6| Step: 1
Training loss: 2.040299415588379
Validation loss: 1.9126176398287538

Epoch: 6| Step: 2
Training loss: 2.434744358062744
Validation loss: 1.898092371161266

Epoch: 6| Step: 3
Training loss: 1.8583590984344482
Validation loss: 1.9071830011183215

Epoch: 6| Step: 4
Training loss: 1.4664301872253418
Validation loss: 1.9015285930325907

Epoch: 6| Step: 5
Training loss: 1.7907648086547852
Validation loss: 1.9069366185895857

Epoch: 6| Step: 6
Training loss: 2.6105737686157227
Validation loss: 1.9072633994522916

Epoch: 6| Step: 7
Training loss: 1.763839602470398
Validation loss: 1.9008853448334562

Epoch: 6| Step: 8
Training loss: 2.5304760932922363
Validation loss: 1.9245250622431438

Epoch: 6| Step: 9
Training loss: 1.9626288414001465
Validation loss: 1.9146610165155062

Epoch: 6| Step: 10
Training loss: 1.8350741863250732
Validation loss: 1.8930057325670797

Epoch: 6| Step: 11
Training loss: 3.4096479415893555
Validation loss: 1.9012408987168343

Epoch: 6| Step: 12
Training loss: 1.732921838760376
Validation loss: 1.8940418792027298

Epoch: 6| Step: 13
Training loss: 1.8598049879074097
Validation loss: 1.913987321238364

Epoch: 98| Step: 0
Training loss: 2.452521800994873
Validation loss: 1.913474932793648

Epoch: 6| Step: 1
Training loss: 2.7588984966278076
Validation loss: 1.9303146882723736

Epoch: 6| Step: 2
Training loss: 1.7454841136932373
Validation loss: 1.9225338223159953

Epoch: 6| Step: 3
Training loss: 2.182798385620117
Validation loss: 1.9128808308673162

Epoch: 6| Step: 4
Training loss: 2.2374277114868164
Validation loss: 1.912244467325108

Epoch: 6| Step: 5
Training loss: 2.711623430252075
Validation loss: 1.9053590348971787

Epoch: 6| Step: 6
Training loss: 1.3286925554275513
Validation loss: 1.8969038455717024

Epoch: 6| Step: 7
Training loss: 2.259242296218872
Validation loss: 1.885774854690798

Epoch: 6| Step: 8
Training loss: 2.095460891723633
Validation loss: 1.8873002670144523

Epoch: 6| Step: 9
Training loss: 2.1096439361572266
Validation loss: 1.9032576814774544

Epoch: 6| Step: 10
Training loss: 1.455585241317749
Validation loss: 1.8965991914913218

Epoch: 6| Step: 11
Training loss: 2.180448055267334
Validation loss: 1.889588379090832

Epoch: 6| Step: 12
Training loss: 2.007373332977295
Validation loss: 1.8951649883741974

Epoch: 6| Step: 13
Training loss: 1.2894024848937988
Validation loss: 1.8796210417183496

Epoch: 99| Step: 0
Training loss: 2.2356791496276855
Validation loss: 1.903718113899231

Epoch: 6| Step: 1
Training loss: 2.1558725833892822
Validation loss: 1.9080373035964144

Epoch: 6| Step: 2
Training loss: 2.0162220001220703
Validation loss: 1.9062418476227792

Epoch: 6| Step: 3
Training loss: 2.591884136199951
Validation loss: 1.8983093333500687

Epoch: 6| Step: 4
Training loss: 2.0609357357025146
Validation loss: 1.899830638721425

Epoch: 6| Step: 5
Training loss: 1.8025305271148682
Validation loss: 1.8730927551946333

Epoch: 6| Step: 6
Training loss: 1.7945609092712402
Validation loss: 1.924645362361785

Epoch: 6| Step: 7
Training loss: 1.5313944816589355
Validation loss: 1.904924947728393

Epoch: 6| Step: 8
Training loss: 2.482687473297119
Validation loss: 1.9001107138972129

Epoch: 6| Step: 9
Training loss: 1.99333655834198
Validation loss: 1.9260770428565241

Epoch: 6| Step: 10
Training loss: 2.210841417312622
Validation loss: 1.9180023721469346

Epoch: 6| Step: 11
Training loss: 2.208200454711914
Validation loss: 1.9190917861077093

Epoch: 6| Step: 12
Training loss: 2.1408872604370117
Validation loss: 1.9315051673561014

Epoch: 6| Step: 13
Training loss: 1.536940097808838
Validation loss: 1.9010364368397703

Epoch: 100| Step: 0
Training loss: 2.760427951812744
Validation loss: 1.9034647428861229

Epoch: 6| Step: 1
Training loss: 2.122545003890991
Validation loss: 1.8896830184485323

Epoch: 6| Step: 2
Training loss: 2.1161186695098877
Validation loss: 1.9166246306511663

Epoch: 6| Step: 3
Training loss: 2.3402419090270996
Validation loss: 1.906870981698395

Epoch: 6| Step: 4
Training loss: 2.2398056983947754
Validation loss: 1.8964298694364485

Epoch: 6| Step: 5
Training loss: 1.9933576583862305
Validation loss: 1.8936327580482728

Epoch: 6| Step: 6
Training loss: 2.056732177734375
Validation loss: 1.8867573968825802

Epoch: 6| Step: 7
Training loss: 2.3866169452667236
Validation loss: 1.9013645879683956

Epoch: 6| Step: 8
Training loss: 1.9072449207305908
Validation loss: 1.8994904897546256

Epoch: 6| Step: 9
Training loss: 1.8419944047927856
Validation loss: 1.8980430633791032

Epoch: 6| Step: 10
Training loss: 2.1643245220184326
Validation loss: 1.9126661592914211

Epoch: 6| Step: 11
Training loss: 1.7589153051376343
Validation loss: 1.9200439799216487

Epoch: 6| Step: 12
Training loss: 1.8453022241592407
Validation loss: 1.9130068273954495

Epoch: 6| Step: 13
Training loss: 0.9369081854820251
Validation loss: 1.9102406347951582

Epoch: 101| Step: 0
Training loss: 1.6866796016693115
Validation loss: 1.9075811204089914

Epoch: 6| Step: 1
Training loss: 1.9354101419448853
Validation loss: 1.910039524878225

Epoch: 6| Step: 2
Training loss: 2.172114610671997
Validation loss: 1.9221189124609834

Epoch: 6| Step: 3
Training loss: 1.6248221397399902
Validation loss: 1.8933364486181608

Epoch: 6| Step: 4
Training loss: 2.146291971206665
Validation loss: 1.9174998780732513

Epoch: 6| Step: 5
Training loss: 2.0743775367736816
Validation loss: 1.9047312980057092

Epoch: 6| Step: 6
Training loss: 2.401141405105591
Validation loss: 1.9091324742122362

Epoch: 6| Step: 7
Training loss: 2.538346767425537
Validation loss: 1.892400449322116

Epoch: 6| Step: 8
Training loss: 2.2328474521636963
Validation loss: 1.8947294976121636

Epoch: 6| Step: 9
Training loss: 2.5955333709716797
Validation loss: 1.9213447519527969

Epoch: 6| Step: 10
Training loss: 1.7746906280517578
Validation loss: 1.9075257726894912

Epoch: 6| Step: 11
Training loss: 1.9811391830444336
Validation loss: 1.90376603475181

Epoch: 6| Step: 12
Training loss: 1.5406922101974487
Validation loss: 1.9026566205486175

Epoch: 6| Step: 13
Training loss: 2.1054139137268066
Validation loss: 1.9197444556861796

Epoch: 102| Step: 0
Training loss: 1.8499877452850342
Validation loss: 1.910011511977001

Epoch: 6| Step: 1
Training loss: 1.9443166255950928
Validation loss: 1.893489101881622

Epoch: 6| Step: 2
Training loss: 2.1564197540283203
Validation loss: 1.87235184895095

Epoch: 6| Step: 3
Training loss: 1.7005281448364258
Validation loss: 1.8921953683258386

Epoch: 6| Step: 4
Training loss: 2.296896457672119
Validation loss: 1.8891614047429894

Epoch: 6| Step: 5
Training loss: 2.355752944946289
Validation loss: 1.8918415115725609

Epoch: 6| Step: 6
Training loss: 2.164257526397705
Validation loss: 1.8730499641869658

Epoch: 6| Step: 7
Training loss: 2.3482484817504883
Validation loss: 1.8826761835364885

Epoch: 6| Step: 8
Training loss: 2.0140204429626465
Validation loss: 1.8753688591782764

Epoch: 6| Step: 9
Training loss: 2.207613468170166
Validation loss: 1.8839549326127576

Epoch: 6| Step: 10
Training loss: 1.7371925115585327
Validation loss: 1.8878880841757661

Epoch: 6| Step: 11
Training loss: 1.9574344158172607
Validation loss: 1.887584796515844

Epoch: 6| Step: 12
Training loss: 1.9425795078277588
Validation loss: 1.9056766238263858

Epoch: 6| Step: 13
Training loss: 1.9671636819839478
Validation loss: 1.889998492374215

Epoch: 103| Step: 0
Training loss: 2.9872546195983887
Validation loss: 1.8876869396496845

Epoch: 6| Step: 1
Training loss: 2.4380171298980713
Validation loss: 1.9024857449275192

Epoch: 6| Step: 2
Training loss: 1.5455448627471924
Validation loss: 1.8900439021407918

Epoch: 6| Step: 3
Training loss: 2.105087995529175
Validation loss: 1.8970341861888926

Epoch: 6| Step: 4
Training loss: 2.046071767807007
Validation loss: 1.8983492030892322

Epoch: 6| Step: 5
Training loss: 1.4826070070266724
Validation loss: 1.919080840644016

Epoch: 6| Step: 6
Training loss: 1.8392248153686523
Validation loss: 1.9216454567447785

Epoch: 6| Step: 7
Training loss: 1.7127519845962524
Validation loss: 1.8874679842302877

Epoch: 6| Step: 8
Training loss: 2.4131221771240234
Validation loss: 1.9075855619163924

Epoch: 6| Step: 9
Training loss: 2.8342981338500977
Validation loss: 1.8912479813380907

Epoch: 6| Step: 10
Training loss: 2.3175771236419678
Validation loss: 1.8982792900454613

Epoch: 6| Step: 11
Training loss: 1.9891778230667114
Validation loss: 1.9024012627140168

Epoch: 6| Step: 12
Training loss: 1.5682141780853271
Validation loss: 1.9044864164885653

Epoch: 6| Step: 13
Training loss: 1.212972640991211
Validation loss: 1.8781364066626436

Epoch: 104| Step: 0
Training loss: 2.4940977096557617
Validation loss: 1.8850472114419425

Epoch: 6| Step: 1
Training loss: 2.1183903217315674
Validation loss: 1.8890241346051615

Epoch: 6| Step: 2
Training loss: 2.016003131866455
Validation loss: 1.9123669183382423

Epoch: 6| Step: 3
Training loss: 2.1917941570281982
Validation loss: 1.9025441087702268

Epoch: 6| Step: 4
Training loss: 2.0777363777160645
Validation loss: 1.9289711470245032

Epoch: 6| Step: 5
Training loss: 1.4357620477676392
Validation loss: 1.8977622114202028

Epoch: 6| Step: 6
Training loss: 2.4523212909698486
Validation loss: 1.8880436676804737

Epoch: 6| Step: 7
Training loss: 1.5641274452209473
Validation loss: 1.9062735470392371

Epoch: 6| Step: 8
Training loss: 2.0723977088928223
Validation loss: 1.9010990037713

Epoch: 6| Step: 9
Training loss: 2.3288638591766357
Validation loss: 1.8992396170093166

Epoch: 6| Step: 10
Training loss: 1.837023138999939
Validation loss: 1.9017126790938839

Epoch: 6| Step: 11
Training loss: 2.183145761489868
Validation loss: 1.8944255049510668

Epoch: 6| Step: 12
Training loss: 2.2011873722076416
Validation loss: 1.912391294715225

Epoch: 6| Step: 13
Training loss: 1.1676161289215088
Validation loss: 1.936658933598508

Epoch: 105| Step: 0
Training loss: 2.2910823822021484
Validation loss: 1.90316778485493

Epoch: 6| Step: 1
Training loss: 1.6100770235061646
Validation loss: 1.9189763876699633

Epoch: 6| Step: 2
Training loss: 1.8202353715896606
Validation loss: 1.921789200075211

Epoch: 6| Step: 3
Training loss: 2.4322597980499268
Validation loss: 1.90369067909897

Epoch: 6| Step: 4
Training loss: 2.4226367473602295
Validation loss: 1.9311212390981696

Epoch: 6| Step: 5
Training loss: 2.036313056945801
Validation loss: 1.9173133603988155

Epoch: 6| Step: 6
Training loss: 1.812036395072937
Validation loss: 1.918694729446083

Epoch: 6| Step: 7
Training loss: 2.0619444847106934
Validation loss: 1.9404309167656848

Epoch: 6| Step: 8
Training loss: 2.1211459636688232
Validation loss: 1.925147077088715

Epoch: 6| Step: 9
Training loss: 1.4088739156723022
Validation loss: 1.9133112084481023

Epoch: 6| Step: 10
Training loss: 2.3945655822753906
Validation loss: 1.9282294588704263

Epoch: 6| Step: 11
Training loss: 2.1864676475524902
Validation loss: 1.9249993319152503

Epoch: 6| Step: 12
Training loss: 1.761160135269165
Validation loss: 1.9299868370897026

Epoch: 6| Step: 13
Training loss: 2.0656445026397705
Validation loss: 1.9385791055617794

Epoch: 106| Step: 0
Training loss: 1.3254706859588623
Validation loss: 1.9085105696032125

Epoch: 6| Step: 1
Training loss: 1.4158174991607666
Validation loss: 1.8873822586510771

Epoch: 6| Step: 2
Training loss: 2.177206516265869
Validation loss: 1.9151049775461997

Epoch: 6| Step: 3
Training loss: 1.7265273332595825
Validation loss: 1.9029888312021892

Epoch: 6| Step: 4
Training loss: 2.913607120513916
Validation loss: 1.8959189999488093

Epoch: 6| Step: 5
Training loss: 2.207536220550537
Validation loss: 1.8922010852444557

Epoch: 6| Step: 6
Training loss: 1.4214682579040527
Validation loss: 1.9026285602200417

Epoch: 6| Step: 7
Training loss: 2.7291488647460938
Validation loss: 1.9050109976081437

Epoch: 6| Step: 8
Training loss: 2.2465009689331055
Validation loss: 1.882735800999467

Epoch: 6| Step: 9
Training loss: 2.961535930633545
Validation loss: 1.8787583407535349

Epoch: 6| Step: 10
Training loss: 2.3920068740844727
Validation loss: 1.8836411276171285

Epoch: 6| Step: 11
Training loss: 1.6930975914001465
Validation loss: 1.87939792038292

Epoch: 6| Step: 12
Training loss: 1.3903263807296753
Validation loss: 1.883234849540136

Epoch: 6| Step: 13
Training loss: 1.9543737173080444
Validation loss: 1.8690307524896437

Epoch: 107| Step: 0
Training loss: 1.9461697340011597
Validation loss: 1.9018906406176987

Epoch: 6| Step: 1
Training loss: 1.971775770187378
Validation loss: 1.887569647963329

Epoch: 6| Step: 2
Training loss: 1.792754054069519
Validation loss: 1.887102480857603

Epoch: 6| Step: 3
Training loss: 2.0204358100891113
Validation loss: 1.8864848895739483

Epoch: 6| Step: 4
Training loss: 2.325984001159668
Validation loss: 1.9006538826932189

Epoch: 6| Step: 5
Training loss: 2.0274763107299805
Validation loss: 1.8983150156595374

Epoch: 6| Step: 6
Training loss: 1.356508731842041
Validation loss: 1.9119275859607163

Epoch: 6| Step: 7
Training loss: 2.5207347869873047
Validation loss: 1.9210047170680056

Epoch: 6| Step: 8
Training loss: 1.9949209690093994
Validation loss: 1.885966606037591

Epoch: 6| Step: 9
Training loss: 2.1251308917999268
Validation loss: 1.9063893864231725

Epoch: 6| Step: 10
Training loss: 1.302309513092041
Validation loss: 1.9241448499823128

Epoch: 6| Step: 11
Training loss: 2.196798801422119
Validation loss: 1.8983631621124923

Epoch: 6| Step: 12
Training loss: 2.1941983699798584
Validation loss: 1.9124712649212088

Epoch: 6| Step: 13
Training loss: 2.8673534393310547
Validation loss: 1.891070617142544

Epoch: 108| Step: 0
Training loss: 2.3919997215270996
Validation loss: 1.9006361038454118

Epoch: 6| Step: 1
Training loss: 2.488986015319824
Validation loss: 1.9055456525535994

Epoch: 6| Step: 2
Training loss: 2.3782565593719482
Validation loss: 1.9074976598062823

Epoch: 6| Step: 3
Training loss: 2.5037176609039307
Validation loss: 1.9183907175576815

Epoch: 6| Step: 4
Training loss: 1.821990966796875
Validation loss: 1.9231455249171103

Epoch: 6| Step: 5
Training loss: 1.356912612915039
Validation loss: 1.9025601981788554

Epoch: 6| Step: 6
Training loss: 1.74832284450531
Validation loss: 1.936693222292008

Epoch: 6| Step: 7
Training loss: 2.3841145038604736
Validation loss: 1.9176053513762772

Epoch: 6| Step: 8
Training loss: 2.5108189582824707
Validation loss: 1.9234152788756995

Epoch: 6| Step: 9
Training loss: 2.069638252258301
Validation loss: 1.9366121522841915

Epoch: 6| Step: 10
Training loss: 1.3898155689239502
Validation loss: 1.9429991475997432

Epoch: 6| Step: 11
Training loss: 2.2803635597229004
Validation loss: 1.9246698476934945

Epoch: 6| Step: 12
Training loss: 1.3440569639205933
Validation loss: 1.932317813237508

Epoch: 6| Step: 13
Training loss: 1.9061503410339355
Validation loss: 1.9435109822980818

Epoch: 109| Step: 0
Training loss: 2.716247797012329
Validation loss: 1.938419427922977

Epoch: 6| Step: 1
Training loss: 1.9306740760803223
Validation loss: 1.9189863358774493

Epoch: 6| Step: 2
Training loss: 2.6235907077789307
Validation loss: 1.8918495665314377

Epoch: 6| Step: 3
Training loss: 2.341858386993408
Validation loss: 1.9014495982918689

Epoch: 6| Step: 4
Training loss: 1.7873958349227905
Validation loss: 1.8949867448499125

Epoch: 6| Step: 5
Training loss: 1.4272630214691162
Validation loss: 1.9132072220566452

Epoch: 6| Step: 6
Training loss: 1.584580898284912
Validation loss: 1.8834458986918132

Epoch: 6| Step: 7
Training loss: 1.6424814462661743
Validation loss: 1.8794278047418083

Epoch: 6| Step: 8
Training loss: 1.9643915891647339
Validation loss: 1.9010303648569251

Epoch: 6| Step: 9
Training loss: 2.6048078536987305
Validation loss: 1.9002496247650476

Epoch: 6| Step: 10
Training loss: 1.3446784019470215
Validation loss: 1.8831311836037585

Epoch: 6| Step: 11
Training loss: 1.9495792388916016
Validation loss: 1.8633017975796935

Epoch: 6| Step: 12
Training loss: 2.353851318359375
Validation loss: 1.8921306376816125

Epoch: 6| Step: 13
Training loss: 2.076855182647705
Validation loss: 1.8799783093954927

Epoch: 110| Step: 0
Training loss: 2.155992031097412
Validation loss: 1.8947476187059957

Epoch: 6| Step: 1
Training loss: 1.7256802320480347
Validation loss: 1.8522211684975574

Epoch: 6| Step: 2
Training loss: 1.958482265472412
Validation loss: 1.889119778909991

Epoch: 6| Step: 3
Training loss: 1.7246172428131104
Validation loss: 1.8746220437429284

Epoch: 6| Step: 4
Training loss: 2.6797165870666504
Validation loss: 1.8872225874213762

Epoch: 6| Step: 5
Training loss: 1.788288950920105
Validation loss: 1.8877614275101693

Epoch: 6| Step: 6
Training loss: 2.460658073425293
Validation loss: 1.8762012758562643

Epoch: 6| Step: 7
Training loss: 1.9217653274536133
Validation loss: 1.8794543717497139

Epoch: 6| Step: 8
Training loss: 2.0084068775177
Validation loss: 1.882810474723898

Epoch: 6| Step: 9
Training loss: 2.156008243560791
Validation loss: 1.904419869504949

Epoch: 6| Step: 10
Training loss: 2.162320613861084
Validation loss: 1.879754868886804

Epoch: 6| Step: 11
Training loss: 2.0576868057250977
Validation loss: 1.8958519222915813

Epoch: 6| Step: 12
Training loss: 1.7004246711730957
Validation loss: 1.9176794380270026

Epoch: 6| Step: 13
Training loss: 1.7001676559448242
Validation loss: 1.9052665977067844

Epoch: 111| Step: 0
Training loss: 2.4652113914489746
Validation loss: 1.9202752420979161

Epoch: 6| Step: 1
Training loss: 1.5962815284729004
Validation loss: 1.9015359211993474

Epoch: 6| Step: 2
Training loss: 2.08675217628479
Validation loss: 1.9024888700054539

Epoch: 6| Step: 3
Training loss: 1.9075673818588257
Validation loss: 1.9168245510388446

Epoch: 6| Step: 4
Training loss: 2.153932571411133
Validation loss: 1.893598630864133

Epoch: 6| Step: 5
Training loss: 1.909296989440918
Validation loss: 1.8924941221872966

Epoch: 6| Step: 6
Training loss: 1.3132702112197876
Validation loss: 1.9061595829584266

Epoch: 6| Step: 7
Training loss: 2.1323671340942383
Validation loss: 1.9170480723022132

Epoch: 6| Step: 8
Training loss: 1.8598294258117676
Validation loss: 1.8829338063475907

Epoch: 6| Step: 9
Training loss: 2.143925666809082
Validation loss: 1.9223391727734638

Epoch: 6| Step: 10
Training loss: 2.0765275955200195
Validation loss: 1.9122443147884902

Epoch: 6| Step: 11
Training loss: 2.0474629402160645
Validation loss: 1.9253095465321695

Epoch: 6| Step: 12
Training loss: 2.2647433280944824
Validation loss: 1.89867522639613

Epoch: 6| Step: 13
Training loss: 2.778693675994873
Validation loss: 1.9206578295717958

Epoch: 112| Step: 0
Training loss: 2.051464080810547
Validation loss: 1.919461828406139

Epoch: 6| Step: 1
Training loss: 2.1367807388305664
Validation loss: 1.8866847407433294

Epoch: 6| Step: 2
Training loss: 1.8399746417999268
Validation loss: 1.920041343217255

Epoch: 6| Step: 3
Training loss: 2.085702419281006
Validation loss: 1.9120376725350656

Epoch: 6| Step: 4
Training loss: 2.2275991439819336
Validation loss: 1.9184249716420327

Epoch: 6| Step: 5
Training loss: 1.9510130882263184
Validation loss: 1.8952111531329412

Epoch: 6| Step: 6
Training loss: 2.535818099975586
Validation loss: 1.8968804126144738

Epoch: 6| Step: 7
Training loss: 1.903031349182129
Validation loss: 1.928157442359514

Epoch: 6| Step: 8
Training loss: 2.861586093902588
Validation loss: 1.8945584374089395

Epoch: 6| Step: 9
Training loss: 1.6184368133544922
Validation loss: 1.9126727850206438

Epoch: 6| Step: 10
Training loss: 2.257671356201172
Validation loss: 1.9051833844953967

Epoch: 6| Step: 11
Training loss: 1.8360941410064697
Validation loss: 1.9041042750881565

Epoch: 6| Step: 12
Training loss: 1.3532556295394897
Validation loss: 1.933015610582085

Epoch: 6| Step: 13
Training loss: 1.4135422706604004
Validation loss: 1.938115127625004

Epoch: 113| Step: 0
Training loss: 2.26065993309021
Validation loss: 1.9148519705700617

Epoch: 6| Step: 1
Training loss: 1.6531370878219604
Validation loss: 1.9085004521954445

Epoch: 6| Step: 2
Training loss: 2.753438711166382
Validation loss: 1.8854774454588532

Epoch: 6| Step: 3
Training loss: 1.721763014793396
Validation loss: 1.9028970938856884

Epoch: 6| Step: 4
Training loss: 1.7520819902420044
Validation loss: 1.916015258399389

Epoch: 6| Step: 5
Training loss: 2.4619498252868652
Validation loss: 1.906859177415089

Epoch: 6| Step: 6
Training loss: 1.5110875368118286
Validation loss: 1.9037550995426793

Epoch: 6| Step: 7
Training loss: 2.1904711723327637
Validation loss: 1.9134925488502748

Epoch: 6| Step: 8
Training loss: 1.8550372123718262
Validation loss: 1.890343632749332

Epoch: 6| Step: 9
Training loss: 2.2301220893859863
Validation loss: 1.9231987063602736

Epoch: 6| Step: 10
Training loss: 2.3481969833374023
Validation loss: 1.9040496105788856

Epoch: 6| Step: 11
Training loss: 1.7940672636032104
Validation loss: 1.9030275626849102

Epoch: 6| Step: 12
Training loss: 1.838767170906067
Validation loss: 1.9256828549087688

Epoch: 6| Step: 13
Training loss: 1.3384647369384766
Validation loss: 1.9040795141650784

Epoch: 114| Step: 0
Training loss: 1.987319827079773
Validation loss: 1.918183962504069

Epoch: 6| Step: 1
Training loss: 2.474689245223999
Validation loss: 1.8933308618043059

Epoch: 6| Step: 2
Training loss: 1.2409250736236572
Validation loss: 1.887268284315704

Epoch: 6| Step: 3
Training loss: 3.1099705696105957
Validation loss: 1.8876347567445488

Epoch: 6| Step: 4
Training loss: 3.011990547180176
Validation loss: 1.8996914009894095

Epoch: 6| Step: 5
Training loss: 2.3349928855895996
Validation loss: 1.8853870450809438

Epoch: 6| Step: 6
Training loss: 1.9578546285629272
Validation loss: 1.8856466149771085

Epoch: 6| Step: 7
Training loss: 1.450606346130371
Validation loss: 1.893605060474847

Epoch: 6| Step: 8
Training loss: 1.3900644779205322
Validation loss: 1.8820730640042214

Epoch: 6| Step: 9
Training loss: 2.2305779457092285
Validation loss: 1.8844277422915223

Epoch: 6| Step: 10
Training loss: 1.6835601329803467
Validation loss: 1.9110268572325348

Epoch: 6| Step: 11
Training loss: 1.6399627923965454
Validation loss: 1.8809907513280069

Epoch: 6| Step: 12
Training loss: 2.0608253479003906
Validation loss: 1.896060174511325

Epoch: 6| Step: 13
Training loss: 1.4156396389007568
Validation loss: 1.895149141229609

Epoch: 115| Step: 0
Training loss: 1.991819143295288
Validation loss: 1.9086969924229447

Epoch: 6| Step: 1
Training loss: 2.209041118621826
Validation loss: 1.8930176099141438

Epoch: 6| Step: 2
Training loss: 2.2443671226501465
Validation loss: 1.901322877535256

Epoch: 6| Step: 3
Training loss: 2.1385297775268555
Validation loss: 1.925050699582664

Epoch: 6| Step: 4
Training loss: 1.9314849376678467
Validation loss: 1.9082372214204522

Epoch: 6| Step: 5
Training loss: 2.023477077484131
Validation loss: 1.9192467351113596

Epoch: 6| Step: 6
Training loss: 2.1698832511901855
Validation loss: 1.8965724283649075

Epoch: 6| Step: 7
Training loss: 1.7516931295394897
Validation loss: 1.8842035737088931

Epoch: 6| Step: 8
Training loss: 2.8150033950805664
Validation loss: 1.9204111663244103

Epoch: 6| Step: 9
Training loss: 1.9966777563095093
Validation loss: 1.9247093136592577

Epoch: 6| Step: 10
Training loss: 1.4220776557922363
Validation loss: 1.9389475725030387

Epoch: 6| Step: 11
Training loss: 2.2351832389831543
Validation loss: 1.9030162877933954

Epoch: 6| Step: 12
Training loss: 1.5183719396591187
Validation loss: 1.8967550698147024

Epoch: 6| Step: 13
Training loss: 1.6514159440994263
Validation loss: 1.910446746374971

Epoch: 116| Step: 0
Training loss: 2.9638965129852295
Validation loss: 1.893623523814704

Epoch: 6| Step: 1
Training loss: 1.2047455310821533
Validation loss: 1.9159714457809285

Epoch: 6| Step: 2
Training loss: 2.194709300994873
Validation loss: 1.88041002263305

Epoch: 6| Step: 3
Training loss: 1.8019421100616455
Validation loss: 1.9156657777806765

Epoch: 6| Step: 4
Training loss: 2.5232577323913574
Validation loss: 1.9150143310587893

Epoch: 6| Step: 5
Training loss: 1.6542835235595703
Validation loss: 1.9076790348176034

Epoch: 6| Step: 6
Training loss: 1.6570323705673218
Validation loss: 1.9029227405466058

Epoch: 6| Step: 7
Training loss: 1.6602234840393066
Validation loss: 1.8869781545413438

Epoch: 6| Step: 8
Training loss: 2.6837873458862305
Validation loss: 1.8618064798334593

Epoch: 6| Step: 9
Training loss: 1.7870330810546875
Validation loss: 1.8828321785055182

Epoch: 6| Step: 10
Training loss: 1.464559555053711
Validation loss: 1.9184577336875341

Epoch: 6| Step: 11
Training loss: 2.1621830463409424
Validation loss: 1.881814451627834

Epoch: 6| Step: 12
Training loss: 2.5857603549957275
Validation loss: 1.8774932456272904

Epoch: 6| Step: 13
Training loss: 1.6568450927734375
Validation loss: 1.886387614793675

Epoch: 117| Step: 0
Training loss: 1.5837100744247437
Validation loss: 1.8723612946848716

Epoch: 6| Step: 1
Training loss: 2.061366319656372
Validation loss: 1.8863400118325346

Epoch: 6| Step: 2
Training loss: 1.3811208009719849
Validation loss: 1.8790643894544212

Epoch: 6| Step: 3
Training loss: 2.644920587539673
Validation loss: 1.9228235598533385

Epoch: 6| Step: 4
Training loss: 3.0398731231689453
Validation loss: 1.9033960514171149

Epoch: 6| Step: 5
Training loss: 1.868441104888916
Validation loss: 1.919310882527341

Epoch: 6| Step: 6
Training loss: 2.404737949371338
Validation loss: 1.9170824302140104

Epoch: 6| Step: 7
Training loss: 2.1905529499053955
Validation loss: 1.9092735116199782

Epoch: 6| Step: 8
Training loss: 1.6304869651794434
Validation loss: 1.9139982923384635

Epoch: 6| Step: 9
Training loss: 1.4937477111816406
Validation loss: 1.9312202033176218

Epoch: 6| Step: 10
Training loss: 2.2934794425964355
Validation loss: 1.9302293972302509

Epoch: 6| Step: 11
Training loss: 1.7473829984664917
Validation loss: 1.9267632525454286

Epoch: 6| Step: 12
Training loss: 1.8051263093948364
Validation loss: 1.9125808567129157

Epoch: 6| Step: 13
Training loss: 2.12591814994812
Validation loss: 1.9125989098702707

Epoch: 118| Step: 0
Training loss: 1.9736369848251343
Validation loss: 1.915084731194281

Epoch: 6| Step: 1
Training loss: 3.104109287261963
Validation loss: 1.9458208725016604

Epoch: 6| Step: 2
Training loss: 2.101081371307373
Validation loss: 1.925809334683162

Epoch: 6| Step: 3
Training loss: 2.4907002449035645
Validation loss: 1.9062005114811722

Epoch: 6| Step: 4
Training loss: 1.7403883934020996
Validation loss: 1.9003095575558242

Epoch: 6| Step: 5
Training loss: 2.413944959640503
Validation loss: 1.8977221288988668

Epoch: 6| Step: 6
Training loss: 1.6148179769515991
Validation loss: 1.9241734294481174

Epoch: 6| Step: 7
Training loss: 1.6079181432724
Validation loss: 1.8895838305514345

Epoch: 6| Step: 8
Training loss: 2.2410247325897217
Validation loss: 1.8909581476642239

Epoch: 6| Step: 9
Training loss: 2.4571919441223145
Validation loss: 1.8978413420338784

Epoch: 6| Step: 10
Training loss: 1.8462034463882446
Validation loss: 1.9308111257450555

Epoch: 6| Step: 11
Training loss: 1.1988534927368164
Validation loss: 1.910213839623236

Epoch: 6| Step: 12
Training loss: 1.4573153257369995
Validation loss: 1.9246942176613757

Epoch: 6| Step: 13
Training loss: 1.4843424558639526
Validation loss: 1.905658571950851

Epoch: 119| Step: 0
Training loss: 2.1804471015930176
Validation loss: 1.9102517430500319

Epoch: 6| Step: 1
Training loss: 1.8123191595077515
Validation loss: 1.9114470917691466

Epoch: 6| Step: 2
Training loss: 2.1215767860412598
Validation loss: 1.9016145929213493

Epoch: 6| Step: 3
Training loss: 1.7403392791748047
Validation loss: 1.8990223151381298

Epoch: 6| Step: 4
Training loss: 1.9237370491027832
Validation loss: 1.9170146296101231

Epoch: 6| Step: 5
Training loss: 2.4665088653564453
Validation loss: 1.9257199430978427

Epoch: 6| Step: 6
Training loss: 2.4538590908050537
Validation loss: 1.9033242066701253

Epoch: 6| Step: 7
Training loss: 1.7914618253707886
Validation loss: 1.8978239554230885

Epoch: 6| Step: 8
Training loss: 1.7130486965179443
Validation loss: 1.926145540770664

Epoch: 6| Step: 9
Training loss: 1.9148796796798706
Validation loss: 1.9197371595649309

Epoch: 6| Step: 10
Training loss: 2.18365216255188
Validation loss: 1.9011390157925185

Epoch: 6| Step: 11
Training loss: 1.4853310585021973
Validation loss: 1.8981906393522858

Epoch: 6| Step: 12
Training loss: 2.005765914916992
Validation loss: 1.9104278087615967

Epoch: 6| Step: 13
Training loss: 1.854382038116455
Validation loss: 1.91313838061466

Epoch: 120| Step: 0
Training loss: 2.3993444442749023
Validation loss: 1.888190757843756

Epoch: 6| Step: 1
Training loss: 2.332862377166748
Validation loss: 1.9068616282555364

Epoch: 6| Step: 2
Training loss: 2.7249369621276855
Validation loss: 1.8824628117263957

Epoch: 6| Step: 3
Training loss: 1.3713386058807373
Validation loss: 1.8954302444252917

Epoch: 6| Step: 4
Training loss: 1.7257936000823975
Validation loss: 1.890673819408622

Epoch: 6| Step: 5
Training loss: 2.051684856414795
Validation loss: 1.8770707550869192

Epoch: 6| Step: 6
Training loss: 1.189058780670166
Validation loss: 1.8774968552333053

Epoch: 6| Step: 7
Training loss: 1.5803439617156982
Validation loss: 1.8901669235639675

Epoch: 6| Step: 8
Training loss: 2.138793706893921
Validation loss: 1.8834935452348442

Epoch: 6| Step: 9
Training loss: 2.106010675430298
Validation loss: 1.8921808658107635

Epoch: 6| Step: 10
Training loss: 1.9208807945251465
Validation loss: 1.88083299257422

Epoch: 6| Step: 11
Training loss: 1.9594390392303467
Validation loss: 1.8962737591035905

Epoch: 6| Step: 12
Training loss: 2.18489933013916
Validation loss: 1.8869275700661443

Epoch: 6| Step: 13
Training loss: 1.9882524013519287
Validation loss: 1.8807568332200408

Epoch: 121| Step: 0
Training loss: 2.3505406379699707
Validation loss: 1.9057392836898885

Epoch: 6| Step: 1
Training loss: 2.1544196605682373
Validation loss: 1.9181830985571748

Epoch: 6| Step: 2
Training loss: 1.9731388092041016
Validation loss: 1.873420561513593

Epoch: 6| Step: 3
Training loss: 1.5276658535003662
Validation loss: 1.9011510085034113

Epoch: 6| Step: 4
Training loss: 1.9868009090423584
Validation loss: 1.9066111426199637

Epoch: 6| Step: 5
Training loss: 3.2189064025878906
Validation loss: 1.902584901420019

Epoch: 6| Step: 6
Training loss: 1.9097355604171753
Validation loss: 1.90282259192518

Epoch: 6| Step: 7
Training loss: 2.0154566764831543
Validation loss: 1.8809783676619172

Epoch: 6| Step: 8
Training loss: 1.427846908569336
Validation loss: 1.8907206058502197

Epoch: 6| Step: 9
Training loss: 1.9082294702529907
Validation loss: 1.9020496094098656

Epoch: 6| Step: 10
Training loss: 1.3730682134628296
Validation loss: 1.8933379675752373

Epoch: 6| Step: 11
Training loss: 1.6405736207962036
Validation loss: 1.92215129252403

Epoch: 6| Step: 12
Training loss: 1.7936677932739258
Validation loss: 1.8810573124116468

Epoch: 6| Step: 13
Training loss: 2.6893064975738525
Validation loss: 1.8903708047764276

Epoch: 122| Step: 0
Training loss: 2.233638048171997
Validation loss: 1.912366699146968

Epoch: 6| Step: 1
Training loss: 1.832831859588623
Validation loss: 1.8685117101156583

Epoch: 6| Step: 2
Training loss: 1.186844825744629
Validation loss: 1.9223465791312597

Epoch: 6| Step: 3
Training loss: 1.9002032279968262
Validation loss: 1.911836137053787

Epoch: 6| Step: 4
Training loss: 2.080305576324463
Validation loss: 1.9001980391881799

Epoch: 6| Step: 5
Training loss: 2.183807373046875
Validation loss: 1.9249229995153283

Epoch: 6| Step: 6
Training loss: 1.7471370697021484
Validation loss: 1.9100390185591996

Epoch: 6| Step: 7
Training loss: 1.9008336067199707
Validation loss: 1.897861340994476

Epoch: 6| Step: 8
Training loss: 1.6156253814697266
Validation loss: 1.9121389491583711

Epoch: 6| Step: 9
Training loss: 2.155693292617798
Validation loss: 1.9198171977073915

Epoch: 6| Step: 10
Training loss: 2.217658519744873
Validation loss: 1.9118285332956622

Epoch: 6| Step: 11
Training loss: 1.985336184501648
Validation loss: 1.9162623164474324

Epoch: 6| Step: 12
Training loss: 2.366938591003418
Validation loss: 1.9426346645560315

Epoch: 6| Step: 13
Training loss: 2.3614606857299805
Validation loss: 1.9017977893993419

Epoch: 123| Step: 0
Training loss: 1.185808777809143
Validation loss: 1.8996330576558267

Epoch: 6| Step: 1
Training loss: 2.247908115386963
Validation loss: 1.8862574920859387

Epoch: 6| Step: 2
Training loss: 1.8744980096817017
Validation loss: 1.9022203517216507

Epoch: 6| Step: 3
Training loss: 2.036567211151123
Validation loss: 1.896617724049476

Epoch: 6| Step: 4
Training loss: 2.8364310264587402
Validation loss: 1.9129383192267468

Epoch: 6| Step: 5
Training loss: 2.097209930419922
Validation loss: 1.893814677833229

Epoch: 6| Step: 6
Training loss: 2.3375699520111084
Validation loss: 1.895502039181289

Epoch: 6| Step: 7
Training loss: 2.3348608016967773
Validation loss: 1.8901652546339138

Epoch: 6| Step: 8
Training loss: 2.208857297897339
Validation loss: 1.910653575774162

Epoch: 6| Step: 9
Training loss: 1.8033394813537598
Validation loss: 1.9122848459469375

Epoch: 6| Step: 10
Training loss: 1.438441276550293
Validation loss: 1.923415195557379

Epoch: 6| Step: 11
Training loss: 1.8517910242080688
Validation loss: 1.9134325340229978

Epoch: 6| Step: 12
Training loss: 1.8215365409851074
Validation loss: 1.904348861786627

Epoch: 6| Step: 13
Training loss: 1.4361042976379395
Validation loss: 1.9258313717380646

Epoch: 124| Step: 0
Training loss: 1.8432657718658447
Validation loss: 1.9295747792848976

Epoch: 6| Step: 1
Training loss: 1.6266119480133057
Validation loss: 1.9005298588865547

Epoch: 6| Step: 2
Training loss: 1.988940715789795
Validation loss: 1.8833423045373732

Epoch: 6| Step: 3
Training loss: 1.696230411529541
Validation loss: 1.878039583083122

Epoch: 6| Step: 4
Training loss: 1.165528655052185
Validation loss: 1.894659447413619

Epoch: 6| Step: 5
Training loss: 1.9488561153411865
Validation loss: 1.8783916158060874

Epoch: 6| Step: 6
Training loss: 2.882551670074463
Validation loss: 1.8822715205530967

Epoch: 6| Step: 7
Training loss: 1.9924848079681396
Validation loss: 1.8869339676313504

Epoch: 6| Step: 8
Training loss: 1.8364074230194092
Validation loss: 1.8755956529289164

Epoch: 6| Step: 9
Training loss: 2.2403621673583984
Validation loss: 1.8896624465142526

Epoch: 6| Step: 10
Training loss: 2.7882168292999268
Validation loss: 1.8873848287008141

Epoch: 6| Step: 11
Training loss: 1.6452362537384033
Validation loss: 1.9159013494368522

Epoch: 6| Step: 12
Training loss: 2.0671944618225098
Validation loss: 1.9146981982774631

Epoch: 6| Step: 13
Training loss: 1.7899430990219116
Validation loss: 1.9058425311119325

Epoch: 125| Step: 0
Training loss: 1.9197605848312378
Validation loss: 1.9244782463196786

Epoch: 6| Step: 1
Training loss: 2.26881742477417
Validation loss: 1.878717807031447

Epoch: 6| Step: 2
Training loss: 1.4151824712753296
Validation loss: 1.881091684423467

Epoch: 6| Step: 3
Training loss: 2.459153413772583
Validation loss: 1.9035032795321556

Epoch: 6| Step: 4
Training loss: 1.6276192665100098
Validation loss: 1.9014096952253772

Epoch: 6| Step: 5
Training loss: 2.2346010208129883
Validation loss: 1.880592994792487

Epoch: 6| Step: 6
Training loss: 1.98714280128479
Validation loss: 1.898025966459705

Epoch: 6| Step: 7
Training loss: 2.2067813873291016
Validation loss: 1.9212017059326172

Epoch: 6| Step: 8
Training loss: 2.1881284713745117
Validation loss: 1.8827470887091853

Epoch: 6| Step: 9
Training loss: 1.5682108402252197
Validation loss: 1.8925986007977558

Epoch: 6| Step: 10
Training loss: 1.840517520904541
Validation loss: 1.9118376508835824

Epoch: 6| Step: 11
Training loss: 1.9881000518798828
Validation loss: 1.8917069447937833

Epoch: 6| Step: 12
Training loss: 1.993647575378418
Validation loss: 1.8982434554766583

Epoch: 6| Step: 13
Training loss: 1.6119023561477661
Validation loss: 1.9314249753952026

Epoch: 126| Step: 0
Training loss: 2.057461977005005
Validation loss: 1.917296221179347

Epoch: 6| Step: 1
Training loss: 2.2667715549468994
Validation loss: 1.9124945286781556

Epoch: 6| Step: 2
Training loss: 1.9225741624832153
Validation loss: 1.907137341396783

Epoch: 6| Step: 3
Training loss: 1.6593034267425537
Validation loss: 1.914191290896426

Epoch: 6| Step: 4
Training loss: 2.8127574920654297
Validation loss: 1.9201336970893286

Epoch: 6| Step: 5
Training loss: 1.6631112098693848
Validation loss: 1.9256767816441034

Epoch: 6| Step: 6
Training loss: 1.9965598583221436
Validation loss: 1.9105859392432756

Epoch: 6| Step: 7
Training loss: 2.447153091430664
Validation loss: 1.9284236828486125

Epoch: 6| Step: 8
Training loss: 2.036659002304077
Validation loss: 1.934113722975536

Epoch: 6| Step: 9
Training loss: 2.0319111347198486
Validation loss: 1.9196354304590533

Epoch: 6| Step: 10
Training loss: 1.7265008687973022
Validation loss: 1.9031322822775891

Epoch: 6| Step: 11
Training loss: 1.5243775844573975
Validation loss: 1.9182166681494763

Epoch: 6| Step: 12
Training loss: 1.640946388244629
Validation loss: 1.8827293316523235

Epoch: 6| Step: 13
Training loss: 1.7643609046936035
Validation loss: 1.9111878384826004

Epoch: 127| Step: 0
Training loss: 2.206174373626709
Validation loss: 1.9172968851622714

Epoch: 6| Step: 1
Training loss: 1.386378288269043
Validation loss: 1.9162754269056423

Epoch: 6| Step: 2
Training loss: 2.0543439388275146
Validation loss: 1.9194098723831998

Epoch: 6| Step: 3
Training loss: 2.3994107246398926
Validation loss: 1.9219467986014582

Epoch: 6| Step: 4
Training loss: 2.1773481369018555
Validation loss: 1.9051846573429723

Epoch: 6| Step: 5
Training loss: 2.0587122440338135
Validation loss: 1.9257849185697493

Epoch: 6| Step: 6
Training loss: 1.8669408559799194
Validation loss: 1.906086608927737

Epoch: 6| Step: 7
Training loss: 2.8807616233825684
Validation loss: 1.9285485206111785

Epoch: 6| Step: 8
Training loss: 1.3811166286468506
Validation loss: 1.90387176698254

Epoch: 6| Step: 9
Training loss: 1.3100602626800537
Validation loss: 1.9155890146891277

Epoch: 6| Step: 10
Training loss: 2.0718703269958496
Validation loss: 1.9224428105097946

Epoch: 6| Step: 11
Training loss: 1.7614448070526123
Validation loss: 1.9440313590470182

Epoch: 6| Step: 12
Training loss: 2.04305362701416
Validation loss: 1.954120594968078

Epoch: 6| Step: 13
Training loss: 1.9615228176116943
Validation loss: 1.9222128211811025

Epoch: 128| Step: 0
Training loss: 1.710585117340088
Validation loss: 1.891303725140069

Epoch: 6| Step: 1
Training loss: 1.503554344177246
Validation loss: 1.9135591099339146

Epoch: 6| Step: 2
Training loss: 2.6360855102539062
Validation loss: 1.914677079005908

Epoch: 6| Step: 3
Training loss: 1.8182059526443481
Validation loss: 1.9325593210035754

Epoch: 6| Step: 4
Training loss: 2.120553493499756
Validation loss: 1.8902090146977415

Epoch: 6| Step: 5
Training loss: 1.9344981908798218
Validation loss: 1.8888510363076323

Epoch: 6| Step: 6
Training loss: 1.6260440349578857
Validation loss: 1.9101611362990512

Epoch: 6| Step: 7
Training loss: 1.6354916095733643
Validation loss: 1.9193850230145197

Epoch: 6| Step: 8
Training loss: 1.956748366355896
Validation loss: 1.9015651659298969

Epoch: 6| Step: 9
Training loss: 1.8194501399993896
Validation loss: 1.8826755733900173

Epoch: 6| Step: 10
Training loss: 2.3182735443115234
Validation loss: 1.9021696941826933

Epoch: 6| Step: 11
Training loss: 1.9430633783340454
Validation loss: 1.914931135792886

Epoch: 6| Step: 12
Training loss: 2.357909679412842
Validation loss: 1.8795805541417931

Epoch: 6| Step: 13
Training loss: 1.8653932809829712
Validation loss: 1.8779644068851267

Epoch: 129| Step: 0
Training loss: 1.8758982419967651
Validation loss: 1.8894549595412387

Epoch: 6| Step: 1
Training loss: 1.3531675338745117
Validation loss: 1.8862536991796186

Epoch: 6| Step: 2
Training loss: 2.0847010612487793
Validation loss: 1.8800484480396393

Epoch: 6| Step: 3
Training loss: 2.631866455078125
Validation loss: 1.9060788910876039

Epoch: 6| Step: 4
Training loss: 1.6978858709335327
Validation loss: 1.88884308004892

Epoch: 6| Step: 5
Training loss: 2.038968563079834
Validation loss: 1.8689680560942619

Epoch: 6| Step: 6
Training loss: 1.8804265260696411
Validation loss: 1.8790694923811062

Epoch: 6| Step: 7
Training loss: 1.907090663909912
Validation loss: 1.8844963863331785

Epoch: 6| Step: 8
Training loss: 2.0998451709747314
Validation loss: 1.8819262058504167

Epoch: 6| Step: 9
Training loss: 1.2730637788772583
Validation loss: 1.9078693902620705

Epoch: 6| Step: 10
Training loss: 2.314849376678467
Validation loss: 1.9103108849576724

Epoch: 6| Step: 11
Training loss: 1.2429276704788208
Validation loss: 1.8860070372140536

Epoch: 6| Step: 12
Training loss: 2.689763307571411
Validation loss: 1.9041844952491023

Epoch: 6| Step: 13
Training loss: 2.19695782661438
Validation loss: 1.88449768353534

Epoch: 130| Step: 0
Training loss: 2.6534273624420166
Validation loss: 1.9146816563862625

Epoch: 6| Step: 1
Training loss: 1.9382463693618774
Validation loss: 1.8860897018063454

Epoch: 6| Step: 2
Training loss: 1.40134596824646
Validation loss: 1.902095402440717

Epoch: 6| Step: 3
Training loss: 1.6643399000167847
Validation loss: 1.915133185284112

Epoch: 6| Step: 4
Training loss: 1.3956928253173828
Validation loss: 1.9138869072801323

Epoch: 6| Step: 5
Training loss: 2.100984573364258
Validation loss: 1.9025062386707594

Epoch: 6| Step: 6
Training loss: 1.9229475259780884
Validation loss: 1.9237304349099436

Epoch: 6| Step: 7
Training loss: 1.631746530532837
Validation loss: 1.9256202969499814

Epoch: 6| Step: 8
Training loss: 2.460940361022949
Validation loss: 1.902383223656685

Epoch: 6| Step: 9
Training loss: 2.041595935821533
Validation loss: 1.8974330463717062

Epoch: 6| Step: 10
Training loss: 2.2111997604370117
Validation loss: 1.917548535972513

Epoch: 6| Step: 11
Training loss: 2.4319162368774414
Validation loss: 1.9104246683018182

Epoch: 6| Step: 12
Training loss: 1.8317115306854248
Validation loss: 1.9107825909891436

Epoch: 6| Step: 13
Training loss: 1.010311245918274
Validation loss: 1.900053208874118

Epoch: 131| Step: 0
Training loss: 1.2944011688232422
Validation loss: 1.9281380407271846

Epoch: 6| Step: 1
Training loss: 2.993962287902832
Validation loss: 1.9112685700898528

Epoch: 6| Step: 2
Training loss: 1.955700397491455
Validation loss: 1.9153491361166841

Epoch: 6| Step: 3
Training loss: 1.3456385135650635
Validation loss: 1.9361333744500273

Epoch: 6| Step: 4
Training loss: 2.039761543273926
Validation loss: 1.9044766015903924

Epoch: 6| Step: 5
Training loss: 1.913084626197815
Validation loss: 1.8894637964105094

Epoch: 6| Step: 6
Training loss: 1.9518216848373413
Validation loss: 1.8836366245823521

Epoch: 6| Step: 7
Training loss: 1.4282331466674805
Validation loss: 1.9023463097951745

Epoch: 6| Step: 8
Training loss: 2.0730972290039062
Validation loss: 1.8910963355853994

Epoch: 6| Step: 9
Training loss: 1.6590147018432617
Validation loss: 1.8776882361340266

Epoch: 6| Step: 10
Training loss: 2.0310683250427246
Validation loss: 1.883076847240489

Epoch: 6| Step: 11
Training loss: 1.9054129123687744
Validation loss: 1.8964500811792189

Epoch: 6| Step: 12
Training loss: 1.6393176317214966
Validation loss: 1.9007448944994199

Epoch: 6| Step: 13
Training loss: 3.2055277824401855
Validation loss: 1.9116663214980916

Epoch: 132| Step: 0
Training loss: 2.0424420833587646
Validation loss: 1.8869830408403951

Epoch: 6| Step: 1
Training loss: 1.5080816745758057
Validation loss: 1.895030531831967

Epoch: 6| Step: 2
Training loss: 2.405052423477173
Validation loss: 1.8908528409978396

Epoch: 6| Step: 3
Training loss: 2.3590989112854004
Validation loss: 1.911677437443887

Epoch: 6| Step: 4
Training loss: 1.9872090816497803
Validation loss: 1.8963332176208496

Epoch: 6| Step: 5
Training loss: 1.4616472721099854
Validation loss: 1.9155636243922736

Epoch: 6| Step: 6
Training loss: 2.170910358428955
Validation loss: 1.8824038640145333

Epoch: 6| Step: 7
Training loss: 1.4967504739761353
Validation loss: 1.9034197227929228

Epoch: 6| Step: 8
Training loss: 1.6406214237213135
Validation loss: 1.8887328024833434

Epoch: 6| Step: 9
Training loss: 2.983090877532959
Validation loss: 1.8643941155043982

Epoch: 6| Step: 10
Training loss: 1.4126743078231812
Validation loss: 1.8928460023736442

Epoch: 6| Step: 11
Training loss: 1.3994078636169434
Validation loss: 1.8984635312070128

Epoch: 6| Step: 12
Training loss: 2.3217251300811768
Validation loss: 1.8973409206636491

Epoch: 6| Step: 13
Training loss: 1.7600563764572144
Validation loss: 1.908804274374439

Epoch: 133| Step: 0
Training loss: 1.8250010013580322
Validation loss: 1.92928788738866

Epoch: 6| Step: 1
Training loss: 1.8734540939331055
Validation loss: 1.9060337761397004

Epoch: 6| Step: 2
Training loss: 2.105259418487549
Validation loss: 1.8935969901341263

Epoch: 6| Step: 3
Training loss: 1.3282297849655151
Validation loss: 1.9146769187783683

Epoch: 6| Step: 4
Training loss: 1.4682774543762207
Validation loss: 1.9070156710122221

Epoch: 6| Step: 5
Training loss: 1.5040996074676514
Validation loss: 1.9153906735040809

Epoch: 6| Step: 6
Training loss: 2.4057016372680664
Validation loss: 1.9034669681261944

Epoch: 6| Step: 7
Training loss: 2.4329490661621094
Validation loss: 1.914029175235379

Epoch: 6| Step: 8
Training loss: 2.703456401824951
Validation loss: 1.9113220078970796

Epoch: 6| Step: 9
Training loss: 1.8466144800186157
Validation loss: 1.930560955437281

Epoch: 6| Step: 10
Training loss: 2.731278896331787
Validation loss: 1.9267545310399865

Epoch: 6| Step: 11
Training loss: 1.2736985683441162
Validation loss: 1.9168399380099388

Epoch: 6| Step: 12
Training loss: 1.4038175344467163
Validation loss: 1.941091065765709

Epoch: 6| Step: 13
Training loss: 2.1903233528137207
Validation loss: 1.9367764713943645

Epoch: 134| Step: 0
Training loss: 2.2051570415496826
Validation loss: 1.9433582803254486

Epoch: 6| Step: 1
Training loss: 1.9461402893066406
Validation loss: 1.9283140179931477

Epoch: 6| Step: 2
Training loss: 2.3575758934020996
Validation loss: 1.9158259514839417

Epoch: 6| Step: 3
Training loss: 2.1759209632873535
Validation loss: 1.9262309330765919

Epoch: 6| Step: 4
Training loss: 1.4058103561401367
Validation loss: 1.9288075918792396

Epoch: 6| Step: 5
Training loss: 1.419220209121704
Validation loss: 1.9248411014515867

Epoch: 6| Step: 6
Training loss: 1.9211187362670898
Validation loss: 1.8926000877093243

Epoch: 6| Step: 7
Training loss: 1.7289297580718994
Validation loss: 1.9234263730305496

Epoch: 6| Step: 8
Training loss: 1.8488421440124512
Validation loss: 1.8868393769828222

Epoch: 6| Step: 9
Training loss: 2.6076345443725586
Validation loss: 1.8884313632083196

Epoch: 6| Step: 10
Training loss: 2.3014636039733887
Validation loss: 1.8972480117633779

Epoch: 6| Step: 11
Training loss: 1.2537986040115356
Validation loss: 1.8898539171423963

Epoch: 6| Step: 12
Training loss: 1.968306064605713
Validation loss: 1.8801957804669616

Epoch: 6| Step: 13
Training loss: 1.8844274282455444
Validation loss: 1.916194232561255

Epoch: 135| Step: 0
Training loss: 1.639868974685669
Validation loss: 1.8862393825284895

Epoch: 6| Step: 1
Training loss: 1.744586706161499
Validation loss: 1.8883592364608601

Epoch: 6| Step: 2
Training loss: 1.4428801536560059
Validation loss: 1.911746718550241

Epoch: 6| Step: 3
Training loss: 2.163390636444092
Validation loss: 1.9052292531536472

Epoch: 6| Step: 4
Training loss: 1.672337293624878
Validation loss: 1.882687609682801

Epoch: 6| Step: 5
Training loss: 2.5767807960510254
Validation loss: 1.8887219505925332

Epoch: 6| Step: 6
Training loss: 2.818631410598755
Validation loss: 1.903018238723919

Epoch: 6| Step: 7
Training loss: 2.109027862548828
Validation loss: 1.8969637168351041

Epoch: 6| Step: 8
Training loss: 1.4794013500213623
Validation loss: 1.87733962715313

Epoch: 6| Step: 9
Training loss: 2.3712940216064453
Validation loss: 1.8900602197134366

Epoch: 6| Step: 10
Training loss: 1.737428069114685
Validation loss: 1.9032646366344985

Epoch: 6| Step: 11
Training loss: 2.002164602279663
Validation loss: 1.9040106047866165

Epoch: 6| Step: 12
Training loss: 1.6014288663864136
Validation loss: 1.8979267343398063

Epoch: 6| Step: 13
Training loss: 1.301352620124817
Validation loss: 1.9167346108344294

Epoch: 136| Step: 0
Training loss: 1.900301218032837
Validation loss: 1.9284126130483483

Epoch: 6| Step: 1
Training loss: 1.77809739112854
Validation loss: 1.9047297175212572

Epoch: 6| Step: 2
Training loss: 1.624029517173767
Validation loss: 1.9098793716840847

Epoch: 6| Step: 3
Training loss: 2.055030107498169
Validation loss: 1.9262521331028273

Epoch: 6| Step: 4
Training loss: 1.706737756729126
Validation loss: 1.9117088804962814

Epoch: 6| Step: 5
Training loss: 2.3569324016571045
Validation loss: 1.9179023760621265

Epoch: 6| Step: 6
Training loss: 2.0738131999969482
Validation loss: 1.9443859823288456

Epoch: 6| Step: 7
Training loss: 2.123654365539551
Validation loss: 1.9473851880719584

Epoch: 6| Step: 8
Training loss: 1.430659294128418
Validation loss: 1.921599857268795

Epoch: 6| Step: 9
Training loss: 1.9747841358184814
Validation loss: 1.911211057375836

Epoch: 6| Step: 10
Training loss: 1.8469465970993042
Validation loss: 1.916407859453591

Epoch: 6| Step: 11
Training loss: 1.8143768310546875
Validation loss: 1.9000277314134824

Epoch: 6| Step: 12
Training loss: 2.0192668437957764
Validation loss: 1.9261655102493942

Epoch: 6| Step: 13
Training loss: 2.6771013736724854
Validation loss: 1.885928383437536

Epoch: 137| Step: 0
Training loss: 1.3732060194015503
Validation loss: 1.8919055692611202

Epoch: 6| Step: 1
Training loss: 1.8383921384811401
Validation loss: 1.9131611829162927

Epoch: 6| Step: 2
Training loss: 1.590287685394287
Validation loss: 1.8934971747859832

Epoch: 6| Step: 3
Training loss: 1.931579351425171
Validation loss: 1.9202309616150395

Epoch: 6| Step: 4
Training loss: 1.4660768508911133
Validation loss: 1.9051584120719665

Epoch: 6| Step: 5
Training loss: 2.03360652923584
Validation loss: 1.9072690997072446

Epoch: 6| Step: 6
Training loss: 1.7758395671844482
Validation loss: 1.9219832343439902

Epoch: 6| Step: 7
Training loss: 2.393118143081665
Validation loss: 1.9165463755207677

Epoch: 6| Step: 8
Training loss: 2.3672945499420166
Validation loss: 1.9154557720307381

Epoch: 6| Step: 9
Training loss: 1.8377323150634766
Validation loss: 1.9136706398379417

Epoch: 6| Step: 10
Training loss: 2.0542819499969482
Validation loss: 1.9471810517772552

Epoch: 6| Step: 11
Training loss: 1.7523343563079834
Validation loss: 1.913657715243678

Epoch: 6| Step: 12
Training loss: 2.068645477294922
Validation loss: 1.9232227494639735

Epoch: 6| Step: 13
Training loss: 2.3930225372314453
Validation loss: 1.9444045533416092

Epoch: 138| Step: 0
Training loss: 1.6820396184921265
Validation loss: 1.9131321484042751

Epoch: 6| Step: 1
Training loss: 2.543492317199707
Validation loss: 1.9293187497764506

Epoch: 6| Step: 2
Training loss: 1.801279067993164
Validation loss: 1.9176898592261857

Epoch: 6| Step: 3
Training loss: 1.931929588317871
Validation loss: 1.9164263176661667

Epoch: 6| Step: 4
Training loss: 2.170666456222534
Validation loss: 1.9065516559026574

Epoch: 6| Step: 5
Training loss: 1.5358896255493164
Validation loss: 1.900264088825513

Epoch: 6| Step: 6
Training loss: 1.7532246112823486
Validation loss: 1.90279052078083

Epoch: 6| Step: 7
Training loss: 1.6931536197662354
Validation loss: 1.9044190004307737

Epoch: 6| Step: 8
Training loss: 1.9817790985107422
Validation loss: 1.9165866580060733

Epoch: 6| Step: 9
Training loss: 1.3016164302825928
Validation loss: 1.8983782696467575

Epoch: 6| Step: 10
Training loss: 2.6772592067718506
Validation loss: 1.8807429703333045

Epoch: 6| Step: 11
Training loss: 2.0014290809631348
Validation loss: 1.8941871209811139

Epoch: 6| Step: 12
Training loss: 1.6013202667236328
Validation loss: 1.9221484007373932

Epoch: 6| Step: 13
Training loss: 2.2046468257904053
Validation loss: 1.901349457361365

Epoch: 139| Step: 0
Training loss: 1.51154625415802
Validation loss: 1.9184575644872521

Epoch: 6| Step: 1
Training loss: 2.4063234329223633
Validation loss: 1.9075337686846334

Epoch: 6| Step: 2
Training loss: 2.3383400440216064
Validation loss: 1.9142197921711912

Epoch: 6| Step: 3
Training loss: 1.7163177728652954
Validation loss: 1.929963909169679

Epoch: 6| Step: 4
Training loss: 1.510632038116455
Validation loss: 1.9368545150244108

Epoch: 6| Step: 5
Training loss: 2.0347609519958496
Validation loss: 1.9173203719559537

Epoch: 6| Step: 6
Training loss: 2.4254093170166016
Validation loss: 1.907081450185468

Epoch: 6| Step: 7
Training loss: 2.2466139793395996
Validation loss: 1.915777244875508

Epoch: 6| Step: 8
Training loss: 1.8402427434921265
Validation loss: 1.8947386459637714

Epoch: 6| Step: 9
Training loss: 1.979506015777588
Validation loss: 1.9135815815259052

Epoch: 6| Step: 10
Training loss: 1.3279025554656982
Validation loss: 1.9104372147590882

Epoch: 6| Step: 11
Training loss: 1.5932903289794922
Validation loss: 1.9109220274033085

Epoch: 6| Step: 12
Training loss: 1.5561156272888184
Validation loss: 1.9062131643295288

Epoch: 6| Step: 13
Training loss: 2.687289237976074
Validation loss: 1.940821224643338

Epoch: 140| Step: 0
Training loss: 1.2691527605056763
Validation loss: 1.8874329341355192

Epoch: 6| Step: 1
Training loss: 1.7793974876403809
Validation loss: 1.8892778786279822

Epoch: 6| Step: 2
Training loss: 1.9353034496307373
Validation loss: 1.9128676806726763

Epoch: 6| Step: 3
Training loss: 2.4497413635253906
Validation loss: 1.9661731643061484

Epoch: 6| Step: 4
Training loss: 1.9220449924468994
Validation loss: 1.9168262250961796

Epoch: 6| Step: 5
Training loss: 2.085505485534668
Validation loss: 1.880980045564713

Epoch: 6| Step: 6
Training loss: 1.8440957069396973
Validation loss: 1.9087434725094867

Epoch: 6| Step: 7
Training loss: 2.110105037689209
Validation loss: 1.9111319767531527

Epoch: 6| Step: 8
Training loss: 1.5735290050506592
Validation loss: 1.9078968391623548

Epoch: 6| Step: 9
Training loss: 2.3579769134521484
Validation loss: 1.8839148629096247

Epoch: 6| Step: 10
Training loss: 2.1718616485595703
Validation loss: 1.9103720623959777

Epoch: 6| Step: 11
Training loss: 1.7570016384124756
Validation loss: 1.9263631118241178

Epoch: 6| Step: 12
Training loss: 1.5862109661102295
Validation loss: 1.9044644601883427

Epoch: 6| Step: 13
Training loss: 1.532881259918213
Validation loss: 1.9064580702012586

Epoch: 141| Step: 0
Training loss: 1.913812279701233
Validation loss: 1.9100823069131503

Epoch: 6| Step: 1
Training loss: 1.6236189603805542
Validation loss: 1.9167924234944005

Epoch: 6| Step: 2
Training loss: 2.4923999309539795
Validation loss: 1.8935669237567532

Epoch: 6| Step: 3
Training loss: 3.0725440979003906
Validation loss: 1.9181560008756575

Epoch: 6| Step: 4
Training loss: 1.6732921600341797
Validation loss: 1.9078474044799805

Epoch: 6| Step: 5
Training loss: 1.6214238405227661
Validation loss: 1.9055865298035324

Epoch: 6| Step: 6
Training loss: 1.7395524978637695
Validation loss: 1.9137140845739713

Epoch: 6| Step: 7
Training loss: 2.3008792400360107
Validation loss: 1.9006655395671885

Epoch: 6| Step: 8
Training loss: 1.4279838800430298
Validation loss: 1.9155884968337191

Epoch: 6| Step: 9
Training loss: 1.4173413515090942
Validation loss: 1.9058977557766823

Epoch: 6| Step: 10
Training loss: 1.0414047241210938
Validation loss: 1.9059509590107908

Epoch: 6| Step: 11
Training loss: 2.5204684734344482
Validation loss: 1.9135900735855103

Epoch: 6| Step: 12
Training loss: 2.5749690532684326
Validation loss: 1.880425004548924

Epoch: 6| Step: 13
Training loss: 0.8134238719940186
Validation loss: 1.9234645584578156

Epoch: 142| Step: 0
Training loss: 2.5083179473876953
Validation loss: 1.9141839191477785

Epoch: 6| Step: 1
Training loss: 1.379691243171692
Validation loss: 1.9116448433168474

Epoch: 6| Step: 2
Training loss: 2.2899396419525146
Validation loss: 1.9307639598846436

Epoch: 6| Step: 3
Training loss: 1.927722454071045
Validation loss: 1.9081769566382132

Epoch: 6| Step: 4
Training loss: 1.696242094039917
Validation loss: 1.8950435910173642

Epoch: 6| Step: 5
Training loss: 1.9792494773864746
Validation loss: 1.9086260295683337

Epoch: 6| Step: 6
Training loss: 1.9669169187545776
Validation loss: 1.9180730876102243

Epoch: 6| Step: 7
Training loss: 2.0987164974212646
Validation loss: 1.9307760179683726

Epoch: 6| Step: 8
Training loss: 1.628463864326477
Validation loss: 1.9046999600625807

Epoch: 6| Step: 9
Training loss: 2.2469029426574707
Validation loss: 1.9026423295338948

Epoch: 6| Step: 10
Training loss: 1.9122358560562134
Validation loss: 1.8997754602022068

Epoch: 6| Step: 11
Training loss: 1.3436989784240723
Validation loss: 1.8918766872857207

Epoch: 6| Step: 12
Training loss: 2.4850833415985107
Validation loss: 1.8864034093836302

Epoch: 6| Step: 13
Training loss: 0.8719191551208496
Validation loss: 1.9152539942854194

Epoch: 143| Step: 0
Training loss: 2.498459577560425
Validation loss: 1.8772881748855754

Epoch: 6| Step: 1
Training loss: 1.1330138444900513
Validation loss: 1.925977958145962

Epoch: 6| Step: 2
Training loss: 1.8528454303741455
Validation loss: 1.8967954702274774

Epoch: 6| Step: 3
Training loss: 1.842169165611267
Validation loss: 1.881937183359618

Epoch: 6| Step: 4
Training loss: 1.6014974117279053
Validation loss: 1.8710968878961378

Epoch: 6| Step: 5
Training loss: 1.9625864028930664
Validation loss: 1.8579397765539025

Epoch: 6| Step: 6
Training loss: 1.336225986480713
Validation loss: 1.8915010729143698

Epoch: 6| Step: 7
Training loss: 2.5282955169677734
Validation loss: 1.8914129170038367

Epoch: 6| Step: 8
Training loss: 1.8769118785858154
Validation loss: 1.9158072253709197

Epoch: 6| Step: 9
Training loss: 2.2950024604797363
Validation loss: 1.89119537415043

Epoch: 6| Step: 10
Training loss: 1.4012932777404785
Validation loss: 1.9059712861173896

Epoch: 6| Step: 11
Training loss: 1.9315577745437622
Validation loss: 1.9378282741833759

Epoch: 6| Step: 12
Training loss: 1.8718533515930176
Validation loss: 1.9081548388286302

Epoch: 6| Step: 13
Training loss: 2.7195634841918945
Validation loss: 1.8693487362195087

Epoch: 144| Step: 0
Training loss: 2.422569751739502
Validation loss: 1.8948900917524933

Epoch: 6| Step: 1
Training loss: 2.0729074478149414
Validation loss: 1.8957259526816748

Epoch: 6| Step: 2
Training loss: 1.7234067916870117
Validation loss: 1.9157773807484617

Epoch: 6| Step: 3
Training loss: 2.506927013397217
Validation loss: 1.928960427161186

Epoch: 6| Step: 4
Training loss: 1.7459052801132202
Validation loss: 1.9399854675416024

Epoch: 6| Step: 5
Training loss: 1.7803924083709717
Validation loss: 1.9230226009122786

Epoch: 6| Step: 6
Training loss: 1.5137014389038086
Validation loss: 1.927524346177296

Epoch: 6| Step: 7
Training loss: 2.428318977355957
Validation loss: 1.9256373246510823

Epoch: 6| Step: 8
Training loss: 1.6325865983963013
Validation loss: 1.930570371689335

Epoch: 6| Step: 9
Training loss: 1.6582424640655518
Validation loss: 1.9227609685672227

Epoch: 6| Step: 10
Training loss: 0.9708163142204285
Validation loss: 1.8944276020091066

Epoch: 6| Step: 11
Training loss: 1.4709203243255615
Validation loss: 1.922178670924197

Epoch: 6| Step: 12
Training loss: 2.9485278129577637
Validation loss: 1.8934921987595097

Epoch: 6| Step: 13
Training loss: 1.6273260116577148
Validation loss: 1.883159214450467

Epoch: 145| Step: 0
Training loss: 1.404773235321045
Validation loss: 1.898083899610786

Epoch: 6| Step: 1
Training loss: 1.6361812353134155
Validation loss: 1.9111249677596553

Epoch: 6| Step: 2
Training loss: 1.805614709854126
Validation loss: 1.903728574834844

Epoch: 6| Step: 3
Training loss: 1.3055052757263184
Validation loss: 1.9185952114802536

Epoch: 6| Step: 4
Training loss: 1.5735950469970703
Validation loss: 1.9010067191175235

Epoch: 6| Step: 5
Training loss: 1.6342251300811768
Validation loss: 1.9084957902149489

Epoch: 6| Step: 6
Training loss: 1.7611873149871826
Validation loss: 1.8818573131356189

Epoch: 6| Step: 7
Training loss: 2.488248348236084
Validation loss: 1.9009516854440012

Epoch: 6| Step: 8
Training loss: 2.481861114501953
Validation loss: 1.8965016949561335

Epoch: 6| Step: 9
Training loss: 1.939733862876892
Validation loss: 1.9073053098494006

Epoch: 6| Step: 10
Training loss: 2.0727195739746094
Validation loss: 1.9017910047244

Epoch: 6| Step: 11
Training loss: 2.0342602729797363
Validation loss: 1.9210032288746168

Epoch: 6| Step: 12
Training loss: 2.051863670349121
Validation loss: 1.8944920724438084

Epoch: 6| Step: 13
Training loss: 2.4126875400543213
Validation loss: 1.8773740991469352

Epoch: 146| Step: 0
Training loss: 2.014397621154785
Validation loss: 1.887683678698796

Epoch: 6| Step: 1
Training loss: 2.0005362033843994
Validation loss: 1.8972270873285109

Epoch: 6| Step: 2
Training loss: 2.0568089485168457
Validation loss: 1.9023981953179965

Epoch: 6| Step: 3
Training loss: 1.6819615364074707
Validation loss: 1.8991880288688086

Epoch: 6| Step: 4
Training loss: 1.970667839050293
Validation loss: 1.9118757401743243

Epoch: 6| Step: 5
Training loss: 2.010934352874756
Validation loss: 1.9018573273894608

Epoch: 6| Step: 6
Training loss: 1.831579327583313
Validation loss: 1.8839809279288016

Epoch: 6| Step: 7
Training loss: 2.1181375980377197
Validation loss: 1.885086965817277

Epoch: 6| Step: 8
Training loss: 1.4396287202835083
Validation loss: 1.8917101544718589

Epoch: 6| Step: 9
Training loss: 1.6511842012405396
Validation loss: 1.8769079690338464

Epoch: 6| Step: 10
Training loss: 2.0930986404418945
Validation loss: 1.8976573777455155

Epoch: 6| Step: 11
Training loss: 1.572706699371338
Validation loss: 1.9097993886598976

Epoch: 6| Step: 12
Training loss: 1.7647054195404053
Validation loss: 1.9281208143439343

Epoch: 6| Step: 13
Training loss: 2.289527654647827
Validation loss: 1.8866155762826242

Epoch: 147| Step: 0
Training loss: 1.4344258308410645
Validation loss: 1.9005529316522742

Epoch: 6| Step: 1
Training loss: 1.4197218418121338
Validation loss: 1.9303838591421805

Epoch: 6| Step: 2
Training loss: 1.4524389505386353
Validation loss: 1.8780219849719797

Epoch: 6| Step: 3
Training loss: 1.810970664024353
Validation loss: 1.8875542686831566

Epoch: 6| Step: 4
Training loss: 1.8479394912719727
Validation loss: 1.8939596965748777

Epoch: 6| Step: 5
Training loss: 2.5259792804718018
Validation loss: 1.9148649631008026

Epoch: 6| Step: 6
Training loss: 1.4478716850280762
Validation loss: 1.8925826998167141

Epoch: 6| Step: 7
Training loss: 1.820366621017456
Validation loss: 1.8913737484203872

Epoch: 6| Step: 8
Training loss: 1.8301851749420166
Validation loss: 1.9029480590615222

Epoch: 6| Step: 9
Training loss: 2.547579765319824
Validation loss: 1.8843042850494385

Epoch: 6| Step: 10
Training loss: 1.7499582767486572
Validation loss: 1.9237127624532229

Epoch: 6| Step: 11
Training loss: 2.203751564025879
Validation loss: 1.8829736555776289

Epoch: 6| Step: 12
Training loss: 2.189840793609619
Validation loss: 1.9132117853369763

Epoch: 6| Step: 13
Training loss: 1.927074670791626
Validation loss: 1.9304604145788378

Epoch: 148| Step: 0
Training loss: 2.0022740364074707
Validation loss: 1.9101541452510382

Epoch: 6| Step: 1
Training loss: 1.6744575500488281
Validation loss: 1.941609533884192

Epoch: 6| Step: 2
Training loss: 1.6374200582504272
Validation loss: 1.923435886700948

Epoch: 6| Step: 3
Training loss: 1.6459414958953857
Validation loss: 1.9268437944432741

Epoch: 6| Step: 4
Training loss: 1.7774494886398315
Validation loss: 1.9261951010714295

Epoch: 6| Step: 5
Training loss: 2.907731533050537
Validation loss: 1.9095798833395845

Epoch: 6| Step: 6
Training loss: 1.052344799041748
Validation loss: 1.9176347332616006

Epoch: 6| Step: 7
Training loss: 2.0259153842926025
Validation loss: 1.9332863848696473

Epoch: 6| Step: 8
Training loss: 1.915614366531372
Validation loss: 1.9128277609425206

Epoch: 6| Step: 9
Training loss: 2.236098527908325
Validation loss: 1.9243077795992616

Epoch: 6| Step: 10
Training loss: 1.9139487743377686
Validation loss: 1.9051688742893997

Epoch: 6| Step: 11
Training loss: 1.8957911729812622
Validation loss: 1.932925021776589

Epoch: 6| Step: 12
Training loss: 1.95308256149292
Validation loss: 1.8944493403998754

Epoch: 6| Step: 13
Training loss: 1.7776436805725098
Validation loss: 1.8998666847905805

Epoch: 149| Step: 0
Training loss: 2.0991406440734863
Validation loss: 1.9127065417587117

Epoch: 6| Step: 1
Training loss: 2.0898561477661133
Validation loss: 1.880123238409719

Epoch: 6| Step: 2
Training loss: 2.603085517883301
Validation loss: 1.8912404403891614

Epoch: 6| Step: 3
Training loss: 1.1415510177612305
Validation loss: 1.8832293236127464

Epoch: 6| Step: 4
Training loss: 1.6887192726135254
Validation loss: 1.8875379049649803

Epoch: 6| Step: 5
Training loss: 1.5786209106445312
Validation loss: 1.8923988419194375

Epoch: 6| Step: 6
Training loss: 1.3836886882781982
Validation loss: 1.9148076336870912

Epoch: 6| Step: 7
Training loss: 2.2186949253082275
Validation loss: 1.8798670563646542

Epoch: 6| Step: 8
Training loss: 1.8724002838134766
Validation loss: 1.8694117158971808

Epoch: 6| Step: 9
Training loss: 1.1728450059890747
Validation loss: 1.897775375714866

Epoch: 6| Step: 10
Training loss: 1.4956481456756592
Validation loss: 1.927084158825618

Epoch: 6| Step: 11
Training loss: 2.521453857421875
Validation loss: 1.916873288410966

Epoch: 6| Step: 12
Training loss: 2.1652162075042725
Validation loss: 1.9063462467603787

Epoch: 6| Step: 13
Training loss: 2.1762495040893555
Validation loss: 1.8973101697942263

Epoch: 150| Step: 0
Training loss: 2.2929253578186035
Validation loss: 1.9018694559733074

Epoch: 6| Step: 1
Training loss: 1.6159896850585938
Validation loss: 1.9134294191996257

Epoch: 6| Step: 2
Training loss: 2.2361183166503906
Validation loss: 1.8801354464664255

Epoch: 6| Step: 3
Training loss: 1.7469532489776611
Validation loss: 1.9105807632528327

Epoch: 6| Step: 4
Training loss: 1.5657789707183838
Validation loss: 1.8954074344327372

Epoch: 6| Step: 5
Training loss: 1.2494477033615112
Validation loss: 1.9068671670011295

Epoch: 6| Step: 6
Training loss: 1.6883258819580078
Validation loss: 1.8927941450508692

Epoch: 6| Step: 7
Training loss: 1.6178195476531982
Validation loss: 1.9097724601786623

Epoch: 6| Step: 8
Training loss: 1.624974012374878
Validation loss: 1.8931388470434374

Epoch: 6| Step: 9
Training loss: 2.1750571727752686
Validation loss: 1.8852305643020137

Epoch: 6| Step: 10
Training loss: 2.1590805053710938
Validation loss: 1.9023479005341888

Epoch: 6| Step: 11
Training loss: 1.9958038330078125
Validation loss: 1.895549097368794

Epoch: 6| Step: 12
Training loss: 1.9352736473083496
Validation loss: 1.9020090667150353

Epoch: 6| Step: 13
Training loss: 2.1779026985168457
Validation loss: 1.8888098783390497

Epoch: 151| Step: 0
Training loss: 2.564507484436035
Validation loss: 1.893771021596847

Epoch: 6| Step: 1
Training loss: 2.315906047821045
Validation loss: 1.9113233679084367

Epoch: 6| Step: 2
Training loss: 1.9364326000213623
Validation loss: 1.8820928399280836

Epoch: 6| Step: 3
Training loss: 2.5524680614471436
Validation loss: 1.898412053303052

Epoch: 6| Step: 4
Training loss: 1.224500060081482
Validation loss: 1.8879080715999808

Epoch: 6| Step: 5
Training loss: 1.4028847217559814
Validation loss: 1.881033150098657

Epoch: 6| Step: 6
Training loss: 1.8790801763534546
Validation loss: 1.9123411768226213

Epoch: 6| Step: 7
Training loss: 2.212702989578247
Validation loss: 1.9071905753945793

Epoch: 6| Step: 8
Training loss: 1.6197137832641602
Validation loss: 1.9136250326710362

Epoch: 6| Step: 9
Training loss: 2.155111074447632
Validation loss: 1.896535651658171

Epoch: 6| Step: 10
Training loss: 1.8135011196136475
Validation loss: 1.867770614162568

Epoch: 6| Step: 11
Training loss: 1.5307934284210205
Validation loss: 1.8943643159763788

Epoch: 6| Step: 12
Training loss: 1.030187726020813
Validation loss: 1.8970884751248103

Epoch: 6| Step: 13
Training loss: 1.708254098892212
Validation loss: 1.8989152959598008

Epoch: 152| Step: 0
Training loss: 1.8945133686065674
Validation loss: 1.9022804575581704

Epoch: 6| Step: 1
Training loss: 2.016740322113037
Validation loss: 1.8785830390068792

Epoch: 6| Step: 2
Training loss: 1.6855933666229248
Validation loss: 1.8845362432541386

Epoch: 6| Step: 3
Training loss: 2.2617671489715576
Validation loss: 1.900209003879178

Epoch: 6| Step: 4
Training loss: 1.6876728534698486
Validation loss: 1.9254848559697468

Epoch: 6| Step: 5
Training loss: 2.262059211730957
Validation loss: 1.9032814259170203

Epoch: 6| Step: 6
Training loss: 2.5964441299438477
Validation loss: 1.9002433976819437

Epoch: 6| Step: 7
Training loss: 2.0743446350097656
Validation loss: 1.8720719224663191

Epoch: 6| Step: 8
Training loss: 1.74201238155365
Validation loss: 1.8909683432630313

Epoch: 6| Step: 9
Training loss: 1.5923328399658203
Validation loss: 1.8739895487344393

Epoch: 6| Step: 10
Training loss: 1.7109354734420776
Validation loss: 1.893131402231032

Epoch: 6| Step: 11
Training loss: 0.9736565351486206
Validation loss: 1.9020442142281482

Epoch: 6| Step: 12
Training loss: 1.6378147602081299
Validation loss: 1.8986175239727061

Epoch: 6| Step: 13
Training loss: 1.6236774921417236
Validation loss: 1.9029103479077738

Epoch: 153| Step: 0
Training loss: 1.5735279321670532
Validation loss: 1.8772235121778262

Epoch: 6| Step: 1
Training loss: 1.905319094657898
Validation loss: 1.9160755770180815

Epoch: 6| Step: 2
Training loss: 1.3626130819320679
Validation loss: 1.8948611187678512

Epoch: 6| Step: 3
Training loss: 2.0792958736419678
Validation loss: 1.9054032833345476

Epoch: 6| Step: 4
Training loss: 1.544865369796753
Validation loss: 1.9109023206977434

Epoch: 6| Step: 5
Training loss: 2.0826501846313477
Validation loss: 1.9251624307324808

Epoch: 6| Step: 6
Training loss: 1.9912519454956055
Validation loss: 1.8988287756519933

Epoch: 6| Step: 7
Training loss: 2.396174430847168
Validation loss: 1.9009372726563485

Epoch: 6| Step: 8
Training loss: 1.4190454483032227
Validation loss: 1.8808935265387259

Epoch: 6| Step: 9
Training loss: 1.8549573421478271
Validation loss: 1.8896824775203582

Epoch: 6| Step: 10
Training loss: 1.9127397537231445
Validation loss: 1.8959188897122619

Epoch: 6| Step: 11
Training loss: 2.1337943077087402
Validation loss: 1.933041803298458

Epoch: 6| Step: 12
Training loss: 2.1151928901672363
Validation loss: 1.9038963958781252

Epoch: 6| Step: 13
Training loss: 1.4586482048034668
Validation loss: 1.9119141358201222

Epoch: 154| Step: 0
Training loss: 3.0191397666931152
Validation loss: 1.9152984490958593

Epoch: 6| Step: 1
Training loss: 1.6956803798675537
Validation loss: 1.9009924883483558

Epoch: 6| Step: 2
Training loss: 1.4113308191299438
Validation loss: 1.9119960556748092

Epoch: 6| Step: 3
Training loss: 2.0228500366210938
Validation loss: 1.8946662641340686

Epoch: 6| Step: 4
Training loss: 1.845703125
Validation loss: 1.9117859319974018

Epoch: 6| Step: 5
Training loss: 1.870572805404663
Validation loss: 1.9126702303527503

Epoch: 6| Step: 6
Training loss: 2.6237733364105225
Validation loss: 1.9097541186117357

Epoch: 6| Step: 7
Training loss: 1.9859657287597656
Validation loss: 1.9220337867736816

Epoch: 6| Step: 8
Training loss: 1.0289958715438843
Validation loss: 1.8831900832473591

Epoch: 6| Step: 9
Training loss: 1.9581117630004883
Validation loss: 1.8943303297924738

Epoch: 6| Step: 10
Training loss: 2.083352565765381
Validation loss: 1.9147628327851653

Epoch: 6| Step: 11
Training loss: 1.4468843936920166
Validation loss: 1.8795676051929433

Epoch: 6| Step: 12
Training loss: 1.0494887828826904
Validation loss: 1.872536172149002

Epoch: 6| Step: 13
Training loss: 1.8410048484802246
Validation loss: 1.882214069366455

Epoch: 155| Step: 0
Training loss: 1.5352232456207275
Validation loss: 1.9028858548851424

Epoch: 6| Step: 1
Training loss: 2.1738440990448
Validation loss: 1.8725302757755402

Epoch: 6| Step: 2
Training loss: 1.832321286201477
Validation loss: 1.8904890424461775

Epoch: 6| Step: 3
Training loss: 1.3038969039916992
Validation loss: 1.886158529148307

Epoch: 6| Step: 4
Training loss: 1.6636883020401
Validation loss: 1.879220470305412

Epoch: 6| Step: 5
Training loss: 1.3531278371810913
Validation loss: 1.8967549108689832

Epoch: 6| Step: 6
Training loss: 1.7949894666671753
Validation loss: 1.8786510562384

Epoch: 6| Step: 7
Training loss: 2.27783203125
Validation loss: 1.8821588049652755

Epoch: 6| Step: 8
Training loss: 1.5363394021987915
Validation loss: 1.870325844774964

Epoch: 6| Step: 9
Training loss: 1.5633466243743896
Validation loss: 1.9014806798709336

Epoch: 6| Step: 10
Training loss: 1.8737046718597412
Validation loss: 1.895087234435543

Epoch: 6| Step: 11
Training loss: 2.8084330558776855
Validation loss: 1.9044234701382217

Epoch: 6| Step: 12
Training loss: 1.9850263595581055
Validation loss: 1.9162822602897562

Epoch: 6| Step: 13
Training loss: 2.537325143814087
Validation loss: 1.8871538997978292

Epoch: 156| Step: 0
Training loss: 1.8030868768692017
Validation loss: 1.9289048358958254

Epoch: 6| Step: 1
Training loss: 2.4729905128479004
Validation loss: 1.8946585347575526

Epoch: 6| Step: 2
Training loss: 1.3460752964019775
Validation loss: 1.8910218002975627

Epoch: 6| Step: 3
Training loss: 2.1690635681152344
Validation loss: 1.9132326059443976

Epoch: 6| Step: 4
Training loss: 1.7734854221343994
Validation loss: 1.8829536207260624

Epoch: 6| Step: 5
Training loss: 2.350041389465332
Validation loss: 1.9183330382070234

Epoch: 6| Step: 6
Training loss: 1.3019835948944092
Validation loss: 1.9224934244668612

Epoch: 6| Step: 7
Training loss: 1.9055140018463135
Validation loss: 1.9434645688661965

Epoch: 6| Step: 8
Training loss: 1.61604905128479
Validation loss: 1.9370680855166527

Epoch: 6| Step: 9
Training loss: 2.1106297969818115
Validation loss: 1.9769741591586862

Epoch: 6| Step: 10
Training loss: 1.4109899997711182
Validation loss: 1.9455807773015832

Epoch: 6| Step: 11
Training loss: 1.861330270767212
Validation loss: 1.9454392630566832

Epoch: 6| Step: 12
Training loss: 1.8665308952331543
Validation loss: 1.9724923282541253

Epoch: 6| Step: 13
Training loss: 1.9157922267913818
Validation loss: 1.904773840340235

Epoch: 157| Step: 0
Training loss: 2.0148866176605225
Validation loss: 1.9405144876049412

Epoch: 6| Step: 1
Training loss: 1.3138025999069214
Validation loss: 1.9112799962361653

Epoch: 6| Step: 2
Training loss: 1.5663304328918457
Validation loss: 1.924909786511493

Epoch: 6| Step: 3
Training loss: 1.4775781631469727
Validation loss: 1.8863802866269184

Epoch: 6| Step: 4
Training loss: 2.009812593460083
Validation loss: 1.9181673757491573

Epoch: 6| Step: 5
Training loss: 1.8941879272460938
Validation loss: 1.879175014393304

Epoch: 6| Step: 6
Training loss: 2.3831183910369873
Validation loss: 1.8983801641771871

Epoch: 6| Step: 7
Training loss: 1.8196903467178345
Validation loss: 1.912620400869718

Epoch: 6| Step: 8
Training loss: 1.5615084171295166
Validation loss: 1.9103410910534602

Epoch: 6| Step: 9
Training loss: 2.7472052574157715
Validation loss: 1.8824775629146124

Epoch: 6| Step: 10
Training loss: 1.516977071762085
Validation loss: 1.8765003168454735

Epoch: 6| Step: 11
Training loss: 1.5441224575042725
Validation loss: 1.874877563086889

Epoch: 6| Step: 12
Training loss: 2.031160831451416
Validation loss: 1.873920823938103

Epoch: 6| Step: 13
Training loss: 1.7991392612457275
Validation loss: 1.8824880725593978

Epoch: 158| Step: 0
Training loss: 1.3157659769058228
Validation loss: 1.8939430226561844

Epoch: 6| Step: 1
Training loss: 1.302969217300415
Validation loss: 1.9153646115333802

Epoch: 6| Step: 2
Training loss: 2.4249653816223145
Validation loss: 1.8975632754705285

Epoch: 6| Step: 3
Training loss: 1.5865298509597778
Validation loss: 1.87406543249725

Epoch: 6| Step: 4
Training loss: 2.0459184646606445
Validation loss: 1.8830496406042447

Epoch: 6| Step: 5
Training loss: 2.3916831016540527
Validation loss: 1.8718943865068498

Epoch: 6| Step: 6
Training loss: 1.5870707035064697
Validation loss: 1.884783911448653

Epoch: 6| Step: 7
Training loss: 2.7160868644714355
Validation loss: 1.8915040249465613

Epoch: 6| Step: 8
Training loss: 2.0948500633239746
Validation loss: 1.8978426687179073

Epoch: 6| Step: 9
Training loss: 1.8249645233154297
Validation loss: 1.8636117904416976

Epoch: 6| Step: 10
Training loss: 1.174762487411499
Validation loss: 1.8768232868563743

Epoch: 6| Step: 11
Training loss: 1.587022066116333
Validation loss: 1.8940044333857875

Epoch: 6| Step: 12
Training loss: 1.825358271598816
Validation loss: 1.8880364535957255

Epoch: 6| Step: 13
Training loss: 1.9942330121994019
Validation loss: 1.8960229991584696

Epoch: 159| Step: 0
Training loss: 1.1880817413330078
Validation loss: 1.87785538037618

Epoch: 6| Step: 1
Training loss: 2.6255650520324707
Validation loss: 1.9078663190205891

Epoch: 6| Step: 2
Training loss: 2.1444671154022217
Validation loss: 1.9157167096291818

Epoch: 6| Step: 3
Training loss: 1.8992435932159424
Validation loss: 1.9099052823999876

Epoch: 6| Step: 4
Training loss: 1.7011775970458984
Validation loss: 1.8946948435998732

Epoch: 6| Step: 5
Training loss: 1.359313726425171
Validation loss: 1.884913747028638

Epoch: 6| Step: 6
Training loss: 1.5563712120056152
Validation loss: 1.9046480719761183

Epoch: 6| Step: 7
Training loss: 2.628662347793579
Validation loss: 1.920154038295951

Epoch: 6| Step: 8
Training loss: 1.812488317489624
Validation loss: 1.9004186122648177

Epoch: 6| Step: 9
Training loss: 1.9587985277175903
Validation loss: 1.906621503573592

Epoch: 6| Step: 10
Training loss: 1.6730409860610962
Validation loss: 1.8915669841151084

Epoch: 6| Step: 11
Training loss: 1.6078799962997437
Validation loss: 1.8836111945490683

Epoch: 6| Step: 12
Training loss: 1.9021899700164795
Validation loss: 1.9154494654747747

Epoch: 6| Step: 13
Training loss: 1.2095820903778076
Validation loss: 1.891822370149756

Epoch: 160| Step: 0
Training loss: 2.757115364074707
Validation loss: 1.8633794528181835

Epoch: 6| Step: 1
Training loss: 1.592137098312378
Validation loss: 1.909006094419828

Epoch: 6| Step: 2
Training loss: 1.980516791343689
Validation loss: 1.9205776927291707

Epoch: 6| Step: 3
Training loss: 0.8879841566085815
Validation loss: 1.8673177765261741

Epoch: 6| Step: 4
Training loss: 1.4480657577514648
Validation loss: 1.8796108999559957

Epoch: 6| Step: 5
Training loss: 1.5913457870483398
Validation loss: 1.9113223950068157

Epoch: 6| Step: 6
Training loss: 2.2731895446777344
Validation loss: 1.8944655336359495

Epoch: 6| Step: 7
Training loss: 1.8645700216293335
Validation loss: 1.882292168114775

Epoch: 6| Step: 8
Training loss: 0.9854360818862915
Validation loss: 1.8724280288142543

Epoch: 6| Step: 9
Training loss: 2.129573106765747
Validation loss: 1.8830194652721446

Epoch: 6| Step: 10
Training loss: 2.55996036529541
Validation loss: 1.8740284263446767

Epoch: 6| Step: 11
Training loss: 2.5228469371795654
Validation loss: 1.9028830207804197

Epoch: 6| Step: 12
Training loss: 1.5249214172363281
Validation loss: 1.87488849957784

Epoch: 6| Step: 13
Training loss: 1.6036875247955322
Validation loss: 1.9042862820368942

Epoch: 161| Step: 0
Training loss: 2.235267400741577
Validation loss: 1.8970291229986376

Epoch: 6| Step: 1
Training loss: 1.6338528394699097
Validation loss: 1.9028235686722623

Epoch: 6| Step: 2
Training loss: 2.200918674468994
Validation loss: 1.8793858379446051

Epoch: 6| Step: 3
Training loss: 1.8848035335540771
Validation loss: 1.900400900071667

Epoch: 6| Step: 4
Training loss: 1.7838140726089478
Validation loss: 1.9081461660323604

Epoch: 6| Step: 5
Training loss: 2.108330726623535
Validation loss: 1.900974242917953

Epoch: 6| Step: 6
Training loss: 2.171204090118408
Validation loss: 1.905177847031624

Epoch: 6| Step: 7
Training loss: 1.9376060962677002
Validation loss: 1.9289446351348714

Epoch: 6| Step: 8
Training loss: 1.3333454132080078
Validation loss: 1.9192370650588826

Epoch: 6| Step: 9
Training loss: 2.187035083770752
Validation loss: 1.8940822385972547

Epoch: 6| Step: 10
Training loss: 1.808707356452942
Validation loss: 1.9043045633582658

Epoch: 6| Step: 11
Training loss: 1.9305744171142578
Validation loss: 1.9071175129182878

Epoch: 6| Step: 12
Training loss: 1.0398125648498535
Validation loss: 1.906746102917579

Epoch: 6| Step: 13
Training loss: 1.1148393154144287
Validation loss: 1.9008521136417185

Epoch: 162| Step: 0
Training loss: 1.4537906646728516
Validation loss: 1.8967928194230603

Epoch: 6| Step: 1
Training loss: 1.8500910997390747
Validation loss: 1.9082448379967802

Epoch: 6| Step: 2
Training loss: 2.012467384338379
Validation loss: 1.892961871239447

Epoch: 6| Step: 3
Training loss: 1.8893134593963623
Validation loss: 1.8933972799649803

Epoch: 6| Step: 4
Training loss: 1.2951387166976929
Validation loss: 1.8614868105098765

Epoch: 6| Step: 5
Training loss: 1.525226354598999
Validation loss: 1.89538057901526

Epoch: 6| Step: 6
Training loss: 2.102297306060791
Validation loss: 1.8813525848491217

Epoch: 6| Step: 7
Training loss: 1.5973262786865234
Validation loss: 1.9037220093511766

Epoch: 6| Step: 8
Training loss: 1.9212722778320312
Validation loss: 1.8568095558433122

Epoch: 6| Step: 9
Training loss: 1.7866322994232178
Validation loss: 1.8989035339765652

Epoch: 6| Step: 10
Training loss: 1.9033355712890625
Validation loss: 1.854771937093427

Epoch: 6| Step: 11
Training loss: 1.3240865468978882
Validation loss: 1.872625272761109

Epoch: 6| Step: 12
Training loss: 2.206655740737915
Validation loss: 1.8837570554466658

Epoch: 6| Step: 13
Training loss: 3.299187660217285
Validation loss: 1.8981414482157717

Epoch: 163| Step: 0
Training loss: 1.7807345390319824
Validation loss: 1.8763853311538696

Epoch: 6| Step: 1
Training loss: 1.4786940813064575
Validation loss: 1.8847137407589984

Epoch: 6| Step: 2
Training loss: 1.3350768089294434
Validation loss: 1.8684687101712791

Epoch: 6| Step: 3
Training loss: 2.1098461151123047
Validation loss: 1.8813517132113058

Epoch: 6| Step: 4
Training loss: 2.1647157669067383
Validation loss: 1.8958977422406595

Epoch: 6| Step: 5
Training loss: 1.4313013553619385
Validation loss: 1.8905278508381178

Epoch: 6| Step: 6
Training loss: 1.4970260858535767
Validation loss: 1.8689640580966909

Epoch: 6| Step: 7
Training loss: 2.3167319297790527
Validation loss: 1.8881174928398543

Epoch: 6| Step: 8
Training loss: 1.579427719116211
Validation loss: 1.8926716196921565

Epoch: 6| Step: 9
Training loss: 2.2096049785614014
Validation loss: 1.861112630495461

Epoch: 6| Step: 10
Training loss: 1.6109857559204102
Validation loss: 1.8815308796462191

Epoch: 6| Step: 11
Training loss: 2.164759635925293
Validation loss: 1.9015170540860904

Epoch: 6| Step: 12
Training loss: 2.399056911468506
Validation loss: 1.8925599769879413

Epoch: 6| Step: 13
Training loss: 1.0430397987365723
Validation loss: 1.8984727385223552

Epoch: 164| Step: 0
Training loss: 1.50331711769104
Validation loss: 1.8670050264686666

Epoch: 6| Step: 1
Training loss: 1.7705802917480469
Validation loss: 1.8847827783194921

Epoch: 6| Step: 2
Training loss: 2.437811851501465
Validation loss: 1.911186125970656

Epoch: 6| Step: 3
Training loss: 1.4693632125854492
Validation loss: 1.9089308861763246

Epoch: 6| Step: 4
Training loss: 2.398373603820801
Validation loss: 1.905901308982603

Epoch: 6| Step: 5
Training loss: 1.7802083492279053
Validation loss: 1.8928444923893097

Epoch: 6| Step: 6
Training loss: 1.2738624811172485
Validation loss: 1.9213280690613614

Epoch: 6| Step: 7
Training loss: 1.8472599983215332
Validation loss: 1.9093159142360892

Epoch: 6| Step: 8
Training loss: 1.4401644468307495
Validation loss: 1.9103321849658925

Epoch: 6| Step: 9
Training loss: 2.229872941970825
Validation loss: 1.8786984464173675

Epoch: 6| Step: 10
Training loss: 1.9120914936065674
Validation loss: 1.8841184672488962

Epoch: 6| Step: 11
Training loss: 1.7907867431640625
Validation loss: 1.8927156950837822

Epoch: 6| Step: 12
Training loss: 1.4963736534118652
Validation loss: 1.9078470045520413

Epoch: 6| Step: 13
Training loss: 2.236874580383301
Validation loss: 1.937205050581245

Epoch: 165| Step: 0
Training loss: 2.070887565612793
Validation loss: 1.8770156701405842

Epoch: 6| Step: 1
Training loss: 1.502032995223999
Validation loss: 1.8955023673272902

Epoch: 6| Step: 2
Training loss: 2.1746647357940674
Validation loss: 1.8907247692026117

Epoch: 6| Step: 3
Training loss: 1.815176010131836
Validation loss: 1.8823971927806895

Epoch: 6| Step: 4
Training loss: 1.6293987035751343
Validation loss: 1.8877032726041731

Epoch: 6| Step: 5
Training loss: 1.8938136100769043
Validation loss: 1.8784771965396019

Epoch: 6| Step: 6
Training loss: 1.6431498527526855
Validation loss: 1.8891857862472534

Epoch: 6| Step: 7
Training loss: 1.7231144905090332
Validation loss: 1.88617108714196

Epoch: 6| Step: 8
Training loss: 2.1318905353546143
Validation loss: 1.8905544832188597

Epoch: 6| Step: 9
Training loss: 2.527005434036255
Validation loss: 1.9123328603723997

Epoch: 6| Step: 10
Training loss: 1.729682445526123
Validation loss: 1.8565369729072816

Epoch: 6| Step: 11
Training loss: 1.2940727472305298
Validation loss: 1.8658344989181848

Epoch: 6| Step: 12
Training loss: 1.8910974264144897
Validation loss: 1.8656580217422978

Epoch: 6| Step: 13
Training loss: 1.1329786777496338
Validation loss: 1.8750165649639663

Epoch: 166| Step: 0
Training loss: 2.649834156036377
Validation loss: 1.8990080997508059

Epoch: 6| Step: 1
Training loss: 1.3536686897277832
Validation loss: 1.9016490802969983

Epoch: 6| Step: 2
Training loss: 1.5356144905090332
Validation loss: 1.937191750413628

Epoch: 6| Step: 3
Training loss: 2.0948803424835205
Validation loss: 1.907151727266209

Epoch: 6| Step: 4
Training loss: 1.804596185684204
Validation loss: 1.9011579700695571

Epoch: 6| Step: 5
Training loss: 1.992868185043335
Validation loss: 1.8996143417973672

Epoch: 6| Step: 6
Training loss: 1.5540437698364258
Validation loss: 1.8982366682380758

Epoch: 6| Step: 7
Training loss: 2.5131168365478516
Validation loss: 1.906814367540421

Epoch: 6| Step: 8
Training loss: 1.2850139141082764
Validation loss: 1.867117501074268

Epoch: 6| Step: 9
Training loss: 1.5891797542572021
Validation loss: 1.9060326596742034

Epoch: 6| Step: 10
Training loss: 1.7463840246200562
Validation loss: 1.9083043888051023

Epoch: 6| Step: 11
Training loss: 1.904820203781128
Validation loss: 1.8904695369864022

Epoch: 6| Step: 12
Training loss: 1.639859676361084
Validation loss: 1.8898855499041978

Epoch: 6| Step: 13
Training loss: 1.9430139064788818
Validation loss: 1.8986195582215504

Epoch: 167| Step: 0
Training loss: 1.5866203308105469
Validation loss: 1.9029375250621507

Epoch: 6| Step: 1
Training loss: 2.0420174598693848
Validation loss: 1.8966904852979927

Epoch: 6| Step: 2
Training loss: 1.4337166547775269
Validation loss: 1.8677154433342718

Epoch: 6| Step: 3
Training loss: 1.4771641492843628
Validation loss: 1.8821653922398884

Epoch: 6| Step: 4
Training loss: 1.761083722114563
Validation loss: 1.8778676525239022

Epoch: 6| Step: 5
Training loss: 1.8810044527053833
Validation loss: 1.8771211049890006

Epoch: 6| Step: 6
Training loss: 1.1741288900375366
Validation loss: 1.8666062931860647

Epoch: 6| Step: 7
Training loss: 1.861499547958374
Validation loss: 1.8987439858016146

Epoch: 6| Step: 8
Training loss: 1.788259506225586
Validation loss: 1.8927699494105514

Epoch: 6| Step: 9
Training loss: 2.1639153957366943
Validation loss: 1.844717679485198

Epoch: 6| Step: 10
Training loss: 2.5798768997192383
Validation loss: 1.8563021459887106

Epoch: 6| Step: 11
Training loss: 1.9180738925933838
Validation loss: 1.8756084749775548

Epoch: 6| Step: 12
Training loss: 1.7432475090026855
Validation loss: 1.8729540083997993

Epoch: 6| Step: 13
Training loss: 1.8014971017837524
Validation loss: 1.8737320874326973

Epoch: 168| Step: 0
Training loss: 1.8582794666290283
Validation loss: 1.8937576534927532

Epoch: 6| Step: 1
Training loss: 2.0239968299865723
Validation loss: 1.8768585228150891

Epoch: 6| Step: 2
Training loss: 1.7037557363510132
Validation loss: 1.9239657617384387

Epoch: 6| Step: 3
Training loss: 2.401355743408203
Validation loss: 1.8894504218973138

Epoch: 6| Step: 4
Training loss: 2.060739278793335
Validation loss: 1.89396152188701

Epoch: 6| Step: 5
Training loss: 1.6950417757034302
Validation loss: 1.8995310260403542

Epoch: 6| Step: 6
Training loss: 1.3857135772705078
Validation loss: 1.8873448038613925

Epoch: 6| Step: 7
Training loss: 1.153548240661621
Validation loss: 1.872661199620975

Epoch: 6| Step: 8
Training loss: 1.6292340755462646
Validation loss: 1.8885197319010252

Epoch: 6| Step: 9
Training loss: 1.6586519479751587
Validation loss: 1.8780572670762257

Epoch: 6| Step: 10
Training loss: 1.8408963680267334
Validation loss: 1.8792781073559996

Epoch: 6| Step: 11
Training loss: 1.9011428356170654
Validation loss: 1.8667960833477717

Epoch: 6| Step: 12
Training loss: 1.7506828308105469
Validation loss: 1.8487694442913096

Epoch: 6| Step: 13
Training loss: 2.1316745281219482
Validation loss: 1.8597729436812862

Epoch: 169| Step: 0
Training loss: 1.394300937652588
Validation loss: 1.896803222676759

Epoch: 6| Step: 1
Training loss: 1.5120322704315186
Validation loss: 1.8567509612729471

Epoch: 6| Step: 2
Training loss: 2.0012216567993164
Validation loss: 1.895109631681955

Epoch: 6| Step: 3
Training loss: 1.9444259405136108
Validation loss: 1.898662462029406

Epoch: 6| Step: 4
Training loss: 1.6721444129943848
Validation loss: 1.8698224944453086

Epoch: 6| Step: 5
Training loss: 1.3192138671875
Validation loss: 1.8891034664646271

Epoch: 6| Step: 6
Training loss: 1.625683307647705
Validation loss: 1.8903831179423998

Epoch: 6| Step: 7
Training loss: 1.7848421335220337
Validation loss: 1.8752967055125902

Epoch: 6| Step: 8
Training loss: 1.960094690322876
Validation loss: 1.9072383475560013

Epoch: 6| Step: 9
Training loss: 1.112227439880371
Validation loss: 1.8926617714666552

Epoch: 6| Step: 10
Training loss: 2.319577217102051
Validation loss: 1.877598984267122

Epoch: 6| Step: 11
Training loss: 2.2367918491363525
Validation loss: 1.8974675645110428

Epoch: 6| Step: 12
Training loss: 2.313364028930664
Validation loss: 1.9109308527361961

Epoch: 6| Step: 13
Training loss: 2.1039328575134277
Validation loss: 1.8772076419604722

Epoch: 170| Step: 0
Training loss: 1.8182884454727173
Validation loss: 1.8493124003051429

Epoch: 6| Step: 1
Training loss: 1.8348755836486816
Validation loss: 1.9043366396298973

Epoch: 6| Step: 2
Training loss: 2.324955463409424
Validation loss: 1.8934354102739723

Epoch: 6| Step: 3
Training loss: 1.2840455770492554
Validation loss: 1.9044961954957695

Epoch: 6| Step: 4
Training loss: 2.036374092102051
Validation loss: 1.8758272599148493

Epoch: 6| Step: 5
Training loss: 1.8683925867080688
Validation loss: 1.8805219563104774

Epoch: 6| Step: 6
Training loss: 1.8894155025482178
Validation loss: 1.90653028539432

Epoch: 6| Step: 7
Training loss: 1.7158790826797485
Validation loss: 1.896853761006427

Epoch: 6| Step: 8
Training loss: 1.8313689231872559
Validation loss: 1.8890496223203597

Epoch: 6| Step: 9
Training loss: 1.396926999092102
Validation loss: 1.853567087522117

Epoch: 6| Step: 10
Training loss: 2.2584314346313477
Validation loss: 1.888874315446423

Epoch: 6| Step: 11
Training loss: 1.5679945945739746
Validation loss: 1.8982248190910584

Epoch: 6| Step: 12
Training loss: 1.3194215297698975
Validation loss: 1.9030201973453644

Epoch: 6| Step: 13
Training loss: 1.6685423851013184
Validation loss: 1.9062540044066727

Epoch: 171| Step: 0
Training loss: 1.869185209274292
Validation loss: 1.886739198879529

Epoch: 6| Step: 1
Training loss: 1.5141849517822266
Validation loss: 1.90674409045968

Epoch: 6| Step: 2
Training loss: 1.5900789499282837
Validation loss: 1.8692470071136311

Epoch: 6| Step: 3
Training loss: 1.6781610250473022
Validation loss: 1.8807241852565477

Epoch: 6| Step: 4
Training loss: 2.0010457038879395
Validation loss: 1.8919521800933345

Epoch: 6| Step: 5
Training loss: 2.520212411880493
Validation loss: 1.878817230142573

Epoch: 6| Step: 6
Training loss: 2.395939826965332
Validation loss: 1.9120412718865178

Epoch: 6| Step: 7
Training loss: 1.4641940593719482
Validation loss: 1.9056419851959392

Epoch: 6| Step: 8
Training loss: 0.8304063081741333
Validation loss: 1.8853060635187293

Epoch: 6| Step: 9
Training loss: 1.8307178020477295
Validation loss: 1.8961020849084342

Epoch: 6| Step: 10
Training loss: 1.7605853080749512
Validation loss: 1.895534416680695

Epoch: 6| Step: 11
Training loss: 1.7255234718322754
Validation loss: 1.863905422149166

Epoch: 6| Step: 12
Training loss: 1.6199312210083008
Validation loss: 1.8924433339026667

Epoch: 6| Step: 13
Training loss: 2.1996541023254395
Validation loss: 1.8966192788975214

Epoch: 172| Step: 0
Training loss: 2.063286781311035
Validation loss: 1.893902752989082

Epoch: 6| Step: 1
Training loss: 1.2128009796142578
Validation loss: 1.9018818921940301

Epoch: 6| Step: 2
Training loss: 1.3486835956573486
Validation loss: 1.8957387529393679

Epoch: 6| Step: 3
Training loss: 1.9551935195922852
Validation loss: 1.8856446384101786

Epoch: 6| Step: 4
Training loss: 0.9709347486495972
Validation loss: 1.8631410444936445

Epoch: 6| Step: 5
Training loss: 1.8324306011199951
Validation loss: 1.8746836723819855

Epoch: 6| Step: 6
Training loss: 1.8628911972045898
Validation loss: 1.8747772606470252

Epoch: 6| Step: 7
Training loss: 1.485349178314209
Validation loss: 1.8742749550009286

Epoch: 6| Step: 8
Training loss: 1.6787611246109009
Validation loss: 1.868899578689247

Epoch: 6| Step: 9
Training loss: 2.34782075881958
Validation loss: 1.8949915311669792

Epoch: 6| Step: 10
Training loss: 1.5052151679992676
Validation loss: 1.88657578345268

Epoch: 6| Step: 11
Training loss: 2.4266271591186523
Validation loss: 1.8701736696304814

Epoch: 6| Step: 12
Training loss: 2.6076877117156982
Validation loss: 1.9107115037979618

Epoch: 6| Step: 13
Training loss: 1.8648027181625366
Validation loss: 1.8721898166082238

Epoch: 173| Step: 0
Training loss: 1.905761480331421
Validation loss: 1.8739268754118232

Epoch: 6| Step: 1
Training loss: 1.9134122133255005
Validation loss: 1.8714649369639735

Epoch: 6| Step: 2
Training loss: 1.1751031875610352
Validation loss: 1.885224570510208

Epoch: 6| Step: 3
Training loss: 1.579514980316162
Validation loss: 1.896891713142395

Epoch: 6| Step: 4
Training loss: 2.035176992416382
Validation loss: 1.8525555595274894

Epoch: 6| Step: 5
Training loss: 2.124087333679199
Validation loss: 1.882217122662452

Epoch: 6| Step: 6
Training loss: 1.8840967416763306
Validation loss: 1.8869361300622263

Epoch: 6| Step: 7
Training loss: 1.9174199104309082
Validation loss: 1.9016614037175332

Epoch: 6| Step: 8
Training loss: 2.310732126235962
Validation loss: 1.896394702696031

Epoch: 6| Step: 9
Training loss: 2.1172244548797607
Validation loss: 1.8566427064198319

Epoch: 6| Step: 10
Training loss: 1.3635178804397583
Validation loss: 1.88762370873523

Epoch: 6| Step: 11
Training loss: 1.8187432289123535
Validation loss: 1.9081797933065763

Epoch: 6| Step: 12
Training loss: 0.9609830379486084
Validation loss: 1.878469733781712

Epoch: 6| Step: 13
Training loss: 1.1979933977127075
Validation loss: 1.8778482649915962

Epoch: 174| Step: 0
Training loss: 1.6427640914916992
Validation loss: 1.8819960099394604

Epoch: 6| Step: 1
Training loss: 1.2662880420684814
Validation loss: 1.9109341329143894

Epoch: 6| Step: 2
Training loss: 2.264932155609131
Validation loss: 1.8757182705786921

Epoch: 6| Step: 3
Training loss: 1.7347779273986816
Validation loss: 1.8878708360015706

Epoch: 6| Step: 4
Training loss: 1.8089449405670166
Validation loss: 1.8859543210716658

Epoch: 6| Step: 5
Training loss: 2.356349468231201
Validation loss: 1.8978755550999795

Epoch: 6| Step: 6
Training loss: 1.8649898767471313
Validation loss: 1.9036533242912703

Epoch: 6| Step: 7
Training loss: 1.4633378982543945
Validation loss: 1.886371995813103

Epoch: 6| Step: 8
Training loss: 0.9609071016311646
Validation loss: 1.892735432553035

Epoch: 6| Step: 9
Training loss: 1.813045859336853
Validation loss: 1.8296588825923141

Epoch: 6| Step: 10
Training loss: 2.1893906593322754
Validation loss: 1.8761218158147668

Epoch: 6| Step: 11
Training loss: 2.0286388397216797
Validation loss: 1.8774808734975836

Epoch: 6| Step: 12
Training loss: 1.9732064008712769
Validation loss: 1.8524718758880452

Epoch: 6| Step: 13
Training loss: 1.729020118713379
Validation loss: 1.8610156736066263

Epoch: 175| Step: 0
Training loss: 1.628454327583313
Validation loss: 1.8865880863640898

Epoch: 6| Step: 1
Training loss: 1.3848230838775635
Validation loss: 1.9004274337522444

Epoch: 6| Step: 2
Training loss: 1.4841046333312988
Validation loss: 1.900407265591365

Epoch: 6| Step: 3
Training loss: 2.035426616668701
Validation loss: 1.871587860968805

Epoch: 6| Step: 4
Training loss: 2.1766750812530518
Validation loss: 1.8779901509643884

Epoch: 6| Step: 5
Training loss: 1.3801701068878174
Validation loss: 1.8774644097974222

Epoch: 6| Step: 6
Training loss: 1.697177767753601
Validation loss: 1.867315161612726

Epoch: 6| Step: 7
Training loss: 1.597434639930725
Validation loss: 1.8830117692229569

Epoch: 6| Step: 8
Training loss: 1.6788307428359985
Validation loss: 1.9057898508605136

Epoch: 6| Step: 9
Training loss: 2.5945310592651367
Validation loss: 1.8935168276550949

Epoch: 6| Step: 10
Training loss: 1.845802903175354
Validation loss: 1.891001207213248

Epoch: 6| Step: 11
Training loss: 1.821151852607727
Validation loss: 1.8687042138909782

Epoch: 6| Step: 12
Training loss: 1.6018972396850586
Validation loss: 1.9169486914911578

Epoch: 6| Step: 13
Training loss: 1.8261075019836426
Validation loss: 1.898175775363881

Epoch: 176| Step: 0
Training loss: 1.852958083152771
Validation loss: 1.8727393893785373

Epoch: 6| Step: 1
Training loss: 1.7250453233718872
Validation loss: 1.8651814896573302

Epoch: 6| Step: 2
Training loss: 1.8640830516815186
Validation loss: 1.8700100529578425

Epoch: 6| Step: 3
Training loss: 1.5332204103469849
Validation loss: 1.8755006123614568

Epoch: 6| Step: 4
Training loss: 1.7662652730941772
Validation loss: 1.8254354948638587

Epoch: 6| Step: 5
Training loss: 2.021466016769409
Validation loss: 1.8866276715391426

Epoch: 6| Step: 6
Training loss: 2.171774387359619
Validation loss: 1.8809410179814985

Epoch: 6| Step: 7
Training loss: 0.9836912155151367
Validation loss: 1.859604392000424

Epoch: 6| Step: 8
Training loss: 1.334639072418213
Validation loss: 1.8816521411300988

Epoch: 6| Step: 9
Training loss: 1.93131685256958
Validation loss: 1.8421575946192588

Epoch: 6| Step: 10
Training loss: 2.4868249893188477
Validation loss: 1.8695271117712862

Epoch: 6| Step: 11
Training loss: 2.0856704711914062
Validation loss: 1.8563961700726581

Epoch: 6| Step: 12
Training loss: 1.4673593044281006
Validation loss: 1.8899977066183602

Epoch: 6| Step: 13
Training loss: 1.1552033424377441
Validation loss: 1.861036700587119

Epoch: 177| Step: 0
Training loss: 1.6512731313705444
Validation loss: 1.867137369289193

Epoch: 6| Step: 1
Training loss: 1.919488787651062
Validation loss: 1.838238928907661

Epoch: 6| Step: 2
Training loss: 1.257507562637329
Validation loss: 1.9175212101269794

Epoch: 6| Step: 3
Training loss: 1.6035168170928955
Validation loss: 1.9132006258092902

Epoch: 6| Step: 4
Training loss: 1.9628984928131104
Validation loss: 1.8854451384595645

Epoch: 6| Step: 5
Training loss: 1.9793041944503784
Validation loss: 1.8713326672072053

Epoch: 6| Step: 6
Training loss: 2.721424102783203
Validation loss: 1.8981925351645357

Epoch: 6| Step: 7
Training loss: 1.425087332725525
Validation loss: 1.9207276990336757

Epoch: 6| Step: 8
Training loss: 1.7114582061767578
Validation loss: 1.8805368279898038

Epoch: 6| Step: 9
Training loss: 2.2267420291900635
Validation loss: 1.907673115371376

Epoch: 6| Step: 10
Training loss: 1.6593828201293945
Validation loss: 1.8577015720387942

Epoch: 6| Step: 11
Training loss: 1.8544080257415771
Validation loss: 1.8844637793879355

Epoch: 6| Step: 12
Training loss: 1.0436487197875977
Validation loss: 1.8681935738491755

Epoch: 6| Step: 13
Training loss: 1.7630887031555176
Validation loss: 1.9181428827265257

Epoch: 178| Step: 0
Training loss: 0.9171946048736572
Validation loss: 1.9057869706102597

Epoch: 6| Step: 1
Training loss: 1.5624363422393799
Validation loss: 1.8665239400761102

Epoch: 6| Step: 2
Training loss: 0.8669202327728271
Validation loss: 1.8941755166617773

Epoch: 6| Step: 3
Training loss: 2.4114432334899902
Validation loss: 1.9120982193177747

Epoch: 6| Step: 4
Training loss: 2.2232394218444824
Validation loss: 1.8837885856628418

Epoch: 6| Step: 5
Training loss: 1.5958778858184814
Validation loss: 1.8474017625213952

Epoch: 6| Step: 6
Training loss: 1.876707673072815
Validation loss: 1.8765136593131608

Epoch: 6| Step: 7
Training loss: 1.5389612913131714
Validation loss: 1.8675227959950764

Epoch: 6| Step: 8
Training loss: 1.8803222179412842
Validation loss: 1.8825109004974365

Epoch: 6| Step: 9
Training loss: 2.515324592590332
Validation loss: 1.8692578154225503

Epoch: 6| Step: 10
Training loss: 1.4209747314453125
Validation loss: 1.8945006785854217

Epoch: 6| Step: 11
Training loss: 1.878069281578064
Validation loss: 1.8343504462190854

Epoch: 6| Step: 12
Training loss: 2.111522674560547
Validation loss: 1.893542702480029

Epoch: 6| Step: 13
Training loss: 2.2527618408203125
Validation loss: 1.860518632396575

Epoch: 179| Step: 0
Training loss: 2.4358530044555664
Validation loss: 1.881289764117169

Epoch: 6| Step: 1
Training loss: 1.5746713876724243
Validation loss: 1.9021405404613865

Epoch: 6| Step: 2
Training loss: 1.3913516998291016
Validation loss: 1.898523812652916

Epoch: 6| Step: 3
Training loss: 1.7825847864151
Validation loss: 1.897710149006177

Epoch: 6| Step: 4
Training loss: 1.2842168807983398
Validation loss: 1.8484292517426193

Epoch: 6| Step: 5
Training loss: 1.4403257369995117
Validation loss: 1.8628934634629117

Epoch: 6| Step: 6
Training loss: 1.9704896211624146
Validation loss: 1.8871097962061565

Epoch: 6| Step: 7
Training loss: 2.154155731201172
Validation loss: 1.866498213942333

Epoch: 6| Step: 8
Training loss: 1.3890959024429321
Validation loss: 1.8900281844600555

Epoch: 6| Step: 9
Training loss: 1.8549693822860718
Validation loss: 1.8734711703433786

Epoch: 6| Step: 10
Training loss: 1.3709796667099
Validation loss: 1.878964752279302

Epoch: 6| Step: 11
Training loss: 1.5948326587677002
Validation loss: 1.8650509221579439

Epoch: 6| Step: 12
Training loss: 2.095675468444824
Validation loss: 1.8336506325711486

Epoch: 6| Step: 13
Training loss: 2.4834535121917725
Validation loss: 1.8560783965613252

Epoch: 180| Step: 0
Training loss: 1.3821618556976318
Validation loss: 1.8816121675634896

Epoch: 6| Step: 1
Training loss: 2.3718690872192383
Validation loss: 1.864278684380234

Epoch: 6| Step: 2
Training loss: 2.035797595977783
Validation loss: 1.9159182528013825

Epoch: 6| Step: 3
Training loss: 1.9456961154937744
Validation loss: 1.9092758829875658

Epoch: 6| Step: 4
Training loss: 1.8824024200439453
Validation loss: 1.9176101710206719

Epoch: 6| Step: 5
Training loss: 1.4786581993103027
Validation loss: 1.9214744606325704

Epoch: 6| Step: 6
Training loss: 2.313441276550293
Validation loss: 1.8843891646272393

Epoch: 6| Step: 7
Training loss: 1.2284703254699707
Validation loss: 1.9036712159392655

Epoch: 6| Step: 8
Training loss: 1.3998785018920898
Validation loss: 1.8835308808152393

Epoch: 6| Step: 9
Training loss: 1.410383701324463
Validation loss: 1.8636828199509652

Epoch: 6| Step: 10
Training loss: 1.2033703327178955
Validation loss: 1.9054480239909182

Epoch: 6| Step: 11
Training loss: 1.6813793182373047
Validation loss: 1.8402380571570447

Epoch: 6| Step: 12
Training loss: 2.108225107192993
Validation loss: 1.8845346127786944

Epoch: 6| Step: 13
Training loss: 2.3670220375061035
Validation loss: 1.8627992509513773

Epoch: 181| Step: 0
Training loss: 1.910549283027649
Validation loss: 1.9021893214153986

Epoch: 6| Step: 1
Training loss: 2.3056745529174805
Validation loss: 1.8966116213029431

Epoch: 6| Step: 2
Training loss: 1.7232787609100342
Validation loss: 1.8929460740858508

Epoch: 6| Step: 3
Training loss: 1.6244434118270874
Validation loss: 1.8719271998251639

Epoch: 6| Step: 4
Training loss: 1.5143545866012573
Validation loss: 1.8774864776160127

Epoch: 6| Step: 5
Training loss: 1.8985607624053955
Validation loss: 1.8713626938481485

Epoch: 6| Step: 6
Training loss: 2.146364212036133
Validation loss: 1.8797037101561023

Epoch: 6| Step: 7
Training loss: 1.7858691215515137
Validation loss: 1.8831070469271751

Epoch: 6| Step: 8
Training loss: 0.9476877450942993
Validation loss: 1.8459953787506267

Epoch: 6| Step: 9
Training loss: 2.024303913116455
Validation loss: 1.8626010879393546

Epoch: 6| Step: 10
Training loss: 1.07709801197052
Validation loss: 1.8788779602255872

Epoch: 6| Step: 11
Training loss: 1.6812891960144043
Validation loss: 1.8813100758419241

Epoch: 6| Step: 12
Training loss: 1.8635523319244385
Validation loss: 1.8444026849603141

Epoch: 6| Step: 13
Training loss: 1.777018666267395
Validation loss: 1.8444707329555223

Epoch: 182| Step: 0
Training loss: 1.5812017917633057
Validation loss: 1.8547697849171136

Epoch: 6| Step: 1
Training loss: 2.435302257537842
Validation loss: 1.8316987663187005

Epoch: 6| Step: 2
Training loss: 1.1787370443344116
Validation loss: 1.8539618279344292

Epoch: 6| Step: 3
Training loss: 1.9763290882110596
Validation loss: 1.856022983468989

Epoch: 6| Step: 4
Training loss: 1.4123399257659912
Validation loss: 1.8736540412390104

Epoch: 6| Step: 5
Training loss: 2.050654172897339
Validation loss: 1.8675006897218767

Epoch: 6| Step: 6
Training loss: 1.8792572021484375
Validation loss: 1.880524331523526

Epoch: 6| Step: 7
Training loss: 1.6417663097381592
Validation loss: 1.9084649662817679

Epoch: 6| Step: 8
Training loss: 2.0070159435272217
Validation loss: 1.8797838303350634

Epoch: 6| Step: 9
Training loss: 1.7014104127883911
Validation loss: 1.892834581354613

Epoch: 6| Step: 10
Training loss: 1.2799861431121826
Validation loss: 1.8952361229927308

Epoch: 6| Step: 11
Training loss: 1.5995736122131348
Validation loss: 1.8866835973596061

Epoch: 6| Step: 12
Training loss: 1.8305251598358154
Validation loss: 1.8792279920270365

Epoch: 6| Step: 13
Training loss: 2.402463912963867
Validation loss: 1.8952511792541833

Epoch: 183| Step: 0
Training loss: 2.0717878341674805
Validation loss: 1.887681927732242

Epoch: 6| Step: 1
Training loss: 1.8418548107147217
Validation loss: 1.8859744956416469

Epoch: 6| Step: 2
Training loss: 1.1795551776885986
Validation loss: 1.891155522356751

Epoch: 6| Step: 3
Training loss: 1.5514979362487793
Validation loss: 1.8571778420479066

Epoch: 6| Step: 4
Training loss: 1.2775017023086548
Validation loss: 1.9009324683937976

Epoch: 6| Step: 5
Training loss: 1.5411651134490967
Validation loss: 1.8682444544248684

Epoch: 6| Step: 6
Training loss: 1.767459750175476
Validation loss: 1.8669497979584562

Epoch: 6| Step: 7
Training loss: 1.9763565063476562
Validation loss: 1.8877971454333233

Epoch: 6| Step: 8
Training loss: 1.4407339096069336
Validation loss: 1.8832080453954718

Epoch: 6| Step: 9
Training loss: 2.199190616607666
Validation loss: 1.8742667705782

Epoch: 6| Step: 10
Training loss: 1.7478667497634888
Validation loss: 1.8951940895408712

Epoch: 6| Step: 11
Training loss: 2.661407709121704
Validation loss: 1.8414994465407504

Epoch: 6| Step: 12
Training loss: 1.6811001300811768
Validation loss: 1.8700474539110739

Epoch: 6| Step: 13
Training loss: 1.3883492946624756
Validation loss: 1.878065784772237

Epoch: 184| Step: 0
Training loss: 2.3977489471435547
Validation loss: 1.8783669779377599

Epoch: 6| Step: 1
Training loss: 2.347659111022949
Validation loss: 1.883744764071639

Epoch: 6| Step: 2
Training loss: 1.3889305591583252
Validation loss: 1.9100156420020646

Epoch: 6| Step: 3
Training loss: 1.9146881103515625
Validation loss: 1.871449565374723

Epoch: 6| Step: 4
Training loss: 1.4859645366668701
Validation loss: 1.8929885061838294

Epoch: 6| Step: 5
Training loss: 1.6035443544387817
Validation loss: 1.8941251898324618

Epoch: 6| Step: 6
Training loss: 1.681757926940918
Validation loss: 1.8916239764100762

Epoch: 6| Step: 7
Training loss: 1.3493964672088623
Validation loss: 1.8492875842637913

Epoch: 6| Step: 8
Training loss: 1.6379374265670776
Validation loss: 1.8733622156163698

Epoch: 6| Step: 9
Training loss: 1.9137498140335083
Validation loss: 1.9213997253807642

Epoch: 6| Step: 10
Training loss: 1.3122061491012573
Validation loss: 1.8918725764879616

Epoch: 6| Step: 11
Training loss: 1.7871609926223755
Validation loss: 1.8973767654870146

Epoch: 6| Step: 12
Training loss: 1.8574838638305664
Validation loss: 1.9122022813366306

Epoch: 6| Step: 13
Training loss: 1.6156681776046753
Validation loss: 1.8956727802112538

Epoch: 185| Step: 0
Training loss: 2.215914249420166
Validation loss: 1.8701643149058025

Epoch: 6| Step: 1
Training loss: 1.5493465662002563
Validation loss: 1.8699173183851345

Epoch: 6| Step: 2
Training loss: 1.6919984817504883
Validation loss: 1.8779435696140412

Epoch: 6| Step: 3
Training loss: 1.5446932315826416
Validation loss: 1.874921380832631

Epoch: 6| Step: 4
Training loss: 1.7138856649398804
Validation loss: 1.8707339353458856

Epoch: 6| Step: 5
Training loss: 1.797797441482544
Validation loss: 1.8842082920894827

Epoch: 6| Step: 6
Training loss: 1.0159897804260254
Validation loss: 1.8704324076252599

Epoch: 6| Step: 7
Training loss: 1.40791916847229
Validation loss: 1.855472308333202

Epoch: 6| Step: 8
Training loss: 1.2722711563110352
Validation loss: 1.904541075870555

Epoch: 6| Step: 9
Training loss: 2.213402271270752
Validation loss: 1.8768662970553163

Epoch: 6| Step: 10
Training loss: 1.742628574371338
Validation loss: 1.8596510169326619

Epoch: 6| Step: 11
Training loss: 2.422041893005371
Validation loss: 1.8525279157905168

Epoch: 6| Step: 12
Training loss: 1.683470606803894
Validation loss: 1.854904326059485

Epoch: 6| Step: 13
Training loss: 2.3000400066375732
Validation loss: 1.8591202279572845

Epoch: 186| Step: 0
Training loss: 1.2620198726654053
Validation loss: 1.8869168707119521

Epoch: 6| Step: 1
Training loss: 1.2911090850830078
Validation loss: 1.859429044108237

Epoch: 6| Step: 2
Training loss: 1.9797747135162354
Validation loss: 1.834141988908091

Epoch: 6| Step: 3
Training loss: 1.3625776767730713
Validation loss: 1.8595925261897426

Epoch: 6| Step: 4
Training loss: 2.017258405685425
Validation loss: 1.851305506562674

Epoch: 6| Step: 5
Training loss: 1.2016632556915283
Validation loss: 1.8502472805720505

Epoch: 6| Step: 6
Training loss: 1.2713959217071533
Validation loss: 1.8491766273334462

Epoch: 6| Step: 7
Training loss: 2.0628974437713623
Validation loss: 1.864138904438224

Epoch: 6| Step: 8
Training loss: 2.1063060760498047
Validation loss: 1.8687853351716073

Epoch: 6| Step: 9
Training loss: 2.2425498962402344
Validation loss: 1.872837338396298

Epoch: 6| Step: 10
Training loss: 1.9203460216522217
Validation loss: 1.8791207677574568

Epoch: 6| Step: 11
Training loss: 1.9182965755462646
Validation loss: 1.8746502566081222

Epoch: 6| Step: 12
Training loss: 1.871911644935608
Validation loss: 1.9071717249449862

Epoch: 6| Step: 13
Training loss: 1.8088510036468506
Validation loss: 1.8747478415889125

Epoch: 187| Step: 0
Training loss: 2.0966272354125977
Validation loss: 1.8521729271898988

Epoch: 6| Step: 1
Training loss: 1.1769369840621948
Validation loss: 1.8628353764933925

Epoch: 6| Step: 2
Training loss: 2.1234192848205566
Validation loss: 1.898737520299932

Epoch: 6| Step: 3
Training loss: 2.1578903198242188
Validation loss: 1.8730136681628484

Epoch: 6| Step: 4
Training loss: 1.8953598737716675
Validation loss: 1.8888687882372128

Epoch: 6| Step: 5
Training loss: 0.9385019540786743
Validation loss: 1.8711808676360755

Epoch: 6| Step: 6
Training loss: 1.888537883758545
Validation loss: 1.8711739278608752

Epoch: 6| Step: 7
Training loss: 1.896032691001892
Validation loss: 1.843546425142596

Epoch: 6| Step: 8
Training loss: 0.7331156134605408
Validation loss: 1.8651944834698913

Epoch: 6| Step: 9
Training loss: 1.911449670791626
Validation loss: 1.8814232477577784

Epoch: 6| Step: 10
Training loss: 1.693242073059082
Validation loss: 1.8759588913250995

Epoch: 6| Step: 11
Training loss: 1.6119630336761475
Validation loss: 1.8385209755230976

Epoch: 6| Step: 12
Training loss: 2.035454750061035
Validation loss: 1.8561395932269353

Epoch: 6| Step: 13
Training loss: 1.983237624168396
Validation loss: 1.8276957311937887

Epoch: 188| Step: 0
Training loss: 2.493734121322632
Validation loss: 1.865765102448002

Epoch: 6| Step: 1
Training loss: 1.5525400638580322
Validation loss: 1.8733001293674592

Epoch: 6| Step: 2
Training loss: 1.7166554927825928
Validation loss: 1.857873983280633

Epoch: 6| Step: 3
Training loss: 1.1381289958953857
Validation loss: 1.8554621845163324

Epoch: 6| Step: 4
Training loss: 1.7617990970611572
Validation loss: 1.9113612021169355

Epoch: 6| Step: 5
Training loss: 1.4759821891784668
Validation loss: 1.8581597317931473

Epoch: 6| Step: 6
Training loss: 1.4583847522735596
Validation loss: 1.8798800899136452

Epoch: 6| Step: 7
Training loss: 1.167140007019043
Validation loss: 1.861333365081459

Epoch: 6| Step: 8
Training loss: 1.7653753757476807
Validation loss: 1.8723571813234718

Epoch: 6| Step: 9
Training loss: 1.590550422668457
Validation loss: 1.856534041384215

Epoch: 6| Step: 10
Training loss: 2.352585792541504
Validation loss: 1.8539354660177743

Epoch: 6| Step: 11
Training loss: 1.9106364250183105
Validation loss: 1.8543159807882001

Epoch: 6| Step: 12
Training loss: 1.7551848888397217
Validation loss: 1.8497701729497602

Epoch: 6| Step: 13
Training loss: 2.26202130317688
Validation loss: 1.876789003290156

Epoch: 189| Step: 0
Training loss: 1.987733244895935
Validation loss: 1.8455558412818498

Epoch: 6| Step: 1
Training loss: 1.0176198482513428
Validation loss: 1.8994583570829002

Epoch: 6| Step: 2
Training loss: 1.7041822671890259
Validation loss: 1.8941189037856234

Epoch: 6| Step: 3
Training loss: 2.216590166091919
Validation loss: 1.8780923197346349

Epoch: 6| Step: 4
Training loss: 1.331897497177124
Validation loss: 1.8431317754971084

Epoch: 6| Step: 5
Training loss: 1.73951256275177
Validation loss: 1.8647662208926292

Epoch: 6| Step: 6
Training loss: 1.9613206386566162
Validation loss: 1.8818587974835468

Epoch: 6| Step: 7
Training loss: 1.7366490364074707
Validation loss: 1.8635347056132492

Epoch: 6| Step: 8
Training loss: 1.289095401763916
Validation loss: 1.8688872398868683

Epoch: 6| Step: 9
Training loss: 1.3349227905273438
Validation loss: 1.8895320097605388

Epoch: 6| Step: 10
Training loss: 1.8151849508285522
Validation loss: 1.8946046316495506

Epoch: 6| Step: 11
Training loss: 2.351102352142334
Validation loss: 1.8962660476725588

Epoch: 6| Step: 12
Training loss: 2.1176435947418213
Validation loss: 1.8775177553135862

Epoch: 6| Step: 13
Training loss: 1.2789617776870728
Validation loss: 1.8867482446855115

Epoch: 190| Step: 0
Training loss: 1.646462082862854
Validation loss: 1.8601287475196264

Epoch: 6| Step: 1
Training loss: 1.7345988750457764
Validation loss: 1.8618260698933755

Epoch: 6| Step: 2
Training loss: 1.7303111553192139
Validation loss: 1.85515966082132

Epoch: 6| Step: 3
Training loss: 1.551457166671753
Validation loss: 1.8535943518402755

Epoch: 6| Step: 4
Training loss: 1.485483169555664
Validation loss: 1.8695196464497557

Epoch: 6| Step: 5
Training loss: 1.5736843347549438
Validation loss: 1.8627736247995847

Epoch: 6| Step: 6
Training loss: 2.5721664428710938
Validation loss: 1.8713430486699587

Epoch: 6| Step: 7
Training loss: 1.6179251670837402
Validation loss: 1.8509871421321746

Epoch: 6| Step: 8
Training loss: 1.3534067869186401
Validation loss: 1.8377006489743468

Epoch: 6| Step: 9
Training loss: 1.7870557308197021
Validation loss: 1.8546166112346034

Epoch: 6| Step: 10
Training loss: 1.581540822982788
Validation loss: 1.8584652421295003

Epoch: 6| Step: 11
Training loss: 1.6485168933868408
Validation loss: 1.8496114900035243

Epoch: 6| Step: 12
Training loss: 1.7524152994155884
Validation loss: 1.8302690623908915

Epoch: 6| Step: 13
Training loss: 1.9977288246154785
Validation loss: 1.8342435090772566

Epoch: 191| Step: 0
Training loss: 1.4649701118469238
Validation loss: 1.8427701329672208

Epoch: 6| Step: 1
Training loss: 1.5602236986160278
Validation loss: 1.8708660858933643

Epoch: 6| Step: 2
Training loss: 1.2545392513275146
Validation loss: 1.8534745477860974

Epoch: 6| Step: 3
Training loss: 2.209394931793213
Validation loss: 1.8369206766928396

Epoch: 6| Step: 4
Training loss: 1.588411808013916
Validation loss: 1.8770848217830862

Epoch: 6| Step: 5
Training loss: 1.7435636520385742
Validation loss: 1.8269319431756132

Epoch: 6| Step: 6
Training loss: 2.402515411376953
Validation loss: 1.8512726573533909

Epoch: 6| Step: 7
Training loss: 2.5383479595184326
Validation loss: 1.8367425267414381

Epoch: 6| Step: 8
Training loss: 1.7013871669769287
Validation loss: 1.823733425909473

Epoch: 6| Step: 9
Training loss: 1.2451647520065308
Validation loss: 1.8667981316966396

Epoch: 6| Step: 10
Training loss: 1.3201380968093872
Validation loss: 1.8703313130204395

Epoch: 6| Step: 11
Training loss: 2.025317668914795
Validation loss: 1.8485407060192478

Epoch: 6| Step: 12
Training loss: 1.3229570388793945
Validation loss: 1.8542736179085189

Epoch: 6| Step: 13
Training loss: 1.3471227884292603
Validation loss: 1.8872450615770073

Epoch: 192| Step: 0
Training loss: 1.6025338172912598
Validation loss: 1.8723031782334851

Epoch: 6| Step: 1
Training loss: 1.0236190557479858
Validation loss: 1.853895297614477

Epoch: 6| Step: 2
Training loss: 1.9064143896102905
Validation loss: 1.8910486121331491

Epoch: 6| Step: 3
Training loss: 1.9751601219177246
Validation loss: 1.8979191344271424

Epoch: 6| Step: 4
Training loss: 1.8374536037445068
Validation loss: 1.8740194869297806

Epoch: 6| Step: 5
Training loss: 2.238718271255493
Validation loss: 1.901468708950986

Epoch: 6| Step: 6
Training loss: 1.2565829753875732
Validation loss: 1.8916973939505957

Epoch: 6| Step: 7
Training loss: 2.044400691986084
Validation loss: 1.870690372682387

Epoch: 6| Step: 8
Training loss: 1.8392064571380615
Validation loss: 1.8786427282517957

Epoch: 6| Step: 9
Training loss: 2.2290303707122803
Validation loss: 1.8545325212581183

Epoch: 6| Step: 10
Training loss: 1.6033655405044556
Validation loss: 1.8430466318643222

Epoch: 6| Step: 11
Training loss: 1.5534636974334717
Validation loss: 1.8568660815556843

Epoch: 6| Step: 12
Training loss: 1.4885330200195312
Validation loss: 1.8593293005420315

Epoch: 6| Step: 13
Training loss: 1.3075611591339111
Validation loss: 1.8912396853969944

Epoch: 193| Step: 0
Training loss: 1.5994343757629395
Validation loss: 1.8542679843082224

Epoch: 6| Step: 1
Training loss: 1.8877198696136475
Validation loss: 1.8562484620719828

Epoch: 6| Step: 2
Training loss: 1.9950567483901978
Validation loss: 1.889243248970278

Epoch: 6| Step: 3
Training loss: 1.4250967502593994
Validation loss: 1.8440113490627659

Epoch: 6| Step: 4
Training loss: 2.144292116165161
Validation loss: 1.8504100679069437

Epoch: 6| Step: 5
Training loss: 2.211413860321045
Validation loss: 1.8759097899160078

Epoch: 6| Step: 6
Training loss: 1.3175199031829834
Validation loss: 1.855501554345572

Epoch: 6| Step: 7
Training loss: 0.5806379318237305
Validation loss: 1.8596328855842672

Epoch: 6| Step: 8
Training loss: 1.5404680967330933
Validation loss: 1.897466080163115

Epoch: 6| Step: 9
Training loss: 2.063729763031006
Validation loss: 1.8752578253387122

Epoch: 6| Step: 10
Training loss: 1.5593912601470947
Validation loss: 1.8858231536803707

Epoch: 6| Step: 11
Training loss: 2.493131160736084
Validation loss: 1.8793789699513426

Epoch: 6| Step: 12
Training loss: 1.6796536445617676
Validation loss: 1.8860536826554166

Epoch: 6| Step: 13
Training loss: 1.153623104095459
Validation loss: 1.8926782915669103

Epoch: 194| Step: 0
Training loss: 1.9373140335083008
Validation loss: 1.8877065361187022

Epoch: 6| Step: 1
Training loss: 2.1167402267456055
Validation loss: 1.8780179357015958

Epoch: 6| Step: 2
Training loss: 1.5490903854370117
Validation loss: 1.8372588785745765

Epoch: 6| Step: 3
Training loss: 2.1094141006469727
Validation loss: 1.855735509626327

Epoch: 6| Step: 4
Training loss: 1.4531161785125732
Validation loss: 1.8534886503732333

Epoch: 6| Step: 5
Training loss: 1.4471880197525024
Validation loss: 1.8622562244374266

Epoch: 6| Step: 6
Training loss: 2.114332914352417
Validation loss: 1.8747028971231112

Epoch: 6| Step: 7
Training loss: 1.7480754852294922
Validation loss: 1.8459495421378844

Epoch: 6| Step: 8
Training loss: 1.845654010772705
Validation loss: 1.859406558416223

Epoch: 6| Step: 9
Training loss: 1.773719072341919
Validation loss: 1.8431594628159718

Epoch: 6| Step: 10
Training loss: 1.8883394002914429
Validation loss: 1.8550869444365143

Epoch: 6| Step: 11
Training loss: 1.3452949523925781
Validation loss: 1.8811884221210275

Epoch: 6| Step: 12
Training loss: 0.9987678527832031
Validation loss: 1.8489695274701683

Epoch: 6| Step: 13
Training loss: 1.450751781463623
Validation loss: 1.8737162966882028

Epoch: 195| Step: 0
Training loss: 1.6294081211090088
Validation loss: 1.876480289684829

Epoch: 6| Step: 1
Training loss: 1.8283966779708862
Validation loss: 1.8484867183111047

Epoch: 6| Step: 2
Training loss: 1.6392021179199219
Validation loss: 1.8401208744254163

Epoch: 6| Step: 3
Training loss: 2.1508121490478516
Validation loss: 1.8509246944099345

Epoch: 6| Step: 4
Training loss: 1.6623024940490723
Validation loss: 1.8607740735494962

Epoch: 6| Step: 5
Training loss: 2.0460851192474365
Validation loss: 1.8567476503310665

Epoch: 6| Step: 6
Training loss: 1.5292850732803345
Validation loss: 1.878546719909996

Epoch: 6| Step: 7
Training loss: 2.1576809883117676
Validation loss: 1.8620192491880028

Epoch: 6| Step: 8
Training loss: 1.5966064929962158
Validation loss: 1.8230799551933043

Epoch: 6| Step: 9
Training loss: 1.38681960105896
Validation loss: 1.8538948310318815

Epoch: 6| Step: 10
Training loss: 1.2507679462432861
Validation loss: 1.8529538980094336

Epoch: 6| Step: 11
Training loss: 1.2204759120941162
Validation loss: 1.8648039512736823

Epoch: 6| Step: 12
Training loss: 1.3973171710968018
Validation loss: 1.8494562538721229

Epoch: 6| Step: 13
Training loss: 2.548008918762207
Validation loss: 1.8490342786235194

Epoch: 196| Step: 0
Training loss: 2.115217924118042
Validation loss: 1.8447479368537985

Epoch: 6| Step: 1
Training loss: 1.8997623920440674
Validation loss: 1.857532114110967

Epoch: 6| Step: 2
Training loss: 1.6986196041107178
Validation loss: 1.8325574167313115

Epoch: 6| Step: 3
Training loss: 1.7760958671569824
Validation loss: 1.8323670894868913

Epoch: 6| Step: 4
Training loss: 2.0104353427886963
Validation loss: 1.8588055000510266

Epoch: 6| Step: 5
Training loss: 0.8303890228271484
Validation loss: 1.8775129177237069

Epoch: 6| Step: 6
Training loss: 1.2631657123565674
Validation loss: 1.8700623102085565

Epoch: 6| Step: 7
Training loss: 2.062534809112549
Validation loss: 1.824431332208777

Epoch: 6| Step: 8
Training loss: 1.5511465072631836
Validation loss: 1.8754288458055066

Epoch: 6| Step: 9
Training loss: 1.5574252605438232
Validation loss: 1.8321765558693999

Epoch: 6| Step: 10
Training loss: 1.385437250137329
Validation loss: 1.848335495559118

Epoch: 6| Step: 11
Training loss: 1.9267604351043701
Validation loss: 1.8513037261142526

Epoch: 6| Step: 12
Training loss: 1.988339900970459
Validation loss: 1.8928093294943533

Epoch: 6| Step: 13
Training loss: 1.4068573713302612
Validation loss: 1.8479857085853495

Epoch: 197| Step: 0
Training loss: 1.2615174055099487
Validation loss: 1.8735429240811257

Epoch: 6| Step: 1
Training loss: 1.6263978481292725
Validation loss: 1.8624210972939768

Epoch: 6| Step: 2
Training loss: 1.0971648693084717
Validation loss: 1.8580905698960828

Epoch: 6| Step: 3
Training loss: 0.9621542096138
Validation loss: 1.831576616533341

Epoch: 6| Step: 4
Training loss: 2.1430625915527344
Validation loss: 1.8727980852127075

Epoch: 6| Step: 5
Training loss: 2.263115644454956
Validation loss: 1.8999736796143234

Epoch: 6| Step: 6
Training loss: 2.3622913360595703
Validation loss: 1.8802563657042801

Epoch: 6| Step: 7
Training loss: 1.7306020259857178
Validation loss: 1.8467932619074339

Epoch: 6| Step: 8
Training loss: 2.0403590202331543
Validation loss: 1.8625678336748512

Epoch: 6| Step: 9
Training loss: 1.0194820165634155
Validation loss: 1.8601199273140199

Epoch: 6| Step: 10
Training loss: 1.49905526638031
Validation loss: 1.8741399831669305

Epoch: 6| Step: 11
Training loss: 1.4152181148529053
Validation loss: 1.8667530603306268

Epoch: 6| Step: 12
Training loss: 2.50905442237854
Validation loss: 1.871109934263332

Epoch: 6| Step: 13
Training loss: 1.6920193433761597
Validation loss: 1.8509213578316472

Epoch: 198| Step: 0
Training loss: 1.2654006481170654
Validation loss: 1.8491953534464682

Epoch: 6| Step: 1
Training loss: 1.757516860961914
Validation loss: 1.8683225826550556

Epoch: 6| Step: 2
Training loss: 1.5257480144500732
Validation loss: 1.8389019761034238

Epoch: 6| Step: 3
Training loss: 1.499220848083496
Validation loss: 1.8554610026779996

Epoch: 6| Step: 4
Training loss: 1.9164164066314697
Validation loss: 1.8513136358671292

Epoch: 6| Step: 5
Training loss: 1.1319010257720947
Validation loss: 1.8367005868624615

Epoch: 6| Step: 6
Training loss: 1.700286626815796
Validation loss: 1.820440323122086

Epoch: 6| Step: 7
Training loss: 1.6290098428726196
Validation loss: 1.8470156410688996

Epoch: 6| Step: 8
Training loss: 1.9908543825149536
Validation loss: 1.8417787808243946

Epoch: 6| Step: 9
Training loss: 2.5230326652526855
Validation loss: 1.8442618539256435

Epoch: 6| Step: 10
Training loss: 1.6766514778137207
Validation loss: 1.8875765172384118

Epoch: 6| Step: 11
Training loss: 1.566934585571289
Validation loss: 1.8896832850671583

Epoch: 6| Step: 12
Training loss: 1.3431223630905151
Validation loss: 1.8635776863303235

Epoch: 6| Step: 13
Training loss: 1.8332773447036743
Validation loss: 1.8180302573788552

Epoch: 199| Step: 0
Training loss: 1.6625829935073853
Validation loss: 1.8339701275671683

Epoch: 6| Step: 1
Training loss: 1.4117110967636108
Validation loss: 1.8577759047990203

Epoch: 6| Step: 2
Training loss: 2.3340060710906982
Validation loss: 1.8501401101389239

Epoch: 6| Step: 3
Training loss: 1.5484302043914795
Validation loss: 1.8682296865729875

Epoch: 6| Step: 4
Training loss: 1.7847089767456055
Validation loss: 1.8627168529777116

Epoch: 6| Step: 5
Training loss: 1.8509089946746826
Validation loss: 1.8428130021659277

Epoch: 6| Step: 6
Training loss: 2.154934883117676
Validation loss: 1.9076309486102032

Epoch: 6| Step: 7
Training loss: 1.405021071434021
Validation loss: 1.8803858654473418

Epoch: 6| Step: 8
Training loss: 1.874854564666748
Validation loss: 1.8734797098303353

Epoch: 6| Step: 9
Training loss: 1.7862883806228638
Validation loss: 1.8743986788616385

Epoch: 6| Step: 10
Training loss: 1.190033197402954
Validation loss: 1.8780578362044467

Epoch: 6| Step: 11
Training loss: 1.2693572044372559
Validation loss: 1.8560612099145049

Epoch: 6| Step: 12
Training loss: 1.4999685287475586
Validation loss: 1.8742198790273359

Epoch: 6| Step: 13
Training loss: 1.7836600542068481
Validation loss: 1.8675921399106261

Epoch: 200| Step: 0
Training loss: 2.100039005279541
Validation loss: 1.8842544119845155

Epoch: 6| Step: 1
Training loss: 2.2111144065856934
Validation loss: 1.8516540783707813

Epoch: 6| Step: 2
Training loss: 0.9913150668144226
Validation loss: 1.8279184449103572

Epoch: 6| Step: 3
Training loss: 1.386181116104126
Validation loss: 1.8485029153926398

Epoch: 6| Step: 4
Training loss: 1.7222017049789429
Validation loss: 1.8592610231009863

Epoch: 6| Step: 5
Training loss: 1.736328363418579
Validation loss: 1.9123861443611883

Epoch: 6| Step: 6
Training loss: 1.8946218490600586
Validation loss: 1.8746761609149236

Epoch: 6| Step: 7
Training loss: 1.4294891357421875
Validation loss: 1.9131773338522962

Epoch: 6| Step: 8
Training loss: 2.467125415802002
Validation loss: 1.8665432263446111

Epoch: 6| Step: 9
Training loss: 1.1981427669525146
Validation loss: 1.8856018333024875

Epoch: 6| Step: 10
Training loss: 1.6890459060668945
Validation loss: 1.813072435317501

Epoch: 6| Step: 11
Training loss: 1.9838168621063232
Validation loss: 1.8707942308918122

Epoch: 6| Step: 12
Training loss: 1.361162781715393
Validation loss: 1.8400455033907326

Epoch: 6| Step: 13
Training loss: 1.1178497076034546
Validation loss: 1.844107808605317

Epoch: 201| Step: 0
Training loss: 1.673673152923584
Validation loss: 1.8238612503133795

Epoch: 6| Step: 1
Training loss: 1.826890468597412
Validation loss: 1.8685921751042849

Epoch: 6| Step: 2
Training loss: 1.6646661758422852
Validation loss: 1.9046870790502077

Epoch: 6| Step: 3
Training loss: 1.6564126014709473
Validation loss: 1.8557437760855562

Epoch: 6| Step: 4
Training loss: 1.9702283143997192
Validation loss: 1.843781376397738

Epoch: 6| Step: 5
Training loss: 1.6412214040756226
Validation loss: 1.8464099412323327

Epoch: 6| Step: 6
Training loss: 1.8212412595748901
Validation loss: 1.8340487967255295

Epoch: 6| Step: 7
Training loss: 1.986565113067627
Validation loss: 1.8196623940621652

Epoch: 6| Step: 8
Training loss: 1.441523551940918
Validation loss: 1.8831947900915658

Epoch: 6| Step: 9
Training loss: 1.308855652809143
Validation loss: 1.8364587124957834

Epoch: 6| Step: 10
Training loss: 1.789344310760498
Validation loss: 1.8431234090558943

Epoch: 6| Step: 11
Training loss: 1.503678798675537
Validation loss: 1.866518638467276

Epoch: 6| Step: 12
Training loss: 1.8827979564666748
Validation loss: 1.8574517619225286

Epoch: 6| Step: 13
Training loss: 0.9663389921188354
Validation loss: 1.8741686023691648

Epoch: 202| Step: 0
Training loss: 1.3988087177276611
Validation loss: 1.84223606125001

Epoch: 6| Step: 1
Training loss: 1.8101756572723389
Validation loss: 1.8967584756112867

Epoch: 6| Step: 2
Training loss: 1.5635130405426025
Validation loss: 1.8577918044982418

Epoch: 6| Step: 3
Training loss: 1.632216215133667
Validation loss: 1.84289562830361

Epoch: 6| Step: 4
Training loss: 1.955551266670227
Validation loss: 1.8830595362570979

Epoch: 6| Step: 5
Training loss: 1.494247555732727
Validation loss: 1.8570899989015313

Epoch: 6| Step: 6
Training loss: 1.754035472869873
Validation loss: 1.8655816893423758

Epoch: 6| Step: 7
Training loss: 1.90842866897583
Validation loss: 1.888241378209924

Epoch: 6| Step: 8
Training loss: 1.9417541027069092
Validation loss: 1.883057519953738

Epoch: 6| Step: 9
Training loss: 1.2019037008285522
Validation loss: 1.8586004908366869

Epoch: 6| Step: 10
Training loss: 1.5054924488067627
Validation loss: 1.88672379268113

Epoch: 6| Step: 11
Training loss: 1.6446690559387207
Validation loss: 1.9198328410425494

Epoch: 6| Step: 12
Training loss: 1.74806809425354
Validation loss: 1.8799306205523911

Epoch: 6| Step: 13
Training loss: 1.8826473951339722
Validation loss: 1.8602086754255398

Epoch: 203| Step: 0
Training loss: 2.0624747276306152
Validation loss: 1.8500714737881896

Epoch: 6| Step: 1
Training loss: 2.1012611389160156
Validation loss: 1.8862185529483262

Epoch: 6| Step: 2
Training loss: 1.8900463581085205
Validation loss: 1.8761812333137757

Epoch: 6| Step: 3
Training loss: 1.1068366765975952
Validation loss: 1.8505836648325766

Epoch: 6| Step: 4
Training loss: 1.966155767440796
Validation loss: 1.8459215702549103

Epoch: 6| Step: 5
Training loss: 1.4188851118087769
Validation loss: 1.8834611203080864

Epoch: 6| Step: 6
Training loss: 2.1408820152282715
Validation loss: 1.8268143438523816

Epoch: 6| Step: 7
Training loss: 1.5985121726989746
Validation loss: 1.8333621499358967

Epoch: 6| Step: 8
Training loss: 1.7252953052520752
Validation loss: 1.8595589053246282

Epoch: 6| Step: 9
Training loss: 1.390517234802246
Validation loss: 1.8535866660456504

Epoch: 6| Step: 10
Training loss: 1.5369036197662354
Validation loss: 1.8730429500661872

Epoch: 6| Step: 11
Training loss: 1.2246695756912231
Validation loss: 1.8698545399532522

Epoch: 6| Step: 12
Training loss: 1.6040691137313843
Validation loss: 1.8729608417839132

Epoch: 6| Step: 13
Training loss: 1.6852061748504639
Validation loss: 1.8690830828041158

Epoch: 204| Step: 0
Training loss: 1.3902497291564941
Validation loss: 1.8389239618855138

Epoch: 6| Step: 1
Training loss: 1.5795507431030273
Validation loss: 1.831876197168904

Epoch: 6| Step: 2
Training loss: 1.7021023035049438
Validation loss: 1.8450529216438212

Epoch: 6| Step: 3
Training loss: 1.9361271858215332
Validation loss: 1.9022247714381064

Epoch: 6| Step: 4
Training loss: 1.6837998628616333
Validation loss: 1.8573322847325315

Epoch: 6| Step: 5
Training loss: 1.5966057777404785
Validation loss: 1.8487308486815421

Epoch: 6| Step: 6
Training loss: 1.463083267211914
Validation loss: 1.8761761547416769

Epoch: 6| Step: 7
Training loss: 1.140761137008667
Validation loss: 1.876647772327546

Epoch: 6| Step: 8
Training loss: 1.4964487552642822
Validation loss: 1.8437388609814387

Epoch: 6| Step: 9
Training loss: 2.0414958000183105
Validation loss: 1.8440381083437192

Epoch: 6| Step: 10
Training loss: 1.3630931377410889
Validation loss: 1.838087825364964

Epoch: 6| Step: 11
Training loss: 2.23054838180542
Validation loss: 1.851511614297026

Epoch: 6| Step: 12
Training loss: 1.8823720216751099
Validation loss: 1.8458859215500534

Epoch: 6| Step: 13
Training loss: 2.269116163253784
Validation loss: 1.833512540786497

Epoch: 205| Step: 0
Training loss: 2.2211477756500244
Validation loss: 1.8560054981580345

Epoch: 6| Step: 1
Training loss: 2.121262311935425
Validation loss: 1.8536917496752996

Epoch: 6| Step: 2
Training loss: 1.1018668413162231
Validation loss: 1.8706495377325243

Epoch: 6| Step: 3
Training loss: 1.674837589263916
Validation loss: 1.8354388808691373

Epoch: 6| Step: 4
Training loss: 1.7603259086608887
Validation loss: 1.8144717165218887

Epoch: 6| Step: 5
Training loss: 1.3187792301177979
Validation loss: 1.8862433202805058

Epoch: 6| Step: 6
Training loss: 0.9973397850990295
Validation loss: 1.8783016884198753

Epoch: 6| Step: 7
Training loss: 1.7658603191375732
Validation loss: 1.8587258438910208

Epoch: 6| Step: 8
Training loss: 2.0234265327453613
Validation loss: 1.8483294235762728

Epoch: 6| Step: 9
Training loss: 1.5133459568023682
Validation loss: 1.8769825555944954

Epoch: 6| Step: 10
Training loss: 1.5872920751571655
Validation loss: 1.8598166127358713

Epoch: 6| Step: 11
Training loss: 1.9634240865707397
Validation loss: 1.856243351454376

Epoch: 6| Step: 12
Training loss: 1.5859029293060303
Validation loss: 1.8713652510796823

Epoch: 6| Step: 13
Training loss: 1.344189167022705
Validation loss: 1.8729050390182003

Epoch: 206| Step: 0
Training loss: 1.446529746055603
Validation loss: 1.8818227116779616

Epoch: 6| Step: 1
Training loss: 1.1809487342834473
Validation loss: 1.8493085509987288

Epoch: 6| Step: 2
Training loss: 1.0753473043441772
Validation loss: 1.8980496801355833

Epoch: 6| Step: 3
Training loss: 1.7960554361343384
Validation loss: 1.849253055869892

Epoch: 6| Step: 4
Training loss: 1.848862886428833
Validation loss: 1.8648193510629798

Epoch: 6| Step: 5
Training loss: 1.3370933532714844
Validation loss: 1.8649485111236572

Epoch: 6| Step: 6
Training loss: 1.7838037014007568
Validation loss: 1.8638624504048338

Epoch: 6| Step: 7
Training loss: 2.501688003540039
Validation loss: 1.8313138766955304

Epoch: 6| Step: 8
Training loss: 1.559605598449707
Validation loss: 1.8391118395713069

Epoch: 6| Step: 9
Training loss: 1.6139049530029297
Validation loss: 1.8482093234216013

Epoch: 6| Step: 10
Training loss: 1.9026331901550293
Validation loss: 1.840463557550984

Epoch: 6| Step: 11
Training loss: 1.9404820203781128
Validation loss: 1.858659807071891

Epoch: 6| Step: 12
Training loss: 2.249014139175415
Validation loss: 1.8469584744463685

Epoch: 6| Step: 13
Training loss: 0.8795998096466064
Validation loss: 1.8438271758376912

Epoch: 207| Step: 0
Training loss: 1.9146265983581543
Validation loss: 1.8054048656135477

Epoch: 6| Step: 1
Training loss: 1.7315740585327148
Validation loss: 1.8127895747461626

Epoch: 6| Step: 2
Training loss: 1.7349317073822021
Validation loss: 1.82388226960295

Epoch: 6| Step: 3
Training loss: 1.6373376846313477
Validation loss: 1.834319410785552

Epoch: 6| Step: 4
Training loss: 0.8491920232772827
Validation loss: 1.8548738597541727

Epoch: 6| Step: 5
Training loss: 1.7994389533996582
Validation loss: 1.8256374853913502

Epoch: 6| Step: 6
Training loss: 1.4687249660491943
Validation loss: 1.8571891797486173

Epoch: 6| Step: 7
Training loss: 1.8932921886444092
Validation loss: 1.8247368540815128

Epoch: 6| Step: 8
Training loss: 1.944212555885315
Validation loss: 1.8217480900467082

Epoch: 6| Step: 9
Training loss: 1.6820287704467773
Validation loss: 1.8373483457872946

Epoch: 6| Step: 10
Training loss: 1.6517727375030518
Validation loss: 1.8536732978718256

Epoch: 6| Step: 11
Training loss: 1.2404204607009888
Validation loss: 1.831810365441025

Epoch: 6| Step: 12
Training loss: 1.813079833984375
Validation loss: 1.832614334680701

Epoch: 6| Step: 13
Training loss: 2.0958433151245117
Validation loss: 1.8333278163786857

Epoch: 208| Step: 0
Training loss: 1.2015552520751953
Validation loss: 1.868903556177693

Epoch: 6| Step: 1
Training loss: 2.1196303367614746
Validation loss: 1.8603263003851778

Epoch: 6| Step: 2
Training loss: 1.8230230808258057
Validation loss: 1.8791944570438837

Epoch: 6| Step: 3
Training loss: 1.730555534362793
Validation loss: 1.9112381499300721

Epoch: 6| Step: 4
Training loss: 1.8898307085037231
Validation loss: 1.9150984966626732

Epoch: 6| Step: 5
Training loss: 1.7057509422302246
Validation loss: 1.9252661671689761

Epoch: 6| Step: 6
Training loss: 1.819293737411499
Validation loss: 1.902424197043142

Epoch: 6| Step: 7
Training loss: 1.9895108938217163
Validation loss: 1.9060385727113294

Epoch: 6| Step: 8
Training loss: 1.402231216430664
Validation loss: 1.9080855923314248

Epoch: 6| Step: 9
Training loss: 2.0231409072875977
Validation loss: 1.8822002398070468

Epoch: 6| Step: 10
Training loss: 0.9635054469108582
Validation loss: 1.901841413590216

Epoch: 6| Step: 11
Training loss: 1.461778163909912
Validation loss: 1.8824571870988416

Epoch: 6| Step: 12
Training loss: 1.9299620389938354
Validation loss: 1.8371684820421281

Epoch: 6| Step: 13
Training loss: 1.6223136186599731
Validation loss: 1.8546109430251583

Epoch: 209| Step: 0
Training loss: 1.6818894147872925
Validation loss: 1.8571168504735476

Epoch: 6| Step: 1
Training loss: 1.3966124057769775
Validation loss: 1.8317431173016947

Epoch: 6| Step: 2
Training loss: 2.0843505859375
Validation loss: 1.8105619030614053

Epoch: 6| Step: 3
Training loss: 1.4807195663452148
Validation loss: 1.8323289963506884

Epoch: 6| Step: 4
Training loss: 2.0038766860961914
Validation loss: 1.8444524836796585

Epoch: 6| Step: 5
Training loss: 2.198837995529175
Validation loss: 1.8608158929373628

Epoch: 6| Step: 6
Training loss: 1.2222367525100708
Validation loss: 1.8668039409063195

Epoch: 6| Step: 7
Training loss: 1.3923463821411133
Validation loss: 1.8558061199803506

Epoch: 6| Step: 8
Training loss: 1.5518920421600342
Validation loss: 1.838843527660575

Epoch: 6| Step: 9
Training loss: 1.8124127388000488
Validation loss: 1.8463731247891662

Epoch: 6| Step: 10
Training loss: 2.653644323348999
Validation loss: 1.8535238517227994

Epoch: 6| Step: 11
Training loss: 1.3426358699798584
Validation loss: 1.8316251885506414

Epoch: 6| Step: 12
Training loss: 1.0133790969848633
Validation loss: 1.857460618019104

Epoch: 6| Step: 13
Training loss: 1.9773279428482056
Validation loss: 1.8429378463375954

Epoch: 210| Step: 0
Training loss: 1.3840157985687256
Validation loss: 1.8497982307146954

Epoch: 6| Step: 1
Training loss: 1.2837119102478027
Validation loss: 1.8706698866300686

Epoch: 6| Step: 2
Training loss: 1.765486478805542
Validation loss: 1.8957925611926663

Epoch: 6| Step: 3
Training loss: 1.2178874015808105
Validation loss: 1.8802459932142688

Epoch: 6| Step: 4
Training loss: 1.2750080823898315
Validation loss: 1.8599901109613397

Epoch: 6| Step: 5
Training loss: 1.5438222885131836
Validation loss: 1.8901532439775364

Epoch: 6| Step: 6
Training loss: 1.8095875978469849
Validation loss: 1.8661292804184781

Epoch: 6| Step: 7
Training loss: 1.93868088722229
Validation loss: 1.8767490207508046

Epoch: 6| Step: 8
Training loss: 2.0073187351226807
Validation loss: 1.8674647692711122

Epoch: 6| Step: 9
Training loss: 1.9929221868515015
Validation loss: 1.8518855135927919

Epoch: 6| Step: 10
Training loss: 1.4239784479141235
Validation loss: 1.8615689085375877

Epoch: 6| Step: 11
Training loss: 1.9937794208526611
Validation loss: 1.865656816831199

Epoch: 6| Step: 12
Training loss: 2.0188376903533936
Validation loss: 1.86562305624767

Epoch: 6| Step: 13
Training loss: 1.3243613243103027
Validation loss: 1.8387830757325696

Epoch: 211| Step: 0
Training loss: 1.7572455406188965
Validation loss: 1.8752916846224057

Epoch: 6| Step: 1
Training loss: 1.3994660377502441
Validation loss: 1.861974795659383

Epoch: 6| Step: 2
Training loss: 1.474062204360962
Validation loss: 1.8526744022164294

Epoch: 6| Step: 3
Training loss: 1.7216265201568604
Validation loss: 1.8421387351969236

Epoch: 6| Step: 4
Training loss: 1.4057025909423828
Validation loss: 1.8474750390616796

Epoch: 6| Step: 5
Training loss: 2.0778121948242188
Validation loss: 1.8068245226337063

Epoch: 6| Step: 6
Training loss: 1.655388355255127
Validation loss: 1.8599298179790538

Epoch: 6| Step: 7
Training loss: 1.6120007038116455
Validation loss: 1.8479621166824012

Epoch: 6| Step: 8
Training loss: 2.056306838989258
Validation loss: 1.8274709127282585

Epoch: 6| Step: 9
Training loss: 1.7707533836364746
Validation loss: 1.8587998959325975

Epoch: 6| Step: 10
Training loss: 1.71803879737854
Validation loss: 1.8815901843450402

Epoch: 6| Step: 11
Training loss: 1.1666549444198608
Validation loss: 1.8295527017244728

Epoch: 6| Step: 12
Training loss: 1.2106784582138062
Validation loss: 1.8273374060148835

Epoch: 6| Step: 13
Training loss: 1.8587193489074707
Validation loss: 1.8050771195401427

Epoch: 212| Step: 0
Training loss: 1.3831006288528442
Validation loss: 1.8505070055684736

Epoch: 6| Step: 1
Training loss: 1.238531231880188
Validation loss: 1.820564289246836

Epoch: 6| Step: 2
Training loss: 1.3940505981445312
Validation loss: 1.8172923313674105

Epoch: 6| Step: 3
Training loss: 1.5279815196990967
Validation loss: 1.8517868929011847

Epoch: 6| Step: 4
Training loss: 0.9382483959197998
Validation loss: 1.8286513795134842

Epoch: 6| Step: 5
Training loss: 1.7624077796936035
Validation loss: 1.8312399118177352

Epoch: 6| Step: 6
Training loss: 1.1267954111099243
Validation loss: 1.846253236134847

Epoch: 6| Step: 7
Training loss: 2.013425827026367
Validation loss: 1.8307039814610635

Epoch: 6| Step: 8
Training loss: 1.7169950008392334
Validation loss: 1.8327595879954677

Epoch: 6| Step: 9
Training loss: 1.6972312927246094
Validation loss: 1.8629708879737443

Epoch: 6| Step: 10
Training loss: 1.3731904029846191
Validation loss: 1.8200191092747513

Epoch: 6| Step: 11
Training loss: 3.068484306335449
Validation loss: 1.8570695833493305

Epoch: 6| Step: 12
Training loss: 1.7282880544662476
Validation loss: 1.8712066899063766

Epoch: 6| Step: 13
Training loss: 1.8594352006912231
Validation loss: 1.8721513184168006

Epoch: 213| Step: 0
Training loss: 1.54417085647583
Validation loss: 1.8733829580327517

Epoch: 6| Step: 1
Training loss: 0.9918192625045776
Validation loss: 1.8703452630709576

Epoch: 6| Step: 2
Training loss: 2.202502489089966
Validation loss: 1.8975911371169552

Epoch: 6| Step: 3
Training loss: 2.2317121028900146
Validation loss: 1.8310544157540927

Epoch: 6| Step: 4
Training loss: 1.4335618019104004
Validation loss: 1.8267496349991008

Epoch: 6| Step: 5
Training loss: 1.0415364503860474
Validation loss: 1.841447009835192

Epoch: 6| Step: 6
Training loss: 1.117464542388916
Validation loss: 1.8541662603296258

Epoch: 6| Step: 7
Training loss: 1.687450885772705
Validation loss: 1.8536742900007515

Epoch: 6| Step: 8
Training loss: 2.02485990524292
Validation loss: 1.885564983531993

Epoch: 6| Step: 9
Training loss: 1.9036853313446045
Validation loss: 1.8576324550054406

Epoch: 6| Step: 10
Training loss: 0.905310869216919
Validation loss: 1.8681097940732074

Epoch: 6| Step: 11
Training loss: 2.1388370990753174
Validation loss: 1.8574207828890892

Epoch: 6| Step: 12
Training loss: 2.1392242908477783
Validation loss: 1.8627796429459766

Epoch: 6| Step: 13
Training loss: 1.1907539367675781
Validation loss: 1.8803312611836258

Epoch: 214| Step: 0
Training loss: 1.6523661613464355
Validation loss: 1.891973509583422

Epoch: 6| Step: 1
Training loss: 1.7057021856307983
Validation loss: 1.8652119867263302

Epoch: 6| Step: 2
Training loss: 1.4531044960021973
Validation loss: 1.8458692707041258

Epoch: 6| Step: 3
Training loss: 1.5860815048217773
Validation loss: 1.8560244652532762

Epoch: 6| Step: 4
Training loss: 1.5311729907989502
Validation loss: 1.8442756411849812

Epoch: 6| Step: 5
Training loss: 1.4092659950256348
Validation loss: 1.8351105695129724

Epoch: 6| Step: 6
Training loss: 2.0553369522094727
Validation loss: 1.8121982441153577

Epoch: 6| Step: 7
Training loss: 1.9767215251922607
Validation loss: 1.8139996426079863

Epoch: 6| Step: 8
Training loss: 1.283914566040039
Validation loss: 1.856837304689551

Epoch: 6| Step: 9
Training loss: 1.2887775897979736
Validation loss: 1.8545489400945685

Epoch: 6| Step: 10
Training loss: 1.9139291048049927
Validation loss: 1.8574928775910409

Epoch: 6| Step: 11
Training loss: 1.9294300079345703
Validation loss: 1.8519969729967014

Epoch: 6| Step: 12
Training loss: 1.5090179443359375
Validation loss: 1.8174711196653304

Epoch: 6| Step: 13
Training loss: 1.6840221881866455
Validation loss: 1.8158793257128807

Epoch: 215| Step: 0
Training loss: 2.0688886642456055
Validation loss: 1.8523159360372892

Epoch: 6| Step: 1
Training loss: 2.213230609893799
Validation loss: 1.849061849296734

Epoch: 6| Step: 2
Training loss: 2.207434892654419
Validation loss: 1.8460770704412972

Epoch: 6| Step: 3
Training loss: 1.2786973714828491
Validation loss: 1.806944224142259

Epoch: 6| Step: 4
Training loss: 0.8325157761573792
Validation loss: 1.8512456070992254

Epoch: 6| Step: 5
Training loss: 1.1346848011016846
Validation loss: 1.8531476400231803

Epoch: 6| Step: 6
Training loss: 1.815220594406128
Validation loss: 1.8242315502576931

Epoch: 6| Step: 7
Training loss: 1.1005127429962158
Validation loss: 1.8069710744324552

Epoch: 6| Step: 8
Training loss: 1.682847261428833
Validation loss: 1.8407574469043362

Epoch: 6| Step: 9
Training loss: 1.8927059173583984
Validation loss: 1.8633502401331419

Epoch: 6| Step: 10
Training loss: 1.395115613937378
Validation loss: 1.8467673127369215

Epoch: 6| Step: 11
Training loss: 2.1251964569091797
Validation loss: 1.8576755754409298

Epoch: 6| Step: 12
Training loss: 1.7157671451568604
Validation loss: 1.864914971013223

Epoch: 6| Step: 13
Training loss: 1.0825605392456055
Validation loss: 1.8437546337804487

Epoch: 216| Step: 0
Training loss: 1.944098949432373
Validation loss: 1.8531257067957232

Epoch: 6| Step: 1
Training loss: 1.8272995948791504
Validation loss: 1.871450452394383

Epoch: 6| Step: 2
Training loss: 1.221228837966919
Validation loss: 1.8777398832382695

Epoch: 6| Step: 3
Training loss: 1.2643687725067139
Validation loss: 1.8565333415103216

Epoch: 6| Step: 4
Training loss: 1.7943809032440186
Validation loss: 1.8403847473923878

Epoch: 6| Step: 5
Training loss: 2.446174144744873
Validation loss: 1.9003407621896395

Epoch: 6| Step: 6
Training loss: 1.2574549913406372
Validation loss: 1.8460087545456425

Epoch: 6| Step: 7
Training loss: 1.2790851593017578
Validation loss: 1.8503680203550605

Epoch: 6| Step: 8
Training loss: 1.9952430725097656
Validation loss: 1.8679643997582056

Epoch: 6| Step: 9
Training loss: 1.5398167371749878
Validation loss: 1.8292674197945544

Epoch: 6| Step: 10
Training loss: 1.867927074432373
Validation loss: 1.8327887417167745

Epoch: 6| Step: 11
Training loss: 1.1980489492416382
Validation loss: 1.8078190152363112

Epoch: 6| Step: 12
Training loss: 1.3357276916503906
Validation loss: 1.8382963634306384

Epoch: 6| Step: 13
Training loss: 1.9893430471420288
Validation loss: 1.8303820535700808

Epoch: 217| Step: 0
Training loss: 1.7832075357437134
Validation loss: 1.8286856092432493

Epoch: 6| Step: 1
Training loss: 2.7868385314941406
Validation loss: 1.839556473557667

Epoch: 6| Step: 2
Training loss: 1.6509252786636353
Validation loss: 1.837369430449701

Epoch: 6| Step: 3
Training loss: 1.0109922885894775
Validation loss: 1.8429432389556721

Epoch: 6| Step: 4
Training loss: 1.222975254058838
Validation loss: 1.8459429202541229

Epoch: 6| Step: 5
Training loss: 1.5727488994598389
Validation loss: 1.8866658774755334

Epoch: 6| Step: 6
Training loss: 1.850940465927124
Validation loss: 1.85327317894146

Epoch: 6| Step: 7
Training loss: 1.3786871433258057
Validation loss: 1.8536232799612067

Epoch: 6| Step: 8
Training loss: 1.929909110069275
Validation loss: 1.8596203198996923

Epoch: 6| Step: 9
Training loss: 1.2318730354309082
Validation loss: 1.8693681763064476

Epoch: 6| Step: 10
Training loss: 1.5650413036346436
Validation loss: 1.8831594105689757

Epoch: 6| Step: 11
Training loss: 1.9711267948150635
Validation loss: 1.8494624271187732

Epoch: 6| Step: 12
Training loss: 1.6844478845596313
Validation loss: 1.8737223853347122

Epoch: 6| Step: 13
Training loss: 1.2308180332183838
Validation loss: 1.885634042883432

Epoch: 218| Step: 0
Training loss: 1.1663846969604492
Validation loss: 1.8537560252733127

Epoch: 6| Step: 1
Training loss: 1.4785065650939941
Validation loss: 1.8421216651957522

Epoch: 6| Step: 2
Training loss: 2.7120771408081055
Validation loss: 1.8317616447325675

Epoch: 6| Step: 3
Training loss: 1.4878168106079102
Validation loss: 1.8293542246664725

Epoch: 6| Step: 4
Training loss: 1.4463410377502441
Validation loss: 1.8218880468799221

Epoch: 6| Step: 5
Training loss: 2.010556936264038
Validation loss: 1.8444900243513045

Epoch: 6| Step: 6
Training loss: 1.545100450515747
Validation loss: 1.8128781344300957

Epoch: 6| Step: 7
Training loss: 1.3243119716644287
Validation loss: 1.860142546315347

Epoch: 6| Step: 8
Training loss: 1.863357424736023
Validation loss: 1.7897070530922181

Epoch: 6| Step: 9
Training loss: 1.4228932857513428
Validation loss: 1.8403482693497852

Epoch: 6| Step: 10
Training loss: 1.6924808025360107
Validation loss: 1.8476958332523223

Epoch: 6| Step: 11
Training loss: 1.9033511877059937
Validation loss: 1.8359239588501632

Epoch: 6| Step: 12
Training loss: 1.4124987125396729
Validation loss: 1.8402311007181804

Epoch: 6| Step: 13
Training loss: 1.2358646392822266
Validation loss: 1.8847006649099372

Epoch: 219| Step: 0
Training loss: 1.8198786973953247
Validation loss: 1.8593020413511543

Epoch: 6| Step: 1
Training loss: 1.797658920288086
Validation loss: 1.8360229461423812

Epoch: 6| Step: 2
Training loss: 1.4776675701141357
Validation loss: 1.8469786220981228

Epoch: 6| Step: 3
Training loss: 1.7252707481384277
Validation loss: 1.855043818873744

Epoch: 6| Step: 4
Training loss: 1.0320980548858643
Validation loss: 1.8736737120536067

Epoch: 6| Step: 5
Training loss: 1.5429322719573975
Validation loss: 1.827860786068824

Epoch: 6| Step: 6
Training loss: 1.774979591369629
Validation loss: 1.8325143001412834

Epoch: 6| Step: 7
Training loss: 1.972784399986267
Validation loss: 1.8243529027508152

Epoch: 6| Step: 8
Training loss: 1.4951691627502441
Validation loss: 1.8436619722714989

Epoch: 6| Step: 9
Training loss: 1.6781854629516602
Validation loss: 1.8358257573138002

Epoch: 6| Step: 10
Training loss: 1.4979615211486816
Validation loss: 1.8209669538723525

Epoch: 6| Step: 11
Training loss: 1.712599277496338
Validation loss: 1.8596212364012195

Epoch: 6| Step: 12
Training loss: 1.6559879779815674
Validation loss: 1.807648257542682

Epoch: 6| Step: 13
Training loss: 1.5737595558166504
Validation loss: 1.8197298793382541

Epoch: 220| Step: 0
Training loss: 1.8392587900161743
Validation loss: 1.8418923180590394

Epoch: 6| Step: 1
Training loss: 1.5153179168701172
Validation loss: 1.7899311665565736

Epoch: 6| Step: 2
Training loss: 0.9467068314552307
Validation loss: 1.8592102912164503

Epoch: 6| Step: 3
Training loss: 1.173170566558838
Validation loss: 1.831383034747134

Epoch: 6| Step: 4
Training loss: 1.2697131633758545
Validation loss: 1.826929533353416

Epoch: 6| Step: 5
Training loss: 1.2703787088394165
Validation loss: 1.8501635751416605

Epoch: 6| Step: 6
Training loss: 1.5274280309677124
Validation loss: 1.8448480585569977

Epoch: 6| Step: 7
Training loss: 2.5601863861083984
Validation loss: 1.8516144598684003

Epoch: 6| Step: 8
Training loss: 1.8838093280792236
Validation loss: 1.8127256580578384

Epoch: 6| Step: 9
Training loss: 1.6672627925872803
Validation loss: 1.8233265402496501

Epoch: 6| Step: 10
Training loss: 1.5924345254898071
Validation loss: 1.842978016022713

Epoch: 6| Step: 11
Training loss: 2.1404755115509033
Validation loss: 1.9023822558823453

Epoch: 6| Step: 12
Training loss: 2.0269391536712646
Validation loss: 1.8494095904852754

Epoch: 6| Step: 13
Training loss: 0.9653341770172119
Validation loss: 1.8444339421487623

Epoch: 221| Step: 0
Training loss: 1.6921405792236328
Validation loss: 1.8592180411020915

Epoch: 6| Step: 1
Training loss: 1.8090095520019531
Validation loss: 1.846434857255669

Epoch: 6| Step: 2
Training loss: 0.9021978378295898
Validation loss: 1.8376897509380052

Epoch: 6| Step: 3
Training loss: 1.0063819885253906
Validation loss: 1.8432481891365462

Epoch: 6| Step: 4
Training loss: 1.2792141437530518
Validation loss: 1.8450784221772225

Epoch: 6| Step: 5
Training loss: 2.204000949859619
Validation loss: 1.8725173319539716

Epoch: 6| Step: 6
Training loss: 1.6155157089233398
Validation loss: 1.8678205244002803

Epoch: 6| Step: 7
Training loss: 1.2136309146881104
Validation loss: 1.8588090301841818

Epoch: 6| Step: 8
Training loss: 1.6299123764038086
Validation loss: 1.8218231354990313

Epoch: 6| Step: 9
Training loss: 1.837121844291687
Validation loss: 1.8386675734673776

Epoch: 6| Step: 10
Training loss: 1.9865307807922363
Validation loss: 1.8592178847200127

Epoch: 6| Step: 11
Training loss: 2.214463710784912
Validation loss: 1.8477388684467604

Epoch: 6| Step: 12
Training loss: 1.1622380018234253
Validation loss: 1.8217008549679992

Epoch: 6| Step: 13
Training loss: 2.5542306900024414
Validation loss: 1.8323838018601941

Epoch: 222| Step: 0
Training loss: 2.0472724437713623
Validation loss: 1.8481972935379192

Epoch: 6| Step: 1
Training loss: 1.3167787790298462
Validation loss: 1.8551234186336558

Epoch: 6| Step: 2
Training loss: 1.1978931427001953
Validation loss: 1.8483770893466087

Epoch: 6| Step: 3
Training loss: 1.3322858810424805
Validation loss: 1.8372453412702006

Epoch: 6| Step: 4
Training loss: 2.2222275733947754
Validation loss: 1.8246623469937233

Epoch: 6| Step: 5
Training loss: 1.780165433883667
Validation loss: 1.8334727594929356

Epoch: 6| Step: 6
Training loss: 2.2819020748138428
Validation loss: 1.8022839279584988

Epoch: 6| Step: 7
Training loss: 0.9643484950065613
Validation loss: 1.8767114326518068

Epoch: 6| Step: 8
Training loss: 1.8059991598129272
Validation loss: 1.8493734123886272

Epoch: 6| Step: 9
Training loss: 1.0675629377365112
Validation loss: 1.8021207445411271

Epoch: 6| Step: 10
Training loss: 1.6195008754730225
Validation loss: 1.8495587302792458

Epoch: 6| Step: 11
Training loss: 1.802675724029541
Validation loss: 1.8431472086137342

Epoch: 6| Step: 12
Training loss: 1.7075605392456055
Validation loss: 1.8445070405160227

Epoch: 6| Step: 13
Training loss: 1.0935851335525513
Validation loss: 1.8419672776294012

Epoch: 223| Step: 0
Training loss: 2.104020833969116
Validation loss: 1.8370388848807222

Epoch: 6| Step: 1
Training loss: 2.1032378673553467
Validation loss: 1.827751341686454

Epoch: 6| Step: 2
Training loss: 1.1766608953475952
Validation loss: 1.8496888709324661

Epoch: 6| Step: 3
Training loss: 1.7346749305725098
Validation loss: 1.817834911807891

Epoch: 6| Step: 4
Training loss: 1.109626293182373
Validation loss: 1.837066473499421

Epoch: 6| Step: 5
Training loss: 2.205577850341797
Validation loss: 1.8242868556771228

Epoch: 6| Step: 6
Training loss: 1.4816935062408447
Validation loss: 1.8557148261736798

Epoch: 6| Step: 7
Training loss: 1.094763159751892
Validation loss: 1.8645454222156155

Epoch: 6| Step: 8
Training loss: 1.10285222530365
Validation loss: 1.8320987263033468

Epoch: 6| Step: 9
Training loss: 0.7370461225509644
Validation loss: 1.8124227959622619

Epoch: 6| Step: 10
Training loss: 1.678654432296753
Validation loss: 1.8322362310142928

Epoch: 6| Step: 11
Training loss: 1.92214035987854
Validation loss: 1.8545066477150045

Epoch: 6| Step: 12
Training loss: 1.699049472808838
Validation loss: 1.8586655355268908

Epoch: 6| Step: 13
Training loss: 2.538421630859375
Validation loss: 1.8287250072725358

Epoch: 224| Step: 0
Training loss: 2.172119140625
Validation loss: 1.8501134328944708

Epoch: 6| Step: 1
Training loss: 2.266592264175415
Validation loss: 1.8594697790761148

Epoch: 6| Step: 2
Training loss: 1.3406867980957031
Validation loss: 1.8659963812879337

Epoch: 6| Step: 3
Training loss: 1.167901873588562
Validation loss: 1.8558285774723176

Epoch: 6| Step: 4
Training loss: 1.320570468902588
Validation loss: 1.8333441236967682

Epoch: 6| Step: 5
Training loss: 0.9269794225692749
Validation loss: 1.8319488084444435

Epoch: 6| Step: 6
Training loss: 1.5835905075073242
Validation loss: 1.8379633452302666

Epoch: 6| Step: 7
Training loss: 1.508398175239563
Validation loss: 1.8663950607340822

Epoch: 6| Step: 8
Training loss: 1.5776207447052002
Validation loss: 1.8391775866990447

Epoch: 6| Step: 9
Training loss: 1.4948406219482422
Validation loss: 1.8334235927110076

Epoch: 6| Step: 10
Training loss: 1.3740653991699219
Validation loss: 1.82497666728112

Epoch: 6| Step: 11
Training loss: 1.9014389514923096
Validation loss: 1.8418494206602856

Epoch: 6| Step: 12
Training loss: 1.8583964109420776
Validation loss: 1.8472562951426352

Epoch: 6| Step: 13
Training loss: 2.1937637329101562
Validation loss: 1.821992140944286

Epoch: 225| Step: 0
Training loss: 1.8429453372955322
Validation loss: 1.8422306276136828

Epoch: 6| Step: 1
Training loss: 1.3656361103057861
Validation loss: 1.8571994317475187

Epoch: 6| Step: 2
Training loss: 1.298638105392456
Validation loss: 1.8259901705608572

Epoch: 6| Step: 3
Training loss: 1.4210573434829712
Validation loss: 1.8462696472803752

Epoch: 6| Step: 4
Training loss: 1.1717562675476074
Validation loss: 1.7939369319587626

Epoch: 6| Step: 5
Training loss: 1.6863782405853271
Validation loss: 1.8424178515711138

Epoch: 6| Step: 6
Training loss: 1.2669131755828857
Validation loss: 1.8380442921833327

Epoch: 6| Step: 7
Training loss: 2.0752201080322266
Validation loss: 1.857430096595518

Epoch: 6| Step: 8
Training loss: 1.6089364290237427
Validation loss: 1.82923420142102

Epoch: 6| Step: 9
Training loss: 1.7813619375228882
Validation loss: 1.8585560501262706

Epoch: 6| Step: 10
Training loss: 1.1881574392318726
Validation loss: 1.848623796175885

Epoch: 6| Step: 11
Training loss: 2.53416109085083
Validation loss: 1.860075484039963

Epoch: 6| Step: 12
Training loss: 1.4411053657531738
Validation loss: 1.831215996896067

Epoch: 6| Step: 13
Training loss: 1.629457950592041
Validation loss: 1.864885252009156

Epoch: 226| Step: 0
Training loss: 1.406707763671875
Validation loss: 1.8477521993780648

Epoch: 6| Step: 1
Training loss: 2.102936267852783
Validation loss: 1.8681537425646217

Epoch: 6| Step: 2
Training loss: 1.7325599193572998
Validation loss: 1.8112801428764098

Epoch: 6| Step: 3
Training loss: 2.2396750450134277
Validation loss: 1.8656306946149437

Epoch: 6| Step: 4
Training loss: 0.5620886087417603
Validation loss: 1.8486405752038444

Epoch: 6| Step: 5
Training loss: 1.8183618783950806
Validation loss: 1.8622284627729846

Epoch: 6| Step: 6
Training loss: 1.5886651277542114
Validation loss: 1.855100667604836

Epoch: 6| Step: 7
Training loss: 1.0483983755111694
Validation loss: 1.867810050646464

Epoch: 6| Step: 8
Training loss: 1.7202551364898682
Validation loss: 1.8710603124351912

Epoch: 6| Step: 9
Training loss: 1.7126648426055908
Validation loss: 1.8158132132663523

Epoch: 6| Step: 10
Training loss: 1.1763122081756592
Validation loss: 1.8302655194395332

Epoch: 6| Step: 11
Training loss: 2.0123391151428223
Validation loss: 1.8582897942553285

Epoch: 6| Step: 12
Training loss: 1.5945706367492676
Validation loss: 1.8304572579681233

Epoch: 6| Step: 13
Training loss: 1.619546890258789
Validation loss: 1.8475780999788673

Epoch: 227| Step: 0
Training loss: 1.8004112243652344
Validation loss: 1.8101467445332518

Epoch: 6| Step: 1
Training loss: 1.4941880702972412
Validation loss: 1.8329835155958771

Epoch: 6| Step: 2
Training loss: 1.121108055114746
Validation loss: 1.848428713378086

Epoch: 6| Step: 3
Training loss: 1.2128263711929321
Validation loss: 1.8025838521219069

Epoch: 6| Step: 4
Training loss: 1.6036648750305176
Validation loss: 1.7980024109604538

Epoch: 6| Step: 5
Training loss: 2.2834455966949463
Validation loss: 1.8241214521469609

Epoch: 6| Step: 6
Training loss: 1.038718342781067
Validation loss: 1.8096669386791926

Epoch: 6| Step: 7
Training loss: 1.8549184799194336
Validation loss: 1.8541575439514653

Epoch: 6| Step: 8
Training loss: 1.1692473888397217
Validation loss: 1.8352405319931686

Epoch: 6| Step: 9
Training loss: 1.999324083328247
Validation loss: 1.87219318907748

Epoch: 6| Step: 10
Training loss: 2.0598411560058594
Validation loss: 1.851117512231232

Epoch: 6| Step: 11
Training loss: 1.3250070810317993
Validation loss: 1.823311823670582

Epoch: 6| Step: 12
Training loss: 1.5735585689544678
Validation loss: 1.8109420422584779

Epoch: 6| Step: 13
Training loss: 1.7275347709655762
Validation loss: 1.8303964702031945

Epoch: 228| Step: 0
Training loss: 1.35966956615448
Validation loss: 1.8171554098847091

Epoch: 6| Step: 1
Training loss: 1.8879106044769287
Validation loss: 1.7982270051074285

Epoch: 6| Step: 2
Training loss: 1.353666067123413
Validation loss: 1.8361365128588933

Epoch: 6| Step: 3
Training loss: 1.4353058338165283
Validation loss: 1.820739176965529

Epoch: 6| Step: 4
Training loss: 1.2451450824737549
Validation loss: 1.8472141091541578

Epoch: 6| Step: 5
Training loss: 1.3215043544769287
Validation loss: 1.8266488864857664

Epoch: 6| Step: 6
Training loss: 2.571254014968872
Validation loss: 1.844395778512442

Epoch: 6| Step: 7
Training loss: 1.2177817821502686
Validation loss: 1.8248783670445925

Epoch: 6| Step: 8
Training loss: 1.1162461042404175
Validation loss: 1.8216911669700377

Epoch: 6| Step: 9
Training loss: 1.8121527433395386
Validation loss: 1.8441408808513353

Epoch: 6| Step: 10
Training loss: 1.6837435960769653
Validation loss: 1.8375717920641745

Epoch: 6| Step: 11
Training loss: 2.133563995361328
Validation loss: 1.868739071712699

Epoch: 6| Step: 12
Training loss: 1.0198028087615967
Validation loss: 1.8340994452917447

Epoch: 6| Step: 13
Training loss: 2.306994915008545
Validation loss: 1.8712972979391775

Epoch: 229| Step: 0
Training loss: 1.3316712379455566
Validation loss: 1.851512332116404

Epoch: 6| Step: 1
Training loss: 2.0069267749786377
Validation loss: 1.8572695139915711

Epoch: 6| Step: 2
Training loss: 1.6848070621490479
Validation loss: 1.872000794256887

Epoch: 6| Step: 3
Training loss: 1.476477861404419
Validation loss: 1.8319577017138082

Epoch: 6| Step: 4
Training loss: 0.8702973127365112
Validation loss: 1.8240943877927718

Epoch: 6| Step: 5
Training loss: 1.5991758108139038
Validation loss: 1.8419493116358274

Epoch: 6| Step: 6
Training loss: 1.3008201122283936
Validation loss: 1.8064094064056233

Epoch: 6| Step: 7
Training loss: 1.245142936706543
Validation loss: 1.821146588171682

Epoch: 6| Step: 8
Training loss: 2.2475087642669678
Validation loss: 1.8196814752394153

Epoch: 6| Step: 9
Training loss: 1.828640103340149
Validation loss: 1.8247012451130857

Epoch: 6| Step: 10
Training loss: 1.7545804977416992
Validation loss: 1.7856465578079224

Epoch: 6| Step: 11
Training loss: 1.4603297710418701
Validation loss: 1.825500645945149

Epoch: 6| Step: 12
Training loss: 1.9852185249328613
Validation loss: 1.8243321859708397

Epoch: 6| Step: 13
Training loss: 1.664618968963623
Validation loss: 1.827180403535084

Epoch: 230| Step: 0
Training loss: 1.1776717901229858
Validation loss: 1.8590358021438762

Epoch: 6| Step: 1
Training loss: 1.3788111209869385
Validation loss: 1.8275938136603243

Epoch: 6| Step: 2
Training loss: 1.3889265060424805
Validation loss: 1.836650389496998

Epoch: 6| Step: 3
Training loss: 1.5745282173156738
Validation loss: 1.8741196881058395

Epoch: 6| Step: 4
Training loss: 1.581465244293213
Validation loss: 1.8481279444950882

Epoch: 6| Step: 5
Training loss: 1.6776214838027954
Validation loss: 1.8187827576873123

Epoch: 6| Step: 6
Training loss: 1.7824310064315796
Validation loss: 1.8807529749408844

Epoch: 6| Step: 7
Training loss: 1.0099151134490967
Validation loss: 1.8643200807673956

Epoch: 6| Step: 8
Training loss: 1.4361578226089478
Validation loss: 1.8680460863215949

Epoch: 6| Step: 9
Training loss: 1.6357800960540771
Validation loss: 1.8391892243457097

Epoch: 6| Step: 10
Training loss: 1.8036471605300903
Validation loss: 1.8449859747322657

Epoch: 6| Step: 11
Training loss: 1.750920295715332
Validation loss: 1.8406159531685613

Epoch: 6| Step: 12
Training loss: 2.2012901306152344
Validation loss: 1.8510601097537625

Epoch: 6| Step: 13
Training loss: 1.6689093112945557
Validation loss: 1.827861205224068

Epoch: 231| Step: 0
Training loss: 1.9173109531402588
Validation loss: 1.8147824477123957

Epoch: 6| Step: 1
Training loss: 1.1573314666748047
Validation loss: 1.8508076616512832

Epoch: 6| Step: 2
Training loss: 1.2977951765060425
Validation loss: 1.815857534767479

Epoch: 6| Step: 3
Training loss: 1.7868388891220093
Validation loss: 1.870422194080968

Epoch: 6| Step: 4
Training loss: 1.7688074111938477
Validation loss: 1.8449074068377096

Epoch: 6| Step: 5
Training loss: 1.5808829069137573
Validation loss: 1.807203269773914

Epoch: 6| Step: 6
Training loss: 1.5091800689697266
Validation loss: 1.8536377773490003

Epoch: 6| Step: 7
Training loss: 1.8313350677490234
Validation loss: 1.869788723607217

Epoch: 6| Step: 8
Training loss: 1.609330177307129
Validation loss: 1.8209587015131468

Epoch: 6| Step: 9
Training loss: 1.5883681774139404
Validation loss: 1.8461452171366701

Epoch: 6| Step: 10
Training loss: 1.1280584335327148
Validation loss: 1.8190652721671647

Epoch: 6| Step: 11
Training loss: 1.9157655239105225
Validation loss: 1.8254659470691477

Epoch: 6| Step: 12
Training loss: 1.6558983325958252
Validation loss: 1.82274640247386

Epoch: 6| Step: 13
Training loss: 1.6319650411605835
Validation loss: 1.8174563620680122

Epoch: 232| Step: 0
Training loss: 1.5506726503372192
Validation loss: 1.8112814016239618

Epoch: 6| Step: 1
Training loss: 1.3863818645477295
Validation loss: 1.8290587881559968

Epoch: 6| Step: 2
Training loss: 0.7521716356277466
Validation loss: 1.8461273690705657

Epoch: 6| Step: 3
Training loss: 1.6121799945831299
Validation loss: 1.8698905052677277

Epoch: 6| Step: 4
Training loss: 1.7613568305969238
Validation loss: 1.8165166993294992

Epoch: 6| Step: 5
Training loss: 1.7725193500518799
Validation loss: 1.8556822333284604

Epoch: 6| Step: 6
Training loss: 1.898043155670166
Validation loss: 1.8769355820071312

Epoch: 6| Step: 7
Training loss: 1.2010953426361084
Validation loss: 1.8541490724009853

Epoch: 6| Step: 8
Training loss: 2.0562586784362793
Validation loss: 1.84947108837866

Epoch: 6| Step: 9
Training loss: 2.2176291942596436
Validation loss: 1.8474490796366045

Epoch: 6| Step: 10
Training loss: 1.7522125244140625
Validation loss: 1.890948478893567

Epoch: 6| Step: 11
Training loss: 1.365849494934082
Validation loss: 1.8445011236334359

Epoch: 6| Step: 12
Training loss: 1.27601957321167
Validation loss: 1.8538580081796134

Epoch: 6| Step: 13
Training loss: 2.198925256729126
Validation loss: 1.8462466014328824

Epoch: 233| Step: 0
Training loss: 0.9742085933685303
Validation loss: 1.845276519816409

Epoch: 6| Step: 1
Training loss: 1.3149545192718506
Validation loss: 1.8126381417756439

Epoch: 6| Step: 2
Training loss: 1.7996938228607178
Validation loss: 1.8297567213735273

Epoch: 6| Step: 3
Training loss: 1.1793676614761353
Validation loss: 1.8237871162353023

Epoch: 6| Step: 4
Training loss: 1.2537299394607544
Validation loss: 1.8580690481329476

Epoch: 6| Step: 5
Training loss: 1.714270830154419
Validation loss: 1.8442722482066

Epoch: 6| Step: 6
Training loss: 1.4494379758834839
Validation loss: 1.8421927370050901

Epoch: 6| Step: 7
Training loss: 1.8998934030532837
Validation loss: 1.8287230717238558

Epoch: 6| Step: 8
Training loss: 1.541530966758728
Validation loss: 1.8691421144752092

Epoch: 6| Step: 9
Training loss: 1.7385823726654053
Validation loss: 1.8386078073132424

Epoch: 6| Step: 10
Training loss: 2.1821179389953613
Validation loss: 1.8871832765558714

Epoch: 6| Step: 11
Training loss: 1.5643054246902466
Validation loss: 1.831769730455132

Epoch: 6| Step: 12
Training loss: 1.4908642768859863
Validation loss: 1.8998371478049987

Epoch: 6| Step: 13
Training loss: 1.9986509084701538
Validation loss: 1.8415493349875174

Epoch: 234| Step: 0
Training loss: 1.0144100189208984
Validation loss: 1.862870644497615

Epoch: 6| Step: 1
Training loss: 1.75407075881958
Validation loss: 1.8706855632925545

Epoch: 6| Step: 2
Training loss: 1.499545693397522
Validation loss: 1.8601156819251277

Epoch: 6| Step: 3
Training loss: 1.760101318359375
Validation loss: 1.8381865780840638

Epoch: 6| Step: 4
Training loss: 1.2120603322982788
Validation loss: 1.833028381870639

Epoch: 6| Step: 5
Training loss: 1.9255343675613403
Validation loss: 1.830982913253128

Epoch: 6| Step: 6
Training loss: 1.5723018646240234
Validation loss: 1.8396643554010699

Epoch: 6| Step: 7
Training loss: 2.2399392127990723
Validation loss: 1.8268777362761959

Epoch: 6| Step: 8
Training loss: 1.7431228160858154
Validation loss: 1.83739532450194

Epoch: 6| Step: 9
Training loss: 1.5509213209152222
Validation loss: 1.8096999981070077

Epoch: 6| Step: 10
Training loss: 1.2204171419143677
Validation loss: 1.827478918977963

Epoch: 6| Step: 11
Training loss: 2.1575100421905518
Validation loss: 1.8232907941264491

Epoch: 6| Step: 12
Training loss: 0.8930269479751587
Validation loss: 1.8203169748347292

Epoch: 6| Step: 13
Training loss: 1.0800318717956543
Validation loss: 1.8250552287665747

Epoch: 235| Step: 0
Training loss: 1.8058812618255615
Validation loss: 1.799055262278485

Epoch: 6| Step: 1
Training loss: 1.7497203350067139
Validation loss: 1.8612244590636222

Epoch: 6| Step: 2
Training loss: 1.0804228782653809
Validation loss: 1.840087180496544

Epoch: 6| Step: 3
Training loss: 1.5440800189971924
Validation loss: 1.8351320502578572

Epoch: 6| Step: 4
Training loss: 1.6538872718811035
Validation loss: 1.840425996370213

Epoch: 6| Step: 5
Training loss: 1.3957669734954834
Validation loss: 1.874913046436925

Epoch: 6| Step: 6
Training loss: 1.444061040878296
Validation loss: 1.822510819281301

Epoch: 6| Step: 7
Training loss: 1.7393767833709717
Validation loss: 1.8344358346795524

Epoch: 6| Step: 8
Training loss: 1.7998926639556885
Validation loss: 1.8740227042987783

Epoch: 6| Step: 9
Training loss: 1.551098346710205
Validation loss: 1.8493768861216884

Epoch: 6| Step: 10
Training loss: 1.8062264919281006
Validation loss: 1.846864664426414

Epoch: 6| Step: 11
Training loss: 1.7230224609375
Validation loss: 1.8523214222282491

Epoch: 6| Step: 12
Training loss: 1.3636047840118408
Validation loss: 1.8385431035872428

Epoch: 6| Step: 13
Training loss: 1.0992026329040527
Validation loss: 1.8525457702657229

Epoch: 236| Step: 0
Training loss: 1.1319987773895264
Validation loss: 1.8344398365225842

Epoch: 6| Step: 1
Training loss: 1.7820086479187012
Validation loss: 1.8315596913778653

Epoch: 6| Step: 2
Training loss: 1.0888545513153076
Validation loss: 1.8185008918085406

Epoch: 6| Step: 3
Training loss: 2.028294086456299
Validation loss: 1.8375787222257225

Epoch: 6| Step: 4
Training loss: 1.0595202445983887
Validation loss: 1.8405795328078731

Epoch: 6| Step: 5
Training loss: 1.7197799682617188
Validation loss: 1.8365960082700175

Epoch: 6| Step: 6
Training loss: 1.3911759853363037
Validation loss: 1.841094611793436

Epoch: 6| Step: 7
Training loss: 1.3180341720581055
Validation loss: 1.8366352140262563

Epoch: 6| Step: 8
Training loss: 2.069321393966675
Validation loss: 1.835888312708947

Epoch: 6| Step: 9
Training loss: 1.4333022832870483
Validation loss: 1.826997628775976

Epoch: 6| Step: 10
Training loss: 1.3352328538894653
Validation loss: 1.8585237354360602

Epoch: 6| Step: 11
Training loss: 1.9176723957061768
Validation loss: 1.8290228638597714

Epoch: 6| Step: 12
Training loss: 2.679020881652832
Validation loss: 1.818645264512749

Epoch: 6| Step: 13
Training loss: 0.7290616035461426
Validation loss: 1.827577810133657

Epoch: 237| Step: 0
Training loss: 1.6768403053283691
Validation loss: 1.852399008248442

Epoch: 6| Step: 1
Training loss: 0.903808057308197
Validation loss: 1.8399643385282127

Epoch: 6| Step: 2
Training loss: 1.3332107067108154
Validation loss: 1.8315125639720629

Epoch: 6| Step: 3
Training loss: 1.1726518869400024
Validation loss: 1.7937199966881865

Epoch: 6| Step: 4
Training loss: 1.618660807609558
Validation loss: 1.8021667016449796

Epoch: 6| Step: 5
Training loss: 0.8606268763542175
Validation loss: 1.8254486976131317

Epoch: 6| Step: 6
Training loss: 1.8585150241851807
Validation loss: 1.8313002419728104

Epoch: 6| Step: 7
Training loss: 1.3326237201690674
Validation loss: 1.8429921980827086

Epoch: 6| Step: 8
Training loss: 2.0190072059631348
Validation loss: 1.8083307614890478

Epoch: 6| Step: 9
Training loss: 1.5673394203186035
Validation loss: 1.8325553914552093

Epoch: 6| Step: 10
Training loss: 1.6208407878875732
Validation loss: 1.8279365877951346

Epoch: 6| Step: 11
Training loss: 1.9542936086654663
Validation loss: 1.8184143817552956

Epoch: 6| Step: 12
Training loss: 2.0640475749969482
Validation loss: 1.8251547121232556

Epoch: 6| Step: 13
Training loss: 2.670125722885132
Validation loss: 1.8571281304923437

Epoch: 238| Step: 0
Training loss: 1.069218635559082
Validation loss: 1.8443609950362996

Epoch: 6| Step: 1
Training loss: 1.620976209640503
Validation loss: 1.8173463280482958

Epoch: 6| Step: 2
Training loss: 1.8724515438079834
Validation loss: 1.8200224766167261

Epoch: 6| Step: 3
Training loss: 1.4478230476379395
Validation loss: 1.8372121087966427

Epoch: 6| Step: 4
Training loss: 1.496042251586914
Validation loss: 1.8296630023628153

Epoch: 6| Step: 5
Training loss: 2.099175453186035
Validation loss: 1.8303928349607734

Epoch: 6| Step: 6
Training loss: 1.2789617776870728
Validation loss: 1.8921852560453518

Epoch: 6| Step: 7
Training loss: 1.7429523468017578
Validation loss: 1.86154846478534

Epoch: 6| Step: 8
Training loss: 2.269536256790161
Validation loss: 1.8505028140160344

Epoch: 6| Step: 9
Training loss: 1.0913653373718262
Validation loss: 1.829059382920624

Epoch: 6| Step: 10
Training loss: 1.7841434478759766
Validation loss: 1.8264934785904423

Epoch: 6| Step: 11
Training loss: 1.4167754650115967
Validation loss: 1.8569690745363954

Epoch: 6| Step: 12
Training loss: 1.2939517498016357
Validation loss: 1.8292649868995912

Epoch: 6| Step: 13
Training loss: 1.5781784057617188
Validation loss: 1.8492179916751

Epoch: 239| Step: 0
Training loss: 1.531455397605896
Validation loss: 1.8304375717716832

Epoch: 6| Step: 1
Training loss: 1.1819263696670532
Validation loss: 1.8202949659798735

Epoch: 6| Step: 2
Training loss: 2.0297670364379883
Validation loss: 1.7984158838948896

Epoch: 6| Step: 3
Training loss: 1.6758713722229004
Validation loss: 1.835222928754745

Epoch: 6| Step: 4
Training loss: 1.2155736684799194
Validation loss: 1.8104698786171534

Epoch: 6| Step: 5
Training loss: 2.0641837120056152
Validation loss: 1.830105512372909

Epoch: 6| Step: 6
Training loss: 1.9089453220367432
Validation loss: 1.8424178528529342

Epoch: 6| Step: 7
Training loss: 1.0691527128219604
Validation loss: 1.8351709406862977

Epoch: 6| Step: 8
Training loss: 1.4423282146453857
Validation loss: 1.7966289097262966

Epoch: 6| Step: 9
Training loss: 1.4403831958770752
Validation loss: 1.8198253467518797

Epoch: 6| Step: 10
Training loss: 1.5285468101501465
Validation loss: 1.8231643963885564

Epoch: 6| Step: 11
Training loss: 1.2983640432357788
Validation loss: 1.8399694965731712

Epoch: 6| Step: 12
Training loss: 1.9997889995574951
Validation loss: 1.83010616097399

Epoch: 6| Step: 13
Training loss: 1.9886419773101807
Validation loss: 1.8522213607706048

Epoch: 240| Step: 0
Training loss: 1.2775280475616455
Validation loss: 1.8426196036800262

Epoch: 6| Step: 1
Training loss: 1.2591586112976074
Validation loss: 1.8167876863992343

Epoch: 6| Step: 2
Training loss: 1.3400672674179077
Validation loss: 1.8255128681018788

Epoch: 6| Step: 3
Training loss: 1.474670171737671
Validation loss: 1.836948223011468

Epoch: 6| Step: 4
Training loss: 1.9026336669921875
Validation loss: 1.823321723168896

Epoch: 6| Step: 5
Training loss: 1.4735209941864014
Validation loss: 1.8579375359319872

Epoch: 6| Step: 6
Training loss: 1.5989259481430054
Validation loss: 1.8204304543874597

Epoch: 6| Step: 7
Training loss: 1.3330336809158325
Validation loss: 1.826615325866207

Epoch: 6| Step: 8
Training loss: 2.1308116912841797
Validation loss: 1.8294183208096413

Epoch: 6| Step: 9
Training loss: 2.118131160736084
Validation loss: 1.8358226476177093

Epoch: 6| Step: 10
Training loss: 1.5409897565841675
Validation loss: 1.8372938850874543

Epoch: 6| Step: 11
Training loss: 1.4570457935333252
Validation loss: 1.8373372042050926

Epoch: 6| Step: 12
Training loss: 1.4724863767623901
Validation loss: 1.803076050614798

Epoch: 6| Step: 13
Training loss: 1.0701375007629395
Validation loss: 1.8287263813839163

Epoch: 241| Step: 0
Training loss: 1.4343432188034058
Validation loss: 1.8584866459651659

Epoch: 6| Step: 1
Training loss: 1.522397756576538
Validation loss: 1.823801076540383

Epoch: 6| Step: 2
Training loss: 1.3995447158813477
Validation loss: 1.786418850703906

Epoch: 6| Step: 3
Training loss: 1.4299925565719604
Validation loss: 1.8252283680823542

Epoch: 6| Step: 4
Training loss: 1.0393800735473633
Validation loss: 1.8378203735556653

Epoch: 6| Step: 5
Training loss: 1.5825893878936768
Validation loss: 1.8416945383112917

Epoch: 6| Step: 6
Training loss: 1.4673973321914673
Validation loss: 1.817124750024529

Epoch: 6| Step: 7
Training loss: 2.2069931030273438
Validation loss: 1.8251434115953342

Epoch: 6| Step: 8
Training loss: 1.4086003303527832
Validation loss: 1.8266459703445435

Epoch: 6| Step: 9
Training loss: 1.5458369255065918
Validation loss: 1.8012136220932007

Epoch: 6| Step: 10
Training loss: 2.129927635192871
Validation loss: 1.8466890973429526

Epoch: 6| Step: 11
Training loss: 1.7923073768615723
Validation loss: 1.82575213268239

Epoch: 6| Step: 12
Training loss: 1.2579398155212402
Validation loss: 1.811153765647642

Epoch: 6| Step: 13
Training loss: 1.6468819379806519
Validation loss: 1.8213834698482225

Epoch: 242| Step: 0
Training loss: 1.1280779838562012
Validation loss: 1.804550358044204

Epoch: 6| Step: 1
Training loss: 0.9536936283111572
Validation loss: 1.8555078609015352

Epoch: 6| Step: 2
Training loss: 1.1073092222213745
Validation loss: 1.835432364094642

Epoch: 6| Step: 3
Training loss: 1.118443250656128
Validation loss: 1.8180696156717115

Epoch: 6| Step: 4
Training loss: 2.333190679550171
Validation loss: 1.8526706464828984

Epoch: 6| Step: 5
Training loss: 1.5325578451156616
Validation loss: 1.8157625147091445

Epoch: 6| Step: 6
Training loss: 1.7568843364715576
Validation loss: 1.841038780827676

Epoch: 6| Step: 7
Training loss: 2.1814329624176025
Validation loss: 1.8114093593371812

Epoch: 6| Step: 8
Training loss: 1.3077524900436401
Validation loss: 1.8185367584228516

Epoch: 6| Step: 9
Training loss: 1.5620455741882324
Validation loss: 1.8475883481323079

Epoch: 6| Step: 10
Training loss: 1.6874089241027832
Validation loss: 1.8490814701203377

Epoch: 6| Step: 11
Training loss: 2.2099311351776123
Validation loss: 1.792084640072238

Epoch: 6| Step: 12
Training loss: 1.3021230697631836
Validation loss: 1.8350204998447048

Epoch: 6| Step: 13
Training loss: 1.501870036125183
Validation loss: 1.8509468493923065

Epoch: 243| Step: 0
Training loss: 1.1479971408843994
Validation loss: 1.8164758630978164

Epoch: 6| Step: 1
Training loss: 1.2716548442840576
Validation loss: 1.8449224092627083

Epoch: 6| Step: 2
Training loss: 1.8749791383743286
Validation loss: 1.8562593716447071

Epoch: 6| Step: 3
Training loss: 1.130405306816101
Validation loss: 1.7991105548797115

Epoch: 6| Step: 4
Training loss: 1.6394448280334473
Validation loss: 1.809123089236598

Epoch: 6| Step: 5
Training loss: 1.6867847442626953
Validation loss: 1.8358519974575247

Epoch: 6| Step: 6
Training loss: 0.9489840865135193
Validation loss: 1.8221532734491492

Epoch: 6| Step: 7
Training loss: 1.742034673690796
Validation loss: 1.8470952382651709

Epoch: 6| Step: 8
Training loss: 1.2595888376235962
Validation loss: 1.8107941919757473

Epoch: 6| Step: 9
Training loss: 1.468597173690796
Validation loss: 1.808181801149922

Epoch: 6| Step: 10
Training loss: 1.7593106031417847
Validation loss: 1.8211924927209013

Epoch: 6| Step: 11
Training loss: 2.2277560234069824
Validation loss: 1.8405652738386584

Epoch: 6| Step: 12
Training loss: 1.6173231601715088
Validation loss: 1.8139885164076281

Epoch: 6| Step: 13
Training loss: 2.2907450199127197
Validation loss: 1.8549224522805983

Epoch: 244| Step: 0
Training loss: 1.1701278686523438
Validation loss: 1.86767497498502

Epoch: 6| Step: 1
Training loss: 1.7854783535003662
Validation loss: 1.8813485099423317

Epoch: 6| Step: 2
Training loss: 1.8351116180419922
Validation loss: 1.888577611215653

Epoch: 6| Step: 3
Training loss: 1.3479132652282715
Validation loss: 1.8795968896599227

Epoch: 6| Step: 4
Training loss: 1.8860278129577637
Validation loss: 1.9019250408295663

Epoch: 6| Step: 5
Training loss: 1.907821774482727
Validation loss: 1.881266438832847

Epoch: 6| Step: 6
Training loss: 1.5665528774261475
Validation loss: 1.8593035538991292

Epoch: 6| Step: 7
Training loss: 1.30753493309021
Validation loss: 1.8567901708746468

Epoch: 6| Step: 8
Training loss: 1.427248477935791
Validation loss: 1.8717693051984232

Epoch: 6| Step: 9
Training loss: 1.2780325412750244
Validation loss: 1.833662994446293

Epoch: 6| Step: 10
Training loss: 1.6366651058197021
Validation loss: 1.8427374465491182

Epoch: 6| Step: 11
Training loss: 1.6833873987197876
Validation loss: 1.8031733112950479

Epoch: 6| Step: 12
Training loss: 1.2634732723236084
Validation loss: 1.816369592502553

Epoch: 6| Step: 13
Training loss: 1.34902024269104
Validation loss: 1.8384242467982794

Epoch: 245| Step: 0
Training loss: 1.6790837049484253
Validation loss: 1.8116474875839808

Epoch: 6| Step: 1
Training loss: 1.4496779441833496
Validation loss: 1.839899948848191

Epoch: 6| Step: 2
Training loss: 1.6202478408813477
Validation loss: 1.8268265070453766

Epoch: 6| Step: 3
Training loss: 2.046055793762207
Validation loss: 1.8170628163122362

Epoch: 6| Step: 4
Training loss: 1.5871862173080444
Validation loss: 1.8057484601133613

Epoch: 6| Step: 5
Training loss: 1.546279788017273
Validation loss: 1.8315283021619242

Epoch: 6| Step: 6
Training loss: 0.9253736138343811
Validation loss: 1.8426781456957582

Epoch: 6| Step: 7
Training loss: 1.3766281604766846
Validation loss: 1.8229408302614767

Epoch: 6| Step: 8
Training loss: 2.432340145111084
Validation loss: 1.8248008040971653

Epoch: 6| Step: 9
Training loss: 1.8069480657577515
Validation loss: 1.8299285660507858

Epoch: 6| Step: 10
Training loss: 1.769297480583191
Validation loss: 1.808542287477883

Epoch: 6| Step: 11
Training loss: 1.1625562906265259
Validation loss: 1.8302934131314677

Epoch: 6| Step: 12
Training loss: 0.9258742332458496
Validation loss: 1.8182570626658778

Epoch: 6| Step: 13
Training loss: 1.2965283393859863
Validation loss: 1.8055098274702668

Epoch: 246| Step: 0
Training loss: 1.60822331905365
Validation loss: 1.8134967998791767

Epoch: 6| Step: 1
Training loss: 1.5503666400909424
Validation loss: 1.802270802118445

Epoch: 6| Step: 2
Training loss: 1.7389922142028809
Validation loss: 1.799534313140377

Epoch: 6| Step: 3
Training loss: 1.237182378768921
Validation loss: 1.8193882793508551

Epoch: 6| Step: 4
Training loss: 1.8517409563064575
Validation loss: 1.7885777219649284

Epoch: 6| Step: 5
Training loss: 1.1442159414291382
Validation loss: 1.8348197308919763

Epoch: 6| Step: 6
Training loss: 1.8142707347869873
Validation loss: 1.8100492697890087

Epoch: 6| Step: 7
Training loss: 1.6855162382125854
Validation loss: 1.8059981548657982

Epoch: 6| Step: 8
Training loss: 1.5251579284667969
Validation loss: 1.8222830308380948

Epoch: 6| Step: 9
Training loss: 1.2949930429458618
Validation loss: 1.8117246909808087

Epoch: 6| Step: 10
Training loss: 1.1659948825836182
Validation loss: 1.8154880795427548

Epoch: 6| Step: 11
Training loss: 1.8140393495559692
Validation loss: 1.8487183791334911

Epoch: 6| Step: 12
Training loss: 1.2027013301849365
Validation loss: 1.8119440822191135

Epoch: 6| Step: 13
Training loss: 2.2632901668548584
Validation loss: 1.8412611433254775

Epoch: 247| Step: 0
Training loss: 1.1976597309112549
Validation loss: 1.807780570881341

Epoch: 6| Step: 1
Training loss: 2.130296468734741
Validation loss: 1.7654748680771037

Epoch: 6| Step: 2
Training loss: 1.6541223526000977
Validation loss: 1.8362729946772258

Epoch: 6| Step: 3
Training loss: 2.1234655380249023
Validation loss: 1.8553271678186232

Epoch: 6| Step: 4
Training loss: 1.2513508796691895
Validation loss: 1.8335054382201164

Epoch: 6| Step: 5
Training loss: 1.6895490884780884
Validation loss: 1.796264148527576

Epoch: 6| Step: 6
Training loss: 1.333998680114746
Validation loss: 1.7931011774206673

Epoch: 6| Step: 7
Training loss: 1.448735237121582
Validation loss: 1.8095457630772744

Epoch: 6| Step: 8
Training loss: 1.292711615562439
Validation loss: 1.816931854012192

Epoch: 6| Step: 9
Training loss: 1.3868768215179443
Validation loss: 1.8294759540147678

Epoch: 6| Step: 10
Training loss: 1.1621983051300049
Validation loss: 1.8023107667123117

Epoch: 6| Step: 11
Training loss: 1.5967466831207275
Validation loss: 1.84268585840861

Epoch: 6| Step: 12
Training loss: 1.0817407369613647
Validation loss: 1.8081497735874628

Epoch: 6| Step: 13
Training loss: 2.442023754119873
Validation loss: 1.8255839379884864

Epoch: 248| Step: 0
Training loss: 2.6577224731445312
Validation loss: 1.8236376495771511

Epoch: 6| Step: 1
Training loss: 1.2103359699249268
Validation loss: 1.8580021960760957

Epoch: 6| Step: 2
Training loss: 1.70121431350708
Validation loss: 1.8074002804294709

Epoch: 6| Step: 3
Training loss: 1.798353910446167
Validation loss: 1.8198880303290583

Epoch: 6| Step: 4
Training loss: 1.244472622871399
Validation loss: 1.8072179850711618

Epoch: 6| Step: 5
Training loss: 1.7731521129608154
Validation loss: 1.8339327983958746

Epoch: 6| Step: 6
Training loss: 1.1374170780181885
Validation loss: 1.844740544596026

Epoch: 6| Step: 7
Training loss: 0.7395292520523071
Validation loss: 1.8225500634921494

Epoch: 6| Step: 8
Training loss: 1.5207892656326294
Validation loss: 1.845897251559842

Epoch: 6| Step: 9
Training loss: 1.4890172481536865
Validation loss: 1.8151416624746015

Epoch: 6| Step: 10
Training loss: 1.6157820224761963
Validation loss: 1.8273844642023886

Epoch: 6| Step: 11
Training loss: 1.364084005355835
Validation loss: 1.8051368562124108

Epoch: 6| Step: 12
Training loss: 2.0206704139709473
Validation loss: 1.8067392021097162

Epoch: 6| Step: 13
Training loss: 0.5550877451896667
Validation loss: 1.828903176451242

Epoch: 249| Step: 0
Training loss: 2.0677433013916016
Validation loss: 1.8286913774346794

Epoch: 6| Step: 1
Training loss: 1.8977587223052979
Validation loss: 1.8091535863055979

Epoch: 6| Step: 2
Training loss: 1.0388044118881226
Validation loss: 1.8347893107321955

Epoch: 6| Step: 3
Training loss: 1.19520103931427
Validation loss: 1.82676181485576

Epoch: 6| Step: 4
Training loss: 0.596088171005249
Validation loss: 1.8325807689338602

Epoch: 6| Step: 5
Training loss: 1.5419378280639648
Validation loss: 1.796177589765159

Epoch: 6| Step: 6
Training loss: 1.7377320528030396
Validation loss: 1.8268057864199403

Epoch: 6| Step: 7
Training loss: 1.075278878211975
Validation loss: 1.8537866351425007

Epoch: 6| Step: 8
Training loss: 1.4677321910858154
Validation loss: 1.8009115162716116

Epoch: 6| Step: 9
Training loss: 2.0048210620880127
Validation loss: 1.8494376238956247

Epoch: 6| Step: 10
Training loss: 1.81745183467865
Validation loss: 1.837579995073298

Epoch: 6| Step: 11
Training loss: 1.638778567314148
Validation loss: 1.8343675072475145

Epoch: 6| Step: 12
Training loss: 1.58152437210083
Validation loss: 1.8458783447101552

Epoch: 6| Step: 13
Training loss: 2.000262975692749
Validation loss: 1.8575145108725435

Epoch: 250| Step: 0
Training loss: 1.4618442058563232
Validation loss: 1.8585294164637083

Epoch: 6| Step: 1
Training loss: 2.1479575634002686
Validation loss: 1.8720448850303568

Epoch: 6| Step: 2
Training loss: 1.7373863458633423
Validation loss: 1.829522108518949

Epoch: 6| Step: 3
Training loss: 1.699986219406128
Validation loss: 1.826973074225969

Epoch: 6| Step: 4
Training loss: 1.5337597131729126
Validation loss: 1.8128295329309279

Epoch: 6| Step: 5
Training loss: 1.0427414178848267
Validation loss: 1.8070297587302424

Epoch: 6| Step: 6
Training loss: 1.220876693725586
Validation loss: 1.7924276295528616

Epoch: 6| Step: 7
Training loss: 1.1682010889053345
Validation loss: 1.7960290870358866

Epoch: 6| Step: 8
Training loss: 2.2824277877807617
Validation loss: 1.8260271677406885

Epoch: 6| Step: 9
Training loss: 1.8668410778045654
Validation loss: 1.8416483812434699

Epoch: 6| Step: 10
Training loss: 1.1210216283798218
Validation loss: 1.8210332932010773

Epoch: 6| Step: 11
Training loss: 1.8878262042999268
Validation loss: 1.8582874151968187

Epoch: 6| Step: 12
Training loss: 1.4810552597045898
Validation loss: 1.8277516864961194

Epoch: 6| Step: 13
Training loss: 0.8193268179893494
Validation loss: 1.796781555298836

Epoch: 251| Step: 0
Training loss: 1.6481132507324219
Validation loss: 1.8289010678568194

Epoch: 6| Step: 1
Training loss: 1.300095796585083
Validation loss: 1.7662565977342668

Epoch: 6| Step: 2
Training loss: 1.9619728326797485
Validation loss: 1.8357886024700698

Epoch: 6| Step: 3
Training loss: 1.4341285228729248
Validation loss: 1.8501696484063261

Epoch: 6| Step: 4
Training loss: 1.88486647605896
Validation loss: 1.8057332243970645

Epoch: 6| Step: 5
Training loss: 0.9907700419425964
Validation loss: 1.8158665895462036

Epoch: 6| Step: 6
Training loss: 1.3769428730010986
Validation loss: 1.8395976943354453

Epoch: 6| Step: 7
Training loss: 1.4487996101379395
Validation loss: 1.831486512255925

Epoch: 6| Step: 8
Training loss: 1.548532485961914
Validation loss: 1.8297389604712044

Epoch: 6| Step: 9
Training loss: 1.6273223161697388
Validation loss: 1.8357122739156086

Epoch: 6| Step: 10
Training loss: 1.9966479539871216
Validation loss: 1.8080269559737174

Epoch: 6| Step: 11
Training loss: 1.5240724086761475
Validation loss: 1.848877561989651

Epoch: 6| Step: 12
Training loss: 1.5025521516799927
Validation loss: 1.8591146879298712

Epoch: 6| Step: 13
Training loss: 0.882285475730896
Validation loss: 1.8614777441947692

Epoch: 252| Step: 0
Training loss: 1.6009596586227417
Validation loss: 1.8569269757116995

Epoch: 6| Step: 1
Training loss: 1.2784479856491089
Validation loss: 1.816448418042993

Epoch: 6| Step: 2
Training loss: 0.9315494298934937
Validation loss: 1.8646071598093996

Epoch: 6| Step: 3
Training loss: 2.1173853874206543
Validation loss: 1.797164273518388

Epoch: 6| Step: 4
Training loss: 1.0574300289154053
Validation loss: 1.8007325741552538

Epoch: 6| Step: 5
Training loss: 1.6252083778381348
Validation loss: 1.855438555440595

Epoch: 6| Step: 6
Training loss: 0.9487409591674805
Validation loss: 1.8016997319395824

Epoch: 6| Step: 7
Training loss: 1.382876992225647
Validation loss: 1.8468956293598298

Epoch: 6| Step: 8
Training loss: 1.8333791494369507
Validation loss: 1.8487175344139017

Epoch: 6| Step: 9
Training loss: 1.676072597503662
Validation loss: 1.8429065224944905

Epoch: 6| Step: 10
Training loss: 1.6744985580444336
Validation loss: 1.8575172821680705

Epoch: 6| Step: 11
Training loss: 1.8425358533859253
Validation loss: 1.7933296772741503

Epoch: 6| Step: 12
Training loss: 1.8138394355773926
Validation loss: 1.8076282265365764

Epoch: 6| Step: 13
Training loss: 1.4634747505187988
Validation loss: 1.8317727901602303

Epoch: 253| Step: 0
Training loss: 1.5179896354675293
Validation loss: 1.839193800444244

Epoch: 6| Step: 1
Training loss: 1.5152056217193604
Validation loss: 1.7847322289661696

Epoch: 6| Step: 2
Training loss: 1.385772466659546
Validation loss: 1.8078120434156029

Epoch: 6| Step: 3
Training loss: 1.255739450454712
Validation loss: 1.858012871075702

Epoch: 6| Step: 4
Training loss: 1.5176427364349365
Validation loss: 1.8521827561880952

Epoch: 6| Step: 5
Training loss: 1.6822532415390015
Validation loss: 1.864582629613979

Epoch: 6| Step: 6
Training loss: 1.2550475597381592
Validation loss: 1.8267664781180761

Epoch: 6| Step: 7
Training loss: 2.0396103858947754
Validation loss: 1.8324226538340251

Epoch: 6| Step: 8
Training loss: 1.4605644941329956
Validation loss: 1.844015457296884

Epoch: 6| Step: 9
Training loss: 2.0421624183654785
Validation loss: 1.8364688273399108

Epoch: 6| Step: 10
Training loss: 1.6018140316009521
Validation loss: 1.8291487296422322

Epoch: 6| Step: 11
Training loss: 1.5853596925735474
Validation loss: 1.807047756769324

Epoch: 6| Step: 12
Training loss: 1.0975239276885986
Validation loss: 1.8376198468669769

Epoch: 6| Step: 13
Training loss: 1.375744342803955
Validation loss: 1.8450630018788

Epoch: 254| Step: 0
Training loss: 1.6329680681228638
Validation loss: 1.7973350337756577

Epoch: 6| Step: 1
Training loss: 1.2719075679779053
Validation loss: 1.7962445161675895

Epoch: 6| Step: 2
Training loss: 1.174694538116455
Validation loss: 1.7989553020846458

Epoch: 6| Step: 3
Training loss: 1.3766028881072998
Validation loss: 1.7899388536330192

Epoch: 6| Step: 4
Training loss: 1.586165428161621
Validation loss: 1.796611391088014

Epoch: 6| Step: 5
Training loss: 0.9924479722976685
Validation loss: 1.799729283137988

Epoch: 6| Step: 6
Training loss: 1.6912397146224976
Validation loss: 1.8104462726141817

Epoch: 6| Step: 7
Training loss: 1.4395864009857178
Validation loss: 1.832337341000957

Epoch: 6| Step: 8
Training loss: 1.8912460803985596
Validation loss: 1.8273303739486202

Epoch: 6| Step: 9
Training loss: 1.051710605621338
Validation loss: 1.806760803345711

Epoch: 6| Step: 10
Training loss: 1.2913563251495361
Validation loss: 1.8028729743854974

Epoch: 6| Step: 11
Training loss: 2.3148193359375
Validation loss: 1.8212120648353332

Epoch: 6| Step: 12
Training loss: 1.3894394636154175
Validation loss: 1.8042977522778254

Epoch: 6| Step: 13
Training loss: 2.0943968296051025
Validation loss: 1.8165449455220213

Epoch: 255| Step: 0
Training loss: 2.0641837120056152
Validation loss: 1.8056753271369523

Epoch: 6| Step: 1
Training loss: 1.1665401458740234
Validation loss: 1.7939189659651888

Epoch: 6| Step: 2
Training loss: 2.034827709197998
Validation loss: 1.867481295780469

Epoch: 6| Step: 3
Training loss: 1.2981059551239014
Validation loss: 1.8284825278866677

Epoch: 6| Step: 4
Training loss: 0.8711848258972168
Validation loss: 1.8256456595595165

Epoch: 6| Step: 5
Training loss: 1.883493185043335
Validation loss: 1.8469608112048077

Epoch: 6| Step: 6
Training loss: 1.666487216949463
Validation loss: 1.841689876330796

Epoch: 6| Step: 7
Training loss: 1.4767946004867554
Validation loss: 1.8454978273760887

Epoch: 6| Step: 8
Training loss: 1.41829252243042
Validation loss: 1.824778292768745

Epoch: 6| Step: 9
Training loss: 1.9745640754699707
Validation loss: 1.8248148631024104

Epoch: 6| Step: 10
Training loss: 1.0420740842819214
Validation loss: 1.8170697432692333

Epoch: 6| Step: 11
Training loss: 1.1322052478790283
Validation loss: 1.8182016329098774

Epoch: 6| Step: 12
Training loss: 1.7563165426254272
Validation loss: 1.8186451363307174

Epoch: 6| Step: 13
Training loss: 1.4111449718475342
Validation loss: 1.8377961215152536

Epoch: 256| Step: 0
Training loss: 1.360611081123352
Validation loss: 1.8220900566347185

Epoch: 6| Step: 1
Training loss: 1.3369698524475098
Validation loss: 1.8218126194451445

Epoch: 6| Step: 2
Training loss: 1.8711985349655151
Validation loss: 1.8172545830408733

Epoch: 6| Step: 3
Training loss: 1.4487624168395996
Validation loss: 1.837953612368594

Epoch: 6| Step: 4
Training loss: 1.4973827600479126
Validation loss: 1.8435560298222367

Epoch: 6| Step: 5
Training loss: 2.047492504119873
Validation loss: 1.828274344885221

Epoch: 6| Step: 6
Training loss: 1.388418197631836
Validation loss: 1.8626792277059248

Epoch: 6| Step: 7
Training loss: 1.4036858081817627
Validation loss: 1.8588216381688272

Epoch: 6| Step: 8
Training loss: 1.383230209350586
Validation loss: 1.8309593649320706

Epoch: 6| Step: 9
Training loss: 1.481760859489441
Validation loss: 1.866807605630608

Epoch: 6| Step: 10
Training loss: 1.1290712356567383
Validation loss: 1.8358688828765706

Epoch: 6| Step: 11
Training loss: 1.647336721420288
Validation loss: 1.8450873603102982

Epoch: 6| Step: 12
Training loss: 1.4110499620437622
Validation loss: 1.8499446863769202

Epoch: 6| Step: 13
Training loss: 1.869271993637085
Validation loss: 1.8102471418278192

Epoch: 257| Step: 0
Training loss: 1.9860373735427856
Validation loss: 1.8427938838158884

Epoch: 6| Step: 1
Training loss: 1.5004949569702148
Validation loss: 1.816833108984014

Epoch: 6| Step: 2
Training loss: 1.6484453678131104
Validation loss: 1.8446968486232143

Epoch: 6| Step: 3
Training loss: 1.753810167312622
Validation loss: 1.8327896748819659

Epoch: 6| Step: 4
Training loss: 1.301400065422058
Validation loss: 1.8426854866807179

Epoch: 6| Step: 5
Training loss: 1.249022126197815
Validation loss: 1.8191782556554323

Epoch: 6| Step: 6
Training loss: 1.1441383361816406
Validation loss: 1.7826813395305345

Epoch: 6| Step: 7
Training loss: 1.8992189168930054
Validation loss: 1.8148276793059481

Epoch: 6| Step: 8
Training loss: 1.2337234020233154
Validation loss: 1.7867418591694166

Epoch: 6| Step: 9
Training loss: 0.6543362140655518
Validation loss: 1.8310757016622892

Epoch: 6| Step: 10
Training loss: 1.6975634098052979
Validation loss: 1.8116931325645858

Epoch: 6| Step: 11
Training loss: 1.630250096321106
Validation loss: 1.8296949927524855

Epoch: 6| Step: 12
Training loss: 1.9504258632659912
Validation loss: 1.8033138129018969

Epoch: 6| Step: 13
Training loss: 1.6377580165863037
Validation loss: 1.8340914941603137

Epoch: 258| Step: 0
Training loss: 1.9026648998260498
Validation loss: 1.7945246606744745

Epoch: 6| Step: 1
Training loss: 1.6056045293807983
Validation loss: 1.7778170749705324

Epoch: 6| Step: 2
Training loss: 1.9027153253555298
Validation loss: 1.8462279073653682

Epoch: 6| Step: 3
Training loss: 1.057530164718628
Validation loss: 1.8510252762866277

Epoch: 6| Step: 4
Training loss: 1.6389381885528564
Validation loss: 1.8453878946201776

Epoch: 6| Step: 5
Training loss: 1.6959755420684814
Validation loss: 1.8379540263965566

Epoch: 6| Step: 6
Training loss: 1.9789844751358032
Validation loss: 1.8563617326880013

Epoch: 6| Step: 7
Training loss: 1.3644626140594482
Validation loss: 1.905298134332062

Epoch: 6| Step: 8
Training loss: 1.2357219457626343
Validation loss: 1.8603448021796443

Epoch: 6| Step: 9
Training loss: 1.2937654256820679
Validation loss: 1.8451670933795232

Epoch: 6| Step: 10
Training loss: 1.6436251401901245
Validation loss: 1.8529077191506662

Epoch: 6| Step: 11
Training loss: 1.5980100631713867
Validation loss: 1.8524157347217682

Epoch: 6| Step: 12
Training loss: 0.9688799381256104
Validation loss: 1.8242078776000648

Epoch: 6| Step: 13
Training loss: 1.1031616926193237
Validation loss: 1.8014861858019264

Epoch: 259| Step: 0
Training loss: 1.560415506362915
Validation loss: 1.8053065217951292

Epoch: 6| Step: 1
Training loss: 1.2187280654907227
Validation loss: 1.835875641915106

Epoch: 6| Step: 2
Training loss: 1.6509932279586792
Validation loss: 1.8239760809047247

Epoch: 6| Step: 3
Training loss: 1.4796273708343506
Validation loss: 1.7735559119973132

Epoch: 6| Step: 4
Training loss: 1.2173490524291992
Validation loss: 1.798190280955325

Epoch: 6| Step: 5
Training loss: 1.348412275314331
Validation loss: 1.8325358795863327

Epoch: 6| Step: 6
Training loss: 2.00518536567688
Validation loss: 1.8000827271451232

Epoch: 6| Step: 7
Training loss: 1.814837098121643
Validation loss: 1.80745348622722

Epoch: 6| Step: 8
Training loss: 1.474365234375
Validation loss: 1.809355628105902

Epoch: 6| Step: 9
Training loss: 1.3175804615020752
Validation loss: 1.7923468312909525

Epoch: 6| Step: 10
Training loss: 1.268331527709961
Validation loss: 1.7869971093311106

Epoch: 6| Step: 11
Training loss: 1.9592055082321167
Validation loss: 1.7914820653136059

Epoch: 6| Step: 12
Training loss: 0.8935904502868652
Validation loss: 1.8046053173721477

Epoch: 6| Step: 13
Training loss: 2.0896172523498535
Validation loss: 1.8189805758896695

Epoch: 260| Step: 0
Training loss: 1.9469726085662842
Validation loss: 1.8673027343647455

Epoch: 6| Step: 1
Training loss: 1.4737293720245361
Validation loss: 1.85377327985661

Epoch: 6| Step: 2
Training loss: 0.9628660678863525
Validation loss: 1.8207781186667822

Epoch: 6| Step: 3
Training loss: 1.0743439197540283
Validation loss: 1.8613384372444564

Epoch: 6| Step: 4
Training loss: 1.947418451309204
Validation loss: 1.8465984149645733

Epoch: 6| Step: 5
Training loss: 1.4282405376434326
Validation loss: 1.8576636545119747

Epoch: 6| Step: 6
Training loss: 1.243539571762085
Validation loss: 1.850974126528668

Epoch: 6| Step: 7
Training loss: 1.4176050424575806
Validation loss: 1.8504301758222683

Epoch: 6| Step: 8
Training loss: 1.6124157905578613
Validation loss: 1.8433900007637598

Epoch: 6| Step: 9
Training loss: 1.4834405183792114
Validation loss: 1.8346446534638763

Epoch: 6| Step: 10
Training loss: 1.47935152053833
Validation loss: 1.847777097455917

Epoch: 6| Step: 11
Training loss: 1.2194572687149048
Validation loss: 1.8339229770886

Epoch: 6| Step: 12
Training loss: 1.6290581226348877
Validation loss: 1.818516013442829

Epoch: 6| Step: 13
Training loss: 2.6509861946105957
Validation loss: 1.8551478168015838

Epoch: 261| Step: 0
Training loss: 2.0223569869995117
Validation loss: 1.8044416699358212

Epoch: 6| Step: 1
Training loss: 1.2330976724624634
Validation loss: 1.8143494795727473

Epoch: 6| Step: 2
Training loss: 1.3967971801757812
Validation loss: 1.8004306413794076

Epoch: 6| Step: 3
Training loss: 1.3551406860351562
Validation loss: 1.809450408463837

Epoch: 6| Step: 4
Training loss: 1.878583550453186
Validation loss: 1.8092343512401785

Epoch: 6| Step: 5
Training loss: 1.4155457019805908
Validation loss: 1.801991803671724

Epoch: 6| Step: 6
Training loss: 1.363619089126587
Validation loss: 1.787622691482626

Epoch: 6| Step: 7
Training loss: 1.439587116241455
Validation loss: 1.8009044201143327

Epoch: 6| Step: 8
Training loss: 1.8435485363006592
Validation loss: 1.8102404430348387

Epoch: 6| Step: 9
Training loss: 1.4424712657928467
Validation loss: 1.8170600398894279

Epoch: 6| Step: 10
Training loss: 1.2585744857788086
Validation loss: 1.804444618122552

Epoch: 6| Step: 11
Training loss: 1.487532138824463
Validation loss: 1.808528095163325

Epoch: 6| Step: 12
Training loss: 1.5632624626159668
Validation loss: 1.7844296924529537

Epoch: 6| Step: 13
Training loss: 1.4305211305618286
Validation loss: 1.7928182591674149

Epoch: 262| Step: 0
Training loss: 0.7636814117431641
Validation loss: 1.8208904830358361

Epoch: 6| Step: 1
Training loss: 1.3619887828826904
Validation loss: 1.804829643618676

Epoch: 6| Step: 2
Training loss: 0.9845325350761414
Validation loss: 1.8218060283250705

Epoch: 6| Step: 3
Training loss: 2.0220236778259277
Validation loss: 1.8405113989307034

Epoch: 6| Step: 4
Training loss: 1.8040997982025146
Validation loss: 1.8631498941811182

Epoch: 6| Step: 5
Training loss: 1.6134262084960938
Validation loss: 1.8708300987879436

Epoch: 6| Step: 6
Training loss: 1.6358387470245361
Validation loss: 1.8460080110898582

Epoch: 6| Step: 7
Training loss: 0.875633716583252
Validation loss: 1.847574431409118

Epoch: 6| Step: 8
Training loss: 1.4199458360671997
Validation loss: 1.815660419002656

Epoch: 6| Step: 9
Training loss: 2.0362110137939453
Validation loss: 1.8585483335679578

Epoch: 6| Step: 10
Training loss: 1.7113659381866455
Validation loss: 1.8890454538406865

Epoch: 6| Step: 11
Training loss: 1.8620529174804688
Validation loss: 1.83185403449561

Epoch: 6| Step: 12
Training loss: 1.7492661476135254
Validation loss: 1.8325800844418105

Epoch: 6| Step: 13
Training loss: 1.3669309616088867
Validation loss: 1.8315520555742326

Epoch: 263| Step: 0
Training loss: 1.929052472114563
Validation loss: 1.841324229394236

Epoch: 6| Step: 1
Training loss: 1.9291839599609375
Validation loss: 1.8458896413926156

Epoch: 6| Step: 2
Training loss: 1.1824020147323608
Validation loss: 1.8520050305192188

Epoch: 6| Step: 3
Training loss: 1.5174943208694458
Validation loss: 1.8058927148901007

Epoch: 6| Step: 4
Training loss: 1.8957171440124512
Validation loss: 1.7959790229797363

Epoch: 6| Step: 5
Training loss: 1.2793599367141724
Validation loss: 1.8225132137216546

Epoch: 6| Step: 6
Training loss: 0.798108696937561
Validation loss: 1.7980448584402762

Epoch: 6| Step: 7
Training loss: 1.2804747819900513
Validation loss: 1.788049885021743

Epoch: 6| Step: 8
Training loss: 1.9143426418304443
Validation loss: 1.809805489355518

Epoch: 6| Step: 9
Training loss: 1.2107632160186768
Validation loss: 1.794953123215706

Epoch: 6| Step: 10
Training loss: 1.904299020767212
Validation loss: 1.8319772558827554

Epoch: 6| Step: 11
Training loss: 1.1487077474594116
Validation loss: 1.7878921608771048

Epoch: 6| Step: 12
Training loss: 1.6833916902542114
Validation loss: 1.8184554423055341

Epoch: 6| Step: 13
Training loss: 1.3243643045425415
Validation loss: 1.8061870374987203

Epoch: 264| Step: 0
Training loss: 0.7561089992523193
Validation loss: 1.7980568216693016

Epoch: 6| Step: 1
Training loss: 1.6975362300872803
Validation loss: 1.8135985366759761

Epoch: 6| Step: 2
Training loss: 1.5653846263885498
Validation loss: 1.777191703037549

Epoch: 6| Step: 3
Training loss: 1.4853919744491577
Validation loss: 1.7946034490421254

Epoch: 6| Step: 4
Training loss: 1.5876927375793457
Validation loss: 1.783137911109514

Epoch: 6| Step: 5
Training loss: 1.2071157693862915
Validation loss: 1.817086612024615

Epoch: 6| Step: 6
Training loss: 1.9584252834320068
Validation loss: 1.8029302025354037

Epoch: 6| Step: 7
Training loss: 1.0282678604125977
Validation loss: 1.8008638684467604

Epoch: 6| Step: 8
Training loss: 1.719383716583252
Validation loss: 1.8380551748378302

Epoch: 6| Step: 9
Training loss: 2.4136953353881836
Validation loss: 1.822031823537683

Epoch: 6| Step: 10
Training loss: 1.0647451877593994
Validation loss: 1.8357646067937214

Epoch: 6| Step: 11
Training loss: 1.2888190746307373
Validation loss: 1.854177398066367

Epoch: 6| Step: 12
Training loss: 1.3627052307128906
Validation loss: 1.8453945870040565

Epoch: 6| Step: 13
Training loss: 2.0828754901885986
Validation loss: 1.8417019318508845

Epoch: 265| Step: 0
Training loss: 1.5799075365066528
Validation loss: 1.829984909744673

Epoch: 6| Step: 1
Training loss: 1.3511624336242676
Validation loss: 1.8317508979510235

Epoch: 6| Step: 2
Training loss: 1.1659998893737793
Validation loss: 1.820143827828028

Epoch: 6| Step: 3
Training loss: 1.6996359825134277
Validation loss: 1.8362199170615083

Epoch: 6| Step: 4
Training loss: 1.5794166326522827
Validation loss: 1.810719036286877

Epoch: 6| Step: 5
Training loss: 1.2949966192245483
Validation loss: 1.79382521875443

Epoch: 6| Step: 6
Training loss: 1.6660964488983154
Validation loss: 1.8173671518602679

Epoch: 6| Step: 7
Training loss: 0.776155412197113
Validation loss: 1.823754975872655

Epoch: 6| Step: 8
Training loss: 1.359044075012207
Validation loss: 1.8014539339209115

Epoch: 6| Step: 9
Training loss: 1.8475313186645508
Validation loss: 1.7719240239871445

Epoch: 6| Step: 10
Training loss: 1.830868124961853
Validation loss: 1.7919328994648431

Epoch: 6| Step: 11
Training loss: 1.298954725265503
Validation loss: 1.7699990234067362

Epoch: 6| Step: 12
Training loss: 1.7190027236938477
Validation loss: 1.780996726405236

Epoch: 6| Step: 13
Training loss: 1.348217248916626
Validation loss: 1.8124944702271493

Epoch: 266| Step: 0
Training loss: 1.3576602935791016
Validation loss: 1.8288773080354095

Epoch: 6| Step: 1
Training loss: 1.6633343696594238
Validation loss: 1.8029362514454832

Epoch: 6| Step: 2
Training loss: 1.740774393081665
Validation loss: 1.7732186919899398

Epoch: 6| Step: 3
Training loss: 2.0809381008148193
Validation loss: 1.8203008674806165

Epoch: 6| Step: 4
Training loss: 1.2924137115478516
Validation loss: 1.835414921083758

Epoch: 6| Step: 5
Training loss: 0.8939886093139648
Validation loss: 1.8298516555499005

Epoch: 6| Step: 6
Training loss: 1.501368522644043
Validation loss: 1.8507425118518133

Epoch: 6| Step: 7
Training loss: 1.4118221998214722
Validation loss: 1.8119220131187028

Epoch: 6| Step: 8
Training loss: 1.3261842727661133
Validation loss: 1.8172113395506335

Epoch: 6| Step: 9
Training loss: 1.264063835144043
Validation loss: 1.8226752999008342

Epoch: 6| Step: 10
Training loss: 1.7912092208862305
Validation loss: 1.8499862468370827

Epoch: 6| Step: 11
Training loss: 1.1591846942901611
Validation loss: 1.78401090252784

Epoch: 6| Step: 12
Training loss: 2.035240411758423
Validation loss: 1.8432076541326379

Epoch: 6| Step: 13
Training loss: 1.183811902999878
Validation loss: 1.8216005807281823

Epoch: 267| Step: 0
Training loss: 1.335296869277954
Validation loss: 1.808679360215382

Epoch: 6| Step: 1
Training loss: 1.344395637512207
Validation loss: 1.8209565019094816

Epoch: 6| Step: 2
Training loss: 0.8932647705078125
Validation loss: 1.80346389227016

Epoch: 6| Step: 3
Training loss: 1.710236668586731
Validation loss: 1.812490652966243

Epoch: 6| Step: 4
Training loss: 1.2479362487792969
Validation loss: 1.815239510228557

Epoch: 6| Step: 5
Training loss: 1.504804015159607
Validation loss: 1.8137693225696523

Epoch: 6| Step: 6
Training loss: 1.464568853378296
Validation loss: 1.8243515081303094

Epoch: 6| Step: 7
Training loss: 2.104457139968872
Validation loss: 1.8382259209950764

Epoch: 6| Step: 8
Training loss: 1.8666272163391113
Validation loss: 1.7949986098915018

Epoch: 6| Step: 9
Training loss: 1.979397177696228
Validation loss: 1.8206144097030803

Epoch: 6| Step: 10
Training loss: 1.2073711156845093
Validation loss: 1.782131475787009

Epoch: 6| Step: 11
Training loss: 1.3534458875656128
Validation loss: 1.8232179739141976

Epoch: 6| Step: 12
Training loss: 1.1514623165130615
Validation loss: 1.7832704705576743

Epoch: 6| Step: 13
Training loss: 1.2327790260314941
Validation loss: 1.8174873898106236

Epoch: 268| Step: 0
Training loss: 1.5259900093078613
Validation loss: 1.8210000966184883

Epoch: 6| Step: 1
Training loss: 1.7186988592147827
Validation loss: 1.820414177833065

Epoch: 6| Step: 2
Training loss: 1.193207859992981
Validation loss: 1.7658581092793455

Epoch: 6| Step: 3
Training loss: 1.527010440826416
Validation loss: 1.8389913292341336

Epoch: 6| Step: 4
Training loss: 1.5899360179901123
Validation loss: 1.8007398959129088

Epoch: 6| Step: 5
Training loss: 1.318727731704712
Validation loss: 1.8715776281972085

Epoch: 6| Step: 6
Training loss: 1.0776760578155518
Validation loss: 1.8234193068678661

Epoch: 6| Step: 7
Training loss: 1.1309031248092651
Validation loss: 1.8195416286427488

Epoch: 6| Step: 8
Training loss: 1.6839392185211182
Validation loss: 1.8115346021549676

Epoch: 6| Step: 9
Training loss: 1.3946712017059326
Validation loss: 1.7902459380447224

Epoch: 6| Step: 10
Training loss: 1.409562349319458
Validation loss: 1.80033859386239

Epoch: 6| Step: 11
Training loss: 1.9902291297912598
Validation loss: 1.80879605713711

Epoch: 6| Step: 12
Training loss: 2.0153098106384277
Validation loss: 1.8141136387343049

Epoch: 6| Step: 13
Training loss: 0.9086483716964722
Validation loss: 1.845373656160088

Epoch: 269| Step: 0
Training loss: 1.636181354522705
Validation loss: 1.8070910899869856

Epoch: 6| Step: 1
Training loss: 1.0558230876922607
Validation loss: 1.7773889521116852

Epoch: 6| Step: 2
Training loss: 1.6062780618667603
Validation loss: 1.8042537384135748

Epoch: 6| Step: 3
Training loss: 1.3767285346984863
Validation loss: 1.7992030805157078

Epoch: 6| Step: 4
Training loss: 1.3914414644241333
Validation loss: 1.7871247901711413

Epoch: 6| Step: 5
Training loss: 0.8448141813278198
Validation loss: 1.7808814100039903

Epoch: 6| Step: 6
Training loss: 1.3511724472045898
Validation loss: 1.7731444861299248

Epoch: 6| Step: 7
Training loss: 2.0327253341674805
Validation loss: 1.8039403871823383

Epoch: 6| Step: 8
Training loss: 1.4659709930419922
Validation loss: 1.819266015483487

Epoch: 6| Step: 9
Training loss: 1.6230483055114746
Validation loss: 1.7996838733714113

Epoch: 6| Step: 10
Training loss: 2.5078623294830322
Validation loss: 1.7976056298901957

Epoch: 6| Step: 11
Training loss: 1.0213996171951294
Validation loss: 1.8185055396890129

Epoch: 6| Step: 12
Training loss: 1.1565030813217163
Validation loss: 1.79991780301576

Epoch: 6| Step: 13
Training loss: 1.6315836906433105
Validation loss: 1.8415364847388318

Epoch: 270| Step: 0
Training loss: 1.216660499572754
Validation loss: 1.7947319746017456

Epoch: 6| Step: 1
Training loss: 1.641836404800415
Validation loss: 1.8325773926191433

Epoch: 6| Step: 2
Training loss: 1.7064746618270874
Validation loss: 1.8360102689394386

Epoch: 6| Step: 3
Training loss: 1.3492541313171387
Validation loss: 1.838229008900222

Epoch: 6| Step: 4
Training loss: 1.5800023078918457
Validation loss: 1.8186051153367566

Epoch: 6| Step: 5
Training loss: 0.9215986728668213
Validation loss: 1.8201443174833893

Epoch: 6| Step: 6
Training loss: 2.1145381927490234
Validation loss: 1.7952877244641703

Epoch: 6| Step: 7
Training loss: 1.7561181783676147
Validation loss: 1.8360279811325895

Epoch: 6| Step: 8
Training loss: 1.5155892372131348
Validation loss: 1.833209829945718

Epoch: 6| Step: 9
Training loss: 1.213079571723938
Validation loss: 1.7789324739927888

Epoch: 6| Step: 10
Training loss: 1.3903648853302002
Validation loss: 1.809479864694739

Epoch: 6| Step: 11
Training loss: 1.2637114524841309
Validation loss: 1.8139740664471862

Epoch: 6| Step: 12
Training loss: 1.2422658205032349
Validation loss: 1.801464557647705

Epoch: 6| Step: 13
Training loss: 1.8852286338806152
Validation loss: 1.8195887201575822

Epoch: 271| Step: 0
Training loss: 1.3049767017364502
Validation loss: 1.7777414885900353

Epoch: 6| Step: 1
Training loss: 1.810005784034729
Validation loss: 1.8163093290021342

Epoch: 6| Step: 2
Training loss: 2.162835121154785
Validation loss: 1.830353513840706

Epoch: 6| Step: 3
Training loss: 1.2029616832733154
Validation loss: 1.7589504552143875

Epoch: 6| Step: 4
Training loss: 1.1214313507080078
Validation loss: 1.8169860788570937

Epoch: 6| Step: 5
Training loss: 1.6213457584381104
Validation loss: 1.8510809726612543

Epoch: 6| Step: 6
Training loss: 1.3273450136184692
Validation loss: 1.8453832275124007

Epoch: 6| Step: 7
Training loss: 1.5856742858886719
Validation loss: 1.8264618266013362

Epoch: 6| Step: 8
Training loss: 1.1800868511199951
Validation loss: 1.7828050762094476

Epoch: 6| Step: 9
Training loss: 1.3603363037109375
Validation loss: 1.7854803954401324

Epoch: 6| Step: 10
Training loss: 1.412926197052002
Validation loss: 1.7839567494648758

Epoch: 6| Step: 11
Training loss: 1.5615339279174805
Validation loss: 1.8290420104098577

Epoch: 6| Step: 12
Training loss: 1.5628917217254639
Validation loss: 1.828742483610748

Epoch: 6| Step: 13
Training loss: 1.3094021081924438
Validation loss: 1.8001075098591466

Epoch: 272| Step: 0
Training loss: 1.7508623600006104
Validation loss: 1.8050453662872314

Epoch: 6| Step: 1
Training loss: 1.6242128610610962
Validation loss: 1.7720398851620254

Epoch: 6| Step: 2
Training loss: 1.0143611431121826
Validation loss: 1.8201488782000799

Epoch: 6| Step: 3
Training loss: 1.3382632732391357
Validation loss: 1.8061482226976784

Epoch: 6| Step: 4
Training loss: 1.9765315055847168
Validation loss: 1.7793829261615712

Epoch: 6| Step: 5
Training loss: 1.4275100231170654
Validation loss: 1.8070682812762517

Epoch: 6| Step: 6
Training loss: 1.3561739921569824
Validation loss: 1.7730517784754436

Epoch: 6| Step: 7
Training loss: 1.302497148513794
Validation loss: 1.7932727490701983

Epoch: 6| Step: 8
Training loss: 1.781648874282837
Validation loss: 1.8002149597291024

Epoch: 6| Step: 9
Training loss: 0.8933959007263184
Validation loss: 1.8184456850892754

Epoch: 6| Step: 10
Training loss: 1.3887748718261719
Validation loss: 1.808889381347164

Epoch: 6| Step: 11
Training loss: 1.7356390953063965
Validation loss: 1.8449470907129266

Epoch: 6| Step: 12
Training loss: 1.5239222049713135
Validation loss: 1.8024457141917238

Epoch: 6| Step: 13
Training loss: 1.6036630868911743
Validation loss: 1.8558046728052118

Epoch: 273| Step: 0
Training loss: 1.4789760112762451
Validation loss: 1.8013277361469884

Epoch: 6| Step: 1
Training loss: 1.631124496459961
Validation loss: 1.8461289585277598

Epoch: 6| Step: 2
Training loss: 2.47944974899292
Validation loss: 1.8394406969829271

Epoch: 6| Step: 3
Training loss: 1.3162927627563477
Validation loss: 1.824361938302235

Epoch: 6| Step: 4
Training loss: 1.497418761253357
Validation loss: 1.8301955730684343

Epoch: 6| Step: 5
Training loss: 1.0182480812072754
Validation loss: 1.8219960158871067

Epoch: 6| Step: 6
Training loss: 1.986952543258667
Validation loss: 1.7857097092495169

Epoch: 6| Step: 7
Training loss: 1.2990245819091797
Validation loss: 1.856239982830581

Epoch: 6| Step: 8
Training loss: 1.3908517360687256
Validation loss: 1.8275347960892545

Epoch: 6| Step: 9
Training loss: 1.5248222351074219
Validation loss: 1.794172651024275

Epoch: 6| Step: 10
Training loss: 1.223049521446228
Validation loss: 1.798816256625678

Epoch: 6| Step: 11
Training loss: 1.4827704429626465
Validation loss: 1.8192859567621702

Epoch: 6| Step: 12
Training loss: 1.1106798648834229
Validation loss: 1.8089842078506306

Epoch: 6| Step: 13
Training loss: 0.9736925959587097
Validation loss: 1.8439221741050802

Epoch: 274| Step: 0
Training loss: 1.1221954822540283
Validation loss: 1.7928640483528056

Epoch: 6| Step: 1
Training loss: 1.6820166110992432
Validation loss: 1.7879933862275974

Epoch: 6| Step: 2
Training loss: 1.0472924709320068
Validation loss: 1.8114595720844884

Epoch: 6| Step: 3
Training loss: 1.5631272792816162
Validation loss: 1.7365190982818604

Epoch: 6| Step: 4
Training loss: 1.431715965270996
Validation loss: 1.8222936404648649

Epoch: 6| Step: 5
Training loss: 0.8334329128265381
Validation loss: 1.7760603363795946

Epoch: 6| Step: 6
Training loss: 1.1986113786697388
Validation loss: 1.7858807515072566

Epoch: 6| Step: 7
Training loss: 1.8775485754013062
Validation loss: 1.8142162202506937

Epoch: 6| Step: 8
Training loss: 1.673433780670166
Validation loss: 1.7783945606600853

Epoch: 6| Step: 9
Training loss: 1.7480385303497314
Validation loss: 1.7914576004910212

Epoch: 6| Step: 10
Training loss: 1.0837230682373047
Validation loss: 1.8119560672390846

Epoch: 6| Step: 11
Training loss: 2.0474050045013428
Validation loss: 1.7901730037504626

Epoch: 6| Step: 12
Training loss: 1.8148185014724731
Validation loss: 1.754026174545288

Epoch: 6| Step: 13
Training loss: 1.1681920289993286
Validation loss: 1.8076785072203605

Epoch: 275| Step: 0
Training loss: 1.1675734519958496
Validation loss: 1.7822202661985993

Epoch: 6| Step: 1
Training loss: 1.9645726680755615
Validation loss: 1.8114329999493015

Epoch: 6| Step: 2
Training loss: 1.2934823036193848
Validation loss: 1.8004784878864084

Epoch: 6| Step: 3
Training loss: 1.8570469617843628
Validation loss: 1.8003876811714583

Epoch: 6| Step: 4
Training loss: 1.344043493270874
Validation loss: 1.8308842938433412

Epoch: 6| Step: 5
Training loss: 1.484480381011963
Validation loss: 1.8092081649329073

Epoch: 6| Step: 6
Training loss: 0.9815508127212524
Validation loss: 1.8242388079243321

Epoch: 6| Step: 7
Training loss: 0.9764836430549622
Validation loss: 1.8367157495150002

Epoch: 6| Step: 8
Training loss: 1.6671037673950195
Validation loss: 1.780485741553768

Epoch: 6| Step: 9
Training loss: 2.6230554580688477
Validation loss: 1.811139706642397

Epoch: 6| Step: 10
Training loss: 1.1788383722305298
Validation loss: 1.8207426199349024

Epoch: 6| Step: 11
Training loss: 1.768622875213623
Validation loss: 1.7619078005513837

Epoch: 6| Step: 12
Training loss: 1.029059648513794
Validation loss: 1.7917664909875521

Epoch: 6| Step: 13
Training loss: 0.966116189956665
Validation loss: 1.8124826826075071

Epoch: 276| Step: 0
Training loss: 2.0057692527770996
Validation loss: 1.8231376319803216

Epoch: 6| Step: 1
Training loss: 1.1372833251953125
Validation loss: 1.785025958091982

Epoch: 6| Step: 2
Training loss: 1.3468985557556152
Validation loss: 1.772220362899124

Epoch: 6| Step: 3
Training loss: 1.4110801219940186
Validation loss: 1.7384677856199202

Epoch: 6| Step: 4
Training loss: 1.7535805702209473
Validation loss: 1.809487808135248

Epoch: 6| Step: 5
Training loss: 1.7708067893981934
Validation loss: 1.8139246638103197

Epoch: 6| Step: 6
Training loss: 1.5971046686172485
Validation loss: 1.8045949051457066

Epoch: 6| Step: 7
Training loss: 2.2662651538848877
Validation loss: 1.7716983672111266

Epoch: 6| Step: 8
Training loss: 0.6459514498710632
Validation loss: 1.7866411747470978

Epoch: 6| Step: 9
Training loss: 1.7375009059906006
Validation loss: 1.8052046119525869

Epoch: 6| Step: 10
Training loss: 1.6191322803497314
Validation loss: 1.8271560310035624

Epoch: 6| Step: 11
Training loss: 1.1442580223083496
Validation loss: 1.7931684396600212

Epoch: 6| Step: 12
Training loss: 1.120168685913086
Validation loss: 1.7770245062407626

Epoch: 6| Step: 13
Training loss: 0.8030112385749817
Validation loss: 1.8702811412913825

Epoch: 277| Step: 0
Training loss: 1.5963735580444336
Validation loss: 1.8312326080055648

Epoch: 6| Step: 1
Training loss: 1.8679180145263672
Validation loss: 1.8340732436026297

Epoch: 6| Step: 2
Training loss: 1.6596156358718872
Validation loss: 1.8065788245970202

Epoch: 6| Step: 3
Training loss: 1.9712859392166138
Validation loss: 1.8118602537339734

Epoch: 6| Step: 4
Training loss: 1.3394312858581543
Validation loss: 1.7890245222276258

Epoch: 6| Step: 5
Training loss: 1.532251000404358
Validation loss: 1.7829100239661433

Epoch: 6| Step: 6
Training loss: 1.3788530826568604
Validation loss: 1.7953080720798944

Epoch: 6| Step: 7
Training loss: 0.8919159173965454
Validation loss: 1.7662146206825011

Epoch: 6| Step: 8
Training loss: 1.8507764339447021
Validation loss: 1.8037372301983576

Epoch: 6| Step: 9
Training loss: 0.9689431190490723
Validation loss: 1.7935699916655017

Epoch: 6| Step: 10
Training loss: 1.255488395690918
Validation loss: 1.8122907325785647

Epoch: 6| Step: 11
Training loss: 1.717278003692627
Validation loss: 1.8020919920295797

Epoch: 6| Step: 12
Training loss: 1.1620500087738037
Validation loss: 1.8186057652196577

Epoch: 6| Step: 13
Training loss: 1.649452567100525
Validation loss: 1.7916179600582327

Epoch: 278| Step: 0
Training loss: 1.5931919813156128
Validation loss: 1.7638475715473134

Epoch: 6| Step: 1
Training loss: 1.6212047338485718
Validation loss: 1.7905299061088151

Epoch: 6| Step: 2
Training loss: 1.3878111839294434
Validation loss: 1.79062980862074

Epoch: 6| Step: 3
Training loss: 1.5701117515563965
Validation loss: 1.799395320236042

Epoch: 6| Step: 4
Training loss: 1.7975891828536987
Validation loss: 1.8110654648914133

Epoch: 6| Step: 5
Training loss: 0.8410813808441162
Validation loss: 1.832377100503573

Epoch: 6| Step: 6
Training loss: 1.0592774152755737
Validation loss: 1.821542501449585

Epoch: 6| Step: 7
Training loss: 1.9069099426269531
Validation loss: 1.8383226343380508

Epoch: 6| Step: 8
Training loss: 1.4339420795440674
Validation loss: 1.8691307754926785

Epoch: 6| Step: 9
Training loss: 1.764054298400879
Validation loss: 1.8545143783733409

Epoch: 6| Step: 10
Training loss: 0.9149497747421265
Validation loss: 1.8200840334738455

Epoch: 6| Step: 11
Training loss: 1.9256160259246826
Validation loss: 1.8451933091686619

Epoch: 6| Step: 12
Training loss: 1.3023948669433594
Validation loss: 1.8320822895214122

Epoch: 6| Step: 13
Training loss: 1.141797423362732
Validation loss: 1.8396785310519639

Epoch: 279| Step: 0
Training loss: 2.2520556449890137
Validation loss: 1.8447571441691408

Epoch: 6| Step: 1
Training loss: 1.440233588218689
Validation loss: 1.8269271453221638

Epoch: 6| Step: 2
Training loss: 1.4099745750427246
Validation loss: 1.8583223204458914

Epoch: 6| Step: 3
Training loss: 1.540292739868164
Validation loss: 1.8430949334175355

Epoch: 6| Step: 4
Training loss: 1.8944263458251953
Validation loss: 1.8249679444938578

Epoch: 6| Step: 5
Training loss: 0.9994971752166748
Validation loss: 1.8151492611054452

Epoch: 6| Step: 6
Training loss: 1.978082537651062
Validation loss: 1.7838334780867382

Epoch: 6| Step: 7
Training loss: 0.4904978275299072
Validation loss: 1.8114426251380675

Epoch: 6| Step: 8
Training loss: 1.530866265296936
Validation loss: 1.804934629829981

Epoch: 6| Step: 9
Training loss: 1.4010639190673828
Validation loss: 1.8168830102489841

Epoch: 6| Step: 10
Training loss: 0.8883439302444458
Validation loss: 1.8118028294655584

Epoch: 6| Step: 11
Training loss: 1.610005497932434
Validation loss: 1.8129191065347323

Epoch: 6| Step: 12
Training loss: 1.2956956624984741
Validation loss: 1.8107555476568078

Epoch: 6| Step: 13
Training loss: 1.0031992197036743
Validation loss: 1.7628379842286468

Epoch: 280| Step: 0
Training loss: 1.5065085887908936
Validation loss: 1.8039768844522455

Epoch: 6| Step: 1
Training loss: 1.5464853048324585
Validation loss: 1.7470921188272455

Epoch: 6| Step: 2
Training loss: 1.4867571592330933
Validation loss: 1.8028106817635157

Epoch: 6| Step: 3
Training loss: 1.904561161994934
Validation loss: 1.7987706584315146

Epoch: 6| Step: 4
Training loss: 1.2932219505310059
Validation loss: 1.8434007154997958

Epoch: 6| Step: 5
Training loss: 1.1816896200180054
Validation loss: 1.7814280256148307

Epoch: 6| Step: 6
Training loss: 1.1912994384765625
Validation loss: 1.7883411120342951

Epoch: 6| Step: 7
Training loss: 1.4103169441223145
Validation loss: 1.752595942507508

Epoch: 6| Step: 8
Training loss: 1.7198619842529297
Validation loss: 1.8099254895282049

Epoch: 6| Step: 9
Training loss: 1.287891149520874
Validation loss: 1.8102527472280687

Epoch: 6| Step: 10
Training loss: 0.6670331954956055
Validation loss: 1.806625000892147

Epoch: 6| Step: 11
Training loss: 1.532435417175293
Validation loss: 1.7582654414638397

Epoch: 6| Step: 12
Training loss: 1.8016902208328247
Validation loss: 1.8398258968066143

Epoch: 6| Step: 13
Training loss: 1.6720317602157593
Validation loss: 1.778777906971593

Epoch: 281| Step: 0
Training loss: 0.6185461282730103
Validation loss: 1.8209243525740921

Epoch: 6| Step: 1
Training loss: 1.1020915508270264
Validation loss: 1.813923361480877

Epoch: 6| Step: 2
Training loss: 1.6157103776931763
Validation loss: 1.7743207818718367

Epoch: 6| Step: 3
Training loss: 1.6744487285614014
Validation loss: 1.8059502109404533

Epoch: 6| Step: 4
Training loss: 1.387986421585083
Validation loss: 1.8155680702578636

Epoch: 6| Step: 5
Training loss: 1.0005073547363281
Validation loss: 1.7840851301788

Epoch: 6| Step: 6
Training loss: 1.3265823125839233
Validation loss: 1.7651838141102945

Epoch: 6| Step: 7
Training loss: 0.58916836977005
Validation loss: 1.7706198910231232

Epoch: 6| Step: 8
Training loss: 1.6823055744171143
Validation loss: 1.77713652067287

Epoch: 6| Step: 9
Training loss: 1.5587693452835083
Validation loss: 1.8133565187454224

Epoch: 6| Step: 10
Training loss: 2.061314105987549
Validation loss: 1.7842950795286445

Epoch: 6| Step: 11
Training loss: 2.3496150970458984
Validation loss: 1.7859212621565788

Epoch: 6| Step: 12
Training loss: 1.4655814170837402
Validation loss: 1.7940334453377673

Epoch: 6| Step: 13
Training loss: 1.6952039003372192
Validation loss: 1.7371498384783346

Epoch: 282| Step: 0
Training loss: 1.3946360349655151
Validation loss: 1.7707088762714016

Epoch: 6| Step: 1
Training loss: 1.3775079250335693
Validation loss: 1.7643142425885765

Epoch: 6| Step: 2
Training loss: 1.3365720510482788
Validation loss: 1.7734474648711502

Epoch: 6| Step: 3
Training loss: 1.878344178199768
Validation loss: 1.8267993029727732

Epoch: 6| Step: 4
Training loss: 1.4164081811904907
Validation loss: 1.7891813119252522

Epoch: 6| Step: 5
Training loss: 1.026913046836853
Validation loss: 1.811856940228452

Epoch: 6| Step: 6
Training loss: 1.5483053922653198
Validation loss: 1.8130259565127793

Epoch: 6| Step: 7
Training loss: 2.1473209857940674
Validation loss: 1.790398040125447

Epoch: 6| Step: 8
Training loss: 1.4666457176208496
Validation loss: 1.788665722775203

Epoch: 6| Step: 9
Training loss: 1.6517786979675293
Validation loss: 1.8153869157196374

Epoch: 6| Step: 10
Training loss: 1.3137553930282593
Validation loss: 1.8127660930797618

Epoch: 6| Step: 11
Training loss: 0.8469960689544678
Validation loss: 1.8148640535211051

Epoch: 6| Step: 12
Training loss: 1.350393295288086
Validation loss: 1.8216240854673489

Epoch: 6| Step: 13
Training loss: 0.9896571040153503
Validation loss: 1.7909690872315438

Epoch: 283| Step: 0
Training loss: 1.7159372568130493
Validation loss: 1.7878885986984416

Epoch: 6| Step: 1
Training loss: 1.2037103176116943
Validation loss: 1.7925308430066673

Epoch: 6| Step: 2
Training loss: 1.3131296634674072
Validation loss: 1.7920248444362352

Epoch: 6| Step: 3
Training loss: 1.6470848321914673
Validation loss: 1.8086589831177906

Epoch: 6| Step: 4
Training loss: 1.2102127075195312
Validation loss: 1.8138906084081179

Epoch: 6| Step: 5
Training loss: 1.2149360179901123
Validation loss: 1.811761821469953

Epoch: 6| Step: 6
Training loss: 1.7083922624588013
Validation loss: 1.8026822561858802

Epoch: 6| Step: 7
Training loss: 1.4763485193252563
Validation loss: 1.8156789066970989

Epoch: 6| Step: 8
Training loss: 0.9697277545928955
Validation loss: 1.8251426014848935

Epoch: 6| Step: 9
Training loss: 1.7737791538238525
Validation loss: 1.7678042432313323

Epoch: 6| Step: 10
Training loss: 1.358604907989502
Validation loss: 1.7901468328250352

Epoch: 6| Step: 11
Training loss: 0.9194824695587158
Validation loss: 1.8273759939337288

Epoch: 6| Step: 12
Training loss: 2.163864850997925
Validation loss: 1.8000911410136888

Epoch: 6| Step: 13
Training loss: 1.114093542098999
Validation loss: 1.818028332084738

Epoch: 284| Step: 0
Training loss: 1.0338456630706787
Validation loss: 1.7679526023967291

Epoch: 6| Step: 1
Training loss: 1.8011054992675781
Validation loss: 1.8073188720210906

Epoch: 6| Step: 2
Training loss: 1.5224430561065674
Validation loss: 1.7899933553511096

Epoch: 6| Step: 3
Training loss: 0.9828121662139893
Validation loss: 1.7900593511519893

Epoch: 6| Step: 4
Training loss: 1.3289541006088257
Validation loss: 1.78999662399292

Epoch: 6| Step: 5
Training loss: 1.5729362964630127
Validation loss: 1.7878600435872232

Epoch: 6| Step: 6
Training loss: 1.7614887952804565
Validation loss: 1.7867083934045607

Epoch: 6| Step: 7
Training loss: 1.393531084060669
Validation loss: 1.8072567550084924

Epoch: 6| Step: 8
Training loss: 1.8689724206924438
Validation loss: 1.7982183297475178

Epoch: 6| Step: 9
Training loss: 0.9409717321395874
Validation loss: 1.7859555713592037

Epoch: 6| Step: 10
Training loss: 2.1772069931030273
Validation loss: 1.8239519929373136

Epoch: 6| Step: 11
Training loss: 1.246935248374939
Validation loss: 1.7947813926204559

Epoch: 6| Step: 12
Training loss: 0.9251445531845093
Validation loss: 1.847897247601581

Epoch: 6| Step: 13
Training loss: 1.2534279823303223
Validation loss: 1.8269245470723798

Epoch: 285| Step: 0
Training loss: 1.0744960308074951
Validation loss: 1.8221243094372492

Epoch: 6| Step: 1
Training loss: 1.3927462100982666
Validation loss: 1.7767968190613614

Epoch: 6| Step: 2
Training loss: 1.0306813716888428
Validation loss: 1.8087705553218882

Epoch: 6| Step: 3
Training loss: 0.934306263923645
Validation loss: 1.8139459394639539

Epoch: 6| Step: 4
Training loss: 1.3345714807510376
Validation loss: 1.8050930077029812

Epoch: 6| Step: 5
Training loss: 1.70232093334198
Validation loss: 1.7972358926650016

Epoch: 6| Step: 6
Training loss: 1.5636128187179565
Validation loss: 1.762483560910789

Epoch: 6| Step: 7
Training loss: 0.8711928725242615
Validation loss: 1.7801508653548457

Epoch: 6| Step: 8
Training loss: 2.2270941734313965
Validation loss: 1.8164233033375075

Epoch: 6| Step: 9
Training loss: 1.6666730642318726
Validation loss: 1.7686464196892195

Epoch: 6| Step: 10
Training loss: 2.0301764011383057
Validation loss: 1.7812034814588484

Epoch: 6| Step: 11
Training loss: 1.4098718166351318
Validation loss: 1.7735392214149557

Epoch: 6| Step: 12
Training loss: 1.3972809314727783
Validation loss: 1.8078843547451882

Epoch: 6| Step: 13
Training loss: 1.0496407747268677
Validation loss: 1.7660571605928483

Epoch: 286| Step: 0
Training loss: 1.4837167263031006
Validation loss: 1.7899971136482813

Epoch: 6| Step: 1
Training loss: 1.4688249826431274
Validation loss: 1.8028404738313408

Epoch: 6| Step: 2
Training loss: 1.108404517173767
Validation loss: 1.782529269495318

Epoch: 6| Step: 3
Training loss: 1.0894713401794434
Validation loss: 1.793658823095342

Epoch: 6| Step: 4
Training loss: 1.6374218463897705
Validation loss: 1.7810720166852396

Epoch: 6| Step: 5
Training loss: 1.5775026082992554
Validation loss: 1.7897363247409943

Epoch: 6| Step: 6
Training loss: 1.917740821838379
Validation loss: 1.7948952823556878

Epoch: 6| Step: 7
Training loss: 0.9705315828323364
Validation loss: 1.8309119080984464

Epoch: 6| Step: 8
Training loss: 1.599865198135376
Validation loss: 1.824443732538531

Epoch: 6| Step: 9
Training loss: 1.7547332048416138
Validation loss: 1.7808500528335571

Epoch: 6| Step: 10
Training loss: 1.4368159770965576
Validation loss: 1.7815792752850441

Epoch: 6| Step: 11
Training loss: 1.3217270374298096
Validation loss: 1.8198711513191141

Epoch: 6| Step: 12
Training loss: 0.9311710596084595
Validation loss: 1.793040462719497

Epoch: 6| Step: 13
Training loss: 1.3473800420761108
Validation loss: 1.8067520728675268

Epoch: 287| Step: 0
Training loss: 1.3533251285552979
Validation loss: 1.8537886783640871

Epoch: 6| Step: 1
Training loss: 1.7353119850158691
Validation loss: 1.8243686883680281

Epoch: 6| Step: 2
Training loss: 1.2371702194213867
Validation loss: 1.8236036736478087

Epoch: 6| Step: 3
Training loss: 1.3987499475479126
Validation loss: 1.8073874981172624

Epoch: 6| Step: 4
Training loss: 1.1510531902313232
Validation loss: 1.8207905689875286

Epoch: 6| Step: 5
Training loss: 1.76202392578125
Validation loss: 1.8522998056104105

Epoch: 6| Step: 6
Training loss: 1.2654483318328857
Validation loss: 1.8285146836311585

Epoch: 6| Step: 7
Training loss: 1.5159242153167725
Validation loss: 1.7808835198802333

Epoch: 6| Step: 8
Training loss: 1.4478040933609009
Validation loss: 1.805464712522363

Epoch: 6| Step: 9
Training loss: 1.1308531761169434
Validation loss: 1.8108131475346063

Epoch: 6| Step: 10
Training loss: 1.0427336692810059
Validation loss: 1.8706829906791769

Epoch: 6| Step: 11
Training loss: 1.6111183166503906
Validation loss: 1.8661833719540668

Epoch: 6| Step: 12
Training loss: 1.526801347732544
Validation loss: 1.7689085147714103

Epoch: 6| Step: 13
Training loss: 1.3359283208847046
Validation loss: 1.7957602072787542

Epoch: 288| Step: 0
Training loss: 1.9613537788391113
Validation loss: 1.8278865737299765

Epoch: 6| Step: 1
Training loss: 1.3352261781692505
Validation loss: 1.8064432438983713

Epoch: 6| Step: 2
Training loss: 1.2100493907928467
Validation loss: 1.80497363562225

Epoch: 6| Step: 3
Training loss: 1.5711432695388794
Validation loss: 1.816565498228996

Epoch: 6| Step: 4
Training loss: 1.8066775798797607
Validation loss: 1.8040012608292282

Epoch: 6| Step: 5
Training loss: 0.9011203050613403
Validation loss: 1.7823700199845016

Epoch: 6| Step: 6
Training loss: 1.4153763055801392
Validation loss: 1.784867339236762

Epoch: 6| Step: 7
Training loss: 1.1451025009155273
Validation loss: 1.8028082469458222

Epoch: 6| Step: 8
Training loss: 1.111104965209961
Validation loss: 1.8389784982127528

Epoch: 6| Step: 9
Training loss: 0.89853435754776
Validation loss: 1.8142385200787616

Epoch: 6| Step: 10
Training loss: 1.9657777547836304
Validation loss: 1.8287667459057224

Epoch: 6| Step: 11
Training loss: 1.3537920713424683
Validation loss: 1.7968011133132442

Epoch: 6| Step: 12
Training loss: 1.8545137643814087
Validation loss: 1.8197979952699395

Epoch: 6| Step: 13
Training loss: 1.3222813606262207
Validation loss: 1.7601016657326811

Epoch: 289| Step: 0
Training loss: 1.5997122526168823
Validation loss: 1.8148489152231524

Epoch: 6| Step: 1
Training loss: 1.0048571825027466
Validation loss: 1.8094352855477283

Epoch: 6| Step: 2
Training loss: 1.4660996198654175
Validation loss: 1.7967182308114984

Epoch: 6| Step: 3
Training loss: 1.7491415739059448
Validation loss: 1.7885589932882657

Epoch: 6| Step: 4
Training loss: 1.5250093936920166
Validation loss: 1.7805575786098358

Epoch: 6| Step: 5
Training loss: 1.2075178623199463
Validation loss: 1.8071116529485232

Epoch: 6| Step: 6
Training loss: 1.827265977859497
Validation loss: 1.8139035086477957

Epoch: 6| Step: 7
Training loss: 1.4946589469909668
Validation loss: 1.7740407489961194

Epoch: 6| Step: 8
Training loss: 1.061446189880371
Validation loss: 1.8145085598832817

Epoch: 6| Step: 9
Training loss: 0.8844417929649353
Validation loss: 1.845909099425039

Epoch: 6| Step: 10
Training loss: 1.3989287614822388
Validation loss: 1.8436330749142555

Epoch: 6| Step: 11
Training loss: 1.6032905578613281
Validation loss: 1.7765410869352278

Epoch: 6| Step: 12
Training loss: 1.3091564178466797
Validation loss: 1.818192958831787

Epoch: 6| Step: 13
Training loss: 1.4311044216156006
Validation loss: 1.818879024956816

Epoch: 290| Step: 0
Training loss: 1.4868446588516235
Validation loss: 1.7755236330852713

Epoch: 6| Step: 1
Training loss: 1.4530889987945557
Validation loss: 1.7648063616086078

Epoch: 6| Step: 2
Training loss: 1.605445146560669
Validation loss: 1.7798104798921974

Epoch: 6| Step: 3
Training loss: 0.9134902358055115
Validation loss: 1.8209120458172214

Epoch: 6| Step: 4
Training loss: 1.3368130922317505
Validation loss: 1.766938753025506

Epoch: 6| Step: 5
Training loss: 1.5241219997406006
Validation loss: 1.8327971068761681

Epoch: 6| Step: 6
Training loss: 1.2466570138931274
Validation loss: 1.7724375647883261

Epoch: 6| Step: 7
Training loss: 1.414209008216858
Validation loss: 1.8301562109301168

Epoch: 6| Step: 8
Training loss: 2.0315425395965576
Validation loss: 1.7815848755580124

Epoch: 6| Step: 9
Training loss: 2.0636038780212402
Validation loss: 1.7417368670945526

Epoch: 6| Step: 10
Training loss: 0.9682861566543579
Validation loss: 1.8048375088681456

Epoch: 6| Step: 11
Training loss: 1.334855556488037
Validation loss: 1.806834308050012

Epoch: 6| Step: 12
Training loss: 1.1117030382156372
Validation loss: 1.786543853821293

Epoch: 6| Step: 13
Training loss: 0.8486953973770142
Validation loss: 1.7590327365424043

Epoch: 291| Step: 0
Training loss: 1.3605852127075195
Validation loss: 1.8022456656220138

Epoch: 6| Step: 1
Training loss: 1.5762887001037598
Validation loss: 1.79246380829042

Epoch: 6| Step: 2
Training loss: 1.4800031185150146
Validation loss: 1.7767902228140062

Epoch: 6| Step: 3
Training loss: 0.7722524404525757
Validation loss: 1.762661704453089

Epoch: 6| Step: 4
Training loss: 1.5131468772888184
Validation loss: 1.7934519719052058

Epoch: 6| Step: 5
Training loss: 1.069759488105774
Validation loss: 1.763229617508509

Epoch: 6| Step: 6
Training loss: 1.7634847164154053
Validation loss: 1.7971371822459723

Epoch: 6| Step: 7
Training loss: 1.6910598278045654
Validation loss: 1.7681170791708014

Epoch: 6| Step: 8
Training loss: 1.5321862697601318
Validation loss: 1.7819567752140824

Epoch: 6| Step: 9
Training loss: 1.5620545148849487
Validation loss: 1.7676706865269651

Epoch: 6| Step: 10
Training loss: 1.4163517951965332
Validation loss: 1.790787422528831

Epoch: 6| Step: 11
Training loss: 1.7005236148834229
Validation loss: 1.839290798351329

Epoch: 6| Step: 12
Training loss: 0.9733229875564575
Validation loss: 1.7806394292462258

Epoch: 6| Step: 13
Training loss: 1.3445789813995361
Validation loss: 1.7716439308658722

Epoch: 292| Step: 0
Training loss: 1.5062100887298584
Validation loss: 1.8024938362900929

Epoch: 6| Step: 1
Training loss: 2.123673915863037
Validation loss: 1.819680683074459

Epoch: 6| Step: 2
Training loss: 1.7190308570861816
Validation loss: 1.78302219734397

Epoch: 6| Step: 3
Training loss: 1.3094189167022705
Validation loss: 1.8611084620157878

Epoch: 6| Step: 4
Training loss: 1.28226637840271
Validation loss: 1.8243548126630886

Epoch: 6| Step: 5
Training loss: 1.190427541732788
Validation loss: 1.842374732417445

Epoch: 6| Step: 6
Training loss: 1.2532408237457275
Validation loss: 1.7561268947457755

Epoch: 6| Step: 7
Training loss: 1.269776701927185
Validation loss: 1.8654830109688543

Epoch: 6| Step: 8
Training loss: 1.0600693225860596
Validation loss: 1.8025487058906144

Epoch: 6| Step: 9
Training loss: 1.1306612491607666
Validation loss: 1.819269839153495

Epoch: 6| Step: 10
Training loss: 1.1976531744003296
Validation loss: 1.8041229171137656

Epoch: 6| Step: 11
Training loss: 2.3761367797851562
Validation loss: 1.79813265544112

Epoch: 6| Step: 12
Training loss: 1.3676941394805908
Validation loss: 1.7963254028751003

Epoch: 6| Step: 13
Training loss: 0.7749361991882324
Validation loss: 1.7995940728854107

Epoch: 293| Step: 0
Training loss: 1.6652946472167969
Validation loss: 1.7889433983833558

Epoch: 6| Step: 1
Training loss: 1.269970178604126
Validation loss: 1.8188786711744083

Epoch: 6| Step: 2
Training loss: 1.0448542833328247
Validation loss: 1.8141920361467587

Epoch: 6| Step: 3
Training loss: 2.2748265266418457
Validation loss: 1.8027161834060506

Epoch: 6| Step: 4
Training loss: 1.3374704122543335
Validation loss: 1.7971060827214231

Epoch: 6| Step: 5
Training loss: 1.89005446434021
Validation loss: 1.7965311427270212

Epoch: 6| Step: 6
Training loss: 1.111324429512024
Validation loss: 1.7983416626530309

Epoch: 6| Step: 7
Training loss: 1.5372217893600464
Validation loss: 1.792815609644818

Epoch: 6| Step: 8
Training loss: 1.543043613433838
Validation loss: 1.803173590731877

Epoch: 6| Step: 9
Training loss: 1.4554569721221924
Validation loss: 1.7844917107653875

Epoch: 6| Step: 10
Training loss: 1.0140241384506226
Validation loss: 1.7939303075113604

Epoch: 6| Step: 11
Training loss: 0.9582515358924866
Validation loss: 1.792159495815154

Epoch: 6| Step: 12
Training loss: 1.5584721565246582
Validation loss: 1.7992116725572975

Epoch: 6| Step: 13
Training loss: 0.6259225606918335
Validation loss: 1.750108124107443

Epoch: 294| Step: 0
Training loss: 1.5309542417526245
Validation loss: 1.827353480041668

Epoch: 6| Step: 1
Training loss: 1.0076417922973633
Validation loss: 1.8174857016532653

Epoch: 6| Step: 2
Training loss: 0.9086741805076599
Validation loss: 1.8094959310306016

Epoch: 6| Step: 3
Training loss: 1.7623695135116577
Validation loss: 1.831009070078532

Epoch: 6| Step: 4
Training loss: 0.8468750715255737
Validation loss: 1.8048430014682073

Epoch: 6| Step: 5
Training loss: 1.2751939296722412
Validation loss: 1.8431862477333314

Epoch: 6| Step: 6
Training loss: 1.8400695323944092
Validation loss: 1.7818188718570176

Epoch: 6| Step: 7
Training loss: 1.6481456756591797
Validation loss: 1.7789581879492729

Epoch: 6| Step: 8
Training loss: 1.2368481159210205
Validation loss: 1.8335064406036048

Epoch: 6| Step: 9
Training loss: 1.6880000829696655
Validation loss: 1.8183789894145022

Epoch: 6| Step: 10
Training loss: 1.6391901969909668
Validation loss: 1.8103088358397126

Epoch: 6| Step: 11
Training loss: 1.0535210371017456
Validation loss: 1.7741360510549238

Epoch: 6| Step: 12
Training loss: 1.5741679668426514
Validation loss: 1.798768558809834

Epoch: 6| Step: 13
Training loss: 2.033297538757324
Validation loss: 1.7982605400905813

Epoch: 295| Step: 0
Training loss: 1.8965452909469604
Validation loss: 1.8151624177091865

Epoch: 6| Step: 1
Training loss: 1.4057838916778564
Validation loss: 1.7969823204061037

Epoch: 6| Step: 2
Training loss: 1.2576229572296143
Validation loss: 1.803308561284055

Epoch: 6| Step: 3
Training loss: 1.4265289306640625
Validation loss: 1.743379162203881

Epoch: 6| Step: 4
Training loss: 0.9729117751121521
Validation loss: 1.81685673293247

Epoch: 6| Step: 5
Training loss: 1.000990390777588
Validation loss: 1.8048153410675705

Epoch: 6| Step: 6
Training loss: 1.8672442436218262
Validation loss: 1.7763289418271793

Epoch: 6| Step: 7
Training loss: 1.648165225982666
Validation loss: 1.808630533115838

Epoch: 6| Step: 8
Training loss: 1.5540920495986938
Validation loss: 1.8031967788614252

Epoch: 6| Step: 9
Training loss: 0.8517906069755554
Validation loss: 1.7535509563261462

Epoch: 6| Step: 10
Training loss: 1.4121973514556885
Validation loss: 1.8079443054814492

Epoch: 6| Step: 11
Training loss: 1.2038094997406006
Validation loss: 1.7790161730140768

Epoch: 6| Step: 12
Training loss: 1.3657190799713135
Validation loss: 1.800800943887362

Epoch: 6| Step: 13
Training loss: 1.505796194076538
Validation loss: 1.7625467456797117

Epoch: 296| Step: 0
Training loss: 1.7193467617034912
Validation loss: 1.7836881517082133

Epoch: 6| Step: 1
Training loss: 1.0905768871307373
Validation loss: 1.799217838113026

Epoch: 6| Step: 2
Training loss: 1.328101634979248
Validation loss: 1.8107055682007984

Epoch: 6| Step: 3
Training loss: 1.9701265096664429
Validation loss: 1.782148172778468

Epoch: 6| Step: 4
Training loss: 1.2094616889953613
Validation loss: 1.821115824484056

Epoch: 6| Step: 5
Training loss: 1.3527436256408691
Validation loss: 1.7701715692397086

Epoch: 6| Step: 6
Training loss: 1.0694046020507812
Validation loss: 1.7521041747062438

Epoch: 6| Step: 7
Training loss: 0.8912651538848877
Validation loss: 1.7754747547129148

Epoch: 6| Step: 8
Training loss: 0.9354098439216614
Validation loss: 1.7915076748017342

Epoch: 6| Step: 9
Training loss: 1.1411653757095337
Validation loss: 1.7844873577035882

Epoch: 6| Step: 10
Training loss: 1.9289941787719727
Validation loss: 1.81897868135924

Epoch: 6| Step: 11
Training loss: 1.481757402420044
Validation loss: 1.8220733032431653

Epoch: 6| Step: 12
Training loss: 1.1489728689193726
Validation loss: 1.7840015798486688

Epoch: 6| Step: 13
Training loss: 2.7786078453063965
Validation loss: 1.8048181085176365

Epoch: 297| Step: 0
Training loss: 1.2948448657989502
Validation loss: 1.780188081085041

Epoch: 6| Step: 1
Training loss: 0.7936135530471802
Validation loss: 1.7840712826739076

Epoch: 6| Step: 2
Training loss: 1.508469820022583
Validation loss: 1.7981564344898346

Epoch: 6| Step: 3
Training loss: 1.1498913764953613
Validation loss: 1.7773291923666512

Epoch: 6| Step: 4
Training loss: 1.0322173833847046
Validation loss: 1.778107097071986

Epoch: 6| Step: 5
Training loss: 1.793594479560852
Validation loss: 1.797844361233455

Epoch: 6| Step: 6
Training loss: 1.3432151079177856
Validation loss: 1.7893988573422996

Epoch: 6| Step: 7
Training loss: 1.3956665992736816
Validation loss: 1.7463423821233934

Epoch: 6| Step: 8
Training loss: 1.1567047834396362
Validation loss: 1.7847639642735964

Epoch: 6| Step: 9
Training loss: 0.9676832556724548
Validation loss: 1.7681659293431107

Epoch: 6| Step: 10
Training loss: 2.1069629192352295
Validation loss: 1.8156295040602326

Epoch: 6| Step: 11
Training loss: 1.6069362163543701
Validation loss: 1.8028968444434545

Epoch: 6| Step: 12
Training loss: 1.5544781684875488
Validation loss: 1.8220633909266482

Epoch: 6| Step: 13
Training loss: 2.076584577560425
Validation loss: 1.8015393108449957

Epoch: 298| Step: 0
Training loss: 1.112931728363037
Validation loss: 1.8416399930113105

Epoch: 6| Step: 1
Training loss: 1.4437804222106934
Validation loss: 1.7741164597131873

Epoch: 6| Step: 2
Training loss: 0.9644760489463806
Validation loss: 1.7927002381252986

Epoch: 6| Step: 3
Training loss: 1.2685489654541016
Validation loss: 1.7906777986916163

Epoch: 6| Step: 4
Training loss: 1.2433631420135498
Validation loss: 1.7968928660115888

Epoch: 6| Step: 5
Training loss: 1.59508216381073
Validation loss: 1.7970677050211097

Epoch: 6| Step: 6
Training loss: 1.9390206336975098
Validation loss: 1.7864033022234518

Epoch: 6| Step: 7
Training loss: 1.1357014179229736
Validation loss: 1.7905645280755975

Epoch: 6| Step: 8
Training loss: 1.2901616096496582
Validation loss: 1.8054577035288657

Epoch: 6| Step: 9
Training loss: 1.1549335718154907
Validation loss: 1.8274704897275535

Epoch: 6| Step: 10
Training loss: 1.2547639608383179
Validation loss: 1.7859146902638097

Epoch: 6| Step: 11
Training loss: 1.7342934608459473
Validation loss: 1.772144445808985

Epoch: 6| Step: 12
Training loss: 1.4614059925079346
Validation loss: 1.773479474488125

Epoch: 6| Step: 13
Training loss: 2.05405855178833
Validation loss: 1.8215313291036954

Epoch: 299| Step: 0
Training loss: 0.6832910776138306
Validation loss: 1.7440582988082722

Epoch: 6| Step: 1
Training loss: 1.9839913845062256
Validation loss: 1.8145910475843696

Epoch: 6| Step: 2
Training loss: 1.8689987659454346
Validation loss: 1.7372127809832174

Epoch: 6| Step: 3
Training loss: 1.6224870681762695
Validation loss: 1.7613456082600418

Epoch: 6| Step: 4
Training loss: 1.0828168392181396
Validation loss: 1.775054875240531

Epoch: 6| Step: 5
Training loss: 1.1881775856018066
Validation loss: 1.7893659222510554

Epoch: 6| Step: 6
Training loss: 1.4453847408294678
Validation loss: 1.7933059866710375

Epoch: 6| Step: 7
Training loss: 1.5830507278442383
Validation loss: 1.7499758838325419

Epoch: 6| Step: 8
Training loss: 1.488131046295166
Validation loss: 1.7568092679464689

Epoch: 6| Step: 9
Training loss: 1.1485131978988647
Validation loss: 1.8105464545629357

Epoch: 6| Step: 10
Training loss: 1.855436086654663
Validation loss: 1.7888028057672645

Epoch: 6| Step: 11
Training loss: 1.6820335388183594
Validation loss: 1.8265004055474394

Epoch: 6| Step: 12
Training loss: 0.9345486164093018
Validation loss: 1.7993408582543815

Epoch: 6| Step: 13
Training loss: 0.655285120010376
Validation loss: 1.7575811288690055

Epoch: 300| Step: 0
Training loss: 1.4114315509796143
Validation loss: 1.8136292144816408

Epoch: 6| Step: 1
Training loss: 1.100744605064392
Validation loss: 1.7929223750227241

Epoch: 6| Step: 2
Training loss: 1.8784363269805908
Validation loss: 1.8154004978877243

Epoch: 6| Step: 3
Training loss: 1.263812780380249
Validation loss: 1.8180034570796515

Epoch: 6| Step: 4
Training loss: 1.2831592559814453
Validation loss: 1.7801762652653519

Epoch: 6| Step: 5
Training loss: 1.060457706451416
Validation loss: 1.8180023752233034

Epoch: 6| Step: 6
Training loss: 1.4130076169967651
Validation loss: 1.7580562150606545

Epoch: 6| Step: 7
Training loss: 1.4583790302276611
Validation loss: 1.7977591009550198

Epoch: 6| Step: 8
Training loss: 1.5501210689544678
Validation loss: 1.7974491965386175

Epoch: 6| Step: 9
Training loss: 1.5458292961120605
Validation loss: 1.773421638755388

Epoch: 6| Step: 10
Training loss: 1.4512076377868652
Validation loss: 1.830651751128576

Epoch: 6| Step: 11
Training loss: 1.0196847915649414
Validation loss: 1.8214739855899607

Epoch: 6| Step: 12
Training loss: 1.6314365863800049
Validation loss: 1.7936663255896619

Epoch: 6| Step: 13
Training loss: 1.3555322885513306
Validation loss: 1.7747272599127986

Epoch: 301| Step: 0
Training loss: 0.9960957765579224
Validation loss: 1.7880504528681438

Epoch: 6| Step: 1
Training loss: 1.615429162979126
Validation loss: 1.790514240982712

Epoch: 6| Step: 2
Training loss: 1.6614758968353271
Validation loss: 1.8230332533518474

Epoch: 6| Step: 3
Training loss: 1.1350346803665161
Validation loss: 1.7744012801877913

Epoch: 6| Step: 4
Training loss: 1.6428678035736084
Validation loss: 1.748432324778649

Epoch: 6| Step: 5
Training loss: 1.3256901502609253
Validation loss: 1.7752931284648117

Epoch: 6| Step: 6
Training loss: 1.394953966140747
Validation loss: 1.7601706084384714

Epoch: 6| Step: 7
Training loss: 1.2508931159973145
Validation loss: 1.809792536561207

Epoch: 6| Step: 8
Training loss: 1.5093657970428467
Validation loss: 1.7412942314660678

Epoch: 6| Step: 9
Training loss: 1.34823477268219
Validation loss: 1.828985857707198

Epoch: 6| Step: 10
Training loss: 1.1116409301757812
Validation loss: 1.782578787496013

Epoch: 6| Step: 11
Training loss: 1.2162398099899292
Validation loss: 1.7995924103644587

Epoch: 6| Step: 12
Training loss: 1.489050030708313
Validation loss: 1.7921876010074411

Epoch: 6| Step: 13
Training loss: 1.9178698062896729
Validation loss: 1.8194487402516026

Epoch: 302| Step: 0
Training loss: 1.6473339796066284
Validation loss: 1.8142031841380621

Epoch: 6| Step: 1
Training loss: 1.23284912109375
Validation loss: 1.7801263896367883

Epoch: 6| Step: 2
Training loss: 0.8630290031433105
Validation loss: 1.8223330859215028

Epoch: 6| Step: 3
Training loss: 1.3788516521453857
Validation loss: 1.8646206573773456

Epoch: 6| Step: 4
Training loss: 1.0870088338851929
Validation loss: 1.8837221642976165

Epoch: 6| Step: 5
Training loss: 1.4039578437805176
Validation loss: 1.886658122462611

Epoch: 6| Step: 6
Training loss: 0.9745415449142456
Validation loss: 1.8070576613949192

Epoch: 6| Step: 7
Training loss: 1.8369840383529663
Validation loss: 1.8002355816543743

Epoch: 6| Step: 8
Training loss: 1.529249668121338
Validation loss: 1.760898309369241

Epoch: 6| Step: 9
Training loss: 1.1403957605361938
Validation loss: 1.8038646405743015

Epoch: 6| Step: 10
Training loss: 1.7924144268035889
Validation loss: 1.761159327722365

Epoch: 6| Step: 11
Training loss: 1.6953070163726807
Validation loss: 1.8143824582458825

Epoch: 6| Step: 12
Training loss: 0.8963831067085266
Validation loss: 1.771148798286274

Epoch: 6| Step: 13
Training loss: 1.9060673713684082
Validation loss: 1.8022256025704004

Epoch: 303| Step: 0
Training loss: 1.3731095790863037
Validation loss: 1.7950642544736144

Epoch: 6| Step: 1
Training loss: 1.1773957014083862
Validation loss: 1.7603460511853617

Epoch: 6| Step: 2
Training loss: 1.3936903476715088
Validation loss: 1.7759092879551712

Epoch: 6| Step: 3
Training loss: 1.5051276683807373
Validation loss: 1.7916979584642636

Epoch: 6| Step: 4
Training loss: 1.5812479257583618
Validation loss: 1.7551550352445213

Epoch: 6| Step: 5
Training loss: 1.1451301574707031
Validation loss: 1.7995089933436403

Epoch: 6| Step: 6
Training loss: 1.3175619840621948
Validation loss: 1.785261813030448

Epoch: 6| Step: 7
Training loss: 1.4460296630859375
Validation loss: 1.7803605961543258

Epoch: 6| Step: 8
Training loss: 1.9119594097137451
Validation loss: 1.78753650060264

Epoch: 6| Step: 9
Training loss: 0.9041919112205505
Validation loss: 1.7991434963800574

Epoch: 6| Step: 10
Training loss: 1.4652992486953735
Validation loss: 1.7914418674284411

Epoch: 6| Step: 11
Training loss: 2.042417287826538
Validation loss: 1.7789480417005477

Epoch: 6| Step: 12
Training loss: 1.0289896726608276
Validation loss: 1.8123847002624183

Epoch: 6| Step: 13
Training loss: 1.4600328207015991
Validation loss: 1.799943434294834

Epoch: 304| Step: 0
Training loss: 1.7744593620300293
Validation loss: 1.8198568359498055

Epoch: 6| Step: 1
Training loss: 1.369999885559082
Validation loss: 1.8191644876233992

Epoch: 6| Step: 2
Training loss: 1.6347825527191162
Validation loss: 1.7735791949815647

Epoch: 6| Step: 3
Training loss: 1.1946614980697632
Validation loss: 1.8029695364736742

Epoch: 6| Step: 4
Training loss: 1.0481743812561035
Validation loss: 1.8208495340039652

Epoch: 6| Step: 5
Training loss: 1.4531810283660889
Validation loss: 1.7876054330538678

Epoch: 6| Step: 6
Training loss: 1.4219119548797607
Validation loss: 1.8175213580490441

Epoch: 6| Step: 7
Training loss: 1.0575997829437256
Validation loss: 1.8104645462446316

Epoch: 6| Step: 8
Training loss: 1.4336990118026733
Validation loss: 1.79278810562626

Epoch: 6| Step: 9
Training loss: 1.7016456127166748
Validation loss: 1.820164224152924

Epoch: 6| Step: 10
Training loss: 1.2659716606140137
Validation loss: 1.787321481653439

Epoch: 6| Step: 11
Training loss: 0.9564900398254395
Validation loss: 1.7899148412930068

Epoch: 6| Step: 12
Training loss: 1.0467138290405273
Validation loss: 1.7656243078170284

Epoch: 6| Step: 13
Training loss: 1.6775583028793335
Validation loss: 1.7998190925967308

Epoch: 305| Step: 0
Training loss: 1.2673890590667725
Validation loss: 1.7765844829620854

Epoch: 6| Step: 1
Training loss: 1.3770118951797485
Validation loss: 1.8001229891213038

Epoch: 6| Step: 2
Training loss: 1.9958055019378662
Validation loss: 1.7666901465385192

Epoch: 6| Step: 3
Training loss: 1.2638992071151733
Validation loss: 1.759664753431915

Epoch: 6| Step: 4
Training loss: 1.2732715606689453
Validation loss: 1.8166496676783408

Epoch: 6| Step: 5
Training loss: 1.5561861991882324
Validation loss: 1.7603712376727854

Epoch: 6| Step: 6
Training loss: 1.034153938293457
Validation loss: 1.8413325304626136

Epoch: 6| Step: 7
Training loss: 1.5536891222000122
Validation loss: 1.7736849188804626

Epoch: 6| Step: 8
Training loss: 0.6632489562034607
Validation loss: 1.7537480092817737

Epoch: 6| Step: 9
Training loss: 1.0426281690597534
Validation loss: 1.7417085555291945

Epoch: 6| Step: 10
Training loss: 1.089160442352295
Validation loss: 1.8017727405794206

Epoch: 6| Step: 11
Training loss: 1.827000379562378
Validation loss: 1.7934793913236229

Epoch: 6| Step: 12
Training loss: 2.2674787044525146
Validation loss: 1.7886016676502843

Epoch: 6| Step: 13
Training loss: 0.9597814083099365
Validation loss: 1.7519057540483371

Epoch: 306| Step: 0
Training loss: 1.3886489868164062
Validation loss: 1.808102943563974

Epoch: 6| Step: 1
Training loss: 1.1368203163146973
Validation loss: 1.8141859654457337

Epoch: 6| Step: 2
Training loss: 1.5337337255477905
Validation loss: 1.837595675581245

Epoch: 6| Step: 3
Training loss: 1.0749247074127197
Validation loss: 1.7846705323906356

Epoch: 6| Step: 4
Training loss: 1.2094812393188477
Validation loss: 1.8117135493986067

Epoch: 6| Step: 5
Training loss: 1.2946484088897705
Validation loss: 1.8240041848151916

Epoch: 6| Step: 6
Training loss: 1.4625011682510376
Validation loss: 1.8174562108132146

Epoch: 6| Step: 7
Training loss: 1.5270212888717651
Validation loss: 1.8239707023866716

Epoch: 6| Step: 8
Training loss: 1.4440479278564453
Validation loss: 1.7753244958898073

Epoch: 6| Step: 9
Training loss: 0.9596855640411377
Validation loss: 1.8059525771807599

Epoch: 6| Step: 10
Training loss: 1.2066166400909424
Validation loss: 1.7962060589944162

Epoch: 6| Step: 11
Training loss: 1.652733564376831
Validation loss: 1.801536371631007

Epoch: 6| Step: 12
Training loss: 1.369808554649353
Validation loss: 1.7501527545272664

Epoch: 6| Step: 13
Training loss: 2.183407783508301
Validation loss: 1.7802463423821233

Epoch: 307| Step: 0
Training loss: 0.601272463798523
Validation loss: 1.7574114197043962

Epoch: 6| Step: 1
Training loss: 2.1577930450439453
Validation loss: 1.7675111498883975

Epoch: 6| Step: 2
Training loss: 1.4326226711273193
Validation loss: 1.8192350531137118

Epoch: 6| Step: 3
Training loss: 0.7176741361618042
Validation loss: 1.7466946507012973

Epoch: 6| Step: 4
Training loss: 1.598419427871704
Validation loss: 1.772045479025892

Epoch: 6| Step: 5
Training loss: 0.9070295095443726
Validation loss: 1.785380612137497

Epoch: 6| Step: 6
Training loss: 1.236075758934021
Validation loss: 1.8164700590154177

Epoch: 6| Step: 7
Training loss: 1.537117838859558
Validation loss: 1.7798713381572435

Epoch: 6| Step: 8
Training loss: 1.1129851341247559
Validation loss: 1.7780203011728102

Epoch: 6| Step: 9
Training loss: 1.6782071590423584
Validation loss: 1.740496067590611

Epoch: 6| Step: 10
Training loss: 1.611840844154358
Validation loss: 1.770064115524292

Epoch: 6| Step: 11
Training loss: 1.1998186111450195
Validation loss: 1.7603823741277058

Epoch: 6| Step: 12
Training loss: 1.095308542251587
Validation loss: 1.7925942764487317

Epoch: 6| Step: 13
Training loss: 1.7479685544967651
Validation loss: 1.7695669525413102

Epoch: 308| Step: 0
Training loss: 1.1658544540405273
Validation loss: 1.8042056868153233

Epoch: 6| Step: 1
Training loss: 1.2233082056045532
Validation loss: 1.7963013456713768

Epoch: 6| Step: 2
Training loss: 1.5093698501586914
Validation loss: 1.827465336809876

Epoch: 6| Step: 3
Training loss: 1.6563620567321777
Validation loss: 1.7583390935774772

Epoch: 6| Step: 4
Training loss: 0.9959065914154053
Validation loss: 1.8008931682955833

Epoch: 6| Step: 5
Training loss: 1.300751805305481
Validation loss: 1.7716294603963052

Epoch: 6| Step: 6
Training loss: 1.7159883975982666
Validation loss: 1.7968511325056835

Epoch: 6| Step: 7
Training loss: 1.6813890933990479
Validation loss: 1.7590147103032758

Epoch: 6| Step: 8
Training loss: 0.7392736673355103
Validation loss: 1.8325766722361247

Epoch: 6| Step: 9
Training loss: 1.3812509775161743
Validation loss: 1.7611973567675518

Epoch: 6| Step: 10
Training loss: 1.2680442333221436
Validation loss: 1.7972737396917036

Epoch: 6| Step: 11
Training loss: 1.3489737510681152
Validation loss: 1.7838366082919541

Epoch: 6| Step: 12
Training loss: 1.6224149465560913
Validation loss: 1.7604544008931806

Epoch: 6| Step: 13
Training loss: 1.6086797714233398
Validation loss: 1.7798463823974773

Epoch: 309| Step: 0
Training loss: 1.9320118427276611
Validation loss: 1.743150136804068

Epoch: 6| Step: 1
Training loss: 1.1859498023986816
Validation loss: 1.821137761556974

Epoch: 6| Step: 2
Training loss: 1.8810770511627197
Validation loss: 1.7827648270514704

Epoch: 6| Step: 3
Training loss: 1.194058895111084
Validation loss: 1.7992043213177753

Epoch: 6| Step: 4
Training loss: 1.624011516571045
Validation loss: 1.7797102902525215

Epoch: 6| Step: 5
Training loss: 0.9952059984207153
Validation loss: 1.7818363481952297

Epoch: 6| Step: 6
Training loss: 0.794107973575592
Validation loss: 1.785530073668367

Epoch: 6| Step: 7
Training loss: 1.0120729207992554
Validation loss: 1.808842420578003

Epoch: 6| Step: 8
Training loss: 1.7518864870071411
Validation loss: 1.7610059938123148

Epoch: 6| Step: 9
Training loss: 1.6299824714660645
Validation loss: 1.8185893156195199

Epoch: 6| Step: 10
Training loss: 1.1814954280853271
Validation loss: 1.7936017897821241

Epoch: 6| Step: 11
Training loss: 1.3195960521697998
Validation loss: 1.7634602644110238

Epoch: 6| Step: 12
Training loss: 1.3825265169143677
Validation loss: 1.802012348687777

Epoch: 6| Step: 13
Training loss: 1.0790241956710815
Validation loss: 1.784774931528235

Epoch: 310| Step: 0
Training loss: 1.1772801876068115
Validation loss: 1.8398869614447317

Epoch: 6| Step: 1
Training loss: 1.694314956665039
Validation loss: 1.7641985352321337

Epoch: 6| Step: 2
Training loss: 1.0819734334945679
Validation loss: 1.7677807327239745

Epoch: 6| Step: 3
Training loss: 1.6491727828979492
Validation loss: 1.8338310846718409

Epoch: 6| Step: 4
Training loss: 1.2618910074234009
Validation loss: 1.8010938231663038

Epoch: 6| Step: 5
Training loss: 1.191359281539917
Validation loss: 1.8083096499084144

Epoch: 6| Step: 6
Training loss: 1.097611665725708
Validation loss: 1.776179527723661

Epoch: 6| Step: 7
Training loss: 1.2434009313583374
Validation loss: 1.783175076207807

Epoch: 6| Step: 8
Training loss: 1.3698647022247314
Validation loss: 1.7390192644570464

Epoch: 6| Step: 9
Training loss: 2.3333215713500977
Validation loss: 1.7666395928270073

Epoch: 6| Step: 10
Training loss: 1.1406077146530151
Validation loss: 1.7928267666088638

Epoch: 6| Step: 11
Training loss: 1.2444177865982056
Validation loss: 1.8027626122197797

Epoch: 6| Step: 12
Training loss: 1.288489818572998
Validation loss: 1.7579287918665076

Epoch: 6| Step: 13
Training loss: 1.364665150642395
Validation loss: 1.7719175341308757

Epoch: 311| Step: 0
Training loss: 1.5219483375549316
Validation loss: 1.788179600110618

Epoch: 6| Step: 1
Training loss: 1.456359624862671
Validation loss: 1.761044950895412

Epoch: 6| Step: 2
Training loss: 1.2752249240875244
Validation loss: 1.784917753229859

Epoch: 6| Step: 3
Training loss: 1.4116592407226562
Validation loss: 1.7478907569762199

Epoch: 6| Step: 4
Training loss: 0.7848078012466431
Validation loss: 1.8013655113917526

Epoch: 6| Step: 5
Training loss: 1.2385963201522827
Validation loss: 1.7955230666745094

Epoch: 6| Step: 6
Training loss: 0.8743020296096802
Validation loss: 1.7904509805863904

Epoch: 6| Step: 7
Training loss: 1.2628118991851807
Validation loss: 1.7672820809066936

Epoch: 6| Step: 8
Training loss: 1.2037556171417236
Validation loss: 1.748264103807429

Epoch: 6| Step: 9
Training loss: 1.7536511421203613
Validation loss: 1.7793412170102518

Epoch: 6| Step: 10
Training loss: 1.5818685293197632
Validation loss: 1.7955018243482035

Epoch: 6| Step: 11
Training loss: 1.31724214553833
Validation loss: 1.7811017331256662

Epoch: 6| Step: 12
Training loss: 1.6408939361572266
Validation loss: 1.7525050524742372

Epoch: 6| Step: 13
Training loss: 2.116929292678833
Validation loss: 1.8052176685743435

Epoch: 312| Step: 0
Training loss: 1.1069854497909546
Validation loss: 1.757229692192488

Epoch: 6| Step: 1
Training loss: 1.0136168003082275
Validation loss: 1.766220969538535

Epoch: 6| Step: 2
Training loss: 1.1068859100341797
Validation loss: 1.7785505684473182

Epoch: 6| Step: 3
Training loss: 1.1581119298934937
Validation loss: 1.7509099680890319

Epoch: 6| Step: 4
Training loss: 2.328179121017456
Validation loss: 1.79192727932366

Epoch: 6| Step: 5
Training loss: 1.2714849710464478
Validation loss: 1.7838088030456214

Epoch: 6| Step: 6
Training loss: 1.5856890678405762
Validation loss: 1.7654961873126287

Epoch: 6| Step: 7
Training loss: 1.360816478729248
Validation loss: 1.7930816886245564

Epoch: 6| Step: 8
Training loss: 1.5493593215942383
Validation loss: 1.7796958415738997

Epoch: 6| Step: 9
Training loss: 1.2138553857803345
Validation loss: 1.78237743531504

Epoch: 6| Step: 10
Training loss: 1.4452528953552246
Validation loss: 1.8349115335813133

Epoch: 6| Step: 11
Training loss: 0.9936140775680542
Validation loss: 1.8210025448952951

Epoch: 6| Step: 12
Training loss: 1.2433087825775146
Validation loss: 1.793775773817493

Epoch: 6| Step: 13
Training loss: 1.5297913551330566
Validation loss: 1.8271279424749396

Epoch: 313| Step: 0
Training loss: 1.042250394821167
Validation loss: 1.8479692859034385

Epoch: 6| Step: 1
Training loss: 1.3766460418701172
Validation loss: 1.8292866714539067

Epoch: 6| Step: 2
Training loss: 1.5015909671783447
Validation loss: 1.78585781076903

Epoch: 6| Step: 3
Training loss: 1.1602903604507446
Validation loss: 1.7806005849633166

Epoch: 6| Step: 4
Training loss: 1.3707395792007446
Validation loss: 1.8059170348669893

Epoch: 6| Step: 5
Training loss: 1.5861064195632935
Validation loss: 1.7713343071681198

Epoch: 6| Step: 6
Training loss: 1.9981520175933838
Validation loss: 1.7972865950676702

Epoch: 6| Step: 7
Training loss: 0.8174247145652771
Validation loss: 1.749855705486831

Epoch: 6| Step: 8
Training loss: 1.2177066802978516
Validation loss: 1.7649919679087978

Epoch: 6| Step: 9
Training loss: 1.3649260997772217
Validation loss: 1.7598872646208732

Epoch: 6| Step: 10
Training loss: 1.766648769378662
Validation loss: 1.743236073883631

Epoch: 6| Step: 11
Training loss: 1.2366340160369873
Validation loss: 1.7712890396835983

Epoch: 6| Step: 12
Training loss: 1.391907811164856
Validation loss: 1.784249064742878

Epoch: 6| Step: 13
Training loss: 1.0063986778259277
Validation loss: 1.795765176896126

Epoch: 314| Step: 0
Training loss: 1.7656127214431763
Validation loss: 1.7783868069289832

Epoch: 6| Step: 1
Training loss: 1.2727972269058228
Validation loss: 1.7374690322465793

Epoch: 6| Step: 2
Training loss: 1.7045081853866577
Validation loss: 1.783362788538779

Epoch: 6| Step: 3
Training loss: 1.402468204498291
Validation loss: 1.7780661967492872

Epoch: 6| Step: 4
Training loss: 1.1677846908569336
Validation loss: 1.8014534224746048

Epoch: 6| Step: 5
Training loss: 1.0873022079467773
Validation loss: 1.76943596588668

Epoch: 6| Step: 6
Training loss: 1.5193421840667725
Validation loss: 1.7519218537115282

Epoch: 6| Step: 7
Training loss: 1.4392430782318115
Validation loss: 1.8140740035682597

Epoch: 6| Step: 8
Training loss: 0.8839409947395325
Validation loss: 1.8096438043860978

Epoch: 6| Step: 9
Training loss: 1.7130862474441528
Validation loss: 1.7535460636179934

Epoch: 6| Step: 10
Training loss: 1.2266863584518433
Validation loss: 1.7867900786861297

Epoch: 6| Step: 11
Training loss: 1.7115371227264404
Validation loss: 1.7756327377852572

Epoch: 6| Step: 12
Training loss: 0.9823883771896362
Validation loss: 1.7733117534268288

Epoch: 6| Step: 13
Training loss: 1.255408525466919
Validation loss: 1.7759238032884495

Epoch: 315| Step: 0
Training loss: 1.443396806716919
Validation loss: 1.7595396682780275

Epoch: 6| Step: 1
Training loss: 1.4326157569885254
Validation loss: 1.7785622227576472

Epoch: 6| Step: 2
Training loss: 1.5309727191925049
Validation loss: 1.7854494074339509

Epoch: 6| Step: 3
Training loss: 0.8242987990379333
Validation loss: 1.8004596412822764

Epoch: 6| Step: 4
Training loss: 1.7056055068969727
Validation loss: 1.7415240310853528

Epoch: 6| Step: 5
Training loss: 1.4949711561203003
Validation loss: 1.7812096521418581

Epoch: 6| Step: 6
Training loss: 1.1196362972259521
Validation loss: 1.749102165622096

Epoch: 6| Step: 7
Training loss: 1.1027472019195557
Validation loss: 1.8116397703847578

Epoch: 6| Step: 8
Training loss: 1.284921407699585
Validation loss: 1.7507823128854074

Epoch: 6| Step: 9
Training loss: 1.3252695798873901
Validation loss: 1.7681628747652935

Epoch: 6| Step: 10
Training loss: 2.103940486907959
Validation loss: 1.765866252683824

Epoch: 6| Step: 11
Training loss: 1.45920991897583
Validation loss: 1.7720147691747195

Epoch: 6| Step: 12
Training loss: 1.0994436740875244
Validation loss: 1.7756858512919436

Epoch: 6| Step: 13
Training loss: 0.9201689958572388
Validation loss: 1.7780513994155391

Epoch: 316| Step: 0
Training loss: 1.4104316234588623
Validation loss: 1.775848518135727

Epoch: 6| Step: 1
Training loss: 1.6130812168121338
Validation loss: 1.8077656979201941

Epoch: 6| Step: 2
Training loss: 0.791978657245636
Validation loss: 1.807387210989511

Epoch: 6| Step: 3
Training loss: 1.3408994674682617
Validation loss: 1.857473296503867

Epoch: 6| Step: 4
Training loss: 2.0941059589385986
Validation loss: 1.8012218424068984

Epoch: 6| Step: 5
Training loss: 1.4301868677139282
Validation loss: 1.7910716931025188

Epoch: 6| Step: 6
Training loss: 1.0808008909225464
Validation loss: 1.7917423530291485

Epoch: 6| Step: 7
Training loss: 0.7425581216812134
Validation loss: 1.7550529510744157

Epoch: 6| Step: 8
Training loss: 1.2999670505523682
Validation loss: 1.7601234502689813

Epoch: 6| Step: 9
Training loss: 0.8732571601867676
Validation loss: 1.7653870582580566

Epoch: 6| Step: 10
Training loss: 1.2897686958312988
Validation loss: 1.75416011323211

Epoch: 6| Step: 11
Training loss: 1.0571696758270264
Validation loss: 1.769278254560245

Epoch: 6| Step: 12
Training loss: 2.195661783218384
Validation loss: 1.7118499150840185

Epoch: 6| Step: 13
Training loss: 1.4304287433624268
Validation loss: 1.7876813975713586

Epoch: 317| Step: 0
Training loss: 0.7061214447021484
Validation loss: 1.7542473821229831

Epoch: 6| Step: 1
Training loss: 1.2440881729125977
Validation loss: 1.7845230551176174

Epoch: 6| Step: 2
Training loss: 0.8662328720092773
Validation loss: 1.7294220091194235

Epoch: 6| Step: 3
Training loss: 2.1615524291992188
Validation loss: 1.781578997130035

Epoch: 6| Step: 4
Training loss: 1.2663837671279907
Validation loss: 1.7589763159392982

Epoch: 6| Step: 5
Training loss: 1.8852431774139404
Validation loss: 1.7976590587246803

Epoch: 6| Step: 6
Training loss: 1.169602870941162
Validation loss: 1.7577363162912347

Epoch: 6| Step: 7
Training loss: 1.526491641998291
Validation loss: 1.7475564005554363

Epoch: 6| Step: 8
Training loss: 0.9204592108726501
Validation loss: 1.7772767018246394

Epoch: 6| Step: 9
Training loss: 1.2218705415725708
Validation loss: 1.7821984111621816

Epoch: 6| Step: 10
Training loss: 1.5123977661132812
Validation loss: 1.8027280197348645

Epoch: 6| Step: 11
Training loss: 1.4902160167694092
Validation loss: 1.7728145084073466

Epoch: 6| Step: 12
Training loss: 1.2955207824707031
Validation loss: 1.800140570568782

Epoch: 6| Step: 13
Training loss: 1.3832048177719116
Validation loss: 1.8220068434233307

Epoch: 318| Step: 0
Training loss: 1.0681308507919312
Validation loss: 1.7726431341581448

Epoch: 6| Step: 1
Training loss: 1.541269302368164
Validation loss: 1.7991636876137025

Epoch: 6| Step: 2
Training loss: 0.8689613938331604
Validation loss: 1.8492664034648607

Epoch: 6| Step: 3
Training loss: 1.370397925376892
Validation loss: 1.8226288454506987

Epoch: 6| Step: 4
Training loss: 1.1013678312301636
Validation loss: 1.7907840321140904

Epoch: 6| Step: 5
Training loss: 1.7161314487457275
Validation loss: 1.7722705564191263

Epoch: 6| Step: 6
Training loss: 1.1611263751983643
Validation loss: 1.7423210900316957

Epoch: 6| Step: 7
Training loss: 1.592101812362671
Validation loss: 1.7721193567399056

Epoch: 6| Step: 8
Training loss: 1.630109429359436
Validation loss: 1.7980098698728828

Epoch: 6| Step: 9
Training loss: 1.5217177867889404
Validation loss: 1.781202208611273

Epoch: 6| Step: 10
Training loss: 1.2340174913406372
Validation loss: 1.762932647940933

Epoch: 6| Step: 11
Training loss: 1.0787869691848755
Validation loss: 1.7799217201048327

Epoch: 6| Step: 12
Training loss: 1.1501688957214355
Validation loss: 1.807288327524739

Epoch: 6| Step: 13
Training loss: 1.0591567754745483
Validation loss: 1.8247797130256571

Epoch: 319| Step: 0
Training loss: 1.0771963596343994
Validation loss: 1.7835379531306605

Epoch: 6| Step: 1
Training loss: 1.217067837715149
Validation loss: 1.770475617019079

Epoch: 6| Step: 2
Training loss: 1.1831303834915161
Validation loss: 1.76706527638179

Epoch: 6| Step: 3
Training loss: 1.824631929397583
Validation loss: 1.7584289196998841

Epoch: 6| Step: 4
Training loss: 1.427471399307251
Validation loss: 1.7078068384560205

Epoch: 6| Step: 5
Training loss: 1.1578571796417236
Validation loss: 1.7678293284549509

Epoch: 6| Step: 6
Training loss: 1.0619456768035889
Validation loss: 1.7840430364813855

Epoch: 6| Step: 7
Training loss: 1.0802068710327148
Validation loss: 1.7709530194600422

Epoch: 6| Step: 8
Training loss: 1.7063379287719727
Validation loss: 1.7415714058824765

Epoch: 6| Step: 9
Training loss: 1.368351936340332
Validation loss: 1.7616947607327533

Epoch: 6| Step: 10
Training loss: 1.2598114013671875
Validation loss: 1.7467853548706218

Epoch: 6| Step: 11
Training loss: 1.7036653757095337
Validation loss: 1.7586426722106112

Epoch: 6| Step: 12
Training loss: 1.666994571685791
Validation loss: 1.821488372741207

Epoch: 6| Step: 13
Training loss: 0.9042655229568481
Validation loss: 1.7694979688172698

Epoch: 320| Step: 0
Training loss: 1.446968674659729
Validation loss: 1.7781152225309802

Epoch: 6| Step: 1
Training loss: 1.4665155410766602
Validation loss: 1.8206596964149064

Epoch: 6| Step: 2
Training loss: 1.6290899515151978
Validation loss: 1.77711021900177

Epoch: 6| Step: 3
Training loss: 1.7272262573242188
Validation loss: 1.7992467752066992

Epoch: 6| Step: 4
Training loss: 0.8141085505485535
Validation loss: 1.838328302547496

Epoch: 6| Step: 5
Training loss: 1.3133772611618042
Validation loss: 1.8148220123783234

Epoch: 6| Step: 6
Training loss: 1.4387316703796387
Validation loss: 1.7916687124518937

Epoch: 6| Step: 7
Training loss: 1.220034122467041
Validation loss: 1.7561732517775668

Epoch: 6| Step: 8
Training loss: 1.4355485439300537
Validation loss: 1.7854025158830868

Epoch: 6| Step: 9
Training loss: 1.5891824960708618
Validation loss: 1.7442506077469035

Epoch: 6| Step: 10
Training loss: 1.029910683631897
Validation loss: 1.7845569874650689

Epoch: 6| Step: 11
Training loss: 1.2143363952636719
Validation loss: 1.7566229733087684

Epoch: 6| Step: 12
Training loss: 1.2279044389724731
Validation loss: 1.7662312574284051

Epoch: 6| Step: 13
Training loss: 1.034775733947754
Validation loss: 1.7611913450302616

Epoch: 321| Step: 0
Training loss: 0.9943639039993286
Validation loss: 1.8040790993680236

Epoch: 6| Step: 1
Training loss: 1.3582262992858887
Validation loss: 1.7864115827827043

Epoch: 6| Step: 2
Training loss: 0.9895569682121277
Validation loss: 1.7872417716569797

Epoch: 6| Step: 3
Training loss: 1.2051467895507812
Validation loss: 1.7713874565657748

Epoch: 6| Step: 4
Training loss: 1.4636411666870117
Validation loss: 1.7581314912406347

Epoch: 6| Step: 5
Training loss: 1.8026491403579712
Validation loss: 1.7573448317025298

Epoch: 6| Step: 6
Training loss: 1.9513479471206665
Validation loss: 1.7507167554670764

Epoch: 6| Step: 7
Training loss: 0.9083863496780396
Validation loss: 1.7914238437529533

Epoch: 6| Step: 8
Training loss: 1.896122694015503
Validation loss: 1.7435121382436445

Epoch: 6| Step: 9
Training loss: 1.3189783096313477
Validation loss: 1.7834459402227913

Epoch: 6| Step: 10
Training loss: 1.2646046876907349
Validation loss: 1.7622747510992072

Epoch: 6| Step: 11
Training loss: 1.118868112564087
Validation loss: 1.7539082855306647

Epoch: 6| Step: 12
Training loss: 1.100395917892456
Validation loss: 1.7931144506700578

Epoch: 6| Step: 13
Training loss: 0.8733924627304077
Validation loss: 1.7424603123818674

Epoch: 322| Step: 0
Training loss: 1.7224388122558594
Validation loss: 1.7246870225475681

Epoch: 6| Step: 1
Training loss: 0.8382658362388611
Validation loss: 1.749696163720982

Epoch: 6| Step: 2
Training loss: 0.8771737813949585
Validation loss: 1.8085532188415527

Epoch: 6| Step: 3
Training loss: 0.6828014254570007
Validation loss: 1.7919361578520907

Epoch: 6| Step: 4
Training loss: 1.0560401678085327
Validation loss: 1.726067864766685

Epoch: 6| Step: 5
Training loss: 2.3098621368408203
Validation loss: 1.7676732309402958

Epoch: 6| Step: 6
Training loss: 1.3595619201660156
Validation loss: 1.7862243870253205

Epoch: 6| Step: 7
Training loss: 1.3540406227111816
Validation loss: 1.796449606136609

Epoch: 6| Step: 8
Training loss: 1.1650723218917847
Validation loss: 1.7723991499152234

Epoch: 6| Step: 9
Training loss: 1.33070969581604
Validation loss: 1.7487694037857877

Epoch: 6| Step: 10
Training loss: 1.1925585269927979
Validation loss: 1.7387118172901932

Epoch: 6| Step: 11
Training loss: 1.3388452529907227
Validation loss: 1.7675531961584603

Epoch: 6| Step: 12
Training loss: 1.876374363899231
Validation loss: 1.7765409356804305

Epoch: 6| Step: 13
Training loss: 1.451420545578003
Validation loss: 1.7718889956833215

Epoch: 323| Step: 0
Training loss: 1.132502555847168
Validation loss: 1.7755656562825686

Epoch: 6| Step: 1
Training loss: 1.5461475849151611
Validation loss: 1.8112123832907727

Epoch: 6| Step: 2
Training loss: 1.0921106338500977
Validation loss: 1.7945709677152737

Epoch: 6| Step: 3
Training loss: 0.92596036195755
Validation loss: 1.7742824426261328

Epoch: 6| Step: 4
Training loss: 0.9766460657119751
Validation loss: 1.7662376460208689

Epoch: 6| Step: 5
Training loss: 1.2489677667617798
Validation loss: 1.7677467894810501

Epoch: 6| Step: 6
Training loss: 1.2575652599334717
Validation loss: 1.787788055276358

Epoch: 6| Step: 7
Training loss: 1.7713322639465332
Validation loss: 1.8101409148144465

Epoch: 6| Step: 8
Training loss: 1.6326212882995605
Validation loss: 1.7658651823638587

Epoch: 6| Step: 9
Training loss: 1.0957413911819458
Validation loss: 1.7831820172648276

Epoch: 6| Step: 10
Training loss: 1.7365700006484985
Validation loss: 1.7806120854552074

Epoch: 6| Step: 11
Training loss: 1.292918086051941
Validation loss: 1.7806152233513453

Epoch: 6| Step: 12
Training loss: 1.5377123355865479
Validation loss: 1.7629036275289391

Epoch: 6| Step: 13
Training loss: 1.2654021978378296
Validation loss: 1.7752683034507177

Epoch: 324| Step: 0
Training loss: 1.7341322898864746
Validation loss: 1.7769134172829248

Epoch: 6| Step: 1
Training loss: 1.4283347129821777
Validation loss: 1.7845362322304839

Epoch: 6| Step: 2
Training loss: 0.760761559009552
Validation loss: 1.7536186761753534

Epoch: 6| Step: 3
Training loss: 1.1343963146209717
Validation loss: 1.7796485372768935

Epoch: 6| Step: 4
Training loss: 1.6131013631820679
Validation loss: 1.723942006787946

Epoch: 6| Step: 5
Training loss: 1.8788063526153564
Validation loss: 1.7735299294994724

Epoch: 6| Step: 6
Training loss: 1.405288577079773
Validation loss: 1.771816954817823

Epoch: 6| Step: 7
Training loss: 0.8955429792404175
Validation loss: 1.7622643196454613

Epoch: 6| Step: 8
Training loss: 1.421274185180664
Validation loss: 1.825794021288554

Epoch: 6| Step: 9
Training loss: 1.137977123260498
Validation loss: 1.7527688831411383

Epoch: 6| Step: 10
Training loss: 1.4105032682418823
Validation loss: 1.783391785878007

Epoch: 6| Step: 11
Training loss: 1.1424001455307007
Validation loss: 1.7845758404783023

Epoch: 6| Step: 12
Training loss: 1.4835692644119263
Validation loss: 1.7690267588502617

Epoch: 6| Step: 13
Training loss: 0.8540155291557312
Validation loss: 1.7832127360887424

Epoch: 325| Step: 0
Training loss: 1.6555105447769165
Validation loss: 1.779221111728299

Epoch: 6| Step: 1
Training loss: 1.3889238834381104
Validation loss: 1.7905861780207644

Epoch: 6| Step: 2
Training loss: 1.2549412250518799
Validation loss: 1.8552019288462978

Epoch: 6| Step: 3
Training loss: 2.035658597946167
Validation loss: 1.8575667758141794

Epoch: 6| Step: 4
Training loss: 1.123132586479187
Validation loss: 1.8206875349885674

Epoch: 6| Step: 5
Training loss: 1.0710110664367676
Validation loss: 1.8051390417160527

Epoch: 6| Step: 6
Training loss: 1.234858512878418
Validation loss: 1.8279880195535638

Epoch: 6| Step: 7
Training loss: 0.813310980796814
Validation loss: 1.8292975092446933

Epoch: 6| Step: 8
Training loss: 1.3825280666351318
Validation loss: 1.784002237422492

Epoch: 6| Step: 9
Training loss: 1.456233263015747
Validation loss: 1.7798040784815305

Epoch: 6| Step: 10
Training loss: 1.4869235754013062
Validation loss: 1.78744315267891

Epoch: 6| Step: 11
Training loss: 1.2831175327301025
Validation loss: 1.7881105881865307

Epoch: 6| Step: 12
Training loss: 1.0143777132034302
Validation loss: 1.8171579863435479

Epoch: 6| Step: 13
Training loss: 1.3274824619293213
Validation loss: 1.764072049048639

Epoch: 326| Step: 0
Training loss: 1.5706236362457275
Validation loss: 1.7440329392751057

Epoch: 6| Step: 1
Training loss: 1.07436203956604
Validation loss: 1.736146967898133

Epoch: 6| Step: 2
Training loss: 1.3969125747680664
Validation loss: 1.755928716351909

Epoch: 6| Step: 3
Training loss: 1.2161896228790283
Validation loss: 1.763519464000579

Epoch: 6| Step: 4
Training loss: 1.3912873268127441
Validation loss: 1.7430151880428355

Epoch: 6| Step: 5
Training loss: 1.4187759160995483
Validation loss: 1.7538565204989525

Epoch: 6| Step: 6
Training loss: 1.041252613067627
Validation loss: 1.7476449820303148

Epoch: 6| Step: 7
Training loss: 1.9935053586959839
Validation loss: 1.7940135335409513

Epoch: 6| Step: 8
Training loss: 1.0476551055908203
Validation loss: 1.7913238758681922

Epoch: 6| Step: 9
Training loss: 1.0839974880218506
Validation loss: 1.763814849238242

Epoch: 6| Step: 10
Training loss: 1.5205585956573486
Validation loss: 1.768333254321929

Epoch: 6| Step: 11
Training loss: 1.2378711700439453
Validation loss: 1.8080331971568446

Epoch: 6| Step: 12
Training loss: 1.419384479522705
Validation loss: 1.7621228156551239

Epoch: 6| Step: 13
Training loss: 0.7241309285163879
Validation loss: 1.7829011153149348

Epoch: 327| Step: 0
Training loss: 1.1392204761505127
Validation loss: 1.7879180972294142

Epoch: 6| Step: 1
Training loss: 1.3085944652557373
Validation loss: 1.7625050557556974

Epoch: 6| Step: 2
Training loss: 1.030937910079956
Validation loss: 1.7236989967284664

Epoch: 6| Step: 3
Training loss: 1.1329848766326904
Validation loss: 1.774799523815032

Epoch: 6| Step: 4
Training loss: 1.194814920425415
Validation loss: 1.7746263165627756

Epoch: 6| Step: 5
Training loss: 1.2662074565887451
Validation loss: 1.7817499868331417

Epoch: 6| Step: 6
Training loss: 1.5049169063568115
Validation loss: 1.8343295986934374

Epoch: 6| Step: 7
Training loss: 1.7110707759857178
Validation loss: 1.796044345824949

Epoch: 6| Step: 8
Training loss: 1.686732292175293
Validation loss: 1.7614058768877419

Epoch: 6| Step: 9
Training loss: 1.6462833881378174
Validation loss: 1.7709056010810278

Epoch: 6| Step: 10
Training loss: 0.6961626410484314
Validation loss: 1.743991837706617

Epoch: 6| Step: 11
Training loss: 1.5101789236068726
Validation loss: 1.7793976952952724

Epoch: 6| Step: 12
Training loss: 1.160801649093628
Validation loss: 1.7790567067361647

Epoch: 6| Step: 13
Training loss: 1.1728079319000244
Validation loss: 1.7948873145605928

Epoch: 328| Step: 0
Training loss: 1.0262316465377808
Validation loss: 1.8132430250926683

Epoch: 6| Step: 1
Training loss: 2.0445685386657715
Validation loss: 1.7815936585908294

Epoch: 6| Step: 2
Training loss: 1.5400320291519165
Validation loss: 1.7458313331809094

Epoch: 6| Step: 3
Training loss: 1.2641868591308594
Validation loss: 1.7577353831260436

Epoch: 6| Step: 4
Training loss: 1.4965591430664062
Validation loss: 1.8029747252823205

Epoch: 6| Step: 5
Training loss: 1.1163976192474365
Validation loss: 1.7568172870143768

Epoch: 6| Step: 6
Training loss: 1.054332971572876
Validation loss: 1.7423969314944359

Epoch: 6| Step: 7
Training loss: 1.3147108554840088
Validation loss: 1.7065187295277913

Epoch: 6| Step: 8
Training loss: 1.3628910779953003
Validation loss: 1.7396896257195422

Epoch: 6| Step: 9
Training loss: 0.9192710518836975
Validation loss: 1.776070357650839

Epoch: 6| Step: 10
Training loss: 0.9757544994354248
Validation loss: 1.7522944993870233

Epoch: 6| Step: 11
Training loss: 1.1102486848831177
Validation loss: 1.7794491385900846

Epoch: 6| Step: 12
Training loss: 1.358109712600708
Validation loss: 1.7526785135269165

Epoch: 6| Step: 13
Training loss: 1.9255644083023071
Validation loss: 1.7662486850574453

Epoch: 329| Step: 0
Training loss: 0.9127006530761719
Validation loss: 1.7686300380255586

Epoch: 6| Step: 1
Training loss: 1.2122496366500854
Validation loss: 1.7600109807906612

Epoch: 6| Step: 2
Training loss: 1.3031349182128906
Validation loss: 1.7745904461030038

Epoch: 6| Step: 3
Training loss: 0.7377350330352783
Validation loss: 1.7569377345423545

Epoch: 6| Step: 4
Training loss: 0.8156023025512695
Validation loss: 1.7787379180231402

Epoch: 6| Step: 5
Training loss: 0.9916958808898926
Validation loss: 1.7919370769172587

Epoch: 6| Step: 6
Training loss: 0.9393478631973267
Validation loss: 1.80682703884699

Epoch: 6| Step: 7
Training loss: 1.5382249355316162
Validation loss: 1.8218260157492854

Epoch: 6| Step: 8
Training loss: 1.6404449939727783
Validation loss: 1.761339541404478

Epoch: 6| Step: 9
Training loss: 2.2744479179382324
Validation loss: 1.774357675224222

Epoch: 6| Step: 10
Training loss: 1.2267673015594482
Validation loss: 1.771386133727207

Epoch: 6| Step: 11
Training loss: 2.0102474689483643
Validation loss: 1.7379942786309026

Epoch: 6| Step: 12
Training loss: 1.2174477577209473
Validation loss: 1.7672497110982095

Epoch: 6| Step: 13
Training loss: 1.4163527488708496
Validation loss: 1.7543186859417987

Epoch: 330| Step: 0
Training loss: 1.1936581134796143
Validation loss: 1.7438688303834649

Epoch: 6| Step: 1
Training loss: 0.9311845898628235
Validation loss: 1.758607655443171

Epoch: 6| Step: 2
Training loss: 1.3669028282165527
Validation loss: 1.7639678703841342

Epoch: 6| Step: 3
Training loss: 0.7686929106712341
Validation loss: 1.7395110873765842

Epoch: 6| Step: 4
Training loss: 1.0269780158996582
Validation loss: 1.7486939430236816

Epoch: 6| Step: 5
Training loss: 1.4969661235809326
Validation loss: 1.7441078129635061

Epoch: 6| Step: 6
Training loss: 1.784142255783081
Validation loss: 1.7992330110201271

Epoch: 6| Step: 7
Training loss: 1.305083990097046
Validation loss: 1.7928945915673369

Epoch: 6| Step: 8
Training loss: 1.4048041105270386
Validation loss: 1.7801131099782965

Epoch: 6| Step: 9
Training loss: 1.0783414840698242
Validation loss: 1.759529561124822

Epoch: 6| Step: 10
Training loss: 1.0613696575164795
Validation loss: 1.769867443269299

Epoch: 6| Step: 11
Training loss: 1.0945801734924316
Validation loss: 1.7264222227117068

Epoch: 6| Step: 12
Training loss: 2.0711517333984375
Validation loss: 1.773945108536751

Epoch: 6| Step: 13
Training loss: 1.761027455329895
Validation loss: 1.7782748911970405

Epoch: 331| Step: 0
Training loss: 1.6135953664779663
Validation loss: 1.7815451622009277

Epoch: 6| Step: 1
Training loss: 0.9091063737869263
Validation loss: 1.793991873341222

Epoch: 6| Step: 2
Training loss: 0.7581106424331665
Validation loss: 1.779308783110752

Epoch: 6| Step: 3
Training loss: 0.9410840272903442
Validation loss: 1.742850847141717

Epoch: 6| Step: 4
Training loss: 1.3019969463348389
Validation loss: 1.7099119488910963

Epoch: 6| Step: 5
Training loss: 1.224200963973999
Validation loss: 1.7544150647296701

Epoch: 6| Step: 6
Training loss: 1.012782335281372
Validation loss: 1.7781517838919034

Epoch: 6| Step: 7
Training loss: 1.3348411321640015
Validation loss: 1.7610538992830502

Epoch: 6| Step: 8
Training loss: 1.5966336727142334
Validation loss: 1.7882536598431167

Epoch: 6| Step: 9
Training loss: 1.4031898975372314
Validation loss: 1.7756076576889201

Epoch: 6| Step: 10
Training loss: 1.146850824356079
Validation loss: 1.7810802613535235

Epoch: 6| Step: 11
Training loss: 1.385469675064087
Validation loss: 1.745730197557839

Epoch: 6| Step: 12
Training loss: 2.2064716815948486
Validation loss: 1.7654478575593682

Epoch: 6| Step: 13
Training loss: 1.5442101955413818
Validation loss: 1.7817013853339738

Epoch: 332| Step: 0
Training loss: 1.6182080507278442
Validation loss: 1.7605069696262319

Epoch: 6| Step: 1
Training loss: 1.1781284809112549
Validation loss: 1.707626018472897

Epoch: 6| Step: 2
Training loss: 1.679319143295288
Validation loss: 1.7582316206347557

Epoch: 6| Step: 3
Training loss: 1.6154696941375732
Validation loss: 1.782145502746746

Epoch: 6| Step: 4
Training loss: 0.9325200915336609
Validation loss: 1.7479605597834433

Epoch: 6| Step: 5
Training loss: 1.147165060043335
Validation loss: 1.8265615009492444

Epoch: 6| Step: 6
Training loss: 0.830862820148468
Validation loss: 1.760510116495112

Epoch: 6| Step: 7
Training loss: 1.0884521007537842
Validation loss: 1.7632946827078377

Epoch: 6| Step: 8
Training loss: 1.8577966690063477
Validation loss: 1.7469333525626891

Epoch: 6| Step: 9
Training loss: 1.0605213642120361
Validation loss: 1.7651126397553312

Epoch: 6| Step: 10
Training loss: 1.766632080078125
Validation loss: 1.765070225602837

Epoch: 6| Step: 11
Training loss: 1.5849504470825195
Validation loss: 1.7723859305022864

Epoch: 6| Step: 12
Training loss: 0.619857668876648
Validation loss: 1.768653811946992

Epoch: 6| Step: 13
Training loss: 1.073661208152771
Validation loss: 1.8057084134829942

Epoch: 333| Step: 0
Training loss: 0.9342109560966492
Validation loss: 1.801840264310119

Epoch: 6| Step: 1
Training loss: 1.448732852935791
Validation loss: 1.7758394428478774

Epoch: 6| Step: 2
Training loss: 1.3098199367523193
Validation loss: 1.7806024487300585

Epoch: 6| Step: 3
Training loss: 0.7013887763023376
Validation loss: 1.7953475418911184

Epoch: 6| Step: 4
Training loss: 1.3537532091140747
Validation loss: 1.767189759080128

Epoch: 6| Step: 5
Training loss: 1.5584478378295898
Validation loss: 1.7852450968116842

Epoch: 6| Step: 6
Training loss: 1.3160972595214844
Validation loss: 1.7971435439202093

Epoch: 6| Step: 7
Training loss: 1.8511366844177246
Validation loss: 1.790580318820092

Epoch: 6| Step: 8
Training loss: 1.9033918380737305
Validation loss: 1.7287170066628406

Epoch: 6| Step: 9
Training loss: 1.0354804992675781
Validation loss: 1.7473344161946287

Epoch: 6| Step: 10
Training loss: 1.3972960710525513
Validation loss: 1.7739064885723976

Epoch: 6| Step: 11
Training loss: 1.302880048751831
Validation loss: 1.7311861617590791

Epoch: 6| Step: 12
Training loss: 1.2043343782424927
Validation loss: 1.77560624512293

Epoch: 6| Step: 13
Training loss: 1.3321583271026611
Validation loss: 1.786369522412618

Epoch: 334| Step: 0
Training loss: 1.169612169265747
Validation loss: 1.7325127304241221

Epoch: 6| Step: 1
Training loss: 1.4989490509033203
Validation loss: 1.7429713145379098

Epoch: 6| Step: 2
Training loss: 1.4085397720336914
Validation loss: 1.7665478324377408

Epoch: 6| Step: 3
Training loss: 0.671931803226471
Validation loss: 1.7871210382830711

Epoch: 6| Step: 4
Training loss: 1.6432530879974365
Validation loss: 1.7998554014390515

Epoch: 6| Step: 5
Training loss: 1.216450810432434
Validation loss: 1.7642317305329025

Epoch: 6| Step: 6
Training loss: 1.1713505983352661
Validation loss: 1.7769657181155296

Epoch: 6| Step: 7
Training loss: 1.1681902408599854
Validation loss: 1.7593326799331173

Epoch: 6| Step: 8
Training loss: 1.3300764560699463
Validation loss: 1.7508535205676992

Epoch: 6| Step: 9
Training loss: 1.6938167810440063
Validation loss: 1.7799019890446817

Epoch: 6| Step: 10
Training loss: 1.7107632160186768
Validation loss: 1.747449282676943

Epoch: 6| Step: 11
Training loss: 0.9530707597732544
Validation loss: 1.7879343930111136

Epoch: 6| Step: 12
Training loss: 0.8655709624290466
Validation loss: 1.7912935902995448

Epoch: 6| Step: 13
Training loss: 1.0371897220611572
Validation loss: 1.7835076444892473

Epoch: 335| Step: 0
Training loss: 1.6230063438415527
Validation loss: 1.8111743773183515

Epoch: 6| Step: 1
Training loss: 1.3662879467010498
Validation loss: 1.8112862648502472

Epoch: 6| Step: 2
Training loss: 0.8821330070495605
Validation loss: 1.8003236324556413

Epoch: 6| Step: 3
Training loss: 1.5814738273620605
Validation loss: 1.7708423983666204

Epoch: 6| Step: 4
Training loss: 1.0868464708328247
Validation loss: 1.7491472446790306

Epoch: 6| Step: 5
Training loss: 1.0177710056304932
Validation loss: 1.7766696688949422

Epoch: 6| Step: 6
Training loss: 1.6299455165863037
Validation loss: 1.8089444714207803

Epoch: 6| Step: 7
Training loss: 0.8716277480125427
Validation loss: 1.7806684535036805

Epoch: 6| Step: 8
Training loss: 1.7076666355133057
Validation loss: 1.745530201542762

Epoch: 6| Step: 9
Training loss: 1.2578985691070557
Validation loss: 1.7690738272923294

Epoch: 6| Step: 10
Training loss: 1.527683138847351
Validation loss: 1.7976225191547024

Epoch: 6| Step: 11
Training loss: 1.1911126375198364
Validation loss: 1.7906280409905218

Epoch: 6| Step: 12
Training loss: 0.8379119634628296
Validation loss: 1.7748779763457596

Epoch: 6| Step: 13
Training loss: 1.4393723011016846
Validation loss: 1.7816102184275144

Epoch: 336| Step: 0
Training loss: 0.8155766725540161
Validation loss: 1.7538780320075251

Epoch: 6| Step: 1
Training loss: 1.2135984897613525
Validation loss: 1.7673370966347315

Epoch: 6| Step: 2
Training loss: 1.2480137348175049
Validation loss: 1.770826651204017

Epoch: 6| Step: 3
Training loss: 1.4859614372253418
Validation loss: 1.7439519602765319

Epoch: 6| Step: 4
Training loss: 1.31509268283844
Validation loss: 1.7700194158861715

Epoch: 6| Step: 5
Training loss: 1.1412363052368164
Validation loss: 1.7798880120759368

Epoch: 6| Step: 6
Training loss: 1.5023726224899292
Validation loss: 1.7768507260148243

Epoch: 6| Step: 7
Training loss: 1.3060089349746704
Validation loss: 1.7695254330993981

Epoch: 6| Step: 8
Training loss: 1.2108352184295654
Validation loss: 1.8061189856580508

Epoch: 6| Step: 9
Training loss: 1.9360325336456299
Validation loss: 1.767890868648406

Epoch: 6| Step: 10
Training loss: 1.288002371788025
Validation loss: 1.7821674013650546

Epoch: 6| Step: 11
Training loss: 1.1526896953582764
Validation loss: 1.7723808673120314

Epoch: 6| Step: 12
Training loss: 0.9767232537269592
Validation loss: 1.7978951597726474

Epoch: 6| Step: 13
Training loss: 1.5127805471420288
Validation loss: 1.7623281683973087

Epoch: 337| Step: 0
Training loss: 0.5766750574111938
Validation loss: 1.808310580509965

Epoch: 6| Step: 1
Training loss: 1.5304388999938965
Validation loss: 1.792961291087571

Epoch: 6| Step: 2
Training loss: 1.1664040088653564
Validation loss: 1.7344650542864235

Epoch: 6| Step: 3
Training loss: 1.7743017673492432
Validation loss: 1.7135619758277811

Epoch: 6| Step: 4
Training loss: 0.6112826466560364
Validation loss: 1.7286219045680056

Epoch: 6| Step: 5
Training loss: 0.9446669816970825
Validation loss: 1.7513923683474142

Epoch: 6| Step: 6
Training loss: 1.7621889114379883
Validation loss: 1.745663187837088

Epoch: 6| Step: 7
Training loss: 1.1241934299468994
Validation loss: 1.7679173087561002

Epoch: 6| Step: 8
Training loss: 1.333592414855957
Validation loss: 1.7581636380123835

Epoch: 6| Step: 9
Training loss: 1.8337563276290894
Validation loss: 1.7485825900108583

Epoch: 6| Step: 10
Training loss: 0.8966134190559387
Validation loss: 1.7621316012515817

Epoch: 6| Step: 11
Training loss: 1.284944772720337
Validation loss: 1.7819691152982815

Epoch: 6| Step: 12
Training loss: 1.4089022874832153
Validation loss: 1.7187344592104676

Epoch: 6| Step: 13
Training loss: 1.919289469718933
Validation loss: 1.7363592732337214

Epoch: 338| Step: 0
Training loss: 1.6035301685333252
Validation loss: 1.7762628434806742

Epoch: 6| Step: 1
Training loss: 0.9732841849327087
Validation loss: 1.8177150680172829

Epoch: 6| Step: 2
Training loss: 1.1170743703842163
Validation loss: 1.7846630645054642

Epoch: 6| Step: 3
Training loss: 0.7730735540390015
Validation loss: 1.7852770666922293

Epoch: 6| Step: 4
Training loss: 0.7144253253936768
Validation loss: 1.7712787415391655

Epoch: 6| Step: 5
Training loss: 1.6703383922576904
Validation loss: 1.7727885451368106

Epoch: 6| Step: 6
Training loss: 0.6095577478408813
Validation loss: 1.7681526637846423

Epoch: 6| Step: 7
Training loss: 1.4846274852752686
Validation loss: 1.7767270739360521

Epoch: 6| Step: 8
Training loss: 1.1251404285430908
Validation loss: 1.7884017382898638

Epoch: 6| Step: 9
Training loss: 1.5015506744384766
Validation loss: 1.7543236978592411

Epoch: 6| Step: 10
Training loss: 1.2127439975738525
Validation loss: 1.7834703255725164

Epoch: 6| Step: 11
Training loss: 2.198512554168701
Validation loss: 1.7987148761749268

Epoch: 6| Step: 12
Training loss: 1.5070216655731201
Validation loss: 1.7594519148590744

Epoch: 6| Step: 13
Training loss: 1.005860686302185
Validation loss: 1.7667365727886077

Epoch: 339| Step: 0
Training loss: 1.4597662687301636
Validation loss: 1.768865736581946

Epoch: 6| Step: 1
Training loss: 1.6090030670166016
Validation loss: 1.752601045434193

Epoch: 6| Step: 2
Training loss: 1.4087555408477783
Validation loss: 1.7977138706432876

Epoch: 6| Step: 3
Training loss: 1.0940295457839966
Validation loss: 1.7758916911258493

Epoch: 6| Step: 4
Training loss: 1.3898568153381348
Validation loss: 1.781586097132775

Epoch: 6| Step: 5
Training loss: 1.1667133569717407
Validation loss: 1.771761445588963

Epoch: 6| Step: 6
Training loss: 1.576852798461914
Validation loss: 1.8080470126162294

Epoch: 6| Step: 7
Training loss: 1.0822746753692627
Validation loss: 1.7476216593096334

Epoch: 6| Step: 8
Training loss: 0.9810605049133301
Validation loss: 1.7780758219380532

Epoch: 6| Step: 9
Training loss: 1.2546809911727905
Validation loss: 1.7483890851338704

Epoch: 6| Step: 10
Training loss: 0.8512178659439087
Validation loss: 1.8137269404626661

Epoch: 6| Step: 11
Training loss: 1.296375036239624
Validation loss: 1.777413245170347

Epoch: 6| Step: 12
Training loss: 0.9435329437255859
Validation loss: 1.7757994256993777

Epoch: 6| Step: 13
Training loss: 1.18490469455719
Validation loss: 1.804073090194374

Epoch: 340| Step: 0
Training loss: 0.7089616060256958
Validation loss: 1.7542872813440138

Epoch: 6| Step: 1
Training loss: 1.4895479679107666
Validation loss: 1.760280780894782

Epoch: 6| Step: 2
Training loss: 1.1819921731948853
Validation loss: 1.7598919400604822

Epoch: 6| Step: 3
Training loss: 0.7066476345062256
Validation loss: 1.7478156807602092

Epoch: 6| Step: 4
Training loss: 1.3417086601257324
Validation loss: 1.7304708406489382

Epoch: 6| Step: 5
Training loss: 1.8705415725708008
Validation loss: 1.7647594367304156

Epoch: 6| Step: 6
Training loss: 1.8818552494049072
Validation loss: 1.784161780470161

Epoch: 6| Step: 7
Training loss: 1.2306585311889648
Validation loss: 1.8253663304031535

Epoch: 6| Step: 8
Training loss: 1.7555029392242432
Validation loss: 1.8232101663466422

Epoch: 6| Step: 9
Training loss: 1.2136943340301514
Validation loss: 1.7596392272621073

Epoch: 6| Step: 10
Training loss: 1.0137094259262085
Validation loss: 1.719041907659141

Epoch: 6| Step: 11
Training loss: 1.2654879093170166
Validation loss: 1.749262632862214

Epoch: 6| Step: 12
Training loss: 1.3093249797821045
Validation loss: 1.8141669457958591

Epoch: 6| Step: 13
Training loss: 0.741195797920227
Validation loss: 1.7664751096438336

Epoch: 341| Step: 0
Training loss: 0.9122869372367859
Validation loss: 1.792848075589826

Epoch: 6| Step: 1
Training loss: 1.5345215797424316
Validation loss: 1.7763349317735242

Epoch: 6| Step: 2
Training loss: 1.1679133176803589
Validation loss: 1.7918312267590595

Epoch: 6| Step: 3
Training loss: 1.1033897399902344
Validation loss: 1.7962823324306036

Epoch: 6| Step: 4
Training loss: 1.0390841960906982
Validation loss: 1.807191784663867

Epoch: 6| Step: 5
Training loss: 1.375973105430603
Validation loss: 1.7879398561293078

Epoch: 6| Step: 6
Training loss: 1.2844135761260986
Validation loss: 1.7581137918656873

Epoch: 6| Step: 7
Training loss: 1.1362502574920654
Validation loss: 1.7814387916236796

Epoch: 6| Step: 8
Training loss: 1.9812474250793457
Validation loss: 1.7292516782719602

Epoch: 6| Step: 9
Training loss: 1.0788942575454712
Validation loss: 1.7713145235533356

Epoch: 6| Step: 10
Training loss: 1.4925155639648438
Validation loss: 1.7495898597983903

Epoch: 6| Step: 11
Training loss: 1.3720531463623047
Validation loss: 1.7609580716779154

Epoch: 6| Step: 12
Training loss: 1.6971380710601807
Validation loss: 1.7779884210196875

Epoch: 6| Step: 13
Training loss: 0.4129602313041687
Validation loss: 1.7526898179002988

Epoch: 342| Step: 0
Training loss: 1.50044584274292
Validation loss: 1.7668598813395346

Epoch: 6| Step: 1
Training loss: 0.9358161091804504
Validation loss: 1.7201079348082184

Epoch: 6| Step: 2
Training loss: 1.1266365051269531
Validation loss: 1.7433950798485869

Epoch: 6| Step: 3
Training loss: 1.311690092086792
Validation loss: 1.7553864884120163

Epoch: 6| Step: 4
Training loss: 1.0126250982284546
Validation loss: 1.7706313184512559

Epoch: 6| Step: 5
Training loss: 1.1034778356552124
Validation loss: 1.7482541773908882

Epoch: 6| Step: 6
Training loss: 0.8213078379631042
Validation loss: 1.7785409035221222

Epoch: 6| Step: 7
Training loss: 1.6136198043823242
Validation loss: 1.7627637027412333

Epoch: 6| Step: 8
Training loss: 1.749704122543335
Validation loss: 1.778995701061782

Epoch: 6| Step: 9
Training loss: 1.0316667556762695
Validation loss: 1.7631097416723929

Epoch: 6| Step: 10
Training loss: 1.4403839111328125
Validation loss: 1.8102087564365839

Epoch: 6| Step: 11
Training loss: 1.6017186641693115
Validation loss: 1.7772144438118063

Epoch: 6| Step: 12
Training loss: 1.4025278091430664
Validation loss: 1.7897398753832745

Epoch: 6| Step: 13
Training loss: 1.1521912813186646
Validation loss: 1.7583603615401893

Epoch: 343| Step: 0
Training loss: 0.8514400720596313
Validation loss: 1.7360106283618557

Epoch: 6| Step: 1
Training loss: 1.1625008583068848
Validation loss: 1.735497317006511

Epoch: 6| Step: 2
Training loss: 1.237104892730713
Validation loss: 1.7594938457653087

Epoch: 6| Step: 3
Training loss: 0.9772263765335083
Validation loss: 1.758049411158408

Epoch: 6| Step: 4
Training loss: 1.0163755416870117
Validation loss: 1.7534194031069357

Epoch: 6| Step: 5
Training loss: 1.2594220638275146
Validation loss: 1.7751574016386462

Epoch: 6| Step: 6
Training loss: 1.6479146480560303
Validation loss: 1.7392533338198097

Epoch: 6| Step: 7
Training loss: 1.2363897562026978
Validation loss: 1.7534410633066648

Epoch: 6| Step: 8
Training loss: 1.5500097274780273
Validation loss: 1.7376255335346344

Epoch: 6| Step: 9
Training loss: 1.792663812637329
Validation loss: 1.770771248366243

Epoch: 6| Step: 10
Training loss: 0.941063404083252
Validation loss: 1.7492497300588956

Epoch: 6| Step: 11
Training loss: 1.4548652172088623
Validation loss: 1.7797049732618435

Epoch: 6| Step: 12
Training loss: 1.092789649963379
Validation loss: 1.7796068627347228

Epoch: 6| Step: 13
Training loss: 1.3492580652236938
Validation loss: 1.7864900981226275

Epoch: 344| Step: 0
Training loss: 0.7256087064743042
Validation loss: 1.7980700641550043

Epoch: 6| Step: 1
Training loss: 1.5816693305969238
Validation loss: 1.7649132333776003

Epoch: 6| Step: 2
Training loss: 1.5712060928344727
Validation loss: 1.8104325225276332

Epoch: 6| Step: 3
Training loss: 0.882024347782135
Validation loss: 1.8181349782533542

Epoch: 6| Step: 4
Training loss: 1.2160189151763916
Validation loss: 1.7806854478774532

Epoch: 6| Step: 5
Training loss: 1.1811671257019043
Validation loss: 1.8500895205364432

Epoch: 6| Step: 6
Training loss: 1.3192239999771118
Validation loss: 1.7894248616310857

Epoch: 6| Step: 7
Training loss: 1.8930561542510986
Validation loss: 1.7681841055552165

Epoch: 6| Step: 8
Training loss: 1.1693295240402222
Validation loss: 1.765565069772864

Epoch: 6| Step: 9
Training loss: 1.2577240467071533
Validation loss: 1.8046850927414433

Epoch: 6| Step: 10
Training loss: 1.217142105102539
Validation loss: 1.7781934968886837

Epoch: 6| Step: 11
Training loss: 1.3385324478149414
Validation loss: 1.7546960499978834

Epoch: 6| Step: 12
Training loss: 1.0030308961868286
Validation loss: 1.7272447360459195

Epoch: 6| Step: 13
Training loss: 1.4493250846862793
Validation loss: 1.7558334553113548

Epoch: 345| Step: 0
Training loss: 1.0117583274841309
Validation loss: 1.8001152353902017

Epoch: 6| Step: 1
Training loss: 1.775974988937378
Validation loss: 1.7326631802384571

Epoch: 6| Step: 2
Training loss: 1.3616787195205688
Validation loss: 1.741463799630442

Epoch: 6| Step: 3
Training loss: 0.8373481035232544
Validation loss: 1.7396364058217695

Epoch: 6| Step: 4
Training loss: 0.6560746431350708
Validation loss: 1.7944267167839953

Epoch: 6| Step: 5
Training loss: 1.0304509401321411
Validation loss: 1.7646336760572208

Epoch: 6| Step: 6
Training loss: 1.1174030303955078
Validation loss: 1.799329497480905

Epoch: 6| Step: 7
Training loss: 1.3234254121780396
Validation loss: 1.7328284607138684

Epoch: 6| Step: 8
Training loss: 1.1990540027618408
Validation loss: 1.7364929017200266

Epoch: 6| Step: 9
Training loss: 1.4208731651306152
Validation loss: 1.755232713555777

Epoch: 6| Step: 10
Training loss: 1.5817248821258545
Validation loss: 1.794597884660126

Epoch: 6| Step: 11
Training loss: 0.9698326587677002
Validation loss: 1.7964863943797287

Epoch: 6| Step: 12
Training loss: 1.5665698051452637
Validation loss: 1.7909728096377464

Epoch: 6| Step: 13
Training loss: 1.995617151260376
Validation loss: 1.7734924042096702

Epoch: 346| Step: 0
Training loss: 0.8692185878753662
Validation loss: 1.7547482777667303

Epoch: 6| Step: 1
Training loss: 1.5335211753845215
Validation loss: 1.7560685706394974

Epoch: 6| Step: 2
Training loss: 1.499021291732788
Validation loss: 1.800043862353089

Epoch: 6| Step: 3
Training loss: 0.9242347478866577
Validation loss: 1.756363502112768

Epoch: 6| Step: 4
Training loss: 1.1503068208694458
Validation loss: 1.785899378920114

Epoch: 6| Step: 5
Training loss: 1.458388328552246
Validation loss: 1.754174219664707

Epoch: 6| Step: 6
Training loss: 0.9231154918670654
Validation loss: 1.7509497288734681

Epoch: 6| Step: 7
Training loss: 1.4960687160491943
Validation loss: 1.812187494770173

Epoch: 6| Step: 8
Training loss: 1.123746633529663
Validation loss: 1.741061746433217

Epoch: 6| Step: 9
Training loss: 1.1895666122436523
Validation loss: 1.7497846593138993

Epoch: 6| Step: 10
Training loss: 1.4758360385894775
Validation loss: 1.7289721042879167

Epoch: 6| Step: 11
Training loss: 1.4479900598526
Validation loss: 1.7572449791815974

Epoch: 6| Step: 12
Training loss: 1.303987741470337
Validation loss: 1.7232995366537442

Epoch: 6| Step: 13
Training loss: 1.2425036430358887
Validation loss: 1.7589481992106284

Epoch: 347| Step: 0
Training loss: 1.189225196838379
Validation loss: 1.7017323445248347

Epoch: 6| Step: 1
Training loss: 0.9550268650054932
Validation loss: 1.7674981227485083

Epoch: 6| Step: 2
Training loss: 1.5321060419082642
Validation loss: 1.7471459642533334

Epoch: 6| Step: 3
Training loss: 1.0387852191925049
Validation loss: 1.7450335525697278

Epoch: 6| Step: 4
Training loss: 1.5954252481460571
Validation loss: 1.7735040956927883

Epoch: 6| Step: 5
Training loss: 0.8852885365486145
Validation loss: 1.808869610550583

Epoch: 6| Step: 6
Training loss: 1.9765336513519287
Validation loss: 1.7181786157751595

Epoch: 6| Step: 7
Training loss: 0.9494396448135376
Validation loss: 1.8184883491967314

Epoch: 6| Step: 8
Training loss: 1.3367098569869995
Validation loss: 1.7639453693102765

Epoch: 6| Step: 9
Training loss: 1.0046418905258179
Validation loss: 1.7619204598088418

Epoch: 6| Step: 10
Training loss: 1.3941638469696045
Validation loss: 1.8074299443152644

Epoch: 6| Step: 11
Training loss: 1.4529919624328613
Validation loss: 1.7476230385482951

Epoch: 6| Step: 12
Training loss: 1.2430808544158936
Validation loss: 1.741068810544988

Epoch: 6| Step: 13
Training loss: 1.2007942199707031
Validation loss: 1.772916591295632

Epoch: 348| Step: 0
Training loss: 1.271031379699707
Validation loss: 1.7991501169819986

Epoch: 6| Step: 1
Training loss: 1.2115097045898438
Validation loss: 1.7661265865448983

Epoch: 6| Step: 2
Training loss: 1.1185381412506104
Validation loss: 1.7547936952242287

Epoch: 6| Step: 3
Training loss: 0.9610359072685242
Validation loss: 1.7556751979294645

Epoch: 6| Step: 4
Training loss: 1.7380404472351074
Validation loss: 1.7391774359569754

Epoch: 6| Step: 5
Training loss: 1.0728299617767334
Validation loss: 1.8046492479180778

Epoch: 6| Step: 6
Training loss: 0.49852079153060913
Validation loss: 1.7468365533377535

Epoch: 6| Step: 7
Training loss: 1.4356739521026611
Validation loss: 1.7383308026098436

Epoch: 6| Step: 8
Training loss: 1.3193402290344238
Validation loss: 1.742117617719917

Epoch: 6| Step: 9
Training loss: 0.9560683965682983
Validation loss: 1.763728259712137

Epoch: 6| Step: 10
Training loss: 0.999703586101532
Validation loss: 1.7666657073523409

Epoch: 6| Step: 11
Training loss: 1.7926470041275024
Validation loss: 1.7454899664848083

Epoch: 6| Step: 12
Training loss: 1.330881953239441
Validation loss: 1.7380196548277331

Epoch: 6| Step: 13
Training loss: 2.085214138031006
Validation loss: 1.7416103719383158

Epoch: 349| Step: 0
Training loss: 1.4330658912658691
Validation loss: 1.756354425543098

Epoch: 6| Step: 1
Training loss: 1.1226496696472168
Validation loss: 1.7567763841280373

Epoch: 6| Step: 2
Training loss: 1.0722620487213135
Validation loss: 1.7642384267622424

Epoch: 6| Step: 3
Training loss: 1.1035726070404053
Validation loss: 1.751533313464093

Epoch: 6| Step: 4
Training loss: 1.2330529689788818
Validation loss: 1.7457284978640977

Epoch: 6| Step: 5
Training loss: 1.7306681871414185
Validation loss: 1.8149082814493487

Epoch: 6| Step: 6
Training loss: 0.9375056624412537
Validation loss: 1.7368911863655172

Epoch: 6| Step: 7
Training loss: 1.6976453065872192
Validation loss: 1.7793555990342171

Epoch: 6| Step: 8
Training loss: 1.0998120307922363
Validation loss: 1.749289571598012

Epoch: 6| Step: 9
Training loss: 1.216589093208313
Validation loss: 1.7192192551910237

Epoch: 6| Step: 10
Training loss: 1.2667629718780518
Validation loss: 1.751611203275701

Epoch: 6| Step: 11
Training loss: 0.9442895650863647
Validation loss: 1.7831578126517675

Epoch: 6| Step: 12
Training loss: 1.0936250686645508
Validation loss: 1.767121366275254

Epoch: 6| Step: 13
Training loss: 1.1880536079406738
Validation loss: 1.7301349178437264

Epoch: 350| Step: 0
Training loss: 1.3358676433563232
Validation loss: 1.7391256260615524

Epoch: 6| Step: 1
Training loss: 1.1413183212280273
Validation loss: 1.7660747792131157

Epoch: 6| Step: 2
Training loss: 1.3908483982086182
Validation loss: 1.723252341311465

Epoch: 6| Step: 3
Training loss: 1.4832561016082764
Validation loss: 1.751016036156685

Epoch: 6| Step: 4
Training loss: 1.0243724584579468
Validation loss: 1.7410154727197462

Epoch: 6| Step: 5
Training loss: 1.559790015220642
Validation loss: 1.7136934034286007

Epoch: 6| Step: 6
Training loss: 1.780973196029663
Validation loss: 1.759441880769627

Epoch: 6| Step: 7
Training loss: 1.4901177883148193
Validation loss: 1.7416887437143633

Epoch: 6| Step: 8
Training loss: 1.4015588760375977
Validation loss: 1.732761303583781

Epoch: 6| Step: 9
Training loss: 0.7638558149337769
Validation loss: 1.735884730533887

Epoch: 6| Step: 10
Training loss: 0.8151458501815796
Validation loss: 1.7435814565227878

Epoch: 6| Step: 11
Training loss: 0.450713574886322
Validation loss: 1.7761494831372333

Epoch: 6| Step: 12
Training loss: 1.6135642528533936
Validation loss: 1.8029534611650693

Epoch: 6| Step: 13
Training loss: 0.980854332447052
Validation loss: 1.81795661551978

Epoch: 351| Step: 0
Training loss: 0.9390743374824524
Validation loss: 1.7421813395715529

Epoch: 6| Step: 1
Training loss: 1.0717365741729736
Validation loss: 1.7979110030717746

Epoch: 6| Step: 2
Training loss: 0.7744562029838562
Validation loss: 1.7979432754619147

Epoch: 6| Step: 3
Training loss: 1.139939308166504
Validation loss: 1.7461416567525556

Epoch: 6| Step: 4
Training loss: 1.267948865890503
Validation loss: 1.7586643644558486

Epoch: 6| Step: 5
Training loss: 1.3903989791870117
Validation loss: 1.7275784759111301

Epoch: 6| Step: 6
Training loss: 0.7939680218696594
Validation loss: 1.7421975456258303

Epoch: 6| Step: 7
Training loss: 1.296507477760315
Validation loss: 1.7581230004628499

Epoch: 6| Step: 8
Training loss: 1.4816652536392212
Validation loss: 1.7428904271894885

Epoch: 6| Step: 9
Training loss: 1.5067503452301025
Validation loss: 1.71939552855748

Epoch: 6| Step: 10
Training loss: 1.4355841875076294
Validation loss: 1.7236471560693556

Epoch: 6| Step: 11
Training loss: 1.4307087659835815
Validation loss: 1.6992450914075297

Epoch: 6| Step: 12
Training loss: 1.3017958402633667
Validation loss: 1.7647067590426373

Epoch: 6| Step: 13
Training loss: 1.1647589206695557
Validation loss: 1.7689741670444448

Epoch: 352| Step: 0
Training loss: 1.2558375597000122
Validation loss: 1.7674140584084295

Epoch: 6| Step: 1
Training loss: 1.1767579317092896
Validation loss: 1.778595660322456

Epoch: 6| Step: 2
Training loss: 0.9785730838775635
Validation loss: 1.7610901594161987

Epoch: 6| Step: 3
Training loss: 1.2157871723175049
Validation loss: 1.7482529993980163

Epoch: 6| Step: 4
Training loss: 1.5056524276733398
Validation loss: 1.736252668083355

Epoch: 6| Step: 5
Training loss: 0.9207315444946289
Validation loss: 1.739688701527093

Epoch: 6| Step: 6
Training loss: 1.452987790107727
Validation loss: 1.7228941007327008

Epoch: 6| Step: 7
Training loss: 0.8931370973587036
Validation loss: 1.758245204084663

Epoch: 6| Step: 8
Training loss: 1.6903280019760132
Validation loss: 1.7416496469128517

Epoch: 6| Step: 9
Training loss: 1.3172764778137207
Validation loss: 1.737550207363662

Epoch: 6| Step: 10
Training loss: 1.06077241897583
Validation loss: 1.738511404683513

Epoch: 6| Step: 11
Training loss: 1.4490118026733398
Validation loss: 1.7394596825363815

Epoch: 6| Step: 12
Training loss: 1.3507816791534424
Validation loss: 1.7787839046088598

Epoch: 6| Step: 13
Training loss: 0.6431776285171509
Validation loss: 1.74865678305267

Epoch: 353| Step: 0
Training loss: 1.0942621231079102
Validation loss: 1.7886426154003348

Epoch: 6| Step: 1
Training loss: 1.834004521369934
Validation loss: 1.7698136478342035

Epoch: 6| Step: 2
Training loss: 0.8409677147865295
Validation loss: 1.7591897415858444

Epoch: 6| Step: 3
Training loss: 1.5271257162094116
Validation loss: 1.7398004454951133

Epoch: 6| Step: 4
Training loss: 1.4110679626464844
Validation loss: 1.7561651173458304

Epoch: 6| Step: 5
Training loss: 1.2693657875061035
Validation loss: 1.7361990623576666

Epoch: 6| Step: 6
Training loss: 0.9026581048965454
Validation loss: 1.7332355053194108

Epoch: 6| Step: 7
Training loss: 1.137613296508789
Validation loss: 1.788589923612533

Epoch: 6| Step: 8
Training loss: 1.6008810997009277
Validation loss: 1.7874413626168364

Epoch: 6| Step: 9
Training loss: 1.5863137245178223
Validation loss: 1.7460413543126916

Epoch: 6| Step: 10
Training loss: 1.2798261642456055
Validation loss: 1.738889491686257

Epoch: 6| Step: 11
Training loss: 0.8949779272079468
Validation loss: 1.7714639991842291

Epoch: 6| Step: 12
Training loss: 0.7210918664932251
Validation loss: 1.7862477969097834

Epoch: 6| Step: 13
Training loss: 1.3573261499404907
Validation loss: 1.7608526099112727

Epoch: 354| Step: 0
Training loss: 1.9645061492919922
Validation loss: 1.800318879465903

Epoch: 6| Step: 1
Training loss: 0.8396825194358826
Validation loss: 1.7270915187815183

Epoch: 6| Step: 2
Training loss: 1.2249879837036133
Validation loss: 1.7090100114063551

Epoch: 6| Step: 3
Training loss: 1.3956942558288574
Validation loss: 1.7579919561263053

Epoch: 6| Step: 4
Training loss: 1.2313566207885742
Validation loss: 1.739688265708185

Epoch: 6| Step: 5
Training loss: 1.3091950416564941
Validation loss: 1.7633466669308242

Epoch: 6| Step: 6
Training loss: 0.760424017906189
Validation loss: 1.794880933659051

Epoch: 6| Step: 7
Training loss: 1.1454651355743408
Validation loss: 1.7518241033759168

Epoch: 6| Step: 8
Training loss: 1.0123121738433838
Validation loss: 1.7494042137617707

Epoch: 6| Step: 9
Training loss: 1.3797811269760132
Validation loss: 1.768606424331665

Epoch: 6| Step: 10
Training loss: 0.9438390731811523
Validation loss: 1.7470896692686184

Epoch: 6| Step: 11
Training loss: 1.344241738319397
Validation loss: 1.7210444724687965

Epoch: 6| Step: 12
Training loss: 1.264235496520996
Validation loss: 1.7314429949688654

Epoch: 6| Step: 13
Training loss: 1.548454761505127
Validation loss: 1.7613704896742297

Epoch: 355| Step: 0
Training loss: 0.9543215036392212
Validation loss: 1.7284035810860254

Epoch: 6| Step: 1
Training loss: 1.5280358791351318
Validation loss: 1.7731000531104304

Epoch: 6| Step: 2
Training loss: 1.0114150047302246
Validation loss: 1.7417620638365388

Epoch: 6| Step: 3
Training loss: 0.7727607488632202
Validation loss: 1.7131748225099297

Epoch: 6| Step: 4
Training loss: 0.7678412199020386
Validation loss: 1.7804454962412517

Epoch: 6| Step: 5
Training loss: 0.4032547175884247
Validation loss: 1.7347925170775382

Epoch: 6| Step: 6
Training loss: 1.5321626663208008
Validation loss: 1.8028461433226062

Epoch: 6| Step: 7
Training loss: 1.1174836158752441
Validation loss: 1.7600797350688646

Epoch: 6| Step: 8
Training loss: 1.4841889142990112
Validation loss: 1.7328046406469038

Epoch: 6| Step: 9
Training loss: 1.4677859544754028
Validation loss: 1.7535235868987216

Epoch: 6| Step: 10
Training loss: 1.7763549089431763
Validation loss: 1.75688846136934

Epoch: 6| Step: 11
Training loss: 1.2348591089248657
Validation loss: 1.7572294819739558

Epoch: 6| Step: 12
Training loss: 1.365593433380127
Validation loss: 1.7895389603030296

Epoch: 6| Step: 13
Training loss: 2.5702247619628906
Validation loss: 1.8096033962824012

Epoch: 356| Step: 0
Training loss: 1.1156010627746582
Validation loss: 1.7779005291641399

Epoch: 6| Step: 1
Training loss: 1.905836582183838
Validation loss: 1.820850911960807

Epoch: 6| Step: 2
Training loss: 0.6958009004592896
Validation loss: 1.793276676567652

Epoch: 6| Step: 3
Training loss: 1.4398387670516968
Validation loss: 1.777641273313953

Epoch: 6| Step: 4
Training loss: 1.1974916458129883
Validation loss: 1.762304675194525

Epoch: 6| Step: 5
Training loss: 1.4822231531143188
Validation loss: 1.7516329916574622

Epoch: 6| Step: 6
Training loss: 0.8210870027542114
Validation loss: 1.7293948678560154

Epoch: 6| Step: 7
Training loss: 0.9045410752296448
Validation loss: 1.7478915183774886

Epoch: 6| Step: 8
Training loss: 1.025805950164795
Validation loss: 1.7519901208980109

Epoch: 6| Step: 9
Training loss: 1.1992030143737793
Validation loss: 1.7703744083322503

Epoch: 6| Step: 10
Training loss: 1.3147320747375488
Validation loss: 1.7086099757943103

Epoch: 6| Step: 11
Training loss: 1.1513839960098267
Validation loss: 1.7181633018678235

Epoch: 6| Step: 12
Training loss: 1.665142297744751
Validation loss: 1.6949984617130731

Epoch: 6| Step: 13
Training loss: 1.1524006128311157
Validation loss: 1.73262236707954

Epoch: 357| Step: 0
Training loss: 1.8072378635406494
Validation loss: 1.7243667494866155

Epoch: 6| Step: 1
Training loss: 1.4983606338500977
Validation loss: 1.7508822359064573

Epoch: 6| Step: 2
Training loss: 0.7463648319244385
Validation loss: 1.7677183843428088

Epoch: 6| Step: 3
Training loss: 1.0375558137893677
Validation loss: 1.7515723256654636

Epoch: 6| Step: 4
Training loss: 1.0674196481704712
Validation loss: 1.694301857743212

Epoch: 6| Step: 5
Training loss: 1.4183131456375122
Validation loss: 1.7294597241186327

Epoch: 6| Step: 6
Training loss: 1.0629312992095947
Validation loss: 1.7600144596510037

Epoch: 6| Step: 7
Training loss: 0.8035662770271301
Validation loss: 1.7830446458631946

Epoch: 6| Step: 8
Training loss: 0.8179230690002441
Validation loss: 1.796202536552183

Epoch: 6| Step: 9
Training loss: 1.198682427406311
Validation loss: 1.7931631175420617

Epoch: 6| Step: 10
Training loss: 1.2690106630325317
Validation loss: 1.806355050815049

Epoch: 6| Step: 11
Training loss: 0.9882493019104004
Validation loss: 1.803339881281699

Epoch: 6| Step: 12
Training loss: 1.7852681875228882
Validation loss: 1.755577132266055

Epoch: 6| Step: 13
Training loss: 1.792250156402588
Validation loss: 1.7840439606738347

Epoch: 358| Step: 0
Training loss: 1.028990387916565
Validation loss: 1.7735946806528236

Epoch: 6| Step: 1
Training loss: 1.1609766483306885
Validation loss: 1.7818607476449781

Epoch: 6| Step: 2
Training loss: 0.9982238411903381
Validation loss: 1.7910446325937908

Epoch: 6| Step: 3
Training loss: 1.2936606407165527
Validation loss: 1.6718502980406567

Epoch: 6| Step: 4
Training loss: 1.3717621564865112
Validation loss: 1.7388028893419492

Epoch: 6| Step: 5
Training loss: 1.1099586486816406
Validation loss: 1.7453665246245682

Epoch: 6| Step: 6
Training loss: 1.0860450267791748
Validation loss: 1.738813938633088

Epoch: 6| Step: 7
Training loss: 1.2695567607879639
Validation loss: 1.6811907163230322

Epoch: 6| Step: 8
Training loss: 1.1223673820495605
Validation loss: 1.7346424582184001

Epoch: 6| Step: 9
Training loss: 1.655135989189148
Validation loss: 1.7158119229860203

Epoch: 6| Step: 10
Training loss: 1.3606008291244507
Validation loss: 1.7550477955930976

Epoch: 6| Step: 11
Training loss: 1.14332115650177
Validation loss: 1.6981690365781066

Epoch: 6| Step: 12
Training loss: 0.6944228410720825
Validation loss: 1.7392459556620607

Epoch: 6| Step: 13
Training loss: 1.6692028045654297
Validation loss: 1.7564756306268836

Epoch: 359| Step: 0
Training loss: 1.1340935230255127
Validation loss: 1.712671882362776

Epoch: 6| Step: 1
Training loss: 1.2122137546539307
Validation loss: 1.7361736835971955

Epoch: 6| Step: 2
Training loss: 0.894511342048645
Validation loss: 1.7731589258358043

Epoch: 6| Step: 3
Training loss: 1.0311670303344727
Validation loss: 1.7388247200237807

Epoch: 6| Step: 4
Training loss: 1.24468195438385
Validation loss: 1.7748092810312908

Epoch: 6| Step: 5
Training loss: 1.2101119756698608
Validation loss: 1.7804695213994672

Epoch: 6| Step: 6
Training loss: 1.153076171875
Validation loss: 1.6897678721335627

Epoch: 6| Step: 7
Training loss: 1.6232373714447021
Validation loss: 1.7434714481394777

Epoch: 6| Step: 8
Training loss: 1.1650875806808472
Validation loss: 1.800353532196373

Epoch: 6| Step: 9
Training loss: 1.3988585472106934
Validation loss: 1.7506920958078036

Epoch: 6| Step: 10
Training loss: 0.8674594163894653
Validation loss: 1.7598379965751403

Epoch: 6| Step: 11
Training loss: 1.217880129814148
Validation loss: 1.759883383268951

Epoch: 6| Step: 12
Training loss: 1.4774006605148315
Validation loss: 1.7112343593310284

Epoch: 6| Step: 13
Training loss: 0.5753097534179688
Validation loss: 1.7747993853784376

Epoch: 360| Step: 0
Training loss: 0.8786515593528748
Validation loss: 1.7867661522280784

Epoch: 6| Step: 1
Training loss: 2.056466817855835
Validation loss: 1.7948484984777306

Epoch: 6| Step: 2
Training loss: 1.4909617900848389
Validation loss: 1.7755638501977409

Epoch: 6| Step: 3
Training loss: 1.3546476364135742
Validation loss: 1.7764715046010993

Epoch: 6| Step: 4
Training loss: 1.2634434700012207
Validation loss: 1.7380845328812957

Epoch: 6| Step: 5
Training loss: 1.262101173400879
Validation loss: 1.7975641745392994

Epoch: 6| Step: 6
Training loss: 1.1588886976242065
Validation loss: 1.809498942026528

Epoch: 6| Step: 7
Training loss: 0.8451940417289734
Validation loss: 1.776242127982519

Epoch: 6| Step: 8
Training loss: 1.1184980869293213
Validation loss: 1.7430298636036534

Epoch: 6| Step: 9
Training loss: 1.2443554401397705
Validation loss: 1.7425100406010945

Epoch: 6| Step: 10
Training loss: 0.9394266605377197
Validation loss: 1.7067379874567832

Epoch: 6| Step: 11
Training loss: 1.4427350759506226
Validation loss: 1.7388879150472663

Epoch: 6| Step: 12
Training loss: 0.5263408422470093
Validation loss: 1.7409522353961904

Epoch: 6| Step: 13
Training loss: 1.0582021474838257
Validation loss: 1.7252076864242554

Epoch: 361| Step: 0
Training loss: 0.718713104724884
Validation loss: 1.7760310480671544

Epoch: 6| Step: 1
Training loss: 0.8883953094482422
Validation loss: 1.7134043708924325

Epoch: 6| Step: 2
Training loss: 1.1114797592163086
Validation loss: 1.7749455359674269

Epoch: 6| Step: 3
Training loss: 0.9557428956031799
Validation loss: 1.7245050796898462

Epoch: 6| Step: 4
Training loss: 1.1292343139648438
Validation loss: 1.7567747869799215

Epoch: 6| Step: 5
Training loss: 0.8992916941642761
Validation loss: 1.7379481638631513

Epoch: 6| Step: 6
Training loss: 1.2833861112594604
Validation loss: 1.7239150039611324

Epoch: 6| Step: 7
Training loss: 1.7057693004608154
Validation loss: 1.7797782254475418

Epoch: 6| Step: 8
Training loss: 1.4826653003692627
Validation loss: 1.6964605546766711

Epoch: 6| Step: 9
Training loss: 0.9841645956039429
Validation loss: 1.757462796344552

Epoch: 6| Step: 10
Training loss: 1.0368638038635254
Validation loss: 1.7850364292821577

Epoch: 6| Step: 11
Training loss: 1.6001882553100586
Validation loss: 1.747087340201101

Epoch: 6| Step: 12
Training loss: 1.3187010288238525
Validation loss: 1.7232177270356046

Epoch: 6| Step: 13
Training loss: 1.701580286026001
Validation loss: 1.7872613001895208

Epoch: 362| Step: 0
Training loss: 0.9193214178085327
Validation loss: 1.7649672774858371

Epoch: 6| Step: 1
Training loss: 1.1770198345184326
Validation loss: 1.7755019895492061

Epoch: 6| Step: 2
Training loss: 1.4296486377716064
Validation loss: 1.7766477407947663

Epoch: 6| Step: 3
Training loss: 1.3488883972167969
Validation loss: 1.7038753801776516

Epoch: 6| Step: 4
Training loss: 1.4435653686523438
Validation loss: 1.7376116821842809

Epoch: 6| Step: 5
Training loss: 1.5318870544433594
Validation loss: 1.7663440217253983

Epoch: 6| Step: 6
Training loss: 0.743378758430481
Validation loss: 1.7321614552569646

Epoch: 6| Step: 7
Training loss: 1.6664230823516846
Validation loss: 1.7423084807652298

Epoch: 6| Step: 8
Training loss: 1.4711649417877197
Validation loss: 1.7108402290651876

Epoch: 6| Step: 9
Training loss: 0.8421803712844849
Validation loss: 1.7415910843879945

Epoch: 6| Step: 10
Training loss: 0.733026385307312
Validation loss: 1.7462124183613768

Epoch: 6| Step: 11
Training loss: 1.2783875465393066
Validation loss: 1.779729539348233

Epoch: 6| Step: 12
Training loss: 1.2267451286315918
Validation loss: 1.7531350620331303

Epoch: 6| Step: 13
Training loss: 1.0572761297225952
Validation loss: 1.7360097131421488

Epoch: 363| Step: 0
Training loss: 1.350324273109436
Validation loss: 1.7603242089671474

Epoch: 6| Step: 1
Training loss: 1.4695770740509033
Validation loss: 1.7432805286940707

Epoch: 6| Step: 2
Training loss: 0.6553778648376465
Validation loss: 1.6860548514191822

Epoch: 6| Step: 3
Training loss: 1.5500538349151611
Validation loss: 1.7294596190093665

Epoch: 6| Step: 4
Training loss: 1.3248164653778076
Validation loss: 1.763848288084871

Epoch: 6| Step: 5
Training loss: 0.9510824084281921
Validation loss: 1.767386737690177

Epoch: 6| Step: 6
Training loss: 0.936116099357605
Validation loss: 1.7558710049557429

Epoch: 6| Step: 7
Training loss: 1.4607839584350586
Validation loss: 1.7508824999614427

Epoch: 6| Step: 8
Training loss: 1.502750277519226
Validation loss: 1.7924036787402244

Epoch: 6| Step: 9
Training loss: 0.776573896408081
Validation loss: 1.7629271425226682

Epoch: 6| Step: 10
Training loss: 0.9488486051559448
Validation loss: 1.7718425053422169

Epoch: 6| Step: 11
Training loss: 1.268606424331665
Validation loss: 1.7553994232608425

Epoch: 6| Step: 12
Training loss: 1.5617294311523438
Validation loss: 1.7428021520696662

Epoch: 6| Step: 13
Training loss: 0.939177393913269
Validation loss: 1.7724519442486506

Epoch: 364| Step: 0
Training loss: 1.0612584352493286
Validation loss: 1.7755416772698844

Epoch: 6| Step: 1
Training loss: 1.0840774774551392
Validation loss: 1.7366627275302846

Epoch: 6| Step: 2
Training loss: 1.2377824783325195
Validation loss: 1.726964835197695

Epoch: 6| Step: 3
Training loss: 1.2531263828277588
Validation loss: 1.757992462445331

Epoch: 6| Step: 4
Training loss: 1.1589901447296143
Validation loss: 1.7908974283485002

Epoch: 6| Step: 5
Training loss: 1.5992770195007324
Validation loss: 1.7720280129422423

Epoch: 6| Step: 6
Training loss: 1.1289072036743164
Validation loss: 1.7107541125307801

Epoch: 6| Step: 7
Training loss: 1.2967376708984375
Validation loss: 1.7554780334554694

Epoch: 6| Step: 8
Training loss: 1.380807876586914
Validation loss: 1.7369219064712524

Epoch: 6| Step: 9
Training loss: 1.490311622619629
Validation loss: 1.723431476982691

Epoch: 6| Step: 10
Training loss: 1.0536420345306396
Validation loss: 1.7544279585602462

Epoch: 6| Step: 11
Training loss: 0.8684208393096924
Validation loss: 1.7143791631985736

Epoch: 6| Step: 12
Training loss: 0.8620615005493164
Validation loss: 1.7741672992706299

Epoch: 6| Step: 13
Training loss: 1.6992206573486328
Validation loss: 1.7572123081453386

Epoch: 365| Step: 0
Training loss: 1.0356467962265015
Validation loss: 1.7368158358399586

Epoch: 6| Step: 1
Training loss: 1.242995262145996
Validation loss: 1.7227061858741186

Epoch: 6| Step: 2
Training loss: 0.7803181409835815
Validation loss: 1.8346220959899247

Epoch: 6| Step: 3
Training loss: 1.0930840969085693
Validation loss: 1.799675049320344

Epoch: 6| Step: 4
Training loss: 0.9185329675674438
Validation loss: 1.795065938785512

Epoch: 6| Step: 5
Training loss: 1.1774629354476929
Validation loss: 1.765244633920731

Epoch: 6| Step: 6
Training loss: 0.8595818281173706
Validation loss: 1.8083078425417665

Epoch: 6| Step: 7
Training loss: 1.5905251502990723
Validation loss: 1.7355562563865417

Epoch: 6| Step: 8
Training loss: 1.1149852275848389
Validation loss: 1.708623937381211

Epoch: 6| Step: 9
Training loss: 1.4327807426452637
Validation loss: 1.7279762529557752

Epoch: 6| Step: 10
Training loss: 0.8284951448440552
Validation loss: 1.7246191822072512

Epoch: 6| Step: 11
Training loss: 1.6064677238464355
Validation loss: 1.7824714170989169

Epoch: 6| Step: 12
Training loss: 1.8465358018875122
Validation loss: 1.7874271164658249

Epoch: 6| Step: 13
Training loss: 1.198189377784729
Validation loss: 1.7681054966424101

Epoch: 366| Step: 0
Training loss: 1.4913108348846436
Validation loss: 1.76973960861083

Epoch: 6| Step: 1
Training loss: 0.9122254252433777
Validation loss: 1.765488363081409

Epoch: 6| Step: 2
Training loss: 1.2383813858032227
Validation loss: 1.75879664703082

Epoch: 6| Step: 3
Training loss: 1.781148076057434
Validation loss: 1.7606240677577194

Epoch: 6| Step: 4
Training loss: 1.2502598762512207
Validation loss: 1.7515339197651032

Epoch: 6| Step: 5
Training loss: 1.19868004322052
Validation loss: 1.7543040001264183

Epoch: 6| Step: 6
Training loss: 0.9742822051048279
Validation loss: 1.7853622064795545

Epoch: 6| Step: 7
Training loss: 1.6264903545379639
Validation loss: 1.714810876436131

Epoch: 6| Step: 8
Training loss: 1.3360648155212402
Validation loss: 1.7538882327336136

Epoch: 6| Step: 9
Training loss: 1.9769330024719238
Validation loss: 1.7364928722381592

Epoch: 6| Step: 10
Training loss: 0.4298924207687378
Validation loss: 1.704485083139071

Epoch: 6| Step: 11
Training loss: 0.9203809499740601
Validation loss: 1.7541768730327647

Epoch: 6| Step: 12
Training loss: 0.8230586051940918
Validation loss: 1.7035580950398599

Epoch: 6| Step: 13
Training loss: 0.5973088145256042
Validation loss: 1.7524885900558964

Epoch: 367| Step: 0
Training loss: 0.8398704528808594
Validation loss: 1.7398844470259964

Epoch: 6| Step: 1
Training loss: 1.1615052223205566
Validation loss: 1.7570112969285698

Epoch: 6| Step: 2
Training loss: 1.6954344511032104
Validation loss: 1.7491782275579308

Epoch: 6| Step: 3
Training loss: 0.7922091484069824
Validation loss: 1.7548985993990334

Epoch: 6| Step: 4
Training loss: 1.6069233417510986
Validation loss: 1.723079595514523

Epoch: 6| Step: 5
Training loss: 1.0903804302215576
Validation loss: 1.7019121864790558

Epoch: 6| Step: 6
Training loss: 1.2140967845916748
Validation loss: 1.758846785432549

Epoch: 6| Step: 7
Training loss: 0.7407482862472534
Validation loss: 1.7361906395163587

Epoch: 6| Step: 8
Training loss: 1.2759246826171875
Validation loss: 1.7336721369015273

Epoch: 6| Step: 9
Training loss: 0.692737877368927
Validation loss: 1.729481331763729

Epoch: 6| Step: 10
Training loss: 1.590113878250122
Validation loss: 1.7272111459444928

Epoch: 6| Step: 11
Training loss: 1.356552004814148
Validation loss: 1.7384907763491395

Epoch: 6| Step: 12
Training loss: 0.947516918182373
Validation loss: 1.7058030533534225

Epoch: 6| Step: 13
Training loss: 1.7179853916168213
Validation loss: 1.7423065516256517

Epoch: 368| Step: 0
Training loss: 1.2570302486419678
Validation loss: 1.8214679251434982

Epoch: 6| Step: 1
Training loss: 0.8067221641540527
Validation loss: 1.7134936689048685

Epoch: 6| Step: 2
Training loss: 1.0202252864837646
Validation loss: 1.80069657551345

Epoch: 6| Step: 3
Training loss: 1.4913893938064575
Validation loss: 1.7769561249722716

Epoch: 6| Step: 4
Training loss: 1.2613131999969482
Validation loss: 1.7722714139569191

Epoch: 6| Step: 5
Training loss: 1.4434690475463867
Validation loss: 1.8034288088480632

Epoch: 6| Step: 6
Training loss: 1.077143907546997
Validation loss: 1.7701749109452771

Epoch: 6| Step: 7
Training loss: 1.4529831409454346
Validation loss: 1.7424544634357575

Epoch: 6| Step: 8
Training loss: 1.2542210817337036
Validation loss: 1.7740234110945015

Epoch: 6| Step: 9
Training loss: 1.032033085823059
Validation loss: 1.7916783075178824

Epoch: 6| Step: 10
Training loss: 1.4613556861877441
Validation loss: 1.7815897772389073

Epoch: 6| Step: 11
Training loss: 0.9666007161140442
Validation loss: 1.7461581409618419

Epoch: 6| Step: 12
Training loss: 0.8227697610855103
Validation loss: 1.757761522005963

Epoch: 6| Step: 13
Training loss: 1.3699947595596313
Validation loss: 1.7502030608474568

Epoch: 369| Step: 0
Training loss: 1.1331411600112915
Validation loss: 1.765714309548819

Epoch: 6| Step: 1
Training loss: 0.624485194683075
Validation loss: 1.7324314950614847

Epoch: 6| Step: 2
Training loss: 0.9363937973976135
Validation loss: 1.761946580743277

Epoch: 6| Step: 3
Training loss: 1.7144477367401123
Validation loss: 1.735640089998963

Epoch: 6| Step: 4
Training loss: 0.7986305356025696
Validation loss: 1.6830359492250668

Epoch: 6| Step: 5
Training loss: 1.9705989360809326
Validation loss: 1.7578422407950125

Epoch: 6| Step: 6
Training loss: 1.5724071264266968
Validation loss: 1.763987365589347

Epoch: 6| Step: 7
Training loss: 1.182285189628601
Validation loss: 1.7334144153902609

Epoch: 6| Step: 8
Training loss: 0.998694896697998
Validation loss: 1.7644786642443748

Epoch: 6| Step: 9
Training loss: 0.8999060392379761
Validation loss: 1.7551643662555243

Epoch: 6| Step: 10
Training loss: 1.3231701850891113
Validation loss: 1.7802865210399832

Epoch: 6| Step: 11
Training loss: 1.5803953409194946
Validation loss: 1.82895613485767

Epoch: 6| Step: 12
Training loss: 0.8291662931442261
Validation loss: 1.8136010592983616

Epoch: 6| Step: 13
Training loss: 1.4011578559875488
Validation loss: 1.7988210160245177

Epoch: 370| Step: 0
Training loss: 1.1610138416290283
Validation loss: 1.7774803728185675

Epoch: 6| Step: 1
Training loss: 0.4938313961029053
Validation loss: 1.7603051764990694

Epoch: 6| Step: 2
Training loss: 1.3479042053222656
Validation loss: 1.755217964931201

Epoch: 6| Step: 3
Training loss: 1.1326770782470703
Validation loss: 1.6815236794051303

Epoch: 6| Step: 4
Training loss: 1.3844223022460938
Validation loss: 1.6921779494131766

Epoch: 6| Step: 5
Training loss: 1.3422975540161133
Validation loss: 1.753984639721532

Epoch: 6| Step: 6
Training loss: 1.1212159395217896
Validation loss: 1.764166549969745

Epoch: 6| Step: 7
Training loss: 1.2933913469314575
Validation loss: 1.7283689296373757

Epoch: 6| Step: 8
Training loss: 1.3977851867675781
Validation loss: 1.7081570445850331

Epoch: 6| Step: 9
Training loss: 0.873943567276001
Validation loss: 1.7361831357402187

Epoch: 6| Step: 10
Training loss: 1.2610251903533936
Validation loss: 1.7265723520709622

Epoch: 6| Step: 11
Training loss: 1.0039769411087036
Validation loss: 1.717468447582696

Epoch: 6| Step: 12
Training loss: 1.0241308212280273
Validation loss: 1.775916580230959

Epoch: 6| Step: 13
Training loss: 1.7017650604248047
Validation loss: 1.7333773925740232

Epoch: 371| Step: 0
Training loss: 1.5859367847442627
Validation loss: 1.7273692892443748

Epoch: 6| Step: 1
Training loss: 1.000986099243164
Validation loss: 1.7668079868439706

Epoch: 6| Step: 2
Training loss: 0.9331046938896179
Validation loss: 1.773300249089477

Epoch: 6| Step: 3
Training loss: 1.0494136810302734
Validation loss: 1.7532062222880702

Epoch: 6| Step: 4
Training loss: 1.228266716003418
Validation loss: 1.7850064539140271

Epoch: 6| Step: 5
Training loss: 1.091130018234253
Validation loss: 1.8102905096546296

Epoch: 6| Step: 6
Training loss: 1.4759490489959717
Validation loss: 1.782196016721828

Epoch: 6| Step: 7
Training loss: 1.523508071899414
Validation loss: 1.7520656521602342

Epoch: 6| Step: 8
Training loss: 1.0821349620819092
Validation loss: 1.7619801182900705

Epoch: 6| Step: 9
Training loss: 1.6027939319610596
Validation loss: 1.7399896755013415

Epoch: 6| Step: 10
Training loss: 1.336908221244812
Validation loss: 1.735060167568986

Epoch: 6| Step: 11
Training loss: 0.9034274220466614
Validation loss: 1.737724822054627

Epoch: 6| Step: 12
Training loss: 0.9346778988838196
Validation loss: 1.7491671616031277

Epoch: 6| Step: 13
Training loss: 0.5228121280670166
Validation loss: 1.7358435571834605

Epoch: 372| Step: 0
Training loss: 0.5044314861297607
Validation loss: 1.7277955034727692

Epoch: 6| Step: 1
Training loss: 1.1235589981079102
Validation loss: 1.7013397370615313

Epoch: 6| Step: 2
Training loss: 0.9388298392295837
Validation loss: 1.6909421631084975

Epoch: 6| Step: 3
Training loss: 0.8480106592178345
Validation loss: 1.7359086980101883

Epoch: 6| Step: 4
Training loss: 0.9815329909324646
Validation loss: 1.7087433979075441

Epoch: 6| Step: 5
Training loss: 0.6905645132064819
Validation loss: 1.7472536820237354

Epoch: 6| Step: 6
Training loss: 0.9802296757698059
Validation loss: 1.7142399229029173

Epoch: 6| Step: 7
Training loss: 0.9392940402030945
Validation loss: 1.7476309332796323

Epoch: 6| Step: 8
Training loss: 1.8105684518814087
Validation loss: 1.7996506665342598

Epoch: 6| Step: 9
Training loss: 1.1855778694152832
Validation loss: 1.7360519773216658

Epoch: 6| Step: 10
Training loss: 1.543473720550537
Validation loss: 1.7369129606472549

Epoch: 6| Step: 11
Training loss: 1.407772183418274
Validation loss: 1.7323306029842747

Epoch: 6| Step: 12
Training loss: 1.3760395050048828
Validation loss: 1.757217832790908

Epoch: 6| Step: 13
Training loss: 2.26318621635437
Validation loss: 1.72704940970226

Epoch: 373| Step: 0
Training loss: 1.088622808456421
Validation loss: 1.7984196620602761

Epoch: 6| Step: 1
Training loss: 1.1529765129089355
Validation loss: 1.765365614685961

Epoch: 6| Step: 2
Training loss: 0.6441989541053772
Validation loss: 1.7522171466581282

Epoch: 6| Step: 3
Training loss: 1.3715226650238037
Validation loss: 1.748782624480545

Epoch: 6| Step: 4
Training loss: 0.8216643929481506
Validation loss: 1.7445201027777888

Epoch: 6| Step: 5
Training loss: 1.366830825805664
Validation loss: 1.7349161614653885

Epoch: 6| Step: 6
Training loss: 1.3208649158477783
Validation loss: 1.7559436316131263

Epoch: 6| Step: 7
Training loss: 0.9982001781463623
Validation loss: 1.758634159641881

Epoch: 6| Step: 8
Training loss: 1.1481752395629883
Validation loss: 1.7532346210172098

Epoch: 6| Step: 9
Training loss: 1.2165871858596802
Validation loss: 1.771913255414655

Epoch: 6| Step: 10
Training loss: 1.1704564094543457
Validation loss: 1.7649794688788794

Epoch: 6| Step: 11
Training loss: 1.4054765701293945
Validation loss: 1.7501976284929501

Epoch: 6| Step: 12
Training loss: 1.4057667255401611
Validation loss: 1.8032640834008493

Epoch: 6| Step: 13
Training loss: 1.0149188041687012
Validation loss: 1.797247653366417

Epoch: 374| Step: 0
Training loss: 1.0122265815734863
Validation loss: 1.75831320593434

Epoch: 6| Step: 1
Training loss: 1.5734477043151855
Validation loss: 1.7689120192681589

Epoch: 6| Step: 2
Training loss: 0.941811203956604
Validation loss: 1.726860148932344

Epoch: 6| Step: 3
Training loss: 1.660644769668579
Validation loss: 1.7543941351675219

Epoch: 6| Step: 4
Training loss: 0.8280645608901978
Validation loss: 1.7233391756652503

Epoch: 6| Step: 5
Training loss: 1.027596354484558
Validation loss: 1.6861125564062467

Epoch: 6| Step: 6
Training loss: 1.262428641319275
Validation loss: 1.7407093240368752

Epoch: 6| Step: 7
Training loss: 1.0781352519989014
Validation loss: 1.7381777737730293

Epoch: 6| Step: 8
Training loss: 0.7634188532829285
Validation loss: 1.66442415278445

Epoch: 6| Step: 9
Training loss: 1.8285272121429443
Validation loss: 1.7350739356010192

Epoch: 6| Step: 10
Training loss: 1.2506855726242065
Validation loss: 1.7104772739512946

Epoch: 6| Step: 11
Training loss: 0.9717334508895874
Validation loss: 1.7786664193676365

Epoch: 6| Step: 12
Training loss: 1.3554236888885498
Validation loss: 1.740963864070113

Epoch: 6| Step: 13
Training loss: 1.2974982261657715
Validation loss: 1.7998179415220856

Epoch: 375| Step: 0
Training loss: 0.6060651540756226
Validation loss: 1.790851895527173

Epoch: 6| Step: 1
Training loss: 1.326808214187622
Validation loss: 1.7600296428126674

Epoch: 6| Step: 2
Training loss: 0.9827220439910889
Validation loss: 1.7705423460211804

Epoch: 6| Step: 3
Training loss: 1.152340292930603
Validation loss: 1.766248603020945

Epoch: 6| Step: 4
Training loss: 1.188380241394043
Validation loss: 1.7834077291591193

Epoch: 6| Step: 5
Training loss: 1.0774651765823364
Validation loss: 1.7306571711776078

Epoch: 6| Step: 6
Training loss: 1.3633840084075928
Validation loss: 1.7870454301116288

Epoch: 6| Step: 7
Training loss: 0.9658695459365845
Validation loss: 1.7764110039639216

Epoch: 6| Step: 8
Training loss: 1.106856346130371
Validation loss: 1.7878960858109176

Epoch: 6| Step: 9
Training loss: 1.487713098526001
Validation loss: 1.7512139812592538

Epoch: 6| Step: 10
Training loss: 1.0942165851593018
Validation loss: 1.7702115466517787

Epoch: 6| Step: 11
Training loss: 1.0868070125579834
Validation loss: 1.754473186949248

Epoch: 6| Step: 12
Training loss: 0.9239066243171692
Validation loss: 1.785320807528752

Epoch: 6| Step: 13
Training loss: 2.2970004081726074
Validation loss: 1.7473765163011448

Epoch: 376| Step: 0
Training loss: 0.9337677359580994
Validation loss: 1.7486187052983109

Epoch: 6| Step: 1
Training loss: 1.3711460828781128
Validation loss: 1.7371939830882575

Epoch: 6| Step: 2
Training loss: 1.407578945159912
Validation loss: 1.7510603550941712

Epoch: 6| Step: 3
Training loss: 1.550200343132019
Validation loss: 1.7725559767856394

Epoch: 6| Step: 4
Training loss: 1.2673838138580322
Validation loss: 1.7436210404160202

Epoch: 6| Step: 5
Training loss: 0.6413065195083618
Validation loss: 1.7508161375599522

Epoch: 6| Step: 6
Training loss: 1.1120880842208862
Validation loss: 1.7484800264399538

Epoch: 6| Step: 7
Training loss: 0.7463873624801636
Validation loss: 1.7691931545093496

Epoch: 6| Step: 8
Training loss: 1.260677456855774
Validation loss: 1.7051394613840247

Epoch: 6| Step: 9
Training loss: 1.286597490310669
Validation loss: 1.758278537822026

Epoch: 6| Step: 10
Training loss: 1.4925010204315186
Validation loss: 1.7597654865634056

Epoch: 6| Step: 11
Training loss: 0.9602086544036865
Validation loss: 1.78971569256116

Epoch: 6| Step: 12
Training loss: 1.0975008010864258
Validation loss: 1.7434772112036263

Epoch: 6| Step: 13
Training loss: 0.4925607442855835
Validation loss: 1.733037252579966

Epoch: 377| Step: 0
Training loss: 1.095384120941162
Validation loss: 1.7847504423510643

Epoch: 6| Step: 1
Training loss: 1.5305418968200684
Validation loss: 1.7925333899836386

Epoch: 6| Step: 2
Training loss: 1.399409532546997
Validation loss: 1.6929860743143226

Epoch: 6| Step: 3
Training loss: 0.6515281200408936
Validation loss: 1.7354382545717302

Epoch: 6| Step: 4
Training loss: 1.4702816009521484
Validation loss: 1.792768286120507

Epoch: 6| Step: 5
Training loss: 1.8914034366607666
Validation loss: 1.7518573909677484

Epoch: 6| Step: 6
Training loss: 1.0812288522720337
Validation loss: 1.7641894189260339

Epoch: 6| Step: 7
Training loss: 0.6986485719680786
Validation loss: 1.7113448253241919

Epoch: 6| Step: 8
Training loss: 1.6233041286468506
Validation loss: 1.7764301338503439

Epoch: 6| Step: 9
Training loss: 0.9679362177848816
Validation loss: 1.7769528819668678

Epoch: 6| Step: 10
Training loss: 0.8058278560638428
Validation loss: 1.7762747490277855

Epoch: 6| Step: 11
Training loss: 0.7893251180648804
Validation loss: 1.75655069017923

Epoch: 6| Step: 12
Training loss: 0.8726927638053894
Validation loss: 1.7032223568167737

Epoch: 6| Step: 13
Training loss: 1.4181289672851562
Validation loss: 1.702102429123335

Epoch: 378| Step: 0
Training loss: 1.1135506629943848
Validation loss: 1.7483297714623072

Epoch: 6| Step: 1
Training loss: 0.6325535774230957
Validation loss: 1.7059482387317124

Epoch: 6| Step: 2
Training loss: 1.0905711650848389
Validation loss: 1.7714289542167418

Epoch: 6| Step: 3
Training loss: 1.1799708604812622
Validation loss: 1.750406272949711

Epoch: 6| Step: 4
Training loss: 0.8873811364173889
Validation loss: 1.7500814340447868

Epoch: 6| Step: 5
Training loss: 0.887078583240509
Validation loss: 1.7881136709643948

Epoch: 6| Step: 6
Training loss: 1.033462405204773
Validation loss: 1.806144296482045

Epoch: 6| Step: 7
Training loss: 1.2929892539978027
Validation loss: 1.763142829300255

Epoch: 6| Step: 8
Training loss: 1.4535655975341797
Validation loss: 1.8021264819688694

Epoch: 6| Step: 9
Training loss: 0.952377200126648
Validation loss: 1.759232763321169

Epoch: 6| Step: 10
Training loss: 1.7806684970855713
Validation loss: 1.7785737591405069

Epoch: 6| Step: 11
Training loss: 1.6458172798156738
Validation loss: 1.7272079170391124

Epoch: 6| Step: 12
Training loss: 1.5411615371704102
Validation loss: 1.7581428827777985

Epoch: 6| Step: 13
Training loss: 0.6137807369232178
Validation loss: 1.7887425602123301

Epoch: 379| Step: 0
Training loss: 0.8561429381370544
Validation loss: 1.7570193839329544

Epoch: 6| Step: 1
Training loss: 0.6745065450668335
Validation loss: 1.7286153647207445

Epoch: 6| Step: 2
Training loss: 1.0557490587234497
Validation loss: 1.798903916471748

Epoch: 6| Step: 3
Training loss: 0.8342365622520447
Validation loss: 1.7194645866270988

Epoch: 6| Step: 4
Training loss: 1.5915546417236328
Validation loss: 1.761521408634801

Epoch: 6| Step: 5
Training loss: 1.310258388519287
Validation loss: 1.7454323499433455

Epoch: 6| Step: 6
Training loss: 1.226029872894287
Validation loss: 1.750021820427269

Epoch: 6| Step: 7
Training loss: 1.1956465244293213
Validation loss: 1.6949817711307156

Epoch: 6| Step: 8
Training loss: 1.06951904296875
Validation loss: 1.755596617216705

Epoch: 6| Step: 9
Training loss: 1.5387741327285767
Validation loss: 1.7501751492100377

Epoch: 6| Step: 10
Training loss: 1.273000717163086
Validation loss: 1.785243131781137

Epoch: 6| Step: 11
Training loss: 0.9806369543075562
Validation loss: 1.735536212562233

Epoch: 6| Step: 12
Training loss: 1.2715234756469727
Validation loss: 1.728497007841705

Epoch: 6| Step: 13
Training loss: 1.3135230541229248
Validation loss: 1.7360425815787366

Epoch: 380| Step: 0
Training loss: 1.2782349586486816
Validation loss: 1.7944471746362665

Epoch: 6| Step: 1
Training loss: 1.1386228799819946
Validation loss: 1.7414984677427559

Epoch: 6| Step: 2
Training loss: 1.2032831907272339
Validation loss: 1.7520065589617657

Epoch: 6| Step: 3
Training loss: 1.1036145687103271
Validation loss: 1.7171055245143112

Epoch: 6| Step: 4
Training loss: 0.8710386753082275
Validation loss: 1.771856802766041

Epoch: 6| Step: 5
Training loss: 0.607379138469696
Validation loss: 1.7350280502791047

Epoch: 6| Step: 6
Training loss: 0.9005123376846313
Validation loss: 1.7423535008584299

Epoch: 6| Step: 7
Training loss: 1.490159511566162
Validation loss: 1.7637037205439743

Epoch: 6| Step: 8
Training loss: 1.397007942199707
Validation loss: 1.6986082061644523

Epoch: 6| Step: 9
Training loss: 1.0070213079452515
Validation loss: 1.7622854940352901

Epoch: 6| Step: 10
Training loss: 1.0348730087280273
Validation loss: 1.745710656207095

Epoch: 6| Step: 11
Training loss: 1.438732624053955
Validation loss: 1.7331503219501947

Epoch: 6| Step: 12
Training loss: 1.1457650661468506
Validation loss: 1.72513763366207

Epoch: 6| Step: 13
Training loss: 1.9243566989898682
Validation loss: 1.7510907983267179

Epoch: 381| Step: 0
Training loss: 0.8071143627166748
Validation loss: 1.7719845053970174

Epoch: 6| Step: 1
Training loss: 1.022262454032898
Validation loss: 1.7551634670585714

Epoch: 6| Step: 2
Training loss: 1.330070972442627
Validation loss: 1.7457997234918738

Epoch: 6| Step: 3
Training loss: 1.1821544170379639
Validation loss: 1.744829850812112

Epoch: 6| Step: 4
Training loss: 1.1697852611541748
Validation loss: 1.8014941087333105

Epoch: 6| Step: 5
Training loss: 1.0186787843704224
Validation loss: 1.7028649096847863

Epoch: 6| Step: 6
Training loss: 1.1847505569458008
Validation loss: 1.7889305494164909

Epoch: 6| Step: 7
Training loss: 0.8739443421363831
Validation loss: 1.7623287721346783

Epoch: 6| Step: 8
Training loss: 1.149317979812622
Validation loss: 1.7407814892389442

Epoch: 6| Step: 9
Training loss: 1.2892051935195923
Validation loss: 1.764632914655952

Epoch: 6| Step: 10
Training loss: 1.3999907970428467
Validation loss: 1.7064289444236345

Epoch: 6| Step: 11
Training loss: 1.2061505317687988
Validation loss: 1.708889756151425

Epoch: 6| Step: 12
Training loss: 1.2571309804916382
Validation loss: 1.7224037775429346

Epoch: 6| Step: 13
Training loss: 1.125631332397461
Validation loss: 1.6830078735146472

Epoch: 382| Step: 0
Training loss: 1.2964006662368774
Validation loss: 1.7598493714486398

Epoch: 6| Step: 1
Training loss: 1.0887612104415894
Validation loss: 1.7324755025166336

Epoch: 6| Step: 2
Training loss: 0.9879134297370911
Validation loss: 1.7634595260825208

Epoch: 6| Step: 3
Training loss: 1.7334730625152588
Validation loss: 1.7272646747609621

Epoch: 6| Step: 4
Training loss: 1.2804179191589355
Validation loss: 1.724900375130356

Epoch: 6| Step: 5
Training loss: 1.3028960227966309
Validation loss: 1.7336090585236907

Epoch: 6| Step: 6
Training loss: 0.9891437292098999
Validation loss: 1.7506459489945443

Epoch: 6| Step: 7
Training loss: 0.8296871781349182
Validation loss: 1.7265042912575506

Epoch: 6| Step: 8
Training loss: 0.9486334323883057
Validation loss: 1.7107613842974427

Epoch: 6| Step: 9
Training loss: 1.456597089767456
Validation loss: 1.7639416712586597

Epoch: 6| Step: 10
Training loss: 0.8064647912979126
Validation loss: 1.7323727184726345

Epoch: 6| Step: 11
Training loss: 1.6369235515594482
Validation loss: 1.76037432301429

Epoch: 6| Step: 12
Training loss: 1.2109684944152832
Validation loss: 1.7622167692389539

Epoch: 6| Step: 13
Training loss: 0.9228458404541016
Validation loss: 1.8001433495552308

Epoch: 383| Step: 0
Training loss: 1.0476605892181396
Validation loss: 1.7499221089065715

Epoch: 6| Step: 1
Training loss: 1.1970105171203613
Validation loss: 1.736753334281265

Epoch: 6| Step: 2
Training loss: 0.9442273378372192
Validation loss: 1.7720149153022355

Epoch: 6| Step: 3
Training loss: 1.284803867340088
Validation loss: 1.7703568089392878

Epoch: 6| Step: 4
Training loss: 0.8003077507019043
Validation loss: 1.717167074962329

Epoch: 6| Step: 5
Training loss: 0.8390002250671387
Validation loss: 1.7539694334871025

Epoch: 6| Step: 6
Training loss: 1.185424566268921
Validation loss: 1.6944643605139948

Epoch: 6| Step: 7
Training loss: 0.9055599570274353
Validation loss: 1.7234654503483926

Epoch: 6| Step: 8
Training loss: 1.1506778001785278
Validation loss: 1.7416717647224345

Epoch: 6| Step: 9
Training loss: 1.0235533714294434
Validation loss: 1.7785034974416096

Epoch: 6| Step: 10
Training loss: 1.618180751800537
Validation loss: 1.7003231099856797

Epoch: 6| Step: 11
Training loss: 1.038555383682251
Validation loss: 1.7467863187995007

Epoch: 6| Step: 12
Training loss: 1.4485565423965454
Validation loss: 1.7686522340261808

Epoch: 6| Step: 13
Training loss: 1.4831700325012207
Validation loss: 1.7233859697977703

Epoch: 384| Step: 0
Training loss: 1.2961286306381226
Validation loss: 1.7514887522625666

Epoch: 6| Step: 1
Training loss: 0.8247526288032532
Validation loss: 1.7451503289643155

Epoch: 6| Step: 2
Training loss: 1.1048619747161865
Validation loss: 1.757027256873346

Epoch: 6| Step: 3
Training loss: 1.3612654209136963
Validation loss: 1.773473637719308

Epoch: 6| Step: 4
Training loss: 1.0467538833618164
Validation loss: 1.7322760294842463

Epoch: 6| Step: 5
Training loss: 1.3636633157730103
Validation loss: 1.7554589266418128

Epoch: 6| Step: 6
Training loss: 0.8361533880233765
Validation loss: 1.7556721241243425

Epoch: 6| Step: 7
Training loss: 1.5667240619659424
Validation loss: 1.7554916527963453

Epoch: 6| Step: 8
Training loss: 1.0262049436569214
Validation loss: 1.765818222876518

Epoch: 6| Step: 9
Training loss: 1.2185896635055542
Validation loss: 1.7293360028215634

Epoch: 6| Step: 10
Training loss: 1.496825933456421
Validation loss: 1.7741291728070987

Epoch: 6| Step: 11
Training loss: 0.9614654779434204
Validation loss: 1.7111649449153612

Epoch: 6| Step: 12
Training loss: 1.013085961341858
Validation loss: 1.762219322625027

Epoch: 6| Step: 13
Training loss: 0.8389835357666016
Validation loss: 1.7377518351360033

Epoch: 385| Step: 0
Training loss: 0.9779109954833984
Validation loss: 1.7019544224585257

Epoch: 6| Step: 1
Training loss: 1.3475978374481201
Validation loss: 1.78196572103808

Epoch: 6| Step: 2
Training loss: 0.7876757383346558
Validation loss: 1.7619980483926752

Epoch: 6| Step: 3
Training loss: 0.5297073721885681
Validation loss: 1.723222900462407

Epoch: 6| Step: 4
Training loss: 1.5671170949935913
Validation loss: 1.6847943887915662

Epoch: 6| Step: 5
Training loss: 0.9219962358474731
Validation loss: 1.7701007473853327

Epoch: 6| Step: 6
Training loss: 1.2997918128967285
Validation loss: 1.7129650718422347

Epoch: 6| Step: 7
Training loss: 0.9464498162269592
Validation loss: 1.762560849548668

Epoch: 6| Step: 8
Training loss: 1.066770076751709
Validation loss: 1.7400654951731365

Epoch: 6| Step: 9
Training loss: 1.3732876777648926
Validation loss: 1.72537826466304

Epoch: 6| Step: 10
Training loss: 1.1022034883499146
Validation loss: 1.7503605504189768

Epoch: 6| Step: 11
Training loss: 1.0807595252990723
Validation loss: 1.7057956623774704

Epoch: 6| Step: 12
Training loss: 1.5053943395614624
Validation loss: 1.6780294808008338

Epoch: 6| Step: 13
Training loss: 0.6453337073326111
Validation loss: 1.7504481320740075

Epoch: 386| Step: 0
Training loss: 0.8094952702522278
Validation loss: 1.7555583241165325

Epoch: 6| Step: 1
Training loss: 0.933751106262207
Validation loss: 1.7533797333317418

Epoch: 6| Step: 2
Training loss: 1.3443694114685059
Validation loss: 1.7461425963268484

Epoch: 6| Step: 3
Training loss: 0.9877704381942749
Validation loss: 1.750771894249865

Epoch: 6| Step: 4
Training loss: 0.9520487785339355
Validation loss: 1.7758133552407707

Epoch: 6| Step: 5
Training loss: 0.9628008604049683
Validation loss: 1.7741663609781573

Epoch: 6| Step: 6
Training loss: 1.3991062641143799
Validation loss: 1.7201203530834568

Epoch: 6| Step: 7
Training loss: 0.39911970496177673
Validation loss: 1.703143564603662

Epoch: 6| Step: 8
Training loss: 1.165090560913086
Validation loss: 1.682359391643155

Epoch: 6| Step: 9
Training loss: 1.2120790481567383
Validation loss: 1.6914870687710342

Epoch: 6| Step: 10
Training loss: 1.8257578611373901
Validation loss: 1.770848640831568

Epoch: 6| Step: 11
Training loss: 1.3853628635406494
Validation loss: 1.717890485640495

Epoch: 6| Step: 12
Training loss: 0.9460077285766602
Validation loss: 1.745338181013702

Epoch: 6| Step: 13
Training loss: 1.5593161582946777
Validation loss: 1.7414815387418192

Epoch: 387| Step: 0
Training loss: 1.1769137382507324
Validation loss: 1.7262874508416781

Epoch: 6| Step: 1
Training loss: 0.8756253719329834
Validation loss: 1.8078651761495939

Epoch: 6| Step: 2
Training loss: 1.0443105697631836
Validation loss: 1.7331669933052474

Epoch: 6| Step: 3
Training loss: 0.921941339969635
Validation loss: 1.8026579169816868

Epoch: 6| Step: 4
Training loss: 1.2816122770309448
Validation loss: 1.7362127970623713

Epoch: 6| Step: 5
Training loss: 0.6977972388267517
Validation loss: 1.772675516784832

Epoch: 6| Step: 6
Training loss: 1.497281789779663
Validation loss: 1.7843245075594993

Epoch: 6| Step: 7
Training loss: 1.00477135181427
Validation loss: 1.697230803069248

Epoch: 6| Step: 8
Training loss: 1.1851218938827515
Validation loss: 1.751247218860093

Epoch: 6| Step: 9
Training loss: 0.8796745538711548
Validation loss: 1.7539361651225756

Epoch: 6| Step: 10
Training loss: 1.0920014381408691
Validation loss: 1.6922956282092678

Epoch: 6| Step: 11
Training loss: 1.4627056121826172
Validation loss: 1.7678017103543846

Epoch: 6| Step: 12
Training loss: 1.376816749572754
Validation loss: 1.7777022289973434

Epoch: 6| Step: 13
Training loss: 1.542906641960144
Validation loss: 1.7233812860263291

Epoch: 388| Step: 0
Training loss: 0.871265709400177
Validation loss: 1.7089313358388922

Epoch: 6| Step: 1
Training loss: 1.263638973236084
Validation loss: 1.70991640193488

Epoch: 6| Step: 2
Training loss: 1.8032734394073486
Validation loss: 1.720571667917313

Epoch: 6| Step: 3
Training loss: 0.8981297612190247
Validation loss: 1.7268034155650804

Epoch: 6| Step: 4
Training loss: 0.8553653955459595
Validation loss: 1.6968346218908987

Epoch: 6| Step: 5
Training loss: 1.091468334197998
Validation loss: 1.743337296670483

Epoch: 6| Step: 6
Training loss: 1.053617000579834
Validation loss: 1.7631717356302405

Epoch: 6| Step: 7
Training loss: 1.1825008392333984
Validation loss: 1.714195846229471

Epoch: 6| Step: 8
Training loss: 1.1966699361801147
Validation loss: 1.7058296536886564

Epoch: 6| Step: 9
Training loss: 1.4674301147460938
Validation loss: 1.7091668254585677

Epoch: 6| Step: 10
Training loss: 0.9203568696975708
Validation loss: 1.707573163893915

Epoch: 6| Step: 11
Training loss: 1.4328668117523193
Validation loss: 1.745704286841936

Epoch: 6| Step: 12
Training loss: 0.9342882037162781
Validation loss: 1.7419725643691195

Epoch: 6| Step: 13
Training loss: 1.2179534435272217
Validation loss: 1.6916507264619232

Epoch: 389| Step: 0
Training loss: 1.4331653118133545
Validation loss: 1.8091379224613149

Epoch: 6| Step: 1
Training loss: 1.036807894706726
Validation loss: 1.7371341554067468

Epoch: 6| Step: 2
Training loss: 1.5167062282562256
Validation loss: 1.7122811143116285

Epoch: 6| Step: 3
Training loss: 0.8675182461738586
Validation loss: 1.720493362795922

Epoch: 6| Step: 4
Training loss: 0.9632708430290222
Validation loss: 1.74766004982815

Epoch: 6| Step: 5
Training loss: 0.7803338766098022
Validation loss: 1.766759508399553

Epoch: 6| Step: 6
Training loss: 1.477917194366455
Validation loss: 1.7521243685035295

Epoch: 6| Step: 7
Training loss: 0.9455193281173706
Validation loss: 1.728975074265593

Epoch: 6| Step: 8
Training loss: 1.1377947330474854
Validation loss: 1.710350295548798

Epoch: 6| Step: 9
Training loss: 1.076373815536499
Validation loss: 1.7121047332722654

Epoch: 6| Step: 10
Training loss: 1.506270170211792
Validation loss: 1.7052340225506855

Epoch: 6| Step: 11
Training loss: 1.1429147720336914
Validation loss: 1.7437140787801435

Epoch: 6| Step: 12
Training loss: 0.7536112070083618
Validation loss: 1.7422971340917772

Epoch: 6| Step: 13
Training loss: 1.222784161567688
Validation loss: 1.7751040574043029

Epoch: 390| Step: 0
Training loss: 0.8399051427841187
Validation loss: 1.7453704303310764

Epoch: 6| Step: 1
Training loss: 1.0480940341949463
Validation loss: 1.7529519950189898

Epoch: 6| Step: 2
Training loss: 1.0473802089691162
Validation loss: 1.7223987143526795

Epoch: 6| Step: 3
Training loss: 1.1797552108764648
Validation loss: 1.650598938747119

Epoch: 6| Step: 4
Training loss: 1.1886775493621826
Validation loss: 1.7285407704691733

Epoch: 6| Step: 5
Training loss: 1.6867445707321167
Validation loss: 1.7091181893502512

Epoch: 6| Step: 6
Training loss: 1.284713625907898
Validation loss: 1.7166286207014514

Epoch: 6| Step: 7
Training loss: 1.1816575527191162
Validation loss: 1.7049589182740899

Epoch: 6| Step: 8
Training loss: 1.2951703071594238
Validation loss: 1.708657487746208

Epoch: 6| Step: 9
Training loss: 1.1183583736419678
Validation loss: 1.7466484603061472

Epoch: 6| Step: 10
Training loss: 0.8801100850105286
Validation loss: 1.741495793865573

Epoch: 6| Step: 11
Training loss: 0.8962002396583557
Validation loss: 1.753426985074115

Epoch: 6| Step: 12
Training loss: 0.9420652389526367
Validation loss: 1.728434967738326

Epoch: 6| Step: 13
Training loss: 1.267254114151001
Validation loss: 1.76873141975813

Epoch: 391| Step: 0
Training loss: 1.3772011995315552
Validation loss: 1.7573764824098157

Epoch: 6| Step: 1
Training loss: 1.3717679977416992
Validation loss: 1.7139657697369974

Epoch: 6| Step: 2
Training loss: 1.1081805229187012
Validation loss: 1.7120722506635933

Epoch: 6| Step: 3
Training loss: 0.9570935368537903
Validation loss: 1.834692378197947

Epoch: 6| Step: 4
Training loss: 1.1229970455169678
Validation loss: 1.784671063064247

Epoch: 6| Step: 5
Training loss: 1.4509506225585938
Validation loss: 1.7678686085567679

Epoch: 6| Step: 6
Training loss: 1.09202241897583
Validation loss: 1.7925998856944423

Epoch: 6| Step: 7
Training loss: 1.1358777284622192
Validation loss: 1.7974985696936165

Epoch: 6| Step: 8
Training loss: 0.5352697372436523
Validation loss: 1.7642211785880468

Epoch: 6| Step: 9
Training loss: 1.1418392658233643
Validation loss: 1.743592578877685

Epoch: 6| Step: 10
Training loss: 0.9833555817604065
Validation loss: 1.7295085396817935

Epoch: 6| Step: 11
Training loss: 0.9727592468261719
Validation loss: 1.7708608181245866

Epoch: 6| Step: 12
Training loss: 1.7954045534133911
Validation loss: 1.745277747031181

Epoch: 6| Step: 13
Training loss: 1.1773062944412231
Validation loss: 1.769799437574161

Epoch: 392| Step: 0
Training loss: 1.080019474029541
Validation loss: 1.7103338113395117

Epoch: 6| Step: 1
Training loss: 1.6379516124725342
Validation loss: 1.7414465937563168

Epoch: 6| Step: 2
Training loss: 0.9791073799133301
Validation loss: 1.6915960952799807

Epoch: 6| Step: 3
Training loss: 0.8803429007530212
Validation loss: 1.7155007123947144

Epoch: 6| Step: 4
Training loss: 1.597176432609558
Validation loss: 1.6706067644139773

Epoch: 6| Step: 5
Training loss: 1.11237633228302
Validation loss: 1.6880775235032524

Epoch: 6| Step: 6
Training loss: 0.8538633584976196
Validation loss: 1.7151723215656896

Epoch: 6| Step: 7
Training loss: 1.0204006433486938
Validation loss: 1.7592340515505882

Epoch: 6| Step: 8
Training loss: 1.1644065380096436
Validation loss: 1.7463562680828957

Epoch: 6| Step: 9
Training loss: 1.001835584640503
Validation loss: 1.6955447453324513

Epoch: 6| Step: 10
Training loss: 1.341177225112915
Validation loss: 1.7593864266590407

Epoch: 6| Step: 11
Training loss: 0.820647120475769
Validation loss: 1.7778424947492537

Epoch: 6| Step: 12
Training loss: 1.108900785446167
Validation loss: 1.6889203184394426

Epoch: 6| Step: 13
Training loss: 0.9117900133132935
Validation loss: 1.7457348441564908

Epoch: 393| Step: 0
Training loss: 0.7719865441322327
Validation loss: 1.7730260856689946

Epoch: 6| Step: 1
Training loss: 0.7290500402450562
Validation loss: 1.71668960971217

Epoch: 6| Step: 2
Training loss: 1.5471882820129395
Validation loss: 1.7987373067486672

Epoch: 6| Step: 3
Training loss: 0.9567177295684814
Validation loss: 1.7111991118359309

Epoch: 6| Step: 4
Training loss: 1.378013253211975
Validation loss: 1.7471638584649691

Epoch: 6| Step: 5
Training loss: 1.3302353620529175
Validation loss: 1.7134966260643416

Epoch: 6| Step: 6
Training loss: 0.8273158073425293
Validation loss: 1.7043988140680457

Epoch: 6| Step: 7
Training loss: 1.1156463623046875
Validation loss: 1.737593222689885

Epoch: 6| Step: 8
Training loss: 0.49481818079948425
Validation loss: 1.7006583188169746

Epoch: 6| Step: 9
Training loss: 1.4319089651107788
Validation loss: 1.7584639031399962

Epoch: 6| Step: 10
Training loss: 1.599501132965088
Validation loss: 1.7152651676567652

Epoch: 6| Step: 11
Training loss: 1.5345275402069092
Validation loss: 1.7198745614738875

Epoch: 6| Step: 12
Training loss: 0.8836004734039307
Validation loss: 1.7347173037067536

Epoch: 6| Step: 13
Training loss: 0.6301626563072205
Validation loss: 1.7769888652268278

Epoch: 394| Step: 0
Training loss: 1.1881284713745117
Validation loss: 1.754685563425864

Epoch: 6| Step: 1
Training loss: 0.9771361351013184
Validation loss: 1.763189294004953

Epoch: 6| Step: 2
Training loss: 1.3550615310668945
Validation loss: 1.7519694092453166

Epoch: 6| Step: 3
Training loss: 0.9916427135467529
Validation loss: 1.7389975542663245

Epoch: 6| Step: 4
Training loss: 1.1101750135421753
Validation loss: 1.7466832066095004

Epoch: 6| Step: 5
Training loss: 1.4520142078399658
Validation loss: 1.7622266777100102

Epoch: 6| Step: 6
Training loss: 0.8189640045166016
Validation loss: 1.7640804936808925

Epoch: 6| Step: 7
Training loss: 1.1526463031768799
Validation loss: 1.7282473271892917

Epoch: 6| Step: 8
Training loss: 1.3558616638183594
Validation loss: 1.749920787349824

Epoch: 6| Step: 9
Training loss: 1.220118522644043
Validation loss: 1.74014389130377

Epoch: 6| Step: 10
Training loss: 0.5264744758605957
Validation loss: 1.7167221128299672

Epoch: 6| Step: 11
Training loss: 1.2899794578552246
Validation loss: 1.741634048441405

Epoch: 6| Step: 12
Training loss: 0.6802603006362915
Validation loss: 1.6752049358942176

Epoch: 6| Step: 13
Training loss: 1.8453916311264038
Validation loss: 1.7375807210963259

Epoch: 395| Step: 0
Training loss: 1.4821858406066895
Validation loss: 1.7249322091379473

Epoch: 6| Step: 1
Training loss: 1.4433170557022095
Validation loss: 1.7059305662749915

Epoch: 6| Step: 2
Training loss: 0.9139068126678467
Validation loss: 1.7594798482874388

Epoch: 6| Step: 3
Training loss: 1.236824870109558
Validation loss: 1.7013687754190097

Epoch: 6| Step: 4
Training loss: 1.4007000923156738
Validation loss: 1.6926917555511638

Epoch: 6| Step: 5
Training loss: 0.996647298336029
Validation loss: 1.7169365523963847

Epoch: 6| Step: 6
Training loss: 0.9232739210128784
Validation loss: 1.7213149762922717

Epoch: 6| Step: 7
Training loss: 1.2424101829528809
Validation loss: 1.7609936268098894

Epoch: 6| Step: 8
Training loss: 1.1164956092834473
Validation loss: 1.7213629727722497

Epoch: 6| Step: 9
Training loss: 0.6380324363708496
Validation loss: 1.7211127127370527

Epoch: 6| Step: 10
Training loss: 0.5712152719497681
Validation loss: 1.767247885786077

Epoch: 6| Step: 11
Training loss: 1.443535327911377
Validation loss: 1.7646927820738925

Epoch: 6| Step: 12
Training loss: 1.1055766344070435
Validation loss: 1.7425968903367237

Epoch: 6| Step: 13
Training loss: 1.1359344720840454
Validation loss: 1.72404694813554

Epoch: 396| Step: 0
Training loss: 1.6289743185043335
Validation loss: 1.7337740685350151

Epoch: 6| Step: 1
Training loss: 0.7232624292373657
Validation loss: 1.750920444406489

Epoch: 6| Step: 2
Training loss: 1.0819040536880493
Validation loss: 1.7026580097854778

Epoch: 6| Step: 3
Training loss: 2.0356976985931396
Validation loss: 1.7132899094653387

Epoch: 6| Step: 4
Training loss: 0.5545642375946045
Validation loss: 1.703430724400346

Epoch: 6| Step: 5
Training loss: 1.1555290222167969
Validation loss: 1.7140882220319522

Epoch: 6| Step: 6
Training loss: 1.1491239070892334
Validation loss: 1.7433022350393317

Epoch: 6| Step: 7
Training loss: 0.8753176927566528
Validation loss: 1.7130727652580506

Epoch: 6| Step: 8
Training loss: 1.3972408771514893
Validation loss: 1.7171869361272423

Epoch: 6| Step: 9
Training loss: 1.0435872077941895
Validation loss: 1.761492589468597

Epoch: 6| Step: 10
Training loss: 0.8392665386199951
Validation loss: 1.7400421352796658

Epoch: 6| Step: 11
Training loss: 1.2275199890136719
Validation loss: 1.7207897786171205

Epoch: 6| Step: 12
Training loss: 1.1414433717727661
Validation loss: 1.713079733233298

Epoch: 6| Step: 13
Training loss: 0.7242942452430725
Validation loss: 1.73593512786332

Epoch: 397| Step: 0
Training loss: 1.2952197790145874
Validation loss: 1.7654135304112588

Epoch: 6| Step: 1
Training loss: 0.8925458788871765
Validation loss: 1.735929355826429

Epoch: 6| Step: 2
Training loss: 1.1247450113296509
Validation loss: 1.73640388442624

Epoch: 6| Step: 3
Training loss: 0.8616577982902527
Validation loss: 1.7564465256147488

Epoch: 6| Step: 4
Training loss: 1.0765047073364258
Validation loss: 1.7147202068759548

Epoch: 6| Step: 5
Training loss: 0.9558670520782471
Validation loss: 1.7429442456973496

Epoch: 6| Step: 6
Training loss: 0.8538691401481628
Validation loss: 1.7278007820088377

Epoch: 6| Step: 7
Training loss: 0.9450052976608276
Validation loss: 1.7763049205144246

Epoch: 6| Step: 8
Training loss: 1.0579782724380493
Validation loss: 1.7551932450263732

Epoch: 6| Step: 9
Training loss: 1.2872233390808105
Validation loss: 1.7541979435951478

Epoch: 6| Step: 10
Training loss: 1.0058956146240234
Validation loss: 1.7306050869726366

Epoch: 6| Step: 11
Training loss: 0.8723322153091431
Validation loss: 1.727142910803518

Epoch: 6| Step: 12
Training loss: 1.53961181640625
Validation loss: 1.7479124082032071

Epoch: 6| Step: 13
Training loss: 1.5438417196273804
Validation loss: 1.7301501356145388

Epoch: 398| Step: 0
Training loss: 1.3506412506103516
Validation loss: 1.7514867628774335

Epoch: 6| Step: 1
Training loss: 1.45894455909729
Validation loss: 1.7492426595380228

Epoch: 6| Step: 2
Training loss: 1.4378844499588013
Validation loss: 1.7589742419540242

Epoch: 6| Step: 3
Training loss: 1.2448172569274902
Validation loss: 1.7853904898448656

Epoch: 6| Step: 4
Training loss: 1.3502153158187866
Validation loss: 1.7915360248217018

Epoch: 6| Step: 5
Training loss: 1.5419224500656128
Validation loss: 1.7579775676932385

Epoch: 6| Step: 6
Training loss: 1.2943081855773926
Validation loss: 1.760066266982786

Epoch: 6| Step: 7
Training loss: 0.771127462387085
Validation loss: 1.7890330412054574

Epoch: 6| Step: 8
Training loss: 0.8745594620704651
Validation loss: 1.7128078565802625

Epoch: 6| Step: 9
Training loss: 1.1581945419311523
Validation loss: 1.7504354497437835

Epoch: 6| Step: 10
Training loss: 1.3748483657836914
Validation loss: 1.7415479088342318

Epoch: 6| Step: 11
Training loss: 0.9259053468704224
Validation loss: 1.716544178224379

Epoch: 6| Step: 12
Training loss: 1.2671421766281128
Validation loss: 1.7468687052367835

Epoch: 6| Step: 13
Training loss: 0.4762922525405884
Validation loss: 1.7554440165078768

Epoch: 399| Step: 0
Training loss: 1.4222235679626465
Validation loss: 1.8029904519357989

Epoch: 6| Step: 1
Training loss: 1.3949321508407593
Validation loss: 1.7866736753012544

Epoch: 6| Step: 2
Training loss: 1.0965790748596191
Validation loss: 1.7676986763554234

Epoch: 6| Step: 3
Training loss: 1.6052114963531494
Validation loss: 1.7897849518765685

Epoch: 6| Step: 4
Training loss: 1.1023337841033936
Validation loss: 1.7713297490150697

Epoch: 6| Step: 5
Training loss: 1.076948642730713
Validation loss: 1.7364250677888111

Epoch: 6| Step: 6
Training loss: 1.4057197570800781
Validation loss: 1.7353115222787345

Epoch: 6| Step: 7
Training loss: 0.9575207233428955
Validation loss: 1.7375052295705324

Epoch: 6| Step: 8
Training loss: 0.7186414003372192
Validation loss: 1.7809974711428407

Epoch: 6| Step: 9
Training loss: 0.7652087211608887
Validation loss: 1.7129291462641891

Epoch: 6| Step: 10
Training loss: 0.653996467590332
Validation loss: 1.769843828293585

Epoch: 6| Step: 11
Training loss: 0.8976243734359741
Validation loss: 1.722939774554263

Epoch: 6| Step: 12
Training loss: 1.5041208267211914
Validation loss: 1.7124000467279905

Epoch: 6| Step: 13
Training loss: 1.270463466644287
Validation loss: 1.7326808385951544

Epoch: 400| Step: 0
Training loss: 1.2771955728530884
Validation loss: 1.7663101919235722

Epoch: 6| Step: 1
Training loss: 1.2664260864257812
Validation loss: 1.738607124615741

Epoch: 6| Step: 2
Training loss: 0.9011425375938416
Validation loss: 1.739541128117551

Epoch: 6| Step: 3
Training loss: 1.3982383012771606
Validation loss: 1.7872033247383692

Epoch: 6| Step: 4
Training loss: 0.8406198620796204
Validation loss: 1.7184998572513621

Epoch: 6| Step: 5
Training loss: 1.2327983379364014
Validation loss: 1.7403099344622703

Epoch: 6| Step: 6
Training loss: 0.8746599555015564
Validation loss: 1.7714188682135714

Epoch: 6| Step: 7
Training loss: 0.6783221960067749
Validation loss: 1.7520063936069448

Epoch: 6| Step: 8
Training loss: 1.4106640815734863
Validation loss: 1.726579878919868

Epoch: 6| Step: 9
Training loss: 0.8564174175262451
Validation loss: 1.740950169101838

Epoch: 6| Step: 10
Training loss: 0.887927770614624
Validation loss: 1.7905402337351153

Epoch: 6| Step: 11
Training loss: 1.3253178596496582
Validation loss: 1.7343963576901344

Epoch: 6| Step: 12
Training loss: 1.01219642162323
Validation loss: 1.7045045014350646

Epoch: 6| Step: 13
Training loss: 1.495607614517212
Validation loss: 1.7489626728078371

Epoch: 401| Step: 0
Training loss: 1.2133346796035767
Validation loss: 1.7135694334583897

Epoch: 6| Step: 1
Training loss: 0.830517053604126
Validation loss: 1.7162363042113602

Epoch: 6| Step: 2
Training loss: 1.0026488304138184
Validation loss: 1.762472112973531

Epoch: 6| Step: 3
Training loss: 0.5988954901695251
Validation loss: 1.749187897610408

Epoch: 6| Step: 4
Training loss: 1.758177399635315
Validation loss: 1.7187443753724456

Epoch: 6| Step: 5
Training loss: 1.5384992361068726
Validation loss: 1.6902126253292125

Epoch: 6| Step: 6
Training loss: 1.068804144859314
Validation loss: 1.6937528284647132

Epoch: 6| Step: 7
Training loss: 1.1907234191894531
Validation loss: 1.7117308890947731

Epoch: 6| Step: 8
Training loss: 1.1856577396392822
Validation loss: 1.725464843934582

Epoch: 6| Step: 9
Training loss: 1.2972153425216675
Validation loss: 1.6734988561240576

Epoch: 6| Step: 10
Training loss: 0.8326156735420227
Validation loss: 1.680274901851531

Epoch: 6| Step: 11
Training loss: 0.9040440320968628
Validation loss: 1.7165708452142694

Epoch: 6| Step: 12
Training loss: 0.8118331432342529
Validation loss: 1.7117804058136479

Epoch: 6| Step: 13
Training loss: 1.5063698291778564
Validation loss: 1.7438008426338114

Epoch: 402| Step: 0
Training loss: 1.0843514204025269
Validation loss: 1.7493757573507165

Epoch: 6| Step: 1
Training loss: 1.152482509613037
Validation loss: 1.7029248899029148

Epoch: 6| Step: 2
Training loss: 1.140555500984192
Validation loss: 1.7616629139069588

Epoch: 6| Step: 3
Training loss: 1.2548556327819824
Validation loss: 1.7146238691063338

Epoch: 6| Step: 4
Training loss: 1.6760594844818115
Validation loss: 1.7521705870987268

Epoch: 6| Step: 5
Training loss: 0.8820348978042603
Validation loss: 1.768912032086362

Epoch: 6| Step: 6
Training loss: 0.8360956907272339
Validation loss: 1.7599899320192234

Epoch: 6| Step: 7
Training loss: 0.945950448513031
Validation loss: 1.7603351390489967

Epoch: 6| Step: 8
Training loss: 1.1333998441696167
Validation loss: 1.7536978977982716

Epoch: 6| Step: 9
Training loss: 1.2585867643356323
Validation loss: 1.7521267526893205

Epoch: 6| Step: 10
Training loss: 0.652668297290802
Validation loss: 1.7656276251680108

Epoch: 6| Step: 11
Training loss: 0.9640799760818481
Validation loss: 1.7320871635149884

Epoch: 6| Step: 12
Training loss: 1.1257942914962769
Validation loss: 1.708828935059168

Epoch: 6| Step: 13
Training loss: 1.4661085605621338
Validation loss: 1.6843355894088745

Epoch: 403| Step: 0
Training loss: 1.705560326576233
Validation loss: 1.7194760896826302

Epoch: 6| Step: 1
Training loss: 1.3073692321777344
Validation loss: 1.7029807964960735

Epoch: 6| Step: 2
Training loss: 1.0914911031723022
Validation loss: 1.7490595553510933

Epoch: 6| Step: 3
Training loss: 1.2411015033721924
Validation loss: 1.738899573203056

Epoch: 6| Step: 4
Training loss: 1.2313740253448486
Validation loss: 1.6920421033777215

Epoch: 6| Step: 5
Training loss: 0.8821010589599609
Validation loss: 1.7411720034896687

Epoch: 6| Step: 6
Training loss: 0.9122673869132996
Validation loss: 1.7557294766108196

Epoch: 6| Step: 7
Training loss: 1.3797922134399414
Validation loss: 1.704060887777677

Epoch: 6| Step: 8
Training loss: 0.9196820855140686
Validation loss: 1.7278764273530693

Epoch: 6| Step: 9
Training loss: 1.3698415756225586
Validation loss: 1.7715239114658807

Epoch: 6| Step: 10
Training loss: 1.0522329807281494
Validation loss: 1.7268127267078688

Epoch: 6| Step: 11
Training loss: 0.8192945122718811
Validation loss: 1.7228453838697044

Epoch: 6| Step: 12
Training loss: 0.7091715931892395
Validation loss: 1.7615791431037329

Epoch: 6| Step: 13
Training loss: 0.7601532936096191
Validation loss: 1.731645969934361

Epoch: 404| Step: 0
Training loss: 0.8315079808235168
Validation loss: 1.712348788015304

Epoch: 6| Step: 1
Training loss: 0.94972825050354
Validation loss: 1.7841577286361365

Epoch: 6| Step: 2
Training loss: 0.8716950416564941
Validation loss: 1.7702660458062285

Epoch: 6| Step: 3
Training loss: 1.3178033828735352
Validation loss: 1.7578822899890203

Epoch: 6| Step: 4
Training loss: 1.1754586696624756
Validation loss: 1.7498644654468825

Epoch: 6| Step: 5
Training loss: 1.29121732711792
Validation loss: 1.7440588705001339

Epoch: 6| Step: 6
Training loss: 0.6928439736366272
Validation loss: 1.7762052859029462

Epoch: 6| Step: 7
Training loss: 1.407515525817871
Validation loss: 1.7025281370327037

Epoch: 6| Step: 8
Training loss: 0.832223653793335
Validation loss: 1.7738254929101596

Epoch: 6| Step: 9
Training loss: 0.7721966505050659
Validation loss: 1.6861746593188214

Epoch: 6| Step: 10
Training loss: 1.3869425058364868
Validation loss: 1.7771672010421753

Epoch: 6| Step: 11
Training loss: 1.5963181257247925
Validation loss: 1.7020194735578311

Epoch: 6| Step: 12
Training loss: 0.9123979806900024
Validation loss: 1.7264584354175034

Epoch: 6| Step: 13
Training loss: 1.4038867950439453
Validation loss: 1.7360396205738027

Epoch: 405| Step: 0
Training loss: 1.6948952674865723
Validation loss: 1.7856177617144842

Epoch: 6| Step: 1
Training loss: 1.1887949705123901
Validation loss: 1.7415079301403416

Epoch: 6| Step: 2
Training loss: 0.8000069856643677
Validation loss: 1.7179336060759842

Epoch: 6| Step: 3
Training loss: 0.5213178992271423
Validation loss: 1.7265357073917185

Epoch: 6| Step: 4
Training loss: 1.3991904258728027
Validation loss: 1.756201471051862

Epoch: 6| Step: 5
Training loss: 1.5999394655227661
Validation loss: 1.754549253371454

Epoch: 6| Step: 6
Training loss: 0.8063092231750488
Validation loss: 1.7088628020337833

Epoch: 6| Step: 7
Training loss: 0.9031833410263062
Validation loss: 1.7318687041600545

Epoch: 6| Step: 8
Training loss: 1.3084266185760498
Validation loss: 1.7255980737747685

Epoch: 6| Step: 9
Training loss: 1.0358160734176636
Validation loss: 1.7020054735163206

Epoch: 6| Step: 10
Training loss: 0.8949506282806396
Validation loss: 1.6812606075758576

Epoch: 6| Step: 11
Training loss: 1.3008320331573486
Validation loss: 1.6955610718778384

Epoch: 6| Step: 12
Training loss: 0.7843730449676514
Validation loss: 1.7285148712896532

Epoch: 6| Step: 13
Training loss: 0.8670576810836792
Validation loss: 1.7399710916703748

Epoch: 406| Step: 0
Training loss: 0.4933955669403076
Validation loss: 1.7862006823221843

Epoch: 6| Step: 1
Training loss: 1.3641055822372437
Validation loss: 1.723113929071734

Epoch: 6| Step: 2
Training loss: 1.3386932611465454
Validation loss: 1.7363521168308873

Epoch: 6| Step: 3
Training loss: 0.6659058332443237
Validation loss: 1.7148118762559788

Epoch: 6| Step: 4
Training loss: 1.199575424194336
Validation loss: 1.71371808872428

Epoch: 6| Step: 5
Training loss: 1.2827556133270264
Validation loss: 1.709824315963253

Epoch: 6| Step: 6
Training loss: 0.8307671546936035
Validation loss: 1.7613367521634666

Epoch: 6| Step: 7
Training loss: 1.0480256080627441
Validation loss: 1.7404092793823571

Epoch: 6| Step: 8
Training loss: 1.3849008083343506
Validation loss: 1.6976897908795265

Epoch: 6| Step: 9
Training loss: 0.823506772518158
Validation loss: 1.7246414743443972

Epoch: 6| Step: 10
Training loss: 1.0144555568695068
Validation loss: 1.6868432433374467

Epoch: 6| Step: 11
Training loss: 1.5349667072296143
Validation loss: 1.7572809496233541

Epoch: 6| Step: 12
Training loss: 1.091737151145935
Validation loss: 1.7566680228838356

Epoch: 6| Step: 13
Training loss: 1.014488697052002
Validation loss: 1.7028693088921167

Epoch: 407| Step: 0
Training loss: 1.3675135374069214
Validation loss: 1.7458013667855212

Epoch: 6| Step: 1
Training loss: 1.4402384757995605
Validation loss: 1.7155885952775196

Epoch: 6| Step: 2
Training loss: 0.5507310032844543
Validation loss: 1.6870994901144376

Epoch: 6| Step: 3
Training loss: 0.8851656913757324
Validation loss: 1.683343264364427

Epoch: 6| Step: 4
Training loss: 1.1954489946365356
Validation loss: 1.7109788951053415

Epoch: 6| Step: 5
Training loss: 1.4246240854263306
Validation loss: 1.7154425933796873

Epoch: 6| Step: 6
Training loss: 0.6671731472015381
Validation loss: 1.7770844838952506

Epoch: 6| Step: 7
Training loss: 0.8839874267578125
Validation loss: 1.7268456707718551

Epoch: 6| Step: 8
Training loss: 1.1445668935775757
Validation loss: 1.7120837985828359

Epoch: 6| Step: 9
Training loss: 0.9790854454040527
Validation loss: 1.683678755196192

Epoch: 6| Step: 10
Training loss: 1.6692246198654175
Validation loss: 1.729517908506496

Epoch: 6| Step: 11
Training loss: 1.060525894165039
Validation loss: 1.7473873938283613

Epoch: 6| Step: 12
Training loss: 0.9820720553398132
Validation loss: 1.7375422254685433

Epoch: 6| Step: 13
Training loss: 0.8686821460723877
Validation loss: 1.7288777392397645

Epoch: 408| Step: 0
Training loss: 0.9551982879638672
Validation loss: 1.720247894205073

Epoch: 6| Step: 1
Training loss: 0.8649881482124329
Validation loss: 1.7406602226277834

Epoch: 6| Step: 2
Training loss: 0.7284253239631653
Validation loss: 1.7021271938918738

Epoch: 6| Step: 3
Training loss: 1.317682147026062
Validation loss: 1.7216297516258814

Epoch: 6| Step: 4
Training loss: 1.834179401397705
Validation loss: 1.6959760958148586

Epoch: 6| Step: 5
Training loss: 1.1781247854232788
Validation loss: 1.6964419759729856

Epoch: 6| Step: 6
Training loss: 1.1934852600097656
Validation loss: 1.763724616778794

Epoch: 6| Step: 7
Training loss: 1.1726493835449219
Validation loss: 1.7231666388050202

Epoch: 6| Step: 8
Training loss: 1.4073853492736816
Validation loss: 1.6825260039298766

Epoch: 6| Step: 9
Training loss: 1.1100051403045654
Validation loss: 1.75574630050249

Epoch: 6| Step: 10
Training loss: 1.042480707168579
Validation loss: 1.7701852629261632

Epoch: 6| Step: 11
Training loss: 0.74443519115448
Validation loss: 1.742479779387033

Epoch: 6| Step: 12
Training loss: 0.8946671485900879
Validation loss: 1.7476013501485188

Epoch: 6| Step: 13
Training loss: 0.5693920254707336
Validation loss: 1.7607537623374694

Epoch: 409| Step: 0
Training loss: 0.8236856460571289
Validation loss: 1.7069032038411787

Epoch: 6| Step: 1
Training loss: 1.2113561630249023
Validation loss: 1.7445858537509877

Epoch: 6| Step: 2
Training loss: 1.0049446821212769
Validation loss: 1.7370249289338306

Epoch: 6| Step: 3
Training loss: 1.0788469314575195
Validation loss: 1.7481487566424954

Epoch: 6| Step: 4
Training loss: 0.7956160306930542
Validation loss: 1.7686911988001999

Epoch: 6| Step: 5
Training loss: 1.6934971809387207
Validation loss: 1.7892408024880193

Epoch: 6| Step: 6
Training loss: 0.8573583364486694
Validation loss: 1.7802877528693086

Epoch: 6| Step: 7
Training loss: 0.9420356750488281
Validation loss: 1.7630838296746696

Epoch: 6| Step: 8
Training loss: 0.7827680706977844
Validation loss: 1.727441862065305

Epoch: 6| Step: 9
Training loss: 1.120519757270813
Validation loss: 1.7153637383573799

Epoch: 6| Step: 10
Training loss: 0.9633821249008179
Validation loss: 1.729703749379804

Epoch: 6| Step: 11
Training loss: 1.1010680198669434
Validation loss: 1.7253650542228454

Epoch: 6| Step: 12
Training loss: 1.2680978775024414
Validation loss: 1.7295791846449657

Epoch: 6| Step: 13
Training loss: 1.2485997676849365
Validation loss: 1.7984009570972894

Epoch: 410| Step: 0
Training loss: 0.6120126247406006
Validation loss: 1.6766293189858879

Epoch: 6| Step: 1
Training loss: 1.5104115009307861
Validation loss: 1.730446555281198

Epoch: 6| Step: 2
Training loss: 1.0010210275650024
Validation loss: 1.7307700514793396

Epoch: 6| Step: 3
Training loss: 0.7454431056976318
Validation loss: 1.7170892966690885

Epoch: 6| Step: 4
Training loss: 1.1403616666793823
Validation loss: 1.757483260605925

Epoch: 6| Step: 5
Training loss: 1.5335907936096191
Validation loss: 1.733509486721408

Epoch: 6| Step: 6
Training loss: 0.721331000328064
Validation loss: 1.7461466455972323

Epoch: 6| Step: 7
Training loss: 1.2522451877593994
Validation loss: 1.7404781092879593

Epoch: 6| Step: 8
Training loss: 1.7539687156677246
Validation loss: 1.7391312224890596

Epoch: 6| Step: 9
Training loss: 0.6721876859664917
Validation loss: 1.7246377198926863

Epoch: 6| Step: 10
Training loss: 1.0264687538146973
Validation loss: 1.795677443986298

Epoch: 6| Step: 11
Training loss: 1.2752667665481567
Validation loss: 1.7344465230100898

Epoch: 6| Step: 12
Training loss: 1.3618605136871338
Validation loss: 1.745687989778416

Epoch: 6| Step: 13
Training loss: 0.8212215900421143
Validation loss: 1.7441584653751825

Epoch: 411| Step: 0
Training loss: 1.4863145351409912
Validation loss: 1.740227988971177

Epoch: 6| Step: 1
Training loss: 0.9556686878204346
Validation loss: 1.7246073753603044

Epoch: 6| Step: 2
Training loss: 0.5863673090934753
Validation loss: 1.7306248782783427

Epoch: 6| Step: 3
Training loss: 1.0632715225219727
Validation loss: 1.7586906327996203

Epoch: 6| Step: 4
Training loss: 1.2358908653259277
Validation loss: 1.7403109278730167

Epoch: 6| Step: 5
Training loss: 0.7153133153915405
Validation loss: 1.7642267083608976

Epoch: 6| Step: 6
Training loss: 1.3064308166503906
Validation loss: 1.7177251000558176

Epoch: 6| Step: 7
Training loss: 0.7865133881568909
Validation loss: 1.765572908104107

Epoch: 6| Step: 8
Training loss: 1.4325840473175049
Validation loss: 1.7610339144224763

Epoch: 6| Step: 9
Training loss: 1.050718069076538
Validation loss: 1.734002508142943

Epoch: 6| Step: 10
Training loss: 0.8280012607574463
Validation loss: 1.692183825277513

Epoch: 6| Step: 11
Training loss: 1.3227261304855347
Validation loss: 1.733264733386296

Epoch: 6| Step: 12
Training loss: 1.529792070388794
Validation loss: 1.697602391242981

Epoch: 6| Step: 13
Training loss: 0.9499541521072388
Validation loss: 1.741584349704045

Epoch: 412| Step: 0
Training loss: 0.8997468948364258
Validation loss: 1.6828743078375374

Epoch: 6| Step: 1
Training loss: 1.4181222915649414
Validation loss: 1.7566240756742415

Epoch: 6| Step: 2
Training loss: 0.7179262042045593
Validation loss: 1.7406388226375784

Epoch: 6| Step: 3
Training loss: 1.4871264696121216
Validation loss: 1.753228597743537

Epoch: 6| Step: 4
Training loss: 1.475283145904541
Validation loss: 1.722093633426133

Epoch: 6| Step: 5
Training loss: 0.7076663970947266
Validation loss: 1.7172217663898264

Epoch: 6| Step: 6
Training loss: 0.5614986419677734
Validation loss: 1.7231559291962655

Epoch: 6| Step: 7
Training loss: 0.9424818754196167
Validation loss: 1.7483464146173129

Epoch: 6| Step: 8
Training loss: 1.25433349609375
Validation loss: 1.7651835077552385

Epoch: 6| Step: 9
Training loss: 1.3501896858215332
Validation loss: 1.7594075126032676

Epoch: 6| Step: 10
Training loss: 1.1833325624465942
Validation loss: 1.7382041946534188

Epoch: 6| Step: 11
Training loss: 0.6582504510879517
Validation loss: 1.7848438191157516

Epoch: 6| Step: 12
Training loss: 1.243239402770996
Validation loss: 1.6902656414175545

Epoch: 6| Step: 13
Training loss: 0.7217866778373718
Validation loss: 1.754655647021468

Epoch: 413| Step: 0
Training loss: 1.3914380073547363
Validation loss: 1.7206972209356164

Epoch: 6| Step: 1
Training loss: 0.6201428174972534
Validation loss: 1.739877236786709

Epoch: 6| Step: 2
Training loss: 1.209504246711731
Validation loss: 1.7553166894502537

Epoch: 6| Step: 3
Training loss: 1.2850786447525024
Validation loss: 1.7702407452367968

Epoch: 6| Step: 4
Training loss: 0.8093432188034058
Validation loss: 1.6992228672068606

Epoch: 6| Step: 5
Training loss: 1.8026645183563232
Validation loss: 1.737414868929053

Epoch: 6| Step: 6
Training loss: 1.209330439567566
Validation loss: 1.7331309421088106

Epoch: 6| Step: 7
Training loss: 0.8990182876586914
Validation loss: 1.7114727881646925

Epoch: 6| Step: 8
Training loss: 1.0422686338424683
Validation loss: 1.7245634704507806

Epoch: 6| Step: 9
Training loss: 0.829813539981842
Validation loss: 1.7360273766261276

Epoch: 6| Step: 10
Training loss: 1.1744158267974854
Validation loss: 1.72411935944711

Epoch: 6| Step: 11
Training loss: 0.45614174008369446
Validation loss: 1.7798221470207296

Epoch: 6| Step: 12
Training loss: 1.1298611164093018
Validation loss: 1.6935277741442445

Epoch: 6| Step: 13
Training loss: 0.8952579498291016
Validation loss: 1.7014735796118294

Epoch: 414| Step: 0
Training loss: 1.3828939199447632
Validation loss: 1.6995911905842442

Epoch: 6| Step: 1
Training loss: 0.9063534736633301
Validation loss: 1.7549591218271563

Epoch: 6| Step: 2
Training loss: 0.9901210069656372
Validation loss: 1.7635737196091683

Epoch: 6| Step: 3
Training loss: 0.5324227213859558
Validation loss: 1.7015523449067147

Epoch: 6| Step: 4
Training loss: 1.1095823049545288
Validation loss: 1.7640144645526845

Epoch: 6| Step: 5
Training loss: 1.5007609128952026
Validation loss: 1.7474756138299101

Epoch: 6| Step: 6
Training loss: 1.580134391784668
Validation loss: 1.7668928343762633

Epoch: 6| Step: 7
Training loss: 0.6469590663909912
Validation loss: 1.71399413834336

Epoch: 6| Step: 8
Training loss: 0.731511116027832
Validation loss: 1.6776276198766564

Epoch: 6| Step: 9
Training loss: 1.080627679824829
Validation loss: 1.720423540761394

Epoch: 6| Step: 10
Training loss: 1.0270963907241821
Validation loss: 1.7036692365523307

Epoch: 6| Step: 11
Training loss: 1.2729582786560059
Validation loss: 1.7049995763327486

Epoch: 6| Step: 12
Training loss: 0.7930213809013367
Validation loss: 1.7025603619954919

Epoch: 6| Step: 13
Training loss: 0.7994821667671204
Validation loss: 1.7155742017171716

Epoch: 415| Step: 0
Training loss: 1.2740533351898193
Validation loss: 1.7430085853863788

Epoch: 6| Step: 1
Training loss: 1.2709827423095703
Validation loss: 1.7148752943161996

Epoch: 6| Step: 2
Training loss: 0.851347029209137
Validation loss: 1.6795683689014886

Epoch: 6| Step: 3
Training loss: 1.2945234775543213
Validation loss: 1.7736763825980566

Epoch: 6| Step: 4
Training loss: 1.0208353996276855
Validation loss: 1.7379868748367473

Epoch: 6| Step: 5
Training loss: 1.6857558488845825
Validation loss: 1.779135920668161

Epoch: 6| Step: 6
Training loss: 1.1138746738433838
Validation loss: 1.7430375135073097

Epoch: 6| Step: 7
Training loss: 0.7048171162605286
Validation loss: 1.7488104874087917

Epoch: 6| Step: 8
Training loss: 0.802831768989563
Validation loss: 1.7506805286612561

Epoch: 6| Step: 9
Training loss: 1.1614091396331787
Validation loss: 1.683161368934057

Epoch: 6| Step: 10
Training loss: 0.6402041912078857
Validation loss: 1.7103747347349763

Epoch: 6| Step: 11
Training loss: 0.7683946490287781
Validation loss: 1.7315026637046569

Epoch: 6| Step: 12
Training loss: 0.9234880805015564
Validation loss: 1.7853220701217651

Epoch: 6| Step: 13
Training loss: 1.2714064121246338
Validation loss: 1.7266326655623734

Epoch: 416| Step: 0
Training loss: 1.001479148864746
Validation loss: 1.69314577246225

Epoch: 6| Step: 1
Training loss: 1.2165930271148682
Validation loss: 1.737350199812202

Epoch: 6| Step: 2
Training loss: 0.9261665344238281
Validation loss: 1.7711343816531602

Epoch: 6| Step: 3
Training loss: 0.9274698495864868
Validation loss: 1.7583520668809132

Epoch: 6| Step: 4
Training loss: 1.8691096305847168
Validation loss: 1.7012759665007233

Epoch: 6| Step: 5
Training loss: 0.7436361908912659
Validation loss: 1.732225647536657

Epoch: 6| Step: 6
Training loss: 0.9813798666000366
Validation loss: 1.7089526499471357

Epoch: 6| Step: 7
Training loss: 1.2689026594161987
Validation loss: 1.7321340127657818

Epoch: 6| Step: 8
Training loss: 0.5550798773765564
Validation loss: 1.7436173987644974

Epoch: 6| Step: 9
Training loss: 0.967728853225708
Validation loss: 1.6982881279401882

Epoch: 6| Step: 10
Training loss: 0.7868479490280151
Validation loss: 1.703508480902641

Epoch: 6| Step: 11
Training loss: 1.4369854927062988
Validation loss: 1.7226400234365975

Epoch: 6| Step: 12
Training loss: 0.7684868574142456
Validation loss: 1.7101807978845411

Epoch: 6| Step: 13
Training loss: 0.8259186148643494
Validation loss: 1.6908533419332197

Epoch: 417| Step: 0
Training loss: 1.4355474710464478
Validation loss: 1.7156872954419864

Epoch: 6| Step: 1
Training loss: 0.8669945001602173
Validation loss: 1.6858640511830647

Epoch: 6| Step: 2
Training loss: 1.3104987144470215
Validation loss: 1.710759981986015

Epoch: 6| Step: 3
Training loss: 1.1656203269958496
Validation loss: 1.7273864412820468

Epoch: 6| Step: 4
Training loss: 0.8483899831771851
Validation loss: 1.7322117833681003

Epoch: 6| Step: 5
Training loss: 0.9223849773406982
Validation loss: 1.6819226075244207

Epoch: 6| Step: 6
Training loss: 1.0211749076843262
Validation loss: 1.670677468340884

Epoch: 6| Step: 7
Training loss: 0.7162400484085083
Validation loss: 1.7353610595067341

Epoch: 6| Step: 8
Training loss: 0.996282160282135
Validation loss: 1.6894096866730721

Epoch: 6| Step: 9
Training loss: 1.1821352243423462
Validation loss: 1.7140749718553276

Epoch: 6| Step: 10
Training loss: 0.7001330852508545
Validation loss: 1.7639711928623978

Epoch: 6| Step: 11
Training loss: 1.307649850845337
Validation loss: 1.7302806326138076

Epoch: 6| Step: 12
Training loss: 1.511252999305725
Validation loss: 1.7253805386122836

Epoch: 6| Step: 13
Training loss: 0.6247726082801819
Validation loss: 1.7516658613758702

Epoch: 418| Step: 0
Training loss: 1.472795844078064
Validation loss: 1.7326734860738118

Epoch: 6| Step: 1
Training loss: 1.1139417886734009
Validation loss: 1.7360956604762743

Epoch: 6| Step: 2
Training loss: 1.1015323400497437
Validation loss: 1.6663618626133088

Epoch: 6| Step: 3
Training loss: 0.905907154083252
Validation loss: 1.696257257974276

Epoch: 6| Step: 4
Training loss: 1.4025462865829468
Validation loss: 1.7180979303134385

Epoch: 6| Step: 5
Training loss: 0.8754022717475891
Validation loss: 1.7215583298795967

Epoch: 6| Step: 6
Training loss: 0.8349361419677734
Validation loss: 1.6772602014644171

Epoch: 6| Step: 7
Training loss: 0.7779231071472168
Validation loss: 1.7569749970589914

Epoch: 6| Step: 8
Training loss: 1.0334144830703735
Validation loss: 1.7245021763668265

Epoch: 6| Step: 9
Training loss: 1.2579896450042725
Validation loss: 1.783085302640033

Epoch: 6| Step: 10
Training loss: 1.0338947772979736
Validation loss: 1.6729524443226476

Epoch: 6| Step: 11
Training loss: 1.03614342212677
Validation loss: 1.7319073446335331

Epoch: 6| Step: 12
Training loss: 0.8544501066207886
Validation loss: 1.720880518677414

Epoch: 6| Step: 13
Training loss: 1.2441353797912598
Validation loss: 1.6718744718900291

Epoch: 419| Step: 0
Training loss: 1.4872431755065918
Validation loss: 1.7238831545716973

Epoch: 6| Step: 1
Training loss: 1.146565318107605
Validation loss: 1.6753759473882697

Epoch: 6| Step: 2
Training loss: 1.1330227851867676
Validation loss: 1.7267367327085106

Epoch: 6| Step: 3
Training loss: 1.5860116481781006
Validation loss: 1.6897581341446086

Epoch: 6| Step: 4
Training loss: 1.1539452075958252
Validation loss: 1.6774019605369979

Epoch: 6| Step: 5
Training loss: 1.5896265506744385
Validation loss: 1.74012662518409

Epoch: 6| Step: 6
Training loss: 0.8256415724754333
Validation loss: 1.7292577476911648

Epoch: 6| Step: 7
Training loss: 1.3298332691192627
Validation loss: 1.712078667456104

Epoch: 6| Step: 8
Training loss: 0.42017102241516113
Validation loss: 1.7001249662009619

Epoch: 6| Step: 9
Training loss: 0.7504316568374634
Validation loss: 1.7447166801780782

Epoch: 6| Step: 10
Training loss: 0.8831425309181213
Validation loss: 1.7814951186539025

Epoch: 6| Step: 11
Training loss: 0.7440917491912842
Validation loss: 1.733306090037028

Epoch: 6| Step: 12
Training loss: 0.8299363255500793
Validation loss: 1.7073191372297143

Epoch: 6| Step: 13
Training loss: 0.8583558201789856
Validation loss: 1.7378047589332826

Epoch: 420| Step: 0
Training loss: 1.437422752380371
Validation loss: 1.7137509751063522

Epoch: 6| Step: 1
Training loss: 0.9642273187637329
Validation loss: 1.7743491613736717

Epoch: 6| Step: 2
Training loss: 0.8675428628921509
Validation loss: 1.8257199577105943

Epoch: 6| Step: 3
Training loss: 1.277693510055542
Validation loss: 1.7932699688019291

Epoch: 6| Step: 4
Training loss: 0.8152592778205872
Validation loss: 1.806274483280797

Epoch: 6| Step: 5
Training loss: 1.3759139776229858
Validation loss: 1.7835619449615479

Epoch: 6| Step: 6
Training loss: 1.1504229307174683
Validation loss: 1.7696564389813332

Epoch: 6| Step: 7
Training loss: 0.9117841720581055
Validation loss: 1.795217546083594

Epoch: 6| Step: 8
Training loss: 1.087712049484253
Validation loss: 1.7308089220395653

Epoch: 6| Step: 9
Training loss: 0.5552506446838379
Validation loss: 1.678694309726838

Epoch: 6| Step: 10
Training loss: 1.1990060806274414
Validation loss: 1.6819149332661782

Epoch: 6| Step: 11
Training loss: 1.0438055992126465
Validation loss: 1.7354121105645293

Epoch: 6| Step: 12
Training loss: 1.306889295578003
Validation loss: 1.75367872945724

Epoch: 6| Step: 13
Training loss: 0.6417995095252991
Validation loss: 1.7105067737640873

Epoch: 421| Step: 0
Training loss: 1.2208940982818604
Validation loss: 1.759633518034412

Epoch: 6| Step: 1
Training loss: 1.6234371662139893
Validation loss: 1.6636091932173698

Epoch: 6| Step: 2
Training loss: 2.0482542514801025
Validation loss: 1.7091085500614618

Epoch: 6| Step: 3
Training loss: 1.3311275243759155
Validation loss: 1.7170155099643174

Epoch: 6| Step: 4
Training loss: 1.1428806781768799
Validation loss: 1.75503501712635

Epoch: 6| Step: 5
Training loss: 1.1805596351623535
Validation loss: 1.729201405279098

Epoch: 6| Step: 6
Training loss: 0.8508850336074829
Validation loss: 1.7497395148841284

Epoch: 6| Step: 7
Training loss: 1.0450001955032349
Validation loss: 1.7110821867501864

Epoch: 6| Step: 8
Training loss: 0.5385946035385132
Validation loss: 1.7025383903134255

Epoch: 6| Step: 9
Training loss: 0.8429723978042603
Validation loss: 1.7295166651407878

Epoch: 6| Step: 10
Training loss: 0.894768238067627
Validation loss: 1.7327689150328278

Epoch: 6| Step: 11
Training loss: 0.9198927879333496
Validation loss: 1.7671754872927101

Epoch: 6| Step: 12
Training loss: 0.9670964479446411
Validation loss: 1.680246469795063

Epoch: 6| Step: 13
Training loss: 0.76414555311203
Validation loss: 1.7210179913428523

Epoch: 422| Step: 0
Training loss: 1.019559621810913
Validation loss: 1.6963190993955057

Epoch: 6| Step: 1
Training loss: 1.0709848403930664
Validation loss: 1.7946274626639582

Epoch: 6| Step: 2
Training loss: 0.7407070994377136
Validation loss: 1.7271724054890294

Epoch: 6| Step: 3
Training loss: 1.2117094993591309
Validation loss: 1.7584263240137408

Epoch: 6| Step: 4
Training loss: 0.953463077545166
Validation loss: 1.7239811471713486

Epoch: 6| Step: 5
Training loss: 1.8559470176696777
Validation loss: 1.7426216358779578

Epoch: 6| Step: 6
Training loss: 0.778722882270813
Validation loss: 1.7839486470786474

Epoch: 6| Step: 7
Training loss: 0.7346989512443542
Validation loss: 1.7209210485540412

Epoch: 6| Step: 8
Training loss: 0.9185525178909302
Validation loss: 1.7053031152294529

Epoch: 6| Step: 9
Training loss: 0.7980690002441406
Validation loss: 1.6932718189813758

Epoch: 6| Step: 10
Training loss: 0.6478334069252014
Validation loss: 1.760594646135966

Epoch: 6| Step: 11
Training loss: 1.1440846920013428
Validation loss: 1.7117522429394465

Epoch: 6| Step: 12
Training loss: 1.205767273902893
Validation loss: 1.7083664888976722

Epoch: 6| Step: 13
Training loss: 0.9726496934890747
Validation loss: 1.7203431411456036

Epoch: 423| Step: 0
Training loss: 1.1818530559539795
Validation loss: 1.7498336991956156

Epoch: 6| Step: 1
Training loss: 1.5743958950042725
Validation loss: 1.7111143258310133

Epoch: 6| Step: 2
Training loss: 1.073752999305725
Validation loss: 1.7266571419213408

Epoch: 6| Step: 3
Training loss: 0.6879264116287231
Validation loss: 1.7683724485417849

Epoch: 6| Step: 4
Training loss: 0.9476925730705261
Validation loss: 1.7461991617756505

Epoch: 6| Step: 5
Training loss: 1.2778923511505127
Validation loss: 1.7404612238689134

Epoch: 6| Step: 6
Training loss: 0.7611017227172852
Validation loss: 1.744039309922085

Epoch: 6| Step: 7
Training loss: 0.753481388092041
Validation loss: 1.7368444063330208

Epoch: 6| Step: 8
Training loss: 0.8508201837539673
Validation loss: 1.7325512696337957

Epoch: 6| Step: 9
Training loss: 1.6368725299835205
Validation loss: 1.7310795476359706

Epoch: 6| Step: 10
Training loss: 0.9433717131614685
Validation loss: 1.730685289188098

Epoch: 6| Step: 11
Training loss: 1.170863389968872
Validation loss: 1.7309747844614007

Epoch: 6| Step: 12
Training loss: 0.4791082739830017
Validation loss: 1.7951475779215496

Epoch: 6| Step: 13
Training loss: 1.1358038187026978
Validation loss: 1.733904835998371

Epoch: 424| Step: 0
Training loss: 0.9736813902854919
Validation loss: 1.7429305289381294

Epoch: 6| Step: 1
Training loss: 1.0168123245239258
Validation loss: 1.7206936138932423

Epoch: 6| Step: 2
Training loss: 1.5656596422195435
Validation loss: 1.6935319644148632

Epoch: 6| Step: 3
Training loss: 0.7775639891624451
Validation loss: 1.7000259737814627

Epoch: 6| Step: 4
Training loss: 1.0364240407943726
Validation loss: 1.7307094873920563

Epoch: 6| Step: 5
Training loss: 1.0896378755569458
Validation loss: 1.7785096040336035

Epoch: 6| Step: 6
Training loss: 1.1443116664886475
Validation loss: 1.7523939647982198

Epoch: 6| Step: 7
Training loss: 1.734779953956604
Validation loss: 1.7296056708981913

Epoch: 6| Step: 8
Training loss: 0.8781137466430664
Validation loss: 1.6745918976363314

Epoch: 6| Step: 9
Training loss: 0.8328507542610168
Validation loss: 1.703136545355602

Epoch: 6| Step: 10
Training loss: 1.1297787427902222
Validation loss: 1.7263720086825791

Epoch: 6| Step: 11
Training loss: 0.7891603112220764
Validation loss: 1.730562053700929

Epoch: 6| Step: 12
Training loss: 0.6253145933151245
Validation loss: 1.7353689503926102

Epoch: 6| Step: 13
Training loss: 0.8959774374961853
Validation loss: 1.723720585146258

Epoch: 425| Step: 0
Training loss: 1.7446327209472656
Validation loss: 1.7447632666557067

Epoch: 6| Step: 1
Training loss: 1.1222050189971924
Validation loss: 1.7953707607843543

Epoch: 6| Step: 2
Training loss: 0.9736536741256714
Validation loss: 1.7447224688786331

Epoch: 6| Step: 3
Training loss: 1.051192045211792
Validation loss: 1.7200082220057005

Epoch: 6| Step: 4
Training loss: 0.7106643915176392
Validation loss: 1.7148087768144504

Epoch: 6| Step: 5
Training loss: 1.068173885345459
Validation loss: 1.6984927731175576

Epoch: 6| Step: 6
Training loss: 1.2133066654205322
Validation loss: 1.7569604676256898

Epoch: 6| Step: 7
Training loss: 1.0418481826782227
Validation loss: 1.7156802800393873

Epoch: 6| Step: 8
Training loss: 0.7781989574432373
Validation loss: 1.7087215582529705

Epoch: 6| Step: 9
Training loss: 1.0374486446380615
Validation loss: 1.744968327142859

Epoch: 6| Step: 10
Training loss: 0.6714940071105957
Validation loss: 1.7388183301494968

Epoch: 6| Step: 11
Training loss: 1.3943145275115967
Validation loss: 1.7015397625584756

Epoch: 6| Step: 12
Training loss: 0.8283437490463257
Validation loss: 1.7125700801931403

Epoch: 6| Step: 13
Training loss: 0.8979895114898682
Validation loss: 1.761025285208097

Epoch: 426| Step: 0
Training loss: 0.9378167390823364
Validation loss: 1.726866856698067

Epoch: 6| Step: 1
Training loss: 1.0054150819778442
Validation loss: 1.7078943919110041

Epoch: 6| Step: 2
Training loss: 1.4702839851379395
Validation loss: 1.676089725186748

Epoch: 6| Step: 3
Training loss: 1.5387723445892334
Validation loss: 1.739645347800306

Epoch: 6| Step: 4
Training loss: 1.0549876689910889
Validation loss: 1.775149300534238

Epoch: 6| Step: 5
Training loss: 1.0856962203979492
Validation loss: 1.7637324858737249

Epoch: 6| Step: 6
Training loss: 1.1916531324386597
Validation loss: 1.6908948152296004

Epoch: 6| Step: 7
Training loss: 1.2163587808609009
Validation loss: 1.7625367026175223

Epoch: 6| Step: 8
Training loss: 1.0538642406463623
Validation loss: 1.7646304638155046

Epoch: 6| Step: 9
Training loss: 0.8033292293548584
Validation loss: 1.687800512518934

Epoch: 6| Step: 10
Training loss: 0.5375723242759705
Validation loss: 1.7263293855933732

Epoch: 6| Step: 11
Training loss: 0.46712633967399597
Validation loss: 1.7596928483696395

Epoch: 6| Step: 12
Training loss: 1.2364563941955566
Validation loss: 1.6898222866878714

Epoch: 6| Step: 13
Training loss: 0.7606555223464966
Validation loss: 1.7063607118463004

Epoch: 427| Step: 0
Training loss: 1.029140591621399
Validation loss: 1.711752273703134

Epoch: 6| Step: 1
Training loss: 0.5423299074172974
Validation loss: 1.7221288527211835

Epoch: 6| Step: 2
Training loss: 1.230285406112671
Validation loss: 1.691251741942539

Epoch: 6| Step: 3
Training loss: 0.7856863737106323
Validation loss: 1.745474047558282

Epoch: 6| Step: 4
Training loss: 1.1073116064071655
Validation loss: 1.7390762695702173

Epoch: 6| Step: 5
Training loss: 1.3104891777038574
Validation loss: 1.7121599220460462

Epoch: 6| Step: 6
Training loss: 1.3238472938537598
Validation loss: 1.7136496984830467

Epoch: 6| Step: 7
Training loss: 0.845349907875061
Validation loss: 1.7489533334650018

Epoch: 6| Step: 8
Training loss: 1.48087739944458
Validation loss: 1.7320608746620916

Epoch: 6| Step: 9
Training loss: 0.9535768032073975
Validation loss: 1.7193658838989914

Epoch: 6| Step: 10
Training loss: 1.0677504539489746
Validation loss: 1.759335788347388

Epoch: 6| Step: 11
Training loss: 1.203802227973938
Validation loss: 1.6691194516356274

Epoch: 6| Step: 12
Training loss: 0.8345503807067871
Validation loss: 1.729922212580199

Epoch: 6| Step: 13
Training loss: 0.9275324940681458
Validation loss: 1.6652008589877878

Epoch: 428| Step: 0
Training loss: 1.1894176006317139
Validation loss: 1.728397866731049

Epoch: 6| Step: 1
Training loss: 1.0940258502960205
Validation loss: 1.7131377240662933

Epoch: 6| Step: 2
Training loss: 1.4203619956970215
Validation loss: 1.7069481713797456

Epoch: 6| Step: 3
Training loss: 1.0841361284255981
Validation loss: 1.7113548171135686

Epoch: 6| Step: 4
Training loss: 0.8718814253807068
Validation loss: 1.7079200667719687

Epoch: 6| Step: 5
Training loss: 0.7732145190238953
Validation loss: 1.7158368428548176

Epoch: 6| Step: 6
Training loss: 1.0034897327423096
Validation loss: 1.7217104896422355

Epoch: 6| Step: 7
Training loss: 0.9453705549240112
Validation loss: 1.6507121850085515

Epoch: 6| Step: 8
Training loss: 1.5971578359603882
Validation loss: 1.7488962219607445

Epoch: 6| Step: 9
Training loss: 1.0534722805023193
Validation loss: 1.6802902196043281

Epoch: 6| Step: 10
Training loss: 0.8362170457839966
Validation loss: 1.7234742769631006

Epoch: 6| Step: 11
Training loss: 0.8966152667999268
Validation loss: 1.7335093841757825

Epoch: 6| Step: 12
Training loss: 0.787081241607666
Validation loss: 1.722381978906611

Epoch: 6| Step: 13
Training loss: 0.6813963651657104
Validation loss: 1.74832595035594

Epoch: 429| Step: 0
Training loss: 1.0399441719055176
Validation loss: 1.7233032654690486

Epoch: 6| Step: 1
Training loss: 1.0530704259872437
Validation loss: 1.7349006027303717

Epoch: 6| Step: 2
Training loss: 0.6104440689086914
Validation loss: 1.7136237518761748

Epoch: 6| Step: 3
Training loss: 0.7123769521713257
Validation loss: 1.7072890650841497

Epoch: 6| Step: 4
Training loss: 1.1729228496551514
Validation loss: 1.7240311215000768

Epoch: 6| Step: 5
Training loss: 1.1751408576965332
Validation loss: 1.7085161234742852

Epoch: 6| Step: 6
Training loss: 0.8164193034172058
Validation loss: 1.729033189435159

Epoch: 6| Step: 7
Training loss: 1.4891562461853027
Validation loss: 1.721088586315032

Epoch: 6| Step: 8
Training loss: 1.0612187385559082
Validation loss: 1.6964120275230818

Epoch: 6| Step: 9
Training loss: 0.6658784747123718
Validation loss: 1.6985943868596067

Epoch: 6| Step: 10
Training loss: 1.6990201473236084
Validation loss: 1.7244370214400753

Epoch: 6| Step: 11
Training loss: 0.5254620313644409
Validation loss: 1.70535042337192

Epoch: 6| Step: 12
Training loss: 1.1762111186981201
Validation loss: 1.68346526545863

Epoch: 6| Step: 13
Training loss: 0.9653860926628113
Validation loss: 1.6787321336807743

Epoch: 430| Step: 0
Training loss: 1.32126784324646
Validation loss: 1.713571588198344

Epoch: 6| Step: 1
Training loss: 0.784402072429657
Validation loss: 1.7239962059964415

Epoch: 6| Step: 2
Training loss: 0.5648682117462158
Validation loss: 1.7492094411644885

Epoch: 6| Step: 3
Training loss: 0.6900423169136047
Validation loss: 1.7039698195713822

Epoch: 6| Step: 4
Training loss: 0.9491695165634155
Validation loss: 1.700041670953074

Epoch: 6| Step: 5
Training loss: 1.4420931339263916
Validation loss: 1.7259447061887352

Epoch: 6| Step: 6
Training loss: 1.2203998565673828
Validation loss: 1.7126696385363096

Epoch: 6| Step: 7
Training loss: 0.8854920864105225
Validation loss: 1.6580320237785258

Epoch: 6| Step: 8
Training loss: 1.3897264003753662
Validation loss: 1.6592909648854246

Epoch: 6| Step: 9
Training loss: 0.922592282295227
Validation loss: 1.704979440217377

Epoch: 6| Step: 10
Training loss: 1.1991097927093506
Validation loss: 1.6975116473372265

Epoch: 6| Step: 11
Training loss: 0.8816443681716919
Validation loss: 1.7366118905364827

Epoch: 6| Step: 12
Training loss: 0.9063059687614441
Validation loss: 1.6875207808709913

Epoch: 6| Step: 13
Training loss: 1.1306021213531494
Validation loss: 1.7244781178812827

Epoch: 431| Step: 0
Training loss: 1.0665565729141235
Validation loss: 1.7034779787063599

Epoch: 6| Step: 1
Training loss: 0.8371530771255493
Validation loss: 1.7379017119766564

Epoch: 6| Step: 2
Training loss: 0.8143417835235596
Validation loss: 1.7354613017010432

Epoch: 6| Step: 3
Training loss: 1.1544896364212036
Validation loss: 1.6883008467253817

Epoch: 6| Step: 4
Training loss: 1.116451382637024
Validation loss: 1.6504704606148504

Epoch: 6| Step: 5
Training loss: 0.6500688195228577
Validation loss: 1.715074719921235

Epoch: 6| Step: 6
Training loss: 0.7704135179519653
Validation loss: 1.7141029142564344

Epoch: 6| Step: 7
Training loss: 1.317824363708496
Validation loss: 1.68116497096195

Epoch: 6| Step: 8
Training loss: 1.243476152420044
Validation loss: 1.6659185412109538

Epoch: 6| Step: 9
Training loss: 1.2816497087478638
Validation loss: 1.69766616564925

Epoch: 6| Step: 10
Training loss: 0.8647359609603882
Validation loss: 1.7030635649158108

Epoch: 6| Step: 11
Training loss: 1.3233959674835205
Validation loss: 1.659865310115199

Epoch: 6| Step: 12
Training loss: 1.18975031375885
Validation loss: 1.7043710998309556

Epoch: 6| Step: 13
Training loss: 0.23073141276836395
Validation loss: 1.6593888946758804

Epoch: 432| Step: 0
Training loss: 1.2604484558105469
Validation loss: 1.7018410877514911

Epoch: 6| Step: 1
Training loss: 1.5754679441452026
Validation loss: 1.7293181880827873

Epoch: 6| Step: 2
Training loss: 0.5240310430526733
Validation loss: 1.7409358665507326

Epoch: 6| Step: 3
Training loss: 1.5741103887557983
Validation loss: 1.7128923221301007

Epoch: 6| Step: 4
Training loss: 0.4843977391719818
Validation loss: 1.6837304099913566

Epoch: 6| Step: 5
Training loss: 0.7224806547164917
Validation loss: 1.7555335337115872

Epoch: 6| Step: 6
Training loss: 0.8994556665420532
Validation loss: 1.747222872190578

Epoch: 6| Step: 7
Training loss: 1.360003113746643
Validation loss: 1.6927661229205389

Epoch: 6| Step: 8
Training loss: 0.5796188116073608
Validation loss: 1.7412002548094718

Epoch: 6| Step: 9
Training loss: 1.1781578063964844
Validation loss: 1.7545208943787443

Epoch: 6| Step: 10
Training loss: 0.7604487538337708
Validation loss: 1.737687349319458

Epoch: 6| Step: 11
Training loss: 1.4869349002838135
Validation loss: 1.7652338935482887

Epoch: 6| Step: 12
Training loss: 0.9032776951789856
Validation loss: 1.7516158332106888

Epoch: 6| Step: 13
Training loss: 0.7679093480110168
Validation loss: 1.7185605110660676

Epoch: 433| Step: 0
Training loss: 1.1328967809677124
Validation loss: 1.6629641030424385

Epoch: 6| Step: 1
Training loss: 1.326357364654541
Validation loss: 1.6971593620956584

Epoch: 6| Step: 2
Training loss: 1.02094566822052
Validation loss: 1.6852731961075977

Epoch: 6| Step: 3
Training loss: 0.9774147272109985
Validation loss: 1.6564080792088662

Epoch: 6| Step: 4
Training loss: 0.9911523461341858
Validation loss: 1.7161699251462055

Epoch: 6| Step: 5
Training loss: 0.9176928997039795
Validation loss: 1.6613081751331207

Epoch: 6| Step: 6
Training loss: 1.6339492797851562
Validation loss: 1.7527450617923532

Epoch: 6| Step: 7
Training loss: 1.0564377307891846
Validation loss: 1.7010754821121052

Epoch: 6| Step: 8
Training loss: 1.3013625144958496
Validation loss: 1.6781289487756708

Epoch: 6| Step: 9
Training loss: 0.3718026280403137
Validation loss: 1.732003632412162

Epoch: 6| Step: 10
Training loss: 0.8522929549217224
Validation loss: 1.7341946991541053

Epoch: 6| Step: 11
Training loss: 0.5909081697463989
Validation loss: 1.7522566421057588

Epoch: 6| Step: 12
Training loss: 1.1832501888275146
Validation loss: 1.730709736065198

Epoch: 6| Step: 13
Training loss: 1.1204314231872559
Validation loss: 1.7726947287077546

Epoch: 434| Step: 0
Training loss: 0.6620364189147949
Validation loss: 1.706363526723718

Epoch: 6| Step: 1
Training loss: 1.546134352684021
Validation loss: 1.756259117075192

Epoch: 6| Step: 2
Training loss: 1.3263556957244873
Validation loss: 1.746426546445457

Epoch: 6| Step: 3
Training loss: 0.8682892322540283
Validation loss: 1.729086874633707

Epoch: 6| Step: 4
Training loss: 1.0628752708435059
Validation loss: 1.7680536213741507

Epoch: 6| Step: 5
Training loss: 0.8800637722015381
Validation loss: 1.7028505097153366

Epoch: 6| Step: 6
Training loss: 1.0134146213531494
Validation loss: 1.7124186613226449

Epoch: 6| Step: 7
Training loss: 0.4119188189506531
Validation loss: 1.7213968833287556

Epoch: 6| Step: 8
Training loss: 1.1665692329406738
Validation loss: 1.6880106310690604

Epoch: 6| Step: 9
Training loss: 0.8972662091255188
Validation loss: 1.733202003663586

Epoch: 6| Step: 10
Training loss: 0.9507606029510498
Validation loss: 1.7316332811950355

Epoch: 6| Step: 11
Training loss: 1.2904045581817627
Validation loss: 1.7128691365641933

Epoch: 6| Step: 12
Training loss: 1.1459474563598633
Validation loss: 1.6331612397265691

Epoch: 6| Step: 13
Training loss: 1.0367343425750732
Validation loss: 1.6782213103386663

Epoch: 435| Step: 0
Training loss: 0.6624611020088196
Validation loss: 1.686035204959172

Epoch: 6| Step: 1
Training loss: 1.3403143882751465
Validation loss: 1.70365737330529

Epoch: 6| Step: 2
Training loss: 0.7809436917304993
Validation loss: 1.6646558136068366

Epoch: 6| Step: 3
Training loss: 1.1023123264312744
Validation loss: 1.74422570325995

Epoch: 6| Step: 4
Training loss: 0.9148238301277161
Validation loss: 1.6648298078967678

Epoch: 6| Step: 5
Training loss: 1.4413108825683594
Validation loss: 1.7171554911521174

Epoch: 6| Step: 6
Training loss: 1.018987774848938
Validation loss: 1.6885566698607577

Epoch: 6| Step: 7
Training loss: 0.9182332754135132
Validation loss: 1.6895672916084208

Epoch: 6| Step: 8
Training loss: 1.3552026748657227
Validation loss: 1.7179160707740373

Epoch: 6| Step: 9
Training loss: 1.4143669605255127
Validation loss: 1.7195052305857341

Epoch: 6| Step: 10
Training loss: 0.7791192531585693
Validation loss: 1.714377781396271

Epoch: 6| Step: 11
Training loss: 0.8171876668930054
Validation loss: 1.712751632095665

Epoch: 6| Step: 12
Training loss: 1.0057867765426636
Validation loss: 1.7162546688510525

Epoch: 6| Step: 13
Training loss: 0.6695783138275146
Validation loss: 1.6749667095881637

Epoch: 436| Step: 0
Training loss: 0.9972186088562012
Validation loss: 1.7284154327966834

Epoch: 6| Step: 1
Training loss: 0.5991442203521729
Validation loss: 1.7015394664579822

Epoch: 6| Step: 2
Training loss: 1.1073901653289795
Validation loss: 1.6716105835412138

Epoch: 6| Step: 3
Training loss: 1.0560314655303955
Validation loss: 1.7026797879126765

Epoch: 6| Step: 4
Training loss: 0.6247775554656982
Validation loss: 1.6448896008153115

Epoch: 6| Step: 5
Training loss: 1.0200929641723633
Validation loss: 1.6994688946713683

Epoch: 6| Step: 6
Training loss: 0.9390331506729126
Validation loss: 1.6707376626230055

Epoch: 6| Step: 7
Training loss: 1.417952060699463
Validation loss: 1.7061801905273108

Epoch: 6| Step: 8
Training loss: 0.8399444222450256
Validation loss: 1.692230814246721

Epoch: 6| Step: 9
Training loss: 0.9155861735343933
Validation loss: 1.7098585021111272

Epoch: 6| Step: 10
Training loss: 0.7681392431259155
Validation loss: 1.687281552181449

Epoch: 6| Step: 11
Training loss: 1.8684340715408325
Validation loss: 1.677329836353179

Epoch: 6| Step: 12
Training loss: 1.1728876829147339
Validation loss: 1.709690514431205

Epoch: 6| Step: 13
Training loss: 0.8126310110092163
Validation loss: 1.7216219107309978

Epoch: 437| Step: 0
Training loss: 1.4566720724105835
Validation loss: 1.7135106363604147

Epoch: 6| Step: 1
Training loss: 0.7905335426330566
Validation loss: 1.7439026127579391

Epoch: 6| Step: 2
Training loss: 1.2480331659317017
Validation loss: 1.703166886042523

Epoch: 6| Step: 3
Training loss: 0.4878721833229065
Validation loss: 1.72960542350687

Epoch: 6| Step: 4
Training loss: 0.5672828555107117
Validation loss: 1.7042717395290252

Epoch: 6| Step: 5
Training loss: 1.188523769378662
Validation loss: 1.7314219308155838

Epoch: 6| Step: 6
Training loss: 1.0998172760009766
Validation loss: 1.7262157278676187

Epoch: 6| Step: 7
Training loss: 1.0931389331817627
Validation loss: 1.7320539041232037

Epoch: 6| Step: 8
Training loss: 1.411508321762085
Validation loss: 1.6977969113216604

Epoch: 6| Step: 9
Training loss: 1.4363913536071777
Validation loss: 1.7081507598200152

Epoch: 6| Step: 10
Training loss: 0.9966450929641724
Validation loss: 1.6601642639406267

Epoch: 6| Step: 11
Training loss: 0.7729343175888062
Validation loss: 1.6635016023471791

Epoch: 6| Step: 12
Training loss: 0.6039547920227051
Validation loss: 1.6675392299570062

Epoch: 6| Step: 13
Training loss: 1.306688666343689
Validation loss: 1.6885882353269925

Epoch: 438| Step: 0
Training loss: 0.9794754385948181
Validation loss: 1.647343703495559

Epoch: 6| Step: 1
Training loss: 1.028694748878479
Validation loss: 1.712880765238116

Epoch: 6| Step: 2
Training loss: 0.9820469617843628
Validation loss: 1.6616507832721998

Epoch: 6| Step: 3
Training loss: 1.1133604049682617
Validation loss: 1.7546068776038386

Epoch: 6| Step: 4
Training loss: 0.9994617700576782
Validation loss: 1.7240018280603553

Epoch: 6| Step: 5
Training loss: 1.1728901863098145
Validation loss: 1.6863344830851401

Epoch: 6| Step: 6
Training loss: 0.794378399848938
Validation loss: 1.673375000235855

Epoch: 6| Step: 7
Training loss: 1.242030143737793
Validation loss: 1.7093297871210242

Epoch: 6| Step: 8
Training loss: 0.819709062576294
Validation loss: 1.6966230805202196

Epoch: 6| Step: 9
Training loss: 1.5032099485397339
Validation loss: 1.704387044393888

Epoch: 6| Step: 10
Training loss: 0.8352910280227661
Validation loss: 1.6766681055868826

Epoch: 6| Step: 11
Training loss: 1.1639875173568726
Validation loss: 1.7117899015385618

Epoch: 6| Step: 12
Training loss: 0.6259188652038574
Validation loss: 1.697870494217001

Epoch: 6| Step: 13
Training loss: 0.5070184469223022
Validation loss: 1.7225256440460042

Epoch: 439| Step: 0
Training loss: 1.1251170635223389
Validation loss: 1.7237710158030193

Epoch: 6| Step: 1
Training loss: 0.8076848983764648
Validation loss: 1.7093298640302432

Epoch: 6| Step: 2
Training loss: 0.7426308393478394
Validation loss: 1.774112166896943

Epoch: 6| Step: 3
Training loss: 1.1524832248687744
Validation loss: 1.7156624896551973

Epoch: 6| Step: 4
Training loss: 1.1991682052612305
Validation loss: 1.6867696649284774

Epoch: 6| Step: 5
Training loss: 1.4535703659057617
Validation loss: 1.716983711847695

Epoch: 6| Step: 6
Training loss: 0.9053948521614075
Validation loss: 1.6481979290644329

Epoch: 6| Step: 7
Training loss: 0.997593879699707
Validation loss: 1.676682759356755

Epoch: 6| Step: 8
Training loss: 0.7637903690338135
Validation loss: 1.7025594237030193

Epoch: 6| Step: 9
Training loss: 1.1070671081542969
Validation loss: 1.7147681943831905

Epoch: 6| Step: 10
Training loss: 1.6990329027175903
Validation loss: 1.709277936207351

Epoch: 6| Step: 11
Training loss: 1.0048496723175049
Validation loss: 1.6970838449334587

Epoch: 6| Step: 12
Training loss: 0.7272205948829651
Validation loss: 1.7393944250640048

Epoch: 6| Step: 13
Training loss: 0.2420705407857895
Validation loss: 1.7319275333035378

Epoch: 440| Step: 0
Training loss: 0.8784617781639099
Validation loss: 1.6715971577552058

Epoch: 6| Step: 1
Training loss: 1.3447542190551758
Validation loss: 1.7237628044620636

Epoch: 6| Step: 2
Training loss: 1.202231764793396
Validation loss: 1.710881430615661

Epoch: 6| Step: 3
Training loss: 0.653627336025238
Validation loss: 1.7349240677331084

Epoch: 6| Step: 4
Training loss: 0.9398444890975952
Validation loss: 1.6830370131359305

Epoch: 6| Step: 5
Training loss: 1.2631001472473145
Validation loss: 1.6945498579291887

Epoch: 6| Step: 6
Training loss: 1.1761126518249512
Validation loss: 1.6671655844616633

Epoch: 6| Step: 7
Training loss: 0.9300551414489746
Validation loss: 1.7236059455461399

Epoch: 6| Step: 8
Training loss: 0.9656375050544739
Validation loss: 1.688184711240953

Epoch: 6| Step: 9
Training loss: 0.7518280744552612
Validation loss: 1.6799460534126527

Epoch: 6| Step: 10
Training loss: 0.6677761077880859
Validation loss: 1.666801801291845

Epoch: 6| Step: 11
Training loss: 0.3822154402732849
Validation loss: 1.716229518254598

Epoch: 6| Step: 12
Training loss: 1.2965519428253174
Validation loss: 1.6995700315762592

Epoch: 6| Step: 13
Training loss: 1.8416563272476196
Validation loss: 1.6529573291860602

Epoch: 441| Step: 0
Training loss: 0.8958244323730469
Validation loss: 1.6629958421953264

Epoch: 6| Step: 1
Training loss: 0.9672383069992065
Validation loss: 1.6807484088405487

Epoch: 6| Step: 2
Training loss: 0.6792616844177246
Validation loss: 1.6979925055657663

Epoch: 6| Step: 3
Training loss: 0.6614277362823486
Validation loss: 1.7153119220528552

Epoch: 6| Step: 4
Training loss: 1.0661486387252808
Validation loss: 1.7245839718849427

Epoch: 6| Step: 5
Training loss: 1.786104440689087
Validation loss: 1.7164821727301485

Epoch: 6| Step: 6
Training loss: 0.8780604600906372
Validation loss: 1.6958860735739432

Epoch: 6| Step: 7
Training loss: 1.6982946395874023
Validation loss: 1.7043281319320842

Epoch: 6| Step: 8
Training loss: 1.014253854751587
Validation loss: 1.640382405250303

Epoch: 6| Step: 9
Training loss: 0.943799614906311
Validation loss: 1.7312019678854174

Epoch: 6| Step: 10
Training loss: 0.6697154641151428
Validation loss: 1.689428715295689

Epoch: 6| Step: 11
Training loss: 0.8211796283721924
Validation loss: 1.7294898609961233

Epoch: 6| Step: 12
Training loss: 0.9880598187446594
Validation loss: 1.6820874009081113

Epoch: 6| Step: 13
Training loss: 0.7293585538864136
Validation loss: 1.6861345037337272

Epoch: 442| Step: 0
Training loss: 0.8781419992446899
Validation loss: 1.7271992391155613

Epoch: 6| Step: 1
Training loss: 1.427910327911377
Validation loss: 1.691821526455623

Epoch: 6| Step: 2
Training loss: 1.1790932416915894
Validation loss: 1.6850207569778606

Epoch: 6| Step: 3
Training loss: 1.22577965259552
Validation loss: 1.6531101478043424

Epoch: 6| Step: 4
Training loss: 1.2091071605682373
Validation loss: 1.7197706122552194

Epoch: 6| Step: 5
Training loss: 1.0169224739074707
Validation loss: 1.7337361240899691

Epoch: 6| Step: 6
Training loss: 0.7086188197135925
Validation loss: 1.6940959397182669

Epoch: 6| Step: 7
Training loss: 0.6675963401794434
Validation loss: 1.7245730315485308

Epoch: 6| Step: 8
Training loss: 0.9340993165969849
Validation loss: 1.67874671951417

Epoch: 6| Step: 9
Training loss: 0.536275327205658
Validation loss: 1.7297745827705628

Epoch: 6| Step: 10
Training loss: 1.1124002933502197
Validation loss: 1.6650457689839024

Epoch: 6| Step: 11
Training loss: 1.1560258865356445
Validation loss: 1.6616178597173383

Epoch: 6| Step: 12
Training loss: 1.0045892000198364
Validation loss: 1.7357153597698416

Epoch: 6| Step: 13
Training loss: 0.8757637143135071
Validation loss: 1.7606944627659296

Epoch: 443| Step: 0
Training loss: 1.833702564239502
Validation loss: 1.737747576928908

Epoch: 6| Step: 1
Training loss: 1.1823464632034302
Validation loss: 1.7009337384213683

Epoch: 6| Step: 2
Training loss: 0.5339956879615784
Validation loss: 1.704853093752297

Epoch: 6| Step: 3
Training loss: 0.9030314683914185
Validation loss: 1.7228072394606888

Epoch: 6| Step: 4
Training loss: 1.0881550312042236
Validation loss: 1.7019649833761237

Epoch: 6| Step: 5
Training loss: 0.7504688501358032
Validation loss: 1.7015932939385856

Epoch: 6| Step: 6
Training loss: 0.9835342168807983
Validation loss: 1.7138665312079973

Epoch: 6| Step: 7
Training loss: 0.9327521324157715
Validation loss: 1.7558578509156422

Epoch: 6| Step: 8
Training loss: 0.9638099670410156
Validation loss: 1.735056100353118

Epoch: 6| Step: 9
Training loss: 0.9658674001693726
Validation loss: 1.716559499822637

Epoch: 6| Step: 10
Training loss: 1.255650281906128
Validation loss: 1.6790826794921712

Epoch: 6| Step: 11
Training loss: 0.5718920230865479
Validation loss: 1.7088342084679553

Epoch: 6| Step: 12
Training loss: 1.2246026992797852
Validation loss: 1.699723425731864

Epoch: 6| Step: 13
Training loss: 0.3577500581741333
Validation loss: 1.6476255642470492

Epoch: 444| Step: 0
Training loss: 0.7715876698493958
Validation loss: 1.7023146908770326

Epoch: 6| Step: 1
Training loss: 1.3431376218795776
Validation loss: 1.7027210279177594

Epoch: 6| Step: 2
Training loss: 0.8042039275169373
Validation loss: 1.7055226141406643

Epoch: 6| Step: 3
Training loss: 0.474365770816803
Validation loss: 1.7293384421256282

Epoch: 6| Step: 4
Training loss: 1.2719229459762573
Validation loss: 1.7144970611859394

Epoch: 6| Step: 5
Training loss: 0.6394872069358826
Validation loss: 1.6860847037325624

Epoch: 6| Step: 6
Training loss: 0.7478311657905579
Validation loss: 1.7476296617138771

Epoch: 6| Step: 7
Training loss: 0.9702852964401245
Validation loss: 1.7572923949969712

Epoch: 6| Step: 8
Training loss: 1.1611814498901367
Validation loss: 1.7019026804995794

Epoch: 6| Step: 9
Training loss: 0.8361746072769165
Validation loss: 1.7388407197049869

Epoch: 6| Step: 10
Training loss: 1.6707139015197754
Validation loss: 1.7167344811142131

Epoch: 6| Step: 11
Training loss: 1.2420134544372559
Validation loss: 1.661386134803936

Epoch: 6| Step: 12
Training loss: 1.0936834812164307
Validation loss: 1.6825056191413634

Epoch: 6| Step: 13
Training loss: 1.0353842973709106
Validation loss: 1.704222991902341

Epoch: 445| Step: 0
Training loss: 0.812441349029541
Validation loss: 1.6874750480856946

Epoch: 6| Step: 1
Training loss: 0.698466420173645
Validation loss: 1.7552428732636154

Epoch: 6| Step: 2
Training loss: 1.1565792560577393
Validation loss: 1.7329688777205765

Epoch: 6| Step: 3
Training loss: 1.1908481121063232
Validation loss: 1.7602382731694046

Epoch: 6| Step: 4
Training loss: 0.9582856893539429
Validation loss: 1.7040247763356855

Epoch: 6| Step: 5
Training loss: 0.8098208904266357
Validation loss: 1.7355752606545725

Epoch: 6| Step: 6
Training loss: 1.28743314743042
Validation loss: 1.7596487857962166

Epoch: 6| Step: 7
Training loss: 1.0455430746078491
Validation loss: 1.7406962379332511

Epoch: 6| Step: 8
Training loss: 1.1371490955352783
Validation loss: 1.7168424539668585

Epoch: 6| Step: 9
Training loss: 0.5568668842315674
Validation loss: 1.708909660257319

Epoch: 6| Step: 10
Training loss: 1.2963056564331055
Validation loss: 1.7006472323530464

Epoch: 6| Step: 11
Training loss: 1.2879571914672852
Validation loss: 1.7131040609011086

Epoch: 6| Step: 12
Training loss: 0.8847253322601318
Validation loss: 1.6927610969030729

Epoch: 6| Step: 13
Training loss: 1.6391607522964478
Validation loss: 1.7016936297057776

Epoch: 446| Step: 0
Training loss: 0.6224157214164734
Validation loss: 1.728468765494644

Epoch: 6| Step: 1
Training loss: 0.8759406805038452
Validation loss: 1.744685919695003

Epoch: 6| Step: 2
Training loss: 0.9553502798080444
Validation loss: 1.7099432535068964

Epoch: 6| Step: 3
Training loss: 1.183020830154419
Validation loss: 1.738915346002066

Epoch: 6| Step: 4
Training loss: 0.759297251701355
Validation loss: 1.7294619185950166

Epoch: 6| Step: 5
Training loss: 1.0148329734802246
Validation loss: 1.6866095822344545

Epoch: 6| Step: 6
Training loss: 0.8772523403167725
Validation loss: 1.6879121500958678

Epoch: 6| Step: 7
Training loss: 1.2180275917053223
Validation loss: 1.7212745451158094

Epoch: 6| Step: 8
Training loss: 0.5045394897460938
Validation loss: 1.704302244288947

Epoch: 6| Step: 9
Training loss: 1.0659573078155518
Validation loss: 1.7466906424491637

Epoch: 6| Step: 10
Training loss: 1.2685718536376953
Validation loss: 1.745972034751728

Epoch: 6| Step: 11
Training loss: 1.4065810441970825
Validation loss: 1.7263166545539774

Epoch: 6| Step: 12
Training loss: 1.053053379058838
Validation loss: 1.7095864677941928

Epoch: 6| Step: 13
Training loss: 1.0369415283203125
Validation loss: 1.7009413902477553

Epoch: 447| Step: 0
Training loss: 0.8021547794342041
Validation loss: 1.7322262807558941

Epoch: 6| Step: 1
Training loss: 1.3138035535812378
Validation loss: 1.695861316496326

Epoch: 6| Step: 2
Training loss: 0.882988452911377
Validation loss: 1.6583055693616149

Epoch: 6| Step: 3
Training loss: 0.6019744873046875
Validation loss: 1.7063048193531651

Epoch: 6| Step: 4
Training loss: 0.5795034170150757
Validation loss: 1.7036133709774222

Epoch: 6| Step: 5
Training loss: 0.7492185831069946
Validation loss: 1.6698000533606416

Epoch: 6| Step: 6
Training loss: 1.559093952178955
Validation loss: 1.691889751342035

Epoch: 6| Step: 7
Training loss: 1.2213106155395508
Validation loss: 1.694444981954431

Epoch: 6| Step: 8
Training loss: 1.0491728782653809
Validation loss: 1.6904373374036563

Epoch: 6| Step: 9
Training loss: 0.6687213182449341
Validation loss: 1.6782139731991677

Epoch: 6| Step: 10
Training loss: 1.3985161781311035
Validation loss: 1.7301976603846396

Epoch: 6| Step: 11
Training loss: 0.6765819191932678
Validation loss: 1.7444220640326058

Epoch: 6| Step: 12
Training loss: 1.255985975265503
Validation loss: 1.73532816543374

Epoch: 6| Step: 13
Training loss: 0.6486573815345764
Validation loss: 1.7560450171911588

Epoch: 448| Step: 0
Training loss: 1.4792698621749878
Validation loss: 1.7056545929242206

Epoch: 6| Step: 1
Training loss: 1.4610397815704346
Validation loss: 1.6851995888576712

Epoch: 6| Step: 2
Training loss: 0.627181887626648
Validation loss: 1.6947752442411197

Epoch: 6| Step: 3
Training loss: 0.9757418036460876
Validation loss: 1.7028357636544011

Epoch: 6| Step: 4
Training loss: 0.6564447283744812
Validation loss: 1.753616027934577

Epoch: 6| Step: 5
Training loss: 1.6239018440246582
Validation loss: 1.7449284215127268

Epoch: 6| Step: 6
Training loss: 0.8962323665618896
Validation loss: 1.7699268761501517

Epoch: 6| Step: 7
Training loss: 0.6290768384933472
Validation loss: 1.713853092603786

Epoch: 6| Step: 8
Training loss: 0.8528029918670654
Validation loss: 1.7203873049828313

Epoch: 6| Step: 9
Training loss: 0.6970815062522888
Validation loss: 1.718927489813938

Epoch: 6| Step: 10
Training loss: 0.6692649126052856
Validation loss: 1.670795033054967

Epoch: 6| Step: 11
Training loss: 0.9837237596511841
Validation loss: 1.6977476227668025

Epoch: 6| Step: 12
Training loss: 1.1798021793365479
Validation loss: 1.7217916211774271

Epoch: 6| Step: 13
Training loss: 0.9783137440681458
Validation loss: 1.7119011878967285

Epoch: 449| Step: 0
Training loss: 0.8931267261505127
Validation loss: 1.6565358100398895

Epoch: 6| Step: 1
Training loss: 0.7144874930381775
Validation loss: 1.7092815470951859

Epoch: 6| Step: 2
Training loss: 1.0084813833236694
Validation loss: 1.707641383653046

Epoch: 6| Step: 3
Training loss: 0.7001850605010986
Validation loss: 1.7420130083637853

Epoch: 6| Step: 4
Training loss: 1.575646162033081
Validation loss: 1.7278781949832875

Epoch: 6| Step: 5
Training loss: 1.0083422660827637
Validation loss: 1.7684765990062425

Epoch: 6| Step: 6
Training loss: 0.6859191060066223
Validation loss: 1.7680409646803332

Epoch: 6| Step: 7
Training loss: 1.0502716302871704
Validation loss: 1.7148640271156066

Epoch: 6| Step: 8
Training loss: 1.068421721458435
Validation loss: 1.7140062150134836

Epoch: 6| Step: 9
Training loss: 1.0340874195098877
Validation loss: 1.7606944140567575

Epoch: 6| Step: 10
Training loss: 1.023045539855957
Validation loss: 1.658384141101632

Epoch: 6| Step: 11
Training loss: 1.0958631038665771
Validation loss: 1.633973237006895

Epoch: 6| Step: 12
Training loss: 1.0974725484848022
Validation loss: 1.723779619380992

Epoch: 6| Step: 13
Training loss: 1.0990831851959229
Validation loss: 1.691083053747813

Epoch: 450| Step: 0
Training loss: 1.5923199653625488
Validation loss: 1.7176928789384904

Epoch: 6| Step: 1
Training loss: 1.133897304534912
Validation loss: 1.7272957755673317

Epoch: 6| Step: 2
Training loss: 0.698895275592804
Validation loss: 1.6930294511138753

Epoch: 6| Step: 3
Training loss: 1.3085825443267822
Validation loss: 1.6891922156016033

Epoch: 6| Step: 4
Training loss: 1.0582624673843384
Validation loss: 1.7204044044658702

Epoch: 6| Step: 5
Training loss: 0.9689586162567139
Validation loss: 1.6755270291400213

Epoch: 6| Step: 6
Training loss: 0.9418383836746216
Validation loss: 1.7283418614377257

Epoch: 6| Step: 7
Training loss: 0.9957248568534851
Validation loss: 1.7081017045564548

Epoch: 6| Step: 8
Training loss: 0.40776515007019043
Validation loss: 1.665392029669977

Epoch: 6| Step: 9
Training loss: 1.2798956632614136
Validation loss: 1.718777237399932

Epoch: 6| Step: 10
Training loss: 1.091882586479187
Validation loss: 1.7240434410751506

Epoch: 6| Step: 11
Training loss: 0.7227578163146973
Validation loss: 1.6868906456937072

Epoch: 6| Step: 12
Training loss: 0.4740005135536194
Validation loss: 1.731864175488872

Epoch: 6| Step: 13
Training loss: 1.2955927848815918
Validation loss: 1.6843599298948884

Epoch: 451| Step: 0
Training loss: 0.9213725328445435
Validation loss: 1.713463762755035

Epoch: 6| Step: 1
Training loss: 1.0452207326889038
Validation loss: 1.716841588738144

Epoch: 6| Step: 2
Training loss: 0.9129584431648254
Validation loss: 1.7039618684399513

Epoch: 6| Step: 3
Training loss: 1.3908660411834717
Validation loss: 1.7557076920745194

Epoch: 6| Step: 4
Training loss: 0.8785548210144043
Validation loss: 1.745455631645777

Epoch: 6| Step: 5
Training loss: 1.051870584487915
Validation loss: 1.6544210385250788

Epoch: 6| Step: 6
Training loss: 0.8260684013366699
Validation loss: 1.665945488919494

Epoch: 6| Step: 7
Training loss: 1.2496240139007568
Validation loss: 1.684125602886241

Epoch: 6| Step: 8
Training loss: 1.103334903717041
Validation loss: 1.6406068904425508

Epoch: 6| Step: 9
Training loss: 0.9076241254806519
Validation loss: 1.666201574828035

Epoch: 6| Step: 10
Training loss: 1.1976817846298218
Validation loss: 1.6648457460505988

Epoch: 6| Step: 11
Training loss: 0.9379978775978088
Validation loss: 1.704819312659643

Epoch: 6| Step: 12
Training loss: 0.7862153053283691
Validation loss: 1.7130731164768178

Epoch: 6| Step: 13
Training loss: 0.5102499723434448
Validation loss: 1.6741213260158416

Epoch: 452| Step: 0
Training loss: 0.8086303472518921
Validation loss: 1.699271766088342

Epoch: 6| Step: 1
Training loss: 0.5381039381027222
Validation loss: 1.7221609315564554

Epoch: 6| Step: 2
Training loss: 1.6295883655548096
Validation loss: 1.699830767928913

Epoch: 6| Step: 3
Training loss: 1.058730125427246
Validation loss: 1.7053473495667981

Epoch: 6| Step: 4
Training loss: 0.5284186601638794
Validation loss: 1.6918818514834169

Epoch: 6| Step: 5
Training loss: 0.7910628318786621
Validation loss: 1.6881803261336459

Epoch: 6| Step: 6
Training loss: 1.1845288276672363
Validation loss: 1.736354071606872

Epoch: 6| Step: 7
Training loss: 1.085815191268921
Validation loss: 1.6955474051096107

Epoch: 6| Step: 8
Training loss: 1.031672716140747
Validation loss: 1.716410970175138

Epoch: 6| Step: 9
Training loss: 0.8559576272964478
Validation loss: 1.6914371213605326

Epoch: 6| Step: 10
Training loss: 0.8550910949707031
Validation loss: 1.6975313232791038

Epoch: 6| Step: 11
Training loss: 1.215895175933838
Validation loss: 1.6943522319998792

Epoch: 6| Step: 12
Training loss: 1.3797297477722168
Validation loss: 1.7073186712880288

Epoch: 6| Step: 13
Training loss: 0.7672985196113586
Validation loss: 1.6919327166772657

Epoch: 453| Step: 0
Training loss: 0.9242689609527588
Validation loss: 1.734376427947834

Epoch: 6| Step: 1
Training loss: 0.7029083371162415
Validation loss: 1.6908487735256073

Epoch: 6| Step: 2
Training loss: 0.9194219708442688
Validation loss: 1.705131729443868

Epoch: 6| Step: 3
Training loss: 1.064225435256958
Validation loss: 1.6723228013643654

Epoch: 6| Step: 4
Training loss: 1.2703741788864136
Validation loss: 1.729737647118107

Epoch: 6| Step: 5
Training loss: 1.4071433544158936
Validation loss: 1.6678943185396091

Epoch: 6| Step: 6
Training loss: 1.1540718078613281
Validation loss: 1.677300904386787

Epoch: 6| Step: 7
Training loss: 0.625508189201355
Validation loss: 1.696459807375426

Epoch: 6| Step: 8
Training loss: 0.7242871522903442
Validation loss: 1.7266334372182046

Epoch: 6| Step: 9
Training loss: 1.3933627605438232
Validation loss: 1.6599364575519358

Epoch: 6| Step: 10
Training loss: 0.979365885257721
Validation loss: 1.7021176161304596

Epoch: 6| Step: 11
Training loss: 0.47251150012016296
Validation loss: 1.681243827266078

Epoch: 6| Step: 12
Training loss: 1.04636812210083
Validation loss: 1.6890848182862805

Epoch: 6| Step: 13
Training loss: 0.8035652041435242
Validation loss: 1.6848411431876562

Epoch: 454| Step: 0
Training loss: 0.9230157136917114
Validation loss: 1.7201991811875375

Epoch: 6| Step: 1
Training loss: 0.8370399475097656
Validation loss: 1.7296783296010827

Epoch: 6| Step: 2
Training loss: 0.8833436369895935
Validation loss: 1.6771509942188059

Epoch: 6| Step: 3
Training loss: 0.8979688286781311
Validation loss: 1.71416122938997

Epoch: 6| Step: 4
Training loss: 0.8902788162231445
Validation loss: 1.7734549045562744

Epoch: 6| Step: 5
Training loss: 0.6267310380935669
Validation loss: 1.697661425477715

Epoch: 6| Step: 6
Training loss: 1.2744624614715576
Validation loss: 1.703805035160434

Epoch: 6| Step: 7
Training loss: 0.7818279266357422
Validation loss: 1.7127087270059893

Epoch: 6| Step: 8
Training loss: 0.6750289797782898
Validation loss: 1.6303444152237268

Epoch: 6| Step: 9
Training loss: 1.1133378744125366
Validation loss: 1.6975452079567859

Epoch: 6| Step: 10
Training loss: 0.87903892993927
Validation loss: 1.6838417873587659

Epoch: 6| Step: 11
Training loss: 0.9403409361839294
Validation loss: 1.6380573754669518

Epoch: 6| Step: 12
Training loss: 1.5502345561981201
Validation loss: 1.664819017533333

Epoch: 6| Step: 13
Training loss: 1.21157968044281
Validation loss: 1.696621419281088

Epoch: 455| Step: 0
Training loss: 1.066187858581543
Validation loss: 1.7337807955280427

Epoch: 6| Step: 1
Training loss: 0.6877504587173462
Validation loss: 1.6600892454065301

Epoch: 6| Step: 2
Training loss: 0.6323196291923523
Validation loss: 1.7170171404397616

Epoch: 6| Step: 3
Training loss: 0.8939212560653687
Validation loss: 1.707572203810497

Epoch: 6| Step: 4
Training loss: 1.0324337482452393
Validation loss: 1.6897538644011303

Epoch: 6| Step: 5
Training loss: 0.888537585735321
Validation loss: 1.7112384932015532

Epoch: 6| Step: 6
Training loss: 1.0047698020935059
Validation loss: 1.7310671191061697

Epoch: 6| Step: 7
Training loss: 1.7565690279006958
Validation loss: 1.705614968012738

Epoch: 6| Step: 8
Training loss: 0.8803149461746216
Validation loss: 1.7156678527914069

Epoch: 6| Step: 9
Training loss: 0.9958429336547852
Validation loss: 1.7578657545069212

Epoch: 6| Step: 10
Training loss: 1.154914140701294
Validation loss: 1.7983740093887493

Epoch: 6| Step: 11
Training loss: 1.1834099292755127
Validation loss: 1.725015817149993

Epoch: 6| Step: 12
Training loss: 1.2501057386398315
Validation loss: 1.7233933453918786

Epoch: 6| Step: 13
Training loss: 0.5296193361282349
Validation loss: 1.7335060155519875

Epoch: 456| Step: 0
Training loss: 0.9405453205108643
Validation loss: 1.7578474526764245

Epoch: 6| Step: 1
Training loss: 0.9349373579025269
Validation loss: 1.6872811958354006

Epoch: 6| Step: 2
Training loss: 1.076005220413208
Validation loss: 1.7073356131071686

Epoch: 6| Step: 3
Training loss: 0.978086531162262
Validation loss: 1.7016286811520975

Epoch: 6| Step: 4
Training loss: 0.6989029049873352
Validation loss: 1.7413616987966722

Epoch: 6| Step: 5
Training loss: 1.2580554485321045
Validation loss: 1.6383198589406989

Epoch: 6| Step: 6
Training loss: 1.1245548725128174
Validation loss: 1.6944280285989084

Epoch: 6| Step: 7
Training loss: 0.7502352595329285
Validation loss: 1.6698114769433134

Epoch: 6| Step: 8
Training loss: 1.0499202013015747
Validation loss: 1.6912308585259221

Epoch: 6| Step: 9
Training loss: 0.9020538330078125
Validation loss: 1.6566417806891984

Epoch: 6| Step: 10
Training loss: 0.8427772521972656
Validation loss: 1.7203085255879227

Epoch: 6| Step: 11
Training loss: 0.9664997458457947
Validation loss: 1.7197207135538901

Epoch: 6| Step: 12
Training loss: 1.3089098930358887
Validation loss: 1.688267057941806

Epoch: 6| Step: 13
Training loss: 0.7202821373939514
Validation loss: 1.7145052930360198

Epoch: 457| Step: 0
Training loss: 0.9300085306167603
Validation loss: 1.7750254138823478

Epoch: 6| Step: 1
Training loss: 1.3457481861114502
Validation loss: 1.8216683428774598

Epoch: 6| Step: 2
Training loss: 0.7715917229652405
Validation loss: 1.7536982695261638

Epoch: 6| Step: 3
Training loss: 1.4254343509674072
Validation loss: 1.7313319098564885

Epoch: 6| Step: 4
Training loss: 0.6967815160751343
Validation loss: 1.7675388333618

Epoch: 6| Step: 5
Training loss: 0.6129242777824402
Validation loss: 1.7303380607276835

Epoch: 6| Step: 6
Training loss: 0.806611180305481
Validation loss: 1.7129848336660733

Epoch: 6| Step: 7
Training loss: 1.2985655069351196
Validation loss: 1.6772358737966067

Epoch: 6| Step: 8
Training loss: 0.879249632358551
Validation loss: 1.7957151474491242

Epoch: 6| Step: 9
Training loss: 0.6055340766906738
Validation loss: 1.728092093621531

Epoch: 6| Step: 10
Training loss: 1.7652350664138794
Validation loss: 1.6800228434224282

Epoch: 6| Step: 11
Training loss: 0.9562928676605225
Validation loss: 1.6994159067830732

Epoch: 6| Step: 12
Training loss: 0.8906757831573486
Validation loss: 1.6871180854817873

Epoch: 6| Step: 13
Training loss: 0.6729701161384583
Validation loss: 1.7295767825136903

Epoch: 458| Step: 0
Training loss: 1.7757000923156738
Validation loss: 1.736030327376499

Epoch: 6| Step: 1
Training loss: 0.7233617305755615
Validation loss: 1.6873977133022842

Epoch: 6| Step: 2
Training loss: 1.239600658416748
Validation loss: 1.6815342069954

Epoch: 6| Step: 3
Training loss: 0.904144287109375
Validation loss: 1.6970837564878567

Epoch: 6| Step: 4
Training loss: 1.1351450681686401
Validation loss: 1.7142389192376086

Epoch: 6| Step: 5
Training loss: 0.5389971733093262
Validation loss: 1.7242678032126477

Epoch: 6| Step: 6
Training loss: 0.8277547359466553
Validation loss: 1.696253864995895

Epoch: 6| Step: 7
Training loss: 0.7663732767105103
Validation loss: 1.7384598588430753

Epoch: 6| Step: 8
Training loss: 0.7968339920043945
Validation loss: 1.6790894090488393

Epoch: 6| Step: 9
Training loss: 0.7315913438796997
Validation loss: 1.718129756630108

Epoch: 6| Step: 10
Training loss: 1.0871363878250122
Validation loss: 1.7300628769782282

Epoch: 6| Step: 11
Training loss: 0.9717357754707336
Validation loss: 1.674931364674722

Epoch: 6| Step: 12
Training loss: 1.4270365238189697
Validation loss: 1.746172724231597

Epoch: 6| Step: 13
Training loss: 0.40239936113357544
Validation loss: 1.704994547751642

Epoch: 459| Step: 0
Training loss: 0.8479534387588501
Validation loss: 1.7106899728057205

Epoch: 6| Step: 1
Training loss: 1.2290818691253662
Validation loss: 1.721217724584764

Epoch: 6| Step: 2
Training loss: 0.9047739505767822
Validation loss: 1.670978993497869

Epoch: 6| Step: 3
Training loss: 0.7102515697479248
Validation loss: 1.7059802009213356

Epoch: 6| Step: 4
Training loss: 0.6655120253562927
Validation loss: 1.72001907133287

Epoch: 6| Step: 5
Training loss: 0.9650582671165466
Validation loss: 1.6873581550454582

Epoch: 6| Step: 6
Training loss: 0.7606713175773621
Validation loss: 1.6733469578527636

Epoch: 6| Step: 7
Training loss: 0.8959890604019165
Validation loss: 1.6982662805946924

Epoch: 6| Step: 8
Training loss: 1.1327911615371704
Validation loss: 1.7393607054987261

Epoch: 6| Step: 9
Training loss: 0.984562337398529
Validation loss: 1.6533271958751063

Epoch: 6| Step: 10
Training loss: 0.8232226371765137
Validation loss: 1.7264885543495097

Epoch: 6| Step: 11
Training loss: 0.7521423101425171
Validation loss: 1.7105563571376186

Epoch: 6| Step: 12
Training loss: 1.5600605010986328
Validation loss: 1.711218640368472

Epoch: 6| Step: 13
Training loss: 1.3399423360824585
Validation loss: 1.6851423273804367

Epoch: 460| Step: 0
Training loss: 1.4873440265655518
Validation loss: 1.6676141267181726

Epoch: 6| Step: 1
Training loss: 0.852149248123169
Validation loss: 1.68852416417932

Epoch: 6| Step: 2
Training loss: 1.0569185018539429
Validation loss: 1.7493507605727001

Epoch: 6| Step: 3
Training loss: 0.7233306169509888
Validation loss: 1.6741901898896823

Epoch: 6| Step: 4
Training loss: 0.5503376126289368
Validation loss: 1.7115381276735695

Epoch: 6| Step: 5
Training loss: 1.1813139915466309
Validation loss: 1.692124689778974

Epoch: 6| Step: 6
Training loss: 0.6114548444747925
Validation loss: 1.6455757207767938

Epoch: 6| Step: 7
Training loss: 0.8990699052810669
Validation loss: 1.7019640463654713

Epoch: 6| Step: 8
Training loss: 0.8990097045898438
Validation loss: 1.7015625469146236

Epoch: 6| Step: 9
Training loss: 1.157989263534546
Validation loss: 1.7028905627548054

Epoch: 6| Step: 10
Training loss: 0.9695665836334229
Validation loss: 1.7569939167268815

Epoch: 6| Step: 11
Training loss: 1.2978664636611938
Validation loss: 1.7579124050755655

Epoch: 6| Step: 12
Training loss: 1.0133086442947388
Validation loss: 1.6911611095551522

Epoch: 6| Step: 13
Training loss: 0.4432740807533264
Validation loss: 1.7195092875470397

Epoch: 461| Step: 0
Training loss: 0.9875920414924622
Validation loss: 1.738177828891303

Epoch: 6| Step: 1
Training loss: 0.8344745635986328
Validation loss: 1.6694877096401748

Epoch: 6| Step: 2
Training loss: 1.3864529132843018
Validation loss: 1.7500513907401793

Epoch: 6| Step: 3
Training loss: 1.4137089252471924
Validation loss: 1.7374426062389086

Epoch: 6| Step: 4
Training loss: 0.6553932428359985
Validation loss: 1.7160772662008963

Epoch: 6| Step: 5
Training loss: 1.1688947677612305
Validation loss: 1.7644985170774563

Epoch: 6| Step: 6
Training loss: 1.0621962547302246
Validation loss: 1.7338981359235701

Epoch: 6| Step: 7
Training loss: 1.177607774734497
Validation loss: 1.677532180663078

Epoch: 6| Step: 8
Training loss: 0.9700438976287842
Validation loss: 1.6971948710821008

Epoch: 6| Step: 9
Training loss: 0.75853431224823
Validation loss: 1.718332802095721

Epoch: 6| Step: 10
Training loss: 0.9855378270149231
Validation loss: 1.712526039410663

Epoch: 6| Step: 11
Training loss: 1.0246412754058838
Validation loss: 1.7525883323402816

Epoch: 6| Step: 12
Training loss: 0.3671303391456604
Validation loss: 1.7155210766741025

Epoch: 6| Step: 13
Training loss: 0.5449769496917725
Validation loss: 1.712072846710041

Epoch: 462| Step: 0
Training loss: 0.5911850333213806
Validation loss: 1.7197773802664973

Epoch: 6| Step: 1
Training loss: 1.0276321172714233
Validation loss: 1.7191184066957044

Epoch: 6| Step: 2
Training loss: 1.0120654106140137
Validation loss: 1.702558325183007

Epoch: 6| Step: 3
Training loss: 1.0523338317871094
Validation loss: 1.6539135697067424

Epoch: 6| Step: 4
Training loss: 0.948516309261322
Validation loss: 1.743916001371158

Epoch: 6| Step: 5
Training loss: 0.9010131359100342
Validation loss: 1.6626098809703704

Epoch: 6| Step: 6
Training loss: 1.1604578495025635
Validation loss: 1.757082490510838

Epoch: 6| Step: 7
Training loss: 1.0096179246902466
Validation loss: 1.7430353677400978

Epoch: 6| Step: 8
Training loss: 0.9586873054504395
Validation loss: 1.7212492522372995

Epoch: 6| Step: 9
Training loss: 0.9766877889633179
Validation loss: 1.7018000336103543

Epoch: 6| Step: 10
Training loss: 0.9833360910415649
Validation loss: 1.6776778492876279

Epoch: 6| Step: 11
Training loss: 1.1191153526306152
Validation loss: 1.6844082596481487

Epoch: 6| Step: 12
Training loss: 1.0749015808105469
Validation loss: 1.704782937162666

Epoch: 6| Step: 13
Training loss: 0.7426119446754456
Validation loss: 1.6592504914088915

Epoch: 463| Step: 0
Training loss: 0.4464319348335266
Validation loss: 1.7078700450158888

Epoch: 6| Step: 1
Training loss: 1.686248779296875
Validation loss: 1.7291570055869319

Epoch: 6| Step: 2
Training loss: 0.8107498288154602
Validation loss: 1.7806604472539758

Epoch: 6| Step: 3
Training loss: 0.9829493761062622
Validation loss: 1.7428919320465417

Epoch: 6| Step: 4
Training loss: 1.4979645013809204
Validation loss: 1.7924682081386607

Epoch: 6| Step: 5
Training loss: 0.858221173286438
Validation loss: 1.7328191085528302

Epoch: 6| Step: 6
Training loss: 1.1714507341384888
Validation loss: 1.7609211078254126

Epoch: 6| Step: 7
Training loss: 0.8038039207458496
Validation loss: 1.6906416634077668

Epoch: 6| Step: 8
Training loss: 0.9299310445785522
Validation loss: 1.7106449091306297

Epoch: 6| Step: 9
Training loss: 0.39056116342544556
Validation loss: 1.7100930598474318

Epoch: 6| Step: 10
Training loss: 0.8714396953582764
Validation loss: 1.7159137661739061

Epoch: 6| Step: 11
Training loss: 0.8901287317276001
Validation loss: 1.699046367599118

Epoch: 6| Step: 12
Training loss: 0.6532237529754639
Validation loss: 1.6824421549356112

Epoch: 6| Step: 13
Training loss: 0.5873448848724365
Validation loss: 1.6728573870915238

Epoch: 464| Step: 0
Training loss: 0.6248660087585449
Validation loss: 1.6554937260125273

Epoch: 6| Step: 1
Training loss: 0.9308987855911255
Validation loss: 1.6444616779204337

Epoch: 6| Step: 2
Training loss: 0.8177272081375122
Validation loss: 1.6669019614496539

Epoch: 6| Step: 3
Training loss: 0.8503689765930176
Validation loss: 1.700571866445644

Epoch: 6| Step: 4
Training loss: 1.1935930252075195
Validation loss: 1.681972308825421

Epoch: 6| Step: 5
Training loss: 0.9104341864585876
Validation loss: 1.7041237764461066

Epoch: 6| Step: 6
Training loss: 1.596039056777954
Validation loss: 1.6923525077040478

Epoch: 6| Step: 7
Training loss: 1.137965440750122
Validation loss: 1.7256772620703584

Epoch: 6| Step: 8
Training loss: 0.6539008617401123
Validation loss: 1.7255004811030563

Epoch: 6| Step: 9
Training loss: 0.7079041004180908
Validation loss: 1.7083302313281643

Epoch: 6| Step: 10
Training loss: 0.7691535949707031
Validation loss: 1.7028302582361365

Epoch: 6| Step: 11
Training loss: 0.9410446882247925
Validation loss: 1.7707496150847404

Epoch: 6| Step: 12
Training loss: 1.3381643295288086
Validation loss: 1.7367718937576457

Epoch: 6| Step: 13
Training loss: 0.6533129811286926
Validation loss: 1.7401960126815303

Epoch: 465| Step: 0
Training loss: 1.2055890560150146
Validation loss: 1.7266227788822626

Epoch: 6| Step: 1
Training loss: 0.8156412839889526
Validation loss: 1.7398847572265133

Epoch: 6| Step: 2
Training loss: 0.48674607276916504
Validation loss: 1.719799223766532

Epoch: 6| Step: 3
Training loss: 0.828526496887207
Validation loss: 1.7004812314946165

Epoch: 6| Step: 4
Training loss: 0.8068375587463379
Validation loss: 1.714594478248268

Epoch: 6| Step: 5
Training loss: 1.3215936422348022
Validation loss: 1.692702490796325

Epoch: 6| Step: 6
Training loss: 0.7776221632957458
Validation loss: 1.7137247990536433

Epoch: 6| Step: 7
Training loss: 1.1110601425170898
Validation loss: 1.676680446952902

Epoch: 6| Step: 8
Training loss: 1.0360443592071533
Validation loss: 1.7201519896907191

Epoch: 6| Step: 9
Training loss: 1.4058279991149902
Validation loss: 1.7101297916904572

Epoch: 6| Step: 10
Training loss: 1.1751073598861694
Validation loss: 1.6748791356240549

Epoch: 6| Step: 11
Training loss: 0.918029248714447
Validation loss: 1.6814268173709992

Epoch: 6| Step: 12
Training loss: 1.1048345565795898
Validation loss: 1.6427278839131838

Epoch: 6| Step: 13
Training loss: 0.8830671310424805
Validation loss: 1.6555931093872234

Epoch: 466| Step: 0
Training loss: 0.6519709825515747
Validation loss: 1.6866598706091604

Epoch: 6| Step: 1
Training loss: 1.0324814319610596
Validation loss: 1.7022802727196806

Epoch: 6| Step: 2
Training loss: 0.8664451241493225
Validation loss: 1.7428636896994807

Epoch: 6| Step: 3
Training loss: 1.0876998901367188
Validation loss: 1.6626624791852889

Epoch: 6| Step: 4
Training loss: 1.182798147201538
Validation loss: 1.6947763171247257

Epoch: 6| Step: 5
Training loss: 0.4982271194458008
Validation loss: 1.7643282900574386

Epoch: 6| Step: 6
Training loss: 0.9337555170059204
Validation loss: 1.660508204531926

Epoch: 6| Step: 7
Training loss: 0.9495903849601746
Validation loss: 1.6506189607804822

Epoch: 6| Step: 8
Training loss: 0.7984663248062134
Validation loss: 1.6700187069113537

Epoch: 6| Step: 9
Training loss: 0.8558951616287231
Validation loss: 1.6976456398605018

Epoch: 6| Step: 10
Training loss: 0.6898308396339417
Validation loss: 1.719386649388139

Epoch: 6| Step: 11
Training loss: 1.3213872909545898
Validation loss: 1.7433010878101471

Epoch: 6| Step: 12
Training loss: 1.1700868606567383
Validation loss: 1.7134869842119114

Epoch: 6| Step: 13
Training loss: 1.5608537197113037
Validation loss: 1.7041636756671372

Epoch: 467| Step: 0
Training loss: 0.7761955261230469
Validation loss: 1.7113528687466857

Epoch: 6| Step: 1
Training loss: 0.9170982837677002
Validation loss: 1.7020520369211833

Epoch: 6| Step: 2
Training loss: 1.0427675247192383
Validation loss: 1.760838775224583

Epoch: 6| Step: 3
Training loss: 1.7549060583114624
Validation loss: 1.7009974192547541

Epoch: 6| Step: 4
Training loss: 0.8841180801391602
Validation loss: 1.6853243227927917

Epoch: 6| Step: 5
Training loss: 0.9275480508804321
Validation loss: 1.7197920122454244

Epoch: 6| Step: 6
Training loss: 0.6526138186454773
Validation loss: 1.6685013450602049

Epoch: 6| Step: 7
Training loss: 0.8671727180480957
Validation loss: 1.757674636379365

Epoch: 6| Step: 8
Training loss: 0.8953619003295898
Validation loss: 1.7301673812250937

Epoch: 6| Step: 9
Training loss: 0.8135690689086914
Validation loss: 1.6402774292935607

Epoch: 6| Step: 10
Training loss: 0.6813222169876099
Validation loss: 1.7427135218856156

Epoch: 6| Step: 11
Training loss: 0.9052878618240356
Validation loss: 1.655245877081348

Epoch: 6| Step: 12
Training loss: 0.811397910118103
Validation loss: 1.7285109848104498

Epoch: 6| Step: 13
Training loss: 0.5036759972572327
Validation loss: 1.7338649572864655

Epoch: 468| Step: 0
Training loss: 1.126574993133545
Validation loss: 1.7220351965196672

Epoch: 6| Step: 1
Training loss: 1.028571605682373
Validation loss: 1.6933065076028146

Epoch: 6| Step: 2
Training loss: 1.0355925559997559
Validation loss: 1.7356005701967465

Epoch: 6| Step: 3
Training loss: 0.8250877261161804
Validation loss: 1.7392067877195214

Epoch: 6| Step: 4
Training loss: 1.0549896955490112
Validation loss: 1.719255844751994

Epoch: 6| Step: 5
Training loss: 1.4501025676727295
Validation loss: 1.6871224064980783

Epoch: 6| Step: 6
Training loss: 0.4681389331817627
Validation loss: 1.7215262779625513

Epoch: 6| Step: 7
Training loss: 1.1954936981201172
Validation loss: 1.7230428264987083

Epoch: 6| Step: 8
Training loss: 1.1655054092407227
Validation loss: 1.6957752230346843

Epoch: 6| Step: 9
Training loss: 0.7744597792625427
Validation loss: 1.6593354107231222

Epoch: 6| Step: 10
Training loss: 0.7191258072853088
Validation loss: 1.67546828844214

Epoch: 6| Step: 11
Training loss: 0.559666097164154
Validation loss: 1.68153428775008

Epoch: 6| Step: 12
Training loss: 1.0791478157043457
Validation loss: 1.6929156600788076

Epoch: 6| Step: 13
Training loss: 0.7804269790649414
Validation loss: 1.6658314287021596

Epoch: 469| Step: 0
Training loss: 0.5809385776519775
Validation loss: 1.69087355367599

Epoch: 6| Step: 1
Training loss: 1.1795648336410522
Validation loss: 1.6968744506118119

Epoch: 6| Step: 2
Training loss: 0.9499252438545227
Validation loss: 1.678494131693276

Epoch: 6| Step: 3
Training loss: 0.986484169960022
Validation loss: 1.724709713330833

Epoch: 6| Step: 4
Training loss: 1.0211732387542725
Validation loss: 1.73129456017607

Epoch: 6| Step: 5
Training loss: 0.678520917892456
Validation loss: 1.7166758224528322

Epoch: 6| Step: 6
Training loss: 0.9735187292098999
Validation loss: 1.6678736261142197

Epoch: 6| Step: 7
Training loss: 0.7922167181968689
Validation loss: 1.6599751377618441

Epoch: 6| Step: 8
Training loss: 0.9947347640991211
Validation loss: 1.6927856758076658

Epoch: 6| Step: 9
Training loss: 1.0049200057983398
Validation loss: 1.6743301012182747

Epoch: 6| Step: 10
Training loss: 1.0639936923980713
Validation loss: 1.6986309302750455

Epoch: 6| Step: 11
Training loss: 1.0647847652435303
Validation loss: 1.6819060002603838

Epoch: 6| Step: 12
Training loss: 0.8127645254135132
Validation loss: 1.6667154578752414

Epoch: 6| Step: 13
Training loss: 1.3932347297668457
Validation loss: 1.6379853717742427

Epoch: 470| Step: 0
Training loss: 0.7541583776473999
Validation loss: 1.6782838721429147

Epoch: 6| Step: 1
Training loss: 0.557335376739502
Validation loss: 1.688564541519329

Epoch: 6| Step: 2
Training loss: 1.1580414772033691
Validation loss: 1.6807107143504645

Epoch: 6| Step: 3
Training loss: 1.025894284248352
Validation loss: 1.7073868013197375

Epoch: 6| Step: 4
Training loss: 1.0670115947723389
Validation loss: 1.6400105196942565

Epoch: 6| Step: 5
Training loss: 0.7731731534004211
Validation loss: 1.7006196860344178

Epoch: 6| Step: 6
Training loss: 0.945666491985321
Validation loss: 1.7052638376912763

Epoch: 6| Step: 7
Training loss: 0.6042385697364807
Validation loss: 1.6868927478790283

Epoch: 6| Step: 8
Training loss: 0.922976553440094
Validation loss: 1.71010604212361

Epoch: 6| Step: 9
Training loss: 1.2871941328048706
Validation loss: 1.7222468442814325

Epoch: 6| Step: 10
Training loss: 0.41434627771377563
Validation loss: 1.6717433455169841

Epoch: 6| Step: 11
Training loss: 0.7191447019577026
Validation loss: 1.666471686414493

Epoch: 6| Step: 12
Training loss: 1.6599953174591064
Validation loss: 1.6566507765041885

Epoch: 6| Step: 13
Training loss: 0.8885807394981384
Validation loss: 1.7286024183355353

Epoch: 471| Step: 0
Training loss: 1.0232359170913696
Validation loss: 1.7041456930098995

Epoch: 6| Step: 1
Training loss: 0.6968827247619629
Validation loss: 1.7065245554011355

Epoch: 6| Step: 2
Training loss: 0.6574797630310059
Validation loss: 1.6446622058909426

Epoch: 6| Step: 3
Training loss: 1.2354944944381714
Validation loss: 1.7038865050961893

Epoch: 6| Step: 4
Training loss: 0.95281982421875
Validation loss: 1.6880523363749187

Epoch: 6| Step: 5
Training loss: 0.9689120054244995
Validation loss: 1.657374276909777

Epoch: 6| Step: 6
Training loss: 1.1983299255371094
Validation loss: 1.6586580750762776

Epoch: 6| Step: 7
Training loss: 0.6649374961853027
Validation loss: 1.6707900839467202

Epoch: 6| Step: 8
Training loss: 1.1170017719268799
Validation loss: 1.6692077805919032

Epoch: 6| Step: 9
Training loss: 0.7827016711235046
Validation loss: 1.7738601507679108

Epoch: 6| Step: 10
Training loss: 0.7557947635650635
Validation loss: 1.6810407497549569

Epoch: 6| Step: 11
Training loss: 0.9598623514175415
Validation loss: 1.6785232315781295

Epoch: 6| Step: 12
Training loss: 0.9929652214050293
Validation loss: 1.7218383178916028

Epoch: 6| Step: 13
Training loss: 1.3905375003814697
Validation loss: 1.7501659598401798

Epoch: 472| Step: 0
Training loss: 0.6282798647880554
Validation loss: 1.7233154235347625

Epoch: 6| Step: 1
Training loss: 1.1613411903381348
Validation loss: 1.695025569649153

Epoch: 6| Step: 2
Training loss: 1.669783353805542
Validation loss: 1.7442336761823265

Epoch: 6| Step: 3
Training loss: 0.7568237781524658
Validation loss: 1.6876743749905658

Epoch: 6| Step: 4
Training loss: 1.1621005535125732
Validation loss: 1.6698026823741134

Epoch: 6| Step: 5
Training loss: 0.893004834651947
Validation loss: 1.7249671848871375

Epoch: 6| Step: 6
Training loss: 0.9207963943481445
Validation loss: 1.702755747302886

Epoch: 6| Step: 7
Training loss: 0.901580274105072
Validation loss: 1.7470843561234013

Epoch: 6| Step: 8
Training loss: 0.9662617444992065
Validation loss: 1.7278252006858907

Epoch: 6| Step: 9
Training loss: 0.9181708097457886
Validation loss: 1.6521383857214322

Epoch: 6| Step: 10
Training loss: 0.9365061521530151
Validation loss: 1.694163663412935

Epoch: 6| Step: 11
Training loss: 0.9704172015190125
Validation loss: 1.6349597284870763

Epoch: 6| Step: 12
Training loss: 0.6282501220703125
Validation loss: 1.6475697050812423

Epoch: 6| Step: 13
Training loss: 1.3076255321502686
Validation loss: 1.6253129884760866

Epoch: 473| Step: 0
Training loss: 0.709456741809845
Validation loss: 1.7019172035237795

Epoch: 6| Step: 1
Training loss: 0.7607378959655762
Validation loss: 1.7211132318742814

Epoch: 6| Step: 2
Training loss: 1.1336854696273804
Validation loss: 1.6621642292186778

Epoch: 6| Step: 3
Training loss: 0.8425981998443604
Validation loss: 1.680271940846597

Epoch: 6| Step: 4
Training loss: 1.165118932723999
Validation loss: 1.7439954947399836

Epoch: 6| Step: 5
Training loss: 1.4652769565582275
Validation loss: 1.7332554171162267

Epoch: 6| Step: 6
Training loss: 1.0222541093826294
Validation loss: 1.75586393315305

Epoch: 6| Step: 7
Training loss: 0.6926624774932861
Validation loss: 1.7309938348749632

Epoch: 6| Step: 8
Training loss: 1.0028455257415771
Validation loss: 1.7267257718629734

Epoch: 6| Step: 9
Training loss: 0.6441246271133423
Validation loss: 1.6910142078194568

Epoch: 6| Step: 10
Training loss: 1.1285814046859741
Validation loss: 1.7373945046496648

Epoch: 6| Step: 11
Training loss: 0.7724796533584595
Validation loss: 1.712606882536283

Epoch: 6| Step: 12
Training loss: 0.813473641872406
Validation loss: 1.6422671989728046

Epoch: 6| Step: 13
Training loss: 1.0039910078048706
Validation loss: 1.703252321930342

Epoch: 474| Step: 0
Training loss: 0.9521984457969666
Validation loss: 1.616920873682986

Epoch: 6| Step: 1
Training loss: 1.0295443534851074
Validation loss: 1.6658343768888904

Epoch: 6| Step: 2
Training loss: 1.0823360681533813
Validation loss: 1.6583814274880193

Epoch: 6| Step: 3
Training loss: 0.9950739741325378
Validation loss: 1.6959787248283305

Epoch: 6| Step: 4
Training loss: 0.8378461599349976
Validation loss: 1.7067847687710997

Epoch: 6| Step: 5
Training loss: 0.9892414808273315
Validation loss: 1.687769502721807

Epoch: 6| Step: 6
Training loss: 0.7438251376152039
Validation loss: 1.6781215334451327

Epoch: 6| Step: 7
Training loss: 0.9956188201904297
Validation loss: 1.6584140152059577

Epoch: 6| Step: 8
Training loss: 0.6845423579216003
Validation loss: 1.6702580234055877

Epoch: 6| Step: 9
Training loss: 0.7915163636207581
Validation loss: 1.689494062495488

Epoch: 6| Step: 10
Training loss: 0.8444338440895081
Validation loss: 1.6791557996503768

Epoch: 6| Step: 11
Training loss: 1.4718620777130127
Validation loss: 1.6706469981901106

Epoch: 6| Step: 12
Training loss: 0.7272582054138184
Validation loss: 1.6555048458037838

Epoch: 6| Step: 13
Training loss: 0.7228950262069702
Validation loss: 1.6378861857998757

Epoch: 475| Step: 0
Training loss: 1.2634055614471436
Validation loss: 1.6299364054074852

Epoch: 6| Step: 1
Training loss: 0.9687412977218628
Validation loss: 1.694199356981503

Epoch: 6| Step: 2
Training loss: 0.8083398342132568
Validation loss: 1.6971819375150947

Epoch: 6| Step: 3
Training loss: 0.5973720550537109
Validation loss: 1.706517961717421

Epoch: 6| Step: 4
Training loss: 0.9357123374938965
Validation loss: 1.735811580893814

Epoch: 6| Step: 5
Training loss: 1.295473575592041
Validation loss: 1.7187842745934763

Epoch: 6| Step: 6
Training loss: 0.7667961120605469
Validation loss: 1.6594259315921414

Epoch: 6| Step: 7
Training loss: 0.818426787853241
Validation loss: 1.693861149972485

Epoch: 6| Step: 8
Training loss: 1.328078031539917
Validation loss: 1.695635090592087

Epoch: 6| Step: 9
Training loss: 0.643673300743103
Validation loss: 1.6810988835109177

Epoch: 6| Step: 10
Training loss: 0.8505799770355225
Validation loss: 1.7045731916222522

Epoch: 6| Step: 11
Training loss: 0.9010350704193115
Validation loss: 1.740659377908194

Epoch: 6| Step: 12
Training loss: 0.9172520637512207
Validation loss: 1.658665724979934

Epoch: 6| Step: 13
Training loss: 0.9747900366783142
Validation loss: 1.6516305733752508

Epoch: 476| Step: 0
Training loss: 1.1674010753631592
Validation loss: 1.6656140755581599

Epoch: 6| Step: 1
Training loss: 0.6633332967758179
Validation loss: 1.6664591989209574

Epoch: 6| Step: 2
Training loss: 0.6855823397636414
Validation loss: 1.6686250279026646

Epoch: 6| Step: 3
Training loss: 0.8416675925254822
Validation loss: 1.7051736180500319

Epoch: 6| Step: 4
Training loss: 1.8107028007507324
Validation loss: 1.6830808654908211

Epoch: 6| Step: 5
Training loss: 0.7910842895507812
Validation loss: 1.7185949061506538

Epoch: 6| Step: 6
Training loss: 0.6985442042350769
Validation loss: 1.6815205652226684

Epoch: 6| Step: 7
Training loss: 1.1272927522659302
Validation loss: 1.6887316332068494

Epoch: 6| Step: 8
Training loss: 1.0543040037155151
Validation loss: 1.6979046085829377

Epoch: 6| Step: 9
Training loss: 0.7108515501022339
Validation loss: 1.6984364319873113

Epoch: 6| Step: 10
Training loss: 0.9944127798080444
Validation loss: 1.70453276172761

Epoch: 6| Step: 11
Training loss: 0.9145187139511108
Validation loss: 1.7132344258728849

Epoch: 6| Step: 12
Training loss: 0.8106248378753662
Validation loss: 1.6777531075221237

Epoch: 6| Step: 13
Training loss: 0.8052833080291748
Validation loss: 1.697115973759723

Epoch: 477| Step: 0
Training loss: 0.9754674434661865
Validation loss: 1.6818203182630642

Epoch: 6| Step: 1
Training loss: 1.1681288480758667
Validation loss: 1.6778845376865839

Epoch: 6| Step: 2
Training loss: 0.987872302532196
Validation loss: 1.6283172433094313

Epoch: 6| Step: 3
Training loss: 0.7192418575286865
Validation loss: 1.6563451085039365

Epoch: 6| Step: 4
Training loss: 1.1209686994552612
Validation loss: 1.6364435931687713

Epoch: 6| Step: 5
Training loss: 0.5572807192802429
Validation loss: 1.6594422504466066

Epoch: 6| Step: 6
Training loss: 0.7407346367835999
Validation loss: 1.727237847543532

Epoch: 6| Step: 7
Training loss: 1.0087549686431885
Validation loss: 1.6855225293867049

Epoch: 6| Step: 8
Training loss: 1.3210434913635254
Validation loss: 1.7188866035912627

Epoch: 6| Step: 9
Training loss: 0.44200339913368225
Validation loss: 1.7335622772093742

Epoch: 6| Step: 10
Training loss: 1.0168020725250244
Validation loss: 1.7438819587871592

Epoch: 6| Step: 11
Training loss: 0.7556014060974121
Validation loss: 1.7694293324665358

Epoch: 6| Step: 12
Training loss: 0.8401996493339539
Validation loss: 1.6576889099613312

Epoch: 6| Step: 13
Training loss: 1.4081120491027832
Validation loss: 1.7363721580915554

Epoch: 478| Step: 0
Training loss: 0.775696873664856
Validation loss: 1.774760600059263

Epoch: 6| Step: 1
Training loss: 0.35079526901245117
Validation loss: 1.6721871924656693

Epoch: 6| Step: 2
Training loss: 0.7954307794570923
Validation loss: 1.6669567579864173

Epoch: 6| Step: 3
Training loss: 0.6514852643013
Validation loss: 1.7135095750131915

Epoch: 6| Step: 4
Training loss: 0.7863932251930237
Validation loss: 1.6884080697131414

Epoch: 6| Step: 5
Training loss: 1.0195847749710083
Validation loss: 1.6990619449205295

Epoch: 6| Step: 6
Training loss: 1.0383609533309937
Validation loss: 1.6742344492225236

Epoch: 6| Step: 7
Training loss: 0.7666201591491699
Validation loss: 1.6826915625602967

Epoch: 6| Step: 8
Training loss: 0.8777809143066406
Validation loss: 1.6567561587979716

Epoch: 6| Step: 9
Training loss: 1.2884485721588135
Validation loss: 1.6794273545665126

Epoch: 6| Step: 10
Training loss: 1.114126443862915
Validation loss: 1.705769290206253

Epoch: 6| Step: 11
Training loss: 0.7408846616744995
Validation loss: 1.6828111269140755

Epoch: 6| Step: 12
Training loss: 1.4862639904022217
Validation loss: 1.645190195370746

Epoch: 6| Step: 13
Training loss: 0.6553390622138977
Validation loss: 1.7362358313734814

Epoch: 479| Step: 0
Training loss: 0.77473384141922
Validation loss: 1.7122744565368981

Epoch: 6| Step: 1
Training loss: 1.0067061185836792
Validation loss: 1.6750968707505094

Epoch: 6| Step: 2
Training loss: 1.0626428127288818
Validation loss: 1.6920292018562235

Epoch: 6| Step: 3
Training loss: 0.8795883655548096
Validation loss: 1.6949571358260287

Epoch: 6| Step: 4
Training loss: 1.063887596130371
Validation loss: 1.6960648490536598

Epoch: 6| Step: 5
Training loss: 0.6318753957748413
Validation loss: 1.667367168652114

Epoch: 6| Step: 6
Training loss: 1.4573462009429932
Validation loss: 1.7412850728598974

Epoch: 6| Step: 7
Training loss: 0.8296687602996826
Validation loss: 1.6984301754223403

Epoch: 6| Step: 8
Training loss: 0.8955108523368835
Validation loss: 1.6954435353638024

Epoch: 6| Step: 9
Training loss: 1.050990104675293
Validation loss: 1.6878817722361574

Epoch: 6| Step: 10
Training loss: 1.5029683113098145
Validation loss: 1.680676019319924

Epoch: 6| Step: 11
Training loss: 0.562695324420929
Validation loss: 1.6897778716138614

Epoch: 6| Step: 12
Training loss: 0.6269761323928833
Validation loss: 1.683085008334088

Epoch: 6| Step: 13
Training loss: 0.6446768045425415
Validation loss: 1.7076601482206775

Epoch: 480| Step: 0
Training loss: 1.1420140266418457
Validation loss: 1.7316313456463557

Epoch: 6| Step: 1
Training loss: 0.5344868898391724
Validation loss: 1.6901652851412374

Epoch: 6| Step: 2
Training loss: 0.8699400424957275
Validation loss: 1.6650674202108895

Epoch: 6| Step: 3
Training loss: 0.7401983141899109
Validation loss: 1.631242923839118

Epoch: 6| Step: 4
Training loss: 0.9840890765190125
Validation loss: 1.6669780695310203

Epoch: 6| Step: 5
Training loss: 0.9065290093421936
Validation loss: 1.6859799841398835

Epoch: 6| Step: 6
Training loss: 0.6094043254852295
Validation loss: 1.6822021327992922

Epoch: 6| Step: 7
Training loss: 1.0913689136505127
Validation loss: 1.6743132401538152

Epoch: 6| Step: 8
Training loss: 0.7179490923881531
Validation loss: 1.6986822748696933

Epoch: 6| Step: 9
Training loss: 1.2533169984817505
Validation loss: 1.6728090829746698

Epoch: 6| Step: 10
Training loss: 0.9654713869094849
Validation loss: 1.6832727860378962

Epoch: 6| Step: 11
Training loss: 0.9485077857971191
Validation loss: 1.6766382481462212

Epoch: 6| Step: 12
Training loss: 1.1310546398162842
Validation loss: 1.7044797930666196

Epoch: 6| Step: 13
Training loss: 0.7428923845291138
Validation loss: 1.6557202057171894

Epoch: 481| Step: 0
Training loss: 1.05289888381958
Validation loss: 1.6794383115665887

Epoch: 6| Step: 1
Training loss: 0.5126464366912842
Validation loss: 1.6458914818302277

Epoch: 6| Step: 2
Training loss: 0.5506897568702698
Validation loss: 1.6512242824800554

Epoch: 6| Step: 3
Training loss: 1.081792950630188
Validation loss: 1.7056499693983345

Epoch: 6| Step: 4
Training loss: 0.6013613939285278
Validation loss: 1.677839934184987

Epoch: 6| Step: 5
Training loss: 0.9606137275695801
Validation loss: 1.6260519130255586

Epoch: 6| Step: 6
Training loss: 1.256554365158081
Validation loss: 1.6539098126913911

Epoch: 6| Step: 7
Training loss: 0.9052330255508423
Validation loss: 1.68372086299363

Epoch: 6| Step: 8
Training loss: 1.013465404510498
Validation loss: 1.6642791135336763

Epoch: 6| Step: 9
Training loss: 0.8333896398544312
Validation loss: 1.6897924292472102

Epoch: 6| Step: 10
Training loss: 0.9577264785766602
Validation loss: 1.6884748294789305

Epoch: 6| Step: 11
Training loss: 1.0432605743408203
Validation loss: 1.6922730809898787

Epoch: 6| Step: 12
Training loss: 0.9214900732040405
Validation loss: 1.685139972676513

Epoch: 6| Step: 13
Training loss: 1.216078281402588
Validation loss: 1.7053905430660452

Epoch: 482| Step: 0
Training loss: 0.9972473382949829
Validation loss: 1.6541446575554468

Epoch: 6| Step: 1
Training loss: 1.4066214561462402
Validation loss: 1.6999452408923899

Epoch: 6| Step: 2
Training loss: 0.3885248899459839
Validation loss: 1.6533210469830422

Epoch: 6| Step: 3
Training loss: 0.6766921877861023
Validation loss: 1.6766812006632488

Epoch: 6| Step: 4
Training loss: 1.0833570957183838
Validation loss: 1.705872816424216

Epoch: 6| Step: 5
Training loss: 1.002550721168518
Validation loss: 1.6521757020745227

Epoch: 6| Step: 6
Training loss: 0.6797264218330383
Validation loss: 1.6784168366462953

Epoch: 6| Step: 7
Training loss: 0.6078405976295471
Validation loss: 1.6491549720046341

Epoch: 6| Step: 8
Training loss: 0.7420690059661865
Validation loss: 1.6850967740499845

Epoch: 6| Step: 9
Training loss: 0.6063430905342102
Validation loss: 1.7078611658465477

Epoch: 6| Step: 10
Training loss: 0.9070891737937927
Validation loss: 1.676819811585129

Epoch: 6| Step: 11
Training loss: 1.2536160945892334
Validation loss: 1.717094434204922

Epoch: 6| Step: 12
Training loss: 1.604071855545044
Validation loss: 1.6494063126143588

Epoch: 6| Step: 13
Training loss: 0.8982712626457214
Validation loss: 1.6710292062451761

Epoch: 483| Step: 0
Training loss: 1.127354383468628
Validation loss: 1.6983075987908147

Epoch: 6| Step: 1
Training loss: 0.7901498675346375
Validation loss: 1.7234619766153314

Epoch: 6| Step: 2
Training loss: 1.1452393531799316
Validation loss: 1.7044907205848283

Epoch: 6| Step: 3
Training loss: 0.500503420829773
Validation loss: 1.715114180759717

Epoch: 6| Step: 4
Training loss: 0.563506543636322
Validation loss: 1.673085367807778

Epoch: 6| Step: 5
Training loss: 1.2826272249221802
Validation loss: 1.6936507199400215

Epoch: 6| Step: 6
Training loss: 0.7370463609695435
Validation loss: 1.6662479600598734

Epoch: 6| Step: 7
Training loss: 1.1056259870529175
Validation loss: 1.6632699851066834

Epoch: 6| Step: 8
Training loss: 1.115584135055542
Validation loss: 1.6792440927156838

Epoch: 6| Step: 9
Training loss: 0.5377436876296997
Validation loss: 1.632305650300877

Epoch: 6| Step: 10
Training loss: 0.8050382137298584
Validation loss: 1.6614947729213263

Epoch: 6| Step: 11
Training loss: 1.1994823217391968
Validation loss: 1.6977156259680306

Epoch: 6| Step: 12
Training loss: 0.48791253566741943
Validation loss: 1.644231451454983

Epoch: 6| Step: 13
Training loss: 0.7635306715965271
Validation loss: 1.6493204947440856

Epoch: 484| Step: 0
Training loss: 1.3271396160125732
Validation loss: 1.6642009058306295

Epoch: 6| Step: 1
Training loss: 0.9557711482048035
Validation loss: 1.680623371114013

Epoch: 6| Step: 2
Training loss: 0.8320161700248718
Validation loss: 1.6982308767175163

Epoch: 6| Step: 3
Training loss: 0.5240627527236938
Validation loss: 1.7592441663947156

Epoch: 6| Step: 4
Training loss: 0.7170652151107788
Validation loss: 1.7234750358007287

Epoch: 6| Step: 5
Training loss: 0.9705981612205505
Validation loss: 1.7629949303083523

Epoch: 6| Step: 6
Training loss: 0.6432181596755981
Validation loss: 1.7105666642547936

Epoch: 6| Step: 7
Training loss: 0.825660228729248
Validation loss: 1.7451978575798772

Epoch: 6| Step: 8
Training loss: 0.9593498110771179
Validation loss: 1.718756757756715

Epoch: 6| Step: 9
Training loss: 0.9959784150123596
Validation loss: 1.7593190464922177

Epoch: 6| Step: 10
Training loss: 1.3754826784133911
Validation loss: 1.7039937614112772

Epoch: 6| Step: 11
Training loss: 1.173552393913269
Validation loss: 1.6754704572821175

Epoch: 6| Step: 12
Training loss: 0.8107411861419678
Validation loss: 1.6737949181628484

Epoch: 6| Step: 13
Training loss: 0.3567489981651306
Validation loss: 1.6737513234538417

Epoch: 485| Step: 0
Training loss: 0.8256503939628601
Validation loss: 1.6563668930402367

Epoch: 6| Step: 1
Training loss: 0.5445713400840759
Validation loss: 1.6463745012078235

Epoch: 6| Step: 2
Training loss: 0.716907799243927
Validation loss: 1.6371286799830775

Epoch: 6| Step: 3
Training loss: 1.2323830127716064
Validation loss: 1.6493080136596516

Epoch: 6| Step: 4
Training loss: 1.1871163845062256
Validation loss: 1.6489991449540662

Epoch: 6| Step: 5
Training loss: 1.1845407485961914
Validation loss: 1.6962087128752021

Epoch: 6| Step: 6
Training loss: 0.7350485324859619
Validation loss: 1.6820187876301427

Epoch: 6| Step: 7
Training loss: 0.8749114274978638
Validation loss: 1.6361410028191024

Epoch: 6| Step: 8
Training loss: 0.7930070161819458
Validation loss: 1.6581270220459148

Epoch: 6| Step: 9
Training loss: 0.5815476179122925
Validation loss: 1.7186648871309014

Epoch: 6| Step: 10
Training loss: 1.0015242099761963
Validation loss: 1.7330641464520526

Epoch: 6| Step: 11
Training loss: 1.1774003505706787
Validation loss: 1.7007838897807623

Epoch: 6| Step: 12
Training loss: 0.6378157138824463
Validation loss: 1.6668018269282516

Epoch: 6| Step: 13
Training loss: 0.9829638004302979
Validation loss: 1.7036879421562277

Epoch: 486| Step: 0
Training loss: 0.8423121571540833
Validation loss: 1.6633980620291926

Epoch: 6| Step: 1
Training loss: 0.5865304470062256
Validation loss: 1.7363576927492697

Epoch: 6| Step: 2
Training loss: 0.9445432424545288
Validation loss: 1.6987348602664085

Epoch: 6| Step: 3
Training loss: 1.0470542907714844
Validation loss: 1.6719973625675324

Epoch: 6| Step: 4
Training loss: 0.9670804142951965
Validation loss: 1.7068443734158751

Epoch: 6| Step: 5
Training loss: 1.0318790674209595
Validation loss: 1.6694445199863885

Epoch: 6| Step: 6
Training loss: 0.8287163376808167
Validation loss: 1.6993290942202333

Epoch: 6| Step: 7
Training loss: 1.259728193283081
Validation loss: 1.7173067946587839

Epoch: 6| Step: 8
Training loss: 1.0516080856323242
Validation loss: 1.6714416037323654

Epoch: 6| Step: 9
Training loss: 0.8617424964904785
Validation loss: 1.6538913352515108

Epoch: 6| Step: 10
Training loss: 0.4655945301055908
Validation loss: 1.709469315826252

Epoch: 6| Step: 11
Training loss: 0.617558479309082
Validation loss: 1.6951937367839198

Epoch: 6| Step: 12
Training loss: 1.320251703262329
Validation loss: 1.6892430538772254

Epoch: 6| Step: 13
Training loss: 0.8315078616142273
Validation loss: 1.6708072577753375

Epoch: 487| Step: 0
Training loss: 1.0258407592773438
Validation loss: 1.6079748843305854

Epoch: 6| Step: 1
Training loss: 1.5076115131378174
Validation loss: 1.6846522259455856

Epoch: 6| Step: 2
Training loss: 1.1546393632888794
Validation loss: 1.654479636940905

Epoch: 6| Step: 3
Training loss: 0.7356829643249512
Validation loss: 1.6386560227281304

Epoch: 6| Step: 4
Training loss: 0.9028339982032776
Validation loss: 1.6375260263360956

Epoch: 6| Step: 5
Training loss: 0.4291682541370392
Validation loss: 1.6224403419802267

Epoch: 6| Step: 6
Training loss: 0.5407996773719788
Validation loss: 1.6973197280719716

Epoch: 6| Step: 7
Training loss: 0.805457353591919
Validation loss: 1.6657095660445511

Epoch: 6| Step: 8
Training loss: 0.7309484481811523
Validation loss: 1.6601538888869747

Epoch: 6| Step: 9
Training loss: 1.2650519609451294
Validation loss: 1.6631217015686857

Epoch: 6| Step: 10
Training loss: 1.251799464225769
Validation loss: 1.6740055558502034

Epoch: 6| Step: 11
Training loss: 0.9472488164901733
Validation loss: 1.6849724490155455

Epoch: 6| Step: 12
Training loss: 0.5370163321495056
Validation loss: 1.723363878906414

Epoch: 6| Step: 13
Training loss: 0.6458557844161987
Validation loss: 1.68266087578189

Epoch: 488| Step: 0
Training loss: 1.0193123817443848
Validation loss: 1.6476405012992121

Epoch: 6| Step: 1
Training loss: 1.1942026615142822
Validation loss: 1.6671364153585126

Epoch: 6| Step: 2
Training loss: 0.9914644956588745
Validation loss: 1.6720219299357424

Epoch: 6| Step: 3
Training loss: 0.8369985818862915
Validation loss: 1.6102133912424887

Epoch: 6| Step: 4
Training loss: 0.6113718748092651
Validation loss: 1.6867594847115137

Epoch: 6| Step: 5
Training loss: 0.8671447038650513
Validation loss: 1.694221104345014

Epoch: 6| Step: 6
Training loss: 1.1568880081176758
Validation loss: 1.719756281504067

Epoch: 6| Step: 7
Training loss: 0.7454493045806885
Validation loss: 1.7028518338357248

Epoch: 6| Step: 8
Training loss: 1.0194858312606812
Validation loss: 1.6593409276777698

Epoch: 6| Step: 9
Training loss: 0.834909975528717
Validation loss: 1.6769622756588844

Epoch: 6| Step: 10
Training loss: 0.6461297273635864
Validation loss: 1.6704493325243714

Epoch: 6| Step: 11
Training loss: 0.7348836660385132
Validation loss: 1.6805929817179197

Epoch: 6| Step: 12
Training loss: 0.8969913125038147
Validation loss: 1.703732713576286

Epoch: 6| Step: 13
Training loss: 1.2221072912216187
Validation loss: 1.6544484681980585

Epoch: 489| Step: 0
Training loss: 0.8883903622627258
Validation loss: 1.6856738123842465

Epoch: 6| Step: 1
Training loss: 1.2643835544586182
Validation loss: 1.681199242991786

Epoch: 6| Step: 2
Training loss: 1.1959953308105469
Validation loss: 1.6703480059100735

Epoch: 6| Step: 3
Training loss: 0.6712117791175842
Validation loss: 1.700162528663553

Epoch: 6| Step: 4
Training loss: 0.45367103815078735
Validation loss: 1.671308148291803

Epoch: 6| Step: 5
Training loss: 0.8647735118865967
Validation loss: 1.649404832111892

Epoch: 6| Step: 6
Training loss: 0.7738186120986938
Validation loss: 1.7020234600190194

Epoch: 6| Step: 7
Training loss: 1.1961610317230225
Validation loss: 1.675864588829779

Epoch: 6| Step: 8
Training loss: 0.9028328061103821
Validation loss: 1.6344445059376378

Epoch: 6| Step: 9
Training loss: 0.8313125371932983
Validation loss: 1.6410014296090731

Epoch: 6| Step: 10
Training loss: 1.4403156042099
Validation loss: 1.6640836795171101

Epoch: 6| Step: 11
Training loss: 0.5312326550483704
Validation loss: 1.691606310106093

Epoch: 6| Step: 12
Training loss: 1.1277070045471191
Validation loss: 1.680056486078488

Epoch: 6| Step: 13
Training loss: 0.5822372436523438
Validation loss: 1.6957947695127098

Epoch: 490| Step: 0
Training loss: 0.613882303237915
Validation loss: 1.6640849933829358

Epoch: 6| Step: 1
Training loss: 0.6235476136207581
Validation loss: 1.7233336881924701

Epoch: 6| Step: 2
Training loss: 0.9052679538726807
Validation loss: 1.7388150461258427

Epoch: 6| Step: 3
Training loss: 1.049727201461792
Validation loss: 1.7176807721455891

Epoch: 6| Step: 4
Training loss: 0.997340202331543
Validation loss: 1.7245303264228247

Epoch: 6| Step: 5
Training loss: 0.46568840742111206
Validation loss: 1.7387178521002493

Epoch: 6| Step: 6
Training loss: 1.0747387409210205
Validation loss: 1.6500384858859483

Epoch: 6| Step: 7
Training loss: 1.0016452074050903
Validation loss: 1.6491987705230713

Epoch: 6| Step: 8
Training loss: 1.2549349069595337
Validation loss: 1.6920215160615983

Epoch: 6| Step: 9
Training loss: 0.9257431030273438
Validation loss: 1.6732756117338776

Epoch: 6| Step: 10
Training loss: 0.8227918148040771
Validation loss: 1.6799691313056535

Epoch: 6| Step: 11
Training loss: 0.913481593132019
Validation loss: 1.65154819462889

Epoch: 6| Step: 12
Training loss: 1.0376994609832764
Validation loss: 1.6197839193446661

Epoch: 6| Step: 13
Training loss: 0.642395555973053
Validation loss: 1.6451358179892264

Epoch: 491| Step: 0
Training loss: 1.4067258834838867
Validation loss: 1.6699028797047113

Epoch: 6| Step: 1
Training loss: 0.7017349004745483
Validation loss: 1.7419768571853638

Epoch: 6| Step: 2
Training loss: 0.6971895694732666
Validation loss: 1.6657873328014086

Epoch: 6| Step: 3
Training loss: 1.4467897415161133
Validation loss: 1.7054374884533625

Epoch: 6| Step: 4
Training loss: 0.7968020439147949
Validation loss: 1.6701391345711165

Epoch: 6| Step: 5
Training loss: 0.8665400743484497
Validation loss: 1.6723934527366393

Epoch: 6| Step: 6
Training loss: 0.7302062511444092
Validation loss: 1.7658246435144895

Epoch: 6| Step: 7
Training loss: 0.6067588329315186
Validation loss: 1.6648121572309924

Epoch: 6| Step: 8
Training loss: 0.9262735247612
Validation loss: 1.6965355462925409

Epoch: 6| Step: 9
Training loss: 0.7758339643478394
Validation loss: 1.6947445536172518

Epoch: 6| Step: 10
Training loss: 1.2364134788513184
Validation loss: 1.659433400759133

Epoch: 6| Step: 11
Training loss: 0.7123868465423584
Validation loss: 1.7110196954460555

Epoch: 6| Step: 12
Training loss: 1.0956878662109375
Validation loss: 1.6403791353266726

Epoch: 6| Step: 13
Training loss: 0.5448548793792725
Validation loss: 1.7096834785194808

Epoch: 492| Step: 0
Training loss: 1.2977547645568848
Validation loss: 1.6598584216128114

Epoch: 6| Step: 1
Training loss: 0.712897002696991
Validation loss: 1.6640628883915562

Epoch: 6| Step: 2
Training loss: 0.955042839050293
Validation loss: 1.7010859392022575

Epoch: 6| Step: 3
Training loss: 1.5103291273117065
Validation loss: 1.6575465202331543

Epoch: 6| Step: 4
Training loss: 0.7149401307106018
Validation loss: 1.6857929857828284

Epoch: 6| Step: 5
Training loss: 0.8003002405166626
Validation loss: 1.6544232522287676

Epoch: 6| Step: 6
Training loss: 0.918245255947113
Validation loss: 1.705439236856276

Epoch: 6| Step: 7
Training loss: 0.6867991089820862
Validation loss: 1.7567999632127824

Epoch: 6| Step: 8
Training loss: 0.6416618824005127
Validation loss: 1.8070771668546943

Epoch: 6| Step: 9
Training loss: 0.7642101645469666
Validation loss: 1.7410941803327171

Epoch: 6| Step: 10
Training loss: 0.9451650977134705
Validation loss: 1.6759146605768511

Epoch: 6| Step: 11
Training loss: 1.3235679864883423
Validation loss: 1.6991484319010088

Epoch: 6| Step: 12
Training loss: 0.6973447799682617
Validation loss: 1.682529100166854

Epoch: 6| Step: 13
Training loss: 0.7240709662437439
Validation loss: 1.6603415858361028

Epoch: 493| Step: 0
Training loss: 0.857572078704834
Validation loss: 1.7340157134558565

Epoch: 6| Step: 1
Training loss: 0.7672582268714905
Validation loss: 1.674846040305271

Epoch: 6| Step: 2
Training loss: 0.5434761047363281
Validation loss: 1.6418503010144798

Epoch: 6| Step: 3
Training loss: 0.776828408241272
Validation loss: 1.6651360475888817

Epoch: 6| Step: 4
Training loss: 0.9185532331466675
Validation loss: 1.6531193794742707

Epoch: 6| Step: 5
Training loss: 0.6642003059387207
Validation loss: 1.6562758479067075

Epoch: 6| Step: 6
Training loss: 0.7443512082099915
Validation loss: 1.6789044564770115

Epoch: 6| Step: 7
Training loss: 1.845062494277954
Validation loss: 1.7333097252794492

Epoch: 6| Step: 8
Training loss: 0.640173077583313
Validation loss: 1.7365446949517855

Epoch: 6| Step: 9
Training loss: 1.2802932262420654
Validation loss: 1.6822134205090102

Epoch: 6| Step: 10
Training loss: 1.0510292053222656
Validation loss: 1.6984557849104687

Epoch: 6| Step: 11
Training loss: 0.5611087083816528
Validation loss: 1.7183634722104637

Epoch: 6| Step: 12
Training loss: 0.839856743812561
Validation loss: 1.769068492356167

Epoch: 6| Step: 13
Training loss: 0.6937785744667053
Validation loss: 1.7277927065408358

Epoch: 494| Step: 0
Training loss: 1.0478150844573975
Validation loss: 1.7338395349441036

Epoch: 6| Step: 1
Training loss: 0.8997124433517456
Validation loss: 1.7293159051608014

Epoch: 6| Step: 2
Training loss: 0.7977191209793091
Validation loss: 1.701394522061912

Epoch: 6| Step: 3
Training loss: 1.2872262001037598
Validation loss: 1.7116631666819255

Epoch: 6| Step: 4
Training loss: 0.8123297691345215
Validation loss: 1.65544718439861

Epoch: 6| Step: 5
Training loss: 1.1136226654052734
Validation loss: 1.613529033558343

Epoch: 6| Step: 6
Training loss: 1.110763430595398
Validation loss: 1.635803735384377

Epoch: 6| Step: 7
Training loss: 0.5945242643356323
Validation loss: 1.658517208150638

Epoch: 6| Step: 8
Training loss: 0.7204605340957642
Validation loss: 1.645534989654377

Epoch: 6| Step: 9
Training loss: 1.0113139152526855
Validation loss: 1.6602017469303583

Epoch: 6| Step: 10
Training loss: 0.754734218120575
Validation loss: 1.691908400545838

Epoch: 6| Step: 11
Training loss: 1.0016319751739502
Validation loss: 1.5882305637482674

Epoch: 6| Step: 12
Training loss: 0.9501613974571228
Validation loss: 1.6818717372032903

Epoch: 6| Step: 13
Training loss: 0.49781084060668945
Validation loss: 1.6738008247908724

Epoch: 495| Step: 0
Training loss: 0.9022631049156189
Validation loss: 1.6721414558349117

Epoch: 6| Step: 1
Training loss: 1.039088249206543
Validation loss: 1.6758907366824407

Epoch: 6| Step: 2
Training loss: 1.177590250968933
Validation loss: 1.7261646152824484

Epoch: 6| Step: 3
Training loss: 0.8609132766723633
Validation loss: 1.7129759160421227

Epoch: 6| Step: 4
Training loss: 0.7899013757705688
Validation loss: 1.7039623183588828

Epoch: 6| Step: 5
Training loss: 0.6705921292304993
Validation loss: 1.7366822073536534

Epoch: 6| Step: 6
Training loss: 1.0718491077423096
Validation loss: 1.751858438214948

Epoch: 6| Step: 7
Training loss: 0.3177054524421692
Validation loss: 1.7222997283422818

Epoch: 6| Step: 8
Training loss: 1.3899389505386353
Validation loss: 1.7354183261112501

Epoch: 6| Step: 9
Training loss: 1.0901412963867188
Validation loss: 1.6881685769686134

Epoch: 6| Step: 10
Training loss: 1.230968952178955
Validation loss: 1.7170613658043645

Epoch: 6| Step: 11
Training loss: 0.8194583654403687
Validation loss: 1.676084494078031

Epoch: 6| Step: 12
Training loss: 0.6709731817245483
Validation loss: 1.684653425729403

Epoch: 6| Step: 13
Training loss: 0.5780757069587708
Validation loss: 1.7339562895477458

Epoch: 496| Step: 0
Training loss: 0.758602499961853
Validation loss: 1.6662111871985978

Epoch: 6| Step: 1
Training loss: 0.8970646858215332
Validation loss: 1.6719764189053608

Epoch: 6| Step: 2
Training loss: 0.6058143377304077
Validation loss: 1.7173058730299755

Epoch: 6| Step: 3
Training loss: 0.6351637840270996
Validation loss: 1.68969206143451

Epoch: 6| Step: 4
Training loss: 0.8368651866912842
Validation loss: 1.6625768548698836

Epoch: 6| Step: 5
Training loss: 0.7386718392372131
Validation loss: 1.6589999801369124

Epoch: 6| Step: 6
Training loss: 1.0241916179656982
Validation loss: 1.6482488903948056

Epoch: 6| Step: 7
Training loss: 0.7677111625671387
Validation loss: 1.6135927900191276

Epoch: 6| Step: 8
Training loss: 1.1969189643859863
Validation loss: 1.6624964155176634

Epoch: 6| Step: 9
Training loss: 1.0445805788040161
Validation loss: 1.6687540033812165

Epoch: 6| Step: 10
Training loss: 1.3581660985946655
Validation loss: 1.6191092242476761

Epoch: 6| Step: 11
Training loss: 0.9935944080352783
Validation loss: 1.6600770591407694

Epoch: 6| Step: 12
Training loss: 1.2324886322021484
Validation loss: 1.6876817300755491

Epoch: 6| Step: 13
Training loss: 0.5802199244499207
Validation loss: 1.635803363656485

Epoch: 497| Step: 0
Training loss: 0.6024973392486572
Validation loss: 1.6532941627246078

Epoch: 6| Step: 1
Training loss: 1.128418207168579
Validation loss: 1.6535050651078582

Epoch: 6| Step: 2
Training loss: 0.6353952884674072
Validation loss: 1.640929091361261

Epoch: 6| Step: 3
Training loss: 0.945949375629425
Validation loss: 1.6935275472620481

Epoch: 6| Step: 4
Training loss: 0.7661705017089844
Validation loss: 1.6352561622537591

Epoch: 6| Step: 5
Training loss: 1.1980111598968506
Validation loss: 1.6673754569022887

Epoch: 6| Step: 6
Training loss: 0.4752395749092102
Validation loss: 1.722050364299487

Epoch: 6| Step: 7
Training loss: 0.7487921118736267
Validation loss: 1.6549554832520024

Epoch: 6| Step: 8
Training loss: 0.9310698509216309
Validation loss: 1.6474617373558782

Epoch: 6| Step: 9
Training loss: 1.0950896739959717
Validation loss: 1.6457872685565744

Epoch: 6| Step: 10
Training loss: 1.312462329864502
Validation loss: 1.6198168749450355

Epoch: 6| Step: 11
Training loss: 1.041839361190796
Validation loss: 1.6715291277054818

Epoch: 6| Step: 12
Training loss: 0.578792929649353
Validation loss: 1.6476180784163936

Epoch: 6| Step: 13
Training loss: 0.5065827965736389
Validation loss: 1.6504006565258067

Epoch: 498| Step: 0
Training loss: 0.5035252571105957
Validation loss: 1.6271260681972708

Epoch: 6| Step: 1
Training loss: 0.8491910696029663
Validation loss: 1.6785061282496299

Epoch: 6| Step: 2
Training loss: 1.0447883605957031
Validation loss: 1.657161074299966

Epoch: 6| Step: 3
Training loss: 0.9200714826583862
Validation loss: 1.6956701124868085

Epoch: 6| Step: 4
Training loss: 0.713249921798706
Validation loss: 1.6838332094171995

Epoch: 6| Step: 5
Training loss: 0.7936092615127563
Validation loss: 1.667725928368107

Epoch: 6| Step: 6
Training loss: 1.0851848125457764
Validation loss: 1.6994351071696128

Epoch: 6| Step: 7
Training loss: 0.690237283706665
Validation loss: 1.6512961772180372

Epoch: 6| Step: 8
Training loss: 0.7535388469696045
Validation loss: 1.6288899311455347

Epoch: 6| Step: 9
Training loss: 1.4563875198364258
Validation loss: 1.6238404320132347

Epoch: 6| Step: 10
Training loss: 0.7077300548553467
Validation loss: 1.704149535907212

Epoch: 6| Step: 11
Training loss: 0.7526476383209229
Validation loss: 1.6791165426213255

Epoch: 6| Step: 12
Training loss: 0.5286434888839722
Validation loss: 1.663395732961675

Epoch: 6| Step: 13
Training loss: 1.1708307266235352
Validation loss: 1.661509899682896

Epoch: 499| Step: 0
Training loss: 0.730843722820282
Validation loss: 1.652888931253905

Epoch: 6| Step: 1
Training loss: 0.8654425144195557
Validation loss: 1.6424452322785572

Epoch: 6| Step: 2
Training loss: 1.2153511047363281
Validation loss: 1.703085498143268

Epoch: 6| Step: 3
Training loss: 1.002406120300293
Validation loss: 1.6531357124287596

Epoch: 6| Step: 4
Training loss: 1.3130464553833008
Validation loss: 1.6953926740154144

Epoch: 6| Step: 5
Training loss: 0.5261498689651489
Validation loss: 1.6863854136518253

Epoch: 6| Step: 6
Training loss: 0.6639381051063538
Validation loss: 1.6783818814062303

Epoch: 6| Step: 7
Training loss: 1.4388470649719238
Validation loss: 1.6716060843518985

Epoch: 6| Step: 8
Training loss: 0.87470942735672
Validation loss: 1.6802312802242976

Epoch: 6| Step: 9
Training loss: 0.547411322593689
Validation loss: 1.7013866606579031

Epoch: 6| Step: 10
Training loss: 0.7734881639480591
Validation loss: 1.7234682831712949

Epoch: 6| Step: 11
Training loss: 0.685161292552948
Validation loss: 1.6804867880318755

Epoch: 6| Step: 12
Training loss: 0.5220659971237183
Validation loss: 1.7104188088447816

Epoch: 6| Step: 13
Training loss: 1.4568816423416138
Validation loss: 1.6533502712044665

Epoch: 500| Step: 0
Training loss: 0.7987128496170044
Validation loss: 1.637607660344852

Epoch: 6| Step: 1
Training loss: 0.8461483716964722
Validation loss: 1.7036174510114936

Epoch: 6| Step: 2
Training loss: 0.8479739427566528
Validation loss: 1.629173304445

Epoch: 6| Step: 3
Training loss: 0.7251333594322205
Validation loss: 1.6656613080732283

Epoch: 6| Step: 4
Training loss: 0.8577979207038879
Validation loss: 1.6217492152285833

Epoch: 6| Step: 5
Training loss: 0.4607812464237213
Validation loss: 1.6561801882200344

Epoch: 6| Step: 6
Training loss: 1.0127843618392944
Validation loss: 1.6591751075560046

Epoch: 6| Step: 7
Training loss: 0.8456903100013733
Validation loss: 1.6954888515574957

Epoch: 6| Step: 8
Training loss: 0.8171839714050293
Validation loss: 1.697603012925835

Epoch: 6| Step: 9
Training loss: 1.2194541692733765
Validation loss: 1.6480869785431893

Epoch: 6| Step: 10
Training loss: 1.008026123046875
Validation loss: 1.6232380424776385

Epoch: 6| Step: 11
Training loss: 0.8653988242149353
Validation loss: 1.6968830862352926

Epoch: 6| Step: 12
Training loss: 0.9616422057151794
Validation loss: 1.6049218075249785

Epoch: 6| Step: 13
Training loss: 0.9986248016357422
Validation loss: 1.5977894234400924

Epoch: 501| Step: 0
Training loss: 0.7377703189849854
Validation loss: 1.6389988968449254

Epoch: 6| Step: 1
Training loss: 0.618952751159668
Validation loss: 1.6669258122803063

Epoch: 6| Step: 2
Training loss: 0.7672280073165894
Validation loss: 1.6618607249311221

Epoch: 6| Step: 3
Training loss: 0.5322579741477966
Validation loss: 1.6821940304130636

Epoch: 6| Step: 4
Training loss: 1.1315455436706543
Validation loss: 1.6255366866306593

Epoch: 6| Step: 5
Training loss: 1.3234150409698486
Validation loss: 1.6585417075823712

Epoch: 6| Step: 6
Training loss: 0.6876990795135498
Validation loss: 1.677106685535882

Epoch: 6| Step: 7
Training loss: 1.0274838209152222
Validation loss: 1.6768092416947888

Epoch: 6| Step: 8
Training loss: 0.8174233436584473
Validation loss: 1.6344722137656262

Epoch: 6| Step: 9
Training loss: 0.6442147493362427
Validation loss: 1.702551914799598

Epoch: 6| Step: 10
Training loss: 0.9791672825813293
Validation loss: 1.6589349995377243

Epoch: 6| Step: 11
Training loss: 1.2269461154937744
Validation loss: 1.623240610604645

Epoch: 6| Step: 12
Training loss: 0.7229195833206177
Validation loss: 1.706745683505971

Epoch: 6| Step: 13
Training loss: 0.7429931163787842
Validation loss: 1.670866450955791

Epoch: 502| Step: 0
Training loss: 1.1139016151428223
Validation loss: 1.6955587069193523

Epoch: 6| Step: 1
Training loss: 1.1896302700042725
Validation loss: 1.7003749673084547

Epoch: 6| Step: 2
Training loss: 0.9335763454437256
Validation loss: 1.6592783735644432

Epoch: 6| Step: 3
Training loss: 1.051425814628601
Validation loss: 1.6649319894852177

Epoch: 6| Step: 4
Training loss: 0.5824635624885559
Validation loss: 1.652565404932986

Epoch: 6| Step: 5
Training loss: 0.6424216032028198
Validation loss: 1.7392649804392168

Epoch: 6| Step: 6
Training loss: 0.837329626083374
Validation loss: 1.688044871053388

Epoch: 6| Step: 7
Training loss: 0.6457875967025757
Validation loss: 1.688002928610771

Epoch: 6| Step: 8
Training loss: 1.19047212600708
Validation loss: 1.6826162043438162

Epoch: 6| Step: 9
Training loss: 0.6974762678146362
Validation loss: 1.6755929916135726

Epoch: 6| Step: 10
Training loss: 1.0231189727783203
Validation loss: 1.6443670911173667

Epoch: 6| Step: 11
Training loss: 0.6621843576431274
Validation loss: 1.6451061028306202

Epoch: 6| Step: 12
Training loss: 0.7899618148803711
Validation loss: 1.6181722084681194

Epoch: 6| Step: 13
Training loss: 0.6771507263183594
Validation loss: 1.6337454408727667

Epoch: 503| Step: 0
Training loss: 0.5551505088806152
Validation loss: 1.6757076427500734

Epoch: 6| Step: 1
Training loss: 1.083422064781189
Validation loss: 1.6476237184257918

Epoch: 6| Step: 2
Training loss: 0.6851392388343811
Validation loss: 1.706556030499038

Epoch: 6| Step: 3
Training loss: 0.7858456373214722
Validation loss: 1.6896424613973147

Epoch: 6| Step: 4
Training loss: 0.604128897190094
Validation loss: 1.6324888352424867

Epoch: 6| Step: 5
Training loss: 1.1976144313812256
Validation loss: 1.6379837900079706

Epoch: 6| Step: 6
Training loss: 1.076327919960022
Validation loss: 1.6504070053818405

Epoch: 6| Step: 7
Training loss: 0.9904984831809998
Validation loss: 1.659645556121744

Epoch: 6| Step: 8
Training loss: 0.7516857385635376
Validation loss: 1.7528447938221756

Epoch: 6| Step: 9
Training loss: 1.2532567977905273
Validation loss: 1.680835973191005

Epoch: 6| Step: 10
Training loss: 0.8923473954200745
Validation loss: 1.677777462108161

Epoch: 6| Step: 11
Training loss: 0.6534867286682129
Validation loss: 1.639666340684378

Epoch: 6| Step: 12
Training loss: 0.701959490776062
Validation loss: 1.6345450852506904

Epoch: 6| Step: 13
Training loss: 0.7055606245994568
Validation loss: 1.668789271385439

Epoch: 504| Step: 0
Training loss: 0.91754150390625
Validation loss: 1.6615001181120514

Epoch: 6| Step: 1
Training loss: 0.5933017134666443
Validation loss: 1.6923137928849907

Epoch: 6| Step: 2
Training loss: 1.028272032737732
Validation loss: 1.6561271554680281

Epoch: 6| Step: 3
Training loss: 0.8244196176528931
Validation loss: 1.708387529978188

Epoch: 6| Step: 4
Training loss: 0.6831380724906921
Validation loss: 1.6946753917201873

Epoch: 6| Step: 5
Training loss: 0.9182824492454529
Validation loss: 1.6626428378525602

Epoch: 6| Step: 6
Training loss: 0.5472760200500488
Validation loss: 1.6892738573012813

Epoch: 6| Step: 7
Training loss: 1.001813292503357
Validation loss: 1.6446279556520524

Epoch: 6| Step: 8
Training loss: 0.8087682127952576
Validation loss: 1.635375476652576

Epoch: 6| Step: 9
Training loss: 0.7501516342163086
Validation loss: 1.6636349437057332

Epoch: 6| Step: 10
Training loss: 0.8560212850570679
Validation loss: 1.6489216986522879

Epoch: 6| Step: 11
Training loss: 0.9500224590301514
Validation loss: 1.612310609509868

Epoch: 6| Step: 12
Training loss: 1.2311201095581055
Validation loss: 1.7058945714786489

Epoch: 6| Step: 13
Training loss: 0.5624411702156067
Validation loss: 1.6266187813974196

Epoch: 505| Step: 0
Training loss: 0.8823670744895935
Validation loss: 1.6811077094847156

Epoch: 6| Step: 1
Training loss: 0.9516004920005798
Validation loss: 1.6691980605484338

Epoch: 6| Step: 2
Training loss: 0.5884255766868591
Validation loss: 1.680156818000219

Epoch: 6| Step: 3
Training loss: 0.8762633204460144
Validation loss: 1.6562978503524617

Epoch: 6| Step: 4
Training loss: 0.9810968041419983
Validation loss: 1.7109503412759433

Epoch: 6| Step: 5
Training loss: 0.9537563323974609
Validation loss: 1.731623649597168

Epoch: 6| Step: 6
Training loss: 0.6548281908035278
Validation loss: 1.6758124264337684

Epoch: 6| Step: 7
Training loss: 1.027497410774231
Validation loss: 1.6914133038572086

Epoch: 6| Step: 8
Training loss: 0.5162442922592163
Validation loss: 1.677443442806121

Epoch: 6| Step: 9
Training loss: 1.0894197225570679
Validation loss: 1.7309579977425196

Epoch: 6| Step: 10
Training loss: 0.8736969828605652
Validation loss: 1.6882735477980746

Epoch: 6| Step: 11
Training loss: 0.8443259596824646
Validation loss: 1.699717571658473

Epoch: 6| Step: 12
Training loss: 0.7874552011489868
Validation loss: 1.665146827697754

Epoch: 6| Step: 13
Training loss: 1.0296412706375122
Validation loss: 1.6684356056233889

Epoch: 506| Step: 0
Training loss: 0.563286304473877
Validation loss: 1.6338578924056022

Epoch: 6| Step: 1
Training loss: 0.8171576261520386
Validation loss: 1.6858288818790066

Epoch: 6| Step: 2
Training loss: 1.6608209609985352
Validation loss: 1.6393164909014137

Epoch: 6| Step: 3
Training loss: 0.7110630869865417
Validation loss: 1.6660671413585704

Epoch: 6| Step: 4
Training loss: 0.9541845917701721
Validation loss: 1.665654864362491

Epoch: 6| Step: 5
Training loss: 0.7378194332122803
Validation loss: 1.6934547180770545

Epoch: 6| Step: 6
Training loss: 0.8701263666152954
Validation loss: 1.6621498356583297

Epoch: 6| Step: 7
Training loss: 0.8538719415664673
Validation loss: 1.6505525240334131

Epoch: 6| Step: 8
Training loss: 0.918827474117279
Validation loss: 1.6736492572292205

Epoch: 6| Step: 9
Training loss: 0.6525067090988159
Validation loss: 1.6663962794888405

Epoch: 6| Step: 10
Training loss: 0.5389323830604553
Validation loss: 1.6977658656335646

Epoch: 6| Step: 11
Training loss: 0.5326941609382629
Validation loss: 1.693794224851875

Epoch: 6| Step: 12
Training loss: 1.297787070274353
Validation loss: 1.6954382696459371

Epoch: 6| Step: 13
Training loss: 0.5324889421463013
Validation loss: 1.619628857540828

Epoch: 507| Step: 0
Training loss: 0.7317767143249512
Validation loss: 1.714712283944571

Epoch: 6| Step: 1
Training loss: 0.6810307502746582
Validation loss: 1.6219669926551081

Epoch: 6| Step: 2
Training loss: 1.0070018768310547
Validation loss: 1.6415391916869788

Epoch: 6| Step: 3
Training loss: 0.9070590734481812
Validation loss: 1.686145354342717

Epoch: 6| Step: 4
Training loss: 0.9241142868995667
Validation loss: 1.7156597311778734

Epoch: 6| Step: 5
Training loss: 0.8893358111381531
Validation loss: 1.652649333400111

Epoch: 6| Step: 6
Training loss: 0.7433696985244751
Validation loss: 1.6901963116020284

Epoch: 6| Step: 7
Training loss: 1.0735702514648438
Validation loss: 1.6905081707944152

Epoch: 6| Step: 8
Training loss: 1.0554494857788086
Validation loss: 1.6589619831372333

Epoch: 6| Step: 9
Training loss: 1.1765544414520264
Validation loss: 1.6206245999182425

Epoch: 6| Step: 10
Training loss: 0.6183218955993652
Validation loss: 1.6718758075468

Epoch: 6| Step: 11
Training loss: 0.7238279581069946
Validation loss: 1.6409146516553816

Epoch: 6| Step: 12
Training loss: 0.6850727796554565
Validation loss: 1.6348906063264417

Epoch: 6| Step: 13
Training loss: 0.6255446076393127
Validation loss: 1.663793376697007

Epoch: 508| Step: 0
Training loss: 0.68153977394104
Validation loss: 1.6369235515594482

Epoch: 6| Step: 1
Training loss: 1.057943344116211
Validation loss: 1.625421198465491

Epoch: 6| Step: 2
Training loss: 1.429281234741211
Validation loss: 1.639697540190912

Epoch: 6| Step: 3
Training loss: 0.7215487957000732
Validation loss: 1.6662604360170261

Epoch: 6| Step: 4
Training loss: 0.3666236400604248
Validation loss: 1.6426705416812692

Epoch: 6| Step: 5
Training loss: 0.5717445611953735
Validation loss: 1.6575030460152576

Epoch: 6| Step: 6
Training loss: 0.9617310762405396
Validation loss: 1.6756125009188088

Epoch: 6| Step: 7
Training loss: 0.8724062442779541
Validation loss: 1.6858788844077819

Epoch: 6| Step: 8
Training loss: 0.8909854888916016
Validation loss: 1.6869994709568639

Epoch: 6| Step: 9
Training loss: 0.8119140267372131
Validation loss: 1.6402092044071486

Epoch: 6| Step: 10
Training loss: 1.097414255142212
Validation loss: 1.64814809701776

Epoch: 6| Step: 11
Training loss: 0.906829833984375
Validation loss: 1.6971535810860254

Epoch: 6| Step: 12
Training loss: 0.6054062843322754
Validation loss: 1.679685817610833

Epoch: 6| Step: 13
Training loss: 0.568954586982727
Validation loss: 1.6385857193700728

Epoch: 509| Step: 0
Training loss: 0.7789016962051392
Validation loss: 1.627280741609553

Epoch: 6| Step: 1
Training loss: 0.7482476234436035
Validation loss: 1.6651255763987058

Epoch: 6| Step: 2
Training loss: 1.0307868719100952
Validation loss: 1.7041651048967916

Epoch: 6| Step: 3
Training loss: 0.7120730876922607
Validation loss: 1.649794199133432

Epoch: 6| Step: 4
Training loss: 0.8717472553253174
Validation loss: 1.6799450484655236

Epoch: 6| Step: 5
Training loss: 0.4474683403968811
Validation loss: 1.6776562326697892

Epoch: 6| Step: 6
Training loss: 0.7885423302650452
Validation loss: 1.6082122479715655

Epoch: 6| Step: 7
Training loss: 0.6935613751411438
Validation loss: 1.6979126430326892

Epoch: 6| Step: 8
Training loss: 0.8754665851593018
Validation loss: 1.6560176957038142

Epoch: 6| Step: 9
Training loss: 1.1042749881744385
Validation loss: 1.6479269682720143

Epoch: 6| Step: 10
Training loss: 0.879226565361023
Validation loss: 1.6578713078652658

Epoch: 6| Step: 11
Training loss: 0.6792516708374023
Validation loss: 1.685584396444341

Epoch: 6| Step: 12
Training loss: 1.1880817413330078
Validation loss: 1.6683442784893898

Epoch: 6| Step: 13
Training loss: 0.7020084857940674
Validation loss: 1.6763178238304712

Epoch: 510| Step: 0
Training loss: 0.9453574419021606
Validation loss: 1.6894963941266459

Epoch: 6| Step: 1
Training loss: 0.6277135610580444
Validation loss: 1.672040247148083

Epoch: 6| Step: 2
Training loss: 0.7439897060394287
Validation loss: 1.7143702225018573

Epoch: 6| Step: 3
Training loss: 0.8670629858970642
Validation loss: 1.7403171767470658

Epoch: 6| Step: 4
Training loss: 0.8600571751594543
Validation loss: 1.67845203158676

Epoch: 6| Step: 5
Training loss: 1.20757257938385
Validation loss: 1.6946888508335236

Epoch: 6| Step: 6
Training loss: 0.6529596447944641
Validation loss: 1.72436398331837

Epoch: 6| Step: 7
Training loss: 0.7954748272895813
Validation loss: 1.6967756235471336

Epoch: 6| Step: 8
Training loss: 0.7873797416687012
Validation loss: 1.670658887073558

Epoch: 6| Step: 9
Training loss: 1.3295100927352905
Validation loss: 1.5911282006130423

Epoch: 6| Step: 10
Training loss: 0.7871158123016357
Validation loss: 1.6501592897599744

Epoch: 6| Step: 11
Training loss: 0.7020540237426758
Validation loss: 1.6507649344782676

Epoch: 6| Step: 12
Training loss: 0.6576192378997803
Validation loss: 1.6561236266166932

Epoch: 6| Step: 13
Training loss: 0.9110397696495056
Validation loss: 1.6298281210725025

Epoch: 511| Step: 0
Training loss: 0.7240196466445923
Validation loss: 1.6485363373192408

Epoch: 6| Step: 1
Training loss: 1.1447830200195312
Validation loss: 1.6451969569729221

Epoch: 6| Step: 2
Training loss: 0.7209109663963318
Validation loss: 1.708945248716621

Epoch: 6| Step: 3
Training loss: 1.2857403755187988
Validation loss: 1.7022314956111293

Epoch: 6| Step: 4
Training loss: 0.6363859176635742
Validation loss: 1.6615897455523092

Epoch: 6| Step: 5
Training loss: 0.5052042007446289
Validation loss: 1.6196433216012933

Epoch: 6| Step: 6
Training loss: 0.8292531967163086
Validation loss: 1.6059042016665142

Epoch: 6| Step: 7
Training loss: 1.1709725856781006
Validation loss: 1.6812630186798752

Epoch: 6| Step: 8
Training loss: 0.7822993993759155
Validation loss: 1.7265828091611144

Epoch: 6| Step: 9
Training loss: 0.8366262912750244
Validation loss: 1.6474991344636487

Epoch: 6| Step: 10
Training loss: 0.8010391592979431
Validation loss: 1.630715097150495

Epoch: 6| Step: 11
Training loss: 0.48607414960861206
Validation loss: 1.639260712490287

Epoch: 6| Step: 12
Training loss: 0.7784867286682129
Validation loss: 1.657938039431008

Epoch: 6| Step: 13
Training loss: 1.0120288133621216
Validation loss: 1.6454351076515772

Epoch: 512| Step: 0
Training loss: 0.6960582733154297
Validation loss: 1.6429813382446126

Epoch: 6| Step: 1
Training loss: 1.3371813297271729
Validation loss: 1.6828048203581123

Epoch: 6| Step: 2
Training loss: 1.0179468393325806
Validation loss: 1.6335596205085836

Epoch: 6| Step: 3
Training loss: 0.8774365186691284
Validation loss: 1.6491330541590208

Epoch: 6| Step: 4
Training loss: 0.6622608304023743
Validation loss: 1.5989698863798572

Epoch: 6| Step: 5
Training loss: 1.126143217086792
Validation loss: 1.6078501875682543

Epoch: 6| Step: 6
Training loss: 0.6800417900085449
Validation loss: 1.6810227427431332

Epoch: 6| Step: 7
Training loss: 0.6925621628761292
Validation loss: 1.591804229444073

Epoch: 6| Step: 8
Training loss: 0.3918476104736328
Validation loss: 1.6999597498165664

Epoch: 6| Step: 9
Training loss: 1.0288617610931396
Validation loss: 1.6373672498169767

Epoch: 6| Step: 10
Training loss: 1.0104563236236572
Validation loss: 1.687649860176989

Epoch: 6| Step: 11
Training loss: 0.8430793285369873
Validation loss: 1.6849366939196022

Epoch: 6| Step: 12
Training loss: 0.5102766752243042
Validation loss: 1.6605518992229173

Epoch: 6| Step: 13
Training loss: 0.8864673972129822
Validation loss: 1.6400821837045814

Epoch: 513| Step: 0
Training loss: 0.6877928972244263
Validation loss: 1.6188392619932852

Epoch: 6| Step: 1
Training loss: 0.4132671356201172
Validation loss: 1.684687711859262

Epoch: 6| Step: 2
Training loss: 0.43301039934158325
Validation loss: 1.6874869356873214

Epoch: 6| Step: 3
Training loss: 0.8446813821792603
Validation loss: 1.627588584858884

Epoch: 6| Step: 4
Training loss: 0.5595536828041077
Validation loss: 1.6202837036501976

Epoch: 6| Step: 5
Training loss: 0.7310269474983215
Validation loss: 1.619593176790463

Epoch: 6| Step: 6
Training loss: 1.1074638366699219
Validation loss: 1.6620555949467484

Epoch: 6| Step: 7
Training loss: 0.5639699697494507
Validation loss: 1.6490550310380998

Epoch: 6| Step: 8
Training loss: 0.8975253105163574
Validation loss: 1.649563233057658

Epoch: 6| Step: 9
Training loss: 0.7605400681495667
Validation loss: 1.6599316930258146

Epoch: 6| Step: 10
Training loss: 0.9299389719963074
Validation loss: 1.727906434766708

Epoch: 6| Step: 11
Training loss: 1.189508080482483
Validation loss: 1.648808588263809

Epoch: 6| Step: 12
Training loss: 1.325582504272461
Validation loss: 1.6026431616916452

Epoch: 6| Step: 13
Training loss: 0.7915898561477661
Validation loss: 1.7076650486197522

Epoch: 514| Step: 0
Training loss: 0.5539377331733704
Validation loss: 1.6644770535089637

Epoch: 6| Step: 1
Training loss: 0.4134328365325928
Validation loss: 1.6627278661215177

Epoch: 6| Step: 2
Training loss: 0.7841642498970032
Validation loss: 1.6537702609133977

Epoch: 6| Step: 3
Training loss: 0.7762451171875
Validation loss: 1.6044189699234501

Epoch: 6| Step: 4
Training loss: 1.0822367668151855
Validation loss: 1.673432619340958

Epoch: 6| Step: 5
Training loss: 0.7361465692520142
Validation loss: 1.680406565307289

Epoch: 6| Step: 6
Training loss: 0.9910718202590942
Validation loss: 1.6797030728350404

Epoch: 6| Step: 7
Training loss: 1.1807609796524048
Validation loss: 1.6598760402330788

Epoch: 6| Step: 8
Training loss: 0.7373729944229126
Validation loss: 1.7040771181865404

Epoch: 6| Step: 9
Training loss: 0.8705606460571289
Validation loss: 1.6821456288778653

Epoch: 6| Step: 10
Training loss: 1.2377427816390991
Validation loss: 1.6569246822787869

Epoch: 6| Step: 11
Training loss: 0.9444952011108398
Validation loss: 1.7031592681843748

Epoch: 6| Step: 12
Training loss: 1.1037213802337646
Validation loss: 1.6667768775775869

Epoch: 6| Step: 13
Training loss: 0.47242471575737
Validation loss: 1.6982300384070284

Epoch: 515| Step: 0
Training loss: 0.6450885534286499
Validation loss: 1.6345900643256404

Epoch: 6| Step: 1
Training loss: 0.6909763813018799
Validation loss: 1.661822195976011

Epoch: 6| Step: 2
Training loss: 0.9568911790847778
Validation loss: 1.6455946609538088

Epoch: 6| Step: 3
Training loss: 0.8998968601226807
Validation loss: 1.6594192392082625

Epoch: 6| Step: 4
Training loss: 1.2847576141357422
Validation loss: 1.5670727504196988

Epoch: 6| Step: 5
Training loss: 1.0335369110107422
Validation loss: 1.625443273975003

Epoch: 6| Step: 6
Training loss: 0.5662146806716919
Validation loss: 1.6328877813072615

Epoch: 6| Step: 7
Training loss: 1.080655574798584
Validation loss: 1.628950039545695

Epoch: 6| Step: 8
Training loss: 0.39236879348754883
Validation loss: 1.6669293603589457

Epoch: 6| Step: 9
Training loss: 0.7708430290222168
Validation loss: 1.7314904120660597

Epoch: 6| Step: 10
Training loss: 0.8879531621932983
Validation loss: 1.6802408618311728

Epoch: 6| Step: 11
Training loss: 0.8099449276924133
Validation loss: 1.6778045559442172

Epoch: 6| Step: 12
Training loss: 0.7273112535476685
Validation loss: 1.72140718788229

Epoch: 6| Step: 13
Training loss: 0.6479130983352661
Validation loss: 1.6868756240414036

Epoch: 516| Step: 0
Training loss: 1.2307374477386475
Validation loss: 1.6962450960631013

Epoch: 6| Step: 1
Training loss: 0.9639211893081665
Validation loss: 1.6931162162493634

Epoch: 6| Step: 2
Training loss: 1.067857265472412
Validation loss: 1.6600653561212684

Epoch: 6| Step: 3
Training loss: 0.40056464076042175
Validation loss: 1.6396317187175955

Epoch: 6| Step: 4
Training loss: 1.0776822566986084
Validation loss: 1.6844339063090663

Epoch: 6| Step: 5
Training loss: 0.8252166509628296
Validation loss: 1.6820568833299863

Epoch: 6| Step: 6
Training loss: 1.0016992092132568
Validation loss: 1.6647861106421358

Epoch: 6| Step: 7
Training loss: 0.7895635366439819
Validation loss: 1.7061804456095542

Epoch: 6| Step: 8
Training loss: 0.8021431565284729
Validation loss: 1.6375501258398897

Epoch: 6| Step: 9
Training loss: 0.7329635620117188
Validation loss: 1.6098682277946061

Epoch: 6| Step: 10
Training loss: 0.4819062650203705
Validation loss: 1.6600060014314548

Epoch: 6| Step: 11
Training loss: 0.6569581031799316
Validation loss: 1.6511094288159442

Epoch: 6| Step: 12
Training loss: 0.6741781830787659
Validation loss: 1.7145815228903165

Epoch: 6| Step: 13
Training loss: 0.4818815588951111
Validation loss: 1.6780771068347398

Epoch: 517| Step: 0
Training loss: 0.5537782311439514
Validation loss: 1.609150307152861

Epoch: 6| Step: 1
Training loss: 0.6948181390762329
Validation loss: 1.673149654942174

Epoch: 6| Step: 2
Training loss: 0.5574332475662231
Validation loss: 1.7141535410317041

Epoch: 6| Step: 3
Training loss: 0.8870364427566528
Validation loss: 1.676960837456488

Epoch: 6| Step: 4
Training loss: 0.41639742255210876
Validation loss: 1.615433942887091

Epoch: 6| Step: 5
Training loss: 0.9870256781578064
Validation loss: 1.6311482793541365

Epoch: 6| Step: 6
Training loss: 0.7279173135757446
Validation loss: 1.6467939551158617

Epoch: 6| Step: 7
Training loss: 0.8116611242294312
Validation loss: 1.7264635075805008

Epoch: 6| Step: 8
Training loss: 0.8840299844741821
Validation loss: 1.685442200271032

Epoch: 6| Step: 9
Training loss: 1.5332417488098145
Validation loss: 1.6706291937058972

Epoch: 6| Step: 10
Training loss: 0.9670764803886414
Validation loss: 1.6432412516686223

Epoch: 6| Step: 11
Training loss: 0.680167555809021
Validation loss: 1.6326917909806775

Epoch: 6| Step: 12
Training loss: 1.1730132102966309
Validation loss: 1.6729759170163063

Epoch: 6| Step: 13
Training loss: 0.6204693913459778
Validation loss: 1.6307678466202111

Epoch: 518| Step: 0
Training loss: 1.158083200454712
Validation loss: 1.6181534028822375

Epoch: 6| Step: 1
Training loss: 0.773944616317749
Validation loss: 1.654620780739733

Epoch: 6| Step: 2
Training loss: 0.6479952335357666
Validation loss: 1.6449264275130404

Epoch: 6| Step: 3
Training loss: 0.5727027058601379
Validation loss: 1.671257411279986

Epoch: 6| Step: 4
Training loss: 0.5763211250305176
Validation loss: 1.6447720758376583

Epoch: 6| Step: 5
Training loss: 0.721049964427948
Validation loss: 1.6485325149310532

Epoch: 6| Step: 6
Training loss: 0.9018120169639587
Validation loss: 1.661256605579007

Epoch: 6| Step: 7
Training loss: 0.9057104587554932
Validation loss: 1.6742794693157237

Epoch: 6| Step: 8
Training loss: 1.1061992645263672
Validation loss: 1.6811165681449316

Epoch: 6| Step: 9
Training loss: 1.0118777751922607
Validation loss: 1.7284670017098869

Epoch: 6| Step: 10
Training loss: 0.42205628752708435
Validation loss: 1.6598981759881462

Epoch: 6| Step: 11
Training loss: 1.0613360404968262
Validation loss: 1.6385597772495721

Epoch: 6| Step: 12
Training loss: 0.5607457160949707
Validation loss: 1.6706877331579886

Epoch: 6| Step: 13
Training loss: 1.4863570928573608
Validation loss: 1.7257055313356462

Epoch: 519| Step: 0
Training loss: 0.929314374923706
Validation loss: 1.6761144861098258

Epoch: 6| Step: 1
Training loss: 1.2501977682113647
Validation loss: 1.6669606213928552

Epoch: 6| Step: 2
Training loss: 0.6135566830635071
Validation loss: 1.6725908787019792

Epoch: 6| Step: 3
Training loss: 0.5233114957809448
Validation loss: 1.6848617497310843

Epoch: 6| Step: 4
Training loss: 1.043556809425354
Validation loss: 1.6596417004062283

Epoch: 6| Step: 5
Training loss: 0.7499969601631165
Validation loss: 1.6271285408286638

Epoch: 6| Step: 6
Training loss: 0.8258969783782959
Validation loss: 1.6525023547551965

Epoch: 6| Step: 7
Training loss: 0.7011410593986511
Validation loss: 1.655727901766377

Epoch: 6| Step: 8
Training loss: 1.0123615264892578
Validation loss: 1.7013493096956642

Epoch: 6| Step: 9
Training loss: 0.8209928274154663
Validation loss: 1.6579830954151769

Epoch: 6| Step: 10
Training loss: 0.5710107088088989
Validation loss: 1.6043888612460064

Epoch: 6| Step: 11
Training loss: 1.0650787353515625
Validation loss: 1.6584321401452506

Epoch: 6| Step: 12
Training loss: 0.5777121186256409
Validation loss: 1.722930455720553

Epoch: 6| Step: 13
Training loss: 1.23935866355896
Validation loss: 1.6526712230456773

Epoch: 520| Step: 0
Training loss: 0.66398024559021
Validation loss: 1.636233739955451

Epoch: 6| Step: 1
Training loss: 0.6860840320587158
Validation loss: 1.6763978209546817

Epoch: 6| Step: 2
Training loss: 0.4816148281097412
Validation loss: 1.6820882648550055

Epoch: 6| Step: 3
Training loss: 0.578138530254364
Validation loss: 1.651809287327592

Epoch: 6| Step: 4
Training loss: 0.6812445521354675
Validation loss: 1.6923794656671503

Epoch: 6| Step: 5
Training loss: 0.7101068496704102
Validation loss: 1.6239091222004225

Epoch: 6| Step: 6
Training loss: 0.9516036510467529
Validation loss: 1.6561059592872538

Epoch: 6| Step: 7
Training loss: 1.7645506858825684
Validation loss: 1.6088365047208724

Epoch: 6| Step: 8
Training loss: 0.7097295522689819
Validation loss: 1.6386429289335847

Epoch: 6| Step: 9
Training loss: 0.9376296997070312
Validation loss: 1.6286071603016188

Epoch: 6| Step: 10
Training loss: 0.7835376858711243
Validation loss: 1.6504992079991165

Epoch: 6| Step: 11
Training loss: 0.7376028299331665
Validation loss: 1.6693135333317581

Epoch: 6| Step: 12
Training loss: 0.8647363781929016
Validation loss: 1.6781959258100039

Epoch: 6| Step: 13
Training loss: 1.1352038383483887
Validation loss: 1.6538880871188255

Epoch: 521| Step: 0
Training loss: 0.5947681665420532
Validation loss: 1.586473488038586

Epoch: 6| Step: 1
Training loss: 0.76316237449646
Validation loss: 1.65061665222209

Epoch: 6| Step: 2
Training loss: 1.2763795852661133
Validation loss: 1.6137581909856489

Epoch: 6| Step: 3
Training loss: 0.6184136271476746
Validation loss: 1.6247406031495781

Epoch: 6| Step: 4
Training loss: 0.537233829498291
Validation loss: 1.6582322902576898

Epoch: 6| Step: 5
Training loss: 0.6016570329666138
Validation loss: 1.679619280240869

Epoch: 6| Step: 6
Training loss: 0.587627112865448
Validation loss: 1.664772875847355

Epoch: 6| Step: 7
Training loss: 1.2868306636810303
Validation loss: 1.6309999394160446

Epoch: 6| Step: 8
Training loss: 0.6566600799560547
Validation loss: 1.6852045084840508

Epoch: 6| Step: 9
Training loss: 1.4080382585525513
Validation loss: 1.7174573098459551

Epoch: 6| Step: 10
Training loss: 0.911782443523407
Validation loss: 1.715185816569995

Epoch: 6| Step: 11
Training loss: 0.7107232809066772
Validation loss: 1.671653959058946

Epoch: 6| Step: 12
Training loss: 0.9907649755477905
Validation loss: 1.6484461394689416

Epoch: 6| Step: 13
Training loss: 0.8288285136222839
Validation loss: 1.7192926893952072

Epoch: 522| Step: 0
Training loss: 1.5051348209381104
Validation loss: 1.6809565239055182

Epoch: 6| Step: 1
Training loss: 0.6556713581085205
Validation loss: 1.6442870837385937

Epoch: 6| Step: 2
Training loss: 1.2071706056594849
Validation loss: 1.6407226503536265

Epoch: 6| Step: 3
Training loss: 0.8777002096176147
Validation loss: 1.665759442954935

Epoch: 6| Step: 4
Training loss: 0.34771499037742615
Validation loss: 1.6603791329168505

Epoch: 6| Step: 5
Training loss: 0.7103549242019653
Validation loss: 1.6957163439002088

Epoch: 6| Step: 6
Training loss: 0.8280282616615295
Validation loss: 1.7337548322575067

Epoch: 6| Step: 7
Training loss: 0.6887527108192444
Validation loss: 1.7552056799652755

Epoch: 6| Step: 8
Training loss: 0.8234704732894897
Validation loss: 1.6684120822978277

Epoch: 6| Step: 9
Training loss: 0.9877859950065613
Validation loss: 1.7089903636645245

Epoch: 6| Step: 10
Training loss: 0.8108258247375488
Validation loss: 1.6870256047095022

Epoch: 6| Step: 11
Training loss: 0.8583939075469971
Validation loss: 1.7432135612733903

Epoch: 6| Step: 12
Training loss: 0.4256829023361206
Validation loss: 1.6770372967566214

Epoch: 6| Step: 13
Training loss: 0.6800825595855713
Validation loss: 1.6481516156145322

Epoch: 523| Step: 0
Training loss: 0.7005289196968079
Validation loss: 1.6677256591858403

Epoch: 6| Step: 1
Training loss: 0.8280594348907471
Validation loss: 1.6396314610717118

Epoch: 6| Step: 2
Training loss: 1.134981632232666
Validation loss: 1.6320598048548545

Epoch: 6| Step: 3
Training loss: 0.9466637372970581
Validation loss: 1.6547566613843363

Epoch: 6| Step: 4
Training loss: 0.8477493524551392
Validation loss: 1.6588487176484958

Epoch: 6| Step: 5
Training loss: 0.940388023853302
Validation loss: 1.6495759820425382

Epoch: 6| Step: 6
Training loss: 1.3535659313201904
Validation loss: 1.6657055872742847

Epoch: 6| Step: 7
Training loss: 0.6920270919799805
Validation loss: 1.6402636971524966

Epoch: 6| Step: 8
Training loss: 0.8693976402282715
Validation loss: 1.6830139980521253

Epoch: 6| Step: 9
Training loss: 0.786017656326294
Validation loss: 1.6679745502369379

Epoch: 6| Step: 10
Training loss: 0.8175475597381592
Validation loss: 1.6829575915490427

Epoch: 6| Step: 11
Training loss: 0.6778874397277832
Validation loss: 1.696426559520024

Epoch: 6| Step: 12
Training loss: 0.5397059917449951
Validation loss: 1.6230470826548915

Epoch: 6| Step: 13
Training loss: 0.7744662761688232
Validation loss: 1.6805973463161017

Epoch: 524| Step: 0
Training loss: 0.9073746800422668
Validation loss: 1.6628393011708413

Epoch: 6| Step: 1
Training loss: 0.6172524690628052
Validation loss: 1.644768355995096

Epoch: 6| Step: 2
Training loss: 0.940753698348999
Validation loss: 1.6354624327792917

Epoch: 6| Step: 3
Training loss: 0.6905630230903625
Validation loss: 1.630794584110219

Epoch: 6| Step: 4
Training loss: 0.601912260055542
Validation loss: 1.69581994318193

Epoch: 6| Step: 5
Training loss: 0.5153246521949768
Validation loss: 1.6717115294548772

Epoch: 6| Step: 6
Training loss: 0.7692867517471313
Validation loss: 1.6238972935625302

Epoch: 6| Step: 7
Training loss: 0.9880717992782593
Validation loss: 1.6103051734227005

Epoch: 6| Step: 8
Training loss: 0.6998448371887207
Validation loss: 1.6342539274564354

Epoch: 6| Step: 9
Training loss: 1.22950279712677
Validation loss: 1.6727824864848968

Epoch: 6| Step: 10
Training loss: 0.49639880657196045
Validation loss: 1.6927768286838327

Epoch: 6| Step: 11
Training loss: 0.6207376718521118
Validation loss: 1.6537967317847795

Epoch: 6| Step: 12
Training loss: 0.8576920032501221
Validation loss: 1.6191867269495481

Epoch: 6| Step: 13
Training loss: 1.1391546726226807
Validation loss: 1.678164723098919

Epoch: 525| Step: 0
Training loss: 1.0220866203308105
Validation loss: 1.693289392737932

Epoch: 6| Step: 1
Training loss: 0.38379237055778503
Validation loss: 1.68673833083081

Epoch: 6| Step: 2
Training loss: 1.0896446704864502
Validation loss: 1.7003189145877797

Epoch: 6| Step: 3
Training loss: 0.635047972202301
Validation loss: 1.6199369045995897

Epoch: 6| Step: 4
Training loss: 0.9619816541671753
Validation loss: 1.7135963927033127

Epoch: 6| Step: 5
Training loss: 1.1488564014434814
Validation loss: 1.6957132149768133

Epoch: 6| Step: 6
Training loss: 0.6936038732528687
Validation loss: 1.690357603052611

Epoch: 6| Step: 7
Training loss: 0.7522542476654053
Validation loss: 1.6111268561373475

Epoch: 6| Step: 8
Training loss: 1.0975450277328491
Validation loss: 1.7058280334677747

Epoch: 6| Step: 9
Training loss: 0.6984489560127258
Validation loss: 1.6529499843556394

Epoch: 6| Step: 10
Training loss: 0.620770275592804
Validation loss: 1.6372269520195581

Epoch: 6| Step: 11
Training loss: 0.45588356256484985
Validation loss: 1.6496774842662196

Epoch: 6| Step: 12
Training loss: 0.6645652055740356
Validation loss: 1.6379411361550773

Epoch: 6| Step: 13
Training loss: 1.2367112636566162
Validation loss: 1.5923111143932547

Epoch: 526| Step: 0
Training loss: 0.8283610343933105
Validation loss: 1.600810948238578

Epoch: 6| Step: 1
Training loss: 0.878294825553894
Validation loss: 1.7038852348122546

Epoch: 6| Step: 2
Training loss: 0.48702752590179443
Validation loss: 1.6612829533956384

Epoch: 6| Step: 3
Training loss: 0.40355101227760315
Validation loss: 1.642616492445751

Epoch: 6| Step: 4
Training loss: 1.0356502532958984
Validation loss: 1.6502996901030182

Epoch: 6| Step: 5
Training loss: 0.8895823955535889
Validation loss: 1.633330398990262

Epoch: 6| Step: 6
Training loss: 0.9833645820617676
Validation loss: 1.6866803797342445

Epoch: 6| Step: 7
Training loss: 0.899935245513916
Validation loss: 1.6199443096755652

Epoch: 6| Step: 8
Training loss: 1.146099328994751
Validation loss: 1.663639663368143

Epoch: 6| Step: 9
Training loss: 0.5099582672119141
Validation loss: 1.6306839296894688

Epoch: 6| Step: 10
Training loss: 0.838355541229248
Validation loss: 1.6740051059312717

Epoch: 6| Step: 11
Training loss: 0.5921029448509216
Validation loss: 1.6287348603689542

Epoch: 6| Step: 12
Training loss: 0.8618556261062622
Validation loss: 1.6096325792292112

Epoch: 6| Step: 13
Training loss: 1.2180190086364746
Validation loss: 1.5958984385254562

Epoch: 527| Step: 0
Training loss: 1.0996270179748535
Validation loss: 1.6948930114828131

Epoch: 6| Step: 1
Training loss: 0.9942904710769653
Validation loss: 1.6305434062916746

Epoch: 6| Step: 2
Training loss: 0.570060133934021
Validation loss: 1.5756074356776413

Epoch: 6| Step: 3
Training loss: 1.1955463886260986
Validation loss: 1.5939631744097638

Epoch: 6| Step: 4
Training loss: 0.5955438613891602
Validation loss: 1.6060348851706392

Epoch: 6| Step: 5
Training loss: 0.8013198971748352
Validation loss: 1.6455477001846477

Epoch: 6| Step: 6
Training loss: 0.862330436706543
Validation loss: 1.6389565249925018

Epoch: 6| Step: 7
Training loss: 0.7467311024665833
Validation loss: 1.6760109598918627

Epoch: 6| Step: 8
Training loss: 0.7207761406898499
Validation loss: 1.6813579336289437

Epoch: 6| Step: 9
Training loss: 1.2282030582427979
Validation loss: 1.6713925676961099

Epoch: 6| Step: 10
Training loss: 0.6674284338951111
Validation loss: 1.719512704880007

Epoch: 6| Step: 11
Training loss: 0.7417508959770203
Validation loss: 1.6747587329597884

Epoch: 6| Step: 12
Training loss: 0.5621685981750488
Validation loss: 1.6661841728354012

Epoch: 6| Step: 13
Training loss: 0.4236820936203003
Validation loss: 1.63890927837741

Epoch: 528| Step: 0
Training loss: 0.7806499004364014
Validation loss: 1.619154514804963

Epoch: 6| Step: 1
Training loss: 0.9189676642417908
Validation loss: 1.6351316052098428

Epoch: 6| Step: 2
Training loss: 0.8116335272789001
Validation loss: 1.6738165540079917

Epoch: 6| Step: 3
Training loss: 0.9073657989501953
Validation loss: 1.6913959800556142

Epoch: 6| Step: 4
Training loss: 0.4598281979560852
Validation loss: 1.687812860294055

Epoch: 6| Step: 5
Training loss: 0.8236311674118042
Validation loss: 1.6723751227060955

Epoch: 6| Step: 6
Training loss: 1.1083883047103882
Validation loss: 1.664430308085616

Epoch: 6| Step: 7
Training loss: 1.0254595279693604
Validation loss: 1.6228096254410282

Epoch: 6| Step: 8
Training loss: 0.6004103422164917
Validation loss: 1.6340970787950742

Epoch: 6| Step: 9
Training loss: 0.7554375529289246
Validation loss: 1.6773818667216966

Epoch: 6| Step: 10
Training loss: 0.9212894439697266
Validation loss: 1.661536951218882

Epoch: 6| Step: 11
Training loss: 0.533196747303009
Validation loss: 1.665774413334426

Epoch: 6| Step: 12
Training loss: 0.8885159492492676
Validation loss: 1.6908040597874632

Epoch: 6| Step: 13
Training loss: 0.8547171354293823
Validation loss: 1.684268633524577

Epoch: 529| Step: 0
Training loss: 0.8516479730606079
Validation loss: 1.7098459377083728

Epoch: 6| Step: 1
Training loss: 0.6527841687202454
Validation loss: 1.6727490476382676

Epoch: 6| Step: 2
Training loss: 0.9183462858200073
Validation loss: 1.6880966027577717

Epoch: 6| Step: 3
Training loss: 1.2475143671035767
Validation loss: 1.695609587495045

Epoch: 6| Step: 4
Training loss: 0.7745749950408936
Validation loss: 1.6463064967945058

Epoch: 6| Step: 5
Training loss: 0.9820755124092102
Validation loss: 1.636860450108846

Epoch: 6| Step: 6
Training loss: 0.6287776231765747
Validation loss: 1.6514672951031757

Epoch: 6| Step: 7
Training loss: 0.5950313806533813
Validation loss: 1.6683056162249656

Epoch: 6| Step: 8
Training loss: 1.1566342115402222
Validation loss: 1.7103402755593742

Epoch: 6| Step: 9
Training loss: 0.76674485206604
Validation loss: 1.6335760278086509

Epoch: 6| Step: 10
Training loss: 0.6991082429885864
Validation loss: 1.6938497289534538

Epoch: 6| Step: 11
Training loss: 0.47533750534057617
Validation loss: 1.6013112119449082

Epoch: 6| Step: 12
Training loss: 0.8685444593429565
Validation loss: 1.6110406011663458

Epoch: 6| Step: 13
Training loss: 0.6757059097290039
Validation loss: 1.6050061269473004

Epoch: 530| Step: 0
Training loss: 0.6110151410102844
Validation loss: 1.6980025858007453

Epoch: 6| Step: 1
Training loss: 0.7439812421798706
Validation loss: 1.6282455068762585

Epoch: 6| Step: 2
Training loss: 0.6219955682754517
Validation loss: 1.6265008731554913

Epoch: 6| Step: 3
Training loss: 1.1843345165252686
Validation loss: 1.6474587763509443

Epoch: 6| Step: 4
Training loss: 0.503936767578125
Validation loss: 1.6292418779865387

Epoch: 6| Step: 5
Training loss: 0.5703195333480835
Validation loss: 1.6716145418023551

Epoch: 6| Step: 6
Training loss: 0.8800303936004639
Validation loss: 1.6143412872027325

Epoch: 6| Step: 7
Training loss: 0.8532962203025818
Validation loss: 1.646284980158652

Epoch: 6| Step: 8
Training loss: 0.945294201374054
Validation loss: 1.6148072641382936

Epoch: 6| Step: 9
Training loss: 1.1388418674468994
Validation loss: 1.676505652807092

Epoch: 6| Step: 10
Training loss: 0.8750771880149841
Validation loss: 1.638590734492066

Epoch: 6| Step: 11
Training loss: 0.7208221554756165
Validation loss: 1.6343275090699554

Epoch: 6| Step: 12
Training loss: 0.624787449836731
Validation loss: 1.6201272856804632

Epoch: 6| Step: 13
Training loss: 0.9517879486083984
Validation loss: 1.7105826729087419

Epoch: 531| Step: 0
Training loss: 0.5924950838088989
Validation loss: 1.6688518293442265

Epoch: 6| Step: 1
Training loss: 0.9194132089614868
Validation loss: 1.6519144529937415

Epoch: 6| Step: 2
Training loss: 0.6766986846923828
Validation loss: 1.65736650395137

Epoch: 6| Step: 3
Training loss: 0.6967308521270752
Validation loss: 1.677225725625151

Epoch: 6| Step: 4
Training loss: 0.6527900099754333
Validation loss: 1.6582106556943668

Epoch: 6| Step: 5
Training loss: 1.0830190181732178
Validation loss: 1.65714979428117

Epoch: 6| Step: 6
Training loss: 0.5938416123390198
Validation loss: 1.6478408228966497

Epoch: 6| Step: 7
Training loss: 1.1956889629364014
Validation loss: 1.6269315647822555

Epoch: 6| Step: 8
Training loss: 0.6057469248771667
Validation loss: 1.6111084568885066

Epoch: 6| Step: 9
Training loss: 0.7050679326057434
Validation loss: 1.6637343937350857

Epoch: 6| Step: 10
Training loss: 1.0801451206207275
Validation loss: 1.630522443402198

Epoch: 6| Step: 11
Training loss: 0.7977268695831299
Validation loss: 1.6569352995964788

Epoch: 6| Step: 12
Training loss: 0.7379647493362427
Validation loss: 1.7715334994818575

Epoch: 6| Step: 13
Training loss: 0.9143962860107422
Validation loss: 1.7094430410733787

Epoch: 532| Step: 0
Training loss: 0.5570355653762817
Validation loss: 1.6919904498643772

Epoch: 6| Step: 1
Training loss: 0.7503551244735718
Validation loss: 1.662070562762599

Epoch: 6| Step: 2
Training loss: 0.6291901469230652
Validation loss: 1.6284707028378722

Epoch: 6| Step: 3
Training loss: 0.5694630742073059
Validation loss: 1.6574212248607347

Epoch: 6| Step: 4
Training loss: 0.6993200778961182
Validation loss: 1.5543628328589982

Epoch: 6| Step: 5
Training loss: 0.7259325385093689
Validation loss: 1.5993344540237098

Epoch: 6| Step: 6
Training loss: 0.7112373113632202
Validation loss: 1.6060190393078713

Epoch: 6| Step: 7
Training loss: 1.1360210180282593
Validation loss: 1.6862803287403558

Epoch: 6| Step: 8
Training loss: 0.8707395195960999
Validation loss: 1.6683635032305153

Epoch: 6| Step: 9
Training loss: 1.1283504962921143
Validation loss: 1.623380434128546

Epoch: 6| Step: 10
Training loss: 0.8065005540847778
Validation loss: 1.676793485559443

Epoch: 6| Step: 11
Training loss: 0.5574636459350586
Validation loss: 1.6380939675915627

Epoch: 6| Step: 12
Training loss: 1.3027327060699463
Validation loss: 1.6401932149805047

Epoch: 6| Step: 13
Training loss: 0.9371776580810547
Validation loss: 1.669019071004724

Epoch: 533| Step: 0
Training loss: 0.9329904913902283
Validation loss: 1.7023249582577777

Epoch: 6| Step: 1
Training loss: 0.810166597366333
Validation loss: 1.6622696025397188

Epoch: 6| Step: 2
Training loss: 0.8873898386955261
Validation loss: 1.609491773830947

Epoch: 6| Step: 3
Training loss: 0.40454086661338806
Validation loss: 1.6665083977483934

Epoch: 6| Step: 4
Training loss: 0.7427998781204224
Validation loss: 1.6615474006181121

Epoch: 6| Step: 5
Training loss: 0.4816760718822479
Validation loss: 1.7176852636439826

Epoch: 6| Step: 6
Training loss: 0.7287517786026001
Validation loss: 1.6344236520028883

Epoch: 6| Step: 7
Training loss: 1.1638422012329102
Validation loss: 1.6058456878508292

Epoch: 6| Step: 8
Training loss: 0.6601189374923706
Validation loss: 1.6390523192703084

Epoch: 6| Step: 9
Training loss: 0.8892532587051392
Validation loss: 1.6386122690734042

Epoch: 6| Step: 10
Training loss: 1.3149123191833496
Validation loss: 1.6352018720360213

Epoch: 6| Step: 11
Training loss: 0.7158829569816589
Validation loss: 1.6784950302493187

Epoch: 6| Step: 12
Training loss: 1.263314127922058
Validation loss: 1.6352712377425163

Epoch: 6| Step: 13
Training loss: 0.28819432854652405
Validation loss: 1.58223960861083

Epoch: 534| Step: 0
Training loss: 0.8955254554748535
Validation loss: 1.6406739065724034

Epoch: 6| Step: 1
Training loss: 0.7912678718566895
Validation loss: 1.657381119266633

Epoch: 6| Step: 2
Training loss: 0.8372319340705872
Validation loss: 1.6379329722414735

Epoch: 6| Step: 3
Training loss: 1.0479576587677002
Validation loss: 1.6354887985414075

Epoch: 6| Step: 4
Training loss: 0.8782325983047485
Validation loss: 1.6517405330493886

Epoch: 6| Step: 5
Training loss: 0.5359178781509399
Validation loss: 1.6673550810865176

Epoch: 6| Step: 6
Training loss: 1.1836159229278564
Validation loss: 1.6942865592177196

Epoch: 6| Step: 7
Training loss: 0.6494345664978027
Validation loss: 1.717913080287236

Epoch: 6| Step: 8
Training loss: 0.6160730719566345
Validation loss: 1.7314927424153974

Epoch: 6| Step: 9
Training loss: 0.9517015218734741
Validation loss: 1.6888514846883795

Epoch: 6| Step: 10
Training loss: 0.6793416738510132
Validation loss: 1.689429190851027

Epoch: 6| Step: 11
Training loss: 0.65622478723526
Validation loss: 1.6481053495919833

Epoch: 6| Step: 12
Training loss: 0.8255373239517212
Validation loss: 1.6276701791312105

Epoch: 6| Step: 13
Training loss: 0.3976888358592987
Validation loss: 1.7030694074528192

Epoch: 535| Step: 0
Training loss: 0.6775127649307251
Validation loss: 1.7201842928445468

Epoch: 6| Step: 1
Training loss: 0.6286838054656982
Validation loss: 1.6217178003762358

Epoch: 6| Step: 2
Training loss: 0.7543988227844238
Validation loss: 1.6376087639921455

Epoch: 6| Step: 3
Training loss: 0.5620652437210083
Validation loss: 1.6619851025201942

Epoch: 6| Step: 4
Training loss: 1.1000157594680786
Validation loss: 1.6392663268632786

Epoch: 6| Step: 5
Training loss: 0.8926298022270203
Validation loss: 1.652734676996867

Epoch: 6| Step: 6
Training loss: 0.9280973672866821
Validation loss: 1.6473795329370806

Epoch: 6| Step: 7
Training loss: 0.41930145025253296
Validation loss: 1.700334177222303

Epoch: 6| Step: 8
Training loss: 1.0209603309631348
Validation loss: 1.6789553908891575

Epoch: 6| Step: 9
Training loss: 0.46915456652641296
Validation loss: 1.6805256412875267

Epoch: 6| Step: 10
Training loss: 0.7442086935043335
Validation loss: 1.7321883991200437

Epoch: 6| Step: 11
Training loss: 0.8566100597381592
Validation loss: 1.7067520233892626

Epoch: 6| Step: 12
Training loss: 1.3068625926971436
Validation loss: 1.6008077641969085

Epoch: 6| Step: 13
Training loss: 0.9998608827590942
Validation loss: 1.6092649377802366

Epoch: 536| Step: 0
Training loss: 0.6074523329734802
Validation loss: 1.6804082252646004

Epoch: 6| Step: 1
Training loss: 0.4780557155609131
Validation loss: 1.6310978410064534

Epoch: 6| Step: 2
Training loss: 0.5182785987854004
Validation loss: 1.6944142208304456

Epoch: 6| Step: 3
Training loss: 0.6456626653671265
Validation loss: 1.7136182515851912

Epoch: 6| Step: 4
Training loss: 0.7780213952064514
Validation loss: 1.6980730897636824

Epoch: 6| Step: 5
Training loss: 0.8631938695907593
Validation loss: 1.6845606488566245

Epoch: 6| Step: 6
Training loss: 1.2572351694107056
Validation loss: 1.6591379040031022

Epoch: 6| Step: 7
Training loss: 0.8930407762527466
Validation loss: 1.6328863469503259

Epoch: 6| Step: 8
Training loss: 1.0458346605300903
Validation loss: 1.6613004758793821

Epoch: 6| Step: 9
Training loss: 0.6101245284080505
Validation loss: 1.66636186774059

Epoch: 6| Step: 10
Training loss: 1.019728660583496
Validation loss: 1.6781702772263558

Epoch: 6| Step: 11
Training loss: 1.1508804559707642
Validation loss: 1.6592439804025876

Epoch: 6| Step: 12
Training loss: 0.8371129631996155
Validation loss: 1.6665874001800374

Epoch: 6| Step: 13
Training loss: 0.6872699856758118
Validation loss: 1.6477769472265755

Epoch: 537| Step: 0
Training loss: 1.0756664276123047
Validation loss: 1.5799720492414249

Epoch: 6| Step: 1
Training loss: 0.819585919380188
Validation loss: 1.6246447588807793

Epoch: 6| Step: 2
Training loss: 0.7052274942398071
Validation loss: 1.6042190854267409

Epoch: 6| Step: 3
Training loss: 0.6724358797073364
Validation loss: 1.6456819900902369

Epoch: 6| Step: 4
Training loss: 0.9330776929855347
Validation loss: 1.632337381762843

Epoch: 6| Step: 5
Training loss: 0.8635400533676147
Validation loss: 1.6403874210132066

Epoch: 6| Step: 6
Training loss: 0.5412746667861938
Validation loss: 1.6119338876457625

Epoch: 6| Step: 7
Training loss: 0.6711065173149109
Validation loss: 1.6490962338703934

Epoch: 6| Step: 8
Training loss: 0.8078249096870422
Validation loss: 1.6534361993112872

Epoch: 6| Step: 9
Training loss: 0.6974074840545654
Validation loss: 1.613824091931825

Epoch: 6| Step: 10
Training loss: 0.6300268173217773
Validation loss: 1.7058308034814813

Epoch: 6| Step: 11
Training loss: 0.9932653903961182
Validation loss: 1.6580215974520611

Epoch: 6| Step: 12
Training loss: 0.6731678247451782
Validation loss: 1.6521846684076453

Epoch: 6| Step: 13
Training loss: 1.0546317100524902
Validation loss: 1.6298638466865785

Epoch: 538| Step: 0
Training loss: 0.9883655905723572
Validation loss: 1.6434775424259964

Epoch: 6| Step: 1
Training loss: 0.5068690180778503
Validation loss: 1.6088095416304886

Epoch: 6| Step: 2
Training loss: 0.9843844175338745
Validation loss: 1.67473235694311

Epoch: 6| Step: 3
Training loss: 0.9813269972801208
Validation loss: 1.6340944895180323

Epoch: 6| Step: 4
Training loss: 0.7303192019462585
Validation loss: 1.6290941533221994

Epoch: 6| Step: 5
Training loss: 0.6777055859565735
Validation loss: 1.6430754123195526

Epoch: 6| Step: 6
Training loss: 0.8738827705383301
Validation loss: 1.598117136186169

Epoch: 6| Step: 7
Training loss: 1.1534104347229004
Validation loss: 1.6557640555084392

Epoch: 6| Step: 8
Training loss: 0.7608602046966553
Validation loss: 1.6774875367841413

Epoch: 6| Step: 9
Training loss: 0.6365472078323364
Validation loss: 1.6326114490468016

Epoch: 6| Step: 10
Training loss: 0.5445067882537842
Validation loss: 1.6360135206612207

Epoch: 6| Step: 11
Training loss: 0.45561981201171875
Validation loss: 1.646463499274305

Epoch: 6| Step: 12
Training loss: 0.5880119204521179
Validation loss: 1.6261781543813727

Epoch: 6| Step: 13
Training loss: 0.9311690926551819
Validation loss: 1.6254890541876517

Epoch: 539| Step: 0
Training loss: 0.6648839712142944
Validation loss: 1.645512678289926

Epoch: 6| Step: 1
Training loss: 1.604351282119751
Validation loss: 1.6281358529162664

Epoch: 6| Step: 2
Training loss: 0.6909056305885315
Validation loss: 1.710272390355346

Epoch: 6| Step: 3
Training loss: 0.8611592054367065
Validation loss: 1.672073923131471

Epoch: 6| Step: 4
Training loss: 0.6673426628112793
Validation loss: 1.7097198347891531

Epoch: 6| Step: 5
Training loss: 0.5741938948631287
Validation loss: 1.7118429086541618

Epoch: 6| Step: 6
Training loss: 1.0431792736053467
Validation loss: 1.7249112847030803

Epoch: 6| Step: 7
Training loss: 0.7815746665000916
Validation loss: 1.7228855343275173

Epoch: 6| Step: 8
Training loss: 0.6516164541244507
Validation loss: 1.6751813324548865

Epoch: 6| Step: 9
Training loss: 0.8129714727401733
Validation loss: 1.6557157155006164

Epoch: 6| Step: 10
Training loss: 0.7029639482498169
Validation loss: 1.6656986808264127

Epoch: 6| Step: 11
Training loss: 0.5491871237754822
Validation loss: 1.6453035800687728

Epoch: 6| Step: 12
Training loss: 0.6736583113670349
Validation loss: 1.61202068995404

Epoch: 6| Step: 13
Training loss: 0.7175758481025696
Validation loss: 1.6249219986700243

Epoch: 540| Step: 0
Training loss: 0.8489189743995667
Validation loss: 1.6316360594123922

Epoch: 6| Step: 1
Training loss: 0.929751992225647
Validation loss: 1.6999728846293625

Epoch: 6| Step: 2
Training loss: 0.8534047603607178
Validation loss: 1.6747805610779793

Epoch: 6| Step: 3
Training loss: 0.3649224042892456
Validation loss: 1.6692058450432234

Epoch: 6| Step: 4
Training loss: 1.2960190773010254
Validation loss: 1.5901234252478487

Epoch: 6| Step: 5
Training loss: 0.7954950928688049
Validation loss: 1.6412494477405344

Epoch: 6| Step: 6
Training loss: 0.7813299894332886
Validation loss: 1.671256462732951

Epoch: 6| Step: 7
Training loss: 0.6286660432815552
Validation loss: 1.6766034390336724

Epoch: 6| Step: 8
Training loss: 0.6271153688430786
Validation loss: 1.6516150992403749

Epoch: 6| Step: 9
Training loss: 0.617364764213562
Validation loss: 1.6496229107661913

Epoch: 6| Step: 10
Training loss: 0.5570305585861206
Validation loss: 1.6484987748566495

Epoch: 6| Step: 11
Training loss: 1.4048653841018677
Validation loss: 1.6533275560666156

Epoch: 6| Step: 12
Training loss: 0.7641924023628235
Validation loss: 1.6946305972273632

Epoch: 6| Step: 13
Training loss: 0.3590156137943268
Validation loss: 1.62956137939166

Epoch: 541| Step: 0
Training loss: 0.9768968224525452
Validation loss: 1.6523149705702258

Epoch: 6| Step: 1
Training loss: 0.6936867833137512
Validation loss: 1.6550592760885916

Epoch: 6| Step: 2
Training loss: 0.8447083234786987
Validation loss: 1.6281442898575977

Epoch: 6| Step: 3
Training loss: 0.5646882653236389
Validation loss: 1.6032891850317679

Epoch: 6| Step: 4
Training loss: 0.8779550790786743
Validation loss: 1.601659042860872

Epoch: 6| Step: 5
Training loss: 0.6125546097755432
Validation loss: 1.555990437025665

Epoch: 6| Step: 6
Training loss: 0.7091959118843079
Validation loss: 1.6494028132448915

Epoch: 6| Step: 7
Training loss: 0.6488177180290222
Validation loss: 1.632433875914543

Epoch: 6| Step: 8
Training loss: 0.8293455839157104
Validation loss: 1.644294035050177

Epoch: 6| Step: 9
Training loss: 1.1734287738800049
Validation loss: 1.6343759952052948

Epoch: 6| Step: 10
Training loss: 0.8189903497695923
Validation loss: 1.5854387001324726

Epoch: 6| Step: 11
Training loss: 1.1492490768432617
Validation loss: 1.6350983983726912

Epoch: 6| Step: 12
Training loss: 0.622986912727356
Validation loss: 1.716958612524053

Epoch: 6| Step: 13
Training loss: 0.757576584815979
Validation loss: 1.650246961142427

Epoch: 542| Step: 0
Training loss: 0.8673503994941711
Validation loss: 1.6647972611970798

Epoch: 6| Step: 1
Training loss: 0.7130961418151855
Validation loss: 1.6620673505208825

Epoch: 6| Step: 2
Training loss: 0.7741385698318481
Validation loss: 1.6577963893131544

Epoch: 6| Step: 3
Training loss: 1.3910976648330688
Validation loss: 1.6914244569757932

Epoch: 6| Step: 4
Training loss: 0.5824228525161743
Validation loss: 1.6754647608726256

Epoch: 6| Step: 5
Training loss: 0.768198549747467
Validation loss: 1.6560859731448594

Epoch: 6| Step: 6
Training loss: 0.42400282621383667
Validation loss: 1.6176724100625643

Epoch: 6| Step: 7
Training loss: 0.6208610534667969
Validation loss: 1.5847285332218293

Epoch: 6| Step: 8
Training loss: 0.6263285875320435
Validation loss: 1.6423621587855841

Epoch: 6| Step: 9
Training loss: 0.5663149952888489
Validation loss: 1.6024817253953667

Epoch: 6| Step: 10
Training loss: 1.1484754085540771
Validation loss: 1.6136583538465603

Epoch: 6| Step: 11
Training loss: 0.9347527623176575
Validation loss: 1.5777873813465078

Epoch: 6| Step: 12
Training loss: 0.8278350234031677
Validation loss: 1.6167249820565666

Epoch: 6| Step: 13
Training loss: 1.2464646100997925
Validation loss: 1.5972421528190694

Epoch: 543| Step: 0
Training loss: 0.8993226289749146
Validation loss: 1.6799326224993634

Epoch: 6| Step: 1
Training loss: 0.7429083585739136
Validation loss: 1.6390297284690283

Epoch: 6| Step: 2
Training loss: 1.467437505722046
Validation loss: 1.6707859257216096

Epoch: 6| Step: 3
Training loss: 0.7671095132827759
Validation loss: 1.6216514713020735

Epoch: 6| Step: 4
Training loss: 0.5823343396186829
Validation loss: 1.6446065031072146

Epoch: 6| Step: 5
Training loss: 0.7133437395095825
Validation loss: 1.6591987943136564

Epoch: 6| Step: 6
Training loss: 0.822685718536377
Validation loss: 1.597489526194911

Epoch: 6| Step: 7
Training loss: 0.34332776069641113
Validation loss: 1.6491324158125027

Epoch: 6| Step: 8
Training loss: 0.8813016414642334
Validation loss: 1.7069425070157616

Epoch: 6| Step: 9
Training loss: 0.5538307428359985
Validation loss: 1.647161535037461

Epoch: 6| Step: 10
Training loss: 0.5547142028808594
Validation loss: 1.650164295268315

Epoch: 6| Step: 11
Training loss: 0.5136961936950684
Validation loss: 1.6316488737701087

Epoch: 6| Step: 12
Training loss: 0.4291256070137024
Validation loss: 1.6175186864791378

Epoch: 6| Step: 13
Training loss: 0.7532132267951965
Validation loss: 1.5996690155357443

Epoch: 544| Step: 0
Training loss: 0.7331947088241577
Validation loss: 1.634376481015195

Epoch: 6| Step: 1
Training loss: 0.6419042348861694
Validation loss: 1.6893416976415983

Epoch: 6| Step: 2
Training loss: 0.7312769889831543
Validation loss: 1.6111516567968553

Epoch: 6| Step: 3
Training loss: 0.5733575224876404
Validation loss: 1.663338215120377

Epoch: 6| Step: 4
Training loss: 0.7653409242630005
Validation loss: 1.6357274491299865

Epoch: 6| Step: 5
Training loss: 1.01279616355896
Validation loss: 1.665381621288997

Epoch: 6| Step: 6
Training loss: 1.0932602882385254
Validation loss: 1.6078317479420734

Epoch: 6| Step: 7
Training loss: 0.597966730594635
Validation loss: 1.6397024841718777

Epoch: 6| Step: 8
Training loss: 0.7837196588516235
Validation loss: 1.648447322589095

Epoch: 6| Step: 9
Training loss: 0.5582669973373413
Validation loss: 1.6415244456260436

Epoch: 6| Step: 10
Training loss: 0.8980722427368164
Validation loss: 1.658965955498398

Epoch: 6| Step: 11
Training loss: 0.7588516473770142
Validation loss: 1.6256714277370001

Epoch: 6| Step: 12
Training loss: 0.6334033608436584
Validation loss: 1.6376946395443333

Epoch: 6| Step: 13
Training loss: 1.1145397424697876
Validation loss: 1.669931528388813

Epoch: 545| Step: 0
Training loss: 0.8887348175048828
Validation loss: 1.6536520860528434

Epoch: 6| Step: 1
Training loss: 0.8673790693283081
Validation loss: 1.5999050294199297

Epoch: 6| Step: 2
Training loss: 0.8164699077606201
Validation loss: 1.639232434252257

Epoch: 6| Step: 3
Training loss: 0.722183108329773
Validation loss: 1.675572108196956

Epoch: 6| Step: 4
Training loss: 0.7811923623085022
Validation loss: 1.620244954221992

Epoch: 6| Step: 5
Training loss: 0.7602213621139526
Validation loss: 1.634874241326445

Epoch: 6| Step: 6
Training loss: 0.7479188442230225
Validation loss: 1.6911225536818146

Epoch: 6| Step: 7
Training loss: 0.7650095224380493
Validation loss: 1.5934540046158658

Epoch: 6| Step: 8
Training loss: 0.6331487894058228
Validation loss: 1.6142699897930186

Epoch: 6| Step: 9
Training loss: 0.948885977268219
Validation loss: 1.6140106429335892

Epoch: 6| Step: 10
Training loss: 0.5387635231018066
Validation loss: 1.6476385619050713

Epoch: 6| Step: 11
Training loss: 0.7490109205245972
Validation loss: 1.5989005924553

Epoch: 6| Step: 12
Training loss: 0.9769361019134521
Validation loss: 1.6116357195761897

Epoch: 6| Step: 13
Training loss: 0.63668292760849
Validation loss: 1.6988956620616298

Epoch: 546| Step: 0
Training loss: 0.6884610056877136
Validation loss: 1.6653772925817838

Epoch: 6| Step: 1
Training loss: 0.6790691614151001
Validation loss: 1.6008783514781664

Epoch: 6| Step: 2
Training loss: 0.6669739484786987
Validation loss: 1.7114558937729045

Epoch: 6| Step: 3
Training loss: 0.874968409538269
Validation loss: 1.629111281005285

Epoch: 6| Step: 4
Training loss: 0.331790030002594
Validation loss: 1.6454761092380812

Epoch: 6| Step: 5
Training loss: 0.9873981475830078
Validation loss: 1.6242793452355169

Epoch: 6| Step: 6
Training loss: 0.6502112150192261
Validation loss: 1.6280536318338046

Epoch: 6| Step: 7
Training loss: 0.9517783522605896
Validation loss: 1.5948385589866227

Epoch: 6| Step: 8
Training loss: 0.5022391676902771
Validation loss: 1.6290736788062639

Epoch: 6| Step: 9
Training loss: 1.0919544696807861
Validation loss: 1.6067582266305083

Epoch: 6| Step: 10
Training loss: 0.454355925321579
Validation loss: 1.6783993026261688

Epoch: 6| Step: 11
Training loss: 0.8297327160835266
Validation loss: 1.6409729706343783

Epoch: 6| Step: 12
Training loss: 1.5481698513031006
Validation loss: 1.6285776066523727

Epoch: 6| Step: 13
Training loss: 0.834402859210968
Validation loss: 1.6480278930356425

Epoch: 547| Step: 0
Training loss: 0.9243643283843994
Validation loss: 1.6064911683400471

Epoch: 6| Step: 1
Training loss: 0.6893879175186157
Validation loss: 1.6567234339252594

Epoch: 6| Step: 2
Training loss: 0.840508759021759
Validation loss: 1.641713438495513

Epoch: 6| Step: 3
Training loss: 0.5608882904052734
Validation loss: 1.6358195838107858

Epoch: 6| Step: 4
Training loss: 0.9082179069519043
Validation loss: 1.6796143535644776

Epoch: 6| Step: 5
Training loss: 0.6921241879463196
Validation loss: 1.6887685919320712

Epoch: 6| Step: 6
Training loss: 1.2116245031356812
Validation loss: 1.5991333517976987

Epoch: 6| Step: 7
Training loss: 0.4651658535003662
Validation loss: 1.6479476164746028

Epoch: 6| Step: 8
Training loss: 0.9463240504264832
Validation loss: 1.65742669182439

Epoch: 6| Step: 9
Training loss: 0.5740931034088135
Validation loss: 1.6810584914299749

Epoch: 6| Step: 10
Training loss: 0.8087260723114014
Validation loss: 1.6226077413046232

Epoch: 6| Step: 11
Training loss: 0.8406631350517273
Validation loss: 1.687115059104017

Epoch: 6| Step: 12
Training loss: 0.6815025806427002
Validation loss: 1.660656382960658

Epoch: 6| Step: 13
Training loss: 0.6790186166763306
Validation loss: 1.6010448471192391

Epoch: 548| Step: 0
Training loss: 0.6707576513290405
Validation loss: 1.6396126747131348

Epoch: 6| Step: 1
Training loss: 0.9942996501922607
Validation loss: 1.6756950283563266

Epoch: 6| Step: 2
Training loss: 0.8858760595321655
Validation loss: 1.6461294363903742

Epoch: 6| Step: 3
Training loss: 0.8663458228111267
Validation loss: 1.6363687822895665

Epoch: 6| Step: 4
Training loss: 0.6094956994056702
Validation loss: 1.6398646831512451

Epoch: 6| Step: 5
Training loss: 1.1052007675170898
Validation loss: 1.5946896447930285

Epoch: 6| Step: 6
Training loss: 0.7710970640182495
Validation loss: 1.6559719398457518

Epoch: 6| Step: 7
Training loss: 0.7982836365699768
Validation loss: 1.6520396765842233

Epoch: 6| Step: 8
Training loss: 0.49896472692489624
Validation loss: 1.6271506740200905

Epoch: 6| Step: 9
Training loss: 0.6545708179473877
Validation loss: 1.6638178299832087

Epoch: 6| Step: 10
Training loss: 0.5157244205474854
Validation loss: 1.6302019793500182

Epoch: 6| Step: 11
Training loss: 0.7702018618583679
Validation loss: 1.6579029047360985

Epoch: 6| Step: 12
Training loss: 1.0850647687911987
Validation loss: 1.6869167230462516

Epoch: 6| Step: 13
Training loss: 0.4510490596294403
Validation loss: 1.6813709876870597

Epoch: 549| Step: 0
Training loss: 0.4085652530193329
Validation loss: 1.674945721062281

Epoch: 6| Step: 1
Training loss: 0.9694898724555969
Validation loss: 1.6901320808677263

Epoch: 6| Step: 2
Training loss: 0.5663877129554749
Validation loss: 1.6905083207673923

Epoch: 6| Step: 3
Training loss: 0.5466737747192383
Validation loss: 1.6405024797685686

Epoch: 6| Step: 4
Training loss: 0.5496695637702942
Validation loss: 1.652943520135777

Epoch: 6| Step: 5
Training loss: 0.6827706098556519
Validation loss: 1.6239066572599514

Epoch: 6| Step: 6
Training loss: 0.7991293668746948
Validation loss: 1.6549303685465167

Epoch: 6| Step: 7
Training loss: 1.3572032451629639
Validation loss: 1.6321257288737963

Epoch: 6| Step: 8
Training loss: 0.7781311273574829
Validation loss: 1.6752260872112807

Epoch: 6| Step: 9
Training loss: 1.2734198570251465
Validation loss: 1.64737275338942

Epoch: 6| Step: 10
Training loss: 0.5888693928718567
Validation loss: 1.6104790613215456

Epoch: 6| Step: 11
Training loss: 0.9271705150604248
Validation loss: 1.6032109170831659

Epoch: 6| Step: 12
Training loss: 0.7818576693534851
Validation loss: 1.6103828927522064

Epoch: 6| Step: 13
Training loss: 0.9470291137695312
Validation loss: 1.6306486501488635

Epoch: 550| Step: 0
Training loss: 0.5061710476875305
Validation loss: 1.7116793842725857

Epoch: 6| Step: 1
Training loss: 0.696439802646637
Validation loss: 1.6353725451295094

Epoch: 6| Step: 2
Training loss: 0.5003280639648438
Validation loss: 1.6591791811809744

Epoch: 6| Step: 3
Training loss: 0.482586145401001
Validation loss: 1.602572928192795

Epoch: 6| Step: 4
Training loss: 0.9181915521621704
Validation loss: 1.704764892978053

Epoch: 6| Step: 5
Training loss: 1.2027555704116821
Validation loss: 1.6838964698135213

Epoch: 6| Step: 6
Training loss: 0.39003369212150574
Validation loss: 1.6473496075599425

Epoch: 6| Step: 7
Training loss: 0.8293352723121643
Validation loss: 1.6643089325197282

Epoch: 6| Step: 8
Training loss: 0.7970160245895386
Validation loss: 1.6902566097115959

Epoch: 6| Step: 9
Training loss: 0.6428052186965942
Validation loss: 1.6954983498460503

Epoch: 6| Step: 10
Training loss: 0.7226359844207764
Validation loss: 1.690487838560535

Epoch: 6| Step: 11
Training loss: 1.0373365879058838
Validation loss: 1.6182406153730167

Epoch: 6| Step: 12
Training loss: 1.145588755607605
Validation loss: 1.6696263583757545

Epoch: 6| Step: 13
Training loss: 0.419192373752594
Validation loss: 1.6545661764760171

Epoch: 551| Step: 0
Training loss: 0.5604263544082642
Validation loss: 1.6386330845535442

Epoch: 6| Step: 1
Training loss: 0.8723821640014648
Validation loss: 1.5920301143841078

Epoch: 6| Step: 2
Training loss: 0.7589969635009766
Validation loss: 1.6925836352891819

Epoch: 6| Step: 3
Training loss: 0.5398761034011841
Validation loss: 1.642998218536377

Epoch: 6| Step: 4
Training loss: 0.6044541597366333
Validation loss: 1.6569163760831278

Epoch: 6| Step: 5
Training loss: 0.8651085495948792
Validation loss: 1.6236734467168008

Epoch: 6| Step: 6
Training loss: 0.494159460067749
Validation loss: 1.6389426492875623

Epoch: 6| Step: 7
Training loss: 0.4757465720176697
Validation loss: 1.578497112438243

Epoch: 6| Step: 8
Training loss: 0.9707479476928711
Validation loss: 1.6025967879961895

Epoch: 6| Step: 9
Training loss: 0.8028775453567505
Validation loss: 1.6571070609554168

Epoch: 6| Step: 10
Training loss: 0.529787003993988
Validation loss: 1.6360436421568676

Epoch: 6| Step: 11
Training loss: 1.031287431716919
Validation loss: 1.607728579992889

Epoch: 6| Step: 12
Training loss: 0.4925951659679413
Validation loss: 1.6591894741981261

Epoch: 6| Step: 13
Training loss: 1.3081756830215454
Validation loss: 1.6664589246114094

Epoch: 552| Step: 0
Training loss: 0.9472686052322388
Validation loss: 1.6050158841635591

Epoch: 6| Step: 1
Training loss: 0.5718383193016052
Validation loss: 1.7442397686742968

Epoch: 6| Step: 2
Training loss: 0.6800321936607361
Validation loss: 1.661837129182713

Epoch: 6| Step: 3
Training loss: 0.6526983976364136
Validation loss: 1.6393208913905646

Epoch: 6| Step: 4
Training loss: 0.587739109992981
Validation loss: 1.6525336760346607

Epoch: 6| Step: 5
Training loss: 1.0722227096557617
Validation loss: 1.6543056349600516

Epoch: 6| Step: 6
Training loss: 0.3690624237060547
Validation loss: 1.6630885908680577

Epoch: 6| Step: 7
Training loss: 0.5454874038696289
Validation loss: 1.588507902237677

Epoch: 6| Step: 8
Training loss: 1.0133355855941772
Validation loss: 1.6219935904267013

Epoch: 6| Step: 9
Training loss: 0.47113096714019775
Validation loss: 1.640653625611336

Epoch: 6| Step: 10
Training loss: 1.1489479541778564
Validation loss: 1.6331685563569427

Epoch: 6| Step: 11
Training loss: 0.7704727053642273
Validation loss: 1.6560308779439619

Epoch: 6| Step: 12
Training loss: 1.0379105806350708
Validation loss: 1.6519460152554255

Epoch: 6| Step: 13
Training loss: 0.6801549196243286
Validation loss: 1.6482015143158615

Epoch: 553| Step: 0
Training loss: 0.5519747734069824
Validation loss: 1.695299530542025

Epoch: 6| Step: 1
Training loss: 0.4666571617126465
Validation loss: 1.6836952573509627

Epoch: 6| Step: 2
Training loss: 1.0252387523651123
Validation loss: 1.6339502815277345

Epoch: 6| Step: 3
Training loss: 0.8789678812026978
Validation loss: 1.6373423120026946

Epoch: 6| Step: 4
Training loss: 0.6940933465957642
Validation loss: 1.6779890303970666

Epoch: 6| Step: 5
Training loss: 0.6924890279769897
Validation loss: 1.6516190664742583

Epoch: 6| Step: 6
Training loss: 0.7045144438743591
Validation loss: 1.6824617860137776

Epoch: 6| Step: 7
Training loss: 0.84011310338974
Validation loss: 1.5990730254880843

Epoch: 6| Step: 8
Training loss: 0.8512318134307861
Validation loss: 1.6056505903120963

Epoch: 6| Step: 9
Training loss: 0.38994765281677246
Validation loss: 1.6292979409617763

Epoch: 6| Step: 10
Training loss: 0.6069526672363281
Validation loss: 1.6097040035391366

Epoch: 6| Step: 11
Training loss: 0.7975444793701172
Validation loss: 1.593679634473657

Epoch: 6| Step: 12
Training loss: 0.6621536016464233
Validation loss: 1.6324213512482182

Epoch: 6| Step: 13
Training loss: 0.9062358140945435
Validation loss: 1.628541689406159

Epoch: 554| Step: 0
Training loss: 0.7197099924087524
Validation loss: 1.623003916073871

Epoch: 6| Step: 1
Training loss: 1.0252680778503418
Validation loss: 1.6547861253061602

Epoch: 6| Step: 2
Training loss: 0.9526272416114807
Validation loss: 1.6911482093154744

Epoch: 6| Step: 3
Training loss: 0.7559040784835815
Validation loss: 1.5789170912517014

Epoch: 6| Step: 4
Training loss: 0.8661543130874634
Validation loss: 1.6300375897397277

Epoch: 6| Step: 5
Training loss: 1.0440995693206787
Validation loss: 1.6191490068230578

Epoch: 6| Step: 6
Training loss: 0.5248647928237915
Validation loss: 1.6012475157296786

Epoch: 6| Step: 7
Training loss: 0.8130632638931274
Validation loss: 1.6026211630913518

Epoch: 6| Step: 8
Training loss: 0.5085449814796448
Validation loss: 1.6787870853177962

Epoch: 6| Step: 9
Training loss: 0.7136076092720032
Validation loss: 1.6495579493943082

Epoch: 6| Step: 10
Training loss: 0.6656779050827026
Validation loss: 1.6470637834200295

Epoch: 6| Step: 11
Training loss: 0.3430638313293457
Validation loss: 1.6868090475759199

Epoch: 6| Step: 12
Training loss: 0.6349078416824341
Validation loss: 1.7084086018223916

Epoch: 6| Step: 13
Training loss: 1.0612272024154663
Validation loss: 1.6245548622582549

Epoch: 555| Step: 0
Training loss: 1.2478482723236084
Validation loss: 1.6344892209576023

Epoch: 6| Step: 1
Training loss: 0.7392289042472839
Validation loss: 1.5888896232010217

Epoch: 6| Step: 2
Training loss: 0.4600672423839569
Validation loss: 1.657158915714551

Epoch: 6| Step: 3
Training loss: 1.0773218870162964
Validation loss: 1.592136077983405

Epoch: 6| Step: 4
Training loss: 0.9682673215866089
Validation loss: 1.6228231101907709

Epoch: 6| Step: 5
Training loss: 0.7988020777702332
Validation loss: 1.599612860269444

Epoch: 6| Step: 6
Training loss: 0.5827604532241821
Validation loss: 1.6214810135543987

Epoch: 6| Step: 7
Training loss: 0.5801348686218262
Validation loss: 1.6580400595100977

Epoch: 6| Step: 8
Training loss: 0.4998295307159424
Validation loss: 1.6138827839205343

Epoch: 6| Step: 9
Training loss: 0.7959855794906616
Validation loss: 1.6803736930252404

Epoch: 6| Step: 10
Training loss: 0.7461978197097778
Validation loss: 1.6438925009901806

Epoch: 6| Step: 11
Training loss: 0.8386918306350708
Validation loss: 1.716853134093746

Epoch: 6| Step: 12
Training loss: 1.0311208963394165
Validation loss: 1.6678994753027474

Epoch: 6| Step: 13
Training loss: 0.7279843091964722
Validation loss: 1.7098852255011117

Epoch: 556| Step: 0
Training loss: 0.6450006365776062
Validation loss: 1.7231969871828634

Epoch: 6| Step: 1
Training loss: 1.1649482250213623
Validation loss: 1.665962355111235

Epoch: 6| Step: 2
Training loss: 0.8657543659210205
Validation loss: 1.6747522456671602

Epoch: 6| Step: 3
Training loss: 0.6636850833892822
Validation loss: 1.6365790213308027

Epoch: 6| Step: 4
Training loss: 0.6206555366516113
Validation loss: 1.6508464018503826

Epoch: 6| Step: 5
Training loss: 0.943935215473175
Validation loss: 1.6320819444553827

Epoch: 6| Step: 6
Training loss: 0.9480663537979126
Validation loss: 1.6064024099739649

Epoch: 6| Step: 7
Training loss: 0.538766622543335
Validation loss: 1.6409196571637226

Epoch: 6| Step: 8
Training loss: 0.570237934589386
Validation loss: 1.6200819746140511

Epoch: 6| Step: 9
Training loss: 0.6387012600898743
Validation loss: 1.6326818312368085

Epoch: 6| Step: 10
Training loss: 1.258005142211914
Validation loss: 1.5586752212175758

Epoch: 6| Step: 11
Training loss: 0.4628376364707947
Validation loss: 1.6676477745015135

Epoch: 6| Step: 12
Training loss: 0.9421870112419128
Validation loss: 1.6132512515591038

Epoch: 6| Step: 13
Training loss: 0.2886505126953125
Validation loss: 1.6400101031026533

Epoch: 557| Step: 0
Training loss: 0.45963168144226074
Validation loss: 1.619808812295237

Epoch: 6| Step: 1
Training loss: 0.7261666655540466
Validation loss: 1.6614927335452008

Epoch: 6| Step: 2
Training loss: 0.5197241306304932
Validation loss: 1.6125134037386986

Epoch: 6| Step: 3
Training loss: 0.6650943756103516
Validation loss: 1.6990737735584218

Epoch: 6| Step: 4
Training loss: 0.8322464227676392
Validation loss: 1.7054017448938021

Epoch: 6| Step: 5
Training loss: 1.30976140499115
Validation loss: 1.663746436436971

Epoch: 6| Step: 6
Training loss: 0.6282398700714111
Validation loss: 1.6799553773736442

Epoch: 6| Step: 7
Training loss: 1.1388204097747803
Validation loss: 1.677409005421464

Epoch: 6| Step: 8
Training loss: 0.770942211151123
Validation loss: 1.7082575982616794

Epoch: 6| Step: 9
Training loss: 1.0809528827667236
Validation loss: 1.5898896955674695

Epoch: 6| Step: 10
Training loss: 0.7076933979988098
Validation loss: 1.6596973403807609

Epoch: 6| Step: 11
Training loss: 0.5169485807418823
Validation loss: 1.6366073880144345

Epoch: 6| Step: 12
Training loss: 0.3793042302131653
Validation loss: 1.617015948859594

Epoch: 6| Step: 13
Training loss: 0.37292808294296265
Validation loss: 1.6237845677201466

Epoch: 558| Step: 0
Training loss: 0.47231999039649963
Validation loss: 1.65296301662281

Epoch: 6| Step: 1
Training loss: 0.45076459646224976
Validation loss: 1.6897535965006838

Epoch: 6| Step: 2
Training loss: 1.2580647468566895
Validation loss: 1.656005799129445

Epoch: 6| Step: 3
Training loss: 0.5388564467430115
Validation loss: 1.6663288070309548

Epoch: 6| Step: 4
Training loss: 0.8123523592948914
Validation loss: 1.7204020741165325

Epoch: 6| Step: 5
Training loss: 0.8626545071601868
Validation loss: 1.6784030532324186

Epoch: 6| Step: 6
Training loss: 0.8592144250869751
Validation loss: 1.6496996687304588

Epoch: 6| Step: 7
Training loss: 0.5342491865158081
Validation loss: 1.6455494652512253

Epoch: 6| Step: 8
Training loss: 0.7696419358253479
Validation loss: 1.6030143076373684

Epoch: 6| Step: 9
Training loss: 0.809443473815918
Validation loss: 1.612000310292808

Epoch: 6| Step: 10
Training loss: 0.684361457824707
Validation loss: 1.6671002577709895

Epoch: 6| Step: 11
Training loss: 1.003643274307251
Validation loss: 1.6340307433118102

Epoch: 6| Step: 12
Training loss: 0.5969511270523071
Validation loss: 1.65713248842506

Epoch: 6| Step: 13
Training loss: 0.7625617384910583
Validation loss: 1.6362301970040927

Epoch: 559| Step: 0
Training loss: 1.2537782192230225
Validation loss: 1.6814725655381397

Epoch: 6| Step: 1
Training loss: 0.40332621335983276
Validation loss: 1.670126449677252

Epoch: 6| Step: 2
Training loss: 0.5984294414520264
Validation loss: 1.6321277464589765

Epoch: 6| Step: 3
Training loss: 0.93852299451828
Validation loss: 1.6376212604584233

Epoch: 6| Step: 4
Training loss: 1.087476134300232
Validation loss: 1.6458055588506884

Epoch: 6| Step: 5
Training loss: 0.867393970489502
Validation loss: 1.6607055151334373

Epoch: 6| Step: 6
Training loss: 0.7040210366249084
Validation loss: 1.6685321741206671

Epoch: 6| Step: 7
Training loss: 0.5309751033782959
Validation loss: 1.6910378010042253

Epoch: 6| Step: 8
Training loss: 0.5058466196060181
Validation loss: 1.6385247143366004

Epoch: 6| Step: 9
Training loss: 0.381325364112854
Validation loss: 1.717470706150096

Epoch: 6| Step: 10
Training loss: 0.9304584264755249
Validation loss: 1.6425754729137625

Epoch: 6| Step: 11
Training loss: 0.7658886313438416
Validation loss: 1.6431804216036232

Epoch: 6| Step: 12
Training loss: 1.037416934967041
Validation loss: 1.6501981148155787

Epoch: 6| Step: 13
Training loss: 0.5037491321563721
Validation loss: 1.6428291002909343

Epoch: 560| Step: 0
Training loss: 0.7198789119720459
Validation loss: 1.592952496262007

Epoch: 6| Step: 1
Training loss: 0.6181725263595581
Validation loss: 1.6088407014005928

Epoch: 6| Step: 2
Training loss: 0.674456000328064
Validation loss: 1.6321266197389173

Epoch: 6| Step: 3
Training loss: 0.725139856338501
Validation loss: 1.6520875577003724

Epoch: 6| Step: 4
Training loss: 1.0925891399383545
Validation loss: 1.5696107764397897

Epoch: 6| Step: 5
Training loss: 0.8825157880783081
Validation loss: 1.64198019812184

Epoch: 6| Step: 6
Training loss: 0.5980159640312195
Validation loss: 1.642295229819513

Epoch: 6| Step: 7
Training loss: 0.6268141865730286
Validation loss: 1.625904921562441

Epoch: 6| Step: 8
Training loss: 0.9131810069084167
Validation loss: 1.556324811391933

Epoch: 6| Step: 9
Training loss: 0.8679829835891724
Validation loss: 1.6625160491594704

Epoch: 6| Step: 10
Training loss: 0.7603722810745239
Validation loss: 1.6304485823518486

Epoch: 6| Step: 11
Training loss: 0.7650246620178223
Validation loss: 1.6974131086821198

Epoch: 6| Step: 12
Training loss: 0.8412977457046509
Validation loss: 1.6459173053823493

Epoch: 6| Step: 13
Training loss: 0.5594318509101868
Validation loss: 1.6796332482368714

Epoch: 561| Step: 0
Training loss: 1.1844019889831543
Validation loss: 1.642550269762675

Epoch: 6| Step: 1
Training loss: 0.92942875623703
Validation loss: 1.6779410185352448

Epoch: 6| Step: 2
Training loss: 0.4856703579425812
Validation loss: 1.6254317004193541

Epoch: 6| Step: 3
Training loss: 0.7297815680503845
Validation loss: 1.6580944753462268

Epoch: 6| Step: 4
Training loss: 0.504746675491333
Validation loss: 1.7046012468235467

Epoch: 6| Step: 5
Training loss: 0.5992622375488281
Validation loss: 1.622059558027534

Epoch: 6| Step: 6
Training loss: 0.6258013844490051
Validation loss: 1.64642237206941

Epoch: 6| Step: 7
Training loss: 1.2365832328796387
Validation loss: 1.5951795642093947

Epoch: 6| Step: 8
Training loss: 0.7751854658126831
Validation loss: 1.6413226794171076

Epoch: 6| Step: 9
Training loss: 0.6757797002792358
Validation loss: 1.6398490821161578

Epoch: 6| Step: 10
Training loss: 0.5863275527954102
Validation loss: 1.6187337316492552

Epoch: 6| Step: 11
Training loss: 0.9561260342597961
Validation loss: 1.6104974567249257

Epoch: 6| Step: 12
Training loss: 0.56671142578125
Validation loss: 1.6758298937992384

Epoch: 6| Step: 13
Training loss: 0.705327033996582
Validation loss: 1.654826912828671

Epoch: 562| Step: 0
Training loss: 0.8143970966339111
Validation loss: 1.6442643480916177

Epoch: 6| Step: 1
Training loss: 0.9912642240524292
Validation loss: 1.671525179698903

Epoch: 6| Step: 2
Training loss: 0.4605958163738251
Validation loss: 1.6299570286145775

Epoch: 6| Step: 3
Training loss: 0.6433571577072144
Validation loss: 1.6406925211670578

Epoch: 6| Step: 4
Training loss: 0.8360211849212646
Validation loss: 1.6278578350620885

Epoch: 6| Step: 5
Training loss: 1.4425630569458008
Validation loss: 1.6216538119059738

Epoch: 6| Step: 6
Training loss: 0.667961061000824
Validation loss: 1.6303229408879434

Epoch: 6| Step: 7
Training loss: 0.6218143105506897
Validation loss: 1.646267843502824

Epoch: 6| Step: 8
Training loss: 0.4417497217655182
Validation loss: 1.6260640877549366

Epoch: 6| Step: 9
Training loss: 0.6356037259101868
Validation loss: 1.6005205159546227

Epoch: 6| Step: 10
Training loss: 0.756841778755188
Validation loss: 1.674959530112564

Epoch: 6| Step: 11
Training loss: 0.43300044536590576
Validation loss: 1.6354140466259373

Epoch: 6| Step: 12
Training loss: 0.864989697933197
Validation loss: 1.6765493859526932

Epoch: 6| Step: 13
Training loss: 0.49854719638824463
Validation loss: 1.6634043826851794

Epoch: 563| Step: 0
Training loss: 0.5610376596450806
Validation loss: 1.5717962403451242

Epoch: 6| Step: 1
Training loss: 0.9090286493301392
Validation loss: 1.6249502256352415

Epoch: 6| Step: 2
Training loss: 0.9001399278640747
Validation loss: 1.5779944068642073

Epoch: 6| Step: 3
Training loss: 0.6687459945678711
Validation loss: 1.6221638212921798

Epoch: 6| Step: 4
Training loss: 0.5343549251556396
Validation loss: 1.602366312216687

Epoch: 6| Step: 5
Training loss: 0.5521458387374878
Validation loss: 1.6468894891841437

Epoch: 6| Step: 6
Training loss: 0.5792012810707092
Validation loss: 1.6140758183694655

Epoch: 6| Step: 7
Training loss: 0.9670161008834839
Validation loss: 1.5983727068029425

Epoch: 6| Step: 8
Training loss: 1.0269215106964111
Validation loss: 1.6530753181826683

Epoch: 6| Step: 9
Training loss: 0.9244959354400635
Validation loss: 1.6725672726990075

Epoch: 6| Step: 10
Training loss: 0.6239588260650635
Validation loss: 1.6404555997540873

Epoch: 6| Step: 11
Training loss: 0.9083206653594971
Validation loss: 1.6358759210955711

Epoch: 6| Step: 12
Training loss: 0.7754322290420532
Validation loss: 1.6719965921935214

Epoch: 6| Step: 13
Training loss: 0.25806331634521484
Validation loss: 1.6253247466138614

Epoch: 564| Step: 0
Training loss: 0.49405258893966675
Validation loss: 1.575692763892553

Epoch: 6| Step: 1
Training loss: 0.7230229377746582
Validation loss: 1.6467171792061097

Epoch: 6| Step: 2
Training loss: 0.6317654848098755
Validation loss: 1.634262341325001

Epoch: 6| Step: 3
Training loss: 0.42864298820495605
Validation loss: 1.6338255751517512

Epoch: 6| Step: 4
Training loss: 0.5776670575141907
Validation loss: 1.645491389818089

Epoch: 6| Step: 5
Training loss: 0.7040107250213623
Validation loss: 1.6513146661943006

Epoch: 6| Step: 6
Training loss: 0.5842986106872559
Validation loss: 1.581728437895416

Epoch: 6| Step: 7
Training loss: 0.8691973686218262
Validation loss: 1.6582676338893112

Epoch: 6| Step: 8
Training loss: 0.9257368445396423
Validation loss: 1.6355890112538491

Epoch: 6| Step: 9
Training loss: 0.8117403984069824
Validation loss: 1.6567093633836316

Epoch: 6| Step: 10
Training loss: 1.2593896389007568
Validation loss: 1.6366922265739852

Epoch: 6| Step: 11
Training loss: 0.8045305013656616
Validation loss: 1.6487710117011942

Epoch: 6| Step: 12
Training loss: 0.44435226917266846
Validation loss: 1.6407963204127487

Epoch: 6| Step: 13
Training loss: 1.0044918060302734
Validation loss: 1.6183684513133059

Epoch: 565| Step: 0
Training loss: 1.239943504333496
Validation loss: 1.6001724171382126

Epoch: 6| Step: 1
Training loss: 0.661160945892334
Validation loss: 1.6690935947561776

Epoch: 6| Step: 2
Training loss: 0.6273186802864075
Validation loss: 1.6659492420893844

Epoch: 6| Step: 3
Training loss: 0.4248455762863159
Validation loss: 1.6995152632395427

Epoch: 6| Step: 4
Training loss: 1.0329132080078125
Validation loss: 1.6443735143189788

Epoch: 6| Step: 5
Training loss: 0.4924609065055847
Validation loss: 1.61172531753458

Epoch: 6| Step: 6
Training loss: 0.8051538467407227
Validation loss: 1.6558005207328386

Epoch: 6| Step: 7
Training loss: 0.8064020872116089
Validation loss: 1.626833523473432

Epoch: 6| Step: 8
Training loss: 0.6665748953819275
Validation loss: 1.6451897595518379

Epoch: 6| Step: 9
Training loss: 0.5180666446685791
Validation loss: 1.6649993132519465

Epoch: 6| Step: 10
Training loss: 1.2639755010604858
Validation loss: 1.5908471640720163

Epoch: 6| Step: 11
Training loss: 0.5437636971473694
Validation loss: 1.6210834903101767

Epoch: 6| Step: 12
Training loss: 0.36504995822906494
Validation loss: 1.6431997565812961

Epoch: 6| Step: 13
Training loss: 0.8514347076416016
Validation loss: 1.6232627502051733

Epoch: 566| Step: 0
Training loss: 0.94062340259552
Validation loss: 1.62855710265457

Epoch: 6| Step: 1
Training loss: 0.8262754678726196
Validation loss: 1.5952411287574357

Epoch: 6| Step: 2
Training loss: 0.7100426554679871
Validation loss: 1.6398380892251128

Epoch: 6| Step: 3
Training loss: 0.35582244396209717
Validation loss: 1.641718150467001

Epoch: 6| Step: 4
Training loss: 1.1640650033950806
Validation loss: 1.6876708153755433

Epoch: 6| Step: 5
Training loss: 1.0119904279708862
Validation loss: 1.6761684815088909

Epoch: 6| Step: 6
Training loss: 0.6004929542541504
Validation loss: 1.6051147086645967

Epoch: 6| Step: 7
Training loss: 0.5081785917282104
Validation loss: 1.6698281418892644

Epoch: 6| Step: 8
Training loss: 0.8679448366165161
Validation loss: 1.668999800118067

Epoch: 6| Step: 9
Training loss: 0.7916750907897949
Validation loss: 1.6283922336434806

Epoch: 6| Step: 10
Training loss: 0.8979495763778687
Validation loss: 1.6523360142143824

Epoch: 6| Step: 11
Training loss: 0.5970503687858582
Validation loss: 1.6580697259595316

Epoch: 6| Step: 12
Training loss: 0.7034263014793396
Validation loss: 1.5739976898316415

Epoch: 6| Step: 13
Training loss: 0.7632286548614502
Validation loss: 1.6675385531558786

Epoch: 567| Step: 0
Training loss: 0.8023823499679565
Validation loss: 1.5944810772454867

Epoch: 6| Step: 1
Training loss: 0.8404505848884583
Validation loss: 1.6552682845823226

Epoch: 6| Step: 2
Training loss: 0.6408344507217407
Validation loss: 1.6031390646452546

Epoch: 6| Step: 3
Training loss: 0.4910278618335724
Validation loss: 1.5653099949641893

Epoch: 6| Step: 4
Training loss: 0.9080640077590942
Validation loss: 1.630452025321222

Epoch: 6| Step: 5
Training loss: 0.8750448822975159
Validation loss: 1.6313337395268102

Epoch: 6| Step: 6
Training loss: 0.543707549571991
Validation loss: 1.6285708604320404

Epoch: 6| Step: 7
Training loss: 0.8886216878890991
Validation loss: 1.6200577251372799

Epoch: 6| Step: 8
Training loss: 1.0018572807312012
Validation loss: 1.6004837892388786

Epoch: 6| Step: 9
Training loss: 0.7275090217590332
Validation loss: 1.6565771000359648

Epoch: 6| Step: 10
Training loss: 0.5822974443435669
Validation loss: 1.6280099781610633

Epoch: 6| Step: 11
Training loss: 0.5285931825637817
Validation loss: 1.6121473863560667

Epoch: 6| Step: 12
Training loss: 0.32883352041244507
Validation loss: 1.553249784695205

Epoch: 6| Step: 13
Training loss: 1.1605165004730225
Validation loss: 1.6840358998185845

Epoch: 568| Step: 0
Training loss: 0.870077908039093
Validation loss: 1.6708447907560615

Epoch: 6| Step: 1
Training loss: 1.1536893844604492
Validation loss: 1.6336532715828187

Epoch: 6| Step: 2
Training loss: 0.8937995433807373
Validation loss: 1.6184822487574753

Epoch: 6| Step: 3
Training loss: 0.43801558017730713
Validation loss: 1.6460354687065206

Epoch: 6| Step: 4
Training loss: 0.8834578990936279
Validation loss: 1.6312236747434061

Epoch: 6| Step: 5
Training loss: 0.3343130052089691
Validation loss: 1.5757101876761324

Epoch: 6| Step: 6
Training loss: 0.7133967280387878
Validation loss: 1.6268250916593818

Epoch: 6| Step: 7
Training loss: 0.7134405374526978
Validation loss: 1.6633604764938354

Epoch: 6| Step: 8
Training loss: 0.5037438869476318
Validation loss: 1.6147518311777422

Epoch: 6| Step: 9
Training loss: 0.7702513933181763
Validation loss: 1.6216980295796548

Epoch: 6| Step: 10
Training loss: 0.46562010049819946
Validation loss: 1.5876818594112192

Epoch: 6| Step: 11
Training loss: 1.2060389518737793
Validation loss: 1.6144076765224498

Epoch: 6| Step: 12
Training loss: 0.8870170712471008
Validation loss: 1.6305275860653128

Epoch: 6| Step: 13
Training loss: 0.6901105046272278
Validation loss: 1.5928694048235494

Epoch: 569| Step: 0
Training loss: 0.39330074191093445
Validation loss: 1.6193486541830084

Epoch: 6| Step: 1
Training loss: 0.8992186784744263
Validation loss: 1.6264937898164153

Epoch: 6| Step: 2
Training loss: 0.6428085565567017
Validation loss: 1.655858532074959

Epoch: 6| Step: 3
Training loss: 0.6527653932571411
Validation loss: 1.6423858532341578

Epoch: 6| Step: 4
Training loss: 1.0869648456573486
Validation loss: 1.6258428994045462

Epoch: 6| Step: 5
Training loss: 1.047752857208252
Validation loss: 1.6334799951122654

Epoch: 6| Step: 6
Training loss: 0.416606605052948
Validation loss: 1.6841129654197282

Epoch: 6| Step: 7
Training loss: 0.9741118550300598
Validation loss: 1.7055836121241252

Epoch: 6| Step: 8
Training loss: 0.787004828453064
Validation loss: 1.6391633095279816

Epoch: 6| Step: 9
Training loss: 0.7925699353218079
Validation loss: 1.633110680887776

Epoch: 6| Step: 10
Training loss: 0.5476326942443848
Validation loss: 1.617235601589244

Epoch: 6| Step: 11
Training loss: 0.2998186945915222
Validation loss: 1.712558505355671

Epoch: 6| Step: 12
Training loss: 0.7027654647827148
Validation loss: 1.6279241628544305

Epoch: 6| Step: 13
Training loss: 0.8247420787811279
Validation loss: 1.6530279959401777

Epoch: 570| Step: 0
Training loss: 0.44861432909965515
Validation loss: 1.6597094433282011

Epoch: 6| Step: 1
Training loss: 0.5525890588760376
Validation loss: 1.6287769938027987

Epoch: 6| Step: 2
Training loss: 0.8023043274879456
Validation loss: 1.6758977751578055

Epoch: 6| Step: 3
Training loss: 0.8099236488342285
Validation loss: 1.6051264014295352

Epoch: 6| Step: 4
Training loss: 1.0613698959350586
Validation loss: 1.650531530380249

Epoch: 6| Step: 5
Training loss: 0.6475369334220886
Validation loss: 1.665064161823642

Epoch: 6| Step: 6
Training loss: 0.9559471011161804
Validation loss: 1.6363343846413396

Epoch: 6| Step: 7
Training loss: 0.7548873424530029
Validation loss: 1.6676734160351496

Epoch: 6| Step: 8
Training loss: 0.6923176050186157
Validation loss: 1.6334010247261292

Epoch: 6| Step: 9
Training loss: 0.7102976441383362
Validation loss: 1.6210116391540856

Epoch: 6| Step: 10
Training loss: 0.5463649034500122
Validation loss: 1.620976553168348

Epoch: 6| Step: 11
Training loss: 0.40458646416664124
Validation loss: 1.6673633231911609

Epoch: 6| Step: 12
Training loss: 1.1552201509475708
Validation loss: 1.5593094941108459

Epoch: 6| Step: 13
Training loss: 0.4985927939414978
Validation loss: 1.5998156301436885

Epoch: 571| Step: 0
Training loss: 0.5775473117828369
Validation loss: 1.5736434280231435

Epoch: 6| Step: 1
Training loss: 0.6653993129730225
Validation loss: 1.6681996276301723

Epoch: 6| Step: 2
Training loss: 0.5398846864700317
Validation loss: 1.6175765568210232

Epoch: 6| Step: 3
Training loss: 0.9471895098686218
Validation loss: 1.6903755773780167

Epoch: 6| Step: 4
Training loss: 0.7997769117355347
Validation loss: 1.7119892028070265

Epoch: 6| Step: 5
Training loss: 1.0366573333740234
Validation loss: 1.66952133435075

Epoch: 6| Step: 6
Training loss: 0.6136130094528198
Validation loss: 1.629694361840525

Epoch: 6| Step: 7
Training loss: 0.6754909753799438
Validation loss: 1.6264694736849876

Epoch: 6| Step: 8
Training loss: 0.933218777179718
Validation loss: 1.6331944875819708

Epoch: 6| Step: 9
Training loss: 0.5883378982543945
Validation loss: 1.681325057501434

Epoch: 6| Step: 10
Training loss: 0.7975388765335083
Validation loss: 1.6498498044988161

Epoch: 6| Step: 11
Training loss: 0.847003698348999
Validation loss: 1.6273583353206675

Epoch: 6| Step: 12
Training loss: 0.6173000335693359
Validation loss: 1.6202311195353025

Epoch: 6| Step: 13
Training loss: 0.6101928949356079
Validation loss: 1.5862071526947843

Epoch: 572| Step: 0
Training loss: 0.47113293409347534
Validation loss: 1.6825099228530802

Epoch: 6| Step: 1
Training loss: 0.8371896743774414
Validation loss: 1.6333475048824022

Epoch: 6| Step: 2
Training loss: 0.4720606505870819
Validation loss: 1.6865741283662858

Epoch: 6| Step: 3
Training loss: 0.629755973815918
Validation loss: 1.6246489222331713

Epoch: 6| Step: 4
Training loss: 0.7670509815216064
Validation loss: 1.6340505666630243

Epoch: 6| Step: 5
Training loss: 0.7427127957344055
Validation loss: 1.6010212000980173

Epoch: 6| Step: 6
Training loss: 1.1014320850372314
Validation loss: 1.647584157605325

Epoch: 6| Step: 7
Training loss: 0.6741518974304199
Validation loss: 1.634004831314087

Epoch: 6| Step: 8
Training loss: 0.49983590841293335
Validation loss: 1.641634996219348

Epoch: 6| Step: 9
Training loss: 1.2400397062301636
Validation loss: 1.7054366373246717

Epoch: 6| Step: 10
Training loss: 0.7464065551757812
Validation loss: 1.69439003416287

Epoch: 6| Step: 11
Training loss: 0.6306668519973755
Validation loss: 1.6438583071513841

Epoch: 6| Step: 12
Training loss: 0.5468865633010864
Validation loss: 1.658852989955615

Epoch: 6| Step: 13
Training loss: 0.6317723393440247
Validation loss: 1.628337155106247

Epoch: 573| Step: 0
Training loss: 0.7962135672569275
Validation loss: 1.6413304536573348

Epoch: 6| Step: 1
Training loss: 1.2796986103057861
Validation loss: 1.6571680358661118

Epoch: 6| Step: 2
Training loss: 0.57091224193573
Validation loss: 1.651601545272335

Epoch: 6| Step: 3
Training loss: 0.7882552146911621
Validation loss: 1.6074762600724415

Epoch: 6| Step: 4
Training loss: 0.5519971251487732
Validation loss: 1.6786795598204418

Epoch: 6| Step: 5
Training loss: 1.2355265617370605
Validation loss: 1.6217595249093988

Epoch: 6| Step: 6
Training loss: 0.4396354854106903
Validation loss: 1.629613728933437

Epoch: 6| Step: 7
Training loss: 0.7325357794761658
Validation loss: 1.6957506364391697

Epoch: 6| Step: 8
Training loss: 0.6129151582717896
Validation loss: 1.6482225233508694

Epoch: 6| Step: 9
Training loss: 0.9879947900772095
Validation loss: 1.599485807521369

Epoch: 6| Step: 10
Training loss: 0.7567561864852905
Validation loss: 1.6014072907868253

Epoch: 6| Step: 11
Training loss: 0.4591173231601715
Validation loss: 1.6091162414960964

Epoch: 6| Step: 12
Training loss: 0.5001423358917236
Validation loss: 1.5970512577282485

Epoch: 6| Step: 13
Training loss: 0.5483397245407104
Validation loss: 1.640432733361439

Epoch: 574| Step: 0
Training loss: 0.7532764673233032
Validation loss: 1.6539887074501283

Epoch: 6| Step: 1
Training loss: 0.4362422525882721
Validation loss: 1.6243063352441276

Epoch: 6| Step: 2
Training loss: 0.82291579246521
Validation loss: 1.673166480115665

Epoch: 6| Step: 3
Training loss: 0.6701926589012146
Validation loss: 1.5950761418188772

Epoch: 6| Step: 4
Training loss: 0.9484416246414185
Validation loss: 1.6632024280486568

Epoch: 6| Step: 5
Training loss: 0.8371195793151855
Validation loss: 1.645009740706413

Epoch: 6| Step: 6
Training loss: 0.4450092613697052
Validation loss: 1.5756845243515507

Epoch: 6| Step: 7
Training loss: 0.6454135179519653
Validation loss: 1.6384224391752673

Epoch: 6| Step: 8
Training loss: 0.5215001106262207
Validation loss: 1.6304264465967815

Epoch: 6| Step: 9
Training loss: 0.6938812136650085
Validation loss: 1.6332000327366654

Epoch: 6| Step: 10
Training loss: 0.7803558111190796
Validation loss: 1.6886829471075406

Epoch: 6| Step: 11
Training loss: 0.49138009548187256
Validation loss: 1.6307722971003542

Epoch: 6| Step: 12
Training loss: 1.0500648021697998
Validation loss: 1.6146154967687463

Epoch: 6| Step: 13
Training loss: 0.9360390901565552
Validation loss: 1.5896144759270452

Epoch: 575| Step: 0
Training loss: 0.5723457932472229
Validation loss: 1.6409380333397978

Epoch: 6| Step: 1
Training loss: 0.520194411277771
Validation loss: 1.609726208512501

Epoch: 6| Step: 2
Training loss: 0.7948713302612305
Validation loss: 1.654661617612326

Epoch: 6| Step: 3
Training loss: 0.4509907066822052
Validation loss: 1.6372706351741668

Epoch: 6| Step: 4
Training loss: 0.5538234710693359
Validation loss: 1.6797471661721506

Epoch: 6| Step: 5
Training loss: 1.094851016998291
Validation loss: 1.6204340675825715

Epoch: 6| Step: 6
Training loss: 0.7180881500244141
Validation loss: 1.669768093734659

Epoch: 6| Step: 7
Training loss: 0.6720058917999268
Validation loss: 1.6559611853732858

Epoch: 6| Step: 8
Training loss: 0.5534224510192871
Validation loss: 1.5644292036692302

Epoch: 6| Step: 9
Training loss: 0.9841228723526001
Validation loss: 1.634671926498413

Epoch: 6| Step: 10
Training loss: 0.501562237739563
Validation loss: 1.61232251762062

Epoch: 6| Step: 11
Training loss: 0.7934228777885437
Validation loss: 1.6080829815198017

Epoch: 6| Step: 12
Training loss: 0.6855474710464478
Validation loss: 1.6432110019909438

Epoch: 6| Step: 13
Training loss: 1.7908663749694824
Validation loss: 1.6099166703480545

Epoch: 576| Step: 0
Training loss: 0.9577891826629639
Validation loss: 1.6254092198546215

Epoch: 6| Step: 1
Training loss: 0.6515267491340637
Validation loss: 1.6137533316048243

Epoch: 6| Step: 2
Training loss: 0.7147202491760254
Validation loss: 1.6045834197792956

Epoch: 6| Step: 3
Training loss: 0.8089261054992676
Validation loss: 1.6339556504321355

Epoch: 6| Step: 4
Training loss: 0.38628101348876953
Validation loss: 1.6859153239957747

Epoch: 6| Step: 5
Training loss: 0.43579694628715515
Validation loss: 1.6152041701860325

Epoch: 6| Step: 6
Training loss: 0.5417810678482056
Validation loss: 1.65542999903361

Epoch: 6| Step: 7
Training loss: 1.0658049583435059
Validation loss: 1.6481749460261355

Epoch: 6| Step: 8
Training loss: 0.681267499923706
Validation loss: 1.6895622091908609

Epoch: 6| Step: 9
Training loss: 0.5492567420005798
Validation loss: 1.6241878360830329

Epoch: 6| Step: 10
Training loss: 1.2206556797027588
Validation loss: 1.613169930314505

Epoch: 6| Step: 11
Training loss: 0.5944505929946899
Validation loss: 1.5962288251487158

Epoch: 6| Step: 12
Training loss: 0.8121383190155029
Validation loss: 1.6513884503354308

Epoch: 6| Step: 13
Training loss: 1.0201830863952637
Validation loss: 1.6344954159951979

Epoch: 577| Step: 0
Training loss: 0.4581097960472107
Validation loss: 1.6192615955106673

Epoch: 6| Step: 1
Training loss: 0.7675928473472595
Validation loss: 1.6460900229792441

Epoch: 6| Step: 2
Training loss: 0.4736659526824951
Validation loss: 1.6390616240039948

Epoch: 6| Step: 3
Training loss: 0.9278833866119385
Validation loss: 1.650453629032258

Epoch: 6| Step: 4
Training loss: 0.6721024513244629
Validation loss: 1.606095531935333

Epoch: 6| Step: 5
Training loss: 0.5991010069847107
Validation loss: 1.6085456455907514

Epoch: 6| Step: 6
Training loss: 0.9985263347625732
Validation loss: 1.5986809525438535

Epoch: 6| Step: 7
Training loss: 1.0943902730941772
Validation loss: 1.664390617801297

Epoch: 6| Step: 8
Training loss: 0.743403434753418
Validation loss: 1.599025341772264

Epoch: 6| Step: 9
Training loss: 0.5984742641448975
Validation loss: 1.623735753438806

Epoch: 6| Step: 10
Training loss: 0.6797165274620056
Validation loss: 1.5809904324111117

Epoch: 6| Step: 11
Training loss: 1.2843775749206543
Validation loss: 1.6109776202068533

Epoch: 6| Step: 12
Training loss: 0.5173364877700806
Validation loss: 1.6230298037170081

Epoch: 6| Step: 13
Training loss: 0.6385186910629272
Validation loss: 1.6741354029665712

Epoch: 578| Step: 0
Training loss: 0.9160257577896118
Validation loss: 1.585345914286952

Epoch: 6| Step: 1
Training loss: 1.4112379550933838
Validation loss: 1.689685788205875

Epoch: 6| Step: 2
Training loss: 0.504388153553009
Validation loss: 1.6245338006686139

Epoch: 6| Step: 3
Training loss: 0.6805143356323242
Validation loss: 1.6379361524376819

Epoch: 6| Step: 4
Training loss: 0.6038267016410828
Validation loss: 1.6246756122958275

Epoch: 6| Step: 5
Training loss: 0.47015225887298584
Validation loss: 1.6760583334071661

Epoch: 6| Step: 6
Training loss: 0.9391758441925049
Validation loss: 1.6167259139399375

Epoch: 6| Step: 7
Training loss: 0.46440035104751587
Validation loss: 1.53384353012167

Epoch: 6| Step: 8
Training loss: 0.7057310342788696
Validation loss: 1.6253029646412018

Epoch: 6| Step: 9
Training loss: 0.692041277885437
Validation loss: 1.6181523505077566

Epoch: 6| Step: 10
Training loss: 0.8691259622573853
Validation loss: 1.598525797167132

Epoch: 6| Step: 11
Training loss: 0.5136765241622925
Validation loss: 1.6210331442535564

Epoch: 6| Step: 12
Training loss: 0.5090517997741699
Validation loss: 1.5704929777370986

Epoch: 6| Step: 13
Training loss: 0.8746752738952637
Validation loss: 1.60596893166983

Epoch: 579| Step: 0
Training loss: 1.030574083328247
Validation loss: 1.6284135323698803

Epoch: 6| Step: 1
Training loss: 0.43693649768829346
Validation loss: 1.638397938461714

Epoch: 6| Step: 2
Training loss: 0.5483420491218567
Validation loss: 1.651154746291458

Epoch: 6| Step: 3
Training loss: 0.4691886007785797
Validation loss: 1.6884330216274466

Epoch: 6| Step: 4
Training loss: 0.585875391960144
Validation loss: 1.6657472887346823

Epoch: 6| Step: 5
Training loss: 0.7944447994232178
Validation loss: 1.702530937810098

Epoch: 6| Step: 6
Training loss: 0.4858628511428833
Validation loss: 1.6750107170433126

Epoch: 6| Step: 7
Training loss: 0.4547141492366791
Validation loss: 1.6264849260289183

Epoch: 6| Step: 8
Training loss: 0.5798695683479309
Validation loss: 1.613442978551311

Epoch: 6| Step: 9
Training loss: 0.9343222379684448
Validation loss: 1.6295604808356172

Epoch: 6| Step: 10
Training loss: 0.6734037399291992
Validation loss: 1.6113707019436745

Epoch: 6| Step: 11
Training loss: 0.8508585095405579
Validation loss: 1.5868027043598953

Epoch: 6| Step: 12
Training loss: 1.2045700550079346
Validation loss: 1.6295504800734981

Epoch: 6| Step: 13
Training loss: 0.8563978672027588
Validation loss: 1.6300806249341657

Epoch: 580| Step: 0
Training loss: 0.6997970342636108
Validation loss: 1.625879523574665

Epoch: 6| Step: 1
Training loss: 0.777521014213562
Validation loss: 1.5987454216967347

Epoch: 6| Step: 2
Training loss: 0.6335920691490173
Validation loss: 1.5598024347777009

Epoch: 6| Step: 3
Training loss: 0.4093562364578247
Validation loss: 1.5670163823712258

Epoch: 6| Step: 4
Training loss: 0.9726420044898987
Validation loss: 1.5418716092263498

Epoch: 6| Step: 5
Training loss: 0.7017967700958252
Validation loss: 1.6318565453252485

Epoch: 6| Step: 6
Training loss: 0.8853705525398254
Validation loss: 1.6423576711326517

Epoch: 6| Step: 7
Training loss: 0.9295859932899475
Validation loss: 1.645994835002448

Epoch: 6| Step: 8
Training loss: 0.6934161186218262
Validation loss: 1.6390686483793362

Epoch: 6| Step: 9
Training loss: 0.7026000022888184
Validation loss: 1.5954579204641364

Epoch: 6| Step: 10
Training loss: 0.46229034662246704
Validation loss: 1.6282529254113474

Epoch: 6| Step: 11
Training loss: 0.6956431865692139
Validation loss: 1.6527472619087464

Epoch: 6| Step: 12
Training loss: 0.9564015865325928
Validation loss: 1.6094379168684765

Epoch: 6| Step: 13
Training loss: 0.4542032778263092
Validation loss: 1.6054772189868394

Epoch: 581| Step: 0
Training loss: 0.8491763472557068
Validation loss: 1.6343395633082236

Epoch: 6| Step: 1
Training loss: 0.6814950704574585
Validation loss: 1.668390457348157

Epoch: 6| Step: 2
Training loss: 0.6701999306678772
Validation loss: 1.556348373813014

Epoch: 6| Step: 3
Training loss: 0.8434146642684937
Validation loss: 1.5795074073217248

Epoch: 6| Step: 4
Training loss: 0.45661041140556335
Validation loss: 1.668280082364236

Epoch: 6| Step: 5
Training loss: 0.3645414412021637
Validation loss: 1.6330457900160102

Epoch: 6| Step: 6
Training loss: 0.9098327159881592
Validation loss: 1.6311697972718107

Epoch: 6| Step: 7
Training loss: 0.7968020439147949
Validation loss: 1.66631668613803

Epoch: 6| Step: 8
Training loss: 0.5253560543060303
Validation loss: 1.6363574535615983

Epoch: 6| Step: 9
Training loss: 1.202735185623169
Validation loss: 1.7060215460356845

Epoch: 6| Step: 10
Training loss: 0.9837965369224548
Validation loss: 1.6677396771728352

Epoch: 6| Step: 11
Training loss: 0.5196698904037476
Validation loss: 1.634346378746853

Epoch: 6| Step: 12
Training loss: 0.5637450218200684
Validation loss: 1.6672586266712477

Epoch: 6| Step: 13
Training loss: 0.6635289788246155
Validation loss: 1.663389334114649

Epoch: 582| Step: 0
Training loss: 0.8713192939758301
Validation loss: 1.6274350740576302

Epoch: 6| Step: 1
Training loss: 0.5838792324066162
Validation loss: 1.60860647309211

Epoch: 6| Step: 2
Training loss: 0.4913064241409302
Validation loss: 1.5777227391478836

Epoch: 6| Step: 3
Training loss: 0.5802595615386963
Validation loss: 1.6094703110315467

Epoch: 6| Step: 4
Training loss: 0.8596010208129883
Validation loss: 1.631438983383999

Epoch: 6| Step: 5
Training loss: 0.9358843564987183
Validation loss: 1.5974510754308393

Epoch: 6| Step: 6
Training loss: 0.49828317761421204
Validation loss: 1.6491386275137625

Epoch: 6| Step: 7
Training loss: 0.6391620635986328
Validation loss: 1.6041339084666262

Epoch: 6| Step: 8
Training loss: 0.9903407692909241
Validation loss: 1.6082005680248301

Epoch: 6| Step: 9
Training loss: 0.767927348613739
Validation loss: 1.566313318026963

Epoch: 6| Step: 10
Training loss: 0.36253297328948975
Validation loss: 1.6207736012756184

Epoch: 6| Step: 11
Training loss: 0.4808976948261261
Validation loss: 1.6420310825429938

Epoch: 6| Step: 12
Training loss: 1.041466236114502
Validation loss: 1.596302015807039

Epoch: 6| Step: 13
Training loss: 0.5974330306053162
Validation loss: 1.6179924152230705

Epoch: 583| Step: 0
Training loss: 0.7460250854492188
Validation loss: 1.616826647071428

Epoch: 6| Step: 1
Training loss: 0.891545295715332
Validation loss: 1.658348500087697

Epoch: 6| Step: 2
Training loss: 0.7066390514373779
Validation loss: 1.6847628880572576

Epoch: 6| Step: 3
Training loss: 0.8152982592582703
Validation loss: 1.566133149208561

Epoch: 6| Step: 4
Training loss: 0.7644303441047668
Validation loss: 1.6186802899965675

Epoch: 6| Step: 5
Training loss: 0.5574268102645874
Validation loss: 1.6006085590649677

Epoch: 6| Step: 6
Training loss: 0.5483211278915405
Validation loss: 1.605428026568505

Epoch: 6| Step: 7
Training loss: 0.8416783809661865
Validation loss: 1.6391614008975286

Epoch: 6| Step: 8
Training loss: 0.39885514974594116
Validation loss: 1.625767373269604

Epoch: 6| Step: 9
Training loss: 0.9030358195304871
Validation loss: 1.6516904125931442

Epoch: 6| Step: 10
Training loss: 0.47760164737701416
Validation loss: 1.6322707360790623

Epoch: 6| Step: 11
Training loss: 0.7674500942230225
Validation loss: 1.5827172802340599

Epoch: 6| Step: 12
Training loss: 0.6936245560646057
Validation loss: 1.5859351734961233

Epoch: 6| Step: 13
Training loss: 0.5678921937942505
Validation loss: 1.5915483082494428

Epoch: 584| Step: 0
Training loss: 0.79580157995224
Validation loss: 1.5902399478420135

Epoch: 6| Step: 1
Training loss: 1.0346662998199463
Validation loss: 1.5600160232154272

Epoch: 6| Step: 2
Training loss: 0.48462027311325073
Validation loss: 1.5606116466624762

Epoch: 6| Step: 3
Training loss: 0.7118169069290161
Validation loss: 1.6617467775139758

Epoch: 6| Step: 4
Training loss: 0.9815073609352112
Validation loss: 1.604138917820428

Epoch: 6| Step: 5
Training loss: 0.39369815587997437
Validation loss: 1.6352842725733274

Epoch: 6| Step: 6
Training loss: 0.6771585941314697
Validation loss: 1.626811344136474

Epoch: 6| Step: 7
Training loss: 0.7207629084587097
Validation loss: 1.6509616054514402

Epoch: 6| Step: 8
Training loss: 0.49919551610946655
Validation loss: 1.5801206301617365

Epoch: 6| Step: 9
Training loss: 0.5678297281265259
Validation loss: 1.5239282609314047

Epoch: 6| Step: 10
Training loss: 0.9244300127029419
Validation loss: 1.6244018129123154

Epoch: 6| Step: 11
Training loss: 0.9460361003875732
Validation loss: 1.6335577099554

Epoch: 6| Step: 12
Training loss: 0.7595772743225098
Validation loss: 1.656116295886296

Epoch: 6| Step: 13
Training loss: 0.5995246767997742
Validation loss: 1.6023131801236061

Epoch: 585| Step: 0
Training loss: 0.8913469314575195
Validation loss: 1.6108638830082391

Epoch: 6| Step: 1
Training loss: 0.6664700508117676
Validation loss: 1.5657964278292913

Epoch: 6| Step: 2
Training loss: 1.0678777694702148
Validation loss: 1.658207292197853

Epoch: 6| Step: 3
Training loss: 0.4116424322128296
Validation loss: 1.5936335914878434

Epoch: 6| Step: 4
Training loss: 0.3521624803543091
Validation loss: 1.6224191675903976

Epoch: 6| Step: 5
Training loss: 0.6704058647155762
Validation loss: 1.6217734262507448

Epoch: 6| Step: 6
Training loss: 0.7741338610649109
Validation loss: 1.6065467301235403

Epoch: 6| Step: 7
Training loss: 0.8292645215988159
Validation loss: 1.6230340260331348

Epoch: 6| Step: 8
Training loss: 0.48524370789527893
Validation loss: 1.6093077108424196

Epoch: 6| Step: 9
Training loss: 0.6902255415916443
Validation loss: 1.5928702662068028

Epoch: 6| Step: 10
Training loss: 0.8883408308029175
Validation loss: 1.591111292121231

Epoch: 6| Step: 11
Training loss: 0.6211484670639038
Validation loss: 1.6026792244244648

Epoch: 6| Step: 12
Training loss: 0.651971697807312
Validation loss: 1.6165821321548954

Epoch: 6| Step: 13
Training loss: 0.7747310996055603
Validation loss: 1.6243048098779493

Epoch: 586| Step: 0
Training loss: 1.1257874965667725
Validation loss: 1.662219823047679

Epoch: 6| Step: 1
Training loss: 0.5002169013023376
Validation loss: 1.607638983316319

Epoch: 6| Step: 2
Training loss: 0.7654051780700684
Validation loss: 1.6476732953902213

Epoch: 6| Step: 3
Training loss: 1.0622284412384033
Validation loss: 1.585430061304441

Epoch: 6| Step: 4
Training loss: 1.2499775886535645
Validation loss: 1.6031305238764773

Epoch: 6| Step: 5
Training loss: 0.6869478225708008
Validation loss: 1.6216385825987785

Epoch: 6| Step: 6
Training loss: 0.7527740001678467
Validation loss: 1.5768094972897602

Epoch: 6| Step: 7
Training loss: 0.3571544289588928
Validation loss: 1.6309538906620396

Epoch: 6| Step: 8
Training loss: 0.46849578619003296
Validation loss: 1.6281301065157818

Epoch: 6| Step: 9
Training loss: 0.6905834674835205
Validation loss: 1.6182719917707546

Epoch: 6| Step: 10
Training loss: 0.22773519158363342
Validation loss: 1.6385623895993797

Epoch: 6| Step: 11
Training loss: 0.6498708128929138
Validation loss: 1.5940369790600193

Epoch: 6| Step: 12
Training loss: 0.9383765459060669
Validation loss: 1.6527776269502537

Epoch: 6| Step: 13
Training loss: 0.6036185622215271
Validation loss: 1.6222379822884836

Epoch: 587| Step: 0
Training loss: 0.7641973495483398
Validation loss: 1.6134573695480183

Epoch: 6| Step: 1
Training loss: 0.5329626202583313
Validation loss: 1.6256557395381313

Epoch: 6| Step: 2
Training loss: 1.125259280204773
Validation loss: 1.6112848161369242

Epoch: 6| Step: 3
Training loss: 0.9647482633590698
Validation loss: 1.6386222582991405

Epoch: 6| Step: 4
Training loss: 0.5865068435668945
Validation loss: 1.6490931357106855

Epoch: 6| Step: 5
Training loss: 0.9632749557495117
Validation loss: 1.6300437078681043

Epoch: 6| Step: 6
Training loss: 0.6646814346313477
Validation loss: 1.6018884053794287

Epoch: 6| Step: 7
Training loss: 0.4709358811378479
Validation loss: 1.5884100352564166

Epoch: 6| Step: 8
Training loss: 0.4416429400444031
Validation loss: 1.5833228775250014

Epoch: 6| Step: 9
Training loss: 0.5310071110725403
Validation loss: 1.5736902042101788

Epoch: 6| Step: 10
Training loss: 0.8171833753585815
Validation loss: 1.5786189199775778

Epoch: 6| Step: 11
Training loss: 0.5992419719696045
Validation loss: 1.6029447535032868

Epoch: 6| Step: 12
Training loss: 0.49526000022888184
Validation loss: 1.6402756244905534

Epoch: 6| Step: 13
Training loss: 0.6371992230415344
Validation loss: 1.5804725616208968

Epoch: 588| Step: 0
Training loss: 0.5943371057510376
Validation loss: 1.6189406225758214

Epoch: 6| Step: 1
Training loss: 0.537259578704834
Validation loss: 1.6375079924060452

Epoch: 6| Step: 2
Training loss: 0.6197335720062256
Validation loss: 1.6459502891827655

Epoch: 6| Step: 3
Training loss: 0.7820324301719666
Validation loss: 1.60351445469805

Epoch: 6| Step: 4
Training loss: 0.5896173119544983
Validation loss: 1.6210075450199906

Epoch: 6| Step: 5
Training loss: 0.4294883906841278
Validation loss: 1.641037598732979

Epoch: 6| Step: 6
Training loss: 0.4034672677516937
Validation loss: 1.6369974959281184

Epoch: 6| Step: 7
Training loss: 1.0506565570831299
Validation loss: 1.628236242519912

Epoch: 6| Step: 8
Training loss: 0.6877849102020264
Validation loss: 1.5996177363139328

Epoch: 6| Step: 9
Training loss: 0.5139804482460022
Validation loss: 1.614710441199682

Epoch: 6| Step: 10
Training loss: 0.9762090444564819
Validation loss: 1.6407970305412047

Epoch: 6| Step: 11
Training loss: 0.9408645033836365
Validation loss: 1.6612463984438168

Epoch: 6| Step: 12
Training loss: 0.8033875823020935
Validation loss: 1.6092552395277127

Epoch: 6| Step: 13
Training loss: 0.46518558263778687
Validation loss: 1.652577095134284

Epoch: 589| Step: 0
Training loss: 0.38681358098983765
Validation loss: 1.6029066552398026

Epoch: 6| Step: 1
Training loss: 0.6966708898544312
Validation loss: 1.5760118666515555

Epoch: 6| Step: 2
Training loss: 0.48233771324157715
Validation loss: 1.6430383689941899

Epoch: 6| Step: 3
Training loss: 0.8233907222747803
Validation loss: 1.6601935137984574

Epoch: 6| Step: 4
Training loss: 0.8824123740196228
Validation loss: 1.6317644144899102

Epoch: 6| Step: 5
Training loss: 0.8468248248100281
Validation loss: 1.6425689279392202

Epoch: 6| Step: 6
Training loss: 0.8561128377914429
Validation loss: 1.629066255784804

Epoch: 6| Step: 7
Training loss: 0.4098733961582184
Validation loss: 1.589552217914212

Epoch: 6| Step: 8
Training loss: 0.511414110660553
Validation loss: 1.5905410243618874

Epoch: 6| Step: 9
Training loss: 0.8101568818092346
Validation loss: 1.6258545473057737

Epoch: 6| Step: 10
Training loss: 0.8036492466926575
Validation loss: 1.6032930599745883

Epoch: 6| Step: 11
Training loss: 0.593085527420044
Validation loss: 1.6482353838541175

Epoch: 6| Step: 12
Training loss: 0.736087441444397
Validation loss: 1.5680238867318759

Epoch: 6| Step: 13
Training loss: 1.3043158054351807
Validation loss: 1.6420604951920048

Epoch: 590| Step: 0
Training loss: 0.5774986147880554
Validation loss: 1.6418949186161

Epoch: 6| Step: 1
Training loss: 1.3449223041534424
Validation loss: 1.661793936965286

Epoch: 6| Step: 2
Training loss: 0.4845236837863922
Validation loss: 1.6025782618471371

Epoch: 6| Step: 3
Training loss: 0.5051265954971313
Validation loss: 1.624418907268073

Epoch: 6| Step: 4
Training loss: 0.5756585597991943
Validation loss: 1.6607919662229476

Epoch: 6| Step: 5
Training loss: 1.1588923931121826
Validation loss: 1.610677170497115

Epoch: 6| Step: 6
Training loss: 0.356842964887619
Validation loss: 1.6259709173633206

Epoch: 6| Step: 7
Training loss: 0.7893326282501221
Validation loss: 1.5974088714968773

Epoch: 6| Step: 8
Training loss: 0.619562029838562
Validation loss: 1.6423836651668753

Epoch: 6| Step: 9
Training loss: 0.48476845026016235
Validation loss: 1.6189281696914344

Epoch: 6| Step: 10
Training loss: 0.6573835611343384
Validation loss: 1.6256231300292476

Epoch: 6| Step: 11
Training loss: 0.8531779646873474
Validation loss: 1.6625747937028126

Epoch: 6| Step: 12
Training loss: 0.7694942951202393
Validation loss: 1.5642362961205103

Epoch: 6| Step: 13
Training loss: 0.7311360836029053
Validation loss: 1.5859870308188981

Epoch: 591| Step: 0
Training loss: 0.8681731820106506
Validation loss: 1.6326432317815802

Epoch: 6| Step: 1
Training loss: 0.6449439525604248
Validation loss: 1.6209731550626858

Epoch: 6| Step: 2
Training loss: 0.7406594753265381
Validation loss: 1.6238643853895125

Epoch: 6| Step: 3
Training loss: 0.7203290462493896
Validation loss: 1.633788412617099

Epoch: 6| Step: 4
Training loss: 0.6209592223167419
Validation loss: 1.614049812798859

Epoch: 6| Step: 5
Training loss: 1.6256933212280273
Validation loss: 1.624024264274105

Epoch: 6| Step: 6
Training loss: 0.6912447214126587
Validation loss: 1.6885324332021898

Epoch: 6| Step: 7
Training loss: 0.7260358333587646
Validation loss: 1.6251748146549347

Epoch: 6| Step: 8
Training loss: 0.6598357558250427
Validation loss: 1.6190053532200475

Epoch: 6| Step: 9
Training loss: 0.46393972635269165
Validation loss: 1.6492951685382473

Epoch: 6| Step: 10
Training loss: 0.5186301469802856
Validation loss: 1.592058866254745

Epoch: 6| Step: 11
Training loss: 0.33218106627464294
Validation loss: 1.6414685736420334

Epoch: 6| Step: 12
Training loss: 0.6675480604171753
Validation loss: 1.610152695768623

Epoch: 6| Step: 13
Training loss: 0.3938784599304199
Validation loss: 1.6233547246584328

Epoch: 592| Step: 0
Training loss: 0.5278706550598145
Validation loss: 1.5995444841282342

Epoch: 6| Step: 1
Training loss: 0.5678364634513855
Validation loss: 1.5968045688444568

Epoch: 6| Step: 2
Training loss: 0.7489705085754395
Validation loss: 1.6392575079394924

Epoch: 6| Step: 3
Training loss: 0.812005877494812
Validation loss: 1.6524639104002266

Epoch: 6| Step: 4
Training loss: 0.9704533815383911
Validation loss: 1.64930477962699

Epoch: 6| Step: 5
Training loss: 1.328317403793335
Validation loss: 1.6241497583286737

Epoch: 6| Step: 6
Training loss: 0.8425664901733398
Validation loss: 1.6683788658470236

Epoch: 6| Step: 7
Training loss: 0.4300696849822998
Validation loss: 1.6428007361709431

Epoch: 6| Step: 8
Training loss: 0.6984805464744568
Validation loss: 1.6449157217497468

Epoch: 6| Step: 9
Training loss: 0.5874042510986328
Validation loss: 1.638082750381962

Epoch: 6| Step: 10
Training loss: 0.4883948862552643
Validation loss: 1.59857645726973

Epoch: 6| Step: 11
Training loss: 0.6176270246505737
Validation loss: 1.6405869927457584

Epoch: 6| Step: 12
Training loss: 0.6095418930053711
Validation loss: 1.638369103913666

Epoch: 6| Step: 13
Training loss: 0.8679935932159424
Validation loss: 1.5981320258109801

Epoch: 593| Step: 0
Training loss: 1.1159255504608154
Validation loss: 1.5943349343474194

Epoch: 6| Step: 1
Training loss: 1.0805044174194336
Validation loss: 1.6423026951410438

Epoch: 6| Step: 2
Training loss: 0.8200488090515137
Validation loss: 1.617015754022906

Epoch: 6| Step: 3
Training loss: 0.5198540687561035
Validation loss: 1.627026774549997

Epoch: 6| Step: 4
Training loss: 0.5093291997909546
Validation loss: 1.5852354803392965

Epoch: 6| Step: 5
Training loss: 0.5640110373497009
Validation loss: 1.6433232856053177

Epoch: 6| Step: 6
Training loss: 0.567206859588623
Validation loss: 1.5980461758951987

Epoch: 6| Step: 7
Training loss: 0.6573861837387085
Validation loss: 1.6359809111523371

Epoch: 6| Step: 8
Training loss: 0.2750953137874603
Validation loss: 1.6482407572448894

Epoch: 6| Step: 9
Training loss: 0.6797412633895874
Validation loss: 1.6825470744922597

Epoch: 6| Step: 10
Training loss: 1.1003782749176025
Validation loss: 1.702666821018342

Epoch: 6| Step: 11
Training loss: 0.3934133052825928
Validation loss: 1.6544461442578224

Epoch: 6| Step: 12
Training loss: 0.6482348442077637
Validation loss: 1.6692375777870097

Epoch: 6| Step: 13
Training loss: 0.7840089797973633
Validation loss: 1.6280736654035506

Epoch: 594| Step: 0
Training loss: 0.43285858631134033
Validation loss: 1.6494986229045416

Epoch: 6| Step: 1
Training loss: 1.0668916702270508
Validation loss: 1.6280750613058768

Epoch: 6| Step: 2
Training loss: 0.3512364625930786
Validation loss: 1.6663224645840224

Epoch: 6| Step: 3
Training loss: 0.4119866192340851
Validation loss: 1.6153653514000677

Epoch: 6| Step: 4
Training loss: 0.44843804836273193
Validation loss: 1.6200579981650076

Epoch: 6| Step: 5
Training loss: 0.9496250152587891
Validation loss: 1.6541515652851393

Epoch: 6| Step: 6
Training loss: 0.8502007722854614
Validation loss: 1.7067001199209562

Epoch: 6| Step: 7
Training loss: 0.8475931882858276
Validation loss: 1.6302294333775837

Epoch: 6| Step: 8
Training loss: 0.5689321756362915
Validation loss: 1.6229698401625439

Epoch: 6| Step: 9
Training loss: 0.4983636140823364
Validation loss: 1.6134890484553512

Epoch: 6| Step: 10
Training loss: 1.0655755996704102
Validation loss: 1.6325522789391138

Epoch: 6| Step: 11
Training loss: 0.7265294194221497
Validation loss: 1.6198434906621133

Epoch: 6| Step: 12
Training loss: 0.7454874515533447
Validation loss: 1.6497506415972145

Epoch: 6| Step: 13
Training loss: 0.7560034990310669
Validation loss: 1.604189711232339

Epoch: 595| Step: 0
Training loss: 0.8514057397842407
Validation loss: 1.6362429408616916

Epoch: 6| Step: 1
Training loss: 0.35504093766212463
Validation loss: 1.6295410510032409

Epoch: 6| Step: 2
Training loss: 0.7101647257804871
Validation loss: 1.6307973771966913

Epoch: 6| Step: 3
Training loss: 0.986993670463562
Validation loss: 1.6424891923063545

Epoch: 6| Step: 4
Training loss: 0.2545839548110962
Validation loss: 1.6494617051975702

Epoch: 6| Step: 5
Training loss: 0.7338780164718628
Validation loss: 1.6078716183221469

Epoch: 6| Step: 6
Training loss: 0.5352067947387695
Validation loss: 1.5770403185198385

Epoch: 6| Step: 7
Training loss: 0.9993619918823242
Validation loss: 1.6048903695998653

Epoch: 6| Step: 8
Training loss: 0.5764579772949219
Validation loss: 1.5929794542251094

Epoch: 6| Step: 9
Training loss: 0.7766519784927368
Validation loss: 1.6055630791571833

Epoch: 6| Step: 10
Training loss: 0.6012149453163147
Validation loss: 1.6285626734456708

Epoch: 6| Step: 11
Training loss: 0.4965704679489136
Validation loss: 1.6283569694847189

Epoch: 6| Step: 12
Training loss: 0.5727287530899048
Validation loss: 1.6538446334100538

Epoch: 6| Step: 13
Training loss: 0.8920629024505615
Validation loss: 1.5928703020977717

Epoch: 596| Step: 0
Training loss: 0.6857998371124268
Validation loss: 1.614179608642414

Epoch: 6| Step: 1
Training loss: 0.6287822723388672
Validation loss: 1.602013571287996

Epoch: 6| Step: 2
Training loss: 0.6879426836967468
Validation loss: 1.6509199578274962

Epoch: 6| Step: 3
Training loss: 0.6126527786254883
Validation loss: 1.645558907139686

Epoch: 6| Step: 4
Training loss: 0.7719615697860718
Validation loss: 1.5801636313879361

Epoch: 6| Step: 5
Training loss: 0.5140978693962097
Validation loss: 1.633727858143468

Epoch: 6| Step: 6
Training loss: 0.6585856676101685
Validation loss: 1.6251131501249088

Epoch: 6| Step: 7
Training loss: 0.7853090763092041
Validation loss: 1.625624998923271

Epoch: 6| Step: 8
Training loss: 0.7961492538452148
Validation loss: 1.672121810656722

Epoch: 6| Step: 9
Training loss: 0.5738555192947388
Validation loss: 1.6032633589160057

Epoch: 6| Step: 10
Training loss: 1.4357502460479736
Validation loss: 1.6188946641901487

Epoch: 6| Step: 11
Training loss: 0.22635945677757263
Validation loss: 1.6353607869917346

Epoch: 6| Step: 12
Training loss: 0.6155889630317688
Validation loss: 1.6833320997094596

Epoch: 6| Step: 13
Training loss: 1.0508971214294434
Validation loss: 1.6292358745810807

Epoch: 597| Step: 0
Training loss: 0.48761171102523804
Validation loss: 1.6000770074065014

Epoch: 6| Step: 1
Training loss: 0.6033380031585693
Validation loss: 1.6542906940624278

Epoch: 6| Step: 2
Training loss: 1.1114314794540405
Validation loss: 1.5991836209450998

Epoch: 6| Step: 3
Training loss: 0.8583656549453735
Validation loss: 1.5886829591566516

Epoch: 6| Step: 4
Training loss: 0.596174955368042
Validation loss: 1.549050465706856

Epoch: 6| Step: 5
Training loss: 0.7356843948364258
Validation loss: 1.6498090349217898

Epoch: 6| Step: 6
Training loss: 0.8536459803581238
Validation loss: 1.5861493067074848

Epoch: 6| Step: 7
Training loss: 0.5664929151535034
Validation loss: 1.6176187248640164

Epoch: 6| Step: 8
Training loss: 0.7670953273773193
Validation loss: 1.5937169841540757

Epoch: 6| Step: 9
Training loss: 0.589079737663269
Validation loss: 1.561768792008841

Epoch: 6| Step: 10
Training loss: 0.5209088325500488
Validation loss: 1.5746206532242477

Epoch: 6| Step: 11
Training loss: 0.4174429178237915
Validation loss: 1.5834114166998094

Epoch: 6| Step: 12
Training loss: 0.676629900932312
Validation loss: 1.6496703406815887

Epoch: 6| Step: 13
Training loss: 0.35670003294944763
Validation loss: 1.6359283244738014

Epoch: 598| Step: 0
Training loss: 0.856439471244812
Validation loss: 1.6522225628616989

Epoch: 6| Step: 1
Training loss: 0.8535295128822327
Validation loss: 1.575656465304795

Epoch: 6| Step: 2
Training loss: 0.40486347675323486
Validation loss: 1.605281792661195

Epoch: 6| Step: 3
Training loss: 0.5339004993438721
Validation loss: 1.6177931831729027

Epoch: 6| Step: 4
Training loss: 0.5938143134117126
Validation loss: 1.6446895048182497

Epoch: 6| Step: 5
Training loss: 0.5402023792266846
Validation loss: 1.64178313491165

Epoch: 6| Step: 6
Training loss: 0.5450249910354614
Validation loss: 1.5844272625061773

Epoch: 6| Step: 7
Training loss: 0.9706870317459106
Validation loss: 1.6358376446590628

Epoch: 6| Step: 8
Training loss: 1.1795721054077148
Validation loss: 1.610048129994382

Epoch: 6| Step: 9
Training loss: 0.47961366176605225
Validation loss: 1.6131126598645282

Epoch: 6| Step: 10
Training loss: 0.7179092168807983
Validation loss: 1.5845273617775208

Epoch: 6| Step: 11
Training loss: 0.7729990482330322
Validation loss: 1.5906208407494329

Epoch: 6| Step: 12
Training loss: 0.43445903062820435
Validation loss: 1.6177190683221305

Epoch: 6| Step: 13
Training loss: 0.5005719661712646
Validation loss: 1.6332753704440208

Epoch: 599| Step: 0
Training loss: 0.74921715259552
Validation loss: 1.6571812809154551

Epoch: 6| Step: 1
Training loss: 0.366863489151001
Validation loss: 1.676331207316409

Epoch: 6| Step: 2
Training loss: 1.0792186260223389
Validation loss: 1.625496260581478

Epoch: 6| Step: 3
Training loss: 0.6284748315811157
Validation loss: 1.6603372712289133

Epoch: 6| Step: 4
Training loss: 0.422115683555603
Validation loss: 1.663900343320703

Epoch: 6| Step: 5
Training loss: 0.4336526393890381
Validation loss: 1.602114604365441

Epoch: 6| Step: 6
Training loss: 0.9000855684280396
Validation loss: 1.613594166694149

Epoch: 6| Step: 7
Training loss: 0.8101927042007446
Validation loss: 1.5703798212030882

Epoch: 6| Step: 8
Training loss: 0.5899339318275452
Validation loss: 1.563605684106068

Epoch: 6| Step: 9
Training loss: 0.7307471632957458
Validation loss: 1.5957684260542675

Epoch: 6| Step: 10
Training loss: 0.8118155598640442
Validation loss: 1.5444351678253503

Epoch: 6| Step: 11
Training loss: 0.7306365370750427
Validation loss: 1.5859146912892659

Epoch: 6| Step: 12
Training loss: 0.5853750705718994
Validation loss: 1.617044178388452

Epoch: 6| Step: 13
Training loss: 0.6486040353775024
Validation loss: 1.568234960238139

Epoch: 600| Step: 0
Training loss: 0.7830864191055298
Validation loss: 1.5974781410668486

Epoch: 6| Step: 1
Training loss: 0.7167980670928955
Validation loss: 1.5810247672501432

Epoch: 6| Step: 2
Training loss: 0.9208215475082397
Validation loss: 1.6137315560412664

Epoch: 6| Step: 3
Training loss: 0.6248201727867126
Validation loss: 1.586605970577527

Epoch: 6| Step: 4
Training loss: 0.6162787675857544
Validation loss: 1.6308735429599721

Epoch: 6| Step: 5
Training loss: 0.6470247507095337
Validation loss: 1.5887294994887484

Epoch: 6| Step: 6
Training loss: 1.2432751655578613
Validation loss: 1.62466053424343

Epoch: 6| Step: 7
Training loss: 0.4995105564594269
Validation loss: 1.5843240676387664

Epoch: 6| Step: 8
Training loss: 0.6589782238006592
Validation loss: 1.6447630646408244

Epoch: 6| Step: 9
Training loss: 0.5317970514297485
Validation loss: 1.6319030010572044

Epoch: 6| Step: 10
Training loss: 0.4267456829547882
Validation loss: 1.5765424313083771

Epoch: 6| Step: 11
Training loss: 0.4784560799598694
Validation loss: 1.6289022507206086

Epoch: 6| Step: 12
Training loss: 0.5110377669334412
Validation loss: 1.6034516314024567

Epoch: 6| Step: 13
Training loss: 0.6307138800621033
Validation loss: 1.6088967502758067

Epoch: 601| Step: 0
Training loss: 0.7729760408401489
Validation loss: 1.606920834510557

Epoch: 6| Step: 1
Training loss: 0.998109757900238
Validation loss: 1.6192255994325042

Epoch: 6| Step: 2
Training loss: 0.3949093818664551
Validation loss: 1.6561292871352165

Epoch: 6| Step: 3
Training loss: 0.6002728343009949
Validation loss: 1.602517815046413

Epoch: 6| Step: 4
Training loss: 0.535765528678894
Validation loss: 1.6089960913504324

Epoch: 6| Step: 5
Training loss: 0.727425217628479
Validation loss: 1.6446711478694793

Epoch: 6| Step: 6
Training loss: 0.558017373085022
Validation loss: 1.6141580176609818

Epoch: 6| Step: 7
Training loss: 1.1651277542114258
Validation loss: 1.6177055028177076

Epoch: 6| Step: 8
Training loss: 0.5207729339599609
Validation loss: 1.6112162297771824

Epoch: 6| Step: 9
Training loss: 0.6333692073822021
Validation loss: 1.6368910445961902

Epoch: 6| Step: 10
Training loss: 0.49333685636520386
Validation loss: 1.6005071029868176

Epoch: 6| Step: 11
Training loss: 0.567089319229126
Validation loss: 1.6370625303637596

Epoch: 6| Step: 12
Training loss: 0.79771888256073
Validation loss: 1.650829138294343

Epoch: 6| Step: 13
Training loss: 0.5652005672454834
Validation loss: 1.6137049480151104

Epoch: 602| Step: 0
Training loss: 1.3588942289352417
Validation loss: 1.6139731996802873

Epoch: 6| Step: 1
Training loss: 0.6854491233825684
Validation loss: 1.605975982963398

Epoch: 6| Step: 2
Training loss: 0.59991455078125
Validation loss: 1.6372106075286865

Epoch: 6| Step: 3
Training loss: 0.7482336759567261
Validation loss: 1.6040105281337615

Epoch: 6| Step: 4
Training loss: 0.5400570631027222
Validation loss: 1.6271255349600187

Epoch: 6| Step: 5
Training loss: 0.6042130589485168
Validation loss: 1.598656641539707

Epoch: 6| Step: 6
Training loss: 0.48379433155059814
Validation loss: 1.6067009343895862

Epoch: 6| Step: 7
Training loss: 0.6555740833282471
Validation loss: 1.6821806879453762

Epoch: 6| Step: 8
Training loss: 0.7619664669036865
Validation loss: 1.6237832769270866

Epoch: 6| Step: 9
Training loss: 0.42256972193717957
Validation loss: 1.6050644356717345

Epoch: 6| Step: 10
Training loss: 0.6176373958587646
Validation loss: 1.6272388376215452

Epoch: 6| Step: 11
Training loss: 0.6809554696083069
Validation loss: 1.628218461108464

Epoch: 6| Step: 12
Training loss: 0.4415106773376465
Validation loss: 1.6387963794892835

Epoch: 6| Step: 13
Training loss: 0.9589076638221741
Validation loss: 1.6153717643471175

Epoch: 603| Step: 0
Training loss: 0.5390193462371826
Validation loss: 1.6069354549531014

Epoch: 6| Step: 1
Training loss: 0.4494197368621826
Validation loss: 1.5970633299120012

Epoch: 6| Step: 2
Training loss: 0.8640300035476685
Validation loss: 1.600676287886917

Epoch: 6| Step: 3
Training loss: 0.9632737040519714
Validation loss: 1.598398345772938

Epoch: 6| Step: 4
Training loss: 0.7148014307022095
Validation loss: 1.6311939659939017

Epoch: 6| Step: 5
Training loss: 0.6911351680755615
Validation loss: 1.6169310346726449

Epoch: 6| Step: 6
Training loss: 0.8609955310821533
Validation loss: 1.5894766212791525

Epoch: 6| Step: 7
Training loss: 0.5161466598510742
Validation loss: 1.6103355820460985

Epoch: 6| Step: 8
Training loss: 0.5379917621612549
Validation loss: 1.6220013133941158

Epoch: 6| Step: 9
Training loss: 0.887757420539856
Validation loss: 1.5977468516236992

Epoch: 6| Step: 10
Training loss: 0.8255228400230408
Validation loss: 1.550567711553266

Epoch: 6| Step: 11
Training loss: 0.3705750107765198
Validation loss: 1.5377094694363174

Epoch: 6| Step: 12
Training loss: 0.5775868892669678
Validation loss: 1.6065471133878153

Epoch: 6| Step: 13
Training loss: 0.5843894481658936
Validation loss: 1.6005690969446653

Epoch: 604| Step: 0
Training loss: 1.2735779285430908
Validation loss: 1.5504366313257525

Epoch: 6| Step: 1
Training loss: 0.9130984544754028
Validation loss: 1.5857715337507186

Epoch: 6| Step: 2
Training loss: 0.7062434554100037
Validation loss: 1.5777617231492074

Epoch: 6| Step: 3
Training loss: 0.6822423934936523
Validation loss: 1.6059146004338418

Epoch: 6| Step: 4
Training loss: 0.6686066389083862
Validation loss: 1.604906488490361

Epoch: 6| Step: 5
Training loss: 0.5073962211608887
Validation loss: 1.5963687640364452

Epoch: 6| Step: 6
Training loss: 0.646347165107727
Validation loss: 1.583072453416804

Epoch: 6| Step: 7
Training loss: 0.35500001907348633
Validation loss: 1.5973876407069545

Epoch: 6| Step: 8
Training loss: 0.5687015056610107
Validation loss: 1.6457844562427972

Epoch: 6| Step: 9
Training loss: 0.5033389925956726
Validation loss: 1.5780197625519128

Epoch: 6| Step: 10
Training loss: 0.7809680700302124
Validation loss: 1.5964450772090624

Epoch: 6| Step: 11
Training loss: 0.7663017511367798
Validation loss: 1.5762295274324314

Epoch: 6| Step: 12
Training loss: 0.6762064099311829
Validation loss: 1.588669849980262

Epoch: 6| Step: 13
Training loss: 0.4245671033859253
Validation loss: 1.6058293581008911

Epoch: 605| Step: 0
Training loss: 0.6550403833389282
Validation loss: 1.5903076510275564

Epoch: 6| Step: 1
Training loss: 0.6800680756568909
Validation loss: 1.6634628926554034

Epoch: 6| Step: 2
Training loss: 0.6784868240356445
Validation loss: 1.5740214509348716

Epoch: 6| Step: 3
Training loss: 0.5651973485946655
Validation loss: 1.5618753330681914

Epoch: 6| Step: 4
Training loss: 0.7757887244224548
Validation loss: 1.6250426935893234

Epoch: 6| Step: 5
Training loss: 0.7172505855560303
Validation loss: 1.6509820517673288

Epoch: 6| Step: 6
Training loss: 0.6253253221511841
Validation loss: 1.5934187212297994

Epoch: 6| Step: 7
Training loss: 0.7902092933654785
Validation loss: 1.6381560922950826

Epoch: 6| Step: 8
Training loss: 0.4327443242073059
Validation loss: 1.6210370486782444

Epoch: 6| Step: 9
Training loss: 0.4580965042114258
Validation loss: 1.5937671738286172

Epoch: 6| Step: 10
Training loss: 0.5765868425369263
Validation loss: 1.6452555733342324

Epoch: 6| Step: 11
Training loss: 0.6334228515625
Validation loss: 1.6429406417313444

Epoch: 6| Step: 12
Training loss: 1.1371663808822632
Validation loss: 1.5670154748424407

Epoch: 6| Step: 13
Training loss: 0.736708402633667
Validation loss: 1.6072058934037403

Epoch: 606| Step: 0
Training loss: 0.5256356000900269
Validation loss: 1.6259612178289762

Epoch: 6| Step: 1
Training loss: 0.7996287941932678
Validation loss: 1.6580574409936064

Epoch: 6| Step: 2
Training loss: 0.5729894638061523
Validation loss: 1.643089545670376

Epoch: 6| Step: 3
Training loss: 0.8992141485214233
Validation loss: 1.5887136331168554

Epoch: 6| Step: 4
Training loss: 0.9060258269309998
Validation loss: 1.6373389100515714

Epoch: 6| Step: 5
Training loss: 0.4302534759044647
Validation loss: 1.5704913152161466

Epoch: 6| Step: 6
Training loss: 1.0213119983673096
Validation loss: 1.6376456240172028

Epoch: 6| Step: 7
Training loss: 0.4453883171081543
Validation loss: 1.602863920632229

Epoch: 6| Step: 8
Training loss: 0.6870008707046509
Validation loss: 1.6263551519763084

Epoch: 6| Step: 9
Training loss: 0.48313555121421814
Validation loss: 1.6389984174441266

Epoch: 6| Step: 10
Training loss: 0.6328222155570984
Validation loss: 1.640999900397434

Epoch: 6| Step: 11
Training loss: 0.6095730662345886
Validation loss: 1.6159206859527095

Epoch: 6| Step: 12
Training loss: 0.7606829404830933
Validation loss: 1.617288508722859

Epoch: 6| Step: 13
Training loss: 0.5390284061431885
Validation loss: 1.5881963878549554

Epoch: 607| Step: 0
Training loss: 0.731791079044342
Validation loss: 1.639721853758699

Epoch: 6| Step: 1
Training loss: 0.7493740916252136
Validation loss: 1.6286831978828675

Epoch: 6| Step: 2
Training loss: 0.7075778245925903
Validation loss: 1.558418684108283

Epoch: 6| Step: 3
Training loss: 0.5464239716529846
Validation loss: 1.5761756140698668

Epoch: 6| Step: 4
Training loss: 0.5216203927993774
Validation loss: 1.5782473471856886

Epoch: 6| Step: 5
Training loss: 0.40809908509254456
Validation loss: 1.557811725524164

Epoch: 6| Step: 6
Training loss: 0.8269203305244446
Validation loss: 1.6205182421591975

Epoch: 6| Step: 7
Training loss: 0.8078609108924866
Validation loss: 1.625808831184141

Epoch: 6| Step: 8
Training loss: 0.4720273017883301
Validation loss: 1.635695121621573

Epoch: 6| Step: 9
Training loss: 0.6336789131164551
Validation loss: 1.6284118237033967

Epoch: 6| Step: 10
Training loss: 0.8231036067008972
Validation loss: 1.611679857777011

Epoch: 6| Step: 11
Training loss: 0.4409918487071991
Validation loss: 1.619083349422742

Epoch: 6| Step: 12
Training loss: 0.898632287979126
Validation loss: 1.6269767374120734

Epoch: 6| Step: 13
Training loss: 0.4650120139122009
Validation loss: 1.5749428220974502

Epoch: 608| Step: 0
Training loss: 0.7132148742675781
Validation loss: 1.6111524822891399

Epoch: 6| Step: 1
Training loss: 0.4705687165260315
Validation loss: 1.6018932897557494

Epoch: 6| Step: 2
Training loss: 1.15680992603302
Validation loss: 1.652052253805181

Epoch: 6| Step: 3
Training loss: 0.6590477824211121
Validation loss: 1.6231598469518846

Epoch: 6| Step: 4
Training loss: 0.680102527141571
Validation loss: 1.6646705699223343

Epoch: 6| Step: 5
Training loss: 0.9349464178085327
Validation loss: 1.622143139121353

Epoch: 6| Step: 6
Training loss: 0.8869722485542297
Validation loss: 1.5965204213255195

Epoch: 6| Step: 7
Training loss: 0.40253040194511414
Validation loss: 1.5804444154103596

Epoch: 6| Step: 8
Training loss: 0.40665626525878906
Validation loss: 1.6463506580680929

Epoch: 6| Step: 9
Training loss: 0.7623133063316345
Validation loss: 1.5957075524073776

Epoch: 6| Step: 10
Training loss: 0.6522983312606812
Validation loss: 1.6009780924807313

Epoch: 6| Step: 11
Training loss: 0.4558637738227844
Validation loss: 1.5186664019861529

Epoch: 6| Step: 12
Training loss: 0.7028878927230835
Validation loss: 1.6316505593638266

Epoch: 6| Step: 13
Training loss: 0.5144968032836914
Validation loss: 1.6051489794126121

Epoch: 609| Step: 0
Training loss: 0.5492421388626099
Validation loss: 1.6968746672394455

Epoch: 6| Step: 1
Training loss: 0.6912882328033447
Validation loss: 1.626241789069227

Epoch: 6| Step: 2
Training loss: 0.9456818699836731
Validation loss: 1.568537909497497

Epoch: 6| Step: 3
Training loss: 0.8028081655502319
Validation loss: 1.5984636301635413

Epoch: 6| Step: 4
Training loss: 0.5479177236557007
Validation loss: 1.5789730356585594

Epoch: 6| Step: 5
Training loss: 0.29626139998435974
Validation loss: 1.6516386206432054

Epoch: 6| Step: 6
Training loss: 1.1267802715301514
Validation loss: 1.5802657770854172

Epoch: 6| Step: 7
Training loss: 0.7961215972900391
Validation loss: 1.610324175127091

Epoch: 6| Step: 8
Training loss: 0.559429407119751
Validation loss: 1.6442678718156711

Epoch: 6| Step: 9
Training loss: 0.30516770482063293
Validation loss: 1.6139867703119914

Epoch: 6| Step: 10
Training loss: 1.168818473815918
Validation loss: 1.6185609332976802

Epoch: 6| Step: 11
Training loss: 0.467285692691803
Validation loss: 1.5933307358013686

Epoch: 6| Step: 12
Training loss: 0.6424052715301514
Validation loss: 1.595123291015625

Epoch: 6| Step: 13
Training loss: 0.48418235778808594
Validation loss: 1.5846197143677743

Epoch: 610| Step: 0
Training loss: 0.4267118573188782
Validation loss: 1.5784458498800955

Epoch: 6| Step: 1
Training loss: 0.5828452706336975
Validation loss: 1.582011640712779

Epoch: 6| Step: 2
Training loss: 0.9370336532592773
Validation loss: 1.593368754591993

Epoch: 6| Step: 3
Training loss: 0.918470025062561
Validation loss: 1.6156229972839355

Epoch: 6| Step: 4
Training loss: 0.9914810657501221
Validation loss: 1.5785668690999348

Epoch: 6| Step: 5
Training loss: 0.5601739883422852
Validation loss: 1.552337484975015

Epoch: 6| Step: 6
Training loss: 0.5295519828796387
Validation loss: 1.6283840017934

Epoch: 6| Step: 7
Training loss: 0.3935050368309021
Validation loss: 1.7041576998208159

Epoch: 6| Step: 8
Training loss: 0.8815010190010071
Validation loss: 1.6184219903843378

Epoch: 6| Step: 9
Training loss: 0.5674639940261841
Validation loss: 1.567932867234753

Epoch: 6| Step: 10
Training loss: 0.7832404971122742
Validation loss: 1.543128111029184

Epoch: 6| Step: 11
Training loss: 0.5770704746246338
Validation loss: 1.5922721983284078

Epoch: 6| Step: 12
Training loss: 0.38560211658477783
Validation loss: 1.6017752603818012

Epoch: 6| Step: 13
Training loss: 0.49970531463623047
Validation loss: 1.571482766059137

Epoch: 611| Step: 0
Training loss: 0.750006377696991
Validation loss: 1.608368033362973

Epoch: 6| Step: 1
Training loss: 1.3093308210372925
Validation loss: 1.6052311953677927

Epoch: 6| Step: 2
Training loss: 0.4473817050457001
Validation loss: 1.6173948677637244

Epoch: 6| Step: 3
Training loss: 0.4626401662826538
Validation loss: 1.5591612823547856

Epoch: 6| Step: 4
Training loss: 0.795566976070404
Validation loss: 1.6656418654226488

Epoch: 6| Step: 5
Training loss: 0.8403868675231934
Validation loss: 1.6201031028583486

Epoch: 6| Step: 6
Training loss: 0.725899338722229
Validation loss: 1.6835274927077755

Epoch: 6| Step: 7
Training loss: 0.7039756774902344
Validation loss: 1.6195956430127543

Epoch: 6| Step: 8
Training loss: 0.6951302289962769
Validation loss: 1.588365408682054

Epoch: 6| Step: 9
Training loss: 0.5841672420501709
Validation loss: 1.6500281133959371

Epoch: 6| Step: 10
Training loss: 0.4949985444545746
Validation loss: 1.5755265066700597

Epoch: 6| Step: 11
Training loss: 0.45012277364730835
Validation loss: 1.6502937475840251

Epoch: 6| Step: 12
Training loss: 0.32609325647354126
Validation loss: 1.586688736433624

Epoch: 6| Step: 13
Training loss: 0.888025164604187
Validation loss: 1.5963940620422363

Epoch: 612| Step: 0
Training loss: 0.9977405071258545
Validation loss: 1.602170854486445

Epoch: 6| Step: 1
Training loss: 0.5835292339324951
Validation loss: 1.5639108047690442

Epoch: 6| Step: 2
Training loss: 0.4862625002861023
Validation loss: 1.60243780766764

Epoch: 6| Step: 3
Training loss: 1.3903603553771973
Validation loss: 1.6423840445856894

Epoch: 6| Step: 4
Training loss: 0.7964128255844116
Validation loss: 1.6010621311844035

Epoch: 6| Step: 5
Training loss: 0.7831159830093384
Validation loss: 1.6176068782806396

Epoch: 6| Step: 6
Training loss: 0.5006178617477417
Validation loss: 1.61016450389739

Epoch: 6| Step: 7
Training loss: 0.6368621587753296
Validation loss: 1.6205010721760411

Epoch: 6| Step: 8
Training loss: 0.39166632294654846
Validation loss: 1.6228946191008373

Epoch: 6| Step: 9
Training loss: 0.5843591690063477
Validation loss: 1.555718880827709

Epoch: 6| Step: 10
Training loss: 0.5532174706459045
Validation loss: 1.5992933011824084

Epoch: 6| Step: 11
Training loss: 0.8114814758300781
Validation loss: 1.6368870683895644

Epoch: 6| Step: 12
Training loss: 0.4309931993484497
Validation loss: 1.6115811114670129

Epoch: 6| Step: 13
Training loss: 0.3102991282939911
Validation loss: 1.5864499756084975

Epoch: 613| Step: 0
Training loss: 0.7621296644210815
Validation loss: 1.5936047966762255

Epoch: 6| Step: 1
Training loss: 0.5010421276092529
Validation loss: 1.6002599488022506

Epoch: 6| Step: 2
Training loss: 0.6954103112220764
Validation loss: 1.6243475842219528

Epoch: 6| Step: 3
Training loss: 0.4994208812713623
Validation loss: 1.5803799180574314

Epoch: 6| Step: 4
Training loss: 0.7268089056015015
Validation loss: 1.6656763630528604

Epoch: 6| Step: 5
Training loss: 0.5127677917480469
Validation loss: 1.6349620344818279

Epoch: 6| Step: 6
Training loss: 0.654032826423645
Validation loss: 1.6291380889954106

Epoch: 6| Step: 7
Training loss: 0.5912996530532837
Validation loss: 1.6053576354057557

Epoch: 6| Step: 8
Training loss: 1.19118332862854
Validation loss: 1.6105041164223866

Epoch: 6| Step: 9
Training loss: 0.6143895983695984
Validation loss: 1.632424957008772

Epoch: 6| Step: 10
Training loss: 0.845180869102478
Validation loss: 1.6357648770014446

Epoch: 6| Step: 11
Training loss: 0.5934118628501892
Validation loss: 1.5824953971370574

Epoch: 6| Step: 12
Training loss: 0.48572275042533875
Validation loss: 1.569908401017548

Epoch: 6| Step: 13
Training loss: 0.45459598302841187
Validation loss: 1.5965277277013308

Epoch: 614| Step: 0
Training loss: 1.0304701328277588
Validation loss: 1.5900204720035676

Epoch: 6| Step: 1
Training loss: 0.5495801568031311
Validation loss: 1.5762705226098337

Epoch: 6| Step: 2
Training loss: 0.7258661985397339
Validation loss: 1.6390742601886872

Epoch: 6| Step: 3
Training loss: 0.7277160882949829
Validation loss: 1.564903175959023

Epoch: 6| Step: 4
Training loss: 0.62663733959198
Validation loss: 1.5715014806357763

Epoch: 6| Step: 5
Training loss: 0.8428788185119629
Validation loss: 1.6016683437490975

Epoch: 6| Step: 6
Training loss: 0.5676900744438171
Validation loss: 1.5874891665674025

Epoch: 6| Step: 7
Training loss: 0.6119869351387024
Validation loss: 1.5185132154854395

Epoch: 6| Step: 8
Training loss: 0.5625545978546143
Validation loss: 1.5790013100511284

Epoch: 6| Step: 9
Training loss: 0.691352367401123
Validation loss: 1.6047996577396189

Epoch: 6| Step: 10
Training loss: 0.5914285182952881
Validation loss: 1.6138852257882395

Epoch: 6| Step: 11
Training loss: 0.6145451068878174
Validation loss: 1.5943219225893739

Epoch: 6| Step: 12
Training loss: 0.5232105851173401
Validation loss: 1.6374693057870353

Epoch: 6| Step: 13
Training loss: 0.6810598373413086
Validation loss: 1.6073030323110602

Epoch: 615| Step: 0
Training loss: 0.8435585498809814
Validation loss: 1.5674750240900184

Epoch: 6| Step: 1
Training loss: 0.7784470915794373
Validation loss: 1.5790753121017127

Epoch: 6| Step: 2
Training loss: 0.551379919052124
Validation loss: 1.5525002620553459

Epoch: 6| Step: 3
Training loss: 0.2724582552909851
Validation loss: 1.5736285140437465

Epoch: 6| Step: 4
Training loss: 0.7380599975585938
Validation loss: 1.5606918924598283

Epoch: 6| Step: 5
Training loss: 0.8511753082275391
Validation loss: 1.6095601160039184

Epoch: 6| Step: 6
Training loss: 0.6204582452774048
Validation loss: 1.5890510466790968

Epoch: 6| Step: 7
Training loss: 0.5810160636901855
Validation loss: 1.6194632745558215

Epoch: 6| Step: 8
Training loss: 0.5342075824737549
Validation loss: 1.5582569376114876

Epoch: 6| Step: 9
Training loss: 0.5679100155830383
Validation loss: 1.6196355447974256

Epoch: 6| Step: 10
Training loss: 0.634121298789978
Validation loss: 1.6451929820481168

Epoch: 6| Step: 11
Training loss: 0.4811255633831024
Validation loss: 1.5833619358719035

Epoch: 6| Step: 12
Training loss: 0.43685364723205566
Validation loss: 1.5696061913685133

Epoch: 6| Step: 13
Training loss: 1.166500210762024
Validation loss: 1.5705427521018571

Epoch: 616| Step: 0
Training loss: 0.6471933722496033
Validation loss: 1.6553551125270065

Epoch: 6| Step: 1
Training loss: 0.6829414963722229
Validation loss: 1.545946067379367

Epoch: 6| Step: 2
Training loss: 0.4830731153488159
Validation loss: 1.6076329215880363

Epoch: 6| Step: 3
Training loss: 0.797325611114502
Validation loss: 1.647112161882462

Epoch: 6| Step: 4
Training loss: 0.5252782106399536
Validation loss: 1.607903407466027

Epoch: 6| Step: 5
Training loss: 0.5825415849685669
Validation loss: 1.624647243048555

Epoch: 6| Step: 6
Training loss: 0.7723433375358582
Validation loss: 1.6112177346342353

Epoch: 6| Step: 7
Training loss: 0.5653387904167175
Validation loss: 1.57868561180689

Epoch: 6| Step: 8
Training loss: 0.5663453340530396
Validation loss: 1.6680946760280158

Epoch: 6| Step: 9
Training loss: 1.233921766281128
Validation loss: 1.6183865621525755

Epoch: 6| Step: 10
Training loss: 0.4707198739051819
Validation loss: 1.5543540959717126

Epoch: 6| Step: 11
Training loss: 0.7980168461799622
Validation loss: 1.559956342943253

Epoch: 6| Step: 12
Training loss: 0.5527747869491577
Validation loss: 1.6375342312679495

Epoch: 6| Step: 13
Training loss: 0.4033134877681732
Validation loss: 1.670744735707519

Epoch: 617| Step: 0
Training loss: 0.6541177034378052
Validation loss: 1.6299941103945497

Epoch: 6| Step: 1
Training loss: 1.1453807353973389
Validation loss: 1.5240778756398026

Epoch: 6| Step: 2
Training loss: 0.5800253748893738
Validation loss: 1.5722627793588946

Epoch: 6| Step: 3
Training loss: 0.6785614490509033
Validation loss: 1.6293316066906016

Epoch: 6| Step: 4
Training loss: 0.7378279566764832
Validation loss: 1.655551238726544

Epoch: 6| Step: 5
Training loss: 0.96784508228302
Validation loss: 1.6088241492548296

Epoch: 6| Step: 6
Training loss: 0.37987953424453735
Validation loss: 1.6298877423809421

Epoch: 6| Step: 7
Training loss: 0.3644442558288574
Validation loss: 1.625807798036965

Epoch: 6| Step: 8
Training loss: 0.9816747903823853
Validation loss: 1.5669650236765544

Epoch: 6| Step: 9
Training loss: 0.591079831123352
Validation loss: 1.5332503293150215

Epoch: 6| Step: 10
Training loss: 0.4912375807762146
Validation loss: 1.561164144546755

Epoch: 6| Step: 11
Training loss: 0.6096360683441162
Validation loss: 1.572777376380018

Epoch: 6| Step: 12
Training loss: 0.7006254196166992
Validation loss: 1.5668249027703398

Epoch: 6| Step: 13
Training loss: 0.3519102931022644
Validation loss: 1.5402732767084593

Epoch: 618| Step: 0
Training loss: 0.5463649034500122
Validation loss: 1.5687347253163655

Epoch: 6| Step: 1
Training loss: 0.6665072441101074
Validation loss: 1.5389778575589579

Epoch: 6| Step: 2
Training loss: 0.3626123070716858
Validation loss: 1.5465310658178022

Epoch: 6| Step: 3
Training loss: 0.6900424957275391
Validation loss: 1.5385549747815697

Epoch: 6| Step: 4
Training loss: 0.5453317165374756
Validation loss: 1.57050871592696

Epoch: 6| Step: 5
Training loss: 0.8041964769363403
Validation loss: 1.593935610145651

Epoch: 6| Step: 6
Training loss: 0.32117071747779846
Validation loss: 1.5586199055435837

Epoch: 6| Step: 7
Training loss: 0.9597969055175781
Validation loss: 1.5715293448458436

Epoch: 6| Step: 8
Training loss: 0.7198042273521423
Validation loss: 1.55538313106824

Epoch: 6| Step: 9
Training loss: 0.5987926721572876
Validation loss: 1.568883051154434

Epoch: 6| Step: 10
Training loss: 0.3905019760131836
Validation loss: 1.56312164696314

Epoch: 6| Step: 11
Training loss: 0.8569867610931396
Validation loss: 1.5539957246472758

Epoch: 6| Step: 12
Training loss: 0.8175036311149597
Validation loss: 1.551726584793419

Epoch: 6| Step: 13
Training loss: 0.8762567043304443
Validation loss: 1.6393186148776804

Epoch: 619| Step: 0
Training loss: 0.6295679807662964
Validation loss: 1.5519729301493654

Epoch: 6| Step: 1
Training loss: 0.9146565198898315
Validation loss: 1.6467632350101267

Epoch: 6| Step: 2
Training loss: 0.7704856395721436
Validation loss: 1.5949473406678887

Epoch: 6| Step: 3
Training loss: 0.8616669178009033
Validation loss: 1.644085758475847

Epoch: 6| Step: 4
Training loss: 0.4511725902557373
Validation loss: 1.633735820811282

Epoch: 6| Step: 5
Training loss: 0.7661552429199219
Validation loss: 1.5776082136297738

Epoch: 6| Step: 6
Training loss: 0.6755582094192505
Validation loss: 1.6740178344070271

Epoch: 6| Step: 7
Training loss: 0.8632758259773254
Validation loss: 1.6436350730157667

Epoch: 6| Step: 8
Training loss: 0.4662567377090454
Validation loss: 1.6046433525700723

Epoch: 6| Step: 9
Training loss: 0.3085104823112488
Validation loss: 1.6501650605150449

Epoch: 6| Step: 10
Training loss: 0.5167409777641296
Validation loss: 1.6269995089500182

Epoch: 6| Step: 11
Training loss: 0.546173095703125
Validation loss: 1.6967604160308838

Epoch: 6| Step: 12
Training loss: 0.6560187339782715
Validation loss: 1.6033069702886766

Epoch: 6| Step: 13
Training loss: 0.5542997717857361
Validation loss: 1.5820563685509466

Epoch: 620| Step: 0
Training loss: 0.5877923369407654
Validation loss: 1.5869711919497418

Epoch: 6| Step: 1
Training loss: 0.6853473782539368
Validation loss: 1.6055528656128915

Epoch: 6| Step: 2
Training loss: 0.4409174621105194
Validation loss: 1.6100657774556069

Epoch: 6| Step: 3
Training loss: 0.450133353471756
Validation loss: 1.5712931579159153

Epoch: 6| Step: 4
Training loss: 0.9565316438674927
Validation loss: 1.6105530652948605

Epoch: 6| Step: 5
Training loss: 0.6692845821380615
Validation loss: 1.5816206355248728

Epoch: 6| Step: 6
Training loss: 0.7328495979309082
Validation loss: 1.5768084820880686

Epoch: 6| Step: 7
Training loss: 0.5666862726211548
Validation loss: 1.5307407366332186

Epoch: 6| Step: 8
Training loss: 0.6440215110778809
Validation loss: 1.5694152129593717

Epoch: 6| Step: 9
Training loss: 0.7141679525375366
Validation loss: 1.670686339819303

Epoch: 6| Step: 10
Training loss: 0.4362223446369171
Validation loss: 1.6016114886089037

Epoch: 6| Step: 11
Training loss: 1.0941287279129028
Validation loss: 1.647506042193341

Epoch: 6| Step: 12
Training loss: 0.655764639377594
Validation loss: 1.6488892198890768

Epoch: 6| Step: 13
Training loss: 0.7508440017700195
Validation loss: 1.6372481110275432

Epoch: 621| Step: 0
Training loss: 0.550792932510376
Validation loss: 1.6190249317435808

Epoch: 6| Step: 1
Training loss: 0.7325323820114136
Validation loss: 1.6063974095929054

Epoch: 6| Step: 2
Training loss: 0.520715594291687
Validation loss: 1.6440321924865886

Epoch: 6| Step: 3
Training loss: 0.6409955024719238
Validation loss: 1.6588095118922572

Epoch: 6| Step: 4
Training loss: 0.41719359159469604
Validation loss: 1.6689250687117219

Epoch: 6| Step: 5
Training loss: 0.6200091242790222
Validation loss: 1.5831910038507113

Epoch: 6| Step: 6
Training loss: 0.9288972616195679
Validation loss: 1.566505939729752

Epoch: 6| Step: 7
Training loss: 1.2136458158493042
Validation loss: 1.5818401241815219

Epoch: 6| Step: 8
Training loss: 0.9879326820373535
Validation loss: 1.6053060754652946

Epoch: 6| Step: 9
Training loss: 0.46564099192619324
Validation loss: 1.560989401673758

Epoch: 6| Step: 10
Training loss: 0.5087971687316895
Validation loss: 1.5867312185225948

Epoch: 6| Step: 11
Training loss: 0.558096170425415
Validation loss: 1.5890269253843574

Epoch: 6| Step: 12
Training loss: 0.8250085115432739
Validation loss: 1.60373124512293

Epoch: 6| Step: 13
Training loss: 0.7025904655456543
Validation loss: 1.5575329872869677

Epoch: 622| Step: 0
Training loss: 0.6514067649841309
Validation loss: 1.5854203342109598

Epoch: 6| Step: 1
Training loss: 0.6781052350997925
Validation loss: 1.5623798511361564

Epoch: 6| Step: 2
Training loss: 0.6478338241577148
Validation loss: 1.6332752550801923

Epoch: 6| Step: 3
Training loss: 0.5711347460746765
Validation loss: 1.6184074801783408

Epoch: 6| Step: 4
Training loss: 1.1170878410339355
Validation loss: 1.605292748379451

Epoch: 6| Step: 5
Training loss: 0.6666321754455566
Validation loss: 1.680947579363341

Epoch: 6| Step: 6
Training loss: 0.8043460845947266
Validation loss: 1.6421983152307489

Epoch: 6| Step: 7
Training loss: 0.5590990781784058
Validation loss: 1.5858843300932197

Epoch: 6| Step: 8
Training loss: 0.5350682735443115
Validation loss: 1.6132253369977396

Epoch: 6| Step: 9
Training loss: 0.7838674783706665
Validation loss: 1.620097191103043

Epoch: 6| Step: 10
Training loss: 0.8426333665847778
Validation loss: 1.6117132966236403

Epoch: 6| Step: 11
Training loss: 0.45363762974739075
Validation loss: 1.6453812218481494

Epoch: 6| Step: 12
Training loss: 0.7572132349014282
Validation loss: 1.6115183317533104

Epoch: 6| Step: 13
Training loss: 0.316581130027771
Validation loss: 1.6017495380934847

Epoch: 623| Step: 0
Training loss: 0.7267023921012878
Validation loss: 1.5888249810023973

Epoch: 6| Step: 1
Training loss: 0.3822236955165863
Validation loss: 1.6060146785551501

Epoch: 6| Step: 2
Training loss: 0.4662759304046631
Validation loss: 1.6135863270810855

Epoch: 6| Step: 3
Training loss: 0.9781618118286133
Validation loss: 1.6073404614643385

Epoch: 6| Step: 4
Training loss: 0.987054705619812
Validation loss: 1.6589233580455984

Epoch: 6| Step: 5
Training loss: 0.5973458886146545
Validation loss: 1.650352736955048

Epoch: 6| Step: 6
Training loss: 0.42099279165267944
Validation loss: 1.6236808530745968

Epoch: 6| Step: 7
Training loss: 0.6718866229057312
Validation loss: 1.62111331442351

Epoch: 6| Step: 8
Training loss: 0.7193113565444946
Validation loss: 1.617696359593381

Epoch: 6| Step: 9
Training loss: 0.4040316343307495
Validation loss: 1.6279758714860486

Epoch: 6| Step: 10
Training loss: 0.6955732107162476
Validation loss: 1.6467456663808515

Epoch: 6| Step: 11
Training loss: 0.7976099252700806
Validation loss: 1.5860919811392342

Epoch: 6| Step: 12
Training loss: 0.8703359961509705
Validation loss: 1.6272145932720554

Epoch: 6| Step: 13
Training loss: 0.573147714138031
Validation loss: 1.6004367938605688

Epoch: 624| Step: 0
Training loss: 0.8625919818878174
Validation loss: 1.5753624823785597

Epoch: 6| Step: 1
Training loss: 0.5115703344345093
Validation loss: 1.551764690747825

Epoch: 6| Step: 2
Training loss: 0.6416167616844177
Validation loss: 1.5635039062910183

Epoch: 6| Step: 3
Training loss: 0.41353172063827515
Validation loss: 1.5363049885278106

Epoch: 6| Step: 4
Training loss: 0.43645375967025757
Validation loss: 1.632366290656469

Epoch: 6| Step: 5
Training loss: 0.3420572876930237
Validation loss: 1.6119753583785026

Epoch: 6| Step: 6
Training loss: 1.3281581401824951
Validation loss: 1.603038175131685

Epoch: 6| Step: 7
Training loss: 0.7269985675811768
Validation loss: 1.5875188701896257

Epoch: 6| Step: 8
Training loss: 0.43439167737960815
Validation loss: 1.6049057001708655

Epoch: 6| Step: 9
Training loss: 0.4976311922073364
Validation loss: 1.6318436361128283

Epoch: 6| Step: 10
Training loss: 0.8187663555145264
Validation loss: 1.6433225703495804

Epoch: 6| Step: 11
Training loss: 0.627601683139801
Validation loss: 1.5930053098227388

Epoch: 6| Step: 12
Training loss: 0.42532581090927124
Validation loss: 1.60055665046938

Epoch: 6| Step: 13
Training loss: 0.6997466683387756
Validation loss: 1.5666694846204532

Epoch: 625| Step: 0
Training loss: 0.6265437602996826
Validation loss: 1.5814616923691125

Epoch: 6| Step: 1
Training loss: 0.603721022605896
Validation loss: 1.5965255191249232

Epoch: 6| Step: 2
Training loss: 0.873206615447998
Validation loss: 1.5477787871514597

Epoch: 6| Step: 3
Training loss: 0.4664791226387024
Validation loss: 1.571196888082771

Epoch: 6| Step: 4
Training loss: 0.9262158870697021
Validation loss: 1.583132227261861

Epoch: 6| Step: 5
Training loss: 0.5483293533325195
Validation loss: 1.5798683435686174

Epoch: 6| Step: 6
Training loss: 0.454689085483551
Validation loss: 1.5796539783477783

Epoch: 6| Step: 7
Training loss: 0.8043824434280396
Validation loss: 1.6090053563476892

Epoch: 6| Step: 8
Training loss: 0.999920129776001
Validation loss: 1.531854510307312

Epoch: 6| Step: 9
Training loss: 0.6488551497459412
Validation loss: 1.5951323624580138

Epoch: 6| Step: 10
Training loss: 0.43900609016418457
Validation loss: 1.6298612356185913

Epoch: 6| Step: 11
Training loss: 0.2814253866672516
Validation loss: 1.5734557861922889

Epoch: 6| Step: 12
Training loss: 0.7978416681289673
Validation loss: 1.5755362190226072

Epoch: 6| Step: 13
Training loss: 0.48477301001548767
Validation loss: 1.625567134990487

Epoch: 626| Step: 0
Training loss: 0.6984596252441406
Validation loss: 1.5680490988557056

Epoch: 6| Step: 1
Training loss: 0.9447357654571533
Validation loss: 1.6335770955649755

Epoch: 6| Step: 2
Training loss: 0.3034653961658478
Validation loss: 1.5934283541094871

Epoch: 6| Step: 3
Training loss: 0.5376241207122803
Validation loss: 1.5634236079390331

Epoch: 6| Step: 4
Training loss: 0.5581377744674683
Validation loss: 1.6227990363233833

Epoch: 6| Step: 5
Training loss: 0.477882981300354
Validation loss: 1.6142775384328698

Epoch: 6| Step: 6
Training loss: 0.7056924700737
Validation loss: 1.583447349968777

Epoch: 6| Step: 7
Training loss: 0.7486791610717773
Validation loss: 1.6142264848114343

Epoch: 6| Step: 8
Training loss: 0.6710582971572876
Validation loss: 1.6478720377850276

Epoch: 6| Step: 9
Training loss: 0.7409557104110718
Validation loss: 1.619390062106553

Epoch: 6| Step: 10
Training loss: 1.0028313398361206
Validation loss: 1.6474868405249812

Epoch: 6| Step: 11
Training loss: 0.7227907180786133
Validation loss: 1.6125319875696653

Epoch: 6| Step: 12
Training loss: 0.5545464754104614
Validation loss: 1.58385516366651

Epoch: 6| Step: 13
Training loss: 0.526160478591919
Validation loss: 1.5753141385252758

Epoch: 627| Step: 0
Training loss: 0.6469690799713135
Validation loss: 1.6192291090565343

Epoch: 6| Step: 1
Training loss: 0.3998257517814636
Validation loss: 1.5903247146196262

Epoch: 6| Step: 2
Training loss: 0.4716455340385437
Validation loss: 1.664941967174571

Epoch: 6| Step: 3
Training loss: 0.5274209976196289
Validation loss: 1.6131761471430461

Epoch: 6| Step: 4
Training loss: 0.4845127761363983
Validation loss: 1.6196196835528138

Epoch: 6| Step: 5
Training loss: 0.4738939106464386
Validation loss: 1.5670971306421424

Epoch: 6| Step: 6
Training loss: 0.671032726764679
Validation loss: 1.6041587655262282

Epoch: 6| Step: 7
Training loss: 0.44071829319000244
Validation loss: 1.617505036374574

Epoch: 6| Step: 8
Training loss: 0.8563188314437866
Validation loss: 1.6108940903858473

Epoch: 6| Step: 9
Training loss: 0.7579449415206909
Validation loss: 1.5572304443646503

Epoch: 6| Step: 10
Training loss: 1.0316541194915771
Validation loss: 1.5403255467773767

Epoch: 6| Step: 11
Training loss: 0.8378600478172302
Validation loss: 1.6409911365919216

Epoch: 6| Step: 12
Training loss: 0.4494495987892151
Validation loss: 1.6149448604993923

Epoch: 6| Step: 13
Training loss: 0.9974606037139893
Validation loss: 1.618458431254151

Epoch: 628| Step: 0
Training loss: 0.3734007477760315
Validation loss: 1.5998460746580554

Epoch: 6| Step: 1
Training loss: 0.5596533417701721
Validation loss: 1.6122904400671683

Epoch: 6| Step: 2
Training loss: 0.9150007963180542
Validation loss: 1.6336631121173981

Epoch: 6| Step: 3
Training loss: 0.7107762694358826
Validation loss: 1.6685454319882136

Epoch: 6| Step: 4
Training loss: 0.7137335538864136
Validation loss: 1.6205695341992121

Epoch: 6| Step: 5
Training loss: 0.7007466554641724
Validation loss: 1.629277201109035

Epoch: 6| Step: 6
Training loss: 0.5891045928001404
Validation loss: 1.6486754814783733

Epoch: 6| Step: 7
Training loss: 0.4959314465522766
Validation loss: 1.6471028879124632

Epoch: 6| Step: 8
Training loss: 0.701147198677063
Validation loss: 1.6123156765455842

Epoch: 6| Step: 9
Training loss: 0.4842669367790222
Validation loss: 1.5906794327561573

Epoch: 6| Step: 10
Training loss: 0.5309056043624878
Validation loss: 1.5747661821303829

Epoch: 6| Step: 11
Training loss: 0.9918017983436584
Validation loss: 1.5926764421565558

Epoch: 6| Step: 12
Training loss: 0.4419899582862854
Validation loss: 1.6057360890091106

Epoch: 6| Step: 13
Training loss: 0.9206368327140808
Validation loss: 1.5610034978517922

Epoch: 629| Step: 0
Training loss: 0.5680851936340332
Validation loss: 1.6080408057858866

Epoch: 6| Step: 1
Training loss: 0.5190560221672058
Validation loss: 1.648998970626503

Epoch: 6| Step: 2
Training loss: 0.48289987444877625
Validation loss: 1.589309779546594

Epoch: 6| Step: 3
Training loss: 0.5970242023468018
Validation loss: 1.5789283693477671

Epoch: 6| Step: 4
Training loss: 0.5419862866401672
Validation loss: 1.60992193606592

Epoch: 6| Step: 5
Training loss: 0.3332422971725464
Validation loss: 1.606280835725928

Epoch: 6| Step: 6
Training loss: 0.851044774055481
Validation loss: 1.6238985574373634

Epoch: 6| Step: 7
Training loss: 0.6258582472801208
Validation loss: 1.62650603120045

Epoch: 6| Step: 8
Training loss: 0.5160086750984192
Validation loss: 1.566655546747228

Epoch: 6| Step: 9
Training loss: 1.312728762626648
Validation loss: 1.6320053851732643

Epoch: 6| Step: 10
Training loss: 0.7126606702804565
Validation loss: 1.627256594678407

Epoch: 6| Step: 11
Training loss: 0.3712291121482849
Validation loss: 1.6329575418144144

Epoch: 6| Step: 12
Training loss: 0.5993713140487671
Validation loss: 1.6266662895038564

Epoch: 6| Step: 13
Training loss: 0.8885905742645264
Validation loss: 1.6706928296755719

Epoch: 630| Step: 0
Training loss: 0.5717790126800537
Validation loss: 1.5838876680661274

Epoch: 6| Step: 1
Training loss: 0.5050513744354248
Validation loss: 1.600945161234948

Epoch: 6| Step: 2
Training loss: 1.2969133853912354
Validation loss: 1.6258547549606652

Epoch: 6| Step: 3
Training loss: 0.6594469547271729
Validation loss: 1.6050175627072651

Epoch: 6| Step: 4
Training loss: 0.5035465359687805
Validation loss: 1.5811362561359201

Epoch: 6| Step: 5
Training loss: 0.5692974328994751
Validation loss: 1.5947077094867665

Epoch: 6| Step: 6
Training loss: 0.5250253677368164
Validation loss: 1.576308019699589

Epoch: 6| Step: 7
Training loss: 0.9321846961975098
Validation loss: 1.5865834489945443

Epoch: 6| Step: 8
Training loss: 0.36485278606414795
Validation loss: 1.6047316212807932

Epoch: 6| Step: 9
Training loss: 0.5596582889556885
Validation loss: 1.5713390983561033

Epoch: 6| Step: 10
Training loss: 0.8090270757675171
Validation loss: 1.6491678837806947

Epoch: 6| Step: 11
Training loss: 0.5955935716629028
Validation loss: 1.6304524303764425

Epoch: 6| Step: 12
Training loss: 0.39846742153167725
Validation loss: 1.6362446585009176

Epoch: 6| Step: 13
Training loss: 0.3596704304218292
Validation loss: 1.6723825380366335

Epoch: 631| Step: 0
Training loss: 0.6469022631645203
Validation loss: 1.6669957381422802

Epoch: 6| Step: 1
Training loss: 0.6151731014251709
Validation loss: 1.6343509151089577

Epoch: 6| Step: 2
Training loss: 1.210838794708252
Validation loss: 1.6923320908700266

Epoch: 6| Step: 3
Training loss: 1.0910662412643433
Validation loss: 1.7039122619936544

Epoch: 6| Step: 4
Training loss: 0.5420095920562744
Validation loss: 1.6825268242948799

Epoch: 6| Step: 5
Training loss: 0.5229138135910034
Validation loss: 1.6904317717398367

Epoch: 6| Step: 6
Training loss: 0.5457383394241333
Validation loss: 1.653902579379338

Epoch: 6| Step: 7
Training loss: 0.8280885219573975
Validation loss: 1.589897762062729

Epoch: 6| Step: 8
Training loss: 0.6845579147338867
Validation loss: 1.5980734709770448

Epoch: 6| Step: 9
Training loss: 0.42475625872612
Validation loss: 1.6164799082663752

Epoch: 6| Step: 10
Training loss: 0.48339611291885376
Validation loss: 1.6300079835358487

Epoch: 6| Step: 11
Training loss: 0.5772013068199158
Validation loss: 1.6154305210677526

Epoch: 6| Step: 12
Training loss: 0.3374878764152527
Validation loss: 1.5768375960729455

Epoch: 6| Step: 13
Training loss: 0.4099837839603424
Validation loss: 1.5529872704577703

Epoch: 632| Step: 0
Training loss: 0.6965686082839966
Validation loss: 1.5727114664610995

Epoch: 6| Step: 1
Training loss: 0.8468297123908997
Validation loss: 1.618751072755424

Epoch: 6| Step: 2
Training loss: 0.35485726594924927
Validation loss: 1.629916790992983

Epoch: 6| Step: 3
Training loss: 0.5222643613815308
Validation loss: 1.6101015639561478

Epoch: 6| Step: 4
Training loss: 0.8594846725463867
Validation loss: 1.617844453421972

Epoch: 6| Step: 5
Training loss: 0.8287909030914307
Validation loss: 1.6239502865781066

Epoch: 6| Step: 6
Training loss: 0.3631698489189148
Validation loss: 1.578716665185908

Epoch: 6| Step: 7
Training loss: 0.9160894155502319
Validation loss: 1.6341491155726935

Epoch: 6| Step: 8
Training loss: 0.5075109004974365
Validation loss: 1.618291344693912

Epoch: 6| Step: 9
Training loss: 0.37603265047073364
Validation loss: 1.5892740244506507

Epoch: 6| Step: 10
Training loss: 0.8118165731430054
Validation loss: 1.6276824256425262

Epoch: 6| Step: 11
Training loss: 0.6703634262084961
Validation loss: 1.586281091936173

Epoch: 6| Step: 12
Training loss: 0.5451133251190186
Validation loss: 1.628600621736178

Epoch: 6| Step: 13
Training loss: 0.6590850353240967
Validation loss: 1.5857772660511795

Epoch: 633| Step: 0
Training loss: 0.7862361669540405
Validation loss: 1.6052143612215597

Epoch: 6| Step: 1
Training loss: 0.38318127393722534
Validation loss: 1.5832340640406455

Epoch: 6| Step: 2
Training loss: 1.0687217712402344
Validation loss: 1.5882855474307973

Epoch: 6| Step: 3
Training loss: 0.607318639755249
Validation loss: 1.6285455931899369

Epoch: 6| Step: 4
Training loss: 0.6106407046318054
Validation loss: 1.6291119206336238

Epoch: 6| Step: 5
Training loss: 0.6588355898857117
Validation loss: 1.609596707487619

Epoch: 6| Step: 6
Training loss: 0.7026760578155518
Validation loss: 1.6163537207470144

Epoch: 6| Step: 7
Training loss: 0.4085877537727356
Validation loss: 1.567040285756511

Epoch: 6| Step: 8
Training loss: 0.3444777727127075
Validation loss: 1.6235701063627839

Epoch: 6| Step: 9
Training loss: 0.5353643894195557
Validation loss: 1.5720728161514446

Epoch: 6| Step: 10
Training loss: 0.4961074888706207
Validation loss: 1.5967351505833287

Epoch: 6| Step: 11
Training loss: 0.5597829818725586
Validation loss: 1.6394693954016573

Epoch: 6| Step: 12
Training loss: 1.0544579029083252
Validation loss: 1.6023135031423261

Epoch: 6| Step: 13
Training loss: 0.5726285576820374
Validation loss: 1.6257163183663481

Epoch: 634| Step: 0
Training loss: 0.6234779357910156
Validation loss: 1.6308062294478058

Epoch: 6| Step: 1
Training loss: 0.6602458953857422
Validation loss: 1.6632226590187318

Epoch: 6| Step: 2
Training loss: 0.5115071535110474
Validation loss: 1.655913588821247

Epoch: 6| Step: 3
Training loss: 0.5079014301300049
Validation loss: 1.6416003434888777

Epoch: 6| Step: 4
Training loss: 0.9502898454666138
Validation loss: 1.5999589312461115

Epoch: 6| Step: 5
Training loss: 1.0360466241836548
Validation loss: 1.6322743995215303

Epoch: 6| Step: 6
Training loss: 0.4289911687374115
Validation loss: 1.6303358058775625

Epoch: 6| Step: 7
Training loss: 0.7145249843597412
Validation loss: 1.573559481610534

Epoch: 6| Step: 8
Training loss: 0.6177941560745239
Validation loss: 1.580884979617211

Epoch: 6| Step: 9
Training loss: 0.47564125061035156
Validation loss: 1.5676174804728518

Epoch: 6| Step: 10
Training loss: 0.6320838928222656
Validation loss: 1.5978443250861218

Epoch: 6| Step: 11
Training loss: 0.7509889602661133
Validation loss: 1.625669216596952

Epoch: 6| Step: 12
Training loss: 0.5182827711105347
Validation loss: 1.5711976289749146

Epoch: 6| Step: 13
Training loss: 0.900680422782898
Validation loss: 1.5822741754593388

Epoch: 635| Step: 0
Training loss: 0.38775864243507385
Validation loss: 1.616787366328701

Epoch: 6| Step: 1
Training loss: 0.8948111534118652
Validation loss: 1.6320483069266043

Epoch: 6| Step: 2
Training loss: 0.7556077837944031
Validation loss: 1.660974548709008

Epoch: 6| Step: 3
Training loss: 0.6015298366546631
Validation loss: 1.6403018736070203

Epoch: 6| Step: 4
Training loss: 0.5967724323272705
Validation loss: 1.666658393798336

Epoch: 6| Step: 5
Training loss: 0.4831826984882355
Validation loss: 1.6143439700526576

Epoch: 6| Step: 6
Training loss: 0.4990076422691345
Validation loss: 1.6718431775287916

Epoch: 6| Step: 7
Training loss: 0.4216010272502899
Validation loss: 1.6490905464336436

Epoch: 6| Step: 8
Training loss: 0.9777485728263855
Validation loss: 1.6063966610098397

Epoch: 6| Step: 9
Training loss: 0.6748732328414917
Validation loss: 1.6489156292330833

Epoch: 6| Step: 10
Training loss: 0.9463210105895996
Validation loss: 1.6257570635887884

Epoch: 6| Step: 11
Training loss: 0.3053833842277527
Validation loss: 1.6056255563612907

Epoch: 6| Step: 12
Training loss: 0.8602439761161804
Validation loss: 1.5931995350827453

Epoch: 6| Step: 13
Training loss: 0.5492517948150635
Validation loss: 1.5379417480960969

Epoch: 636| Step: 0
Training loss: 0.7879724502563477
Validation loss: 1.6344765091455111

Epoch: 6| Step: 1
Training loss: 0.38015860319137573
Validation loss: 1.6016982037533996

Epoch: 6| Step: 2
Training loss: 0.7076097726821899
Validation loss: 1.5431547011098554

Epoch: 6| Step: 3
Training loss: 0.46608424186706543
Validation loss: 1.5923525748714324

Epoch: 6| Step: 4
Training loss: 0.771375298500061
Validation loss: 1.5994400439723846

Epoch: 6| Step: 5
Training loss: 0.6435880661010742
Validation loss: 1.5854946080074515

Epoch: 6| Step: 6
Training loss: 0.8045628070831299
Validation loss: 1.614593368704601

Epoch: 6| Step: 7
Training loss: 0.3299110531806946
Validation loss: 1.6072484895747194

Epoch: 6| Step: 8
Training loss: 0.5026953220367432
Validation loss: 1.6040812102697228

Epoch: 6| Step: 9
Training loss: 0.49762511253356934
Validation loss: 1.6214264067270423

Epoch: 6| Step: 10
Training loss: 0.5717024803161621
Validation loss: 1.6223948617135324

Epoch: 6| Step: 11
Training loss: 0.9670048356056213
Validation loss: 1.6843357188727266

Epoch: 6| Step: 12
Training loss: 0.547516942024231
Validation loss: 1.5750005552845616

Epoch: 6| Step: 13
Training loss: 0.42267000675201416
Validation loss: 1.592896443541332

Epoch: 637| Step: 0
Training loss: 0.5147079229354858
Validation loss: 1.5847821940657913

Epoch: 6| Step: 1
Training loss: 0.404050350189209
Validation loss: 1.604715670308759

Epoch: 6| Step: 2
Training loss: 0.7992923259735107
Validation loss: 1.6094646966585548

Epoch: 6| Step: 3
Training loss: 0.6346505880355835
Validation loss: 1.5577267651916833

Epoch: 6| Step: 4
Training loss: 0.5371257662773132
Validation loss: 1.6032272103012248

Epoch: 6| Step: 5
Training loss: 0.6981199979782104
Validation loss: 1.5705666747144473

Epoch: 6| Step: 6
Training loss: 0.6732912659645081
Validation loss: 1.5925527016321819

Epoch: 6| Step: 7
Training loss: 0.8502777218818665
Validation loss: 1.640469802323208

Epoch: 6| Step: 8
Training loss: 1.179054617881775
Validation loss: 1.564392702553862

Epoch: 6| Step: 9
Training loss: 0.4152521789073944
Validation loss: 1.5674293361684328

Epoch: 6| Step: 10
Training loss: 0.5822374820709229
Validation loss: 1.6183637021690287

Epoch: 6| Step: 11
Training loss: 0.3571397662162781
Validation loss: 1.5738902271434825

Epoch: 6| Step: 12
Training loss: 0.7104520797729492
Validation loss: 1.5718799534664358

Epoch: 6| Step: 13
Training loss: 0.5129959583282471
Validation loss: 1.5979276882704867

Epoch: 638| Step: 0
Training loss: 0.7249242663383484
Validation loss: 1.6117413223430674

Epoch: 6| Step: 1
Training loss: 0.49426937103271484
Validation loss: 1.617857547216518

Epoch: 6| Step: 2
Training loss: 0.7610865831375122
Validation loss: 1.7159613396531792

Epoch: 6| Step: 3
Training loss: 0.7123889923095703
Validation loss: 1.6020510453049854

Epoch: 6| Step: 4
Training loss: 0.39347633719444275
Validation loss: 1.6347525132599698

Epoch: 6| Step: 5
Training loss: 0.4147360324859619
Validation loss: 1.5527933374527962

Epoch: 6| Step: 6
Training loss: 0.5692914128303528
Validation loss: 1.5580524795798845

Epoch: 6| Step: 7
Training loss: 0.77031010389328
Validation loss: 1.6183877273272442

Epoch: 6| Step: 8
Training loss: 0.7266685962677002
Validation loss: 1.571605545218273

Epoch: 6| Step: 9
Training loss: 0.5600653886795044
Validation loss: 1.6666345391222226

Epoch: 6| Step: 10
Training loss: 0.6419334411621094
Validation loss: 1.568608303223887

Epoch: 6| Step: 11
Training loss: 0.7444182634353638
Validation loss: 1.6306133013899609

Epoch: 6| Step: 12
Training loss: 0.7794770002365112
Validation loss: 1.5840653270803473

Epoch: 6| Step: 13
Training loss: 0.22780054807662964
Validation loss: 1.6328878787256056

Epoch: 639| Step: 0
Training loss: 0.4568093419075012
Validation loss: 1.657255603421119

Epoch: 6| Step: 1
Training loss: 0.7977609634399414
Validation loss: 1.6168551496280137

Epoch: 6| Step: 2
Training loss: 0.4437047243118286
Validation loss: 1.6351754370556082

Epoch: 6| Step: 3
Training loss: 0.5178555250167847
Validation loss: 1.6075786852067517

Epoch: 6| Step: 4
Training loss: 0.6913822889328003
Validation loss: 1.6068819927912887

Epoch: 6| Step: 5
Training loss: 0.2597104012966156
Validation loss: 1.6390713940384567

Epoch: 6| Step: 6
Training loss: 0.5139621496200562
Validation loss: 1.598817866335633

Epoch: 6| Step: 7
Training loss: 0.606712818145752
Validation loss: 1.5799141359585587

Epoch: 6| Step: 8
Training loss: 0.45571568608283997
Validation loss: 1.6289266309430521

Epoch: 6| Step: 9
Training loss: 0.8744524121284485
Validation loss: 1.6226968842168008

Epoch: 6| Step: 10
Training loss: 0.7774006724357605
Validation loss: 1.5789935153017762

Epoch: 6| Step: 11
Training loss: 0.9073418378829956
Validation loss: 1.5976556686944858

Epoch: 6| Step: 12
Training loss: 0.950687050819397
Validation loss: 1.6107461542211554

Epoch: 6| Step: 13
Training loss: 0.6626753211021423
Validation loss: 1.5851587300659509

Epoch: 640| Step: 0
Training loss: 0.471513956785202
Validation loss: 1.5768828776574904

Epoch: 6| Step: 1
Training loss: 0.6382554173469543
Validation loss: 1.627888564140566

Epoch: 6| Step: 2
Training loss: 0.9542251825332642
Validation loss: 1.590755788228845

Epoch: 6| Step: 3
Training loss: 0.5818934440612793
Validation loss: 1.5531291500214608

Epoch: 6| Step: 4
Training loss: 0.7343350648880005
Validation loss: 1.6139683749086113

Epoch: 6| Step: 5
Training loss: 1.1537599563598633
Validation loss: 1.6377086921404767

Epoch: 6| Step: 6
Training loss: 0.4108065664768219
Validation loss: 1.689871161214767

Epoch: 6| Step: 7
Training loss: 0.6001822352409363
Validation loss: 1.658038943044601

Epoch: 6| Step: 8
Training loss: 0.6589252948760986
Validation loss: 1.6534780340809976

Epoch: 6| Step: 9
Training loss: 0.6610519289970398
Validation loss: 1.5863951188261791

Epoch: 6| Step: 10
Training loss: 0.6713656187057495
Validation loss: 1.5688792774754186

Epoch: 6| Step: 11
Training loss: 0.41292548179626465
Validation loss: 1.613841925897906

Epoch: 6| Step: 12
Training loss: 0.3844986855983734
Validation loss: 1.6431364013302712

Epoch: 6| Step: 13
Training loss: 0.9789806008338928
Validation loss: 1.5901600635179909

Epoch: 641| Step: 0
Training loss: 0.558469295501709
Validation loss: 1.634809431209359

Epoch: 6| Step: 1
Training loss: 0.5246335864067078
Validation loss: 1.6041825817477318

Epoch: 6| Step: 2
Training loss: 0.4389578700065613
Validation loss: 1.5442497281618015

Epoch: 6| Step: 3
Training loss: 0.6780804395675659
Validation loss: 1.5770143103855911

Epoch: 6| Step: 4
Training loss: 0.6451232433319092
Validation loss: 1.5652448605465632

Epoch: 6| Step: 5
Training loss: 0.6649317741394043
Validation loss: 1.648592911740785

Epoch: 6| Step: 6
Training loss: 0.7189871668815613
Validation loss: 1.5997284817439255

Epoch: 6| Step: 7
Training loss: 0.4468933045864105
Validation loss: 1.591935388503536

Epoch: 6| Step: 8
Training loss: 0.4648224711418152
Validation loss: 1.6866466435053016

Epoch: 6| Step: 9
Training loss: 0.8115493059158325
Validation loss: 1.7085044973640031

Epoch: 6| Step: 10
Training loss: 0.8827582001686096
Validation loss: 1.636699475267882

Epoch: 6| Step: 11
Training loss: 0.9029908776283264
Validation loss: 1.7057583729426067

Epoch: 6| Step: 12
Training loss: 0.702534556388855
Validation loss: 1.6707076141911168

Epoch: 6| Step: 13
Training loss: 0.5699700117111206
Validation loss: 1.681349019850454

Epoch: 642| Step: 0
Training loss: 0.80040043592453
Validation loss: 1.5932753855182278

Epoch: 6| Step: 1
Training loss: 0.48486292362213135
Validation loss: 1.6377976414977864

Epoch: 6| Step: 2
Training loss: 0.6469111442565918
Validation loss: 1.6177899427311395

Epoch: 6| Step: 3
Training loss: 0.46146252751350403
Validation loss: 1.5462255157450193

Epoch: 6| Step: 4
Training loss: 0.6164969205856323
Validation loss: 1.5749538354976202

Epoch: 6| Step: 5
Training loss: 0.8388637900352478
Validation loss: 1.5983165053911106

Epoch: 6| Step: 6
Training loss: 0.6468943357467651
Validation loss: 1.5913069107199227

Epoch: 6| Step: 7
Training loss: 1.279874324798584
Validation loss: 1.5592175331166995

Epoch: 6| Step: 8
Training loss: 0.5222132205963135
Validation loss: 1.5863989899235387

Epoch: 6| Step: 9
Training loss: 0.6676577925682068
Validation loss: 1.6392383934349142

Epoch: 6| Step: 10
Training loss: 0.4397253394126892
Validation loss: 1.6232450578802375

Epoch: 6| Step: 11
Training loss: 0.4872089624404907
Validation loss: 1.576746750903386

Epoch: 6| Step: 12
Training loss: 0.5315896272659302
Validation loss: 1.6297260804842877

Epoch: 6| Step: 13
Training loss: 0.36679181456565857
Validation loss: 1.6450374485344015

Epoch: 643| Step: 0
Training loss: 0.5592939853668213
Validation loss: 1.5839672280896095

Epoch: 6| Step: 1
Training loss: 0.853496253490448
Validation loss: 1.5857657924775155

Epoch: 6| Step: 2
Training loss: 0.3005797564983368
Validation loss: 1.6362632038772746

Epoch: 6| Step: 3
Training loss: 0.4189995527267456
Validation loss: 1.605530697171406

Epoch: 6| Step: 4
Training loss: 0.40385863184928894
Validation loss: 1.584871272886953

Epoch: 6| Step: 5
Training loss: 0.40273547172546387
Validation loss: 1.5272447780896259

Epoch: 6| Step: 6
Training loss: 0.7563621997833252
Validation loss: 1.5457961815659718

Epoch: 6| Step: 7
Training loss: 0.5365111827850342
Validation loss: 1.574148049918554

Epoch: 6| Step: 8
Training loss: 0.8746812343597412
Validation loss: 1.5847741147523284

Epoch: 6| Step: 9
Training loss: 0.741783618927002
Validation loss: 1.5795885029659475

Epoch: 6| Step: 10
Training loss: 0.48854565620422363
Validation loss: 1.5636668628261936

Epoch: 6| Step: 11
Training loss: 0.7468501329421997
Validation loss: 1.5627127584590708

Epoch: 6| Step: 12
Training loss: 0.6834735870361328
Validation loss: 1.6016863712700464

Epoch: 6| Step: 13
Training loss: 0.6786673665046692
Validation loss: 1.6426547945186656

Epoch: 644| Step: 0
Training loss: 0.3987613320350647
Validation loss: 1.5869412704180645

Epoch: 6| Step: 1
Training loss: 0.7796727418899536
Validation loss: 1.571189885498375

Epoch: 6| Step: 2
Training loss: 0.6634964942932129
Validation loss: 1.6332202278157717

Epoch: 6| Step: 3
Training loss: 0.7182119488716125
Validation loss: 1.6009734394729778

Epoch: 6| Step: 4
Training loss: 0.3771274983882904
Validation loss: 1.6043541777518489

Epoch: 6| Step: 5
Training loss: 0.37331482768058777
Validation loss: 1.5955342182549097

Epoch: 6| Step: 6
Training loss: 0.29592224955558777
Validation loss: 1.6561137617275279

Epoch: 6| Step: 7
Training loss: 0.4111980199813843
Validation loss: 1.575237169060656

Epoch: 6| Step: 8
Training loss: 0.693658709526062
Validation loss: 1.5619958228962396

Epoch: 6| Step: 9
Training loss: 0.5591647624969482
Validation loss: 1.5946783814378964

Epoch: 6| Step: 10
Training loss: 1.0284538269042969
Validation loss: 1.6061710875521424

Epoch: 6| Step: 11
Training loss: 1.0442359447479248
Validation loss: 1.5711589346649826

Epoch: 6| Step: 12
Training loss: 0.19289827346801758
Validation loss: 1.5971423067072386

Epoch: 6| Step: 13
Training loss: 0.9928612112998962
Validation loss: 1.5761799120133924

Epoch: 645| Step: 0
Training loss: 0.31723880767822266
Validation loss: 1.640833580365745

Epoch: 6| Step: 1
Training loss: 0.6464365124702454
Validation loss: 1.6641663338548394

Epoch: 6| Step: 2
Training loss: 0.5071289539337158
Validation loss: 1.668824206116379

Epoch: 6| Step: 3
Training loss: 0.48231929540634155
Validation loss: 1.668235477580819

Epoch: 6| Step: 4
Training loss: 0.6947681903839111
Validation loss: 1.6248566771066317

Epoch: 6| Step: 5
Training loss: 0.899225652217865
Validation loss: 1.6564353537815872

Epoch: 6| Step: 6
Training loss: 0.5772545337677002
Validation loss: 1.6060231565147318

Epoch: 6| Step: 7
Training loss: 0.4379655718803406
Validation loss: 1.6339668529008025

Epoch: 6| Step: 8
Training loss: 0.48461592197418213
Validation loss: 1.5657542008225636

Epoch: 6| Step: 9
Training loss: 0.6083819270133972
Validation loss: 1.594216956887194

Epoch: 6| Step: 10
Training loss: 0.7624664306640625
Validation loss: 1.6304243213386946

Epoch: 6| Step: 11
Training loss: 1.1833386421203613
Validation loss: 1.5320513171534385

Epoch: 6| Step: 12
Training loss: 0.46698132157325745
Validation loss: 1.6023051866921045

Epoch: 6| Step: 13
Training loss: 0.80430006980896
Validation loss: 1.5918608865430277

Epoch: 646| Step: 0
Training loss: 0.4883774518966675
Validation loss: 1.5122678882332259

Epoch: 6| Step: 1
Training loss: 0.6444762945175171
Validation loss: 1.6012053143593572

Epoch: 6| Step: 2
Training loss: 0.7759179472923279
Validation loss: 1.5884504388737422

Epoch: 6| Step: 3
Training loss: 1.0797970294952393
Validation loss: 1.6598522637480049

Epoch: 6| Step: 4
Training loss: 0.5222961902618408
Validation loss: 1.6184701842646445

Epoch: 6| Step: 5
Training loss: 0.6383485794067383
Validation loss: 1.562848283398536

Epoch: 6| Step: 6
Training loss: 0.35441461205482483
Validation loss: 1.6146727153050002

Epoch: 6| Step: 7
Training loss: 0.41290926933288574
Validation loss: 1.558847241504218

Epoch: 6| Step: 8
Training loss: 0.5464992523193359
Validation loss: 1.60836882745066

Epoch: 6| Step: 9
Training loss: 0.5588672161102295
Validation loss: 1.5677390406208653

Epoch: 6| Step: 10
Training loss: 0.9541083574295044
Validation loss: 1.5486930954840876

Epoch: 6| Step: 11
Training loss: 0.4109092652797699
Validation loss: 1.5656069991409138

Epoch: 6| Step: 12
Training loss: 0.5262282490730286
Validation loss: 1.6417357819054716

Epoch: 6| Step: 13
Training loss: 0.5620602369308472
Validation loss: 1.6352122393987512

Epoch: 647| Step: 0
Training loss: 0.7807250022888184
Validation loss: 1.6584123642213884

Epoch: 6| Step: 1
Training loss: 0.5012070536613464
Validation loss: 1.5768478134626984

Epoch: 6| Step: 2
Training loss: 0.7484714984893799
Validation loss: 1.6340655857516873

Epoch: 6| Step: 3
Training loss: 0.8695885539054871
Validation loss: 1.5773776872183687

Epoch: 6| Step: 4
Training loss: 0.5091779232025146
Validation loss: 1.6299978943281277

Epoch: 6| Step: 5
Training loss: 0.6703070402145386
Validation loss: 1.6601117669895131

Epoch: 6| Step: 6
Training loss: 0.32651036977767944
Validation loss: 1.5998527183327624

Epoch: 6| Step: 7
Training loss: 0.39117711782455444
Validation loss: 1.6275427674734464

Epoch: 6| Step: 8
Training loss: 0.804038405418396
Validation loss: 1.5420051633670766

Epoch: 6| Step: 9
Training loss: 0.7187361121177673
Validation loss: 1.522821573800938

Epoch: 6| Step: 10
Training loss: 0.6144521832466125
Validation loss: 1.5665881710667764

Epoch: 6| Step: 11
Training loss: 0.6612356901168823
Validation loss: 1.5939837463440434

Epoch: 6| Step: 12
Training loss: 0.6224315762519836
Validation loss: 1.6245625634347238

Epoch: 6| Step: 13
Training loss: 0.9915705919265747
Validation loss: 1.6026519703608688

Epoch: 648| Step: 0
Training loss: 0.9226146936416626
Validation loss: 1.6060655258035148

Epoch: 6| Step: 1
Training loss: 0.42992112040519714
Validation loss: 1.5866819350950179

Epoch: 6| Step: 2
Training loss: 0.6613273620605469
Validation loss: 1.6118070322980163

Epoch: 6| Step: 3
Training loss: 0.9244251251220703
Validation loss: 1.5826792614434355

Epoch: 6| Step: 4
Training loss: 0.2668452858924866
Validation loss: 1.609466802689337

Epoch: 6| Step: 5
Training loss: 0.8526430726051331
Validation loss: 1.5934783617655437

Epoch: 6| Step: 6
Training loss: 0.6603214740753174
Validation loss: 1.6150261420075611

Epoch: 6| Step: 7
Training loss: 0.6661924719810486
Validation loss: 1.611779773107139

Epoch: 6| Step: 8
Training loss: 0.7520573735237122
Validation loss: 1.6389411226395638

Epoch: 6| Step: 9
Training loss: 0.39132174849510193
Validation loss: 1.5351638037671325

Epoch: 6| Step: 10
Training loss: 0.5181825757026672
Validation loss: 1.565173009390472

Epoch: 6| Step: 11
Training loss: 0.5360094308853149
Validation loss: 1.5900554016072264

Epoch: 6| Step: 12
Training loss: 0.34924113750457764
Validation loss: 1.5805585256186865

Epoch: 6| Step: 13
Training loss: 1.0663877725601196
Validation loss: 1.5720694385549074

Epoch: 649| Step: 0
Training loss: 0.7709300518035889
Validation loss: 1.5524272636700702

Epoch: 6| Step: 1
Training loss: 0.46635136008262634
Validation loss: 1.5349248993781306

Epoch: 6| Step: 2
Training loss: 0.6387372016906738
Validation loss: 1.6050697398442093

Epoch: 6| Step: 3
Training loss: 0.9498420357704163
Validation loss: 1.6163701062561364

Epoch: 6| Step: 4
Training loss: 0.8052608966827393
Validation loss: 1.6470522265280447

Epoch: 6| Step: 5
Training loss: 0.36809396743774414
Validation loss: 1.5994544708600609

Epoch: 6| Step: 6
Training loss: 0.5041347742080688
Validation loss: 1.6079988133522771

Epoch: 6| Step: 7
Training loss: 1.0450773239135742
Validation loss: 1.6436922498928603

Epoch: 6| Step: 8
Training loss: 0.572859525680542
Validation loss: 1.6380883327094458

Epoch: 6| Step: 9
Training loss: 0.3144214153289795
Validation loss: 1.602487987087619

Epoch: 6| Step: 10
Training loss: 0.27590346336364746
Validation loss: 1.603544735139416

Epoch: 6| Step: 11
Training loss: 0.6116491556167603
Validation loss: 1.574711927803614

Epoch: 6| Step: 12
Training loss: 0.5042951107025146
Validation loss: 1.567414096606675

Epoch: 6| Step: 13
Training loss: 0.45521122217178345
Validation loss: 1.6047233855852516

Epoch: 650| Step: 0
Training loss: 0.8244655132293701
Validation loss: 1.6064404928556053

Epoch: 6| Step: 1
Training loss: 0.6574690937995911
Validation loss: 1.5734847796860563

Epoch: 6| Step: 2
Training loss: 0.3900514245033264
Validation loss: 1.573339323843679

Epoch: 6| Step: 3
Training loss: 0.37511929869651794
Validation loss: 1.6139065514328659

Epoch: 6| Step: 4
Training loss: 0.9570214748382568
Validation loss: 1.6153573477140037

Epoch: 6| Step: 5
Training loss: 0.382659375667572
Validation loss: 1.634392915233489

Epoch: 6| Step: 6
Training loss: 0.7683650851249695
Validation loss: 1.625172221532432

Epoch: 6| Step: 7
Training loss: 0.591217041015625
Validation loss: 1.6326700871990574

Epoch: 6| Step: 8
Training loss: 0.3917684555053711
Validation loss: 1.5684832898519372

Epoch: 6| Step: 9
Training loss: 0.6832936406135559
Validation loss: 1.6382266295853483

Epoch: 6| Step: 10
Training loss: 0.4412570893764496
Validation loss: 1.6446814793412403

Epoch: 6| Step: 11
Training loss: 0.8850353360176086
Validation loss: 1.5831152367335495

Epoch: 6| Step: 12
Training loss: 0.4834963381290436
Validation loss: 1.550846065244367

Epoch: 6| Step: 13
Training loss: 0.7881574034690857
Validation loss: 1.5398954447879587

Testing loss: 2.3378534025616116
