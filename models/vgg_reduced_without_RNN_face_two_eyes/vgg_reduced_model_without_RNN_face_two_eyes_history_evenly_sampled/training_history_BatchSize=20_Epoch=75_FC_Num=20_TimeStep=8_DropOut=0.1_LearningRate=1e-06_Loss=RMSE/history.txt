Epoch: 1| Step: 0
Training loss: 4.460020702639031
Validation loss: 5.480243486121393

Epoch: 5| Step: 1
Training loss: 6.214584105394933
Validation loss: 5.474379456777597

Epoch: 5| Step: 2
Training loss: 5.3784282308472795
Validation loss: 5.46880287437837

Epoch: 5| Step: 3
Training loss: 6.140064631317639
Validation loss: 5.464018377256087

Epoch: 5| Step: 4
Training loss: 4.6191486769882255
Validation loss: 5.459059945503096

Epoch: 5| Step: 5
Training loss: 5.635129497025085
Validation loss: 5.453166590701634

Epoch: 5| Step: 6
Training loss: 5.846245054545094
Validation loss: 5.448832471534241

Epoch: 5| Step: 7
Training loss: 5.421390039043892
Validation loss: 5.444254563746773

Epoch: 5| Step: 8
Training loss: 5.5017049054320495
Validation loss: 5.437599099189358

Epoch: 5| Step: 9
Training loss: 6.13043376688518
Validation loss: 5.433401101527281

Epoch: 5| Step: 10
Training loss: 4.752422718782289
Validation loss: 5.428140247262702

Epoch: 2| Step: 0
Training loss: 5.134571720378339
Validation loss: 5.422580000908752

Epoch: 5| Step: 1
Training loss: 4.819394807929442
Validation loss: 5.419423032281273

Epoch: 5| Step: 2
Training loss: 6.123358370266507
Validation loss: 5.4146196925962595

Epoch: 5| Step: 3
Training loss: 5.542926425248028
Validation loss: 5.408900671248541

Epoch: 5| Step: 4
Training loss: 5.186285589155332
Validation loss: 5.4043506987404974

Epoch: 5| Step: 5
Training loss: 6.322524769268035
Validation loss: 5.398722986120873

Epoch: 5| Step: 6
Training loss: 5.647367130656803
Validation loss: 5.394432171333518

Epoch: 5| Step: 7
Training loss: 5.947547843262834
Validation loss: 5.390475960683914

Epoch: 5| Step: 8
Training loss: 4.367740602902508
Validation loss: 5.386575561267961

Epoch: 5| Step: 9
Training loss: 5.345463528209775
Validation loss: 5.382000526491516

Epoch: 5| Step: 10
Training loss: 5.238718172494138
Validation loss: 5.375820489346754

Epoch: 3| Step: 0
Training loss: 4.708295141194601
Validation loss: 5.371458246506178

Epoch: 5| Step: 1
Training loss: 4.740795653961177
Validation loss: 5.367401836676084

Epoch: 5| Step: 2
Training loss: 5.731151038327388
Validation loss: 5.363446730543483

Epoch: 5| Step: 3
Training loss: 5.072036238555932
Validation loss: 5.356380178263587

Epoch: 5| Step: 4
Training loss: 5.502715394147182
Validation loss: 5.3527334229430705

Epoch: 5| Step: 5
Training loss: 5.920125818719789
Validation loss: 5.348615318700704

Epoch: 5| Step: 6
Training loss: 5.194824379383927
Validation loss: 5.34422047924731

Epoch: 5| Step: 7
Training loss: 5.900721955175075
Validation loss: 5.340672633837469

Epoch: 5| Step: 8
Training loss: 4.867088353599927
Validation loss: 5.3348656511713255

Epoch: 5| Step: 9
Training loss: 6.407083894373557
Validation loss: 5.329555728482179

Epoch: 5| Step: 10
Training loss: 5.039616801211354
Validation loss: 5.325702793520781

Epoch: 4| Step: 0
Training loss: 5.277228455092344
Validation loss: 5.319649565226241

Epoch: 5| Step: 1
Training loss: 5.213830330777906
Validation loss: 5.31416071896998

Epoch: 5| Step: 2
Training loss: 5.340454870274212
Validation loss: 5.309029602718492

Epoch: 5| Step: 3
Training loss: 4.386687879037635
Validation loss: 5.302936573864952

Epoch: 5| Step: 4
Training loss: 6.368090306969181
Validation loss: 5.297528241296971

Epoch: 5| Step: 5
Training loss: 4.949739183432677
Validation loss: 5.293824597947043

Epoch: 5| Step: 6
Training loss: 5.889672645059893
Validation loss: 5.2860334528610435

Epoch: 5| Step: 7
Training loss: 4.72528593621117
Validation loss: 5.28197032066778

Epoch: 5| Step: 8
Training loss: 6.246707506782511
Validation loss: 5.275678322350911

Epoch: 5| Step: 9
Training loss: 5.206345120187294
Validation loss: 5.270325572978033

Epoch: 5| Step: 10
Training loss: 4.779651449416084
Validation loss: 5.265433596845894

Epoch: 5| Step: 0
Training loss: 4.9557786445600005
Validation loss: 5.260714087844884

Epoch: 5| Step: 1
Training loss: 6.207526886382855
Validation loss: 5.255726967701025

Epoch: 5| Step: 2
Training loss: 4.280192223626342
Validation loss: 5.248418984991077

Epoch: 5| Step: 3
Training loss: 5.278487526982494
Validation loss: 5.244115855479163

Epoch: 5| Step: 4
Training loss: 5.4821339780683225
Validation loss: 5.237506977679394

Epoch: 5| Step: 5
Training loss: 5.998239258861134
Validation loss: 5.229974175548659

Epoch: 5| Step: 6
Training loss: 5.462861820345493
Validation loss: 5.226375780118428

Epoch: 5| Step: 7
Training loss: 4.966857933782181
Validation loss: 5.219973454080819

Epoch: 5| Step: 8
Training loss: 5.159974388827853
Validation loss: 5.2146533638345325

Epoch: 5| Step: 9
Training loss: 5.205515452723201
Validation loss: 5.2063887610494985

Epoch: 5| Step: 10
Training loss: 4.84494948763346
Validation loss: 5.201313052510001

Epoch: 6| Step: 0
Training loss: 4.789534827085328
Validation loss: 5.195016354843603

Epoch: 5| Step: 1
Training loss: 4.884077961017502
Validation loss: 5.186936111729258

Epoch: 5| Step: 2
Training loss: 5.168805182276568
Validation loss: 5.184370304365075

Epoch: 5| Step: 3
Training loss: 5.238350795935616
Validation loss: 5.177175440521568

Epoch: 5| Step: 4
Training loss: 5.7566854339158215
Validation loss: 5.171121216505886

Epoch: 5| Step: 5
Training loss: 5.250207442772016
Validation loss: 5.1636807324470935

Epoch: 5| Step: 6
Training loss: 4.762576269305014
Validation loss: 5.15646410584875

Epoch: 5| Step: 7
Training loss: 5.219149454327911
Validation loss: 5.150313754887817

Epoch: 5| Step: 8
Training loss: 5.780106384987853
Validation loss: 5.143844143628174

Epoch: 5| Step: 9
Training loss: 4.4630784544035444
Validation loss: 5.137207856402544

Epoch: 5| Step: 10
Training loss: 6.049420592251222
Validation loss: 5.129895776905574

Epoch: 7| Step: 0
Training loss: 6.3719044069637745
Validation loss: 5.12403340482347

Epoch: 5| Step: 1
Training loss: 4.498788034628613
Validation loss: 5.119628572501877

Epoch: 5| Step: 2
Training loss: 5.478669331344237
Validation loss: 5.109703203698477

Epoch: 5| Step: 3
Training loss: 5.686518993241652
Validation loss: 5.105436637285269

Epoch: 5| Step: 4
Training loss: 4.726247124357037
Validation loss: 5.0967590535729395

Epoch: 5| Step: 5
Training loss: 4.704137547382864
Validation loss: 5.088553571265711

Epoch: 5| Step: 6
Training loss: 4.895383622096957
Validation loss: 5.081499477347181

Epoch: 5| Step: 7
Training loss: 5.3149412043882025
Validation loss: 5.073103122940405

Epoch: 5| Step: 8
Training loss: 5.398494030094759
Validation loss: 5.068123078068456

Epoch: 5| Step: 9
Training loss: 4.776950074488968
Validation loss: 5.060094454537634

Epoch: 5| Step: 10
Training loss: 4.3656614636568865
Validation loss: 5.052885293015789

Epoch: 8| Step: 0
Training loss: 4.194045005007495
Validation loss: 5.047932736369252

Epoch: 5| Step: 1
Training loss: 5.3947651320022985
Validation loss: 5.039914225847677

Epoch: 5| Step: 2
Training loss: 4.31277531284066
Validation loss: 5.033732547804571

Epoch: 5| Step: 3
Training loss: 6.022125140756999
Validation loss: 5.025062777447936

Epoch: 5| Step: 4
Training loss: 4.914384064213014
Validation loss: 5.016585919806192

Epoch: 5| Step: 5
Training loss: 5.313419935572867
Validation loss: 5.010566543235058

Epoch: 5| Step: 6
Training loss: 4.957658203493954
Validation loss: 5.002740476077777

Epoch: 5| Step: 7
Training loss: 5.598092380951217
Validation loss: 4.994091975482107

Epoch: 5| Step: 8
Training loss: 4.463657919201842
Validation loss: 4.988547449734674

Epoch: 5| Step: 9
Training loss: 5.454891760265362
Validation loss: 4.976962117361595

Epoch: 5| Step: 10
Training loss: 4.809938616132933
Validation loss: 4.971809549890168

Epoch: 9| Step: 0
Training loss: 4.516587943391629
Validation loss: 4.963701319352397

Epoch: 5| Step: 1
Training loss: 5.819508255047535
Validation loss: 4.954026737660672

Epoch: 5| Step: 2
Training loss: 5.905852773720598
Validation loss: 4.945709647504602

Epoch: 5| Step: 3
Training loss: 5.1631748746654855
Validation loss: 4.936561666653248

Epoch: 5| Step: 4
Training loss: 4.730767717057034
Validation loss: 4.92782338227079

Epoch: 5| Step: 5
Training loss: 5.137506808905255
Validation loss: 4.919792807583561

Epoch: 5| Step: 6
Training loss: 4.431598231052734
Validation loss: 4.911890004173451

Epoch: 5| Step: 7
Training loss: 4.3212823313860005
Validation loss: 4.9023388657208296

Epoch: 5| Step: 8
Training loss: 4.6636216356233176
Validation loss: 4.892719802375446

Epoch: 5| Step: 9
Training loss: 5.234569762293122
Validation loss: 4.8844727100266585

Epoch: 5| Step: 10
Training loss: 4.626608697672825
Validation loss: 4.878044423073374

Epoch: 10| Step: 0
Training loss: 4.397597020886005
Validation loss: 4.867854114291477

Epoch: 5| Step: 1
Training loss: 5.600754428181522
Validation loss: 4.860472668953062

Epoch: 5| Step: 2
Training loss: 4.532355022520952
Validation loss: 4.848545404456436

Epoch: 5| Step: 3
Training loss: 4.398971498099171
Validation loss: 4.8374881319536005

Epoch: 5| Step: 4
Training loss: 5.261933886598036
Validation loss: 4.832866339918423

Epoch: 5| Step: 5
Training loss: 4.687998427276868
Validation loss: 4.821541202842331

Epoch: 5| Step: 6
Training loss: 5.479464949501229
Validation loss: 4.811694314947425

Epoch: 5| Step: 7
Training loss: 5.900558716779795
Validation loss: 4.80152993482135

Epoch: 5| Step: 8
Training loss: 4.697853555981419
Validation loss: 4.792819333463051

Epoch: 5| Step: 9
Training loss: 4.341438391914714
Validation loss: 4.780922840112075

Epoch: 5| Step: 10
Training loss: 4.024301380634016
Validation loss: 4.771143065161841

Epoch: 11| Step: 0
Training loss: 4.77705169059476
Validation loss: 4.75937831886276

Epoch: 5| Step: 1
Training loss: 4.850919868305968
Validation loss: 4.752945462214657

Epoch: 5| Step: 2
Training loss: 5.171130907634383
Validation loss: 4.741230088481014

Epoch: 5| Step: 3
Training loss: 3.7892870020475775
Validation loss: 4.729768153284885

Epoch: 5| Step: 4
Training loss: 4.587132676721664
Validation loss: 4.718170669394599

Epoch: 5| Step: 5
Training loss: 4.72602213143015
Validation loss: 4.709397042911086

Epoch: 5| Step: 6
Training loss: 5.129417562455731
Validation loss: 4.6986998196839345

Epoch: 5| Step: 7
Training loss: 5.068505010552144
Validation loss: 4.6841464542853375

Epoch: 5| Step: 8
Training loss: 4.560532446109401
Validation loss: 4.676413914358073

Epoch: 5| Step: 9
Training loss: 5.189983830362464
Validation loss: 4.664820905222914

Epoch: 5| Step: 10
Training loss: 4.588522291485354
Validation loss: 4.651743475756099

Epoch: 12| Step: 0
Training loss: 4.307960000209301
Validation loss: 4.640557465514696

Epoch: 5| Step: 1
Training loss: 4.935471323187567
Validation loss: 4.630611597241839

Epoch: 5| Step: 2
Training loss: 5.5248645196244475
Validation loss: 4.617663044018287

Epoch: 5| Step: 3
Training loss: 5.215807239235395
Validation loss: 4.6064084108490935

Epoch: 5| Step: 4
Training loss: 4.971211909128295
Validation loss: 4.59612957619711

Epoch: 5| Step: 5
Training loss: 3.7329824237302414
Validation loss: 4.580795383402093

Epoch: 5| Step: 6
Training loss: 3.901326242549534
Validation loss: 4.569714712392981

Epoch: 5| Step: 7
Training loss: 5.055798840287472
Validation loss: 4.553795720123157

Epoch: 5| Step: 8
Training loss: 4.895960033752278
Validation loss: 4.5434497216817356

Epoch: 5| Step: 9
Training loss: 4.109247125876992
Validation loss: 4.530575408338433

Epoch: 5| Step: 10
Training loss: 4.2225997878683525
Validation loss: 4.5167931077245465

Epoch: 13| Step: 0
Training loss: 4.857380841139004
Validation loss: 4.502185833011627

Epoch: 5| Step: 1
Training loss: 4.843172494239696
Validation loss: 4.489806473921234

Epoch: 5| Step: 2
Training loss: 4.752719100886219
Validation loss: 4.481673524117195

Epoch: 5| Step: 3
Training loss: 4.036287221255532
Validation loss: 4.46278836060953

Epoch: 5| Step: 4
Training loss: 4.798328092589215
Validation loss: 4.451432161034091

Epoch: 5| Step: 5
Training loss: 3.7651202231535454
Validation loss: 4.437437390687794

Epoch: 5| Step: 6
Training loss: 5.097835283314445
Validation loss: 4.423174609245097

Epoch: 5| Step: 7
Training loss: 4.084460252194629
Validation loss: 4.409165171430799

Epoch: 5| Step: 8
Training loss: 4.261106899966188
Validation loss: 4.396936228212469

Epoch: 5| Step: 9
Training loss: 4.71132980914695
Validation loss: 4.384870366198615

Epoch: 5| Step: 10
Training loss: 4.366359133968711
Validation loss: 4.370624110599895

Epoch: 14| Step: 0
Training loss: 4.15962988160643
Validation loss: 4.351930613578243

Epoch: 5| Step: 1
Training loss: 4.507639017188193
Validation loss: 4.336004110170358

Epoch: 5| Step: 2
Training loss: 4.391944116928254
Validation loss: 4.32556803473457

Epoch: 5| Step: 3
Training loss: 4.09065630545997
Validation loss: 4.306110051219435

Epoch: 5| Step: 4
Training loss: 4.68479780511961
Validation loss: 4.298995086498423

Epoch: 5| Step: 5
Training loss: 4.5172473144793495
Validation loss: 4.2770140401645005

Epoch: 5| Step: 6
Training loss: 4.150620398051441
Validation loss: 4.264584474774699

Epoch: 5| Step: 7
Training loss: 3.710475531483636
Validation loss: 4.250447963242944

Epoch: 5| Step: 8
Training loss: 4.34953702019411
Validation loss: 4.228923608566549

Epoch: 5| Step: 9
Training loss: 4.413421638350604
Validation loss: 4.2145101896199835

Epoch: 5| Step: 10
Training loss: 5.055233296520644
Validation loss: 4.201174506269391

Epoch: 15| Step: 0
Training loss: 5.597236782630343
Validation loss: 4.186450070545179

Epoch: 5| Step: 1
Training loss: 3.8463725005866296
Validation loss: 4.164929774060073

Epoch: 5| Step: 2
Training loss: 3.9519199147855235
Validation loss: 4.149171342585718

Epoch: 5| Step: 3
Training loss: 2.4566161952879266
Validation loss: 4.1260135955323305

Epoch: 5| Step: 4
Training loss: 4.5088856178406775
Validation loss: 4.1207704970258545

Epoch: 5| Step: 5
Training loss: 3.724762871894433
Validation loss: 4.09700995348967

Epoch: 5| Step: 6
Training loss: 4.188589836753731
Validation loss: 4.0818440486192165

Epoch: 5| Step: 7
Training loss: 4.331403571594826
Validation loss: 4.064741285318306

Epoch: 5| Step: 8
Training loss: 4.0441182884175
Validation loss: 4.046589979323693

Epoch: 5| Step: 9
Training loss: 4.621074557163757
Validation loss: 4.023624636993946

Epoch: 5| Step: 10
Training loss: 4.282782510056094
Validation loss: 4.008610341170749

Epoch: 16| Step: 0
Training loss: 3.548381737456092
Validation loss: 3.988165542948745

Epoch: 5| Step: 1
Training loss: 4.1553481421384
Validation loss: 3.971759959898574

Epoch: 5| Step: 2
Training loss: 3.2627565480354255
Validation loss: 3.9521453692891004

Epoch: 5| Step: 3
Training loss: 4.307761643711072
Validation loss: 3.9343726647674453

Epoch: 5| Step: 4
Training loss: 3.6043251017474707
Validation loss: 3.9260954321632537

Epoch: 5| Step: 5
Training loss: 3.474298936121384
Validation loss: 3.8977864815726693

Epoch: 5| Step: 6
Training loss: 4.734557900499643
Validation loss: 3.8790380507581066

Epoch: 5| Step: 7
Training loss: 3.702788905090213
Validation loss: 3.8626589023352156

Epoch: 5| Step: 8
Training loss: 3.996966523053899
Validation loss: 3.844460245084525

Epoch: 5| Step: 9
Training loss: 4.445969786094726
Validation loss: 3.8210738060780054

Epoch: 5| Step: 10
Training loss: 4.623831524033557
Validation loss: 3.804159765548726

Epoch: 17| Step: 0
Training loss: 3.2357746726145185
Validation loss: 3.78364335239517

Epoch: 5| Step: 1
Training loss: 4.116836793501313
Validation loss: 3.759287620387295

Epoch: 5| Step: 2
Training loss: 3.9853326581578106
Validation loss: 3.7443984303552584

Epoch: 5| Step: 3
Training loss: 3.056536882973929
Validation loss: 3.723948072675628

Epoch: 5| Step: 4
Training loss: 3.927633245333769
Validation loss: 3.7035055162757513

Epoch: 5| Step: 5
Training loss: 3.933365482802389
Validation loss: 3.6859620747289967

Epoch: 5| Step: 6
Training loss: 4.385568333749385
Validation loss: 3.659272152217534

Epoch: 5| Step: 7
Training loss: 4.1963739455357745
Validation loss: 3.6360306638982367

Epoch: 5| Step: 8
Training loss: 3.5001119868210053
Validation loss: 3.6171267549165425

Epoch: 5| Step: 9
Training loss: 3.6129067056722626
Validation loss: 3.597040685225293

Epoch: 5| Step: 10
Training loss: 3.75146277826191
Validation loss: 3.574798936766731

Epoch: 18| Step: 0
Training loss: 3.4532313265764043
Validation loss: 3.558280909010567

Epoch: 5| Step: 1
Training loss: 3.6004324441364037
Validation loss: 3.535149350587617

Epoch: 5| Step: 2
Training loss: 3.9274011107293467
Validation loss: 3.507312621284566

Epoch: 5| Step: 3
Training loss: 4.232065619740559
Validation loss: 3.4943536621152202

Epoch: 5| Step: 4
Training loss: 3.793255371830108
Validation loss: 3.4671199360468306

Epoch: 5| Step: 5
Training loss: 3.9003111592900157
Validation loss: 3.4465176372028976

Epoch: 5| Step: 6
Training loss: 3.732051749170138
Validation loss: 3.4246934285723536

Epoch: 5| Step: 7
Training loss: 3.4363787122747116
Validation loss: 3.400654762282676

Epoch: 5| Step: 8
Training loss: 3.2807500549190824
Validation loss: 3.3779833645114805

Epoch: 5| Step: 9
Training loss: 2.8126875920782783
Validation loss: 3.356150316808333

Epoch: 5| Step: 10
Training loss: 3.270686848917836
Validation loss: 3.3430972155485073

Epoch: 19| Step: 0
Training loss: 3.390355956482699
Validation loss: 3.3177102553307845

Epoch: 5| Step: 1
Training loss: 3.5760049327841923
Validation loss: 3.297250775739942

Epoch: 5| Step: 2
Training loss: 3.2834747038741514
Validation loss: 3.274831969155654

Epoch: 5| Step: 3
Training loss: 3.2687809492290807
Validation loss: 3.253337233686639

Epoch: 5| Step: 4
Training loss: 2.9323222202224724
Validation loss: 3.238783728023003

Epoch: 5| Step: 5
Training loss: 3.0850436304305577
Validation loss: 3.2194023582319518

Epoch: 5| Step: 6
Training loss: 3.8903546220213663
Validation loss: 3.2016341242623296

Epoch: 5| Step: 7
Training loss: 2.3907188446973158
Validation loss: 3.17699318604428

Epoch: 5| Step: 8
Training loss: 3.9510775001859413
Validation loss: 3.157283814678481

Epoch: 5| Step: 9
Training loss: 3.5337728754793556
Validation loss: 3.13983473643122

Epoch: 5| Step: 10
Training loss: 3.9002727706593645
Validation loss: 3.126376485897851

Epoch: 20| Step: 0
Training loss: 3.2494503436751794
Validation loss: 3.1063038506029255

Epoch: 5| Step: 1
Training loss: 3.5170453402558004
Validation loss: 3.0851205060264824

Epoch: 5| Step: 2
Training loss: 3.4481951705765157
Validation loss: 3.0664951198458104

Epoch: 5| Step: 3
Training loss: 2.635724910355796
Validation loss: 3.054346610298291

Epoch: 5| Step: 4
Training loss: 2.627295534869491
Validation loss: 3.031203208387125

Epoch: 5| Step: 5
Training loss: 3.065832699147192
Validation loss: 3.0097594615557512

Epoch: 5| Step: 6
Training loss: 3.5555198952423073
Validation loss: 2.9981322935008308

Epoch: 5| Step: 7
Training loss: 3.309447123288242
Validation loss: 2.9683204448055074

Epoch: 5| Step: 8
Training loss: 3.198419007516689
Validation loss: 2.966562854249713

Epoch: 5| Step: 9
Training loss: 3.591739257881402
Validation loss: 2.9426369610029046

Epoch: 5| Step: 10
Training loss: 3.2829059600235886
Validation loss: 2.9413405224495603

Epoch: 21| Step: 0
Training loss: 3.1248020872387454
Validation loss: 2.922904263610278

Epoch: 5| Step: 1
Training loss: 3.1712635371694002
Validation loss: 2.9053349963758697

Epoch: 5| Step: 2
Training loss: 3.1924047693971893
Validation loss: 2.8935011186922006

Epoch: 5| Step: 3
Training loss: 2.645098987306321
Validation loss: 2.8820130503906682

Epoch: 5| Step: 4
Training loss: 3.2569619950773037
Validation loss: 2.8680139869159746

Epoch: 5| Step: 5
Training loss: 3.299368543609528
Validation loss: 2.8548379217561206

Epoch: 5| Step: 6
Training loss: 3.8825464905892515
Validation loss: 2.8300125530148152

Epoch: 5| Step: 7
Training loss: 3.0423816903024026
Validation loss: 2.8261803128978515

Epoch: 5| Step: 8
Training loss: 2.789553046162983
Validation loss: 2.820944801915583

Epoch: 5| Step: 9
Training loss: 2.8743879247193584
Validation loss: 2.8080803239008763

Epoch: 5| Step: 10
Training loss: 2.691998287908908
Validation loss: 2.7911840458481265

Epoch: 22| Step: 0
Training loss: 2.820310640202382
Validation loss: 2.7929042426353754

Epoch: 5| Step: 1
Training loss: 3.3224582335959103
Validation loss: 2.7831215630587076

Epoch: 5| Step: 2
Training loss: 2.050067421339443
Validation loss: 2.7701170281723058

Epoch: 5| Step: 3
Training loss: 2.4284076815787006
Validation loss: 2.761950554303419

Epoch: 5| Step: 4
Training loss: 3.585524458357451
Validation loss: 2.750563403929591

Epoch: 5| Step: 5
Training loss: 3.1522372581145146
Validation loss: 2.734476667116768

Epoch: 5| Step: 6
Training loss: 3.4717971202448776
Validation loss: 2.7338150308904727

Epoch: 5| Step: 7
Training loss: 3.398634771124299
Validation loss: 2.730873307618414

Epoch: 5| Step: 8
Training loss: 2.8316842123037747
Validation loss: 2.7336426347453506

Epoch: 5| Step: 9
Training loss: 2.517387294121573
Validation loss: 2.716852995643319

Epoch: 5| Step: 10
Training loss: 3.3160049321468104
Validation loss: 2.7220931167645097

Epoch: 23| Step: 0
Training loss: 3.2768062473602644
Validation loss: 2.713816225321669

Epoch: 5| Step: 1
Training loss: 3.0999768717733662
Validation loss: 2.699524688205514

Epoch: 5| Step: 2
Training loss: 2.1485186197398654
Validation loss: 2.6975799035524517

Epoch: 5| Step: 3
Training loss: 2.8296693410559324
Validation loss: 2.689247536174487

Epoch: 5| Step: 4
Training loss: 2.975352604590432
Validation loss: 2.683921919879673

Epoch: 5| Step: 5
Training loss: 3.673505964659333
Validation loss: 2.695274702071353

Epoch: 5| Step: 6
Training loss: 2.9520542686250244
Validation loss: 2.6806495929556653

Epoch: 5| Step: 7
Training loss: 3.3727511224929336
Validation loss: 2.681354628955644

Epoch: 5| Step: 8
Training loss: 2.937449353369906
Validation loss: 2.671211663586907

Epoch: 5| Step: 9
Training loss: 2.6328593173519623
Validation loss: 2.678601225625216

Epoch: 5| Step: 10
Training loss: 2.7156678190905086
Validation loss: 2.6705149837896767

Epoch: 24| Step: 0
Training loss: 2.628969823740273
Validation loss: 2.666870277332717

Epoch: 5| Step: 1
Training loss: 2.291613826720517
Validation loss: 2.6619188730500616

Epoch: 5| Step: 2
Training loss: 3.633278699924921
Validation loss: 2.6560073674164397

Epoch: 5| Step: 3
Training loss: 2.9518436295980575
Validation loss: 2.669810090816774

Epoch: 5| Step: 4
Training loss: 2.907660685434443
Validation loss: 2.657842283606567

Epoch: 5| Step: 5
Training loss: 2.9633434656210977
Validation loss: 2.6563911820302386

Epoch: 5| Step: 6
Training loss: 2.694426106087939
Validation loss: 2.6553898325233782

Epoch: 5| Step: 7
Training loss: 2.7374147793817145
Validation loss: 2.6582957063703843

Epoch: 5| Step: 8
Training loss: 3.280051166786622
Validation loss: 2.653135725946362

Epoch: 5| Step: 9
Training loss: 2.616544821103259
Validation loss: 2.655934387798025

Epoch: 5| Step: 10
Training loss: 3.857095887135314
Validation loss: 2.639192556112698

Epoch: 25| Step: 0
Training loss: 3.336131034436547
Validation loss: 2.649842242345258

Epoch: 5| Step: 1
Training loss: 2.8573247511048456
Validation loss: 2.6467265923333754

Epoch: 5| Step: 2
Training loss: 2.6590867098083772
Validation loss: 2.6448135771777985

Epoch: 5| Step: 3
Training loss: 2.941810205287817
Validation loss: 2.639934780889798

Epoch: 5| Step: 4
Training loss: 2.6193391524137213
Validation loss: 2.6436788685100128

Epoch: 5| Step: 5
Training loss: 3.358841822696118
Validation loss: 2.6525118569137907

Epoch: 5| Step: 6
Training loss: 2.77015556325543
Validation loss: 2.6401371396896125

Epoch: 5| Step: 7
Training loss: 3.310712656016896
Validation loss: 2.6410561156444383

Epoch: 5| Step: 8
Training loss: 3.187124940834414
Validation loss: 2.6407952226787783

Epoch: 5| Step: 9
Training loss: 2.3396529946241826
Validation loss: 2.6457156625990708

Epoch: 5| Step: 10
Training loss: 3.120363992830629
Validation loss: 2.6453118857292215

Epoch: 26| Step: 0
Training loss: 3.2711558253864887
Validation loss: 2.6474459049570642

Epoch: 5| Step: 1
Training loss: 2.084554034869807
Validation loss: 2.6362974274313964

Epoch: 5| Step: 2
Training loss: 2.7255057224345873
Validation loss: 2.6374488850885265

Epoch: 5| Step: 3
Training loss: 3.2212150541637077
Validation loss: 2.638018192291193

Epoch: 5| Step: 4
Training loss: 2.7659900661408727
Validation loss: 2.647516008323429

Epoch: 5| Step: 5
Training loss: 3.778166341121587
Validation loss: 2.6438567051856414

Epoch: 5| Step: 6
Training loss: 3.2305239542403794
Validation loss: 2.633662439631194

Epoch: 5| Step: 7
Training loss: 2.691781824756576
Validation loss: 2.6387406239707065

Epoch: 5| Step: 8
Training loss: 2.8219004886527954
Validation loss: 2.640835847717477

Epoch: 5| Step: 9
Training loss: 2.593610828756404
Validation loss: 2.6380161417807533

Epoch: 5| Step: 10
Training loss: 3.066034107344519
Validation loss: 2.633571800202057

Epoch: 27| Step: 0
Training loss: 2.977342398289594
Validation loss: 2.6348283538980644

Epoch: 5| Step: 1
Training loss: 3.2665420047821745
Validation loss: 2.6332922807154246

Epoch: 5| Step: 2
Training loss: 2.614636444727669
Validation loss: 2.6306938697115565

Epoch: 5| Step: 3
Training loss: 2.760351638507835
Validation loss: 2.6388186014900623

Epoch: 5| Step: 4
Training loss: 2.9583548603259646
Validation loss: 2.6375322515781225

Epoch: 5| Step: 5
Training loss: 3.1490835279554017
Validation loss: 2.639638640933643

Epoch: 5| Step: 6
Training loss: 2.6481342873535363
Validation loss: 2.656502507927728

Epoch: 5| Step: 7
Training loss: 2.572214275244385
Validation loss: 2.6323307414882557

Epoch: 5| Step: 8
Training loss: 2.9704800032292695
Validation loss: 2.6296751869505197

Epoch: 5| Step: 9
Training loss: 3.1530137797646463
Validation loss: 2.640772939218509

Epoch: 5| Step: 10
Training loss: 3.366863898993136
Validation loss: 2.628740852386111

Epoch: 28| Step: 0
Training loss: 2.7494487209890175
Validation loss: 2.621715734409461

Epoch: 5| Step: 1
Training loss: 2.652065616457591
Validation loss: 2.6282174822458413

Epoch: 5| Step: 2
Training loss: 2.901273178277543
Validation loss: 2.629351893983342

Epoch: 5| Step: 3
Training loss: 2.620653459433994
Validation loss: 2.63676014176865

Epoch: 5| Step: 4
Training loss: 2.803790530805967
Validation loss: 2.630492923187578

Epoch: 5| Step: 5
Training loss: 3.726259487156658
Validation loss: 2.620127226326758

Epoch: 5| Step: 6
Training loss: 2.8674228166271476
Validation loss: 2.6094433910182526

Epoch: 5| Step: 7
Training loss: 2.726202386285503
Validation loss: 2.63009307488579

Epoch: 5| Step: 8
Training loss: 2.8317259735788203
Validation loss: 2.625103303895282

Epoch: 5| Step: 9
Training loss: 3.115495341978722
Validation loss: 2.622941043214025

Epoch: 5| Step: 10
Training loss: 3.190385746368662
Validation loss: 2.631457119436016

Epoch: 29| Step: 0
Training loss: 3.3143591791617353
Validation loss: 2.6223767831993543

Epoch: 5| Step: 1
Training loss: 3.3638865848795523
Validation loss: 2.615963293749481

Epoch: 5| Step: 2
Training loss: 2.8095720096883996
Validation loss: 2.629636199887342

Epoch: 5| Step: 3
Training loss: 2.3638122466478473
Validation loss: 2.623309394790633

Epoch: 5| Step: 4
Training loss: 2.2676766412775327
Validation loss: 2.629419423184878

Epoch: 5| Step: 5
Training loss: 2.953441461631694
Validation loss: 2.630757072337869

Epoch: 5| Step: 6
Training loss: 3.385475854600792
Validation loss: 2.623882966246265

Epoch: 5| Step: 7
Training loss: 2.3798984406544723
Validation loss: 2.6308775815587957

Epoch: 5| Step: 8
Training loss: 3.5446649463537705
Validation loss: 2.6400123968576006

Epoch: 5| Step: 9
Training loss: 2.9501304985535968
Validation loss: 2.623499316818698

Epoch: 5| Step: 10
Training loss: 2.609306745721519
Validation loss: 2.627353786818548

Epoch: 30| Step: 0
Training loss: 2.839052953373379
Validation loss: 2.6287249530784114

Epoch: 5| Step: 1
Training loss: 3.0454574025941694
Validation loss: 2.6268851947277474

Epoch: 5| Step: 2
Training loss: 3.0536537860417843
Validation loss: 2.6242527559825595

Epoch: 5| Step: 3
Training loss: 3.3959491608569468
Validation loss: 2.6214778262909646

Epoch: 5| Step: 4
Training loss: 2.2676769566909716
Validation loss: 2.6172763712032183

Epoch: 5| Step: 5
Training loss: 2.4446182971840416
Validation loss: 2.6189449496868376

Epoch: 5| Step: 6
Training loss: 3.091937372192718
Validation loss: 2.6210710349604844

Epoch: 5| Step: 7
Training loss: 3.2158659819676956
Validation loss: 2.629241265720941

Epoch: 5| Step: 8
Training loss: 3.128781891255265
Validation loss: 2.61638610746061

Epoch: 5| Step: 9
Training loss: 2.876893125116873
Validation loss: 2.6151227235741725

Epoch: 5| Step: 10
Training loss: 2.606689716084356
Validation loss: 2.620335000857093

Epoch: 31| Step: 0
Training loss: 2.689892347230863
Validation loss: 2.6177088377875752

Epoch: 5| Step: 1
Training loss: 2.6937093638742704
Validation loss: 2.6156360164300616

Epoch: 5| Step: 2
Training loss: 3.1686127521955827
Validation loss: 2.6177396683728635

Epoch: 5| Step: 3
Training loss: 2.712677762583629
Validation loss: 2.6134333277577912

Epoch: 5| Step: 4
Training loss: 2.4133707678861436
Validation loss: 2.6173407592860958

Epoch: 5| Step: 5
Training loss: 2.8539432150438495
Validation loss: 2.621920273744739

Epoch: 5| Step: 6
Training loss: 2.7297670611538267
Validation loss: 2.623358544851367

Epoch: 5| Step: 7
Training loss: 3.356370158681823
Validation loss: 2.6081247599430637

Epoch: 5| Step: 8
Training loss: 3.394015397009377
Validation loss: 2.6234912179081147

Epoch: 5| Step: 9
Training loss: 2.9178775635225014
Validation loss: 2.6184159881746076

Epoch: 5| Step: 10
Training loss: 3.2208473261191606
Validation loss: 2.613120013995306

Epoch: 32| Step: 0
Training loss: 2.906381255436582
Validation loss: 2.6134915208336307

Epoch: 5| Step: 1
Training loss: 2.4534804943079753
Validation loss: 2.6213922402324927

Epoch: 5| Step: 2
Training loss: 3.1212486639237667
Validation loss: 2.617082528396972

Epoch: 5| Step: 3
Training loss: 2.522555453973526
Validation loss: 2.6063799883737

Epoch: 5| Step: 4
Training loss: 2.822888410551163
Validation loss: 2.610754000277623

Epoch: 5| Step: 5
Training loss: 3.360912875870467
Validation loss: 2.6062793177130206

Epoch: 5| Step: 6
Training loss: 3.092005073829426
Validation loss: 2.6068807412411523

Epoch: 5| Step: 7
Training loss: 3.348910476239795
Validation loss: 2.610871519865098

Epoch: 5| Step: 8
Training loss: 2.720673154952035
Validation loss: 2.6189778722511536

Epoch: 5| Step: 9
Training loss: 2.8449109401071087
Validation loss: 2.6042338038168293

Epoch: 5| Step: 10
Training loss: 2.741356009030843
Validation loss: 2.6043428193268543

Epoch: 33| Step: 0
Training loss: 3.3113457450114403
Validation loss: 2.6086144324130722

Epoch: 5| Step: 1
Training loss: 2.780314427439761
Validation loss: 2.6105844162038725

Epoch: 5| Step: 2
Training loss: 2.570445605138975
Validation loss: 2.616359445869298

Epoch: 5| Step: 3
Training loss: 2.969470448663094
Validation loss: 2.6210523035119317

Epoch: 5| Step: 4
Training loss: 3.6417924703579363
Validation loss: 2.616065905441214

Epoch: 5| Step: 5
Training loss: 2.4659710465995412
Validation loss: 2.607214167760129

Epoch: 5| Step: 6
Training loss: 2.6709465510691546
Validation loss: 2.602230182564644

Epoch: 5| Step: 7
Training loss: 2.6810571490026582
Validation loss: 2.6112992794081857

Epoch: 5| Step: 8
Training loss: 3.080489436560724
Validation loss: 2.605698113467355

Epoch: 5| Step: 9
Training loss: 3.264777698747835
Validation loss: 2.603651807198506

Epoch: 5| Step: 10
Training loss: 2.1516784636718036
Validation loss: 2.6023128882914297

Epoch: 34| Step: 0
Training loss: 2.9157386029876116
Validation loss: 2.6085166961318564

Epoch: 5| Step: 1
Training loss: 3.1349260996210817
Validation loss: 2.6051599212192214

Epoch: 5| Step: 2
Training loss: 3.370249477853049
Validation loss: 2.6043458177204695

Epoch: 5| Step: 3
Training loss: 2.6618077197487544
Validation loss: 2.6077167521991584

Epoch: 5| Step: 4
Training loss: 2.426296898036317
Validation loss: 2.6025397687833802

Epoch: 5| Step: 5
Training loss: 2.256217630846302
Validation loss: 2.609150328213528

Epoch: 5| Step: 6
Training loss: 2.586027207215961
Validation loss: 2.6035291939125735

Epoch: 5| Step: 7
Training loss: 2.537919382851583
Validation loss: 2.6006169277046687

Epoch: 5| Step: 8
Training loss: 3.2944654002674807
Validation loss: 2.604750991402674

Epoch: 5| Step: 9
Training loss: 3.06189752997546
Validation loss: 2.6076903981629216

Epoch: 5| Step: 10
Training loss: 3.5577480010433877
Validation loss: 2.5995447854001372

Epoch: 35| Step: 0
Training loss: 3.0310594951110463
Validation loss: 2.6046129384920707

Epoch: 5| Step: 1
Training loss: 2.9072831481203765
Validation loss: 2.6094996777648194

Epoch: 5| Step: 2
Training loss: 2.934974558783358
Validation loss: 2.605093246183657

Epoch: 5| Step: 3
Training loss: 3.113546822012833
Validation loss: 2.604518730402085

Epoch: 5| Step: 4
Training loss: 3.0130645476225113
Validation loss: 2.6052940947095093

Epoch: 5| Step: 5
Training loss: 2.9286948188015094
Validation loss: 2.6041109009381134

Epoch: 5| Step: 6
Training loss: 2.954801537679848
Validation loss: 2.595590783550804

Epoch: 5| Step: 7
Training loss: 2.959930812439492
Validation loss: 2.6088876557132226

Epoch: 5| Step: 8
Training loss: 3.0931442130034164
Validation loss: 2.5988021712591247

Epoch: 5| Step: 9
Training loss: 2.1172619345555295
Validation loss: 2.595418494960259

Epoch: 5| Step: 10
Training loss: 2.7281642460922337
Validation loss: 2.6051439744347995

Epoch: 36| Step: 0
Training loss: 3.138431371318026
Validation loss: 2.5960448740939497

Epoch: 5| Step: 1
Training loss: 2.9587147605612123
Validation loss: 2.596684859836033

Epoch: 5| Step: 2
Training loss: 3.3877500659941777
Validation loss: 2.587535145902191

Epoch: 5| Step: 3
Training loss: 2.990564608387673
Validation loss: 2.5879473081956705

Epoch: 5| Step: 4
Training loss: 2.9430384267928935
Validation loss: 2.5963799725719023

Epoch: 5| Step: 5
Training loss: 2.9770465767586556
Validation loss: 2.5963614224023654

Epoch: 5| Step: 6
Training loss: 3.0038073539576304
Validation loss: 2.5945059026577564

Epoch: 5| Step: 7
Training loss: 2.4402946688215157
Validation loss: 2.600444417081937

Epoch: 5| Step: 8
Training loss: 2.5932070611973224
Validation loss: 2.5921514541671473

Epoch: 5| Step: 9
Training loss: 2.6075998081259284
Validation loss: 2.591087514701607

Epoch: 5| Step: 10
Training loss: 2.5681156869600144
Validation loss: 2.5999792232267005

Epoch: 37| Step: 0
Training loss: 2.4399040300225368
Validation loss: 2.6048323701277027

Epoch: 5| Step: 1
Training loss: 2.6591343198136017
Validation loss: 2.6001500244967657

Epoch: 5| Step: 2
Training loss: 2.8465768366925954
Validation loss: 2.5885178472509494

Epoch: 5| Step: 3
Training loss: 2.1871800869934495
Validation loss: 2.5969974664124233

Epoch: 5| Step: 4
Training loss: 3.4658075172787903
Validation loss: 2.5984327691682663

Epoch: 5| Step: 5
Training loss: 3.279239583608386
Validation loss: 2.5931872565277563

Epoch: 5| Step: 6
Training loss: 2.7586746381137752
Validation loss: 2.593638911304091

Epoch: 5| Step: 7
Training loss: 3.1326931671474285
Validation loss: 2.5940213684776343

Epoch: 5| Step: 8
Training loss: 3.0696916801876983
Validation loss: 2.5908941802906655

Epoch: 5| Step: 9
Training loss: 3.1126792641610357
Validation loss: 2.5882573637134656

Epoch: 5| Step: 10
Training loss: 2.438460332031988
Validation loss: 2.5926405185241994

Epoch: 38| Step: 0
Training loss: 2.6346910606109555
Validation loss: 2.6001859851211275

Epoch: 5| Step: 1
Training loss: 2.311584910198651
Validation loss: 2.5881613082627677

Epoch: 5| Step: 2
Training loss: 2.6725316718627257
Validation loss: 2.5881794169926935

Epoch: 5| Step: 3
Training loss: 2.8731431354965213
Validation loss: 2.5947422818438226

Epoch: 5| Step: 4
Training loss: 2.900212076259299
Validation loss: 2.5929320778282907

Epoch: 5| Step: 5
Training loss: 2.5360072137507417
Validation loss: 2.591696648816173

Epoch: 5| Step: 6
Training loss: 2.9553469417759817
Validation loss: 2.5828663125647124

Epoch: 5| Step: 7
Training loss: 2.835519807178976
Validation loss: 2.5850399710062373

Epoch: 5| Step: 8
Training loss: 3.653551197888271
Validation loss: 2.5951349203535035

Epoch: 5| Step: 9
Training loss: 2.8058195671859436
Validation loss: 2.594995260271267

Epoch: 5| Step: 10
Training loss: 3.3566064116124825
Validation loss: 2.600320650889396

Epoch: 39| Step: 0
Training loss: 2.623374253874409
Validation loss: 2.5899757593265087

Epoch: 5| Step: 1
Training loss: 2.9101231515525505
Validation loss: 2.5961612208391105

Epoch: 5| Step: 2
Training loss: 3.233255238589464
Validation loss: 2.598020753677308

Epoch: 5| Step: 3
Training loss: 3.45091418441417
Validation loss: 2.602754833500443

Epoch: 5| Step: 4
Training loss: 2.913841259614269
Validation loss: 2.590536503726499

Epoch: 5| Step: 5
Training loss: 2.7212463844285812
Validation loss: 2.5874104164138996

Epoch: 5| Step: 6
Training loss: 2.1739730032654503
Validation loss: 2.58270050366417

Epoch: 5| Step: 7
Training loss: 2.9951372472429
Validation loss: 2.5889924844995638

Epoch: 5| Step: 8
Training loss: 2.868432047724776
Validation loss: 2.5761937972489135

Epoch: 5| Step: 9
Training loss: 2.85238543615543
Validation loss: 2.5899056367055393

Epoch: 5| Step: 10
Training loss: 2.749779172180569
Validation loss: 2.58341457730086

Epoch: 40| Step: 0
Training loss: 2.9012802455102955
Validation loss: 2.58072503652706

Epoch: 5| Step: 1
Training loss: 2.939338757897633
Validation loss: 2.5705557085144113

Epoch: 5| Step: 2
Training loss: 3.0130428663990663
Validation loss: 2.588782071638004

Epoch: 5| Step: 3
Training loss: 3.272051898069043
Validation loss: 2.5986082259736314

Epoch: 5| Step: 4
Training loss: 3.1576219353044657
Validation loss: 2.5881967411103175

Epoch: 5| Step: 5
Training loss: 2.7690406009594666
Validation loss: 2.5900765638255034

Epoch: 5| Step: 6
Training loss: 3.1461561092148314
Validation loss: 2.5900928656711635

Epoch: 5| Step: 7
Training loss: 3.05986532426058
Validation loss: 2.594594971752152

Epoch: 5| Step: 8
Training loss: 2.4529117564437377
Validation loss: 2.5921412595237774

Epoch: 5| Step: 9
Training loss: 2.357733957892351
Validation loss: 2.5892749734022606

Epoch: 5| Step: 10
Training loss: 2.2686780681714085
Validation loss: 2.5815895316704474

Epoch: 41| Step: 0
Training loss: 3.348209580191076
Validation loss: 2.576710070771781

Epoch: 5| Step: 1
Training loss: 3.0630545600617434
Validation loss: 2.5831144129640853

Epoch: 5| Step: 2
Training loss: 2.598282954975734
Validation loss: 2.585046231738727

Epoch: 5| Step: 3
Training loss: 2.8679404452430557
Validation loss: 2.5806484885091763

Epoch: 5| Step: 4
Training loss: 2.9894575209954777
Validation loss: 2.5769046185855267

Epoch: 5| Step: 5
Training loss: 3.160120790563188
Validation loss: 2.5791491311792045

Epoch: 5| Step: 6
Training loss: 3.0661011367908713
Validation loss: 2.5901338761872608

Epoch: 5| Step: 7
Training loss: 2.120121685710336
Validation loss: 2.5785719020862596

Epoch: 5| Step: 8
Training loss: 2.4116861937425904
Validation loss: 2.581505078563532

Epoch: 5| Step: 9
Training loss: 2.7782780059114143
Validation loss: 2.576836173797344

Epoch: 5| Step: 10
Training loss: 2.8506205636065016
Validation loss: 2.5704030766744728

Epoch: 42| Step: 0
Training loss: 2.7606768983259675
Validation loss: 2.5830390513141763

Epoch: 5| Step: 1
Training loss: 3.0712966700521838
Validation loss: 2.577963075745368

Epoch: 5| Step: 2
Training loss: 3.052709070492533
Validation loss: 2.5768551585091837

Epoch: 5| Step: 3
Training loss: 2.657335306484921
Validation loss: 2.57685573404248

Epoch: 5| Step: 4
Training loss: 3.369013527946906
Validation loss: 2.5774862234551223

Epoch: 5| Step: 5
Training loss: 2.2904508891425133
Validation loss: 2.5814112467031864

Epoch: 5| Step: 6
Training loss: 2.8911303928966037
Validation loss: 2.5795654479080676

Epoch: 5| Step: 7
Training loss: 3.1095585601145603
Validation loss: 2.574896997688911

Epoch: 5| Step: 8
Training loss: 2.675514909617529
Validation loss: 2.5821422691853604

Epoch: 5| Step: 9
Training loss: 2.6180046058596784
Validation loss: 2.590421602611209

Epoch: 5| Step: 10
Training loss: 2.902046034318328
Validation loss: 2.5797480868862244

Epoch: 43| Step: 0
Training loss: 2.649160460874527
Validation loss: 2.581901036794702

Epoch: 5| Step: 1
Training loss: 2.549430267415747
Validation loss: 2.5814994239607634

Epoch: 5| Step: 2
Training loss: 2.7635651584685528
Validation loss: 2.583780017531189

Epoch: 5| Step: 3
Training loss: 2.2104545578029455
Validation loss: 2.5682311398275792

Epoch: 5| Step: 4
Training loss: 2.7143781743040942
Validation loss: 2.5700306380498055

Epoch: 5| Step: 5
Training loss: 2.4775605221466654
Validation loss: 2.570919536321301

Epoch: 5| Step: 6
Training loss: 2.8946666608635008
Validation loss: 2.57271683028015

Epoch: 5| Step: 7
Training loss: 3.1769394305215575
Validation loss: 2.566650526840078

Epoch: 5| Step: 8
Training loss: 3.3610377255529773
Validation loss: 2.5702977483486715

Epoch: 5| Step: 9
Training loss: 2.937438152554952
Validation loss: 2.5675587895843033

Epoch: 5| Step: 10
Training loss: 3.5561627690724054
Validation loss: 2.575071511498707

Epoch: 44| Step: 0
Training loss: 2.895471746982388
Validation loss: 2.5787451959237497

Epoch: 5| Step: 1
Training loss: 2.6172135536832863
Validation loss: 2.5811067483375307

Epoch: 5| Step: 2
Training loss: 3.0776870338506677
Validation loss: 2.5646297599343666

Epoch: 5| Step: 3
Training loss: 2.918144905053491
Validation loss: 2.5819714165250955

Epoch: 5| Step: 4
Training loss: 2.2824983708353903
Validation loss: 2.578419140256934

Epoch: 5| Step: 5
Training loss: 3.0108943854958365
Validation loss: 2.5760174133651312

Epoch: 5| Step: 6
Training loss: 2.7887449110421567
Validation loss: 2.5772298074709323

Epoch: 5| Step: 7
Training loss: 3.355674799497912
Validation loss: 2.5715249857851927

Epoch: 5| Step: 8
Training loss: 2.8474181275826234
Validation loss: 2.561089248154024

Epoch: 5| Step: 9
Training loss: 2.6943062935857918
Validation loss: 2.563075655494651

Epoch: 5| Step: 10
Training loss: 2.6905603062099424
Validation loss: 2.568037069987147

Epoch: 45| Step: 0
Training loss: 2.576854970975835
Validation loss: 2.570007572438233

Epoch: 5| Step: 1
Training loss: 3.188720768548182
Validation loss: 2.5749674414187096

Epoch: 5| Step: 2
Training loss: 2.5697961537899636
Validation loss: 2.5665046379726517

Epoch: 5| Step: 3
Training loss: 3.2768954492164095
Validation loss: 2.5752389534329296

Epoch: 5| Step: 4
Training loss: 3.142943025010074
Validation loss: 2.5695724072603827

Epoch: 5| Step: 5
Training loss: 1.9624505759654942
Validation loss: 2.5637859276331825

Epoch: 5| Step: 6
Training loss: 2.439293030738031
Validation loss: 2.5624294656469733

Epoch: 5| Step: 7
Training loss: 2.4594970362630484
Validation loss: 2.552070121069622

Epoch: 5| Step: 8
Training loss: 3.6096571774844275
Validation loss: 2.573064747920266

Epoch: 5| Step: 9
Training loss: 2.652732045399139
Validation loss: 2.5724660458793394

Epoch: 5| Step: 10
Training loss: 3.038989068642099
Validation loss: 2.565745600573451

Epoch: 46| Step: 0
Training loss: 2.745383549282708
Validation loss: 2.5653543839450665

Epoch: 5| Step: 1
Training loss: 2.413143933786818
Validation loss: 2.5604557914637933

Epoch: 5| Step: 2
Training loss: 2.782137782674443
Validation loss: 2.5532420324165574

Epoch: 5| Step: 3
Training loss: 2.644845693085775
Validation loss: 2.5577997379151354

Epoch: 5| Step: 4
Training loss: 3.116592388661923
Validation loss: 2.5606664985688954

Epoch: 5| Step: 5
Training loss: 3.04889475073342
Validation loss: 2.558671622119463

Epoch: 5| Step: 6
Training loss: 2.8829320867281996
Validation loss: 2.5661563623960113

Epoch: 5| Step: 7
Training loss: 2.913923735804686
Validation loss: 2.5631292267410575

Epoch: 5| Step: 8
Training loss: 3.04383283498479
Validation loss: 2.5667722520364418

Epoch: 5| Step: 9
Training loss: 2.5014527868054395
Validation loss: 2.5555604660744353

Epoch: 5| Step: 10
Training loss: 3.0575510637412506
Validation loss: 2.569643727746416

Epoch: 47| Step: 0
Training loss: 2.8776604326135646
Validation loss: 2.5640443679596285

Epoch: 5| Step: 1
Training loss: 2.343468407563049
Validation loss: 2.5783169771563603

Epoch: 5| Step: 2
Training loss: 3.136942664262391
Validation loss: 2.56445057980538

Epoch: 5| Step: 3
Training loss: 2.6257102550384928
Validation loss: 2.5610144746474517

Epoch: 5| Step: 4
Training loss: 2.6088126484578034
Validation loss: 2.5642744833924054

Epoch: 5| Step: 5
Training loss: 3.449079672751741
Validation loss: 2.565174800703378

Epoch: 5| Step: 6
Training loss: 2.31924701720993
Validation loss: 2.5628760852450645

Epoch: 5| Step: 7
Training loss: 2.9585689038970253
Validation loss: 2.557169767212518

Epoch: 5| Step: 8
Training loss: 3.080414980390794
Validation loss: 2.565453638673646

Epoch: 5| Step: 9
Training loss: 2.5507633039184934
Validation loss: 2.5683528420165467

Epoch: 5| Step: 10
Training loss: 3.029823518152082
Validation loss: 2.559433906297284

Epoch: 48| Step: 0
Training loss: 2.4664373067810277
Validation loss: 2.5689590226343735

Epoch: 5| Step: 1
Training loss: 2.1326647137872152
Validation loss: 2.573961542389404

Epoch: 5| Step: 2
Training loss: 2.8609129724956417
Validation loss: 2.5673158303995307

Epoch: 5| Step: 3
Training loss: 3.551447269770584
Validation loss: 2.5708678560353393

Epoch: 5| Step: 4
Training loss: 3.2543361787365175
Validation loss: 2.5629568655633497

Epoch: 5| Step: 5
Training loss: 2.736290222820342
Validation loss: 2.5718281903643017

Epoch: 5| Step: 6
Training loss: 2.77564695222897
Validation loss: 2.563608980554904

Epoch: 5| Step: 7
Training loss: 1.9697617852499585
Validation loss: 2.5613343093310648

Epoch: 5| Step: 8
Training loss: 2.8203576419842094
Validation loss: 2.5702195422368797

Epoch: 5| Step: 9
Training loss: 3.0113138799989803
Validation loss: 2.5666639380592997

Epoch: 5| Step: 10
Training loss: 3.289190511862704
Validation loss: 2.5576852956199465

Epoch: 49| Step: 0
Training loss: 2.437495011544625
Validation loss: 2.5575522200313157

Epoch: 5| Step: 1
Training loss: 2.7324918529392535
Validation loss: 2.566608198187395

Epoch: 5| Step: 2
Training loss: 2.5835158888599743
Validation loss: 2.5680052803067555

Epoch: 5| Step: 3
Training loss: 3.2861463073181305
Validation loss: 2.565137602693998

Epoch: 5| Step: 4
Training loss: 2.8490236450370974
Validation loss: 2.563132736438788

Epoch: 5| Step: 5
Training loss: 2.9675827140817814
Validation loss: 2.554281533077031

Epoch: 5| Step: 6
Training loss: 2.5379775326142444
Validation loss: 2.562874212185781

Epoch: 5| Step: 7
Training loss: 2.845004632875663
Validation loss: 2.5650401697357808

Epoch: 5| Step: 8
Training loss: 2.7552221306285314
Validation loss: 2.5587003957288523

Epoch: 5| Step: 9
Training loss: 2.8501350906211513
Validation loss: 2.547978259677923

Epoch: 5| Step: 10
Training loss: 3.15580640640503
Validation loss: 2.5602627914324834

Epoch: 50| Step: 0
Training loss: 3.000074703558015
Validation loss: 2.5545069059410594

Epoch: 5| Step: 1
Training loss: 3.5760194672005583
Validation loss: 2.5541607211814843

Epoch: 5| Step: 2
Training loss: 2.555228266513197
Validation loss: 2.5558864076680674

Epoch: 5| Step: 3
Training loss: 3.15676588620229
Validation loss: 2.555610962734196

Epoch: 5| Step: 4
Training loss: 2.899894409888225
Validation loss: 2.562219752992515

Epoch: 5| Step: 5
Training loss: 2.6619286367364614
Validation loss: 2.554003528088462

Epoch: 5| Step: 6
Training loss: 3.0728446477866647
Validation loss: 2.54893535834297

Epoch: 5| Step: 7
Training loss: 2.374620808898437
Validation loss: 2.561815466040796

Epoch: 5| Step: 8
Training loss: 2.6482831071620594
Validation loss: 2.550714477193745

Epoch: 5| Step: 9
Training loss: 2.4885209715152867
Validation loss: 2.563962267574499

Epoch: 5| Step: 10
Training loss: 2.176736673258447
Validation loss: 2.566924411650227

Epoch: 51| Step: 0
Training loss: 2.6265109118967125
Validation loss: 2.568342769510948

Epoch: 5| Step: 1
Training loss: 2.6556951504314545
Validation loss: 2.562967654418233

Epoch: 5| Step: 2
Training loss: 2.8383017528999868
Validation loss: 2.55763676141552

Epoch: 5| Step: 3
Training loss: 2.2244578268864057
Validation loss: 2.554464007744606

Epoch: 5| Step: 4
Training loss: 3.286313899635279
Validation loss: 2.551317001382376

Epoch: 5| Step: 5
Training loss: 2.9112794078424256
Validation loss: 2.5506961054957937

Epoch: 5| Step: 6
Training loss: 2.4678357519895053
Validation loss: 2.561358697155065

Epoch: 5| Step: 7
Training loss: 3.3858248577032177
Validation loss: 2.5423003542665197

Epoch: 5| Step: 8
Training loss: 2.7608769926684964
Validation loss: 2.5614120971311007

Epoch: 5| Step: 9
Training loss: 2.6252651988898097
Validation loss: 2.5488876542641736

Epoch: 5| Step: 10
Training loss: 3.1050842430984513
Validation loss: 2.5477804716767363

Epoch: 52| Step: 0
Training loss: 2.94077848546706
Validation loss: 2.5551891548733234

Epoch: 5| Step: 1
Training loss: 2.201094103897293
Validation loss: 2.5479998429484882

Epoch: 5| Step: 2
Training loss: 2.87999589813788
Validation loss: 2.5552446753047398

Epoch: 5| Step: 3
Training loss: 2.8646182156375226
Validation loss: 2.5477150868344727

Epoch: 5| Step: 4
Training loss: 2.758838927231873
Validation loss: 2.5518807533999395

Epoch: 5| Step: 5
Training loss: 2.935318806634474
Validation loss: 2.5561288796047905

Epoch: 5| Step: 6
Training loss: 3.0131534864831346
Validation loss: 2.5448615115375524

Epoch: 5| Step: 7
Training loss: 2.830579840901467
Validation loss: 2.5348051387904964

Epoch: 5| Step: 8
Training loss: 2.765788014235936
Validation loss: 2.537297010988701

Epoch: 5| Step: 9
Training loss: 2.951017081583212
Validation loss: 2.5495025410125796

Epoch: 5| Step: 10
Training loss: 2.644494105744496
Validation loss: 2.5561836986446482

Epoch: 53| Step: 0
Training loss: 3.0607257296575106
Validation loss: 2.5473834477138526

Epoch: 5| Step: 1
Training loss: 2.8306202708158703
Validation loss: 2.551918364151351

Epoch: 5| Step: 2
Training loss: 3.1093691725173094
Validation loss: 2.5443106149312134

Epoch: 5| Step: 3
Training loss: 2.5751497614003225
Validation loss: 2.5444544292670255

Epoch: 5| Step: 4
Training loss: 2.9305665998768013
Validation loss: 2.538870700000238

Epoch: 5| Step: 5
Training loss: 2.5911229629401857
Validation loss: 2.5505404648988796

Epoch: 5| Step: 6
Training loss: 2.3014455979253476
Validation loss: 2.543120769298554

Epoch: 5| Step: 7
Training loss: 2.6199150789490373
Validation loss: 2.549173000465549

Epoch: 5| Step: 8
Training loss: 3.204512132954704
Validation loss: 2.555491868949943

Epoch: 5| Step: 9
Training loss: 2.9191635525013737
Validation loss: 2.5561846935383317

Epoch: 5| Step: 10
Training loss: 2.659989361562465
Validation loss: 2.5542251215142553

Epoch: 54| Step: 0
Training loss: 1.983934548825038
Validation loss: 2.5512141991422532

Epoch: 5| Step: 1
Training loss: 3.2636715827909804
Validation loss: 2.5495272652437926

Epoch: 5| Step: 2
Training loss: 2.635613646452279
Validation loss: 2.5548712511383953

Epoch: 5| Step: 3
Training loss: 1.752317937081741
Validation loss: 2.549258398980672

Epoch: 5| Step: 4
Training loss: 3.184124524389146
Validation loss: 2.5377950019083224

Epoch: 5| Step: 5
Training loss: 2.9764218434819427
Validation loss: 2.536646658563395

Epoch: 5| Step: 6
Training loss: 2.9126968251794
Validation loss: 2.553382882862884

Epoch: 5| Step: 7
Training loss: 2.70103232463884
Validation loss: 2.5401894506027514

Epoch: 5| Step: 8
Training loss: 3.3097339813653885
Validation loss: 2.5486078025269827

Epoch: 5| Step: 9
Training loss: 3.2258672450089874
Validation loss: 2.546070047417666

Epoch: 5| Step: 10
Training loss: 2.2913690084714418
Validation loss: 2.5509536188183337

Epoch: 55| Step: 0
Training loss: 2.959964320509037
Validation loss: 2.54274302089835

Epoch: 5| Step: 1
Training loss: 2.8634612689082415
Validation loss: 2.5494113183100247

Epoch: 5| Step: 2
Training loss: 2.884148678316153
Validation loss: 2.5418486050088838

Epoch: 5| Step: 3
Training loss: 2.5616939486471924
Validation loss: 2.5398923082399296

Epoch: 5| Step: 4
Training loss: 2.844152904096811
Validation loss: 2.5399697105893893

Epoch: 5| Step: 5
Training loss: 2.9721743459995036
Validation loss: 2.539407050117331

Epoch: 5| Step: 6
Training loss: 3.155353381018748
Validation loss: 2.5483986445212423

Epoch: 5| Step: 7
Training loss: 2.3831122538147937
Validation loss: 2.5459684762608012

Epoch: 5| Step: 8
Training loss: 2.789830206349704
Validation loss: 2.531856788230775

Epoch: 5| Step: 9
Training loss: 3.038018289939164
Validation loss: 2.53378879917376

Epoch: 5| Step: 10
Training loss: 2.2211333892215577
Validation loss: 2.530445355341193

Epoch: 56| Step: 0
Training loss: 2.9217702265431256
Validation loss: 2.5439527738111125

Epoch: 5| Step: 1
Training loss: 2.863343533492951
Validation loss: 2.5464316945534295

Epoch: 5| Step: 2
Training loss: 2.093757629380631
Validation loss: 2.5550020993886355

Epoch: 5| Step: 3
Training loss: 3.235453108078557
Validation loss: 2.5455804329614216

Epoch: 5| Step: 4
Training loss: 2.746010574231553
Validation loss: 2.541046139115971

Epoch: 5| Step: 5
Training loss: 3.2055163877119157
Validation loss: 2.5380027539663432

Epoch: 5| Step: 6
Training loss: 2.419054222196257
Validation loss: 2.5435729366559285

Epoch: 5| Step: 7
Training loss: 2.7528714880554332
Validation loss: 2.5297382407539235

Epoch: 5| Step: 8
Training loss: 2.941176690494305
Validation loss: 2.5373593538575614

Epoch: 5| Step: 9
Training loss: 2.9069718315615285
Validation loss: 2.538522432377196

Epoch: 5| Step: 10
Training loss: 2.321364655505586
Validation loss: 2.543376987312563

Epoch: 57| Step: 0
Training loss: 2.3378752259374327
Validation loss: 2.5375917062999807

Epoch: 5| Step: 1
Training loss: 2.1858520840145883
Validation loss: 2.538630870546278

Epoch: 5| Step: 2
Training loss: 2.9301583280521912
Validation loss: 2.5456936077511947

Epoch: 5| Step: 3
Training loss: 2.168968176517265
Validation loss: 2.550869099151789

Epoch: 5| Step: 4
Training loss: 2.9279951166518714
Validation loss: 2.548772594548075

Epoch: 5| Step: 5
Training loss: 2.7824976833501807
Validation loss: 2.5314438873620975

Epoch: 5| Step: 6
Training loss: 2.917695182017974
Validation loss: 2.5470226533678897

Epoch: 5| Step: 7
Training loss: 2.7111789914615883
Validation loss: 2.5360652607811467

Epoch: 5| Step: 8
Training loss: 3.2980528259765833
Validation loss: 2.5468758233846187

Epoch: 5| Step: 9
Training loss: 3.1645001144131903
Validation loss: 2.539678376554106

Epoch: 5| Step: 10
Training loss: 3.0284887892509444
Validation loss: 2.5489197638440677

Epoch: 58| Step: 0
Training loss: 2.430538899198105
Validation loss: 2.540851317665911

Epoch: 5| Step: 1
Training loss: 2.822216543015033
Validation loss: 2.5326871550856924

Epoch: 5| Step: 2
Training loss: 2.5257186735586066
Validation loss: 2.539002425348426

Epoch: 5| Step: 3
Training loss: 2.87999689154987
Validation loss: 2.535458564161027

Epoch: 5| Step: 4
Training loss: 2.956247122442607
Validation loss: 2.5446200887047103

Epoch: 5| Step: 5
Training loss: 2.6541820779190304
Validation loss: 2.5282657065905494

Epoch: 5| Step: 6
Training loss: 2.3751668369520766
Validation loss: 2.5324159704504874

Epoch: 5| Step: 7
Training loss: 2.3406252566898953
Validation loss: 2.545083822364885

Epoch: 5| Step: 8
Training loss: 2.9803924350792528
Validation loss: 2.544501626051837

Epoch: 5| Step: 9
Training loss: 3.137132515226416
Validation loss: 2.5399609784478243

Epoch: 5| Step: 10
Training loss: 3.426496337585852
Validation loss: 2.5375423291071084

Epoch: 59| Step: 0
Training loss: 2.9899851211126616
Validation loss: 2.533500935537536

Epoch: 5| Step: 1
Training loss: 2.9063869977265933
Validation loss: 2.531611411827349

Epoch: 5| Step: 2
Training loss: 2.9832080736627478
Validation loss: 2.5455538173227903

Epoch: 5| Step: 3
Training loss: 3.33981562373939
Validation loss: 2.5411782914264696

Epoch: 5| Step: 4
Training loss: 2.40076534863068
Validation loss: 2.5365095734540017

Epoch: 5| Step: 5
Training loss: 1.9568008622265067
Validation loss: 2.5356337216818843

Epoch: 5| Step: 6
Training loss: 3.2245904470219764
Validation loss: 2.5380782852095685

Epoch: 5| Step: 7
Training loss: 2.450906223932683
Validation loss: 2.5351715595574325

Epoch: 5| Step: 8
Training loss: 2.6726248954800407
Validation loss: 2.5347968100969043

Epoch: 5| Step: 9
Training loss: 3.231475414920988
Validation loss: 2.53141935615747

Epoch: 5| Step: 10
Training loss: 1.8991577916972255
Validation loss: 2.533076278846948

Epoch: 60| Step: 0
Training loss: 2.866547973156854
Validation loss: 2.540589838932831

Epoch: 5| Step: 1
Training loss: 2.762137417710938
Validation loss: 2.520178148767013

Epoch: 5| Step: 2
Training loss: 2.4938338530934088
Validation loss: 2.5362726754115976

Epoch: 5| Step: 3
Training loss: 3.433405987115896
Validation loss: 2.534958722681654

Epoch: 5| Step: 4
Training loss: 3.0235166711816035
Validation loss: 2.534806815651058

Epoch: 5| Step: 5
Training loss: 2.4670959919537796
Validation loss: 2.532634871276128

Epoch: 5| Step: 6
Training loss: 2.8193569942331527
Validation loss: 2.5371524999396975

Epoch: 5| Step: 7
Training loss: 2.5667112218614396
Validation loss: 2.5371626720198317

Epoch: 5| Step: 8
Training loss: 2.428478173060246
Validation loss: 2.528535482961436

Epoch: 5| Step: 9
Training loss: 2.5024783248038895
Validation loss: 2.539343846890695

Epoch: 5| Step: 10
Training loss: 3.136042653873908
Validation loss: 2.5408637375415077

Epoch: 61| Step: 0
Training loss: 2.8426152574830095
Validation loss: 2.5206408320811127

Epoch: 5| Step: 1
Training loss: 3.0976959649290463
Validation loss: 2.5375796699716413

Epoch: 5| Step: 2
Training loss: 2.2714988596512597
Validation loss: 2.537546358119992

Epoch: 5| Step: 3
Training loss: 2.77106178508312
Validation loss: 2.535582225587123

Epoch: 5| Step: 4
Training loss: 2.847635821150145
Validation loss: 2.53506226198454

Epoch: 5| Step: 5
Training loss: 2.5722703520920405
Validation loss: 2.5364776029097196

Epoch: 5| Step: 6
Training loss: 2.781852314054557
Validation loss: 2.5417273201674266

Epoch: 5| Step: 7
Training loss: 3.023486390815136
Validation loss: 2.528347406643901

Epoch: 5| Step: 8
Training loss: 2.5117781707711764
Validation loss: 2.54405872428425

Epoch: 5| Step: 9
Training loss: 2.5138476235484455
Validation loss: 2.5332890153170045

Epoch: 5| Step: 10
Training loss: 3.2488379234871627
Validation loss: 2.5387969200757965

Epoch: 62| Step: 0
Training loss: 2.8324939007874397
Validation loss: 2.529433051671305

Epoch: 5| Step: 1
Training loss: 3.0820329518670047
Validation loss: 2.5225965624528617

Epoch: 5| Step: 2
Training loss: 2.7494039756599085
Validation loss: 2.5313814023517174

Epoch: 5| Step: 3
Training loss: 2.4671685670460812
Validation loss: 2.5282216026335447

Epoch: 5| Step: 4
Training loss: 2.931998274892427
Validation loss: 2.5340640520277296

Epoch: 5| Step: 5
Training loss: 2.160771259966387
Validation loss: 2.534852417135223

Epoch: 5| Step: 6
Training loss: 3.350914098801458
Validation loss: 2.546266751031467

Epoch: 5| Step: 7
Training loss: 2.383938982733152
Validation loss: 2.538559136738798

Epoch: 5| Step: 8
Training loss: 2.8362086983468995
Validation loss: 2.5318212929164847

Epoch: 5| Step: 9
Training loss: 2.86092747301629
Validation loss: 2.5290230095387436

Epoch: 5| Step: 10
Training loss: 2.623621715010169
Validation loss: 2.527382693073334

Epoch: 63| Step: 0
Training loss: 3.3733598467824017
Validation loss: 2.531028840189457

Epoch: 5| Step: 1
Training loss: 2.4966018470053855
Validation loss: 2.5363187539051166

Epoch: 5| Step: 2
Training loss: 3.10161677007975
Validation loss: 2.5391641555768816

Epoch: 5| Step: 3
Training loss: 3.077197094783505
Validation loss: 2.529317008640857

Epoch: 5| Step: 4
Training loss: 2.1691211833525688
Validation loss: 2.526146220276314

Epoch: 5| Step: 5
Training loss: 2.273113319381646
Validation loss: 2.526339784433119

Epoch: 5| Step: 6
Training loss: 2.904308860359012
Validation loss: 2.5295866242458755

Epoch: 5| Step: 7
Training loss: 1.9673183624881192
Validation loss: 2.5229488321130713

Epoch: 5| Step: 8
Training loss: 3.0398164809196784
Validation loss: 2.519317950140326

Epoch: 5| Step: 9
Training loss: 2.6504663668824584
Validation loss: 2.523313201735343

Epoch: 5| Step: 10
Training loss: 3.1132071185888712
Validation loss: 2.5167377069371595

Epoch: 64| Step: 0
Training loss: 2.8868347062088056
Validation loss: 2.521243486535868

Epoch: 5| Step: 1
Training loss: 2.374551630361291
Validation loss: 2.5280091637953097

Epoch: 5| Step: 2
Training loss: 2.7250832641199643
Validation loss: 2.5154416289999473

Epoch: 5| Step: 3
Training loss: 2.85300056044088
Validation loss: 2.5313721423125135

Epoch: 5| Step: 4
Training loss: 2.520760075369027
Validation loss: 2.526855315044506

Epoch: 5| Step: 5
Training loss: 3.0176846284805463
Validation loss: 2.5221265728030176

Epoch: 5| Step: 6
Training loss: 2.671943083670891
Validation loss: 2.5250502458818342

Epoch: 5| Step: 7
Training loss: 2.958181744484006
Validation loss: 2.5241042117110584

Epoch: 5| Step: 8
Training loss: 2.8998266628684233
Validation loss: 2.5354811129403276

Epoch: 5| Step: 9
Training loss: 2.496996792340157
Validation loss: 2.528168842156535

Epoch: 5| Step: 10
Training loss: 3.01981485670874
Validation loss: 2.5134770757020366

Epoch: 65| Step: 0
Training loss: 3.194774479794404
Validation loss: 2.524260242263441

Epoch: 5| Step: 1
Training loss: 2.860840302112632
Validation loss: 2.534452330168173

Epoch: 5| Step: 2
Training loss: 2.2898276030102283
Validation loss: 2.530640003349908

Epoch: 5| Step: 3
Training loss: 2.448201286056426
Validation loss: 2.527738600011886

Epoch: 5| Step: 4
Training loss: 2.9382001975701004
Validation loss: 2.540187161663405

Epoch: 5| Step: 5
Training loss: 2.92606204713754
Validation loss: 2.537433162952434

Epoch: 5| Step: 6
Training loss: 2.7380249077588417
Validation loss: 2.5194147895644283

Epoch: 5| Step: 7
Training loss: 2.818137897082081
Validation loss: 2.5237876328908504

Epoch: 5| Step: 8
Training loss: 2.9619684764619287
Validation loss: 2.530368855644095

Epoch: 5| Step: 9
Training loss: 2.3115971839141722
Validation loss: 2.5245449519132697

Epoch: 5| Step: 10
Training loss: 2.8194427417150743
Validation loss: 2.5320645055816886

Epoch: 66| Step: 0
Training loss: 3.1399562750037693
Validation loss: 2.528922873414271

Epoch: 5| Step: 1
Training loss: 2.9576350896943837
Validation loss: 2.5349731085902834

Epoch: 5| Step: 2
Training loss: 3.1059692747189316
Validation loss: 2.5275818683003486

Epoch: 5| Step: 3
Training loss: 2.759939956288342
Validation loss: 2.5278713334163663

Epoch: 5| Step: 4
Training loss: 2.6230236060956003
Validation loss: 2.5224868727155574

Epoch: 5| Step: 5
Training loss: 2.359605285319675
Validation loss: 2.518498808158457

Epoch: 5| Step: 6
Training loss: 2.5669960958275047
Validation loss: 2.525583225400138

Epoch: 5| Step: 7
Training loss: 3.6126519722305024
Validation loss: 2.51951321157167

Epoch: 5| Step: 8
Training loss: 2.385383494672606
Validation loss: 2.531310339658803

Epoch: 5| Step: 9
Training loss: 2.368205238849498
Validation loss: 2.5206142572044286

Epoch: 5| Step: 10
Training loss: 2.0760340676277864
Validation loss: 2.520632163671703

Epoch: 67| Step: 0
Training loss: 2.471641103141153
Validation loss: 2.5227147011397757

Epoch: 5| Step: 1
Training loss: 3.022769035942594
Validation loss: 2.534706276898574

Epoch: 5| Step: 2
Training loss: 2.750222803973631
Validation loss: 2.5247001337494734

Epoch: 5| Step: 3
Training loss: 3.172388946537419
Validation loss: 2.5181761340495106

Epoch: 5| Step: 4
Training loss: 2.767684945230343
Validation loss: 2.5316746237961234

Epoch: 5| Step: 5
Training loss: 2.8196251367087894
Validation loss: 2.514252504487474

Epoch: 5| Step: 6
Training loss: 2.703892857855406
Validation loss: 2.5148463989798824

Epoch: 5| Step: 7
Training loss: 2.5797090230283053
Validation loss: 2.534484186672158

Epoch: 5| Step: 8
Training loss: 2.4350996669918037
Validation loss: 2.5194646654983575

Epoch: 5| Step: 9
Training loss: 2.269848589615945
Validation loss: 2.518849857571445

Epoch: 5| Step: 10
Training loss: 3.2469810255581217
Validation loss: 2.5071299953166593

Epoch: 68| Step: 0
Training loss: 2.382426046082285
Validation loss: 2.523537637403859

Epoch: 5| Step: 1
Training loss: 2.1537766576391366
Validation loss: 2.5184958704277878

Epoch: 5| Step: 2
Training loss: 2.5689066372749236
Validation loss: 2.528657470492504

Epoch: 5| Step: 3
Training loss: 2.8426046894693715
Validation loss: 2.5291533786378455

Epoch: 5| Step: 4
Training loss: 2.853316094474174
Validation loss: 2.517836066619526

Epoch: 5| Step: 5
Training loss: 2.3746974149994724
Validation loss: 2.5288669180353436

Epoch: 5| Step: 6
Training loss: 3.3051693973037217
Validation loss: 2.528801085221042

Epoch: 5| Step: 7
Training loss: 2.993600058732881
Validation loss: 2.5164558293670125

Epoch: 5| Step: 8
Training loss: 3.2281050054590126
Validation loss: 2.5298170639246975

Epoch: 5| Step: 9
Training loss: 2.5891287206401032
Validation loss: 2.5262910635840905

Epoch: 5| Step: 10
Training loss: 2.7163973746978964
Validation loss: 2.525288740844296

Epoch: 69| Step: 0
Training loss: 2.692140077781016
Validation loss: 2.5412526236397204

Epoch: 5| Step: 1
Training loss: 2.4513230235395054
Validation loss: 2.526074238245681

Epoch: 5| Step: 2
Training loss: 2.5597194379309682
Validation loss: 2.520853328464512

Epoch: 5| Step: 3
Training loss: 2.7549747206952593
Validation loss: 2.518494216298651

Epoch: 5| Step: 4
Training loss: 2.833139263313251
Validation loss: 2.5315227516046357

Epoch: 5| Step: 5
Training loss: 3.232904809562204
Validation loss: 2.522533612852322

Epoch: 5| Step: 6
Training loss: 3.3998801490752837
Validation loss: 2.532206356826189

Epoch: 5| Step: 7
Training loss: 2.794703487711803
Validation loss: 2.5233540641980046

Epoch: 5| Step: 8
Training loss: 2.8186050276258667
Validation loss: 2.523474303896288

Epoch: 5| Step: 9
Training loss: 2.199976842931769
Validation loss: 2.522511836585508

Epoch: 5| Step: 10
Training loss: 2.304639395518892
Validation loss: 2.5230018953182745

Epoch: 70| Step: 0
Training loss: 2.9549203088022646
Validation loss: 2.5353878801581753

Epoch: 5| Step: 1
Training loss: 2.3737329817689674
Validation loss: 2.530127238470214

Epoch: 5| Step: 2
Training loss: 2.844174363887493
Validation loss: 2.524951096472047

Epoch: 5| Step: 3
Training loss: 2.775296643871933
Validation loss: 2.5170377997017392

Epoch: 5| Step: 4
Training loss: 2.652674523741322
Validation loss: 2.513170022609719

Epoch: 5| Step: 5
Training loss: 2.4305606757216034
Validation loss: 2.526153252110456

Epoch: 5| Step: 6
Training loss: 2.9761768802150623
Validation loss: 2.521089905024851

Epoch: 5| Step: 7
Training loss: 2.5420838206508063
Validation loss: 2.5237208427363655

Epoch: 5| Step: 8
Training loss: 2.8437040555826663
Validation loss: 2.505729692846099

Epoch: 5| Step: 9
Training loss: 3.0418854377838693
Validation loss: 2.516759099229261

Epoch: 5| Step: 10
Training loss: 2.6991260032342783
Validation loss: 2.509972212112681

Epoch: 71| Step: 0
Training loss: 2.3050132391956955
Validation loss: 2.520585851301958

Epoch: 5| Step: 1
Training loss: 3.005357409150912
Validation loss: 2.515922361172023

Epoch: 5| Step: 2
Training loss: 3.0238831657364695
Validation loss: 2.509284479558484

Epoch: 5| Step: 3
Training loss: 2.7384910775193028
Validation loss: 2.5026223703376904

Epoch: 5| Step: 4
Training loss: 2.678954088034795
Validation loss: 2.519703452084247

Epoch: 5| Step: 5
Training loss: 3.1095978163432547
Validation loss: 2.5170013091020187

Epoch: 5| Step: 6
Training loss: 2.724391127291625
Validation loss: 2.513540524438181

Epoch: 5| Step: 7
Training loss: 2.2394245416695853
Validation loss: 2.521966433603029

Epoch: 5| Step: 8
Training loss: 2.7727989643737745
Validation loss: 2.5160559716462254

Epoch: 5| Step: 9
Training loss: 2.924886691515267
Validation loss: 2.5200951950758137

Epoch: 5| Step: 10
Training loss: 2.49772149204529
Validation loss: 2.508872660803591

Epoch: 72| Step: 0
Training loss: 2.7037091809144225
Validation loss: 2.51565639583517

Epoch: 5| Step: 1
Training loss: 2.874462906799021
Validation loss: 2.5097836435982406

Epoch: 5| Step: 2
Training loss: 2.7813856113247364
Validation loss: 2.5234293298624926

Epoch: 5| Step: 3
Training loss: 2.301475536726098
Validation loss: 2.5058503669540606

Epoch: 5| Step: 4
Training loss: 2.6890660535843205
Validation loss: 2.517592426931724

Epoch: 5| Step: 5
Training loss: 2.3509843185206862
Validation loss: 2.530028641659528

Epoch: 5| Step: 6
Training loss: 2.899148941124741
Validation loss: 2.516959705893299

Epoch: 5| Step: 7
Training loss: 2.735356443564906
Validation loss: 2.5207745789206677

Epoch: 5| Step: 8
Training loss: 3.1201532543885695
Validation loss: 2.511717372092618

Epoch: 5| Step: 9
Training loss: 2.592274625393589
Validation loss: 2.515330089519785

Epoch: 5| Step: 10
Training loss: 3.1218485391009003
Validation loss: 2.5252690603498573

Epoch: 73| Step: 0
Training loss: 2.4483822210774773
Validation loss: 2.5177387133603046

Epoch: 5| Step: 1
Training loss: 2.7186130182243455
Validation loss: 2.518312967042058

Epoch: 5| Step: 2
Training loss: 2.5143566843798038
Validation loss: 2.5235390012379355

Epoch: 5| Step: 3
Training loss: 2.7499178960854778
Validation loss: 2.52905132878581

Epoch: 5| Step: 4
Training loss: 2.579952632557946
Validation loss: 2.5119640646659933

Epoch: 5| Step: 5
Training loss: 2.975030940560121
Validation loss: 2.5115611104505313

Epoch: 5| Step: 6
Training loss: 3.110773280133193
Validation loss: 2.5193149736786657

Epoch: 5| Step: 7
Training loss: 2.8226895868574817
Validation loss: 2.5277760674438796

Epoch: 5| Step: 8
Training loss: 3.1389237536029158
Validation loss: 2.525740116660219

Epoch: 5| Step: 9
Training loss: 2.2626644390899235
Validation loss: 2.5117161248306172

Epoch: 5| Step: 10
Training loss: 2.662453531925368
Validation loss: 2.5263996107044964

Epoch: 74| Step: 0
Training loss: 2.9563877710736968
Validation loss: 2.523204794641904

Epoch: 5| Step: 1
Training loss: 2.886787134994292
Validation loss: 2.5220725179003844

Epoch: 5| Step: 2
Training loss: 2.2710695289708593
Validation loss: 2.527148177559863

Epoch: 5| Step: 3
Training loss: 2.2175178867723973
Validation loss: 2.514914370798726

Epoch: 5| Step: 4
Training loss: 3.364311813563338
Validation loss: 2.520417466857806

Epoch: 5| Step: 5
Training loss: 2.5037922706787583
Validation loss: 2.525490012960909

Epoch: 5| Step: 6
Training loss: 2.495170506096164
Validation loss: 2.521155501948605

Epoch: 5| Step: 7
Training loss: 2.899461755459884
Validation loss: 2.522858672453806

Epoch: 5| Step: 8
Training loss: 3.0981571134126895
Validation loss: 2.5219788697329424

Epoch: 5| Step: 9
Training loss: 2.660323307208534
Validation loss: 2.522998622942603

Epoch: 5| Step: 10
Training loss: 2.5631369752750666
Validation loss: 2.51202613714005

Epoch: 75| Step: 0
Training loss: 3.0824515826034053
Validation loss: 2.5326098606651213

Epoch: 5| Step: 1
Training loss: 3.233597666629061
Validation loss: 2.5075140022681315

Epoch: 5| Step: 2
Training loss: 2.781204737605714
Validation loss: 2.519408958973173

Epoch: 5| Step: 3
Training loss: 2.725573866027102
Validation loss: 2.5218169289153116

Epoch: 5| Step: 4
Training loss: 2.386098228491854
Validation loss: 2.5124589117848735

Epoch: 5| Step: 5
Training loss: 2.0605800824856746
Validation loss: 2.51286903690975

Epoch: 5| Step: 6
Training loss: 3.0737037469673445
Validation loss: 2.538254668883322

Epoch: 5| Step: 7
Training loss: 2.8587862669825608
Validation loss: 2.528167704413916

Epoch: 5| Step: 8
Training loss: 2.7642041883278607
Validation loss: 2.5222144310209464

Epoch: 5| Step: 9
Training loss: 2.5170436673595424
Validation loss: 2.518862561497255

Epoch: 5| Step: 10
Training loss: 2.185766459625028
Validation loss: 2.515422923244809

Testing loss: 2.5202551144434278
