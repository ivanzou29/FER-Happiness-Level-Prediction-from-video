Epoch: 1| Step: 0
Training loss: 4.236767768859863
Validation loss: 5.216926256815593

Epoch: 6| Step: 1
Training loss: 6.040412425994873
Validation loss: 5.2145248254140215

Epoch: 6| Step: 2
Training loss: 5.718661308288574
Validation loss: 5.211910327275594

Epoch: 6| Step: 3
Training loss: 5.6155009269714355
Validation loss: 5.209400018056233

Epoch: 6| Step: 4
Training loss: 6.587904930114746
Validation loss: 5.206985155741374

Epoch: 6| Step: 5
Training loss: 5.643806457519531
Validation loss: 5.204408009847005

Epoch: 6| Step: 6
Training loss: 5.235372543334961
Validation loss: 5.202066580454509

Epoch: 6| Step: 7
Training loss: 4.239202499389648
Validation loss: 5.199616193771362

Epoch: 6| Step: 8
Training loss: 6.24897575378418
Validation loss: 5.197040557861328

Epoch: 6| Step: 9
Training loss: 4.448999404907227
Validation loss: 5.194504737854004

Epoch: 6| Step: 10
Training loss: 5.076712608337402
Validation loss: 5.1919675668080645

Epoch: 6| Step: 11
Training loss: 4.6379594802856445
Validation loss: 5.189324855804443

Epoch: 6| Step: 12
Training loss: 5.083354949951172
Validation loss: 5.186451355616252

Epoch: 6| Step: 13
Training loss: 4.977209091186523
Validation loss: 5.183590888977051

Epoch: 2| Step: 0
Training loss: 5.027736663818359
Validation loss: 5.180654764175415

Epoch: 6| Step: 1
Training loss: 3.942229986190796
Validation loss: 5.177633762359619

Epoch: 6| Step: 2
Training loss: 4.614068984985352
Validation loss: 5.174261252085368

Epoch: 6| Step: 3
Training loss: 4.920801639556885
Validation loss: 5.170844395955403

Epoch: 6| Step: 4
Training loss: 5.822937965393066
Validation loss: 5.1670394738515215

Epoch: 6| Step: 5
Training loss: 5.888153076171875
Validation loss: 5.1633923053741455

Epoch: 6| Step: 6
Training loss: 5.207623481750488
Validation loss: 5.159406979878743

Epoch: 6| Step: 7
Training loss: 6.253940105438232
Validation loss: 5.155330737431844

Epoch: 6| Step: 8
Training loss: 5.849932670593262
Validation loss: 5.150869766871135

Epoch: 6| Step: 9
Training loss: 4.968649864196777
Validation loss: 5.14626948038737

Epoch: 6| Step: 10
Training loss: 6.357553482055664
Validation loss: 5.141360362370809

Epoch: 6| Step: 11
Training loss: 5.117434978485107
Validation loss: 5.136242548624675

Epoch: 6| Step: 12
Training loss: 5.445730209350586
Validation loss: 5.131045420964559

Epoch: 6| Step: 13
Training loss: 3.7599334716796875
Validation loss: 5.125723520914714

Epoch: 3| Step: 0
Training loss: 4.122564792633057
Validation loss: 5.1198209921518965

Epoch: 6| Step: 1
Training loss: 5.275684356689453
Validation loss: 5.114170471827189

Epoch: 6| Step: 2
Training loss: 4.679619312286377
Validation loss: 5.1078769365946455

Epoch: 6| Step: 3
Training loss: 5.570037364959717
Validation loss: 5.101584355036418

Epoch: 6| Step: 4
Training loss: 3.2246508598327637
Validation loss: 5.094985564549764

Epoch: 6| Step: 5
Training loss: 4.363738059997559
Validation loss: 5.088098128636678

Epoch: 6| Step: 6
Training loss: 5.350356578826904
Validation loss: 5.081255594889323

Epoch: 6| Step: 7
Training loss: 5.176233768463135
Validation loss: 5.073975404103597

Epoch: 6| Step: 8
Training loss: 5.59954833984375
Validation loss: 5.066370248794556

Epoch: 6| Step: 9
Training loss: 6.416430473327637
Validation loss: 5.059046824773152

Epoch: 6| Step: 10
Training loss: 5.181917190551758
Validation loss: 5.051271835962932

Epoch: 6| Step: 11
Training loss: 5.7885518074035645
Validation loss: 5.043325106302897

Epoch: 6| Step: 12
Training loss: 5.040413856506348
Validation loss: 5.035349607467651

Epoch: 6| Step: 13
Training loss: 6.307223796844482
Validation loss: 5.027049899101257

Epoch: 4| Step: 0
Training loss: 5.483572959899902
Validation loss: 5.019063154856364

Epoch: 6| Step: 1
Training loss: 4.860058307647705
Validation loss: 5.01042898495992

Epoch: 6| Step: 2
Training loss: 3.473267078399658
Validation loss: 5.001742919286092

Epoch: 6| Step: 3
Training loss: 3.8759238719940186
Validation loss: 4.9934267203013105

Epoch: 6| Step: 4
Training loss: 4.762596607208252
Validation loss: 4.984878142674764

Epoch: 6| Step: 5
Training loss: 5.408210754394531
Validation loss: 4.976442575454712

Epoch: 6| Step: 6
Training loss: 5.05964469909668
Validation loss: 4.967632373174031

Epoch: 6| Step: 7
Training loss: 5.643525123596191
Validation loss: 4.959112326304118

Epoch: 6| Step: 8
Training loss: 5.6551513671875
Validation loss: 4.950211803118388

Epoch: 6| Step: 9
Training loss: 5.6811323165893555
Validation loss: 4.9414567947387695

Epoch: 6| Step: 10
Training loss: 5.665816307067871
Validation loss: 4.932639996210734

Epoch: 6| Step: 11
Training loss: 5.192748069763184
Validation loss: 4.923413674036662

Epoch: 6| Step: 12
Training loss: 5.136019229888916
Validation loss: 4.913974205652873

Epoch: 6| Step: 13
Training loss: 4.699918746948242
Validation loss: 4.904996196428935

Epoch: 5| Step: 0
Training loss: 4.337340354919434
Validation loss: 4.895350217819214

Epoch: 6| Step: 1
Training loss: 4.077145576477051
Validation loss: 4.88587498664856

Epoch: 6| Step: 2
Training loss: 5.093708515167236
Validation loss: 4.875860174496968

Epoch: 6| Step: 3
Training loss: 4.31995964050293
Validation loss: 4.866501967112224

Epoch: 6| Step: 4
Training loss: 5.094846725463867
Validation loss: 4.856499989827474

Epoch: 6| Step: 5
Training loss: 5.177585601806641
Validation loss: 4.846760908762614

Epoch: 6| Step: 6
Training loss: 5.197387218475342
Validation loss: 4.837283452351888

Epoch: 6| Step: 7
Training loss: 5.077589988708496
Validation loss: 4.827955722808838

Epoch: 6| Step: 8
Training loss: 3.877307653427124
Validation loss: 4.818628549575806

Epoch: 6| Step: 9
Training loss: 5.175375938415527
Validation loss: 4.809535304705302

Epoch: 6| Step: 10
Training loss: 4.8680419921875
Validation loss: 4.800552487373352

Epoch: 6| Step: 11
Training loss: 5.702090263366699
Validation loss: 4.7919314702351885

Epoch: 6| Step: 12
Training loss: 5.123196601867676
Validation loss: 4.783153613408406

Epoch: 6| Step: 13
Training loss: 5.777377128601074
Validation loss: 4.774584770202637

Epoch: 6| Step: 0
Training loss: 4.349043846130371
Validation loss: 4.765711863835652

Epoch: 6| Step: 1
Training loss: 5.115903377532959
Validation loss: 4.757410367329915

Epoch: 6| Step: 2
Training loss: 4.604469299316406
Validation loss: 4.748822212219238

Epoch: 6| Step: 3
Training loss: 4.891282081604004
Validation loss: 4.740834792455037

Epoch: 6| Step: 4
Training loss: 4.692865371704102
Validation loss: 4.732386390368144

Epoch: 6| Step: 5
Training loss: 3.987532615661621
Validation loss: 4.724453250567119

Epoch: 6| Step: 6
Training loss: 5.625072479248047
Validation loss: 4.716527382532756

Epoch: 6| Step: 7
Training loss: 4.948434352874756
Validation loss: 4.708495537439982

Epoch: 6| Step: 8
Training loss: 4.368056297302246
Validation loss: 4.700390179951985

Epoch: 6| Step: 9
Training loss: 3.9763381481170654
Validation loss: 4.692237854003906

Epoch: 6| Step: 10
Training loss: 4.625637531280518
Validation loss: 4.684497833251953

Epoch: 6| Step: 11
Training loss: 5.731441497802734
Validation loss: 4.67655873298645

Epoch: 6| Step: 12
Training loss: 6.001413822174072
Validation loss: 4.668460845947266

Epoch: 6| Step: 13
Training loss: 4.354285717010498
Validation loss: 4.66057276725769

Epoch: 7| Step: 0
Training loss: 4.926045894622803
Validation loss: 4.652304331461589

Epoch: 6| Step: 1
Training loss: 4.221585750579834
Validation loss: 4.644513686498006

Epoch: 6| Step: 2
Training loss: 4.597165107727051
Validation loss: 4.636620839436849

Epoch: 6| Step: 3
Training loss: 3.3123059272766113
Validation loss: 4.628686706225078

Epoch: 6| Step: 4
Training loss: 4.858963966369629
Validation loss: 4.620565176010132

Epoch: 6| Step: 5
Training loss: 6.232988357543945
Validation loss: 4.613026142120361

Epoch: 6| Step: 6
Training loss: 5.168852806091309
Validation loss: 4.605039914449056

Epoch: 6| Step: 7
Training loss: 5.536611557006836
Validation loss: 4.597701072692871

Epoch: 6| Step: 8
Training loss: 4.562754154205322
Validation loss: 4.589699347813924

Epoch: 6| Step: 9
Training loss: 4.110164642333984
Validation loss: 4.582179625829061

Epoch: 6| Step: 10
Training loss: 4.973589897155762
Validation loss: 4.5743184089660645

Epoch: 6| Step: 11
Training loss: 3.7589025497436523
Validation loss: 4.56687315305074

Epoch: 6| Step: 12
Training loss: 5.0184478759765625
Validation loss: 4.5599972407023115

Epoch: 6| Step: 13
Training loss: 4.531483173370361
Validation loss: 4.552168051401774

Epoch: 8| Step: 0
Training loss: 2.4311838150024414
Validation loss: 4.5455215771993

Epoch: 6| Step: 1
Training loss: 5.079329967498779
Validation loss: 4.537816286087036

Epoch: 6| Step: 2
Training loss: 3.800083637237549
Validation loss: 4.531255006790161

Epoch: 6| Step: 3
Training loss: 4.469574928283691
Validation loss: 4.52431845664978

Epoch: 6| Step: 4
Training loss: 4.729775905609131
Validation loss: 4.517508467038472

Epoch: 6| Step: 5
Training loss: 3.6170167922973633
Validation loss: 4.510333220163981

Epoch: 6| Step: 6
Training loss: 4.4183783531188965
Validation loss: 4.5041210651397705

Epoch: 6| Step: 7
Training loss: 4.874197959899902
Validation loss: 4.497692704200745

Epoch: 6| Step: 8
Training loss: 5.5147504806518555
Validation loss: 4.4911426703135175

Epoch: 6| Step: 9
Training loss: 3.772397756576538
Validation loss: 4.4846731424331665

Epoch: 6| Step: 10
Training loss: 6.364067077636719
Validation loss: 4.47884996732076

Epoch: 6| Step: 11
Training loss: 6.0068840980529785
Validation loss: 4.471965630849202

Epoch: 6| Step: 12
Training loss: 5.054248809814453
Validation loss: 4.465547164281209

Epoch: 6| Step: 13
Training loss: 4.354206085205078
Validation loss: 4.459560354550679

Epoch: 9| Step: 0
Training loss: 5.010885715484619
Validation loss: 4.4539774258931475

Epoch: 6| Step: 1
Training loss: 4.647971153259277
Validation loss: 4.447654604911804

Epoch: 6| Step: 2
Training loss: 5.252467155456543
Validation loss: 4.441389282544454

Epoch: 6| Step: 3
Training loss: 5.0837297439575195
Validation loss: 4.43588403860728

Epoch: 6| Step: 4
Training loss: 3.858243703842163
Validation loss: 4.42961569627126

Epoch: 6| Step: 5
Training loss: 5.932651519775391
Validation loss: 4.423834919929504

Epoch: 6| Step: 6
Training loss: 4.083660125732422
Validation loss: 4.417771736780803

Epoch: 6| Step: 7
Training loss: 3.8056998252868652
Validation loss: 4.411930958429973

Epoch: 6| Step: 8
Training loss: 3.3822269439697266
Validation loss: 4.406114141146342

Epoch: 6| Step: 9
Training loss: 4.371707916259766
Validation loss: 4.400384863217671

Epoch: 6| Step: 10
Training loss: 4.530625343322754
Validation loss: 4.395719289779663

Epoch: 6| Step: 11
Training loss: 3.919766902923584
Validation loss: 4.390015959739685

Epoch: 6| Step: 12
Training loss: 4.581645488739014
Validation loss: 4.38457989692688

Epoch: 6| Step: 13
Training loss: 4.969326972961426
Validation loss: 4.379098216692607

Epoch: 10| Step: 0
Training loss: 3.9576563835144043
Validation loss: 4.373596827189128

Epoch: 6| Step: 1
Training loss: 4.840158939361572
Validation loss: 4.367998282114665

Epoch: 6| Step: 2
Training loss: 4.9943108558654785
Validation loss: 4.362489779790242

Epoch: 6| Step: 3
Training loss: 4.537670612335205
Validation loss: 4.356488386789958

Epoch: 6| Step: 4
Training loss: 5.32498836517334
Validation loss: 4.350892066955566

Epoch: 6| Step: 5
Training loss: 4.637630939483643
Validation loss: 4.344825983047485

Epoch: 6| Step: 6
Training loss: 4.71241569519043
Validation loss: 4.339576919873555

Epoch: 6| Step: 7
Training loss: 3.8222742080688477
Validation loss: 4.333401918411255

Epoch: 6| Step: 8
Training loss: 4.486840724945068
Validation loss: 4.3287075360616045

Epoch: 6| Step: 9
Training loss: 4.506646156311035
Validation loss: 4.323523759841919

Epoch: 6| Step: 10
Training loss: 4.153234958648682
Validation loss: 4.317554434140523

Epoch: 6| Step: 11
Training loss: 3.9497101306915283
Validation loss: 4.311999320983887

Epoch: 6| Step: 12
Training loss: 4.533771514892578
Validation loss: 4.306606650352478

Epoch: 6| Step: 13
Training loss: 3.977431058883667
Validation loss: 4.301386594772339

Epoch: 11| Step: 0
Training loss: 4.618918418884277
Validation loss: 4.2957955201466875

Epoch: 6| Step: 1
Training loss: 4.649683952331543
Validation loss: 4.290637930234273

Epoch: 6| Step: 2
Training loss: 4.056131362915039
Validation loss: 4.284692366917928

Epoch: 6| Step: 3
Training loss: 4.154485702514648
Validation loss: 4.279276132583618

Epoch: 6| Step: 4
Training loss: 3.447040557861328
Validation loss: 4.273416558901469

Epoch: 6| Step: 5
Training loss: 4.919060707092285
Validation loss: 4.267782171567281

Epoch: 6| Step: 6
Training loss: 4.893276214599609
Validation loss: 4.261830806732178

Epoch: 6| Step: 7
Training loss: 4.716823101043701
Validation loss: 4.256161530812581

Epoch: 6| Step: 8
Training loss: 3.759859323501587
Validation loss: 4.250765442848206

Epoch: 6| Step: 9
Training loss: 4.507281303405762
Validation loss: 4.245197852452596

Epoch: 6| Step: 10
Training loss: 3.752319812774658
Validation loss: 4.239641507466634

Epoch: 6| Step: 11
Training loss: 5.003417015075684
Validation loss: 4.233025232950847

Epoch: 6| Step: 12
Training loss: 4.3154826164245605
Validation loss: 4.228601257006328

Epoch: 6| Step: 13
Training loss: 4.6186089515686035
Validation loss: 4.222133914629619

Epoch: 12| Step: 0
Training loss: 4.334183692932129
Validation loss: 4.216432174046834

Epoch: 6| Step: 1
Training loss: 4.5233917236328125
Validation loss: 4.210781296094258

Epoch: 6| Step: 2
Training loss: 4.518815517425537
Validation loss: 4.203671296437581

Epoch: 6| Step: 3
Training loss: 3.791198492050171
Validation loss: 4.198306202888489

Epoch: 6| Step: 4
Training loss: 3.4574499130249023
Validation loss: 4.192725698153178

Epoch: 6| Step: 5
Training loss: 4.641504764556885
Validation loss: 4.186344901720683

Epoch: 6| Step: 6
Training loss: 4.159743309020996
Validation loss: 4.180668910344441

Epoch: 6| Step: 7
Training loss: 5.445254325866699
Validation loss: 4.174432595570882

Epoch: 6| Step: 8
Training loss: 4.340246200561523
Validation loss: 4.168925801912944

Epoch: 6| Step: 9
Training loss: 3.8018312454223633
Validation loss: 4.162794748942058

Epoch: 6| Step: 10
Training loss: 5.0912556648254395
Validation loss: 4.156129280726115

Epoch: 6| Step: 11
Training loss: 3.1765635013580322
Validation loss: 4.150452057520549

Epoch: 6| Step: 12
Training loss: 3.8698863983154297
Validation loss: 4.14500371615092

Epoch: 6| Step: 13
Training loss: 5.242753028869629
Validation loss: 4.140227437019348

Epoch: 13| Step: 0
Training loss: 4.128261089324951
Validation loss: 4.133653402328491

Epoch: 6| Step: 1
Training loss: 3.95829701423645
Validation loss: 4.12853483359019

Epoch: 6| Step: 2
Training loss: 4.257218360900879
Validation loss: 4.123183369636536

Epoch: 6| Step: 3
Training loss: 4.597164630889893
Validation loss: 4.117840607961019

Epoch: 6| Step: 4
Training loss: 4.207212448120117
Validation loss: 4.114445765813191

Epoch: 6| Step: 5
Training loss: 4.885228633880615
Validation loss: 4.107543031374614

Epoch: 6| Step: 6
Training loss: 4.163509368896484
Validation loss: 4.102190216382344

Epoch: 6| Step: 7
Training loss: 3.7543246746063232
Validation loss: 4.096042156219482

Epoch: 6| Step: 8
Training loss: 4.312628269195557
Validation loss: 4.091271638870239

Epoch: 6| Step: 9
Training loss: 4.321489334106445
Validation loss: 4.085951765378316

Epoch: 6| Step: 10
Training loss: 3.9346365928649902
Validation loss: 4.079134066899617

Epoch: 6| Step: 11
Training loss: 4.405853271484375
Validation loss: 4.075497666994731

Epoch: 6| Step: 12
Training loss: 4.694569110870361
Validation loss: 4.069497346878052

Epoch: 6| Step: 13
Training loss: 3.741933822631836
Validation loss: 4.064188559850057

Epoch: 14| Step: 0
Training loss: 4.131281852722168
Validation loss: 4.059939424196879

Epoch: 6| Step: 1
Training loss: 5.658059597015381
Validation loss: 4.053996404012044

Epoch: 6| Step: 2
Training loss: 4.182429790496826
Validation loss: 4.048768202463786

Epoch: 6| Step: 3
Training loss: 4.064970016479492
Validation loss: 4.043018976847331

Epoch: 6| Step: 4
Training loss: 3.7883033752441406
Validation loss: 4.038250883420308

Epoch: 6| Step: 5
Training loss: 4.079155921936035
Validation loss: 4.033734122912089

Epoch: 6| Step: 6
Training loss: 3.8864874839782715
Validation loss: 4.028699437777202

Epoch: 6| Step: 7
Training loss: 2.2164077758789062
Validation loss: 4.023851593335469

Epoch: 6| Step: 8
Training loss: 4.426979064941406
Validation loss: 4.01820695400238

Epoch: 6| Step: 9
Training loss: 3.644056797027588
Validation loss: 4.0128757158915205

Epoch: 6| Step: 10
Training loss: 4.105157852172852
Validation loss: 4.008125901222229

Epoch: 6| Step: 11
Training loss: 4.5211029052734375
Validation loss: 4.003461718559265

Epoch: 6| Step: 12
Training loss: 4.775144577026367
Validation loss: 3.997631231943766

Epoch: 6| Step: 13
Training loss: 4.908153057098389
Validation loss: 3.9933727582295737

Epoch: 15| Step: 0
Training loss: 3.1709189414978027
Validation loss: 3.987517515818278

Epoch: 6| Step: 1
Training loss: 3.4971208572387695
Validation loss: 3.982880115509033

Epoch: 6| Step: 2
Training loss: 4.415321350097656
Validation loss: 3.9780083894729614

Epoch: 6| Step: 3
Training loss: 4.811927318572998
Validation loss: 3.972759246826172

Epoch: 6| Step: 4
Training loss: 4.026315689086914
Validation loss: 3.9675182898839316

Epoch: 6| Step: 5
Training loss: 3.912585735321045
Validation loss: 3.962087551752726

Epoch: 6| Step: 6
Training loss: 3.8463330268859863
Validation loss: 3.9570099512736

Epoch: 6| Step: 7
Training loss: 4.4826130867004395
Validation loss: 3.9515467484792075

Epoch: 6| Step: 8
Training loss: 4.258161544799805
Validation loss: 3.946516831715902

Epoch: 6| Step: 9
Training loss: 4.088630676269531
Validation loss: 3.940558989842733

Epoch: 6| Step: 10
Training loss: 3.9941110610961914
Validation loss: 3.935084660847982

Epoch: 6| Step: 11
Training loss: 4.20653772354126
Validation loss: 3.9300922552744546

Epoch: 6| Step: 12
Training loss: 3.915780544281006
Validation loss: 3.9249983628590903

Epoch: 6| Step: 13
Training loss: 4.805971622467041
Validation loss: 3.919960538546244

Epoch: 16| Step: 0
Training loss: 3.578479051589966
Validation loss: 3.914949337641398

Epoch: 6| Step: 1
Training loss: 3.0686044692993164
Validation loss: 3.9105237325032554

Epoch: 6| Step: 2
Training loss: 3.7735676765441895
Validation loss: 3.9055145978927612

Epoch: 6| Step: 3
Training loss: 4.188731670379639
Validation loss: 3.8998863299687705

Epoch: 6| Step: 4
Training loss: 4.926050186157227
Validation loss: 3.896015206972758

Epoch: 6| Step: 5
Training loss: 3.810734272003174
Validation loss: 3.891313910484314

Epoch: 6| Step: 6
Training loss: 4.883519172668457
Validation loss: 3.885111649831136

Epoch: 6| Step: 7
Training loss: 3.495654344558716
Validation loss: 3.879856824874878

Epoch: 6| Step: 8
Training loss: 3.901414155960083
Validation loss: 3.873945116996765

Epoch: 6| Step: 9
Training loss: 5.545170307159424
Validation loss: 3.870185454686483

Epoch: 6| Step: 10
Training loss: 4.203319549560547
Validation loss: 3.8650606075922647

Epoch: 6| Step: 11
Training loss: 4.1141357421875
Validation loss: 3.8596171538035073

Epoch: 6| Step: 12
Training loss: 3.7080652713775635
Validation loss: 3.854543606440226

Epoch: 6| Step: 13
Training loss: 3.2789182662963867
Validation loss: 3.849996050198873

Epoch: 17| Step: 0
Training loss: 5.058866024017334
Validation loss: 3.8459396759668985

Epoch: 6| Step: 1
Training loss: 3.4740376472473145
Validation loss: 3.8413213094075522

Epoch: 6| Step: 2
Training loss: 4.00775146484375
Validation loss: 3.8349440892537436

Epoch: 6| Step: 3
Training loss: 3.1100001335144043
Validation loss: 3.829972227414449

Epoch: 6| Step: 4
Training loss: 4.553525924682617
Validation loss: 3.8249383767445884

Epoch: 6| Step: 5
Training loss: 3.908433437347412
Validation loss: 3.820615530014038

Epoch: 6| Step: 6
Training loss: 3.4970967769622803
Validation loss: 3.8161964416503906

Epoch: 6| Step: 7
Training loss: 3.416886329650879
Validation loss: 3.810639262199402

Epoch: 6| Step: 8
Training loss: 5.629831790924072
Validation loss: 3.805377642313639

Epoch: 6| Step: 9
Training loss: 3.7396628856658936
Validation loss: 3.8007190227508545

Epoch: 6| Step: 10
Training loss: 3.564760208129883
Validation loss: 3.7961286306381226

Epoch: 6| Step: 11
Training loss: 3.9087772369384766
Validation loss: 3.792312582333883

Epoch: 6| Step: 12
Training loss: 4.213308811187744
Validation loss: 3.7885375022888184

Epoch: 6| Step: 13
Training loss: 3.4903154373168945
Validation loss: 3.7828176418940225

Epoch: 18| Step: 0
Training loss: 3.9425950050354004
Validation loss: 3.775520165761312

Epoch: 6| Step: 1
Training loss: 3.074361801147461
Validation loss: 3.770308176676432

Epoch: 6| Step: 2
Training loss: 4.564855575561523
Validation loss: 3.7668980757395425

Epoch: 6| Step: 3
Training loss: 4.014978408813477
Validation loss: 3.76237960656484

Epoch: 6| Step: 4
Training loss: 3.9173245429992676
Validation loss: 3.7566916942596436

Epoch: 6| Step: 5
Training loss: 3.7458226680755615
Validation loss: 3.7510459423065186

Epoch: 6| Step: 6
Training loss: 3.781660556793213
Validation loss: 3.743834932645162

Epoch: 6| Step: 7
Training loss: 4.161228179931641
Validation loss: 3.7399373054504395

Epoch: 6| Step: 8
Training loss: 3.599078416824341
Validation loss: 3.7360315720240274

Epoch: 6| Step: 9
Training loss: 3.960843086242676
Validation loss: 3.734007398287455

Epoch: 6| Step: 10
Training loss: 4.844053268432617
Validation loss: 3.7273000876108804

Epoch: 6| Step: 11
Training loss: 4.176591873168945
Validation loss: 3.7197421391805015

Epoch: 6| Step: 12
Training loss: 4.188867568969727
Validation loss: 3.715630610783895

Epoch: 6| Step: 13
Training loss: 2.6591405868530273
Validation loss: 3.7117634614308677

Epoch: 19| Step: 0
Training loss: 3.5768330097198486
Validation loss: 3.7080788215001426

Epoch: 6| Step: 1
Training loss: 3.702173948287964
Validation loss: 3.703053832054138

Epoch: 6| Step: 2
Training loss: 3.9641354084014893
Validation loss: 3.6968331336975098

Epoch: 6| Step: 3
Training loss: 4.0684709548950195
Validation loss: 3.692673405011495

Epoch: 6| Step: 4
Training loss: 3.882187604904175
Validation loss: 3.6875675121943154

Epoch: 6| Step: 5
Training loss: 4.069284439086914
Validation loss: 3.6819080909093223

Epoch: 6| Step: 6
Training loss: 3.754920482635498
Validation loss: 3.676913579305013

Epoch: 6| Step: 7
Training loss: 3.2442359924316406
Validation loss: 3.6719000339508057

Epoch: 6| Step: 8
Training loss: 4.595692157745361
Validation loss: 3.6673748095830283

Epoch: 6| Step: 9
Training loss: 4.0981035232543945
Validation loss: 3.6616427501042685

Epoch: 6| Step: 10
Training loss: 3.6584925651550293
Validation loss: 3.6570520401000977

Epoch: 6| Step: 11
Training loss: 3.039417266845703
Validation loss: 3.649431745211283

Epoch: 6| Step: 12
Training loss: 3.7088418006896973
Validation loss: 3.645617405573527

Epoch: 6| Step: 13
Training loss: 4.343011379241943
Validation loss: 3.640748222668966

Epoch: 20| Step: 0
Training loss: 3.267508029937744
Validation loss: 3.6354052623113

Epoch: 6| Step: 1
Training loss: 4.050076961517334
Validation loss: 3.6324534018834433

Epoch: 6| Step: 2
Training loss: 3.7835469245910645
Validation loss: 3.6285220781962075

Epoch: 6| Step: 3
Training loss: 4.355587959289551
Validation loss: 3.6220893462498984

Epoch: 6| Step: 4
Training loss: 3.2893877029418945
Validation loss: 3.6157681147257485

Epoch: 6| Step: 5
Training loss: 4.027678489685059
Validation loss: 3.6102745135625205

Epoch: 6| Step: 6
Training loss: 3.1179025173187256
Validation loss: 3.606269915898641

Epoch: 6| Step: 7
Training loss: 4.498522758483887
Validation loss: 3.6017404397328696

Epoch: 6| Step: 8
Training loss: 3.5734777450561523
Validation loss: 3.5961333513259888

Epoch: 6| Step: 9
Training loss: 4.342840671539307
Validation loss: 3.591158151626587

Epoch: 6| Step: 10
Training loss: 3.7093071937561035
Validation loss: 3.586176554361979

Epoch: 6| Step: 11
Training loss: 3.1018924713134766
Validation loss: 3.58087694644928

Epoch: 6| Step: 12
Training loss: 3.4888362884521484
Validation loss: 3.5768850247065225

Epoch: 6| Step: 13
Training loss: 4.120535373687744
Validation loss: 3.5705506801605225

Epoch: 21| Step: 0
Training loss: 3.6623706817626953
Validation loss: 3.56571098168691

Epoch: 6| Step: 1
Training loss: 3.8649189472198486
Validation loss: 3.560784657796224

Epoch: 6| Step: 2
Training loss: 3.2943525314331055
Validation loss: 3.555826981862386

Epoch: 6| Step: 3
Training loss: 3.5613927841186523
Validation loss: 3.5497867266337075

Epoch: 6| Step: 4
Training loss: 4.394397258758545
Validation loss: 3.544751763343811

Epoch: 6| Step: 5
Training loss: 3.525317668914795
Validation loss: 3.5390928586324057

Epoch: 6| Step: 6
Training loss: 3.192880153656006
Validation loss: 3.533376177151998

Epoch: 6| Step: 7
Training loss: 3.5902011394500732
Validation loss: 3.52858297030131

Epoch: 6| Step: 8
Training loss: 4.3425726890563965
Validation loss: 3.5231359004974365

Epoch: 6| Step: 9
Training loss: 3.294675827026367
Validation loss: 3.517178694407145

Epoch: 6| Step: 10
Training loss: 4.249688148498535
Validation loss: 3.512496749560038

Epoch: 6| Step: 11
Training loss: 3.9610042572021484
Validation loss: 3.5079095363616943

Epoch: 6| Step: 12
Training loss: 3.4770736694335938
Validation loss: 3.502373456954956

Epoch: 6| Step: 13
Training loss: 3.386378288269043
Validation loss: 3.4975486199061074

Epoch: 22| Step: 0
Training loss: 2.7580575942993164
Validation loss: 3.492100636164347

Epoch: 6| Step: 1
Training loss: 3.8414247035980225
Validation loss: 3.4877082109451294

Epoch: 6| Step: 2
Training loss: 3.888406753540039
Validation loss: 3.4829717874526978

Epoch: 6| Step: 3
Training loss: 3.4890503883361816
Validation loss: 3.477839152018229

Epoch: 6| Step: 4
Training loss: 3.5811009407043457
Validation loss: 3.4725849628448486

Epoch: 6| Step: 5
Training loss: 3.7861037254333496
Validation loss: 3.466928760210673

Epoch: 6| Step: 6
Training loss: 4.3043317794799805
Validation loss: 3.4617835680643716

Epoch: 6| Step: 7
Training loss: 3.3925905227661133
Validation loss: 3.4572531382242837

Epoch: 6| Step: 8
Training loss: 3.0188915729522705
Validation loss: 3.4512253602345786

Epoch: 6| Step: 9
Training loss: 3.0684447288513184
Validation loss: 3.4462274312973022

Epoch: 6| Step: 10
Training loss: 3.4981045722961426
Validation loss: 3.4424022436141968

Epoch: 6| Step: 11
Training loss: 3.40932035446167
Validation loss: 3.4361597696940103

Epoch: 6| Step: 12
Training loss: 3.461148262023926
Validation loss: 3.431838870048523

Epoch: 6| Step: 13
Training loss: 5.2906060218811035
Validation loss: 3.4265839656194053

Epoch: 23| Step: 0
Training loss: 3.8413474559783936
Validation loss: 3.4233298699061074

Epoch: 6| Step: 1
Training loss: 3.2981903553009033
Validation loss: 3.4191046555836997

Epoch: 6| Step: 2
Training loss: 3.0999486446380615
Validation loss: 3.4142070213953652

Epoch: 6| Step: 3
Training loss: 4.1707868576049805
Validation loss: 3.4081955353418985

Epoch: 6| Step: 4
Training loss: 2.3324389457702637
Validation loss: 3.4034979740778604

Epoch: 6| Step: 5
Training loss: 2.747603178024292
Validation loss: 3.3982725143432617

Epoch: 6| Step: 6
Training loss: 3.6121625900268555
Validation loss: 3.3929793437321982

Epoch: 6| Step: 7
Training loss: 3.593139171600342
Validation loss: 3.3878897031148276

Epoch: 6| Step: 8
Training loss: 3.8936383724212646
Validation loss: 3.382369041442871

Epoch: 6| Step: 9
Training loss: 3.626835823059082
Validation loss: 3.377665638923645

Epoch: 6| Step: 10
Training loss: 3.6679041385650635
Validation loss: 3.3729196389516196

Epoch: 6| Step: 11
Training loss: 3.722249984741211
Validation loss: 3.3681089878082275

Epoch: 6| Step: 12
Training loss: 4.670165538787842
Validation loss: 3.3635251919428506

Epoch: 6| Step: 13
Training loss: 3.572038412094116
Validation loss: 3.3586754401524863

Epoch: 24| Step: 0
Training loss: 4.90131139755249
Validation loss: 3.3538907368977866

Epoch: 6| Step: 1
Training loss: 3.6089651584625244
Validation loss: 3.3497169415156045

Epoch: 6| Step: 2
Training loss: 3.292625904083252
Validation loss: 3.3453673919041953

Epoch: 6| Step: 3
Training loss: 3.359126091003418
Validation loss: 3.339609225591024

Epoch: 6| Step: 4
Training loss: 2.88246488571167
Validation loss: 3.3358243306477866

Epoch: 6| Step: 5
Training loss: 2.784087896347046
Validation loss: 3.331193447113037

Epoch: 6| Step: 6
Training loss: 3.1466352939605713
Validation loss: 3.327980637550354

Epoch: 6| Step: 7
Training loss: 2.805480718612671
Validation loss: 3.322754661242167

Epoch: 6| Step: 8
Training loss: 3.489560604095459
Validation loss: 3.317856510480245

Epoch: 6| Step: 9
Training loss: 4.842719078063965
Validation loss: 3.313487490018209

Epoch: 6| Step: 10
Training loss: 3.6865458488464355
Validation loss: 3.3090948263804116

Epoch: 6| Step: 11
Training loss: 3.098179340362549
Validation loss: 3.3046517769495645

Epoch: 6| Step: 12
Training loss: 2.930055856704712
Validation loss: 3.3004923264185586

Epoch: 6| Step: 13
Training loss: 4.114401817321777
Validation loss: 3.295411388079325

Epoch: 25| Step: 0
Training loss: 3.360974073410034
Validation loss: 3.2905415693918862

Epoch: 6| Step: 1
Training loss: 2.913954973220825
Validation loss: 3.2856749296188354

Epoch: 6| Step: 2
Training loss: 4.141918659210205
Validation loss: 3.2810806035995483

Epoch: 6| Step: 3
Training loss: 3.6058502197265625
Validation loss: 3.2772190173467

Epoch: 6| Step: 4
Training loss: 3.277045249938965
Validation loss: 3.272843877474467

Epoch: 6| Step: 5
Training loss: 3.9063773155212402
Validation loss: 3.268099824587504

Epoch: 6| Step: 6
Training loss: 2.953751802444458
Validation loss: 3.263766129811605

Epoch: 6| Step: 7
Training loss: 3.858705997467041
Validation loss: 3.2599109411239624

Epoch: 6| Step: 8
Training loss: 3.292163848876953
Validation loss: 3.255096713701884

Epoch: 6| Step: 9
Training loss: 3.7177085876464844
Validation loss: 3.2507429917653403

Epoch: 6| Step: 10
Training loss: 2.7002506256103516
Validation loss: 3.2454715967178345

Epoch: 6| Step: 11
Training loss: 2.931591510772705
Validation loss: 3.2420583963394165

Epoch: 6| Step: 12
Training loss: 3.777507781982422
Validation loss: 3.2373332182566323

Epoch: 6| Step: 13
Training loss: 3.6869289875030518
Validation loss: 3.232736070950826

Epoch: 26| Step: 0
Training loss: 3.6709654331207275
Validation loss: 3.227683146794637

Epoch: 6| Step: 1
Training loss: 3.4890623092651367
Validation loss: 3.223501205444336

Epoch: 6| Step: 2
Training loss: 3.188241958618164
Validation loss: 3.2185224294662476

Epoch: 6| Step: 3
Training loss: 3.135822296142578
Validation loss: 3.2131701707839966

Epoch: 6| Step: 4
Training loss: 3.6046581268310547
Validation loss: 3.208815018335978

Epoch: 6| Step: 5
Training loss: 3.471893548965454
Validation loss: 3.2041397094726562

Epoch: 6| Step: 6
Training loss: 3.348468065261841
Validation loss: 3.199509382247925

Epoch: 6| Step: 7
Training loss: 2.6467833518981934
Validation loss: 3.1945035457611084

Epoch: 6| Step: 8
Training loss: 3.032543182373047
Validation loss: 3.190073768297831

Epoch: 6| Step: 9
Training loss: 4.249736785888672
Validation loss: 3.1861772934595742

Epoch: 6| Step: 10
Training loss: 3.8662548065185547
Validation loss: 3.180881381034851

Epoch: 6| Step: 11
Training loss: 3.0577940940856934
Validation loss: 3.17691707611084

Epoch: 6| Step: 12
Training loss: 3.600008249282837
Validation loss: 3.171673536300659

Epoch: 6| Step: 13
Training loss: 2.9816880226135254
Validation loss: 3.1671537160873413

Epoch: 27| Step: 0
Training loss: 2.3167097568511963
Validation loss: 3.162811835606893

Epoch: 6| Step: 1
Training loss: 2.5592880249023438
Validation loss: 3.1588939825693765

Epoch: 6| Step: 2
Training loss: 4.215838432312012
Validation loss: 3.1546324491500854

Epoch: 6| Step: 3
Training loss: 2.8564724922180176
Validation loss: 3.151673158009847

Epoch: 6| Step: 4
Training loss: 3.703275442123413
Validation loss: 3.1478845278422036

Epoch: 6| Step: 5
Training loss: 3.977098226547241
Validation loss: 3.1429008642832437

Epoch: 6| Step: 6
Training loss: 2.687872886657715
Validation loss: 3.139330426851908

Epoch: 6| Step: 7
Training loss: 3.567481279373169
Validation loss: 3.1348459323247275

Epoch: 6| Step: 8
Training loss: 3.1050686836242676
Validation loss: 3.131415923436483

Epoch: 6| Step: 9
Training loss: 3.0172994136810303
Validation loss: 3.1265918811162314

Epoch: 6| Step: 10
Training loss: 3.9054312705993652
Validation loss: 3.1228131453196206

Epoch: 6| Step: 11
Training loss: 3.2123756408691406
Validation loss: 3.119245688120524

Epoch: 6| Step: 12
Training loss: 3.8823349475860596
Validation loss: 3.114702026049296

Epoch: 6| Step: 13
Training loss: 3.5012996196746826
Validation loss: 3.1101481914520264

Epoch: 28| Step: 0
Training loss: 2.4035494327545166
Validation loss: 3.1069063742955527

Epoch: 6| Step: 1
Training loss: 2.824009895324707
Validation loss: 3.1010674635569253

Epoch: 6| Step: 2
Training loss: 2.609527826309204
Validation loss: 3.0967776775360107

Epoch: 6| Step: 3
Training loss: 3.257087230682373
Validation loss: 3.093982140223185

Epoch: 6| Step: 4
Training loss: 4.171746730804443
Validation loss: 3.0898571809132895

Epoch: 6| Step: 5
Training loss: 3.895315408706665
Validation loss: 3.0861350297927856

Epoch: 6| Step: 6
Training loss: 3.9098410606384277
Validation loss: 3.0822156270345054

Epoch: 6| Step: 7
Training loss: 2.9327473640441895
Validation loss: 3.077840526898702

Epoch: 6| Step: 8
Training loss: 3.082050323486328
Validation loss: 3.074004888534546

Epoch: 6| Step: 9
Training loss: 3.6744179725646973
Validation loss: 3.070508122444153

Epoch: 6| Step: 10
Training loss: 2.7348337173461914
Validation loss: 3.0669084787368774

Epoch: 6| Step: 11
Training loss: 3.694220781326294
Validation loss: 3.063468098640442

Epoch: 6| Step: 12
Training loss: 2.953549385070801
Validation loss: 3.059623122215271

Epoch: 6| Step: 13
Training loss: 3.6222856044769287
Validation loss: 3.056377649307251

Epoch: 29| Step: 0
Training loss: 2.584146022796631
Validation loss: 3.051765203475952

Epoch: 6| Step: 1
Training loss: 3.659428358078003
Validation loss: 3.0482197999954224

Epoch: 6| Step: 2
Training loss: 2.3767356872558594
Validation loss: 3.04474139213562

Epoch: 6| Step: 3
Training loss: 2.9869961738586426
Validation loss: 3.040696938832601

Epoch: 6| Step: 4
Training loss: 2.985384225845337
Validation loss: 3.0374661684036255

Epoch: 6| Step: 5
Training loss: 3.5854830741882324
Validation loss: 3.034691492716471

Epoch: 6| Step: 6
Training loss: 3.6513288021087646
Validation loss: 3.0305465857187905

Epoch: 6| Step: 7
Training loss: 2.2259414196014404
Validation loss: 3.026810050010681

Epoch: 6| Step: 8
Training loss: 2.881495952606201
Validation loss: 3.0236636797587075

Epoch: 6| Step: 9
Training loss: 3.8767752647399902
Validation loss: 3.0194909969965615

Epoch: 6| Step: 10
Training loss: 3.51157808303833
Validation loss: 3.0162890752156577

Epoch: 6| Step: 11
Training loss: 3.726888656616211
Validation loss: 3.012163241704305

Epoch: 6| Step: 12
Training loss: 2.883086681365967
Validation loss: 3.0083226958910623

Epoch: 6| Step: 13
Training loss: 4.124860763549805
Validation loss: 3.004325270652771

Epoch: 30| Step: 0
Training loss: 3.41867733001709
Validation loss: 2.999829332033793

Epoch: 6| Step: 1
Training loss: 3.487856864929199
Validation loss: 2.9960357348124185

Epoch: 6| Step: 2
Training loss: 2.8462910652160645
Validation loss: 2.9912348985671997

Epoch: 6| Step: 3
Training loss: 3.010528564453125
Validation loss: 2.988138198852539

Epoch: 6| Step: 4
Training loss: 3.459547281265259
Validation loss: 2.9846580028533936

Epoch: 6| Step: 5
Training loss: 3.2721033096313477
Validation loss: 2.98219629128774

Epoch: 6| Step: 6
Training loss: 3.179823398590088
Validation loss: 2.9784282048543296

Epoch: 6| Step: 7
Training loss: 3.5007214546203613
Validation loss: 2.973377307256063

Epoch: 6| Step: 8
Training loss: 2.395848274230957
Validation loss: 2.9683334827423096

Epoch: 6| Step: 9
Training loss: 2.4676167964935303
Validation loss: 2.9665270249048867

Epoch: 6| Step: 10
Training loss: 3.327681541442871
Validation loss: 2.9631098906199136

Epoch: 6| Step: 11
Training loss: 3.204859733581543
Validation loss: 2.958530306816101

Epoch: 6| Step: 12
Training loss: 4.120523452758789
Validation loss: 2.9569855531056723

Epoch: 6| Step: 13
Training loss: 2.7391715049743652
Validation loss: 2.95136026541392

Epoch: 31| Step: 0
Training loss: 3.190593719482422
Validation loss: 2.9485787550608316

Epoch: 6| Step: 1
Training loss: 2.604966878890991
Validation loss: 2.944897691408793

Epoch: 6| Step: 2
Training loss: 3.5097579956054688
Validation loss: 2.942073663075765

Epoch: 6| Step: 3
Training loss: 2.8220086097717285
Validation loss: 2.9388136068979898

Epoch: 6| Step: 4
Training loss: 2.774568557739258
Validation loss: 2.9357499281565347

Epoch: 6| Step: 5
Training loss: 3.252467632293701
Validation loss: 2.9325705766677856

Epoch: 6| Step: 6
Training loss: 2.8284990787506104
Validation loss: 2.9286728302637735

Epoch: 6| Step: 7
Training loss: 3.47892689704895
Validation loss: 2.926512837409973

Epoch: 6| Step: 8
Training loss: 3.8840537071228027
Validation loss: 2.923609813054403

Epoch: 6| Step: 9
Training loss: 3.079066753387451
Validation loss: 2.920450210571289

Epoch: 6| Step: 10
Training loss: 2.5891001224517822
Validation loss: 2.9170064528783164

Epoch: 6| Step: 11
Training loss: 2.3802456855773926
Validation loss: 2.9141435623168945

Epoch: 6| Step: 12
Training loss: 3.280449867248535
Validation loss: 2.910926421483358

Epoch: 6| Step: 13
Training loss: 4.125133514404297
Validation loss: 2.9097993771235147

Epoch: 32| Step: 0
Training loss: 3.232248067855835
Validation loss: 2.9060304959615073

Epoch: 6| Step: 1
Training loss: 3.097926139831543
Validation loss: 2.9018961588541665

Epoch: 6| Step: 2
Training loss: 3.1134119033813477
Validation loss: 2.9009169340133667

Epoch: 6| Step: 3
Training loss: 3.82560133934021
Validation loss: 2.897401809692383

Epoch: 6| Step: 4
Training loss: 3.891201972961426
Validation loss: 2.8904569149017334

Epoch: 6| Step: 5
Training loss: 3.6660568714141846
Validation loss: 2.8860288858413696

Epoch: 6| Step: 6
Training loss: 2.810356616973877
Validation loss: 2.8809468348821006

Epoch: 6| Step: 7
Training loss: 2.7995076179504395
Validation loss: 2.877310832341512

Epoch: 6| Step: 8
Training loss: 3.373965263366699
Validation loss: 2.8741204341252646

Epoch: 6| Step: 9
Training loss: 2.45627760887146
Validation loss: 2.871222654978434

Epoch: 6| Step: 10
Training loss: 2.4974303245544434
Validation loss: 2.8675281604131064

Epoch: 6| Step: 11
Training loss: 2.4337379932403564
Validation loss: 2.8636813163757324

Epoch: 6| Step: 12
Training loss: 3.0289783477783203
Validation loss: 2.8588841358820596

Epoch: 6| Step: 13
Training loss: 2.996112108230591
Validation loss: 2.855352997779846

Epoch: 33| Step: 0
Training loss: 2.4578869342803955
Validation loss: 2.852030793825785

Epoch: 6| Step: 1
Training loss: 3.1279025077819824
Validation loss: 2.849774638811747

Epoch: 6| Step: 2
Training loss: 2.5073652267456055
Validation loss: 2.846624732017517

Epoch: 6| Step: 3
Training loss: 3.0561206340789795
Validation loss: 2.84390652179718

Epoch: 6| Step: 4
Training loss: 2.803272247314453
Validation loss: 2.8408796787261963

Epoch: 6| Step: 5
Training loss: 3.4829187393188477
Validation loss: 2.838892857233683

Epoch: 6| Step: 6
Training loss: 3.5747530460357666
Validation loss: 2.836105982462565

Epoch: 6| Step: 7
Training loss: 3.231688976287842
Validation loss: 2.8314671913782754

Epoch: 6| Step: 8
Training loss: 2.4725022315979004
Validation loss: 2.8273884455362954

Epoch: 6| Step: 9
Training loss: 3.7459239959716797
Validation loss: 2.8263827761014304

Epoch: 6| Step: 10
Training loss: 3.8035383224487305
Validation loss: 2.8213509718577066

Epoch: 6| Step: 11
Training loss: 3.4277236461639404
Validation loss: 2.818115234375

Epoch: 6| Step: 12
Training loss: 2.598085403442383
Validation loss: 2.814424713452657

Epoch: 6| Step: 13
Training loss: 2.3186042308807373
Validation loss: 2.8137150009473166

Epoch: 34| Step: 0
Training loss: 2.690011501312256
Validation loss: 2.8101665576299033

Epoch: 6| Step: 1
Training loss: 2.6912894248962402
Validation loss: 2.808643182118734

Epoch: 6| Step: 2
Training loss: 3.2354304790496826
Validation loss: 2.8043247063954673

Epoch: 6| Step: 3
Training loss: 3.9816982746124268
Validation loss: 2.7995625535647073

Epoch: 6| Step: 4
Training loss: 3.327086925506592
Validation loss: 2.7938677867253623

Epoch: 6| Step: 5
Training loss: 3.2022705078125
Validation loss: 2.791373689969381

Epoch: 6| Step: 6
Training loss: 3.592653274536133
Validation loss: 2.787785808245341

Epoch: 6| Step: 7
Training loss: 2.659538507461548
Validation loss: 2.786319891611735

Epoch: 6| Step: 8
Training loss: 2.78448486328125
Validation loss: 2.7874271869659424

Epoch: 6| Step: 9
Training loss: 2.784836769104004
Validation loss: 2.7787134647369385

Epoch: 6| Step: 10
Training loss: 3.0847387313842773
Validation loss: 2.775885740915934

Epoch: 6| Step: 11
Training loss: 2.685298204421997
Validation loss: 2.7752626736958823

Epoch: 6| Step: 12
Training loss: 2.992189884185791
Validation loss: 2.7712227503458657

Epoch: 6| Step: 13
Training loss: 2.2829089164733887
Validation loss: 2.7640787760416665

Epoch: 35| Step: 0
Training loss: 3.435659408569336
Validation loss: 2.763820012410482

Epoch: 6| Step: 1
Training loss: 2.5108981132507324
Validation loss: 2.75948695341746

Epoch: 6| Step: 2
Training loss: 2.7748517990112305
Validation loss: 2.758960008621216

Epoch: 6| Step: 3
Training loss: 3.8695576190948486
Validation loss: 2.756121873855591

Epoch: 6| Step: 4
Training loss: 3.19685697555542
Validation loss: 2.750819762547811

Epoch: 6| Step: 5
Training loss: 1.8448299169540405
Validation loss: 2.74683944384257

Epoch: 6| Step: 6
Training loss: 3.0061919689178467
Validation loss: 2.744317094484965

Epoch: 6| Step: 7
Training loss: 2.2022430896759033
Validation loss: 2.7430631717046103

Epoch: 6| Step: 8
Training loss: 2.432685375213623
Validation loss: 2.7454161047935486

Epoch: 6| Step: 9
Training loss: 2.5792744159698486
Validation loss: 2.7370404799779258

Epoch: 6| Step: 10
Training loss: 3.2809691429138184
Validation loss: 2.73302427927653

Epoch: 6| Step: 11
Training loss: 3.5127463340759277
Validation loss: 2.729328751564026

Epoch: 6| Step: 12
Training loss: 3.2938790321350098
Validation loss: 2.7278995513916016

Epoch: 6| Step: 13
Training loss: 3.4005260467529297
Validation loss: 2.7244966427485147

Epoch: 36| Step: 0
Training loss: 2.9339237213134766
Validation loss: 2.719171682993571

Epoch: 6| Step: 1
Training loss: 2.691649913787842
Validation loss: 2.717822233835856

Epoch: 6| Step: 2
Training loss: 3.2829127311706543
Validation loss: 2.7138612270355225

Epoch: 6| Step: 3
Training loss: 2.7536206245422363
Validation loss: 2.711848179499308

Epoch: 6| Step: 4
Training loss: 3.0575900077819824
Validation loss: 2.706895351409912

Epoch: 6| Step: 5
Training loss: 2.498981475830078
Validation loss: 2.7052051226298013

Epoch: 6| Step: 6
Training loss: 2.3147952556610107
Validation loss: 2.7055335442225137

Epoch: 6| Step: 7
Training loss: 3.045966625213623
Validation loss: 2.7004396518071494

Epoch: 6| Step: 8
Training loss: 2.535120964050293
Validation loss: 2.696991483370463

Epoch: 6| Step: 9
Training loss: 2.5749833583831787
Validation loss: 2.6928462187449136

Epoch: 6| Step: 10
Training loss: 2.8486549854278564
Validation loss: 2.691074252128601

Epoch: 6| Step: 11
Training loss: 3.4694132804870605
Validation loss: 2.690384308497111

Epoch: 6| Step: 12
Training loss: 3.044783115386963
Validation loss: 2.683741807937622

Epoch: 6| Step: 13
Training loss: 3.6311166286468506
Validation loss: 2.68021829922994

Epoch: 37| Step: 0
Training loss: 2.4900269508361816
Validation loss: 2.676765561103821

Epoch: 6| Step: 1
Training loss: 3.2991490364074707
Validation loss: 2.673733115196228

Epoch: 6| Step: 2
Training loss: 2.8342437744140625
Validation loss: 2.67266313234965

Epoch: 6| Step: 3
Training loss: 3.1091556549072266
Validation loss: 2.66816782951355

Epoch: 6| Step: 4
Training loss: 3.6348962783813477
Validation loss: 2.6653853257497153

Epoch: 6| Step: 5
Training loss: 2.4366250038146973
Validation loss: 2.6618974606196084

Epoch: 6| Step: 6
Training loss: 2.814852714538574
Validation loss: 2.6589315136273703

Epoch: 6| Step: 7
Training loss: 3.045234441757202
Validation loss: 2.6542203426361084

Epoch: 6| Step: 8
Training loss: 2.5875329971313477
Validation loss: 2.6516719659169516

Epoch: 6| Step: 9
Training loss: 3.137761116027832
Validation loss: 2.6507385969161987

Epoch: 6| Step: 10
Training loss: 2.8469290733337402
Validation loss: 2.6457858085632324

Epoch: 6| Step: 11
Training loss: 2.4697258472442627
Validation loss: 2.6417601505915322

Epoch: 6| Step: 12
Training loss: 2.6658029556274414
Validation loss: 2.639325420061747

Epoch: 6| Step: 13
Training loss: 2.6606321334838867
Validation loss: 2.6344454288482666

Epoch: 38| Step: 0
Training loss: 3.2347264289855957
Validation loss: 2.637899120648702

Epoch: 6| Step: 1
Training loss: 3.273869752883911
Validation loss: 2.629301150639852

Epoch: 6| Step: 2
Training loss: 2.886012077331543
Validation loss: 2.624022960662842

Epoch: 6| Step: 3
Training loss: 2.380289316177368
Validation loss: 2.621527671813965

Epoch: 6| Step: 4
Training loss: 2.824676990509033
Validation loss: 2.61867892742157

Epoch: 6| Step: 5
Training loss: 2.9026358127593994
Validation loss: 2.6160444418589273

Epoch: 6| Step: 6
Training loss: 2.6136159896850586
Validation loss: 2.6142679850260415

Epoch: 6| Step: 7
Training loss: 2.4184138774871826
Validation loss: 2.6092973550160727

Epoch: 6| Step: 8
Training loss: 2.7462358474731445
Validation loss: 2.605267802874247

Epoch: 6| Step: 9
Training loss: 2.7283031940460205
Validation loss: 2.6024462779363

Epoch: 6| Step: 10
Training loss: 3.594082832336426
Validation loss: 2.6021289626757302

Epoch: 6| Step: 11
Training loss: 2.4329607486724854
Validation loss: 2.59636398156484

Epoch: 6| Step: 12
Training loss: 2.308522939682007
Validation loss: 2.594451347986857

Epoch: 6| Step: 13
Training loss: 3.0801501274108887
Validation loss: 2.5895963509877524

Epoch: 39| Step: 0
Training loss: 2.7305235862731934
Validation loss: 2.5890913605690002

Epoch: 6| Step: 1
Training loss: 2.5761795043945312
Validation loss: 2.5838544368743896

Epoch: 6| Step: 2
Training loss: 2.6760144233703613
Validation loss: 2.581132650375366

Epoch: 6| Step: 3
Training loss: 3.1019859313964844
Validation loss: 2.581108053525289

Epoch: 6| Step: 4
Training loss: 2.6808278560638428
Validation loss: 2.5769888957341514

Epoch: 6| Step: 5
Training loss: 2.88806414604187
Validation loss: 2.576215386390686

Epoch: 6| Step: 6
Training loss: 2.634028911590576
Validation loss: 2.572528084119161

Epoch: 6| Step: 7
Training loss: 2.9728307723999023
Validation loss: 2.5663092931111655

Epoch: 6| Step: 8
Training loss: 3.3536338806152344
Validation loss: 2.562375028928121

Epoch: 6| Step: 9
Training loss: 2.2884788513183594
Validation loss: 2.559883197148641

Epoch: 6| Step: 10
Training loss: 2.519753932952881
Validation loss: 2.5587508281071982

Epoch: 6| Step: 11
Training loss: 2.370180130004883
Validation loss: 2.5530129273732505

Epoch: 6| Step: 12
Training loss: 2.5050253868103027
Validation loss: 2.55225270986557

Epoch: 6| Step: 13
Training loss: 3.440120220184326
Validation loss: 2.548295338948568

Epoch: 40| Step: 0
Training loss: 2.9366941452026367
Validation loss: 2.5499420166015625

Epoch: 6| Step: 1
Training loss: 3.289043426513672
Validation loss: 2.546625852584839

Epoch: 6| Step: 2
Training loss: 3.11508846282959
Validation loss: 2.5415672063827515

Epoch: 6| Step: 3
Training loss: 2.401444673538208
Validation loss: 2.5381176471710205

Epoch: 6| Step: 4
Training loss: 2.801440954208374
Validation loss: 2.5360097885131836

Epoch: 6| Step: 5
Training loss: 2.7948482036590576
Validation loss: 2.534081816673279

Epoch: 6| Step: 6
Training loss: 2.431203842163086
Validation loss: 2.5290329853693643

Epoch: 6| Step: 7
Training loss: 2.22570538520813
Validation loss: 2.5286869605382285

Epoch: 6| Step: 8
Training loss: 2.6351897716522217
Validation loss: 2.5217022697130838

Epoch: 6| Step: 9
Training loss: 2.832794666290283
Validation loss: 2.5204477310180664

Epoch: 6| Step: 10
Training loss: 2.765740394592285
Validation loss: 2.5179755290349326

Epoch: 6| Step: 11
Training loss: 2.3524694442749023
Validation loss: 2.5129055976867676

Epoch: 6| Step: 12
Training loss: 3.1467957496643066
Validation loss: 2.5104355414708457

Epoch: 6| Step: 13
Training loss: 2.4080920219421387
Validation loss: 2.50874125957489

Epoch: 41| Step: 0
Training loss: 2.412595272064209
Validation loss: 2.5083707571029663

Epoch: 6| Step: 1
Training loss: 2.6156396865844727
Validation loss: 2.503230094909668

Epoch: 6| Step: 2
Training loss: 2.988776445388794
Validation loss: 2.5004266103108725

Epoch: 6| Step: 3
Training loss: 2.750037670135498
Validation loss: 2.497621695200602

Epoch: 6| Step: 4
Training loss: 2.4410929679870605
Validation loss: 2.493635972340902

Epoch: 6| Step: 5
Training loss: 2.762659788131714
Validation loss: 2.4890849192937217

Epoch: 6| Step: 6
Training loss: 2.0444135665893555
Validation loss: 2.4888293743133545

Epoch: 6| Step: 7
Training loss: 2.403712749481201
Validation loss: 2.484121799468994

Epoch: 6| Step: 8
Training loss: 2.778012275695801
Validation loss: 2.48101399342219

Epoch: 6| Step: 9
Training loss: 3.2672998905181885
Validation loss: 2.4796902736028037

Epoch: 6| Step: 10
Training loss: 2.558934211730957
Validation loss: 2.4762024879455566

Epoch: 6| Step: 11
Training loss: 2.691321849822998
Validation loss: 2.4760363499323526

Epoch: 6| Step: 12
Training loss: 2.957094430923462
Validation loss: 2.479387879371643

Epoch: 6| Step: 13
Training loss: 2.8228254318237305
Validation loss: 2.4705812533696494

Epoch: 42| Step: 0
Training loss: 2.963542938232422
Validation loss: 2.4691199461619058

Epoch: 6| Step: 1
Training loss: 1.6908094882965088
Validation loss: 2.4624212980270386

Epoch: 6| Step: 2
Training loss: 2.8075313568115234
Validation loss: 2.4651472767194114

Epoch: 6| Step: 3
Training loss: 3.592318296432495
Validation loss: 2.4612441460291543

Epoch: 6| Step: 4
Training loss: 2.639132022857666
Validation loss: 2.45901886622111

Epoch: 6| Step: 5
Training loss: 2.5531628131866455
Validation loss: 2.4629216392834983

Epoch: 6| Step: 6
Training loss: 2.8411123752593994
Validation loss: 2.4553547700246177

Epoch: 6| Step: 7
Training loss: 3.086437702178955
Validation loss: 2.4555391470591226

Epoch: 6| Step: 8
Training loss: 2.1500256061553955
Validation loss: 2.453203479448954

Epoch: 6| Step: 9
Training loss: 2.7826590538024902
Validation loss: 2.446736693382263

Epoch: 6| Step: 10
Training loss: 2.3952670097351074
Validation loss: 2.442282557487488

Epoch: 6| Step: 11
Training loss: 2.628789186477661
Validation loss: 2.4358765284220376

Epoch: 6| Step: 12
Training loss: 2.4410505294799805
Validation loss: 2.4375688632329306

Epoch: 6| Step: 13
Training loss: 2.297797679901123
Validation loss: 2.448646585146586

Epoch: 43| Step: 0
Training loss: 2.4163241386413574
Validation loss: 2.4498278896013894

Epoch: 6| Step: 1
Training loss: 2.5667052268981934
Validation loss: 2.4507948557535806

Epoch: 6| Step: 2
Training loss: 2.956268072128296
Validation loss: 2.4562445481618247

Epoch: 6| Step: 3
Training loss: 2.592891216278076
Validation loss: 2.4322867592175803

Epoch: 6| Step: 4
Training loss: 2.427424430847168
Validation loss: 2.416312098503113

Epoch: 6| Step: 5
Training loss: 2.1502692699432373
Validation loss: 2.411174496014913

Epoch: 6| Step: 6
Training loss: 2.6195104122161865
Validation loss: 2.4127307732899985

Epoch: 6| Step: 7
Training loss: 2.232637882232666
Validation loss: 2.4135843912760415

Epoch: 6| Step: 8
Training loss: 3.1741435527801514
Validation loss: 2.418573339780172

Epoch: 6| Step: 9
Training loss: 3.10463809967041
Validation loss: 2.4198769330978394

Epoch: 6| Step: 10
Training loss: 2.083430051803589
Validation loss: 2.4168744484583535

Epoch: 6| Step: 11
Training loss: 2.6577582359313965
Validation loss: 2.4096389611562095

Epoch: 6| Step: 12
Training loss: 2.705659866333008
Validation loss: 2.400436441103617

Epoch: 6| Step: 13
Training loss: 2.8165674209594727
Validation loss: 2.393310030301412

Epoch: 44| Step: 0
Training loss: 2.8234992027282715
Validation loss: 2.391702651977539

Epoch: 6| Step: 1
Training loss: 3.2418808937072754
Validation loss: 2.390846769014994

Epoch: 6| Step: 2
Training loss: 3.0997538566589355
Validation loss: 2.3914040327072144

Epoch: 6| Step: 3
Training loss: 2.080601215362549
Validation loss: 2.3949859142303467

Epoch: 6| Step: 4
Training loss: 2.7383944988250732
Validation loss: 2.4009700218836465

Epoch: 6| Step: 5
Training loss: 2.725818634033203
Validation loss: 2.4031508763631186

Epoch: 6| Step: 6
Training loss: 2.4140474796295166
Validation loss: 2.395405948162079

Epoch: 6| Step: 7
Training loss: 2.23030424118042
Validation loss: 2.3875127037366233

Epoch: 6| Step: 8
Training loss: 2.7856342792510986
Validation loss: 2.3790328900019326

Epoch: 6| Step: 9
Training loss: 2.170361280441284
Validation loss: 2.3712880611419678

Epoch: 6| Step: 10
Training loss: 2.2861740589141846
Validation loss: 2.3691484530766806

Epoch: 6| Step: 11
Training loss: 2.426400661468506
Validation loss: 2.360704024632772

Epoch: 6| Step: 12
Training loss: 2.3196089267730713
Validation loss: 2.3578027884165444

Epoch: 6| Step: 13
Training loss: 2.477233409881592
Validation loss: 2.3562483191490173

Epoch: 45| Step: 0
Training loss: 2.6411519050598145
Validation loss: 2.354387402534485

Epoch: 6| Step: 1
Training loss: 2.431873321533203
Validation loss: 2.3549312353134155

Epoch: 6| Step: 2
Training loss: 2.6455109119415283
Validation loss: 2.3575875759124756

Epoch: 6| Step: 3
Training loss: 2.233351230621338
Validation loss: 2.36365536848704

Epoch: 6| Step: 4
Training loss: 3.0763211250305176
Validation loss: 2.363210995992025

Epoch: 6| Step: 5
Training loss: 2.8381574153900146
Validation loss: 2.34913162390391

Epoch: 6| Step: 6
Training loss: 2.763706684112549
Validation loss: 2.348659336566925

Epoch: 6| Step: 7
Training loss: 2.5154457092285156
Validation loss: 2.3380372325579324

Epoch: 6| Step: 8
Training loss: 2.035773277282715
Validation loss: 2.3356128533681235

Epoch: 6| Step: 9
Training loss: 1.9498964548110962
Validation loss: 2.3319931626319885

Epoch: 6| Step: 10
Training loss: 2.2293472290039062
Validation loss: 2.331499934196472

Epoch: 6| Step: 11
Training loss: 2.166308879852295
Validation loss: 2.328912675380707

Epoch: 6| Step: 12
Training loss: 2.581367015838623
Validation loss: 2.327568292617798

Epoch: 6| Step: 13
Training loss: 3.1059324741363525
Validation loss: 2.32485568523407

Epoch: 46| Step: 0
Training loss: 2.2577548027038574
Validation loss: 2.322812775770823

Epoch: 6| Step: 1
Training loss: 2.294874668121338
Validation loss: 2.3190784056981406

Epoch: 6| Step: 2
Training loss: 2.1815638542175293
Validation loss: 2.3163846532503762

Epoch: 6| Step: 3
Training loss: 2.1996660232543945
Validation loss: 2.3128199179967246

Epoch: 6| Step: 4
Training loss: 2.9085745811462402
Validation loss: 2.3109307289123535

Epoch: 6| Step: 5
Training loss: 2.4477314949035645
Validation loss: 2.3088646729787192

Epoch: 6| Step: 6
Training loss: 2.8808178901672363
Validation loss: 2.3072128295898438

Epoch: 6| Step: 7
Training loss: 2.6718063354492188
Validation loss: 2.2996870279312134

Epoch: 6| Step: 8
Training loss: 2.8039872646331787
Validation loss: 2.304132024447123

Epoch: 6| Step: 9
Training loss: 2.5611822605133057
Validation loss: 2.2951257626215615

Epoch: 6| Step: 10
Training loss: 2.6661734580993652
Validation loss: 2.298634886741638

Epoch: 6| Step: 11
Training loss: 1.903364896774292
Validation loss: 2.2921745777130127

Epoch: 6| Step: 12
Training loss: 2.061267375946045
Validation loss: 2.2873504360516868

Epoch: 6| Step: 13
Training loss: 2.78617262840271
Validation loss: 2.2893842458724976

Epoch: 47| Step: 0
Training loss: 2.635004758834839
Validation loss: 2.2829737663269043

Epoch: 6| Step: 1
Training loss: 2.9325711727142334
Validation loss: 2.2817705074946084

Epoch: 6| Step: 2
Training loss: 2.8443148136138916
Validation loss: 2.2816248536109924

Epoch: 6| Step: 3
Training loss: 2.65175199508667
Validation loss: 2.2801484862963357

Epoch: 6| Step: 4
Training loss: 1.8244885206222534
Validation loss: 2.277378340562185

Epoch: 6| Step: 5
Training loss: 1.7065411806106567
Validation loss: 2.2701276938120523

Epoch: 6| Step: 6
Training loss: 1.9847841262817383
Validation loss: 2.2723838885625205

Epoch: 6| Step: 7
Training loss: 2.9220147132873535
Validation loss: 2.2674607038497925

Epoch: 6| Step: 8
Training loss: 2.453909397125244
Validation loss: 2.264943480491638

Epoch: 6| Step: 9
Training loss: 2.3725337982177734
Validation loss: 2.2589492797851562

Epoch: 6| Step: 10
Training loss: 2.9320263862609863
Validation loss: 2.2574212551116943

Epoch: 6| Step: 11
Training loss: 2.2259483337402344
Validation loss: 2.259563763936361

Epoch: 6| Step: 12
Training loss: 2.6276745796203613
Validation loss: 2.2554150025049844

Epoch: 6| Step: 13
Training loss: 1.8919503688812256
Validation loss: 2.2578253746032715

Epoch: 48| Step: 0
Training loss: 2.288864850997925
Validation loss: 2.258601168791453

Epoch: 6| Step: 1
Training loss: 2.6897716522216797
Validation loss: 2.2492679953575134

Epoch: 6| Step: 2
Training loss: 2.1481270790100098
Validation loss: 2.2424664894739785

Epoch: 6| Step: 3
Training loss: 2.847907304763794
Validation loss: 2.2415709495544434

Epoch: 6| Step: 4
Training loss: 2.41034197807312
Validation loss: 2.2365185817082724

Epoch: 6| Step: 5
Training loss: 2.252851963043213
Validation loss: 2.236137052377065

Epoch: 6| Step: 6
Training loss: 2.1793384552001953
Validation loss: 2.2344386180241904

Epoch: 6| Step: 7
Training loss: 2.190678119659424
Validation loss: 2.23388671875

Epoch: 6| Step: 8
Training loss: 2.5571250915527344
Validation loss: 2.2395291527112327

Epoch: 6| Step: 9
Training loss: 2.194063425064087
Validation loss: 2.2363217870394387

Epoch: 6| Step: 10
Training loss: 2.4021759033203125
Validation loss: 2.2375280459721885

Epoch: 6| Step: 11
Training loss: 2.131000518798828
Validation loss: 2.228199621041616

Epoch: 6| Step: 12
Training loss: 2.4294190406799316
Validation loss: 2.227425992488861

Epoch: 6| Step: 13
Training loss: 2.8885679244995117
Validation loss: 2.2228154937426248

Epoch: 49| Step: 0
Training loss: 2.697092294692993
Validation loss: 2.2223763863245645

Epoch: 6| Step: 1
Training loss: 2.250178337097168
Validation loss: 2.2197482585906982

Epoch: 6| Step: 2
Training loss: 2.00704026222229
Validation loss: 2.2140697240829468

Epoch: 6| Step: 3
Training loss: 2.0796866416931152
Validation loss: 2.2127620776494346

Epoch: 6| Step: 4
Training loss: 2.4239163398742676
Validation loss: 2.2075137297312417

Epoch: 6| Step: 5
Training loss: 2.1287717819213867
Validation loss: 2.204384128252665

Epoch: 6| Step: 6
Training loss: 2.347829818725586
Validation loss: 2.206729014714559

Epoch: 6| Step: 7
Training loss: 2.245997428894043
Validation loss: 2.207037369410197

Epoch: 6| Step: 8
Training loss: 2.206047773361206
Validation loss: 2.2052818139394126

Epoch: 6| Step: 9
Training loss: 2.2916579246520996
Validation loss: 2.2042609254519143

Epoch: 6| Step: 10
Training loss: 2.3256430625915527
Validation loss: 2.2028372287750244

Epoch: 6| Step: 11
Training loss: 2.3703975677490234
Validation loss: 2.198621074358622

Epoch: 6| Step: 12
Training loss: 2.6088390350341797
Validation loss: 2.193872332572937

Epoch: 6| Step: 13
Training loss: 3.1058104038238525
Validation loss: 2.198086659113566

Epoch: 50| Step: 0
Training loss: 2.1273629665374756
Validation loss: 2.197136640548706

Epoch: 6| Step: 1
Training loss: 1.9276647567749023
Validation loss: 2.1908689538637796

Epoch: 6| Step: 2
Training loss: 1.6484851837158203
Validation loss: 2.192652622858683

Epoch: 6| Step: 3
Training loss: 2.7927167415618896
Validation loss: 2.192349155743917

Epoch: 6| Step: 4
Training loss: 2.4374513626098633
Validation loss: 2.1934913396835327

Epoch: 6| Step: 5
Training loss: 2.84454345703125
Validation loss: 2.195195734500885

Epoch: 6| Step: 6
Training loss: 2.734229803085327
Validation loss: 2.1961395343144736

Epoch: 6| Step: 7
Training loss: 2.445932149887085
Validation loss: 2.198073387145996

Epoch: 6| Step: 8
Training loss: 2.0904057025909424
Validation loss: 2.1972028811772666

Epoch: 6| Step: 9
Training loss: 2.4868125915527344
Validation loss: 2.186873197555542

Epoch: 6| Step: 10
Training loss: 2.4846653938293457
Validation loss: 2.1803210576375327

Epoch: 6| Step: 11
Training loss: 2.1308388710021973
Validation loss: 2.177212039629618

Epoch: 6| Step: 12
Training loss: 2.339317560195923
Validation loss: 2.1756732066472373

Epoch: 6| Step: 13
Training loss: 2.3376481533050537
Validation loss: 2.172341227531433

Epoch: 51| Step: 0
Training loss: 1.9817715883255005
Validation loss: 2.165640652179718

Epoch: 6| Step: 1
Training loss: 2.740701913833618
Validation loss: 2.1625534494717917

Epoch: 6| Step: 2
Training loss: 2.6545045375823975
Validation loss: 2.161036948362986

Epoch: 6| Step: 3
Training loss: 2.7792739868164062
Validation loss: 2.16199920574824

Epoch: 6| Step: 4
Training loss: 2.336475372314453
Validation loss: 2.1612154642740884

Epoch: 6| Step: 5
Training loss: 2.2789864540100098
Validation loss: 2.159296234448751

Epoch: 6| Step: 6
Training loss: 2.551671266555786
Validation loss: 2.1537582874298096

Epoch: 6| Step: 7
Training loss: 2.874464750289917
Validation loss: 2.156842529773712

Epoch: 6| Step: 8
Training loss: 2.2957839965820312
Validation loss: 2.15872452656428

Epoch: 6| Step: 9
Training loss: 1.9212450981140137
Validation loss: 2.160873611768087

Epoch: 6| Step: 10
Training loss: 1.7960041761398315
Validation loss: 2.154123683770498

Epoch: 6| Step: 11
Training loss: 2.7111620903015137
Validation loss: 2.1565995613733926

Epoch: 6| Step: 12
Training loss: 1.5386755466461182
Validation loss: 2.152455230553945

Epoch: 6| Step: 13
Training loss: 2.048799514770508
Validation loss: 2.1519068479537964

Epoch: 52| Step: 0
Training loss: 2.32283878326416
Validation loss: 2.1487387220064798

Epoch: 6| Step: 1
Training loss: 2.354907512664795
Validation loss: 2.1524248719215393

Epoch: 6| Step: 2
Training loss: 2.1690211296081543
Validation loss: 2.147485613822937

Epoch: 6| Step: 3
Training loss: 1.7210921049118042
Validation loss: 2.144326150417328

Epoch: 6| Step: 4
Training loss: 2.954131603240967
Validation loss: 2.138765295346578

Epoch: 6| Step: 5
Training loss: 2.444762706756592
Validation loss: 2.1404379407564798

Epoch: 6| Step: 6
Training loss: 2.9578042030334473
Validation loss: 2.1382635831832886

Epoch: 6| Step: 7
Training loss: 2.506713390350342
Validation loss: 2.136590619881948

Epoch: 6| Step: 8
Training loss: 2.2442877292633057
Validation loss: 2.14189479748408

Epoch: 6| Step: 9
Training loss: 2.542219877243042
Validation loss: 2.129433790842692

Epoch: 6| Step: 10
Training loss: 1.4205505847930908
Validation loss: 2.129768669605255

Epoch: 6| Step: 11
Training loss: 2.3735570907592773
Validation loss: 2.129525125026703

Epoch: 6| Step: 12
Training loss: 2.015735387802124
Validation loss: 2.132372339566549

Epoch: 6| Step: 13
Training loss: 2.1917691230773926
Validation loss: 2.128856639067332

Epoch: 53| Step: 0
Training loss: 2.550116539001465
Validation loss: 2.1345943212509155

Epoch: 6| Step: 1
Training loss: 2.3987767696380615
Validation loss: 2.125913401444753

Epoch: 6| Step: 2
Training loss: 2.84856915473938
Validation loss: 2.139398992061615

Epoch: 6| Step: 3
Training loss: 2.0936548709869385
Validation loss: 2.154101292292277

Epoch: 6| Step: 4
Training loss: 2.3298726081848145
Validation loss: 2.157574494679769

Epoch: 6| Step: 5
Training loss: 2.3337812423706055
Validation loss: 2.131488343079885

Epoch: 6| Step: 6
Training loss: 2.1483378410339355
Validation loss: 2.131368637084961

Epoch: 6| Step: 7
Training loss: 2.1999971866607666
Validation loss: 2.126485049724579

Epoch: 6| Step: 8
Training loss: 2.077834367752075
Validation loss: 2.115832567214966

Epoch: 6| Step: 9
Training loss: 1.667384147644043
Validation loss: 2.123710334300995

Epoch: 6| Step: 10
Training loss: 2.4541826248168945
Validation loss: 2.117807944615682

Epoch: 6| Step: 11
Training loss: 2.6357781887054443
Validation loss: 2.114546080430349

Epoch: 6| Step: 12
Training loss: 1.7380225658416748
Validation loss: 2.118908723195394

Epoch: 6| Step: 13
Training loss: 2.660247802734375
Validation loss: 2.1190552910168967

Epoch: 54| Step: 0
Training loss: 2.3642492294311523
Validation loss: 2.114819288253784

Epoch: 6| Step: 1
Training loss: 2.1309893131256104
Validation loss: 2.1195274194081626

Epoch: 6| Step: 2
Training loss: 2.842151403427124
Validation loss: 2.1153600613276162

Epoch: 6| Step: 3
Training loss: 2.0779166221618652
Validation loss: 2.1172806223233542

Epoch: 6| Step: 4
Training loss: 1.8686951398849487
Validation loss: 2.1125541726748147

Epoch: 6| Step: 5
Training loss: 2.7173609733581543
Validation loss: 2.1062156756718955

Epoch: 6| Step: 6
Training loss: 2.2500317096710205
Validation loss: 2.1045395334561667

Epoch: 6| Step: 7
Training loss: 2.1051435470581055
Validation loss: 2.106119453907013

Epoch: 6| Step: 8
Training loss: 2.338219165802002
Validation loss: 2.103606561819712

Epoch: 6| Step: 9
Training loss: 1.9753597974777222
Validation loss: 2.104980210463206

Epoch: 6| Step: 10
Training loss: 1.883711576461792
Validation loss: 2.1040491660435996

Epoch: 6| Step: 11
Training loss: 2.875426769256592
Validation loss: 2.101288656393687

Epoch: 6| Step: 12
Training loss: 2.0252952575683594
Validation loss: 2.0975844065348306

Epoch: 6| Step: 13
Training loss: 2.4993748664855957
Validation loss: 2.096340080102285

Epoch: 55| Step: 0
Training loss: 2.3125250339508057
Validation loss: 2.0961779952049255

Epoch: 6| Step: 1
Training loss: 1.8365192413330078
Validation loss: 2.100621283054352

Epoch: 6| Step: 2
Training loss: 2.2198755741119385
Validation loss: 2.0936928590138755

Epoch: 6| Step: 3
Training loss: 2.686276912689209
Validation loss: 2.0947287877400718

Epoch: 6| Step: 4
Training loss: 2.5095343589782715
Validation loss: 2.0885228912035623

Epoch: 6| Step: 5
Training loss: 1.729759931564331
Validation loss: 2.0915695826212564

Epoch: 6| Step: 6
Training loss: 2.147589683532715
Validation loss: 2.091067393620809

Epoch: 6| Step: 7
Training loss: 2.082120895385742
Validation loss: 2.087095320224762

Epoch: 6| Step: 8
Training loss: 2.3109145164489746
Validation loss: 2.0860578616460166

Epoch: 6| Step: 9
Training loss: 2.38189435005188
Validation loss: 2.0842440128326416

Epoch: 6| Step: 10
Training loss: 2.571916341781616
Validation loss: 2.0875532031059265

Epoch: 6| Step: 11
Training loss: 2.3866820335388184
Validation loss: 2.082931399345398

Epoch: 6| Step: 12
Training loss: 2.1023736000061035
Validation loss: 2.08021346728007

Epoch: 6| Step: 13
Training loss: 2.42972469329834
Validation loss: 2.0814300576845803

Epoch: 56| Step: 0
Training loss: 2.0309934616088867
Validation loss: 2.0790161887804666

Epoch: 6| Step: 1
Training loss: 2.3180952072143555
Validation loss: 2.0807989835739136

Epoch: 6| Step: 2
Training loss: 2.446227550506592
Validation loss: 2.0821372469266257

Epoch: 6| Step: 3
Training loss: 2.459277629852295
Validation loss: 2.08185084660848

Epoch: 6| Step: 4
Training loss: 2.291810989379883
Validation loss: 2.079300363858541

Epoch: 6| Step: 5
Training loss: 1.7464944124221802
Validation loss: 2.0786096652348838

Epoch: 6| Step: 6
Training loss: 2.650275230407715
Validation loss: 2.0765958229700723

Epoch: 6| Step: 7
Training loss: 2.0752615928649902
Validation loss: 2.0781461000442505

Epoch: 6| Step: 8
Training loss: 2.687199115753174
Validation loss: 2.073470870653788

Epoch: 6| Step: 9
Training loss: 2.481198787689209
Validation loss: 2.0796144207318625

Epoch: 6| Step: 10
Training loss: 1.9839330911636353
Validation loss: 2.077352523803711

Epoch: 6| Step: 11
Training loss: 2.0419673919677734
Validation loss: 2.07416037718455

Epoch: 6| Step: 12
Training loss: 1.8582978248596191
Validation loss: 2.077344298362732

Epoch: 6| Step: 13
Training loss: 2.4574737548828125
Validation loss: 2.070627053578695

Epoch: 57| Step: 0
Training loss: 2.7216780185699463
Validation loss: 2.0621140797932944

Epoch: 6| Step: 1
Training loss: 2.6450953483581543
Validation loss: 2.0687941114107766

Epoch: 6| Step: 2
Training loss: 2.5366694927215576
Validation loss: 2.0653653740882874

Epoch: 6| Step: 3
Training loss: 2.7258968353271484
Validation loss: 2.0601062774658203

Epoch: 6| Step: 4
Training loss: 2.1041336059570312
Validation loss: 2.060692330201467

Epoch: 6| Step: 5
Training loss: 2.2281224727630615
Validation loss: 2.0623236298561096

Epoch: 6| Step: 6
Training loss: 2.083364725112915
Validation loss: 2.0640767415364585

Epoch: 6| Step: 7
Training loss: 2.454115152359009
Validation loss: 2.057396868864695

Epoch: 6| Step: 8
Training loss: 1.7712829113006592
Validation loss: 2.055693566799164

Epoch: 6| Step: 9
Training loss: 2.3871047496795654
Validation loss: 2.065351446469625

Epoch: 6| Step: 10
Training loss: 1.7870330810546875
Validation loss: 2.0498289664586387

Epoch: 6| Step: 11
Training loss: 2.065239906311035
Validation loss: 2.0557637214660645

Epoch: 6| Step: 12
Training loss: 2.2345235347747803
Validation loss: 2.054474870363871

Epoch: 6| Step: 13
Training loss: 1.6375885009765625
Validation loss: 2.057379364967346

Epoch: 58| Step: 0
Training loss: 2.6239404678344727
Validation loss: 2.054292102654775

Epoch: 6| Step: 1
Training loss: 2.037921905517578
Validation loss: 2.051803628603617

Epoch: 6| Step: 2
Training loss: 2.1342344284057617
Validation loss: 2.0512551069259644

Epoch: 6| Step: 3
Training loss: 2.444091320037842
Validation loss: 2.060614287853241

Epoch: 6| Step: 4
Training loss: 2.6359102725982666
Validation loss: 2.0552523136138916

Epoch: 6| Step: 5
Training loss: 1.6448938846588135
Validation loss: 2.05418453613917

Epoch: 6| Step: 6
Training loss: 2.163097858428955
Validation loss: 2.0504453778266907

Epoch: 6| Step: 7
Training loss: 1.7039514780044556
Validation loss: 2.0534382661183677

Epoch: 6| Step: 8
Training loss: 2.5475172996520996
Validation loss: 2.051989217599233

Epoch: 6| Step: 9
Training loss: 2.2268667221069336
Validation loss: 2.0499184131622314

Epoch: 6| Step: 10
Training loss: 2.268345832824707
Validation loss: 2.053118189175924

Epoch: 6| Step: 11
Training loss: 2.0669190883636475
Validation loss: 2.049200634161631

Epoch: 6| Step: 12
Training loss: 2.193337917327881
Validation loss: 2.0486335158348083

Epoch: 6| Step: 13
Training loss: 2.5749473571777344
Validation loss: 2.0472033818562827

Epoch: 59| Step: 0
Training loss: 2.4568190574645996
Validation loss: 2.047235369682312

Epoch: 6| Step: 1
Training loss: 2.1485016345977783
Validation loss: 2.0437587102254233

Epoch: 6| Step: 2
Training loss: 1.8746507167816162
Validation loss: 2.044390539328257

Epoch: 6| Step: 3
Training loss: 1.892439603805542
Validation loss: 2.042870024840037

Epoch: 6| Step: 4
Training loss: 2.690049171447754
Validation loss: 2.045536835988363

Epoch: 6| Step: 5
Training loss: 1.9601094722747803
Validation loss: 2.043235162893931

Epoch: 6| Step: 6
Training loss: 2.502962827682495
Validation loss: 2.0436963637669883

Epoch: 6| Step: 7
Training loss: 1.995778203010559
Validation loss: 2.041060209274292

Epoch: 6| Step: 8
Training loss: 1.6800391674041748
Validation loss: 2.0493524074554443

Epoch: 6| Step: 9
Training loss: 2.7953732013702393
Validation loss: 2.051313837369283

Epoch: 6| Step: 10
Training loss: 2.3389265537261963
Validation loss: 2.046343366305033

Epoch: 6| Step: 11
Training loss: 1.8107751607894897
Validation loss: 2.0481645862261453

Epoch: 6| Step: 12
Training loss: 2.662076950073242
Validation loss: 2.037760237852732

Epoch: 6| Step: 13
Training loss: 2.5641727447509766
Validation loss: 2.0332582592964172

Epoch: 60| Step: 0
Training loss: 2.1208243370056152
Validation loss: 2.0387760202089944

Epoch: 6| Step: 1
Training loss: 2.3286991119384766
Validation loss: 2.0446542302767434

Epoch: 6| Step: 2
Training loss: 2.5621395111083984
Validation loss: 2.048466523488363

Epoch: 6| Step: 3
Training loss: 2.8081703186035156
Validation loss: 2.0617149273554483

Epoch: 6| Step: 4
Training loss: 2.051605463027954
Validation loss: 2.0578797658284507

Epoch: 6| Step: 5
Training loss: 2.320462226867676
Validation loss: 2.0532031456629434

Epoch: 6| Step: 6
Training loss: 2.1970911026000977
Validation loss: 2.047150711218516

Epoch: 6| Step: 7
Training loss: 1.8411121368408203
Validation loss: 2.0453508694966636

Epoch: 6| Step: 8
Training loss: 2.1646904945373535
Validation loss: 2.0385889212290444

Epoch: 6| Step: 9
Training loss: 2.392545461654663
Validation loss: 2.041597763697306

Epoch: 6| Step: 10
Training loss: 2.248481035232544
Validation loss: 2.0473715464274087

Epoch: 6| Step: 11
Training loss: 1.7808613777160645
Validation loss: 2.0346630414326987

Epoch: 6| Step: 12
Training loss: 2.2527449131011963
Validation loss: 2.0354432662328086

Epoch: 6| Step: 13
Training loss: 2.1845545768737793
Validation loss: 2.0390515128771463

Epoch: 61| Step: 0
Training loss: 2.3390402793884277
Validation loss: 2.0299453139305115

Epoch: 6| Step: 1
Training loss: 1.9392948150634766
Validation loss: 2.0284725030263266

Epoch: 6| Step: 2
Training loss: 1.6807940006256104
Validation loss: 2.035918116569519

Epoch: 6| Step: 3
Training loss: 2.3358473777770996
Validation loss: 2.0334570606549582

Epoch: 6| Step: 4
Training loss: 2.543644428253174
Validation loss: 2.0322062174479165

Epoch: 6| Step: 5
Training loss: 1.8893287181854248
Validation loss: 2.0372476975123086

Epoch: 6| Step: 6
Training loss: 2.1270809173583984
Validation loss: 2.042015274365743

Epoch: 6| Step: 7
Training loss: 2.9546093940734863
Validation loss: 2.0454869866371155

Epoch: 6| Step: 8
Training loss: 2.368004560470581
Validation loss: 2.0475494861602783

Epoch: 6| Step: 9
Training loss: 2.328321933746338
Validation loss: 2.0438891847928367

Epoch: 6| Step: 10
Training loss: 2.43943452835083
Validation loss: 2.047853966554006

Epoch: 6| Step: 11
Training loss: 2.28405499458313
Validation loss: 2.0378748575846353

Epoch: 6| Step: 12
Training loss: 2.214298963546753
Validation loss: 2.0453507900238037

Epoch: 6| Step: 13
Training loss: 1.7073144912719727
Validation loss: 2.048152486483256

Epoch: 62| Step: 0
Training loss: 1.8445909023284912
Validation loss: 2.04062420129776

Epoch: 6| Step: 1
Training loss: 2.243950128555298
Validation loss: 2.042885979016622

Epoch: 6| Step: 2
Training loss: 1.6829254627227783
Validation loss: 2.042143960793813

Epoch: 6| Step: 3
Training loss: 1.7557182312011719
Validation loss: 2.039578398068746

Epoch: 6| Step: 4
Training loss: 1.9049265384674072
Validation loss: 2.0376726190249124

Epoch: 6| Step: 5
Training loss: 2.328702449798584
Validation loss: 2.034512678782145

Epoch: 6| Step: 6
Training loss: 1.9949398040771484
Validation loss: 2.0339644948641458

Epoch: 6| Step: 7
Training loss: 2.4708194732666016
Validation loss: 2.0352974931399026

Epoch: 6| Step: 8
Training loss: 2.44364070892334
Validation loss: 2.044543524583181

Epoch: 6| Step: 9
Training loss: 2.4143190383911133
Validation loss: 2.039307634035746

Epoch: 6| Step: 10
Training loss: 2.266162395477295
Validation loss: 2.045937955379486

Epoch: 6| Step: 11
Training loss: 2.446981906890869
Validation loss: 2.046795050303141

Epoch: 6| Step: 12
Training loss: 2.6413660049438477
Validation loss: 2.0546447237332663

Epoch: 6| Step: 13
Training loss: 2.596350908279419
Validation loss: 2.054548521836599

Epoch: 63| Step: 0
Training loss: 2.320549964904785
Validation loss: 2.0624399383862815

Epoch: 6| Step: 1
Training loss: 2.2303733825683594
Validation loss: 2.070480982462565

Epoch: 6| Step: 2
Training loss: 1.9920614957809448
Validation loss: 2.063400367895762

Epoch: 6| Step: 3
Training loss: 2.3287699222564697
Validation loss: 2.054228047529856

Epoch: 6| Step: 4
Training loss: 1.9364638328552246
Validation loss: 2.037215828895569

Epoch: 6| Step: 5
Training loss: 2.0798730850219727
Validation loss: 2.0252378582954407

Epoch: 6| Step: 6
Training loss: 2.215550661087036
Validation loss: 2.0218978921572366

Epoch: 6| Step: 7
Training loss: 2.226701498031616
Validation loss: 2.0270554423332214

Epoch: 6| Step: 8
Training loss: 2.115609645843506
Validation loss: 2.0390844345092773

Epoch: 6| Step: 9
Training loss: 2.6703758239746094
Validation loss: 2.060925086339315

Epoch: 6| Step: 10
Training loss: 2.1794586181640625
Validation loss: 2.06361190478007

Epoch: 6| Step: 11
Training loss: 2.192734718322754
Validation loss: 2.0705637534459433

Epoch: 6| Step: 12
Training loss: 2.6917147636413574
Validation loss: 2.0627084175745645

Epoch: 6| Step: 13
Training loss: 2.2294371128082275
Validation loss: 2.055960714817047

Epoch: 64| Step: 0
Training loss: 2.6125476360321045
Validation loss: 2.0530571142832437

Epoch: 6| Step: 1
Training loss: 2.1836438179016113
Validation loss: 2.047069509824117

Epoch: 6| Step: 2
Training loss: 2.336127281188965
Validation loss: 2.045206069946289

Epoch: 6| Step: 3
Training loss: 2.2694525718688965
Validation loss: 2.043669581413269

Epoch: 6| Step: 4
Training loss: 1.5406891107559204
Validation loss: 2.043181856473287

Epoch: 6| Step: 5
Training loss: 2.2538747787475586
Validation loss: 2.0346709489822388

Epoch: 6| Step: 6
Training loss: 2.217442035675049
Validation loss: 2.0276854634284973

Epoch: 6| Step: 7
Training loss: 2.4926974773406982
Validation loss: 2.0260373751322427

Epoch: 6| Step: 8
Training loss: 1.836756706237793
Validation loss: 2.0218669772148132

Epoch: 6| Step: 9
Training loss: 2.123723030090332
Validation loss: 2.017405609289805

Epoch: 6| Step: 10
Training loss: 2.1360297203063965
Validation loss: 2.0158079067866006

Epoch: 6| Step: 11
Training loss: 2.016111135482788
Validation loss: 2.017476499080658

Epoch: 6| Step: 12
Training loss: 2.473238706588745
Validation loss: 2.012845516204834

Epoch: 6| Step: 13
Training loss: 2.6014018058776855
Validation loss: 2.0205905636151633

Epoch: 65| Step: 0
Training loss: 1.7205252647399902
Validation loss: 2.0181904435157776

Epoch: 6| Step: 1
Training loss: 2.247593879699707
Validation loss: 2.014630158742269

Epoch: 6| Step: 2
Training loss: 2.9562151432037354
Validation loss: 2.0137702226638794

Epoch: 6| Step: 3
Training loss: 2.512576103210449
Validation loss: 2.0245789289474487

Epoch: 6| Step: 4
Training loss: 2.1876707077026367
Validation loss: 2.0189616481463113

Epoch: 6| Step: 5
Training loss: 1.9555234909057617
Validation loss: 2.0256537596384683

Epoch: 6| Step: 6
Training loss: 2.1684775352478027
Validation loss: 2.021503746509552

Epoch: 6| Step: 7
Training loss: 2.307651996612549
Validation loss: 2.011084020137787

Epoch: 6| Step: 8
Training loss: 2.480318784713745
Validation loss: 2.011927843093872

Epoch: 6| Step: 9
Training loss: 2.29710054397583
Validation loss: 2.0125771363576255

Epoch: 6| Step: 10
Training loss: 1.9959228038787842
Validation loss: 2.009393831094106

Epoch: 6| Step: 11
Training loss: 1.916321873664856
Validation loss: 2.011464536190033

Epoch: 6| Step: 12
Training loss: 1.996107816696167
Validation loss: 2.019833266735077

Epoch: 6| Step: 13
Training loss: 2.011812210083008
Validation loss: 2.0253478288650513

Epoch: 66| Step: 0
Training loss: 2.524392604827881
Validation loss: 2.023525873819987

Epoch: 6| Step: 1
Training loss: 2.382171869277954
Validation loss: 2.0272255738576255

Epoch: 6| Step: 2
Training loss: 2.0041348934173584
Validation loss: 2.0228960315386453

Epoch: 6| Step: 3
Training loss: 2.2983808517456055
Validation loss: 2.015431006749471

Epoch: 6| Step: 4
Training loss: 1.7819898128509521
Validation loss: 2.016184171040853

Epoch: 6| Step: 5
Training loss: 2.01243257522583
Validation loss: 2.0130820671717324

Epoch: 6| Step: 6
Training loss: 2.9411609172821045
Validation loss: 2.01488588253657

Epoch: 6| Step: 7
Training loss: 1.6513628959655762
Validation loss: 2.0134450793266296

Epoch: 6| Step: 8
Training loss: 2.20871639251709
Validation loss: 2.0169475277264914

Epoch: 6| Step: 9
Training loss: 2.0444908142089844
Validation loss: 2.0107800165812173

Epoch: 6| Step: 10
Training loss: 2.1069483757019043
Validation loss: 2.016888737678528

Epoch: 6| Step: 11
Training loss: 1.8905320167541504
Validation loss: 2.0195774833361306

Epoch: 6| Step: 12
Training loss: 2.5500082969665527
Validation loss: 2.013188660144806

Epoch: 6| Step: 13
Training loss: 2.282866954803467
Validation loss: 2.0202738642692566

Epoch: 67| Step: 0
Training loss: 1.926210880279541
Validation loss: 2.00974706808726

Epoch: 6| Step: 1
Training loss: 2.130709409713745
Validation loss: 2.0147828658421836

Epoch: 6| Step: 2
Training loss: 2.2916860580444336
Validation loss: 2.0140092372894287

Epoch: 6| Step: 3
Training loss: 2.1678433418273926
Validation loss: 2.018726666768392

Epoch: 6| Step: 4
Training loss: 2.0500502586364746
Validation loss: 2.0109742681185403

Epoch: 6| Step: 5
Training loss: 2.6876487731933594
Validation loss: 2.01261701186498

Epoch: 6| Step: 6
Training loss: 2.5259337425231934
Validation loss: 2.007632553577423

Epoch: 6| Step: 7
Training loss: 1.843677043914795
Validation loss: 2.0092923045158386

Epoch: 6| Step: 8
Training loss: 2.403566598892212
Validation loss: 2.0183104077974954

Epoch: 6| Step: 9
Training loss: 2.247236490249634
Validation loss: 2.0209495623906455

Epoch: 6| Step: 10
Training loss: 2.21388578414917
Validation loss: 2.0259231527646384

Epoch: 6| Step: 11
Training loss: 1.4989769458770752
Validation loss: 2.013300438721975

Epoch: 6| Step: 12
Training loss: 2.396531343460083
Validation loss: 2.018403947353363

Epoch: 6| Step: 13
Training loss: 2.136028289794922
Validation loss: 2.0109692215919495

Epoch: 68| Step: 0
Training loss: 2.124861001968384
Validation loss: 2.0150612195332847

Epoch: 6| Step: 1
Training loss: 2.570244789123535
Validation loss: 2.0155195792516074

Epoch: 6| Step: 2
Training loss: 2.233030319213867
Validation loss: 2.014267603556315

Epoch: 6| Step: 3
Training loss: 1.9830834865570068
Validation loss: 2.011838515599569

Epoch: 6| Step: 4
Training loss: 2.0250978469848633
Validation loss: 2.014652689297994

Epoch: 6| Step: 5
Training loss: 1.8698945045471191
Validation loss: 2.0107946594556174

Epoch: 6| Step: 6
Training loss: 2.036776304244995
Validation loss: 2.0107491413752236

Epoch: 6| Step: 7
Training loss: 2.2828447818756104
Validation loss: 2.0090537667274475

Epoch: 6| Step: 8
Training loss: 2.072019100189209
Validation loss: 2.016980151335398

Epoch: 6| Step: 9
Training loss: 2.477534770965576
Validation loss: 2.0226582487424216

Epoch: 6| Step: 10
Training loss: 2.0663795471191406
Validation loss: 2.0191450715065002

Epoch: 6| Step: 11
Training loss: 2.3847429752349854
Validation loss: 2.0228320956230164

Epoch: 6| Step: 12
Training loss: 2.7600669860839844
Validation loss: 2.0285528699556985

Epoch: 6| Step: 13
Training loss: 1.5124735832214355
Validation loss: 2.016729732354482

Epoch: 69| Step: 0
Training loss: 2.1334140300750732
Validation loss: 2.0275073846181235

Epoch: 6| Step: 1
Training loss: 2.5800561904907227
Validation loss: 2.0250500639279685

Epoch: 6| Step: 2
Training loss: 2.0047316551208496
Validation loss: 2.0182286302248635

Epoch: 6| Step: 3
Training loss: 2.2206783294677734
Validation loss: 2.023310979207357

Epoch: 6| Step: 4
Training loss: 1.572845697402954
Validation loss: 2.012329896291097

Epoch: 6| Step: 5
Training loss: 2.641695976257324
Validation loss: 2.012555480003357

Epoch: 6| Step: 6
Training loss: 1.671346664428711
Validation loss: 2.0198676586151123

Epoch: 6| Step: 7
Training loss: 2.6208605766296387
Validation loss: 2.013415296872457

Epoch: 6| Step: 8
Training loss: 2.4354820251464844
Validation loss: 2.0230056246121726

Epoch: 6| Step: 9
Training loss: 2.221508741378784
Validation loss: 2.027716855208079

Epoch: 6| Step: 10
Training loss: 2.0500712394714355
Validation loss: 2.0194289088249207

Epoch: 6| Step: 11
Training loss: 2.3637242317199707
Validation loss: 2.020521799723307

Epoch: 6| Step: 12
Training loss: 2.081597328186035
Validation loss: 2.0224969387054443

Epoch: 6| Step: 13
Training loss: 1.6762402057647705
Validation loss: 2.026714007059733

Epoch: 70| Step: 0
Training loss: 2.2167019844055176
Validation loss: 2.0242610375086465

Epoch: 6| Step: 1
Training loss: 2.26956844329834
Validation loss: 2.029381434122721

Epoch: 6| Step: 2
Training loss: 2.4516122341156006
Validation loss: 2.0236249963442483

Epoch: 6| Step: 3
Training loss: 2.019261360168457
Validation loss: 2.0305211544036865

Epoch: 6| Step: 4
Training loss: 2.304546594619751
Validation loss: 2.033685803413391

Epoch: 6| Step: 5
Training loss: 3.4784317016601562
Validation loss: 2.027336140473684

Epoch: 6| Step: 6
Training loss: 1.4505531787872314
Validation loss: 2.0238617261250815

Epoch: 6| Step: 7
Training loss: 2.2382431030273438
Validation loss: 2.022792379061381

Epoch: 6| Step: 8
Training loss: 2.373859167098999
Validation loss: 2.0147143602371216

Epoch: 6| Step: 9
Training loss: 2.5284109115600586
Validation loss: 2.0151273210843406

Epoch: 6| Step: 10
Training loss: 1.6239378452301025
Validation loss: 2.017564117908478

Epoch: 6| Step: 11
Training loss: 1.1850847005844116
Validation loss: 2.015740394592285

Epoch: 6| Step: 12
Training loss: 2.4352073669433594
Validation loss: 2.0147976875305176

Epoch: 6| Step: 13
Training loss: 1.6571733951568604
Validation loss: 2.0151140093803406

Epoch: 71| Step: 0
Training loss: 2.3018035888671875
Validation loss: 2.018268048763275

Epoch: 6| Step: 1
Training loss: 2.290358543395996
Validation loss: 2.0193559527397156

Epoch: 6| Step: 2
Training loss: 2.3833367824554443
Validation loss: 2.023599843184153

Epoch: 6| Step: 3
Training loss: 2.121706485748291
Validation loss: 2.0239892403284707

Epoch: 6| Step: 4
Training loss: 2.65816068649292
Validation loss: 2.0229191184043884

Epoch: 6| Step: 5
Training loss: 2.1226086616516113
Validation loss: 2.0225718021392822

Epoch: 6| Step: 6
Training loss: 2.3177881240844727
Validation loss: 2.024474640687307

Epoch: 6| Step: 7
Training loss: 2.061591625213623
Validation loss: 2.0165634950002036

Epoch: 6| Step: 8
Training loss: 1.80299711227417
Validation loss: 2.0212086041768393

Epoch: 6| Step: 9
Training loss: 2.2358062267303467
Validation loss: 2.022641678651174

Epoch: 6| Step: 10
Training loss: 2.5256149768829346
Validation loss: 2.0256532430648804

Epoch: 6| Step: 11
Training loss: 1.7536218166351318
Validation loss: 2.026197890440623

Epoch: 6| Step: 12
Training loss: 1.839216709136963
Validation loss: 2.0230612556139627

Epoch: 6| Step: 13
Training loss: 1.7073975801467896
Validation loss: 2.020493447780609

Epoch: 72| Step: 0
Training loss: 1.8446178436279297
Validation loss: 2.0245219071706138

Epoch: 6| Step: 1
Training loss: 1.9392342567443848
Validation loss: 2.0349618991216025

Epoch: 6| Step: 2
Training loss: 3.002786874771118
Validation loss: 2.0338396231333413

Epoch: 6| Step: 3
Training loss: 1.5199851989746094
Validation loss: 2.0398480693499246

Epoch: 6| Step: 4
Training loss: 2.658555746078491
Validation loss: 2.0480755964914956

Epoch: 6| Step: 5
Training loss: 2.8145971298217773
Validation loss: 2.0505818923314414

Epoch: 6| Step: 6
Training loss: 2.2939910888671875
Validation loss: 2.043516000111898

Epoch: 6| Step: 7
Training loss: 1.7154802083969116
Validation loss: 2.045678993066152

Epoch: 6| Step: 8
Training loss: 2.0210630893707275
Validation loss: 2.040480891863505

Epoch: 6| Step: 9
Training loss: 1.7371242046356201
Validation loss: 2.025621692339579

Epoch: 6| Step: 10
Training loss: 1.8289425373077393
Validation loss: 2.0166346033414206

Epoch: 6| Step: 11
Training loss: 2.807898998260498
Validation loss: 2.0159995555877686

Epoch: 6| Step: 12
Training loss: 1.94462251663208
Validation loss: 2.0158382455507913

Epoch: 6| Step: 13
Training loss: 2.1526336669921875
Validation loss: 2.017496109008789

Epoch: 73| Step: 0
Training loss: 2.2040066719055176
Validation loss: 2.024226347605387

Epoch: 6| Step: 1
Training loss: 1.4833905696868896
Validation loss: 2.02591335773468

Epoch: 6| Step: 2
Training loss: 2.4422497749328613
Validation loss: 2.033433119455973

Epoch: 6| Step: 3
Training loss: 2.1290769577026367
Validation loss: 2.0344889163970947

Epoch: 6| Step: 4
Training loss: 2.1868622303009033
Validation loss: 2.0305821299552917

Epoch: 6| Step: 5
Training loss: 2.3496904373168945
Validation loss: 2.0329185326894126

Epoch: 6| Step: 6
Training loss: 1.9003784656524658
Validation loss: 2.032684028148651

Epoch: 6| Step: 7
Training loss: 3.0018725395202637
Validation loss: 2.026298999786377

Epoch: 6| Step: 8
Training loss: 1.8986681699752808
Validation loss: 2.0292023022969565

Epoch: 6| Step: 9
Training loss: 1.656725525856018
Validation loss: 2.0231319665908813

Epoch: 6| Step: 10
Training loss: 2.223022937774658
Validation loss: 2.025991896788279

Epoch: 6| Step: 11
Training loss: 2.7850732803344727
Validation loss: 2.0116785566012063

Epoch: 6| Step: 12
Training loss: 1.9153615236282349
Validation loss: 2.0158929228782654

Epoch: 6| Step: 13
Training loss: 2.2498538494110107
Validation loss: 2.0183305541674295

Epoch: 74| Step: 0
Training loss: 1.9580018520355225
Validation loss: 2.0271050532658896

Epoch: 6| Step: 1
Training loss: 2.5362467765808105
Validation loss: 2.031526426474253

Epoch: 6| Step: 2
Training loss: 2.398775815963745
Validation loss: 2.0464417934417725

Epoch: 6| Step: 3
Training loss: 1.9298624992370605
Validation loss: 2.052840987841288

Epoch: 6| Step: 4
Training loss: 1.5476332902908325
Validation loss: 2.049043854077657

Epoch: 6| Step: 5
Training loss: 2.3854997158050537
Validation loss: 2.048123915990194

Epoch: 6| Step: 6
Training loss: 1.8523526191711426
Validation loss: 2.056019385655721

Epoch: 6| Step: 7
Training loss: 2.875150442123413
Validation loss: 2.0511515537897744

Epoch: 6| Step: 8
Training loss: 1.9041054248809814
Validation loss: 2.0401824712753296

Epoch: 6| Step: 9
Training loss: 2.3326292037963867
Validation loss: 2.028602679570516

Epoch: 6| Step: 10
Training loss: 1.9924373626708984
Validation loss: 2.039128561814626

Epoch: 6| Step: 11
Training loss: 2.238368272781372
Validation loss: 2.0328330794970193

Epoch: 6| Step: 12
Training loss: 2.5366859436035156
Validation loss: 2.028687298297882

Epoch: 6| Step: 13
Training loss: 1.8562769889831543
Validation loss: 2.0210588773091636

Epoch: 75| Step: 0
Training loss: 2.0815653800964355
Validation loss: 2.0275933146476746

Epoch: 6| Step: 1
Training loss: 2.0052876472473145
Validation loss: 2.013529340426127

Epoch: 6| Step: 2
Training loss: 2.1941750049591064
Validation loss: 2.0159310499827066

Epoch: 6| Step: 3
Training loss: 2.3885765075683594
Validation loss: 2.0170621275901794

Epoch: 6| Step: 4
Training loss: 2.2041640281677246
Validation loss: 2.01512748003006

Epoch: 6| Step: 5
Training loss: 2.1493725776672363
Validation loss: 2.0181067188580832

Epoch: 6| Step: 6
Training loss: 2.482927083969116
Validation loss: 2.0190946062405906

Epoch: 6| Step: 7
Training loss: 1.8622872829437256
Validation loss: 2.0146514972050986

Epoch: 6| Step: 8
Training loss: 2.9224867820739746
Validation loss: 2.020306885242462

Epoch: 6| Step: 9
Training loss: 1.868420124053955
Validation loss: 2.0183448791503906

Epoch: 6| Step: 10
Training loss: 2.0406150817871094
Validation loss: 2.014202813307444

Epoch: 6| Step: 11
Training loss: 2.088024616241455
Validation loss: 2.0167672832806907

Epoch: 6| Step: 12
Training loss: 2.1427230834960938
Validation loss: 2.01520965496699

Epoch: 6| Step: 13
Training loss: 1.6714168787002563
Validation loss: 2.023854911327362

Testing loss: 1.6562192928876809
