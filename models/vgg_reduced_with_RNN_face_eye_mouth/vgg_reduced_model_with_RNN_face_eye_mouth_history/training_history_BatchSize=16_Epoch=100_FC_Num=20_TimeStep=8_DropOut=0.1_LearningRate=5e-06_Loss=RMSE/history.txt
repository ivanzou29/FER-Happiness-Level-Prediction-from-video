Epoch: 1| Step: 0
Training loss: 5.6179124048723255
Validation loss: 5.921981609260529

Epoch: 6| Step: 1
Training loss: 5.509166015538793
Validation loss: 5.919704552830137

Epoch: 6| Step: 2
Training loss: 5.111904066651242
Validation loss: 5.917547760311257

Epoch: 6| Step: 3
Training loss: 4.966994833292078
Validation loss: 5.91522315598897

Epoch: 6| Step: 4
Training loss: 6.857364299014201
Validation loss: 5.913016397669473

Epoch: 6| Step: 5
Training loss: 6.259920105835642
Validation loss: 5.9109553679087705

Epoch: 6| Step: 6
Training loss: 6.246993295332851
Validation loss: 5.908767513504474

Epoch: 6| Step: 7
Training loss: 6.421463927688871
Validation loss: 5.906671364368324

Epoch: 6| Step: 8
Training loss: 6.095369563927163
Validation loss: 5.904546205987463

Epoch: 6| Step: 9
Training loss: 6.126113478986647
Validation loss: 5.902546685376311

Epoch: 6| Step: 10
Training loss: 6.7334272598413225
Validation loss: 5.9005468643112176

Epoch: 6| Step: 11
Training loss: 6.33644322118588
Validation loss: 5.898452213092163

Epoch: 6| Step: 12
Training loss: 4.878219715007784
Validation loss: 5.896293361586055

Epoch: 6| Step: 13
Training loss: 6.701250147550012
Validation loss: 5.894135175559977

Epoch: 2| Step: 0
Training loss: 6.086275338625307
Validation loss: 5.891933413900835

Epoch: 6| Step: 1
Training loss: 5.695733786073258
Validation loss: 5.889733365926178

Epoch: 6| Step: 2
Training loss: 5.935401626019776
Validation loss: 5.887246266679599

Epoch: 6| Step: 3
Training loss: 5.229908965213814
Validation loss: 5.884547706753119

Epoch: 6| Step: 4
Training loss: 6.481845739311637
Validation loss: 5.882077573520454

Epoch: 6| Step: 5
Training loss: 5.6140708713060326
Validation loss: 5.879393537736867

Epoch: 6| Step: 6
Training loss: 5.908790970239214
Validation loss: 5.876525518518558

Epoch: 6| Step: 7
Training loss: 5.865197627777825
Validation loss: 5.873524284347446

Epoch: 6| Step: 8
Training loss: 6.0950494407795315
Validation loss: 5.870417356498043

Epoch: 6| Step: 9
Training loss: 5.156422560145203
Validation loss: 5.867143071222707

Epoch: 6| Step: 10
Training loss: 6.748328955754036
Validation loss: 5.863981424976193

Epoch: 6| Step: 11
Training loss: 6.709323533548821
Validation loss: 5.860221781260631

Epoch: 6| Step: 12
Training loss: 7.019070397364886
Validation loss: 5.856618492233741

Epoch: 6| Step: 13
Training loss: 4.887772480815648
Validation loss: 5.852971571530374

Epoch: 3| Step: 0
Training loss: 4.905002313860271
Validation loss: 5.848983624189348

Epoch: 6| Step: 1
Training loss: 5.552103678348141
Validation loss: 5.845021617796128

Epoch: 6| Step: 2
Training loss: 6.216963775053082
Validation loss: 5.840840205103574

Epoch: 6| Step: 3
Training loss: 5.527987622612927
Validation loss: 5.836351140830954

Epoch: 6| Step: 4
Training loss: 6.340348557960026
Validation loss: 5.8319028826190005

Epoch: 6| Step: 5
Training loss: 6.42886929503141
Validation loss: 5.82735849202955

Epoch: 6| Step: 6
Training loss: 6.369084025449985
Validation loss: 5.822727461887452

Epoch: 6| Step: 7
Training loss: 5.617022133888017
Validation loss: 5.817857658999298

Epoch: 6| Step: 8
Training loss: 6.08186880101774
Validation loss: 5.812651683509948

Epoch: 6| Step: 9
Training loss: 6.056914597963346
Validation loss: 5.807540418375026

Epoch: 6| Step: 10
Training loss: 6.376874461134264
Validation loss: 5.802156494702093

Epoch: 6| Step: 11
Training loss: 6.0452386578950055
Validation loss: 5.796779525532698

Epoch: 6| Step: 12
Training loss: 6.043463954842978
Validation loss: 5.791294945879275

Epoch: 6| Step: 13
Training loss: 5.292756676736211
Validation loss: 5.785377966980653

Epoch: 4| Step: 0
Training loss: 6.114768688851939
Validation loss: 5.779868020879525

Epoch: 6| Step: 1
Training loss: 6.461942029583767
Validation loss: 5.774008592330306

Epoch: 6| Step: 2
Training loss: 6.544464614454245
Validation loss: 5.768004053228173

Epoch: 6| Step: 3
Training loss: 5.896344309884144
Validation loss: 5.761701673924201

Epoch: 6| Step: 4
Training loss: 5.387987636084697
Validation loss: 5.75516421846309

Epoch: 6| Step: 5
Training loss: 6.254134374743138
Validation loss: 5.749051444277727

Epoch: 6| Step: 6
Training loss: 5.224238633166047
Validation loss: 5.742624555982651

Epoch: 6| Step: 7
Training loss: 6.150628481130251
Validation loss: 5.736156384420522

Epoch: 6| Step: 8
Training loss: 4.946262937215063
Validation loss: 5.72974518600482

Epoch: 6| Step: 9
Training loss: 6.180643617762244
Validation loss: 5.723041723676597

Epoch: 6| Step: 10
Training loss: 5.798869239812984
Validation loss: 5.716651100530461

Epoch: 6| Step: 11
Training loss: 5.827945000781057
Validation loss: 5.709990583368611

Epoch: 6| Step: 12
Training loss: 6.118076381679175
Validation loss: 5.703248490342178

Epoch: 6| Step: 13
Training loss: 4.762947506042083
Validation loss: 5.696275110792818

Epoch: 5| Step: 0
Training loss: 5.862477694145665
Validation loss: 5.689502237869467

Epoch: 6| Step: 1
Training loss: 5.4666232960228855
Validation loss: 5.682720817306722

Epoch: 6| Step: 2
Training loss: 5.1823694066745505
Validation loss: 5.675987161155412

Epoch: 6| Step: 3
Training loss: 5.699233475392218
Validation loss: 5.669187275018579

Epoch: 6| Step: 4
Training loss: 5.533228805810949
Validation loss: 5.662504584371635

Epoch: 6| Step: 5
Training loss: 5.288253203870082
Validation loss: 5.655664852779138

Epoch: 6| Step: 6
Training loss: 5.865568666589004
Validation loss: 5.649256589250463

Epoch: 6| Step: 7
Training loss: 6.924427810331211
Validation loss: 5.64232031652587

Epoch: 6| Step: 8
Training loss: 5.603952831551746
Validation loss: 5.635355283317086

Epoch: 6| Step: 9
Training loss: 6.0120322063342275
Validation loss: 5.62877118885972

Epoch: 6| Step: 10
Training loss: 5.2681824221181675
Validation loss: 5.621753462162779

Epoch: 6| Step: 11
Training loss: 5.260858659462243
Validation loss: 5.61494689028571

Epoch: 6| Step: 12
Training loss: 5.836523473447487
Validation loss: 5.60843695232618

Epoch: 6| Step: 13
Training loss: 6.591280940457261
Validation loss: 5.602155681505633

Epoch: 6| Step: 0
Training loss: 5.779515681583698
Validation loss: 5.595480681342534

Epoch: 6| Step: 1
Training loss: 6.171024775792693
Validation loss: 5.589188120326694

Epoch: 6| Step: 2
Training loss: 5.514697637215229
Validation loss: 5.582567456605615

Epoch: 6| Step: 3
Training loss: 5.860622263083236
Validation loss: 5.576200892455876

Epoch: 6| Step: 4
Training loss: 5.250117346042543
Validation loss: 5.56992213525229

Epoch: 6| Step: 5
Training loss: 5.727252247320992
Validation loss: 5.563966907714533

Epoch: 6| Step: 6
Training loss: 5.566869840892586
Validation loss: 5.557556212783446

Epoch: 6| Step: 7
Training loss: 6.421554817329885
Validation loss: 5.551814985917495

Epoch: 6| Step: 8
Training loss: 5.117300809814194
Validation loss: 5.545843323952465

Epoch: 6| Step: 9
Training loss: 6.415754311173991
Validation loss: 5.540095094491236

Epoch: 6| Step: 10
Training loss: 5.966209949652298
Validation loss: 5.5340220084075

Epoch: 6| Step: 11
Training loss: 4.7022722554764975
Validation loss: 5.528674860653627

Epoch: 6| Step: 12
Training loss: 5.12108201782838
Validation loss: 5.522669111488596

Epoch: 6| Step: 13
Training loss: 5.55896706845472
Validation loss: 5.51707674252204

Epoch: 7| Step: 0
Training loss: 6.419822049155433
Validation loss: 5.511751711481216

Epoch: 6| Step: 1
Training loss: 6.106005117294911
Validation loss: 5.505894305734205

Epoch: 6| Step: 2
Training loss: 5.635655969790816
Validation loss: 5.50064929828638

Epoch: 6| Step: 3
Training loss: 5.607058926232726
Validation loss: 5.495442438383577

Epoch: 6| Step: 4
Training loss: 5.339777311903807
Validation loss: 5.490242770674981

Epoch: 6| Step: 5
Training loss: 5.5979186140974395
Validation loss: 5.484914494105604

Epoch: 6| Step: 6
Training loss: 5.6187862407801275
Validation loss: 5.4801991097970175

Epoch: 6| Step: 7
Training loss: 4.950164198801164
Validation loss: 5.475375596028294

Epoch: 6| Step: 8
Training loss: 5.375937801432699
Validation loss: 5.470737234270525

Epoch: 6| Step: 9
Training loss: 5.592562245690595
Validation loss: 5.466057890435539

Epoch: 6| Step: 10
Training loss: 4.765389258385462
Validation loss: 5.4616534591917105

Epoch: 6| Step: 11
Training loss: 5.732039888252486
Validation loss: 5.457111872316635

Epoch: 6| Step: 12
Training loss: 5.4382428944290995
Validation loss: 5.45276239131381

Epoch: 6| Step: 13
Training loss: 6.018354316927679
Validation loss: 5.448378660648093

Epoch: 8| Step: 0
Training loss: 5.337749123398898
Validation loss: 5.443898262256094

Epoch: 6| Step: 1
Training loss: 5.349920268667891
Validation loss: 5.439784333825293

Epoch: 6| Step: 2
Training loss: 5.903211023724715
Validation loss: 5.435743201572567

Epoch: 6| Step: 3
Training loss: 5.372278455992003
Validation loss: 5.43131916220131

Epoch: 6| Step: 4
Training loss: 6.510482258784164
Validation loss: 5.426729401843632

Epoch: 6| Step: 5
Training loss: 5.312506462542025
Validation loss: 5.422631788984068

Epoch: 6| Step: 6
Training loss: 4.533611655573808
Validation loss: 5.417759633446355

Epoch: 6| Step: 7
Training loss: 5.736561870131251
Validation loss: 5.413402933713097

Epoch: 6| Step: 8
Training loss: 5.001915755424639
Validation loss: 5.409419003782746

Epoch: 6| Step: 9
Training loss: 6.076233086420221
Validation loss: 5.405192424255511

Epoch: 6| Step: 10
Training loss: 5.7367477289501965
Validation loss: 5.400972616648802

Epoch: 6| Step: 11
Training loss: 5.1282831236214435
Validation loss: 5.396600214639579

Epoch: 6| Step: 12
Training loss: 5.547368073375329
Validation loss: 5.392261643675138

Epoch: 6| Step: 13
Training loss: 5.708421061414819
Validation loss: 5.387795056541132

Epoch: 9| Step: 0
Training loss: 5.800705952268029
Validation loss: 5.383571060096682

Epoch: 6| Step: 1
Training loss: 4.995824405427813
Validation loss: 5.37923161324382

Epoch: 6| Step: 2
Training loss: 4.683377093091453
Validation loss: 5.37503424345242

Epoch: 6| Step: 3
Training loss: 5.00740742346918
Validation loss: 5.370650638682047

Epoch: 6| Step: 4
Training loss: 4.973555442377547
Validation loss: 5.366750848398177

Epoch: 6| Step: 5
Training loss: 5.812429776331509
Validation loss: 5.36296437349139

Epoch: 6| Step: 6
Training loss: 5.316530202391814
Validation loss: 5.358526550100002

Epoch: 6| Step: 7
Training loss: 6.9517675553455245
Validation loss: 5.354354182223991

Epoch: 6| Step: 8
Training loss: 6.247338300415926
Validation loss: 5.350116439693059

Epoch: 6| Step: 9
Training loss: 5.947620640573816
Validation loss: 5.3462192414940235

Epoch: 6| Step: 10
Training loss: 5.00626933919193
Validation loss: 5.341998283499258

Epoch: 6| Step: 11
Training loss: 5.445357334822597
Validation loss: 5.33796986068501

Epoch: 6| Step: 12
Training loss: 5.306277951008538
Validation loss: 5.333128935155546

Epoch: 6| Step: 13
Training loss: 4.715109930607646
Validation loss: 5.32903758537165

Epoch: 10| Step: 0
Training loss: 4.762095260442744
Validation loss: 5.324961359782307

Epoch: 6| Step: 1
Training loss: 5.751299835566216
Validation loss: 5.32004507982663

Epoch: 6| Step: 2
Training loss: 6.1458714715668705
Validation loss: 5.315699731958171

Epoch: 6| Step: 3
Training loss: 6.315755778774928
Validation loss: 5.311609979013221

Epoch: 6| Step: 4
Training loss: 5.222119003430152
Validation loss: 5.307529922044033

Epoch: 6| Step: 5
Training loss: 5.574117123613719
Validation loss: 5.302344904694741

Epoch: 6| Step: 6
Training loss: 5.284679315197615
Validation loss: 5.297979969161998

Epoch: 6| Step: 7
Training loss: 4.479894865709741
Validation loss: 5.293956511461668

Epoch: 6| Step: 8
Training loss: 5.863141692938574
Validation loss: 5.289345459950032

Epoch: 6| Step: 9
Training loss: 5.457404351228487
Validation loss: 5.28406114268441

Epoch: 6| Step: 10
Training loss: 5.366344135772968
Validation loss: 5.279441237842677

Epoch: 6| Step: 11
Training loss: 5.464375168382471
Validation loss: 5.274874147236631

Epoch: 6| Step: 12
Training loss: 5.613942786240142
Validation loss: 5.269781115701638

Epoch: 6| Step: 13
Training loss: 4.131687638595144
Validation loss: 5.265365699850837

Epoch: 11| Step: 0
Training loss: 5.990339130869974
Validation loss: 5.2609048547610895

Epoch: 6| Step: 1
Training loss: 4.311504746738932
Validation loss: 5.256944755756879

Epoch: 6| Step: 2
Training loss: 5.225364285414291
Validation loss: 5.252141863769043

Epoch: 6| Step: 3
Training loss: 5.7117530250903625
Validation loss: 5.248369538969818

Epoch: 6| Step: 4
Training loss: 5.191913244148599
Validation loss: 5.244005838244942

Epoch: 6| Step: 5
Training loss: 5.432810899077633
Validation loss: 5.239478846494697

Epoch: 6| Step: 6
Training loss: 5.624306190935424
Validation loss: 5.235200002760992

Epoch: 6| Step: 7
Training loss: 6.032102534467408
Validation loss: 5.231198355641243

Epoch: 6| Step: 8
Training loss: 5.015322286912533
Validation loss: 5.226599844745444

Epoch: 6| Step: 9
Training loss: 4.908591131015038
Validation loss: 5.222595260138459

Epoch: 6| Step: 10
Training loss: 5.68843288945145
Validation loss: 5.218426966615521

Epoch: 6| Step: 11
Training loss: 4.332825019562466
Validation loss: 5.21390846428064

Epoch: 6| Step: 12
Training loss: 5.651739693232394
Validation loss: 5.209314828581237

Epoch: 6| Step: 13
Training loss: 5.510726006616108
Validation loss: 5.204672979317234

Epoch: 12| Step: 0
Training loss: 5.109527305642801
Validation loss: 5.199749681365505

Epoch: 6| Step: 1
Training loss: 4.9327999874871
Validation loss: 5.195280376134238

Epoch: 6| Step: 2
Training loss: 5.441635137975856
Validation loss: 5.191146457544887

Epoch: 6| Step: 3
Training loss: 4.769199719103129
Validation loss: 5.18713981266525

Epoch: 6| Step: 4
Training loss: 5.593538930309914
Validation loss: 5.183696808086375

Epoch: 6| Step: 5
Training loss: 5.345998190728597
Validation loss: 5.179142236178846

Epoch: 6| Step: 6
Training loss: 4.898087435781894
Validation loss: 5.1749829560765495

Epoch: 6| Step: 7
Training loss: 5.029944208946774
Validation loss: 5.170302875287345

Epoch: 6| Step: 8
Training loss: 4.680848959842998
Validation loss: 5.165520612704657

Epoch: 6| Step: 9
Training loss: 4.841345011564048
Validation loss: 5.16049777683195

Epoch: 6| Step: 10
Training loss: 5.770489219936413
Validation loss: 5.156410014434347

Epoch: 6| Step: 11
Training loss: 5.786417533211058
Validation loss: 5.152725248020481

Epoch: 6| Step: 12
Training loss: 6.090568455315704
Validation loss: 5.148811106808894

Epoch: 6| Step: 13
Training loss: 5.599394779198065
Validation loss: 5.1434134637833555

Epoch: 13| Step: 0
Training loss: 4.705831262367261
Validation loss: 5.139363421047026

Epoch: 6| Step: 1
Training loss: 5.208739038560693
Validation loss: 5.13563829089503

Epoch: 6| Step: 2
Training loss: 5.333443322637004
Validation loss: 5.131012282012908

Epoch: 6| Step: 3
Training loss: 5.329288478688962
Validation loss: 5.126928478363378

Epoch: 6| Step: 4
Training loss: 5.703988456682293
Validation loss: 5.121976999815342

Epoch: 6| Step: 5
Training loss: 4.515092547747131
Validation loss: 5.117715481220546

Epoch: 6| Step: 6
Training loss: 5.1656704013903925
Validation loss: 5.113910835426689

Epoch: 6| Step: 7
Training loss: 4.787387872483444
Validation loss: 5.109283881974141

Epoch: 6| Step: 8
Training loss: 5.325968286297385
Validation loss: 5.105297892288991

Epoch: 6| Step: 9
Training loss: 4.9836195609438985
Validation loss: 5.100289201951442

Epoch: 6| Step: 10
Training loss: 5.828502653020717
Validation loss: 5.09619515674016

Epoch: 6| Step: 11
Training loss: 5.371626216504539
Validation loss: 5.09309629524516

Epoch: 6| Step: 12
Training loss: 5.072406260083471
Validation loss: 5.088186240562375

Epoch: 6| Step: 13
Training loss: 5.7699372000888145
Validation loss: 5.0837686487798015

Epoch: 14| Step: 0
Training loss: 4.954518023010112
Validation loss: 5.078931851966249

Epoch: 6| Step: 1
Training loss: 5.695747180985743
Validation loss: 5.07511917751044

Epoch: 6| Step: 2
Training loss: 4.482586972722066
Validation loss: 5.070306387076197

Epoch: 6| Step: 3
Training loss: 4.982586291571286
Validation loss: 5.065610581474956

Epoch: 6| Step: 4
Training loss: 5.403488600561353
Validation loss: 5.061173850092987

Epoch: 6| Step: 5
Training loss: 4.626038718213684
Validation loss: 5.057427302020482

Epoch: 6| Step: 6
Training loss: 5.40650683548161
Validation loss: 5.0538917477216305

Epoch: 6| Step: 7
Training loss: 4.748270623455894
Validation loss: 5.048558099192324

Epoch: 6| Step: 8
Training loss: 5.118734297769052
Validation loss: 5.0446665432547135

Epoch: 6| Step: 9
Training loss: 5.912743283966407
Validation loss: 5.039940982705175

Epoch: 6| Step: 10
Training loss: 5.066701958349357
Validation loss: 5.036251228226958

Epoch: 6| Step: 11
Training loss: 5.664214033533318
Validation loss: 5.032433096271514

Epoch: 6| Step: 12
Training loss: 5.602596682284973
Validation loss: 5.027329206507389

Epoch: 6| Step: 13
Training loss: 4.517985957596273
Validation loss: 5.023327736770223

Epoch: 15| Step: 0
Training loss: 4.727419940950424
Validation loss: 5.018978404116515

Epoch: 6| Step: 1
Training loss: 4.649371705626479
Validation loss: 5.015774068072956

Epoch: 6| Step: 2
Training loss: 5.602233250679547
Validation loss: 5.011110359543328

Epoch: 6| Step: 3
Training loss: 4.633621222427937
Validation loss: 5.006071314676749

Epoch: 6| Step: 4
Training loss: 5.9006896310989445
Validation loss: 5.001315579590236

Epoch: 6| Step: 5
Training loss: 4.734856407944957
Validation loss: 4.99704499344198

Epoch: 6| Step: 6
Training loss: 4.811692405414262
Validation loss: 4.9929537396520445

Epoch: 6| Step: 7
Training loss: 5.333349088804497
Validation loss: 4.989536431184368

Epoch: 6| Step: 8
Training loss: 5.314345992752869
Validation loss: 4.984509632679991

Epoch: 6| Step: 9
Training loss: 4.666068561009369
Validation loss: 4.979268295123469

Epoch: 6| Step: 10
Training loss: 5.618723440478801
Validation loss: 4.974624695671302

Epoch: 6| Step: 11
Training loss: 5.032303030571978
Validation loss: 4.969509938344329

Epoch: 6| Step: 12
Training loss: 5.722911217123
Validation loss: 4.966175812055829

Epoch: 6| Step: 13
Training loss: 4.575806326762428
Validation loss: 4.961393304345674

Epoch: 16| Step: 0
Training loss: 5.3235402000201395
Validation loss: 4.956510459851667

Epoch: 6| Step: 1
Training loss: 4.585504306693442
Validation loss: 4.951540431764634

Epoch: 6| Step: 2
Training loss: 5.626934481811358
Validation loss: 4.947122428459185

Epoch: 6| Step: 3
Training loss: 6.085036714265974
Validation loss: 4.941839733384703

Epoch: 6| Step: 4
Training loss: 5.999791777494534
Validation loss: 4.937037418119884

Epoch: 6| Step: 5
Training loss: 4.664336690079614
Validation loss: 4.93143151371845

Epoch: 6| Step: 6
Training loss: 5.03123199270118
Validation loss: 4.926535104759504

Epoch: 6| Step: 7
Training loss: 4.3033824126155675
Validation loss: 4.920902119714836

Epoch: 6| Step: 8
Training loss: 4.511054976875646
Validation loss: 4.91596541279937

Epoch: 6| Step: 9
Training loss: 4.988972137330549
Validation loss: 4.911018273658961

Epoch: 6| Step: 10
Training loss: 5.130097807905495
Validation loss: 4.905342779492795

Epoch: 6| Step: 11
Training loss: 4.239514374543151
Validation loss: 4.900350275300534

Epoch: 6| Step: 12
Training loss: 5.305282896446534
Validation loss: 4.895956754819664

Epoch: 6| Step: 13
Training loss: 4.440085074494632
Validation loss: 4.892132901399059

Epoch: 17| Step: 0
Training loss: 5.365284855969286
Validation loss: 4.885921731420596

Epoch: 6| Step: 1
Training loss: 4.749470129073138
Validation loss: 4.881019950912936

Epoch: 6| Step: 2
Training loss: 4.865605227234832
Validation loss: 4.875969977756085

Epoch: 6| Step: 3
Training loss: 5.041266286205542
Validation loss: 4.870874142482633

Epoch: 6| Step: 4
Training loss: 4.97447824473814
Validation loss: 4.866721076312806

Epoch: 6| Step: 5
Training loss: 4.1998800351403265
Validation loss: 4.8610972207491585

Epoch: 6| Step: 6
Training loss: 5.744082183696246
Validation loss: 4.856749648251662

Epoch: 6| Step: 7
Training loss: 5.587219517983759
Validation loss: 4.851840000539859

Epoch: 6| Step: 8
Training loss: 5.10092780705607
Validation loss: 4.846792926499262

Epoch: 6| Step: 9
Training loss: 5.360673307859623
Validation loss: 4.842263270447226

Epoch: 6| Step: 10
Training loss: 4.769270506283888
Validation loss: 4.837139467116358

Epoch: 6| Step: 11
Training loss: 4.620630623189548
Validation loss: 4.831996875456669

Epoch: 6| Step: 12
Training loss: 4.490658282513015
Validation loss: 4.827153574180455

Epoch: 6| Step: 13
Training loss: 4.604684285660144
Validation loss: 4.821572772229458

Epoch: 18| Step: 0
Training loss: 4.406223161764453
Validation loss: 4.817786677642835

Epoch: 6| Step: 1
Training loss: 4.180315373401121
Validation loss: 4.813259345584068

Epoch: 6| Step: 2
Training loss: 5.025934859279097
Validation loss: 4.808673377659907

Epoch: 6| Step: 3
Training loss: 5.196530673972033
Validation loss: 4.803787171902199

Epoch: 6| Step: 4
Training loss: 5.325243576281607
Validation loss: 4.798590172247955

Epoch: 6| Step: 5
Training loss: 4.300983032703968
Validation loss: 4.793773364922365

Epoch: 6| Step: 6
Training loss: 4.631164978317711
Validation loss: 4.789037093509492

Epoch: 6| Step: 7
Training loss: 4.797746113263392
Validation loss: 4.784190385355801

Epoch: 6| Step: 8
Training loss: 5.3052548539105455
Validation loss: 4.7799381958119564

Epoch: 6| Step: 9
Training loss: 5.082022242497782
Validation loss: 4.774460004061538

Epoch: 6| Step: 10
Training loss: 5.7689533499506
Validation loss: 4.769598199914445

Epoch: 6| Step: 11
Training loss: 4.760236651844883
Validation loss: 4.767133396924858

Epoch: 6| Step: 12
Training loss: 4.9611816346178985
Validation loss: 4.7606310083171826

Epoch: 6| Step: 13
Training loss: 4.77113578981499
Validation loss: 4.755079364455241

Epoch: 19| Step: 0
Training loss: 4.472459227374504
Validation loss: 4.751424809971512

Epoch: 6| Step: 1
Training loss: 4.712127889416396
Validation loss: 4.7469016728374855

Epoch: 6| Step: 2
Training loss: 5.022436157853756
Validation loss: 4.742576620863467

Epoch: 6| Step: 3
Training loss: 4.137587790119657
Validation loss: 4.736209023148124

Epoch: 6| Step: 4
Training loss: 5.464283017995759
Validation loss: 4.732337101790931

Epoch: 6| Step: 5
Training loss: 6.120744433535377
Validation loss: 4.7280650711379675

Epoch: 6| Step: 6
Training loss: 5.174747280271071
Validation loss: 4.722836810989052

Epoch: 6| Step: 7
Training loss: 4.354774152853771
Validation loss: 4.718033220364728

Epoch: 6| Step: 8
Training loss: 4.977002087016834
Validation loss: 4.712949914476315

Epoch: 6| Step: 9
Training loss: 4.249580811415863
Validation loss: 4.708232991097387

Epoch: 6| Step: 10
Training loss: 5.7378245276462225
Validation loss: 4.703899129733234

Epoch: 6| Step: 11
Training loss: 4.175710907674603
Validation loss: 4.698207747526719

Epoch: 6| Step: 12
Training loss: 4.394442273404795
Validation loss: 4.693767121914901

Epoch: 6| Step: 13
Training loss: 4.346144859922713
Validation loss: 4.68922701068993

Epoch: 20| Step: 0
Training loss: 5.167888845458903
Validation loss: 4.684588990721962

Epoch: 6| Step: 1
Training loss: 4.113817026107505
Validation loss: 4.679932313521974

Epoch: 6| Step: 2
Training loss: 4.802672023919178
Validation loss: 4.674102983417796

Epoch: 6| Step: 3
Training loss: 4.9131013691431775
Validation loss: 4.670276925632258

Epoch: 6| Step: 4
Training loss: 4.428777584428234
Validation loss: 4.666068646169775

Epoch: 6| Step: 5
Training loss: 4.9421442136699065
Validation loss: 4.6617180721725076

Epoch: 6| Step: 6
Training loss: 5.598707847019204
Validation loss: 4.656661986146367

Epoch: 6| Step: 7
Training loss: 4.167079269325317
Validation loss: 4.651980360536894

Epoch: 6| Step: 8
Training loss: 4.689620085337383
Validation loss: 4.646742602037545

Epoch: 6| Step: 9
Training loss: 4.871407383272192
Validation loss: 4.642271971942483

Epoch: 6| Step: 10
Training loss: 4.738376248532428
Validation loss: 4.637939669459181

Epoch: 6| Step: 11
Training loss: 4.796066762820615
Validation loss: 4.6334031893360565

Epoch: 6| Step: 12
Training loss: 4.219815494065479
Validation loss: 4.628001313206325

Epoch: 6| Step: 13
Training loss: 5.242893131707238
Validation loss: 4.6243191982641605

Epoch: 21| Step: 0
Training loss: 4.8953140740950625
Validation loss: 4.617542010110872

Epoch: 6| Step: 1
Training loss: 5.405660961012542
Validation loss: 4.616028202863248

Epoch: 6| Step: 2
Training loss: 4.323994231835116
Validation loss: 4.610852951779327

Epoch: 6| Step: 3
Training loss: 5.014679151104823
Validation loss: 4.6043819302369995

Epoch: 6| Step: 4
Training loss: 5.160610320495521
Validation loss: 4.5987160583941264

Epoch: 6| Step: 5
Training loss: 4.356608507682207
Validation loss: 4.594704630438269

Epoch: 6| Step: 6
Training loss: 5.065542554802172
Validation loss: 4.591852535817473

Epoch: 6| Step: 7
Training loss: 4.013401944998674
Validation loss: 4.587822513174873

Epoch: 6| Step: 8
Training loss: 5.437852168462718
Validation loss: 4.580270344835886

Epoch: 6| Step: 9
Training loss: 3.7227389955881223
Validation loss: 4.573948366517296

Epoch: 6| Step: 10
Training loss: 4.994715568379124
Validation loss: 4.569608263495175

Epoch: 6| Step: 11
Training loss: 4.219266732676972
Validation loss: 4.565039916238297

Epoch: 6| Step: 12
Training loss: 4.134525744399654
Validation loss: 4.560724130544404

Epoch: 6| Step: 13
Training loss: 4.88267538869993
Validation loss: 4.556350134092393

Epoch: 22| Step: 0
Training loss: 5.245646715468072
Validation loss: 4.5512551515252

Epoch: 6| Step: 1
Training loss: 3.8442033949996017
Validation loss: 4.544770827745809

Epoch: 6| Step: 2
Training loss: 4.864637463069034
Validation loss: 4.541856755936153

Epoch: 6| Step: 3
Training loss: 5.0592081175549
Validation loss: 4.537709229744777

Epoch: 6| Step: 4
Training loss: 4.507773572730535
Validation loss: 4.530818313555963

Epoch: 6| Step: 5
Training loss: 4.566161476277576
Validation loss: 4.52827390957283

Epoch: 6| Step: 6
Training loss: 4.904556662523964
Validation loss: 4.526108536776837

Epoch: 6| Step: 7
Training loss: 4.155357322339243
Validation loss: 4.519286487296221

Epoch: 6| Step: 8
Training loss: 5.146704143196659
Validation loss: 4.513880831719405

Epoch: 6| Step: 9
Training loss: 4.449414658356979
Validation loss: 4.508772687721827

Epoch: 6| Step: 10
Training loss: 4.579844910107194
Validation loss: 4.5034925365096035

Epoch: 6| Step: 11
Training loss: 3.599221484458751
Validation loss: 4.4998596664022354

Epoch: 6| Step: 12
Training loss: 5.335579677218152
Validation loss: 4.495832915684654

Epoch: 6| Step: 13
Training loss: 4.467059475911209
Validation loss: 4.490355930394882

Epoch: 23| Step: 0
Training loss: 5.044987659269122
Validation loss: 4.4851032157597075

Epoch: 6| Step: 1
Training loss: 4.356936193027424
Validation loss: 4.479862827346755

Epoch: 6| Step: 2
Training loss: 4.764486608397757
Validation loss: 4.475397496532958

Epoch: 6| Step: 3
Training loss: 4.371898096444866
Validation loss: 4.471082883176519

Epoch: 6| Step: 4
Training loss: 5.383572152492595
Validation loss: 4.46554644448602

Epoch: 6| Step: 5
Training loss: 3.9416875219028595
Validation loss: 4.460441334617759

Epoch: 6| Step: 6
Training loss: 4.541522989129419
Validation loss: 4.456066779480361

Epoch: 6| Step: 7
Training loss: 4.376958572132375
Validation loss: 4.450698923379958

Epoch: 6| Step: 8
Training loss: 4.41903800403476
Validation loss: 4.446104670750093

Epoch: 6| Step: 9
Training loss: 3.745811921179778
Validation loss: 4.440619254416127

Epoch: 6| Step: 10
Training loss: 5.400962404744264
Validation loss: 4.435875770002279

Epoch: 6| Step: 11
Training loss: 5.29225844230665
Validation loss: 4.431194822670012

Epoch: 6| Step: 12
Training loss: 3.743654859349699
Validation loss: 4.426291050045941

Epoch: 6| Step: 13
Training loss: 4.333476039786345
Validation loss: 4.421217151678361

Epoch: 24| Step: 0
Training loss: 4.436540311814431
Validation loss: 4.417420784729886

Epoch: 6| Step: 1
Training loss: 4.917491692757584
Validation loss: 4.411602403734506

Epoch: 6| Step: 2
Training loss: 4.2185786459702665
Validation loss: 4.407336739069424

Epoch: 6| Step: 3
Training loss: 4.162079358540871
Validation loss: 4.402011645567281

Epoch: 6| Step: 4
Training loss: 4.340076237725275
Validation loss: 4.397728130444142

Epoch: 6| Step: 5
Training loss: 3.639173750530174
Validation loss: 4.392526597167017

Epoch: 6| Step: 6
Training loss: 4.454412762677336
Validation loss: 4.389705104554054

Epoch: 6| Step: 7
Training loss: 4.342598522344603
Validation loss: 4.383611197179967

Epoch: 6| Step: 8
Training loss: 4.905301530846041
Validation loss: 4.379767971454061

Epoch: 6| Step: 9
Training loss: 5.230317413442642
Validation loss: 4.375669428154796

Epoch: 6| Step: 10
Training loss: 4.288430978666797
Validation loss: 4.370478700712841

Epoch: 6| Step: 11
Training loss: 4.407510779979416
Validation loss: 4.36575765296702

Epoch: 6| Step: 12
Training loss: 5.555660886825644
Validation loss: 4.361737630808832

Epoch: 6| Step: 13
Training loss: 3.952518703119663
Validation loss: 4.355880740627621

Epoch: 25| Step: 0
Training loss: 5.455011866597696
Validation loss: 4.350868667452241

Epoch: 6| Step: 1
Training loss: 4.392330177945397
Validation loss: 4.346494800021106

Epoch: 6| Step: 2
Training loss: 4.277952831919598
Validation loss: 4.341963164931334

Epoch: 6| Step: 3
Training loss: 4.291791648649771
Validation loss: 4.336343648864579

Epoch: 6| Step: 4
Training loss: 4.755600087580238
Validation loss: 4.331384122605827

Epoch: 6| Step: 5
Training loss: 4.750676157158612
Validation loss: 4.325928517451035

Epoch: 6| Step: 6
Training loss: 4.051288804689676
Validation loss: 4.321607472673547

Epoch: 6| Step: 7
Training loss: 3.9724967271852547
Validation loss: 4.3165329950518645

Epoch: 6| Step: 8
Training loss: 4.353594266267622
Validation loss: 4.31163384773928

Epoch: 6| Step: 9
Training loss: 3.6718163018912024
Validation loss: 4.3077050794422584

Epoch: 6| Step: 10
Training loss: 4.49024818023378
Validation loss: 4.30289860990746

Epoch: 6| Step: 11
Training loss: 4.481730994210582
Validation loss: 4.299368505904157

Epoch: 6| Step: 12
Training loss: 4.723276758566313
Validation loss: 4.293508257994679

Epoch: 6| Step: 13
Training loss: 4.391635764855973
Validation loss: 4.288701591755887

Epoch: 26| Step: 0
Training loss: 4.155988871466797
Validation loss: 4.284941555175085

Epoch: 6| Step: 1
Training loss: 4.088140706934787
Validation loss: 4.280695004467474

Epoch: 6| Step: 2
Training loss: 4.2952185194850045
Validation loss: 4.276753944364678

Epoch: 6| Step: 3
Training loss: 4.396095641688103
Validation loss: 4.272158229603811

Epoch: 6| Step: 4
Training loss: 4.746998692019122
Validation loss: 4.267674346234804

Epoch: 6| Step: 5
Training loss: 4.759250667799009
Validation loss: 4.262371830211187

Epoch: 6| Step: 6
Training loss: 4.2206945388332375
Validation loss: 4.257848952951036

Epoch: 6| Step: 7
Training loss: 4.311168962813651
Validation loss: 4.252578028240182

Epoch: 6| Step: 8
Training loss: 4.606752017859518
Validation loss: 4.248245232288277

Epoch: 6| Step: 9
Training loss: 4.284605618536727
Validation loss: 4.242589567367053

Epoch: 6| Step: 10
Training loss: 4.425216221241209
Validation loss: 4.238817294160426

Epoch: 6| Step: 11
Training loss: 4.41446887820999
Validation loss: 4.233152806695595

Epoch: 6| Step: 12
Training loss: 4.525461011132595
Validation loss: 4.227900473682485

Epoch: 6| Step: 13
Training loss: 4.111730328456052
Validation loss: 4.222929666602976

Epoch: 27| Step: 0
Training loss: 4.660679086803864
Validation loss: 4.217822201279041

Epoch: 6| Step: 1
Training loss: 4.7700386995868955
Validation loss: 4.21213864928296

Epoch: 6| Step: 2
Training loss: 4.163454165225972
Validation loss: 4.2074828594702565

Epoch: 6| Step: 3
Training loss: 3.7370414631222286
Validation loss: 4.202751568509915

Epoch: 6| Step: 4
Training loss: 4.313922592154792
Validation loss: 4.197615036015729

Epoch: 6| Step: 5
Training loss: 4.141638980724331
Validation loss: 4.1941631881079955

Epoch: 6| Step: 6
Training loss: 4.148580947378648
Validation loss: 4.188737923515455

Epoch: 6| Step: 7
Training loss: 4.308722569328798
Validation loss: 4.1841620051308555

Epoch: 6| Step: 8
Training loss: 3.9357627790498375
Validation loss: 4.17906453371361

Epoch: 6| Step: 9
Training loss: 4.452795826306924
Validation loss: 4.173992976644737

Epoch: 6| Step: 10
Training loss: 4.391072640728826
Validation loss: 4.1692372721223325

Epoch: 6| Step: 11
Training loss: 4.066497713758839
Validation loss: 4.164189435158538

Epoch: 6| Step: 12
Training loss: 5.005866042901821
Validation loss: 4.159609896941134

Epoch: 6| Step: 13
Training loss: 4.1846071186027185
Validation loss: 4.1548682571500715

Epoch: 28| Step: 0
Training loss: 4.915794855615926
Validation loss: 4.150371189445915

Epoch: 6| Step: 1
Training loss: 4.785915118397715
Validation loss: 4.145605026680861

Epoch: 6| Step: 2
Training loss: 3.9694859580759703
Validation loss: 4.140446017253646

Epoch: 6| Step: 3
Training loss: 3.185654049584294
Validation loss: 4.135642147242926

Epoch: 6| Step: 4
Training loss: 3.3327584406693114
Validation loss: 4.130434117473546

Epoch: 6| Step: 5
Training loss: 4.8751001592275
Validation loss: 4.1257688403085915

Epoch: 6| Step: 6
Training loss: 4.647439288501531
Validation loss: 4.122056720189773

Epoch: 6| Step: 7
Training loss: 3.3423672963450257
Validation loss: 4.116165545821538

Epoch: 6| Step: 8
Training loss: 4.988507987823621
Validation loss: 4.1120095552848

Epoch: 6| Step: 9
Training loss: 4.051123079538118
Validation loss: 4.1069814192199345

Epoch: 6| Step: 10
Training loss: 3.6582164204076335
Validation loss: 4.10264448154399

Epoch: 6| Step: 11
Training loss: 4.009696175725894
Validation loss: 4.097596998728803

Epoch: 6| Step: 12
Training loss: 4.216650772567366
Validation loss: 4.0927770298006285

Epoch: 6| Step: 13
Training loss: 4.895787448532762
Validation loss: 4.088483183942631

Epoch: 29| Step: 0
Training loss: 4.838637675088025
Validation loss: 4.083748420066594

Epoch: 6| Step: 1
Training loss: 4.527554814024247
Validation loss: 4.078430787920011

Epoch: 6| Step: 2
Training loss: 3.271754886204098
Validation loss: 4.073761750702065

Epoch: 6| Step: 3
Training loss: 4.327732770754058
Validation loss: 4.069561030454123

Epoch: 6| Step: 4
Training loss: 4.633777845909765
Validation loss: 4.064685742163345

Epoch: 6| Step: 5
Training loss: 3.2989281503115477
Validation loss: 4.059525325067964

Epoch: 6| Step: 6
Training loss: 3.9887275408737444
Validation loss: 4.055524236232995

Epoch: 6| Step: 7
Training loss: 5.31853833074332
Validation loss: 4.050235644105965

Epoch: 6| Step: 8
Training loss: 3.4231413148578627
Validation loss: 4.045882232140036

Epoch: 6| Step: 9
Training loss: 4.270309837946252
Validation loss: 4.040757237527719

Epoch: 6| Step: 10
Training loss: 4.031915654072234
Validation loss: 4.0359927723154785

Epoch: 6| Step: 11
Training loss: 3.974647525538649
Validation loss: 4.03107272603598

Epoch: 6| Step: 12
Training loss: 4.017117827681869
Validation loss: 4.026759561915555

Epoch: 6| Step: 13
Training loss: 4.167181568120075
Validation loss: 4.0224867601731935

Epoch: 30| Step: 0
Training loss: 3.6171403062019833
Validation loss: 4.0173511283367285

Epoch: 6| Step: 1
Training loss: 3.798390027357217
Validation loss: 4.01280433950433

Epoch: 6| Step: 2
Training loss: 3.5389464908811243
Validation loss: 4.00843709995094

Epoch: 6| Step: 3
Training loss: 4.573296510160765
Validation loss: 4.003888703594683

Epoch: 6| Step: 4
Training loss: 3.615002493323262
Validation loss: 3.999166481276138

Epoch: 6| Step: 5
Training loss: 4.0806205976885765
Validation loss: 3.994791991603926

Epoch: 6| Step: 6
Training loss: 3.7279526139059653
Validation loss: 3.990425153849873

Epoch: 6| Step: 7
Training loss: 4.318903936576838
Validation loss: 3.9859041957044568

Epoch: 6| Step: 8
Training loss: 4.672914727400935
Validation loss: 3.981418045944877

Epoch: 6| Step: 9
Training loss: 4.675243783398263
Validation loss: 3.9773518216744255

Epoch: 6| Step: 10
Training loss: 3.9841553870619046
Validation loss: 3.972220477894457

Epoch: 6| Step: 11
Training loss: 3.9281252719147677
Validation loss: 3.967638415762717

Epoch: 6| Step: 12
Training loss: 4.5779171007882455
Validation loss: 3.962947017192615

Epoch: 6| Step: 13
Training loss: 4.302524694873929
Validation loss: 3.9580296985552272

Epoch: 31| Step: 0
Training loss: 4.8018445047276375
Validation loss: 3.9536026978889933

Epoch: 6| Step: 1
Training loss: 3.644245753906858
Validation loss: 3.9487175577845015

Epoch: 6| Step: 2
Training loss: 4.121356395288728
Validation loss: 3.9438982049548055

Epoch: 6| Step: 3
Training loss: 2.7247338051224115
Validation loss: 3.939833660971367

Epoch: 6| Step: 4
Training loss: 4.4396591306553175
Validation loss: 3.9375260165530728

Epoch: 6| Step: 5
Training loss: 4.784766605628421
Validation loss: 3.9313728050534773

Epoch: 6| Step: 6
Training loss: 3.583401849372592
Validation loss: 3.925418666208369

Epoch: 6| Step: 7
Training loss: 3.9237569116080064
Validation loss: 3.920148147618627

Epoch: 6| Step: 8
Training loss: 4.04799138875656
Validation loss: 3.9153581760236933

Epoch: 6| Step: 9
Training loss: 3.407608321351021
Validation loss: 3.91098413077646

Epoch: 6| Step: 10
Training loss: 4.1513271002313505
Validation loss: 3.906420915043422

Epoch: 6| Step: 11
Training loss: 3.8248366576579023
Validation loss: 3.902472294398119

Epoch: 6| Step: 12
Training loss: 4.335483726607304
Validation loss: 3.8977946004235084

Epoch: 6| Step: 13
Training loss: 4.494516634639673
Validation loss: 3.892985964252246

Epoch: 32| Step: 0
Training loss: 4.275096843135659
Validation loss: 3.8881390658587494

Epoch: 6| Step: 1
Training loss: 4.359975247094121
Validation loss: 3.8836020901936465

Epoch: 6| Step: 2
Training loss: 4.454674595038415
Validation loss: 3.878408245734198

Epoch: 6| Step: 3
Training loss: 4.075498941218492
Validation loss: 3.873613006772486

Epoch: 6| Step: 4
Training loss: 3.99454746552669
Validation loss: 3.8689558410937774

Epoch: 6| Step: 5
Training loss: 4.12859580786574
Validation loss: 3.86435899657456

Epoch: 6| Step: 6
Training loss: 3.208876047842528
Validation loss: 3.8597939864872806

Epoch: 6| Step: 7
Training loss: 3.4373825053162186
Validation loss: 3.855105510839489

Epoch: 6| Step: 8
Training loss: 4.468318891737889
Validation loss: 3.8505000569970553

Epoch: 6| Step: 9
Training loss: 2.826444010362381
Validation loss: 3.846028859357361

Epoch: 6| Step: 10
Training loss: 3.734644157892956
Validation loss: 3.8412953837964303

Epoch: 6| Step: 11
Training loss: 4.485529628003941
Validation loss: 3.8368018394363994

Epoch: 6| Step: 12
Training loss: 2.9248743013940066
Validation loss: 3.8322649102582997

Epoch: 6| Step: 13
Training loss: 4.888796723585571
Validation loss: 3.827712222311373

Epoch: 33| Step: 0
Training loss: 3.245133791664939
Validation loss: 3.8231705348290457

Epoch: 6| Step: 1
Training loss: 3.705641265848883
Validation loss: 3.8189052494038864

Epoch: 6| Step: 2
Training loss: 4.510727282159017
Validation loss: 3.814470334395916

Epoch: 6| Step: 3
Training loss: 2.904543467906447
Validation loss: 3.8104337293862645

Epoch: 6| Step: 4
Training loss: 3.303038417868765
Validation loss: 3.8057359194805493

Epoch: 6| Step: 5
Training loss: 4.264076482820491
Validation loss: 3.8012676391727522

Epoch: 6| Step: 6
Training loss: 3.9769904425383653
Validation loss: 3.797268149870144

Epoch: 6| Step: 7
Training loss: 4.127413419373425
Validation loss: 3.792752438842051

Epoch: 6| Step: 8
Training loss: 4.188198657609912
Validation loss: 3.7882047436080093

Epoch: 6| Step: 9
Training loss: 4.527379559958679
Validation loss: 3.783859235423667

Epoch: 6| Step: 10
Training loss: 4.759540613590453
Validation loss: 3.7795085417281777

Epoch: 6| Step: 11
Training loss: 3.25063904568352
Validation loss: 3.7745114858801823

Epoch: 6| Step: 12
Training loss: 4.040635649275409
Validation loss: 3.7698337466500282

Epoch: 6| Step: 13
Training loss: 3.6916687241341144
Validation loss: 3.7656355101885874

Epoch: 34| Step: 0
Training loss: 3.71621874403809
Validation loss: 3.7609427903860166

Epoch: 6| Step: 1
Training loss: 3.417983258897777
Validation loss: 3.7564012570005048

Epoch: 6| Step: 2
Training loss: 3.7020925378264615
Validation loss: 3.752279034131349

Epoch: 6| Step: 3
Training loss: 3.4363448542952733
Validation loss: 3.7475805318813626

Epoch: 6| Step: 4
Training loss: 3.655530157712798
Validation loss: 3.743280536509138

Epoch: 6| Step: 5
Training loss: 3.521828294527263
Validation loss: 3.7393303079817866

Epoch: 6| Step: 6
Training loss: 4.248987862734609
Validation loss: 3.73512754213181

Epoch: 6| Step: 7
Training loss: 3.650878351162272
Validation loss: 3.7308837659771625

Epoch: 6| Step: 8
Training loss: 3.5293175465031728
Validation loss: 3.726228732364349

Epoch: 6| Step: 9
Training loss: 3.955900763212934
Validation loss: 3.7219802119846026

Epoch: 6| Step: 10
Training loss: 4.651816901187936
Validation loss: 3.7175145167204366

Epoch: 6| Step: 11
Training loss: 4.113802884925989
Validation loss: 3.713128914528417

Epoch: 6| Step: 12
Training loss: 3.986875220832633
Validation loss: 3.708500004712525

Epoch: 6| Step: 13
Training loss: 4.323208547030005
Validation loss: 3.7040634146604248

Epoch: 35| Step: 0
Training loss: 3.1305620667477214
Validation loss: 3.6996373144875125

Epoch: 6| Step: 1
Training loss: 3.485133067235438
Validation loss: 3.6951336054549193

Epoch: 6| Step: 2
Training loss: 3.931008937704231
Validation loss: 3.6908054192501556

Epoch: 6| Step: 3
Training loss: 4.063101386526955
Validation loss: 3.6867304931160434

Epoch: 6| Step: 4
Training loss: 4.865958020249865
Validation loss: 3.68225396913533

Epoch: 6| Step: 5
Training loss: 3.9246320418375986
Validation loss: 3.677397061689492

Epoch: 6| Step: 6
Training loss: 4.247728526146173
Validation loss: 3.67264835519381

Epoch: 6| Step: 7
Training loss: 3.655776294767339
Validation loss: 3.6678518995062808

Epoch: 6| Step: 8
Training loss: 3.9232123173210733
Validation loss: 3.663039617093887

Epoch: 6| Step: 9
Training loss: 3.396784097390452
Validation loss: 3.658415867447256

Epoch: 6| Step: 10
Training loss: 3.4544359023231674
Validation loss: 3.65417156211905

Epoch: 6| Step: 11
Training loss: 3.4813586123934344
Validation loss: 3.6496328700516294

Epoch: 6| Step: 12
Training loss: 2.711199481189191
Validation loss: 3.6455615060379136

Epoch: 6| Step: 13
Training loss: 4.504866194182712
Validation loss: 3.641377732768775

Epoch: 36| Step: 0
Training loss: 3.9263092141481906
Validation loss: 3.6372648567324366

Epoch: 6| Step: 1
Training loss: 2.927034117442161
Validation loss: 3.6327165269650807

Epoch: 6| Step: 2
Training loss: 4.573277533795981
Validation loss: 3.62842093659113

Epoch: 6| Step: 3
Training loss: 4.257628158638497
Validation loss: 3.624166634013536

Epoch: 6| Step: 4
Training loss: 4.218399146290198
Validation loss: 3.619552860570132

Epoch: 6| Step: 5
Training loss: 3.4234005388487114
Validation loss: 3.6147060904787867

Epoch: 6| Step: 6
Training loss: 3.3345612807289244
Validation loss: 3.6102954742171947

Epoch: 6| Step: 7
Training loss: 2.8006572190491394
Validation loss: 3.606323647807613

Epoch: 6| Step: 8
Training loss: 3.468411540796883
Validation loss: 3.602184581197782

Epoch: 6| Step: 9
Training loss: 3.809936036501648
Validation loss: 3.5980924161754593

Epoch: 6| Step: 10
Training loss: 3.7477092103792584
Validation loss: 3.5938825942194508

Epoch: 6| Step: 11
Training loss: 3.853288925161398
Validation loss: 3.5901504402198308

Epoch: 6| Step: 12
Training loss: 4.424108796973797
Validation loss: 3.585622270811471

Epoch: 6| Step: 13
Training loss: 3.17143750109698
Validation loss: 3.5812253222189465

Epoch: 37| Step: 0
Training loss: 3.7429901727562163
Validation loss: 3.577458504205796

Epoch: 6| Step: 1
Training loss: 4.164948961327601
Validation loss: 3.57303424934594

Epoch: 6| Step: 2
Training loss: 4.0322718545001095
Validation loss: 3.5687117713176746

Epoch: 6| Step: 3
Training loss: 3.7543863709939442
Validation loss: 3.5650855826243433

Epoch: 6| Step: 4
Training loss: 3.0873749680627407
Validation loss: 3.5595068822580647

Epoch: 6| Step: 5
Training loss: 3.876648213962275
Validation loss: 3.5572312639878727

Epoch: 6| Step: 6
Training loss: 2.649450057924481
Validation loss: 3.5529987054420387

Epoch: 6| Step: 7
Training loss: 3.934587400488768
Validation loss: 3.550405865065498

Epoch: 6| Step: 8
Training loss: 4.045379008677993
Validation loss: 3.5439233135382584

Epoch: 6| Step: 9
Training loss: 3.0103812210125804
Validation loss: 3.539227457251225

Epoch: 6| Step: 10
Training loss: 3.7864866959647783
Validation loss: 3.535113918549787

Epoch: 6| Step: 11
Training loss: 4.391876802478017
Validation loss: 3.53092221339449

Epoch: 6| Step: 12
Training loss: 3.462841879151412
Validation loss: 3.5267087379595017

Epoch: 6| Step: 13
Training loss: 3.259838325142352
Validation loss: 3.5222075374456265

Epoch: 38| Step: 0
Training loss: 4.186627652984718
Validation loss: 3.5177917698002013

Epoch: 6| Step: 1
Training loss: 3.865281993848285
Validation loss: 3.513525735905881

Epoch: 6| Step: 2
Training loss: 3.371889447030131
Validation loss: 3.5091728399061335

Epoch: 6| Step: 3
Training loss: 4.120849602142918
Validation loss: 3.5045446454346223

Epoch: 6| Step: 4
Training loss: 2.9485198752859128
Validation loss: 3.4999407581583553

Epoch: 6| Step: 5
Training loss: 3.51455889325707
Validation loss: 3.4954133748058593

Epoch: 6| Step: 6
Training loss: 3.3674537217118656
Validation loss: 3.4918258673185534

Epoch: 6| Step: 7
Training loss: 3.8426781377160077
Validation loss: 3.4882771490912345

Epoch: 6| Step: 8
Training loss: 3.1770404416717106
Validation loss: 3.4840292994321613

Epoch: 6| Step: 9
Training loss: 4.617445472184662
Validation loss: 3.4800802771126

Epoch: 6| Step: 10
Training loss: 4.000553331250161
Validation loss: 3.4754530375803663

Epoch: 6| Step: 11
Training loss: 2.871155199703794
Validation loss: 3.4710662256867164

Epoch: 6| Step: 12
Training loss: 3.378290197407255
Validation loss: 3.4669015673379406

Epoch: 6| Step: 13
Training loss: 3.057270333748019
Validation loss: 3.4631688349933487

Epoch: 39| Step: 0
Training loss: 4.198882163109336
Validation loss: 3.4593216659629484

Epoch: 6| Step: 1
Training loss: 3.436022076643519
Validation loss: 3.455199549129722

Epoch: 6| Step: 2
Training loss: 3.6595532746057593
Validation loss: 3.451593672273578

Epoch: 6| Step: 3
Training loss: 3.1831602585429755
Validation loss: 3.4464819113638883

Epoch: 6| Step: 4
Training loss: 2.737251381928348
Validation loss: 3.4417669920503835

Epoch: 6| Step: 5
Training loss: 4.021649661565041
Validation loss: 3.438316063392994

Epoch: 6| Step: 6
Training loss: 3.0956556827989306
Validation loss: 3.4338337391614537

Epoch: 6| Step: 7
Training loss: 3.562975935348026
Validation loss: 3.4302645974748613

Epoch: 6| Step: 8
Training loss: 2.930552606646444
Validation loss: 3.426299464469354

Epoch: 6| Step: 9
Training loss: 4.0334622722434545
Validation loss: 3.4234039978217354

Epoch: 6| Step: 10
Training loss: 3.933189575887255
Validation loss: 3.4192430195351444

Epoch: 6| Step: 11
Training loss: 3.705939659776162
Validation loss: 3.414709732543256

Epoch: 6| Step: 12
Training loss: 3.373437307763282
Validation loss: 3.4105897841249977

Epoch: 6| Step: 13
Training loss: 3.7760956999321915
Validation loss: 3.407321353146664

Epoch: 40| Step: 0
Training loss: 3.2186981493282745
Validation loss: 3.4027358893759425

Epoch: 6| Step: 1
Training loss: 2.979603092976446
Validation loss: 3.3986657778485725

Epoch: 6| Step: 2
Training loss: 3.9926174701184824
Validation loss: 3.3952961050130153

Epoch: 6| Step: 3
Training loss: 3.3942154538808054
Validation loss: 3.3910237911345606

Epoch: 6| Step: 4
Training loss: 3.5356823945912286
Validation loss: 3.3877966550314507

Epoch: 6| Step: 5
Training loss: 3.5021682562545715
Validation loss: 3.383437383082187

Epoch: 6| Step: 6
Training loss: 3.6747845748768633
Validation loss: 3.380149891744386

Epoch: 6| Step: 7
Training loss: 3.4830653718765636
Validation loss: 3.376079174862489

Epoch: 6| Step: 8
Training loss: 3.7308849162498676
Validation loss: 3.372401874001689

Epoch: 6| Step: 9
Training loss: 4.008484901105725
Validation loss: 3.369120150149138

Epoch: 6| Step: 10
Training loss: 3.399163390059286
Validation loss: 3.3658408933704007

Epoch: 6| Step: 11
Training loss: 3.4634824054591076
Validation loss: 3.363746956406049

Epoch: 6| Step: 12
Training loss: 3.7575026164296395
Validation loss: 3.359802964030412

Epoch: 6| Step: 13
Training loss: 2.8934385061998737
Validation loss: 3.3561058046608796

Epoch: 41| Step: 0
Training loss: 3.6122026472898625
Validation loss: 3.3483484443550164

Epoch: 6| Step: 1
Training loss: 3.0416829008601085
Validation loss: 3.3449681520110075

Epoch: 6| Step: 2
Training loss: 3.4786688777828343
Validation loss: 3.341282561020202

Epoch: 6| Step: 3
Training loss: 2.5656965833521133
Validation loss: 3.339059980906499

Epoch: 6| Step: 4
Training loss: 3.5075461917372395
Validation loss: 3.336418694864023

Epoch: 6| Step: 5
Training loss: 3.4850148524401607
Validation loss: 3.333380404775776

Epoch: 6| Step: 6
Training loss: 3.707084631259161
Validation loss: 3.3304134256025875

Epoch: 6| Step: 7
Training loss: 3.4912221372197982
Validation loss: 3.3268389179519273

Epoch: 6| Step: 8
Training loss: 3.0294448354017254
Validation loss: 3.3240741200704362

Epoch: 6| Step: 9
Training loss: 3.655897465851956
Validation loss: 3.32025724477231

Epoch: 6| Step: 10
Training loss: 3.3823747946382006
Validation loss: 3.3152890010267857

Epoch: 6| Step: 11
Training loss: 3.660493263191534
Validation loss: 3.3109356287155394

Epoch: 6| Step: 12
Training loss: 3.967598575360188
Validation loss: 3.306806073121426

Epoch: 6| Step: 13
Training loss: 3.697051270281868
Validation loss: 3.302896000512862

Epoch: 42| Step: 0
Training loss: 3.8044694215285397
Validation loss: 3.298468880961139

Epoch: 6| Step: 1
Training loss: 3.2319096554130273
Validation loss: 3.29469417621156

Epoch: 6| Step: 2
Training loss: 4.0290885867759085
Validation loss: 3.291426170995697

Epoch: 6| Step: 3
Training loss: 2.9440667631934123
Validation loss: 3.286113150595896

Epoch: 6| Step: 4
Training loss: 3.1747252337893106
Validation loss: 3.2836561554218484

Epoch: 6| Step: 5
Training loss: 3.0862332359282005
Validation loss: 3.280094294394418

Epoch: 6| Step: 6
Training loss: 2.9753453927735563
Validation loss: 3.2760030908946516

Epoch: 6| Step: 7
Training loss: 3.7905378792383053
Validation loss: 3.2720822462666823

Epoch: 6| Step: 8
Training loss: 3.288557362672558
Validation loss: 3.2691020311637717

Epoch: 6| Step: 9
Training loss: 3.4251693126846505
Validation loss: 3.265707729818776

Epoch: 6| Step: 10
Training loss: 3.6100624387630167
Validation loss: 3.2614471139697603

Epoch: 6| Step: 11
Training loss: 4.144285951594555
Validation loss: 3.2581259304552415

Epoch: 6| Step: 12
Training loss: 3.155141503596129
Validation loss: 3.2541965387188685

Epoch: 6| Step: 13
Training loss: 2.810919762768003
Validation loss: 3.2506885166046704

Epoch: 43| Step: 0
Training loss: 3.4645650551581997
Validation loss: 3.246591296512416

Epoch: 6| Step: 1
Training loss: 3.87318500959227
Validation loss: 3.24378544292552

Epoch: 6| Step: 2
Training loss: 3.271702126615113
Validation loss: 3.240514288261535

Epoch: 6| Step: 3
Training loss: 3.8014545216808413
Validation loss: 3.237301545215921

Epoch: 6| Step: 4
Training loss: 3.5478819371463306
Validation loss: 3.233821004454941

Epoch: 6| Step: 5
Training loss: 2.6235013044094875
Validation loss: 3.230207427286224

Epoch: 6| Step: 6
Training loss: 3.1323217449936647
Validation loss: 3.227089605618795

Epoch: 6| Step: 7
Training loss: 3.129797647778533
Validation loss: 3.2243897370757537

Epoch: 6| Step: 8
Training loss: 4.3119909013641555
Validation loss: 3.2206737361975923

Epoch: 6| Step: 9
Training loss: 3.479174372194327
Validation loss: 3.2168863821016678

Epoch: 6| Step: 10
Training loss: 3.3894440312630114
Validation loss: 3.2132267645685313

Epoch: 6| Step: 11
Training loss: 3.648251122364119
Validation loss: 3.2098814255511092

Epoch: 6| Step: 12
Training loss: 2.0523250327765172
Validation loss: 3.20589430275488

Epoch: 6| Step: 13
Training loss: 2.786012151534177
Validation loss: 3.2017238871041545

Epoch: 44| Step: 0
Training loss: 4.293115365160156
Validation loss: 3.1987381707296096

Epoch: 6| Step: 1
Training loss: 2.9824132413308235
Validation loss: 3.1954130298373116

Epoch: 6| Step: 2
Training loss: 4.024469395131924
Validation loss: 3.1928108949767053

Epoch: 6| Step: 3
Training loss: 3.30596624934328
Validation loss: 3.1874451726050186

Epoch: 6| Step: 4
Training loss: 3.7241156840482046
Validation loss: 3.185146085941084

Epoch: 6| Step: 5
Training loss: 3.5412269020067866
Validation loss: 3.181955626747585

Epoch: 6| Step: 6
Training loss: 3.310114163276817
Validation loss: 3.1772579749630574

Epoch: 6| Step: 7
Training loss: 3.3390404164535
Validation loss: 3.1735252885369354

Epoch: 6| Step: 8
Training loss: 2.6962519238659217
Validation loss: 3.170588290303248

Epoch: 6| Step: 9
Training loss: 2.850606679759238
Validation loss: 3.1676638104062182

Epoch: 6| Step: 10
Training loss: 2.9495298107895653
Validation loss: 3.1645521750474286

Epoch: 6| Step: 11
Training loss: 3.518803901327281
Validation loss: 3.1612354977215875

Epoch: 6| Step: 12
Training loss: 2.5503942596227356
Validation loss: 3.158329697122888

Epoch: 6| Step: 13
Training loss: 2.9051550986928283
Validation loss: 3.1556665617785407

Epoch: 45| Step: 0
Training loss: 3.350688971656103
Validation loss: 3.152474641347523

Epoch: 6| Step: 1
Training loss: 2.881542060265747
Validation loss: 3.1491768775754885

Epoch: 6| Step: 2
Training loss: 2.8639193418429283
Validation loss: 3.1469154307329292

Epoch: 6| Step: 3
Training loss: 3.0487635310562116
Validation loss: 3.143409923970135

Epoch: 6| Step: 4
Training loss: 3.382151197675525
Validation loss: 3.14063233838086

Epoch: 6| Step: 5
Training loss: 3.275149969496492
Validation loss: 3.138135616160694

Epoch: 6| Step: 6
Training loss: 3.232381160053249
Validation loss: 3.135892424285612

Epoch: 6| Step: 7
Training loss: 3.696289191504291
Validation loss: 3.1326130512577386

Epoch: 6| Step: 8
Training loss: 3.438422894133496
Validation loss: 3.1295993019915183

Epoch: 6| Step: 9
Training loss: 3.208469008182071
Validation loss: 3.1272619072341845

Epoch: 6| Step: 10
Training loss: 3.851927826986633
Validation loss: 3.1245069496296036

Epoch: 6| Step: 11
Training loss: 3.03254058735253
Validation loss: 3.121808571374447

Epoch: 6| Step: 12
Training loss: 3.4901805461538773
Validation loss: 3.118978280763466

Epoch: 6| Step: 13
Training loss: 2.952127762601272
Validation loss: 3.1163848761463666

Epoch: 46| Step: 0
Training loss: 3.3790648671223673
Validation loss: 3.113053234115323

Epoch: 6| Step: 1
Training loss: 3.277788934491095
Validation loss: 3.1103242993719467

Epoch: 6| Step: 2
Training loss: 3.4079806629581513
Validation loss: 3.1068887019387645

Epoch: 6| Step: 3
Training loss: 2.4982729668563137
Validation loss: 3.10342835387051

Epoch: 6| Step: 4
Training loss: 3.6208110151638317
Validation loss: 3.1001296877651967

Epoch: 6| Step: 5
Training loss: 3.461920811655974
Validation loss: 3.0977122176294776

Epoch: 6| Step: 6
Training loss: 3.5326006171602993
Validation loss: 3.094521307566124

Epoch: 6| Step: 7
Training loss: 2.709451581495237
Validation loss: 3.0909853312155517

Epoch: 6| Step: 8
Training loss: 3.6616119453833744
Validation loss: 3.088150891718731

Epoch: 6| Step: 9
Training loss: 3.453404479993823
Validation loss: 3.0849674808842975

Epoch: 6| Step: 10
Training loss: 3.9430848735098447
Validation loss: 3.0821830734679594

Epoch: 6| Step: 11
Training loss: 2.680366719193314
Validation loss: 3.0792491170523633

Epoch: 6| Step: 12
Training loss: 2.714057292504989
Validation loss: 3.07679890372901

Epoch: 6| Step: 13
Training loss: 2.4738332830580405
Validation loss: 3.0731726243484268

Epoch: 47| Step: 0
Training loss: 3.299457424526743
Validation loss: 3.0699917251193742

Epoch: 6| Step: 1
Training loss: 3.533276271959109
Validation loss: 3.068925901966727

Epoch: 6| Step: 2
Training loss: 3.512033756033052
Validation loss: 3.064271635018328

Epoch: 6| Step: 3
Training loss: 2.658516220051902
Validation loss: 3.0630816082545884

Epoch: 6| Step: 4
Training loss: 3.397173065331737
Validation loss: 3.0607078394689737

Epoch: 6| Step: 5
Training loss: 3.545405953303269
Validation loss: 3.0562162354521294

Epoch: 6| Step: 6
Training loss: 3.3379700519002284
Validation loss: 3.0556135278076657

Epoch: 6| Step: 7
Training loss: 3.0428010749896233
Validation loss: 3.0510613788676886

Epoch: 6| Step: 8
Training loss: 3.0975472622299156
Validation loss: 3.048638092902564

Epoch: 6| Step: 9
Training loss: 3.3172602009005137
Validation loss: 3.0454869686990467

Epoch: 6| Step: 10
Training loss: 2.4150653225295917
Validation loss: 3.044656947145539

Epoch: 6| Step: 11
Training loss: 3.306787134970417
Validation loss: 3.040820792344726

Epoch: 6| Step: 12
Training loss: 3.0474502411708233
Validation loss: 3.036572427498185

Epoch: 6| Step: 13
Training loss: 2.9828145206498524
Validation loss: 3.0327552518792054

Epoch: 48| Step: 0
Training loss: 3.5334554891043193
Validation loss: 3.0312573672070724

Epoch: 6| Step: 1
Training loss: 3.1108643305252914
Validation loss: 3.027636914568577

Epoch: 6| Step: 2
Training loss: 3.538140789536509
Validation loss: 3.0254443438665444

Epoch: 6| Step: 3
Training loss: 3.162939253748069
Validation loss: 3.0227001253718124

Epoch: 6| Step: 4
Training loss: 3.039372367065469
Validation loss: 3.020124146097135

Epoch: 6| Step: 5
Training loss: 2.452259080974057
Validation loss: 3.0176089782125177

Epoch: 6| Step: 6
Training loss: 2.7831558384140904
Validation loss: 3.015279206526918

Epoch: 6| Step: 7
Training loss: 3.6946589918310417
Validation loss: 3.01254759786525

Epoch: 6| Step: 8
Training loss: 3.2136665868153433
Validation loss: 3.010695623829028

Epoch: 6| Step: 9
Training loss: 3.0066851199895543
Validation loss: 3.0067167457743444

Epoch: 6| Step: 10
Training loss: 3.2717729583538686
Validation loss: 3.004192151840263

Epoch: 6| Step: 11
Training loss: 3.2161377611972757
Validation loss: 3.001029129469977

Epoch: 6| Step: 12
Training loss: 3.0083137391809265
Validation loss: 2.9994341793529578

Epoch: 6| Step: 13
Training loss: 2.935411075742842
Validation loss: 2.9994599333063294

Epoch: 49| Step: 0
Training loss: 3.527956076160442
Validation loss: 3.0170397824555906

Epoch: 6| Step: 1
Training loss: 3.115944215267843
Validation loss: 3.016903212706275

Epoch: 6| Step: 2
Training loss: 3.8764126571484847
Validation loss: 2.9974916356097028

Epoch: 6| Step: 3
Training loss: 3.2680678288530634
Validation loss: 2.9886405512735035

Epoch: 6| Step: 4
Training loss: 3.352021157063652
Validation loss: 2.984179958074933

Epoch: 6| Step: 5
Training loss: 3.325861201222529
Validation loss: 2.9830176443937306

Epoch: 6| Step: 6
Training loss: 3.435719254220758
Validation loss: 2.9808706909972686

Epoch: 6| Step: 7
Training loss: 2.496958885645742
Validation loss: 2.9843318330262556

Epoch: 6| Step: 8
Training loss: 2.7195356264328474
Validation loss: 2.9850752376827403

Epoch: 6| Step: 9
Training loss: 2.546874344714496
Validation loss: 2.986573639368902

Epoch: 6| Step: 10
Training loss: 2.9813870956279813
Validation loss: 2.9820978421244764

Epoch: 6| Step: 11
Training loss: 3.0085720936152534
Validation loss: 2.976956011908366

Epoch: 6| Step: 12
Training loss: 2.8169603371500744
Validation loss: 2.9741880302556183

Epoch: 6| Step: 13
Training loss: 2.9460470968238273
Validation loss: 2.9644948614183932

Epoch: 50| Step: 0
Training loss: 3.2262719418394035
Validation loss: 2.9612477189529325

Epoch: 6| Step: 1
Training loss: 3.2283868319743276
Validation loss: 2.9586992350925057

Epoch: 6| Step: 2
Training loss: 3.13062390675281
Validation loss: 2.956925545217897

Epoch: 6| Step: 3
Training loss: 3.0197472735630386
Validation loss: 2.9558563518748167

Epoch: 6| Step: 4
Training loss: 3.3980069994930138
Validation loss: 2.952836683620186

Epoch: 6| Step: 5
Training loss: 2.70241771110436
Validation loss: 2.9508406804390206

Epoch: 6| Step: 6
Training loss: 3.103962236538475
Validation loss: 2.9492948341239624

Epoch: 6| Step: 7
Training loss: 3.026618329164913
Validation loss: 2.9469915405400555

Epoch: 6| Step: 8
Training loss: 2.9746217182627195
Validation loss: 2.945387632725432

Epoch: 6| Step: 9
Training loss: 2.6632116306971123
Validation loss: 2.942744490589825

Epoch: 6| Step: 10
Training loss: 3.087584854998548
Validation loss: 2.939452084090174

Epoch: 6| Step: 11
Training loss: 3.2897067130016864
Validation loss: 2.9365569690937643

Epoch: 6| Step: 12
Training loss: 2.9015408993247194
Validation loss: 2.9329065160462333

Epoch: 6| Step: 13
Training loss: 3.3843443752040936
Validation loss: 2.930203486462402

Epoch: 51| Step: 0
Training loss: 2.699131479798503
Validation loss: 2.926983208261799

Epoch: 6| Step: 1
Training loss: 2.521402583727417
Validation loss: 2.925431641902246

Epoch: 6| Step: 2
Training loss: 3.0785649174060947
Validation loss: 2.923323015791441

Epoch: 6| Step: 3
Training loss: 3.634822035346118
Validation loss: 2.9208510401502408

Epoch: 6| Step: 4
Training loss: 3.0505530434414037
Validation loss: 2.9188447766705297

Epoch: 6| Step: 5
Training loss: 3.152077816094619
Validation loss: 2.9158812055630894

Epoch: 6| Step: 6
Training loss: 3.1530500752797566
Validation loss: 2.9138054619301124

Epoch: 6| Step: 7
Training loss: 2.8280584843859184
Validation loss: 2.9102535632630273

Epoch: 6| Step: 8
Training loss: 2.7398460368594764
Validation loss: 2.908312841377825

Epoch: 6| Step: 9
Training loss: 3.5205691688047924
Validation loss: 2.906365176964195

Epoch: 6| Step: 10
Training loss: 2.863283248421881
Validation loss: 2.9058953345681755

Epoch: 6| Step: 11
Training loss: 3.121172582898345
Validation loss: 2.9015459116685975

Epoch: 6| Step: 12
Training loss: 3.3230021275419666
Validation loss: 2.899813973829103

Epoch: 6| Step: 13
Training loss: 2.852366880073894
Validation loss: 2.8989491795075386

Epoch: 52| Step: 0
Training loss: 2.896357116167231
Validation loss: 2.8944814989187626

Epoch: 6| Step: 1
Training loss: 2.9784138046120967
Validation loss: 2.893596448456414

Epoch: 6| Step: 2
Training loss: 2.758121289480459
Validation loss: 2.8914770365566222

Epoch: 6| Step: 3
Training loss: 3.2082584091619704
Validation loss: 2.8892468440576717

Epoch: 6| Step: 4
Training loss: 3.1430854838267726
Validation loss: 2.8902269243952996

Epoch: 6| Step: 5
Training loss: 3.205055808594611
Validation loss: 2.8840580070004007

Epoch: 6| Step: 6
Training loss: 3.039835304517149
Validation loss: 2.882465372663351

Epoch: 6| Step: 7
Training loss: 3.1476453063729157
Validation loss: 2.879817878695658

Epoch: 6| Step: 8
Training loss: 3.0350550729194845
Validation loss: 2.878637307319326

Epoch: 6| Step: 9
Training loss: 2.698340266098846
Validation loss: 2.8751106517340794

Epoch: 6| Step: 10
Training loss: 3.027867740690591
Validation loss: 2.875538402398447

Epoch: 6| Step: 11
Training loss: 3.0510674219074385
Validation loss: 2.875492841522959

Epoch: 6| Step: 12
Training loss: 2.788071742247138
Validation loss: 2.8758740962221863

Epoch: 6| Step: 13
Training loss: 3.287101686664731
Validation loss: 2.870465988072854

Epoch: 53| Step: 0
Training loss: 3.200068806862181
Validation loss: 2.8688482728967792

Epoch: 6| Step: 1
Training loss: 3.0855483956628422
Validation loss: 2.8648994456337786

Epoch: 6| Step: 2
Training loss: 3.1216783799581194
Validation loss: 2.861295892145489

Epoch: 6| Step: 3
Training loss: 3.002242204078999
Validation loss: 2.859111169202143

Epoch: 6| Step: 4
Training loss: 3.1316392180772845
Validation loss: 2.8576830946411795

Epoch: 6| Step: 5
Training loss: 2.955260781078328
Validation loss: 2.8562843142617838

Epoch: 6| Step: 6
Training loss: 2.8008124058478936
Validation loss: 2.854410917500072

Epoch: 6| Step: 7
Training loss: 3.137690449439898
Validation loss: 2.8523467078603253

Epoch: 6| Step: 8
Training loss: 3.288251980836861
Validation loss: 2.850108600800434

Epoch: 6| Step: 9
Training loss: 2.9147619476740956
Validation loss: 2.8475526250989507

Epoch: 6| Step: 10
Training loss: 3.062778382396894
Validation loss: 2.846391952743148

Epoch: 6| Step: 11
Training loss: 2.5198220255235726
Validation loss: 2.844761371672401

Epoch: 6| Step: 12
Training loss: 2.511307891892362
Validation loss: 2.8417755930170316

Epoch: 6| Step: 13
Training loss: 3.0928628593600918
Validation loss: 2.8415757415484215

Epoch: 54| Step: 0
Training loss: 2.2788792663169364
Validation loss: 2.835304757142024

Epoch: 6| Step: 1
Training loss: 3.583981980159282
Validation loss: 2.840055532136386

Epoch: 6| Step: 2
Training loss: 2.9037236543955403
Validation loss: 2.8346554859568287

Epoch: 6| Step: 3
Training loss: 2.797060656645752
Validation loss: 2.8339825942815806

Epoch: 6| Step: 4
Training loss: 3.6055036648499046
Validation loss: 2.83035694659248

Epoch: 6| Step: 5
Training loss: 3.2609589017157514
Validation loss: 2.8276845402846527

Epoch: 6| Step: 6
Training loss: 3.3954394215412598
Validation loss: 2.826808573883982

Epoch: 6| Step: 7
Training loss: 2.768452551301646
Validation loss: 2.8259724105258535

Epoch: 6| Step: 8
Training loss: 2.3518821524400546
Validation loss: 2.8240341611611486

Epoch: 6| Step: 9
Training loss: 2.6652204843891836
Validation loss: 2.824748009439691

Epoch: 6| Step: 10
Training loss: 2.512191419488056
Validation loss: 2.8235627498968716

Epoch: 6| Step: 11
Training loss: 3.292673045645811
Validation loss: 2.8207255560280604

Epoch: 6| Step: 12
Training loss: 2.8641374460623434
Validation loss: 2.8179644023486987

Epoch: 6| Step: 13
Training loss: 2.8884902907345853
Validation loss: 2.816878435725127

Epoch: 55| Step: 0
Training loss: 2.323241879630339
Validation loss: 2.8149809738338316

Epoch: 6| Step: 1
Training loss: 2.8682104463499156
Validation loss: 2.8124499281205386

Epoch: 6| Step: 2
Training loss: 2.7292864727096653
Validation loss: 2.813537434576289

Epoch: 6| Step: 3
Training loss: 2.9251247020776874
Validation loss: 2.810898133914565

Epoch: 6| Step: 4
Training loss: 2.684158820972111
Validation loss: 2.8117101195919183

Epoch: 6| Step: 5
Training loss: 2.9234123877257714
Validation loss: 2.8243784386673756

Epoch: 6| Step: 6
Training loss: 3.055607415732124
Validation loss: 2.8235885599410326

Epoch: 6| Step: 7
Training loss: 3.260111704123688
Validation loss: 2.8185806945343908

Epoch: 6| Step: 8
Training loss: 3.1210482215663977
Validation loss: 2.800362002722707

Epoch: 6| Step: 9
Training loss: 3.67195863019789
Validation loss: 2.7977344890109177

Epoch: 6| Step: 10
Training loss: 2.6314615921154556
Validation loss: 2.802445432010908

Epoch: 6| Step: 11
Training loss: 2.848090412129942
Validation loss: 2.8055725826296487

Epoch: 6| Step: 12
Training loss: 2.9886499912915157
Validation loss: 2.8163565297528432

Epoch: 6| Step: 13
Training loss: 3.0189500572619923
Validation loss: 2.821202695058695

Epoch: 56| Step: 0
Training loss: 2.8830273555922536
Validation loss: 2.8163344347188577

Epoch: 6| Step: 1
Training loss: 3.3714267040275225
Validation loss: 2.8080750872072278

Epoch: 6| Step: 2
Training loss: 2.720943399240888
Validation loss: 2.8009562914287947

Epoch: 6| Step: 3
Training loss: 2.435808621974087
Validation loss: 2.7946542771264378

Epoch: 6| Step: 4
Training loss: 3.1630119180807554
Validation loss: 2.7922282911329916

Epoch: 6| Step: 5
Training loss: 2.4654714326211127
Validation loss: 2.787746799417325

Epoch: 6| Step: 6
Training loss: 3.337567755193565
Validation loss: 2.7853647290458867

Epoch: 6| Step: 7
Training loss: 3.1006972790048097
Validation loss: 2.7824712208107556

Epoch: 6| Step: 8
Training loss: 2.6026898481764555
Validation loss: 2.7788721127719502

Epoch: 6| Step: 9
Training loss: 3.255385118897435
Validation loss: 2.7769398527480633

Epoch: 6| Step: 10
Training loss: 2.584174070654182
Validation loss: 2.773700540453196

Epoch: 6| Step: 11
Training loss: 3.242133670957514
Validation loss: 2.7719610591518387

Epoch: 6| Step: 12
Training loss: 2.5503735997897716
Validation loss: 2.7704792131039877

Epoch: 6| Step: 13
Training loss: 2.8782265842995836
Validation loss: 2.7716947569334516

Epoch: 57| Step: 0
Training loss: 3.090082325749142
Validation loss: 2.79090754782672

Epoch: 6| Step: 1
Training loss: 2.4045458617458335
Validation loss: 2.7876366996603434

Epoch: 6| Step: 2
Training loss: 3.309346551385631
Validation loss: 2.7915924309116984

Epoch: 6| Step: 3
Training loss: 2.39973350078428
Validation loss: 2.771648650333514

Epoch: 6| Step: 4
Training loss: 3.090641193713895
Validation loss: 2.760003016926319

Epoch: 6| Step: 5
Training loss: 3.3042375695669484
Validation loss: 2.7589280535138534

Epoch: 6| Step: 6
Training loss: 2.879956658090192
Validation loss: 2.758756250957165

Epoch: 6| Step: 7
Training loss: 3.0400290239354013
Validation loss: 2.7550234284878834

Epoch: 6| Step: 8
Training loss: 3.0515957769482958
Validation loss: 2.754714912022839

Epoch: 6| Step: 9
Training loss: 2.5747447655855438
Validation loss: 2.753092183304685

Epoch: 6| Step: 10
Training loss: 2.3357125368524208
Validation loss: 2.75067745880744

Epoch: 6| Step: 11
Training loss: 3.4993228257260665
Validation loss: 2.7522809799187447

Epoch: 6| Step: 12
Training loss: 2.784069903405944
Validation loss: 2.7520083405420053

Epoch: 6| Step: 13
Training loss: 2.5127490171704405
Validation loss: 2.7510714755501007

Epoch: 58| Step: 0
Training loss: 3.1342264918005363
Validation loss: 2.7510795497247953

Epoch: 6| Step: 1
Training loss: 2.368912776296168
Validation loss: 2.7506318955817886

Epoch: 6| Step: 2
Training loss: 2.7876937456753987
Validation loss: 2.7484746228187453

Epoch: 6| Step: 3
Training loss: 2.1337241435705114
Validation loss: 2.745863635793683

Epoch: 6| Step: 4
Training loss: 2.484153497766164
Validation loss: 2.743268588736273

Epoch: 6| Step: 5
Training loss: 2.3994949445184357
Validation loss: 2.7418666699012446

Epoch: 6| Step: 6
Training loss: 3.2771039654534344
Validation loss: 2.740843658249977

Epoch: 6| Step: 7
Training loss: 2.7370245603407892
Validation loss: 2.7391151540670924

Epoch: 6| Step: 8
Training loss: 3.2693043109337854
Validation loss: 2.7367326363485205

Epoch: 6| Step: 9
Training loss: 3.46175772632721
Validation loss: 2.7355285826946685

Epoch: 6| Step: 10
Training loss: 2.449982981720031
Validation loss: 2.7324181230149813

Epoch: 6| Step: 11
Training loss: 3.334263258601686
Validation loss: 2.7295674085630504

Epoch: 6| Step: 12
Training loss: 3.0508734656157475
Validation loss: 2.729445659170362

Epoch: 6| Step: 13
Training loss: 3.003834499102447
Validation loss: 2.727500601120698

Epoch: 59| Step: 0
Training loss: 2.732109657320962
Validation loss: 2.7262903057595467

Epoch: 6| Step: 1
Training loss: 2.3605589264583045
Validation loss: 2.7287154710454535

Epoch: 6| Step: 2
Training loss: 2.921149995175106
Validation loss: 2.7265215764076047

Epoch: 6| Step: 3
Training loss: 2.7261117819511496
Validation loss: 2.7255155198210486

Epoch: 6| Step: 4
Training loss: 2.365436069699455
Validation loss: 2.7192621442949085

Epoch: 6| Step: 5
Training loss: 3.172898752149845
Validation loss: 2.7148001761107086

Epoch: 6| Step: 6
Training loss: 3.129494753390557
Validation loss: 2.719533310512897

Epoch: 6| Step: 7
Training loss: 2.3706227169332617
Validation loss: 2.73083212803463

Epoch: 6| Step: 8
Training loss: 3.3533725785776975
Validation loss: 2.7248662793308545

Epoch: 6| Step: 9
Training loss: 2.9997092741922997
Validation loss: 2.7250858305033305

Epoch: 6| Step: 10
Training loss: 2.5965919092440877
Validation loss: 2.7321231979650635

Epoch: 6| Step: 11
Training loss: 2.972968387131587
Validation loss: 2.722906494316202

Epoch: 6| Step: 12
Training loss: 3.0697757164357706
Validation loss: 2.7172024513492827

Epoch: 6| Step: 13
Training loss: 3.0394755967734546
Validation loss: 2.710149454427384

Epoch: 60| Step: 0
Training loss: 3.1188493854228736
Validation loss: 2.7073936054744587

Epoch: 6| Step: 1
Training loss: 3.1784296570537576
Validation loss: 2.7084414436085975

Epoch: 6| Step: 2
Training loss: 3.153619860104559
Validation loss: 2.7063559625215707

Epoch: 6| Step: 3
Training loss: 3.121799814046297
Validation loss: 2.707544143330989

Epoch: 6| Step: 4
Training loss: 2.5422978373136416
Validation loss: 2.7083046593737636

Epoch: 6| Step: 5
Training loss: 2.8029751026301244
Validation loss: 2.7101874142883204

Epoch: 6| Step: 6
Training loss: 2.998405032556111
Validation loss: 2.7106458670144478

Epoch: 6| Step: 7
Training loss: 2.4799878232410886
Validation loss: 2.7132095065280692

Epoch: 6| Step: 8
Training loss: 3.155432113582115
Validation loss: 2.714023134908365

Epoch: 6| Step: 9
Training loss: 1.8256315523348
Validation loss: 2.709283798894473

Epoch: 6| Step: 10
Training loss: 2.666952316561636
Validation loss: 2.711401761305418

Epoch: 6| Step: 11
Training loss: 2.883260387166771
Validation loss: 2.7076505436113365

Epoch: 6| Step: 12
Training loss: 2.5777927993833667
Validation loss: 2.7056836199973215

Epoch: 6| Step: 13
Training loss: 3.0275532311595916
Validation loss: 2.701079401257012

Epoch: 61| Step: 0
Training loss: 2.7876159164891727
Validation loss: 2.7001727231433423

Epoch: 6| Step: 1
Training loss: 2.702202082612601
Validation loss: 2.696708929283195

Epoch: 6| Step: 2
Training loss: 2.9845271046807764
Validation loss: 2.696128036294278

Epoch: 6| Step: 3
Training loss: 2.6880169748269833
Validation loss: 2.693944995074098

Epoch: 6| Step: 4
Training loss: 3.266957572388285
Validation loss: 2.693642936756224

Epoch: 6| Step: 5
Training loss: 2.639197601419719
Validation loss: 2.691959584441482

Epoch: 6| Step: 6
Training loss: 3.019102947065646
Validation loss: 2.6906854543713656

Epoch: 6| Step: 7
Training loss: 2.6007325277580393
Validation loss: 2.68849899886774

Epoch: 6| Step: 8
Training loss: 3.1873659591914607
Validation loss: 2.6870671596465256

Epoch: 6| Step: 9
Training loss: 2.777946653530856
Validation loss: 2.6848548173161078

Epoch: 6| Step: 10
Training loss: 3.131233711733303
Validation loss: 2.6837985697714535

Epoch: 6| Step: 11
Training loss: 2.66090684963814
Validation loss: 2.6812984714113357

Epoch: 6| Step: 12
Training loss: 2.4715124199501353
Validation loss: 2.6796518366065154

Epoch: 6| Step: 13
Training loss: 2.530396494197437
Validation loss: 2.6789585972067

Epoch: 62| Step: 0
Training loss: 2.733334937521611
Validation loss: 2.6763642578584075

Epoch: 6| Step: 1
Training loss: 2.8533186012256144
Validation loss: 2.6731153141298445

Epoch: 6| Step: 2
Training loss: 2.443990039012233
Validation loss: 2.672782312605762

Epoch: 6| Step: 3
Training loss: 2.467582813021162
Validation loss: 2.673442165326838

Epoch: 6| Step: 4
Training loss: 2.671429245557474
Validation loss: 2.6674699070289796

Epoch: 6| Step: 5
Training loss: 2.8970354910201683
Validation loss: 2.669793625164963

Epoch: 6| Step: 6
Training loss: 2.904726675178771
Validation loss: 2.6697790242070805

Epoch: 6| Step: 7
Training loss: 2.816453824851736
Validation loss: 2.666521401223661

Epoch: 6| Step: 8
Training loss: 3.071651875182077
Validation loss: 2.66672961836261

Epoch: 6| Step: 9
Training loss: 2.744026806191613
Validation loss: 2.662284906859701

Epoch: 6| Step: 10
Training loss: 3.0698850688482624
Validation loss: 2.661082878927547

Epoch: 6| Step: 11
Training loss: 2.9791524037551023
Validation loss: 2.6609986138993067

Epoch: 6| Step: 12
Training loss: 3.1155758470275674
Validation loss: 2.663078805158292

Epoch: 6| Step: 13
Training loss: 2.363643801283972
Validation loss: 2.657563367287309

Epoch: 63| Step: 0
Training loss: 2.8374367526227395
Validation loss: 2.652704872563098

Epoch: 6| Step: 1
Training loss: 2.723605500826671
Validation loss: 2.6596660190306904

Epoch: 6| Step: 2
Training loss: 2.6538602962563607
Validation loss: 2.652964740731197

Epoch: 6| Step: 3
Training loss: 2.8178953342588233
Validation loss: 2.660669830831113

Epoch: 6| Step: 4
Training loss: 2.621212361092355
Validation loss: 2.654886845885177

Epoch: 6| Step: 5
Training loss: 2.9064352325147764
Validation loss: 2.655334868520755

Epoch: 6| Step: 6
Training loss: 3.042738703796315
Validation loss: 2.6497316002627875

Epoch: 6| Step: 7
Training loss: 3.2111014442635666
Validation loss: 2.653150238288503

Epoch: 6| Step: 8
Training loss: 3.1183180515629134
Validation loss: 2.6489388020513314

Epoch: 6| Step: 9
Training loss: 2.6962165532626274
Validation loss: 2.6500049405081896

Epoch: 6| Step: 10
Training loss: 2.5941215157146083
Validation loss: 2.650390040285837

Epoch: 6| Step: 11
Training loss: 2.7005595121982706
Validation loss: 2.6480890605601397

Epoch: 6| Step: 12
Training loss: 2.6665489250256904
Validation loss: 2.6458907734400485

Epoch: 6| Step: 13
Training loss: 2.3204549109942905
Validation loss: 2.646793496634657

Epoch: 64| Step: 0
Training loss: 2.4687125287652707
Validation loss: 2.6433001328636623

Epoch: 6| Step: 1
Training loss: 2.830652277421907
Validation loss: 2.6438016274704204

Epoch: 6| Step: 2
Training loss: 2.6995084527058752
Validation loss: 2.6431412605488456

Epoch: 6| Step: 3
Training loss: 2.8993048591130703
Validation loss: 2.6459028930731674

Epoch: 6| Step: 4
Training loss: 2.8799545056670453
Validation loss: 2.647217986468297

Epoch: 6| Step: 5
Training loss: 2.706818455290702
Validation loss: 2.6508946605960677

Epoch: 6| Step: 6
Training loss: 2.728160663035174
Validation loss: 2.6509165306510587

Epoch: 6| Step: 7
Training loss: 2.843209016086449
Validation loss: 2.64286047457825

Epoch: 6| Step: 8
Training loss: 2.8214417624553234
Validation loss: 2.637786754429337

Epoch: 6| Step: 9
Training loss: 2.9194025196566065
Validation loss: 2.638264972703202

Epoch: 6| Step: 10
Training loss: 2.282642514311983
Validation loss: 2.6407422372649183

Epoch: 6| Step: 11
Training loss: 2.789056430671136
Validation loss: 2.641978186120484

Epoch: 6| Step: 12
Training loss: 3.1065185307997356
Validation loss: 2.641851813590096

Epoch: 6| Step: 13
Training loss: 2.750209106818168
Validation loss: 2.6422459068587867

Epoch: 65| Step: 0
Training loss: 2.7503592516585162
Validation loss: 2.6421030335974516

Epoch: 6| Step: 1
Training loss: 2.807757808978437
Validation loss: 2.642300211711075

Epoch: 6| Step: 2
Training loss: 2.960453366278742
Validation loss: 2.6415251000996722

Epoch: 6| Step: 3
Training loss: 3.166300568415889
Validation loss: 2.6431801000591646

Epoch: 6| Step: 4
Training loss: 3.224313908423575
Validation loss: 2.6426863289892957

Epoch: 6| Step: 5
Training loss: 3.40606548964505
Validation loss: 2.6443132078662464

Epoch: 6| Step: 6
Training loss: 2.1900750399061493
Validation loss: 2.6394277713964254

Epoch: 6| Step: 7
Training loss: 2.7161437071477676
Validation loss: 2.6390512656286482

Epoch: 6| Step: 8
Training loss: 2.7465913628313703
Validation loss: 2.637061820611247

Epoch: 6| Step: 9
Training loss: 2.7871398282542645
Validation loss: 2.6349198145672705

Epoch: 6| Step: 10
Training loss: 2.486985472559632
Validation loss: 2.631859641832412

Epoch: 6| Step: 11
Training loss: 2.381440314750148
Validation loss: 2.630334761700113

Epoch: 6| Step: 12
Training loss: 2.717131999207426
Validation loss: 2.627224358190106

Epoch: 6| Step: 13
Training loss: 2.238161200321431
Validation loss: 2.625457769170154

Epoch: 66| Step: 0
Training loss: 2.8625942098115105
Validation loss: 2.625558975286737

Epoch: 6| Step: 1
Training loss: 3.056905814175223
Validation loss: 2.622568881788182

Epoch: 6| Step: 2
Training loss: 2.877823645505636
Validation loss: 2.6205913064023254

Epoch: 6| Step: 3
Training loss: 3.111554326169966
Validation loss: 2.6167328700622

Epoch: 6| Step: 4
Training loss: 2.6147816090170903
Validation loss: 2.617457042877184

Epoch: 6| Step: 5
Training loss: 2.241413793753916
Validation loss: 2.6127472670746474

Epoch: 6| Step: 6
Training loss: 2.9731666237092846
Validation loss: 2.6153961124030816

Epoch: 6| Step: 7
Training loss: 2.6621228985292507
Validation loss: 2.614848914975704

Epoch: 6| Step: 8
Training loss: 2.5690827833998315
Validation loss: 2.6173361816685485

Epoch: 6| Step: 9
Training loss: 2.8460476155590397
Validation loss: 2.6244554408937053

Epoch: 6| Step: 10
Training loss: 2.523675865985249
Validation loss: 2.616610593458195

Epoch: 6| Step: 11
Training loss: 2.4599516331949887
Validation loss: 2.6164762071270893

Epoch: 6| Step: 12
Training loss: 2.8821863667828027
Validation loss: 2.618132463354864

Epoch: 6| Step: 13
Training loss: 2.570109443412273
Validation loss: 2.609021846302059

Epoch: 67| Step: 0
Training loss: 2.4190639794772273
Validation loss: 2.6142206181058243

Epoch: 6| Step: 1
Training loss: 2.674754147506509
Validation loss: 2.6082919341956865

Epoch: 6| Step: 2
Training loss: 3.263924333817309
Validation loss: 2.6064778155952344

Epoch: 6| Step: 3
Training loss: 2.674725801906985
Validation loss: 2.606467936648563

Epoch: 6| Step: 4
Training loss: 2.918940248354172
Validation loss: 2.6034276803862912

Epoch: 6| Step: 5
Training loss: 2.9546401562218687
Validation loss: 2.6066865300822544

Epoch: 6| Step: 6
Training loss: 2.3283751692548367
Validation loss: 2.6075540763877587

Epoch: 6| Step: 7
Training loss: 2.6787267803373096
Validation loss: 2.6107957212107293

Epoch: 6| Step: 8
Training loss: 2.7288392625259417
Validation loss: 2.609965046396456

Epoch: 6| Step: 9
Training loss: 2.490030724669104
Validation loss: 2.6073514816935517

Epoch: 6| Step: 10
Training loss: 2.8898314340395506
Validation loss: 2.603963894896994

Epoch: 6| Step: 11
Training loss: 2.694892209220552
Validation loss: 2.6029067742937446

Epoch: 6| Step: 12
Training loss: 3.0298631779463565
Validation loss: 2.6000866832710554

Epoch: 6| Step: 13
Training loss: 2.5368330807263955
Validation loss: 2.597869711306012

Epoch: 68| Step: 0
Training loss: 2.451953000537674
Validation loss: 2.5998056186248975

Epoch: 6| Step: 1
Training loss: 2.834356198148602
Validation loss: 2.598914095719347

Epoch: 6| Step: 2
Training loss: 2.8499366619366793
Validation loss: 2.5941488732956097

Epoch: 6| Step: 3
Training loss: 2.8597640309656978
Validation loss: 2.591987608594474

Epoch: 6| Step: 4
Training loss: 2.7838528915321468
Validation loss: 2.5946955049068077

Epoch: 6| Step: 5
Training loss: 2.347706925897269
Validation loss: 2.5960716366770766

Epoch: 6| Step: 6
Training loss: 3.203362135134121
Validation loss: 2.607123601000021

Epoch: 6| Step: 7
Training loss: 2.735144109189618
Validation loss: 2.6079857910555138

Epoch: 6| Step: 8
Training loss: 2.7450529163589614
Validation loss: 2.6205065581636275

Epoch: 6| Step: 9
Training loss: 2.725873187792362
Validation loss: 2.593583021189436

Epoch: 6| Step: 10
Training loss: 2.3310237989548597
Validation loss: 2.6000293265424954

Epoch: 6| Step: 11
Training loss: 2.886401911422367
Validation loss: 2.599026150987607

Epoch: 6| Step: 12
Training loss: 2.152010080051568
Validation loss: 2.5904159719257507

Epoch: 6| Step: 13
Training loss: 3.0655349951547697
Validation loss: 2.588023839436888

Epoch: 69| Step: 0
Training loss: 2.8271550153744722
Validation loss: 2.5932355623357273

Epoch: 6| Step: 1
Training loss: 2.5394018327936987
Validation loss: 2.591439884440185

Epoch: 6| Step: 2
Training loss: 2.9840501538579653
Validation loss: 2.5968343787415114

Epoch: 6| Step: 3
Training loss: 2.6247473095568417
Validation loss: 2.594013507127461

Epoch: 6| Step: 4
Training loss: 2.3915600911318595
Validation loss: 2.596301635292386

Epoch: 6| Step: 5
Training loss: 2.164342538500411
Validation loss: 2.5941839046704107

Epoch: 6| Step: 6
Training loss: 2.990847135483455
Validation loss: 2.5991568378076333

Epoch: 6| Step: 7
Training loss: 2.602668046170531
Validation loss: 2.5930542989504284

Epoch: 6| Step: 8
Training loss: 2.868989217254597
Validation loss: 2.588058708058616

Epoch: 6| Step: 9
Training loss: 2.7785152749037634
Validation loss: 2.586325548143154

Epoch: 6| Step: 10
Training loss: 3.0533266280099243
Validation loss: 2.582796092211082

Epoch: 6| Step: 11
Training loss: 2.722458601007185
Validation loss: 2.580524938196658

Epoch: 6| Step: 12
Training loss: 2.7698095528860884
Validation loss: 2.581167610460744

Epoch: 6| Step: 13
Training loss: 2.728081659800803
Validation loss: 2.588242808435619

Epoch: 70| Step: 0
Training loss: 3.1813903297995347
Validation loss: 2.581303219250448

Epoch: 6| Step: 1
Training loss: 2.1730659567684136
Validation loss: 2.5775377317541115

Epoch: 6| Step: 2
Training loss: 2.9610468459257935
Validation loss: 2.5758768008598167

Epoch: 6| Step: 3
Training loss: 2.809770743361284
Validation loss: 2.5809399582545955

Epoch: 6| Step: 4
Training loss: 2.99914109332463
Validation loss: 2.57899688465906

Epoch: 6| Step: 5
Training loss: 2.415111523693057
Validation loss: 2.5852991182428293

Epoch: 6| Step: 6
Training loss: 2.5025397751245277
Validation loss: 2.5813212916740946

Epoch: 6| Step: 7
Training loss: 2.863862398923143
Validation loss: 2.5752387025678707

Epoch: 6| Step: 8
Training loss: 2.2696475394784743
Validation loss: 2.582960276175296

Epoch: 6| Step: 9
Training loss: 3.080806590397476
Validation loss: 2.5769024348828244

Epoch: 6| Step: 10
Training loss: 2.93282221618246
Validation loss: 2.576643269454447

Epoch: 6| Step: 11
Training loss: 2.6311495365345463
Validation loss: 2.576957199249971

Epoch: 6| Step: 12
Training loss: 2.299169108366583
Validation loss: 2.5730071006871635

Epoch: 6| Step: 13
Training loss: 2.369670912352414
Validation loss: 2.5732749324020507

Epoch: 71| Step: 0
Training loss: 2.8397550923231036
Validation loss: 2.5810872024295133

Epoch: 6| Step: 1
Training loss: 2.916899172280386
Validation loss: 2.5832833367298544

Epoch: 6| Step: 2
Training loss: 2.072730843603292
Validation loss: 2.5847316054631024

Epoch: 6| Step: 3
Training loss: 2.5146429384041813
Validation loss: 2.589259431263991

Epoch: 6| Step: 4
Training loss: 2.736114123278755
Validation loss: 2.5930290752280873

Epoch: 6| Step: 5
Training loss: 2.455832281337893
Validation loss: 2.602324793179783

Epoch: 6| Step: 6
Training loss: 3.271004512381408
Validation loss: 2.6008752902320715

Epoch: 6| Step: 7
Training loss: 2.674405333116733
Validation loss: 2.5946421640012822

Epoch: 6| Step: 8
Training loss: 2.8794246294875325
Validation loss: 2.5878418731895776

Epoch: 6| Step: 9
Training loss: 2.680738237532517
Validation loss: 2.586185024742655

Epoch: 6| Step: 10
Training loss: 2.7752074705356
Validation loss: 2.5847136798735475

Epoch: 6| Step: 11
Training loss: 2.7314178170820713
Validation loss: 2.5835240560289825

Epoch: 6| Step: 12
Training loss: 2.6328968974093336
Validation loss: 2.5836321955257096

Epoch: 6| Step: 13
Training loss: 2.7038537955851814
Validation loss: 2.5795426295495036

Epoch: 72| Step: 0
Training loss: 2.9768458754648304
Validation loss: 2.5770871009480456

Epoch: 6| Step: 1
Training loss: 2.090307109481926
Validation loss: 2.575808106316066

Epoch: 6| Step: 2
Training loss: 2.0857822774789825
Validation loss: 2.5741978491560293

Epoch: 6| Step: 3
Training loss: 3.080470397004537
Validation loss: 2.572240019767146

Epoch: 6| Step: 4
Training loss: 2.711555520444695
Validation loss: 2.570499842347113

Epoch: 6| Step: 5
Training loss: 3.141926054698124
Validation loss: 2.5663319136151586

Epoch: 6| Step: 6
Training loss: 2.583326698622849
Validation loss: 2.5637295727076417

Epoch: 6| Step: 7
Training loss: 2.7487698317745215
Validation loss: 2.5600524005891376

Epoch: 6| Step: 8
Training loss: 3.130045060878498
Validation loss: 2.5611733902631353

Epoch: 6| Step: 9
Training loss: 2.855678315828597
Validation loss: 2.559388139789591

Epoch: 6| Step: 10
Training loss: 2.5100152629980954
Validation loss: 2.5632168767275845

Epoch: 6| Step: 11
Training loss: 2.5587684629936125
Validation loss: 2.559084515666526

Epoch: 6| Step: 12
Training loss: 2.636186650592612
Validation loss: 2.560261547292907

Epoch: 6| Step: 13
Training loss: 2.499803916870828
Validation loss: 2.5622009009745814

Epoch: 73| Step: 0
Training loss: 3.126593526813036
Validation loss: 2.552816314277254

Epoch: 6| Step: 1
Training loss: 2.653303778817644
Validation loss: 2.5527815869145782

Epoch: 6| Step: 2
Training loss: 2.074842915851165
Validation loss: 2.555864131191764

Epoch: 6| Step: 3
Training loss: 2.813342837035894
Validation loss: 2.5588186538895727

Epoch: 6| Step: 4
Training loss: 2.1260568571194396
Validation loss: 2.5576689313033936

Epoch: 6| Step: 5
Training loss: 2.6362852291178847
Validation loss: 2.564873565274339

Epoch: 6| Step: 6
Training loss: 2.3108630185766095
Validation loss: 2.5609602915704115

Epoch: 6| Step: 7
Training loss: 2.8017387509154648
Validation loss: 2.5630853651160885

Epoch: 6| Step: 8
Training loss: 2.9631136745517255
Validation loss: 2.562719436492035

Epoch: 6| Step: 9
Training loss: 2.5166937411875074
Validation loss: 2.562058728688724

Epoch: 6| Step: 10
Training loss: 2.966849592191277
Validation loss: 2.5592905740937786

Epoch: 6| Step: 11
Training loss: 2.435520052666559
Validation loss: 2.5584186212528004

Epoch: 6| Step: 12
Training loss: 2.9074474861998394
Validation loss: 2.5596574353455948

Epoch: 6| Step: 13
Training loss: 3.0730992839451794
Validation loss: 2.557428427546489

Epoch: 74| Step: 0
Training loss: 2.5308218699892664
Validation loss: 2.5498994526955

Epoch: 6| Step: 1
Training loss: 2.271643281267255
Validation loss: 2.554413542606444

Epoch: 6| Step: 2
Training loss: 2.717815545510126
Validation loss: 2.5480136627258143

Epoch: 6| Step: 3
Training loss: 2.4598875682228076
Validation loss: 2.552804110721796

Epoch: 6| Step: 4
Training loss: 2.9033894561119946
Validation loss: 2.5467341565464747

Epoch: 6| Step: 5
Training loss: 2.7741001250962154
Validation loss: 2.550005870388479

Epoch: 6| Step: 6
Training loss: 2.8470999301192363
Validation loss: 2.5507523212282095

Epoch: 6| Step: 7
Training loss: 2.0562140881959157
Validation loss: 2.5602182448510336

Epoch: 6| Step: 8
Training loss: 2.9492006415006973
Validation loss: 2.571877680329432

Epoch: 6| Step: 9
Training loss: 2.9046808744440136
Validation loss: 2.5719879626174853

Epoch: 6| Step: 10
Training loss: 2.4310202914183168
Validation loss: 2.5732781674923695

Epoch: 6| Step: 11
Training loss: 2.967283187697327
Validation loss: 2.5745848577218813

Epoch: 6| Step: 12
Training loss: 3.0506832483158877
Validation loss: 2.5581602083540904

Epoch: 6| Step: 13
Training loss: 2.462414495077717
Validation loss: 2.5521809513859215

Epoch: 75| Step: 0
Training loss: 2.7101247487088953
Validation loss: 2.557278857746146

Epoch: 6| Step: 1
Training loss: 2.5578488262861714
Validation loss: 2.5483502287103974

Epoch: 6| Step: 2
Training loss: 2.736527821607633
Validation loss: 2.547221333801584

Epoch: 6| Step: 3
Training loss: 2.9368139236830904
Validation loss: 2.547486495112298

Epoch: 6| Step: 4
Training loss: 2.6018432832242193
Validation loss: 2.5484845744731346

Epoch: 6| Step: 5
Training loss: 2.5829289847967036
Validation loss: 2.5523967835881582

Epoch: 6| Step: 6
Training loss: 2.451032778984154
Validation loss: 2.559947021427924

Epoch: 6| Step: 7
Training loss: 2.937740721883269
Validation loss: 2.561066606520626

Epoch: 6| Step: 8
Training loss: 2.8416250484994965
Validation loss: 2.559063693075911

Epoch: 6| Step: 9
Training loss: 2.146466825238197
Validation loss: 2.560101262513759

Epoch: 6| Step: 10
Training loss: 2.745113192310771
Validation loss: 2.5580791703340977

Epoch: 6| Step: 11
Training loss: 2.7036906626235395
Validation loss: 2.558237422756499

Epoch: 6| Step: 12
Training loss: 3.1180342286722698
Validation loss: 2.5566498105646915

Epoch: 6| Step: 13
Training loss: 2.296864619847931
Validation loss: 2.55923149566703

Epoch: 76| Step: 0
Training loss: 3.1112964003502657
Validation loss: 2.5589959680198278

Epoch: 6| Step: 1
Training loss: 2.1813136225387324
Validation loss: 2.558041764915308

Epoch: 6| Step: 2
Training loss: 2.18110812799724
Validation loss: 2.5572549282524597

Epoch: 6| Step: 3
Training loss: 2.672177749346548
Validation loss: 2.557616659258807

Epoch: 6| Step: 4
Training loss: 2.8521639254997884
Validation loss: 2.555371907334252

Epoch: 6| Step: 5
Training loss: 2.5880116790673044
Validation loss: 2.5482772836037006

Epoch: 6| Step: 6
Training loss: 2.501627678293075
Validation loss: 2.5487638307064877

Epoch: 6| Step: 7
Training loss: 2.777302458680179
Validation loss: 2.5442788323413645

Epoch: 6| Step: 8
Training loss: 2.942716471342914
Validation loss: 2.5451006725287657

Epoch: 6| Step: 9
Training loss: 2.708955419450289
Validation loss: 2.539081843375837

Epoch: 6| Step: 10
Training loss: 2.60418504835635
Validation loss: 2.5372258669348584

Epoch: 6| Step: 11
Training loss: 2.3409916222645255
Validation loss: 2.5399466202851406

Epoch: 6| Step: 12
Training loss: 2.7934054373430883
Validation loss: 2.537504960667564

Epoch: 6| Step: 13
Training loss: 3.0015999977831647
Validation loss: 2.5349202332747183

Epoch: 77| Step: 0
Training loss: 3.514124707001711
Validation loss: 2.535056952288816

Epoch: 6| Step: 1
Training loss: 2.047416906475601
Validation loss: 2.535796207637174

Epoch: 6| Step: 2
Training loss: 2.526117749723383
Validation loss: 2.535997734051764

Epoch: 6| Step: 3
Training loss: 2.033785250217005
Validation loss: 2.537244128025081

Epoch: 6| Step: 4
Training loss: 3.0108400638891175
Validation loss: 2.534861480394421

Epoch: 6| Step: 5
Training loss: 2.7368979013987103
Validation loss: 2.5361512851446277

Epoch: 6| Step: 6
Training loss: 2.711330594192346
Validation loss: 2.528034349725238

Epoch: 6| Step: 7
Training loss: 2.0176160574317152
Validation loss: 2.5323616930371298

Epoch: 6| Step: 8
Training loss: 2.6726579021057355
Validation loss: 2.5334078221496155

Epoch: 6| Step: 9
Training loss: 2.737586701992785
Validation loss: 2.530856239241149

Epoch: 6| Step: 10
Training loss: 2.3195365867155053
Validation loss: 2.5301359888452573

Epoch: 6| Step: 11
Training loss: 2.7357201455582465
Validation loss: 2.5376551087426624

Epoch: 6| Step: 12
Training loss: 2.919679194033025
Validation loss: 2.527646250557534

Epoch: 6| Step: 13
Training loss: 2.6243350685463076
Validation loss: 2.5291949905828943

Epoch: 78| Step: 0
Training loss: 2.613147680863436
Validation loss: 2.5283946348925874

Epoch: 6| Step: 1
Training loss: 2.6443680638236073
Validation loss: 2.52880953655973

Epoch: 6| Step: 2
Training loss: 2.4555622797893593
Validation loss: 2.5296088184657797

Epoch: 6| Step: 3
Training loss: 2.3499176254444563
Validation loss: 2.5288090494414135

Epoch: 6| Step: 4
Training loss: 2.8407699564761795
Validation loss: 2.524868743305042

Epoch: 6| Step: 5
Training loss: 2.7740054126678446
Validation loss: 2.522657701057339

Epoch: 6| Step: 6
Training loss: 2.5408649326593626
Validation loss: 2.525793056773122

Epoch: 6| Step: 7
Training loss: 2.8666742265586826
Validation loss: 2.517975122102649

Epoch: 6| Step: 8
Training loss: 2.9773957295260898
Validation loss: 2.5224890092623524

Epoch: 6| Step: 9
Training loss: 2.968980639683991
Validation loss: 2.524333090255217

Epoch: 6| Step: 10
Training loss: 2.153718651152075
Validation loss: 2.5219251433110093

Epoch: 6| Step: 11
Training loss: 2.5596891664507266
Validation loss: 2.5226183684761407

Epoch: 6| Step: 12
Training loss: 2.434841760589153
Validation loss: 2.5265354473527055

Epoch: 6| Step: 13
Training loss: 2.7644142906023816
Validation loss: 2.524905790327734

Epoch: 79| Step: 0
Training loss: 2.69497528178074
Validation loss: 2.5263767505214574

Epoch: 6| Step: 1
Training loss: 2.5512986410570155
Validation loss: 2.525706685195958

Epoch: 6| Step: 2
Training loss: 2.888864341859781
Validation loss: 2.525842078015595

Epoch: 6| Step: 3
Training loss: 3.185469036449379
Validation loss: 2.525323499597311

Epoch: 6| Step: 4
Training loss: 2.5606170807618915
Validation loss: 2.529034622323436

Epoch: 6| Step: 5
Training loss: 2.4032331107516467
Validation loss: 2.530353214601737

Epoch: 6| Step: 6
Training loss: 3.141693692550644
Validation loss: 2.530225381575203

Epoch: 6| Step: 7
Training loss: 2.2562579971129484
Validation loss: 2.5289323030971538

Epoch: 6| Step: 8
Training loss: 2.539547354547895
Validation loss: 2.5319191005170985

Epoch: 6| Step: 9
Training loss: 2.331916026682622
Validation loss: 2.5276658070629168

Epoch: 6| Step: 10
Training loss: 2.6876116884665793
Validation loss: 2.5261757778996623

Epoch: 6| Step: 11
Training loss: 2.716797928086604
Validation loss: 2.5250610545617156

Epoch: 6| Step: 12
Training loss: 2.4148003398112117
Validation loss: 2.5242576722843943

Epoch: 6| Step: 13
Training loss: 2.5898234048680036
Validation loss: 2.521275778370574

Epoch: 80| Step: 0
Training loss: 2.557021448551907
Validation loss: 2.521846541346963

Epoch: 6| Step: 1
Training loss: 2.5694826403920543
Validation loss: 2.516024966460229

Epoch: 6| Step: 2
Training loss: 2.5124725112550013
Validation loss: 2.520196256185814

Epoch: 6| Step: 3
Training loss: 2.6144613614957852
Validation loss: 2.5213397176877907

Epoch: 6| Step: 4
Training loss: 2.8547910206967138
Validation loss: 2.519544813331548

Epoch: 6| Step: 5
Training loss: 2.533726363897525
Validation loss: 2.522596394260077

Epoch: 6| Step: 6
Training loss: 2.7705580686973383
Validation loss: 2.5340048473023757

Epoch: 6| Step: 7
Training loss: 2.918484602630868
Validation loss: 2.5342646413686665

Epoch: 6| Step: 8
Training loss: 2.724040529215667
Validation loss: 2.531404027451837

Epoch: 6| Step: 9
Training loss: 2.941942305434187
Validation loss: 2.5355867040994156

Epoch: 6| Step: 10
Training loss: 2.676246769638998
Validation loss: 2.525293303598741

Epoch: 6| Step: 11
Training loss: 2.2468460017469836
Validation loss: 2.5175729164087413

Epoch: 6| Step: 12
Training loss: 2.593469443716884
Validation loss: 2.513857518721047

Epoch: 6| Step: 13
Training loss: 2.5818082450560698
Validation loss: 2.512732475748218

Epoch: 81| Step: 0
Training loss: 3.3895624842800682
Validation loss: 2.513936204505979

Epoch: 6| Step: 1
Training loss: 2.301141111666558
Validation loss: 2.5210390138392786

Epoch: 6| Step: 2
Training loss: 2.8041728192999247
Validation loss: 2.521434260431014

Epoch: 6| Step: 3
Training loss: 2.696672267963013
Validation loss: 2.525960804277512

Epoch: 6| Step: 4
Training loss: 2.657925963404722
Validation loss: 2.529521666053529

Epoch: 6| Step: 5
Training loss: 2.581682374962666
Validation loss: 2.532560331172637

Epoch: 6| Step: 6
Training loss: 2.1122094219733394
Validation loss: 2.5349126149151053

Epoch: 6| Step: 7
Training loss: 2.1615881700854174
Validation loss: 2.5333782244352308

Epoch: 6| Step: 8
Training loss: 2.6711764844704184
Validation loss: 2.534854394842988

Epoch: 6| Step: 9
Training loss: 2.9213031066324344
Validation loss: 2.5308253242065324

Epoch: 6| Step: 10
Training loss: 2.7462542773193053
Validation loss: 2.5283186779800304

Epoch: 6| Step: 11
Training loss: 2.542565192152928
Validation loss: 2.5246228090574445

Epoch: 6| Step: 12
Training loss: 2.71394967924623
Validation loss: 2.5222235122496244

Epoch: 6| Step: 13
Training loss: 2.649800627783984
Validation loss: 2.5190295367995943

Epoch: 82| Step: 0
Training loss: 2.5631170692869962
Validation loss: 2.5178022893993965

Epoch: 6| Step: 1
Training loss: 2.198215723408006
Validation loss: 2.5160424022437113

Epoch: 6| Step: 2
Training loss: 2.5451002431736818
Validation loss: 2.5198461528016076

Epoch: 6| Step: 3
Training loss: 2.8208785823045868
Validation loss: 2.51755317101493

Epoch: 6| Step: 4
Training loss: 2.7470902741565
Validation loss: 2.510207904878218

Epoch: 6| Step: 5
Training loss: 3.057032940827781
Validation loss: 2.511118166931427

Epoch: 6| Step: 6
Training loss: 2.456875212404198
Validation loss: 2.5057047288033742

Epoch: 6| Step: 7
Training loss: 2.4747681480240953
Validation loss: 2.515914426467274

Epoch: 6| Step: 8
Training loss: 2.9909502862990394
Validation loss: 2.513025287103742

Epoch: 6| Step: 9
Training loss: 3.2460878741673653
Validation loss: 2.5058740430577537

Epoch: 6| Step: 10
Training loss: 2.067588078791811
Validation loss: 2.5096120745322903

Epoch: 6| Step: 11
Training loss: 2.2969458951843102
Validation loss: 2.509991531991036

Epoch: 6| Step: 12
Training loss: 2.861214801510166
Validation loss: 2.5078850851517376

Epoch: 6| Step: 13
Training loss: 2.3647498745743314
Validation loss: 2.499612412607587

Epoch: 83| Step: 0
Training loss: 2.6112740738609497
Validation loss: 2.5064254363215275

Epoch: 6| Step: 1
Training loss: 2.28717546505973
Validation loss: 2.50311169884712

Epoch: 6| Step: 2
Training loss: 2.200966284695144
Validation loss: 2.5064402278964604

Epoch: 6| Step: 3
Training loss: 2.632995418001296
Validation loss: 2.5078668637983723

Epoch: 6| Step: 4
Training loss: 2.86599215918651
Validation loss: 2.5047838693452094

Epoch: 6| Step: 5
Training loss: 2.4829354584041416
Validation loss: 2.5035859615774023

Epoch: 6| Step: 6
Training loss: 2.2142414976354936
Validation loss: 2.5058631649172027

Epoch: 6| Step: 7
Training loss: 2.680601447925377
Validation loss: 2.502323247337451

Epoch: 6| Step: 8
Training loss: 2.601295067957231
Validation loss: 2.5018421856248763

Epoch: 6| Step: 9
Training loss: 2.627297259057523
Validation loss: 2.4979899591081742

Epoch: 6| Step: 10
Training loss: 2.7035876633386486
Validation loss: 2.5072539629529444

Epoch: 6| Step: 11
Training loss: 3.0603408987604594
Validation loss: 2.500778124830253

Epoch: 6| Step: 12
Training loss: 3.184963638361598
Validation loss: 2.5003433309678194

Epoch: 6| Step: 13
Training loss: 2.3192236814939275
Validation loss: 2.5035498370870846

Epoch: 84| Step: 0
Training loss: 2.756185683972713
Validation loss: 2.5021231377892574

Epoch: 6| Step: 1
Training loss: 2.845484613264702
Validation loss: 2.502729181877993

Epoch: 6| Step: 2
Training loss: 2.094876797497145
Validation loss: 2.502233985306144

Epoch: 6| Step: 3
Training loss: 2.791279400586525
Validation loss: 2.5033567780854233

Epoch: 6| Step: 4
Training loss: 2.8895205475564585
Validation loss: 2.4966342840229467

Epoch: 6| Step: 5
Training loss: 2.479651032475918
Validation loss: 2.502441215701212

Epoch: 6| Step: 6
Training loss: 2.565435449472498
Validation loss: 2.506093435240879

Epoch: 6| Step: 7
Training loss: 2.856393562565414
Validation loss: 2.500728548704807

Epoch: 6| Step: 8
Training loss: 1.9749375852549027
Validation loss: 2.511135225358405

Epoch: 6| Step: 9
Training loss: 2.391993112471243
Validation loss: 2.5082882343770776

Epoch: 6| Step: 10
Training loss: 2.6735172690124
Validation loss: 2.50302130603041

Epoch: 6| Step: 11
Training loss: 2.7971363478300537
Validation loss: 2.507698016856279

Epoch: 6| Step: 12
Training loss: 2.58008366944427
Validation loss: 2.5163289382460934

Epoch: 6| Step: 13
Training loss: 2.7711276039139867
Validation loss: 2.510112005295586

Epoch: 85| Step: 0
Training loss: 2.6127613502718003
Validation loss: 2.5067193331495146

Epoch: 6| Step: 1
Training loss: 2.4902523743222056
Validation loss: 2.5044291997086585

Epoch: 6| Step: 2
Training loss: 2.7219035833633902
Validation loss: 2.4962370686585333

Epoch: 6| Step: 3
Training loss: 2.0324860553333477
Validation loss: 2.4975792290763286

Epoch: 6| Step: 4
Training loss: 2.8163722190970186
Validation loss: 2.4919445912001277

Epoch: 6| Step: 5
Training loss: 2.548880600663116
Validation loss: 2.4971283791655354

Epoch: 6| Step: 6
Training loss: 3.1081522161848203
Validation loss: 2.4974166476774875

Epoch: 6| Step: 7
Training loss: 2.010908419169825
Validation loss: 2.492892876019056

Epoch: 6| Step: 8
Training loss: 2.7982216262408106
Validation loss: 2.4993906073127867

Epoch: 6| Step: 9
Training loss: 2.4537901735830836
Validation loss: 2.5019709129604464

Epoch: 6| Step: 10
Training loss: 2.8100678842293205
Validation loss: 2.5041696030085947

Epoch: 6| Step: 11
Training loss: 2.6906598167514972
Validation loss: 2.503815758905405

Epoch: 6| Step: 12
Training loss: 2.9899267515568493
Validation loss: 2.5054625754245112

Epoch: 6| Step: 13
Training loss: 2.298986489440856
Validation loss: 2.503427674991647

Epoch: 86| Step: 0
Training loss: 2.2717167480426346
Validation loss: 2.5022873586985415

Epoch: 6| Step: 1
Training loss: 2.6673442059312555
Validation loss: 2.5013748679955725

Epoch: 6| Step: 2
Training loss: 2.8387813548578333
Validation loss: 2.5023109245707893

Epoch: 6| Step: 3
Training loss: 2.312882675262896
Validation loss: 2.497612242061883

Epoch: 6| Step: 4
Training loss: 1.9050459263990076
Validation loss: 2.496465186718476

Epoch: 6| Step: 5
Training loss: 2.7574379642318183
Validation loss: 2.4944481397467837

Epoch: 6| Step: 6
Training loss: 2.884458490653273
Validation loss: 2.4936817437106957

Epoch: 6| Step: 7
Training loss: 2.511244472499478
Validation loss: 2.4916153812127413

Epoch: 6| Step: 8
Training loss: 2.30787722445814
Validation loss: 2.497331657553031

Epoch: 6| Step: 9
Training loss: 2.8056740898380683
Validation loss: 2.494584337086367

Epoch: 6| Step: 10
Training loss: 2.8787641347852007
Validation loss: 2.4937494021409417

Epoch: 6| Step: 11
Training loss: 2.6166804947052382
Validation loss: 2.5016167816874444

Epoch: 6| Step: 12
Training loss: 3.1286511263615506
Validation loss: 2.4955937337950878

Epoch: 6| Step: 13
Training loss: 2.4973607437060634
Validation loss: 2.496237100495597

Epoch: 87| Step: 0
Training loss: 2.9097651071556965
Validation loss: 2.496020917471633

Epoch: 6| Step: 1
Training loss: 2.90150145762813
Validation loss: 2.4925072922212532

Epoch: 6| Step: 2
Training loss: 2.4378704865425633
Validation loss: 2.496855625973408

Epoch: 6| Step: 3
Training loss: 3.012256064767975
Validation loss: 2.495350583302811

Epoch: 6| Step: 4
Training loss: 2.3259588827892617
Validation loss: 2.4970674322054744

Epoch: 6| Step: 5
Training loss: 2.653661656106353
Validation loss: 2.4923829387697345

Epoch: 6| Step: 6
Training loss: 2.856641452934722
Validation loss: 2.4973047191452418

Epoch: 6| Step: 7
Training loss: 2.823103688556326
Validation loss: 2.494341374948601

Epoch: 6| Step: 8
Training loss: 2.470099454568622
Validation loss: 2.488942312502647

Epoch: 6| Step: 9
Training loss: 2.7375760768962083
Validation loss: 2.493337543257901

Epoch: 6| Step: 10
Training loss: 2.3995769167553367
Validation loss: 2.4924749290355823

Epoch: 6| Step: 11
Training loss: 2.232865043433001
Validation loss: 2.4964027671187194

Epoch: 6| Step: 12
Training loss: 2.4931686526837886
Validation loss: 2.5018753964819855

Epoch: 6| Step: 13
Training loss: 2.193651976392398
Validation loss: 2.4934251635856204

Epoch: 88| Step: 0
Training loss: 3.2421730868467282
Validation loss: 2.4981296297930293

Epoch: 6| Step: 1
Training loss: 2.269499734209965
Validation loss: 2.4969986383273732

Epoch: 6| Step: 2
Training loss: 2.374155396309432
Validation loss: 2.494918674004861

Epoch: 6| Step: 3
Training loss: 1.9424092025843638
Validation loss: 2.4947085330201832

Epoch: 6| Step: 4
Training loss: 2.570357580282389
Validation loss: 2.5010659250155127

Epoch: 6| Step: 5
Training loss: 2.8871163183497046
Validation loss: 2.5008756852326903

Epoch: 6| Step: 6
Training loss: 2.7488108578164416
Validation loss: 2.4886514736607293

Epoch: 6| Step: 7
Training loss: 2.387855271674126
Validation loss: 2.4971681609741756

Epoch: 6| Step: 8
Training loss: 2.791019639905921
Validation loss: 2.490491842286533

Epoch: 6| Step: 9
Training loss: 2.5845567411015824
Validation loss: 2.4926608601720406

Epoch: 6| Step: 10
Training loss: 2.558615368467829
Validation loss: 2.4957891764951086

Epoch: 6| Step: 11
Training loss: 2.448997864809114
Validation loss: 2.4989951657475786

Epoch: 6| Step: 12
Training loss: 2.9722937063333736
Validation loss: 2.490038623969856

Epoch: 6| Step: 13
Training loss: 2.4400981847363363
Validation loss: 2.493555791522007

Epoch: 89| Step: 0
Training loss: 2.6205402818919907
Validation loss: 2.4902556614184177

Epoch: 6| Step: 1
Training loss: 2.6799213096111623
Validation loss: 2.486415640745878

Epoch: 6| Step: 2
Training loss: 3.1626417949989407
Validation loss: 2.486481195628921

Epoch: 6| Step: 3
Training loss: 2.253877054484871
Validation loss: 2.488575102074633

Epoch: 6| Step: 4
Training loss: 2.4941241832122514
Validation loss: 2.4904448536203225

Epoch: 6| Step: 5
Training loss: 2.449499476161573
Validation loss: 2.491422354374095

Epoch: 6| Step: 6
Training loss: 2.0135029112323775
Validation loss: 2.4922386491044892

Epoch: 6| Step: 7
Training loss: 2.4886144777240595
Validation loss: 2.4894274951464044

Epoch: 6| Step: 8
Training loss: 2.5040618324445516
Validation loss: 2.49244195960449

Epoch: 6| Step: 9
Training loss: 2.580369838998271
Validation loss: 2.49095848974687

Epoch: 6| Step: 10
Training loss: 2.571379002592886
Validation loss: 2.4935954072307234

Epoch: 6| Step: 11
Training loss: 2.691650645284143
Validation loss: 2.4925384912098263

Epoch: 6| Step: 12
Training loss: 2.978485047230338
Validation loss: 2.4919776309944823

Epoch: 6| Step: 13
Training loss: 2.7921778272601063
Validation loss: 2.48660913613921

Epoch: 90| Step: 0
Training loss: 1.8484648211564916
Validation loss: 2.4877920423411752

Epoch: 6| Step: 1
Training loss: 2.2200489808598802
Validation loss: 2.487800188337987

Epoch: 6| Step: 2
Training loss: 2.6230031547396524
Validation loss: 2.4874124412525864

Epoch: 6| Step: 3
Training loss: 2.4586577982601225
Validation loss: 2.4867419437625533

Epoch: 6| Step: 4
Training loss: 2.6591663283209694
Validation loss: 2.486324441152412

Epoch: 6| Step: 5
Training loss: 3.2443890186551485
Validation loss: 2.481634728034249

Epoch: 6| Step: 6
Training loss: 2.3159218292879746
Validation loss: 2.4869567284229244

Epoch: 6| Step: 7
Training loss: 2.6647942844028383
Validation loss: 2.492471899947437

Epoch: 6| Step: 8
Training loss: 2.710645412573149
Validation loss: 2.488758019524297

Epoch: 6| Step: 9
Training loss: 2.4893074255182372
Validation loss: 2.488384873464746

Epoch: 6| Step: 10
Training loss: 2.5624154239746515
Validation loss: 2.489268755224636

Epoch: 6| Step: 11
Training loss: 3.0527631156676502
Validation loss: 2.4875301263413006

Epoch: 6| Step: 12
Training loss: 2.564826095664378
Validation loss: 2.4870698655983903

Epoch: 6| Step: 13
Training loss: 2.614815984053686
Validation loss: 2.4913529261260203

Epoch: 91| Step: 0
Training loss: 2.790126565503056
Validation loss: 2.48871791168122

Epoch: 6| Step: 1
Training loss: 2.41643617341994
Validation loss: 2.4898556888845884

Epoch: 6| Step: 2
Training loss: 2.202725854523333
Validation loss: 2.4829945917817016

Epoch: 6| Step: 3
Training loss: 3.0187936846808436
Validation loss: 2.4889268900840684

Epoch: 6| Step: 4
Training loss: 2.7860758200992657
Validation loss: 2.486964381841415

Epoch: 6| Step: 5
Training loss: 3.043358911223652
Validation loss: 2.4890761291041366

Epoch: 6| Step: 6
Training loss: 3.049168589103894
Validation loss: 2.4846753592632935

Epoch: 6| Step: 7
Training loss: 2.8614631074176553
Validation loss: 2.4867364468725315

Epoch: 6| Step: 8
Training loss: 2.534004125963569
Validation loss: 2.488543294525785

Epoch: 6| Step: 9
Training loss: 1.8395704321518684
Validation loss: 2.47951148277168

Epoch: 6| Step: 10
Training loss: 1.276864057989753
Validation loss: 2.4871733797678024

Epoch: 6| Step: 11
Training loss: 2.809154046082265
Validation loss: 2.4805228720540073

Epoch: 6| Step: 12
Training loss: 2.251487981660413
Validation loss: 2.487731505568439

Epoch: 6| Step: 13
Training loss: 2.6732581055569216
Validation loss: 2.4860722724064015

Epoch: 92| Step: 0
Training loss: 2.91934992569364
Validation loss: 2.486580819121631

Epoch: 6| Step: 1
Training loss: 2.588404651190703
Validation loss: 2.4869456716681895

Epoch: 6| Step: 2
Training loss: 2.1016816172823045
Validation loss: 2.4810610727278415

Epoch: 6| Step: 3
Training loss: 2.3634306553044584
Validation loss: 2.4707750473309678

Epoch: 6| Step: 4
Training loss: 3.0477720847335283
Validation loss: 2.4832965261389965

Epoch: 6| Step: 5
Training loss: 2.147306609322124
Validation loss: 2.4897590053832284

Epoch: 6| Step: 6
Training loss: 1.7972708224656904
Validation loss: 2.5020072190658054

Epoch: 6| Step: 7
Training loss: 2.714662921838607
Validation loss: 2.5171869298080662

Epoch: 6| Step: 8
Training loss: 2.41946074223227
Validation loss: 2.539235974768007

Epoch: 6| Step: 9
Training loss: 3.159999320114642
Validation loss: 2.5473574472011653

Epoch: 6| Step: 10
Training loss: 2.89195031379027
Validation loss: 2.530073402631643

Epoch: 6| Step: 11
Training loss: 3.0126921469796986
Validation loss: 2.5191641133461937

Epoch: 6| Step: 12
Training loss: 2.786819881382636
Validation loss: 2.479250310774395

Epoch: 6| Step: 13
Training loss: 2.295084144861497
Validation loss: 2.484865855863235

Epoch: 93| Step: 0
Training loss: 2.657180712836017
Validation loss: 2.4877435331764337

Epoch: 6| Step: 1
Training loss: 2.482818691853316
Validation loss: 2.5028775344040968

Epoch: 6| Step: 2
Training loss: 2.74472059318313
Validation loss: 2.5146528620511237

Epoch: 6| Step: 3
Training loss: 2.766498578568836
Validation loss: 2.532750928798349

Epoch: 6| Step: 4
Training loss: 2.791919260316804
Validation loss: 2.5384185365648473

Epoch: 6| Step: 5
Training loss: 2.5845836771951936
Validation loss: 2.5611037350307266

Epoch: 6| Step: 6
Training loss: 2.706349648982257
Validation loss: 2.575730570143295

Epoch: 6| Step: 7
Training loss: 2.762433813346506
Validation loss: 2.5816105102069384

Epoch: 6| Step: 8
Training loss: 2.2269672226739794
Validation loss: 2.5868466748774943

Epoch: 6| Step: 9
Training loss: 2.802235501115304
Validation loss: 2.5886613036561963

Epoch: 6| Step: 10
Training loss: 3.264981000999799
Validation loss: 2.5875535661493974

Epoch: 6| Step: 11
Training loss: 2.69751709049669
Validation loss: 2.5901890865365527

Epoch: 6| Step: 12
Training loss: 2.8107804870010673
Validation loss: 2.590660890730176

Epoch: 6| Step: 13
Training loss: 2.422540585519419
Validation loss: 2.5811935966677897

Epoch: 94| Step: 0
Training loss: 2.5518390045504953
Validation loss: 2.572867996640955

Epoch: 6| Step: 1
Training loss: 3.1379617054962816
Validation loss: 2.566273214065197

Epoch: 6| Step: 2
Training loss: 2.928324552756968
Validation loss: 2.567012287583544

Epoch: 6| Step: 3
Training loss: 2.2206282925977274
Validation loss: 2.5543179337066646

Epoch: 6| Step: 4
Training loss: 2.6030993804953177
Validation loss: 2.5514677252437887

Epoch: 6| Step: 5
Training loss: 3.222761598656864
Validation loss: 2.5478227408297

Epoch: 6| Step: 6
Training loss: 2.6201042661230955
Validation loss: 2.539999639255768

Epoch: 6| Step: 7
Training loss: 2.6064727541642716
Validation loss: 2.5361463105483075

Epoch: 6| Step: 8
Training loss: 2.7423232172667404
Validation loss: 2.528817110451804

Epoch: 6| Step: 9
Training loss: 2.193701536507283
Validation loss: 2.526705174299452

Epoch: 6| Step: 10
Training loss: 2.2720986320483765
Validation loss: 2.523439121934745

Epoch: 6| Step: 11
Training loss: 2.4370845538448416
Validation loss: 2.5188421682149293

Epoch: 6| Step: 12
Training loss: 2.2925839986773027
Validation loss: 2.51601288452852

Epoch: 6| Step: 13
Training loss: 3.0659260173314684
Validation loss: 2.510006017589068

Epoch: 95| Step: 0
Training loss: 2.1057859050973557
Validation loss: 2.510452639584528

Epoch: 6| Step: 1
Training loss: 3.232917789092428
Validation loss: 2.5025818208827477

Epoch: 6| Step: 2
Training loss: 2.1668553147963596
Validation loss: 2.49844607697065

Epoch: 6| Step: 3
Training loss: 2.3282508560059485
Validation loss: 2.4918277365210635

Epoch: 6| Step: 4
Training loss: 2.731072922472289
Validation loss: 2.4872622077548496

Epoch: 6| Step: 5
Training loss: 2.8338339494235143
Validation loss: 2.488608745460234

Epoch: 6| Step: 6
Training loss: 2.779228418704105
Validation loss: 2.48281310625431

Epoch: 6| Step: 7
Training loss: 2.8263316501462903
Validation loss: 2.4790663712246617

Epoch: 6| Step: 8
Training loss: 2.4194302925526165
Validation loss: 2.4811675441567256

Epoch: 6| Step: 9
Training loss: 2.60110744586143
Validation loss: 2.4789002673420253

Epoch: 6| Step: 10
Training loss: 2.8885378338998944
Validation loss: 2.482710242561318

Epoch: 6| Step: 11
Training loss: 2.612771114171704
Validation loss: 2.4823384764933802

Epoch: 6| Step: 12
Training loss: 2.0691095276019427
Validation loss: 2.4736542498109815

Epoch: 6| Step: 13
Training loss: 2.435487356429936
Validation loss: 2.4904434016643937

Epoch: 96| Step: 0
Training loss: 2.6234929436191985
Validation loss: 2.4781522411823063

Epoch: 6| Step: 1
Training loss: 3.226484468638767
Validation loss: 2.4824194739305363

Epoch: 6| Step: 2
Training loss: 2.3624112632273695
Validation loss: 2.477631884560113

Epoch: 6| Step: 3
Training loss: 3.076740863796713
Validation loss: 2.47345541142083

Epoch: 6| Step: 4
Training loss: 2.767124868467126
Validation loss: 2.4760710893572466

Epoch: 6| Step: 5
Training loss: 2.590604230293608
Validation loss: 2.475893742613899

Epoch: 6| Step: 6
Training loss: 2.359249389538409
Validation loss: 2.475634797245483

Epoch: 6| Step: 7
Training loss: 2.661164259418552
Validation loss: 2.4712702606610684

Epoch: 6| Step: 8
Training loss: 2.5601960966881645
Validation loss: 2.478269876973063

Epoch: 6| Step: 9
Training loss: 2.83674513400874
Validation loss: 2.47755347320251

Epoch: 6| Step: 10
Training loss: 2.173514316937295
Validation loss: 2.4794853123212333

Epoch: 6| Step: 11
Training loss: 2.154738297116111
Validation loss: 2.47156248564605

Epoch: 6| Step: 12
Training loss: 2.9636100846065334
Validation loss: 2.4730834270534308

Epoch: 6| Step: 13
Training loss: 1.5678085176851861
Validation loss: 2.4852011724411462

Epoch: 97| Step: 0
Training loss: 2.8338289014469065
Validation loss: 2.476299380214937

Epoch: 6| Step: 1
Training loss: 2.6506436591918416
Validation loss: 2.4763590571680245

Epoch: 6| Step: 2
Training loss: 2.2877971810499007
Validation loss: 2.4772141137876447

Epoch: 6| Step: 3
Training loss: 2.8202036152371135
Validation loss: 2.475610688516555

Epoch: 6| Step: 4
Training loss: 2.460386378020816
Validation loss: 2.47059450576714

Epoch: 6| Step: 5
Training loss: 2.4785621825069692
Validation loss: 2.4735166831404

Epoch: 6| Step: 6
Training loss: 2.395801798295065
Validation loss: 2.4648819087682425

Epoch: 6| Step: 7
Training loss: 2.5357992476538547
Validation loss: 2.471895033429255

Epoch: 6| Step: 8
Training loss: 2.1543348348806015
Validation loss: 2.4712971773534163

Epoch: 6| Step: 9
Training loss: 2.799710163374303
Validation loss: 2.4756404953461795

Epoch: 6| Step: 10
Training loss: 2.63730941373137
Validation loss: 2.475963756815738

Epoch: 6| Step: 11
Training loss: 2.3736656857783904
Validation loss: 2.4766840859780768

Epoch: 6| Step: 12
Training loss: 2.7435391564485294
Validation loss: 2.465328033961818

Epoch: 6| Step: 13
Training loss: 2.7788718696807573
Validation loss: 2.4772568460389706

Epoch: 98| Step: 0
Training loss: 2.497197010345356
Validation loss: 2.470359004284898

Epoch: 6| Step: 1
Training loss: 2.4867750367012293
Validation loss: 2.470366628698455

Epoch: 6| Step: 2
Training loss: 2.52208378150928
Validation loss: 2.478031224340147

Epoch: 6| Step: 3
Training loss: 2.7563686319369065
Validation loss: 2.468877169395937

Epoch: 6| Step: 4
Training loss: 2.6761096613585735
Validation loss: 2.4731672661888964

Epoch: 6| Step: 5
Training loss: 2.407720339507138
Validation loss: 2.4719828913661415

Epoch: 6| Step: 6
Training loss: 2.4147619326753107
Validation loss: 2.4724959752918245

Epoch: 6| Step: 7
Training loss: 2.830355444379437
Validation loss: 2.4703740922366135

Epoch: 6| Step: 8
Training loss: 2.6022178580514197
Validation loss: 2.469107718646496

Epoch: 6| Step: 9
Training loss: 2.5120945199993745
Validation loss: 2.4702838285593143

Epoch: 6| Step: 10
Training loss: 2.624780191573601
Validation loss: 2.466431748527547

Epoch: 6| Step: 11
Training loss: 2.19557639059785
Validation loss: 2.4711718048140394

Epoch: 6| Step: 12
Training loss: 2.752644394526784
Validation loss: 2.466707020077244

Epoch: 6| Step: 13
Training loss: 2.6582284179201716
Validation loss: 2.4731069177225686

Epoch: 99| Step: 0
Training loss: 2.711290232112343
Validation loss: 2.46963906676806

Epoch: 6| Step: 1
Training loss: 2.332735450530005
Validation loss: 2.4756740416449516

Epoch: 6| Step: 2
Training loss: 2.5934608022486656
Validation loss: 2.476611677417603

Epoch: 6| Step: 3
Training loss: 2.091508491077555
Validation loss: 2.473249134338242

Epoch: 6| Step: 4
Training loss: 2.9311113076655424
Validation loss: 2.4789482522702806

Epoch: 6| Step: 5
Training loss: 2.1305831044767505
Validation loss: 2.4727831863677086

Epoch: 6| Step: 6
Training loss: 2.8733056092602722
Validation loss: 2.477337656742439

Epoch: 6| Step: 7
Training loss: 3.1907028861258357
Validation loss: 2.475968812205822

Epoch: 6| Step: 8
Training loss: 2.8328554835059427
Validation loss: 2.472975370315049

Epoch: 6| Step: 9
Training loss: 2.5059300663194763
Validation loss: 2.474001678622475

Epoch: 6| Step: 10
Training loss: 2.3581552952757296
Validation loss: 2.4745790097833202

Epoch: 6| Step: 11
Training loss: 2.4240906455651077
Validation loss: 2.4697479452261133

Epoch: 6| Step: 12
Training loss: 2.488742851427159
Validation loss: 2.471562373103876

Epoch: 6| Step: 13
Training loss: 2.359580529968152
Validation loss: 2.4715922287552465

Epoch: 100| Step: 0
Training loss: 2.655819128657037
Validation loss: 2.4691926422538084

Epoch: 6| Step: 1
Training loss: 2.3043886152526882
Validation loss: 2.464146922134215

Epoch: 6| Step: 2
Training loss: 2.7607692181478702
Validation loss: 2.4734838144412703

Epoch: 6| Step: 3
Training loss: 2.6793734975409738
Validation loss: 2.4734660625917164

Epoch: 6| Step: 4
Training loss: 2.630319382743627
Validation loss: 2.473636234128975

Epoch: 6| Step: 5
Training loss: 2.470937315204035
Validation loss: 2.4711984492218346

Epoch: 6| Step: 6
Training loss: 1.7092134333101616
Validation loss: 2.475995758063278

Epoch: 6| Step: 7
Training loss: 2.7324815570456695
Validation loss: 2.4756089870927283

Epoch: 6| Step: 8
Training loss: 2.3374255489793647
Validation loss: 2.4772301384682747

Epoch: 6| Step: 9
Training loss: 2.8759007908630503
Validation loss: 2.47291872902334

Epoch: 6| Step: 10
Training loss: 2.5629479551713
Validation loss: 2.470620963397863

Epoch: 6| Step: 11
Training loss: 2.5963022015777986
Validation loss: 2.473599302775477

Epoch: 6| Step: 12
Training loss: 3.001447646223812
Validation loss: 2.482597354876423

Epoch: 6| Step: 13
Training loss: 2.6151884272942754
Validation loss: 2.4906992998132984

Testing loss: 2.067434465331494
