Epoch: 1| Step: 0
Training loss: 5.757987976074219
Validation loss: 5.384445309638977

Epoch: 5| Step: 1
Training loss: 4.586178779602051
Validation loss: 5.382509171962738

Epoch: 5| Step: 2
Training loss: 6.408743381500244
Validation loss: 5.38060986995697

Epoch: 5| Step: 3
Training loss: 5.052016735076904
Validation loss: 5.378679831822713

Epoch: 5| Step: 4
Training loss: 5.305375576019287
Validation loss: 5.3768336574236555

Epoch: 5| Step: 5
Training loss: 5.9488205909729
Validation loss: 5.374941448370616

Epoch: 5| Step: 6
Training loss: 5.791529178619385
Validation loss: 5.37308673063914

Epoch: 5| Step: 7
Training loss: 4.7206830978393555
Validation loss: 5.371044337749481

Epoch: 5| Step: 8
Training loss: 5.0186543464660645
Validation loss: 5.369015574455261

Epoch: 5| Step: 9
Training loss: 5.093842506408691
Validation loss: 5.366896629333496

Epoch: 5| Step: 10
Training loss: 5.889166355133057
Validation loss: 5.364714125792186

Epoch: 5| Step: 11
Training loss: 6.9735002517700195
Validation loss: 5.362311681111653

Epoch: 2| Step: 0
Training loss: 5.699827671051025
Validation loss: 5.359956343968709

Epoch: 5| Step: 1
Training loss: 6.370563507080078
Validation loss: 5.357456227143605

Epoch: 5| Step: 2
Training loss: 6.226385116577148
Validation loss: 5.354786952336629

Epoch: 5| Step: 3
Training loss: 4.901066780090332
Validation loss: 5.352111001809438

Epoch: 5| Step: 4
Training loss: 4.50023889541626
Validation loss: 5.349298516909282

Epoch: 5| Step: 5
Training loss: 5.8302483558654785
Validation loss: 5.346194386482239

Epoch: 5| Step: 6
Training loss: 4.928014755249023
Validation loss: 5.342920899391174

Epoch: 5| Step: 7
Training loss: 6.409441947937012
Validation loss: 5.339524547259013

Epoch: 5| Step: 8
Training loss: 4.827939033508301
Validation loss: 5.335963646570842

Epoch: 5| Step: 9
Training loss: 4.733260154724121
Validation loss: 5.33213484287262

Epoch: 5| Step: 10
Training loss: 4.647984027862549
Validation loss: 5.328294595082601

Epoch: 5| Step: 11
Training loss: 7.803893089294434
Validation loss: 5.323986132939656

Epoch: 3| Step: 0
Training loss: 6.188093185424805
Validation loss: 5.319450120131175

Epoch: 5| Step: 1
Training loss: 5.268231391906738
Validation loss: 5.3147092461586

Epoch: 5| Step: 2
Training loss: 5.483878135681152
Validation loss: 5.309817930062612

Epoch: 5| Step: 3
Training loss: 5.542799472808838
Validation loss: 5.304760932922363

Epoch: 5| Step: 4
Training loss: 5.904193878173828
Validation loss: 5.299242854118347

Epoch: 5| Step: 5
Training loss: 5.679434299468994
Validation loss: 5.293436884880066

Epoch: 5| Step: 6
Training loss: 5.315741539001465
Validation loss: 5.287232041358948

Epoch: 5| Step: 7
Training loss: 4.661402702331543
Validation loss: 5.280965626239777

Epoch: 5| Step: 8
Training loss: 4.946383476257324
Validation loss: 5.274324516455333

Epoch: 5| Step: 9
Training loss: 4.687211513519287
Validation loss: 5.267423152923584

Epoch: 5| Step: 10
Training loss: 5.220856666564941
Validation loss: 5.260091821352641

Epoch: 5| Step: 11
Training loss: 5.711038589477539
Validation loss: 5.252536157766978

Epoch: 4| Step: 0
Training loss: 6.242191314697266
Validation loss: 5.244814236958821

Epoch: 5| Step: 1
Training loss: 4.234487533569336
Validation loss: 5.236616492271423

Epoch: 5| Step: 2
Training loss: 5.051116466522217
Validation loss: 5.228251834710439

Epoch: 5| Step: 3
Training loss: 5.009915828704834
Validation loss: 5.219836175441742

Epoch: 5| Step: 4
Training loss: 6.395228385925293
Validation loss: 5.21104250351588

Epoch: 5| Step: 5
Training loss: 4.809908866882324
Validation loss: 5.20167859395345

Epoch: 5| Step: 6
Training loss: 4.841940879821777
Validation loss: 5.192336658636729

Epoch: 5| Step: 7
Training loss: 5.379220485687256
Validation loss: 5.182566682497661

Epoch: 5| Step: 8
Training loss: 5.649846076965332
Validation loss: 5.172882874806722

Epoch: 5| Step: 9
Training loss: 5.349371433258057
Validation loss: 5.162686904271443

Epoch: 5| Step: 10
Training loss: 4.72798490524292
Validation loss: 5.15234375

Epoch: 5| Step: 11
Training loss: 6.7387237548828125
Validation loss: 5.141621430714925

Epoch: 5| Step: 0
Training loss: 4.661948204040527
Validation loss: 5.131094654401143

Epoch: 5| Step: 1
Training loss: 5.128461837768555
Validation loss: 5.120110114415486

Epoch: 5| Step: 2
Training loss: 5.318482398986816
Validation loss: 5.109009703000386

Epoch: 5| Step: 3
Training loss: 6.046811103820801
Validation loss: 5.097688943147659

Epoch: 5| Step: 4
Training loss: 5.024875640869141
Validation loss: 5.085793872674306

Epoch: 5| Step: 5
Training loss: 3.88739275932312
Validation loss: 5.073858877023061

Epoch: 5| Step: 6
Training loss: 4.90018367767334
Validation loss: 5.061555763085683

Epoch: 5| Step: 7
Training loss: 4.979783535003662
Validation loss: 5.049350718657176

Epoch: 5| Step: 8
Training loss: 5.509352207183838
Validation loss: 5.0370655457178755

Epoch: 5| Step: 9
Training loss: 5.123912334442139
Validation loss: 5.023885091145833

Epoch: 5| Step: 10
Training loss: 5.732691287994385
Validation loss: 5.011017362276713

Epoch: 5| Step: 11
Training loss: 6.690781593322754
Validation loss: 4.997974276542664

Epoch: 6| Step: 0
Training loss: 5.054508686065674
Validation loss: 4.984952171643575

Epoch: 5| Step: 1
Training loss: 5.278923988342285
Validation loss: 4.9718047976493835

Epoch: 5| Step: 2
Training loss: 5.816405773162842
Validation loss: 4.958420157432556

Epoch: 5| Step: 3
Training loss: 3.8936448097229004
Validation loss: 4.945149580637614

Epoch: 5| Step: 4
Training loss: 3.990926742553711
Validation loss: 4.9321942528088885

Epoch: 5| Step: 5
Training loss: 5.075018882751465
Validation loss: 4.918407032887141

Epoch: 5| Step: 6
Training loss: 5.337333679199219
Validation loss: 4.905089646577835

Epoch: 5| Step: 7
Training loss: 5.169973373413086
Validation loss: 4.892495791117351

Epoch: 5| Step: 8
Training loss: 4.574233055114746
Validation loss: 4.87966005007426

Epoch: 5| Step: 9
Training loss: 5.407283782958984
Validation loss: 4.867183089256287

Epoch: 5| Step: 10
Training loss: 5.633134365081787
Validation loss: 4.854966799418132

Epoch: 5| Step: 11
Training loss: 3.883942127227783
Validation loss: 4.843189001083374

Epoch: 7| Step: 0
Training loss: 4.764374732971191
Validation loss: 4.831187228361766

Epoch: 5| Step: 1
Training loss: 4.636950492858887
Validation loss: 4.819198131561279

Epoch: 5| Step: 2
Training loss: 5.716078758239746
Validation loss: 4.80833766857783

Epoch: 5| Step: 3
Training loss: 4.422430992126465
Validation loss: 4.797221064567566

Epoch: 5| Step: 4
Training loss: 5.206498622894287
Validation loss: 4.786189476648967

Epoch: 5| Step: 5
Training loss: 4.865694522857666
Validation loss: 4.77548701564471

Epoch: 5| Step: 6
Training loss: 3.8902130126953125
Validation loss: 4.765009005864461

Epoch: 5| Step: 7
Training loss: 4.942715644836426
Validation loss: 4.754683196544647

Epoch: 5| Step: 8
Training loss: 5.58148717880249
Validation loss: 4.744461953639984

Epoch: 5| Step: 9
Training loss: 4.918784141540527
Validation loss: 4.7348272403081255

Epoch: 5| Step: 10
Training loss: 4.178359508514404
Validation loss: 4.724325338999431

Epoch: 5| Step: 11
Training loss: 6.842205047607422
Validation loss: 4.7148082454999285

Epoch: 8| Step: 0
Training loss: 4.209892749786377
Validation loss: 4.70506089925766

Epoch: 5| Step: 1
Training loss: 5.337586402893066
Validation loss: 4.695160984992981

Epoch: 5| Step: 2
Training loss: 4.308149814605713
Validation loss: 4.685613791147868

Epoch: 5| Step: 3
Training loss: 5.2863664627075195
Validation loss: 4.6758430401484175

Epoch: 5| Step: 4
Training loss: 4.978749752044678
Validation loss: 4.666553159554799

Epoch: 5| Step: 5
Training loss: 4.566775321960449
Validation loss: 4.657114128271739

Epoch: 5| Step: 6
Training loss: 4.768038272857666
Validation loss: 4.647810240586598

Epoch: 5| Step: 7
Training loss: 5.5905680656433105
Validation loss: 4.6390061775843305

Epoch: 5| Step: 8
Training loss: 4.45748233795166
Validation loss: 4.630276242891948

Epoch: 5| Step: 9
Training loss: 4.324105262756348
Validation loss: 4.622171779473622

Epoch: 5| Step: 10
Training loss: 4.693389415740967
Validation loss: 4.6148810386657715

Epoch: 5| Step: 11
Training loss: 3.533332586288452
Validation loss: 4.60692963997523

Epoch: 9| Step: 0
Training loss: 3.956143856048584
Validation loss: 4.600317080815633

Epoch: 5| Step: 1
Training loss: 4.276648998260498
Validation loss: 4.593414634466171

Epoch: 5| Step: 2
Training loss: 4.448046684265137
Validation loss: 4.586371531089147

Epoch: 5| Step: 3
Training loss: 4.807554721832275
Validation loss: 4.579541703065236

Epoch: 5| Step: 4
Training loss: 5.285794258117676
Validation loss: 4.572776297728221

Epoch: 5| Step: 5
Training loss: 5.228191375732422
Validation loss: 4.56681102514267

Epoch: 5| Step: 6
Training loss: 5.215550899505615
Validation loss: 4.560781180858612

Epoch: 5| Step: 7
Training loss: 5.378012180328369
Validation loss: 4.553695301214854

Epoch: 5| Step: 8
Training loss: 3.896514415740967
Validation loss: 4.54699123899142

Epoch: 5| Step: 9
Training loss: 4.791276454925537
Validation loss: 4.5407099823156996

Epoch: 5| Step: 10
Training loss: 4.244654178619385
Validation loss: 4.5341638922691345

Epoch: 5| Step: 11
Training loss: 3.6976823806762695
Validation loss: 4.528911004463832

Epoch: 10| Step: 0
Training loss: 5.332892417907715
Validation loss: 4.522947192192078

Epoch: 5| Step: 1
Training loss: 4.952385902404785
Validation loss: 4.5168183247248335

Epoch: 5| Step: 2
Training loss: 4.766313552856445
Validation loss: 4.511105895042419

Epoch: 5| Step: 3
Training loss: 4.1920976638793945
Validation loss: 4.505060374736786

Epoch: 5| Step: 4
Training loss: 4.034181118011475
Validation loss: 4.498552699883779

Epoch: 5| Step: 5
Training loss: 4.186756134033203
Validation loss: 4.492456297079722

Epoch: 5| Step: 6
Training loss: 4.627530574798584
Validation loss: 4.4868453939755755

Epoch: 5| Step: 7
Training loss: 4.232179641723633
Validation loss: 4.480922242005666

Epoch: 5| Step: 8
Training loss: 4.971763610839844
Validation loss: 4.4746495087941485

Epoch: 5| Step: 9
Training loss: 4.766963005065918
Validation loss: 4.468642125527064

Epoch: 5| Step: 10
Training loss: 4.738957405090332
Validation loss: 4.462468047936757

Epoch: 5| Step: 11
Training loss: 3.5604407787323
Validation loss: 4.456137140591939

Epoch: 11| Step: 0
Training loss: 3.984799861907959
Validation loss: 4.450541853904724

Epoch: 5| Step: 1
Training loss: 4.523921489715576
Validation loss: 4.444504578908284

Epoch: 5| Step: 2
Training loss: 4.437024116516113
Validation loss: 4.43871342142423

Epoch: 5| Step: 3
Training loss: 4.373693943023682
Validation loss: 4.43290243546168

Epoch: 5| Step: 4
Training loss: 4.5154008865356445
Validation loss: 4.427711645762126

Epoch: 5| Step: 5
Training loss: 4.15511417388916
Validation loss: 4.422172844409943

Epoch: 5| Step: 6
Training loss: 5.094126224517822
Validation loss: 4.41651514172554

Epoch: 5| Step: 7
Training loss: 3.8497397899627686
Validation loss: 4.4107478857040405

Epoch: 5| Step: 8
Training loss: 4.490718364715576
Validation loss: 4.405303001403809

Epoch: 5| Step: 9
Training loss: 5.696393013000488
Validation loss: 4.399306813875834

Epoch: 5| Step: 10
Training loss: 4.565239429473877
Validation loss: 4.3933518926302595

Epoch: 5| Step: 11
Training loss: 5.550541877746582
Validation loss: 4.387718280156453

Epoch: 12| Step: 0
Training loss: 4.8516740798950195
Validation loss: 4.382207582394282

Epoch: 5| Step: 1
Training loss: 3.7350590229034424
Validation loss: 4.376363436381022

Epoch: 5| Step: 2
Training loss: 4.373618125915527
Validation loss: 4.3708471556504565

Epoch: 5| Step: 3
Training loss: 4.912115573883057
Validation loss: 4.3649285435676575

Epoch: 5| Step: 4
Training loss: 4.346457481384277
Validation loss: 4.357392658789952

Epoch: 5| Step: 5
Training loss: 5.173863410949707
Validation loss: 4.351752996444702

Epoch: 5| Step: 6
Training loss: 4.058116436004639
Validation loss: 4.345507562160492

Epoch: 5| Step: 7
Training loss: 4.340824604034424
Validation loss: 4.3395236531893415

Epoch: 5| Step: 8
Training loss: 4.032147407531738
Validation loss: 4.3344699541727705

Epoch: 5| Step: 9
Training loss: 4.651546955108643
Validation loss: 4.32826030254364

Epoch: 5| Step: 10
Training loss: 4.848413467407227
Validation loss: 4.321684290965398

Epoch: 5| Step: 11
Training loss: 3.748114585876465
Validation loss: 4.315644760926564

Epoch: 13| Step: 0
Training loss: 5.231234073638916
Validation loss: 4.311293055613835

Epoch: 5| Step: 1
Training loss: 4.573063850402832
Validation loss: 4.304501215616862

Epoch: 5| Step: 2
Training loss: 4.645391941070557
Validation loss: 4.297432333230972

Epoch: 5| Step: 3
Training loss: 4.436224460601807
Validation loss: 4.291363934675853

Epoch: 5| Step: 4
Training loss: 4.055842399597168
Validation loss: 4.286405275265376

Epoch: 5| Step: 5
Training loss: 4.666859149932861
Validation loss: 4.281417657931645

Epoch: 5| Step: 6
Training loss: 4.656301975250244
Validation loss: 4.276458660761516

Epoch: 5| Step: 7
Training loss: 5.117959976196289
Validation loss: 4.271371444066365

Epoch: 5| Step: 8
Training loss: 2.9451966285705566
Validation loss: 4.265514433383942

Epoch: 5| Step: 9
Training loss: 4.766844272613525
Validation loss: 4.260597904523213

Epoch: 5| Step: 10
Training loss: 3.4200732707977295
Validation loss: 4.2549153963724775

Epoch: 5| Step: 11
Training loss: 4.321308135986328
Validation loss: 4.250141431887944

Epoch: 14| Step: 0
Training loss: 3.3130087852478027
Validation loss: 4.2453921139240265

Epoch: 5| Step: 1
Training loss: 4.193191051483154
Validation loss: 4.240516980489095

Epoch: 5| Step: 2
Training loss: 4.631636142730713
Validation loss: 4.235582113265991

Epoch: 5| Step: 3
Training loss: 4.95438814163208
Validation loss: 4.230494936307271

Epoch: 5| Step: 4
Training loss: 3.72016978263855
Validation loss: 4.225238253672917

Epoch: 5| Step: 5
Training loss: 5.051626682281494
Validation loss: 4.21954204638799

Epoch: 5| Step: 6
Training loss: 3.949909210205078
Validation loss: 4.214865247408549

Epoch: 5| Step: 7
Training loss: 4.909804344177246
Validation loss: 4.2075852652390795

Epoch: 5| Step: 8
Training loss: 3.9157702922821045
Validation loss: 4.1996961037317915

Epoch: 5| Step: 9
Training loss: 5.340738773345947
Validation loss: 4.1934832235177355

Epoch: 5| Step: 10
Training loss: 3.563798189163208
Validation loss: 4.188613583644231

Epoch: 5| Step: 11
Training loss: 5.861084938049316
Validation loss: 4.184095660845439

Epoch: 15| Step: 0
Training loss: 4.374738693237305
Validation loss: 4.179443885882695

Epoch: 5| Step: 1
Training loss: 3.971623659133911
Validation loss: 4.174605806668599

Epoch: 5| Step: 2
Training loss: 5.21675968170166
Validation loss: 4.169230331977208

Epoch: 5| Step: 3
Training loss: 3.3133111000061035
Validation loss: 4.164381156365077

Epoch: 5| Step: 4
Training loss: 3.8039402961730957
Validation loss: 4.1590682665507

Epoch: 5| Step: 5
Training loss: 4.286322116851807
Validation loss: 4.153850297133128

Epoch: 5| Step: 6
Training loss: 4.823363304138184
Validation loss: 4.148743361234665

Epoch: 5| Step: 7
Training loss: 4.33835506439209
Validation loss: 4.1438566247622175

Epoch: 5| Step: 8
Training loss: 4.4898858070373535
Validation loss: 4.13870773712794

Epoch: 5| Step: 9
Training loss: 4.192246437072754
Validation loss: 4.133791585763295

Epoch: 5| Step: 10
Training loss: 4.493035793304443
Validation loss: 4.128898531198502

Epoch: 5| Step: 11
Training loss: 3.755878448486328
Validation loss: 4.123632570107778

Epoch: 16| Step: 0
Training loss: 4.076826095581055
Validation loss: 4.1186448733011884

Epoch: 5| Step: 1
Training loss: 4.2458624839782715
Validation loss: 4.113632490237554

Epoch: 5| Step: 2
Training loss: 3.7746245861053467
Validation loss: 4.108572900295258

Epoch: 5| Step: 3
Training loss: 4.889529228210449
Validation loss: 4.10413904984792

Epoch: 5| Step: 4
Training loss: 4.641934394836426
Validation loss: 4.098662942647934

Epoch: 5| Step: 5
Training loss: 4.337624549865723
Validation loss: 4.0934553146362305

Epoch: 5| Step: 6
Training loss: 3.1927859783172607
Validation loss: 4.088754564523697

Epoch: 5| Step: 7
Training loss: 4.39622688293457
Validation loss: 4.0834744572639465

Epoch: 5| Step: 8
Training loss: 4.119349956512451
Validation loss: 4.078873763481776

Epoch: 5| Step: 9
Training loss: 3.784686326980591
Validation loss: 4.073732962210973

Epoch: 5| Step: 10
Training loss: 4.957211017608643
Validation loss: 4.068981985251109

Epoch: 5| Step: 11
Training loss: 5.017362594604492
Validation loss: 4.06427788734436

Epoch: 17| Step: 0
Training loss: 3.3724396228790283
Validation loss: 4.0599081714948015

Epoch: 5| Step: 1
Training loss: 4.813873291015625
Validation loss: 4.055989901224772

Epoch: 5| Step: 2
Training loss: 5.232320785522461
Validation loss: 4.051610678434372

Epoch: 5| Step: 3
Training loss: 3.734858274459839
Validation loss: 4.046373009681702

Epoch: 5| Step: 4
Training loss: 4.127164840698242
Validation loss: 4.041403065125148

Epoch: 5| Step: 5
Training loss: 4.357146263122559
Validation loss: 4.036525438229243

Epoch: 5| Step: 6
Training loss: 4.78870153427124
Validation loss: 4.0316079159577685

Epoch: 5| Step: 7
Training loss: 2.8373494148254395
Validation loss: 4.027038246393204

Epoch: 5| Step: 8
Training loss: 4.248992443084717
Validation loss: 4.023195952177048

Epoch: 5| Step: 9
Training loss: 4.488286018371582
Validation loss: 4.017578800519307

Epoch: 5| Step: 10
Training loss: 3.622736692428589
Validation loss: 4.012954165538152

Epoch: 5| Step: 11
Training loss: 5.9810333251953125
Validation loss: 4.008556475241979

Epoch: 18| Step: 0
Training loss: 4.6182451248168945
Validation loss: 4.00401892264684

Epoch: 5| Step: 1
Training loss: 3.1962838172912598
Validation loss: 3.9992346465587616

Epoch: 5| Step: 2
Training loss: 3.7331509590148926
Validation loss: 3.99422096212705

Epoch: 5| Step: 3
Training loss: 4.647080421447754
Validation loss: 3.9899244209130607

Epoch: 5| Step: 4
Training loss: 4.4611945152282715
Validation loss: 3.9846814473470054

Epoch: 5| Step: 5
Training loss: 3.1667490005493164
Validation loss: 3.9800371328989663

Epoch: 5| Step: 6
Training loss: 3.976339817047119
Validation loss: 3.9748211105664573

Epoch: 5| Step: 7
Training loss: 5.113091945648193
Validation loss: 3.9700583616892495

Epoch: 5| Step: 8
Training loss: 4.19613790512085
Validation loss: 3.9648740688959756

Epoch: 5| Step: 9
Training loss: 3.1817870140075684
Validation loss: 3.960425078868866

Epoch: 5| Step: 10
Training loss: 4.6412224769592285
Validation loss: 3.956525444984436

Epoch: 5| Step: 11
Training loss: 6.378931999206543
Validation loss: 3.951033224662145

Epoch: 19| Step: 0
Training loss: 3.665808916091919
Validation loss: 3.946164886156718

Epoch: 5| Step: 1
Training loss: 3.86749005317688
Validation loss: 3.9419631560643515

Epoch: 5| Step: 2
Training loss: 4.523263931274414
Validation loss: 3.9378419121106467

Epoch: 5| Step: 3
Training loss: 4.017284393310547
Validation loss: 3.9335672756036124

Epoch: 5| Step: 4
Training loss: 3.618370771408081
Validation loss: 3.928966442743937

Epoch: 5| Step: 5
Training loss: 3.5361874103546143
Validation loss: 3.9241050084431968

Epoch: 5| Step: 6
Training loss: 5.14822244644165
Validation loss: 3.9188904960950217

Epoch: 5| Step: 7
Training loss: 4.143448352813721
Validation loss: 3.9145873685677848

Epoch: 5| Step: 8
Training loss: 3.7493629455566406
Validation loss: 3.9097234308719635

Epoch: 5| Step: 9
Training loss: 3.7009525299072266
Validation loss: 3.905317485332489

Epoch: 5| Step: 10
Training loss: 4.664860725402832
Validation loss: 3.9006024400393167

Epoch: 5| Step: 11
Training loss: 4.7622904777526855
Validation loss: 3.8958407938480377

Epoch: 20| Step: 0
Training loss: 4.624499320983887
Validation loss: 3.8911718229452767

Epoch: 5| Step: 1
Training loss: 3.875588893890381
Validation loss: 3.887410600980123

Epoch: 5| Step: 2
Training loss: 3.268962860107422
Validation loss: 3.883083979288737

Epoch: 5| Step: 3
Training loss: 4.278575897216797
Validation loss: 3.8783903221289315

Epoch: 5| Step: 4
Training loss: 4.18993616104126
Validation loss: 3.874160567919413

Epoch: 5| Step: 5
Training loss: 4.357710838317871
Validation loss: 3.868875910838445

Epoch: 5| Step: 6
Training loss: 3.9334330558776855
Validation loss: 3.8640239040056863

Epoch: 5| Step: 7
Training loss: 4.169699192047119
Validation loss: 3.859758128722509

Epoch: 5| Step: 8
Training loss: 4.114927291870117
Validation loss: 3.8552501797676086

Epoch: 5| Step: 9
Training loss: 3.6249775886535645
Validation loss: 3.850591152906418

Epoch: 5| Step: 10
Training loss: 3.8427493572235107
Validation loss: 3.8460192581017814

Epoch: 5| Step: 11
Training loss: 3.6849284172058105
Validation loss: 3.8409703274567923

Epoch: 21| Step: 0
Training loss: 4.941498756408691
Validation loss: 3.8360626498858132

Epoch: 5| Step: 1
Training loss: 3.5207085609436035
Validation loss: 3.8306704461574554

Epoch: 5| Step: 2
Training loss: 4.278435707092285
Validation loss: 3.8256931801637015

Epoch: 5| Step: 3
Training loss: 4.118988990783691
Validation loss: 3.8218196829160056

Epoch: 5| Step: 4
Training loss: 3.5206878185272217
Validation loss: 3.817403733730316

Epoch: 5| Step: 5
Training loss: 4.25260066986084
Validation loss: 3.813256154457728

Epoch: 5| Step: 6
Training loss: 3.6661689281463623
Validation loss: 3.8079670468966165

Epoch: 5| Step: 7
Training loss: 3.3723747730255127
Validation loss: 3.805059472719828

Epoch: 5| Step: 8
Training loss: 3.61790132522583
Validation loss: 3.800339957078298

Epoch: 5| Step: 9
Training loss: 3.3060684204101562
Validation loss: 3.794746180375417

Epoch: 5| Step: 10
Training loss: 4.956072807312012
Validation loss: 3.7897590895493827

Epoch: 5| Step: 11
Training loss: 4.429815769195557
Validation loss: 3.78635436296463

Epoch: 22| Step: 0
Training loss: 3.3871262073516846
Validation loss: 3.781534900267919

Epoch: 5| Step: 1
Training loss: 3.389514923095703
Validation loss: 3.777511805295944

Epoch: 5| Step: 2
Training loss: 4.171916484832764
Validation loss: 3.7732032239437103

Epoch: 5| Step: 3
Training loss: 4.241798400878906
Validation loss: 3.769049863020579

Epoch: 5| Step: 4
Training loss: 4.679757118225098
Validation loss: 3.764774630467097

Epoch: 5| Step: 5
Training loss: 4.5242462158203125
Validation loss: 3.7603383461634317

Epoch: 5| Step: 6
Training loss: 3.6358132362365723
Validation loss: 3.755999912818273

Epoch: 5| Step: 7
Training loss: 3.6072146892547607
Validation loss: 3.751633942127228

Epoch: 5| Step: 8
Training loss: 3.464984178543091
Validation loss: 3.7471067706743875

Epoch: 5| Step: 9
Training loss: 4.5884270668029785
Validation loss: 3.7430224617322287

Epoch: 5| Step: 10
Training loss: 3.637453079223633
Validation loss: 3.7385661900043488

Epoch: 5| Step: 11
Training loss: 2.708848476409912
Validation loss: 3.733638127644857

Epoch: 23| Step: 0
Training loss: 3.722508192062378
Validation loss: 3.730540951093038

Epoch: 5| Step: 1
Training loss: 3.781716823577881
Validation loss: 3.7259612580140433

Epoch: 5| Step: 2
Training loss: 4.754942893981934
Validation loss: 3.7222587565581002

Epoch: 5| Step: 3
Training loss: 3.771813154220581
Validation loss: 3.718440890312195

Epoch: 5| Step: 4
Training loss: 4.30756950378418
Validation loss: 3.7130433221658072

Epoch: 5| Step: 5
Training loss: 3.759150743484497
Validation loss: 3.708831419547399

Epoch: 5| Step: 6
Training loss: 3.7982230186462402
Validation loss: 3.7052250107129416

Epoch: 5| Step: 7
Training loss: 3.7625930309295654
Validation loss: 3.7009854714075723

Epoch: 5| Step: 8
Training loss: 3.458278179168701
Validation loss: 3.6962701876958213

Epoch: 5| Step: 9
Training loss: 3.4809746742248535
Validation loss: 3.6921895146369934

Epoch: 5| Step: 10
Training loss: 3.9507343769073486
Validation loss: 3.688594420750936

Epoch: 5| Step: 11
Training loss: 4.036378860473633
Validation loss: 3.6842046678066254

Epoch: 24| Step: 0
Training loss: 3.45367693901062
Validation loss: 3.680091083049774

Epoch: 5| Step: 1
Training loss: 3.7465362548828125
Validation loss: 3.6760092278321586

Epoch: 5| Step: 2
Training loss: 3.9469573497772217
Validation loss: 3.6719598472118378

Epoch: 5| Step: 3
Training loss: 4.662275791168213
Validation loss: 3.667719841003418

Epoch: 5| Step: 4
Training loss: 3.7684550285339355
Validation loss: 3.663666089375814

Epoch: 5| Step: 5
Training loss: 3.63635516166687
Validation loss: 3.659954239924749

Epoch: 5| Step: 6
Training loss: 4.039867401123047
Validation loss: 3.6562243501345315

Epoch: 5| Step: 7
Training loss: 3.3774497509002686
Validation loss: 3.6522209544976554

Epoch: 5| Step: 8
Training loss: 3.913609266281128
Validation loss: 3.647633204857508

Epoch: 5| Step: 9
Training loss: 4.048714637756348
Validation loss: 3.6433202226956687

Epoch: 5| Step: 10
Training loss: 3.5260727405548096
Validation loss: 3.6389707724253335

Epoch: 5| Step: 11
Training loss: 3.369657039642334
Validation loss: 3.634620507558187

Epoch: 25| Step: 0
Training loss: 3.9597268104553223
Validation loss: 3.6306886672973633

Epoch: 5| Step: 1
Training loss: 3.771181583404541
Validation loss: 3.6262427866458893

Epoch: 5| Step: 2
Training loss: 3.8735642433166504
Validation loss: 3.622261176506678

Epoch: 5| Step: 3
Training loss: 4.1722846031188965
Validation loss: 3.617903252442678

Epoch: 5| Step: 4
Training loss: 3.1353976726531982
Validation loss: 3.613163044055303

Epoch: 5| Step: 5
Training loss: 3.6281604766845703
Validation loss: 3.608984569708506

Epoch: 5| Step: 6
Training loss: 3.980750560760498
Validation loss: 3.6046649714310965

Epoch: 5| Step: 7
Training loss: 4.558284282684326
Validation loss: 3.6004386246204376

Epoch: 5| Step: 8
Training loss: 3.2098135948181152
Validation loss: 3.5966041882832847

Epoch: 5| Step: 9
Training loss: 3.9257712364196777
Validation loss: 3.5923064053058624

Epoch: 5| Step: 10
Training loss: 3.5617737770080566
Validation loss: 3.5884238481521606

Epoch: 5| Step: 11
Training loss: 2.41274356842041
Validation loss: 3.583893964687983

Epoch: 26| Step: 0
Training loss: 3.767251491546631
Validation loss: 3.5800468424956002

Epoch: 5| Step: 1
Training loss: 4.882501125335693
Validation loss: 3.575719783703486

Epoch: 5| Step: 2
Training loss: 3.213848829269409
Validation loss: 3.5722589989503226

Epoch: 5| Step: 3
Training loss: 3.346604824066162
Validation loss: 3.567986379067103

Epoch: 5| Step: 4
Training loss: 4.241580963134766
Validation loss: 3.563930650552114

Epoch: 5| Step: 5
Training loss: 3.7147529125213623
Validation loss: 3.5604502062002816

Epoch: 5| Step: 6
Training loss: 3.8481998443603516
Validation loss: 3.5564574102560678

Epoch: 5| Step: 7
Training loss: 3.399399995803833
Validation loss: 3.5510244766871133

Epoch: 5| Step: 8
Training loss: 3.2097434997558594
Validation loss: 3.5473958949247995

Epoch: 5| Step: 9
Training loss: 3.5284194946289062
Validation loss: 3.5427448451519012

Epoch: 5| Step: 10
Training loss: 4.160801887512207
Validation loss: 3.538392335176468

Epoch: 5| Step: 11
Training loss: 1.8883023262023926
Validation loss: 3.5340887904167175

Epoch: 27| Step: 0
Training loss: 3.0105154514312744
Validation loss: 3.529520849386851

Epoch: 5| Step: 1
Training loss: 3.2496418952941895
Validation loss: 3.525289316972097

Epoch: 5| Step: 2
Training loss: 3.3170018196105957
Validation loss: 3.520062963167826

Epoch: 5| Step: 3
Training loss: 3.504671573638916
Validation loss: 3.5157318115234375

Epoch: 5| Step: 4
Training loss: 4.047942161560059
Validation loss: 3.510752350091934

Epoch: 5| Step: 5
Training loss: 2.982241153717041
Validation loss: 3.507010668516159

Epoch: 5| Step: 6
Training loss: 3.389611005783081
Validation loss: 3.505295137564341

Epoch: 5| Step: 7
Training loss: 4.326565265655518
Validation loss: 3.50901930530866

Epoch: 5| Step: 8
Training loss: 4.015332221984863
Validation loss: 3.4945029517014823

Epoch: 5| Step: 9
Training loss: 3.8714282512664795
Validation loss: 3.4906714061896005

Epoch: 5| Step: 10
Training loss: 4.425351142883301
Validation loss: 3.4845041632652283

Epoch: 5| Step: 11
Training loss: 4.9502668380737305
Validation loss: 3.480159729719162

Epoch: 28| Step: 0
Training loss: 2.9690346717834473
Validation loss: 3.4754596451918283

Epoch: 5| Step: 1
Training loss: 3.4299519062042236
Validation loss: 3.4721991618474326

Epoch: 5| Step: 2
Training loss: 3.3254363536834717
Validation loss: 3.4659540355205536

Epoch: 5| Step: 3
Training loss: 3.873319625854492
Validation loss: 3.4632072846094766

Epoch: 5| Step: 4
Training loss: 3.5053398609161377
Validation loss: 3.4570176899433136

Epoch: 5| Step: 5
Training loss: 3.6748263835906982
Validation loss: 3.4528449376424155

Epoch: 5| Step: 6
Training loss: 3.9821715354919434
Validation loss: 3.4491098721822104

Epoch: 5| Step: 7
Training loss: 3.506934404373169
Validation loss: 3.443777581055959

Epoch: 5| Step: 8
Training loss: 3.80798077583313
Validation loss: 3.4389301339785256

Epoch: 5| Step: 9
Training loss: 3.9435417652130127
Validation loss: 3.4363946517308555

Epoch: 5| Step: 10
Training loss: 3.969437837600708
Validation loss: 3.432433952887853

Epoch: 5| Step: 11
Training loss: 2.7051761150360107
Validation loss: 3.4270779291788735

Epoch: 29| Step: 0
Training loss: 3.194301128387451
Validation loss: 3.4235332111517587

Epoch: 5| Step: 1
Training loss: 3.8681321144104004
Validation loss: 3.418270081281662

Epoch: 5| Step: 2
Training loss: 3.720562696456909
Validation loss: 3.4142173131306968

Epoch: 5| Step: 3
Training loss: 3.6338391304016113
Validation loss: 3.4082294702529907

Epoch: 5| Step: 4
Training loss: 3.8061935901641846
Validation loss: 3.403438170750936

Epoch: 5| Step: 5
Training loss: 3.2261765003204346
Validation loss: 3.4009658296902976

Epoch: 5| Step: 6
Training loss: 3.902073621749878
Validation loss: 3.3962319592634835

Epoch: 5| Step: 7
Training loss: 3.1131460666656494
Validation loss: 3.3914068738619485

Epoch: 5| Step: 8
Training loss: 3.285738468170166
Validation loss: 3.3883129854997

Epoch: 5| Step: 9
Training loss: 3.5482089519500732
Validation loss: 3.3833770155906677

Epoch: 5| Step: 10
Training loss: 4.028029441833496
Validation loss: 3.378999044497808

Epoch: 5| Step: 11
Training loss: 3.1295814514160156
Validation loss: 3.3732984960079193

Epoch: 30| Step: 0
Training loss: 3.9888625144958496
Validation loss: 3.3692611753940582

Epoch: 5| Step: 1
Training loss: 3.7352795600891113
Validation loss: 3.3656333684921265

Epoch: 5| Step: 2
Training loss: 3.361629009246826
Validation loss: 3.359850416580836

Epoch: 5| Step: 3
Training loss: 3.6819865703582764
Validation loss: 3.3557043969631195

Epoch: 5| Step: 4
Training loss: 2.7176997661590576
Validation loss: 3.350981593132019

Epoch: 5| Step: 5
Training loss: 4.045807838439941
Validation loss: 3.347056965033213

Epoch: 5| Step: 6
Training loss: 3.6150994300842285
Validation loss: 3.342141350110372

Epoch: 5| Step: 7
Training loss: 3.8297646045684814
Validation loss: 3.338120182355245

Epoch: 5| Step: 8
Training loss: 4.096349239349365
Validation loss: 3.333866228659948

Epoch: 5| Step: 9
Training loss: 3.0058481693267822
Validation loss: 3.3283636768658957

Epoch: 5| Step: 10
Training loss: 3.0383191108703613
Validation loss: 3.324068268140157

Epoch: 5| Step: 11
Training loss: 1.452430009841919
Validation loss: 3.3196010688940683

Epoch: 31| Step: 0
Training loss: 3.74212646484375
Validation loss: 3.316194256146749

Epoch: 5| Step: 1
Training loss: 3.4245219230651855
Validation loss: 3.313125342130661

Epoch: 5| Step: 2
Training loss: 3.853842258453369
Validation loss: 3.3092412253220878

Epoch: 5| Step: 3
Training loss: 2.822160243988037
Validation loss: 3.3056143621603646

Epoch: 5| Step: 4
Training loss: 4.001925945281982
Validation loss: 3.3012081483999887

Epoch: 5| Step: 5
Training loss: 3.638408660888672
Validation loss: 3.296100894610087

Epoch: 5| Step: 6
Training loss: 3.0898056030273438
Validation loss: 3.2929907143115997

Epoch: 5| Step: 7
Training loss: 3.3313663005828857
Validation loss: 3.2890369296073914

Epoch: 5| Step: 8
Training loss: 2.769753932952881
Validation loss: 3.286811739206314

Epoch: 5| Step: 9
Training loss: 3.386132001876831
Validation loss: 3.28271355231603

Epoch: 5| Step: 10
Training loss: 3.764786958694458
Validation loss: 3.2788224716981254

Epoch: 5| Step: 11
Training loss: 5.3132805824279785
Validation loss: 3.274058828751246

Epoch: 32| Step: 0
Training loss: 3.8571534156799316
Validation loss: 3.2691823542118073

Epoch: 5| Step: 1
Training loss: 3.463144302368164
Validation loss: 3.2658352752526603

Epoch: 5| Step: 2
Training loss: 2.825256109237671
Validation loss: 3.2628976007302604

Epoch: 5| Step: 3
Training loss: 2.785588264465332
Validation loss: 3.257733384768168

Epoch: 5| Step: 4
Training loss: 3.492868423461914
Validation loss: 3.253572642803192

Epoch: 5| Step: 5
Training loss: 3.648118257522583
Validation loss: 3.247821480035782

Epoch: 5| Step: 6
Training loss: 3.1367850303649902
Validation loss: 3.2433576385180154

Epoch: 5| Step: 7
Training loss: 4.238528251647949
Validation loss: 3.2401617765426636

Epoch: 5| Step: 8
Training loss: 2.993690013885498
Validation loss: 3.2363727589448295

Epoch: 5| Step: 9
Training loss: 2.8339600563049316
Validation loss: 3.2412503759066262

Epoch: 5| Step: 10
Training loss: 3.9549002647399902
Validation loss: 3.2467730045318604

Epoch: 5| Step: 11
Training loss: 5.859171390533447
Validation loss: 3.222960333029429

Epoch: 33| Step: 0
Training loss: 3.6518139839172363
Validation loss: 3.219081530968348

Epoch: 5| Step: 1
Training loss: 3.6275317668914795
Validation loss: 3.2202337781588235

Epoch: 5| Step: 2
Training loss: 2.7206015586853027
Validation loss: 3.2216486036777496

Epoch: 5| Step: 3
Training loss: 2.8161258697509766
Validation loss: 3.2173786560694375

Epoch: 5| Step: 4
Training loss: 4.070920467376709
Validation loss: 3.2117871244748435

Epoch: 5| Step: 5
Training loss: 3.221426486968994
Validation loss: 3.206523964802424

Epoch: 5| Step: 6
Training loss: 3.4894676208496094
Validation loss: 3.199172685543696

Epoch: 5| Step: 7
Training loss: 3.6549789905548096
Validation loss: 3.193836987018585

Epoch: 5| Step: 8
Training loss: 3.0951859951019287
Validation loss: 3.1892875830332437

Epoch: 5| Step: 9
Training loss: 2.9344260692596436
Validation loss: 3.1862574021021524

Epoch: 5| Step: 10
Training loss: 3.809174060821533
Validation loss: 3.184547632932663

Epoch: 5| Step: 11
Training loss: 4.098156452178955
Validation loss: 3.1834807991981506

Epoch: 34| Step: 0
Training loss: 2.9508450031280518
Validation loss: 3.17704846461614

Epoch: 5| Step: 1
Training loss: 3.706521987915039
Validation loss: 3.170961191256841

Epoch: 5| Step: 2
Training loss: 3.2566370964050293
Validation loss: 3.165707677602768

Epoch: 5| Step: 3
Training loss: 2.7146809101104736
Validation loss: 3.160352329413096

Epoch: 5| Step: 4
Training loss: 3.2919745445251465
Validation loss: 3.154559701681137

Epoch: 5| Step: 5
Training loss: 4.00021505355835
Validation loss: 3.1489077111085257

Epoch: 5| Step: 6
Training loss: 2.5936713218688965
Validation loss: 3.144402325153351

Epoch: 5| Step: 7
Training loss: 4.047406196594238
Validation loss: 3.1401807069778442

Epoch: 5| Step: 8
Training loss: 3.861063003540039
Validation loss: 3.1357966462771096

Epoch: 5| Step: 9
Training loss: 3.5215344429016113
Validation loss: 3.1318077544371286

Epoch: 5| Step: 10
Training loss: 2.835257053375244
Validation loss: 3.1274668673674264

Epoch: 5| Step: 11
Training loss: 2.8389689922332764
Validation loss: 3.123424857854843

Epoch: 35| Step: 0
Training loss: 3.171452045440674
Validation loss: 3.1194642086823783

Epoch: 5| Step: 1
Training loss: 3.1701018810272217
Validation loss: 3.115551541248957

Epoch: 5| Step: 2
Training loss: 4.157837390899658
Validation loss: 3.1113981008529663

Epoch: 5| Step: 3
Training loss: 3.3964505195617676
Validation loss: 3.1070256729920707

Epoch: 5| Step: 4
Training loss: 3.2160401344299316
Validation loss: 3.1024611393610635

Epoch: 5| Step: 5
Training loss: 2.858886241912842
Validation loss: 3.0986914734045663

Epoch: 5| Step: 6
Training loss: 2.531752824783325
Validation loss: 3.0943317910035453

Epoch: 5| Step: 7
Training loss: 3.352478504180908
Validation loss: 3.090249498685201

Epoch: 5| Step: 8
Training loss: 3.1308491230010986
Validation loss: 3.086594263712565

Epoch: 5| Step: 9
Training loss: 3.5201163291931152
Validation loss: 3.0824775795141854

Epoch: 5| Step: 10
Training loss: 3.863241672515869
Validation loss: 3.077577362457911

Epoch: 5| Step: 11
Training loss: 2.1523239612579346
Validation loss: 3.076298495133718

Epoch: 36| Step: 0
Training loss: 3.5073094367980957
Validation loss: 3.0706182420253754

Epoch: 5| Step: 1
Training loss: 3.4154553413391113
Validation loss: 3.0666641195615134

Epoch: 5| Step: 2
Training loss: 3.2405993938446045
Validation loss: 3.063937912384669

Epoch: 5| Step: 3
Training loss: 2.855419635772705
Validation loss: 3.0600981016953788

Epoch: 5| Step: 4
Training loss: 3.220690965652466
Validation loss: 3.061200519402822

Epoch: 5| Step: 5
Training loss: 3.3803305625915527
Validation loss: 3.0604897340138755

Epoch: 5| Step: 6
Training loss: 3.5290966033935547
Validation loss: 3.0470252335071564

Epoch: 5| Step: 7
Training loss: 3.416572093963623
Validation loss: 3.04480442404747

Epoch: 5| Step: 8
Training loss: 3.1483771800994873
Validation loss: 3.0393786629041037

Epoch: 5| Step: 9
Training loss: 3.4303345680236816
Validation loss: 3.035948077837626

Epoch: 5| Step: 10
Training loss: 2.3379263877868652
Validation loss: 3.0334448417027793

Epoch: 5| Step: 11
Training loss: 4.14686393737793
Validation loss: 3.0322311023871102

Epoch: 37| Step: 0
Training loss: 3.1881327629089355
Validation loss: 3.0286222199598947

Epoch: 5| Step: 1
Training loss: 3.3203442096710205
Validation loss: 3.021255532900492

Epoch: 5| Step: 2
Training loss: 3.128485918045044
Validation loss: 3.01641054948171

Epoch: 5| Step: 3
Training loss: 3.5448875427246094
Validation loss: 3.0126845439275107

Epoch: 5| Step: 4
Training loss: 2.9692418575286865
Validation loss: 3.009894520044327

Epoch: 5| Step: 5
Training loss: 3.317330837249756
Validation loss: 3.007344881693522

Epoch: 5| Step: 6
Training loss: 3.750808000564575
Validation loss: 3.0026946465174356

Epoch: 5| Step: 7
Training loss: 3.1177449226379395
Validation loss: 2.9997717440128326

Epoch: 5| Step: 8
Training loss: 3.0221381187438965
Validation loss: 2.996088226636251

Epoch: 5| Step: 9
Training loss: 2.5697929859161377
Validation loss: 2.9941347936789193

Epoch: 5| Step: 10
Training loss: 3.420647382736206
Validation loss: 2.993602325518926

Epoch: 5| Step: 11
Training loss: 2.462691307067871
Validation loss: 2.9831875761349997

Epoch: 38| Step: 0
Training loss: 2.8921804428100586
Validation loss: 2.980458438396454

Epoch: 5| Step: 1
Training loss: 2.8267574310302734
Validation loss: 2.9771380623181662

Epoch: 5| Step: 2
Training loss: 2.872973680496216
Validation loss: 2.972316344579061

Epoch: 5| Step: 3
Training loss: 3.4663703441619873
Validation loss: 2.9691808223724365

Epoch: 5| Step: 4
Training loss: 3.601433277130127
Validation loss: 2.9663854042689004

Epoch: 5| Step: 5
Training loss: 2.3847718238830566
Validation loss: 2.964123477538427

Epoch: 5| Step: 6
Training loss: 2.844151496887207
Validation loss: 2.960338662068049

Epoch: 5| Step: 7
Training loss: 3.688864231109619
Validation loss: 2.957141866286596

Epoch: 5| Step: 8
Training loss: 3.631977081298828
Validation loss: 2.954038073619207

Epoch: 5| Step: 9
Training loss: 4.125700950622559
Validation loss: 2.950125058492025

Epoch: 5| Step: 10
Training loss: 2.522641658782959
Validation loss: 2.9461917678515115

Epoch: 5| Step: 11
Training loss: 2.771916389465332
Validation loss: 2.9424810806910195

Epoch: 39| Step: 0
Training loss: 3.7471625804901123
Validation loss: 2.938470184803009

Epoch: 5| Step: 1
Training loss: 2.6225833892822266
Validation loss: 2.934845378001531

Epoch: 5| Step: 2
Training loss: 2.6870908737182617
Validation loss: 2.9309783478577933

Epoch: 5| Step: 3
Training loss: 2.9796104431152344
Validation loss: 2.9290599127610526

Epoch: 5| Step: 4
Training loss: 3.7026684284210205
Validation loss: 2.925673613945643

Epoch: 5| Step: 5
Training loss: 3.0991435050964355
Validation loss: 2.9226787785689035

Epoch: 5| Step: 6
Training loss: 2.8437485694885254
Validation loss: 2.9193207820256553

Epoch: 5| Step: 7
Training loss: 2.5406126976013184
Validation loss: 2.914575845003128

Epoch: 5| Step: 8
Training loss: 3.1851248741149902
Validation loss: 2.913441280523936

Epoch: 5| Step: 9
Training loss: 3.5058434009552
Validation loss: 2.908883492151896

Epoch: 5| Step: 10
Training loss: 3.5920491218566895
Validation loss: 2.9068263371785483

Epoch: 5| Step: 11
Training loss: 2.37182879447937
Validation loss: 2.9057327806949615

Epoch: 40| Step: 0
Training loss: 2.599175214767456
Validation loss: 2.9006086885929108

Epoch: 5| Step: 1
Training loss: 3.0723652839660645
Validation loss: 2.8996085127194724

Epoch: 5| Step: 2
Training loss: 3.6575584411621094
Validation loss: 2.8982823888460794

Epoch: 5| Step: 3
Training loss: 2.4855446815490723
Validation loss: 2.901780108610789

Epoch: 5| Step: 4
Training loss: 3.7998440265655518
Validation loss: 2.927585552136103

Epoch: 5| Step: 5
Training loss: 3.5892558097839355
Validation loss: 2.971678485472997

Epoch: 5| Step: 6
Training loss: 3.1909403800964355
Validation loss: 2.8869991401831308

Epoch: 5| Step: 7
Training loss: 2.6076648235321045
Validation loss: 2.8761869768301644

Epoch: 5| Step: 8
Training loss: 3.03313946723938
Validation loss: 2.8746142288049064

Epoch: 5| Step: 9
Training loss: 2.8848178386688232
Validation loss: 2.890098383029302

Epoch: 5| Step: 10
Training loss: 3.254896879196167
Validation loss: 2.8984250823656716

Epoch: 5| Step: 11
Training loss: 2.9170799255371094
Validation loss: 2.900303542613983

Epoch: 41| Step: 0
Training loss: 3.1927621364593506
Validation loss: 2.9062016308307648

Epoch: 5| Step: 1
Training loss: 2.5497286319732666
Validation loss: 2.89028862118721

Epoch: 5| Step: 2
Training loss: 3.2061073780059814
Validation loss: 2.865660458803177

Epoch: 5| Step: 3
Training loss: 3.487114429473877
Validation loss: 2.8571031192938485

Epoch: 5| Step: 4
Training loss: 2.718900203704834
Validation loss: 2.8515895704428353

Epoch: 5| Step: 5
Training loss: 2.519895553588867
Validation loss: 2.8471924662590027

Epoch: 5| Step: 6
Training loss: 3.8036563396453857
Validation loss: 2.8435615499814353

Epoch: 5| Step: 7
Training loss: 2.5309977531433105
Validation loss: 2.8419926961263022

Epoch: 5| Step: 8
Training loss: 3.144984722137451
Validation loss: 2.8392092883586884

Epoch: 5| Step: 9
Training loss: 2.946861743927002
Validation loss: 2.838164875904719

Epoch: 5| Step: 10
Training loss: 3.6581802368164062
Validation loss: 2.8351032535235086

Epoch: 5| Step: 11
Training loss: 2.8038012981414795
Validation loss: 2.83390611410141

Epoch: 42| Step: 0
Training loss: 3.181459426879883
Validation loss: 2.829269369443258

Epoch: 5| Step: 1
Training loss: 3.2156577110290527
Validation loss: 2.826712946097056

Epoch: 5| Step: 2
Training loss: 3.2875239849090576
Validation loss: 2.8235808511575065

Epoch: 5| Step: 3
Training loss: 3.600594997406006
Validation loss: 2.8192670941352844

Epoch: 5| Step: 4
Training loss: 2.6612141132354736
Validation loss: 2.8139306803544364

Epoch: 5| Step: 5
Training loss: 2.956115245819092
Validation loss: 2.810761829217275

Epoch: 5| Step: 6
Training loss: 2.54590106010437
Validation loss: 2.80681178967158

Epoch: 5| Step: 7
Training loss: 2.7239160537719727
Validation loss: 2.802705148855845

Epoch: 5| Step: 8
Training loss: 3.49298095703125
Validation loss: 2.7993284364541373

Epoch: 5| Step: 9
Training loss: 2.9026265144348145
Validation loss: 2.797238598267237

Epoch: 5| Step: 10
Training loss: 2.8060219287872314
Validation loss: 2.7943141758441925

Epoch: 5| Step: 11
Training loss: 2.1503608226776123
Validation loss: 2.7913956344127655

Epoch: 43| Step: 0
Training loss: 3.126093626022339
Validation loss: 2.7864774962266288

Epoch: 5| Step: 1
Training loss: 3.207318067550659
Validation loss: 2.7838763296604156

Epoch: 5| Step: 2
Training loss: 3.3547263145446777
Validation loss: 2.77792293826739

Epoch: 5| Step: 3
Training loss: 2.7224931716918945
Validation loss: 2.7771318554878235

Epoch: 5| Step: 4
Training loss: 2.4274585247039795
Validation loss: 2.7752413749694824

Epoch: 5| Step: 5
Training loss: 3.152831554412842
Validation loss: 2.7745537062486014

Epoch: 5| Step: 6
Training loss: 2.894801616668701
Validation loss: 2.7701639334360757

Epoch: 5| Step: 7
Training loss: 3.350586414337158
Validation loss: 2.774128645658493

Epoch: 5| Step: 8
Training loss: 3.202775478363037
Validation loss: 2.7777445912361145

Epoch: 5| Step: 9
Training loss: 3.261648178100586
Validation loss: 2.7589947084585824

Epoch: 5| Step: 10
Training loss: 2.240830659866333
Validation loss: 2.7567662994066873

Epoch: 5| Step: 11
Training loss: 2.324448585510254
Validation loss: 2.7535347739855447

Epoch: 44| Step: 0
Training loss: 3.0923399925231934
Validation loss: 2.749387373526891

Epoch: 5| Step: 1
Training loss: 3.3729071617126465
Validation loss: 2.7485287884871163

Epoch: 5| Step: 2
Training loss: 3.286287784576416
Validation loss: 2.745301971832911

Epoch: 5| Step: 3
Training loss: 3.4106993675231934
Validation loss: 2.7455178797245026

Epoch: 5| Step: 4
Training loss: 2.598907947540283
Validation loss: 2.7426469326019287

Epoch: 5| Step: 5
Training loss: 2.2275550365448
Validation loss: 2.7394856909910836

Epoch: 5| Step: 6
Training loss: 2.686448812484741
Validation loss: 2.7359692454338074

Epoch: 5| Step: 7
Training loss: 2.9568285942077637
Validation loss: 2.733264227708181

Epoch: 5| Step: 8
Training loss: 2.553560972213745
Validation loss: 2.730807195107142

Epoch: 5| Step: 9
Training loss: 2.1644299030303955
Validation loss: 2.7270279129346213

Epoch: 5| Step: 10
Training loss: 3.7121124267578125
Validation loss: 2.7241669992605844

Epoch: 5| Step: 11
Training loss: 4.768105506896973
Validation loss: 2.7211920420328775

Epoch: 45| Step: 0
Training loss: 3.015399217605591
Validation loss: 2.7175436913967133

Epoch: 5| Step: 1
Training loss: 1.960831642150879
Validation loss: 2.712800145149231

Epoch: 5| Step: 2
Training loss: 2.824510097503662
Validation loss: 2.710624913374583

Epoch: 5| Step: 3
Training loss: 2.8708572387695312
Validation loss: 2.7074171155691147

Epoch: 5| Step: 4
Training loss: 3.4177443981170654
Validation loss: 2.7034464677174888

Epoch: 5| Step: 5
Training loss: 3.104562759399414
Validation loss: 2.700732558965683

Epoch: 5| Step: 6
Training loss: 2.618274450302124
Validation loss: 2.695704936981201

Epoch: 5| Step: 7
Training loss: 2.8772783279418945
Validation loss: 2.691947191953659

Epoch: 5| Step: 8
Training loss: 3.1819119453430176
Validation loss: 2.690090755621592

Epoch: 5| Step: 9
Training loss: 3.5249927043914795
Validation loss: 2.6869566837946572

Epoch: 5| Step: 10
Training loss: 2.7053346633911133
Validation loss: 2.6819609105587006

Epoch: 5| Step: 11
Training loss: 2.288217067718506
Validation loss: 2.6808094580968223

Epoch: 46| Step: 0
Training loss: 2.7931156158447266
Validation loss: 2.676148553689321

Epoch: 5| Step: 1
Training loss: 3.3191094398498535
Validation loss: 2.673306186993917

Epoch: 5| Step: 2
Training loss: 3.1941938400268555
Validation loss: 2.6712652246157327

Epoch: 5| Step: 3
Training loss: 2.7083611488342285
Validation loss: 2.668237497409185

Epoch: 5| Step: 4
Training loss: 2.511852741241455
Validation loss: 2.6653690735499063

Epoch: 5| Step: 5
Training loss: 3.5328431129455566
Validation loss: 2.6580688059329987

Epoch: 5| Step: 6
Training loss: 2.8609461784362793
Validation loss: 2.6573669016361237

Epoch: 5| Step: 7
Training loss: 2.1305925846099854
Validation loss: 2.6534229815006256

Epoch: 5| Step: 8
Training loss: 2.487879991531372
Validation loss: 2.651591887076696

Epoch: 5| Step: 9
Training loss: 3.3540573120117188
Validation loss: 2.646737426519394

Epoch: 5| Step: 10
Training loss: 2.8308327198028564
Validation loss: 2.6448229948679605

Epoch: 5| Step: 11
Training loss: 1.7911429405212402
Validation loss: 2.6420090893904367

Epoch: 47| Step: 0
Training loss: 2.714343786239624
Validation loss: 2.6369769871234894

Epoch: 5| Step: 1
Training loss: 3.5652477741241455
Validation loss: 2.634772777557373

Epoch: 5| Step: 2
Training loss: 2.7158310413360596
Validation loss: 2.6330083111921945

Epoch: 5| Step: 3
Training loss: 3.279682159423828
Validation loss: 2.6303573846817017

Epoch: 5| Step: 4
Training loss: 2.8294501304626465
Validation loss: 2.6268160790205

Epoch: 5| Step: 5
Training loss: 2.3130202293395996
Validation loss: 2.620788554350535

Epoch: 5| Step: 6
Training loss: 2.841212034225464
Validation loss: 2.616357853015264

Epoch: 5| Step: 7
Training loss: 2.4092211723327637
Validation loss: 2.6133979757626853

Epoch: 5| Step: 8
Training loss: 3.0068345069885254
Validation loss: 2.6112247308095298

Epoch: 5| Step: 9
Training loss: 2.8049211502075195
Validation loss: 2.6125787993272147

Epoch: 5| Step: 10
Training loss: 2.8884117603302
Validation loss: 2.6076683898766837

Epoch: 5| Step: 11
Training loss: 1.2921137809753418
Validation loss: 2.6100259919961295

Epoch: 48| Step: 0
Training loss: 2.0122992992401123
Validation loss: 2.6017954448858895

Epoch: 5| Step: 1
Training loss: 3.330235719680786
Validation loss: 2.6082977453867593

Epoch: 5| Step: 2
Training loss: 2.8462274074554443
Validation loss: 2.633149951696396

Epoch: 5| Step: 3
Training loss: 3.545963764190674
Validation loss: 2.6746083001295724

Epoch: 5| Step: 4
Training loss: 3.5847671031951904
Validation loss: 2.6895838578542075

Epoch: 5| Step: 5
Training loss: 2.872745990753174
Validation loss: 2.6825949450333915

Epoch: 5| Step: 6
Training loss: 2.5286598205566406
Validation loss: 2.6684056719144187

Epoch: 5| Step: 7
Training loss: 2.8861818313598633
Validation loss: 2.665393521388372

Epoch: 5| Step: 8
Training loss: 3.0823874473571777
Validation loss: 2.653239051500956

Epoch: 5| Step: 9
Training loss: 2.3558897972106934
Validation loss: 2.641572654247284

Epoch: 5| Step: 10
Training loss: 2.6518442630767822
Validation loss: 2.6359402338663735

Epoch: 5| Step: 11
Training loss: 1.145227074623108
Validation loss: 2.6282940904299417

Epoch: 49| Step: 0
Training loss: 2.814093589782715
Validation loss: 2.6232388814290366

Epoch: 5| Step: 1
Training loss: 2.7522308826446533
Validation loss: 2.616275201241175

Epoch: 5| Step: 2
Training loss: 3.1704230308532715
Validation loss: 2.6091152131557465

Epoch: 5| Step: 3
Training loss: 2.2136447429656982
Validation loss: 2.6009960075219474

Epoch: 5| Step: 4
Training loss: 3.1177802085876465
Validation loss: 2.5962882041931152

Epoch: 5| Step: 5
Training loss: 3.053640127182007
Validation loss: 2.5909441312154136

Epoch: 5| Step: 6
Training loss: 1.999518632888794
Validation loss: 2.5814742545286813

Epoch: 5| Step: 7
Training loss: 2.312574625015259
Validation loss: 2.569660638769468

Epoch: 5| Step: 8
Training loss: 2.89151930809021
Validation loss: 2.5602766573429108

Epoch: 5| Step: 9
Training loss: 2.9441940784454346
Validation loss: 2.5541662772496543

Epoch: 5| Step: 10
Training loss: 3.1239688396453857
Validation loss: 2.5497681697209678

Epoch: 5| Step: 11
Training loss: 4.011220932006836
Validation loss: 2.5461489260196686

Epoch: 50| Step: 0
Training loss: 2.4493916034698486
Validation loss: 2.5442215402921042

Epoch: 5| Step: 1
Training loss: 2.6674070358276367
Validation loss: 2.5398593147595725

Epoch: 5| Step: 2
Training loss: 2.5111334323883057
Validation loss: 2.53615731994311

Epoch: 5| Step: 3
Training loss: 3.048107624053955
Validation loss: 2.534845232963562

Epoch: 5| Step: 4
Training loss: 2.855964422225952
Validation loss: 2.5314990977446237

Epoch: 5| Step: 5
Training loss: 2.3526275157928467
Validation loss: 2.527883549531301

Epoch: 5| Step: 6
Training loss: 2.985663652420044
Validation loss: 2.5258921881516776

Epoch: 5| Step: 7
Training loss: 2.7649476528167725
Validation loss: 2.521913101275762

Epoch: 5| Step: 8
Training loss: 3.048435688018799
Validation loss: 2.5183088878790536

Epoch: 5| Step: 9
Training loss: 2.6603620052337646
Validation loss: 2.512955129146576

Epoch: 5| Step: 10
Training loss: 2.614192247390747
Validation loss: 2.5096916457017264

Epoch: 5| Step: 11
Training loss: 3.0529701709747314
Validation loss: 2.5077063093582788

Epoch: 51| Step: 0
Training loss: 2.9423632621765137
Validation loss: 2.5072587529818215

Epoch: 5| Step: 1
Training loss: 2.541572332382202
Validation loss: 2.5033677021662393

Epoch: 5| Step: 2
Training loss: 2.813476085662842
Validation loss: 2.502862443526586

Epoch: 5| Step: 3
Training loss: 2.5262463092803955
Validation loss: 2.499790837367376

Epoch: 5| Step: 4
Training loss: 2.18550705909729
Validation loss: 2.4974784354368844

Epoch: 5| Step: 5
Training loss: 2.7096660137176514
Validation loss: 2.494314968585968

Epoch: 5| Step: 6
Training loss: 3.1936073303222656
Validation loss: 2.4924915730953217

Epoch: 5| Step: 7
Training loss: 2.2288618087768555
Validation loss: 2.490016450484594

Epoch: 5| Step: 8
Training loss: 2.695906162261963
Validation loss: 2.487385461727778

Epoch: 5| Step: 9
Training loss: 2.8189921379089355
Validation loss: 2.4861897130807242

Epoch: 5| Step: 10
Training loss: 2.8929827213287354
Validation loss: 2.4842428267002106

Epoch: 5| Step: 11
Training loss: 3.0666239261627197
Validation loss: 2.482883562644323

Epoch: 52| Step: 0
Training loss: 2.6643290519714355
Validation loss: 2.479393074909846

Epoch: 5| Step: 1
Training loss: 2.1906113624572754
Validation loss: 2.4780497550964355

Epoch: 5| Step: 2
Training loss: 2.1887104511260986
Validation loss: 2.4732408920923867

Epoch: 5| Step: 3
Training loss: 3.1240649223327637
Validation loss: 2.471576432387034

Epoch: 5| Step: 4
Training loss: 2.5182902812957764
Validation loss: 2.468128209312757

Epoch: 5| Step: 5
Training loss: 2.7458438873291016
Validation loss: 2.4672706574201584

Epoch: 5| Step: 6
Training loss: 2.671518325805664
Validation loss: 2.4648319482803345

Epoch: 5| Step: 7
Training loss: 2.9124064445495605
Validation loss: 2.4627632796764374

Epoch: 5| Step: 8
Training loss: 2.4450275897979736
Validation loss: 2.4607301354408264

Epoch: 5| Step: 9
Training loss: 3.207371950149536
Validation loss: 2.4576584299405417

Epoch: 5| Step: 10
Training loss: 2.6960396766662598
Validation loss: 2.453888068596522

Epoch: 5| Step: 11
Training loss: 2.120846748352051
Validation loss: 2.45377546052138

Epoch: 53| Step: 0
Training loss: 2.633578062057495
Validation loss: 2.4495204985141754

Epoch: 5| Step: 1
Training loss: 2.9657959938049316
Validation loss: 2.4503081838289895

Epoch: 5| Step: 2
Training loss: 2.3011929988861084
Validation loss: 2.447547107934952

Epoch: 5| Step: 3
Training loss: 2.235663890838623
Validation loss: 2.4424745440483093

Epoch: 5| Step: 4
Training loss: 2.8043034076690674
Validation loss: 2.445780177911123

Epoch: 5| Step: 5
Training loss: 1.629660964012146
Validation loss: 2.4388461659351983

Epoch: 5| Step: 6
Training loss: 3.108375072479248
Validation loss: 2.4335207045078278

Epoch: 5| Step: 7
Training loss: 2.5733695030212402
Validation loss: 2.430412848790487

Epoch: 5| Step: 8
Training loss: 3.3682644367218018
Validation loss: 2.4303282300631204

Epoch: 5| Step: 9
Training loss: 2.4790446758270264
Validation loss: 2.4267735183238983

Epoch: 5| Step: 10
Training loss: 2.636711835861206
Validation loss: 2.4268551766872406

Epoch: 5| Step: 11
Training loss: 3.471250534057617
Validation loss: 2.4239722192287445

Epoch: 54| Step: 0
Training loss: 2.0451431274414062
Validation loss: 2.4171886841456094

Epoch: 5| Step: 1
Training loss: 2.6057345867156982
Validation loss: 2.414921293656031

Epoch: 5| Step: 2
Training loss: 2.5751540660858154
Validation loss: 2.413985311985016

Epoch: 5| Step: 3
Training loss: 2.380709409713745
Validation loss: 2.4096918205420175

Epoch: 5| Step: 4
Training loss: 2.755755662918091
Validation loss: 2.4068827827771506

Epoch: 5| Step: 5
Training loss: 2.7452282905578613
Validation loss: 2.405409514904022

Epoch: 5| Step: 6
Training loss: 2.6310620307922363
Validation loss: 2.4046510060628257

Epoch: 5| Step: 7
Training loss: 2.9278855323791504
Validation loss: 2.400868852933248

Epoch: 5| Step: 8
Training loss: 2.9976162910461426
Validation loss: 2.3959740897019706

Epoch: 5| Step: 9
Training loss: 2.6794161796569824
Validation loss: 2.3964034616947174

Epoch: 5| Step: 10
Training loss: 2.349804162979126
Validation loss: 2.394171357154846

Epoch: 5| Step: 11
Training loss: 1.7774808406829834
Validation loss: 2.3928412993748984

Epoch: 55| Step: 0
Training loss: 2.2685513496398926
Validation loss: 2.386057883501053

Epoch: 5| Step: 1
Training loss: 2.7078254222869873
Validation loss: 2.3886313339074454

Epoch: 5| Step: 2
Training loss: 2.249300241470337
Validation loss: 2.3876142352819443

Epoch: 5| Step: 3
Training loss: 2.2288992404937744
Validation loss: 2.386471594373385

Epoch: 5| Step: 4
Training loss: 2.6940903663635254
Validation loss: 2.3854231536388397

Epoch: 5| Step: 5
Training loss: 2.6231849193573
Validation loss: 2.384670923153559

Epoch: 5| Step: 6
Training loss: 2.3232054710388184
Validation loss: 2.38235796491305

Epoch: 5| Step: 7
Training loss: 2.0759291648864746
Validation loss: 2.3792531192302704

Epoch: 5| Step: 8
Training loss: 3.2236454486846924
Validation loss: 2.374804417292277

Epoch: 5| Step: 9
Training loss: 2.9756903648376465
Validation loss: 2.3721099694569907

Epoch: 5| Step: 10
Training loss: 2.702052593231201
Validation loss: 2.3694363633791604

Epoch: 5| Step: 11
Training loss: 3.328845977783203
Validation loss: 2.3669672310352325

Epoch: 56| Step: 0
Training loss: 2.234823226928711
Validation loss: 2.3673761586348214

Epoch: 5| Step: 1
Training loss: 2.726832866668701
Validation loss: 2.3614842693010965

Epoch: 5| Step: 2
Training loss: 2.301792621612549
Validation loss: 2.359024961789449

Epoch: 5| Step: 3
Training loss: 2.2055623531341553
Validation loss: 2.3551546931266785

Epoch: 5| Step: 4
Training loss: 2.8305163383483887
Validation loss: 2.353633095820745

Epoch: 5| Step: 5
Training loss: 2.8781230449676514
Validation loss: 2.353111426035563

Epoch: 5| Step: 6
Training loss: 2.608027696609497
Validation loss: 2.348074734210968

Epoch: 5| Step: 7
Training loss: 2.2759790420532227
Validation loss: 2.3474457462628684

Epoch: 5| Step: 8
Training loss: 2.628868579864502
Validation loss: 2.3471775501966476

Epoch: 5| Step: 9
Training loss: 2.1698715686798096
Validation loss: 2.344301829735438

Epoch: 5| Step: 10
Training loss: 3.0082619190216064
Validation loss: 2.337992841998736

Epoch: 5| Step: 11
Training loss: 2.6180591583251953
Validation loss: 2.33716714878877

Epoch: 57| Step: 0
Training loss: 2.35495924949646
Validation loss: 2.3371545871098838

Epoch: 5| Step: 1
Training loss: 2.4742846488952637
Validation loss: 2.3313999076684317

Epoch: 5| Step: 2
Training loss: 2.5417323112487793
Validation loss: 2.331650177637736

Epoch: 5| Step: 3
Training loss: 2.3661696910858154
Validation loss: 2.330094556013743

Epoch: 5| Step: 4
Training loss: 2.2145094871520996
Validation loss: 2.3310999870300293

Epoch: 5| Step: 5
Training loss: 2.599926233291626
Validation loss: 2.3235744585593543

Epoch: 5| Step: 6
Training loss: 2.546600341796875
Validation loss: 2.3224657277266183

Epoch: 5| Step: 7
Training loss: 2.0990495681762695
Validation loss: 2.3222345362106958

Epoch: 5| Step: 8
Training loss: 2.3453478813171387
Validation loss: 2.317191258072853

Epoch: 5| Step: 9
Training loss: 2.812833786010742
Validation loss: 2.3183846523364386

Epoch: 5| Step: 10
Training loss: 3.1272900104522705
Validation loss: 2.3172502915064492

Epoch: 5| Step: 11
Training loss: 2.818385362625122
Validation loss: 2.3139140407244363

Epoch: 58| Step: 0
Training loss: 2.7922825813293457
Validation loss: 2.3128399699926376

Epoch: 5| Step: 1
Training loss: 2.1234118938446045
Validation loss: 2.3137958496809006

Epoch: 5| Step: 2
Training loss: 3.0572941303253174
Validation loss: 2.313141872485479

Epoch: 5| Step: 3
Training loss: 2.5646214485168457
Validation loss: 2.311764419078827

Epoch: 5| Step: 4
Training loss: 2.9299635887145996
Validation loss: 2.3097938001155853

Epoch: 5| Step: 5
Training loss: 2.564169406890869
Validation loss: 2.3103792667388916

Epoch: 5| Step: 6
Training loss: 1.9275996685028076
Validation loss: 2.308344771464666

Epoch: 5| Step: 7
Training loss: 2.267050266265869
Validation loss: 2.306433786948522

Epoch: 5| Step: 8
Training loss: 1.6528995037078857
Validation loss: 2.3034942348798118

Epoch: 5| Step: 9
Training loss: 2.5002553462982178
Validation loss: 2.298749695221583

Epoch: 5| Step: 10
Training loss: 2.7595179080963135
Validation loss: 2.2964826921621957

Epoch: 5| Step: 11
Training loss: 3.0313820838928223
Validation loss: 2.2940247654914856

Epoch: 59| Step: 0
Training loss: 2.3194496631622314
Validation loss: 2.2905568281809487

Epoch: 5| Step: 1
Training loss: 2.4868643283843994
Validation loss: 2.2847580313682556

Epoch: 5| Step: 2
Training loss: 3.0740880966186523
Validation loss: 2.2836384773254395

Epoch: 5| Step: 3
Training loss: 2.4973177909851074
Validation loss: 2.2840884377559028

Epoch: 5| Step: 4
Training loss: 2.5492775440216064
Validation loss: 2.2788847436507544

Epoch: 5| Step: 5
Training loss: 2.784343957901001
Validation loss: 2.2764855275551477

Epoch: 5| Step: 6
Training loss: 2.028144359588623
Validation loss: 2.274661734700203

Epoch: 5| Step: 7
Training loss: 2.9002068042755127
Validation loss: 2.275471235315005

Epoch: 5| Step: 8
Training loss: 2.050032138824463
Validation loss: 2.271946926911672

Epoch: 5| Step: 9
Training loss: 2.1818504333496094
Validation loss: 2.2708112398783364

Epoch: 5| Step: 10
Training loss: 2.1410014629364014
Validation loss: 2.2698147346576056

Epoch: 5| Step: 11
Training loss: 2.3919076919555664
Validation loss: 2.266354272762934

Epoch: 60| Step: 0
Training loss: 2.326042890548706
Validation loss: 2.2698517590761185

Epoch: 5| Step: 1
Training loss: 2.388967752456665
Validation loss: 2.2651155491669974

Epoch: 5| Step: 2
Training loss: 1.6354955434799194
Validation loss: 2.258138279120127

Epoch: 5| Step: 3
Training loss: 2.4097352027893066
Validation loss: 2.2564085920651755

Epoch: 5| Step: 4
Training loss: 2.3908846378326416
Validation loss: 2.2494800835847855

Epoch: 5| Step: 5
Training loss: 2.402500629425049
Validation loss: 2.2500338902076087

Epoch: 5| Step: 6
Training loss: 2.8023765087127686
Validation loss: 2.2537324329217276

Epoch: 5| Step: 7
Training loss: 2.974388837814331
Validation loss: 2.2477501928806305

Epoch: 5| Step: 8
Training loss: 1.8078727722167969
Validation loss: 2.242207949360212

Epoch: 5| Step: 9
Training loss: 2.5183489322662354
Validation loss: 2.2395643492539725

Epoch: 5| Step: 10
Training loss: 2.9891083240509033
Validation loss: 2.2361905574798584

Epoch: 5| Step: 11
Training loss: 1.9823933839797974
Validation loss: 2.2389475305875144

Epoch: 61| Step: 0
Training loss: 2.206937551498413
Validation loss: 2.234940638144811

Epoch: 5| Step: 1
Training loss: 2.1914432048797607
Validation loss: 2.250654379526774

Epoch: 5| Step: 2
Training loss: 2.2366039752960205
Validation loss: 2.2689453959465027

Epoch: 5| Step: 3
Training loss: 2.816403865814209
Validation loss: 2.311198423306147

Epoch: 5| Step: 4
Training loss: 2.877350330352783
Validation loss: 2.296888550122579

Epoch: 5| Step: 5
Training loss: 2.2229232788085938
Validation loss: 2.2496800124645233

Epoch: 5| Step: 6
Training loss: 2.4282925128936768
Validation loss: 2.224808613459269

Epoch: 5| Step: 7
Training loss: 2.449899673461914
Validation loss: 2.2293281306823096

Epoch: 5| Step: 8
Training loss: 2.0758395195007324
Validation loss: 2.231210619211197

Epoch: 5| Step: 9
Training loss: 1.8487237691879272
Validation loss: 2.2300760000944138

Epoch: 5| Step: 10
Training loss: 3.288201093673706
Validation loss: 2.236310904224714

Epoch: 5| Step: 11
Training loss: 2.1165542602539062
Validation loss: 2.2434532990058265

Epoch: 62| Step: 0
Training loss: 2.6051859855651855
Validation loss: 2.2426070471604667

Epoch: 5| Step: 1
Training loss: 2.2681655883789062
Validation loss: 2.239905675252279

Epoch: 5| Step: 2
Training loss: 1.975775957107544
Validation loss: 2.23885370294253

Epoch: 5| Step: 3
Training loss: 2.0607752799987793
Validation loss: 2.237662230928739

Epoch: 5| Step: 4
Training loss: 2.6280744075775146
Validation loss: 2.2316612899303436

Epoch: 5| Step: 5
Training loss: 2.7588610649108887
Validation loss: 2.2289413114388785

Epoch: 5| Step: 6
Training loss: 2.379582166671753
Validation loss: 2.2292584975560508

Epoch: 5| Step: 7
Training loss: 2.528961181640625
Validation loss: 2.226403534412384

Epoch: 5| Step: 8
Training loss: 2.2331857681274414
Validation loss: 2.2241995533307395

Epoch: 5| Step: 9
Training loss: 2.69939923286438
Validation loss: 2.221333235502243

Epoch: 5| Step: 10
Training loss: 2.259913921356201
Validation loss: 2.2212912142276764

Epoch: 5| Step: 11
Training loss: 2.1049892902374268
Validation loss: 2.215104361375173

Epoch: 63| Step: 0
Training loss: 2.672714948654175
Validation loss: 2.2146372497081757

Epoch: 5| Step: 1
Training loss: 1.8905935287475586
Validation loss: 2.2095107287168503

Epoch: 5| Step: 2
Training loss: 2.0462629795074463
Validation loss: 2.207925483584404

Epoch: 5| Step: 3
Training loss: 2.722299098968506
Validation loss: 2.2035407523314157

Epoch: 5| Step: 4
Training loss: 2.1677818298339844
Validation loss: 2.1997680564721427

Epoch: 5| Step: 5
Training loss: 2.731985569000244
Validation loss: 2.1974495947360992

Epoch: 5| Step: 6
Training loss: 2.481475353240967
Validation loss: 2.195575699210167

Epoch: 5| Step: 7
Training loss: 2.0304019451141357
Validation loss: 2.193747103214264

Epoch: 5| Step: 8
Training loss: 2.288618803024292
Validation loss: 2.189097225666046

Epoch: 5| Step: 9
Training loss: 2.596735715866089
Validation loss: 2.1873426735401154

Epoch: 5| Step: 10
Training loss: 2.3558082580566406
Validation loss: 2.185923159122467

Epoch: 5| Step: 11
Training loss: 2.3251092433929443
Validation loss: 2.1762260595957437

Epoch: 64| Step: 0
Training loss: 2.3864753246307373
Validation loss: 2.1782132188479104

Epoch: 5| Step: 1
Training loss: 2.854926586151123
Validation loss: 2.1786961555480957

Epoch: 5| Step: 2
Training loss: 2.3430874347686768
Validation loss: 2.1742593348026276

Epoch: 5| Step: 3
Training loss: 1.9066784381866455
Validation loss: 2.171274354060491

Epoch: 5| Step: 4
Training loss: 2.29492449760437
Validation loss: 2.1773004035154977

Epoch: 5| Step: 5
Training loss: 3.089521884918213
Validation loss: 2.17096841832002

Epoch: 5| Step: 6
Training loss: 2.0312507152557373
Validation loss: 2.164237608512243

Epoch: 5| Step: 7
Training loss: 2.368732213973999
Validation loss: 2.167324259877205

Epoch: 5| Step: 8
Training loss: 2.130885601043701
Validation loss: 2.164920190970103

Epoch: 5| Step: 9
Training loss: 2.032179832458496
Validation loss: 2.1626327286163964

Epoch: 5| Step: 10
Training loss: 2.4118473529815674
Validation loss: 2.1685193876425424

Epoch: 5| Step: 11
Training loss: 1.3890681266784668
Validation loss: 2.160586580634117

Epoch: 65| Step: 0
Training loss: 2.1982169151306152
Validation loss: 2.1634430438280106

Epoch: 5| Step: 1
Training loss: 1.8619340658187866
Validation loss: 2.1609319895505905

Epoch: 5| Step: 2
Training loss: 1.9596151113510132
Validation loss: 2.162076711654663

Epoch: 5| Step: 3
Training loss: 1.9376462697982788
Validation loss: 2.159503777821859

Epoch: 5| Step: 4
Training loss: 2.249150514602661
Validation loss: 2.1523071279128394

Epoch: 5| Step: 5
Training loss: 2.1127724647521973
Validation loss: 2.154922664165497

Epoch: 5| Step: 6
Training loss: 3.1298301219940186
Validation loss: 2.155370016892751

Epoch: 5| Step: 7
Training loss: 2.729598045349121
Validation loss: 2.149824599424998

Epoch: 5| Step: 8
Training loss: 2.3295738697052
Validation loss: 2.1523615419864655

Epoch: 5| Step: 9
Training loss: 2.2738866806030273
Validation loss: 2.1506554931402206

Epoch: 5| Step: 10
Training loss: 2.549257755279541
Validation loss: 2.142844299475352

Epoch: 5| Step: 11
Training loss: 3.032562017440796
Validation loss: 2.1459226508935294

Epoch: 66| Step: 0
Training loss: 2.189091920852661
Validation loss: 2.1466283847888312

Epoch: 5| Step: 1
Training loss: 2.746107578277588
Validation loss: 2.141454045971235

Epoch: 5| Step: 2
Training loss: 2.206008195877075
Validation loss: 2.149406989415487

Epoch: 5| Step: 3
Training loss: 2.3601527214050293
Validation loss: 2.136721988519033

Epoch: 5| Step: 4
Training loss: 2.079692840576172
Validation loss: 2.137219155828158

Epoch: 5| Step: 5
Training loss: 2.386664628982544
Validation loss: 2.1397835165262222

Epoch: 5| Step: 6
Training loss: 2.0858254432678223
Validation loss: 2.1365508238474527

Epoch: 5| Step: 7
Training loss: 1.9390491247177124
Validation loss: 2.136240800221761

Epoch: 5| Step: 8
Training loss: 2.2863717079162598
Validation loss: 2.1370759457349777

Epoch: 5| Step: 9
Training loss: 2.1255202293395996
Validation loss: 2.132337530454

Epoch: 5| Step: 10
Training loss: 2.9207706451416016
Validation loss: 2.1338435262441635

Epoch: 5| Step: 11
Training loss: 2.671550750732422
Validation loss: 2.132655158638954

Epoch: 67| Step: 0
Training loss: 2.1417953968048096
Validation loss: 2.129605328043302

Epoch: 5| Step: 1
Training loss: 2.5500500202178955
Validation loss: 2.1376112749179206

Epoch: 5| Step: 2
Training loss: 2.0457961559295654
Validation loss: 2.1361065357923508

Epoch: 5| Step: 3
Training loss: 2.21498441696167
Validation loss: 2.1435734232266745

Epoch: 5| Step: 4
Training loss: 2.7200417518615723
Validation loss: 2.151502619187037

Epoch: 5| Step: 5
Training loss: 1.8173389434814453
Validation loss: 2.1444349040587745

Epoch: 5| Step: 6
Training loss: 2.569950580596924
Validation loss: 2.139075383543968

Epoch: 5| Step: 7
Training loss: 1.9990381002426147
Validation loss: 2.131326417128245

Epoch: 5| Step: 8
Training loss: 2.5760982036590576
Validation loss: 2.1262279649575553

Epoch: 5| Step: 9
Training loss: 1.9096400737762451
Validation loss: 2.1242623825867972

Epoch: 5| Step: 10
Training loss: 2.7595362663269043
Validation loss: 2.117696225643158

Epoch: 5| Step: 11
Training loss: 2.213214874267578
Validation loss: 2.116302952170372

Epoch: 68| Step: 0
Training loss: 1.7757781744003296
Validation loss: 2.110734765728315

Epoch: 5| Step: 1
Training loss: 2.479231357574463
Validation loss: 2.11539833744367

Epoch: 5| Step: 2
Training loss: 2.131833791732788
Validation loss: 2.1100889841715493

Epoch: 5| Step: 3
Training loss: 2.697798252105713
Validation loss: 2.114021524786949

Epoch: 5| Step: 4
Training loss: 2.1955058574676514
Validation loss: 2.112045094370842

Epoch: 5| Step: 5
Training loss: 2.2659077644348145
Validation loss: 2.1225638339916864

Epoch: 5| Step: 6
Training loss: 2.0025362968444824
Validation loss: 2.1185450851917267

Epoch: 5| Step: 7
Training loss: 2.6221325397491455
Validation loss: 2.1152451187372208

Epoch: 5| Step: 8
Training loss: 1.8498296737670898
Validation loss: 2.115490903457006

Epoch: 5| Step: 9
Training loss: 2.330315113067627
Validation loss: 2.1161723732948303

Epoch: 5| Step: 10
Training loss: 2.845001697540283
Validation loss: 2.1085606267054877

Epoch: 5| Step: 11
Training loss: 1.6787388324737549
Validation loss: 2.1133970518906913

Epoch: 69| Step: 0
Training loss: 2.080022096633911
Validation loss: 2.114006037513415

Epoch: 5| Step: 1
Training loss: 2.6142842769622803
Validation loss: 2.1200406601031623

Epoch: 5| Step: 2
Training loss: 2.1329472064971924
Validation loss: 2.116918454567591

Epoch: 5| Step: 3
Training loss: 2.385300397872925
Validation loss: 2.113807424902916

Epoch: 5| Step: 4
Training loss: 2.2244529724121094
Validation loss: 2.111242488026619

Epoch: 5| Step: 5
Training loss: 2.1538822650909424
Validation loss: 2.111057326197624

Epoch: 5| Step: 6
Training loss: 2.541133403778076
Validation loss: 2.1076755970716476

Epoch: 5| Step: 7
Training loss: 2.610654830932617
Validation loss: 2.1085683703422546

Epoch: 5| Step: 8
Training loss: 1.65505051612854
Validation loss: 2.109554017583529

Epoch: 5| Step: 9
Training loss: 2.6466152667999268
Validation loss: 2.09965243935585

Epoch: 5| Step: 10
Training loss: 1.9651412963867188
Validation loss: 2.1007177233695984

Epoch: 5| Step: 11
Training loss: 2.6647982597351074
Validation loss: 2.1022708664337793

Epoch: 70| Step: 0
Training loss: 2.788992404937744
Validation loss: 2.086798588434855

Epoch: 5| Step: 1
Training loss: 2.2749171257019043
Validation loss: 2.095780372619629

Epoch: 5| Step: 2
Training loss: 2.2143540382385254
Validation loss: 2.107586845755577

Epoch: 5| Step: 3
Training loss: 2.4898290634155273
Validation loss: 2.106067349513372

Epoch: 5| Step: 4
Training loss: 2.0267910957336426
Validation loss: 2.1159642934799194

Epoch: 5| Step: 5
Training loss: 2.0261623859405518
Validation loss: 2.1152365704377494

Epoch: 5| Step: 6
Training loss: 2.3946473598480225
Validation loss: 2.1382227689027786

Epoch: 5| Step: 7
Training loss: 2.389721393585205
Validation loss: 2.1264566282431283

Epoch: 5| Step: 8
Training loss: 2.3545939922332764
Validation loss: 2.1076074292262397

Epoch: 5| Step: 9
Training loss: 2.1184990406036377
Validation loss: 2.089039703210195

Epoch: 5| Step: 10
Training loss: 1.8079969882965088
Validation loss: 2.0856433560450873

Epoch: 5| Step: 11
Training loss: 3.0737524032592773
Validation loss: 2.099935660759608

Epoch: 71| Step: 0
Training loss: 2.6197752952575684
Validation loss: 2.1004657596349716

Epoch: 5| Step: 1
Training loss: 2.0881829261779785
Validation loss: 2.1016584237416587

Epoch: 5| Step: 2
Training loss: 1.9813474416732788
Validation loss: 2.104924107591311

Epoch: 5| Step: 3
Training loss: 1.693738579750061
Validation loss: 2.1034340312083564

Epoch: 5| Step: 4
Training loss: 2.3625571727752686
Validation loss: 2.108215570449829

Epoch: 5| Step: 5
Training loss: 2.5733094215393066
Validation loss: 2.1072834134101868

Epoch: 5| Step: 6
Training loss: 2.589907169342041
Validation loss: 2.1082542836666107

Epoch: 5| Step: 7
Training loss: 2.1226699352264404
Validation loss: 2.105452239513397

Epoch: 5| Step: 8
Training loss: 1.8289711475372314
Validation loss: 2.1018168230851493

Epoch: 5| Step: 9
Training loss: 2.262737512588501
Validation loss: 2.094532291094462

Epoch: 5| Step: 10
Training loss: 2.865845203399658
Validation loss: 2.0954744815826416

Epoch: 5| Step: 11
Training loss: 2.9783775806427
Validation loss: 2.0896639128526053

Epoch: 72| Step: 0
Training loss: 2.4316065311431885
Validation loss: 2.0942971458037696

Epoch: 5| Step: 1
Training loss: 2.250978469848633
Validation loss: 2.0886506934960685

Epoch: 5| Step: 2
Training loss: 2.2261853218078613
Validation loss: 2.0868266969919205

Epoch: 5| Step: 3
Training loss: 1.878989577293396
Validation loss: 2.0792188147703805

Epoch: 5| Step: 4
Training loss: 2.63873553276062
Validation loss: 2.0701380223035812

Epoch: 5| Step: 5
Training loss: 3.0008490085601807
Validation loss: 2.0809016724427543

Epoch: 5| Step: 6
Training loss: 1.7615110874176025
Validation loss: 2.0837011684974036

Epoch: 5| Step: 7
Training loss: 2.5146613121032715
Validation loss: 2.099628413716952

Epoch: 5| Step: 8
Training loss: 2.4558331966400146
Validation loss: 2.111783837278684

Epoch: 5| Step: 9
Training loss: 2.4428067207336426
Validation loss: 2.1024669408798218

Epoch: 5| Step: 10
Training loss: 1.592692494392395
Validation loss: 2.0882340719302497

Epoch: 5| Step: 11
Training loss: 1.4763257503509521
Validation loss: 2.064666122198105

Epoch: 73| Step: 0
Training loss: 2.261121988296509
Validation loss: 2.074992294112841

Epoch: 5| Step: 1
Training loss: 2.0540475845336914
Validation loss: 2.0773836771647134

Epoch: 5| Step: 2
Training loss: 2.222561836242676
Validation loss: 2.0839673280715942

Epoch: 5| Step: 3
Training loss: 2.1052355766296387
Validation loss: 2.087806840737661

Epoch: 5| Step: 4
Training loss: 2.232238531112671
Validation loss: 2.088196804126104

Epoch: 5| Step: 5
Training loss: 2.248932123184204
Validation loss: 2.0903015583753586

Epoch: 5| Step: 6
Training loss: 2.4224772453308105
Validation loss: 2.089370181163152

Epoch: 5| Step: 7
Training loss: 2.4402294158935547
Validation loss: 2.0967183858156204

Epoch: 5| Step: 8
Training loss: 2.342258930206299
Validation loss: 2.0950984756151834

Epoch: 5| Step: 9
Training loss: 2.5596861839294434
Validation loss: 2.0964287420113883

Epoch: 5| Step: 10
Training loss: 2.2626049518585205
Validation loss: 2.101528192559878

Epoch: 5| Step: 11
Training loss: 1.5876655578613281
Validation loss: 2.099249760309855

Epoch: 74| Step: 0
Training loss: 2.307453155517578
Validation loss: 2.096269980072975

Epoch: 5| Step: 1
Training loss: 2.77705454826355
Validation loss: 2.09187218050162

Epoch: 5| Step: 2
Training loss: 2.418741226196289
Validation loss: 2.086808209617933

Epoch: 5| Step: 3
Training loss: 2.1336374282836914
Validation loss: 2.08504019677639

Epoch: 5| Step: 4
Training loss: 1.5709298849105835
Validation loss: 2.0784288197755814

Epoch: 5| Step: 5
Training loss: 2.332390308380127
Validation loss: 2.078366279602051

Epoch: 5| Step: 6
Training loss: 1.9052146673202515
Validation loss: 2.0761619160572686

Epoch: 5| Step: 7
Training loss: 2.571316719055176
Validation loss: 2.0647446513175964

Epoch: 5| Step: 8
Training loss: 1.8772552013397217
Validation loss: 2.070285364985466

Epoch: 5| Step: 9
Training loss: 2.818837881088257
Validation loss: 2.051949138442675

Epoch: 5| Step: 10
Training loss: 1.9640405178070068
Validation loss: 2.0503116895755134

Epoch: 5| Step: 11
Training loss: 3.2424652576446533
Validation loss: 2.047253871957461

Epoch: 75| Step: 0
Training loss: 2.2170426845550537
Validation loss: 2.0452285508314767

Epoch: 5| Step: 1
Training loss: 2.1349549293518066
Validation loss: 2.046866456667582

Epoch: 5| Step: 2
Training loss: 2.1978859901428223
Validation loss: 2.049870938062668

Epoch: 5| Step: 3
Training loss: 2.5134119987487793
Validation loss: 2.04280091325442

Epoch: 5| Step: 4
Training loss: 2.4313788414001465
Validation loss: 2.0433458586533866

Epoch: 5| Step: 5
Training loss: 2.4105045795440674
Validation loss: 2.046578198671341

Epoch: 5| Step: 6
Training loss: 2.4299674034118652
Validation loss: 2.041965698202451

Epoch: 5| Step: 7
Training loss: 1.9945443868637085
Validation loss: 2.044769505659739

Epoch: 5| Step: 8
Training loss: 1.4777835607528687
Validation loss: 2.0521619270245233

Epoch: 5| Step: 9
Training loss: 2.2800111770629883
Validation loss: 2.053297554453214

Epoch: 5| Step: 10
Training loss: 2.1940128803253174
Validation loss: 2.0582474768161774

Epoch: 5| Step: 11
Training loss: 2.981351852416992
Validation loss: 2.061457395553589

Testing loss: 1.6640477369157531
