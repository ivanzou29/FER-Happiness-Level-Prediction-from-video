Epoch: 1| Step: 0
Training loss: 5.774788539697592
Validation loss: 5.857879447808826

Epoch: 6| Step: 1
Training loss: 5.869308636842309
Validation loss: 5.856304371193622

Epoch: 6| Step: 2
Training loss: 5.5854698572278565
Validation loss: 5.854610150283291

Epoch: 6| Step: 3
Training loss: 6.443681434244355
Validation loss: 5.852937761697234

Epoch: 6| Step: 4
Training loss: 5.948895250868899
Validation loss: 5.851309960572906

Epoch: 6| Step: 5
Training loss: 6.260675392157526
Validation loss: 5.849705101253122

Epoch: 6| Step: 6
Training loss: 5.814407527848589
Validation loss: 5.848094447248645

Epoch: 6| Step: 7
Training loss: 6.005094590533921
Validation loss: 5.846455048254992

Epoch: 6| Step: 8
Training loss: 4.159955430892466
Validation loss: 5.844724332532295

Epoch: 6| Step: 9
Training loss: 6.958563368720165
Validation loss: 5.843121173501177

Epoch: 6| Step: 10
Training loss: 6.442605965823098
Validation loss: 5.841264274259182

Epoch: 6| Step: 11
Training loss: 5.215157923003409
Validation loss: 5.8394828353147465

Epoch: 6| Step: 12
Training loss: 6.201618770806375
Validation loss: 5.837617481691382

Epoch: 6| Step: 13
Training loss: 6.338305612858392
Validation loss: 5.835561417628922

Epoch: 2| Step: 0
Training loss: 5.84252264015992
Validation loss: 5.83344035277516

Epoch: 6| Step: 1
Training loss: 5.781502053204767
Validation loss: 5.831232955269879

Epoch: 6| Step: 2
Training loss: 5.247959467021909
Validation loss: 5.82902412194818

Epoch: 6| Step: 3
Training loss: 5.764807501008307
Validation loss: 5.826670174470336

Epoch: 6| Step: 4
Training loss: 6.332322826414465
Validation loss: 5.82425943996203

Epoch: 6| Step: 5
Training loss: 5.297458312737847
Validation loss: 5.8215640094368855

Epoch: 6| Step: 6
Training loss: 5.634863788139752
Validation loss: 5.8188224779771724

Epoch: 6| Step: 7
Training loss: 6.998236842854878
Validation loss: 5.816070499127563

Epoch: 6| Step: 8
Training loss: 6.404239692677013
Validation loss: 5.813180589652431

Epoch: 6| Step: 9
Training loss: 5.376664547116705
Validation loss: 5.810021121391034

Epoch: 6| Step: 10
Training loss: 5.507821157462168
Validation loss: 5.806748610851555

Epoch: 6| Step: 11
Training loss: 6.060555057600019
Validation loss: 5.803319401002155

Epoch: 6| Step: 12
Training loss: 6.452489493715112
Validation loss: 5.799653627203636

Epoch: 6| Step: 13
Training loss: 6.0757860719088495
Validation loss: 5.795719165166605

Epoch: 3| Step: 0
Training loss: 6.0604115457820225
Validation loss: 5.7917819754925

Epoch: 6| Step: 1
Training loss: 6.975737348844106
Validation loss: 5.7876789534978705

Epoch: 6| Step: 2
Training loss: 6.810943705728132
Validation loss: 5.78321906571455

Epoch: 6| Step: 3
Training loss: 5.140080292664606
Validation loss: 5.778629238201676

Epoch: 6| Step: 4
Training loss: 5.231870137309124
Validation loss: 5.773732261721313

Epoch: 6| Step: 5
Training loss: 5.84920569350002
Validation loss: 5.768809251629084

Epoch: 6| Step: 6
Training loss: 5.472185723214762
Validation loss: 5.763716439523297

Epoch: 6| Step: 7
Training loss: 5.431528956511226
Validation loss: 5.75857313938478

Epoch: 6| Step: 8
Training loss: 5.522220979396613
Validation loss: 5.7529385010347385

Epoch: 6| Step: 9
Training loss: 6.506365666749228
Validation loss: 5.7476018797550745

Epoch: 6| Step: 10
Training loss: 5.888665720871577
Validation loss: 5.741804446637495

Epoch: 6| Step: 11
Training loss: 5.370892396793987
Validation loss: 5.735679346460133

Epoch: 6| Step: 12
Training loss: 6.499023951094082
Validation loss: 5.729641213848628

Epoch: 6| Step: 13
Training loss: 5.070178954447955
Validation loss: 5.722974068384224

Epoch: 4| Step: 0
Training loss: 4.489450805312961
Validation loss: 5.7166418974018205

Epoch: 6| Step: 1
Training loss: 5.444134928324044
Validation loss: 5.70995525883718

Epoch: 6| Step: 2
Training loss: 5.861750169639571
Validation loss: 5.703174942703699

Epoch: 6| Step: 3
Training loss: 6.032926494447147
Validation loss: 5.696138159021083

Epoch: 6| Step: 4
Training loss: 6.213513800874841
Validation loss: 5.689063559440131

Epoch: 6| Step: 5
Training loss: 5.541632439452669
Validation loss: 5.681680070065465

Epoch: 6| Step: 6
Training loss: 6.447727412176967
Validation loss: 5.673652167335772

Epoch: 6| Step: 7
Training loss: 5.803943529880944
Validation loss: 5.665835216709113

Epoch: 6| Step: 8
Training loss: 6.145625672361208
Validation loss: 5.657785955291483

Epoch: 6| Step: 9
Training loss: 5.262548798903421
Validation loss: 5.648964702085121

Epoch: 6| Step: 10
Training loss: 5.39594481756839
Validation loss: 5.640467619527595

Epoch: 6| Step: 11
Training loss: 6.64381127602857
Validation loss: 5.631670945071743

Epoch: 6| Step: 12
Training loss: 5.622883716480583
Validation loss: 5.622667719203991

Epoch: 6| Step: 13
Training loss: 5.732275804676438
Validation loss: 5.613569612823406

Epoch: 5| Step: 0
Training loss: 6.075499136556665
Validation loss: 5.604005756927953

Epoch: 6| Step: 1
Training loss: 4.890298753283107
Validation loss: 5.594478794124192

Epoch: 6| Step: 2
Training loss: 6.049165513677505
Validation loss: 5.584979635421796

Epoch: 6| Step: 3
Training loss: 5.746636111597906
Validation loss: 5.575558568003316

Epoch: 6| Step: 4
Training loss: 5.37828549063041
Validation loss: 5.565982885489982

Epoch: 6| Step: 5
Training loss: 5.7120715892590415
Validation loss: 5.556054427742447

Epoch: 6| Step: 6
Training loss: 6.160552249775729
Validation loss: 5.546548724540586

Epoch: 6| Step: 7
Training loss: 6.672425008433145
Validation loss: 5.536988982652806

Epoch: 6| Step: 8
Training loss: 5.389535279631771
Validation loss: 5.527216300798015

Epoch: 6| Step: 9
Training loss: 5.742394766667474
Validation loss: 5.517552083271878

Epoch: 6| Step: 10
Training loss: 4.484754380184709
Validation loss: 5.508132788181084

Epoch: 6| Step: 11
Training loss: 6.057076141730327
Validation loss: 5.499503460058002

Epoch: 6| Step: 12
Training loss: 5.138000746035345
Validation loss: 5.490342215020952

Epoch: 6| Step: 13
Training loss: 5.390224099109706
Validation loss: 5.480876157938515

Epoch: 6| Step: 0
Training loss: 5.938092975118556
Validation loss: 5.472104451589873

Epoch: 6| Step: 1
Training loss: 5.044323349972921
Validation loss: 5.463027372297823

Epoch: 6| Step: 2
Training loss: 5.960507438614707
Validation loss: 5.454523703262039

Epoch: 6| Step: 3
Training loss: 5.505641125064187
Validation loss: 5.446355660491745

Epoch: 6| Step: 4
Training loss: 5.826668483172264
Validation loss: 5.438828083244379

Epoch: 6| Step: 5
Training loss: 5.264480058839333
Validation loss: 5.431052993578616

Epoch: 6| Step: 6
Training loss: 6.25989512102795
Validation loss: 5.423414468015729

Epoch: 6| Step: 7
Training loss: 5.664694536395924
Validation loss: 5.415955873460819

Epoch: 6| Step: 8
Training loss: 5.150001392549493
Validation loss: 5.40816944424552

Epoch: 6| Step: 9
Training loss: 5.55421533737359
Validation loss: 5.400309773967185

Epoch: 6| Step: 10
Training loss: 4.605337877169342
Validation loss: 5.3933460978736925

Epoch: 6| Step: 11
Training loss: 6.081692548372508
Validation loss: 5.385886530297911

Epoch: 6| Step: 12
Training loss: 4.771269110665589
Validation loss: 5.3790412909889795

Epoch: 6| Step: 13
Training loss: 5.673824091005451
Validation loss: 5.37249591072818

Epoch: 7| Step: 0
Training loss: 5.1311760881980755
Validation loss: 5.365718190667504

Epoch: 6| Step: 1
Training loss: 5.669809180653219
Validation loss: 5.359383096494203

Epoch: 6| Step: 2
Training loss: 5.656059472684576
Validation loss: 5.353399892245179

Epoch: 6| Step: 3
Training loss: 6.051670745425197
Validation loss: 5.347194134306796

Epoch: 6| Step: 4
Training loss: 5.801292196562964
Validation loss: 5.341082079832541

Epoch: 6| Step: 5
Training loss: 6.039671399607298
Validation loss: 5.334761319122994

Epoch: 6| Step: 6
Training loss: 5.684429974995294
Validation loss: 5.3284985363816775

Epoch: 6| Step: 7
Training loss: 5.742603686554565
Validation loss: 5.322703357859294

Epoch: 6| Step: 8
Training loss: 4.0487061117348615
Validation loss: 5.31660111644998

Epoch: 6| Step: 9
Training loss: 5.310843175694083
Validation loss: 5.3109065639383815

Epoch: 6| Step: 10
Training loss: 5.304758692222941
Validation loss: 5.305174949846058

Epoch: 6| Step: 11
Training loss: 4.093007726569284
Validation loss: 5.29959804642141

Epoch: 6| Step: 12
Training loss: 4.848871882481001
Validation loss: 5.294242452259865

Epoch: 6| Step: 13
Training loss: 6.34306624913519
Validation loss: 5.289003177462276

Epoch: 8| Step: 0
Training loss: 6.23000586054788
Validation loss: 5.28365874426523

Epoch: 6| Step: 1
Training loss: 5.346905406907805
Validation loss: 5.278424321554655

Epoch: 6| Step: 2
Training loss: 5.651059967808307
Validation loss: 5.273236758332005

Epoch: 6| Step: 3
Training loss: 4.641720215484545
Validation loss: 5.2680422463273935

Epoch: 6| Step: 4
Training loss: 4.931655515138412
Validation loss: 5.262623037801246

Epoch: 6| Step: 5
Training loss: 5.190425185939958
Validation loss: 5.257985656819321

Epoch: 6| Step: 6
Training loss: 5.834154706983655
Validation loss: 5.252436844356634

Epoch: 6| Step: 7
Training loss: 4.523637783643538
Validation loss: 5.247360686254682

Epoch: 6| Step: 8
Training loss: 5.374537958202561
Validation loss: 5.242469018236115

Epoch: 6| Step: 9
Training loss: 6.159990287872189
Validation loss: 5.23779928828693

Epoch: 6| Step: 10
Training loss: 5.481330743975729
Validation loss: 5.233201961123785

Epoch: 6| Step: 11
Training loss: 5.054510523249375
Validation loss: 5.228059699636321

Epoch: 6| Step: 12
Training loss: 4.691709535627629
Validation loss: 5.223268726454862

Epoch: 6| Step: 13
Training loss: 5.7586687504655005
Validation loss: 5.217676718594433

Epoch: 9| Step: 0
Training loss: 6.002425657143223
Validation loss: 5.212643429424127

Epoch: 6| Step: 1
Training loss: 4.743927738443456
Validation loss: 5.208062686246009

Epoch: 6| Step: 2
Training loss: 5.619591040885171
Validation loss: 5.203398031988809

Epoch: 6| Step: 3
Training loss: 4.755213235752995
Validation loss: 5.1990611842789445

Epoch: 6| Step: 4
Training loss: 5.364882239251859
Validation loss: 5.194421463279184

Epoch: 6| Step: 5
Training loss: 5.816333450056495
Validation loss: 5.189520875036046

Epoch: 6| Step: 6
Training loss: 6.059153783654497
Validation loss: 5.184434528863673

Epoch: 6| Step: 7
Training loss: 4.293555402718803
Validation loss: 5.179278342694347

Epoch: 6| Step: 8
Training loss: 5.279885742222812
Validation loss: 5.174807236869929

Epoch: 6| Step: 9
Training loss: 4.7332524646423595
Validation loss: 5.170357811042262

Epoch: 6| Step: 10
Training loss: 4.5611423928637125
Validation loss: 5.166199550226965

Epoch: 6| Step: 11
Training loss: 5.635788637907475
Validation loss: 5.161220212717868

Epoch: 6| Step: 12
Training loss: 5.0740665122226165
Validation loss: 5.156365348989926

Epoch: 6| Step: 13
Training loss: 5.922779024313638
Validation loss: 5.151518837864555

Epoch: 10| Step: 0
Training loss: 4.979976997781968
Validation loss: 5.147348384245421

Epoch: 6| Step: 1
Training loss: 5.472926000445069
Validation loss: 5.142479682749941

Epoch: 6| Step: 2
Training loss: 5.462485949325822
Validation loss: 5.138181652627112

Epoch: 6| Step: 3
Training loss: 5.409904876267574
Validation loss: 5.133953244483689

Epoch: 6| Step: 4
Training loss: 5.096309089233875
Validation loss: 5.129412883403132

Epoch: 6| Step: 5
Training loss: 5.083118788564
Validation loss: 5.1241264529203

Epoch: 6| Step: 6
Training loss: 4.985954967003152
Validation loss: 5.1189818985312145

Epoch: 6| Step: 7
Training loss: 5.385252998663957
Validation loss: 5.114461157971714

Epoch: 6| Step: 8
Training loss: 4.5253760840158055
Validation loss: 5.109937631036079

Epoch: 6| Step: 9
Training loss: 5.605507370021576
Validation loss: 5.105115820417427

Epoch: 6| Step: 10
Training loss: 5.230317413442642
Validation loss: 5.1001939948591115

Epoch: 6| Step: 11
Training loss: 5.064105497493718
Validation loss: 5.095009037742298

Epoch: 6| Step: 12
Training loss: 5.912231968294531
Validation loss: 5.089974468794209

Epoch: 6| Step: 13
Training loss: 5.007502839368072
Validation loss: 5.085298043877897

Epoch: 11| Step: 0
Training loss: 5.264457052407268
Validation loss: 5.080153372193977

Epoch: 6| Step: 1
Training loss: 4.678608510443478
Validation loss: 5.075166155220186

Epoch: 6| Step: 2
Training loss: 5.8515286005359854
Validation loss: 5.070095815862976

Epoch: 6| Step: 3
Training loss: 5.001201103903886
Validation loss: 5.064833805612474

Epoch: 6| Step: 4
Training loss: 4.964356981571583
Validation loss: 5.060293399612431

Epoch: 6| Step: 5
Training loss: 4.984635588432006
Validation loss: 5.054908130514006

Epoch: 6| Step: 6
Training loss: 5.178175669613852
Validation loss: 5.050453735967487

Epoch: 6| Step: 7
Training loss: 5.8838395517802615
Validation loss: 5.0451873067533795

Epoch: 6| Step: 8
Training loss: 5.485622687937447
Validation loss: 5.039928588563111

Epoch: 6| Step: 9
Training loss: 3.916597014003991
Validation loss: 5.034586714166976

Epoch: 6| Step: 10
Training loss: 4.8678528650846955
Validation loss: 5.030218488575421

Epoch: 6| Step: 11
Training loss: 5.587057361522029
Validation loss: 5.024366483719494

Epoch: 6| Step: 12
Training loss: 5.316635496871287
Validation loss: 5.019376973553263

Epoch: 6| Step: 13
Training loss: 5.1065436401355075
Validation loss: 5.014149481475697

Epoch: 12| Step: 0
Training loss: 4.715085659442351
Validation loss: 5.009570245235762

Epoch: 6| Step: 1
Training loss: 5.118677100103791
Validation loss: 5.004341164160859

Epoch: 6| Step: 2
Training loss: 5.061106925783033
Validation loss: 4.999204699526408

Epoch: 6| Step: 3
Training loss: 5.700744633807307
Validation loss: 4.994238840429594

Epoch: 6| Step: 4
Training loss: 4.194638444962803
Validation loss: 4.98944541830807

Epoch: 6| Step: 5
Training loss: 4.574128681863049
Validation loss: 4.984256770885269

Epoch: 6| Step: 6
Training loss: 5.356283558547878
Validation loss: 4.979123752467585

Epoch: 6| Step: 7
Training loss: 5.367893755559221
Validation loss: 4.974549689432221

Epoch: 6| Step: 8
Training loss: 5.272171614555543
Validation loss: 4.969608320719935

Epoch: 6| Step: 9
Training loss: 4.441300819507766
Validation loss: 4.96470330152488

Epoch: 6| Step: 10
Training loss: 5.3116922998702565
Validation loss: 4.959857364521249

Epoch: 6| Step: 11
Training loss: 5.480844779787334
Validation loss: 4.954651702587935

Epoch: 6| Step: 12
Training loss: 5.218039093023198
Validation loss: 4.950060019466388

Epoch: 6| Step: 13
Training loss: 5.351208573492673
Validation loss: 4.945377230911106

Epoch: 13| Step: 0
Training loss: 5.39222618316862
Validation loss: 4.940818685345944

Epoch: 6| Step: 1
Training loss: 6.036848089116888
Validation loss: 4.934984507976051

Epoch: 6| Step: 2
Training loss: 4.506949885985008
Validation loss: 4.929928184796093

Epoch: 6| Step: 3
Training loss: 5.2976046709464635
Validation loss: 4.926939958848013

Epoch: 6| Step: 4
Training loss: 4.641493385317625
Validation loss: 4.921362827032471

Epoch: 6| Step: 5
Training loss: 5.251478985954051
Validation loss: 4.91616894201643

Epoch: 6| Step: 6
Training loss: 4.521616198469818
Validation loss: 4.910390382463589

Epoch: 6| Step: 7
Training loss: 4.873502452401604
Validation loss: 4.904942656222983

Epoch: 6| Step: 8
Training loss: 5.569706909303396
Validation loss: 4.900747043728016

Epoch: 6| Step: 9
Training loss: 4.471468865314457
Validation loss: 4.8971116311279115

Epoch: 6| Step: 10
Training loss: 4.973836538478021
Validation loss: 4.892560581929626

Epoch: 6| Step: 11
Training loss: 4.571379290894141
Validation loss: 4.885411287588101

Epoch: 6| Step: 12
Training loss: 4.917463766021741
Validation loss: 4.882170270264195

Epoch: 6| Step: 13
Training loss: 5.18066084103929
Validation loss: 4.878217792626292

Epoch: 14| Step: 0
Training loss: 5.113000172815557
Validation loss: 4.874053895875912

Epoch: 6| Step: 1
Training loss: 4.424187692340883
Validation loss: 4.868896772060128

Epoch: 6| Step: 2
Training loss: 6.336200600463688
Validation loss: 4.866613853289953

Epoch: 6| Step: 3
Training loss: 4.44044847989893
Validation loss: 4.859441856913807

Epoch: 6| Step: 4
Training loss: 4.782063732837725
Validation loss: 4.854547586625657

Epoch: 6| Step: 5
Training loss: 5.320487984383366
Validation loss: 4.85118726506797

Epoch: 6| Step: 6
Training loss: 4.5546925251901955
Validation loss: 4.846819653534254

Epoch: 6| Step: 7
Training loss: 4.525976861710008
Validation loss: 4.84299714175039

Epoch: 6| Step: 8
Training loss: 5.653972356835965
Validation loss: 4.839307113342752

Epoch: 6| Step: 9
Training loss: 5.067104176822254
Validation loss: 4.834532632787389

Epoch: 6| Step: 10
Training loss: 4.9709229905941985
Validation loss: 4.828647260185982

Epoch: 6| Step: 11
Training loss: 5.16229781154365
Validation loss: 4.823197715705124

Epoch: 6| Step: 12
Training loss: 3.4785308409180824
Validation loss: 4.817758205946112

Epoch: 6| Step: 13
Training loss: 5.180521856112582
Validation loss: 4.815577592230617

Epoch: 15| Step: 0
Training loss: 5.435858116875097
Validation loss: 4.810910379354615

Epoch: 6| Step: 1
Training loss: 4.743153104559352
Validation loss: 4.804837025535792

Epoch: 6| Step: 2
Training loss: 5.448985455075469
Validation loss: 4.800792606134436

Epoch: 6| Step: 3
Training loss: 4.001690030700359
Validation loss: 4.796340266440346

Epoch: 6| Step: 4
Training loss: 4.113754665449772
Validation loss: 4.791806934902044

Epoch: 6| Step: 5
Training loss: 4.242479964092646
Validation loss: 4.787421006894786

Epoch: 6| Step: 6
Training loss: 5.388305695865327
Validation loss: 4.782908897753606

Epoch: 6| Step: 7
Training loss: 4.959985260172446
Validation loss: 4.778698175820994

Epoch: 6| Step: 8
Training loss: 4.857006808387111
Validation loss: 4.7742101332251154

Epoch: 6| Step: 9
Training loss: 5.131861118069764
Validation loss: 4.770110024116991

Epoch: 6| Step: 10
Training loss: 5.4290518189601125
Validation loss: 4.765513551169721

Epoch: 6| Step: 11
Training loss: 3.6414398460254263
Validation loss: 4.762083077725134

Epoch: 6| Step: 12
Training loss: 5.3735143693160525
Validation loss: 4.75690203026691

Epoch: 6| Step: 13
Training loss: 5.408428480881716
Validation loss: 4.7523474330449895

Epoch: 16| Step: 0
Training loss: 4.893785326989748
Validation loss: 4.747983906185959

Epoch: 6| Step: 1
Training loss: 5.113634486342577
Validation loss: 4.743436394378515

Epoch: 6| Step: 2
Training loss: 5.460544206375877
Validation loss: 4.739527166124594

Epoch: 6| Step: 3
Training loss: 4.671905415413639
Validation loss: 4.734441372749219

Epoch: 6| Step: 4
Training loss: 4.324181698689505
Validation loss: 4.729459689076778

Epoch: 6| Step: 5
Training loss: 4.688366415696105
Validation loss: 4.725043909854478

Epoch: 6| Step: 6
Training loss: 5.235055270044426
Validation loss: 4.72131490156283

Epoch: 6| Step: 7
Training loss: 4.453981979628288
Validation loss: 4.716667709530197

Epoch: 6| Step: 8
Training loss: 4.694626743807421
Validation loss: 4.713589269352025

Epoch: 6| Step: 9
Training loss: 5.433207779976347
Validation loss: 4.710489820103237

Epoch: 6| Step: 10
Training loss: 4.322323432877095
Validation loss: 4.705825959480137

Epoch: 6| Step: 11
Training loss: 4.798094355276756
Validation loss: 4.701866699736073

Epoch: 6| Step: 12
Training loss: 4.78801094695125
Validation loss: 4.6979499471744495

Epoch: 6| Step: 13
Training loss: 4.8117338289005085
Validation loss: 4.6921953378858134

Epoch: 17| Step: 0
Training loss: 5.14899095446099
Validation loss: 4.687844225642179

Epoch: 6| Step: 1
Training loss: 4.464309940817356
Validation loss: 4.683205922295341

Epoch: 6| Step: 2
Training loss: 5.616986479365515
Validation loss: 4.67803572690797

Epoch: 6| Step: 3
Training loss: 4.290659567185956
Validation loss: 4.673042245108064

Epoch: 6| Step: 4
Training loss: 4.210920287824285
Validation loss: 4.6685263073300405

Epoch: 6| Step: 5
Training loss: 4.859676830080604
Validation loss: 4.663691435110236

Epoch: 6| Step: 6
Training loss: 5.128597578535344
Validation loss: 4.659043977928202

Epoch: 6| Step: 7
Training loss: 4.975140762254677
Validation loss: 4.654804184479688

Epoch: 6| Step: 8
Training loss: 4.438730418517381
Validation loss: 4.650506165687426

Epoch: 6| Step: 9
Training loss: 3.794623566907048
Validation loss: 4.645763630479542

Epoch: 6| Step: 10
Training loss: 4.407111117581444
Validation loss: 4.640983593376436

Epoch: 6| Step: 11
Training loss: 5.01071658859301
Validation loss: 4.636959884873689

Epoch: 6| Step: 12
Training loss: 5.148624214178787
Validation loss: 4.63288351844017

Epoch: 6| Step: 13
Training loss: 5.161962315820523
Validation loss: 4.628871774880409

Epoch: 18| Step: 0
Training loss: 4.644826098452264
Validation loss: 4.624609458174298

Epoch: 6| Step: 1
Training loss: 5.2095255390057105
Validation loss: 4.620134767380508

Epoch: 6| Step: 2
Training loss: 5.641410794036392
Validation loss: 4.615816105231187

Epoch: 6| Step: 3
Training loss: 4.961207777455403
Validation loss: 4.609679476062259

Epoch: 6| Step: 4
Training loss: 4.4739213378702996
Validation loss: 4.604995595382478

Epoch: 6| Step: 5
Training loss: 4.626474094029341
Validation loss: 4.600512693001997

Epoch: 6| Step: 6
Training loss: 4.939311407491512
Validation loss: 4.5952775279606675

Epoch: 6| Step: 7
Training loss: 4.490787400698399
Validation loss: 4.590557277760731

Epoch: 6| Step: 8
Training loss: 3.3825971081109825
Validation loss: 4.585490562933111

Epoch: 6| Step: 9
Training loss: 4.697896186237001
Validation loss: 4.581634218099419

Epoch: 6| Step: 10
Training loss: 4.495413456148793
Validation loss: 4.577040542775247

Epoch: 6| Step: 11
Training loss: 4.511946608829468
Validation loss: 4.5723564946073125

Epoch: 6| Step: 12
Training loss: 4.606903965566161
Validation loss: 4.567473535654188

Epoch: 6| Step: 13
Training loss: 5.071250605386872
Validation loss: 4.562754898266804

Epoch: 19| Step: 0
Training loss: 4.607225026594502
Validation loss: 4.557771400996082

Epoch: 6| Step: 1
Training loss: 5.0830195387412775
Validation loss: 4.553009736210784

Epoch: 6| Step: 2
Training loss: 4.264933212132997
Validation loss: 4.5484954987539625

Epoch: 6| Step: 3
Training loss: 5.1115904504952026
Validation loss: 4.544009149954094

Epoch: 6| Step: 4
Training loss: 4.21787823747579
Validation loss: 4.539310870923215

Epoch: 6| Step: 5
Training loss: 4.445408181499927
Validation loss: 4.534748682266521

Epoch: 6| Step: 6
Training loss: 4.660899458757767
Validation loss: 4.530615330238177

Epoch: 6| Step: 7
Training loss: 4.671566343796499
Validation loss: 4.526450410507843

Epoch: 6| Step: 8
Training loss: 4.6302967156069545
Validation loss: 4.521124319154797

Epoch: 6| Step: 9
Training loss: 5.395982639598703
Validation loss: 4.516865807303932

Epoch: 6| Step: 10
Training loss: 4.65885903401029
Validation loss: 4.511907294491103

Epoch: 6| Step: 11
Training loss: 4.1078771610039
Validation loss: 4.507280500148514

Epoch: 6| Step: 12
Training loss: 4.587698343339232
Validation loss: 4.502133675993561

Epoch: 6| Step: 13
Training loss: 4.5746769858806955
Validation loss: 4.497937789568202

Epoch: 20| Step: 0
Training loss: 5.236742264371718
Validation loss: 4.492940911401522

Epoch: 6| Step: 1
Training loss: 4.8821065895981075
Validation loss: 4.488386710145007

Epoch: 6| Step: 2
Training loss: 4.439517569923798
Validation loss: 4.483273768590637

Epoch: 6| Step: 3
Training loss: 3.2931410630146236
Validation loss: 4.478605947957567

Epoch: 6| Step: 4
Training loss: 4.750170052144659
Validation loss: 4.474007881195125

Epoch: 6| Step: 5
Training loss: 4.171910660837756
Validation loss: 4.469806323993837

Epoch: 6| Step: 6
Training loss: 5.2337015658210895
Validation loss: 4.4653315952051225

Epoch: 6| Step: 7
Training loss: 4.426228351685513
Validation loss: 4.460176419673396

Epoch: 6| Step: 8
Training loss: 4.225079796393042
Validation loss: 4.4558628522243415

Epoch: 6| Step: 9
Training loss: 4.737001200564077
Validation loss: 4.451493277725091

Epoch: 6| Step: 10
Training loss: 3.78151279513575
Validation loss: 4.446878060335137

Epoch: 6| Step: 11
Training loss: 4.937806711448809
Validation loss: 4.442165429535349

Epoch: 6| Step: 12
Training loss: 5.076577476040256
Validation loss: 4.437673717554975

Epoch: 6| Step: 13
Training loss: 4.668924375900819
Validation loss: 4.4332306969504796

Epoch: 21| Step: 0
Training loss: 3.8892540412102568
Validation loss: 4.42840903983526

Epoch: 6| Step: 1
Training loss: 5.134322456745753
Validation loss: 4.423973996169344

Epoch: 6| Step: 2
Training loss: 3.726779251672715
Validation loss: 4.418946175759584

Epoch: 6| Step: 3
Training loss: 3.60371648957454
Validation loss: 4.414998525213886

Epoch: 6| Step: 4
Training loss: 3.8710122046942192
Validation loss: 4.4103916264205925

Epoch: 6| Step: 5
Training loss: 5.3236645237262685
Validation loss: 4.405898979760514

Epoch: 6| Step: 6
Training loss: 5.041897897173006
Validation loss: 4.401396438775663

Epoch: 6| Step: 7
Training loss: 3.875561089040245
Validation loss: 4.396926701722307

Epoch: 6| Step: 8
Training loss: 4.71932292769567
Validation loss: 4.392544563225173

Epoch: 6| Step: 9
Training loss: 5.316188115473489
Validation loss: 4.387601270530327

Epoch: 6| Step: 10
Training loss: 4.364877161349102
Validation loss: 4.382998357720444

Epoch: 6| Step: 11
Training loss: 4.281550932839983
Validation loss: 4.377705309817239

Epoch: 6| Step: 12
Training loss: 5.314437153997961
Validation loss: 4.373120185631688

Epoch: 6| Step: 13
Training loss: 4.325461108373167
Validation loss: 4.3682258840942545

Epoch: 22| Step: 0
Training loss: 3.249244602152805
Validation loss: 4.362284866172974

Epoch: 6| Step: 1
Training loss: 5.01703906699518
Validation loss: 4.358060431217955

Epoch: 6| Step: 2
Training loss: 4.433350247993803
Validation loss: 4.353195148969898

Epoch: 6| Step: 3
Training loss: 3.336824178671276
Validation loss: 4.349072787973542

Epoch: 6| Step: 4
Training loss: 4.18550677331466
Validation loss: 4.343476504125054

Epoch: 6| Step: 5
Training loss: 4.685293670211403
Validation loss: 4.339105716719509

Epoch: 6| Step: 6
Training loss: 4.623942073762784
Validation loss: 4.334866943165327

Epoch: 6| Step: 7
Training loss: 4.386383070972313
Validation loss: 4.330232807035509

Epoch: 6| Step: 8
Training loss: 3.227639376514083
Validation loss: 4.324938026528116

Epoch: 6| Step: 9
Training loss: 4.457266611609929
Validation loss: 4.31973722650636

Epoch: 6| Step: 10
Training loss: 5.21689376255499
Validation loss: 4.315489557430317

Epoch: 6| Step: 11
Training loss: 5.3047036801345655
Validation loss: 4.310245256194662

Epoch: 6| Step: 12
Training loss: 5.042484984179311
Validation loss: 4.305566382992711

Epoch: 6| Step: 13
Training loss: 4.560738001214569
Validation loss: 4.300295306570724

Epoch: 23| Step: 0
Training loss: 3.7564861153577405
Validation loss: 4.296017684952216

Epoch: 6| Step: 1
Training loss: 5.324837036504689
Validation loss: 4.2905650653991945

Epoch: 6| Step: 2
Training loss: 4.561857622466024
Validation loss: 4.285553859553981

Epoch: 6| Step: 3
Training loss: 3.699126970548359
Validation loss: 4.280371044362271

Epoch: 6| Step: 4
Training loss: 4.425053293370592
Validation loss: 4.275385345878612

Epoch: 6| Step: 5
Training loss: 5.309987090933817
Validation loss: 4.270469178592682

Epoch: 6| Step: 6
Training loss: 4.107855105986254
Validation loss: 4.265079067446896

Epoch: 6| Step: 7
Training loss: 4.012984658321026
Validation loss: 4.260209443043404

Epoch: 6| Step: 8
Training loss: 4.230857824184925
Validation loss: 4.254763551560713

Epoch: 6| Step: 9
Training loss: 4.175766633510434
Validation loss: 4.249419266162109

Epoch: 6| Step: 10
Training loss: 4.132413502345829
Validation loss: 4.24471436724655

Epoch: 6| Step: 11
Training loss: 4.2901718845034615
Validation loss: 4.240366545494016

Epoch: 6| Step: 12
Training loss: 4.819197119169654
Validation loss: 4.235430483866662

Epoch: 6| Step: 13
Training loss: 4.315733650933614
Validation loss: 4.230083491476121

Epoch: 24| Step: 0
Training loss: 5.012519992398468
Validation loss: 4.224778471637251

Epoch: 6| Step: 1
Training loss: 3.595114540111143
Validation loss: 4.219866833205304

Epoch: 6| Step: 2
Training loss: 4.733507939373228
Validation loss: 4.215461051737161

Epoch: 6| Step: 3
Training loss: 4.744354105041427
Validation loss: 4.210357324080413

Epoch: 6| Step: 4
Training loss: 4.629983845758785
Validation loss: 4.204988957351658

Epoch: 6| Step: 5
Training loss: 3.704656356751413
Validation loss: 4.1996583315219596

Epoch: 6| Step: 6
Training loss: 4.522523672401466
Validation loss: 4.194514003847756

Epoch: 6| Step: 7
Training loss: 4.771790565288319
Validation loss: 4.189766227919727

Epoch: 6| Step: 8
Training loss: 3.9852369385929958
Validation loss: 4.184323239831342

Epoch: 6| Step: 9
Training loss: 4.168801993942297
Validation loss: 4.178569874823363

Epoch: 6| Step: 10
Training loss: 4.091225347913765
Validation loss: 4.173391611791238

Epoch: 6| Step: 11
Training loss: 3.72391670399408
Validation loss: 4.168450577642914

Epoch: 6| Step: 12
Training loss: 3.826927028752761
Validation loss: 4.163768249764899

Epoch: 6| Step: 13
Training loss: 4.689586124337427
Validation loss: 4.158852128339095

Epoch: 25| Step: 0
Training loss: 4.063864610804742
Validation loss: 4.153229823151862

Epoch: 6| Step: 1
Training loss: 4.005851756757749
Validation loss: 4.14854901314169

Epoch: 6| Step: 2
Training loss: 4.796033555575996
Validation loss: 4.1436043247184005

Epoch: 6| Step: 3
Training loss: 4.6968479787692665
Validation loss: 4.138249436776453

Epoch: 6| Step: 4
Training loss: 4.125549279835543
Validation loss: 4.132877572886802

Epoch: 6| Step: 5
Training loss: 4.46233371456862
Validation loss: 4.127744416783342

Epoch: 6| Step: 6
Training loss: 3.5905811436616704
Validation loss: 4.121586437213195

Epoch: 6| Step: 7
Training loss: 4.485943350527359
Validation loss: 4.116415164899485

Epoch: 6| Step: 8
Training loss: 4.765971186836925
Validation loss: 4.11095025990815

Epoch: 6| Step: 9
Training loss: 4.123412780571983
Validation loss: 4.10553826328594

Epoch: 6| Step: 10
Training loss: 3.6454809981350436
Validation loss: 4.100130597802571

Epoch: 6| Step: 11
Training loss: 3.4609383266611595
Validation loss: 4.095104721369845

Epoch: 6| Step: 12
Training loss: 4.577506274183089
Validation loss: 4.0899665180132265

Epoch: 6| Step: 13
Training loss: 4.428911521263841
Validation loss: 4.084717421903748

Epoch: 26| Step: 0
Training loss: 3.7032201569640475
Validation loss: 4.078724764668786

Epoch: 6| Step: 1
Training loss: 4.069373785858606
Validation loss: 4.073848894106373

Epoch: 6| Step: 2
Training loss: 4.5787890476704
Validation loss: 4.069023098938569

Epoch: 6| Step: 3
Training loss: 3.5351797197943298
Validation loss: 4.063595061777276

Epoch: 6| Step: 4
Training loss: 4.120393203564138
Validation loss: 4.059080337664173

Epoch: 6| Step: 5
Training loss: 4.000190253501573
Validation loss: 4.053612440960884

Epoch: 6| Step: 6
Training loss: 4.4674305068184275
Validation loss: 4.0488113032480895

Epoch: 6| Step: 7
Training loss: 4.284659928099649
Validation loss: 4.04298026901791

Epoch: 6| Step: 8
Training loss: 3.92559346371455
Validation loss: 4.037444645961815

Epoch: 6| Step: 9
Training loss: 4.6753773909234955
Validation loss: 4.032673015347532

Epoch: 6| Step: 10
Training loss: 3.0539890281015496
Validation loss: 4.028278053755617

Epoch: 6| Step: 11
Training loss: 4.993470697147575
Validation loss: 4.022382381814667

Epoch: 6| Step: 12
Training loss: 3.9671431765459806
Validation loss: 4.016969487869608

Epoch: 6| Step: 13
Training loss: 4.689098034895344
Validation loss: 4.011595172210668

Epoch: 27| Step: 0
Training loss: 4.092184684784494
Validation loss: 4.0055589989517895

Epoch: 6| Step: 1
Training loss: 4.97952962959668
Validation loss: 4.000712390881405

Epoch: 6| Step: 2
Training loss: 4.4547159130484175
Validation loss: 3.9949007114744903

Epoch: 6| Step: 3
Training loss: 4.482418896377006
Validation loss: 3.9883987952435636

Epoch: 6| Step: 4
Training loss: 4.066130908215344
Validation loss: 3.98410679531585

Epoch: 6| Step: 5
Training loss: 3.3768568229291978
Validation loss: 3.97705109098436

Epoch: 6| Step: 6
Training loss: 4.065164953734869
Validation loss: 3.9713461687184664

Epoch: 6| Step: 7
Training loss: 3.2592100077899135
Validation loss: 3.9650647933303205

Epoch: 6| Step: 8
Training loss: 3.9531123345816748
Validation loss: 3.9592636755126436

Epoch: 6| Step: 9
Training loss: 3.41900305221167
Validation loss: 3.954075373623088

Epoch: 6| Step: 10
Training loss: 4.433213863818608
Validation loss: 3.9487628415776315

Epoch: 6| Step: 11
Training loss: 4.674605474297487
Validation loss: 3.943959483181646

Epoch: 6| Step: 12
Training loss: 4.027088708507241
Validation loss: 3.937276884347574

Epoch: 6| Step: 13
Training loss: 3.756804459918168
Validation loss: 3.9312675843606173

Epoch: 28| Step: 0
Training loss: 3.8650103364833384
Validation loss: 3.9261363310149555

Epoch: 6| Step: 1
Training loss: 3.1272669389884884
Validation loss: 3.9201675487574783

Epoch: 6| Step: 2
Training loss: 3.981424952425254
Validation loss: 3.9147806327328283

Epoch: 6| Step: 3
Training loss: 4.7894360643964555
Validation loss: 3.909178935297153

Epoch: 6| Step: 4
Training loss: 5.05564284103741
Validation loss: 3.9028729705845997

Epoch: 6| Step: 5
Training loss: 3.593471615831156
Validation loss: 3.8962213183642462

Epoch: 6| Step: 6
Training loss: 2.9059615453497933
Validation loss: 3.8920868931930905

Epoch: 6| Step: 7
Training loss: 3.8946997205286493
Validation loss: 3.886555393179064

Epoch: 6| Step: 8
Training loss: 4.7432614764741885
Validation loss: 3.880566956334868

Epoch: 6| Step: 9
Training loss: 4.442078498418099
Validation loss: 3.8747755621445474

Epoch: 6| Step: 10
Training loss: 3.381437731483011
Validation loss: 3.8698819108437577

Epoch: 6| Step: 11
Training loss: 4.38997637210127
Validation loss: 3.8636491302714497

Epoch: 6| Step: 12
Training loss: 3.4983404857410325
Validation loss: 3.8586136997569906

Epoch: 6| Step: 13
Training loss: 3.96832525428442
Validation loss: 3.8528546170639397

Epoch: 29| Step: 0
Training loss: 4.19863867723139
Validation loss: 3.847284402968333

Epoch: 6| Step: 1
Training loss: 3.7578989126060485
Validation loss: 3.840898815768518

Epoch: 6| Step: 2
Training loss: 4.752797959091192
Validation loss: 3.8353429205312866

Epoch: 6| Step: 3
Training loss: 3.568364853794713
Validation loss: 3.8291754702085314

Epoch: 6| Step: 4
Training loss: 4.795537209116768
Validation loss: 3.823382183839323

Epoch: 6| Step: 5
Training loss: 4.137370892956515
Validation loss: 3.8171633565177956

Epoch: 6| Step: 6
Training loss: 4.223335543187583
Validation loss: 3.8116762282286762

Epoch: 6| Step: 7
Training loss: 3.250367363928004
Validation loss: 3.8058192393024757

Epoch: 6| Step: 8
Training loss: 2.6578716040514534
Validation loss: 3.800143787942943

Epoch: 6| Step: 9
Training loss: 3.6221073053095427
Validation loss: 3.7953852071088887

Epoch: 6| Step: 10
Training loss: 4.98757841196781
Validation loss: 3.7900309894740847

Epoch: 6| Step: 11
Training loss: 4.210287691557277
Validation loss: 3.784162434856505

Epoch: 6| Step: 12
Training loss: 3.8562127258378864
Validation loss: 3.77786982336917

Epoch: 6| Step: 13
Training loss: 2.222512936119991
Validation loss: 3.7722034108050724

Epoch: 30| Step: 0
Training loss: 4.364749999342768
Validation loss: 3.767370787499224

Epoch: 6| Step: 1
Training loss: 3.8297760808840917
Validation loss: 3.76152154782565

Epoch: 6| Step: 2
Training loss: 4.501563754175892
Validation loss: 3.756745967609054

Epoch: 6| Step: 3
Training loss: 3.558030252406319
Validation loss: 3.751079785337715

Epoch: 6| Step: 4
Training loss: 3.8442216289193025
Validation loss: 3.7454119696025203

Epoch: 6| Step: 5
Training loss: 4.320810023765754
Validation loss: 3.7405985071470496

Epoch: 6| Step: 6
Training loss: 3.9395949830371007
Validation loss: 3.735178415445065

Epoch: 6| Step: 7
Training loss: 3.779412319578836
Validation loss: 3.7304616558546746

Epoch: 6| Step: 8
Training loss: 2.8546684176804744
Validation loss: 3.7250690359933825

Epoch: 6| Step: 9
Training loss: 3.0719062997614626
Validation loss: 3.7198410570719735

Epoch: 6| Step: 10
Training loss: 3.66290928763775
Validation loss: 3.7151151144163306

Epoch: 6| Step: 11
Training loss: 3.540073679787639
Validation loss: 3.710247117455531

Epoch: 6| Step: 12
Training loss: 4.377722628698438
Validation loss: 3.704792060593898

Epoch: 6| Step: 13
Training loss: 4.140650565590296
Validation loss: 3.7002539685008995

Epoch: 31| Step: 0
Training loss: 3.4825907017492947
Validation loss: 3.6949834374661834

Epoch: 6| Step: 1
Training loss: 3.683151526013316
Validation loss: 3.691325902316708

Epoch: 6| Step: 2
Training loss: 3.9717817366100374
Validation loss: 3.686220949407116

Epoch: 6| Step: 3
Training loss: 3.705001162633057
Validation loss: 3.680727628768111

Epoch: 6| Step: 4
Training loss: 4.313158731321762
Validation loss: 3.6761697529397632

Epoch: 6| Step: 5
Training loss: 4.668586926248611
Validation loss: 3.670667041096343

Epoch: 6| Step: 6
Training loss: 3.5863219077984314
Validation loss: 3.665843322097433

Epoch: 6| Step: 7
Training loss: 3.6499301381153253
Validation loss: 3.661204098176811

Epoch: 6| Step: 8
Training loss: 3.36554438955809
Validation loss: 3.6555566592216433

Epoch: 6| Step: 9
Training loss: 3.9150360175920436
Validation loss: 3.6510116350985853

Epoch: 6| Step: 10
Training loss: 4.43558880119716
Validation loss: 3.6457277700491146

Epoch: 6| Step: 11
Training loss: 3.3079527827425235
Validation loss: 3.641148869229412

Epoch: 6| Step: 12
Training loss: 3.441953790863192
Validation loss: 3.63607479722013

Epoch: 6| Step: 13
Training loss: 3.370383602235909
Validation loss: 3.6313205622406497

Epoch: 32| Step: 0
Training loss: 3.4391300844712225
Validation loss: 3.6265112258987733

Epoch: 6| Step: 1
Training loss: 3.7330204889372354
Validation loss: 3.6220382012940595

Epoch: 6| Step: 2
Training loss: 3.4954954860845273
Validation loss: 3.6175047238944527

Epoch: 6| Step: 3
Training loss: 3.9782214947884285
Validation loss: 3.6127162072271313

Epoch: 6| Step: 4
Training loss: 3.6900961837018156
Validation loss: 3.607727269173291

Epoch: 6| Step: 5
Training loss: 4.059136039625131
Validation loss: 3.6029832179596006

Epoch: 6| Step: 6
Training loss: 3.9375733868254117
Validation loss: 3.59824092944825

Epoch: 6| Step: 7
Training loss: 3.8914368789652993
Validation loss: 3.5935062049326314

Epoch: 6| Step: 8
Training loss: 3.90997124995518
Validation loss: 3.5890818698190423

Epoch: 6| Step: 9
Training loss: 3.663010045493158
Validation loss: 3.5842588175818397

Epoch: 6| Step: 10
Training loss: 3.229567931480595
Validation loss: 3.5798331990445256

Epoch: 6| Step: 11
Training loss: 4.246214583291041
Validation loss: 3.5750500655503283

Epoch: 6| Step: 12
Training loss: 3.45617651421511
Validation loss: 3.56985545276253

Epoch: 6| Step: 13
Training loss: 3.408259647633025
Validation loss: 3.565220602663791

Epoch: 33| Step: 0
Training loss: 3.6836266298738027
Validation loss: 3.5606218707817674

Epoch: 6| Step: 1
Training loss: 3.3726312307243185
Validation loss: 3.5562453436974657

Epoch: 6| Step: 2
Training loss: 4.321615343437653
Validation loss: 3.5520821549906785

Epoch: 6| Step: 3
Training loss: 4.420360292275437
Validation loss: 3.5471106855647143

Epoch: 6| Step: 4
Training loss: 3.2276568092648192
Validation loss: 3.542411785656105

Epoch: 6| Step: 5
Training loss: 4.305522858416918
Validation loss: 3.537514230724238

Epoch: 6| Step: 6
Training loss: 3.6605306492910854
Validation loss: 3.5326761612249538

Epoch: 6| Step: 7
Training loss: 4.405138890201735
Validation loss: 3.527661956594606

Epoch: 6| Step: 8
Training loss: 3.709504374792407
Validation loss: 3.522292893627002

Epoch: 6| Step: 9
Training loss: 2.8434563789114073
Validation loss: 3.517816699641326

Epoch: 6| Step: 10
Training loss: 3.276846119289393
Validation loss: 3.513045974238053

Epoch: 6| Step: 11
Training loss: 3.3573571110682034
Validation loss: 3.5086928341236643

Epoch: 6| Step: 12
Training loss: 2.936978232937226
Validation loss: 3.50410418339442

Epoch: 6| Step: 13
Training loss: 3.376174439845578
Validation loss: 3.5000869535816457

Epoch: 34| Step: 0
Training loss: 3.0813714736609423
Validation loss: 3.4955638519437096

Epoch: 6| Step: 1
Training loss: 4.104314552908774
Validation loss: 3.4914759651371816

Epoch: 6| Step: 2
Training loss: 3.447461485229193
Validation loss: 3.487090792969124

Epoch: 6| Step: 3
Training loss: 3.8020546829328636
Validation loss: 3.4831689820158633

Epoch: 6| Step: 4
Training loss: 3.5238464524139568
Validation loss: 3.478566161696577

Epoch: 6| Step: 5
Training loss: 4.064166152846649
Validation loss: 3.474521360663888

Epoch: 6| Step: 6
Training loss: 3.359109699507838
Validation loss: 3.46948355859787

Epoch: 6| Step: 7
Training loss: 3.8482738638195997
Validation loss: 3.4646954596094206

Epoch: 6| Step: 8
Training loss: 3.8543332175620146
Validation loss: 3.4604089245756486

Epoch: 6| Step: 9
Training loss: 2.423634437611521
Validation loss: 3.4555504797489003

Epoch: 6| Step: 10
Training loss: 3.6929750045810557
Validation loss: 3.451021638430806

Epoch: 6| Step: 11
Training loss: 3.5932709747829725
Validation loss: 3.4471691892569454

Epoch: 6| Step: 12
Training loss: 3.9114629522805133
Validation loss: 3.4425275392522767

Epoch: 6| Step: 13
Training loss: 3.4284133108327266
Validation loss: 3.4378956653725763

Epoch: 35| Step: 0
Training loss: 3.6965172640504265
Validation loss: 3.433287611598286

Epoch: 6| Step: 1
Training loss: 3.0624847411729244
Validation loss: 3.4290448443318264

Epoch: 6| Step: 2
Training loss: 2.9691515199280443
Validation loss: 3.4242581875167937

Epoch: 6| Step: 3
Training loss: 3.9401215802715757
Validation loss: 3.4197576931115963

Epoch: 6| Step: 4
Training loss: 3.7208367911931823
Validation loss: 3.415416259995187

Epoch: 6| Step: 5
Training loss: 3.6061258595485524
Validation loss: 3.4109089338615353

Epoch: 6| Step: 6
Training loss: 3.5688417439601627
Validation loss: 3.406419044056371

Epoch: 6| Step: 7
Training loss: 4.028400922488919
Validation loss: 3.40185939350014

Epoch: 6| Step: 8
Training loss: 3.4709223912518916
Validation loss: 3.397153812162229

Epoch: 6| Step: 9
Training loss: 3.7506077591814933
Validation loss: 3.392929161473823

Epoch: 6| Step: 10
Training loss: 4.0784729557017565
Validation loss: 3.388814146662924

Epoch: 6| Step: 11
Training loss: 2.8331109875968488
Validation loss: 3.3837837310939842

Epoch: 6| Step: 12
Training loss: 3.15919191337472
Validation loss: 3.379878074527312

Epoch: 6| Step: 13
Training loss: 3.4730492145314638
Validation loss: 3.3757003010534192

Epoch: 36| Step: 0
Training loss: 3.9646809060616275
Validation loss: 3.371369516726788

Epoch: 6| Step: 1
Training loss: 3.3241148953738775
Validation loss: 3.3674763307067623

Epoch: 6| Step: 2
Training loss: 3.6656718349472963
Validation loss: 3.363994857927793

Epoch: 6| Step: 3
Training loss: 3.34190916923946
Validation loss: 3.359100661793693

Epoch: 6| Step: 4
Training loss: 2.821926680014548
Validation loss: 3.354805729486405

Epoch: 6| Step: 5
Training loss: 2.801082153330354
Validation loss: 3.350943033136203

Epoch: 6| Step: 6
Training loss: 3.675769185645385
Validation loss: 3.347142302129285

Epoch: 6| Step: 7
Training loss: 3.5663291028673303
Validation loss: 3.342941519185122

Epoch: 6| Step: 8
Training loss: 3.664143966061967
Validation loss: 3.3389526130137113

Epoch: 6| Step: 9
Training loss: 3.92444541560567
Validation loss: 3.334826651495105

Epoch: 6| Step: 10
Training loss: 3.4786198047285377
Validation loss: 3.3309939201938525

Epoch: 6| Step: 11
Training loss: 3.94258515918512
Validation loss: 3.3263697644672567

Epoch: 6| Step: 12
Training loss: 3.1768162015749146
Validation loss: 3.3220654935097427

Epoch: 6| Step: 13
Training loss: 3.181637927312392
Validation loss: 3.318200251083513

Epoch: 37| Step: 0
Training loss: 3.2292157733423794
Validation loss: 3.3144155637687955

Epoch: 6| Step: 1
Training loss: 3.5998395990029617
Validation loss: 3.3102412530042926

Epoch: 6| Step: 2
Training loss: 3.606683693761584
Validation loss: 3.3064151273185542

Epoch: 6| Step: 3
Training loss: 3.363252469071469
Validation loss: 3.30239382145523

Epoch: 6| Step: 4
Training loss: 4.248562289134785
Validation loss: 3.298658638773498

Epoch: 6| Step: 5
Training loss: 3.3641162150444797
Validation loss: 3.294705633888874

Epoch: 6| Step: 6
Training loss: 2.8655801784125905
Validation loss: 3.290124837908962

Epoch: 6| Step: 7
Training loss: 3.0427882247478317
Validation loss: 3.2868735186678744

Epoch: 6| Step: 8
Training loss: 3.3634726439988643
Validation loss: 3.282784239526145

Epoch: 6| Step: 9
Training loss: 3.9070420339611345
Validation loss: 3.279295372446673

Epoch: 6| Step: 10
Training loss: 3.343489021740759
Validation loss: 3.275324748587492

Epoch: 6| Step: 11
Training loss: 2.788437033224318
Validation loss: 3.2711161270512026

Epoch: 6| Step: 12
Training loss: 3.5668065325921985
Validation loss: 3.267331919920882

Epoch: 6| Step: 13
Training loss: 3.446271767144544
Validation loss: 3.2636200074891826

Epoch: 38| Step: 0
Training loss: 3.0828059664781247
Validation loss: 3.259827732281541

Epoch: 6| Step: 1
Training loss: 3.172758233132207
Validation loss: 3.256523798330767

Epoch: 6| Step: 2
Training loss: 3.269013321665882
Validation loss: 3.2522657272799593

Epoch: 6| Step: 3
Training loss: 3.348862491895423
Validation loss: 3.2486702326000843

Epoch: 6| Step: 4
Training loss: 3.2842560576906954
Validation loss: 3.244744404080683

Epoch: 6| Step: 5
Training loss: 3.849988882866204
Validation loss: 3.2405364831001706

Epoch: 6| Step: 6
Training loss: 3.8695374410030223
Validation loss: 3.2368816791727486

Epoch: 6| Step: 7
Training loss: 2.963362453161711
Validation loss: 3.2330701471819507

Epoch: 6| Step: 8
Training loss: 3.099865504392845
Validation loss: 3.229274764353852

Epoch: 6| Step: 9
Training loss: 3.6432816794998435
Validation loss: 3.2255936123122124

Epoch: 6| Step: 10
Training loss: 3.6913650429661016
Validation loss: 3.2219687851811165

Epoch: 6| Step: 11
Training loss: 3.104069770137008
Validation loss: 3.2182637560326772

Epoch: 6| Step: 12
Training loss: 3.4721672477608765
Validation loss: 3.2150891049319266

Epoch: 6| Step: 13
Training loss: 3.2619848085724468
Validation loss: 3.2112056747036335

Epoch: 39| Step: 0
Training loss: 3.5720170707850056
Validation loss: 3.207164245895833

Epoch: 6| Step: 1
Training loss: 3.396673336552843
Validation loss: 3.2036659962385463

Epoch: 6| Step: 2
Training loss: 3.3628497937994104
Validation loss: 3.199850067460774

Epoch: 6| Step: 3
Training loss: 3.5987557751210746
Validation loss: 3.196576304572342

Epoch: 6| Step: 4
Training loss: 3.340390808632207
Validation loss: 3.1922304543598785

Epoch: 6| Step: 5
Training loss: 3.020911292462304
Validation loss: 3.1888936056780812

Epoch: 6| Step: 6
Training loss: 3.280879263142557
Validation loss: 3.184936589718187

Epoch: 6| Step: 7
Training loss: 2.9325776759638478
Validation loss: 3.1820617609382147

Epoch: 6| Step: 8
Training loss: 3.433554031784642
Validation loss: 3.1783213136869444

Epoch: 6| Step: 9
Training loss: 3.7656689399909804
Validation loss: 3.175031072109096

Epoch: 6| Step: 10
Training loss: 2.961301756020477
Validation loss: 3.171254665805871

Epoch: 6| Step: 11
Training loss: 3.0710571007396488
Validation loss: 3.1679096961171562

Epoch: 6| Step: 12
Training loss: 3.402136602566748
Validation loss: 3.164726934801599

Epoch: 6| Step: 13
Training loss: 3.3096311129705787
Validation loss: 3.16121585089904

Epoch: 40| Step: 0
Training loss: 3.9384403619632495
Validation loss: 3.1583396616312878

Epoch: 6| Step: 1
Training loss: 3.762408517124562
Validation loss: 3.1544096337035783

Epoch: 6| Step: 2
Training loss: 3.128505419179726
Validation loss: 3.150714817382499

Epoch: 6| Step: 3
Training loss: 3.1694066257061153
Validation loss: 3.147456998523753

Epoch: 6| Step: 4
Training loss: 2.9794220892688146
Validation loss: 3.1443536617450003

Epoch: 6| Step: 5
Training loss: 3.1754064585116994
Validation loss: 3.140544390553308

Epoch: 6| Step: 6
Training loss: 3.13254110249971
Validation loss: 3.1372050173266883

Epoch: 6| Step: 7
Training loss: 2.7177471196623695
Validation loss: 3.134027513415311

Epoch: 6| Step: 8
Training loss: 3.438762918307279
Validation loss: 3.1309843873282794

Epoch: 6| Step: 9
Training loss: 2.973525853731159
Validation loss: 3.1279232848045617

Epoch: 6| Step: 10
Training loss: 3.4890081282674323
Validation loss: 3.124745651066702

Epoch: 6| Step: 11
Training loss: 3.8395558867333386
Validation loss: 3.121339790662919

Epoch: 6| Step: 12
Training loss: 2.8736516029533314
Validation loss: 3.117771167336499

Epoch: 6| Step: 13
Training loss: 2.998365274725331
Validation loss: 3.1147135236358525

Epoch: 41| Step: 0
Training loss: 3.238591932755527
Validation loss: 3.1116360058846335

Epoch: 6| Step: 1
Training loss: 3.360135866097568
Validation loss: 3.1082384853533793

Epoch: 6| Step: 2
Training loss: 3.8783112191516627
Validation loss: 3.1051205869756218

Epoch: 6| Step: 3
Training loss: 3.065204438303617
Validation loss: 3.101908589999238

Epoch: 6| Step: 4
Training loss: 2.8995291820990934
Validation loss: 3.098540504989008

Epoch: 6| Step: 5
Training loss: 3.4556878017239057
Validation loss: 3.095343388174326

Epoch: 6| Step: 6
Training loss: 3.2235305987184337
Validation loss: 3.091847563709832

Epoch: 6| Step: 7
Training loss: 2.8336601255860634
Validation loss: 3.0885759880298944

Epoch: 6| Step: 8
Training loss: 3.405246691849011
Validation loss: 3.085462882970581

Epoch: 6| Step: 9
Training loss: 3.5820502859959698
Validation loss: 3.08275680478792

Epoch: 6| Step: 10
Training loss: 2.9057835030191868
Validation loss: 3.07913443187588

Epoch: 6| Step: 11
Training loss: 3.4427563793313576
Validation loss: 3.076264957049054

Epoch: 6| Step: 12
Training loss: 2.7384276956315023
Validation loss: 3.0728744159099937

Epoch: 6| Step: 13
Training loss: 3.037656797278817
Validation loss: 3.0699484417590135

Epoch: 42| Step: 0
Training loss: 2.5101520404133315
Validation loss: 3.0670752571026227

Epoch: 6| Step: 1
Training loss: 3.677587472794652
Validation loss: 3.0641654280500177

Epoch: 6| Step: 2
Training loss: 2.7035825485458655
Validation loss: 3.0613309094957177

Epoch: 6| Step: 3
Training loss: 3.296761605721733
Validation loss: 3.0590871491710314

Epoch: 6| Step: 4
Training loss: 3.776442821722869
Validation loss: 3.0559524817775165

Epoch: 6| Step: 5
Training loss: 3.225037886522705
Validation loss: 3.0533308966458965

Epoch: 6| Step: 6
Training loss: 3.322294186890379
Validation loss: 3.0504255816061865

Epoch: 6| Step: 7
Training loss: 3.146130192036194
Validation loss: 3.0474470987127766

Epoch: 6| Step: 8
Training loss: 3.4945142534483544
Validation loss: 3.0444620342705586

Epoch: 6| Step: 9
Training loss: 3.248080787321084
Validation loss: 3.0416506718950953

Epoch: 6| Step: 10
Training loss: 2.8990767357556795
Validation loss: 3.038343944443842

Epoch: 6| Step: 11
Training loss: 2.7493875862001724
Validation loss: 3.0355926487967073

Epoch: 6| Step: 12
Training loss: 3.369200916580099
Validation loss: 3.032571524195626

Epoch: 6| Step: 13
Training loss: 2.9727568239700415
Validation loss: 3.0299210011011204

Epoch: 43| Step: 0
Training loss: 3.2053402567432716
Validation loss: 3.0268984099942737

Epoch: 6| Step: 1
Training loss: 2.710228027378542
Validation loss: 3.0240623754950904

Epoch: 6| Step: 2
Training loss: 3.4990966175974947
Validation loss: 3.0213702722172897

Epoch: 6| Step: 3
Training loss: 3.1732271065549957
Validation loss: 3.018754590269907

Epoch: 6| Step: 4
Training loss: 3.155177472378083
Validation loss: 3.0160281450466035

Epoch: 6| Step: 5
Training loss: 3.2904641252482754
Validation loss: 3.0130194573603957

Epoch: 6| Step: 6
Training loss: 3.607570576972053
Validation loss: 3.0101296883163693

Epoch: 6| Step: 7
Training loss: 3.54193591422075
Validation loss: 3.007419524179711

Epoch: 6| Step: 8
Training loss: 2.976986351773797
Validation loss: 3.004355712388546

Epoch: 6| Step: 9
Training loss: 2.8729378311967326
Validation loss: 3.001327128385143

Epoch: 6| Step: 10
Training loss: 3.161311557301669
Validation loss: 2.998641024188017

Epoch: 6| Step: 11
Training loss: 3.033191491747653
Validation loss: 2.9960905404137934

Epoch: 6| Step: 12
Training loss: 3.1646913256791116
Validation loss: 2.9931143179364543

Epoch: 6| Step: 13
Training loss: 2.540798685253197
Validation loss: 2.990238733701646

Epoch: 44| Step: 0
Training loss: 3.2711596154104416
Validation loss: 2.987625748290258

Epoch: 6| Step: 1
Training loss: 3.617921561121014
Validation loss: 2.9851684980050504

Epoch: 6| Step: 2
Training loss: 3.28526946427243
Validation loss: 2.982388525982268

Epoch: 6| Step: 3
Training loss: 3.0717600741770354
Validation loss: 2.9796480487944974

Epoch: 6| Step: 4
Training loss: 3.7558711820943507
Validation loss: 2.9772091727937595

Epoch: 6| Step: 5
Training loss: 3.1137544853824393
Validation loss: 2.974383780828582

Epoch: 6| Step: 6
Training loss: 2.4924237847799904
Validation loss: 2.9718919423954473

Epoch: 6| Step: 7
Training loss: 3.369161288433011
Validation loss: 2.9692578734604806

Epoch: 6| Step: 8
Training loss: 2.9426015828892904
Validation loss: 2.9665900018694344

Epoch: 6| Step: 9
Training loss: 2.8872248266643576
Validation loss: 2.964151414694882

Epoch: 6| Step: 10
Training loss: 3.151693246273107
Validation loss: 2.9613853927755627

Epoch: 6| Step: 11
Training loss: 2.990988070174352
Validation loss: 2.959134548560469

Epoch: 6| Step: 12
Training loss: 3.332133283763445
Validation loss: 2.95641824137368

Epoch: 6| Step: 13
Training loss: 1.842441676548252
Validation loss: 2.953727660673808

Epoch: 45| Step: 0
Training loss: 3.082122840052271
Validation loss: 2.9512867260373503

Epoch: 6| Step: 1
Training loss: 3.4287402815338597
Validation loss: 2.948645125428645

Epoch: 6| Step: 2
Training loss: 3.4305780249583524
Validation loss: 2.9461278351833733

Epoch: 6| Step: 3
Training loss: 3.5183756600391964
Validation loss: 2.943511844188477

Epoch: 6| Step: 4
Training loss: 3.439993214267869
Validation loss: 2.940879676700874

Epoch: 6| Step: 5
Training loss: 2.8834022807732804
Validation loss: 2.938074055846542

Epoch: 6| Step: 6
Training loss: 2.6976663677115327
Validation loss: 2.9354958156494577

Epoch: 6| Step: 7
Training loss: 2.9008269216248723
Validation loss: 2.932901746976847

Epoch: 6| Step: 8
Training loss: 3.447622757262111
Validation loss: 2.9306852142272355

Epoch: 6| Step: 9
Training loss: 2.6346897032299474
Validation loss: 2.928116874995675

Epoch: 6| Step: 10
Training loss: 3.215963249841113
Validation loss: 2.9259522086338787

Epoch: 6| Step: 11
Training loss: 2.363455370328922
Validation loss: 2.92354726281196

Epoch: 6| Step: 12
Training loss: 2.433301782621222
Validation loss: 2.9213856169953423

Epoch: 6| Step: 13
Training loss: 3.291128058168456
Validation loss: 2.9189856075408174

Epoch: 46| Step: 0
Training loss: 3.199115458068104
Validation loss: 2.9168735612422014

Epoch: 6| Step: 1
Training loss: 3.1317983303304113
Validation loss: 2.914698009039168

Epoch: 6| Step: 2
Training loss: 2.824972851378036
Validation loss: 2.9128002333985568

Epoch: 6| Step: 3
Training loss: 2.8635443635504383
Validation loss: 2.9106873302899943

Epoch: 6| Step: 4
Training loss: 3.220696018412414
Validation loss: 2.908427335500657

Epoch: 6| Step: 5
Training loss: 2.684700683447708
Validation loss: 2.9063961443508246

Epoch: 6| Step: 6
Training loss: 2.3751995605149703
Validation loss: 2.9042739850159602

Epoch: 6| Step: 7
Training loss: 3.627640124505848
Validation loss: 2.902329565931721

Epoch: 6| Step: 8
Training loss: 3.3673017796641855
Validation loss: 2.9001902501413195

Epoch: 6| Step: 9
Training loss: 3.2374214899271894
Validation loss: 2.898116471847942

Epoch: 6| Step: 10
Training loss: 3.2768987960577136
Validation loss: 2.8958461861816884

Epoch: 6| Step: 11
Training loss: 2.739829590224852
Validation loss: 2.893342399040938

Epoch: 6| Step: 12
Training loss: 3.047759098995965
Validation loss: 2.8909808790378824

Epoch: 6| Step: 13
Training loss: 2.7981732301728406
Validation loss: 2.8885719225280564

Epoch: 47| Step: 0
Training loss: 2.9878495845801347
Validation loss: 2.8865698335923424

Epoch: 6| Step: 1
Training loss: 2.941838408761875
Validation loss: 2.8842127293175794

Epoch: 6| Step: 2
Training loss: 3.0169567270788633
Validation loss: 2.882298369423412

Epoch: 6| Step: 3
Training loss: 2.885600904695027
Validation loss: 2.8801993610778087

Epoch: 6| Step: 4
Training loss: 2.6334670523803596
Validation loss: 2.878236993908782

Epoch: 6| Step: 5
Training loss: 3.623960280118622
Validation loss: 2.8762096956035563

Epoch: 6| Step: 6
Training loss: 3.117570055286903
Validation loss: 2.8734859958225787

Epoch: 6| Step: 7
Training loss: 2.7145201126508685
Validation loss: 2.871743873809942

Epoch: 6| Step: 8
Training loss: 2.7672871051009698
Validation loss: 2.8698604365495934

Epoch: 6| Step: 9
Training loss: 2.97079028240611
Validation loss: 2.8677881150533753

Epoch: 6| Step: 10
Training loss: 2.790796761176783
Validation loss: 2.8658243346417347

Epoch: 6| Step: 11
Training loss: 3.275431824381242
Validation loss: 2.8639680005022754

Epoch: 6| Step: 12
Training loss: 3.1715413937574417
Validation loss: 2.861583975158363

Epoch: 6| Step: 13
Training loss: 3.159829404547772
Validation loss: 2.8601113710526778

Epoch: 48| Step: 0
Training loss: 2.793676497412036
Validation loss: 2.858253731652566

Epoch: 6| Step: 1
Training loss: 3.481587616525393
Validation loss: 2.855311092367873

Epoch: 6| Step: 2
Training loss: 3.5025260528967808
Validation loss: 2.8526850472244636

Epoch: 6| Step: 3
Training loss: 3.3880818053889024
Validation loss: 2.8496760569059387

Epoch: 6| Step: 4
Training loss: 2.8440616981799463
Validation loss: 2.8461038258929436

Epoch: 6| Step: 5
Training loss: 2.31604309837812
Validation loss: 2.8440393992295743

Epoch: 6| Step: 6
Training loss: 2.8939430782095545
Validation loss: 2.84247904451911

Epoch: 6| Step: 7
Training loss: 2.9403455222407335
Validation loss: 2.852503693511649

Epoch: 6| Step: 8
Training loss: 2.4370076587041667
Validation loss: 2.8416305161206146

Epoch: 6| Step: 9
Training loss: 3.13555590213756
Validation loss: 2.8361779593538254

Epoch: 6| Step: 10
Training loss: 2.593283278056565
Validation loss: 2.8348592734912734

Epoch: 6| Step: 11
Training loss: 2.867574307078408
Validation loss: 2.835451559113214

Epoch: 6| Step: 12
Training loss: 3.2836116466265945
Validation loss: 2.834383129597494

Epoch: 6| Step: 13
Training loss: 3.055364275252983
Validation loss: 2.833388851594214

Epoch: 49| Step: 0
Training loss: 3.010823434629902
Validation loss: 2.833810406144673

Epoch: 6| Step: 1
Training loss: 3.050483796568577
Validation loss: 2.8290799602842127

Epoch: 6| Step: 2
Training loss: 2.9005592990725986
Validation loss: 2.826532832507163

Epoch: 6| Step: 3
Training loss: 3.0533135097254385
Validation loss: 2.823909702161367

Epoch: 6| Step: 4
Training loss: 2.8840946148022515
Validation loss: 2.821059743527837

Epoch: 6| Step: 5
Training loss: 2.6522274300823727
Validation loss: 2.8200098440661305

Epoch: 6| Step: 6
Training loss: 2.463728324372868
Validation loss: 2.817255746498242

Epoch: 6| Step: 7
Training loss: 2.627089894644772
Validation loss: 2.815516867133052

Epoch: 6| Step: 8
Training loss: 3.1753983495531277
Validation loss: 2.8153508184445397

Epoch: 6| Step: 9
Training loss: 3.419564080816094
Validation loss: 2.8137091404035286

Epoch: 6| Step: 10
Training loss: 3.0459513511354523
Validation loss: 2.8101296785689343

Epoch: 6| Step: 11
Training loss: 3.1147350329621175
Validation loss: 2.808475228374527

Epoch: 6| Step: 12
Training loss: 3.1328131088294295
Validation loss: 2.8063812525356453

Epoch: 6| Step: 13
Training loss: 2.7984483438576717
Validation loss: 2.803566172799948

Epoch: 50| Step: 0
Training loss: 3.134828294739602
Validation loss: 2.8020869731288562

Epoch: 6| Step: 1
Training loss: 3.064880380209824
Validation loss: 2.8003972214546473

Epoch: 6| Step: 2
Training loss: 3.3195294343149304
Validation loss: 2.7986958009470424

Epoch: 6| Step: 3
Training loss: 3.1311794981186365
Validation loss: 2.7965213829135607

Epoch: 6| Step: 4
Training loss: 2.859830892938611
Validation loss: 2.7951577880304694

Epoch: 6| Step: 5
Training loss: 2.964839246743945
Validation loss: 2.79394127335357

Epoch: 6| Step: 6
Training loss: 2.5632473855890314
Validation loss: 2.7922930702669486

Epoch: 6| Step: 7
Training loss: 2.871139090043783
Validation loss: 2.790227936807534

Epoch: 6| Step: 8
Training loss: 3.2117609977495274
Validation loss: 2.7882403275855525

Epoch: 6| Step: 9
Training loss: 2.7953366785512364
Validation loss: 2.7851826156930515

Epoch: 6| Step: 10
Training loss: 2.617086562302623
Validation loss: 2.782316924770414

Epoch: 6| Step: 11
Training loss: 2.8666030329657435
Validation loss: 2.7801397586472674

Epoch: 6| Step: 12
Training loss: 2.552771360075416
Validation loss: 2.777964676821234

Epoch: 6| Step: 13
Training loss: 2.997513058135261
Validation loss: 2.774619295737212

Epoch: 51| Step: 0
Training loss: 2.699352653041725
Validation loss: 2.771899990813496

Epoch: 6| Step: 1
Training loss: 3.1368807968143853
Validation loss: 2.7725761114645584

Epoch: 6| Step: 2
Training loss: 3.355823431487466
Validation loss: 2.7717068999308987

Epoch: 6| Step: 3
Training loss: 2.769920848996337
Validation loss: 2.769784676345855

Epoch: 6| Step: 4
Training loss: 2.872715913445037
Validation loss: 2.7702564604617645

Epoch: 6| Step: 5
Training loss: 2.563885570049606
Validation loss: 2.7693687143773174

Epoch: 6| Step: 6
Training loss: 3.2820023900220354
Validation loss: 2.7667685405711695

Epoch: 6| Step: 7
Training loss: 2.244538672780484
Validation loss: 2.765803430121096

Epoch: 6| Step: 8
Training loss: 2.365245765513706
Validation loss: 2.764204806468264

Epoch: 6| Step: 9
Training loss: 2.631691170357513
Validation loss: 2.7634795177002744

Epoch: 6| Step: 10
Training loss: 3.335966802463884
Validation loss: 2.7613585586586793

Epoch: 6| Step: 11
Training loss: 2.706177327719849
Validation loss: 2.7581414016684302

Epoch: 6| Step: 12
Training loss: 3.0549698721091554
Validation loss: 2.757028484478215

Epoch: 6| Step: 13
Training loss: 3.3698442426507733
Validation loss: 2.7519088824587095

Epoch: 52| Step: 0
Training loss: 3.33446661439863
Validation loss: 2.752287996600701

Epoch: 6| Step: 1
Training loss: 3.176465851026007
Validation loss: 2.7499467526684955

Epoch: 6| Step: 2
Training loss: 3.1692618895221396
Validation loss: 2.7483433733175127

Epoch: 6| Step: 3
Training loss: 2.945144284248482
Validation loss: 2.74831756509391

Epoch: 6| Step: 4
Training loss: 2.650793777197871
Validation loss: 2.746165680248487

Epoch: 6| Step: 5
Training loss: 2.56555477515513
Validation loss: 2.7473973905489637

Epoch: 6| Step: 6
Training loss: 3.530762495300098
Validation loss: 2.74348849221262

Epoch: 6| Step: 7
Training loss: 2.744053219526589
Validation loss: 2.7374047270036814

Epoch: 6| Step: 8
Training loss: 2.8302627829680933
Validation loss: 2.736162585910839

Epoch: 6| Step: 9
Training loss: 2.95781065572529
Validation loss: 2.7390397309718613

Epoch: 6| Step: 10
Training loss: 2.279726538738948
Validation loss: 2.7389064479606344

Epoch: 6| Step: 11
Training loss: 2.428167032985104
Validation loss: 2.734808911000642

Epoch: 6| Step: 12
Training loss: 2.8210619831435886
Validation loss: 2.739867806018566

Epoch: 6| Step: 13
Training loss: 2.7451387266808838
Validation loss: 2.743179634496378

Epoch: 53| Step: 0
Training loss: 2.955892245237316
Validation loss: 2.7360854403157004

Epoch: 6| Step: 1
Training loss: 2.697607152753332
Validation loss: 2.7298942692861425

Epoch: 6| Step: 2
Training loss: 2.6018908410892436
Validation loss: 2.7323567235203856

Epoch: 6| Step: 3
Training loss: 2.7859740695061563
Validation loss: 2.7315515382287328

Epoch: 6| Step: 4
Training loss: 3.0829508948064026
Validation loss: 2.730704265109636

Epoch: 6| Step: 5
Training loss: 2.6589887076228105
Validation loss: 2.727553616494132

Epoch: 6| Step: 6
Training loss: 2.9901825484874345
Validation loss: 2.7207152326889075

Epoch: 6| Step: 7
Training loss: 3.189613389650767
Validation loss: 2.7333823736567617

Epoch: 6| Step: 8
Training loss: 2.4233295625694913
Validation loss: 2.7353606999626106

Epoch: 6| Step: 9
Training loss: 3.1614059787460342
Validation loss: 2.7362447976007287

Epoch: 6| Step: 10
Training loss: 2.818018944919601
Validation loss: 2.7504484215621394

Epoch: 6| Step: 11
Training loss: 2.9898273931075305
Validation loss: 2.761836076876394

Epoch: 6| Step: 12
Training loss: 3.187533808510195
Validation loss: 2.730481134549398

Epoch: 6| Step: 13
Training loss: 2.63726547789509
Validation loss: 2.7096071671066277

Epoch: 54| Step: 0
Training loss: 2.9389803788243056
Validation loss: 2.708084569412508

Epoch: 6| Step: 1
Training loss: 3.0604309566433385
Validation loss: 2.70961756458234

Epoch: 6| Step: 2
Training loss: 2.8915885350411537
Validation loss: 2.7169274985026286

Epoch: 6| Step: 3
Training loss: 3.5338901338970046
Validation loss: 2.7308604296481835

Epoch: 6| Step: 4
Training loss: 2.438352778008041
Validation loss: 2.7186058123124535

Epoch: 6| Step: 5
Training loss: 3.148156695468577
Validation loss: 2.7056258288645325

Epoch: 6| Step: 6
Training loss: 2.7422519252414572
Validation loss: 2.702394610975225

Epoch: 6| Step: 7
Training loss: 2.7426338375959824
Validation loss: 2.6978425908075865

Epoch: 6| Step: 8
Training loss: 2.992925089868922
Validation loss: 2.6971586235196914

Epoch: 6| Step: 9
Training loss: 3.0278365589311615
Validation loss: 2.6998627368744987

Epoch: 6| Step: 10
Training loss: 2.6478674170963523
Validation loss: 2.7013331889403225

Epoch: 6| Step: 11
Training loss: 2.5401538557477896
Validation loss: 2.699847062218132

Epoch: 6| Step: 12
Training loss: 2.716070937931163
Validation loss: 2.697558395182638

Epoch: 6| Step: 13
Training loss: 2.262757058056428
Validation loss: 2.6937780315359747

Epoch: 55| Step: 0
Training loss: 2.2448344805559213
Validation loss: 2.6910744782301346

Epoch: 6| Step: 1
Training loss: 2.5822084397823413
Validation loss: 2.689552366244404

Epoch: 6| Step: 2
Training loss: 3.180464366140509
Validation loss: 2.6887812258794286

Epoch: 6| Step: 3
Training loss: 3.1893251466975614
Validation loss: 2.6890434520105173

Epoch: 6| Step: 4
Training loss: 2.595568467573306
Validation loss: 2.6889090060325738

Epoch: 6| Step: 5
Training loss: 3.049710406954106
Validation loss: 2.68757214560259

Epoch: 6| Step: 6
Training loss: 2.8877679675717873
Validation loss: 2.685973125500372

Epoch: 6| Step: 7
Training loss: 2.925700411933974
Validation loss: 2.6846147840916244

Epoch: 6| Step: 8
Training loss: 2.463609195829442
Validation loss: 2.6815605920312797

Epoch: 6| Step: 9
Training loss: 3.370357994511775
Validation loss: 2.678163708733881

Epoch: 6| Step: 10
Training loss: 2.5153580991953213
Validation loss: 2.680004490378874

Epoch: 6| Step: 11
Training loss: 3.268432724326708
Validation loss: 2.6765901925249795

Epoch: 6| Step: 12
Training loss: 2.382574751202648
Validation loss: 2.674775837332623

Epoch: 6| Step: 13
Training loss: 2.621097570379574
Validation loss: 2.6736985763400867

Epoch: 56| Step: 0
Training loss: 2.4215709864632236
Validation loss: 2.674092701615844

Epoch: 6| Step: 1
Training loss: 3.136885053090679
Validation loss: 2.671834056756191

Epoch: 6| Step: 2
Training loss: 2.6680061036115887
Validation loss: 2.6738504613663694

Epoch: 6| Step: 3
Training loss: 2.675409488887176
Validation loss: 2.6701859160141495

Epoch: 6| Step: 4
Training loss: 2.692881762430702
Validation loss: 2.6717456838385467

Epoch: 6| Step: 5
Training loss: 3.26937417367419
Validation loss: 2.67026288213552

Epoch: 6| Step: 6
Training loss: 3.0567604309587937
Validation loss: 2.666560101366635

Epoch: 6| Step: 7
Training loss: 2.677650500430109
Validation loss: 2.6656017014743814

Epoch: 6| Step: 8
Training loss: 2.854878209283848
Validation loss: 2.6660497269644345

Epoch: 6| Step: 9
Training loss: 2.318984451162859
Validation loss: 2.6635518558821003

Epoch: 6| Step: 10
Training loss: 2.7911327382870987
Validation loss: 2.6618346354497873

Epoch: 6| Step: 11
Training loss: 2.963346683856883
Validation loss: 2.6598798745501164

Epoch: 6| Step: 12
Training loss: 3.1900327007566824
Validation loss: 2.6592103954255446

Epoch: 6| Step: 13
Training loss: 2.4053679001256407
Validation loss: 2.6554497205144627

Epoch: 57| Step: 0
Training loss: 2.6704918030550715
Validation loss: 2.6538687111070605

Epoch: 6| Step: 1
Training loss: 2.8834237791954354
Validation loss: 2.654211151931986

Epoch: 6| Step: 2
Training loss: 2.79038119730214
Validation loss: 2.661768965438263

Epoch: 6| Step: 3
Training loss: 1.971369257423629
Validation loss: 2.6661695573311026

Epoch: 6| Step: 4
Training loss: 3.0674439053431373
Validation loss: 2.6617212084837316

Epoch: 6| Step: 5
Training loss: 3.012265246096664
Validation loss: 2.675008843309277

Epoch: 6| Step: 6
Training loss: 2.5808235610548618
Validation loss: 2.663081117949014

Epoch: 6| Step: 7
Training loss: 3.0102396102281173
Validation loss: 2.646148517688722

Epoch: 6| Step: 8
Training loss: 2.8062534051887225
Validation loss: 2.6492431525506426

Epoch: 6| Step: 9
Training loss: 2.612671922201309
Validation loss: 2.6429448217529803

Epoch: 6| Step: 10
Training loss: 3.2453118770123077
Validation loss: 2.6410221952309514

Epoch: 6| Step: 11
Training loss: 2.6033067326116757
Validation loss: 2.6422036923740064

Epoch: 6| Step: 12
Training loss: 2.715961297637297
Validation loss: 2.644138549316962

Epoch: 6| Step: 13
Training loss: 2.918593578517314
Validation loss: 2.645717743478803

Epoch: 58| Step: 0
Training loss: 2.290220937440591
Validation loss: 2.650671078024263

Epoch: 6| Step: 1
Training loss: 2.730839127072787
Validation loss: 2.6589228627107224

Epoch: 6| Step: 2
Training loss: 2.6705924184835133
Validation loss: 2.6806313916307523

Epoch: 6| Step: 3
Training loss: 2.3135101586443034
Validation loss: 2.6769973998372416

Epoch: 6| Step: 4
Training loss: 2.6912684080040954
Validation loss: 2.6562806969159163

Epoch: 6| Step: 5
Training loss: 2.9103902223478366
Validation loss: 2.6501309692359727

Epoch: 6| Step: 6
Training loss: 2.9127120501555903
Validation loss: 2.64493869063839

Epoch: 6| Step: 7
Training loss: 2.737983110552707
Validation loss: 2.6400149541729947

Epoch: 6| Step: 8
Training loss: 3.049666939982827
Validation loss: 2.636430098192658

Epoch: 6| Step: 9
Training loss: 2.855872171399658
Validation loss: 2.6342018453664013

Epoch: 6| Step: 10
Training loss: 2.8883529394166354
Validation loss: 2.6332048978348275

Epoch: 6| Step: 11
Training loss: 3.1523708261983865
Validation loss: 2.6315672785098716

Epoch: 6| Step: 12
Training loss: 3.1807633063270306
Validation loss: 2.6299506687570826

Epoch: 6| Step: 13
Training loss: 2.434425762856785
Validation loss: 2.6303697794600622

Epoch: 59| Step: 0
Training loss: 2.911543752182684
Validation loss: 2.6298155740008164

Epoch: 6| Step: 1
Training loss: 2.3241112435745768
Validation loss: 2.628116483368381

Epoch: 6| Step: 2
Training loss: 3.1023074391722614
Validation loss: 2.620610427069909

Epoch: 6| Step: 3
Training loss: 2.521939993662522
Validation loss: 2.620788996149103

Epoch: 6| Step: 4
Training loss: 2.792201735807652
Validation loss: 2.6191089314347877

Epoch: 6| Step: 5
Training loss: 2.974324343595251
Validation loss: 2.6220595375564226

Epoch: 6| Step: 6
Training loss: 2.566870521112384
Validation loss: 2.6232766292006535

Epoch: 6| Step: 7
Training loss: 2.780972241880063
Validation loss: 2.6252292199947886

Epoch: 6| Step: 8
Training loss: 2.431331164419833
Validation loss: 2.6191639739154304

Epoch: 6| Step: 9
Training loss: 2.716555356356721
Validation loss: 2.61931267992717

Epoch: 6| Step: 10
Training loss: 2.7150840158969127
Validation loss: 2.6152699748002917

Epoch: 6| Step: 11
Training loss: 2.9659534332776674
Validation loss: 2.614958099214319

Epoch: 6| Step: 12
Training loss: 2.621136319629161
Validation loss: 2.6143003870437895

Epoch: 6| Step: 13
Training loss: 3.1089326936903094
Validation loss: 2.61234209170554

Epoch: 60| Step: 0
Training loss: 3.062198857662916
Validation loss: 2.6120445621071617

Epoch: 6| Step: 1
Training loss: 2.7369696813262334
Validation loss: 2.611706740731804

Epoch: 6| Step: 2
Training loss: 2.9130112948239617
Validation loss: 2.6080770557591006

Epoch: 6| Step: 3
Training loss: 2.940537850105043
Validation loss: 2.6080027948717537

Epoch: 6| Step: 4
Training loss: 2.1789832943069793
Validation loss: 2.6062227041887143

Epoch: 6| Step: 5
Training loss: 2.713441950649296
Validation loss: 2.6030233136634062

Epoch: 6| Step: 6
Training loss: 3.150699683092946
Validation loss: 2.602651083839323

Epoch: 6| Step: 7
Training loss: 2.7556287208024997
Validation loss: 2.6016674001506557

Epoch: 6| Step: 8
Training loss: 2.807122663649238
Validation loss: 2.6056513152818503

Epoch: 6| Step: 9
Training loss: 2.332263724083174
Validation loss: 2.602521427517058

Epoch: 6| Step: 10
Training loss: 2.3337113096996944
Validation loss: 2.6048764800052213

Epoch: 6| Step: 11
Training loss: 2.643770409904318
Validation loss: 2.595773175942142

Epoch: 6| Step: 12
Training loss: 2.958391932233968
Validation loss: 2.5968634827408548

Epoch: 6| Step: 13
Training loss: 2.7134091765311488
Validation loss: 2.6007773557744387

Epoch: 61| Step: 0
Training loss: 2.994333956474379
Validation loss: 2.597076672596935

Epoch: 6| Step: 1
Training loss: 2.6808848917181844
Validation loss: 2.6009324984441466

Epoch: 6| Step: 2
Training loss: 3.0908939009308494
Validation loss: 2.601059201484049

Epoch: 6| Step: 3
Training loss: 2.6250474108092945
Validation loss: 2.6030993652302725

Epoch: 6| Step: 4
Training loss: 2.8162670762466715
Validation loss: 2.6042175033693606

Epoch: 6| Step: 5
Training loss: 3.023340031435219
Validation loss: 2.601625321463142

Epoch: 6| Step: 6
Training loss: 2.11102772709768
Validation loss: 2.60223764817664

Epoch: 6| Step: 7
Training loss: 2.8063181437691362
Validation loss: 2.6011635567048548

Epoch: 6| Step: 8
Training loss: 2.400928905649926
Validation loss: 2.5976098995806067

Epoch: 6| Step: 9
Training loss: 2.572073938733775
Validation loss: 2.59676293331368

Epoch: 6| Step: 10
Training loss: 2.9522845974740344
Validation loss: 2.5957438760184504

Epoch: 6| Step: 11
Training loss: 3.176339301032817
Validation loss: 2.59259333730364

Epoch: 6| Step: 12
Training loss: 2.2869551921836835
Validation loss: 2.5925407654890313

Epoch: 6| Step: 13
Training loss: 2.5637003250554566
Validation loss: 2.5880898145875433

Epoch: 62| Step: 0
Training loss: 2.6482587095693764
Validation loss: 2.5893121464324453

Epoch: 6| Step: 1
Training loss: 2.5412311389258817
Validation loss: 2.5900393834550286

Epoch: 6| Step: 2
Training loss: 2.694100635481225
Validation loss: 2.5935718980791687

Epoch: 6| Step: 3
Training loss: 2.517183188512272
Validation loss: 2.5890150245023293

Epoch: 6| Step: 4
Training loss: 3.338135185233303
Validation loss: 2.595047101700144

Epoch: 6| Step: 5
Training loss: 2.01471364317497
Validation loss: 2.5905860845804973

Epoch: 6| Step: 6
Training loss: 3.249458854812766
Validation loss: 2.595663743477415

Epoch: 6| Step: 7
Training loss: 2.4286716704957976
Validation loss: 2.5839985995815407

Epoch: 6| Step: 8
Training loss: 2.930296974364747
Validation loss: 2.5814198565073987

Epoch: 6| Step: 9
Training loss: 3.093681257620908
Validation loss: 2.5858946582514544

Epoch: 6| Step: 10
Training loss: 2.189788928725361
Validation loss: 2.5875027040722363

Epoch: 6| Step: 11
Training loss: 2.8443884499654533
Validation loss: 2.5899364364708863

Epoch: 6| Step: 12
Training loss: 2.9692363139922153
Validation loss: 2.5907935332730703

Epoch: 6| Step: 13
Training loss: 2.588303512168918
Validation loss: 2.590901538061138

Epoch: 63| Step: 0
Training loss: 2.5128609772802184
Validation loss: 2.5898445478450567

Epoch: 6| Step: 1
Training loss: 2.314748444206159
Validation loss: 2.586799577767266

Epoch: 6| Step: 2
Training loss: 2.6314507197209345
Validation loss: 2.584409817603689

Epoch: 6| Step: 3
Training loss: 2.867482682086828
Validation loss: 2.5794156013450174

Epoch: 6| Step: 4
Training loss: 2.3374808325976133
Validation loss: 2.576400827641229

Epoch: 6| Step: 5
Training loss: 2.809532974095826
Validation loss: 2.5755878487338797

Epoch: 6| Step: 6
Training loss: 2.633056267113586
Validation loss: 2.5746059869338707

Epoch: 6| Step: 7
Training loss: 2.671382033173669
Validation loss: 2.574089089477384

Epoch: 6| Step: 8
Training loss: 2.8295392457323594
Validation loss: 2.5754616129167105

Epoch: 6| Step: 9
Training loss: 2.9484770189476137
Validation loss: 2.5789614004643897

Epoch: 6| Step: 10
Training loss: 3.27858807808584
Validation loss: 2.5772750686539867

Epoch: 6| Step: 11
Training loss: 2.816840827418063
Validation loss: 2.5683689673260353

Epoch: 6| Step: 12
Training loss: 2.7905406294111774
Validation loss: 2.5680784741480402

Epoch: 6| Step: 13
Training loss: 2.585357600994166
Validation loss: 2.566507214592854

Epoch: 64| Step: 0
Training loss: 2.5049284040380653
Validation loss: 2.5711210113597813

Epoch: 6| Step: 1
Training loss: 2.958696549016989
Validation loss: 2.570817381831492

Epoch: 6| Step: 2
Training loss: 3.3543928239923493
Validation loss: 2.5715835659554798

Epoch: 6| Step: 3
Training loss: 2.242659462625013
Validation loss: 2.576372495006718

Epoch: 6| Step: 4
Training loss: 3.1445204835316463
Validation loss: 2.578579918384854

Epoch: 6| Step: 5
Training loss: 2.87852858572703
Validation loss: 2.5831223268369707

Epoch: 6| Step: 6
Training loss: 2.002087457383348
Validation loss: 2.5845639671359835

Epoch: 6| Step: 7
Training loss: 2.9055890387929115
Validation loss: 2.5820276180516877

Epoch: 6| Step: 8
Training loss: 3.0088123591783087
Validation loss: 2.58198709685817

Epoch: 6| Step: 9
Training loss: 2.7524808617254797
Validation loss: 2.580000101084547

Epoch: 6| Step: 10
Training loss: 2.38268462291342
Validation loss: 2.578764803325097

Epoch: 6| Step: 11
Training loss: 2.5615686724584807
Validation loss: 2.574758454755846

Epoch: 6| Step: 12
Training loss: 2.592304792274119
Validation loss: 2.5755396046097467

Epoch: 6| Step: 13
Training loss: 2.4616957692169565
Validation loss: 2.5747147016280194

Epoch: 65| Step: 0
Training loss: 2.8536245754782525
Validation loss: 2.573325450305361

Epoch: 6| Step: 1
Training loss: 2.374180602218775
Validation loss: 2.5698296074965077

Epoch: 6| Step: 2
Training loss: 3.120680150209975
Validation loss: 2.5648138872806214

Epoch: 6| Step: 3
Training loss: 2.6244168314969207
Validation loss: 2.564521550400913

Epoch: 6| Step: 4
Training loss: 2.753460873781806
Validation loss: 2.5615979289369553

Epoch: 6| Step: 5
Training loss: 2.518522690580482
Validation loss: 2.565255567597594

Epoch: 6| Step: 6
Training loss: 3.1097910233720545
Validation loss: 2.5620108657078418

Epoch: 6| Step: 7
Training loss: 2.7733192096252752
Validation loss: 2.5592792786524554

Epoch: 6| Step: 8
Training loss: 2.340659583616753
Validation loss: 2.5556016039039786

Epoch: 6| Step: 9
Training loss: 2.4824668225917046
Validation loss: 2.552996278815142

Epoch: 6| Step: 10
Training loss: 2.8182074386237534
Validation loss: 2.5525932788649106

Epoch: 6| Step: 11
Training loss: 2.424735072500492
Validation loss: 2.552954783187513

Epoch: 6| Step: 12
Training loss: 2.895981233694066
Validation loss: 2.550674334977995

Epoch: 6| Step: 13
Training loss: 2.639612669707725
Validation loss: 2.5522608688780206

Epoch: 66| Step: 0
Training loss: 2.770809163917927
Validation loss: 2.5527369901239476

Epoch: 6| Step: 1
Training loss: 2.9452360836406486
Validation loss: 2.553173024579165

Epoch: 6| Step: 2
Training loss: 2.195711255766835
Validation loss: 2.5517963689243315

Epoch: 6| Step: 3
Training loss: 2.7115330110735516
Validation loss: 2.5503124684515823

Epoch: 6| Step: 4
Training loss: 2.8254973286062723
Validation loss: 2.55422224344231

Epoch: 6| Step: 5
Training loss: 3.058303448966749
Validation loss: 2.5531744875522184

Epoch: 6| Step: 6
Training loss: 2.715412063942037
Validation loss: 2.549079642912207

Epoch: 6| Step: 7
Training loss: 2.576901232104555
Validation loss: 2.5493096414430134

Epoch: 6| Step: 8
Training loss: 2.2603774763187716
Validation loss: 2.5497510542306503

Epoch: 6| Step: 9
Training loss: 2.3564502701784256
Validation loss: 2.549256036727146

Epoch: 6| Step: 10
Training loss: 3.089629540812764
Validation loss: 2.5497564386472957

Epoch: 6| Step: 11
Training loss: 1.9965330114618525
Validation loss: 2.5474912525859144

Epoch: 6| Step: 12
Training loss: 2.5407457611550095
Validation loss: 2.548469902189652

Epoch: 6| Step: 13
Training loss: 3.1770875691036484
Validation loss: 2.546951526826106

Epoch: 67| Step: 0
Training loss: 2.6071090453431944
Validation loss: 2.5453198605519387

Epoch: 6| Step: 1
Training loss: 2.706323396246879
Validation loss: 2.544894191213707

Epoch: 6| Step: 2
Training loss: 2.8982065113904523
Validation loss: 2.541886950676511

Epoch: 6| Step: 3
Training loss: 3.284191883619192
Validation loss: 2.5457344075496855

Epoch: 6| Step: 4
Training loss: 2.328867032380874
Validation loss: 2.5424532272552747

Epoch: 6| Step: 5
Training loss: 2.1161253119213885
Validation loss: 2.5408000615152755

Epoch: 6| Step: 6
Training loss: 2.8017435163237563
Validation loss: 2.5414381132914468

Epoch: 6| Step: 7
Training loss: 2.347707839881366
Validation loss: 2.543981050812627

Epoch: 6| Step: 8
Training loss: 2.706829201119946
Validation loss: 2.542832221972452

Epoch: 6| Step: 9
Training loss: 2.9971104057069007
Validation loss: 2.5403801731639515

Epoch: 6| Step: 10
Training loss: 2.6898899540850905
Validation loss: 2.5433936635715906

Epoch: 6| Step: 11
Training loss: 2.374445197907033
Validation loss: 2.541082163864869

Epoch: 6| Step: 12
Training loss: 2.843436255282331
Validation loss: 2.539602181226737

Epoch: 6| Step: 13
Training loss: 2.5666788963753118
Validation loss: 2.5394348341032704

Epoch: 68| Step: 0
Training loss: 3.033596114070029
Validation loss: 2.5362533523063635

Epoch: 6| Step: 1
Training loss: 2.190496299979109
Validation loss: 2.53794747934241

Epoch: 6| Step: 2
Training loss: 2.8217702886305425
Validation loss: 2.5342255046135187

Epoch: 6| Step: 3
Training loss: 2.68754932447015
Validation loss: 2.53520672027397

Epoch: 6| Step: 4
Training loss: 2.538285638365705
Validation loss: 2.532722625612603

Epoch: 6| Step: 5
Training loss: 2.125679692790415
Validation loss: 2.5356037546267145

Epoch: 6| Step: 6
Training loss: 3.0586166673291335
Validation loss: 2.5341135946192233

Epoch: 6| Step: 7
Training loss: 2.345002106948264
Validation loss: 2.5330162008786234

Epoch: 6| Step: 8
Training loss: 2.7410745563018835
Validation loss: 2.5337416704590154

Epoch: 6| Step: 9
Training loss: 2.568435865068223
Validation loss: 2.5327432019345144

Epoch: 6| Step: 10
Training loss: 2.671195495934815
Validation loss: 2.532999336871093

Epoch: 6| Step: 11
Training loss: 3.119848812303779
Validation loss: 2.5338795037618405

Epoch: 6| Step: 12
Training loss: 2.5367907881310554
Validation loss: 2.5292526025223596

Epoch: 6| Step: 13
Training loss: 2.6578131171690567
Validation loss: 2.5265368471119216

Epoch: 69| Step: 0
Training loss: 2.228601960524986
Validation loss: 2.5271497098712805

Epoch: 6| Step: 1
Training loss: 2.8016128901445976
Validation loss: 2.5401914932876224

Epoch: 6| Step: 2
Training loss: 2.5179920314999054
Validation loss: 2.543723045787423

Epoch: 6| Step: 3
Training loss: 2.7966915475362217
Validation loss: 2.547409882965268

Epoch: 6| Step: 4
Training loss: 2.6996006564348796
Validation loss: 2.5555006749254185

Epoch: 6| Step: 5
Training loss: 2.980801025107469
Validation loss: 2.5318928910772693

Epoch: 6| Step: 6
Training loss: 2.5264623127868204
Validation loss: 2.5326720587678113

Epoch: 6| Step: 7
Training loss: 2.629914723743452
Validation loss: 2.524091700736486

Epoch: 6| Step: 8
Training loss: 2.452022815131477
Validation loss: 2.524540836144225

Epoch: 6| Step: 9
Training loss: 2.6457890684575154
Validation loss: 2.527852277973694

Epoch: 6| Step: 10
Training loss: 2.938611571030283
Validation loss: 2.530992769585446

Epoch: 6| Step: 11
Training loss: 2.7888958023647556
Validation loss: 2.5352323782236663

Epoch: 6| Step: 12
Training loss: 2.6040880013346452
Validation loss: 2.537811330979702

Epoch: 6| Step: 13
Training loss: 2.693775214057333
Validation loss: 2.5444230522504

Epoch: 70| Step: 0
Training loss: 2.80292091945074
Validation loss: 2.543424332100271

Epoch: 6| Step: 1
Training loss: 2.685240305655155
Validation loss: 2.547637045346407

Epoch: 6| Step: 2
Training loss: 3.1197678061428875
Validation loss: 2.545966097361028

Epoch: 6| Step: 3
Training loss: 2.6778937472517135
Validation loss: 2.5491869053988614

Epoch: 6| Step: 4
Training loss: 3.005497663421814
Validation loss: 2.5447643247851337

Epoch: 6| Step: 5
Training loss: 2.5087616927516385
Validation loss: 2.5461076231776825

Epoch: 6| Step: 6
Training loss: 2.259308949371674
Validation loss: 2.543250361806117

Epoch: 6| Step: 7
Training loss: 2.4602965473911342
Validation loss: 2.5411130010276

Epoch: 6| Step: 8
Training loss: 2.8454631633556025
Validation loss: 2.5381932105672966

Epoch: 6| Step: 9
Training loss: 2.311496104315318
Validation loss: 2.5364049061207834

Epoch: 6| Step: 10
Training loss: 3.082566518197349
Validation loss: 2.5282814923652466

Epoch: 6| Step: 11
Training loss: 2.571484515928809
Validation loss: 2.5276683066375067

Epoch: 6| Step: 12
Training loss: 2.322733120587705
Validation loss: 2.5265271116918764

Epoch: 6| Step: 13
Training loss: 2.6522343518894647
Validation loss: 2.523056773152386

Epoch: 71| Step: 0
Training loss: 2.9700857269553462
Validation loss: 2.5239361092259025

Epoch: 6| Step: 1
Training loss: 3.0389446637763298
Validation loss: 2.5229856954676344

Epoch: 6| Step: 2
Training loss: 2.5369344860996064
Validation loss: 2.520239536768851

Epoch: 6| Step: 3
Training loss: 2.562492556677452
Validation loss: 2.5213699610346185

Epoch: 6| Step: 4
Training loss: 2.757634057169609
Validation loss: 2.519621917906927

Epoch: 6| Step: 5
Training loss: 2.8498755913066263
Validation loss: 2.516664325847758

Epoch: 6| Step: 6
Training loss: 1.9967835311357223
Validation loss: 2.5130149617233597

Epoch: 6| Step: 7
Training loss: 2.5192295573976997
Validation loss: 2.518786558354487

Epoch: 6| Step: 8
Training loss: 2.6236288940336814
Validation loss: 2.521890108740012

Epoch: 6| Step: 9
Training loss: 2.7987506906321986
Validation loss: 2.521776942253684

Epoch: 6| Step: 10
Training loss: 2.490957117851705
Validation loss: 2.520314223589843

Epoch: 6| Step: 11
Training loss: 2.576727471006367
Validation loss: 2.515298368048008

Epoch: 6| Step: 12
Training loss: 2.473080084997557
Validation loss: 2.5137827981395953

Epoch: 6| Step: 13
Training loss: 2.8838368485183192
Validation loss: 2.517340618064747

Epoch: 72| Step: 0
Training loss: 2.9276099404426996
Validation loss: 2.516293201988435

Epoch: 6| Step: 1
Training loss: 2.9406980596662757
Validation loss: 2.5118910600361275

Epoch: 6| Step: 2
Training loss: 2.4138153838552827
Validation loss: 2.5126847959916843

Epoch: 6| Step: 3
Training loss: 2.3571127852466134
Validation loss: 2.514096247713445

Epoch: 6| Step: 4
Training loss: 2.48344183136488
Validation loss: 2.517619951175459

Epoch: 6| Step: 5
Training loss: 2.636336416145838
Validation loss: 2.5162369988666677

Epoch: 6| Step: 6
Training loss: 2.718236852867563
Validation loss: 2.5147644845795862

Epoch: 6| Step: 7
Training loss: 2.4239597330934957
Validation loss: 2.5134999558020232

Epoch: 6| Step: 8
Training loss: 2.8864354470780955
Validation loss: 2.518127681313838

Epoch: 6| Step: 9
Training loss: 2.664408462747381
Validation loss: 2.5152861562423516

Epoch: 6| Step: 10
Training loss: 2.3566824599640173
Validation loss: 2.513640701191538

Epoch: 6| Step: 11
Training loss: 2.832071490824019
Validation loss: 2.5163426451691615

Epoch: 6| Step: 12
Training loss: 2.4052320036143993
Validation loss: 2.514571330545682

Epoch: 6| Step: 13
Training loss: 2.8664283682967158
Validation loss: 2.5169353823747818

Epoch: 73| Step: 0
Training loss: 2.7917037126351043
Validation loss: 2.5129910218573945

Epoch: 6| Step: 1
Training loss: 2.7204986736432493
Validation loss: 2.5135514142294957

Epoch: 6| Step: 2
Training loss: 2.3784167157183367
Validation loss: 2.5148701769398296

Epoch: 6| Step: 3
Training loss: 2.546500149154434
Validation loss: 2.5153044660296726

Epoch: 6| Step: 4
Training loss: 3.187625358958789
Validation loss: 2.515116535555808

Epoch: 6| Step: 5
Training loss: 3.043813879451117
Validation loss: 2.5128549919683585

Epoch: 6| Step: 6
Training loss: 2.5850748426866215
Validation loss: 2.5111908305950776

Epoch: 6| Step: 7
Training loss: 2.1957150561950676
Validation loss: 2.5105878262454047

Epoch: 6| Step: 8
Training loss: 2.5627668288335803
Validation loss: 2.511077751605747

Epoch: 6| Step: 9
Training loss: 2.803433958992589
Validation loss: 2.50924991598367

Epoch: 6| Step: 10
Training loss: 2.5813917328944878
Validation loss: 2.510528203193331

Epoch: 6| Step: 11
Training loss: 2.6230550554251626
Validation loss: 2.5110879267078965

Epoch: 6| Step: 12
Training loss: 2.307598486851596
Validation loss: 2.507569963842619

Epoch: 6| Step: 13
Training loss: 2.5192658986964758
Validation loss: 2.5089768730081907

Epoch: 74| Step: 0
Training loss: 2.0837640189996183
Validation loss: 2.5040964420350456

Epoch: 6| Step: 1
Training loss: 3.174795525642348
Validation loss: 2.507627581377176

Epoch: 6| Step: 2
Training loss: 2.5912837057318345
Validation loss: 2.5073315088846466

Epoch: 6| Step: 3
Training loss: 2.5195853767199585
Validation loss: 2.509172627296154

Epoch: 6| Step: 4
Training loss: 2.3397762944810196
Validation loss: 2.5055069193615385

Epoch: 6| Step: 5
Training loss: 2.6055421375651253
Validation loss: 2.5055529436049437

Epoch: 6| Step: 6
Training loss: 2.5503502287362587
Validation loss: 2.505801843670085

Epoch: 6| Step: 7
Training loss: 2.755715240018428
Validation loss: 2.5113335092019766

Epoch: 6| Step: 8
Training loss: 2.2208041501110887
Validation loss: 2.51380410645647

Epoch: 6| Step: 9
Training loss: 2.324470262783217
Validation loss: 2.514788691982667

Epoch: 6| Step: 10
Training loss: 3.1863963890643276
Validation loss: 2.5104113271400577

Epoch: 6| Step: 11
Training loss: 2.8709351372535212
Validation loss: 2.5012215332109307

Epoch: 6| Step: 12
Training loss: 2.7007050900456417
Validation loss: 2.5017456000385847

Epoch: 6| Step: 13
Training loss: 2.7410148004120445
Validation loss: 2.5025961667719283

Epoch: 75| Step: 0
Training loss: 2.4228769506302847
Validation loss: 2.505248092579075

Epoch: 6| Step: 1
Training loss: 3.0928785850061034
Validation loss: 2.505543975129001

Epoch: 6| Step: 2
Training loss: 2.932804169030772
Validation loss: 2.5054128540896534

Epoch: 6| Step: 3
Training loss: 2.3960980365865328
Validation loss: 2.5073250111569667

Epoch: 6| Step: 4
Training loss: 2.431935144689026
Validation loss: 2.5105706691331577

Epoch: 6| Step: 5
Training loss: 2.1763290729213214
Validation loss: 2.507466665726529

Epoch: 6| Step: 6
Training loss: 2.7067961707711423
Validation loss: 2.510195003447429

Epoch: 6| Step: 7
Training loss: 2.523921199771548
Validation loss: 2.5125618681873925

Epoch: 6| Step: 8
Training loss: 2.524133544919502
Validation loss: 2.5121635331916115

Epoch: 6| Step: 9
Training loss: 2.6923408380501197
Validation loss: 2.5104900417974965

Epoch: 6| Step: 10
Training loss: 2.5645719385913996
Validation loss: 2.5102646862155473

Epoch: 6| Step: 11
Training loss: 2.8816921465842853
Validation loss: 2.5106087501664116

Epoch: 6| Step: 12
Training loss: 2.712092172929927
Validation loss: 2.5091857477748727

Epoch: 6| Step: 13
Training loss: 2.7620529986910327
Validation loss: 2.5103103541317506

Epoch: 76| Step: 0
Training loss: 2.508456138654699
Validation loss: 2.5063031686421238

Epoch: 6| Step: 1
Training loss: 2.712485890857198
Validation loss: 2.5044577274442257

Epoch: 6| Step: 2
Training loss: 1.9867808258403235
Validation loss: 2.5030261956445776

Epoch: 6| Step: 3
Training loss: 2.675254424643059
Validation loss: 2.502876010279015

Epoch: 6| Step: 4
Training loss: 2.417034702119773
Validation loss: 2.4992880602240137

Epoch: 6| Step: 5
Training loss: 2.6552964237925614
Validation loss: 2.497679141737871

Epoch: 6| Step: 6
Training loss: 2.121102405059747
Validation loss: 2.4938876930663185

Epoch: 6| Step: 7
Training loss: 3.4119781486375005
Validation loss: 2.498001499872442

Epoch: 6| Step: 8
Training loss: 2.7703505838856386
Validation loss: 2.5031773879609003

Epoch: 6| Step: 9
Training loss: 2.5650683302078434
Validation loss: 2.4954539928318806

Epoch: 6| Step: 10
Training loss: 2.4246757801833154
Validation loss: 2.4946802920100732

Epoch: 6| Step: 11
Training loss: 2.7884413083503743
Validation loss: 2.4954898284728255

Epoch: 6| Step: 12
Training loss: 2.6167944769614144
Validation loss: 2.5007643008171674

Epoch: 6| Step: 13
Training loss: 2.7963948610219553
Validation loss: 2.4991266791526097

Epoch: 77| Step: 0
Training loss: 2.7824018857645725
Validation loss: 2.492687083588276

Epoch: 6| Step: 1
Training loss: 2.4778644978049993
Validation loss: 2.498016921940772

Epoch: 6| Step: 2
Training loss: 2.823487499746433
Validation loss: 2.4979576908165106

Epoch: 6| Step: 3
Training loss: 2.173452120306011
Validation loss: 2.49969463072838

Epoch: 6| Step: 4
Training loss: 3.025103442732727
Validation loss: 2.49864333217226

Epoch: 6| Step: 5
Training loss: 2.512391185776497
Validation loss: 2.497746437344864

Epoch: 6| Step: 6
Training loss: 3.000788902823163
Validation loss: 2.493711175194089

Epoch: 6| Step: 7
Training loss: 2.8892748179593175
Validation loss: 2.4966819201547996

Epoch: 6| Step: 8
Training loss: 2.7671417559952034
Validation loss: 2.4914762624076405

Epoch: 6| Step: 9
Training loss: 2.123737184374728
Validation loss: 2.4929368378387795

Epoch: 6| Step: 10
Training loss: 2.353514611968143
Validation loss: 2.491443630642644

Epoch: 6| Step: 11
Training loss: 2.821630280994828
Validation loss: 2.4967959375957722

Epoch: 6| Step: 12
Training loss: 2.0638973242186713
Validation loss: 2.4901232007710195

Epoch: 6| Step: 13
Training loss: 2.522659039961004
Validation loss: 2.489981126062644

Epoch: 78| Step: 0
Training loss: 2.7484180061555517
Validation loss: 2.4948747869248407

Epoch: 6| Step: 1
Training loss: 2.5813473071214013
Validation loss: 2.494661894564173

Epoch: 6| Step: 2
Training loss: 2.709352937144346
Validation loss: 2.4914938221394967

Epoch: 6| Step: 3
Training loss: 2.865854395147208
Validation loss: 2.4954864606928857

Epoch: 6| Step: 4
Training loss: 2.5214085408692224
Validation loss: 2.4910946067048183

Epoch: 6| Step: 5
Training loss: 2.5674736323205214
Validation loss: 2.4946365759525007

Epoch: 6| Step: 6
Training loss: 2.8195488654115146
Validation loss: 2.4917950136774056

Epoch: 6| Step: 7
Training loss: 2.7964642612049913
Validation loss: 2.488491542519476

Epoch: 6| Step: 8
Training loss: 2.354154254801841
Validation loss: 2.488868280828777

Epoch: 6| Step: 9
Training loss: 1.9393262562356546
Validation loss: 2.488928215202461

Epoch: 6| Step: 10
Training loss: 2.343090931097033
Validation loss: 2.4868862168016848

Epoch: 6| Step: 11
Training loss: 2.8538641850556177
Validation loss: 2.491712407316369

Epoch: 6| Step: 12
Training loss: 2.3899098242822223
Validation loss: 2.492610277690796

Epoch: 6| Step: 13
Training loss: 2.933068849459792
Validation loss: 2.4915499773631438

Epoch: 79| Step: 0
Training loss: 2.7251410071611217
Validation loss: 2.4919747767052107

Epoch: 6| Step: 1
Training loss: 2.3015531271687335
Validation loss: 2.4931249340277635

Epoch: 6| Step: 2
Training loss: 2.6832504386023617
Validation loss: 2.491655282937607

Epoch: 6| Step: 3
Training loss: 2.41127262814802
Validation loss: 2.497694812389863

Epoch: 6| Step: 4
Training loss: 2.1442738640867036
Validation loss: 2.4927759701492462

Epoch: 6| Step: 5
Training loss: 2.2865511818168147
Validation loss: 2.5019787586813806

Epoch: 6| Step: 6
Training loss: 2.873881578589972
Validation loss: 2.4939699087165623

Epoch: 6| Step: 7
Training loss: 3.1478731392645605
Validation loss: 2.50081028522708

Epoch: 6| Step: 8
Training loss: 2.748537021242594
Validation loss: 2.494558850430494

Epoch: 6| Step: 9
Training loss: 2.731570827749432
Validation loss: 2.4893068508557326

Epoch: 6| Step: 10
Training loss: 2.2847742527606267
Validation loss: 2.4993320685443066

Epoch: 6| Step: 11
Training loss: 2.8559583252075416
Validation loss: 2.4947065738402925

Epoch: 6| Step: 12
Training loss: 2.3106809111257167
Validation loss: 2.496298354254714

Epoch: 6| Step: 13
Training loss: 2.7781535710344936
Validation loss: 2.494332135166015

Epoch: 80| Step: 0
Training loss: 2.7608575624768554
Validation loss: 2.4946206232633905

Epoch: 6| Step: 1
Training loss: 2.5837620922852067
Validation loss: 2.491699011432196

Epoch: 6| Step: 2
Training loss: 2.5004471379005024
Validation loss: 2.4918876156608394

Epoch: 6| Step: 3
Training loss: 2.9108677755903334
Validation loss: 2.494374430787077

Epoch: 6| Step: 4
Training loss: 2.5115906013795297
Validation loss: 2.490699937970217

Epoch: 6| Step: 5
Training loss: 2.7912507008245453
Validation loss: 2.488338563619313

Epoch: 6| Step: 6
Training loss: 2.7926886571475342
Validation loss: 2.4890572751603623

Epoch: 6| Step: 7
Training loss: 2.5072327891527513
Validation loss: 2.484599313266085

Epoch: 6| Step: 8
Training loss: 2.255079786999485
Validation loss: 2.4872665212633827

Epoch: 6| Step: 9
Training loss: 2.5472525100358685
Validation loss: 2.486297071831847

Epoch: 6| Step: 10
Training loss: 2.3028250717666827
Validation loss: 2.4897714541132983

Epoch: 6| Step: 11
Training loss: 2.495625674397879
Validation loss: 2.487654259146214

Epoch: 6| Step: 12
Training loss: 2.6810998336604697
Validation loss: 2.485924691279749

Epoch: 6| Step: 13
Training loss: 2.7219562259997025
Validation loss: 2.4895074478991104

Epoch: 81| Step: 0
Training loss: 2.6273108710285697
Validation loss: 2.485021543044843

Epoch: 6| Step: 1
Training loss: 2.989629304290951
Validation loss: 2.4869414534713483

Epoch: 6| Step: 2
Training loss: 2.3040909334490363
Validation loss: 2.486692247600071

Epoch: 6| Step: 3
Training loss: 2.3353714783442943
Validation loss: 2.4892704712565945

Epoch: 6| Step: 4
Training loss: 2.6999641416075875
Validation loss: 2.483089490307428

Epoch: 6| Step: 5
Training loss: 1.8958242506990395
Validation loss: 2.4878728222969944

Epoch: 6| Step: 6
Training loss: 2.6213662564424376
Validation loss: 2.4862669132885475

Epoch: 6| Step: 7
Training loss: 2.9466226026712756
Validation loss: 2.4882108078531897

Epoch: 6| Step: 8
Training loss: 2.2653564293941177
Validation loss: 2.489870634752749

Epoch: 6| Step: 9
Training loss: 2.4351470545673752
Validation loss: 2.484671904858362

Epoch: 6| Step: 10
Training loss: 3.3400938776951175
Validation loss: 2.485678404855485

Epoch: 6| Step: 11
Training loss: 2.0825635505129365
Validation loss: 2.4844155618167423

Epoch: 6| Step: 12
Training loss: 2.7108058402770974
Validation loss: 2.4839237691051848

Epoch: 6| Step: 13
Training loss: 2.7591890784386184
Validation loss: 2.4873425975437202

Epoch: 82| Step: 0
Training loss: 2.1108757049528646
Validation loss: 2.483978895683342

Epoch: 6| Step: 1
Training loss: 2.109779940695911
Validation loss: 2.481577163510133

Epoch: 6| Step: 2
Training loss: 2.565041560975902
Validation loss: 2.4828133463232938

Epoch: 6| Step: 3
Training loss: 2.6603946438930604
Validation loss: 2.4785748958890577

Epoch: 6| Step: 4
Training loss: 2.8059810110198717
Validation loss: 2.489938723896628

Epoch: 6| Step: 5
Training loss: 1.9812371382912575
Validation loss: 2.4813846369039236

Epoch: 6| Step: 6
Training loss: 2.4357079985672887
Validation loss: 2.48935298306243

Epoch: 6| Step: 7
Training loss: 2.597979853844884
Validation loss: 2.482191617878157

Epoch: 6| Step: 8
Training loss: 3.0787388533198
Validation loss: 2.4884387594741444

Epoch: 6| Step: 9
Training loss: 2.5141742385111296
Validation loss: 2.493859363092293

Epoch: 6| Step: 10
Training loss: 2.4390436810800566
Validation loss: 2.4853482049645788

Epoch: 6| Step: 11
Training loss: 2.7834392032551696
Validation loss: 2.4896632677810002

Epoch: 6| Step: 12
Training loss: 2.776172074242377
Validation loss: 2.4853109679938266

Epoch: 6| Step: 13
Training loss: 3.0591165965350666
Validation loss: 2.4841520581289895

Epoch: 83| Step: 0
Training loss: 2.5647531233691456
Validation loss: 2.4954626711391845

Epoch: 6| Step: 1
Training loss: 2.666771727717599
Validation loss: 2.4864525255684904

Epoch: 6| Step: 2
Training loss: 2.951593233900668
Validation loss: 2.489511230786656

Epoch: 6| Step: 3
Training loss: 2.5280990769008547
Validation loss: 2.483143643253936

Epoch: 6| Step: 4
Training loss: 2.544074642825765
Validation loss: 2.4861616032431995

Epoch: 6| Step: 5
Training loss: 2.6847971254562975
Validation loss: 2.486893734621302

Epoch: 6| Step: 6
Training loss: 2.623119679887097
Validation loss: 2.493404573563473

Epoch: 6| Step: 7
Training loss: 2.83810165681293
Validation loss: 2.4910629350120597

Epoch: 6| Step: 8
Training loss: 2.498368875540408
Validation loss: 2.491246826200478

Epoch: 6| Step: 9
Training loss: 2.764352796803055
Validation loss: 2.493218219755095

Epoch: 6| Step: 10
Training loss: 2.8330739594462377
Validation loss: 2.491571762888766

Epoch: 6| Step: 11
Training loss: 2.4413149396987155
Validation loss: 2.49063719040884

Epoch: 6| Step: 12
Training loss: 2.5069579572891683
Validation loss: 2.489708172422771

Epoch: 6| Step: 13
Training loss: 1.9633572910943353
Validation loss: 2.4843499204381394

Epoch: 84| Step: 0
Training loss: 2.9249535320536038
Validation loss: 2.482187471645508

Epoch: 6| Step: 1
Training loss: 2.6803336295946965
Validation loss: 2.489440472280034

Epoch: 6| Step: 2
Training loss: 2.684652372336226
Validation loss: 2.4837495588363976

Epoch: 6| Step: 3
Training loss: 2.5957879023201773
Validation loss: 2.4869822770077628

Epoch: 6| Step: 4
Training loss: 2.8616209121213
Validation loss: 2.4844674946902905

Epoch: 6| Step: 5
Training loss: 2.4695181315579577
Validation loss: 2.4847192745666287

Epoch: 6| Step: 6
Training loss: 2.7819943235711024
Validation loss: 2.485582613994068

Epoch: 6| Step: 7
Training loss: 2.5425279648404753
Validation loss: 2.4890002894045686

Epoch: 6| Step: 8
Training loss: 2.585985073792941
Validation loss: 2.4885456896866898

Epoch: 6| Step: 9
Training loss: 2.3053779214452574
Validation loss: 2.492124781920564

Epoch: 6| Step: 10
Training loss: 2.81996790928539
Validation loss: 2.49154086279133

Epoch: 6| Step: 11
Training loss: 2.5824111912866563
Validation loss: 2.485304980288024

Epoch: 6| Step: 12
Training loss: 2.088251437778222
Validation loss: 2.485978207034123

Epoch: 6| Step: 13
Training loss: 2.3022211876469614
Validation loss: 2.4850420186374755

Epoch: 85| Step: 0
Training loss: 2.194369619303696
Validation loss: 2.4811406064201

Epoch: 6| Step: 1
Training loss: 2.8644812178472914
Validation loss: 2.4792625718573267

Epoch: 6| Step: 2
Training loss: 3.0645751150830565
Validation loss: 2.4776643133223697

Epoch: 6| Step: 3
Training loss: 2.8999355177451926
Validation loss: 2.46999088118359

Epoch: 6| Step: 4
Training loss: 2.3857355917965517
Validation loss: 2.4750206336371883

Epoch: 6| Step: 5
Training loss: 2.6338973258245737
Validation loss: 2.4732978072875342

Epoch: 6| Step: 6
Training loss: 2.319107102197922
Validation loss: 2.4675193004632754

Epoch: 6| Step: 7
Training loss: 2.0837570395347895
Validation loss: 2.4755399339804343

Epoch: 6| Step: 8
Training loss: 2.184388918416181
Validation loss: 2.4725404604798524

Epoch: 6| Step: 9
Training loss: 2.8214491141538893
Validation loss: 2.4708410010988118

Epoch: 6| Step: 10
Training loss: 2.860406408178091
Validation loss: 2.473644715893068

Epoch: 6| Step: 11
Training loss: 2.6572222557159146
Validation loss: 2.4736505149612484

Epoch: 6| Step: 12
Training loss: 2.885536292358674
Validation loss: 2.476723041004063

Epoch: 6| Step: 13
Training loss: 2.1756693676000123
Validation loss: 2.4839277524653918

Epoch: 86| Step: 0
Training loss: 2.535688676455335
Validation loss: 2.484249039821664

Epoch: 6| Step: 1
Training loss: 2.5548098473605925
Validation loss: 2.4837592299503766

Epoch: 6| Step: 2
Training loss: 2.3093516595097148
Validation loss: 2.4792293465862425

Epoch: 6| Step: 3
Training loss: 2.553050318621402
Validation loss: 2.477363593243482

Epoch: 6| Step: 4
Training loss: 2.5185098159656305
Validation loss: 2.4720410490146207

Epoch: 6| Step: 5
Training loss: 2.7747848461701317
Validation loss: 2.47530349835759

Epoch: 6| Step: 6
Training loss: 2.758734616442829
Validation loss: 2.477993765166585

Epoch: 6| Step: 7
Training loss: 2.701613869297257
Validation loss: 2.470587034852941

Epoch: 6| Step: 8
Training loss: 2.1561578924436904
Validation loss: 2.4786567056642808

Epoch: 6| Step: 9
Training loss: 2.1989629945716143
Validation loss: 2.4798622651460827

Epoch: 6| Step: 10
Training loss: 2.467575373247239
Validation loss: 2.479952188205268

Epoch: 6| Step: 11
Training loss: 2.7512433102503433
Validation loss: 2.4811135963209776

Epoch: 6| Step: 12
Training loss: 3.0648044557408083
Validation loss: 2.481690962241046

Epoch: 6| Step: 13
Training loss: 2.922717946902088
Validation loss: 2.4823923096695752

Epoch: 87| Step: 0
Training loss: 1.7066006673901195
Validation loss: 2.4812923475826794

Epoch: 6| Step: 1
Training loss: 2.361547114438363
Validation loss: 2.481502671913063

Epoch: 6| Step: 2
Training loss: 2.4859264975351665
Validation loss: 2.4813285398824734

Epoch: 6| Step: 3
Training loss: 2.3268386051877954
Validation loss: 2.4812232604615843

Epoch: 6| Step: 4
Training loss: 2.6573481365460814
Validation loss: 2.4815052820390693

Epoch: 6| Step: 5
Training loss: 2.7659572250909297
Validation loss: 2.4815874275467436

Epoch: 6| Step: 6
Training loss: 2.626989972731814
Validation loss: 2.483757902074261

Epoch: 6| Step: 7
Training loss: 2.085861376112729
Validation loss: 2.482564278276565

Epoch: 6| Step: 8
Training loss: 2.792070065479969
Validation loss: 2.4821687414734863

Epoch: 6| Step: 9
Training loss: 2.4023055406958864
Validation loss: 2.4835494647178167

Epoch: 6| Step: 10
Training loss: 2.9360487579330083
Validation loss: 2.4826293826569588

Epoch: 6| Step: 11
Training loss: 2.8183616590589757
Validation loss: 2.48238496230219

Epoch: 6| Step: 12
Training loss: 3.112831992708817
Validation loss: 2.4828378492421272

Epoch: 6| Step: 13
Training loss: 2.985098706119836
Validation loss: 2.484063982738968

Epoch: 88| Step: 0
Training loss: 2.4460999802175327
Validation loss: 2.4810585261981903

Epoch: 6| Step: 1
Training loss: 2.7574578508353125
Validation loss: 2.478305864889497

Epoch: 6| Step: 2
Training loss: 2.5621056602184726
Validation loss: 2.483266139134796

Epoch: 6| Step: 3
Training loss: 2.5536006750514635
Validation loss: 2.47930820178617

Epoch: 6| Step: 4
Training loss: 2.563057722479817
Validation loss: 2.4822007907929593

Epoch: 6| Step: 5
Training loss: 2.3284689629968023
Validation loss: 2.482762435174651

Epoch: 6| Step: 6
Training loss: 2.3960202240958073
Validation loss: 2.481448963557428

Epoch: 6| Step: 7
Training loss: 2.7557787433943144
Validation loss: 2.479428691534282

Epoch: 6| Step: 8
Training loss: 2.732385227483868
Validation loss: 2.476192715511951

Epoch: 6| Step: 9
Training loss: 2.838096280401032
Validation loss: 2.4689778250986905

Epoch: 6| Step: 10
Training loss: 2.4115963285989253
Validation loss: 2.48159290381724

Epoch: 6| Step: 11
Training loss: 2.833661976622107
Validation loss: 2.502462763501342

Epoch: 6| Step: 12
Training loss: 2.754369905007023
Validation loss: 2.484398127994007

Epoch: 6| Step: 13
Training loss: 2.4979064758788607
Validation loss: 2.4729692000926193

Epoch: 89| Step: 0
Training loss: 2.709794388885511
Validation loss: 2.478660553206274

Epoch: 6| Step: 1
Training loss: 2.387495598114909
Validation loss: 2.463601292432308

Epoch: 6| Step: 2
Training loss: 2.4989243100516156
Validation loss: 2.4708293736786873

Epoch: 6| Step: 3
Training loss: 2.4676383690653294
Validation loss: 2.474880453555643

Epoch: 6| Step: 4
Training loss: 2.1867954754495296
Validation loss: 2.470227905729533

Epoch: 6| Step: 5
Training loss: 2.4616058895155923
Validation loss: 2.47740109402459

Epoch: 6| Step: 6
Training loss: 2.568640446241052
Validation loss: 2.478821118633532

Epoch: 6| Step: 7
Training loss: 2.700838919397133
Validation loss: 2.4803794544397015

Epoch: 6| Step: 8
Training loss: 2.514042042328346
Validation loss: 2.4782243642172155

Epoch: 6| Step: 9
Training loss: 2.744237410715339
Validation loss: 2.484278663030986

Epoch: 6| Step: 10
Training loss: 3.0210885477230875
Validation loss: 2.480447403623187

Epoch: 6| Step: 11
Training loss: 2.743557666476323
Validation loss: 2.478025146884289

Epoch: 6| Step: 12
Training loss: 2.7898678939060892
Validation loss: 2.4817028269835064

Epoch: 6| Step: 13
Training loss: 2.3744574479230134
Validation loss: 2.48170180223066

Epoch: 90| Step: 0
Training loss: 2.7906044509660823
Validation loss: 2.4822253477837126

Epoch: 6| Step: 1
Training loss: 2.404844096279609
Validation loss: 2.4815019032864765

Epoch: 6| Step: 2
Training loss: 2.06960506228376
Validation loss: 2.483479224363689

Epoch: 6| Step: 3
Training loss: 2.591233192900912
Validation loss: 2.4787951332609195

Epoch: 6| Step: 4
Training loss: 1.6648449558090792
Validation loss: 2.4781585347943986

Epoch: 6| Step: 5
Training loss: 2.694882388972303
Validation loss: 2.4787140975457884

Epoch: 6| Step: 6
Training loss: 2.868556555914061
Validation loss: 2.4768897160309424

Epoch: 6| Step: 7
Training loss: 2.65053536027638
Validation loss: 2.479843389221733

Epoch: 6| Step: 8
Training loss: 2.480422997240442
Validation loss: 2.478605628978418

Epoch: 6| Step: 9
Training loss: 2.83102588566541
Validation loss: 2.4713351882404164

Epoch: 6| Step: 10
Training loss: 2.950741891191952
Validation loss: 2.4706445498553076

Epoch: 6| Step: 11
Training loss: 2.920564245289642
Validation loss: 2.470945146892257

Epoch: 6| Step: 12
Training loss: 2.895585705897892
Validation loss: 2.471950725644556

Epoch: 6| Step: 13
Training loss: 2.0339991818616756
Validation loss: 2.47056506428329

Epoch: 91| Step: 0
Training loss: 2.3971045949854872
Validation loss: 2.462683535608795

Epoch: 6| Step: 1
Training loss: 2.493585081072846
Validation loss: 2.4691725904393875

Epoch: 6| Step: 2
Training loss: 2.6422664799720867
Validation loss: 2.4678981776148436

Epoch: 6| Step: 3
Training loss: 2.661226435423052
Validation loss: 2.467338045571146

Epoch: 6| Step: 4
Training loss: 2.596641950559044
Validation loss: 2.4674460915162006

Epoch: 6| Step: 5
Training loss: 2.3617311548632207
Validation loss: 2.470959547806532

Epoch: 6| Step: 6
Training loss: 2.797472756724447
Validation loss: 2.4694008592960377

Epoch: 6| Step: 7
Training loss: 2.5986614376241897
Validation loss: 2.4662302896337476

Epoch: 6| Step: 8
Training loss: 2.6481960490394116
Validation loss: 2.4667772225356974

Epoch: 6| Step: 9
Training loss: 2.884505108412704
Validation loss: 2.467718834544025

Epoch: 6| Step: 10
Training loss: 2.3941434014058895
Validation loss: 2.4712000732832684

Epoch: 6| Step: 11
Training loss: 2.680099589077437
Validation loss: 2.471394052508555

Epoch: 6| Step: 12
Training loss: 2.2689384697430603
Validation loss: 2.4699125087933895

Epoch: 6| Step: 13
Training loss: 2.595588124686329
Validation loss: 2.4680686525526747

Epoch: 92| Step: 0
Training loss: 1.891532238904595
Validation loss: 2.468961296213885

Epoch: 6| Step: 1
Training loss: 2.6594040040923494
Validation loss: 2.473584491525341

Epoch: 6| Step: 2
Training loss: 2.568484691274987
Validation loss: 2.4678943293952433

Epoch: 6| Step: 3
Training loss: 2.676875560332032
Validation loss: 2.466831129515338

Epoch: 6| Step: 4
Training loss: 2.5231576297852762
Validation loss: 2.4667557496231667

Epoch: 6| Step: 5
Training loss: 2.6901012517883127
Validation loss: 2.4696424617503667

Epoch: 6| Step: 6
Training loss: 2.1368590035164754
Validation loss: 2.465599077327786

Epoch: 6| Step: 7
Training loss: 2.5970217740185704
Validation loss: 2.4724274138212405

Epoch: 6| Step: 8
Training loss: 2.8312771760086815
Validation loss: 2.4671371116590217

Epoch: 6| Step: 9
Training loss: 2.5932717859111927
Validation loss: 2.4683114318167916

Epoch: 6| Step: 10
Training loss: 2.6481489626367716
Validation loss: 2.467062747789764

Epoch: 6| Step: 11
Training loss: 2.6430397504515595
Validation loss: 2.4650151938227434

Epoch: 6| Step: 12
Training loss: 3.130917858546099
Validation loss: 2.468052222231096

Epoch: 6| Step: 13
Training loss: 2.3526424323491546
Validation loss: 2.463551306890507

Epoch: 93| Step: 0
Training loss: 1.9023312797372653
Validation loss: 2.474654175458958

Epoch: 6| Step: 1
Training loss: 3.1191935191390203
Validation loss: 2.468383262853936

Epoch: 6| Step: 2
Training loss: 2.4800031089763226
Validation loss: 2.4688505804119187

Epoch: 6| Step: 3
Training loss: 2.7136855035442107
Validation loss: 2.4651537265520065

Epoch: 6| Step: 4
Training loss: 2.934599885458311
Validation loss: 2.4699259826185185

Epoch: 6| Step: 5
Training loss: 2.4627618718204327
Validation loss: 2.4701164745302533

Epoch: 6| Step: 6
Training loss: 2.0918180747787773
Validation loss: 2.4731366261904757

Epoch: 6| Step: 7
Training loss: 2.812604859834509
Validation loss: 2.4772545522469045

Epoch: 6| Step: 8
Training loss: 3.1041786825130977
Validation loss: 2.4716516656692624

Epoch: 6| Step: 9
Training loss: 2.553524861020709
Validation loss: 2.476707125350834

Epoch: 6| Step: 10
Training loss: 2.446525882062473
Validation loss: 2.473237140675171

Epoch: 6| Step: 11
Training loss: 2.4536921337609314
Validation loss: 2.4780207531470237

Epoch: 6| Step: 12
Training loss: 2.652366671793213
Validation loss: 2.4744409886742242

Epoch: 6| Step: 13
Training loss: 1.8682281275770156
Validation loss: 2.4758756549555914

Epoch: 94| Step: 0
Training loss: 2.613793749085101
Validation loss: 2.4752953272883893

Epoch: 6| Step: 1
Training loss: 3.166858182101692
Validation loss: 2.4700219302162703

Epoch: 6| Step: 2
Training loss: 2.044044925979815
Validation loss: 2.472920609052987

Epoch: 6| Step: 3
Training loss: 2.8989474524018384
Validation loss: 2.476639081571152

Epoch: 6| Step: 4
Training loss: 2.216606071427919
Validation loss: 2.4754069346983747

Epoch: 6| Step: 5
Training loss: 3.1819415526809625
Validation loss: 2.473899733535356

Epoch: 6| Step: 6
Training loss: 2.8558417831962286
Validation loss: 2.4751976255385344

Epoch: 6| Step: 7
Training loss: 2.6961903787174553
Validation loss: 2.4704005522279338

Epoch: 6| Step: 8
Training loss: 1.8640677593505541
Validation loss: 2.4714923065670846

Epoch: 6| Step: 9
Training loss: 2.2394647847818083
Validation loss: 2.465549132288265

Epoch: 6| Step: 10
Training loss: 2.7176637781618265
Validation loss: 2.453229541535302

Epoch: 6| Step: 11
Training loss: 2.4758982444462063
Validation loss: 2.4593822267483527

Epoch: 6| Step: 12
Training loss: 2.132533463889694
Validation loss: 2.458405127258242

Epoch: 6| Step: 13
Training loss: 2.6652746044054125
Validation loss: 2.4617216768189865

Epoch: 95| Step: 0
Training loss: 2.57395394197648
Validation loss: 2.4602083286472007

Epoch: 6| Step: 1
Training loss: 2.6397633247057257
Validation loss: 2.459879313638336

Epoch: 6| Step: 2
Training loss: 2.995512785406562
Validation loss: 2.4636534785784505

Epoch: 6| Step: 3
Training loss: 2.3502775718224895
Validation loss: 2.471445422938043

Epoch: 6| Step: 4
Training loss: 2.0478096495174394
Validation loss: 2.476867881583067

Epoch: 6| Step: 5
Training loss: 2.6900235238163446
Validation loss: 2.4784931475434506

Epoch: 6| Step: 6
Training loss: 2.1464044002389753
Validation loss: 2.477977977943729

Epoch: 6| Step: 7
Training loss: 2.36357157791823
Validation loss: 2.475432674722408

Epoch: 6| Step: 8
Training loss: 2.4476383348595285
Validation loss: 2.477770986842309

Epoch: 6| Step: 9
Training loss: 2.9003638269490115
Validation loss: 2.4756478306283305

Epoch: 6| Step: 10
Training loss: 3.2424701613418714
Validation loss: 2.4749026025687844

Epoch: 6| Step: 11
Training loss: 2.488829643626722
Validation loss: 2.4762401350949115

Epoch: 6| Step: 12
Training loss: 2.7912414758383823
Validation loss: 2.4762069013639443

Epoch: 6| Step: 13
Training loss: 2.188348224218315
Validation loss: 2.479295011345088

Epoch: 96| Step: 0
Training loss: 2.4771307164037837
Validation loss: 2.479348718279358

Epoch: 6| Step: 1
Training loss: 2.836335629767306
Validation loss: 2.4717147826666457

Epoch: 6| Step: 2
Training loss: 3.030377291867614
Validation loss: 2.472248656480411

Epoch: 6| Step: 3
Training loss: 2.4734134328301427
Validation loss: 2.4710403473597564

Epoch: 6| Step: 4
Training loss: 2.339497892518632
Validation loss: 2.468969713566323

Epoch: 6| Step: 5
Training loss: 2.6394214483135556
Validation loss: 2.4626135149641253

Epoch: 6| Step: 6
Training loss: 2.5815588999502515
Validation loss: 2.4568776222641344

Epoch: 6| Step: 7
Training loss: 2.726392855462935
Validation loss: 2.462301919525625

Epoch: 6| Step: 8
Training loss: 1.9237190641675819
Validation loss: 2.4644417976590294

Epoch: 6| Step: 9
Training loss: 2.9008805089232443
Validation loss: 2.466150420096354

Epoch: 6| Step: 10
Training loss: 2.659536415517766
Validation loss: 2.464194484829315

Epoch: 6| Step: 11
Training loss: 2.083264069995269
Validation loss: 2.457717678328992

Epoch: 6| Step: 12
Training loss: 2.0735295474355158
Validation loss: 2.4604737667356322

Epoch: 6| Step: 13
Training loss: 2.8402238719978405
Validation loss: 2.468092738353097

Epoch: 97| Step: 0
Training loss: 2.8029667668245466
Validation loss: 2.463313930273316

Epoch: 6| Step: 1
Training loss: 2.4086739357547295
Validation loss: 2.4574580385409996

Epoch: 6| Step: 2
Training loss: 2.6313901959037063
Validation loss: 2.4585335752325315

Epoch: 6| Step: 3
Training loss: 1.721510871837366
Validation loss: 2.45803303150551

Epoch: 6| Step: 4
Training loss: 3.316933885349582
Validation loss: 2.468637793844011

Epoch: 6| Step: 5
Training loss: 2.515568418636542
Validation loss: 2.4619279755387473

Epoch: 6| Step: 6
Training loss: 2.390026142184882
Validation loss: 2.4480132036585425

Epoch: 6| Step: 7
Training loss: 2.5013234450172606
Validation loss: 2.4665659164352856

Epoch: 6| Step: 8
Training loss: 2.5755356240820135
Validation loss: 2.4570014923509333

Epoch: 6| Step: 9
Training loss: 2.58785432610156
Validation loss: 2.454458744779141

Epoch: 6| Step: 10
Training loss: 2.3650011094072574
Validation loss: 2.4573718523755366

Epoch: 6| Step: 11
Training loss: 2.1392781273643413
Validation loss: 2.4579033448635954

Epoch: 6| Step: 12
Training loss: 2.9446909119558824
Validation loss: 2.4660633453355576

Epoch: 6| Step: 13
Training loss: 2.5361228475569537
Validation loss: 2.458717305428733

Epoch: 98| Step: 0
Training loss: 2.2506736170870836
Validation loss: 2.465817581024168

Epoch: 6| Step: 1
Training loss: 2.2472687144186136
Validation loss: 2.462564921289787

Epoch: 6| Step: 2
Training loss: 2.767265221372885
Validation loss: 2.457057433198585

Epoch: 6| Step: 3
Training loss: 2.4151781584298884
Validation loss: 2.4579785354966215

Epoch: 6| Step: 4
Training loss: 2.59065687208276
Validation loss: 2.454403521815098

Epoch: 6| Step: 5
Training loss: 2.3111013358268067
Validation loss: 2.457630611996311

Epoch: 6| Step: 6
Training loss: 3.0400229066688444
Validation loss: 2.4605609908534016

Epoch: 6| Step: 7
Training loss: 2.8006581554736023
Validation loss: 2.459567735318702

Epoch: 6| Step: 8
Training loss: 2.454837857114828
Validation loss: 2.456942283260913

Epoch: 6| Step: 9
Training loss: 2.3552937355625154
Validation loss: 2.4580168816721595

Epoch: 6| Step: 10
Training loss: 2.5392031586640007
Validation loss: 2.457174995394103

Epoch: 6| Step: 11
Training loss: 3.0443348786747535
Validation loss: 2.469485821095401

Epoch: 6| Step: 12
Training loss: 2.2581176551595927
Validation loss: 2.4653869691286885

Epoch: 6| Step: 13
Training loss: 2.4589201878660907
Validation loss: 2.4614593598413013

Epoch: 99| Step: 0
Training loss: 2.26003285561369
Validation loss: 2.4670211436336285

Epoch: 6| Step: 1
Training loss: 2.5684193419211336
Validation loss: 2.4645577741916895

Epoch: 6| Step: 2
Training loss: 2.2311299908845217
Validation loss: 2.4618910380235945

Epoch: 6| Step: 3
Training loss: 2.9256829727840934
Validation loss: 2.456273757133746

Epoch: 6| Step: 4
Training loss: 2.6215923534352803
Validation loss: 2.4495086417242034

Epoch: 6| Step: 5
Training loss: 2.0690353196799838
Validation loss: 2.4598596543696463

Epoch: 6| Step: 6
Training loss: 1.9233332118404005
Validation loss: 2.4562710069529743

Epoch: 6| Step: 7
Training loss: 2.6506287278767755
Validation loss: 2.462042375827409

Epoch: 6| Step: 8
Training loss: 3.3369016303818015
Validation loss: 2.4671307335592854

Epoch: 6| Step: 9
Training loss: 2.554691046382764
Validation loss: 2.464931593275272

Epoch: 6| Step: 10
Training loss: 2.7174978771043503
Validation loss: 2.470464408912035

Epoch: 6| Step: 11
Training loss: 2.226789068105241
Validation loss: 2.45498327670387

Epoch: 6| Step: 12
Training loss: 2.921509582190441
Validation loss: 2.4552968933507997

Epoch: 6| Step: 13
Training loss: 2.4831993152204532
Validation loss: 2.4623245770601803

Epoch: 100| Step: 0
Training loss: 2.1856098183030173
Validation loss: 2.4626700624973665

Epoch: 6| Step: 1
Training loss: 2.108355014171876
Validation loss: 2.474678309563606

Epoch: 6| Step: 2
Training loss: 2.271243160491538
Validation loss: 2.4718657199638803

Epoch: 6| Step: 3
Training loss: 2.6774560295362644
Validation loss: 2.476089977990834

Epoch: 6| Step: 4
Training loss: 2.587508724032083
Validation loss: 2.4774694376579944

Epoch: 6| Step: 5
Training loss: 2.3461874938995737
Validation loss: 2.4783284081788715

Epoch: 6| Step: 6
Training loss: 2.9276868168669017
Validation loss: 2.479074834410396

Epoch: 6| Step: 7
Training loss: 2.8368700244000173
Validation loss: 2.4801308389215597

Epoch: 6| Step: 8
Training loss: 2.8993476199653823
Validation loss: 2.4702581474860374

Epoch: 6| Step: 9
Training loss: 2.4336780025293234
Validation loss: 2.4752791134955747

Epoch: 6| Step: 10
Training loss: 2.9575296483363567
Validation loss: 2.4762160964485784

Epoch: 6| Step: 11
Training loss: 2.874991541311011
Validation loss: 2.466383012580175

Epoch: 6| Step: 12
Training loss: 2.173728316792844
Validation loss: 2.463263567873034

Epoch: 6| Step: 13
Training loss: 2.5256845962527734
Validation loss: 2.463563194476554

Epoch: 101| Step: 0
Training loss: 2.006943926724987
Validation loss: 2.454195910561831

Epoch: 6| Step: 1
Training loss: 2.628998299924258
Validation loss: 2.4577415422114197

Epoch: 6| Step: 2
Training loss: 2.90650840348834
Validation loss: 2.456124199451735

Epoch: 6| Step: 3
Training loss: 2.8941526590087574
Validation loss: 2.4507092610532815

Epoch: 6| Step: 4
Training loss: 2.71585630566539
Validation loss: 2.457558547519403

Epoch: 6| Step: 5
Training loss: 2.3321077216052646
Validation loss: 2.4629058232394367

Epoch: 6| Step: 6
Training loss: 2.817355563397256
Validation loss: 2.45197850870004

Epoch: 6| Step: 7
Training loss: 2.5312482103883043
Validation loss: 2.451669184071666

Epoch: 6| Step: 8
Training loss: 2.4791196503441815
Validation loss: 2.45731032362956

Epoch: 6| Step: 9
Training loss: 2.658336582799697
Validation loss: 2.45895530758242

Epoch: 6| Step: 10
Training loss: 2.2383963936420153
Validation loss: 2.4599002165832387

Epoch: 6| Step: 11
Training loss: 2.288012371109816
Validation loss: 2.4562942377948755

Epoch: 6| Step: 12
Training loss: 2.761828386647599
Validation loss: 2.4681411265953

Epoch: 6| Step: 13
Training loss: 2.4405007109700585
Validation loss: 2.471933637937068

Epoch: 102| Step: 0
Training loss: 2.6205588418882773
Validation loss: 2.471583675638348

Epoch: 6| Step: 1
Training loss: 3.017809141136845
Validation loss: 2.471609543903168

Epoch: 6| Step: 2
Training loss: 2.7663495682535957
Validation loss: 2.4724925360134646

Epoch: 6| Step: 3
Training loss: 2.5591492493944683
Validation loss: 2.4764202570454406

Epoch: 6| Step: 4
Training loss: 2.7619022810193523
Validation loss: 2.473916205331928

Epoch: 6| Step: 5
Training loss: 2.1463153137328996
Validation loss: 2.4737371459596136

Epoch: 6| Step: 6
Training loss: 2.4194305881824167
Validation loss: 2.4730032325339923

Epoch: 6| Step: 7
Training loss: 2.1471668161687623
Validation loss: 2.4739467633963965

Epoch: 6| Step: 8
Training loss: 2.534827259505994
Validation loss: 2.4747931962359484

Epoch: 6| Step: 9
Training loss: 2.3933343431830156
Validation loss: 2.468295317036618

Epoch: 6| Step: 10
Training loss: 2.697068060090078
Validation loss: 2.466065923462946

Epoch: 6| Step: 11
Training loss: 3.1292314491389535
Validation loss: 2.467668545940171

Epoch: 6| Step: 12
Training loss: 2.432839853945148
Validation loss: 2.4672876767321097

Epoch: 6| Step: 13
Training loss: 2.263259916037105
Validation loss: 2.460966548041816

Epoch: 103| Step: 0
Training loss: 2.597536012548588
Validation loss: 2.461787485744755

Epoch: 6| Step: 1
Training loss: 3.131718242302446
Validation loss: 2.4688906891084996

Epoch: 6| Step: 2
Training loss: 2.715810655715931
Validation loss: 2.458346533874588

Epoch: 6| Step: 3
Training loss: 2.1753668946999256
Validation loss: 2.455246754926831

Epoch: 6| Step: 4
Training loss: 2.0503432614507773
Validation loss: 2.4667156706487305

Epoch: 6| Step: 5
Training loss: 2.878455200472206
Validation loss: 2.465142974988636

Epoch: 6| Step: 6
Training loss: 2.688293517311174
Validation loss: 2.4628470707147305

Epoch: 6| Step: 7
Training loss: 2.9533933487327535
Validation loss: 2.462838188740556

Epoch: 6| Step: 8
Training loss: 2.6934995884460395
Validation loss: 2.4557726233565607

Epoch: 6| Step: 9
Training loss: 2.5734067339468036
Validation loss: 2.461841058108916

Epoch: 6| Step: 10
Training loss: 2.854638684820554
Validation loss: 2.4657188188167773

Epoch: 6| Step: 11
Training loss: 2.0281784309202546
Validation loss: 2.4730871948946604

Epoch: 6| Step: 12
Training loss: 1.6977494826436115
Validation loss: 2.4722820559296337

Epoch: 6| Step: 13
Training loss: 2.5204094354348467
Validation loss: 2.474861933007197

Epoch: 104| Step: 0
Training loss: 2.9487795875426506
Validation loss: 2.478092447061462

Epoch: 6| Step: 1
Training loss: 2.407203782536738
Validation loss: 2.47903298303396

Epoch: 6| Step: 2
Training loss: 2.6308416126673957
Validation loss: 2.484930444200654

Epoch: 6| Step: 3
Training loss: 2.766803382651531
Validation loss: 2.485392667958824

Epoch: 6| Step: 4
Training loss: 3.41906427755572
Validation loss: 2.4823985525136636

Epoch: 6| Step: 5
Training loss: 2.5071233355049753
Validation loss: 2.480761925700409

Epoch: 6| Step: 6
Training loss: 1.8065749037877188
Validation loss: 2.4793628700471846

Epoch: 6| Step: 7
Training loss: 2.396594006953927
Validation loss: 2.4793697936459584

Epoch: 6| Step: 8
Training loss: 3.1549030111310166
Validation loss: 2.4768054253362286

Epoch: 6| Step: 9
Training loss: 1.9445461004417366
Validation loss: 2.4791837793181686

Epoch: 6| Step: 10
Training loss: 2.45059676395602
Validation loss: 2.473774316201412

Epoch: 6| Step: 11
Training loss: 2.676120886861921
Validation loss: 2.4724100802932347

Epoch: 6| Step: 12
Training loss: 2.360861000826217
Validation loss: 2.4723627560089585

Epoch: 6| Step: 13
Training loss: 2.3636819294892333
Validation loss: 2.4709867332233055

Epoch: 105| Step: 0
Training loss: 2.1383311657833888
Validation loss: 2.4686456811167297

Epoch: 6| Step: 1
Training loss: 2.311267421196681
Validation loss: 2.468617624846307

Epoch: 6| Step: 2
Training loss: 2.9647078451538356
Validation loss: 2.4669766072418082

Epoch: 6| Step: 3
Training loss: 2.805120323170794
Validation loss: 2.461695930635882

Epoch: 6| Step: 4
Training loss: 2.073062322920938
Validation loss: 2.4589195899418104

Epoch: 6| Step: 5
Training loss: 2.3398985689138696
Validation loss: 2.456872018123122

Epoch: 6| Step: 6
Training loss: 2.5340667875862612
Validation loss: 2.4584011995247455

Epoch: 6| Step: 7
Training loss: 2.5892782615216117
Validation loss: 2.455539802593758

Epoch: 6| Step: 8
Training loss: 2.362921064688107
Validation loss: 2.4598181060802866

Epoch: 6| Step: 9
Training loss: 2.700146042441537
Validation loss: 2.4601617952964507

Epoch: 6| Step: 10
Training loss: 2.5652151842185122
Validation loss: 2.4580359090422568

Epoch: 6| Step: 11
Training loss: 2.6760017693974185
Validation loss: 2.4611115570680298

Epoch: 6| Step: 12
Training loss: 2.9413877691775006
Validation loss: 2.464622991462626

Epoch: 6| Step: 13
Training loss: 2.7663774921395152
Validation loss: 2.4558472724633735

Epoch: 106| Step: 0
Training loss: 2.508083055584184
Validation loss: 2.462434488964532

Epoch: 6| Step: 1
Training loss: 2.454318394096832
Validation loss: 2.467667128891339

Epoch: 6| Step: 2
Training loss: 2.5049525795900554
Validation loss: 2.466647093497623

Epoch: 6| Step: 3
Training loss: 2.2309411612514167
Validation loss: 2.4721295607866605

Epoch: 6| Step: 4
Training loss: 2.844531947352977
Validation loss: 2.47584168607248

Epoch: 6| Step: 5
Training loss: 2.7985371174166325
Validation loss: 2.4754143589610234

Epoch: 6| Step: 6
Training loss: 2.206735668813036
Validation loss: 2.472941345524483

Epoch: 6| Step: 7
Training loss: 2.765118568734027
Validation loss: 2.474763162436291

Epoch: 6| Step: 8
Training loss: 3.0304798838997744
Validation loss: 2.475532309448514

Epoch: 6| Step: 9
Training loss: 2.2888528252613334
Validation loss: 2.477602719160909

Epoch: 6| Step: 10
Training loss: 2.438430804036025
Validation loss: 2.467827854077331

Epoch: 6| Step: 11
Training loss: 2.7161974269591007
Validation loss: 2.4713884410886573

Epoch: 6| Step: 12
Training loss: 2.4161113451758793
Validation loss: 2.470377277101636

Epoch: 6| Step: 13
Training loss: 2.7479186417864416
Validation loss: 2.4582067284607394

Epoch: 107| Step: 0
Training loss: 1.382713572955994
Validation loss: 2.4671417019478703

Epoch: 6| Step: 1
Training loss: 2.780267091723088
Validation loss: 2.462419804204736

Epoch: 6| Step: 2
Training loss: 2.486116578601056
Validation loss: 2.458677273198183

Epoch: 6| Step: 3
Training loss: 2.617443197484776
Validation loss: 2.4672316537795274

Epoch: 6| Step: 4
Training loss: 2.1323615075920075
Validation loss: 2.4702059480519885

Epoch: 6| Step: 5
Training loss: 2.414830650410068
Validation loss: 2.475853466498622

Epoch: 6| Step: 6
Training loss: 2.756814662676943
Validation loss: 2.470880192981859

Epoch: 6| Step: 7
Training loss: 2.599720162224196
Validation loss: 2.471669864622462

Epoch: 6| Step: 8
Training loss: 3.12214774619528
Validation loss: 2.4764216209478707

Epoch: 6| Step: 9
Training loss: 3.205139568699964
Validation loss: 2.478826168196229

Epoch: 6| Step: 10
Training loss: 2.9135365356647442
Validation loss: 2.465945393125037

Epoch: 6| Step: 11
Training loss: 2.602839709123787
Validation loss: 2.472350380346249

Epoch: 6| Step: 12
Training loss: 1.9375568504606748
Validation loss: 2.4592941044675563

Epoch: 6| Step: 13
Training loss: 2.3126461910742706
Validation loss: 2.4553700113991406

Epoch: 108| Step: 0
Training loss: 2.929406887602807
Validation loss: 2.4591485681474303

Epoch: 6| Step: 1
Training loss: 2.6182021266698707
Validation loss: 2.465842051394479

Epoch: 6| Step: 2
Training loss: 3.0470440157448855
Validation loss: 2.464190558260841

Epoch: 6| Step: 3
Training loss: 1.965234311914566
Validation loss: 2.463363259262332

Epoch: 6| Step: 4
Training loss: 2.514967459284224
Validation loss: 2.465290978147122

Epoch: 6| Step: 5
Training loss: 2.685678441379519
Validation loss: 2.4689399871475017

Epoch: 6| Step: 6
Training loss: 2.2889467802514516
Validation loss: 2.461734210835126

Epoch: 6| Step: 7
Training loss: 2.383560013383834
Validation loss: 2.4624411696944017

Epoch: 6| Step: 8
Training loss: 2.770971184841239
Validation loss: 2.464658638541853

Epoch: 6| Step: 9
Training loss: 2.3959442997541522
Validation loss: 2.4654106701297716

Epoch: 6| Step: 10
Training loss: 2.2114854544726805
Validation loss: 2.466997192335857

Epoch: 6| Step: 11
Training loss: 2.7085501853007496
Validation loss: 2.458341733196154

Epoch: 6| Step: 12
Training loss: 2.7558855019026405
Validation loss: 2.462132070135081

Epoch: 6| Step: 13
Training loss: 2.1373853463102592
Validation loss: 2.459467195352451

Epoch: 109| Step: 0
Training loss: 2.44364936016495
Validation loss: 2.4589362186466395

Epoch: 6| Step: 1
Training loss: 2.528539831504419
Validation loss: 2.4600601166200065

Epoch: 6| Step: 2
Training loss: 1.6888987078018751
Validation loss: 2.453636002822862

Epoch: 6| Step: 3
Training loss: 3.0869047942560957
Validation loss: 2.454576722835907

Epoch: 6| Step: 4
Training loss: 2.441680648642163
Validation loss: 2.4678180641735374

Epoch: 6| Step: 5
Training loss: 2.9195127679016784
Validation loss: 2.4576835635689314

Epoch: 6| Step: 6
Training loss: 2.9975625308579983
Validation loss: 2.4659385285193873

Epoch: 6| Step: 7
Training loss: 2.2825654300198663
Validation loss: 2.453988637981315

Epoch: 6| Step: 8
Training loss: 2.668477268264412
Validation loss: 2.4588963192622892

Epoch: 6| Step: 9
Training loss: 2.658834299778608
Validation loss: 2.456251254093539

Epoch: 6| Step: 10
Training loss: 2.6677499795920308
Validation loss: 2.4698406659213994

Epoch: 6| Step: 11
Training loss: 2.1028309223957105
Validation loss: 2.46575066294992

Epoch: 6| Step: 12
Training loss: 2.4223820309412187
Validation loss: 2.471064500678826

Epoch: 6| Step: 13
Training loss: 2.4187724267673953
Validation loss: 2.467596162689131

Epoch: 110| Step: 0
Training loss: 2.671536697475491
Validation loss: 2.4703310479005265

Epoch: 6| Step: 1
Training loss: 2.5926474560377137
Validation loss: 2.4758698851734344

Epoch: 6| Step: 2
Training loss: 2.757480417633386
Validation loss: 2.4687573396597777

Epoch: 6| Step: 3
Training loss: 2.7098975921650568
Validation loss: 2.471852023616318

Epoch: 6| Step: 4
Training loss: 2.493910812508553
Validation loss: 2.465444565147162

Epoch: 6| Step: 5
Training loss: 2.737039368775244
Validation loss: 2.4649738130345575

Epoch: 6| Step: 6
Training loss: 3.2030379120687757
Validation loss: 2.4656423815496122

Epoch: 6| Step: 7
Training loss: 2.072486973481142
Validation loss: 2.459334595221905

Epoch: 6| Step: 8
Training loss: 2.48944687303075
Validation loss: 2.4580490034085063

Epoch: 6| Step: 9
Training loss: 2.5393110417717666
Validation loss: 2.4605231688143183

Epoch: 6| Step: 10
Training loss: 2.332738823311698
Validation loss: 2.4559450887263568

Epoch: 6| Step: 11
Training loss: 1.8356462612875553
Validation loss: 2.4555350935223914

Epoch: 6| Step: 12
Training loss: 1.9198559956390189
Validation loss: 2.453742708806512

Epoch: 6| Step: 13
Training loss: 2.9879697550068904
Validation loss: 2.4508886490275414

Epoch: 111| Step: 0
Training loss: 2.6166179891379486
Validation loss: 2.454419792562461

Epoch: 6| Step: 1
Training loss: 1.7106805199061932
Validation loss: 2.451728431365363

Epoch: 6| Step: 2
Training loss: 2.7790954473960237
Validation loss: 2.45416603757616

Epoch: 6| Step: 3
Training loss: 1.9303172701628013
Validation loss: 2.4597601117657963

Epoch: 6| Step: 4
Training loss: 2.4556692742453445
Validation loss: 2.4701328509043687

Epoch: 6| Step: 5
Training loss: 2.553333541963069
Validation loss: 2.477337817142167

Epoch: 6| Step: 6
Training loss: 2.818379170116294
Validation loss: 2.4743170280760394

Epoch: 6| Step: 7
Training loss: 2.9262313598404135
Validation loss: 2.473826793720693

Epoch: 6| Step: 8
Training loss: 2.5559254484572294
Validation loss: 2.4645806044635727

Epoch: 6| Step: 9
Training loss: 2.3568377462481145
Validation loss: 2.4666726510731385

Epoch: 6| Step: 10
Training loss: 2.6504934427309412
Validation loss: 2.4625752968418575

Epoch: 6| Step: 11
Training loss: 2.7243014253893003
Validation loss: 2.4623953724432845

Epoch: 6| Step: 12
Training loss: 2.954351099997782
Validation loss: 2.4603350754747924

Epoch: 6| Step: 13
Training loss: 2.5318777930612257
Validation loss: 2.459318066155701

Epoch: 112| Step: 0
Training loss: 2.344435527999499
Validation loss: 2.463405731730591

Epoch: 6| Step: 1
Training loss: 3.008266979412131
Validation loss: 2.45616264737975

Epoch: 6| Step: 2
Training loss: 3.0293428379411194
Validation loss: 2.4633988277863526

Epoch: 6| Step: 3
Training loss: 2.456662391424233
Validation loss: 2.4607078808426874

Epoch: 6| Step: 4
Training loss: 2.4925749187631197
Validation loss: 2.459902017717397

Epoch: 6| Step: 5
Training loss: 2.3434903827565123
Validation loss: 2.466991554807618

Epoch: 6| Step: 6
Training loss: 2.813840080591914
Validation loss: 2.466039191373671

Epoch: 6| Step: 7
Training loss: 2.864487044132156
Validation loss: 2.470664324348967

Epoch: 6| Step: 8
Training loss: 2.117951090030925
Validation loss: 2.4650674467550977

Epoch: 6| Step: 9
Training loss: 2.3360062911197135
Validation loss: 2.472177644987318

Epoch: 6| Step: 10
Training loss: 2.2097934957833383
Validation loss: 2.467301865468335

Epoch: 6| Step: 11
Training loss: 2.2314564243432304
Validation loss: 2.470380848006021

Epoch: 6| Step: 12
Training loss: 2.713992110126359
Validation loss: 2.465142185141802

Epoch: 6| Step: 13
Training loss: 2.7239142293380465
Validation loss: 2.4668957390182054

Epoch: 113| Step: 0
Training loss: 2.8797233591729277
Validation loss: 2.4679608753767432

Epoch: 6| Step: 1
Training loss: 2.3014550250637873
Validation loss: 2.462808622265129

Epoch: 6| Step: 2
Training loss: 2.558740975606758
Validation loss: 2.4600830370888613

Epoch: 6| Step: 3
Training loss: 2.821521193586132
Validation loss: 2.4648221554543226

Epoch: 6| Step: 4
Training loss: 2.2554194562260363
Validation loss: 2.463919763133894

Epoch: 6| Step: 5
Training loss: 2.3423850599036578
Validation loss: 2.463714082798981

Epoch: 6| Step: 6
Training loss: 1.846098228833371
Validation loss: 2.47086467390678

Epoch: 6| Step: 7
Training loss: 2.7857451384795593
Validation loss: 2.4676274672967518

Epoch: 6| Step: 8
Training loss: 2.5945248652847424
Validation loss: 2.4708236323182806

Epoch: 6| Step: 9
Training loss: 2.496887749363668
Validation loss: 2.470462888916943

Epoch: 6| Step: 10
Training loss: 2.8370772664436696
Validation loss: 2.4668784391077843

Epoch: 6| Step: 11
Training loss: 2.4873498344143283
Validation loss: 2.463630389712109

Epoch: 6| Step: 12
Training loss: 2.362672635991555
Validation loss: 2.461788244385347

Epoch: 6| Step: 13
Training loss: 3.027838921196906
Validation loss: 2.4645926966829235

Epoch: 114| Step: 0
Training loss: 2.914334118331576
Validation loss: 2.4683205436239537

Epoch: 6| Step: 1
Training loss: 2.3349217276350247
Validation loss: 2.4737465751101224

Epoch: 6| Step: 2
Training loss: 2.878553930538399
Validation loss: 2.4744362834559266

Epoch: 6| Step: 3
Training loss: 2.931179307683012
Validation loss: 2.4686381479670003

Epoch: 6| Step: 4
Training loss: 2.8611279726817553
Validation loss: 2.461551956890935

Epoch: 6| Step: 5
Training loss: 2.592689297275285
Validation loss: 2.459848346584351

Epoch: 6| Step: 6
Training loss: 2.094989125262239
Validation loss: 2.453154545502809

Epoch: 6| Step: 7
Training loss: 3.0587175327163325
Validation loss: 2.454076303093245

Epoch: 6| Step: 8
Training loss: 2.0323329679540842
Validation loss: 2.4472455883702744

Epoch: 6| Step: 9
Training loss: 2.062861555371775
Validation loss: 2.453571594795131

Epoch: 6| Step: 10
Training loss: 2.3889012324090686
Validation loss: 2.448210505171614

Epoch: 6| Step: 11
Training loss: 2.549732687907726
Validation loss: 2.4523346715141123

Epoch: 6| Step: 12
Training loss: 2.659533995056618
Validation loss: 2.4610038788739197

Epoch: 6| Step: 13
Training loss: 1.813384662327117
Validation loss: 2.4631632755547956

Epoch: 115| Step: 0
Training loss: 2.5166678784432768
Validation loss: 2.4592511570410607

Epoch: 6| Step: 1
Training loss: 2.803551829150681
Validation loss: 2.466326477674716

Epoch: 6| Step: 2
Training loss: 2.064773462537506
Validation loss: 2.4588555304010336

Epoch: 6| Step: 3
Training loss: 2.1696750833583796
Validation loss: 2.4615693103785987

Epoch: 6| Step: 4
Training loss: 2.596450135585043
Validation loss: 2.466755540208996

Epoch: 6| Step: 5
Training loss: 2.471401480786932
Validation loss: 2.4662819609622937

Epoch: 6| Step: 6
Training loss: 2.2070738121587357
Validation loss: 2.463620615387048

Epoch: 6| Step: 7
Training loss: 3.2002587869429813
Validation loss: 2.4568902375997252

Epoch: 6| Step: 8
Training loss: 2.852678973963108
Validation loss: 2.4632772474481253

Epoch: 6| Step: 9
Training loss: 2.455860726374489
Validation loss: 2.4621687135360175

Epoch: 6| Step: 10
Training loss: 2.810454069491475
Validation loss: 2.451955690737582

Epoch: 6| Step: 11
Training loss: 2.616764045733761
Validation loss: 2.446986428846092

Epoch: 6| Step: 12
Training loss: 1.9280036034847157
Validation loss: 2.4503002222842767

Epoch: 6| Step: 13
Training loss: 2.527298468489253
Validation loss: 2.446692973869456

Epoch: 116| Step: 0
Training loss: 2.7790094844934923
Validation loss: 2.4527248534064183

Epoch: 6| Step: 1
Training loss: 2.7116710538854045
Validation loss: 2.4577084382878964

Epoch: 6| Step: 2
Training loss: 2.5318107454823595
Validation loss: 2.451775764961392

Epoch: 6| Step: 3
Training loss: 2.2068410065614077
Validation loss: 2.4526874856708996

Epoch: 6| Step: 4
Training loss: 2.646928655627763
Validation loss: 2.462166954407012

Epoch: 6| Step: 5
Training loss: 2.8534285618883635
Validation loss: 2.4651011772360625

Epoch: 6| Step: 6
Training loss: 2.495799159185924
Validation loss: 2.4593547595627996

Epoch: 6| Step: 7
Training loss: 2.807782433995781
Validation loss: 2.462711869240953

Epoch: 6| Step: 8
Training loss: 2.106411243458552
Validation loss: 2.462924667635382

Epoch: 6| Step: 9
Training loss: 2.317323139771114
Validation loss: 2.459708303432141

Epoch: 6| Step: 10
Training loss: 2.5112976385661208
Validation loss: 2.464925338434616

Epoch: 6| Step: 11
Training loss: 2.412889510418939
Validation loss: 2.4592945326454214

Epoch: 6| Step: 12
Training loss: 2.967304078393777
Validation loss: 2.460831315913559

Epoch: 6| Step: 13
Training loss: 2.1170247708665686
Validation loss: 2.4653395745019773

Epoch: 117| Step: 0
Training loss: 2.1481053320989054
Validation loss: 2.464837333723242

Epoch: 6| Step: 1
Training loss: 2.4552986574019453
Validation loss: 2.457402090642721

Epoch: 6| Step: 2
Training loss: 2.56800260785526
Validation loss: 2.4578145713660002

Epoch: 6| Step: 3
Training loss: 2.549850691369753
Validation loss: 2.450633798739272

Epoch: 6| Step: 4
Training loss: 2.5200712349829373
Validation loss: 2.4576632885061405

Epoch: 6| Step: 5
Training loss: 2.4679590237707503
Validation loss: 2.4481461167173455

Epoch: 6| Step: 6
Training loss: 2.625749208617452
Validation loss: 2.458823338397296

Epoch: 6| Step: 7
Training loss: 2.1502665554083897
Validation loss: 2.4572742303604542

Epoch: 6| Step: 8
Training loss: 2.881002048903494
Validation loss: 2.4638063370605066

Epoch: 6| Step: 9
Training loss: 2.5166913728153912
Validation loss: 2.455303625869461

Epoch: 6| Step: 10
Training loss: 3.0219503683259736
Validation loss: 2.454546894957166

Epoch: 6| Step: 11
Training loss: 2.085247940214297
Validation loss: 2.444754848736647

Epoch: 6| Step: 12
Training loss: 2.973810640977928
Validation loss: 2.4511938816009757

Epoch: 6| Step: 13
Training loss: 2.615140199568126
Validation loss: 2.459197108141618

Epoch: 118| Step: 0
Training loss: 2.629634399240593
Validation loss: 2.4726130846865035

Epoch: 6| Step: 1
Training loss: 3.109907095156209
Validation loss: 2.4648274513346577

Epoch: 6| Step: 2
Training loss: 2.3845684647972814
Validation loss: 2.4704803647829126

Epoch: 6| Step: 3
Training loss: 3.2697287150084757
Validation loss: 2.4605728767370847

Epoch: 6| Step: 4
Training loss: 2.1353641658624904
Validation loss: 2.466643017792961

Epoch: 6| Step: 5
Training loss: 2.4219720636421447
Validation loss: 2.4618330199074627

Epoch: 6| Step: 6
Training loss: 2.2247182603400875
Validation loss: 2.4580388835710836

Epoch: 6| Step: 7
Training loss: 2.512000653953224
Validation loss: 2.4609551161685546

Epoch: 6| Step: 8
Training loss: 1.935711188708509
Validation loss: 2.460999777676974

Epoch: 6| Step: 9
Training loss: 2.7739773077225713
Validation loss: 2.4527288874352995

Epoch: 6| Step: 10
Training loss: 2.6938384074774393
Validation loss: 2.4568222272353757

Epoch: 6| Step: 11
Training loss: 2.3167615235300287
Validation loss: 2.4606030595179287

Epoch: 6| Step: 12
Training loss: 2.2001909779972837
Validation loss: 2.460528885761024

Epoch: 6| Step: 13
Training loss: 2.677935859117177
Validation loss: 2.4629452301272448

Epoch: 119| Step: 0
Training loss: 2.569340391601042
Validation loss: 2.462663035474075

Epoch: 6| Step: 1
Training loss: 2.490940463622233
Validation loss: 2.465302228731736

Epoch: 6| Step: 2
Training loss: 2.661975568961619
Validation loss: 2.465135092628278

Epoch: 6| Step: 3
Training loss: 2.822679028708168
Validation loss: 2.4664243777807866

Epoch: 6| Step: 4
Training loss: 2.9052719603462633
Validation loss: 2.467490780474011

Epoch: 6| Step: 5
Training loss: 2.2710837013276897
Validation loss: 2.46971915331808

Epoch: 6| Step: 6
Training loss: 2.6398897671082615
Validation loss: 2.4654844794382154

Epoch: 6| Step: 7
Training loss: 3.1583432347554297
Validation loss: 2.4696743196507955

Epoch: 6| Step: 8
Training loss: 2.4279555253004355
Validation loss: 2.4697308100991546

Epoch: 6| Step: 9
Training loss: 2.5246209832688504
Validation loss: 2.462874152067689

Epoch: 6| Step: 10
Training loss: 2.5818823974917096
Validation loss: 2.4531221005043986

Epoch: 6| Step: 11
Training loss: 1.9938651407411914
Validation loss: 2.456490073471465

Epoch: 6| Step: 12
Training loss: 1.4100770796005209
Validation loss: 2.4607345093664525

Epoch: 6| Step: 13
Training loss: 2.774628719201714
Validation loss: 2.458286354995393

Epoch: 120| Step: 0
Training loss: 2.6896538198992146
Validation loss: 2.4576281220316814

Epoch: 6| Step: 1
Training loss: 2.6059487514067685
Validation loss: 2.462651280695684

Epoch: 6| Step: 2
Training loss: 2.627570573927878
Validation loss: 2.4575956229113385

Epoch: 6| Step: 3
Training loss: 2.4422479017992367
Validation loss: 2.4621413904087914

Epoch: 6| Step: 4
Training loss: 2.6658647543448732
Validation loss: 2.4651055940008284

Epoch: 6| Step: 5
Training loss: 2.5788463161452917
Validation loss: 2.46146614007819

Epoch: 6| Step: 6
Training loss: 2.832238341027418
Validation loss: 2.46214030909746

Epoch: 6| Step: 7
Training loss: 2.1968170114951833
Validation loss: 2.467830406208698

Epoch: 6| Step: 8
Training loss: 2.8976677954786503
Validation loss: 2.465413281174781

Epoch: 6| Step: 9
Training loss: 2.4407029260364403
Validation loss: 2.4699629608522624

Epoch: 6| Step: 10
Training loss: 2.5435590630181495
Validation loss: 2.465573710080163

Epoch: 6| Step: 11
Training loss: 2.289892261086275
Validation loss: 2.467522344079027

Epoch: 6| Step: 12
Training loss: 2.551115472696071
Validation loss: 2.47124213771055

Epoch: 6| Step: 13
Training loss: 2.0952131937661007
Validation loss: 2.459200921496043

Epoch: 121| Step: 0
Training loss: 3.038499794768401
Validation loss: 2.4526191400435557

Epoch: 6| Step: 1
Training loss: 1.7842795725623701
Validation loss: 2.454670915035665

Epoch: 6| Step: 2
Training loss: 2.226714333159191
Validation loss: 2.4505735034261833

Epoch: 6| Step: 3
Training loss: 2.31390678299112
Validation loss: 2.4556894039577

Epoch: 6| Step: 4
Training loss: 2.347704183942844
Validation loss: 2.450577613964596

Epoch: 6| Step: 5
Training loss: 2.5273101662905844
Validation loss: 2.451605405122061

Epoch: 6| Step: 6
Training loss: 2.1355656889733377
Validation loss: 2.4607931185557304

Epoch: 6| Step: 7
Training loss: 2.7234384734808037
Validation loss: 2.4610001328990267

Epoch: 6| Step: 8
Training loss: 2.864522334518629
Validation loss: 2.4674336911934645

Epoch: 6| Step: 9
Training loss: 2.8830716810044903
Validation loss: 2.4735628688686133

Epoch: 6| Step: 10
Training loss: 2.8302270653958526
Validation loss: 2.450105594772827

Epoch: 6| Step: 11
Training loss: 2.7215908598596665
Validation loss: 2.446132112241018

Epoch: 6| Step: 12
Training loss: 2.195040974506112
Validation loss: 2.444530780548769

Epoch: 6| Step: 13
Training loss: 2.768726226497911
Validation loss: 2.4564173770009745

Epoch: 122| Step: 0
Training loss: 1.91218780263221
Validation loss: 2.46660561120876

Epoch: 6| Step: 1
Training loss: 3.6498321546867403
Validation loss: 2.4704200954438122

Epoch: 6| Step: 2
Training loss: 2.1759965608583647
Validation loss: 2.4737339814836705

Epoch: 6| Step: 3
Training loss: 1.783147971897455
Validation loss: 2.470408160428296

Epoch: 6| Step: 4
Training loss: 2.2580024612926923
Validation loss: 2.4750038801991265

Epoch: 6| Step: 5
Training loss: 2.8751109557924326
Validation loss: 2.466288582934559

Epoch: 6| Step: 6
Training loss: 2.8407350424423363
Validation loss: 2.4742447911441805

Epoch: 6| Step: 7
Training loss: 3.0141310079411325
Validation loss: 2.4736359449774135

Epoch: 6| Step: 8
Training loss: 2.68682036566797
Validation loss: 2.476408383039604

Epoch: 6| Step: 9
Training loss: 2.3687201344562463
Validation loss: 2.4723005074049134

Epoch: 6| Step: 10
Training loss: 2.453731097528968
Validation loss: 2.458501508315992

Epoch: 6| Step: 11
Training loss: 2.3196659921406777
Validation loss: 2.4640044381883004

Epoch: 6| Step: 12
Training loss: 2.626003527689044
Validation loss: 2.4538713846418885

Epoch: 6| Step: 13
Training loss: 2.066360790423282
Validation loss: 2.457527462290687

Epoch: 123| Step: 0
Training loss: 2.358562203165041
Validation loss: 2.4548287600109644

Epoch: 6| Step: 1
Training loss: 2.5464516504335215
Validation loss: 2.4519211068584186

Epoch: 6| Step: 2
Training loss: 2.7777971415374614
Validation loss: 2.455348899959583

Epoch: 6| Step: 3
Training loss: 2.5524745303983973
Validation loss: 2.4627821210434764

Epoch: 6| Step: 4
Training loss: 1.974448660659558
Validation loss: 2.4695228139654186

Epoch: 6| Step: 5
Training loss: 2.7693267014996032
Validation loss: 2.471584825166119

Epoch: 6| Step: 6
Training loss: 2.253806602880122
Validation loss: 2.4670080002468295

Epoch: 6| Step: 7
Training loss: 1.8196460993919863
Validation loss: 2.4578823198513002

Epoch: 6| Step: 8
Training loss: 3.1441706290693174
Validation loss: 2.4512820438182015

Epoch: 6| Step: 9
Training loss: 2.4389916770764897
Validation loss: 2.4460456082335824

Epoch: 6| Step: 10
Training loss: 2.6954741056341622
Validation loss: 2.4504583650113654

Epoch: 6| Step: 11
Training loss: 2.62956458545091
Validation loss: 2.4565817174583215

Epoch: 6| Step: 12
Training loss: 2.8534247183500416
Validation loss: 2.462037098165816

Epoch: 6| Step: 13
Training loss: 2.7512427902993797
Validation loss: 2.4644443613588765

Epoch: 124| Step: 0
Training loss: 2.6638387546941993
Validation loss: 2.461846594445256

Epoch: 6| Step: 1
Training loss: 2.414740704818799
Validation loss: 2.4640570350833104

Epoch: 6| Step: 2
Training loss: 3.125662924069834
Validation loss: 2.4554989579766286

Epoch: 6| Step: 3
Training loss: 2.392459140855204
Validation loss: 2.4544901440898443

Epoch: 6| Step: 4
Training loss: 2.3623554528637407
Validation loss: 2.45098065647423

Epoch: 6| Step: 5
Training loss: 1.992964170563572
Validation loss: 2.4517707569302583

Epoch: 6| Step: 6
Training loss: 2.386455215414323
Validation loss: 2.4547189365302766

Epoch: 6| Step: 7
Training loss: 3.129424662987348
Validation loss: 2.452290945952035

Epoch: 6| Step: 8
Training loss: 2.524327549291264
Validation loss: 2.4545770547044325

Epoch: 6| Step: 9
Training loss: 2.47453586195193
Validation loss: 2.4609951759321067

Epoch: 6| Step: 10
Training loss: 2.60580025870187
Validation loss: 2.464832239381057

Epoch: 6| Step: 11
Training loss: 2.4329886135676837
Validation loss: 2.456416891703556

Epoch: 6| Step: 12
Training loss: 2.5956189878905285
Validation loss: 2.4538687532190058

Epoch: 6| Step: 13
Training loss: 2.352606456103227
Validation loss: 2.455889187261682

Epoch: 125| Step: 0
Training loss: 2.2519753579913986
Validation loss: 2.4513760951509505

Epoch: 6| Step: 1
Training loss: 2.5051053370335126
Validation loss: 2.459212167625506

Epoch: 6| Step: 2
Training loss: 2.4260754982694217
Validation loss: 2.458668578182658

Epoch: 6| Step: 3
Training loss: 2.3736679959708846
Validation loss: 2.4646716977227086

Epoch: 6| Step: 4
Training loss: 2.9836865974277393
Validation loss: 2.4696631292078473

Epoch: 6| Step: 5
Training loss: 2.796657788244014
Validation loss: 2.465775818879722

Epoch: 6| Step: 6
Training loss: 2.695783402591262
Validation loss: 2.477549744230767

Epoch: 6| Step: 7
Training loss: 2.0020894818272756
Validation loss: 2.4724610197866457

Epoch: 6| Step: 8
Training loss: 2.6459697377845206
Validation loss: 2.468384743884254

Epoch: 6| Step: 9
Training loss: 2.8414904661916442
Validation loss: 2.4699459961407095

Epoch: 6| Step: 10
Training loss: 2.8454142301452845
Validation loss: 2.4706173847987274

Epoch: 6| Step: 11
Training loss: 2.262472340114397
Validation loss: 2.4692758088758078

Epoch: 6| Step: 12
Training loss: 2.378309453761037
Validation loss: 2.4696449476467737

Epoch: 6| Step: 13
Training loss: 2.669744076839863
Validation loss: 2.4663538672179346

Epoch: 126| Step: 0
Training loss: 2.821592426198383
Validation loss: 2.4595769037516693

Epoch: 6| Step: 1
Training loss: 2.6131763294637484
Validation loss: 2.456118666395093

Epoch: 6| Step: 2
Training loss: 2.3368924335605854
Validation loss: 2.4535857170922686

Epoch: 6| Step: 3
Training loss: 2.276128690148567
Validation loss: 2.4596074460998674

Epoch: 6| Step: 4
Training loss: 2.762875585786113
Validation loss: 2.473675526298994

Epoch: 6| Step: 5
Training loss: 2.213613447633627
Validation loss: 2.47106634995784

Epoch: 6| Step: 6
Training loss: 2.3406874929725885
Validation loss: 2.4625987183200633

Epoch: 6| Step: 7
Training loss: 2.8289119405407415
Validation loss: 2.4735046506125613

Epoch: 6| Step: 8
Training loss: 2.8555736183291205
Validation loss: 2.471131942185338

Epoch: 6| Step: 9
Training loss: 2.7080802701438222
Validation loss: 2.4598037287871715

Epoch: 6| Step: 10
Training loss: 2.6602966002691897
Validation loss: 2.4631343098828853

Epoch: 6| Step: 11
Training loss: 2.6580423927342216
Validation loss: 2.455239908961868

Epoch: 6| Step: 12
Training loss: 2.462299660215876
Validation loss: 2.458897886808036

Epoch: 6| Step: 13
Training loss: 1.9374097372379593
Validation loss: 2.4629482713286124

Epoch: 127| Step: 0
Training loss: 2.5224945857705423
Validation loss: 2.4570986238671972

Epoch: 6| Step: 1
Training loss: 2.908479225266805
Validation loss: 2.4609391792735673

Epoch: 6| Step: 2
Training loss: 2.446511361687288
Validation loss: 2.4520960794234794

Epoch: 6| Step: 3
Training loss: 2.6244643436857884
Validation loss: 2.4506827668140914

Epoch: 6| Step: 4
Training loss: 2.5462489382517366
Validation loss: 2.458308451467339

Epoch: 6| Step: 5
Training loss: 3.0688367407945294
Validation loss: 2.4535434957167443

Epoch: 6| Step: 6
Training loss: 2.1881091768269596
Validation loss: 2.4597136830198965

Epoch: 6| Step: 7
Training loss: 2.2371982264404795
Validation loss: 2.4619252962357745

Epoch: 6| Step: 8
Training loss: 2.483018420774456
Validation loss: 2.4585403312130163

Epoch: 6| Step: 9
Training loss: 1.9521332320841975
Validation loss: 2.459411648610944

Epoch: 6| Step: 10
Training loss: 2.7275788344922978
Validation loss: 2.456907850440681

Epoch: 6| Step: 11
Training loss: 2.498206162612347
Validation loss: 2.457390221762957

Epoch: 6| Step: 12
Training loss: 1.8037314256331651
Validation loss: 2.4609772613381176

Epoch: 6| Step: 13
Training loss: 3.0954175366099075
Validation loss: 2.4572088665586924

Epoch: 128| Step: 0
Training loss: 2.433430918822667
Validation loss: 2.460688486569726

Epoch: 6| Step: 1
Training loss: 1.9982842596146102
Validation loss: 2.4590165648955407

Epoch: 6| Step: 2
Training loss: 2.6528875273880708
Validation loss: 2.4564705488407927

Epoch: 6| Step: 3
Training loss: 3.0092126535137695
Validation loss: 2.453260349176307

Epoch: 6| Step: 4
Training loss: 2.376115536966464
Validation loss: 2.4560938888262758

Epoch: 6| Step: 5
Training loss: 2.3691325741825286
Validation loss: 2.454207916323286

Epoch: 6| Step: 6
Training loss: 1.662845506833376
Validation loss: 2.45926259683517

Epoch: 6| Step: 7
Training loss: 2.890193102764009
Validation loss: 2.45215868697714

Epoch: 6| Step: 8
Training loss: 2.641484227985618
Validation loss: 2.458638848431651

Epoch: 6| Step: 9
Training loss: 2.6417605875770036
Validation loss: 2.457706263679999

Epoch: 6| Step: 10
Training loss: 3.4125513708698487
Validation loss: 2.465235981713778

Epoch: 6| Step: 11
Training loss: 2.574402312013241
Validation loss: 2.464207280400207

Epoch: 6| Step: 12
Training loss: 2.005211596465655
Validation loss: 2.4684832304061097

Epoch: 6| Step: 13
Training loss: 2.240397732539801
Validation loss: 2.469325372790543

Epoch: 129| Step: 0
Training loss: 2.1359822958523274
Validation loss: 2.47025899199786

Epoch: 6| Step: 1
Training loss: 2.4282070936467157
Validation loss: 2.475737585756254

Epoch: 6| Step: 2
Training loss: 2.783284418357725
Validation loss: 2.463761049036507

Epoch: 6| Step: 3
Training loss: 2.8591083339728605
Validation loss: 2.470958695493451

Epoch: 6| Step: 4
Training loss: 2.295577948109087
Validation loss: 2.4655543540822538

Epoch: 6| Step: 5
Training loss: 2.2798750404781645
Validation loss: 2.460644352321409

Epoch: 6| Step: 6
Training loss: 2.3292391370532495
Validation loss: 2.4612223303928125

Epoch: 6| Step: 7
Training loss: 2.2557864486994843
Validation loss: 2.463013434417468

Epoch: 6| Step: 8
Training loss: 3.2003864770203805
Validation loss: 2.4598723351813243

Epoch: 6| Step: 9
Training loss: 2.5573257682272055
Validation loss: 2.4641728362168642

Epoch: 6| Step: 10
Training loss: 2.504119721119131
Validation loss: 2.4545657711494053

Epoch: 6| Step: 11
Training loss: 2.517656157877178
Validation loss: 2.4579208211114096

Epoch: 6| Step: 12
Training loss: 2.280292466796937
Validation loss: 2.458538003795998

Epoch: 6| Step: 13
Training loss: 2.7029207185499544
Validation loss: 2.4577571118146846

Epoch: 130| Step: 0
Training loss: 2.9692112614525628
Validation loss: 2.4484131870876267

Epoch: 6| Step: 1
Training loss: 2.5579436196920833
Validation loss: 2.4511060566570007

Epoch: 6| Step: 2
Training loss: 2.404646202758966
Validation loss: 2.4444813478699374

Epoch: 6| Step: 3
Training loss: 2.3235484975995275
Validation loss: 2.4427185600625196

Epoch: 6| Step: 4
Training loss: 2.8341906503367156
Validation loss: 2.4444945148435866

Epoch: 6| Step: 5
Training loss: 2.570845435643163
Validation loss: 2.445155438303922

Epoch: 6| Step: 6
Training loss: 2.380468397450335
Validation loss: 2.4409863571208725

Epoch: 6| Step: 7
Training loss: 2.3268211861411676
Validation loss: 2.45459423086294

Epoch: 6| Step: 8
Training loss: 2.06924883311249
Validation loss: 2.455814612241422

Epoch: 6| Step: 9
Training loss: 2.6155218944942162
Validation loss: 2.44190828985274

Epoch: 6| Step: 10
Training loss: 2.832640694123057
Validation loss: 2.451538706936123

Epoch: 6| Step: 11
Training loss: 2.166364086248434
Validation loss: 2.45014364249649

Epoch: 6| Step: 12
Training loss: 2.4139825999052404
Validation loss: 2.4543428900703295

Epoch: 6| Step: 13
Training loss: 2.701503377502465
Validation loss: 2.4525955908601027

Epoch: 131| Step: 0
Training loss: 2.045336428998439
Validation loss: 2.4589070658187415

Epoch: 6| Step: 1
Training loss: 2.224108390897451
Validation loss: 2.4612203122672227

Epoch: 6| Step: 2
Training loss: 2.898884288972157
Validation loss: 2.4641391655947538

Epoch: 6| Step: 3
Training loss: 2.8705265237406423
Validation loss: 2.463207719574276

Epoch: 6| Step: 4
Training loss: 2.5255975601605
Validation loss: 2.4688309684384477

Epoch: 6| Step: 5
Training loss: 2.234325808537123
Validation loss: 2.46942959859548

Epoch: 6| Step: 6
Training loss: 2.4076691443106495
Validation loss: 2.4693451015265455

Epoch: 6| Step: 7
Training loss: 2.481775711444385
Validation loss: 2.4743686911244045

Epoch: 6| Step: 8
Training loss: 2.4899292283935397
Validation loss: 2.469312402589481

Epoch: 6| Step: 9
Training loss: 2.306472035706343
Validation loss: 2.4718982404475565

Epoch: 6| Step: 10
Training loss: 3.0631660204314075
Validation loss: 2.469642654829789

Epoch: 6| Step: 11
Training loss: 2.5134355008568994
Validation loss: 2.4628452717343556

Epoch: 6| Step: 12
Training loss: 3.027303269638631
Validation loss: 2.459025016289238

Epoch: 6| Step: 13
Training loss: 2.023081980222243
Validation loss: 2.4532047914782584

Epoch: 132| Step: 0
Training loss: 2.788735079312901
Validation loss: 2.455264808437927

Epoch: 6| Step: 1
Training loss: 2.6428671803523156
Validation loss: 2.4508485294568323

Epoch: 6| Step: 2
Training loss: 2.475458807756438
Validation loss: 2.4591503455942103

Epoch: 6| Step: 3
Training loss: 2.206992035914071
Validation loss: 2.4680612625440586

Epoch: 6| Step: 4
Training loss: 2.949896930251782
Validation loss: 2.4560571709703107

Epoch: 6| Step: 5
Training loss: 2.5050900141215124
Validation loss: 2.450716379101778

Epoch: 6| Step: 6
Training loss: 2.8635303758435855
Validation loss: 2.4467483708601097

Epoch: 6| Step: 7
Training loss: 2.5587897072801358
Validation loss: 2.4536779230057655

Epoch: 6| Step: 8
Training loss: 2.183228381985658
Validation loss: 2.4625384255136704

Epoch: 6| Step: 9
Training loss: 2.3138853511449975
Validation loss: 2.4542516239229926

Epoch: 6| Step: 10
Training loss: 2.484095719672378
Validation loss: 2.464775894609403

Epoch: 6| Step: 11
Training loss: 2.8096878403739907
Validation loss: 2.46160444476299

Epoch: 6| Step: 12
Training loss: 2.266669933466334
Validation loss: 2.4583982900884798

Epoch: 6| Step: 13
Training loss: 2.3235512680593673
Validation loss: 2.460196319864304

Epoch: 133| Step: 0
Training loss: 1.721657807486465
Validation loss: 2.4537250894404945

Epoch: 6| Step: 1
Training loss: 2.7308358094436307
Validation loss: 2.4599973628694207

Epoch: 6| Step: 2
Training loss: 3.1182220195541595
Validation loss: 2.458327023988375

Epoch: 6| Step: 3
Training loss: 1.9129200542632945
Validation loss: 2.455506288696845

Epoch: 6| Step: 4
Training loss: 2.322215933945866
Validation loss: 2.4530505839275993

Epoch: 6| Step: 5
Training loss: 3.0217177751542423
Validation loss: 2.4559032315119964

Epoch: 6| Step: 6
Training loss: 2.618770473646008
Validation loss: 2.457308852095353

Epoch: 6| Step: 7
Training loss: 2.0522799583253133
Validation loss: 2.45558864047152

Epoch: 6| Step: 8
Training loss: 2.5429040575368553
Validation loss: 2.457972287211929

Epoch: 6| Step: 9
Training loss: 2.4724543339877454
Validation loss: 2.46086098688255

Epoch: 6| Step: 10
Training loss: 2.3384201482679368
Validation loss: 2.4585964633186044

Epoch: 6| Step: 11
Training loss: 2.9943110248926956
Validation loss: 2.456370723303991

Epoch: 6| Step: 12
Training loss: 2.3834831919828687
Validation loss: 2.4548657147623505

Epoch: 6| Step: 13
Training loss: 2.4869062855745048
Validation loss: 2.4559776420466104

Epoch: 134| Step: 0
Training loss: 2.311478775940267
Validation loss: 2.4587881319508536

Epoch: 6| Step: 1
Training loss: 2.551410871907223
Validation loss: 2.4536819635650384

Epoch: 6| Step: 2
Training loss: 2.577361670111191
Validation loss: 2.4530203082185755

Epoch: 6| Step: 3
Training loss: 2.2756842034990656
Validation loss: 2.456082919636652

Epoch: 6| Step: 4
Training loss: 2.6268407634543456
Validation loss: 2.4639549688284705

Epoch: 6| Step: 5
Training loss: 3.031763406908387
Validation loss: 2.4575036529224112

Epoch: 6| Step: 6
Training loss: 2.6049326469515117
Validation loss: 2.45543993921761

Epoch: 6| Step: 7
Training loss: 1.8157476071900405
Validation loss: 2.461508031841933

Epoch: 6| Step: 8
Training loss: 2.3538934554731314
Validation loss: 2.4653002864783167

Epoch: 6| Step: 9
Training loss: 2.556229338993807
Validation loss: 2.4589541077108215

Epoch: 6| Step: 10
Training loss: 2.8628925304221724
Validation loss: 2.4589306272773896

Epoch: 6| Step: 11
Training loss: 2.2264009115912886
Validation loss: 2.462882251407628

Epoch: 6| Step: 12
Training loss: 2.653752487979249
Validation loss: 2.454938780907653

Epoch: 6| Step: 13
Training loss: 2.523095358692651
Validation loss: 2.4559332451648213

Epoch: 135| Step: 0
Training loss: 2.376439912883534
Validation loss: 2.4584846019002766

Epoch: 6| Step: 1
Training loss: 1.9755023631258197
Validation loss: 2.4578187263799536

Epoch: 6| Step: 2
Training loss: 2.8558529700999338
Validation loss: 2.4572277303875385

Epoch: 6| Step: 3
Training loss: 2.81231459960208
Validation loss: 2.451949605371529

Epoch: 6| Step: 4
Training loss: 2.8738019354309916
Validation loss: 2.450756411659129

Epoch: 6| Step: 5
Training loss: 2.4339598354326366
Validation loss: 2.456490413169548

Epoch: 6| Step: 6
Training loss: 2.3606868911317793
Validation loss: 2.4605589721853875

Epoch: 6| Step: 7
Training loss: 2.0841518574335582
Validation loss: 2.462464939390665

Epoch: 6| Step: 8
Training loss: 2.4284379205149893
Validation loss: 2.4690417185787026

Epoch: 6| Step: 9
Training loss: 3.3134913850335277
Validation loss: 2.463928496063819

Epoch: 6| Step: 10
Training loss: 2.0630121462192115
Validation loss: 2.457988154429073

Epoch: 6| Step: 11
Training loss: 2.6917010451759986
Validation loss: 2.4655066967436583

Epoch: 6| Step: 12
Training loss: 2.4769625656508705
Validation loss: 2.4623906926198345

Epoch: 6| Step: 13
Training loss: 2.100166850046602
Validation loss: 2.4601947450700004

Epoch: 136| Step: 0
Training loss: 2.237099007418791
Validation loss: 2.464122620379099

Epoch: 6| Step: 1
Training loss: 2.8171238507503196
Validation loss: 2.4570747133099164

Epoch: 6| Step: 2
Training loss: 2.6955562757739373
Validation loss: 2.460401607879715

Epoch: 6| Step: 3
Training loss: 2.21714724826097
Validation loss: 2.4634477840758806

Epoch: 6| Step: 4
Training loss: 2.8057673083759496
Validation loss: 2.463136011857432

Epoch: 6| Step: 5
Training loss: 2.2106389898968906
Validation loss: 2.4659788457185376

Epoch: 6| Step: 6
Training loss: 2.2868417637055223
Validation loss: 2.4701727940019866

Epoch: 6| Step: 7
Training loss: 2.348133108547934
Validation loss: 2.4725672347772836

Epoch: 6| Step: 8
Training loss: 3.0350795819628282
Validation loss: 2.467270677520145

Epoch: 6| Step: 9
Training loss: 2.9213073505457343
Validation loss: 2.462755361377494

Epoch: 6| Step: 10
Training loss: 2.4846797732181614
Validation loss: 2.4569249294386046

Epoch: 6| Step: 11
Training loss: 2.219466510111846
Validation loss: 2.4635673317301556

Epoch: 6| Step: 12
Training loss: 2.342774556944032
Validation loss: 2.4597854420412553

Epoch: 6| Step: 13
Training loss: 2.4514531555492836
Validation loss: 2.4597482704187277

Epoch: 137| Step: 0
Training loss: 1.8120136266116
Validation loss: 2.459887810529174

Epoch: 6| Step: 1
Training loss: 2.370847183303291
Validation loss: 2.4522785095046826

Epoch: 6| Step: 2
Training loss: 2.154505812057478
Validation loss: 2.456428102049464

Epoch: 6| Step: 3
Training loss: 2.36752196111433
Validation loss: 2.4566764231668814

Epoch: 6| Step: 4
Training loss: 2.7054132908053368
Validation loss: 2.463872590262565

Epoch: 6| Step: 5
Training loss: 3.0156858764196275
Validation loss: 2.4548605511664854

Epoch: 6| Step: 6
Training loss: 2.9497915355927424
Validation loss: 2.46365259954419

Epoch: 6| Step: 7
Training loss: 2.2022066840273653
Validation loss: 2.4623586597963922

Epoch: 6| Step: 8
Training loss: 2.08986052034013
Validation loss: 2.456255225709075

Epoch: 6| Step: 9
Training loss: 2.730691314052693
Validation loss: 2.467215499735153

Epoch: 6| Step: 10
Training loss: 2.6460247020649654
Validation loss: 2.454748147190595

Epoch: 6| Step: 11
Training loss: 2.019668426872192
Validation loss: 2.460757342813503

Epoch: 6| Step: 12
Training loss: 3.0231220563803634
Validation loss: 2.4513849943404438

Epoch: 6| Step: 13
Training loss: 2.5552246275697303
Validation loss: 2.4481698791270223

Epoch: 138| Step: 0
Training loss: 2.7723788967806064
Validation loss: 2.458625474370977

Epoch: 6| Step: 1
Training loss: 3.156297135709298
Validation loss: 2.452741013783373

Epoch: 6| Step: 2
Training loss: 2.467239787131727
Validation loss: 2.4616707814396808

Epoch: 6| Step: 3
Training loss: 2.338439214171286
Validation loss: 2.4658659252820256

Epoch: 6| Step: 4
Training loss: 2.190410965981073
Validation loss: 2.4572055190831503

Epoch: 6| Step: 5
Training loss: 2.3403758875213523
Validation loss: 2.455832766750837

Epoch: 6| Step: 6
Training loss: 2.7100082695753884
Validation loss: 2.4563284203821065

Epoch: 6| Step: 7
Training loss: 2.4765645216683883
Validation loss: 2.4519754619957452

Epoch: 6| Step: 8
Training loss: 2.404547150737966
Validation loss: 2.453027322367406

Epoch: 6| Step: 9
Training loss: 2.186035101717807
Validation loss: 2.449603685775831

Epoch: 6| Step: 10
Training loss: 2.161998770072086
Validation loss: 2.449565435003393

Epoch: 6| Step: 11
Training loss: 2.2431240983325065
Validation loss: 2.45273186840017

Epoch: 6| Step: 12
Training loss: 2.948922532723419
Validation loss: 2.450486621084107

Epoch: 6| Step: 13
Training loss: 2.4944035832835088
Validation loss: 2.4501042648758062

Epoch: 139| Step: 0
Training loss: 2.4186003172934574
Validation loss: 2.4527753511932606

Epoch: 6| Step: 1
Training loss: 2.3141928997299783
Validation loss: 2.457108699061087

Epoch: 6| Step: 2
Training loss: 1.6139799733957993
Validation loss: 2.453815354966574

Epoch: 6| Step: 3
Training loss: 2.7748474835247667
Validation loss: 2.460302943207844

Epoch: 6| Step: 4
Training loss: 2.405237951105967
Validation loss: 2.463725227684304

Epoch: 6| Step: 5
Training loss: 2.105507929902735
Validation loss: 2.45571780210571

Epoch: 6| Step: 6
Training loss: 3.0541239264925095
Validation loss: 2.4555597715451896

Epoch: 6| Step: 7
Training loss: 2.789048053265937
Validation loss: 2.463228207109955

Epoch: 6| Step: 8
Training loss: 2.5666113645202255
Validation loss: 2.461549583892881

Epoch: 6| Step: 9
Training loss: 2.8157992191587002
Validation loss: 2.4634733909732294

Epoch: 6| Step: 10
Training loss: 2.8298395344562355
Validation loss: 2.464971217644481

Epoch: 6| Step: 11
Training loss: 2.5861933371309007
Validation loss: 2.461495424029653

Epoch: 6| Step: 12
Training loss: 2.4044858732706875
Validation loss: 2.462477397008135

Epoch: 6| Step: 13
Training loss: 1.9214004302838263
Validation loss: 2.4554479983475748

Epoch: 140| Step: 0
Training loss: 2.682893397911685
Validation loss: 2.4511862867116587

Epoch: 6| Step: 1
Training loss: 1.7188493179756257
Validation loss: 2.462987588803421

Epoch: 6| Step: 2
Training loss: 2.654257352308769
Validation loss: 2.4633537823013696

Epoch: 6| Step: 3
Training loss: 2.4631934104620674
Validation loss: 2.45473605503921

Epoch: 6| Step: 4
Training loss: 2.566451863387221
Validation loss: 2.4612850044774546

Epoch: 6| Step: 5
Training loss: 3.0717639549884064
Validation loss: 2.467107202094136

Epoch: 6| Step: 6
Training loss: 2.6186981851554645
Validation loss: 2.456184949005388

Epoch: 6| Step: 7
Training loss: 2.9352884286701473
Validation loss: 2.4613661781222556

Epoch: 6| Step: 8
Training loss: 2.198509196703139
Validation loss: 2.4568208848001998

Epoch: 6| Step: 9
Training loss: 1.7270454663342376
Validation loss: 2.4605426935859964

Epoch: 6| Step: 10
Training loss: 2.218020251980536
Validation loss: 2.452916664947342

Epoch: 6| Step: 11
Training loss: 3.0460877012675582
Validation loss: 2.4674049930647013

Epoch: 6| Step: 12
Training loss: 2.173913232554552
Validation loss: 2.463901023113309

Epoch: 6| Step: 13
Training loss: 2.660871815612754
Validation loss: 2.465331410703671

Epoch: 141| Step: 0
Training loss: 2.298612599085864
Validation loss: 2.466945568203251

Epoch: 6| Step: 1
Training loss: 2.5793128773829657
Validation loss: 2.4677691865317564

Epoch: 6| Step: 2
Training loss: 2.853657493746187
Validation loss: 2.4623883204300685

Epoch: 6| Step: 3
Training loss: 2.4944931414447393
Validation loss: 2.4707185807580228

Epoch: 6| Step: 4
Training loss: 2.1523517255410307
Validation loss: 2.4649186241356817

Epoch: 6| Step: 5
Training loss: 1.8768252072126896
Validation loss: 2.4640078812510295

Epoch: 6| Step: 6
Training loss: 2.8006571339196276
Validation loss: 2.4655949595998075

Epoch: 6| Step: 7
Training loss: 2.668052928931431
Validation loss: 2.461461611850625

Epoch: 6| Step: 8
Training loss: 2.3111531227319984
Validation loss: 2.466002339609753

Epoch: 6| Step: 9
Training loss: 2.398153580253446
Validation loss: 2.468123569766638

Epoch: 6| Step: 10
Training loss: 2.361347813677999
Validation loss: 2.4741328663078823

Epoch: 6| Step: 11
Training loss: 2.431587482162763
Validation loss: 2.4651194406682735

Epoch: 6| Step: 12
Training loss: 2.532233906480384
Validation loss: 2.4669446098043037

Epoch: 6| Step: 13
Training loss: 3.0495731242641773
Validation loss: 2.467496062574817

Epoch: 142| Step: 0
Training loss: 2.8660164502264722
Validation loss: 2.465593879803074

Epoch: 6| Step: 1
Training loss: 2.782633833635591
Validation loss: 2.4640763544641784

Epoch: 6| Step: 2
Training loss: 2.271606337076689
Validation loss: 2.4627359186883298

Epoch: 6| Step: 3
Training loss: 2.171633919707828
Validation loss: 2.4609386625741303

Epoch: 6| Step: 4
Training loss: 1.4820984901051442
Validation loss: 2.46120058298429

Epoch: 6| Step: 5
Training loss: 2.2706462071397313
Validation loss: 2.4558242396494925

Epoch: 6| Step: 6
Training loss: 2.4783958604523164
Validation loss: 2.4592916485025125

Epoch: 6| Step: 7
Training loss: 2.874296351030945
Validation loss: 2.4655782065808247

Epoch: 6| Step: 8
Training loss: 1.801726451073606
Validation loss: 2.466926706199224

Epoch: 6| Step: 9
Training loss: 2.751649102013033
Validation loss: 2.4685239567667203

Epoch: 6| Step: 10
Training loss: 3.0736758226501606
Validation loss: 2.4680445906677524

Epoch: 6| Step: 11
Training loss: 2.616048080883247
Validation loss: 2.462843158132416

Epoch: 6| Step: 12
Training loss: 2.6548828196843046
Validation loss: 2.4651962326484833

Epoch: 6| Step: 13
Training loss: 2.362299035622631
Validation loss: 2.467387004224577

Epoch: 143| Step: 0
Training loss: 2.9220597315850974
Validation loss: 2.4666866258724425

Epoch: 6| Step: 1
Training loss: 2.2823669625459426
Validation loss: 2.472701407246702

Epoch: 6| Step: 2
Training loss: 2.4880827101424434
Validation loss: 2.470113868456776

Epoch: 6| Step: 3
Training loss: 2.098366956171266
Validation loss: 2.4655228539256484

Epoch: 6| Step: 4
Training loss: 2.024949617112303
Validation loss: 2.4730223052791174

Epoch: 6| Step: 5
Training loss: 3.0366625098302245
Validation loss: 2.472237887553137

Epoch: 6| Step: 6
Training loss: 3.041287350627111
Validation loss: 2.466684273923288

Epoch: 6| Step: 7
Training loss: 2.5737617330112337
Validation loss: 2.4648545834746076

Epoch: 6| Step: 8
Training loss: 2.926051943471119
Validation loss: 2.459391008104432

Epoch: 6| Step: 9
Training loss: 2.1371134893746953
Validation loss: 2.4689197401451515

Epoch: 6| Step: 10
Training loss: 2.553024450631059
Validation loss: 2.4748525562744246

Epoch: 6| Step: 11
Training loss: 1.9024254000019638
Validation loss: 2.4636727769304776

Epoch: 6| Step: 12
Training loss: 2.274814149580272
Validation loss: 2.4715944795705633

Epoch: 6| Step: 13
Training loss: 2.806794546601346
Validation loss: 2.462511429219582

Epoch: 144| Step: 0
Training loss: 1.7722911742909873
Validation loss: 2.4624066685322092

Epoch: 6| Step: 1
Training loss: 2.3471240362313788
Validation loss: 2.4611585568240844

Epoch: 6| Step: 2
Training loss: 3.011352675141527
Validation loss: 2.464117202038713

Epoch: 6| Step: 3
Training loss: 2.484855365496947
Validation loss: 2.4695581811411733

Epoch: 6| Step: 4
Training loss: 2.493663195483168
Validation loss: 2.46963994367152

Epoch: 6| Step: 5
Training loss: 2.5769560042072177
Validation loss: 2.4724545750625393

Epoch: 6| Step: 6
Training loss: 2.21507829773166
Validation loss: 2.4664616421172716

Epoch: 6| Step: 7
Training loss: 2.7512332578476357
Validation loss: 2.4683117376907227

Epoch: 6| Step: 8
Training loss: 2.932912938019462
Validation loss: 2.4663224497750584

Epoch: 6| Step: 9
Training loss: 2.5955769183130357
Validation loss: 2.46632952276249

Epoch: 6| Step: 10
Training loss: 2.26579336658887
Validation loss: 2.465786841640615

Epoch: 6| Step: 11
Training loss: 2.3822564148445724
Validation loss: 2.467391618205476

Epoch: 6| Step: 12
Training loss: 2.9727223372663687
Validation loss: 2.46600660973741

Epoch: 6| Step: 13
Training loss: 1.6341389647915503
Validation loss: 2.4725102466387643

Epoch: 145| Step: 0
Training loss: 2.6164724711218867
Validation loss: 2.4735403464055774

Epoch: 6| Step: 1
Training loss: 2.6867365972664348
Validation loss: 2.4786813458611143

Epoch: 6| Step: 2
Training loss: 2.2709622361114326
Validation loss: 2.478171546886932

Epoch: 6| Step: 3
Training loss: 1.8761225836666675
Validation loss: 2.4669510930840395

Epoch: 6| Step: 4
Training loss: 2.7223479918752465
Validation loss: 2.475388835456662

Epoch: 6| Step: 5
Training loss: 2.3936377596125866
Validation loss: 2.474504692916444

Epoch: 6| Step: 6
Training loss: 2.055530795672794
Validation loss: 2.473872596192019

Epoch: 6| Step: 7
Training loss: 2.8523794179800506
Validation loss: 2.4730683877664323

Epoch: 6| Step: 8
Training loss: 3.2362612324295403
Validation loss: 2.4745961675414407

Epoch: 6| Step: 9
Training loss: 2.5129346025657853
Validation loss: 2.475235624689195

Epoch: 6| Step: 10
Training loss: 2.656613672829574
Validation loss: 2.475103596404064

Epoch: 6| Step: 11
Training loss: 2.40270794844789
Validation loss: 2.4808646619529493

Epoch: 6| Step: 12
Training loss: 2.162648754846894
Validation loss: 2.4774051520305957

Epoch: 6| Step: 13
Training loss: 2.1519097030726506
Validation loss: 2.4802791893482787

Epoch: 146| Step: 0
Training loss: 2.578264267367729
Validation loss: 2.475273928270113

Epoch: 6| Step: 1
Training loss: 1.71543759293479
Validation loss: 2.4845079110538393

Epoch: 6| Step: 2
Training loss: 3.0125262690621555
Validation loss: 2.472675052227832

Epoch: 6| Step: 3
Training loss: 2.851049256840225
Validation loss: 2.475137422901549

Epoch: 6| Step: 4
Training loss: 2.7668540508131207
Validation loss: 2.479371204006301

Epoch: 6| Step: 5
Training loss: 2.1913599019580667
Validation loss: 2.473807775366655

Epoch: 6| Step: 6
Training loss: 2.7833992872209423
Validation loss: 2.484111795938063

Epoch: 6| Step: 7
Training loss: 2.0930935414166556
Validation loss: 2.4776595260169607

Epoch: 6| Step: 8
Training loss: 2.473270960567153
Validation loss: 2.481879126209834

Epoch: 6| Step: 9
Training loss: 1.8413666660616665
Validation loss: 2.4830233657819094

Epoch: 6| Step: 10
Training loss: 1.9480995527556848
Validation loss: 2.4802226748019143

Epoch: 6| Step: 11
Training loss: 2.7872229742090933
Validation loss: 2.4829042027644945

Epoch: 6| Step: 12
Training loss: 3.123209325824947
Validation loss: 2.4852896552129353

Epoch: 6| Step: 13
Training loss: 2.23555655016581
Validation loss: 2.475795005181524

Epoch: 147| Step: 0
Training loss: 2.5013436521339
Validation loss: 2.4760022417160017

Epoch: 6| Step: 1
Training loss: 2.7755110605136655
Validation loss: 2.4850606232174863

Epoch: 6| Step: 2
Training loss: 2.6754249948172846
Validation loss: 2.486938721226394

Epoch: 6| Step: 3
Training loss: 2.2577432272028783
Validation loss: 2.4948501633148576

Epoch: 6| Step: 4
Training loss: 2.685037593755963
Validation loss: 2.5026621790317116

Epoch: 6| Step: 5
Training loss: 2.6454626609692067
Validation loss: 2.4815568434746837

Epoch: 6| Step: 6
Training loss: 3.115171311077977
Validation loss: 2.494029768290185

Epoch: 6| Step: 7
Training loss: 2.904077517775317
Validation loss: 2.4818713290244148

Epoch: 6| Step: 8
Training loss: 2.7968171182961856
Validation loss: 2.4769105395939786

Epoch: 6| Step: 9
Training loss: 2.1435252124610753
Validation loss: 2.470831496531258

Epoch: 6| Step: 10
Training loss: 2.3744055355364804
Validation loss: 2.473359524720146

Epoch: 6| Step: 11
Training loss: 1.9389149821048912
Validation loss: 2.485762554528966

Epoch: 6| Step: 12
Training loss: 2.562093190722058
Validation loss: 2.4773039084087585

Epoch: 6| Step: 13
Training loss: 1.8758599534497944
Validation loss: 2.48103073842489

Epoch: 148| Step: 0
Training loss: 2.2257018450374098
Validation loss: 2.4675731348693097

Epoch: 6| Step: 1
Training loss: 2.02252695223623
Validation loss: 2.4791336511502573

Epoch: 6| Step: 2
Training loss: 1.8848659350330716
Validation loss: 2.47442223198284

Epoch: 6| Step: 3
Training loss: 3.256553058835708
Validation loss: 2.4805399886987614

Epoch: 6| Step: 4
Training loss: 2.718458664291302
Validation loss: 2.4829706185280056

Epoch: 6| Step: 5
Training loss: 1.9307303757342607
Validation loss: 2.4755373817713116

Epoch: 6| Step: 6
Training loss: 2.9306456766438433
Validation loss: 2.4827939006604103

Epoch: 6| Step: 7
Training loss: 2.855362374846144
Validation loss: 2.4756472126677624

Epoch: 6| Step: 8
Training loss: 2.623212841745432
Validation loss: 2.487544415267508

Epoch: 6| Step: 9
Training loss: 2.544591336218721
Validation loss: 2.4875289602207267

Epoch: 6| Step: 10
Training loss: 2.200338563010274
Validation loss: 2.50081630731075

Epoch: 6| Step: 11
Training loss: 2.6068517854654254
Validation loss: 2.503767544321014

Epoch: 6| Step: 12
Training loss: 2.5211282562835526
Validation loss: 2.4976659369497107

Epoch: 6| Step: 13
Training loss: 2.4442360553154443
Validation loss: 2.4955328926624856

Epoch: 149| Step: 0
Training loss: 2.6795010960643055
Validation loss: 2.4916931427364433

Epoch: 6| Step: 1
Training loss: 1.927781372115821
Validation loss: 2.4814683877331687

Epoch: 6| Step: 2
Training loss: 2.6484151743620212
Validation loss: 2.482959015902209

Epoch: 6| Step: 3
Training loss: 2.4809986900070897
Validation loss: 2.47946109679618

Epoch: 6| Step: 4
Training loss: 2.3454372182236956
Validation loss: 2.4754945074750014

Epoch: 6| Step: 5
Training loss: 2.7853149540052686
Validation loss: 2.474883335587781

Epoch: 6| Step: 6
Training loss: 1.7891507855749775
Validation loss: 2.4745133322865773

Epoch: 6| Step: 7
Training loss: 2.1172212830272867
Validation loss: 2.4725697900522188

Epoch: 6| Step: 8
Training loss: 2.5485719983260933
Validation loss: 2.4803051992248615

Epoch: 6| Step: 9
Training loss: 3.0170174185781407
Validation loss: 2.4790183004227235

Epoch: 6| Step: 10
Training loss: 2.500113007852339
Validation loss: 2.472122801759197

Epoch: 6| Step: 11
Training loss: 2.7311012070409597
Validation loss: 2.4739292879240007

Epoch: 6| Step: 12
Training loss: 2.3798823115959156
Validation loss: 2.479095767847967

Epoch: 6| Step: 13
Training loss: 2.595258435002554
Validation loss: 2.473895525218691

Epoch: 150| Step: 0
Training loss: 2.475619645049119
Validation loss: 2.472166538206718

Epoch: 6| Step: 1
Training loss: 2.4523991768398345
Validation loss: 2.4765809035394595

Epoch: 6| Step: 2
Training loss: 2.611617078750583
Validation loss: 2.4799455065790466

Epoch: 6| Step: 3
Training loss: 1.981464684825519
Validation loss: 2.48067757435859

Epoch: 6| Step: 4
Training loss: 2.531279481315826
Validation loss: 2.480040369564064

Epoch: 6| Step: 5
Training loss: 2.247979316392277
Validation loss: 2.4761610217141663

Epoch: 6| Step: 6
Training loss: 2.207803290713056
Validation loss: 2.47632619410316

Epoch: 6| Step: 7
Training loss: 2.3808556698276644
Validation loss: 2.475459273268671

Epoch: 6| Step: 8
Training loss: 2.6552569159793102
Validation loss: 2.473049781342488

Epoch: 6| Step: 9
Training loss: 3.134737027712238
Validation loss: 2.472864496783623

Epoch: 6| Step: 10
Training loss: 2.10622198612589
Validation loss: 2.477147110571703

Epoch: 6| Step: 11
Training loss: 3.0355568404200404
Validation loss: 2.482669260747717

Epoch: 6| Step: 12
Training loss: 2.2667404059962997
Validation loss: 2.4853508270402482

Epoch: 6| Step: 13
Training loss: 2.336929161829615
Validation loss: 2.489612823907542

Epoch: 151| Step: 0
Training loss: 2.321386634531702
Validation loss: 2.48689338309783

Epoch: 6| Step: 1
Training loss: 2.1033872035645023
Validation loss: 2.4898283663608503

Epoch: 6| Step: 2
Training loss: 1.9795408464049054
Validation loss: 2.486146842858415

Epoch: 6| Step: 3
Training loss: 2.3924948167894238
Validation loss: 2.4836567414247175

Epoch: 6| Step: 4
Training loss: 2.8961499999279248
Validation loss: 2.49963113129802

Epoch: 6| Step: 5
Training loss: 2.348988489830038
Validation loss: 2.4875689913896295

Epoch: 6| Step: 6
Training loss: 2.2833378265039643
Validation loss: 2.4739687119651066

Epoch: 6| Step: 7
Training loss: 2.6724905453863523
Validation loss: 2.472085044093408

Epoch: 6| Step: 8
Training loss: 2.5914925552546797
Validation loss: 2.4742321839935

Epoch: 6| Step: 9
Training loss: 2.551160705289627
Validation loss: 2.481195954984174

Epoch: 6| Step: 10
Training loss: 2.524193806880689
Validation loss: 2.479404523536039

Epoch: 6| Step: 11
Training loss: 2.469056315673221
Validation loss: 2.4740633704658683

Epoch: 6| Step: 12
Training loss: 2.4880752358422416
Validation loss: 2.4762382415384474

Epoch: 6| Step: 13
Training loss: 2.9234699649119347
Validation loss: 2.4716797357300715

Epoch: 152| Step: 0
Training loss: 2.105487887095601
Validation loss: 2.4754528845069332

Epoch: 6| Step: 1
Training loss: 2.677449796261178
Validation loss: 2.4816183635126103

Epoch: 6| Step: 2
Training loss: 2.353923233634383
Validation loss: 2.4700769809613634

Epoch: 6| Step: 3
Training loss: 2.514382191609095
Validation loss: 2.481432902067262

Epoch: 6| Step: 4
Training loss: 1.8385836746848778
Validation loss: 2.495941284808541

Epoch: 6| Step: 5
Training loss: 2.422584971068532
Validation loss: 2.50119139575187

Epoch: 6| Step: 6
Training loss: 2.3408177661842116
Validation loss: 2.4984531544442845

Epoch: 6| Step: 7
Training loss: 3.0182847069190615
Validation loss: 2.5040162409975792

Epoch: 6| Step: 8
Training loss: 2.8394404023867192
Validation loss: 2.495937925597973

Epoch: 6| Step: 9
Training loss: 2.542543999845411
Validation loss: 2.5098513260791364

Epoch: 6| Step: 10
Training loss: 2.616267620524902
Validation loss: 2.501168073525877

Epoch: 6| Step: 11
Training loss: 2.558600272832811
Validation loss: 2.4856695644983655

Epoch: 6| Step: 12
Training loss: 2.3391389374357243
Validation loss: 2.4919151547981255

Epoch: 6| Step: 13
Training loss: 2.4854718552052804
Validation loss: 2.4803084354207923

Epoch: 153| Step: 0
Training loss: 2.720929204197149
Validation loss: 2.4822425007136473

Epoch: 6| Step: 1
Training loss: 2.001542331138321
Validation loss: 2.484563440497745

Epoch: 6| Step: 2
Training loss: 2.752716543357218
Validation loss: 2.487234265623951

Epoch: 6| Step: 3
Training loss: 1.6342111830003216
Validation loss: 2.486486037864021

Epoch: 6| Step: 4
Training loss: 2.160786486773869
Validation loss: 2.485101173843488

Epoch: 6| Step: 5
Training loss: 2.6300820701180867
Validation loss: 2.4838318780907027

Epoch: 6| Step: 6
Training loss: 2.0232291685102175
Validation loss: 2.481082461872148

Epoch: 6| Step: 7
Training loss: 2.6538078301085606
Validation loss: 2.494653834687992

Epoch: 6| Step: 8
Training loss: 2.720217955215529
Validation loss: 2.480298406403828

Epoch: 6| Step: 9
Training loss: 3.1987796244529614
Validation loss: 2.481313518540712

Epoch: 6| Step: 10
Training loss: 2.5965852982092588
Validation loss: 2.4853503473924667

Epoch: 6| Step: 11
Training loss: 2.254734462320331
Validation loss: 2.4897644317603986

Epoch: 6| Step: 12
Training loss: 2.4576166907980506
Validation loss: 2.4927843549087267

Epoch: 6| Step: 13
Training loss: 2.2357165170760274
Validation loss: 2.5088797305779695

Epoch: 154| Step: 0
Training loss: 1.900363651409613
Validation loss: 2.5109186475228435

Epoch: 6| Step: 1
Training loss: 2.17295448316643
Validation loss: 2.5285838021639377

Epoch: 6| Step: 2
Training loss: 2.4125644022987776
Validation loss: 2.5330977112801194

Epoch: 6| Step: 3
Training loss: 2.807542033640886
Validation loss: 2.5146997144094403

Epoch: 6| Step: 4
Training loss: 2.308659741383116
Validation loss: 2.5108481124795783

Epoch: 6| Step: 5
Training loss: 2.25259948612381
Validation loss: 2.4928138926295205

Epoch: 6| Step: 6
Training loss: 3.085086753528081
Validation loss: 2.487887620357584

Epoch: 6| Step: 7
Training loss: 2.6346023769153937
Validation loss: 2.480188613251387

Epoch: 6| Step: 8
Training loss: 2.258523690434507
Validation loss: 2.4788905291815726

Epoch: 6| Step: 9
Training loss: 3.0082615901039307
Validation loss: 2.4881114811974396

Epoch: 6| Step: 10
Training loss: 2.4340473076917677
Validation loss: 2.486307428258361

Epoch: 6| Step: 11
Training loss: 2.1790720299715196
Validation loss: 2.4817403982937485

Epoch: 6| Step: 12
Training loss: 2.407494755597607
Validation loss: 2.4833181760525944

Epoch: 6| Step: 13
Training loss: 2.6098535521480257
Validation loss: 2.490288675750906

Epoch: 155| Step: 0
Training loss: 1.8114898760789349
Validation loss: 2.5030468493964384

Epoch: 6| Step: 1
Training loss: 2.6309511753483092
Validation loss: 2.487342709371903

Epoch: 6| Step: 2
Training loss: 2.058775341848431
Validation loss: 2.5150634423173557

Epoch: 6| Step: 3
Training loss: 2.449139704790052
Validation loss: 2.4943484162771776

Epoch: 6| Step: 4
Training loss: 1.6826715266862338
Validation loss: 2.5021213749882185

Epoch: 6| Step: 5
Training loss: 2.632415017026931
Validation loss: 2.5114902058154156

Epoch: 6| Step: 6
Training loss: 2.7232188186786455
Validation loss: 2.5152690311782773

Epoch: 6| Step: 7
Training loss: 2.22414162183515
Validation loss: 2.5057925668573353

Epoch: 6| Step: 8
Training loss: 2.442420882912507
Validation loss: 2.486761566282476

Epoch: 6| Step: 9
Training loss: 3.0737256208386112
Validation loss: 2.4863765818710224

Epoch: 6| Step: 10
Training loss: 2.909360799949402
Validation loss: 2.485762362701643

Epoch: 6| Step: 11
Training loss: 2.2138376793495524
Validation loss: 2.484934617838393

Epoch: 6| Step: 12
Training loss: 2.1879340694822416
Validation loss: 2.475451937427785

Epoch: 6| Step: 13
Training loss: 3.001368846136963
Validation loss: 2.483234903659197

Epoch: 156| Step: 0
Training loss: 2.561476805564625
Validation loss: 2.490935821475209

Epoch: 6| Step: 1
Training loss: 2.8079816339549692
Validation loss: 2.4802213610537

Epoch: 6| Step: 2
Training loss: 2.2380728899256424
Validation loss: 2.485035726468239

Epoch: 6| Step: 3
Training loss: 2.097051607929471
Validation loss: 2.483188321746201

Epoch: 6| Step: 4
Training loss: 1.8168328553341944
Validation loss: 2.47747890072078

Epoch: 6| Step: 5
Training loss: 2.5259724925424374
Validation loss: 2.4803685606098935

Epoch: 6| Step: 6
Training loss: 2.7726556239983267
Validation loss: 2.480486211439934

Epoch: 6| Step: 7
Training loss: 2.2736952592951223
Validation loss: 2.4803544786619347

Epoch: 6| Step: 8
Training loss: 1.9848901875866973
Validation loss: 2.4891369684178395

Epoch: 6| Step: 9
Training loss: 2.780160754928065
Validation loss: 2.5014873927808545

Epoch: 6| Step: 10
Training loss: 2.3288569995748976
Validation loss: 2.4952830638355543

Epoch: 6| Step: 11
Training loss: 2.996873179764339
Validation loss: 2.512597436106864

Epoch: 6| Step: 12
Training loss: 2.573364486538705
Validation loss: 2.505182727410571

Epoch: 6| Step: 13
Training loss: 2.220841402632014
Validation loss: 2.4936430854792313

Epoch: 157| Step: 0
Training loss: 2.2414524056331757
Validation loss: 2.4908558188536274

Epoch: 6| Step: 1
Training loss: 3.1384863712585536
Validation loss: 2.4939734538071936

Epoch: 6| Step: 2
Training loss: 2.7428650630257563
Validation loss: 2.4984616791948993

Epoch: 6| Step: 3
Training loss: 2.826536375212888
Validation loss: 2.4849342980196574

Epoch: 6| Step: 4
Training loss: 2.0549418360885623
Validation loss: 2.478988950968652

Epoch: 6| Step: 5
Training loss: 2.2294707996948278
Validation loss: 2.4814037092820507

Epoch: 6| Step: 6
Training loss: 2.690309697018011
Validation loss: 2.486230353355617

Epoch: 6| Step: 7
Training loss: 2.015657173313962
Validation loss: 2.4822317191145014

Epoch: 6| Step: 8
Training loss: 2.556086725742658
Validation loss: 2.472687104862782

Epoch: 6| Step: 9
Training loss: 2.2917443926952665
Validation loss: 2.4767901519532374

Epoch: 6| Step: 10
Training loss: 2.2560288931166523
Validation loss: 2.4788258716348945

Epoch: 6| Step: 11
Training loss: 2.3598240305065237
Validation loss: 2.483457367848242

Epoch: 6| Step: 12
Training loss: 2.857460089510783
Validation loss: 2.4859432652772444

Epoch: 6| Step: 13
Training loss: 2.3424677074897584
Validation loss: 2.483922809258397

Epoch: 158| Step: 0
Training loss: 2.734125965222007
Validation loss: 2.491742962420787

Epoch: 6| Step: 1
Training loss: 2.7688490184704837
Validation loss: 2.4981807606250923

Epoch: 6| Step: 2
Training loss: 2.5993188112408805
Validation loss: 2.5034261750107274

Epoch: 6| Step: 3
Training loss: 2.30045273512847
Validation loss: 2.5096180438278597

Epoch: 6| Step: 4
Training loss: 2.271792206442779
Validation loss: 2.502239051142659

Epoch: 6| Step: 5
Training loss: 2.336826933381492
Validation loss: 2.499311272801664

Epoch: 6| Step: 6
Training loss: 2.3825039022759964
Validation loss: 2.497831262226671

Epoch: 6| Step: 7
Training loss: 2.011416751452185
Validation loss: 2.497219128501295

Epoch: 6| Step: 8
Training loss: 2.0083835843501627
Validation loss: 2.4980975064656086

Epoch: 6| Step: 9
Training loss: 2.652329817048502
Validation loss: 2.505090601025665

Epoch: 6| Step: 10
Training loss: 2.025022850378648
Validation loss: 2.492398387632184

Epoch: 6| Step: 11
Training loss: 2.7323686486841434
Validation loss: 2.501520663945473

Epoch: 6| Step: 12
Training loss: 2.8972259210173013
Validation loss: 2.501324334642183

Epoch: 6| Step: 13
Training loss: 2.3119052431428684
Validation loss: 2.5070073706025666

Epoch: 159| Step: 0
Training loss: 2.636984578613739
Validation loss: 2.5069393170821805

Epoch: 6| Step: 1
Training loss: 2.6993353414128434
Validation loss: 2.5047291372054565

Epoch: 6| Step: 2
Training loss: 1.965386560287788
Validation loss: 2.506617291966936

Epoch: 6| Step: 3
Training loss: 2.1371021101194834
Validation loss: 2.513513251306183

Epoch: 6| Step: 4
Training loss: 2.4361000931694967
Validation loss: 2.516066344662559

Epoch: 6| Step: 5
Training loss: 2.713663978285122
Validation loss: 2.5138153137999097

Epoch: 6| Step: 6
Training loss: 2.1775790171952774
Validation loss: 2.5099576052850714

Epoch: 6| Step: 7
Training loss: 3.256155347272124
Validation loss: 2.5030941094926424

Epoch: 6| Step: 8
Training loss: 3.1072041203264287
Validation loss: 2.5038943635099997

Epoch: 6| Step: 9
Training loss: 2.7672238658236497
Validation loss: 2.4897615749338917

Epoch: 6| Step: 10
Training loss: 2.1403107795368665
Validation loss: 2.499275658895542

Epoch: 6| Step: 11
Training loss: 1.8984131360158565
Validation loss: 2.4939719322071134

Epoch: 6| Step: 12
Training loss: 2.0584899760371225
Validation loss: 2.4929583083949938

Epoch: 6| Step: 13
Training loss: 1.922732216311965
Validation loss: 2.4920863785751948

Epoch: 160| Step: 0
Training loss: 2.3390602494039774
Validation loss: 2.4818449913278644

Epoch: 6| Step: 1
Training loss: 2.7696824133420725
Validation loss: 2.483890958132112

Epoch: 6| Step: 2
Training loss: 1.896183323954681
Validation loss: 2.487222363363082

Epoch: 6| Step: 3
Training loss: 2.22532421278794
Validation loss: 2.4721565404541543

Epoch: 6| Step: 4
Training loss: 2.8900088091653324
Validation loss: 2.487706316086781

Epoch: 6| Step: 5
Training loss: 2.6670280350769606
Validation loss: 2.4937637749389485

Epoch: 6| Step: 6
Training loss: 2.294073043651434
Validation loss: 2.4917130850824036

Epoch: 6| Step: 7
Training loss: 2.8239775537511935
Validation loss: 2.482538596189685

Epoch: 6| Step: 8
Training loss: 2.373679145129138
Validation loss: 2.4779355227241155

Epoch: 6| Step: 9
Training loss: 2.2830122320488275
Validation loss: 2.4708764780618795

Epoch: 6| Step: 10
Training loss: 1.7785791819321928
Validation loss: 2.4702993432405806

Epoch: 6| Step: 11
Training loss: 2.21372610483138
Validation loss: 2.4740261403211057

Epoch: 6| Step: 12
Training loss: 2.8024915849217336
Validation loss: 2.474936431813377

Epoch: 6| Step: 13
Training loss: 2.661885286388778
Validation loss: 2.4674583307346745

Epoch: 161| Step: 0
Training loss: 2.3219430248620587
Validation loss: 2.4610169735947975

Epoch: 6| Step: 1
Training loss: 2.7302439846800044
Validation loss: 2.471061139811684

Epoch: 6| Step: 2
Training loss: 2.857338769190476
Validation loss: 2.4727068871269355

Epoch: 6| Step: 3
Training loss: 2.625871604447642
Validation loss: 2.466772397992861

Epoch: 6| Step: 4
Training loss: 2.634084513114377
Validation loss: 2.476609912502707

Epoch: 6| Step: 5
Training loss: 2.4608233712995102
Validation loss: 2.4751561340379524

Epoch: 6| Step: 6
Training loss: 2.8416290758020053
Validation loss: 2.4784338266007726

Epoch: 6| Step: 7
Training loss: 2.171812427085918
Validation loss: 2.473797422831231

Epoch: 6| Step: 8
Training loss: 2.4384214175783048
Validation loss: 2.4814002503225927

Epoch: 6| Step: 9
Training loss: 2.1259330496236077
Validation loss: 2.492508503839748

Epoch: 6| Step: 10
Training loss: 2.0337334343458875
Validation loss: 2.492598193857593

Epoch: 6| Step: 11
Training loss: 1.9283833285845662
Validation loss: 2.5033303648435394

Epoch: 6| Step: 12
Training loss: 2.2163782472290325
Validation loss: 2.495356188610415

Epoch: 6| Step: 13
Training loss: 2.8015351923363245
Validation loss: 2.499631854607661

Epoch: 162| Step: 0
Training loss: 2.723467625217735
Validation loss: 2.5031674823180134

Epoch: 6| Step: 1
Training loss: 2.611719597152495
Validation loss: 2.500246449085073

Epoch: 6| Step: 2
Training loss: 2.2746434110426854
Validation loss: 2.503301411546679

Epoch: 6| Step: 3
Training loss: 2.710287318465113
Validation loss: 2.4992689573828146

Epoch: 6| Step: 4
Training loss: 2.7648514350036244
Validation loss: 2.5050556720580217

Epoch: 6| Step: 5
Training loss: 2.505325557850291
Validation loss: 2.5001671417312505

Epoch: 6| Step: 6
Training loss: 2.407937882195664
Validation loss: 2.5024956326695866

Epoch: 6| Step: 7
Training loss: 2.0371062149798718
Validation loss: 2.493960030235185

Epoch: 6| Step: 8
Training loss: 2.131546706859925
Validation loss: 2.503642329660663

Epoch: 6| Step: 9
Training loss: 2.1991753853406695
Validation loss: 2.506964646173191

Epoch: 6| Step: 10
Training loss: 2.060110036818434
Validation loss: 2.506462597411479

Epoch: 6| Step: 11
Training loss: 2.5512455609669398
Validation loss: 2.504311039381323

Epoch: 6| Step: 12
Training loss: 2.554159687358371
Validation loss: 2.494764345108392

Epoch: 6| Step: 13
Training loss: 2.6134916257926633
Validation loss: 2.489580614628498

Epoch: 163| Step: 0
Training loss: 2.367023626012181
Validation loss: 2.493384740366666

Epoch: 6| Step: 1
Training loss: 2.2951429414801536
Validation loss: 2.4938276388755165

Epoch: 6| Step: 2
Training loss: 2.337514287731547
Validation loss: 2.499307393454376

Epoch: 6| Step: 3
Training loss: 2.000660906311271
Validation loss: 2.4969641213233453

Epoch: 6| Step: 4
Training loss: 2.4459333027864205
Validation loss: 2.5070560063001355

Epoch: 6| Step: 5
Training loss: 3.0867155615254984
Validation loss: 2.5105869873856315

Epoch: 6| Step: 6
Training loss: 2.4759915533091195
Validation loss: 2.523634155924953

Epoch: 6| Step: 7
Training loss: 2.7524148568576083
Validation loss: 2.5203458351410766

Epoch: 6| Step: 8
Training loss: 2.238247589870158
Validation loss: 2.509819756504231

Epoch: 6| Step: 9
Training loss: 2.3726275791801132
Validation loss: 2.5189980901388087

Epoch: 6| Step: 10
Training loss: 2.908906112566804
Validation loss: 2.509923131925831

Epoch: 6| Step: 11
Training loss: 1.7040965257805223
Validation loss: 2.5160049878097768

Epoch: 6| Step: 12
Training loss: 2.4713118576003046
Validation loss: 2.5011812280506542

Epoch: 6| Step: 13
Training loss: 2.4151330444461
Validation loss: 2.4973872598627533

Epoch: 164| Step: 0
Training loss: 2.4134485149119835
Validation loss: 2.507360700907097

Epoch: 6| Step: 1
Training loss: 3.1331219223071267
Validation loss: 2.494618297650667

Epoch: 6| Step: 2
Training loss: 3.0287111012365338
Validation loss: 2.4929085926977392

Epoch: 6| Step: 3
Training loss: 2.3927816000850486
Validation loss: 2.4966532876539453

Epoch: 6| Step: 4
Training loss: 2.190378311786043
Validation loss: 2.4949770216817

Epoch: 6| Step: 5
Training loss: 1.6664870960137734
Validation loss: 2.4911323952689597

Epoch: 6| Step: 6
Training loss: 2.75308280159071
Validation loss: 2.481735154516223

Epoch: 6| Step: 7
Training loss: 2.174342229189939
Validation loss: 2.5008906844097836

Epoch: 6| Step: 8
Training loss: 2.4504342842560622
Validation loss: 2.49325167298676

Epoch: 6| Step: 9
Training loss: 1.9946833515557383
Validation loss: 2.493271499273343

Epoch: 6| Step: 10
Training loss: 2.7152044921073553
Validation loss: 2.481980807590592

Epoch: 6| Step: 11
Training loss: 2.397165762760855
Validation loss: 2.4851886208712575

Epoch: 6| Step: 12
Training loss: 2.4510913364507703
Validation loss: 2.4825536741438823

Epoch: 6| Step: 13
Training loss: 1.7984911740775553
Validation loss: 2.496269430824469

Epoch: 165| Step: 0
Training loss: 2.9296723632421466
Validation loss: 2.4997089852390024

Epoch: 6| Step: 1
Training loss: 2.3064906421192863
Validation loss: 2.4983849156301057

Epoch: 6| Step: 2
Training loss: 2.438720690904526
Validation loss: 2.538699377454593

Epoch: 6| Step: 3
Training loss: 2.0619841421795897
Validation loss: 2.547009696597016

Epoch: 6| Step: 4
Training loss: 2.7340492272455434
Validation loss: 2.561993308486161

Epoch: 6| Step: 5
Training loss: 2.337432077002369
Validation loss: 2.540208763194063

Epoch: 6| Step: 6
Training loss: 1.9755805067816483
Validation loss: 2.5095267928069465

Epoch: 6| Step: 7
Training loss: 2.7255310031189155
Validation loss: 2.4901851634230585

Epoch: 6| Step: 8
Training loss: 2.024477893726553
Validation loss: 2.4835519126943346

Epoch: 6| Step: 9
Training loss: 1.9698805212203356
Validation loss: 2.468383037479679

Epoch: 6| Step: 10
Training loss: 3.1023268058196933
Validation loss: 2.4742224515504394

Epoch: 6| Step: 11
Training loss: 2.360951080384192
Validation loss: 2.4834822324195707

Epoch: 6| Step: 12
Training loss: 2.799997217313201
Validation loss: 2.4765428046918485

Epoch: 6| Step: 13
Training loss: 2.37842252977968
Validation loss: 2.476828920813468

Epoch: 166| Step: 0
Training loss: 2.025926392192478
Validation loss: 2.473878715974044

Epoch: 6| Step: 1
Training loss: 2.658497656005607
Validation loss: 2.4760227678214557

Epoch: 6| Step: 2
Training loss: 2.171904748946158
Validation loss: 2.482896296769742

Epoch: 6| Step: 3
Training loss: 2.5514917012266025
Validation loss: 2.4887019529866694

Epoch: 6| Step: 4
Training loss: 1.983331841647231
Validation loss: 2.4891956352010083

Epoch: 6| Step: 5
Training loss: 2.0780242666052042
Validation loss: 2.5076044933216566

Epoch: 6| Step: 6
Training loss: 2.9775515537619257
Validation loss: 2.519991558126408

Epoch: 6| Step: 7
Training loss: 2.779060959604828
Validation loss: 2.534501926365447

Epoch: 6| Step: 8
Training loss: 2.0597425581423408
Validation loss: 2.553487637873038

Epoch: 6| Step: 9
Training loss: 2.5403862422226413
Validation loss: 2.5460415433993875

Epoch: 6| Step: 10
Training loss: 2.370463707060903
Validation loss: 2.5251601788416465

Epoch: 6| Step: 11
Training loss: 2.4921431104001317
Validation loss: 2.521773727759682

Epoch: 6| Step: 12
Training loss: 2.7929327262209163
Validation loss: 2.513652905182888

Epoch: 6| Step: 13
Training loss: 2.55719561632778
Validation loss: 2.4991521351251773

Epoch: 167| Step: 0
Training loss: 2.074110470116897
Validation loss: 2.495867046792943

Epoch: 6| Step: 1
Training loss: 2.6725453210740095
Validation loss: 2.4980070276489847

Epoch: 6| Step: 2
Training loss: 2.1951957481534947
Validation loss: 2.4888309847627927

Epoch: 6| Step: 3
Training loss: 2.0796787505392116
Validation loss: 2.499972247923357

Epoch: 6| Step: 4
Training loss: 2.8189074960763696
Validation loss: 2.5217528807211815

Epoch: 6| Step: 5
Training loss: 2.840426336712852
Validation loss: 2.5132774156156397

Epoch: 6| Step: 6
Training loss: 2.1619108775752354
Validation loss: 2.5076170594619716

Epoch: 6| Step: 7
Training loss: 2.081973649421622
Validation loss: 2.5224573142980335

Epoch: 6| Step: 8
Training loss: 2.1670729427410045
Validation loss: 2.5423311761490397

Epoch: 6| Step: 9
Training loss: 2.87212908495629
Validation loss: 2.5280682224582787

Epoch: 6| Step: 10
Training loss: 2.46198669350667
Validation loss: 2.528882666096725

Epoch: 6| Step: 11
Training loss: 2.4892959322429404
Validation loss: 2.502772907412757

Epoch: 6| Step: 12
Training loss: 2.683657449690905
Validation loss: 2.516995185184635

Epoch: 6| Step: 13
Training loss: 2.205699741808296
Validation loss: 2.5114628575929143

Epoch: 168| Step: 0
Training loss: 2.410440140733245
Validation loss: 2.500751159989055

Epoch: 6| Step: 1
Training loss: 2.017760454120762
Validation loss: 2.508416068549201

Epoch: 6| Step: 2
Training loss: 2.516009946952043
Validation loss: 2.5133931070356836

Epoch: 6| Step: 3
Training loss: 2.4678518858722107
Validation loss: 2.501538979179304

Epoch: 6| Step: 4
Training loss: 2.387946329788464
Validation loss: 2.512363048635691

Epoch: 6| Step: 5
Training loss: 2.595755847082613
Validation loss: 2.5286852083502773

Epoch: 6| Step: 6
Training loss: 1.9848476657980456
Validation loss: 2.5319555264796176

Epoch: 6| Step: 7
Training loss: 1.8234053111238444
Validation loss: 2.532501021444925

Epoch: 6| Step: 8
Training loss: 2.6680307674321067
Validation loss: 2.528033438063042

Epoch: 6| Step: 9
Training loss: 2.5187571674557314
Validation loss: 2.508638493509042

Epoch: 6| Step: 10
Training loss: 2.3471215983334313
Validation loss: 2.505210445559134

Epoch: 6| Step: 11
Training loss: 2.2760642695814055
Validation loss: 2.4895251571902177

Epoch: 6| Step: 12
Training loss: 2.3626130980209057
Validation loss: 2.485200692764481

Epoch: 6| Step: 13
Training loss: 3.167321455333515
Validation loss: 2.4826606017425177

Epoch: 169| Step: 0
Training loss: 2.6191142263653777
Validation loss: 2.482713763716634

Epoch: 6| Step: 1
Training loss: 2.6176025972416403
Validation loss: 2.4908120436496124

Epoch: 6| Step: 2
Training loss: 2.1101115883341732
Validation loss: 2.495481365225235

Epoch: 6| Step: 3
Training loss: 3.284235586007711
Validation loss: 2.4855500167626188

Epoch: 6| Step: 4
Training loss: 2.396904868843748
Validation loss: 2.4992996347417358

Epoch: 6| Step: 5
Training loss: 2.249061918736953
Validation loss: 2.5151798968125676

Epoch: 6| Step: 6
Training loss: 2.431724553019485
Validation loss: 2.5038125848335993

Epoch: 6| Step: 7
Training loss: 2.2176487298436265
Validation loss: 2.508977973728288

Epoch: 6| Step: 8
Training loss: 2.3844900760904064
Validation loss: 2.494291798334968

Epoch: 6| Step: 9
Training loss: 2.573299724362677
Validation loss: 2.4980589642902022

Epoch: 6| Step: 10
Training loss: 2.2137411827975875
Validation loss: 2.4891398898168977

Epoch: 6| Step: 11
Training loss: 2.022405412723143
Validation loss: 2.498987612778705

Epoch: 6| Step: 12
Training loss: 1.8916793279462174
Validation loss: 2.5034207544372666

Epoch: 6| Step: 13
Training loss: 2.99935015951698
Validation loss: 2.500624824961865

Epoch: 170| Step: 0
Training loss: 2.6351743342946485
Validation loss: 2.5084664194364628

Epoch: 6| Step: 1
Training loss: 1.9775256196495254
Validation loss: 2.514275119563586

Epoch: 6| Step: 2
Training loss: 2.694957942032894
Validation loss: 2.509532683134397

Epoch: 6| Step: 3
Training loss: 3.2442085309532076
Validation loss: 2.5077029607346124

Epoch: 6| Step: 4
Training loss: 2.3009047677477095
Validation loss: 2.498995944894648

Epoch: 6| Step: 5
Training loss: 2.13323813861807
Validation loss: 2.4907332654880485

Epoch: 6| Step: 6
Training loss: 2.374897000940395
Validation loss: 2.505407080958448

Epoch: 6| Step: 7
Training loss: 2.084681214769278
Validation loss: 2.5079764751251736

Epoch: 6| Step: 8
Training loss: 2.099021311178787
Validation loss: 2.524606801883174

Epoch: 6| Step: 9
Training loss: 2.543622145380331
Validation loss: 2.521023188816117

Epoch: 6| Step: 10
Training loss: 2.7476589468605703
Validation loss: 2.5123180190649546

Epoch: 6| Step: 11
Training loss: 2.056905383451005
Validation loss: 2.5302427509134793

Epoch: 6| Step: 12
Training loss: 2.9932303341970075
Validation loss: 2.531304221494802

Epoch: 6| Step: 13
Training loss: 2.0339876945971085
Validation loss: 2.5269943223725173

Epoch: 171| Step: 0
Training loss: 2.3772311522125493
Validation loss: 2.516120182686497

Epoch: 6| Step: 1
Training loss: 2.1292527223081206
Validation loss: 2.512101954470588

Epoch: 6| Step: 2
Training loss: 2.4436752151792787
Validation loss: 2.50534558994157

Epoch: 6| Step: 3
Training loss: 2.3412545716036894
Validation loss: 2.509250010999544

Epoch: 6| Step: 4
Training loss: 2.2268194753023733
Validation loss: 2.493123563324731

Epoch: 6| Step: 5
Training loss: 2.5448489877681215
Validation loss: 2.5022326037125877

Epoch: 6| Step: 6
Training loss: 2.5698739927104253
Validation loss: 2.493008070918266

Epoch: 6| Step: 7
Training loss: 2.7816061584797254
Validation loss: 2.4812314680610132

Epoch: 6| Step: 8
Training loss: 2.642871149681414
Validation loss: 2.488964927087521

Epoch: 6| Step: 9
Training loss: 2.5712321297224396
Validation loss: 2.4876364167345706

Epoch: 6| Step: 10
Training loss: 1.913930211069421
Validation loss: 2.4853655042176093

Epoch: 6| Step: 11
Training loss: 2.860134336611117
Validation loss: 2.4893911651972704

Epoch: 6| Step: 12
Training loss: 1.646938709279001
Validation loss: 2.4958263526610844

Epoch: 6| Step: 13
Training loss: 2.450632177263105
Validation loss: 2.536872028450276

Epoch: 172| Step: 0
Training loss: 2.3967351681182825
Validation loss: 2.5380804109042288

Epoch: 6| Step: 1
Training loss: 2.413551844439713
Validation loss: 2.541751443251611

Epoch: 6| Step: 2
Training loss: 2.3685192227234815
Validation loss: 2.541505719910096

Epoch: 6| Step: 3
Training loss: 2.5324463077739305
Validation loss: 2.519958885629498

Epoch: 6| Step: 4
Training loss: 2.602488676517415
Validation loss: 2.516664910052699

Epoch: 6| Step: 5
Training loss: 1.9425729358388237
Validation loss: 2.4952408632407304

Epoch: 6| Step: 6
Training loss: 2.6111101788548456
Validation loss: 2.473985633030229

Epoch: 6| Step: 7
Training loss: 2.938235900902204
Validation loss: 2.4990081249988814

Epoch: 6| Step: 8
Training loss: 2.171406866983344
Validation loss: 2.4959862914259134

Epoch: 6| Step: 9
Training loss: 2.259169965755915
Validation loss: 2.4840968074229894

Epoch: 6| Step: 10
Training loss: 2.7377472926929287
Validation loss: 2.496304562322089

Epoch: 6| Step: 11
Training loss: 2.8234728913867753
Validation loss: 2.4946815662870163

Epoch: 6| Step: 12
Training loss: 2.381066254662864
Validation loss: 2.4897035439383988

Epoch: 6| Step: 13
Training loss: 2.3590156332017873
Validation loss: 2.5043867565641005

Epoch: 173| Step: 0
Training loss: 2.3516014324019707
Validation loss: 2.499435551819201

Epoch: 6| Step: 1
Training loss: 2.611116935732502
Validation loss: 2.500981599106807

Epoch: 6| Step: 2
Training loss: 2.347225613061787
Validation loss: 2.496430471331078

Epoch: 6| Step: 3
Training loss: 2.1210813855676682
Validation loss: 2.504809077456009

Epoch: 6| Step: 4
Training loss: 2.2945499199902253
Validation loss: 2.5194031675444353

Epoch: 6| Step: 5
Training loss: 2.7839685933380474
Validation loss: 2.5121240679378896

Epoch: 6| Step: 6
Training loss: 2.7886701890304733
Validation loss: 2.5197489168836147

Epoch: 6| Step: 7
Training loss: 2.6364134661231473
Validation loss: 2.5152353810356094

Epoch: 6| Step: 8
Training loss: 2.406328769732177
Validation loss: 2.5399873428329736

Epoch: 6| Step: 9
Training loss: 2.093344805781196
Validation loss: 2.516528012917193

Epoch: 6| Step: 10
Training loss: 2.2621403698122657
Validation loss: 2.522573041523166

Epoch: 6| Step: 11
Training loss: 1.8813641307593634
Validation loss: 2.5174280974731063

Epoch: 6| Step: 12
Training loss: 2.329905910474983
Validation loss: 2.5114102250729515

Epoch: 6| Step: 13
Training loss: 2.535477863242966
Validation loss: 2.5271530275936787

Epoch: 174| Step: 0
Training loss: 2.116845585427512
Validation loss: 2.519805238794175

Epoch: 6| Step: 1
Training loss: 3.21928697569772
Validation loss: 2.508687422294561

Epoch: 6| Step: 2
Training loss: 1.873172250634761
Validation loss: 2.5094867318798233

Epoch: 6| Step: 3
Training loss: 2.356928283040552
Validation loss: 2.498908774321907

Epoch: 6| Step: 4
Training loss: 2.6311894063247454
Validation loss: 2.4941522074733915

Epoch: 6| Step: 5
Training loss: 2.257406442420806
Validation loss: 2.4946203524729795

Epoch: 6| Step: 6
Training loss: 2.1990934237991526
Validation loss: 2.497259656729036

Epoch: 6| Step: 7
Training loss: 2.401386349335149
Validation loss: 2.499597270634423

Epoch: 6| Step: 8
Training loss: 2.6895797134560224
Validation loss: 2.4996062604468765

Epoch: 6| Step: 9
Training loss: 1.9290467715923756
Validation loss: 2.514878811946849

Epoch: 6| Step: 10
Training loss: 2.8822113485465337
Validation loss: 2.52714768149857

Epoch: 6| Step: 11
Training loss: 2.536212060606038
Validation loss: 2.534149518626621

Epoch: 6| Step: 12
Training loss: 2.0596600255695003
Validation loss: 2.534393211390253

Epoch: 6| Step: 13
Training loss: 2.4209825409579158
Validation loss: 2.532946547879861

Epoch: 175| Step: 0
Training loss: 1.3056842856599273
Validation loss: 2.532643503665395

Epoch: 6| Step: 1
Training loss: 2.4386172546204277
Validation loss: 2.520572228478738

Epoch: 6| Step: 2
Training loss: 2.361502187417314
Validation loss: 2.520668281847579

Epoch: 6| Step: 3
Training loss: 2.1083883733186735
Validation loss: 2.5050862230346183

Epoch: 6| Step: 4
Training loss: 2.4721588550499844
Validation loss: 2.4975452451327462

Epoch: 6| Step: 5
Training loss: 2.375523559684725
Validation loss: 2.501809633474598

Epoch: 6| Step: 6
Training loss: 2.834749840088855
Validation loss: 2.508813501785684

Epoch: 6| Step: 7
Training loss: 2.4461510533675375
Validation loss: 2.503788477626899

Epoch: 6| Step: 8
Training loss: 2.6964611314956852
Validation loss: 2.507086485352029

Epoch: 6| Step: 9
Training loss: 2.412208709524714
Validation loss: 2.514073479855437

Epoch: 6| Step: 10
Training loss: 2.4365259816494733
Validation loss: 2.497869839731778

Epoch: 6| Step: 11
Training loss: 2.358404098725089
Validation loss: 2.504421425130383

Epoch: 6| Step: 12
Training loss: 2.6922535220135626
Validation loss: 2.504778031307283

Epoch: 6| Step: 13
Training loss: 2.5829788292915525
Validation loss: 2.491971699171775

Epoch: 176| Step: 0
Training loss: 2.472319521281102
Validation loss: 2.5041602328742005

Epoch: 6| Step: 1
Training loss: 2.705902436735543
Validation loss: 2.5024649230348253

Epoch: 6| Step: 2
Training loss: 2.3587961055128974
Validation loss: 2.5021089400591228

Epoch: 6| Step: 3
Training loss: 2.031212674311504
Validation loss: 2.5050543237456933

Epoch: 6| Step: 4
Training loss: 2.340968401461375
Validation loss: 2.504918584636342

Epoch: 6| Step: 5
Training loss: 2.0301261727345126
Validation loss: 2.51492362976408

Epoch: 6| Step: 6
Training loss: 2.7160316996796174
Validation loss: 2.5071509450280796

Epoch: 6| Step: 7
Training loss: 2.5155042536408976
Validation loss: 2.5091093043832853

Epoch: 6| Step: 8
Training loss: 2.6131796139965817
Validation loss: 2.5141172609752704

Epoch: 6| Step: 9
Training loss: 2.745363401528369
Validation loss: 2.5087017728677554

Epoch: 6| Step: 10
Training loss: 2.7202929798983737
Validation loss: 2.5218803238684497

Epoch: 6| Step: 11
Training loss: 1.9636957595492681
Validation loss: 2.5222119011390047

Epoch: 6| Step: 12
Training loss: 2.2969941607854856
Validation loss: 2.53921481727122

Epoch: 6| Step: 13
Training loss: 1.9884417455982504
Validation loss: 2.549588285195004

Epoch: 177| Step: 0
Training loss: 2.3682564817662244
Validation loss: 2.5385357589141595

Epoch: 6| Step: 1
Training loss: 2.1676414448874497
Validation loss: 2.5161854216463766

Epoch: 6| Step: 2
Training loss: 1.3261494023662042
Validation loss: 2.498884142757191

Epoch: 6| Step: 3
Training loss: 2.2362146873521977
Validation loss: 2.48993478207033

Epoch: 6| Step: 4
Training loss: 2.1974777458374697
Validation loss: 2.496024499448947

Epoch: 6| Step: 5
Training loss: 2.052430280089062
Validation loss: 2.4986650399488095

Epoch: 6| Step: 6
Training loss: 2.67697700457552
Validation loss: 2.49441124571373

Epoch: 6| Step: 7
Training loss: 1.5538068414481274
Validation loss: 2.5028763913103727

Epoch: 6| Step: 8
Training loss: 2.902296432992491
Validation loss: 2.5010256411796203

Epoch: 6| Step: 9
Training loss: 2.6144260698620205
Validation loss: 2.507736854561108

Epoch: 6| Step: 10
Training loss: 3.06546033131187
Validation loss: 2.5039791388175874

Epoch: 6| Step: 11
Training loss: 2.6634793804008616
Validation loss: 2.5228587491742607

Epoch: 6| Step: 12
Training loss: 2.0011007141054056
Validation loss: 2.5258281551984694

Epoch: 6| Step: 13
Training loss: 3.064189211468776
Validation loss: 2.540355709079328

Epoch: 178| Step: 0
Training loss: 2.8927383533019473
Validation loss: 2.5542178874353594

Epoch: 6| Step: 1
Training loss: 2.347117738323169
Validation loss: 2.5633740833930845

Epoch: 6| Step: 2
Training loss: 2.563968237818526
Validation loss: 2.578738083817278

Epoch: 6| Step: 3
Training loss: 2.1883285043415714
Validation loss: 2.574327928681236

Epoch: 6| Step: 4
Training loss: 2.105703365580812
Validation loss: 2.5922175250269968

Epoch: 6| Step: 5
Training loss: 2.1542260442798282
Validation loss: 2.565452177706424

Epoch: 6| Step: 6
Training loss: 2.744573788377021
Validation loss: 2.5475822590059134

Epoch: 6| Step: 7
Training loss: 2.9577055430633683
Validation loss: 2.526098511570781

Epoch: 6| Step: 8
Training loss: 1.6769086695478197
Validation loss: 2.5091572500394466

Epoch: 6| Step: 9
Training loss: 2.6785148523804394
Validation loss: 2.496487056687165

Epoch: 6| Step: 10
Training loss: 2.105618897924869
Validation loss: 2.4826800404467395

Epoch: 6| Step: 11
Training loss: 2.0132615774938043
Validation loss: 2.473215852382479

Epoch: 6| Step: 12
Training loss: 2.3475005594888656
Validation loss: 2.486929070465805

Epoch: 6| Step: 13
Training loss: 2.789027964487688
Validation loss: 2.4875557968297124

Epoch: 179| Step: 0
Training loss: 1.9253123488238078
Validation loss: 2.489401444902744

Epoch: 6| Step: 1
Training loss: 2.6539079101844787
Validation loss: 2.4969368765830384

Epoch: 6| Step: 2
Training loss: 2.7022499917388814
Validation loss: 2.5077792410066198

Epoch: 6| Step: 3
Training loss: 3.0055446249276754
Validation loss: 2.4991631696760748

Epoch: 6| Step: 4
Training loss: 2.3421560334986022
Validation loss: 2.4998670224745445

Epoch: 6| Step: 5
Training loss: 3.1415124654660707
Validation loss: 2.497279148869737

Epoch: 6| Step: 6
Training loss: 2.696734863035072
Validation loss: 2.492296397860416

Epoch: 6| Step: 7
Training loss: 2.476404612228542
Validation loss: 2.4855785693387524

Epoch: 6| Step: 8
Training loss: 2.1156470969552035
Validation loss: 2.491357679143819

Epoch: 6| Step: 9
Training loss: 1.9570749852819531
Validation loss: 2.4949476529110584

Epoch: 6| Step: 10
Training loss: 2.1237040663270927
Validation loss: 2.5041952854072

Epoch: 6| Step: 11
Training loss: 2.2379736031483195
Validation loss: 2.506856084330767

Epoch: 6| Step: 12
Training loss: 2.56897540808965
Validation loss: 2.5098880881428607

Epoch: 6| Step: 13
Training loss: 2.278168779117346
Validation loss: 2.506116790909747

Epoch: 180| Step: 0
Training loss: 2.5408453213550803
Validation loss: 2.524049273364114

Epoch: 6| Step: 1
Training loss: 1.8240753705614836
Validation loss: 2.4979045669309277

Epoch: 6| Step: 2
Training loss: 2.826971672474823
Validation loss: 2.5084848186040376

Epoch: 6| Step: 3
Training loss: 2.869617233005971
Validation loss: 2.5093648825600234

Epoch: 6| Step: 4
Training loss: 2.3688471550254295
Validation loss: 2.5016168928775375

Epoch: 6| Step: 5
Training loss: 2.263719691511261
Validation loss: 2.5069403156682113

Epoch: 6| Step: 6
Training loss: 1.9308066887046793
Validation loss: 2.5018001115530617

Epoch: 6| Step: 7
Training loss: 2.5098097979150142
Validation loss: 2.4949141268582227

Epoch: 6| Step: 8
Training loss: 1.9223129269741792
Validation loss: 2.504834618454907

Epoch: 6| Step: 9
Training loss: 2.451181601698829
Validation loss: 2.5009437051442114

Epoch: 6| Step: 10
Training loss: 2.014602756768223
Validation loss: 2.5093165212288295

Epoch: 6| Step: 11
Training loss: 2.553810925832914
Validation loss: 2.517037186810292

Epoch: 6| Step: 12
Training loss: 2.550913224596036
Validation loss: 2.5300551054912837

Epoch: 6| Step: 13
Training loss: 2.5434055216965756
Validation loss: 2.5288983476601943

Epoch: 181| Step: 0
Training loss: 2.411404328259901
Validation loss: 2.5481476831600016

Epoch: 6| Step: 1
Training loss: 2.965136286158801
Validation loss: 2.5704559471660686

Epoch: 6| Step: 2
Training loss: 1.9464393630422305
Validation loss: 2.567592847805003

Epoch: 6| Step: 3
Training loss: 3.002279528194782
Validation loss: 2.5277957659443477

Epoch: 6| Step: 4
Training loss: 2.1834477630020244
Validation loss: 2.5352369706087674

Epoch: 6| Step: 5
Training loss: 2.6130734120103045
Validation loss: 2.5240539333255905

Epoch: 6| Step: 6
Training loss: 2.1751129384151158
Validation loss: 2.5261110014428736

Epoch: 6| Step: 7
Training loss: 1.9844224578709269
Validation loss: 2.513751973474336

Epoch: 6| Step: 8
Training loss: 2.295493716155508
Validation loss: 2.5069963309524037

Epoch: 6| Step: 9
Training loss: 2.2652893870160367
Validation loss: 2.5015009189247945

Epoch: 6| Step: 10
Training loss: 2.5594585325887786
Validation loss: 2.5107138261314654

Epoch: 6| Step: 11
Training loss: 1.825144890037201
Validation loss: 2.507697224567178

Epoch: 6| Step: 12
Training loss: 2.1878794749676826
Validation loss: 2.5042949182437972

Epoch: 6| Step: 13
Training loss: 2.806274730004176
Validation loss: 2.503094220617111

Epoch: 182| Step: 0
Training loss: 2.4606791042729084
Validation loss: 2.517674324164742

Epoch: 6| Step: 1
Training loss: 2.0456145387749762
Validation loss: 2.5072765629346074

Epoch: 6| Step: 2
Training loss: 1.9200075582514449
Validation loss: 2.508053127323367

Epoch: 6| Step: 3
Training loss: 2.8139045598994468
Validation loss: 2.542477483609052

Epoch: 6| Step: 4
Training loss: 2.287631580341443
Validation loss: 2.531494081761892

Epoch: 6| Step: 5
Training loss: 2.277096978717019
Validation loss: 2.542621891647016

Epoch: 6| Step: 6
Training loss: 2.397995302273664
Validation loss: 2.54872485422973

Epoch: 6| Step: 7
Training loss: 2.135724549467063
Validation loss: 2.5535886930986598

Epoch: 6| Step: 8
Training loss: 2.3125015464983742
Validation loss: 2.562646179371705

Epoch: 6| Step: 9
Training loss: 2.399280114291263
Validation loss: 2.5695601640595616

Epoch: 6| Step: 10
Training loss: 2.562316143604335
Validation loss: 2.5824441815252785

Epoch: 6| Step: 11
Training loss: 2.19550059317101
Validation loss: 2.614204642745868

Epoch: 6| Step: 12
Training loss: 3.0708850588813705
Validation loss: 2.598077243735842

Epoch: 6| Step: 13
Training loss: 2.7121843004872606
Validation loss: 2.5575521197932574

Epoch: 183| Step: 0
Training loss: 2.0726219108258976
Validation loss: 2.538650040993158

Epoch: 6| Step: 1
Training loss: 2.1201549721702104
Validation loss: 2.505232833985708

Epoch: 6| Step: 2
Training loss: 2.6580988115840944
Validation loss: 2.4992234136488816

Epoch: 6| Step: 3
Training loss: 3.0308170599330553
Validation loss: 2.5075962531954614

Epoch: 6| Step: 4
Training loss: 2.1044071047548583
Validation loss: 2.4960426400951152

Epoch: 6| Step: 5
Training loss: 2.11385519585957
Validation loss: 2.4925945591311325

Epoch: 6| Step: 6
Training loss: 2.167827099820647
Validation loss: 2.493362452733067

Epoch: 6| Step: 7
Training loss: 2.4230771926441905
Validation loss: 2.499396728207502

Epoch: 6| Step: 8
Training loss: 2.9498663791200928
Validation loss: 2.4949344177392696

Epoch: 6| Step: 9
Training loss: 3.099889808665253
Validation loss: 2.5043337373227565

Epoch: 6| Step: 10
Training loss: 2.2961154642081016
Validation loss: 2.5029099535948633

Epoch: 6| Step: 11
Training loss: 1.9652713136001274
Validation loss: 2.496905302867254

Epoch: 6| Step: 12
Training loss: 2.2310048543004357
Validation loss: 2.515339410655046

Epoch: 6| Step: 13
Training loss: 2.2801760928432215
Validation loss: 2.516846117564867

Epoch: 184| Step: 0
Training loss: 1.7181584814201514
Validation loss: 2.5169478703545116

Epoch: 6| Step: 1
Training loss: 2.043565010307962
Validation loss: 2.539767671132274

Epoch: 6| Step: 2
Training loss: 3.2682528349284086
Validation loss: 2.528646723822068

Epoch: 6| Step: 3
Training loss: 2.625814039166927
Validation loss: 2.5587697830019347

Epoch: 6| Step: 4
Training loss: 2.766888346083004
Validation loss: 2.569906718680073

Epoch: 6| Step: 5
Training loss: 2.4449669346982135
Validation loss: 2.5879943980397595

Epoch: 6| Step: 6
Training loss: 2.4743326539734976
Validation loss: 2.574549374454945

Epoch: 6| Step: 7
Training loss: 1.528234509871795
Validation loss: 2.5530029715951437

Epoch: 6| Step: 8
Training loss: 2.6528524773306734
Validation loss: 2.5389591841585277

Epoch: 6| Step: 9
Training loss: 2.422423663594959
Validation loss: 2.52672005159988

Epoch: 6| Step: 10
Training loss: 2.294280370778334
Validation loss: 2.502466209226676

Epoch: 6| Step: 11
Training loss: 2.5088348681469417
Validation loss: 2.487632766771569

Epoch: 6| Step: 12
Training loss: 2.3866747962912656
Validation loss: 2.4868306273727807

Epoch: 6| Step: 13
Training loss: 1.7710722219860835
Validation loss: 2.497750239572089

Epoch: 185| Step: 0
Training loss: 2.063184451194531
Validation loss: 2.49741369618275

Epoch: 6| Step: 1
Training loss: 1.7972663121594195
Validation loss: 2.4959759592392188

Epoch: 6| Step: 2
Training loss: 2.511553104805968
Validation loss: 2.4965198453642476

Epoch: 6| Step: 3
Training loss: 2.714500350640148
Validation loss: 2.5011842624783127

Epoch: 6| Step: 4
Training loss: 2.301951293841012
Validation loss: 2.501682605358011

Epoch: 6| Step: 5
Training loss: 2.184704547521458
Validation loss: 2.4968757339750187

Epoch: 6| Step: 6
Training loss: 2.518675855581802
Validation loss: 2.5120335406870553

Epoch: 6| Step: 7
Training loss: 1.7781673325794138
Validation loss: 2.5059157791588578

Epoch: 6| Step: 8
Training loss: 3.0259590772343845
Validation loss: 2.5175979175485073

Epoch: 6| Step: 9
Training loss: 1.8727342267088298
Validation loss: 2.531569221367425

Epoch: 6| Step: 10
Training loss: 2.489812311046413
Validation loss: 2.5373218536481428

Epoch: 6| Step: 11
Training loss: 1.8358613992705286
Validation loss: 2.5477857307067437

Epoch: 6| Step: 12
Training loss: 3.129051328955516
Validation loss: 2.5638586799777037

Epoch: 6| Step: 13
Training loss: 2.508764923918031
Validation loss: 2.551970519602116

Epoch: 186| Step: 0
Training loss: 1.8393785410933476
Validation loss: 2.5557872804220487

Epoch: 6| Step: 1
Training loss: 2.084976489256988
Validation loss: 2.559032715082833

Epoch: 6| Step: 2
Training loss: 1.6300093394286905
Validation loss: 2.559970739490458

Epoch: 6| Step: 3
Training loss: 2.2096234517774787
Validation loss: 2.530235079208698

Epoch: 6| Step: 4
Training loss: 2.660828089634712
Validation loss: 2.528881495475111

Epoch: 6| Step: 5
Training loss: 2.488420467584293
Validation loss: 2.516032105038364

Epoch: 6| Step: 6
Training loss: 2.3161048628764296
Validation loss: 2.5018361977763752

Epoch: 6| Step: 7
Training loss: 2.609506204013353
Validation loss: 2.4962497238594556

Epoch: 6| Step: 8
Training loss: 2.4238837002907956
Validation loss: 2.5007252435948324

Epoch: 6| Step: 9
Training loss: 2.29021125585295
Validation loss: 2.504106010764515

Epoch: 6| Step: 10
Training loss: 2.5299277914244462
Validation loss: 2.496017494688508

Epoch: 6| Step: 11
Training loss: 2.763238081569261
Validation loss: 2.504690554294322

Epoch: 6| Step: 12
Training loss: 2.5627122186382656
Validation loss: 2.500694226196057

Epoch: 6| Step: 13
Training loss: 2.641175161981327
Validation loss: 2.5087601722013075

Epoch: 187| Step: 0
Training loss: 2.114547491161338
Validation loss: 2.5182883338854625

Epoch: 6| Step: 1
Training loss: 2.7833635678809694
Validation loss: 2.5316522694626813

Epoch: 6| Step: 2
Training loss: 1.9870855487094699
Validation loss: 2.5303255755756555

Epoch: 6| Step: 3
Training loss: 2.155705258763055
Validation loss: 2.566112174377346

Epoch: 6| Step: 4
Training loss: 2.207362111365541
Validation loss: 2.571960971858505

Epoch: 6| Step: 5
Training loss: 2.6140875377926656
Validation loss: 2.567446532195714

Epoch: 6| Step: 6
Training loss: 2.8074680666920515
Validation loss: 2.5609505628803877

Epoch: 6| Step: 7
Training loss: 1.8510678431331444
Validation loss: 2.5618835265926716

Epoch: 6| Step: 8
Training loss: 2.3726433556099242
Validation loss: 2.563227775005858

Epoch: 6| Step: 9
Training loss: 2.3306608790333785
Validation loss: 2.5451098763230577

Epoch: 6| Step: 10
Training loss: 1.9234185571923064
Validation loss: 2.545679564652588

Epoch: 6| Step: 11
Training loss: 2.9230202455083774
Validation loss: 2.528055962310327

Epoch: 6| Step: 12
Training loss: 2.805218404607097
Validation loss: 2.5076783363209016

Epoch: 6| Step: 13
Training loss: 2.094433573259809
Validation loss: 2.518230376429039

Epoch: 188| Step: 0
Training loss: 2.0493697476937762
Validation loss: 2.5074400342957337

Epoch: 6| Step: 1
Training loss: 2.6442569832736207
Validation loss: 2.5186750825226736

Epoch: 6| Step: 2
Training loss: 2.968498460252339
Validation loss: 2.5036791273431764

Epoch: 6| Step: 3
Training loss: 1.8020944172365814
Validation loss: 2.4933732180754213

Epoch: 6| Step: 4
Training loss: 2.1014383839539943
Validation loss: 2.4785319458785104

Epoch: 6| Step: 5
Training loss: 2.021938401986624
Validation loss: 2.482996760245504

Epoch: 6| Step: 6
Training loss: 2.310555852258289
Validation loss: 2.486965220680214

Epoch: 6| Step: 7
Training loss: 2.3317440501476936
Validation loss: 2.4852335024349648

Epoch: 6| Step: 8
Training loss: 1.9165440257544384
Validation loss: 2.5074572445237475

Epoch: 6| Step: 9
Training loss: 2.7533760155547635
Validation loss: 2.510879922336044

Epoch: 6| Step: 10
Training loss: 2.26751998051396
Validation loss: 2.5000110467030927

Epoch: 6| Step: 11
Training loss: 2.3743027115210644
Validation loss: 2.512033849146446

Epoch: 6| Step: 12
Training loss: 2.6176786502764777
Validation loss: 2.537090643073812

Epoch: 6| Step: 13
Training loss: 2.498056037414784
Validation loss: 2.5496237807648345

Epoch: 189| Step: 0
Training loss: 2.587613118965504
Validation loss: 2.559597457204264

Epoch: 6| Step: 1
Training loss: 2.299976357048254
Validation loss: 2.570745738890219

Epoch: 6| Step: 2
Training loss: 1.8954571221406669
Validation loss: 2.5596188653782153

Epoch: 6| Step: 3
Training loss: 2.9482947512600597
Validation loss: 2.541413581212928

Epoch: 6| Step: 4
Training loss: 2.4474702035650746
Validation loss: 2.5545353119886482

Epoch: 6| Step: 5
Training loss: 2.9854437227658064
Validation loss: 2.5279402738841354

Epoch: 6| Step: 6
Training loss: 2.985461451710753
Validation loss: 2.514584786310121

Epoch: 6| Step: 7
Training loss: 1.7640631865777976
Validation loss: 2.504109731927212

Epoch: 6| Step: 8
Training loss: 2.6566914808613364
Validation loss: 2.4920343334043307

Epoch: 6| Step: 9
Training loss: 2.5268474014816875
Validation loss: 2.496438700561016

Epoch: 6| Step: 10
Training loss: 2.22775161846189
Validation loss: 2.491757059743484

Epoch: 6| Step: 11
Training loss: 2.1064276555240493
Validation loss: 2.4929864334281024

Epoch: 6| Step: 12
Training loss: 1.798460484812702
Validation loss: 2.497893542728075

Epoch: 6| Step: 13
Training loss: 1.7975922852914685
Validation loss: 2.492662374601761

Epoch: 190| Step: 0
Training loss: 2.6000808299778324
Validation loss: 2.495348465385013

Epoch: 6| Step: 1
Training loss: 2.594523119317846
Validation loss: 2.507162102866191

Epoch: 6| Step: 2
Training loss: 2.2062777422924915
Validation loss: 2.5000103473449196

Epoch: 6| Step: 3
Training loss: 2.512683167115031
Validation loss: 2.525653743780145

Epoch: 6| Step: 4
Training loss: 2.3129819419343938
Validation loss: 2.5430176120327688

Epoch: 6| Step: 5
Training loss: 2.2485117758861812
Validation loss: 2.5499362918898862

Epoch: 6| Step: 6
Training loss: 2.1111818839920313
Validation loss: 2.556907987590836

Epoch: 6| Step: 7
Training loss: 2.857837701501784
Validation loss: 2.538816688572019

Epoch: 6| Step: 8
Training loss: 2.8335492294932716
Validation loss: 2.552145187770166

Epoch: 6| Step: 9
Training loss: 1.7384956827666882
Validation loss: 2.5298314613375403

Epoch: 6| Step: 10
Training loss: 1.9752852946059893
Validation loss: 2.533291938928751

Epoch: 6| Step: 11
Training loss: 2.1481407376718162
Validation loss: 2.508481389066462

Epoch: 6| Step: 12
Training loss: 2.3471337877978464
Validation loss: 2.5136608092907493

Epoch: 6| Step: 13
Training loss: 2.738225873749086
Validation loss: 2.5127145267586624

Epoch: 191| Step: 0
Training loss: 2.704125368089959
Validation loss: 2.509210412822235

Epoch: 6| Step: 1
Training loss: 2.7033017492115152
Validation loss: 2.4918616389750476

Epoch: 6| Step: 2
Training loss: 2.1890053065668282
Validation loss: 2.502876518320812

Epoch: 6| Step: 3
Training loss: 1.6044272504262698
Validation loss: 2.4977112465822193

Epoch: 6| Step: 4
Training loss: 2.1712928924979713
Validation loss: 2.509500998710195

Epoch: 6| Step: 5
Training loss: 2.018134986566837
Validation loss: 2.503893205010627

Epoch: 6| Step: 6
Training loss: 2.6898961585326977
Validation loss: 2.5088185226593556

Epoch: 6| Step: 7
Training loss: 2.492709401172027
Validation loss: 2.500754909978484

Epoch: 6| Step: 8
Training loss: 2.754093418118764
Validation loss: 2.493884538225742

Epoch: 6| Step: 9
Training loss: 2.28821462089456
Validation loss: 2.4958225793452913

Epoch: 6| Step: 10
Training loss: 2.7868537598489413
Validation loss: 2.4932712602113414

Epoch: 6| Step: 11
Training loss: 1.6809756994720584
Validation loss: 2.4928882534476444

Epoch: 6| Step: 12
Training loss: 2.2338960574429114
Validation loss: 2.495436827210382

Epoch: 6| Step: 13
Training loss: 2.4092863667731863
Validation loss: 2.51265490672773

Epoch: 192| Step: 0
Training loss: 2.977248545805912
Validation loss: 2.4869816219191225

Epoch: 6| Step: 1
Training loss: 1.7134793008356097
Validation loss: 2.5162202750767095

Epoch: 6| Step: 2
Training loss: 2.599946307581587
Validation loss: 2.526844759563659

Epoch: 6| Step: 3
Training loss: 2.008918309261208
Validation loss: 2.536123317602317

Epoch: 6| Step: 4
Training loss: 2.3747335585665454
Validation loss: 2.5358604703068157

Epoch: 6| Step: 5
Training loss: 2.2187416183958106
Validation loss: 2.52869576045731

Epoch: 6| Step: 6
Training loss: 2.3380223797199395
Validation loss: 2.5369501805449186

Epoch: 6| Step: 7
Training loss: 2.607595967970831
Validation loss: 2.5506497593121757

Epoch: 6| Step: 8
Training loss: 1.7470224116983497
Validation loss: 2.545222114658278

Epoch: 6| Step: 9
Training loss: 2.5632583612491486
Validation loss: 2.5384998343653433

Epoch: 6| Step: 10
Training loss: 2.9293525199117103
Validation loss: 2.534835724633631

Epoch: 6| Step: 11
Training loss: 2.307009803886731
Validation loss: 2.5377328530946963

Epoch: 6| Step: 12
Training loss: 2.089741299693815
Validation loss: 2.523116068647438

Epoch: 6| Step: 13
Training loss: 2.264617485436929
Validation loss: 2.528922199791739

Epoch: 193| Step: 0
Training loss: 2.5479859345555407
Validation loss: 2.5326806017015433

Epoch: 6| Step: 1
Training loss: 2.0079008446638875
Validation loss: 2.5294725433184557

Epoch: 6| Step: 2
Training loss: 2.437064987881421
Validation loss: 2.5091729994531047

Epoch: 6| Step: 3
Training loss: 2.0074516001718377
Validation loss: 2.5171481589793503

Epoch: 6| Step: 4
Training loss: 2.019516374839439
Validation loss: 2.516632162788106

Epoch: 6| Step: 5
Training loss: 2.4619872745460842
Validation loss: 2.513812753029085

Epoch: 6| Step: 6
Training loss: 2.4868946853322593
Validation loss: 2.5344600965808244

Epoch: 6| Step: 7
Training loss: 2.0583868918098247
Validation loss: 2.5271789402708866

Epoch: 6| Step: 8
Training loss: 2.0952704303793626
Validation loss: 2.5295390559329003

Epoch: 6| Step: 9
Training loss: 2.550251226578384
Validation loss: 2.530778754680707

Epoch: 6| Step: 10
Training loss: 2.382725048023792
Validation loss: 2.5472029492383923

Epoch: 6| Step: 11
Training loss: 2.680020058684937
Validation loss: 2.557384642071715

Epoch: 6| Step: 12
Training loss: 2.981218196291396
Validation loss: 2.5926041120949406

Epoch: 6| Step: 13
Training loss: 2.2081474249937645
Validation loss: 2.564841046207462

Epoch: 194| Step: 0
Training loss: 2.064506479546469
Validation loss: 2.5740591182040475

Epoch: 6| Step: 1
Training loss: 1.7933003569812618
Validation loss: 2.5525576299973327

Epoch: 6| Step: 2
Training loss: 1.861386469339878
Validation loss: 2.544894456654712

Epoch: 6| Step: 3
Training loss: 2.168871772271677
Validation loss: 2.5434007878272236

Epoch: 6| Step: 4
Training loss: 2.29717787218418
Validation loss: 2.5304941689389477

Epoch: 6| Step: 5
Training loss: 2.1497452518443083
Validation loss: 2.538456348545042

Epoch: 6| Step: 6
Training loss: 2.6086915543081743
Validation loss: 2.5395380445348104

Epoch: 6| Step: 7
Training loss: 1.6136790378608272
Validation loss: 2.533526476181469

Epoch: 6| Step: 8
Training loss: 2.9108859587450926
Validation loss: 2.550809944774234

Epoch: 6| Step: 9
Training loss: 2.902193252953744
Validation loss: 2.545489021863551

Epoch: 6| Step: 10
Training loss: 2.402793283969872
Validation loss: 2.528062155264288

Epoch: 6| Step: 11
Training loss: 2.3516032573424983
Validation loss: 2.5227756636193783

Epoch: 6| Step: 12
Training loss: 2.7871328137701363
Validation loss: 2.514042966967107

Epoch: 6| Step: 13
Training loss: 2.3415941623128855
Validation loss: 2.5155218825915378

Epoch: 195| Step: 0
Training loss: 2.031863897428802
Validation loss: 2.5227839959245375

Epoch: 6| Step: 1
Training loss: 2.698377641059218
Validation loss: 2.525830798179825

Epoch: 6| Step: 2
Training loss: 2.171490532306547
Validation loss: 2.5416941927894126

Epoch: 6| Step: 3
Training loss: 1.7418983116821047
Validation loss: 2.554259642567722

Epoch: 6| Step: 4
Training loss: 2.429498107005008
Validation loss: 2.5537168581755973

Epoch: 6| Step: 5
Training loss: 2.441514255423473
Validation loss: 2.542404666965051

Epoch: 6| Step: 6
Training loss: 2.5439490612976217
Validation loss: 2.527509507998711

Epoch: 6| Step: 7
Training loss: 1.6767646376171519
Validation loss: 2.533669841736096

Epoch: 6| Step: 8
Training loss: 2.590216746447892
Validation loss: 2.5078691612806554

Epoch: 6| Step: 9
Training loss: 2.0832501076922934
Validation loss: 2.516065286526169

Epoch: 6| Step: 10
Training loss: 2.017736467497802
Validation loss: 2.5243576623948214

Epoch: 6| Step: 11
Training loss: 1.9944128435418327
Validation loss: 2.5192722867612267

Epoch: 6| Step: 12
Training loss: 2.8407560244852803
Validation loss: 2.5319676892758616

Epoch: 6| Step: 13
Training loss: 3.017750519701341
Validation loss: 2.5323874268862943

Epoch: 196| Step: 0
Training loss: 1.673163799624028
Validation loss: 2.5370687002318735

Epoch: 6| Step: 1
Training loss: 2.4882213639219652
Validation loss: 2.541498527802106

Epoch: 6| Step: 2
Training loss: 2.152769070952935
Validation loss: 2.5356676460699834

Epoch: 6| Step: 3
Training loss: 2.171087767272591
Validation loss: 2.5382292803524806

Epoch: 6| Step: 4
Training loss: 3.0494483448863146
Validation loss: 2.5271399139166997

Epoch: 6| Step: 5
Training loss: 2.8828890823902236
Validation loss: 2.518874090086539

Epoch: 6| Step: 6
Training loss: 1.5292862737100623
Validation loss: 2.516741542354939

Epoch: 6| Step: 7
Training loss: 1.8053900602087993
Validation loss: 2.506344961014688

Epoch: 6| Step: 8
Training loss: 2.114411282860929
Validation loss: 2.508817128853161

Epoch: 6| Step: 9
Training loss: 3.085638954110956
Validation loss: 2.5246003879672636

Epoch: 6| Step: 10
Training loss: 2.260645267394665
Validation loss: 2.5218062822007368

Epoch: 6| Step: 11
Training loss: 2.478160258519763
Validation loss: 2.5371725785681614

Epoch: 6| Step: 12
Training loss: 2.335569014558366
Validation loss: 2.561705706548529

Epoch: 6| Step: 13
Training loss: 2.315762666839151
Validation loss: 2.5543357459190523

Epoch: 197| Step: 0
Training loss: 2.3586079948629437
Validation loss: 2.5552078945834973

Epoch: 6| Step: 1
Training loss: 2.805773171607986
Validation loss: 2.5502486712310155

Epoch: 6| Step: 2
Training loss: 2.393147353364044
Validation loss: 2.5354909651398536

Epoch: 6| Step: 3
Training loss: 2.179233845635016
Validation loss: 2.5294988249643873

Epoch: 6| Step: 4
Training loss: 2.3834212729318156
Validation loss: 2.5208862840329895

Epoch: 6| Step: 5
Training loss: 2.5627994827555773
Validation loss: 2.513446077462358

Epoch: 6| Step: 6
Training loss: 2.4342610284767616
Validation loss: 2.5170711364938922

Epoch: 6| Step: 7
Training loss: 1.302648538624077
Validation loss: 2.511076604332701

Epoch: 6| Step: 8
Training loss: 2.7744576310762006
Validation loss: 2.5447099060173994

Epoch: 6| Step: 9
Training loss: 2.1455773753373637
Validation loss: 2.553772306464652

Epoch: 6| Step: 10
Training loss: 2.740334256799571
Validation loss: 2.563943518358198

Epoch: 6| Step: 11
Training loss: 2.0962125047163513
Validation loss: 2.570450830263993

Epoch: 6| Step: 12
Training loss: 2.1947397591334252
Validation loss: 2.5618263847910865

Epoch: 6| Step: 13
Training loss: 2.3119694900281544
Validation loss: 2.5316388180849936

Epoch: 198| Step: 0
Training loss: 2.196654645957338
Validation loss: 2.515000291423642

Epoch: 6| Step: 1
Training loss: 3.0201761166585577
Validation loss: 2.514281457091315

Epoch: 6| Step: 2
Training loss: 2.4336621319270035
Validation loss: 2.5039459558632715

Epoch: 6| Step: 3
Training loss: 3.2593004227296185
Validation loss: 2.5024942194630224

Epoch: 6| Step: 4
Training loss: 2.122560559454605
Validation loss: 2.5008224882733683

Epoch: 6| Step: 5
Training loss: 2.2731667059113305
Validation loss: 2.5021016426485865

Epoch: 6| Step: 6
Training loss: 2.3097009988792125
Validation loss: 2.495769927461815

Epoch: 6| Step: 7
Training loss: 2.2304453405965625
Validation loss: 2.4879953648349233

Epoch: 6| Step: 8
Training loss: 1.5686895989572274
Validation loss: 2.496031480309963

Epoch: 6| Step: 9
Training loss: 2.3478053294752326
Validation loss: 2.4939028936058834

Epoch: 6| Step: 10
Training loss: 2.315980611617872
Validation loss: 2.499911481561763

Epoch: 6| Step: 11
Training loss: 2.291216569106166
Validation loss: 2.503032212396955

Epoch: 6| Step: 12
Training loss: 2.1523311219995933
Validation loss: 2.5228013849944837

Epoch: 6| Step: 13
Training loss: 1.761843116582731
Validation loss: 2.548214254106539

Epoch: 199| Step: 0
Training loss: 2.371282780510685
Validation loss: 2.562092632384978

Epoch: 6| Step: 1
Training loss: 2.2000089211716536
Validation loss: 2.542193894865734

Epoch: 6| Step: 2
Training loss: 2.4997930441071916
Validation loss: 2.5305352477361374

Epoch: 6| Step: 3
Training loss: 3.0617154731937366
Validation loss: 2.5166586890525773

Epoch: 6| Step: 4
Training loss: 2.621272665134104
Validation loss: 2.501891628505221

Epoch: 6| Step: 5
Training loss: 2.579945978885466
Validation loss: 2.4944884820145754

Epoch: 6| Step: 6
Training loss: 2.6151537836490206
Validation loss: 2.520643326925791

Epoch: 6| Step: 7
Training loss: 2.2708116816150508
Validation loss: 2.5139130321301106

Epoch: 6| Step: 8
Training loss: 2.1360978195422886
Validation loss: 2.5263757674822696

Epoch: 6| Step: 9
Training loss: 2.1261873854758755
Validation loss: 2.5290785529568605

Epoch: 6| Step: 10
Training loss: 2.518569265843325
Validation loss: 2.549420214170473

Epoch: 6| Step: 11
Training loss: 1.6862047664154631
Validation loss: 2.5470040255513386

Epoch: 6| Step: 12
Training loss: 2.2816062544559075
Validation loss: 2.552722708089991

Epoch: 6| Step: 13
Training loss: 2.179853207431851
Validation loss: 2.534138009200863

Epoch: 200| Step: 0
Training loss: 2.5969551230142014
Validation loss: 2.543947358719387

Epoch: 6| Step: 1
Training loss: 2.2858148131232765
Validation loss: 2.536742612873165

Epoch: 6| Step: 2
Training loss: 2.079016472762675
Validation loss: 2.508667622803847

Epoch: 6| Step: 3
Training loss: 2.5691409702193493
Validation loss: 2.5295588334372203

Epoch: 6| Step: 4
Training loss: 2.812938655977713
Validation loss: 2.513054571106447

Epoch: 6| Step: 5
Training loss: 2.6122145136305646
Validation loss: 2.522850968387238

Epoch: 6| Step: 6
Training loss: 1.923826018201575
Validation loss: 2.5384044400894554

Epoch: 6| Step: 7
Training loss: 2.2065179548641654
Validation loss: 2.539338567348637

Epoch: 6| Step: 8
Training loss: 2.459461362841974
Validation loss: 2.54322337854901

Epoch: 6| Step: 9
Training loss: 1.9575217844797146
Validation loss: 2.5358944422086136

Epoch: 6| Step: 10
Training loss: 2.1135488400651687
Validation loss: 2.524397935944924

Epoch: 6| Step: 11
Training loss: 1.9651473855419765
Validation loss: 2.5214515484939195

Epoch: 6| Step: 12
Training loss: 2.7482394738611258
Validation loss: 2.527426512442553

Epoch: 6| Step: 13
Training loss: 2.152955233188675
Validation loss: 2.5274929138220092

Epoch: 201| Step: 0
Training loss: 2.2099737756131193
Validation loss: 2.5170133957105394

Epoch: 6| Step: 1
Training loss: 2.2464711809243476
Validation loss: 2.5062117017957473

Epoch: 6| Step: 2
Training loss: 2.535967633814004
Validation loss: 2.489975237359393

Epoch: 6| Step: 3
Training loss: 1.9617019318376607
Validation loss: 2.5093737819568913

Epoch: 6| Step: 4
Training loss: 1.7465707694851142
Validation loss: 2.5026521443277776

Epoch: 6| Step: 5
Training loss: 2.5161659180435665
Validation loss: 2.5041920007406957

Epoch: 6| Step: 6
Training loss: 2.7786510196960346
Validation loss: 2.5086883093080883

Epoch: 6| Step: 7
Training loss: 2.4503074063886805
Validation loss: 2.515796189574671

Epoch: 6| Step: 8
Training loss: 2.252815604163444
Validation loss: 2.5290853875898174

Epoch: 6| Step: 9
Training loss: 2.5141475912029434
Validation loss: 2.5597502756631214

Epoch: 6| Step: 10
Training loss: 3.1061782122477575
Validation loss: 2.5587335368789823

Epoch: 6| Step: 11
Training loss: 1.7091344102667256
Validation loss: 2.5873407588247037

Epoch: 6| Step: 12
Training loss: 1.8927620403736685
Validation loss: 2.6154793398340184

Epoch: 6| Step: 13
Training loss: 2.587796652185315
Validation loss: 2.6060931798164044

Epoch: 202| Step: 0
Training loss: 2.521578455321498
Validation loss: 2.586014776237306

Epoch: 6| Step: 1
Training loss: 2.1956545743136804
Validation loss: 2.5567167196467984

Epoch: 6| Step: 2
Training loss: 2.4556863618574134
Validation loss: 2.5512425705064685

Epoch: 6| Step: 3
Training loss: 2.819544975689177
Validation loss: 2.528509752492746

Epoch: 6| Step: 4
Training loss: 2.9228484628178517
Validation loss: 2.52354674206174

Epoch: 6| Step: 5
Training loss: 1.738662849287999
Validation loss: 2.5090672096382134

Epoch: 6| Step: 6
Training loss: 2.3875613059915684
Validation loss: 2.5239239864449994

Epoch: 6| Step: 7
Training loss: 2.5558351511203043
Validation loss: 2.5136723492435937

Epoch: 6| Step: 8
Training loss: 1.875949110776501
Validation loss: 2.5122800746588814

Epoch: 6| Step: 9
Training loss: 1.8552168183201405
Validation loss: 2.5279644965865713

Epoch: 6| Step: 10
Training loss: 2.199299514398715
Validation loss: 2.522422846359948

Epoch: 6| Step: 11
Training loss: 2.895265884971143
Validation loss: 2.522295383362303

Epoch: 6| Step: 12
Training loss: 1.875231919250673
Validation loss: 2.520934163328546

Epoch: 6| Step: 13
Training loss: 2.190762294325155
Validation loss: 2.540142921046261

Epoch: 203| Step: 0
Training loss: 2.47945314777015
Validation loss: 2.5320512578766747

Epoch: 6| Step: 1
Training loss: 2.5428326126433984
Validation loss: 2.5354122822163854

Epoch: 6| Step: 2
Training loss: 2.1636290408768963
Validation loss: 2.54952649600888

Epoch: 6| Step: 3
Training loss: 2.040707213540562
Validation loss: 2.5412262759123134

Epoch: 6| Step: 4
Training loss: 1.845677612774241
Validation loss: 2.5719297320574355

Epoch: 6| Step: 5
Training loss: 1.9960661585742887
Validation loss: 2.5690127935203595

Epoch: 6| Step: 6
Training loss: 2.293276920437974
Validation loss: 2.5836109709494988

Epoch: 6| Step: 7
Training loss: 2.983647762188264
Validation loss: 2.5704697364708

Epoch: 6| Step: 8
Training loss: 1.8596230990515585
Validation loss: 2.5774905647551605

Epoch: 6| Step: 9
Training loss: 2.115858047699594
Validation loss: 2.5681312682142683

Epoch: 6| Step: 10
Training loss: 2.7490049642751866
Validation loss: 2.5575527024269165

Epoch: 6| Step: 11
Training loss: 2.599240386478411
Validation loss: 2.5386083421702375

Epoch: 6| Step: 12
Training loss: 2.4048252594213224
Validation loss: 2.544948730951608

Epoch: 6| Step: 13
Training loss: 2.2995663399911437
Validation loss: 2.549436727968724

Epoch: 204| Step: 0
Training loss: 2.019128637560542
Validation loss: 2.548883313279436

Epoch: 6| Step: 1
Training loss: 2.342132213466799
Validation loss: 2.5495549711206444

Epoch: 6| Step: 2
Training loss: 2.3129422563930757
Validation loss: 2.56654013831721

Epoch: 6| Step: 3
Training loss: 1.4633567485080083
Validation loss: 2.551277786071175

Epoch: 6| Step: 4
Training loss: 3.1005367245110165
Validation loss: 2.527765316519105

Epoch: 6| Step: 5
Training loss: 2.4629165684349297
Validation loss: 2.528832289594603

Epoch: 6| Step: 6
Training loss: 2.4745014651886352
Validation loss: 2.5266205638849764

Epoch: 6| Step: 7
Training loss: 2.2921215877404584
Validation loss: 2.507007275501696

Epoch: 6| Step: 8
Training loss: 2.075953905464846
Validation loss: 2.4982517010324696

Epoch: 6| Step: 9
Training loss: 1.9035869194408572
Validation loss: 2.509397392125537

Epoch: 6| Step: 10
Training loss: 2.7159337332482902
Validation loss: 2.501378823565502

Epoch: 6| Step: 11
Training loss: 2.685146809689817
Validation loss: 2.5098207222794615

Epoch: 6| Step: 12
Training loss: 2.2452087250940127
Validation loss: 2.4966695536285672

Epoch: 6| Step: 13
Training loss: 2.0667652762893494
Validation loss: 2.5087515715711506

Epoch: 205| Step: 0
Training loss: 2.073995402177443
Validation loss: 2.5224214758243377

Epoch: 6| Step: 1
Training loss: 2.1372295096951603
Validation loss: 2.5435290366389416

Epoch: 6| Step: 2
Training loss: 2.9106526815463183
Validation loss: 2.552369920378267

Epoch: 6| Step: 3
Training loss: 2.234977160855542
Validation loss: 2.578218570128654

Epoch: 6| Step: 4
Training loss: 2.3216865144726957
Validation loss: 2.5648232449809854

Epoch: 6| Step: 5
Training loss: 2.2944294892327353
Validation loss: 2.5315224143797823

Epoch: 6| Step: 6
Training loss: 1.5065346476574262
Validation loss: 2.5351892517167554

Epoch: 6| Step: 7
Training loss: 1.819956797935915
Validation loss: 2.512850888423984

Epoch: 6| Step: 8
Training loss: 2.7362267028179277
Validation loss: 2.5279665557413566

Epoch: 6| Step: 9
Training loss: 2.8668841375617404
Validation loss: 2.5345456368120516

Epoch: 6| Step: 10
Training loss: 2.2058986221910284
Validation loss: 2.5247880295893768

Epoch: 6| Step: 11
Training loss: 2.434866044513357
Validation loss: 2.5329639613091164

Epoch: 6| Step: 12
Training loss: 2.639655211648494
Validation loss: 2.5290380082774377

Epoch: 6| Step: 13
Training loss: 2.0361153654453346
Validation loss: 2.5250087605692655

Epoch: 206| Step: 0
Training loss: 2.894051001035441
Validation loss: 2.5226505891041953

Epoch: 6| Step: 1
Training loss: 2.4951972605179904
Validation loss: 2.539971698443116

Epoch: 6| Step: 2
Training loss: 2.052340599496178
Validation loss: 2.5699313498579066

Epoch: 6| Step: 3
Training loss: 2.3882727925129323
Validation loss: 2.570144570535709

Epoch: 6| Step: 4
Training loss: 2.548760400800451
Validation loss: 2.570010692188271

Epoch: 6| Step: 5
Training loss: 2.1905050073430155
Validation loss: 2.5629423426486864

Epoch: 6| Step: 6
Training loss: 2.038378136621477
Validation loss: 2.5422733682371295

Epoch: 6| Step: 7
Training loss: 2.5869362737638864
Validation loss: 2.5544752991376165

Epoch: 6| Step: 8
Training loss: 2.281529239651931
Validation loss: 2.5430975674818166

Epoch: 6| Step: 9
Training loss: 2.018808143179962
Validation loss: 2.526580396536544

Epoch: 6| Step: 10
Training loss: 2.266802672438412
Validation loss: 2.5123598379132526

Epoch: 6| Step: 11
Training loss: 2.396005397644077
Validation loss: 2.513223311151982

Epoch: 6| Step: 12
Training loss: 2.037590226123974
Validation loss: 2.4893128289355766

Epoch: 6| Step: 13
Training loss: 2.394831528123785
Validation loss: 2.4819363154946057

Epoch: 207| Step: 0
Training loss: 1.9871280826012694
Validation loss: 2.499784778231849

Epoch: 6| Step: 1
Training loss: 2.3327876769966154
Validation loss: 2.4946919914408103

Epoch: 6| Step: 2
Training loss: 2.0740211522008667
Validation loss: 2.4986782871659403

Epoch: 6| Step: 3
Training loss: 2.325213153871597
Validation loss: 2.5091314442253987

Epoch: 6| Step: 4
Training loss: 1.8082211730676037
Validation loss: 2.513845584442542

Epoch: 6| Step: 5
Training loss: 2.8372665107549833
Validation loss: 2.5139346080531006

Epoch: 6| Step: 6
Training loss: 1.5054039569525512
Validation loss: 2.5277105003411995

Epoch: 6| Step: 7
Training loss: 2.625969299102078
Validation loss: 2.5260165708153886

Epoch: 6| Step: 8
Training loss: 2.8269878651507283
Validation loss: 2.5390464508331916

Epoch: 6| Step: 9
Training loss: 2.5828623393581602
Validation loss: 2.5368254367835874

Epoch: 6| Step: 10
Training loss: 1.988019525055975
Validation loss: 2.556205726121986

Epoch: 6| Step: 11
Training loss: 2.0690082400394334
Validation loss: 2.549184333396699

Epoch: 6| Step: 12
Training loss: 2.141981711265926
Validation loss: 2.5383426213068447

Epoch: 6| Step: 13
Training loss: 2.851921832293481
Validation loss: 2.5379218096992298

Epoch: 208| Step: 0
Training loss: 2.577322262723262
Validation loss: 2.5578887667089503

Epoch: 6| Step: 1
Training loss: 2.916497325522565
Validation loss: 2.561301734318672

Epoch: 6| Step: 2
Training loss: 1.9504492168919858
Validation loss: 2.5850162305635958

Epoch: 6| Step: 3
Training loss: 1.9533725429067124
Validation loss: 2.572940414463261

Epoch: 6| Step: 4
Training loss: 2.237067354452734
Validation loss: 2.569190525418872

Epoch: 6| Step: 5
Training loss: 2.536670579326618
Validation loss: 2.5693207888589793

Epoch: 6| Step: 6
Training loss: 2.2963895738905546
Validation loss: 2.5879547917310264

Epoch: 6| Step: 7
Training loss: 2.2972301805392448
Validation loss: 2.5708484033012033

Epoch: 6| Step: 8
Training loss: 1.8062798547092425
Validation loss: 2.5672904726266244

Epoch: 6| Step: 9
Training loss: 1.9942660988125243
Validation loss: 2.5687385076186855

Epoch: 6| Step: 10
Training loss: 2.286635013320461
Validation loss: 2.534771247865763

Epoch: 6| Step: 11
Training loss: 2.2904429781048266
Validation loss: 2.5197532063188226

Epoch: 6| Step: 12
Training loss: 2.698341591460904
Validation loss: 2.5203652748657253

Epoch: 6| Step: 13
Training loss: 2.1409757006645784
Validation loss: 2.512077958449296

Epoch: 209| Step: 0
Training loss: 2.8635603494174626
Validation loss: 2.49705454244894

Epoch: 6| Step: 1
Training loss: 1.8717360379663965
Validation loss: 2.494920410041146

Epoch: 6| Step: 2
Training loss: 2.6643652422317126
Validation loss: 2.4967986908838844

Epoch: 6| Step: 3
Training loss: 1.936879458574627
Validation loss: 2.4841578326686182

Epoch: 6| Step: 4
Training loss: 2.119895188961619
Validation loss: 2.499119921589794

Epoch: 6| Step: 5
Training loss: 2.5125448194463242
Validation loss: 2.4971539509848872

Epoch: 6| Step: 6
Training loss: 2.466546149359745
Validation loss: 2.532309934256499

Epoch: 6| Step: 7
Training loss: 2.184827207109697
Validation loss: 2.543560547143205

Epoch: 6| Step: 8
Training loss: 1.941338827700927
Validation loss: 2.539353151558378

Epoch: 6| Step: 9
Training loss: 2.1071295195150483
Validation loss: 2.550669388706126

Epoch: 6| Step: 10
Training loss: 2.249355647752957
Validation loss: 2.559730909952245

Epoch: 6| Step: 11
Training loss: 2.687863170127096
Validation loss: 2.569343879094906

Epoch: 6| Step: 12
Training loss: 2.551008649565397
Validation loss: 2.584160646638457

Epoch: 6| Step: 13
Training loss: 1.9403472406758007
Validation loss: 2.6426030111069125

Epoch: 210| Step: 0
Training loss: 2.5911161539240615
Validation loss: 2.6297713467518236

Epoch: 6| Step: 1
Training loss: 2.603658204349116
Validation loss: 2.6404361243481915

Epoch: 6| Step: 2
Training loss: 1.88022597314339
Validation loss: 2.6481257942588057

Epoch: 6| Step: 3
Training loss: 2.054436265793792
Validation loss: 2.608145479337756

Epoch: 6| Step: 4
Training loss: 2.933924670291871
Validation loss: 2.5852639049941453

Epoch: 6| Step: 5
Training loss: 2.796112638603164
Validation loss: 2.5372421781979586

Epoch: 6| Step: 6
Training loss: 1.8285195992566563
Validation loss: 2.531432572989995

Epoch: 6| Step: 7
Training loss: 1.8396430098407697
Validation loss: 2.5210434114127387

Epoch: 6| Step: 8
Training loss: 2.4429338970571073
Validation loss: 2.510557120629564

Epoch: 6| Step: 9
Training loss: 2.903056040623398
Validation loss: 2.4996947420039737

Epoch: 6| Step: 10
Training loss: 1.4267151164951832
Validation loss: 2.518087630977343

Epoch: 6| Step: 11
Training loss: 2.3429052229177856
Validation loss: 2.5020310496241622

Epoch: 6| Step: 12
Training loss: 2.5563854675959075
Validation loss: 2.5299940093601556

Epoch: 6| Step: 13
Training loss: 2.109073193469728
Validation loss: 2.533569011475314

Epoch: 211| Step: 0
Training loss: 2.5713949504047013
Validation loss: 2.5291880776904154

Epoch: 6| Step: 1
Training loss: 2.98529997067581
Validation loss: 2.547246137541648

Epoch: 6| Step: 2
Training loss: 2.6208122090841273
Validation loss: 2.55367027819269

Epoch: 6| Step: 3
Training loss: 2.544808702155509
Validation loss: 2.5707517517186758

Epoch: 6| Step: 4
Training loss: 2.713597029245073
Validation loss: 2.591306784277994

Epoch: 6| Step: 5
Training loss: 2.723476291890163
Validation loss: 2.566574470507277

Epoch: 6| Step: 6
Training loss: 2.8971472487761663
Validation loss: 2.5733807617553874

Epoch: 6| Step: 7
Training loss: 1.6115790524315983
Validation loss: 2.5944013352276274

Epoch: 6| Step: 8
Training loss: 1.8020629293650101
Validation loss: 2.6030688349605446

Epoch: 6| Step: 9
Training loss: 1.6560334837840878
Validation loss: 2.5971131486026353

Epoch: 6| Step: 10
Training loss: 1.5872966035318095
Validation loss: 2.5676691285726183

Epoch: 6| Step: 11
Training loss: 1.8834199677292658
Validation loss: 2.565393690368089

Epoch: 6| Step: 12
Training loss: 2.1279617314160264
Validation loss: 2.5459786848622854

Epoch: 6| Step: 13
Training loss: 2.063282904719968
Validation loss: 2.517614505920262

Epoch: 212| Step: 0
Training loss: 2.268235590181478
Validation loss: 2.512937891617554

Epoch: 6| Step: 1
Training loss: 2.0631782110240344
Validation loss: 2.5035376632068824

Epoch: 6| Step: 2
Training loss: 2.0436843581550996
Validation loss: 2.516301618925567

Epoch: 6| Step: 3
Training loss: 2.3383804866126683
Validation loss: 2.502104112177277

Epoch: 6| Step: 4
Training loss: 2.096801811112106
Validation loss: 2.501958858454634

Epoch: 6| Step: 5
Training loss: 2.2128740328564858
Validation loss: 2.499926279888411

Epoch: 6| Step: 6
Training loss: 1.7423595121168625
Validation loss: 2.4995593954284865

Epoch: 6| Step: 7
Training loss: 2.6847616039408635
Validation loss: 2.5007767344875655

Epoch: 6| Step: 8
Training loss: 2.9194116663360554
Validation loss: 2.5058877437390117

Epoch: 6| Step: 9
Training loss: 2.4828382813619747
Validation loss: 2.5050551485956745

Epoch: 6| Step: 10
Training loss: 2.510074344157121
Validation loss: 2.538681659013425

Epoch: 6| Step: 11
Training loss: 2.211826105453175
Validation loss: 2.5501228639511346

Epoch: 6| Step: 12
Training loss: 2.6790169191014885
Validation loss: 2.56203420794081

Epoch: 6| Step: 13
Training loss: 2.1949264892920666
Validation loss: 2.56495164653371

Epoch: 213| Step: 0
Training loss: 1.882971286013846
Validation loss: 2.549287990822571

Epoch: 6| Step: 1
Training loss: 2.3325644543278434
Validation loss: 2.5074890657023614

Epoch: 6| Step: 2
Training loss: 2.373520641364922
Validation loss: 2.5210321416302675

Epoch: 6| Step: 3
Training loss: 2.4750991493170926
Validation loss: 2.503458539478889

Epoch: 6| Step: 4
Training loss: 2.387352891953553
Validation loss: 2.5003212483952333

Epoch: 6| Step: 5
Training loss: 2.0538808885635844
Validation loss: 2.510317129058603

Epoch: 6| Step: 6
Training loss: 2.7941033466315655
Validation loss: 2.5180461439641917

Epoch: 6| Step: 7
Training loss: 1.8159597853102403
Validation loss: 2.527490814977119

Epoch: 6| Step: 8
Training loss: 2.656277824704909
Validation loss: 2.5326905488093763

Epoch: 6| Step: 9
Training loss: 2.2292852518738853
Validation loss: 2.5178299712055137

Epoch: 6| Step: 10
Training loss: 1.7434323913750995
Validation loss: 2.502399993305702

Epoch: 6| Step: 11
Training loss: 2.7578987778089568
Validation loss: 2.5020812748993966

Epoch: 6| Step: 12
Training loss: 2.3377957814800165
Validation loss: 2.5144586327285894

Epoch: 6| Step: 13
Training loss: 2.2696725404128997
Validation loss: 2.50491465051952

Epoch: 214| Step: 0
Training loss: 2.374795704136054
Validation loss: 2.5121011793884462

Epoch: 6| Step: 1
Training loss: 2.667510366088975
Validation loss: 2.515677836556322

Epoch: 6| Step: 2
Training loss: 2.2914751377409193
Validation loss: 2.523129407973176

Epoch: 6| Step: 3
Training loss: 2.003479077352971
Validation loss: 2.5209959676524436

Epoch: 6| Step: 4
Training loss: 2.318647924268863
Validation loss: 2.5408068177001217

Epoch: 6| Step: 5
Training loss: 1.8003871263009439
Validation loss: 2.564868049920901

Epoch: 6| Step: 6
Training loss: 2.275871311216811
Validation loss: 2.567820104883539

Epoch: 6| Step: 7
Training loss: 1.683685229442624
Validation loss: 2.5729608313184444

Epoch: 6| Step: 8
Training loss: 2.80865656712175
Validation loss: 2.5780509090373718

Epoch: 6| Step: 9
Training loss: 2.9954472009561144
Validation loss: 2.5861762052848793

Epoch: 6| Step: 10
Training loss: 2.665736145349865
Validation loss: 2.5790144031630797

Epoch: 6| Step: 11
Training loss: 1.6079323978779798
Validation loss: 2.5781895793186242

Epoch: 6| Step: 12
Training loss: 2.4574387641487663
Validation loss: 2.547814973895246

Epoch: 6| Step: 13
Training loss: 1.9334846234594296
Validation loss: 2.535584463074894

Epoch: 215| Step: 0
Training loss: 2.0207681022681774
Validation loss: 2.547568961929937

Epoch: 6| Step: 1
Training loss: 2.251519114217286
Validation loss: 2.5295997703377213

Epoch: 6| Step: 2
Training loss: 1.5828095958566337
Validation loss: 2.5367403885341706

Epoch: 6| Step: 3
Training loss: 2.7113356943688465
Validation loss: 2.545784293502093

Epoch: 6| Step: 4
Training loss: 2.0629104437053924
Validation loss: 2.5461334053752434

Epoch: 6| Step: 5
Training loss: 2.629680366529104
Validation loss: 2.5687242449407504

Epoch: 6| Step: 6
Training loss: 2.603380455863805
Validation loss: 2.5707679661911276

Epoch: 6| Step: 7
Training loss: 2.227083700648088
Validation loss: 2.56875628171278

Epoch: 6| Step: 8
Training loss: 2.3819578545442814
Validation loss: 2.560179349631915

Epoch: 6| Step: 9
Training loss: 2.326924571396335
Validation loss: 2.566926080012673

Epoch: 6| Step: 10
Training loss: 2.502526723012094
Validation loss: 2.5584622026556105

Epoch: 6| Step: 11
Training loss: 2.3755837777085675
Validation loss: 2.5488008422170885

Epoch: 6| Step: 12
Training loss: 2.123476716634507
Validation loss: 2.5237019718179443

Epoch: 6| Step: 13
Training loss: 2.287261671147625
Validation loss: 2.532588910747893

Epoch: 216| Step: 0
Training loss: 3.132452052206865
Validation loss: 2.534317591056548

Epoch: 6| Step: 1
Training loss: 2.474608122502396
Validation loss: 2.5250610466933057

Epoch: 6| Step: 2
Training loss: 2.9082129627519975
Validation loss: 2.534219201281539

Epoch: 6| Step: 3
Training loss: 1.4418743582973368
Validation loss: 2.53416380341341

Epoch: 6| Step: 4
Training loss: 2.5017021106883526
Validation loss: 2.5400340798737453

Epoch: 6| Step: 5
Training loss: 2.555915933805561
Validation loss: 2.5546176679207058

Epoch: 6| Step: 6
Training loss: 1.4461580020061284
Validation loss: 2.5601553541222066

Epoch: 6| Step: 7
Training loss: 2.4795547844045562
Validation loss: 2.5458480543178195

Epoch: 6| Step: 8
Training loss: 1.9767084482461432
Validation loss: 2.541820112401324

Epoch: 6| Step: 9
Training loss: 2.114458190021125
Validation loss: 2.531093922265402

Epoch: 6| Step: 10
Training loss: 1.973960339655062
Validation loss: 2.549483104750826

Epoch: 6| Step: 11
Training loss: 2.36056407749865
Validation loss: 2.5421568496879026

Epoch: 6| Step: 12
Training loss: 1.5979563237739662
Validation loss: 2.5601825003839505

Epoch: 6| Step: 13
Training loss: 2.489466506153479
Validation loss: 2.577827590588067

Epoch: 217| Step: 0
Training loss: 2.3052011725625783
Validation loss: 2.5607348774848866

Epoch: 6| Step: 1
Training loss: 2.2688717433747816
Validation loss: 2.5630497536555046

Epoch: 6| Step: 2
Training loss: 2.687838865695698
Validation loss: 2.545293289527345

Epoch: 6| Step: 3
Training loss: 2.162319211072905
Validation loss: 2.5592486991972176

Epoch: 6| Step: 4
Training loss: 1.9637287836610249
Validation loss: 2.590790112996776

Epoch: 6| Step: 5
Training loss: 2.938855446919876
Validation loss: 2.629730518614025

Epoch: 6| Step: 6
Training loss: 2.541287805639119
Validation loss: 2.6881668091589725

Epoch: 6| Step: 7
Training loss: 1.7564468164903073
Validation loss: 2.657241501603196

Epoch: 6| Step: 8
Training loss: 2.860145840160908
Validation loss: 2.644845663037572

Epoch: 6| Step: 9
Training loss: 1.9231104407690733
Validation loss: 2.652195817270546

Epoch: 6| Step: 10
Training loss: 1.7165127151244997
Validation loss: 2.6206742323801233

Epoch: 6| Step: 11
Training loss: 2.3448640337407536
Validation loss: 2.5630660478592993

Epoch: 6| Step: 12
Training loss: 2.2025555896130506
Validation loss: 2.5273730567675488

Epoch: 6| Step: 13
Training loss: 1.7692497652686225
Validation loss: 2.5180053979706214

Epoch: 218| Step: 0
Training loss: 2.155717203408596
Validation loss: 2.5021435925429327

Epoch: 6| Step: 1
Training loss: 1.954135175775214
Validation loss: 2.4977158761367306

Epoch: 6| Step: 2
Training loss: 2.319901144124888
Validation loss: 2.502087913295123

Epoch: 6| Step: 3
Training loss: 2.689519256687389
Validation loss: 2.508037735280975

Epoch: 6| Step: 4
Training loss: 2.6961101733768382
Validation loss: 2.512942825187136

Epoch: 6| Step: 5
Training loss: 2.1787492380233893
Validation loss: 2.5100621069358526

Epoch: 6| Step: 6
Training loss: 2.252958048694482
Validation loss: 2.506660727745826

Epoch: 6| Step: 7
Training loss: 3.0209690633513735
Validation loss: 2.512159831867509

Epoch: 6| Step: 8
Training loss: 2.2554488431912905
Validation loss: 2.49258716212758

Epoch: 6| Step: 9
Training loss: 2.683920672408417
Validation loss: 2.510288098051763

Epoch: 6| Step: 10
Training loss: 1.885486650660926
Validation loss: 2.5152267867485962

Epoch: 6| Step: 11
Training loss: 2.218029173766642
Validation loss: 2.5175651666363477

Epoch: 6| Step: 12
Training loss: 2.1964824993322956
Validation loss: 2.532219626498969

Epoch: 6| Step: 13
Training loss: 2.360489638823152
Validation loss: 2.559349301822063

Epoch: 219| Step: 0
Training loss: 2.025587787798367
Validation loss: 2.5806785498979217

Epoch: 6| Step: 1
Training loss: 2.567057580614892
Validation loss: 2.571514463125518

Epoch: 6| Step: 2
Training loss: 2.527489966005657
Validation loss: 2.583622152324061

Epoch: 6| Step: 3
Training loss: 2.4246709620042917
Validation loss: 2.601712975718117

Epoch: 6| Step: 4
Training loss: 1.7809457351753883
Validation loss: 2.5818805044610014

Epoch: 6| Step: 5
Training loss: 2.710640750880587
Validation loss: 2.5734038310038185

Epoch: 6| Step: 6
Training loss: 1.9814498848671986
Validation loss: 2.5723542024639925

Epoch: 6| Step: 7
Training loss: 2.0673681663170975
Validation loss: 2.56005749170994

Epoch: 6| Step: 8
Training loss: 2.2350386054269897
Validation loss: 2.5674458202525425

Epoch: 6| Step: 9
Training loss: 2.3306545366383307
Validation loss: 2.5660434197399233

Epoch: 6| Step: 10
Training loss: 2.445415945576765
Validation loss: 2.5416517934728815

Epoch: 6| Step: 11
Training loss: 2.298574843669591
Validation loss: 2.5540138624159106

Epoch: 6| Step: 12
Training loss: 2.7009700057035446
Validation loss: 2.558826946473779

Epoch: 6| Step: 13
Training loss: 1.739452867317309
Validation loss: 2.5572752683363675

Epoch: 220| Step: 0
Training loss: 2.818229434374602
Validation loss: 2.556906006136363

Epoch: 6| Step: 1
Training loss: 1.8986301402871844
Validation loss: 2.5631670820131403

Epoch: 6| Step: 2
Training loss: 2.0619717701811946
Validation loss: 2.5623011938370244

Epoch: 6| Step: 3
Training loss: 2.415779564811682
Validation loss: 2.5660100173288853

Epoch: 6| Step: 4
Training loss: 2.128632302113284
Validation loss: 2.5750508022543706

Epoch: 6| Step: 5
Training loss: 2.374240352209741
Validation loss: 2.582463169186085

Epoch: 6| Step: 6
Training loss: 2.196241514811574
Validation loss: 2.575010726807606

Epoch: 6| Step: 7
Training loss: 2.927100420231118
Validation loss: 2.597696465584887

Epoch: 6| Step: 8
Training loss: 2.4290568523765836
Validation loss: 2.5826637620632216

Epoch: 6| Step: 9
Training loss: 2.392827733312579
Validation loss: 2.548627784621337

Epoch: 6| Step: 10
Training loss: 1.586195600582376
Validation loss: 2.5627728293718173

Epoch: 6| Step: 11
Training loss: 1.8799175625846622
Validation loss: 2.5439055436650797

Epoch: 6| Step: 12
Training loss: 2.8220284860634495
Validation loss: 2.5487677595022764

Epoch: 6| Step: 13
Training loss: 1.8126932896118912
Validation loss: 2.523569030798113

Epoch: 221| Step: 0
Training loss: 2.222394716667668
Validation loss: 2.538877196763836

Epoch: 6| Step: 1
Training loss: 2.084790203599317
Validation loss: 2.5520079672967078

Epoch: 6| Step: 2
Training loss: 2.4860765879795514
Validation loss: 2.5551423922859504

Epoch: 6| Step: 3
Training loss: 1.3985138771042371
Validation loss: 2.5697713357600267

Epoch: 6| Step: 4
Training loss: 2.836745638287863
Validation loss: 2.566390255704497

Epoch: 6| Step: 5
Training loss: 1.623450200432305
Validation loss: 2.6210743978726843

Epoch: 6| Step: 6
Training loss: 2.548669381880189
Validation loss: 2.6322086596386676

Epoch: 6| Step: 7
Training loss: 2.0869148622117675
Validation loss: 2.6249614743024443

Epoch: 6| Step: 8
Training loss: 2.6868679279199714
Validation loss: 2.626861290821429

Epoch: 6| Step: 9
Training loss: 2.2024688825888035
Validation loss: 2.621774856903999

Epoch: 6| Step: 10
Training loss: 2.521538838005924
Validation loss: 2.6210849418814295

Epoch: 6| Step: 11
Training loss: 1.9333686466390114
Validation loss: 2.6009498615636484

Epoch: 6| Step: 12
Training loss: 2.620410176266747
Validation loss: 2.5620765956513587

Epoch: 6| Step: 13
Training loss: 2.3727858411601863
Validation loss: 2.534297780131694

Epoch: 222| Step: 0
Training loss: 2.2647183412831358
Validation loss: 2.48985979042915

Epoch: 6| Step: 1
Training loss: 2.274178400602317
Validation loss: 2.4890072261071414

Epoch: 6| Step: 2
Training loss: 2.287253332127504
Validation loss: 2.483645190001934

Epoch: 6| Step: 3
Training loss: 2.188502381771222
Validation loss: 2.470845801615228

Epoch: 6| Step: 4
Training loss: 2.3234932929332737
Validation loss: 2.4746856476977976

Epoch: 6| Step: 5
Training loss: 2.5923564798326395
Validation loss: 2.4716316096888638

Epoch: 6| Step: 6
Training loss: 2.158776171801172
Validation loss: 2.468368597386188

Epoch: 6| Step: 7
Training loss: 1.9938436169304787
Validation loss: 2.4809105507192237

Epoch: 6| Step: 8
Training loss: 2.1335322803874046
Validation loss: 2.4919265084244904

Epoch: 6| Step: 9
Training loss: 2.3340756961083278
Validation loss: 2.500622385753513

Epoch: 6| Step: 10
Training loss: 2.081426879881377
Validation loss: 2.5120874809584803

Epoch: 6| Step: 11
Training loss: 2.8772693468014023
Validation loss: 2.5286724483347793

Epoch: 6| Step: 12
Training loss: 2.209558710772379
Validation loss: 2.536801658961775

Epoch: 6| Step: 13
Training loss: 2.4086978896026925
Validation loss: 2.5971122764893493

Epoch: 223| Step: 0
Training loss: 2.1765700713256684
Validation loss: 2.6025328330131825

Epoch: 6| Step: 1
Training loss: 2.648795404697627
Validation loss: 2.6441457628044382

Epoch: 6| Step: 2
Training loss: 2.354700067457494
Validation loss: 2.6504677161837815

Epoch: 6| Step: 3
Training loss: 2.059873121854161
Validation loss: 2.6721217467235943

Epoch: 6| Step: 4
Training loss: 2.3660344000127
Validation loss: 2.641366647556783

Epoch: 6| Step: 5
Training loss: 2.0510084044583268
Validation loss: 2.6525005281132046

Epoch: 6| Step: 6
Training loss: 1.8243952467691085
Validation loss: 2.648552531067031

Epoch: 6| Step: 7
Training loss: 2.493107067014013
Validation loss: 2.6115301373144058

Epoch: 6| Step: 8
Training loss: 2.466462342932733
Validation loss: 2.569974063440603

Epoch: 6| Step: 9
Training loss: 2.3416634999680292
Validation loss: 2.5595709490105163

Epoch: 6| Step: 10
Training loss: 2.496300248512806
Validation loss: 2.540522612338133

Epoch: 6| Step: 11
Training loss: 2.642242207290718
Validation loss: 2.530823204573769

Epoch: 6| Step: 12
Training loss: 1.5279255805142617
Validation loss: 2.5331955955940533

Epoch: 6| Step: 13
Training loss: 1.9861103789973595
Validation loss: 2.5146311500720495

Epoch: 224| Step: 0
Training loss: 2.2861659761717803
Validation loss: 2.4903781585073386

Epoch: 6| Step: 1
Training loss: 1.8303879645540455
Validation loss: 2.501053175025232

Epoch: 6| Step: 2
Training loss: 2.1189592556314922
Validation loss: 2.5073711763545483

Epoch: 6| Step: 3
Training loss: 2.4554337249306597
Validation loss: 2.5341607614348263

Epoch: 6| Step: 4
Training loss: 2.3019744939377036
Validation loss: 2.5499382398020165

Epoch: 6| Step: 5
Training loss: 2.6155880723759752
Validation loss: 2.593604225443803

Epoch: 6| Step: 6
Training loss: 2.0812424530717264
Validation loss: 2.625387193491874

Epoch: 6| Step: 7
Training loss: 1.9307334011440664
Validation loss: 2.6693405564048795

Epoch: 6| Step: 8
Training loss: 2.728574693459588
Validation loss: 2.6354020360809436

Epoch: 6| Step: 9
Training loss: 1.9610161024655122
Validation loss: 2.5668130413856973

Epoch: 6| Step: 10
Training loss: 3.059720549196015
Validation loss: 2.5341665004222964

Epoch: 6| Step: 11
Training loss: 2.5096675868497753
Validation loss: 2.512451618671362

Epoch: 6| Step: 12
Training loss: 2.405691800457374
Validation loss: 2.5075088111111574

Epoch: 6| Step: 13
Training loss: 2.019832389411839
Validation loss: 2.497381070398022

Epoch: 225| Step: 0
Training loss: 2.189807655562327
Validation loss: 2.5026605595094322

Epoch: 6| Step: 1
Training loss: 2.119919481727735
Validation loss: 2.500551147107684

Epoch: 6| Step: 2
Training loss: 2.6386166671974833
Validation loss: 2.4929108880258877

Epoch: 6| Step: 3
Training loss: 2.3026043286539566
Validation loss: 2.5186591953162063

Epoch: 6| Step: 4
Training loss: 1.8865207228585268
Validation loss: 2.523203442311484

Epoch: 6| Step: 5
Training loss: 2.042184828834567
Validation loss: 2.5411674499113537

Epoch: 6| Step: 6
Training loss: 2.3440318637478845
Validation loss: 2.557322800415048

Epoch: 6| Step: 7
Training loss: 2.112519019227496
Validation loss: 2.5886143393392427

Epoch: 6| Step: 8
Training loss: 2.712994325659302
Validation loss: 2.5823074016166023

Epoch: 6| Step: 9
Training loss: 2.564228033456123
Validation loss: 2.6231561648886967

Epoch: 6| Step: 10
Training loss: 2.211913200192989
Validation loss: 2.6483048637433146

Epoch: 6| Step: 11
Training loss: 1.9461777076696574
Validation loss: 2.6512750299313277

Epoch: 6| Step: 12
Training loss: 2.0551095971353432
Validation loss: 2.645626320337317

Epoch: 6| Step: 13
Training loss: 2.954076543024215
Validation loss: 2.598338713902385

Epoch: 226| Step: 0
Training loss: 2.4592455663878585
Validation loss: 2.5572721450796045

Epoch: 6| Step: 1
Training loss: 2.438895779568326
Validation loss: 2.532708662172747

Epoch: 6| Step: 2
Training loss: 2.5257686087247455
Validation loss: 2.5187294958398576

Epoch: 6| Step: 3
Training loss: 2.042631920204418
Validation loss: 2.4922918857888035

Epoch: 6| Step: 4
Training loss: 2.4139061540757574
Validation loss: 2.5138833155374116

Epoch: 6| Step: 5
Training loss: 2.1288020957176674
Validation loss: 2.4868764380097494

Epoch: 6| Step: 6
Training loss: 2.2556660623002327
Validation loss: 2.525334372586027

Epoch: 6| Step: 7
Training loss: 1.9243566726153785
Validation loss: 2.5263229580548847

Epoch: 6| Step: 8
Training loss: 2.3721004655349884
Validation loss: 2.513650549753939

Epoch: 6| Step: 9
Training loss: 2.7624414083904187
Validation loss: 2.505021329523726

Epoch: 6| Step: 10
Training loss: 2.2209025941775806
Validation loss: 2.5222918859552976

Epoch: 6| Step: 11
Training loss: 2.045953674299086
Validation loss: 2.5163237428605782

Epoch: 6| Step: 12
Training loss: 2.1400683716520503
Validation loss: 2.5202187874090427

Epoch: 6| Step: 13
Training loss: 2.052019366769695
Validation loss: 2.532862616609339

Epoch: 227| Step: 0
Training loss: 1.7877534966683337
Validation loss: 2.5342698313336753

Epoch: 6| Step: 1
Training loss: 2.2794057628834876
Validation loss: 2.5619208138780607

Epoch: 6| Step: 2
Training loss: 2.319685931651672
Validation loss: 2.568850672621661

Epoch: 6| Step: 3
Training loss: 2.570294968565544
Validation loss: 2.5524479248782512

Epoch: 6| Step: 4
Training loss: 2.441467675008533
Validation loss: 2.5598191449982335

Epoch: 6| Step: 5
Training loss: 2.3168211078164362
Validation loss: 2.56645653925551

Epoch: 6| Step: 6
Training loss: 1.6879749336189442
Validation loss: 2.558492845870316

Epoch: 6| Step: 7
Training loss: 2.5509582738510637
Validation loss: 2.553447083943203

Epoch: 6| Step: 8
Training loss: 2.484428357205126
Validation loss: 2.561616342042376

Epoch: 6| Step: 9
Training loss: 2.544207902414425
Validation loss: 2.5248387307262488

Epoch: 6| Step: 10
Training loss: 2.430511531128375
Validation loss: 2.549960554977213

Epoch: 6| Step: 11
Training loss: 2.3798092786521337
Validation loss: 2.5800541297399366

Epoch: 6| Step: 12
Training loss: 2.3710643885898306
Validation loss: 2.5724384362775545

Epoch: 6| Step: 13
Training loss: 1.4162098297590395
Validation loss: 2.5931045770963377

Epoch: 228| Step: 0
Training loss: 1.8814898391883152
Validation loss: 2.608578208137484

Epoch: 6| Step: 1
Training loss: 2.6507440386205663
Validation loss: 2.574738360819091

Epoch: 6| Step: 2
Training loss: 2.0692801726794836
Validation loss: 2.5544471355445446

Epoch: 6| Step: 3
Training loss: 2.602011335449392
Validation loss: 2.543206800968828

Epoch: 6| Step: 4
Training loss: 2.6254874185621375
Validation loss: 2.517189550290416

Epoch: 6| Step: 5
Training loss: 2.104284176204838
Validation loss: 2.533450061426124

Epoch: 6| Step: 6
Training loss: 2.6075926764048174
Validation loss: 2.5429535458564856

Epoch: 6| Step: 7
Training loss: 2.080405683202596
Validation loss: 2.557985640227272

Epoch: 6| Step: 8
Training loss: 2.116205980324143
Validation loss: 2.5602832215196902

Epoch: 6| Step: 9
Training loss: 2.65081734198462
Validation loss: 2.590135023827035

Epoch: 6| Step: 10
Training loss: 1.7101517357903888
Validation loss: 2.6164831627648404

Epoch: 6| Step: 11
Training loss: 1.8166948642933824
Validation loss: 2.63501041784284

Epoch: 6| Step: 12
Training loss: 1.9956686085978848
Validation loss: 2.6327158365889582

Epoch: 6| Step: 13
Training loss: 2.528712943876164
Validation loss: 2.6251810707735452

Epoch: 229| Step: 0
Training loss: 2.4114340883248717
Validation loss: 2.57524672625566

Epoch: 6| Step: 1
Training loss: 1.8441606484562165
Validation loss: 2.599365880249589

Epoch: 6| Step: 2
Training loss: 1.7818451941066902
Validation loss: 2.584947655920734

Epoch: 6| Step: 3
Training loss: 2.4548437815451254
Validation loss: 2.550770360856232

Epoch: 6| Step: 4
Training loss: 1.8312830586753133
Validation loss: 2.548866304815618

Epoch: 6| Step: 5
Training loss: 1.952533357655215
Validation loss: 2.5465154491544895

Epoch: 6| Step: 6
Training loss: 2.168312499141465
Validation loss: 2.525084557392145

Epoch: 6| Step: 7
Training loss: 2.724558621279075
Validation loss: 2.5507195286588114

Epoch: 6| Step: 8
Training loss: 2.4884651152081987
Validation loss: 2.540065860570262

Epoch: 6| Step: 9
Training loss: 2.744029934099816
Validation loss: 2.546729896952126

Epoch: 6| Step: 10
Training loss: 1.8952245328636557
Validation loss: 2.5533148201237252

Epoch: 6| Step: 11
Training loss: 2.8599677800317655
Validation loss: 2.543913603699137

Epoch: 6| Step: 12
Training loss: 1.883986617468018
Validation loss: 2.5640892589969715

Epoch: 6| Step: 13
Training loss: 1.80184818857856
Validation loss: 2.5643452459201024

Epoch: 230| Step: 0
Training loss: 2.3568384543706005
Validation loss: 2.5565245048044365

Epoch: 6| Step: 1
Training loss: 1.9758306663792293
Validation loss: 2.5515930846717847

Epoch: 6| Step: 2
Training loss: 2.7887562816075495
Validation loss: 2.5888274103536233

Epoch: 6| Step: 3
Training loss: 1.798322608651798
Validation loss: 2.5574348834322476

Epoch: 6| Step: 4
Training loss: 2.1002214542061424
Validation loss: 2.5405494756918054

Epoch: 6| Step: 5
Training loss: 1.9820235129307995
Validation loss: 2.526304539376928

Epoch: 6| Step: 6
Training loss: 2.4978520702910676
Validation loss: 2.5265904777517525

Epoch: 6| Step: 7
Training loss: 2.354247122771032
Validation loss: 2.524955253708183

Epoch: 6| Step: 8
Training loss: 2.6904132932520013
Validation loss: 2.518301241190746

Epoch: 6| Step: 9
Training loss: 2.282435905835168
Validation loss: 2.5244299134888797

Epoch: 6| Step: 10
Training loss: 1.28356960875272
Validation loss: 2.52115361619688

Epoch: 6| Step: 11
Training loss: 1.9019620853259231
Validation loss: 2.520900005583328

Epoch: 6| Step: 12
Training loss: 2.480836663782637
Validation loss: 2.5228626868103703

Epoch: 6| Step: 13
Training loss: 2.77221076591773
Validation loss: 2.5277589263376092

Epoch: 231| Step: 0
Training loss: 2.2620287536156205
Validation loss: 2.547336435155204

Epoch: 6| Step: 1
Training loss: 2.103611057564194
Validation loss: 2.5879392991196957

Epoch: 6| Step: 2
Training loss: 2.2707269509504453
Validation loss: 2.595133094779995

Epoch: 6| Step: 3
Training loss: 2.1078692678126907
Validation loss: 2.60913808207742

Epoch: 6| Step: 4
Training loss: 2.3264143630826655
Validation loss: 2.5982696803209655

Epoch: 6| Step: 5
Training loss: 2.8658974887166706
Validation loss: 2.595812517534767

Epoch: 6| Step: 6
Training loss: 2.5882919057988847
Validation loss: 2.55336034056654

Epoch: 6| Step: 7
Training loss: 2.134414909291275
Validation loss: 2.5072301899613634

Epoch: 6| Step: 8
Training loss: 2.2955372346530805
Validation loss: 2.4961387538683493

Epoch: 6| Step: 9
Training loss: 2.4400227525306875
Validation loss: 2.4760147034414444

Epoch: 6| Step: 10
Training loss: 2.1312577725713404
Validation loss: 2.4709519332632093

Epoch: 6| Step: 11
Training loss: 2.110390877699495
Validation loss: 2.4701146245401047

Epoch: 6| Step: 12
Training loss: 2.312350809594444
Validation loss: 2.4402218155537443

Epoch: 6| Step: 13
Training loss: 1.996236717643334
Validation loss: 2.4464780976841634

Epoch: 232| Step: 0
Training loss: 2.2706315070473013
Validation loss: 2.451679168122983

Epoch: 6| Step: 1
Training loss: 2.4617075850543184
Validation loss: 2.4695030222857084

Epoch: 6| Step: 2
Training loss: 2.0594440130267557
Validation loss: 2.4832229182212755

Epoch: 6| Step: 3
Training loss: 2.555939813648524
Validation loss: 2.4782796336061854

Epoch: 6| Step: 4
Training loss: 2.497287423038566
Validation loss: 2.4873206311960376

Epoch: 6| Step: 5
Training loss: 2.0391971938271443
Validation loss: 2.509306022231241

Epoch: 6| Step: 6
Training loss: 2.421847435579026
Validation loss: 2.514027690626711

Epoch: 6| Step: 7
Training loss: 1.9268556271302073
Validation loss: 2.540876098836756

Epoch: 6| Step: 8
Training loss: 2.727234590870642
Validation loss: 2.540248355262889

Epoch: 6| Step: 9
Training loss: 2.742058297180999
Validation loss: 2.5258854506387127

Epoch: 6| Step: 10
Training loss: 2.2848677493832397
Validation loss: 2.5387431878042803

Epoch: 6| Step: 11
Training loss: 1.4123097722063944
Validation loss: 2.5184607466707845

Epoch: 6| Step: 12
Training loss: 1.8867953267165556
Validation loss: 2.4926856010559924

Epoch: 6| Step: 13
Training loss: 2.2389534944353224
Validation loss: 2.502666005545874

Epoch: 233| Step: 0
Training loss: 2.4490152910283998
Validation loss: 2.5190244652929406

Epoch: 6| Step: 1
Training loss: 2.3369318144044726
Validation loss: 2.504231130835513

Epoch: 6| Step: 2
Training loss: 1.893315190420845
Validation loss: 2.5064882483885085

Epoch: 6| Step: 3
Training loss: 2.026954569423688
Validation loss: 2.4965376879537087

Epoch: 6| Step: 4
Training loss: 2.364038973311139
Validation loss: 2.5090309106679527

Epoch: 6| Step: 5
Training loss: 2.1932805659469774
Validation loss: 2.505917904002552

Epoch: 6| Step: 6
Training loss: 2.6899132650069775
Validation loss: 2.5102756402594024

Epoch: 6| Step: 7
Training loss: 2.2268934572768084
Validation loss: 2.5251776538331465

Epoch: 6| Step: 8
Training loss: 2.600574660984048
Validation loss: 2.5390524370042975

Epoch: 6| Step: 9
Training loss: 2.28247873319347
Validation loss: 2.5704157227850266

Epoch: 6| Step: 10
Training loss: 2.0598052945758005
Validation loss: 2.535554969127044

Epoch: 6| Step: 11
Training loss: 1.9161202716150647
Validation loss: 2.5402885254867256

Epoch: 6| Step: 12
Training loss: 2.2255819738268237
Validation loss: 2.58743241386172

Epoch: 6| Step: 13
Training loss: 1.9378643308615389
Validation loss: 2.6371202855427627

Epoch: 234| Step: 0
Training loss: 2.0308292833532313
Validation loss: 2.646689559283409

Epoch: 6| Step: 1
Training loss: 2.251081842372589
Validation loss: 2.64016645915798

Epoch: 6| Step: 2
Training loss: 2.452248677977786
Validation loss: 2.597570585210292

Epoch: 6| Step: 3
Training loss: 1.7920081530283336
Validation loss: 2.5533733507046685

Epoch: 6| Step: 4
Training loss: 3.1037033725267285
Validation loss: 2.5288252185766846

Epoch: 6| Step: 5
Training loss: 1.6240286491526044
Validation loss: 2.5095874213495155

Epoch: 6| Step: 6
Training loss: 2.387832506602974
Validation loss: 2.4974542689854045

Epoch: 6| Step: 7
Training loss: 1.687434301157066
Validation loss: 2.506060010727832

Epoch: 6| Step: 8
Training loss: 2.0723574345679094
Validation loss: 2.5174616551691082

Epoch: 6| Step: 9
Training loss: 2.546328620577031
Validation loss: 2.5421050793198523

Epoch: 6| Step: 10
Training loss: 2.4896368768486004
Validation loss: 2.575436772336573

Epoch: 6| Step: 11
Training loss: 2.744480923767566
Validation loss: 2.5976415648081144

Epoch: 6| Step: 12
Training loss: 1.9635644467868074
Validation loss: 2.617064880231537

Epoch: 6| Step: 13
Training loss: 1.5644218832223085
Validation loss: 2.621650602538439

Epoch: 235| Step: 0
Training loss: 2.2072386517593228
Validation loss: 2.6322492379946976

Epoch: 6| Step: 1
Training loss: 2.240233630019765
Validation loss: 2.6365067460342586

Epoch: 6| Step: 2
Training loss: 2.8066560854980405
Validation loss: 2.665159385595665

Epoch: 6| Step: 3
Training loss: 1.787345095238028
Validation loss: 2.6574761346969735

Epoch: 6| Step: 4
Training loss: 2.135814300980187
Validation loss: 2.659942543680819

Epoch: 6| Step: 5
Training loss: 1.4325921408161153
Validation loss: 2.6221665651827375

Epoch: 6| Step: 6
Training loss: 2.121257178542265
Validation loss: 2.5338717254521663

Epoch: 6| Step: 7
Training loss: 2.2448162127669966
Validation loss: 2.5456511632628627

Epoch: 6| Step: 8
Training loss: 3.0419492372569827
Validation loss: 2.4952846244476405

Epoch: 6| Step: 9
Training loss: 2.655193971635228
Validation loss: 2.4881219258944607

Epoch: 6| Step: 10
Training loss: 1.6386227696987254
Validation loss: 2.4862493965527936

Epoch: 6| Step: 11
Training loss: 2.3564313500026666
Validation loss: 2.4569506770974328

Epoch: 6| Step: 12
Training loss: 2.0853576997339913
Validation loss: 2.4578243687806527

Epoch: 6| Step: 13
Training loss: 2.167414853932641
Validation loss: 2.467503953497031

Epoch: 236| Step: 0
Training loss: 2.5874303098867237
Validation loss: 2.45951556749633

Epoch: 6| Step: 1
Training loss: 1.9404643362375824
Validation loss: 2.478483928841483

Epoch: 6| Step: 2
Training loss: 2.0714148699490513
Validation loss: 2.49550526606313

Epoch: 6| Step: 3
Training loss: 2.29594506362826
Validation loss: 2.5014880281856127

Epoch: 6| Step: 4
Training loss: 2.366081054750176
Validation loss: 2.504846793963647

Epoch: 6| Step: 5
Training loss: 2.629043824902517
Validation loss: 2.537538746129268

Epoch: 6| Step: 6
Training loss: 2.1287249286673777
Validation loss: 2.5609110736395038

Epoch: 6| Step: 7
Training loss: 1.9270541489599304
Validation loss: 2.558625199219291

Epoch: 6| Step: 8
Training loss: 2.5157493418416235
Validation loss: 2.5837454979766123

Epoch: 6| Step: 9
Training loss: 2.2189659765728695
Validation loss: 2.5857185509256877

Epoch: 6| Step: 10
Training loss: 2.058340675968968
Validation loss: 2.550102653805785

Epoch: 6| Step: 11
Training loss: 2.1451434041706365
Validation loss: 2.5730844563948545

Epoch: 6| Step: 12
Training loss: 2.2495608431016945
Validation loss: 2.5679829871643065

Epoch: 6| Step: 13
Training loss: 2.22940192956811
Validation loss: 2.5492572993111997

Epoch: 237| Step: 0
Training loss: 1.8859036345392388
Validation loss: 2.5713646000266754

Epoch: 6| Step: 1
Training loss: 1.9040369413943459
Validation loss: 2.5446497082916806

Epoch: 6| Step: 2
Training loss: 2.4410411836430983
Validation loss: 2.535299131562801

Epoch: 6| Step: 3
Training loss: 2.195566617437614
Validation loss: 2.5281939484161624

Epoch: 6| Step: 4
Training loss: 2.614617842690949
Validation loss: 2.4971174470135122

Epoch: 6| Step: 5
Training loss: 2.517305464440112
Validation loss: 2.498863231974258

Epoch: 6| Step: 6
Training loss: 2.733811325829633
Validation loss: 2.5160237819596856

Epoch: 6| Step: 7
Training loss: 2.369080444477305
Validation loss: 2.525662459917187

Epoch: 6| Step: 8
Training loss: 2.368999127897889
Validation loss: 2.565105834547298

Epoch: 6| Step: 9
Training loss: 2.3796331488350613
Validation loss: 2.600089250768886

Epoch: 6| Step: 10
Training loss: 2.1502419402148076
Validation loss: 2.6214217972262652

Epoch: 6| Step: 11
Training loss: 1.7539751680762963
Validation loss: 2.635638820698497

Epoch: 6| Step: 12
Training loss: 1.9510644648316864
Validation loss: 2.6342612034182706

Epoch: 6| Step: 13
Training loss: 1.9758394147547922
Validation loss: 2.598779711704092

Epoch: 238| Step: 0
Training loss: 2.614040657859706
Validation loss: 2.5826234585627397

Epoch: 6| Step: 1
Training loss: 2.166273069088285
Validation loss: 2.5360830030616452

Epoch: 6| Step: 2
Training loss: 2.061563683879999
Validation loss: 2.5290189887415324

Epoch: 6| Step: 3
Training loss: 2.535426144567833
Validation loss: 2.529118947726393

Epoch: 6| Step: 4
Training loss: 1.9721530385785133
Validation loss: 2.537046812018812

Epoch: 6| Step: 5
Training loss: 1.5965554471923211
Validation loss: 2.542923496701163

Epoch: 6| Step: 6
Training loss: 2.2226845684158216
Validation loss: 2.5625216165266633

Epoch: 6| Step: 7
Training loss: 2.1281537607184906
Validation loss: 2.562972064072018

Epoch: 6| Step: 8
Training loss: 2.4737203276070456
Validation loss: 2.5863405280465668

Epoch: 6| Step: 9
Training loss: 2.0692336240339126
Validation loss: 2.572514542469654

Epoch: 6| Step: 10
Training loss: 1.9978631047881215
Validation loss: 2.5560086846022503

Epoch: 6| Step: 11
Training loss: 2.3014408325439706
Validation loss: 2.535745467026879

Epoch: 6| Step: 12
Training loss: 3.0610382328331363
Validation loss: 2.5266635457005346

Epoch: 6| Step: 13
Training loss: 1.6495596876165601
Validation loss: 2.4980618752552872

Epoch: 239| Step: 0
Training loss: 2.23841013379206
Validation loss: 2.4855947639072133

Epoch: 6| Step: 1
Training loss: 1.6259253141557655
Validation loss: 2.512323681415719

Epoch: 6| Step: 2
Training loss: 1.9725018431409533
Validation loss: 2.505991463711857

Epoch: 6| Step: 3
Training loss: 2.519559638284838
Validation loss: 2.5100768295880456

Epoch: 6| Step: 4
Training loss: 2.229452406018277
Validation loss: 2.5160690136911787

Epoch: 6| Step: 5
Training loss: 1.641069115972587
Validation loss: 2.5325916094339154

Epoch: 6| Step: 6
Training loss: 2.2073741005132543
Validation loss: 2.601129421352281

Epoch: 6| Step: 7
Training loss: 2.245520477113216
Validation loss: 2.6410181027559574

Epoch: 6| Step: 8
Training loss: 2.365134781269206
Validation loss: 2.6453355686408386

Epoch: 6| Step: 9
Training loss: 2.078808206097729
Validation loss: 2.663170897440378

Epoch: 6| Step: 10
Training loss: 2.7441430577168933
Validation loss: 2.729723623582991

Epoch: 6| Step: 11
Training loss: 2.9119898402487454
Validation loss: 2.755298899055674

Epoch: 6| Step: 12
Training loss: 2.7605350013176353
Validation loss: 2.7635830526827334

Epoch: 6| Step: 13
Training loss: 1.8359806786187465
Validation loss: 2.6979939782297184

Epoch: 240| Step: 0
Training loss: 2.2876886925755837
Validation loss: 2.643167840155386

Epoch: 6| Step: 1
Training loss: 2.2195703843401855
Validation loss: 2.561831177678462

Epoch: 6| Step: 2
Training loss: 2.667852396403628
Validation loss: 2.4921113324459365

Epoch: 6| Step: 3
Training loss: 2.3303983712894865
Validation loss: 2.4677229889842023

Epoch: 6| Step: 4
Training loss: 1.4313548220434074
Validation loss: 2.469486593461988

Epoch: 6| Step: 5
Training loss: 2.918288043629487
Validation loss: 2.488065094394742

Epoch: 6| Step: 6
Training loss: 2.424909302893265
Validation loss: 2.4927150124187922

Epoch: 6| Step: 7
Training loss: 3.027346585180124
Validation loss: 2.491368971512157

Epoch: 6| Step: 8
Training loss: 2.504678449418058
Validation loss: 2.465393037444784

Epoch: 6| Step: 9
Training loss: 2.4503566404516044
Validation loss: 2.4821802677499183

Epoch: 6| Step: 10
Training loss: 2.7228532717115
Validation loss: 2.463783418972917

Epoch: 6| Step: 11
Training loss: 2.0526423846538258
Validation loss: 2.43699593508004

Epoch: 6| Step: 12
Training loss: 2.417938380135407
Validation loss: 2.438623625822692

Epoch: 6| Step: 13
Training loss: 1.9455466378493724
Validation loss: 2.4246953969562095

Epoch: 241| Step: 0
Training loss: 2.385241861615572
Validation loss: 2.454302592202311

Epoch: 6| Step: 1
Training loss: 1.7259017577606803
Validation loss: 2.5062385206839592

Epoch: 6| Step: 2
Training loss: 1.9871625169892375
Validation loss: 2.5351507640401127

Epoch: 6| Step: 3
Training loss: 1.9859116979524063
Validation loss: 2.60307489524757

Epoch: 6| Step: 4
Training loss: 1.7582428129980308
Validation loss: 2.6573853403825094

Epoch: 6| Step: 5
Training loss: 2.2494342940502867
Validation loss: 2.6825619212668452

Epoch: 6| Step: 6
Training loss: 2.7054805304821308
Validation loss: 2.6920331530274852

Epoch: 6| Step: 7
Training loss: 2.1767580315584234
Validation loss: 2.7018689892375725

Epoch: 6| Step: 8
Training loss: 2.737971790366239
Validation loss: 2.676229813375039

Epoch: 6| Step: 9
Training loss: 3.176334947503249
Validation loss: 2.6348750094327147

Epoch: 6| Step: 10
Training loss: 2.310810399767648
Validation loss: 2.6274556224159324

Epoch: 6| Step: 11
Training loss: 2.0541281283195825
Validation loss: 2.5998595872279697

Epoch: 6| Step: 12
Training loss: 1.9829061283163658
Validation loss: 2.5532408496186365

Epoch: 6| Step: 13
Training loss: 2.1844619362575886
Validation loss: 2.5309286031249894

Epoch: 242| Step: 0
Training loss: 2.459942522695565
Validation loss: 2.522085987263818

Epoch: 6| Step: 1
Training loss: 1.8816375865440553
Validation loss: 2.5353710395094833

Epoch: 6| Step: 2
Training loss: 2.0394416544265987
Validation loss: 2.52792285728755

Epoch: 6| Step: 3
Training loss: 2.2654684078427563
Validation loss: 2.5463964796747844

Epoch: 6| Step: 4
Training loss: 2.249439169606235
Validation loss: 2.5487596290709567

Epoch: 6| Step: 5
Training loss: 2.116413270495808
Validation loss: 2.544091277227416

Epoch: 6| Step: 6
Training loss: 2.0822541938782555
Validation loss: 2.56052562977357

Epoch: 6| Step: 7
Training loss: 2.4471855424472
Validation loss: 2.5875607070312814

Epoch: 6| Step: 8
Training loss: 1.9613313925236673
Validation loss: 2.581503224979356

Epoch: 6| Step: 9
Training loss: 2.204032224173806
Validation loss: 2.584161569253453

Epoch: 6| Step: 10
Training loss: 1.88377843115196
Validation loss: 2.588518880722081

Epoch: 6| Step: 11
Training loss: 2.8205999085290596
Validation loss: 2.5703029071972834

Epoch: 6| Step: 12
Training loss: 1.4716373227406363
Validation loss: 2.5484355677806483

Epoch: 6| Step: 13
Training loss: 2.928609827833274
Validation loss: 2.5135532322499086

Epoch: 243| Step: 0
Training loss: 2.8467512118480256
Validation loss: 2.4961819103354794

Epoch: 6| Step: 1
Training loss: 1.9607842982049082
Validation loss: 2.4848323297125234

Epoch: 6| Step: 2
Training loss: 1.3998386034576578
Validation loss: 2.487807966941419

Epoch: 6| Step: 3
Training loss: 2.8162393930559677
Validation loss: 2.4911592409120176

Epoch: 6| Step: 4
Training loss: 2.265975714537402
Validation loss: 2.475524624699159

Epoch: 6| Step: 5
Training loss: 2.0896832270783223
Validation loss: 2.4821846221070856

Epoch: 6| Step: 6
Training loss: 2.4605513012318303
Validation loss: 2.4883361043827326

Epoch: 6| Step: 7
Training loss: 2.0846352387586458
Validation loss: 2.5033703020653366

Epoch: 6| Step: 8
Training loss: 2.244830338454023
Validation loss: 2.51499284972027

Epoch: 6| Step: 9
Training loss: 2.6936447512429025
Validation loss: 2.5260528931253567

Epoch: 6| Step: 10
Training loss: 1.6305849495440106
Validation loss: 2.5427186045008807

Epoch: 6| Step: 11
Training loss: 1.952823279917694
Validation loss: 2.5167307664484833

Epoch: 6| Step: 12
Training loss: 1.7213416240964268
Validation loss: 2.5199439841811255

Epoch: 6| Step: 13
Training loss: 2.514615253118421
Validation loss: 2.570989332200952

Epoch: 244| Step: 0
Training loss: 2.0230585280968687
Validation loss: 2.58531687070272

Epoch: 6| Step: 1
Training loss: 1.9796978957001865
Validation loss: 2.6016016318554236

Epoch: 6| Step: 2
Training loss: 2.901295037337078
Validation loss: 2.57580540662782

Epoch: 6| Step: 3
Training loss: 2.6524472111114963
Validation loss: 2.580357873551647

Epoch: 6| Step: 4
Training loss: 2.043893404254567
Validation loss: 2.6141389922636105

Epoch: 6| Step: 5
Training loss: 2.489016916704144
Validation loss: 2.6269879911961675

Epoch: 6| Step: 6
Training loss: 1.7601362001214296
Validation loss: 2.6344340808378

Epoch: 6| Step: 7
Training loss: 2.1192115033509653
Validation loss: 2.6183606834812414

Epoch: 6| Step: 8
Training loss: 1.4771906409765865
Validation loss: 2.6202260763845473

Epoch: 6| Step: 9
Training loss: 2.5458064733941552
Validation loss: 2.5984663003842057

Epoch: 6| Step: 10
Training loss: 2.4609807086360527
Validation loss: 2.6054414655256712

Epoch: 6| Step: 11
Training loss: 1.9563052721106664
Validation loss: 2.5825151460393614

Epoch: 6| Step: 12
Training loss: 2.1670929660545135
Validation loss: 2.5937503983217725

Epoch: 6| Step: 13
Training loss: 1.676936607181746
Validation loss: 2.606307703442087

Epoch: 245| Step: 0
Training loss: 2.280701035590837
Validation loss: 2.59499472506703

Epoch: 6| Step: 1
Training loss: 2.4873435081444915
Validation loss: 2.5872292725591652

Epoch: 6| Step: 2
Training loss: 1.7013969403895994
Validation loss: 2.6147731443609312

Epoch: 6| Step: 3
Training loss: 2.4281631054336845
Validation loss: 2.631652923807407

Epoch: 6| Step: 4
Training loss: 2.3018545552033793
Validation loss: 2.668543949555569

Epoch: 6| Step: 5
Training loss: 2.5469712315265034
Validation loss: 2.681715750979039

Epoch: 6| Step: 6
Training loss: 2.650521237915592
Validation loss: 2.704767819451064

Epoch: 6| Step: 7
Training loss: 2.191278300910456
Validation loss: 2.6815728912727135

Epoch: 6| Step: 8
Training loss: 2.203995661120289
Validation loss: 2.6578775543318787

Epoch: 6| Step: 9
Training loss: 2.572433385106986
Validation loss: 2.600790709301396

Epoch: 6| Step: 10
Training loss: 1.9104034326303656
Validation loss: 2.582815461908032

Epoch: 6| Step: 11
Training loss: 2.2639206362047437
Validation loss: 2.543840133044907

Epoch: 6| Step: 12
Training loss: 1.5597118678909396
Validation loss: 2.5292591381817253

Epoch: 6| Step: 13
Training loss: 1.7473218042768814
Validation loss: 2.5214589868947233

Epoch: 246| Step: 0
Training loss: 2.3651670388071877
Validation loss: 2.516183068588146

Epoch: 6| Step: 1
Training loss: 1.7426872734017962
Validation loss: 2.501423470237321

Epoch: 6| Step: 2
Training loss: 1.7654794278519523
Validation loss: 2.541732151459468

Epoch: 6| Step: 3
Training loss: 1.7194966861729526
Validation loss: 2.5217175286032414

Epoch: 6| Step: 4
Training loss: 2.0570820246890564
Validation loss: 2.5459796759400266

Epoch: 6| Step: 5
Training loss: 2.2615736946144107
Validation loss: 2.592114434602686

Epoch: 6| Step: 6
Training loss: 1.8537385281949303
Validation loss: 2.6022823128366595

Epoch: 6| Step: 7
Training loss: 2.3603368150268498
Validation loss: 2.639860264422702

Epoch: 6| Step: 8
Training loss: 2.6148615735907987
Validation loss: 2.661528589524494

Epoch: 6| Step: 9
Training loss: 2.701350075890466
Validation loss: 2.679243697922392

Epoch: 6| Step: 10
Training loss: 2.230780317521814
Validation loss: 2.6605862696114255

Epoch: 6| Step: 11
Training loss: 2.0520069346914918
Validation loss: 2.66856022501747

Epoch: 6| Step: 12
Training loss: 2.793489591678465
Validation loss: 2.626161394084636

Epoch: 6| Step: 13
Training loss: 2.246253391065888
Validation loss: 2.6270092737183997

Epoch: 247| Step: 0
Training loss: 2.1176176302865883
Validation loss: 2.615801285637226

Epoch: 6| Step: 1
Training loss: 1.410237951897042
Validation loss: 2.5892176573755674

Epoch: 6| Step: 2
Training loss: 2.2171500441416465
Validation loss: 2.594878169674658

Epoch: 6| Step: 3
Training loss: 2.333242232951168
Validation loss: 2.576882496447488

Epoch: 6| Step: 4
Training loss: 2.4627808463960994
Validation loss: 2.5335753164249133

Epoch: 6| Step: 5
Training loss: 2.8125812094937914
Validation loss: 2.556422158920719

Epoch: 6| Step: 6
Training loss: 1.7263521782690536
Validation loss: 2.5770554452886416

Epoch: 6| Step: 7
Training loss: 1.3044614310479068
Validation loss: 2.5428560996704044

Epoch: 6| Step: 8
Training loss: 2.6600000276780666
Validation loss: 2.5632757547837604

Epoch: 6| Step: 9
Training loss: 2.8153130768157033
Validation loss: 2.5448200384040027

Epoch: 6| Step: 10
Training loss: 1.8899106023727519
Validation loss: 2.5938658937353787

Epoch: 6| Step: 11
Training loss: 1.6137324480421578
Validation loss: 2.5768230811541972

Epoch: 6| Step: 12
Training loss: 1.97591133096727
Validation loss: 2.5877836615571668

Epoch: 6| Step: 13
Training loss: 2.622227612541966
Validation loss: 2.6365078311907313

Epoch: 248| Step: 0
Training loss: 2.634927505712001
Validation loss: 2.671044746775813

Epoch: 6| Step: 1
Training loss: 1.82467495362074
Validation loss: 2.6973984022926834

Epoch: 6| Step: 2
Training loss: 2.184988705673532
Validation loss: 2.6874723063380173

Epoch: 6| Step: 3
Training loss: 1.9075966752778235
Validation loss: 2.6387161187171717

Epoch: 6| Step: 4
Training loss: 1.7186031625619806
Validation loss: 2.6099904109393806

Epoch: 6| Step: 5
Training loss: 2.4385604507872167
Validation loss: 2.5506182195449787

Epoch: 6| Step: 6
Training loss: 2.547485465625035
Validation loss: 2.591069195762594

Epoch: 6| Step: 7
Training loss: 2.083605430636082
Validation loss: 2.597792588865126

Epoch: 6| Step: 8
Training loss: 2.930530640394253
Validation loss: 2.5726597666704314

Epoch: 6| Step: 9
Training loss: 1.9706206743971428
Validation loss: 2.627340590253615

Epoch: 6| Step: 10
Training loss: 2.1174302753737457
Validation loss: 2.625333704248844

Epoch: 6| Step: 11
Training loss: 1.6148969120157448
Validation loss: 2.6056002879646525

Epoch: 6| Step: 12
Training loss: 2.4243889343537868
Validation loss: 2.57626873968923

Epoch: 6| Step: 13
Training loss: 2.0323653460164883
Validation loss: 2.5286012299228293

Epoch: 249| Step: 0
Training loss: 1.7032939582100768
Validation loss: 2.5273933543349396

Epoch: 6| Step: 1
Training loss: 1.4092092530763463
Validation loss: 2.4981692445482837

Epoch: 6| Step: 2
Training loss: 2.3220536092702404
Validation loss: 2.4759438882302636

Epoch: 6| Step: 3
Training loss: 2.3680251247903144
Validation loss: 2.4669404298919373

Epoch: 6| Step: 4
Training loss: 2.1117215138543233
Validation loss: 2.474470713242405

Epoch: 6| Step: 5
Training loss: 2.2976322093693
Validation loss: 2.4828517410573454

Epoch: 6| Step: 6
Training loss: 2.2859863860091214
Validation loss: 2.466916687211025

Epoch: 6| Step: 7
Training loss: 2.380484021760374
Validation loss: 2.4746197161098387

Epoch: 6| Step: 8
Training loss: 2.420185705893906
Validation loss: 2.4834205185436935

Epoch: 6| Step: 9
Training loss: 2.3304577092194676
Validation loss: 2.4816123428786696

Epoch: 6| Step: 10
Training loss: 2.5980021540432428
Validation loss: 2.499621839532477

Epoch: 6| Step: 11
Training loss: 2.274229036423888
Validation loss: 2.5521047682089057

Epoch: 6| Step: 12
Training loss: 2.090108294989505
Validation loss: 2.6030351443923085

Epoch: 6| Step: 13
Training loss: 2.0528821084445825
Validation loss: 2.6687181796961985

Epoch: 250| Step: 0
Training loss: 2.2343950604158485
Validation loss: 2.7213509348191534

Epoch: 6| Step: 1
Training loss: 2.5714337068839486
Validation loss: 2.724079652106246

Epoch: 6| Step: 2
Training loss: 2.148494539370665
Validation loss: 2.728980725387249

Epoch: 6| Step: 3
Training loss: 1.885538747077274
Validation loss: 2.6780978753026794

Epoch: 6| Step: 4
Training loss: 2.0233392286555185
Validation loss: 2.63383983034609

Epoch: 6| Step: 5
Training loss: 2.0730140190331348
Validation loss: 2.604384624261103

Epoch: 6| Step: 6
Training loss: 1.9971715477091605
Validation loss: 2.555089532013829

Epoch: 6| Step: 7
Training loss: 1.9334328324375811
Validation loss: 2.539160436061939

Epoch: 6| Step: 8
Training loss: 1.7173784505597185
Validation loss: 2.5142113324847486

Epoch: 6| Step: 9
Training loss: 2.5544736813533246
Validation loss: 2.51130733808723

Epoch: 6| Step: 10
Training loss: 2.6038535171420283
Validation loss: 2.501452564410659

Epoch: 6| Step: 11
Training loss: 2.6911110681515784
Validation loss: 2.5127090076162766

Epoch: 6| Step: 12
Training loss: 2.645202461382974
Validation loss: 2.515088705390704

Epoch: 6| Step: 13
Training loss: 1.8177524623232468
Validation loss: 2.4910275780483384

Epoch: 251| Step: 0
Training loss: 2.0004387612669743
Validation loss: 2.522320936342007

Epoch: 6| Step: 1
Training loss: 2.7283420821577615
Validation loss: 2.5136663895759317

Epoch: 6| Step: 2
Training loss: 2.2844938442976352
Validation loss: 2.5311402819052824

Epoch: 6| Step: 3
Training loss: 2.213764230347468
Validation loss: 2.5360552384581023

Epoch: 6| Step: 4
Training loss: 1.5003975500350715
Validation loss: 2.544439231482232

Epoch: 6| Step: 5
Training loss: 2.532026477916332
Validation loss: 2.567846218427975

Epoch: 6| Step: 6
Training loss: 1.706789885682238
Validation loss: 2.574289138595701

Epoch: 6| Step: 7
Training loss: 1.743185535800863
Validation loss: 2.6236643042040226

Epoch: 6| Step: 8
Training loss: 1.8649320507199425
Validation loss: 2.64255059964021

Epoch: 6| Step: 9
Training loss: 1.869531668293544
Validation loss: 2.6444872538345425

Epoch: 6| Step: 10
Training loss: 2.5422398801540838
Validation loss: 2.6332120960027887

Epoch: 6| Step: 11
Training loss: 2.2976645844693278
Validation loss: 2.6447322436630096

Epoch: 6| Step: 12
Training loss: 1.9200512055681702
Validation loss: 2.6296515199583905

Epoch: 6| Step: 13
Training loss: 2.8628069184191305
Validation loss: 2.620709144205173

Epoch: 252| Step: 0
Training loss: 3.041958485718207
Validation loss: 2.6450225508941827

Epoch: 6| Step: 1
Training loss: 2.435313784925586
Validation loss: 2.649462506228308

Epoch: 6| Step: 2
Training loss: 1.7682453392611348
Validation loss: 2.6294544360728636

Epoch: 6| Step: 3
Training loss: 2.4249730138161985
Validation loss: 2.627076296654478

Epoch: 6| Step: 4
Training loss: 1.9912721812514858
Validation loss: 2.609660089265327

Epoch: 6| Step: 5
Training loss: 2.3012907179794664
Validation loss: 2.6124821815917363

Epoch: 6| Step: 6
Training loss: 2.0925544627768953
Validation loss: 2.6139515395859214

Epoch: 6| Step: 7
Training loss: 2.0199137165035395
Validation loss: 2.5835588161958625

Epoch: 6| Step: 8
Training loss: 1.9531348876702843
Validation loss: 2.5661628719998055

Epoch: 6| Step: 9
Training loss: 1.8480811890565318
Validation loss: 2.5744294160921863

Epoch: 6| Step: 10
Training loss: 1.8670816431404653
Validation loss: 2.542525698676651

Epoch: 6| Step: 11
Training loss: 2.220509221209642
Validation loss: 2.550732225119306

Epoch: 6| Step: 12
Training loss: 1.6036754533147313
Validation loss: 2.5583351684050135

Epoch: 6| Step: 13
Training loss: 2.323755554717896
Validation loss: 2.554811371610614

Epoch: 253| Step: 0
Training loss: 2.615021495402521
Validation loss: 2.572125770205993

Epoch: 6| Step: 1
Training loss: 1.9348865849379586
Validation loss: 2.6060234672717413

Epoch: 6| Step: 2
Training loss: 1.630142364954712
Validation loss: 2.589105515246451

Epoch: 6| Step: 3
Training loss: 2.327492237508349
Validation loss: 2.6251087468948957

Epoch: 6| Step: 4
Training loss: 1.9846633941863459
Validation loss: 2.5935936386592826

Epoch: 6| Step: 5
Training loss: 2.3487363542664865
Validation loss: 2.588421768287431

Epoch: 6| Step: 6
Training loss: 1.8775965196204223
Validation loss: 2.575866218347927

Epoch: 6| Step: 7
Training loss: 1.6050121836927738
Validation loss: 2.56626990046576

Epoch: 6| Step: 8
Training loss: 2.0172519475568427
Validation loss: 2.535821937972519

Epoch: 6| Step: 9
Training loss: 1.9532570145814392
Validation loss: 2.5217084127661358

Epoch: 6| Step: 10
Training loss: 2.8865476152334235
Validation loss: 2.51360568552477

Epoch: 6| Step: 11
Training loss: 1.8852174839867473
Validation loss: 2.514600288399268

Epoch: 6| Step: 12
Training loss: 2.673304838883265
Validation loss: 2.497361396072132

Epoch: 6| Step: 13
Training loss: 2.359035139047734
Validation loss: 2.522570970089521

Epoch: 254| Step: 0
Training loss: 1.5225979570217498
Validation loss: 2.525836335846079

Epoch: 6| Step: 1
Training loss: 1.9339186886654534
Validation loss: 2.5550952550969637

Epoch: 6| Step: 2
Training loss: 2.2254182786714876
Validation loss: 2.54994821308881

Epoch: 6| Step: 3
Training loss: 2.1460413662211235
Validation loss: 2.5795191530641874

Epoch: 6| Step: 4
Training loss: 2.986150882268812
Validation loss: 2.630612987449495

Epoch: 6| Step: 5
Training loss: 1.918667730002852
Validation loss: 2.6330064198422574

Epoch: 6| Step: 6
Training loss: 2.291112196920298
Validation loss: 2.671775057524082

Epoch: 6| Step: 7
Training loss: 2.335212007981909
Validation loss: 2.661077428585559

Epoch: 6| Step: 8
Training loss: 1.7254984066518382
Validation loss: 2.6243603547679295

Epoch: 6| Step: 9
Training loss: 1.504752181297961
Validation loss: 2.586727455775079

Epoch: 6| Step: 10
Training loss: 1.8116522812586573
Validation loss: 2.5472632816208174

Epoch: 6| Step: 11
Training loss: 2.501946359188988
Validation loss: 2.545678737356351

Epoch: 6| Step: 12
Training loss: 2.1449049882809357
Validation loss: 2.546443067873847

Epoch: 6| Step: 13
Training loss: 2.8432321600971906
Validation loss: 2.5421742625518076

Epoch: 255| Step: 0
Training loss: 1.6655719340676076
Validation loss: 2.529077170316223

Epoch: 6| Step: 1
Training loss: 2.0986003207553394
Validation loss: 2.5261151856935182

Epoch: 6| Step: 2
Training loss: 2.287836573286141
Validation loss: 2.551076571089585

Epoch: 6| Step: 3
Training loss: 2.1160302184025803
Validation loss: 2.5701482038155334

Epoch: 6| Step: 4
Training loss: 1.8858597025907933
Validation loss: 2.584932698690163

Epoch: 6| Step: 5
Training loss: 2.4268889669978697
Validation loss: 2.5889755489196196

Epoch: 6| Step: 6
Training loss: 2.5000413891227202
Validation loss: 2.59829852355125

Epoch: 6| Step: 7
Training loss: 1.9303519769021982
Validation loss: 2.6288357366710002

Epoch: 6| Step: 8
Training loss: 2.101030587309141
Validation loss: 2.6074018346656906

Epoch: 6| Step: 9
Training loss: 2.0983041228103656
Validation loss: 2.6407851522361288

Epoch: 6| Step: 10
Training loss: 1.7050455446396893
Validation loss: 2.6460232003238406

Epoch: 6| Step: 11
Training loss: 2.120282827800797
Validation loss: 2.6186500524173812

Epoch: 6| Step: 12
Training loss: 2.8291683064054776
Validation loss: 2.605139029484906

Epoch: 6| Step: 13
Training loss: 2.1811205893878634
Validation loss: 2.5790106282976013

Epoch: 256| Step: 0
Training loss: 2.2575615872149224
Validation loss: 2.540955355391522

Epoch: 6| Step: 1
Training loss: 1.9985542436252572
Validation loss: 2.56234204185372

Epoch: 6| Step: 2
Training loss: 1.636777016415139
Validation loss: 2.5219179820227144

Epoch: 6| Step: 3
Training loss: 2.4825442304253245
Validation loss: 2.4923077497500405

Epoch: 6| Step: 4
Training loss: 2.2863769400902627
Validation loss: 2.492614023986028

Epoch: 6| Step: 5
Training loss: 2.682083793412136
Validation loss: 2.5381723261778504

Epoch: 6| Step: 6
Training loss: 1.6176607480719376
Validation loss: 2.506025586818852

Epoch: 6| Step: 7
Training loss: 2.433976977500394
Validation loss: 2.52350654940621

Epoch: 6| Step: 8
Training loss: 2.3853823952246636
Validation loss: 2.533020593345875

Epoch: 6| Step: 9
Training loss: 2.4572322987597977
Validation loss: 2.5193073183048815

Epoch: 6| Step: 10
Training loss: 2.121934811812336
Validation loss: 2.5784800275396864

Epoch: 6| Step: 11
Training loss: 1.6866175852232124
Validation loss: 2.606303495472522

Epoch: 6| Step: 12
Training loss: 1.6380756734897377
Validation loss: 2.613387283888227

Epoch: 6| Step: 13
Training loss: 2.345715118555413
Validation loss: 2.647700594518209

Epoch: 257| Step: 0
Training loss: 1.3819459258071056
Validation loss: 2.662074252312286

Epoch: 6| Step: 1
Training loss: 2.387421699558123
Validation loss: 2.651019208072245

Epoch: 6| Step: 2
Training loss: 1.6846986052823392
Validation loss: 2.6420481531720443

Epoch: 6| Step: 3
Training loss: 2.177952010565694
Validation loss: 2.577775072182226

Epoch: 6| Step: 4
Training loss: 2.2530920187643315
Validation loss: 2.568657068519108

Epoch: 6| Step: 5
Training loss: 1.8961116530583444
Validation loss: 2.5511025445002686

Epoch: 6| Step: 6
Training loss: 2.4266128957296496
Validation loss: 2.550668788921326

Epoch: 6| Step: 7
Training loss: 1.9182435749751254
Validation loss: 2.536008858984146

Epoch: 6| Step: 8
Training loss: 2.3508709369055767
Validation loss: 2.5432658610345413

Epoch: 6| Step: 9
Training loss: 2.919690299658998
Validation loss: 2.5485248487554757

Epoch: 6| Step: 10
Training loss: 1.6153644108120055
Validation loss: 2.5698568989659765

Epoch: 6| Step: 11
Training loss: 2.6160696802454275
Validation loss: 2.5919657778904193

Epoch: 6| Step: 12
Training loss: 2.4615863247491228
Validation loss: 2.623949703632948

Epoch: 6| Step: 13
Training loss: 1.9202163485983017
Validation loss: 2.6949043296577897

Epoch: 258| Step: 0
Training loss: 2.024974106988079
Validation loss: 2.7003775656404723

Epoch: 6| Step: 1
Training loss: 2.9190474103401396
Validation loss: 2.6656989835286207

Epoch: 6| Step: 2
Training loss: 2.28530857197995
Validation loss: 2.6215801517287765

Epoch: 6| Step: 3
Training loss: 2.2589473842050714
Validation loss: 2.5499816856474578

Epoch: 6| Step: 4
Training loss: 2.1004903674941113
Validation loss: 2.515834317867882

Epoch: 6| Step: 5
Training loss: 1.730173882362119
Validation loss: 2.4841438201891104

Epoch: 6| Step: 6
Training loss: 1.7666708625287786
Validation loss: 2.447681737678397

Epoch: 6| Step: 7
Training loss: 1.9824732280525426
Validation loss: 2.4325970955550735

Epoch: 6| Step: 8
Training loss: 2.2773349558953275
Validation loss: 2.4375492971276977

Epoch: 6| Step: 9
Training loss: 2.3204797755097553
Validation loss: 2.458172879128203

Epoch: 6| Step: 10
Training loss: 2.06180595511297
Validation loss: 2.456865702329834

Epoch: 6| Step: 11
Training loss: 1.9792301435497248
Validation loss: 2.498603732885277

Epoch: 6| Step: 12
Training loss: 2.421753320405995
Validation loss: 2.5371655699487756

Epoch: 6| Step: 13
Training loss: 2.231614868934219
Validation loss: 2.569784610729842

Epoch: 259| Step: 0
Training loss: 2.5377127008599127
Validation loss: 2.604450932564464

Epoch: 6| Step: 1
Training loss: 1.8152921808215088
Validation loss: 2.663478873155056

Epoch: 6| Step: 2
Training loss: 2.3085257944603876
Validation loss: 2.7034845131473486

Epoch: 6| Step: 3
Training loss: 2.55104836997453
Validation loss: 2.780944250209858

Epoch: 6| Step: 4
Training loss: 2.7411484882782324
Validation loss: 2.749368306058097

Epoch: 6| Step: 5
Training loss: 1.8067467900605676
Validation loss: 2.6600225921976475

Epoch: 6| Step: 6
Training loss: 2.190915955554708
Validation loss: 2.5557840309657336

Epoch: 6| Step: 7
Training loss: 1.4918340294289794
Validation loss: 2.4679409745647787

Epoch: 6| Step: 8
Training loss: 2.483079296491269
Validation loss: 2.4539268624760666

Epoch: 6| Step: 9
Training loss: 2.1643750347211252
Validation loss: 2.449942368848109

Epoch: 6| Step: 10
Training loss: 2.4960866817559353
Validation loss: 2.484273440606394

Epoch: 6| Step: 11
Training loss: 2.1629351492307465
Validation loss: 2.4796658074901003

Epoch: 6| Step: 12
Training loss: 1.6827821124918576
Validation loss: 2.4684422216624995

Epoch: 6| Step: 13
Training loss: 2.8909214177095133
Validation loss: 2.4625187067912386

Epoch: 260| Step: 0
Training loss: 1.6334555787771319
Validation loss: 2.434416801671576

Epoch: 6| Step: 1
Training loss: 2.7273827660642924
Validation loss: 2.4424208341046656

Epoch: 6| Step: 2
Training loss: 2.8530824555716956
Validation loss: 2.428746064569515

Epoch: 6| Step: 3
Training loss: 1.6232310717342902
Validation loss: 2.4255082800498484

Epoch: 6| Step: 4
Training loss: 2.223132895261801
Validation loss: 2.483946261408738

Epoch: 6| Step: 5
Training loss: 2.2993752501794256
Validation loss: 2.4994239461344234

Epoch: 6| Step: 6
Training loss: 2.1493226603407862
Validation loss: 2.560001690610685

Epoch: 6| Step: 7
Training loss: 2.691558346374772
Validation loss: 2.632566083928147

Epoch: 6| Step: 8
Training loss: 1.5631277730582378
Validation loss: 2.684073089331188

Epoch: 6| Step: 9
Training loss: 1.861292771667142
Validation loss: 2.7271382653921084

Epoch: 6| Step: 10
Training loss: 2.1561584453219127
Validation loss: 2.723172912759838

Epoch: 6| Step: 11
Training loss: 2.209597663504424
Validation loss: 2.7111438742292586

Epoch: 6| Step: 12
Training loss: 2.584818064708389
Validation loss: 2.642224401167062

Epoch: 6| Step: 13
Training loss: 1.8719904588554008
Validation loss: 2.632483758975917

Epoch: 261| Step: 0
Training loss: 2.1689982950952214
Validation loss: 2.567983482325544

Epoch: 6| Step: 1
Training loss: 1.955205008155571
Validation loss: 2.5647052951779648

Epoch: 6| Step: 2
Training loss: 2.5516933428638375
Validation loss: 2.516295570735315

Epoch: 6| Step: 3
Training loss: 1.5040279983187024
Validation loss: 2.5109553939602693

Epoch: 6| Step: 4
Training loss: 2.8281138720214427
Validation loss: 2.500143794056996

Epoch: 6| Step: 5
Training loss: 2.2790994828368585
Validation loss: 2.5121332739162456

Epoch: 6| Step: 6
Training loss: 1.5107553650392889
Validation loss: 2.526467754700539

Epoch: 6| Step: 7
Training loss: 1.938207435663084
Validation loss: 2.538060010929527

Epoch: 6| Step: 8
Training loss: 1.5121714779028084
Validation loss: 2.5446765046536233

Epoch: 6| Step: 9
Training loss: 2.043325593611147
Validation loss: 2.54126799432426

Epoch: 6| Step: 10
Training loss: 2.586728807600879
Validation loss: 2.5361158360366103

Epoch: 6| Step: 11
Training loss: 2.6190099036403454
Validation loss: 2.5527578954530035

Epoch: 6| Step: 12
Training loss: 2.462156835356121
Validation loss: 2.558879434492003

Epoch: 6| Step: 13
Training loss: 1.8931405852599725
Validation loss: 2.562092616875613

Epoch: 262| Step: 0
Training loss: 1.909610849851318
Validation loss: 2.551522731840964

Epoch: 6| Step: 1
Training loss: 3.0883927633705923
Validation loss: 2.5775387954875577

Epoch: 6| Step: 2
Training loss: 1.8198813390301096
Validation loss: 2.5924215476692254

Epoch: 6| Step: 3
Training loss: 1.609955618110374
Validation loss: 2.6078232283663914

Epoch: 6| Step: 4
Training loss: 1.8954419021899978
Validation loss: 2.5899033728976955

Epoch: 6| Step: 5
Training loss: 1.6567682858826969
Validation loss: 2.5560887000593318

Epoch: 6| Step: 6
Training loss: 2.4267047592289335
Validation loss: 2.5711801025083423

Epoch: 6| Step: 7
Training loss: 2.280441140781718
Validation loss: 2.538926231444474

Epoch: 6| Step: 8
Training loss: 2.336584913680196
Validation loss: 2.503396691076336

Epoch: 6| Step: 9
Training loss: 2.215330470729696
Validation loss: 2.484821751250555

Epoch: 6| Step: 10
Training loss: 1.3524752495099899
Validation loss: 2.478229879987641

Epoch: 6| Step: 11
Training loss: 2.516696393761632
Validation loss: 2.468228168303548

Epoch: 6| Step: 12
Training loss: 2.173033371080581
Validation loss: 2.4618519451491587

Epoch: 6| Step: 13
Training loss: 2.640219121133486
Validation loss: 2.470707571957975

Epoch: 263| Step: 0
Training loss: 1.6119748938713903
Validation loss: 2.501244696071834

Epoch: 6| Step: 1
Training loss: 2.5488310247529005
Validation loss: 2.5010496955773425

Epoch: 6| Step: 2
Training loss: 2.0123489133619166
Validation loss: 2.514486296034288

Epoch: 6| Step: 3
Training loss: 2.717735539733074
Validation loss: 2.5434354245488713

Epoch: 6| Step: 4
Training loss: 2.003402557425339
Validation loss: 2.5731967099228865

Epoch: 6| Step: 5
Training loss: 2.472847351114019
Validation loss: 2.580357765754578

Epoch: 6| Step: 6
Training loss: 2.1137191685391197
Validation loss: 2.5589742207770922

Epoch: 6| Step: 7
Training loss: 1.6694685828265232
Validation loss: 2.6138283955538486

Epoch: 6| Step: 8
Training loss: 2.416294288446444
Validation loss: 2.618213463857527

Epoch: 6| Step: 9
Training loss: 2.3670220144107916
Validation loss: 2.6390918893421733

Epoch: 6| Step: 10
Training loss: 2.1194432477612977
Validation loss: 2.5996946974771364

Epoch: 6| Step: 11
Training loss: 2.4348496920587728
Validation loss: 2.561964614887844

Epoch: 6| Step: 12
Training loss: 1.7615043019034582
Validation loss: 2.572252308765915

Epoch: 6| Step: 13
Training loss: 1.6113603808324517
Validation loss: 2.5388374737524013

Epoch: 264| Step: 0
Training loss: 2.378920782135673
Validation loss: 2.520499409608999

Epoch: 6| Step: 1
Training loss: 2.6551611968852873
Validation loss: 2.5052377034221704

Epoch: 6| Step: 2
Training loss: 2.022661568467805
Validation loss: 2.5335023380256456

Epoch: 6| Step: 3
Training loss: 1.608272137573008
Validation loss: 2.496752218793277

Epoch: 6| Step: 4
Training loss: 1.963385220744944
Validation loss: 2.504222514650584

Epoch: 6| Step: 5
Training loss: 1.8933794118530507
Validation loss: 2.508712424868177

Epoch: 6| Step: 6
Training loss: 2.2584447272535964
Validation loss: 2.514901351308547

Epoch: 6| Step: 7
Training loss: 1.9703436562406427
Validation loss: 2.5704847005653337

Epoch: 6| Step: 8
Training loss: 2.7523779558085937
Validation loss: 2.575735090322488

Epoch: 6| Step: 9
Training loss: 2.0655407309836664
Validation loss: 2.585886821269438

Epoch: 6| Step: 10
Training loss: 1.8412445631808043
Validation loss: 2.6100936478711154

Epoch: 6| Step: 11
Training loss: 1.4737502671258504
Validation loss: 2.6308587104250893

Epoch: 6| Step: 12
Training loss: 1.7302253500300464
Validation loss: 2.6049044721029486

Epoch: 6| Step: 13
Training loss: 2.4824767147942897
Validation loss: 2.6360802600298285

Epoch: 265| Step: 0
Training loss: 2.0550905709831495
Validation loss: 2.6400435445185444

Epoch: 6| Step: 1
Training loss: 1.5769504670883054
Validation loss: 2.625814841215522

Epoch: 6| Step: 2
Training loss: 2.544324381696574
Validation loss: 2.64941395751263

Epoch: 6| Step: 3
Training loss: 1.7396875072360702
Validation loss: 2.625065984350762

Epoch: 6| Step: 4
Training loss: 2.0417182552541107
Validation loss: 2.5770661771095806

Epoch: 6| Step: 5
Training loss: 2.606702429565932
Validation loss: 2.5412595037134698

Epoch: 6| Step: 6
Training loss: 2.0202414704454195
Validation loss: 2.508165051485623

Epoch: 6| Step: 7
Training loss: 1.588829598102336
Validation loss: 2.4777163877019213

Epoch: 6| Step: 8
Training loss: 1.9768137414047857
Validation loss: 2.4697573172053535

Epoch: 6| Step: 9
Training loss: 2.4763317301480505
Validation loss: 2.4741599767056357

Epoch: 6| Step: 10
Training loss: 3.022008908292111
Validation loss: 2.461809437803559

Epoch: 6| Step: 11
Training loss: 1.904410553497962
Validation loss: 2.4783665196604647

Epoch: 6| Step: 12
Training loss: 1.7700754974988222
Validation loss: 2.4796294947704283

Epoch: 6| Step: 13
Training loss: 2.3007199031507306
Validation loss: 2.477155516149969

Epoch: 266| Step: 0
Training loss: 2.1266560552844522
Validation loss: 2.5548304713195

Epoch: 6| Step: 1
Training loss: 2.0734572224947456
Validation loss: 2.499636401120613

Epoch: 6| Step: 2
Training loss: 1.7748916646644004
Validation loss: 2.5266526941585785

Epoch: 6| Step: 3
Training loss: 2.1186737812027614
Validation loss: 2.531854769198147

Epoch: 6| Step: 4
Training loss: 2.6012939681113925
Validation loss: 2.545026955102696

Epoch: 6| Step: 5
Training loss: 1.9623048430190542
Validation loss: 2.590472015232156

Epoch: 6| Step: 6
Training loss: 1.7885940138262697
Validation loss: 2.5931983728847667

Epoch: 6| Step: 7
Training loss: 2.0751671643311567
Validation loss: 2.597379649644583

Epoch: 6| Step: 8
Training loss: 1.8780584187059426
Validation loss: 2.6040124516919443

Epoch: 6| Step: 9
Training loss: 2.1943177925721207
Validation loss: 2.6063746336387736

Epoch: 6| Step: 10
Training loss: 2.068068875669212
Validation loss: 2.6002469101454593

Epoch: 6| Step: 11
Training loss: 2.4370461065777844
Validation loss: 2.623943600695902

Epoch: 6| Step: 12
Training loss: 2.2264069084548272
Validation loss: 2.601136318730836

Epoch: 6| Step: 13
Training loss: 2.1619188178221482
Validation loss: 2.597304608630067

Epoch: 267| Step: 0
Training loss: 1.3412949513122423
Validation loss: 2.6356366082088787

Epoch: 6| Step: 1
Training loss: 1.8437692026981016
Validation loss: 2.6057970106152966

Epoch: 6| Step: 2
Training loss: 2.494787121943168
Validation loss: 2.619465215426909

Epoch: 6| Step: 3
Training loss: 2.7490129433358756
Validation loss: 2.647250416752191

Epoch: 6| Step: 4
Training loss: 2.256003212574775
Validation loss: 2.6786657077606573

Epoch: 6| Step: 5
Training loss: 2.1431769314067295
Validation loss: 2.663039517251617

Epoch: 6| Step: 6
Training loss: 1.9353214444434685
Validation loss: 2.65124394532573

Epoch: 6| Step: 7
Training loss: 1.9136195078885665
Validation loss: 2.6565087136330874

Epoch: 6| Step: 8
Training loss: 2.0197583777320856
Validation loss: 2.6072947419946395

Epoch: 6| Step: 9
Training loss: 1.9705276940467928
Validation loss: 2.574338170215917

Epoch: 6| Step: 10
Training loss: 2.5542331489842733
Validation loss: 2.5655872851754236

Epoch: 6| Step: 11
Training loss: 1.803805379248733
Validation loss: 2.5702140348641818

Epoch: 6| Step: 12
Training loss: 2.0355129405289447
Validation loss: 2.4942773170623234

Epoch: 6| Step: 13
Training loss: 2.4064527153729167
Validation loss: 2.496391155293346

Epoch: 268| Step: 0
Training loss: 1.8501087388738395
Validation loss: 2.4992391700144934

Epoch: 6| Step: 1
Training loss: 2.044640639239064
Validation loss: 2.4630559693834675

Epoch: 6| Step: 2
Training loss: 2.3344958906008855
Validation loss: 2.4786226386256627

Epoch: 6| Step: 3
Training loss: 2.525965319131882
Validation loss: 2.5151404946877194

Epoch: 6| Step: 4
Training loss: 1.264562985394257
Validation loss: 2.525790508145923

Epoch: 6| Step: 5
Training loss: 3.0432581635377183
Validation loss: 2.5537703770368987

Epoch: 6| Step: 6
Training loss: 2.5054784828713066
Validation loss: 2.572866513977107

Epoch: 6| Step: 7
Training loss: 1.6348504303113285
Validation loss: 2.59715663149375

Epoch: 6| Step: 8
Training loss: 1.250695083004223
Validation loss: 2.63774957545729

Epoch: 6| Step: 9
Training loss: 1.681912319374612
Validation loss: 2.6110560623300088

Epoch: 6| Step: 10
Training loss: 2.464461646108367
Validation loss: 2.651750418620944

Epoch: 6| Step: 11
Training loss: 1.9356040291763374
Validation loss: 2.605057119083757

Epoch: 6| Step: 12
Training loss: 1.3758990642958917
Validation loss: 2.602184240452833

Epoch: 6| Step: 13
Training loss: 2.360303279333944
Validation loss: 2.599881351649225

Epoch: 269| Step: 0
Training loss: 1.479341908492932
Validation loss: 2.6025402152587933

Epoch: 6| Step: 1
Training loss: 2.275119853792563
Validation loss: 2.6115584080534604

Epoch: 6| Step: 2
Training loss: 2.013844613067213
Validation loss: 2.6250023841847083

Epoch: 6| Step: 3
Training loss: 1.777410954472916
Validation loss: 2.6135412218973553

Epoch: 6| Step: 4
Training loss: 2.696049420885752
Validation loss: 2.6008918058045203

Epoch: 6| Step: 5
Training loss: 1.2072603569984721
Validation loss: 2.6146911786293914

Epoch: 6| Step: 6
Training loss: 1.844095553328324
Validation loss: 2.587132342105726

Epoch: 6| Step: 7
Training loss: 2.19461091801062
Validation loss: 2.5690497917229407

Epoch: 6| Step: 8
Training loss: 1.7780015336063324
Validation loss: 2.5818851369971063

Epoch: 6| Step: 9
Training loss: 1.9378800788443256
Validation loss: 2.5697251009093107

Epoch: 6| Step: 10
Training loss: 2.3796545896803014
Validation loss: 2.5624054837047403

Epoch: 6| Step: 11
Training loss: 2.7917210492962474
Validation loss: 2.5805425002218727

Epoch: 6| Step: 12
Training loss: 1.3392517739491252
Validation loss: 2.610743652915624

Epoch: 6| Step: 13
Training loss: 2.5171399027363397
Validation loss: 2.615600226074931

Epoch: 270| Step: 0
Training loss: 1.9417145942808667
Validation loss: 2.6424303523340473

Epoch: 6| Step: 1
Training loss: 2.2316219201515146
Validation loss: 2.6070931788226046

Epoch: 6| Step: 2
Training loss: 1.9736191618389256
Validation loss: 2.6258488221247913

Epoch: 6| Step: 3
Training loss: 1.8434687254414999
Validation loss: 2.6199945531793327

Epoch: 6| Step: 4
Training loss: 2.143415761977276
Validation loss: 2.596804073205211

Epoch: 6| Step: 5
Training loss: 2.0124498538765323
Validation loss: 2.5633168973094023

Epoch: 6| Step: 6
Training loss: 2.4206545800436357
Validation loss: 2.5195190350534613

Epoch: 6| Step: 7
Training loss: 1.9069255194759478
Validation loss: 2.526181251890319

Epoch: 6| Step: 8
Training loss: 2.5531298820607677
Validation loss: 2.520254089599375

Epoch: 6| Step: 9
Training loss: 1.3065590597790342
Validation loss: 2.496573404582853

Epoch: 6| Step: 10
Training loss: 2.099765846277126
Validation loss: 2.5222864035237467

Epoch: 6| Step: 11
Training loss: 1.5970254786112512
Validation loss: 2.5198491174446707

Epoch: 6| Step: 12
Training loss: 1.8980268497356683
Validation loss: 2.5239538052327126

Epoch: 6| Step: 13
Training loss: 2.820001812251165
Validation loss: 2.5249114559247436

Epoch: 271| Step: 0
Training loss: 1.6004411446863582
Validation loss: 2.5356591053644326

Epoch: 6| Step: 1
Training loss: 1.9995411107996945
Validation loss: 2.5493334428848393

Epoch: 6| Step: 2
Training loss: 1.8668820438565015
Validation loss: 2.60277361931113

Epoch: 6| Step: 3
Training loss: 2.279760736827748
Validation loss: 2.591667733595977

Epoch: 6| Step: 4
Training loss: 2.741857438180131
Validation loss: 2.6364034280494533

Epoch: 6| Step: 5
Training loss: 1.7222153841245251
Validation loss: 2.6406197933469224

Epoch: 6| Step: 6
Training loss: 1.9669748810995495
Validation loss: 2.6610206398376715

Epoch: 6| Step: 7
Training loss: 2.0022781033867405
Validation loss: 2.671610174012139

Epoch: 6| Step: 8
Training loss: 2.7495886755152097
Validation loss: 2.671438214923597

Epoch: 6| Step: 9
Training loss: 2.3075370112764486
Validation loss: 2.6630781933875074

Epoch: 6| Step: 10
Training loss: 2.2359751060410322
Validation loss: 2.619671992658346

Epoch: 6| Step: 11
Training loss: 2.265680141435657
Validation loss: 2.603548836216031

Epoch: 6| Step: 12
Training loss: 1.6978309313263227
Validation loss: 2.5388135426074507

Epoch: 6| Step: 13
Training loss: 1.4005621428643502
Validation loss: 2.511610488575534

Epoch: 272| Step: 0
Training loss: 2.3085904452176007
Validation loss: 2.4843502083427094

Epoch: 6| Step: 1
Training loss: 1.842866200839876
Validation loss: 2.5030420709494012

Epoch: 6| Step: 2
Training loss: 2.097793773497645
Validation loss: 2.5163567152164505

Epoch: 6| Step: 3
Training loss: 2.227617836863365
Validation loss: 2.5184668448843714

Epoch: 6| Step: 4
Training loss: 2.838837457113414
Validation loss: 2.5375751070830446

Epoch: 6| Step: 5
Training loss: 1.9126051356520208
Validation loss: 2.5587654347366526

Epoch: 6| Step: 6
Training loss: 1.8841251846644416
Validation loss: 2.581503486656067

Epoch: 6| Step: 7
Training loss: 2.1127237370756453
Validation loss: 2.6305817191105043

Epoch: 6| Step: 8
Training loss: 2.2678626224550316
Validation loss: 2.6065927623148664

Epoch: 6| Step: 9
Training loss: 2.272759300353055
Validation loss: 2.6272018522854657

Epoch: 6| Step: 10
Training loss: 1.6396815902693613
Validation loss: 2.6137848099479886

Epoch: 6| Step: 11
Training loss: 2.5639934374744624
Validation loss: 2.623294639673654

Epoch: 6| Step: 12
Training loss: 1.522952819409017
Validation loss: 2.6201672951476516

Epoch: 6| Step: 13
Training loss: 1.8354304485979918
Validation loss: 2.587809136025387

Epoch: 273| Step: 0
Training loss: 1.9156575932927027
Validation loss: 2.533892433580631

Epoch: 6| Step: 1
Training loss: 2.5581639518540302
Validation loss: 2.5665209477001594

Epoch: 6| Step: 2
Training loss: 1.8763508063473164
Validation loss: 2.5410961907545566

Epoch: 6| Step: 3
Training loss: 2.3472585230120133
Validation loss: 2.5350523282280086

Epoch: 6| Step: 4
Training loss: 1.8017920183279148
Validation loss: 2.5056302725803934

Epoch: 6| Step: 5
Training loss: 1.8801509041790638
Validation loss: 2.504126782557209

Epoch: 6| Step: 6
Training loss: 1.9809166516520165
Validation loss: 2.496428911435304

Epoch: 6| Step: 7
Training loss: 2.033442209278479
Validation loss: 2.552943802142437

Epoch: 6| Step: 8
Training loss: 1.6932456782449326
Validation loss: 2.5086335752342106

Epoch: 6| Step: 9
Training loss: 2.3961056982935913
Validation loss: 2.515109291684971

Epoch: 6| Step: 10
Training loss: 1.5036223700973925
Validation loss: 2.559052124896803

Epoch: 6| Step: 11
Training loss: 1.9056986026931542
Validation loss: 2.569163613537725

Epoch: 6| Step: 12
Training loss: 2.623900410274199
Validation loss: 2.5751183596818703

Epoch: 6| Step: 13
Training loss: 2.1826407821711253
Validation loss: 2.6201466546739915

Epoch: 274| Step: 0
Training loss: 2.4729188897096903
Validation loss: 2.6343818009825344

Epoch: 6| Step: 1
Training loss: 2.2479693468182833
Validation loss: 2.6095975678143137

Epoch: 6| Step: 2
Training loss: 1.6717127070579336
Validation loss: 2.599544746938794

Epoch: 6| Step: 3
Training loss: 1.9956160419763638
Validation loss: 2.6014445204612615

Epoch: 6| Step: 4
Training loss: 2.0505310487254538
Validation loss: 2.581754653281761

Epoch: 6| Step: 5
Training loss: 2.177792617634839
Validation loss: 2.605136482217004

Epoch: 6| Step: 6
Training loss: 2.773199710591839
Validation loss: 2.60019783985152

Epoch: 6| Step: 7
Training loss: 1.6865235788668875
Validation loss: 2.622778012643495

Epoch: 6| Step: 8
Training loss: 1.835002450031859
Validation loss: 2.6122380537524816

Epoch: 6| Step: 9
Training loss: 1.7566760649360316
Validation loss: 2.6145800151018666

Epoch: 6| Step: 10
Training loss: 1.8814618976677386
Validation loss: 2.631721232691897

Epoch: 6| Step: 11
Training loss: 2.0738099695770082
Validation loss: 2.6194685830920736

Epoch: 6| Step: 12
Training loss: 1.6042752992912837
Validation loss: 2.583203932895031

Epoch: 6| Step: 13
Training loss: 2.159793650872547
Validation loss: 2.5472907290669236

Epoch: 275| Step: 0
Training loss: 2.0989381648783536
Validation loss: 2.5501897261355504

Epoch: 6| Step: 1
Training loss: 1.5347927138689732
Validation loss: 2.5348286076578437

Epoch: 6| Step: 2
Training loss: 2.5552478607350912
Validation loss: 2.5539035352504023

Epoch: 6| Step: 3
Training loss: 2.023440563538342
Validation loss: 2.5616039322133317

Epoch: 6| Step: 4
Training loss: 1.3847385936514527
Validation loss: 2.5665712192259873

Epoch: 6| Step: 5
Training loss: 1.9585937840842513
Validation loss: 2.5954220908841097

Epoch: 6| Step: 6
Training loss: 2.1643144481537475
Validation loss: 2.6224557869102214

Epoch: 6| Step: 7
Training loss: 2.0279461327721546
Validation loss: 2.6749568959503747

Epoch: 6| Step: 8
Training loss: 1.8477420585336763
Validation loss: 2.6678951135976474

Epoch: 6| Step: 9
Training loss: 1.9256355276937422
Validation loss: 2.739296761574142

Epoch: 6| Step: 10
Training loss: 2.4733592596348957
Validation loss: 2.7198986973784627

Epoch: 6| Step: 11
Training loss: 2.118190176043503
Validation loss: 2.6495188528190323

Epoch: 6| Step: 12
Training loss: 2.3676103774446386
Validation loss: 2.6197301251948364

Epoch: 6| Step: 13
Training loss: 2.377026145396478
Validation loss: 2.5128118451174584

Epoch: 276| Step: 0
Training loss: 1.8557376064465856
Validation loss: 2.456107349475802

Epoch: 6| Step: 1
Training loss: 2.076790058190953
Validation loss: 2.4592599307862137

Epoch: 6| Step: 2
Training loss: 1.9085254533612932
Validation loss: 2.425811832908856

Epoch: 6| Step: 3
Training loss: 2.3555308977471934
Validation loss: 2.4267574195170707

Epoch: 6| Step: 4
Training loss: 2.0442511361179503
Validation loss: 2.4629010153139608

Epoch: 6| Step: 5
Training loss: 3.061771695476684
Validation loss: 2.4500264970812764

Epoch: 6| Step: 6
Training loss: 1.6294371839684472
Validation loss: 2.489467751175553

Epoch: 6| Step: 7
Training loss: 1.4847415672225919
Validation loss: 2.496658364813957

Epoch: 6| Step: 8
Training loss: 1.9914071144051246
Validation loss: 2.5385881655794753

Epoch: 6| Step: 9
Training loss: 2.056030530725146
Validation loss: 2.611185751405031

Epoch: 6| Step: 10
Training loss: 2.416293301734565
Validation loss: 2.66329688502816

Epoch: 6| Step: 11
Training loss: 2.2684511644682575
Validation loss: 2.685145315030189

Epoch: 6| Step: 12
Training loss: 2.353771705466585
Validation loss: 2.6963637213967204

Epoch: 6| Step: 13
Training loss: 1.4876396017522315
Validation loss: 2.636525901994675

Epoch: 277| Step: 0
Training loss: 1.6877117730525395
Validation loss: 2.6124306944882254

Epoch: 6| Step: 1
Training loss: 1.8201571549694882
Validation loss: 2.585223572862069

Epoch: 6| Step: 2
Training loss: 1.6779888701677919
Validation loss: 2.5479431096906646

Epoch: 6| Step: 3
Training loss: 2.0216818008212796
Validation loss: 2.5455586126499625

Epoch: 6| Step: 4
Training loss: 2.0646876668374268
Validation loss: 2.529371043017495

Epoch: 6| Step: 5
Training loss: 1.6345087758852948
Validation loss: 2.5620219397239503

Epoch: 6| Step: 6
Training loss: 2.5899301920139886
Validation loss: 2.535674173030154

Epoch: 6| Step: 7
Training loss: 2.019057197935803
Validation loss: 2.5730440260116243

Epoch: 6| Step: 8
Training loss: 2.3096220305057726
Validation loss: 2.546677049304442

Epoch: 6| Step: 9
Training loss: 2.0282819925213857
Validation loss: 2.5640239990864826

Epoch: 6| Step: 10
Training loss: 1.631237237522288
Validation loss: 2.587087968832483

Epoch: 6| Step: 11
Training loss: 1.7845657674224913
Validation loss: 2.56568524641886

Epoch: 6| Step: 12
Training loss: 2.7108036414966437
Validation loss: 2.589012829724847

Epoch: 6| Step: 13
Training loss: 1.9338997646894016
Validation loss: 2.603745866474027

Epoch: 278| Step: 0
Training loss: 1.9034613551672739
Validation loss: 2.6088399281376273

Epoch: 6| Step: 1
Training loss: 1.8878469312534043
Validation loss: 2.5702507065724207

Epoch: 6| Step: 2
Training loss: 2.2453637570534664
Validation loss: 2.585076456691664

Epoch: 6| Step: 3
Training loss: 1.986420305751911
Validation loss: 2.562246852869225

Epoch: 6| Step: 4
Training loss: 1.397204105600178
Validation loss: 2.5862250269057014

Epoch: 6| Step: 5
Training loss: 1.7317410650539078
Validation loss: 2.530635931937147

Epoch: 6| Step: 6
Training loss: 1.8419615266408254
Validation loss: 2.529909775950854

Epoch: 6| Step: 7
Training loss: 2.080249589470501
Validation loss: 2.5809020219661445

Epoch: 6| Step: 8
Training loss: 2.1162834911997286
Validation loss: 2.599408071946091

Epoch: 6| Step: 9
Training loss: 2.2201847219510724
Validation loss: 2.605629233050856

Epoch: 6| Step: 10
Training loss: 2.3463301634469262
Validation loss: 2.6146802592960885

Epoch: 6| Step: 11
Training loss: 2.563890591564924
Validation loss: 2.6220237571518776

Epoch: 6| Step: 12
Training loss: 2.1898198496956534
Validation loss: 2.594436799699991

Epoch: 6| Step: 13
Training loss: 1.6977334733051048
Validation loss: 2.5834829738305194

Epoch: 279| Step: 0
Training loss: 1.9809793570231014
Validation loss: 2.564274723832946

Epoch: 6| Step: 1
Training loss: 1.5963692926267945
Validation loss: 2.5899269777237945

Epoch: 6| Step: 2
Training loss: 2.045863010582294
Validation loss: 2.5615258264718337

Epoch: 6| Step: 3
Training loss: 1.7838961037117298
Validation loss: 2.6072398756804045

Epoch: 6| Step: 4
Training loss: 1.9366158960136175
Validation loss: 2.5887507629884596

Epoch: 6| Step: 5
Training loss: 1.7737977590442024
Validation loss: 2.6324079374401106

Epoch: 6| Step: 6
Training loss: 2.4583390338206605
Validation loss: 2.651558821223593

Epoch: 6| Step: 7
Training loss: 2.760606598467791
Validation loss: 2.6169348447698946

Epoch: 6| Step: 8
Training loss: 1.9138649351961439
Validation loss: 2.5985144858578906

Epoch: 6| Step: 9
Training loss: 1.9348422864963701
Validation loss: 2.5753463567733137

Epoch: 6| Step: 10
Training loss: 2.078921746128478
Validation loss: 2.540379500561194

Epoch: 6| Step: 11
Training loss: 1.3786391737137813
Validation loss: 2.511714620868617

Epoch: 6| Step: 12
Training loss: 2.2451150636136106
Validation loss: 2.46866241331899

Epoch: 6| Step: 13
Training loss: 2.271291552401303
Validation loss: 2.499587374649643

Epoch: 280| Step: 0
Training loss: 1.7462991000613268
Validation loss: 2.4777229069458366

Epoch: 6| Step: 1
Training loss: 1.380749688654914
Validation loss: 2.4483458825818323

Epoch: 6| Step: 2
Training loss: 1.744913064709401
Validation loss: 2.5077493091199856

Epoch: 6| Step: 3
Training loss: 2.0255962624257755
Validation loss: 2.513285494820462

Epoch: 6| Step: 4
Training loss: 1.8981256425069526
Validation loss: 2.5295726885943655

Epoch: 6| Step: 5
Training loss: 2.2238444553018883
Validation loss: 2.564685850679371

Epoch: 6| Step: 6
Training loss: 2.6693958581937034
Validation loss: 2.5712517565280946

Epoch: 6| Step: 7
Training loss: 2.2593723703371733
Validation loss: 2.5849485782548323

Epoch: 6| Step: 8
Training loss: 2.453357758383171
Validation loss: 2.607320475422325

Epoch: 6| Step: 9
Training loss: 2.1325245198207496
Validation loss: 2.6382199984522825

Epoch: 6| Step: 10
Training loss: 2.8443549214951345
Validation loss: 2.674041880684547

Epoch: 6| Step: 11
Training loss: 1.6428356717169696
Validation loss: 2.683215725929734

Epoch: 6| Step: 12
Training loss: 1.9458358244570266
Validation loss: 2.690047586934803

Epoch: 6| Step: 13
Training loss: 1.853735827277982
Validation loss: 2.6534229867571444

Epoch: 281| Step: 0
Training loss: 2.3018109489849388
Validation loss: 2.5976443947734253

Epoch: 6| Step: 1
Training loss: 2.122683103501756
Validation loss: 2.5409570912513026

Epoch: 6| Step: 2
Training loss: 1.9597792529338867
Validation loss: 2.5374773447312617

Epoch: 6| Step: 3
Training loss: 1.4927977267870507
Validation loss: 2.526839585799519

Epoch: 6| Step: 4
Training loss: 1.545140073778172
Validation loss: 2.529460494200008

Epoch: 6| Step: 5
Training loss: 1.9805581939784318
Validation loss: 2.499644508518293

Epoch: 6| Step: 6
Training loss: 1.9659899180319682
Validation loss: 2.51235370115156

Epoch: 6| Step: 7
Training loss: 1.9263979406066989
Validation loss: 2.5786065778914242

Epoch: 6| Step: 8
Training loss: 2.123346470782701
Validation loss: 2.5863466582589454

Epoch: 6| Step: 9
Training loss: 1.4357667508058984
Validation loss: 2.6037426158246646

Epoch: 6| Step: 10
Training loss: 2.696385266868452
Validation loss: 2.632883374687417

Epoch: 6| Step: 11
Training loss: 2.245500728439726
Validation loss: 2.6048595396822636

Epoch: 6| Step: 12
Training loss: 2.033743164576208
Validation loss: 2.57802000506294

Epoch: 6| Step: 13
Training loss: 1.84363852988313
Validation loss: 2.5923621819556932

Epoch: 282| Step: 0
Training loss: 1.9867402045936218
Validation loss: 2.5704664437399583

Epoch: 6| Step: 1
Training loss: 1.607222144880724
Validation loss: 2.600797768003049

Epoch: 6| Step: 2
Training loss: 2.046429534660803
Validation loss: 2.612961829887135

Epoch: 6| Step: 3
Training loss: 1.9794470805903825
Validation loss: 2.6004328599704847

Epoch: 6| Step: 4
Training loss: 1.8543330200092647
Validation loss: 2.6134785044094886

Epoch: 6| Step: 5
Training loss: 1.650615681308151
Validation loss: 2.618714239320909

Epoch: 6| Step: 6
Training loss: 1.9985928950018266
Validation loss: 2.610867482739356

Epoch: 6| Step: 7
Training loss: 2.041579640408648
Validation loss: 2.614975224846203

Epoch: 6| Step: 8
Training loss: 2.120770340179462
Validation loss: 2.608207197663679

Epoch: 6| Step: 9
Training loss: 1.8216565454288534
Validation loss: 2.6065174910802873

Epoch: 6| Step: 10
Training loss: 1.984310119048827
Validation loss: 2.599778702683683

Epoch: 6| Step: 11
Training loss: 2.391789969036045
Validation loss: 2.5863490243019425

Epoch: 6| Step: 12
Training loss: 2.368134966799355
Validation loss: 2.545919523845637

Epoch: 6| Step: 13
Training loss: 1.641178146846429
Validation loss: 2.521170196934553

Epoch: 283| Step: 0
Training loss: 1.8624024308013456
Validation loss: 2.5442884607918073

Epoch: 6| Step: 1
Training loss: 2.221863295125914
Validation loss: 2.551126547279171

Epoch: 6| Step: 2
Training loss: 1.9044320865459143
Validation loss: 2.576379913652615

Epoch: 6| Step: 3
Training loss: 1.8365468414090877
Validation loss: 2.5796320970309523

Epoch: 6| Step: 4
Training loss: 2.0108222222946694
Validation loss: 2.581858842242497

Epoch: 6| Step: 5
Training loss: 1.9366887763113316
Validation loss: 2.527834279147357

Epoch: 6| Step: 6
Training loss: 2.7170002009027017
Validation loss: 2.5387176749022977

Epoch: 6| Step: 7
Training loss: 1.966370613099556
Validation loss: 2.5511294132675295

Epoch: 6| Step: 8
Training loss: 1.8307184587132022
Validation loss: 2.5632963261291266

Epoch: 6| Step: 9
Training loss: 1.7290183850177447
Validation loss: 2.543088364217329

Epoch: 6| Step: 10
Training loss: 2.0842917590126944
Validation loss: 2.5786386768044256

Epoch: 6| Step: 11
Training loss: 1.7083000862173814
Validation loss: 2.5692088841093796

Epoch: 6| Step: 12
Training loss: 1.6819452769645538
Validation loss: 2.585186175928935

Epoch: 6| Step: 13
Training loss: 2.4360442093531667
Validation loss: 2.5905123883640626

Epoch: 284| Step: 0
Training loss: 1.9177882465024265
Validation loss: 2.6083451026025353

Epoch: 6| Step: 1
Training loss: 2.3260302240272757
Validation loss: 2.6215054169319427

Epoch: 6| Step: 2
Training loss: 2.551704087916312
Validation loss: 2.5504525923653865

Epoch: 6| Step: 3
Training loss: 1.5824412626963547
Validation loss: 2.566646988491901

Epoch: 6| Step: 4
Training loss: 2.0816966176175367
Validation loss: 2.5624105391354424

Epoch: 6| Step: 5
Training loss: 1.7419527862229596
Validation loss: 2.5425624493531678

Epoch: 6| Step: 6
Training loss: 2.08324015091088
Validation loss: 2.531163320116891

Epoch: 6| Step: 7
Training loss: 2.1952879554761138
Validation loss: 2.529316387322178

Epoch: 6| Step: 8
Training loss: 2.317201217435849
Validation loss: 2.5386420425107703

Epoch: 6| Step: 9
Training loss: 1.9511979018299792
Validation loss: 2.539918068743351

Epoch: 6| Step: 10
Training loss: 1.4918902835135002
Validation loss: 2.557415857556102

Epoch: 6| Step: 11
Training loss: 2.541775612502556
Validation loss: 2.605230622702731

Epoch: 6| Step: 12
Training loss: 1.807732065796866
Validation loss: 2.5771135754508196

Epoch: 6| Step: 13
Training loss: 1.4932234598225262
Validation loss: 2.5921412615017876

Epoch: 285| Step: 0
Training loss: 2.1024760136273657
Validation loss: 2.565255490146382

Epoch: 6| Step: 1
Training loss: 1.1311872728354821
Validation loss: 2.5863685824835576

Epoch: 6| Step: 2
Training loss: 2.3816695677212594
Validation loss: 2.578999103367997

Epoch: 6| Step: 3
Training loss: 2.317046979063229
Validation loss: 2.6013832679692785

Epoch: 6| Step: 4
Training loss: 1.8778058991718498
Validation loss: 2.614143035614862

Epoch: 6| Step: 5
Training loss: 1.5781969110704483
Validation loss: 2.61562784514582

Epoch: 6| Step: 6
Training loss: 1.6531861955532925
Validation loss: 2.631610463898978

Epoch: 6| Step: 7
Training loss: 1.6653320770630529
Validation loss: 2.584308537616878

Epoch: 6| Step: 8
Training loss: 1.491909460557502
Validation loss: 2.556629574302297

Epoch: 6| Step: 9
Training loss: 1.4900124560865968
Validation loss: 2.555045970844092

Epoch: 6| Step: 10
Training loss: 1.6783679125701458
Validation loss: 2.553150472899123

Epoch: 6| Step: 11
Training loss: 2.7520288439392373
Validation loss: 2.5512141687449112

Epoch: 6| Step: 12
Training loss: 2.993497954969853
Validation loss: 2.558873983863285

Epoch: 6| Step: 13
Training loss: 1.4655255574731318
Validation loss: 2.5372971721447133

Epoch: 286| Step: 0
Training loss: 1.9806880791858188
Validation loss: 2.566036520946567

Epoch: 6| Step: 1
Training loss: 2.9034449668938533
Validation loss: 2.552937988628863

Epoch: 6| Step: 2
Training loss: 1.453191940242426
Validation loss: 2.5388531407826718

Epoch: 6| Step: 3
Training loss: 1.7337063711957277
Validation loss: 2.6000861942235622

Epoch: 6| Step: 4
Training loss: 2.1272929667093194
Validation loss: 2.591534077808837

Epoch: 6| Step: 5
Training loss: 1.6559773346644462
Validation loss: 2.6320493744863698

Epoch: 6| Step: 6
Training loss: 1.792427330299758
Validation loss: 2.654662005395819

Epoch: 6| Step: 7
Training loss: 1.3863290588427355
Validation loss: 2.568591754491072

Epoch: 6| Step: 8
Training loss: 1.3889967998333201
Validation loss: 2.5870975377958554

Epoch: 6| Step: 9
Training loss: 1.3441877760927436
Validation loss: 2.5946991497520866

Epoch: 6| Step: 10
Training loss: 2.2871825534700876
Validation loss: 2.5763325943556072

Epoch: 6| Step: 11
Training loss: 2.161987411518836
Validation loss: 2.5771590455841418

Epoch: 6| Step: 12
Training loss: 2.085709462934767
Validation loss: 2.579645282747264

Epoch: 6| Step: 13
Training loss: 2.4398268328644215
Validation loss: 2.579584329052721

Epoch: 287| Step: 0
Training loss: 1.924776507693421
Validation loss: 2.5821842104051282

Epoch: 6| Step: 1
Training loss: 1.8414206580730073
Validation loss: 2.5925016041587936

Epoch: 6| Step: 2
Training loss: 2.076815084763511
Validation loss: 2.6292655589694096

Epoch: 6| Step: 3
Training loss: 2.1458748254807594
Validation loss: 2.627161861479253

Epoch: 6| Step: 4
Training loss: 1.799498194047849
Validation loss: 2.6258530517373666

Epoch: 6| Step: 5
Training loss: 1.8653003301493498
Validation loss: 2.6679484942343565

Epoch: 6| Step: 6
Training loss: 1.8833994603433653
Validation loss: 2.6463762962728894

Epoch: 6| Step: 7
Training loss: 1.8198823215880502
Validation loss: 2.639919555454722

Epoch: 6| Step: 8
Training loss: 2.0748646335799026
Validation loss: 2.6441233107599715

Epoch: 6| Step: 9
Training loss: 1.7393089428282416
Validation loss: 2.613083265984508

Epoch: 6| Step: 10
Training loss: 2.032658836661614
Validation loss: 2.6629199713149916

Epoch: 6| Step: 11
Training loss: 2.9246230640603064
Validation loss: 2.6330185082317903

Epoch: 6| Step: 12
Training loss: 1.8667898353177321
Validation loss: 2.582812784929177

Epoch: 6| Step: 13
Training loss: 1.7644384667727417
Validation loss: 2.501401905541586

Epoch: 288| Step: 0
Training loss: 1.8247226452076473
Validation loss: 2.530425954050321

Epoch: 6| Step: 1
Training loss: 1.9073403163881193
Validation loss: 2.500711180938654

Epoch: 6| Step: 2
Training loss: 2.571723712907315
Validation loss: 2.5443072412411465

Epoch: 6| Step: 3
Training loss: 1.545050575885287
Validation loss: 2.5763163377863694

Epoch: 6| Step: 4
Training loss: 2.1924745944039885
Validation loss: 2.6225363508431943

Epoch: 6| Step: 5
Training loss: 2.357762676342057
Validation loss: 2.60248714965423

Epoch: 6| Step: 6
Training loss: 2.2261936886159295
Validation loss: 2.655035332099223

Epoch: 6| Step: 7
Training loss: 1.6349482098230852
Validation loss: 2.6761904512658155

Epoch: 6| Step: 8
Training loss: 2.3506384773547597
Validation loss: 2.6798919362490983

Epoch: 6| Step: 9
Training loss: 1.8834214867860053
Validation loss: 2.675852872535016

Epoch: 6| Step: 10
Training loss: 2.0277009917516646
Validation loss: 2.6807939267505887

Epoch: 6| Step: 11
Training loss: 2.71874333523339
Validation loss: 2.6090458645223453

Epoch: 6| Step: 12
Training loss: 1.7293344745637123
Validation loss: 2.5360509295900124

Epoch: 6| Step: 13
Training loss: 1.207642779942077
Validation loss: 2.511710570832774

Epoch: 289| Step: 0
Training loss: 2.3105755608294323
Validation loss: 2.472743494343758

Epoch: 6| Step: 1
Training loss: 2.642784725213312
Validation loss: 2.473705934733152

Epoch: 6| Step: 2
Training loss: 1.3787239105439992
Validation loss: 2.4313779553735415

Epoch: 6| Step: 3
Training loss: 2.473306434807257
Validation loss: 2.4383115558560022

Epoch: 6| Step: 4
Training loss: 2.4033940198152366
Validation loss: 2.467464691883458

Epoch: 6| Step: 5
Training loss: 1.409496290312314
Validation loss: 2.4671199261859806

Epoch: 6| Step: 6
Training loss: 1.6976219654790645
Validation loss: 2.5260071676723426

Epoch: 6| Step: 7
Training loss: 2.1002233840569087
Validation loss: 2.6018381975051224

Epoch: 6| Step: 8
Training loss: 1.8766216894466272
Validation loss: 2.66685066979098

Epoch: 6| Step: 9
Training loss: 2.6639229746328272
Validation loss: 2.6850350926886457

Epoch: 6| Step: 10
Training loss: 1.5121479854320448
Validation loss: 2.717725524224131

Epoch: 6| Step: 11
Training loss: 2.177290606936622
Validation loss: 2.7339124161124095

Epoch: 6| Step: 12
Training loss: 2.057092919386895
Validation loss: 2.722786738344126

Epoch: 6| Step: 13
Training loss: 1.5415567238585595
Validation loss: 2.734893444503141

Epoch: 290| Step: 0
Training loss: 1.3984236903014893
Validation loss: 2.6868231017034243

Epoch: 6| Step: 1
Training loss: 2.256336719822419
Validation loss: 2.6692359041239158

Epoch: 6| Step: 2
Training loss: 1.3649872432014825
Validation loss: 2.6071656519122888

Epoch: 6| Step: 3
Training loss: 1.2765407079473146
Validation loss: 2.643084567519891

Epoch: 6| Step: 4
Training loss: 2.9070348192668227
Validation loss: 2.5649204298074615

Epoch: 6| Step: 5
Training loss: 1.2543281011932703
Validation loss: 2.561135060337911

Epoch: 6| Step: 6
Training loss: 2.773136090300941
Validation loss: 2.5628195152501454

Epoch: 6| Step: 7
Training loss: 1.6957413091536664
Validation loss: 2.5287130224466265

Epoch: 6| Step: 8
Training loss: 1.9803563072893728
Validation loss: 2.520961227535462

Epoch: 6| Step: 9
Training loss: 2.0363313939434007
Validation loss: 2.531507926327259

Epoch: 6| Step: 10
Training loss: 1.3192786508542664
Validation loss: 2.502457189990874

Epoch: 6| Step: 11
Training loss: 1.5028279984583863
Validation loss: 2.5142355610182303

Epoch: 6| Step: 12
Training loss: 2.6713219678196065
Validation loss: 2.5327356711612916

Epoch: 6| Step: 13
Training loss: 2.052053874106108
Validation loss: 2.504548020821252

Epoch: 291| Step: 0
Training loss: 1.6836405524101183
Validation loss: 2.5474976634625373

Epoch: 6| Step: 1
Training loss: 2.0725723312879603
Validation loss: 2.5881181648076312

Epoch: 6| Step: 2
Training loss: 2.1809639423438334
Validation loss: 2.5368035229756205

Epoch: 6| Step: 3
Training loss: 2.626677930520526
Validation loss: 2.5735984599042747

Epoch: 6| Step: 4
Training loss: 1.697370694928181
Validation loss: 2.624915712002423

Epoch: 6| Step: 5
Training loss: 1.8990603080763226
Validation loss: 2.60126151481205

Epoch: 6| Step: 6
Training loss: 1.9058990155394073
Validation loss: 2.5691689882031827

Epoch: 6| Step: 7
Training loss: 1.889413492742554
Validation loss: 2.564246365690177

Epoch: 6| Step: 8
Training loss: 1.5519016168027093
Validation loss: 2.550801283410595

Epoch: 6| Step: 9
Training loss: 1.9938757231962556
Validation loss: 2.5281261744298043

Epoch: 6| Step: 10
Training loss: 1.754526551118307
Validation loss: 2.5590572335353667

Epoch: 6| Step: 11
Training loss: 2.2583067461914466
Validation loss: 2.5280827302232147

Epoch: 6| Step: 12
Training loss: 1.4471621663004077
Validation loss: 2.5290867859377326

Epoch: 6| Step: 13
Training loss: 2.4762871526003987
Validation loss: 2.5277400465188196

Epoch: 292| Step: 0
Training loss: 1.315145596396138
Validation loss: 2.562945365970406

Epoch: 6| Step: 1
Training loss: 2.461364805877236
Validation loss: 2.569319930510643

Epoch: 6| Step: 2
Training loss: 2.3905781261361536
Validation loss: 2.5965918939407855

Epoch: 6| Step: 3
Training loss: 1.379843460893347
Validation loss: 2.628538139006097

Epoch: 6| Step: 4
Training loss: 2.519210250869494
Validation loss: 2.673544587027426

Epoch: 6| Step: 5
Training loss: 1.9848634614275749
Validation loss: 2.701030529826535

Epoch: 6| Step: 6
Training loss: 2.2156539592276174
Validation loss: 2.675298835723361

Epoch: 6| Step: 7
Training loss: 2.0749498935762403
Validation loss: 2.652024816889845

Epoch: 6| Step: 8
Training loss: 2.2790505244239756
Validation loss: 2.5819249287547694

Epoch: 6| Step: 9
Training loss: 1.479347146355835
Validation loss: 2.5413379977818233

Epoch: 6| Step: 10
Training loss: 1.8878149792926928
Validation loss: 2.5168349710822113

Epoch: 6| Step: 11
Training loss: 2.0050421575742248
Validation loss: 2.4733518693680074

Epoch: 6| Step: 12
Training loss: 1.6143047789787386
Validation loss: 2.4563816507663665

Epoch: 6| Step: 13
Training loss: 1.592252588860253
Validation loss: 2.505695071028403

Epoch: 293| Step: 0
Training loss: 2.27799284961171
Validation loss: 2.494289090072548

Epoch: 6| Step: 1
Training loss: 1.9740110069903345
Validation loss: 2.506870635599569

Epoch: 6| Step: 2
Training loss: 1.7674913248067758
Validation loss: 2.521691079190675

Epoch: 6| Step: 3
Training loss: 2.6544441816648203
Validation loss: 2.5805102633044443

Epoch: 6| Step: 4
Training loss: 2.4905824664802543
Validation loss: 2.590233713501917

Epoch: 6| Step: 5
Training loss: 2.1386163573701644
Validation loss: 2.58516457983746

Epoch: 6| Step: 6
Training loss: 1.5341274706661248
Validation loss: 2.5935678839422613

Epoch: 6| Step: 7
Training loss: 1.9159617440738839
Validation loss: 2.622146675423379

Epoch: 6| Step: 8
Training loss: 2.003710880385514
Validation loss: 2.6155605440390195

Epoch: 6| Step: 9
Training loss: 1.7683391134231736
Validation loss: 2.5832463577969893

Epoch: 6| Step: 10
Training loss: 1.3384010844739862
Validation loss: 2.581665459450558

Epoch: 6| Step: 11
Training loss: 1.729993492290627
Validation loss: 2.5434681235559946

Epoch: 6| Step: 12
Training loss: 1.929779668297982
Validation loss: 2.5365388976245953

Epoch: 6| Step: 13
Training loss: 1.5023941959951497
Validation loss: 2.5107585204641834

Epoch: 294| Step: 0
Training loss: 2.6350558992714284
Validation loss: 2.506237260210568

Epoch: 6| Step: 1
Training loss: 1.2067950860249352
Validation loss: 2.5056093150144543

Epoch: 6| Step: 2
Training loss: 2.0885807962787144
Validation loss: 2.474514504540796

Epoch: 6| Step: 3
Training loss: 1.9145684021321545
Validation loss: 2.516426258941248

Epoch: 6| Step: 4
Training loss: 1.2997247111007761
Validation loss: 2.5055508977485363

Epoch: 6| Step: 5
Training loss: 1.9677332114374761
Validation loss: 2.5283209725943037

Epoch: 6| Step: 6
Training loss: 2.192626178377306
Validation loss: 2.5514663158009574

Epoch: 6| Step: 7
Training loss: 2.266937612253125
Validation loss: 2.576316245243936

Epoch: 6| Step: 8
Training loss: 1.927061695974037
Validation loss: 2.5930998420123217

Epoch: 6| Step: 9
Training loss: 2.2180655054888265
Validation loss: 2.5967217392114916

Epoch: 6| Step: 10
Training loss: 1.5583349792281382
Validation loss: 2.6058732252134598

Epoch: 6| Step: 11
Training loss: 1.6234172302096816
Validation loss: 2.615115143287494

Epoch: 6| Step: 12
Training loss: 2.046813963933728
Validation loss: 2.619111343739737

Epoch: 6| Step: 13
Training loss: 1.4817780112934622
Validation loss: 2.621113655329324

Epoch: 295| Step: 0
Training loss: 1.88990675469125
Validation loss: 2.666854245820519

Epoch: 6| Step: 1
Training loss: 2.47104933653871
Validation loss: 2.638788521402815

Epoch: 6| Step: 2
Training loss: 2.0261220907872564
Validation loss: 2.6455134601422428

Epoch: 6| Step: 3
Training loss: 2.0412780884996105
Validation loss: 2.6610612118855697

Epoch: 6| Step: 4
Training loss: 1.807142561186083
Validation loss: 2.673386278373363

Epoch: 6| Step: 5
Training loss: 1.5279717678637494
Validation loss: 2.693334913615276

Epoch: 6| Step: 6
Training loss: 2.0973808349295404
Validation loss: 2.6431653971879983

Epoch: 6| Step: 7
Training loss: 1.3785955495086515
Validation loss: 2.6185748849737003

Epoch: 6| Step: 8
Training loss: 1.4418693150150714
Validation loss: 2.6035948824998805

Epoch: 6| Step: 9
Training loss: 2.1307220834337537
Validation loss: 2.5469129282617677

Epoch: 6| Step: 10
Training loss: 1.6243763240325921
Validation loss: 2.4674983493344635

Epoch: 6| Step: 11
Training loss: 1.8484843618171534
Validation loss: 2.4430403385504107

Epoch: 6| Step: 12
Training loss: 1.819010977356992
Validation loss: 2.423555361359459

Epoch: 6| Step: 13
Training loss: 2.6399392586280475
Validation loss: 2.4412720259326988

Epoch: 296| Step: 0
Training loss: 2.0590266255773444
Validation loss: 2.436236388193085

Epoch: 6| Step: 1
Training loss: 2.3355730978180635
Validation loss: 2.4410704684454116

Epoch: 6| Step: 2
Training loss: 1.9202500583811075
Validation loss: 2.465689020973573

Epoch: 6| Step: 3
Training loss: 2.1655420416813778
Validation loss: 2.511263808621813

Epoch: 6| Step: 4
Training loss: 1.7004749784571982
Validation loss: 2.5554805539592387

Epoch: 6| Step: 5
Training loss: 1.7051564970936506
Validation loss: 2.611853163251277

Epoch: 6| Step: 6
Training loss: 2.0609448667774894
Validation loss: 2.6057928628181055

Epoch: 6| Step: 7
Training loss: 2.261888566831582
Validation loss: 2.62310693236085

Epoch: 6| Step: 8
Training loss: 1.9465131003847578
Validation loss: 2.612768331007693

Epoch: 6| Step: 9
Training loss: 1.7216980360311618
Validation loss: 2.582123193532184

Epoch: 6| Step: 10
Training loss: 1.8020403053865217
Validation loss: 2.5882723851795264

Epoch: 6| Step: 11
Training loss: 1.4132955167692396
Validation loss: 2.5773270113762714

Epoch: 6| Step: 12
Training loss: 2.0074738094383835
Validation loss: 2.580995322064478

Epoch: 6| Step: 13
Training loss: 2.527814535309237
Validation loss: 2.5625419613263603

Epoch: 297| Step: 0
Training loss: 2.3495549856028255
Validation loss: 2.5735174370869096

Epoch: 6| Step: 1
Training loss: 1.3906190850635705
Validation loss: 2.5627148700971145

Epoch: 6| Step: 2
Training loss: 2.4881116488878754
Validation loss: 2.5639742200470894

Epoch: 6| Step: 3
Training loss: 1.6761976316095972
Validation loss: 2.565116523415999

Epoch: 6| Step: 4
Training loss: 1.4488598978194964
Validation loss: 2.586495269212588

Epoch: 6| Step: 5
Training loss: 1.949256116856734
Validation loss: 2.5509408274843097

Epoch: 6| Step: 6
Training loss: 1.9850423096344365
Validation loss: 2.6069195857686567

Epoch: 6| Step: 7
Training loss: 2.483892429915908
Validation loss: 2.6017507154714763

Epoch: 6| Step: 8
Training loss: 2.011798627434215
Validation loss: 2.5786234980595504

Epoch: 6| Step: 9
Training loss: 1.7135334265915652
Validation loss: 2.5904696069365443

Epoch: 6| Step: 10
Training loss: 2.256802976690288
Validation loss: 2.6600067798747995

Epoch: 6| Step: 11
Training loss: 2.162827783339613
Validation loss: 2.630065209048098

Epoch: 6| Step: 12
Training loss: 1.5473404001197582
Validation loss: 2.59963433616495

Epoch: 6| Step: 13
Training loss: 2.3463573956793704
Validation loss: 2.568620737602609

Epoch: 298| Step: 0
Training loss: 1.732594719041132
Validation loss: 2.552228983141858

Epoch: 6| Step: 1
Training loss: 1.3784565827288304
Validation loss: 2.549590926924027

Epoch: 6| Step: 2
Training loss: 1.3589345284158292
Validation loss: 2.5696514945476934

Epoch: 6| Step: 3
Training loss: 1.2175745063559076
Validation loss: 2.5394988795177404

Epoch: 6| Step: 4
Training loss: 1.8989889968625617
Validation loss: 2.5544484344522425

Epoch: 6| Step: 5
Training loss: 2.354912991222399
Validation loss: 2.5573803302961617

Epoch: 6| Step: 6
Training loss: 2.2354527788424265
Validation loss: 2.5697332500554273

Epoch: 6| Step: 7
Training loss: 2.1953594162024115
Validation loss: 2.606348593575173

Epoch: 6| Step: 8
Training loss: 1.8782815826697516
Validation loss: 2.5901853126156005

Epoch: 6| Step: 9
Training loss: 2.1712934415223564
Validation loss: 2.6033190504928623

Epoch: 6| Step: 10
Training loss: 1.851185434311493
Validation loss: 2.6218746592991655

Epoch: 6| Step: 11
Training loss: 2.379755679661076
Validation loss: 2.625376447296797

Epoch: 6| Step: 12
Training loss: 1.899899520224868
Validation loss: 2.6957150808239754

Epoch: 6| Step: 13
Training loss: 1.9267765591420436
Validation loss: 2.59205336788018

Epoch: 299| Step: 0
Training loss: 1.3831138928946085
Validation loss: 2.629552103396224

Epoch: 6| Step: 1
Training loss: 2.0625545610089135
Validation loss: 2.6186657426946423

Epoch: 6| Step: 2
Training loss: 2.3407854786597793
Validation loss: 2.575029013140042

Epoch: 6| Step: 3
Training loss: 1.795685548594676
Validation loss: 2.5728373393031934

Epoch: 6| Step: 4
Training loss: 2.2636530219569204
Validation loss: 2.592360311905966

Epoch: 6| Step: 5
Training loss: 2.297622247708283
Validation loss: 2.5564104000341

Epoch: 6| Step: 6
Training loss: 2.221218294294143
Validation loss: 2.5476036043721897

Epoch: 6| Step: 7
Training loss: 1.8620830658065775
Validation loss: 2.529996914993637

Epoch: 6| Step: 8
Training loss: 1.9245447983001234
Validation loss: 2.543069145068639

Epoch: 6| Step: 9
Training loss: 1.8384228056470029
Validation loss: 2.5380362603303017

Epoch: 6| Step: 10
Training loss: 1.5586343630898702
Validation loss: 2.558576153799027

Epoch: 6| Step: 11
Training loss: 1.8102805920183695
Validation loss: 2.571861828213687

Epoch: 6| Step: 12
Training loss: 1.6889755014886705
Validation loss: 2.5768394887326087

Epoch: 6| Step: 13
Training loss: 1.491745488874245
Validation loss: 2.5667985977184875

Epoch: 300| Step: 0
Training loss: 2.113365975477833
Validation loss: 2.5983752333627383

Epoch: 6| Step: 1
Training loss: 2.1429967062778412
Validation loss: 2.6372796637055056

Epoch: 6| Step: 2
Training loss: 1.9470606536273616
Validation loss: 2.615807787343198

Epoch: 6| Step: 3
Training loss: 1.8300026925906192
Validation loss: 2.6094755659692357

Epoch: 6| Step: 4
Training loss: 1.757780897068343
Validation loss: 2.5775627679147375

Epoch: 6| Step: 5
Training loss: 1.805369524868145
Validation loss: 2.5664493396534462

Epoch: 6| Step: 6
Training loss: 1.5427618346723933
Validation loss: 2.4909793711741886

Epoch: 6| Step: 7
Training loss: 1.6246272906787464
Validation loss: 2.504770606826351

Epoch: 6| Step: 8
Training loss: 2.012935174367231
Validation loss: 2.539921760906002

Epoch: 6| Step: 9
Training loss: 1.823837207698858
Validation loss: 2.5499218461270927

Epoch: 6| Step: 10
Training loss: 2.4699078512570405
Validation loss: 2.550716444110401

Epoch: 6| Step: 11
Training loss: 2.4152980963235167
Validation loss: 2.5809717510214085

Epoch: 6| Step: 12
Training loss: 1.8278949299338652
Validation loss: 2.557535269970414

Epoch: 6| Step: 13
Training loss: 1.5111631806758565
Validation loss: 2.575242359520983

Epoch: 301| Step: 0
Training loss: 2.756562033223899
Validation loss: 2.591286113270837

Epoch: 6| Step: 1
Training loss: 2.2196498711592128
Validation loss: 2.59294909632323

Epoch: 6| Step: 2
Training loss: 1.3197537656348433
Validation loss: 2.666254389205303

Epoch: 6| Step: 3
Training loss: 1.779532826227255
Validation loss: 2.671730617615299

Epoch: 6| Step: 4
Training loss: 2.0654361517333832
Validation loss: 2.667611987722543

Epoch: 6| Step: 5
Training loss: 1.8953688195675058
Validation loss: 2.679335071458116

Epoch: 6| Step: 6
Training loss: 1.635324107019021
Validation loss: 2.6185336773974304

Epoch: 6| Step: 7
Training loss: 1.9299552824344546
Validation loss: 2.6104532325012317

Epoch: 6| Step: 8
Training loss: 2.1442316120431593
Validation loss: 2.5941348575496717

Epoch: 6| Step: 9
Training loss: 1.323696157136696
Validation loss: 2.5358398017545905

Epoch: 6| Step: 10
Training loss: 1.57589897052686
Validation loss: 2.490644337935223

Epoch: 6| Step: 11
Training loss: 1.7144812546197836
Validation loss: 2.4688134326109132

Epoch: 6| Step: 12
Training loss: 2.029747979817264
Validation loss: 2.4709786765293775

Epoch: 6| Step: 13
Training loss: 2.005225388755761
Validation loss: 2.458804963555618

Epoch: 302| Step: 0
Training loss: 2.2004581841272906
Validation loss: 2.4527673318836567

Epoch: 6| Step: 1
Training loss: 2.2860781643938295
Validation loss: 2.44962196742261

Epoch: 6| Step: 2
Training loss: 1.6672714884373228
Validation loss: 2.457256046073105

Epoch: 6| Step: 3
Training loss: 1.9493397157245387
Validation loss: 2.4622894448823494

Epoch: 6| Step: 4
Training loss: 1.665650232635666
Validation loss: 2.493622401645143

Epoch: 6| Step: 5
Training loss: 2.14745916112364
Validation loss: 2.502608496073069

Epoch: 6| Step: 6
Training loss: 1.8560529893307172
Validation loss: 2.5134901540773456

Epoch: 6| Step: 7
Training loss: 1.624333244864398
Validation loss: 2.5406510298968534

Epoch: 6| Step: 8
Training loss: 1.5272045023240814
Validation loss: 2.5594677546162146

Epoch: 6| Step: 9
Training loss: 1.4645921007801048
Validation loss: 2.583293150517498

Epoch: 6| Step: 10
Training loss: 2.074448509925183
Validation loss: 2.6048571675706156

Epoch: 6| Step: 11
Training loss: 1.9637578614172875
Validation loss: 2.620768671395435

Epoch: 6| Step: 12
Training loss: 2.165022103635091
Validation loss: 2.6484523536468147

Epoch: 6| Step: 13
Training loss: 1.9367248461197675
Validation loss: 2.658987990301641

Epoch: 303| Step: 0
Training loss: 2.1734593602170564
Validation loss: 2.688619454426268

Epoch: 6| Step: 1
Training loss: 2.4257769254440116
Validation loss: 2.6396528181180123

Epoch: 6| Step: 2
Training loss: 2.0577170660530038
Validation loss: 2.6267868953708478

Epoch: 6| Step: 3
Training loss: 1.5244691143566804
Validation loss: 2.5753009935031015

Epoch: 6| Step: 4
Training loss: 1.7896507661998518
Validation loss: 2.5542274084123533

Epoch: 6| Step: 5
Training loss: 2.0914909359897185
Validation loss: 2.554997820968346

Epoch: 6| Step: 6
Training loss: 1.9025403808238297
Validation loss: 2.5372638924531867

Epoch: 6| Step: 7
Training loss: 1.1708425933272604
Validation loss: 2.4908037958300713

Epoch: 6| Step: 8
Training loss: 2.3455293132029365
Validation loss: 2.484865703945137

Epoch: 6| Step: 9
Training loss: 1.7158271211891802
Validation loss: 2.494705395145959

Epoch: 6| Step: 10
Training loss: 1.593961065939261
Validation loss: 2.4778240693001425

Epoch: 6| Step: 11
Training loss: 1.9139973532041548
Validation loss: 2.49655085891809

Epoch: 6| Step: 12
Training loss: 1.7171372910466713
Validation loss: 2.4953461563748394

Epoch: 6| Step: 13
Training loss: 1.9713889101730278
Validation loss: 2.5106532485305886

Epoch: 304| Step: 0
Training loss: 1.615028008374614
Validation loss: 2.5615941826992192

Epoch: 6| Step: 1
Training loss: 2.4491353241311478
Validation loss: 2.5561240509517456

Epoch: 6| Step: 2
Training loss: 2.3707649216617277
Validation loss: 2.5930441849721526

Epoch: 6| Step: 3
Training loss: 1.2650212861332086
Validation loss: 2.611328604333644

Epoch: 6| Step: 4
Training loss: 2.0185952000273573
Validation loss: 2.6671419067895816

Epoch: 6| Step: 5
Training loss: 2.220670379424086
Validation loss: 2.6528762859564305

Epoch: 6| Step: 6
Training loss: 1.8745960436229903
Validation loss: 2.6238797083017924

Epoch: 6| Step: 7
Training loss: 1.5178293145457702
Validation loss: 2.603343197644733

Epoch: 6| Step: 8
Training loss: 1.441012031383175
Validation loss: 2.5966490052356708

Epoch: 6| Step: 9
Training loss: 2.4239536348195445
Validation loss: 2.5582044853750094

Epoch: 6| Step: 10
Training loss: 1.7136804897421374
Validation loss: 2.551209503879152

Epoch: 6| Step: 11
Training loss: 2.448253289202492
Validation loss: 2.5725488644362247

Epoch: 6| Step: 12
Training loss: 1.3139520514810685
Validation loss: 2.5809311824582237

Epoch: 6| Step: 13
Training loss: 1.173231382591722
Validation loss: 2.5418073636077922

Epoch: 305| Step: 0
Training loss: 2.2213072747621236
Validation loss: 2.5573973986696097

Epoch: 6| Step: 1
Training loss: 2.565121310155804
Validation loss: 2.5738178070212006

Epoch: 6| Step: 2
Training loss: 1.1570352516903601
Validation loss: 2.5762414390227995

Epoch: 6| Step: 3
Training loss: 1.8340805077265916
Validation loss: 2.5919501099543703

Epoch: 6| Step: 4
Training loss: 1.9811916499164663
Validation loss: 2.6126776408225965

Epoch: 6| Step: 5
Training loss: 2.04186888750771
Validation loss: 2.644408170088868

Epoch: 6| Step: 6
Training loss: 1.851275522389683
Validation loss: 2.622466711748836

Epoch: 6| Step: 7
Training loss: 2.329971400564288
Validation loss: 2.6547903725411057

Epoch: 6| Step: 8
Training loss: 1.7041453533503117
Validation loss: 2.593530025116428

Epoch: 6| Step: 9
Training loss: 1.658916270612116
Validation loss: 2.5355175762004882

Epoch: 6| Step: 10
Training loss: 2.1458399380579167
Validation loss: 2.570647769539311

Epoch: 6| Step: 11
Training loss: 2.0188945895636876
Validation loss: 2.533303860024447

Epoch: 6| Step: 12
Training loss: 2.0518835393267234
Validation loss: 2.539346297616164

Epoch: 6| Step: 13
Training loss: 1.7924111024740437
Validation loss: 2.526263753560041

Epoch: 306| Step: 0
Training loss: 2.088289342337248
Validation loss: 2.4859518489107844

Epoch: 6| Step: 1
Training loss: 1.0287104461593426
Validation loss: 2.4901958387796457

Epoch: 6| Step: 2
Training loss: 2.151405309892602
Validation loss: 2.5099975003841766

Epoch: 6| Step: 3
Training loss: 1.535155784082706
Validation loss: 2.6030492267059726

Epoch: 6| Step: 4
Training loss: 2.4765938838089347
Validation loss: 2.566131979707043

Epoch: 6| Step: 5
Training loss: 1.454262647038999
Validation loss: 2.6038562640529253

Epoch: 6| Step: 6
Training loss: 1.756406230018737
Validation loss: 2.597900945090226

Epoch: 6| Step: 7
Training loss: 1.8032893590213466
Validation loss: 2.5844390307685274

Epoch: 6| Step: 8
Training loss: 2.1195060168858295
Validation loss: 2.6001692545648716

Epoch: 6| Step: 9
Training loss: 2.167430364068742
Validation loss: 2.5769999505762073

Epoch: 6| Step: 10
Training loss: 2.772238114752496
Validation loss: 2.5756847970968755

Epoch: 6| Step: 11
Training loss: 2.774894396172962
Validation loss: 2.6424819767149956

Epoch: 6| Step: 12
Training loss: 2.107979998426714
Validation loss: 2.6408383285155823

Epoch: 6| Step: 13
Training loss: 2.0738491727673782
Validation loss: 2.636766929657232

Epoch: 307| Step: 0
Training loss: 1.6472920419964263
Validation loss: 2.616271941567928

Epoch: 6| Step: 1
Training loss: 2.3610769032512273
Validation loss: 2.6105287784046407

Epoch: 6| Step: 2
Training loss: 1.9625074325712346
Validation loss: 2.589115506483103

Epoch: 6| Step: 3
Training loss: 2.516723393017773
Validation loss: 2.5474190940151122

Epoch: 6| Step: 4
Training loss: 2.3782974240809613
Validation loss: 2.5012588272180443

Epoch: 6| Step: 5
Training loss: 1.8105988232712338
Validation loss: 2.5003373554222645

Epoch: 6| Step: 6
Training loss: 1.3362781469594045
Validation loss: 2.510011416025531

Epoch: 6| Step: 7
Training loss: 2.189839665017484
Validation loss: 2.515315524507931

Epoch: 6| Step: 8
Training loss: 1.8642573009428318
Validation loss: 2.5621927743978343

Epoch: 6| Step: 9
Training loss: 2.226509816399742
Validation loss: 2.60128121292083

Epoch: 6| Step: 10
Training loss: 1.952330465832563
Validation loss: 2.573505501542561

Epoch: 6| Step: 11
Training loss: 1.4681833675729579
Validation loss: 2.469583258060587

Epoch: 6| Step: 12
Training loss: 1.7349119987486683
Validation loss: 2.457673506900001

Epoch: 6| Step: 13
Training loss: 2.5827411362515575
Validation loss: 2.45808047809981

Epoch: 308| Step: 0
Training loss: 2.104915171021689
Validation loss: 2.5025239998438

Epoch: 6| Step: 1
Training loss: 2.24419682551065
Validation loss: 2.5362338541844616

Epoch: 6| Step: 2
Training loss: 2.063364021348324
Validation loss: 2.553944782080374

Epoch: 6| Step: 3
Training loss: 2.2229096011830394
Validation loss: 2.5705813931050465

Epoch: 6| Step: 4
Training loss: 2.0888473274388994
Validation loss: 2.5855285843677067

Epoch: 6| Step: 5
Training loss: 1.95202080603752
Validation loss: 2.597705735426011

Epoch: 6| Step: 6
Training loss: 1.7809525626289076
Validation loss: 2.6201227230469

Epoch: 6| Step: 7
Training loss: 1.7078459517404077
Validation loss: 2.6570101828274124

Epoch: 6| Step: 8
Training loss: 2.1457867169794915
Validation loss: 2.6660906845164876

Epoch: 6| Step: 9
Training loss: 2.109126323593955
Validation loss: 2.657630815824043

Epoch: 6| Step: 10
Training loss: 1.7831424230666324
Validation loss: 2.6222454029161395

Epoch: 6| Step: 11
Training loss: 1.3809919711797352
Validation loss: 2.596425679458164

Epoch: 6| Step: 12
Training loss: 2.2411485983296426
Validation loss: 2.6076489219918377

Epoch: 6| Step: 13
Training loss: 1.8295359587032534
Validation loss: 2.5541388401758063

Epoch: 309| Step: 0
Training loss: 2.230140354546449
Validation loss: 2.5852372680277753

Epoch: 6| Step: 1
Training loss: 1.6359975313760278
Validation loss: 2.530879460595733

Epoch: 6| Step: 2
Training loss: 2.011507663948314
Validation loss: 2.558607680887051

Epoch: 6| Step: 3
Training loss: 2.165975778417864
Validation loss: 2.567974120667244

Epoch: 6| Step: 4
Training loss: 2.058788543692421
Validation loss: 2.5405216191315474

Epoch: 6| Step: 5
Training loss: 1.3809152724028215
Validation loss: 2.5422557919330275

Epoch: 6| Step: 6
Training loss: 1.7788773512136835
Validation loss: 2.5290537281576366

Epoch: 6| Step: 7
Training loss: 1.3783603700771414
Validation loss: 2.525044444294181

Epoch: 6| Step: 8
Training loss: 1.84404377294126
Validation loss: 2.4868674181585875

Epoch: 6| Step: 9
Training loss: 2.0656545385883205
Validation loss: 2.5188447554239377

Epoch: 6| Step: 10
Training loss: 1.8602946595628203
Validation loss: 2.4789723205257292

Epoch: 6| Step: 11
Training loss: 2.6975065727259873
Validation loss: 2.4521595215176615

Epoch: 6| Step: 12
Training loss: 2.1015189354220674
Validation loss: 2.4396618442514666

Epoch: 6| Step: 13
Training loss: 2.056184520664432
Validation loss: 2.4700486433333335

Epoch: 310| Step: 0
Training loss: 2.14003561774587
Validation loss: 2.4360189421396994

Epoch: 6| Step: 1
Training loss: 1.638605091430025
Validation loss: 2.465914905106022

Epoch: 6| Step: 2
Training loss: 1.9705022250136053
Validation loss: 2.500585185544982

Epoch: 6| Step: 3
Training loss: 1.8084140630653234
Validation loss: 2.5701604177823953

Epoch: 6| Step: 4
Training loss: 1.8828594787561665
Validation loss: 2.578149306057496

Epoch: 6| Step: 5
Training loss: 1.6379555920180924
Validation loss: 2.638212437401126

Epoch: 6| Step: 6
Training loss: 1.9883546347275134
Validation loss: 2.613078932065246

Epoch: 6| Step: 7
Training loss: 2.0980350429419317
Validation loss: 2.6149259446637183

Epoch: 6| Step: 8
Training loss: 1.7566922157113827
Validation loss: 2.632037961020349

Epoch: 6| Step: 9
Training loss: 2.5326645277830475
Validation loss: 2.6046539054280053

Epoch: 6| Step: 10
Training loss: 2.3523674787922784
Validation loss: 2.6215715801854644

Epoch: 6| Step: 11
Training loss: 1.8698295511500518
Validation loss: 2.5905152031087244

Epoch: 6| Step: 12
Training loss: 1.461723564951483
Validation loss: 2.5699037267412623

Epoch: 6| Step: 13
Training loss: 1.6532555627733616
Validation loss: 2.5728386520934055

Epoch: 311| Step: 0
Training loss: 1.547818445278605
Validation loss: 2.5801455661950827

Epoch: 6| Step: 1
Training loss: 1.2122327215025763
Validation loss: 2.534606356708794

Epoch: 6| Step: 2
Training loss: 1.076695309711684
Validation loss: 2.5385902161169667

Epoch: 6| Step: 3
Training loss: 2.3277145126271224
Validation loss: 2.568237611231591

Epoch: 6| Step: 4
Training loss: 1.7050031752570782
Validation loss: 2.5422379654195506

Epoch: 6| Step: 5
Training loss: 2.0705537475522546
Validation loss: 2.5908045762867844

Epoch: 6| Step: 6
Training loss: 2.038472642023992
Validation loss: 2.603510191507052

Epoch: 6| Step: 7
Training loss: 1.6230067719831227
Validation loss: 2.612264438212124

Epoch: 6| Step: 8
Training loss: 2.3076919885781875
Validation loss: 2.627414440694146

Epoch: 6| Step: 9
Training loss: 1.2034461843632425
Validation loss: 2.6183552580299354

Epoch: 6| Step: 10
Training loss: 1.7427200392994786
Validation loss: 2.600040345612519

Epoch: 6| Step: 11
Training loss: 2.690030880151645
Validation loss: 2.5998793341683997

Epoch: 6| Step: 12
Training loss: 1.389914127345628
Validation loss: 2.5875603077566853

Epoch: 6| Step: 13
Training loss: 2.2161336167055192
Validation loss: 2.557500226022978

Epoch: 312| Step: 0
Training loss: 2.4696036685702576
Validation loss: 2.555205468602421

Epoch: 6| Step: 1
Training loss: 2.659864053909207
Validation loss: 2.5551057914461124

Epoch: 6| Step: 2
Training loss: 1.999994814389182
Validation loss: 2.550769846775334

Epoch: 6| Step: 3
Training loss: 1.0441801201414653
Validation loss: 2.5293086106900757

Epoch: 6| Step: 4
Training loss: 2.1582145034697224
Validation loss: 2.582735274418662

Epoch: 6| Step: 5
Training loss: 1.513285610998169
Validation loss: 2.5599491169462256

Epoch: 6| Step: 6
Training loss: 2.324334047166496
Validation loss: 2.506156303195422

Epoch: 6| Step: 7
Training loss: 1.7336171186882599
Validation loss: 2.5088341158133685

Epoch: 6| Step: 8
Training loss: 1.7452956046001271
Validation loss: 2.500395441569635

Epoch: 6| Step: 9
Training loss: 1.3991047636511447
Validation loss: 2.5496001534723565

Epoch: 6| Step: 10
Training loss: 1.9555605541813188
Validation loss: 2.5418608205671966

Epoch: 6| Step: 11
Training loss: 1.3325335766424944
Validation loss: 2.534084726464222

Epoch: 6| Step: 12
Training loss: 1.294353838074828
Validation loss: 2.56094336331565

Epoch: 6| Step: 13
Training loss: 1.9792888670556625
Validation loss: 2.571597882309132

Epoch: 313| Step: 0
Training loss: 1.218343715927895
Validation loss: 2.576722073553524

Epoch: 6| Step: 1
Training loss: 2.447468644935893
Validation loss: 2.5821115670767094

Epoch: 6| Step: 2
Training loss: 1.7874439364091015
Validation loss: 2.613869882537715

Epoch: 6| Step: 3
Training loss: 1.8100028100176333
Validation loss: 2.571073842558385

Epoch: 6| Step: 4
Training loss: 2.1456958269918442
Validation loss: 2.531808297082113

Epoch: 6| Step: 5
Training loss: 1.4762280605149094
Validation loss: 2.5724279786443183

Epoch: 6| Step: 6
Training loss: 2.327010431972017
Validation loss: 2.59585311375935

Epoch: 6| Step: 7
Training loss: 1.865021922210221
Validation loss: 2.586482901935955

Epoch: 6| Step: 8
Training loss: 2.0373443731305128
Validation loss: 2.5904639389963173

Epoch: 6| Step: 9
Training loss: 1.647465134340016
Validation loss: 2.634305626803104

Epoch: 6| Step: 10
Training loss: 1.5367061953863272
Validation loss: 2.588229436228153

Epoch: 6| Step: 11
Training loss: 1.6008428678107838
Validation loss: 2.636014212212095

Epoch: 6| Step: 12
Training loss: 1.4377592931005003
Validation loss: 2.6092157524687587

Epoch: 6| Step: 13
Training loss: 1.8082236782643861
Validation loss: 2.5488607704147412

Epoch: 314| Step: 0
Training loss: 1.5250396910958497
Validation loss: 2.5883853540230484

Epoch: 6| Step: 1
Training loss: 2.1304999589470173
Validation loss: 2.559900422866655

Epoch: 6| Step: 2
Training loss: 1.5134057383224206
Validation loss: 2.584676552292236

Epoch: 6| Step: 3
Training loss: 2.272875844260762
Validation loss: 2.540659647662716

Epoch: 6| Step: 4
Training loss: 2.405379001470777
Validation loss: 2.58329868806147

Epoch: 6| Step: 5
Training loss: 2.589932125188986
Validation loss: 2.5897455211209963

Epoch: 6| Step: 6
Training loss: 1.2787917676053928
Validation loss: 2.5760738806298504

Epoch: 6| Step: 7
Training loss: 1.9702295465877977
Validation loss: 2.6109086971646116

Epoch: 6| Step: 8
Training loss: 1.5566259213546467
Validation loss: 2.5547814308186876

Epoch: 6| Step: 9
Training loss: 1.5344753939537963
Validation loss: 2.6022130250234365

Epoch: 6| Step: 10
Training loss: 1.5437654007981316
Validation loss: 2.5739496811140232

Epoch: 6| Step: 11
Training loss: 1.4241946236664154
Validation loss: 2.5895984623641732

Epoch: 6| Step: 12
Training loss: 1.6796392389505732
Validation loss: 2.5692116525947117

Epoch: 6| Step: 13
Training loss: 1.9958758151232558
Validation loss: 2.6038542801731235

Epoch: 315| Step: 0
Training loss: 2.283914342687012
Validation loss: 2.583437953389212

Epoch: 6| Step: 1
Training loss: 1.6810008038048578
Validation loss: 2.5893344752413623

Epoch: 6| Step: 2
Training loss: 1.1389102326437452
Validation loss: 2.596015920896843

Epoch: 6| Step: 3
Training loss: 1.7297365865660093
Validation loss: 2.5537802575588007

Epoch: 6| Step: 4
Training loss: 1.769648196501181
Validation loss: 2.567954143857486

Epoch: 6| Step: 5
Training loss: 1.5345243361884138
Validation loss: 2.6027763673617264

Epoch: 6| Step: 6
Training loss: 1.1306170004524239
Validation loss: 2.5996737874623173

Epoch: 6| Step: 7
Training loss: 1.8966291943934088
Validation loss: 2.615686804353813

Epoch: 6| Step: 8
Training loss: 2.3862803754277007
Validation loss: 2.6186310995296354

Epoch: 6| Step: 9
Training loss: 1.5582024027989365
Validation loss: 2.6087486520424665

Epoch: 6| Step: 10
Training loss: 1.7072068043398914
Validation loss: 2.602148675416308

Epoch: 6| Step: 11
Training loss: 2.16849018046676
Validation loss: 2.6282252676241686

Epoch: 6| Step: 12
Training loss: 1.7015823236997358
Validation loss: 2.605548695372457

Epoch: 6| Step: 13
Training loss: 2.3046639134121443
Validation loss: 2.5515043004023568

Epoch: 316| Step: 0
Training loss: 2.4318543612139427
Validation loss: 2.5799758586690507

Epoch: 6| Step: 1
Training loss: 1.4699747376639223
Validation loss: 2.5814718389744034

Epoch: 6| Step: 2
Training loss: 1.3995964320119605
Validation loss: 2.5774748473693028

Epoch: 6| Step: 3
Training loss: 2.454866605036402
Validation loss: 2.5666865907448964

Epoch: 6| Step: 4
Training loss: 1.8028317773363263
Validation loss: 2.516108369689842

Epoch: 6| Step: 5
Training loss: 1.2879007363956554
Validation loss: 2.5381342673020963

Epoch: 6| Step: 6
Training loss: 1.7893080896784708
Validation loss: 2.531727263114887

Epoch: 6| Step: 7
Training loss: 1.4610035927249878
Validation loss: 2.542665900085099

Epoch: 6| Step: 8
Training loss: 1.86395417863576
Validation loss: 2.5662012894149995

Epoch: 6| Step: 9
Training loss: 2.385381195826331
Validation loss: 2.574241379525992

Epoch: 6| Step: 10
Training loss: 1.8240366810155397
Validation loss: 2.577449039506751

Epoch: 6| Step: 11
Training loss: 1.6224871059193389
Validation loss: 2.568065724187396

Epoch: 6| Step: 12
Training loss: 1.6406107584017289
Validation loss: 2.606348837511402

Epoch: 6| Step: 13
Training loss: 1.5212482078121665
Validation loss: 2.5957366964151216

Epoch: 317| Step: 0
Training loss: 1.4674521860524858
Validation loss: 2.60161735621937

Epoch: 6| Step: 1
Training loss: 1.8826830807601598
Validation loss: 2.5760480895825526

Epoch: 6| Step: 2
Training loss: 2.01425857950812
Validation loss: 2.5594364710044806

Epoch: 6| Step: 3
Training loss: 1.4940831790427325
Validation loss: 2.5872349859823007

Epoch: 6| Step: 4
Training loss: 1.850170207570593
Validation loss: 2.523261978454086

Epoch: 6| Step: 5
Training loss: 1.300160577833548
Validation loss: 2.574905111052142

Epoch: 6| Step: 6
Training loss: 1.8946019110332633
Validation loss: 2.548490281204573

Epoch: 6| Step: 7
Training loss: 1.33935306561373
Validation loss: 2.5669452134207726

Epoch: 6| Step: 8
Training loss: 1.4480057650077245
Validation loss: 2.5526017629107076

Epoch: 6| Step: 9
Training loss: 1.909776209058515
Validation loss: 2.551675745796116

Epoch: 6| Step: 10
Training loss: 2.026198694049059
Validation loss: 2.519351245058696

Epoch: 6| Step: 11
Training loss: 2.0146999158398278
Validation loss: 2.5719691061954806

Epoch: 6| Step: 12
Training loss: 2.216953248545804
Validation loss: 2.551697656462803

Epoch: 6| Step: 13
Training loss: 2.4010075520528145
Validation loss: 2.575000048146664

Epoch: 318| Step: 0
Training loss: 2.130008181345813
Validation loss: 2.530115085065046

Epoch: 6| Step: 1
Training loss: 1.3438163563512568
Validation loss: 2.600006417119837

Epoch: 6| Step: 2
Training loss: 2.5001468615310647
Validation loss: 2.6826435685408407

Epoch: 6| Step: 3
Training loss: 1.9141897976642581
Validation loss: 2.655028477460362

Epoch: 6| Step: 4
Training loss: 1.888610207656475
Validation loss: 2.6603473701105145

Epoch: 6| Step: 5
Training loss: 1.9269163798276308
Validation loss: 2.671673475254051

Epoch: 6| Step: 6
Training loss: 1.780822301011401
Validation loss: 2.6423995020368443

Epoch: 6| Step: 7
Training loss: 1.527869248782674
Validation loss: 2.5928927923917167

Epoch: 6| Step: 8
Training loss: 1.2199607605955542
Validation loss: 2.5832323598099114

Epoch: 6| Step: 9
Training loss: 1.8137075413703774
Validation loss: 2.521565375687888

Epoch: 6| Step: 10
Training loss: 1.5363129196753034
Validation loss: 2.5091430841927918

Epoch: 6| Step: 11
Training loss: 1.4418913069035655
Validation loss: 2.501558469744868

Epoch: 6| Step: 12
Training loss: 2.190700587384802
Validation loss: 2.5435920260127673

Epoch: 6| Step: 13
Training loss: 1.6487240655231636
Validation loss: 2.5284778186885517

Epoch: 319| Step: 0
Training loss: 2.0798892226430707
Validation loss: 2.527060428483086

Epoch: 6| Step: 1
Training loss: 2.114249693258082
Validation loss: 2.5638945669242426

Epoch: 6| Step: 2
Training loss: 1.4158630709849058
Validation loss: 2.5602814754824377

Epoch: 6| Step: 3
Training loss: 1.6673251837925651
Validation loss: 2.583897810966387

Epoch: 6| Step: 4
Training loss: 1.6557410555837986
Validation loss: 2.5732075350489354

Epoch: 6| Step: 5
Training loss: 2.1483139834877885
Validation loss: 2.6296036481568743

Epoch: 6| Step: 6
Training loss: 1.6968425403391771
Validation loss: 2.669315770709136

Epoch: 6| Step: 7
Training loss: 2.617183491718013
Validation loss: 2.7147346017243152

Epoch: 6| Step: 8
Training loss: 1.6943420585939504
Validation loss: 2.6861812105952168

Epoch: 6| Step: 9
Training loss: 1.8456217429974913
Validation loss: 2.7216380334793553

Epoch: 6| Step: 10
Training loss: 1.6956054153183124
Validation loss: 2.639001335849113

Epoch: 6| Step: 11
Training loss: 1.7706684559378336
Validation loss: 2.62859653653174

Epoch: 6| Step: 12
Training loss: 1.8337729822758602
Validation loss: 2.540386398641488

Epoch: 6| Step: 13
Training loss: 1.5658364341641524
Validation loss: 2.5075672382278817

Epoch: 320| Step: 0
Training loss: 1.7473559841685224
Validation loss: 2.5019563411361427

Epoch: 6| Step: 1
Training loss: 1.445535261153599
Validation loss: 2.483851331625342

Epoch: 6| Step: 2
Training loss: 1.5882687276861638
Validation loss: 2.4868411094067233

Epoch: 6| Step: 3
Training loss: 2.171822856030126
Validation loss: 2.470781351693093

Epoch: 6| Step: 4
Training loss: 1.5849570264315578
Validation loss: 2.483738863772375

Epoch: 6| Step: 5
Training loss: 2.149044658525257
Validation loss: 2.5080063092376994

Epoch: 6| Step: 6
Training loss: 2.121979754956285
Validation loss: 2.5020336303941018

Epoch: 6| Step: 7
Training loss: 1.4750228201183855
Validation loss: 2.59849907149699

Epoch: 6| Step: 8
Training loss: 2.145516924693326
Validation loss: 2.592872609111502

Epoch: 6| Step: 9
Training loss: 1.500762586661267
Validation loss: 2.5972066007292804

Epoch: 6| Step: 10
Training loss: 1.1081621229017689
Validation loss: 2.6632250143454876

Epoch: 6| Step: 11
Training loss: 2.6097075655867763
Validation loss: 2.647135831973895

Epoch: 6| Step: 12
Training loss: 1.9736828842493253
Validation loss: 2.6600612748529096

Epoch: 6| Step: 13
Training loss: 1.7348845824402954
Validation loss: 2.688701774936732

Epoch: 321| Step: 0
Training loss: 1.751114081935869
Validation loss: 2.687455849691476

Epoch: 6| Step: 1
Training loss: 1.5770296884716288
Validation loss: 2.6538050899815877

Epoch: 6| Step: 2
Training loss: 1.8389163261407842
Validation loss: 2.5977184622827134

Epoch: 6| Step: 3
Training loss: 1.3784089312795966
Validation loss: 2.613826708088388

Epoch: 6| Step: 4
Training loss: 2.308815779231682
Validation loss: 2.555310592336535

Epoch: 6| Step: 5
Training loss: 1.460895068526524
Validation loss: 2.5875637860506155

Epoch: 6| Step: 6
Training loss: 1.9802315172995109
Validation loss: 2.5612597759451843

Epoch: 6| Step: 7
Training loss: 1.9867085830482334
Validation loss: 2.5531949068332915

Epoch: 6| Step: 8
Training loss: 1.8062666552346645
Validation loss: 2.5548500530389218

Epoch: 6| Step: 9
Training loss: 1.8119400738034046
Validation loss: 2.562571811445149

Epoch: 6| Step: 10
Training loss: 1.7692415450798191
Validation loss: 2.5844084799403406

Epoch: 6| Step: 11
Training loss: 1.4755191245059607
Validation loss: 2.5965884966055253

Epoch: 6| Step: 12
Training loss: 2.201883493797428
Validation loss: 2.6459033285979836

Epoch: 6| Step: 13
Training loss: 1.7905444541510998
Validation loss: 2.616232808909138

Epoch: 322| Step: 0
Training loss: 1.4443806711611302
Validation loss: 2.6003409907898147

Epoch: 6| Step: 1
Training loss: 1.7075564626180197
Validation loss: 2.601214472466819

Epoch: 6| Step: 2
Training loss: 1.584580315222496
Validation loss: 2.5708109054535133

Epoch: 6| Step: 3
Training loss: 1.9698357388713317
Validation loss: 2.59617067464716

Epoch: 6| Step: 4
Training loss: 2.2644218670351024
Validation loss: 2.5881836078747766

Epoch: 6| Step: 5
Training loss: 1.664189723349695
Validation loss: 2.5811929500947217

Epoch: 6| Step: 6
Training loss: 1.6023835845414969
Validation loss: 2.5623343964696055

Epoch: 6| Step: 7
Training loss: 1.782249304221343
Validation loss: 2.578049044019992

Epoch: 6| Step: 8
Training loss: 1.7559293026519789
Validation loss: 2.5743332231044027

Epoch: 6| Step: 9
Training loss: 1.5293411501812457
Validation loss: 2.57803106425845

Epoch: 6| Step: 10
Training loss: 1.548367483517292
Validation loss: 2.555225109652282

Epoch: 6| Step: 11
Training loss: 1.8866413487576708
Validation loss: 2.5637745672518517

Epoch: 6| Step: 12
Training loss: 1.758834067303153
Validation loss: 2.588879758271182

Epoch: 6| Step: 13
Training loss: 2.02258058762289
Validation loss: 2.568786631970355

Epoch: 323| Step: 0
Training loss: 1.3803505398407845
Validation loss: 2.5751033067813043

Epoch: 6| Step: 1
Training loss: 1.2686503479256008
Validation loss: 2.5437771420042257

Epoch: 6| Step: 2
Training loss: 1.3585773188434804
Validation loss: 2.516742466001917

Epoch: 6| Step: 3
Training loss: 2.316819770016805
Validation loss: 2.517451979360041

Epoch: 6| Step: 4
Training loss: 1.789085154827222
Validation loss: 2.5445954900809

Epoch: 6| Step: 5
Training loss: 1.3259265431156613
Validation loss: 2.502733960922427

Epoch: 6| Step: 6
Training loss: 1.773851858793854
Validation loss: 2.499966827808282

Epoch: 6| Step: 7
Training loss: 2.348314139145796
Validation loss: 2.522362116739878

Epoch: 6| Step: 8
Training loss: 2.0076564624283635
Validation loss: 2.488031283947517

Epoch: 6| Step: 9
Training loss: 1.6406271798255607
Validation loss: 2.5209676743537823

Epoch: 6| Step: 10
Training loss: 1.533736098645424
Validation loss: 2.5566992659481955

Epoch: 6| Step: 11
Training loss: 1.5832968841506656
Validation loss: 2.592297994026552

Epoch: 6| Step: 12
Training loss: 1.8373954665364254
Validation loss: 2.5473198531435663

Epoch: 6| Step: 13
Training loss: 1.5319780448455897
Validation loss: 2.5817038462674518

Epoch: 324| Step: 0
Training loss: 1.7913859243525003
Validation loss: 2.5846764907968347

Epoch: 6| Step: 1
Training loss: 1.8344128710397114
Validation loss: 2.5739332551144876

Epoch: 6| Step: 2
Training loss: 1.6476489165040242
Validation loss: 2.5742751690823122

Epoch: 6| Step: 3
Training loss: 1.2592209222407762
Validation loss: 2.550655492357137

Epoch: 6| Step: 4
Training loss: 2.028739669124791
Validation loss: 2.5567307850963727

Epoch: 6| Step: 5
Training loss: 1.2203829658277237
Validation loss: 2.55144665360292

Epoch: 6| Step: 6
Training loss: 1.5839944596916178
Validation loss: 2.5179956216746295

Epoch: 6| Step: 7
Training loss: 1.8346863724450553
Validation loss: 2.4955264756756104

Epoch: 6| Step: 8
Training loss: 1.2304588680778785
Validation loss: 2.512386425101971

Epoch: 6| Step: 9
Training loss: 2.0548005163636542
Validation loss: 2.5168740624955817

Epoch: 6| Step: 10
Training loss: 2.2932995845100494
Validation loss: 2.539864563071972

Epoch: 6| Step: 11
Training loss: 2.081901846866896
Validation loss: 2.5199129983476283

Epoch: 6| Step: 12
Training loss: 1.382712495280379
Validation loss: 2.540162866281914

Epoch: 6| Step: 13
Training loss: 1.5105385128289923
Validation loss: 2.56915614312073

Epoch: 325| Step: 0
Training loss: 1.674224343693263
Validation loss: 2.5806809673305633

Epoch: 6| Step: 1
Training loss: 2.123433489371155
Validation loss: 2.642757119307484

Epoch: 6| Step: 2
Training loss: 1.8897554273652313
Validation loss: 2.6118477775309508

Epoch: 6| Step: 3
Training loss: 1.7792896392038657
Validation loss: 2.569896583183348

Epoch: 6| Step: 4
Training loss: 1.3451390738359381
Validation loss: 2.579417265106777

Epoch: 6| Step: 5
Training loss: 1.6318769192985665
Validation loss: 2.4993193653551087

Epoch: 6| Step: 6
Training loss: 2.048362482648285
Validation loss: 2.49080100400876

Epoch: 6| Step: 7
Training loss: 1.8022992072783455
Validation loss: 2.478950961263084

Epoch: 6| Step: 8
Training loss: 1.348618139232722
Validation loss: 2.4834762003038375

Epoch: 6| Step: 9
Training loss: 1.922927816185773
Validation loss: 2.4869912245426495

Epoch: 6| Step: 10
Training loss: 1.833244198741965
Validation loss: 2.504722299570046

Epoch: 6| Step: 11
Training loss: 1.8339243788650692
Validation loss: 2.516072567127255

Epoch: 6| Step: 12
Training loss: 1.7623854769029983
Validation loss: 2.5023262803802484

Epoch: 6| Step: 13
Training loss: 1.2519929257640916
Validation loss: 2.583992386909072

Epoch: 326| Step: 0
Training loss: 1.8636690451976918
Validation loss: 2.559480570695126

Epoch: 6| Step: 1
Training loss: 1.5709567290526063
Validation loss: 2.606617565139731

Epoch: 6| Step: 2
Training loss: 1.7316678200584195
Validation loss: 2.6589383452288686

Epoch: 6| Step: 3
Training loss: 2.0693906639103092
Validation loss: 2.629281337028856

Epoch: 6| Step: 4
Training loss: 1.739364869187268
Validation loss: 2.634960954390118

Epoch: 6| Step: 5
Training loss: 2.220672634052988
Validation loss: 2.5971867110691393

Epoch: 6| Step: 6
Training loss: 1.9193011160281277
Validation loss: 2.581055164758083

Epoch: 6| Step: 7
Training loss: 1.6932535633436596
Validation loss: 2.5850363983257854

Epoch: 6| Step: 8
Training loss: 2.1001168990523023
Validation loss: 2.6470497268840423

Epoch: 6| Step: 9
Training loss: 1.5076791971211532
Validation loss: 2.5639007740519055

Epoch: 6| Step: 10
Training loss: 1.578164128488851
Validation loss: 2.4920695086603155

Epoch: 6| Step: 11
Training loss: 1.7611067358030141
Validation loss: 2.49567059117406

Epoch: 6| Step: 12
Training loss: 1.3525668254991308
Validation loss: 2.4865790612825953

Epoch: 6| Step: 13
Training loss: 1.6170842234487752
Validation loss: 2.4903076081322233

Epoch: 327| Step: 0
Training loss: 1.6517377603411407
Validation loss: 2.485704494116696

Epoch: 6| Step: 1
Training loss: 1.284596422697714
Validation loss: 2.506535300919834

Epoch: 6| Step: 2
Training loss: 1.9306065150913796
Validation loss: 2.541659673045391

Epoch: 6| Step: 3
Training loss: 1.40677683816151
Validation loss: 2.5671748031949235

Epoch: 6| Step: 4
Training loss: 1.618368408708268
Validation loss: 2.588852275938309

Epoch: 6| Step: 5
Training loss: 1.9736747303115973
Validation loss: 2.5783516678243514

Epoch: 6| Step: 6
Training loss: 1.2908435885812326
Validation loss: 2.5589621630509054

Epoch: 6| Step: 7
Training loss: 1.6070518392190645
Validation loss: 2.594450139913722

Epoch: 6| Step: 8
Training loss: 1.6469442103282046
Validation loss: 2.550291114595623

Epoch: 6| Step: 9
Training loss: 1.712139734951596
Validation loss: 2.5151707967776047

Epoch: 6| Step: 10
Training loss: 1.7187570745149148
Validation loss: 2.520356571941841

Epoch: 6| Step: 11
Training loss: 2.2065433469275235
Validation loss: 2.4901855144818503

Epoch: 6| Step: 12
Training loss: 1.994031225000159
Validation loss: 2.54583591101017

Epoch: 6| Step: 13
Training loss: 2.2050741244635432
Validation loss: 2.535916865294832

Epoch: 328| Step: 0
Training loss: 1.541123457738999
Validation loss: 2.489507096744701

Epoch: 6| Step: 1
Training loss: 1.7269087914533945
Validation loss: 2.567510358646524

Epoch: 6| Step: 2
Training loss: 1.432073384615663
Validation loss: 2.5176718620170258

Epoch: 6| Step: 3
Training loss: 2.1319204847526807
Validation loss: 2.535037303890857

Epoch: 6| Step: 4
Training loss: 1.9163292988732314
Validation loss: 2.5572529703748845

Epoch: 6| Step: 5
Training loss: 2.0888112592588732
Validation loss: 2.548854300606932

Epoch: 6| Step: 6
Training loss: 1.2562919571735447
Validation loss: 2.529265320334357

Epoch: 6| Step: 7
Training loss: 1.3481774690522006
Validation loss: 2.4974130756524153

Epoch: 6| Step: 8
Training loss: 1.795630712503388
Validation loss: 2.495249733387261

Epoch: 6| Step: 9
Training loss: 2.0360030684082653
Validation loss: 2.53687242787085

Epoch: 6| Step: 10
Training loss: 2.196637497024705
Validation loss: 2.524911078218672

Epoch: 6| Step: 11
Training loss: 2.0005270740266363
Validation loss: 2.5389613048243618

Epoch: 6| Step: 12
Training loss: 1.3899960756589531
Validation loss: 2.54367005756052

Epoch: 6| Step: 13
Training loss: 1.134950343738875
Validation loss: 2.533967023781947

Epoch: 329| Step: 0
Training loss: 1.420713600117976
Validation loss: 2.5866070789998235

Epoch: 6| Step: 1
Training loss: 1.1516880044648794
Validation loss: 2.561489541782939

Epoch: 6| Step: 2
Training loss: 1.7866024111229386
Validation loss: 2.6292996993064115

Epoch: 6| Step: 3
Training loss: 1.1449557093420604
Validation loss: 2.632701445066374

Epoch: 6| Step: 4
Training loss: 1.204011169654261
Validation loss: 2.674332067102371

Epoch: 6| Step: 5
Training loss: 2.1594811155355105
Validation loss: 2.662293638371976

Epoch: 6| Step: 6
Training loss: 2.505847577062055
Validation loss: 2.619426229078061

Epoch: 6| Step: 7
Training loss: 2.44495611061692
Validation loss: 2.57218900936711

Epoch: 6| Step: 8
Training loss: 1.6301531147567916
Validation loss: 2.5585938043570087

Epoch: 6| Step: 9
Training loss: 1.66154920594567
Validation loss: 2.5247924914561857

Epoch: 6| Step: 10
Training loss: 1.5833230101934836
Validation loss: 2.490368840196234

Epoch: 6| Step: 11
Training loss: 1.2458527430592692
Validation loss: 2.4904055388224724

Epoch: 6| Step: 12
Training loss: 1.693283343340671
Validation loss: 2.5355950256486617

Epoch: 6| Step: 13
Training loss: 1.6908794049484597
Validation loss: 2.4593931489086582

Epoch: 330| Step: 0
Training loss: 2.099162379744169
Validation loss: 2.463326028710643

Epoch: 6| Step: 1
Training loss: 1.9213697187939176
Validation loss: 2.4888019745510603

Epoch: 6| Step: 2
Training loss: 1.623636260362257
Validation loss: 2.503828994741462

Epoch: 6| Step: 3
Training loss: 1.342583527053296
Validation loss: 2.526045696347093

Epoch: 6| Step: 4
Training loss: 2.075542709892615
Validation loss: 2.5537383234270896

Epoch: 6| Step: 5
Training loss: 1.5908649735712148
Validation loss: 2.579693604124546

Epoch: 6| Step: 6
Training loss: 2.0970458096151625
Validation loss: 2.611363915003428

Epoch: 6| Step: 7
Training loss: 1.7524442632847983
Validation loss: 2.6218806306508

Epoch: 6| Step: 8
Training loss: 1.996262037495321
Validation loss: 2.618502431743455

Epoch: 6| Step: 9
Training loss: 1.5227202463182012
Validation loss: 2.5518000750442837

Epoch: 6| Step: 10
Training loss: 1.426106622227604
Validation loss: 2.51010904498276

Epoch: 6| Step: 11
Training loss: 1.4922266450710528
Validation loss: 2.5211968173014667

Epoch: 6| Step: 12
Training loss: 1.449255929968657
Validation loss: 2.509758136109733

Epoch: 6| Step: 13
Training loss: 1.4919404629239292
Validation loss: 2.4885894967729794

Epoch: 331| Step: 0
Training loss: 1.6852911161696174
Validation loss: 2.48287723585702

Epoch: 6| Step: 1
Training loss: 1.8732129799995303
Validation loss: 2.533094526839071

Epoch: 6| Step: 2
Training loss: 1.9252760032856366
Validation loss: 2.5132651149368983

Epoch: 6| Step: 3
Training loss: 1.8278994298811648
Validation loss: 2.4831767041353645

Epoch: 6| Step: 4
Training loss: 1.6338862488839276
Validation loss: 2.464741635713715

Epoch: 6| Step: 5
Training loss: 1.5309715796386074
Validation loss: 2.4895721791761045

Epoch: 6| Step: 6
Training loss: 1.5298337030728593
Validation loss: 2.4931563324838955

Epoch: 6| Step: 7
Training loss: 1.7786492887121756
Validation loss: 2.4948903159200158

Epoch: 6| Step: 8
Training loss: 2.2869119273892586
Validation loss: 2.5699535300856557

Epoch: 6| Step: 9
Training loss: 1.8471908789758524
Validation loss: 2.5217623273030645

Epoch: 6| Step: 10
Training loss: 1.2048616137520325
Validation loss: 2.5670054455728977

Epoch: 6| Step: 11
Training loss: 1.7349601651986277
Validation loss: 2.514399496552274

Epoch: 6| Step: 12
Training loss: 1.295915915422359
Validation loss: 2.497095598478943

Epoch: 6| Step: 13
Training loss: 2.0797600301451853
Validation loss: 2.5024383415885705

Epoch: 332| Step: 0
Training loss: 2.216562724245889
Validation loss: 2.517675350058913

Epoch: 6| Step: 1
Training loss: 1.3252018342950471
Validation loss: 2.495002774814854

Epoch: 6| Step: 2
Training loss: 1.1793447337590595
Validation loss: 2.5023284241517354

Epoch: 6| Step: 3
Training loss: 1.3574757956354448
Validation loss: 2.498302908893042

Epoch: 6| Step: 4
Training loss: 1.489470960028571
Validation loss: 2.516459229953885

Epoch: 6| Step: 5
Training loss: 1.6898394016275176
Validation loss: 2.5127655110423026

Epoch: 6| Step: 6
Training loss: 1.4114450076366842
Validation loss: 2.511270786678502

Epoch: 6| Step: 7
Training loss: 1.8283399145841888
Validation loss: 2.5561891006017885

Epoch: 6| Step: 8
Training loss: 1.157036539564077
Validation loss: 2.5254428009441545

Epoch: 6| Step: 9
Training loss: 1.8552722063872704
Validation loss: 2.5982589290243654

Epoch: 6| Step: 10
Training loss: 1.861724266975735
Validation loss: 2.6164411476976777

Epoch: 6| Step: 11
Training loss: 2.0763883289462566
Validation loss: 2.6436552008187526

Epoch: 6| Step: 12
Training loss: 1.850162089180525
Validation loss: 2.6301265338729882

Epoch: 6| Step: 13
Training loss: 1.9143003977637412
Validation loss: 2.63594970037007

Epoch: 333| Step: 0
Training loss: 1.5413998123707353
Validation loss: 2.6045562503594386

Epoch: 6| Step: 1
Training loss: 1.5424309288152958
Validation loss: 2.6129330192552622

Epoch: 6| Step: 2
Training loss: 1.7190629154073758
Validation loss: 2.6172251532583717

Epoch: 6| Step: 3
Training loss: 1.618918409387472
Validation loss: 2.572063224706048

Epoch: 6| Step: 4
Training loss: 1.9201364484621635
Validation loss: 2.523313631495666

Epoch: 6| Step: 5
Training loss: 2.0167791329962395
Validation loss: 2.5232953010860926

Epoch: 6| Step: 6
Training loss: 1.89823749257879
Validation loss: 2.498058312106303

Epoch: 6| Step: 7
Training loss: 1.4298931870216367
Validation loss: 2.527677723251657

Epoch: 6| Step: 8
Training loss: 1.4715937416582305
Validation loss: 2.5360709853501304

Epoch: 6| Step: 9
Training loss: 1.3525229332578443
Validation loss: 2.5262761796981805

Epoch: 6| Step: 10
Training loss: 1.3542051554369763
Validation loss: 2.515367119565331

Epoch: 6| Step: 11
Training loss: 1.4905708703023552
Validation loss: 2.5517074204306405

Epoch: 6| Step: 12
Training loss: 1.532095617238669
Validation loss: 2.5637113917739023

Epoch: 6| Step: 13
Training loss: 1.7860307617400417
Validation loss: 2.573251267476864

Epoch: 334| Step: 0
Training loss: 1.4076997701239446
Validation loss: 2.545286951157353

Epoch: 6| Step: 1
Training loss: 1.211374806842704
Validation loss: 2.574029555673958

Epoch: 6| Step: 2
Training loss: 2.0594485279901797
Validation loss: 2.5779606545210196

Epoch: 6| Step: 3
Training loss: 2.3862110353368946
Validation loss: 2.5947551694610778

Epoch: 6| Step: 4
Training loss: 2.012354363331211
Validation loss: 2.565280119513867

Epoch: 6| Step: 5
Training loss: 1.494942882301526
Validation loss: 2.606623418998821

Epoch: 6| Step: 6
Training loss: 1.8767305653039528
Validation loss: 2.603873691608991

Epoch: 6| Step: 7
Training loss: 1.6426221045594909
Validation loss: 2.6042240187369514

Epoch: 6| Step: 8
Training loss: 1.7149120134743765
Validation loss: 2.559093785624399

Epoch: 6| Step: 9
Training loss: 1.9275362324556182
Validation loss: 2.6458144950696676

Epoch: 6| Step: 10
Training loss: 1.7078463705461253
Validation loss: 2.5583938171079406

Epoch: 6| Step: 11
Training loss: 1.5220036728372257
Validation loss: 2.5044576163802565

Epoch: 6| Step: 12
Training loss: 1.6161367347486575
Validation loss: 2.4862099354979117

Epoch: 6| Step: 13
Training loss: 1.7252469812025992
Validation loss: 2.5109146436795577

Epoch: 335| Step: 0
Training loss: 1.8272669155868662
Validation loss: 2.5063995231108662

Epoch: 6| Step: 1
Training loss: 2.0843484948344653
Validation loss: 2.5225987570881934

Epoch: 6| Step: 2
Training loss: 1.8500432086744358
Validation loss: 2.518928049513502

Epoch: 6| Step: 3
Training loss: 1.5933529228272463
Validation loss: 2.4876540834382186

Epoch: 6| Step: 4
Training loss: 1.712812954784793
Validation loss: 2.508475543792998

Epoch: 6| Step: 5
Training loss: 1.7273726827958016
Validation loss: 2.559929915725489

Epoch: 6| Step: 6
Training loss: 0.923356078765173
Validation loss: 2.5996178737456557

Epoch: 6| Step: 7
Training loss: 2.138433964007402
Validation loss: 2.6369808415264364

Epoch: 6| Step: 8
Training loss: 1.5791045066791896
Validation loss: 2.6133687109725945

Epoch: 6| Step: 9
Training loss: 1.9878809437859906
Validation loss: 2.6210160677408973

Epoch: 6| Step: 10
Training loss: 2.0834944344856585
Validation loss: 2.6223640225301605

Epoch: 6| Step: 11
Training loss: 1.2192063088706881
Validation loss: 2.6434747040054605

Epoch: 6| Step: 12
Training loss: 1.2491229795349692
Validation loss: 2.6059528837075074

Epoch: 6| Step: 13
Training loss: 1.5169876108386608
Validation loss: 2.5404801700065627

Epoch: 336| Step: 0
Training loss: 1.6164047632076899
Validation loss: 2.4968076032407684

Epoch: 6| Step: 1
Training loss: 1.4268404436041602
Validation loss: 2.4463091719378887

Epoch: 6| Step: 2
Training loss: 2.090986563261289
Validation loss: 2.4559805947990965

Epoch: 6| Step: 3
Training loss: 1.915908110515599
Validation loss: 2.431681118670112

Epoch: 6| Step: 4
Training loss: 1.3898071284237714
Validation loss: 2.472813268319344

Epoch: 6| Step: 5
Training loss: 2.33484820736343
Validation loss: 2.4454126063321984

Epoch: 6| Step: 6
Training loss: 1.2035855489325398
Validation loss: 2.474454132726395

Epoch: 6| Step: 7
Training loss: 1.2916612266097822
Validation loss: 2.4768953230090904

Epoch: 6| Step: 8
Training loss: 1.5944696185524183
Validation loss: 2.507104973894318

Epoch: 6| Step: 9
Training loss: 1.2721502432712413
Validation loss: 2.5097586110928662

Epoch: 6| Step: 10
Training loss: 1.7979453837848134
Validation loss: 2.480826733005582

Epoch: 6| Step: 11
Training loss: 1.53575941665845
Validation loss: 2.540895021798447

Epoch: 6| Step: 12
Training loss: 2.046775990195441
Validation loss: 2.539285878845786

Epoch: 6| Step: 13
Training loss: 1.5931237430200897
Validation loss: 2.562751695630823

Epoch: 337| Step: 0
Training loss: 1.4386572947657954
Validation loss: 2.571035420673687

Epoch: 6| Step: 1
Training loss: 1.6034573394553173
Validation loss: 2.6160643183950847

Epoch: 6| Step: 2
Training loss: 1.5445847173533154
Validation loss: 2.636815982485761

Epoch: 6| Step: 3
Training loss: 1.28435354470109
Validation loss: 2.64147815051752

Epoch: 6| Step: 4
Training loss: 1.7932681828875556
Validation loss: 2.6225944123124165

Epoch: 6| Step: 5
Training loss: 1.6514794363970031
Validation loss: 2.614089726718407

Epoch: 6| Step: 6
Training loss: 1.4810376043188418
Validation loss: 2.5842352005564715

Epoch: 6| Step: 7
Training loss: 1.66284980822403
Validation loss: 2.60868456266299

Epoch: 6| Step: 8
Training loss: 1.5581089881658778
Validation loss: 2.534093084307179

Epoch: 6| Step: 9
Training loss: 2.259677736886138
Validation loss: 2.5057708415375264

Epoch: 6| Step: 10
Training loss: 1.3823813504425806
Validation loss: 2.487703345084811

Epoch: 6| Step: 11
Training loss: 1.8437435344000774
Validation loss: 2.5037888109078366

Epoch: 6| Step: 12
Training loss: 1.4440213596581761
Validation loss: 2.492409675285381

Epoch: 6| Step: 13
Training loss: 1.8793239961838528
Validation loss: 2.525483521348251

Epoch: 338| Step: 0
Training loss: 1.9664714282588927
Validation loss: 2.5233770467565604

Epoch: 6| Step: 1
Training loss: 1.96957719167461
Validation loss: 2.5335519472544163

Epoch: 6| Step: 2
Training loss: 1.3569779143451255
Validation loss: 2.540851592609994

Epoch: 6| Step: 3
Training loss: 1.823209430255245
Validation loss: 2.535441487884852

Epoch: 6| Step: 4
Training loss: 1.9760853790880486
Validation loss: 2.5627746589905005

Epoch: 6| Step: 5
Training loss: 1.8649014959835493
Validation loss: 2.546183236691491

Epoch: 6| Step: 6
Training loss: 1.5269568848484345
Validation loss: 2.5934117567745374

Epoch: 6| Step: 7
Training loss: 1.453477878177819
Validation loss: 2.666604172947872

Epoch: 6| Step: 8
Training loss: 1.2630732679461614
Validation loss: 2.6590518909033043

Epoch: 6| Step: 9
Training loss: 2.4134317209761633
Validation loss: 2.663429490821508

Epoch: 6| Step: 10
Training loss: 1.8658793827091535
Validation loss: 2.670400052526103

Epoch: 6| Step: 11
Training loss: 1.5933118479701964
Validation loss: 2.553265205807404

Epoch: 6| Step: 12
Training loss: 1.1842442100597572
Validation loss: 2.5730473772172684

Epoch: 6| Step: 13
Training loss: 1.4427304685067446
Validation loss: 2.6582699593749854

Epoch: 339| Step: 0
Training loss: 1.1750165410602256
Validation loss: 2.6125131342069476

Epoch: 6| Step: 1
Training loss: 2.011539903116474
Validation loss: 2.614826120196153

Epoch: 6| Step: 2
Training loss: 1.3917271393449955
Validation loss: 2.6243038768235225

Epoch: 6| Step: 3
Training loss: 1.4071750565261854
Validation loss: 2.660183033035792

Epoch: 6| Step: 4
Training loss: 1.7263289764038976
Validation loss: 2.6423189497090576

Epoch: 6| Step: 5
Training loss: 1.8607952560011727
Validation loss: 2.605547627823551

Epoch: 6| Step: 6
Training loss: 1.7713644540187605
Validation loss: 2.625962217269761

Epoch: 6| Step: 7
Training loss: 2.063113381469517
Validation loss: 2.5915690985300883

Epoch: 6| Step: 8
Training loss: 1.5189196770471587
Validation loss: 2.6190823352461488

Epoch: 6| Step: 9
Training loss: 1.6786981552196603
Validation loss: 2.61503430513597

Epoch: 6| Step: 10
Training loss: 1.7737152285457487
Validation loss: 2.610141831827937

Epoch: 6| Step: 11
Training loss: 1.589535620070382
Validation loss: 2.5801479225237607

Epoch: 6| Step: 12
Training loss: 1.7184083078766075
Validation loss: 2.589485623170185

Epoch: 6| Step: 13
Training loss: 1.5509215322699028
Validation loss: 2.533094715082003

Epoch: 340| Step: 0
Training loss: 1.7260382361215845
Validation loss: 2.536262682210425

Epoch: 6| Step: 1
Training loss: 1.3912670496386879
Validation loss: 2.5258800861290256

Epoch: 6| Step: 2
Training loss: 1.5202427941207852
Validation loss: 2.4646360830776337

Epoch: 6| Step: 3
Training loss: 1.7338973753764675
Validation loss: 2.4893213849874916

Epoch: 6| Step: 4
Training loss: 1.7961973819976509
Validation loss: 2.518682071599638

Epoch: 6| Step: 5
Training loss: 1.897619502912012
Validation loss: 2.487318857904235

Epoch: 6| Step: 6
Training loss: 1.3489007925283074
Validation loss: 2.5004242934348153

Epoch: 6| Step: 7
Training loss: 1.4422808219167302
Validation loss: 2.4985833763810694

Epoch: 6| Step: 8
Training loss: 1.3501995469011336
Validation loss: 2.581798102413308

Epoch: 6| Step: 9
Training loss: 1.7397568515270467
Validation loss: 2.5334736275934926

Epoch: 6| Step: 10
Training loss: 1.404742980472415
Validation loss: 2.528529270889043

Epoch: 6| Step: 11
Training loss: 2.61524786742692
Validation loss: 2.5459872611836647

Epoch: 6| Step: 12
Training loss: 1.1854796037017452
Validation loss: 2.5789532804779896

Epoch: 6| Step: 13
Training loss: 1.227541393195878
Validation loss: 2.560912268411324

Epoch: 341| Step: 0
Training loss: 2.127972487307644
Validation loss: 2.576458124314113

Epoch: 6| Step: 1
Training loss: 1.6535485747163683
Validation loss: 2.602706642314199

Epoch: 6| Step: 2
Training loss: 1.0622205927857156
Validation loss: 2.635887953242271

Epoch: 6| Step: 3
Training loss: 1.648432944051946
Validation loss: 2.6391522064230406

Epoch: 6| Step: 4
Training loss: 1.308466754273793
Validation loss: 2.5752237660978627

Epoch: 6| Step: 5
Training loss: 1.632348975867634
Validation loss: 2.553402623273087

Epoch: 6| Step: 6
Training loss: 1.7869958393323864
Validation loss: 2.5538114548613007

Epoch: 6| Step: 7
Training loss: 1.3781401583644537
Validation loss: 2.5183713150273896

Epoch: 6| Step: 8
Training loss: 1.5830602243019973
Validation loss: 2.507357341147662

Epoch: 6| Step: 9
Training loss: 0.9537340313335808
Validation loss: 2.5289186801237626

Epoch: 6| Step: 10
Training loss: 1.4272887738711304
Validation loss: 2.4927047782603724

Epoch: 6| Step: 11
Training loss: 1.4737088516871355
Validation loss: 2.5283252553448246

Epoch: 6| Step: 12
Training loss: 2.343600052169484
Validation loss: 2.5507068477137143

Epoch: 6| Step: 13
Training loss: 1.6493208267664945
Validation loss: 2.510889520604136

Epoch: 342| Step: 0
Training loss: 1.4547338296004981
Validation loss: 2.5053564227476395

Epoch: 6| Step: 1
Training loss: 2.180088894982692
Validation loss: 2.5295483791839484

Epoch: 6| Step: 2
Training loss: 1.915092969385659
Validation loss: 2.5661487188852723

Epoch: 6| Step: 3
Training loss: 1.6883473564737976
Validation loss: 2.570674093952305

Epoch: 6| Step: 4
Training loss: 2.029431042169069
Validation loss: 2.5770903389624005

Epoch: 6| Step: 5
Training loss: 1.6129784103528493
Validation loss: 2.645376231039275

Epoch: 6| Step: 6
Training loss: 1.3294227542738215
Validation loss: 2.679118400918127

Epoch: 6| Step: 7
Training loss: 1.7189389211689496
Validation loss: 2.6364267597294875

Epoch: 6| Step: 8
Training loss: 1.4735306387758806
Validation loss: 2.643179897105978

Epoch: 6| Step: 9
Training loss: 1.5140285932997917
Validation loss: 2.6043255617621517

Epoch: 6| Step: 10
Training loss: 1.387324198333628
Validation loss: 2.565019857244238

Epoch: 6| Step: 11
Training loss: 1.4646562379984638
Validation loss: 2.5661827233921644

Epoch: 6| Step: 12
Training loss: 1.4111279972614643
Validation loss: 2.5776157222932503

Epoch: 6| Step: 13
Training loss: 1.5151658296631376
Validation loss: 2.5589017493380832

Epoch: 343| Step: 0
Training loss: 1.0295378603761378
Validation loss: 2.5508824435963677

Epoch: 6| Step: 1
Training loss: 1.6250878823798312
Validation loss: 2.5289505297979886

Epoch: 6| Step: 2
Training loss: 1.6351164848059838
Validation loss: 2.545429186003143

Epoch: 6| Step: 3
Training loss: 1.3532046006115752
Validation loss: 2.5224955388166124

Epoch: 6| Step: 4
Training loss: 1.9267800238479957
Validation loss: 2.533181501427142

Epoch: 6| Step: 5
Training loss: 1.73892508595377
Validation loss: 2.556031436483577

Epoch: 6| Step: 6
Training loss: 1.5796152764326212
Validation loss: 2.5969728723009333

Epoch: 6| Step: 7
Training loss: 1.7882252029028662
Validation loss: 2.560317591050581

Epoch: 6| Step: 8
Training loss: 1.9060442453874873
Validation loss: 2.5598150934556005

Epoch: 6| Step: 9
Training loss: 1.2392409784182181
Validation loss: 2.5627546416506597

Epoch: 6| Step: 10
Training loss: 2.105332520559459
Validation loss: 2.5680574459630368

Epoch: 6| Step: 11
Training loss: 1.9132677569211456
Validation loss: 2.5248318845977376

Epoch: 6| Step: 12
Training loss: 1.5870129175940413
Validation loss: 2.527542020006343

Epoch: 6| Step: 13
Training loss: 1.645103735508155
Validation loss: 2.5277030410361156

Epoch: 344| Step: 0
Training loss: 1.6110660594180606
Validation loss: 2.505638987006648

Epoch: 6| Step: 1
Training loss: 1.8444843446227983
Validation loss: 2.5280760186239997

Epoch: 6| Step: 2
Training loss: 1.7259204758262596
Validation loss: 2.550223133198056

Epoch: 6| Step: 3
Training loss: 1.382937495729994
Validation loss: 2.5087310914988725

Epoch: 6| Step: 4
Training loss: 1.4608172198877771
Validation loss: 2.491141248142224

Epoch: 6| Step: 5
Training loss: 1.270311415180339
Validation loss: 2.5025358769642576

Epoch: 6| Step: 6
Training loss: 1.1818040971150103
Validation loss: 2.498286987567856

Epoch: 6| Step: 7
Training loss: 1.120574618311725
Validation loss: 2.504303669051306

Epoch: 6| Step: 8
Training loss: 1.2632566356443133
Validation loss: 2.4860689637952467

Epoch: 6| Step: 9
Training loss: 1.6607252873585148
Validation loss: 2.535305432209834

Epoch: 6| Step: 10
Training loss: 1.9813017588692758
Validation loss: 2.531997491803165

Epoch: 6| Step: 11
Training loss: 1.7278593552449715
Validation loss: 2.5179750353065704

Epoch: 6| Step: 12
Training loss: 1.9771660045494153
Validation loss: 2.524692439871522

Epoch: 6| Step: 13
Training loss: 1.5471690505315996
Validation loss: 2.5400295665602086

Epoch: 345| Step: 0
Training loss: 1.3205842410006814
Validation loss: 2.5374946409397507

Epoch: 6| Step: 1
Training loss: 1.9984528995066737
Validation loss: 2.539962077095501

Epoch: 6| Step: 2
Training loss: 1.6870914953776617
Validation loss: 2.5440626706750136

Epoch: 6| Step: 3
Training loss: 1.0232005536630429
Validation loss: 2.575081479533407

Epoch: 6| Step: 4
Training loss: 1.1982432321110208
Validation loss: 2.520942627820525

Epoch: 6| Step: 5
Training loss: 1.8186709488406254
Validation loss: 2.552771134368458

Epoch: 6| Step: 6
Training loss: 2.0086244358966665
Validation loss: 2.5255766502836794

Epoch: 6| Step: 7
Training loss: 1.075284727226244
Validation loss: 2.4959906376180143

Epoch: 6| Step: 8
Training loss: 1.8369947919693883
Validation loss: 2.526075757507791

Epoch: 6| Step: 9
Training loss: 1.6438636421401245
Validation loss: 2.544318806180692

Epoch: 6| Step: 10
Training loss: 1.4856937372966477
Validation loss: 2.5481702245361046

Epoch: 6| Step: 11
Training loss: 1.07812992039539
Validation loss: 2.55160815946984

Epoch: 6| Step: 12
Training loss: 1.314812711642876
Validation loss: 2.5151426828331336

Epoch: 6| Step: 13
Training loss: 1.3562889585744629
Validation loss: 2.5289461224052165

Epoch: 346| Step: 0
Training loss: 1.0959622489804042
Validation loss: 2.5083635701187306

Epoch: 6| Step: 1
Training loss: 1.5546398059679447
Validation loss: 2.547339601792376

Epoch: 6| Step: 2
Training loss: 1.4118240089209162
Validation loss: 2.5674334695548024

Epoch: 6| Step: 3
Training loss: 1.8142338713693458
Validation loss: 2.5659060752876117

Epoch: 6| Step: 4
Training loss: 1.1926820521672785
Validation loss: 2.5778646010085984

Epoch: 6| Step: 5
Training loss: 2.0253151683675017
Validation loss: 2.51680222603036

Epoch: 6| Step: 6
Training loss: 1.3175771695723633
Validation loss: 2.5563881100728225

Epoch: 6| Step: 7
Training loss: 1.4649812760963001
Validation loss: 2.599274967045442

Epoch: 6| Step: 8
Training loss: 1.1597394098060247
Validation loss: 2.592391750021675

Epoch: 6| Step: 9
Training loss: 1.6669964781908753
Validation loss: 2.524247550268761

Epoch: 6| Step: 10
Training loss: 1.1164109525588175
Validation loss: 2.507759394732071

Epoch: 6| Step: 11
Training loss: 1.974877947645452
Validation loss: 2.547917720100973

Epoch: 6| Step: 12
Training loss: 1.4118652132665246
Validation loss: 2.5240868834158103

Epoch: 6| Step: 13
Training loss: 1.9132738629623371
Validation loss: 2.5484158120322977

Epoch: 347| Step: 0
Training loss: 1.1417101570997374
Validation loss: 2.555517732529235

Epoch: 6| Step: 1
Training loss: 1.8335284071511742
Validation loss: 2.5673860163213416

Epoch: 6| Step: 2
Training loss: 1.2663473257938709
Validation loss: 2.542643833449284

Epoch: 6| Step: 3
Training loss: 1.9351531551183871
Validation loss: 2.537413577156809

Epoch: 6| Step: 4
Training loss: 1.3906837193811123
Validation loss: 2.555703306303744

Epoch: 6| Step: 5
Training loss: 1.2172243399180633
Validation loss: 2.5319019623991212

Epoch: 6| Step: 6
Training loss: 1.1230391261621258
Validation loss: 2.517136129797918

Epoch: 6| Step: 7
Training loss: 1.6814519796329008
Validation loss: 2.4754815053889097

Epoch: 6| Step: 8
Training loss: 1.7212294294337345
Validation loss: 2.4913596728566385

Epoch: 6| Step: 9
Training loss: 1.6466100606313752
Validation loss: 2.5199702863606595

Epoch: 6| Step: 10
Training loss: 1.5131505843799953
Validation loss: 2.5083681008051144

Epoch: 6| Step: 11
Training loss: 1.6470228154189297
Validation loss: 2.516652752246243

Epoch: 6| Step: 12
Training loss: 1.3409686023925165
Validation loss: 2.4979580725980948

Epoch: 6| Step: 13
Training loss: 1.4401513402937307
Validation loss: 2.4838778880138386

Epoch: 348| Step: 0
Training loss: 1.8961076922192905
Validation loss: 2.5179752878042465

Epoch: 6| Step: 1
Training loss: 1.4194399764970873
Validation loss: 2.557070850128224

Epoch: 6| Step: 2
Training loss: 1.1553192000624322
Validation loss: 2.5575009407347498

Epoch: 6| Step: 3
Training loss: 1.6338318193841073
Validation loss: 2.532695185026888

Epoch: 6| Step: 4
Training loss: 1.3043505753267035
Validation loss: 2.557945794524152

Epoch: 6| Step: 5
Training loss: 1.6592943534722355
Validation loss: 2.5586501408931692

Epoch: 6| Step: 6
Training loss: 1.3038261905545871
Validation loss: 2.5621251863353396

Epoch: 6| Step: 7
Training loss: 1.1626785551376202
Validation loss: 2.5287031775486324

Epoch: 6| Step: 8
Training loss: 1.920699651814692
Validation loss: 2.5362961160431996

Epoch: 6| Step: 9
Training loss: 2.0903775968265763
Validation loss: 2.553694404660373

Epoch: 6| Step: 10
Training loss: 1.3618812696042115
Validation loss: 2.549752947738813

Epoch: 6| Step: 11
Training loss: 1.339346746234813
Validation loss: 2.5551593123185343

Epoch: 6| Step: 12
Training loss: 1.4093930194658593
Validation loss: 2.521834440035148

Epoch: 6| Step: 13
Training loss: 1.4147603541735296
Validation loss: 2.5007832810086703

Epoch: 349| Step: 0
Training loss: 1.4087665927860917
Validation loss: 2.5213195211079937

Epoch: 6| Step: 1
Training loss: 1.7725437954117895
Validation loss: 2.503814870165705

Epoch: 6| Step: 2
Training loss: 1.2049100440230474
Validation loss: 2.5118848113935957

Epoch: 6| Step: 3
Training loss: 2.044304201538145
Validation loss: 2.509121007800559

Epoch: 6| Step: 4
Training loss: 0.9988233677314786
Validation loss: 2.5079416021943355

Epoch: 6| Step: 5
Training loss: 1.4627670826713912
Validation loss: 2.4733877440874346

Epoch: 6| Step: 6
Training loss: 1.6210399205106456
Validation loss: 2.507801059843373

Epoch: 6| Step: 7
Training loss: 1.4216224529968378
Validation loss: 2.5092146173374212

Epoch: 6| Step: 8
Training loss: 1.9898169681587452
Validation loss: 2.5183351817230504

Epoch: 6| Step: 9
Training loss: 0.926974240145738
Validation loss: 2.5141273210418356

Epoch: 6| Step: 10
Training loss: 1.4938878462645035
Validation loss: 2.5466214075194387

Epoch: 6| Step: 11
Training loss: 1.1768865617780768
Validation loss: 2.5400710308600973

Epoch: 6| Step: 12
Training loss: 1.8609629029558807
Validation loss: 2.5283082578903837

Epoch: 6| Step: 13
Training loss: 1.5066348205565367
Validation loss: 2.5716055542348744

Epoch: 350| Step: 0
Training loss: 1.3495980688744948
Validation loss: 2.52535311303991

Epoch: 6| Step: 1
Training loss: 1.6532533995984073
Validation loss: 2.572853139075025

Epoch: 6| Step: 2
Training loss: 1.4216513824684784
Validation loss: 2.5399750150618146

Epoch: 6| Step: 3
Training loss: 1.4546588472849065
Validation loss: 2.5414290369190584

Epoch: 6| Step: 4
Training loss: 1.2223744905632432
Validation loss: 2.552173789361078

Epoch: 6| Step: 5
Training loss: 1.857635710367908
Validation loss: 2.5172267182237347

Epoch: 6| Step: 6
Training loss: 1.613484219767381
Validation loss: 2.5112377317213412

Epoch: 6| Step: 7
Training loss: 1.478577868261326
Validation loss: 2.509995695619578

Epoch: 6| Step: 8
Training loss: 1.7282659490404806
Validation loss: 2.502190377399036

Epoch: 6| Step: 9
Training loss: 1.1443893292549248
Validation loss: 2.540466734088461

Epoch: 6| Step: 10
Training loss: 1.309980289878787
Validation loss: 2.5437586310112916

Epoch: 6| Step: 11
Training loss: 1.6652123861630634
Validation loss: 2.559299237779939

Epoch: 6| Step: 12
Training loss: 1.0180637130884642
Validation loss: 2.540659272297843

Epoch: 6| Step: 13
Training loss: 1.8478685059520081
Validation loss: 2.5712165054417015

Epoch: 351| Step: 0
Training loss: 1.5135061653246036
Validation loss: 2.5840707362268973

Epoch: 6| Step: 1
Training loss: 1.9294340762629791
Validation loss: 2.6019938190620384

Epoch: 6| Step: 2
Training loss: 1.496280588779075
Validation loss: 2.599803646938492

Epoch: 6| Step: 3
Training loss: 1.618449580178234
Validation loss: 2.573587265860315

Epoch: 6| Step: 4
Training loss: 1.9713782674776743
Validation loss: 2.502364979142879

Epoch: 6| Step: 5
Training loss: 1.7507192632212314
Validation loss: 2.518082092050879

Epoch: 6| Step: 6
Training loss: 1.3054867426455883
Validation loss: 2.490171049222908

Epoch: 6| Step: 7
Training loss: 1.2094767958901704
Validation loss: 2.541326810179795

Epoch: 6| Step: 8
Training loss: 1.318043762858171
Validation loss: 2.5010436899435704

Epoch: 6| Step: 9
Training loss: 1.5059219129665657
Validation loss: 2.5142081794392492

Epoch: 6| Step: 10
Training loss: 1.6017441065099187
Validation loss: 2.5023987229591533

Epoch: 6| Step: 11
Training loss: 1.4010164147503856
Validation loss: 2.570322858022363

Epoch: 6| Step: 12
Training loss: 1.5825449168503487
Validation loss: 2.5244521235948425

Epoch: 6| Step: 13
Training loss: 1.5415160475002938
Validation loss: 2.5957209287730834

Epoch: 352| Step: 0
Training loss: 1.3465222438868827
Validation loss: 2.566530949443449

Epoch: 6| Step: 1
Training loss: 1.136902784413815
Validation loss: 2.5399939447365822

Epoch: 6| Step: 2
Training loss: 1.702697560279278
Validation loss: 2.5244709965221013

Epoch: 6| Step: 3
Training loss: 1.237339901441853
Validation loss: 2.5084517823785304

Epoch: 6| Step: 4
Training loss: 1.3737971506539892
Validation loss: 2.5104097759315818

Epoch: 6| Step: 5
Training loss: 1.4125336448915986
Validation loss: 2.4832395682031776

Epoch: 6| Step: 6
Training loss: 1.3147132015413585
Validation loss: 2.5115804283138536

Epoch: 6| Step: 7
Training loss: 1.3954983304491104
Validation loss: 2.5038397309527674

Epoch: 6| Step: 8
Training loss: 1.6760977777351072
Validation loss: 2.5089161188449776

Epoch: 6| Step: 9
Training loss: 1.3180602235826413
Validation loss: 2.549831507607614

Epoch: 6| Step: 10
Training loss: 1.6795130439472086
Validation loss: 2.555401654608077

Epoch: 6| Step: 11
Training loss: 1.5963859451225797
Validation loss: 2.541298188144974

Epoch: 6| Step: 12
Training loss: 2.0903165763670377
Validation loss: 2.5813472378498483

Epoch: 6| Step: 13
Training loss: 1.6149567039048014
Validation loss: 2.561968825887393

Epoch: 353| Step: 0
Training loss: 1.403405003125777
Validation loss: 2.526869244376701

Epoch: 6| Step: 1
Training loss: 1.3484088952134645
Validation loss: 2.505075896655865

Epoch: 6| Step: 2
Training loss: 1.4093074621693913
Validation loss: 2.475054340857746

Epoch: 6| Step: 3
Training loss: 1.1103019602624533
Validation loss: 2.51304317062544

Epoch: 6| Step: 4
Training loss: 1.0565322002408986
Validation loss: 2.503351682764183

Epoch: 6| Step: 5
Training loss: 1.3810321964098997
Validation loss: 2.507990497043824

Epoch: 6| Step: 6
Training loss: 1.6087292607177726
Validation loss: 2.535062657897984

Epoch: 6| Step: 7
Training loss: 2.0238963899215423
Validation loss: 2.4851534161775883

Epoch: 6| Step: 8
Training loss: 1.6436836432345687
Validation loss: 2.4892895630300282

Epoch: 6| Step: 9
Training loss: 1.9179878311606533
Validation loss: 2.4872861236690285

Epoch: 6| Step: 10
Training loss: 1.4236790038669658
Validation loss: 2.4735623548061234

Epoch: 6| Step: 11
Training loss: 1.5059010144919878
Validation loss: 2.4859132942573336

Epoch: 6| Step: 12
Training loss: 1.0603566710482024
Validation loss: 2.5034625473105936

Epoch: 6| Step: 13
Training loss: 1.0288259742836579
Validation loss: 2.549332819405242

Epoch: 354| Step: 0
Training loss: 1.410224722681862
Validation loss: 2.5387785532710674

Epoch: 6| Step: 1
Training loss: 1.1967405876202315
Validation loss: 2.582575815152094

Epoch: 6| Step: 2
Training loss: 0.9291156965796107
Validation loss: 2.618915985358191

Epoch: 6| Step: 3
Training loss: 1.2828832776411143
Validation loss: 2.5779902259201406

Epoch: 6| Step: 4
Training loss: 2.195574435969283
Validation loss: 2.6540290822809953

Epoch: 6| Step: 5
Training loss: 1.850411616748475
Validation loss: 2.612820161247724

Epoch: 6| Step: 6
Training loss: 1.2593699225614439
Validation loss: 2.602667679748703

Epoch: 6| Step: 7
Training loss: 1.1327198911498997
Validation loss: 2.606234497524295

Epoch: 6| Step: 8
Training loss: 1.7498658673789111
Validation loss: 2.590088116915512

Epoch: 6| Step: 9
Training loss: 1.370043838941195
Validation loss: 2.5459568108198973

Epoch: 6| Step: 10
Training loss: 1.3132601761814902
Validation loss: 2.5221297395819855

Epoch: 6| Step: 11
Training loss: 2.2900695668610664
Validation loss: 2.5134357380010073

Epoch: 6| Step: 12
Training loss: 1.9403177506481315
Validation loss: 2.5265256175610853

Epoch: 6| Step: 13
Training loss: 0.9693652014664478
Validation loss: 2.502451648225992

Epoch: 355| Step: 0
Training loss: 1.5554968486031735
Validation loss: 2.477514699641456

Epoch: 6| Step: 1
Training loss: 1.3342980481009767
Validation loss: 2.526669710613756

Epoch: 6| Step: 2
Training loss: 1.1030947802675617
Validation loss: 2.5672537818504653

Epoch: 6| Step: 3
Training loss: 2.336067323681294
Validation loss: 2.5692614538883904

Epoch: 6| Step: 4
Training loss: 1.322449574149161
Validation loss: 2.6041513722288503

Epoch: 6| Step: 5
Training loss: 1.0955330619819879
Validation loss: 2.660093541090057

Epoch: 6| Step: 6
Training loss: 1.7031690259370191
Validation loss: 2.6690439763625022

Epoch: 6| Step: 7
Training loss: 1.8657041906677476
Validation loss: 2.7001180517032113

Epoch: 6| Step: 8
Training loss: 1.1785669120272673
Validation loss: 2.670191645393886

Epoch: 6| Step: 9
Training loss: 1.109317724334349
Validation loss: 2.6615129727741316

Epoch: 6| Step: 10
Training loss: 1.1089721808010007
Validation loss: 2.673260639939241

Epoch: 6| Step: 11
Training loss: 1.8084735212467948
Validation loss: 2.623452123798495

Epoch: 6| Step: 12
Training loss: 1.6089075391056098
Validation loss: 2.6342339305582443

Epoch: 6| Step: 13
Training loss: 1.9635818706683414
Validation loss: 2.6009919511787105

Epoch: 356| Step: 0
Training loss: 1.2899650419658737
Validation loss: 2.529927218135415

Epoch: 6| Step: 1
Training loss: 1.8766436683957568
Validation loss: 2.548540534192262

Epoch: 6| Step: 2
Training loss: 2.2156977546056242
Validation loss: 2.5213609463803404

Epoch: 6| Step: 3
Training loss: 1.6717309622350167
Validation loss: 2.4910590348437553

Epoch: 6| Step: 4
Training loss: 1.5213679414791794
Validation loss: 2.502175131920829

Epoch: 6| Step: 5
Training loss: 1.6176404088439522
Validation loss: 2.549722277408831

Epoch: 6| Step: 6
Training loss: 1.988644310080765
Validation loss: 2.575959245777478

Epoch: 6| Step: 7
Training loss: 1.3569002974448088
Validation loss: 2.5359034678772225

Epoch: 6| Step: 8
Training loss: 1.3627745990342008
Validation loss: 2.4957759935503625

Epoch: 6| Step: 9
Training loss: 1.1822783459600577
Validation loss: 2.5019280787020075

Epoch: 6| Step: 10
Training loss: 1.3613026861498463
Validation loss: 2.5167651386658902

Epoch: 6| Step: 11
Training loss: 1.031190176875883
Validation loss: 2.5571046334814826

Epoch: 6| Step: 12
Training loss: 1.6205897271569012
Validation loss: 2.561737722512927

Epoch: 6| Step: 13
Training loss: 1.4083201958910705
Validation loss: 2.6100097310650923

Epoch: 357| Step: 0
Training loss: 1.5294730327382484
Validation loss: 2.6105875179055786

Epoch: 6| Step: 1
Training loss: 1.06321994848632
Validation loss: 2.6202888750054982

Epoch: 6| Step: 2
Training loss: 1.5356181374420979
Validation loss: 2.5943749299245034

Epoch: 6| Step: 3
Training loss: 1.5246181510264165
Validation loss: 2.600248721037063

Epoch: 6| Step: 4
Training loss: 1.8166498492567817
Validation loss: 2.6105290371718604

Epoch: 6| Step: 5
Training loss: 1.1409027597513524
Validation loss: 2.5767690618566266

Epoch: 6| Step: 6
Training loss: 1.4430121183461515
Validation loss: 2.568485681403925

Epoch: 6| Step: 7
Training loss: 1.016649580379387
Validation loss: 2.5373678489311295

Epoch: 6| Step: 8
Training loss: 2.291114694415963
Validation loss: 2.5212794347913112

Epoch: 6| Step: 9
Training loss: 1.267616024538146
Validation loss: 2.5380385931280713

Epoch: 6| Step: 10
Training loss: 1.4676793843057028
Validation loss: 2.5060454388959346

Epoch: 6| Step: 11
Training loss: 1.4255270535388285
Validation loss: 2.4944962317970387

Epoch: 6| Step: 12
Training loss: 1.6056761967272768
Validation loss: 2.477306362556889

Epoch: 6| Step: 13
Training loss: 1.8471935894626488
Validation loss: 2.4756080079709393

Epoch: 358| Step: 0
Training loss: 2.1062728110869497
Validation loss: 2.4718901063479173

Epoch: 6| Step: 1
Training loss: 1.2330013309418981
Validation loss: 2.459094727059744

Epoch: 6| Step: 2
Training loss: 1.3058920684747688
Validation loss: 2.540512719357573

Epoch: 6| Step: 3
Training loss: 1.8481116348624453
Validation loss: 2.5292346215165966

Epoch: 6| Step: 4
Training loss: 1.3174908525124027
Validation loss: 2.580009388302816

Epoch: 6| Step: 5
Training loss: 1.101237959433298
Validation loss: 2.577210882716135

Epoch: 6| Step: 6
Training loss: 1.2001137143138731
Validation loss: 2.6134890714613577

Epoch: 6| Step: 7
Training loss: 1.8829039238857814
Validation loss: 2.6442476061304956

Epoch: 6| Step: 8
Training loss: 1.5736752463986747
Validation loss: 2.6201364784511605

Epoch: 6| Step: 9
Training loss: 1.9647128173400716
Validation loss: 2.629662898449691

Epoch: 6| Step: 10
Training loss: 1.6604684334235313
Validation loss: 2.624694761058866

Epoch: 6| Step: 11
Training loss: 1.3298911076619093
Validation loss: 2.594691967257964

Epoch: 6| Step: 12
Training loss: 1.0754249043514346
Validation loss: 2.545212809790406

Epoch: 6| Step: 13
Training loss: 1.6866840226457755
Validation loss: 2.5644322762727696

Epoch: 359| Step: 0
Training loss: 1.4371066177146778
Validation loss: 2.5259815300668675

Epoch: 6| Step: 1
Training loss: 1.613053497420582
Validation loss: 2.501089097261346

Epoch: 6| Step: 2
Training loss: 1.5554505589033125
Validation loss: 2.523421729385966

Epoch: 6| Step: 3
Training loss: 1.272984429952691
Validation loss: 2.507766057710421

Epoch: 6| Step: 4
Training loss: 1.5422336034251003
Validation loss: 2.516511109472924

Epoch: 6| Step: 5
Training loss: 1.672932228152185
Validation loss: 2.5002951924569263

Epoch: 6| Step: 6
Training loss: 0.813580638002542
Validation loss: 2.515017552614738

Epoch: 6| Step: 7
Training loss: 1.5123538868845494
Validation loss: 2.5056746611253424

Epoch: 6| Step: 8
Training loss: 1.9153327308217443
Validation loss: 2.562995893675786

Epoch: 6| Step: 9
Training loss: 1.8449032942696235
Validation loss: 2.5544684391029553

Epoch: 6| Step: 10
Training loss: 1.3803102083815453
Validation loss: 2.5948583846752347

Epoch: 6| Step: 11
Training loss: 0.9614094761385603
Validation loss: 2.6258160821204126

Epoch: 6| Step: 12
Training loss: 1.4426962602938784
Validation loss: 2.605024720292489

Epoch: 6| Step: 13
Training loss: 1.5945218778911396
Validation loss: 2.636716655212324

Epoch: 360| Step: 0
Training loss: 1.602354049463524
Validation loss: 2.6367112298552096

Epoch: 6| Step: 1
Training loss: 1.3551509605576304
Validation loss: 2.569890676590162

Epoch: 6| Step: 2
Training loss: 1.3968486604191401
Validation loss: 2.5494301115517817

Epoch: 6| Step: 3
Training loss: 0.8886569179072685
Validation loss: 2.551112302957741

Epoch: 6| Step: 4
Training loss: 1.7796630482588929
Validation loss: 2.498010018210764

Epoch: 6| Step: 5
Training loss: 1.47625664666704
Validation loss: 2.5276860079566337

Epoch: 6| Step: 6
Training loss: 1.5167367534722351
Validation loss: 2.5432146132255435

Epoch: 6| Step: 7
Training loss: 1.6260009030648102
Validation loss: 2.5450331848269325

Epoch: 6| Step: 8
Training loss: 1.4231449366711406
Validation loss: 2.483959831080142

Epoch: 6| Step: 9
Training loss: 1.9285983204858927
Validation loss: 2.5355207027466977

Epoch: 6| Step: 10
Training loss: 1.1029410968107307
Validation loss: 2.5061770342117096

Epoch: 6| Step: 11
Training loss: 1.5992486381626339
Validation loss: 2.506144649355712

Epoch: 6| Step: 12
Training loss: 1.2293183777282823
Validation loss: 2.497676484876466

Epoch: 6| Step: 13
Training loss: 1.2407043527741557
Validation loss: 2.5154978086173503

Epoch: 361| Step: 0
Training loss: 1.3649871558678506
Validation loss: 2.5371059136762297

Epoch: 6| Step: 1
Training loss: 1.4060529782771942
Validation loss: 2.550339150782076

Epoch: 6| Step: 2
Training loss: 1.1983745971246091
Validation loss: 2.554297181155835

Epoch: 6| Step: 3
Training loss: 1.402212917844799
Validation loss: 2.5750429785638547

Epoch: 6| Step: 4
Training loss: 1.9742207281467323
Validation loss: 2.5928339891852397

Epoch: 6| Step: 5
Training loss: 1.318953407112498
Validation loss: 2.5455437517893826

Epoch: 6| Step: 6
Training loss: 1.1858413054161863
Validation loss: 2.565207377001697

Epoch: 6| Step: 7
Training loss: 1.4881234473324894
Validation loss: 2.5517889566682794

Epoch: 6| Step: 8
Training loss: 1.3950591811065483
Validation loss: 2.5683513297957012

Epoch: 6| Step: 9
Training loss: 1.5479849484128376
Validation loss: 2.544999850160086

Epoch: 6| Step: 10
Training loss: 1.6574183967260743
Validation loss: 2.5519307045482327

Epoch: 6| Step: 11
Training loss: 1.4369139098498798
Validation loss: 2.5306157545914942

Epoch: 6| Step: 12
Training loss: 1.1230429475135129
Validation loss: 2.5469671439448116

Epoch: 6| Step: 13
Training loss: 1.2111632105988563
Validation loss: 2.554137673350858

Epoch: 362| Step: 0
Training loss: 1.1325305456290513
Validation loss: 2.5409624004727323

Epoch: 6| Step: 1
Training loss: 0.8119953495653527
Validation loss: 2.5254451768435744

Epoch: 6| Step: 2
Training loss: 1.36223135583321
Validation loss: 2.5144951377978915

Epoch: 6| Step: 3
Training loss: 1.8222450835776187
Validation loss: 2.526824127346895

Epoch: 6| Step: 4
Training loss: 1.3969573813772993
Validation loss: 2.5430952549499004

Epoch: 6| Step: 5
Training loss: 1.425170767741228
Validation loss: 2.5035065854189567

Epoch: 6| Step: 6
Training loss: 1.4588320651338507
Validation loss: 2.530650511343205

Epoch: 6| Step: 7
Training loss: 1.6972237637782168
Validation loss: 2.4890661833073944

Epoch: 6| Step: 8
Training loss: 1.337470084595581
Validation loss: 2.5469170081295824

Epoch: 6| Step: 9
Training loss: 1.1489571154885685
Validation loss: 2.523880989462969

Epoch: 6| Step: 10
Training loss: 1.2729074510073213
Validation loss: 2.530052372688147

Epoch: 6| Step: 11
Training loss: 1.2834151047916162
Validation loss: 2.542630862178802

Epoch: 6| Step: 12
Training loss: 1.8191222527616318
Validation loss: 2.557470479852639

Epoch: 6| Step: 13
Training loss: 1.3152743490662957
Validation loss: 2.5317371119487615

Epoch: 363| Step: 0
Training loss: 1.807860916003709
Validation loss: 2.569523683534707

Epoch: 6| Step: 1
Training loss: 1.0943978162268273
Validation loss: 2.545951090605855

Epoch: 6| Step: 2
Training loss: 1.5707440139241156
Validation loss: 2.5634721292124363

Epoch: 6| Step: 3
Training loss: 1.576963015778796
Validation loss: 2.5579278210350505

Epoch: 6| Step: 4
Training loss: 1.329093355690244
Validation loss: 2.5490441319708506

Epoch: 6| Step: 5
Training loss: 1.309144681280128
Validation loss: 2.5262927268150928

Epoch: 6| Step: 6
Training loss: 1.161095236000996
Validation loss: 2.51518086052962

Epoch: 6| Step: 7
Training loss: 1.0858952905149675
Validation loss: 2.516869405028676

Epoch: 6| Step: 8
Training loss: 1.770324731230674
Validation loss: 2.5379407546881882

Epoch: 6| Step: 9
Training loss: 1.4428016090766937
Validation loss: 2.5503796762286046

Epoch: 6| Step: 10
Training loss: 1.3184391704005338
Validation loss: 2.5159486518991447

Epoch: 6| Step: 11
Training loss: 0.8896712835165178
Validation loss: 2.506946513232936

Epoch: 6| Step: 12
Training loss: 1.1981969201476417
Validation loss: 2.5153301374224877

Epoch: 6| Step: 13
Training loss: 1.593505990291524
Validation loss: 2.502465851951228

Epoch: 364| Step: 0
Training loss: 1.4722762287878453
Validation loss: 2.5406700170954157

Epoch: 6| Step: 1
Training loss: 1.7018141995600515
Validation loss: 2.5119024420172003

Epoch: 6| Step: 2
Training loss: 1.068642531674718
Validation loss: 2.5242092656994686

Epoch: 6| Step: 3
Training loss: 0.9252019751906596
Validation loss: 2.513890491810587

Epoch: 6| Step: 4
Training loss: 1.3179574763568296
Validation loss: 2.5087808183450693

Epoch: 6| Step: 5
Training loss: 1.4779482197447182
Validation loss: 2.521278292160401

Epoch: 6| Step: 6
Training loss: 1.3310540605796854
Validation loss: 2.5397043835082784

Epoch: 6| Step: 7
Training loss: 0.9564693124637165
Validation loss: 2.5452671865820906

Epoch: 6| Step: 8
Training loss: 1.7072709044085648
Validation loss: 2.5302207957987286

Epoch: 6| Step: 9
Training loss: 1.1501104405487717
Validation loss: 2.5363634367207615

Epoch: 6| Step: 10
Training loss: 1.1418749609969643
Validation loss: 2.5483788105225185

Epoch: 6| Step: 11
Training loss: 1.9912057888680985
Validation loss: 2.522039650257729

Epoch: 6| Step: 12
Training loss: 0.9880479982161138
Validation loss: 2.5139912261880597

Epoch: 6| Step: 13
Training loss: 1.665762306265249
Validation loss: 2.504585955443972

Epoch: 365| Step: 0
Training loss: 1.051356728813738
Validation loss: 2.4753231794469417

Epoch: 6| Step: 1
Training loss: 0.9887499093828509
Validation loss: 2.4926408536720035

Epoch: 6| Step: 2
Training loss: 1.0039599808737927
Validation loss: 2.4747961104825946

Epoch: 6| Step: 3
Training loss: 1.6070915244245416
Validation loss: 2.5416882128401563

Epoch: 6| Step: 4
Training loss: 1.3681596188197376
Validation loss: 2.4920679300896587

Epoch: 6| Step: 5
Training loss: 1.39774471576574
Validation loss: 2.5292214322222724

Epoch: 6| Step: 6
Training loss: 1.2302502150462722
Validation loss: 2.5159939007748338

Epoch: 6| Step: 7
Training loss: 1.084888308177433
Validation loss: 2.515987251689132

Epoch: 6| Step: 8
Training loss: 1.7723447146812867
Validation loss: 2.519474141264718

Epoch: 6| Step: 9
Training loss: 1.3391190506913262
Validation loss: 2.5238958676666896

Epoch: 6| Step: 10
Training loss: 1.91968312142053
Validation loss: 2.51496046778436

Epoch: 6| Step: 11
Training loss: 1.0957333701680148
Validation loss: 2.488994294609212

Epoch: 6| Step: 12
Training loss: 1.3501014530066415
Validation loss: 2.5669534333120105

Epoch: 6| Step: 13
Training loss: 1.383518448282375
Validation loss: 2.5343434775164217

Epoch: 366| Step: 0
Training loss: 1.743185535800863
Validation loss: 2.559768019027518

Epoch: 6| Step: 1
Training loss: 0.8880495344578405
Validation loss: 2.51144194078785

Epoch: 6| Step: 2
Training loss: 1.366412657106012
Validation loss: 2.518476635129118

Epoch: 6| Step: 3
Training loss: 1.3710256706355377
Validation loss: 2.5355471175985143

Epoch: 6| Step: 4
Training loss: 0.6112750825630798
Validation loss: 2.582633174848776

Epoch: 6| Step: 5
Training loss: 1.9878097004983921
Validation loss: 2.5553510000650053

Epoch: 6| Step: 6
Training loss: 1.2810852596161197
Validation loss: 2.5139206825152027

Epoch: 6| Step: 7
Training loss: 1.1038406298572532
Validation loss: 2.522496066536182

Epoch: 6| Step: 8
Training loss: 1.6310612536446536
Validation loss: 2.499781821585186

Epoch: 6| Step: 9
Training loss: 1.1334171654512897
Validation loss: 2.514527833879744

Epoch: 6| Step: 10
Training loss: 0.8758444457856963
Validation loss: 2.495201130330257

Epoch: 6| Step: 11
Training loss: 1.3532577643334698
Validation loss: 2.5210377213610324

Epoch: 6| Step: 12
Training loss: 1.2955702227336026
Validation loss: 2.55119012006346

Epoch: 6| Step: 13
Training loss: 1.5364459107322441
Validation loss: 2.5372578864011834

Epoch: 367| Step: 0
Training loss: 0.8726704445199327
Validation loss: 2.5323179056640743

Epoch: 6| Step: 1
Training loss: 1.0763021345282369
Validation loss: 2.5766906447320954

Epoch: 6| Step: 2
Training loss: 1.6018407068291565
Validation loss: 2.5921320790687186

Epoch: 6| Step: 3
Training loss: 1.3694023284901227
Validation loss: 2.561237489400742

Epoch: 6| Step: 4
Training loss: 1.2877656829181163
Validation loss: 2.5782790937515445

Epoch: 6| Step: 5
Training loss: 0.9953987838737688
Validation loss: 2.5774817695059293

Epoch: 6| Step: 6
Training loss: 1.7838535355244283
Validation loss: 2.576573901346897

Epoch: 6| Step: 7
Training loss: 1.493903725985727
Validation loss: 2.54673827570786

Epoch: 6| Step: 8
Training loss: 1.259130083979516
Validation loss: 2.4938276229416045

Epoch: 6| Step: 9
Training loss: 1.5710810967632485
Validation loss: 2.4990593173596802

Epoch: 6| Step: 10
Training loss: 0.988413112121225
Validation loss: 2.488768948480145

Epoch: 6| Step: 11
Training loss: 1.6812434596959072
Validation loss: 2.5312683042013564

Epoch: 6| Step: 12
Training loss: 1.6074910664643887
Validation loss: 2.502887893667171

Epoch: 6| Step: 13
Training loss: 0.868386033198523
Validation loss: 2.536318378908581

Epoch: 368| Step: 0
Training loss: 1.333969719332927
Validation loss: 2.509848317962234

Epoch: 6| Step: 1
Training loss: 1.3393513300126312
Validation loss: 2.575659920100032

Epoch: 6| Step: 2
Training loss: 1.2528849212427215
Validation loss: 2.5230774519255084

Epoch: 6| Step: 3
Training loss: 1.404390928808788
Validation loss: 2.5639298101911074

Epoch: 6| Step: 4
Training loss: 1.552303307154747
Validation loss: 2.537789903250556

Epoch: 6| Step: 5
Training loss: 0.9759042581399074
Validation loss: 2.591025257979315

Epoch: 6| Step: 6
Training loss: 1.7464617654987467
Validation loss: 2.527943747757729

Epoch: 6| Step: 7
Training loss: 1.663264481731873
Validation loss: 2.5146728040384994

Epoch: 6| Step: 8
Training loss: 1.3380884622915579
Validation loss: 2.5082528271434374

Epoch: 6| Step: 9
Training loss: 1.5052988713720377
Validation loss: 2.4965094517185675

Epoch: 6| Step: 10
Training loss: 1.4563531601675903
Validation loss: 2.48288118888789

Epoch: 6| Step: 11
Training loss: 1.056393860720468
Validation loss: 2.5834565338372464

Epoch: 6| Step: 12
Training loss: 1.1173576812238402
Validation loss: 2.532581999274358

Epoch: 6| Step: 13
Training loss: 0.752105182284545
Validation loss: 2.5685131263885133

Epoch: 369| Step: 0
Training loss: 1.1737128532795982
Validation loss: 2.602084331853312

Epoch: 6| Step: 1
Training loss: 1.4911401878016446
Validation loss: 2.6310231271827056

Epoch: 6| Step: 2
Training loss: 1.3997073242255327
Validation loss: 2.599495525814353

Epoch: 6| Step: 3
Training loss: 1.8813491136162601
Validation loss: 2.645581606406849

Epoch: 6| Step: 4
Training loss: 1.103138330827516
Validation loss: 2.590119774379736

Epoch: 6| Step: 5
Training loss: 1.55019184894134
Validation loss: 2.644018825093196

Epoch: 6| Step: 6
Training loss: 1.12003576885736
Validation loss: 2.58741750938884

Epoch: 6| Step: 7
Training loss: 1.3133483143418374
Validation loss: 2.63630577338307

Epoch: 6| Step: 8
Training loss: 1.0730334036321347
Validation loss: 2.641920723616815

Epoch: 6| Step: 9
Training loss: 1.5548758081231193
Validation loss: 2.623176183327698

Epoch: 6| Step: 10
Training loss: 1.7169487965169026
Validation loss: 2.6207294694204966

Epoch: 6| Step: 11
Training loss: 1.3756053632333822
Validation loss: 2.580893076680521

Epoch: 6| Step: 12
Training loss: 1.5605381665804423
Validation loss: 2.5353673877383307

Epoch: 6| Step: 13
Training loss: 1.1714117533277317
Validation loss: 2.4992833222878357

Epoch: 370| Step: 0
Training loss: 1.5318751713267449
Validation loss: 2.502684105990007

Epoch: 6| Step: 1
Training loss: 1.5483088157910865
Validation loss: 2.4934065497030056

Epoch: 6| Step: 2
Training loss: 1.647791008030521
Validation loss: 2.493623166535745

Epoch: 6| Step: 3
Training loss: 0.8458134180615205
Validation loss: 2.521733829875429

Epoch: 6| Step: 4
Training loss: 1.0661571057942327
Validation loss: 2.5049890804243127

Epoch: 6| Step: 5
Training loss: 1.2164980305547173
Validation loss: 2.5148235647705492

Epoch: 6| Step: 6
Training loss: 1.7317456083444427
Validation loss: 2.4999541914239836

Epoch: 6| Step: 7
Training loss: 1.2199003708135343
Validation loss: 2.5170815399555884

Epoch: 6| Step: 8
Training loss: 1.4318830797424538
Validation loss: 2.547287616967269

Epoch: 6| Step: 9
Training loss: 0.8297204896507001
Validation loss: 2.4918519275478332

Epoch: 6| Step: 10
Training loss: 1.7288682136195594
Validation loss: 2.5721631870905792

Epoch: 6| Step: 11
Training loss: 1.5921283774587551
Validation loss: 2.55499014583163

Epoch: 6| Step: 12
Training loss: 1.620543016389491
Validation loss: 2.5341953284455303

Epoch: 6| Step: 13
Training loss: 1.2866557455011152
Validation loss: 2.5256898195815647

Epoch: 371| Step: 0
Training loss: 0.829634029296185
Validation loss: 2.5411320160489286

Epoch: 6| Step: 1
Training loss: 1.266068557437775
Validation loss: 2.507456388769344

Epoch: 6| Step: 2
Training loss: 1.3518048548742607
Validation loss: 2.505152859671731

Epoch: 6| Step: 3
Training loss: 0.9733796397934198
Validation loss: 2.504430008898072

Epoch: 6| Step: 4
Training loss: 2.113792033349995
Validation loss: 2.554630243902176

Epoch: 6| Step: 5
Training loss: 1.2207166014881101
Validation loss: 2.530332673808892

Epoch: 6| Step: 6
Training loss: 1.1528460943260201
Validation loss: 2.5408439372979834

Epoch: 6| Step: 7
Training loss: 1.49471273003367
Validation loss: 2.5752561694869565

Epoch: 6| Step: 8
Training loss: 1.2011165947327744
Validation loss: 2.5611608464102553

Epoch: 6| Step: 9
Training loss: 0.8339187631995895
Validation loss: 2.559971903656718

Epoch: 6| Step: 10
Training loss: 1.8661186958005662
Validation loss: 2.572123761852452

Epoch: 6| Step: 11
Training loss: 1.3026240586637166
Validation loss: 2.533581119474111

Epoch: 6| Step: 12
Training loss: 1.2163950346893357
Validation loss: 2.5687163246342055

Epoch: 6| Step: 13
Training loss: 1.5640565367136257
Validation loss: 2.5101246222046845

Epoch: 372| Step: 0
Training loss: 2.1980691890014405
Validation loss: 2.521075045344148

Epoch: 6| Step: 1
Training loss: 1.3269510803117066
Validation loss: 2.541113798535465

Epoch: 6| Step: 2
Training loss: 1.1385380713757112
Validation loss: 2.558969018803027

Epoch: 6| Step: 3
Training loss: 0.6955855829839209
Validation loss: 2.559698449742726

Epoch: 6| Step: 4
Training loss: 1.6176063621726036
Validation loss: 2.5226325610401164

Epoch: 6| Step: 5
Training loss: 1.4417686937131298
Validation loss: 2.5419073668358374

Epoch: 6| Step: 6
Training loss: 1.3220632558829577
Validation loss: 2.509514244146585

Epoch: 6| Step: 7
Training loss: 1.6562605083779993
Validation loss: 2.484968710279573

Epoch: 6| Step: 8
Training loss: 0.7747653390572872
Validation loss: 2.4767813600892237

Epoch: 6| Step: 9
Training loss: 1.3454219264099636
Validation loss: 2.505744945344556

Epoch: 6| Step: 10
Training loss: 1.1693532131659017
Validation loss: 2.567240153272099

Epoch: 6| Step: 11
Training loss: 1.2772964328786243
Validation loss: 2.553937609442965

Epoch: 6| Step: 12
Training loss: 1.2100360591496617
Validation loss: 2.5440366566294306

Epoch: 6| Step: 13
Training loss: 1.4788493859371281
Validation loss: 2.5911828017672702

Epoch: 373| Step: 0
Training loss: 0.8671141584845097
Validation loss: 2.5577668695684905

Epoch: 6| Step: 1
Training loss: 1.4761519895830841
Validation loss: 2.5848076879068826

Epoch: 6| Step: 2
Training loss: 1.0834062013817267
Validation loss: 2.587159758233732

Epoch: 6| Step: 3
Training loss: 1.0645473053590855
Validation loss: 2.64191713639905

Epoch: 6| Step: 4
Training loss: 1.2199461031562082
Validation loss: 2.6287188300199844

Epoch: 6| Step: 5
Training loss: 1.0975881535052052
Validation loss: 2.583722644101897

Epoch: 6| Step: 6
Training loss: 1.0846759961044905
Validation loss: 2.5765157744313845

Epoch: 6| Step: 7
Training loss: 1.6765758702295177
Validation loss: 2.58362276752896

Epoch: 6| Step: 8
Training loss: 1.6871006811067673
Validation loss: 2.55521632329472

Epoch: 6| Step: 9
Training loss: 1.3629575416097957
Validation loss: 2.5067584317189398

Epoch: 6| Step: 10
Training loss: 1.0656905794520342
Validation loss: 2.4937181704982803

Epoch: 6| Step: 11
Training loss: 1.782672381097788
Validation loss: 2.4876132948872094

Epoch: 6| Step: 12
Training loss: 1.3132633532519313
Validation loss: 2.5233271115057097

Epoch: 6| Step: 13
Training loss: 1.1529120644074402
Validation loss: 2.5356077586631462

Epoch: 374| Step: 0
Training loss: 0.8895303457293394
Validation loss: 2.5424300490927623

Epoch: 6| Step: 1
Training loss: 1.7730362223901668
Validation loss: 2.5412502156095074

Epoch: 6| Step: 2
Training loss: 1.4899235672516329
Validation loss: 2.5619500120494174

Epoch: 6| Step: 3
Training loss: 1.4010022050294262
Validation loss: 2.5612627314382546

Epoch: 6| Step: 4
Training loss: 1.0315261239956426
Validation loss: 2.530331024884805

Epoch: 6| Step: 5
Training loss: 1.7157283230712452
Validation loss: 2.5276682673360384

Epoch: 6| Step: 6
Training loss: 1.1258443207184636
Validation loss: 2.559244553591765

Epoch: 6| Step: 7
Training loss: 1.52041670784184
Validation loss: 2.5717749720264877

Epoch: 6| Step: 8
Training loss: 0.9498473546718568
Validation loss: 2.529571337641339

Epoch: 6| Step: 9
Training loss: 0.9414883652959339
Validation loss: 2.587595958128252

Epoch: 6| Step: 10
Training loss: 1.1392360748618622
Validation loss: 2.565169998072929

Epoch: 6| Step: 11
Training loss: 1.260861415529293
Validation loss: 2.563305627361454

Epoch: 6| Step: 12
Training loss: 1.19809105750904
Validation loss: 2.5677014415924457

Epoch: 6| Step: 13
Training loss: 1.2349063840126042
Validation loss: 2.565294068305472

Epoch: 375| Step: 0
Training loss: 1.2794056620461967
Validation loss: 2.563234627100194

Epoch: 6| Step: 1
Training loss: 1.1497410752260488
Validation loss: 2.556309767244339

Epoch: 6| Step: 2
Training loss: 1.3352274653067533
Validation loss: 2.548931952806238

Epoch: 6| Step: 3
Training loss: 1.1831186681901438
Validation loss: 2.556751036099468

Epoch: 6| Step: 4
Training loss: 1.4436550224737121
Validation loss: 2.537905588918619

Epoch: 6| Step: 5
Training loss: 1.286108713351478
Validation loss: 2.5456592802079014

Epoch: 6| Step: 6
Training loss: 1.1770524665138729
Validation loss: 2.568099656891737

Epoch: 6| Step: 7
Training loss: 1.419601803140578
Validation loss: 2.537463329156696

Epoch: 6| Step: 8
Training loss: 1.255893072029212
Validation loss: 2.5379045320591422

Epoch: 6| Step: 9
Training loss: 0.97984902299117
Validation loss: 2.547990160859702

Epoch: 6| Step: 10
Training loss: 1.164660460227569
Validation loss: 2.558813630185507

Epoch: 6| Step: 11
Training loss: 1.3215326393417997
Validation loss: 2.5565642172302465

Epoch: 6| Step: 12
Training loss: 1.722583518363457
Validation loss: 2.5626084684659896

Epoch: 6| Step: 13
Training loss: 1.4482464677743558
Validation loss: 2.535380897698046

Epoch: 376| Step: 0
Training loss: 1.151810241302887
Validation loss: 2.601089923387059

Epoch: 6| Step: 1
Training loss: 1.2326157503538258
Validation loss: 2.5269894319611965

Epoch: 6| Step: 2
Training loss: 1.1145217141679784
Validation loss: 2.5568252780443355

Epoch: 6| Step: 3
Training loss: 1.1995419243867682
Validation loss: 2.5239964861051885

Epoch: 6| Step: 4
Training loss: 1.0052365050378895
Validation loss: 2.5438428744670545

Epoch: 6| Step: 5
Training loss: 1.1767094898986554
Validation loss: 2.5354706618724827

Epoch: 6| Step: 6
Training loss: 1.2914259081184905
Validation loss: 2.5610965203811777

Epoch: 6| Step: 7
Training loss: 1.3354158777402232
Validation loss: 2.5431604816058146

Epoch: 6| Step: 8
Training loss: 1.1778983386331714
Validation loss: 2.5294144179673377

Epoch: 6| Step: 9
Training loss: 0.9058060709744175
Validation loss: 2.5566444406658206

Epoch: 6| Step: 10
Training loss: 1.2731600500122058
Validation loss: 2.562849439660124

Epoch: 6| Step: 11
Training loss: 0.8990571248805734
Validation loss: 2.545541285377657

Epoch: 6| Step: 12
Training loss: 1.7489216070387885
Validation loss: 2.5384743972858703

Epoch: 6| Step: 13
Training loss: 2.10200535529096
Validation loss: 2.5266227420882417

Epoch: 377| Step: 0
Training loss: 0.8249872611247197
Validation loss: 2.5139863895127745

Epoch: 6| Step: 1
Training loss: 1.0015391187869656
Validation loss: 2.568572424499906

Epoch: 6| Step: 2
Training loss: 1.2457270067616606
Validation loss: 2.6160365672263195

Epoch: 6| Step: 3
Training loss: 1.8105165876141205
Validation loss: 2.581335761836909

Epoch: 6| Step: 4
Training loss: 1.2512402104043374
Validation loss: 2.5338163356694734

Epoch: 6| Step: 5
Training loss: 1.1838721020413054
Validation loss: 2.588562953152752

Epoch: 6| Step: 6
Training loss: 1.0023360385137279
Validation loss: 2.571774902497101

Epoch: 6| Step: 7
Training loss: 1.0083261999293023
Validation loss: 2.5592306261714595

Epoch: 6| Step: 8
Training loss: 1.1956672889899989
Validation loss: 2.5516993538697834

Epoch: 6| Step: 9
Training loss: 2.3831638765002836
Validation loss: 2.589607561713684

Epoch: 6| Step: 10
Training loss: 1.4322932110402422
Validation loss: 2.5996827751208746

Epoch: 6| Step: 11
Training loss: 1.3388293905786994
Validation loss: 2.5654800423650217

Epoch: 6| Step: 12
Training loss: 1.2103560497624883
Validation loss: 2.5767176938977654

Epoch: 6| Step: 13
Training loss: 1.420771411579351
Validation loss: 2.580848519150528

Epoch: 378| Step: 0
Training loss: 0.9142051976643055
Validation loss: 2.5452239100567207

Epoch: 6| Step: 1
Training loss: 1.4132568846500637
Validation loss: 2.5676135393226187

Epoch: 6| Step: 2
Training loss: 1.352398123438655
Validation loss: 2.5329695775067145

Epoch: 6| Step: 3
Training loss: 1.0904092722899446
Validation loss: 2.517680124407056

Epoch: 6| Step: 4
Training loss: 1.0091722763140816
Validation loss: 2.5487919323764388

Epoch: 6| Step: 5
Training loss: 1.221172077890823
Validation loss: 2.559445553382762

Epoch: 6| Step: 6
Training loss: 2.0600364305922922
Validation loss: 2.5285968376360355

Epoch: 6| Step: 7
Training loss: 1.5719797573484933
Validation loss: 2.53859051352303

Epoch: 6| Step: 8
Training loss: 1.1062287323195092
Validation loss: 2.5238907665781514

Epoch: 6| Step: 9
Training loss: 0.7910054147320399
Validation loss: 2.576342727668025

Epoch: 6| Step: 10
Training loss: 1.2071386986964774
Validation loss: 2.557395363211849

Epoch: 6| Step: 11
Training loss: 1.2635785736119793
Validation loss: 2.547869996968813

Epoch: 6| Step: 12
Training loss: 1.1639178909495973
Validation loss: 2.5499079612876634

Epoch: 6| Step: 13
Training loss: 1.207653194052963
Validation loss: 2.592481295212526

Epoch: 379| Step: 0
Training loss: 0.962614751143287
Validation loss: 2.610631164502102

Epoch: 6| Step: 1
Training loss: 1.003028575029974
Validation loss: 2.562982288968177

Epoch: 6| Step: 2
Training loss: 1.0656409119791204
Validation loss: 2.558621751471894

Epoch: 6| Step: 3
Training loss: 1.0269187367203856
Validation loss: 2.5376925171481193

Epoch: 6| Step: 4
Training loss: 1.2931679747913651
Validation loss: 2.566893006434915

Epoch: 6| Step: 5
Training loss: 1.9047827780522195
Validation loss: 2.567959799585082

Epoch: 6| Step: 6
Training loss: 1.2824404698585736
Validation loss: 2.5425755694426266

Epoch: 6| Step: 7
Training loss: 1.7944218351017798
Validation loss: 2.5369972006471975

Epoch: 6| Step: 8
Training loss: 1.2927512824428957
Validation loss: 2.529863126743894

Epoch: 6| Step: 9
Training loss: 0.8622976024159488
Validation loss: 2.5373405055641136

Epoch: 6| Step: 10
Training loss: 1.0135609707589983
Validation loss: 2.556064806061389

Epoch: 6| Step: 11
Training loss: 1.3986387480945568
Validation loss: 2.560610361328193

Epoch: 6| Step: 12
Training loss: 1.24164843108507
Validation loss: 2.5503545913491723

Epoch: 6| Step: 13
Training loss: 1.055433955773209
Validation loss: 2.578688850781122

Epoch: 380| Step: 0
Training loss: 0.9860988841544998
Validation loss: 2.5986659026258168

Epoch: 6| Step: 1
Training loss: 1.4132185467105227
Validation loss: 2.591275164317455

Epoch: 6| Step: 2
Training loss: 1.2741343457996257
Validation loss: 2.5951247497786807

Epoch: 6| Step: 3
Training loss: 0.8893049060492747
Validation loss: 2.6065106536766542

Epoch: 6| Step: 4
Training loss: 0.8074890551696351
Validation loss: 2.5842895327623214

Epoch: 6| Step: 5
Training loss: 1.2692659541012674
Validation loss: 2.615606515591966

Epoch: 6| Step: 6
Training loss: 1.6675972089213849
Validation loss: 2.634868011860584

Epoch: 6| Step: 7
Training loss: 1.610682132582484
Validation loss: 2.6190651681960246

Epoch: 6| Step: 8
Training loss: 1.8456247141495847
Validation loss: 2.5954048209216807

Epoch: 6| Step: 9
Training loss: 1.381666408963672
Validation loss: 2.598638898423523

Epoch: 6| Step: 10
Training loss: 1.4405731853840367
Validation loss: 2.6100628797037997

Epoch: 6| Step: 11
Training loss: 1.3998303004003103
Validation loss: 2.6783885569438906

Epoch: 6| Step: 12
Training loss: 1.5437683351485811
Validation loss: 2.577298611834138

Epoch: 6| Step: 13
Training loss: 1.198178414759497
Validation loss: 2.550851693380689

Epoch: 381| Step: 0
Training loss: 0.8721717356860064
Validation loss: 2.5699357024237957

Epoch: 6| Step: 1
Training loss: 1.0449721279716555
Validation loss: 2.559937770082179

Epoch: 6| Step: 2
Training loss: 2.1289499260858067
Validation loss: 2.597068869358054

Epoch: 6| Step: 3
Training loss: 1.0595709875429877
Validation loss: 2.60970979625222

Epoch: 6| Step: 4
Training loss: 1.1670866732474088
Validation loss: 2.5393938679752712

Epoch: 6| Step: 5
Training loss: 1.3004786508869182
Validation loss: 2.581307067732867

Epoch: 6| Step: 6
Training loss: 1.034459696641452
Validation loss: 2.55016247350158

Epoch: 6| Step: 7
Training loss: 0.914641856940263
Validation loss: 2.553152060394505

Epoch: 6| Step: 8
Training loss: 0.9511580260598261
Validation loss: 2.565116492433835

Epoch: 6| Step: 9
Training loss: 1.4344376826666614
Validation loss: 2.5954526651723135

Epoch: 6| Step: 10
Training loss: 1.7818415144841748
Validation loss: 2.5824318102351835

Epoch: 6| Step: 11
Training loss: 1.7940640563373362
Validation loss: 2.493315040050384

Epoch: 6| Step: 12
Training loss: 0.9864300363598236
Validation loss: 2.5370494041569427

Epoch: 6| Step: 13
Training loss: 1.3611006033528563
Validation loss: 2.542678230437715

Epoch: 382| Step: 0
Training loss: 1.0094754006731461
Validation loss: 2.594314804781798

Epoch: 6| Step: 1
Training loss: 1.0910807600016996
Validation loss: 2.4994945174043455

Epoch: 6| Step: 2
Training loss: 1.4527929603475425
Validation loss: 2.555230482533923

Epoch: 6| Step: 3
Training loss: 1.7397387619784817
Validation loss: 2.5430595041889412

Epoch: 6| Step: 4
Training loss: 1.073841208957241
Validation loss: 2.5359740111456377

Epoch: 6| Step: 5
Training loss: 1.008912306990866
Validation loss: 2.5251115771150374

Epoch: 6| Step: 6
Training loss: 1.4940995354082516
Validation loss: 2.5899472376580843

Epoch: 6| Step: 7
Training loss: 0.8739759720002541
Validation loss: 2.54026387280783

Epoch: 6| Step: 8
Training loss: 1.7349282147071006
Validation loss: 2.5935035190130624

Epoch: 6| Step: 9
Training loss: 1.0551813170478919
Validation loss: 2.5424789058494173

Epoch: 6| Step: 10
Training loss: 1.12576045719299
Validation loss: 2.5521246511008178

Epoch: 6| Step: 11
Training loss: 0.8562617001813101
Validation loss: 2.579439202013325

Epoch: 6| Step: 12
Training loss: 1.0700656021364632
Validation loss: 2.5745411479469746

Epoch: 6| Step: 13
Training loss: 1.4210956659456144
Validation loss: 2.5290038735684472

Epoch: 383| Step: 0
Training loss: 0.9530065806883159
Validation loss: 2.5808721452068646

Epoch: 6| Step: 1
Training loss: 1.5460839609045363
Validation loss: 2.499417857102911

Epoch: 6| Step: 2
Training loss: 1.3251970216631848
Validation loss: 2.607633927350856

Epoch: 6| Step: 3
Training loss: 1.1899341932100835
Validation loss: 2.5779597373937575

Epoch: 6| Step: 4
Training loss: 1.1297840019152252
Validation loss: 2.5816790811409724

Epoch: 6| Step: 5
Training loss: 1.565022225755326
Validation loss: 2.5863792295697436

Epoch: 6| Step: 6
Training loss: 1.5321196597207676
Validation loss: 2.5755914434789386

Epoch: 6| Step: 7
Training loss: 1.073791085857153
Validation loss: 2.540027657981534

Epoch: 6| Step: 8
Training loss: 1.0205109664649228
Validation loss: 2.5234860631090408

Epoch: 6| Step: 9
Training loss: 0.9695995666386482
Validation loss: 2.578464562759464

Epoch: 6| Step: 10
Training loss: 1.1483916189150316
Validation loss: 2.5360143117500824

Epoch: 6| Step: 11
Training loss: 0.8424792433765503
Validation loss: 2.5291224199810203

Epoch: 6| Step: 12
Training loss: 1.5289025510841656
Validation loss: 2.486769252259885

Epoch: 6| Step: 13
Training loss: 1.0547012893340466
Validation loss: 2.5122650485789353

Epoch: 384| Step: 0
Training loss: 1.2667661161449657
Validation loss: 2.5128216336745353

Epoch: 6| Step: 1
Training loss: 1.0656080787187778
Validation loss: 2.5052101362595973

Epoch: 6| Step: 2
Training loss: 1.508227592611643
Validation loss: 2.5538394154115633

Epoch: 6| Step: 3
Training loss: 0.9304853910276087
Validation loss: 2.525038598020539

Epoch: 6| Step: 4
Training loss: 1.0800136664196986
Validation loss: 2.5555177558531366

Epoch: 6| Step: 5
Training loss: 1.1842690735002315
Validation loss: 2.5159737323538036

Epoch: 6| Step: 6
Training loss: 0.9562742080616186
Validation loss: 2.5831007596403097

Epoch: 6| Step: 7
Training loss: 0.8531673253218244
Validation loss: 2.5796679262850812

Epoch: 6| Step: 8
Training loss: 1.2568075299850263
Validation loss: 2.5344483533874915

Epoch: 6| Step: 9
Training loss: 1.3764985328386596
Validation loss: 2.531652928688222

Epoch: 6| Step: 10
Training loss: 1.6667242119709371
Validation loss: 2.5474379059795695

Epoch: 6| Step: 11
Training loss: 1.2349361641019094
Validation loss: 2.5903163994531084

Epoch: 6| Step: 12
Training loss: 0.9659046101593697
Validation loss: 2.5861146065260057

Epoch: 6| Step: 13
Training loss: 1.5924879574881792
Validation loss: 2.583078069278257

Epoch: 385| Step: 0
Training loss: 1.1539086013181126
Validation loss: 2.59662458158805

Epoch: 6| Step: 1
Training loss: 1.1445454150680612
Validation loss: 2.6000490798352605

Epoch: 6| Step: 2
Training loss: 1.6923009607207857
Validation loss: 2.624355093134103

Epoch: 6| Step: 3
Training loss: 1.2450865019962702
Validation loss: 2.6379242879680835

Epoch: 6| Step: 4
Training loss: 1.0190249534224527
Validation loss: 2.626377879410568

Epoch: 6| Step: 5
Training loss: 1.3486873938849786
Validation loss: 2.5845632291589284

Epoch: 6| Step: 6
Training loss: 1.6179882775955974
Validation loss: 2.618903558761294

Epoch: 6| Step: 7
Training loss: 1.061495137473499
Validation loss: 2.5660246512620652

Epoch: 6| Step: 8
Training loss: 1.459232253091719
Validation loss: 2.5660554364490427

Epoch: 6| Step: 9
Training loss: 1.2154692483869816
Validation loss: 2.5922376980787187

Epoch: 6| Step: 10
Training loss: 1.287357566880656
Validation loss: 2.600418763488143

Epoch: 6| Step: 11
Training loss: 0.8952213940027589
Validation loss: 2.5559303612373623

Epoch: 6| Step: 12
Training loss: 1.4759130109103775
Validation loss: 2.5459318462443434

Epoch: 6| Step: 13
Training loss: 0.8257748346431413
Validation loss: 2.506361861677631

Epoch: 386| Step: 0
Training loss: 0.9029298010414906
Validation loss: 2.536732783473086

Epoch: 6| Step: 1
Training loss: 1.1714160274704597
Validation loss: 2.5869421030370274

Epoch: 6| Step: 2
Training loss: 1.326264278468033
Validation loss: 2.5903435287675833

Epoch: 6| Step: 3
Training loss: 1.012020404870056
Validation loss: 2.596935361488885

Epoch: 6| Step: 4
Training loss: 0.9047035308102779
Validation loss: 2.650475512133533

Epoch: 6| Step: 5
Training loss: 1.3354138692190751
Validation loss: 2.6541863447225396

Epoch: 6| Step: 6
Training loss: 1.3730525617630946
Validation loss: 2.6491962347533495

Epoch: 6| Step: 7
Training loss: 1.1526699315733273
Validation loss: 2.698892856178109

Epoch: 6| Step: 8
Training loss: 1.3122118679036132
Validation loss: 2.647991690534527

Epoch: 6| Step: 9
Training loss: 1.2540738002744212
Validation loss: 2.609559195407519

Epoch: 6| Step: 10
Training loss: 1.6347882304571324
Validation loss: 2.575293895776286

Epoch: 6| Step: 11
Training loss: 1.3260083104703153
Validation loss: 2.5728575253092356

Epoch: 6| Step: 12
Training loss: 1.6233963756474294
Validation loss: 2.5612920534682067

Epoch: 6| Step: 13
Training loss: 1.1407078752065436
Validation loss: 2.5943790270526668

Epoch: 387| Step: 0
Training loss: 0.9978255233607679
Validation loss: 2.5757718994044954

Epoch: 6| Step: 1
Training loss: 1.3164706341763965
Validation loss: 2.574156903694717

Epoch: 6| Step: 2
Training loss: 1.5379871155009393
Validation loss: 2.568415613368561

Epoch: 6| Step: 3
Training loss: 0.7869286720205475
Validation loss: 2.5597054044277168

Epoch: 6| Step: 4
Training loss: 1.0604585220880125
Validation loss: 2.537888592999141

Epoch: 6| Step: 5
Training loss: 1.1013854405297174
Validation loss: 2.5769180709492425

Epoch: 6| Step: 6
Training loss: 1.3110272909883949
Validation loss: 2.5673228368456256

Epoch: 6| Step: 7
Training loss: 0.8569694489805652
Validation loss: 2.581072115060504

Epoch: 6| Step: 8
Training loss: 1.0118007553034427
Validation loss: 2.587782847721318

Epoch: 6| Step: 9
Training loss: 1.3827177974363052
Validation loss: 2.5958456283041405

Epoch: 6| Step: 10
Training loss: 1.2230253789737278
Validation loss: 2.6076603355377994

Epoch: 6| Step: 11
Training loss: 1.428288092785143
Validation loss: 2.58359463713517

Epoch: 6| Step: 12
Training loss: 1.818340493994348
Validation loss: 2.621085411850638

Epoch: 6| Step: 13
Training loss: 1.6997629280838644
Validation loss: 2.597495335540157

Epoch: 388| Step: 0
Training loss: 1.089457563115624
Validation loss: 2.6690141557547005

Epoch: 6| Step: 1
Training loss: 1.2855259325934896
Validation loss: 2.571761290152058

Epoch: 6| Step: 2
Training loss: 1.0816237580929169
Validation loss: 2.53153897429493

Epoch: 6| Step: 3
Training loss: 0.7855783722726485
Validation loss: 2.5664743756020134

Epoch: 6| Step: 4
Training loss: 1.731791315937572
Validation loss: 2.5722277307096655

Epoch: 6| Step: 5
Training loss: 1.1741882381167847
Validation loss: 2.5535451530098072

Epoch: 6| Step: 6
Training loss: 0.8035669765651839
Validation loss: 2.5774610647078338

Epoch: 6| Step: 7
Training loss: 1.2723460756749323
Validation loss: 2.599216017756523

Epoch: 6| Step: 8
Training loss: 1.192713985957226
Validation loss: 2.5835114130558376

Epoch: 6| Step: 9
Training loss: 1.2377035435984833
Validation loss: 2.5891383894927418

Epoch: 6| Step: 10
Training loss: 1.6317146662560815
Validation loss: 2.6029322457817985

Epoch: 6| Step: 11
Training loss: 1.113477080672404
Validation loss: 2.637966337453868

Epoch: 6| Step: 12
Training loss: 1.6547389785208217
Validation loss: 2.623064311393981

Epoch: 6| Step: 13
Training loss: 1.2309979950604197
Validation loss: 2.6799577552635325

Epoch: 389| Step: 0
Training loss: 1.3866836758328445
Validation loss: 2.6624322790091117

Epoch: 6| Step: 1
Training loss: 1.1424310051517257
Validation loss: 2.6308759289026957

Epoch: 6| Step: 2
Training loss: 1.4312105664813652
Validation loss: 2.6644528756455896

Epoch: 6| Step: 3
Training loss: 1.3997812900687558
Validation loss: 2.6687153208710606

Epoch: 6| Step: 4
Training loss: 0.8864780721173935
Validation loss: 2.573825078643912

Epoch: 6| Step: 5
Training loss: 1.0985950514343912
Validation loss: 2.5427093139129795

Epoch: 6| Step: 6
Training loss: 1.4096819642722938
Validation loss: 2.5682946103902653

Epoch: 6| Step: 7
Training loss: 0.6126830712975253
Validation loss: 2.568382411993682

Epoch: 6| Step: 8
Training loss: 0.977696698537697
Validation loss: 2.5448489877681215

Epoch: 6| Step: 9
Training loss: 1.4457939377107116
Validation loss: 2.5597811130237718

Epoch: 6| Step: 10
Training loss: 1.209212372562534
Validation loss: 2.565370827899835

Epoch: 6| Step: 11
Training loss: 0.9578850810443789
Validation loss: 2.526379227778514

Epoch: 6| Step: 12
Training loss: 1.107810085277858
Validation loss: 2.5946878476521493

Epoch: 6| Step: 13
Training loss: 1.5397716766630247
Validation loss: 2.5450083751328316

Epoch: 390| Step: 0
Training loss: 1.5639059226578549
Validation loss: 2.590724452019062

Epoch: 6| Step: 1
Training loss: 1.077739923234065
Validation loss: 2.4912856013664686

Epoch: 6| Step: 2
Training loss: 1.2612201662192937
Validation loss: 2.5296279985052217

Epoch: 6| Step: 3
Training loss: 0.8458621820375242
Validation loss: 2.530988601248444

Epoch: 6| Step: 4
Training loss: 1.355517955403605
Validation loss: 2.5095237843010327

Epoch: 6| Step: 5
Training loss: 1.1707581347733353
Validation loss: 2.5179093298162587

Epoch: 6| Step: 6
Training loss: 0.8167508506852207
Validation loss: 2.5594959949279

Epoch: 6| Step: 7
Training loss: 1.2378029847351173
Validation loss: 2.571032298677141

Epoch: 6| Step: 8
Training loss: 0.9836147036452858
Validation loss: 2.6054904751918024

Epoch: 6| Step: 9
Training loss: 1.1147606907614438
Validation loss: 2.6000758783565665

Epoch: 6| Step: 10
Training loss: 1.2773109921795858
Validation loss: 2.6436301141826175

Epoch: 6| Step: 11
Training loss: 1.6868459352333445
Validation loss: 2.660464462671425

Epoch: 6| Step: 12
Training loss: 1.1362217081910069
Validation loss: 2.621184194475855

Epoch: 6| Step: 13
Training loss: 0.9385694126398642
Validation loss: 2.6310117545740668

Epoch: 391| Step: 0
Training loss: 1.1956705791202709
Validation loss: 2.620551972885366

Epoch: 6| Step: 1
Training loss: 0.9256940068209479
Validation loss: 2.5952365246330964

Epoch: 6| Step: 2
Training loss: 1.461978724902822
Validation loss: 2.5605210982634574

Epoch: 6| Step: 3
Training loss: 1.0028999717938336
Validation loss: 2.538781581890708

Epoch: 6| Step: 4
Training loss: 1.2091620442577917
Validation loss: 2.5556254089409873

Epoch: 6| Step: 5
Training loss: 0.8017292273161513
Validation loss: 2.5536537684307534

Epoch: 6| Step: 6
Training loss: 1.5795861457887548
Validation loss: 2.567148164280229

Epoch: 6| Step: 7
Training loss: 0.8218108888285813
Validation loss: 2.5916418677448845

Epoch: 6| Step: 8
Training loss: 1.3127831653131596
Validation loss: 2.5793900131701903

Epoch: 6| Step: 9
Training loss: 1.2416842418851985
Validation loss: 2.564035211635252

Epoch: 6| Step: 10
Training loss: 0.9958972811949369
Validation loss: 2.5825158230548233

Epoch: 6| Step: 11
Training loss: 1.1620452606722993
Validation loss: 2.576275587946608

Epoch: 6| Step: 12
Training loss: 1.25529474406829
Validation loss: 2.5743664557801473

Epoch: 6| Step: 13
Training loss: 1.4181515074093916
Validation loss: 2.5739637681776837

Epoch: 392| Step: 0
Training loss: 1.4294771967400375
Validation loss: 2.577058467472622

Epoch: 6| Step: 1
Training loss: 0.9897737353341356
Validation loss: 2.626671062391576

Epoch: 6| Step: 2
Training loss: 0.950847092466798
Validation loss: 2.611024810895694

Epoch: 6| Step: 3
Training loss: 1.127562835617189
Validation loss: 2.61303811683791

Epoch: 6| Step: 4
Training loss: 0.7631186508301993
Validation loss: 2.610525627531143

Epoch: 6| Step: 5
Training loss: 1.7854014422354776
Validation loss: 2.6183584753618567

Epoch: 6| Step: 6
Training loss: 1.2692269767580082
Validation loss: 2.6108651236960685

Epoch: 6| Step: 7
Training loss: 1.522723612658011
Validation loss: 2.6099583474364083

Epoch: 6| Step: 8
Training loss: 1.2690377083023907
Validation loss: 2.599938451820974

Epoch: 6| Step: 9
Training loss: 0.9468210651912529
Validation loss: 2.6078006921633814

Epoch: 6| Step: 10
Training loss: 1.0009264826458555
Validation loss: 2.6092984003637274

Epoch: 6| Step: 11
Training loss: 1.153154198088218
Validation loss: 2.6235821391545002

Epoch: 6| Step: 12
Training loss: 1.0910858404863544
Validation loss: 2.596702687483345

Epoch: 6| Step: 13
Training loss: 1.4148232115714037
Validation loss: 2.6000112313248067

Epoch: 393| Step: 0
Training loss: 1.00660064937632
Validation loss: 2.5639544832892907

Epoch: 6| Step: 1
Training loss: 0.9484524243357347
Validation loss: 2.5190797780790755

Epoch: 6| Step: 2
Training loss: 1.1236964196658927
Validation loss: 2.5758551729976014

Epoch: 6| Step: 3
Training loss: 1.069831461601167
Validation loss: 2.570237055234577

Epoch: 6| Step: 4
Training loss: 1.1441626882981726
Validation loss: 2.5318346329554

Epoch: 6| Step: 5
Training loss: 1.1000328535895827
Validation loss: 2.574495353753313

Epoch: 6| Step: 6
Training loss: 0.9737715550535593
Validation loss: 2.5881125684849686

Epoch: 6| Step: 7
Training loss: 1.1602038235655778
Validation loss: 2.5424703880243547

Epoch: 6| Step: 8
Training loss: 1.1370148158487892
Validation loss: 2.570797488943167

Epoch: 6| Step: 9
Training loss: 1.1255318126410687
Validation loss: 2.597031834254601

Epoch: 6| Step: 10
Training loss: 1.026227511439491
Validation loss: 2.5863851599623797

Epoch: 6| Step: 11
Training loss: 1.0143933383978632
Validation loss: 2.5981697053101342

Epoch: 6| Step: 12
Training loss: 1.9753777492798317
Validation loss: 2.603317882815176

Epoch: 6| Step: 13
Training loss: 1.5315045514962278
Validation loss: 2.563086775921273

Epoch: 394| Step: 0
Training loss: 1.0133047743796728
Validation loss: 2.626011199552502

Epoch: 6| Step: 1
Training loss: 1.0871224285058914
Validation loss: 2.6363007993643683

Epoch: 6| Step: 2
Training loss: 0.8421497711619805
Validation loss: 2.654111262950406

Epoch: 6| Step: 3
Training loss: 1.1608875166348747
Validation loss: 2.685137427357183

Epoch: 6| Step: 4
Training loss: 1.4455734429770517
Validation loss: 2.6325277897115766

Epoch: 6| Step: 5
Training loss: 1.0248573878561935
Validation loss: 2.5952760887156376

Epoch: 6| Step: 6
Training loss: 1.229959340082519
Validation loss: 2.602089493446195

Epoch: 6| Step: 7
Training loss: 1.098215035583382
Validation loss: 2.6066979630860647

Epoch: 6| Step: 8
Training loss: 1.7111398934273434
Validation loss: 2.6050888463231234

Epoch: 6| Step: 9
Training loss: 1.4814796720378915
Validation loss: 2.644204927687207

Epoch: 6| Step: 10
Training loss: 1.77690142482735
Validation loss: 2.668149064218294

Epoch: 6| Step: 11
Training loss: 1.8909589614368951
Validation loss: 2.6409855884186237

Epoch: 6| Step: 12
Training loss: 1.9345203992093947
Validation loss: 2.656587048258493

Epoch: 6| Step: 13
Training loss: 1.8369136082244588
Validation loss: 2.660648115620865

Epoch: 395| Step: 0
Training loss: 0.957730438799385
Validation loss: 2.700021170898135

Epoch: 6| Step: 1
Training loss: 1.6642094220415853
Validation loss: 2.736988743923477

Epoch: 6| Step: 2
Training loss: 1.6753667572235391
Validation loss: 2.754415233281572

Epoch: 6| Step: 3
Training loss: 1.2247259884544193
Validation loss: 2.7245104627076406

Epoch: 6| Step: 4
Training loss: 1.0360416296728727
Validation loss: 2.652099403358631

Epoch: 6| Step: 5
Training loss: 1.5054670681273445
Validation loss: 2.663460030396838

Epoch: 6| Step: 6
Training loss: 1.277757210266513
Validation loss: 2.6463061883865735

Epoch: 6| Step: 7
Training loss: 1.1225449477034597
Validation loss: 2.550229241158432

Epoch: 6| Step: 8
Training loss: 1.348129366326899
Validation loss: 2.531882046253648

Epoch: 6| Step: 9
Training loss: 1.0510236609397061
Validation loss: 2.5366610864418333

Epoch: 6| Step: 10
Training loss: 1.0000707482106936
Validation loss: 2.5609388480610584

Epoch: 6| Step: 11
Training loss: 1.5701927784692575
Validation loss: 2.5172461583576116

Epoch: 6| Step: 12
Training loss: 1.1597858698289871
Validation loss: 2.5616821906918883

Epoch: 6| Step: 13
Training loss: 1.3526217328638395
Validation loss: 2.497639415796795

Epoch: 396| Step: 0
Training loss: 1.4676096121096096
Validation loss: 2.5704848396939033

Epoch: 6| Step: 1
Training loss: 1.1517953893396664
Validation loss: 2.544802034668967

Epoch: 6| Step: 2
Training loss: 1.2630361287347718
Validation loss: 2.564524835270066

Epoch: 6| Step: 3
Training loss: 1.2681522332995
Validation loss: 2.6040026702105403

Epoch: 6| Step: 4
Training loss: 1.3489098067619512
Validation loss: 2.610088700021082

Epoch: 6| Step: 5
Training loss: 1.195473604004199
Validation loss: 2.633652640753373

Epoch: 6| Step: 6
Training loss: 1.0276576385790268
Validation loss: 2.5981784993502037

Epoch: 6| Step: 7
Training loss: 1.2528974331207372
Validation loss: 2.582060443907426

Epoch: 6| Step: 8
Training loss: 0.6523760484934427
Validation loss: 2.583128526218954

Epoch: 6| Step: 9
Training loss: 1.0838636176402856
Validation loss: 2.5407357986645365

Epoch: 6| Step: 10
Training loss: 1.084085325746897
Validation loss: 2.551788489508563

Epoch: 6| Step: 11
Training loss: 1.766547848046714
Validation loss: 2.5899220297036463

Epoch: 6| Step: 12
Training loss: 0.6995346804754766
Validation loss: 2.5837222519239513

Epoch: 6| Step: 13
Training loss: 1.029201669651164
Validation loss: 2.571114048915849

Epoch: 397| Step: 0
Training loss: 1.0628107401904214
Validation loss: 2.6311575407454413

Epoch: 6| Step: 1
Training loss: 1.135126210896258
Validation loss: 2.523125998341134

Epoch: 6| Step: 2
Training loss: 1.2089679575161287
Validation loss: 2.5989192177396956

Epoch: 6| Step: 3
Training loss: 1.6981293792724301
Validation loss: 2.577077055368098

Epoch: 6| Step: 4
Training loss: 1.4136960729808492
Validation loss: 2.630081601756491

Epoch: 6| Step: 5
Training loss: 1.041532520557464
Validation loss: 2.605702783843838

Epoch: 6| Step: 6
Training loss: 1.1072640550435802
Validation loss: 2.6355810202111196

Epoch: 6| Step: 7
Training loss: 1.2020978630329353
Validation loss: 2.611945966292158

Epoch: 6| Step: 8
Training loss: 1.185520982538119
Validation loss: 2.5462018783159492

Epoch: 6| Step: 9
Training loss: 0.8096401796459531
Validation loss: 2.602659862737413

Epoch: 6| Step: 10
Training loss: 0.7953194788418633
Validation loss: 2.596281095883918

Epoch: 6| Step: 11
Training loss: 1.59105784104738
Validation loss: 2.5942045985396898

Epoch: 6| Step: 12
Training loss: 1.1599526274807832
Validation loss: 2.57655147737513

Epoch: 6| Step: 13
Training loss: 0.9905699513059013
Validation loss: 2.5655529939844204

Epoch: 398| Step: 0
Training loss: 1.3779732462745513
Validation loss: 2.618308484861823

Epoch: 6| Step: 1
Training loss: 1.5051144193326975
Validation loss: 2.6055750026894438

Epoch: 6| Step: 2
Training loss: 1.5084989892325904
Validation loss: 2.578018972355153

Epoch: 6| Step: 3
Training loss: 1.178030505046067
Validation loss: 2.6105250947743786

Epoch: 6| Step: 4
Training loss: 0.8398286330171103
Validation loss: 2.61014134466442

Epoch: 6| Step: 5
Training loss: 0.9895608932895515
Validation loss: 2.6039950098047524

Epoch: 6| Step: 6
Training loss: 0.9957213958704123
Validation loss: 2.5951118570816925

Epoch: 6| Step: 7
Training loss: 1.4231223200260572
Validation loss: 2.573801040526207

Epoch: 6| Step: 8
Training loss: 0.9092451127355975
Validation loss: 2.592233482598363

Epoch: 6| Step: 9
Training loss: 1.2968638775819645
Validation loss: 2.5557983036665193

Epoch: 6| Step: 10
Training loss: 1.0104730072568864
Validation loss: 2.5348009704016112

Epoch: 6| Step: 11
Training loss: 0.8100767679687813
Validation loss: 2.532598332601412

Epoch: 6| Step: 12
Training loss: 1.1485077713208134
Validation loss: 2.5067565215860923

Epoch: 6| Step: 13
Training loss: 1.0679931012763046
Validation loss: 2.5535021412710166

Epoch: 399| Step: 0
Training loss: 0.9183499457858124
Validation loss: 2.574881491974082

Epoch: 6| Step: 1
Training loss: 0.8412162389116564
Validation loss: 2.5968035605864324

Epoch: 6| Step: 2
Training loss: 1.5003398669177652
Validation loss: 2.6072218914705987

Epoch: 6| Step: 3
Training loss: 1.3918861927940789
Validation loss: 2.6060578053548764

Epoch: 6| Step: 4
Training loss: 1.2153952962578765
Validation loss: 2.666535617667979

Epoch: 6| Step: 5
Training loss: 1.2482172651194914
Validation loss: 2.6866080038427924

Epoch: 6| Step: 6
Training loss: 1.1573146866993385
Validation loss: 2.6863581575252624

Epoch: 6| Step: 7
Training loss: 0.7058170493798531
Validation loss: 2.667862271464283

Epoch: 6| Step: 8
Training loss: 1.844444532024172
Validation loss: 2.6639858917229327

Epoch: 6| Step: 9
Training loss: 0.7785903289983112
Validation loss: 2.613070461893516

Epoch: 6| Step: 10
Training loss: 1.3112656374745295
Validation loss: 2.5814061872691143

Epoch: 6| Step: 11
Training loss: 0.8948735410974415
Validation loss: 2.540933399008686

Epoch: 6| Step: 12
Training loss: 1.2606067776816892
Validation loss: 2.568438371379002

Epoch: 6| Step: 13
Training loss: 0.8250544501166869
Validation loss: 2.5398554106731854

Epoch: 400| Step: 0
Training loss: 1.3368836560354758
Validation loss: 2.513465807692601

Epoch: 6| Step: 1
Training loss: 1.3881469249410845
Validation loss: 2.5261480302473274

Epoch: 6| Step: 2
Training loss: 1.0520822632031932
Validation loss: 2.5133512658542756

Epoch: 6| Step: 3
Training loss: 0.9886391937629906
Validation loss: 2.529565258343791

Epoch: 6| Step: 4
Training loss: 0.9555820625593687
Validation loss: 2.539102485537515

Epoch: 6| Step: 5
Training loss: 1.6343205984481635
Validation loss: 2.586557150796783

Epoch: 6| Step: 6
Training loss: 0.7351812036152723
Validation loss: 2.5655556889726663

Epoch: 6| Step: 7
Training loss: 0.816828349385925
Validation loss: 2.6457391757180755

Epoch: 6| Step: 8
Training loss: 0.8016209363550344
Validation loss: 2.6288170234914126

Epoch: 6| Step: 9
Training loss: 1.7877466951877676
Validation loss: 2.690365852757153

Epoch: 6| Step: 10
Training loss: 0.7754040387816646
Validation loss: 2.655967667478603

Epoch: 6| Step: 11
Training loss: 1.1049913110003036
Validation loss: 2.655809807299655

Epoch: 6| Step: 12
Training loss: 1.7075140159109883
Validation loss: 2.6659009002854974

Epoch: 6| Step: 13
Training loss: 1.1000680729003312
Validation loss: 2.6821260765343635

Epoch: 401| Step: 0
Training loss: 0.9564647009677815
Validation loss: 2.626410332514935

Epoch: 6| Step: 1
Training loss: 1.409971441696656
Validation loss: 2.650413278826323

Epoch: 6| Step: 2
Training loss: 1.0427804269679657
Validation loss: 2.6181435883615642

Epoch: 6| Step: 3
Training loss: 1.3929846385620908
Validation loss: 2.5867229087194747

Epoch: 6| Step: 4
Training loss: 1.6197090577610576
Validation loss: 2.5804200101124755

Epoch: 6| Step: 5
Training loss: 1.318374701516814
Validation loss: 2.594024398567399

Epoch: 6| Step: 6
Training loss: 1.5608978449736028
Validation loss: 2.5736999452011626

Epoch: 6| Step: 7
Training loss: 1.0606426947426497
Validation loss: 2.5413272089002104

Epoch: 6| Step: 8
Training loss: 0.903843150001192
Validation loss: 2.6043535063793257

Epoch: 6| Step: 9
Training loss: 0.8117328837158287
Validation loss: 2.5941095830623175

Epoch: 6| Step: 10
Training loss: 1.2365730127481085
Validation loss: 2.602593279781375

Epoch: 6| Step: 11
Training loss: 1.1650240210483864
Validation loss: 2.6490226406782575

Epoch: 6| Step: 12
Training loss: 1.0553281745503413
Validation loss: 2.672895522912339

Epoch: 6| Step: 13
Training loss: 1.1367861278792222
Validation loss: 2.6486955215062715

Epoch: 402| Step: 0
Training loss: 0.9142955254769131
Validation loss: 2.644240768609336

Epoch: 6| Step: 1
Training loss: 1.2081611061127855
Validation loss: 2.640206034753229

Epoch: 6| Step: 2
Training loss: 1.647379965338405
Validation loss: 2.616143119780733

Epoch: 6| Step: 3
Training loss: 0.931562312451497
Validation loss: 2.580413503938011

Epoch: 6| Step: 4
Training loss: 1.0788281124473282
Validation loss: 2.5925674960142833

Epoch: 6| Step: 5
Training loss: 0.8543791080311909
Validation loss: 2.5582696529833777

Epoch: 6| Step: 6
Training loss: 1.2888950123495309
Validation loss: 2.557884463550631

Epoch: 6| Step: 7
Training loss: 1.432496110601288
Validation loss: 2.629135975807195

Epoch: 6| Step: 8
Training loss: 1.4618281133405804
Validation loss: 2.572433184295719

Epoch: 6| Step: 9
Training loss: 1.2222191269912444
Validation loss: 2.6484213709457323

Epoch: 6| Step: 10
Training loss: 1.0238291449689096
Validation loss: 2.553687013473918

Epoch: 6| Step: 11
Training loss: 1.3103490188353328
Validation loss: 2.568855251312388

Epoch: 6| Step: 12
Training loss: 0.7022417030414708
Validation loss: 2.57596847043526

Epoch: 6| Step: 13
Training loss: 1.0985507239297463
Validation loss: 2.5949422401855284

Epoch: 403| Step: 0
Training loss: 1.190989937509969
Validation loss: 2.6217093505181617

Epoch: 6| Step: 1
Training loss: 1.0656203843181804
Validation loss: 2.6363684979680957

Epoch: 6| Step: 2
Training loss: 1.2481001721674443
Validation loss: 2.641826822638624

Epoch: 6| Step: 3
Training loss: 1.4721426232530062
Validation loss: 2.6003074024115174

Epoch: 6| Step: 4
Training loss: 1.0269969746546028
Validation loss: 2.6252885311742746

Epoch: 6| Step: 5
Training loss: 1.2479801070571892
Validation loss: 2.6457827455585528

Epoch: 6| Step: 6
Training loss: 0.9002868857376323
Validation loss: 2.6618229764912384

Epoch: 6| Step: 7
Training loss: 1.0329556087546032
Validation loss: 2.633894957234792

Epoch: 6| Step: 8
Training loss: 1.2876253844752106
Validation loss: 2.630227681205267

Epoch: 6| Step: 9
Training loss: 1.4088134289655487
Validation loss: 2.583855696646118

Epoch: 6| Step: 10
Training loss: 0.9017846162781242
Validation loss: 2.588366655436958

Epoch: 6| Step: 11
Training loss: 0.796803265503048
Validation loss: 2.574766742301595

Epoch: 6| Step: 12
Training loss: 0.9022479976696312
Validation loss: 2.5565555909044826

Epoch: 6| Step: 13
Training loss: 1.280079190367557
Validation loss: 2.627939773062021

Epoch: 404| Step: 0
Training loss: 0.926179502432446
Validation loss: 2.6418374868773467

Epoch: 6| Step: 1
Training loss: 1.5292861178081913
Validation loss: 2.613855828116565

Epoch: 6| Step: 2
Training loss: 0.7277099818238215
Validation loss: 2.5247956548913684

Epoch: 6| Step: 3
Training loss: 1.0498294987075312
Validation loss: 2.566673957723525

Epoch: 6| Step: 4
Training loss: 1.332566676663463
Validation loss: 2.5656332383699216

Epoch: 6| Step: 5
Training loss: 1.0011108308385508
Validation loss: 2.547514969629212

Epoch: 6| Step: 6
Training loss: 1.0389077207543709
Validation loss: 2.565462632797237

Epoch: 6| Step: 7
Training loss: 1.202011484856094
Validation loss: 2.59108108107332

Epoch: 6| Step: 8
Training loss: 0.8930658723173637
Validation loss: 2.563483553437888

Epoch: 6| Step: 9
Training loss: 1.0207156029108975
Validation loss: 2.5921080957491176

Epoch: 6| Step: 10
Training loss: 1.4565622019608886
Validation loss: 2.6078643232940473

Epoch: 6| Step: 11
Training loss: 0.9311750996314031
Validation loss: 2.6030232068049646

Epoch: 6| Step: 12
Training loss: 1.1876425406587305
Validation loss: 2.625136129694475

Epoch: 6| Step: 13
Training loss: 1.0587625404164693
Validation loss: 2.6392936886845706

Epoch: 405| Step: 0
Training loss: 1.1032281281675842
Validation loss: 2.590468126677303

Epoch: 6| Step: 1
Training loss: 0.966576198477111
Validation loss: 2.645318354153075

Epoch: 6| Step: 2
Training loss: 1.0137580732031173
Validation loss: 2.623769895766816

Epoch: 6| Step: 3
Training loss: 1.5988620227880261
Validation loss: 2.6256976033244186

Epoch: 6| Step: 4
Training loss: 0.9997053010148069
Validation loss: 2.640666397041102

Epoch: 6| Step: 5
Training loss: 0.9075242325145736
Validation loss: 2.637880528074479

Epoch: 6| Step: 6
Training loss: 1.1287729785223584
Validation loss: 2.602145300606569

Epoch: 6| Step: 7
Training loss: 0.7896512922433054
Validation loss: 2.580483207696783

Epoch: 6| Step: 8
Training loss: 1.4130411411189523
Validation loss: 2.607026922481284

Epoch: 6| Step: 9
Training loss: 1.1899838821537738
Validation loss: 2.5676761235711667

Epoch: 6| Step: 10
Training loss: 1.1050853805870142
Validation loss: 2.597236817421479

Epoch: 6| Step: 11
Training loss: 0.7740471489022842
Validation loss: 2.591100542193422

Epoch: 6| Step: 12
Training loss: 0.9076269803915417
Validation loss: 2.591218824013502

Epoch: 6| Step: 13
Training loss: 1.3254391608217697
Validation loss: 2.596645485551246

Epoch: 406| Step: 0
Training loss: 1.0691825861252369
Validation loss: 2.6367960600645297

Epoch: 6| Step: 1
Training loss: 1.453629764954196
Validation loss: 2.674244192784154

Epoch: 6| Step: 2
Training loss: 1.1160920648029395
Validation loss: 2.5932933987637488

Epoch: 6| Step: 3
Training loss: 0.9801284077753802
Validation loss: 2.6886017928752595

Epoch: 6| Step: 4
Training loss: 1.115887772844365
Validation loss: 2.620227282023051

Epoch: 6| Step: 5
Training loss: 1.4553690165136488
Validation loss: 2.6277736663338147

Epoch: 6| Step: 6
Training loss: 0.989682948803954
Validation loss: 2.5555002084442253

Epoch: 6| Step: 7
Training loss: 1.0661073482383632
Validation loss: 2.642220611334715

Epoch: 6| Step: 8
Training loss: 1.0852465729992162
Validation loss: 2.5788357458191067

Epoch: 6| Step: 9
Training loss: 1.1708600035556473
Validation loss: 2.582651845709118

Epoch: 6| Step: 10
Training loss: 0.8118053547953487
Validation loss: 2.5560077440520623

Epoch: 6| Step: 11
Training loss: 0.8548401216859817
Validation loss: 2.5964949151051835

Epoch: 6| Step: 12
Training loss: 1.1520262199901528
Validation loss: 2.648285537906214

Epoch: 6| Step: 13
Training loss: 0.6367360680220098
Validation loss: 2.642546411790606

Epoch: 407| Step: 0
Training loss: 1.3202376034051164
Validation loss: 2.5935234982051325

Epoch: 6| Step: 1
Training loss: 0.7209268444978625
Validation loss: 2.6227385604134277

Epoch: 6| Step: 2
Training loss: 0.8452908257545612
Validation loss: 2.6203077249136575

Epoch: 6| Step: 3
Training loss: 1.107460949728129
Validation loss: 2.6476319474866226

Epoch: 6| Step: 4
Training loss: 1.192774303005586
Validation loss: 2.601878821890733

Epoch: 6| Step: 5
Training loss: 0.9209445848765229
Validation loss: 2.611226991241942

Epoch: 6| Step: 6
Training loss: 0.9649493819880887
Validation loss: 2.6298446303092597

Epoch: 6| Step: 7
Training loss: 0.6875160388809609
Validation loss: 2.623959622768334

Epoch: 6| Step: 8
Training loss: 1.2984855486888596
Validation loss: 2.6142704587774683

Epoch: 6| Step: 9
Training loss: 1.1467151831927342
Validation loss: 2.6453559675136016

Epoch: 6| Step: 10
Training loss: 1.0933179819572256
Validation loss: 2.6166095152361977

Epoch: 6| Step: 11
Training loss: 0.9550726642725568
Validation loss: 2.5939374649139397

Epoch: 6| Step: 12
Training loss: 0.9976159227266782
Validation loss: 2.612606324461302

Epoch: 6| Step: 13
Training loss: 1.1944004144365086
Validation loss: 2.6057641940393497

Epoch: 408| Step: 0
Training loss: 0.8846725852838275
Validation loss: 2.562558413824452

Epoch: 6| Step: 1
Training loss: 1.1207156723452905
Validation loss: 2.584139933845083

Epoch: 6| Step: 2
Training loss: 0.7073937851264777
Validation loss: 2.563232441253086

Epoch: 6| Step: 3
Training loss: 1.6755473367122389
Validation loss: 2.5930774077103305

Epoch: 6| Step: 4
Training loss: 1.2901982708047903
Validation loss: 2.6174356523223365

Epoch: 6| Step: 5
Training loss: 0.8983757992994734
Validation loss: 2.5669090982195173

Epoch: 6| Step: 6
Training loss: 1.0140862178526882
Validation loss: 2.579564765646049

Epoch: 6| Step: 7
Training loss: 1.1235498512762652
Validation loss: 2.642542517159704

Epoch: 6| Step: 8
Training loss: 1.227269254544672
Validation loss: 2.6836933263732927

Epoch: 6| Step: 9
Training loss: 1.029292473973632
Validation loss: 2.681150120651054

Epoch: 6| Step: 10
Training loss: 1.238064960639631
Validation loss: 2.612933627559033

Epoch: 6| Step: 11
Training loss: 0.7494223277312493
Validation loss: 2.6130587298239463

Epoch: 6| Step: 12
Training loss: 0.7135423999049371
Validation loss: 2.6022326090386674

Epoch: 6| Step: 13
Training loss: 0.9364376724956909
Validation loss: 2.631365777592315

Epoch: 409| Step: 0
Training loss: 1.0367806411126461
Validation loss: 2.616236135169926

Epoch: 6| Step: 1
Training loss: 1.1317267114237322
Validation loss: 2.6503640278714133

Epoch: 6| Step: 2
Training loss: 1.0072555185726855
Validation loss: 2.672041101479353

Epoch: 6| Step: 3
Training loss: 0.7295373700919349
Validation loss: 2.6227242505005197

Epoch: 6| Step: 4
Training loss: 1.1714926032184099
Validation loss: 2.6008423733597423

Epoch: 6| Step: 5
Training loss: 1.5027097227505382
Validation loss: 2.5744633729637902

Epoch: 6| Step: 6
Training loss: 1.0951227565220334
Validation loss: 2.6286812204652548

Epoch: 6| Step: 7
Training loss: 1.0233239263750389
Validation loss: 2.631506576170361

Epoch: 6| Step: 8
Training loss: 0.9694220457583357
Validation loss: 2.639517045687852

Epoch: 6| Step: 9
Training loss: 1.1838972753733639
Validation loss: 2.604136052269594

Epoch: 6| Step: 10
Training loss: 0.904511164740237
Validation loss: 2.6079587462269194

Epoch: 6| Step: 11
Training loss: 1.1041757955113798
Validation loss: 2.633432928346702

Epoch: 6| Step: 12
Training loss: 1.0722169291794428
Validation loss: 2.5946936212242573

Epoch: 6| Step: 13
Training loss: 1.162280158308269
Validation loss: 2.6184393247045694

Epoch: 410| Step: 0
Training loss: 0.961088401297054
Validation loss: 2.6193476933365383

Epoch: 6| Step: 1
Training loss: 0.8267913011328598
Validation loss: 2.575480559483852

Epoch: 6| Step: 2
Training loss: 0.9362123865840627
Validation loss: 2.6102479551879876

Epoch: 6| Step: 3
Training loss: 1.1300393196455631
Validation loss: 2.572789028157496

Epoch: 6| Step: 4
Training loss: 1.0511134873883747
Validation loss: 2.6153882878552484

Epoch: 6| Step: 5
Training loss: 1.0645280444176586
Validation loss: 2.60919624371143

Epoch: 6| Step: 6
Training loss: 1.198043396369155
Validation loss: 2.633946748906329

Epoch: 6| Step: 7
Training loss: 1.406375625085357
Validation loss: 2.634674741828502

Epoch: 6| Step: 8
Training loss: 0.7679481294023149
Validation loss: 2.7060399591400057

Epoch: 6| Step: 9
Training loss: 0.9914796061089641
Validation loss: 2.702506022062835

Epoch: 6| Step: 10
Training loss: 1.0784835219311542
Validation loss: 2.7255433080499727

Epoch: 6| Step: 11
Training loss: 1.4517410414892147
Validation loss: 2.6603733745289717

Epoch: 6| Step: 12
Training loss: 1.0518509195782058
Validation loss: 2.6296263299492484

Epoch: 6| Step: 13
Training loss: 0.8746983144295347
Validation loss: 2.6418679376295247

Epoch: 411| Step: 0
Training loss: 0.871894844403596
Validation loss: 2.6249137289009266

Epoch: 6| Step: 1
Training loss: 1.3713097035460482
Validation loss: 2.5728477257721423

Epoch: 6| Step: 2
Training loss: 1.0781686746347925
Validation loss: 2.620807554384048

Epoch: 6| Step: 3
Training loss: 0.8512329723878972
Validation loss: 2.591157881870085

Epoch: 6| Step: 4
Training loss: 0.6825836784640731
Validation loss: 2.603631068782579

Epoch: 6| Step: 5
Training loss: 1.0918218237904436
Validation loss: 2.6680187632097785

Epoch: 6| Step: 6
Training loss: 1.0705804419834917
Validation loss: 2.6386160798742253

Epoch: 6| Step: 7
Training loss: 1.0443280680787819
Validation loss: 2.690067971728622

Epoch: 6| Step: 8
Training loss: 1.2315153968706571
Validation loss: 2.621334392721377

Epoch: 6| Step: 9
Training loss: 0.7703291730643221
Validation loss: 2.5816539001970082

Epoch: 6| Step: 10
Training loss: 1.0511324270863596
Validation loss: 2.6183357263121505

Epoch: 6| Step: 11
Training loss: 1.3941496853308228
Validation loss: 2.605589338159069

Epoch: 6| Step: 12
Training loss: 0.7688494145070315
Validation loss: 2.6550070827914087

Epoch: 6| Step: 13
Training loss: 0.9243171800709915
Validation loss: 2.6557187839466443

Epoch: 412| Step: 0
Training loss: 0.9357931493848782
Validation loss: 2.644553991583405

Epoch: 6| Step: 1
Training loss: 0.9712555079261009
Validation loss: 2.658791108213405

Epoch: 6| Step: 2
Training loss: 1.1327673015127713
Validation loss: 2.635835596695285

Epoch: 6| Step: 3
Training loss: 0.87060163478895
Validation loss: 2.6453925964643137

Epoch: 6| Step: 4
Training loss: 1.2750013613226112
Validation loss: 2.637021256036286

Epoch: 6| Step: 5
Training loss: 0.8611528213886218
Validation loss: 2.6071956464943558

Epoch: 6| Step: 6
Training loss: 1.2048498892773025
Validation loss: 2.6598202067875

Epoch: 6| Step: 7
Training loss: 1.3443018645003695
Validation loss: 2.662771603934641

Epoch: 6| Step: 8
Training loss: 0.8142005290860636
Validation loss: 2.6163121823623023

Epoch: 6| Step: 9
Training loss: 0.8295212976114104
Validation loss: 2.6341030229335862

Epoch: 6| Step: 10
Training loss: 1.1200325758488119
Validation loss: 2.5723823013047573

Epoch: 6| Step: 11
Training loss: 0.6088439387976264
Validation loss: 2.630907133330206

Epoch: 6| Step: 12
Training loss: 1.1378517403524377
Validation loss: 2.6112510043967534

Epoch: 6| Step: 13
Training loss: 0.7592844873809848
Validation loss: 2.5743793520420253

Epoch: 413| Step: 0
Training loss: 1.195747047173429
Validation loss: 2.581689270426249

Epoch: 6| Step: 1
Training loss: 1.0380982822606477
Validation loss: 2.6273257382452577

Epoch: 6| Step: 2
Training loss: 0.9082510986783485
Validation loss: 2.6528794539329925

Epoch: 6| Step: 3
Training loss: 1.064853697833182
Validation loss: 2.625909102918601

Epoch: 6| Step: 4
Training loss: 0.588032702136706
Validation loss: 2.6741186615258905

Epoch: 6| Step: 5
Training loss: 1.0804983359786975
Validation loss: 2.650977965203507

Epoch: 6| Step: 6
Training loss: 1.080993705759418
Validation loss: 2.620383608449749

Epoch: 6| Step: 7
Training loss: 0.8810684734087058
Validation loss: 2.586454311024097

Epoch: 6| Step: 8
Training loss: 0.9491028577597354
Validation loss: 2.640330672555045

Epoch: 6| Step: 9
Training loss: 0.8574195114485504
Validation loss: 2.6617657408631183

Epoch: 6| Step: 10
Training loss: 1.1055098347392482
Validation loss: 2.697681951929748

Epoch: 6| Step: 11
Training loss: 1.11975666553296
Validation loss: 2.6697524713940064

Epoch: 6| Step: 12
Training loss: 1.158944470033915
Validation loss: 2.6836683919077657

Epoch: 6| Step: 13
Training loss: 1.1349165745462568
Validation loss: 2.683551356736394

Epoch: 414| Step: 0
Training loss: 0.8755187812764486
Validation loss: 2.625365928091408

Epoch: 6| Step: 1
Training loss: 0.8104933387816785
Validation loss: 2.6356284366808698

Epoch: 6| Step: 2
Training loss: 1.1783363739542778
Validation loss: 2.620567962622595

Epoch: 6| Step: 3
Training loss: 1.114765342516138
Validation loss: 2.615450139127536

Epoch: 6| Step: 4
Training loss: 1.5457124290928597
Validation loss: 2.631766408592826

Epoch: 6| Step: 5
Training loss: 1.1080648180631663
Validation loss: 2.592369907392726

Epoch: 6| Step: 6
Training loss: 1.241646366892186
Validation loss: 2.6184691294448696

Epoch: 6| Step: 7
Training loss: 1.0228986413510897
Validation loss: 2.611615496363184

Epoch: 6| Step: 8
Training loss: 0.6362750139546783
Validation loss: 2.630565329518657

Epoch: 6| Step: 9
Training loss: 0.7527537257781067
Validation loss: 2.602980111964413

Epoch: 6| Step: 10
Training loss: 0.8816942204590891
Validation loss: 2.603148243446579

Epoch: 6| Step: 11
Training loss: 0.8810451675337065
Validation loss: 2.6259528201935476

Epoch: 6| Step: 12
Training loss: 0.5616870409593396
Validation loss: 2.6500562673868964

Epoch: 6| Step: 13
Training loss: 0.9483157285543458
Validation loss: 2.6364214091363563

Epoch: 415| Step: 0
Training loss: 0.9244375980684828
Validation loss: 2.650996034800297

Epoch: 6| Step: 1
Training loss: 0.9123952282890762
Validation loss: 2.621582675440432

Epoch: 6| Step: 2
Training loss: 0.9484066098758749
Validation loss: 2.674676285524209

Epoch: 6| Step: 3
Training loss: 1.1128110729316574
Validation loss: 2.6360231287264275

Epoch: 6| Step: 4
Training loss: 1.0283564808454204
Validation loss: 2.5911966801291846

Epoch: 6| Step: 5
Training loss: 1.0233546216181462
Validation loss: 2.640242787826672

Epoch: 6| Step: 6
Training loss: 0.8327811000837725
Validation loss: 2.6244061494634967

Epoch: 6| Step: 7
Training loss: 0.5665536096867431
Validation loss: 2.568880047255872

Epoch: 6| Step: 8
Training loss: 1.5020887613749563
Validation loss: 2.589384794923385

Epoch: 6| Step: 9
Training loss: 0.8927400471333614
Validation loss: 2.629147930854343

Epoch: 6| Step: 10
Training loss: 0.6822297356916971
Validation loss: 2.6077372118590283

Epoch: 6| Step: 11
Training loss: 0.7284520507563691
Validation loss: 2.612155879170394

Epoch: 6| Step: 12
Training loss: 0.9472014415272492
Validation loss: 2.6105672354986105

Epoch: 6| Step: 13
Training loss: 1.310419522733664
Validation loss: 2.6454436448244167

Epoch: 416| Step: 0
Training loss: 1.072385020461679
Validation loss: 2.6519928944987816

Epoch: 6| Step: 1
Training loss: 1.1153175336361307
Validation loss: 2.6287206288557825

Epoch: 6| Step: 2
Training loss: 0.8911257557453061
Validation loss: 2.6117526584028816

Epoch: 6| Step: 3
Training loss: 0.8076216156733196
Validation loss: 2.629860110255146

Epoch: 6| Step: 4
Training loss: 0.8396481663272453
Validation loss: 2.6117323774369647

Epoch: 6| Step: 5
Training loss: 0.8747028118618229
Validation loss: 2.651267356234221

Epoch: 6| Step: 6
Training loss: 1.1815335816378492
Validation loss: 2.673109167356996

Epoch: 6| Step: 7
Training loss: 0.7720322607049617
Validation loss: 2.626902571975243

Epoch: 6| Step: 8
Training loss: 1.229798003954841
Validation loss: 2.6567202432304393

Epoch: 6| Step: 9
Training loss: 0.993041564528661
Validation loss: 2.693029186580263

Epoch: 6| Step: 10
Training loss: 1.0595555176998495
Validation loss: 2.7232472577805114

Epoch: 6| Step: 11
Training loss: 1.4485177455100842
Validation loss: 2.6562072376474215

Epoch: 6| Step: 12
Training loss: 0.6399416651813292
Validation loss: 2.68909284421981

Epoch: 6| Step: 13
Training loss: 0.5577235613104717
Validation loss: 2.725771515088033

Epoch: 417| Step: 0
Training loss: 0.6889945388115207
Validation loss: 2.690611922778384

Epoch: 6| Step: 1
Training loss: 1.1445720261740984
Validation loss: 2.6477401700588197

Epoch: 6| Step: 2
Training loss: 0.8002091015295029
Validation loss: 2.663623031509266

Epoch: 6| Step: 3
Training loss: 0.8779524311179092
Validation loss: 2.6665004638694363

Epoch: 6| Step: 4
Training loss: 0.7086496114529655
Validation loss: 2.68330535005309

Epoch: 6| Step: 5
Training loss: 0.9975738897658671
Validation loss: 2.6881079614497376

Epoch: 6| Step: 6
Training loss: 1.0251420364592272
Validation loss: 2.713549598687136

Epoch: 6| Step: 7
Training loss: 1.0792937646987395
Validation loss: 2.661594250537299

Epoch: 6| Step: 8
Training loss: 0.6503686758009208
Validation loss: 2.6663759987090527

Epoch: 6| Step: 9
Training loss: 0.7953867759570243
Validation loss: 2.611761589280914

Epoch: 6| Step: 10
Training loss: 0.9656507692324393
Validation loss: 2.6515350532197695

Epoch: 6| Step: 11
Training loss: 1.1847902802902561
Validation loss: 2.65382850824328

Epoch: 6| Step: 12
Training loss: 1.1511436808446935
Validation loss: 2.644862384809747

Epoch: 6| Step: 13
Training loss: 1.099107644783889
Validation loss: 2.638706706824482

Epoch: 418| Step: 0
Training loss: 1.1080907453394426
Validation loss: 2.672632730873578

Epoch: 6| Step: 1
Training loss: 0.9416205451158083
Validation loss: 2.6080864258275214

Epoch: 6| Step: 2
Training loss: 0.7439866595046406
Validation loss: 2.6048635593006066

Epoch: 6| Step: 3
Training loss: 1.2034480664372063
Validation loss: 2.6332250436012914

Epoch: 6| Step: 4
Training loss: 1.0520730285643465
Validation loss: 2.6601658100660326

Epoch: 6| Step: 5
Training loss: 0.8661136336008134
Validation loss: 2.609465150170515

Epoch: 6| Step: 6
Training loss: 1.17616427953441
Validation loss: 2.5991700773552076

Epoch: 6| Step: 7
Training loss: 0.8285621353036965
Validation loss: 2.6693335152066093

Epoch: 6| Step: 8
Training loss: 0.7983969198466612
Validation loss: 2.6828084849003746

Epoch: 6| Step: 9
Training loss: 0.6204460413477351
Validation loss: 2.6833740470198495

Epoch: 6| Step: 10
Training loss: 0.719731738461396
Validation loss: 2.617557237613229

Epoch: 6| Step: 11
Training loss: 1.1638347223666805
Validation loss: 2.6488980293285125

Epoch: 6| Step: 12
Training loss: 0.8419660853988075
Validation loss: 2.6148255427258236

Epoch: 6| Step: 13
Training loss: 1.2521448806809763
Validation loss: 2.641681708003242

Epoch: 419| Step: 0
Training loss: 0.6902423696265445
Validation loss: 2.6104236102386054

Epoch: 6| Step: 1
Training loss: 1.0870336036716963
Validation loss: 2.5782192174476455

Epoch: 6| Step: 2
Training loss: 0.9582282851874093
Validation loss: 2.603307495803034

Epoch: 6| Step: 3
Training loss: 0.7550374374833975
Validation loss: 2.629563240535033

Epoch: 6| Step: 4
Training loss: 0.9789304786600326
Validation loss: 2.6658221611280934

Epoch: 6| Step: 5
Training loss: 0.6059151757206693
Validation loss: 2.666644876112917

Epoch: 6| Step: 6
Training loss: 1.2357618532625212
Validation loss: 2.5809968000587

Epoch: 6| Step: 7
Training loss: 0.9863823904085232
Validation loss: 2.6186588839002876

Epoch: 6| Step: 8
Training loss: 1.243961243445837
Validation loss: 2.6086680659618504

Epoch: 6| Step: 9
Training loss: 1.0566411890955634
Validation loss: 2.632773915054315

Epoch: 6| Step: 10
Training loss: 0.854418209688304
Validation loss: 2.627006263620891

Epoch: 6| Step: 11
Training loss: 0.738145200112193
Validation loss: 2.6167927306680014

Epoch: 6| Step: 12
Training loss: 0.8652716428424588
Validation loss: 2.611635169630688

Epoch: 6| Step: 13
Training loss: 1.1636502860974407
Validation loss: 2.561276849494579

Epoch: 420| Step: 0
Training loss: 0.8491065631169384
Validation loss: 2.580330516051135

Epoch: 6| Step: 1
Training loss: 0.8548424226432958
Validation loss: 2.621914200305966

Epoch: 6| Step: 2
Training loss: 0.848904161343602
Validation loss: 2.658955531316214

Epoch: 6| Step: 3
Training loss: 0.8048986509746175
Validation loss: 2.627125984186507

Epoch: 6| Step: 4
Training loss: 0.8677836594203865
Validation loss: 2.5926968224958205

Epoch: 6| Step: 5
Training loss: 0.9352763507560093
Validation loss: 2.6442721759781964

Epoch: 6| Step: 6
Training loss: 1.114474008968199
Validation loss: 2.678356362746083

Epoch: 6| Step: 7
Training loss: 0.8749244521088024
Validation loss: 2.6577205551602847

Epoch: 6| Step: 8
Training loss: 1.1237155681592537
Validation loss: 2.6500353348973342

Epoch: 6| Step: 9
Training loss: 1.0210844756028459
Validation loss: 2.677108398399324

Epoch: 6| Step: 10
Training loss: 1.2215298957991887
Validation loss: 2.682845483783398

Epoch: 6| Step: 11
Training loss: 0.8195363687331765
Validation loss: 2.6669278737129614

Epoch: 6| Step: 12
Training loss: 0.9049497023457352
Validation loss: 2.657036758293014

Epoch: 6| Step: 13
Training loss: 0.6646514524828078
Validation loss: 2.6176774055140535

Epoch: 421| Step: 0
Training loss: 0.9015644886649428
Validation loss: 2.6734069908685756

Epoch: 6| Step: 1
Training loss: 1.0390826918855744
Validation loss: 2.701488006547288

Epoch: 6| Step: 2
Training loss: 1.1416631703195612
Validation loss: 2.667967565935579

Epoch: 6| Step: 3
Training loss: 0.9818569553691272
Validation loss: 2.651820420036101

Epoch: 6| Step: 4
Training loss: 0.6405569366025893
Validation loss: 2.6353030475555648

Epoch: 6| Step: 5
Training loss: 1.0218845845277533
Validation loss: 2.6504944172164553

Epoch: 6| Step: 6
Training loss: 0.6489096611552387
Validation loss: 2.6555021392587634

Epoch: 6| Step: 7
Training loss: 0.9197950012446117
Validation loss: 2.6730457365925613

Epoch: 6| Step: 8
Training loss: 1.1628938479470161
Validation loss: 2.7052873404306297

Epoch: 6| Step: 9
Training loss: 0.9106115749419417
Validation loss: 2.6577958339891508

Epoch: 6| Step: 10
Training loss: 1.1700118958447183
Validation loss: 2.6427452709326613

Epoch: 6| Step: 11
Training loss: 1.100437807609241
Validation loss: 2.571466845682937

Epoch: 6| Step: 12
Training loss: 0.7876635321106641
Validation loss: 2.6339915849169393

Epoch: 6| Step: 13
Training loss: 0.7675855019872528
Validation loss: 2.668374428687774

Epoch: 422| Step: 0
Training loss: 0.5821803881159113
Validation loss: 2.631764022986436

Epoch: 6| Step: 1
Training loss: 0.8056045787700099
Validation loss: 2.642123066398304

Epoch: 6| Step: 2
Training loss: 1.0948253794571996
Validation loss: 2.6622355770088526

Epoch: 6| Step: 3
Training loss: 0.6299269549848503
Validation loss: 2.6237357667728043

Epoch: 6| Step: 4
Training loss: 0.9124773088011536
Validation loss: 2.6398545896336394

Epoch: 6| Step: 5
Training loss: 1.3666604034156256
Validation loss: 2.701766214656641

Epoch: 6| Step: 6
Training loss: 1.0211324577904424
Validation loss: 2.704887124489983

Epoch: 6| Step: 7
Training loss: 0.7928887688651419
Validation loss: 2.6613156653061756

Epoch: 6| Step: 8
Training loss: 0.8315021103896968
Validation loss: 2.7291731992065835

Epoch: 6| Step: 9
Training loss: 1.0114844798445048
Validation loss: 2.6331174694587114

Epoch: 6| Step: 10
Training loss: 0.746678188361385
Validation loss: 2.6148415978731236

Epoch: 6| Step: 11
Training loss: 0.8791491363609666
Validation loss: 2.653015965414291

Epoch: 6| Step: 12
Training loss: 1.0005514889173832
Validation loss: 2.6605610961862567

Epoch: 6| Step: 13
Training loss: 1.0841313992705863
Validation loss: 2.6868513196795085

Epoch: 423| Step: 0
Training loss: 1.0137059788488747
Validation loss: 2.6352012430634932

Epoch: 6| Step: 1
Training loss: 1.0263377438576728
Validation loss: 2.670900118662824

Epoch: 6| Step: 2
Training loss: 0.78487565829533
Validation loss: 2.6449542249673907

Epoch: 6| Step: 3
Training loss: 0.8678030286745321
Validation loss: 2.650883118410688

Epoch: 6| Step: 4
Training loss: 1.1159561413757182
Validation loss: 2.6801431489073204

Epoch: 6| Step: 5
Training loss: 1.0763405669382657
Validation loss: 2.639862492188018

Epoch: 6| Step: 6
Training loss: 1.0262399988465387
Validation loss: 2.6995334616594584

Epoch: 6| Step: 7
Training loss: 0.6911818576633841
Validation loss: 2.63356508390098

Epoch: 6| Step: 8
Training loss: 0.6816420240852404
Validation loss: 2.6877918084985506

Epoch: 6| Step: 9
Training loss: 0.7548551764123813
Validation loss: 2.6874187664204485

Epoch: 6| Step: 10
Training loss: 0.8361513808963675
Validation loss: 2.6608447483015816

Epoch: 6| Step: 11
Training loss: 0.761065432781976
Validation loss: 2.672443597089551

Epoch: 6| Step: 12
Training loss: 1.1314231508212542
Validation loss: 2.6216492308271064

Epoch: 6| Step: 13
Training loss: 0.9984676422201824
Validation loss: 2.651057917177248

Epoch: 424| Step: 0
Training loss: 1.0110893501017406
Validation loss: 2.7008809015459065

Epoch: 6| Step: 1
Training loss: 1.2119546863469868
Validation loss: 2.639818019314428

Epoch: 6| Step: 2
Training loss: 0.8569654496838857
Validation loss: 2.631498331416241

Epoch: 6| Step: 3
Training loss: 0.9884213434973917
Validation loss: 2.6343597484070203

Epoch: 6| Step: 4
Training loss: 0.7252470845082016
Validation loss: 2.668950248013011

Epoch: 6| Step: 5
Training loss: 0.5836554273826364
Validation loss: 2.643511652141125

Epoch: 6| Step: 6
Training loss: 1.1443620367894123
Validation loss: 2.6820044255695437

Epoch: 6| Step: 7
Training loss: 0.9695131925734872
Validation loss: 2.673156193154391

Epoch: 6| Step: 8
Training loss: 0.9499187635522486
Validation loss: 2.6730850335184417

Epoch: 6| Step: 9
Training loss: 0.9182079571665192
Validation loss: 2.6587259608540386

Epoch: 6| Step: 10
Training loss: 0.49231571465140445
Validation loss: 2.596177202556203

Epoch: 6| Step: 11
Training loss: 0.588607984086682
Validation loss: 2.639565881813446

Epoch: 6| Step: 12
Training loss: 0.9039615149323674
Validation loss: 2.6146272957032717

Epoch: 6| Step: 13
Training loss: 0.9414495244507113
Validation loss: 2.6408566254824155

Epoch: 425| Step: 0
Training loss: 0.7644979784422967
Validation loss: 2.6524626115805905

Epoch: 6| Step: 1
Training loss: 0.8760651168375937
Validation loss: 2.6393009906918845

Epoch: 6| Step: 2
Training loss: 0.7976347723300808
Validation loss: 2.6471259546493897

Epoch: 6| Step: 3
Training loss: 0.4336265689011027
Validation loss: 2.632628739129275

Epoch: 6| Step: 4
Training loss: 0.8071804134044526
Validation loss: 2.6091478443065865

Epoch: 6| Step: 5
Training loss: 0.7669655877093885
Validation loss: 2.6202460489659716

Epoch: 6| Step: 6
Training loss: 1.1270785732956154
Validation loss: 2.6458491427532462

Epoch: 6| Step: 7
Training loss: 0.9553298774414042
Validation loss: 2.632063701637547

Epoch: 6| Step: 8
Training loss: 0.6544577785042799
Validation loss: 2.5980272988932733

Epoch: 6| Step: 9
Training loss: 1.3624460892117165
Validation loss: 2.627402492883222

Epoch: 6| Step: 10
Training loss: 1.351763054405293
Validation loss: 2.641671073219964

Epoch: 6| Step: 11
Training loss: 0.8888419523032857
Validation loss: 2.6484224062089097

Epoch: 6| Step: 12
Training loss: 0.9614686195977757
Validation loss: 2.688873413223556

Epoch: 6| Step: 13
Training loss: 0.7156215251188578
Validation loss: 2.6580331688708907

Epoch: 426| Step: 0
Training loss: 1.1034107799854607
Validation loss: 2.626681999954097

Epoch: 6| Step: 1
Training loss: 0.8800033842368509
Validation loss: 2.6358916768039

Epoch: 6| Step: 2
Training loss: 0.8445793596904103
Validation loss: 2.6644218403839535

Epoch: 6| Step: 3
Training loss: 0.6444674604812061
Validation loss: 2.651890007538188

Epoch: 6| Step: 4
Training loss: 0.7795201414367746
Validation loss: 2.6365161808519835

Epoch: 6| Step: 5
Training loss: 1.1687064504414557
Validation loss: 2.6518985035616165

Epoch: 6| Step: 6
Training loss: 0.9785750746037537
Validation loss: 2.605297039117733

Epoch: 6| Step: 7
Training loss: 1.0055914364578347
Validation loss: 2.6694833115778116

Epoch: 6| Step: 8
Training loss: 0.763156609720197
Validation loss: 2.6735376906669464

Epoch: 6| Step: 9
Training loss: 0.7114318554160091
Validation loss: 2.64622500416671

Epoch: 6| Step: 10
Training loss: 0.6510133253922356
Validation loss: 2.638403000910845

Epoch: 6| Step: 11
Training loss: 1.1297530328043448
Validation loss: 2.709899850334393

Epoch: 6| Step: 12
Training loss: 1.1212352703236939
Validation loss: 2.6614103866608008

Epoch: 6| Step: 13
Training loss: 0.9493185548156654
Validation loss: 2.6947539999420456

Epoch: 427| Step: 0
Training loss: 1.0057845893390778
Validation loss: 2.658371142015877

Epoch: 6| Step: 1
Training loss: 0.8914631697513203
Validation loss: 2.681785599951961

Epoch: 6| Step: 2
Training loss: 1.3762037036949584
Validation loss: 2.6995081435884605

Epoch: 6| Step: 3
Training loss: 1.055512225923699
Validation loss: 2.637373041047212

Epoch: 6| Step: 4
Training loss: 1.0973948102866922
Validation loss: 2.6805800572419174

Epoch: 6| Step: 5
Training loss: 1.1148052826455463
Validation loss: 2.6373931851083636

Epoch: 6| Step: 6
Training loss: 0.8197259168097439
Validation loss: 2.6341654605575098

Epoch: 6| Step: 7
Training loss: 0.7650853805018775
Validation loss: 2.6647787464377277

Epoch: 6| Step: 8
Training loss: 1.015337037564603
Validation loss: 2.6441464841521034

Epoch: 6| Step: 9
Training loss: 0.6649910661627902
Validation loss: 2.674831301577751

Epoch: 6| Step: 10
Training loss: 0.847322530141353
Validation loss: 2.7179254180269834

Epoch: 6| Step: 11
Training loss: 1.196698451155786
Validation loss: 2.684032953961113

Epoch: 6| Step: 12
Training loss: 0.7735953892316962
Validation loss: 2.7461437439652223

Epoch: 6| Step: 13
Training loss: 0.9675193476159376
Validation loss: 2.7751111778692965

Epoch: 428| Step: 0
Training loss: 1.1265239989411808
Validation loss: 2.7314242181564654

Epoch: 6| Step: 1
Training loss: 1.0980847157105855
Validation loss: 2.6909963501426226

Epoch: 6| Step: 2
Training loss: 0.8769407887430098
Validation loss: 2.704051224742985

Epoch: 6| Step: 3
Training loss: 1.0278783067448025
Validation loss: 2.702497030827635

Epoch: 6| Step: 4
Training loss: 0.8528790227623781
Validation loss: 2.6515637141689323

Epoch: 6| Step: 5
Training loss: 0.9726974294746752
Validation loss: 2.709730167128517

Epoch: 6| Step: 6
Training loss: 0.6869873823398143
Validation loss: 2.7320888444492857

Epoch: 6| Step: 7
Training loss: 1.640096815554524
Validation loss: 2.738622175280889

Epoch: 6| Step: 8
Training loss: 0.9255702748113454
Validation loss: 2.7506054009557914

Epoch: 6| Step: 9
Training loss: 1.2576085274734834
Validation loss: 2.705768006051821

Epoch: 6| Step: 10
Training loss: 0.9312407397123409
Validation loss: 2.6919523957499107

Epoch: 6| Step: 11
Training loss: 0.9133550074075397
Validation loss: 2.74561056314921

Epoch: 6| Step: 12
Training loss: 0.710266383394677
Validation loss: 2.6591805093712386

Epoch: 6| Step: 13
Training loss: 0.7758171772392914
Validation loss: 2.7022474771926004

Epoch: 429| Step: 0
Training loss: 1.313515043581289
Validation loss: 2.6715918943095707

Epoch: 6| Step: 1
Training loss: 1.0550032531543492
Validation loss: 2.6936554168594022

Epoch: 6| Step: 2
Training loss: 1.1810986497587896
Validation loss: 2.6769023096848548

Epoch: 6| Step: 3
Training loss: 0.946774510757591
Validation loss: 2.667550884120212

Epoch: 6| Step: 4
Training loss: 0.6647980599218997
Validation loss: 2.646006485887586

Epoch: 6| Step: 5
Training loss: 0.7201969674688266
Validation loss: 2.643175883139756

Epoch: 6| Step: 6
Training loss: 0.9107875353743049
Validation loss: 2.6424611947522494

Epoch: 6| Step: 7
Training loss: 0.9779009992148704
Validation loss: 2.656576869524717

Epoch: 6| Step: 8
Training loss: 1.0346870942663688
Validation loss: 2.687716305330125

Epoch: 6| Step: 9
Training loss: 0.9776189963845732
Validation loss: 2.6791105548288447

Epoch: 6| Step: 10
Training loss: 1.0944533130417673
Validation loss: 2.6497781936619305

Epoch: 6| Step: 11
Training loss: 0.622158816762304
Validation loss: 2.598304411445971

Epoch: 6| Step: 12
Training loss: 1.3089159213079138
Validation loss: 2.6236980327798647

Epoch: 6| Step: 13
Training loss: 1.1242224867535295
Validation loss: 2.647037102105272

Epoch: 430| Step: 0
Training loss: 0.7820310884184009
Validation loss: 2.6928082908115525

Epoch: 6| Step: 1
Training loss: 0.8572768868662898
Validation loss: 2.7017016770457296

Epoch: 6| Step: 2
Training loss: 1.1838013117624895
Validation loss: 2.7364288899658034

Epoch: 6| Step: 3
Training loss: 1.1493253843832139
Validation loss: 2.6889272049555015

Epoch: 6| Step: 4
Training loss: 1.1278673823599419
Validation loss: 2.7126511902285237

Epoch: 6| Step: 5
Training loss: 0.8929071800652443
Validation loss: 2.6520573756847243

Epoch: 6| Step: 6
Training loss: 0.9219916318401972
Validation loss: 2.6984597227841443

Epoch: 6| Step: 7
Training loss: 1.1563728885814857
Validation loss: 2.667141072473112

Epoch: 6| Step: 8
Training loss: 0.9293824023815855
Validation loss: 2.6522355354867044

Epoch: 6| Step: 9
Training loss: 1.2055505849635193
Validation loss: 2.66244427856976

Epoch: 6| Step: 10
Training loss: 1.110605014670585
Validation loss: 2.657077181803347

Epoch: 6| Step: 11
Training loss: 0.741296494362216
Validation loss: 2.6463801101847366

Epoch: 6| Step: 12
Training loss: 0.8968277151157129
Validation loss: 2.6272460320410356

Epoch: 6| Step: 13
Training loss: 1.469629065235846
Validation loss: 2.6897346314164525

Epoch: 431| Step: 0
Training loss: 0.7798559721606328
Validation loss: 2.65496138188401

Epoch: 6| Step: 1
Training loss: 1.1066036262615502
Validation loss: 2.700460072161539

Epoch: 6| Step: 2
Training loss: 0.9779567683519456
Validation loss: 2.657956506414897

Epoch: 6| Step: 3
Training loss: 0.744663605428714
Validation loss: 2.5973945810944636

Epoch: 6| Step: 4
Training loss: 0.6335906201531073
Validation loss: 2.666790733332193

Epoch: 6| Step: 5
Training loss: 0.7285995230547265
Validation loss: 2.7135803210140597

Epoch: 6| Step: 6
Training loss: 0.8455344509863987
Validation loss: 2.633903367981853

Epoch: 6| Step: 7
Training loss: 0.9045946854333412
Validation loss: 2.603400572943533

Epoch: 6| Step: 8
Training loss: 0.7534042821940181
Validation loss: 2.6133658752272377

Epoch: 6| Step: 9
Training loss: 0.9148235250398845
Validation loss: 2.5793638085209625

Epoch: 6| Step: 10
Training loss: 0.9410101979480413
Validation loss: 2.5918061199468925

Epoch: 6| Step: 11
Training loss: 0.7433145899469421
Validation loss: 2.6183451355494736

Epoch: 6| Step: 12
Training loss: 0.9179983580663953
Validation loss: 2.631221135601072

Epoch: 6| Step: 13
Training loss: 1.111886740542649
Validation loss: 2.6680635181312375

Epoch: 432| Step: 0
Training loss: 0.7999036492500182
Validation loss: 2.626786199510815

Epoch: 6| Step: 1
Training loss: 0.7898883840927439
Validation loss: 2.6456784681118095

Epoch: 6| Step: 2
Training loss: 0.7157124311851686
Validation loss: 2.6675830448693847

Epoch: 6| Step: 3
Training loss: 0.8530915208332768
Validation loss: 2.6781245679346815

Epoch: 6| Step: 4
Training loss: 0.6277210132100207
Validation loss: 2.614326119910976

Epoch: 6| Step: 5
Training loss: 0.7016840687116838
Validation loss: 2.67656629049549

Epoch: 6| Step: 6
Training loss: 0.9237617323650443
Validation loss: 2.6743933872233576

Epoch: 6| Step: 7
Training loss: 0.906043851359606
Validation loss: 2.660329132512035

Epoch: 6| Step: 8
Training loss: 1.1063615947407344
Validation loss: 2.666444744372832

Epoch: 6| Step: 9
Training loss: 0.7004236676261285
Validation loss: 2.6352509809638818

Epoch: 6| Step: 10
Training loss: 0.7336022389726157
Validation loss: 2.657076807929821

Epoch: 6| Step: 11
Training loss: 1.0324601673266087
Validation loss: 2.635190951566249

Epoch: 6| Step: 12
Training loss: 1.101624940225298
Validation loss: 2.6148047992991574

Epoch: 6| Step: 13
Training loss: 0.9707742891379824
Validation loss: 2.681527769080699

Epoch: 433| Step: 0
Training loss: 0.8598205798418954
Validation loss: 2.657189162034471

Epoch: 6| Step: 1
Training loss: 1.1027153421584395
Validation loss: 2.6859620151432897

Epoch: 6| Step: 2
Training loss: 1.3592688858883981
Validation loss: 2.696499077745201

Epoch: 6| Step: 3
Training loss: 0.7980727375935425
Validation loss: 2.676208818342429

Epoch: 6| Step: 4
Training loss: 1.0585638513600921
Validation loss: 2.6302785026834075

Epoch: 6| Step: 5
Training loss: 0.7103168167540271
Validation loss: 2.6227510294427554

Epoch: 6| Step: 6
Training loss: 0.5957838660382078
Validation loss: 2.6412183708130135

Epoch: 6| Step: 7
Training loss: 0.9835681636230549
Validation loss: 2.629028997630625

Epoch: 6| Step: 8
Training loss: 0.8208413009127767
Validation loss: 2.622690100324045

Epoch: 6| Step: 9
Training loss: 0.7276705015104454
Validation loss: 2.643537296068385

Epoch: 6| Step: 10
Training loss: 0.8211709390031926
Validation loss: 2.640533445678464

Epoch: 6| Step: 11
Training loss: 0.6485039090999764
Validation loss: 2.5953245401151013

Epoch: 6| Step: 12
Training loss: 0.6387354267943808
Validation loss: 2.611703180481039

Epoch: 6| Step: 13
Training loss: 0.624789202427581
Validation loss: 2.626371396306465

Epoch: 434| Step: 0
Training loss: 0.8426483167504407
Validation loss: 2.626532493297363

Epoch: 6| Step: 1
Training loss: 0.7118113670008508
Validation loss: 2.6275082971772767

Epoch: 6| Step: 2
Training loss: 0.8065995767046032
Validation loss: 2.6579472822535157

Epoch: 6| Step: 3
Training loss: 0.9210366461915492
Validation loss: 2.648002783882871

Epoch: 6| Step: 4
Training loss: 0.8972796069107474
Validation loss: 2.645572481788389

Epoch: 6| Step: 5
Training loss: 1.0948417664209544
Validation loss: 2.612747038944479

Epoch: 6| Step: 6
Training loss: 0.9218471328920016
Validation loss: 2.628144197700046

Epoch: 6| Step: 7
Training loss: 0.5498771551965378
Validation loss: 2.6265655723310237

Epoch: 6| Step: 8
Training loss: 0.7901885807120782
Validation loss: 2.6600274845127907

Epoch: 6| Step: 9
Training loss: 0.8164111415588732
Validation loss: 2.6470834427043983

Epoch: 6| Step: 10
Training loss: 0.8500044682329206
Validation loss: 2.6733251283841573

Epoch: 6| Step: 11
Training loss: 0.8451807113269886
Validation loss: 2.7196414260734065

Epoch: 6| Step: 12
Training loss: 0.922688012541373
Validation loss: 2.6797011127626633

Epoch: 6| Step: 13
Training loss: 0.7615584375948558
Validation loss: 2.713936296836561

Epoch: 435| Step: 0
Training loss: 0.8387135197285821
Validation loss: 2.6755915739304212

Epoch: 6| Step: 1
Training loss: 0.7004356876137783
Validation loss: 2.717402507924743

Epoch: 6| Step: 2
Training loss: 1.1103568232134062
Validation loss: 2.6604797420527424

Epoch: 6| Step: 3
Training loss: 0.9296064581930666
Validation loss: 2.7118648881292184

Epoch: 6| Step: 4
Training loss: 0.8591596160091237
Validation loss: 2.7579794626962797

Epoch: 6| Step: 5
Training loss: 0.7030623302081399
Validation loss: 2.67649528090913

Epoch: 6| Step: 6
Training loss: 0.8051695629687113
Validation loss: 2.7135464649316656

Epoch: 6| Step: 7
Training loss: 0.8513342525222802
Validation loss: 2.7131619373833886

Epoch: 6| Step: 8
Training loss: 0.8443875200203189
Validation loss: 2.669402050731837

Epoch: 6| Step: 9
Training loss: 0.7198354568815193
Validation loss: 2.6460273901794507

Epoch: 6| Step: 10
Training loss: 0.6834352363998959
Validation loss: 2.7376059489889513

Epoch: 6| Step: 11
Training loss: 0.7271519392668502
Validation loss: 2.6579207906428404

Epoch: 6| Step: 12
Training loss: 0.9560175606958249
Validation loss: 2.6550576020701446

Epoch: 6| Step: 13
Training loss: 0.8435029975191141
Validation loss: 2.7031278444837477

Epoch: 436| Step: 0
Training loss: 0.9852135432113595
Validation loss: 2.6934630604777867

Epoch: 6| Step: 1
Training loss: 0.8099251074370903
Validation loss: 2.6567038802775693

Epoch: 6| Step: 2
Training loss: 0.7988490542629031
Validation loss: 2.692347922391361

Epoch: 6| Step: 3
Training loss: 0.8171652956803324
Validation loss: 2.67756344736378

Epoch: 6| Step: 4
Training loss: 0.8850158607009944
Validation loss: 2.676022899696015

Epoch: 6| Step: 5
Training loss: 0.8294466376681955
Validation loss: 2.6951176079948476

Epoch: 6| Step: 6
Training loss: 1.0563528405861329
Validation loss: 2.666409678791806

Epoch: 6| Step: 7
Training loss: 1.0895680724923646
Validation loss: 2.6787842617552515

Epoch: 6| Step: 8
Training loss: 0.7817420554323126
Validation loss: 2.706408804799844

Epoch: 6| Step: 9
Training loss: 0.9980838417926109
Validation loss: 2.7323585559269814

Epoch: 6| Step: 10
Training loss: 0.5883276192880216
Validation loss: 2.7376870287404995

Epoch: 6| Step: 11
Training loss: 0.865061723348124
Validation loss: 2.7173918623992788

Epoch: 6| Step: 12
Training loss: 0.6561446786561375
Validation loss: 2.6669670521908815

Epoch: 6| Step: 13
Training loss: 0.6341493402521109
Validation loss: 2.6903819445131516

Epoch: 437| Step: 0
Training loss: 1.0882632372502596
Validation loss: 2.739462357860922

Epoch: 6| Step: 1
Training loss: 0.9985999200612699
Validation loss: 2.7396205179183295

Epoch: 6| Step: 2
Training loss: 0.6607043457019973
Validation loss: 2.729350023201231

Epoch: 6| Step: 3
Training loss: 1.0332773683118281
Validation loss: 2.6855708524616158

Epoch: 6| Step: 4
Training loss: 0.8601371160140875
Validation loss: 2.670263016065352

Epoch: 6| Step: 5
Training loss: 0.9800472797452382
Validation loss: 2.7340225137854706

Epoch: 6| Step: 6
Training loss: 0.6030407367408231
Validation loss: 2.6905649066967956

Epoch: 6| Step: 7
Training loss: 0.8516394904093844
Validation loss: 2.656124650578088

Epoch: 6| Step: 8
Training loss: 0.7310918506549541
Validation loss: 2.702239271814778

Epoch: 6| Step: 9
Training loss: 1.0108886612617283
Validation loss: 2.6847312326724646

Epoch: 6| Step: 10
Training loss: 1.0627489359331423
Validation loss: 2.6793292874766594

Epoch: 6| Step: 11
Training loss: 0.8773695333060254
Validation loss: 2.6886228684867635

Epoch: 6| Step: 12
Training loss: 0.6054268607138757
Validation loss: 2.6510784294012635

Epoch: 6| Step: 13
Training loss: 0.7702352334166801
Validation loss: 2.669413349099732

Epoch: 438| Step: 0
Training loss: 0.6577990958689794
Validation loss: 2.688782156931246

Epoch: 6| Step: 1
Training loss: 0.9206008187489471
Validation loss: 2.6559697321216538

Epoch: 6| Step: 2
Training loss: 0.9515416485987066
Validation loss: 2.6076914368160504

Epoch: 6| Step: 3
Training loss: 0.7450251891210973
Validation loss: 2.692034547918051

Epoch: 6| Step: 4
Training loss: 0.7483904973125614
Validation loss: 2.6832816855473323

Epoch: 6| Step: 5
Training loss: 0.8907392328185972
Validation loss: 2.688255839554321

Epoch: 6| Step: 6
Training loss: 0.5565311792761208
Validation loss: 2.686395344187413

Epoch: 6| Step: 7
Training loss: 0.9242686215486047
Validation loss: 2.6740118186088435

Epoch: 6| Step: 8
Training loss: 0.7979895333533465
Validation loss: 2.68954683693241

Epoch: 6| Step: 9
Training loss: 0.8722750262220609
Validation loss: 2.659774117977488

Epoch: 6| Step: 10
Training loss: 0.7221699083365392
Validation loss: 2.678862538337544

Epoch: 6| Step: 11
Training loss: 0.8884865032989201
Validation loss: 2.715004954137433

Epoch: 6| Step: 12
Training loss: 0.8906653880280988
Validation loss: 2.701349825823159

Epoch: 6| Step: 13
Training loss: 1.0019005358244413
Validation loss: 2.6524781917307094

Epoch: 439| Step: 0
Training loss: 0.761972746927401
Validation loss: 2.684367342765169

Epoch: 6| Step: 1
Training loss: 0.5905690565307466
Validation loss: 2.6379921181343877

Epoch: 6| Step: 2
Training loss: 0.7661740027944931
Validation loss: 2.643315331067826

Epoch: 6| Step: 3
Training loss: 0.8094817367340773
Validation loss: 2.6730645340782107

Epoch: 6| Step: 4
Training loss: 0.7631098637809821
Validation loss: 2.651772888504872

Epoch: 6| Step: 5
Training loss: 1.0117568667975039
Validation loss: 2.6646409585988495

Epoch: 6| Step: 6
Training loss: 0.7539163302207217
Validation loss: 2.617615667591097

Epoch: 6| Step: 7
Training loss: 1.0262705487924944
Validation loss: 2.716287264825033

Epoch: 6| Step: 8
Training loss: 0.876675840179931
Validation loss: 2.6930341591088056

Epoch: 6| Step: 9
Training loss: 0.925559262730289
Validation loss: 2.711344473098458

Epoch: 6| Step: 10
Training loss: 0.6617211297903313
Validation loss: 2.7131902475690466

Epoch: 6| Step: 11
Training loss: 0.6372169932321137
Validation loss: 2.6611968183840267

Epoch: 6| Step: 12
Training loss: 0.9627645228144188
Validation loss: 2.659282090700444

Epoch: 6| Step: 13
Training loss: 0.9645515648132954
Validation loss: 2.702737115214543

Epoch: 440| Step: 0
Training loss: 0.6819169541904192
Validation loss: 2.703519391815717

Epoch: 6| Step: 1
Training loss: 0.9162293532518563
Validation loss: 2.72152035341134

Epoch: 6| Step: 2
Training loss: 0.7151860319224349
Validation loss: 2.6297314781278676

Epoch: 6| Step: 3
Training loss: 1.219317866345295
Validation loss: 2.6811524030326135

Epoch: 6| Step: 4
Training loss: 0.523288050710158
Validation loss: 2.687819217974638

Epoch: 6| Step: 5
Training loss: 0.918018875376806
Validation loss: 2.662881912158248

Epoch: 6| Step: 6
Training loss: 0.6685551305976133
Validation loss: 2.71330065886423

Epoch: 6| Step: 7
Training loss: 0.8261176918965983
Validation loss: 2.7132120987881607

Epoch: 6| Step: 8
Training loss: 0.7890431618917466
Validation loss: 2.6987238428881026

Epoch: 6| Step: 9
Training loss: 1.040351641609883
Validation loss: 2.7247592242198784

Epoch: 6| Step: 10
Training loss: 1.0403082700662283
Validation loss: 2.6755703511159923

Epoch: 6| Step: 11
Training loss: 0.7223157750776916
Validation loss: 2.720153738520253

Epoch: 6| Step: 12
Training loss: 0.6998704398691887
Validation loss: 2.654330289179856

Epoch: 6| Step: 13
Training loss: 0.8999916235216068
Validation loss: 2.670154575345366

Epoch: 441| Step: 0
Training loss: 1.0522194135429908
Validation loss: 2.6735881050298027

Epoch: 6| Step: 1
Training loss: 0.8077157086171844
Validation loss: 2.6857847462124864

Epoch: 6| Step: 2
Training loss: 0.9392949722627394
Validation loss: 2.7031127400202917

Epoch: 6| Step: 3
Training loss: 1.0023209935709902
Validation loss: 2.705100129883799

Epoch: 6| Step: 4
Training loss: 1.0137204432382652
Validation loss: 2.646144568292541

Epoch: 6| Step: 5
Training loss: 0.7760755459006206
Validation loss: 2.6827206808650685

Epoch: 6| Step: 6
Training loss: 0.6695500445760365
Validation loss: 2.6883170046687854

Epoch: 6| Step: 7
Training loss: 0.7706548166191699
Validation loss: 2.6633606524094815

Epoch: 6| Step: 8
Training loss: 1.146143796071236
Validation loss: 2.7155648204718603

Epoch: 6| Step: 9
Training loss: 0.7071596313595314
Validation loss: 2.696200768981172

Epoch: 6| Step: 10
Training loss: 1.1107747019017897
Validation loss: 2.7082640174407415

Epoch: 6| Step: 11
Training loss: 0.65660639576651
Validation loss: 2.6852708265439675

Epoch: 6| Step: 12
Training loss: 0.7979578626736641
Validation loss: 2.6749096566984494

Epoch: 6| Step: 13
Training loss: 0.7442014173771504
Validation loss: 2.628768562085687

Epoch: 442| Step: 0
Training loss: 0.6524280790541728
Validation loss: 2.607088225278146

Epoch: 6| Step: 1
Training loss: 0.6533802501058112
Validation loss: 2.6743022385972366

Epoch: 6| Step: 2
Training loss: 0.7215035808260243
Validation loss: 2.6669249310202465

Epoch: 6| Step: 3
Training loss: 0.7819198788235365
Validation loss: 2.6385906215442936

Epoch: 6| Step: 4
Training loss: 0.69031628401735
Validation loss: 2.6538448739518303

Epoch: 6| Step: 5
Training loss: 0.7938187651997053
Validation loss: 2.651123725105768

Epoch: 6| Step: 6
Training loss: 0.5362928252470552
Validation loss: 2.6648619376152483

Epoch: 6| Step: 7
Training loss: 0.42170507046313205
Validation loss: 2.6648015016226125

Epoch: 6| Step: 8
Training loss: 0.7810684756153962
Validation loss: 2.7246661072069225

Epoch: 6| Step: 9
Training loss: 1.1110446883586769
Validation loss: 2.681460047321623

Epoch: 6| Step: 10
Training loss: 0.8519400363425682
Validation loss: 2.697605915411983

Epoch: 6| Step: 11
Training loss: 0.9136579221367078
Validation loss: 2.6782292586470957

Epoch: 6| Step: 12
Training loss: 1.1746268958360295
Validation loss: 2.6748313238612664

Epoch: 6| Step: 13
Training loss: 1.0505325420119893
Validation loss: 2.653245655516935

Epoch: 443| Step: 0
Training loss: 0.7986361172580423
Validation loss: 2.6678661589215724

Epoch: 6| Step: 1
Training loss: 0.8475417661924832
Validation loss: 2.6956521230303494

Epoch: 6| Step: 2
Training loss: 0.6489436690345802
Validation loss: 2.6533276058579296

Epoch: 6| Step: 3
Training loss: 0.6987702407020836
Validation loss: 2.667017873842648

Epoch: 6| Step: 4
Training loss: 0.7075206685501341
Validation loss: 2.678198338516727

Epoch: 6| Step: 5
Training loss: 0.5833664498692643
Validation loss: 2.6779960506320823

Epoch: 6| Step: 6
Training loss: 0.7579330663040974
Validation loss: 2.667917484742261

Epoch: 6| Step: 7
Training loss: 0.8810783503134223
Validation loss: 2.7111591904403585

Epoch: 6| Step: 8
Training loss: 0.9313739898885047
Validation loss: 2.7339364562995128

Epoch: 6| Step: 9
Training loss: 1.1087512022095778
Validation loss: 2.7218694512376023

Epoch: 6| Step: 10
Training loss: 0.6088035300294716
Validation loss: 2.6880135008656447

Epoch: 6| Step: 11
Training loss: 0.6427851056616594
Validation loss: 2.7030743867990483

Epoch: 6| Step: 12
Training loss: 0.6170660696205571
Validation loss: 2.6739681440370817

Epoch: 6| Step: 13
Training loss: 1.0901720653128686
Validation loss: 2.7103077416275765

Epoch: 444| Step: 0
Training loss: 0.7487857446433346
Validation loss: 2.7166859914720316

Epoch: 6| Step: 1
Training loss: 0.37817181856964865
Validation loss: 2.731176769342739

Epoch: 6| Step: 2
Training loss: 0.7849492042046144
Validation loss: 2.7097328140422845

Epoch: 6| Step: 3
Training loss: 0.8715168904557036
Validation loss: 2.70479852399672

Epoch: 6| Step: 4
Training loss: 0.6333580961740339
Validation loss: 2.670668867009679

Epoch: 6| Step: 5
Training loss: 0.7677679627931002
Validation loss: 2.6978662454221243

Epoch: 6| Step: 6
Training loss: 0.5883187797500585
Validation loss: 2.6713711447550272

Epoch: 6| Step: 7
Training loss: 0.6981198503787576
Validation loss: 2.6915292771729136

Epoch: 6| Step: 8
Training loss: 0.6935420265857621
Validation loss: 2.671049745354722

Epoch: 6| Step: 9
Training loss: 0.5721548448429004
Validation loss: 2.6939769587306706

Epoch: 6| Step: 10
Training loss: 1.1469353433891918
Validation loss: 2.6866200950962456

Epoch: 6| Step: 11
Training loss: 0.7089032423608487
Validation loss: 2.6573446673515053

Epoch: 6| Step: 12
Training loss: 0.9430178701380256
Validation loss: 2.708397062481059

Epoch: 6| Step: 13
Training loss: 0.9482547275959401
Validation loss: 2.6824411048123964

Epoch: 445| Step: 0
Training loss: 0.8232963426545566
Validation loss: 2.6660509565944275

Epoch: 6| Step: 1
Training loss: 0.7774429641361102
Validation loss: 2.6816045726733724

Epoch: 6| Step: 2
Training loss: 0.7056864600028218
Validation loss: 2.650297713800532

Epoch: 6| Step: 3
Training loss: 0.7727937813175942
Validation loss: 2.6856782786270705

Epoch: 6| Step: 4
Training loss: 0.5274195863800956
Validation loss: 2.7076821693713278

Epoch: 6| Step: 5
Training loss: 1.1124815092800375
Validation loss: 2.696247517303564

Epoch: 6| Step: 6
Training loss: 0.7242739330283757
Validation loss: 2.6781363488116

Epoch: 6| Step: 7
Training loss: 0.5970519258003429
Validation loss: 2.7000431139765064

Epoch: 6| Step: 8
Training loss: 0.9475363433027663
Validation loss: 2.67570729397112

Epoch: 6| Step: 9
Training loss: 0.5322568552338146
Validation loss: 2.708533827378598

Epoch: 6| Step: 10
Training loss: 0.7212697517956418
Validation loss: 2.662804195476312

Epoch: 6| Step: 11
Training loss: 0.65910938029281
Validation loss: 2.7056229209172273

Epoch: 6| Step: 12
Training loss: 0.7781217123061742
Validation loss: 2.6972099075621188

Epoch: 6| Step: 13
Training loss: 0.9961941836718249
Validation loss: 2.6492830500237736

Epoch: 446| Step: 0
Training loss: 0.6658799824786944
Validation loss: 2.702060644269717

Epoch: 6| Step: 1
Training loss: 0.763573291395995
Validation loss: 2.668449809025946

Epoch: 6| Step: 2
Training loss: 0.7133440221969053
Validation loss: 2.6798682416012807

Epoch: 6| Step: 3
Training loss: 0.5814706547615154
Validation loss: 2.6620419503748667

Epoch: 6| Step: 4
Training loss: 0.8759920082729319
Validation loss: 2.687090406329176

Epoch: 6| Step: 5
Training loss: 0.6531025020247128
Validation loss: 2.6293181370198666

Epoch: 6| Step: 6
Training loss: 0.5809562022629192
Validation loss: 2.650811720632761

Epoch: 6| Step: 7
Training loss: 0.8433421526763102
Validation loss: 2.697085592535228

Epoch: 6| Step: 8
Training loss: 1.0105042108318736
Validation loss: 2.689300303756422

Epoch: 6| Step: 9
Training loss: 0.6365728386632574
Validation loss: 2.683739418988512

Epoch: 6| Step: 10
Training loss: 0.7252889977969591
Validation loss: 2.714842403420679

Epoch: 6| Step: 11
Training loss: 0.6840016918942234
Validation loss: 2.654657671998269

Epoch: 6| Step: 12
Training loss: 0.8617612826519262
Validation loss: 2.6546382726603444

Epoch: 6| Step: 13
Training loss: 0.9485940957920963
Validation loss: 2.6556679630253233

Epoch: 447| Step: 0
Training loss: 0.6856625233886496
Validation loss: 2.7276447119524065

Epoch: 6| Step: 1
Training loss: 0.9941953033219685
Validation loss: 2.712357280275601

Epoch: 6| Step: 2
Training loss: 0.7325794101413757
Validation loss: 2.6855681669373754

Epoch: 6| Step: 3
Training loss: 0.6948519263570281
Validation loss: 2.6815672306649883

Epoch: 6| Step: 4
Training loss: 0.6573825554697327
Validation loss: 2.6413446833857552

Epoch: 6| Step: 5
Training loss: 0.8589656201544744
Validation loss: 2.7151497208777515

Epoch: 6| Step: 6
Training loss: 0.993580388643542
Validation loss: 2.669355829637923

Epoch: 6| Step: 7
Training loss: 0.6591599072914769
Validation loss: 2.654854651074692

Epoch: 6| Step: 8
Training loss: 0.8174964160432328
Validation loss: 2.7412510909602936

Epoch: 6| Step: 9
Training loss: 1.0657809593648813
Validation loss: 2.667224525175306

Epoch: 6| Step: 10
Training loss: 0.8609764782620097
Validation loss: 2.73824246062097

Epoch: 6| Step: 11
Training loss: 0.5642351831933893
Validation loss: 2.6934621162911023

Epoch: 6| Step: 12
Training loss: 0.6398999833395673
Validation loss: 2.702556131293437

Epoch: 6| Step: 13
Training loss: 0.8408035471592749
Validation loss: 2.6668426833076975

Epoch: 448| Step: 0
Training loss: 1.076694922199465
Validation loss: 2.6374875151231754

Epoch: 6| Step: 1
Training loss: 0.5030805343028547
Validation loss: 2.6511142973078194

Epoch: 6| Step: 2
Training loss: 1.0810829165803948
Validation loss: 2.6908968520462198

Epoch: 6| Step: 3
Training loss: 0.45952616429684434
Validation loss: 2.726743777715109

Epoch: 6| Step: 4
Training loss: 0.7617002827288621
Validation loss: 2.6698706323617194

Epoch: 6| Step: 5
Training loss: 0.7436467331432308
Validation loss: 2.6745494671094003

Epoch: 6| Step: 6
Training loss: 0.8282207577601199
Validation loss: 2.684718992302926

Epoch: 6| Step: 7
Training loss: 0.5790078922056677
Validation loss: 2.736017180915896

Epoch: 6| Step: 8
Training loss: 0.709290745642824
Validation loss: 2.696298347078591

Epoch: 6| Step: 9
Training loss: 0.8099215381791246
Validation loss: 2.7721997861733625

Epoch: 6| Step: 10
Training loss: 0.6182442322341272
Validation loss: 2.7109520331880907

Epoch: 6| Step: 11
Training loss: 0.6726426684772927
Validation loss: 2.732665292196804

Epoch: 6| Step: 12
Training loss: 0.9926378624724862
Validation loss: 2.7134023888124252

Epoch: 6| Step: 13
Training loss: 0.6780678975546838
Validation loss: 2.70333568949975

Epoch: 449| Step: 0
Training loss: 0.8506931101643658
Validation loss: 2.7096559131781377

Epoch: 6| Step: 1
Training loss: 0.638586872755428
Validation loss: 2.693619938400446

Epoch: 6| Step: 2
Training loss: 0.7002984772980076
Validation loss: 2.657108736539396

Epoch: 6| Step: 3
Training loss: 0.6936456653392165
Validation loss: 2.6856671226630175

Epoch: 6| Step: 4
Training loss: 0.8027285833219443
Validation loss: 2.6603321198422156

Epoch: 6| Step: 5
Training loss: 0.628441656773277
Validation loss: 2.6810369328372987

Epoch: 6| Step: 6
Training loss: 0.7809793766512713
Validation loss: 2.690709895538433

Epoch: 6| Step: 7
Training loss: 0.7329899327053877
Validation loss: 2.712153767464145

Epoch: 6| Step: 8
Training loss: 0.6074282287069099
Validation loss: 2.6800338773341754

Epoch: 6| Step: 9
Training loss: 0.8329471686806678
Validation loss: 2.6847064114538286

Epoch: 6| Step: 10
Training loss: 0.6063794332156238
Validation loss: 2.714091230059944

Epoch: 6| Step: 11
Training loss: 0.7062039883571996
Validation loss: 2.696999505662148

Epoch: 6| Step: 12
Training loss: 1.0389178756221746
Validation loss: 2.697230694926982

Epoch: 6| Step: 13
Training loss: 1.0392933639241098
Validation loss: 2.6519682388523034

Epoch: 450| Step: 0
Training loss: 0.9036983874133633
Validation loss: 2.676828087736978

Epoch: 6| Step: 1
Training loss: 0.7143720727895603
Validation loss: 2.6500835123638358

Epoch: 6| Step: 2
Training loss: 0.6235062391585371
Validation loss: 2.7056429533797135

Epoch: 6| Step: 3
Training loss: 0.5161752654562285
Validation loss: 2.6876347086657315

Epoch: 6| Step: 4
Training loss: 0.6928409411245368
Validation loss: 2.663138056731041

Epoch: 6| Step: 5
Training loss: 0.8733760887216738
Validation loss: 2.6677023594998035

Epoch: 6| Step: 6
Training loss: 0.6999181307873372
Validation loss: 2.7013344539942525

Epoch: 6| Step: 7
Training loss: 0.7573015909362346
Validation loss: 2.6576909214793143

Epoch: 6| Step: 8
Training loss: 0.7910766578016802
Validation loss: 2.678659566307183

Epoch: 6| Step: 9
Training loss: 0.836619731554205
Validation loss: 2.692353014250114

Epoch: 6| Step: 10
Training loss: 0.7054559641003645
Validation loss: 2.71305131539318

Epoch: 6| Step: 11
Training loss: 0.6006348628763589
Validation loss: 2.704240704675426

Epoch: 6| Step: 12
Training loss: 0.8236180507466903
Validation loss: 2.723097179435037

Epoch: 6| Step: 13
Training loss: 1.0123713093671636
Validation loss: 2.6906117381715347

Epoch: 451| Step: 0
Training loss: 0.6452545500221324
Validation loss: 2.6765182185625185

Epoch: 6| Step: 1
Training loss: 0.7752302566076015
Validation loss: 2.73660829440771

Epoch: 6| Step: 2
Training loss: 1.093969377587751
Validation loss: 2.7421254208050536

Epoch: 6| Step: 3
Training loss: 0.7814193542028522
Validation loss: 2.7251238885184366

Epoch: 6| Step: 4
Training loss: 0.8134367751046115
Validation loss: 2.7604651440856176

Epoch: 6| Step: 5
Training loss: 0.8810347490331504
Validation loss: 2.722182682835794

Epoch: 6| Step: 6
Training loss: 0.6364650806083921
Validation loss: 2.7216854690802426

Epoch: 6| Step: 7
Training loss: 0.5178374882195679
Validation loss: 2.7220127069418187

Epoch: 6| Step: 8
Training loss: 0.7321707333099341
Validation loss: 2.6728400556646266

Epoch: 6| Step: 9
Training loss: 0.8518611489259315
Validation loss: 2.7192570735980497

Epoch: 6| Step: 10
Training loss: 0.6363972279194556
Validation loss: 2.722548173887467

Epoch: 6| Step: 11
Training loss: 0.8147415638358428
Validation loss: 2.672941050984413

Epoch: 6| Step: 12
Training loss: 0.6826440372016348
Validation loss: 2.718941575824121

Epoch: 6| Step: 13
Training loss: 1.0800489866661755
Validation loss: 2.710184540559242

Epoch: 452| Step: 0
Training loss: 0.697682253533457
Validation loss: 2.696166886257268

Epoch: 6| Step: 1
Training loss: 0.7795188033287215
Validation loss: 2.7235063405181097

Epoch: 6| Step: 2
Training loss: 0.895715853654311
Validation loss: 2.7192238727209994

Epoch: 6| Step: 3
Training loss: 0.6953203436591251
Validation loss: 2.7156853924098607

Epoch: 6| Step: 4
Training loss: 0.5244967716852263
Validation loss: 2.7449424793908133

Epoch: 6| Step: 5
Training loss: 0.5854242238363566
Validation loss: 2.728144961615816

Epoch: 6| Step: 6
Training loss: 0.7251960456447867
Validation loss: 2.7298105999288236

Epoch: 6| Step: 7
Training loss: 0.5442342487311074
Validation loss: 2.737973299727139

Epoch: 6| Step: 8
Training loss: 1.1194306375637055
Validation loss: 2.732082823085771

Epoch: 6| Step: 9
Training loss: 0.7976457197220951
Validation loss: 2.7498290557905127

Epoch: 6| Step: 10
Training loss: 0.8997820868530134
Validation loss: 2.7183591919851553

Epoch: 6| Step: 11
Training loss: 0.7950563059366803
Validation loss: 2.7403591831792933

Epoch: 6| Step: 12
Training loss: 0.5311451696299583
Validation loss: 2.739308366405349

Epoch: 6| Step: 13
Training loss: 0.7553954758558874
Validation loss: 2.745873772975066

Epoch: 453| Step: 0
Training loss: 0.9982787458263305
Validation loss: 2.7158250823534016

Epoch: 6| Step: 1
Training loss: 0.7638908521068276
Validation loss: 2.7114942054168427

Epoch: 6| Step: 2
Training loss: 0.7363775828621694
Validation loss: 2.6844936233618135

Epoch: 6| Step: 3
Training loss: 0.8258777572842162
Validation loss: 2.7737980138156697

Epoch: 6| Step: 4
Training loss: 0.9694169425129953
Validation loss: 2.698221614104331

Epoch: 6| Step: 5
Training loss: 0.46301683081608686
Validation loss: 2.7557524136072407

Epoch: 6| Step: 6
Training loss: 0.8022998831252367
Validation loss: 2.745670479521474

Epoch: 6| Step: 7
Training loss: 0.7165644630109115
Validation loss: 2.66704642055502

Epoch: 6| Step: 8
Training loss: 0.505394563728867
Validation loss: 2.6751982339153892

Epoch: 6| Step: 9
Training loss: 0.70237711232077
Validation loss: 2.6961628037950667

Epoch: 6| Step: 10
Training loss: 0.6081888440953946
Validation loss: 2.70728079566275

Epoch: 6| Step: 11
Training loss: 0.7617146027280929
Validation loss: 2.6919069751747338

Epoch: 6| Step: 12
Training loss: 0.9372826642205196
Validation loss: 2.681512861549251

Epoch: 6| Step: 13
Training loss: 0.8313155342025456
Validation loss: 2.6735389688730336

Epoch: 454| Step: 0
Training loss: 0.7156105306570182
Validation loss: 2.6645397754376883

Epoch: 6| Step: 1
Training loss: 0.8066843681389919
Validation loss: 2.7091141137719155

Epoch: 6| Step: 2
Training loss: 0.6624928492034209
Validation loss: 2.681838993034375

Epoch: 6| Step: 3
Training loss: 0.9652025737023849
Validation loss: 2.7271234177649246

Epoch: 6| Step: 4
Training loss: 0.9539752669677105
Validation loss: 2.683564698174488

Epoch: 6| Step: 5
Training loss: 0.9084652758204471
Validation loss: 2.750956007926147

Epoch: 6| Step: 6
Training loss: 0.9838040830682165
Validation loss: 2.7828584656157873

Epoch: 6| Step: 7
Training loss: 0.5963340794763149
Validation loss: 2.795538940128457

Epoch: 6| Step: 8
Training loss: 0.9778799097288262
Validation loss: 2.7818037189100875

Epoch: 6| Step: 9
Training loss: 0.8138610004714435
Validation loss: 2.7350472777311845

Epoch: 6| Step: 10
Training loss: 0.7893424717716733
Validation loss: 2.7115908375059057

Epoch: 6| Step: 11
Training loss: 0.7594285231828802
Validation loss: 2.738993625968173

Epoch: 6| Step: 12
Training loss: 0.9744506584386438
Validation loss: 2.744688105695506

Epoch: 6| Step: 13
Training loss: 0.8151801726925838
Validation loss: 2.7508577107394525

Epoch: 455| Step: 0
Training loss: 1.032595883274683
Validation loss: 2.7179042479926157

Epoch: 6| Step: 1
Training loss: 0.8407770692912431
Validation loss: 2.7289380324790216

Epoch: 6| Step: 2
Training loss: 0.8773584257615534
Validation loss: 2.710505221125121

Epoch: 6| Step: 3
Training loss: 1.1644926876397057
Validation loss: 2.7227583382146987

Epoch: 6| Step: 4
Training loss: 0.7266426042267934
Validation loss: 2.7326042763374536

Epoch: 6| Step: 5
Training loss: 0.6491389329966045
Validation loss: 2.7662382864700494

Epoch: 6| Step: 6
Training loss: 0.9959301982572475
Validation loss: 2.7854390689592843

Epoch: 6| Step: 7
Training loss: 0.8450435330389897
Validation loss: 2.7565823297695884

Epoch: 6| Step: 8
Training loss: 1.067738521738416
Validation loss: 2.7583096482065796

Epoch: 6| Step: 9
Training loss: 0.6879914651205493
Validation loss: 2.749560248731868

Epoch: 6| Step: 10
Training loss: 0.9622785623146376
Validation loss: 2.6963421904899887

Epoch: 6| Step: 11
Training loss: 0.756897915179042
Validation loss: 2.6634745018857293

Epoch: 6| Step: 12
Training loss: 0.494395103817448
Validation loss: 2.6572250371814348

Epoch: 6| Step: 13
Training loss: 0.8422819718010455
Validation loss: 2.7450170309838957

Epoch: 456| Step: 0
Training loss: 0.7703924636656403
Validation loss: 2.6780841802025606

Epoch: 6| Step: 1
Training loss: 0.854681898583393
Validation loss: 2.731453095544231

Epoch: 6| Step: 2
Training loss: 0.7583508889468311
Validation loss: 2.701543606334813

Epoch: 6| Step: 3
Training loss: 1.007335224544518
Validation loss: 2.7541949326011674

Epoch: 6| Step: 4
Training loss: 0.7551187440195963
Validation loss: 2.7096554145765506

Epoch: 6| Step: 5
Training loss: 0.2943582517471966
Validation loss: 2.741049882873049

Epoch: 6| Step: 6
Training loss: 0.7494726711377871
Validation loss: 2.737242156416986

Epoch: 6| Step: 7
Training loss: 0.5628417619281757
Validation loss: 2.708465489806668

Epoch: 6| Step: 8
Training loss: 0.6906131139224356
Validation loss: 2.7299258265823183

Epoch: 6| Step: 9
Training loss: 0.673152795251402
Validation loss: 2.6890078609810812

Epoch: 6| Step: 10
Training loss: 0.7248814321444057
Validation loss: 2.7027836696207252

Epoch: 6| Step: 11
Training loss: 0.8133253527142925
Validation loss: 2.7434994130561225

Epoch: 6| Step: 12
Training loss: 0.6496576067646878
Validation loss: 2.7660384363035524

Epoch: 6| Step: 13
Training loss: 0.8509562372840771
Validation loss: 2.7396522532642935

Epoch: 457| Step: 0
Training loss: 0.6783155208806139
Validation loss: 2.7254546063322302

Epoch: 6| Step: 1
Training loss: 0.7552741887986792
Validation loss: 2.7148050063042164

Epoch: 6| Step: 2
Training loss: 0.6609957171112368
Validation loss: 2.7391249027749187

Epoch: 6| Step: 3
Training loss: 0.7276911019826924
Validation loss: 2.7233825036056976

Epoch: 6| Step: 4
Training loss: 0.800116621398204
Validation loss: 2.7342883141718772

Epoch: 6| Step: 5
Training loss: 0.5561094460090347
Validation loss: 2.715574843949852

Epoch: 6| Step: 6
Training loss: 0.6074372317222005
Validation loss: 2.66433597328214

Epoch: 6| Step: 7
Training loss: 0.9085433486774785
Validation loss: 2.6984229674442197

Epoch: 6| Step: 8
Training loss: 0.8046397593141508
Validation loss: 2.7050637144951226

Epoch: 6| Step: 9
Training loss: 0.7502618968189437
Validation loss: 2.6877390732995936

Epoch: 6| Step: 10
Training loss: 0.7653418815458837
Validation loss: 2.70192230164379

Epoch: 6| Step: 11
Training loss: 0.5286700489028999
Validation loss: 2.720462303703917

Epoch: 6| Step: 12
Training loss: 0.7902898025119303
Validation loss: 2.723543187751852

Epoch: 6| Step: 13
Training loss: 0.5758706291319352
Validation loss: 2.7057751433523562

Epoch: 458| Step: 0
Training loss: 0.7483981828974363
Validation loss: 2.768634401639371

Epoch: 6| Step: 1
Training loss: 0.5466870393630089
Validation loss: 2.7186207503073443

Epoch: 6| Step: 2
Training loss: 0.5573514448767777
Validation loss: 2.709259444621082

Epoch: 6| Step: 3
Training loss: 0.7540338833149623
Validation loss: 2.6804228756954895

Epoch: 6| Step: 4
Training loss: 0.8315974434410089
Validation loss: 2.743917196823379

Epoch: 6| Step: 5
Training loss: 0.3903352425686287
Validation loss: 2.6628490007335186

Epoch: 6| Step: 6
Training loss: 0.6384137299790497
Validation loss: 2.715394020573431

Epoch: 6| Step: 7
Training loss: 0.6799939440359395
Validation loss: 2.715486899472443

Epoch: 6| Step: 8
Training loss: 0.8194068268764125
Validation loss: 2.680769454468525

Epoch: 6| Step: 9
Training loss: 0.6547211367540079
Validation loss: 2.7473106383120878

Epoch: 6| Step: 10
Training loss: 0.8241857368402359
Validation loss: 2.6957447387272278

Epoch: 6| Step: 11
Training loss: 0.896217921599379
Validation loss: 2.7097601335607435

Epoch: 6| Step: 12
Training loss: 0.7800882093363227
Validation loss: 2.686011722908371

Epoch: 6| Step: 13
Training loss: 0.7520373805018326
Validation loss: 2.653522736923441

Epoch: 459| Step: 0
Training loss: 0.5659974826514133
Validation loss: 2.6902595664699933

Epoch: 6| Step: 1
Training loss: 0.6301763752382235
Validation loss: 2.6851124915030575

Epoch: 6| Step: 2
Training loss: 0.6226766556635281
Validation loss: 2.7429865499795536

Epoch: 6| Step: 3
Training loss: 1.0527813676243363
Validation loss: 2.6709176369115886

Epoch: 6| Step: 4
Training loss: 0.84230631483841
Validation loss: 2.733235228820969

Epoch: 6| Step: 5
Training loss: 0.6155408307933595
Validation loss: 2.7346283858834637

Epoch: 6| Step: 6
Training loss: 0.5179411856335007
Validation loss: 2.7102015776228314

Epoch: 6| Step: 7
Training loss: 0.7732559145070074
Validation loss: 2.70391349097128

Epoch: 6| Step: 8
Training loss: 0.5526637918541702
Validation loss: 2.7300848957108257

Epoch: 6| Step: 9
Training loss: 0.8043304688310053
Validation loss: 2.7063584292026968

Epoch: 6| Step: 10
Training loss: 0.4398614469935179
Validation loss: 2.730440829984277

Epoch: 6| Step: 11
Training loss: 0.8315920678078319
Validation loss: 2.7223832856969175

Epoch: 6| Step: 12
Training loss: 0.9790270719379689
Validation loss: 2.7389576031738136

Epoch: 6| Step: 13
Training loss: 0.6698055333135342
Validation loss: 2.7067268497685193

Epoch: 460| Step: 0
Training loss: 0.4899221695181427
Validation loss: 2.7271165840408513

Epoch: 6| Step: 1
Training loss: 0.7766411831635711
Validation loss: 2.749743724210169

Epoch: 6| Step: 2
Training loss: 0.9921066371376187
Validation loss: 2.739915390100517

Epoch: 6| Step: 3
Training loss: 0.7086551206481927
Validation loss: 2.7568244352786526

Epoch: 6| Step: 4
Training loss: 0.6690906673027391
Validation loss: 2.7892202836684366

Epoch: 6| Step: 5
Training loss: 0.7357485891154297
Validation loss: 2.7474939819931845

Epoch: 6| Step: 6
Training loss: 0.6239924893294004
Validation loss: 2.71335299977604

Epoch: 6| Step: 7
Training loss: 0.6794087287721106
Validation loss: 2.765279471729355

Epoch: 6| Step: 8
Training loss: 0.6032656550077523
Validation loss: 2.7088915958665707

Epoch: 6| Step: 9
Training loss: 0.7109799215215312
Validation loss: 2.6931473886239896

Epoch: 6| Step: 10
Training loss: 0.6030075255315026
Validation loss: 2.7213369025210583

Epoch: 6| Step: 11
Training loss: 0.5605235609994745
Validation loss: 2.7320566285456085

Epoch: 6| Step: 12
Training loss: 0.8390136519834281
Validation loss: 2.714513979123679

Epoch: 6| Step: 13
Training loss: 0.7350924213846463
Validation loss: 2.7142629756907204

Epoch: 461| Step: 0
Training loss: 0.7666040116775168
Validation loss: 2.6876393067679483

Epoch: 6| Step: 1
Training loss: 0.6395231633871542
Validation loss: 2.682270314153229

Epoch: 6| Step: 2
Training loss: 0.7182431299642515
Validation loss: 2.6883041154708835

Epoch: 6| Step: 3
Training loss: 0.8671288341576576
Validation loss: 2.7084485298502274

Epoch: 6| Step: 4
Training loss: 0.5420838699465224
Validation loss: 2.700229976125737

Epoch: 6| Step: 5
Training loss: 0.6376172846073263
Validation loss: 2.712317988299738

Epoch: 6| Step: 6
Training loss: 0.8701195165600843
Validation loss: 2.7165364282979785

Epoch: 6| Step: 7
Training loss: 0.6529857651355078
Validation loss: 2.725769860479005

Epoch: 6| Step: 8
Training loss: 0.8285447262586069
Validation loss: 2.7009954719011184

Epoch: 6| Step: 9
Training loss: 0.6788100575033559
Validation loss: 2.7295763906958244

Epoch: 6| Step: 10
Training loss: 0.7052912508865525
Validation loss: 2.782137368476211

Epoch: 6| Step: 11
Training loss: 0.8092883531298704
Validation loss: 2.6779608840540483

Epoch: 6| Step: 12
Training loss: 0.6595938504678444
Validation loss: 2.7344039624814735

Epoch: 6| Step: 13
Training loss: 0.5166103888696897
Validation loss: 2.7610804545438055

Epoch: 462| Step: 0
Training loss: 0.6214649123064085
Validation loss: 2.743047718782672

Epoch: 6| Step: 1
Training loss: 0.6325802317910848
Validation loss: 2.742958967437148

Epoch: 6| Step: 2
Training loss: 0.7243903309711289
Validation loss: 2.7248150929002186

Epoch: 6| Step: 3
Training loss: 0.4325792627524594
Validation loss: 2.771249601220432

Epoch: 6| Step: 4
Training loss: 0.7638943633451715
Validation loss: 2.73922977172498

Epoch: 6| Step: 5
Training loss: 0.7290247552014912
Validation loss: 2.7306014625848647

Epoch: 6| Step: 6
Training loss: 0.6703021913460468
Validation loss: 2.7688101550270456

Epoch: 6| Step: 7
Training loss: 0.6726046304246748
Validation loss: 2.7356617688212292

Epoch: 6| Step: 8
Training loss: 0.7006176216356311
Validation loss: 2.803373888095102

Epoch: 6| Step: 9
Training loss: 0.9356377225022328
Validation loss: 2.7825698863870008

Epoch: 6| Step: 10
Training loss: 0.8291278740579869
Validation loss: 2.7766992435475313

Epoch: 6| Step: 11
Training loss: 0.6446117697617992
Validation loss: 2.7749674271055116

Epoch: 6| Step: 12
Training loss: 1.0083192246345898
Validation loss: 2.7240296251779172

Epoch: 6| Step: 13
Training loss: 0.6322744931733051
Validation loss: 2.7747533837555074

Epoch: 463| Step: 0
Training loss: 0.5732565882886894
Validation loss: 2.732447382544526

Epoch: 6| Step: 1
Training loss: 0.68519078758124
Validation loss: 2.755490169039915

Epoch: 6| Step: 2
Training loss: 0.5788986339402732
Validation loss: 2.7385906311355184

Epoch: 6| Step: 3
Training loss: 0.9562653883150871
Validation loss: 2.6984737709669213

Epoch: 6| Step: 4
Training loss: 0.6858958255560149
Validation loss: 2.6869595597856817

Epoch: 6| Step: 5
Training loss: 0.7013861028743928
Validation loss: 2.7124029443959357

Epoch: 6| Step: 6
Training loss: 0.3749363765785567
Validation loss: 2.7069690544906515

Epoch: 6| Step: 7
Training loss: 0.46642061655483646
Validation loss: 2.725120928469657

Epoch: 6| Step: 8
Training loss: 0.8524439038701024
Validation loss: 2.69881071400811

Epoch: 6| Step: 9
Training loss: 0.8898482030366931
Validation loss: 2.753141155332636

Epoch: 6| Step: 10
Training loss: 0.5492759859260711
Validation loss: 2.7423546242934385

Epoch: 6| Step: 11
Training loss: 0.6856865373812796
Validation loss: 2.7479307163237014

Epoch: 6| Step: 12
Training loss: 0.5977076589377335
Validation loss: 2.7280395063278555

Epoch: 6| Step: 13
Training loss: 0.47511992446448553
Validation loss: 2.7682996700826887

Epoch: 464| Step: 0
Training loss: 0.6055493208897685
Validation loss: 2.679519395958664

Epoch: 6| Step: 1
Training loss: 0.5926863026561106
Validation loss: 2.7372578709790822

Epoch: 6| Step: 2
Training loss: 0.6975759034917668
Validation loss: 2.679281383765683

Epoch: 6| Step: 3
Training loss: 0.47314505089887776
Validation loss: 2.7132436450769126

Epoch: 6| Step: 4
Training loss: 0.42353585709119584
Validation loss: 2.7010948333823386

Epoch: 6| Step: 5
Training loss: 0.48477902021198355
Validation loss: 2.6868588695646807

Epoch: 6| Step: 6
Training loss: 0.8606315443002049
Validation loss: 2.714719276410577

Epoch: 6| Step: 7
Training loss: 0.5643270015055275
Validation loss: 2.7082504015231796

Epoch: 6| Step: 8
Training loss: 0.5829434511067629
Validation loss: 2.686110617913621

Epoch: 6| Step: 9
Training loss: 1.019512775589921
Validation loss: 2.664747550940564

Epoch: 6| Step: 10
Training loss: 0.9680495652521683
Validation loss: 2.7146165491991296

Epoch: 6| Step: 11
Training loss: 0.7143983964935154
Validation loss: 2.6625459890915892

Epoch: 6| Step: 12
Training loss: 0.8617288431525858
Validation loss: 2.744281038468164

Epoch: 6| Step: 13
Training loss: 1.1113868523552335
Validation loss: 2.7264642852611747

Epoch: 465| Step: 0
Training loss: 0.8785214408251177
Validation loss: 2.7504560208077984

Epoch: 6| Step: 1
Training loss: 0.9835364387910336
Validation loss: 2.774074148256995

Epoch: 6| Step: 2
Training loss: 0.6011754066209873
Validation loss: 2.7667856887892133

Epoch: 6| Step: 3
Training loss: 1.021620207119659
Validation loss: 2.761428551577448

Epoch: 6| Step: 4
Training loss: 0.7213859321586852
Validation loss: 2.7338613990537346

Epoch: 6| Step: 5
Training loss: 0.9627319267060417
Validation loss: 2.738943617555296

Epoch: 6| Step: 6
Training loss: 0.5680563731862562
Validation loss: 2.7403139849169467

Epoch: 6| Step: 7
Training loss: 0.5813629358565868
Validation loss: 2.745032577993012

Epoch: 6| Step: 8
Training loss: 0.5573998610621246
Validation loss: 2.7217337360360414

Epoch: 6| Step: 9
Training loss: 0.7484279687708608
Validation loss: 2.797562456090031

Epoch: 6| Step: 10
Training loss: 0.8390514806382591
Validation loss: 2.7667065389663197

Epoch: 6| Step: 11
Training loss: 0.7454835083747309
Validation loss: 2.795711040712146

Epoch: 6| Step: 12
Training loss: 0.6601436997524213
Validation loss: 2.747813424770732

Epoch: 6| Step: 13
Training loss: 0.5767792167786882
Validation loss: 2.8123366131831413

Epoch: 466| Step: 0
Training loss: 0.8054087101253401
Validation loss: 2.7658393762408893

Epoch: 6| Step: 1
Training loss: 0.9512758296111493
Validation loss: 2.7179628306886623

Epoch: 6| Step: 2
Training loss: 0.8469888899118418
Validation loss: 2.701373567404251

Epoch: 6| Step: 3
Training loss: 0.787668715675176
Validation loss: 2.71180396107784

Epoch: 6| Step: 4
Training loss: 0.8745363914634408
Validation loss: 2.6810924602308104

Epoch: 6| Step: 5
Training loss: 0.9397555873549482
Validation loss: 2.6596216009001488

Epoch: 6| Step: 6
Training loss: 0.759744756652272
Validation loss: 2.649905380323198

Epoch: 6| Step: 7
Training loss: 1.0547740194366526
Validation loss: 2.686169036004855

Epoch: 6| Step: 8
Training loss: 0.590542032580526
Validation loss: 2.679300560183748

Epoch: 6| Step: 9
Training loss: 0.6185439691557472
Validation loss: 2.729634184262985

Epoch: 6| Step: 10
Training loss: 0.9340373625297012
Validation loss: 2.692479687740742

Epoch: 6| Step: 11
Training loss: 0.5461088808771314
Validation loss: 2.6904875244274846

Epoch: 6| Step: 12
Training loss: 0.6737286480437921
Validation loss: 2.7182771556560503

Epoch: 6| Step: 13
Training loss: 0.726004273278557
Validation loss: 2.7975542888083798

Epoch: 467| Step: 0
Training loss: 0.8945734605450203
Validation loss: 2.734380929123036

Epoch: 6| Step: 1
Training loss: 0.9811724383078215
Validation loss: 2.7711042305212485

Epoch: 6| Step: 2
Training loss: 0.6911866437356676
Validation loss: 2.731804298702583

Epoch: 6| Step: 3
Training loss: 0.8453984581753903
Validation loss: 2.689466466711302

Epoch: 6| Step: 4
Training loss: 0.5702795776897868
Validation loss: 2.7577874792186905

Epoch: 6| Step: 5
Training loss: 0.9148435597537631
Validation loss: 2.7136089343460346

Epoch: 6| Step: 6
Training loss: 0.7346967844374396
Validation loss: 2.7685471809908893

Epoch: 6| Step: 7
Training loss: 0.7331479148828332
Validation loss: 2.7099789583907197

Epoch: 6| Step: 8
Training loss: 0.8773916800392094
Validation loss: 2.7909319015057803

Epoch: 6| Step: 9
Training loss: 0.7437380204718581
Validation loss: 2.811223793116828

Epoch: 6| Step: 10
Training loss: 0.9514420769822004
Validation loss: 2.7510367664397997

Epoch: 6| Step: 11
Training loss: 0.6378705191495042
Validation loss: 2.7750870504844567

Epoch: 6| Step: 12
Training loss: 0.7658344293765699
Validation loss: 2.749910960056439

Epoch: 6| Step: 13
Training loss: 0.4567327910544553
Validation loss: 2.6991044649182636

Epoch: 468| Step: 0
Training loss: 0.760419392689735
Validation loss: 2.7614495893982935

Epoch: 6| Step: 1
Training loss: 0.6703179525940546
Validation loss: 2.728120651911664

Epoch: 6| Step: 2
Training loss: 0.5928828281478539
Validation loss: 2.7038428762717763

Epoch: 6| Step: 3
Training loss: 0.7471029037646884
Validation loss: 2.7501315605598897

Epoch: 6| Step: 4
Training loss: 1.4636026643506217
Validation loss: 2.7672316774747396

Epoch: 6| Step: 5
Training loss: 0.7092184725918661
Validation loss: 2.7088468993933614

Epoch: 6| Step: 6
Training loss: 0.6009775265254191
Validation loss: 2.737206524311269

Epoch: 6| Step: 7
Training loss: 0.8867657350704066
Validation loss: 2.7313600467070462

Epoch: 6| Step: 8
Training loss: 0.7277291068901509
Validation loss: 2.7006735223602925

Epoch: 6| Step: 9
Training loss: 0.48144808259673894
Validation loss: 2.7374208761128633

Epoch: 6| Step: 10
Training loss: 0.5381502642665527
Validation loss: 2.713287910316319

Epoch: 6| Step: 11
Training loss: 0.5896647604887612
Validation loss: 2.689937033666728

Epoch: 6| Step: 12
Training loss: 0.5908670202030738
Validation loss: 2.7113370426897663

Epoch: 6| Step: 13
Training loss: 0.8256594825260624
Validation loss: 2.7125668132188654

Epoch: 469| Step: 0
Training loss: 0.6630677570440613
Validation loss: 2.7664923448298713

Epoch: 6| Step: 1
Training loss: 0.8300325268955735
Validation loss: 2.723208327216152

Epoch: 6| Step: 2
Training loss: 0.46627000579151495
Validation loss: 2.80232418306225

Epoch: 6| Step: 3
Training loss: 0.5228370524841534
Validation loss: 2.8077232062184168

Epoch: 6| Step: 4
Training loss: 0.6459599237559207
Validation loss: 2.7294573859564872

Epoch: 6| Step: 5
Training loss: 0.653322547714903
Validation loss: 2.7263848539264153

Epoch: 6| Step: 6
Training loss: 0.9950682803069305
Validation loss: 2.747446420694977

Epoch: 6| Step: 7
Training loss: 0.6713222403342194
Validation loss: 2.7425084229684504

Epoch: 6| Step: 8
Training loss: 0.8707610722422978
Validation loss: 2.738221970087466

Epoch: 6| Step: 9
Training loss: 0.8419576964794492
Validation loss: 2.764965028915316

Epoch: 6| Step: 10
Training loss: 0.704752585372161
Validation loss: 2.733914131199266

Epoch: 6| Step: 11
Training loss: 0.755169852142362
Validation loss: 2.7491330167297665

Epoch: 6| Step: 12
Training loss: 0.6019167661980587
Validation loss: 2.7024903039231924

Epoch: 6| Step: 13
Training loss: 0.8227044970790911
Validation loss: 2.7658709831544805

Epoch: 470| Step: 0
Training loss: 0.7868042915456042
Validation loss: 2.7354694174459238

Epoch: 6| Step: 1
Training loss: 0.5051543577272635
Validation loss: 2.7759071708767884

Epoch: 6| Step: 2
Training loss: 0.7959750085985785
Validation loss: 2.749415241550219

Epoch: 6| Step: 3
Training loss: 0.5368285676197286
Validation loss: 2.718790046718499

Epoch: 6| Step: 4
Training loss: 0.5922442718509036
Validation loss: 2.7430585182485125

Epoch: 6| Step: 5
Training loss: 0.6255667501002784
Validation loss: 2.769954919803999

Epoch: 6| Step: 6
Training loss: 0.5461397951112318
Validation loss: 2.7724410295191593

Epoch: 6| Step: 7
Training loss: 0.6510851934505608
Validation loss: 2.7479831061864237

Epoch: 6| Step: 8
Training loss: 0.7306239325366286
Validation loss: 2.7900224275040784

Epoch: 6| Step: 9
Training loss: 0.8519522098919389
Validation loss: 2.7494953588370357

Epoch: 6| Step: 10
Training loss: 0.5827578674973429
Validation loss: 2.8015158881107336

Epoch: 6| Step: 11
Training loss: 0.7920525053975968
Validation loss: 2.789307584421567

Epoch: 6| Step: 12
Training loss: 0.878316859670498
Validation loss: 2.754150552938149

Epoch: 6| Step: 13
Training loss: 0.5994799098306574
Validation loss: 2.741628475754175

Epoch: 471| Step: 0
Training loss: 0.9144880820155271
Validation loss: 2.779250794433268

Epoch: 6| Step: 1
Training loss: 0.5416101707437464
Validation loss: 2.7335182955041057

Epoch: 6| Step: 2
Training loss: 0.8043316174525857
Validation loss: 2.7739501336081935

Epoch: 6| Step: 3
Training loss: 0.39844520411803414
Validation loss: 2.7569575438894223

Epoch: 6| Step: 4
Training loss: 0.46028117959656967
Validation loss: 2.717877829078936

Epoch: 6| Step: 5
Training loss: 0.4708961787381263
Validation loss: 2.7213126488154473

Epoch: 6| Step: 6
Training loss: 0.802038554803582
Validation loss: 2.6735679810142883

Epoch: 6| Step: 7
Training loss: 0.47898147639372995
Validation loss: 2.748584845581632

Epoch: 6| Step: 8
Training loss: 0.6131058460319622
Validation loss: 2.741728756055644

Epoch: 6| Step: 9
Training loss: 0.9030288803534698
Validation loss: 2.701102983391977

Epoch: 6| Step: 10
Training loss: 0.8756650713206748
Validation loss: 2.7065626126835385

Epoch: 6| Step: 11
Training loss: 0.7579756099128641
Validation loss: 2.7664929193686123

Epoch: 6| Step: 12
Training loss: 0.8349362375275697
Validation loss: 2.723410189577934

Epoch: 6| Step: 13
Training loss: 0.5933546707740329
Validation loss: 2.7268660557632476

Epoch: 472| Step: 0
Training loss: 0.592609011927047
Validation loss: 2.7590428130443776

Epoch: 6| Step: 1
Training loss: 0.8097520723142662
Validation loss: 2.6830011164117518

Epoch: 6| Step: 2
Training loss: 0.6854073146039051
Validation loss: 2.777525533243469

Epoch: 6| Step: 3
Training loss: 1.1097799287469718
Validation loss: 2.740735443917255

Epoch: 6| Step: 4
Training loss: 0.7755382022659026
Validation loss: 2.7417754092773183

Epoch: 6| Step: 5
Training loss: 0.5719942354231909
Validation loss: 2.8133707182179566

Epoch: 6| Step: 6
Training loss: 0.6279535363208391
Validation loss: 2.815700744219768

Epoch: 6| Step: 7
Training loss: 0.74474420374023
Validation loss: 2.741400769759917

Epoch: 6| Step: 8
Training loss: 0.7345810459106398
Validation loss: 2.776928591202851

Epoch: 6| Step: 9
Training loss: 0.35076882525149033
Validation loss: 2.7569394409194072

Epoch: 6| Step: 10
Training loss: 0.6531241768279661
Validation loss: 2.7776318850881645

Epoch: 6| Step: 11
Training loss: 0.7208324616120053
Validation loss: 2.7900182687396002

Epoch: 6| Step: 12
Training loss: 0.7852551222460776
Validation loss: 2.7647284079928296

Epoch: 6| Step: 13
Training loss: 0.7964453193252565
Validation loss: 2.805718291843249

Epoch: 473| Step: 0
Training loss: 0.6497313448600877
Validation loss: 2.7483421732766335

Epoch: 6| Step: 1
Training loss: 1.1296524696669907
Validation loss: 2.6974699959015793

Epoch: 6| Step: 2
Training loss: 0.4520973522749171
Validation loss: 2.730662559576348

Epoch: 6| Step: 3
Training loss: 0.48193331547413126
Validation loss: 2.744387129349453

Epoch: 6| Step: 4
Training loss: 0.5315874654748134
Validation loss: 2.70644473226146

Epoch: 6| Step: 5
Training loss: 0.8225362518113248
Validation loss: 2.691845699729791

Epoch: 6| Step: 6
Training loss: 0.5670462314185494
Validation loss: 2.7607134581506867

Epoch: 6| Step: 7
Training loss: 0.6493595874855514
Validation loss: 2.777647263851659

Epoch: 6| Step: 8
Training loss: 0.8621714090447553
Validation loss: 2.7368052845075836

Epoch: 6| Step: 9
Training loss: 0.5699244707661554
Validation loss: 2.700013827064807

Epoch: 6| Step: 10
Training loss: 0.5746932891006498
Validation loss: 2.6969082443881707

Epoch: 6| Step: 11
Training loss: 0.6359356001467057
Validation loss: 2.7134286682460824

Epoch: 6| Step: 12
Training loss: 0.5774165787658463
Validation loss: 2.7309626622366183

Epoch: 6| Step: 13
Training loss: 0.5551549526793172
Validation loss: 2.7242098461808233

Epoch: 474| Step: 0
Training loss: 0.9285191479312375
Validation loss: 2.707339622911394

Epoch: 6| Step: 1
Training loss: 0.5595836804242832
Validation loss: 2.726187344075524

Epoch: 6| Step: 2
Training loss: 0.7442654082036265
Validation loss: 2.6873279486889063

Epoch: 6| Step: 3
Training loss: 0.717057266544757
Validation loss: 2.7456612895347767

Epoch: 6| Step: 4
Training loss: 0.5679512787326375
Validation loss: 2.7556256060600695

Epoch: 6| Step: 5
Training loss: 0.5985879803496224
Validation loss: 2.7194872693227157

Epoch: 6| Step: 6
Training loss: 0.6355866741527588
Validation loss: 2.7095378593591675

Epoch: 6| Step: 7
Training loss: 0.5404047357432876
Validation loss: 2.717937684290507

Epoch: 6| Step: 8
Training loss: 0.47718072095751035
Validation loss: 2.743990748103479

Epoch: 6| Step: 9
Training loss: 0.550652779821246
Validation loss: 2.7628799723757758

Epoch: 6| Step: 10
Training loss: 0.7110814378511147
Validation loss: 2.7345058300871994

Epoch: 6| Step: 11
Training loss: 0.9100546063817707
Validation loss: 2.718076059698019

Epoch: 6| Step: 12
Training loss: 0.7034953095903995
Validation loss: 2.7491793419471646

Epoch: 6| Step: 13
Training loss: 0.41325522847453694
Validation loss: 2.710402638406147

Epoch: 475| Step: 0
Training loss: 0.796276653268892
Validation loss: 2.7582530677465096

Epoch: 6| Step: 1
Training loss: 0.481830682559635
Validation loss: 2.7329139220994616

Epoch: 6| Step: 2
Training loss: 0.5324671490256359
Validation loss: 2.74029084897639

Epoch: 6| Step: 3
Training loss: 0.8235416976178568
Validation loss: 2.754187819783923

Epoch: 6| Step: 4
Training loss: 0.549587904911342
Validation loss: 2.7737370718766026

Epoch: 6| Step: 5
Training loss: 0.5438439430552556
Validation loss: 2.752662626792744

Epoch: 6| Step: 6
Training loss: 0.918950047414907
Validation loss: 2.798508208102353

Epoch: 6| Step: 7
Training loss: 0.5722555739005073
Validation loss: 2.7602293610753788

Epoch: 6| Step: 8
Training loss: 0.6455535179958846
Validation loss: 2.708652951870159

Epoch: 6| Step: 9
Training loss: 0.7095516237023268
Validation loss: 2.7499666500959266

Epoch: 6| Step: 10
Training loss: 0.46398664040694104
Validation loss: 2.744565854323608

Epoch: 6| Step: 11
Training loss: 0.3984446805419147
Validation loss: 2.686538990215625

Epoch: 6| Step: 12
Training loss: 0.5321718800302617
Validation loss: 2.7505409691209666

Epoch: 6| Step: 13
Training loss: 0.765112569168587
Validation loss: 2.713134139510664

Epoch: 476| Step: 0
Training loss: 0.6769947116270548
Validation loss: 2.742489108953929

Epoch: 6| Step: 1
Training loss: 0.7647789542910711
Validation loss: 2.7687922013096986

Epoch: 6| Step: 2
Training loss: 0.8387435093612928
Validation loss: 2.7451611920980885

Epoch: 6| Step: 3
Training loss: 0.769454410027864
Validation loss: 2.734522846402932

Epoch: 6| Step: 4
Training loss: 0.482792515017018
Validation loss: 2.7507539062527737

Epoch: 6| Step: 5
Training loss: 0.5115533226462324
Validation loss: 2.7608515606789057

Epoch: 6| Step: 6
Training loss: 0.7359920311423829
Validation loss: 2.743905249441718

Epoch: 6| Step: 7
Training loss: 0.5742571551915537
Validation loss: 2.7381185573074553

Epoch: 6| Step: 8
Training loss: 0.4906474345235093
Validation loss: 2.763704843852416

Epoch: 6| Step: 9
Training loss: 0.5715689992144087
Validation loss: 2.764029867217892

Epoch: 6| Step: 10
Training loss: 0.6078789270185121
Validation loss: 2.7359123631137217

Epoch: 6| Step: 11
Training loss: 0.7084239499714976
Validation loss: 2.766732649609992

Epoch: 6| Step: 12
Training loss: 0.4953631630868706
Validation loss: 2.7264191627171153

Epoch: 6| Step: 13
Training loss: 0.6788358065776069
Validation loss: 2.761819466243126

Epoch: 477| Step: 0
Training loss: 0.7129887761520677
Validation loss: 2.7285182755352047

Epoch: 6| Step: 1
Training loss: 0.90410349943127
Validation loss: 2.7351371066394994

Epoch: 6| Step: 2
Training loss: 0.6483175787282272
Validation loss: 2.6924270664987793

Epoch: 6| Step: 3
Training loss: 0.4090017509959264
Validation loss: 2.71804588524938

Epoch: 6| Step: 4
Training loss: 0.6067048775076487
Validation loss: 2.6742583681738616

Epoch: 6| Step: 5
Training loss: 0.6654199974041989
Validation loss: 2.7150016757030246

Epoch: 6| Step: 6
Training loss: 0.9158283684803928
Validation loss: 2.7328584734403267

Epoch: 6| Step: 7
Training loss: 0.612760772467198
Validation loss: 2.7218848238861524

Epoch: 6| Step: 8
Training loss: 0.5450611551778007
Validation loss: 2.766829434934407

Epoch: 6| Step: 9
Training loss: 0.3947845627775503
Validation loss: 2.714836431626077

Epoch: 6| Step: 10
Training loss: 0.5158764775012159
Validation loss: 2.7627767202753426

Epoch: 6| Step: 11
Training loss: 0.7930584936612722
Validation loss: 2.727949778729399

Epoch: 6| Step: 12
Training loss: 0.5514335287020942
Validation loss: 2.730974811741838

Epoch: 6| Step: 13
Training loss: 0.6552247485564281
Validation loss: 2.7626806128191617

Epoch: 478| Step: 0
Training loss: 0.7243100188026258
Validation loss: 2.7519627271547424

Epoch: 6| Step: 1
Training loss: 0.796200335763814
Validation loss: 2.825050382811892

Epoch: 6| Step: 2
Training loss: 0.8747446164327729
Validation loss: 2.7665478016317704

Epoch: 6| Step: 3
Training loss: 0.5040284829152151
Validation loss: 2.754250132055396

Epoch: 6| Step: 4
Training loss: 0.6008128660139999
Validation loss: 2.75220217817555

Epoch: 6| Step: 5
Training loss: 0.7596264395424751
Validation loss: 2.7459123966679755

Epoch: 6| Step: 6
Training loss: 0.5935953089328828
Validation loss: 2.7303122574288463

Epoch: 6| Step: 7
Training loss: 0.7001712427830439
Validation loss: 2.77486280611918

Epoch: 6| Step: 8
Training loss: 0.5000163314059536
Validation loss: 2.7742561815494393

Epoch: 6| Step: 9
Training loss: 0.7525678623687337
Validation loss: 2.7623811365392528

Epoch: 6| Step: 10
Training loss: 0.631752350597892
Validation loss: 2.737330904401967

Epoch: 6| Step: 11
Training loss: 0.6684532639123546
Validation loss: 2.711331649402064

Epoch: 6| Step: 12
Training loss: 0.7753722911752345
Validation loss: 2.734201625595445

Epoch: 6| Step: 13
Training loss: 0.5361185540976691
Validation loss: 2.743288346296782

Epoch: 479| Step: 0
Training loss: 0.5417296177401393
Validation loss: 2.7171031962955996

Epoch: 6| Step: 1
Training loss: 0.7834587916557298
Validation loss: 2.7461611367319083

Epoch: 6| Step: 2
Training loss: 0.8177693500147877
Validation loss: 2.705577729839483

Epoch: 6| Step: 3
Training loss: 0.5519037914434118
Validation loss: 2.745515490260645

Epoch: 6| Step: 4
Training loss: 0.7899965857178509
Validation loss: 2.73811677229254

Epoch: 6| Step: 5
Training loss: 0.6318454181602521
Validation loss: 2.716079013742572

Epoch: 6| Step: 6
Training loss: 0.6558290902848345
Validation loss: 2.7512865813805965

Epoch: 6| Step: 7
Training loss: 1.049152118217389
Validation loss: 2.6997540868221965

Epoch: 6| Step: 8
Training loss: 0.5600422571621552
Validation loss: 2.6703926346720723

Epoch: 6| Step: 9
Training loss: 0.41201175419349995
Validation loss: 2.695312573713956

Epoch: 6| Step: 10
Training loss: 0.8088780884522397
Validation loss: 2.7347578525455467

Epoch: 6| Step: 11
Training loss: 0.49151419953395636
Validation loss: 2.7006648634364123

Epoch: 6| Step: 12
Training loss: 0.6420447272053387
Validation loss: 2.677557540830906

Epoch: 6| Step: 13
Training loss: 0.9041938475875612
Validation loss: 2.69984982920634

Epoch: 480| Step: 0
Training loss: 0.49851375462907976
Validation loss: 2.7126808167764542

Epoch: 6| Step: 1
Training loss: 0.8207854224679373
Validation loss: 2.732909429251437

Epoch: 6| Step: 2
Training loss: 0.7537648755277375
Validation loss: 2.7021721573590365

Epoch: 6| Step: 3
Training loss: 0.5676129870593701
Validation loss: 2.7696823846482195

Epoch: 6| Step: 4
Training loss: 0.7258316794492301
Validation loss: 2.7345317904615296

Epoch: 6| Step: 5
Training loss: 0.8453645446888893
Validation loss: 2.7150332158341794

Epoch: 6| Step: 6
Training loss: 0.6183545872110747
Validation loss: 2.738220054534004

Epoch: 6| Step: 7
Training loss: 0.8610333481066914
Validation loss: 2.722355436019631

Epoch: 6| Step: 8
Training loss: 0.5887296398959229
Validation loss: 2.745701942329624

Epoch: 6| Step: 9
Training loss: 0.4348445755528883
Validation loss: 2.678628977505523

Epoch: 6| Step: 10
Training loss: 0.5483007102854566
Validation loss: 2.713877261173879

Epoch: 6| Step: 11
Training loss: 0.7729105069171209
Validation loss: 2.6802647657466547

Epoch: 6| Step: 12
Training loss: 0.5300513938961048
Validation loss: 2.671753075626783

Epoch: 6| Step: 13
Training loss: 0.7701228235180251
Validation loss: 2.7324505673352455

Epoch: 481| Step: 0
Training loss: 0.7133664150306338
Validation loss: 2.6811248364760103

Epoch: 6| Step: 1
Training loss: 0.45629448477860296
Validation loss: 2.6967569654676598

Epoch: 6| Step: 2
Training loss: 0.5107521070753375
Validation loss: 2.7105969921491955

Epoch: 6| Step: 3
Training loss: 0.9967742988642322
Validation loss: 2.7037129433453213

Epoch: 6| Step: 4
Training loss: 0.8303627513514438
Validation loss: 2.729936546955318

Epoch: 6| Step: 5
Training loss: 0.5604081995819578
Validation loss: 2.768289780095211

Epoch: 6| Step: 6
Training loss: 0.5500225496004412
Validation loss: 2.6880455202712046

Epoch: 6| Step: 7
Training loss: 0.6375191928741902
Validation loss: 2.7270844842506663

Epoch: 6| Step: 8
Training loss: 0.3406207749340956
Validation loss: 2.681561703410836

Epoch: 6| Step: 9
Training loss: 0.6290038133848276
Validation loss: 2.7064507666187363

Epoch: 6| Step: 10
Training loss: 0.8174368454223038
Validation loss: 2.6946489632276793

Epoch: 6| Step: 11
Training loss: 0.6910851374069445
Validation loss: 2.7088519602388064

Epoch: 6| Step: 12
Training loss: 0.4746063609086391
Validation loss: 2.7056623688653065

Epoch: 6| Step: 13
Training loss: 0.6579404131191696
Validation loss: 2.7598057316743034

Epoch: 482| Step: 0
Training loss: 0.5809206511468882
Validation loss: 2.724235744220926

Epoch: 6| Step: 1
Training loss: 0.9543898897439703
Validation loss: 2.7440380941583666

Epoch: 6| Step: 2
Training loss: 0.44919314104144464
Validation loss: 2.6992381822518676

Epoch: 6| Step: 3
Training loss: 0.4830765702622708
Validation loss: 2.689694787357552

Epoch: 6| Step: 4
Training loss: 0.5786705278494486
Validation loss: 2.694314906577565

Epoch: 6| Step: 5
Training loss: 0.5289225363090406
Validation loss: 2.665371473508774

Epoch: 6| Step: 6
Training loss: 0.6971477761572469
Validation loss: 2.7143829320524824

Epoch: 6| Step: 7
Training loss: 0.49960579829840834
Validation loss: 2.668884179868769

Epoch: 6| Step: 8
Training loss: 0.711153018688443
Validation loss: 2.7640539761115877

Epoch: 6| Step: 9
Training loss: 0.6309963349282759
Validation loss: 2.726476163326095

Epoch: 6| Step: 10
Training loss: 0.7136001191712181
Validation loss: 2.7312856751882855

Epoch: 6| Step: 11
Training loss: 0.8937554472643904
Validation loss: 2.7297349488607683

Epoch: 6| Step: 12
Training loss: 0.4357843649647892
Validation loss: 2.7187319787842252

Epoch: 6| Step: 13
Training loss: 0.4046385974867854
Validation loss: 2.7431991609306383

Epoch: 483| Step: 0
Training loss: 0.7217668989084103
Validation loss: 2.6917605081582643

Epoch: 6| Step: 1
Training loss: 0.6241812588505835
Validation loss: 2.6897716088933703

Epoch: 6| Step: 2
Training loss: 0.42027567663162674
Validation loss: 2.7188530533358635

Epoch: 6| Step: 3
Training loss: 0.6728905166843796
Validation loss: 2.7437065677203143

Epoch: 6| Step: 4
Training loss: 0.4489269801769632
Validation loss: 2.714947156514809

Epoch: 6| Step: 5
Training loss: 0.5667108177300941
Validation loss: 2.7321028215245495

Epoch: 6| Step: 6
Training loss: 0.7578061290355181
Validation loss: 2.729635145052502

Epoch: 6| Step: 7
Training loss: 0.692494328265599
Validation loss: 2.7165389442453804

Epoch: 6| Step: 8
Training loss: 0.7926094481406333
Validation loss: 2.712613206250206

Epoch: 6| Step: 9
Training loss: 0.625185914998332
Validation loss: 2.6871573799031347

Epoch: 6| Step: 10
Training loss: 0.6885578080524973
Validation loss: 2.680791147505088

Epoch: 6| Step: 11
Training loss: 0.2797746107101289
Validation loss: 2.707682917818714

Epoch: 6| Step: 12
Training loss: 0.4261065998664748
Validation loss: 2.722258032889765

Epoch: 6| Step: 13
Training loss: 0.6207783696040347
Validation loss: 2.7042819066661754

Epoch: 484| Step: 0
Training loss: 0.607445155246514
Validation loss: 2.7128278314451424

Epoch: 6| Step: 1
Training loss: 0.8473401864757869
Validation loss: 2.713809629207192

Epoch: 6| Step: 2
Training loss: 0.678490955736662
Validation loss: 2.7215616296175544

Epoch: 6| Step: 3
Training loss: 0.5939907539543944
Validation loss: 2.709227727270159

Epoch: 6| Step: 4
Training loss: 0.4640299621888882
Validation loss: 2.7032183518947424

Epoch: 6| Step: 5
Training loss: 0.34978898192589597
Validation loss: 2.7676503152524687

Epoch: 6| Step: 6
Training loss: 0.7509921187636182
Validation loss: 2.738174153408978

Epoch: 6| Step: 7
Training loss: 0.549643077779478
Validation loss: 2.7057499130574683

Epoch: 6| Step: 8
Training loss: 0.6949328768514886
Validation loss: 2.7396113874113452

Epoch: 6| Step: 9
Training loss: 0.5913503743916303
Validation loss: 2.7572637341598525

Epoch: 6| Step: 10
Training loss: 0.492208298743256
Validation loss: 2.7684352411677966

Epoch: 6| Step: 11
Training loss: 0.39738898598440914
Validation loss: 2.7392754230624496

Epoch: 6| Step: 12
Training loss: 0.4772281843977351
Validation loss: 2.6991970946514714

Epoch: 6| Step: 13
Training loss: 0.9594352578986876
Validation loss: 2.7270136972681853

Epoch: 485| Step: 0
Training loss: 0.7519657678903667
Validation loss: 2.7311128030474623

Epoch: 6| Step: 1
Training loss: 0.5520699487419228
Validation loss: 2.7567562569663426

Epoch: 6| Step: 2
Training loss: 0.4453934378435608
Validation loss: 2.6934766183719567

Epoch: 6| Step: 3
Training loss: 0.4874536137642464
Validation loss: 2.689014141350585

Epoch: 6| Step: 4
Training loss: 0.8132710832735393
Validation loss: 2.728598736985607

Epoch: 6| Step: 5
Training loss: 0.4425180493730826
Validation loss: 2.734778470744467

Epoch: 6| Step: 6
Training loss: 0.711388832447123
Validation loss: 2.668832411078038

Epoch: 6| Step: 7
Training loss: 0.7688665472244165
Validation loss: 2.723150616153884

Epoch: 6| Step: 8
Training loss: 0.7019701056106236
Validation loss: 2.7225389496370203

Epoch: 6| Step: 9
Training loss: 0.5569246872335735
Validation loss: 2.7186657976579736

Epoch: 6| Step: 10
Training loss: 0.6804127605541803
Validation loss: 2.745487556817901

Epoch: 6| Step: 11
Training loss: 0.6631688556317045
Validation loss: 2.746382298871956

Epoch: 6| Step: 12
Training loss: 0.511865551107946
Validation loss: 2.7291702872293544

Epoch: 6| Step: 13
Training loss: 0.4234201955602561
Validation loss: 2.751183746339721

Epoch: 486| Step: 0
Training loss: 0.4887120139685133
Validation loss: 2.750668892285212

Epoch: 6| Step: 1
Training loss: 0.49135015801298815
Validation loss: 2.732008631235082

Epoch: 6| Step: 2
Training loss: 0.7315763348522287
Validation loss: 2.7139151688935303

Epoch: 6| Step: 3
Training loss: 0.5529443187118558
Validation loss: 2.688679388293387

Epoch: 6| Step: 4
Training loss: 0.846999832750054
Validation loss: 2.6616117927119562

Epoch: 6| Step: 5
Training loss: 0.4301056301319628
Validation loss: 2.6968861137270173

Epoch: 6| Step: 6
Training loss: 0.41226992259515416
Validation loss: 2.7081441421941546

Epoch: 6| Step: 7
Training loss: 0.5717188074654558
Validation loss: 2.714822072919116

Epoch: 6| Step: 8
Training loss: 0.4706252734118879
Validation loss: 2.704873344666861

Epoch: 6| Step: 9
Training loss: 0.8909555457571274
Validation loss: 2.6953804044416496

Epoch: 6| Step: 10
Training loss: 0.6135161126281907
Validation loss: 2.724155941585489

Epoch: 6| Step: 11
Training loss: 0.6066459778342599
Validation loss: 2.704416220209561

Epoch: 6| Step: 12
Training loss: 0.4932584615572289
Validation loss: 2.7125717938791314

Epoch: 6| Step: 13
Training loss: 0.6640852082801622
Validation loss: 2.741795728326074

Epoch: 487| Step: 0
Training loss: 0.5204652693719986
Validation loss: 2.7117890001856173

Epoch: 6| Step: 1
Training loss: 0.6161842400862853
Validation loss: 2.6949206376053323

Epoch: 6| Step: 2
Training loss: 0.638684823841103
Validation loss: 2.746123355798135

Epoch: 6| Step: 3
Training loss: 0.7002783690156735
Validation loss: 2.7869643895648535

Epoch: 6| Step: 4
Training loss: 0.609244479359819
Validation loss: 2.6687818622101602

Epoch: 6| Step: 5
Training loss: 0.6400302591844683
Validation loss: 2.7740147164593187

Epoch: 6| Step: 6
Training loss: 0.4357285740673763
Validation loss: 2.7376725431322138

Epoch: 6| Step: 7
Training loss: 0.361890633365619
Validation loss: 2.7351222733776526

Epoch: 6| Step: 8
Training loss: 0.5905448082066268
Validation loss: 2.728367132662251

Epoch: 6| Step: 9
Training loss: 0.5681690802013281
Validation loss: 2.7215177544640707

Epoch: 6| Step: 10
Training loss: 0.410741805848703
Validation loss: 2.754356603570379

Epoch: 6| Step: 11
Training loss: 0.41407909000198345
Validation loss: 2.7369561501408426

Epoch: 6| Step: 12
Training loss: 0.8688767278986381
Validation loss: 2.7460234964499515

Epoch: 6| Step: 13
Training loss: 0.6467628685887865
Validation loss: 2.7380469090874096

Epoch: 488| Step: 0
Training loss: 0.9040190762304735
Validation loss: 2.737785203728919

Epoch: 6| Step: 1
Training loss: 0.5447444832125508
Validation loss: 2.7722650619777887

Epoch: 6| Step: 2
Training loss: 0.6295197616062884
Validation loss: 2.76231269258957

Epoch: 6| Step: 3
Training loss: 0.6773113502576461
Validation loss: 2.751940331701175

Epoch: 6| Step: 4
Training loss: 0.5597009955589024
Validation loss: 2.731123947970926

Epoch: 6| Step: 5
Training loss: 0.6886093119885488
Validation loss: 2.7655235386859798

Epoch: 6| Step: 6
Training loss: 0.5989388808256703
Validation loss: 2.7395302848369645

Epoch: 6| Step: 7
Training loss: 0.5081974038015359
Validation loss: 2.7044221121617293

Epoch: 6| Step: 8
Training loss: 0.5066802386559605
Validation loss: 2.6988774556318753

Epoch: 6| Step: 9
Training loss: 0.6207324242563727
Validation loss: 2.710234302559861

Epoch: 6| Step: 10
Training loss: 0.5988235045451996
Validation loss: 2.712444813484832

Epoch: 6| Step: 11
Training loss: 0.527621471601996
Validation loss: 2.7360210731997965

Epoch: 6| Step: 12
Training loss: 0.6653906611180204
Validation loss: 2.7637383155339963

Epoch: 6| Step: 13
Training loss: 0.5276913662770744
Validation loss: 2.7398180456145913

Epoch: 489| Step: 0
Training loss: 0.8561605504224488
Validation loss: 2.7659766050927566

Epoch: 6| Step: 1
Training loss: 0.4226282600541111
Validation loss: 2.7297076836844054

Epoch: 6| Step: 2
Training loss: 0.38282604582818147
Validation loss: 2.7232300396835054

Epoch: 6| Step: 3
Training loss: 0.47119618151522946
Validation loss: 2.6842944078704165

Epoch: 6| Step: 4
Training loss: 0.5294402093819129
Validation loss: 2.6773719533060576

Epoch: 6| Step: 5
Training loss: 0.5383888126086716
Validation loss: 2.757482838581597

Epoch: 6| Step: 6
Training loss: 0.4667263536373441
Validation loss: 2.701416887161659

Epoch: 6| Step: 7
Training loss: 0.6141470853288385
Validation loss: 2.716789006089955

Epoch: 6| Step: 8
Training loss: 0.67896168419931
Validation loss: 2.7063592073813947

Epoch: 6| Step: 9
Training loss: 0.3290468844035121
Validation loss: 2.729614240525438

Epoch: 6| Step: 10
Training loss: 0.6249664059193548
Validation loss: 2.730425585549749

Epoch: 6| Step: 11
Training loss: 0.639150830718829
Validation loss: 2.754755012895151

Epoch: 6| Step: 12
Training loss: 0.8974594431668564
Validation loss: 2.713817169984084

Epoch: 6| Step: 13
Training loss: 0.5286737694585857
Validation loss: 2.7615378328207125

Epoch: 490| Step: 0
Training loss: 0.6620112883795298
Validation loss: 2.7657468952105324

Epoch: 6| Step: 1
Training loss: 0.4393724155485673
Validation loss: 2.746800859338224

Epoch: 6| Step: 2
Training loss: 0.6731318317799826
Validation loss: 2.7574239282383775

Epoch: 6| Step: 3
Training loss: 0.4032048759873304
Validation loss: 2.7290798833507375

Epoch: 6| Step: 4
Training loss: 0.6768459466350546
Validation loss: 2.741655144092344

Epoch: 6| Step: 5
Training loss: 0.5565603365633864
Validation loss: 2.728962138328362

Epoch: 6| Step: 6
Training loss: 0.6428218483697136
Validation loss: 2.7377717781732236

Epoch: 6| Step: 7
Training loss: 0.8176024220552047
Validation loss: 2.7127296174773967

Epoch: 6| Step: 8
Training loss: 0.6319710116921033
Validation loss: 2.717954906674349

Epoch: 6| Step: 9
Training loss: 0.4453768432711803
Validation loss: 2.7045316619317354

Epoch: 6| Step: 10
Training loss: 0.6442454079925818
Validation loss: 2.7619671096169327

Epoch: 6| Step: 11
Training loss: 0.45093254247889225
Validation loss: 2.769633575973895

Epoch: 6| Step: 12
Training loss: 0.876869180650495
Validation loss: 2.783952236083696

Epoch: 6| Step: 13
Training loss: 0.7190590069821501
Validation loss: 2.7044851155759213

Epoch: 491| Step: 0
Training loss: 0.48132782405923735
Validation loss: 2.7082381500733304

Epoch: 6| Step: 1
Training loss: 0.7033608358966079
Validation loss: 2.723473636448006

Epoch: 6| Step: 2
Training loss: 0.6599799377831228
Validation loss: 2.765533517592453

Epoch: 6| Step: 3
Training loss: 0.7835759443273922
Validation loss: 2.766035706795062

Epoch: 6| Step: 4
Training loss: 0.5741508080387517
Validation loss: 2.7722660223261966

Epoch: 6| Step: 5
Training loss: 0.9248410049606551
Validation loss: 2.7840896854150237

Epoch: 6| Step: 6
Training loss: 0.5739289674902516
Validation loss: 2.7280127340189235

Epoch: 6| Step: 7
Training loss: 0.6321715653014558
Validation loss: 2.739988193161672

Epoch: 6| Step: 8
Training loss: 0.798614025571361
Validation loss: 2.7705311335542517

Epoch: 6| Step: 9
Training loss: 0.7285420512706631
Validation loss: 2.8466719961525957

Epoch: 6| Step: 10
Training loss: 0.6108448202172885
Validation loss: 2.7811053234860905

Epoch: 6| Step: 11
Training loss: 0.7020474760556391
Validation loss: 2.768389898438441

Epoch: 6| Step: 12
Training loss: 0.46625682283783737
Validation loss: 2.6957795922427135

Epoch: 6| Step: 13
Training loss: 0.39755113032922407
Validation loss: 2.709444013902379

Epoch: 492| Step: 0
Training loss: 0.6016771529288633
Validation loss: 2.7047844939724537

Epoch: 6| Step: 1
Training loss: 0.5243129526196149
Validation loss: 2.7204710675891857

Epoch: 6| Step: 2
Training loss: 0.7597474240670151
Validation loss: 2.7025223135460763

Epoch: 6| Step: 3
Training loss: 0.6022267328140721
Validation loss: 2.714492914231452

Epoch: 6| Step: 4
Training loss: 0.6236993129982711
Validation loss: 2.6735898885393805

Epoch: 6| Step: 5
Training loss: 0.6841148134445851
Validation loss: 2.706219733629137

Epoch: 6| Step: 6
Training loss: 0.5728026854677889
Validation loss: 2.7201725464559363

Epoch: 6| Step: 7
Training loss: 0.4507253179113287
Validation loss: 2.7149797657071515

Epoch: 6| Step: 8
Training loss: 0.6635214901845354
Validation loss: 2.684675343904507

Epoch: 6| Step: 9
Training loss: 0.4844112997912182
Validation loss: 2.725735120746524

Epoch: 6| Step: 10
Training loss: 0.38322562677577415
Validation loss: 2.7265605325336515

Epoch: 6| Step: 11
Training loss: 0.4628900455519514
Validation loss: 2.6816223247632505

Epoch: 6| Step: 12
Training loss: 0.5690177957738656
Validation loss: 2.7641005687920557

Epoch: 6| Step: 13
Training loss: 0.6869119817134437
Validation loss: 2.764041080682978

Epoch: 493| Step: 0
Training loss: 0.543581582437881
Validation loss: 2.741265644632446

Epoch: 6| Step: 1
Training loss: 0.44427722920341556
Validation loss: 2.734052381102547

Epoch: 6| Step: 2
Training loss: 0.5334469304203753
Validation loss: 2.7710759240749274

Epoch: 6| Step: 3
Training loss: 0.8937205676587819
Validation loss: 2.7620251030182845

Epoch: 6| Step: 4
Training loss: 0.5701270128418247
Validation loss: 2.7878887224789977

Epoch: 6| Step: 5
Training loss: 0.6512361820827127
Validation loss: 2.7287302080742295

Epoch: 6| Step: 6
Training loss: 0.5778390331788565
Validation loss: 2.833016817327769

Epoch: 6| Step: 7
Training loss: 0.7173355946942437
Validation loss: 2.7910337205055082

Epoch: 6| Step: 8
Training loss: 0.7570877542263429
Validation loss: 2.7331111493949343

Epoch: 6| Step: 9
Training loss: 0.8157517579480892
Validation loss: 2.753677120551696

Epoch: 6| Step: 10
Training loss: 0.5633189015496137
Validation loss: 2.752562946936054

Epoch: 6| Step: 11
Training loss: 0.6938505340452064
Validation loss: 2.728751803793772

Epoch: 6| Step: 12
Training loss: 0.5843665872060088
Validation loss: 2.743675791693458

Epoch: 6| Step: 13
Training loss: 0.5453400460092791
Validation loss: 2.767832620280635

Epoch: 494| Step: 0
Training loss: 0.5639411161641416
Validation loss: 2.7368754552663823

Epoch: 6| Step: 1
Training loss: 0.6461327509888397
Validation loss: 2.7383916871587806

Epoch: 6| Step: 2
Training loss: 0.9444140113028704
Validation loss: 2.7507828551842715

Epoch: 6| Step: 3
Training loss: 0.8059742833145359
Validation loss: 2.782845928627497

Epoch: 6| Step: 4
Training loss: 0.49646074132245954
Validation loss: 2.780071080120152

Epoch: 6| Step: 5
Training loss: 0.5406793313481443
Validation loss: 2.805929647397092

Epoch: 6| Step: 6
Training loss: 0.6738409289926504
Validation loss: 2.7724158039385403

Epoch: 6| Step: 7
Training loss: 0.577330171789333
Validation loss: 2.6734689341691955

Epoch: 6| Step: 8
Training loss: 0.5993501929359447
Validation loss: 2.717903531600447

Epoch: 6| Step: 9
Training loss: 0.3510070014877509
Validation loss: 2.7917617715226606

Epoch: 6| Step: 10
Training loss: 0.45204495920489507
Validation loss: 2.7655703580526674

Epoch: 6| Step: 11
Training loss: 0.4177186164002452
Validation loss: 2.7429528250685156

Epoch: 6| Step: 12
Training loss: 0.8333931106744018
Validation loss: 2.722299181137949

Epoch: 6| Step: 13
Training loss: 0.4946961879630004
Validation loss: 2.7711923457485987

Epoch: 495| Step: 0
Training loss: 0.4779414878171019
Validation loss: 2.722940117273624

Epoch: 6| Step: 1
Training loss: 0.6128901309612512
Validation loss: 2.7758999276015275

Epoch: 6| Step: 2
Training loss: 0.5773502519832466
Validation loss: 2.7196803346422853

Epoch: 6| Step: 3
Training loss: 0.6349944186528539
Validation loss: 2.7437886692296893

Epoch: 6| Step: 4
Training loss: 0.6623172489956064
Validation loss: 2.744615934031714

Epoch: 6| Step: 5
Training loss: 0.4980146360247788
Validation loss: 2.805266466658622

Epoch: 6| Step: 6
Training loss: 0.5528350037543878
Validation loss: 2.750555451968703

Epoch: 6| Step: 7
Training loss: 0.5170497284368649
Validation loss: 2.7457587018287706

Epoch: 6| Step: 8
Training loss: 0.4353819051430991
Validation loss: 2.7890791834627

Epoch: 6| Step: 9
Training loss: 0.39640423946750375
Validation loss: 2.734365263422025

Epoch: 6| Step: 10
Training loss: 0.730394329013097
Validation loss: 2.7384188005742773

Epoch: 6| Step: 11
Training loss: 0.3706815538471343
Validation loss: 2.6614843741758545

Epoch: 6| Step: 12
Training loss: 0.6663559969595187
Validation loss: 2.7557457950724573

Epoch: 6| Step: 13
Training loss: 0.4254353719528907
Validation loss: 2.6783110380006354

Epoch: 496| Step: 0
Training loss: 0.6728399577475763
Validation loss: 2.7162982365151724

Epoch: 6| Step: 1
Training loss: 0.4259938750319217
Validation loss: 2.7597101039030596

Epoch: 6| Step: 2
Training loss: 0.741022339802001
Validation loss: 2.7272604966130216

Epoch: 6| Step: 3
Training loss: 0.5021099632239557
Validation loss: 2.719631037698192

Epoch: 6| Step: 4
Training loss: 0.5151412312820719
Validation loss: 2.725159933780589

Epoch: 6| Step: 5
Training loss: 0.6054313402001363
Validation loss: 2.7164860357211977

Epoch: 6| Step: 6
Training loss: 0.5529549094713029
Validation loss: 2.676274609156376

Epoch: 6| Step: 7
Training loss: 0.6402799561004471
Validation loss: 2.7163837922347045

Epoch: 6| Step: 8
Training loss: 0.5614718471545076
Validation loss: 2.7308756643799015

Epoch: 6| Step: 9
Training loss: 0.5639943300936159
Validation loss: 2.8119317222380356

Epoch: 6| Step: 10
Training loss: 0.5981141374612117
Validation loss: 2.765692772905951

Epoch: 6| Step: 11
Training loss: 0.6222677591195063
Validation loss: 2.7247628409167137

Epoch: 6| Step: 12
Training loss: 0.7236816966318884
Validation loss: 2.7174743641308288

Epoch: 6| Step: 13
Training loss: 0.5699290201263467
Validation loss: 2.748631801680485

Epoch: 497| Step: 0
Training loss: 0.5192820015652942
Validation loss: 2.7762107630623065

Epoch: 6| Step: 1
Training loss: 0.7993581640932702
Validation loss: 2.734270409899821

Epoch: 6| Step: 2
Training loss: 0.4277547369861335
Validation loss: 2.7650222408832703

Epoch: 6| Step: 3
Training loss: 0.453287227134916
Validation loss: 2.7467388844100653

Epoch: 6| Step: 4
Training loss: 0.43904384627713355
Validation loss: 2.745454861302925

Epoch: 6| Step: 5
Training loss: 0.7110439681932331
Validation loss: 2.77539353143449

Epoch: 6| Step: 6
Training loss: 0.5568853007861304
Validation loss: 2.776670636368471

Epoch: 6| Step: 7
Training loss: 0.5675165278174797
Validation loss: 2.7612812823435693

Epoch: 6| Step: 8
Training loss: 0.7578082526962967
Validation loss: 2.726091273119679

Epoch: 6| Step: 9
Training loss: 0.47306487650053214
Validation loss: 2.7293632718000156

Epoch: 6| Step: 10
Training loss: 0.6367075398400264
Validation loss: 2.7813562737209487

Epoch: 6| Step: 11
Training loss: 0.5823841944990341
Validation loss: 2.7673062604007073

Epoch: 6| Step: 12
Training loss: 0.5682233667354464
Validation loss: 2.771613439055339

Epoch: 6| Step: 13
Training loss: 0.599488932786586
Validation loss: 2.7620058823186104

Epoch: 498| Step: 0
Training loss: 0.7102299197754516
Validation loss: 2.76732561659589

Epoch: 6| Step: 1
Training loss: 0.5814563292720879
Validation loss: 2.730586510093987

Epoch: 6| Step: 2
Training loss: 0.36367813088581197
Validation loss: 2.787189741787061

Epoch: 6| Step: 3
Training loss: 0.5001768157172507
Validation loss: 2.744569763440382

Epoch: 6| Step: 4
Training loss: 0.45286401270047505
Validation loss: 2.7801361139397587

Epoch: 6| Step: 5
Training loss: 0.46489580648315176
Validation loss: 2.728064996584577

Epoch: 6| Step: 6
Training loss: 0.49883804311429053
Validation loss: 2.7721504914587745

Epoch: 6| Step: 7
Training loss: 0.6211020990926157
Validation loss: 2.7379631695774593

Epoch: 6| Step: 8
Training loss: 0.6685844394706861
Validation loss: 2.7075924715903854

Epoch: 6| Step: 9
Training loss: 0.5493215603056817
Validation loss: 2.6979990667968825

Epoch: 6| Step: 10
Training loss: 0.4453888208673589
Validation loss: 2.7199610209009504

Epoch: 6| Step: 11
Training loss: 0.6605334586794943
Validation loss: 2.7421354196498915

Epoch: 6| Step: 12
Training loss: 1.004455594221992
Validation loss: 2.7074029106797237

Epoch: 6| Step: 13
Training loss: 0.6107956392316156
Validation loss: 2.7084820975503705

Epoch: 499| Step: 0
Training loss: 0.44442268614689423
Validation loss: 2.716767117821604

Epoch: 6| Step: 1
Training loss: 0.725176812677488
Validation loss: 2.7043259439059057

Epoch: 6| Step: 2
Training loss: 0.6783057011624118
Validation loss: 2.76699825180379

Epoch: 6| Step: 3
Training loss: 0.7951904143214293
Validation loss: 2.73500653921086

Epoch: 6| Step: 4
Training loss: 0.6190933065052282
Validation loss: 2.791738357382571

Epoch: 6| Step: 5
Training loss: 0.5742888115939656
Validation loss: 2.691543213893937

Epoch: 6| Step: 6
Training loss: 0.45658983612210663
Validation loss: 2.689150000623898

Epoch: 6| Step: 7
Training loss: 0.47112249157026004
Validation loss: 2.675632281460946

Epoch: 6| Step: 8
Training loss: 0.582447031502499
Validation loss: 2.7120522983674373

Epoch: 6| Step: 9
Training loss: 0.4351449831423436
Validation loss: 2.7329781951895202

Epoch: 6| Step: 10
Training loss: 0.5472319391789631
Validation loss: 2.699993738120082

Epoch: 6| Step: 11
Training loss: 0.6255576745162627
Validation loss: 2.7342971354705994

Epoch: 6| Step: 12
Training loss: 0.5600123498610702
Validation loss: 2.714803542610121

Epoch: 6| Step: 13
Training loss: 0.5262541357589183
Validation loss: 2.714996333602762

Epoch: 500| Step: 0
Training loss: 0.7155431858921008
Validation loss: 2.684121248022241

Epoch: 6| Step: 1
Training loss: 0.3307593161690252
Validation loss: 2.7148394028882685

Epoch: 6| Step: 2
Training loss: 0.34019332752005665
Validation loss: 2.7455200927384475

Epoch: 6| Step: 3
Training loss: 0.46977842683031995
Validation loss: 2.7187314379997485

Epoch: 6| Step: 4
Training loss: 0.5072721394012335
Validation loss: 2.7158945661697875

Epoch: 6| Step: 5
Training loss: 0.4771183867951889
Validation loss: 2.7605854102806577

Epoch: 6| Step: 6
Training loss: 0.5396779182436116
Validation loss: 2.755567694281773

Epoch: 6| Step: 7
Training loss: 0.7675990133379568
Validation loss: 2.7679470393382495

Epoch: 6| Step: 8
Training loss: 0.4670358150051046
Validation loss: 2.7850191101295194

Epoch: 6| Step: 9
Training loss: 0.5040081128212999
Validation loss: 2.802719006291342

Epoch: 6| Step: 10
Training loss: 0.6813171406129359
Validation loss: 2.7718158117810963

Epoch: 6| Step: 11
Training loss: 0.515974966406709
Validation loss: 2.7521108848777067

Epoch: 6| Step: 12
Training loss: 0.3270421211232876
Validation loss: 2.7772729420208964

Epoch: 6| Step: 13
Training loss: 0.6943158926129329
Validation loss: 2.724618213051302

Epoch: 501| Step: 0
Training loss: 0.5383981674626525
Validation loss: 2.7121828646810155

Epoch: 6| Step: 1
Training loss: 0.7712968815754707
Validation loss: 2.793837661562613

Epoch: 6| Step: 2
Training loss: 0.7399767424820646
Validation loss: 2.7449059411328287

Epoch: 6| Step: 3
Training loss: 0.5361710553869592
Validation loss: 2.721336851414742

Epoch: 6| Step: 4
Training loss: 0.5874895521005987
Validation loss: 2.706924942813637

Epoch: 6| Step: 5
Training loss: 0.46885296962200734
Validation loss: 2.7469602025531437

Epoch: 6| Step: 6
Training loss: 0.40440054038989887
Validation loss: 2.6744191510611692

Epoch: 6| Step: 7
Training loss: 0.5592587121038495
Validation loss: 2.7426983827458007

Epoch: 6| Step: 8
Training loss: 0.6981626665409492
Validation loss: 2.7472257781469125

Epoch: 6| Step: 9
Training loss: 0.4791566564371247
Validation loss: 2.6881755748592266

Epoch: 6| Step: 10
Training loss: 0.41805332433366355
Validation loss: 2.667763817113491

Epoch: 6| Step: 11
Training loss: 0.4844777244421189
Validation loss: 2.7158991164271815

Epoch: 6| Step: 12
Training loss: 0.4200002020596972
Validation loss: 2.6907669585228535

Epoch: 6| Step: 13
Training loss: 0.5911900143911164
Validation loss: 2.726323697509167

Epoch: 502| Step: 0
Training loss: 0.6487443496663844
Validation loss: 2.719898522064149

Epoch: 6| Step: 1
Training loss: 0.3960511796033871
Validation loss: 2.73878666616271

Epoch: 6| Step: 2
Training loss: 0.3615386349674502
Validation loss: 2.704210405236017

Epoch: 6| Step: 3
Training loss: 0.5015304507654983
Validation loss: 2.688516335932752

Epoch: 6| Step: 4
Training loss: 0.3262620789750944
Validation loss: 2.7111870671881664

Epoch: 6| Step: 5
Training loss: 0.592900572062638
Validation loss: 2.7142225108161697

Epoch: 6| Step: 6
Training loss: 0.6177055502491654
Validation loss: 2.724921037538987

Epoch: 6| Step: 7
Training loss: 0.6669700697084325
Validation loss: 2.807610783224127

Epoch: 6| Step: 8
Training loss: 0.5867276776443465
Validation loss: 2.751045274040017

Epoch: 6| Step: 9
Training loss: 0.44863452238455376
Validation loss: 2.7511368193535364

Epoch: 6| Step: 10
Training loss: 0.32548468834158406
Validation loss: 2.747514815563906

Epoch: 6| Step: 11
Training loss: 0.8629627589636498
Validation loss: 2.7342035875634485

Epoch: 6| Step: 12
Training loss: 0.5704401213108296
Validation loss: 2.738874689464718

Epoch: 6| Step: 13
Training loss: 0.463692674435462
Validation loss: 2.72464986062364

Epoch: 503| Step: 0
Training loss: 0.38807175662697957
Validation loss: 2.745362590983434

Epoch: 6| Step: 1
Training loss: 0.27917371048272943
Validation loss: 2.768887493890248

Epoch: 6| Step: 2
Training loss: 0.6626068317000114
Validation loss: 2.758282398971393

Epoch: 6| Step: 3
Training loss: 0.5526294406452734
Validation loss: 2.7694631549335376

Epoch: 6| Step: 4
Training loss: 0.6002962731983639
Validation loss: 2.788868004208603

Epoch: 6| Step: 5
Training loss: 0.7178545640005763
Validation loss: 2.7271312422851053

Epoch: 6| Step: 6
Training loss: 0.5515500377943773
Validation loss: 2.7089209774916867

Epoch: 6| Step: 7
Training loss: 0.49545569952141566
Validation loss: 2.7763514295218696

Epoch: 6| Step: 8
Training loss: 0.5576794484348275
Validation loss: 2.823661766863382

Epoch: 6| Step: 9
Training loss: 0.5294249826499993
Validation loss: 2.7837135034368963

Epoch: 6| Step: 10
Training loss: 0.5910072220169016
Validation loss: 2.732035015315595

Epoch: 6| Step: 11
Training loss: 0.5115767420217616
Validation loss: 2.746199944488093

Epoch: 6| Step: 12
Training loss: 0.5102425167875102
Validation loss: 2.7303039180863355

Epoch: 6| Step: 13
Training loss: 0.7519711182658505
Validation loss: 2.705235673376764

Epoch: 504| Step: 0
Training loss: 0.5770508349617613
Validation loss: 2.7109088731293154

Epoch: 6| Step: 1
Training loss: 0.4727777057055697
Validation loss: 2.7319112086465607

Epoch: 6| Step: 2
Training loss: 0.6042021023015759
Validation loss: 2.7369884462982643

Epoch: 6| Step: 3
Training loss: 0.7392552727236136
Validation loss: 2.7050395792981776

Epoch: 6| Step: 4
Training loss: 0.5955308008307876
Validation loss: 2.7209609822993857

Epoch: 6| Step: 5
Training loss: 0.6002585410352904
Validation loss: 2.736402715246765

Epoch: 6| Step: 6
Training loss: 0.5023211009850901
Validation loss: 2.756743918385452

Epoch: 6| Step: 7
Training loss: 0.5065141953929648
Validation loss: 2.7464379013109035

Epoch: 6| Step: 8
Training loss: 0.45065740672497995
Validation loss: 2.7181308085085027

Epoch: 6| Step: 9
Training loss: 0.701532255340662
Validation loss: 2.7329651749401247

Epoch: 6| Step: 10
Training loss: 0.47482999532547704
Validation loss: 2.708039353383359

Epoch: 6| Step: 11
Training loss: 0.600915412159673
Validation loss: 2.720932497395478

Epoch: 6| Step: 12
Training loss: 0.25864959413454935
Validation loss: 2.655404842782753

Epoch: 6| Step: 13
Training loss: 0.5963254585741247
Validation loss: 2.724442511294752

Epoch: 505| Step: 0
Training loss: 0.5160616557449433
Validation loss: 2.69036056512839

Epoch: 6| Step: 1
Training loss: 0.6286209596666018
Validation loss: 2.7412339134689425

Epoch: 6| Step: 2
Training loss: 0.49742304309763535
Validation loss: 2.701265051671968

Epoch: 6| Step: 3
Training loss: 0.7142176152873116
Validation loss: 2.7081292784676356

Epoch: 6| Step: 4
Training loss: 0.5311588882405007
Validation loss: 2.710013533531452

Epoch: 6| Step: 5
Training loss: 0.4930914192707919
Validation loss: 2.682546812101137

Epoch: 6| Step: 6
Training loss: 0.6619600110667757
Validation loss: 2.7059776380535507

Epoch: 6| Step: 7
Training loss: 0.5794310637490929
Validation loss: 2.7321552094679844

Epoch: 6| Step: 8
Training loss: 0.39597887784926916
Validation loss: 2.768651538300817

Epoch: 6| Step: 9
Training loss: 0.5982612091238627
Validation loss: 2.731619080048927

Epoch: 6| Step: 10
Training loss: 0.5594327800893845
Validation loss: 2.7170353301925103

Epoch: 6| Step: 11
Training loss: 0.5326558193161405
Validation loss: 2.7459703601303485

Epoch: 6| Step: 12
Training loss: 0.5680965064764757
Validation loss: 2.7110755511485363

Epoch: 6| Step: 13
Training loss: 0.44540288911296966
Validation loss: 2.7304196332844284

Epoch: 506| Step: 0
Training loss: 0.5512780458318169
Validation loss: 2.7520734888363227

Epoch: 6| Step: 1
Training loss: 0.6253413222045956
Validation loss: 2.7039202363788575

Epoch: 6| Step: 2
Training loss: 0.5210169150742201
Validation loss: 2.791639361081929

Epoch: 6| Step: 3
Training loss: 0.7626786663666412
Validation loss: 2.7313091565555676

Epoch: 6| Step: 4
Training loss: 0.6032014788429892
Validation loss: 2.7926568984280267

Epoch: 6| Step: 5
Training loss: 0.3633809106777138
Validation loss: 2.7991545638329747

Epoch: 6| Step: 6
Training loss: 0.4298023763898013
Validation loss: 2.7703003956429355

Epoch: 6| Step: 7
Training loss: 0.7972397063180805
Validation loss: 2.7273290079563983

Epoch: 6| Step: 8
Training loss: 0.7475836293060439
Validation loss: 2.7390542093497143

Epoch: 6| Step: 9
Training loss: 0.45207485646622825
Validation loss: 2.7690992354675013

Epoch: 6| Step: 10
Training loss: 0.5403561204607598
Validation loss: 2.730276207417983

Epoch: 6| Step: 11
Training loss: 0.46628465840689437
Validation loss: 2.770091026706382

Epoch: 6| Step: 12
Training loss: 0.44479498992262106
Validation loss: 2.779493141348389

Epoch: 6| Step: 13
Training loss: 0.3924728745909655
Validation loss: 2.737519379987006

Epoch: 507| Step: 0
Training loss: 0.6661721769904607
Validation loss: 2.7549221753149458

Epoch: 6| Step: 1
Training loss: 0.6384465464633982
Validation loss: 2.7453776873435722

Epoch: 6| Step: 2
Training loss: 0.49924787934855275
Validation loss: 2.765759107423755

Epoch: 6| Step: 3
Training loss: 0.5066305049217856
Validation loss: 2.7861699225406373

Epoch: 6| Step: 4
Training loss: 0.5941756379233581
Validation loss: 2.7623563944917042

Epoch: 6| Step: 5
Training loss: 0.6400155680968324
Validation loss: 2.7597383541443503

Epoch: 6| Step: 6
Training loss: 0.6150597218459565
Validation loss: 2.7214053257174804

Epoch: 6| Step: 7
Training loss: 0.5941799012895299
Validation loss: 2.7089949362176973

Epoch: 6| Step: 8
Training loss: 0.48830102499018957
Validation loss: 2.690617793269591

Epoch: 6| Step: 9
Training loss: 0.38126879473776737
Validation loss: 2.7045984239930547

Epoch: 6| Step: 10
Training loss: 0.4887769700436052
Validation loss: 2.798347156741193

Epoch: 6| Step: 11
Training loss: 0.5005395183853202
Validation loss: 2.6862724147173287

Epoch: 6| Step: 12
Training loss: 0.538746450903724
Validation loss: 2.7201973581239973

Epoch: 6| Step: 13
Training loss: 0.4873879004241393
Validation loss: 2.7229638895046975

Epoch: 508| Step: 0
Training loss: 0.5645073465354105
Validation loss: 2.711591731417254

Epoch: 6| Step: 1
Training loss: 0.713734083382331
Validation loss: 2.730634619714148

Epoch: 6| Step: 2
Training loss: 0.633383552124635
Validation loss: 2.7118303072867973

Epoch: 6| Step: 3
Training loss: 0.6207334805094522
Validation loss: 2.740143205028289

Epoch: 6| Step: 4
Training loss: 0.4195357743344282
Validation loss: 2.7784767468865925

Epoch: 6| Step: 5
Training loss: 0.5944092002439658
Validation loss: 2.713080988833621

Epoch: 6| Step: 6
Training loss: 0.4883254374537332
Validation loss: 2.739306088961102

Epoch: 6| Step: 7
Training loss: 0.38206950895176
Validation loss: 2.73122326090721

Epoch: 6| Step: 8
Training loss: 0.29212680635069266
Validation loss: 2.7340824370319137

Epoch: 6| Step: 9
Training loss: 0.3633624160498272
Validation loss: 2.7623877104064842

Epoch: 6| Step: 10
Training loss: 0.7120260770608565
Validation loss: 2.7812843177764117

Epoch: 6| Step: 11
Training loss: 0.40321047490336887
Validation loss: 2.7697659542348343

Epoch: 6| Step: 12
Training loss: 0.6951013737439534
Validation loss: 2.790433438095798

Epoch: 6| Step: 13
Training loss: 0.44712904131489095
Validation loss: 2.754385976288382

Epoch: 509| Step: 0
Training loss: 0.5886868126283304
Validation loss: 2.71096839850532

Epoch: 6| Step: 1
Training loss: 0.42000075198287856
Validation loss: 2.727251696264693

Epoch: 6| Step: 2
Training loss: 0.3982344091085139
Validation loss: 2.7542768513102183

Epoch: 6| Step: 3
Training loss: 0.4423140920858607
Validation loss: 2.7408131255389496

Epoch: 6| Step: 4
Training loss: 0.7118218758632376
Validation loss: 2.7822532273158793

Epoch: 6| Step: 5
Training loss: 0.5119509570505038
Validation loss: 2.7248933960830444

Epoch: 6| Step: 6
Training loss: 0.5756982440718283
Validation loss: 2.7465743634152227

Epoch: 6| Step: 7
Training loss: 0.5182468628537686
Validation loss: 2.7532095963596777

Epoch: 6| Step: 8
Training loss: 0.7125413012664157
Validation loss: 2.7623751380515644

Epoch: 6| Step: 9
Training loss: 0.4779678479149029
Validation loss: 2.744551332629943

Epoch: 6| Step: 10
Training loss: 0.37792763721787204
Validation loss: 2.749645831681164

Epoch: 6| Step: 11
Training loss: 0.6863951474999697
Validation loss: 2.7357044366881937

Epoch: 6| Step: 12
Training loss: 0.6059430633336743
Validation loss: 2.7532312454235606

Epoch: 6| Step: 13
Training loss: 0.4507188710864043
Validation loss: 2.76069225639005

Epoch: 510| Step: 0
Training loss: 0.8708414986940954
Validation loss: 2.759545348263721

Epoch: 6| Step: 1
Training loss: 0.5131354195934285
Validation loss: 2.8034126550910643

Epoch: 6| Step: 2
Training loss: 0.5171945554131021
Validation loss: 2.7259365044496913

Epoch: 6| Step: 3
Training loss: 0.3448684875714039
Validation loss: 2.7198274750082985

Epoch: 6| Step: 4
Training loss: 0.6231177119342525
Validation loss: 2.744347463394492

Epoch: 6| Step: 5
Training loss: 0.5126883660708735
Validation loss: 2.7281561769245783

Epoch: 6| Step: 6
Training loss: 0.39244272734466606
Validation loss: 2.721376356311236

Epoch: 6| Step: 7
Training loss: 0.5357656420205651
Validation loss: 2.6989170610655266

Epoch: 6| Step: 8
Training loss: 0.553175975584269
Validation loss: 2.777791548270955

Epoch: 6| Step: 9
Training loss: 0.48554769195217845
Validation loss: 2.6998706330401627

Epoch: 6| Step: 10
Training loss: 0.5233018044472523
Validation loss: 2.7450645692338274

Epoch: 6| Step: 11
Training loss: 0.5288848962797845
Validation loss: 2.710831448608769

Epoch: 6| Step: 12
Training loss: 0.4794409233083432
Validation loss: 2.7773924661004146

Epoch: 6| Step: 13
Training loss: 0.7501397002765753
Validation loss: 2.749825125249223

Epoch: 511| Step: 0
Training loss: 0.7932275058647965
Validation loss: 2.73857822521983

Epoch: 6| Step: 1
Training loss: 0.4153981887791671
Validation loss: 2.704050438552514

Epoch: 6| Step: 2
Training loss: 0.4158946474787063
Validation loss: 2.7267932958120107

Epoch: 6| Step: 3
Training loss: 0.5319097013169359
Validation loss: 2.7055362685280038

Epoch: 6| Step: 4
Training loss: 0.39443893107887684
Validation loss: 2.705876282457907

Epoch: 6| Step: 5
Training loss: 0.4153604497275357
Validation loss: 2.664035681387265

Epoch: 6| Step: 6
Training loss: 0.5786813430351477
Validation loss: 2.7047549204996826

Epoch: 6| Step: 7
Training loss: 0.5416842573928655
Validation loss: 2.7301320753881324

Epoch: 6| Step: 8
Training loss: 0.430418987132511
Validation loss: 2.702968530407737

Epoch: 6| Step: 9
Training loss: 0.8415096350496218
Validation loss: 2.767971157180955

Epoch: 6| Step: 10
Training loss: 0.5490142940925586
Validation loss: 2.7076056211891757

Epoch: 6| Step: 11
Training loss: 0.6256813150492102
Validation loss: 2.702121320431487

Epoch: 6| Step: 12
Training loss: 0.6360936753365031
Validation loss: 2.7317942329522182

Epoch: 6| Step: 13
Training loss: 0.5196742671215402
Validation loss: 2.707521417156786

Epoch: 512| Step: 0
Training loss: 0.5213155866201574
Validation loss: 2.7006340088973966

Epoch: 6| Step: 1
Training loss: 0.35885312708172123
Validation loss: 2.725171380092982

Epoch: 6| Step: 2
Training loss: 0.5126927548299298
Validation loss: 2.7245105793860076

Epoch: 6| Step: 3
Training loss: 0.6200306749446469
Validation loss: 2.732203291465922

Epoch: 6| Step: 4
Training loss: 0.4275387181489341
Validation loss: 2.7813228497626112

Epoch: 6| Step: 5
Training loss: 0.6978293739120273
Validation loss: 2.7207684825122342

Epoch: 6| Step: 6
Training loss: 0.41318838954766884
Validation loss: 2.7340856199180457

Epoch: 6| Step: 7
Training loss: 0.5528206370408771
Validation loss: 2.752116638625068

Epoch: 6| Step: 8
Training loss: 0.48078229024462754
Validation loss: 2.7575547599485284

Epoch: 6| Step: 9
Training loss: 0.6115879323327029
Validation loss: 2.7765763837173476

Epoch: 6| Step: 10
Training loss: 0.5118802521917084
Validation loss: 2.792688699833742

Epoch: 6| Step: 11
Training loss: 0.6283651832161302
Validation loss: 2.7720159908363726

Epoch: 6| Step: 12
Training loss: 0.425382655045432
Validation loss: 2.798394371224332

Epoch: 6| Step: 13
Training loss: 0.40025154117165995
Validation loss: 2.766564046343027

Epoch: 513| Step: 0
Training loss: 0.655169369297604
Validation loss: 2.737833056228124

Epoch: 6| Step: 1
Training loss: 0.6686132790391627
Validation loss: 2.7512679067072576

Epoch: 6| Step: 2
Training loss: 0.5382280663957147
Validation loss: 2.782554006449431

Epoch: 6| Step: 3
Training loss: 0.5289866534245857
Validation loss: 2.740121786098006

Epoch: 6| Step: 4
Training loss: 0.6319819993491692
Validation loss: 2.7680619848133823

Epoch: 6| Step: 5
Training loss: 0.4860528373606406
Validation loss: 2.7139102346239605

Epoch: 6| Step: 6
Training loss: 0.4456948596345093
Validation loss: 2.7352138722057826

Epoch: 6| Step: 7
Training loss: 0.4037668559450268
Validation loss: 2.6883222815358767

Epoch: 6| Step: 8
Training loss: 0.5086824448181181
Validation loss: 2.7458737946820526

Epoch: 6| Step: 9
Training loss: 0.6998164856001616
Validation loss: 2.72948106503026

Epoch: 6| Step: 10
Training loss: 0.5774976058183723
Validation loss: 2.712883623597952

Epoch: 6| Step: 11
Training loss: 0.5153174205427126
Validation loss: 2.7548908610802756

Epoch: 6| Step: 12
Training loss: 0.5420343056199792
Validation loss: 2.760226712198911

Epoch: 6| Step: 13
Training loss: 0.9150982718512152
Validation loss: 2.733223772663806

Epoch: 514| Step: 0
Training loss: 0.5676530204447977
Validation loss: 2.799332141416126

Epoch: 6| Step: 1
Training loss: 0.4062957004371263
Validation loss: 2.7528719066570217

Epoch: 6| Step: 2
Training loss: 0.7189431967441192
Validation loss: 2.7735907713754973

Epoch: 6| Step: 3
Training loss: 0.5663241622897728
Validation loss: 2.77433053266549

Epoch: 6| Step: 4
Training loss: 0.5490645310131498
Validation loss: 2.7457763792353047

Epoch: 6| Step: 5
Training loss: 0.4644768974309793
Validation loss: 2.799117767900205

Epoch: 6| Step: 6
Training loss: 0.36525897590893014
Validation loss: 2.787966144970105

Epoch: 6| Step: 7
Training loss: 0.5540786410334944
Validation loss: 2.713950030643406

Epoch: 6| Step: 8
Training loss: 0.622172875685136
Validation loss: 2.7569995867138872

Epoch: 6| Step: 9
Training loss: 0.7058026931204345
Validation loss: 2.803479982237845

Epoch: 6| Step: 10
Training loss: 0.5838841891389478
Validation loss: 2.7584357777574984

Epoch: 6| Step: 11
Training loss: 0.5696332361405652
Validation loss: 2.703764867296404

Epoch: 6| Step: 12
Training loss: 0.5211567510355525
Validation loss: 2.738263313789777

Epoch: 6| Step: 13
Training loss: 0.6688532633691913
Validation loss: 2.740552489054749

Epoch: 515| Step: 0
Training loss: 0.494586577491865
Validation loss: 2.711543503746371

Epoch: 6| Step: 1
Training loss: 0.5017306951944035
Validation loss: 2.768619862663367

Epoch: 6| Step: 2
Training loss: 0.7120653365889061
Validation loss: 2.773596072253026

Epoch: 6| Step: 3
Training loss: 0.5783575466631576
Validation loss: 2.791834033864485

Epoch: 6| Step: 4
Training loss: 0.6619328401344081
Validation loss: 2.762402656186459

Epoch: 6| Step: 5
Training loss: 0.4897500795789793
Validation loss: 2.7073900536368862

Epoch: 6| Step: 6
Training loss: 0.7397872661551727
Validation loss: 2.7852759707821124

Epoch: 6| Step: 7
Training loss: 0.4325081233546148
Validation loss: 2.774965608515428

Epoch: 6| Step: 8
Training loss: 0.7580203528326483
Validation loss: 2.733103225682916

Epoch: 6| Step: 9
Training loss: 0.5355497987585301
Validation loss: 2.790665793467806

Epoch: 6| Step: 10
Training loss: 0.409888370773974
Validation loss: 2.7517019914877743

Epoch: 6| Step: 11
Training loss: 0.5882936281317918
Validation loss: 2.7262101114192228

Epoch: 6| Step: 12
Training loss: 0.6195561551912373
Validation loss: 2.7814112127207764

Epoch: 6| Step: 13
Training loss: 0.47559699764354774
Validation loss: 2.777353707897936

Epoch: 516| Step: 0
Training loss: 0.47728351081807724
Validation loss: 2.7799133846571156

Epoch: 6| Step: 1
Training loss: 0.7451607827648442
Validation loss: 2.727231210575647

Epoch: 6| Step: 2
Training loss: 0.46126987305915335
Validation loss: 2.743112551154693

Epoch: 6| Step: 3
Training loss: 0.45167180226750625
Validation loss: 2.7645430091690177

Epoch: 6| Step: 4
Training loss: 0.5034755078204873
Validation loss: 2.758963268259965

Epoch: 6| Step: 5
Training loss: 0.80179843962278
Validation loss: 2.777831888201643

Epoch: 6| Step: 6
Training loss: 0.6694567430807783
Validation loss: 2.7536477547029117

Epoch: 6| Step: 7
Training loss: 0.3486353769929314
Validation loss: 2.7850024594171097

Epoch: 6| Step: 8
Training loss: 0.48849651931939997
Validation loss: 2.766523628290694

Epoch: 6| Step: 9
Training loss: 0.5040808382618425
Validation loss: 2.797178994250613

Epoch: 6| Step: 10
Training loss: 0.49151756469254576
Validation loss: 2.774928635031837

Epoch: 6| Step: 11
Training loss: 0.6485407643649398
Validation loss: 2.78277022001036

Epoch: 6| Step: 12
Training loss: 0.648109467963133
Validation loss: 2.7884540766878407

Epoch: 6| Step: 13
Training loss: 0.6931291654717888
Validation loss: 2.7773537007442863

Epoch: 517| Step: 0
Training loss: 0.478983358551027
Validation loss: 2.7839995376889806

Epoch: 6| Step: 1
Training loss: 0.6284091951814459
Validation loss: 2.729179707464458

Epoch: 6| Step: 2
Training loss: 0.43181375337000016
Validation loss: 2.7577897486049916

Epoch: 6| Step: 3
Training loss: 0.7547288271248728
Validation loss: 2.7965411336806323

Epoch: 6| Step: 4
Training loss: 0.6832147037840116
Validation loss: 2.7783047229260194

Epoch: 6| Step: 5
Training loss: 0.37567747035240856
Validation loss: 2.7483018920824187

Epoch: 6| Step: 6
Training loss: 0.6351024966233353
Validation loss: 2.772421909696721

Epoch: 6| Step: 7
Training loss: 0.7625996899708963
Validation loss: 2.732500767290357

Epoch: 6| Step: 8
Training loss: 0.544610867912097
Validation loss: 2.7097934283932217

Epoch: 6| Step: 9
Training loss: 0.5314157451800908
Validation loss: 2.7435575506079926

Epoch: 6| Step: 10
Training loss: 0.5517525731741012
Validation loss: 2.7335212609963455

Epoch: 6| Step: 11
Training loss: 0.5137940178180261
Validation loss: 2.7417784093175297

Epoch: 6| Step: 12
Training loss: 0.6790768960900517
Validation loss: 2.748461018155009

Epoch: 6| Step: 13
Training loss: 0.5337279814169671
Validation loss: 2.750337348822556

Epoch: 518| Step: 0
Training loss: 0.5790632727381598
Validation loss: 2.7813144347767027

Epoch: 6| Step: 1
Training loss: 0.40137051026391296
Validation loss: 2.770932724013837

Epoch: 6| Step: 2
Training loss: 0.5757668316095621
Validation loss: 2.7335774157641985

Epoch: 6| Step: 3
Training loss: 0.5374166823284762
Validation loss: 2.7737851350360363

Epoch: 6| Step: 4
Training loss: 0.7870406506544775
Validation loss: 2.7606753725904745

Epoch: 6| Step: 5
Training loss: 0.5042587939598656
Validation loss: 2.7688100545669205

Epoch: 6| Step: 6
Training loss: 0.6759003109870982
Validation loss: 2.7604565359631237

Epoch: 6| Step: 7
Training loss: 0.3851506586810297
Validation loss: 2.717750292437416

Epoch: 6| Step: 8
Training loss: 0.5198791601001282
Validation loss: 2.748747764483565

Epoch: 6| Step: 9
Training loss: 0.42479700541949417
Validation loss: 2.787443558445109

Epoch: 6| Step: 10
Training loss: 0.5028211754334376
Validation loss: 2.777259063502628

Epoch: 6| Step: 11
Training loss: 0.540302315919916
Validation loss: 2.7964532061724063

Epoch: 6| Step: 12
Training loss: 0.521407961158128
Validation loss: 2.754952580504841

Epoch: 6| Step: 13
Training loss: 0.4018272491966482
Validation loss: 2.778428721980578

Epoch: 519| Step: 0
Training loss: 0.44805083002874124
Validation loss: 2.7720750067802897

Epoch: 6| Step: 1
Training loss: 0.34633154783272063
Validation loss: 2.780612300958986

Epoch: 6| Step: 2
Training loss: 0.3730750347913258
Validation loss: 2.7159800980287736

Epoch: 6| Step: 3
Training loss: 0.4319918830139925
Validation loss: 2.702567835076128

Epoch: 6| Step: 4
Training loss: 0.734914459778295
Validation loss: 2.7287718557687395

Epoch: 6| Step: 5
Training loss: 0.43023920187070325
Validation loss: 2.7335245608295167

Epoch: 6| Step: 6
Training loss: 0.4123454028201613
Validation loss: 2.792849522604516

Epoch: 6| Step: 7
Training loss: 0.4880053389161448
Validation loss: 2.7722468439621375

Epoch: 6| Step: 8
Training loss: 0.440778336324328
Validation loss: 2.7445868331850574

Epoch: 6| Step: 9
Training loss: 0.44879574970180913
Validation loss: 2.7727861167810173

Epoch: 6| Step: 10
Training loss: 0.6802171419360996
Validation loss: 2.764047779987847

Epoch: 6| Step: 11
Training loss: 0.7049198131410634
Validation loss: 2.8365361586275

Epoch: 6| Step: 12
Training loss: 0.5697572173514703
Validation loss: 2.751825485355847

Epoch: 6| Step: 13
Training loss: 0.5873431828387771
Validation loss: 2.753308978592653

Epoch: 520| Step: 0
Training loss: 0.4093217625836115
Validation loss: 2.7817335101401364

Epoch: 6| Step: 1
Training loss: 0.7164799459942562
Validation loss: 2.7599290141131387

Epoch: 6| Step: 2
Training loss: 0.3409360235586112
Validation loss: 2.7551575183088475

Epoch: 6| Step: 3
Training loss: 0.5758506526035441
Validation loss: 2.7460157257615183

Epoch: 6| Step: 4
Training loss: 0.411898409825048
Validation loss: 2.730068484880751

Epoch: 6| Step: 5
Training loss: 0.495479744434628
Validation loss: 2.7244494246518056

Epoch: 6| Step: 6
Training loss: 0.3333629716670651
Validation loss: 2.7620869004019424

Epoch: 6| Step: 7
Training loss: 0.4942481184129109
Validation loss: 2.7385489441339765

Epoch: 6| Step: 8
Training loss: 0.5184043192118389
Validation loss: 2.7011162528496415

Epoch: 6| Step: 9
Training loss: 0.35954438239844067
Validation loss: 2.693078631107159

Epoch: 6| Step: 10
Training loss: 0.5064388182047515
Validation loss: 2.7257588467342875

Epoch: 6| Step: 11
Training loss: 0.6857228501564162
Validation loss: 2.7916404357550824

Epoch: 6| Step: 12
Training loss: 0.6029113410849831
Validation loss: 2.7563156373850717

Epoch: 6| Step: 13
Training loss: 0.47061731023192693
Validation loss: 2.7346550643636958

Epoch: 521| Step: 0
Training loss: 0.6101551441763847
Validation loss: 2.7537175323539396

Epoch: 6| Step: 1
Training loss: 0.7740210441419517
Validation loss: 2.7454476100536236

Epoch: 6| Step: 2
Training loss: 0.6322094669570302
Validation loss: 2.7307999409587818

Epoch: 6| Step: 3
Training loss: 0.6088672380917871
Validation loss: 2.740204836087337

Epoch: 6| Step: 4
Training loss: 0.7126907695563793
Validation loss: 2.778590413011317

Epoch: 6| Step: 5
Training loss: 0.3663006075113327
Validation loss: 2.792944663061746

Epoch: 6| Step: 6
Training loss: 0.32568341073598683
Validation loss: 2.7752770783876763

Epoch: 6| Step: 7
Training loss: 0.5615705122081573
Validation loss: 2.785520924738087

Epoch: 6| Step: 8
Training loss: 0.5901327120101886
Validation loss: 2.7474213488992456

Epoch: 6| Step: 9
Training loss: 0.5182184253390952
Validation loss: 2.7535080209216583

Epoch: 6| Step: 10
Training loss: 0.35398519532313416
Validation loss: 2.795872698723249

Epoch: 6| Step: 11
Training loss: 0.4651961713682545
Validation loss: 2.757752199027027

Epoch: 6| Step: 12
Training loss: 0.6547740960947191
Validation loss: 2.728637830927974

Epoch: 6| Step: 13
Training loss: 0.5711729273984009
Validation loss: 2.788938161605532

Epoch: 522| Step: 0
Training loss: 0.5806058801268484
Validation loss: 2.739786500734229

Epoch: 6| Step: 1
Training loss: 0.43518848813421535
Validation loss: 2.698907152400023

Epoch: 6| Step: 2
Training loss: 0.6264349201099411
Validation loss: 2.7287950092820266

Epoch: 6| Step: 3
Training loss: 0.5428109248373998
Validation loss: 2.7131964353483524

Epoch: 6| Step: 4
Training loss: 0.480407741984271
Validation loss: 2.7117325700638335

Epoch: 6| Step: 5
Training loss: 0.48123057375750805
Validation loss: 2.7433642174831334

Epoch: 6| Step: 6
Training loss: 0.4170601139534853
Validation loss: 2.7102073983506476

Epoch: 6| Step: 7
Training loss: 0.4755139462855618
Validation loss: 2.7293836250165984

Epoch: 6| Step: 8
Training loss: 0.4936422314914601
Validation loss: 2.707264371359828

Epoch: 6| Step: 9
Training loss: 0.4156083813550045
Validation loss: 2.819292949705106

Epoch: 6| Step: 10
Training loss: 0.5566930378113469
Validation loss: 2.776533377914536

Epoch: 6| Step: 11
Training loss: 0.4402928107944637
Validation loss: 2.766783972535996

Epoch: 6| Step: 12
Training loss: 0.46031314785064253
Validation loss: 2.684179442938932

Epoch: 6| Step: 13
Training loss: 0.7276517025586563
Validation loss: 2.796004886357336

Epoch: 523| Step: 0
Training loss: 0.4152732457711397
Validation loss: 2.7556269471301587

Epoch: 6| Step: 1
Training loss: 0.4269746277639166
Validation loss: 2.7479698895170266

Epoch: 6| Step: 2
Training loss: 0.7990601815796876
Validation loss: 2.803783203667634

Epoch: 6| Step: 3
Training loss: 0.5615650460127662
Validation loss: 2.7737707663158835

Epoch: 6| Step: 4
Training loss: 0.43786701067257777
Validation loss: 2.7773310307364856

Epoch: 6| Step: 5
Training loss: 0.40378161781919586
Validation loss: 2.70956768859855

Epoch: 6| Step: 6
Training loss: 0.5245079936717529
Validation loss: 2.7315869968015436

Epoch: 6| Step: 7
Training loss: 0.4685212848900947
Validation loss: 2.7760209780000267

Epoch: 6| Step: 8
Training loss: 0.6134171547919077
Validation loss: 2.778215546021005

Epoch: 6| Step: 9
Training loss: 0.5422684249069196
Validation loss: 2.7448203262097195

Epoch: 6| Step: 10
Training loss: 0.3753590851394264
Validation loss: 2.7444863098270105

Epoch: 6| Step: 11
Training loss: 0.6725880587191296
Validation loss: 2.775629175159109

Epoch: 6| Step: 12
Training loss: 0.4377860768831067
Validation loss: 2.754317506784932

Epoch: 6| Step: 13
Training loss: 0.5170585183371066
Validation loss: 2.7960333241444673

Epoch: 524| Step: 0
Training loss: 0.4351577388936567
Validation loss: 2.763807586824511

Epoch: 6| Step: 1
Training loss: 0.44922115491140396
Validation loss: 2.8180884752961473

Epoch: 6| Step: 2
Training loss: 0.4723778685154345
Validation loss: 2.7500271506847667

Epoch: 6| Step: 3
Training loss: 0.5320087512128301
Validation loss: 2.807017216805284

Epoch: 6| Step: 4
Training loss: 0.7035842667155943
Validation loss: 2.8208773286019055

Epoch: 6| Step: 5
Training loss: 0.4041515955458245
Validation loss: 2.8027632265455695

Epoch: 6| Step: 6
Training loss: 0.5577396452099429
Validation loss: 2.82528421609546

Epoch: 6| Step: 7
Training loss: 0.4784778190781282
Validation loss: 2.7262257656796747

Epoch: 6| Step: 8
Training loss: 0.5682112772847305
Validation loss: 2.7344051250433172

Epoch: 6| Step: 9
Training loss: 0.48052303658815587
Validation loss: 2.7374217615893532

Epoch: 6| Step: 10
Training loss: 0.5198335843458157
Validation loss: 2.7731087073345506

Epoch: 6| Step: 11
Training loss: 0.4934818112877731
Validation loss: 2.76468817869724

Epoch: 6| Step: 12
Training loss: 0.5529949531048949
Validation loss: 2.7684897548051244

Epoch: 6| Step: 13
Training loss: 0.49144493581479826
Validation loss: 2.79826935405497

Epoch: 525| Step: 0
Training loss: 0.6392785553519933
Validation loss: 2.7916377668640378

Epoch: 6| Step: 1
Training loss: 0.5712435190680416
Validation loss: 2.7644845798757145

Epoch: 6| Step: 2
Training loss: 0.579893448842279
Validation loss: 2.781077333155358

Epoch: 6| Step: 3
Training loss: 0.43383558934964
Validation loss: 2.732358090553994

Epoch: 6| Step: 4
Training loss: 0.490256198838031
Validation loss: 2.7254941900491474

Epoch: 6| Step: 5
Training loss: 0.3676312180219909
Validation loss: 2.7469655982169625

Epoch: 6| Step: 6
Training loss: 0.6352340378465415
Validation loss: 2.755950255757546

Epoch: 6| Step: 7
Training loss: 0.5582447161973245
Validation loss: 2.7773337348367537

Epoch: 6| Step: 8
Training loss: 0.6110151909798721
Validation loss: 2.7579174147867733

Epoch: 6| Step: 9
Training loss: 0.3892538802603379
Validation loss: 2.707315596068305

Epoch: 6| Step: 10
Training loss: 0.5260776721479142
Validation loss: 2.722542963357432

Epoch: 6| Step: 11
Training loss: 0.48169789836148696
Validation loss: 2.7468242514721144

Epoch: 6| Step: 12
Training loss: 0.5721583347189861
Validation loss: 2.7276411974111485

Epoch: 6| Step: 13
Training loss: 0.5323293044288744
Validation loss: 2.725512480010714

Epoch: 526| Step: 0
Training loss: 0.453748963987991
Validation loss: 2.719382296585795

Epoch: 6| Step: 1
Training loss: 0.45908520179534956
Validation loss: 2.6963293101802255

Epoch: 6| Step: 2
Training loss: 0.4390182547488646
Validation loss: 2.750224068211862

Epoch: 6| Step: 3
Training loss: 0.469858258159437
Validation loss: 2.6952674456530294

Epoch: 6| Step: 4
Training loss: 0.416741145947825
Validation loss: 2.7392353711991104

Epoch: 6| Step: 5
Training loss: 0.4622293086096497
Validation loss: 2.7274402127471666

Epoch: 6| Step: 6
Training loss: 0.666315251853448
Validation loss: 2.751036867548955

Epoch: 6| Step: 7
Training loss: 0.4693068217097722
Validation loss: 2.7420834687325732

Epoch: 6| Step: 8
Training loss: 0.7182252461024651
Validation loss: 2.771730841694455

Epoch: 6| Step: 9
Training loss: 0.372020728143919
Validation loss: 2.722922240535885

Epoch: 6| Step: 10
Training loss: 0.516356960143115
Validation loss: 2.74965570201885

Epoch: 6| Step: 11
Training loss: 0.4342439261622766
Validation loss: 2.776718849097838

Epoch: 6| Step: 12
Training loss: 0.652414420862637
Validation loss: 2.7812981476348755

Epoch: 6| Step: 13
Training loss: 0.47311487882464043
Validation loss: 2.712867570105795

Epoch: 527| Step: 0
Training loss: 0.45999835402774725
Validation loss: 2.713639919579189

Epoch: 6| Step: 1
Training loss: 0.6278947550547727
Validation loss: 2.71039795797011

Epoch: 6| Step: 2
Training loss: 0.3238364689100568
Validation loss: 2.7589119798852435

Epoch: 6| Step: 3
Training loss: 0.5115071798437811
Validation loss: 2.7420365164291725

Epoch: 6| Step: 4
Training loss: 0.4090160324829697
Validation loss: 2.728852732028306

Epoch: 6| Step: 5
Training loss: 0.5649504269314115
Validation loss: 2.761337879901362

Epoch: 6| Step: 6
Training loss: 0.5163576527407876
Validation loss: 2.7775078504596213

Epoch: 6| Step: 7
Training loss: 0.4139703612107242
Validation loss: 2.7262334615959896

Epoch: 6| Step: 8
Training loss: 0.4671164021567147
Validation loss: 2.7359995639049637

Epoch: 6| Step: 9
Training loss: 0.4298938602482031
Validation loss: 2.7520195307953443

Epoch: 6| Step: 10
Training loss: 0.4852484395868289
Validation loss: 2.7495904964379343

Epoch: 6| Step: 11
Training loss: 0.4612064062105781
Validation loss: 2.6990449281731266

Epoch: 6| Step: 12
Training loss: 0.5229775984727582
Validation loss: 2.8191144235408307

Epoch: 6| Step: 13
Training loss: 0.5546851896855771
Validation loss: 2.766547442552195

Epoch: 528| Step: 0
Training loss: 0.3240385933815689
Validation loss: 2.7332821505879514

Epoch: 6| Step: 1
Training loss: 0.6661065898089952
Validation loss: 2.754540120216078

Epoch: 6| Step: 2
Training loss: 0.3769795304769486
Validation loss: 2.7873824729149232

Epoch: 6| Step: 3
Training loss: 0.5623336652024757
Validation loss: 2.7294545689119043

Epoch: 6| Step: 4
Training loss: 0.516053022116738
Validation loss: 2.7461203894446746

Epoch: 6| Step: 5
Training loss: 0.42753992058819035
Validation loss: 2.698039274240431

Epoch: 6| Step: 6
Training loss: 0.48111064800681147
Validation loss: 2.709005174692215

Epoch: 6| Step: 7
Training loss: 0.42332817510343307
Validation loss: 2.780233690401805

Epoch: 6| Step: 8
Training loss: 0.5259146080542969
Validation loss: 2.7816688993645773

Epoch: 6| Step: 9
Training loss: 0.4277889269178198
Validation loss: 2.7644232457563844

Epoch: 6| Step: 10
Training loss: 0.61030578441607
Validation loss: 2.712726072626393

Epoch: 6| Step: 11
Training loss: 0.5477882933504673
Validation loss: 2.69315903001262

Epoch: 6| Step: 12
Training loss: 0.38447889304050137
Validation loss: 2.752650515269281

Epoch: 6| Step: 13
Training loss: 0.5614595327087313
Validation loss: 2.7744542367047997

Epoch: 529| Step: 0
Training loss: 0.5326438178135973
Validation loss: 2.8013943010550157

Epoch: 6| Step: 1
Training loss: 0.29834106744743155
Validation loss: 2.7448048503831766

Epoch: 6| Step: 2
Training loss: 0.439290334431347
Validation loss: 2.7449850826170774

Epoch: 6| Step: 3
Training loss: 0.6031012980097846
Validation loss: 2.753487860458968

Epoch: 6| Step: 4
Training loss: 0.2859529965271538
Validation loss: 2.789632843998869

Epoch: 6| Step: 5
Training loss: 0.560022939995522
Validation loss: 2.7550244813859437

Epoch: 6| Step: 6
Training loss: 0.38706590502704313
Validation loss: 2.727038191695425

Epoch: 6| Step: 7
Training loss: 0.5855906159068563
Validation loss: 2.7754190019789475

Epoch: 6| Step: 8
Training loss: 0.5915131345082253
Validation loss: 2.782444036822961

Epoch: 6| Step: 9
Training loss: 0.5356033017226963
Validation loss: 2.769779009513346

Epoch: 6| Step: 10
Training loss: 0.42331173637385466
Validation loss: 2.727355003861865

Epoch: 6| Step: 11
Training loss: 0.49611011988747394
Validation loss: 2.738672726410263

Epoch: 6| Step: 12
Training loss: 0.3195066083439579
Validation loss: 2.752752602628148

Epoch: 6| Step: 13
Training loss: 0.6179702237927867
Validation loss: 2.7538380427289577

Epoch: 530| Step: 0
Training loss: 0.4270554122481796
Validation loss: 2.794488439177805

Epoch: 6| Step: 1
Training loss: 0.46518733045376826
Validation loss: 2.715146164551298

Epoch: 6| Step: 2
Training loss: 0.5698293965160806
Validation loss: 2.754429479362747

Epoch: 6| Step: 3
Training loss: 0.550133831907599
Validation loss: 2.726846805822826

Epoch: 6| Step: 4
Training loss: 0.4056023790961245
Validation loss: 2.734123618060151

Epoch: 6| Step: 5
Training loss: 0.5233186045880263
Validation loss: 2.768135676894157

Epoch: 6| Step: 6
Training loss: 0.3393480039365582
Validation loss: 2.762557805579955

Epoch: 6| Step: 7
Training loss: 0.5316650228066377
Validation loss: 2.766238703048905

Epoch: 6| Step: 8
Training loss: 0.4414193311795347
Validation loss: 2.7820631403007146

Epoch: 6| Step: 9
Training loss: 0.460602428395673
Validation loss: 2.744574114136023

Epoch: 6| Step: 10
Training loss: 0.5292040472519588
Validation loss: 2.7352967080287582

Epoch: 6| Step: 11
Training loss: 0.5008681033035453
Validation loss: 2.785011262762466

Epoch: 6| Step: 12
Training loss: 0.43640264764344494
Validation loss: 2.7795483673539048

Epoch: 6| Step: 13
Training loss: 0.6068590997720689
Validation loss: 2.7600471009275886

Epoch: 531| Step: 0
Training loss: 0.5617822465303691
Validation loss: 2.7821240141208508

Epoch: 6| Step: 1
Training loss: 0.2658307456744619
Validation loss: 2.7824732915528143

Epoch: 6| Step: 2
Training loss: 0.381238269625447
Validation loss: 2.7983360452470327

Epoch: 6| Step: 3
Training loss: 0.6369795703860668
Validation loss: 2.767511683321364

Epoch: 6| Step: 4
Training loss: 0.6756365406134088
Validation loss: 2.7611456910016265

Epoch: 6| Step: 5
Training loss: 0.5695077627019683
Validation loss: 2.73573401693115

Epoch: 6| Step: 6
Training loss: 0.3602006177404996
Validation loss: 2.7585195296062186

Epoch: 6| Step: 7
Training loss: 0.3664453188761276
Validation loss: 2.7843998849015774

Epoch: 6| Step: 8
Training loss: 0.37659259216875124
Validation loss: 2.766653663440006

Epoch: 6| Step: 9
Training loss: 0.5011773850219107
Validation loss: 2.7631661068006332

Epoch: 6| Step: 10
Training loss: 0.7157831741836755
Validation loss: 2.796318453464017

Epoch: 6| Step: 11
Training loss: 0.4454720361936939
Validation loss: 2.809507607741589

Epoch: 6| Step: 12
Training loss: 0.520195958829683
Validation loss: 2.8269486483540707

Epoch: 6| Step: 13
Training loss: 0.5233521463066065
Validation loss: 2.801174971440883

Epoch: 532| Step: 0
Training loss: 0.42905681447973576
Validation loss: 2.7888815684895825

Epoch: 6| Step: 1
Training loss: 0.5363489490086577
Validation loss: 2.7444029115922475

Epoch: 6| Step: 2
Training loss: 0.4335300123776836
Validation loss: 2.7915235359356254

Epoch: 6| Step: 3
Training loss: 0.2897270913830945
Validation loss: 2.7678082140979487

Epoch: 6| Step: 4
Training loss: 0.6875155620547613
Validation loss: 2.75030053909568

Epoch: 6| Step: 5
Training loss: 0.35125804009517897
Validation loss: 2.7746272011381667

Epoch: 6| Step: 6
Training loss: 0.6164982000697484
Validation loss: 2.7863910322291265

Epoch: 6| Step: 7
Training loss: 0.43937380604697046
Validation loss: 2.7141710138525235

Epoch: 6| Step: 8
Training loss: 0.49532760573015444
Validation loss: 2.747159545765469

Epoch: 6| Step: 9
Training loss: 0.3744327307690121
Validation loss: 2.7679588973038407

Epoch: 6| Step: 10
Training loss: 0.37809249170713355
Validation loss: 2.736833074259755

Epoch: 6| Step: 11
Training loss: 0.4728523824779991
Validation loss: 2.7745630836769486

Epoch: 6| Step: 12
Training loss: 0.399099827949613
Validation loss: 2.7218412897217434

Epoch: 6| Step: 13
Training loss: 0.48945473612088625
Validation loss: 2.731929099289757

Epoch: 533| Step: 0
Training loss: 0.5502802416625244
Validation loss: 2.7134541053824752

Epoch: 6| Step: 1
Training loss: 0.4666921905224646
Validation loss: 2.7478671472660476

Epoch: 6| Step: 2
Training loss: 0.35521475132637753
Validation loss: 2.7547856362976972

Epoch: 6| Step: 3
Training loss: 0.4487194935781658
Validation loss: 2.7125191156091724

Epoch: 6| Step: 4
Training loss: 0.5198670356197292
Validation loss: 2.749773637529604

Epoch: 6| Step: 5
Training loss: 0.37676012701942235
Validation loss: 2.7160868993396

Epoch: 6| Step: 6
Training loss: 0.4363177538179634
Validation loss: 2.745456120499954

Epoch: 6| Step: 7
Training loss: 0.334064987002073
Validation loss: 2.769844916210688

Epoch: 6| Step: 8
Training loss: 0.38792335856177007
Validation loss: 2.7398410477673414

Epoch: 6| Step: 9
Training loss: 0.5318689947540115
Validation loss: 2.735897345241882

Epoch: 6| Step: 10
Training loss: 0.3748523898478601
Validation loss: 2.7128508280871406

Epoch: 6| Step: 11
Training loss: 0.6659767385636159
Validation loss: 2.765564438323823

Epoch: 6| Step: 12
Training loss: 0.46042101420713244
Validation loss: 2.7384180315059825

Epoch: 6| Step: 13
Training loss: 0.3616464192389193
Validation loss: 2.675132817687731

Epoch: 534| Step: 0
Training loss: 0.6692638001029109
Validation loss: 2.742082592007113

Epoch: 6| Step: 1
Training loss: 0.4319195773778382
Validation loss: 2.7585330126383467

Epoch: 6| Step: 2
Training loss: 0.4476676366932335
Validation loss: 2.7373997407201585

Epoch: 6| Step: 3
Training loss: 0.3666699800377751
Validation loss: 2.7228037111474777

Epoch: 6| Step: 4
Training loss: 0.3880384833740086
Validation loss: 2.7471171209092704

Epoch: 6| Step: 5
Training loss: 0.4472635260786757
Validation loss: 2.7619720299676698

Epoch: 6| Step: 6
Training loss: 0.5337725383100569
Validation loss: 2.736575754175734

Epoch: 6| Step: 7
Training loss: 0.5935072151523233
Validation loss: 2.7474549466443365

Epoch: 6| Step: 8
Training loss: 0.32445918210954966
Validation loss: 2.724825935462303

Epoch: 6| Step: 9
Training loss: 0.45073664095753974
Validation loss: 2.7550266448738467

Epoch: 6| Step: 10
Training loss: 0.3876983296543591
Validation loss: 2.7709363162949265

Epoch: 6| Step: 11
Training loss: 0.26199418847085054
Validation loss: 2.7885161362454105

Epoch: 6| Step: 12
Training loss: 0.3982865290630519
Validation loss: 2.7991149428838296

Epoch: 6| Step: 13
Training loss: 0.6141628561932574
Validation loss: 2.811215806874391

Epoch: 535| Step: 0
Training loss: 0.49711224991732805
Validation loss: 2.7865378014947035

Epoch: 6| Step: 1
Training loss: 0.5631373291698186
Validation loss: 2.7258217724475546

Epoch: 6| Step: 2
Training loss: 0.4847394433586116
Validation loss: 2.7809635829248904

Epoch: 6| Step: 3
Training loss: 0.3860832348468067
Validation loss: 2.7449805516223966

Epoch: 6| Step: 4
Training loss: 0.5507837931256392
Validation loss: 2.794202013877722

Epoch: 6| Step: 5
Training loss: 0.5892352066028101
Validation loss: 2.7862811783896873

Epoch: 6| Step: 6
Training loss: 0.3230551556006817
Validation loss: 2.72577491177126

Epoch: 6| Step: 7
Training loss: 0.4883786981616905
Validation loss: 2.7092594079538386

Epoch: 6| Step: 8
Training loss: 0.43395826122095926
Validation loss: 2.7485267420816313

Epoch: 6| Step: 9
Training loss: 0.33913360588439473
Validation loss: 2.759471894777443

Epoch: 6| Step: 10
Training loss: 0.5137206659968739
Validation loss: 2.70718220431609

Epoch: 6| Step: 11
Training loss: 0.4194291351045852
Validation loss: 2.742418161745833

Epoch: 6| Step: 12
Training loss: 0.47314607444802836
Validation loss: 2.726324440838966

Epoch: 6| Step: 13
Training loss: 0.40184905370363777
Validation loss: 2.68440417213561

Epoch: 536| Step: 0
Training loss: 0.4465601492166543
Validation loss: 2.7222021555215035

Epoch: 6| Step: 1
Training loss: 0.4124168225437953
Validation loss: 2.7166432954995967

Epoch: 6| Step: 2
Training loss: 0.5411932478085266
Validation loss: 2.742713247474202

Epoch: 6| Step: 3
Training loss: 0.4865577492699441
Validation loss: 2.721643055939759

Epoch: 6| Step: 4
Training loss: 0.4874974635865178
Validation loss: 2.758733147248619

Epoch: 6| Step: 5
Training loss: 0.673429332426952
Validation loss: 2.7435520323731026

Epoch: 6| Step: 6
Training loss: 0.5353765660667626
Validation loss: 2.7486883850269708

Epoch: 6| Step: 7
Training loss: 0.37184528745029966
Validation loss: 2.8047176207162057

Epoch: 6| Step: 8
Training loss: 0.6062660628088354
Validation loss: 2.796206268266432

Epoch: 6| Step: 9
Training loss: 0.392220329339236
Validation loss: 2.753365076157641

Epoch: 6| Step: 10
Training loss: 0.42374120427458223
Validation loss: 2.827452367105362

Epoch: 6| Step: 11
Training loss: 0.3690767384301158
Validation loss: 2.7673574219193404

Epoch: 6| Step: 12
Training loss: 0.6908044728584362
Validation loss: 2.7861364636250756

Epoch: 6| Step: 13
Training loss: 0.49867654527201105
Validation loss: 2.7809378916748035

Epoch: 537| Step: 0
Training loss: 0.444244174075419
Validation loss: 2.7688804905712856

Epoch: 6| Step: 1
Training loss: 0.6691785865076761
Validation loss: 2.7916411403418926

Epoch: 6| Step: 2
Training loss: 0.4748120444264096
Validation loss: 2.7477865414373217

Epoch: 6| Step: 3
Training loss: 0.5484523369067357
Validation loss: 2.8113225096808643

Epoch: 6| Step: 4
Training loss: 0.5357277596005421
Validation loss: 2.768358341814504

Epoch: 6| Step: 5
Training loss: 0.6211420676192777
Validation loss: 2.7680746318259555

Epoch: 6| Step: 6
Training loss: 0.49473697125809907
Validation loss: 2.7887076072827766

Epoch: 6| Step: 7
Training loss: 0.4217065192163065
Validation loss: 2.7682577558149455

Epoch: 6| Step: 8
Training loss: 0.5168484997211922
Validation loss: 2.802063517636331

Epoch: 6| Step: 9
Training loss: 0.5403262266463982
Validation loss: 2.740973773658721

Epoch: 6| Step: 10
Training loss: 0.4544088329013279
Validation loss: 2.7683746404932514

Epoch: 6| Step: 11
Training loss: 0.4470898478561614
Validation loss: 2.71467233386538

Epoch: 6| Step: 12
Training loss: 0.5824991176254728
Validation loss: 2.7177365778348097

Epoch: 6| Step: 13
Training loss: 0.40478088597528905
Validation loss: 2.687791084080343

Epoch: 538| Step: 0
Training loss: 0.3195967586118722
Validation loss: 2.751518985968156

Epoch: 6| Step: 1
Training loss: 0.3756616834414638
Validation loss: 2.724362335490689

Epoch: 6| Step: 2
Training loss: 0.5294277409444522
Validation loss: 2.698027977923958

Epoch: 6| Step: 3
Training loss: 0.6185104580752897
Validation loss: 2.7684618306945086

Epoch: 6| Step: 4
Training loss: 0.3545022127609708
Validation loss: 2.696510689927664

Epoch: 6| Step: 5
Training loss: 0.5067487579221328
Validation loss: 2.7524971966753737

Epoch: 6| Step: 6
Training loss: 0.40670160721282383
Validation loss: 2.7113150444570757

Epoch: 6| Step: 7
Training loss: 0.6343619133863188
Validation loss: 2.773654925639645

Epoch: 6| Step: 8
Training loss: 0.5971747060350477
Validation loss: 2.6908116008991048

Epoch: 6| Step: 9
Training loss: 0.36966127684739797
Validation loss: 2.719973643212618

Epoch: 6| Step: 10
Training loss: 0.43261107360790746
Validation loss: 2.6859195113157583

Epoch: 6| Step: 11
Training loss: 0.38951280570862445
Validation loss: 2.7665038499454324

Epoch: 6| Step: 12
Training loss: 0.6337944230380489
Validation loss: 2.7152231221228136

Epoch: 6| Step: 13
Training loss: 0.25557728133132607
Validation loss: 2.7217753447936985

Epoch: 539| Step: 0
Training loss: 0.44957400662585495
Validation loss: 2.7254059970329796

Epoch: 6| Step: 1
Training loss: 0.3261906167316515
Validation loss: 2.7666468627251537

Epoch: 6| Step: 2
Training loss: 0.41808834325794497
Validation loss: 2.7788521720737123

Epoch: 6| Step: 3
Training loss: 0.49838072115578175
Validation loss: 2.7643486712934995

Epoch: 6| Step: 4
Training loss: 0.4141574966571938
Validation loss: 2.787561833903253

Epoch: 6| Step: 5
Training loss: 0.4062968373808601
Validation loss: 2.8251733709828923

Epoch: 6| Step: 6
Training loss: 0.5188359936136302
Validation loss: 2.758755055445821

Epoch: 6| Step: 7
Training loss: 0.48625245329034505
Validation loss: 2.7534143319658106

Epoch: 6| Step: 8
Training loss: 0.41845190341082167
Validation loss: 2.729990468410299

Epoch: 6| Step: 9
Training loss: 0.39339424819692925
Validation loss: 2.7816766561652986

Epoch: 6| Step: 10
Training loss: 0.5395840871896473
Validation loss: 2.8184006005697904

Epoch: 6| Step: 11
Training loss: 0.6683444255001931
Validation loss: 2.7700338333579233

Epoch: 6| Step: 12
Training loss: 0.4508264383445721
Validation loss: 2.792807877182376

Epoch: 6| Step: 13
Training loss: 0.47650311834870057
Validation loss: 2.8017369638852654

Epoch: 540| Step: 0
Training loss: 0.3302784148415882
Validation loss: 2.769754276164333

Epoch: 6| Step: 1
Training loss: 0.5001358503324527
Validation loss: 2.8059244076032908

Epoch: 6| Step: 2
Training loss: 0.6069126263631125
Validation loss: 2.7797922178645886

Epoch: 6| Step: 3
Training loss: 0.49211833104524294
Validation loss: 2.853048040404279

Epoch: 6| Step: 4
Training loss: 0.39717237790401283
Validation loss: 2.788643728066888

Epoch: 6| Step: 5
Training loss: 0.4802802266513283
Validation loss: 2.8182253454339095

Epoch: 6| Step: 6
Training loss: 0.4340275836520291
Validation loss: 2.7991403963204466

Epoch: 6| Step: 7
Training loss: 0.41117311402456175
Validation loss: 2.8024152159761733

Epoch: 6| Step: 8
Training loss: 0.45162359966078924
Validation loss: 2.8810556187573346

Epoch: 6| Step: 9
Training loss: 0.48377325765999646
Validation loss: 2.787764053781849

Epoch: 6| Step: 10
Training loss: 0.5003876077767977
Validation loss: 2.78891703193349

Epoch: 6| Step: 11
Training loss: 0.6144745752042666
Validation loss: 2.7982246935690247

Epoch: 6| Step: 12
Training loss: 0.5879080126652881
Validation loss: 2.7794894386077584

Epoch: 6| Step: 13
Training loss: 0.46228244923013345
Validation loss: 2.8117260468488894

Epoch: 541| Step: 0
Training loss: 0.5978837421758285
Validation loss: 2.7898593052900713

Epoch: 6| Step: 1
Training loss: 0.40489445626813314
Validation loss: 2.77271828795653

Epoch: 6| Step: 2
Training loss: 0.39119231036401375
Validation loss: 2.770916203763002

Epoch: 6| Step: 3
Training loss: 0.6721582037634709
Validation loss: 2.806691055358007

Epoch: 6| Step: 4
Training loss: 0.757092202393042
Validation loss: 2.8114171380700532

Epoch: 6| Step: 5
Training loss: 0.6845793022838872
Validation loss: 2.775831366058938

Epoch: 6| Step: 6
Training loss: 0.484881136624043
Validation loss: 2.710765206526255

Epoch: 6| Step: 7
Training loss: 0.4881595154646882
Validation loss: 2.798291208322375

Epoch: 6| Step: 8
Training loss: 0.6066872917152142
Validation loss: 2.7218721666405257

Epoch: 6| Step: 9
Training loss: 0.5029471681390167
Validation loss: 2.7241170531810046

Epoch: 6| Step: 10
Training loss: 0.6169563053585806
Validation loss: 2.7177290186905676

Epoch: 6| Step: 11
Training loss: 0.5465983644805067
Validation loss: 2.7430364267403893

Epoch: 6| Step: 12
Training loss: 0.587352823530876
Validation loss: 2.7743450703603143

Epoch: 6| Step: 13
Training loss: 0.42686195761331047
Validation loss: 2.665891480029841

Epoch: 542| Step: 0
Training loss: 0.48416883941968264
Validation loss: 2.7387687332624604

Epoch: 6| Step: 1
Training loss: 0.5539587364563534
Validation loss: 2.7683117418482572

Epoch: 6| Step: 2
Training loss: 0.5673038079677132
Validation loss: 2.7252426523552185

Epoch: 6| Step: 3
Training loss: 0.8166026559059179
Validation loss: 2.7402791540502576

Epoch: 6| Step: 4
Training loss: 0.36458117166514104
Validation loss: 2.741450399972956

Epoch: 6| Step: 5
Training loss: 0.4802065032819299
Validation loss: 2.717442998560263

Epoch: 6| Step: 6
Training loss: 0.36968330577621905
Validation loss: 2.730186495110825

Epoch: 6| Step: 7
Training loss: 0.4171298333649054
Validation loss: 2.7145500188868232

Epoch: 6| Step: 8
Training loss: 0.4639562742115925
Validation loss: 2.770677624297419

Epoch: 6| Step: 9
Training loss: 0.4590503726341531
Validation loss: 2.8031547417227043

Epoch: 6| Step: 10
Training loss: 0.5148667916451417
Validation loss: 2.755173541728523

Epoch: 6| Step: 11
Training loss: 0.5112722939011766
Validation loss: 2.774210876665659

Epoch: 6| Step: 12
Training loss: 0.4907119522066015
Validation loss: 2.728016084213422

Epoch: 6| Step: 13
Training loss: 0.23954327739123826
Validation loss: 2.7413354330554234

Epoch: 543| Step: 0
Training loss: 0.5319220835625904
Validation loss: 2.766790169713097

Epoch: 6| Step: 1
Training loss: 0.45217730633912073
Validation loss: 2.7171002494458194

Epoch: 6| Step: 2
Training loss: 0.38711621829854237
Validation loss: 2.6575798445651357

Epoch: 6| Step: 3
Training loss: 0.5293471815688381
Validation loss: 2.697408714246492

Epoch: 6| Step: 4
Training loss: 0.47510047903917973
Validation loss: 2.6625254682060078

Epoch: 6| Step: 5
Training loss: 0.38725617182315836
Validation loss: 2.7610034295014394

Epoch: 6| Step: 6
Training loss: 0.5970518010108388
Validation loss: 2.717427937108674

Epoch: 6| Step: 7
Training loss: 0.40970685044600297
Validation loss: 2.762993791156042

Epoch: 6| Step: 8
Training loss: 0.40691409484271374
Validation loss: 2.7096462490898525

Epoch: 6| Step: 9
Training loss: 0.5993604112108636
Validation loss: 2.7482199976978663

Epoch: 6| Step: 10
Training loss: 0.42449203034862537
Validation loss: 2.734395853598866

Epoch: 6| Step: 11
Training loss: 0.29807831934573475
Validation loss: 2.7029410356607317

Epoch: 6| Step: 12
Training loss: 0.5089360059706627
Validation loss: 2.7462631904054926

Epoch: 6| Step: 13
Training loss: 0.46811448567988007
Validation loss: 2.746081862733669

Epoch: 544| Step: 0
Training loss: 0.3682674596678404
Validation loss: 2.705934303200449

Epoch: 6| Step: 1
Training loss: 0.5632056737136479
Validation loss: 2.7004898839566978

Epoch: 6| Step: 2
Training loss: 0.43676747577425085
Validation loss: 2.7379546213274395

Epoch: 6| Step: 3
Training loss: 0.5036838839285528
Validation loss: 2.678566552717827

Epoch: 6| Step: 4
Training loss: 0.45751011858105356
Validation loss: 2.7439047281002433

Epoch: 6| Step: 5
Training loss: 0.4330457368794804
Validation loss: 2.7296704756684984

Epoch: 6| Step: 6
Training loss: 0.26057458698734426
Validation loss: 2.719402176547238

Epoch: 6| Step: 7
Training loss: 0.43604708288953753
Validation loss: 2.7843076350279277

Epoch: 6| Step: 8
Training loss: 0.3423289925316454
Validation loss: 2.765387199796252

Epoch: 6| Step: 9
Training loss: 0.37935513521376296
Validation loss: 2.6888589602066726

Epoch: 6| Step: 10
Training loss: 0.6460955277295085
Validation loss: 2.751133446761526

Epoch: 6| Step: 11
Training loss: 0.36361752604871284
Validation loss: 2.758914197936338

Epoch: 6| Step: 12
Training loss: 0.5526296833222129
Validation loss: 2.7334010833004196

Epoch: 6| Step: 13
Training loss: 0.47236790018936575
Validation loss: 2.7686115812973973

Epoch: 545| Step: 0
Training loss: 0.39546382329759006
Validation loss: 2.7879223456548448

Epoch: 6| Step: 1
Training loss: 0.5038072355710153
Validation loss: 2.718753244683094

Epoch: 6| Step: 2
Training loss: 0.6538019158589954
Validation loss: 2.7498549582061154

Epoch: 6| Step: 3
Training loss: 0.3429970080089474
Validation loss: 2.759980441959394

Epoch: 6| Step: 4
Training loss: 0.33132670207258885
Validation loss: 2.7644347019865463

Epoch: 6| Step: 5
Training loss: 0.42125242707999383
Validation loss: 2.769663116658788

Epoch: 6| Step: 6
Training loss: 0.6889289397813815
Validation loss: 2.744836496835161

Epoch: 6| Step: 7
Training loss: 0.510779064006918
Validation loss: 2.7138696693170217

Epoch: 6| Step: 8
Training loss: 0.5649453099543715
Validation loss: 2.7245719660990346

Epoch: 6| Step: 9
Training loss: 0.6175827016546255
Validation loss: 2.7250906424656276

Epoch: 6| Step: 10
Training loss: 0.33246264762380323
Validation loss: 2.745305736448742

Epoch: 6| Step: 11
Training loss: 0.5504325141425375
Validation loss: 2.7100840607587773

Epoch: 6| Step: 12
Training loss: 0.6773146063178832
Validation loss: 2.765351046627164

Epoch: 6| Step: 13
Training loss: 0.3846926353663415
Validation loss: 2.7740362962650673

Epoch: 546| Step: 0
Training loss: 0.26359025610308096
Validation loss: 2.745071560935003

Epoch: 6| Step: 1
Training loss: 0.4448986137813546
Validation loss: 2.7911089771872395

Epoch: 6| Step: 2
Training loss: 0.4821555448810412
Validation loss: 2.7442162264617354

Epoch: 6| Step: 3
Training loss: 0.5466932539706306
Validation loss: 2.814245487683601

Epoch: 6| Step: 4
Training loss: 0.45425917648594827
Validation loss: 2.8246369322681635

Epoch: 6| Step: 5
Training loss: 0.6346326952909702
Validation loss: 2.7863447124572707

Epoch: 6| Step: 6
Training loss: 0.36202597372649714
Validation loss: 2.7899073043473663

Epoch: 6| Step: 7
Training loss: 0.39000992988514005
Validation loss: 2.7661680848544616

Epoch: 6| Step: 8
Training loss: 0.5297211357847471
Validation loss: 2.783142346170246

Epoch: 6| Step: 9
Training loss: 0.6026457409267566
Validation loss: 2.759658663819378

Epoch: 6| Step: 10
Training loss: 0.4822183249084011
Validation loss: 2.756726376172456

Epoch: 6| Step: 11
Training loss: 0.5098398673412127
Validation loss: 2.7212830359305653

Epoch: 6| Step: 12
Training loss: 0.5275036604695524
Validation loss: 2.7535878459572234

Epoch: 6| Step: 13
Training loss: 0.5185530782843439
Validation loss: 2.769614895883292

Epoch: 547| Step: 0
Training loss: 0.38684925613040905
Validation loss: 2.752692999198846

Epoch: 6| Step: 1
Training loss: 0.3760825664155459
Validation loss: 2.73051117157806

Epoch: 6| Step: 2
Training loss: 0.4857120211582527
Validation loss: 2.761774619192482

Epoch: 6| Step: 3
Training loss: 0.6661771203737467
Validation loss: 2.720248456153961

Epoch: 6| Step: 4
Training loss: 0.6877116397738504
Validation loss: 2.7714379924811614

Epoch: 6| Step: 5
Training loss: 0.3407616551155874
Validation loss: 2.687575036117686

Epoch: 6| Step: 6
Training loss: 0.47199777180743824
Validation loss: 2.745461186229292

Epoch: 6| Step: 7
Training loss: 0.4853980120838609
Validation loss: 2.7662264857705545

Epoch: 6| Step: 8
Training loss: 0.48263213174268893
Validation loss: 2.7275809469079038

Epoch: 6| Step: 9
Training loss: 0.5793449572250123
Validation loss: 2.7154905138856233

Epoch: 6| Step: 10
Training loss: 0.3337416966259058
Validation loss: 2.716270236674173

Epoch: 6| Step: 11
Training loss: 0.5072466118117986
Validation loss: 2.6810967657233564

Epoch: 6| Step: 12
Training loss: 0.5252503275119027
Validation loss: 2.677068871089201

Epoch: 6| Step: 13
Training loss: 0.48977843583816744
Validation loss: 2.688760653985583

Epoch: 548| Step: 0
Training loss: 0.49293739473040205
Validation loss: 2.656586434992757

Epoch: 6| Step: 1
Training loss: 0.5072650893323247
Validation loss: 2.739543382670041

Epoch: 6| Step: 2
Training loss: 0.39664720846516455
Validation loss: 2.69254485961607

Epoch: 6| Step: 3
Training loss: 0.4834311271942815
Validation loss: 2.722153254584672

Epoch: 6| Step: 4
Training loss: 0.5493781974794907
Validation loss: 2.7552353846202124

Epoch: 6| Step: 5
Training loss: 0.6228504409373231
Validation loss: 2.757821361322188

Epoch: 6| Step: 6
Training loss: 0.7056546377169755
Validation loss: 2.711801704494093

Epoch: 6| Step: 7
Training loss: 0.36498233442145583
Validation loss: 2.7371528248572723

Epoch: 6| Step: 8
Training loss: 0.46762676766782146
Validation loss: 2.7077027736120596

Epoch: 6| Step: 9
Training loss: 0.5675900945694337
Validation loss: 2.7736302984859464

Epoch: 6| Step: 10
Training loss: 0.46040368284787414
Validation loss: 2.732307084467023

Epoch: 6| Step: 11
Training loss: 0.45452691942593043
Validation loss: 2.6931908849620387

Epoch: 6| Step: 12
Training loss: 0.5457268242137382
Validation loss: 2.699186274272871

Epoch: 6| Step: 13
Training loss: 0.38655512652384466
Validation loss: 2.7222482237795904

Epoch: 549| Step: 0
Training loss: 0.29424754475401366
Validation loss: 2.7128595726189597

Epoch: 6| Step: 1
Training loss: 0.44473784997392835
Validation loss: 2.759450064272101

Epoch: 6| Step: 2
Training loss: 0.5030232166616424
Validation loss: 2.7509537690138868

Epoch: 6| Step: 3
Training loss: 0.4184298957207815
Validation loss: 2.7692045046845966

Epoch: 6| Step: 4
Training loss: 0.36210812071549053
Validation loss: 2.7412949256909105

Epoch: 6| Step: 5
Training loss: 0.3437563938933386
Validation loss: 2.7457886875055983

Epoch: 6| Step: 6
Training loss: 0.45837420223552605
Validation loss: 2.801321576083659

Epoch: 6| Step: 7
Training loss: 0.3715601349443348
Validation loss: 2.791671914242799

Epoch: 6| Step: 8
Training loss: 0.40814142810419335
Validation loss: 2.781032910964865

Epoch: 6| Step: 9
Training loss: 0.30794483477104934
Validation loss: 2.7249847481677

Epoch: 6| Step: 10
Training loss: 0.4524295666185242
Validation loss: 2.7605692599364073

Epoch: 6| Step: 11
Training loss: 0.5020786825996156
Validation loss: 2.7152673624093144

Epoch: 6| Step: 12
Training loss: 0.4116142878756001
Validation loss: 2.7223093549792536

Epoch: 6| Step: 13
Training loss: 0.7307322633713469
Validation loss: 2.6933178583808473

Epoch: 550| Step: 0
Training loss: 0.3897938851246312
Validation loss: 2.6581378137402383

Epoch: 6| Step: 1
Training loss: 0.38187336067559585
Validation loss: 2.680286373915292

Epoch: 6| Step: 2
Training loss: 0.5254288556678908
Validation loss: 2.6897845353784504

Epoch: 6| Step: 3
Training loss: 0.5241831976351385
Validation loss: 2.684759069314767

Epoch: 6| Step: 4
Training loss: 0.44696941312047156
Validation loss: 2.712685262561783

Epoch: 6| Step: 5
Training loss: 0.4888586978579073
Validation loss: 2.707864454225542

Epoch: 6| Step: 6
Training loss: 0.6477563796735907
Validation loss: 2.6902692854294346

Epoch: 6| Step: 7
Training loss: 0.41506571964599986
Validation loss: 2.736788921235204

Epoch: 6| Step: 8
Training loss: 0.33677363025901264
Validation loss: 2.7163802302096913

Epoch: 6| Step: 9
Training loss: 0.3593064947762781
Validation loss: 2.7684783010019958

Epoch: 6| Step: 10
Training loss: 0.5950836212236924
Validation loss: 2.7981143954452916

Epoch: 6| Step: 11
Training loss: 0.3893905972070953
Validation loss: 2.755873447799528

Epoch: 6| Step: 12
Training loss: 0.4193741530908711
Validation loss: 2.727575614876399

Epoch: 6| Step: 13
Training loss: 0.43863537467543184
Validation loss: 2.6827905925433173

Testing loss: 2.5318303874742445
