Epoch: 1| Step: 0
Training loss: 5.902355060276225
Validation loss: 5.941254964353292

Epoch: 5| Step: 1
Training loss: 5.529177002464739
Validation loss: 5.939783440248232

Epoch: 5| Step: 2
Training loss: 6.456486821516483
Validation loss: 5.938203616028558

Epoch: 5| Step: 3
Training loss: 5.5354892843199766
Validation loss: 5.936644522625453

Epoch: 5| Step: 4
Training loss: 6.404977960600743
Validation loss: 5.935135581404979

Epoch: 5| Step: 5
Training loss: 6.373621772932132
Validation loss: 5.933527819074864

Epoch: 5| Step: 6
Training loss: 5.888986374789887
Validation loss: 5.93186442305008

Epoch: 5| Step: 7
Training loss: 5.481405035455757
Validation loss: 5.930188874436623

Epoch: 5| Step: 8
Training loss: 6.240141455685351
Validation loss: 5.928471765211214

Epoch: 5| Step: 9
Training loss: 6.438625200321482
Validation loss: 5.926645831524528

Epoch: 5| Step: 10
Training loss: 6.135421295250624
Validation loss: 5.924730845265182

Epoch: 5| Step: 11
Training loss: 6.249806210374553
Validation loss: 5.922801492997781

Epoch: 2| Step: 0
Training loss: 6.563436968081919
Validation loss: 5.920836821502939

Epoch: 5| Step: 1
Training loss: 5.938118350305619
Validation loss: 5.918738065262456

Epoch: 5| Step: 2
Training loss: 6.428553614516024
Validation loss: 5.9164894999811715

Epoch: 5| Step: 3
Training loss: 5.879185261236246
Validation loss: 5.914288616015168

Epoch: 5| Step: 4
Training loss: 6.771249173428219
Validation loss: 5.911944790849065

Epoch: 5| Step: 5
Training loss: 5.400137913673533
Validation loss: 5.90947048245275

Epoch: 5| Step: 6
Training loss: 5.886397000476335
Validation loss: 5.906986971025212

Epoch: 5| Step: 7
Training loss: 5.606093442978475
Validation loss: 5.9043453718055625

Epoch: 5| Step: 8
Training loss: 5.827149664953994
Validation loss: 5.901623314801768

Epoch: 5| Step: 9
Training loss: 6.028763807116031
Validation loss: 5.8985882670352865

Epoch: 5| Step: 10
Training loss: 5.8345506033805385
Validation loss: 5.895789441685577

Epoch: 5| Step: 11
Training loss: 5.930185731806442
Validation loss: 5.892675998925633

Epoch: 3| Step: 0
Training loss: 5.699617326171549
Validation loss: 5.889521798225185

Epoch: 5| Step: 1
Training loss: 7.0195331520413395
Validation loss: 5.886047068454462

Epoch: 5| Step: 2
Training loss: 5.4394420794883365
Validation loss: 5.882301331999588

Epoch: 5| Step: 3
Training loss: 6.828584214749767
Validation loss: 5.878522243188046

Epoch: 5| Step: 4
Training loss: 5.494193913879056
Validation loss: 5.874312989668319

Epoch: 5| Step: 5
Training loss: 5.922910735612284
Validation loss: 5.870217033437817

Epoch: 5| Step: 6
Training loss: 5.586341256441719
Validation loss: 5.86584873223274

Epoch: 5| Step: 7
Training loss: 6.35112945844668
Validation loss: 5.861153796293156

Epoch: 5| Step: 8
Training loss: 5.535462580289312
Validation loss: 5.856422216053826

Epoch: 5| Step: 9
Training loss: 5.921950689551748
Validation loss: 5.8511593471394425

Epoch: 5| Step: 10
Training loss: 5.500415266139056
Validation loss: 5.845727766048568

Epoch: 5| Step: 11
Training loss: 7.226305421947617
Validation loss: 5.840294705503862

Epoch: 4| Step: 0
Training loss: 5.57554998721311
Validation loss: 5.834375154467653

Epoch: 5| Step: 1
Training loss: 5.90951141248389
Validation loss: 5.828174757894198

Epoch: 5| Step: 2
Training loss: 4.588811802210188
Validation loss: 5.821931078851131

Epoch: 5| Step: 3
Training loss: 4.99713300524358
Validation loss: 5.8151942882624015

Epoch: 5| Step: 4
Training loss: 6.586864763645203
Validation loss: 5.808483404066168

Epoch: 5| Step: 5
Training loss: 5.931388842100255
Validation loss: 5.801513927012204

Epoch: 5| Step: 6
Training loss: 6.466808377840117
Validation loss: 5.794438881026649

Epoch: 5| Step: 7
Training loss: 5.926860713521153
Validation loss: 5.786952963861187

Epoch: 5| Step: 8
Training loss: 5.9551553142545774
Validation loss: 5.77934283167031

Epoch: 5| Step: 9
Training loss: 6.465872451671104
Validation loss: 5.771137307581354

Epoch: 5| Step: 10
Training loss: 6.2137065736599535
Validation loss: 5.763287291735426

Epoch: 5| Step: 11
Training loss: 6.485444424238235
Validation loss: 5.754610852834078

Epoch: 5| Step: 0
Training loss: 6.040755139570714
Validation loss: 5.746255131989519

Epoch: 5| Step: 1
Training loss: 6.015587586125537
Validation loss: 5.737882000818878

Epoch: 5| Step: 2
Training loss: 5.892132715391857
Validation loss: 5.729040979104867

Epoch: 5| Step: 3
Training loss: 5.148623288033895
Validation loss: 5.7202727925557415

Epoch: 5| Step: 4
Training loss: 5.228582382488464
Validation loss: 5.711204630409309

Epoch: 5| Step: 5
Training loss: 5.351071523155232
Validation loss: 5.702853972383334

Epoch: 5| Step: 6
Training loss: 5.965111387352745
Validation loss: 5.69393003383599

Epoch: 5| Step: 7
Training loss: 5.961304499576407
Validation loss: 5.684909209513658

Epoch: 5| Step: 8
Training loss: 6.513422678422841
Validation loss: 5.676119208639011

Epoch: 5| Step: 9
Training loss: 5.890275292172525
Validation loss: 5.667135200578198

Epoch: 5| Step: 10
Training loss: 5.694691900236838
Validation loss: 5.657791349197123

Epoch: 5| Step: 11
Training loss: 6.6019747814123235
Validation loss: 5.64904399199353

Epoch: 6| Step: 0
Training loss: 5.7393285160535585
Validation loss: 5.640049039365974

Epoch: 5| Step: 1
Training loss: 4.698712582491222
Validation loss: 5.631094873050827

Epoch: 5| Step: 2
Training loss: 6.1061619263215565
Validation loss: 5.622467664854914

Epoch: 5| Step: 3
Training loss: 5.303398323995567
Validation loss: 5.613887243581551

Epoch: 5| Step: 4
Training loss: 5.991656223901695
Validation loss: 5.6050967563804495

Epoch: 5| Step: 5
Training loss: 6.430509160174024
Validation loss: 5.596746363209659

Epoch: 5| Step: 6
Training loss: 4.990127544416666
Validation loss: 5.588218411793122

Epoch: 5| Step: 7
Training loss: 5.520711568773172
Validation loss: 5.579904039280181

Epoch: 5| Step: 8
Training loss: 6.2250515242439715
Validation loss: 5.571530858464458

Epoch: 5| Step: 9
Training loss: 5.563585668334011
Validation loss: 5.563199188637165

Epoch: 5| Step: 10
Training loss: 5.978734478189624
Validation loss: 5.554793909898395

Epoch: 5| Step: 11
Training loss: 6.02819114162295
Validation loss: 5.546182487133629

Epoch: 7| Step: 0
Training loss: 6.349725924607058
Validation loss: 5.538176379146098

Epoch: 5| Step: 1
Training loss: 5.550960443920997
Validation loss: 5.529371125677059

Epoch: 5| Step: 2
Training loss: 5.80768114731154
Validation loss: 5.5208818277592355

Epoch: 5| Step: 3
Training loss: 6.125476429373997
Validation loss: 5.51233936891773

Epoch: 5| Step: 4
Training loss: 6.128460587684699
Validation loss: 5.504079245201072

Epoch: 5| Step: 5
Training loss: 5.498463155866011
Validation loss: 5.495331140825885

Epoch: 5| Step: 6
Training loss: 5.690510382799424
Validation loss: 5.486763147109954

Epoch: 5| Step: 7
Training loss: 4.926286349313707
Validation loss: 5.478491704098661

Epoch: 5| Step: 8
Training loss: 5.019497241190724
Validation loss: 5.470736733092409

Epoch: 5| Step: 9
Training loss: 5.4945643180590835
Validation loss: 5.462949644971707

Epoch: 5| Step: 10
Training loss: 5.02631965883032
Validation loss: 5.455159235086202

Epoch: 5| Step: 11
Training loss: 5.512244725966483
Validation loss: 5.447532876125438

Epoch: 8| Step: 0
Training loss: 5.8455376976049935
Validation loss: 5.440175461533995

Epoch: 5| Step: 1
Training loss: 6.069985085080973
Validation loss: 5.432384503584082

Epoch: 5| Step: 2
Training loss: 5.439089137283057
Validation loss: 5.425071777947099

Epoch: 5| Step: 3
Training loss: 5.9395073960649425
Validation loss: 5.417804417573794

Epoch: 5| Step: 4
Training loss: 4.797284136791496
Validation loss: 5.410523851302657

Epoch: 5| Step: 5
Training loss: 5.4216264563327154
Validation loss: 5.403418414987266

Epoch: 5| Step: 6
Training loss: 6.492469827363737
Validation loss: 5.396475126571729

Epoch: 5| Step: 7
Training loss: 4.748133644054961
Validation loss: 5.389620590621858

Epoch: 5| Step: 8
Training loss: 4.955069656575342
Validation loss: 5.382735814257438

Epoch: 5| Step: 9
Training loss: 5.251717967552882
Validation loss: 5.375728040373738

Epoch: 5| Step: 10
Training loss: 5.582468943323718
Validation loss: 5.369514024021315

Epoch: 5| Step: 11
Training loss: 5.39474727742235
Validation loss: 5.362735017548296

Epoch: 9| Step: 0
Training loss: 5.632338759226192
Validation loss: 5.356001983443736

Epoch: 5| Step: 1
Training loss: 5.062308978962696
Validation loss: 5.349481227120283

Epoch: 5| Step: 2
Training loss: 6.067981247774242
Validation loss: 5.342972600356985

Epoch: 5| Step: 3
Training loss: 5.778416614590657
Validation loss: 5.336346619440889

Epoch: 5| Step: 4
Training loss: 5.609328755902695
Validation loss: 5.330186387310681

Epoch: 5| Step: 5
Training loss: 4.505877577038441
Validation loss: 5.3236238068379675

Epoch: 5| Step: 6
Training loss: 5.250871858409563
Validation loss: 5.317279632753625

Epoch: 5| Step: 7
Training loss: 4.893730372052153
Validation loss: 5.310835723485348

Epoch: 5| Step: 8
Training loss: 5.859004871122227
Validation loss: 5.304256273737874

Epoch: 5| Step: 9
Training loss: 5.6502643759660085
Validation loss: 5.297394321006244

Epoch: 5| Step: 10
Training loss: 5.814388829632759
Validation loss: 5.291121517345441

Epoch: 5| Step: 11
Training loss: 2.5876851702052353
Validation loss: 5.284279686000344

Epoch: 10| Step: 0
Training loss: 5.197181950425642
Validation loss: 5.278043499609659

Epoch: 5| Step: 1
Training loss: 5.190286646223954
Validation loss: 5.271497687084703

Epoch: 5| Step: 2
Training loss: 5.153383510159437
Validation loss: 5.265151948743777

Epoch: 5| Step: 3
Training loss: 5.5880626557318385
Validation loss: 5.259069253817927

Epoch: 5| Step: 4
Training loss: 5.436882597850767
Validation loss: 5.252193280402948

Epoch: 5| Step: 5
Training loss: 4.641954636101901
Validation loss: 5.245259975927556

Epoch: 5| Step: 6
Training loss: 5.583054360020013
Validation loss: 5.238871170192423

Epoch: 5| Step: 7
Training loss: 5.307510366479109
Validation loss: 5.232269698784251

Epoch: 5| Step: 8
Training loss: 5.634426441264584
Validation loss: 5.225600453908328

Epoch: 5| Step: 9
Training loss: 5.7235514178278795
Validation loss: 5.218994842998926

Epoch: 5| Step: 10
Training loss: 5.5469886445774605
Validation loss: 5.21245323757843

Epoch: 5| Step: 11
Training loss: 5.120505246028889
Validation loss: 5.205192773640617

Epoch: 11| Step: 0
Training loss: 4.102344837962268
Validation loss: 5.199225842485145

Epoch: 5| Step: 1
Training loss: 5.53815697073009
Validation loss: 5.192288911410543

Epoch: 5| Step: 2
Training loss: 5.708309127125152
Validation loss: 5.1863933976212335

Epoch: 5| Step: 3
Training loss: 5.065348071295202
Validation loss: 5.180482238589358

Epoch: 5| Step: 4
Training loss: 5.780493444479452
Validation loss: 5.174134113522494

Epoch: 5| Step: 5
Training loss: 4.385280845634949
Validation loss: 5.168048361128783

Epoch: 5| Step: 6
Training loss: 5.283673514757216
Validation loss: 5.161816753590454

Epoch: 5| Step: 7
Training loss: 5.107923388976801
Validation loss: 5.156504699889836

Epoch: 5| Step: 8
Training loss: 5.988636063567018
Validation loss: 5.150953697736565

Epoch: 5| Step: 9
Training loss: 5.073899045391734
Validation loss: 5.1444713962696635

Epoch: 5| Step: 10
Training loss: 5.776694652726579
Validation loss: 5.138563266381131

Epoch: 5| Step: 11
Training loss: 5.572642648205134
Validation loss: 5.1329355210609995

Epoch: 12| Step: 0
Training loss: 4.238295200869897
Validation loss: 5.1265700424217915

Epoch: 5| Step: 1
Training loss: 5.859999966670221
Validation loss: 5.120319888967429

Epoch: 5| Step: 2
Training loss: 5.096095568983943
Validation loss: 5.1150041499016945

Epoch: 5| Step: 3
Training loss: 4.859223685407897
Validation loss: 5.108686410464463

Epoch: 5| Step: 4
Training loss: 5.3102126638927185
Validation loss: 5.1027643989318845

Epoch: 5| Step: 5
Training loss: 5.149806580105703
Validation loss: 5.096717204277277

Epoch: 5| Step: 6
Training loss: 5.19445573439479
Validation loss: 5.091203376724502

Epoch: 5| Step: 7
Training loss: 5.979456381696037
Validation loss: 5.08524741683336

Epoch: 5| Step: 8
Training loss: 5.449356307067556
Validation loss: 5.079724714224408

Epoch: 5| Step: 9
Training loss: 4.935338959807458
Validation loss: 5.074098087840764

Epoch: 5| Step: 10
Training loss: 5.243495363002257
Validation loss: 5.068537718392047

Epoch: 5| Step: 11
Training loss: 4.759193558218132
Validation loss: 5.062676768101368

Epoch: 13| Step: 0
Training loss: 5.2426783051955015
Validation loss: 5.056281497324386

Epoch: 5| Step: 1
Training loss: 4.521530355462749
Validation loss: 5.050392106385198

Epoch: 5| Step: 2
Training loss: 4.725524889336245
Validation loss: 5.045260317727406

Epoch: 5| Step: 3
Training loss: 5.2426783051955015
Validation loss: 5.039878254787453

Epoch: 5| Step: 4
Training loss: 5.26943514929281
Validation loss: 5.033948865520411

Epoch: 5| Step: 5
Training loss: 5.764293320445348
Validation loss: 5.027962884369928

Epoch: 5| Step: 6
Training loss: 4.081306473485859
Validation loss: 5.022559928277009

Epoch: 5| Step: 7
Training loss: 5.765095673533962
Validation loss: 5.01702458075456

Epoch: 5| Step: 8
Training loss: 5.587610722411242
Validation loss: 5.0113822445445

Epoch: 5| Step: 9
Training loss: 5.928836324161042
Validation loss: 5.0050556134422015

Epoch: 5| Step: 10
Training loss: 4.658149894874062
Validation loss: 4.998833424853847

Epoch: 5| Step: 11
Training loss: 1.934555646753156
Validation loss: 4.994044197911015

Epoch: 14| Step: 0
Training loss: 4.830625806115698
Validation loss: 4.989337981475902

Epoch: 5| Step: 1
Training loss: 4.572631039167859
Validation loss: 4.98234084504703

Epoch: 5| Step: 2
Training loss: 4.920840587605237
Validation loss: 4.97669682503616

Epoch: 5| Step: 3
Training loss: 5.34390615491643
Validation loss: 4.973002151800738

Epoch: 5| Step: 4
Training loss: 5.184076121466032
Validation loss: 4.967408284987061

Epoch: 5| Step: 5
Training loss: 5.154290584142618
Validation loss: 4.9610284671803555

Epoch: 5| Step: 6
Training loss: 5.249206483000252
Validation loss: 4.955561458805561

Epoch: 5| Step: 7
Training loss: 5.718475835513136
Validation loss: 4.950836687949962

Epoch: 5| Step: 8
Training loss: 5.268478028143633
Validation loss: 4.945454238379056

Epoch: 5| Step: 9
Training loss: 4.950006219108605
Validation loss: 4.938829854546358

Epoch: 5| Step: 10
Training loss: 4.8151873726994365
Validation loss: 4.933915917797946

Epoch: 5| Step: 11
Training loss: 4.313419188795195
Validation loss: 4.9292719162544065

Epoch: 15| Step: 0
Training loss: 5.236090626607682
Validation loss: 4.924159162813362

Epoch: 5| Step: 1
Training loss: 4.712168973836601
Validation loss: 4.917918452701806

Epoch: 5| Step: 2
Training loss: 4.916599898235179
Validation loss: 4.911996266533451

Epoch: 5| Step: 3
Training loss: 4.907295261490515
Validation loss: 4.906621121181349

Epoch: 5| Step: 4
Training loss: 5.908704459618308
Validation loss: 4.902235757922529

Epoch: 5| Step: 5
Training loss: 5.19379346625069
Validation loss: 4.8970825576532775

Epoch: 5| Step: 6
Training loss: 4.993259846070587
Validation loss: 4.890948568249575

Epoch: 5| Step: 7
Training loss: 5.2948289368457395
Validation loss: 4.884265726127716

Epoch: 5| Step: 8
Training loss: 3.4319570066609004
Validation loss: 4.878975645029409

Epoch: 5| Step: 9
Training loss: 4.822713541431832
Validation loss: 4.875029673852842

Epoch: 5| Step: 10
Training loss: 5.17630101311204
Validation loss: 4.868419689225304

Epoch: 5| Step: 11
Training loss: 6.268627636400782
Validation loss: 4.861799030069213

Epoch: 16| Step: 0
Training loss: 4.981350641897165
Validation loss: 4.858462559773667

Epoch: 5| Step: 1
Training loss: 5.65364883214261
Validation loss: 4.854748755114506

Epoch: 5| Step: 2
Training loss: 5.181329205210153
Validation loss: 4.846630044170858

Epoch: 5| Step: 3
Training loss: 4.747081663192303
Validation loss: 4.841474027078709

Epoch: 5| Step: 4
Training loss: 4.758105339471667
Validation loss: 4.837090263954306

Epoch: 5| Step: 5
Training loss: 5.068137338585417
Validation loss: 4.8322257411653835

Epoch: 5| Step: 6
Training loss: 4.0054929687529714
Validation loss: 4.82549073288312

Epoch: 5| Step: 7
Training loss: 5.18362962585315
Validation loss: 4.820267160327101

Epoch: 5| Step: 8
Training loss: 4.799961153508986
Validation loss: 4.813926939359302

Epoch: 5| Step: 9
Training loss: 5.05017813188984
Validation loss: 4.809775088835432

Epoch: 5| Step: 10
Training loss: 5.128578053510753
Validation loss: 4.8051002966065335

Epoch: 5| Step: 11
Training loss: 3.955996348850891
Validation loss: 4.798529663658321

Epoch: 17| Step: 0
Training loss: 5.18958617396247
Validation loss: 4.793760715623507

Epoch: 5| Step: 1
Training loss: 5.3538820460724414
Validation loss: 4.78830436277317

Epoch: 5| Step: 2
Training loss: 4.407108520847469
Validation loss: 4.782391189650823

Epoch: 5| Step: 3
Training loss: 4.24760818496348
Validation loss: 4.7775915522963155

Epoch: 5| Step: 4
Training loss: 4.753292147514607
Validation loss: 4.773304714222754

Epoch: 5| Step: 5
Training loss: 5.1288205304503816
Validation loss: 4.768457231913066

Epoch: 5| Step: 6
Training loss: 5.035656060033891
Validation loss: 4.76175642741868

Epoch: 5| Step: 7
Training loss: 4.083975267879014
Validation loss: 4.75663960014525

Epoch: 5| Step: 8
Training loss: 5.227173180819656
Validation loss: 4.7516689212936

Epoch: 5| Step: 9
Training loss: 5.155981808247816
Validation loss: 4.748355815151806

Epoch: 5| Step: 10
Training loss: 4.93216948742246
Validation loss: 4.741897171911914

Epoch: 5| Step: 11
Training loss: 5.507706531560389
Validation loss: 4.7358132119830625

Epoch: 18| Step: 0
Training loss: 4.462551272656033
Validation loss: 4.730784490975027

Epoch: 5| Step: 1
Training loss: 4.407662023378052
Validation loss: 4.7259124645150274

Epoch: 5| Step: 2
Training loss: 5.160030574264434
Validation loss: 4.721172679254172

Epoch: 5| Step: 3
Training loss: 5.055343090152761
Validation loss: 4.714530869126153

Epoch: 5| Step: 4
Training loss: 4.2282264804432925
Validation loss: 4.7094364336913745

Epoch: 5| Step: 5
Training loss: 4.474828467464694
Validation loss: 4.704181582030491

Epoch: 5| Step: 6
Training loss: 4.525784688955192
Validation loss: 4.6997813339635

Epoch: 5| Step: 7
Training loss: 5.58865294711576
Validation loss: 4.695255306697431

Epoch: 5| Step: 8
Training loss: 5.001607636447966
Validation loss: 4.689695310449094

Epoch: 5| Step: 9
Training loss: 5.110063325672472
Validation loss: 4.683451120359284

Epoch: 5| Step: 10
Training loss: 5.0013109395939335
Validation loss: 4.678706028526394

Epoch: 5| Step: 11
Training loss: 4.54140938312994
Validation loss: 4.67614773551895

Epoch: 19| Step: 0
Training loss: 4.7459195328749955
Validation loss: 4.669387044345165

Epoch: 5| Step: 1
Training loss: 4.477212003288173
Validation loss: 4.662285956820985

Epoch: 5| Step: 2
Training loss: 5.044272114745847
Validation loss: 4.656439792255425

Epoch: 5| Step: 3
Training loss: 4.625703088054603
Validation loss: 4.652335465063773

Epoch: 5| Step: 4
Training loss: 3.7383998744403764
Validation loss: 4.6471372949780445

Epoch: 5| Step: 5
Training loss: 5.444788465638208
Validation loss: 4.642422936819661

Epoch: 5| Step: 6
Training loss: 5.045411077713612
Validation loss: 4.635836827241791

Epoch: 5| Step: 7
Training loss: 4.588631405712409
Validation loss: 4.630561929538314

Epoch: 5| Step: 8
Training loss: 4.608993462758012
Validation loss: 4.625807983685411

Epoch: 5| Step: 9
Training loss: 4.462939559701633
Validation loss: 4.620307414766226

Epoch: 5| Step: 10
Training loss: 5.3132621667197
Validation loss: 4.615667481292574

Epoch: 5| Step: 11
Training loss: 5.3403655817854965
Validation loss: 4.609169846619097

Epoch: 20| Step: 0
Training loss: 5.472988905452312
Validation loss: 4.604097968519643

Epoch: 5| Step: 1
Training loss: 4.643292723124622
Validation loss: 4.599586036444737

Epoch: 5| Step: 2
Training loss: 3.874957915046793
Validation loss: 4.595515701140395

Epoch: 5| Step: 3
Training loss: 4.774026837468873
Validation loss: 4.59018456458504

Epoch: 5| Step: 4
Training loss: 4.315231563856919
Validation loss: 4.584577151788427

Epoch: 5| Step: 5
Training loss: 4.8885727741653335
Validation loss: 4.578574469920776

Epoch: 5| Step: 6
Training loss: 5.0654649882192455
Validation loss: 4.573904155334175

Epoch: 5| Step: 7
Training loss: 4.616240170238782
Validation loss: 4.57105582080301

Epoch: 5| Step: 8
Training loss: 4.287627211037601
Validation loss: 4.5643518251912605

Epoch: 5| Step: 9
Training loss: 4.448747591520184
Validation loss: 4.558024253455404

Epoch: 5| Step: 10
Training loss: 5.153109247057486
Validation loss: 4.551723106615894

Epoch: 5| Step: 11
Training loss: 4.825205886480268
Validation loss: 4.546918827295732

Epoch: 21| Step: 0
Training loss: 4.76449501523972
Validation loss: 4.541982826404252

Epoch: 5| Step: 1
Training loss: 5.005488625682405
Validation loss: 4.535998336063396

Epoch: 5| Step: 2
Training loss: 4.063484659441284
Validation loss: 4.530419030124723

Epoch: 5| Step: 3
Training loss: 5.270374363553962
Validation loss: 4.52632306463909

Epoch: 5| Step: 4
Training loss: 4.9203302774989455
Validation loss: 4.521103212179563

Epoch: 5| Step: 5
Training loss: 4.83529594738561
Validation loss: 4.51501350266334

Epoch: 5| Step: 6
Training loss: 4.547888783701292
Validation loss: 4.508750262639837

Epoch: 5| Step: 7
Training loss: 4.070722504392024
Validation loss: 4.504598956341083

Epoch: 5| Step: 8
Training loss: 3.974634088912723
Validation loss: 4.500002075124192

Epoch: 5| Step: 9
Training loss: 4.688312104131101
Validation loss: 4.494176266277597

Epoch: 5| Step: 10
Training loss: 4.777970130261786
Validation loss: 4.488866335739527

Epoch: 5| Step: 11
Training loss: 4.524119271403525
Validation loss: 4.483097022799931

Epoch: 22| Step: 0
Training loss: 4.602033762609447
Validation loss: 4.478342338234002

Epoch: 5| Step: 1
Training loss: 4.5079823797468865
Validation loss: 4.4731514780105615

Epoch: 5| Step: 2
Training loss: 5.082982952779026
Validation loss: 4.468523682240899

Epoch: 5| Step: 3
Training loss: 4.842882435536075
Validation loss: 4.462401506706527

Epoch: 5| Step: 4
Training loss: 3.870158462631589
Validation loss: 4.456969492264606

Epoch: 5| Step: 5
Training loss: 4.943259827128841
Validation loss: 4.453178820368466

Epoch: 5| Step: 6
Training loss: 4.649767773479665
Validation loss: 4.449102219910734

Epoch: 5| Step: 7
Training loss: 4.554302637711853
Validation loss: 4.443751860670513

Epoch: 5| Step: 8
Training loss: 4.744298424261711
Validation loss: 4.437432516954967

Epoch: 5| Step: 9
Training loss: 4.171735782657816
Validation loss: 4.4299960917562515

Epoch: 5| Step: 10
Training loss: 4.135953520832802
Validation loss: 4.4254289236001645

Epoch: 5| Step: 11
Training loss: 5.247795368694311
Validation loss: 4.420714510268484

Epoch: 23| Step: 0
Training loss: 4.82986448488804
Validation loss: 4.412322195863588

Epoch: 5| Step: 1
Training loss: 4.250463572632448
Validation loss: 4.407185272625212

Epoch: 5| Step: 2
Training loss: 4.101178832501956
Validation loss: 4.402577134235963

Epoch: 5| Step: 3
Training loss: 4.609944971049915
Validation loss: 4.3974322564403066

Epoch: 5| Step: 4
Training loss: 4.0901214592766975
Validation loss: 4.392114456783511

Epoch: 5| Step: 5
Training loss: 4.784350617768333
Validation loss: 4.384282518944513

Epoch: 5| Step: 6
Training loss: 4.62044114884197
Validation loss: 4.379152865558997

Epoch: 5| Step: 7
Training loss: 4.887968176543037
Validation loss: 4.374615761368773

Epoch: 5| Step: 8
Training loss: 4.264597115667547
Validation loss: 4.370121997567767

Epoch: 5| Step: 9
Training loss: 4.795752179574702
Validation loss: 4.362471812502383

Epoch: 5| Step: 10
Training loss: 4.647130445835928
Validation loss: 4.358124155868448

Epoch: 5| Step: 11
Training loss: 2.431334008184949
Validation loss: 4.351944939126538

Epoch: 24| Step: 0
Training loss: 3.960518297513158
Validation loss: 4.346170108007127

Epoch: 5| Step: 1
Training loss: 4.405001416070821
Validation loss: 4.341480110294821

Epoch: 5| Step: 2
Training loss: 3.6594134608071047
Validation loss: 4.336996688004158

Epoch: 5| Step: 3
Training loss: 4.734282539900057
Validation loss: 4.33175273948206

Epoch: 5| Step: 4
Training loss: 4.238639907779648
Validation loss: 4.326619709335124

Epoch: 5| Step: 5
Training loss: 5.036831431358402
Validation loss: 4.321696238614578

Epoch: 5| Step: 6
Training loss: 4.9799070991522045
Validation loss: 4.316860224583147

Epoch: 5| Step: 7
Training loss: 4.612878741503344
Validation loss: 4.311612586154245

Epoch: 5| Step: 8
Training loss: 3.994186348874896
Validation loss: 4.307471084394354

Epoch: 5| Step: 9
Training loss: 5.05353402090694
Validation loss: 4.301940733953158

Epoch: 5| Step: 10
Training loss: 4.128877378018141
Validation loss: 4.297194613505234

Epoch: 5| Step: 11
Training loss: 3.9278885532736894
Validation loss: 4.293020010339293

Epoch: 25| Step: 0
Training loss: 3.6880448795492358
Validation loss: 4.288161664349273

Epoch: 5| Step: 1
Training loss: 4.139078564034866
Validation loss: 4.284691255946332

Epoch: 5| Step: 2
Training loss: 4.363885330553801
Validation loss: 4.2795282739789124

Epoch: 5| Step: 3
Training loss: 4.758819824219526
Validation loss: 4.275109010091067

Epoch: 5| Step: 4
Training loss: 4.154285855944484
Validation loss: 4.269363916578441

Epoch: 5| Step: 5
Training loss: 4.404369412858867
Validation loss: 4.26486817424149

Epoch: 5| Step: 6
Training loss: 4.7752755929396775
Validation loss: 4.261196599826968

Epoch: 5| Step: 7
Training loss: 4.483721854996542
Validation loss: 4.255995551152999

Epoch: 5| Step: 8
Training loss: 5.02166840295079
Validation loss: 4.251060269436666

Epoch: 5| Step: 9
Training loss: 4.287111154612387
Validation loss: 4.24709960197617

Epoch: 5| Step: 10
Training loss: 4.488480977660082
Validation loss: 4.241809839868843

Epoch: 5| Step: 11
Training loss: 1.7319099848396158
Validation loss: 4.237240514996823

Epoch: 26| Step: 0
Training loss: 4.240016655799253
Validation loss: 4.233427328783335

Epoch: 5| Step: 1
Training loss: 4.392362529099361
Validation loss: 4.22897572235111

Epoch: 5| Step: 2
Training loss: 4.110619650209857
Validation loss: 4.22504477242066

Epoch: 5| Step: 3
Training loss: 4.665907094083648
Validation loss: 4.220143867333365

Epoch: 5| Step: 4
Training loss: 4.301556176992606
Validation loss: 4.215604725782592

Epoch: 5| Step: 5
Training loss: 4.456637740420554
Validation loss: 4.21112817392748

Epoch: 5| Step: 6
Training loss: 4.343148827975316
Validation loss: 4.20700288584152

Epoch: 5| Step: 7
Training loss: 3.5605466071550915
Validation loss: 4.203300552767219

Epoch: 5| Step: 8
Training loss: 4.940396195867651
Validation loss: 4.19821359358902

Epoch: 5| Step: 9
Training loss: 4.667484529670858
Validation loss: 4.193823215586468

Epoch: 5| Step: 10
Training loss: 3.8247521313906274
Validation loss: 4.18955518098791

Epoch: 5| Step: 11
Training loss: 4.757790050234392
Validation loss: 4.1852912106785825

Epoch: 27| Step: 0
Training loss: 4.322069690260755
Validation loss: 4.180479536741832

Epoch: 5| Step: 1
Training loss: 4.481511813593263
Validation loss: 4.1768183762888995

Epoch: 5| Step: 2
Training loss: 4.220859932446934
Validation loss: 4.172642888372318

Epoch: 5| Step: 3
Training loss: 4.634177921809469
Validation loss: 4.167950864620619

Epoch: 5| Step: 4
Training loss: 4.769759589000816
Validation loss: 4.163929963999671

Epoch: 5| Step: 5
Training loss: 3.635141196466722
Validation loss: 4.15873992641992

Epoch: 5| Step: 6
Training loss: 4.538896094733725
Validation loss: 4.154328396798201

Epoch: 5| Step: 7
Training loss: 4.097140938909841
Validation loss: 4.150657481272425

Epoch: 5| Step: 8
Training loss: 4.764671155183851
Validation loss: 4.146627774950592

Epoch: 5| Step: 9
Training loss: 3.7400928600023327
Validation loss: 4.141932198374313

Epoch: 5| Step: 10
Training loss: 3.9832533510443393
Validation loss: 4.13776474534985

Epoch: 5| Step: 11
Training loss: 3.348979532620662
Validation loss: 4.133096695991535

Epoch: 28| Step: 0
Training loss: 4.355784698111663
Validation loss: 4.128900841330767

Epoch: 5| Step: 1
Training loss: 3.9137350162400812
Validation loss: 4.124728449158118

Epoch: 5| Step: 2
Training loss: 4.486689485337914
Validation loss: 4.120496511949389

Epoch: 5| Step: 3
Training loss: 3.642384509138835
Validation loss: 4.115930798562075

Epoch: 5| Step: 4
Training loss: 4.431224630307423
Validation loss: 4.112146552530135

Epoch: 5| Step: 5
Training loss: 4.281521976491615
Validation loss: 4.107695866212271

Epoch: 5| Step: 6
Training loss: 4.608204217703524
Validation loss: 4.1031489135014345

Epoch: 5| Step: 7
Training loss: 4.267947280944309
Validation loss: 4.099343261999131

Epoch: 5| Step: 8
Training loss: 4.303212877316771
Validation loss: 4.09461000741971

Epoch: 5| Step: 9
Training loss: 3.796798014547132
Validation loss: 4.091585246996279

Epoch: 5| Step: 10
Training loss: 4.47595572894773
Validation loss: 4.087268080241874

Epoch: 5| Step: 11
Training loss: 4.0547876952035145
Validation loss: 4.082325512563313

Epoch: 29| Step: 0
Training loss: 4.078524865902758
Validation loss: 4.078163726544814

Epoch: 5| Step: 1
Training loss: 4.367157364470041
Validation loss: 4.074087060962233

Epoch: 5| Step: 2
Training loss: 3.783200982309344
Validation loss: 4.069243316902387

Epoch: 5| Step: 3
Training loss: 4.34041593747119
Validation loss: 4.065309457851345

Epoch: 5| Step: 4
Training loss: 4.4969917414756715
Validation loss: 4.061437966836311

Epoch: 5| Step: 5
Training loss: 4.593688964438271
Validation loss: 4.056551387896931

Epoch: 5| Step: 6
Training loss: 5.113203102021708
Validation loss: 4.052263749461037

Epoch: 5| Step: 7
Training loss: 4.027630741168688
Validation loss: 4.047907021406812

Epoch: 5| Step: 8
Training loss: 3.7803526515047206
Validation loss: 4.043552861427242

Epoch: 5| Step: 9
Training loss: 3.751314060130713
Validation loss: 4.03921260099826

Epoch: 5| Step: 10
Training loss: 3.434491731223597
Validation loss: 4.034771113373954

Epoch: 5| Step: 11
Training loss: 4.434382888539605
Validation loss: 4.0306271015117785

Epoch: 30| Step: 0
Training loss: 5.02594169029721
Validation loss: 4.026442847881434

Epoch: 5| Step: 1
Training loss: 3.5354382818696846
Validation loss: 4.021774466798644

Epoch: 5| Step: 2
Training loss: 3.7498888635061522
Validation loss: 4.016983277490939

Epoch: 5| Step: 3
Training loss: 3.2448250578524096
Validation loss: 4.0131749349023345

Epoch: 5| Step: 4
Training loss: 4.24783584245936
Validation loss: 4.009598966523966

Epoch: 5| Step: 5
Training loss: 3.5405698686096896
Validation loss: 4.004751517540374

Epoch: 5| Step: 6
Training loss: 3.89339033152606
Validation loss: 4.000828458505871

Epoch: 5| Step: 7
Training loss: 4.416268072795842
Validation loss: 3.997423852414357

Epoch: 5| Step: 8
Training loss: 4.527120668643803
Validation loss: 3.9929458236359583

Epoch: 5| Step: 9
Training loss: 4.2350078264724855
Validation loss: 3.9887742981010734

Epoch: 5| Step: 10
Training loss: 4.385659012550478
Validation loss: 3.9843010290921295

Epoch: 5| Step: 11
Training loss: 5.706346746253383
Validation loss: 3.9805138772260094

Epoch: 31| Step: 0
Training loss: 3.9308223716179183
Validation loss: 3.9764290358174494

Epoch: 5| Step: 1
Training loss: 4.142449894511706
Validation loss: 3.9712626295536286

Epoch: 5| Step: 2
Training loss: 3.8099312805626644
Validation loss: 3.9671774624806093

Epoch: 5| Step: 3
Training loss: 3.9329943839546413
Validation loss: 3.9626054631427445

Epoch: 5| Step: 4
Training loss: 3.6275419333496957
Validation loss: 3.9591976058790594

Epoch: 5| Step: 5
Training loss: 4.703829791720004
Validation loss: 3.955116172576123

Epoch: 5| Step: 6
Training loss: 4.394330724591613
Validation loss: 3.95031407652797

Epoch: 5| Step: 7
Training loss: 4.052197818397299
Validation loss: 3.9457166961999492

Epoch: 5| Step: 8
Training loss: 3.966204931061402
Validation loss: 3.9411148855833393

Epoch: 5| Step: 9
Training loss: 4.669424990229513
Validation loss: 3.93670356607761

Epoch: 5| Step: 10
Training loss: 3.5977353761402404
Validation loss: 3.934031977608708

Epoch: 5| Step: 11
Training loss: 3.935119878355836
Validation loss: 3.929353728886284

Epoch: 32| Step: 0
Training loss: 3.220109818996695
Validation loss: 3.9250731631463815

Epoch: 5| Step: 1
Training loss: 3.2622634158823676
Validation loss: 3.9201394251840047

Epoch: 5| Step: 2
Training loss: 4.2502113738509655
Validation loss: 3.916911440498655

Epoch: 5| Step: 3
Training loss: 4.156887607856458
Validation loss: 3.911731241443829

Epoch: 5| Step: 4
Training loss: 4.162610915713852
Validation loss: 3.90843375645657

Epoch: 5| Step: 5
Training loss: 3.625837558143894
Validation loss: 3.9043775877402815

Epoch: 5| Step: 6
Training loss: 4.588513354395604
Validation loss: 3.901185050471779

Epoch: 5| Step: 7
Training loss: 4.421598284255265
Validation loss: 3.896457605102669

Epoch: 5| Step: 8
Training loss: 4.168901734114295
Validation loss: 3.8923096131135613

Epoch: 5| Step: 9
Training loss: 3.9091134524350646
Validation loss: 3.8878575380360374

Epoch: 5| Step: 10
Training loss: 4.320595481944997
Validation loss: 3.8835784954783636

Epoch: 5| Step: 11
Training loss: 4.315216093697132
Validation loss: 3.8788730380457044

Epoch: 33| Step: 0
Training loss: 3.981045996501086
Validation loss: 3.8752672862089077

Epoch: 5| Step: 1
Training loss: 4.537756727117701
Validation loss: 3.871601357589995

Epoch: 5| Step: 2
Training loss: 3.289525812639488
Validation loss: 3.8664762774133177

Epoch: 5| Step: 3
Training loss: 4.050996191636487
Validation loss: 3.8626736740769236

Epoch: 5| Step: 4
Training loss: 4.319348853805863
Validation loss: 3.85850485749314

Epoch: 5| Step: 5
Training loss: 5.127331273256856
Validation loss: 3.855043948912961

Epoch: 5| Step: 6
Training loss: 3.825204786416019
Validation loss: 3.8495569585221534

Epoch: 5| Step: 7
Training loss: 4.477237776975025
Validation loss: 3.845446571431944

Epoch: 5| Step: 8
Training loss: 2.5502223385388705
Validation loss: 3.840856507175484

Epoch: 5| Step: 9
Training loss: 3.2712622359283485
Validation loss: 3.8363864063677844

Epoch: 5| Step: 10
Training loss: 3.925109016216565
Validation loss: 3.8326730401344498

Epoch: 5| Step: 11
Training loss: 3.4915574292656784
Validation loss: 3.829019091768008

Epoch: 34| Step: 0
Training loss: 4.560751383931726
Validation loss: 3.8250389479438978

Epoch: 5| Step: 1
Training loss: 4.173624079228017
Validation loss: 3.820827504024961

Epoch: 5| Step: 2
Training loss: 4.292828128028421
Validation loss: 3.8169422170266105

Epoch: 5| Step: 3
Training loss: 3.575794510486528
Validation loss: 3.812558559322365

Epoch: 5| Step: 4
Training loss: 3.9001810765411355
Validation loss: 3.8090679114812356

Epoch: 5| Step: 5
Training loss: 2.796975075407132
Validation loss: 3.8048748829238783

Epoch: 5| Step: 6
Training loss: 3.6620492182559086
Validation loss: 3.800949343877955

Epoch: 5| Step: 7
Training loss: 3.8534204671395287
Validation loss: 3.797710996462217

Epoch: 5| Step: 8
Training loss: 4.429126414669053
Validation loss: 3.793484399685103

Epoch: 5| Step: 9
Training loss: 3.849113753729285
Validation loss: 3.7897197035456673

Epoch: 5| Step: 10
Training loss: 4.132296264943337
Validation loss: 3.7857370262371255

Epoch: 5| Step: 11
Training loss: 2.923337030035079
Validation loss: 3.7817339889538126

Epoch: 35| Step: 0
Training loss: 4.008960224916298
Validation loss: 3.778173603368922

Epoch: 5| Step: 1
Training loss: 3.5562247169816055
Validation loss: 3.7744674014278394

Epoch: 5| Step: 2
Training loss: 4.139283851934386
Validation loss: 3.7711833331274422

Epoch: 5| Step: 3
Training loss: 3.673527771730173
Validation loss: 3.76716645534338

Epoch: 5| Step: 4
Training loss: 4.17240416639016
Validation loss: 3.7630621761528067

Epoch: 5| Step: 5
Training loss: 3.975197428472819
Validation loss: 3.7588026047004526

Epoch: 5| Step: 6
Training loss: 4.462519216629667
Validation loss: 3.7558667491484043

Epoch: 5| Step: 7
Training loss: 3.369205728537653
Validation loss: 3.751405012984361

Epoch: 5| Step: 8
Training loss: 3.9850843807845093
Validation loss: 3.7472694946510856

Epoch: 5| Step: 9
Training loss: 3.9257236761170016
Validation loss: 3.743244597891196

Epoch: 5| Step: 10
Training loss: 3.215765300689124
Validation loss: 3.7394986032363575

Epoch: 5| Step: 11
Training loss: 4.711516235634497
Validation loss: 3.735829297600418

Epoch: 36| Step: 0
Training loss: 4.009050382583483
Validation loss: 3.731551450291267

Epoch: 5| Step: 1
Training loss: 3.777321784854053
Validation loss: 3.728065773982982

Epoch: 5| Step: 2
Training loss: 4.433404456311446
Validation loss: 3.7234331556501084

Epoch: 5| Step: 3
Training loss: 4.3323854485637305
Validation loss: 3.719250161865351

Epoch: 5| Step: 4
Training loss: 4.015249746875673
Validation loss: 3.7151938031808625

Epoch: 5| Step: 5
Training loss: 2.3148977890684996
Validation loss: 3.710643138253252

Epoch: 5| Step: 6
Training loss: 3.6699018655488307
Validation loss: 3.707355518582572

Epoch: 5| Step: 7
Training loss: 3.492885033498636
Validation loss: 3.703908743458877

Epoch: 5| Step: 8
Training loss: 4.063191516415669
Validation loss: 3.6992355824308776

Epoch: 5| Step: 9
Training loss: 4.0202545909069
Validation loss: 3.695448305028476

Epoch: 5| Step: 10
Training loss: 3.6513208272581767
Validation loss: 3.6917423371136686

Epoch: 5| Step: 11
Training loss: 4.434583538332237
Validation loss: 3.6879657354262942

Epoch: 37| Step: 0
Training loss: 4.229217428770299
Validation loss: 3.6840745080222637

Epoch: 5| Step: 1
Training loss: 4.688638777688732
Validation loss: 3.679968130070442

Epoch: 5| Step: 2
Training loss: 3.2171872984268695
Validation loss: 3.6760307170603594

Epoch: 5| Step: 3
Training loss: 4.069418781591629
Validation loss: 3.671724524695078

Epoch: 5| Step: 4
Training loss: 3.7202860761182306
Validation loss: 3.6680861980036683

Epoch: 5| Step: 5
Training loss: 3.3952383132462662
Validation loss: 3.663787310907145

Epoch: 5| Step: 6
Training loss: 3.889268385823397
Validation loss: 3.659783690771005

Epoch: 5| Step: 7
Training loss: 3.790672353525779
Validation loss: 3.65581082154447

Epoch: 5| Step: 8
Training loss: 3.6637303704081146
Validation loss: 3.651996768782162

Epoch: 5| Step: 9
Training loss: 3.786144525186616
Validation loss: 3.6485104060053173

Epoch: 5| Step: 10
Training loss: 3.3029535312230696
Validation loss: 3.644458100844463

Epoch: 5| Step: 11
Training loss: 2.848603184035582
Validation loss: 3.6404221495952767

Epoch: 38| Step: 0
Training loss: 3.6726015062112705
Validation loss: 3.6370877776284667

Epoch: 5| Step: 1
Training loss: 3.702587233500338
Validation loss: 3.632923619474809

Epoch: 5| Step: 2
Training loss: 4.590322240683701
Validation loss: 3.629293655833674

Epoch: 5| Step: 3
Training loss: 3.7850164145513094
Validation loss: 3.625527792906889

Epoch: 5| Step: 4
Training loss: 3.227080001156201
Validation loss: 3.6218873066291257

Epoch: 5| Step: 5
Training loss: 4.542736778995378
Validation loss: 3.6180027701411372

Epoch: 5| Step: 6
Training loss: 3.5883234600870955
Validation loss: 3.614158103328168

Epoch: 5| Step: 7
Training loss: 3.071472570034465
Validation loss: 3.610358870642229

Epoch: 5| Step: 8
Training loss: 3.979215385311863
Validation loss: 3.606625152106285

Epoch: 5| Step: 9
Training loss: 3.7436007258184123
Validation loss: 3.602827720145608

Epoch: 5| Step: 10
Training loss: 3.016188810939611
Validation loss: 3.599164433335458

Epoch: 5| Step: 11
Training loss: 3.9585531608709523
Validation loss: 3.5953939409577016

Epoch: 39| Step: 0
Training loss: 4.150005956438685
Validation loss: 3.591730180445778

Epoch: 5| Step: 1
Training loss: 3.8650874437159635
Validation loss: 3.588320647337005

Epoch: 5| Step: 2
Training loss: 3.4289855933945
Validation loss: 3.5850044261013005

Epoch: 5| Step: 3
Training loss: 3.606931709897386
Validation loss: 3.581080342036094

Epoch: 5| Step: 4
Training loss: 3.760674859620315
Validation loss: 3.577559419489938

Epoch: 5| Step: 5
Training loss: 3.3997218018204003
Validation loss: 3.573469495498027

Epoch: 5| Step: 6
Training loss: 3.762612305039177
Validation loss: 3.5702144239270237

Epoch: 5| Step: 7
Training loss: 3.7115402214073487
Validation loss: 3.5663582560780265

Epoch: 5| Step: 8
Training loss: 4.117449236373331
Validation loss: 3.5627642862545095

Epoch: 5| Step: 9
Training loss: 3.510379387330259
Validation loss: 3.5596079604151196

Epoch: 5| Step: 10
Training loss: 3.3793580916277866
Validation loss: 3.55558907949187

Epoch: 5| Step: 11
Training loss: 3.9479483382565896
Validation loss: 3.551953588374025

Epoch: 40| Step: 0
Training loss: 3.5425419492532813
Validation loss: 3.5484648570914494

Epoch: 5| Step: 1
Training loss: 4.310681388080197
Validation loss: 3.545334132579509

Epoch: 5| Step: 2
Training loss: 3.41396305454423
Validation loss: 3.5413817973666863

Epoch: 5| Step: 3
Training loss: 3.5281936787491732
Validation loss: 3.5377963610318255

Epoch: 5| Step: 4
Training loss: 3.4826556013388146
Validation loss: 3.5344970594354232

Epoch: 5| Step: 5
Training loss: 4.119386263198051
Validation loss: 3.5310247850195537

Epoch: 5| Step: 6
Training loss: 3.002061771171554
Validation loss: 3.5275101845961703

Epoch: 5| Step: 7
Training loss: 3.9775046560858445
Validation loss: 3.52421031294957

Epoch: 5| Step: 8
Training loss: 3.9156749091959657
Validation loss: 3.5202140413939276

Epoch: 5| Step: 9
Training loss: 3.5372397337156634
Validation loss: 3.5167297887937483

Epoch: 5| Step: 10
Training loss: 3.1561667554094255
Validation loss: 3.5128209495753886

Epoch: 5| Step: 11
Training loss: 4.3483888295088855
Validation loss: 3.509484400279615

Epoch: 41| Step: 0
Training loss: 3.530752231319797
Validation loss: 3.505981431853498

Epoch: 5| Step: 1
Training loss: 3.572815399662557
Validation loss: 3.502429374483769

Epoch: 5| Step: 2
Training loss: 3.9742889200130844
Validation loss: 3.498406280110219

Epoch: 5| Step: 3
Training loss: 3.914186030283063
Validation loss: 3.4946154802522953

Epoch: 5| Step: 4
Training loss: 3.724671721874289
Validation loss: 3.4907219732435686

Epoch: 5| Step: 5
Training loss: 2.675523909842458
Validation loss: 3.4871001370988743

Epoch: 5| Step: 6
Training loss: 3.2457144431856757
Validation loss: 3.483410272630742

Epoch: 5| Step: 7
Training loss: 3.6903840764001323
Validation loss: 3.4800735460471692

Epoch: 5| Step: 8
Training loss: 4.2583218051184515
Validation loss: 3.4766350099238474

Epoch: 5| Step: 9
Training loss: 3.8507970703196275
Validation loss: 3.4726952921414456

Epoch: 5| Step: 10
Training loss: 3.1882755607586
Validation loss: 3.4688696568559623

Epoch: 5| Step: 11
Training loss: 3.602964182273073
Validation loss: 3.465144474435949

Epoch: 42| Step: 0
Training loss: 3.4050386007084343
Validation loss: 3.4617368752313467

Epoch: 5| Step: 1
Training loss: 2.4629834586427104
Validation loss: 3.4580119665423106

Epoch: 5| Step: 2
Training loss: 3.817920895739655
Validation loss: 3.4539666566971463

Epoch: 5| Step: 3
Training loss: 4.45246555732715
Validation loss: 3.4510522090168596

Epoch: 5| Step: 4
Training loss: 4.0477487217409465
Validation loss: 3.446819002002692

Epoch: 5| Step: 5
Training loss: 3.4062145826265775
Validation loss: 3.443703988858869

Epoch: 5| Step: 6
Training loss: 4.356109818292399
Validation loss: 3.439553075403542

Epoch: 5| Step: 7
Training loss: 3.3483649519672283
Validation loss: 3.4364819088293195

Epoch: 5| Step: 8
Training loss: 3.0293310324577316
Validation loss: 3.432579825330465

Epoch: 5| Step: 9
Training loss: 3.269480058823039
Validation loss: 3.4292868841489006

Epoch: 5| Step: 10
Training loss: 3.389250305234295
Validation loss: 3.4254684740430172

Epoch: 5| Step: 11
Training loss: 3.327898044638359
Validation loss: 3.4221190332172893

Epoch: 43| Step: 0
Training loss: 3.5782671904317884
Validation loss: 3.4185385790348763

Epoch: 5| Step: 1
Training loss: 3.7224090269922514
Validation loss: 3.415367115798847

Epoch: 5| Step: 2
Training loss: 3.6778072404657727
Validation loss: 3.41156417546597

Epoch: 5| Step: 3
Training loss: 3.6237064552914733
Validation loss: 3.40826090096049

Epoch: 5| Step: 4
Training loss: 3.208624459141301
Validation loss: 3.404781672526407

Epoch: 5| Step: 5
Training loss: 2.94691128430323
Validation loss: 3.4013055851852623

Epoch: 5| Step: 6
Training loss: 3.8902353604856796
Validation loss: 3.398033509778333

Epoch: 5| Step: 7
Training loss: 2.8918614397953264
Validation loss: 3.3944665678041797

Epoch: 5| Step: 8
Training loss: 3.496976500155407
Validation loss: 3.3912187340646454

Epoch: 5| Step: 9
Training loss: 3.6788373155306315
Validation loss: 3.3879828757589303

Epoch: 5| Step: 10
Training loss: 3.985377525912426
Validation loss: 3.3847959663453184

Epoch: 5| Step: 11
Training loss: 3.8331340793294966
Validation loss: 3.3814844309920193

Epoch: 44| Step: 0
Training loss: 3.1141336343912216
Validation loss: 3.3775386210806952

Epoch: 5| Step: 1
Training loss: 3.7102059054751866
Validation loss: 3.375314797920203

Epoch: 5| Step: 2
Training loss: 3.454302004627326
Validation loss: 3.374385648313649

Epoch: 5| Step: 3
Training loss: 3.9509402785638046
Validation loss: 3.371142988556292

Epoch: 5| Step: 4
Training loss: 3.2624766674157426
Validation loss: 3.3658964450835054

Epoch: 5| Step: 5
Training loss: 3.7496406382988003
Validation loss: 3.3606406910327618

Epoch: 5| Step: 6
Training loss: 3.0451390725433822
Validation loss: 3.357134836534197

Epoch: 5| Step: 7
Training loss: 3.5917615613917917
Validation loss: 3.3540552409048576

Epoch: 5| Step: 8
Training loss: 3.229044922205193
Validation loss: 3.351635912111206

Epoch: 5| Step: 9
Training loss: 3.483012253657868
Validation loss: 3.349220201370237

Epoch: 5| Step: 10
Training loss: 3.90044820606439
Validation loss: 3.3461696390813067

Epoch: 5| Step: 11
Training loss: 2.825426700740928
Validation loss: 3.3423046571261588

Epoch: 45| Step: 0
Training loss: 3.3508150561053305
Validation loss: 3.3384372716680613

Epoch: 5| Step: 1
Training loss: 3.5900732720423427
Validation loss: 3.334632147633853

Epoch: 5| Step: 2
Training loss: 4.116462194844854
Validation loss: 3.330745187958975

Epoch: 5| Step: 3
Training loss: 3.1228347906704537
Validation loss: 3.3272928710974172

Epoch: 5| Step: 4
Training loss: 4.039444512429171
Validation loss: 3.32408531509875

Epoch: 5| Step: 5
Training loss: 3.8420110971507984
Validation loss: 3.3213612175580938

Epoch: 5| Step: 6
Training loss: 2.9258213422444985
Validation loss: 3.3174769781502547

Epoch: 5| Step: 7
Training loss: 3.4476284279252853
Validation loss: 3.3143544913912737

Epoch: 5| Step: 8
Training loss: 3.0699235897930697
Validation loss: 3.3107655500810003

Epoch: 5| Step: 9
Training loss: 3.008983829859259
Validation loss: 3.308043805400464

Epoch: 5| Step: 10
Training loss: 3.319215983922228
Validation loss: 3.304651042235116

Epoch: 5| Step: 11
Training loss: 3.440237723719558
Validation loss: 3.3010135576410238

Epoch: 46| Step: 0
Training loss: 3.421735368779994
Validation loss: 3.2970715836286235

Epoch: 5| Step: 1
Training loss: 3.5412943625642166
Validation loss: 3.294339064945663

Epoch: 5| Step: 2
Training loss: 3.5641895771576104
Validation loss: 3.291308290955632

Epoch: 5| Step: 3
Training loss: 3.3645331946889843
Validation loss: 3.2883784473035846

Epoch: 5| Step: 4
Training loss: 3.6040242484882654
Validation loss: 3.2850568970282232

Epoch: 5| Step: 5
Training loss: 2.609289750402664
Validation loss: 3.282505231273518

Epoch: 5| Step: 6
Training loss: 3.4462052138071213
Validation loss: 3.279476576624775

Epoch: 5| Step: 7
Training loss: 3.4957725334715253
Validation loss: 3.276372836203332

Epoch: 5| Step: 8
Training loss: 3.3522308323480243
Validation loss: 3.2732146527920394

Epoch: 5| Step: 9
Training loss: 3.872661869613698
Validation loss: 3.269224151688059

Epoch: 5| Step: 10
Training loss: 3.107863168893138
Validation loss: 3.2658915312080925

Epoch: 5| Step: 11
Training loss: 3.9412309439380215
Validation loss: 3.262528480025469

Epoch: 47| Step: 0
Training loss: 3.5183935496425094
Validation loss: 3.2588170528305316

Epoch: 5| Step: 1
Training loss: 3.2953434139156434
Validation loss: 3.2554041638279285

Epoch: 5| Step: 2
Training loss: 3.1312839650883677
Validation loss: 3.252605231564635

Epoch: 5| Step: 3
Training loss: 3.1767597638231786
Validation loss: 3.2493962497386892

Epoch: 5| Step: 4
Training loss: 3.9690645348570928
Validation loss: 3.2460182814656187

Epoch: 5| Step: 5
Training loss: 3.4730365832395873
Validation loss: 3.2431345954283066

Epoch: 5| Step: 6
Training loss: 3.5634536805153942
Validation loss: 3.2396549582868532

Epoch: 5| Step: 7
Training loss: 3.569988077394895
Validation loss: 3.2367702497528157

Epoch: 5| Step: 8
Training loss: 3.887349047903887
Validation loss: 3.2331728520991896

Epoch: 5| Step: 9
Training loss: 2.6217509552957616
Validation loss: 3.229987739445237

Epoch: 5| Step: 10
Training loss: 2.792529091542614
Validation loss: 3.2260377347875195

Epoch: 5| Step: 11
Training loss: 3.1835624459254657
Validation loss: 3.2236561805658552

Epoch: 48| Step: 0
Training loss: 3.167217424248512
Validation loss: 3.2208739251411966

Epoch: 5| Step: 1
Training loss: 3.288762384708158
Validation loss: 3.217814232312454

Epoch: 5| Step: 2
Training loss: 3.5811731939418014
Validation loss: 3.214743191215119

Epoch: 5| Step: 3
Training loss: 3.429141198794108
Validation loss: 3.211924776264499

Epoch: 5| Step: 4
Training loss: 2.655957194626815
Validation loss: 3.2087036554873043

Epoch: 5| Step: 5
Training loss: 3.5283811275204497
Validation loss: 3.2061260957925355

Epoch: 5| Step: 6
Training loss: 3.1900463031529442
Validation loss: 3.203156702148361

Epoch: 5| Step: 7
Training loss: 3.2961390247838644
Validation loss: 3.2002686022740896

Epoch: 5| Step: 8
Training loss: 3.2631572543663343
Validation loss: 3.1976320262233413

Epoch: 5| Step: 9
Training loss: 4.097342741894515
Validation loss: 3.194413634626188

Epoch: 5| Step: 10
Training loss: 3.423348444899425
Validation loss: 3.1915881954453464

Epoch: 5| Step: 11
Training loss: 1.324933424662616
Validation loss: 3.1884797715954214

Epoch: 49| Step: 0
Training loss: 3.2216946363608168
Validation loss: 3.186098975155048

Epoch: 5| Step: 1
Training loss: 2.868980740843864
Validation loss: 3.1836179642643807

Epoch: 5| Step: 2
Training loss: 3.2443089174534037
Validation loss: 3.180862968674215

Epoch: 5| Step: 3
Training loss: 3.077408140718905
Validation loss: 3.177722236095862

Epoch: 5| Step: 4
Training loss: 3.1405105190383344
Validation loss: 3.17518415855621

Epoch: 5| Step: 5
Training loss: 3.1855742677297867
Validation loss: 3.1724735753807876

Epoch: 5| Step: 6
Training loss: 3.564826607145665
Validation loss: 3.170300739781035

Epoch: 5| Step: 7
Training loss: 3.9891423445651366
Validation loss: 3.167488917878597

Epoch: 5| Step: 8
Training loss: 3.814242605717869
Validation loss: 3.1643654635086835

Epoch: 5| Step: 9
Training loss: 3.0670664471423703
Validation loss: 3.161361772465088

Epoch: 5| Step: 10
Training loss: 2.9904949291487934
Validation loss: 3.1587101032629334

Epoch: 5| Step: 11
Training loss: 3.7361994799468454
Validation loss: 3.155062820456015

Epoch: 50| Step: 0
Training loss: 2.8075128207504196
Validation loss: 3.154555885853234

Epoch: 5| Step: 1
Training loss: 3.11634513161975
Validation loss: 3.1609055267793664

Epoch: 5| Step: 2
Training loss: 3.612475892088811
Validation loss: 3.162036444875615

Epoch: 5| Step: 3
Training loss: 3.195587519443238
Validation loss: 3.1469662291641445

Epoch: 5| Step: 4
Training loss: 3.682696430382506
Validation loss: 3.143549015023852

Epoch: 5| Step: 5
Training loss: 3.114266233770756
Validation loss: 3.1422199766711802

Epoch: 5| Step: 6
Training loss: 2.833631855067145
Validation loss: 3.142172945944606

Epoch: 5| Step: 7
Training loss: 3.3628953098650434
Validation loss: 3.141631713128029

Epoch: 5| Step: 8
Training loss: 3.1139451375647553
Validation loss: 3.1403765097728873

Epoch: 5| Step: 9
Training loss: 3.3178842798326094
Validation loss: 3.1340486492875756

Epoch: 5| Step: 10
Training loss: 3.9500051860533847
Validation loss: 3.1300094951794364

Epoch: 5| Step: 11
Training loss: 2.526737476487308
Validation loss: 3.1260554565783134

Epoch: 51| Step: 0
Training loss: 3.312542321276669
Validation loss: 3.1228986509709853

Epoch: 5| Step: 1
Training loss: 2.6789622757360534
Validation loss: 3.1203553778959727

Epoch: 5| Step: 2
Training loss: 2.9460755834472048
Validation loss: 3.118069580507254

Epoch: 5| Step: 3
Training loss: 3.405840087864015
Validation loss: 3.1156759270039003

Epoch: 5| Step: 4
Training loss: 3.7386218068328825
Validation loss: 3.113010696276343

Epoch: 5| Step: 5
Training loss: 2.8165373751820018
Validation loss: 3.1097151987112817

Epoch: 5| Step: 6
Training loss: 3.683012478577611
Validation loss: 3.1076693497247625

Epoch: 5| Step: 7
Training loss: 3.2105120077628966
Validation loss: 3.104701166838009

Epoch: 5| Step: 8
Training loss: 3.3596432600922093
Validation loss: 3.101813862669713

Epoch: 5| Step: 9
Training loss: 2.9551371828822637
Validation loss: 3.0993554552727027

Epoch: 5| Step: 10
Training loss: 3.464889715291923
Validation loss: 3.096338704645144

Epoch: 5| Step: 11
Training loss: 3.2156042634019184
Validation loss: 3.0920575582847634

Epoch: 52| Step: 0
Training loss: 3.6039702668821105
Validation loss: 3.089902887690711

Epoch: 5| Step: 1
Training loss: 2.8541849697296535
Validation loss: 3.086620618965567

Epoch: 5| Step: 2
Training loss: 3.072123296876038
Validation loss: 3.0844867756902707

Epoch: 5| Step: 3
Training loss: 3.1125758579309375
Validation loss: 3.0820059313940855

Epoch: 5| Step: 4
Training loss: 3.9777265542448035
Validation loss: 3.079490339450762

Epoch: 5| Step: 5
Training loss: 3.25050995567216
Validation loss: 3.0765486810392257

Epoch: 5| Step: 6
Training loss: 3.058668893253987
Validation loss: 3.0734692136042727

Epoch: 5| Step: 7
Training loss: 3.0921009947949174
Validation loss: 3.0704186237556916

Epoch: 5| Step: 8
Training loss: 3.382883965351852
Validation loss: 3.0675075650970354

Epoch: 5| Step: 9
Training loss: 2.9077699029867925
Validation loss: 3.064461806321272

Epoch: 5| Step: 10
Training loss: 2.8630570848258823
Validation loss: 3.061330302675242

Epoch: 5| Step: 11
Training loss: 3.415818520078222
Validation loss: 3.058585389809126

Epoch: 53| Step: 0
Training loss: 2.88705322640444
Validation loss: 3.056492928053545

Epoch: 5| Step: 1
Training loss: 2.776142187726012
Validation loss: 3.053748257137243

Epoch: 5| Step: 2
Training loss: 3.1206682318564196
Validation loss: 3.0525799803965388

Epoch: 5| Step: 3
Training loss: 2.565616573268791
Validation loss: 3.0504571512140477

Epoch: 5| Step: 4
Training loss: 3.4290709756050988
Validation loss: 3.0490404112550307

Epoch: 5| Step: 5
Training loss: 2.990767896660377
Validation loss: 3.0453087294039634

Epoch: 5| Step: 6
Training loss: 3.5852027422878203
Validation loss: 3.0413501304807595

Epoch: 5| Step: 7
Training loss: 3.3024632248430006
Validation loss: 3.0387809021494054

Epoch: 5| Step: 8
Training loss: 3.6217955533679023
Validation loss: 3.0358947778386525

Epoch: 5| Step: 9
Training loss: 3.445467921620164
Validation loss: 3.034162603370511

Epoch: 5| Step: 10
Training loss: 3.179936729617449
Validation loss: 3.032078832855666

Epoch: 5| Step: 11
Training loss: 2.8315072252254465
Validation loss: 3.0297846545911398

Epoch: 54| Step: 0
Training loss: 2.688772654276121
Validation loss: 3.027318846897531

Epoch: 5| Step: 1
Training loss: 3.316646643598937
Validation loss: 3.024501133733827

Epoch: 5| Step: 2
Training loss: 2.7297356184772634
Validation loss: 3.0215175226551336

Epoch: 5| Step: 3
Training loss: 3.6567958848134356
Validation loss: 3.0192344325535725

Epoch: 5| Step: 4
Training loss: 3.5823713534270816
Validation loss: 3.0151470049272078

Epoch: 5| Step: 5
Training loss: 3.393107406449743
Validation loss: 3.0127949455516636

Epoch: 5| Step: 6
Training loss: 2.6815222862010346
Validation loss: 3.0104692425916113

Epoch: 5| Step: 7
Training loss: 3.5530402422536294
Validation loss: 3.0077753106002105

Epoch: 5| Step: 8
Training loss: 2.924285057920241
Validation loss: 3.0044762542255175

Epoch: 5| Step: 9
Training loss: 2.843772301219646
Validation loss: 3.002253824899544

Epoch: 5| Step: 10
Training loss: 3.0497826420612926
Validation loss: 3.000671023584192

Epoch: 5| Step: 11
Training loss: 3.511917804512146
Validation loss: 2.997821132515329

Epoch: 55| Step: 0
Training loss: 2.6894416005449346
Validation loss: 2.9977986517752386

Epoch: 5| Step: 1
Training loss: 2.930489148135319
Validation loss: 3.002615043882909

Epoch: 5| Step: 2
Training loss: 3.336486914102694
Validation loss: 2.9931844207585763

Epoch: 5| Step: 3
Training loss: 3.372741084548424
Validation loss: 2.9895068213123475

Epoch: 5| Step: 4
Training loss: 3.2130001524834073
Validation loss: 2.986758280765307

Epoch: 5| Step: 5
Training loss: 3.3224266591814557
Validation loss: 2.98467539728423

Epoch: 5| Step: 6
Training loss: 3.498984734557791
Validation loss: 2.983585442958234

Epoch: 5| Step: 7
Training loss: 2.8682925721869945
Validation loss: 2.9812280596786125

Epoch: 5| Step: 8
Training loss: 3.224024330823542
Validation loss: 2.9800536940364877

Epoch: 5| Step: 9
Training loss: 3.080097786230447
Validation loss: 2.9784412945920757

Epoch: 5| Step: 10
Training loss: 2.892118820619756
Validation loss: 2.977103270154062

Epoch: 5| Step: 11
Training loss: 2.509152728696297
Validation loss: 2.975125657694916

Epoch: 56| Step: 0
Training loss: 3.392367710578683
Validation loss: 2.9730392556867016

Epoch: 5| Step: 1
Training loss: 2.683847029503936
Validation loss: 2.970451305851131

Epoch: 5| Step: 2
Training loss: 3.0585009876278937
Validation loss: 2.9677480345284537

Epoch: 5| Step: 3
Training loss: 3.3088795291923967
Validation loss: 2.9660793036863806

Epoch: 5| Step: 4
Training loss: 2.877758195762175
Validation loss: 2.962610126278028

Epoch: 5| Step: 5
Training loss: 3.3349193296727293
Validation loss: 2.9594703367587445

Epoch: 5| Step: 6
Training loss: 2.956736460495959
Validation loss: 2.958361854997787

Epoch: 5| Step: 7
Training loss: 3.350081109730399
Validation loss: 2.955697814282182

Epoch: 5| Step: 8
Training loss: 3.152907159272641
Validation loss: 2.9512205896200663

Epoch: 5| Step: 9
Training loss: 2.7501607327738697
Validation loss: 2.9518469276792216

Epoch: 5| Step: 10
Training loss: 3.1624441270076713
Validation loss: 2.948794437562509

Epoch: 5| Step: 11
Training loss: 3.052936491129822
Validation loss: 2.9455188506919794

Epoch: 57| Step: 0
Training loss: 2.4605847302649897
Validation loss: 2.943927105154069

Epoch: 5| Step: 1
Training loss: 2.949488100800323
Validation loss: 2.9411834726998247

Epoch: 5| Step: 2
Training loss: 2.917706785481941
Validation loss: 2.9391274374224095

Epoch: 5| Step: 3
Training loss: 2.335463970248598
Validation loss: 2.936388752466917

Epoch: 5| Step: 4
Training loss: 2.8868948298167796
Validation loss: 2.9346164693391965

Epoch: 5| Step: 5
Training loss: 3.672585276632218
Validation loss: 2.931115883075071

Epoch: 5| Step: 6
Training loss: 2.814252942899311
Validation loss: 2.9314972912140798

Epoch: 5| Step: 7
Training loss: 3.39527173849497
Validation loss: 2.930380563774371

Epoch: 5| Step: 8
Training loss: 3.1956152737531216
Validation loss: 2.926652232877104

Epoch: 5| Step: 9
Training loss: 3.71943824874543
Validation loss: 2.9248488145321767

Epoch: 5| Step: 10
Training loss: 3.053238547018559
Validation loss: 2.9217980658590483

Epoch: 5| Step: 11
Training loss: 3.4100010367920492
Validation loss: 2.9187572661587806

Epoch: 58| Step: 0
Training loss: 3.11812996061645
Validation loss: 2.9164125343144

Epoch: 5| Step: 1
Training loss: 3.027947740907607
Validation loss: 2.914997431523286

Epoch: 5| Step: 2
Training loss: 3.345352359340058
Validation loss: 2.911947002357203

Epoch: 5| Step: 3
Training loss: 2.6187537218308687
Validation loss: 2.9105847548867794

Epoch: 5| Step: 4
Training loss: 2.9114415549862214
Validation loss: 2.907709729296641

Epoch: 5| Step: 5
Training loss: 3.51403243551119
Validation loss: 2.906550166308249

Epoch: 5| Step: 6
Training loss: 2.9432106512069316
Validation loss: 2.904851546228598

Epoch: 5| Step: 7
Training loss: 3.3626694250143396
Validation loss: 2.9040723763916447

Epoch: 5| Step: 8
Training loss: 2.3099248827656225
Validation loss: 2.901355409122143

Epoch: 5| Step: 9
Training loss: 3.1075516918790256
Validation loss: 2.89968788547392

Epoch: 5| Step: 10
Training loss: 2.9917452413145447
Validation loss: 2.897064521293584

Epoch: 5| Step: 11
Training loss: 3.4754953868332104
Validation loss: 2.8937332625210583

Epoch: 59| Step: 0
Training loss: 3.0286133300576568
Validation loss: 2.893001188034014

Epoch: 5| Step: 1
Training loss: 3.1569960817126033
Validation loss: 2.8895115056607272

Epoch: 5| Step: 2
Training loss: 3.0674283602058448
Validation loss: 2.88799826037314

Epoch: 5| Step: 3
Training loss: 2.2346402524344477
Validation loss: 2.8860808111963703

Epoch: 5| Step: 4
Training loss: 3.2342548440184995
Validation loss: 2.8852330481063166

Epoch: 5| Step: 5
Training loss: 3.034746807667076
Validation loss: 2.882449591588226

Epoch: 5| Step: 6
Training loss: 3.120339695215506
Validation loss: 2.881762246930869

Epoch: 5| Step: 7
Training loss: 3.3334834700787233
Validation loss: 2.876600794249778

Epoch: 5| Step: 8
Training loss: 3.493689433819977
Validation loss: 2.876050062810922

Epoch: 5| Step: 9
Training loss: 3.230042878093684
Validation loss: 2.875040219896363

Epoch: 5| Step: 10
Training loss: 2.0882032568938422
Validation loss: 2.872656904007311

Epoch: 5| Step: 11
Training loss: 2.483461415958223
Validation loss: 2.8711754715895332

Epoch: 60| Step: 0
Training loss: 3.2862076862755383
Validation loss: 2.8682754801487307

Epoch: 5| Step: 1
Training loss: 3.2234439141583664
Validation loss: 2.8659310632606436

Epoch: 5| Step: 2
Training loss: 3.3499604066245543
Validation loss: 2.864108137539574

Epoch: 5| Step: 3
Training loss: 2.6768471481295797
Validation loss: 2.861406271847073

Epoch: 5| Step: 4
Training loss: 2.7872929449116746
Validation loss: 2.8595215007724946

Epoch: 5| Step: 5
Training loss: 2.703237189461967
Validation loss: 2.856968049040623

Epoch: 5| Step: 6
Training loss: 2.5268219257284517
Validation loss: 2.8553220412891056

Epoch: 5| Step: 7
Training loss: 3.275619034829956
Validation loss: 2.853463181351655

Epoch: 5| Step: 8
Training loss: 2.8794769590992386
Validation loss: 2.8506997218504573

Epoch: 5| Step: 9
Training loss: 2.826365561132574
Validation loss: 2.850555060806319

Epoch: 5| Step: 10
Training loss: 3.309807024628959
Validation loss: 2.8501128566158624

Epoch: 5| Step: 11
Training loss: 3.0663090587204853
Validation loss: 2.849259464637911

Epoch: 61| Step: 0
Training loss: 2.8702396290125503
Validation loss: 2.847219244379073

Epoch: 5| Step: 1
Training loss: 2.6395991211749963
Validation loss: 2.8427264219393265

Epoch: 5| Step: 2
Training loss: 2.981122386448332
Validation loss: 2.8398993100586716

Epoch: 5| Step: 3
Training loss: 3.679231327881206
Validation loss: 2.838860906211921

Epoch: 5| Step: 4
Training loss: 2.9309604981700956
Validation loss: 2.8366855689086523

Epoch: 5| Step: 5
Training loss: 2.868704163428238
Validation loss: 2.8343855479477704

Epoch: 5| Step: 6
Training loss: 2.8011585018768073
Validation loss: 2.833985822709229

Epoch: 5| Step: 7
Training loss: 3.0929854247782393
Validation loss: 2.8317351929708647

Epoch: 5| Step: 8
Training loss: 2.989780822681787
Validation loss: 2.830597279882417

Epoch: 5| Step: 9
Training loss: 3.0540289986163605
Validation loss: 2.8293019264278274

Epoch: 5| Step: 10
Training loss: 2.8244578153485658
Validation loss: 2.8270266316143053

Epoch: 5| Step: 11
Training loss: 2.5375558931555915
Validation loss: 2.8273211297420446

Epoch: 62| Step: 0
Training loss: 2.715112993899354
Validation loss: 2.8238074080941686

Epoch: 5| Step: 1
Training loss: 2.5036604785960375
Validation loss: 2.8274880810808787

Epoch: 5| Step: 2
Training loss: 3.5272395223128967
Validation loss: 2.8268063071928657

Epoch: 5| Step: 3
Training loss: 2.9673400743256946
Validation loss: 2.8209423654540444

Epoch: 5| Step: 4
Training loss: 3.159146933997521
Validation loss: 2.819312361242177

Epoch: 5| Step: 5
Training loss: 3.0857403269683137
Validation loss: 2.817222205420971

Epoch: 5| Step: 6
Training loss: 3.263219357981946
Validation loss: 2.8155415724779527

Epoch: 5| Step: 7
Training loss: 3.1622244311506904
Validation loss: 2.813779172696681

Epoch: 5| Step: 8
Training loss: 2.512007487595691
Validation loss: 2.8117203868180374

Epoch: 5| Step: 9
Training loss: 2.4275831327336674
Validation loss: 2.8104920778462055

Epoch: 5| Step: 10
Training loss: 2.8151648718081588
Validation loss: 2.8091857915748015

Epoch: 5| Step: 11
Training loss: 3.830850681821354
Validation loss: 2.8064955158633906

Epoch: 63| Step: 0
Training loss: 3.018041245559759
Validation loss: 2.8062171802428213

Epoch: 5| Step: 1
Training loss: 2.880505473495392
Validation loss: 2.805254348526685

Epoch: 5| Step: 2
Training loss: 2.9085467707477135
Validation loss: 2.8029982882310858

Epoch: 5| Step: 3
Training loss: 2.885706826136982
Validation loss: 2.801422226687019

Epoch: 5| Step: 4
Training loss: 3.0505893075422357
Validation loss: 2.798531349066746

Epoch: 5| Step: 5
Training loss: 2.6021927536945397
Validation loss: 2.796500079636664

Epoch: 5| Step: 6
Training loss: 2.415292074892259
Validation loss: 2.7949444805220085

Epoch: 5| Step: 7
Training loss: 2.9820752295273416
Validation loss: 2.7927385782218783

Epoch: 5| Step: 8
Training loss: 3.3324017335522047
Validation loss: 2.7920923560863495

Epoch: 5| Step: 9
Training loss: 3.0945077603899733
Validation loss: 2.789197122439677

Epoch: 5| Step: 10
Training loss: 2.8620456251643613
Validation loss: 2.7874295238600664

Epoch: 5| Step: 11
Training loss: 3.758876974931595
Validation loss: 2.784319658796222

Epoch: 64| Step: 0
Training loss: 3.007969443450098
Validation loss: 2.783597170056542

Epoch: 5| Step: 1
Training loss: 2.6491966397378914
Validation loss: 2.785940882805015

Epoch: 5| Step: 2
Training loss: 2.3980269189362473
Validation loss: 2.777645911954468

Epoch: 5| Step: 3
Training loss: 3.104512615682632
Validation loss: 2.7812147906214246

Epoch: 5| Step: 4
Training loss: 3.4057231810655666
Validation loss: 2.7768280831087706

Epoch: 5| Step: 5
Training loss: 2.9060591768355337
Validation loss: 2.7764772761655148

Epoch: 5| Step: 6
Training loss: 2.8510623022876715
Validation loss: 2.7765222327912324

Epoch: 5| Step: 7
Training loss: 2.535830462459661
Validation loss: 2.772295388043205

Epoch: 5| Step: 8
Training loss: 3.1536259082235096
Validation loss: 2.7712294622843765

Epoch: 5| Step: 9
Training loss: 2.8602815452125165
Validation loss: 2.768400383741487

Epoch: 5| Step: 10
Training loss: 2.8161437273355694
Validation loss: 2.7678595350258095

Epoch: 5| Step: 11
Training loss: 3.873062880151625
Validation loss: 2.767383530011554

Epoch: 65| Step: 0
Training loss: 2.8937595177776116
Validation loss: 2.7654957103501716

Epoch: 5| Step: 1
Training loss: 2.7419723035052153
Validation loss: 2.765416958270379

Epoch: 5| Step: 2
Training loss: 2.5054224336516433
Validation loss: 2.7671449295752852

Epoch: 5| Step: 3
Training loss: 3.1796722036832628
Validation loss: 2.770061623275743

Epoch: 5| Step: 4
Training loss: 3.122331471717073
Validation loss: 2.7712352372772684

Epoch: 5| Step: 5
Training loss: 3.146883370351408
Validation loss: 2.7729667550618586

Epoch: 5| Step: 6
Training loss: 2.9924870831586046
Validation loss: 2.7682086564623325

Epoch: 5| Step: 7
Training loss: 2.679077256897474
Validation loss: 2.763927513493782

Epoch: 5| Step: 8
Training loss: 3.0650540036893683
Validation loss: 2.7599182518656047

Epoch: 5| Step: 9
Training loss: 2.4066313404262654
Validation loss: 2.757079108883882

Epoch: 5| Step: 10
Training loss: 3.1575489959177347
Validation loss: 2.753868027009231

Epoch: 5| Step: 11
Training loss: 2.7081960398769644
Validation loss: 2.7523863473758174

Epoch: 66| Step: 0
Training loss: 2.710540654490989
Validation loss: 2.7512222268821396

Epoch: 5| Step: 1
Training loss: 3.0025874741490868
Validation loss: 2.7510181947915555

Epoch: 5| Step: 2
Training loss: 2.570119554878175
Validation loss: 2.7485956919623504

Epoch: 5| Step: 3
Training loss: 2.848306882440447
Validation loss: 2.748024935658497

Epoch: 5| Step: 4
Training loss: 2.844490709359038
Validation loss: 2.746881985935764

Epoch: 5| Step: 5
Training loss: 2.6958873191117267
Validation loss: 2.743655779849366

Epoch: 5| Step: 6
Training loss: 2.981380698100193
Validation loss: 2.742575988348526

Epoch: 5| Step: 7
Training loss: 2.6294236828844775
Validation loss: 2.7370479525492213

Epoch: 5| Step: 8
Training loss: 2.9694119970176294
Validation loss: 2.73930079425856

Epoch: 5| Step: 9
Training loss: 2.984750933711472
Validation loss: 2.736652617327474

Epoch: 5| Step: 10
Training loss: 3.384753509517411
Validation loss: 2.735041063112038

Epoch: 5| Step: 11
Training loss: 2.9821924347423443
Validation loss: 2.7344014084766872

Epoch: 67| Step: 0
Training loss: 2.8189985855006974
Validation loss: 2.7331237654963423

Epoch: 5| Step: 1
Training loss: 2.9151615800781725
Validation loss: 2.730251094381854

Epoch: 5| Step: 2
Training loss: 2.747200407818657
Validation loss: 2.730841524348364

Epoch: 5| Step: 3
Training loss: 2.910429871259993
Validation loss: 2.7314719020516285

Epoch: 5| Step: 4
Training loss: 2.660725312836455
Validation loss: 2.7261661033716855

Epoch: 5| Step: 5
Training loss: 3.318762275974824
Validation loss: 2.7263176707002748

Epoch: 5| Step: 6
Training loss: 2.949202905069191
Validation loss: 2.7257585952617673

Epoch: 5| Step: 7
Training loss: 2.743883961250923
Validation loss: 2.7230335012547195

Epoch: 5| Step: 8
Training loss: 2.746663670661675
Validation loss: 2.725350001953079

Epoch: 5| Step: 9
Training loss: 3.154525134446156
Validation loss: 2.7202775398241394

Epoch: 5| Step: 10
Training loss: 2.7658033582858566
Validation loss: 2.720616814165561

Epoch: 5| Step: 11
Training loss: 1.3499150902925157
Validation loss: 2.717415942723074

Epoch: 68| Step: 0
Training loss: 2.9316851913043265
Validation loss: 2.714432803733151

Epoch: 5| Step: 1
Training loss: 2.724852104723254
Validation loss: 2.7156520052007176

Epoch: 5| Step: 2
Training loss: 3.002088932100079
Validation loss: 2.7146908467730566

Epoch: 5| Step: 3
Training loss: 2.890116218949197
Validation loss: 2.711619079833087

Epoch: 5| Step: 4
Training loss: 3.0893066556742097
Validation loss: 2.713293039765113

Epoch: 5| Step: 5
Training loss: 2.9629670688371115
Validation loss: 2.713793570211043

Epoch: 5| Step: 6
Training loss: 2.6725726192874517
Validation loss: 2.708823659722989

Epoch: 5| Step: 7
Training loss: 2.7955241430772135
Validation loss: 2.708798721871663

Epoch: 5| Step: 8
Training loss: 2.6366928890514187
Validation loss: 2.706997697336941

Epoch: 5| Step: 9
Training loss: 2.419424971210039
Validation loss: 2.7089184911408455

Epoch: 5| Step: 10
Training loss: 3.164884936032461
Validation loss: 2.706011643899694

Epoch: 5| Step: 11
Training loss: 2.9055460415699175
Validation loss: 2.7035964562033383

Epoch: 69| Step: 0
Training loss: 2.944694312507872
Validation loss: 2.702534896003033

Epoch: 5| Step: 1
Training loss: 2.7615478980755483
Validation loss: 2.703112409264673

Epoch: 5| Step: 2
Training loss: 3.278665742013291
Validation loss: 2.7023929824895427

Epoch: 5| Step: 3
Training loss: 2.83080135605518
Validation loss: 2.7017424066643425

Epoch: 5| Step: 4
Training loss: 3.05712995908433
Validation loss: 2.6979419468955803

Epoch: 5| Step: 5
Training loss: 3.1204446778933557
Validation loss: 2.6960399327912348

Epoch: 5| Step: 6
Training loss: 2.927745938675879
Validation loss: 2.697011170940628

Epoch: 5| Step: 7
Training loss: 2.1853056664607537
Validation loss: 2.6955464984841315

Epoch: 5| Step: 8
Training loss: 2.678986037727359
Validation loss: 2.693617939496233

Epoch: 5| Step: 9
Training loss: 2.813447072259537
Validation loss: 2.692972477710292

Epoch: 5| Step: 10
Training loss: 2.4534064453398576
Validation loss: 2.691161670100502

Epoch: 5| Step: 11
Training loss: 2.9571768600109594
Validation loss: 2.6906242692557245

Epoch: 70| Step: 0
Training loss: 3.2713540669010857
Validation loss: 2.6900122233825687

Epoch: 5| Step: 1
Training loss: 2.388228468082415
Validation loss: 2.690364231760334

Epoch: 5| Step: 2
Training loss: 2.240493081012131
Validation loss: 2.688804986073156

Epoch: 5| Step: 3
Training loss: 2.800570640998396
Validation loss: 2.6841461856830073

Epoch: 5| Step: 4
Training loss: 2.909454056170721
Validation loss: 2.6817564544519454

Epoch: 5| Step: 5
Training loss: 2.6272515223182262
Validation loss: 2.6830865416757357

Epoch: 5| Step: 6
Training loss: 2.986322855773229
Validation loss: 2.6781972999264965

Epoch: 5| Step: 7
Training loss: 2.8547160230191935
Validation loss: 2.6766592548294663

Epoch: 5| Step: 8
Training loss: 3.0316608583109117
Validation loss: 2.6761673957290917

Epoch: 5| Step: 9
Training loss: 2.7697741747635334
Validation loss: 2.674634282047359

Epoch: 5| Step: 10
Training loss: 2.8582589728318752
Validation loss: 2.6773825687250588

Epoch: 5| Step: 11
Training loss: 3.4816566435245218
Validation loss: 2.6738012111396947

Epoch: 71| Step: 0
Training loss: 2.726686316359523
Validation loss: 2.6742751920648185

Epoch: 5| Step: 1
Training loss: 2.949602074374739
Validation loss: 2.6717559683834127

Epoch: 5| Step: 2
Training loss: 3.1532326051405692
Validation loss: 2.671705203396141

Epoch: 5| Step: 3
Training loss: 2.784837359434076
Validation loss: 2.6681281545296764

Epoch: 5| Step: 4
Training loss: 2.834603324197973
Validation loss: 2.6655975759272432

Epoch: 5| Step: 5
Training loss: 2.5840701826384804
Validation loss: 2.666835378485581

Epoch: 5| Step: 6
Training loss: 3.1469286765376245
Validation loss: 2.6640118904564383

Epoch: 5| Step: 7
Training loss: 2.395222848706274
Validation loss: 2.663081244779415

Epoch: 5| Step: 8
Training loss: 2.6121414047976894
Validation loss: 2.664471972367677

Epoch: 5| Step: 9
Training loss: 2.4941492282178364
Validation loss: 2.661131020641599

Epoch: 5| Step: 10
Training loss: 3.001817629454756
Validation loss: 2.6617831587474665

Epoch: 5| Step: 11
Training loss: 3.2055062723439076
Validation loss: 2.6594389939518495

Epoch: 72| Step: 0
Training loss: 3.158257478660293
Validation loss: 2.656851429263019

Epoch: 5| Step: 1
Training loss: 2.9101329828138667
Validation loss: 2.656148100749683

Epoch: 5| Step: 2
Training loss: 2.861793204257272
Validation loss: 2.655462593355044

Epoch: 5| Step: 3
Training loss: 2.732437057398403
Validation loss: 2.6543912742133218

Epoch: 5| Step: 4
Training loss: 2.751649535241529
Validation loss: 2.6558052887486694

Epoch: 5| Step: 5
Training loss: 2.798047549854641
Validation loss: 2.651353590375998

Epoch: 5| Step: 6
Training loss: 2.577195340937101
Validation loss: 2.651532082204311

Epoch: 5| Step: 7
Training loss: 2.9982467932631875
Validation loss: 2.646922568141877

Epoch: 5| Step: 8
Training loss: 2.53473235408436
Validation loss: 2.648261286631988

Epoch: 5| Step: 9
Training loss: 2.654848514409146
Validation loss: 2.6500553714617365

Epoch: 5| Step: 10
Training loss: 2.6026432209750254
Validation loss: 2.6498326403174297

Epoch: 5| Step: 11
Training loss: 3.09372395205851
Validation loss: 2.648204616934054

Epoch: 73| Step: 0
Training loss: 2.6281702788418033
Validation loss: 2.648628678074936

Epoch: 5| Step: 1
Training loss: 2.815217210239099
Validation loss: 2.6443386561830127

Epoch: 5| Step: 2
Training loss: 2.5957470295266423
Validation loss: 2.644899392435024

Epoch: 5| Step: 3
Training loss: 2.801665907236965
Validation loss: 2.642564546560066

Epoch: 5| Step: 4
Training loss: 3.01794107470363
Validation loss: 2.641375884489221

Epoch: 5| Step: 5
Training loss: 2.917844389240416
Validation loss: 2.642890954890648

Epoch: 5| Step: 6
Training loss: 3.188154415196083
Validation loss: 2.6411727021258056

Epoch: 5| Step: 7
Training loss: 2.4709563234885175
Validation loss: 2.6384085244492836

Epoch: 5| Step: 8
Training loss: 2.446422970698751
Validation loss: 2.6395290892059675

Epoch: 5| Step: 9
Training loss: 3.0775296172786137
Validation loss: 2.639867324023898

Epoch: 5| Step: 10
Training loss: 2.362942858973308
Validation loss: 2.6346495659115714

Epoch: 5| Step: 11
Training loss: 3.2316065932761764
Validation loss: 2.6357118581972845

Epoch: 74| Step: 0
Training loss: 2.9325841799570185
Validation loss: 2.635151138549516

Epoch: 5| Step: 1
Training loss: 2.9630415795634186
Validation loss: 2.6356125760043794

Epoch: 5| Step: 2
Training loss: 2.4915443475440706
Validation loss: 2.6325831289772403

Epoch: 5| Step: 3
Training loss: 2.3266836735596614
Validation loss: 2.6343228076668384

Epoch: 5| Step: 4
Training loss: 3.126182332486726
Validation loss: 2.630426127163327

Epoch: 5| Step: 5
Training loss: 2.619804963722131
Validation loss: 2.6303412803564012

Epoch: 5| Step: 6
Training loss: 2.69584575298422
Validation loss: 2.6302344078559265

Epoch: 5| Step: 7
Training loss: 2.536381265355879
Validation loss: 2.6294440956367584

Epoch: 5| Step: 8
Training loss: 2.6717584595723443
Validation loss: 2.6252563593584317

Epoch: 5| Step: 9
Training loss: 2.6032740372837817
Validation loss: 2.627024214490541

Epoch: 5| Step: 10
Training loss: 3.3810032329662336
Validation loss: 2.624932954325574

Epoch: 5| Step: 11
Training loss: 2.27216190588666
Validation loss: 2.623718137955025

Epoch: 75| Step: 0
Training loss: 2.798727775100439
Validation loss: 2.6235912455920793

Epoch: 5| Step: 1
Training loss: 2.589301465367107
Validation loss: 2.6238666312950336

Epoch: 5| Step: 2
Training loss: 3.0903386275530997
Validation loss: 2.6251526780610597

Epoch: 5| Step: 3
Training loss: 2.9721711373222184
Validation loss: 2.6259016861176296

Epoch: 5| Step: 4
Training loss: 2.527470722576031
Validation loss: 2.624769722965172

Epoch: 5| Step: 5
Training loss: 2.751588709293208
Validation loss: 2.624745409593469

Epoch: 5| Step: 6
Training loss: 2.6519595332791
Validation loss: 2.6249312248000263

Epoch: 5| Step: 7
Training loss: 2.870379674433825
Validation loss: 2.620680267117549

Epoch: 5| Step: 8
Training loss: 2.7382466835093138
Validation loss: 2.6210061260951316

Epoch: 5| Step: 9
Training loss: 2.9632968008094465
Validation loss: 2.621335423523363

Epoch: 5| Step: 10
Training loss: 2.3322965384792087
Validation loss: 2.616235284619625

Epoch: 5| Step: 11
Training loss: 2.7868573529954532
Validation loss: 2.6168394474116607

Epoch: 76| Step: 0
Training loss: 2.4639262140546467
Validation loss: 2.6171387663142407

Epoch: 5| Step: 1
Training loss: 2.426125125806193
Validation loss: 2.6171174984200847

Epoch: 5| Step: 2
Training loss: 2.6418844075122307
Validation loss: 2.6134262082770805

Epoch: 5| Step: 3
Training loss: 2.5513572334656645
Validation loss: 2.61687773584199

Epoch: 5| Step: 4
Training loss: 3.0335234935247497
Validation loss: 2.6103131402857223

Epoch: 5| Step: 5
Training loss: 2.7832462990072404
Validation loss: 2.6128174503752346

Epoch: 5| Step: 6
Training loss: 3.068003944096026
Validation loss: 2.6093182966882185

Epoch: 5| Step: 7
Training loss: 2.8474692033369977
Validation loss: 2.6094978631003474

Epoch: 5| Step: 8
Training loss: 2.9910253753044844
Validation loss: 2.605698529147927

Epoch: 5| Step: 9
Training loss: 2.839069245098963
Validation loss: 2.607398439985441

Epoch: 5| Step: 10
Training loss: 2.659576666567279
Validation loss: 2.6079065032040134

Epoch: 5| Step: 11
Training loss: 1.6767355595813331
Validation loss: 2.6045648092456273

Epoch: 77| Step: 0
Training loss: 2.8613937839096315
Validation loss: 2.6067124981725094

Epoch: 5| Step: 1
Training loss: 2.4832976302411534
Validation loss: 2.604835898556639

Epoch: 5| Step: 2
Training loss: 2.661705697366046
Validation loss: 2.604770973025937

Epoch: 5| Step: 3
Training loss: 2.336059771243402
Validation loss: 2.6045367524709113

Epoch: 5| Step: 4
Training loss: 2.6484494729460653
Validation loss: 2.602622743064039

Epoch: 5| Step: 5
Training loss: 2.686909721666598
Validation loss: 2.6004597041985775

Epoch: 5| Step: 6
Training loss: 2.679143466720473
Validation loss: 2.6022672376452376

Epoch: 5| Step: 7
Training loss: 2.8638465812444913
Validation loss: 2.6040221530235192

Epoch: 5| Step: 8
Training loss: 3.083924846787341
Validation loss: 2.6026188879313676

Epoch: 5| Step: 9
Training loss: 2.764479922727612
Validation loss: 2.598665401842626

Epoch: 5| Step: 10
Training loss: 2.895944186131185
Validation loss: 2.600657862338216

Epoch: 5| Step: 11
Training loss: 3.2374228155295426
Validation loss: 2.6013165721412794

Epoch: 78| Step: 0
Training loss: 2.3240439469454928
Validation loss: 2.60876175913577

Epoch: 5| Step: 1
Training loss: 3.1019791099882847
Validation loss: 2.617715681687857

Epoch: 5| Step: 2
Training loss: 2.543177723538447
Validation loss: 2.6179605205926024

Epoch: 5| Step: 3
Training loss: 2.0973500289317144
Validation loss: 2.625930904900848

Epoch: 5| Step: 4
Training loss: 2.898109767101303
Validation loss: 2.6317103273970788

Epoch: 5| Step: 5
Training loss: 2.732631454446889
Validation loss: 2.625051531967065

Epoch: 5| Step: 6
Training loss: 2.8890767668087602
Validation loss: 2.613836867070069

Epoch: 5| Step: 7
Training loss: 3.034879733221267
Validation loss: 2.6048289194448184

Epoch: 5| Step: 8
Training loss: 2.7400696664849895
Validation loss: 2.601870792515939

Epoch: 5| Step: 9
Training loss: 3.031698449380491
Validation loss: 2.597886930467335

Epoch: 5| Step: 10
Training loss: 2.8013796200396923
Validation loss: 2.5965288741785155

Epoch: 5| Step: 11
Training loss: 1.7500032697374588
Validation loss: 2.5943641931205654

Epoch: 79| Step: 0
Training loss: 2.8401884475833015
Validation loss: 2.5932156805262525

Epoch: 5| Step: 1
Training loss: 2.4998333875449816
Validation loss: 2.59231564490747

Epoch: 5| Step: 2
Training loss: 2.584909655469784
Validation loss: 2.5939851102783993

Epoch: 5| Step: 3
Training loss: 2.7749869303352575
Validation loss: 2.5903047023893144

Epoch: 5| Step: 4
Training loss: 2.9755086960765627
Validation loss: 2.590668276128925

Epoch: 5| Step: 5
Training loss: 2.568088578137427
Validation loss: 2.589023730690482

Epoch: 5| Step: 6
Training loss: 3.3055286103618733
Validation loss: 2.590421129924072

Epoch: 5| Step: 7
Training loss: 2.672693852101843
Validation loss: 2.588581028619192

Epoch: 5| Step: 8
Training loss: 2.5781325831446242
Validation loss: 2.5870547920561773

Epoch: 5| Step: 9
Training loss: 2.693700512920489
Validation loss: 2.5874563445372205

Epoch: 5| Step: 10
Training loss: 2.3858625059201883
Validation loss: 2.5886521510922242

Epoch: 5| Step: 11
Training loss: 2.569411285003136
Validation loss: 2.5879388000994537

Epoch: 80| Step: 0
Training loss: 2.91172602770044
Validation loss: 2.5856810843120788

Epoch: 5| Step: 1
Training loss: 2.4724277191859665
Validation loss: 2.5856837045338446

Epoch: 5| Step: 2
Training loss: 2.4421392454333337
Validation loss: 2.582435060782009

Epoch: 5| Step: 3
Training loss: 3.0648992054531585
Validation loss: 2.5857064411854243

Epoch: 5| Step: 4
Training loss: 2.9462448789465463
Validation loss: 2.5829885096270417

Epoch: 5| Step: 5
Training loss: 2.914982300274409
Validation loss: 2.580974252856897

Epoch: 5| Step: 6
Training loss: 2.5814791044297967
Validation loss: 2.5806522813437285

Epoch: 5| Step: 7
Training loss: 2.927649519023374
Validation loss: 2.5805481245102486

Epoch: 5| Step: 8
Training loss: 2.561413511360081
Validation loss: 2.5773274893246287

Epoch: 5| Step: 9
Training loss: 2.245527378490418
Validation loss: 2.5753045655038713

Epoch: 5| Step: 10
Training loss: 2.6243134463623625
Validation loss: 2.5793760732080524

Epoch: 5| Step: 11
Training loss: 2.908852345264836
Validation loss: 2.57372799075157

Epoch: 81| Step: 0
Training loss: 2.4550535554346853
Validation loss: 2.5763284993755833

Epoch: 5| Step: 1
Training loss: 2.5629846998361576
Validation loss: 2.5768334245716495

Epoch: 5| Step: 2
Training loss: 2.5832545258181416
Validation loss: 2.5746192929236935

Epoch: 5| Step: 3
Training loss: 2.63609756499297
Validation loss: 2.5764048183996353

Epoch: 5| Step: 4
Training loss: 2.8751721537919135
Validation loss: 2.577655271644158

Epoch: 5| Step: 5
Training loss: 2.869547109458794
Validation loss: 2.5778156094873963

Epoch: 5| Step: 6
Training loss: 2.74954592684001
Validation loss: 2.5769782280567823

Epoch: 5| Step: 7
Training loss: 2.5413041299214103
Validation loss: 2.5782772327522263

Epoch: 5| Step: 8
Training loss: 2.945866459323469
Validation loss: 2.578312942127934

Epoch: 5| Step: 9
Training loss: 2.5460211135696005
Validation loss: 2.5773956808543868

Epoch: 5| Step: 10
Training loss: 2.9658333354484414
Validation loss: 2.5721013145327043

Epoch: 5| Step: 11
Training loss: 2.9943871443280656
Validation loss: 2.5739256364409595

Epoch: 82| Step: 0
Training loss: 2.624424462575676
Validation loss: 2.5734032789810453

Epoch: 5| Step: 1
Training loss: 2.0507340489359738
Validation loss: 2.5737405389714083

Epoch: 5| Step: 2
Training loss: 2.2700234698456097
Validation loss: 2.5724568374381382

Epoch: 5| Step: 3
Training loss: 2.5381757390808257
Validation loss: 2.570232784345305

Epoch: 5| Step: 4
Training loss: 3.2644084507869624
Validation loss: 2.5696168246024045

Epoch: 5| Step: 5
Training loss: 2.5151067164325145
Validation loss: 2.5732969062290763

Epoch: 5| Step: 6
Training loss: 2.803100051683806
Validation loss: 2.568900840550484

Epoch: 5| Step: 7
Training loss: 2.6237935518136832
Validation loss: 2.568807310004938

Epoch: 5| Step: 8
Training loss: 2.972270444278768
Validation loss: 2.567536115513073

Epoch: 5| Step: 9
Training loss: 2.7538884155561703
Validation loss: 2.5661519474746175

Epoch: 5| Step: 10
Training loss: 3.154376843268436
Validation loss: 2.5635246771278264

Epoch: 5| Step: 11
Training loss: 2.3516956177607193
Validation loss: 2.5650103453439317

Epoch: 83| Step: 0
Training loss: 2.8517720184693425
Validation loss: 2.5627539245277218

Epoch: 5| Step: 1
Training loss: 2.5023023494138514
Validation loss: 2.5647846326271146

Epoch: 5| Step: 2
Training loss: 2.9434696979262185
Validation loss: 2.5642682619230848

Epoch: 5| Step: 3
Training loss: 2.9745826043710824
Validation loss: 2.563173077738654

Epoch: 5| Step: 4
Training loss: 2.5473761504281263
Validation loss: 2.5645896331023854

Epoch: 5| Step: 5
Training loss: 2.911036989208324
Validation loss: 2.563803132100405

Epoch: 5| Step: 6
Training loss: 2.546686832521229
Validation loss: 2.564718046350792

Epoch: 5| Step: 7
Training loss: 2.745198045406232
Validation loss: 2.5633152851053054

Epoch: 5| Step: 8
Training loss: 2.039807530654664
Validation loss: 2.5604017125855156

Epoch: 5| Step: 9
Training loss: 2.718794372898041
Validation loss: 2.5605351389352418

Epoch: 5| Step: 10
Training loss: 2.736448885685111
Validation loss: 2.559292681794321

Epoch: 5| Step: 11
Training loss: 2.5456908111719314
Validation loss: 2.5605407334561265

Epoch: 84| Step: 0
Training loss: 2.869847531937434
Validation loss: 2.5565427368479483

Epoch: 5| Step: 1
Training loss: 2.8020194706972075
Validation loss: 2.558165206158283

Epoch: 5| Step: 2
Training loss: 2.3081585107514595
Validation loss: 2.5578259119153293

Epoch: 5| Step: 3
Training loss: 2.6868157513748385
Validation loss: 2.5580626812602953

Epoch: 5| Step: 4
Training loss: 2.819001714797241
Validation loss: 2.5542802748583338

Epoch: 5| Step: 5
Training loss: 2.5286710811864426
Validation loss: 2.5544007788852987

Epoch: 5| Step: 6
Training loss: 2.5147271301400673
Validation loss: 2.5523948803651204

Epoch: 5| Step: 7
Training loss: 2.715943214025117
Validation loss: 2.551999524096292

Epoch: 5| Step: 8
Training loss: 2.7331412883685795
Validation loss: 2.5537932266582692

Epoch: 5| Step: 9
Training loss: 2.647651218061711
Validation loss: 2.5512256167098726

Epoch: 5| Step: 10
Training loss: 2.838452949654072
Validation loss: 2.54461201957431

Epoch: 5| Step: 11
Training loss: 2.6767122973887094
Validation loss: 2.5491310456044207

Epoch: 85| Step: 0
Training loss: 3.1827960740996586
Validation loss: 2.546475892107198

Epoch: 5| Step: 1
Training loss: 2.720485089746892
Validation loss: 2.5493322426864786

Epoch: 5| Step: 2
Training loss: 2.193741422891831
Validation loss: 2.553838933067437

Epoch: 5| Step: 3
Training loss: 3.2647779908578536
Validation loss: 2.554483679710516

Epoch: 5| Step: 4
Training loss: 2.4635849048995007
Validation loss: 2.549121700446037

Epoch: 5| Step: 5
Training loss: 2.8449015538994304
Validation loss: 2.5462195288199307

Epoch: 5| Step: 6
Training loss: 3.1131112352613344
Validation loss: 2.547911684577752

Epoch: 5| Step: 7
Training loss: 2.079879479034386
Validation loss: 2.5472502246756377

Epoch: 5| Step: 8
Training loss: 2.497890536118853
Validation loss: 2.5466618282919584

Epoch: 5| Step: 9
Training loss: 2.3657219003965513
Validation loss: 2.5461337487199383

Epoch: 5| Step: 10
Training loss: 2.441231536717285
Validation loss: 2.5477404342946928

Epoch: 5| Step: 11
Training loss: 2.6043198095432976
Validation loss: 2.5489162541886117

Epoch: 86| Step: 0
Training loss: 3.169896302557818
Validation loss: 2.546669321784871

Epoch: 5| Step: 1
Training loss: 2.0411653746649137
Validation loss: 2.548640674699088

Epoch: 5| Step: 2
Training loss: 2.4505601826399275
Validation loss: 2.550000003428241

Epoch: 5| Step: 3
Training loss: 1.9282216052518344
Validation loss: 2.550063226420876

Epoch: 5| Step: 4
Training loss: 2.4309177044112613
Validation loss: 2.548858408547047

Epoch: 5| Step: 5
Training loss: 3.3068807191426193
Validation loss: 2.548656721916757

Epoch: 5| Step: 6
Training loss: 2.8993759075672383
Validation loss: 2.546986829022702

Epoch: 5| Step: 7
Training loss: 3.1216039896991834
Validation loss: 2.5437044133343476

Epoch: 5| Step: 8
Training loss: 2.608070915679748
Validation loss: 2.5424174244854845

Epoch: 5| Step: 9
Training loss: 2.819967824738831
Validation loss: 2.540993579218605

Epoch: 5| Step: 10
Training loss: 2.314959275153167
Validation loss: 2.5403821323139923

Epoch: 5| Step: 11
Training loss: 2.593246870765133
Validation loss: 2.538672690179368

Epoch: 87| Step: 0
Training loss: 2.883568972034394
Validation loss: 2.539035628739019

Epoch: 5| Step: 1
Training loss: 2.827000093933039
Validation loss: 2.5410667060489285

Epoch: 5| Step: 2
Training loss: 2.910291261549397
Validation loss: 2.5368838387418595

Epoch: 5| Step: 3
Training loss: 2.547744041036877
Validation loss: 2.5379568773886856

Epoch: 5| Step: 4
Training loss: 2.6198949673398317
Validation loss: 2.5378280299212235

Epoch: 5| Step: 5
Training loss: 2.630662623286181
Validation loss: 2.5335899377308584

Epoch: 5| Step: 6
Training loss: 2.3022412782458916
Validation loss: 2.535076816060869

Epoch: 5| Step: 7
Training loss: 2.681226371892221
Validation loss: 2.533949431026567

Epoch: 5| Step: 8
Training loss: 2.427099094148688
Validation loss: 2.5372899798530604

Epoch: 5| Step: 9
Training loss: 2.8059669062973356
Validation loss: 2.5346214698264866

Epoch: 5| Step: 10
Training loss: 2.3494841557317785
Validation loss: 2.5312558986453806

Epoch: 5| Step: 11
Training loss: 3.468950695383541
Validation loss: 2.5346680863287996

Epoch: 88| Step: 0
Training loss: 2.4541775334565052
Validation loss: 2.530318135757832

Epoch: 5| Step: 1
Training loss: 2.468638550379426
Validation loss: 2.533496142685406

Epoch: 5| Step: 2
Training loss: 2.4682437039556486
Validation loss: 2.534147099926704

Epoch: 5| Step: 3
Training loss: 3.149729423406688
Validation loss: 2.5338856864032535

Epoch: 5| Step: 4
Training loss: 2.7444871785452856
Validation loss: 2.5342220667907447

Epoch: 5| Step: 5
Training loss: 2.832140185135488
Validation loss: 2.5335758810465

Epoch: 5| Step: 6
Training loss: 2.858592108605876
Validation loss: 2.534781739365011

Epoch: 5| Step: 7
Training loss: 2.626402434873309
Validation loss: 2.5341535445612333

Epoch: 5| Step: 8
Training loss: 2.1927142532039174
Validation loss: 2.533854553494452

Epoch: 5| Step: 9
Training loss: 2.585506898922809
Validation loss: 2.533441642643972

Epoch: 5| Step: 10
Training loss: 2.7838906600077995
Validation loss: 2.530710637747752

Epoch: 5| Step: 11
Training loss: 2.4751003052393843
Validation loss: 2.5320034554052655

Epoch: 89| Step: 0
Training loss: 2.942441476970774
Validation loss: 2.533432145502626

Epoch: 5| Step: 1
Training loss: 2.3279842871827183
Validation loss: 2.5339159015428505

Epoch: 5| Step: 2
Training loss: 2.676660902682979
Validation loss: 2.5318073024188363

Epoch: 5| Step: 3
Training loss: 3.1966875097757446
Validation loss: 2.5299846602654608

Epoch: 5| Step: 4
Training loss: 2.3056785392387535
Validation loss: 2.5284104432461856

Epoch: 5| Step: 5
Training loss: 2.3769186200761783
Validation loss: 2.5287020147010075

Epoch: 5| Step: 6
Training loss: 2.3581297158629626
Validation loss: 2.5257336117340112

Epoch: 5| Step: 7
Training loss: 2.6572111298247183
Validation loss: 2.5219146652915425

Epoch: 5| Step: 8
Training loss: 2.6794521573211196
Validation loss: 2.5197843045057087

Epoch: 5| Step: 9
Training loss: 2.979403364119724
Validation loss: 2.523552690205452

Epoch: 5| Step: 10
Training loss: 2.5627607817653297
Validation loss: 2.5219079136424014

Epoch: 5| Step: 11
Training loss: 2.392645686227231
Validation loss: 2.5206207364392546

Epoch: 90| Step: 0
Training loss: 2.7911958629587335
Validation loss: 2.525958460325546

Epoch: 5| Step: 1
Training loss: 2.509152728696297
Validation loss: 2.532893263611503

Epoch: 5| Step: 2
Training loss: 2.6896414985148946
Validation loss: 2.53485843925309

Epoch: 5| Step: 3
Training loss: 2.166791936725376
Validation loss: 2.529353310288032

Epoch: 5| Step: 4
Training loss: 2.5765795150204274
Validation loss: 2.53473468208444

Epoch: 5| Step: 5
Training loss: 2.410143884661098
Validation loss: 2.5258792130186

Epoch: 5| Step: 6
Training loss: 2.615718873594311
Validation loss: 2.5249691026515735

Epoch: 5| Step: 7
Training loss: 2.552278275083486
Validation loss: 2.5258070545115334

Epoch: 5| Step: 8
Training loss: 2.8366852922496752
Validation loss: 2.5213369911983645

Epoch: 5| Step: 9
Training loss: 2.8947926762320475
Validation loss: 2.521248035893505

Epoch: 5| Step: 10
Training loss: 3.055563096316502
Validation loss: 2.519724358937973

Epoch: 5| Step: 11
Training loss: 2.8804625984707672
Validation loss: 2.517435539869971

Epoch: 91| Step: 0
Training loss: 2.141532093179022
Validation loss: 2.522067620359595

Epoch: 5| Step: 1
Training loss: 2.901784275599532
Validation loss: 2.523665048833102

Epoch: 5| Step: 2
Training loss: 2.3267990535173464
Validation loss: 2.519973241002315

Epoch: 5| Step: 3
Training loss: 2.55690993019177
Validation loss: 2.520878493217146

Epoch: 5| Step: 4
Training loss: 2.649064881500437
Validation loss: 2.519484708292072

Epoch: 5| Step: 5
Training loss: 2.6163985700201278
Validation loss: 2.520757663526371

Epoch: 5| Step: 6
Training loss: 2.9794584189232736
Validation loss: 2.5210560090784764

Epoch: 5| Step: 7
Training loss: 2.869500248692461
Validation loss: 2.521488425096194

Epoch: 5| Step: 8
Training loss: 2.472955429514646
Validation loss: 2.5191619917884767

Epoch: 5| Step: 9
Training loss: 2.825645666690235
Validation loss: 2.522656980411837

Epoch: 5| Step: 10
Training loss: 2.6663092035873337
Validation loss: 2.5188885127713116

Epoch: 5| Step: 11
Training loss: 2.5360677576369453
Validation loss: 2.5171665065275914

Epoch: 92| Step: 0
Training loss: 2.520177666592458
Validation loss: 2.518970038628924

Epoch: 5| Step: 1
Training loss: 2.8178009939323694
Validation loss: 2.51780564705772

Epoch: 5| Step: 2
Training loss: 2.0870890778274465
Validation loss: 2.517498104854907

Epoch: 5| Step: 3
Training loss: 3.217118377461739
Validation loss: 2.516607242844763

Epoch: 5| Step: 4
Training loss: 2.7623331770432134
Validation loss: 2.5157973899771364

Epoch: 5| Step: 5
Training loss: 2.796019865617593
Validation loss: 2.518188899657493

Epoch: 5| Step: 6
Training loss: 2.684098863887209
Validation loss: 2.5200847008008704

Epoch: 5| Step: 7
Training loss: 2.786376856863471
Validation loss: 2.513096081228081

Epoch: 5| Step: 8
Training loss: 2.703030005753842
Validation loss: 2.5210896327557757

Epoch: 5| Step: 9
Training loss: 2.1777927271120094
Validation loss: 2.518078016750338

Epoch: 5| Step: 10
Training loss: 2.15992953609397
Validation loss: 2.517938312406124

Epoch: 5| Step: 11
Training loss: 3.1382575530149173
Validation loss: 2.5124899637834757

Epoch: 93| Step: 0
Training loss: 2.54468025237406
Validation loss: 2.5140021798006296

Epoch: 5| Step: 1
Training loss: 2.830335227602969
Validation loss: 2.5176243113169634

Epoch: 5| Step: 2
Training loss: 2.7609306192879033
Validation loss: 2.519597871279096

Epoch: 5| Step: 3
Training loss: 2.7278358961734916
Validation loss: 2.5202181370179133

Epoch: 5| Step: 4
Training loss: 3.0864884669343176
Validation loss: 2.5313594857230335

Epoch: 5| Step: 5
Training loss: 2.9901799970051544
Validation loss: 2.541991519231778

Epoch: 5| Step: 6
Training loss: 2.3650555468240038
Validation loss: 2.544843218220481

Epoch: 5| Step: 7
Training loss: 2.6198612959742817
Validation loss: 2.5438711984178086

Epoch: 5| Step: 8
Training loss: 2.565203752214384
Validation loss: 2.5437590605928233

Epoch: 5| Step: 9
Training loss: 2.638844629106174
Validation loss: 2.543362846249107

Epoch: 5| Step: 10
Training loss: 2.269568017868584
Validation loss: 2.5416572302241853

Epoch: 5| Step: 11
Training loss: 1.2782486909366846
Validation loss: 2.5380176291839227

Epoch: 94| Step: 0
Training loss: 2.7280306210966754
Validation loss: 2.5280184663221865

Epoch: 5| Step: 1
Training loss: 2.6405580049401705
Validation loss: 2.526984034414242

Epoch: 5| Step: 2
Training loss: 2.8176895582851027
Validation loss: 2.526729322346914

Epoch: 5| Step: 3
Training loss: 2.388604900079304
Validation loss: 2.5239107772706877

Epoch: 5| Step: 4
Training loss: 2.8172957329209547
Validation loss: 2.5237433028766008

Epoch: 5| Step: 5
Training loss: 2.9223110261227223
Validation loss: 2.5160272170097255

Epoch: 5| Step: 6
Training loss: 2.763972936616447
Validation loss: 2.516820560312098

Epoch: 5| Step: 7
Training loss: 2.439602067735918
Validation loss: 2.510710793329443

Epoch: 5| Step: 8
Training loss: 2.5041162935375145
Validation loss: 2.5178158304805507

Epoch: 5| Step: 9
Training loss: 2.4378357680459346
Validation loss: 2.5132019781469577

Epoch: 5| Step: 10
Training loss: 2.655288163116578
Validation loss: 2.510204442077385

Epoch: 5| Step: 11
Training loss: 2.298275890153474
Validation loss: 2.5128206453324577

Epoch: 95| Step: 0
Training loss: 2.814522927005681
Validation loss: 2.5119244900096387

Epoch: 5| Step: 1
Training loss: 2.3105554395115466
Validation loss: 2.51431544003329

Epoch: 5| Step: 2
Training loss: 2.6797883929507664
Validation loss: 2.507917487144389

Epoch: 5| Step: 3
Training loss: 2.561078677612213
Validation loss: 2.504091566412145

Epoch: 5| Step: 4
Training loss: 2.7562340387760194
Validation loss: 2.5045477590370413

Epoch: 5| Step: 5
Training loss: 2.6479385491124012
Validation loss: 2.510400896036042

Epoch: 5| Step: 6
Training loss: 2.5441889728559968
Validation loss: 2.507064327450919

Epoch: 5| Step: 7
Training loss: 2.7880318925366097
Validation loss: 2.5064827472431115

Epoch: 5| Step: 8
Training loss: 2.7168040710836583
Validation loss: 2.503754867603575

Epoch: 5| Step: 9
Training loss: 2.6589750784874946
Validation loss: 2.5080045426498434

Epoch: 5| Step: 10
Training loss: 2.48208022749201
Validation loss: 2.505222690617799

Epoch: 5| Step: 11
Training loss: 2.3016701812312172
Validation loss: 2.503189345321349

Epoch: 96| Step: 0
Training loss: 2.9823128331204165
Validation loss: 2.501683709287526

Epoch: 5| Step: 1
Training loss: 2.028168086224666
Validation loss: 2.5049193619409507

Epoch: 5| Step: 2
Training loss: 2.804597986009521
Validation loss: 2.500044901762497

Epoch: 5| Step: 3
Training loss: 2.6400047341217596
Validation loss: 2.5012883840116595

Epoch: 5| Step: 4
Training loss: 2.6750476583353118
Validation loss: 2.501648554055478

Epoch: 5| Step: 5
Training loss: 2.3493346753710154
Validation loss: 2.503860489084429

Epoch: 5| Step: 6
Training loss: 2.6858383187028676
Validation loss: 2.5020579371459126

Epoch: 5| Step: 7
Training loss: 2.9349843068003874
Validation loss: 2.5014350547309956

Epoch: 5| Step: 8
Training loss: 2.932677998453759
Validation loss: 2.5000435626685036

Epoch: 5| Step: 9
Training loss: 2.2810681414295204
Validation loss: 2.5021864667839266

Epoch: 5| Step: 10
Training loss: 2.4520263155323168
Validation loss: 2.5016673270029175

Epoch: 5| Step: 11
Training loss: 2.161311084067219
Validation loss: 2.49714190107339

Epoch: 97| Step: 0
Training loss: 2.9079588101498826
Validation loss: 2.499010359071609

Epoch: 5| Step: 1
Training loss: 2.4102070956068027
Validation loss: 2.499482371466055

Epoch: 5| Step: 2
Training loss: 2.389027379578044
Validation loss: 2.498597447037126

Epoch: 5| Step: 3
Training loss: 2.3833741573580935
Validation loss: 2.499354159856605

Epoch: 5| Step: 4
Training loss: 2.627074557195692
Validation loss: 2.5003535696187273

Epoch: 5| Step: 5
Training loss: 2.633897235305258
Validation loss: 2.5017914711124973

Epoch: 5| Step: 6
Training loss: 2.44057153699396
Validation loss: 2.5019410267323225

Epoch: 5| Step: 7
Training loss: 2.4419419334187626
Validation loss: 2.5002454955045783

Epoch: 5| Step: 8
Training loss: 2.6834571059530177
Validation loss: 2.5029655708978473

Epoch: 5| Step: 9
Training loss: 3.4874306183069623
Validation loss: 2.5000079432997078

Epoch: 5| Step: 10
Training loss: 2.310679363408822
Validation loss: 2.5018896709796272

Epoch: 5| Step: 11
Training loss: 2.2720351465757282
Validation loss: 2.502598268632293

Epoch: 98| Step: 0
Training loss: 2.3086882441202015
Validation loss: 2.5040731865376222

Epoch: 5| Step: 1
Training loss: 2.7767269774897803
Validation loss: 2.5051327308672673

Epoch: 5| Step: 2
Training loss: 2.7640806724766085
Validation loss: 2.507689468043662

Epoch: 5| Step: 3
Training loss: 2.433348225413002
Validation loss: 2.5039297887337444

Epoch: 5| Step: 4
Training loss: 2.0723042821559283
Validation loss: 2.507797387732173

Epoch: 5| Step: 5
Training loss: 2.5984941780299633
Validation loss: 2.5014218260847456

Epoch: 5| Step: 6
Training loss: 3.296169983026791
Validation loss: 2.496854770564129

Epoch: 5| Step: 7
Training loss: 2.610462624484512
Validation loss: 2.4961304241544746

Epoch: 5| Step: 8
Training loss: 2.2168736650383853
Validation loss: 2.4989765854031543

Epoch: 5| Step: 9
Training loss: 2.8596443091136345
Validation loss: 2.5009045196408874

Epoch: 5| Step: 10
Training loss: 2.7071793861095834
Validation loss: 2.4975591585588113

Epoch: 5| Step: 11
Training loss: 2.4812265274897802
Validation loss: 2.499356469138684

Epoch: 99| Step: 0
Training loss: 2.8065011368760606
Validation loss: 2.4960113555570165

Epoch: 5| Step: 1
Training loss: 2.564347973169074
Validation loss: 2.4927415580676704

Epoch: 5| Step: 2
Training loss: 2.000680092574699
Validation loss: 2.4929471706666617

Epoch: 5| Step: 3
Training loss: 2.048817884566877
Validation loss: 2.4976348179198062

Epoch: 5| Step: 4
Training loss: 2.4679586373484548
Validation loss: 2.4997476967018466

Epoch: 5| Step: 5
Training loss: 3.00254745407783
Validation loss: 2.4960149236180973

Epoch: 5| Step: 6
Training loss: 2.488853113403617
Validation loss: 2.497798192478684

Epoch: 5| Step: 7
Training loss: 2.777305119885619
Validation loss: 2.501738623209626

Epoch: 5| Step: 8
Training loss: 3.056065553431424
Validation loss: 2.4961034608432158

Epoch: 5| Step: 9
Training loss: 2.849686515030689
Validation loss: 2.489258203597479

Epoch: 5| Step: 10
Training loss: 2.4922375330192725
Validation loss: 2.498566361476527

Epoch: 5| Step: 11
Training loss: 2.3805501234758446
Validation loss: 2.5002059057000525

Epoch: 100| Step: 0
Training loss: 2.4666118778982975
Validation loss: 2.4906089191882876

Epoch: 5| Step: 1
Training loss: 2.8328320863933514
Validation loss: 2.492252329079821

Epoch: 5| Step: 2
Training loss: 2.7493044233618247
Validation loss: 2.4960380034572003

Epoch: 5| Step: 3
Training loss: 2.522982907757826
Validation loss: 2.496943588333312

Epoch: 5| Step: 4
Training loss: 2.7951739375495053
Validation loss: 2.500269072675639

Epoch: 5| Step: 5
Training loss: 2.8306361057083005
Validation loss: 2.49712072109463

Epoch: 5| Step: 6
Training loss: 1.9628159845688986
Validation loss: 2.4973898772538927

Epoch: 5| Step: 7
Training loss: 2.869252804510081
Validation loss: 2.5022950843273395

Epoch: 5| Step: 8
Training loss: 2.9594887281597293
Validation loss: 2.4997084050195184

Epoch: 5| Step: 9
Training loss: 2.2643335278909347
Validation loss: 2.502234437896971

Epoch: 5| Step: 10
Training loss: 2.5310959945735636
Validation loss: 2.4976502740713125

Epoch: 5| Step: 11
Training loss: 2.286255870246338
Validation loss: 2.4923053940777584

Epoch: 101| Step: 0
Training loss: 2.5372449737327645
Validation loss: 2.4930063753905976

Epoch: 5| Step: 1
Training loss: 2.9441388369455233
Validation loss: 2.492459109980722

Epoch: 5| Step: 2
Training loss: 2.8470394685807814
Validation loss: 2.494877275552366

Epoch: 5| Step: 3
Training loss: 2.444337498126749
Validation loss: 2.493747370502612

Epoch: 5| Step: 4
Training loss: 2.4987257571091557
Validation loss: 2.497828537916416

Epoch: 5| Step: 5
Training loss: 2.5775066212107496
Validation loss: 2.4953315816940727

Epoch: 5| Step: 6
Training loss: 2.5143510898227928
Validation loss: 2.498816480237257

Epoch: 5| Step: 7
Training loss: 2.6829599578804
Validation loss: 2.4983627640562336

Epoch: 5| Step: 8
Training loss: 2.2650114083581734
Validation loss: 2.497081594947665

Epoch: 5| Step: 9
Training loss: 2.932579301963493
Validation loss: 2.4943834394227595

Epoch: 5| Step: 10
Training loss: 2.3537447616024547
Validation loss: 2.4938159752247424

Epoch: 5| Step: 11
Training loss: 3.095831738998256
Validation loss: 2.496231596657134

Epoch: 102| Step: 0
Training loss: 2.5246801948087545
Validation loss: 2.4930361714815263

Epoch: 5| Step: 1
Training loss: 2.6211464161705393
Validation loss: 2.4962376178478296

Epoch: 5| Step: 2
Training loss: 2.7233926879907915
Validation loss: 2.4960557738725004

Epoch: 5| Step: 3
Training loss: 2.8343997706095285
Validation loss: 2.489625784114344

Epoch: 5| Step: 4
Training loss: 2.7471768019208307
Validation loss: 2.493446343082706

Epoch: 5| Step: 5
Training loss: 2.236326205989897
Validation loss: 2.493223407505753

Epoch: 5| Step: 6
Training loss: 2.8091913046520722
Validation loss: 2.4936267439897173

Epoch: 5| Step: 7
Training loss: 2.6329590165208083
Validation loss: 2.4930619566176144

Epoch: 5| Step: 8
Training loss: 2.577889264050871
Validation loss: 2.490373096466805

Epoch: 5| Step: 9
Training loss: 2.341689157434519
Validation loss: 2.4943294707568335

Epoch: 5| Step: 10
Training loss: 2.5614120220658463
Validation loss: 2.4891656833868527

Epoch: 5| Step: 11
Training loss: 2.5210648947885796
Validation loss: 2.491332948997365

Epoch: 103| Step: 0
Training loss: 2.1585474352401626
Validation loss: 2.486443012756614

Epoch: 5| Step: 1
Training loss: 3.140753596315858
Validation loss: 2.4928658099446084

Epoch: 5| Step: 2
Training loss: 2.458529890144442
Validation loss: 2.485528622099162

Epoch: 5| Step: 3
Training loss: 2.706451309857052
Validation loss: 2.4958808143463806

Epoch: 5| Step: 4
Training loss: 2.5470055856752047
Validation loss: 2.496681184053762

Epoch: 5| Step: 5
Training loss: 2.850041566512174
Validation loss: 2.491084980020353

Epoch: 5| Step: 6
Training loss: 2.175052102878926
Validation loss: 2.4896092247248407

Epoch: 5| Step: 7
Training loss: 2.874838451324843
Validation loss: 2.4891241453510906

Epoch: 5| Step: 8
Training loss: 2.661220522493775
Validation loss: 2.4862182105442074

Epoch: 5| Step: 9
Training loss: 2.724713242167821
Validation loss: 2.4831741637758906

Epoch: 5| Step: 10
Training loss: 2.2181926618302477
Validation loss: 2.4907170564685384

Epoch: 5| Step: 11
Training loss: 2.399517102138639
Validation loss: 2.490029677411441

Epoch: 104| Step: 0
Training loss: 2.964656859125251
Validation loss: 2.4900557829201513

Epoch: 5| Step: 1
Training loss: 2.671135158613936
Validation loss: 2.4989875750138033

Epoch: 5| Step: 2
Training loss: 2.5876410367555462
Validation loss: 2.5187968955710898

Epoch: 5| Step: 3
Training loss: 2.534706016964836
Validation loss: 2.517771502107326

Epoch: 5| Step: 4
Training loss: 3.147515931153524
Validation loss: 2.5174864758958813

Epoch: 5| Step: 5
Training loss: 2.3250374001396925
Validation loss: 2.515330800925782

Epoch: 5| Step: 6
Training loss: 2.61428198021258
Validation loss: 2.522342889327146

Epoch: 5| Step: 7
Training loss: 3.079751296715626
Validation loss: 2.526841673391036

Epoch: 5| Step: 8
Training loss: 2.1053661540837094
Validation loss: 2.504877351453751

Epoch: 5| Step: 9
Training loss: 2.3731527673776105
Validation loss: 2.498995513581122

Epoch: 5| Step: 10
Training loss: 2.2658416644447468
Validation loss: 2.493989072062206

Epoch: 5| Step: 11
Training loss: 3.368434029165168
Validation loss: 2.4912674400375026

Epoch: 105| Step: 0
Training loss: 2.5728784988187527
Validation loss: 2.4934914943332505

Epoch: 5| Step: 1
Training loss: 2.700625460200236
Validation loss: 2.5012813383900623

Epoch: 5| Step: 2
Training loss: 2.461378076261702
Validation loss: 2.50508063553312

Epoch: 5| Step: 3
Training loss: 1.8731413848231615
Validation loss: 2.508554002384974

Epoch: 5| Step: 4
Training loss: 2.615287614982725
Validation loss: 2.5108091013342886

Epoch: 5| Step: 5
Training loss: 2.712343142847977
Validation loss: 2.507744492096915

Epoch: 5| Step: 6
Training loss: 2.790452284984094
Validation loss: 2.506456676088697

Epoch: 5| Step: 7
Training loss: 2.8364934875424277
Validation loss: 2.512521310023184

Epoch: 5| Step: 8
Training loss: 2.5839924945545145
Validation loss: 2.512160432937606

Epoch: 5| Step: 9
Training loss: 2.832875345651309
Validation loss: 2.5097936448092892

Epoch: 5| Step: 10
Training loss: 2.8932769982029165
Validation loss: 2.506794149349946

Epoch: 5| Step: 11
Training loss: 2.1359931229755693
Validation loss: 2.5014850378105615

Epoch: 106| Step: 0
Training loss: 2.631142287416874
Validation loss: 2.4928767806665606

Epoch: 5| Step: 1
Training loss: 2.5502211231772844
Validation loss: 2.4926917025474538

Epoch: 5| Step: 2
Training loss: 2.415707123657087
Validation loss: 2.489839917026263

Epoch: 5| Step: 3
Training loss: 2.990365611659224
Validation loss: 2.4895155922732846

Epoch: 5| Step: 4
Training loss: 2.8008341977103832
Validation loss: 2.4869980669884555

Epoch: 5| Step: 5
Training loss: 2.3914235096669705
Validation loss: 2.491649796887024

Epoch: 5| Step: 6
Training loss: 2.672011522519514
Validation loss: 2.491057419741596

Epoch: 5| Step: 7
Training loss: 2.7104456562561032
Validation loss: 2.487706200281663

Epoch: 5| Step: 8
Training loss: 2.3545865609974888
Validation loss: 2.4876747569960806

Epoch: 5| Step: 9
Training loss: 2.5137341898416694
Validation loss: 2.487439634558712

Epoch: 5| Step: 10
Training loss: 2.6823638807532304
Validation loss: 2.4889069054569766

Epoch: 5| Step: 11
Training loss: 2.8862543829500105
Validation loss: 2.4860814789533987

Epoch: 107| Step: 0
Training loss: 2.51877770799111
Validation loss: 2.488190969189757

Epoch: 5| Step: 1
Training loss: 2.8680126032000377
Validation loss: 2.487901288320783

Epoch: 5| Step: 2
Training loss: 2.4038736077721627
Validation loss: 2.4853591309277925

Epoch: 5| Step: 3
Training loss: 2.761486685794504
Validation loss: 2.485184235801485

Epoch: 5| Step: 4
Training loss: 2.8101825915436422
Validation loss: 2.483430834964026

Epoch: 5| Step: 5
Training loss: 2.5595516828537974
Validation loss: 2.4867378570496914

Epoch: 5| Step: 6
Training loss: 2.5087023906058183
Validation loss: 2.486824589397579

Epoch: 5| Step: 7
Training loss: 2.358060559065379
Validation loss: 2.4842598786462364

Epoch: 5| Step: 8
Training loss: 2.8830286787487553
Validation loss: 2.485041167156802

Epoch: 5| Step: 9
Training loss: 2.5233038049009067
Validation loss: 2.48489854202544

Epoch: 5| Step: 10
Training loss: 2.5663255188203586
Validation loss: 2.48287030603468

Epoch: 5| Step: 11
Training loss: 1.6605888251921814
Validation loss: 2.4867876721433633

Epoch: 108| Step: 0
Training loss: 3.2526567310802563
Validation loss: 2.4883945305558086

Epoch: 5| Step: 1
Training loss: 2.2766910095179416
Validation loss: 2.482944648575612

Epoch: 5| Step: 2
Training loss: 2.939895951382643
Validation loss: 2.4846576433927154

Epoch: 5| Step: 3
Training loss: 2.5041245768517233
Validation loss: 2.4826066663439748

Epoch: 5| Step: 4
Training loss: 2.1369675625671896
Validation loss: 2.486931974485865

Epoch: 5| Step: 5
Training loss: 2.7046228569675654
Validation loss: 2.483543696763605

Epoch: 5| Step: 6
Training loss: 2.4991335320976513
Validation loss: 2.4838180617491146

Epoch: 5| Step: 7
Training loss: 2.2908215322661194
Validation loss: 2.479031524394158

Epoch: 5| Step: 8
Training loss: 2.521839687095448
Validation loss: 2.483622378983976

Epoch: 5| Step: 9
Training loss: 2.668349321290852
Validation loss: 2.479809719055131

Epoch: 5| Step: 10
Training loss: 2.701064277982878
Validation loss: 2.4842236550734547

Epoch: 5| Step: 11
Training loss: 2.23386563984249
Validation loss: 2.481597871680826

Epoch: 109| Step: 0
Training loss: 2.0610508307010282
Validation loss: 2.480386002729816

Epoch: 5| Step: 1
Training loss: 2.633609549204269
Validation loss: 2.4828356246239447

Epoch: 5| Step: 2
Training loss: 3.04581076791513
Validation loss: 2.4827648519173495

Epoch: 5| Step: 3
Training loss: 2.652253139560512
Validation loss: 2.4865682904962805

Epoch: 5| Step: 4
Training loss: 2.574689946442581
Validation loss: 2.4878364856172106

Epoch: 5| Step: 5
Training loss: 3.0177495716364233
Validation loss: 2.49080433026408

Epoch: 5| Step: 6
Training loss: 2.3617462974302073
Validation loss: 2.4896633635443823

Epoch: 5| Step: 7
Training loss: 2.4133574311052635
Validation loss: 2.4881506505814794

Epoch: 5| Step: 8
Training loss: 2.5556089273583127
Validation loss: 2.4904494328603994

Epoch: 5| Step: 9
Training loss: 2.4496634777714656
Validation loss: 2.4911479675317856

Epoch: 5| Step: 10
Training loss: 2.6036685518078793
Validation loss: 2.4889731690268597

Epoch: 5| Step: 11
Training loss: 3.2158158641405614
Validation loss: 2.485020475686989

Epoch: 110| Step: 0
Training loss: 2.4174701626503454
Validation loss: 2.4902111974896677

Epoch: 5| Step: 1
Training loss: 2.5063087018908075
Validation loss: 2.485683188706512

Epoch: 5| Step: 2
Training loss: 2.848094597713428
Validation loss: 2.4853833989051006

Epoch: 5| Step: 3
Training loss: 2.7646896590996994
Validation loss: 2.4831569532720814

Epoch: 5| Step: 4
Training loss: 2.022678188589561
Validation loss: 2.4852350693577083

Epoch: 5| Step: 5
Training loss: 2.8046031716082958
Validation loss: 2.480360694594212

Epoch: 5| Step: 6
Training loss: 2.5596392410119866
Validation loss: 2.480366029389647

Epoch: 5| Step: 7
Training loss: 2.468867335368026
Validation loss: 2.4788845580272305

Epoch: 5| Step: 8
Training loss: 2.6847285685097226
Validation loss: 2.4788538384149135

Epoch: 5| Step: 9
Training loss: 2.798270447482412
Validation loss: 2.476922302904576

Epoch: 5| Step: 10
Training loss: 2.6209993302782144
Validation loss: 2.475998121228273

Epoch: 5| Step: 11
Training loss: 2.622755453434053
Validation loss: 2.4747407111100745

Epoch: 111| Step: 0
Training loss: 2.4974609833229056
Validation loss: 2.4716178919476253

Epoch: 5| Step: 1
Training loss: 2.666942482830493
Validation loss: 2.4721479450871318

Epoch: 5| Step: 2
Training loss: 2.075465055998157
Validation loss: 2.4731312356323474

Epoch: 5| Step: 3
Training loss: 2.6724805536088985
Validation loss: 2.4720328430501137

Epoch: 5| Step: 4
Training loss: 2.4196942755786455
Validation loss: 2.4756450778937036

Epoch: 5| Step: 5
Training loss: 2.707843785179511
Validation loss: 2.4760662989714475

Epoch: 5| Step: 6
Training loss: 2.2738479296213847
Validation loss: 2.469465572534147

Epoch: 5| Step: 7
Training loss: 2.658006334272864
Validation loss: 2.472156134595982

Epoch: 5| Step: 8
Training loss: 2.389149528400258
Validation loss: 2.477728387748328

Epoch: 5| Step: 9
Training loss: 2.6754880869854523
Validation loss: 2.476373879904296

Epoch: 5| Step: 10
Training loss: 3.1189495259830484
Validation loss: 2.473133199853473

Epoch: 5| Step: 11
Training loss: 3.024469559246237
Validation loss: 2.471702878017545

Epoch: 112| Step: 0
Training loss: 2.9230292177361585
Validation loss: 2.4739166892043527

Epoch: 5| Step: 1
Training loss: 1.7608980352114023
Validation loss: 2.4693695248718766

Epoch: 5| Step: 2
Training loss: 3.1112891971238623
Validation loss: 2.469113741607998

Epoch: 5| Step: 3
Training loss: 2.940789835705382
Validation loss: 2.4717379366832173

Epoch: 5| Step: 4
Training loss: 3.006528426697807
Validation loss: 2.4781452079516653

Epoch: 5| Step: 5
Training loss: 2.2856940264314907
Validation loss: 2.4800627408692337

Epoch: 5| Step: 6
Training loss: 2.5522655707448667
Validation loss: 2.477959288115144

Epoch: 5| Step: 7
Training loss: 2.5772345652468225
Validation loss: 2.4737899214324894

Epoch: 5| Step: 8
Training loss: 2.3914986802850584
Validation loss: 2.475769309049897

Epoch: 5| Step: 9
Training loss: 1.6673478482903579
Validation loss: 2.4764109383625597

Epoch: 5| Step: 10
Training loss: 2.466887918636109
Validation loss: 2.4714842917161595

Epoch: 5| Step: 11
Training loss: 3.6402058503349095
Validation loss: 2.4755584213663817

Epoch: 113| Step: 0
Training loss: 2.7587238999494574
Validation loss: 2.4784559659037897

Epoch: 5| Step: 1
Training loss: 2.8380890558315057
Validation loss: 2.481405162523996

Epoch: 5| Step: 2
Training loss: 2.867367606262043
Validation loss: 2.4813315905809645

Epoch: 5| Step: 3
Training loss: 2.4945609053017748
Validation loss: 2.481440272270447

Epoch: 5| Step: 4
Training loss: 2.2462859759795877
Validation loss: 2.4781600360389984

Epoch: 5| Step: 5
Training loss: 2.2345461479742945
Validation loss: 2.472281003162736

Epoch: 5| Step: 6
Training loss: 2.5414668979203916
Validation loss: 2.4786622124569155

Epoch: 5| Step: 7
Training loss: 2.7356140816993357
Validation loss: 2.4788045271408157

Epoch: 5| Step: 8
Training loss: 2.504605247779496
Validation loss: 2.474002124331885

Epoch: 5| Step: 9
Training loss: 2.462532519595365
Validation loss: 2.4728199531477886

Epoch: 5| Step: 10
Training loss: 2.610174273668737
Validation loss: 2.4772346138110137

Epoch: 5| Step: 11
Training loss: 2.3585933375729393
Validation loss: 2.4718227538492292

Epoch: 114| Step: 0
Training loss: 2.260724470097961
Validation loss: 2.4765026394161027

Epoch: 5| Step: 1
Training loss: 2.576055447461486
Validation loss: 2.4754455205557058

Epoch: 5| Step: 2
Training loss: 2.654081738688707
Validation loss: 2.471582220640892

Epoch: 5| Step: 3
Training loss: 1.9923829824243569
Validation loss: 2.469681234208997

Epoch: 5| Step: 4
Training loss: 2.663823360326193
Validation loss: 2.4748058326414877

Epoch: 5| Step: 5
Training loss: 2.2592458432163447
Validation loss: 2.476695986739338

Epoch: 5| Step: 6
Training loss: 2.9623404930729036
Validation loss: 2.4747983503557833

Epoch: 5| Step: 7
Training loss: 2.6205202660623996
Validation loss: 2.4718684568129663

Epoch: 5| Step: 8
Training loss: 2.9186620335525446
Validation loss: 2.4779074553754716

Epoch: 5| Step: 9
Training loss: 2.7087756944959547
Validation loss: 2.4668050379755226

Epoch: 5| Step: 10
Training loss: 2.8815384197066685
Validation loss: 2.4644500853331874

Epoch: 5| Step: 11
Training loss: 0.51101974618612
Validation loss: 2.4711744861517233

Epoch: 115| Step: 0
Training loss: 2.8441834171881233
Validation loss: 2.473247668270692

Epoch: 5| Step: 1
Training loss: 2.782496997869334
Validation loss: 2.4725597095576126

Epoch: 5| Step: 2
Training loss: 2.3011904289496137
Validation loss: 2.4750991774124325

Epoch: 5| Step: 3
Training loss: 3.107178185172853
Validation loss: 2.471131226613921

Epoch: 5| Step: 4
Training loss: 2.531924310984184
Validation loss: 2.4700727500446424

Epoch: 5| Step: 5
Training loss: 2.781027538532199
Validation loss: 2.4766057649477506

Epoch: 5| Step: 6
Training loss: 2.2000616975282554
Validation loss: 2.4782040006561203

Epoch: 5| Step: 7
Training loss: 2.1954430375030025
Validation loss: 2.4730062412813587

Epoch: 5| Step: 8
Training loss: 1.9841566791734329
Validation loss: 2.471721864338203

Epoch: 5| Step: 9
Training loss: 2.93621522118769
Validation loss: 2.473721257277801

Epoch: 5| Step: 10
Training loss: 2.3904802864504964
Validation loss: 2.4712754583068484

Epoch: 5| Step: 11
Training loss: 2.6351535248593883
Validation loss: 2.4718401276660087

Epoch: 116| Step: 0
Training loss: 2.653879162254589
Validation loss: 2.479015475292409

Epoch: 5| Step: 1
Training loss: 2.2879116042407714
Validation loss: 2.4806439275284586

Epoch: 5| Step: 2
Training loss: 2.6804821737871114
Validation loss: 2.4800566683916703

Epoch: 5| Step: 3
Training loss: 2.7389756218840997
Validation loss: 2.4763998425454745

Epoch: 5| Step: 4
Training loss: 2.9208860304609447
Validation loss: 2.4796198115557906

Epoch: 5| Step: 5
Training loss: 2.6969909749118743
Validation loss: 2.4819516492676317

Epoch: 5| Step: 6
Training loss: 2.100335312367395
Validation loss: 2.4837189693909116

Epoch: 5| Step: 7
Training loss: 2.7082272044197615
Validation loss: 2.484619304552898

Epoch: 5| Step: 8
Training loss: 2.6099462740399932
Validation loss: 2.4812248719558094

Epoch: 5| Step: 9
Training loss: 2.624924976548344
Validation loss: 2.481150019446625

Epoch: 5| Step: 10
Training loss: 2.262522921788562
Validation loss: 2.477322927993179

Epoch: 5| Step: 11
Training loss: 2.6528135622372693
Validation loss: 2.477348193979984

Epoch: 117| Step: 0
Training loss: 2.776462678075573
Validation loss: 2.4844847960771723

Epoch: 5| Step: 1
Training loss: 2.3567381011769344
Validation loss: 2.4795503453008148

Epoch: 5| Step: 2
Training loss: 2.385815438556438
Validation loss: 2.4698607002455835

Epoch: 5| Step: 3
Training loss: 2.661564794353317
Validation loss: 2.4750053853641063

Epoch: 5| Step: 4
Training loss: 2.1801395289364174
Validation loss: 2.4745080149826455

Epoch: 5| Step: 5
Training loss: 2.417056107109339
Validation loss: 2.4806222422610014

Epoch: 5| Step: 6
Training loss: 2.7346103239977335
Validation loss: 2.4751740182523347

Epoch: 5| Step: 7
Training loss: 2.4386017094688333
Validation loss: 2.4718099454541043

Epoch: 5| Step: 8
Training loss: 2.7756659353081257
Validation loss: 2.473469139052598

Epoch: 5| Step: 9
Training loss: 3.0345774212783603
Validation loss: 2.4677236572365233

Epoch: 5| Step: 10
Training loss: 2.4499901829736954
Validation loss: 2.470138569740282

Epoch: 5| Step: 11
Training loss: 3.053770430094849
Validation loss: 2.4732166999010303

Epoch: 118| Step: 0
Training loss: 2.304647154374081
Validation loss: 2.4667172775252886

Epoch: 5| Step: 1
Training loss: 2.4958924882487885
Validation loss: 2.474157033603666

Epoch: 5| Step: 2
Training loss: 2.3467984528636108
Validation loss: 2.4781566707644576

Epoch: 5| Step: 3
Training loss: 2.3435782814698025
Validation loss: 2.4794261954140726

Epoch: 5| Step: 4
Training loss: 3.0260471643779843
Validation loss: 2.487753148831834

Epoch: 5| Step: 5
Training loss: 2.8283769695517726
Validation loss: 2.491284544667456

Epoch: 5| Step: 6
Training loss: 2.5047454617862117
Validation loss: 2.4963946631208582

Epoch: 5| Step: 7
Training loss: 3.073740978995633
Validation loss: 2.501513581251335

Epoch: 5| Step: 8
Training loss: 2.70363299056219
Validation loss: 2.5107220520691915

Epoch: 5| Step: 9
Training loss: 2.544404405401932
Validation loss: 2.517093841717293

Epoch: 5| Step: 10
Training loss: 2.5493162659661666
Validation loss: 2.524827316567182

Epoch: 5| Step: 11
Training loss: 1.3959230375170535
Validation loss: 2.5273112079268545

Epoch: 119| Step: 0
Training loss: 2.3449137532330093
Validation loss: 2.52803774487811

Epoch: 5| Step: 1
Training loss: 2.710847001118001
Validation loss: 2.525342987547463

Epoch: 5| Step: 2
Training loss: 2.9439873990431917
Validation loss: 2.5309205135138577

Epoch: 5| Step: 3
Training loss: 2.5112384912465426
Validation loss: 2.5133908225077652

Epoch: 5| Step: 4
Training loss: 3.30278880448386
Validation loss: 2.5124510176709274

Epoch: 5| Step: 5
Training loss: 1.8962128088264307
Validation loss: 2.5049898259812253

Epoch: 5| Step: 6
Training loss: 2.555540543203442
Validation loss: 2.5058848894365937

Epoch: 5| Step: 7
Training loss: 2.651495054755076
Validation loss: 2.496740855280605

Epoch: 5| Step: 8
Training loss: 2.4242053234086267
Validation loss: 2.4951694988184294

Epoch: 5| Step: 9
Training loss: 2.6166469642075585
Validation loss: 2.4975274455395677

Epoch: 5| Step: 10
Training loss: 2.5915771023237606
Validation loss: 2.4902857118189297

Epoch: 5| Step: 11
Training loss: 2.650180479417643
Validation loss: 2.4843012001064486

Epoch: 120| Step: 0
Training loss: 2.7302189222875413
Validation loss: 2.478381618988397

Epoch: 5| Step: 1
Training loss: 2.5837488968195816
Validation loss: 2.4750063165590492

Epoch: 5| Step: 2
Training loss: 2.772119257162981
Validation loss: 2.4735008793910214

Epoch: 5| Step: 3
Training loss: 2.1621170939761716
Validation loss: 2.471169955613942

Epoch: 5| Step: 4
Training loss: 2.959767777380602
Validation loss: 2.467054690361346

Epoch: 5| Step: 5
Training loss: 2.616523954626263
Validation loss: 2.4654464025242335

Epoch: 5| Step: 6
Training loss: 2.715209058155962
Validation loss: 2.4681191503526785

Epoch: 5| Step: 7
Training loss: 2.3891944344854745
Validation loss: 2.465839849715686

Epoch: 5| Step: 8
Training loss: 2.6591396097615636
Validation loss: 2.4619592473081244

Epoch: 5| Step: 9
Training loss: 2.6272009750352785
Validation loss: 2.4606557311365225

Epoch: 5| Step: 10
Training loss: 2.1327705798378607
Validation loss: 2.4625635134062973

Epoch: 5| Step: 11
Training loss: 1.6244753944456727
Validation loss: 2.4616599722910903

Epoch: 121| Step: 0
Training loss: 2.246661464428562
Validation loss: 2.4582694531616363

Epoch: 5| Step: 1
Training loss: 3.069219418922619
Validation loss: 2.464650875551553

Epoch: 5| Step: 2
Training loss: 2.4593167250828962
Validation loss: 2.485039448204318

Epoch: 5| Step: 3
Training loss: 2.2989288282092666
Validation loss: 2.501150097152187

Epoch: 5| Step: 4
Training loss: 2.464663733242863
Validation loss: 2.507818212136233

Epoch: 5| Step: 5
Training loss: 2.8047345935831247
Validation loss: 2.5137802294319274

Epoch: 5| Step: 6
Training loss: 2.599711358114168
Validation loss: 2.522962271522052

Epoch: 5| Step: 7
Training loss: 2.8573774854506624
Validation loss: 2.4971675284483763

Epoch: 5| Step: 8
Training loss: 2.6883733350596355
Validation loss: 2.4951376519107367

Epoch: 5| Step: 9
Training loss: 2.570411935291665
Validation loss: 2.490664775280299

Epoch: 5| Step: 10
Training loss: 2.8006384053640514
Validation loss: 2.4762444557681174

Epoch: 5| Step: 11
Training loss: 2.0261969290295405
Validation loss: 2.4707838344333295

Epoch: 122| Step: 0
Training loss: 2.510086027244138
Validation loss: 2.4672996872368893

Epoch: 5| Step: 1
Training loss: 3.1778178048743704
Validation loss: 2.4626385617525024

Epoch: 5| Step: 2
Training loss: 2.2770189737460065
Validation loss: 2.467205715454452

Epoch: 5| Step: 3
Training loss: 2.5921624162321435
Validation loss: 2.4680467320159667

Epoch: 5| Step: 4
Training loss: 2.6028210227772726
Validation loss: 2.4710063079854843

Epoch: 5| Step: 5
Training loss: 2.8320571792994027
Validation loss: 2.475657332755828

Epoch: 5| Step: 6
Training loss: 2.293348654577545
Validation loss: 2.4781112441217905

Epoch: 5| Step: 7
Training loss: 2.3361249867603124
Validation loss: 2.4760085086958767

Epoch: 5| Step: 8
Training loss: 2.1442721962586626
Validation loss: 2.4779668410358178

Epoch: 5| Step: 9
Training loss: 2.802444453646046
Validation loss: 2.483017440573589

Epoch: 5| Step: 10
Training loss: 2.9065750104411205
Validation loss: 2.4805265725272228

Epoch: 5| Step: 11
Training loss: 1.4600540998965188
Validation loss: 2.483441783363236

Epoch: 123| Step: 0
Training loss: 2.539841940159594
Validation loss: 2.47956413133618

Epoch: 5| Step: 1
Training loss: 3.1171217220699283
Validation loss: 2.4746249227780552

Epoch: 5| Step: 2
Training loss: 1.8901475666102427
Validation loss: 2.477322811702679

Epoch: 5| Step: 3
Training loss: 2.525840913850775
Validation loss: 2.4765082232026

Epoch: 5| Step: 4
Training loss: 2.850276123858664
Validation loss: 2.4745863883564923

Epoch: 5| Step: 5
Training loss: 1.8424484702245376
Validation loss: 2.472733663639789

Epoch: 5| Step: 6
Training loss: 2.485890819751465
Validation loss: 2.469314975313129

Epoch: 5| Step: 7
Training loss: 2.784515435544381
Validation loss: 2.4725614813812835

Epoch: 5| Step: 8
Training loss: 2.7493810824192315
Validation loss: 2.4719423505928986

Epoch: 5| Step: 9
Training loss: 2.8282272573288556
Validation loss: 2.46938237810847

Epoch: 5| Step: 10
Training loss: 2.678165815614353
Validation loss: 2.4659403977566217

Epoch: 5| Step: 11
Training loss: 1.7830311085356132
Validation loss: 2.4653077935613794

Epoch: 124| Step: 0
Training loss: 2.456336379534332
Validation loss: 2.4652564080674755

Epoch: 5| Step: 1
Training loss: 2.076204832574431
Validation loss: 2.462194785617185

Epoch: 5| Step: 2
Training loss: 2.7570967569457268
Validation loss: 2.464088598325597

Epoch: 5| Step: 3
Training loss: 2.6857711198990666
Validation loss: 2.4620408869469586

Epoch: 5| Step: 4
Training loss: 2.788076188960628
Validation loss: 2.4593365462260546

Epoch: 5| Step: 5
Training loss: 2.2135551781335483
Validation loss: 2.4715785389307965

Epoch: 5| Step: 6
Training loss: 2.825873052673573
Validation loss: 2.4647702963353506

Epoch: 5| Step: 7
Training loss: 2.752095031328388
Validation loss: 2.4627818709544864

Epoch: 5| Step: 8
Training loss: 2.362151880198848
Validation loss: 2.462193218153067

Epoch: 5| Step: 9
Training loss: 3.0069207789366152
Validation loss: 2.4635384312958606

Epoch: 5| Step: 10
Training loss: 2.2835010239590696
Validation loss: 2.464874219025972

Epoch: 5| Step: 11
Training loss: 2.530037672041316
Validation loss: 2.4612874382727394

Epoch: 125| Step: 0
Training loss: 3.0376930583621
Validation loss: 2.4697241611552

Epoch: 5| Step: 1
Training loss: 1.7493348219858402
Validation loss: 2.4653516347922584

Epoch: 5| Step: 2
Training loss: 2.2573047317762858
Validation loss: 2.4651549677339637

Epoch: 5| Step: 3
Training loss: 2.9331802097004074
Validation loss: 2.463928157391213

Epoch: 5| Step: 4
Training loss: 2.691750381238699
Validation loss: 2.463818429047902

Epoch: 5| Step: 5
Training loss: 2.540889704616836
Validation loss: 2.463510252340301

Epoch: 5| Step: 6
Training loss: 2.9517499356305774
Validation loss: 2.4588616431171824

Epoch: 5| Step: 7
Training loss: 2.665155986207308
Validation loss: 2.46307426814675

Epoch: 5| Step: 8
Training loss: 2.3096699279851687
Validation loss: 2.4640014345757844

Epoch: 5| Step: 9
Training loss: 2.77481509099527
Validation loss: 2.4631479901758366

Epoch: 5| Step: 10
Training loss: 2.288205243401779
Validation loss: 2.4660795169978638

Epoch: 5| Step: 11
Training loss: 1.6958951168693377
Validation loss: 2.464654182685145

Epoch: 126| Step: 0
Training loss: 2.7077042264692706
Validation loss: 2.464659106093967

Epoch: 5| Step: 1
Training loss: 2.2194551233961204
Validation loss: 2.4626703610042266

Epoch: 5| Step: 2
Training loss: 2.5570153878964454
Validation loss: 2.4652099579152096

Epoch: 5| Step: 3
Training loss: 2.302597494805268
Validation loss: 2.45973407445855

Epoch: 5| Step: 4
Training loss: 2.8555806316787056
Validation loss: 2.46436076160213

Epoch: 5| Step: 5
Training loss: 2.4662267610563884
Validation loss: 2.46110237416993

Epoch: 5| Step: 6
Training loss: 2.909513384583546
Validation loss: 2.4637264857145027

Epoch: 5| Step: 7
Training loss: 3.1475495631623462
Validation loss: 2.458696073235832

Epoch: 5| Step: 8
Training loss: 2.1426207434728406
Validation loss: 2.4640520963608443

Epoch: 5| Step: 9
Training loss: 2.619388759160933
Validation loss: 2.459785914558265

Epoch: 5| Step: 10
Training loss: 1.9909361256307427
Validation loss: 2.461441646384298

Epoch: 5| Step: 11
Training loss: 2.967069612062499
Validation loss: 2.4602977910234634

Epoch: 127| Step: 0
Training loss: 2.652035949555431
Validation loss: 2.461251560738299

Epoch: 5| Step: 1
Training loss: 2.6531708766174495
Validation loss: 2.46316114609344

Epoch: 5| Step: 2
Training loss: 2.5698499640223065
Validation loss: 2.4596462192301547

Epoch: 5| Step: 3
Training loss: 2.3683649036934993
Validation loss: 2.457575743262447

Epoch: 5| Step: 4
Training loss: 2.0808452499021945
Validation loss: 2.4570855365652946

Epoch: 5| Step: 5
Training loss: 2.935850776175155
Validation loss: 2.4627916687767426

Epoch: 5| Step: 6
Training loss: 2.3252491438080414
Validation loss: 2.460601872561631

Epoch: 5| Step: 7
Training loss: 2.597861099770573
Validation loss: 2.4604200798116507

Epoch: 5| Step: 8
Training loss: 2.307298842534488
Validation loss: 2.4603112609749043

Epoch: 5| Step: 9
Training loss: 3.019766380166468
Validation loss: 2.464071776607051

Epoch: 5| Step: 10
Training loss: 2.223829660259329
Validation loss: 2.464567839046303

Epoch: 5| Step: 11
Training loss: 3.89442595221869
Validation loss: 2.467838263858416

Epoch: 128| Step: 0
Training loss: 2.207077917095114
Validation loss: 2.4667889737616555

Epoch: 5| Step: 1
Training loss: 2.9610737389295
Validation loss: 2.4630721628077517

Epoch: 5| Step: 2
Training loss: 2.453768700379263
Validation loss: 2.4621789354224686

Epoch: 5| Step: 3
Training loss: 2.3782044927517236
Validation loss: 2.465080471530764

Epoch: 5| Step: 4
Training loss: 2.5504160410753505
Validation loss: 2.460233666421486

Epoch: 5| Step: 5
Training loss: 2.502270049392241
Validation loss: 2.4644443089562333

Epoch: 5| Step: 6
Training loss: 2.4043198808302253
Validation loss: 2.454609359057571

Epoch: 5| Step: 7
Training loss: 2.44670021728809
Validation loss: 2.4619969343062524

Epoch: 5| Step: 8
Training loss: 2.3534817895000377
Validation loss: 2.4594769417535645

Epoch: 5| Step: 9
Training loss: 3.1040493390399475
Validation loss: 2.4590054956265894

Epoch: 5| Step: 10
Training loss: 2.670821400425796
Validation loss: 2.4615799363026314

Epoch: 5| Step: 11
Training loss: 2.794649229473334
Validation loss: 2.458537179501943

Epoch: 129| Step: 0
Training loss: 2.7383559539225906
Validation loss: 2.4550778458017755

Epoch: 5| Step: 1
Training loss: 2.2884270629061376
Validation loss: 2.4573071420421315

Epoch: 5| Step: 2
Training loss: 2.817369780353308
Validation loss: 2.4502193712776696

Epoch: 5| Step: 3
Training loss: 1.8907556409861372
Validation loss: 2.455530833504174

Epoch: 5| Step: 4
Training loss: 2.8899822448396257
Validation loss: 2.4596352961741967

Epoch: 5| Step: 5
Training loss: 2.4649101042846553
Validation loss: 2.457943029993576

Epoch: 5| Step: 6
Training loss: 2.703594718209368
Validation loss: 2.465330336835791

Epoch: 5| Step: 7
Training loss: 2.324169100703947
Validation loss: 2.4612179349131544

Epoch: 5| Step: 8
Training loss: 2.667520644618394
Validation loss: 2.4660846389756568

Epoch: 5| Step: 9
Training loss: 2.41044993288323
Validation loss: 2.47060077842254

Epoch: 5| Step: 10
Training loss: 2.671604165075705
Validation loss: 2.471775116893784

Epoch: 5| Step: 11
Training loss: 3.3448312027427196
Validation loss: 2.469009949080202

Epoch: 130| Step: 0
Training loss: 2.6053296556762437
Validation loss: 2.464558858473157

Epoch: 5| Step: 1
Training loss: 2.669532686120937
Validation loss: 2.467015671257743

Epoch: 5| Step: 2
Training loss: 2.231793172421076
Validation loss: 2.4704202924836793

Epoch: 5| Step: 3
Training loss: 2.431744358040904
Validation loss: 2.464059790684564

Epoch: 5| Step: 4
Training loss: 2.773515383204424
Validation loss: 2.46898089508142

Epoch: 5| Step: 5
Training loss: 2.5094366310693688
Validation loss: 2.462294645347723

Epoch: 5| Step: 6
Training loss: 2.2561314010093927
Validation loss: 2.46092945077377

Epoch: 5| Step: 7
Training loss: 2.59442424053827
Validation loss: 2.4655264600652806

Epoch: 5| Step: 8
Training loss: 2.9397927933939187
Validation loss: 2.4586600003096093

Epoch: 5| Step: 9
Training loss: 2.7846631313110053
Validation loss: 2.460244952246508

Epoch: 5| Step: 10
Training loss: 2.4090143153935886
Validation loss: 2.4645779683518776

Epoch: 5| Step: 11
Training loss: 2.1604418712336355
Validation loss: 2.459151319149743

Epoch: 131| Step: 0
Training loss: 2.63656150066397
Validation loss: 2.457204932870177

Epoch: 5| Step: 1
Training loss: 2.6694994622298043
Validation loss: 2.462787292232713

Epoch: 5| Step: 2
Training loss: 2.152465041493658
Validation loss: 2.457699816643419

Epoch: 5| Step: 3
Training loss: 3.0637718206754627
Validation loss: 2.4593743824745964

Epoch: 5| Step: 4
Training loss: 2.150930948309818
Validation loss: 2.4599403823694406

Epoch: 5| Step: 5
Training loss: 2.514803260555493
Validation loss: 2.456688218664908

Epoch: 5| Step: 6
Training loss: 2.287964853883779
Validation loss: 2.4587902894409557

Epoch: 5| Step: 7
Training loss: 2.645334141615134
Validation loss: 2.455733874017459

Epoch: 5| Step: 8
Training loss: 2.1177741219852715
Validation loss: 2.453292849036504

Epoch: 5| Step: 9
Training loss: 2.7891899528553323
Validation loss: 2.459364300405259

Epoch: 5| Step: 10
Training loss: 3.0355981532090364
Validation loss: 2.461272080701643

Epoch: 5| Step: 11
Training loss: 1.491437473839518
Validation loss: 2.4603948368220614

Epoch: 132| Step: 0
Training loss: 2.8748829029949405
Validation loss: 2.458479146889518

Epoch: 5| Step: 1
Training loss: 2.2722890778239995
Validation loss: 2.457621157393192

Epoch: 5| Step: 2
Training loss: 2.0234340829709927
Validation loss: 2.456865419291342

Epoch: 5| Step: 3
Training loss: 2.2278864621831396
Validation loss: 2.4525250715710474

Epoch: 5| Step: 4
Training loss: 2.6623245790387866
Validation loss: 2.459471791877971

Epoch: 5| Step: 5
Training loss: 2.8689368625526557
Validation loss: 2.4575568053017705

Epoch: 5| Step: 6
Training loss: 2.461420308541947
Validation loss: 2.46155119817752

Epoch: 5| Step: 7
Training loss: 2.6800134755265517
Validation loss: 2.4609655146543257

Epoch: 5| Step: 8
Training loss: 2.471969050994512
Validation loss: 2.467960839149683

Epoch: 5| Step: 9
Training loss: 3.054824084572319
Validation loss: 2.4641468898825423

Epoch: 5| Step: 10
Training loss: 2.21309370706622
Validation loss: 2.4670268857898283

Epoch: 5| Step: 11
Training loss: 3.074318172878074
Validation loss: 2.458858592821202

Epoch: 133| Step: 0
Training loss: 2.5204234354823036
Validation loss: 2.46183879837622

Epoch: 5| Step: 1
Training loss: 2.3733380174412027
Validation loss: 2.4599277261387855

Epoch: 5| Step: 2
Training loss: 2.705586189455172
Validation loss: 2.4585766523712396

Epoch: 5| Step: 3
Training loss: 2.597270277216797
Validation loss: 2.4688826215508337

Epoch: 5| Step: 4
Training loss: 2.9851935896725803
Validation loss: 2.4616873754182556

Epoch: 5| Step: 5
Training loss: 2.2285625910845743
Validation loss: 2.4659732824032217

Epoch: 5| Step: 6
Training loss: 2.6694212236915007
Validation loss: 2.4615435222446096

Epoch: 5| Step: 7
Training loss: 2.706012484587228
Validation loss: 2.464533303162261

Epoch: 5| Step: 8
Training loss: 2.795806851287662
Validation loss: 2.4652824636125286

Epoch: 5| Step: 9
Training loss: 2.3623883538886283
Validation loss: 2.4623323110747273

Epoch: 5| Step: 10
Training loss: 2.1096582293213886
Validation loss: 2.462226175036033

Epoch: 5| Step: 11
Training loss: 2.211059566942812
Validation loss: 2.462610255514726

Epoch: 134| Step: 0
Training loss: 2.2622084540418848
Validation loss: 2.4643408599353993

Epoch: 5| Step: 1
Training loss: 2.1723988950883544
Validation loss: 2.457964721350472

Epoch: 5| Step: 2
Training loss: 2.7325937627426757
Validation loss: 2.459791255609605

Epoch: 5| Step: 3
Training loss: 1.993227160070436
Validation loss: 2.4574693209433227

Epoch: 5| Step: 4
Training loss: 2.6700406386465216
Validation loss: 2.4574663234917926

Epoch: 5| Step: 5
Training loss: 2.3155128853409943
Validation loss: 2.458666889277377

Epoch: 5| Step: 6
Training loss: 2.5774773911410476
Validation loss: 2.4554383431668962

Epoch: 5| Step: 7
Training loss: 2.2477875534279166
Validation loss: 2.4627491615158967

Epoch: 5| Step: 8
Training loss: 3.2188717717219
Validation loss: 2.4611042955175977

Epoch: 5| Step: 9
Training loss: 2.6211688831095445
Validation loss: 2.4609135379331097

Epoch: 5| Step: 10
Training loss: 2.795239700384384
Validation loss: 2.458278179897007

Epoch: 5| Step: 11
Training loss: 3.2189246565458847
Validation loss: 2.4570974513901045

Epoch: 135| Step: 0
Training loss: 2.7615536825227713
Validation loss: 2.4580355210599705

Epoch: 5| Step: 1
Training loss: 2.1322746297295136
Validation loss: 2.461847117006972

Epoch: 5| Step: 2
Training loss: 2.682850652922188
Validation loss: 2.4621312026619235

Epoch: 5| Step: 3
Training loss: 2.8527304569798853
Validation loss: 2.458177086072762

Epoch: 5| Step: 4
Training loss: 2.380927769442921
Validation loss: 2.4587166912936635

Epoch: 5| Step: 5
Training loss: 2.508027539882309
Validation loss: 2.461362860516809

Epoch: 5| Step: 6
Training loss: 2.215877016097683
Validation loss: 2.459939146633132

Epoch: 5| Step: 7
Training loss: 2.8828247400866505
Validation loss: 2.4613032437570204

Epoch: 5| Step: 8
Training loss: 2.2405737409487667
Validation loss: 2.4647730571848343

Epoch: 5| Step: 9
Training loss: 2.167161836039013
Validation loss: 2.462642422218889

Epoch: 5| Step: 10
Training loss: 3.210929926285548
Validation loss: 2.464021000324176

Epoch: 5| Step: 11
Training loss: 1.402816905156878
Validation loss: 2.463889943533233

Epoch: 136| Step: 0
Training loss: 2.9227796163986017
Validation loss: 2.4696478438336067

Epoch: 5| Step: 1
Training loss: 2.419200971489161
Validation loss: 2.4614669189970653

Epoch: 5| Step: 2
Training loss: 2.8283837131590763
Validation loss: 2.462956253455984

Epoch: 5| Step: 3
Training loss: 2.3562620734353206
Validation loss: 2.4612549390367118

Epoch: 5| Step: 4
Training loss: 2.2778066488571054
Validation loss: 2.4588971878766794

Epoch: 5| Step: 5
Training loss: 2.9329088734810775
Validation loss: 2.455273620704185

Epoch: 5| Step: 6
Training loss: 2.4779645639368924
Validation loss: 2.456405022107664

Epoch: 5| Step: 7
Training loss: 2.52611406884534
Validation loss: 2.454735937678681

Epoch: 5| Step: 8
Training loss: 2.375622517163696
Validation loss: 2.453904645583875

Epoch: 5| Step: 9
Training loss: 2.4312845850350295
Validation loss: 2.4578573458477178

Epoch: 5| Step: 10
Training loss: 2.5602597934806393
Validation loss: 2.459022612573623

Epoch: 5| Step: 11
Training loss: 2.248103508124069
Validation loss: 2.45459168925234

Epoch: 137| Step: 0
Training loss: 2.4714215466740486
Validation loss: 2.460882123697498

Epoch: 5| Step: 1
Training loss: 2.3065831551106997
Validation loss: 2.458636173625336

Epoch: 5| Step: 2
Training loss: 2.8668174400896627
Validation loss: 2.4590376569668035

Epoch: 5| Step: 3
Training loss: 2.655622879497914
Validation loss: 2.4629563220239192

Epoch: 5| Step: 4
Training loss: 2.325950580003035
Validation loss: 2.457964656684889

Epoch: 5| Step: 5
Training loss: 2.6098965791696003
Validation loss: 2.464856421291469

Epoch: 5| Step: 6
Training loss: 2.1700288898988433
Validation loss: 2.4627008004462323

Epoch: 5| Step: 7
Training loss: 2.8482688799493268
Validation loss: 2.4631121357089243

Epoch: 5| Step: 8
Training loss: 2.7154540329682573
Validation loss: 2.4687984035269737

Epoch: 5| Step: 9
Training loss: 2.526718604762669
Validation loss: 2.465252019780472

Epoch: 5| Step: 10
Training loss: 2.4831598537023964
Validation loss: 2.4607864858321444

Epoch: 5| Step: 11
Training loss: 1.8241448397642657
Validation loss: 2.4561757962227024

Epoch: 138| Step: 0
Training loss: 2.6345297988535568
Validation loss: 2.4523006763140973

Epoch: 5| Step: 1
Training loss: 3.0642385413736872
Validation loss: 2.4508162565997242

Epoch: 5| Step: 2
Training loss: 2.5229049451342034
Validation loss: 2.461984090932612

Epoch: 5| Step: 3
Training loss: 2.8170175510627558
Validation loss: 2.4553172688735057

Epoch: 5| Step: 4
Training loss: 2.2702146148057967
Validation loss: 2.4567215546925136

Epoch: 5| Step: 5
Training loss: 2.4809235403694285
Validation loss: 2.4529988809226118

Epoch: 5| Step: 6
Training loss: 2.7717116452908868
Validation loss: 2.4538957433871356

Epoch: 5| Step: 7
Training loss: 2.163067861098285
Validation loss: 2.4502155966519035

Epoch: 5| Step: 8
Training loss: 2.166519698024625
Validation loss: 2.4586530022299193

Epoch: 5| Step: 9
Training loss: 2.504360020980422
Validation loss: 2.453801659078957

Epoch: 5| Step: 10
Training loss: 2.332947108683363
Validation loss: 2.4558664137242516

Epoch: 5| Step: 11
Training loss: 2.136617208296235
Validation loss: 2.457443724246952

Epoch: 139| Step: 0
Training loss: 2.5834976164561523
Validation loss: 2.453675493808611

Epoch: 5| Step: 1
Training loss: 2.2935885837729857
Validation loss: 2.4582634379800905

Epoch: 5| Step: 2
Training loss: 2.273407506581036
Validation loss: 2.4466989708044604

Epoch: 5| Step: 3
Training loss: 3.036450516356433
Validation loss: 2.4545020715133994

Epoch: 5| Step: 4
Training loss: 2.6935642930737016
Validation loss: 2.4569352924185335

Epoch: 5| Step: 5
Training loss: 2.613140199330105
Validation loss: 2.453820148306759

Epoch: 5| Step: 6
Training loss: 2.6850813694563906
Validation loss: 2.4554844218866636

Epoch: 5| Step: 7
Training loss: 2.4238291086445427
Validation loss: 2.4514592502523445

Epoch: 5| Step: 8
Training loss: 2.480767660077939
Validation loss: 2.4632273359898593

Epoch: 5| Step: 9
Training loss: 2.1725809610292
Validation loss: 2.4562646168151745

Epoch: 5| Step: 10
Training loss: 2.3902804057774074
Validation loss: 2.4555212170826026

Epoch: 5| Step: 11
Training loss: 3.009104582460303
Validation loss: 2.4566542473155177

Epoch: 140| Step: 0
Training loss: 2.30388893904833
Validation loss: 2.456469001988418

Epoch: 5| Step: 1
Training loss: 2.1894385331388198
Validation loss: 2.457013027525881

Epoch: 5| Step: 2
Training loss: 2.5494768391417706
Validation loss: 2.452731382373536

Epoch: 5| Step: 3
Training loss: 2.926675535056799
Validation loss: 2.4588942790272816

Epoch: 5| Step: 4
Training loss: 1.9329525896031605
Validation loss: 2.4593832082906304

Epoch: 5| Step: 5
Training loss: 2.7222188108340664
Validation loss: 2.4676404141480135

Epoch: 5| Step: 6
Training loss: 2.839160947294738
Validation loss: 2.4595608852248922

Epoch: 5| Step: 7
Training loss: 2.517612596132316
Validation loss: 2.4525725275087447

Epoch: 5| Step: 8
Training loss: 2.9336985888078457
Validation loss: 2.4634111234072327

Epoch: 5| Step: 9
Training loss: 2.8729881213188575
Validation loss: 2.463147356979992

Epoch: 5| Step: 10
Training loss: 1.912325323767088
Validation loss: 2.4670248240915247

Epoch: 5| Step: 11
Training loss: 2.599588922868693
Validation loss: 2.473045033307741

Epoch: 141| Step: 0
Training loss: 2.5581201479017897
Validation loss: 2.4734258915332976

Epoch: 5| Step: 1
Training loss: 2.4870978255533234
Validation loss: 2.4777324813024846

Epoch: 5| Step: 2
Training loss: 2.8842930080543194
Validation loss: 2.4789768929068194

Epoch: 5| Step: 3
Training loss: 2.0839310615105333
Validation loss: 2.478891735433153

Epoch: 5| Step: 4
Training loss: 2.90277745329527
Validation loss: 2.4694344782893385

Epoch: 5| Step: 5
Training loss: 2.364200835583327
Validation loss: 2.4794633705174363

Epoch: 5| Step: 6
Training loss: 2.5016777131177506
Validation loss: 2.472356616402214

Epoch: 5| Step: 7
Training loss: 2.720351350475107
Validation loss: 2.470506952310598

Epoch: 5| Step: 8
Training loss: 2.517575283951558
Validation loss: 2.466461331986228

Epoch: 5| Step: 9
Training loss: 2.9819015718586237
Validation loss: 2.46622830380259

Epoch: 5| Step: 10
Training loss: 1.74870838456608
Validation loss: 2.4636181556704266

Epoch: 5| Step: 11
Training loss: 3.3785133442080983
Validation loss: 2.4630636829518995

Epoch: 142| Step: 0
Training loss: 2.449128801802262
Validation loss: 2.459038093268992

Epoch: 5| Step: 1
Training loss: 1.8538189751312728
Validation loss: 2.462239456916428

Epoch: 5| Step: 2
Training loss: 2.5499376476368862
Validation loss: 2.459779993953963

Epoch: 5| Step: 3
Training loss: 3.147663182156055
Validation loss: 2.4851498904841884

Epoch: 5| Step: 4
Training loss: 2.655594150133293
Validation loss: 2.494640749280196

Epoch: 5| Step: 5
Training loss: 2.5882346100984783
Validation loss: 2.4904345383326487

Epoch: 5| Step: 6
Training loss: 2.7160170400531602
Validation loss: 2.4807700026794715

Epoch: 5| Step: 7
Training loss: 2.302229161771644
Validation loss: 2.4854271658019873

Epoch: 5| Step: 8
Training loss: 2.301160382831546
Validation loss: 2.48747330128896

Epoch: 5| Step: 9
Training loss: 2.7931049020299787
Validation loss: 2.4722938854627285

Epoch: 5| Step: 10
Training loss: 2.7756649904520523
Validation loss: 2.462055281437708

Epoch: 5| Step: 11
Training loss: 2.6846195131791006
Validation loss: 2.4560839672125554

Epoch: 143| Step: 0
Training loss: 2.6134619771506076
Validation loss: 2.4577056553553263

Epoch: 5| Step: 1
Training loss: 1.8968527501920793
Validation loss: 2.4611850997455997

Epoch: 5| Step: 2
Training loss: 2.6929477213853867
Validation loss: 2.4647159936263177

Epoch: 5| Step: 3
Training loss: 2.7425566422099616
Validation loss: 2.4671060585333002

Epoch: 5| Step: 4
Training loss: 2.6348300527241375
Validation loss: 2.4749452141757375

Epoch: 5| Step: 5
Training loss: 2.6697198753711335
Validation loss: 2.475121786030411

Epoch: 5| Step: 6
Training loss: 2.4625074434894043
Validation loss: 2.4729170096787363

Epoch: 5| Step: 7
Training loss: 2.5836051264703603
Validation loss: 2.477976608884494

Epoch: 5| Step: 8
Training loss: 2.4279169334706943
Validation loss: 2.4754816458439084

Epoch: 5| Step: 9
Training loss: 2.5904628652308714
Validation loss: 2.4706936440267078

Epoch: 5| Step: 10
Training loss: 2.8105891200026107
Validation loss: 2.473230489107552

Epoch: 5| Step: 11
Training loss: 2.5448332483488687
Validation loss: 2.472320353034393

Epoch: 144| Step: 0
Training loss: 2.0184437758671083
Validation loss: 2.4716714883741426

Epoch: 5| Step: 1
Training loss: 2.762254805924682
Validation loss: 2.471872801203017

Epoch: 5| Step: 2
Training loss: 2.777601442038254
Validation loss: 2.471195482492995

Epoch: 5| Step: 3
Training loss: 2.918820666615595
Validation loss: 2.470513506663205

Epoch: 5| Step: 4
Training loss: 2.5440386559170625
Validation loss: 2.471219927750006

Epoch: 5| Step: 5
Training loss: 2.054142520703305
Validation loss: 2.469325457273639

Epoch: 5| Step: 6
Training loss: 2.692894511670048
Validation loss: 2.471097413618226

Epoch: 5| Step: 7
Training loss: 2.8536434575768554
Validation loss: 2.469213031853182

Epoch: 5| Step: 8
Training loss: 2.7240659110207757
Validation loss: 2.467540452709943

Epoch: 5| Step: 9
Training loss: 2.5197562656909436
Validation loss: 2.4702378429220118

Epoch: 5| Step: 10
Training loss: 2.113221342186037
Validation loss: 2.460958325333253

Epoch: 5| Step: 11
Training loss: 2.5616324281938017
Validation loss: 2.463833307070335

Epoch: 145| Step: 0
Training loss: 2.5615418666535867
Validation loss: 2.4578760026123536

Epoch: 5| Step: 1
Training loss: 2.8179724117685696
Validation loss: 2.4545755532013573

Epoch: 5| Step: 2
Training loss: 2.744660482342047
Validation loss: 2.458132110593178

Epoch: 5| Step: 3
Training loss: 2.3413023311145387
Validation loss: 2.445485211530381

Epoch: 5| Step: 4
Training loss: 2.6432843783520696
Validation loss: 2.4512401231887413

Epoch: 5| Step: 5
Training loss: 2.626538053145776
Validation loss: 2.4436009341253704

Epoch: 5| Step: 6
Training loss: 2.2570049597297364
Validation loss: 2.4492978251061555

Epoch: 5| Step: 7
Training loss: 2.1457124941482597
Validation loss: 2.4518348030427526

Epoch: 5| Step: 8
Training loss: 2.266645846084263
Validation loss: 2.4456470370353895

Epoch: 5| Step: 9
Training loss: 2.342870928893251
Validation loss: 2.459920614552399

Epoch: 5| Step: 10
Training loss: 3.0749138672713574
Validation loss: 2.4587558825005047

Epoch: 5| Step: 11
Training loss: 0.6529380238668671
Validation loss: 2.456949868443911

Epoch: 146| Step: 0
Training loss: 2.2586804473926447
Validation loss: 2.4596102531334685

Epoch: 5| Step: 1
Training loss: 2.106905473541344
Validation loss: 2.457257093148882

Epoch: 5| Step: 2
Training loss: 2.4470781770540673
Validation loss: 2.4638379760897484

Epoch: 5| Step: 3
Training loss: 2.630234540047092
Validation loss: 2.4571978861750057

Epoch: 5| Step: 4
Training loss: 2.6234676793301164
Validation loss: 2.4536568374943055

Epoch: 5| Step: 5
Training loss: 2.4164682394537733
Validation loss: 2.4544872826328175

Epoch: 5| Step: 6
Training loss: 2.796603823680565
Validation loss: 2.4638674717501168

Epoch: 5| Step: 7
Training loss: 2.539981523131202
Validation loss: 2.459473183355224

Epoch: 5| Step: 8
Training loss: 2.5186449014777748
Validation loss: 2.4702781301669483

Epoch: 5| Step: 9
Training loss: 3.008120989151862
Validation loss: 2.4662488588903115

Epoch: 5| Step: 10
Training loss: 2.1715679363293026
Validation loss: 2.4763049885297543

Epoch: 5| Step: 11
Training loss: 3.443957003760355
Validation loss: 2.4682940693844144

Epoch: 147| Step: 0
Training loss: 3.1373840614570083
Validation loss: 2.470273642221294

Epoch: 5| Step: 1
Training loss: 2.5010911467674415
Validation loss: 2.4759843795326777

Epoch: 5| Step: 2
Training loss: 2.6740088614214974
Validation loss: 2.467234697750124

Epoch: 5| Step: 3
Training loss: 2.2643882796140047
Validation loss: 2.467374933752061

Epoch: 5| Step: 4
Training loss: 2.590684665043472
Validation loss: 2.4680835653294793

Epoch: 5| Step: 5
Training loss: 2.460586086795877
Validation loss: 2.4649263822525556

Epoch: 5| Step: 6
Training loss: 2.719768289626043
Validation loss: 2.4602000751389603

Epoch: 5| Step: 7
Training loss: 2.1264905750631766
Validation loss: 2.463082516057099

Epoch: 5| Step: 8
Training loss: 2.560793983297004
Validation loss: 2.4646384047360894

Epoch: 5| Step: 9
Training loss: 2.2327066875609622
Validation loss: 2.459961494787985

Epoch: 5| Step: 10
Training loss: 2.6483284806850653
Validation loss: 2.4550600943943937

Epoch: 5| Step: 11
Training loss: 1.639559081632155
Validation loss: 2.453170658504679

Epoch: 148| Step: 0
Training loss: 2.5453922191334
Validation loss: 2.4621627462102773

Epoch: 5| Step: 1
Training loss: 2.3540269478265854
Validation loss: 2.4746057038153255

Epoch: 5| Step: 2
Training loss: 3.265705162415111
Validation loss: 2.50933916597604

Epoch: 5| Step: 3
Training loss: 2.453700101464571
Validation loss: 2.488763763419055

Epoch: 5| Step: 4
Training loss: 2.294087801389611
Validation loss: 2.478256292180391

Epoch: 5| Step: 5
Training loss: 2.7959113991797
Validation loss: 2.476608075385411

Epoch: 5| Step: 6
Training loss: 2.6117120202400304
Validation loss: 2.4708411699613566

Epoch: 5| Step: 7
Training loss: 2.1595109248131177
Validation loss: 2.456103778042628

Epoch: 5| Step: 8
Training loss: 2.594765521795398
Validation loss: 2.463246690108631

Epoch: 5| Step: 9
Training loss: 2.3303705433260307
Validation loss: 2.473988130624249

Epoch: 5| Step: 10
Training loss: 2.635962257653397
Validation loss: 2.476461137688881

Epoch: 5| Step: 11
Training loss: 2.470877587713887
Validation loss: 2.472008297328645

Epoch: 149| Step: 0
Training loss: 2.1089565285859573
Validation loss: 2.4692707679446526

Epoch: 5| Step: 1
Training loss: 2.2466717581686555
Validation loss: 2.474891875294223

Epoch: 5| Step: 2
Training loss: 2.317822182820135
Validation loss: 2.475838648671501

Epoch: 5| Step: 3
Training loss: 1.8999098103851288
Validation loss: 2.469396880662857

Epoch: 5| Step: 4
Training loss: 2.4188405377301234
Validation loss: 2.4690644027804987

Epoch: 5| Step: 5
Training loss: 2.703172098973256
Validation loss: 2.466232778969532

Epoch: 5| Step: 6
Training loss: 2.69902653982789
Validation loss: 2.468201600501946

Epoch: 5| Step: 7
Training loss: 2.7475693104048378
Validation loss: 2.4680400946354744

Epoch: 5| Step: 8
Training loss: 2.7696228442628956
Validation loss: 2.4613497091135095

Epoch: 5| Step: 9
Training loss: 3.480789049953806
Validation loss: 2.4546912107676353

Epoch: 5| Step: 10
Training loss: 2.6024937151595715
Validation loss: 2.4509597139374466

Epoch: 5| Step: 11
Training loss: 1.8644156211854983
Validation loss: 2.4539700366740034

Epoch: 150| Step: 0
Training loss: 2.0741841516285247
Validation loss: 2.4517275926262228

Epoch: 5| Step: 1
Training loss: 3.51441100458775
Validation loss: 2.4477955497376573

Epoch: 5| Step: 2
Training loss: 1.9462313645878835
Validation loss: 2.4513912351006892

Epoch: 5| Step: 3
Training loss: 2.529445994337306
Validation loss: 2.4557537726217613

Epoch: 5| Step: 4
Training loss: 2.883179349223707
Validation loss: 2.46434666074163

Epoch: 5| Step: 5
Training loss: 2.312195938327991
Validation loss: 2.4680022624333633

Epoch: 5| Step: 6
Training loss: 2.377609325346237
Validation loss: 2.4689418581359597

Epoch: 5| Step: 7
Training loss: 2.6271084991225826
Validation loss: 2.4682120087067405

Epoch: 5| Step: 8
Training loss: 2.6080036328705836
Validation loss: 2.4543699883549954

Epoch: 5| Step: 9
Training loss: 2.3970209467692367
Validation loss: 2.460136444667847

Epoch: 5| Step: 10
Training loss: 2.391068261633953
Validation loss: 2.4618103417076664

Epoch: 5| Step: 11
Training loss: 2.5025231979773523
Validation loss: 2.4548422397377974

Testing loss: 1.9978547958391977
