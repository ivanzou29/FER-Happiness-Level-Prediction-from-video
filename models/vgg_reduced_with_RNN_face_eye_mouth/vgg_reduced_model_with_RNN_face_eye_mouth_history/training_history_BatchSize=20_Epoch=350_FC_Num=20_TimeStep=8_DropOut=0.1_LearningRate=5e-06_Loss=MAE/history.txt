Epoch: 1| Step: 0
Training loss: 4.6436381340026855
Validation loss: 5.279844601949056

Epoch: 5| Step: 1
Training loss: 5.211306571960449
Validation loss: 5.277701695760091

Epoch: 5| Step: 2
Training loss: 5.259520530700684
Validation loss: 5.275717496871948

Epoch: 5| Step: 3
Training loss: 5.091231346130371
Validation loss: 5.273611108462016

Epoch: 5| Step: 4
Training loss: 5.09527587890625
Validation loss: 5.271623492240906

Epoch: 5| Step: 5
Training loss: 4.988452911376953
Validation loss: 5.269591550032298

Epoch: 5| Step: 6
Training loss: 4.691396713256836
Validation loss: 5.267616093158722

Epoch: 5| Step: 7
Training loss: 6.274153232574463
Validation loss: 5.265651722749074

Epoch: 5| Step: 8
Training loss: 5.98699426651001
Validation loss: 5.263523558775584

Epoch: 5| Step: 9
Training loss: 6.673574924468994
Validation loss: 5.2615682284037275

Epoch: 5| Step: 10
Training loss: 4.774460792541504
Validation loss: 5.259521027406056

Epoch: 5| Step: 11
Training loss: 5.518004417419434
Validation loss: 5.257309257984161

Epoch: 2| Step: 0
Training loss: 5.394698143005371
Validation loss: 5.255152265230815

Epoch: 5| Step: 1
Training loss: 5.324002742767334
Validation loss: 5.252848585446675

Epoch: 5| Step: 2
Training loss: 5.218971252441406
Validation loss: 5.250425338745117

Epoch: 5| Step: 3
Training loss: 5.661634922027588
Validation loss: 5.247919778029124

Epoch: 5| Step: 4
Training loss: 5.565947532653809
Validation loss: 5.245318611462911

Epoch: 5| Step: 5
Training loss: 5.584628105163574
Validation loss: 5.2425399621327715

Epoch: 5| Step: 6
Training loss: 5.621134281158447
Validation loss: 5.239646156628926

Epoch: 5| Step: 7
Training loss: 4.233933448791504
Validation loss: 5.236557106177012

Epoch: 5| Step: 8
Training loss: 4.882798194885254
Validation loss: 5.2332605719566345

Epoch: 5| Step: 9
Training loss: 4.7826828956604
Validation loss: 5.230178693930308

Epoch: 5| Step: 10
Training loss: 5.771329402923584
Validation loss: 5.226664106051127

Epoch: 5| Step: 11
Training loss: 7.212162971496582
Validation loss: 5.222757677237193

Epoch: 3| Step: 0
Training loss: 5.2414445877075195
Validation loss: 5.218948761622111

Epoch: 5| Step: 1
Training loss: 4.794532775878906
Validation loss: 5.2147654096285505

Epoch: 5| Step: 2
Training loss: 5.215860843658447
Validation loss: 5.210605472326279

Epoch: 5| Step: 3
Training loss: 4.767228126525879
Validation loss: 5.205945193767548

Epoch: 5| Step: 4
Training loss: 6.415896415710449
Validation loss: 5.201056400934855

Epoch: 5| Step: 5
Training loss: 5.8415703773498535
Validation loss: 5.196076254049937

Epoch: 5| Step: 6
Training loss: 5.402129173278809
Validation loss: 5.190748810768127

Epoch: 5| Step: 7
Training loss: 6.78262186050415
Validation loss: 5.185223460197449

Epoch: 5| Step: 8
Training loss: 4.355084419250488
Validation loss: 5.179359058539073

Epoch: 5| Step: 9
Training loss: 4.2500152587890625
Validation loss: 5.172821601231893

Epoch: 5| Step: 10
Training loss: 5.296839714050293
Validation loss: 5.166792035102844

Epoch: 5| Step: 11
Training loss: 2.974471092224121
Validation loss: 5.159570058186849

Epoch: 4| Step: 0
Training loss: 6.59995174407959
Validation loss: 5.152646481990814

Epoch: 5| Step: 1
Training loss: 4.714303016662598
Validation loss: 5.14531131585439

Epoch: 5| Step: 2
Training loss: 5.086352348327637
Validation loss: 5.137547334035237

Epoch: 5| Step: 3
Training loss: 4.889637470245361
Validation loss: 5.129598776499431

Epoch: 5| Step: 4
Training loss: 4.892935752868652
Validation loss: 5.121324102083842

Epoch: 5| Step: 5
Training loss: 5.321841239929199
Validation loss: 5.112735132376353

Epoch: 5| Step: 6
Training loss: 4.894898414611816
Validation loss: 5.104247510433197

Epoch: 5| Step: 7
Training loss: 4.1476263999938965
Validation loss: 5.095117410024007

Epoch: 5| Step: 8
Training loss: 6.127108097076416
Validation loss: 5.086193998654683

Epoch: 5| Step: 9
Training loss: 5.129514694213867
Validation loss: 5.076706767082214

Epoch: 5| Step: 10
Training loss: 5.111134052276611
Validation loss: 5.0674110651016235

Epoch: 5| Step: 11
Training loss: 5.807821273803711
Validation loss: 5.057513654232025

Epoch: 5| Step: 0
Training loss: 4.394017696380615
Validation loss: 5.047832469145457

Epoch: 5| Step: 1
Training loss: 5.6324782371521
Validation loss: 5.037946303685506

Epoch: 5| Step: 2
Training loss: 5.306535720825195
Validation loss: 5.027763326962789

Epoch: 5| Step: 3
Training loss: 4.149012088775635
Validation loss: 5.017734984556834

Epoch: 5| Step: 4
Training loss: 4.196866035461426
Validation loss: 5.00725523630778

Epoch: 5| Step: 5
Training loss: 5.4125165939331055
Validation loss: 4.99666612346967

Epoch: 5| Step: 6
Training loss: 4.685528755187988
Validation loss: 4.9860188364982605

Epoch: 5| Step: 7
Training loss: 5.654038906097412
Validation loss: 4.974834601084392

Epoch: 5| Step: 8
Training loss: 6.20782470703125
Validation loss: 4.963973979155223

Epoch: 5| Step: 9
Training loss: 4.47977352142334
Validation loss: 4.952696323394775

Epoch: 5| Step: 10
Training loss: 5.526594161987305
Validation loss: 4.941062490145366

Epoch: 5| Step: 11
Training loss: 5.878870964050293
Validation loss: 4.929594834645589

Epoch: 6| Step: 0
Training loss: 4.898571968078613
Validation loss: 4.918314715226491

Epoch: 5| Step: 1
Training loss: 4.8789849281311035
Validation loss: 4.90746549765269

Epoch: 5| Step: 2
Training loss: 4.99517297744751
Validation loss: 4.896358847618103

Epoch: 5| Step: 3
Training loss: 3.673460006713867
Validation loss: 4.885856866836548

Epoch: 5| Step: 4
Training loss: 4.589825630187988
Validation loss: 4.875292181968689

Epoch: 5| Step: 5
Training loss: 5.1506452560424805
Validation loss: 4.865002334117889

Epoch: 5| Step: 6
Training loss: 5.732670307159424
Validation loss: 4.855156242847443

Epoch: 5| Step: 7
Training loss: 4.2602949142456055
Validation loss: 4.845468143622081

Epoch: 5| Step: 8
Training loss: 5.742850303649902
Validation loss: 4.835884253184001

Epoch: 5| Step: 9
Training loss: 5.671151638031006
Validation loss: 4.826015929381053

Epoch: 5| Step: 10
Training loss: 5.270426273345947
Validation loss: 4.8166172703107195

Epoch: 5| Step: 11
Training loss: 2.8866610527038574
Validation loss: 4.807075262069702

Epoch: 7| Step: 0
Training loss: 4.888056755065918
Validation loss: 4.797921458880107

Epoch: 5| Step: 1
Training loss: 3.9146580696105957
Validation loss: 4.788649241129558

Epoch: 5| Step: 2
Training loss: 4.052745819091797
Validation loss: 4.779735366503398

Epoch: 5| Step: 3
Training loss: 5.923357963562012
Validation loss: 4.7706319491068525

Epoch: 5| Step: 4
Training loss: 5.438981056213379
Validation loss: 4.761363704999288

Epoch: 5| Step: 5
Training loss: 4.952284812927246
Validation loss: 4.752426524957021

Epoch: 5| Step: 6
Training loss: 5.240660667419434
Validation loss: 4.743340154488881

Epoch: 5| Step: 7
Training loss: 4.546966552734375
Validation loss: 4.734107315540314

Epoch: 5| Step: 8
Training loss: 4.42892599105835
Validation loss: 4.724559466044108

Epoch: 5| Step: 9
Training loss: 4.554574489593506
Validation loss: 4.715825915336609

Epoch: 5| Step: 10
Training loss: 5.000702381134033
Validation loss: 4.706841935714086

Epoch: 5| Step: 11
Training loss: 6.393868923187256
Validation loss: 4.698497881491979

Epoch: 8| Step: 0
Training loss: 4.5443434715271
Validation loss: 4.689909398555756

Epoch: 5| Step: 1
Training loss: 5.302490234375
Validation loss: 4.681969195604324

Epoch: 5| Step: 2
Training loss: 4.78376579284668
Validation loss: 4.673865934213002

Epoch: 5| Step: 3
Training loss: 4.778870582580566
Validation loss: 4.666242808103561

Epoch: 5| Step: 4
Training loss: 5.344988822937012
Validation loss: 4.65885317325592

Epoch: 5| Step: 5
Training loss: 5.151406288146973
Validation loss: 4.650824983914693

Epoch: 5| Step: 6
Training loss: 4.710258483886719
Validation loss: 4.643473704655965

Epoch: 5| Step: 7
Training loss: 4.8264641761779785
Validation loss: 4.636250933011373

Epoch: 5| Step: 8
Training loss: 4.02425479888916
Validation loss: 4.629346927007039

Epoch: 5| Step: 9
Training loss: 4.921950340270996
Validation loss: 4.622247536977132

Epoch: 5| Step: 10
Training loss: 4.190985202789307
Validation loss: 4.61547436316808

Epoch: 5| Step: 11
Training loss: 2.9461493492126465
Validation loss: 4.607839037974675

Epoch: 9| Step: 0
Training loss: 4.869322776794434
Validation loss: 4.601396322250366

Epoch: 5| Step: 1
Training loss: 5.0730485916137695
Validation loss: 4.595060070355733

Epoch: 5| Step: 2
Training loss: 4.681445598602295
Validation loss: 4.588609158992767

Epoch: 5| Step: 3
Training loss: 4.866879463195801
Validation loss: 4.581855257352193

Epoch: 5| Step: 4
Training loss: 4.139050483703613
Validation loss: 4.575228214263916

Epoch: 5| Step: 5
Training loss: 4.217504501342773
Validation loss: 4.56846010684967

Epoch: 5| Step: 6
Training loss: 4.240389823913574
Validation loss: 4.561922152837117

Epoch: 5| Step: 7
Training loss: 5.3488922119140625
Validation loss: 4.555408318837483

Epoch: 5| Step: 8
Training loss: 3.661125898361206
Validation loss: 4.54828021923701

Epoch: 5| Step: 9
Training loss: 4.638062953948975
Validation loss: 4.5418088634808855

Epoch: 5| Step: 10
Training loss: 5.479455947875977
Validation loss: 4.535021523634593

Epoch: 5| Step: 11
Training loss: 5.414283752441406
Validation loss: 4.528175314267476

Epoch: 10| Step: 0
Training loss: 4.664292812347412
Validation loss: 4.521222114562988

Epoch: 5| Step: 1
Training loss: 5.585202693939209
Validation loss: 4.514408310254415

Epoch: 5| Step: 2
Training loss: 4.433184623718262
Validation loss: 4.507475167512894

Epoch: 5| Step: 3
Training loss: 4.3845720291137695
Validation loss: 4.499907940626144

Epoch: 5| Step: 4
Training loss: 4.801955699920654
Validation loss: 4.492088337739308

Epoch: 5| Step: 5
Training loss: 4.147540092468262
Validation loss: 4.484914571046829

Epoch: 5| Step: 6
Training loss: 4.39919900894165
Validation loss: 4.477984180053075

Epoch: 5| Step: 7
Training loss: 4.405133247375488
Validation loss: 4.470780809720357

Epoch: 5| Step: 8
Training loss: 5.122805118560791
Validation loss: 4.463858654101689

Epoch: 5| Step: 9
Training loss: 4.444218635559082
Validation loss: 4.455930391947429

Epoch: 5| Step: 10
Training loss: 4.101560115814209
Validation loss: 4.449622611204783

Epoch: 5| Step: 11
Training loss: 4.783286094665527
Validation loss: 4.442318469285965

Epoch: 11| Step: 0
Training loss: 4.460536003112793
Validation loss: 4.435884435971578

Epoch: 5| Step: 1
Training loss: 4.779692649841309
Validation loss: 4.428080757459004

Epoch: 5| Step: 2
Training loss: 4.680049896240234
Validation loss: 4.421206037203471

Epoch: 5| Step: 3
Training loss: 4.0959930419921875
Validation loss: 4.414312680562337

Epoch: 5| Step: 4
Training loss: 3.9077439308166504
Validation loss: 4.408023029565811

Epoch: 5| Step: 5
Training loss: 3.9524471759796143
Validation loss: 4.400879452625911

Epoch: 5| Step: 6
Training loss: 4.064404487609863
Validation loss: 4.3944732050100965

Epoch: 5| Step: 7
Training loss: 4.1965436935424805
Validation loss: 4.387472967306773

Epoch: 5| Step: 8
Training loss: 4.9315266609191895
Validation loss: 4.381232778231303

Epoch: 5| Step: 9
Training loss: 5.451099395751953
Validation loss: 4.374831974506378

Epoch: 5| Step: 10
Training loss: 5.1213765144348145
Validation loss: 4.36826338370641

Epoch: 5| Step: 11
Training loss: 4.677607536315918
Validation loss: 4.362665404876073

Epoch: 12| Step: 0
Training loss: 3.4339728355407715
Validation loss: 4.356308152278264

Epoch: 5| Step: 1
Training loss: 5.4116597175598145
Validation loss: 4.350830306609471

Epoch: 5| Step: 2
Training loss: 3.727247714996338
Validation loss: 4.344742298126221

Epoch: 5| Step: 3
Training loss: 4.349859714508057
Validation loss: 4.338355014721553

Epoch: 5| Step: 4
Training loss: 4.6633124351501465
Validation loss: 4.332535554965337

Epoch: 5| Step: 5
Training loss: 5.077239036560059
Validation loss: 4.327187240123749

Epoch: 5| Step: 6
Training loss: 5.15848445892334
Validation loss: 4.322794844706853

Epoch: 5| Step: 7
Training loss: 3.4244894981384277
Validation loss: 4.316695908705394

Epoch: 5| Step: 8
Training loss: 4.043224811553955
Validation loss: 4.312388310829799

Epoch: 5| Step: 9
Training loss: 4.354067802429199
Validation loss: 4.303471624851227

Epoch: 5| Step: 10
Training loss: 5.183592319488525
Validation loss: 4.298930416504542

Epoch: 5| Step: 11
Training loss: 5.074361801147461
Validation loss: 4.2933396100997925

Epoch: 13| Step: 0
Training loss: 5.461943626403809
Validation loss: 4.287818411986033

Epoch: 5| Step: 1
Training loss: 3.7057526111602783
Validation loss: 4.281946778297424

Epoch: 5| Step: 2
Training loss: 5.071308135986328
Validation loss: 4.276077051957448

Epoch: 5| Step: 3
Training loss: 4.646397590637207
Validation loss: 4.271479745705922

Epoch: 5| Step: 4
Training loss: 3.231423854827881
Validation loss: 4.26598048210144

Epoch: 5| Step: 5
Training loss: 4.650304794311523
Validation loss: 4.259534825881322

Epoch: 5| Step: 6
Training loss: 3.9570860862731934
Validation loss: 4.255096028248469

Epoch: 5| Step: 7
Training loss: 4.333885669708252
Validation loss: 4.249119112888972

Epoch: 5| Step: 8
Training loss: 4.055288791656494
Validation loss: 4.243293344974518

Epoch: 5| Step: 9
Training loss: 4.5747389793396
Validation loss: 4.237951119740804

Epoch: 5| Step: 10
Training loss: 4.615653038024902
Validation loss: 4.23284528652827

Epoch: 5| Step: 11
Training loss: 4.198245048522949
Validation loss: 4.2275058428446455

Epoch: 14| Step: 0
Training loss: 5.11267614364624
Validation loss: 4.221934676170349

Epoch: 5| Step: 1
Training loss: 3.6890735626220703
Validation loss: 4.216249446074168

Epoch: 5| Step: 2
Training loss: 4.6988935470581055
Validation loss: 4.211029181877772

Epoch: 5| Step: 3
Training loss: 4.4186296463012695
Validation loss: 4.205599586168925

Epoch: 5| Step: 4
Training loss: 3.2799720764160156
Validation loss: 4.199700186649959

Epoch: 5| Step: 5
Training loss: 4.260172367095947
Validation loss: 4.1936591764291125

Epoch: 5| Step: 6
Training loss: 5.573744297027588
Validation loss: 4.18786899248759

Epoch: 5| Step: 7
Training loss: 4.266066074371338
Validation loss: 4.181964755058289

Epoch: 5| Step: 8
Training loss: 4.312005043029785
Validation loss: 4.176502863566081

Epoch: 5| Step: 9
Training loss: 2.8714606761932373
Validation loss: 4.171278794606526

Epoch: 5| Step: 10
Training loss: 5.046987533569336
Validation loss: 4.165986895561218

Epoch: 5| Step: 11
Training loss: 4.699576377868652
Validation loss: 4.160073866446813

Epoch: 15| Step: 0
Training loss: 3.1798107624053955
Validation loss: 4.153692384560903

Epoch: 5| Step: 1
Training loss: 5.193276882171631
Validation loss: 4.149924794832866

Epoch: 5| Step: 2
Training loss: 3.017066478729248
Validation loss: 4.142579168081284

Epoch: 5| Step: 3
Training loss: 4.725290775299072
Validation loss: 4.138574570417404

Epoch: 5| Step: 4
Training loss: 4.012180328369141
Validation loss: 4.1339149077733355

Epoch: 5| Step: 5
Training loss: 5.082497596740723
Validation loss: 4.128319501876831

Epoch: 5| Step: 6
Training loss: 4.589117527008057
Validation loss: 4.120718826850255

Epoch: 5| Step: 7
Training loss: 4.097073554992676
Validation loss: 4.115497529506683

Epoch: 5| Step: 8
Training loss: 3.937155246734619
Validation loss: 4.109582910935084

Epoch: 5| Step: 9
Training loss: 4.384751796722412
Validation loss: 4.103278021017711

Epoch: 5| Step: 10
Training loss: 4.5089521408081055
Validation loss: 4.097965757052104

Epoch: 5| Step: 11
Training loss: 5.270785808563232
Validation loss: 4.092537085215251

Epoch: 16| Step: 0
Training loss: 3.391824245452881
Validation loss: 4.0869008004665375

Epoch: 5| Step: 1
Training loss: 4.63773250579834
Validation loss: 4.080318242311478

Epoch: 5| Step: 2
Training loss: 4.791861057281494
Validation loss: 4.075216233730316

Epoch: 5| Step: 3
Training loss: 3.799436092376709
Validation loss: 4.070513774951299

Epoch: 5| Step: 4
Training loss: 4.174498081207275
Validation loss: 4.064140637715657

Epoch: 5| Step: 5
Training loss: 4.350972652435303
Validation loss: 4.058594713608424

Epoch: 5| Step: 6
Training loss: 4.138636589050293
Validation loss: 4.052538245916367

Epoch: 5| Step: 7
Training loss: 3.961106777191162
Validation loss: 4.046939750512441

Epoch: 5| Step: 8
Training loss: 4.148259162902832
Validation loss: 4.042066464821498

Epoch: 5| Step: 9
Training loss: 4.413419246673584
Validation loss: 4.035404096047084

Epoch: 5| Step: 10
Training loss: 4.415472030639648
Validation loss: 4.031037390232086

Epoch: 5| Step: 11
Training loss: 4.154073238372803
Validation loss: 4.027590324481328

Epoch: 17| Step: 0
Training loss: 3.6890854835510254
Validation loss: 4.019176542758942

Epoch: 5| Step: 1
Training loss: 4.081982612609863
Validation loss: 4.013675322135289

Epoch: 5| Step: 2
Training loss: 4.978837490081787
Validation loss: 4.009171416362126

Epoch: 5| Step: 3
Training loss: 4.569174289703369
Validation loss: 4.0041743616263075

Epoch: 5| Step: 4
Training loss: 3.6042568683624268
Validation loss: 3.9983205000559487

Epoch: 5| Step: 5
Training loss: 4.00626802444458
Validation loss: 3.9929117262363434

Epoch: 5| Step: 6
Training loss: 4.364256381988525
Validation loss: 3.988418618837992

Epoch: 5| Step: 7
Training loss: 3.929464817047119
Validation loss: 3.9828879733880362

Epoch: 5| Step: 8
Training loss: 3.875091552734375
Validation loss: 3.977500448624293

Epoch: 5| Step: 9
Training loss: 4.097760200500488
Validation loss: 3.972440759340922

Epoch: 5| Step: 10
Training loss: 4.4608235359191895
Validation loss: 3.966675798098246

Epoch: 5| Step: 11
Training loss: 3.470500946044922
Validation loss: 3.9609728952248893

Epoch: 18| Step: 0
Training loss: 5.200888633728027
Validation loss: 3.9583365519841514

Epoch: 5| Step: 1
Training loss: 4.166667938232422
Validation loss: 3.9518719911575317

Epoch: 5| Step: 2
Training loss: 3.928112745285034
Validation loss: 3.9457746545473733

Epoch: 5| Step: 3
Training loss: 4.55324649810791
Validation loss: 3.9401877323786416

Epoch: 5| Step: 4
Training loss: 4.108248710632324
Validation loss: 3.9355109532674155

Epoch: 5| Step: 5
Training loss: 4.335003852844238
Validation loss: 3.9302535553773246

Epoch: 5| Step: 6
Training loss: 4.175487041473389
Validation loss: 3.9245329002539315

Epoch: 5| Step: 7
Training loss: 4.203949928283691
Validation loss: 3.919689416885376

Epoch: 5| Step: 8
Training loss: 3.9376120567321777
Validation loss: 3.9152795573075614

Epoch: 5| Step: 9
Training loss: 3.051121234893799
Validation loss: 3.9090720613797507

Epoch: 5| Step: 10
Training loss: 3.495677947998047
Validation loss: 3.9043157597382865

Epoch: 5| Step: 11
Training loss: 2.6125478744506836
Validation loss: 3.899390459060669

Epoch: 19| Step: 0
Training loss: 3.505326747894287
Validation loss: 3.8949405948321023

Epoch: 5| Step: 1
Training loss: 4.486851215362549
Validation loss: 3.889762302239736

Epoch: 5| Step: 2
Training loss: 4.816409587860107
Validation loss: 3.8840088744958243

Epoch: 5| Step: 3
Training loss: 3.3208401203155518
Validation loss: 3.8796181082725525

Epoch: 5| Step: 4
Training loss: 3.59484601020813
Validation loss: 3.8751054406166077

Epoch: 5| Step: 5
Training loss: 4.3907599449157715
Validation loss: 3.8717181781927743

Epoch: 5| Step: 6
Training loss: 3.5756263732910156
Validation loss: 3.870147834221522

Epoch: 5| Step: 7
Training loss: 3.483424425125122
Validation loss: 3.86105677485466

Epoch: 5| Step: 8
Training loss: 5.764698028564453
Validation loss: 3.8546305696169534

Epoch: 5| Step: 9
Training loss: 4.347018241882324
Validation loss: 3.8493252098560333

Epoch: 5| Step: 10
Training loss: 2.894334316253662
Validation loss: 3.845055262247721

Epoch: 5| Step: 11
Training loss: 4.268969535827637
Validation loss: 3.840443789958954

Epoch: 20| Step: 0
Training loss: 4.42453670501709
Validation loss: 3.834803968667984

Epoch: 5| Step: 1
Training loss: 3.6210522651672363
Validation loss: 3.8298294444878898

Epoch: 5| Step: 2
Training loss: 3.805744171142578
Validation loss: 3.8242288728555045

Epoch: 5| Step: 3
Training loss: 3.889902114868164
Validation loss: 3.820507208506266

Epoch: 5| Step: 4
Training loss: 4.827951431274414
Validation loss: 3.8141887386639914

Epoch: 5| Step: 5
Training loss: 3.688535213470459
Validation loss: 3.809876243273417

Epoch: 5| Step: 6
Training loss: 4.063394069671631
Validation loss: 3.803715238968531

Epoch: 5| Step: 7
Training loss: 4.673132419586182
Validation loss: 3.7999328474203744

Epoch: 5| Step: 8
Training loss: 3.011514186859131
Validation loss: 3.794495165348053

Epoch: 5| Step: 9
Training loss: 3.695754289627075
Validation loss: 3.7896014153957367

Epoch: 5| Step: 10
Training loss: 3.8968303203582764
Validation loss: 3.784571965535482

Epoch: 5| Step: 11
Training loss: 4.043595314025879
Validation loss: 3.780007710059484

Epoch: 21| Step: 0
Training loss: 4.322486877441406
Validation loss: 3.777771681547165

Epoch: 5| Step: 1
Training loss: 3.574738025665283
Validation loss: 3.771680861711502

Epoch: 5| Step: 2
Training loss: 3.2653186321258545
Validation loss: 3.765798052151998

Epoch: 5| Step: 3
Training loss: 4.1764750480651855
Validation loss: 3.761902501185735

Epoch: 5| Step: 4
Training loss: 3.140669345855713
Validation loss: 3.7565961877504983

Epoch: 5| Step: 5
Training loss: 4.244037628173828
Validation loss: 3.752112011114756

Epoch: 5| Step: 6
Training loss: 3.874189853668213
Validation loss: 3.7467833956082663

Epoch: 5| Step: 7
Training loss: 3.8811306953430176
Validation loss: 3.742969334125519

Epoch: 5| Step: 8
Training loss: 3.669520854949951
Validation loss: 3.738005131483078

Epoch: 5| Step: 9
Training loss: 3.970301389694214
Validation loss: 3.7345545987288156

Epoch: 5| Step: 10
Training loss: 4.720522880554199
Validation loss: 3.7292586167653403

Epoch: 5| Step: 11
Training loss: 4.767682075500488
Validation loss: 3.723146398862203

Epoch: 22| Step: 0
Training loss: 4.3279523849487305
Validation loss: 3.7189336518446603

Epoch: 5| Step: 1
Training loss: 3.6212234497070312
Validation loss: 3.714383602142334

Epoch: 5| Step: 2
Training loss: 5.0580244064331055
Validation loss: 3.709536135196686

Epoch: 5| Step: 3
Training loss: 3.949470043182373
Validation loss: 3.705198456843694

Epoch: 5| Step: 4
Training loss: 3.1372668743133545
Validation loss: 3.6995221078395844

Epoch: 5| Step: 5
Training loss: 3.6819140911102295
Validation loss: 3.6945830384890237

Epoch: 5| Step: 6
Training loss: 3.708883285522461
Validation loss: 3.6891546746095023

Epoch: 5| Step: 7
Training loss: 3.4275596141815186
Validation loss: 3.684318244457245

Epoch: 5| Step: 8
Training loss: 3.851048231124878
Validation loss: 3.679245561361313

Epoch: 5| Step: 9
Training loss: 3.8109467029571533
Validation loss: 3.6724835137526193

Epoch: 5| Step: 10
Training loss: 3.6240997314453125
Validation loss: 3.6673619151115417

Epoch: 5| Step: 11
Training loss: 4.850208282470703
Validation loss: 3.670837849378586

Epoch: 23| Step: 0
Training loss: 4.191513538360596
Validation loss: 3.6568503081798553

Epoch: 5| Step: 1
Training loss: 3.9846725463867188
Validation loss: 3.6503901183605194

Epoch: 5| Step: 2
Training loss: 4.387281894683838
Validation loss: 3.6453132728735604

Epoch: 5| Step: 3
Training loss: 4.2561492919921875
Validation loss: 3.640357583761215

Epoch: 5| Step: 4
Training loss: 4.5157246589660645
Validation loss: 3.6345893939336142

Epoch: 5| Step: 5
Training loss: 3.1721136569976807
Validation loss: 3.628239721059799

Epoch: 5| Step: 6
Training loss: 3.810807704925537
Validation loss: 3.623189220825831

Epoch: 5| Step: 7
Training loss: 2.8072166442871094
Validation loss: 3.618791162967682

Epoch: 5| Step: 8
Training loss: 3.365626811981201
Validation loss: 3.6131809254487357

Epoch: 5| Step: 9
Training loss: 3.245197296142578
Validation loss: 3.608341713746389

Epoch: 5| Step: 10
Training loss: 3.783491611480713
Validation loss: 3.602796028057734

Epoch: 5| Step: 11
Training loss: 4.728060722351074
Validation loss: 3.596642623345057

Epoch: 24| Step: 0
Training loss: 3.6286659240722656
Validation loss: 3.591311921676

Epoch: 5| Step: 1
Training loss: 3.4225735664367676
Validation loss: 3.586210439602534

Epoch: 5| Step: 2
Training loss: 4.1083784103393555
Validation loss: 3.5826908548672995

Epoch: 5| Step: 3
Training loss: 3.321951389312744
Validation loss: 3.5758690536022186

Epoch: 5| Step: 4
Training loss: 3.79927396774292
Validation loss: 3.5717801054318747

Epoch: 5| Step: 5
Training loss: 4.346153259277344
Validation loss: 3.5654310286045074

Epoch: 5| Step: 6
Training loss: 3.49943470954895
Validation loss: 3.558498442173004

Epoch: 5| Step: 7
Training loss: 3.4225916862487793
Validation loss: 3.5535079737504325

Epoch: 5| Step: 8
Training loss: 4.731381416320801
Validation loss: 3.547736515601476

Epoch: 5| Step: 9
Training loss: 3.3598124980926514
Validation loss: 3.5418094098567963

Epoch: 5| Step: 10
Training loss: 3.258056163787842
Validation loss: 3.537200619777044

Epoch: 5| Step: 11
Training loss: 4.24021053314209
Validation loss: 3.530969431002935

Epoch: 25| Step: 0
Training loss: 4.638885974884033
Validation loss: 3.5252683957417807

Epoch: 5| Step: 1
Training loss: 3.7072997093200684
Validation loss: 3.519528100887934

Epoch: 5| Step: 2
Training loss: 4.273855686187744
Validation loss: 3.514772891998291

Epoch: 5| Step: 3
Training loss: 4.243727207183838
Validation loss: 3.509303331375122

Epoch: 5| Step: 4
Training loss: 4.171847343444824
Validation loss: 3.503414382537206

Epoch: 5| Step: 5
Training loss: 3.388780117034912
Validation loss: 3.497679760058721

Epoch: 5| Step: 6
Training loss: 3.32989501953125
Validation loss: 3.4924637774626413

Epoch: 5| Step: 7
Training loss: 3.228163480758667
Validation loss: 3.487177550792694

Epoch: 5| Step: 8
Training loss: 3.7904052734375
Validation loss: 3.4863099455833435

Epoch: 5| Step: 9
Training loss: 3.20973539352417
Validation loss: 3.476209670305252

Epoch: 5| Step: 10
Training loss: 2.4753081798553467
Validation loss: 3.472217172384262

Epoch: 5| Step: 11
Training loss: 2.922161340713501
Validation loss: 3.4691357811292014

Epoch: 26| Step: 0
Training loss: 4.24839973449707
Validation loss: 3.4657845894495645

Epoch: 5| Step: 1
Training loss: 2.8388564586639404
Validation loss: 3.4611753722031913

Epoch: 5| Step: 2
Training loss: 4.008309841156006
Validation loss: 3.4549968242645264

Epoch: 5| Step: 3
Training loss: 4.5559282302856445
Validation loss: 3.449062615633011

Epoch: 5| Step: 4
Training loss: 3.2260773181915283
Validation loss: 3.4434296091397605

Epoch: 5| Step: 5
Training loss: 3.181260585784912
Validation loss: 3.4382258653640747

Epoch: 5| Step: 6
Training loss: 4.14265775680542
Validation loss: 3.4344960749149323

Epoch: 5| Step: 7
Training loss: 2.990277051925659
Validation loss: 3.4288134972254434

Epoch: 5| Step: 8
Training loss: 2.8689160346984863
Validation loss: 3.423355350891749

Epoch: 5| Step: 9
Training loss: 4.078015327453613
Validation loss: 3.417993406454722

Epoch: 5| Step: 10
Training loss: 3.486386775970459
Validation loss: 3.4132183690865836

Epoch: 5| Step: 11
Training loss: 3.76956844329834
Validation loss: 3.408535361289978

Epoch: 27| Step: 0
Training loss: 3.8985068798065186
Validation loss: 3.405720055103302

Epoch: 5| Step: 1
Training loss: 3.584686279296875
Validation loss: 3.4018393556276956

Epoch: 5| Step: 2
Training loss: 3.6237151622772217
Validation loss: 3.395122597614924

Epoch: 5| Step: 3
Training loss: 4.017086029052734
Validation loss: 3.390204429626465

Epoch: 5| Step: 4
Training loss: 3.122809886932373
Validation loss: 3.3834819893042245

Epoch: 5| Step: 5
Training loss: 2.788574457168579
Validation loss: 3.3785876631736755

Epoch: 5| Step: 6
Training loss: 2.985732078552246
Validation loss: 3.373955726623535

Epoch: 5| Step: 7
Training loss: 3.697301149368286
Validation loss: 3.368910074234009

Epoch: 5| Step: 8
Training loss: 4.096220016479492
Validation loss: 3.3658255636692047

Epoch: 5| Step: 9
Training loss: 3.4599239826202393
Validation loss: 3.3625103731950126

Epoch: 5| Step: 10
Training loss: 3.5018069744110107
Validation loss: 3.3567188878854117

Epoch: 5| Step: 11
Training loss: 4.8632307052612305
Validation loss: 3.351874510447184

Epoch: 28| Step: 0
Training loss: 2.8341305255889893
Validation loss: 3.3455092310905457

Epoch: 5| Step: 1
Training loss: 3.583995819091797
Validation loss: 3.3413799504439035

Epoch: 5| Step: 2
Training loss: 3.6750359535217285
Validation loss: 3.3362088004748025

Epoch: 5| Step: 3
Training loss: 3.592843532562256
Validation loss: 3.332156886657079

Epoch: 5| Step: 4
Training loss: 3.438218355178833
Validation loss: 3.327889859676361

Epoch: 5| Step: 5
Training loss: 3.5132999420166016
Validation loss: 3.3228678504625955

Epoch: 5| Step: 6
Training loss: 2.9294240474700928
Validation loss: 3.3172398010889688

Epoch: 5| Step: 7
Training loss: 3.5031609535217285
Validation loss: 3.3140814205010733

Epoch: 5| Step: 8
Training loss: 3.282932996749878
Validation loss: 3.308736433585485

Epoch: 5| Step: 9
Training loss: 4.171514511108398
Validation loss: 3.3038616875807443

Epoch: 5| Step: 10
Training loss: 3.8166873455047607
Validation loss: 3.299365450938543

Epoch: 5| Step: 11
Training loss: 3.8594729900360107
Validation loss: 3.2949700355529785

Epoch: 29| Step: 0
Training loss: 3.7758948802948
Validation loss: 3.2903189758459725

Epoch: 5| Step: 1
Training loss: 3.6381754875183105
Validation loss: 3.2847773234049478

Epoch: 5| Step: 2
Training loss: 3.270754337310791
Validation loss: 3.2802776992321014

Epoch: 5| Step: 3
Training loss: 2.3997604846954346
Validation loss: 3.275282015403112

Epoch: 5| Step: 4
Training loss: 3.1037838459014893
Validation loss: 3.2716868817806244

Epoch: 5| Step: 5
Training loss: 4.197005271911621
Validation loss: 3.267636686563492

Epoch: 5| Step: 6
Training loss: 3.4499459266662598
Validation loss: 3.263866206010183

Epoch: 5| Step: 7
Training loss: 3.295182466506958
Validation loss: 3.259392410516739

Epoch: 5| Step: 8
Training loss: 3.5210068225860596
Validation loss: 3.2561587194601693

Epoch: 5| Step: 9
Training loss: 3.440619707107544
Validation loss: 3.254017343123754

Epoch: 5| Step: 10
Training loss: 3.5655300617218018
Validation loss: 3.2494156857331595

Epoch: 5| Step: 11
Training loss: 4.536834239959717
Validation loss: 3.243500739336014

Epoch: 30| Step: 0
Training loss: 3.6341910362243652
Validation loss: 3.238613098859787

Epoch: 5| Step: 1
Training loss: 3.2956795692443848
Validation loss: 3.2333973348140717

Epoch: 5| Step: 2
Training loss: 3.1588058471679688
Validation loss: 3.229533235232035

Epoch: 5| Step: 3
Training loss: 2.9749562740325928
Validation loss: 3.2255155046780906

Epoch: 5| Step: 4
Training loss: 3.544781446456909
Validation loss: 3.221287260452906

Epoch: 5| Step: 5
Training loss: 4.174824237823486
Validation loss: 3.217845549186071

Epoch: 5| Step: 6
Training loss: 4.10915470123291
Validation loss: 3.216486136118571

Epoch: 5| Step: 7
Training loss: 3.8873000144958496
Validation loss: 3.2105163435141244

Epoch: 5| Step: 8
Training loss: 2.4776010513305664
Validation loss: 3.2053727209568024

Epoch: 5| Step: 9
Training loss: 3.668914794921875
Validation loss: 3.200004130601883

Epoch: 5| Step: 10
Training loss: 2.728902816772461
Validation loss: 3.1961172421773276

Epoch: 5| Step: 11
Training loss: 1.77909255027771
Validation loss: 3.192460964123408

Epoch: 31| Step: 0
Training loss: 3.6360669136047363
Validation loss: 3.191387265920639

Epoch: 5| Step: 1
Training loss: 3.0959904193878174
Validation loss: 3.1871578892072043

Epoch: 5| Step: 2
Training loss: 3.4832260608673096
Validation loss: 3.1819958686828613

Epoch: 5| Step: 3
Training loss: 4.3526692390441895
Validation loss: 3.1760929226875305

Epoch: 5| Step: 4
Training loss: 3.032247543334961
Validation loss: 3.172307332356771

Epoch: 5| Step: 5
Training loss: 3.173121929168701
Validation loss: 3.1681844294071198

Epoch: 5| Step: 6
Training loss: 4.187849998474121
Validation loss: 3.1651614904403687

Epoch: 5| Step: 7
Training loss: 3.277467727661133
Validation loss: 3.1605388621489205

Epoch: 5| Step: 8
Training loss: 2.8471972942352295
Validation loss: 3.1567453344662986

Epoch: 5| Step: 9
Training loss: 2.5040688514709473
Validation loss: 3.151858021815618

Epoch: 5| Step: 10
Training loss: 3.1430726051330566
Validation loss: 3.146919677654902

Epoch: 5| Step: 11
Training loss: 4.061169624328613
Validation loss: 3.143120010693868

Epoch: 32| Step: 0
Training loss: 3.0138189792633057
Validation loss: 3.138420949379603

Epoch: 5| Step: 1
Training loss: 3.8939316272735596
Validation loss: 3.134165515502294

Epoch: 5| Step: 2
Training loss: 3.9352073669433594
Validation loss: 3.1293079356352487

Epoch: 5| Step: 3
Training loss: 3.6451220512390137
Validation loss: 3.126114288965861

Epoch: 5| Step: 4
Training loss: 3.40144419670105
Validation loss: 3.1218517124652863

Epoch: 5| Step: 5
Training loss: 2.942686080932617
Validation loss: 3.117033620675405

Epoch: 5| Step: 6
Training loss: 3.46085786819458
Validation loss: 3.112216889858246

Epoch: 5| Step: 7
Training loss: 2.7554337978363037
Validation loss: 3.107242782910665

Epoch: 5| Step: 8
Training loss: 2.8155910968780518
Validation loss: 3.103180934985479

Epoch: 5| Step: 9
Training loss: 3.74827241897583
Validation loss: 3.100623140732447

Epoch: 5| Step: 10
Training loss: 2.6759800910949707
Validation loss: 3.104143649339676

Epoch: 5| Step: 11
Training loss: 3.678973913192749
Validation loss: 3.1003809173901877

Epoch: 33| Step: 0
Training loss: 3.0336062908172607
Validation loss: 3.1249845822652182

Epoch: 5| Step: 1
Training loss: 3.2006144523620605
Validation loss: 3.1087092558542886

Epoch: 5| Step: 2
Training loss: 3.0196244716644287
Validation loss: 3.0820577840010324

Epoch: 5| Step: 3
Training loss: 3.8172874450683594
Validation loss: 3.0768761535485587

Epoch: 5| Step: 4
Training loss: 3.777705669403076
Validation loss: 3.0744424164295197

Epoch: 5| Step: 5
Training loss: 3.161510705947876
Validation loss: 3.074379945794741

Epoch: 5| Step: 6
Training loss: 3.1232409477233887
Validation loss: 3.074308762947718

Epoch: 5| Step: 7
Training loss: 2.936433792114258
Validation loss: 3.0713836749394736

Epoch: 5| Step: 8
Training loss: 3.2506072521209717
Validation loss: 3.064571519692739

Epoch: 5| Step: 9
Training loss: 3.384897232055664
Validation loss: 3.0605312486489615

Epoch: 5| Step: 10
Training loss: 2.7646543979644775
Validation loss: 3.057181547085444

Epoch: 5| Step: 11
Training loss: 5.4610209465026855
Validation loss: 3.0524600545565286

Epoch: 34| Step: 0
Training loss: 3.4569766521453857
Validation loss: 3.049397428830465

Epoch: 5| Step: 1
Training loss: 3.1331329345703125
Validation loss: 3.0437421997388205

Epoch: 5| Step: 2
Training loss: 2.914865016937256
Validation loss: 3.0401213665803275

Epoch: 5| Step: 3
Training loss: 3.9490673542022705
Validation loss: 3.035910040140152

Epoch: 5| Step: 4
Training loss: 3.330336332321167
Validation loss: 3.030178556839625

Epoch: 5| Step: 5
Training loss: 2.797191858291626
Validation loss: 3.0262676576773324

Epoch: 5| Step: 6
Training loss: 3.2555580139160156
Validation loss: 3.0220949153105416

Epoch: 5| Step: 7
Training loss: 3.0290398597717285
Validation loss: 3.018150587876638

Epoch: 5| Step: 8
Training loss: 2.7289834022521973
Validation loss: 3.0140830278396606

Epoch: 5| Step: 9
Training loss: 3.797473430633545
Validation loss: 3.0111842652161918

Epoch: 5| Step: 10
Training loss: 2.9852280616760254
Validation loss: 3.0075201789538064

Epoch: 5| Step: 11
Training loss: 3.459237813949585
Validation loss: 3.0036954283714294

Epoch: 35| Step: 0
Training loss: 3.015575885772705
Validation loss: 2.9996409515539804

Epoch: 5| Step: 1
Training loss: 3.397125720977783
Validation loss: 2.997104525566101

Epoch: 5| Step: 2
Training loss: 2.0469517707824707
Validation loss: 2.9929932753245034

Epoch: 5| Step: 3
Training loss: 3.8604187965393066
Validation loss: 2.989372581243515

Epoch: 5| Step: 4
Training loss: 3.144987106323242
Validation loss: 2.985247621933619

Epoch: 5| Step: 5
Training loss: 3.5507655143737793
Validation loss: 2.9833187560240426

Epoch: 5| Step: 6
Training loss: 3.637350559234619
Validation loss: 2.978307217359543

Epoch: 5| Step: 7
Training loss: 3.034639835357666
Validation loss: 2.974474310874939

Epoch: 5| Step: 8
Training loss: 2.425266742706299
Validation loss: 2.970727096001307

Epoch: 5| Step: 9
Training loss: 3.5182712078094482
Validation loss: 2.9665761391321817

Epoch: 5| Step: 10
Training loss: 3.2315402030944824
Validation loss: 2.9634361366430917

Epoch: 5| Step: 11
Training loss: 3.493269681930542
Validation loss: 2.9594180981318154

Epoch: 36| Step: 0
Training loss: 3.2358012199401855
Validation loss: 2.955615649620692

Epoch: 5| Step: 1
Training loss: 2.93438982963562
Validation loss: 2.9564527372519174

Epoch: 5| Step: 2
Training loss: 3.107318878173828
Validation loss: 2.9568279087543488

Epoch: 5| Step: 3
Training loss: 3.159222364425659
Validation loss: 2.953933616479238

Epoch: 5| Step: 4
Training loss: 3.3267388343811035
Validation loss: 2.9489344557126365

Epoch: 5| Step: 5
Training loss: 3.055858850479126
Validation loss: 2.945136845111847

Epoch: 5| Step: 6
Training loss: 3.3707756996154785
Validation loss: 2.937163253625234

Epoch: 5| Step: 7
Training loss: 2.843873977661133
Validation loss: 2.932907521724701

Epoch: 5| Step: 8
Training loss: 3.7097229957580566
Validation loss: 2.92849729458491

Epoch: 5| Step: 9
Training loss: 2.9924466609954834
Validation loss: 2.926848808924357

Epoch: 5| Step: 10
Training loss: 2.708693027496338
Validation loss: 2.923414478699366

Epoch: 5| Step: 11
Training loss: 3.6623873710632324
Validation loss: 2.921717047691345

Epoch: 37| Step: 0
Training loss: 2.875109910964966
Validation loss: 2.9190272788206735

Epoch: 5| Step: 1
Training loss: 3.2086563110351562
Validation loss: 2.915306270122528

Epoch: 5| Step: 2
Training loss: 3.005171775817871
Validation loss: 2.912514477968216

Epoch: 5| Step: 3
Training loss: 2.6602141857147217
Validation loss: 2.908804247776667

Epoch: 5| Step: 4
Training loss: 3.316612958908081
Validation loss: 2.904846419890722

Epoch: 5| Step: 5
Training loss: 3.599990129470825
Validation loss: 2.901280254125595

Epoch: 5| Step: 6
Training loss: 3.4180636405944824
Validation loss: 2.89889387289683

Epoch: 5| Step: 7
Training loss: 2.991178035736084
Validation loss: 2.894543538490931

Epoch: 5| Step: 8
Training loss: 3.3546860218048096
Validation loss: 2.8912008901437125

Epoch: 5| Step: 9
Training loss: 2.253541946411133
Validation loss: 2.8904078602790833

Epoch: 5| Step: 10
Training loss: 3.4421238899230957
Validation loss: 2.888213743766149

Epoch: 5| Step: 11
Training loss: 3.0502636432647705
Validation loss: 2.884695420662562

Epoch: 38| Step: 0
Training loss: 3.3760428428649902
Validation loss: 2.882411946853002

Epoch: 5| Step: 1
Training loss: 2.2373130321502686
Validation loss: 2.8827124337355294

Epoch: 5| Step: 2
Training loss: 3.359687328338623
Validation loss: 2.8738036851088204

Epoch: 5| Step: 3
Training loss: 3.392383098602295
Validation loss: 2.869903783003489

Epoch: 5| Step: 4
Training loss: 3.30314302444458
Validation loss: 2.867932846148809

Epoch: 5| Step: 5
Training loss: 2.9038918018341064
Validation loss: 2.8622391621271768

Epoch: 5| Step: 6
Training loss: 2.456089973449707
Validation loss: 2.8584555089473724

Epoch: 5| Step: 7
Training loss: 2.5495753288269043
Validation loss: 2.8587060421705246

Epoch: 5| Step: 8
Training loss: 3.0495753288269043
Validation loss: 2.855082998673121

Epoch: 5| Step: 9
Training loss: 3.1992759704589844
Validation loss: 2.8523028790950775

Epoch: 5| Step: 10
Training loss: 3.7204833030700684
Validation loss: 2.8491051495075226

Epoch: 5| Step: 11
Training loss: 3.9738473892211914
Validation loss: 2.847055514653524

Epoch: 39| Step: 0
Training loss: 3.0248160362243652
Validation loss: 2.8441946109135947

Epoch: 5| Step: 1
Training loss: 2.6554977893829346
Validation loss: 2.8407153884569802

Epoch: 5| Step: 2
Training loss: 3.5479133129119873
Validation loss: 2.8396025796731315

Epoch: 5| Step: 3
Training loss: 3.176309823989868
Validation loss: 2.8377141654491425

Epoch: 5| Step: 4
Training loss: 3.215550184249878
Validation loss: 2.834896673758825

Epoch: 5| Step: 5
Training loss: 2.5362117290496826
Validation loss: 2.8306019057830176

Epoch: 5| Step: 6
Training loss: 2.841512441635132
Validation loss: 2.826310952504476

Epoch: 5| Step: 7
Training loss: 2.4543228149414062
Validation loss: 2.8192261457443237

Epoch: 5| Step: 8
Training loss: 3.0589921474456787
Validation loss: 2.816548854112625

Epoch: 5| Step: 9
Training loss: 3.355309009552002
Validation loss: 2.8139842053254447

Epoch: 5| Step: 10
Training loss: 3.490912914276123
Validation loss: 2.8105612794558206

Epoch: 5| Step: 11
Training loss: 2.8307812213897705
Validation loss: 2.806747486193975

Epoch: 40| Step: 0
Training loss: 2.44350266456604
Validation loss: 2.803420136372248

Epoch: 5| Step: 1
Training loss: 3.2628281116485596
Validation loss: 2.80203644434611

Epoch: 5| Step: 2
Training loss: 2.332000494003296
Validation loss: 2.7987513542175293

Epoch: 5| Step: 3
Training loss: 3.658994197845459
Validation loss: 2.797171096007029

Epoch: 5| Step: 4
Training loss: 3.182023525238037
Validation loss: 2.7929609020551047

Epoch: 5| Step: 5
Training loss: 3.016756534576416
Validation loss: 2.7902448574701944

Epoch: 5| Step: 6
Training loss: 2.9834306240081787
Validation loss: 2.7874613106250763

Epoch: 5| Step: 7
Training loss: 3.3898041248321533
Validation loss: 2.7841000457604728

Epoch: 5| Step: 8
Training loss: 2.6523518562316895
Validation loss: 2.7831385831038156

Epoch: 5| Step: 9
Training loss: 2.9555578231811523
Validation loss: 2.781132529179255

Epoch: 5| Step: 10
Training loss: 2.952404022216797
Validation loss: 2.779281755288442

Epoch: 5| Step: 11
Training loss: 3.583148241043091
Validation loss: 2.7782413959503174

Epoch: 41| Step: 0
Training loss: 2.652845621109009
Validation loss: 2.7707905073960624

Epoch: 5| Step: 1
Training loss: 2.6147947311401367
Validation loss: 2.7670741379261017

Epoch: 5| Step: 2
Training loss: 3.0252997875213623
Validation loss: 2.765129884084066

Epoch: 5| Step: 3
Training loss: 2.6486129760742188
Validation loss: 2.7609543104966483

Epoch: 5| Step: 4
Training loss: 3.3724074363708496
Validation loss: 2.7567753195762634

Epoch: 5| Step: 5
Training loss: 2.938011884689331
Validation loss: 2.7570509016513824

Epoch: 5| Step: 6
Training loss: 3.191895008087158
Validation loss: 2.751360366741816

Epoch: 5| Step: 7
Training loss: 2.6516823768615723
Validation loss: 2.7475436131159463

Epoch: 5| Step: 8
Training loss: 3.0837783813476562
Validation loss: 2.746820161739985

Epoch: 5| Step: 9
Training loss: 3.012317180633545
Validation loss: 2.7426651616891227

Epoch: 5| Step: 10
Training loss: 2.9863483905792236
Validation loss: 2.738424221674601

Epoch: 5| Step: 11
Training loss: 4.82639741897583
Validation loss: 2.73608606060346

Epoch: 42| Step: 0
Training loss: 2.9150173664093018
Validation loss: 2.7306893865267434

Epoch: 5| Step: 1
Training loss: 3.306121349334717
Validation loss: 2.7306840121746063

Epoch: 5| Step: 2
Training loss: 3.0098800659179688
Validation loss: 2.729032705227534

Epoch: 5| Step: 3
Training loss: 2.3156301975250244
Validation loss: 2.726000120242437

Epoch: 5| Step: 4
Training loss: 2.661835193634033
Validation loss: 2.72499418258667

Epoch: 5| Step: 5
Training loss: 2.7141263484954834
Validation loss: 2.7196243703365326

Epoch: 5| Step: 6
Training loss: 3.1304221153259277
Validation loss: 2.716578314701716

Epoch: 5| Step: 7
Training loss: 2.917032241821289
Validation loss: 2.7122637927532196

Epoch: 5| Step: 8
Training loss: 3.0533270835876465
Validation loss: 2.708123246828715

Epoch: 5| Step: 9
Training loss: 3.473532199859619
Validation loss: 2.7062832514444985

Epoch: 5| Step: 10
Training loss: 2.731097459793091
Validation loss: 2.7006982813278833

Epoch: 5| Step: 11
Training loss: 2.5038857460021973
Validation loss: 2.6988259802261987

Epoch: 43| Step: 0
Training loss: 2.4115231037139893
Validation loss: 2.6980579495429993

Epoch: 5| Step: 1
Training loss: 2.483978509902954
Validation loss: 2.6939745247364044

Epoch: 5| Step: 2
Training loss: 2.847318172454834
Validation loss: 2.6934150209029517

Epoch: 5| Step: 3
Training loss: 3.3641953468322754
Validation loss: 2.6892119447390237

Epoch: 5| Step: 4
Training loss: 2.7674789428710938
Validation loss: 2.6870151857535043

Epoch: 5| Step: 5
Training loss: 2.7274057865142822
Validation loss: 2.67950048049291

Epoch: 5| Step: 6
Training loss: 2.489978075027466
Validation loss: 2.6801324983437858

Epoch: 5| Step: 7
Training loss: 3.217494249343872
Validation loss: 2.675158907969793

Epoch: 5| Step: 8
Training loss: 3.301081895828247
Validation loss: 2.67247873544693

Epoch: 5| Step: 9
Training loss: 3.2290115356445312
Validation loss: 2.67083673675855

Epoch: 5| Step: 10
Training loss: 2.8711345195770264
Validation loss: 2.665238877137502

Epoch: 5| Step: 11
Training loss: 2.875995635986328
Validation loss: 2.6628893514474234

Epoch: 44| Step: 0
Training loss: 3.082437515258789
Validation loss: 2.66353647907575

Epoch: 5| Step: 1
Training loss: 2.8730640411376953
Validation loss: 2.6588242948055267

Epoch: 5| Step: 2
Training loss: 2.965834379196167
Validation loss: 2.655689905087153

Epoch: 5| Step: 3
Training loss: 2.34920072555542
Validation loss: 2.65485347310702

Epoch: 5| Step: 4
Training loss: 2.634352445602417
Validation loss: 2.6516924500465393

Epoch: 5| Step: 5
Training loss: 3.417126417160034
Validation loss: 2.6471818685531616

Epoch: 5| Step: 6
Training loss: 3.408712863922119
Validation loss: 2.6453577677408853

Epoch: 5| Step: 7
Training loss: 2.587808847427368
Validation loss: 2.6436938643455505

Epoch: 5| Step: 8
Training loss: 2.857445478439331
Validation loss: 2.6396815280119577

Epoch: 5| Step: 9
Training loss: 2.4395253658294678
Validation loss: 2.6388252079486847

Epoch: 5| Step: 10
Training loss: 2.5109920501708984
Validation loss: 2.636763205130895

Epoch: 5| Step: 11
Training loss: 3.804641008377075
Validation loss: 2.6362389822800956

Epoch: 45| Step: 0
Training loss: 2.7359390258789062
Validation loss: 2.632436990737915

Epoch: 5| Step: 1
Training loss: 3.359302520751953
Validation loss: 2.631681273380915

Epoch: 5| Step: 2
Training loss: 3.170466661453247
Validation loss: 2.6196675399939218

Epoch: 5| Step: 3
Training loss: 2.804375410079956
Validation loss: 2.615813732147217

Epoch: 5| Step: 4
Training loss: 3.240683078765869
Validation loss: 2.616111030181249

Epoch: 5| Step: 5
Training loss: 2.118180990219116
Validation loss: 2.6133285065491996

Epoch: 5| Step: 6
Training loss: 2.3268208503723145
Validation loss: 2.6094858249028525

Epoch: 5| Step: 7
Training loss: 2.6636128425598145
Validation loss: 2.6093984047571817

Epoch: 5| Step: 8
Training loss: 2.366149425506592
Validation loss: 2.6095839937527976

Epoch: 5| Step: 9
Training loss: 3.021449327468872
Validation loss: 2.6071092983086905

Epoch: 5| Step: 10
Training loss: 3.0929150581359863
Validation loss: 2.6021683712800345

Epoch: 5| Step: 11
Training loss: 3.437894821166992
Validation loss: 2.597935895125071

Epoch: 46| Step: 0
Training loss: 3.3767142295837402
Validation loss: 2.593502849340439

Epoch: 5| Step: 1
Training loss: 2.6814897060394287
Validation loss: 2.593726376692454

Epoch: 5| Step: 2
Training loss: 2.6913845539093018
Validation loss: 2.5891234378019967

Epoch: 5| Step: 3
Training loss: 2.6581289768218994
Validation loss: 2.585442086060842

Epoch: 5| Step: 4
Training loss: 3.038045883178711
Validation loss: 2.5784218509991965

Epoch: 5| Step: 5
Training loss: 2.675571918487549
Validation loss: 2.5779369175434113

Epoch: 5| Step: 6
Training loss: 2.4455771446228027
Validation loss: 2.577628324429194

Epoch: 5| Step: 7
Training loss: 3.0812227725982666
Validation loss: 2.574591209491094

Epoch: 5| Step: 8
Training loss: 2.465756416320801
Validation loss: 2.568290740251541

Epoch: 5| Step: 9
Training loss: 2.878143787384033
Validation loss: 2.565692494312922

Epoch: 5| Step: 10
Training loss: 2.297818422317505
Validation loss: 2.5659069220225015

Epoch: 5| Step: 11
Training loss: 4.025140762329102
Validation loss: 2.5622621874014535

Epoch: 47| Step: 0
Training loss: 2.820728302001953
Validation loss: 2.5575745006402335

Epoch: 5| Step: 1
Training loss: 2.724682569503784
Validation loss: 2.560965910553932

Epoch: 5| Step: 2
Training loss: 2.5258240699768066
Validation loss: 2.5647750894228616

Epoch: 5| Step: 3
Training loss: 3.121920108795166
Validation loss: 2.552349776029587

Epoch: 5| Step: 4
Training loss: 2.619858503341675
Validation loss: 2.5480195681254068

Epoch: 5| Step: 5
Training loss: 2.4466185569763184
Validation loss: 2.544527848561605

Epoch: 5| Step: 6
Training loss: 2.695399045944214
Validation loss: 2.5444033443927765

Epoch: 5| Step: 7
Training loss: 2.7644858360290527
Validation loss: 2.541495054960251

Epoch: 5| Step: 8
Training loss: 3.2459850311279297
Validation loss: 2.54068190852801

Epoch: 5| Step: 9
Training loss: 2.986454963684082
Validation loss: 2.5376944740613303

Epoch: 5| Step: 10
Training loss: 2.3079638481140137
Validation loss: 2.5353512267271676

Epoch: 5| Step: 11
Training loss: 2.239015579223633
Validation loss: 2.531569182872772

Epoch: 48| Step: 0
Training loss: 2.729613780975342
Validation loss: 2.5273548861344657

Epoch: 5| Step: 1
Training loss: 2.1286354064941406
Validation loss: 2.527244205276171

Epoch: 5| Step: 2
Training loss: 2.3262858390808105
Validation loss: 2.5275557339191437

Epoch: 5| Step: 3
Training loss: 2.512840747833252
Validation loss: 2.5227946440378823

Epoch: 5| Step: 4
Training loss: 2.9209301471710205
Validation loss: 2.523966828982035

Epoch: 5| Step: 5
Training loss: 3.050934314727783
Validation loss: 2.517766833305359

Epoch: 5| Step: 6
Training loss: 2.580108165740967
Validation loss: 2.5155591865380607

Epoch: 5| Step: 7
Training loss: 2.8673553466796875
Validation loss: 2.5150960981845856

Epoch: 5| Step: 8
Training loss: 3.020677328109741
Validation loss: 2.5126015146573386

Epoch: 5| Step: 9
Training loss: 3.0736775398254395
Validation loss: 2.5070402125517526

Epoch: 5| Step: 10
Training loss: 2.6080234050750732
Validation loss: 2.506729781627655

Epoch: 5| Step: 11
Training loss: 2.5137388706207275
Validation loss: 2.502433270215988

Epoch: 49| Step: 0
Training loss: 2.6572699546813965
Validation loss: 2.50148798028628

Epoch: 5| Step: 1
Training loss: 3.0098745822906494
Validation loss: 2.5031070510546365

Epoch: 5| Step: 2
Training loss: 2.3647050857543945
Validation loss: 2.4940316577752433

Epoch: 5| Step: 3
Training loss: 2.5425376892089844
Validation loss: 2.493222932020823

Epoch: 5| Step: 4
Training loss: 2.7746667861938477
Validation loss: 2.4915692607561746

Epoch: 5| Step: 5
Training loss: 2.844263792037964
Validation loss: 2.484156847000122

Epoch: 5| Step: 6
Training loss: 2.4369893074035645
Validation loss: 2.485208958387375

Epoch: 5| Step: 7
Training loss: 3.0552616119384766
Validation loss: 2.4821401139100394

Epoch: 5| Step: 8
Training loss: 2.8883049488067627
Validation loss: 2.479383796453476

Epoch: 5| Step: 9
Training loss: 2.740976333618164
Validation loss: 2.47764960428079

Epoch: 5| Step: 10
Training loss: 2.1955034732818604
Validation loss: 2.475526968638102

Epoch: 5| Step: 11
Training loss: 2.3689329624176025
Validation loss: 2.4789094229539237

Epoch: 50| Step: 0
Training loss: 2.3735527992248535
Validation loss: 2.4833507339159646

Epoch: 5| Step: 1
Training loss: 2.4827017784118652
Validation loss: 2.475433871150017

Epoch: 5| Step: 2
Training loss: 2.533413887023926
Validation loss: 2.4694584608078003

Epoch: 5| Step: 3
Training loss: 2.4794654846191406
Validation loss: 2.459327131509781

Epoch: 5| Step: 4
Training loss: 2.2868824005126953
Validation loss: 2.459053377310435

Epoch: 5| Step: 5
Training loss: 2.749844551086426
Validation loss: 2.454721291859945

Epoch: 5| Step: 6
Training loss: 3.038978338241577
Validation loss: 2.455246865749359

Epoch: 5| Step: 7
Training loss: 3.377112627029419
Validation loss: 2.453212479750315

Epoch: 5| Step: 8
Training loss: 3.0157268047332764
Validation loss: 2.451530252893766

Epoch: 5| Step: 9
Training loss: 1.7552248239517212
Validation loss: 2.4500870406627655

Epoch: 5| Step: 10
Training loss: 3.081743001937866
Validation loss: 2.446455250183741

Epoch: 5| Step: 11
Training loss: 2.354781150817871
Validation loss: 2.4399184584617615

Epoch: 51| Step: 0
Training loss: 2.3991074562072754
Validation loss: 2.442560096581777

Epoch: 5| Step: 1
Training loss: 2.590754270553589
Validation loss: 2.439131418863932

Epoch: 5| Step: 2
Training loss: 2.1599926948547363
Validation loss: 2.437537203232447

Epoch: 5| Step: 3
Training loss: 2.7638914585113525
Validation loss: 2.435730238755544

Epoch: 5| Step: 4
Training loss: 2.6291441917419434
Validation loss: 2.42893593509992

Epoch: 5| Step: 5
Training loss: 2.4838874340057373
Validation loss: 2.436965435743332

Epoch: 5| Step: 6
Training loss: 2.9023311138153076
Validation loss: 2.429663360118866

Epoch: 5| Step: 7
Training loss: 1.8949527740478516
Validation loss: 2.4262631138165793

Epoch: 5| Step: 8
Training loss: 3.3519744873046875
Validation loss: 2.4193937381108603

Epoch: 5| Step: 9
Training loss: 2.972456455230713
Validation loss: 2.4194463590780892

Epoch: 5| Step: 10
Training loss: 2.373079538345337
Validation loss: 2.4119111398855844

Epoch: 5| Step: 11
Training loss: 3.61489200592041
Validation loss: 2.419092079003652

Epoch: 52| Step: 0
Training loss: 3.1595425605773926
Validation loss: 2.4135470191637673

Epoch: 5| Step: 1
Training loss: 2.6290059089660645
Validation loss: 2.4148233036200204

Epoch: 5| Step: 2
Training loss: 2.657151460647583
Validation loss: 2.413218706846237

Epoch: 5| Step: 3
Training loss: 2.5689139366149902
Validation loss: 2.412104770541191

Epoch: 5| Step: 4
Training loss: 1.954827070236206
Validation loss: 2.4137810468673706

Epoch: 5| Step: 5
Training loss: 2.0427629947662354
Validation loss: 2.4002656439940133

Epoch: 5| Step: 6
Training loss: 2.4400417804718018
Validation loss: 2.396926979223887

Epoch: 5| Step: 7
Training loss: 2.833869457244873
Validation loss: 2.4003012279669442

Epoch: 5| Step: 8
Training loss: 2.473120927810669
Validation loss: 2.402330199877421

Epoch: 5| Step: 9
Training loss: 2.564309597015381
Validation loss: 2.4012769957383475

Epoch: 5| Step: 10
Training loss: 3.310460329055786
Validation loss: 2.404088318347931

Epoch: 5| Step: 11
Training loss: 1.532856822013855
Validation loss: 2.400196691354116

Epoch: 53| Step: 0
Training loss: 2.494797468185425
Validation loss: 2.4008825421333313

Epoch: 5| Step: 1
Training loss: 2.235949754714966
Validation loss: 2.40336940685908

Epoch: 5| Step: 2
Training loss: 3.0215396881103516
Validation loss: 2.405111163854599

Epoch: 5| Step: 3
Training loss: 2.865713596343994
Validation loss: 2.4003107945124307

Epoch: 5| Step: 4
Training loss: 1.958878755569458
Validation loss: 2.3954134980837503

Epoch: 5| Step: 5
Training loss: 2.970475912094116
Validation loss: 2.385383536418279

Epoch: 5| Step: 6
Training loss: 2.618192195892334
Validation loss: 2.3826052645842233

Epoch: 5| Step: 7
Training loss: 2.199554443359375
Validation loss: 2.376980339487394

Epoch: 5| Step: 8
Training loss: 2.7367031574249268
Validation loss: 2.3726959228515625

Epoch: 5| Step: 9
Training loss: 2.05672025680542
Validation loss: 2.369856963555018

Epoch: 5| Step: 10
Training loss: 2.7761311531066895
Validation loss: 2.3651249011357627

Epoch: 5| Step: 11
Training loss: 3.564663887023926
Validation loss: 2.363710234562556

Epoch: 54| Step: 0
Training loss: 2.741947650909424
Validation loss: 2.3635609249273934

Epoch: 5| Step: 1
Training loss: 2.4502415657043457
Validation loss: 2.365694443384806

Epoch: 5| Step: 2
Training loss: 2.953279972076416
Validation loss: 2.359373559554418

Epoch: 5| Step: 3
Training loss: 2.2970070838928223
Validation loss: 2.3592277665932975

Epoch: 5| Step: 4
Training loss: 2.574228048324585
Validation loss: 2.3538790394862494

Epoch: 5| Step: 5
Training loss: 2.9688785076141357
Validation loss: 2.3480449318885803

Epoch: 5| Step: 6
Training loss: 2.6045050621032715
Validation loss: 2.3487437069416046

Epoch: 5| Step: 7
Training loss: 2.641300678253174
Validation loss: 2.3454478830099106

Epoch: 5| Step: 8
Training loss: 2.241939067840576
Validation loss: 2.344799429178238

Epoch: 5| Step: 9
Training loss: 1.919551134109497
Validation loss: 2.341828554868698

Epoch: 5| Step: 10
Training loss: 2.465562343597412
Validation loss: 2.3394496043523154

Epoch: 5| Step: 11
Training loss: 1.9677354097366333
Validation loss: 2.337610363960266

Epoch: 55| Step: 0
Training loss: 2.560844659805298
Validation loss: 2.3331154038508735

Epoch: 5| Step: 1
Training loss: 2.8362343311309814
Validation loss: 2.3320554246505103

Epoch: 5| Step: 2
Training loss: 2.225184440612793
Validation loss: 2.331201603015264

Epoch: 5| Step: 3
Training loss: 3.267585039138794
Validation loss: 2.3252627551555634

Epoch: 5| Step: 4
Training loss: 1.97323739528656
Validation loss: 2.322054078181585

Epoch: 5| Step: 5
Training loss: 2.3435661792755127
Validation loss: 2.3231520553429923

Epoch: 5| Step: 6
Training loss: 2.1919445991516113
Validation loss: 2.3153320799271264

Epoch: 5| Step: 7
Training loss: 2.762439012527466
Validation loss: 2.312913626432419

Epoch: 5| Step: 8
Training loss: 2.6347527503967285
Validation loss: 2.312396580974261

Epoch: 5| Step: 9
Training loss: 2.2530179023742676
Validation loss: 2.311316321293513

Epoch: 5| Step: 10
Training loss: 2.4879400730133057
Validation loss: 2.314318592349688

Epoch: 5| Step: 11
Training loss: 1.6004620790481567
Validation loss: 2.314913332462311

Epoch: 56| Step: 0
Training loss: 2.226541042327881
Validation loss: 2.3054913183053336

Epoch: 5| Step: 1
Training loss: 2.7422127723693848
Validation loss: 2.3079964071512222

Epoch: 5| Step: 2
Training loss: 2.1316890716552734
Validation loss: 2.3066432575384774

Epoch: 5| Step: 3
Training loss: 2.319509506225586
Validation loss: 2.295826325813929

Epoch: 5| Step: 4
Training loss: 2.9411182403564453
Validation loss: 2.292375405629476

Epoch: 5| Step: 5
Training loss: 2.2854466438293457
Validation loss: 2.2957827846209207

Epoch: 5| Step: 6
Training loss: 2.835477828979492
Validation loss: 2.2890213231245675

Epoch: 5| Step: 7
Training loss: 2.2314510345458984
Validation loss: 2.293975998957952

Epoch: 5| Step: 8
Training loss: 2.547393321990967
Validation loss: 2.286968713005384

Epoch: 5| Step: 9
Training loss: 2.418109893798828
Validation loss: 2.2859904964764914

Epoch: 5| Step: 10
Training loss: 2.2538723945617676
Validation loss: 2.28324593603611

Epoch: 5| Step: 11
Training loss: 3.035266399383545
Validation loss: 2.286661679546038

Epoch: 57| Step: 0
Training loss: 2.7082595825195312
Validation loss: 2.284225732088089

Epoch: 5| Step: 1
Training loss: 2.248635768890381
Validation loss: 2.282021383444468

Epoch: 5| Step: 2
Training loss: 2.5729317665100098
Validation loss: 2.2787026117245355

Epoch: 5| Step: 3
Training loss: 2.4524929523468018
Validation loss: 2.2728149394194284

Epoch: 5| Step: 4
Training loss: 2.835411310195923
Validation loss: 2.2691748092571893

Epoch: 5| Step: 5
Training loss: 2.644340753555298
Validation loss: 2.271836365262667

Epoch: 5| Step: 6
Training loss: 2.1256463527679443
Validation loss: 2.265747457742691

Epoch: 5| Step: 7
Training loss: 2.3450207710266113
Validation loss: 2.2625100314617157

Epoch: 5| Step: 8
Training loss: 1.6608810424804688
Validation loss: 2.2633166710535684

Epoch: 5| Step: 9
Training loss: 2.5006825923919678
Validation loss: 2.262320727109909

Epoch: 5| Step: 10
Training loss: 2.7403404712677
Validation loss: 2.2586281349261603

Epoch: 5| Step: 11
Training loss: 2.039102554321289
Validation loss: 2.26018558939298

Epoch: 58| Step: 0
Training loss: 2.24713134765625
Validation loss: 2.257651463150978

Epoch: 5| Step: 1
Training loss: 2.2884411811828613
Validation loss: 2.2613867421944938

Epoch: 5| Step: 2
Training loss: 2.9587464332580566
Validation loss: 2.257968028386434

Epoch: 5| Step: 3
Training loss: 2.521073341369629
Validation loss: 2.259348228573799

Epoch: 5| Step: 4
Training loss: 2.3119311332702637
Validation loss: 2.254475861787796

Epoch: 5| Step: 5
Training loss: 2.416196823120117
Validation loss: 2.252822329600652

Epoch: 5| Step: 6
Training loss: 2.38504695892334
Validation loss: 2.252074678738912

Epoch: 5| Step: 7
Training loss: 2.1912336349487305
Validation loss: 2.2469020634889603

Epoch: 5| Step: 8
Training loss: 2.572862148284912
Validation loss: 2.2464820941289267

Epoch: 5| Step: 9
Training loss: 2.713360071182251
Validation loss: 2.2419568647940955

Epoch: 5| Step: 10
Training loss: 2.0465891361236572
Validation loss: 2.2402023474375405

Epoch: 5| Step: 11
Training loss: 1.7402558326721191
Validation loss: 2.2391005903482437

Epoch: 59| Step: 0
Training loss: 2.535231590270996
Validation loss: 2.234851524233818

Epoch: 5| Step: 1
Training loss: 2.1649394035339355
Validation loss: 2.2310894628365836

Epoch: 5| Step: 2
Training loss: 1.3722628355026245
Validation loss: 2.2277910858392715

Epoch: 5| Step: 3
Training loss: 2.908068895339966
Validation loss: 2.224373290936152

Epoch: 5| Step: 4
Training loss: 2.5669379234313965
Validation loss: 2.221792240937551

Epoch: 5| Step: 5
Training loss: 3.048069477081299
Validation loss: 2.223277519146601

Epoch: 5| Step: 6
Training loss: 2.9009978771209717
Validation loss: 2.222939575711886

Epoch: 5| Step: 7
Training loss: 2.2528316974639893
Validation loss: 2.215360179543495

Epoch: 5| Step: 8
Training loss: 1.7521040439605713
Validation loss: 2.2149891505638757

Epoch: 5| Step: 9
Training loss: 2.5506699085235596
Validation loss: 2.210838178793589

Epoch: 5| Step: 10
Training loss: 2.2744133472442627
Validation loss: 2.2149851620197296

Epoch: 5| Step: 11
Training loss: 1.612818717956543
Validation loss: 2.2089669158061347

Epoch: 60| Step: 0
Training loss: 2.026813507080078
Validation loss: 2.2074782898028693

Epoch: 5| Step: 1
Training loss: 2.3317291736602783
Validation loss: 2.2091196179389954

Epoch: 5| Step: 2
Training loss: 1.8668506145477295
Validation loss: 2.2128866215546927

Epoch: 5| Step: 3
Training loss: 2.2736024856567383
Validation loss: 2.205199753244718

Epoch: 5| Step: 4
Training loss: 2.4897570610046387
Validation loss: 2.2133725732564926

Epoch: 5| Step: 5
Training loss: 2.5709850788116455
Validation loss: 2.2032077461481094

Epoch: 5| Step: 6
Training loss: 1.8951597213745117
Validation loss: 2.20054562886556

Epoch: 5| Step: 7
Training loss: 2.4852466583251953
Validation loss: 2.200469359755516

Epoch: 5| Step: 8
Training loss: 2.539599657058716
Validation loss: 2.196158841252327

Epoch: 5| Step: 9
Training loss: 2.462569236755371
Validation loss: 2.193218559026718

Epoch: 5| Step: 10
Training loss: 2.6986119747161865
Validation loss: 2.195524384578069

Epoch: 5| Step: 11
Training loss: 3.6392974853515625
Validation loss: 2.193436553080877

Epoch: 61| Step: 0
Training loss: 2.3186700344085693
Validation loss: 2.197445511817932

Epoch: 5| Step: 1
Training loss: 1.804757833480835
Validation loss: 2.1958009401957193

Epoch: 5| Step: 2
Training loss: 2.435072183609009
Validation loss: 2.1951912144819894

Epoch: 5| Step: 3
Training loss: 1.9762003421783447
Validation loss: 2.1964391271273294

Epoch: 5| Step: 4
Training loss: 2.8821043968200684
Validation loss: 2.1927707493305206

Epoch: 5| Step: 5
Training loss: 2.0105350017547607
Validation loss: 2.1920200337966285

Epoch: 5| Step: 6
Training loss: 2.2619175910949707
Validation loss: 2.1895194550355277

Epoch: 5| Step: 7
Training loss: 2.574553966522217
Validation loss: 2.190223182241122

Epoch: 5| Step: 8
Training loss: 2.550900459289551
Validation loss: 2.1861900140841803

Epoch: 5| Step: 9
Training loss: 2.0351550579071045
Validation loss: 2.1837320923805237

Epoch: 5| Step: 10
Training loss: 2.92899751663208
Validation loss: 2.185680324832598

Epoch: 5| Step: 11
Training loss: 2.4702978134155273
Validation loss: 2.182727813720703

Epoch: 62| Step: 0
Training loss: 2.3103480339050293
Validation loss: 2.180798351764679

Epoch: 5| Step: 1
Training loss: 2.6442484855651855
Validation loss: 2.1838015417257943

Epoch: 5| Step: 2
Training loss: 2.087430477142334
Validation loss: 2.1802760114272437

Epoch: 5| Step: 3
Training loss: 2.160409450531006
Validation loss: 2.175962214668592

Epoch: 5| Step: 4
Training loss: 2.6107983589172363
Validation loss: 2.1763528684775033

Epoch: 5| Step: 5
Training loss: 2.6284940242767334
Validation loss: 2.1747348805268607

Epoch: 5| Step: 6
Training loss: 2.1403470039367676
Validation loss: 2.172424544890722

Epoch: 5| Step: 7
Training loss: 2.547947645187378
Validation loss: 2.1598416616519294

Epoch: 5| Step: 8
Training loss: 1.9706302881240845
Validation loss: 2.162419686714808

Epoch: 5| Step: 9
Training loss: 2.047135829925537
Validation loss: 2.160431911547979

Epoch: 5| Step: 10
Training loss: 2.411020040512085
Validation loss: 2.1612191597620645

Epoch: 5| Step: 11
Training loss: 2.325683116912842
Validation loss: 2.155533035596212

Epoch: 63| Step: 0
Training loss: 2.7358155250549316
Validation loss: 2.158018017808596

Epoch: 5| Step: 1
Training loss: 1.6450233459472656
Validation loss: 2.158041169246038

Epoch: 5| Step: 2
Training loss: 2.1405856609344482
Validation loss: 2.1564111709594727

Epoch: 5| Step: 3
Training loss: 2.4502978324890137
Validation loss: 2.1512053410212197

Epoch: 5| Step: 4
Training loss: 2.765547513961792
Validation loss: 2.1506809294223785

Epoch: 5| Step: 5
Training loss: 2.4231936931610107
Validation loss: 2.1560292889674506

Epoch: 5| Step: 6
Training loss: 2.1277897357940674
Validation loss: 2.1578443348407745

Epoch: 5| Step: 7
Training loss: 2.5761666297912598
Validation loss: 2.157262290517489

Epoch: 5| Step: 8
Training loss: 2.0124363899230957
Validation loss: 2.1539466033379235

Epoch: 5| Step: 9
Training loss: 1.938531517982483
Validation loss: 2.1451576898495355

Epoch: 5| Step: 10
Training loss: 2.7547836303710938
Validation loss: 2.1423630913098655

Epoch: 5| Step: 11
Training loss: 1.5859326124191284
Validation loss: 2.1335261364777884

Epoch: 64| Step: 0
Training loss: 1.9289004802703857
Validation loss: 2.1479849020640054

Epoch: 5| Step: 1
Training loss: 2.8386902809143066
Validation loss: 2.163850888609886

Epoch: 5| Step: 2
Training loss: 2.32369065284729
Validation loss: 2.1610409965117774

Epoch: 5| Step: 3
Training loss: 2.1619009971618652
Validation loss: 2.143092999855677

Epoch: 5| Step: 4
Training loss: 2.4131431579589844
Validation loss: 2.139548738797506

Epoch: 5| Step: 5
Training loss: 2.6568222045898438
Validation loss: 2.1424300372600555

Epoch: 5| Step: 6
Training loss: 2.4682486057281494
Validation loss: 2.145095114906629

Epoch: 5| Step: 7
Training loss: 1.751503348350525
Validation loss: 2.1448792020479837

Epoch: 5| Step: 8
Training loss: 2.6441333293914795
Validation loss: 2.150177995363871

Epoch: 5| Step: 9
Training loss: 2.448507308959961
Validation loss: 2.1541727781295776

Epoch: 5| Step: 10
Training loss: 1.906294822692871
Validation loss: 2.1529239366451898

Epoch: 5| Step: 11
Training loss: 2.5297820568084717
Validation loss: 2.1540843347708383

Epoch: 65| Step: 0
Training loss: 2.2610020637512207
Validation loss: 2.1624425848325095

Epoch: 5| Step: 1
Training loss: 2.0420708656311035
Validation loss: 2.1600256015857062

Epoch: 5| Step: 2
Training loss: 2.863192319869995
Validation loss: 2.156587908665339

Epoch: 5| Step: 3
Training loss: 2.291600227355957
Validation loss: 2.1533583452304206

Epoch: 5| Step: 4
Training loss: 2.2175960540771484
Validation loss: 2.1466762522856393

Epoch: 5| Step: 5
Training loss: 1.8477836847305298
Validation loss: 2.142869914571444

Epoch: 5| Step: 6
Training loss: 2.6145803928375244
Validation loss: 2.1412033985058465

Epoch: 5| Step: 7
Training loss: 1.9486303329467773
Validation loss: 2.1387882232666016

Epoch: 5| Step: 8
Training loss: 2.6834099292755127
Validation loss: 2.131128783027331

Epoch: 5| Step: 9
Training loss: 2.1010966300964355
Validation loss: 2.1340201745430627

Epoch: 5| Step: 10
Training loss: 2.503659963607788
Validation loss: 2.13338311513265

Epoch: 5| Step: 11
Training loss: 2.9609556198120117
Validation loss: 2.1228901048501334

Epoch: 66| Step: 0
Training loss: 1.8139803409576416
Validation loss: 2.1206770638624826

Epoch: 5| Step: 1
Training loss: 2.1586995124816895
Validation loss: 2.125917841990789

Epoch: 5| Step: 2
Training loss: 2.5549683570861816
Validation loss: 2.1324249605337777

Epoch: 5| Step: 3
Training loss: 2.168560743331909
Validation loss: 2.132173036535581

Epoch: 5| Step: 4
Training loss: 2.955435276031494
Validation loss: 2.144533187150955

Epoch: 5| Step: 5
Training loss: 2.5951521396636963
Validation loss: 2.147230868538221

Epoch: 5| Step: 6
Training loss: 1.8257755041122437
Validation loss: 2.1502708842357

Epoch: 5| Step: 7
Training loss: 2.203958034515381
Validation loss: 2.152693053086599

Epoch: 5| Step: 8
Training loss: 1.9952325820922852
Validation loss: 2.1417327572902045

Epoch: 5| Step: 9
Training loss: 2.58013653755188
Validation loss: 2.14243753751119

Epoch: 5| Step: 10
Training loss: 2.664250373840332
Validation loss: 2.1314192016919455

Epoch: 5| Step: 11
Training loss: 1.92359459400177
Validation loss: 2.126736198862394

Epoch: 67| Step: 0
Training loss: 2.512800931930542
Validation loss: 2.119013865788778

Epoch: 5| Step: 1
Training loss: 2.0943431854248047
Validation loss: 2.116587817668915

Epoch: 5| Step: 2
Training loss: 2.01261568069458
Validation loss: 2.115076626340548

Epoch: 5| Step: 3
Training loss: 2.0416998863220215
Validation loss: 2.1075382431348166

Epoch: 5| Step: 4
Training loss: 2.4639382362365723
Validation loss: 2.1054283479849496

Epoch: 5| Step: 5
Training loss: 2.3650693893432617
Validation loss: 2.0990612357854843

Epoch: 5| Step: 6
Training loss: 3.0578818321228027
Validation loss: 2.1025951504707336

Epoch: 5| Step: 7
Training loss: 2.155395030975342
Validation loss: 2.095461035768191

Epoch: 5| Step: 8
Training loss: 1.7249696254730225
Validation loss: 2.100810021162033

Epoch: 5| Step: 9
Training loss: 2.426964282989502
Validation loss: 2.1082507371902466

Epoch: 5| Step: 10
Training loss: 2.397351026535034
Validation loss: 2.1003247499465942

Epoch: 5| Step: 11
Training loss: 2.1040351390838623
Validation loss: 2.104848191142082

Epoch: 68| Step: 0
Training loss: 2.1884677410125732
Validation loss: 2.0991232146819434

Epoch: 5| Step: 1
Training loss: 2.4635543823242188
Validation loss: 2.097304413715998

Epoch: 5| Step: 2
Training loss: 1.6684134006500244
Validation loss: 2.1043944557507834

Epoch: 5| Step: 3
Training loss: 2.1361780166625977
Validation loss: 2.112156947453817

Epoch: 5| Step: 4
Training loss: 2.083016872406006
Validation loss: 2.1076935728391013

Epoch: 5| Step: 5
Training loss: 2.4024109840393066
Validation loss: 2.115528161327044

Epoch: 5| Step: 6
Training loss: 2.5071938037872314
Validation loss: 2.1025619308153787

Epoch: 5| Step: 7
Training loss: 1.9696903228759766
Validation loss: 2.100369448463122

Epoch: 5| Step: 8
Training loss: 2.1147055625915527
Validation loss: 2.1008425503969193

Epoch: 5| Step: 9
Training loss: 2.7285549640655518
Validation loss: 2.098820378383001

Epoch: 5| Step: 10
Training loss: 2.5762412548065186
Validation loss: 2.0961057394742966

Epoch: 5| Step: 11
Training loss: 3.17374324798584
Validation loss: 2.090579256415367

Epoch: 69| Step: 0
Training loss: 2.80692720413208
Validation loss: 2.0989122490088143

Epoch: 5| Step: 1
Training loss: 2.2963974475860596
Validation loss: 2.1044762978951135

Epoch: 5| Step: 2
Training loss: 2.1725986003875732
Validation loss: 2.104244500398636

Epoch: 5| Step: 3
Training loss: 2.226478338241577
Validation loss: 2.1022225270668664

Epoch: 5| Step: 4
Training loss: 2.632819414138794
Validation loss: 2.1074603696664176

Epoch: 5| Step: 5
Training loss: 2.0877060890197754
Validation loss: 2.1072700719038644

Epoch: 5| Step: 6
Training loss: 2.093705654144287
Validation loss: 2.1045071532328925

Epoch: 5| Step: 7
Training loss: 2.1190409660339355
Validation loss: 2.107952058315277

Epoch: 5| Step: 8
Training loss: 2.3969829082489014
Validation loss: 2.1068120350440345

Epoch: 5| Step: 9
Training loss: 2.3637633323669434
Validation loss: 2.1012328416109085

Epoch: 5| Step: 10
Training loss: 2.1086297035217285
Validation loss: 2.102349132299423

Epoch: 5| Step: 11
Training loss: 0.8901119232177734
Validation loss: 2.098927304148674

Epoch: 70| Step: 0
Training loss: 2.0031776428222656
Validation loss: 2.0967441697915397

Epoch: 5| Step: 1
Training loss: 2.15096116065979
Validation loss: 2.089607745409012

Epoch: 5| Step: 2
Training loss: 2.289334297180176
Validation loss: 2.085025206208229

Epoch: 5| Step: 3
Training loss: 2.3784756660461426
Validation loss: 2.0904106001059213

Epoch: 5| Step: 4
Training loss: 2.1459779739379883
Validation loss: 2.0878536850214005

Epoch: 5| Step: 5
Training loss: 2.530668258666992
Validation loss: 2.084491267800331

Epoch: 5| Step: 6
Training loss: 2.664080858230591
Validation loss: 2.0822436114152274

Epoch: 5| Step: 7
Training loss: 2.1632866859436035
Validation loss: 2.0847805589437485

Epoch: 5| Step: 8
Training loss: 2.2760863304138184
Validation loss: 2.080155332883199

Epoch: 5| Step: 9
Training loss: 2.0925281047821045
Validation loss: 2.082472503185272

Epoch: 5| Step: 10
Training loss: 2.245736598968506
Validation loss: 2.072848786910375

Epoch: 5| Step: 11
Training loss: 1.6949901580810547
Validation loss: 2.069610446691513

Epoch: 71| Step: 0
Training loss: 2.374457836151123
Validation loss: 2.074029326438904

Epoch: 5| Step: 1
Training loss: 2.2153267860412598
Validation loss: 2.0721647441387177

Epoch: 5| Step: 2
Training loss: 2.5375759601593018
Validation loss: 2.0747707337141037

Epoch: 5| Step: 3
Training loss: 2.131354331970215
Validation loss: 2.0660572747389474

Epoch: 5| Step: 4
Training loss: 2.6451492309570312
Validation loss: 2.073391074935595

Epoch: 5| Step: 5
Training loss: 2.6400012969970703
Validation loss: 2.0742461482683816

Epoch: 5| Step: 6
Training loss: 1.3078409433364868
Validation loss: 2.0723336935043335

Epoch: 5| Step: 7
Training loss: 2.7032947540283203
Validation loss: 2.073794240752856

Epoch: 5| Step: 8
Training loss: 1.9368107318878174
Validation loss: 2.0642477373282113

Epoch: 5| Step: 9
Training loss: 2.1187663078308105
Validation loss: 2.058945417404175

Epoch: 5| Step: 10
Training loss: 2.3391499519348145
Validation loss: 2.0652774274349213

Epoch: 5| Step: 11
Training loss: 1.717282772064209
Validation loss: 2.064279501636823

Epoch: 72| Step: 0
Training loss: 1.8697572946548462
Validation loss: 2.0711894581715264

Epoch: 5| Step: 1
Training loss: 2.3430228233337402
Validation loss: 2.0736520141363144

Epoch: 5| Step: 2
Training loss: 1.6486799716949463
Validation loss: 2.069186344742775

Epoch: 5| Step: 3
Training loss: 2.404978036880493
Validation loss: 2.0675440281629562

Epoch: 5| Step: 4
Training loss: 2.1558468341827393
Validation loss: 2.06831718981266

Epoch: 5| Step: 5
Training loss: 2.3501343727111816
Validation loss: 2.0645707696676254

Epoch: 5| Step: 6
Training loss: 2.598010540008545
Validation loss: 2.0634674578905106

Epoch: 5| Step: 7
Training loss: 2.204641103744507
Validation loss: 2.0568981866041818

Epoch: 5| Step: 8
Training loss: 2.7425811290740967
Validation loss: 2.0567204554875693

Epoch: 5| Step: 9
Training loss: 2.3044493198394775
Validation loss: 2.049258515238762

Epoch: 5| Step: 10
Training loss: 1.8234632015228271
Validation loss: 2.0544214894374213

Epoch: 5| Step: 11
Training loss: 3.3753714561462402
Validation loss: 2.0548808624347052

Epoch: 73| Step: 0
Training loss: 2.7460570335388184
Validation loss: 2.057745556036631

Epoch: 5| Step: 1
Training loss: 2.9227662086486816
Validation loss: 2.06541608273983

Epoch: 5| Step: 2
Training loss: 2.3928263187408447
Validation loss: 2.050933594504992

Epoch: 5| Step: 3
Training loss: 2.4156510829925537
Validation loss: 2.056032881140709

Epoch: 5| Step: 4
Training loss: 1.7793943881988525
Validation loss: 2.0552376906077066

Epoch: 5| Step: 5
Training loss: 2.0699660778045654
Validation loss: 2.05343725780646

Epoch: 5| Step: 6
Training loss: 2.5249640941619873
Validation loss: 2.0584365278482437

Epoch: 5| Step: 7
Training loss: 1.689204454421997
Validation loss: 2.0537827809651694

Epoch: 5| Step: 8
Training loss: 1.7801358699798584
Validation loss: 2.0525976518789926

Epoch: 5| Step: 9
Training loss: 1.6253334283828735
Validation loss: 2.056797534227371

Epoch: 5| Step: 10
Training loss: 2.449589252471924
Validation loss: 2.0676884154478707

Epoch: 5| Step: 11
Training loss: 3.158534288406372
Validation loss: 2.0572838534911475

Epoch: 74| Step: 0
Training loss: 1.8352863788604736
Validation loss: 2.056041955947876

Epoch: 5| Step: 1
Training loss: 2.1286587715148926
Validation loss: 2.057923123240471

Epoch: 5| Step: 2
Training loss: 2.0460445880889893
Validation loss: 2.0481464664141336

Epoch: 5| Step: 3
Training loss: 2.4432876110076904
Validation loss: 2.047380348046621

Epoch: 5| Step: 4
Training loss: 2.471520185470581
Validation loss: 2.0583506723244986

Epoch: 5| Step: 5
Training loss: 2.314350128173828
Validation loss: 2.0562064349651337

Epoch: 5| Step: 6
Training loss: 2.1547982692718506
Validation loss: 2.0593510270118713

Epoch: 5| Step: 7
Training loss: 2.510776996612549
Validation loss: 2.0562064945697784

Epoch: 5| Step: 8
Training loss: 2.307514190673828
Validation loss: 2.0448814928531647

Epoch: 5| Step: 9
Training loss: 2.3274052143096924
Validation loss: 2.0467870434125266

Epoch: 5| Step: 10
Training loss: 1.9619486331939697
Validation loss: 2.036178082227707

Epoch: 5| Step: 11
Training loss: 2.5476560592651367
Validation loss: 2.0375860780477524

Epoch: 75| Step: 0
Training loss: 1.872471809387207
Validation loss: 2.038155515988668

Epoch: 5| Step: 1
Training loss: 2.315547466278076
Validation loss: 2.0449839333693185

Epoch: 5| Step: 2
Training loss: 2.6626477241516113
Validation loss: 2.0326168090105057

Epoch: 5| Step: 3
Training loss: 2.082186222076416
Validation loss: 2.039536659916242

Epoch: 5| Step: 4
Training loss: 2.353288173675537
Validation loss: 2.0386792620023093

Epoch: 5| Step: 5
Training loss: 2.5951523780822754
Validation loss: 2.0345503638188043

Epoch: 5| Step: 6
Training loss: 2.1308178901672363
Validation loss: 2.0413251370191574

Epoch: 5| Step: 7
Training loss: 2.073436737060547
Validation loss: 2.0476490259170532

Epoch: 5| Step: 8
Training loss: 1.8708223104476929
Validation loss: 2.048489590485891

Epoch: 5| Step: 9
Training loss: 2.6303229331970215
Validation loss: 2.0506833841403327

Epoch: 5| Step: 10
Training loss: 2.011551856994629
Validation loss: 2.04684712489446

Epoch: 5| Step: 11
Training loss: 2.1361613273620605
Validation loss: 2.0425455967585244

Epoch: 76| Step: 0
Training loss: 2.8165605068206787
Validation loss: 2.0491505910952887

Epoch: 5| Step: 1
Training loss: 2.2617955207824707
Validation loss: 2.0496896704037986

Epoch: 5| Step: 2
Training loss: 2.4253580570220947
Validation loss: 2.0461346159378686

Epoch: 5| Step: 3
Training loss: 2.0263450145721436
Validation loss: 2.0518140395482383

Epoch: 5| Step: 4
Training loss: 2.038547992706299
Validation loss: 2.0510582327842712

Epoch: 5| Step: 5
Training loss: 2.250857353210449
Validation loss: 2.044705400864283

Epoch: 5| Step: 6
Training loss: 1.755589246749878
Validation loss: 2.039757251739502

Epoch: 5| Step: 7
Training loss: 1.961824655532837
Validation loss: 2.037475516398748

Epoch: 5| Step: 8
Training loss: 1.874498724937439
Validation loss: 2.0380537509918213

Epoch: 5| Step: 9
Training loss: 2.5098190307617188
Validation loss: 2.032166004180908

Epoch: 5| Step: 10
Training loss: 2.429976224899292
Validation loss: 2.0388363748788834

Epoch: 5| Step: 11
Training loss: 3.0874483585357666
Validation loss: 2.029845267534256

Epoch: 77| Step: 0
Training loss: 2.2518181800842285
Validation loss: 2.035414149363836

Epoch: 5| Step: 1
Training loss: 2.4020423889160156
Validation loss: 2.0358119110266366

Epoch: 5| Step: 2
Training loss: 2.1532962322235107
Validation loss: 2.0298651307821274

Epoch: 5| Step: 3
Training loss: 2.059199810028076
Validation loss: 2.037147427598635

Epoch: 5| Step: 4
Training loss: 2.1529653072357178
Validation loss: 2.0376851161321006

Epoch: 5| Step: 5
Training loss: 1.7808128595352173
Validation loss: 2.0443287988503775

Epoch: 5| Step: 6
Training loss: 2.012857437133789
Validation loss: 2.0438380738099418

Epoch: 5| Step: 7
Training loss: 2.5597753524780273
Validation loss: 2.0542094906171164

Epoch: 5| Step: 8
Training loss: 2.4813404083251953
Validation loss: 2.0432488868633905

Epoch: 5| Step: 9
Training loss: 1.8634964227676392
Validation loss: 2.047929768760999

Epoch: 5| Step: 10
Training loss: 2.5541439056396484
Validation loss: 2.042953516046206

Epoch: 5| Step: 11
Training loss: 2.6873779296875
Validation loss: 2.0299380173285804

Epoch: 78| Step: 0
Training loss: 1.9487346410751343
Validation loss: 2.0354168762763343

Epoch: 5| Step: 1
Training loss: 2.590026378631592
Validation loss: 2.0446161528428397

Epoch: 5| Step: 2
Training loss: 2.1892902851104736
Validation loss: 2.044970373312632

Epoch: 5| Step: 3
Training loss: 2.010194778442383
Validation loss: 2.038981636365255

Epoch: 5| Step: 4
Training loss: 2.663696765899658
Validation loss: 2.0533449997504554

Epoch: 5| Step: 5
Training loss: 2.1810011863708496
Validation loss: 2.050501455863317

Epoch: 5| Step: 6
Training loss: 2.0549774169921875
Validation loss: 2.0445241083701453

Epoch: 5| Step: 7
Training loss: 1.7145274877548218
Validation loss: 2.0514324754476547

Epoch: 5| Step: 8
Training loss: 2.458763599395752
Validation loss: 2.0425945967435837

Epoch: 5| Step: 9
Training loss: 2.3579275608062744
Validation loss: 2.041393647591273

Epoch: 5| Step: 10
Training loss: 2.0866217613220215
Validation loss: 2.034810851017634

Epoch: 5| Step: 11
Training loss: 2.944599151611328
Validation loss: 2.0303280850251517

Epoch: 79| Step: 0
Training loss: 2.4208035469055176
Validation loss: 2.022841523090998

Epoch: 5| Step: 1
Training loss: 1.5281102657318115
Validation loss: 2.0298481782277427

Epoch: 5| Step: 2
Training loss: 2.5070574283599854
Validation loss: 2.0336162795623145

Epoch: 5| Step: 3
Training loss: 2.0051608085632324
Validation loss: 2.0387302935123444

Epoch: 5| Step: 4
Training loss: 2.3431663513183594
Validation loss: 2.0364429354667664

Epoch: 5| Step: 5
Training loss: 2.28328275680542
Validation loss: 2.040504738688469

Epoch: 5| Step: 6
Training loss: 2.497777223587036
Validation loss: 2.044961800177892

Epoch: 5| Step: 7
Training loss: 2.2050840854644775
Validation loss: 2.0440085381269455

Epoch: 5| Step: 8
Training loss: 2.180696964263916
Validation loss: 2.0419976313908896

Epoch: 5| Step: 9
Training loss: 2.0900425910949707
Validation loss: 2.0502833326657615

Epoch: 5| Step: 10
Training loss: 2.1708080768585205
Validation loss: 2.03694386780262

Epoch: 5| Step: 11
Training loss: 2.3017663955688477
Validation loss: 2.034663880864779

Epoch: 80| Step: 0
Training loss: 1.8382543325424194
Validation loss: 2.021762361129125

Epoch: 5| Step: 1
Training loss: 2.0229265689849854
Validation loss: 2.0173380970954895

Epoch: 5| Step: 2
Training loss: 2.0864484310150146
Validation loss: 2.0226706316073737

Epoch: 5| Step: 3
Training loss: 2.3815348148345947
Validation loss: 2.0363117357095084

Epoch: 5| Step: 4
Training loss: 1.8477729558944702
Validation loss: 2.0349160184462867

Epoch: 5| Step: 5
Training loss: 2.344367027282715
Validation loss: 2.019833520054817

Epoch: 5| Step: 6
Training loss: 2.5814902782440186
Validation loss: 2.0213447560866675

Epoch: 5| Step: 7
Training loss: 2.7159297466278076
Validation loss: 2.0217170119285583

Epoch: 5| Step: 8
Training loss: 2.4280848503112793
Validation loss: 2.015527844429016

Epoch: 5| Step: 9
Training loss: 1.672760009765625
Validation loss: 2.026189615329107

Epoch: 5| Step: 10
Training loss: 2.0433273315429688
Validation loss: 2.0213096092144647

Epoch: 5| Step: 11
Training loss: 2.639561653137207
Validation loss: 2.0230404287576675

Epoch: 81| Step: 0
Training loss: 1.9289051294326782
Validation loss: 2.0193545569976172

Epoch: 5| Step: 1
Training loss: 2.4544739723205566
Validation loss: 2.0283931493759155

Epoch: 5| Step: 2
Training loss: 2.3448309898376465
Validation loss: 2.0406862745682397

Epoch: 5| Step: 3
Training loss: 2.3842549324035645
Validation loss: 2.045634095867475

Epoch: 5| Step: 4
Training loss: 2.0420024394989014
Validation loss: 2.0459440102179847

Epoch: 5| Step: 5
Training loss: 1.9168517589569092
Validation loss: 2.0406715323527655

Epoch: 5| Step: 6
Training loss: 1.9471170902252197
Validation loss: 2.036259194215139

Epoch: 5| Step: 7
Training loss: 2.503997802734375
Validation loss: 2.033238415916761

Epoch: 5| Step: 8
Training loss: 2.0956664085388184
Validation loss: 2.0305262009302774

Epoch: 5| Step: 9
Training loss: 2.452784299850464
Validation loss: 2.019261663158735

Epoch: 5| Step: 10
Training loss: 2.3475985527038574
Validation loss: 2.0171190053224564

Epoch: 5| Step: 11
Training loss: 1.9134427309036255
Validation loss: 2.0159111569325128

Epoch: 82| Step: 0
Training loss: 2.207681894302368
Validation loss: 2.0230506906906762

Epoch: 5| Step: 1
Training loss: 2.089979648590088
Validation loss: 2.013838385542234

Epoch: 5| Step: 2
Training loss: 2.132181167602539
Validation loss: 2.0214172899723053

Epoch: 5| Step: 3
Training loss: 2.7630996704101562
Validation loss: 2.0254078755776086

Epoch: 5| Step: 4
Training loss: 1.6263628005981445
Validation loss: 2.019422044356664

Epoch: 5| Step: 5
Training loss: 2.174652338027954
Validation loss: 2.0266661942005157

Epoch: 5| Step: 6
Training loss: 2.3517959117889404
Validation loss: 2.0304722636938095

Epoch: 5| Step: 7
Training loss: 1.9952274560928345
Validation loss: 2.0250386744737625

Epoch: 5| Step: 8
Training loss: 2.4348831176757812
Validation loss: 2.023553947607676

Epoch: 5| Step: 9
Training loss: 2.2540111541748047
Validation loss: 2.0209842969973884

Epoch: 5| Step: 10
Training loss: 2.229949712753296
Validation loss: 2.0100758026043573

Epoch: 5| Step: 11
Training loss: 1.8697751760482788
Validation loss: 2.0163581719001136

Epoch: 83| Step: 0
Training loss: 2.6669132709503174
Validation loss: 2.018682817618052

Epoch: 5| Step: 1
Training loss: 1.836287260055542
Validation loss: 2.019802823662758

Epoch: 5| Step: 2
Training loss: 2.3199479579925537
Validation loss: 2.0145307977994285

Epoch: 5| Step: 3
Training loss: 1.919793725013733
Validation loss: 2.014566664894422

Epoch: 5| Step: 4
Training loss: 1.6577110290527344
Validation loss: 2.015962560971578

Epoch: 5| Step: 5
Training loss: 2.186039924621582
Validation loss: 2.028339738647143

Epoch: 5| Step: 6
Training loss: 3.3187179565429688
Validation loss: 2.0299499233563743

Epoch: 5| Step: 7
Training loss: 1.7515004873275757
Validation loss: 2.0221237242221832

Epoch: 5| Step: 8
Training loss: 1.961264967918396
Validation loss: 2.0224844266970954

Epoch: 5| Step: 9
Training loss: 2.1827614307403564
Validation loss: 2.0286020835240683

Epoch: 5| Step: 10
Training loss: 2.370598316192627
Validation loss: 2.017179732521375

Epoch: 5| Step: 11
Training loss: 1.9519774913787842
Validation loss: 2.013638883829117

Epoch: 84| Step: 0
Training loss: 2.142225742340088
Validation loss: 2.0075443039337793

Epoch: 5| Step: 1
Training loss: 1.703417181968689
Validation loss: 2.017360101143519

Epoch: 5| Step: 2
Training loss: 2.6321895122528076
Validation loss: 2.0138214329878488

Epoch: 5| Step: 3
Training loss: 2.1205625534057617
Validation loss: 2.021174728870392

Epoch: 5| Step: 4
Training loss: 2.1935832500457764
Validation loss: 2.010559856891632

Epoch: 5| Step: 5
Training loss: 1.772173523902893
Validation loss: 2.0104222695032754

Epoch: 5| Step: 6
Training loss: 2.3623945713043213
Validation loss: 2.0132728616396585

Epoch: 5| Step: 7
Training loss: 2.1914916038513184
Validation loss: 2.0135470430056253

Epoch: 5| Step: 8
Training loss: 2.729133129119873
Validation loss: 2.0119531551996865

Epoch: 5| Step: 9
Training loss: 2.1932578086853027
Validation loss: 2.0107067128022513

Epoch: 5| Step: 10
Training loss: 1.9762157201766968
Validation loss: 2.015125557780266

Epoch: 5| Step: 11
Training loss: 2.4632601737976074
Validation loss: 2.0156610310077667

Epoch: 85| Step: 0
Training loss: 2.551754951477051
Validation loss: 2.0163785914580026

Epoch: 5| Step: 1
Training loss: 2.152592897415161
Validation loss: 2.0254516899585724

Epoch: 5| Step: 2
Training loss: 2.4400806427001953
Validation loss: 2.0240910897652307

Epoch: 5| Step: 3
Training loss: 1.9966293573379517
Validation loss: 2.0278885116179786

Epoch: 5| Step: 4
Training loss: 1.9281539916992188
Validation loss: 2.0159303496281304

Epoch: 5| Step: 5
Training loss: 2.3192598819732666
Validation loss: 2.015763372182846

Epoch: 5| Step: 6
Training loss: 2.15246844291687
Validation loss: 2.009325221180916

Epoch: 5| Step: 7
Training loss: 2.5693464279174805
Validation loss: 2.010572532812754

Epoch: 5| Step: 8
Training loss: 2.2973246574401855
Validation loss: 2.014716779192289

Epoch: 5| Step: 9
Training loss: 2.078442335128784
Validation loss: 2.0094511856635413

Epoch: 5| Step: 10
Training loss: 1.7045761346817017
Validation loss: 2.013744220137596

Epoch: 5| Step: 11
Training loss: 2.2832272052764893
Validation loss: 2.0187482635180154

Epoch: 86| Step: 0
Training loss: 2.464150905609131
Validation loss: 2.0335750182469687

Epoch: 5| Step: 1
Training loss: 2.43023681640625
Validation loss: 2.0284538914759955

Epoch: 5| Step: 2
Training loss: 2.25009822845459
Validation loss: 2.033131957054138

Epoch: 5| Step: 3
Training loss: 2.138319969177246
Validation loss: 2.042038003603617

Epoch: 5| Step: 4
Training loss: 1.9805476665496826
Validation loss: 2.039405186971029

Epoch: 5| Step: 5
Training loss: 1.761980652809143
Validation loss: 2.0382231175899506

Epoch: 5| Step: 6
Training loss: 2.649205446243286
Validation loss: 2.0412099063396454

Epoch: 5| Step: 7
Training loss: 1.9126310348510742
Validation loss: 2.0357973525921502

Epoch: 5| Step: 8
Training loss: 2.2448647022247314
Validation loss: 2.036064530412356

Epoch: 5| Step: 9
Training loss: 2.229203701019287
Validation loss: 2.0350199937820435

Epoch: 5| Step: 10
Training loss: 2.271230697631836
Validation loss: 2.0309137403964996

Epoch: 5| Step: 11
Training loss: 1.8672038316726685
Validation loss: 2.0168410191933313

Epoch: 87| Step: 0
Training loss: 1.9351383447647095
Validation loss: 2.0086295157670975

Epoch: 5| Step: 1
Training loss: 2.45430326461792
Validation loss: 2.0143543034791946

Epoch: 5| Step: 2
Training loss: 2.0715959072113037
Validation loss: 2.0231894155343375

Epoch: 5| Step: 3
Training loss: 2.163112163543701
Validation loss: 2.0308954467376075

Epoch: 5| Step: 4
Training loss: 2.1734843254089355
Validation loss: 2.0347022215525308

Epoch: 5| Step: 5
Training loss: 1.728654146194458
Validation loss: 2.0412220656871796

Epoch: 5| Step: 6
Training loss: 2.410055160522461
Validation loss: 2.068655307094256

Epoch: 5| Step: 7
Training loss: 2.0166335105895996
Validation loss: 2.0792329212029776

Epoch: 5| Step: 8
Training loss: 2.429140329360962
Validation loss: 2.0970398286978402

Epoch: 5| Step: 9
Training loss: 2.608358144760132
Validation loss: 2.0601911594470343

Epoch: 5| Step: 10
Training loss: 2.555743455886841
Validation loss: 2.029833421111107

Epoch: 5| Step: 11
Training loss: 1.2388579845428467
Validation loss: 2.01239180068175

Epoch: 88| Step: 0
Training loss: 2.635354518890381
Validation loss: 2.010136509935061

Epoch: 5| Step: 1
Training loss: 1.790022611618042
Validation loss: 2.036464666326841

Epoch: 5| Step: 2
Training loss: 2.60258412361145
Validation loss: 2.0474040607611337

Epoch: 5| Step: 3
Training loss: 2.4689643383026123
Validation loss: 2.064429526527723

Epoch: 5| Step: 4
Training loss: 1.9124000072479248
Validation loss: 2.0801776945590973

Epoch: 5| Step: 5
Training loss: 2.278754949569702
Validation loss: 2.095211401581764

Epoch: 5| Step: 6
Training loss: 2.215693235397339
Validation loss: 2.109901567300161

Epoch: 5| Step: 7
Training loss: 2.561091899871826
Validation loss: 2.1215718736251197

Epoch: 5| Step: 8
Training loss: 2.439925193786621
Validation loss: 2.133643632133802

Epoch: 5| Step: 9
Training loss: 1.2884275913238525
Validation loss: 2.140785132845243

Epoch: 5| Step: 10
Training loss: 2.8615505695343018
Validation loss: 2.1451907555262246

Epoch: 5| Step: 11
Training loss: 1.890605092048645
Validation loss: 2.133850932121277

Epoch: 89| Step: 0
Training loss: 2.160707950592041
Validation loss: 2.129044512907664

Epoch: 5| Step: 1
Training loss: 2.471519947052002
Validation loss: 2.1205366601546607

Epoch: 5| Step: 2
Training loss: 1.8435827493667603
Validation loss: 2.108031411965688

Epoch: 5| Step: 3
Training loss: 2.80682635307312
Validation loss: 2.1040381540854773

Epoch: 5| Step: 4
Training loss: 2.106713056564331
Validation loss: 2.091449091831843

Epoch: 5| Step: 5
Training loss: 2.484004020690918
Validation loss: 2.0803174575169883

Epoch: 5| Step: 6
Training loss: 2.2633488178253174
Validation loss: 2.074951017896334

Epoch: 5| Step: 7
Training loss: 2.7131526470184326
Validation loss: 2.0725636929273605

Epoch: 5| Step: 8
Training loss: 2.131502866744995
Validation loss: 2.0654043157895408

Epoch: 5| Step: 9
Training loss: 2.1662726402282715
Validation loss: 2.060099412997564

Epoch: 5| Step: 10
Training loss: 1.6042280197143555
Validation loss: 2.0617138743400574

Epoch: 5| Step: 11
Training loss: 3.2264394760131836
Validation loss: 2.0582728485266366

Epoch: 90| Step: 0
Training loss: 2.6588029861450195
Validation loss: 2.05286398033301

Epoch: 5| Step: 1
Training loss: 2.530493974685669
Validation loss: 2.056078056494395

Epoch: 5| Step: 2
Training loss: 1.941504716873169
Validation loss: 2.050187756617864

Epoch: 5| Step: 3
Training loss: 2.332367420196533
Validation loss: 2.0510527044534683

Epoch: 5| Step: 4
Training loss: 2.483585834503174
Validation loss: 2.0463209648927054

Epoch: 5| Step: 5
Training loss: 2.1538028717041016
Validation loss: 2.044824222723643

Epoch: 5| Step: 6
Training loss: 2.158328056335449
Validation loss: 2.035996968547503

Epoch: 5| Step: 7
Training loss: 1.8070061206817627
Validation loss: 2.0281775345404944

Epoch: 5| Step: 8
Training loss: 2.0492382049560547
Validation loss: 2.0276748637358346

Epoch: 5| Step: 9
Training loss: 2.28481388092041
Validation loss: 2.0183858424425125

Epoch: 5| Step: 10
Training loss: 2.075084924697876
Validation loss: 2.016460428635279

Epoch: 5| Step: 11
Training loss: 1.4057561159133911
Validation loss: 2.0145113368829093

Epoch: 91| Step: 0
Training loss: 2.041609287261963
Validation loss: 2.0168730864922204

Epoch: 5| Step: 1
Training loss: 2.583195447921753
Validation loss: 2.015495225787163

Epoch: 5| Step: 2
Training loss: 1.9452030658721924
Validation loss: 2.01800366739432

Epoch: 5| Step: 3
Training loss: 2.218942165374756
Validation loss: 2.0320142954587936

Epoch: 5| Step: 4
Training loss: 2.038242816925049
Validation loss: 2.031782016158104

Epoch: 5| Step: 5
Training loss: 2.2485244274139404
Validation loss: 2.033082996805509

Epoch: 5| Step: 6
Training loss: 2.489704132080078
Validation loss: 2.0331031729777655

Epoch: 5| Step: 7
Training loss: 2.308755874633789
Validation loss: 2.029424324631691

Epoch: 5| Step: 8
Training loss: 2.0250282287597656
Validation loss: 2.035959561665853

Epoch: 5| Step: 9
Training loss: 2.56683611869812
Validation loss: 2.020061140259107

Epoch: 5| Step: 10
Training loss: 1.7246217727661133
Validation loss: 2.015917112429937

Epoch: 5| Step: 11
Training loss: 2.5983903408050537
Validation loss: 2.0091563115517297

Epoch: 92| Step: 0
Training loss: 1.9195648431777954
Validation loss: 2.0097049127022424

Epoch: 5| Step: 1
Training loss: 2.336106777191162
Validation loss: 2.0123433073361716

Epoch: 5| Step: 2
Training loss: 1.763092041015625
Validation loss: 2.020234932502111

Epoch: 5| Step: 3
Training loss: 2.118612766265869
Validation loss: 2.022276148200035

Epoch: 5| Step: 4
Training loss: 2.0421602725982666
Validation loss: 2.0262536853551865

Epoch: 5| Step: 5
Training loss: 2.464451551437378
Validation loss: 2.026889815926552

Epoch: 5| Step: 6
Training loss: 2.45859432220459
Validation loss: 2.0233828524748483

Epoch: 5| Step: 7
Training loss: 2.004232883453369
Validation loss: 2.0278750409682593

Epoch: 5| Step: 8
Training loss: 2.460237741470337
Validation loss: 2.0240844984849296

Epoch: 5| Step: 9
Training loss: 2.2260525226593018
Validation loss: 2.0235904355843863

Epoch: 5| Step: 10
Training loss: 2.312856912612915
Validation loss: 2.0191335876782737

Epoch: 5| Step: 11
Training loss: 2.5235862731933594
Validation loss: 2.0167540411154428

Epoch: 93| Step: 0
Training loss: 2.2475523948669434
Validation loss: 2.0099709779024124

Epoch: 5| Step: 1
Training loss: 1.6114673614501953
Validation loss: 2.014119476079941

Epoch: 5| Step: 2
Training loss: 2.41658091545105
Validation loss: 2.0062107890844345

Epoch: 5| Step: 3
Training loss: 2.496001720428467
Validation loss: 2.009782334168752

Epoch: 5| Step: 4
Training loss: 2.179729461669922
Validation loss: 2.01132071018219

Epoch: 5| Step: 5
Training loss: 2.3864197731018066
Validation loss: 2.0029403815666833

Epoch: 5| Step: 6
Training loss: 2.0988497734069824
Validation loss: 2.0181946555773416

Epoch: 5| Step: 7
Training loss: 2.4883313179016113
Validation loss: 2.0020425617694855

Epoch: 5| Step: 8
Training loss: 1.8558132648468018
Validation loss: 2.0033480674028397

Epoch: 5| Step: 9
Training loss: 2.4512104988098145
Validation loss: 1.9997488756974537

Epoch: 5| Step: 10
Training loss: 2.0336127281188965
Validation loss: 2.003704438606898

Epoch: 5| Step: 11
Training loss: 1.3315575122833252
Validation loss: 2.007856105764707

Epoch: 94| Step: 0
Training loss: 1.9267597198486328
Validation loss: 2.0107896824677787

Epoch: 5| Step: 1
Training loss: 2.194103956222534
Validation loss: 2.0079055577516556

Epoch: 5| Step: 2
Training loss: 2.0346882343292236
Validation loss: 2.0112253924210868

Epoch: 5| Step: 3
Training loss: 2.414588451385498
Validation loss: 2.0050590684016547

Epoch: 5| Step: 4
Training loss: 2.2241101264953613
Validation loss: 2.0018798460563025

Epoch: 5| Step: 5
Training loss: 2.7964415550231934
Validation loss: 1.9976339588562648

Epoch: 5| Step: 6
Training loss: 2.461601734161377
Validation loss: 1.996382196744283

Epoch: 5| Step: 7
Training loss: 1.8043015003204346
Validation loss: 2.0012506345907846

Epoch: 5| Step: 8
Training loss: 2.2790451049804688
Validation loss: 1.9981456597646077

Epoch: 5| Step: 9
Training loss: 2.1065762042999268
Validation loss: 1.9974587857723236

Epoch: 5| Step: 10
Training loss: 1.677201509475708
Validation loss: 2.0024598141511283

Epoch: 5| Step: 11
Training loss: 2.5726187229156494
Validation loss: 1.9935955554246902

Epoch: 95| Step: 0
Training loss: 1.781010389328003
Validation loss: 2.0012453893820443

Epoch: 5| Step: 1
Training loss: 2.309664487838745
Validation loss: 2.0017680674791336

Epoch: 5| Step: 2
Training loss: 2.0934224128723145
Validation loss: 2.0015755693117776

Epoch: 5| Step: 3
Training loss: 2.2235188484191895
Validation loss: 2.0024843414624534

Epoch: 5| Step: 4
Training loss: 2.0347542762756348
Validation loss: 2.0109548370043435

Epoch: 5| Step: 5
Training loss: 2.3987069129943848
Validation loss: 2.001191625992457

Epoch: 5| Step: 6
Training loss: 2.266928195953369
Validation loss: 2.0112573554118476

Epoch: 5| Step: 7
Training loss: 2.2236175537109375
Validation loss: 2.01122510433197

Epoch: 5| Step: 8
Training loss: 2.348243236541748
Validation loss: 2.0155677745739617

Epoch: 5| Step: 9
Training loss: 2.0526130199432373
Validation loss: 2.006162871917089

Epoch: 5| Step: 10
Training loss: 1.929464340209961
Validation loss: 2.0010081926981607

Epoch: 5| Step: 11
Training loss: 2.2216453552246094
Validation loss: 2.006325880686442

Epoch: 96| Step: 0
Training loss: 1.8902227878570557
Validation loss: 2.0051239679257074

Epoch: 5| Step: 1
Training loss: 2.56396746635437
Validation loss: 2.0042447398106256

Epoch: 5| Step: 2
Training loss: 1.977560043334961
Validation loss: 2.004710172613462

Epoch: 5| Step: 3
Training loss: 2.296414613723755
Validation loss: 2.00764898955822

Epoch: 5| Step: 4
Training loss: 1.8714256286621094
Validation loss: 2.006357192993164

Epoch: 5| Step: 5
Training loss: 1.9387718439102173
Validation loss: 2.011835296948751

Epoch: 5| Step: 6
Training loss: 2.529160261154175
Validation loss: 2.0190687676270804

Epoch: 5| Step: 7
Training loss: 2.4301037788391113
Validation loss: 2.0165484299262366

Epoch: 5| Step: 8
Training loss: 2.188922166824341
Validation loss: 2.0233031859000525

Epoch: 5| Step: 9
Training loss: 2.078371524810791
Validation loss: 2.0138662258783975

Epoch: 5| Step: 10
Training loss: 2.1323342323303223
Validation loss: 2.011117031176885

Epoch: 5| Step: 11
Training loss: 0.9594221115112305
Validation loss: 2.0067687729994454

Epoch: 97| Step: 0
Training loss: 2.0476088523864746
Validation loss: 2.0026994049549103

Epoch: 5| Step: 1
Training loss: 2.1152052879333496
Validation loss: 2.009990627566973

Epoch: 5| Step: 2
Training loss: 2.0512378215789795
Validation loss: 2.0100790510574975

Epoch: 5| Step: 3
Training loss: 2.124720335006714
Validation loss: 2.0254475126663842

Epoch: 5| Step: 4
Training loss: 2.348381519317627
Validation loss: 2.0090281714995704

Epoch: 5| Step: 5
Training loss: 2.249338388442993
Validation loss: 2.00880998869737

Epoch: 5| Step: 6
Training loss: 2.446564197540283
Validation loss: 2.0035016437371573

Epoch: 5| Step: 7
Training loss: 1.7263574600219727
Validation loss: 2.0158446729183197

Epoch: 5| Step: 8
Training loss: 1.9467384815216064
Validation loss: 2.004285509387652

Epoch: 5| Step: 9
Training loss: 2.198453426361084
Validation loss: 2.0058830430110297

Epoch: 5| Step: 10
Training loss: 2.2575459480285645
Validation loss: 2.0200300017992654

Epoch: 5| Step: 11
Training loss: 2.835999011993408
Validation loss: 2.0117125461498895

Epoch: 98| Step: 0
Training loss: 2.25988507270813
Validation loss: 2.019951860109965

Epoch: 5| Step: 1
Training loss: 2.2187886238098145
Validation loss: 2.00893834233284

Epoch: 5| Step: 2
Training loss: 1.7340552806854248
Validation loss: 2.0091079274813333

Epoch: 5| Step: 3
Training loss: 1.941145896911621
Validation loss: 2.0217840472857156

Epoch: 5| Step: 4
Training loss: 1.8897842168807983
Validation loss: 2.01635272304217

Epoch: 5| Step: 5
Training loss: 2.5958588123321533
Validation loss: 2.0094569275776544

Epoch: 5| Step: 6
Training loss: 2.1989777088165283
Validation loss: 2.009794513384501

Epoch: 5| Step: 7
Training loss: 2.3970141410827637
Validation loss: 2.0127319246530533

Epoch: 5| Step: 8
Training loss: 2.3063786029815674
Validation loss: 2.0101685225963593

Epoch: 5| Step: 9
Training loss: 2.137505292892456
Validation loss: 2.0074493885040283

Epoch: 5| Step: 10
Training loss: 2.0768091678619385
Validation loss: 2.003783936301867

Epoch: 5| Step: 11
Training loss: 1.3406883478164673
Validation loss: 2.001192187269529

Epoch: 99| Step: 0
Training loss: 2.267402172088623
Validation loss: 2.009426772594452

Epoch: 5| Step: 1
Training loss: 2.0238864421844482
Validation loss: 2.0206411977609

Epoch: 5| Step: 2
Training loss: 2.7471022605895996
Validation loss: 2.0118156572182975

Epoch: 5| Step: 3
Training loss: 2.0861496925354004
Validation loss: 2.0133370012044907

Epoch: 5| Step: 4
Training loss: 2.2289977073669434
Validation loss: 2.0231455167134604

Epoch: 5| Step: 5
Training loss: 1.8118820190429688
Validation loss: 2.0194248110055923

Epoch: 5| Step: 6
Training loss: 2.554903030395508
Validation loss: 2.0259137749671936

Epoch: 5| Step: 7
Training loss: 2.3216822147369385
Validation loss: 2.0159596105416617

Epoch: 5| Step: 8
Training loss: 2.04896879196167
Validation loss: 2.01832407216231

Epoch: 5| Step: 9
Training loss: 1.9402477741241455
Validation loss: 2.007808282971382

Epoch: 5| Step: 10
Training loss: 2.0547327995300293
Validation loss: 2.012518306573232

Epoch: 5| Step: 11
Training loss: 1.165179967880249
Validation loss: 2.007931172847748

Epoch: 100| Step: 0
Training loss: 2.4591991901397705
Validation loss: 2.006409461299578

Epoch: 5| Step: 1
Training loss: 1.9895387887954712
Validation loss: 2.008469899495443

Epoch: 5| Step: 2
Training loss: 2.111950159072876
Validation loss: 2.002378841241201

Epoch: 5| Step: 3
Training loss: 2.2985939979553223
Validation loss: 2.0047039687633514

Epoch: 5| Step: 4
Training loss: 2.1002650260925293
Validation loss: 2.003530447681745

Epoch: 5| Step: 5
Training loss: 2.050844192504883
Validation loss: 2.012591078877449

Epoch: 5| Step: 6
Training loss: 2.146888256072998
Validation loss: 2.0224898060162864

Epoch: 5| Step: 7
Training loss: 2.397796630859375
Validation loss: 2.0310456653436026

Epoch: 5| Step: 8
Training loss: 2.1746068000793457
Validation loss: 2.030743549267451

Epoch: 5| Step: 9
Training loss: 2.176321506500244
Validation loss: 2.029057631889979

Epoch: 5| Step: 10
Training loss: 1.8347076177597046
Validation loss: 2.029633581638336

Epoch: 5| Step: 11
Training loss: 2.2165188789367676
Validation loss: 2.0235726485649743

Epoch: 101| Step: 0
Training loss: 1.7744585275650024
Validation loss: 2.025148257613182

Epoch: 5| Step: 1
Training loss: 2.4917805194854736
Validation loss: 2.0241386940081916

Epoch: 5| Step: 2
Training loss: 2.098496913909912
Validation loss: 2.041751444339752

Epoch: 5| Step: 3
Training loss: 2.115389347076416
Validation loss: 2.0342723031838736

Epoch: 5| Step: 4
Training loss: 1.8357150554656982
Validation loss: 2.0318968147039413

Epoch: 5| Step: 5
Training loss: 2.277249336242676
Validation loss: 2.032931307951609

Epoch: 5| Step: 6
Training loss: 2.5072481632232666
Validation loss: 2.0202733228603997

Epoch: 5| Step: 7
Training loss: 2.027653455734253
Validation loss: 2.013021315137545

Epoch: 5| Step: 8
Training loss: 1.9478832483291626
Validation loss: 2.018535186847051

Epoch: 5| Step: 9
Training loss: 2.398672103881836
Validation loss: 2.005686327815056

Epoch: 5| Step: 10
Training loss: 2.4572272300720215
Validation loss: 2.008107975125313

Epoch: 5| Step: 11
Training loss: 1.7036609649658203
Validation loss: 2.011779263615608

Epoch: 102| Step: 0
Training loss: 2.430189609527588
Validation loss: 2.0147566348314285

Epoch: 5| Step: 1
Training loss: 2.0664172172546387
Validation loss: 2.014679431915283

Epoch: 5| Step: 2
Training loss: 1.9005286693572998
Validation loss: 2.012804627418518

Epoch: 5| Step: 3
Training loss: 2.216919422149658
Validation loss: 2.0188218702872596

Epoch: 5| Step: 4
Training loss: 1.6365039348602295
Validation loss: 2.0165627102057138

Epoch: 5| Step: 5
Training loss: 2.034693479537964
Validation loss: 2.011397878328959

Epoch: 5| Step: 6
Training loss: 2.599412441253662
Validation loss: 2.011856332421303

Epoch: 5| Step: 7
Training loss: 1.909419059753418
Validation loss: 2.014760767420133

Epoch: 5| Step: 8
Training loss: 1.9948949813842773
Validation loss: 2.0189282993475595

Epoch: 5| Step: 9
Training loss: 2.129958152770996
Validation loss: 2.0110415120919547

Epoch: 5| Step: 10
Training loss: 2.694225549697876
Validation loss: 2.0180902431408563

Epoch: 5| Step: 11
Training loss: 2.4422473907470703
Validation loss: 2.0202173988024392

Epoch: 103| Step: 0
Training loss: 1.9987990856170654
Validation loss: 2.0190154314041138

Epoch: 5| Step: 1
Training loss: 2.054922580718994
Validation loss: 2.0308619687954583

Epoch: 5| Step: 2
Training loss: 2.347202777862549
Validation loss: 2.0206266939640045

Epoch: 5| Step: 3
Training loss: 2.390876054763794
Validation loss: 2.023403227329254

Epoch: 5| Step: 4
Training loss: 1.5880110263824463
Validation loss: 2.0280690838893256

Epoch: 5| Step: 5
Training loss: 1.8380777835845947
Validation loss: 2.0199217597643533

Epoch: 5| Step: 6
Training loss: 2.477062940597534
Validation loss: 2.0071992029746375

Epoch: 5| Step: 7
Training loss: 1.920993447303772
Validation loss: 2.015155464410782

Epoch: 5| Step: 8
Training loss: 2.7248425483703613
Validation loss: 2.0222450296084085

Epoch: 5| Step: 9
Training loss: 2.1862261295318604
Validation loss: 2.023870741327604

Epoch: 5| Step: 10
Training loss: 2.108032703399658
Validation loss: 2.0131861865520477

Epoch: 5| Step: 11
Training loss: 2.053618907928467
Validation loss: 2.0190714548031488

Epoch: 104| Step: 0
Training loss: 2.3463332653045654
Validation loss: 2.0096528033415475

Epoch: 5| Step: 1
Training loss: 2.296072006225586
Validation loss: 2.009546771645546

Epoch: 5| Step: 2
Training loss: 1.9577674865722656
Validation loss: 2.0193466544151306

Epoch: 5| Step: 3
Training loss: 2.2864365577697754
Validation loss: 2.0080641160408654

Epoch: 5| Step: 4
Training loss: 2.2614309787750244
Validation loss: 2.0208850552638373

Epoch: 5| Step: 5
Training loss: 2.0484554767608643
Validation loss: 2.0149545470873513

Epoch: 5| Step: 6
Training loss: 2.4773545265197754
Validation loss: 2.01464473704497

Epoch: 5| Step: 7
Training loss: 2.069871425628662
Validation loss: 2.01423849662145

Epoch: 5| Step: 8
Training loss: 2.2107768058776855
Validation loss: 2.0260946502288184

Epoch: 5| Step: 9
Training loss: 2.1388802528381348
Validation loss: 2.023305187622706

Epoch: 5| Step: 10
Training loss: 1.611825942993164
Validation loss: 2.0225749164819717

Epoch: 5| Step: 11
Training loss: 1.0812814235687256
Validation loss: 2.0349810421466827

Epoch: 105| Step: 0
Training loss: 2.5995285511016846
Validation loss: 2.0297111769517264

Epoch: 5| Step: 1
Training loss: 2.3123881816864014
Validation loss: 2.027727857232094

Epoch: 5| Step: 2
Training loss: 2.4825387001037598
Validation loss: 2.0271312991778054

Epoch: 5| Step: 3
Training loss: 1.904486894607544
Validation loss: 2.019394482175509

Epoch: 5| Step: 4
Training loss: 2.373849630355835
Validation loss: 2.031070570151011

Epoch: 5| Step: 5
Training loss: 1.7358198165893555
Validation loss: 2.020104303956032

Epoch: 5| Step: 6
Training loss: 2.2900123596191406
Validation loss: 2.019884059826533

Epoch: 5| Step: 7
Training loss: 1.5574724674224854
Validation loss: 2.0305592318375907

Epoch: 5| Step: 8
Training loss: 1.2363502979278564
Validation loss: 2.0312168995539346

Epoch: 5| Step: 9
Training loss: 2.676013708114624
Validation loss: 2.025193671385447

Epoch: 5| Step: 10
Training loss: 2.280799388885498
Validation loss: 2.0213743398586907

Epoch: 5| Step: 11
Training loss: 2.2854065895080566
Validation loss: 2.0324138154586158

Epoch: 106| Step: 0
Training loss: 1.9125001430511475
Validation loss: 2.024577190478643

Epoch: 5| Step: 1
Training loss: 1.5345869064331055
Validation loss: 2.01467435558637

Epoch: 5| Step: 2
Training loss: 1.9581152200698853
Validation loss: 2.020685056845347

Epoch: 5| Step: 3
Training loss: 1.9177614450454712
Validation loss: 2.0032102465629578

Epoch: 5| Step: 4
Training loss: 2.462509870529175
Validation loss: 2.020409420132637

Epoch: 5| Step: 5
Training loss: 2.529555559158325
Validation loss: 2.016403297583262

Epoch: 5| Step: 6
Training loss: 2.363407611846924
Validation loss: 2.008019338051478

Epoch: 5| Step: 7
Training loss: 2.0233702659606934
Validation loss: 2.005870819091797

Epoch: 5| Step: 8
Training loss: 2.4030961990356445
Validation loss: 1.9965172310670216

Epoch: 5| Step: 9
Training loss: 2.221128463745117
Validation loss: 2.0079017281532288

Epoch: 5| Step: 10
Training loss: 2.146792411804199
Validation loss: 2.0026835501194

Epoch: 5| Step: 11
Training loss: 1.937171459197998
Validation loss: 2.001517131924629

Epoch: 107| Step: 0
Training loss: 1.5188207626342773
Validation loss: 2.0056525568167367

Epoch: 5| Step: 1
Training loss: 2.312283992767334
Validation loss: 2.0048562784989676

Epoch: 5| Step: 2
Training loss: 1.826829195022583
Validation loss: 2.007171223560969

Epoch: 5| Step: 3
Training loss: 2.2238056659698486
Validation loss: 2.008819431066513

Epoch: 5| Step: 4
Training loss: 2.2273943424224854
Validation loss: 2.01227106153965

Epoch: 5| Step: 5
Training loss: 2.0858500003814697
Validation loss: 2.003331412871679

Epoch: 5| Step: 6
Training loss: 1.9249318838119507
Validation loss: 2.004361152648926

Epoch: 5| Step: 7
Training loss: 2.4155986309051514
Validation loss: 2.0067911396423974

Epoch: 5| Step: 8
Training loss: 2.2735307216644287
Validation loss: 2.009387801090876

Epoch: 5| Step: 9
Training loss: 2.334735155105591
Validation loss: 2.000480994582176

Epoch: 5| Step: 10
Training loss: 2.0468497276306152
Validation loss: 2.0007640520731607

Epoch: 5| Step: 11
Training loss: 2.6951189041137695
Validation loss: 2.0169229904810586

Epoch: 108| Step: 0
Training loss: 2.6508278846740723
Validation loss: 2.0318939288457236

Epoch: 5| Step: 1
Training loss: 2.042100667953491
Validation loss: 2.057346041003863

Epoch: 5| Step: 2
Training loss: 1.9352039098739624
Validation loss: 2.061529502272606

Epoch: 5| Step: 3
Training loss: 2.346997022628784
Validation loss: 2.0384265879789987

Epoch: 5| Step: 4
Training loss: 1.864126205444336
Validation loss: 2.025035878022512

Epoch: 5| Step: 5
Training loss: 1.9554780721664429
Validation loss: 2.0108512341976166

Epoch: 5| Step: 6
Training loss: 2.2517199516296387
Validation loss: 2.009440168738365

Epoch: 5| Step: 7
Training loss: 2.3220818042755127
Validation loss: 2.000037262837092

Epoch: 5| Step: 8
Training loss: 2.091336488723755
Validation loss: 2.0000392695267997

Epoch: 5| Step: 9
Training loss: 2.3454275131225586
Validation loss: 2.008749008178711

Epoch: 5| Step: 10
Training loss: 2.0016391277313232
Validation loss: 2.020202855269114

Epoch: 5| Step: 11
Training loss: 2.3793156147003174
Validation loss: 2.0163491566975913

Epoch: 109| Step: 0
Training loss: 2.6428253650665283
Validation loss: 2.0223283221324286

Epoch: 5| Step: 1
Training loss: 2.2827744483947754
Validation loss: 2.0282255311807

Epoch: 5| Step: 2
Training loss: 2.030789852142334
Validation loss: 2.0326924373706183

Epoch: 5| Step: 3
Training loss: 2.31394624710083
Validation loss: 2.0296748131513596

Epoch: 5| Step: 4
Training loss: 2.428687334060669
Validation loss: 2.0265088776747384

Epoch: 5| Step: 5
Training loss: 2.148930549621582
Validation loss: 2.0296168526013694

Epoch: 5| Step: 6
Training loss: 1.955243706703186
Validation loss: 2.0257092267274857

Epoch: 5| Step: 7
Training loss: 1.6281521320343018
Validation loss: 2.0243797649939856

Epoch: 5| Step: 8
Training loss: 2.4546921253204346
Validation loss: 2.0215450624624887

Epoch: 5| Step: 9
Training loss: 1.8491199016571045
Validation loss: 2.0196998566389084

Epoch: 5| Step: 10
Training loss: 2.4003758430480957
Validation loss: 2.014655813574791

Epoch: 5| Step: 11
Training loss: 1.1957874298095703
Validation loss: 2.0112775017817817

Epoch: 110| Step: 0
Training loss: 2.399700164794922
Validation loss: 2.010446324944496

Epoch: 5| Step: 1
Training loss: 2.420516014099121
Validation loss: 1.9966925034920375

Epoch: 5| Step: 2
Training loss: 2.1241579055786133
Validation loss: 1.9923928827047348

Epoch: 5| Step: 3
Training loss: 2.0581467151641846
Validation loss: 1.997012346982956

Epoch: 5| Step: 4
Training loss: 1.9175935983657837
Validation loss: 2.0103162775437036

Epoch: 5| Step: 5
Training loss: 2.017942428588867
Validation loss: 2.008401249845823

Epoch: 5| Step: 6
Training loss: 2.107175588607788
Validation loss: 2.0082389265298843

Epoch: 5| Step: 7
Training loss: 2.092708110809326
Validation loss: 2.0190868029991784

Epoch: 5| Step: 8
Training loss: 2.512683391571045
Validation loss: 2.0114842454592385

Epoch: 5| Step: 9
Training loss: 1.933885931968689
Validation loss: 2.0106767465670905

Epoch: 5| Step: 10
Training loss: 2.1920313835144043
Validation loss: 1.9964050352573395

Epoch: 5| Step: 11
Training loss: 2.5869176387786865
Validation loss: 1.9924843907356262

Epoch: 111| Step: 0
Training loss: 1.7740850448608398
Validation loss: 1.9948795437812805

Epoch: 5| Step: 1
Training loss: 1.94925856590271
Validation loss: 2.0284166634082794

Epoch: 5| Step: 2
Training loss: 2.3575491905212402
Validation loss: 2.029178654154142

Epoch: 5| Step: 3
Training loss: 2.4070606231689453
Validation loss: 2.0376047442356744

Epoch: 5| Step: 4
Training loss: 1.6889922618865967
Validation loss: 2.0404551178216934

Epoch: 5| Step: 5
Training loss: 2.224456310272217
Validation loss: 2.0369808872540793

Epoch: 5| Step: 6
Training loss: 2.006884813308716
Validation loss: 2.039455994963646

Epoch: 5| Step: 7
Training loss: 2.2478671073913574
Validation loss: 2.04133810599645

Epoch: 5| Step: 8
Training loss: 2.101741075515747
Validation loss: 2.054367537299792

Epoch: 5| Step: 9
Training loss: 2.475050687789917
Validation loss: 2.0426465372244516

Epoch: 5| Step: 10
Training loss: 2.5955872535705566
Validation loss: 2.0503086696068444

Epoch: 5| Step: 11
Training loss: 3.48842716217041
Validation loss: 2.0499042719602585

Epoch: 112| Step: 0
Training loss: 2.1883881092071533
Validation loss: 2.0483160664637885

Epoch: 5| Step: 1
Training loss: 2.4992356300354004
Validation loss: 2.041140059630076

Epoch: 5| Step: 2
Training loss: 2.466071128845215
Validation loss: 2.0412473181883493

Epoch: 5| Step: 3
Training loss: 2.1806766986846924
Validation loss: 2.0343925654888153

Epoch: 5| Step: 4
Training loss: 1.845014214515686
Validation loss: 2.0268716563781104

Epoch: 5| Step: 5
Training loss: 2.128573179244995
Validation loss: 2.0248575657606125

Epoch: 5| Step: 6
Training loss: 2.118500232696533
Validation loss: 2.0164254754781723

Epoch: 5| Step: 7
Training loss: 2.170485019683838
Validation loss: 2.00229874253273

Epoch: 5| Step: 8
Training loss: 2.087000608444214
Validation loss: 1.9999495695034664

Epoch: 5| Step: 9
Training loss: 2.2913949489593506
Validation loss: 2.0079220781723657

Epoch: 5| Step: 10
Training loss: 2.0886430740356445
Validation loss: 2.0054066876570382

Epoch: 5| Step: 11
Training loss: 2.821153402328491
Validation loss: 1.9960667043924332

Epoch: 113| Step: 0
Training loss: 1.8879591226577759
Validation loss: 2.001347064971924

Epoch: 5| Step: 1
Training loss: 2.050039529800415
Validation loss: 1.9982944031556447

Epoch: 5| Step: 2
Training loss: 2.662317991256714
Validation loss: 1.995895932118098

Epoch: 5| Step: 3
Training loss: 2.717207193374634
Validation loss: 1.9953099489212036

Epoch: 5| Step: 4
Training loss: 1.9441421031951904
Validation loss: 1.9934384226799011

Epoch: 5| Step: 5
Training loss: 1.936095952987671
Validation loss: 1.9840815911690395

Epoch: 5| Step: 6
Training loss: 2.279783248901367
Validation loss: 1.9966771999994914

Epoch: 5| Step: 7
Training loss: 2.1421046257019043
Validation loss: 1.9969517240921657

Epoch: 5| Step: 8
Training loss: 2.083414316177368
Validation loss: 1.9965437004963558

Epoch: 5| Step: 9
Training loss: 2.2865421772003174
Validation loss: 1.9968638966480892

Epoch: 5| Step: 10
Training loss: 1.7772995233535767
Validation loss: 1.998618299762408

Epoch: 5| Step: 11
Training loss: 1.5126633644104004
Validation loss: 2.0064383894205093

Epoch: 114| Step: 0
Training loss: 1.9029709100723267
Validation loss: 2.0106702595949173

Epoch: 5| Step: 1
Training loss: 1.9444234371185303
Validation loss: 2.0109032640854516

Epoch: 5| Step: 2
Training loss: 2.2967419624328613
Validation loss: 2.034879595041275

Epoch: 5| Step: 3
Training loss: 1.7331502437591553
Validation loss: 2.034360701839129

Epoch: 5| Step: 4
Training loss: 2.426264762878418
Validation loss: 2.0407265524069467

Epoch: 5| Step: 5
Training loss: 2.316143751144409
Validation loss: 2.037242040038109

Epoch: 5| Step: 6
Training loss: 1.9796240329742432
Validation loss: 2.034306471546491

Epoch: 5| Step: 7
Training loss: 2.5444748401641846
Validation loss: 2.014714941382408

Epoch: 5| Step: 8
Training loss: 2.639702081680298
Validation loss: 2.0206200182437897

Epoch: 5| Step: 9
Training loss: 2.1566262245178223
Validation loss: 2.003377581636111

Epoch: 5| Step: 10
Training loss: 1.8327465057373047
Validation loss: 2.0101181914409003

Epoch: 5| Step: 11
Training loss: 1.415597915649414
Validation loss: 1.9993482033411663

Epoch: 115| Step: 0
Training loss: 2.2455832958221436
Validation loss: 2.0126775006453195

Epoch: 5| Step: 1
Training loss: 1.648097276687622
Validation loss: 2.002352332075437

Epoch: 5| Step: 2
Training loss: 2.702239513397217
Validation loss: 2.0101528068383536

Epoch: 5| Step: 3
Training loss: 1.7470905780792236
Validation loss: 2.0074584037065506

Epoch: 5| Step: 4
Training loss: 1.979000449180603
Validation loss: 2.002410978078842

Epoch: 5| Step: 5
Training loss: 2.2939066886901855
Validation loss: 2.0089625865221024

Epoch: 5| Step: 6
Training loss: 2.281057834625244
Validation loss: 2.010766019423803

Epoch: 5| Step: 7
Training loss: 2.183995008468628
Validation loss: 2.010375216603279

Epoch: 5| Step: 8
Training loss: 1.9497668743133545
Validation loss: 2.0204870651165643

Epoch: 5| Step: 9
Training loss: 1.7551803588867188
Validation loss: 2.0176559537649155

Epoch: 5| Step: 10
Training loss: 2.303757429122925
Validation loss: 2.013721227645874

Epoch: 5| Step: 11
Training loss: 3.4910240173339844
Validation loss: 2.0203049828608832

Epoch: 116| Step: 0
Training loss: 2.038402557373047
Validation loss: 2.015206426382065

Epoch: 5| Step: 1
Training loss: 2.0237033367156982
Validation loss: 2.024703030784925

Epoch: 5| Step: 2
Training loss: 2.023040294647217
Validation loss: 2.011751413345337

Epoch: 5| Step: 3
Training loss: 2.481393575668335
Validation loss: 2.0300885985294976

Epoch: 5| Step: 4
Training loss: 1.8895457983016968
Validation loss: 2.0181434949239097

Epoch: 5| Step: 5
Training loss: 2.288862705230713
Validation loss: 2.020891785621643

Epoch: 5| Step: 6
Training loss: 2.1695334911346436
Validation loss: 2.0117292950550714

Epoch: 5| Step: 7
Training loss: 2.3208489418029785
Validation loss: 2.015438437461853

Epoch: 5| Step: 8
Training loss: 1.4201021194458008
Validation loss: 2.0173267225424447

Epoch: 5| Step: 9
Training loss: 2.1197056770324707
Validation loss: 2.0084280918041864

Epoch: 5| Step: 10
Training loss: 2.5502779483795166
Validation loss: 2.0179930478334427

Epoch: 5| Step: 11
Training loss: 2.158982276916504
Validation loss: 2.0081551671028137

Epoch: 117| Step: 0
Training loss: 2.3015942573547363
Validation loss: 2.0011405497789383

Epoch: 5| Step: 1
Training loss: 2.8050951957702637
Validation loss: 2.0041521986325583

Epoch: 5| Step: 2
Training loss: 1.8408924341201782
Validation loss: 2.0001783967018127

Epoch: 5| Step: 3
Training loss: 2.1406147480010986
Validation loss: 1.9992729723453522

Epoch: 5| Step: 4
Training loss: 1.687687635421753
Validation loss: 2.005839149157206

Epoch: 5| Step: 5
Training loss: 2.5280046463012695
Validation loss: 2.0001854449510574

Epoch: 5| Step: 6
Training loss: 1.7881196737289429
Validation loss: 2.0016975104808807

Epoch: 5| Step: 7
Training loss: 1.9097179174423218
Validation loss: 1.994706705212593

Epoch: 5| Step: 8
Training loss: 2.1368918418884277
Validation loss: 1.9942994862794876

Epoch: 5| Step: 9
Training loss: 2.1265454292297363
Validation loss: 1.9984342356522877

Epoch: 5| Step: 10
Training loss: 1.9125804901123047
Validation loss: 1.9962650537490845

Epoch: 5| Step: 11
Training loss: 2.165219306945801
Validation loss: 2.0110684037208557

Epoch: 118| Step: 0
Training loss: 2.5294950008392334
Validation loss: 2.016463026404381

Epoch: 5| Step: 1
Training loss: 2.1516470909118652
Validation loss: 2.042503555615743

Epoch: 5| Step: 2
Training loss: 2.1454129219055176
Validation loss: 2.029958188533783

Epoch: 5| Step: 3
Training loss: 2.278529644012451
Validation loss: 2.033534159262975

Epoch: 5| Step: 4
Training loss: 1.9133106470108032
Validation loss: 2.0351947794357934

Epoch: 5| Step: 5
Training loss: 1.9286445379257202
Validation loss: 2.0388325601816177

Epoch: 5| Step: 6
Training loss: 1.3787028789520264
Validation loss: 2.0176277657349906

Epoch: 5| Step: 7
Training loss: 2.294039487838745
Validation loss: 2.0176661560932794

Epoch: 5| Step: 8
Training loss: 2.7060327529907227
Validation loss: 2.000477895140648

Epoch: 5| Step: 9
Training loss: 2.4146296977996826
Validation loss: 2.0107129563887916

Epoch: 5| Step: 10
Training loss: 1.892068862915039
Validation loss: 2.0087439020474753

Epoch: 5| Step: 11
Training loss: 2.23665189743042
Validation loss: 2.000370815396309

Epoch: 119| Step: 0
Training loss: 2.48909068107605
Validation loss: 2.0060956478118896

Epoch: 5| Step: 1
Training loss: 2.2435431480407715
Validation loss: 2.0018098205327988

Epoch: 5| Step: 2
Training loss: 2.522773265838623
Validation loss: 2.0041474054257074

Epoch: 5| Step: 3
Training loss: 2.106778144836426
Validation loss: 2.00346410771211

Epoch: 5| Step: 4
Training loss: 1.9323240518569946
Validation loss: 1.9990757952133815

Epoch: 5| Step: 5
Training loss: 1.8203452825546265
Validation loss: 2.004941314458847

Epoch: 5| Step: 6
Training loss: 2.2668256759643555
Validation loss: 2.0043392380078635

Epoch: 5| Step: 7
Training loss: 2.0455589294433594
Validation loss: 2.0100211650133133

Epoch: 5| Step: 8
Training loss: 2.1874775886535645
Validation loss: 2.0023443698883057

Epoch: 5| Step: 9
Training loss: 2.078774929046631
Validation loss: 2.0089575201272964

Epoch: 5| Step: 10
Training loss: 1.9316351413726807
Validation loss: 2.0133160452047982

Epoch: 5| Step: 11
Training loss: 1.4601434469223022
Validation loss: 2.004874994357427

Epoch: 120| Step: 0
Training loss: 2.342874765396118
Validation loss: 2.0105280677477517

Epoch: 5| Step: 1
Training loss: 2.3639912605285645
Validation loss: 2.0101446410020194

Epoch: 5| Step: 2
Training loss: 2.146503448486328
Validation loss: 1.9978845318158467

Epoch: 5| Step: 3
Training loss: 1.5847663879394531
Validation loss: 2.0070639103651047

Epoch: 5| Step: 4
Training loss: 2.423626184463501
Validation loss: 2.0007103234529495

Epoch: 5| Step: 5
Training loss: 1.6438106298446655
Validation loss: 2.005694588025411

Epoch: 5| Step: 6
Training loss: 1.9439404010772705
Validation loss: 2.0083836764097214

Epoch: 5| Step: 7
Training loss: 1.7184330224990845
Validation loss: 2.0086449533700943

Epoch: 5| Step: 8
Training loss: 2.722282886505127
Validation loss: 2.0048360228538513

Epoch: 5| Step: 9
Training loss: 2.214914321899414
Validation loss: 2.0008094112078347

Epoch: 5| Step: 10
Training loss: 2.2873082160949707
Validation loss: 2.013700673977534

Epoch: 5| Step: 11
Training loss: 1.3531959056854248
Validation loss: 2.011821592847506

Epoch: 121| Step: 0
Training loss: 2.10853910446167
Validation loss: 2.0106989492972693

Epoch: 5| Step: 1
Training loss: 2.1173367500305176
Validation loss: 2.0193286736806235

Epoch: 5| Step: 2
Training loss: 2.1164863109588623
Validation loss: 2.011916925509771

Epoch: 5| Step: 3
Training loss: 1.9453903436660767
Validation loss: 2.010951891541481

Epoch: 5| Step: 4
Training loss: 1.6600399017333984
Validation loss: 2.0355707009633384

Epoch: 5| Step: 5
Training loss: 2.1018357276916504
Validation loss: 2.0301860719919205

Epoch: 5| Step: 6
Training loss: 2.217919111251831
Validation loss: 2.0420738061269126

Epoch: 5| Step: 7
Training loss: 1.7021725177764893
Validation loss: 2.041855663061142

Epoch: 5| Step: 8
Training loss: 2.689103841781616
Validation loss: 2.0257220367590585

Epoch: 5| Step: 9
Training loss: 2.419107437133789
Validation loss: 2.0188394635915756

Epoch: 5| Step: 10
Training loss: 2.073913097381592
Validation loss: 2.0211567481358848

Epoch: 5| Step: 11
Training loss: 3.7548232078552246
Validation loss: 2.013096049427986

Epoch: 122| Step: 0
Training loss: 2.484853982925415
Validation loss: 2.00853268802166

Epoch: 5| Step: 1
Training loss: 2.0090603828430176
Validation loss: 2.029824515183767

Epoch: 5| Step: 2
Training loss: 2.467282295227051
Validation loss: 2.0307086209456124

Epoch: 5| Step: 3
Training loss: 2.65812349319458
Validation loss: 2.038307771086693

Epoch: 5| Step: 4
Training loss: 2.428178310394287
Validation loss: 2.0400205105543137

Epoch: 5| Step: 5
Training loss: 1.665487289428711
Validation loss: 2.0464313675959906

Epoch: 5| Step: 6
Training loss: 2.2107670307159424
Validation loss: 2.048387552301089

Epoch: 5| Step: 7
Training loss: 1.9078943729400635
Validation loss: 2.05110232035319

Epoch: 5| Step: 8
Training loss: 2.309335231781006
Validation loss: 2.053766975800196

Epoch: 5| Step: 9
Training loss: 2.0427627563476562
Validation loss: 2.0559917986392975

Epoch: 5| Step: 10
Training loss: 1.9773857593536377
Validation loss: 2.059212932984034

Epoch: 5| Step: 11
Training loss: 2.1192493438720703
Validation loss: 2.056051641702652

Epoch: 123| Step: 0
Training loss: 2.666569948196411
Validation loss: 2.0526297440131507

Epoch: 5| Step: 1
Training loss: 1.809971570968628
Validation loss: 2.052174543341001

Epoch: 5| Step: 2
Training loss: 2.433002471923828
Validation loss: 2.056999852259954

Epoch: 5| Step: 3
Training loss: 2.1327338218688965
Validation loss: 2.0487494617700577

Epoch: 5| Step: 4
Training loss: 1.7949373722076416
Validation loss: 2.047648176550865

Epoch: 5| Step: 5
Training loss: 2.3244175910949707
Validation loss: 2.0483560959498086

Epoch: 5| Step: 6
Training loss: 2.2482235431671143
Validation loss: 2.041765903433164

Epoch: 5| Step: 7
Training loss: 2.2892496585845947
Validation loss: 2.0404638200998306

Epoch: 5| Step: 8
Training loss: 2.279731273651123
Validation loss: 2.043683926264445

Epoch: 5| Step: 9
Training loss: 1.7961084842681885
Validation loss: 2.039754798014959

Epoch: 5| Step: 10
Training loss: 2.4055910110473633
Validation loss: 2.0383654286464057

Epoch: 5| Step: 11
Training loss: 2.2699971199035645
Validation loss: 2.031348759929339

Epoch: 124| Step: 0
Training loss: 2.279177188873291
Validation loss: 2.0252150098482766

Epoch: 5| Step: 1
Training loss: 2.2967119216918945
Validation loss: 2.017651076118151

Epoch: 5| Step: 2
Training loss: 2.102633476257324
Validation loss: 2.0140238255262375

Epoch: 5| Step: 3
Training loss: 2.0680508613586426
Validation loss: 2.02009055018425

Epoch: 5| Step: 4
Training loss: 1.9246747493743896
Validation loss: 2.017938901980718

Epoch: 5| Step: 5
Training loss: 2.242305278778076
Validation loss: 2.011969784895579

Epoch: 5| Step: 6
Training loss: 1.9556715488433838
Validation loss: 2.016159320871035

Epoch: 5| Step: 7
Training loss: 2.0291385650634766
Validation loss: 2.0133115549882254

Epoch: 5| Step: 8
Training loss: 2.096503257751465
Validation loss: 2.016073231895765

Epoch: 5| Step: 9
Training loss: 2.461498260498047
Validation loss: 2.024495075146357

Epoch: 5| Step: 10
Training loss: 2.063664674758911
Validation loss: 2.032658795515696

Epoch: 5| Step: 11
Training loss: 2.2838082313537598
Validation loss: 2.030219475428263

Epoch: 125| Step: 0
Training loss: 2.01080060005188
Validation loss: 2.0271466920773187

Epoch: 5| Step: 1
Training loss: 1.9423106908798218
Validation loss: 2.024103502432505

Epoch: 5| Step: 2
Training loss: 2.022481679916382
Validation loss: 2.0337185660998025

Epoch: 5| Step: 3
Training loss: 2.50443696975708
Validation loss: 2.024772052963575

Epoch: 5| Step: 4
Training loss: 2.0742335319519043
Validation loss: 2.027686263124148

Epoch: 5| Step: 5
Training loss: 2.530667304992676
Validation loss: 2.032204955816269

Epoch: 5| Step: 6
Training loss: 2.0032401084899902
Validation loss: 2.026455834507942

Epoch: 5| Step: 7
Training loss: 2.037666082382202
Validation loss: 2.0311766068140664

Epoch: 5| Step: 8
Training loss: 1.9607772827148438
Validation loss: 2.0289090275764465

Epoch: 5| Step: 9
Training loss: 2.3783118724823
Validation loss: 2.02988338470459

Epoch: 5| Step: 10
Training loss: 1.6999391317367554
Validation loss: 2.0294720182816186

Epoch: 5| Step: 11
Training loss: 1.920810341835022
Validation loss: 2.0229825526475906

Epoch: 126| Step: 0
Training loss: 2.078294038772583
Validation loss: 2.0222329596678414

Epoch: 5| Step: 1
Training loss: 2.1551918983459473
Validation loss: 2.019464229544004

Epoch: 5| Step: 2
Training loss: 2.1099212169647217
Validation loss: 2.014561494191488

Epoch: 5| Step: 3
Training loss: 2.351602554321289
Validation loss: 2.0180397431055703

Epoch: 5| Step: 4
Training loss: 2.352727174758911
Validation loss: 2.0125469317038855

Epoch: 5| Step: 5
Training loss: 2.0047643184661865
Validation loss: 2.014245996872584

Epoch: 5| Step: 6
Training loss: 2.213714122772217
Validation loss: 2.007733474175135

Epoch: 5| Step: 7
Training loss: 2.0819497108459473
Validation loss: 2.017743249734243

Epoch: 5| Step: 8
Training loss: 1.6365886926651
Validation loss: 2.018246442079544

Epoch: 5| Step: 9
Training loss: 2.182563543319702
Validation loss: 2.0103723059097924

Epoch: 5| Step: 10
Training loss: 1.9467849731445312
Validation loss: 2.034056231379509

Epoch: 5| Step: 11
Training loss: 1.8638100624084473
Validation loss: 2.020866612593333

Epoch: 127| Step: 0
Training loss: 1.2408899068832397
Validation loss: 2.010323310891787

Epoch: 5| Step: 1
Training loss: 2.4466381072998047
Validation loss: 2.018567522366842

Epoch: 5| Step: 2
Training loss: 2.0230376720428467
Validation loss: 2.0271117885907493

Epoch: 5| Step: 3
Training loss: 1.9619919061660767
Validation loss: 2.0156716157992682

Epoch: 5| Step: 4
Training loss: 1.8031165599822998
Validation loss: 2.018329049150149

Epoch: 5| Step: 5
Training loss: 2.2914066314697266
Validation loss: 2.025173768401146

Epoch: 5| Step: 6
Training loss: 2.331381320953369
Validation loss: 2.020200068751971

Epoch: 5| Step: 7
Training loss: 2.346923589706421
Validation loss: 2.020920758446058

Epoch: 5| Step: 8
Training loss: 2.2554330825805664
Validation loss: 2.0170746395985284

Epoch: 5| Step: 9
Training loss: 2.4141762256622314
Validation loss: 2.0208046038945517

Epoch: 5| Step: 10
Training loss: 2.1181445121765137
Validation loss: 2.0112721224625907

Epoch: 5| Step: 11
Training loss: 1.2025086879730225
Validation loss: 2.0125419944524765

Epoch: 128| Step: 0
Training loss: 2.161991596221924
Validation loss: 2.011485675970713

Epoch: 5| Step: 1
Training loss: 2.1317522525787354
Validation loss: 2.0120936135450997

Epoch: 5| Step: 2
Training loss: 1.870295763015747
Validation loss: 2.0122100561857224

Epoch: 5| Step: 3
Training loss: 2.646848201751709
Validation loss: 2.0112504909435907

Epoch: 5| Step: 4
Training loss: 1.7324777841567993
Validation loss: 2.0150520404179892

Epoch: 5| Step: 5
Training loss: 1.958993911743164
Validation loss: 2.004260783394178

Epoch: 5| Step: 6
Training loss: 2.0711419582366943
Validation loss: 2.0209145148595176

Epoch: 5| Step: 7
Training loss: 2.39892578125
Validation loss: 2.0093975315491357

Epoch: 5| Step: 8
Training loss: 2.357434034347534
Validation loss: 2.007009079058965

Epoch: 5| Step: 9
Training loss: 2.196298837661743
Validation loss: 2.0102212131023407

Epoch: 5| Step: 10
Training loss: 1.533187747001648
Validation loss: 2.016346459587415

Epoch: 5| Step: 11
Training loss: 2.7140426635742188
Validation loss: 2.011776531736056

Epoch: 129| Step: 0
Training loss: 1.7909355163574219
Validation loss: 2.014275406797727

Epoch: 5| Step: 1
Training loss: 2.4311165809631348
Validation loss: 2.0135273734728494

Epoch: 5| Step: 2
Training loss: 1.9288318157196045
Validation loss: 2.002605135242144

Epoch: 5| Step: 3
Training loss: 2.068373918533325
Validation loss: 2.015736162662506

Epoch: 5| Step: 4
Training loss: 2.163600444793701
Validation loss: 2.0140826354424157

Epoch: 5| Step: 5
Training loss: 1.8949661254882812
Validation loss: 2.0081511487563453

Epoch: 5| Step: 6
Training loss: 2.4570021629333496
Validation loss: 2.0111304422219596

Epoch: 5| Step: 7
Training loss: 2.6401848793029785
Validation loss: 2.0094002882639566

Epoch: 5| Step: 8
Training loss: 2.2328526973724365
Validation loss: 2.0074131240447364

Epoch: 5| Step: 9
Training loss: 1.75002920627594
Validation loss: 2.009259060025215

Epoch: 5| Step: 10
Training loss: 1.8637861013412476
Validation loss: 2.0170183181762695

Epoch: 5| Step: 11
Training loss: 1.316602110862732
Validation loss: 2.0180543114741645

Epoch: 130| Step: 0
Training loss: 2.355236530303955
Validation loss: 2.026563952366511

Epoch: 5| Step: 1
Training loss: 1.8985564708709717
Validation loss: 2.039236848553022

Epoch: 5| Step: 2
Training loss: 2.057936906814575
Validation loss: 2.043477634588877

Epoch: 5| Step: 3
Training loss: 1.9596843719482422
Validation loss: 2.047032425800959

Epoch: 5| Step: 4
Training loss: 1.9841581583023071
Validation loss: 2.035011132558187

Epoch: 5| Step: 5
Training loss: 1.937213659286499
Validation loss: 2.0388499895731607

Epoch: 5| Step: 6
Training loss: 2.3140759468078613
Validation loss: 2.03633118669192

Epoch: 5| Step: 7
Training loss: 2.2435708045959473
Validation loss: 2.024572198589643

Epoch: 5| Step: 8
Training loss: 2.5549116134643555
Validation loss: 2.0234498182932534

Epoch: 5| Step: 9
Training loss: 1.415263056755066
Validation loss: 2.023536632458369

Epoch: 5| Step: 10
Training loss: 2.4847819805145264
Validation loss: 2.0185796171426773

Epoch: 5| Step: 11
Training loss: 1.4825011491775513
Validation loss: 2.0214681873718896

Epoch: 131| Step: 0
Training loss: 1.9213275909423828
Validation loss: 2.0119834740956626

Epoch: 5| Step: 1
Training loss: 2.026954174041748
Validation loss: 2.012778654694557

Epoch: 5| Step: 2
Training loss: 2.1894490718841553
Validation loss: 2.019959112008413

Epoch: 5| Step: 3
Training loss: 2.0660548210144043
Validation loss: 2.033380225300789

Epoch: 5| Step: 4
Training loss: 2.235015869140625
Validation loss: 2.0324612309535346

Epoch: 5| Step: 5
Training loss: 2.9782283306121826
Validation loss: 2.0343799193700156

Epoch: 5| Step: 6
Training loss: 1.8170077800750732
Validation loss: 2.0436297555764518

Epoch: 5| Step: 7
Training loss: 1.7012428045272827
Validation loss: 2.0362296352783837

Epoch: 5| Step: 8
Training loss: 2.057520866394043
Validation loss: 2.043765793244044

Epoch: 5| Step: 9
Training loss: 3.0346717834472656
Validation loss: 2.034927010536194

Epoch: 5| Step: 10
Training loss: 1.8353469371795654
Validation loss: 2.0389006237188974

Epoch: 5| Step: 11
Training loss: 2.3072757720947266
Validation loss: 2.0312459071477256

Epoch: 132| Step: 0
Training loss: 2.2241268157958984
Validation loss: 2.025772993763288

Epoch: 5| Step: 1
Training loss: 2.072984218597412
Validation loss: 2.0252873649199805

Epoch: 5| Step: 2
Training loss: 1.9101909399032593
Validation loss: 2.0178522914648056

Epoch: 5| Step: 3
Training loss: 2.0853922367095947
Validation loss: 2.0155724386374154

Epoch: 5| Step: 4
Training loss: 2.2972254753112793
Validation loss: 2.0034702916940055

Epoch: 5| Step: 5
Training loss: 2.1548452377319336
Validation loss: 2.0006030599276223

Epoch: 5| Step: 6
Training loss: 2.060796022415161
Validation loss: 2.0062877982854843

Epoch: 5| Step: 7
Training loss: 1.9167226552963257
Validation loss: 2.011153762539228

Epoch: 5| Step: 8
Training loss: 2.2320189476013184
Validation loss: 2.0118892888228097

Epoch: 5| Step: 9
Training loss: 2.224012851715088
Validation loss: 2.0089300821224847

Epoch: 5| Step: 10
Training loss: 2.411360502243042
Validation loss: 2.0075850735108056

Epoch: 5| Step: 11
Training loss: 1.7301467657089233
Validation loss: 2.0112790067990622

Epoch: 133| Step: 0
Training loss: 1.5298752784729004
Validation loss: 2.0074799805879593

Epoch: 5| Step: 1
Training loss: 1.7124660015106201
Validation loss: 2.0157574067513147

Epoch: 5| Step: 2
Training loss: 2.236182689666748
Validation loss: 2.0223691711823144

Epoch: 5| Step: 3
Training loss: 2.5039010047912598
Validation loss: 2.0172593047221503

Epoch: 5| Step: 4
Training loss: 2.306546211242676
Validation loss: 2.0242557326952615

Epoch: 5| Step: 5
Training loss: 2.446805953979492
Validation loss: 2.0165784806013107

Epoch: 5| Step: 6
Training loss: 2.0525853633880615
Validation loss: 2.019081955154737

Epoch: 5| Step: 7
Training loss: 1.7765281200408936
Validation loss: 2.018360580007235

Epoch: 5| Step: 8
Training loss: 1.7865850925445557
Validation loss: 2.024954453110695

Epoch: 5| Step: 9
Training loss: 2.451483726501465
Validation loss: 2.021155426899592

Epoch: 5| Step: 10
Training loss: 2.0734310150146484
Validation loss: 2.0154028832912445

Epoch: 5| Step: 11
Training loss: 2.3354220390319824
Validation loss: 2.019421935081482

Epoch: 134| Step: 0
Training loss: 2.2847468852996826
Validation loss: 2.015353098511696

Epoch: 5| Step: 1
Training loss: 2.0974276065826416
Validation loss: 2.0130597949028015

Epoch: 5| Step: 2
Training loss: 2.0904345512390137
Validation loss: 2.0115101585785546

Epoch: 5| Step: 3
Training loss: 2.029878616333008
Validation loss: 2.012464980284373

Epoch: 5| Step: 4
Training loss: 2.3077220916748047
Validation loss: 2.01251128812631

Epoch: 5| Step: 5
Training loss: 1.7797123193740845
Validation loss: 2.0031339526176453

Epoch: 5| Step: 6
Training loss: 2.0141587257385254
Validation loss: 2.0130543410778046

Epoch: 5| Step: 7
Training loss: 1.7828359603881836
Validation loss: 2.0061114182074866

Epoch: 5| Step: 8
Training loss: 2.0189132690429688
Validation loss: 2.010695293545723

Epoch: 5| Step: 9
Training loss: 2.3413100242614746
Validation loss: 2.0235356191794076

Epoch: 5| Step: 10
Training loss: 2.3541953563690186
Validation loss: 2.0197640657424927

Epoch: 5| Step: 11
Training loss: 2.2396554946899414
Validation loss: 2.0139969090620675

Epoch: 135| Step: 0
Training loss: 2.2322516441345215
Validation loss: 2.0139022121826806

Epoch: 5| Step: 1
Training loss: 2.173428773880005
Validation loss: 2.030032972494761

Epoch: 5| Step: 2
Training loss: 1.6894832849502563
Validation loss: 2.0219421784083047

Epoch: 5| Step: 3
Training loss: 2.041764974594116
Validation loss: 2.0249080856641135

Epoch: 5| Step: 4
Training loss: 1.9634387493133545
Validation loss: 2.013905704021454

Epoch: 5| Step: 5
Training loss: 1.7316348552703857
Validation loss: 2.016430154442787

Epoch: 5| Step: 6
Training loss: 2.2971761226654053
Validation loss: 2.020329867800077

Epoch: 5| Step: 7
Training loss: 1.9243199825286865
Validation loss: 2.0148287564516068

Epoch: 5| Step: 8
Training loss: 2.44096302986145
Validation loss: 2.019751399755478

Epoch: 5| Step: 9
Training loss: 2.0815863609313965
Validation loss: 2.0111092925071716

Epoch: 5| Step: 10
Training loss: 2.128955841064453
Validation loss: 2.0098844915628433

Epoch: 5| Step: 11
Training loss: 3.1523540019989014
Validation loss: 2.012700915336609

Epoch: 136| Step: 0
Training loss: 2.379138469696045
Validation loss: 2.0159623424212136

Epoch: 5| Step: 1
Training loss: 2.051880359649658
Validation loss: 2.016192242503166

Epoch: 5| Step: 2
Training loss: 1.9268842935562134
Validation loss: 2.014003942410151

Epoch: 5| Step: 3
Training loss: 2.197460174560547
Validation loss: 2.0193677892287574

Epoch: 5| Step: 4
Training loss: 1.9896204471588135
Validation loss: 2.0264842212200165

Epoch: 5| Step: 5
Training loss: 1.9898475408554077
Validation loss: 2.032976726690928

Epoch: 5| Step: 6
Training loss: 2.4213268756866455
Validation loss: 2.0158839523792267

Epoch: 5| Step: 7
Training loss: 2.455618381500244
Validation loss: 2.0114166190226874

Epoch: 5| Step: 8
Training loss: 2.0359652042388916
Validation loss: 2.014146074652672

Epoch: 5| Step: 9
Training loss: 1.9386314153671265
Validation loss: 2.0183527866999307

Epoch: 5| Step: 10
Training loss: 2.071718215942383
Validation loss: 2.01514400045077

Epoch: 5| Step: 11
Training loss: 0.7022955417633057
Validation loss: 2.012255777915319

Epoch: 137| Step: 0
Training loss: 1.6110811233520508
Validation loss: 2.012412905693054

Epoch: 5| Step: 1
Training loss: 2.34492826461792
Validation loss: 2.003877023855845

Epoch: 5| Step: 2
Training loss: 1.7466304302215576
Validation loss: 2.010924518108368

Epoch: 5| Step: 3
Training loss: 2.0935471057891846
Validation loss: 2.0064779271682105

Epoch: 5| Step: 4
Training loss: 1.903469443321228
Validation loss: 2.0086378256479898

Epoch: 5| Step: 5
Training loss: 2.112260580062866
Validation loss: 2.0104122161865234

Epoch: 5| Step: 6
Training loss: 1.9731194972991943
Validation loss: 2.0065616269906363

Epoch: 5| Step: 7
Training loss: 2.1362204551696777
Validation loss: 2.009434620539347

Epoch: 5| Step: 8
Training loss: 2.375422477722168
Validation loss: 2.0184883177280426

Epoch: 5| Step: 9
Training loss: 2.6601450443267822
Validation loss: 2.0108704566955566

Epoch: 5| Step: 10
Training loss: 2.1147727966308594
Validation loss: 2.0195990204811096

Epoch: 5| Step: 11
Training loss: 2.0069823265075684
Validation loss: 2.01783694823583

Epoch: 138| Step: 0
Training loss: 2.588994026184082
Validation loss: 2.0149765014648438

Epoch: 5| Step: 1
Training loss: 1.8884971141815186
Validation loss: 2.0106309354305267

Epoch: 5| Step: 2
Training loss: 2.8252367973327637
Validation loss: 2.010456825296084

Epoch: 5| Step: 3
Training loss: 1.4551880359649658
Validation loss: 2.0080082366863885

Epoch: 5| Step: 4
Training loss: 2.6462318897247314
Validation loss: 2.012583797176679

Epoch: 5| Step: 5
Training loss: 1.9436336755752563
Validation loss: 2.013574148217837

Epoch: 5| Step: 6
Training loss: 1.896675705909729
Validation loss: 2.0209840734799704

Epoch: 5| Step: 7
Training loss: 1.9261633157730103
Validation loss: 2.0092665950457254

Epoch: 5| Step: 8
Training loss: 1.8157787322998047
Validation loss: 2.0156869689623513

Epoch: 5| Step: 9
Training loss: 2.572537660598755
Validation loss: 2.016955256462097

Epoch: 5| Step: 10
Training loss: 1.3482096195220947
Validation loss: 2.019628127415975

Epoch: 5| Step: 11
Training loss: 1.5613938570022583
Validation loss: 2.0136245787143707

Epoch: 139| Step: 0
Training loss: 2.6151556968688965
Validation loss: 2.006714309255282

Epoch: 5| Step: 1
Training loss: 2.1288492679595947
Validation loss: 2.0181680619716644

Epoch: 5| Step: 2
Training loss: 1.8861297369003296
Validation loss: 2.0204280813535056

Epoch: 5| Step: 3
Training loss: 1.8481067419052124
Validation loss: 2.0211482842763266

Epoch: 5| Step: 4
Training loss: 1.872937798500061
Validation loss: 2.01304791867733

Epoch: 5| Step: 5
Training loss: 2.470419406890869
Validation loss: 2.020936980843544

Epoch: 5| Step: 6
Training loss: 2.239971876144409
Validation loss: 2.0260144770145416

Epoch: 5| Step: 7
Training loss: 1.9760372638702393
Validation loss: 2.021397292613983

Epoch: 5| Step: 8
Training loss: 1.8564382791519165
Validation loss: 2.0286660691102347

Epoch: 5| Step: 9
Training loss: 2.1756997108459473
Validation loss: 2.0180362264315286

Epoch: 5| Step: 10
Training loss: 1.9590442180633545
Validation loss: 2.0216018557548523

Epoch: 5| Step: 11
Training loss: 0.7623985409736633
Validation loss: 2.0354104141394296

Epoch: 140| Step: 0
Training loss: 2.415081739425659
Validation loss: 2.0477488388617835

Epoch: 5| Step: 1
Training loss: 2.0640339851379395
Validation loss: 2.0708630979061127

Epoch: 5| Step: 2
Training loss: 2.7926478385925293
Validation loss: 2.0988475581010184

Epoch: 5| Step: 3
Training loss: 2.014726161956787
Validation loss: 2.0951539178689322

Epoch: 5| Step: 4
Training loss: 2.269932746887207
Validation loss: 2.08395092189312

Epoch: 5| Step: 5
Training loss: 1.9334392547607422
Validation loss: 2.057444999615351

Epoch: 5| Step: 6
Training loss: 2.2786552906036377
Validation loss: 2.052613784869512

Epoch: 5| Step: 7
Training loss: 2.0771749019622803
Validation loss: 2.0340498288472495

Epoch: 5| Step: 8
Training loss: 2.2777228355407715
Validation loss: 2.0263211826483407

Epoch: 5| Step: 9
Training loss: 1.5485939979553223
Validation loss: 2.0219057500362396

Epoch: 5| Step: 10
Training loss: 2.110778331756592
Validation loss: 2.0166065196196237

Epoch: 5| Step: 11
Training loss: 1.586318850517273
Validation loss: 2.0153527657190957

Epoch: 141| Step: 0
Training loss: 2.6140849590301514
Validation loss: 2.0132951537768045

Epoch: 5| Step: 1
Training loss: 1.8781394958496094
Validation loss: 2.01227767765522

Epoch: 5| Step: 2
Training loss: 2.0047268867492676
Validation loss: 2.0200237731138864

Epoch: 5| Step: 3
Training loss: 1.788050889968872
Validation loss: 2.00745852291584

Epoch: 5| Step: 4
Training loss: 1.7608697414398193
Validation loss: 2.012688532471657

Epoch: 5| Step: 5
Training loss: 2.6806044578552246
Validation loss: 2.020810678601265

Epoch: 5| Step: 6
Training loss: 2.0347540378570557
Validation loss: 2.0206898947556815

Epoch: 5| Step: 7
Training loss: 2.1096174716949463
Validation loss: 2.026574711004893

Epoch: 5| Step: 8
Training loss: 2.182209014892578
Validation loss: 2.014048924048742

Epoch: 5| Step: 9
Training loss: 1.4335535764694214
Validation loss: 2.0238893926143646

Epoch: 5| Step: 10
Training loss: 2.5001988410949707
Validation loss: 2.010813976327578

Epoch: 5| Step: 11
Training loss: 3.064281940460205
Validation loss: 2.018148144086202

Epoch: 142| Step: 0
Training loss: 2.225991725921631
Validation loss: 2.017456442117691

Epoch: 5| Step: 1
Training loss: 2.355605363845825
Validation loss: 2.0238970716794333

Epoch: 5| Step: 2
Training loss: 2.184370756149292
Validation loss: 2.0358244280020394

Epoch: 5| Step: 3
Training loss: 1.793060541152954
Validation loss: 2.024024799466133

Epoch: 5| Step: 4
Training loss: 1.7492929697036743
Validation loss: 2.0381305118401847

Epoch: 5| Step: 5
Training loss: 2.1380796432495117
Validation loss: 2.03589894870917

Epoch: 5| Step: 6
Training loss: 1.6786543130874634
Validation loss: 2.0441897908846536

Epoch: 5| Step: 7
Training loss: 2.4078240394592285
Validation loss: 2.0344513058662415

Epoch: 5| Step: 8
Training loss: 1.548185110092163
Validation loss: 2.0433107366164527

Epoch: 5| Step: 9
Training loss: 2.5766329765319824
Validation loss: 2.043154090642929

Epoch: 5| Step: 10
Training loss: 1.8259732723236084
Validation loss: 2.037280688683192

Epoch: 5| Step: 11
Training loss: 3.2571187019348145
Validation loss: 2.0347360521554947

Epoch: 143| Step: 0
Training loss: 1.8698251247406006
Validation loss: 2.042203331987063

Epoch: 5| Step: 1
Training loss: 1.8271328210830688
Validation loss: 2.025800789395968

Epoch: 5| Step: 2
Training loss: 2.093677282333374
Validation loss: 2.031951919198036

Epoch: 5| Step: 3
Training loss: 2.091679811477661
Validation loss: 2.0282508184512458

Epoch: 5| Step: 4
Training loss: 1.3752378225326538
Validation loss: 2.022907465696335

Epoch: 5| Step: 5
Training loss: 1.94403076171875
Validation loss: 2.0216324031352997

Epoch: 5| Step: 6
Training loss: 1.7342764139175415
Validation loss: 2.0233760873476663

Epoch: 5| Step: 7
Training loss: 2.5192928314208984
Validation loss: 2.0282184233268103

Epoch: 5| Step: 8
Training loss: 2.493842601776123
Validation loss: 2.0153387685616813

Epoch: 5| Step: 9
Training loss: 2.262627124786377
Validation loss: 2.020200898249944

Epoch: 5| Step: 10
Training loss: 2.3566229343414307
Validation loss: 2.0291793843110404

Epoch: 5| Step: 11
Training loss: 2.6104421615600586
Validation loss: 2.0199729402860007

Epoch: 144| Step: 0
Training loss: 1.814255714416504
Validation loss: 2.0222554157177606

Epoch: 5| Step: 1
Training loss: 2.2665717601776123
Validation loss: 2.0182395577430725

Epoch: 5| Step: 2
Training loss: 2.043125867843628
Validation loss: 2.018758535385132

Epoch: 5| Step: 3
Training loss: 2.2436349391937256
Validation loss: 2.0165093690156937

Epoch: 5| Step: 4
Training loss: 2.018606424331665
Validation loss: 2.0267429053783417

Epoch: 5| Step: 5
Training loss: 2.174894332885742
Validation loss: 2.025252257784208

Epoch: 5| Step: 6
Training loss: 1.476137399673462
Validation loss: 2.025100593765577

Epoch: 5| Step: 7
Training loss: 2.8144845962524414
Validation loss: 2.040913388133049

Epoch: 5| Step: 8
Training loss: 1.5769340991973877
Validation loss: 2.028044874469439

Epoch: 5| Step: 9
Training loss: 1.9847471714019775
Validation loss: 2.0467381179332733

Epoch: 5| Step: 10
Training loss: 2.2959842681884766
Validation loss: 2.044031709432602

Epoch: 5| Step: 11
Training loss: 2.2996602058410645
Validation loss: 2.03910294175148

Epoch: 145| Step: 0
Training loss: 2.461366653442383
Validation loss: 2.02991591890653

Epoch: 5| Step: 1
Training loss: 1.9793869256973267
Validation loss: 2.0405315160751343

Epoch: 5| Step: 2
Training loss: 2.079066753387451
Validation loss: 2.029310310880343

Epoch: 5| Step: 3
Training loss: 2.6990554332733154
Validation loss: 2.0267129888137183

Epoch: 5| Step: 4
Training loss: 1.9285762310028076
Validation loss: 2.0174004634221396

Epoch: 5| Step: 5
Training loss: 1.848894476890564
Validation loss: 2.0244982739289603

Epoch: 5| Step: 6
Training loss: 1.72849440574646
Validation loss: 2.0308411916097007

Epoch: 5| Step: 7
Training loss: 1.9347347021102905
Validation loss: 2.0205716590086618

Epoch: 5| Step: 8
Training loss: 1.8485233783721924
Validation loss: 2.0185208221276603

Epoch: 5| Step: 9
Training loss: 1.7025489807128906
Validation loss: 2.029693509141604

Epoch: 5| Step: 10
Training loss: 2.3795156478881836
Validation loss: 2.0219643215338388

Epoch: 5| Step: 11
Training loss: 2.8770411014556885
Validation loss: 2.0361347595850625

Epoch: 146| Step: 0
Training loss: 2.3502700328826904
Validation loss: 2.0323236336310706

Epoch: 5| Step: 1
Training loss: 2.585233688354492
Validation loss: 2.027846003572146

Epoch: 5| Step: 2
Training loss: 1.6432304382324219
Validation loss: 2.029542808731397

Epoch: 5| Step: 3
Training loss: 2.3460583686828613
Validation loss: 2.035781219601631

Epoch: 5| Step: 4
Training loss: 2.0701396465301514
Validation loss: 2.0264001538356147

Epoch: 5| Step: 5
Training loss: 2.087120294570923
Validation loss: 2.0333386411269507

Epoch: 5| Step: 6
Training loss: 1.9316482543945312
Validation loss: 2.033057913184166

Epoch: 5| Step: 7
Training loss: 1.7389684915542603
Validation loss: 2.027948558330536

Epoch: 5| Step: 8
Training loss: 1.7152631282806396
Validation loss: 2.0340920885403952

Epoch: 5| Step: 9
Training loss: 1.8518460988998413
Validation loss: 2.0373265196879706

Epoch: 5| Step: 10
Training loss: 2.3533272743225098
Validation loss: 2.0379233906666436

Epoch: 5| Step: 11
Training loss: 1.6633386611938477
Validation loss: 2.0416432321071625

Epoch: 147| Step: 0
Training loss: 2.243234157562256
Validation loss: 2.0317325989405313

Epoch: 5| Step: 1
Training loss: 2.48616099357605
Validation loss: 2.030956362684568

Epoch: 5| Step: 2
Training loss: 1.9722591638565063
Validation loss: 2.034365803003311

Epoch: 5| Step: 3
Training loss: 2.1325647830963135
Validation loss: 2.036181469758352

Epoch: 5| Step: 4
Training loss: 2.1545186042785645
Validation loss: 2.052230844895045

Epoch: 5| Step: 5
Training loss: 2.044370412826538
Validation loss: 2.043490082025528

Epoch: 5| Step: 6
Training loss: 1.6459051370620728
Validation loss: 2.054197291533152

Epoch: 5| Step: 7
Training loss: 1.8351848125457764
Validation loss: 2.05490472416083

Epoch: 5| Step: 8
Training loss: 2.3063149452209473
Validation loss: 2.0541898806889853

Epoch: 5| Step: 9
Training loss: 1.9802074432373047
Validation loss: 2.04804557065169

Epoch: 5| Step: 10
Training loss: 2.0494771003723145
Validation loss: 2.036431834101677

Epoch: 5| Step: 11
Training loss: 0.9337016344070435
Validation loss: 2.0429091453552246

Epoch: 148| Step: 0
Training loss: 2.3104257583618164
Validation loss: 2.043241505821546

Epoch: 5| Step: 1
Training loss: 1.6912841796875
Validation loss: 2.037695904572805

Epoch: 5| Step: 2
Training loss: 2.4125423431396484
Validation loss: 2.034950037797292

Epoch: 5| Step: 3
Training loss: 2.040828227996826
Validation loss: 2.0384211242198944

Epoch: 5| Step: 4
Training loss: 2.1877732276916504
Validation loss: 2.0449005415042243

Epoch: 5| Step: 5
Training loss: 2.141744375228882
Validation loss: 2.0369313855965934

Epoch: 5| Step: 6
Training loss: 2.5711333751678467
Validation loss: 2.043583775560061

Epoch: 5| Step: 7
Training loss: 1.9752193689346313
Validation loss: 2.0326174398263297

Epoch: 5| Step: 8
Training loss: 2.3042330741882324
Validation loss: 2.0373798112074533

Epoch: 5| Step: 9
Training loss: 1.6161577701568604
Validation loss: 2.041401515404383

Epoch: 5| Step: 10
Training loss: 1.5218255519866943
Validation loss: 2.0349032084147134

Epoch: 5| Step: 11
Training loss: 1.0321907997131348
Validation loss: 2.0384623606999717

Epoch: 149| Step: 0
Training loss: 1.8406474590301514
Validation loss: 2.0389016767342887

Epoch: 5| Step: 1
Training loss: 2.098588466644287
Validation loss: 2.034966140985489

Epoch: 5| Step: 2
Training loss: 2.028822422027588
Validation loss: 2.054499705632528

Epoch: 5| Step: 3
Training loss: 1.7715057134628296
Validation loss: 2.0571089337269464

Epoch: 5| Step: 4
Training loss: 2.3713834285736084
Validation loss: 2.049575905005137

Epoch: 5| Step: 5
Training loss: 2.131852388381958
Validation loss: 2.0530864149332047

Epoch: 5| Step: 6
Training loss: 1.8751537799835205
Validation loss: 2.0493048230806985

Epoch: 5| Step: 7
Training loss: 1.9854685068130493
Validation loss: 2.0440647254387536

Epoch: 5| Step: 8
Training loss: 1.919745683670044
Validation loss: 2.0538676927487054

Epoch: 5| Step: 9
Training loss: 2.6827893257141113
Validation loss: 2.0378456761439643

Epoch: 5| Step: 10
Training loss: 1.7865451574325562
Validation loss: 2.049008399248123

Epoch: 5| Step: 11
Training loss: 2.1295876502990723
Validation loss: 2.0425227880477905

Epoch: 150| Step: 0
Training loss: 2.2376484870910645
Validation loss: 2.036202241977056

Epoch: 5| Step: 1
Training loss: 1.6965091228485107
Validation loss: 2.023976077636083

Epoch: 5| Step: 2
Training loss: 2.1024513244628906
Validation loss: 2.022862712542216

Epoch: 5| Step: 3
Training loss: 2.246000289916992
Validation loss: 2.0271069308122

Epoch: 5| Step: 4
Training loss: 2.2698543071746826
Validation loss: 2.0274967749913535

Epoch: 5| Step: 5
Training loss: 1.8730272054672241
Validation loss: 2.023067538936933

Epoch: 5| Step: 6
Training loss: 2.356222152709961
Validation loss: 2.029588753978411

Epoch: 5| Step: 7
Training loss: 2.0241599082946777
Validation loss: 2.017263407508532

Epoch: 5| Step: 8
Training loss: 1.6554893255233765
Validation loss: 2.0238561083873114

Epoch: 5| Step: 9
Training loss: 1.9556663036346436
Validation loss: 2.030801311135292

Epoch: 5| Step: 10
Training loss: 2.097275733947754
Validation loss: 2.0411837796370187

Epoch: 5| Step: 11
Training loss: 3.3666934967041016
Validation loss: 2.032721623778343

Epoch: 151| Step: 0
Training loss: 2.2854437828063965
Validation loss: 2.0356884698073068

Epoch: 5| Step: 1
Training loss: 2.13887619972229
Validation loss: 2.0527081290880838

Epoch: 5| Step: 2
Training loss: 1.6525795459747314
Validation loss: 2.043225814898809

Epoch: 5| Step: 3
Training loss: 2.1894922256469727
Validation loss: 2.057921886444092

Epoch: 5| Step: 4
Training loss: 1.6189470291137695
Validation loss: 2.045362507303556

Epoch: 5| Step: 5
Training loss: 2.5358073711395264
Validation loss: 2.0350784907738366

Epoch: 5| Step: 6
Training loss: 1.7530006170272827
Validation loss: 2.0481958339611688

Epoch: 5| Step: 7
Training loss: 1.7523458003997803
Validation loss: 2.054507484038671

Epoch: 5| Step: 8
Training loss: 2.4889657497406006
Validation loss: 2.050450603167216

Epoch: 5| Step: 9
Training loss: 1.6795024871826172
Validation loss: 2.0369568119446435

Epoch: 5| Step: 10
Training loss: 2.1212639808654785
Validation loss: 2.0407007982333503

Epoch: 5| Step: 11
Training loss: 3.541879653930664
Validation loss: 2.0429223577181497

Epoch: 152| Step: 0
Training loss: 1.6968610286712646
Validation loss: 2.034633288780848

Epoch: 5| Step: 1
Training loss: 1.9689795970916748
Validation loss: 2.029307554165522

Epoch: 5| Step: 2
Training loss: 2.1267409324645996
Validation loss: 2.0255028853813806

Epoch: 5| Step: 3
Training loss: 2.091890811920166
Validation loss: 2.0323667526245117

Epoch: 5| Step: 4
Training loss: 2.108665943145752
Validation loss: 2.0236606498559317

Epoch: 5| Step: 5
Training loss: 2.02994966506958
Validation loss: 2.026897743344307

Epoch: 5| Step: 6
Training loss: 2.3065199851989746
Validation loss: 2.0266099820534387

Epoch: 5| Step: 7
Training loss: 1.966841459274292
Validation loss: 2.0243951926628747

Epoch: 5| Step: 8
Training loss: 1.8894706964492798
Validation loss: 2.030542423327764

Epoch: 5| Step: 9
Training loss: 2.472234010696411
Validation loss: 2.0369094908237457

Epoch: 5| Step: 10
Training loss: 1.5796239376068115
Validation loss: 2.0490226248900094

Epoch: 5| Step: 11
Training loss: 3.031035900115967
Validation loss: 2.062362755338351

Epoch: 153| Step: 0
Training loss: 1.9800188541412354
Validation loss: 2.0726949274539948

Epoch: 5| Step: 1
Training loss: 2.3245279788970947
Validation loss: 2.0714977830648422

Epoch: 5| Step: 2
Training loss: 2.4370265007019043
Validation loss: 2.058802550037702

Epoch: 5| Step: 3
Training loss: 2.25384521484375
Validation loss: 2.063964088757833

Epoch: 5| Step: 4
Training loss: 1.71779465675354
Validation loss: 2.0516438583532968

Epoch: 5| Step: 5
Training loss: 2.381181240081787
Validation loss: 2.0558594365914664

Epoch: 5| Step: 6
Training loss: 1.9397064447402954
Validation loss: 2.0375993102788925

Epoch: 5| Step: 7
Training loss: 2.1222238540649414
Validation loss: 2.0463605473438897

Epoch: 5| Step: 8
Training loss: 1.4934008121490479
Validation loss: 2.032330776254336

Epoch: 5| Step: 9
Training loss: 2.0864245891571045
Validation loss: 2.0413659612337747

Epoch: 5| Step: 10
Training loss: 1.9239689111709595
Validation loss: 2.0550821324189505

Epoch: 5| Step: 11
Training loss: 1.7181943655014038
Validation loss: 2.038909966746966

Epoch: 154| Step: 0
Training loss: 1.9695762395858765
Validation loss: 2.043844302495321

Epoch: 5| Step: 1
Training loss: 1.8250172138214111
Validation loss: 2.0366036891937256

Epoch: 5| Step: 2
Training loss: 1.9578602313995361
Validation loss: 2.0299263099829354

Epoch: 5| Step: 3
Training loss: 2.401735782623291
Validation loss: 2.020739585161209

Epoch: 5| Step: 4
Training loss: 2.328263759613037
Validation loss: 2.02551232278347

Epoch: 5| Step: 5
Training loss: 2.0263097286224365
Validation loss: 2.023433049519857

Epoch: 5| Step: 6
Training loss: 1.732336401939392
Validation loss: 2.0388835221529007

Epoch: 5| Step: 7
Training loss: 2.047018527984619
Validation loss: 2.0323390314976373

Epoch: 5| Step: 8
Training loss: 2.5091686248779297
Validation loss: 2.0319163848956427

Epoch: 5| Step: 9
Training loss: 2.359140634536743
Validation loss: 2.0257603029410043

Epoch: 5| Step: 10
Training loss: 2.1013455390930176
Validation loss: 2.021104867259661

Epoch: 5| Step: 11
Training loss: 1.294872522354126
Validation loss: 2.0229184528191886

Epoch: 155| Step: 0
Training loss: 1.7026336193084717
Validation loss: 2.0221129854520163

Epoch: 5| Step: 1
Training loss: 1.7854430675506592
Validation loss: 2.0183603912591934

Epoch: 5| Step: 2
Training loss: 2.145036220550537
Validation loss: 2.0241222580273948

Epoch: 5| Step: 3
Training loss: 2.0304691791534424
Validation loss: 2.0216083228588104

Epoch: 5| Step: 4
Training loss: 1.5130326747894287
Validation loss: 2.0218248516321182

Epoch: 5| Step: 5
Training loss: 2.229361057281494
Validation loss: 2.0312807162602744

Epoch: 5| Step: 6
Training loss: 2.1276779174804688
Validation loss: 2.036000763376554

Epoch: 5| Step: 7
Training loss: 2.1315369606018066
Validation loss: 2.051906163493792

Epoch: 5| Step: 8
Training loss: 2.945746898651123
Validation loss: 2.0518372555573783

Epoch: 5| Step: 9
Training loss: 2.686950206756592
Validation loss: 2.045661931236585

Epoch: 5| Step: 10
Training loss: 1.3913943767547607
Validation loss: 2.047394240895907

Epoch: 5| Step: 11
Training loss: 1.6321169137954712
Validation loss: 2.0316169758637748

Epoch: 156| Step: 0
Training loss: 2.206972360610962
Validation loss: 2.0346161276102066

Epoch: 5| Step: 1
Training loss: 1.7658770084381104
Validation loss: 2.0360391239325204

Epoch: 5| Step: 2
Training loss: 2.1958119869232178
Validation loss: 2.0306976636250815

Epoch: 5| Step: 3
Training loss: 1.6019996404647827
Validation loss: 2.0318872183561325

Epoch: 5| Step: 4
Training loss: 2.2491161823272705
Validation loss: 2.0293115178743997

Epoch: 5| Step: 5
Training loss: 1.9280383586883545
Validation loss: 2.027663270632426

Epoch: 5| Step: 6
Training loss: 2.1592531204223633
Validation loss: 2.0284619281689324

Epoch: 5| Step: 7
Training loss: 1.9783166646957397
Validation loss: 2.0405079126358032

Epoch: 5| Step: 8
Training loss: 2.514338254928589
Validation loss: 2.0304222802321115

Epoch: 5| Step: 9
Training loss: 2.3022313117980957
Validation loss: 2.0325968861579895

Epoch: 5| Step: 10
Training loss: 1.8248679637908936
Validation loss: 2.026989405353864

Epoch: 5| Step: 11
Training loss: 1.8101122379302979
Validation loss: 2.041401813427607

Epoch: 157| Step: 0
Training loss: 2.0935821533203125
Validation loss: 2.0422383248806

Epoch: 5| Step: 1
Training loss: 1.8358068466186523
Validation loss: 2.0275495449701944

Epoch: 5| Step: 2
Training loss: 2.3016135692596436
Validation loss: 2.0323117623726525

Epoch: 5| Step: 3
Training loss: 2.0961906909942627
Validation loss: 2.0425525307655334

Epoch: 5| Step: 4
Training loss: 1.90256667137146
Validation loss: 2.0445004800955453

Epoch: 5| Step: 5
Training loss: 2.2060463428497314
Validation loss: 2.044545183579127

Epoch: 5| Step: 6
Training loss: 2.2739779949188232
Validation loss: 2.036670356988907

Epoch: 5| Step: 7
Training loss: 1.7319796085357666
Validation loss: 2.0527570148309073

Epoch: 5| Step: 8
Training loss: 2.470313310623169
Validation loss: 2.060444916288058

Epoch: 5| Step: 9
Training loss: 1.9767707586288452
Validation loss: 2.0572878221670785

Epoch: 5| Step: 10
Training loss: 1.3996068239212036
Validation loss: 2.04504864414533

Epoch: 5| Step: 11
Training loss: 2.808875560760498
Validation loss: 2.065459191799164

Epoch: 158| Step: 0
Training loss: 1.7744686603546143
Validation loss: 2.0699022859334946

Epoch: 5| Step: 1
Training loss: 2.4444520473480225
Validation loss: 2.0621362576882043

Epoch: 5| Step: 2
Training loss: 2.2108752727508545
Validation loss: 2.0588240573803582

Epoch: 5| Step: 3
Training loss: 1.514736294746399
Validation loss: 2.047246510783831

Epoch: 5| Step: 4
Training loss: 1.7751989364624023
Validation loss: 2.05514590938886

Epoch: 5| Step: 5
Training loss: 1.8909698724746704
Validation loss: 2.0449664940436683

Epoch: 5| Step: 6
Training loss: 2.3695645332336426
Validation loss: 2.038164565960566

Epoch: 5| Step: 7
Training loss: 1.706547498703003
Validation loss: 2.0446631759405136

Epoch: 5| Step: 8
Training loss: 1.8391271829605103
Validation loss: 2.0601498037576675

Epoch: 5| Step: 9
Training loss: 2.664247989654541
Validation loss: 2.0570090810457864

Epoch: 5| Step: 10
Training loss: 2.0936059951782227
Validation loss: 2.042151063680649

Epoch: 5| Step: 11
Training loss: 2.611654281616211
Validation loss: 2.0507365415493646

Epoch: 159| Step: 0
Training loss: 1.9408906698226929
Validation loss: 2.0401353190342584

Epoch: 5| Step: 1
Training loss: 2.1083431243896484
Validation loss: 2.031670073668162

Epoch: 5| Step: 2
Training loss: 2.2229535579681396
Validation loss: 2.0406960050264993

Epoch: 5| Step: 3
Training loss: 1.3377227783203125
Validation loss: 2.040780708193779

Epoch: 5| Step: 4
Training loss: 1.6754801273345947
Validation loss: 2.044602726896604

Epoch: 5| Step: 5
Training loss: 2.0985236167907715
Validation loss: 2.0487685799598694

Epoch: 5| Step: 6
Training loss: 2.1684937477111816
Validation loss: 2.042471339305242

Epoch: 5| Step: 7
Training loss: 2.224647045135498
Validation loss: 2.0649357239405313

Epoch: 5| Step: 8
Training loss: 2.0888097286224365
Validation loss: 2.069052209456762

Epoch: 5| Step: 9
Training loss: 2.184497356414795
Validation loss: 2.0753704408804574

Epoch: 5| Step: 10
Training loss: 2.416776180267334
Validation loss: 2.062209904193878

Epoch: 5| Step: 11
Training loss: 2.365950107574463
Validation loss: 2.060187190771103

Epoch: 160| Step: 0
Training loss: 1.882480263710022
Validation loss: 2.065496931473414

Epoch: 5| Step: 1
Training loss: 2.349093437194824
Validation loss: 2.076428254445394

Epoch: 5| Step: 2
Training loss: 2.246161699295044
Validation loss: 2.0530418306589127

Epoch: 5| Step: 3
Training loss: 1.6114037036895752
Validation loss: 2.050270492831866

Epoch: 5| Step: 4
Training loss: 1.592105746269226
Validation loss: 2.0385792503754296

Epoch: 5| Step: 5
Training loss: 2.5667660236358643
Validation loss: 2.034678171078364

Epoch: 5| Step: 6
Training loss: 2.3532474040985107
Validation loss: 2.0416742712259293

Epoch: 5| Step: 7
Training loss: 1.785617470741272
Validation loss: 2.055573597550392

Epoch: 5| Step: 8
Training loss: 1.835431694984436
Validation loss: 2.04354061683019

Epoch: 5| Step: 9
Training loss: 1.871720314025879
Validation loss: 2.0489041954278946

Epoch: 5| Step: 10
Training loss: 2.343106746673584
Validation loss: 2.0477944165468216

Epoch: 5| Step: 11
Training loss: 1.668246865272522
Validation loss: 2.054245119293531

Epoch: 161| Step: 0
Training loss: 2.4355528354644775
Validation loss: 2.033291851480802

Epoch: 5| Step: 1
Training loss: 2.1931862831115723
Validation loss: 2.038379813234011

Epoch: 5| Step: 2
Training loss: 2.589059829711914
Validation loss: 2.038276727000872

Epoch: 5| Step: 3
Training loss: 2.027435064315796
Validation loss: 2.030646021167437

Epoch: 5| Step: 4
Training loss: 2.1025938987731934
Validation loss: 2.039586399992307

Epoch: 5| Step: 5
Training loss: 1.9177099466323853
Validation loss: 2.0401327908039093

Epoch: 5| Step: 6
Training loss: 1.7628974914550781
Validation loss: 2.034838557243347

Epoch: 5| Step: 7
Training loss: 2.09002423286438
Validation loss: 2.043981601794561

Epoch: 5| Step: 8
Training loss: 1.6505943536758423
Validation loss: 2.044928267598152

Epoch: 5| Step: 9
Training loss: 1.4340847730636597
Validation loss: 2.0458025435606637

Epoch: 5| Step: 10
Training loss: 2.026353120803833
Validation loss: 2.0506158570448556

Epoch: 5| Step: 11
Training loss: 2.45672869682312
Validation loss: 2.052110865712166

Epoch: 162| Step: 0
Training loss: 1.8350893259048462
Validation loss: 2.0449741780757904

Epoch: 5| Step: 1
Training loss: 2.131737232208252
Validation loss: 2.05456006526947

Epoch: 5| Step: 2
Training loss: 2.09006929397583
Validation loss: 2.0704506933689117

Epoch: 5| Step: 3
Training loss: 1.798937201499939
Validation loss: 2.0465895185867944

Epoch: 5| Step: 4
Training loss: 2.1167807579040527
Validation loss: 2.0473648657401404

Epoch: 5| Step: 5
Training loss: 1.9879461526870728
Validation loss: 2.0467992971340814

Epoch: 5| Step: 6
Training loss: 2.233081102371216
Validation loss: 2.043211132287979

Epoch: 5| Step: 7
Training loss: 1.8056905269622803
Validation loss: 2.0380312303702035

Epoch: 5| Step: 8
Training loss: 2.105938196182251
Validation loss: 2.0406778156757355

Epoch: 5| Step: 9
Training loss: 2.5177524089813232
Validation loss: 2.0282977173725762

Epoch: 5| Step: 10
Training loss: 1.653078317642212
Validation loss: 2.0271854797999063

Epoch: 5| Step: 11
Training loss: 3.0949606895446777
Validation loss: 2.0292386561632156

Epoch: 163| Step: 0
Training loss: 2.3029258251190186
Validation loss: 2.027240668733915

Epoch: 5| Step: 1
Training loss: 2.2111129760742188
Validation loss: 2.032875880599022

Epoch: 5| Step: 2
Training loss: 1.6345020532608032
Validation loss: 2.0390928188959756

Epoch: 5| Step: 3
Training loss: 1.851641058921814
Validation loss: 2.045356829961141

Epoch: 5| Step: 4
Training loss: 2.4240925312042236
Validation loss: 2.0399587551752725

Epoch: 5| Step: 5
Training loss: 2.534677743911743
Validation loss: 2.047732209165891

Epoch: 5| Step: 6
Training loss: 1.7195764780044556
Validation loss: 2.0460580388704934

Epoch: 5| Step: 7
Training loss: 2.3316421508789062
Validation loss: 2.0353415409723916

Epoch: 5| Step: 8
Training loss: 1.7976675033569336
Validation loss: 2.0392432461182275

Epoch: 5| Step: 9
Training loss: 2.110851764678955
Validation loss: 2.0336189369360604

Epoch: 5| Step: 10
Training loss: 2.2717182636260986
Validation loss: 2.0279463877280555

Epoch: 5| Step: 11
Training loss: 1.9544388055801392
Validation loss: 2.026269401113192

Epoch: 164| Step: 0
Training loss: 2.1026535034179688
Validation loss: 2.042278900742531

Epoch: 5| Step: 1
Training loss: 2.4047255516052246
Validation loss: 2.0472393383582435

Epoch: 5| Step: 2
Training loss: 1.8083412647247314
Validation loss: 2.0558034231265387

Epoch: 5| Step: 3
Training loss: 1.980147123336792
Validation loss: 2.0659402310848236

Epoch: 5| Step: 4
Training loss: 2.0735042095184326
Validation loss: 2.0736265182495117

Epoch: 5| Step: 5
Training loss: 1.994278907775879
Validation loss: 2.0669778982798257

Epoch: 5| Step: 6
Training loss: 1.4326379299163818
Validation loss: 2.0702993174393973

Epoch: 5| Step: 7
Training loss: 1.9797815084457397
Validation loss: 2.0713394582271576

Epoch: 5| Step: 8
Training loss: 2.084275960922241
Validation loss: 2.052126328150431

Epoch: 5| Step: 9
Training loss: 3.0971179008483887
Validation loss: 2.0472969114780426

Epoch: 5| Step: 10
Training loss: 2.0924794673919678
Validation loss: 2.044083461165428

Epoch: 5| Step: 11
Training loss: 1.7926628589630127
Validation loss: 2.032535860935847

Epoch: 165| Step: 0
Training loss: 1.4847549200057983
Validation loss: 2.0407287975152335

Epoch: 5| Step: 1
Training loss: 1.7273435592651367
Validation loss: 2.0543122440576553

Epoch: 5| Step: 2
Training loss: 2.4573843479156494
Validation loss: 2.0503477851549783

Epoch: 5| Step: 3
Training loss: 1.7996639013290405
Validation loss: 2.0518048852682114

Epoch: 5| Step: 4
Training loss: 1.6238124370574951
Validation loss: 2.05745962758859

Epoch: 5| Step: 5
Training loss: 2.2219860553741455
Validation loss: 2.0600068469842276

Epoch: 5| Step: 6
Training loss: 2.001925230026245
Validation loss: 2.0667883455753326

Epoch: 5| Step: 7
Training loss: 2.516939401626587
Validation loss: 2.045841157436371

Epoch: 5| Step: 8
Training loss: 2.706972122192383
Validation loss: 2.046308770775795

Epoch: 5| Step: 9
Training loss: 1.9874563217163086
Validation loss: 2.0486925592025123

Epoch: 5| Step: 10
Training loss: 1.9885509014129639
Validation loss: 2.0531684358914695

Epoch: 5| Step: 11
Training loss: 0.9556674957275391
Validation loss: 2.0431931416193643

Epoch: 166| Step: 0
Training loss: 1.7020244598388672
Validation loss: 2.054299379388491

Epoch: 5| Step: 1
Training loss: 1.7191131114959717
Validation loss: 2.0476090411345163

Epoch: 5| Step: 2
Training loss: 1.7871673107147217
Validation loss: 2.066243583957354

Epoch: 5| Step: 3
Training loss: 2.5982792377471924
Validation loss: 2.0751123130321503

Epoch: 5| Step: 4
Training loss: 2.3520922660827637
Validation loss: 2.06228199104468

Epoch: 5| Step: 5
Training loss: 1.8458458185195923
Validation loss: 2.0713209559520087

Epoch: 5| Step: 6
Training loss: 2.1076323986053467
Validation loss: 2.0743396083513894

Epoch: 5| Step: 7
Training loss: 2.1139979362487793
Validation loss: 2.0714957068363824

Epoch: 5| Step: 8
Training loss: 1.7219089269638062
Validation loss: 2.057240217924118

Epoch: 5| Step: 9
Training loss: 2.7441108226776123
Validation loss: 2.0577105035384498

Epoch: 5| Step: 10
Training loss: 1.4400105476379395
Validation loss: 2.048995777964592

Epoch: 5| Step: 11
Training loss: 2.771510124206543
Validation loss: 2.055190215508143

Epoch: 167| Step: 0
Training loss: 1.3362913131713867
Validation loss: 2.046829620997111

Epoch: 5| Step: 1
Training loss: 2.2550835609436035
Validation loss: 2.0589532951513925

Epoch: 5| Step: 2
Training loss: 2.0735878944396973
Validation loss: 2.0565338134765625

Epoch: 5| Step: 3
Training loss: 1.9088226556777954
Validation loss: 2.067847897609075

Epoch: 5| Step: 4
Training loss: 1.983445405960083
Validation loss: 2.0615784724553428

Epoch: 5| Step: 5
Training loss: 2.074312925338745
Validation loss: 2.059866805871328

Epoch: 5| Step: 6
Training loss: 2.3159067630767822
Validation loss: 2.0609549383322396

Epoch: 5| Step: 7
Training loss: 2.065412998199463
Validation loss: 2.060506448149681

Epoch: 5| Step: 8
Training loss: 2.060032844543457
Validation loss: 2.054965411623319

Epoch: 5| Step: 9
Training loss: 1.6081184148788452
Validation loss: 2.046992172797521

Epoch: 5| Step: 10
Training loss: 2.102091073989868
Validation loss: 2.0460970451434455

Epoch: 5| Step: 11
Training loss: 4.013688087463379
Validation loss: 2.052865336338679

Epoch: 168| Step: 0
Training loss: 2.2204747200012207
Validation loss: 2.046379968523979

Epoch: 5| Step: 1
Training loss: 1.5878537893295288
Validation loss: 2.056878919402758

Epoch: 5| Step: 2
Training loss: 2.166576862335205
Validation loss: 2.0486609737078347

Epoch: 5| Step: 3
Training loss: 2.294970989227295
Validation loss: 2.0558909873167672

Epoch: 5| Step: 4
Training loss: 2.0024924278259277
Validation loss: 2.0644047260284424

Epoch: 5| Step: 5
Training loss: 2.0369999408721924
Validation loss: 2.057828644911448

Epoch: 5| Step: 6
Training loss: 2.0325942039489746
Validation loss: 2.0607491731643677

Epoch: 5| Step: 7
Training loss: 2.1618571281433105
Validation loss: 2.0624807278315225

Epoch: 5| Step: 8
Training loss: 1.5251381397247314
Validation loss: 2.066448559363683

Epoch: 5| Step: 9
Training loss: 2.4110381603240967
Validation loss: 2.062044491370519

Epoch: 5| Step: 10
Training loss: 1.9175550937652588
Validation loss: 2.0556912223498025

Epoch: 5| Step: 11
Training loss: 2.2426440715789795
Validation loss: 2.041261817018191

Epoch: 169| Step: 0
Training loss: 1.803047776222229
Validation loss: 2.045783778031667

Epoch: 5| Step: 1
Training loss: 2.086585521697998
Validation loss: 2.047308072447777

Epoch: 5| Step: 2
Training loss: 2.1887869834899902
Validation loss: 2.0402899781862893

Epoch: 5| Step: 3
Training loss: 2.4866509437561035
Validation loss: 2.034786512454351

Epoch: 5| Step: 4
Training loss: 2.003988027572632
Validation loss: 2.031685302654902

Epoch: 5| Step: 5
Training loss: 1.9788789749145508
Validation loss: 2.0348231345415115

Epoch: 5| Step: 6
Training loss: 1.743679404258728
Validation loss: 2.050185655554136

Epoch: 5| Step: 7
Training loss: 2.0121726989746094
Validation loss: 2.0502142906188965

Epoch: 5| Step: 8
Training loss: 1.9331525564193726
Validation loss: 2.0453337728977203

Epoch: 5| Step: 9
Training loss: 2.6917262077331543
Validation loss: 2.0397937297821045

Epoch: 5| Step: 10
Training loss: 1.608872652053833
Validation loss: 2.0369901160399118

Epoch: 5| Step: 11
Training loss: 1.094452142715454
Validation loss: 2.056032285094261

Epoch: 170| Step: 0
Training loss: 1.8991222381591797
Validation loss: 2.0495404452085495

Epoch: 5| Step: 1
Training loss: 1.939113974571228
Validation loss: 2.047594969471296

Epoch: 5| Step: 2
Training loss: 2.5858943462371826
Validation loss: 2.0548675060272217

Epoch: 5| Step: 3
Training loss: 1.9366302490234375
Validation loss: 2.074429785211881

Epoch: 5| Step: 4
Training loss: 2.429840564727783
Validation loss: 2.0664118379354477

Epoch: 5| Step: 5
Training loss: 2.096452474594116
Validation loss: 2.0654771675666175

Epoch: 5| Step: 6
Training loss: 1.845028281211853
Validation loss: 2.057163804769516

Epoch: 5| Step: 7
Training loss: 2.121288299560547
Validation loss: 2.0541931639115014

Epoch: 5| Step: 8
Training loss: 1.851457953453064
Validation loss: 2.0592582325140634

Epoch: 5| Step: 9
Training loss: 1.7057921886444092
Validation loss: 2.058871865272522

Epoch: 5| Step: 10
Training loss: 1.6500132083892822
Validation loss: 2.0556654830773673

Epoch: 5| Step: 11
Training loss: 1.8947052955627441
Validation loss: 2.0578627636035285

Epoch: 171| Step: 0
Training loss: 1.8214836120605469
Validation loss: 2.0533799727757773

Epoch: 5| Step: 1
Training loss: 2.05076265335083
Validation loss: 2.049452399214109

Epoch: 5| Step: 2
Training loss: 2.0288844108581543
Validation loss: 2.047786374886831

Epoch: 5| Step: 3
Training loss: 2.3166604042053223
Validation loss: 2.0416537125905356

Epoch: 5| Step: 4
Training loss: 1.7815523147583008
Validation loss: 2.048928832014402

Epoch: 5| Step: 5
Training loss: 1.6164839267730713
Validation loss: 2.047072450319926

Epoch: 5| Step: 6
Training loss: 2.131336212158203
Validation loss: 2.056764617562294

Epoch: 5| Step: 7
Training loss: 1.6115432977676392
Validation loss: 2.064346199234327

Epoch: 5| Step: 8
Training loss: 2.2030653953552246
Validation loss: 2.0442954897880554

Epoch: 5| Step: 9
Training loss: 2.4084973335266113
Validation loss: 2.0625287691752114

Epoch: 5| Step: 10
Training loss: 2.3569891452789307
Validation loss: 2.064107432961464

Epoch: 5| Step: 11
Training loss: 1.2270779609680176
Validation loss: 2.0774606515963874

Epoch: 172| Step: 0
Training loss: 2.0386147499084473
Validation loss: 2.0537443459033966

Epoch: 5| Step: 1
Training loss: 2.1685333251953125
Validation loss: 2.0523520708084106

Epoch: 5| Step: 2
Training loss: 2.1008174419403076
Validation loss: 2.0534710188706717

Epoch: 5| Step: 3
Training loss: 1.8603477478027344
Validation loss: 2.0591456294059753

Epoch: 5| Step: 4
Training loss: 1.5927684307098389
Validation loss: 2.056555519501368

Epoch: 5| Step: 5
Training loss: 1.7800079584121704
Validation loss: 2.058352455496788

Epoch: 5| Step: 6
Training loss: 1.7463438510894775
Validation loss: 2.056500176588694

Epoch: 5| Step: 7
Training loss: 1.7601134777069092
Validation loss: 2.073774124185244

Epoch: 5| Step: 8
Training loss: 2.1790623664855957
Validation loss: 2.055163433154424

Epoch: 5| Step: 9
Training loss: 2.3851141929626465
Validation loss: 2.0576206545035043

Epoch: 5| Step: 10
Training loss: 2.485124349594116
Validation loss: 2.0640196253856025

Epoch: 5| Step: 11
Training loss: 1.8499687910079956
Validation loss: 2.0563878814379373

Epoch: 173| Step: 0
Training loss: 2.026798963546753
Validation loss: 2.043782422939936

Epoch: 5| Step: 1
Training loss: 2.394963264465332
Validation loss: 2.042094667752584

Epoch: 5| Step: 2
Training loss: 1.9435975551605225
Validation loss: 2.0354170302549996

Epoch: 5| Step: 3
Training loss: 1.8046029806137085
Validation loss: 2.036540557940801

Epoch: 5| Step: 4
Training loss: 2.0002336502075195
Validation loss: 2.039644440015157

Epoch: 5| Step: 5
Training loss: 1.8618789911270142
Validation loss: 2.0430168757836022

Epoch: 5| Step: 6
Training loss: 1.7371126413345337
Validation loss: 2.040656715631485

Epoch: 5| Step: 7
Training loss: 2.3396027088165283
Validation loss: 2.040187562505404

Epoch: 5| Step: 8
Training loss: 1.5398986339569092
Validation loss: 2.0319139659404755

Epoch: 5| Step: 9
Training loss: 1.910556435585022
Validation loss: 2.04412534336249

Epoch: 5| Step: 10
Training loss: 2.7238550186157227
Validation loss: 2.0476340552171073

Epoch: 5| Step: 11
Training loss: 2.2915587425231934
Validation loss: 2.0550790826479592

Epoch: 174| Step: 0
Training loss: 2.074450969696045
Validation loss: 2.0498746633529663

Epoch: 5| Step: 1
Training loss: 2.3332467079162598
Validation loss: 2.0566125760475793

Epoch: 5| Step: 2
Training loss: 2.1214377880096436
Validation loss: 2.0643130987882614

Epoch: 5| Step: 3
Training loss: 1.7799358367919922
Validation loss: 2.0620339065790176

Epoch: 5| Step: 4
Training loss: 2.562650203704834
Validation loss: 2.063795953989029

Epoch: 5| Step: 5
Training loss: 1.9787505865097046
Validation loss: 2.06799153983593

Epoch: 5| Step: 6
Training loss: 1.9258321523666382
Validation loss: 2.067701295018196

Epoch: 5| Step: 7
Training loss: 2.1189517974853516
Validation loss: 2.0751183132330575

Epoch: 5| Step: 8
Training loss: 1.7147884368896484
Validation loss: 2.0687823394934335

Epoch: 5| Step: 9
Training loss: 1.951989769935608
Validation loss: 2.0705417692661285

Epoch: 5| Step: 10
Training loss: 1.623731255531311
Validation loss: 2.0779835681120553

Epoch: 5| Step: 11
Training loss: 1.2390680313110352
Validation loss: 2.07469009856383

Epoch: 175| Step: 0
Training loss: 1.373213768005371
Validation loss: 2.070434937874476

Epoch: 5| Step: 1
Training loss: 2.011380672454834
Validation loss: 2.0561662962039313

Epoch: 5| Step: 2
Training loss: 1.7957191467285156
Validation loss: 2.057684669891993

Epoch: 5| Step: 3
Training loss: 2.5687804222106934
Validation loss: 2.0577220817406974

Epoch: 5| Step: 4
Training loss: 2.111981153488159
Validation loss: 2.0549477438131967

Epoch: 5| Step: 5
Training loss: 1.6560781002044678
Validation loss: 2.047770624359449

Epoch: 5| Step: 6
Training loss: 2.005549430847168
Validation loss: 2.058508430918058

Epoch: 5| Step: 7
Training loss: 1.498920202255249
Validation loss: 2.056409845749537

Epoch: 5| Step: 8
Training loss: 2.0049641132354736
Validation loss: 2.0462428530057273

Epoch: 5| Step: 9
Training loss: 2.170189619064331
Validation loss: 2.06022314230601

Epoch: 5| Step: 10
Training loss: 2.7065625190734863
Validation loss: 2.0727590918540955

Epoch: 5| Step: 11
Training loss: 2.168393611907959
Validation loss: 2.06559548775355

Epoch: 176| Step: 0
Training loss: 1.9417979717254639
Validation loss: 2.07411789894104

Epoch: 5| Step: 1
Training loss: 1.970516562461853
Validation loss: 2.0787836809953055

Epoch: 5| Step: 2
Training loss: 1.82528817653656
Validation loss: 2.082599793871244

Epoch: 5| Step: 3
Training loss: 2.437995433807373
Validation loss: 2.0819421460231147

Epoch: 5| Step: 4
Training loss: 1.7268478870391846
Validation loss: 2.071281060576439

Epoch: 5| Step: 5
Training loss: 2.3332369327545166
Validation loss: 2.06671009461085

Epoch: 5| Step: 6
Training loss: 2.296229839324951
Validation loss: 2.0776965618133545

Epoch: 5| Step: 7
Training loss: 1.8697402477264404
Validation loss: 2.07566270728906

Epoch: 5| Step: 8
Training loss: 1.7906138896942139
Validation loss: 2.068531940380732

Epoch: 5| Step: 9
Training loss: 1.667388916015625
Validation loss: 2.068219915032387

Epoch: 5| Step: 10
Training loss: 1.7903368473052979
Validation loss: 2.063765565554301

Epoch: 5| Step: 11
Training loss: 4.159548282623291
Validation loss: 2.0633553018172583

Epoch: 177| Step: 0
Training loss: 1.6054496765136719
Validation loss: 2.045567144950231

Epoch: 5| Step: 1
Training loss: 1.9452848434448242
Validation loss: 2.0727838973204293

Epoch: 5| Step: 2
Training loss: 2.073340892791748
Validation loss: 2.0833265632390976

Epoch: 5| Step: 3
Training loss: 2.501065731048584
Validation loss: 2.0823280860980353

Epoch: 5| Step: 4
Training loss: 1.8143949508666992
Validation loss: 2.0850366155306497

Epoch: 5| Step: 5
Training loss: 1.5855642557144165
Validation loss: 2.0981498559316

Epoch: 5| Step: 6
Training loss: 1.7780529260635376
Validation loss: 2.0793058772881827

Epoch: 5| Step: 7
Training loss: 2.1465682983398438
Validation loss: 2.091712772846222

Epoch: 5| Step: 8
Training loss: 2.4614343643188477
Validation loss: 2.0801999320586524

Epoch: 5| Step: 9
Training loss: 2.112067937850952
Validation loss: 2.0923141837120056

Epoch: 5| Step: 10
Training loss: 2.2071099281311035
Validation loss: 2.0696732501188913

Epoch: 5| Step: 11
Training loss: 1.608074426651001
Validation loss: 2.0737234900395074

Epoch: 178| Step: 0
Training loss: 2.3091068267822266
Validation loss: 2.063846384485563

Epoch: 5| Step: 1
Training loss: 1.681370735168457
Validation loss: 2.052117496728897

Epoch: 5| Step: 2
Training loss: 1.7485688924789429
Validation loss: 2.053763195872307

Epoch: 5| Step: 3
Training loss: 1.407827377319336
Validation loss: 2.0600177198648453

Epoch: 5| Step: 4
Training loss: 2.4340054988861084
Validation loss: 2.0462436030308404

Epoch: 5| Step: 5
Training loss: 2.0766780376434326
Validation loss: 2.0513415137926736

Epoch: 5| Step: 6
Training loss: 1.9101269245147705
Validation loss: 2.072363475958506

Epoch: 5| Step: 7
Training loss: 1.9253743886947632
Validation loss: 2.0548219780127206

Epoch: 5| Step: 8
Training loss: 2.364295482635498
Validation loss: 2.081032787760099

Epoch: 5| Step: 9
Training loss: 2.5871689319610596
Validation loss: 2.0732106963793435

Epoch: 5| Step: 10
Training loss: 1.9683176279067993
Validation loss: 2.05809585750103

Epoch: 5| Step: 11
Training loss: 2.2376809120178223
Validation loss: 2.0719065964221954

Epoch: 179| Step: 0
Training loss: 2.1160197257995605
Validation loss: 2.0782976746559143

Epoch: 5| Step: 1
Training loss: 2.1659982204437256
Validation loss: 2.075348600745201

Epoch: 5| Step: 2
Training loss: 1.9436359405517578
Validation loss: 2.0565481086572013

Epoch: 5| Step: 3
Training loss: 2.142256498336792
Validation loss: 2.0725360810756683

Epoch: 5| Step: 4
Training loss: 1.505638837814331
Validation loss: 2.06883741915226

Epoch: 5| Step: 5
Training loss: 1.6370830535888672
Validation loss: 2.0668346881866455

Epoch: 5| Step: 6
Training loss: 1.7725988626480103
Validation loss: 2.0758743435144424

Epoch: 5| Step: 7
Training loss: 2.802748441696167
Validation loss: 2.0760272989670434

Epoch: 5| Step: 8
Training loss: 2.185565710067749
Validation loss: 2.0636315594116845

Epoch: 5| Step: 9
Training loss: 1.8864368200302124
Validation loss: 2.0591317961613336

Epoch: 5| Step: 10
Training loss: 1.8314106464385986
Validation loss: 2.0543781916300454

Epoch: 5| Step: 11
Training loss: 1.7019431591033936
Validation loss: 2.057043711344401

Epoch: 180| Step: 0
Training loss: 2.0216801166534424
Validation loss: 2.0659953306118646

Epoch: 5| Step: 1
Training loss: 2.3499884605407715
Validation loss: 2.0648332933584848

Epoch: 5| Step: 2
Training loss: 1.6749515533447266
Validation loss: 2.0774853577216468

Epoch: 5| Step: 3
Training loss: 1.694898009300232
Validation loss: 2.0735733807086945

Epoch: 5| Step: 4
Training loss: 1.6507556438446045
Validation loss: 2.069606125354767

Epoch: 5| Step: 5
Training loss: 1.9738185405731201
Validation loss: 2.060331334670385

Epoch: 5| Step: 6
Training loss: 2.1818161010742188
Validation loss: 2.076820974548658

Epoch: 5| Step: 7
Training loss: 2.306908369064331
Validation loss: 2.0660107831160226

Epoch: 5| Step: 8
Training loss: 1.9476988315582275
Validation loss: 2.0691075722376504

Epoch: 5| Step: 9
Training loss: 1.9219681024551392
Validation loss: 2.0590045104424157

Epoch: 5| Step: 10
Training loss: 2.094229221343994
Validation loss: 2.060042122999827

Epoch: 5| Step: 11
Training loss: 1.568530559539795
Validation loss: 2.0658310651779175

Epoch: 181| Step: 0
Training loss: 1.9343783855438232
Validation loss: 2.0752034385999045

Epoch: 5| Step: 1
Training loss: 2.2038941383361816
Validation loss: 2.061575641234716

Epoch: 5| Step: 2
Training loss: 2.4677670001983643
Validation loss: 2.0635547737280526

Epoch: 5| Step: 3
Training loss: 1.729575514793396
Validation loss: 2.0704029500484467

Epoch: 5| Step: 4
Training loss: 1.6329177618026733
Validation loss: 2.0606031268835068

Epoch: 5| Step: 5
Training loss: 2.3481974601745605
Validation loss: 2.0581986606121063

Epoch: 5| Step: 6
Training loss: 2.05202054977417
Validation loss: 2.0530161261558533

Epoch: 5| Step: 7
Training loss: 1.8057060241699219
Validation loss: 2.059203719099363

Epoch: 5| Step: 8
Training loss: 2.095668315887451
Validation loss: 2.07269956668218

Epoch: 5| Step: 9
Training loss: 1.7075064182281494
Validation loss: 2.0632661084334054

Epoch: 5| Step: 10
Training loss: 1.7640044689178467
Validation loss: 2.062839830915133

Epoch: 5| Step: 11
Training loss: 2.4985508918762207
Validation loss: 2.058482160170873

Epoch: 182| Step: 0
Training loss: 2.1791532039642334
Validation loss: 2.0625377843777337

Epoch: 5| Step: 1
Training loss: 1.7115428447723389
Validation loss: 2.0619058112303414

Epoch: 5| Step: 2
Training loss: 1.9588664770126343
Validation loss: 2.067878156900406

Epoch: 5| Step: 3
Training loss: 2.1787514686584473
Validation loss: 2.0598783791065216

Epoch: 5| Step: 4
Training loss: 2.1832542419433594
Validation loss: 2.0586785475413003

Epoch: 5| Step: 5
Training loss: 1.9702444076538086
Validation loss: 2.0629491358995438

Epoch: 5| Step: 6
Training loss: 2.1014914512634277
Validation loss: 2.059869716564814

Epoch: 5| Step: 7
Training loss: 1.3060133457183838
Validation loss: 2.0567948718865714

Epoch: 5| Step: 8
Training loss: 2.227656126022339
Validation loss: 2.059843515356382

Epoch: 5| Step: 9
Training loss: 2.2215914726257324
Validation loss: 2.0730738987525306

Epoch: 5| Step: 10
Training loss: 1.718996286392212
Validation loss: 2.0557109117507935

Epoch: 5| Step: 11
Training loss: 2.20281982421875
Validation loss: 2.0683952371279397

Epoch: 183| Step: 0
Training loss: 2.144157886505127
Validation loss: 2.080400904019674

Epoch: 5| Step: 1
Training loss: 1.652396559715271
Validation loss: 2.084776376684507

Epoch: 5| Step: 2
Training loss: 2.021657943725586
Validation loss: 2.0909243325392404

Epoch: 5| Step: 3
Training loss: 1.971925973892212
Validation loss: 2.085549240310987

Epoch: 5| Step: 4
Training loss: 1.6437151432037354
Validation loss: 2.0917689949274063

Epoch: 5| Step: 5
Training loss: 2.3385727405548096
Validation loss: 2.0732503732045493

Epoch: 5| Step: 6
Training loss: 2.2547802925109863
Validation loss: 2.065147956212362

Epoch: 5| Step: 7
Training loss: 1.8754761219024658
Validation loss: 2.081579476594925

Epoch: 5| Step: 8
Training loss: 1.5725654363632202
Validation loss: 2.064873774846395

Epoch: 5| Step: 9
Training loss: 2.043388843536377
Validation loss: 2.058139438430468

Epoch: 5| Step: 10
Training loss: 2.347163438796997
Validation loss: 2.0598272532224655

Epoch: 5| Step: 11
Training loss: 2.579784393310547
Validation loss: 2.0486536572376886

Epoch: 184| Step: 0
Training loss: 2.1549174785614014
Validation loss: 2.0600896080334983

Epoch: 5| Step: 1
Training loss: 2.0319221019744873
Validation loss: 2.0436432709296546

Epoch: 5| Step: 2
Training loss: 1.9392973184585571
Validation loss: 2.0614450772603354

Epoch: 5| Step: 3
Training loss: 2.085336208343506
Validation loss: 2.0590596298376718

Epoch: 5| Step: 4
Training loss: 1.6940460205078125
Validation loss: 2.06347893178463

Epoch: 5| Step: 5
Training loss: 2.4289937019348145
Validation loss: 2.0718705554803214

Epoch: 5| Step: 6
Training loss: 1.6751654148101807
Validation loss: 2.0536666760842004

Epoch: 5| Step: 7
Training loss: 1.929211974143982
Validation loss: 2.0697209537029266

Epoch: 5| Step: 8
Training loss: 2.19820237159729
Validation loss: 2.0837393601735434

Epoch: 5| Step: 9
Training loss: 2.043142318725586
Validation loss: 2.0667287011941275

Epoch: 5| Step: 10
Training loss: 2.068819999694824
Validation loss: 2.0681405564149222

Epoch: 5| Step: 11
Training loss: 2.3272459506988525
Validation loss: 2.0810050865014396

Epoch: 185| Step: 0
Training loss: 2.2263429164886475
Validation loss: 2.0720395147800446

Epoch: 5| Step: 1
Training loss: 2.1332650184631348
Validation loss: 2.0706711610158286

Epoch: 5| Step: 2
Training loss: 2.078794479370117
Validation loss: 2.078926349679629

Epoch: 5| Step: 3
Training loss: 1.8334413766860962
Validation loss: 2.0786813497543335

Epoch: 5| Step: 4
Training loss: 1.9317042827606201
Validation loss: 2.0831671009461084

Epoch: 5| Step: 5
Training loss: 1.6167583465576172
Validation loss: 2.0803204278151193

Epoch: 5| Step: 6
Training loss: 2.188533067703247
Validation loss: 2.0650810102621713

Epoch: 5| Step: 7
Training loss: 1.8024909496307373
Validation loss: 2.06309467057387

Epoch: 5| Step: 8
Training loss: 2.037937641143799
Validation loss: 2.0692171305418015

Epoch: 5| Step: 9
Training loss: 1.8728078603744507
Validation loss: 2.0723453611135483

Epoch: 5| Step: 10
Training loss: 1.6514898538589478
Validation loss: 2.069310486316681

Epoch: 5| Step: 11
Training loss: 3.384078025817871
Validation loss: 2.0699324111143746

Epoch: 186| Step: 0
Training loss: 1.8331663608551025
Validation loss: 2.0855141480763755

Epoch: 5| Step: 1
Training loss: 2.3077034950256348
Validation loss: 2.088048900167147

Epoch: 5| Step: 2
Training loss: 1.6685116291046143
Validation loss: 2.0846537053585052

Epoch: 5| Step: 3
Training loss: 1.6341317892074585
Validation loss: 2.1029379119475684

Epoch: 5| Step: 4
Training loss: 1.7471940517425537
Validation loss: 2.0975395987431207

Epoch: 5| Step: 5
Training loss: 2.5208866596221924
Validation loss: 2.081433559457461

Epoch: 5| Step: 6
Training loss: 1.7995631694793701
Validation loss: 2.0879228164752326

Epoch: 5| Step: 7
Training loss: 1.7989251613616943
Validation loss: 2.078282887736956

Epoch: 5| Step: 8
Training loss: 1.5972782373428345
Validation loss: 2.073445791999499

Epoch: 5| Step: 9
Training loss: 2.189955949783325
Validation loss: 2.071556399265925

Epoch: 5| Step: 10
Training loss: 2.386085033416748
Validation loss: 2.0713698814312616

Epoch: 5| Step: 11
Training loss: 2.5281243324279785
Validation loss: 2.0692094961802163

Epoch: 187| Step: 0
Training loss: 2.4511008262634277
Validation loss: 2.068604275584221

Epoch: 5| Step: 1
Training loss: 1.5939775705337524
Validation loss: 2.061337023973465

Epoch: 5| Step: 2
Training loss: 1.831652045249939
Validation loss: 2.0606659849484763

Epoch: 5| Step: 3
Training loss: 1.767016053199768
Validation loss: 2.0662399580081305

Epoch: 5| Step: 4
Training loss: 2.2127153873443604
Validation loss: 2.0692340632279715

Epoch: 5| Step: 5
Training loss: 1.677172303199768
Validation loss: 2.0705775568882623

Epoch: 5| Step: 6
Training loss: 1.9672874212265015
Validation loss: 2.0690818428993225

Epoch: 5| Step: 7
Training loss: 1.8575931787490845
Validation loss: 2.0692686835924783

Epoch: 5| Step: 8
Training loss: 2.3001227378845215
Validation loss: 2.081577345728874

Epoch: 5| Step: 9
Training loss: 2.322828769683838
Validation loss: 2.0701092729965844

Epoch: 5| Step: 10
Training loss: 1.6826221942901611
Validation loss: 2.0832281361023584

Epoch: 5| Step: 11
Training loss: 1.8121176958084106
Validation loss: 2.0887075116237006

Epoch: 188| Step: 0
Training loss: 2.1756742000579834
Validation loss: 2.0824280182520547

Epoch: 5| Step: 1
Training loss: 1.9596436023712158
Validation loss: 2.090756436189016

Epoch: 5| Step: 2
Training loss: 1.9702361822128296
Validation loss: 2.092502141992251

Epoch: 5| Step: 3
Training loss: 2.045936346054077
Validation loss: 2.07207328081131

Epoch: 5| Step: 4
Training loss: 2.2096362113952637
Validation loss: 2.0722240060567856

Epoch: 5| Step: 5
Training loss: 1.8721164464950562
Validation loss: 2.065791209538778

Epoch: 5| Step: 6
Training loss: 1.7334043979644775
Validation loss: 2.0708125034968057

Epoch: 5| Step: 7
Training loss: 2.1222190856933594
Validation loss: 2.0780721058448157

Epoch: 5| Step: 8
Training loss: 1.5930198431015015
Validation loss: 2.0730682810147605

Epoch: 5| Step: 9
Training loss: 2.4286680221557617
Validation loss: 2.0722534507513046

Epoch: 5| Step: 10
Training loss: 1.7703965902328491
Validation loss: 2.076027035713196

Epoch: 5| Step: 11
Training loss: 1.6253734827041626
Validation loss: 2.0864097625017166

Epoch: 189| Step: 0
Training loss: 2.2248587608337402
Validation loss: 2.071665644645691

Epoch: 5| Step: 1
Training loss: 1.5796211957931519
Validation loss: 2.0857950001955032

Epoch: 5| Step: 2
Training loss: 2.325284957885742
Validation loss: 2.0944285690784454

Epoch: 5| Step: 3
Training loss: 2.1451518535614014
Validation loss: 2.0940863440434136

Epoch: 5| Step: 4
Training loss: 1.6162397861480713
Validation loss: 2.104035576184591

Epoch: 5| Step: 5
Training loss: 1.6602141857147217
Validation loss: 2.1002850383520126

Epoch: 5| Step: 6
Training loss: 1.7272872924804688
Validation loss: 2.097021907567978

Epoch: 5| Step: 7
Training loss: 2.471975803375244
Validation loss: 2.098039055864016

Epoch: 5| Step: 8
Training loss: 2.033161163330078
Validation loss: 2.093298152089119

Epoch: 5| Step: 9
Training loss: 1.8766534328460693
Validation loss: 2.067906285325686

Epoch: 5| Step: 10
Training loss: 1.6572080850601196
Validation loss: 2.074084629615148

Epoch: 5| Step: 11
Training loss: 3.4446029663085938
Validation loss: 2.064544051885605

Epoch: 190| Step: 0
Training loss: 2.1408257484436035
Validation loss: 2.0609702418247857

Epoch: 5| Step: 1
Training loss: 2.4952425956726074
Validation loss: 2.061498244603475

Epoch: 5| Step: 2
Training loss: 2.426464796066284
Validation loss: 2.0624442249536514

Epoch: 5| Step: 3
Training loss: 1.634852409362793
Validation loss: 2.0664672404527664

Epoch: 5| Step: 4
Training loss: 1.9123948812484741
Validation loss: 2.056343952814738

Epoch: 5| Step: 5
Training loss: 1.8847030401229858
Validation loss: 2.0569920440514884

Epoch: 5| Step: 6
Training loss: 2.1905295848846436
Validation loss: 2.0632065385580063

Epoch: 5| Step: 7
Training loss: 2.3200249671936035
Validation loss: 2.0590565900007882

Epoch: 5| Step: 8
Training loss: 2.3672966957092285
Validation loss: 2.0524737189213433

Epoch: 5| Step: 9
Training loss: 1.827894926071167
Validation loss: 2.049736147125562

Epoch: 5| Step: 10
Training loss: 1.5461254119873047
Validation loss: 2.0615021387736

Epoch: 5| Step: 11
Training loss: 1.4918723106384277
Validation loss: 2.072665070494016

Epoch: 191| Step: 0
Training loss: 1.3949501514434814
Validation loss: 2.080743432044983

Epoch: 5| Step: 1
Training loss: 2.628265857696533
Validation loss: 2.097309793035189

Epoch: 5| Step: 2
Training loss: 1.5045373439788818
Validation loss: 2.0980959782997766

Epoch: 5| Step: 3
Training loss: 2.445277452468872
Validation loss: 2.1079957087834678

Epoch: 5| Step: 4
Training loss: 2.4986681938171387
Validation loss: 2.092814395825068

Epoch: 5| Step: 5
Training loss: 2.0229296684265137
Validation loss: 2.1102716475725174

Epoch: 5| Step: 6
Training loss: 1.7419795989990234
Validation loss: 2.0995418777068457

Epoch: 5| Step: 7
Training loss: 1.952820062637329
Validation loss: 2.09329129755497

Epoch: 5| Step: 8
Training loss: 2.2629332542419434
Validation loss: 2.080222432812055

Epoch: 5| Step: 9
Training loss: 2.336543560028076
Validation loss: 2.101931949456533

Epoch: 5| Step: 10
Training loss: 1.9416921138763428
Validation loss: 2.0974340786536536

Epoch: 5| Step: 11
Training loss: 0.7315843105316162
Validation loss: 2.0845889151096344

Epoch: 192| Step: 0
Training loss: 1.9342254400253296
Validation loss: 2.0802879383166633

Epoch: 5| Step: 1
Training loss: 1.8777010440826416
Validation loss: 2.0685745428005853

Epoch: 5| Step: 2
Training loss: 1.6777136325836182
Validation loss: 2.0870873828728995

Epoch: 5| Step: 3
Training loss: 1.8575547933578491
Validation loss: 2.070591618617376

Epoch: 5| Step: 4
Training loss: 2.7326788902282715
Validation loss: 2.0609424908955893

Epoch: 5| Step: 5
Training loss: 2.011456251144409
Validation loss: 2.0694176306327186

Epoch: 5| Step: 6
Training loss: 1.8728660345077515
Validation loss: 2.061749145388603

Epoch: 5| Step: 7
Training loss: 1.7327430248260498
Validation loss: 2.0793733845154443

Epoch: 5| Step: 8
Training loss: 2.235974073410034
Validation loss: 2.077137127518654

Epoch: 5| Step: 9
Training loss: 1.848598837852478
Validation loss: 2.084134424726168

Epoch: 5| Step: 10
Training loss: 1.9194129705429077
Validation loss: 2.079655130704244

Epoch: 5| Step: 11
Training loss: 3.128366470336914
Validation loss: 2.085685352484385

Epoch: 193| Step: 0
Training loss: 1.6157516241073608
Validation loss: 2.073399066925049

Epoch: 5| Step: 1
Training loss: 2.4499075412750244
Validation loss: 2.0727003117402396

Epoch: 5| Step: 2
Training loss: 1.979397177696228
Validation loss: 2.0770801305770874

Epoch: 5| Step: 3
Training loss: 1.6863044500350952
Validation loss: 2.0630370875199637

Epoch: 5| Step: 4
Training loss: 2.1974689960479736
Validation loss: 2.071029245853424

Epoch: 5| Step: 5
Training loss: 1.701505422592163
Validation loss: 2.0768635173638663

Epoch: 5| Step: 6
Training loss: 2.125654697418213
Validation loss: 2.0807207226753235

Epoch: 5| Step: 7
Training loss: 2.9644980430603027
Validation loss: 2.0717696895202002

Epoch: 5| Step: 8
Training loss: 1.6352198123931885
Validation loss: 2.074825276931127

Epoch: 5| Step: 9
Training loss: 1.7732868194580078
Validation loss: 2.0681115637222924

Epoch: 5| Step: 10
Training loss: 1.7297779321670532
Validation loss: 2.0733375251293182

Epoch: 5| Step: 11
Training loss: 1.88466477394104
Validation loss: 2.0751042316357293

Epoch: 194| Step: 0
Training loss: 1.66604483127594
Validation loss: 2.0842451651891074

Epoch: 5| Step: 1
Training loss: 1.5724201202392578
Validation loss: 2.088248794277509

Epoch: 5| Step: 2
Training loss: 1.9967873096466064
Validation loss: 2.0892952432235083

Epoch: 5| Step: 3
Training loss: 2.2596397399902344
Validation loss: 2.1030799547831216

Epoch: 5| Step: 4
Training loss: 1.7611734867095947
Validation loss: 2.109785795211792

Epoch: 5| Step: 5
Training loss: 1.6659154891967773
Validation loss: 2.1068422744671502

Epoch: 5| Step: 6
Training loss: 2.3040976524353027
Validation loss: 2.110001504421234

Epoch: 5| Step: 7
Training loss: 2.295893669128418
Validation loss: 2.107995887597402

Epoch: 5| Step: 8
Training loss: 2.21893572807312
Validation loss: 2.1124729812145233

Epoch: 5| Step: 9
Training loss: 2.361848831176758
Validation loss: 2.101097047328949

Epoch: 5| Step: 10
Training loss: 1.925702691078186
Validation loss: 2.092980523904165

Epoch: 5| Step: 11
Training loss: 1.304403305053711
Validation loss: 2.089507127801577

Epoch: 195| Step: 0
Training loss: 2.016026020050049
Validation loss: 2.0803338438272476

Epoch: 5| Step: 1
Training loss: 2.087432384490967
Validation loss: 2.0862345695495605

Epoch: 5| Step: 2
Training loss: 1.7600841522216797
Validation loss: 2.076043317715327

Epoch: 5| Step: 3
Training loss: 2.246997833251953
Validation loss: 2.0633263190587363

Epoch: 5| Step: 4
Training loss: 2.0798611640930176
Validation loss: 2.0681172013282776

Epoch: 5| Step: 5
Training loss: 2.1388368606567383
Validation loss: 2.071613162755966

Epoch: 5| Step: 6
Training loss: 2.2054481506347656
Validation loss: 2.074224362770716

Epoch: 5| Step: 7
Training loss: 1.9916088581085205
Validation loss: 2.065136214097341

Epoch: 5| Step: 8
Training loss: 1.9922008514404297
Validation loss: 2.0680101811885834

Epoch: 5| Step: 9
Training loss: 1.8396532535552979
Validation loss: 2.0860140870014825

Epoch: 5| Step: 10
Training loss: 1.4761338233947754
Validation loss: 2.0875286559263864

Epoch: 5| Step: 11
Training loss: 1.2184311151504517
Validation loss: 2.0944561858971915

Epoch: 196| Step: 0
Training loss: 1.9189773797988892
Validation loss: 2.079607049624125

Epoch: 5| Step: 1
Training loss: 1.4790990352630615
Validation loss: 2.1032099475463233

Epoch: 5| Step: 2
Training loss: 2.3099279403686523
Validation loss: 2.097028831640879

Epoch: 5| Step: 3
Training loss: 1.9112327098846436
Validation loss: 2.0992469837268195

Epoch: 5| Step: 4
Training loss: 1.571338415145874
Validation loss: 2.0982237408558526

Epoch: 5| Step: 5
Training loss: 2.017216920852661
Validation loss: 2.0997071067492166

Epoch: 5| Step: 6
Training loss: 1.9094581604003906
Validation loss: 2.091077228387197

Epoch: 5| Step: 7
Training loss: 2.8824050426483154
Validation loss: 2.0833834608395896

Epoch: 5| Step: 8
Training loss: 1.8954299688339233
Validation loss: 2.0849440644184747

Epoch: 5| Step: 9
Training loss: 2.273738145828247
Validation loss: 2.084818477431933

Epoch: 5| Step: 10
Training loss: 1.755425214767456
Validation loss: 2.0895800044139228

Epoch: 5| Step: 11
Training loss: 0.8102006912231445
Validation loss: 2.084552377462387

Epoch: 197| Step: 0
Training loss: 2.2252118587493896
Validation loss: 2.0736134350299835

Epoch: 5| Step: 1
Training loss: 2.0306479930877686
Validation loss: 2.0821158985296884

Epoch: 5| Step: 2
Training loss: 2.093473434448242
Validation loss: 2.0799228499333062

Epoch: 5| Step: 3
Training loss: 2.30452561378479
Validation loss: 2.075238913297653

Epoch: 5| Step: 4
Training loss: 1.577181339263916
Validation loss: 2.085423469543457

Epoch: 5| Step: 5
Training loss: 2.0585548877716064
Validation loss: 2.0761619210243225

Epoch: 5| Step: 6
Training loss: 1.5944641828536987
Validation loss: 2.0742757469415665

Epoch: 5| Step: 7
Training loss: 2.243335008621216
Validation loss: 2.070656324426333

Epoch: 5| Step: 8
Training loss: 1.8467258214950562
Validation loss: 2.0749734292427697

Epoch: 5| Step: 9
Training loss: 1.9035120010375977
Validation loss: 2.0727344304323196

Epoch: 5| Step: 10
Training loss: 1.8985874652862549
Validation loss: 2.0633992652098336

Epoch: 5| Step: 11
Training loss: 2.248899459838867
Validation loss: 2.0805542369683585

Epoch: 198| Step: 0
Training loss: 1.791343331336975
Validation loss: 2.0848311434189477

Epoch: 5| Step: 1
Training loss: 1.8710750341415405
Validation loss: 2.0772744516531625

Epoch: 5| Step: 2
Training loss: 1.7168464660644531
Validation loss: 2.069584901134173

Epoch: 5| Step: 3
Training loss: 1.9777381420135498
Validation loss: 2.0757572750250497

Epoch: 5| Step: 4
Training loss: 1.8508344888687134
Validation loss: 2.072055771946907

Epoch: 5| Step: 5
Training loss: 2.0544803142547607
Validation loss: 2.062993417183558

Epoch: 5| Step: 6
Training loss: 2.333712339401245
Validation loss: 2.0713945080836615

Epoch: 5| Step: 7
Training loss: 2.204794406890869
Validation loss: 2.0666691114505134

Epoch: 5| Step: 8
Training loss: 1.6280807256698608
Validation loss: 2.0830056567986808

Epoch: 5| Step: 9
Training loss: 2.2655646800994873
Validation loss: 2.063078468044599

Epoch: 5| Step: 10
Training loss: 2.3343868255615234
Validation loss: 2.074046184619268

Epoch: 5| Step: 11
Training loss: 0.9893264770507812
Validation loss: 2.071154683828354

Epoch: 199| Step: 0
Training loss: 1.8380588293075562
Validation loss: 2.0712071657180786

Epoch: 5| Step: 1
Training loss: 1.9743887186050415
Validation loss: 2.072699377934138

Epoch: 5| Step: 2
Training loss: 2.032046318054199
Validation loss: 2.074055035909017

Epoch: 5| Step: 3
Training loss: 1.5422968864440918
Validation loss: 2.0795690019925437

Epoch: 5| Step: 4
Training loss: 1.7413612604141235
Validation loss: 2.0796538442373276

Epoch: 5| Step: 5
Training loss: 1.9391940832138062
Validation loss: 2.0959395517905555

Epoch: 5| Step: 6
Training loss: 2.0813679695129395
Validation loss: 2.095100854833921

Epoch: 5| Step: 7
Training loss: 2.6437032222747803
Validation loss: 2.1018850753704705

Epoch: 5| Step: 8
Training loss: 1.8683984279632568
Validation loss: 2.1206311136484146

Epoch: 5| Step: 9
Training loss: 2.3214313983917236
Validation loss: 2.1130854338407516

Epoch: 5| Step: 10
Training loss: 1.9093196392059326
Validation loss: 2.1089353263378143

Epoch: 5| Step: 11
Training loss: 1.8200721740722656
Validation loss: 2.0950803260008493

Epoch: 200| Step: 0
Training loss: 2.1078948974609375
Validation loss: 2.0923774987459183

Epoch: 5| Step: 1
Training loss: 1.6489667892456055
Validation loss: 2.0862458993991218

Epoch: 5| Step: 2
Training loss: 1.6003093719482422
Validation loss: 2.0784652729829154

Epoch: 5| Step: 3
Training loss: 1.8041832447052002
Validation loss: 2.0961234321196875

Epoch: 5| Step: 4
Training loss: 1.9365841150283813
Validation loss: 2.0857425034046173

Epoch: 5| Step: 5
Training loss: 2.2462005615234375
Validation loss: 2.091163461407026

Epoch: 5| Step: 6
Training loss: 2.362178087234497
Validation loss: 2.090122083822886

Epoch: 5| Step: 7
Training loss: 2.0609428882598877
Validation loss: 2.0946053862571716

Epoch: 5| Step: 8
Training loss: 1.7962898015975952
Validation loss: 2.0936706562836966

Epoch: 5| Step: 9
Training loss: 2.411862850189209
Validation loss: 2.0892806152502694

Epoch: 5| Step: 10
Training loss: 1.768090009689331
Validation loss: 2.089336097240448

Epoch: 5| Step: 11
Training loss: 1.145721435546875
Validation loss: 2.094824785987536

Epoch: 201| Step: 0
Training loss: 2.163153886795044
Validation loss: 2.0846756349007287

Epoch: 5| Step: 1
Training loss: 1.450921893119812
Validation loss: 2.0968689620494843

Epoch: 5| Step: 2
Training loss: 2.126915454864502
Validation loss: 2.0831491549809775

Epoch: 5| Step: 3
Training loss: 1.988997220993042
Validation loss: 2.0977654457092285

Epoch: 5| Step: 4
Training loss: 1.520898461341858
Validation loss: 2.079017420609792

Epoch: 5| Step: 5
Training loss: 2.330775737762451
Validation loss: 2.0778072575728097

Epoch: 5| Step: 6
Training loss: 1.81813645362854
Validation loss: 2.0894965628782907

Epoch: 5| Step: 7
Training loss: 2.211961507797241
Validation loss: 2.0839847077926

Epoch: 5| Step: 8
Training loss: 2.397937536239624
Validation loss: 2.0747636357943215

Epoch: 5| Step: 9
Training loss: 1.8950809240341187
Validation loss: 2.0991964787244797

Epoch: 5| Step: 10
Training loss: 1.8910961151123047
Validation loss: 2.0832518289486566

Epoch: 5| Step: 11
Training loss: 1.3922123908996582
Validation loss: 2.090431993206342

Epoch: 202| Step: 0
Training loss: 1.3937749862670898
Validation loss: 2.082047551870346

Epoch: 5| Step: 1
Training loss: 2.4240546226501465
Validation loss: 2.0891096194585166

Epoch: 5| Step: 2
Training loss: 1.2234386205673218
Validation loss: 2.089385579029719

Epoch: 5| Step: 3
Training loss: 1.4079177379608154
Validation loss: 2.0792433569828668

Epoch: 5| Step: 4
Training loss: 2.3109290599823
Validation loss: 2.088788171609243

Epoch: 5| Step: 5
Training loss: 2.031425714492798
Validation loss: 2.0809578796227775

Epoch: 5| Step: 6
Training loss: 2.119954824447632
Validation loss: 2.0836009283860526

Epoch: 5| Step: 7
Training loss: 2.330127477645874
Validation loss: 2.0910589396953583

Epoch: 5| Step: 8
Training loss: 1.7667558193206787
Validation loss: 2.084698756535848

Epoch: 5| Step: 9
Training loss: 2.1300952434539795
Validation loss: 2.0928269773721695

Epoch: 5| Step: 10
Training loss: 2.4838688373565674
Validation loss: 2.0794475128253302

Epoch: 5| Step: 11
Training loss: 2.0876283645629883
Validation loss: 2.096047888199488

Epoch: 203| Step: 0
Training loss: 1.896323561668396
Validation loss: 2.0977110117673874

Epoch: 5| Step: 1
Training loss: 1.8825056552886963
Validation loss: 2.107745885848999

Epoch: 5| Step: 2
Training loss: 2.1602282524108887
Validation loss: 2.1015627086162567

Epoch: 5| Step: 3
Training loss: 1.942214012145996
Validation loss: 2.106368670860926

Epoch: 5| Step: 4
Training loss: 2.404064178466797
Validation loss: 2.105108837286631

Epoch: 5| Step: 5
Training loss: 1.7305996417999268
Validation loss: 2.0920654237270355

Epoch: 5| Step: 6
Training loss: 2.429736614227295
Validation loss: 2.097990314165751

Epoch: 5| Step: 7
Training loss: 1.4922163486480713
Validation loss: 2.1015304625034332

Epoch: 5| Step: 8
Training loss: 1.371934175491333
Validation loss: 2.103569815556208

Epoch: 5| Step: 9
Training loss: 1.897833228111267
Validation loss: 2.101235121488571

Epoch: 5| Step: 10
Training loss: 2.064927101135254
Validation loss: 2.1058970391750336

Epoch: 5| Step: 11
Training loss: 2.6500325202941895
Validation loss: 2.0991302132606506

Epoch: 204| Step: 0
Training loss: 2.7066965103149414
Validation loss: 2.095545381307602

Epoch: 5| Step: 1
Training loss: 1.5389821529388428
Validation loss: 2.0980796267588935

Epoch: 5| Step: 2
Training loss: 1.9677261114120483
Validation loss: 2.1114024072885513

Epoch: 5| Step: 3
Training loss: 1.9574928283691406
Validation loss: 2.09532767534256

Epoch: 5| Step: 4
Training loss: 1.792992353439331
Validation loss: 2.105352222919464

Epoch: 5| Step: 5
Training loss: 1.9743220806121826
Validation loss: 2.0967088441054025

Epoch: 5| Step: 6
Training loss: 1.7119932174682617
Validation loss: 2.0943066080411277

Epoch: 5| Step: 7
Training loss: 2.120363473892212
Validation loss: 2.102580805619558

Epoch: 5| Step: 8
Training loss: 1.5480595827102661
Validation loss: 2.1121033827463784

Epoch: 5| Step: 9
Training loss: 1.9443811178207397
Validation loss: 2.1154287656148276

Epoch: 5| Step: 10
Training loss: 2.2536404132843018
Validation loss: 2.121698791782061

Epoch: 5| Step: 11
Training loss: 1.3960967063903809
Validation loss: 2.130700170993805

Epoch: 205| Step: 0
Training loss: 2.6734426021575928
Validation loss: 2.1201037069161734

Epoch: 5| Step: 1
Training loss: 1.9461915493011475
Validation loss: 2.1299122075239816

Epoch: 5| Step: 2
Training loss: 1.7530161142349243
Validation loss: 2.1148344775040946

Epoch: 5| Step: 3
Training loss: 2.2672781944274902
Validation loss: 2.1055894593397775

Epoch: 5| Step: 4
Training loss: 1.3299094438552856
Validation loss: 2.1018397907416024

Epoch: 5| Step: 5
Training loss: 1.8759734630584717
Validation loss: 2.1085307796796164

Epoch: 5| Step: 6
Training loss: 1.7356033325195312
Validation loss: 2.100922092795372

Epoch: 5| Step: 7
Training loss: 2.756840467453003
Validation loss: 2.104266340533892

Epoch: 5| Step: 8
Training loss: 1.8753585815429688
Validation loss: 2.0950975815455117

Epoch: 5| Step: 9
Training loss: 1.7687008380889893
Validation loss: 2.0966410537560782

Epoch: 5| Step: 10
Training loss: 1.6929473876953125
Validation loss: 2.1014313151439032

Epoch: 5| Step: 11
Training loss: 1.548130989074707
Validation loss: 2.099188049634298

Epoch: 206| Step: 0
Training loss: 2.3505733013153076
Validation loss: 2.1149532198905945

Epoch: 5| Step: 1
Training loss: 1.4379624128341675
Validation loss: 2.1253142754236856

Epoch: 5| Step: 2
Training loss: 2.0392136573791504
Validation loss: 2.1318512459596

Epoch: 5| Step: 3
Training loss: 1.750345230102539
Validation loss: 2.145597671469053

Epoch: 5| Step: 4
Training loss: 1.5380802154541016
Validation loss: 2.1309438049793243

Epoch: 5| Step: 5
Training loss: 1.4487860202789307
Validation loss: 2.1364526450634003

Epoch: 5| Step: 6
Training loss: 2.0749998092651367
Validation loss: 2.1216326455275216

Epoch: 5| Step: 7
Training loss: 2.6539814472198486
Validation loss: 2.135572776198387

Epoch: 5| Step: 8
Training loss: 1.9149749279022217
Validation loss: 2.1199458291133246

Epoch: 5| Step: 9
Training loss: 2.342705488204956
Validation loss: 2.104273493091265

Epoch: 5| Step: 10
Training loss: 2.258155345916748
Validation loss: 2.101633220911026

Epoch: 5| Step: 11
Training loss: 1.6059153079986572
Validation loss: 2.1066095381975174

Epoch: 207| Step: 0
Training loss: 1.7671966552734375
Validation loss: 2.088001231352488

Epoch: 5| Step: 1
Training loss: 1.9250447750091553
Validation loss: 2.079486141602198

Epoch: 5| Step: 2
Training loss: 1.4400798082351685
Validation loss: 2.0886803468068442

Epoch: 5| Step: 3
Training loss: 2.040225028991699
Validation loss: 2.0819689631462097

Epoch: 5| Step: 4
Training loss: 1.8814254999160767
Validation loss: 2.096545328696569

Epoch: 5| Step: 5
Training loss: 2.634800672531128
Validation loss: 2.0843833684921265

Epoch: 5| Step: 6
Training loss: 1.7036364078521729
Validation loss: 2.09489244222641

Epoch: 5| Step: 7
Training loss: 2.0537803173065186
Validation loss: 2.1011231392621994

Epoch: 5| Step: 8
Training loss: 2.2939677238464355
Validation loss: 2.1167143136262894

Epoch: 5| Step: 9
Training loss: 2.0512759685516357
Validation loss: 2.113035415609678

Epoch: 5| Step: 10
Training loss: 2.386319637298584
Validation loss: 2.1281492511431375

Epoch: 5| Step: 11
Training loss: 1.5319957733154297
Validation loss: 2.116027355194092

Epoch: 208| Step: 0
Training loss: 2.3776309490203857
Validation loss: 2.123717283209165

Epoch: 5| Step: 1
Training loss: 2.190931558609009
Validation loss: 2.1161892215410867

Epoch: 5| Step: 2
Training loss: 1.6088123321533203
Validation loss: 2.1086080372333527

Epoch: 5| Step: 3
Training loss: 1.5705206394195557
Validation loss: 2.1168696532646814

Epoch: 5| Step: 4
Training loss: 1.5672701597213745
Validation loss: 2.1157316863536835

Epoch: 5| Step: 5
Training loss: 1.878822684288025
Validation loss: 2.1040853609641395

Epoch: 5| Step: 6
Training loss: 1.96756112575531
Validation loss: 2.1126367300748825

Epoch: 5| Step: 7
Training loss: 1.6367133855819702
Validation loss: 2.1044417321681976

Epoch: 5| Step: 8
Training loss: 1.7824710607528687
Validation loss: 2.117079267899195

Epoch: 5| Step: 9
Training loss: 2.4932844638824463
Validation loss: 2.1061038921276727

Epoch: 5| Step: 10
Training loss: 2.1030001640319824
Validation loss: 2.1155194640159607

Epoch: 5| Step: 11
Training loss: 2.7814784049987793
Validation loss: 2.105933338403702

Epoch: 209| Step: 0
Training loss: 2.4062139987945557
Validation loss: 2.111263101299604

Epoch: 5| Step: 1
Training loss: 1.738509178161621
Validation loss: 2.088635673125585

Epoch: 5| Step: 2
Training loss: 1.9159507751464844
Validation loss: 2.098175525665283

Epoch: 5| Step: 3
Training loss: 1.7616889476776123
Validation loss: 2.1029489735762277

Epoch: 5| Step: 4
Training loss: 2.279068946838379
Validation loss: 2.102038790782293

Epoch: 5| Step: 5
Training loss: 2.056640625
Validation loss: 2.0933515280485153

Epoch: 5| Step: 6
Training loss: 1.9871190786361694
Validation loss: 2.111729512612025

Epoch: 5| Step: 7
Training loss: 1.7606347799301147
Validation loss: 2.1072281499703727

Epoch: 5| Step: 8
Training loss: 2.1512348651885986
Validation loss: 2.1017039120197296

Epoch: 5| Step: 9
Training loss: 1.878788709640503
Validation loss: 2.111361791690191

Epoch: 5| Step: 10
Training loss: 1.6169027090072632
Validation loss: 2.0956832418839135

Epoch: 5| Step: 11
Training loss: 0.9036767482757568
Validation loss: 2.091556583841642

Epoch: 210| Step: 0
Training loss: 1.7362911701202393
Validation loss: 2.0973216195901236

Epoch: 5| Step: 1
Training loss: 1.8831126689910889
Validation loss: 2.1004387636979422

Epoch: 5| Step: 2
Training loss: 2.3293633460998535
Validation loss: 2.099360699454943

Epoch: 5| Step: 3
Training loss: 2.2389328479766846
Validation loss: 2.0985746582349143

Epoch: 5| Step: 4
Training loss: 1.4680957794189453
Validation loss: 2.110973392923673

Epoch: 5| Step: 5
Training loss: 1.5492057800292969
Validation loss: 2.121753697594007

Epoch: 5| Step: 6
Training loss: 1.3750836849212646
Validation loss: 2.1372817556063333

Epoch: 5| Step: 7
Training loss: 1.9426460266113281
Validation loss: 2.1256364782651267

Epoch: 5| Step: 8
Training loss: 2.8668055534362793
Validation loss: 2.128239785631498

Epoch: 5| Step: 9
Training loss: 2.014803409576416
Validation loss: 2.1267362534999847

Epoch: 5| Step: 10
Training loss: 1.9023075103759766
Validation loss: 2.11719574034214

Epoch: 5| Step: 11
Training loss: 1.8877646923065186
Validation loss: 2.1073593348264694

Epoch: 211| Step: 0
Training loss: 1.9498164653778076
Validation loss: 2.1026591112216315

Epoch: 5| Step: 1
Training loss: 1.6837472915649414
Validation loss: 2.0984291781981788

Epoch: 5| Step: 2
Training loss: 1.9110081195831299
Validation loss: 2.088048666715622

Epoch: 5| Step: 3
Training loss: 2.18444561958313
Validation loss: 2.0936962962150574

Epoch: 5| Step: 4
Training loss: 2.1751151084899902
Validation loss: 2.0896216183900833

Epoch: 5| Step: 5
Training loss: 2.1106317043304443
Validation loss: 2.097195873657862

Epoch: 5| Step: 6
Training loss: 2.0908448696136475
Validation loss: 2.0992253124713898

Epoch: 5| Step: 7
Training loss: 1.8527395725250244
Validation loss: 2.1042240063349404

Epoch: 5| Step: 8
Training loss: 2.0864498615264893
Validation loss: 2.117145150899887

Epoch: 5| Step: 9
Training loss: 2.2082719802856445
Validation loss: 2.1156453440586724

Epoch: 5| Step: 10
Training loss: 1.5852737426757812
Validation loss: 2.1255824069182077

Epoch: 5| Step: 11
Training loss: 1.793443202972412
Validation loss: 2.1441349188486734

Epoch: 212| Step: 0
Training loss: 1.379108190536499
Validation loss: 2.1381238102912903

Epoch: 5| Step: 1
Training loss: 2.3904671669006348
Validation loss: 2.150000403324763

Epoch: 5| Step: 2
Training loss: 2.1046371459960938
Validation loss: 2.1341134955485663

Epoch: 5| Step: 3
Training loss: 1.7373863458633423
Validation loss: 2.13605364660422

Epoch: 5| Step: 4
Training loss: 2.161618232727051
Validation loss: 2.136566008130709

Epoch: 5| Step: 5
Training loss: 2.017102003097534
Validation loss: 2.137324964006742

Epoch: 5| Step: 6
Training loss: 1.7047752141952515
Validation loss: 2.142916589975357

Epoch: 5| Step: 7
Training loss: 2.285592555999756
Validation loss: 2.1253659228483834

Epoch: 5| Step: 8
Training loss: 1.9239253997802734
Validation loss: 2.1350905348857245

Epoch: 5| Step: 9
Training loss: 1.6047559976577759
Validation loss: 2.1283209522565207

Epoch: 5| Step: 10
Training loss: 2.146315097808838
Validation loss: 2.1176039973894754

Epoch: 5| Step: 11
Training loss: 0.2026791274547577
Validation loss: 2.108889172474543

Epoch: 213| Step: 0
Training loss: 1.7146621942520142
Validation loss: 2.1120181580384574

Epoch: 5| Step: 1
Training loss: 1.7850010395050049
Validation loss: 2.108885566393534

Epoch: 5| Step: 2
Training loss: 1.552841305732727
Validation loss: 2.113999476035436

Epoch: 5| Step: 3
Training loss: 1.794353723526001
Validation loss: 2.10701717933019

Epoch: 5| Step: 4
Training loss: 2.0459790229797363
Validation loss: 2.1016090462605157

Epoch: 5| Step: 5
Training loss: 1.7461261749267578
Validation loss: 2.1107062896092734

Epoch: 5| Step: 6
Training loss: 2.3125901222229004
Validation loss: 2.1236597150564194

Epoch: 5| Step: 7
Training loss: 2.128544569015503
Validation loss: 2.1215613782405853

Epoch: 5| Step: 8
Training loss: 2.045654773712158
Validation loss: 2.1186446845531464

Epoch: 5| Step: 9
Training loss: 2.090911865234375
Validation loss: 2.1416872988144555

Epoch: 5| Step: 10
Training loss: 2.1593310832977295
Validation loss: 2.147334655125936

Epoch: 5| Step: 11
Training loss: 1.5210301876068115
Validation loss: 2.139539827903112

Epoch: 214| Step: 0
Training loss: 2.4019198417663574
Validation loss: 2.1323453187942505

Epoch: 5| Step: 1
Training loss: 2.152228593826294
Validation loss: 2.117961580554644

Epoch: 5| Step: 2
Training loss: 2.7588419914245605
Validation loss: 2.1150904844204583

Epoch: 5| Step: 3
Training loss: 1.9902856349945068
Validation loss: 2.1113695055246353

Epoch: 5| Step: 4
Training loss: 1.5875723361968994
Validation loss: 2.118538022041321

Epoch: 5| Step: 5
Training loss: 1.7772114276885986
Validation loss: 2.110138530532519

Epoch: 5| Step: 6
Training loss: 1.4026566743850708
Validation loss: 2.108273963133494

Epoch: 5| Step: 7
Training loss: 2.1269805431365967
Validation loss: 2.1112262904644012

Epoch: 5| Step: 8
Training loss: 2.130840301513672
Validation loss: 2.1037963330745697

Epoch: 5| Step: 9
Training loss: 1.3689985275268555
Validation loss: 2.1066076705853143

Epoch: 5| Step: 10
Training loss: 1.4791048765182495
Validation loss: 2.115164195497831

Epoch: 5| Step: 11
Training loss: 1.5496848821640015
Validation loss: 2.1064890970786414

Epoch: 215| Step: 0
Training loss: 1.8880395889282227
Validation loss: 2.124962275226911

Epoch: 5| Step: 1
Training loss: 2.272355556488037
Validation loss: 2.116552342971166

Epoch: 5| Step: 2
Training loss: 1.2059062719345093
Validation loss: 2.109823519984881

Epoch: 5| Step: 3
Training loss: 2.0932037830352783
Validation loss: 2.1288586308558783

Epoch: 5| Step: 4
Training loss: 2.321570873260498
Validation loss: 2.135130191842715

Epoch: 5| Step: 5
Training loss: 1.9767706394195557
Validation loss: 2.1172472536563873

Epoch: 5| Step: 6
Training loss: 2.3278346061706543
Validation loss: 2.1141509960095086

Epoch: 5| Step: 7
Training loss: 1.7568496465682983
Validation loss: 2.1180369704961777

Epoch: 5| Step: 8
Training loss: 1.6885417699813843
Validation loss: 2.134059111277262

Epoch: 5| Step: 9
Training loss: 1.690908432006836
Validation loss: 2.1224472920099893

Epoch: 5| Step: 10
Training loss: 1.6195743083953857
Validation loss: 2.134696145852407

Epoch: 5| Step: 11
Training loss: 2.8890974521636963
Validation loss: 2.125134269396464

Epoch: 216| Step: 0
Training loss: 1.9520155191421509
Validation loss: 2.10333580772082

Epoch: 5| Step: 1
Training loss: 2.280595541000366
Validation loss: 2.1239411433537803

Epoch: 5| Step: 2
Training loss: 1.969465970993042
Validation loss: 2.109786038597425

Epoch: 5| Step: 3
Training loss: 2.7288291454315186
Validation loss: 2.110179901123047

Epoch: 5| Step: 4
Training loss: 1.5349279642105103
Validation loss: 2.0974173297484717

Epoch: 5| Step: 5
Training loss: 1.9294216632843018
Validation loss: 2.1002682546774545

Epoch: 5| Step: 6
Training loss: 1.695166826248169
Validation loss: 2.1050340235233307

Epoch: 5| Step: 7
Training loss: 1.4629130363464355
Validation loss: 2.1180431147416434

Epoch: 5| Step: 8
Training loss: 1.7059307098388672
Validation loss: 2.0918421844641366

Epoch: 5| Step: 9
Training loss: 2.221529245376587
Validation loss: 2.1066324015458426

Epoch: 5| Step: 10
Training loss: 1.836449384689331
Validation loss: 2.1104874114195504

Epoch: 5| Step: 11
Training loss: 1.824471116065979
Validation loss: 2.105778301755587

Epoch: 217| Step: 0
Training loss: 1.7141106128692627
Validation loss: 2.1073399633169174

Epoch: 5| Step: 1
Training loss: 1.5576924085617065
Validation loss: 2.0944094906250634

Epoch: 5| Step: 2
Training loss: 2.093205213546753
Validation loss: 2.0927897840738297

Epoch: 5| Step: 3
Training loss: 2.4344611167907715
Validation loss: 2.0897943526506424

Epoch: 5| Step: 4
Training loss: 2.0071651935577393
Validation loss: 2.1009643375873566

Epoch: 5| Step: 5
Training loss: 1.8672540187835693
Validation loss: 2.086783160765966

Epoch: 5| Step: 6
Training loss: 1.8082042932510376
Validation loss: 2.0844040364027023

Epoch: 5| Step: 7
Training loss: 1.7946100234985352
Validation loss: 2.0878129303455353

Epoch: 5| Step: 8
Training loss: 1.7225010395050049
Validation loss: 2.087946275870005

Epoch: 5| Step: 9
Training loss: 2.370344400405884
Validation loss: 2.0751572847366333

Epoch: 5| Step: 10
Training loss: 1.9047982692718506
Validation loss: 2.0800999253988266

Epoch: 5| Step: 11
Training loss: 3.125006675720215
Validation loss: 2.086182788014412

Epoch: 218| Step: 0
Training loss: 1.5024875402450562
Validation loss: 2.081643357872963

Epoch: 5| Step: 1
Training loss: 2.05244779586792
Validation loss: 2.080003966887792

Epoch: 5| Step: 2
Training loss: 1.7117592096328735
Validation loss: 2.0896942764520645

Epoch: 5| Step: 3
Training loss: 2.516050100326538
Validation loss: 2.077661777536074

Epoch: 5| Step: 4
Training loss: 2.097001314163208
Validation loss: 2.070716604590416

Epoch: 5| Step: 5
Training loss: 1.2850759029388428
Validation loss: 2.0841027249892554

Epoch: 5| Step: 6
Training loss: 2.105581283569336
Validation loss: 2.0804371535778046

Epoch: 5| Step: 7
Training loss: 1.6691100597381592
Validation loss: 2.093314682443937

Epoch: 5| Step: 8
Training loss: 2.084235668182373
Validation loss: 2.0765041212240853

Epoch: 5| Step: 9
Training loss: 2.189330816268921
Validation loss: 2.091683551669121

Epoch: 5| Step: 10
Training loss: 2.1727728843688965
Validation loss: 2.099579001466433

Epoch: 5| Step: 11
Training loss: 2.043551445007324
Validation loss: 2.0876820782820382

Epoch: 219| Step: 0
Training loss: 1.9259006977081299
Validation loss: 2.090828761458397

Epoch: 5| Step: 1
Training loss: 2.414172410964966
Validation loss: 2.1069270819425583

Epoch: 5| Step: 2
Training loss: 1.7209670543670654
Validation loss: 2.1017693132162094

Epoch: 5| Step: 3
Training loss: 2.033933401107788
Validation loss: 2.0994613766670227

Epoch: 5| Step: 4
Training loss: 2.1609582901000977
Validation loss: 2.116984337568283

Epoch: 5| Step: 5
Training loss: 1.7028884887695312
Validation loss: 2.1041248192389808

Epoch: 5| Step: 6
Training loss: 1.906688928604126
Validation loss: 2.0933860341707864

Epoch: 5| Step: 7
Training loss: 1.964552879333496
Validation loss: 2.0983775705099106

Epoch: 5| Step: 8
Training loss: 1.7542266845703125
Validation loss: 2.1081027885278067

Epoch: 5| Step: 9
Training loss: 1.864811658859253
Validation loss: 2.1003255347410836

Epoch: 5| Step: 10
Training loss: 1.9076017141342163
Validation loss: 2.0993750244379044

Epoch: 5| Step: 11
Training loss: 1.5926321744918823
Validation loss: 2.116595576206843

Epoch: 220| Step: 0
Training loss: 2.272951602935791
Validation loss: 2.1273458103338876

Epoch: 5| Step: 1
Training loss: 2.065903663635254
Validation loss: 2.1419041603803635

Epoch: 5| Step: 2
Training loss: 1.4654686450958252
Validation loss: 2.1589765350023904

Epoch: 5| Step: 3
Training loss: 2.242788791656494
Validation loss: 2.167691230773926

Epoch: 5| Step: 4
Training loss: 1.741680383682251
Validation loss: 2.1482567886511483

Epoch: 5| Step: 5
Training loss: 1.6095762252807617
Validation loss: 2.172579199075699

Epoch: 5| Step: 6
Training loss: 2.3979599475860596
Validation loss: 2.17028937737147

Epoch: 5| Step: 7
Training loss: 1.9024007320404053
Validation loss: 2.1711171021064124

Epoch: 5| Step: 8
Training loss: 2.1149468421936035
Validation loss: 2.1645637651284537

Epoch: 5| Step: 9
Training loss: 2.0044708251953125
Validation loss: 2.135822763045629

Epoch: 5| Step: 10
Training loss: 1.6239944696426392
Validation loss: 2.1414948999881744

Epoch: 5| Step: 11
Training loss: 2.448406219482422
Validation loss: 2.1215463280677795

Epoch: 221| Step: 0
Training loss: 2.1103522777557373
Validation loss: 2.1141802072525024

Epoch: 5| Step: 1
Training loss: 1.8840720653533936
Validation loss: 2.0993627458810806

Epoch: 5| Step: 2
Training loss: 2.2792468070983887
Validation loss: 2.1089919805526733

Epoch: 5| Step: 3
Training loss: 2.3049278259277344
Validation loss: 2.111710096398989

Epoch: 5| Step: 4
Training loss: 1.4499022960662842
Validation loss: 2.0879989564418793

Epoch: 5| Step: 5
Training loss: 1.6251709461212158
Validation loss: 2.104149421056112

Epoch: 5| Step: 6
Training loss: 1.3668854236602783
Validation loss: 2.1048848976691565

Epoch: 5| Step: 7
Training loss: 2.450221538543701
Validation loss: 2.108588953812917

Epoch: 5| Step: 8
Training loss: 1.7687183618545532
Validation loss: 2.1229005455970764

Epoch: 5| Step: 9
Training loss: 2.4288992881774902
Validation loss: 2.1314779271682105

Epoch: 5| Step: 10
Training loss: 1.8018471002578735
Validation loss: 2.135149359703064

Epoch: 5| Step: 11
Training loss: 1.5561000108718872
Validation loss: 2.1336078445116677

Epoch: 222| Step: 0
Training loss: 1.623558759689331
Validation loss: 2.1256302893161774

Epoch: 5| Step: 1
Training loss: 1.3899977207183838
Validation loss: 2.1392073879639306

Epoch: 5| Step: 2
Training loss: 1.5744727849960327
Validation loss: 2.132282147804896

Epoch: 5| Step: 3
Training loss: 2.288876533508301
Validation loss: 2.119770502050718

Epoch: 5| Step: 4
Training loss: 1.7345088720321655
Validation loss: 2.121253495415052

Epoch: 5| Step: 5
Training loss: 2.3709146976470947
Validation loss: 2.1199363271395364

Epoch: 5| Step: 6
Training loss: 1.8794212341308594
Validation loss: 2.1206720173358917

Epoch: 5| Step: 7
Training loss: 1.9897677898406982
Validation loss: 2.1128959208726883

Epoch: 5| Step: 8
Training loss: 2.3387534618377686
Validation loss: 2.1165546973546348

Epoch: 5| Step: 9
Training loss: 1.7556272745132446
Validation loss: 2.1179553320010505

Epoch: 5| Step: 10
Training loss: 1.85977041721344
Validation loss: 2.096296489238739

Epoch: 5| Step: 11
Training loss: 3.179448127746582
Validation loss: 2.1101158608992896

Epoch: 223| Step: 0
Training loss: 2.3905022144317627
Validation loss: 2.107060045003891

Epoch: 5| Step: 1
Training loss: 2.0114188194274902
Validation loss: 2.108121395111084

Epoch: 5| Step: 2
Training loss: 1.8743194341659546
Validation loss: 2.119282752275467

Epoch: 5| Step: 3
Training loss: 1.721984624862671
Validation loss: 2.1180792997280755

Epoch: 5| Step: 4
Training loss: 1.7953649759292603
Validation loss: 2.126877943674723

Epoch: 5| Step: 5
Training loss: 1.8932660818099976
Validation loss: 2.120595986644427

Epoch: 5| Step: 6
Training loss: 2.027226209640503
Validation loss: 2.1154320736726127

Epoch: 5| Step: 7
Training loss: 1.7587735652923584
Validation loss: 2.139782284696897

Epoch: 5| Step: 8
Training loss: 1.9250926971435547
Validation loss: 2.1392480731010437

Epoch: 5| Step: 9
Training loss: 1.7204225063323975
Validation loss: 2.142506957054138

Epoch: 5| Step: 10
Training loss: 1.9620527029037476
Validation loss: 2.1459151605765023

Epoch: 5| Step: 11
Training loss: 1.5684711933135986
Validation loss: 2.1422998855511346

Epoch: 224| Step: 0
Training loss: 2.05192232131958
Validation loss: 2.1552569766839347

Epoch: 5| Step: 1
Training loss: 1.4332959651947021
Validation loss: 2.1719669749339423

Epoch: 5| Step: 2
Training loss: 2.197873830795288
Validation loss: 2.1319387008746467

Epoch: 5| Step: 3
Training loss: 1.829153299331665
Validation loss: 2.138245095809301

Epoch: 5| Step: 4
Training loss: 2.235494375228882
Validation loss: 2.125821312268575

Epoch: 5| Step: 5
Training loss: 1.7547184228897095
Validation loss: 2.136506954828898

Epoch: 5| Step: 6
Training loss: 2.1964221000671387
Validation loss: 2.131267418464025

Epoch: 5| Step: 7
Training loss: 1.5948976278305054
Validation loss: 2.127298966050148

Epoch: 5| Step: 8
Training loss: 1.862238883972168
Validation loss: 2.124444678425789

Epoch: 5| Step: 9
Training loss: 1.8296359777450562
Validation loss: 2.133944754799207

Epoch: 5| Step: 10
Training loss: 2.1423301696777344
Validation loss: 2.1400207032759986

Epoch: 5| Step: 11
Training loss: 1.7901737689971924
Validation loss: 2.1459804475307465

Epoch: 225| Step: 0
Training loss: 2.3133139610290527
Validation loss: 2.154450754324595

Epoch: 5| Step: 1
Training loss: 1.7286128997802734
Validation loss: 2.1491433531045914

Epoch: 5| Step: 2
Training loss: 1.8877683877944946
Validation loss: 2.1385997533798218

Epoch: 5| Step: 3
Training loss: 1.7899993658065796
Validation loss: 2.1497280100981393

Epoch: 5| Step: 4
Training loss: 1.7307853698730469
Validation loss: 2.1533721685409546

Epoch: 5| Step: 5
Training loss: 1.1707160472869873
Validation loss: 2.1486620604991913

Epoch: 5| Step: 6
Training loss: 1.918021559715271
Validation loss: 2.1438572655121484

Epoch: 5| Step: 7
Training loss: 1.663427710533142
Validation loss: 2.1384559869766235

Epoch: 5| Step: 8
Training loss: 2.1316184997558594
Validation loss: 2.134962797164917

Epoch: 5| Step: 9
Training loss: 2.2528655529022217
Validation loss: 2.129324714342753

Epoch: 5| Step: 10
Training loss: 2.2173380851745605
Validation loss: 2.1223483979701996

Epoch: 5| Step: 11
Training loss: 2.9863944053649902
Validation loss: 2.1334972778956094

Epoch: 226| Step: 0
Training loss: 1.5932157039642334
Validation loss: 2.1308552573124566

Epoch: 5| Step: 1
Training loss: 1.7564653158187866
Validation loss: 2.1105298350254693

Epoch: 5| Step: 2
Training loss: 2.196958303451538
Validation loss: 2.099366769194603

Epoch: 5| Step: 3
Training loss: 2.0977206230163574
Validation loss: 2.1087879836559296

Epoch: 5| Step: 4
Training loss: 2.0203354358673096
Validation loss: 2.101332272092501

Epoch: 5| Step: 5
Training loss: 2.526390552520752
Validation loss: 2.112699290116628

Epoch: 5| Step: 6
Training loss: 1.7846753597259521
Validation loss: 2.1217827002207437

Epoch: 5| Step: 7
Training loss: 1.7391002178192139
Validation loss: 2.1291062931219735

Epoch: 5| Step: 8
Training loss: 1.3840974569320679
Validation loss: 2.1346119344234467

Epoch: 5| Step: 9
Training loss: 1.8280994892120361
Validation loss: 2.1147384444872537

Epoch: 5| Step: 10
Training loss: 1.9833300113677979
Validation loss: 2.13073738416036

Epoch: 5| Step: 11
Training loss: 2.051706314086914
Validation loss: 2.1345308820406594

Epoch: 227| Step: 0
Training loss: 2.0444626808166504
Validation loss: 2.1480548083782196

Epoch: 5| Step: 1
Training loss: 1.9455769062042236
Validation loss: 2.15292227268219

Epoch: 5| Step: 2
Training loss: 1.592598557472229
Validation loss: 2.1346606562534967

Epoch: 5| Step: 3
Training loss: 2.1666479110717773
Validation loss: 2.152980551123619

Epoch: 5| Step: 4
Training loss: 1.9561790227890015
Validation loss: 2.151407649119695

Epoch: 5| Step: 5
Training loss: 2.2681517601013184
Validation loss: 2.1510665665070214

Epoch: 5| Step: 6
Training loss: 1.790665864944458
Validation loss: 2.127929702401161

Epoch: 5| Step: 7
Training loss: 2.105665922164917
Validation loss: 2.146326964100202

Epoch: 5| Step: 8
Training loss: 1.533480167388916
Validation loss: 2.1423172454039254

Epoch: 5| Step: 9
Training loss: 1.995859146118164
Validation loss: 2.1437887897094092

Epoch: 5| Step: 10
Training loss: 1.7673742771148682
Validation loss: 2.13284562031428

Epoch: 5| Step: 11
Training loss: 0.9950820207595825
Validation loss: 2.1226023932298026

Epoch: 228| Step: 0
Training loss: 1.407459020614624
Validation loss: 2.1230525771776834

Epoch: 5| Step: 1
Training loss: 1.8964135646820068
Validation loss: 2.125687837600708

Epoch: 5| Step: 2
Training loss: 2.350027084350586
Validation loss: 2.1379385391871133

Epoch: 5| Step: 3
Training loss: 1.8505712747573853
Validation loss: 2.118847539027532

Epoch: 5| Step: 4
Training loss: 2.3257718086242676
Validation loss: 2.116206402579943

Epoch: 5| Step: 5
Training loss: 1.712653398513794
Validation loss: 2.1230632166067758

Epoch: 5| Step: 6
Training loss: 2.2487080097198486
Validation loss: 2.1306585570176444

Epoch: 5| Step: 7
Training loss: 1.6136410236358643
Validation loss: 2.120794822772344

Epoch: 5| Step: 8
Training loss: 1.7924470901489258
Validation loss: 2.1052125891049704

Epoch: 5| Step: 9
Training loss: 1.7772632837295532
Validation loss: 2.1244618942340217

Epoch: 5| Step: 10
Training loss: 2.0337305068969727
Validation loss: 2.1424928406874337

Epoch: 5| Step: 11
Training loss: 1.9755115509033203
Validation loss: 2.1424069752295813

Epoch: 229| Step: 0
Training loss: 1.4383580684661865
Validation loss: 2.1361704021692276

Epoch: 5| Step: 1
Training loss: 1.6924126148223877
Validation loss: 2.1466565082470574

Epoch: 5| Step: 2
Training loss: 2.1139330863952637
Validation loss: 2.1308097342650094

Epoch: 5| Step: 3
Training loss: 1.4436668157577515
Validation loss: 2.1313021133343377

Epoch: 5| Step: 4
Training loss: 1.8101238012313843
Validation loss: 2.119816909233729

Epoch: 5| Step: 5
Training loss: 1.8664201498031616
Validation loss: 2.1042062987883887

Epoch: 5| Step: 6
Training loss: 2.477224826812744
Validation loss: 2.107937137285868

Epoch: 5| Step: 7
Training loss: 2.425319194793701
Validation loss: 2.1077681382497153

Epoch: 5| Step: 8
Training loss: 2.1061768531799316
Validation loss: 2.121547609567642

Epoch: 5| Step: 9
Training loss: 1.9608465433120728
Validation loss: 2.103461662928263

Epoch: 5| Step: 10
Training loss: 2.0422885417938232
Validation loss: 2.1050822734832764

Epoch: 5| Step: 11
Training loss: 1.397578239440918
Validation loss: 2.1192922045787177

Epoch: 230| Step: 0
Training loss: 1.9535770416259766
Validation loss: 2.1088677694400153

Epoch: 5| Step: 1
Training loss: 1.9239822626113892
Validation loss: 2.106460909048716

Epoch: 5| Step: 2
Training loss: 1.8328773975372314
Validation loss: 2.1246028741200766

Epoch: 5| Step: 3
Training loss: 1.8327919244766235
Validation loss: 2.0940392116705575

Epoch: 5| Step: 4
Training loss: 2.1690568923950195
Validation loss: 2.1050708144903183

Epoch: 5| Step: 5
Training loss: 1.8858286142349243
Validation loss: 2.1197063078482947

Epoch: 5| Step: 6
Training loss: 1.881368637084961
Validation loss: 2.1190506170193353

Epoch: 5| Step: 7
Training loss: 1.4470407962799072
Validation loss: 2.120492989818255

Epoch: 5| Step: 8
Training loss: 1.7838722467422485
Validation loss: 2.124828706185023

Epoch: 5| Step: 9
Training loss: 2.2218449115753174
Validation loss: 2.122265408436457

Epoch: 5| Step: 10
Training loss: 2.4596118927001953
Validation loss: 2.1364694088697433

Epoch: 5| Step: 11
Training loss: 1.2706713676452637
Validation loss: 2.1553512513637543

Epoch: 231| Step: 0
Training loss: 2.3059022426605225
Validation loss: 2.1497410585482917

Epoch: 5| Step: 1
Training loss: 1.4632561206817627
Validation loss: 2.1463622748851776

Epoch: 5| Step: 2
Training loss: 1.676060438156128
Validation loss: 2.131753851970037

Epoch: 5| Step: 3
Training loss: 2.455587387084961
Validation loss: 2.1290628810723624

Epoch: 5| Step: 4
Training loss: 1.7818377017974854
Validation loss: 2.1139244685570397

Epoch: 5| Step: 5
Training loss: 2.1932530403137207
Validation loss: 2.1142751773198447

Epoch: 5| Step: 6
Training loss: 2.5677459239959717
Validation loss: 2.106967806816101

Epoch: 5| Step: 7
Training loss: 1.9018548727035522
Validation loss: 2.0911880681912103

Epoch: 5| Step: 8
Training loss: 1.7035928964614868
Validation loss: 2.0977884978055954

Epoch: 5| Step: 9
Training loss: 1.5739833116531372
Validation loss: 2.099445869525274

Epoch: 5| Step: 10
Training loss: 1.9388138055801392
Validation loss: 2.103041817744573

Epoch: 5| Step: 11
Training loss: 1.2443273067474365
Validation loss: 2.095491036772728

Epoch: 232| Step: 0
Training loss: 1.4637826681137085
Validation loss: 2.0943736086289086

Epoch: 5| Step: 1
Training loss: 2.256560802459717
Validation loss: 2.1089541912078857

Epoch: 5| Step: 2
Training loss: 1.5537669658660889
Validation loss: 2.093609834710757

Epoch: 5| Step: 3
Training loss: 1.7654956579208374
Validation loss: 2.101089979211489

Epoch: 5| Step: 4
Training loss: 1.9378831386566162
Validation loss: 2.1065076192220054

Epoch: 5| Step: 5
Training loss: 2.1297385692596436
Validation loss: 2.0976157834132514

Epoch: 5| Step: 6
Training loss: 1.758305311203003
Validation loss: 2.1005824357271194

Epoch: 5| Step: 7
Training loss: 2.902707099914551
Validation loss: 2.1100917905569077

Epoch: 5| Step: 8
Training loss: 1.7422479391098022
Validation loss: 2.1154116491476693

Epoch: 5| Step: 9
Training loss: 2.4202558994293213
Validation loss: 2.115474825104078

Epoch: 5| Step: 10
Training loss: 1.897217035293579
Validation loss: 2.1162388026714325

Epoch: 5| Step: 11
Training loss: 0.878017246723175
Validation loss: 2.1293878654638925

Epoch: 233| Step: 0
Training loss: 1.6064338684082031
Validation loss: 2.1318483352661133

Epoch: 5| Step: 1
Training loss: 1.3712949752807617
Validation loss: 2.105024511615435

Epoch: 5| Step: 2
Training loss: 1.666322112083435
Validation loss: 2.116180568933487

Epoch: 5| Step: 3
Training loss: 1.8504555225372314
Validation loss: 2.0993783374627433

Epoch: 5| Step: 4
Training loss: 1.8205578327178955
Validation loss: 2.1031562040249505

Epoch: 5| Step: 5
Training loss: 2.2224788665771484
Validation loss: 2.0833322356144586

Epoch: 5| Step: 6
Training loss: 1.9362493753433228
Validation loss: 2.100930561621984

Epoch: 5| Step: 7
Training loss: 1.6991968154907227
Validation loss: 2.092051938176155

Epoch: 5| Step: 8
Training loss: 2.3654491901397705
Validation loss: 2.100350464383761

Epoch: 5| Step: 9
Training loss: 2.4135544300079346
Validation loss: 2.0992088665564856

Epoch: 5| Step: 10
Training loss: 2.227640151977539
Validation loss: 2.0856013745069504

Epoch: 5| Step: 11
Training loss: 1.5101579427719116
Validation loss: 2.105922391017278

Epoch: 234| Step: 0
Training loss: 1.9196674823760986
Validation loss: 2.112493798136711

Epoch: 5| Step: 1
Training loss: 2.1290318965911865
Validation loss: 2.123022382458051

Epoch: 5| Step: 2
Training loss: 1.659406304359436
Validation loss: 2.1118723650773368

Epoch: 5| Step: 3
Training loss: 1.8989570140838623
Validation loss: 2.121604785323143

Epoch: 5| Step: 4
Training loss: 2.119389057159424
Validation loss: 2.102015589674314

Epoch: 5| Step: 5
Training loss: 1.422666311264038
Validation loss: 2.125984877347946

Epoch: 5| Step: 6
Training loss: 2.0431981086730957
Validation loss: 2.113578736782074

Epoch: 5| Step: 7
Training loss: 1.01898992061615
Validation loss: 2.121753176053365

Epoch: 5| Step: 8
Training loss: 1.911874771118164
Validation loss: 2.1303963164488473

Epoch: 5| Step: 9
Training loss: 1.9509613513946533
Validation loss: 2.13516358534495

Epoch: 5| Step: 10
Training loss: 2.724555253982544
Validation loss: 2.1016365935405097

Epoch: 5| Step: 11
Training loss: 1.8941971063613892
Validation loss: 2.126083582639694

Epoch: 235| Step: 0
Training loss: 2.1415750980377197
Validation loss: 2.122087607781092

Epoch: 5| Step: 1
Training loss: 1.6464817523956299
Validation loss: 2.1234659403562546

Epoch: 5| Step: 2
Training loss: 1.9744914770126343
Validation loss: 2.1225843032201133

Epoch: 5| Step: 3
Training loss: 1.9575046300888062
Validation loss: 2.1320044497648873

Epoch: 5| Step: 4
Training loss: 2.1430578231811523
Validation loss: 2.1378305604060492

Epoch: 5| Step: 5
Training loss: 2.4079272747039795
Validation loss: 2.1343018114566803

Epoch: 5| Step: 6
Training loss: 1.8057056665420532
Validation loss: 2.145526925722758

Epoch: 5| Step: 7
Training loss: 1.8599472045898438
Validation loss: 2.161434754729271

Epoch: 5| Step: 8
Training loss: 2.1670541763305664
Validation loss: 2.151991605758667

Epoch: 5| Step: 9
Training loss: 1.2239210605621338
Validation loss: 2.1454031666119895

Epoch: 5| Step: 10
Training loss: 1.9708442687988281
Validation loss: 2.1778368800878525

Epoch: 5| Step: 11
Training loss: 0.8197084665298462
Validation loss: 2.14369635283947

Epoch: 236| Step: 0
Training loss: 1.9240583181381226
Validation loss: 2.1532025039196014

Epoch: 5| Step: 1
Training loss: 1.5430948734283447
Validation loss: 2.138863871494929

Epoch: 5| Step: 2
Training loss: 1.9921419620513916
Validation loss: 2.1192288299401603

Epoch: 5| Step: 3
Training loss: 1.1636288166046143
Validation loss: 2.130195210377375

Epoch: 5| Step: 4
Training loss: 1.9675381183624268
Validation loss: 2.1316541830698648

Epoch: 5| Step: 5
Training loss: 1.9189637899398804
Validation loss: 2.1250042219956717

Epoch: 5| Step: 6
Training loss: 2.083240509033203
Validation loss: 2.126103992263476

Epoch: 5| Step: 7
Training loss: 2.3044052124023438
Validation loss: 2.1265604545672736

Epoch: 5| Step: 8
Training loss: 1.9941558837890625
Validation loss: 2.119874065121015

Epoch: 5| Step: 9
Training loss: 1.8639284372329712
Validation loss: 2.1345892747243247

Epoch: 5| Step: 10
Training loss: 2.076612949371338
Validation loss: 2.1387238601843515

Epoch: 5| Step: 11
Training loss: 1.6263316869735718
Validation loss: 2.1161580781141915

Epoch: 237| Step: 0
Training loss: 2.1480696201324463
Validation loss: 2.1511205434799194

Epoch: 5| Step: 1
Training loss: 1.5776801109313965
Validation loss: 2.1554541885852814

Epoch: 5| Step: 2
Training loss: 2.1186282634735107
Validation loss: 2.159873147805532

Epoch: 5| Step: 3
Training loss: 1.8792005777359009
Validation loss: 2.181879679361979

Epoch: 5| Step: 4
Training loss: 2.127655267715454
Validation loss: 2.1792021095752716

Epoch: 5| Step: 5
Training loss: 1.378562569618225
Validation loss: 2.1507690151532493

Epoch: 5| Step: 6
Training loss: 1.5783107280731201
Validation loss: 2.159967894355456

Epoch: 5| Step: 7
Training loss: 2.023078441619873
Validation loss: 2.148668279250463

Epoch: 5| Step: 8
Training loss: 2.3186800479888916
Validation loss: 2.136676162481308

Epoch: 5| Step: 9
Training loss: 1.6692841053009033
Validation loss: 2.128434345126152

Epoch: 5| Step: 10
Training loss: 2.1989033222198486
Validation loss: 2.129668657978376

Epoch: 5| Step: 11
Training loss: 1.0536848306655884
Validation loss: 2.123968154191971

Epoch: 238| Step: 0
Training loss: 1.8907279968261719
Validation loss: 2.135460982720057

Epoch: 5| Step: 1
Training loss: 1.491755723953247
Validation loss: 2.129744033018748

Epoch: 5| Step: 2
Training loss: 1.772709608078003
Validation loss: 2.1170962750911713

Epoch: 5| Step: 3
Training loss: 1.3501965999603271
Validation loss: 2.126419867078463

Epoch: 5| Step: 4
Training loss: 1.7439470291137695
Validation loss: 2.1211033960183463

Epoch: 5| Step: 5
Training loss: 2.1985530853271484
Validation loss: 2.1380619605382285

Epoch: 5| Step: 6
Training loss: 2.1940195560455322
Validation loss: 2.1495336393515267

Epoch: 5| Step: 7
Training loss: 1.8378528356552124
Validation loss: 2.148855909705162

Epoch: 5| Step: 8
Training loss: 2.260868787765503
Validation loss: 2.1601289014021554

Epoch: 5| Step: 9
Training loss: 1.5100491046905518
Validation loss: 2.1575253506501517

Epoch: 5| Step: 10
Training loss: 2.5650525093078613
Validation loss: 2.1668336937824884

Epoch: 5| Step: 11
Training loss: 3.6632847785949707
Validation loss: 2.1740905940532684

Epoch: 239| Step: 0
Training loss: 1.8211206197738647
Validation loss: 2.1688563426335654

Epoch: 5| Step: 1
Training loss: 1.7766262292861938
Validation loss: 2.1621453563372293

Epoch: 5| Step: 2
Training loss: 1.707099199295044
Validation loss: 2.145775650938352

Epoch: 5| Step: 3
Training loss: 1.846095323562622
Validation loss: 2.1498941580454507

Epoch: 5| Step: 4
Training loss: 2.309753894805908
Validation loss: 2.1365805814663568

Epoch: 5| Step: 5
Training loss: 1.771619439125061
Validation loss: 2.1419722537199655

Epoch: 5| Step: 6
Training loss: 1.9449176788330078
Validation loss: 2.1501630345980325

Epoch: 5| Step: 7
Training loss: 1.6337417364120483
Validation loss: 2.1451691885789237

Epoch: 5| Step: 8
Training loss: 1.710118055343628
Validation loss: 2.1593598624070487

Epoch: 5| Step: 9
Training loss: 1.8492224216461182
Validation loss: 2.1495098372300467

Epoch: 5| Step: 10
Training loss: 2.2229373455047607
Validation loss: 2.1428340623776116

Epoch: 5| Step: 11
Training loss: 2.176813840866089
Validation loss: 2.146813859542211

Epoch: 240| Step: 0
Training loss: 1.8912811279296875
Validation loss: 2.1486826390028

Epoch: 5| Step: 1
Training loss: 2.077820301055908
Validation loss: 2.1625733325878778

Epoch: 5| Step: 2
Training loss: 1.6867456436157227
Validation loss: 2.1425974468390145

Epoch: 5| Step: 3
Training loss: 1.8415981531143188
Validation loss: 2.148183231552442

Epoch: 5| Step: 4
Training loss: 1.9129562377929688
Validation loss: 2.170895680785179

Epoch: 5| Step: 5
Training loss: 2.1456542015075684
Validation loss: 2.158717597524325

Epoch: 5| Step: 6
Training loss: 1.4819368124008179
Validation loss: 2.1502025574445724

Epoch: 5| Step: 7
Training loss: 1.9976654052734375
Validation loss: 2.162002374728521

Epoch: 5| Step: 8
Training loss: 2.122642993927002
Validation loss: 2.1623230278491974

Epoch: 5| Step: 9
Training loss: 1.9186744689941406
Validation loss: 2.16579199830691

Epoch: 5| Step: 10
Training loss: 1.4399583339691162
Validation loss: 2.1745227575302124

Epoch: 5| Step: 11
Training loss: 1.794028401374817
Validation loss: 2.1482844253381095

Epoch: 241| Step: 0
Training loss: 1.8103885650634766
Validation loss: 2.1581384589274726

Epoch: 5| Step: 1
Training loss: 2.447115659713745
Validation loss: 2.1424534022808075

Epoch: 5| Step: 2
Training loss: 2.0117931365966797
Validation loss: 2.1487207214037576

Epoch: 5| Step: 3
Training loss: 1.7073523998260498
Validation loss: 2.142951021591822

Epoch: 5| Step: 4
Training loss: 1.9501774311065674
Validation loss: 2.114957883954048

Epoch: 5| Step: 5
Training loss: 2.3542985916137695
Validation loss: 2.134423782428106

Epoch: 5| Step: 6
Training loss: 1.7440999746322632
Validation loss: 2.1469958225886026

Epoch: 5| Step: 7
Training loss: 1.3703563213348389
Validation loss: 2.1460507412751517

Epoch: 5| Step: 8
Training loss: 1.9285271167755127
Validation loss: 2.1494590044021606

Epoch: 5| Step: 9
Training loss: 1.7864570617675781
Validation loss: 2.181766668955485

Epoch: 5| Step: 10
Training loss: 1.3288919925689697
Validation loss: 2.168558274706205

Epoch: 5| Step: 11
Training loss: 2.25474214553833
Validation loss: 2.180884708960851

Epoch: 242| Step: 0
Training loss: 1.780045747756958
Validation loss: 2.1824523707230887

Epoch: 5| Step: 1
Training loss: 2.627525806427002
Validation loss: 2.1606056640545526

Epoch: 5| Step: 2
Training loss: 1.818198800086975
Validation loss: 2.166538486878077

Epoch: 5| Step: 3
Training loss: 2.146595001220703
Validation loss: 2.1549132267634072

Epoch: 5| Step: 4
Training loss: 1.852189064025879
Validation loss: 2.1726201673348746

Epoch: 5| Step: 5
Training loss: 2.0821237564086914
Validation loss: 2.1501583655675254

Epoch: 5| Step: 6
Training loss: 1.4913127422332764
Validation loss: 2.1392287015914917

Epoch: 5| Step: 7
Training loss: 2.0659399032592773
Validation loss: 2.1469759742418923

Epoch: 5| Step: 8
Training loss: 1.513573408126831
Validation loss: 2.1448242366313934

Epoch: 5| Step: 9
Training loss: 1.813707709312439
Validation loss: 2.125024219353994

Epoch: 5| Step: 10
Training loss: 1.4337894916534424
Validation loss: 2.139060919483503

Epoch: 5| Step: 11
Training loss: 1.6337504386901855
Validation loss: 2.137397756179174

Epoch: 243| Step: 0
Training loss: 1.9790455102920532
Validation loss: 2.1297616263230643

Epoch: 5| Step: 1
Training loss: 1.5051454305648804
Validation loss: 2.142766684293747

Epoch: 5| Step: 2
Training loss: 1.874809980392456
Validation loss: 2.1380657851696014

Epoch: 5| Step: 3
Training loss: 1.9693034887313843
Validation loss: 2.1534077177445092

Epoch: 5| Step: 4
Training loss: 1.740578055381775
Validation loss: 2.1524981757005057

Epoch: 5| Step: 5
Training loss: 1.7303394079208374
Validation loss: 2.1623798857132592

Epoch: 5| Step: 6
Training loss: 2.2184815406799316
Validation loss: 2.160183012485504

Epoch: 5| Step: 7
Training loss: 1.8285083770751953
Validation loss: 2.1622648189465203

Epoch: 5| Step: 8
Training loss: 2.1359200477600098
Validation loss: 2.1487274219592414

Epoch: 5| Step: 9
Training loss: 1.9666773080825806
Validation loss: 2.141668915748596

Epoch: 5| Step: 10
Training loss: 1.3252519369125366
Validation loss: 2.1569219728310904

Epoch: 5| Step: 11
Training loss: 2.466097831726074
Validation loss: 2.15413490931193

Epoch: 244| Step: 0
Training loss: 1.9230422973632812
Validation loss: 2.1641127665837607

Epoch: 5| Step: 1
Training loss: 1.7378721237182617
Validation loss: 2.171258181333542

Epoch: 5| Step: 2
Training loss: 1.7975422143936157
Validation loss: 2.1451151818037033

Epoch: 5| Step: 3
Training loss: 1.7874767780303955
Validation loss: 2.166366755962372

Epoch: 5| Step: 4
Training loss: 1.803503394126892
Validation loss: 2.176539162794749

Epoch: 5| Step: 5
Training loss: 2.247657299041748
Validation loss: 2.1721717764933905

Epoch: 5| Step: 6
Training loss: 1.233676552772522
Validation loss: 2.165372615059217

Epoch: 5| Step: 7
Training loss: 1.8333234786987305
Validation loss: 2.1844070057074227

Epoch: 5| Step: 8
Training loss: 2.228024959564209
Validation loss: 2.159309377272924

Epoch: 5| Step: 9
Training loss: 1.9887535572052002
Validation loss: 2.1700459818045297

Epoch: 5| Step: 10
Training loss: 2.099360942840576
Validation loss: 2.1607392529646554

Epoch: 5| Step: 11
Training loss: 0.776561975479126
Validation loss: 2.154588763912519

Epoch: 245| Step: 0
Training loss: 1.880453109741211
Validation loss: 2.1459629187981286

Epoch: 5| Step: 1
Training loss: 1.3954417705535889
Validation loss: 2.1316095342238746

Epoch: 5| Step: 2
Training loss: 2.0539803504943848
Validation loss: 2.133287946383158

Epoch: 5| Step: 3
Training loss: 1.4667696952819824
Validation loss: 2.128687714536985

Epoch: 5| Step: 4
Training loss: 2.2541613578796387
Validation loss: 2.1451672315597534

Epoch: 5| Step: 5
Training loss: 2.5794248580932617
Validation loss: 2.136033753554026

Epoch: 5| Step: 6
Training loss: 1.409798264503479
Validation loss: 2.146098330616951

Epoch: 5| Step: 7
Training loss: 1.450628638267517
Validation loss: 2.1545343846082687

Epoch: 5| Step: 8
Training loss: 1.8176895380020142
Validation loss: 2.1522754232088723

Epoch: 5| Step: 9
Training loss: 1.9522104263305664
Validation loss: 2.1433967848618827

Epoch: 5| Step: 10
Training loss: 2.319220542907715
Validation loss: 2.145168403784434

Epoch: 5| Step: 11
Training loss: 1.3802249431610107
Validation loss: 2.143710563580195

Epoch: 246| Step: 0
Training loss: 2.090880870819092
Validation loss: 2.165250117580096

Epoch: 5| Step: 1
Training loss: 1.5049710273742676
Validation loss: 2.169277628262838

Epoch: 5| Step: 2
Training loss: 1.5859283208847046
Validation loss: 2.1798970450957618

Epoch: 5| Step: 3
Training loss: 1.4428424835205078
Validation loss: 2.1682232469320297

Epoch: 5| Step: 4
Training loss: 1.3874289989471436
Validation loss: 2.1629141668478646

Epoch: 5| Step: 5
Training loss: 2.2078919410705566
Validation loss: 2.153871849179268

Epoch: 5| Step: 6
Training loss: 2.2253832817077637
Validation loss: 2.1485211749871573

Epoch: 5| Step: 7
Training loss: 2.2498433589935303
Validation loss: 2.1356965204079947

Epoch: 5| Step: 8
Training loss: 2.1733479499816895
Validation loss: 2.128774185975393

Epoch: 5| Step: 9
Training loss: 1.5890998840332031
Validation loss: 2.121572360396385

Epoch: 5| Step: 10
Training loss: 2.1697335243225098
Validation loss: 2.1254288057486215

Epoch: 5| Step: 11
Training loss: 1.7818187475204468
Validation loss: 2.1091632395982742

Epoch: 247| Step: 0
Training loss: 2.012634754180908
Validation loss: 2.123101914922396

Epoch: 5| Step: 1
Training loss: 2.105034589767456
Validation loss: 2.1353930135567984

Epoch: 5| Step: 2
Training loss: 1.7641680240631104
Validation loss: 2.136754954854647

Epoch: 5| Step: 3
Training loss: 2.344447612762451
Validation loss: 2.1412442475557327

Epoch: 5| Step: 4
Training loss: 1.7724754810333252
Validation loss: 2.153859630227089

Epoch: 5| Step: 5
Training loss: 1.580292820930481
Validation loss: 2.142134577035904

Epoch: 5| Step: 6
Training loss: 1.9072595834732056
Validation loss: 2.161501571536064

Epoch: 5| Step: 7
Training loss: 1.7046152353286743
Validation loss: 2.1612233916918435

Epoch: 5| Step: 8
Training loss: 1.8248106241226196
Validation loss: 2.1499622017145157

Epoch: 5| Step: 9
Training loss: 1.5912057161331177
Validation loss: 2.176229804754257

Epoch: 5| Step: 10
Training loss: 1.6448062658309937
Validation loss: 2.1559434880812964

Epoch: 5| Step: 11
Training loss: 2.758579730987549
Validation loss: 2.166642357905706

Epoch: 248| Step: 0
Training loss: 1.4571622610092163
Validation loss: 2.1908030112584433

Epoch: 5| Step: 1
Training loss: 2.1293129920959473
Validation loss: 2.1793303141991296

Epoch: 5| Step: 2
Training loss: 1.335676908493042
Validation loss: 2.1831732392311096

Epoch: 5| Step: 3
Training loss: 2.0449283123016357
Validation loss: 2.1927352050940194

Epoch: 5| Step: 4
Training loss: 1.918447732925415
Validation loss: 2.163412888844808

Epoch: 5| Step: 5
Training loss: 2.6093945503234863
Validation loss: 2.1517458856105804

Epoch: 5| Step: 6
Training loss: 1.3090853691101074
Validation loss: 2.15326035519441

Epoch: 5| Step: 7
Training loss: 1.9270480871200562
Validation loss: 2.1665275593598685

Epoch: 5| Step: 8
Training loss: 2.1350998878479004
Validation loss: 2.141238490740458

Epoch: 5| Step: 9
Training loss: 2.0748441219329834
Validation loss: 2.1302612076203027

Epoch: 5| Step: 10
Training loss: 1.4710631370544434
Validation loss: 2.179478903611501

Epoch: 5| Step: 11
Training loss: 1.7554779052734375
Validation loss: 2.184048001964887

Epoch: 249| Step: 0
Training loss: 1.743788480758667
Validation loss: 2.18500147263209

Epoch: 5| Step: 1
Training loss: 1.8539769649505615
Validation loss: 2.172581821680069

Epoch: 5| Step: 2
Training loss: 1.4558149576187134
Validation loss: 2.1757031877835593

Epoch: 5| Step: 3
Training loss: 2.2389349937438965
Validation loss: 2.149958610534668

Epoch: 5| Step: 4
Training loss: 2.13793683052063
Validation loss: 2.1749904453754425

Epoch: 5| Step: 5
Training loss: 2.1188316345214844
Validation loss: 2.1763354688882828

Epoch: 5| Step: 6
Training loss: 1.5134012699127197
Validation loss: 2.1568267891804376

Epoch: 5| Step: 7
Training loss: 1.2475497722625732
Validation loss: 2.164439673225085

Epoch: 5| Step: 8
Training loss: 1.6516916751861572
Validation loss: 2.152971714735031

Epoch: 5| Step: 9
Training loss: 2.3997890949249268
Validation loss: 2.1664368311564126

Epoch: 5| Step: 10
Training loss: 1.7545711994171143
Validation loss: 2.1580325067043304

Epoch: 5| Step: 11
Training loss: 3.753695487976074
Validation loss: 2.1430223882198334

Epoch: 250| Step: 0
Training loss: 1.6330897808074951
Validation loss: 2.1417744557062783

Epoch: 5| Step: 1
Training loss: 2.472074031829834
Validation loss: 2.1376730501651764

Epoch: 5| Step: 2
Training loss: 1.5379453897476196
Validation loss: 2.1420319378376007

Epoch: 5| Step: 3
Training loss: 2.0749783515930176
Validation loss: 2.12726029753685

Epoch: 5| Step: 4
Training loss: 1.644722580909729
Validation loss: 2.146111845970154

Epoch: 5| Step: 5
Training loss: 2.019946336746216
Validation loss: 2.1410543819268546

Epoch: 5| Step: 6
Training loss: 1.6802886724472046
Validation loss: 2.1445732414722443

Epoch: 5| Step: 7
Training loss: 1.654567003250122
Validation loss: 2.147366389632225

Epoch: 5| Step: 8
Training loss: 1.446435570716858
Validation loss: 2.1445004840691886

Epoch: 5| Step: 9
Training loss: 1.7356878519058228
Validation loss: 2.144323170185089

Epoch: 5| Step: 10
Training loss: 2.5806825160980225
Validation loss: 2.144399717450142

Epoch: 5| Step: 11
Training loss: 1.836661458015442
Validation loss: 2.137893329064051

Epoch: 251| Step: 0
Training loss: 2.3167831897735596
Validation loss: 2.1580560008684793

Epoch: 5| Step: 1
Training loss: 1.9205291271209717
Validation loss: 2.1612989207108817

Epoch: 5| Step: 2
Training loss: 1.3900845050811768
Validation loss: 2.154642959435781

Epoch: 5| Step: 3
Training loss: 1.48344886302948
Validation loss: 2.148481031258901

Epoch: 5| Step: 4
Training loss: 2.077545404434204
Validation loss: 2.1391327579816184

Epoch: 5| Step: 5
Training loss: 1.7943267822265625
Validation loss: 2.146870866417885

Epoch: 5| Step: 6
Training loss: 1.6193046569824219
Validation loss: 2.1539264172315598

Epoch: 5| Step: 7
Training loss: 1.7231642007827759
Validation loss: 2.149040013551712

Epoch: 5| Step: 8
Training loss: 1.79949152469635
Validation loss: 2.1498392472664514

Epoch: 5| Step: 9
Training loss: 2.6625466346740723
Validation loss: 2.159008418520292

Epoch: 5| Step: 10
Training loss: 1.5773035287857056
Validation loss: 2.1518592735131583

Epoch: 5| Step: 11
Training loss: 1.1944366693496704
Validation loss: 2.155022362867991

Epoch: 252| Step: 0
Training loss: 2.29563570022583
Validation loss: 2.15910076101621

Epoch: 5| Step: 1
Training loss: 1.2966246604919434
Validation loss: 2.1680336197217307

Epoch: 5| Step: 2
Training loss: 1.9359678030014038
Validation loss: 2.149228980143865

Epoch: 5| Step: 3
Training loss: 1.4735625982284546
Validation loss: 2.1722724934418998

Epoch: 5| Step: 4
Training loss: 2.057617664337158
Validation loss: 2.1863646507263184

Epoch: 5| Step: 5
Training loss: 1.7852561473846436
Validation loss: 2.2016642838716507

Epoch: 5| Step: 6
Training loss: 2.322622299194336
Validation loss: 2.215381234884262

Epoch: 5| Step: 7
Training loss: 1.742540955543518
Validation loss: 2.199195941289266

Epoch: 5| Step: 8
Training loss: 2.2700490951538086
Validation loss: 2.1899587909380593

Epoch: 5| Step: 9
Training loss: 1.8016464710235596
Validation loss: 2.167803635199865

Epoch: 5| Step: 10
Training loss: 1.7280519008636475
Validation loss: 2.151193087299665

Epoch: 5| Step: 11
Training loss: 1.1033573150634766
Validation loss: 2.16336956123511

Epoch: 253| Step: 0
Training loss: 1.5684621334075928
Validation loss: 2.1394231418768563

Epoch: 5| Step: 1
Training loss: 1.9107211828231812
Validation loss: 2.1244652569293976

Epoch: 5| Step: 2
Training loss: 2.1814770698547363
Validation loss: 2.1330565214157104

Epoch: 5| Step: 3
Training loss: 2.095792770385742
Validation loss: 2.132987916469574

Epoch: 5| Step: 4
Training loss: 1.7714580297470093
Validation loss: 2.122290849685669

Epoch: 5| Step: 5
Training loss: 1.7278461456298828
Validation loss: 2.138586163520813

Epoch: 5| Step: 6
Training loss: 2.2396247386932373
Validation loss: 2.1260514507691064

Epoch: 5| Step: 7
Training loss: 1.9929592609405518
Validation loss: 2.133112385869026

Epoch: 5| Step: 8
Training loss: 1.7718521356582642
Validation loss: 2.1407516449689865

Epoch: 5| Step: 9
Training loss: 2.0601818561553955
Validation loss: 2.1589513272047043

Epoch: 5| Step: 10
Training loss: 1.830816626548767
Validation loss: 2.1535885582367578

Epoch: 5| Step: 11
Training loss: 1.3111999034881592
Validation loss: 2.1569437185923257

Epoch: 254| Step: 0
Training loss: 1.9538249969482422
Validation loss: 2.16794154047966

Epoch: 5| Step: 1
Training loss: 1.8711588382720947
Validation loss: 2.201162427663803

Epoch: 5| Step: 2
Training loss: 2.1526036262512207
Validation loss: 2.2134225567181907

Epoch: 5| Step: 3
Training loss: 2.2854535579681396
Validation loss: 2.21407949924469

Epoch: 5| Step: 4
Training loss: 1.5001658201217651
Validation loss: 2.2187225421269736

Epoch: 5| Step: 5
Training loss: 1.9611423015594482
Validation loss: 2.217956076065699

Epoch: 5| Step: 6
Training loss: 2.2650654315948486
Validation loss: 2.2117828677097955

Epoch: 5| Step: 7
Training loss: 1.504372000694275
Validation loss: 2.188531110684077

Epoch: 5| Step: 8
Training loss: 1.794289231300354
Validation loss: 2.1629315614700317

Epoch: 5| Step: 9
Training loss: 2.2749438285827637
Validation loss: 2.158304507533709

Epoch: 5| Step: 10
Training loss: 1.358739972114563
Validation loss: 2.1514374564091363

Epoch: 5| Step: 11
Training loss: 2.6538593769073486
Validation loss: 2.141910269856453

Epoch: 255| Step: 0
Training loss: 1.75537109375
Validation loss: 2.1459313233693442

Epoch: 5| Step: 1
Training loss: 1.8358770608901978
Validation loss: 2.1385280738274255

Epoch: 5| Step: 2
Training loss: 1.7260382175445557
Validation loss: 2.1605481008688607

Epoch: 5| Step: 3
Training loss: 1.5590837001800537
Validation loss: 2.1450906842947006

Epoch: 5| Step: 4
Training loss: 1.531823992729187
Validation loss: 2.1629782567421594

Epoch: 5| Step: 5
Training loss: 2.032031774520874
Validation loss: 2.162030816078186

Epoch: 5| Step: 6
Training loss: 1.953992486000061
Validation loss: 2.164828990896543

Epoch: 5| Step: 7
Training loss: 2.014409303665161
Validation loss: 2.1690706411997476

Epoch: 5| Step: 8
Training loss: 2.2558817863464355
Validation loss: 2.169589102268219

Epoch: 5| Step: 9
Training loss: 1.6390540599822998
Validation loss: 2.159290666381518

Epoch: 5| Step: 10
Training loss: 1.9827244281768799
Validation loss: 2.1440929720799127

Epoch: 5| Step: 11
Training loss: 2.0846598148345947
Validation loss: 2.155987486243248

Epoch: 256| Step: 0
Training loss: 1.6769176721572876
Validation loss: 2.176629294951757

Epoch: 5| Step: 1
Training loss: 2.3055858612060547
Validation loss: 2.1622269451618195

Epoch: 5| Step: 2
Training loss: 1.8378559350967407
Validation loss: 2.1696573744217553

Epoch: 5| Step: 3
Training loss: 1.7260634899139404
Validation loss: 2.1485670506954193

Epoch: 5| Step: 4
Training loss: 1.8517124652862549
Validation loss: 2.148827761411667

Epoch: 5| Step: 5
Training loss: 1.8499860763549805
Validation loss: 2.145035962263743

Epoch: 5| Step: 6
Training loss: 1.7704026699066162
Validation loss: 2.1655781169732413

Epoch: 5| Step: 7
Training loss: 1.5446808338165283
Validation loss: 2.140084385871887

Epoch: 5| Step: 8
Training loss: 1.588280439376831
Validation loss: 2.152498245239258

Epoch: 5| Step: 9
Training loss: 2.1755318641662598
Validation loss: 2.160915717482567

Epoch: 5| Step: 10
Training loss: 1.9846407175064087
Validation loss: 2.154534012079239

Epoch: 5| Step: 11
Training loss: 1.4244391918182373
Validation loss: 2.1600442280371985

Epoch: 257| Step: 0
Training loss: 1.8315441608428955
Validation loss: 2.15793277323246

Epoch: 5| Step: 1
Training loss: 1.9585075378417969
Validation loss: 2.1655949552853904

Epoch: 5| Step: 2
Training loss: 1.7589664459228516
Validation loss: 2.1573704729477563

Epoch: 5| Step: 3
Training loss: 1.8770049810409546
Validation loss: 2.155195415019989

Epoch: 5| Step: 4
Training loss: 2.0192008018493652
Validation loss: 2.161099632581075

Epoch: 5| Step: 5
Training loss: 1.6409944295883179
Validation loss: 2.1595019896825156

Epoch: 5| Step: 6
Training loss: 1.8241517543792725
Validation loss: 2.1410545309384665

Epoch: 5| Step: 7
Training loss: 1.6923881769180298
Validation loss: 2.1471360524495444

Epoch: 5| Step: 8
Training loss: 1.6207393407821655
Validation loss: 2.158849596977234

Epoch: 5| Step: 9
Training loss: 1.9197715520858765
Validation loss: 2.1571097373962402

Epoch: 5| Step: 10
Training loss: 2.2267656326293945
Validation loss: 2.1485596150159836

Epoch: 5| Step: 11
Training loss: 0.9376329779624939
Validation loss: 2.154742548863093

Epoch: 258| Step: 0
Training loss: 1.5613245964050293
Validation loss: 2.138000031312307

Epoch: 5| Step: 1
Training loss: 1.710058569908142
Validation loss: 2.1276441315809884

Epoch: 5| Step: 2
Training loss: 2.4376118183135986
Validation loss: 2.1267812301715217

Epoch: 5| Step: 3
Training loss: 2.316927433013916
Validation loss: 2.1398234019676843

Epoch: 5| Step: 4
Training loss: 2.0578160285949707
Validation loss: 2.1347480018933616

Epoch: 5| Step: 5
Training loss: 2.0028862953186035
Validation loss: 2.122312138477961

Epoch: 5| Step: 6
Training loss: 1.6847938299179077
Validation loss: 2.126712530851364

Epoch: 5| Step: 7
Training loss: 1.6478198766708374
Validation loss: 2.124897619088491

Epoch: 5| Step: 8
Training loss: 2.256804943084717
Validation loss: 2.1273006747166314

Epoch: 5| Step: 9
Training loss: 1.6534960269927979
Validation loss: 2.1184527774651847

Epoch: 5| Step: 10
Training loss: 1.999243974685669
Validation loss: 2.1392387797435126

Epoch: 5| Step: 11
Training loss: 1.181875467300415
Validation loss: 2.149243007103602

Epoch: 259| Step: 0
Training loss: 2.0894665718078613
Validation loss: 2.163559138774872

Epoch: 5| Step: 1
Training loss: 2.123227119445801
Validation loss: 2.1620957404375076

Epoch: 5| Step: 2
Training loss: 1.7516310214996338
Validation loss: 2.173917536934217

Epoch: 5| Step: 3
Training loss: 2.2415060997009277
Validation loss: 2.172360713283221

Epoch: 5| Step: 4
Training loss: 1.468605637550354
Validation loss: 2.1810458600521088

Epoch: 5| Step: 5
Training loss: 1.8486061096191406
Validation loss: 2.166662628451983

Epoch: 5| Step: 6
Training loss: 1.98081374168396
Validation loss: 2.165386085708936

Epoch: 5| Step: 7
Training loss: 1.9995918273925781
Validation loss: 2.168620377779007

Epoch: 5| Step: 8
Training loss: 1.7682911157608032
Validation loss: 2.148546094695727

Epoch: 5| Step: 9
Training loss: 1.5557136535644531
Validation loss: 2.152703364690145

Epoch: 5| Step: 10
Training loss: 2.1427524089813232
Validation loss: 2.1336458126703897

Epoch: 5| Step: 11
Training loss: 0.9461768865585327
Validation loss: 2.136350686351458

Epoch: 260| Step: 0
Training loss: 1.7157068252563477
Validation loss: 2.1416189720233283

Epoch: 5| Step: 1
Training loss: 1.5130220651626587
Validation loss: 2.1418759574492774

Epoch: 5| Step: 2
Training loss: 1.8191492557525635
Validation loss: 2.123311693469683

Epoch: 5| Step: 3
Training loss: 1.9776620864868164
Validation loss: 2.131615767876307

Epoch: 5| Step: 4
Training loss: 2.219252109527588
Validation loss: 2.130056470632553

Epoch: 5| Step: 5
Training loss: 2.1752915382385254
Validation loss: 2.1345160007476807

Epoch: 5| Step: 6
Training loss: 1.9672428369522095
Validation loss: 2.145283689101537

Epoch: 5| Step: 7
Training loss: 1.4642442464828491
Validation loss: 2.123771920800209

Epoch: 5| Step: 8
Training loss: 1.377211570739746
Validation loss: 2.127158592144648

Epoch: 5| Step: 9
Training loss: 2.1173605918884277
Validation loss: 2.122319291035334

Epoch: 5| Step: 10
Training loss: 1.8110380172729492
Validation loss: 2.141657347480456

Epoch: 5| Step: 11
Training loss: 3.253445625305176
Validation loss: 2.133075793584188

Epoch: 261| Step: 0
Training loss: 1.5653736591339111
Validation loss: 2.1235071420669556

Epoch: 5| Step: 1
Training loss: 2.4487857818603516
Validation loss: 2.1375383138656616

Epoch: 5| Step: 2
Training loss: 1.6962213516235352
Validation loss: 2.1505739390850067

Epoch: 5| Step: 3
Training loss: 2.321106433868408
Validation loss: 2.1266791075468063

Epoch: 5| Step: 4
Training loss: 1.7060174942016602
Validation loss: 2.1374342292547226

Epoch: 5| Step: 5
Training loss: 1.4942376613616943
Validation loss: 2.130822087327639

Epoch: 5| Step: 6
Training loss: 2.05735182762146
Validation loss: 2.1453999231259027

Epoch: 5| Step: 7
Training loss: 1.8160040378570557
Validation loss: 2.1390585005283356

Epoch: 5| Step: 8
Training loss: 1.334848403930664
Validation loss: 2.1459719936052957

Epoch: 5| Step: 9
Training loss: 1.5113723278045654
Validation loss: 2.154883772134781

Epoch: 5| Step: 10
Training loss: 2.1376793384552
Validation loss: 2.16918275753657

Epoch: 5| Step: 11
Training loss: 1.4644858837127686
Validation loss: 2.1560179789861045

Epoch: 262| Step: 0
Training loss: 1.6448177099227905
Validation loss: 2.144383559624354

Epoch: 5| Step: 1
Training loss: 1.8411983251571655
Validation loss: 2.1293886502583823

Epoch: 5| Step: 2
Training loss: 1.9410429000854492
Validation loss: 2.133556087811788

Epoch: 5| Step: 3
Training loss: 1.6845366954803467
Validation loss: 2.1462066719929376

Epoch: 5| Step: 4
Training loss: 1.4364982843399048
Validation loss: 2.1532594859600067

Epoch: 5| Step: 5
Training loss: 1.3910351991653442
Validation loss: 2.151695321003596

Epoch: 5| Step: 6
Training loss: 1.968998908996582
Validation loss: 2.156919409831365

Epoch: 5| Step: 7
Training loss: 1.9162025451660156
Validation loss: 2.168116102615992

Epoch: 5| Step: 8
Training loss: 2.058260679244995
Validation loss: 2.180681591232618

Epoch: 5| Step: 9
Training loss: 1.9834601879119873
Validation loss: 2.201961318651835

Epoch: 5| Step: 10
Training loss: 2.166445016860962
Validation loss: 2.1913425028324127

Epoch: 5| Step: 11
Training loss: 2.2849032878875732
Validation loss: 2.1826162536938987

Epoch: 263| Step: 0
Training loss: 2.0093677043914795
Validation loss: 2.17993093530337

Epoch: 5| Step: 1
Training loss: 2.081864833831787
Validation loss: 2.1915125846862793

Epoch: 5| Step: 2
Training loss: 1.2880642414093018
Validation loss: 2.182204450170199

Epoch: 5| Step: 3
Training loss: 1.6603708267211914
Validation loss: 2.161942849556605

Epoch: 5| Step: 4
Training loss: 2.2216553688049316
Validation loss: 2.142894188563029

Epoch: 5| Step: 5
Training loss: 1.8247156143188477
Validation loss: 2.1393622209628425

Epoch: 5| Step: 6
Training loss: 1.815476655960083
Validation loss: 2.139879102508227

Epoch: 5| Step: 7
Training loss: 1.6868197917938232
Validation loss: 2.1336250404516854

Epoch: 5| Step: 8
Training loss: 2.454897403717041
Validation loss: 2.148067206144333

Epoch: 5| Step: 9
Training loss: 2.0756335258483887
Validation loss: 2.1503077199061713

Epoch: 5| Step: 10
Training loss: 1.120947003364563
Validation loss: 2.153767704963684

Epoch: 5| Step: 11
Training loss: 1.1261638402938843
Validation loss: 2.1489537159601846

Epoch: 264| Step: 0
Training loss: 2.137446880340576
Validation loss: 2.160415624578794

Epoch: 5| Step: 1
Training loss: 1.7313899993896484
Validation loss: 2.18252902229627

Epoch: 5| Step: 2
Training loss: 1.4856164455413818
Validation loss: 2.189660390218099

Epoch: 5| Step: 3
Training loss: 1.5522305965423584
Validation loss: 2.1925041874249778

Epoch: 5| Step: 4
Training loss: 1.6777263879776
Validation loss: 2.1921035200357437

Epoch: 5| Step: 5
Training loss: 2.1698479652404785
Validation loss: 2.2045356879631677

Epoch: 5| Step: 6
Training loss: 2.9738361835479736
Validation loss: 2.1752845297257104

Epoch: 5| Step: 7
Training loss: 1.9564027786254883
Validation loss: 2.1770017743110657

Epoch: 5| Step: 8
Training loss: 1.4673941135406494
Validation loss: 2.1842499673366547

Epoch: 5| Step: 9
Training loss: 1.4925583600997925
Validation loss: 2.2011467119057975

Epoch: 5| Step: 10
Training loss: 1.5702558755874634
Validation loss: 2.1871349265178046

Epoch: 5| Step: 11
Training loss: 0.9484034776687622
Validation loss: 2.177805542945862

Epoch: 265| Step: 0
Training loss: 1.7376940250396729
Validation loss: 2.1648309777180352

Epoch: 5| Step: 1
Training loss: 1.781484603881836
Validation loss: 2.1558622221151986

Epoch: 5| Step: 2
Training loss: 2.2011539936065674
Validation loss: 2.1459214438994727

Epoch: 5| Step: 3
Training loss: 1.708539366722107
Validation loss: 2.1555810372034707

Epoch: 5| Step: 4
Training loss: 2.093627452850342
Validation loss: 2.1520668317874274

Epoch: 5| Step: 5
Training loss: 2.188450336456299
Validation loss: 2.1417279690504074

Epoch: 5| Step: 6
Training loss: 0.9947341084480286
Validation loss: 2.1327801744143167

Epoch: 5| Step: 7
Training loss: 2.300154209136963
Validation loss: 2.148839756846428

Epoch: 5| Step: 8
Training loss: 1.6267306804656982
Validation loss: 2.1506412625312805

Epoch: 5| Step: 9
Training loss: 2.080106258392334
Validation loss: 2.16357629497846

Epoch: 5| Step: 10
Training loss: 1.7892303466796875
Validation loss: 2.165632888674736

Epoch: 5| Step: 11
Training loss: 1.8564783334732056
Validation loss: 2.16859765847524

Epoch: 266| Step: 0
Training loss: 2.423849582672119
Validation loss: 2.184057275454203

Epoch: 5| Step: 1
Training loss: 1.7803888320922852
Validation loss: 2.1966015100479126

Epoch: 5| Step: 2
Training loss: 1.6152461767196655
Validation loss: 2.191211700439453

Epoch: 5| Step: 3
Training loss: 1.9543380737304688
Validation loss: 2.2146064142386117

Epoch: 5| Step: 4
Training loss: 2.2203752994537354
Validation loss: 2.217618311444918

Epoch: 5| Step: 5
Training loss: 1.7086513042449951
Validation loss: 2.2155215442180634

Epoch: 5| Step: 6
Training loss: 1.491005301475525
Validation loss: 2.2169278264045715

Epoch: 5| Step: 7
Training loss: 2.0390865802764893
Validation loss: 2.223553796609243

Epoch: 5| Step: 8
Training loss: 1.7459619045257568
Validation loss: 2.2129651506741843

Epoch: 5| Step: 9
Training loss: 1.3486530780792236
Validation loss: 2.212054337064425

Epoch: 5| Step: 10
Training loss: 2.036924123764038
Validation loss: 2.1775148610273996

Epoch: 5| Step: 11
Training loss: 1.3538979291915894
Validation loss: 2.1771678725878396

Epoch: 267| Step: 0
Training loss: 2.057366132736206
Validation loss: 2.1706670174996057

Epoch: 5| Step: 1
Training loss: 2.4013257026672363
Validation loss: 2.1548819740613303

Epoch: 5| Step: 2
Training loss: 1.4769196510314941
Validation loss: 2.1427070597807565

Epoch: 5| Step: 3
Training loss: 1.5477672815322876
Validation loss: 2.140549878279368

Epoch: 5| Step: 4
Training loss: 1.4920482635498047
Validation loss: 2.1349800576766333

Epoch: 5| Step: 5
Training loss: 1.7979589700698853
Validation loss: 2.148772860566775

Epoch: 5| Step: 6
Training loss: 2.1791579723358154
Validation loss: 2.1624998599290848

Epoch: 5| Step: 7
Training loss: 2.0061843395233154
Validation loss: 2.1641271114349365

Epoch: 5| Step: 8
Training loss: 1.928602933883667
Validation loss: 2.1860711673895517

Epoch: 5| Step: 9
Training loss: 1.2488303184509277
Validation loss: 2.161142180363337

Epoch: 5| Step: 10
Training loss: 2.128330707550049
Validation loss: 2.170214350024859

Epoch: 5| Step: 11
Training loss: 1.094322919845581
Validation loss: 2.1695659160614014

Epoch: 268| Step: 0
Training loss: 1.5480155944824219
Validation loss: 2.172458291053772

Epoch: 5| Step: 1
Training loss: 1.6684389114379883
Validation loss: 2.172476435701052

Epoch: 5| Step: 2
Training loss: 2.415771007537842
Validation loss: 2.180262232820193

Epoch: 5| Step: 3
Training loss: 2.2234151363372803
Validation loss: 2.1683462411165237

Epoch: 5| Step: 4
Training loss: 1.5268460512161255
Validation loss: 2.1609887381394706

Epoch: 5| Step: 5
Training loss: 1.5535097122192383
Validation loss: 2.155157888929049

Epoch: 5| Step: 6
Training loss: 2.1797001361846924
Validation loss: 2.1477723171313605

Epoch: 5| Step: 7
Training loss: 2.335697889328003
Validation loss: 2.1490470667680106

Epoch: 5| Step: 8
Training loss: 1.688469648361206
Validation loss: 2.1439222345749536

Epoch: 5| Step: 9
Training loss: 1.6042531728744507
Validation loss: 2.1486996759970984

Epoch: 5| Step: 10
Training loss: 1.4487959146499634
Validation loss: 2.170886665582657

Epoch: 5| Step: 11
Training loss: 1.5472235679626465
Validation loss: 2.1734504203001657

Epoch: 269| Step: 0
Training loss: 1.6981315612792969
Validation loss: 2.1766905089219413

Epoch: 5| Step: 1
Training loss: 2.2895712852478027
Validation loss: 2.200034648180008

Epoch: 5| Step: 2
Training loss: 1.9585965871810913
Validation loss: 2.1873479932546616

Epoch: 5| Step: 3
Training loss: 1.666513442993164
Validation loss: 2.1907278498013816

Epoch: 5| Step: 4
Training loss: 1.9335155487060547
Validation loss: 2.1941546152035394

Epoch: 5| Step: 5
Training loss: 1.918839693069458
Validation loss: 2.1900187681118646

Epoch: 5| Step: 6
Training loss: 1.6118494272232056
Validation loss: 2.187432517608007

Epoch: 5| Step: 7
Training loss: 2.2363998889923096
Validation loss: 2.181008999546369

Epoch: 5| Step: 8
Training loss: 1.7364826202392578
Validation loss: 2.207431356112162

Epoch: 5| Step: 9
Training loss: 1.2844709157943726
Validation loss: 2.20295720299085

Epoch: 5| Step: 10
Training loss: 1.5598361492156982
Validation loss: 2.1818394710620246

Epoch: 5| Step: 11
Training loss: 1.3085672855377197
Validation loss: 2.2029327154159546

Epoch: 270| Step: 0
Training loss: 1.8617746829986572
Validation loss: 2.1910625050465264

Epoch: 5| Step: 1
Training loss: 1.8944050073623657
Validation loss: 2.1937587360541024

Epoch: 5| Step: 2
Training loss: 1.3739436864852905
Validation loss: 2.1658497154712677

Epoch: 5| Step: 3
Training loss: 1.6470146179199219
Validation loss: 2.173504039645195

Epoch: 5| Step: 4
Training loss: 1.8349968194961548
Validation loss: 2.1740996738274894

Epoch: 5| Step: 5
Training loss: 1.9968898296356201
Validation loss: 2.1682936449845633

Epoch: 5| Step: 6
Training loss: 1.683401107788086
Validation loss: 2.1829099357128143

Epoch: 5| Step: 7
Training loss: 1.9290497303009033
Validation loss: 2.166350315014521

Epoch: 5| Step: 8
Training loss: 2.1417791843414307
Validation loss: 2.164384345213572

Epoch: 5| Step: 9
Training loss: 1.9553890228271484
Validation loss: 2.171945412953695

Epoch: 5| Step: 10
Training loss: 1.5618739128112793
Validation loss: 2.1518504669268927

Epoch: 5| Step: 11
Training loss: 0.7294051647186279
Validation loss: 2.1361224253972373

Epoch: 271| Step: 0
Training loss: 2.0425360202789307
Validation loss: 2.167217324177424

Epoch: 5| Step: 1
Training loss: 1.6472240686416626
Validation loss: 2.170817330479622

Epoch: 5| Step: 2
Training loss: 1.9162514209747314
Validation loss: 2.174207250277201

Epoch: 5| Step: 3
Training loss: 1.8894922733306885
Validation loss: 2.1844788094361625

Epoch: 5| Step: 4
Training loss: 1.8381259441375732
Validation loss: 2.1866706212361655

Epoch: 5| Step: 5
Training loss: 1.888584852218628
Validation loss: 2.1743605683247247

Epoch: 5| Step: 6
Training loss: 1.5776615142822266
Validation loss: 2.171332284808159

Epoch: 5| Step: 7
Training loss: 1.6032745838165283
Validation loss: 2.1849032938480377

Epoch: 5| Step: 8
Training loss: 1.2852758169174194
Validation loss: 2.1601721346378326

Epoch: 5| Step: 9
Training loss: 2.0840814113616943
Validation loss: 2.153398315111796

Epoch: 5| Step: 10
Training loss: 2.1642680168151855
Validation loss: 2.1821877708037696

Epoch: 5| Step: 11
Training loss: 1.3182018995285034
Validation loss: 2.1871590813001

Epoch: 272| Step: 0
Training loss: 1.8745826482772827
Validation loss: 2.1579381624857583

Epoch: 5| Step: 1
Training loss: 1.6352142095565796
Validation loss: 2.193096583088239

Epoch: 5| Step: 2
Training loss: 2.025160312652588
Validation loss: 2.167266845703125

Epoch: 5| Step: 3
Training loss: 1.8604233264923096
Validation loss: 2.1600911021232605

Epoch: 5| Step: 4
Training loss: 2.005502223968506
Validation loss: 2.1812063455581665

Epoch: 5| Step: 5
Training loss: 1.276572585105896
Validation loss: 2.1881681829690933

Epoch: 5| Step: 6
Training loss: 1.1753530502319336
Validation loss: 2.177300974726677

Epoch: 5| Step: 7
Training loss: 1.8882300853729248
Validation loss: 2.168995196620623

Epoch: 5| Step: 8
Training loss: 1.8033958673477173
Validation loss: 2.1854138473669686

Epoch: 5| Step: 9
Training loss: 2.2084596157073975
Validation loss: 2.168919881184896

Epoch: 5| Step: 10
Training loss: 1.813285231590271
Validation loss: 2.164689133564631

Epoch: 5| Step: 11
Training loss: 1.5686640739440918
Validation loss: 2.1530445516109467

Epoch: 273| Step: 0
Training loss: 1.7136545181274414
Validation loss: 2.15708593527476

Epoch: 5| Step: 1
Training loss: 1.8598663806915283
Validation loss: 2.1693033476670585

Epoch: 5| Step: 2
Training loss: 1.2956318855285645
Validation loss: 2.188917184869448

Epoch: 5| Step: 3
Training loss: 2.2957699298858643
Validation loss: 2.195157547791799

Epoch: 5| Step: 4
Training loss: 2.2672226428985596
Validation loss: 2.1979000767072043

Epoch: 5| Step: 5
Training loss: 1.4795506000518799
Validation loss: 2.1993668377399445

Epoch: 5| Step: 6
Training loss: 1.5556174516677856
Validation loss: 2.206610083580017

Epoch: 5| Step: 7
Training loss: 1.5363796949386597
Validation loss: 2.193287968635559

Epoch: 5| Step: 8
Training loss: 1.8922275304794312
Validation loss: 2.1951604088147483

Epoch: 5| Step: 9
Training loss: 2.1243467330932617
Validation loss: 2.234476705392202

Epoch: 5| Step: 10
Training loss: 1.626199722290039
Validation loss: 2.2179190119107566

Epoch: 5| Step: 11
Training loss: 1.572468876838684
Validation loss: 2.208487316966057

Epoch: 274| Step: 0
Training loss: 1.9242690801620483
Validation loss: 2.2023503482341766

Epoch: 5| Step: 1
Training loss: 1.176317811012268
Validation loss: 2.198935866355896

Epoch: 5| Step: 2
Training loss: 1.6062253713607788
Validation loss: 2.197569986184438

Epoch: 5| Step: 3
Training loss: 1.6654937267303467
Validation loss: 2.1688728630542755

Epoch: 5| Step: 4
Training loss: 1.969188928604126
Validation loss: 2.182194630304972

Epoch: 5| Step: 5
Training loss: 1.5137585401535034
Validation loss: 2.182337393363317

Epoch: 5| Step: 6
Training loss: 1.6377071142196655
Validation loss: 2.171760082244873

Epoch: 5| Step: 7
Training loss: 1.3761570453643799
Validation loss: 2.191247910261154

Epoch: 5| Step: 8
Training loss: 2.5311431884765625
Validation loss: 2.174823800722758

Epoch: 5| Step: 9
Training loss: 1.9446489810943604
Validation loss: 2.1695352296034494

Epoch: 5| Step: 10
Training loss: 2.1153273582458496
Validation loss: 2.183264911174774

Epoch: 5| Step: 11
Training loss: 1.553897738456726
Validation loss: 2.195781538883845

Epoch: 275| Step: 0
Training loss: 1.7772200107574463
Validation loss: 2.2094100614388785

Epoch: 5| Step: 1
Training loss: 1.7642850875854492
Validation loss: 2.2010650783777237

Epoch: 5| Step: 2
Training loss: 1.4638729095458984
Validation loss: 2.18547393878301

Epoch: 5| Step: 3
Training loss: 1.4087679386138916
Validation loss: 2.187494218349457

Epoch: 5| Step: 4
Training loss: 1.7010929584503174
Validation loss: 2.199040248990059

Epoch: 5| Step: 5
Training loss: 1.860364317893982
Validation loss: 2.187855010231336

Epoch: 5| Step: 6
Training loss: 1.340398907661438
Validation loss: 2.1946909775336585

Epoch: 5| Step: 7
Training loss: 2.5510449409484863
Validation loss: 2.1935877750317254

Epoch: 5| Step: 8
Training loss: 1.6048568487167358
Validation loss: 2.1992469131946564

Epoch: 5| Step: 9
Training loss: 1.6551494598388672
Validation loss: 2.196023389697075

Epoch: 5| Step: 10
Training loss: 2.264882802963257
Validation loss: 2.1955193827549615

Epoch: 5| Step: 11
Training loss: 2.325523853302002
Validation loss: 2.164636582136154

Epoch: 276| Step: 0
Training loss: 1.6848962306976318
Validation loss: 2.1861923038959503

Epoch: 5| Step: 1
Training loss: 1.670170545578003
Validation loss: 2.168108209967613

Epoch: 5| Step: 2
Training loss: 1.4461055994033813
Validation loss: 2.196823373436928

Epoch: 5| Step: 3
Training loss: 1.5821101665496826
Validation loss: 2.2290746172269187

Epoch: 5| Step: 4
Training loss: 1.3060128688812256
Validation loss: 2.20264795422554

Epoch: 5| Step: 5
Training loss: 1.7496020793914795
Validation loss: 2.226076220472654

Epoch: 5| Step: 6
Training loss: 2.287083387374878
Validation loss: 2.22458948691686

Epoch: 5| Step: 7
Training loss: 1.9328737258911133
Validation loss: 2.1939520637194314

Epoch: 5| Step: 8
Training loss: 1.852104902267456
Validation loss: 2.1881571958462396

Epoch: 5| Step: 9
Training loss: 2.061387300491333
Validation loss: 2.1699257592360177

Epoch: 5| Step: 10
Training loss: 1.7457643747329712
Validation loss: 2.177513380845388

Epoch: 5| Step: 11
Training loss: 2.868746519088745
Validation loss: 2.1712082823117576

Epoch: 277| Step: 0
Training loss: 1.2651103734970093
Validation loss: 2.1658639311790466

Epoch: 5| Step: 1
Training loss: 2.938530206680298
Validation loss: 2.182194009423256

Epoch: 5| Step: 2
Training loss: 1.499678611755371
Validation loss: 2.2010593712329865

Epoch: 5| Step: 3
Training loss: 1.4127784967422485
Validation loss: 2.201227063934008

Epoch: 5| Step: 4
Training loss: 1.3347046375274658
Validation loss: 2.1797869751850762

Epoch: 5| Step: 5
Training loss: 1.126503586769104
Validation loss: 2.1957217206557593

Epoch: 5| Step: 6
Training loss: 2.072265148162842
Validation loss: 2.1776024202505746

Epoch: 5| Step: 7
Training loss: 1.9449611902236938
Validation loss: 2.1909481088320413

Epoch: 5| Step: 8
Training loss: 1.875306487083435
Validation loss: 2.1942478716373444

Epoch: 5| Step: 9
Training loss: 1.8089128732681274
Validation loss: 2.1942845582962036

Epoch: 5| Step: 10
Training loss: 2.1738314628601074
Validation loss: 2.1952755749225616

Epoch: 5| Step: 11
Training loss: 1.0490955114364624
Validation loss: 2.1881869236628213

Epoch: 278| Step: 0
Training loss: 1.5696327686309814
Validation loss: 2.190751706560453

Epoch: 5| Step: 1
Training loss: 1.6837012767791748
Validation loss: 2.198447505633036

Epoch: 5| Step: 2
Training loss: 1.5563710927963257
Validation loss: 2.1827895740667977

Epoch: 5| Step: 3
Training loss: 1.6773761510849
Validation loss: 2.183099776506424

Epoch: 5| Step: 4
Training loss: 1.7633377313613892
Validation loss: 2.1983377983172736

Epoch: 5| Step: 5
Training loss: 2.160395383834839
Validation loss: 2.160908415913582

Epoch: 5| Step: 6
Training loss: 1.5510427951812744
Validation loss: 2.1880307098229728

Epoch: 5| Step: 7
Training loss: 2.533970355987549
Validation loss: 2.1808546980222068

Epoch: 5| Step: 8
Training loss: 2.165292263031006
Validation loss: 2.1890392005443573

Epoch: 5| Step: 9
Training loss: 1.534670114517212
Validation loss: 2.1734497795502343

Epoch: 5| Step: 10
Training loss: 1.0977752208709717
Validation loss: 2.166313648223877

Epoch: 5| Step: 11
Training loss: 2.8335957527160645
Validation loss: 2.183251455426216

Epoch: 279| Step: 0
Training loss: 1.7735542058944702
Validation loss: 2.1756210575501123

Epoch: 5| Step: 1
Training loss: 1.499342441558838
Validation loss: 2.169287323951721

Epoch: 5| Step: 2
Training loss: 1.9278075695037842
Validation loss: 2.180926332871119

Epoch: 5| Step: 3
Training loss: 1.5996172428131104
Validation loss: 2.183005526661873

Epoch: 5| Step: 4
Training loss: 1.6511691808700562
Validation loss: 2.17858849465847

Epoch: 5| Step: 5
Training loss: 1.7121350765228271
Validation loss: 2.179008518656095

Epoch: 5| Step: 6
Training loss: 1.5737640857696533
Validation loss: 2.192267894744873

Epoch: 5| Step: 7
Training loss: 1.779944658279419
Validation loss: 2.185374438762665

Epoch: 5| Step: 8
Training loss: 2.1238913536071777
Validation loss: 2.1718527475992837

Epoch: 5| Step: 9
Training loss: 2.446150541305542
Validation loss: 2.1990297635396323

Epoch: 5| Step: 10
Training loss: 1.313306450843811
Validation loss: 2.181459238131841

Epoch: 5| Step: 11
Training loss: 2.4215352535247803
Validation loss: 2.1782199442386627

Epoch: 280| Step: 0
Training loss: 1.758252501487732
Validation loss: 2.1829600582520166

Epoch: 5| Step: 1
Training loss: 1.1840794086456299
Validation loss: 2.176298663020134

Epoch: 5| Step: 2
Training loss: 1.2692548036575317
Validation loss: 2.1874567568302155

Epoch: 5| Step: 3
Training loss: 2.261432647705078
Validation loss: 2.164051686724027

Epoch: 5| Step: 4
Training loss: 1.8574663400650024
Validation loss: 2.186961834629377

Epoch: 5| Step: 5
Training loss: 1.9137042760849
Validation loss: 2.183414106567701

Epoch: 5| Step: 6
Training loss: 1.8237603902816772
Validation loss: 2.169066538413366

Epoch: 5| Step: 7
Training loss: 2.155949115753174
Validation loss: 2.1786895394325256

Epoch: 5| Step: 8
Training loss: 1.9791557788848877
Validation loss: 2.1813741823037467

Epoch: 5| Step: 9
Training loss: 1.6341739892959595
Validation loss: 2.175092483560244

Epoch: 5| Step: 10
Training loss: 1.255814790725708
Validation loss: 2.1679785698652267

Epoch: 5| Step: 11
Training loss: 2.1947600841522217
Validation loss: 2.172178561488787

Epoch: 281| Step: 0
Training loss: 1.4919273853302002
Validation loss: 2.1836014787356057

Epoch: 5| Step: 1
Training loss: 1.4094603061676025
Validation loss: 2.18802780409654

Epoch: 5| Step: 2
Training loss: 1.8947696685791016
Validation loss: 2.1699269860982895

Epoch: 5| Step: 3
Training loss: 2.5243256092071533
Validation loss: 2.177724222342173

Epoch: 5| Step: 4
Training loss: 1.5557279586791992
Validation loss: 2.214712177713712

Epoch: 5| Step: 5
Training loss: 1.6954892873764038
Validation loss: 2.175425867239634

Epoch: 5| Step: 6
Training loss: 1.593045949935913
Validation loss: 2.209001580874125

Epoch: 5| Step: 7
Training loss: 1.603650450706482
Validation loss: 2.214285746216774

Epoch: 5| Step: 8
Training loss: 2.0902085304260254
Validation loss: 2.2525645792484283

Epoch: 5| Step: 9
Training loss: 1.6133968830108643
Validation loss: 2.247787982225418

Epoch: 5| Step: 10
Training loss: 1.5504964590072632
Validation loss: 2.2260139485200248

Epoch: 5| Step: 11
Training loss: 4.37981653213501
Validation loss: 2.218860775232315

Epoch: 282| Step: 0
Training loss: 2.3903517723083496
Validation loss: 2.237951030333837

Epoch: 5| Step: 1
Training loss: 1.6063425540924072
Validation loss: 2.215753967563311

Epoch: 5| Step: 2
Training loss: 1.5859102010726929
Validation loss: 2.2209060887495675

Epoch: 5| Step: 3
Training loss: 1.807661771774292
Validation loss: 2.2119993617137275

Epoch: 5| Step: 4
Training loss: 1.5275570154190063
Validation loss: 2.2145755539337793

Epoch: 5| Step: 5
Training loss: 2.042095899581909
Validation loss: 2.178436612089475

Epoch: 5| Step: 6
Training loss: 1.7029037475585938
Validation loss: 2.191902985175451

Epoch: 5| Step: 7
Training loss: 1.416159749031067
Validation loss: 2.1741224229335785

Epoch: 5| Step: 8
Training loss: 1.9922559261322021
Validation loss: 2.1716828048229218

Epoch: 5| Step: 9
Training loss: 1.7791446447372437
Validation loss: 2.176407794157664

Epoch: 5| Step: 10
Training loss: 1.804997205734253
Validation loss: 2.1873305439949036

Epoch: 5| Step: 11
Training loss: 1.0679922103881836
Validation loss: 2.189021239678065

Epoch: 283| Step: 0
Training loss: 2.46960711479187
Validation loss: 2.1875404119491577

Epoch: 5| Step: 1
Training loss: 1.7593610286712646
Validation loss: 2.1687310487031937

Epoch: 5| Step: 2
Training loss: 2.0869765281677246
Validation loss: 2.1883230259021125

Epoch: 5| Step: 3
Training loss: 1.8747066259384155
Validation loss: 2.1939457654953003

Epoch: 5| Step: 4
Training loss: 1.6354854106903076
Validation loss: 2.192601755261421

Epoch: 5| Step: 5
Training loss: 2.072608232498169
Validation loss: 2.1924418906370797

Epoch: 5| Step: 6
Training loss: 1.4995622634887695
Validation loss: 2.1866645216941833

Epoch: 5| Step: 7
Training loss: 1.3951444625854492
Validation loss: 2.1919819712638855

Epoch: 5| Step: 8
Training loss: 1.3256014585494995
Validation loss: 2.1904592414697013

Epoch: 5| Step: 9
Training loss: 1.3910949230194092
Validation loss: 2.2032434145609536

Epoch: 5| Step: 10
Training loss: 1.7877171039581299
Validation loss: 2.2105306734641395

Epoch: 5| Step: 11
Training loss: 1.6095937490463257
Validation loss: 2.2018485069274902

Epoch: 284| Step: 0
Training loss: 1.7553751468658447
Validation loss: 2.1899767220020294

Epoch: 5| Step: 1
Training loss: 1.8487565517425537
Validation loss: 2.2396088987588882

Epoch: 5| Step: 2
Training loss: 1.4418237209320068
Validation loss: 2.2170512080192566

Epoch: 5| Step: 3
Training loss: 1.0879459381103516
Validation loss: 2.216893821954727

Epoch: 5| Step: 4
Training loss: 2.098123550415039
Validation loss: 2.197814424832662

Epoch: 5| Step: 5
Training loss: 1.5619276762008667
Validation loss: 2.2051037549972534

Epoch: 5| Step: 6
Training loss: 1.4232523441314697
Validation loss: 2.1867950558662415

Epoch: 5| Step: 7
Training loss: 1.5954351425170898
Validation loss: 2.1929430613915124

Epoch: 5| Step: 8
Training loss: 1.6433312892913818
Validation loss: 2.187463919321696

Epoch: 5| Step: 9
Training loss: 2.521955966949463
Validation loss: 2.1932643155256906

Epoch: 5| Step: 10
Training loss: 1.9782397747039795
Validation loss: 2.209626058737437

Epoch: 5| Step: 11
Training loss: 3.3655753135681152
Validation loss: 2.191724807024002

Epoch: 285| Step: 0
Training loss: 1.5266315937042236
Validation loss: 2.1883306403954825

Epoch: 5| Step: 1
Training loss: 1.5246856212615967
Validation loss: 2.1972912599643073

Epoch: 5| Step: 2
Training loss: 1.7920093536376953
Validation loss: 2.2165655493736267

Epoch: 5| Step: 3
Training loss: 1.948647141456604
Validation loss: 2.221466064453125

Epoch: 5| Step: 4
Training loss: 2.3504652976989746
Validation loss: 2.2085732221603394

Epoch: 5| Step: 5
Training loss: 1.8470197916030884
Validation loss: 2.2254440585772195

Epoch: 5| Step: 6
Training loss: 1.9960825443267822
Validation loss: 2.227105349302292

Epoch: 5| Step: 7
Training loss: 1.5322281122207642
Validation loss: 2.2019626001516976

Epoch: 5| Step: 8
Training loss: 1.7433245182037354
Validation loss: 2.191553463538488

Epoch: 5| Step: 9
Training loss: 1.5533123016357422
Validation loss: 2.213038523991903

Epoch: 5| Step: 10
Training loss: 1.6313722133636475
Validation loss: 2.207165469725927

Epoch: 5| Step: 11
Training loss: 1.9834810495376587
Validation loss: 2.2278831054766974

Epoch: 286| Step: 0
Training loss: 1.6159003973007202
Validation loss: 2.2088824858268103

Epoch: 5| Step: 1
Training loss: 1.4882408380508423
Validation loss: 2.190931797027588

Epoch: 5| Step: 2
Training loss: 1.7864023447036743
Validation loss: 2.192870413263639

Epoch: 5| Step: 3
Training loss: 2.3928613662719727
Validation loss: 2.2144957234462104

Epoch: 5| Step: 4
Training loss: 1.5582399368286133
Validation loss: 2.2047727604707084

Epoch: 5| Step: 5
Training loss: 1.523597002029419
Validation loss: 2.1850653936465583

Epoch: 5| Step: 6
Training loss: 2.2263216972351074
Validation loss: 2.1863986452420554

Epoch: 5| Step: 7
Training loss: 1.409460425376892
Validation loss: 2.184752474228541

Epoch: 5| Step: 8
Training loss: 1.676306128501892
Validation loss: 2.193308105071386

Epoch: 5| Step: 9
Training loss: 2.0576882362365723
Validation loss: 2.192460760474205

Epoch: 5| Step: 10
Training loss: 1.2002195119857788
Validation loss: 2.1943454494078956

Epoch: 5| Step: 11
Training loss: 2.0017549991607666
Validation loss: 2.1954219142595925

Epoch: 287| Step: 0
Training loss: 1.8406531810760498
Validation loss: 2.2122658640146255

Epoch: 5| Step: 1
Training loss: 1.793389081954956
Validation loss: 2.181108668446541

Epoch: 5| Step: 2
Training loss: 1.9180351495742798
Validation loss: 2.2031165262063346

Epoch: 5| Step: 3
Training loss: 2.028749465942383
Validation loss: 2.194856142004331

Epoch: 5| Step: 4
Training loss: 1.6949704885482788
Validation loss: 2.1964058180650077

Epoch: 5| Step: 5
Training loss: 1.7781965732574463
Validation loss: 2.2049261381228766

Epoch: 5| Step: 6
Training loss: 1.752573013305664
Validation loss: 2.230185324947039

Epoch: 5| Step: 7
Training loss: 1.4904838800430298
Validation loss: 2.212461272875468

Epoch: 5| Step: 8
Training loss: 1.1201043128967285
Validation loss: 2.2187393605709076

Epoch: 5| Step: 9
Training loss: 1.5818970203399658
Validation loss: 2.2024742861588797

Epoch: 5| Step: 10
Training loss: 2.3819079399108887
Validation loss: 2.1972602208455405

Epoch: 5| Step: 11
Training loss: 1.307488203048706
Validation loss: 2.2033505141735077

Epoch: 288| Step: 0
Training loss: 1.6786775588989258
Validation loss: 2.1926133781671524

Epoch: 5| Step: 1
Training loss: 1.6322304010391235
Validation loss: 2.1857552528381348

Epoch: 5| Step: 2
Training loss: 1.741563081741333
Validation loss: 2.182698662082354

Epoch: 5| Step: 3
Training loss: 1.8567911386489868
Validation loss: 2.186423381169637

Epoch: 5| Step: 4
Training loss: 2.1103432178497314
Validation loss: 2.2130505740642548

Epoch: 5| Step: 5
Training loss: 1.2159494161605835
Validation loss: 2.192367414633433

Epoch: 5| Step: 6
Training loss: 1.6336339712142944
Validation loss: 2.213611031572024

Epoch: 5| Step: 7
Training loss: 1.7738851308822632
Validation loss: 2.197818468014399

Epoch: 5| Step: 8
Training loss: 1.8819000720977783
Validation loss: 2.198735843102137

Epoch: 5| Step: 9
Training loss: 2.0794548988342285
Validation loss: 2.19445006052653

Epoch: 5| Step: 10
Training loss: 1.5353822708129883
Validation loss: 2.1909619867801666

Epoch: 5| Step: 11
Training loss: 1.5717642307281494
Validation loss: 2.2130578756332397

Epoch: 289| Step: 0
Training loss: 1.8583781719207764
Validation loss: 2.1920493791500726

Epoch: 5| Step: 1
Training loss: 1.6538883447647095
Validation loss: 2.1970589260260263

Epoch: 5| Step: 2
Training loss: 1.5900390148162842
Validation loss: 2.1730168412129083

Epoch: 5| Step: 3
Training loss: 1.3517662286758423
Validation loss: 2.193437397480011

Epoch: 5| Step: 4
Training loss: 1.919132947921753
Validation loss: 2.180163045724233

Epoch: 5| Step: 5
Training loss: 2.603654384613037
Validation loss: 2.1813089549541473

Epoch: 5| Step: 6
Training loss: 1.2352116107940674
Validation loss: 2.2013359367847443

Epoch: 5| Step: 7
Training loss: 1.4563024044036865
Validation loss: 2.187912185986837

Epoch: 5| Step: 8
Training loss: 2.226285934448242
Validation loss: 2.1978614131609597

Epoch: 5| Step: 9
Training loss: 1.2586472034454346
Validation loss: 2.2251092294851937

Epoch: 5| Step: 10
Training loss: 2.0113730430603027
Validation loss: 2.205009917418162

Epoch: 5| Step: 11
Training loss: 1.5857411623001099
Validation loss: 2.2102730125188828

Epoch: 290| Step: 0
Training loss: 2.3094680309295654
Validation loss: 2.20793188114961

Epoch: 5| Step: 1
Training loss: 1.6107066869735718
Validation loss: 2.1977205077807107

Epoch: 5| Step: 2
Training loss: 1.0962251424789429
Validation loss: 2.1997538010279336

Epoch: 5| Step: 3
Training loss: 2.248077869415283
Validation loss: 2.189429427186648

Epoch: 5| Step: 4
Training loss: 1.5599335432052612
Validation loss: 2.183172345161438

Epoch: 5| Step: 5
Training loss: 1.6393241882324219
Validation loss: 2.1685347706079483

Epoch: 5| Step: 6
Training loss: 1.9308830499649048
Validation loss: 2.177680119872093

Epoch: 5| Step: 7
Training loss: 1.7630627155303955
Validation loss: 2.182633876800537

Epoch: 5| Step: 8
Training loss: 1.470171570777893
Validation loss: 2.185340722401937

Epoch: 5| Step: 9
Training loss: 1.629009485244751
Validation loss: 2.205691615740458

Epoch: 5| Step: 10
Training loss: 1.8555485010147095
Validation loss: 2.204295168320338

Epoch: 5| Step: 11
Training loss: 2.591064929962158
Validation loss: 2.2177897095680237

Epoch: 291| Step: 0
Training loss: 1.9807844161987305
Validation loss: 2.1852476547161737

Epoch: 5| Step: 1
Training loss: 1.2748943567276
Validation loss: 2.193295488754908

Epoch: 5| Step: 2
Training loss: 2.2231078147888184
Validation loss: 2.2065953463315964

Epoch: 5| Step: 3
Training loss: 1.310361385345459
Validation loss: 2.1945267220338187

Epoch: 5| Step: 4
Training loss: 2.2002272605895996
Validation loss: 2.213181510567665

Epoch: 5| Step: 5
Training loss: 2.138762950897217
Validation loss: 2.193337326248487

Epoch: 5| Step: 6
Training loss: 1.7976347208023071
Validation loss: 2.1907985707124076

Epoch: 5| Step: 7
Training loss: 1.8423211574554443
Validation loss: 2.167639752229055

Epoch: 5| Step: 8
Training loss: 1.5672868490219116
Validation loss: 2.184816559155782

Epoch: 5| Step: 9
Training loss: 2.3246734142303467
Validation loss: 2.176512842377027

Epoch: 5| Step: 10
Training loss: 1.6499176025390625
Validation loss: 2.177652736504873

Epoch: 5| Step: 11
Training loss: 0.6078516244888306
Validation loss: 2.1931571116050086

Epoch: 292| Step: 0
Training loss: 1.4863110780715942
Validation loss: 2.1759779701630273

Epoch: 5| Step: 1
Training loss: 2.5177907943725586
Validation loss: 2.164605696996053

Epoch: 5| Step: 2
Training loss: 2.0525593757629395
Validation loss: 2.188153346379598

Epoch: 5| Step: 3
Training loss: 1.7556142807006836
Validation loss: 2.1875912845134735

Epoch: 5| Step: 4
Training loss: 1.7688677310943604
Validation loss: 2.2013468643029532

Epoch: 5| Step: 5
Training loss: 1.7362658977508545
Validation loss: 2.175849571824074

Epoch: 5| Step: 6
Training loss: 1.3575553894042969
Validation loss: 2.2215041319529214

Epoch: 5| Step: 7
Training loss: 1.4686976671218872
Validation loss: 2.207057068745295

Epoch: 5| Step: 8
Training loss: 2.0973076820373535
Validation loss: 2.2100395460923514

Epoch: 5| Step: 9
Training loss: 1.7319772243499756
Validation loss: 2.1997437328100204

Epoch: 5| Step: 10
Training loss: 1.4706377983093262
Validation loss: 2.189776008327802

Epoch: 5| Step: 11
Training loss: 3.27777099609375
Validation loss: 2.184750368197759

Epoch: 293| Step: 0
Training loss: 1.382067084312439
Validation loss: 2.1896154383818307

Epoch: 5| Step: 1
Training loss: 1.9441757202148438
Validation loss: 2.1990110278129578

Epoch: 5| Step: 2
Training loss: 1.8771851062774658
Validation loss: 2.1974473794301352

Epoch: 5| Step: 3
Training loss: 1.3323482275009155
Validation loss: 2.198006754120191

Epoch: 5| Step: 4
Training loss: 1.6414117813110352
Validation loss: 2.179640601078669

Epoch: 5| Step: 5
Training loss: 1.6272741556167603
Validation loss: 2.20158089697361

Epoch: 5| Step: 6
Training loss: 2.232720136642456
Validation loss: 2.187066892782847

Epoch: 5| Step: 7
Training loss: 2.3270766735076904
Validation loss: 2.16501817603906

Epoch: 5| Step: 8
Training loss: 2.036891460418701
Validation loss: 2.161978061000506

Epoch: 5| Step: 9
Training loss: 1.999871015548706
Validation loss: 2.1613327165444693

Epoch: 5| Step: 10
Training loss: 1.1010701656341553
Validation loss: 2.1687446236610413

Epoch: 5| Step: 11
Training loss: 1.3264089822769165
Validation loss: 2.1952223678429923

Epoch: 294| Step: 0
Training loss: 1.9583152532577515
Validation loss: 2.199141507347425

Epoch: 5| Step: 1
Training loss: 1.368168592453003
Validation loss: 2.181467185417811

Epoch: 5| Step: 2
Training loss: 1.9471044540405273
Validation loss: 2.19703871011734

Epoch: 5| Step: 3
Training loss: 2.282665729522705
Validation loss: 2.1938511431217194

Epoch: 5| Step: 4
Training loss: 1.2845816612243652
Validation loss: 2.208912471930186

Epoch: 5| Step: 5
Training loss: 1.3485727310180664
Validation loss: 2.2068488697210946

Epoch: 5| Step: 6
Training loss: 1.519931435585022
Validation loss: 2.2081861098607383

Epoch: 5| Step: 7
Training loss: 1.6166267395019531
Validation loss: 2.2120842337608337

Epoch: 5| Step: 8
Training loss: 1.793981909751892
Validation loss: 2.2076216290394464

Epoch: 5| Step: 9
Training loss: 1.9145475625991821
Validation loss: 2.2085108906030655

Epoch: 5| Step: 10
Training loss: 2.1694469451904297
Validation loss: 2.227827161550522

Epoch: 5| Step: 11
Training loss: 1.8900539875030518
Validation loss: 2.2145829697450004

Epoch: 295| Step: 0
Training loss: 1.564643383026123
Validation loss: 2.214020018776258

Epoch: 5| Step: 1
Training loss: 1.933687448501587
Validation loss: 2.2431052178144455

Epoch: 5| Step: 2
Training loss: 1.5256602764129639
Validation loss: 2.2152628699938455

Epoch: 5| Step: 3
Training loss: 1.4169477224349976
Validation loss: 2.1979232827822366

Epoch: 5| Step: 4
Training loss: 2.4068808555603027
Validation loss: 2.1974179595708847

Epoch: 5| Step: 5
Training loss: 1.8782551288604736
Validation loss: 2.22130619486173

Epoch: 5| Step: 6
Training loss: 1.420647382736206
Validation loss: 2.2308233082294464

Epoch: 5| Step: 7
Training loss: 1.7388718128204346
Validation loss: 2.2089035560687384

Epoch: 5| Step: 8
Training loss: 1.7774698734283447
Validation loss: 2.2007106840610504

Epoch: 5| Step: 9
Training loss: 2.0857391357421875
Validation loss: 2.1847111731767654

Epoch: 5| Step: 10
Training loss: 1.3501474857330322
Validation loss: 2.1822118808825812

Epoch: 5| Step: 11
Training loss: 1.5000170469284058
Validation loss: 2.1869002232948938

Epoch: 296| Step: 0
Training loss: 1.8413732051849365
Validation loss: 2.1802978515625

Epoch: 5| Step: 1
Training loss: 1.4857349395751953
Validation loss: 2.1862165530522666

Epoch: 5| Step: 2
Training loss: 2.067911148071289
Validation loss: 2.193849186102549

Epoch: 5| Step: 3
Training loss: 1.6067168712615967
Validation loss: 2.194602837165197

Epoch: 5| Step: 4
Training loss: 1.5860497951507568
Validation loss: 2.225501378377279

Epoch: 5| Step: 5
Training loss: 1.3971898555755615
Validation loss: 2.2147136628627777

Epoch: 5| Step: 6
Training loss: 1.6923048496246338
Validation loss: 2.220561236143112

Epoch: 5| Step: 7
Training loss: 2.556741237640381
Validation loss: 2.1905737618605294

Epoch: 5| Step: 8
Training loss: 1.1324660778045654
Validation loss: 2.191727260748545

Epoch: 5| Step: 9
Training loss: 2.060683012008667
Validation loss: 2.2089734077453613

Epoch: 5| Step: 10
Training loss: 1.2569913864135742
Validation loss: 2.196069285273552

Epoch: 5| Step: 11
Training loss: 2.4001657962799072
Validation loss: 2.2007310887177787

Epoch: 297| Step: 0
Training loss: 1.033488392829895
Validation loss: 2.17715090016524

Epoch: 5| Step: 1
Training loss: 1.7661813497543335
Validation loss: 2.1849706222613654

Epoch: 5| Step: 2
Training loss: 1.1509119272232056
Validation loss: 2.199425294995308

Epoch: 5| Step: 3
Training loss: 2.2164502143859863
Validation loss: 2.2149530400832496

Epoch: 5| Step: 4
Training loss: 1.5770957469940186
Validation loss: 2.197565754254659

Epoch: 5| Step: 5
Training loss: 1.4320656061172485
Validation loss: 2.201254223783811

Epoch: 5| Step: 6
Training loss: 2.334951877593994
Validation loss: 2.2135974317789078

Epoch: 5| Step: 7
Training loss: 2.064539670944214
Validation loss: 2.231041669845581

Epoch: 5| Step: 8
Training loss: 1.6301714181900024
Validation loss: 2.232004165649414

Epoch: 5| Step: 9
Training loss: 1.7677593231201172
Validation loss: 2.2232867976029715

Epoch: 5| Step: 10
Training loss: 1.6337229013442993
Validation loss: 2.204022154211998

Epoch: 5| Step: 11
Training loss: 3.2639105319976807
Validation loss: 2.2256639699141183

Epoch: 298| Step: 0
Training loss: 1.7714004516601562
Validation loss: 2.208404064178467

Epoch: 5| Step: 1
Training loss: 2.4596195220947266
Validation loss: 2.2321285555760064

Epoch: 5| Step: 2
Training loss: 2.5457911491394043
Validation loss: 2.2432366212209067

Epoch: 5| Step: 3
Training loss: 2.124058723449707
Validation loss: 2.2133944084246955

Epoch: 5| Step: 4
Training loss: 1.5684266090393066
Validation loss: 2.2104328870773315

Epoch: 5| Step: 5
Training loss: 1.26363205909729
Validation loss: 2.212941825389862

Epoch: 5| Step: 6
Training loss: 1.1519763469696045
Validation loss: 2.2241076727708182

Epoch: 5| Step: 7
Training loss: 1.281896948814392
Validation loss: 2.2106913725535073

Epoch: 5| Step: 8
Training loss: 1.793539047241211
Validation loss: 2.228545834620794

Epoch: 5| Step: 9
Training loss: 1.2454761266708374
Validation loss: 2.2434348364671073

Epoch: 5| Step: 10
Training loss: 1.8910573720932007
Validation loss: 2.2285722394784293

Epoch: 5| Step: 11
Training loss: 0.765828549861908
Validation loss: 2.204316020011902

Epoch: 299| Step: 0
Training loss: 1.7308170795440674
Validation loss: 2.197181781133016

Epoch: 5| Step: 1
Training loss: 1.471008539199829
Validation loss: 2.160833408435186

Epoch: 5| Step: 2
Training loss: 1.8680700063705444
Validation loss: 2.181971232096354

Epoch: 5| Step: 3
Training loss: 1.5357309579849243
Validation loss: 2.1835932036240897

Epoch: 5| Step: 4
Training loss: 1.9162986278533936
Validation loss: 2.1851191421349845

Epoch: 5| Step: 5
Training loss: 2.1062769889831543
Validation loss: 2.1903353383143744

Epoch: 5| Step: 6
Training loss: 1.8022003173828125
Validation loss: 2.2076383282740912

Epoch: 5| Step: 7
Training loss: 1.3176038265228271
Validation loss: 2.2015168269475303

Epoch: 5| Step: 8
Training loss: 1.4411436319351196
Validation loss: 2.2289920250574746

Epoch: 5| Step: 9
Training loss: 1.5595320463180542
Validation loss: 2.253787020842234

Epoch: 5| Step: 10
Training loss: 2.459176778793335
Validation loss: 2.2268815338611603

Epoch: 5| Step: 11
Training loss: 1.0324623584747314
Validation loss: 2.237708325187365

Epoch: 300| Step: 0
Training loss: 1.7604520320892334
Validation loss: 2.2643976310888925

Epoch: 5| Step: 1
Training loss: 1.5380408763885498
Validation loss: 2.2273242076238

Epoch: 5| Step: 2
Training loss: 1.5586612224578857
Validation loss: 2.268366739153862

Epoch: 5| Step: 3
Training loss: 2.3318731784820557
Validation loss: 2.2521792153517404

Epoch: 5| Step: 4
Training loss: 1.5949904918670654
Validation loss: 2.2439424792925515

Epoch: 5| Step: 5
Training loss: 1.9954535961151123
Validation loss: 2.231959437330564

Epoch: 5| Step: 6
Training loss: 1.6986128091812134
Validation loss: 2.2436318149169288

Epoch: 5| Step: 7
Training loss: 1.5702661275863647
Validation loss: 2.218764454126358

Epoch: 5| Step: 8
Training loss: 1.9895340204238892
Validation loss: 2.186350171764692

Epoch: 5| Step: 9
Training loss: 1.4127119779586792
Validation loss: 2.194123109181722

Epoch: 5| Step: 10
Training loss: 1.0812621116638184
Validation loss: 2.2021442155043283

Epoch: 5| Step: 11
Training loss: 2.5585451126098633
Validation loss: 2.1912201941013336

Epoch: 301| Step: 0
Training loss: 1.5702133178710938
Validation loss: 2.1730926632881165

Epoch: 5| Step: 1
Training loss: 1.2176973819732666
Validation loss: 2.181718279918035

Epoch: 5| Step: 2
Training loss: 1.9577436447143555
Validation loss: 2.1856101800998053

Epoch: 5| Step: 3
Training loss: 1.87911856174469
Validation loss: 2.179704229036967

Epoch: 5| Step: 4
Training loss: 1.42740797996521
Validation loss: 2.1727638244628906

Epoch: 5| Step: 5
Training loss: 1.8953425884246826
Validation loss: 2.167527496814728

Epoch: 5| Step: 6
Training loss: 1.58805251121521
Validation loss: 2.1769728561242423

Epoch: 5| Step: 7
Training loss: 1.631155014038086
Validation loss: 2.16595695912838

Epoch: 5| Step: 8
Training loss: 2.299595355987549
Validation loss: 2.190591702858607

Epoch: 5| Step: 9
Training loss: 1.8307431936264038
Validation loss: 2.1929711749156318

Epoch: 5| Step: 10
Training loss: 2.1479854583740234
Validation loss: 2.1731642136971154

Epoch: 5| Step: 11
Training loss: 1.2745733261108398
Validation loss: 2.1720322569211326

Epoch: 302| Step: 0
Training loss: 1.5661424398422241
Validation loss: 2.148868868748347

Epoch: 5| Step: 1
Training loss: 1.8467204570770264
Validation loss: 2.1654210885365806

Epoch: 5| Step: 2
Training loss: 2.150338649749756
Validation loss: 2.151635999480883

Epoch: 5| Step: 3
Training loss: 1.5745052099227905
Validation loss: 2.1452732533216476

Epoch: 5| Step: 4
Training loss: 2.3482391834259033
Validation loss: 2.1526957799990973

Epoch: 5| Step: 5
Training loss: 1.8083194494247437
Validation loss: 2.1452981531620026

Epoch: 5| Step: 6
Training loss: 1.8353312015533447
Validation loss: 2.1671940684318542

Epoch: 5| Step: 7
Training loss: 1.2974450588226318
Validation loss: 2.1518642753362656

Epoch: 5| Step: 8
Training loss: 1.9736950397491455
Validation loss: 2.189252624909083

Epoch: 5| Step: 9
Training loss: 1.9338260889053345
Validation loss: 2.1862516005833945

Epoch: 5| Step: 10
Training loss: 1.7070369720458984
Validation loss: 2.168423131108284

Epoch: 5| Step: 11
Training loss: 0.6327279806137085
Validation loss: 2.177085801959038

Epoch: 303| Step: 0
Training loss: 1.839944839477539
Validation loss: 2.175175209840139

Epoch: 5| Step: 1
Training loss: 1.684563398361206
Validation loss: 2.1743004421393075

Epoch: 5| Step: 2
Training loss: 1.7244539260864258
Validation loss: 2.17020653684934

Epoch: 5| Step: 3
Training loss: 1.9690462350845337
Validation loss: 2.18049563964208

Epoch: 5| Step: 4
Training loss: 1.7165870666503906
Validation loss: 2.157399366299311

Epoch: 5| Step: 5
Training loss: 1.8872352838516235
Validation loss: 2.1759284883737564

Epoch: 5| Step: 6
Training loss: 1.943240761756897
Validation loss: 2.1821384926637015

Epoch: 5| Step: 7
Training loss: 1.7016751766204834
Validation loss: 2.1773444612820945

Epoch: 5| Step: 8
Training loss: 1.481215238571167
Validation loss: 2.174460291862488

Epoch: 5| Step: 9
Training loss: 1.5506664514541626
Validation loss: 2.160324146350225

Epoch: 5| Step: 10
Training loss: 1.8071930408477783
Validation loss: 2.165549327929815

Epoch: 5| Step: 11
Training loss: 1.236166000366211
Validation loss: 2.175583134094874

Epoch: 304| Step: 0
Training loss: 1.6385257244110107
Validation loss: 2.178870235880216

Epoch: 5| Step: 1
Training loss: 1.812085509300232
Validation loss: 2.1715134431918464

Epoch: 5| Step: 2
Training loss: 1.856286644935608
Validation loss: 2.1690517514944077

Epoch: 5| Step: 3
Training loss: 1.645939826965332
Validation loss: 2.1445235361655555

Epoch: 5| Step: 4
Training loss: 1.7721521854400635
Validation loss: 2.178167844812075

Epoch: 5| Step: 5
Training loss: 1.834892988204956
Validation loss: 2.14501483241717

Epoch: 5| Step: 6
Training loss: 1.7102031707763672
Validation loss: 2.1559438705444336

Epoch: 5| Step: 7
Training loss: 2.1150996685028076
Validation loss: 2.1578084031740823

Epoch: 5| Step: 8
Training loss: 1.6276785135269165
Validation loss: 2.1687932958205542

Epoch: 5| Step: 9
Training loss: 1.4273111820220947
Validation loss: 2.164894317587217

Epoch: 5| Step: 10
Training loss: 1.5021028518676758
Validation loss: 2.1557597617308297

Epoch: 5| Step: 11
Training loss: 2.4510746002197266
Validation loss: 2.146329407890638

Epoch: 305| Step: 0
Training loss: 2.1808013916015625
Validation loss: 2.1667006562153497

Epoch: 5| Step: 1
Training loss: 1.4253381490707397
Validation loss: 2.1723334193229675

Epoch: 5| Step: 2
Training loss: 1.6164791584014893
Validation loss: 2.16948202252388

Epoch: 5| Step: 3
Training loss: 1.892786979675293
Validation loss: 2.1950936764478683

Epoch: 5| Step: 4
Training loss: 2.2711288928985596
Validation loss: 2.1846232612927756

Epoch: 5| Step: 5
Training loss: 1.860439658164978
Validation loss: 2.1673966149489083

Epoch: 5| Step: 6
Training loss: 2.294017791748047
Validation loss: 2.170222188035647

Epoch: 5| Step: 7
Training loss: 1.370464563369751
Validation loss: 2.192110687494278

Epoch: 5| Step: 8
Training loss: 1.8618981838226318
Validation loss: 2.1867354661226273

Epoch: 5| Step: 9
Training loss: 1.1918379068374634
Validation loss: 2.1809887886047363

Epoch: 5| Step: 10
Training loss: 1.440152883529663
Validation loss: 2.161568522453308

Epoch: 5| Step: 11
Training loss: 0.9680483341217041
Validation loss: 2.1955700318018594

Epoch: 306| Step: 0
Training loss: 1.2196197509765625
Validation loss: 2.1956472297509513

Epoch: 5| Step: 1
Training loss: 1.769083023071289
Validation loss: 2.212535281976064

Epoch: 5| Step: 2
Training loss: 1.5661804676055908
Validation loss: 2.2116659283638

Epoch: 5| Step: 3
Training loss: 2.0681746006011963
Validation loss: 2.204544593890508

Epoch: 5| Step: 4
Training loss: 2.231386184692383
Validation loss: 2.2127144038677216

Epoch: 5| Step: 5
Training loss: 1.6251789331436157
Validation loss: 2.199072872598966

Epoch: 5| Step: 6
Training loss: 1.415368676185608
Validation loss: 2.1981192280848822

Epoch: 5| Step: 7
Training loss: 1.7156803607940674
Validation loss: 2.204649865627289

Epoch: 5| Step: 8
Training loss: 1.5566707849502563
Validation loss: 2.193618029356003

Epoch: 5| Step: 9
Training loss: 1.9017127752304077
Validation loss: 2.224445194005966

Epoch: 5| Step: 10
Training loss: 1.8340237140655518
Validation loss: 2.1975123286247253

Epoch: 5| Step: 11
Training loss: 1.5472121238708496
Validation loss: 2.2022342880566916

Epoch: 307| Step: 0
Training loss: 1.2145657539367676
Validation loss: 2.216031953692436

Epoch: 5| Step: 1
Training loss: 1.510231852531433
Validation loss: 2.209332952896754

Epoch: 5| Step: 2
Training loss: 2.685482978820801
Validation loss: 2.191014349460602

Epoch: 5| Step: 3
Training loss: 1.889161467552185
Validation loss: 2.2004302193721137

Epoch: 5| Step: 4
Training loss: 1.407570481300354
Validation loss: 2.1754509707291922

Epoch: 5| Step: 5
Training loss: 2.103644847869873
Validation loss: 2.2075327932834625

Epoch: 5| Step: 6
Training loss: 1.6364682912826538
Validation loss: 2.1898892919222512

Epoch: 5| Step: 7
Training loss: 1.553572416305542
Validation loss: 2.1705683867136636

Epoch: 5| Step: 8
Training loss: 1.780601143836975
Validation loss: 2.1990179121494293

Epoch: 5| Step: 9
Training loss: 1.5680938959121704
Validation loss: 2.193216025829315

Epoch: 5| Step: 10
Training loss: 1.2546465396881104
Validation loss: 2.22296009461085

Epoch: 5| Step: 11
Training loss: 2.4631457328796387
Validation loss: 2.187590385476748

Epoch: 308| Step: 0
Training loss: 1.602842926979065
Validation loss: 2.224520350495974

Epoch: 5| Step: 1
Training loss: 2.228687047958374
Validation loss: 2.208950231472651

Epoch: 5| Step: 2
Training loss: 2.1665308475494385
Validation loss: 2.2094262888034186

Epoch: 5| Step: 3
Training loss: 1.7624053955078125
Validation loss: 2.196742753187815

Epoch: 5| Step: 4
Training loss: 1.8399730920791626
Validation loss: 2.229290987054507

Epoch: 5| Step: 5
Training loss: 1.9982866048812866
Validation loss: 2.2136672735214233

Epoch: 5| Step: 6
Training loss: 1.4979679584503174
Validation loss: 2.2373623847961426

Epoch: 5| Step: 7
Training loss: 1.6522296667099
Validation loss: 2.225427269935608

Epoch: 5| Step: 8
Training loss: 1.029028296470642
Validation loss: 2.207267999649048

Epoch: 5| Step: 9
Training loss: 1.7353112697601318
Validation loss: 2.200092057387034

Epoch: 5| Step: 10
Training loss: 1.6394670009613037
Validation loss: 2.2095399697621665

Epoch: 5| Step: 11
Training loss: 2.5972728729248047
Validation loss: 2.1998377243677774

Epoch: 309| Step: 0
Training loss: 2.5443973541259766
Validation loss: 2.201347420612971

Epoch: 5| Step: 1
Training loss: 1.8819319009780884
Validation loss: 2.179906964302063

Epoch: 5| Step: 2
Training loss: 2.0913033485412598
Validation loss: 2.1938912173112235

Epoch: 5| Step: 3
Training loss: 1.4598047733306885
Validation loss: 2.1938391824563346

Epoch: 5| Step: 4
Training loss: 1.3011655807495117
Validation loss: 2.2036704818407693

Epoch: 5| Step: 5
Training loss: 1.779345154762268
Validation loss: 2.1998138229052224

Epoch: 5| Step: 6
Training loss: 1.9013187885284424
Validation loss: 2.201302091280619

Epoch: 5| Step: 7
Training loss: 1.7700140476226807
Validation loss: 2.2098143895467124

Epoch: 5| Step: 8
Training loss: 0.6356745958328247
Validation loss: 2.187888244787852

Epoch: 5| Step: 9
Training loss: 1.6525205373764038
Validation loss: 2.2099941869576774

Epoch: 5| Step: 10
Training loss: 1.9555221796035767
Validation loss: 2.1762049247821174

Epoch: 5| Step: 11
Training loss: 0.8936887979507446
Validation loss: 2.175658365090688

Epoch: 310| Step: 0
Training loss: 1.9126014709472656
Validation loss: 2.184364398320516

Epoch: 5| Step: 1
Training loss: 1.8585054874420166
Validation loss: 2.175226107239723

Epoch: 5| Step: 2
Training loss: 1.0911095142364502
Validation loss: 2.1711439043283463

Epoch: 5| Step: 3
Training loss: 1.9099225997924805
Validation loss: 2.177814871072769

Epoch: 5| Step: 4
Training loss: 1.857729196548462
Validation loss: 2.1825564752022424

Epoch: 5| Step: 5
Training loss: 1.9985986948013306
Validation loss: 2.189368595679601

Epoch: 5| Step: 6
Training loss: 1.605908989906311
Validation loss: 2.1951218942801156

Epoch: 5| Step: 7
Training loss: 1.2196812629699707
Validation loss: 2.2001321812470755

Epoch: 5| Step: 8
Training loss: 1.7614972591400146
Validation loss: 2.210484286149343

Epoch: 5| Step: 9
Training loss: 1.349601149559021
Validation loss: 2.1935014526049295

Epoch: 5| Step: 10
Training loss: 2.0519938468933105
Validation loss: 2.2003468026717505

Epoch: 5| Step: 11
Training loss: 1.4009500741958618
Validation loss: 2.170889059702555

Epoch: 311| Step: 0
Training loss: 1.9349151849746704
Validation loss: 2.2053251564502716

Epoch: 5| Step: 1
Training loss: 1.6314903497695923
Validation loss: 2.1931626399358115

Epoch: 5| Step: 2
Training loss: 1.4322304725646973
Validation loss: 2.194728965560595

Epoch: 5| Step: 3
Training loss: 1.7267268896102905
Validation loss: 2.189010724425316

Epoch: 5| Step: 4
Training loss: 2.044257879257202
Validation loss: 2.1957474648952484

Epoch: 5| Step: 5
Training loss: 1.124725341796875
Validation loss: 2.2248492191235223

Epoch: 5| Step: 6
Training loss: 1.6527836322784424
Validation loss: 2.2203904589017234

Epoch: 5| Step: 7
Training loss: 2.0411441326141357
Validation loss: 2.216756825645765

Epoch: 5| Step: 8
Training loss: 1.5709730386734009
Validation loss: 2.208437164624532

Epoch: 5| Step: 9
Training loss: 1.6157341003417969
Validation loss: 2.19536325832208

Epoch: 5| Step: 10
Training loss: 1.4886071681976318
Validation loss: 2.2038494646549225

Epoch: 5| Step: 11
Training loss: 3.1386499404907227
Validation loss: 2.202067861954371

Epoch: 312| Step: 0
Training loss: 1.966112494468689
Validation loss: 2.1954352209965386

Epoch: 5| Step: 1
Training loss: 1.3465827703475952
Validation loss: 2.2094901899496713

Epoch: 5| Step: 2
Training loss: 1.4588253498077393
Validation loss: 2.2089646806319556

Epoch: 5| Step: 3
Training loss: 2.1124305725097656
Validation loss: 2.203639969229698

Epoch: 5| Step: 4
Training loss: 2.208918333053589
Validation loss: 2.2086267173290253

Epoch: 5| Step: 5
Training loss: 1.6384351253509521
Validation loss: 2.2104656994342804

Epoch: 5| Step: 6
Training loss: 1.1718350648880005
Validation loss: 2.2117057542006173

Epoch: 5| Step: 7
Training loss: 1.5586611032485962
Validation loss: 2.2085164239009223

Epoch: 5| Step: 8
Training loss: 1.3434398174285889
Validation loss: 2.222479855020841

Epoch: 5| Step: 9
Training loss: 1.7099838256835938
Validation loss: 2.217491790652275

Epoch: 5| Step: 10
Training loss: 1.6480419635772705
Validation loss: 2.2414482831954956

Epoch: 5| Step: 11
Training loss: 2.269666910171509
Validation loss: 2.2261003057161965

Epoch: 313| Step: 0
Training loss: 1.3429089784622192
Validation loss: 2.2331721484661102

Epoch: 5| Step: 1
Training loss: 1.8449558019638062
Validation loss: 2.2123386561870575

Epoch: 5| Step: 2
Training loss: 1.3203853368759155
Validation loss: 2.195310100913048

Epoch: 5| Step: 3
Training loss: 1.587005853652954
Validation loss: 2.2111175060272217

Epoch: 5| Step: 4
Training loss: 2.050139904022217
Validation loss: 2.2020430167516074

Epoch: 5| Step: 5
Training loss: 1.7299325466156006
Validation loss: 2.1840457121531167

Epoch: 5| Step: 6
Training loss: 2.1996352672576904
Validation loss: 2.2174858997265496

Epoch: 5| Step: 7
Training loss: 1.4903414249420166
Validation loss: 2.211533476909002

Epoch: 5| Step: 8
Training loss: 1.6556648015975952
Validation loss: 2.2238266319036484

Epoch: 5| Step: 9
Training loss: 2.022686243057251
Validation loss: 2.228760540485382

Epoch: 5| Step: 10
Training loss: 1.517358422279358
Validation loss: 2.2180239011844

Epoch: 5| Step: 11
Training loss: 0.5053443908691406
Validation loss: 2.236005758245786

Epoch: 314| Step: 0
Training loss: 2.645707130432129
Validation loss: 2.2352826495965323

Epoch: 5| Step: 1
Training loss: 1.8908312320709229
Validation loss: 2.229133447011312

Epoch: 5| Step: 2
Training loss: 1.3716771602630615
Validation loss: 2.241770232717196

Epoch: 5| Step: 3
Training loss: 1.9051673412322998
Validation loss: 2.22678005695343

Epoch: 5| Step: 4
Training loss: 1.6422693729400635
Validation loss: 2.227421601613363

Epoch: 5| Step: 5
Training loss: 1.3159862756729126
Validation loss: 2.218849167227745

Epoch: 5| Step: 6
Training loss: 1.6081912517547607
Validation loss: 2.2157647013664246

Epoch: 5| Step: 7
Training loss: 1.7386362552642822
Validation loss: 2.2357261131207147

Epoch: 5| Step: 8
Training loss: 2.064728260040283
Validation loss: 2.224351073304812

Epoch: 5| Step: 9
Training loss: 1.4012480974197388
Validation loss: 2.2169145047664642

Epoch: 5| Step: 10
Training loss: 1.3856011629104614
Validation loss: 2.2043123046557107

Epoch: 5| Step: 11
Training loss: 1.2863023281097412
Validation loss: 2.204580068588257

Epoch: 315| Step: 0
Training loss: 1.3675496578216553
Validation loss: 2.2000316977500916

Epoch: 5| Step: 1
Training loss: 1.9873052835464478
Validation loss: 2.1985894491275153

Epoch: 5| Step: 2
Training loss: 1.9612821340560913
Validation loss: 2.202347015341123

Epoch: 5| Step: 3
Training loss: 1.9548742771148682
Validation loss: 2.19191179672877

Epoch: 5| Step: 4
Training loss: 1.4503872394561768
Validation loss: 2.167715221643448

Epoch: 5| Step: 5
Training loss: 2.177870988845825
Validation loss: 2.1806896726290383

Epoch: 5| Step: 6
Training loss: 1.7024714946746826
Validation loss: 2.1849274138609567

Epoch: 5| Step: 7
Training loss: 1.6276493072509766
Validation loss: 2.169186825553576

Epoch: 5| Step: 8
Training loss: 1.2666723728179932
Validation loss: 2.1926735738913217

Epoch: 5| Step: 9
Training loss: 2.2002227306365967
Validation loss: 2.184533476829529

Epoch: 5| Step: 10
Training loss: 2.1356518268585205
Validation loss: 2.196492552757263

Epoch: 5| Step: 11
Training loss: 1.1282949447631836
Validation loss: 2.1710958729187646

Epoch: 316| Step: 0
Training loss: 1.977482557296753
Validation loss: 2.1677234768867493

Epoch: 5| Step: 1
Training loss: 1.4930312633514404
Validation loss: 2.175966794292132

Epoch: 5| Step: 2
Training loss: 1.319110631942749
Validation loss: 2.149183049798012

Epoch: 5| Step: 3
Training loss: 1.3528777360916138
Validation loss: 2.124863157669703

Epoch: 5| Step: 4
Training loss: 1.7320196628570557
Validation loss: 2.1688038210074105

Epoch: 5| Step: 5
Training loss: 1.5014097690582275
Validation loss: 2.15606855849425

Epoch: 5| Step: 6
Training loss: 1.3851501941680908
Validation loss: 2.1503134916226068

Epoch: 5| Step: 7
Training loss: 2.459681749343872
Validation loss: 2.1528670539458594

Epoch: 5| Step: 8
Training loss: 1.5875407457351685
Validation loss: 2.1820388634999595

Epoch: 5| Step: 9
Training loss: 2.444852113723755
Validation loss: 2.1883533696333566

Epoch: 5| Step: 10
Training loss: 1.9270061254501343
Validation loss: 2.184586743513743

Epoch: 5| Step: 11
Training loss: 1.9187185764312744
Validation loss: 2.173290029168129

Epoch: 317| Step: 0
Training loss: 1.5937614440917969
Validation loss: 2.1860766212145486

Epoch: 5| Step: 1
Training loss: 1.4754276275634766
Validation loss: 2.1643575032552085

Epoch: 5| Step: 2
Training loss: 1.660529375076294
Validation loss: 2.174603228767713

Epoch: 5| Step: 3
Training loss: 1.3874943256378174
Validation loss: 2.157488336165746

Epoch: 5| Step: 4
Training loss: 1.7928316593170166
Validation loss: 2.1790898789962134

Epoch: 5| Step: 5
Training loss: 1.5871578454971313
Validation loss: 2.156389777859052

Epoch: 5| Step: 6
Training loss: 1.441225290298462
Validation loss: 2.1705327133337655

Epoch: 5| Step: 7
Training loss: 2.0598254203796387
Validation loss: 2.1578296770652137

Epoch: 5| Step: 8
Training loss: 1.8493255376815796
Validation loss: 2.147834117213885

Epoch: 5| Step: 9
Training loss: 1.5698047876358032
Validation loss: 2.1728133906920752

Epoch: 5| Step: 10
Training loss: 2.075448989868164
Validation loss: 2.1531250278155007

Epoch: 5| Step: 11
Training loss: 1.9728856086730957
Validation loss: 2.1783790290355682

Epoch: 318| Step: 0
Training loss: 1.5166603326797485
Validation loss: 2.1934171418348947

Epoch: 5| Step: 1
Training loss: 1.2620294094085693
Validation loss: 2.1882897367080054

Epoch: 5| Step: 2
Training loss: 2.1152849197387695
Validation loss: 2.198201914628347

Epoch: 5| Step: 3
Training loss: 1.5612494945526123
Validation loss: 2.210360904534658

Epoch: 5| Step: 4
Training loss: 1.4225302934646606
Validation loss: 2.2363027930259705

Epoch: 5| Step: 5
Training loss: 2.5528359413146973
Validation loss: 2.2002518574396768

Epoch: 5| Step: 6
Training loss: 1.363452672958374
Validation loss: 2.216240555047989

Epoch: 5| Step: 7
Training loss: 2.0654399394989014
Validation loss: 2.205282539129257

Epoch: 5| Step: 8
Training loss: 1.8517639636993408
Validation loss: 2.2074381609757743

Epoch: 5| Step: 9
Training loss: 1.1935369968414307
Validation loss: 2.2024628867705665

Epoch: 5| Step: 10
Training loss: 1.4123934507369995
Validation loss: 2.208900421857834

Epoch: 5| Step: 11
Training loss: 2.7214250564575195
Validation loss: 2.194401264190674

Epoch: 319| Step: 0
Training loss: 1.4301846027374268
Validation loss: 2.178728833794594

Epoch: 5| Step: 1
Training loss: 2.655940294265747
Validation loss: 2.188580254713694

Epoch: 5| Step: 2
Training loss: 1.8504587411880493
Validation loss: 2.193825582663218

Epoch: 5| Step: 3
Training loss: 1.8240184783935547
Validation loss: 2.1662894984086356

Epoch: 5| Step: 4
Training loss: 1.7891321182250977
Validation loss: 2.158423284689585

Epoch: 5| Step: 5
Training loss: 1.4821197986602783
Validation loss: 2.146639501055082

Epoch: 5| Step: 6
Training loss: 2.2988193035125732
Validation loss: 2.172697901725769

Epoch: 5| Step: 7
Training loss: 1.4703956842422485
Validation loss: 2.1861799210309982

Epoch: 5| Step: 8
Training loss: 1.2185834646224976
Validation loss: 2.160194749633471

Epoch: 5| Step: 9
Training loss: 1.1337559223175049
Validation loss: 2.169520457585653

Epoch: 5| Step: 10
Training loss: 1.2497676610946655
Validation loss: 2.1793404519557953

Epoch: 5| Step: 11
Training loss: 0.5432730913162231
Validation loss: 2.1710496296485267

Epoch: 320| Step: 0
Training loss: 1.6628551483154297
Validation loss: 2.183191845814387

Epoch: 5| Step: 1
Training loss: 1.2948795557022095
Validation loss: 2.179668446381887

Epoch: 5| Step: 2
Training loss: 1.9962955713272095
Validation loss: 2.150441661477089

Epoch: 5| Step: 3
Training loss: 1.6271568536758423
Validation loss: 2.16859998802344

Epoch: 5| Step: 4
Training loss: 2.1782383918762207
Validation loss: 2.1780511339505515

Epoch: 5| Step: 5
Training loss: 1.7604401111602783
Validation loss: 2.1607073793808618

Epoch: 5| Step: 6
Training loss: 1.364892840385437
Validation loss: 2.1807892670234046

Epoch: 5| Step: 7
Training loss: 1.791961669921875
Validation loss: 2.176647424697876

Epoch: 5| Step: 8
Training loss: 1.9001514911651611
Validation loss: 2.1581607361634574

Epoch: 5| Step: 9
Training loss: 1.5414834022521973
Validation loss: 2.186387449502945

Epoch: 5| Step: 10
Training loss: 2.1858761310577393
Validation loss: 2.150892809033394

Epoch: 5| Step: 11
Training loss: 2.0285274982452393
Validation loss: 2.1652249793211618

Epoch: 321| Step: 0
Training loss: 2.5678610801696777
Validation loss: 2.1654023875792823

Epoch: 5| Step: 1
Training loss: 1.713017225265503
Validation loss: 2.162127763032913

Epoch: 5| Step: 2
Training loss: 1.299330711364746
Validation loss: 2.160087764263153

Epoch: 5| Step: 3
Training loss: 1.9513251781463623
Validation loss: 2.1436843623717627

Epoch: 5| Step: 4
Training loss: 1.7448136806488037
Validation loss: 2.1548843532800674

Epoch: 5| Step: 5
Training loss: 1.89202082157135
Validation loss: 2.1622144083182016

Epoch: 5| Step: 6
Training loss: 1.415223240852356
Validation loss: 2.1453426529963813

Epoch: 5| Step: 7
Training loss: 1.628607988357544
Validation loss: 2.1580157975355783

Epoch: 5| Step: 8
Training loss: 1.5194631814956665
Validation loss: 2.1462669322888055

Epoch: 5| Step: 9
Training loss: 0.8374643325805664
Validation loss: 2.149544124801954

Epoch: 5| Step: 10
Training loss: 1.8025867938995361
Validation loss: 2.1634363929430642

Epoch: 5| Step: 11
Training loss: 1.0343689918518066
Validation loss: 2.1686188181241355

Epoch: 322| Step: 0
Training loss: 1.441489815711975
Validation loss: 2.1817683577537537

Epoch: 5| Step: 1
Training loss: 1.946979284286499
Validation loss: 2.192944829662641

Epoch: 5| Step: 2
Training loss: 1.4659396409988403
Validation loss: 2.1839776933193207

Epoch: 5| Step: 3
Training loss: 1.616978645324707
Validation loss: 2.192078933119774

Epoch: 5| Step: 4
Training loss: 1.642319917678833
Validation loss: 2.1892176270484924

Epoch: 5| Step: 5
Training loss: 1.6236200332641602
Validation loss: 2.1800890366236367

Epoch: 5| Step: 6
Training loss: 1.7486231327056885
Validation loss: 2.1916837195555368

Epoch: 5| Step: 7
Training loss: 1.860142469406128
Validation loss: 2.1925015995899835

Epoch: 5| Step: 8
Training loss: 1.3322327136993408
Validation loss: 2.1744963228702545

Epoch: 5| Step: 9
Training loss: 1.3990037441253662
Validation loss: 2.189102997382482

Epoch: 5| Step: 10
Training loss: 1.8330215215682983
Validation loss: 2.195671498775482

Epoch: 5| Step: 11
Training loss: 1.4921319484710693
Validation loss: 2.1933511147896447

Epoch: 323| Step: 0
Training loss: 1.5178847312927246
Validation loss: 2.1784560630718866

Epoch: 5| Step: 1
Training loss: 2.0929856300354004
Validation loss: 2.165913090109825

Epoch: 5| Step: 2
Training loss: 2.4036316871643066
Validation loss: 2.1648768186569214

Epoch: 5| Step: 3
Training loss: 1.3679521083831787
Validation loss: 2.194501260916392

Epoch: 5| Step: 4
Training loss: 1.7579224109649658
Validation loss: 2.199666221936544

Epoch: 5| Step: 5
Training loss: 1.7890262603759766
Validation loss: 2.189647605021795

Epoch: 5| Step: 6
Training loss: 1.0203137397766113
Validation loss: 2.1966016789277396

Epoch: 5| Step: 7
Training loss: 1.886352777481079
Validation loss: 2.1986424972613654

Epoch: 5| Step: 8
Training loss: 1.288089632987976
Validation loss: 2.201697200536728

Epoch: 5| Step: 9
Training loss: 1.702008605003357
Validation loss: 2.189742068449656

Epoch: 5| Step: 10
Training loss: 1.5558964014053345
Validation loss: 2.2117897470792136

Epoch: 5| Step: 11
Training loss: 1.2208378314971924
Validation loss: 2.210879147052765

Epoch: 324| Step: 0
Training loss: 1.5582678318023682
Validation loss: 2.2038182814915976

Epoch: 5| Step: 1
Training loss: 1.6113113164901733
Validation loss: 2.2021626234054565

Epoch: 5| Step: 2
Training loss: 1.7707128524780273
Validation loss: 2.226131563385328

Epoch: 5| Step: 3
Training loss: 1.8227916955947876
Validation loss: 2.1958530048529306

Epoch: 5| Step: 4
Training loss: 1.7584943771362305
Validation loss: 2.20630736152331

Epoch: 5| Step: 5
Training loss: 1.84413743019104
Validation loss: 2.206093341112137

Epoch: 5| Step: 6
Training loss: 1.8156687021255493
Validation loss: 2.221722051501274

Epoch: 5| Step: 7
Training loss: 1.4257346391677856
Validation loss: 2.210185463229815

Epoch: 5| Step: 8
Training loss: 1.0035927295684814
Validation loss: 2.212052643299103

Epoch: 5| Step: 9
Training loss: 1.6328089237213135
Validation loss: 2.2037555277347565

Epoch: 5| Step: 10
Training loss: 1.5838876962661743
Validation loss: 2.207410047451655

Epoch: 5| Step: 11
Training loss: 2.146038055419922
Validation loss: 2.2077546616395316

Epoch: 325| Step: 0
Training loss: 1.248703956604004
Validation loss: 2.192504405975342

Epoch: 5| Step: 1
Training loss: 1.7631425857543945
Validation loss: 2.2219666987657547

Epoch: 5| Step: 2
Training loss: 1.049092173576355
Validation loss: 2.196926991144816

Epoch: 5| Step: 3
Training loss: 2.034592390060425
Validation loss: 2.2222339461247125

Epoch: 5| Step: 4
Training loss: 0.9244390726089478
Validation loss: 2.2035737484693527

Epoch: 5| Step: 5
Training loss: 1.908169150352478
Validation loss: 2.21600308517615

Epoch: 5| Step: 6
Training loss: 1.4940783977508545
Validation loss: 2.2217130412658057

Epoch: 5| Step: 7
Training loss: 2.3942322731018066
Validation loss: 2.214830696582794

Epoch: 5| Step: 8
Training loss: 1.2938346862792969
Validation loss: 2.2133392691612244

Epoch: 5| Step: 9
Training loss: 1.3394464254379272
Validation loss: 2.207688793540001

Epoch: 5| Step: 10
Training loss: 2.0793190002441406
Validation loss: 2.227987731496493

Epoch: 5| Step: 11
Training loss: 2.952880620956421
Validation loss: 2.199181834856669

Epoch: 326| Step: 0
Training loss: 1.9666191339492798
Validation loss: 2.193527802824974

Epoch: 5| Step: 1
Training loss: 1.0632734298706055
Validation loss: 2.1965965976317725

Epoch: 5| Step: 2
Training loss: 1.7465698719024658
Validation loss: 2.1838656763235726

Epoch: 5| Step: 3
Training loss: 1.5504646301269531
Validation loss: 2.190331051747004

Epoch: 5| Step: 4
Training loss: 1.4122755527496338
Validation loss: 2.174778218070666

Epoch: 5| Step: 5
Training loss: 0.9005281329154968
Validation loss: 2.202870105703672

Epoch: 5| Step: 6
Training loss: 2.088292360305786
Validation loss: 2.216056456168493

Epoch: 5| Step: 7
Training loss: 1.787933111190796
Validation loss: 2.2074070622523627

Epoch: 5| Step: 8
Training loss: 2.083775043487549
Validation loss: 2.20100628832976

Epoch: 5| Step: 9
Training loss: 1.981416940689087
Validation loss: 2.2156072755654654

Epoch: 5| Step: 10
Training loss: 1.1287686824798584
Validation loss: 2.2358901351690292

Epoch: 5| Step: 11
Training loss: 0.6575685143470764
Validation loss: 2.2244018961985907

Epoch: 327| Step: 0
Training loss: 1.5224194526672363
Validation loss: 2.2466467171907425

Epoch: 5| Step: 1
Training loss: 1.9142110347747803
Validation loss: 2.2240718652804694

Epoch: 5| Step: 2
Training loss: 1.761728048324585
Validation loss: 2.207880660891533

Epoch: 5| Step: 3
Training loss: 3.3250155448913574
Validation loss: 2.2294348378976188

Epoch: 5| Step: 4
Training loss: 1.315887689590454
Validation loss: 2.22152974208196

Epoch: 5| Step: 5
Training loss: 1.3626320362091064
Validation loss: 2.24929149945577

Epoch: 5| Step: 6
Training loss: 1.3301031589508057
Validation loss: 2.238005742430687

Epoch: 5| Step: 7
Training loss: 1.1950170993804932
Validation loss: 2.219729204972585

Epoch: 5| Step: 8
Training loss: 1.1221822500228882
Validation loss: 2.2425973415374756

Epoch: 5| Step: 9
Training loss: 1.4643089771270752
Validation loss: 2.2101181695858636

Epoch: 5| Step: 10
Training loss: 1.3893948793411255
Validation loss: 2.259662096699079

Epoch: 5| Step: 11
Training loss: 1.5694944858551025
Validation loss: 2.2344645112752914

Epoch: 328| Step: 0
Training loss: 1.9697765111923218
Validation loss: 2.262537106871605

Epoch: 5| Step: 1
Training loss: 1.6725122928619385
Validation loss: 2.204399605592092

Epoch: 5| Step: 2
Training loss: 1.1362513303756714
Validation loss: 2.253023008505503

Epoch: 5| Step: 3
Training loss: 2.083944797515869
Validation loss: 2.232775628566742

Epoch: 5| Step: 4
Training loss: 1.3168716430664062
Validation loss: 2.212732414404551

Epoch: 5| Step: 5
Training loss: 1.7507177591323853
Validation loss: 2.242846667766571

Epoch: 5| Step: 6
Training loss: 1.495870590209961
Validation loss: 2.247304211060206

Epoch: 5| Step: 7
Training loss: 1.7268054485321045
Validation loss: 2.20762770374616

Epoch: 5| Step: 8
Training loss: 1.3405563831329346
Validation loss: 2.231220309933027

Epoch: 5| Step: 9
Training loss: 1.5556814670562744
Validation loss: 2.222356836001078

Epoch: 5| Step: 10
Training loss: 1.7401844263076782
Validation loss: 2.2048856765031815

Epoch: 5| Step: 11
Training loss: 1.1975986957550049
Validation loss: 2.213503902157148

Epoch: 329| Step: 0
Training loss: 2.221968412399292
Validation loss: 2.2079366544882455

Epoch: 5| Step: 1
Training loss: 1.1005769968032837
Validation loss: 2.190458297729492

Epoch: 5| Step: 2
Training loss: 1.6307014226913452
Validation loss: 2.1773671209812164

Epoch: 5| Step: 3
Training loss: 1.6054975986480713
Validation loss: 2.157083655397097

Epoch: 5| Step: 4
Training loss: 1.6943212747573853
Validation loss: 2.172170509894689

Epoch: 5| Step: 5
Training loss: 1.8206983804702759
Validation loss: 2.1837712625662484

Epoch: 5| Step: 6
Training loss: 1.5802503824234009
Validation loss: 2.181999867161115

Epoch: 5| Step: 7
Training loss: 1.701327919960022
Validation loss: 2.20848456521829

Epoch: 5| Step: 8
Training loss: 1.4959728717803955
Validation loss: 2.188452343146006

Epoch: 5| Step: 9
Training loss: 1.4406845569610596
Validation loss: 2.1895178059736886

Epoch: 5| Step: 10
Training loss: 1.7491426467895508
Validation loss: 2.2049400756756463

Epoch: 5| Step: 11
Training loss: 1.2783633470535278
Validation loss: 2.189939777056376

Epoch: 330| Step: 0
Training loss: 1.1645691394805908
Validation loss: 2.186300794283549

Epoch: 5| Step: 1
Training loss: 2.3635764122009277
Validation loss: 2.2085841794808707

Epoch: 5| Step: 2
Training loss: 1.773841142654419
Validation loss: 2.212190424402555

Epoch: 5| Step: 3
Training loss: 1.940301537513733
Validation loss: 2.2138552963733673

Epoch: 5| Step: 4
Training loss: 2.1050591468811035
Validation loss: 2.200771063566208

Epoch: 5| Step: 5
Training loss: 1.177443265914917
Validation loss: 2.187160203854243

Epoch: 5| Step: 6
Training loss: 1.4852348566055298
Validation loss: 2.167866215109825

Epoch: 5| Step: 7
Training loss: 1.989251732826233
Validation loss: 2.157327945033709

Epoch: 5| Step: 8
Training loss: 1.1801331043243408
Validation loss: 2.173234278957049

Epoch: 5| Step: 9
Training loss: 1.3617299795150757
Validation loss: 2.154832348227501

Epoch: 5| Step: 10
Training loss: 1.6357839107513428
Validation loss: 2.150241489211718

Epoch: 5| Step: 11
Training loss: 1.1004215478897095
Validation loss: 2.1663638254006705

Epoch: 331| Step: 0
Training loss: 1.2880964279174805
Validation loss: 2.1670439143975577

Epoch: 5| Step: 1
Training loss: 1.9028997421264648
Validation loss: 2.174782564242681

Epoch: 5| Step: 2
Training loss: 1.5668426752090454
Validation loss: 2.1579260528087616

Epoch: 5| Step: 3
Training loss: 2.0843665599823
Validation loss: 2.1550709952910743

Epoch: 5| Step: 4
Training loss: 1.6079992055892944
Validation loss: 2.1496996581554413

Epoch: 5| Step: 5
Training loss: 1.4965791702270508
Validation loss: 2.1611422896385193

Epoch: 5| Step: 6
Training loss: 1.115443229675293
Validation loss: 2.167688791950544

Epoch: 5| Step: 7
Training loss: 2.0243146419525146
Validation loss: 2.1942892372608185

Epoch: 5| Step: 8
Training loss: 1.4735174179077148
Validation loss: 2.209249958395958

Epoch: 5| Step: 9
Training loss: 1.5943219661712646
Validation loss: 2.2158707082271576

Epoch: 5| Step: 10
Training loss: 1.9183995723724365
Validation loss: 2.207078367471695

Epoch: 5| Step: 11
Training loss: 1.1190944910049438
Validation loss: 2.220212161540985

Epoch: 332| Step: 0
Training loss: 1.840698003768921
Validation loss: 2.2457641661167145

Epoch: 5| Step: 1
Training loss: 1.330899953842163
Validation loss: 2.2218030194441476

Epoch: 5| Step: 2
Training loss: 1.5483942031860352
Validation loss: 2.2459000994761786

Epoch: 5| Step: 3
Training loss: 1.9931844472885132
Validation loss: 2.2768069157997766

Epoch: 5| Step: 4
Training loss: 1.04081130027771
Validation loss: 2.2446308036645255

Epoch: 5| Step: 5
Training loss: 1.543865442276001
Validation loss: 2.2379542340834937

Epoch: 5| Step: 6
Training loss: 1.462731122970581
Validation loss: 2.203021610776583

Epoch: 5| Step: 7
Training loss: 1.3023849725723267
Validation loss: 2.2398093889156976

Epoch: 5| Step: 8
Training loss: 1.9681812524795532
Validation loss: 2.2469738920529685

Epoch: 5| Step: 9
Training loss: 1.6853139400482178
Validation loss: 2.208557198445002

Epoch: 5| Step: 10
Training loss: 1.6747996807098389
Validation loss: 2.21164337793986

Epoch: 5| Step: 11
Training loss: 1.2905328273773193
Validation loss: 2.197319909930229

Epoch: 333| Step: 0
Training loss: 1.1220741271972656
Validation loss: 2.2115366657574973

Epoch: 5| Step: 1
Training loss: 1.4436167478561401
Validation loss: 2.1917694211006165

Epoch: 5| Step: 2
Training loss: 1.2551687955856323
Validation loss: 2.2142710288365683

Epoch: 5| Step: 3
Training loss: 1.5700457096099854
Validation loss: 2.214865411321322

Epoch: 5| Step: 4
Training loss: 1.7136558294296265
Validation loss: 2.2567132115364075

Epoch: 5| Step: 5
Training loss: 1.8323456048965454
Validation loss: 2.257341722647349

Epoch: 5| Step: 6
Training loss: 1.55752432346344
Validation loss: 2.243737036983172

Epoch: 5| Step: 7
Training loss: 1.8571617603302002
Validation loss: 2.2689372400442758

Epoch: 5| Step: 8
Training loss: 1.422715425491333
Validation loss: 2.2839461167653403

Epoch: 5| Step: 9
Training loss: 1.3866512775421143
Validation loss: 2.266000976165136

Epoch: 5| Step: 10
Training loss: 2.297569990158081
Validation loss: 2.2558321158091226

Epoch: 5| Step: 11
Training loss: 2.209902763366699
Validation loss: 2.267306869228681

Epoch: 334| Step: 0
Training loss: 1.7855802774429321
Validation loss: 2.239657466610273

Epoch: 5| Step: 1
Training loss: 1.3237972259521484
Validation loss: 2.220217843850454

Epoch: 5| Step: 2
Training loss: 1.2687757015228271
Validation loss: 2.2047941585381827

Epoch: 5| Step: 3
Training loss: 1.3662364482879639
Validation loss: 2.2192418028910956

Epoch: 5| Step: 4
Training loss: 1.5495903491973877
Validation loss: 2.2460093796253204

Epoch: 5| Step: 5
Training loss: 1.848785638809204
Validation loss: 2.1958947678407035

Epoch: 5| Step: 6
Training loss: 1.6690948009490967
Validation loss: 2.204572776953379

Epoch: 5| Step: 7
Training loss: 1.1766138076782227
Validation loss: 2.2091956535975137

Epoch: 5| Step: 8
Training loss: 1.551992654800415
Validation loss: 2.2013078033924103

Epoch: 5| Step: 9
Training loss: 2.4034488201141357
Validation loss: 2.195886214574178

Epoch: 5| Step: 10
Training loss: 1.3159092664718628
Validation loss: 2.190873940785726

Epoch: 5| Step: 11
Training loss: 1.3184713125228882
Validation loss: 2.191132033864657

Epoch: 335| Step: 0
Training loss: 1.5286277532577515
Validation loss: 2.1985740015904107

Epoch: 5| Step: 1
Training loss: 2.7565104961395264
Validation loss: 2.1943437407414117

Epoch: 5| Step: 2
Training loss: 1.6455634832382202
Validation loss: 2.2164237101872764

Epoch: 5| Step: 3
Training loss: 1.4269676208496094
Validation loss: 2.2184873272975287

Epoch: 5| Step: 4
Training loss: 1.667474389076233
Validation loss: 2.2150158683458963

Epoch: 5| Step: 5
Training loss: 1.022261381149292
Validation loss: 2.2289289236068726

Epoch: 5| Step: 6
Training loss: 1.6636745929718018
Validation loss: 2.2222554783026376

Epoch: 5| Step: 7
Training loss: 1.4301292896270752
Validation loss: 2.2365022053321204

Epoch: 5| Step: 8
Training loss: 1.163026213645935
Validation loss: 2.245722383260727

Epoch: 5| Step: 9
Training loss: 1.888115644454956
Validation loss: 2.239210764567057

Epoch: 5| Step: 10
Training loss: 1.2552306652069092
Validation loss: 2.2232854018608728

Epoch: 5| Step: 11
Training loss: 1.1089156866073608
Validation loss: 2.241523156563441

Epoch: 336| Step: 0
Training loss: 1.0575693845748901
Validation loss: 2.2454607288042703

Epoch: 5| Step: 1
Training loss: 1.1856147050857544
Validation loss: 2.2304149170716605

Epoch: 5| Step: 2
Training loss: 1.2303011417388916
Validation loss: 2.228334208329519

Epoch: 5| Step: 3
Training loss: 1.916372537612915
Validation loss: 2.2081179519494376

Epoch: 5| Step: 4
Training loss: 1.9498878717422485
Validation loss: 2.217067246635755

Epoch: 5| Step: 5
Training loss: 1.8200485706329346
Validation loss: 2.2218217055002847

Epoch: 5| Step: 6
Training loss: 2.0847463607788086
Validation loss: 2.234076047937075

Epoch: 5| Step: 7
Training loss: 1.5258735418319702
Validation loss: 2.2496922314167023

Epoch: 5| Step: 8
Training loss: 1.1069834232330322
Validation loss: 2.248753691713015

Epoch: 5| Step: 9
Training loss: 1.5330324172973633
Validation loss: 2.253702233235041

Epoch: 5| Step: 10
Training loss: 2.049910068511963
Validation loss: 2.249495883782705

Epoch: 5| Step: 11
Training loss: 1.9239647388458252
Validation loss: 2.220480978488922

Epoch: 337| Step: 0
Training loss: 1.271317958831787
Validation loss: 2.2219862242539725

Epoch: 5| Step: 1
Training loss: 1.1823513507843018
Validation loss: 2.2199831108252206

Epoch: 5| Step: 2
Training loss: 2.0221641063690186
Validation loss: 2.2411928176879883

Epoch: 5| Step: 3
Training loss: 1.144895315170288
Validation loss: 2.2388917009035745

Epoch: 5| Step: 4
Training loss: 1.413047432899475
Validation loss: 2.210608179370562

Epoch: 5| Step: 5
Training loss: 2.245906352996826
Validation loss: 2.2150376240412393

Epoch: 5| Step: 6
Training loss: 1.7165428400039673
Validation loss: 2.183661624789238

Epoch: 5| Step: 7
Training loss: 1.416986346244812
Validation loss: 2.223594382405281

Epoch: 5| Step: 8
Training loss: 1.4890906810760498
Validation loss: 2.19899316628774

Epoch: 5| Step: 9
Training loss: 1.530311942100525
Validation loss: 2.228383551041285

Epoch: 5| Step: 10
Training loss: 1.784895658493042
Validation loss: 2.2277336517969766

Epoch: 5| Step: 11
Training loss: 1.5308384895324707
Validation loss: 2.2275622387727103

Epoch: 338| Step: 0
Training loss: 1.4790500402450562
Validation loss: 2.228391279776891

Epoch: 5| Step: 1
Training loss: 1.595457911491394
Validation loss: 2.2182836631933847

Epoch: 5| Step: 2
Training loss: 2.0816493034362793
Validation loss: 2.2020302514235177

Epoch: 5| Step: 3
Training loss: 1.4077783823013306
Validation loss: 2.194052293896675

Epoch: 5| Step: 4
Training loss: 2.1867129802703857
Validation loss: 2.219035416841507

Epoch: 5| Step: 5
Training loss: 1.4542222023010254
Validation loss: 2.196031630039215

Epoch: 5| Step: 6
Training loss: 1.695835828781128
Validation loss: 2.2233871817588806

Epoch: 5| Step: 7
Training loss: 1.1133480072021484
Validation loss: 2.218796675403913

Epoch: 5| Step: 8
Training loss: 0.9642254114151001
Validation loss: 2.2076703310012817

Epoch: 5| Step: 9
Training loss: 2.193800449371338
Validation loss: 2.194651166598002

Epoch: 5| Step: 10
Training loss: 1.0309239625930786
Validation loss: 2.192845046520233

Epoch: 5| Step: 11
Training loss: 1.650598168373108
Validation loss: 2.209651326139768

Epoch: 339| Step: 0
Training loss: 1.507266640663147
Validation loss: 2.2133990873893103

Epoch: 5| Step: 1
Training loss: 1.7914197444915771
Validation loss: 2.188658540447553

Epoch: 5| Step: 2
Training loss: 1.5513372421264648
Validation loss: 2.2318529784679413

Epoch: 5| Step: 3
Training loss: 1.5278161764144897
Validation loss: 2.243368903795878

Epoch: 5| Step: 4
Training loss: 1.7008033990859985
Validation loss: 2.2325874666372933

Epoch: 5| Step: 5
Training loss: 1.2911040782928467
Validation loss: 2.2356643974781036

Epoch: 5| Step: 6
Training loss: 1.732034683227539
Validation loss: 2.232735047737757

Epoch: 5| Step: 7
Training loss: 1.7206093072891235
Validation loss: 2.2184502432743707

Epoch: 5| Step: 8
Training loss: 1.8633315563201904
Validation loss: 2.2105009853839874

Epoch: 5| Step: 9
Training loss: 1.5735975503921509
Validation loss: 2.2208346128463745

Epoch: 5| Step: 10
Training loss: 1.0270967483520508
Validation loss: 2.193319300810496

Epoch: 5| Step: 11
Training loss: 0.9522028565406799
Validation loss: 2.2211575706799827

Epoch: 340| Step: 0
Training loss: 1.452732801437378
Validation loss: 2.240124613046646

Epoch: 5| Step: 1
Training loss: 1.5440418720245361
Validation loss: 2.2400363882382712

Epoch: 5| Step: 2
Training loss: 1.2033390998840332
Validation loss: 2.2529266079266868

Epoch: 5| Step: 3
Training loss: 1.3826301097869873
Validation loss: 2.2114105174938836

Epoch: 5| Step: 4
Training loss: 1.3729461431503296
Validation loss: 2.2409519652525582

Epoch: 5| Step: 5
Training loss: 1.0124211311340332
Validation loss: 2.2298694352308908

Epoch: 5| Step: 6
Training loss: 1.4725831747055054
Validation loss: 2.2333149711290994

Epoch: 5| Step: 7
Training loss: 2.3060545921325684
Validation loss: 2.214338039358457

Epoch: 5| Step: 8
Training loss: 1.4897023439407349
Validation loss: 2.217662344376246

Epoch: 5| Step: 9
Training loss: 2.0494251251220703
Validation loss: 2.1944097777207694

Epoch: 5| Step: 10
Training loss: 1.496174693107605
Validation loss: 2.1896217862764993

Epoch: 5| Step: 11
Training loss: 3.6456854343414307
Validation loss: 2.187281866868337

Epoch: 341| Step: 0
Training loss: 0.9716717600822449
Validation loss: 2.1696577072143555

Epoch: 5| Step: 1
Training loss: 1.6508277654647827
Validation loss: 2.1793536096811295

Epoch: 5| Step: 2
Training loss: 1.716833472251892
Validation loss: 2.208605945110321

Epoch: 5| Step: 3
Training loss: 1.7157291173934937
Validation loss: 2.214061200618744

Epoch: 5| Step: 4
Training loss: 1.6269481182098389
Validation loss: 2.2243761916955314

Epoch: 5| Step: 5
Training loss: 1.7379707098007202
Validation loss: 2.2135465244452157

Epoch: 5| Step: 6
Training loss: 1.299148440361023
Validation loss: 2.2309553176164627

Epoch: 5| Step: 7
Training loss: 1.8596423864364624
Validation loss: 2.212623124321302

Epoch: 5| Step: 8
Training loss: 1.188463568687439
Validation loss: 2.190903122226397

Epoch: 5| Step: 9
Training loss: 1.4867475032806396
Validation loss: 2.2103343407313027

Epoch: 5| Step: 10
Training loss: 1.7699871063232422
Validation loss: 2.1770958602428436

Epoch: 5| Step: 11
Training loss: 0.6056016683578491
Validation loss: 2.1995699405670166

Epoch: 342| Step: 0
Training loss: 2.105051040649414
Validation loss: 2.193770860632261

Epoch: 5| Step: 1
Training loss: 1.099973440170288
Validation loss: 2.2022118965784707

Epoch: 5| Step: 2
Training loss: 1.562644362449646
Validation loss: 2.2306033074855804

Epoch: 5| Step: 3
Training loss: 1.3861474990844727
Validation loss: 2.2023900151252747

Epoch: 5| Step: 4
Training loss: 1.6862249374389648
Validation loss: 2.1950071503718696

Epoch: 5| Step: 5
Training loss: 1.610234022140503
Validation loss: 2.2325639923413596

Epoch: 5| Step: 6
Training loss: 1.4179017543792725
Validation loss: 2.1843385050694146

Epoch: 5| Step: 7
Training loss: 1.4739606380462646
Validation loss: 2.214428241054217

Epoch: 5| Step: 8
Training loss: 1.965494155883789
Validation loss: 2.179736375808716

Epoch: 5| Step: 9
Training loss: 1.1492916345596313
Validation loss: 2.204645852247874

Epoch: 5| Step: 10
Training loss: 1.352415680885315
Validation loss: 2.2045643478631973

Epoch: 5| Step: 11
Training loss: 3.2009596824645996
Validation loss: 2.2075211902459464

Epoch: 343| Step: 0
Training loss: 2.0293068885803223
Validation loss: 2.205655594666799

Epoch: 5| Step: 1
Training loss: 1.4401744604110718
Validation loss: 2.218050946791967

Epoch: 5| Step: 2
Training loss: 0.8363140225410461
Validation loss: 2.198978508512179

Epoch: 5| Step: 3
Training loss: 1.5723474025726318
Validation loss: 2.2206632445255914

Epoch: 5| Step: 4
Training loss: 1.2926862239837646
Validation loss: 2.2307306428750358

Epoch: 5| Step: 5
Training loss: 1.7095634937286377
Validation loss: 2.2358877658843994

Epoch: 5| Step: 6
Training loss: 1.0033667087554932
Validation loss: 2.2168704768021903

Epoch: 5| Step: 7
Training loss: 1.744195580482483
Validation loss: 2.222014536460241

Epoch: 5| Step: 8
Training loss: 2.1206440925598145
Validation loss: 2.236719941099485

Epoch: 5| Step: 9
Training loss: 1.663047432899475
Validation loss: 2.2387165973583856

Epoch: 5| Step: 10
Training loss: 1.7414119243621826
Validation loss: 2.2050833106040955

Epoch: 5| Step: 11
Training loss: 0.981706976890564
Validation loss: 2.2014478693405786

Epoch: 344| Step: 0
Training loss: 1.0570447444915771
Validation loss: 2.193235938747724

Epoch: 5| Step: 1
Training loss: 2.0816733837127686
Validation loss: 2.2268439630667367

Epoch: 5| Step: 2
Training loss: 1.6032088994979858
Validation loss: 2.228706642985344

Epoch: 5| Step: 3
Training loss: 2.074875593185425
Validation loss: 2.220974544684092

Epoch: 5| Step: 4
Training loss: 1.5791001319885254
Validation loss: 2.2236593067646027

Epoch: 5| Step: 5
Training loss: 1.085422396659851
Validation loss: 2.203311860561371

Epoch: 5| Step: 6
Training loss: 0.8610163927078247
Validation loss: 2.1786621510982513

Epoch: 5| Step: 7
Training loss: 2.1160483360290527
Validation loss: 2.183222452799479

Epoch: 5| Step: 8
Training loss: 1.079545021057129
Validation loss: 2.1859397341807685

Epoch: 5| Step: 9
Training loss: 1.806579828262329
Validation loss: 2.195713698863983

Epoch: 5| Step: 10
Training loss: 1.383693814277649
Validation loss: 2.192817116777102

Epoch: 5| Step: 11
Training loss: 1.9996126890182495
Validation loss: 2.1717981000741324

Epoch: 345| Step: 0
Training loss: 1.511791467666626
Validation loss: 2.194489434361458

Epoch: 5| Step: 1
Training loss: 1.4748212099075317
Validation loss: 2.1782383571068444

Epoch: 5| Step: 2
Training loss: 1.0500917434692383
Validation loss: 2.213618944088618

Epoch: 5| Step: 3
Training loss: 1.1374374628067017
Validation loss: 2.2077389558156333

Epoch: 5| Step: 4
Training loss: 1.5048234462738037
Validation loss: 2.2432512640953064

Epoch: 5| Step: 5
Training loss: 1.8430964946746826
Validation loss: 2.237780953447024

Epoch: 5| Step: 6
Training loss: 1.6559267044067383
Validation loss: 2.2385502606630325

Epoch: 5| Step: 7
Training loss: 1.3724554777145386
Validation loss: 2.2425426046053567

Epoch: 5| Step: 8
Training loss: 1.703736662864685
Validation loss: 2.230089098215103

Epoch: 5| Step: 9
Training loss: 1.9048389196395874
Validation loss: 2.200645844141642

Epoch: 5| Step: 10
Training loss: 1.4069318771362305
Validation loss: 2.2333292613426843

Epoch: 5| Step: 11
Training loss: 2.20220947265625
Validation loss: 2.2209193954865136

Epoch: 346| Step: 0
Training loss: 1.5066863298416138
Validation loss: 2.187517980734507

Epoch: 5| Step: 1
Training loss: 1.890761137008667
Validation loss: 2.204794238011042

Epoch: 5| Step: 2
Training loss: 1.3173552751541138
Validation loss: 2.2195939421653748

Epoch: 5| Step: 3
Training loss: 1.5834707021713257
Validation loss: 2.2083231012026467

Epoch: 5| Step: 4
Training loss: 1.6454989910125732
Validation loss: 2.228665664792061

Epoch: 5| Step: 5
Training loss: 1.3183985948562622
Validation loss: 2.2172978222370148

Epoch: 5| Step: 6
Training loss: 1.7943919897079468
Validation loss: 2.21725424627463

Epoch: 5| Step: 7
Training loss: 1.7682803869247437
Validation loss: 2.244046558936437

Epoch: 5| Step: 8
Training loss: 1.3117752075195312
Validation loss: 2.21664489308993

Epoch: 5| Step: 9
Training loss: 1.7981946468353271
Validation loss: 2.220817585786184

Epoch: 5| Step: 10
Training loss: 1.205865502357483
Validation loss: 2.181262105703354

Epoch: 5| Step: 11
Training loss: 1.4553958177566528
Validation loss: 2.2003463308016458

Epoch: 347| Step: 0
Training loss: 1.361590027809143
Validation loss: 2.2263694355885186

Epoch: 5| Step: 1
Training loss: 1.931626558303833
Validation loss: 2.2098331352074942

Epoch: 5| Step: 2
Training loss: 1.2581398487091064
Validation loss: 2.202683592836062

Epoch: 5| Step: 3
Training loss: 1.7496109008789062
Validation loss: 2.207598532239596

Epoch: 5| Step: 4
Training loss: 2.0634100437164307
Validation loss: 2.205389440059662

Epoch: 5| Step: 5
Training loss: 1.1593266725540161
Validation loss: 2.226351728041967

Epoch: 5| Step: 6
Training loss: 1.9216899871826172
Validation loss: 2.1847948282957077

Epoch: 5| Step: 7
Training loss: 1.3382946252822876
Validation loss: 2.2148799101511636

Epoch: 5| Step: 8
Training loss: 1.7902189493179321
Validation loss: 2.2078013320763907

Epoch: 5| Step: 9
Training loss: 1.3808646202087402
Validation loss: 2.2005001405874887

Epoch: 5| Step: 10
Training loss: 1.3203948736190796
Validation loss: 2.2334066728750863

Epoch: 5| Step: 11
Training loss: 1.981881022453308
Validation loss: 2.2209072560071945

Epoch: 348| Step: 0
Training loss: 1.1788289546966553
Validation loss: 2.2076953450838723

Epoch: 5| Step: 1
Training loss: 1.7452716827392578
Validation loss: 2.226354996363322

Epoch: 5| Step: 2
Training loss: 0.8743540048599243
Validation loss: 2.211344833175341

Epoch: 5| Step: 3
Training loss: 1.307926058769226
Validation loss: 2.1759203374385834

Epoch: 5| Step: 4
Training loss: 1.6466169357299805
Validation loss: 2.1674560407797494

Epoch: 5| Step: 5
Training loss: 2.013176202774048
Validation loss: 2.158947060505549

Epoch: 5| Step: 6
Training loss: 1.779939889907837
Validation loss: 2.144047811627388

Epoch: 5| Step: 7
Training loss: 2.4505553245544434
Validation loss: 2.1518045167128244

Epoch: 5| Step: 8
Training loss: 1.0302382707595825
Validation loss: 2.1571820080280304

Epoch: 5| Step: 9
Training loss: 1.2264058589935303
Validation loss: 2.160581032435099

Epoch: 5| Step: 10
Training loss: 1.237872838973999
Validation loss: 2.1757110208272934

Epoch: 5| Step: 11
Training loss: 1.2653298377990723
Validation loss: 2.174725130200386

Epoch: 349| Step: 0
Training loss: 1.1470054388046265
Validation loss: 2.1585796972115836

Epoch: 5| Step: 1
Training loss: 1.700887680053711
Validation loss: 2.1485332250595093

Epoch: 5| Step: 2
Training loss: 1.4756605625152588
Validation loss: 2.1765351643164954

Epoch: 5| Step: 3
Training loss: 2.182053327560425
Validation loss: 2.1529980103174844

Epoch: 5| Step: 4
Training loss: 1.2099559307098389
Validation loss: 2.166323641935984

Epoch: 5| Step: 5
Training loss: 1.0090433359146118
Validation loss: 2.145105004310608

Epoch: 5| Step: 6
Training loss: 1.7258135080337524
Validation loss: 2.1581378281116486

Epoch: 5| Step: 7
Training loss: 1.9189832210540771
Validation loss: 2.1893941462039948

Epoch: 5| Step: 8
Training loss: 1.6650259494781494
Validation loss: 2.1877662589152655

Epoch: 5| Step: 9
Training loss: 1.766108751296997
Validation loss: 2.187992443641027

Epoch: 5| Step: 10
Training loss: 0.8919681310653687
Validation loss: 2.208286007245382

Epoch: 5| Step: 11
Training loss: 0.814681887626648
Validation loss: 2.206941400965055

Epoch: 350| Step: 0
Training loss: 1.2330008745193481
Validation loss: 2.2141454170147576

Epoch: 5| Step: 1
Training loss: 1.9244763851165771
Validation loss: 2.2300709883371987

Epoch: 5| Step: 2
Training loss: 1.2161142826080322
Validation loss: 2.209231361746788

Epoch: 5| Step: 3
Training loss: 2.278989791870117
Validation loss: 2.2108794450759888

Epoch: 5| Step: 4
Training loss: 1.6037899255752563
Validation loss: 2.226246491074562

Epoch: 5| Step: 5
Training loss: 1.4773865938186646
Validation loss: 2.201147566239039

Epoch: 5| Step: 6
Training loss: 1.448460578918457
Validation loss: 2.1876676877339682

Epoch: 5| Step: 7
Training loss: 1.27399480342865
Validation loss: 2.1610413591066995

Epoch: 5| Step: 8
Training loss: 1.1963088512420654
Validation loss: 2.175061523914337

Epoch: 5| Step: 9
Training loss: 2.1067135334014893
Validation loss: 2.172678912679354

Epoch: 5| Step: 10
Training loss: 0.9866721034049988
Validation loss: 2.180105686187744

Epoch: 5| Step: 11
Training loss: 1.8693065643310547
Validation loss: 2.146987815697988

Testing loss: 1.894629999888029
