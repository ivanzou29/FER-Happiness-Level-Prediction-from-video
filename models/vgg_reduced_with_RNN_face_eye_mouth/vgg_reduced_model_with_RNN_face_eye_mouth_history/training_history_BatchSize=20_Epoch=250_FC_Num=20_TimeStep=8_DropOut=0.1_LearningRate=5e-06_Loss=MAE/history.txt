Epoch: 1| Step: 0
Training loss: 5.588675022125244
Validation loss: 5.385209679603577

Epoch: 5| Step: 1
Training loss: 6.211475372314453
Validation loss: 5.383096645275752

Epoch: 5| Step: 2
Training loss: 5.484447479248047
Validation loss: 5.3808766802151995

Epoch: 5| Step: 3
Training loss: 4.732189178466797
Validation loss: 5.378674825032552

Epoch: 5| Step: 4
Training loss: 4.415197849273682
Validation loss: 5.37653249502182

Epoch: 5| Step: 5
Training loss: 5.46867036819458
Validation loss: 5.374417106310527

Epoch: 5| Step: 6
Training loss: 6.12463903427124
Validation loss: 5.372322817643483

Epoch: 5| Step: 7
Training loss: 6.1572160720825195
Validation loss: 5.370137770970662

Epoch: 5| Step: 8
Training loss: 4.921825408935547
Validation loss: 5.368005553881328

Epoch: 5| Step: 9
Training loss: 5.369786739349365
Validation loss: 5.3658431967099505

Epoch: 5| Step: 10
Training loss: 5.374198913574219
Validation loss: 5.363504032293956

Epoch: 5| Step: 11
Training loss: 5.574835300445557
Validation loss: 5.361253122488658

Epoch: 2| Step: 0
Training loss: 4.912765979766846
Validation loss: 5.358801146348317

Epoch: 5| Step: 1
Training loss: 5.9366655349731445
Validation loss: 5.356332500775655

Epoch: 5| Step: 2
Training loss: 5.305064678192139
Validation loss: 5.35365088780721

Epoch: 5| Step: 3
Training loss: 5.436668395996094
Validation loss: 5.350937465826671

Epoch: 5| Step: 4
Training loss: 4.740415573120117
Validation loss: 5.348127106825511

Epoch: 5| Step: 5
Training loss: 6.044157028198242
Validation loss: 5.344955861568451

Epoch: 5| Step: 6
Training loss: 5.5393266677856445
Validation loss: 5.3418399294217425

Epoch: 5| Step: 7
Training loss: 5.010535717010498
Validation loss: 5.338594237963359

Epoch: 5| Step: 8
Training loss: 5.651318073272705
Validation loss: 5.335180977980296

Epoch: 5| Step: 9
Training loss: 4.904299736022949
Validation loss: 5.3315399289131165

Epoch: 5| Step: 10
Training loss: 5.68867301940918
Validation loss: 5.327914555867513

Epoch: 5| Step: 11
Training loss: 7.284646987915039
Validation loss: 5.3237731258074446

Epoch: 3| Step: 0
Training loss: 6.043061256408691
Validation loss: 5.319900433222453

Epoch: 5| Step: 1
Training loss: 5.490184783935547
Validation loss: 5.3154616355896

Epoch: 5| Step: 2
Training loss: 5.412801742553711
Validation loss: 5.311064859231313

Epoch: 5| Step: 3
Training loss: 4.956711769104004
Validation loss: 5.3064883550008135

Epoch: 5| Step: 4
Training loss: 4.9658098220825195
Validation loss: 5.3014740745226545

Epoch: 5| Step: 5
Training loss: 5.842543601989746
Validation loss: 5.296581864356995

Epoch: 5| Step: 6
Training loss: 5.572984218597412
Validation loss: 5.291211545467377

Epoch: 5| Step: 7
Training loss: 4.662239074707031
Validation loss: 5.2857852180798846

Epoch: 5| Step: 8
Training loss: 4.7270660400390625
Validation loss: 5.28033850590388

Epoch: 5| Step: 9
Training loss: 5.830201148986816
Validation loss: 5.27437953154246

Epoch: 5| Step: 10
Training loss: 5.685457229614258
Validation loss: 5.26846569776535

Epoch: 5| Step: 11
Training loss: 4.476040363311768
Validation loss: 5.262150287628174

Epoch: 4| Step: 0
Training loss: 5.555422306060791
Validation loss: 5.2560243010520935

Epoch: 5| Step: 1
Training loss: 5.416835784912109
Validation loss: 5.249361475308736

Epoch: 5| Step: 2
Training loss: 4.590364933013916
Validation loss: 5.242685278256734

Epoch: 5| Step: 3
Training loss: 3.762131452560425
Validation loss: 5.235653897126515

Epoch: 5| Step: 4
Training loss: 6.0195817947387695
Validation loss: 5.228368520736694

Epoch: 5| Step: 5
Training loss: 4.923248767852783
Validation loss: 5.221384882926941

Epoch: 5| Step: 6
Training loss: 5.1175031661987305
Validation loss: 5.213370780150096

Epoch: 5| Step: 7
Training loss: 5.919412612915039
Validation loss: 5.205463767051697

Epoch: 5| Step: 8
Training loss: 4.7574872970581055
Validation loss: 5.197591086228688

Epoch: 5| Step: 9
Training loss: 5.542547225952148
Validation loss: 5.1890301903088885

Epoch: 5| Step: 10
Training loss: 6.3738813400268555
Validation loss: 5.1808481613794966

Epoch: 5| Step: 11
Training loss: 6.345057964324951
Validation loss: 5.171951075394948

Epoch: 5| Step: 0
Training loss: 4.3379316329956055
Validation loss: 5.16298234462738

Epoch: 5| Step: 1
Training loss: 5.622496604919434
Validation loss: 5.153996427853902

Epoch: 5| Step: 2
Training loss: 6.233518123626709
Validation loss: 5.144735912481944

Epoch: 5| Step: 3
Training loss: 4.633720397949219
Validation loss: 5.135212739308675

Epoch: 5| Step: 4
Training loss: 5.136661052703857
Validation loss: 5.12551995118459

Epoch: 5| Step: 5
Training loss: 5.059916019439697
Validation loss: 5.115603586037953

Epoch: 5| Step: 6
Training loss: 4.890073776245117
Validation loss: 5.105725864569346

Epoch: 5| Step: 7
Training loss: 5.151486396789551
Validation loss: 5.095736960570018

Epoch: 5| Step: 8
Training loss: 5.707114219665527
Validation loss: 5.085422456264496

Epoch: 5| Step: 9
Training loss: 5.758052825927734
Validation loss: 5.07500837246577

Epoch: 5| Step: 10
Training loss: 4.609133720397949
Validation loss: 5.0645133058230085

Epoch: 5| Step: 11
Training loss: 4.888290882110596
Validation loss: 5.053734997908275

Epoch: 6| Step: 0
Training loss: 5.052997589111328
Validation loss: 5.042892028888066

Epoch: 5| Step: 1
Training loss: 5.244280815124512
Validation loss: 5.032574276129405

Epoch: 5| Step: 2
Training loss: 4.7542405128479
Validation loss: 5.021803816159566

Epoch: 5| Step: 3
Training loss: 4.4780802726745605
Validation loss: 5.011139710744222

Epoch: 5| Step: 4
Training loss: 5.223219871520996
Validation loss: 5.000734806060791

Epoch: 5| Step: 5
Training loss: 5.780529975891113
Validation loss: 4.990490893522899

Epoch: 5| Step: 6
Training loss: 4.764171123504639
Validation loss: 4.980426927407582

Epoch: 5| Step: 7
Training loss: 4.686667442321777
Validation loss: 4.970833778381348

Epoch: 5| Step: 8
Training loss: 4.563727378845215
Validation loss: 4.9613505601882935

Epoch: 5| Step: 9
Training loss: 6.220686912536621
Validation loss: 4.952332019805908

Epoch: 5| Step: 10
Training loss: 4.847278594970703
Validation loss: 4.943622807661693

Epoch: 5| Step: 11
Training loss: 5.92406702041626
Validation loss: 4.9350288311640425

Epoch: 7| Step: 0
Training loss: 5.617288112640381
Validation loss: 4.926990767319997

Epoch: 5| Step: 1
Training loss: 5.4468865394592285
Validation loss: 4.918992678324382

Epoch: 5| Step: 2
Training loss: 5.507669925689697
Validation loss: 4.9113995830218

Epoch: 5| Step: 3
Training loss: 5.833645820617676
Validation loss: 4.904763340950012

Epoch: 5| Step: 4
Training loss: 5.041510105133057
Validation loss: 4.897265772024791

Epoch: 5| Step: 5
Training loss: 3.681246519088745
Validation loss: 4.89078148206075

Epoch: 5| Step: 6
Training loss: 4.707858085632324
Validation loss: 4.884149630864461

Epoch: 5| Step: 7
Training loss: 4.804619312286377
Validation loss: 4.877881308396657

Epoch: 5| Step: 8
Training loss: 5.09851598739624
Validation loss: 4.871743967135747

Epoch: 5| Step: 9
Training loss: 4.455648899078369
Validation loss: 4.865710536638896

Epoch: 5| Step: 10
Training loss: 4.024704933166504
Validation loss: 4.860132296880086

Epoch: 5| Step: 11
Training loss: 7.608274459838867
Validation loss: 4.854655424753825

Epoch: 8| Step: 0
Training loss: 4.432299613952637
Validation loss: 4.849181214968364

Epoch: 5| Step: 1
Training loss: 4.8132195472717285
Validation loss: 4.843655486901601

Epoch: 5| Step: 2
Training loss: 4.805394649505615
Validation loss: 4.838423192501068

Epoch: 5| Step: 3
Training loss: 3.622128963470459
Validation loss: 4.833224395910899

Epoch: 5| Step: 4
Training loss: 3.9621100425720215
Validation loss: 4.828296224276225

Epoch: 5| Step: 5
Training loss: 4.9550371170043945
Validation loss: 4.8232448498408

Epoch: 5| Step: 6
Training loss: 6.019957542419434
Validation loss: 4.818347156047821

Epoch: 5| Step: 7
Training loss: 4.510247707366943
Validation loss: 4.813672890265782

Epoch: 5| Step: 8
Training loss: 6.13577938079834
Validation loss: 4.809059162934621

Epoch: 5| Step: 9
Training loss: 4.957444190979004
Validation loss: 4.804359624783198

Epoch: 5| Step: 10
Training loss: 5.6415581703186035
Validation loss: 4.799622734387715

Epoch: 5| Step: 11
Training loss: 5.766026973724365
Validation loss: 4.795323550701141

Epoch: 9| Step: 0
Training loss: 5.3141279220581055
Validation loss: 4.790508548418681

Epoch: 5| Step: 1
Training loss: 4.601093769073486
Validation loss: 4.786186218261719

Epoch: 5| Step: 2
Training loss: 5.485754489898682
Validation loss: 4.781486451625824

Epoch: 5| Step: 3
Training loss: 4.800473690032959
Validation loss: 4.776996552944183

Epoch: 5| Step: 4
Training loss: 3.002549648284912
Validation loss: 4.772584100564321

Epoch: 5| Step: 5
Training loss: 4.961678981781006
Validation loss: 4.76810638109843

Epoch: 5| Step: 6
Training loss: 4.113474369049072
Validation loss: 4.763815303643544

Epoch: 5| Step: 7
Training loss: 5.407266139984131
Validation loss: 4.759455442428589

Epoch: 5| Step: 8
Training loss: 5.249535083770752
Validation loss: 4.754971702893575

Epoch: 5| Step: 9
Training loss: 5.377542018890381
Validation loss: 4.750694553057353

Epoch: 5| Step: 10
Training loss: 4.650104999542236
Validation loss: 4.746742268403371

Epoch: 5| Step: 11
Training loss: 7.297237873077393
Validation loss: 4.742579400539398

Epoch: 10| Step: 0
Training loss: 4.615965843200684
Validation loss: 4.737943232059479

Epoch: 5| Step: 1
Training loss: 4.851138114929199
Validation loss: 4.733354151248932

Epoch: 5| Step: 2
Training loss: 4.097690582275391
Validation loss: 4.729342142740886

Epoch: 5| Step: 3
Training loss: 4.782864570617676
Validation loss: 4.7244910796483355

Epoch: 5| Step: 4
Training loss: 5.488519668579102
Validation loss: 4.720211158196132

Epoch: 5| Step: 5
Training loss: 4.894670009613037
Validation loss: 4.7149937351544695

Epoch: 5| Step: 6
Training loss: 4.724506855010986
Validation loss: 4.710117777188619

Epoch: 5| Step: 7
Training loss: 4.700362205505371
Validation loss: 4.705502847830455

Epoch: 5| Step: 8
Training loss: 4.328012466430664
Validation loss: 4.7006240884462995

Epoch: 5| Step: 9
Training loss: 4.659914970397949
Validation loss: 4.696006755034129

Epoch: 5| Step: 10
Training loss: 5.458574295043945
Validation loss: 4.690552155176799

Epoch: 5| Step: 11
Training loss: 6.236264228820801
Validation loss: 4.685827851295471

Epoch: 11| Step: 0
Training loss: 4.99484920501709
Validation loss: 4.680627803007762

Epoch: 5| Step: 1
Training loss: 4.333653450012207
Validation loss: 4.674982130527496

Epoch: 5| Step: 2
Training loss: 4.82070255279541
Validation loss: 4.669923822085063

Epoch: 5| Step: 3
Training loss: 4.996678352355957
Validation loss: 4.664808849493663

Epoch: 5| Step: 4
Training loss: 4.160602569580078
Validation loss: 4.659411986668904

Epoch: 5| Step: 5
Training loss: 4.222346305847168
Validation loss: 4.655167609453201

Epoch: 5| Step: 6
Training loss: 4.81221866607666
Validation loss: 4.650021503369014

Epoch: 5| Step: 7
Training loss: 4.940229415893555
Validation loss: 4.645124634106954

Epoch: 5| Step: 8
Training loss: 4.979425430297852
Validation loss: 4.639912406603496

Epoch: 5| Step: 9
Training loss: 4.991452217102051
Validation loss: 4.634831349054973

Epoch: 5| Step: 10
Training loss: 5.109132289886475
Validation loss: 4.6304067969322205

Epoch: 5| Step: 11
Training loss: 4.316740989685059
Validation loss: 4.625206470489502

Epoch: 12| Step: 0
Training loss: 4.842503547668457
Validation loss: 4.620223085085551

Epoch: 5| Step: 1
Training loss: 5.844380855560303
Validation loss: 4.615361114343007

Epoch: 5| Step: 2
Training loss: 4.810295104980469
Validation loss: 4.610608478387197

Epoch: 5| Step: 3
Training loss: 4.443323612213135
Validation loss: 4.6062661210695905

Epoch: 5| Step: 4
Training loss: 3.5247726440429688
Validation loss: 4.6011711458365125

Epoch: 5| Step: 5
Training loss: 5.003598690032959
Validation loss: 4.596392909685771

Epoch: 5| Step: 6
Training loss: 4.585743427276611
Validation loss: 4.5916101932525635

Epoch: 5| Step: 7
Training loss: 4.74641227722168
Validation loss: 4.586543182531993

Epoch: 5| Step: 8
Training loss: 4.771553039550781
Validation loss: 4.581668625275294

Epoch: 5| Step: 9
Training loss: 4.992228031158447
Validation loss: 4.577242334683736

Epoch: 5| Step: 10
Training loss: 4.209649085998535
Validation loss: 4.571783483028412

Epoch: 5| Step: 11
Training loss: 4.150720119476318
Validation loss: 4.566874206066132

Epoch: 13| Step: 0
Training loss: 4.2004313468933105
Validation loss: 4.561426162719727

Epoch: 5| Step: 1
Training loss: 4.910485744476318
Validation loss: 4.556931654612224

Epoch: 5| Step: 2
Training loss: 5.126074314117432
Validation loss: 4.552424649397532

Epoch: 5| Step: 3
Training loss: 4.001866817474365
Validation loss: 4.547579308350881

Epoch: 5| Step: 4
Training loss: 4.1226043701171875
Validation loss: 4.542533000310262

Epoch: 5| Step: 5
Training loss: 5.342706203460693
Validation loss: 4.537852068742116

Epoch: 5| Step: 6
Training loss: 4.526864528656006
Validation loss: 4.53357869386673

Epoch: 5| Step: 7
Training loss: 3.486265182495117
Validation loss: 4.5281804005304975

Epoch: 5| Step: 8
Training loss: 4.794900417327881
Validation loss: 4.52326829234759

Epoch: 5| Step: 9
Training loss: 5.191805839538574
Validation loss: 4.517584125200908

Epoch: 5| Step: 10
Training loss: 5.4227166175842285
Validation loss: 4.5126823882261915

Epoch: 5| Step: 11
Training loss: 4.325329303741455
Validation loss: 4.5085262854894

Epoch: 14| Step: 0
Training loss: 3.618201494216919
Validation loss: 4.502327422300975

Epoch: 5| Step: 1
Training loss: 4.78712797164917
Validation loss: 4.497398277123769

Epoch: 5| Step: 2
Training loss: 4.94417142868042
Validation loss: 4.492779493331909

Epoch: 5| Step: 3
Training loss: 4.188479423522949
Validation loss: 4.4874257644017534

Epoch: 5| Step: 4
Training loss: 4.740388870239258
Validation loss: 4.481996933619182

Epoch: 5| Step: 5
Training loss: 4.929621696472168
Validation loss: 4.4764180680116015

Epoch: 5| Step: 6
Training loss: 4.0676727294921875
Validation loss: 4.471237778663635

Epoch: 5| Step: 7
Training loss: 4.4146928787231445
Validation loss: 4.465455591678619

Epoch: 5| Step: 8
Training loss: 3.5945403575897217
Validation loss: 4.460064351558685

Epoch: 5| Step: 9
Training loss: 5.507065296173096
Validation loss: 4.455048779646556

Epoch: 5| Step: 10
Training loss: 5.423596382141113
Validation loss: 4.449134578307469

Epoch: 5| Step: 11
Training loss: 5.805544376373291
Validation loss: 4.44343364238739

Epoch: 15| Step: 0
Training loss: 5.040029048919678
Validation loss: 4.438397993644078

Epoch: 5| Step: 1
Training loss: 4.258055686950684
Validation loss: 4.432916680971782

Epoch: 5| Step: 2
Training loss: 4.411920547485352
Validation loss: 4.426741401354472

Epoch: 5| Step: 3
Training loss: 4.845330715179443
Validation loss: 4.42177426815033

Epoch: 5| Step: 4
Training loss: 4.920979976654053
Validation loss: 4.416694740454356

Epoch: 5| Step: 5
Training loss: 3.685004472732544
Validation loss: 4.411274125178655

Epoch: 5| Step: 6
Training loss: 4.36888313293457
Validation loss: 4.405663192272186

Epoch: 5| Step: 7
Training loss: 4.625396251678467
Validation loss: 4.399936566750209

Epoch: 5| Step: 8
Training loss: 5.397156715393066
Validation loss: 4.393624206384023

Epoch: 5| Step: 9
Training loss: 4.1434006690979
Validation loss: 4.38793017466863

Epoch: 5| Step: 10
Training loss: 4.208837985992432
Validation loss: 4.381667862335841

Epoch: 5| Step: 11
Training loss: 4.0355658531188965
Validation loss: 4.376083294550578

Epoch: 16| Step: 0
Training loss: 4.095973968505859
Validation loss: 4.369372099637985

Epoch: 5| Step: 1
Training loss: 4.296750068664551
Validation loss: 4.363078733285268

Epoch: 5| Step: 2
Training loss: 4.925276756286621
Validation loss: 4.357139766216278

Epoch: 5| Step: 3
Training loss: 4.279149055480957
Validation loss: 4.351115882396698

Epoch: 5| Step: 4
Training loss: 4.428572654724121
Validation loss: 4.345880438884099

Epoch: 5| Step: 5
Training loss: 3.972280502319336
Validation loss: 4.3390562534332275

Epoch: 5| Step: 6
Training loss: 3.9627037048339844
Validation loss: 4.333236942688624

Epoch: 5| Step: 7
Training loss: 5.263972282409668
Validation loss: 4.326981008052826

Epoch: 5| Step: 8
Training loss: 4.269020080566406
Validation loss: 4.3212897678216295

Epoch: 5| Step: 9
Training loss: 4.208699703216553
Validation loss: 4.315528372923533

Epoch: 5| Step: 10
Training loss: 5.187987327575684
Validation loss: 4.3096518615881605

Epoch: 5| Step: 11
Training loss: 5.468715667724609
Validation loss: 4.303663690884908

Epoch: 17| Step: 0
Training loss: 4.027159690856934
Validation loss: 4.298824141422908

Epoch: 5| Step: 1
Training loss: 5.073871612548828
Validation loss: 4.292780170838038

Epoch: 5| Step: 2
Training loss: 4.347866058349609
Validation loss: 4.286272376775742

Epoch: 5| Step: 3
Training loss: 4.904144287109375
Validation loss: 4.2804424067338305

Epoch: 5| Step: 4
Training loss: 3.630542755126953
Validation loss: 4.275201678276062

Epoch: 5| Step: 5
Training loss: 3.8057007789611816
Validation loss: 4.270497332016627

Epoch: 5| Step: 6
Training loss: 5.619162559509277
Validation loss: 4.263362477223079

Epoch: 5| Step: 7
Training loss: 4.152746677398682
Validation loss: 4.25688636302948

Epoch: 5| Step: 8
Training loss: 4.647915840148926
Validation loss: 4.251430382331212

Epoch: 5| Step: 9
Training loss: 3.6920394897460938
Validation loss: 4.245302836100261

Epoch: 5| Step: 10
Training loss: 4.7209978103637695
Validation loss: 4.238851110140483

Epoch: 5| Step: 11
Training loss: 3.1866464614868164
Validation loss: 4.232482135295868

Epoch: 18| Step: 0
Training loss: 4.487159729003906
Validation loss: 4.226786454518636

Epoch: 5| Step: 1
Training loss: 4.785131931304932
Validation loss: 4.221384604771932

Epoch: 5| Step: 2
Training loss: 4.65799617767334
Validation loss: 4.215625594059627

Epoch: 5| Step: 3
Training loss: 4.617466926574707
Validation loss: 4.208782255649567

Epoch: 5| Step: 4
Training loss: 4.388155937194824
Validation loss: 4.202885657548904

Epoch: 5| Step: 5
Training loss: 4.185904502868652
Validation loss: 4.196933150291443

Epoch: 5| Step: 6
Training loss: 4.430055141448975
Validation loss: 4.190745711326599

Epoch: 5| Step: 7
Training loss: 3.7310585975646973
Validation loss: 4.184910088777542

Epoch: 5| Step: 8
Training loss: 3.564786911010742
Validation loss: 4.178663074970245

Epoch: 5| Step: 9
Training loss: 3.938037395477295
Validation loss: 4.172199944655101

Epoch: 5| Step: 10
Training loss: 4.674593448638916
Validation loss: 4.166316509246826

Epoch: 5| Step: 11
Training loss: 5.2988505363464355
Validation loss: 4.160232096910477

Epoch: 19| Step: 0
Training loss: 4.301761627197266
Validation loss: 4.154388070106506

Epoch: 5| Step: 1
Training loss: 4.377140998840332
Validation loss: 4.149050255616506

Epoch: 5| Step: 2
Training loss: 4.801070213317871
Validation loss: 4.143452763557434

Epoch: 5| Step: 3
Training loss: 3.8356215953826904
Validation loss: 4.136882980664571

Epoch: 5| Step: 4
Training loss: 4.050307273864746
Validation loss: 4.13034200668335

Epoch: 5| Step: 5
Training loss: 4.104765892028809
Validation loss: 4.124726255734761

Epoch: 5| Step: 6
Training loss: 3.3467140197753906
Validation loss: 4.118267556031545

Epoch: 5| Step: 7
Training loss: 4.0817155838012695
Validation loss: 4.1131408015886946

Epoch: 5| Step: 8
Training loss: 4.754947185516357
Validation loss: 4.107049127419789

Epoch: 5| Step: 9
Training loss: 4.512396812438965
Validation loss: 4.101384152968724

Epoch: 5| Step: 10
Training loss: 4.964664459228516
Validation loss: 4.094923893610637

Epoch: 5| Step: 11
Training loss: 3.2402868270874023
Validation loss: 4.0883407692114515

Epoch: 20| Step: 0
Training loss: 4.079820156097412
Validation loss: 4.0828171869119005

Epoch: 5| Step: 1
Training loss: 3.339505672454834
Validation loss: 4.078831613063812

Epoch: 5| Step: 2
Training loss: 5.164912223815918
Validation loss: 4.074960947036743

Epoch: 5| Step: 3
Training loss: 3.9581127166748047
Validation loss: 4.070371796687444

Epoch: 5| Step: 4
Training loss: 4.677743434906006
Validation loss: 4.0625928938388824

Epoch: 5| Step: 5
Training loss: 4.564311981201172
Validation loss: 4.05583902200063

Epoch: 5| Step: 6
Training loss: 4.194233417510986
Validation loss: 4.050567249457042

Epoch: 5| Step: 7
Training loss: 3.7237441539764404
Validation loss: 4.046232461929321

Epoch: 5| Step: 8
Training loss: 2.962416887283325
Validation loss: 4.039312581221263

Epoch: 5| Step: 9
Training loss: 4.705589771270752
Validation loss: 4.03398643930753

Epoch: 5| Step: 10
Training loss: 4.727048397064209
Validation loss: 4.028236707051595

Epoch: 5| Step: 11
Training loss: 4.71846866607666
Validation loss: 4.022409955660502

Epoch: 21| Step: 0
Training loss: 3.8101024627685547
Validation loss: 4.017428517341614

Epoch: 5| Step: 1
Training loss: 5.041991710662842
Validation loss: 4.010748823483785

Epoch: 5| Step: 2
Training loss: 4.197451114654541
Validation loss: 4.00563661257426

Epoch: 5| Step: 3
Training loss: 4.068398952484131
Validation loss: 3.9986275831858316

Epoch: 5| Step: 4
Training loss: 3.7264881134033203
Validation loss: 3.9931644201278687

Epoch: 5| Step: 5
Training loss: 4.475881576538086
Validation loss: 3.9869153102238974

Epoch: 5| Step: 6
Training loss: 3.528850555419922
Validation loss: 3.9807060758272805

Epoch: 5| Step: 7
Training loss: 3.650681734085083
Validation loss: 3.975082794825236

Epoch: 5| Step: 8
Training loss: 4.853244781494141
Validation loss: 3.9700306951999664

Epoch: 5| Step: 9
Training loss: 3.7408480644226074
Validation loss: 3.96435076991717

Epoch: 5| Step: 10
Training loss: 4.109901428222656
Validation loss: 3.957470804452896

Epoch: 5| Step: 11
Training loss: 5.460176467895508
Validation loss: 3.9515449007352195

Epoch: 22| Step: 0
Training loss: 4.34011173248291
Validation loss: 3.947945237159729

Epoch: 5| Step: 1
Training loss: 4.000964164733887
Validation loss: 3.9407255252202353

Epoch: 5| Step: 2
Training loss: 4.029580116271973
Validation loss: 3.932783226172129

Epoch: 5| Step: 3
Training loss: 4.3157267570495605
Validation loss: 3.928137093782425

Epoch: 5| Step: 4
Training loss: 3.8948299884796143
Validation loss: 3.9223865966002145

Epoch: 5| Step: 5
Training loss: 3.598201036453247
Validation loss: 3.9152038296063743

Epoch: 5| Step: 6
Training loss: 3.646000623703003
Validation loss: 3.9085115989049277

Epoch: 5| Step: 7
Training loss: 4.420889854431152
Validation loss: 3.904740740855535

Epoch: 5| Step: 8
Training loss: 4.605202674865723
Validation loss: 3.8968204160531363

Epoch: 5| Step: 9
Training loss: 3.979118824005127
Validation loss: 3.8900578916072845

Epoch: 5| Step: 10
Training loss: 4.036746501922607
Validation loss: 3.8843569457530975

Epoch: 5| Step: 11
Training loss: 3.2835354804992676
Validation loss: 3.8798905114332833

Epoch: 23| Step: 0
Training loss: 3.782048463821411
Validation loss: 3.8739638229211173

Epoch: 5| Step: 1
Training loss: 5.190758228302002
Validation loss: 3.8666619658470154

Epoch: 5| Step: 2
Training loss: 4.980786323547363
Validation loss: 3.8602079252401986

Epoch: 5| Step: 3
Training loss: 3.3910224437713623
Validation loss: 3.8532144824663797

Epoch: 5| Step: 4
Training loss: 3.257701873779297
Validation loss: 3.8478789031505585

Epoch: 5| Step: 5
Training loss: 4.744044303894043
Validation loss: 3.840438276529312

Epoch: 5| Step: 6
Training loss: 4.514335632324219
Validation loss: 3.8342788318792977

Epoch: 5| Step: 7
Training loss: 3.7682578563690186
Validation loss: 3.828167607386907

Epoch: 5| Step: 8
Training loss: 2.811605453491211
Validation loss: 3.8225211799144745

Epoch: 5| Step: 9
Training loss: 3.9359142780303955
Validation loss: 3.8157296975453696

Epoch: 5| Step: 10
Training loss: 3.4387049674987793
Validation loss: 3.809572776158651

Epoch: 5| Step: 11
Training loss: 4.639448165893555
Validation loss: 3.803564747174581

Epoch: 24| Step: 0
Training loss: 4.1206231117248535
Validation loss: 3.8015277882417045

Epoch: 5| Step: 1
Training loss: 4.389074802398682
Validation loss: 3.7942666709423065

Epoch: 5| Step: 2
Training loss: 2.5594260692596436
Validation loss: 3.7864471872647605

Epoch: 5| Step: 3
Training loss: 4.501519203186035
Validation loss: 3.7820922434329987

Epoch: 5| Step: 4
Training loss: 4.668757915496826
Validation loss: 3.777655750513077

Epoch: 5| Step: 5
Training loss: 3.540573835372925
Validation loss: 3.770102789004644

Epoch: 5| Step: 6
Training loss: 3.6889312267303467
Validation loss: 3.7635342876116433

Epoch: 5| Step: 7
Training loss: 3.908242702484131
Validation loss: 3.7584310173988342

Epoch: 5| Step: 8
Training loss: 4.287476539611816
Validation loss: 3.75240558385849

Epoch: 5| Step: 9
Training loss: 3.92529296875
Validation loss: 3.74557101726532

Epoch: 5| Step: 10
Training loss: 3.8011670112609863
Validation loss: 3.74098273118337

Epoch: 5| Step: 11
Training loss: 3.004828929901123
Validation loss: 3.735042154788971

Epoch: 25| Step: 0
Training loss: 3.5497078895568848
Validation loss: 3.7283313473065696

Epoch: 5| Step: 1
Training loss: 4.609798908233643
Validation loss: 3.7226259807745614

Epoch: 5| Step: 2
Training loss: 2.978908061981201
Validation loss: 3.716393530368805

Epoch: 5| Step: 3
Training loss: 3.72087025642395
Validation loss: 3.709746460119883

Epoch: 5| Step: 4
Training loss: 3.3852005004882812
Validation loss: 3.706392655769984

Epoch: 5| Step: 5
Training loss: 3.406759738922119
Validation loss: 3.7011407216389975

Epoch: 5| Step: 6
Training loss: 3.773329496383667
Validation loss: 3.694702376921972

Epoch: 5| Step: 7
Training loss: 4.787145614624023
Validation loss: 3.6884454687436423

Epoch: 5| Step: 8
Training loss: 4.192762851715088
Validation loss: 3.681827356417974

Epoch: 5| Step: 9
Training loss: 3.8273799419403076
Validation loss: 3.6776210168997445

Epoch: 5| Step: 10
Training loss: 4.266861915588379
Validation loss: 3.670810580253601

Epoch: 5| Step: 11
Training loss: 3.5148696899414062
Validation loss: 3.6646739840507507

Epoch: 26| Step: 0
Training loss: 3.951124668121338
Validation loss: 3.659283479054769

Epoch: 5| Step: 1
Training loss: 3.743117570877075
Validation loss: 3.6545693278312683

Epoch: 5| Step: 2
Training loss: 3.4358551502227783
Validation loss: 3.648287981748581

Epoch: 5| Step: 3
Training loss: 3.921412229537964
Validation loss: 3.6437545915444693

Epoch: 5| Step: 4
Training loss: 3.052826404571533
Validation loss: 3.637607842683792

Epoch: 5| Step: 5
Training loss: 3.7479805946350098
Validation loss: 3.6328948040803275

Epoch: 5| Step: 6
Training loss: 3.3922343254089355
Validation loss: 3.6265219847361245

Epoch: 5| Step: 7
Training loss: 4.244166374206543
Validation loss: 3.619270990292231

Epoch: 5| Step: 8
Training loss: 4.043426513671875
Validation loss: 3.614705423514048

Epoch: 5| Step: 9
Training loss: 4.056029796600342
Validation loss: 3.6103435258070626

Epoch: 5| Step: 10
Training loss: 3.877169370651245
Validation loss: 3.6078528662522635

Epoch: 5| Step: 11
Training loss: 5.035254955291748
Validation loss: 3.6046072045962014

Epoch: 27| Step: 0
Training loss: 3.4380621910095215
Validation loss: 3.591370850801468

Epoch: 5| Step: 1
Training loss: 2.7976841926574707
Validation loss: 3.589336484670639

Epoch: 5| Step: 2
Training loss: 4.792924880981445
Validation loss: 3.5921343664328256

Epoch: 5| Step: 3
Training loss: 4.396732807159424
Validation loss: 3.5861383775870004

Epoch: 5| Step: 4
Training loss: 3.85432767868042
Validation loss: 3.5771746138731637

Epoch: 5| Step: 5
Training loss: 2.9501681327819824
Validation loss: 3.568246692419052

Epoch: 5| Step: 6
Training loss: 4.629355430603027
Validation loss: 3.5600987374782562

Epoch: 5| Step: 7
Training loss: 3.868710994720459
Validation loss: 3.5555782318115234

Epoch: 5| Step: 8
Training loss: 3.8533225059509277
Validation loss: 3.552146226167679

Epoch: 5| Step: 9
Training loss: 3.954404830932617
Validation loss: 3.5466281473636627

Epoch: 5| Step: 10
Training loss: 2.9411303997039795
Validation loss: 3.5421567062536874

Epoch: 5| Step: 11
Training loss: 1.6986232995986938
Validation loss: 3.5368109047412872

Epoch: 28| Step: 0
Training loss: 3.6933677196502686
Validation loss: 3.5326958000659943

Epoch: 5| Step: 1
Training loss: 3.5636303424835205
Validation loss: 3.523459812005361

Epoch: 5| Step: 2
Training loss: 3.178851366043091
Validation loss: 3.5158618489901223

Epoch: 5| Step: 3
Training loss: 4.1092352867126465
Validation loss: 3.5097238024075827

Epoch: 5| Step: 4
Training loss: 3.2328639030456543
Validation loss: 3.5033886233965554

Epoch: 5| Step: 5
Training loss: 3.6843199729919434
Validation loss: 3.497921258211136

Epoch: 5| Step: 6
Training loss: 3.2735238075256348
Validation loss: 3.4937973022460938

Epoch: 5| Step: 7
Training loss: 3.7448647022247314
Validation loss: 3.489826738834381

Epoch: 5| Step: 8
Training loss: 4.579211711883545
Validation loss: 3.4832916061083474

Epoch: 5| Step: 9
Training loss: 3.1458404064178467
Validation loss: 3.4765873750050864

Epoch: 5| Step: 10
Training loss: 3.6791656017303467
Validation loss: 3.4698783854643502

Epoch: 5| Step: 11
Training loss: 5.7342448234558105
Validation loss: 3.46499295035998

Epoch: 29| Step: 0
Training loss: 3.3421130180358887
Validation loss: 3.461304356654485

Epoch: 5| Step: 1
Training loss: 3.811732530593872
Validation loss: 3.456328362226486

Epoch: 5| Step: 2
Training loss: 3.5205490589141846
Validation loss: 3.45572500427564

Epoch: 5| Step: 3
Training loss: 3.7111077308654785
Validation loss: 3.445522348086039

Epoch: 5| Step: 4
Training loss: 2.7420284748077393
Validation loss: 3.4385313292344413

Epoch: 5| Step: 5
Training loss: 3.2703182697296143
Validation loss: 3.432534803946813

Epoch: 5| Step: 6
Training loss: 4.304062366485596
Validation loss: 3.428515742222468

Epoch: 5| Step: 7
Training loss: 3.729196071624756
Validation loss: 3.424452990293503

Epoch: 5| Step: 8
Training loss: 4.318060874938965
Validation loss: 3.418734530607859

Epoch: 5| Step: 9
Training loss: 2.6632790565490723
Validation loss: 3.413459668556849

Epoch: 5| Step: 10
Training loss: 3.8427982330322266
Validation loss: 3.4078729351361594

Epoch: 5| Step: 11
Training loss: 5.290107727050781
Validation loss: 3.4026095966498056

Epoch: 30| Step: 0
Training loss: 3.9654593467712402
Validation loss: 3.395742932955424

Epoch: 5| Step: 1
Training loss: 4.6676201820373535
Validation loss: 3.391263027985891

Epoch: 5| Step: 2
Training loss: 4.556601524353027
Validation loss: 3.385461320479711

Epoch: 5| Step: 3
Training loss: 3.221118450164795
Validation loss: 3.379853983720144

Epoch: 5| Step: 4
Training loss: 3.476492404937744
Validation loss: 3.374260743459066

Epoch: 5| Step: 5
Training loss: 3.552694320678711
Validation loss: 3.3696870307127633

Epoch: 5| Step: 6
Training loss: 3.492408037185669
Validation loss: 3.3642015159130096

Epoch: 5| Step: 7
Training loss: 2.8883910179138184
Validation loss: 3.35838716228803

Epoch: 5| Step: 8
Training loss: 2.8341622352600098
Validation loss: 3.3530108431975045

Epoch: 5| Step: 9
Training loss: 3.717768907546997
Validation loss: 3.347078969081243

Epoch: 5| Step: 10
Training loss: 2.8127920627593994
Validation loss: 3.3418145775794983

Epoch: 5| Step: 11
Training loss: 2.234495162963867
Validation loss: 3.335331360499064

Epoch: 31| Step: 0
Training loss: 3.4640610218048096
Validation loss: 3.3306605219841003

Epoch: 5| Step: 1
Training loss: 3.726818561553955
Validation loss: 3.3257818023363748

Epoch: 5| Step: 2
Training loss: 3.399613618850708
Validation loss: 3.3198612531026206

Epoch: 5| Step: 3
Training loss: 4.116610527038574
Validation loss: 3.3148685892422995

Epoch: 5| Step: 4
Training loss: 3.680973768234253
Validation loss: 3.310410350561142

Epoch: 5| Step: 5
Training loss: 3.0617268085479736
Validation loss: 3.3048747976620994

Epoch: 5| Step: 6
Training loss: 3.268533706665039
Validation loss: 3.299435247977575

Epoch: 5| Step: 7
Training loss: 3.736095428466797
Validation loss: 3.29618901014328

Epoch: 5| Step: 8
Training loss: 2.7799930572509766
Validation loss: 3.290745367606481

Epoch: 5| Step: 9
Training loss: 4.2964582443237305
Validation loss: 3.2865091363588967

Epoch: 5| Step: 10
Training loss: 2.963118314743042
Validation loss: 3.2809449632962546

Epoch: 5| Step: 11
Training loss: 2.331462860107422
Validation loss: 3.2759628693262735

Epoch: 32| Step: 0
Training loss: 3.771157741546631
Validation loss: 3.2711595594882965

Epoch: 5| Step: 1
Training loss: 4.2062835693359375
Validation loss: 3.2662157813707986

Epoch: 5| Step: 2
Training loss: 3.356231689453125
Validation loss: 3.261882722377777

Epoch: 5| Step: 3
Training loss: 2.8186464309692383
Validation loss: 3.2582248747348785

Epoch: 5| Step: 4
Training loss: 3.888906955718994
Validation loss: 3.253267377614975

Epoch: 5| Step: 5
Training loss: 3.5054118633270264
Validation loss: 3.2476132114728293

Epoch: 5| Step: 6
Training loss: 3.2536301612854004
Validation loss: 3.242588152488073

Epoch: 5| Step: 7
Training loss: 3.3137855529785156
Validation loss: 3.2381993333498635

Epoch: 5| Step: 8
Training loss: 3.0355725288391113
Validation loss: 3.2342054645220437

Epoch: 5| Step: 9
Training loss: 3.3155388832092285
Validation loss: 3.229838232199351

Epoch: 5| Step: 10
Training loss: 3.1599390506744385
Validation loss: 3.225194195906321

Epoch: 5| Step: 11
Training loss: 3.693173408508301
Validation loss: 3.2201856772104898

Epoch: 33| Step: 0
Training loss: 3.7180709838867188
Validation loss: 3.2156118055184684

Epoch: 5| Step: 1
Training loss: 3.1990363597869873
Validation loss: 3.2103649377822876

Epoch: 5| Step: 2
Training loss: 3.6844630241394043
Validation loss: 3.204691151777903

Epoch: 5| Step: 3
Training loss: 3.0436508655548096
Validation loss: 3.201308528582255

Epoch: 5| Step: 4
Training loss: 3.656548023223877
Validation loss: 3.196417639652888

Epoch: 5| Step: 5
Training loss: 2.0181336402893066
Validation loss: 3.1919044852256775

Epoch: 5| Step: 6
Training loss: 3.681408643722534
Validation loss: 3.1882139245669046

Epoch: 5| Step: 7
Training loss: 3.4818198680877686
Validation loss: 3.1836541990439096

Epoch: 5| Step: 8
Training loss: 3.4059195518493652
Validation loss: 3.1790532171726227

Epoch: 5| Step: 9
Training loss: 3.64149808883667
Validation loss: 3.175038347641627

Epoch: 5| Step: 10
Training loss: 3.177339553833008
Validation loss: 3.1702629725138345

Epoch: 5| Step: 11
Training loss: 5.340904712677002
Validation loss: 3.166069746017456

Epoch: 34| Step: 0
Training loss: 3.495924472808838
Validation loss: 3.1609850923220315

Epoch: 5| Step: 1
Training loss: 2.6598148345947266
Validation loss: 3.156422903140386

Epoch: 5| Step: 2
Training loss: 3.706869125366211
Validation loss: 3.1515226662158966

Epoch: 5| Step: 3
Training loss: 3.4266669750213623
Validation loss: 3.147538165251414

Epoch: 5| Step: 4
Training loss: 3.7828330993652344
Validation loss: 3.1427160799503326

Epoch: 5| Step: 5
Training loss: 3.011626958847046
Validation loss: 3.1376361548900604

Epoch: 5| Step: 6
Training loss: 3.5323779582977295
Validation loss: 3.133149653673172

Epoch: 5| Step: 7
Training loss: 3.3842170238494873
Validation loss: 3.128610293070475

Epoch: 5| Step: 8
Training loss: 3.0026793479919434
Validation loss: 3.1239450772603354

Epoch: 5| Step: 9
Training loss: 3.6422393321990967
Validation loss: 3.119722386201223

Epoch: 5| Step: 10
Training loss: 2.966595411300659
Validation loss: 3.1152497927347818

Epoch: 5| Step: 11
Training loss: 3.012904167175293
Validation loss: 3.1111358205477395

Epoch: 35| Step: 0
Training loss: 3.8342621326446533
Validation loss: 3.1060336430867515

Epoch: 5| Step: 1
Training loss: 3.564678907394409
Validation loss: 3.1022405922412872

Epoch: 5| Step: 2
Training loss: 3.1949307918548584
Validation loss: 3.0976272324721017

Epoch: 5| Step: 3
Training loss: 2.9389569759368896
Validation loss: 3.0932085613409677

Epoch: 5| Step: 4
Training loss: 3.5453152656555176
Validation loss: 3.0893882115681968

Epoch: 5| Step: 5
Training loss: 3.4153761863708496
Validation loss: 3.084537555774053

Epoch: 5| Step: 6
Training loss: 3.2436535358428955
Validation loss: 3.0808309515317283

Epoch: 5| Step: 7
Training loss: 2.5504794120788574
Validation loss: 3.0770834187666574

Epoch: 5| Step: 8
Training loss: 3.4178359508514404
Validation loss: 3.072562744220098

Epoch: 5| Step: 9
Training loss: 2.9065799713134766
Validation loss: 3.0691498617331185

Epoch: 5| Step: 10
Training loss: 3.1060192584991455
Validation loss: 3.065407633781433

Epoch: 5| Step: 11
Training loss: 4.759035587310791
Validation loss: 3.0614791413148246

Epoch: 36| Step: 0
Training loss: 3.5784859657287598
Validation loss: 3.0579821467399597

Epoch: 5| Step: 1
Training loss: 2.806195020675659
Validation loss: 3.054274082183838

Epoch: 5| Step: 2
Training loss: 3.3534302711486816
Validation loss: 3.049524108568827

Epoch: 5| Step: 3
Training loss: 3.3312573432922363
Validation loss: 3.0459046363830566

Epoch: 5| Step: 4
Training loss: 3.1496310234069824
Validation loss: 3.041861226161321

Epoch: 5| Step: 5
Training loss: 2.6698529720306396
Validation loss: 3.0380562941233316

Epoch: 5| Step: 6
Training loss: 3.493994951248169
Validation loss: 3.0341386099656424

Epoch: 5| Step: 7
Training loss: 2.680523633956909
Validation loss: 3.0303285916646323

Epoch: 5| Step: 8
Training loss: 3.110591173171997
Validation loss: 3.0256864627202353

Epoch: 5| Step: 9
Training loss: 4.543929100036621
Validation loss: 3.0230715572834015

Epoch: 5| Step: 10
Training loss: 2.9085757732391357
Validation loss: 3.0171209971110025

Epoch: 5| Step: 11
Training loss: 2.619011640548706
Validation loss: 3.0145228604475656

Epoch: 37| Step: 0
Training loss: 3.0467493534088135
Validation loss: 3.012233336766561

Epoch: 5| Step: 1
Training loss: 3.0842230319976807
Validation loss: 3.0080254872639975

Epoch: 5| Step: 2
Training loss: 3.026650905609131
Validation loss: 3.004358102877935

Epoch: 5| Step: 3
Training loss: 3.2935924530029297
Validation loss: 3.0012218058109283

Epoch: 5| Step: 4
Training loss: 3.261397123336792
Validation loss: 2.997108777364095

Epoch: 5| Step: 5
Training loss: 2.992197036743164
Validation loss: 2.99416654308637

Epoch: 5| Step: 6
Training loss: 3.76232647895813
Validation loss: 2.9905923505624137

Epoch: 5| Step: 7
Training loss: 3.340391159057617
Validation loss: 2.987928181886673

Epoch: 5| Step: 8
Training loss: 2.4023680686950684
Validation loss: 2.9843776623408

Epoch: 5| Step: 9
Training loss: 3.2475318908691406
Validation loss: 2.9819282690684

Epoch: 5| Step: 10
Training loss: 3.545319080352783
Validation loss: 2.9765796661376953

Epoch: 5| Step: 11
Training loss: 3.384291172027588
Validation loss: 2.9734385708967843

Epoch: 38| Step: 0
Training loss: 3.4448559284210205
Validation loss: 2.9693225423494973

Epoch: 5| Step: 1
Training loss: 3.1691348552703857
Validation loss: 2.966085205475489

Epoch: 5| Step: 2
Training loss: 2.8750414848327637
Validation loss: 2.962253659963608

Epoch: 5| Step: 3
Training loss: 2.9433987140655518
Validation loss: 2.9587454795837402

Epoch: 5| Step: 4
Training loss: 3.2937674522399902
Validation loss: 2.955642282962799

Epoch: 5| Step: 5
Training loss: 3.8647990226745605
Validation loss: 2.951896548271179

Epoch: 5| Step: 6
Training loss: 2.8503684997558594
Validation loss: 2.9479124546051025

Epoch: 5| Step: 7
Training loss: 2.3287792205810547
Validation loss: 2.9439289569854736

Epoch: 5| Step: 8
Training loss: 2.9132251739501953
Validation loss: 2.939402769009272

Epoch: 5| Step: 9
Training loss: 3.672497272491455
Validation loss: 2.9382010400295258

Epoch: 5| Step: 10
Training loss: 3.118757724761963
Validation loss: 2.936856766541799

Epoch: 5| Step: 11
Training loss: 3.9533843994140625
Validation loss: 2.934327373902003

Epoch: 39| Step: 0
Training loss: 3.153400182723999
Validation loss: 2.9283782045046487

Epoch: 5| Step: 1
Training loss: 2.8172428607940674
Validation loss: 2.923391282558441

Epoch: 5| Step: 2
Training loss: 3.4188969135284424
Validation loss: 2.9199839929739633

Epoch: 5| Step: 3
Training loss: 3.3983798027038574
Validation loss: 2.915627201398214

Epoch: 5| Step: 4
Training loss: 2.6563117504119873
Validation loss: 2.9134430090586343

Epoch: 5| Step: 5
Training loss: 2.5378355979919434
Validation loss: 2.9105777541796365

Epoch: 5| Step: 6
Training loss: 3.5522265434265137
Validation loss: 2.907137910525004

Epoch: 5| Step: 7
Training loss: 2.7065589427948
Validation loss: 2.9048037926355996

Epoch: 5| Step: 8
Training loss: 3.741274356842041
Validation loss: 2.902134190003077

Epoch: 5| Step: 9
Training loss: 2.9148669242858887
Validation loss: 2.8983200589815774

Epoch: 5| Step: 10
Training loss: 3.1123528480529785
Validation loss: 2.8934409519036612

Epoch: 5| Step: 11
Training loss: 4.1849493980407715
Validation loss: 2.8905189434687295

Epoch: 40| Step: 0
Training loss: 3.388892650604248
Validation loss: 2.8862354258696237

Epoch: 5| Step: 1
Training loss: 3.310286045074463
Validation loss: 2.8845584193865457

Epoch: 5| Step: 2
Training loss: 2.702587604522705
Validation loss: 2.881298989057541

Epoch: 5| Step: 3
Training loss: 3.089751720428467
Validation loss: 2.878913382689158

Epoch: 5| Step: 4
Training loss: 3.831541061401367
Validation loss: 2.887001693248749

Epoch: 5| Step: 5
Training loss: 2.9555764198303223
Validation loss: 2.87296790877978

Epoch: 5| Step: 6
Training loss: 3.5041680335998535
Validation loss: 2.868052969376246

Epoch: 5| Step: 7
Training loss: 2.8739516735076904
Validation loss: 2.866535872220993

Epoch: 5| Step: 8
Training loss: 3.0093047618865967
Validation loss: 2.863062938054403

Epoch: 5| Step: 9
Training loss: 1.6794397830963135
Validation loss: 2.861230363448461

Epoch: 5| Step: 10
Training loss: 3.4517383575439453
Validation loss: 2.8586488167444863

Epoch: 5| Step: 11
Training loss: 3.463688611984253
Validation loss: 2.8574639658133187

Epoch: 41| Step: 0
Training loss: 2.922680377960205
Validation loss: 2.8514867623647056

Epoch: 5| Step: 1
Training loss: 3.2019340991973877
Validation loss: 2.8497261802355447

Epoch: 5| Step: 2
Training loss: 3.256493330001831
Validation loss: 2.8447970102230706

Epoch: 5| Step: 3
Training loss: 2.7260444164276123
Validation loss: 2.839709460735321

Epoch: 5| Step: 4
Training loss: 2.7797038555145264
Validation loss: 2.8358213802178702

Epoch: 5| Step: 5
Training loss: 3.67877459526062
Validation loss: 2.833707551161448

Epoch: 5| Step: 6
Training loss: 2.842311382293701
Validation loss: 2.831832786401113

Epoch: 5| Step: 7
Training loss: 3.3944644927978516
Validation loss: 2.8282729983329773

Epoch: 5| Step: 8
Training loss: 2.9961681365966797
Validation loss: 2.8293646474679313

Epoch: 5| Step: 9
Training loss: 3.1000735759735107
Validation loss: 2.827594111363093

Epoch: 5| Step: 10
Training loss: 2.859971523284912
Validation loss: 2.8257802923520408

Epoch: 5| Step: 11
Training loss: 1.6564302444458008
Validation loss: 2.8234675923983255

Epoch: 42| Step: 0
Training loss: 3.0744974613189697
Validation loss: 2.8155100643634796

Epoch: 5| Step: 1
Training loss: 2.3226213455200195
Validation loss: 2.8110840221246085

Epoch: 5| Step: 2
Training loss: 3.508327007293701
Validation loss: 2.8063861628373465

Epoch: 5| Step: 3
Training loss: 3.553931713104248
Validation loss: 2.8013699452082315

Epoch: 5| Step: 4
Training loss: 3.1079471111297607
Validation loss: 2.800524671872457

Epoch: 5| Step: 5
Training loss: 3.532130718231201
Validation loss: 2.796486725409826

Epoch: 5| Step: 6
Training loss: 2.475681781768799
Validation loss: 2.793508311112722

Epoch: 5| Step: 7
Training loss: 3.010260820388794
Validation loss: 2.791410048802694

Epoch: 5| Step: 8
Training loss: 3.2215499877929688
Validation loss: 2.7877645989259086

Epoch: 5| Step: 9
Training loss: 2.358457565307617
Validation loss: 2.7857958674430847

Epoch: 5| Step: 10
Training loss: 2.9769721031188965
Validation loss: 2.7834090987841287

Epoch: 5| Step: 11
Training loss: 2.641307830810547
Validation loss: 2.7820162574450173

Epoch: 43| Step: 0
Training loss: 3.1436586380004883
Validation loss: 2.776717950900396

Epoch: 5| Step: 1
Training loss: 3.1513826847076416
Validation loss: 2.772714505592982

Epoch: 5| Step: 2
Training loss: 3.0513179302215576
Validation loss: 2.771392305692037

Epoch: 5| Step: 3
Training loss: 2.3453896045684814
Validation loss: 2.7680996557076774

Epoch: 5| Step: 4
Training loss: 2.5743260383605957
Validation loss: 2.76553937792778

Epoch: 5| Step: 5
Training loss: 3.4634392261505127
Validation loss: 2.7625873585542045

Epoch: 5| Step: 6
Training loss: 2.635982036590576
Validation loss: 2.7601895232995353

Epoch: 5| Step: 7
Training loss: 3.27028226852417
Validation loss: 2.7570229868094125

Epoch: 5| Step: 8
Training loss: 2.8041651248931885
Validation loss: 2.7541004518667855

Epoch: 5| Step: 9
Training loss: 3.980762481689453
Validation loss: 2.752106895049413

Epoch: 5| Step: 10
Training loss: 2.403607130050659
Validation loss: 2.749036649862925

Epoch: 5| Step: 11
Training loss: 2.2141947746276855
Validation loss: 2.751167664925257

Epoch: 44| Step: 0
Training loss: 2.8472020626068115
Validation loss: 2.7719939947128296

Epoch: 5| Step: 1
Training loss: 3.1242616176605225
Validation loss: 2.7879651288191476

Epoch: 5| Step: 2
Training loss: 2.7906084060668945
Validation loss: 2.7440693378448486

Epoch: 5| Step: 3
Training loss: 2.9738688468933105
Validation loss: 2.7357586920261383

Epoch: 5| Step: 4
Training loss: 2.9050638675689697
Validation loss: 2.7316892544428506

Epoch: 5| Step: 5
Training loss: 2.9791080951690674
Validation loss: 2.7331613103548684

Epoch: 5| Step: 6
Training loss: 2.7565066814422607
Validation loss: 2.7318195601304374

Epoch: 5| Step: 7
Training loss: 3.1164939403533936
Validation loss: 2.7342600723107657

Epoch: 5| Step: 8
Training loss: 2.862450122833252
Validation loss: 2.7342545489470163

Epoch: 5| Step: 9
Training loss: 2.7489681243896484
Validation loss: 2.727877199649811

Epoch: 5| Step: 10
Training loss: 3.3007004261016846
Validation loss: 2.7245516975720725

Epoch: 5| Step: 11
Training loss: 3.0705347061157227
Validation loss: 2.7220798432826996

Epoch: 45| Step: 0
Training loss: 2.8753111362457275
Validation loss: 2.7167644103368125

Epoch: 5| Step: 1
Training loss: 2.688264846801758
Validation loss: 2.709710955619812

Epoch: 5| Step: 2
Training loss: 2.835347890853882
Validation loss: 2.709487567345301

Epoch: 5| Step: 3
Training loss: 2.4043986797332764
Validation loss: 2.702790836493174

Epoch: 5| Step: 4
Training loss: 2.92326021194458
Validation loss: 2.700190842151642

Epoch: 5| Step: 5
Training loss: 3.0223183631896973
Validation loss: 2.69734459122022

Epoch: 5| Step: 6
Training loss: 3.4562506675720215
Validation loss: 2.6945187052090964

Epoch: 5| Step: 7
Training loss: 2.807523488998413
Validation loss: 2.6931181947390237

Epoch: 5| Step: 8
Training loss: 2.9479122161865234
Validation loss: 2.6894174118836722

Epoch: 5| Step: 9
Training loss: 3.01314640045166
Validation loss: 2.6879207293192544

Epoch: 5| Step: 10
Training loss: 3.0372023582458496
Validation loss: 2.685784012079239

Epoch: 5| Step: 11
Training loss: 2.5972824096679688
Validation loss: 2.6871241132418313

Epoch: 46| Step: 0
Training loss: 2.391590118408203
Validation loss: 2.6764974693457284

Epoch: 5| Step: 1
Training loss: 3.261270046234131
Validation loss: 2.67893918355306

Epoch: 5| Step: 2
Training loss: 2.7720913887023926
Validation loss: 2.6789845327536264

Epoch: 5| Step: 3
Training loss: 2.934563398361206
Validation loss: 2.6726856927076974

Epoch: 5| Step: 4
Training loss: 2.0573649406433105
Validation loss: 2.6657195389270782

Epoch: 5| Step: 5
Training loss: 3.0741524696350098
Validation loss: 2.6645329892635345

Epoch: 5| Step: 6
Training loss: 2.723581552505493
Validation loss: 2.6636269291241965

Epoch: 5| Step: 7
Training loss: 2.728945255279541
Validation loss: 2.660951405763626

Epoch: 5| Step: 8
Training loss: 3.5175621509552
Validation loss: 2.658197209239006

Epoch: 5| Step: 9
Training loss: 2.8296923637390137
Validation loss: 2.6537436644236245

Epoch: 5| Step: 10
Training loss: 3.2410964965820312
Validation loss: 2.6522326370080314

Epoch: 5| Step: 11
Training loss: 2.9846160411834717
Validation loss: 2.649399161338806

Epoch: 47| Step: 0
Training loss: 2.644138813018799
Validation loss: 2.6470645864804587

Epoch: 5| Step: 1
Training loss: 2.449930191040039
Validation loss: 2.6450918118158975

Epoch: 5| Step: 2
Training loss: 3.0380187034606934
Validation loss: 2.643258899450302

Epoch: 5| Step: 3
Training loss: 2.558131694793701
Validation loss: 2.6399778922398887

Epoch: 5| Step: 4
Training loss: 2.9205985069274902
Validation loss: 2.6372190912564597

Epoch: 5| Step: 5
Training loss: 3.712059497833252
Validation loss: 2.63444255789121

Epoch: 5| Step: 6
Training loss: 3.232632875442505
Validation loss: 2.630774756272634

Epoch: 5| Step: 7
Training loss: 2.2967934608459473
Validation loss: 2.627645323673884

Epoch: 5| Step: 8
Training loss: 3.036893367767334
Validation loss: 2.622526784737905

Epoch: 5| Step: 9
Training loss: 2.71237850189209
Validation loss: 2.6208756864070892

Epoch: 5| Step: 10
Training loss: 2.5769991874694824
Validation loss: 2.6180091003576913

Epoch: 5| Step: 11
Training loss: 2.9862940311431885
Validation loss: 2.6156028111775718

Epoch: 48| Step: 0
Training loss: 2.528229236602783
Validation loss: 2.612921118736267

Epoch: 5| Step: 1
Training loss: 2.5207626819610596
Validation loss: 2.6172146002451577

Epoch: 5| Step: 2
Training loss: 2.551332473754883
Validation loss: 2.628685086965561

Epoch: 5| Step: 3
Training loss: 3.1790354251861572
Validation loss: 2.6371573408444724

Epoch: 5| Step: 4
Training loss: 3.141338586807251
Validation loss: 2.634884496529897

Epoch: 5| Step: 5
Training loss: 2.4366769790649414
Validation loss: 2.628304441769918

Epoch: 5| Step: 6
Training loss: 2.67724871635437
Validation loss: 2.624783754348755

Epoch: 5| Step: 7
Training loss: 2.9471380710601807
Validation loss: 2.6044112841288247

Epoch: 5| Step: 8
Training loss: 2.673144817352295
Validation loss: 2.593989630540212

Epoch: 5| Step: 9
Training loss: 3.147505283355713
Validation loss: 2.587064137061437

Epoch: 5| Step: 10
Training loss: 3.0769667625427246
Validation loss: 2.584639936685562

Epoch: 5| Step: 11
Training loss: 2.438509941101074
Validation loss: 2.581634283065796

Epoch: 49| Step: 0
Training loss: 3.2084145545959473
Validation loss: 2.5793367624282837

Epoch: 5| Step: 1
Training loss: 1.9146209955215454
Validation loss: 2.5739511450131736

Epoch: 5| Step: 2
Training loss: 2.947441577911377
Validation loss: 2.5779454906781516

Epoch: 5| Step: 3
Training loss: 2.6282341480255127
Validation loss: 2.5798919796943665

Epoch: 5| Step: 4
Training loss: 2.7276198863983154
Validation loss: 2.571953465541204

Epoch: 5| Step: 5
Training loss: 2.93363618850708
Validation loss: 2.5714514553546906

Epoch: 5| Step: 6
Training loss: 2.817986249923706
Validation loss: 2.571620007356008

Epoch: 5| Step: 7
Training loss: 2.8147692680358887
Validation loss: 2.5718767642974854

Epoch: 5| Step: 8
Training loss: 2.9202849864959717
Validation loss: 2.5699258744716644

Epoch: 5| Step: 9
Training loss: 2.7595977783203125
Validation loss: 2.564820090929667

Epoch: 5| Step: 10
Training loss: 2.9108221530914307
Validation loss: 2.557871093352636

Epoch: 5| Step: 11
Training loss: 1.8410570621490479
Validation loss: 2.552250454823176

Epoch: 50| Step: 0
Training loss: 2.4916634559631348
Validation loss: 2.547544151544571

Epoch: 5| Step: 1
Training loss: 2.8269553184509277
Validation loss: 2.54413303732872

Epoch: 5| Step: 2
Training loss: 2.9753918647766113
Validation loss: 2.5462829122940698

Epoch: 5| Step: 3
Training loss: 2.4857819080352783
Validation loss: 2.5410120288530984

Epoch: 5| Step: 4
Training loss: 2.6853175163269043
Validation loss: 2.5431807537873587

Epoch: 5| Step: 5
Training loss: 2.683901071548462
Validation loss: 2.5412897368272147

Epoch: 5| Step: 6
Training loss: 3.104336977005005
Validation loss: 2.538094679514567

Epoch: 5| Step: 7
Training loss: 2.6320197582244873
Validation loss: 2.537072310845057

Epoch: 5| Step: 8
Training loss: 3.0155582427978516
Validation loss: 2.5298028786977134

Epoch: 5| Step: 9
Training loss: 2.678976535797119
Validation loss: 2.529992570479711

Epoch: 5| Step: 10
Training loss: 2.5440163612365723
Validation loss: 2.525792956352234

Epoch: 5| Step: 11
Training loss: 2.5762085914611816
Validation loss: 2.525044689575831

Epoch: 51| Step: 0
Training loss: 2.041645050048828
Validation loss: 2.5193006694316864

Epoch: 5| Step: 1
Training loss: 2.7949957847595215
Validation loss: 2.519201159477234

Epoch: 5| Step: 2
Training loss: 3.298239231109619
Validation loss: 2.5160089830557504

Epoch: 5| Step: 3
Training loss: 2.6576056480407715
Validation loss: 2.512784630060196

Epoch: 5| Step: 4
Training loss: 2.318373680114746
Validation loss: 2.5029458552598953

Epoch: 5| Step: 5
Training loss: 2.7841968536376953
Validation loss: 2.505944455663363

Epoch: 5| Step: 6
Training loss: 2.6910276412963867
Validation loss: 2.505048304796219

Epoch: 5| Step: 7
Training loss: 2.531625270843506
Validation loss: 2.5039695352315903

Epoch: 5| Step: 8
Training loss: 2.9974365234375
Validation loss: 2.509749641021093

Epoch: 5| Step: 9
Training loss: 2.6001064777374268
Validation loss: 2.5059367020924888

Epoch: 5| Step: 10
Training loss: 3.393561601638794
Validation loss: 2.495289703210195

Epoch: 5| Step: 11
Training loss: 0.8461595177650452
Validation loss: 2.495123783747355

Epoch: 52| Step: 0
Training loss: 2.5631022453308105
Validation loss: 2.4941422442595163

Epoch: 5| Step: 1
Training loss: 2.6890902519226074
Validation loss: 2.500422408183416

Epoch: 5| Step: 2
Training loss: 2.9849953651428223
Validation loss: 2.498088777065277

Epoch: 5| Step: 3
Training loss: 3.2348570823669434
Validation loss: 2.494472881158193

Epoch: 5| Step: 4
Training loss: 2.1305317878723145
Validation loss: 2.487987200419108

Epoch: 5| Step: 5
Training loss: 3.0774168968200684
Validation loss: 2.4801659882068634

Epoch: 5| Step: 6
Training loss: 1.9888598918914795
Validation loss: 2.4805519034465155

Epoch: 5| Step: 7
Training loss: 2.250122547149658
Validation loss: 2.479467819134394

Epoch: 5| Step: 8
Training loss: 3.365645170211792
Validation loss: 2.475674420595169

Epoch: 5| Step: 9
Training loss: 2.5971174240112305
Validation loss: 2.47317698597908

Epoch: 5| Step: 10
Training loss: 2.566169261932373
Validation loss: 2.4732278933127723

Epoch: 5| Step: 11
Training loss: 2.6211867332458496
Validation loss: 2.4702283143997192

Epoch: 53| Step: 0
Training loss: 2.5370709896087646
Validation loss: 2.4614917983611426

Epoch: 5| Step: 1
Training loss: 2.576833724975586
Validation loss: 2.457865928610166

Epoch: 5| Step: 2
Training loss: 3.175373077392578
Validation loss: 2.455987870693207

Epoch: 5| Step: 3
Training loss: 2.54321551322937
Validation loss: 2.454126308361689

Epoch: 5| Step: 4
Training loss: 2.958819627761841
Validation loss: 2.4512703816095986

Epoch: 5| Step: 5
Training loss: 2.714250087738037
Validation loss: 2.4534707963466644

Epoch: 5| Step: 6
Training loss: 2.4312117099761963
Validation loss: 2.4492060840129852

Epoch: 5| Step: 7
Training loss: 2.1348114013671875
Validation loss: 2.4465762774149575

Epoch: 5| Step: 8
Training loss: 2.561694622039795
Validation loss: 2.445371319850286

Epoch: 5| Step: 9
Training loss: 2.717613697052002
Validation loss: 2.444107472896576

Epoch: 5| Step: 10
Training loss: 2.6645374298095703
Validation loss: 2.43315127491951

Epoch: 5| Step: 11
Training loss: 2.6230647563934326
Validation loss: 2.436849762996038

Epoch: 54| Step: 0
Training loss: 3.019629716873169
Validation loss: 2.4292714595794678

Epoch: 5| Step: 1
Training loss: 2.223672866821289
Validation loss: 2.4311618407567344

Epoch: 5| Step: 2
Training loss: 2.6161656379699707
Validation loss: 2.4284250140190125

Epoch: 5| Step: 3
Training loss: 2.505972385406494
Validation loss: 2.427452802658081

Epoch: 5| Step: 4
Training loss: 3.185173988342285
Validation loss: 2.428932319084803

Epoch: 5| Step: 5
Training loss: 2.557372808456421
Validation loss: 2.423427244027456

Epoch: 5| Step: 6
Training loss: 2.567289352416992
Validation loss: 2.423821489016215

Epoch: 5| Step: 7
Training loss: 2.580173969268799
Validation loss: 2.4198206861813865

Epoch: 5| Step: 8
Training loss: 2.469245195388794
Validation loss: 2.415780618786812

Epoch: 5| Step: 9
Training loss: 2.5694797039031982
Validation loss: 2.4099028756221137

Epoch: 5| Step: 10
Training loss: 2.25083589553833
Validation loss: 2.4065248370170593

Epoch: 5| Step: 11
Training loss: 3.3154311180114746
Validation loss: 2.408028612534205

Epoch: 55| Step: 0
Training loss: 2.5373401641845703
Validation loss: 2.4011095464229584

Epoch: 5| Step: 1
Training loss: 2.6533195972442627
Validation loss: 2.401256412267685

Epoch: 5| Step: 2
Training loss: 2.470522880554199
Validation loss: 2.399515708287557

Epoch: 5| Step: 3
Training loss: 2.699345350265503
Validation loss: 2.405216629306475

Epoch: 5| Step: 4
Training loss: 2.969907283782959
Validation loss: 2.3946653008461

Epoch: 5| Step: 5
Training loss: 2.7489027976989746
Validation loss: 2.3942138652006784

Epoch: 5| Step: 6
Training loss: 2.3689005374908447
Validation loss: 2.3839159260193505

Epoch: 5| Step: 7
Training loss: 1.6763643026351929
Validation loss: 2.388062447309494

Epoch: 5| Step: 8
Training loss: 2.387073516845703
Validation loss: 2.3875612119833627

Epoch: 5| Step: 9
Training loss: 2.7930614948272705
Validation loss: 2.3872186640898385

Epoch: 5| Step: 10
Training loss: 2.892148017883301
Validation loss: 2.38335249821345

Epoch: 5| Step: 11
Training loss: 3.0080788135528564
Validation loss: 2.379879891872406

Epoch: 56| Step: 0
Training loss: 2.7875332832336426
Validation loss: 2.3707258800665536

Epoch: 5| Step: 1
Training loss: 2.4113359451293945
Validation loss: 2.3709393640359244

Epoch: 5| Step: 2
Training loss: 2.743175983428955
Validation loss: 2.370192900300026

Epoch: 5| Step: 3
Training loss: 2.2835049629211426
Validation loss: 2.3633958995342255

Epoch: 5| Step: 4
Training loss: 2.8609728813171387
Validation loss: 2.365047092239062

Epoch: 5| Step: 5
Training loss: 2.2535994052886963
Validation loss: 2.3644130478302636

Epoch: 5| Step: 6
Training loss: 2.449070930480957
Validation loss: 2.359936232368151

Epoch: 5| Step: 7
Training loss: 2.5516655445098877
Validation loss: 2.3599172135194144

Epoch: 5| Step: 8
Training loss: 2.968308210372925
Validation loss: 2.359757214784622

Epoch: 5| Step: 9
Training loss: 2.137504816055298
Validation loss: 2.351416359345118

Epoch: 5| Step: 10
Training loss: 2.3605217933654785
Validation loss: 2.347772032022476

Epoch: 5| Step: 11
Training loss: 3.1464014053344727
Validation loss: 2.3516174058119454

Epoch: 57| Step: 0
Training loss: 2.7580301761627197
Validation loss: 2.3478806018829346

Epoch: 5| Step: 1
Training loss: 2.489448070526123
Validation loss: 2.3477430939674377

Epoch: 5| Step: 2
Training loss: 2.1503548622131348
Validation loss: 2.3452762564023337

Epoch: 5| Step: 3
Training loss: 2.236254930496216
Validation loss: 2.340206488966942

Epoch: 5| Step: 4
Training loss: 3.305415391921997
Validation loss: 2.341677417357763

Epoch: 5| Step: 5
Training loss: 2.4473061561584473
Validation loss: 2.33613354464372

Epoch: 5| Step: 6
Training loss: 2.5665063858032227
Validation loss: 2.3331877887248993

Epoch: 5| Step: 7
Training loss: 2.2903451919555664
Validation loss: 2.3333510061105094

Epoch: 5| Step: 8
Training loss: 2.8331799507141113
Validation loss: 2.3297070264816284

Epoch: 5| Step: 9
Training loss: 2.203439235687256
Validation loss: 2.3231510718663535

Epoch: 5| Step: 10
Training loss: 2.6190402507781982
Validation loss: 2.328160305817922

Epoch: 5| Step: 11
Training loss: 0.9901378750801086
Validation loss: 2.3267882168293

Epoch: 58| Step: 0
Training loss: 2.2143940925598145
Validation loss: 2.3214034785827002

Epoch: 5| Step: 1
Training loss: 2.5043997764587402
Validation loss: 2.318022146821022

Epoch: 5| Step: 2
Training loss: 2.7859621047973633
Validation loss: 2.315976858139038

Epoch: 5| Step: 3
Training loss: 2.5940327644348145
Validation loss: 2.316938946644465

Epoch: 5| Step: 4
Training loss: 2.7439448833465576
Validation loss: 2.3190756738185883

Epoch: 5| Step: 5
Training loss: 2.4641308784484863
Validation loss: 2.3107800483703613

Epoch: 5| Step: 6
Training loss: 2.403776168823242
Validation loss: 2.309789424141248

Epoch: 5| Step: 7
Training loss: 2.893228054046631
Validation loss: 2.303892955183983

Epoch: 5| Step: 8
Training loss: 1.8803927898406982
Validation loss: 2.306573897600174

Epoch: 5| Step: 9
Training loss: 2.574889659881592
Validation loss: 2.3051093965768814

Epoch: 5| Step: 10
Training loss: 2.2139339447021484
Validation loss: 2.305596560239792

Epoch: 5| Step: 11
Training loss: 2.5196027755737305
Validation loss: 2.300535877545675

Epoch: 59| Step: 0
Training loss: 3.3545024394989014
Validation loss: 2.296240667502085

Epoch: 5| Step: 1
Training loss: 2.7273125648498535
Validation loss: 2.2944984336694083

Epoch: 5| Step: 2
Training loss: 2.1227378845214844
Validation loss: 2.290873567263285

Epoch: 5| Step: 3
Training loss: 2.2999653816223145
Validation loss: 2.2906270921230316

Epoch: 5| Step: 4
Training loss: 2.664440631866455
Validation loss: 2.289676388104757

Epoch: 5| Step: 5
Training loss: 2.0885913372039795
Validation loss: 2.2840368946393332

Epoch: 5| Step: 6
Training loss: 2.473628044128418
Validation loss: 2.2883575558662415

Epoch: 5| Step: 7
Training loss: 2.181999683380127
Validation loss: 2.2816880345344543

Epoch: 5| Step: 8
Training loss: 2.4080452919006348
Validation loss: 2.282505919535955

Epoch: 5| Step: 9
Training loss: 2.340812921524048
Validation loss: 2.285472015539805

Epoch: 5| Step: 10
Training loss: 2.535599708557129
Validation loss: 2.27296249071757

Epoch: 5| Step: 11
Training loss: 1.1867293119430542
Validation loss: 2.2772939602533975

Epoch: 60| Step: 0
Training loss: 2.087280035018921
Validation loss: 2.2725943624973297

Epoch: 5| Step: 1
Training loss: 3.1436734199523926
Validation loss: 2.2799744059642157

Epoch: 5| Step: 2
Training loss: 2.5184078216552734
Validation loss: 2.2726117273171744

Epoch: 5| Step: 3
Training loss: 2.231999397277832
Validation loss: 2.2710305551687875

Epoch: 5| Step: 4
Training loss: 2.820317268371582
Validation loss: 2.2670099635918937

Epoch: 5| Step: 5
Training loss: 2.1365952491760254
Validation loss: 2.2689447899659476

Epoch: 5| Step: 6
Training loss: 2.5946972370147705
Validation loss: 2.2685233851273856

Epoch: 5| Step: 7
Training loss: 2.212846517562866
Validation loss: 2.258029649655024

Epoch: 5| Step: 8
Training loss: 2.371760368347168
Validation loss: 2.2577797869841256

Epoch: 5| Step: 9
Training loss: 1.8661556243896484
Validation loss: 2.2574362655480704

Epoch: 5| Step: 10
Training loss: 2.6030824184417725
Validation loss: 2.256388703982035

Epoch: 5| Step: 11
Training loss: 2.848644971847534
Validation loss: 2.252462536096573

Epoch: 61| Step: 0
Training loss: 2.4648091793060303
Validation loss: 2.2534758001565933

Epoch: 5| Step: 1
Training loss: 1.859910011291504
Validation loss: 2.2518254965543747

Epoch: 5| Step: 2
Training loss: 2.1041061878204346
Validation loss: 2.2483635346094766

Epoch: 5| Step: 3
Training loss: 2.135800838470459
Validation loss: 2.2492623031139374

Epoch: 5| Step: 4
Training loss: 2.4647912979125977
Validation loss: 2.246127794186274

Epoch: 5| Step: 5
Training loss: 2.5505928993225098
Validation loss: 2.2464215755462646

Epoch: 5| Step: 6
Training loss: 2.4247360229492188
Validation loss: 2.250865012407303

Epoch: 5| Step: 7
Training loss: 2.7613956928253174
Validation loss: 2.2350798149903617

Epoch: 5| Step: 8
Training loss: 2.899402141571045
Validation loss: 2.2358893851439157

Epoch: 5| Step: 9
Training loss: 2.497804641723633
Validation loss: 2.227965255578359

Epoch: 5| Step: 10
Training loss: 2.2606539726257324
Validation loss: 2.2328284482161203

Epoch: 5| Step: 11
Training loss: 2.5981192588806152
Validation loss: 2.2302370071411133

Epoch: 62| Step: 0
Training loss: 2.4635422229766846
Validation loss: 2.2305154353380203

Epoch: 5| Step: 1
Training loss: 2.123140335083008
Validation loss: 2.2251402040322623

Epoch: 5| Step: 2
Training loss: 2.3407418727874756
Validation loss: 2.226577748854955

Epoch: 5| Step: 3
Training loss: 2.524900436401367
Validation loss: 2.2313012133042016

Epoch: 5| Step: 4
Training loss: 2.0535166263580322
Validation loss: 2.236368546883265

Epoch: 5| Step: 5
Training loss: 2.226769208908081
Validation loss: 2.2391256392002106

Epoch: 5| Step: 6
Training loss: 2.062716245651245
Validation loss: 2.224567631880442

Epoch: 5| Step: 7
Training loss: 2.6922402381896973
Validation loss: 2.2136090695858

Epoch: 5| Step: 8
Training loss: 2.807631254196167
Validation loss: 2.2181945194800696

Epoch: 5| Step: 9
Training loss: 2.752087116241455
Validation loss: 2.218704183896383

Epoch: 5| Step: 10
Training loss: 2.0278496742248535
Validation loss: 2.220710277557373

Epoch: 5| Step: 11
Training loss: 3.5712199211120605
Validation loss: 2.222827225923538

Epoch: 63| Step: 0
Training loss: 1.8919872045516968
Validation loss: 2.220734715461731

Epoch: 5| Step: 1
Training loss: 1.8600635528564453
Validation loss: 2.2188484917084375

Epoch: 5| Step: 2
Training loss: 2.8176305294036865
Validation loss: 2.209490974744161

Epoch: 5| Step: 3
Training loss: 2.831172227859497
Validation loss: 2.210612873236338

Epoch: 5| Step: 4
Training loss: 2.1076974868774414
Validation loss: 2.2110136846701303

Epoch: 5| Step: 5
Training loss: 2.5900607109069824
Validation loss: 2.21297221382459

Epoch: 5| Step: 6
Training loss: 2.569308280944824
Validation loss: 2.20339568456014

Epoch: 5| Step: 7
Training loss: 2.39516019821167
Validation loss: 2.2003847559293113

Epoch: 5| Step: 8
Training loss: 2.217080593109131
Validation loss: 2.197310929497083

Epoch: 5| Step: 9
Training loss: 2.2093708515167236
Validation loss: 2.2000998904307685

Epoch: 5| Step: 10
Training loss: 2.4905340671539307
Validation loss: 2.1953043341636658

Epoch: 5| Step: 11
Training loss: 2.7797601222991943
Validation loss: 2.194393744071325

Epoch: 64| Step: 0
Training loss: 2.790085554122925
Validation loss: 2.193477993210157

Epoch: 5| Step: 1
Training loss: 2.8160436153411865
Validation loss: 2.193393131097158

Epoch: 5| Step: 2
Training loss: 2.1746654510498047
Validation loss: 2.187538052598635

Epoch: 5| Step: 3
Training loss: 2.525670051574707
Validation loss: 2.1875567932923636

Epoch: 5| Step: 4
Training loss: 1.7435566186904907
Validation loss: 2.1865709722042084

Epoch: 5| Step: 5
Training loss: 2.1047232151031494
Validation loss: 2.1834306021531424

Epoch: 5| Step: 6
Training loss: 2.1930654048919678
Validation loss: 2.1796886076529822

Epoch: 5| Step: 7
Training loss: 2.5900678634643555
Validation loss: 2.181244964400927

Epoch: 5| Step: 8
Training loss: 2.2855255603790283
Validation loss: 2.1699889451265335

Epoch: 5| Step: 9
Training loss: 1.9584872722625732
Validation loss: 2.166657507419586

Epoch: 5| Step: 10
Training loss: 2.412304401397705
Validation loss: 2.17234875758489

Epoch: 5| Step: 11
Training loss: 2.729217529296875
Validation loss: 2.170111949245135

Epoch: 65| Step: 0
Training loss: 2.0100626945495605
Validation loss: 2.169544756412506

Epoch: 5| Step: 1
Training loss: 2.505831241607666
Validation loss: 2.1679972211519876

Epoch: 5| Step: 2
Training loss: 1.683148980140686
Validation loss: 2.176325961947441

Epoch: 5| Step: 3
Training loss: 2.122502565383911
Validation loss: 2.1706482271353402

Epoch: 5| Step: 4
Training loss: 2.3518357276916504
Validation loss: 2.166781877477964

Epoch: 5| Step: 5
Training loss: 2.527073383331299
Validation loss: 2.1673865020275116

Epoch: 5| Step: 6
Training loss: 2.4403786659240723
Validation loss: 2.1626032988230386

Epoch: 5| Step: 7
Training loss: 2.4822893142700195
Validation loss: 2.160828024148941

Epoch: 5| Step: 8
Training loss: 2.6483054161071777
Validation loss: 2.1590413103501

Epoch: 5| Step: 9
Training loss: 2.6232924461364746
Validation loss: 2.159465491771698

Epoch: 5| Step: 10
Training loss: 2.168379068374634
Validation loss: 2.163915902376175

Epoch: 5| Step: 11
Training loss: 2.029592514038086
Validation loss: 2.160236676534017

Epoch: 66| Step: 0
Training loss: 2.6565213203430176
Validation loss: 2.166745960712433

Epoch: 5| Step: 1
Training loss: 2.344066619873047
Validation loss: 2.1682543655236564

Epoch: 5| Step: 2
Training loss: 2.260002613067627
Validation loss: 2.166265979409218

Epoch: 5| Step: 3
Training loss: 2.4885287284851074
Validation loss: 2.1607637206713357

Epoch: 5| Step: 4
Training loss: 2.021348237991333
Validation loss: 2.170044630765915

Epoch: 5| Step: 5
Training loss: 1.930746078491211
Validation loss: 2.1690566738446555

Epoch: 5| Step: 6
Training loss: 2.3298680782318115
Validation loss: 2.159749855597814

Epoch: 5| Step: 7
Training loss: 2.460596799850464
Validation loss: 2.1521740754445395

Epoch: 5| Step: 8
Training loss: 2.256815195083618
Validation loss: 2.147039830684662

Epoch: 5| Step: 9
Training loss: 2.299727201461792
Validation loss: 2.1534986148277917

Epoch: 5| Step: 10
Training loss: 2.372462511062622
Validation loss: 2.1617601017157235

Epoch: 5| Step: 11
Training loss: 2.0976126194000244
Validation loss: 2.16427543759346

Epoch: 67| Step: 0
Training loss: 2.731031656265259
Validation loss: 2.1675740083058677

Epoch: 5| Step: 1
Training loss: 1.9243570566177368
Validation loss: 2.171781818072001

Epoch: 5| Step: 2
Training loss: 2.3436837196350098
Validation loss: 2.1679726938406625

Epoch: 5| Step: 3
Training loss: 2.6325080394744873
Validation loss: 2.1640406052271524

Epoch: 5| Step: 4
Training loss: 2.8472931385040283
Validation loss: 2.1479380279779434

Epoch: 5| Step: 5
Training loss: 2.006962299346924
Validation loss: 2.1427723417679467

Epoch: 5| Step: 6
Training loss: 1.7202190160751343
Validation loss: 2.142906511823336

Epoch: 5| Step: 7
Training loss: 2.15863037109375
Validation loss: 2.13008913397789

Epoch: 5| Step: 8
Training loss: 2.1023764610290527
Validation loss: 2.137821912765503

Epoch: 5| Step: 9
Training loss: 2.059544801712036
Validation loss: 2.1325070609649024

Epoch: 5| Step: 10
Training loss: 2.4698657989501953
Validation loss: 2.1311541001001992

Epoch: 5| Step: 11
Training loss: 3.9065160751342773
Validation loss: 2.1271438797314963

Epoch: 68| Step: 0
Training loss: 1.9297304153442383
Validation loss: 2.132167478402456

Epoch: 5| Step: 1
Training loss: 2.7512686252593994
Validation loss: 2.145203948020935

Epoch: 5| Step: 2
Training loss: 1.7381923198699951
Validation loss: 2.1442684531211853

Epoch: 5| Step: 3
Training loss: 2.5525691509246826
Validation loss: 2.129695604244868

Epoch: 5| Step: 4
Training loss: 2.3823494911193848
Validation loss: 2.12629763285319

Epoch: 5| Step: 5
Training loss: 2.4882044792175293
Validation loss: 2.1256211499373117

Epoch: 5| Step: 6
Training loss: 2.567377805709839
Validation loss: 2.1276917358239493

Epoch: 5| Step: 7
Training loss: 2.601558208465576
Validation loss: 2.1161552518606186

Epoch: 5| Step: 8
Training loss: 2.226675033569336
Validation loss: 2.117238392432531

Epoch: 5| Step: 9
Training loss: 1.8955252170562744
Validation loss: 2.1219744135936103

Epoch: 5| Step: 10
Training loss: 1.866119623184204
Validation loss: 2.1207271118958793

Epoch: 5| Step: 11
Training loss: 3.039652109146118
Validation loss: 2.119075799981753

Epoch: 69| Step: 0
Training loss: 2.2598228454589844
Validation loss: 2.1153592616319656

Epoch: 5| Step: 1
Training loss: 2.178542137145996
Validation loss: 2.1173838476339975

Epoch: 5| Step: 2
Training loss: 2.5474283695220947
Validation loss: 2.121754984060923

Epoch: 5| Step: 3
Training loss: 2.4678425788879395
Validation loss: 2.120019127925237

Epoch: 5| Step: 4
Training loss: 2.0245351791381836
Validation loss: 2.1165432830651603

Epoch: 5| Step: 5
Training loss: 1.8681285381317139
Validation loss: 2.112431893746058

Epoch: 5| Step: 6
Training loss: 2.087999105453491
Validation loss: 2.112810800472895

Epoch: 5| Step: 7
Training loss: 2.367997169494629
Validation loss: 2.1131369123856225

Epoch: 5| Step: 8
Training loss: 1.9538466930389404
Validation loss: 2.1052412390708923

Epoch: 5| Step: 9
Training loss: 3.1106040477752686
Validation loss: 2.103502626220385

Epoch: 5| Step: 10
Training loss: 2.131030797958374
Validation loss: 2.101409529646238

Epoch: 5| Step: 11
Training loss: 2.2686080932617188
Validation loss: 2.1085961759090424

Epoch: 70| Step: 0
Training loss: 2.227098226547241
Validation loss: 2.121142024795214

Epoch: 5| Step: 1
Training loss: 1.9867732524871826
Validation loss: 2.1155884712934494

Epoch: 5| Step: 2
Training loss: 1.979257583618164
Validation loss: 2.11734502017498

Epoch: 5| Step: 3
Training loss: 2.06764554977417
Validation loss: 2.1201954185962677

Epoch: 5| Step: 4
Training loss: 2.2760226726531982
Validation loss: 2.1303189794222512

Epoch: 5| Step: 5
Training loss: 2.528871536254883
Validation loss: 2.1170564591884613

Epoch: 5| Step: 6
Training loss: 2.6685779094696045
Validation loss: 2.1048351377248764

Epoch: 5| Step: 7
Training loss: 2.422823190689087
Validation loss: 2.1001633455355964

Epoch: 5| Step: 8
Training loss: 2.1419501304626465
Validation loss: 2.1049212912718454

Epoch: 5| Step: 9
Training loss: 1.8710225820541382
Validation loss: 2.091226359208425

Epoch: 5| Step: 10
Training loss: 2.5541739463806152
Validation loss: 2.0919481416543326

Epoch: 5| Step: 11
Training loss: 3.263181686401367
Validation loss: 2.0989854484796524

Epoch: 71| Step: 0
Training loss: 1.8945926427841187
Validation loss: 2.1045639564593634

Epoch: 5| Step: 1
Training loss: 2.9501426219940186
Validation loss: 2.112808202703794

Epoch: 5| Step: 2
Training loss: 2.327145576477051
Validation loss: 2.11031574010849

Epoch: 5| Step: 3
Training loss: 2.349257230758667
Validation loss: 2.117306480805079

Epoch: 5| Step: 4
Training loss: 2.421539306640625
Validation loss: 2.1236088226238885

Epoch: 5| Step: 5
Training loss: 2.602247714996338
Validation loss: 2.125425616900126

Epoch: 5| Step: 6
Training loss: 1.9244778156280518
Validation loss: 2.1226914525032043

Epoch: 5| Step: 7
Training loss: 2.204066276550293
Validation loss: 2.1215743919213614

Epoch: 5| Step: 8
Training loss: 2.5247490406036377
Validation loss: 2.124432841936747

Epoch: 5| Step: 9
Training loss: 1.859937310218811
Validation loss: 2.118588924407959

Epoch: 5| Step: 10
Training loss: 2.286583185195923
Validation loss: 2.1142882108688354

Epoch: 5| Step: 11
Training loss: 1.3912538290023804
Validation loss: 2.1108591904242835

Epoch: 72| Step: 0
Training loss: 2.4264538288116455
Validation loss: 2.1068866352240243

Epoch: 5| Step: 1
Training loss: 2.8235881328582764
Validation loss: 2.096351300676664

Epoch: 5| Step: 2
Training loss: 1.8353325128555298
Validation loss: 2.1002304951349893

Epoch: 5| Step: 3
Training loss: 2.350672960281372
Validation loss: 2.094551165898641

Epoch: 5| Step: 4
Training loss: 2.469616413116455
Validation loss: 2.0904323856035867

Epoch: 5| Step: 5
Training loss: 1.5816949605941772
Validation loss: 2.0917134235302606

Epoch: 5| Step: 6
Training loss: 2.17557954788208
Validation loss: 2.087039848168691

Epoch: 5| Step: 7
Training loss: 2.517054319381714
Validation loss: 2.083027179042498

Epoch: 5| Step: 8
Training loss: 2.12395977973938
Validation loss: 2.0786200761795044

Epoch: 5| Step: 9
Training loss: 2.7012035846710205
Validation loss: 2.0822080125411353

Epoch: 5| Step: 10
Training loss: 1.580726146697998
Validation loss: 2.0857291320959725

Epoch: 5| Step: 11
Training loss: 3.492033004760742
Validation loss: 2.08893691500028

Epoch: 73| Step: 0
Training loss: 2.252716064453125
Validation loss: 2.0846238881349564

Epoch: 5| Step: 1
Training loss: 2.4588723182678223
Validation loss: 2.0910673638184867

Epoch: 5| Step: 2
Training loss: 2.4940645694732666
Validation loss: 2.0923162202040353

Epoch: 5| Step: 3
Training loss: 1.7824468612670898
Validation loss: 2.0870559761921563

Epoch: 5| Step: 4
Training loss: 2.249772548675537
Validation loss: 2.093945244948069

Epoch: 5| Step: 5
Training loss: 2.032365322113037
Validation loss: 2.0857498000065484

Epoch: 5| Step: 6
Training loss: 1.9185755252838135
Validation loss: 2.08700958887736

Epoch: 5| Step: 7
Training loss: 2.329317808151245
Validation loss: 2.0796283781528473

Epoch: 5| Step: 8
Training loss: 1.84821355342865
Validation loss: 2.080108195543289

Epoch: 5| Step: 9
Training loss: 2.6270577907562256
Validation loss: 2.0893268287181854

Epoch: 5| Step: 10
Training loss: 2.535301685333252
Validation loss: 2.0722919156154

Epoch: 5| Step: 11
Training loss: 2.5520057678222656
Validation loss: 2.072834014892578

Epoch: 74| Step: 0
Training loss: 2.530423641204834
Validation loss: 2.0855919222036996

Epoch: 5| Step: 1
Training loss: 2.0089590549468994
Validation loss: 2.0897999753554664

Epoch: 5| Step: 2
Training loss: 2.2006473541259766
Validation loss: 2.102609023451805

Epoch: 5| Step: 3
Training loss: 2.084327220916748
Validation loss: 2.1235815634330115

Epoch: 5| Step: 4
Training loss: 1.7538923025131226
Validation loss: 2.1441098848978677

Epoch: 5| Step: 5
Training loss: 2.6314005851745605
Validation loss: 2.1602633049090705

Epoch: 5| Step: 6
Training loss: 2.5580248832702637
Validation loss: 2.1675842801729837

Epoch: 5| Step: 7
Training loss: 2.3132002353668213
Validation loss: 2.1727396150430045

Epoch: 5| Step: 8
Training loss: 2.2769830226898193
Validation loss: 2.173772315184275

Epoch: 5| Step: 9
Training loss: 2.735167980194092
Validation loss: 2.167155315478643

Epoch: 5| Step: 10
Training loss: 2.2808587551116943
Validation loss: 2.1554449995358786

Epoch: 5| Step: 11
Training loss: 2.9405269622802734
Validation loss: 2.1390754034121833

Epoch: 75| Step: 0
Training loss: 2.2821860313415527
Validation loss: 2.124730999271075

Epoch: 5| Step: 1
Training loss: 2.447862386703491
Validation loss: 2.115272427598635

Epoch: 5| Step: 2
Training loss: 2.8008806705474854
Validation loss: 2.105861951907476

Epoch: 5| Step: 3
Training loss: 2.351527452468872
Validation loss: 2.0992280592521033

Epoch: 5| Step: 4
Training loss: 1.4305191040039062
Validation loss: 2.089932998021444

Epoch: 5| Step: 5
Training loss: 2.6530513763427734
Validation loss: 2.087997312347094

Epoch: 5| Step: 6
Training loss: 1.8382179737091064
Validation loss: 2.0816216468811035

Epoch: 5| Step: 7
Training loss: 2.3539071083068848
Validation loss: 2.075803895791372

Epoch: 5| Step: 8
Training loss: 2.319518566131592
Validation loss: 2.072906399766604

Epoch: 5| Step: 9
Training loss: 2.5437374114990234
Validation loss: 2.0658588856458664

Epoch: 5| Step: 10
Training loss: 2.142057418823242
Validation loss: 2.070100540916125

Epoch: 5| Step: 11
Training loss: 1.294113278388977
Validation loss: 2.071720232566198

Epoch: 76| Step: 0
Training loss: 2.3088769912719727
Validation loss: 2.0737920304139457

Epoch: 5| Step: 1
Training loss: 2.1167469024658203
Validation loss: 2.0812705953915915

Epoch: 5| Step: 2
Training loss: 2.0153584480285645
Validation loss: 2.0875266194343567

Epoch: 5| Step: 3
Training loss: 1.9524128437042236
Validation loss: 2.087351620197296

Epoch: 5| Step: 4
Training loss: 2.4421839714050293
Validation loss: 2.0839970409870148

Epoch: 5| Step: 5
Training loss: 2.860610246658325
Validation loss: 2.090307593345642

Epoch: 5| Step: 6
Training loss: 1.9138176441192627
Validation loss: 2.077709118525187

Epoch: 5| Step: 7
Training loss: 2.36157488822937
Validation loss: 2.0718300541241965

Epoch: 5| Step: 8
Training loss: 2.512467622756958
Validation loss: 2.067666416366895

Epoch: 5| Step: 9
Training loss: 1.9840991497039795
Validation loss: 2.0578692704439163

Epoch: 5| Step: 10
Training loss: 2.0876471996307373
Validation loss: 2.0633989026149115

Epoch: 5| Step: 11
Training loss: 2.4326677322387695
Validation loss: 2.064631779988607

Epoch: 77| Step: 0
Training loss: 2.1186389923095703
Validation loss: 2.063224862019221

Epoch: 5| Step: 1
Training loss: 1.8076345920562744
Validation loss: 2.0616597483555474

Epoch: 5| Step: 2
Training loss: 2.61557936668396
Validation loss: 2.0579738169908524

Epoch: 5| Step: 3
Training loss: 2.4101243019104004
Validation loss: 2.0502306123574576

Epoch: 5| Step: 4
Training loss: 2.3366236686706543
Validation loss: 2.0497678170601525

Epoch: 5| Step: 5
Training loss: 2.177217960357666
Validation loss: 2.0521891166766486

Epoch: 5| Step: 6
Training loss: 1.6981693506240845
Validation loss: 2.054801712433497

Epoch: 5| Step: 7
Training loss: 2.4672443866729736
Validation loss: 2.0450757294893265

Epoch: 5| Step: 8
Training loss: 2.0812559127807617
Validation loss: 2.051601196328799

Epoch: 5| Step: 9
Training loss: 1.924997091293335
Validation loss: 2.0505681733290353

Epoch: 5| Step: 10
Training loss: 2.5875072479248047
Validation loss: 2.040595680475235

Epoch: 5| Step: 11
Training loss: 3.4072768688201904
Validation loss: 2.045156553387642

Epoch: 78| Step: 0
Training loss: 2.1142239570617676
Validation loss: 2.0490826616684594

Epoch: 5| Step: 1
Training loss: 2.456381320953369
Validation loss: 2.0608291774988174

Epoch: 5| Step: 2
Training loss: 2.2006213665008545
Validation loss: 2.0530602633953094

Epoch: 5| Step: 3
Training loss: 2.17738938331604
Validation loss: 2.058892364303271

Epoch: 5| Step: 4
Training loss: 2.3844211101531982
Validation loss: 2.0578787326812744

Epoch: 5| Step: 5
Training loss: 2.3721814155578613
Validation loss: 2.0546471923589706

Epoch: 5| Step: 6
Training loss: 2.0887210369110107
Validation loss: 2.05170401930809

Epoch: 5| Step: 7
Training loss: 2.025873899459839
Validation loss: 2.036380077401797

Epoch: 5| Step: 8
Training loss: 2.188046932220459
Validation loss: 2.037652482589086

Epoch: 5| Step: 9
Training loss: 2.299367904663086
Validation loss: 2.0359529654184976

Epoch: 5| Step: 10
Training loss: 2.0991051197052
Validation loss: 2.0432567646106086

Epoch: 5| Step: 11
Training loss: 2.175635814666748
Validation loss: 2.043555031220118

Epoch: 79| Step: 0
Training loss: 2.232785701751709
Validation loss: 2.04721100628376

Epoch: 5| Step: 1
Training loss: 1.8926804065704346
Validation loss: 2.044497326016426

Epoch: 5| Step: 2
Training loss: 2.1632378101348877
Validation loss: 2.0492995282014212

Epoch: 5| Step: 3
Training loss: 2.4862565994262695
Validation loss: 2.045080691576004

Epoch: 5| Step: 4
Training loss: 1.679015874862671
Validation loss: 2.0373221039772034

Epoch: 5| Step: 5
Training loss: 2.4107086658477783
Validation loss: 2.040262987216314

Epoch: 5| Step: 6
Training loss: 2.0022025108337402
Validation loss: 2.042171930273374

Epoch: 5| Step: 7
Training loss: 2.2832674980163574
Validation loss: 2.0407705704371133

Epoch: 5| Step: 8
Training loss: 2.4872610569000244
Validation loss: 2.046593894561132

Epoch: 5| Step: 9
Training loss: 2.625866413116455
Validation loss: 2.049044946829478

Epoch: 5| Step: 10
Training loss: 2.0034549236297607
Validation loss: 2.0504213819901147

Epoch: 5| Step: 11
Training loss: 2.4820590019226074
Validation loss: 2.0456279714902244

Epoch: 80| Step: 0
Training loss: 2.4477531909942627
Validation loss: 2.042436753710111

Epoch: 5| Step: 1
Training loss: 2.286517381668091
Validation loss: 2.0389363020658493

Epoch: 5| Step: 2
Training loss: 2.0771121978759766
Validation loss: 2.029681980609894

Epoch: 5| Step: 3
Training loss: 2.570927143096924
Validation loss: 2.0392761528491974

Epoch: 5| Step: 4
Training loss: 2.590916156768799
Validation loss: 2.0430989414453506

Epoch: 5| Step: 5
Training loss: 1.635873794555664
Validation loss: 2.0372679134209952

Epoch: 5| Step: 6
Training loss: 1.6030536890029907
Validation loss: 2.038499742746353

Epoch: 5| Step: 7
Training loss: 2.107713222503662
Validation loss: 2.0420071681340537

Epoch: 5| Step: 8
Training loss: 2.539146900177002
Validation loss: 2.067291503151258

Epoch: 5| Step: 9
Training loss: 2.051666021347046
Validation loss: 2.0732374687989554

Epoch: 5| Step: 10
Training loss: 2.034064531326294
Validation loss: 2.071012715498606

Epoch: 5| Step: 11
Training loss: 3.8156158924102783
Validation loss: 2.063895583152771

Epoch: 81| Step: 0
Training loss: 2.7641749382019043
Validation loss: 2.063695897658666

Epoch: 5| Step: 1
Training loss: 2.5483999252319336
Validation loss: 2.0635683635870614

Epoch: 5| Step: 2
Training loss: 1.3172839879989624
Validation loss: 2.0680240939060845

Epoch: 5| Step: 3
Training loss: 2.0964913368225098
Validation loss: 2.047895774245262

Epoch: 5| Step: 4
Training loss: 2.4855175018310547
Validation loss: 2.042001351714134

Epoch: 5| Step: 5
Training loss: 2.0114965438842773
Validation loss: 2.03825414677461

Epoch: 5| Step: 6
Training loss: 2.278317928314209
Validation loss: 2.035566141208013

Epoch: 5| Step: 7
Training loss: 2.0454680919647217
Validation loss: 2.0422641336917877

Epoch: 5| Step: 8
Training loss: 2.043344497680664
Validation loss: 2.0392293433348336

Epoch: 5| Step: 9
Training loss: 2.1123766899108887
Validation loss: 2.046336308121681

Epoch: 5| Step: 10
Training loss: 2.5742039680480957
Validation loss: 2.03688013056914

Epoch: 5| Step: 11
Training loss: 1.564507246017456
Validation loss: 2.040778319040934

Epoch: 82| Step: 0
Training loss: 2.3242530822753906
Validation loss: 2.0438152303298316

Epoch: 5| Step: 1
Training loss: 2.6672329902648926
Validation loss: 2.0427038967609406

Epoch: 5| Step: 2
Training loss: 2.1716196537017822
Validation loss: 2.0391090561946235

Epoch: 5| Step: 3
Training loss: 1.691219687461853
Validation loss: 2.044797882437706

Epoch: 5| Step: 4
Training loss: 2.0908210277557373
Validation loss: 2.0416995932658515

Epoch: 5| Step: 5
Training loss: 2.411980390548706
Validation loss: 2.0425042857726416

Epoch: 5| Step: 6
Training loss: 2.0608181953430176
Validation loss: 2.0386982957522073

Epoch: 5| Step: 7
Training loss: 1.7046716213226318
Validation loss: 2.038953502972921

Epoch: 5| Step: 8
Training loss: 2.2533650398254395
Validation loss: 2.048095097144445

Epoch: 5| Step: 9
Training loss: 2.649801254272461
Validation loss: 2.0597191154956818

Epoch: 5| Step: 10
Training loss: 2.3195083141326904
Validation loss: 2.04851441582044

Epoch: 5| Step: 11
Training loss: 1.8107225894927979
Validation loss: 2.0478145331144333

Epoch: 83| Step: 0
Training loss: 2.411628484725952
Validation loss: 2.0468692978223166

Epoch: 5| Step: 1
Training loss: 2.2809414863586426
Validation loss: 2.052490472793579

Epoch: 5| Step: 2
Training loss: 2.196941375732422
Validation loss: 2.067319388190905

Epoch: 5| Step: 3
Training loss: 1.9194223880767822
Validation loss: 2.075383002559344

Epoch: 5| Step: 4
Training loss: 2.346100330352783
Validation loss: 2.073352093497912

Epoch: 5| Step: 5
Training loss: 1.8706716299057007
Validation loss: 2.0823598007361093

Epoch: 5| Step: 6
Training loss: 2.5047643184661865
Validation loss: 2.07830777267615

Epoch: 5| Step: 7
Training loss: 2.232923984527588
Validation loss: 2.071259379386902

Epoch: 5| Step: 8
Training loss: 2.3915257453918457
Validation loss: 2.050461302200953

Epoch: 5| Step: 9
Training loss: 2.178931474685669
Validation loss: 2.0553326507409415

Epoch: 5| Step: 10
Training loss: 1.8464800119400024
Validation loss: 2.03424463669459

Epoch: 5| Step: 11
Training loss: 2.610893726348877
Validation loss: 2.0203556368748345

Epoch: 84| Step: 0
Training loss: 2.2297425270080566
Validation loss: 2.0313411355018616

Epoch: 5| Step: 1
Training loss: 1.3675850629806519
Validation loss: 2.0330383330583572

Epoch: 5| Step: 2
Training loss: 2.0097131729125977
Validation loss: 2.0355187157789865

Epoch: 5| Step: 3
Training loss: 2.226724624633789
Validation loss: 2.0440632551908493

Epoch: 5| Step: 4
Training loss: 2.1374268531799316
Validation loss: 2.038429314891497

Epoch: 5| Step: 5
Training loss: 2.3408093452453613
Validation loss: 2.045914406577746

Epoch: 5| Step: 6
Training loss: 2.2969374656677246
Validation loss: 2.0405200074116387

Epoch: 5| Step: 7
Training loss: 1.9062038660049438
Validation loss: 2.04703089594841

Epoch: 5| Step: 8
Training loss: 2.2832436561584473
Validation loss: 2.0423731058835983

Epoch: 5| Step: 9
Training loss: 2.7661757469177246
Validation loss: 2.038397361834844

Epoch: 5| Step: 10
Training loss: 2.8835642337799072
Validation loss: 2.041322742899259

Epoch: 5| Step: 11
Training loss: 1.9618260860443115
Validation loss: 2.0406906058390937

Epoch: 85| Step: 0
Training loss: 1.929700493812561
Validation loss: 2.030482217669487

Epoch: 5| Step: 1
Training loss: 2.1065149307250977
Validation loss: 2.031036784251531

Epoch: 5| Step: 2
Training loss: 2.483612060546875
Validation loss: 2.031228318810463

Epoch: 5| Step: 3
Training loss: 2.0782504081726074
Validation loss: 2.0183577040831246

Epoch: 5| Step: 4
Training loss: 1.9957910776138306
Validation loss: 2.0349727471669516

Epoch: 5| Step: 5
Training loss: 2.278076410293579
Validation loss: 2.0383044878641763

Epoch: 5| Step: 6
Training loss: 2.174461841583252
Validation loss: 2.0603107810020447

Epoch: 5| Step: 7
Training loss: 2.260099411010742
Validation loss: 2.066240976254145

Epoch: 5| Step: 8
Training loss: 2.0456511974334717
Validation loss: 2.0682280411322913

Epoch: 5| Step: 9
Training loss: 2.2662580013275146
Validation loss: 2.064219757914543

Epoch: 5| Step: 10
Training loss: 2.5876400470733643
Validation loss: 2.072791109482447

Epoch: 5| Step: 11
Training loss: 2.5559487342834473
Validation loss: 2.0567246874173484

Epoch: 86| Step: 0
Training loss: 2.4390907287597656
Validation loss: 2.0468577096859613

Epoch: 5| Step: 1
Training loss: 2.461455821990967
Validation loss: 2.042296047012011

Epoch: 5| Step: 2
Training loss: 1.8686469793319702
Validation loss: 2.019049475590388

Epoch: 5| Step: 3
Training loss: 2.512298583984375
Validation loss: 2.014263535539309

Epoch: 5| Step: 4
Training loss: 2.406740188598633
Validation loss: 2.0190581679344177

Epoch: 5| Step: 5
Training loss: 1.9414341449737549
Validation loss: 2.01300776998202

Epoch: 5| Step: 6
Training loss: 2.452444553375244
Validation loss: 2.018280103802681

Epoch: 5| Step: 7
Training loss: 2.3540756702423096
Validation loss: 2.0120725631713867

Epoch: 5| Step: 8
Training loss: 2.096900463104248
Validation loss: 2.0161592413981757

Epoch: 5| Step: 9
Training loss: 1.6925220489501953
Validation loss: 2.020812213420868

Epoch: 5| Step: 10
Training loss: 1.8318729400634766
Validation loss: 2.030749832590421

Epoch: 5| Step: 11
Training loss: 1.833950161933899
Validation loss: 2.0201810697714486

Epoch: 87| Step: 0
Training loss: 2.4838922023773193
Validation loss: 2.027803892890612

Epoch: 5| Step: 1
Training loss: 2.1943466663360596
Validation loss: 2.020401472846667

Epoch: 5| Step: 2
Training loss: 2.162173271179199
Validation loss: 2.0188114990790686

Epoch: 5| Step: 3
Training loss: 2.589761257171631
Validation loss: 2.023311346769333

Epoch: 5| Step: 4
Training loss: 1.9701191186904907
Validation loss: 2.027334382136663

Epoch: 5| Step: 5
Training loss: 2.1693990230560303
Validation loss: 2.030579681197802

Epoch: 5| Step: 6
Training loss: 1.8090159893035889
Validation loss: 2.036453982194265

Epoch: 5| Step: 7
Training loss: 1.8679472208023071
Validation loss: 2.040055960416794

Epoch: 5| Step: 8
Training loss: 1.7758525609970093
Validation loss: 2.0370602309703827

Epoch: 5| Step: 9
Training loss: 1.9852298498153687
Validation loss: 2.0469955752293267

Epoch: 5| Step: 10
Training loss: 2.623354434967041
Validation loss: 2.039616564909617

Epoch: 5| Step: 11
Training loss: 3.442655086517334
Validation loss: 2.0423410832881927

Epoch: 88| Step: 0
Training loss: 2.2638020515441895
Validation loss: 2.0407049308220544

Epoch: 5| Step: 1
Training loss: 2.75276517868042
Validation loss: 2.036919499437014

Epoch: 5| Step: 2
Training loss: 1.9290046691894531
Validation loss: 2.0441591143608093

Epoch: 5| Step: 3
Training loss: 2.50913143157959
Validation loss: 2.0432210663954415

Epoch: 5| Step: 4
Training loss: 1.256632685661316
Validation loss: 2.036674370368322

Epoch: 5| Step: 5
Training loss: 2.5692970752716064
Validation loss: 2.027802606423696

Epoch: 5| Step: 6
Training loss: 1.9099798202514648
Validation loss: 2.0315679709116616

Epoch: 5| Step: 7
Training loss: 1.6280864477157593
Validation loss: 2.0335243393977485

Epoch: 5| Step: 8
Training loss: 2.4954781532287598
Validation loss: 2.0301036536693573

Epoch: 5| Step: 9
Training loss: 2.354106903076172
Validation loss: 2.0322461674610772

Epoch: 5| Step: 10
Training loss: 2.2401645183563232
Validation loss: 2.035471498966217

Epoch: 5| Step: 11
Training loss: 2.34531831741333
Validation loss: 2.0360242277383804

Epoch: 89| Step: 0
Training loss: 2.590989589691162
Validation loss: 2.0303968687852225

Epoch: 5| Step: 1
Training loss: 2.048287868499756
Validation loss: 2.026131028930346

Epoch: 5| Step: 2
Training loss: 2.010293483734131
Validation loss: 2.032871504624685

Epoch: 5| Step: 3
Training loss: 2.1816787719726562
Validation loss: 2.0413163602352142

Epoch: 5| Step: 4
Training loss: 2.5163025856018066
Validation loss: 2.0383602480093637

Epoch: 5| Step: 5
Training loss: 2.450911521911621
Validation loss: 2.0400041242440543

Epoch: 5| Step: 6
Training loss: 1.8553434610366821
Validation loss: 2.0330290098985038

Epoch: 5| Step: 7
Training loss: 2.131453037261963
Validation loss: 2.044130320350329

Epoch: 5| Step: 8
Training loss: 1.9914779663085938
Validation loss: 2.0361915876468024

Epoch: 5| Step: 9
Training loss: 1.9646066427230835
Validation loss: 2.0353177189826965

Epoch: 5| Step: 10
Training loss: 1.9733871221542358
Validation loss: 2.0454505532979965

Epoch: 5| Step: 11
Training loss: 2.2975263595581055
Validation loss: 2.036921242872874

Epoch: 90| Step: 0
Training loss: 1.9475561380386353
Validation loss: 2.038686787088712

Epoch: 5| Step: 1
Training loss: 2.77787446975708
Validation loss: 2.0336729288101196

Epoch: 5| Step: 2
Training loss: 1.8333765268325806
Validation loss: 2.0405889997879663

Epoch: 5| Step: 3
Training loss: 2.1611132621765137
Validation loss: 2.045135110616684

Epoch: 5| Step: 4
Training loss: 2.1748664379119873
Validation loss: 2.0447950611511865

Epoch: 5| Step: 5
Training loss: 2.294027328491211
Validation loss: 2.046089624365171

Epoch: 5| Step: 6
Training loss: 1.6459239721298218
Validation loss: 2.0403307676315308

Epoch: 5| Step: 7
Training loss: 2.443352460861206
Validation loss: 2.0454232494036355

Epoch: 5| Step: 8
Training loss: 2.1136348247528076
Validation loss: 2.0635546495517096

Epoch: 5| Step: 9
Training loss: 1.9014739990234375
Validation loss: 2.0485858768224716

Epoch: 5| Step: 10
Training loss: 2.4181549549102783
Validation loss: 2.05011094113191

Epoch: 5| Step: 11
Training loss: 2.1880860328674316
Validation loss: 2.0383272419373193

Epoch: 91| Step: 0
Training loss: 2.292112350463867
Validation loss: 2.042604307333628

Epoch: 5| Step: 1
Training loss: 2.299379348754883
Validation loss: 2.0478535989920297

Epoch: 5| Step: 2
Training loss: 1.8542553186416626
Validation loss: 2.049751897652944

Epoch: 5| Step: 3
Training loss: 1.6860355138778687
Validation loss: 2.0605929692586265

Epoch: 5| Step: 4
Training loss: 2.6159615516662598
Validation loss: 2.052716980377833

Epoch: 5| Step: 5
Training loss: 2.355597734451294
Validation loss: 2.053903261820475

Epoch: 5| Step: 6
Training loss: 2.300288438796997
Validation loss: 2.047323927283287

Epoch: 5| Step: 7
Training loss: 2.0115950107574463
Validation loss: 2.037015378475189

Epoch: 5| Step: 8
Training loss: 2.4695396423339844
Validation loss: 2.0285308162371316

Epoch: 5| Step: 9
Training loss: 2.0612804889678955
Validation loss: 2.0331609000762305

Epoch: 5| Step: 10
Training loss: 2.0014586448669434
Validation loss: 2.036916812260946

Epoch: 5| Step: 11
Training loss: 1.2122482061386108
Validation loss: 2.0408993562062583

Epoch: 92| Step: 0
Training loss: 2.0168983936309814
Validation loss: 2.0300613840421042

Epoch: 5| Step: 1
Training loss: 1.6728744506835938
Validation loss: 2.038028508424759

Epoch: 5| Step: 2
Training loss: 1.8888931274414062
Validation loss: 2.0347744127114615

Epoch: 5| Step: 3
Training loss: 2.4299087524414062
Validation loss: 2.036825324098269

Epoch: 5| Step: 4
Training loss: 2.266665458679199
Validation loss: 2.041023939847946

Epoch: 5| Step: 5
Training loss: 2.4729881286621094
Validation loss: 2.0369649728139243

Epoch: 5| Step: 6
Training loss: 1.8755371570587158
Validation loss: 2.03479111691316

Epoch: 5| Step: 7
Training loss: 2.6752777099609375
Validation loss: 2.033548300464948

Epoch: 5| Step: 8
Training loss: 2.510061740875244
Validation loss: 2.0293021351099014

Epoch: 5| Step: 9
Training loss: 2.1234703063964844
Validation loss: 2.0207671572764716

Epoch: 5| Step: 10
Training loss: 2.0889835357666016
Validation loss: 2.0212804675102234

Epoch: 5| Step: 11
Training loss: 2.4185237884521484
Validation loss: 2.022609462340673

Epoch: 93| Step: 0
Training loss: 1.6643050909042358
Validation loss: 2.016623040040334

Epoch: 5| Step: 1
Training loss: 2.3790910243988037
Validation loss: 2.0171879728635154

Epoch: 5| Step: 2
Training loss: 2.360564708709717
Validation loss: 2.018576368689537

Epoch: 5| Step: 3
Training loss: 2.3186233043670654
Validation loss: 2.021276151140531

Epoch: 5| Step: 4
Training loss: 2.2902579307556152
Validation loss: 2.0224699229002

Epoch: 5| Step: 5
Training loss: 2.4110493659973145
Validation loss: 2.0278871158758798

Epoch: 5| Step: 6
Training loss: 2.4915432929992676
Validation loss: 2.03101214269797

Epoch: 5| Step: 7
Training loss: 1.7325865030288696
Validation loss: 2.020181804895401

Epoch: 5| Step: 8
Training loss: 2.2066988945007324
Validation loss: 2.025917520125707

Epoch: 5| Step: 9
Training loss: 1.8522112369537354
Validation loss: 2.032271275917689

Epoch: 5| Step: 10
Training loss: 1.9553368091583252
Validation loss: 2.0310481439034143

Epoch: 5| Step: 11
Training loss: 2.580308437347412
Validation loss: 2.0360751946767173

Epoch: 94| Step: 0
Training loss: 1.6917953491210938
Validation loss: 2.037225365638733

Epoch: 5| Step: 1
Training loss: 1.8524612188339233
Validation loss: 2.0435513108968735

Epoch: 5| Step: 2
Training loss: 2.557342529296875
Validation loss: 2.0333980272213616

Epoch: 5| Step: 3
Training loss: 2.3977646827697754
Validation loss: 2.0424713790416718

Epoch: 5| Step: 4
Training loss: 2.3100500106811523
Validation loss: 2.0453315625588098

Epoch: 5| Step: 5
Training loss: 1.7889959812164307
Validation loss: 2.0444060415029526

Epoch: 5| Step: 6
Training loss: 2.4710609912872314
Validation loss: 2.0426185528437295

Epoch: 5| Step: 7
Training loss: 1.9255445003509521
Validation loss: 2.0424294471740723

Epoch: 5| Step: 8
Training loss: 2.496284246444702
Validation loss: 2.053221811850866

Epoch: 5| Step: 9
Training loss: 1.7819998264312744
Validation loss: 2.041111042102178

Epoch: 5| Step: 10
Training loss: 2.546254873275757
Validation loss: 2.029341662923495

Epoch: 5| Step: 11
Training loss: 1.089189887046814
Validation loss: 2.0365569492181144

Epoch: 95| Step: 0
Training loss: 1.8840147256851196
Validation loss: 2.0307885706424713

Epoch: 5| Step: 1
Training loss: 2.480820894241333
Validation loss: 2.037880077958107

Epoch: 5| Step: 2
Training loss: 2.0835318565368652
Validation loss: 2.03505185743173

Epoch: 5| Step: 3
Training loss: 1.67026686668396
Validation loss: 2.0393824527661004

Epoch: 5| Step: 4
Training loss: 2.8387224674224854
Validation loss: 2.041726758082708

Epoch: 5| Step: 5
Training loss: 2.3283908367156982
Validation loss: 2.0403992434342704

Epoch: 5| Step: 6
Training loss: 1.7596222162246704
Validation loss: 2.0400491605202355

Epoch: 5| Step: 7
Training loss: 2.5239267349243164
Validation loss: 2.038410251339277

Epoch: 5| Step: 8
Training loss: 1.4548513889312744
Validation loss: 2.038878674308459

Epoch: 5| Step: 9
Training loss: 2.2248826026916504
Validation loss: 2.0258262952168784

Epoch: 5| Step: 10
Training loss: 2.563279867172241
Validation loss: 2.0296692897876105

Epoch: 5| Step: 11
Training loss: 1.135898470878601
Validation loss: 2.031028836965561

Epoch: 96| Step: 0
Training loss: 1.6110931634902954
Validation loss: 2.032302270332972

Epoch: 5| Step: 1
Training loss: 1.3006751537322998
Validation loss: 2.028799131512642

Epoch: 5| Step: 2
Training loss: 2.0183207988739014
Validation loss: 2.0324653138717017

Epoch: 5| Step: 3
Training loss: 2.2893662452697754
Validation loss: 2.039495383699735

Epoch: 5| Step: 4
Training loss: 2.4239346981048584
Validation loss: 2.040080110232035

Epoch: 5| Step: 5
Training loss: 2.6771750450134277
Validation loss: 2.0506329983472824

Epoch: 5| Step: 6
Training loss: 2.1351656913757324
Validation loss: 2.041680480043093

Epoch: 5| Step: 7
Training loss: 2.609890937805176
Validation loss: 2.0485630283753076

Epoch: 5| Step: 8
Training loss: 1.8295040130615234
Validation loss: 2.050893555084864

Epoch: 5| Step: 9
Training loss: 2.2012219429016113
Validation loss: 2.0451043943564096

Epoch: 5| Step: 10
Training loss: 2.692889928817749
Validation loss: 2.0433317571878433

Epoch: 5| Step: 11
Training loss: 2.1859655380249023
Validation loss: 2.042720153927803

Epoch: 97| Step: 0
Training loss: 2.0863606929779053
Validation loss: 2.033969168861707

Epoch: 5| Step: 1
Training loss: 1.7615150213241577
Validation loss: 2.033485452334086

Epoch: 5| Step: 2
Training loss: 2.8872907161712646
Validation loss: 2.0318615784247718

Epoch: 5| Step: 3
Training loss: 1.9410842657089233
Validation loss: 2.025725175937017

Epoch: 5| Step: 4
Training loss: 1.82027268409729
Validation loss: 2.029001941283544

Epoch: 5| Step: 5
Training loss: 2.1389060020446777
Validation loss: 2.0313252756992974

Epoch: 5| Step: 6
Training loss: 2.318490505218506
Validation loss: 2.026089668273926

Epoch: 5| Step: 7
Training loss: 2.257628917694092
Validation loss: 2.029159148534139

Epoch: 5| Step: 8
Training loss: 1.8968623876571655
Validation loss: 2.034094050526619

Epoch: 5| Step: 9
Training loss: 2.4043126106262207
Validation loss: 2.0277460714181266

Epoch: 5| Step: 10
Training loss: 2.1838736534118652
Validation loss: 2.023882438739141

Epoch: 5| Step: 11
Training loss: 1.7789801359176636
Validation loss: 2.01944707830747

Epoch: 98| Step: 0
Training loss: 2.3491768836975098
Validation loss: 2.034797673424085

Epoch: 5| Step: 1
Training loss: 2.1146469116210938
Validation loss: 2.042904958128929

Epoch: 5| Step: 2
Training loss: 2.14650297164917
Validation loss: 2.0402269015709558

Epoch: 5| Step: 3
Training loss: 1.900831937789917
Validation loss: 2.0487661163012185

Epoch: 5| Step: 4
Training loss: 1.977659821510315
Validation loss: 2.056590959429741

Epoch: 5| Step: 5
Training loss: 2.0470216274261475
Validation loss: 2.079889545838038

Epoch: 5| Step: 6
Training loss: 2.2745919227600098
Validation loss: 2.08502688507239

Epoch: 5| Step: 7
Training loss: 2.4792544841766357
Validation loss: 2.057795604070028

Epoch: 5| Step: 8
Training loss: 1.8136870861053467
Validation loss: 2.0524512827396393

Epoch: 5| Step: 9
Training loss: 2.611534357070923
Validation loss: 2.0337441116571426

Epoch: 5| Step: 10
Training loss: 2.257873058319092
Validation loss: 2.0227404733498893

Epoch: 5| Step: 11
Training loss: 2.3242430686950684
Validation loss: 2.024354969461759

Epoch: 99| Step: 0
Training loss: 2.082683563232422
Validation loss: 2.019510050614675

Epoch: 5| Step: 1
Training loss: 2.2303667068481445
Validation loss: 2.032648021976153

Epoch: 5| Step: 2
Training loss: 2.1947786808013916
Validation loss: 2.039722869793574

Epoch: 5| Step: 3
Training loss: 2.89367413520813
Validation loss: 2.052225351333618

Epoch: 5| Step: 4
Training loss: 2.18713641166687
Validation loss: 2.051924998561541

Epoch: 5| Step: 5
Training loss: 2.0737252235412598
Validation loss: 2.06313626964887

Epoch: 5| Step: 6
Training loss: 2.507952928543091
Validation loss: 2.070706769824028

Epoch: 5| Step: 7
Training loss: 2.299597978591919
Validation loss: 2.073933040102323

Epoch: 5| Step: 8
Training loss: 2.1308512687683105
Validation loss: 2.091244508822759

Epoch: 5| Step: 9
Training loss: 2.5590484142303467
Validation loss: 2.0912829289833703

Epoch: 5| Step: 10
Training loss: 1.7119029760360718
Validation loss: 2.0865708688894906

Epoch: 5| Step: 11
Training loss: 1.689170479774475
Validation loss: 2.0865360349416733

Epoch: 100| Step: 0
Training loss: 2.277921199798584
Validation loss: 2.0801178266604743

Epoch: 5| Step: 1
Training loss: 2.0688276290893555
Validation loss: 2.0724459290504456

Epoch: 5| Step: 2
Training loss: 2.279872417449951
Validation loss: 2.0708501040935516

Epoch: 5| Step: 3
Training loss: 2.2993216514587402
Validation loss: 2.068140680591265

Epoch: 5| Step: 4
Training loss: 2.1684186458587646
Validation loss: 2.065506339073181

Epoch: 5| Step: 5
Training loss: 2.1575207710266113
Validation loss: 2.0631164411703744

Epoch: 5| Step: 6
Training loss: 2.434230089187622
Validation loss: 2.0572022000948587

Epoch: 5| Step: 7
Training loss: 2.1196084022521973
Validation loss: 2.0525211542844772

Epoch: 5| Step: 8
Training loss: 2.3300042152404785
Validation loss: 2.0492986738681793

Epoch: 5| Step: 9
Training loss: 2.6276087760925293
Validation loss: 2.0467507988214493

Epoch: 5| Step: 10
Training loss: 1.879570722579956
Validation loss: 2.0417021811008453

Epoch: 5| Step: 11
Training loss: 2.451388120651245
Validation loss: 2.0409495880206427

Epoch: 101| Step: 0
Training loss: 2.151580810546875
Validation loss: 2.0412735839684806

Epoch: 5| Step: 1
Training loss: 2.0185818672180176
Validation loss: 2.0378425121307373

Epoch: 5| Step: 2
Training loss: 2.633324384689331
Validation loss: 2.040176644921303

Epoch: 5| Step: 3
Training loss: 2.510131597518921
Validation loss: 2.0318305790424347

Epoch: 5| Step: 4
Training loss: 2.000600814819336
Validation loss: 2.026496484875679

Epoch: 5| Step: 5
Training loss: 1.6079909801483154
Validation loss: 2.0224903374910355

Epoch: 5| Step: 6
Training loss: 2.6485540866851807
Validation loss: 2.0151638090610504

Epoch: 5| Step: 7
Training loss: 2.455605983734131
Validation loss: 2.009936958551407

Epoch: 5| Step: 8
Training loss: 2.278557300567627
Validation loss: 2.0081812938054404

Epoch: 5| Step: 9
Training loss: 1.903163194656372
Validation loss: 2.015856077273687

Epoch: 5| Step: 10
Training loss: 1.90280020236969
Validation loss: 2.0241761406262717

Epoch: 5| Step: 11
Training loss: 2.2261853218078613
Validation loss: 2.011531258622805

Epoch: 102| Step: 0
Training loss: 1.320699691772461
Validation loss: 2.026570131381353

Epoch: 5| Step: 1
Training loss: 2.2481982707977295
Validation loss: 2.0295677731434503

Epoch: 5| Step: 2
Training loss: 2.5340957641601562
Validation loss: 2.025805021325747

Epoch: 5| Step: 3
Training loss: 2.5817906856536865
Validation loss: 2.051834464073181

Epoch: 5| Step: 4
Training loss: 2.2082436084747314
Validation loss: 2.0500251104434333

Epoch: 5| Step: 5
Training loss: 2.538346767425537
Validation loss: 2.039577523867289

Epoch: 5| Step: 6
Training loss: 2.0825958251953125
Validation loss: 2.037232751647631

Epoch: 5| Step: 7
Training loss: 2.270136833190918
Validation loss: 2.033190285166105

Epoch: 5| Step: 8
Training loss: 2.3885509967803955
Validation loss: 2.026444524526596

Epoch: 5| Step: 9
Training loss: 1.8071115016937256
Validation loss: 2.0271440943082175

Epoch: 5| Step: 10
Training loss: 2.009563446044922
Validation loss: 2.017174080014229

Epoch: 5| Step: 11
Training loss: 2.669903039932251
Validation loss: 2.0131339778502784

Epoch: 103| Step: 0
Training loss: 2.4864838123321533
Validation loss: 2.018646761775017

Epoch: 5| Step: 1
Training loss: 2.6058125495910645
Validation loss: 2.0155669947465262

Epoch: 5| Step: 2
Training loss: 2.1716034412384033
Validation loss: 2.016917034983635

Epoch: 5| Step: 3
Training loss: 2.152735471725464
Validation loss: 2.025407130519549

Epoch: 5| Step: 4
Training loss: 2.1183266639709473
Validation loss: 2.0170357823371887

Epoch: 5| Step: 5
Training loss: 1.9422870874404907
Validation loss: 2.0161445240179696

Epoch: 5| Step: 6
Training loss: 1.7146570682525635
Validation loss: 2.015347883105278

Epoch: 5| Step: 7
Training loss: 2.1715731620788574
Validation loss: 2.017704501748085

Epoch: 5| Step: 8
Training loss: 2.2642197608947754
Validation loss: 2.015376632412275

Epoch: 5| Step: 9
Training loss: 2.4968435764312744
Validation loss: 2.0154113173484802

Epoch: 5| Step: 10
Training loss: 1.9031105041503906
Validation loss: 2.0159853051106134

Epoch: 5| Step: 11
Training loss: 1.166147232055664
Validation loss: 2.02185712258021

Epoch: 104| Step: 0
Training loss: 2.3590242862701416
Validation loss: 2.012165034810702

Epoch: 5| Step: 1
Training loss: 2.2243638038635254
Validation loss: 2.0097172558307648

Epoch: 5| Step: 2
Training loss: 1.9313122034072876
Validation loss: 2.0155321607987084

Epoch: 5| Step: 3
Training loss: 2.066155195236206
Validation loss: 2.0168579816818237

Epoch: 5| Step: 4
Training loss: 1.1733890771865845
Validation loss: 2.0210417211055756

Epoch: 5| Step: 5
Training loss: 2.4656083583831787
Validation loss: 2.0200811276833215

Epoch: 5| Step: 6
Training loss: 2.1984639167785645
Validation loss: 2.013797531525294

Epoch: 5| Step: 7
Training loss: 2.359900951385498
Validation loss: 2.0183677772680917

Epoch: 5| Step: 8
Training loss: 2.5476551055908203
Validation loss: 2.0185844401518502

Epoch: 5| Step: 9
Training loss: 2.3874752521514893
Validation loss: 2.0135792096455893

Epoch: 5| Step: 10
Training loss: 2.0873219966888428
Validation loss: 2.030004029472669

Epoch: 5| Step: 11
Training loss: 1.8074498176574707
Validation loss: 2.016603857278824

Epoch: 105| Step: 0
Training loss: 2.609262466430664
Validation loss: 2.0148580074310303

Epoch: 5| Step: 1
Training loss: 2.4494688510894775
Validation loss: 2.020865266521772

Epoch: 5| Step: 2
Training loss: 1.9956176280975342
Validation loss: 2.025635927915573

Epoch: 5| Step: 3
Training loss: 1.4432640075683594
Validation loss: 2.029822607835134

Epoch: 5| Step: 4
Training loss: 1.7948143482208252
Validation loss: 2.0267162124315896

Epoch: 5| Step: 5
Training loss: 2.00199031829834
Validation loss: 2.0265483359495797

Epoch: 5| Step: 6
Training loss: 1.406641960144043
Validation loss: 2.020680695772171

Epoch: 5| Step: 7
Training loss: 2.926396608352661
Validation loss: 2.0186385611693063

Epoch: 5| Step: 8
Training loss: 2.004838705062866
Validation loss: 2.0180517435073853

Epoch: 5| Step: 9
Training loss: 2.236191511154175
Validation loss: 2.007857402165731

Epoch: 5| Step: 10
Training loss: 2.5907392501831055
Validation loss: 2.007512331008911

Epoch: 5| Step: 11
Training loss: 3.148402690887451
Validation loss: 2.0092240472634635

Epoch: 106| Step: 0
Training loss: 2.521954298019409
Validation loss: 2.011210252841314

Epoch: 5| Step: 1
Training loss: 1.9632803201675415
Validation loss: 2.015628089507421

Epoch: 5| Step: 2
Training loss: 2.047776460647583
Validation loss: 2.0164462476968765

Epoch: 5| Step: 3
Training loss: 1.8623383045196533
Validation loss: 2.010605370004972

Epoch: 5| Step: 4
Training loss: 1.3571622371673584
Validation loss: 2.011081630984942

Epoch: 5| Step: 5
Training loss: 2.510126829147339
Validation loss: 2.019816135366758

Epoch: 5| Step: 6
Training loss: 2.398869752883911
Validation loss: 2.023880581061045

Epoch: 5| Step: 7
Training loss: 2.393925189971924
Validation loss: 2.0394102334976196

Epoch: 5| Step: 8
Training loss: 1.866349458694458
Validation loss: 2.0347411384185157

Epoch: 5| Step: 9
Training loss: 1.581160545349121
Validation loss: 2.0404130667448044

Epoch: 5| Step: 10
Training loss: 2.8969993591308594
Validation loss: 2.038894832134247

Epoch: 5| Step: 11
Training loss: 2.775973081588745
Validation loss: 2.0388026237487793

Epoch: 107| Step: 0
Training loss: 2.4396610260009766
Validation loss: 2.047337919473648

Epoch: 5| Step: 1
Training loss: 2.1768383979797363
Validation loss: 2.0555133620897927

Epoch: 5| Step: 2
Training loss: 2.1893937587738037
Validation loss: 2.059219186504682

Epoch: 5| Step: 3
Training loss: 1.608608603477478
Validation loss: 2.0511982142925262

Epoch: 5| Step: 4
Training loss: 2.1831650733947754
Validation loss: 2.05572609603405

Epoch: 5| Step: 5
Training loss: 2.19498348236084
Validation loss: 2.045713504155477

Epoch: 5| Step: 6
Training loss: 2.06904935836792
Validation loss: 2.046484445532163

Epoch: 5| Step: 7
Training loss: 1.682700753211975
Validation loss: 2.0335194716850915

Epoch: 5| Step: 8
Training loss: 1.950523018836975
Validation loss: 2.0326423943042755

Epoch: 5| Step: 9
Training loss: 2.6347551345825195
Validation loss: 2.032383918762207

Epoch: 5| Step: 10
Training loss: 2.5070362091064453
Validation loss: 2.024008015791575

Epoch: 5| Step: 11
Training loss: 1.9097604751586914
Validation loss: 2.0250840385754905

Epoch: 108| Step: 0
Training loss: 2.427302360534668
Validation loss: 2.0282733688751855

Epoch: 5| Step: 1
Training loss: 2.0979464054107666
Validation loss: 2.0243688921133676

Epoch: 5| Step: 2
Training loss: 1.7838042974472046
Validation loss: 2.022320215900739

Epoch: 5| Step: 3
Training loss: 2.305973529815674
Validation loss: 2.0284171253442764

Epoch: 5| Step: 4
Training loss: 2.5011284351348877
Validation loss: 2.0356458624204

Epoch: 5| Step: 5
Training loss: 1.3442537784576416
Validation loss: 2.0277306884527206

Epoch: 5| Step: 6
Training loss: 1.7360601425170898
Validation loss: 2.0251965820789337

Epoch: 5| Step: 7
Training loss: 2.433276653289795
Validation loss: 2.026187558968862

Epoch: 5| Step: 8
Training loss: 2.1719093322753906
Validation loss: 2.0324865877628326

Epoch: 5| Step: 9
Training loss: 2.1759636402130127
Validation loss: 2.022666871547699

Epoch: 5| Step: 10
Training loss: 2.3829264640808105
Validation loss: 2.029468461871147

Epoch: 5| Step: 11
Training loss: 3.058065414428711
Validation loss: 2.0322108616431556

Epoch: 109| Step: 0
Training loss: 2.1241726875305176
Validation loss: 2.0321868459383645

Epoch: 5| Step: 1
Training loss: 2.111964464187622
Validation loss: 2.0245509246985116

Epoch: 5| Step: 2
Training loss: 2.258572816848755
Validation loss: 2.0116976499557495

Epoch: 5| Step: 3
Training loss: 1.8242048025131226
Validation loss: 2.0013256718715033

Epoch: 5| Step: 4
Training loss: 2.3574135303497314
Validation loss: 2.0041233599185944

Epoch: 5| Step: 5
Training loss: 2.0488083362579346
Validation loss: 2.0074797868728638

Epoch: 5| Step: 6
Training loss: 1.983262300491333
Validation loss: 2.007857173681259

Epoch: 5| Step: 7
Training loss: 1.826629638671875
Validation loss: 2.005633925398191

Epoch: 5| Step: 8
Training loss: 2.3815016746520996
Validation loss: 2.010263979434967

Epoch: 5| Step: 9
Training loss: 2.489720344543457
Validation loss: 2.0052877018849053

Epoch: 5| Step: 10
Training loss: 2.4860141277313232
Validation loss: 2.012965520222982

Epoch: 5| Step: 11
Training loss: 1.361718773841858
Validation loss: 2.008575518925985

Epoch: 110| Step: 0
Training loss: 1.9091434478759766
Validation loss: 2.0086490909258523

Epoch: 5| Step: 1
Training loss: 2.3296895027160645
Validation loss: 2.0028124252955117

Epoch: 5| Step: 2
Training loss: 1.872687578201294
Validation loss: 2.012852743268013

Epoch: 5| Step: 3
Training loss: 2.4485552310943604
Validation loss: 2.001215254267057

Epoch: 5| Step: 4
Training loss: 2.1058144569396973
Validation loss: 2.010728677113851

Epoch: 5| Step: 5
Training loss: 2.4147775173187256
Validation loss: 2.0036149621009827

Epoch: 5| Step: 6
Training loss: 2.099431276321411
Validation loss: 2.004907568295797

Epoch: 5| Step: 7
Training loss: 2.1630427837371826
Validation loss: 2.007292464375496

Epoch: 5| Step: 8
Training loss: 2.468334913253784
Validation loss: 2.0072074979543686

Epoch: 5| Step: 9
Training loss: 1.9816852807998657
Validation loss: 2.0113702714443207

Epoch: 5| Step: 10
Training loss: 1.9283263683319092
Validation loss: 2.018378645181656

Epoch: 5| Step: 11
Training loss: 1.7539231777191162
Validation loss: 2.02690052986145

Epoch: 111| Step: 0
Training loss: 1.960008978843689
Validation loss: 2.026889443397522

Epoch: 5| Step: 1
Training loss: 2.393585205078125
Validation loss: 2.040831764539083

Epoch: 5| Step: 2
Training loss: 2.003012180328369
Validation loss: 2.033884714047114

Epoch: 5| Step: 3
Training loss: 2.2111592292785645
Validation loss: 2.040898064772288

Epoch: 5| Step: 4
Training loss: 2.4673125743865967
Validation loss: 2.0482680201530457

Epoch: 5| Step: 5
Training loss: 2.1344382762908936
Validation loss: 2.0508629232645035

Epoch: 5| Step: 6
Training loss: 2.130801200866699
Validation loss: 2.0334249983231225

Epoch: 5| Step: 7
Training loss: 2.6650984287261963
Validation loss: 2.031132866938909

Epoch: 5| Step: 8
Training loss: 2.1690311431884766
Validation loss: 2.0377956479787827

Epoch: 5| Step: 9
Training loss: 1.8739417791366577
Validation loss: 2.0237801472345986

Epoch: 5| Step: 10
Training loss: 1.8650528192520142
Validation loss: 2.0241471181313195

Epoch: 5| Step: 11
Training loss: 0.4431403875350952
Validation loss: 2.021024694045385

Epoch: 112| Step: 0
Training loss: 1.7695643901824951
Validation loss: 2.0239400466283164

Epoch: 5| Step: 1
Training loss: 1.7889997959136963
Validation loss: 2.0273908972740173

Epoch: 5| Step: 2
Training loss: 2.449047803878784
Validation loss: 2.022655482093493

Epoch: 5| Step: 3
Training loss: 2.4222075939178467
Validation loss: 2.029222230116526

Epoch: 5| Step: 4
Training loss: 2.308520793914795
Validation loss: 2.020337318380674

Epoch: 5| Step: 5
Training loss: 1.6972557306289673
Validation loss: 2.0242596914370856

Epoch: 5| Step: 6
Training loss: 2.260547637939453
Validation loss: 2.0326921194791794

Epoch: 5| Step: 7
Training loss: 2.1967337131500244
Validation loss: 2.0382225612799325

Epoch: 5| Step: 8
Training loss: 2.028759717941284
Validation loss: 2.0420392553011575

Epoch: 5| Step: 9
Training loss: 2.329699993133545
Validation loss: 2.048258736729622

Epoch: 5| Step: 10
Training loss: 2.1980202198028564
Validation loss: 2.0413674861192703

Epoch: 5| Step: 11
Training loss: 1.9951908588409424
Validation loss: 2.0447620948155723

Epoch: 113| Step: 0
Training loss: 2.188638210296631
Validation loss: 2.0337071071068444

Epoch: 5| Step: 1
Training loss: 2.6479287147521973
Validation loss: 2.027861918012301

Epoch: 5| Step: 2
Training loss: 2.8466286659240723
Validation loss: 2.028553292155266

Epoch: 5| Step: 3
Training loss: 2.5409326553344727
Validation loss: 2.024533132712046

Epoch: 5| Step: 4
Training loss: 2.224918842315674
Validation loss: 2.0225116908550262

Epoch: 5| Step: 5
Training loss: 2.2357101440429688
Validation loss: 2.0303618609905243

Epoch: 5| Step: 6
Training loss: 1.822749376296997
Validation loss: 2.0180363953113556

Epoch: 5| Step: 7
Training loss: 1.807098388671875
Validation loss: 2.008754293123881

Epoch: 5| Step: 8
Training loss: 1.7898437976837158
Validation loss: 2.020828887820244

Epoch: 5| Step: 9
Training loss: 1.7528877258300781
Validation loss: 2.0205498337745667

Epoch: 5| Step: 10
Training loss: 1.7298139333724976
Validation loss: 2.0200553983449936

Epoch: 5| Step: 11
Training loss: 1.4788061380386353
Validation loss: 2.029294043779373

Epoch: 114| Step: 0
Training loss: 2.5576610565185547
Validation loss: 2.0291832983493805

Epoch: 5| Step: 1
Training loss: 2.122046947479248
Validation loss: 2.0381091088056564

Epoch: 5| Step: 2
Training loss: 2.146209716796875
Validation loss: 2.0453216830889382

Epoch: 5| Step: 3
Training loss: 2.3165366649627686
Validation loss: 2.0417521446943283

Epoch: 5| Step: 4
Training loss: 1.745819330215454
Validation loss: 2.0551256090402603

Epoch: 5| Step: 5
Training loss: 2.024440050125122
Validation loss: 2.050589124361674

Epoch: 5| Step: 6
Training loss: 1.7810808420181274
Validation loss: 2.056708057721456

Epoch: 5| Step: 7
Training loss: 2.5410542488098145
Validation loss: 2.04846782485644

Epoch: 5| Step: 8
Training loss: 2.4453327655792236
Validation loss: 2.043393835425377

Epoch: 5| Step: 9
Training loss: 2.2441375255584717
Validation loss: 2.0388283133506775

Epoch: 5| Step: 10
Training loss: 1.6116247177124023
Validation loss: 2.0406923989454904

Epoch: 5| Step: 11
Training loss: 1.6612238883972168
Validation loss: 2.034731924533844

Epoch: 115| Step: 0
Training loss: 1.7375026941299438
Validation loss: 2.0215172270933786

Epoch: 5| Step: 1
Training loss: 1.3618028163909912
Validation loss: 2.0162089665730796

Epoch: 5| Step: 2
Training loss: 2.5894477367401123
Validation loss: 2.0171985725561776

Epoch: 5| Step: 3
Training loss: 1.4445133209228516
Validation loss: 2.0221963028113046

Epoch: 5| Step: 4
Training loss: 2.7450931072235107
Validation loss: 2.016253431638082

Epoch: 5| Step: 5
Training loss: 2.3369243144989014
Validation loss: 2.022723356882731

Epoch: 5| Step: 6
Training loss: 2.3202545642852783
Validation loss: 2.025390093525251

Epoch: 5| Step: 7
Training loss: 2.498561382293701
Validation loss: 2.028931960463524

Epoch: 5| Step: 8
Training loss: 1.9370628595352173
Validation loss: 2.024891644716263

Epoch: 5| Step: 9
Training loss: 2.5992965698242188
Validation loss: 2.0374421179294586

Epoch: 5| Step: 10
Training loss: 1.9524860382080078
Validation loss: 2.024866392215093

Epoch: 5| Step: 11
Training loss: 1.849286675453186
Validation loss: 2.0198016315698624

Epoch: 116| Step: 0
Training loss: 2.282391309738159
Validation loss: 2.0192986329396567

Epoch: 5| Step: 1
Training loss: 2.174287796020508
Validation loss: 2.0314922829469046

Epoch: 5| Step: 2
Training loss: 2.030392646789551
Validation loss: 2.030461793144544

Epoch: 5| Step: 3
Training loss: 2.1046745777130127
Validation loss: 2.02655990421772

Epoch: 5| Step: 4
Training loss: 1.5729334354400635
Validation loss: 2.028101568420728

Epoch: 5| Step: 5
Training loss: 2.1554148197174072
Validation loss: 2.028755376736323

Epoch: 5| Step: 6
Training loss: 2.3418126106262207
Validation loss: 2.0326037257909775

Epoch: 5| Step: 7
Training loss: 1.8761190176010132
Validation loss: 2.0353641460339227

Epoch: 5| Step: 8
Training loss: 2.099961519241333
Validation loss: 2.0311321963866553

Epoch: 5| Step: 9
Training loss: 2.6363449096679688
Validation loss: 2.035695885618528

Epoch: 5| Step: 10
Training loss: 1.9654194116592407
Validation loss: 2.0392617285251617

Epoch: 5| Step: 11
Training loss: 2.415970802307129
Validation loss: 2.052552819252014

Epoch: 117| Step: 0
Training loss: 1.6566988229751587
Validation loss: 2.0487854033708572

Epoch: 5| Step: 1
Training loss: 2.5787646770477295
Validation loss: 2.048547009627024

Epoch: 5| Step: 2
Training loss: 2.0510072708129883
Validation loss: 2.0364786883195243

Epoch: 5| Step: 3
Training loss: 1.8363304138183594
Validation loss: 2.022794554630915

Epoch: 5| Step: 4
Training loss: 2.183922529220581
Validation loss: 2.0115104715029397

Epoch: 5| Step: 5
Training loss: 2.1112847328186035
Validation loss: 2.020444706082344

Epoch: 5| Step: 6
Training loss: 2.1094603538513184
Validation loss: 2.012705077727636

Epoch: 5| Step: 7
Training loss: 2.0956764221191406
Validation loss: 2.015193780263265

Epoch: 5| Step: 8
Training loss: 2.2776122093200684
Validation loss: 2.0138015697399774

Epoch: 5| Step: 9
Training loss: 1.8706928491592407
Validation loss: 2.010507663091024

Epoch: 5| Step: 10
Training loss: 2.722550392150879
Validation loss: 2.0146237860123315

Epoch: 5| Step: 11
Training loss: 2.4035892486572266
Validation loss: 2.0120099683602652

Epoch: 118| Step: 0
Training loss: 2.5200371742248535
Validation loss: 2.0059458762407303

Epoch: 5| Step: 1
Training loss: 2.4569711685180664
Validation loss: 2.0073669155438743

Epoch: 5| Step: 2
Training loss: 2.3758442401885986
Validation loss: 2.0129540463288627

Epoch: 5| Step: 3
Training loss: 2.159080743789673
Validation loss: 2.0176719427108765

Epoch: 5| Step: 4
Training loss: 1.9619636535644531
Validation loss: 2.0247211307287216

Epoch: 5| Step: 5
Training loss: 2.3684778213500977
Validation loss: 2.02033901711305

Epoch: 5| Step: 6
Training loss: 1.5455546379089355
Validation loss: 2.0147363940874734

Epoch: 5| Step: 7
Training loss: 2.0255463123321533
Validation loss: 2.0265406171480813

Epoch: 5| Step: 8
Training loss: 1.5618501901626587
Validation loss: 2.0201426496108374

Epoch: 5| Step: 9
Training loss: 2.81292462348938
Validation loss: 2.0162531236807504

Epoch: 5| Step: 10
Training loss: 1.6628223657608032
Validation loss: 2.0201792816321054

Epoch: 5| Step: 11
Training loss: 1.820096731185913
Validation loss: 2.0123424331347146

Epoch: 119| Step: 0
Training loss: 2.192409038543701
Validation loss: 2.0108161022265754

Epoch: 5| Step: 1
Training loss: 2.1054515838623047
Validation loss: 2.0193858444690704

Epoch: 5| Step: 2
Training loss: 1.9550119638442993
Validation loss: 2.016249423225721

Epoch: 5| Step: 3
Training loss: 2.2285096645355225
Validation loss: 2.0102867583433786

Epoch: 5| Step: 4
Training loss: 2.0931522846221924
Validation loss: 2.026333063840866

Epoch: 5| Step: 5
Training loss: 1.9334434270858765
Validation loss: 2.0266309082508087

Epoch: 5| Step: 6
Training loss: 2.5009732246398926
Validation loss: 2.031539171934128

Epoch: 5| Step: 7
Training loss: 2.0432212352752686
Validation loss: 2.017839416861534

Epoch: 5| Step: 8
Training loss: 2.0042741298675537
Validation loss: 2.0257634917894998

Epoch: 5| Step: 9
Training loss: 1.8000129461288452
Validation loss: 2.033442268768946

Epoch: 5| Step: 10
Training loss: 2.061432361602783
Validation loss: 2.0266879399617515

Epoch: 5| Step: 11
Training loss: 3.809633731842041
Validation loss: 2.0290512492259345

Epoch: 120| Step: 0
Training loss: 2.02022123336792
Validation loss: 2.025160849094391

Epoch: 5| Step: 1
Training loss: 1.9235652685165405
Validation loss: 2.016268864274025

Epoch: 5| Step: 2
Training loss: 2.0165982246398926
Validation loss: 2.018051271637281

Epoch: 5| Step: 3
Training loss: 2.0886194705963135
Validation loss: 2.006197050213814

Epoch: 5| Step: 4
Training loss: 1.9127918481826782
Validation loss: 2.0135318438212075

Epoch: 5| Step: 5
Training loss: 2.1357929706573486
Validation loss: 2.019579907258352

Epoch: 5| Step: 6
Training loss: 2.069117546081543
Validation loss: 2.0171622733275094

Epoch: 5| Step: 7
Training loss: 2.550792932510376
Validation loss: 2.0148151268561683

Epoch: 5| Step: 8
Training loss: 1.965915322303772
Validation loss: 2.0205527494351068

Epoch: 5| Step: 9
Training loss: 2.2422268390655518
Validation loss: 2.0243032524983087

Epoch: 5| Step: 10
Training loss: 2.233731269836426
Validation loss: 2.028295412659645

Epoch: 5| Step: 11
Training loss: 3.3235058784484863
Validation loss: 2.0232754151026406

Epoch: 121| Step: 0
Training loss: 2.0467283725738525
Validation loss: 2.0320230424404144

Epoch: 5| Step: 1
Training loss: 1.8145742416381836
Validation loss: 2.0215258647998176

Epoch: 5| Step: 2
Training loss: 1.8783032894134521
Validation loss: 2.0320222824811935

Epoch: 5| Step: 3
Training loss: 2.505455493927002
Validation loss: 2.0202798744042716

Epoch: 5| Step: 4
Training loss: 1.831992745399475
Validation loss: 2.0257745534181595

Epoch: 5| Step: 5
Training loss: 2.1282565593719482
Validation loss: 2.033565108974775

Epoch: 5| Step: 6
Training loss: 2.3671278953552246
Validation loss: 2.025872846444448

Epoch: 5| Step: 7
Training loss: 2.441122055053711
Validation loss: 2.028837333122889

Epoch: 5| Step: 8
Training loss: 1.569558024406433
Validation loss: 2.0213392873605094

Epoch: 5| Step: 9
Training loss: 2.303873062133789
Validation loss: 2.0157493551572165

Epoch: 5| Step: 10
Training loss: 2.3727383613586426
Validation loss: 2.019901658097903

Epoch: 5| Step: 11
Training loss: 2.1779065132141113
Validation loss: 2.0167215168476105

Epoch: 122| Step: 0
Training loss: 2.0164763927459717
Validation loss: 2.0206419279177985

Epoch: 5| Step: 1
Training loss: 1.694207787513733
Validation loss: 2.022357225418091

Epoch: 5| Step: 2
Training loss: 2.215026378631592
Validation loss: 2.0440180699030557

Epoch: 5| Step: 3
Training loss: 2.2268176078796387
Validation loss: 2.0264962216218314

Epoch: 5| Step: 4
Training loss: 2.1618404388427734
Validation loss: 2.0381856064001718

Epoch: 5| Step: 5
Training loss: 1.7829997539520264
Validation loss: 2.0511625508467355

Epoch: 5| Step: 6
Training loss: 1.783919095993042
Validation loss: 2.0295513321956

Epoch: 5| Step: 7
Training loss: 2.052950382232666
Validation loss: 2.0374489625295005

Epoch: 5| Step: 8
Training loss: 2.849324941635132
Validation loss: 2.0303170581658683

Epoch: 5| Step: 9
Training loss: 2.6150994300842285
Validation loss: 2.0342081685860953

Epoch: 5| Step: 10
Training loss: 2.1390390396118164
Validation loss: 2.0355846285820007

Epoch: 5| Step: 11
Training loss: 1.453169345855713
Validation loss: 2.0235482454299927

Epoch: 123| Step: 0
Training loss: 1.822366714477539
Validation loss: 2.019914279381434

Epoch: 5| Step: 1
Training loss: 2.723036289215088
Validation loss: 2.011949603756269

Epoch: 5| Step: 2
Training loss: 1.9051659107208252
Validation loss: 2.010372370481491

Epoch: 5| Step: 3
Training loss: 1.8232088088989258
Validation loss: 2.012821634610494

Epoch: 5| Step: 4
Training loss: 2.1866068840026855
Validation loss: 2.0123297621806464

Epoch: 5| Step: 5
Training loss: 1.8530464172363281
Validation loss: 2.018500412503878

Epoch: 5| Step: 6
Training loss: 1.9634811878204346
Validation loss: 2.0177511821190515

Epoch: 5| Step: 7
Training loss: 2.4165291786193848
Validation loss: 2.016713743408521

Epoch: 5| Step: 8
Training loss: 1.8851197957992554
Validation loss: 2.014249632755915

Epoch: 5| Step: 9
Training loss: 2.6796412467956543
Validation loss: 2.017702062924703

Epoch: 5| Step: 10
Training loss: 2.115020275115967
Validation loss: 2.023138071099917

Epoch: 5| Step: 11
Training loss: 1.5553454160690308
Validation loss: 2.0306391517321267

Epoch: 124| Step: 0
Training loss: 2.5332443714141846
Validation loss: 2.027355452378591

Epoch: 5| Step: 1
Training loss: 1.8260643482208252
Validation loss: 2.0231227427721024

Epoch: 5| Step: 2
Training loss: 2.3710825443267822
Validation loss: 2.03610622882843

Epoch: 5| Step: 3
Training loss: 2.1185202598571777
Validation loss: 2.0307159473498664

Epoch: 5| Step: 4
Training loss: 1.9360923767089844
Validation loss: 2.0309695452451706

Epoch: 5| Step: 5
Training loss: 2.247337579727173
Validation loss: 2.038473849495252

Epoch: 5| Step: 6
Training loss: 2.959868907928467
Validation loss: 2.040396437048912

Epoch: 5| Step: 7
Training loss: 1.7453193664550781
Validation loss: 2.036991462111473

Epoch: 5| Step: 8
Training loss: 1.8101189136505127
Validation loss: 2.0317332247893014

Epoch: 5| Step: 9
Training loss: 1.5271185636520386
Validation loss: 2.040429795781771

Epoch: 5| Step: 10
Training loss: 2.0766091346740723
Validation loss: 2.0361431290706

Epoch: 5| Step: 11
Training loss: 2.5285675525665283
Validation loss: 2.0342843929926553

Epoch: 125| Step: 0
Training loss: 1.9142688512802124
Validation loss: 2.0258135000864663

Epoch: 5| Step: 1
Training loss: 2.4246535301208496
Validation loss: 2.02154807249705

Epoch: 5| Step: 2
Training loss: 1.4669822454452515
Validation loss: 2.0300633857647576

Epoch: 5| Step: 3
Training loss: 2.0756022930145264
Validation loss: 2.027230759461721

Epoch: 5| Step: 4
Training loss: 2.1159822940826416
Validation loss: 2.029870629310608

Epoch: 5| Step: 5
Training loss: 2.5013015270233154
Validation loss: 2.024779493610064

Epoch: 5| Step: 6
Training loss: 2.9761390686035156
Validation loss: 2.0318495829900107

Epoch: 5| Step: 7
Training loss: 1.890936255455017
Validation loss: 2.030152827501297

Epoch: 5| Step: 8
Training loss: 1.8914676904678345
Validation loss: 2.0186826636393866

Epoch: 5| Step: 9
Training loss: 2.384970188140869
Validation loss: 2.0239490220944085

Epoch: 5| Step: 10
Training loss: 1.7821714878082275
Validation loss: 2.031022851665815

Epoch: 5| Step: 11
Training loss: 1.5792663097381592
Validation loss: 2.0338924725850425

Epoch: 126| Step: 0
Training loss: 1.6432205438613892
Validation loss: 2.0127125531435013

Epoch: 5| Step: 1
Training loss: 1.8751245737075806
Validation loss: 2.0226094325383506

Epoch: 5| Step: 2
Training loss: 2.044320583343506
Validation loss: 2.0277998646100364

Epoch: 5| Step: 3
Training loss: 2.260474920272827
Validation loss: 2.046966329216957

Epoch: 5| Step: 4
Training loss: 2.9280810356140137
Validation loss: 2.069758355617523

Epoch: 5| Step: 5
Training loss: 1.932795763015747
Validation loss: 2.092981403072675

Epoch: 5| Step: 6
Training loss: 2.2268335819244385
Validation loss: 2.0679913063844046

Epoch: 5| Step: 7
Training loss: 2.2413580417633057
Validation loss: 2.037449300289154

Epoch: 5| Step: 8
Training loss: 2.450167417526245
Validation loss: 2.0344573756059012

Epoch: 5| Step: 9
Training loss: 2.093874216079712
Validation loss: 2.019273320833842

Epoch: 5| Step: 10
Training loss: 2.177262783050537
Validation loss: 2.0075097580750785

Epoch: 5| Step: 11
Training loss: 1.8543636798858643
Validation loss: 2.0030478090047836

Epoch: 127| Step: 0
Training loss: 2.4434242248535156
Validation loss: 2.0094197740157447

Epoch: 5| Step: 1
Training loss: 1.9559863805770874
Validation loss: 2.0164564152558646

Epoch: 5| Step: 2
Training loss: 2.0613760948181152
Validation loss: 2.014855240782102

Epoch: 5| Step: 3
Training loss: 2.107311964035034
Validation loss: 2.0265414069096246

Epoch: 5| Step: 4
Training loss: 2.359931468963623
Validation loss: 2.0231097092231116

Epoch: 5| Step: 5
Training loss: 2.072251796722412
Validation loss: 2.035911798477173

Epoch: 5| Step: 6
Training loss: 2.1476852893829346
Validation loss: 2.0308430592219033

Epoch: 5| Step: 7
Training loss: 2.090625047683716
Validation loss: 2.038374940554301

Epoch: 5| Step: 8
Training loss: 1.9002784490585327
Validation loss: 2.034307142098745

Epoch: 5| Step: 9
Training loss: 2.4711365699768066
Validation loss: 2.0314772526423135

Epoch: 5| Step: 10
Training loss: 2.382993459701538
Validation loss: 2.022950674096743

Epoch: 5| Step: 11
Training loss: 1.6588295698165894
Validation loss: 2.035195897022883

Epoch: 128| Step: 0
Training loss: 2.130446195602417
Validation loss: 2.021802306175232

Epoch: 5| Step: 1
Training loss: 2.197767496109009
Validation loss: 2.01637864112854

Epoch: 5| Step: 2
Training loss: 2.6738293170928955
Validation loss: 2.0152807285388312

Epoch: 5| Step: 3
Training loss: 2.154144287109375
Validation loss: 1.988853504260381

Epoch: 5| Step: 4
Training loss: 1.974827527999878
Validation loss: 2.0051051676273346

Epoch: 5| Step: 5
Training loss: 2.3673808574676514
Validation loss: 1.9991289128859837

Epoch: 5| Step: 6
Training loss: 1.8752291202545166
Validation loss: 1.9967833310365677

Epoch: 5| Step: 7
Training loss: 2.2367610931396484
Validation loss: 1.9909131626288097

Epoch: 5| Step: 8
Training loss: 2.283280849456787
Validation loss: 2.012132783730825

Epoch: 5| Step: 9
Training loss: 2.1090176105499268
Validation loss: 2.0099370727936425

Epoch: 5| Step: 10
Training loss: 1.9712247848510742
Validation loss: 2.00749064485232

Epoch: 5| Step: 11
Training loss: 0.7883319854736328
Validation loss: 2.013285835584005

Epoch: 129| Step: 0
Training loss: 1.966040849685669
Validation loss: 2.012032851576805

Epoch: 5| Step: 1
Training loss: 2.1880526542663574
Validation loss: 2.010772486527761

Epoch: 5| Step: 2
Training loss: 1.8946895599365234
Validation loss: 2.0103535056114197

Epoch: 5| Step: 3
Training loss: 2.1674771308898926
Validation loss: 2.0057950019836426

Epoch: 5| Step: 4
Training loss: 2.3944919109344482
Validation loss: 2.00688898563385

Epoch: 5| Step: 5
Training loss: 2.4904673099517822
Validation loss: 2.0149246553579965

Epoch: 5| Step: 6
Training loss: 2.389876127243042
Validation loss: 2.018648808201154

Epoch: 5| Step: 7
Training loss: 1.7091407775878906
Validation loss: 2.0235273241996765

Epoch: 5| Step: 8
Training loss: 1.8364654779434204
Validation loss: 2.0315550416707993

Epoch: 5| Step: 9
Training loss: 1.9382957220077515
Validation loss: 2.0280766437451043

Epoch: 5| Step: 10
Training loss: 2.562638759613037
Validation loss: 2.033251702785492

Epoch: 5| Step: 11
Training loss: 1.1692373752593994
Validation loss: 2.032457480827967

Epoch: 130| Step: 0
Training loss: 2.21748685836792
Validation loss: 2.0332064231236777

Epoch: 5| Step: 1
Training loss: 2.3278310298919678
Validation loss: 2.030085245768229

Epoch: 5| Step: 2
Training loss: 2.934288740158081
Validation loss: 2.037788743774096

Epoch: 5| Step: 3
Training loss: 1.5825226306915283
Validation loss: 2.0339721739292145

Epoch: 5| Step: 4
Training loss: 2.7367911338806152
Validation loss: 2.0356962382793427

Epoch: 5| Step: 5
Training loss: 2.222133159637451
Validation loss: 2.038433422644933

Epoch: 5| Step: 6
Training loss: 2.600106716156006
Validation loss: 2.0419693688551583

Epoch: 5| Step: 7
Training loss: 1.3671263456344604
Validation loss: 2.0455398708581924

Epoch: 5| Step: 8
Training loss: 1.6753562688827515
Validation loss: 2.0399091889460883

Epoch: 5| Step: 9
Training loss: 1.653236746788025
Validation loss: 2.0368892500797906

Epoch: 5| Step: 10
Training loss: 2.0080513954162598
Validation loss: 2.0373494178056717

Epoch: 5| Step: 11
Training loss: 1.7463525533676147
Validation loss: 2.036527077356974

Epoch: 131| Step: 0
Training loss: 2.120171546936035
Validation loss: 2.0401736199855804

Epoch: 5| Step: 1
Training loss: 2.2109851837158203
Validation loss: 2.034348780910174

Epoch: 5| Step: 2
Training loss: 1.9229719638824463
Validation loss: 2.032504161198934

Epoch: 5| Step: 3
Training loss: 2.2190632820129395
Validation loss: 2.0316000332434974

Epoch: 5| Step: 4
Training loss: 1.854742407798767
Validation loss: 2.0315819829702377

Epoch: 5| Step: 5
Training loss: 1.7240512371063232
Validation loss: 2.031911631425222

Epoch: 5| Step: 6
Training loss: 2.2899739742279053
Validation loss: 2.025276447335879

Epoch: 5| Step: 7
Training loss: 2.686689853668213
Validation loss: 2.0323113401730857

Epoch: 5| Step: 8
Training loss: 1.7875303030014038
Validation loss: 2.0285934507846832

Epoch: 5| Step: 9
Training loss: 2.073002576828003
Validation loss: 2.0319621513287225

Epoch: 5| Step: 10
Training loss: 2.4118919372558594
Validation loss: 2.0283149778842926

Epoch: 5| Step: 11
Training loss: 1.333516240119934
Validation loss: 2.0354670683542886

Epoch: 132| Step: 0
Training loss: 1.9598491191864014
Validation loss: 2.03974357744058

Epoch: 5| Step: 1
Training loss: 1.9024698734283447
Validation loss: 2.045161853233973

Epoch: 5| Step: 2
Training loss: 2.3258280754089355
Validation loss: 2.0442710518836975

Epoch: 5| Step: 3
Training loss: 2.025697708129883
Validation loss: 2.0444737573464713

Epoch: 5| Step: 4
Training loss: 2.439577341079712
Validation loss: 2.048316886027654

Epoch: 5| Step: 5
Training loss: 1.992635726928711
Validation loss: 2.050359159708023

Epoch: 5| Step: 6
Training loss: 2.1530544757843018
Validation loss: 2.038459395368894

Epoch: 5| Step: 7
Training loss: 1.8291181325912476
Validation loss: 2.051761582493782

Epoch: 5| Step: 8
Training loss: 2.3943123817443848
Validation loss: 2.039167727033297

Epoch: 5| Step: 9
Training loss: 2.0544674396514893
Validation loss: 2.040478919943174

Epoch: 5| Step: 10
Training loss: 2.1498589515686035
Validation loss: 2.067474275827408

Epoch: 5| Step: 11
Training loss: 1.6687394380569458
Validation loss: 2.0501108169555664

Epoch: 133| Step: 0
Training loss: 2.4304847717285156
Validation loss: 2.0387723992268243

Epoch: 5| Step: 1
Training loss: 2.18975830078125
Validation loss: 2.0480513821045556

Epoch: 5| Step: 2
Training loss: 2.074328899383545
Validation loss: 2.0416840612888336

Epoch: 5| Step: 3
Training loss: 1.699772834777832
Validation loss: 2.057109678785006

Epoch: 5| Step: 4
Training loss: 1.768659234046936
Validation loss: 2.0443566739559174

Epoch: 5| Step: 5
Training loss: 2.659013271331787
Validation loss: 2.0415665606657663

Epoch: 5| Step: 6
Training loss: 1.746717095375061
Validation loss: 2.030686065554619

Epoch: 5| Step: 7
Training loss: 1.9291126728057861
Validation loss: 2.032713000973066

Epoch: 5| Step: 8
Training loss: 1.912310004234314
Validation loss: 2.0320147474606833

Epoch: 5| Step: 9
Training loss: 2.6778550148010254
Validation loss: 2.0260233680407205

Epoch: 5| Step: 10
Training loss: 1.7549434900283813
Validation loss: 2.0365976144870124

Epoch: 5| Step: 11
Training loss: 3.4908103942871094
Validation loss: 2.0238265693187714

Epoch: 134| Step: 0
Training loss: 1.6382678747177124
Validation loss: 2.0248126735289893

Epoch: 5| Step: 1
Training loss: 1.8647043704986572
Validation loss: 2.0185583581527076

Epoch: 5| Step: 2
Training loss: 2.359947681427002
Validation loss: 2.031700938940048

Epoch: 5| Step: 3
Training loss: 2.032477855682373
Validation loss: 2.029519572854042

Epoch: 5| Step: 4
Training loss: 2.359262704849243
Validation loss: 2.039937595526377

Epoch: 5| Step: 5
Training loss: 1.891700029373169
Validation loss: 2.0346510161956153

Epoch: 5| Step: 6
Training loss: 1.9864507913589478
Validation loss: 2.0373710095882416

Epoch: 5| Step: 7
Training loss: 2.068629741668701
Validation loss: 2.0312017301718392

Epoch: 5| Step: 8
Training loss: 2.1073906421661377
Validation loss: 2.0314209163188934

Epoch: 5| Step: 9
Training loss: 2.474933624267578
Validation loss: 2.042909408609072

Epoch: 5| Step: 10
Training loss: 2.2508738040924072
Validation loss: 2.0363366504510245

Epoch: 5| Step: 11
Training loss: 1.7171075344085693
Validation loss: 2.043501848975817

Epoch: 135| Step: 0
Training loss: 2.3864564895629883
Validation loss: 2.0496142357587814

Epoch: 5| Step: 1
Training loss: 2.3513522148132324
Validation loss: 2.0611043125391006

Epoch: 5| Step: 2
Training loss: 1.6547950506210327
Validation loss: 2.056148832043012

Epoch: 5| Step: 3
Training loss: 2.279819965362549
Validation loss: 2.043877681096395

Epoch: 5| Step: 4
Training loss: 1.5838282108306885
Validation loss: 2.0360385477542877

Epoch: 5| Step: 5
Training loss: 2.617058515548706
Validation loss: 2.0467522541681924

Epoch: 5| Step: 6
Training loss: 2.244467258453369
Validation loss: 2.03735621770223

Epoch: 5| Step: 7
Training loss: 1.8311269283294678
Validation loss: 2.0288142363230386

Epoch: 5| Step: 8
Training loss: 2.0773463249206543
Validation loss: 2.0388556768496833

Epoch: 5| Step: 9
Training loss: 2.3050055503845215
Validation loss: 2.041675711671511

Epoch: 5| Step: 10
Training loss: 1.6008548736572266
Validation loss: 2.0333208491404853

Epoch: 5| Step: 11
Training loss: 2.855752944946289
Validation loss: 2.0461226999759674

Epoch: 136| Step: 0
Training loss: 2.0018134117126465
Validation loss: 2.039953902363777

Epoch: 5| Step: 1
Training loss: 1.6276401281356812
Validation loss: 2.0453274796406427

Epoch: 5| Step: 2
Training loss: 2.3628010749816895
Validation loss: 2.0299661060174308

Epoch: 5| Step: 3
Training loss: 2.3356852531433105
Validation loss: 2.044716273744901

Epoch: 5| Step: 4
Training loss: 1.9743297100067139
Validation loss: 2.0559277683496475

Epoch: 5| Step: 5
Training loss: 2.245497703552246
Validation loss: 2.0428639352321625

Epoch: 5| Step: 6
Training loss: 1.7920074462890625
Validation loss: 2.0452580948670707

Epoch: 5| Step: 7
Training loss: 2.704807758331299
Validation loss: 2.036204293370247

Epoch: 5| Step: 8
Training loss: 1.7663758993148804
Validation loss: 2.037189627687136

Epoch: 5| Step: 9
Training loss: 2.049144744873047
Validation loss: 2.0399510165055594

Epoch: 5| Step: 10
Training loss: 1.9970872402191162
Validation loss: 2.044999892512957

Epoch: 5| Step: 11
Training loss: 2.5502235889434814
Validation loss: 2.042002027233442

Epoch: 137| Step: 0
Training loss: 2.107438802719116
Validation loss: 2.0282853047053018

Epoch: 5| Step: 1
Training loss: 2.345200538635254
Validation loss: 2.031449834505717

Epoch: 5| Step: 2
Training loss: 2.420902729034424
Validation loss: 2.0389447063207626

Epoch: 5| Step: 3
Training loss: 1.7052676677703857
Validation loss: 2.0362582753101983

Epoch: 5| Step: 4
Training loss: 1.6202586889266968
Validation loss: 2.032450964053472

Epoch: 5| Step: 5
Training loss: 2.691521406173706
Validation loss: 2.0321178883314133

Epoch: 5| Step: 6
Training loss: 2.2708756923675537
Validation loss: 2.0269223550955453

Epoch: 5| Step: 7
Training loss: 2.182582378387451
Validation loss: 2.0262197156747184

Epoch: 5| Step: 8
Training loss: 2.4616074562072754
Validation loss: 2.030828982591629

Epoch: 5| Step: 9
Training loss: 1.9194637537002563
Validation loss: 2.026707241932551

Epoch: 5| Step: 10
Training loss: 1.2035160064697266
Validation loss: 2.0319887896378837

Epoch: 5| Step: 11
Training loss: 1.521578311920166
Validation loss: 2.0241273790597916

Epoch: 138| Step: 0
Training loss: 2.4437084197998047
Validation loss: 2.030860126018524

Epoch: 5| Step: 1
Training loss: 2.284633159637451
Validation loss: 2.0183388938506446

Epoch: 5| Step: 2
Training loss: 1.8756738901138306
Validation loss: 2.0392579287290573

Epoch: 5| Step: 3
Training loss: 2.1802163124084473
Validation loss: 2.0263132403294244

Epoch: 5| Step: 4
Training loss: 1.8128589391708374
Validation loss: 2.0467665692170462

Epoch: 5| Step: 5
Training loss: 1.8510236740112305
Validation loss: 2.036125496029854

Epoch: 5| Step: 6
Training loss: 2.017346143722534
Validation loss: 2.0429938485225043

Epoch: 5| Step: 7
Training loss: 2.3493523597717285
Validation loss: 2.0374300479888916

Epoch: 5| Step: 8
Training loss: 1.898737907409668
Validation loss: 2.0360257724920907

Epoch: 5| Step: 9
Training loss: 2.7380528450012207
Validation loss: 2.031656781832377

Epoch: 5| Step: 10
Training loss: 1.5088655948638916
Validation loss: 2.0413036346435547

Epoch: 5| Step: 11
Training loss: 1.463329553604126
Validation loss: 2.038862685362498

Epoch: 139| Step: 0
Training loss: 1.9145927429199219
Validation loss: 2.0494709809621177

Epoch: 5| Step: 1
Training loss: 2.1503756046295166
Validation loss: 2.0548960715532303

Epoch: 5| Step: 2
Training loss: 2.6555895805358887
Validation loss: 2.046942417820295

Epoch: 5| Step: 3
Training loss: 2.2439825534820557
Validation loss: 2.0528574784596763

Epoch: 5| Step: 4
Training loss: 1.705437421798706
Validation loss: 2.0399282972017923

Epoch: 5| Step: 5
Training loss: 1.9234527349472046
Validation loss: 2.039563869436582

Epoch: 5| Step: 6
Training loss: 1.720741868019104
Validation loss: 2.0296453634897866

Epoch: 5| Step: 7
Training loss: 1.8638817071914673
Validation loss: 2.0435532281796136

Epoch: 5| Step: 8
Training loss: 1.843347191810608
Validation loss: 2.0446149160464606

Epoch: 5| Step: 9
Training loss: 1.9739879369735718
Validation loss: 2.041620468099912

Epoch: 5| Step: 10
Training loss: 2.6166443824768066
Validation loss: 2.051986336708069

Epoch: 5| Step: 11
Training loss: 2.8067760467529297
Validation loss: 2.0320963114500046

Epoch: 140| Step: 0
Training loss: 2.326901912689209
Validation loss: 2.0307277888059616

Epoch: 5| Step: 1
Training loss: 1.9120944738388062
Validation loss: 2.028184865911802

Epoch: 5| Step: 2
Training loss: 1.5408077239990234
Validation loss: 2.0282683223485947

Epoch: 5| Step: 3
Training loss: 2.066784620285034
Validation loss: 2.038654158512751

Epoch: 5| Step: 4
Training loss: 1.612370252609253
Validation loss: 2.0503176053365073

Epoch: 5| Step: 5
Training loss: 2.1562461853027344
Validation loss: 2.0462346027294793

Epoch: 5| Step: 6
Training loss: 2.6091532707214355
Validation loss: 2.0508705973625183

Epoch: 5| Step: 7
Training loss: 2.5048956871032715
Validation loss: 2.0538385063409805

Epoch: 5| Step: 8
Training loss: 1.996978521347046
Validation loss: 2.044297238190969

Epoch: 5| Step: 9
Training loss: 2.1283931732177734
Validation loss: 2.042356257637342

Epoch: 5| Step: 10
Training loss: 2.122223377227783
Validation loss: 2.049873784184456

Epoch: 5| Step: 11
Training loss: 1.3145320415496826
Validation loss: 2.0397275487581887

Epoch: 141| Step: 0
Training loss: 2.312730073928833
Validation loss: 2.0404125948747

Epoch: 5| Step: 1
Training loss: 2.7920734882354736
Validation loss: 2.040907214085261

Epoch: 5| Step: 2
Training loss: 2.1987788677215576
Validation loss: 2.0394619703292847

Epoch: 5| Step: 3
Training loss: 1.827833890914917
Validation loss: 2.040243605772654

Epoch: 5| Step: 4
Training loss: 1.8882496356964111
Validation loss: 2.0301211029291153

Epoch: 5| Step: 5
Training loss: 1.6384235620498657
Validation loss: 2.03867514928182

Epoch: 5| Step: 6
Training loss: 2.347851514816284
Validation loss: 2.039591128627459

Epoch: 5| Step: 7
Training loss: 1.7632795572280884
Validation loss: 2.031479095419248

Epoch: 5| Step: 8
Training loss: 1.5558267831802368
Validation loss: 2.048888439933459

Epoch: 5| Step: 9
Training loss: 1.9301140308380127
Validation loss: 2.048305556178093

Epoch: 5| Step: 10
Training loss: 2.6022112369537354
Validation loss: 2.0474116802215576

Epoch: 5| Step: 11
Training loss: 1.311840295791626
Validation loss: 2.0447269131739936

Epoch: 142| Step: 0
Training loss: 2.194833517074585
Validation loss: 2.045457219084104

Epoch: 5| Step: 1
Training loss: 2.0014760494232178
Validation loss: 2.074120302995046

Epoch: 5| Step: 2
Training loss: 2.166109800338745
Validation loss: 2.0617390920718512

Epoch: 5| Step: 3
Training loss: 1.4534947872161865
Validation loss: 2.052737846970558

Epoch: 5| Step: 4
Training loss: 2.6558799743652344
Validation loss: 2.041117951273918

Epoch: 5| Step: 5
Training loss: 2.1089277267456055
Validation loss: 2.035969376564026

Epoch: 5| Step: 6
Training loss: 2.3225865364074707
Validation loss: 2.041547179222107

Epoch: 5| Step: 7
Training loss: 2.3158302307128906
Validation loss: 2.0331802368164062

Epoch: 5| Step: 8
Training loss: 2.264392852783203
Validation loss: 2.0227685819069543

Epoch: 5| Step: 9
Training loss: 1.9193298816680908
Validation loss: 2.035518556833267

Epoch: 5| Step: 10
Training loss: 1.7780033349990845
Validation loss: 2.027687261501948

Epoch: 5| Step: 11
Training loss: 1.254977822303772
Validation loss: 2.0199984858433404

Epoch: 143| Step: 0
Training loss: 1.6304750442504883
Validation loss: 2.016201466321945

Epoch: 5| Step: 1
Training loss: 1.7917625904083252
Validation loss: 2.0232877830664315

Epoch: 5| Step: 2
Training loss: 1.9265152215957642
Validation loss: 2.0309724559386573

Epoch: 5| Step: 3
Training loss: 1.6778032779693604
Validation loss: 2.0402425477902093

Epoch: 5| Step: 4
Training loss: 2.567204475402832
Validation loss: 2.048528944452604

Epoch: 5| Step: 5
Training loss: 2.3482613563537598
Validation loss: 2.030311038096746

Epoch: 5| Step: 6
Training loss: 2.406144857406616
Validation loss: 2.0394984434048333

Epoch: 5| Step: 7
Training loss: 1.889744758605957
Validation loss: 2.019657333691915

Epoch: 5| Step: 8
Training loss: 1.7760719060897827
Validation loss: 2.017150416970253

Epoch: 5| Step: 9
Training loss: 2.837139129638672
Validation loss: 2.012814844648043

Epoch: 5| Step: 10
Training loss: 2.0883452892303467
Validation loss: 2.005220820506414

Epoch: 5| Step: 11
Training loss: 2.1057004928588867
Validation loss: 1.9957472483317058

Epoch: 144| Step: 0
Training loss: 2.1185498237609863
Validation loss: 2.0076102167367935

Epoch: 5| Step: 1
Training loss: 1.804531455039978
Validation loss: 2.0021737664937973

Epoch: 5| Step: 2
Training loss: 1.9349339008331299
Validation loss: 2.012068957090378

Epoch: 5| Step: 3
Training loss: 2.4697983264923096
Validation loss: 2.0171960095564523

Epoch: 5| Step: 4
Training loss: 1.7916154861450195
Validation loss: 2.012307569384575

Epoch: 5| Step: 5
Training loss: 1.9583784341812134
Validation loss: 2.0133328586816788

Epoch: 5| Step: 6
Training loss: 1.9338195323944092
Validation loss: 2.008970116575559

Epoch: 5| Step: 7
Training loss: 2.8068459033966064
Validation loss: 2.0198566764593124

Epoch: 5| Step: 8
Training loss: 1.9489580392837524
Validation loss: 2.0149875034888587

Epoch: 5| Step: 9
Training loss: 1.5677192211151123
Validation loss: 2.0140176564455032

Epoch: 5| Step: 10
Training loss: 2.4088191986083984
Validation loss: 2.0144164115190506

Epoch: 5| Step: 11
Training loss: 2.8367786407470703
Validation loss: 2.0252007146676383

Epoch: 145| Step: 0
Training loss: 2.373734474182129
Validation loss: 2.0064225792884827

Epoch: 5| Step: 1
Training loss: 2.0606589317321777
Validation loss: 2.00262942413489

Epoch: 5| Step: 2
Training loss: 2.2394497394561768
Validation loss: 2.0160549531380334

Epoch: 5| Step: 3
Training loss: 2.056560754776001
Validation loss: 2.022088885307312

Epoch: 5| Step: 4
Training loss: 2.1443023681640625
Validation loss: 2.022355164090792

Epoch: 5| Step: 5
Training loss: 1.7697436809539795
Validation loss: 2.0364972054958344

Epoch: 5| Step: 6
Training loss: 1.5781095027923584
Validation loss: 2.036605184276899

Epoch: 5| Step: 7
Training loss: 1.8680063486099243
Validation loss: 2.0428215314944587

Epoch: 5| Step: 8
Training loss: 2.4796738624572754
Validation loss: 2.0434037248293557

Epoch: 5| Step: 9
Training loss: 2.706169843673706
Validation loss: 2.0453899105389914

Epoch: 5| Step: 10
Training loss: 2.2457871437072754
Validation loss: 2.044217591484388

Epoch: 5| Step: 11
Training loss: 1.19158136844635
Validation loss: 2.0360222657521567

Epoch: 146| Step: 0
Training loss: 2.111819267272949
Validation loss: 2.034610132376353

Epoch: 5| Step: 1
Training loss: 2.00329327583313
Validation loss: 2.015660564104716

Epoch: 5| Step: 2
Training loss: 1.810225248336792
Validation loss: 2.006441205739975

Epoch: 5| Step: 3
Training loss: 2.1288821697235107
Validation loss: 2.0126842310031257

Epoch: 5| Step: 4
Training loss: 2.833728551864624
Validation loss: 2.0166094303131104

Epoch: 5| Step: 5
Training loss: 1.7350871562957764
Validation loss: 2.032902513941129

Epoch: 5| Step: 6
Training loss: 2.679419994354248
Validation loss: 2.035835082332293

Epoch: 5| Step: 7
Training loss: 2.03114914894104
Validation loss: 2.046958401799202

Epoch: 5| Step: 8
Training loss: 2.1385130882263184
Validation loss: 2.060888628164927

Epoch: 5| Step: 9
Training loss: 1.7662070989608765
Validation loss: 2.0613659222920737

Epoch: 5| Step: 10
Training loss: 1.8967053890228271
Validation loss: 2.0536772857109704

Epoch: 5| Step: 11
Training loss: 2.4628961086273193
Validation loss: 2.067564050356547

Epoch: 147| Step: 0
Training loss: 2.486104726791382
Validation loss: 2.044033169746399

Epoch: 5| Step: 1
Training loss: 1.9331233501434326
Validation loss: 2.042556573947271

Epoch: 5| Step: 2
Training loss: 1.7655479907989502
Validation loss: 2.0325232644875846

Epoch: 5| Step: 3
Training loss: 2.1528186798095703
Validation loss: 2.041655406355858

Epoch: 5| Step: 4
Training loss: 2.1206676959991455
Validation loss: 2.0440845092137656

Epoch: 5| Step: 5
Training loss: 1.694705605506897
Validation loss: 2.0503885646661124

Epoch: 5| Step: 6
Training loss: 1.954766869544983
Validation loss: 2.0624654988447824

Epoch: 5| Step: 7
Training loss: 1.8328825235366821
Validation loss: 2.062757189075152

Epoch: 5| Step: 8
Training loss: 2.403031587600708
Validation loss: 2.0599104911088943

Epoch: 5| Step: 9
Training loss: 2.255463123321533
Validation loss: 2.0697786609331765

Epoch: 5| Step: 10
Training loss: 2.3908283710479736
Validation loss: 2.070847069223722

Epoch: 5| Step: 11
Training loss: 1.438946008682251
Validation loss: 2.0688223342100778

Epoch: 148| Step: 0
Training loss: 2.422992706298828
Validation loss: 2.0426185379425683

Epoch: 5| Step: 1
Training loss: 2.164724588394165
Validation loss: 2.055250898003578

Epoch: 5| Step: 2
Training loss: 2.3594319820404053
Validation loss: 2.033404673139254

Epoch: 5| Step: 3
Training loss: 2.0035197734832764
Validation loss: 2.026286229491234

Epoch: 5| Step: 4
Training loss: 2.1569101810455322
Validation loss: 2.033823331197103

Epoch: 5| Step: 5
Training loss: 1.6802637577056885
Validation loss: 2.021987055738767

Epoch: 5| Step: 6
Training loss: 1.8230186700820923
Validation loss: 2.026917979121208

Epoch: 5| Step: 7
Training loss: 2.166027307510376
Validation loss: 2.0099788904190063

Epoch: 5| Step: 8
Training loss: 2.1193931102752686
Validation loss: 2.018113598227501

Epoch: 5| Step: 9
Training loss: 1.7343794107437134
Validation loss: 2.0202292799949646

Epoch: 5| Step: 10
Training loss: 2.1720352172851562
Validation loss: 2.0333482027053833

Epoch: 5| Step: 11
Training loss: 1.7749485969543457
Validation loss: 2.034310981631279

Epoch: 149| Step: 0
Training loss: 2.0089688301086426
Validation loss: 2.0393326183160148

Epoch: 5| Step: 1
Training loss: 2.29162859916687
Validation loss: 2.041180004676183

Epoch: 5| Step: 2
Training loss: 1.9219814538955688
Validation loss: 2.0458736568689346

Epoch: 5| Step: 3
Training loss: 1.9183521270751953
Validation loss: 2.0476921449104943

Epoch: 5| Step: 4
Training loss: 2.6744863986968994
Validation loss: 2.0498533050219216

Epoch: 5| Step: 5
Training loss: 2.00282621383667
Validation loss: 2.0420713424682617

Epoch: 5| Step: 6
Training loss: 1.569983720779419
Validation loss: 2.0377106616894403

Epoch: 5| Step: 7
Training loss: 1.8984525203704834
Validation loss: 2.0427580972512565

Epoch: 5| Step: 8
Training loss: 1.8821933269500732
Validation loss: 2.0314627339442572

Epoch: 5| Step: 9
Training loss: 2.521132469177246
Validation loss: 2.0428290168444314

Epoch: 5| Step: 10
Training loss: 1.9499073028564453
Validation loss: 2.034099499384562

Epoch: 5| Step: 11
Training loss: 1.3288853168487549
Validation loss: 2.0430846512317657

Epoch: 150| Step: 0
Training loss: 2.4604146480560303
Validation loss: 2.0305743465820947

Epoch: 5| Step: 1
Training loss: 1.993299126625061
Validation loss: 2.0317728767792382

Epoch: 5| Step: 2
Training loss: 2.07643985748291
Validation loss: 2.0327484011650085

Epoch: 5| Step: 3
Training loss: 2.0606155395507812
Validation loss: 2.0262301017840705

Epoch: 5| Step: 4
Training loss: 2.1421146392822266
Validation loss: 2.023091122508049

Epoch: 5| Step: 5
Training loss: 1.7923555374145508
Validation loss: 2.0232817033926644

Epoch: 5| Step: 6
Training loss: 1.8964351415634155
Validation loss: 2.0264139423767724

Epoch: 5| Step: 7
Training loss: 2.271803617477417
Validation loss: 2.031791473428408

Epoch: 5| Step: 8
Training loss: 1.9924427270889282
Validation loss: 2.035732607046763

Epoch: 5| Step: 9
Training loss: 2.0305533409118652
Validation loss: 2.037391424179077

Epoch: 5| Step: 10
Training loss: 2.325253963470459
Validation loss: 2.045454293489456

Epoch: 5| Step: 11
Training loss: 1.8438069820404053
Validation loss: 2.0608701705932617

Epoch: 151| Step: 0
Training loss: 2.06376576423645
Validation loss: 2.0655049085617065

Epoch: 5| Step: 1
Training loss: 2.152881145477295
Validation loss: 2.0703532695770264

Epoch: 5| Step: 2
Training loss: 2.5622220039367676
Validation loss: 2.0788242320219674

Epoch: 5| Step: 3
Training loss: 1.9310413599014282
Validation loss: 2.0644986778497696

Epoch: 5| Step: 4
Training loss: 1.8526582717895508
Validation loss: 2.0701720863580704

Epoch: 5| Step: 5
Training loss: 2.106377601623535
Validation loss: 2.056365961829821

Epoch: 5| Step: 6
Training loss: 2.101252794265747
Validation loss: 2.0800206611553826

Epoch: 5| Step: 7
Training loss: 1.9656537771224976
Validation loss: 2.070144305626551

Epoch: 5| Step: 8
Training loss: 2.429509401321411
Validation loss: 2.0581998080015182

Epoch: 5| Step: 9
Training loss: 1.7148380279541016
Validation loss: 2.033617153763771

Epoch: 5| Step: 10
Training loss: 2.025658130645752
Validation loss: 2.042621503273646

Epoch: 5| Step: 11
Training loss: 1.1588778495788574
Validation loss: 2.0373127361138663

Epoch: 152| Step: 0
Training loss: 2.134598970413208
Validation loss: 2.0432270020246506

Epoch: 5| Step: 1
Training loss: 2.0816519260406494
Validation loss: 2.038905451695124

Epoch: 5| Step: 2
Training loss: 2.5567638874053955
Validation loss: 2.058148513237635

Epoch: 5| Step: 3
Training loss: 2.219249725341797
Validation loss: 2.0695043802261353

Epoch: 5| Step: 4
Training loss: 1.7401683330535889
Validation loss: 2.0758841931819916

Epoch: 5| Step: 5
Training loss: 1.8143284320831299
Validation loss: 2.0915580689907074

Epoch: 5| Step: 6
Training loss: 2.566032648086548
Validation loss: 2.0683677246173224

Epoch: 5| Step: 7
Training loss: 2.3603222370147705
Validation loss: 2.0685607939958572

Epoch: 5| Step: 8
Training loss: 1.1800819635391235
Validation loss: 2.0640791157881417

Epoch: 5| Step: 9
Training loss: 2.625516176223755
Validation loss: 2.0487950344880423

Epoch: 5| Step: 10
Training loss: 1.7142423391342163
Validation loss: 2.0403160552183786

Epoch: 5| Step: 11
Training loss: 0.8235228657722473
Validation loss: 2.0362978080908456

Epoch: 153| Step: 0
Training loss: 1.6623064279556274
Validation loss: 2.043940484523773

Epoch: 5| Step: 1
Training loss: 2.2353296279907227
Validation loss: 2.0340297569831214

Epoch: 5| Step: 2
Training loss: 2.4283447265625
Validation loss: 2.032185822725296

Epoch: 5| Step: 3
Training loss: 2.56903076171875
Validation loss: 2.0394998639822006

Epoch: 5| Step: 4
Training loss: 1.8806686401367188
Validation loss: 2.03466888765494

Epoch: 5| Step: 5
Training loss: 1.4607739448547363
Validation loss: 2.035180484255155

Epoch: 5| Step: 6
Training loss: 2.4228694438934326
Validation loss: 2.0310463905334473

Epoch: 5| Step: 7
Training loss: 2.2362232208251953
Validation loss: 2.0446990032990775

Epoch: 5| Step: 8
Training loss: 1.8023878335952759
Validation loss: 2.0477337588866553

Epoch: 5| Step: 9
Training loss: 1.983587622642517
Validation loss: 2.0620132237672806

Epoch: 5| Step: 10
Training loss: 2.0266523361206055
Validation loss: 2.06948451201121

Epoch: 5| Step: 11
Training loss: 1.9923272132873535
Validation loss: 2.0514714270830154

Epoch: 154| Step: 0
Training loss: 2.123359203338623
Validation loss: 2.0716002533833184

Epoch: 5| Step: 1
Training loss: 2.419513702392578
Validation loss: 2.067830810944239

Epoch: 5| Step: 2
Training loss: 2.6834592819213867
Validation loss: 2.045020262400309

Epoch: 5| Step: 3
Training loss: 2.2181191444396973
Validation loss: 2.03932586312294

Epoch: 5| Step: 4
Training loss: 1.7974179983139038
Validation loss: 2.0516492823759713

Epoch: 5| Step: 5
Training loss: 1.9113506078720093
Validation loss: 2.043400769432386

Epoch: 5| Step: 6
Training loss: 1.5712649822235107
Validation loss: 2.039671704173088

Epoch: 5| Step: 7
Training loss: 1.9030739068984985
Validation loss: 2.0385992228984833

Epoch: 5| Step: 8
Training loss: 2.234039068222046
Validation loss: 2.03400752445062

Epoch: 5| Step: 9
Training loss: 1.6701195240020752
Validation loss: 2.024010807275772

Epoch: 5| Step: 10
Training loss: 1.8754314184188843
Validation loss: 2.029310757915179

Epoch: 5| Step: 11
Training loss: 2.6737828254699707
Validation loss: 2.0411984970172248

Epoch: 155| Step: 0
Training loss: 2.3695712089538574
Validation loss: 2.0308456271886826

Epoch: 5| Step: 1
Training loss: 2.086280345916748
Validation loss: 2.0393445789813995

Epoch: 5| Step: 2
Training loss: 2.094092607498169
Validation loss: 2.0444652438163757

Epoch: 5| Step: 3
Training loss: 1.9452203512191772
Validation loss: 2.06128520766894

Epoch: 5| Step: 4
Training loss: 1.9683233499526978
Validation loss: 2.0651442855596542

Epoch: 5| Step: 5
Training loss: 1.5438926219940186
Validation loss: 2.0680269996325173

Epoch: 5| Step: 6
Training loss: 2.592724084854126
Validation loss: 2.0682143419981003

Epoch: 5| Step: 7
Training loss: 2.1520442962646484
Validation loss: 2.0840593526760736

Epoch: 5| Step: 8
Training loss: 1.615509033203125
Validation loss: 2.071273371577263

Epoch: 5| Step: 9
Training loss: 2.082913875579834
Validation loss: 2.0768986890713372

Epoch: 5| Step: 10
Training loss: 2.1302084922790527
Validation loss: 2.0826520969470343

Epoch: 5| Step: 11
Training loss: 1.4166340827941895
Validation loss: 2.074973483880361

Epoch: 156| Step: 0
Training loss: 1.7998014688491821
Validation loss: 2.073747530579567

Epoch: 5| Step: 1
Training loss: 1.7933212518692017
Validation loss: 2.072597950696945

Epoch: 5| Step: 2
Training loss: 2.09722638130188
Validation loss: 2.0840535163879395

Epoch: 5| Step: 3
Training loss: 1.6104589700698853
Validation loss: 2.085301568110784

Epoch: 5| Step: 4
Training loss: 1.8653059005737305
Validation loss: 2.0999965022007623

Epoch: 5| Step: 5
Training loss: 2.1197619438171387
Validation loss: 2.0857657889525094

Epoch: 5| Step: 6
Training loss: 2.1447572708129883
Validation loss: 2.079517513513565

Epoch: 5| Step: 7
Training loss: 2.392918586730957
Validation loss: 2.0687383065621057

Epoch: 5| Step: 8
Training loss: 2.3806471824645996
Validation loss: 2.05638579527537

Epoch: 5| Step: 9
Training loss: 1.9091476202011108
Validation loss: 2.055506815512975

Epoch: 5| Step: 10
Training loss: 2.2874951362609863
Validation loss: 2.0547210226456323

Epoch: 5| Step: 11
Training loss: 3.3153128623962402
Validation loss: 2.0518415768941245

Epoch: 157| Step: 0
Training loss: 1.923002004623413
Validation loss: 2.0632651448249817

Epoch: 5| Step: 1
Training loss: 2.446071147918701
Validation loss: 2.056024114290873

Epoch: 5| Step: 2
Training loss: 2.069605588912964
Validation loss: 2.0441068510214486

Epoch: 5| Step: 3
Training loss: 1.8776432275772095
Validation loss: 2.0558502475420632

Epoch: 5| Step: 4
Training loss: 1.782125473022461
Validation loss: 2.069517562786738

Epoch: 5| Step: 5
Training loss: 1.723209023475647
Validation loss: 2.074541916449865

Epoch: 5| Step: 6
Training loss: 2.1961796283721924
Validation loss: 2.088390573859215

Epoch: 5| Step: 7
Training loss: 2.0964102745056152
Validation loss: 2.0904533763726554

Epoch: 5| Step: 8
Training loss: 2.1642773151397705
Validation loss: 2.135001560052236

Epoch: 5| Step: 9
Training loss: 2.387131690979004
Validation loss: 2.1091324190298715

Epoch: 5| Step: 10
Training loss: 2.128430128097534
Validation loss: 2.110644280910492

Epoch: 5| Step: 11
Training loss: 1.4768439531326294
Validation loss: 2.09261762102445

Epoch: 158| Step: 0
Training loss: 2.142237901687622
Validation loss: 2.0928808450698853

Epoch: 5| Step: 1
Training loss: 2.1042628288269043
Validation loss: 2.0725359370311103

Epoch: 5| Step: 2
Training loss: 2.005072832107544
Validation loss: 2.0554455717404685

Epoch: 5| Step: 3
Training loss: 1.8582069873809814
Validation loss: 2.0467699815829596

Epoch: 5| Step: 4
Training loss: 2.120443820953369
Validation loss: 2.0489656378825507

Epoch: 5| Step: 5
Training loss: 2.430248260498047
Validation loss: 2.052940825621287

Epoch: 5| Step: 6
Training loss: 1.8711440563201904
Validation loss: 2.0452118714650473

Epoch: 5| Step: 7
Training loss: 1.9178911447525024
Validation loss: 2.0430946946144104

Epoch: 5| Step: 8
Training loss: 2.1908459663391113
Validation loss: 2.051151712735494

Epoch: 5| Step: 9
Training loss: 1.8987360000610352
Validation loss: 2.046933278441429

Epoch: 5| Step: 10
Training loss: 1.910434365272522
Validation loss: 2.0427276889483132

Epoch: 5| Step: 11
Training loss: 2.6711089611053467
Validation loss: 2.058767721056938

Epoch: 159| Step: 0
Training loss: 1.7196228504180908
Validation loss: 2.05733060836792

Epoch: 5| Step: 1
Training loss: 1.8039257526397705
Validation loss: 2.0604260563850403

Epoch: 5| Step: 2
Training loss: 2.0483243465423584
Validation loss: 2.0631956607103348

Epoch: 5| Step: 3
Training loss: 2.2010912895202637
Validation loss: 2.0661879579226174

Epoch: 5| Step: 4
Training loss: 1.8631353378295898
Validation loss: 2.0624879697958627

Epoch: 5| Step: 5
Training loss: 2.227937698364258
Validation loss: 2.0631671945254006

Epoch: 5| Step: 6
Training loss: 2.3278627395629883
Validation loss: 2.055476556221644

Epoch: 5| Step: 7
Training loss: 2.1581637859344482
Validation loss: 2.0540194312731423

Epoch: 5| Step: 8
Training loss: 1.6293003559112549
Validation loss: 2.056191553672155

Epoch: 5| Step: 9
Training loss: 2.662956953048706
Validation loss: 2.0633793423573175

Epoch: 5| Step: 10
Training loss: 2.0274696350097656
Validation loss: 2.052048901716868

Epoch: 5| Step: 11
Training loss: 1.875349521636963
Validation loss: 2.055717021226883

Epoch: 160| Step: 0
Training loss: 2.126675605773926
Validation loss: 2.0503116250038147

Epoch: 5| Step: 1
Training loss: 1.5208258628845215
Validation loss: 2.0538528511921563

Epoch: 5| Step: 2
Training loss: 2.0451302528381348
Validation loss: 2.058897470434507

Epoch: 5| Step: 3
Training loss: 2.144257068634033
Validation loss: 2.0571288069089255

Epoch: 5| Step: 4
Training loss: 2.079413414001465
Validation loss: 2.052840714653333

Epoch: 5| Step: 5
Training loss: 2.0721499919891357
Validation loss: 2.0507942934830985

Epoch: 5| Step: 6
Training loss: 1.8054136037826538
Validation loss: 2.053175757328669

Epoch: 5| Step: 7
Training loss: 1.7886018753051758
Validation loss: 2.0356762458880744

Epoch: 5| Step: 8
Training loss: 2.3342628479003906
Validation loss: 2.0430697252353034

Epoch: 5| Step: 9
Training loss: 1.856382131576538
Validation loss: 2.0470106999079385

Epoch: 5| Step: 10
Training loss: 2.487149715423584
Validation loss: 2.0440106640259423

Epoch: 5| Step: 11
Training loss: 3.2256879806518555
Validation loss: 2.0429850121339164

Epoch: 161| Step: 0
Training loss: 2.109163999557495
Validation loss: 2.0458967288335166

Epoch: 5| Step: 1
Training loss: 2.517171859741211
Validation loss: 2.065547396739324

Epoch: 5| Step: 2
Training loss: 1.5855993032455444
Validation loss: 2.06590029100577

Epoch: 5| Step: 3
Training loss: 1.575934648513794
Validation loss: 2.073201914628347

Epoch: 5| Step: 4
Training loss: 1.9647624492645264
Validation loss: 2.065457026163737

Epoch: 5| Step: 5
Training loss: 2.2614824771881104
Validation loss: 2.0595882733662925

Epoch: 5| Step: 6
Training loss: 2.1414408683776855
Validation loss: 2.069203739364942

Epoch: 5| Step: 7
Training loss: 1.6934328079223633
Validation loss: 2.0663643876711526

Epoch: 5| Step: 8
Training loss: 2.4061508178710938
Validation loss: 2.050240139166514

Epoch: 5| Step: 9
Training loss: 1.8057130575180054
Validation loss: 2.058559646209081

Epoch: 5| Step: 10
Training loss: 2.221548557281494
Validation loss: 2.058160016934077

Epoch: 5| Step: 11
Training loss: 3.0488393306732178
Validation loss: 2.0568188776572547

Epoch: 162| Step: 0
Training loss: 2.3051655292510986
Validation loss: 2.0516025771697364

Epoch: 5| Step: 1
Training loss: 2.3763699531555176
Validation loss: 2.0466019362211227

Epoch: 5| Step: 2
Training loss: 2.179060459136963
Validation loss: 2.053239827354749

Epoch: 5| Step: 3
Training loss: 1.936854362487793
Validation loss: 2.0415003101030984

Epoch: 5| Step: 4
Training loss: 1.7332147359848022
Validation loss: 2.0383740415175757

Epoch: 5| Step: 5
Training loss: 1.9851535558700562
Validation loss: 2.039064268271128

Epoch: 5| Step: 6
Training loss: 2.1703267097473145
Validation loss: 2.0450705935557685

Epoch: 5| Step: 7
Training loss: 1.5824265480041504
Validation loss: 2.043008560935656

Epoch: 5| Step: 8
Training loss: 2.0175278186798096
Validation loss: 2.057681938012441

Epoch: 5| Step: 9
Training loss: 2.187915086746216
Validation loss: 2.0554818212985992

Epoch: 5| Step: 10
Training loss: 1.9304678440093994
Validation loss: 2.0657559434572854

Epoch: 5| Step: 11
Training loss: 2.3355040550231934
Validation loss: 2.066409265001615

Epoch: 163| Step: 0
Training loss: 2.0228772163391113
Validation loss: 2.0791465838750205

Epoch: 5| Step: 1
Training loss: 2.2646377086639404
Validation loss: 2.067813436190287

Epoch: 5| Step: 2
Training loss: 3.18153715133667
Validation loss: 2.0890604654947915

Epoch: 5| Step: 3
Training loss: 1.5324628353118896
Validation loss: 2.0893719842036567

Epoch: 5| Step: 4
Training loss: 1.5307108163833618
Validation loss: 2.0682802895704904

Epoch: 5| Step: 5
Training loss: 1.8098608255386353
Validation loss: 2.0592792878548303

Epoch: 5| Step: 6
Training loss: 2.6307053565979004
Validation loss: 2.044430529077848

Epoch: 5| Step: 7
Training loss: 2.2862346172332764
Validation loss: 2.0539721747239432

Epoch: 5| Step: 8
Training loss: 1.9465538263320923
Validation loss: 2.0438017547130585

Epoch: 5| Step: 9
Training loss: 1.4781286716461182
Validation loss: 2.0534326881170273

Epoch: 5| Step: 10
Training loss: 2.045409917831421
Validation loss: 2.0415805031855903

Epoch: 5| Step: 11
Training loss: 1.6440035104751587
Validation loss: 2.0545905033747354

Epoch: 164| Step: 0
Training loss: 2.165647029876709
Validation loss: 2.051978717247645

Epoch: 5| Step: 1
Training loss: 1.833634614944458
Validation loss: 2.0589562952518463

Epoch: 5| Step: 2
Training loss: 1.7723920345306396
Validation loss: 2.0527814577023187

Epoch: 5| Step: 3
Training loss: 1.8585468530654907
Validation loss: 2.0619056870539985

Epoch: 5| Step: 4
Training loss: 2.0535998344421387
Validation loss: 2.055471956729889

Epoch: 5| Step: 5
Training loss: 2.0522701740264893
Validation loss: 2.0686073948939643

Epoch: 5| Step: 6
Training loss: 1.8016637563705444
Validation loss: 2.069039906064669

Epoch: 5| Step: 7
Training loss: 2.6674606800079346
Validation loss: 2.0521159023046494

Epoch: 5| Step: 8
Training loss: 1.8288662433624268
Validation loss: 2.061077351371447

Epoch: 5| Step: 9
Training loss: 2.417513608932495
Validation loss: 2.054581662019094

Epoch: 5| Step: 10
Training loss: 1.8207521438598633
Validation loss: 2.064491187532743

Epoch: 5| Step: 11
Training loss: 1.888835072517395
Validation loss: 2.0578874299923577

Epoch: 165| Step: 0
Training loss: 2.563572406768799
Validation loss: 2.063101182381312

Epoch: 5| Step: 1
Training loss: 1.689719796180725
Validation loss: 2.055808032552401

Epoch: 5| Step: 2
Training loss: 1.901633858680725
Validation loss: 2.05451138317585

Epoch: 5| Step: 3
Training loss: 2.070627212524414
Validation loss: 2.0530763318141303

Epoch: 5| Step: 4
Training loss: 2.127380609512329
Validation loss: 2.052476997176806

Epoch: 5| Step: 5
Training loss: 1.515017032623291
Validation loss: 2.051367531220118

Epoch: 5| Step: 6
Training loss: 2.147073268890381
Validation loss: 2.051313877105713

Epoch: 5| Step: 7
Training loss: 1.994424819946289
Validation loss: 2.057777613401413

Epoch: 5| Step: 8
Training loss: 2.3754944801330566
Validation loss: 2.057728186249733

Epoch: 5| Step: 9
Training loss: 1.8087034225463867
Validation loss: 2.057311788201332

Epoch: 5| Step: 10
Training loss: 2.0988218784332275
Validation loss: 2.050650636355082

Epoch: 5| Step: 11
Training loss: 2.2625207901000977
Validation loss: 2.069148153066635

Epoch: 166| Step: 0
Training loss: 2.0126864910125732
Validation loss: 2.078302318851153

Epoch: 5| Step: 1
Training loss: 2.326878070831299
Validation loss: 2.067251220345497

Epoch: 5| Step: 2
Training loss: 2.6098029613494873
Validation loss: 2.0705544302860894

Epoch: 5| Step: 3
Training loss: 2.0240283012390137
Validation loss: 2.0637125223875046

Epoch: 5| Step: 4
Training loss: 2.2095866203308105
Validation loss: 2.0638663470745087

Epoch: 5| Step: 5
Training loss: 1.6625562906265259
Validation loss: 2.0475494315226874

Epoch: 5| Step: 6
Training loss: 2.1410956382751465
Validation loss: 2.032405083378156

Epoch: 5| Step: 7
Training loss: 2.236417055130005
Validation loss: 2.027561604976654

Epoch: 5| Step: 8
Training loss: 1.920206069946289
Validation loss: 2.0373159050941467

Epoch: 5| Step: 9
Training loss: 1.4879920482635498
Validation loss: 2.0241206338008246

Epoch: 5| Step: 10
Training loss: 1.8008506298065186
Validation loss: 2.0251994530359902

Epoch: 5| Step: 11
Training loss: 1.7854738235473633
Validation loss: 2.0400688300530114

Epoch: 167| Step: 0
Training loss: 1.919447898864746
Validation loss: 2.0343907276789346

Epoch: 5| Step: 1
Training loss: 2.1422371864318848
Validation loss: 2.029088333249092

Epoch: 5| Step: 2
Training loss: 2.3336799144744873
Validation loss: 2.044128810365995

Epoch: 5| Step: 3
Training loss: 1.8546184301376343
Validation loss: 2.054227724671364

Epoch: 5| Step: 4
Training loss: 2.4869401454925537
Validation loss: 2.0463365465402603

Epoch: 5| Step: 5
Training loss: 1.9548476934432983
Validation loss: 2.0407967567443848

Epoch: 5| Step: 6
Training loss: 1.8799278736114502
Validation loss: 2.054717868566513

Epoch: 5| Step: 7
Training loss: 2.2165749073028564
Validation loss: 2.0520454198122025

Epoch: 5| Step: 8
Training loss: 1.6522963047027588
Validation loss: 2.059676999847094

Epoch: 5| Step: 9
Training loss: 2.0153021812438965
Validation loss: 2.0507796307404837

Epoch: 5| Step: 10
Training loss: 2.06154727935791
Validation loss: 2.062167684237162

Epoch: 5| Step: 11
Training loss: 1.8296210765838623
Validation loss: 2.052073299884796

Epoch: 168| Step: 0
Training loss: 2.1430020332336426
Validation loss: 2.0698021352291107

Epoch: 5| Step: 1
Training loss: 1.7409557104110718
Validation loss: 2.0705484598875046

Epoch: 5| Step: 2
Training loss: 1.2706243991851807
Validation loss: 2.075196052591006

Epoch: 5| Step: 3
Training loss: 2.2433879375457764
Validation loss: 2.0700983653465905

Epoch: 5| Step: 4
Training loss: 2.428873062133789
Validation loss: 2.0754457463820777

Epoch: 5| Step: 5
Training loss: 2.0384974479675293
Validation loss: 2.102262556552887

Epoch: 5| Step: 6
Training loss: 2.4673733711242676
Validation loss: 2.0998499939839044

Epoch: 5| Step: 7
Training loss: 2.248169422149658
Validation loss: 2.086664080619812

Epoch: 5| Step: 8
Training loss: 1.3005783557891846
Validation loss: 2.104512388507525

Epoch: 5| Step: 9
Training loss: 2.2926065921783447
Validation loss: 2.097201347351074

Epoch: 5| Step: 10
Training loss: 1.9303834438323975
Validation loss: 2.0859880844751992

Epoch: 5| Step: 11
Training loss: 1.9686169624328613
Validation loss: 2.095885679125786

Epoch: 169| Step: 0
Training loss: 1.6678521633148193
Validation loss: 2.0677587489287057

Epoch: 5| Step: 1
Training loss: 2.3485686779022217
Validation loss: 2.069677025079727

Epoch: 5| Step: 2
Training loss: 1.9341224431991577
Validation loss: 2.0693153589963913

Epoch: 5| Step: 3
Training loss: 1.8570228815078735
Validation loss: 2.0557930717865625

Epoch: 5| Step: 4
Training loss: 2.9516663551330566
Validation loss: 2.0518666754166284

Epoch: 5| Step: 5
Training loss: 1.8204419612884521
Validation loss: 2.0308372726043067

Epoch: 5| Step: 6
Training loss: 2.048628568649292
Validation loss: 2.0325216154257455

Epoch: 5| Step: 7
Training loss: 2.2379677295684814
Validation loss: 2.033164451519648

Epoch: 5| Step: 8
Training loss: 2.3328614234924316
Validation loss: 2.0307427446047464

Epoch: 5| Step: 9
Training loss: 1.5719852447509766
Validation loss: 2.0412407567103705

Epoch: 5| Step: 10
Training loss: 1.627049446105957
Validation loss: 2.0427082578341165

Epoch: 5| Step: 11
Training loss: 1.638401746749878
Validation loss: 2.0474575608968735

Epoch: 170| Step: 0
Training loss: 2.067686080932617
Validation loss: 2.054396544893583

Epoch: 5| Step: 1
Training loss: 1.374436378479004
Validation loss: 2.0750172088543573

Epoch: 5| Step: 2
Training loss: 2.2655200958251953
Validation loss: 2.0848330656687417

Epoch: 5| Step: 3
Training loss: 2.5472500324249268
Validation loss: 2.1205430130163827

Epoch: 5| Step: 4
Training loss: 1.7135534286499023
Validation loss: 2.1205072899659476

Epoch: 5| Step: 5
Training loss: 2.636704206466675
Validation loss: 2.127985253930092

Epoch: 5| Step: 6
Training loss: 2.2324469089508057
Validation loss: 2.1000764966011047

Epoch: 5| Step: 7
Training loss: 2.4312491416931152
Validation loss: 2.0922371546427407

Epoch: 5| Step: 8
Training loss: 1.9994840621948242
Validation loss: 2.045135279496511

Epoch: 5| Step: 9
Training loss: 2.00272274017334
Validation loss: 2.0475285400946936

Epoch: 5| Step: 10
Training loss: 1.871622085571289
Validation loss: 2.040767545501391

Epoch: 5| Step: 11
Training loss: 0.9129126071929932
Validation loss: 2.0365712443987527

Epoch: 171| Step: 0
Training loss: 2.4253458976745605
Validation loss: 2.052794943253199

Epoch: 5| Step: 1
Training loss: 1.7229315042495728
Validation loss: 2.043292537331581

Epoch: 5| Step: 2
Training loss: 1.8323875665664673
Validation loss: 2.0469240148862204

Epoch: 5| Step: 3
Training loss: 2.28539776802063
Validation loss: 2.0376523286104202

Epoch: 5| Step: 4
Training loss: 1.7321093082427979
Validation loss: 2.045715163151423

Epoch: 5| Step: 5
Training loss: 2.0486035346984863
Validation loss: 2.058914119998614

Epoch: 5| Step: 6
Training loss: 1.719072937965393
Validation loss: 2.0605191538731256

Epoch: 5| Step: 7
Training loss: 2.4576878547668457
Validation loss: 2.0781070291996

Epoch: 5| Step: 8
Training loss: 2.250775098800659
Validation loss: 2.0855664064486823

Epoch: 5| Step: 9
Training loss: 1.6446235179901123
Validation loss: 2.085365970929464

Epoch: 5| Step: 10
Training loss: 2.0272488594055176
Validation loss: 2.1068843801816306

Epoch: 5| Step: 11
Training loss: 4.083606719970703
Validation loss: 2.1095054546991983

Epoch: 172| Step: 0
Training loss: 2.5352730751037598
Validation loss: 2.107738678654035

Epoch: 5| Step: 1
Training loss: 1.444588303565979
Validation loss: 2.1114964485168457

Epoch: 5| Step: 2
Training loss: 1.7485908269882202
Validation loss: 2.0973038176695504

Epoch: 5| Step: 3
Training loss: 2.162339687347412
Validation loss: 2.089696486790975

Epoch: 5| Step: 4
Training loss: 2.377190589904785
Validation loss: 2.0768954753875732

Epoch: 5| Step: 5
Training loss: 1.991192102432251
Validation loss: 2.051306496063868

Epoch: 5| Step: 6
Training loss: 2.6646480560302734
Validation loss: 2.0651870667934418

Epoch: 5| Step: 7
Training loss: 1.8566211462020874
Validation loss: 2.047009805838267

Epoch: 5| Step: 8
Training loss: 1.9854834079742432
Validation loss: 2.0515937507152557

Epoch: 5| Step: 9
Training loss: 1.8535165786743164
Validation loss: 2.0644658505916595

Epoch: 5| Step: 10
Training loss: 1.8341703414916992
Validation loss: 2.0679065783818564

Epoch: 5| Step: 11
Training loss: 1.9822765588760376
Validation loss: 2.0732287615537643

Epoch: 173| Step: 0
Training loss: 1.7229490280151367
Validation loss: 2.0709030429522195

Epoch: 5| Step: 1
Training loss: 1.990647554397583
Validation loss: 2.076027736067772

Epoch: 5| Step: 2
Training loss: 2.430349826812744
Validation loss: 2.0736392686764398

Epoch: 5| Step: 3
Training loss: 1.8279125690460205
Validation loss: 2.071542039513588

Epoch: 5| Step: 4
Training loss: 2.3392693996429443
Validation loss: 2.0750230699777603

Epoch: 5| Step: 5
Training loss: 1.576870322227478
Validation loss: 2.0764713088671365

Epoch: 5| Step: 6
Training loss: 2.460704803466797
Validation loss: 2.0605933914581933

Epoch: 5| Step: 7
Training loss: 1.5891568660736084
Validation loss: 2.0749599436918893

Epoch: 5| Step: 8
Training loss: 1.779010534286499
Validation loss: 2.060209795832634

Epoch: 5| Step: 9
Training loss: 2.259115219116211
Validation loss: 2.0656220813592276

Epoch: 5| Step: 10
Training loss: 2.103764772415161
Validation loss: 2.062042107184728

Epoch: 5| Step: 11
Training loss: 2.4426207542419434
Validation loss: 2.0618448505798974

Epoch: 174| Step: 0
Training loss: 2.27553129196167
Validation loss: 2.0518956085046134

Epoch: 5| Step: 1
Training loss: 2.3767101764678955
Validation loss: 2.0451496491829553

Epoch: 5| Step: 2
Training loss: 2.127840042114258
Validation loss: 2.0406406223773956

Epoch: 5| Step: 3
Training loss: 2.428375005722046
Validation loss: 2.059893473982811

Epoch: 5| Step: 4
Training loss: 1.8776206970214844
Validation loss: 2.0518199652433395

Epoch: 5| Step: 5
Training loss: 2.0649070739746094
Validation loss: 2.059677630662918

Epoch: 5| Step: 6
Training loss: 1.5452120304107666
Validation loss: 2.072476009527842

Epoch: 5| Step: 7
Training loss: 2.144235134124756
Validation loss: 2.079371685783068

Epoch: 5| Step: 8
Training loss: 1.6690393686294556
Validation loss: 2.081437329451243

Epoch: 5| Step: 9
Training loss: 1.398346185684204
Validation loss: 2.099673847357432

Epoch: 5| Step: 10
Training loss: 2.338212251663208
Validation loss: 2.1131272514661155

Epoch: 5| Step: 11
Training loss: 2.055917263031006
Validation loss: 2.105771611134211

Epoch: 175| Step: 0
Training loss: 2.498779773712158
Validation loss: 2.0756449153025947

Epoch: 5| Step: 1
Training loss: 1.6427509784698486
Validation loss: 2.0780533452828727

Epoch: 5| Step: 2
Training loss: 1.5849356651306152
Validation loss: 2.0738215297460556

Epoch: 5| Step: 3
Training loss: 2.3879294395446777
Validation loss: 2.0661986768245697

Epoch: 5| Step: 4
Training loss: 2.6970136165618896
Validation loss: 2.069900929927826

Epoch: 5| Step: 5
Training loss: 1.8177669048309326
Validation loss: 2.0717614640792212

Epoch: 5| Step: 6
Training loss: 2.138406276702881
Validation loss: 2.0707697769006095

Epoch: 5| Step: 7
Training loss: 2.0744059085845947
Validation loss: 2.073022872209549

Epoch: 5| Step: 8
Training loss: 1.7138166427612305
Validation loss: 2.067311575015386

Epoch: 5| Step: 9
Training loss: 1.9905297756195068
Validation loss: 2.0763098845879235

Epoch: 5| Step: 10
Training loss: 1.8424873352050781
Validation loss: 2.0930518408616385

Epoch: 5| Step: 11
Training loss: 1.5671279430389404
Validation loss: 2.084337443113327

Epoch: 176| Step: 0
Training loss: 2.0937962532043457
Validation loss: 2.084348574280739

Epoch: 5| Step: 1
Training loss: 2.690782070159912
Validation loss: 2.0949781040350595

Epoch: 5| Step: 2
Training loss: 1.7413638830184937
Validation loss: 2.0837876001993814

Epoch: 5| Step: 3
Training loss: 1.4795371294021606
Validation loss: 2.078579237063726

Epoch: 5| Step: 4
Training loss: 1.9874324798583984
Validation loss: 2.0816132624944053

Epoch: 5| Step: 5
Training loss: 2.1324191093444824
Validation loss: 2.0754767805337906

Epoch: 5| Step: 6
Training loss: 1.700134038925171
Validation loss: 2.0786921679973602

Epoch: 5| Step: 7
Training loss: 1.893450140953064
Validation loss: 2.071404059727987

Epoch: 5| Step: 8
Training loss: 1.9101543426513672
Validation loss: 2.098755126198133

Epoch: 5| Step: 9
Training loss: 2.1224656105041504
Validation loss: 2.081126223007838

Epoch: 5| Step: 10
Training loss: 2.1659843921661377
Validation loss: 2.08961529036363

Epoch: 5| Step: 11
Training loss: 2.54360032081604
Validation loss: 2.077343136072159

Epoch: 177| Step: 0
Training loss: 1.784314513206482
Validation loss: 2.0731768111387887

Epoch: 5| Step: 1
Training loss: 2.1116602420806885
Validation loss: 2.071934392054876

Epoch: 5| Step: 2
Training loss: 1.807368516921997
Validation loss: 2.062606394290924

Epoch: 5| Step: 3
Training loss: 2.156026840209961
Validation loss: 2.0738546748956046

Epoch: 5| Step: 4
Training loss: 1.6811132431030273
Validation loss: 2.073244631290436

Epoch: 5| Step: 5
Training loss: 2.4464335441589355
Validation loss: 2.0627780010302863

Epoch: 5| Step: 6
Training loss: 2.159203052520752
Validation loss: 2.0642180194457374

Epoch: 5| Step: 7
Training loss: 1.6998618841171265
Validation loss: 2.0657822440067926

Epoch: 5| Step: 8
Training loss: 2.0227243900299072
Validation loss: 2.0746856530507407

Epoch: 5| Step: 9
Training loss: 2.2487339973449707
Validation loss: 2.0861349453528724

Epoch: 5| Step: 10
Training loss: 2.0542187690734863
Validation loss: 2.090914318958918

Epoch: 5| Step: 11
Training loss: 1.859485149383545
Validation loss: 2.089980791012446

Epoch: 178| Step: 0
Training loss: 1.8612871170043945
Validation loss: 2.0815289368232093

Epoch: 5| Step: 1
Training loss: 2.253870725631714
Validation loss: 2.078766167163849

Epoch: 5| Step: 2
Training loss: 1.7919559478759766
Validation loss: 2.0729814072450004

Epoch: 5| Step: 3
Training loss: 2.1088061332702637
Validation loss: 2.0611582845449448

Epoch: 5| Step: 4
Training loss: 2.144012451171875
Validation loss: 2.067130520939827

Epoch: 5| Step: 5
Training loss: 2.1443710327148438
Validation loss: 2.0804242144028344

Epoch: 5| Step: 6
Training loss: 1.7552944421768188
Validation loss: 2.0695384442806244

Epoch: 5| Step: 7
Training loss: 2.2445168495178223
Validation loss: 2.079216778278351

Epoch: 5| Step: 8
Training loss: 1.8204419612884521
Validation loss: 2.0815369288126626

Epoch: 5| Step: 9
Training loss: 2.1564857959747314
Validation loss: 2.0769783357779183

Epoch: 5| Step: 10
Training loss: 1.7376577854156494
Validation loss: 2.095200757185618

Epoch: 5| Step: 11
Training loss: 2.3120949268341064
Validation loss: 2.0812656581401825

Epoch: 179| Step: 0
Training loss: 2.438957929611206
Validation loss: 2.0589924305677414

Epoch: 5| Step: 1
Training loss: 1.6977697610855103
Validation loss: 2.065440888206164

Epoch: 5| Step: 2
Training loss: 2.3206660747528076
Validation loss: 2.0716692209243774

Epoch: 5| Step: 3
Training loss: 1.9175708293914795
Validation loss: 2.069787467519442

Epoch: 5| Step: 4
Training loss: 2.001641035079956
Validation loss: 2.062640259663264

Epoch: 5| Step: 5
Training loss: 1.805720567703247
Validation loss: 2.0694726556539536

Epoch: 5| Step: 6
Training loss: 2.0055956840515137
Validation loss: 2.071737051010132

Epoch: 5| Step: 7
Training loss: 1.8472732305526733
Validation loss: 2.083293601870537

Epoch: 5| Step: 8
Training loss: 2.126838207244873
Validation loss: 2.0746604750553765

Epoch: 5| Step: 9
Training loss: 1.8274952173233032
Validation loss: 2.090753068526586

Epoch: 5| Step: 10
Training loss: 2.080080509185791
Validation loss: 2.087769399086634

Epoch: 5| Step: 11
Training loss: 3.107985019683838
Validation loss: 2.0778572460015616

Epoch: 180| Step: 0
Training loss: 2.2717201709747314
Validation loss: 2.0830904841423035

Epoch: 5| Step: 1
Training loss: 1.5928668975830078
Validation loss: 2.1087025751670203

Epoch: 5| Step: 2
Training loss: 2.0991740226745605
Validation loss: 2.099035476644834

Epoch: 5| Step: 3
Training loss: 2.0205113887786865
Validation loss: 2.099623372157415

Epoch: 5| Step: 4
Training loss: 2.122190475463867
Validation loss: 2.1166970133781433

Epoch: 5| Step: 5
Training loss: 2.901414394378662
Validation loss: 2.1062017679214478

Epoch: 5| Step: 6
Training loss: 1.4942007064819336
Validation loss: 2.0943151116371155

Epoch: 5| Step: 7
Training loss: 2.2136406898498535
Validation loss: 2.0916638473669686

Epoch: 5| Step: 8
Training loss: 2.0202417373657227
Validation loss: 2.0788918882608414

Epoch: 5| Step: 9
Training loss: 1.7789630889892578
Validation loss: 2.1024444003899894

Epoch: 5| Step: 10
Training loss: 1.6731574535369873
Validation loss: 2.1065444946289062

Epoch: 5| Step: 11
Training loss: 1.3879640102386475
Validation loss: 2.0803838670253754

Epoch: 181| Step: 0
Training loss: 1.7596919536590576
Validation loss: 2.0954487125078836

Epoch: 5| Step: 1
Training loss: 2.3359577655792236
Validation loss: 2.103782614072164

Epoch: 5| Step: 2
Training loss: 1.801958441734314
Validation loss: 2.101393868525823

Epoch: 5| Step: 3
Training loss: 2.3792355060577393
Validation loss: 2.0973011205593743

Epoch: 5| Step: 4
Training loss: 1.810604453086853
Validation loss: 2.1042766173680625

Epoch: 5| Step: 5
Training loss: 1.7700278759002686
Validation loss: 2.0966964811086655

Epoch: 5| Step: 6
Training loss: 2.514223575592041
Validation loss: 2.100714936852455

Epoch: 5| Step: 7
Training loss: 1.8906141519546509
Validation loss: 2.104762151837349

Epoch: 5| Step: 8
Training loss: 1.446218490600586
Validation loss: 2.1087267249822617

Epoch: 5| Step: 9
Training loss: 1.7288236618041992
Validation loss: 2.0953771670659385

Epoch: 5| Step: 10
Training loss: 2.3355343341827393
Validation loss: 2.0741316825151443

Epoch: 5| Step: 11
Training loss: 2.923638105392456
Validation loss: 2.076592723528544

Epoch: 182| Step: 0
Training loss: 1.7774240970611572
Validation loss: 2.100586399435997

Epoch: 5| Step: 1
Training loss: 1.7212718725204468
Validation loss: 2.0933641294638314

Epoch: 5| Step: 2
Training loss: 1.6722404956817627
Validation loss: 2.119351774454117

Epoch: 5| Step: 3
Training loss: 2.464792251586914
Validation loss: 2.1370093623797097

Epoch: 5| Step: 4
Training loss: 1.7908213138580322
Validation loss: 2.147507374485334

Epoch: 5| Step: 5
Training loss: 2.9478163719177246
Validation loss: 2.1755034029483795

Epoch: 5| Step: 6
Training loss: 2.3671860694885254
Validation loss: 2.150042618314425

Epoch: 5| Step: 7
Training loss: 1.44801926612854
Validation loss: 2.1266349901755652

Epoch: 5| Step: 8
Training loss: 2.559713840484619
Validation loss: 2.1035887698332467

Epoch: 5| Step: 9
Training loss: 1.5299208164215088
Validation loss: 2.079455425341924

Epoch: 5| Step: 10
Training loss: 2.349592685699463
Validation loss: 2.0755461752414703

Epoch: 5| Step: 11
Training loss: 1.1303329467773438
Validation loss: 2.0740265597899756

Epoch: 183| Step: 0
Training loss: 2.4816677570343018
Validation loss: 2.0618096192677817

Epoch: 5| Step: 1
Training loss: 1.7789430618286133
Validation loss: 2.0740334341923394

Epoch: 5| Step: 2
Training loss: 2.1469619274139404
Validation loss: 2.067306006948153

Epoch: 5| Step: 3
Training loss: 1.4257218837738037
Validation loss: 2.0957122643788657

Epoch: 5| Step: 4
Training loss: 2.332550525665283
Validation loss: 2.104310522476832

Epoch: 5| Step: 5
Training loss: 1.6760696172714233
Validation loss: 2.092142020662626

Epoch: 5| Step: 6
Training loss: 1.7325748205184937
Validation loss: 2.121355652809143

Epoch: 5| Step: 7
Training loss: 2.546967029571533
Validation loss: 2.1099699437618256

Epoch: 5| Step: 8
Training loss: 1.8259613513946533
Validation loss: 2.1169015814860663

Epoch: 5| Step: 9
Training loss: 2.4688379764556885
Validation loss: 2.12136502067248

Epoch: 5| Step: 10
Training loss: 1.6797521114349365
Validation loss: 2.113730882604917

Epoch: 5| Step: 11
Training loss: 2.45327091217041
Validation loss: 2.0999771455923715

Epoch: 184| Step: 0
Training loss: 1.9631597995758057
Validation loss: 2.075316240390142

Epoch: 5| Step: 1
Training loss: 2.0809473991394043
Validation loss: 2.0644391824801764

Epoch: 5| Step: 2
Training loss: 2.5198206901550293
Validation loss: 2.057355841000875

Epoch: 5| Step: 3
Training loss: 2.091869831085205
Validation loss: 2.063994367917379

Epoch: 5| Step: 4
Training loss: 1.9826068878173828
Validation loss: 2.079608346025149

Epoch: 5| Step: 5
Training loss: 2.4653477668762207
Validation loss: 2.081850985685984

Epoch: 5| Step: 6
Training loss: 2.132564067840576
Validation loss: 2.087970415751139

Epoch: 5| Step: 7
Training loss: 2.0010952949523926
Validation loss: 2.0885612020889917

Epoch: 5| Step: 8
Training loss: 1.6235897541046143
Validation loss: 2.0834783961375556

Epoch: 5| Step: 9
Training loss: 2.0862181186676025
Validation loss: 2.0810963064432144

Epoch: 5| Step: 10
Training loss: 2.337451457977295
Validation loss: 2.072837139169375

Epoch: 5| Step: 11
Training loss: 1.5808292627334595
Validation loss: 2.0706016023953757

Epoch: 185| Step: 0
Training loss: 2.0204415321350098
Validation loss: 2.064694265524546

Epoch: 5| Step: 1
Training loss: 2.4518282413482666
Validation loss: 2.0629927714665732

Epoch: 5| Step: 2
Training loss: 2.154916286468506
Validation loss: 2.064495931069056

Epoch: 5| Step: 3
Training loss: 2.0622668266296387
Validation loss: 2.051938866575559

Epoch: 5| Step: 4
Training loss: 2.0617778301239014
Validation loss: 2.073618084192276

Epoch: 5| Step: 5
Training loss: 1.447066307067871
Validation loss: 2.075242464741071

Epoch: 5| Step: 6
Training loss: 1.981095552444458
Validation loss: 2.105646381775538

Epoch: 5| Step: 7
Training loss: 1.7768614292144775
Validation loss: 2.1062132666508355

Epoch: 5| Step: 8
Training loss: 1.7858285903930664
Validation loss: 2.1255267759164176

Epoch: 5| Step: 9
Training loss: 2.501913070678711
Validation loss: 2.146999552845955

Epoch: 5| Step: 10
Training loss: 2.2675998210906982
Validation loss: 2.137406647205353

Epoch: 5| Step: 11
Training loss: 2.300442934036255
Validation loss: 2.1446223010619483

Epoch: 186| Step: 0
Training loss: 2.056187152862549
Validation loss: 2.1324022163947425

Epoch: 5| Step: 1
Training loss: 2.337418556213379
Validation loss: 2.095813492933909

Epoch: 5| Step: 2
Training loss: 1.9527835845947266
Validation loss: 2.078683997193972

Epoch: 5| Step: 3
Training loss: 2.5948517322540283
Validation loss: 2.070039148132006

Epoch: 5| Step: 4
Training loss: 2.1988143920898438
Validation loss: 2.062952940662702

Epoch: 5| Step: 5
Training loss: 1.9051997661590576
Validation loss: 2.065339207649231

Epoch: 5| Step: 6
Training loss: 2.3870081901550293
Validation loss: 2.06949291129907

Epoch: 5| Step: 7
Training loss: 1.49403977394104
Validation loss: 2.067313606540362

Epoch: 5| Step: 8
Training loss: 1.9634201526641846
Validation loss: 2.0739786028862

Epoch: 5| Step: 9
Training loss: 2.108212947845459
Validation loss: 2.0683833062648773

Epoch: 5| Step: 10
Training loss: 1.9110126495361328
Validation loss: 2.072659984230995

Epoch: 5| Step: 11
Training loss: 0.8377894163131714
Validation loss: 2.067342539628347

Epoch: 187| Step: 0
Training loss: 2.1222193241119385
Validation loss: 2.0595304618279138

Epoch: 5| Step: 1
Training loss: 2.6748385429382324
Validation loss: 2.0578814645608268

Epoch: 5| Step: 2
Training loss: 1.931597113609314
Validation loss: 2.0698616206645966

Epoch: 5| Step: 3
Training loss: 1.6769282817840576
Validation loss: 2.077546238899231

Epoch: 5| Step: 4
Training loss: 2.1509687900543213
Validation loss: 2.094179799159368

Epoch: 5| Step: 5
Training loss: 1.4007117748260498
Validation loss: 2.101515829563141

Epoch: 5| Step: 6
Training loss: 3.134352684020996
Validation loss: 2.1088078717390695

Epoch: 5| Step: 7
Training loss: 2.0335195064544678
Validation loss: 2.110693251093229

Epoch: 5| Step: 8
Training loss: 1.7959829568862915
Validation loss: 2.107393557826678

Epoch: 5| Step: 9
Training loss: 1.8219740390777588
Validation loss: 2.1044092079003653

Epoch: 5| Step: 10
Training loss: 1.5280860662460327
Validation loss: 2.0936054388682046

Epoch: 5| Step: 11
Training loss: 1.4189367294311523
Validation loss: 2.0886054088672004

Epoch: 188| Step: 0
Training loss: 2.3842201232910156
Validation loss: 2.099496528506279

Epoch: 5| Step: 1
Training loss: 1.7059978246688843
Validation loss: 2.088776538769404

Epoch: 5| Step: 2
Training loss: 2.018603801727295
Validation loss: 2.0811568945646286

Epoch: 5| Step: 3
Training loss: 1.6237903833389282
Validation loss: 2.079774633049965

Epoch: 5| Step: 4
Training loss: 2.0783121585845947
Validation loss: 2.0727756122748056

Epoch: 5| Step: 5
Training loss: 1.9206184148788452
Validation loss: 2.0530091673135757

Epoch: 5| Step: 6
Training loss: 2.259152412414551
Validation loss: 2.0692513585090637

Epoch: 5| Step: 7
Training loss: 1.9214435815811157
Validation loss: 2.0744605908791223

Epoch: 5| Step: 8
Training loss: 2.4115710258483887
Validation loss: 2.068141594529152

Epoch: 5| Step: 9
Training loss: 1.7731558084487915
Validation loss: 2.0875857720772424

Epoch: 5| Step: 10
Training loss: 2.1687111854553223
Validation loss: 2.0995751718680062

Epoch: 5| Step: 11
Training loss: 1.175282597541809
Validation loss: 2.1117365062236786

Epoch: 189| Step: 0
Training loss: 1.6214361190795898
Validation loss: 2.1260367731253305

Epoch: 5| Step: 1
Training loss: 1.8449913263320923
Validation loss: 2.1258873442808786

Epoch: 5| Step: 2
Training loss: 2.145872116088867
Validation loss: 2.1221740196148553

Epoch: 5| Step: 3
Training loss: 2.5219531059265137
Validation loss: 2.12495020031929

Epoch: 5| Step: 4
Training loss: 1.4441964626312256
Validation loss: 2.124556844433149

Epoch: 5| Step: 5
Training loss: 2.265414237976074
Validation loss: 2.098064124584198

Epoch: 5| Step: 6
Training loss: 2.6022520065307617
Validation loss: 2.114670922358831

Epoch: 5| Step: 7
Training loss: 2.10420298576355
Validation loss: 2.0910054494937262

Epoch: 5| Step: 8
Training loss: 1.7565860748291016
Validation loss: 2.0991994390885034

Epoch: 5| Step: 9
Training loss: 1.69482421875
Validation loss: 2.0996931046247482

Epoch: 5| Step: 10
Training loss: 1.9132537841796875
Validation loss: 2.1049302220344543

Epoch: 5| Step: 11
Training loss: 1.8392072916030884
Validation loss: 2.087540457646052

Epoch: 190| Step: 0
Training loss: 2.2293686866760254
Validation loss: 2.0862117211023965

Epoch: 5| Step: 1
Training loss: 2.5530223846435547
Validation loss: 2.0727223257223764

Epoch: 5| Step: 2
Training loss: 1.9023182392120361
Validation loss: 2.084354266524315

Epoch: 5| Step: 3
Training loss: 2.155426502227783
Validation loss: 2.0786362489064536

Epoch: 5| Step: 4
Training loss: 1.7703216075897217
Validation loss: 2.0596173952023187

Epoch: 5| Step: 5
Training loss: 2.3053781986236572
Validation loss: 2.0754826813936234

Epoch: 5| Step: 6
Training loss: 1.7554810047149658
Validation loss: 2.068587303161621

Epoch: 5| Step: 7
Training loss: 1.6661878824234009
Validation loss: 2.0765861123800278

Epoch: 5| Step: 8
Training loss: 1.7843472957611084
Validation loss: 2.081711173057556

Epoch: 5| Step: 9
Training loss: 1.3708536624908447
Validation loss: 2.078704292575518

Epoch: 5| Step: 10
Training loss: 2.303818941116333
Validation loss: 2.0933979948361716

Epoch: 5| Step: 11
Training loss: 2.1297545433044434
Validation loss: 2.1025805672009787

Epoch: 191| Step: 0
Training loss: 2.148355007171631
Validation loss: 2.0963245580593743

Epoch: 5| Step: 1
Training loss: 2.0905017852783203
Validation loss: 2.0882719308137894

Epoch: 5| Step: 2
Training loss: 2.5487160682678223
Validation loss: 2.1097270796696344

Epoch: 5| Step: 3
Training loss: 1.625438928604126
Validation loss: 2.1209711035092673

Epoch: 5| Step: 4
Training loss: 1.5785545110702515
Validation loss: 2.1182091335455575

Epoch: 5| Step: 5
Training loss: 1.908165693283081
Validation loss: 2.0833792636791864

Epoch: 5| Step: 6
Training loss: 1.8827816247940063
Validation loss: 2.100911652048429

Epoch: 5| Step: 7
Training loss: 1.680193305015564
Validation loss: 2.0877164751291275

Epoch: 5| Step: 8
Training loss: 1.98154616355896
Validation loss: 2.083293452858925

Epoch: 5| Step: 9
Training loss: 2.2794816493988037
Validation loss: 2.0676258703072867

Epoch: 5| Step: 10
Training loss: 1.9209766387939453
Validation loss: 2.0669706215461097

Epoch: 5| Step: 11
Training loss: 1.9215246438980103
Validation loss: 2.090748349825541

Epoch: 192| Step: 0
Training loss: 1.34666109085083
Validation loss: 2.0832468767960868

Epoch: 5| Step: 1
Training loss: 2.3984878063201904
Validation loss: 2.093592936793963

Epoch: 5| Step: 2
Training loss: 2.3297877311706543
Validation loss: 2.1032445232073465

Epoch: 5| Step: 3
Training loss: 2.4454174041748047
Validation loss: 2.1031498859326043

Epoch: 5| Step: 4
Training loss: 1.9713757038116455
Validation loss: 2.0903213073809943

Epoch: 5| Step: 5
Training loss: 1.8225072622299194
Validation loss: 2.1166535218556723

Epoch: 5| Step: 6
Training loss: 2.30553936958313
Validation loss: 2.126780847708384

Epoch: 5| Step: 7
Training loss: 1.8433921337127686
Validation loss: 2.12351023654143

Epoch: 5| Step: 8
Training loss: 1.5398069620132446
Validation loss: 2.104117492834727

Epoch: 5| Step: 9
Training loss: 2.0545687675476074
Validation loss: 2.1178799122571945

Epoch: 5| Step: 10
Training loss: 1.5812879800796509
Validation loss: 2.128386070330938

Epoch: 5| Step: 11
Training loss: 1.9526993036270142
Validation loss: 2.1224974940220513

Epoch: 193| Step: 0
Training loss: 1.7764145135879517
Validation loss: 2.0951576183239617

Epoch: 5| Step: 1
Training loss: 2.163764476776123
Validation loss: 2.1021743963162103

Epoch: 5| Step: 2
Training loss: 1.5144153833389282
Validation loss: 2.0974120050668716

Epoch: 5| Step: 3
Training loss: 2.186875343322754
Validation loss: 2.090572322408358

Epoch: 5| Step: 4
Training loss: 2.0396342277526855
Validation loss: 2.0880418568849564

Epoch: 5| Step: 5
Training loss: 2.3005566596984863
Validation loss: 2.094475398461024

Epoch: 5| Step: 6
Training loss: 1.6939728260040283
Validation loss: 2.103415216008822

Epoch: 5| Step: 7
Training loss: 2.19280743598938
Validation loss: 2.1057422161102295

Epoch: 5| Step: 8
Training loss: 2.0233185291290283
Validation loss: 2.1148886531591415

Epoch: 5| Step: 9
Training loss: 1.6044021844863892
Validation loss: 2.1095429758230844

Epoch: 5| Step: 10
Training loss: 2.346904993057251
Validation loss: 2.116207937399546

Epoch: 5| Step: 11
Training loss: 1.7590714693069458
Validation loss: 2.1159204492966333

Epoch: 194| Step: 0
Training loss: 1.9797389507293701
Validation loss: 2.1105130463838577

Epoch: 5| Step: 1
Training loss: 1.717742919921875
Validation loss: 2.128297890226046

Epoch: 5| Step: 2
Training loss: 2.2051281929016113
Validation loss: 2.113332827885946

Epoch: 5| Step: 3
Training loss: 1.6996772289276123
Validation loss: 2.1278245896101

Epoch: 5| Step: 4
Training loss: 2.0746259689331055
Validation loss: 2.1350790510574975

Epoch: 5| Step: 5
Training loss: 1.7314064502716064
Validation loss: 2.1357455452283225

Epoch: 5| Step: 6
Training loss: 1.748666763305664
Validation loss: 2.1155405789613724

Epoch: 5| Step: 7
Training loss: 2.3756825923919678
Validation loss: 2.1207843919595084

Epoch: 5| Step: 8
Training loss: 2.4331002235412598
Validation loss: 2.1096204717954

Epoch: 5| Step: 9
Training loss: 1.5275022983551025
Validation loss: 2.101696858803431

Epoch: 5| Step: 10
Training loss: 2.2701547145843506
Validation loss: 2.0972752769788108

Epoch: 5| Step: 11
Training loss: 1.541678786277771
Validation loss: 2.0942147225141525

Epoch: 195| Step: 0
Training loss: 1.9092499017715454
Validation loss: 2.0815086166063943

Epoch: 5| Step: 1
Training loss: 1.8260860443115234
Validation loss: 2.073784425854683

Epoch: 5| Step: 2
Training loss: 1.6990810632705688
Validation loss: 2.0712797045707703

Epoch: 5| Step: 3
Training loss: 2.0200746059417725
Validation loss: 2.064916118979454

Epoch: 5| Step: 4
Training loss: 2.0300352573394775
Validation loss: 2.073291669289271

Epoch: 5| Step: 5
Training loss: 2.083832025527954
Validation loss: 2.082030728459358

Epoch: 5| Step: 6
Training loss: 1.9748218059539795
Validation loss: 2.0888616144657135

Epoch: 5| Step: 7
Training loss: 1.9635469913482666
Validation loss: 2.08073158065478

Epoch: 5| Step: 8
Training loss: 1.7375366687774658
Validation loss: 2.118062600493431

Epoch: 5| Step: 9
Training loss: 2.231025457382202
Validation loss: 2.134998008608818

Epoch: 5| Step: 10
Training loss: 2.4210166931152344
Validation loss: 2.1313097973664603

Epoch: 5| Step: 11
Training loss: 1.604651927947998
Validation loss: 2.175553878148397

Epoch: 196| Step: 0
Training loss: 2.138340711593628
Validation loss: 2.1591661274433136

Epoch: 5| Step: 1
Training loss: 2.200305938720703
Validation loss: 2.1650035828351974

Epoch: 5| Step: 2
Training loss: 1.74282968044281
Validation loss: 2.167907486359278

Epoch: 5| Step: 3
Training loss: 1.9254703521728516
Validation loss: 2.1577233374118805

Epoch: 5| Step: 4
Training loss: 1.60263192653656
Validation loss: 2.134761303663254

Epoch: 5| Step: 5
Training loss: 1.814324140548706
Validation loss: 2.1137305249770484

Epoch: 5| Step: 6
Training loss: 1.4812648296356201
Validation loss: 2.0994603633880615

Epoch: 5| Step: 7
Training loss: 2.290510654449463
Validation loss: 2.082409883538882

Epoch: 5| Step: 8
Training loss: 1.9704620838165283
Validation loss: 2.0840558111667633

Epoch: 5| Step: 9
Training loss: 2.674327850341797
Validation loss: 2.079096630215645

Epoch: 5| Step: 10
Training loss: 2.2375950813293457
Validation loss: 2.076714038848877

Epoch: 5| Step: 11
Training loss: 2.8096232414245605
Validation loss: 2.0751298566659293

Epoch: 197| Step: 0
Training loss: 1.965207815170288
Validation loss: 2.0733834703763327

Epoch: 5| Step: 1
Training loss: 2.0680108070373535
Validation loss: 2.069482068220774

Epoch: 5| Step: 2
Training loss: 2.1155154705047607
Validation loss: 2.070476084947586

Epoch: 5| Step: 3
Training loss: 1.8974403142929077
Validation loss: 2.076234832406044

Epoch: 5| Step: 4
Training loss: 2.0348048210144043
Validation loss: 2.0845852394898734

Epoch: 5| Step: 5
Training loss: 2.1856865882873535
Validation loss: 2.106560543179512

Epoch: 5| Step: 6
Training loss: 1.8874847888946533
Validation loss: 2.111658126115799

Epoch: 5| Step: 7
Training loss: 1.7410774230957031
Validation loss: 2.125212619702021

Epoch: 5| Step: 8
Training loss: 1.866355299949646
Validation loss: 2.136979714035988

Epoch: 5| Step: 9
Training loss: 2.1122632026672363
Validation loss: 2.117719272772471

Epoch: 5| Step: 10
Training loss: 2.6210227012634277
Validation loss: 2.131827543179194

Epoch: 5| Step: 11
Training loss: 1.3641033172607422
Validation loss: 2.1062162766853967

Epoch: 198| Step: 0
Training loss: 1.8759918212890625
Validation loss: 2.1132023433844247

Epoch: 5| Step: 1
Training loss: 1.7434173822402954
Validation loss: 2.089193105697632

Epoch: 5| Step: 2
Training loss: 2.1712288856506348
Validation loss: 2.0997455716133118

Epoch: 5| Step: 3
Training loss: 2.4225404262542725
Validation loss: 2.090637594461441

Epoch: 5| Step: 4
Training loss: 1.9589455127716064
Validation loss: 2.072497064868609

Epoch: 5| Step: 5
Training loss: 1.4954876899719238
Validation loss: 2.073739548524221

Epoch: 5| Step: 6
Training loss: 1.8799184560775757
Validation loss: 2.088012397289276

Epoch: 5| Step: 7
Training loss: 2.120191812515259
Validation loss: 2.0700460175673165

Epoch: 5| Step: 8
Training loss: 1.971898078918457
Validation loss: 2.083226372798284

Epoch: 5| Step: 9
Training loss: 2.0306034088134766
Validation loss: 2.098371888200442

Epoch: 5| Step: 10
Training loss: 1.947617530822754
Validation loss: 2.096343050400416

Epoch: 5| Step: 11
Training loss: 2.192741632461548
Validation loss: 2.1078402002652488

Epoch: 199| Step: 0
Training loss: 1.7385776042938232
Validation loss: 2.1347370694080987

Epoch: 5| Step: 1
Training loss: 2.453016757965088
Validation loss: 2.136599898338318

Epoch: 5| Step: 2
Training loss: 2.3450911045074463
Validation loss: 2.1611542999744415

Epoch: 5| Step: 3
Training loss: 1.6245044469833374
Validation loss: 2.1622934689124427

Epoch: 5| Step: 4
Training loss: 1.9340670108795166
Validation loss: 2.1602717290321984

Epoch: 5| Step: 5
Training loss: 1.879431128501892
Validation loss: 2.1392353624105453

Epoch: 5| Step: 6
Training loss: 1.8306949138641357
Validation loss: 2.1244854778051376

Epoch: 5| Step: 7
Training loss: 1.9038269519805908
Validation loss: 2.1165862580140433

Epoch: 5| Step: 8
Training loss: 2.4132442474365234
Validation loss: 2.103290840983391

Epoch: 5| Step: 9
Training loss: 1.6158746480941772
Validation loss: 2.0779795994361243

Epoch: 5| Step: 10
Training loss: 2.407064914703369
Validation loss: 2.0903507073720298

Epoch: 5| Step: 11
Training loss: 1.391466498374939
Validation loss: 2.0917460918426514

Epoch: 200| Step: 0
Training loss: 1.456465482711792
Validation loss: 2.0710741380850473

Epoch: 5| Step: 1
Training loss: 2.1818199157714844
Validation loss: 2.0772132525841394

Epoch: 5| Step: 2
Training loss: 1.5812618732452393
Validation loss: 2.075435479482015

Epoch: 5| Step: 3
Training loss: 1.77716863155365
Validation loss: 2.071769634882609

Epoch: 5| Step: 4
Training loss: 2.218240261077881
Validation loss: 2.0812508861223855

Epoch: 5| Step: 5
Training loss: 1.5470010042190552
Validation loss: 2.073120648662249

Epoch: 5| Step: 6
Training loss: 2.14856219291687
Validation loss: 2.083286538720131

Epoch: 5| Step: 7
Training loss: 2.50315523147583
Validation loss: 2.094634845852852

Epoch: 5| Step: 8
Training loss: 1.741779088973999
Validation loss: 2.1009158541758857

Epoch: 5| Step: 9
Training loss: 2.355879306793213
Validation loss: 2.122968797882398

Epoch: 5| Step: 10
Training loss: 2.1247811317443848
Validation loss: 2.127113734682401

Epoch: 5| Step: 11
Training loss: 1.793505072593689
Validation loss: 2.129389708240827

Epoch: 201| Step: 0
Training loss: 1.9624525308609009
Validation loss: 2.1528885662555695

Epoch: 5| Step: 1
Training loss: 2.337491989135742
Validation loss: 2.1475860625505447

Epoch: 5| Step: 2
Training loss: 1.7744687795639038
Validation loss: 2.160756836334864

Epoch: 5| Step: 3
Training loss: 2.3607382774353027
Validation loss: 2.15976449350516

Epoch: 5| Step: 4
Training loss: 1.9494009017944336
Validation loss: 2.146057665348053

Epoch: 5| Step: 5
Training loss: 1.6792924404144287
Validation loss: 2.1442812929550805

Epoch: 5| Step: 6
Training loss: 1.8672269582748413
Validation loss: 2.1288411766290665

Epoch: 5| Step: 7
Training loss: 2.289320230484009
Validation loss: 2.1185489346583686

Epoch: 5| Step: 8
Training loss: 1.8161633014678955
Validation loss: 2.1218901872634888

Epoch: 5| Step: 9
Training loss: 1.8675788640975952
Validation loss: 2.0984606742858887

Epoch: 5| Step: 10
Training loss: 1.584966778755188
Validation loss: 2.0943656663099923

Epoch: 5| Step: 11
Training loss: 2.243035078048706
Validation loss: 2.077076534430186

Epoch: 202| Step: 0
Training loss: 2.3974196910858154
Validation loss: 2.0721292346715927

Epoch: 5| Step: 1
Training loss: 2.148730754852295
Validation loss: 2.067819520831108

Epoch: 5| Step: 2
Training loss: 2.280385732650757
Validation loss: 2.0730338792006173

Epoch: 5| Step: 3
Training loss: 2.3002541065216064
Validation loss: 2.0713771084944406

Epoch: 5| Step: 4
Training loss: 2.3239364624023438
Validation loss: 2.0676188866297402

Epoch: 5| Step: 5
Training loss: 1.5767678022384644
Validation loss: 2.084769055247307

Epoch: 5| Step: 6
Training loss: 1.6061718463897705
Validation loss: 2.076049566268921

Epoch: 5| Step: 7
Training loss: 1.969578504562378
Validation loss: 2.0809146066506705

Epoch: 5| Step: 8
Training loss: 1.7810242176055908
Validation loss: 2.0905215988556543

Epoch: 5| Step: 9
Training loss: 1.4361320734024048
Validation loss: 2.103186542789141

Epoch: 5| Step: 10
Training loss: 1.960715651512146
Validation loss: 2.105993370215098

Epoch: 5| Step: 11
Training loss: 2.45794677734375
Validation loss: 2.115730414787928

Epoch: 203| Step: 0
Training loss: 2.343507766723633
Validation loss: 2.126405745744705

Epoch: 5| Step: 1
Training loss: 2.1932876110076904
Validation loss: 2.128771717349688

Epoch: 5| Step: 2
Training loss: 1.7600284814834595
Validation loss: 2.132350037495295

Epoch: 5| Step: 3
Training loss: 2.33727765083313
Validation loss: 2.139939005176226

Epoch: 5| Step: 4
Training loss: 2.0776474475860596
Validation loss: 2.1362873713175454

Epoch: 5| Step: 5
Training loss: 1.741125464439392
Validation loss: 2.133914147814115

Epoch: 5| Step: 6
Training loss: 1.7466907501220703
Validation loss: 2.1279072165489197

Epoch: 5| Step: 7
Training loss: 1.7782176733016968
Validation loss: 2.1094192415475845

Epoch: 5| Step: 8
Training loss: 1.7579021453857422
Validation loss: 2.1281091272830963

Epoch: 5| Step: 9
Training loss: 2.057863473892212
Validation loss: 2.110384921232859

Epoch: 5| Step: 10
Training loss: 1.990818977355957
Validation loss: 2.0998430401086807

Epoch: 5| Step: 11
Training loss: 1.9082226753234863
Validation loss: 2.1081272860368094

Epoch: 204| Step: 0
Training loss: 1.6330394744873047
Validation loss: 2.1226041863361993

Epoch: 5| Step: 1
Training loss: 1.4035841226577759
Validation loss: 2.1129755278428397

Epoch: 5| Step: 2
Training loss: 1.8163745403289795
Validation loss: 2.114562670389811

Epoch: 5| Step: 3
Training loss: 1.8144611120224
Validation loss: 2.105882833401362

Epoch: 5| Step: 4
Training loss: 1.9388662576675415
Validation loss: 2.0986996243397393

Epoch: 5| Step: 5
Training loss: 1.9536716938018799
Validation loss: 2.1029070218404136

Epoch: 5| Step: 6
Training loss: 2.4536561965942383
Validation loss: 2.1112248549858728

Epoch: 5| Step: 7
Training loss: 2.228760004043579
Validation loss: 2.1141693691412606

Epoch: 5| Step: 8
Training loss: 1.870235800743103
Validation loss: 2.1325316528479257

Epoch: 5| Step: 9
Training loss: 2.499824047088623
Validation loss: 2.127217714985212

Epoch: 5| Step: 10
Training loss: 1.7033593654632568
Validation loss: 2.134809066851934

Epoch: 5| Step: 11
Training loss: 2.3605237007141113
Validation loss: 2.12561788658301

Epoch: 205| Step: 0
Training loss: 2.2817821502685547
Validation loss: 2.127365459998449

Epoch: 5| Step: 1
Training loss: 1.778435468673706
Validation loss: 2.113237351179123

Epoch: 5| Step: 2
Training loss: 1.8550338745117188
Validation loss: 2.106245736281077

Epoch: 5| Step: 3
Training loss: 1.5336310863494873
Validation loss: 2.1029861122369766

Epoch: 5| Step: 4
Training loss: 2.207232713699341
Validation loss: 2.093683401743571

Epoch: 5| Step: 5
Training loss: 1.3555066585540771
Validation loss: 2.1053608109553656

Epoch: 5| Step: 6
Training loss: 2.406424045562744
Validation loss: 2.0943952600161233

Epoch: 5| Step: 7
Training loss: 1.6847206354141235
Validation loss: 2.095835586388906

Epoch: 5| Step: 8
Training loss: 2.3437390327453613
Validation loss: 2.095873678723971

Epoch: 5| Step: 9
Training loss: 1.6863574981689453
Validation loss: 2.1183752765258155

Epoch: 5| Step: 10
Training loss: 2.197089910507202
Validation loss: 2.1209619343280792

Epoch: 5| Step: 11
Training loss: 3.184307813644409
Validation loss: 2.1239781578381858

Epoch: 206| Step: 0
Training loss: 2.0623929500579834
Validation loss: 2.131681432326635

Epoch: 5| Step: 1
Training loss: 1.8432422876358032
Validation loss: 2.1411177963018417

Epoch: 5| Step: 2
Training loss: 1.9331862926483154
Validation loss: 2.1564707458019257

Epoch: 5| Step: 3
Training loss: 2.209589719772339
Validation loss: 2.156824683149656

Epoch: 5| Step: 4
Training loss: 1.8292715549468994
Validation loss: 2.1383203814427056

Epoch: 5| Step: 5
Training loss: 1.943291425704956
Validation loss: 2.1467736760775247

Epoch: 5| Step: 6
Training loss: 1.7103935480117798
Validation loss: 2.1372359494368234

Epoch: 5| Step: 7
Training loss: 2.370328426361084
Validation loss: 2.1216521163781485

Epoch: 5| Step: 8
Training loss: 1.6068605184555054
Validation loss: 2.1330007314682007

Epoch: 5| Step: 9
Training loss: 1.893760323524475
Validation loss: 2.1084323128064475

Epoch: 5| Step: 10
Training loss: 1.7814648151397705
Validation loss: 2.119013930360476

Epoch: 5| Step: 11
Training loss: 2.964355945587158
Validation loss: 2.108326241374016

Epoch: 207| Step: 0
Training loss: 2.2600719928741455
Validation loss: 2.100101118286451

Epoch: 5| Step: 1
Training loss: 1.7738300561904907
Validation loss: 2.084690193335215

Epoch: 5| Step: 2
Training loss: 1.5025205612182617
Validation loss: 2.088807294766108

Epoch: 5| Step: 3
Training loss: 1.9793001413345337
Validation loss: 2.0969844261805215

Epoch: 5| Step: 4
Training loss: 2.3721394538879395
Validation loss: 2.1168697476387024

Epoch: 5| Step: 5
Training loss: 1.8588371276855469
Validation loss: 2.1076874236265817

Epoch: 5| Step: 6
Training loss: 1.7037426233291626
Validation loss: 2.1569138218959174

Epoch: 5| Step: 7
Training loss: 2.5748648643493652
Validation loss: 2.1331111838420234

Epoch: 5| Step: 8
Training loss: 1.5552833080291748
Validation loss: 2.1332588295141854

Epoch: 5| Step: 9
Training loss: 1.8272151947021484
Validation loss: 2.130448674162229

Epoch: 5| Step: 10
Training loss: 2.3181509971618652
Validation loss: 2.143675943215688

Epoch: 5| Step: 11
Training loss: 1.480679988861084
Validation loss: 2.1440966626008353

Epoch: 208| Step: 0
Training loss: 1.6885738372802734
Validation loss: 2.1214983016252518

Epoch: 5| Step: 1
Training loss: 1.7543163299560547
Validation loss: 2.1375842640797296

Epoch: 5| Step: 2
Training loss: 1.9726240634918213
Validation loss: 2.146352211634318

Epoch: 5| Step: 3
Training loss: 2.2049238681793213
Validation loss: 2.153921569387118

Epoch: 5| Step: 4
Training loss: 2.0428948402404785
Validation loss: 2.1529849469661713

Epoch: 5| Step: 5
Training loss: 2.1671204566955566
Validation loss: 2.1512928158044815

Epoch: 5| Step: 6
Training loss: 1.9206136465072632
Validation loss: 2.1663698007663093

Epoch: 5| Step: 7
Training loss: 2.0770516395568848
Validation loss: 2.137873739004135

Epoch: 5| Step: 8
Training loss: 1.7499415874481201
Validation loss: 2.1475748221079507

Epoch: 5| Step: 9
Training loss: 1.6957861185073853
Validation loss: 2.1219579577445984

Epoch: 5| Step: 10
Training loss: 1.9961751699447632
Validation loss: 2.132221147418022

Epoch: 5| Step: 11
Training loss: 2.6396656036376953
Validation loss: 2.1055680165688195

Epoch: 209| Step: 0
Training loss: 1.8993022441864014
Validation loss: 2.1079733123381934

Epoch: 5| Step: 1
Training loss: 1.4060266017913818
Validation loss: 2.1058339178562164

Epoch: 5| Step: 2
Training loss: 2.2222020626068115
Validation loss: 2.084558313091596

Epoch: 5| Step: 3
Training loss: 1.6569483280181885
Validation loss: 2.098670502503713

Epoch: 5| Step: 4
Training loss: 2.450460910797119
Validation loss: 2.086560383439064

Epoch: 5| Step: 5
Training loss: 1.9659204483032227
Validation loss: 2.0875747005144754

Epoch: 5| Step: 6
Training loss: 2.5404438972473145
Validation loss: 2.082451492547989

Epoch: 5| Step: 7
Training loss: 1.8378864526748657
Validation loss: 2.092321435610453

Epoch: 5| Step: 8
Training loss: 2.250732421875
Validation loss: 2.0908987621466317

Epoch: 5| Step: 9
Training loss: 2.1125094890594482
Validation loss: 2.0903257926305137

Epoch: 5| Step: 10
Training loss: 1.5849812030792236
Validation loss: 2.099045435587565

Epoch: 5| Step: 11
Training loss: 1.3622560501098633
Validation loss: 2.101953372359276

Epoch: 210| Step: 0
Training loss: 1.9736922979354858
Validation loss: 2.110526313384374

Epoch: 5| Step: 1
Training loss: 1.524639368057251
Validation loss: 2.1311661154031754

Epoch: 5| Step: 2
Training loss: 1.496950387954712
Validation loss: 2.1489985585212708

Epoch: 5| Step: 3
Training loss: 1.922842264175415
Validation loss: 2.190900206565857

Epoch: 5| Step: 4
Training loss: 1.8669726848602295
Validation loss: 2.221906969944636

Epoch: 5| Step: 5
Training loss: 1.8535737991333008
Validation loss: 2.184877892335256

Epoch: 5| Step: 6
Training loss: 2.0537819862365723
Validation loss: 2.1938610275586448

Epoch: 5| Step: 7
Training loss: 2.4172585010528564
Validation loss: 2.1778012017409005

Epoch: 5| Step: 8
Training loss: 1.9962866306304932
Validation loss: 2.142659440636635

Epoch: 5| Step: 9
Training loss: 2.6383681297302246
Validation loss: 2.1368932276964188

Epoch: 5| Step: 10
Training loss: 1.9654810428619385
Validation loss: 2.121807207663854

Epoch: 5| Step: 11
Training loss: 1.6690555810928345
Validation loss: 2.120133171478907

Epoch: 211| Step: 0
Training loss: 1.554779291152954
Validation loss: 2.0947990864515305

Epoch: 5| Step: 1
Training loss: 1.633050560951233
Validation loss: 2.0998673339684806

Epoch: 5| Step: 2
Training loss: 2.640260934829712
Validation loss: 2.0986308505137763

Epoch: 5| Step: 3
Training loss: 1.7651088237762451
Validation loss: 2.0943123400211334

Epoch: 5| Step: 4
Training loss: 1.914590835571289
Validation loss: 2.0929722587267556

Epoch: 5| Step: 5
Training loss: 1.9492324590682983
Validation loss: 2.096217766404152

Epoch: 5| Step: 6
Training loss: 2.0596907138824463
Validation loss: 2.097620353102684

Epoch: 5| Step: 7
Training loss: 2.5702102184295654
Validation loss: 2.1102999299764633

Epoch: 5| Step: 8
Training loss: 1.7354748249053955
Validation loss: 2.1200085977713266

Epoch: 5| Step: 9
Training loss: 1.9922637939453125
Validation loss: 2.134895627697309

Epoch: 5| Step: 10
Training loss: 1.7712904214859009
Validation loss: 2.152817358573278

Epoch: 5| Step: 11
Training loss: 1.59791898727417
Validation loss: 2.1400767664114633

Epoch: 212| Step: 0
Training loss: 2.2780709266662598
Validation loss: 2.148624633749326

Epoch: 5| Step: 1
Training loss: 1.5362898111343384
Validation loss: 2.152596806486448

Epoch: 5| Step: 2
Training loss: 2.4717729091644287
Validation loss: 2.141597976287206

Epoch: 5| Step: 3
Training loss: 1.6416221857070923
Validation loss: 2.139402190844218

Epoch: 5| Step: 4
Training loss: 1.7586431503295898
Validation loss: 2.1272424360116324

Epoch: 5| Step: 5
Training loss: 1.8370521068572998
Validation loss: 2.1301338374614716

Epoch: 5| Step: 6
Training loss: 2.2142868041992188
Validation loss: 2.106546993056933

Epoch: 5| Step: 7
Training loss: 2.180607318878174
Validation loss: 2.0902347366015115

Epoch: 5| Step: 8
Training loss: 1.727151870727539
Validation loss: 2.0925311098496118

Epoch: 5| Step: 9
Training loss: 2.247560739517212
Validation loss: 2.089806536833445

Epoch: 5| Step: 10
Training loss: 1.7471612691879272
Validation loss: 2.078369597593943

Epoch: 5| Step: 11
Training loss: 1.4460877180099487
Validation loss: 2.08034984767437

Epoch: 213| Step: 0
Training loss: 2.4682395458221436
Validation loss: 2.089646945397059

Epoch: 5| Step: 1
Training loss: 1.8101756572723389
Validation loss: 2.094402939081192

Epoch: 5| Step: 2
Training loss: 2.394247531890869
Validation loss: 2.1059002429246902

Epoch: 5| Step: 3
Training loss: 2.175633668899536
Validation loss: 2.0920371462901435

Epoch: 5| Step: 4
Training loss: 1.8539705276489258
Validation loss: 2.11029984553655

Epoch: 5| Step: 5
Training loss: 1.7548259496688843
Validation loss: 2.1271709899107614

Epoch: 5| Step: 6
Training loss: 2.259871006011963
Validation loss: 2.1245399117469788

Epoch: 5| Step: 7
Training loss: 2.0541391372680664
Validation loss: 2.115250969926516

Epoch: 5| Step: 8
Training loss: 1.2445520162582397
Validation loss: 2.1246349612871804

Epoch: 5| Step: 9
Training loss: 1.716570496559143
Validation loss: 2.1301677276690802

Epoch: 5| Step: 10
Training loss: 1.204059362411499
Validation loss: 2.1228117247422538

Epoch: 5| Step: 11
Training loss: 2.5967864990234375
Validation loss: 2.122596929470698

Epoch: 214| Step: 0
Training loss: 1.9596951007843018
Validation loss: 2.1165922979513803

Epoch: 5| Step: 1
Training loss: 1.8607219457626343
Validation loss: 2.1114325722058616

Epoch: 5| Step: 2
Training loss: 2.1450276374816895
Validation loss: 2.1070925891399384

Epoch: 5| Step: 3
Training loss: 1.746002197265625
Validation loss: 2.1170748472213745

Epoch: 5| Step: 4
Training loss: 1.1914420127868652
Validation loss: 2.1189155032237372

Epoch: 5| Step: 5
Training loss: 1.982200264930725
Validation loss: 2.1365252832571664

Epoch: 5| Step: 6
Training loss: 2.134159803390503
Validation loss: 2.1306961476802826

Epoch: 5| Step: 7
Training loss: 2.2316174507141113
Validation loss: 2.1436863789955773

Epoch: 5| Step: 8
Training loss: 2.1824045181274414
Validation loss: 2.1473335524400077

Epoch: 5| Step: 9
Training loss: 1.9104245901107788
Validation loss: 2.1408200611670813

Epoch: 5| Step: 10
Training loss: 1.7454887628555298
Validation loss: 2.1641055593887963

Epoch: 5| Step: 11
Training loss: 2.229109287261963
Validation loss: 2.1508999466896057

Epoch: 215| Step: 0
Training loss: 1.843070387840271
Validation loss: 2.1461005210876465

Epoch: 5| Step: 1
Training loss: 1.8919798135757446
Validation loss: 2.1285476684570312

Epoch: 5| Step: 2
Training loss: 1.1606686115264893
Validation loss: 2.1348518629868827

Epoch: 5| Step: 3
Training loss: 1.8656879663467407
Validation loss: 2.129467303554217

Epoch: 5| Step: 4
Training loss: 1.803937554359436
Validation loss: 2.1113216330607734

Epoch: 5| Step: 5
Training loss: 2.9762187004089355
Validation loss: 2.0995222628116608

Epoch: 5| Step: 6
Training loss: 2.2490227222442627
Validation loss: 2.0983718236287436

Epoch: 5| Step: 7
Training loss: 2.090937852859497
Validation loss: 2.1255347480376563

Epoch: 5| Step: 8
Training loss: 1.7097160816192627
Validation loss: 2.1167240540186563

Epoch: 5| Step: 9
Training loss: 1.8138195276260376
Validation loss: 2.140558515985807

Epoch: 5| Step: 10
Training loss: 1.7776148319244385
Validation loss: 2.1475628912448883

Epoch: 5| Step: 11
Training loss: 1.2371138334274292
Validation loss: 2.1530177146196365

Epoch: 216| Step: 0
Training loss: 1.9285895824432373
Validation loss: 2.18155566851298

Epoch: 5| Step: 1
Training loss: 1.9417657852172852
Validation loss: 2.1616171101729074

Epoch: 5| Step: 2
Training loss: 1.1256332397460938
Validation loss: 2.1821407079696655

Epoch: 5| Step: 3
Training loss: 2.032285451889038
Validation loss: 2.148148919145266

Epoch: 5| Step: 4
Training loss: 1.4061014652252197
Validation loss: 2.1497876246770224

Epoch: 5| Step: 5
Training loss: 1.9993034601211548
Validation loss: 2.1357811093330383

Epoch: 5| Step: 6
Training loss: 1.9919168949127197
Validation loss: 2.1310943216085434

Epoch: 5| Step: 7
Training loss: 2.071197032928467
Validation loss: 2.1141435702641806

Epoch: 5| Step: 8
Training loss: 1.9675710201263428
Validation loss: 2.119807963569959

Epoch: 5| Step: 9
Training loss: 1.5680978298187256
Validation loss: 2.1299418956041336

Epoch: 5| Step: 10
Training loss: 3.024599313735962
Validation loss: 2.116444398959478

Epoch: 5| Step: 11
Training loss: 2.352597951889038
Validation loss: 2.1198487132787704

Epoch: 217| Step: 0
Training loss: 1.8500831127166748
Validation loss: 2.119695315758387

Epoch: 5| Step: 1
Training loss: 2.031735420227051
Validation loss: 2.120925635099411

Epoch: 5| Step: 2
Training loss: 2.0719199180603027
Validation loss: 2.1167260309060416

Epoch: 5| Step: 3
Training loss: 1.8678979873657227
Validation loss: 2.1373737702767053

Epoch: 5| Step: 4
Training loss: 1.728122353553772
Validation loss: 2.132663374145826

Epoch: 5| Step: 5
Training loss: 2.2990996837615967
Validation loss: 2.13690085709095

Epoch: 5| Step: 6
Training loss: 1.9013477563858032
Validation loss: 2.1635044664144516

Epoch: 5| Step: 7
Training loss: 2.1760618686676025
Validation loss: 2.1572113980849585

Epoch: 5| Step: 8
Training loss: 1.7590373754501343
Validation loss: 2.1587411562601724

Epoch: 5| Step: 9
Training loss: 1.4848508834838867
Validation loss: 2.177333747347196

Epoch: 5| Step: 10
Training loss: 1.6314401626586914
Validation loss: 2.156933476527532

Epoch: 5| Step: 11
Training loss: 2.5517425537109375
Validation loss: 2.177771424253782

Epoch: 218| Step: 0
Training loss: 1.5446479320526123
Validation loss: 2.172128518422445

Epoch: 5| Step: 1
Training loss: 2.136481523513794
Validation loss: 2.1523861438035965

Epoch: 5| Step: 2
Training loss: 2.0322773456573486
Validation loss: 2.1295290887355804

Epoch: 5| Step: 3
Training loss: 2.1819043159484863
Validation loss: 2.117514982819557

Epoch: 5| Step: 4
Training loss: 1.4946520328521729
Validation loss: 2.114150360226631

Epoch: 5| Step: 5
Training loss: 1.936483383178711
Validation loss: 2.108134706815084

Epoch: 5| Step: 6
Training loss: 1.9815772771835327
Validation loss: 2.10571297009786

Epoch: 5| Step: 7
Training loss: 1.887356162071228
Validation loss: 2.1104265600442886

Epoch: 5| Step: 8
Training loss: 1.9199602603912354
Validation loss: 2.104380572835604

Epoch: 5| Step: 9
Training loss: 1.9415369033813477
Validation loss: 2.110916425784429

Epoch: 5| Step: 10
Training loss: 1.999119758605957
Validation loss: 2.105705271164576

Epoch: 5| Step: 11
Training loss: 2.237011194229126
Validation loss: 2.123285233974457

Epoch: 219| Step: 0
Training loss: 1.459349274635315
Validation loss: 2.120486562450727

Epoch: 5| Step: 1
Training loss: 2.137861490249634
Validation loss: 2.1300899386405945

Epoch: 5| Step: 2
Training loss: 1.9282821416854858
Validation loss: 2.136022279659907

Epoch: 5| Step: 3
Training loss: 1.6123988628387451
Validation loss: 2.1293664077917733

Epoch: 5| Step: 4
Training loss: 2.05924654006958
Validation loss: 2.1322104185819626

Epoch: 5| Step: 5
Training loss: 2.1708827018737793
Validation loss: 2.14524253209432

Epoch: 5| Step: 6
Training loss: 1.6848751306533813
Validation loss: 2.141749083995819

Epoch: 5| Step: 7
Training loss: 2.691978693008423
Validation loss: 2.136048366626104

Epoch: 5| Step: 8
Training loss: 1.7488387823104858
Validation loss: 2.1313525289297104

Epoch: 5| Step: 9
Training loss: 2.017657995223999
Validation loss: 2.1237252751986184

Epoch: 5| Step: 10
Training loss: 1.6578553915023804
Validation loss: 2.1220040967067084

Epoch: 5| Step: 11
Training loss: 1.6573748588562012
Validation loss: 2.1330899695555368

Epoch: 220| Step: 0
Training loss: 1.8517074584960938
Validation loss: 2.141978621482849

Epoch: 5| Step: 1
Training loss: 2.243835926055908
Validation loss: 2.1401985734701157

Epoch: 5| Step: 2
Training loss: 1.4783799648284912
Validation loss: 2.1273759057124457

Epoch: 5| Step: 3
Training loss: 1.9758708477020264
Validation loss: 2.151902894179026

Epoch: 5| Step: 4
Training loss: 2.1875431537628174
Validation loss: 2.154691884915034

Epoch: 5| Step: 5
Training loss: 1.8948198556900024
Validation loss: 2.1609882911046348

Epoch: 5| Step: 6
Training loss: 1.977656364440918
Validation loss: 2.1430931091308594

Epoch: 5| Step: 7
Training loss: 1.9364063739776611
Validation loss: 2.1737126956383386

Epoch: 5| Step: 8
Training loss: 2.181361675262451
Validation loss: 2.163500130176544

Epoch: 5| Step: 9
Training loss: 1.4451055526733398
Validation loss: 2.1657327165206275

Epoch: 5| Step: 10
Training loss: 1.8990472555160522
Validation loss: 2.1650586277246475

Epoch: 5| Step: 11
Training loss: 0.7903756499290466
Validation loss: 2.18678546945254

Epoch: 221| Step: 0
Training loss: 1.4301996231079102
Validation loss: 2.175708840290705

Epoch: 5| Step: 1
Training loss: 1.2865607738494873
Validation loss: 2.177597761154175

Epoch: 5| Step: 2
Training loss: 2.082207202911377
Validation loss: 2.172065496444702

Epoch: 5| Step: 3
Training loss: 2.557832717895508
Validation loss: 2.1951550940672555

Epoch: 5| Step: 4
Training loss: 2.229825258255005
Validation loss: 2.1851809968551

Epoch: 5| Step: 5
Training loss: 2.0503885746002197
Validation loss: 2.16309321920077

Epoch: 5| Step: 6
Training loss: 1.9182687997817993
Validation loss: 2.1461179703474045

Epoch: 5| Step: 7
Training loss: 1.9344590902328491
Validation loss: 2.1284034500519433

Epoch: 5| Step: 8
Training loss: 1.702932357788086
Validation loss: 2.118810683488846

Epoch: 5| Step: 9
Training loss: 2.1611366271972656
Validation loss: 2.115470161040624

Epoch: 5| Step: 10
Training loss: 1.8393360376358032
Validation loss: 2.106362928946813

Epoch: 5| Step: 11
Training loss: 0.9827330112457275
Validation loss: 2.1167924404144287

Epoch: 222| Step: 0
Training loss: 1.9975502490997314
Validation loss: 2.1283960243066153

Epoch: 5| Step: 1
Training loss: 1.345853567123413
Validation loss: 2.1275019894043603

Epoch: 5| Step: 2
Training loss: 2.2083916664123535
Validation loss: 2.13260609904925

Epoch: 5| Step: 3
Training loss: 1.8032238483428955
Validation loss: 2.149908517797788

Epoch: 5| Step: 4
Training loss: 2.1960151195526123
Validation loss: 2.1578881541887918

Epoch: 5| Step: 5
Training loss: 2.357642650604248
Validation loss: 2.172616794705391

Epoch: 5| Step: 6
Training loss: 1.9502458572387695
Validation loss: 2.162047788500786

Epoch: 5| Step: 7
Training loss: 1.6373214721679688
Validation loss: 2.1732558657725654

Epoch: 5| Step: 8
Training loss: 1.6127021312713623
Validation loss: 2.1665251155694327

Epoch: 5| Step: 9
Training loss: 1.9048608541488647
Validation loss: 2.149611050883929

Epoch: 5| Step: 10
Training loss: 1.6178929805755615
Validation loss: 2.165957843263944

Epoch: 5| Step: 11
Training loss: 2.0751194953918457
Validation loss: 2.160454352696737

Epoch: 223| Step: 0
Training loss: 1.7997795343399048
Validation loss: 2.1819751809040704

Epoch: 5| Step: 1
Training loss: 2.1765410900115967
Validation loss: 2.1553477197885513

Epoch: 5| Step: 2
Training loss: 1.9562371969223022
Validation loss: 2.1322913418213525

Epoch: 5| Step: 3
Training loss: 1.8161157369613647
Validation loss: 2.1384466687838235

Epoch: 5| Step: 4
Training loss: 1.7466061115264893
Validation loss: 2.130183686812719

Epoch: 5| Step: 5
Training loss: 1.8987621068954468
Validation loss: 2.126589188973109

Epoch: 5| Step: 6
Training loss: 1.8966712951660156
Validation loss: 2.1363623390595117

Epoch: 5| Step: 7
Training loss: 2.117776393890381
Validation loss: 2.130639905730883

Epoch: 5| Step: 8
Training loss: 1.842806100845337
Validation loss: 2.1460760980844498

Epoch: 5| Step: 9
Training loss: 1.8566629886627197
Validation loss: 2.160948723554611

Epoch: 5| Step: 10
Training loss: 1.8720890283584595
Validation loss: 2.1450760861237845

Epoch: 5| Step: 11
Training loss: 2.0410070419311523
Validation loss: 2.16775015493234

Epoch: 224| Step: 0
Training loss: 1.5565904378890991
Validation loss: 2.157888785004616

Epoch: 5| Step: 1
Training loss: 2.6218948364257812
Validation loss: 2.1782375127077103

Epoch: 5| Step: 2
Training loss: 1.9921157360076904
Validation loss: 2.1676561137040458

Epoch: 5| Step: 3
Training loss: 1.8481643199920654
Validation loss: 2.180861860513687

Epoch: 5| Step: 4
Training loss: 1.5057613849639893
Validation loss: 2.1711161384979882

Epoch: 5| Step: 5
Training loss: 1.4371120929718018
Validation loss: 2.1356934010982513

Epoch: 5| Step: 6
Training loss: 1.933066964149475
Validation loss: 2.1510854065418243

Epoch: 5| Step: 7
Training loss: 1.5700461864471436
Validation loss: 2.1505321065584817

Epoch: 5| Step: 8
Training loss: 1.7187579870224
Validation loss: 2.1439367731412253

Epoch: 5| Step: 9
Training loss: 2.127772092819214
Validation loss: 2.159332091609637

Epoch: 5| Step: 10
Training loss: 2.4297752380371094
Validation loss: 2.1533860862255096

Epoch: 5| Step: 11
Training loss: 1.6760903596878052
Validation loss: 2.142975707848867

Epoch: 225| Step: 0
Training loss: 1.9529063701629639
Validation loss: 2.153192773461342

Epoch: 5| Step: 1
Training loss: 2.127107620239258
Validation loss: 2.129089037577311

Epoch: 5| Step: 2
Training loss: 1.895633339881897
Validation loss: 2.125612532099088

Epoch: 5| Step: 3
Training loss: 1.9054667949676514
Validation loss: 2.1197960575421653

Epoch: 5| Step: 4
Training loss: 2.4621596336364746
Validation loss: 2.131688674290975

Epoch: 5| Step: 5
Training loss: 2.1628963947296143
Validation loss: 2.150401388605436

Epoch: 5| Step: 6
Training loss: 1.740923523902893
Validation loss: 2.1403275430202484

Epoch: 5| Step: 7
Training loss: 1.2117891311645508
Validation loss: 2.140922705332438

Epoch: 5| Step: 8
Training loss: 1.6803667545318604
Validation loss: 2.1672480950752893

Epoch: 5| Step: 9
Training loss: 1.920806884765625
Validation loss: 2.17215104897817

Epoch: 5| Step: 10
Training loss: 1.9327476024627686
Validation loss: 2.1687650084495544

Epoch: 5| Step: 11
Training loss: 1.4375019073486328
Validation loss: 2.165061965584755

Epoch: 226| Step: 0
Training loss: 1.558306097984314
Validation loss: 2.1543658872445426

Epoch: 5| Step: 1
Training loss: 2.2460622787475586
Validation loss: 2.1376684407393136

Epoch: 5| Step: 2
Training loss: 2.4656991958618164
Validation loss: 2.154142697652181

Epoch: 5| Step: 3
Training loss: 1.865186333656311
Validation loss: 2.1374267836411796

Epoch: 5| Step: 4
Training loss: 1.7021169662475586
Validation loss: 2.1435577968756356

Epoch: 5| Step: 5
Training loss: 1.537160873413086
Validation loss: 2.132963220278422

Epoch: 5| Step: 6
Training loss: 2.1090941429138184
Validation loss: 2.1404048750797906

Epoch: 5| Step: 7
Training loss: 2.126246452331543
Validation loss: 2.1333855787913003

Epoch: 5| Step: 8
Training loss: 2.0028584003448486
Validation loss: 2.145730828245481

Epoch: 5| Step: 9
Training loss: 1.771836519241333
Validation loss: 2.1410986383756003

Epoch: 5| Step: 10
Training loss: 1.704935073852539
Validation loss: 2.1388268917798996

Epoch: 5| Step: 11
Training loss: 0.38502633571624756
Validation loss: 2.131683533390363

Epoch: 227| Step: 0
Training loss: 1.345548152923584
Validation loss: 2.147579168279966

Epoch: 5| Step: 1
Training loss: 2.064556837081909
Validation loss: 2.146579404671987

Epoch: 5| Step: 2
Training loss: 1.8749973773956299
Validation loss: 2.154139662782351

Epoch: 5| Step: 3
Training loss: 1.9337797164916992
Validation loss: 2.1789626628160477

Epoch: 5| Step: 4
Training loss: 1.9294859170913696
Validation loss: 2.158377230167389

Epoch: 5| Step: 5
Training loss: 1.734405755996704
Validation loss: 2.1690709392229715

Epoch: 5| Step: 6
Training loss: 2.231086492538452
Validation loss: 2.1584997177124023

Epoch: 5| Step: 7
Training loss: 1.4255483150482178
Validation loss: 2.1679000854492188

Epoch: 5| Step: 8
Training loss: 2.5219972133636475
Validation loss: 2.1645952413479486

Epoch: 5| Step: 9
Training loss: 1.8995399475097656
Validation loss: 2.156601990262667

Epoch: 5| Step: 10
Training loss: 2.0575883388519287
Validation loss: 2.141230528553327

Epoch: 5| Step: 11
Training loss: 1.647278904914856
Validation loss: 2.1096283396085105

Epoch: 228| Step: 0
Training loss: 1.7797679901123047
Validation loss: 2.1310770213603973

Epoch: 5| Step: 1
Training loss: 2.493093490600586
Validation loss: 2.1248589952786765

Epoch: 5| Step: 2
Training loss: 1.898321509361267
Validation loss: 2.155386487642924

Epoch: 5| Step: 3
Training loss: 2.1227071285247803
Validation loss: 2.135039081176122

Epoch: 5| Step: 4
Training loss: 1.7219196557998657
Validation loss: 2.175989250342051

Epoch: 5| Step: 5
Training loss: 1.671696662902832
Validation loss: 2.170576204856237

Epoch: 5| Step: 6
Training loss: 1.6465469598770142
Validation loss: 2.218309457103411

Epoch: 5| Step: 7
Training loss: 1.9138416051864624
Validation loss: 2.2025965452194214

Epoch: 5| Step: 8
Training loss: 2.2752461433410645
Validation loss: 2.2042985757191977

Epoch: 5| Step: 9
Training loss: 1.4412331581115723
Validation loss: 2.202131579319636

Epoch: 5| Step: 10
Training loss: 1.8117214441299438
Validation loss: 2.201883614063263

Epoch: 5| Step: 11
Training loss: 1.5678887367248535
Validation loss: 2.1855200678110123

Epoch: 229| Step: 0
Training loss: 1.787969946861267
Validation loss: 2.187354266643524

Epoch: 5| Step: 1
Training loss: 1.4806140661239624
Validation loss: 2.154710536201795

Epoch: 5| Step: 2
Training loss: 1.9500764608383179
Validation loss: 2.1271165708700814

Epoch: 5| Step: 3
Training loss: 1.9151064157485962
Validation loss: 2.1221939424673715

Epoch: 5| Step: 4
Training loss: 2.1637730598449707
Validation loss: 2.135582685470581

Epoch: 5| Step: 5
Training loss: 2.2303948402404785
Validation loss: 2.115186949570974

Epoch: 5| Step: 6
Training loss: 1.5052272081375122
Validation loss: 2.109545240799586

Epoch: 5| Step: 7
Training loss: 2.0124900341033936
Validation loss: 2.124899610877037

Epoch: 5| Step: 8
Training loss: 2.272595167160034
Validation loss: 2.140326922138532

Epoch: 5| Step: 9
Training loss: 2.099827289581299
Validation loss: 2.1489876955747604

Epoch: 5| Step: 10
Training loss: 1.9139444828033447
Validation loss: 2.144937515258789

Epoch: 5| Step: 11
Training loss: 0.5306830406188965
Validation loss: 2.1415613889694214

Epoch: 230| Step: 0
Training loss: 1.7890088558197021
Validation loss: 2.1452191323041916

Epoch: 5| Step: 1
Training loss: 1.995906114578247
Validation loss: 2.1414972841739655

Epoch: 5| Step: 2
Training loss: 1.628800392150879
Validation loss: 2.156836132208506

Epoch: 5| Step: 3
Training loss: 2.4724109172821045
Validation loss: 2.1716912984848022

Epoch: 5| Step: 4
Training loss: 1.6147806644439697
Validation loss: 2.1618269880612693

Epoch: 5| Step: 5
Training loss: 1.7023687362670898
Validation loss: 2.1718097726504006

Epoch: 5| Step: 6
Training loss: 1.7485309839248657
Validation loss: 2.189435581366221

Epoch: 5| Step: 7
Training loss: 1.9289137125015259
Validation loss: 2.1905861099561057

Epoch: 5| Step: 8
Training loss: 1.9804824590682983
Validation loss: 2.2004338800907135

Epoch: 5| Step: 9
Training loss: 1.883458137512207
Validation loss: 2.16564904153347

Epoch: 5| Step: 10
Training loss: 2.0816667079925537
Validation loss: 2.1719849556684494

Epoch: 5| Step: 11
Training loss: 2.3820595741271973
Validation loss: 2.1595440904299417

Epoch: 231| Step: 0
Training loss: 1.9533500671386719
Validation loss: 2.143652061621348

Epoch: 5| Step: 1
Training loss: 2.0702590942382812
Validation loss: 2.125548998514811

Epoch: 5| Step: 2
Training loss: 2.0262086391448975
Validation loss: 2.1278563340504966

Epoch: 5| Step: 3
Training loss: 1.9431352615356445
Validation loss: 2.121147185564041

Epoch: 5| Step: 4
Training loss: 1.6499534845352173
Validation loss: 2.1152751545111337

Epoch: 5| Step: 5
Training loss: 1.7504230737686157
Validation loss: 2.1240171690781913

Epoch: 5| Step: 6
Training loss: 1.7366195917129517
Validation loss: 2.119813770055771

Epoch: 5| Step: 7
Training loss: 1.783324956893921
Validation loss: 2.1287460724512735

Epoch: 5| Step: 8
Training loss: 2.203556537628174
Validation loss: 2.135243445634842

Epoch: 5| Step: 9
Training loss: 1.7287089824676514
Validation loss: 2.134560768802961

Epoch: 5| Step: 10
Training loss: 2.0710794925689697
Validation loss: 2.139625832438469

Epoch: 5| Step: 11
Training loss: 2.5011072158813477
Validation loss: 2.1700339615345

Epoch: 232| Step: 0
Training loss: 1.8143346309661865
Validation loss: 2.177465339501699

Epoch: 5| Step: 1
Training loss: 2.4261879920959473
Validation loss: 2.18873922030131

Epoch: 5| Step: 2
Training loss: 1.9089162349700928
Validation loss: 2.180161496003469

Epoch: 5| Step: 3
Training loss: 1.903093695640564
Validation loss: 2.1758411626021066

Epoch: 5| Step: 4
Training loss: 2.000168800354004
Validation loss: 2.175730735063553

Epoch: 5| Step: 5
Training loss: 1.7439041137695312
Validation loss: 2.139736071228981

Epoch: 5| Step: 6
Training loss: 1.663321852684021
Validation loss: 2.1312213093042374

Epoch: 5| Step: 7
Training loss: 1.8653144836425781
Validation loss: 2.106988733013471

Epoch: 5| Step: 8
Training loss: 2.2702577114105225
Validation loss: 2.104446659485499

Epoch: 5| Step: 9
Training loss: 1.184338092803955
Validation loss: 2.102510248621305

Epoch: 5| Step: 10
Training loss: 2.116776704788208
Validation loss: 2.097041110197703

Epoch: 5| Step: 11
Training loss: 3.684426784515381
Validation loss: 2.108131637175878

Epoch: 233| Step: 0
Training loss: 1.8722435235977173
Validation loss: 2.108482619126638

Epoch: 5| Step: 1
Training loss: 2.0974807739257812
Validation loss: 2.084416384498278

Epoch: 5| Step: 2
Training loss: 1.9147847890853882
Validation loss: 2.104995553692182

Epoch: 5| Step: 3
Training loss: 1.989063024520874
Validation loss: 2.107384587327639

Epoch: 5| Step: 4
Training loss: 1.6119400262832642
Validation loss: 2.111803943912188

Epoch: 5| Step: 5
Training loss: 1.883935570716858
Validation loss: 2.126402661204338

Epoch: 5| Step: 6
Training loss: 2.2569260597229004
Validation loss: 2.1216718753178916

Epoch: 5| Step: 7
Training loss: 1.3766441345214844
Validation loss: 2.1346033910910287

Epoch: 5| Step: 8
Training loss: 1.6031010150909424
Validation loss: 2.127790113290151

Epoch: 5| Step: 9
Training loss: 2.02297306060791
Validation loss: 2.152418221036593

Epoch: 5| Step: 10
Training loss: 1.673041582107544
Validation loss: 2.177450026075045

Epoch: 5| Step: 11
Training loss: 4.659142971038818
Validation loss: 2.1725468138853707

Epoch: 234| Step: 0
Training loss: 1.842760443687439
Validation loss: 2.1817815949519477

Epoch: 5| Step: 1
Training loss: 1.8104795217514038
Validation loss: 2.18005833029747

Epoch: 5| Step: 2
Training loss: 2.0462543964385986
Validation loss: 2.1907461831967034

Epoch: 5| Step: 3
Training loss: 1.5503028631210327
Validation loss: 2.17170919974645

Epoch: 5| Step: 4
Training loss: 1.5134458541870117
Validation loss: 2.170847326517105

Epoch: 5| Step: 5
Training loss: 1.6400953531265259
Validation loss: 2.166872262954712

Epoch: 5| Step: 6
Training loss: 2.4753105640411377
Validation loss: 2.163439765572548

Epoch: 5| Step: 7
Training loss: 1.8679031133651733
Validation loss: 2.1525382647911706

Epoch: 5| Step: 8
Training loss: 2.1789042949676514
Validation loss: 2.164029603203138

Epoch: 5| Step: 9
Training loss: 1.7230565547943115
Validation loss: 2.158179839452108

Epoch: 5| Step: 10
Training loss: 1.7235130071640015
Validation loss: 2.163041114807129

Epoch: 5| Step: 11
Training loss: 2.482795476913452
Validation loss: 2.1464688976605735

Epoch: 235| Step: 0
Training loss: 2.485592842102051
Validation loss: 2.1862350702285767

Epoch: 5| Step: 1
Training loss: 1.636583685874939
Validation loss: 2.154285281896591

Epoch: 5| Step: 2
Training loss: 2.158703327178955
Validation loss: 2.149118642012278

Epoch: 5| Step: 3
Training loss: 1.4919377565383911
Validation loss: 2.1753776371479034

Epoch: 5| Step: 4
Training loss: 2.2645678520202637
Validation loss: 2.163750300804774

Epoch: 5| Step: 5
Training loss: 1.8175662755966187
Validation loss: 2.164030979077021

Epoch: 5| Step: 6
Training loss: 1.5784882307052612
Validation loss: 2.133535072207451

Epoch: 5| Step: 7
Training loss: 1.873798131942749
Validation loss: 2.149548426270485

Epoch: 5| Step: 8
Training loss: 1.3011951446533203
Validation loss: 2.1251381933689117

Epoch: 5| Step: 9
Training loss: 1.692654013633728
Validation loss: 2.1376856863498688

Epoch: 5| Step: 10
Training loss: 2.1275992393493652
Validation loss: 2.148770992954572

Epoch: 5| Step: 11
Training loss: 2.2271955013275146
Validation loss: 2.154632270336151

Epoch: 236| Step: 0
Training loss: 2.296062469482422
Validation loss: 2.1348594427108765

Epoch: 5| Step: 1
Training loss: 1.730821967124939
Validation loss: 2.1289392163356147

Epoch: 5| Step: 2
Training loss: 1.9061565399169922
Validation loss: 2.121836175521215

Epoch: 5| Step: 3
Training loss: 2.1602323055267334
Validation loss: 2.1007232666015625

Epoch: 5| Step: 4
Training loss: 1.58753502368927
Validation loss: 2.104539473851522

Epoch: 5| Step: 5
Training loss: 1.6121559143066406
Validation loss: 2.1076797048250833

Epoch: 5| Step: 6
Training loss: 1.357993245124817
Validation loss: 2.1168294896682105

Epoch: 5| Step: 7
Training loss: 2.343846082687378
Validation loss: 2.1167147904634476

Epoch: 5| Step: 8
Training loss: 1.549742341041565
Validation loss: 2.1386515696843467

Epoch: 5| Step: 9
Training loss: 1.921325445175171
Validation loss: 2.1381476521492004

Epoch: 5| Step: 10
Training loss: 2.3300702571868896
Validation loss: 2.1380602767070136

Epoch: 5| Step: 11
Training loss: 2.9371583461761475
Validation loss: 2.140463908513387

Epoch: 237| Step: 0
Training loss: 1.5948891639709473
Validation loss: 2.1427825639645257

Epoch: 5| Step: 1
Training loss: 1.9668077230453491
Validation loss: 2.158165847261747

Epoch: 5| Step: 2
Training loss: 2.335175037384033
Validation loss: 2.1819366067647934

Epoch: 5| Step: 3
Training loss: 1.7892119884490967
Validation loss: 2.1803051183621087

Epoch: 5| Step: 4
Training loss: 1.553807258605957
Validation loss: 2.207596162954966

Epoch: 5| Step: 5
Training loss: 1.941555380821228
Validation loss: 2.186543454726537

Epoch: 5| Step: 6
Training loss: 2.2703404426574707
Validation loss: 2.1998870770136514

Epoch: 5| Step: 7
Training loss: 1.293152093887329
Validation loss: 2.1934214929739633

Epoch: 5| Step: 8
Training loss: 2.076744556427002
Validation loss: 2.1865777919689813

Epoch: 5| Step: 9
Training loss: 2.0763118267059326
Validation loss: 2.1517844994862876

Epoch: 5| Step: 10
Training loss: 1.7986230850219727
Validation loss: 2.1540397703647614

Epoch: 5| Step: 11
Training loss: 1.7646037340164185
Validation loss: 2.148132344086965

Epoch: 238| Step: 0
Training loss: 1.9880666732788086
Validation loss: 2.126814087231954

Epoch: 5| Step: 1
Training loss: 1.8680171966552734
Validation loss: 2.1170178006092706

Epoch: 5| Step: 2
Training loss: 1.8793131113052368
Validation loss: 2.1206816136837006

Epoch: 5| Step: 3
Training loss: 2.555459499359131
Validation loss: 2.1176392436027527

Epoch: 5| Step: 4
Training loss: 2.168013095855713
Validation loss: 2.1211943527062735

Epoch: 5| Step: 5
Training loss: 1.4407366514205933
Validation loss: 2.1163791616757712

Epoch: 5| Step: 6
Training loss: 2.179785966873169
Validation loss: 2.118175208568573

Epoch: 5| Step: 7
Training loss: 2.144073009490967
Validation loss: 2.122636616230011

Epoch: 5| Step: 8
Training loss: 2.974611759185791
Validation loss: 2.1209803273280463

Epoch: 5| Step: 9
Training loss: 1.8657184839248657
Validation loss: 2.1163240522146225

Epoch: 5| Step: 10
Training loss: 1.3802610635757446
Validation loss: 2.1144124964872995

Epoch: 5| Step: 11
Training loss: 0.8800269961357117
Validation loss: 2.1148213843504586

Epoch: 239| Step: 0
Training loss: 1.9508978128433228
Validation loss: 2.131679813067118

Epoch: 5| Step: 1
Training loss: 1.6224979162216187
Validation loss: 2.1507587085167565

Epoch: 5| Step: 2
Training loss: 1.7848182916641235
Validation loss: 2.1426112403472266

Epoch: 5| Step: 3
Training loss: 1.8493648767471313
Validation loss: 2.167371148864428

Epoch: 5| Step: 4
Training loss: 2.108320713043213
Validation loss: 2.179025277495384

Epoch: 5| Step: 5
Training loss: 2.148729085922241
Validation loss: 2.1750256617863974

Epoch: 5| Step: 6
Training loss: 2.274060010910034
Validation loss: 2.1935376872618995

Epoch: 5| Step: 7
Training loss: 1.9747949838638306
Validation loss: 2.1440297216176987

Epoch: 5| Step: 8
Training loss: 1.771356225013733
Validation loss: 2.155251274506251

Epoch: 5| Step: 9
Training loss: 1.9885761737823486
Validation loss: 2.1452242881059647

Epoch: 5| Step: 10
Training loss: 1.461116909980774
Validation loss: 2.1277459412813187

Epoch: 5| Step: 11
Training loss: 2.1129164695739746
Validation loss: 2.1247120201587677

Epoch: 240| Step: 0
Training loss: 1.2682099342346191
Validation loss: 2.134554664293925

Epoch: 5| Step: 1
Training loss: 1.8266315460205078
Validation loss: 2.128913367787997

Epoch: 5| Step: 2
Training loss: 1.4201377630233765
Validation loss: 2.120817537109057

Epoch: 5| Step: 3
Training loss: 2.064748764038086
Validation loss: 2.123032401005427

Epoch: 5| Step: 4
Training loss: 2.02996563911438
Validation loss: 2.1342344929774604

Epoch: 5| Step: 5
Training loss: 2.323204517364502
Validation loss: 2.124396800994873

Epoch: 5| Step: 6
Training loss: 1.621616005897522
Validation loss: 2.1248796631892524

Epoch: 5| Step: 7
Training loss: 1.7502050399780273
Validation loss: 2.1343870808680854

Epoch: 5| Step: 8
Training loss: 1.9536819458007812
Validation loss: 2.122317145268122

Epoch: 5| Step: 9
Training loss: 2.2096710205078125
Validation loss: 2.139906053741773

Epoch: 5| Step: 10
Training loss: 1.9441099166870117
Validation loss: 2.1510147154331207

Epoch: 5| Step: 11
Training loss: 2.0542025566101074
Validation loss: 2.1530315577983856

Epoch: 241| Step: 0
Training loss: 1.3742082118988037
Validation loss: 2.1670308659474053

Epoch: 5| Step: 1
Training loss: 1.9874416589736938
Validation loss: 2.164587373534838

Epoch: 5| Step: 2
Training loss: 1.9675216674804688
Validation loss: 2.2012817760308585

Epoch: 5| Step: 3
Training loss: 1.9622204303741455
Validation loss: 2.183990553021431

Epoch: 5| Step: 4
Training loss: 2.3320419788360596
Validation loss: 2.201535329222679

Epoch: 5| Step: 5
Training loss: 2.407222270965576
Validation loss: 2.209002157052358

Epoch: 5| Step: 6
Training loss: 1.3988680839538574
Validation loss: 2.214155832926432

Epoch: 5| Step: 7
Training loss: 1.7309682369232178
Validation loss: 2.1983494609594345

Epoch: 5| Step: 8
Training loss: 1.9264377355575562
Validation loss: 2.1720616022745767

Epoch: 5| Step: 9
Training loss: 1.6330029964447021
Validation loss: 2.1617196102937064

Epoch: 5| Step: 10
Training loss: 1.7988640069961548
Validation loss: 2.1559352725744247

Epoch: 5| Step: 11
Training loss: 1.4755401611328125
Validation loss: 2.146016612648964

Epoch: 242| Step: 0
Training loss: 1.9493862390518188
Validation loss: 2.134685824314753

Epoch: 5| Step: 1
Training loss: 1.6857410669326782
Validation loss: 2.1423741976420083

Epoch: 5| Step: 2
Training loss: 2.202080726623535
Validation loss: 2.1448210378487906

Epoch: 5| Step: 3
Training loss: 1.7365001440048218
Validation loss: 2.13868240515391

Epoch: 5| Step: 4
Training loss: 1.9863452911376953
Validation loss: 2.1313520818948746

Epoch: 5| Step: 5
Training loss: 1.7762982845306396
Validation loss: 2.1336787343025208

Epoch: 5| Step: 6
Training loss: 2.5145750045776367
Validation loss: 2.1309864123662314

Epoch: 5| Step: 7
Training loss: 1.380445122718811
Validation loss: 2.1572065552075705

Epoch: 5| Step: 8
Training loss: 2.0800349712371826
Validation loss: 2.1649091194073358

Epoch: 5| Step: 9
Training loss: 1.6446784734725952
Validation loss: 2.1766648491223655

Epoch: 5| Step: 10
Training loss: 1.701681137084961
Validation loss: 2.2022330860296884

Epoch: 5| Step: 11
Training loss: 2.1318187713623047
Validation loss: 2.2194421589374542

Epoch: 243| Step: 0
Training loss: 1.7918376922607422
Validation loss: 2.2429273476203284

Epoch: 5| Step: 1
Training loss: 1.7176735401153564
Validation loss: 2.2480809092521667

Epoch: 5| Step: 2
Training loss: 2.2307751178741455
Validation loss: 2.232894296447436

Epoch: 5| Step: 3
Training loss: 2.3122894763946533
Validation loss: 2.2162716736396155

Epoch: 5| Step: 4
Training loss: 2.5719809532165527
Validation loss: 2.2419355561335883

Epoch: 5| Step: 5
Training loss: 1.9869129657745361
Validation loss: 2.2198637823263803

Epoch: 5| Step: 6
Training loss: 2.4001853466033936
Validation loss: 2.1902180860439935

Epoch: 5| Step: 7
Training loss: 1.7062323093414307
Validation loss: 2.153057108322779

Epoch: 5| Step: 8
Training loss: 1.8473331928253174
Validation loss: 2.1236761609713235

Epoch: 5| Step: 9
Training loss: 1.644456148147583
Validation loss: 2.144579435388247

Epoch: 5| Step: 10
Training loss: 1.7833013534545898
Validation loss: 2.128693396846453

Epoch: 5| Step: 11
Training loss: 1.077414870262146
Validation loss: 2.1299798836310706

Epoch: 244| Step: 0
Training loss: 1.9409490823745728
Validation loss: 2.117238158981005

Epoch: 5| Step: 1
Training loss: 1.6418737173080444
Validation loss: 2.124377836783727

Epoch: 5| Step: 2
Training loss: 1.9294350147247314
Validation loss: 2.1200235337018967

Epoch: 5| Step: 3
Training loss: 2.4457197189331055
Validation loss: 2.1229144583145776

Epoch: 5| Step: 4
Training loss: 1.6485849618911743
Validation loss: 2.1310357799132666

Epoch: 5| Step: 5
Training loss: 2.1113433837890625
Validation loss: 2.1356143057346344

Epoch: 5| Step: 6
Training loss: 2.3067307472229004
Validation loss: 2.1279310335715613

Epoch: 5| Step: 7
Training loss: 1.2842649221420288
Validation loss: 2.139367957909902

Epoch: 5| Step: 8
Training loss: 1.4651374816894531
Validation loss: 2.1375878900289536

Epoch: 5| Step: 9
Training loss: 2.052802562713623
Validation loss: 2.1563951869805655

Epoch: 5| Step: 10
Training loss: 2.3002023696899414
Validation loss: 2.159853349129359

Epoch: 5| Step: 11
Training loss: 2.244994640350342
Validation loss: 2.172576849659284

Epoch: 245| Step: 0
Training loss: 2.336498975753784
Validation loss: 2.1982637544473014

Epoch: 5| Step: 1
Training loss: 2.3655548095703125
Validation loss: 2.1802776406208673

Epoch: 5| Step: 2
Training loss: 1.8955751657485962
Validation loss: 2.1771907409032187

Epoch: 5| Step: 3
Training loss: 1.8697259426116943
Validation loss: 2.1735863784948983

Epoch: 5| Step: 4
Training loss: 1.9003541469573975
Validation loss: 2.1825081010659537

Epoch: 5| Step: 5
Training loss: 1.5397077798843384
Validation loss: 2.175517459710439

Epoch: 5| Step: 6
Training loss: 2.036586046218872
Validation loss: 2.1978341341018677

Epoch: 5| Step: 7
Training loss: 1.4657137393951416
Validation loss: 2.1909198462963104

Epoch: 5| Step: 8
Training loss: 1.8393312692642212
Validation loss: 2.188901205857595

Epoch: 5| Step: 9
Training loss: 2.025062084197998
Validation loss: 2.1618963877360025

Epoch: 5| Step: 10
Training loss: 1.7804911136627197
Validation loss: 2.141261120637258

Epoch: 5| Step: 11
Training loss: 1.1229761838912964
Validation loss: 2.1276673128207526

Epoch: 246| Step: 0
Training loss: 1.60751473903656
Validation loss: 2.1274857272704444

Epoch: 5| Step: 1
Training loss: 1.984623670578003
Validation loss: 2.1232113440831504

Epoch: 5| Step: 2
Training loss: 1.7292940616607666
Validation loss: 2.1183334439992905

Epoch: 5| Step: 3
Training loss: 1.5258055925369263
Validation loss: 2.111043001214663

Epoch: 5| Step: 4
Training loss: 2.780935287475586
Validation loss: 2.119863654176394

Epoch: 5| Step: 5
Training loss: 2.083794593811035
Validation loss: 2.1029772460460663

Epoch: 5| Step: 6
Training loss: 1.894078016281128
Validation loss: 2.107027014096578

Epoch: 5| Step: 7
Training loss: 1.987389326095581
Validation loss: 2.1088218043247857

Epoch: 5| Step: 8
Training loss: 1.784008264541626
Validation loss: 2.1153775453567505

Epoch: 5| Step: 9
Training loss: 1.92037034034729
Validation loss: 2.1165239810943604

Epoch: 5| Step: 10
Training loss: 2.0048415660858154
Validation loss: 2.131245106458664

Epoch: 5| Step: 11
Training loss: 2.6722412109375
Validation loss: 2.124417304992676

Epoch: 247| Step: 0
Training loss: 1.8997623920440674
Validation loss: 2.137199327349663

Epoch: 5| Step: 1
Training loss: 1.7376102209091187
Validation loss: 2.1391539573669434

Epoch: 5| Step: 2
Training loss: 2.018477201461792
Validation loss: 2.1560206611951194

Epoch: 5| Step: 3
Training loss: 1.7793439626693726
Validation loss: 2.15803125500679

Epoch: 5| Step: 4
Training loss: 1.8544752597808838
Validation loss: 2.1709925333658853

Epoch: 5| Step: 5
Training loss: 2.4618000984191895
Validation loss: 2.183932900428772

Epoch: 5| Step: 6
Training loss: 1.6502172946929932
Validation loss: 2.181266044576963

Epoch: 5| Step: 7
Training loss: 1.609795331954956
Validation loss: 2.162678157289823

Epoch: 5| Step: 8
Training loss: 1.7699825763702393
Validation loss: 2.162682513395945

Epoch: 5| Step: 9
Training loss: 2.282235622406006
Validation loss: 2.150521164139112

Epoch: 5| Step: 10
Training loss: 2.0387701988220215
Validation loss: 2.15664471189181

Epoch: 5| Step: 11
Training loss: 1.5107030868530273
Validation loss: 2.15313258767128

Epoch: 248| Step: 0
Training loss: 1.5782724618911743
Validation loss: 2.154804070790609

Epoch: 5| Step: 1
Training loss: 1.9147768020629883
Validation loss: 2.156283954779307

Epoch: 5| Step: 2
Training loss: 2.412867546081543
Validation loss: 2.1425316631793976

Epoch: 5| Step: 3
Training loss: 2.070587635040283
Validation loss: 2.1314549247423806

Epoch: 5| Step: 4
Training loss: 1.9678300619125366
Validation loss: 2.14836656053861

Epoch: 5| Step: 5
Training loss: 1.6696640253067017
Validation loss: 2.156690130631129

Epoch: 5| Step: 6
Training loss: 1.6554151773452759
Validation loss: 2.170593266685804

Epoch: 5| Step: 7
Training loss: 1.5322099924087524
Validation loss: 2.1508567879597345

Epoch: 5| Step: 8
Training loss: 2.0136871337890625
Validation loss: 2.158382842938105

Epoch: 5| Step: 9
Training loss: 1.772377610206604
Validation loss: 2.1720488319794335

Epoch: 5| Step: 10
Training loss: 1.7649379968643188
Validation loss: 2.169286608695984

Epoch: 5| Step: 11
Training loss: 2.134265899658203
Validation loss: 2.178842936952909

Epoch: 249| Step: 0
Training loss: 2.3106343746185303
Validation loss: 2.1653309166431427

Epoch: 5| Step: 1
Training loss: 2.062919855117798
Validation loss: 2.1736149291197457

Epoch: 5| Step: 2
Training loss: 1.5345615148544312
Validation loss: 2.1658221582571664

Epoch: 5| Step: 3
Training loss: 1.696067452430725
Validation loss: 2.178181673089663

Epoch: 5| Step: 4
Training loss: 2.459998369216919
Validation loss: 2.1632671505212784

Epoch: 5| Step: 5
Training loss: 1.777866005897522
Validation loss: 2.1689068178335824

Epoch: 5| Step: 6
Training loss: 1.7282466888427734
Validation loss: 2.1787395924329758

Epoch: 5| Step: 7
Training loss: 1.3005287647247314
Validation loss: 2.161701222260793

Epoch: 5| Step: 8
Training loss: 1.8431737422943115
Validation loss: 2.1598646690448127

Epoch: 5| Step: 9
Training loss: 2.036144971847534
Validation loss: 2.181535025437673

Epoch: 5| Step: 10
Training loss: 1.5379791259765625
Validation loss: 2.1661934008200965

Epoch: 5| Step: 11
Training loss: 2.602715015411377
Validation loss: 2.1450886875391006

Epoch: 250| Step: 0
Training loss: 2.307849884033203
Validation loss: 2.134279027581215

Epoch: 5| Step: 1
Training loss: 2.362440586090088
Validation loss: 2.133034904797872

Epoch: 5| Step: 2
Training loss: 1.9203647375106812
Validation loss: 2.1277873168389

Epoch: 5| Step: 3
Training loss: 2.393979549407959
Validation loss: 2.140703931450844

Epoch: 5| Step: 4
Training loss: 1.2982685565948486
Validation loss: 2.1355988879998526

Epoch: 5| Step: 5
Training loss: 1.488289475440979
Validation loss: 2.1429912944634757

Epoch: 5| Step: 6
Training loss: 1.949097990989685
Validation loss: 2.1394303490718207

Epoch: 5| Step: 7
Training loss: 1.807274580001831
Validation loss: 2.151341825723648

Epoch: 5| Step: 8
Training loss: 1.7162096500396729
Validation loss: 2.15139631430308

Epoch: 5| Step: 9
Training loss: 1.8962348699569702
Validation loss: 2.1522153268257775

Epoch: 5| Step: 10
Training loss: 1.6064376831054688
Validation loss: 2.167349244157473

Epoch: 5| Step: 11
Training loss: 2.505483865737915
Validation loss: 2.1720865219831467

Testing loss: 1.7695225794538318
