Epoch: 1| Step: 0
Training loss: 6.1857192434343276
Validation loss: 5.848941339845732

Epoch: 6| Step: 1
Training loss: 6.665999315556521
Validation loss: 5.847258006167864

Epoch: 6| Step: 2
Training loss: 6.369075041348172
Validation loss: 5.845571903719183

Epoch: 6| Step: 3
Training loss: 6.29673263351003
Validation loss: 5.843857245727619

Epoch: 6| Step: 4
Training loss: 5.283551679525783
Validation loss: 5.842349777151236

Epoch: 6| Step: 5
Training loss: 6.068399292293077
Validation loss: 5.840775138894168

Epoch: 6| Step: 6
Training loss: 5.823437316583375
Validation loss: 5.839244635734539

Epoch: 6| Step: 7
Training loss: 5.701977758111997
Validation loss: 5.837640244121906

Epoch: 6| Step: 8
Training loss: 5.877338674417089
Validation loss: 5.836053059841136

Epoch: 6| Step: 9
Training loss: 4.525071766321109
Validation loss: 5.834354565555181

Epoch: 6| Step: 10
Training loss: 6.285571685015668
Validation loss: 5.832642468912869

Epoch: 6| Step: 11
Training loss: 5.2993896276859465
Validation loss: 5.830811100586143

Epoch: 6| Step: 12
Training loss: 6.610507299950233
Validation loss: 5.828952352180177

Epoch: 6| Step: 13
Training loss: 6.0215239695219465
Validation loss: 5.8269857839202865

Epoch: 2| Step: 0
Training loss: 6.324956708315129
Validation loss: 5.8249285866830744

Epoch: 6| Step: 1
Training loss: 5.743187226960808
Validation loss: 5.822760519027954

Epoch: 6| Step: 2
Training loss: 5.880867483284845
Validation loss: 5.820462996822116

Epoch: 6| Step: 3
Training loss: 6.24431565236004
Validation loss: 5.818012836334171

Epoch: 6| Step: 4
Training loss: 4.698080506889888
Validation loss: 5.815463496744361

Epoch: 6| Step: 5
Training loss: 6.032566697676376
Validation loss: 5.8126352766148806

Epoch: 6| Step: 6
Training loss: 6.241495984557239
Validation loss: 5.809871421043395

Epoch: 6| Step: 7
Training loss: 5.817039112019251
Validation loss: 5.806986063170642

Epoch: 6| Step: 8
Training loss: 6.248719961693593
Validation loss: 5.803723480692037

Epoch: 6| Step: 9
Training loss: 6.191697671572179
Validation loss: 5.800511168283792

Epoch: 6| Step: 10
Training loss: 5.466221513689209
Validation loss: 5.796913523858755

Epoch: 6| Step: 11
Training loss: 5.34771474356249
Validation loss: 5.7931135917899965

Epoch: 6| Step: 12
Training loss: 5.965444238560855
Validation loss: 5.789209114308227

Epoch: 6| Step: 13
Training loss: 6.483273037954516
Validation loss: 5.785150370400596

Epoch: 3| Step: 0
Training loss: 6.033055168750693
Validation loss: 5.780787928905496

Epoch: 6| Step: 1
Training loss: 6.654802191794588
Validation loss: 5.776272006955684

Epoch: 6| Step: 2
Training loss: 5.722836894546448
Validation loss: 5.771426320738761

Epoch: 6| Step: 3
Training loss: 5.715370054904753
Validation loss: 5.766138648333406

Epoch: 6| Step: 4
Training loss: 5.5558649845841925
Validation loss: 5.760989978628166

Epoch: 6| Step: 5
Training loss: 6.418968118232155
Validation loss: 5.755316115070594

Epoch: 6| Step: 6
Training loss: 5.548486266033318
Validation loss: 5.749534449873236

Epoch: 6| Step: 7
Training loss: 6.325006163824041
Validation loss: 5.7431687950318455

Epoch: 6| Step: 8
Training loss: 6.356505250259928
Validation loss: 5.736551479813826

Epoch: 6| Step: 9
Training loss: 6.552329474729591
Validation loss: 5.72992355433272

Epoch: 6| Step: 10
Training loss: 5.203872031348613
Validation loss: 5.722778680075467

Epoch: 6| Step: 11
Training loss: 5.933058513034554
Validation loss: 5.715349419681561

Epoch: 6| Step: 12
Training loss: 4.162092877430936
Validation loss: 5.707519788848395

Epoch: 6| Step: 13
Training loss: 5.386880209690456
Validation loss: 5.699714930137359

Epoch: 4| Step: 0
Training loss: 5.463706693772213
Validation loss: 5.69182274280018

Epoch: 6| Step: 1
Training loss: 4.774707781253457
Validation loss: 5.683733912396879

Epoch: 6| Step: 2
Training loss: 6.2271402012038575
Validation loss: 5.674904146659321

Epoch: 6| Step: 3
Training loss: 4.655451558928446
Validation loss: 5.666329102653036

Epoch: 6| Step: 4
Training loss: 5.466034656525058
Validation loss: 5.65705612929444

Epoch: 6| Step: 5
Training loss: 5.168160478952454
Validation loss: 5.6483203247917055

Epoch: 6| Step: 6
Training loss: 6.337925233437867
Validation loss: 5.638629366577156

Epoch: 6| Step: 7
Training loss: 5.7544604705929805
Validation loss: 5.629139683807255

Epoch: 6| Step: 8
Training loss: 6.539511096657057
Validation loss: 5.618971356143009

Epoch: 6| Step: 9
Training loss: 5.96676554819927
Validation loss: 5.608529879945867

Epoch: 6| Step: 10
Training loss: 6.974525692581153
Validation loss: 5.597934968854796

Epoch: 6| Step: 11
Training loss: 5.341022888683077
Validation loss: 5.586862056307648

Epoch: 6| Step: 12
Training loss: 5.76882572806301
Validation loss: 5.57572054575823

Epoch: 6| Step: 13
Training loss: 5.520113666580406
Validation loss: 5.565057502328399

Epoch: 5| Step: 0
Training loss: 5.228397794128938
Validation loss: 5.5542007712337575

Epoch: 6| Step: 1
Training loss: 5.538407000452489
Validation loss: 5.542966226582113

Epoch: 6| Step: 2
Training loss: 4.685752441171152
Validation loss: 5.532098564963453

Epoch: 6| Step: 3
Training loss: 5.727622232052798
Validation loss: 5.520784034748814

Epoch: 6| Step: 4
Training loss: 6.370362633364478
Validation loss: 5.509770644549734

Epoch: 6| Step: 5
Training loss: 6.097942768332561
Validation loss: 5.498547911413938

Epoch: 6| Step: 6
Training loss: 5.837496262085594
Validation loss: 5.486991468312276

Epoch: 6| Step: 7
Training loss: 5.503889962382749
Validation loss: 5.475331935952215

Epoch: 6| Step: 8
Training loss: 5.587264579575388
Validation loss: 5.464712748980837

Epoch: 6| Step: 9
Training loss: 5.735899844626638
Validation loss: 5.453493996626404

Epoch: 6| Step: 10
Training loss: 5.104570001768425
Validation loss: 5.442639519896801

Epoch: 6| Step: 11
Training loss: 5.4338226160462995
Validation loss: 5.4318130687091255

Epoch: 6| Step: 12
Training loss: 5.684989291191919
Validation loss: 5.421732436182931

Epoch: 6| Step: 13
Training loss: 5.666201104879486
Validation loss: 5.410656906080271

Epoch: 6| Step: 0
Training loss: 5.703213960136657
Validation loss: 5.400446104531554

Epoch: 6| Step: 1
Training loss: 4.577590442474425
Validation loss: 5.389381597002378

Epoch: 6| Step: 2
Training loss: 5.8768164890439145
Validation loss: 5.37950365511529

Epoch: 6| Step: 3
Training loss: 5.040975518050448
Validation loss: 5.369101400129167

Epoch: 6| Step: 4
Training loss: 5.3494496427869
Validation loss: 5.358477369936454

Epoch: 6| Step: 5
Training loss: 6.246314831531419
Validation loss: 5.348791796485376

Epoch: 6| Step: 6
Training loss: 4.607954213630178
Validation loss: 5.33874113377042

Epoch: 6| Step: 7
Training loss: 5.827195162399605
Validation loss: 5.328902798409047

Epoch: 6| Step: 8
Training loss: 4.994917002495277
Validation loss: 5.319384075161984

Epoch: 6| Step: 9
Training loss: 5.804379276599789
Validation loss: 5.310268187614028

Epoch: 6| Step: 10
Training loss: 4.696439636316894
Validation loss: 5.301609530260453

Epoch: 6| Step: 11
Training loss: 5.579680068439202
Validation loss: 5.293318012721441

Epoch: 6| Step: 12
Training loss: 5.908319342865227
Validation loss: 5.284933276758259

Epoch: 6| Step: 13
Training loss: 5.817208300770291
Validation loss: 5.276881892589739

Epoch: 7| Step: 0
Training loss: 5.159137818807253
Validation loss: 5.269049250806633

Epoch: 6| Step: 1
Training loss: 5.710920800890428
Validation loss: 5.260688558167876

Epoch: 6| Step: 2
Training loss: 5.001426493289033
Validation loss: 5.2532784655331115

Epoch: 6| Step: 3
Training loss: 4.887078214821531
Validation loss: 5.245593386316622

Epoch: 6| Step: 4
Training loss: 5.2577566339435435
Validation loss: 5.238527933637371

Epoch: 6| Step: 5
Training loss: 4.935982772846548
Validation loss: 5.2311206323084525

Epoch: 6| Step: 6
Training loss: 4.577883352730925
Validation loss: 5.224362095004835

Epoch: 6| Step: 7
Training loss: 6.219046274153183
Validation loss: 5.216990404575135

Epoch: 6| Step: 8
Training loss: 5.231080980202424
Validation loss: 5.2097213523188515

Epoch: 6| Step: 9
Training loss: 5.536951607099816
Validation loss: 5.2029289078824945

Epoch: 6| Step: 10
Training loss: 5.548742189584465
Validation loss: 5.196202068607915

Epoch: 6| Step: 11
Training loss: 5.90470874194049
Validation loss: 5.1897762467424

Epoch: 6| Step: 12
Training loss: 5.075947174230261
Validation loss: 5.1826738941824955

Epoch: 6| Step: 13
Training loss: 5.543675835252042
Validation loss: 5.176164859015319

Epoch: 8| Step: 0
Training loss: 4.828713390459424
Validation loss: 5.16994908364936

Epoch: 6| Step: 1
Training loss: 5.087402695233756
Validation loss: 5.1633382761672815

Epoch: 6| Step: 2
Training loss: 5.607196863138239
Validation loss: 5.157341334900538

Epoch: 6| Step: 3
Training loss: 4.796591088656333
Validation loss: 5.151110621326048

Epoch: 6| Step: 4
Training loss: 5.711917986112732
Validation loss: 5.144839954117433

Epoch: 6| Step: 5
Training loss: 4.709376644344334
Validation loss: 5.138935186274929

Epoch: 6| Step: 6
Training loss: 5.70894495154024
Validation loss: 5.133093204496582

Epoch: 6| Step: 7
Training loss: 5.532248541577037
Validation loss: 5.126795105451718

Epoch: 6| Step: 8
Training loss: 5.186083864615966
Validation loss: 5.121899325871805

Epoch: 6| Step: 9
Training loss: 5.046214529937597
Validation loss: 5.116061875492834

Epoch: 6| Step: 10
Training loss: 5.1066414989983375
Validation loss: 5.110380767849615

Epoch: 6| Step: 11
Training loss: 5.1372656701472845
Validation loss: 5.104700343459636

Epoch: 6| Step: 12
Training loss: 5.526255103425795
Validation loss: 5.099588492253457

Epoch: 6| Step: 13
Training loss: 5.449947797892734
Validation loss: 5.0945131943192665

Epoch: 9| Step: 0
Training loss: 4.295160124772594
Validation loss: 5.088982033652176

Epoch: 6| Step: 1
Training loss: 5.167599481032011
Validation loss: 5.083435474474377

Epoch: 6| Step: 2
Training loss: 4.467264208513639
Validation loss: 5.0784909160533145

Epoch: 6| Step: 3
Training loss: 5.154755531826462
Validation loss: 5.073381918291471

Epoch: 6| Step: 4
Training loss: 5.898267407522698
Validation loss: 5.068031209270003

Epoch: 6| Step: 5
Training loss: 5.298403719066228
Validation loss: 5.06223971478755

Epoch: 6| Step: 6
Training loss: 5.8259482729259275
Validation loss: 5.057223769051997

Epoch: 6| Step: 7
Training loss: 5.224549320624478
Validation loss: 5.0513274213922355

Epoch: 6| Step: 8
Training loss: 4.069462136384583
Validation loss: 5.04619421367978

Epoch: 6| Step: 9
Training loss: 4.911520684157627
Validation loss: 5.0405382622297505

Epoch: 6| Step: 10
Training loss: 4.977121270877326
Validation loss: 5.034853006469298

Epoch: 6| Step: 11
Training loss: 5.789572504103687
Validation loss: 5.029147544051221

Epoch: 6| Step: 12
Training loss: 5.6221586044558745
Validation loss: 5.023162470398522

Epoch: 6| Step: 13
Training loss: 5.390632430361727
Validation loss: 5.016896943207165

Epoch: 10| Step: 0
Training loss: 5.132943301225307
Validation loss: 5.010901456076193

Epoch: 6| Step: 1
Training loss: 5.1151646466944705
Validation loss: 5.004107377682813

Epoch: 6| Step: 2
Training loss: 4.565748756397243
Validation loss: 4.997982349205321

Epoch: 6| Step: 3
Training loss: 4.628627282601207
Validation loss: 4.991594051454891

Epoch: 6| Step: 4
Training loss: 4.340233126940465
Validation loss: 4.985721482000937

Epoch: 6| Step: 5
Training loss: 4.591837166853212
Validation loss: 4.979499944070003

Epoch: 6| Step: 6
Training loss: 5.596265855757776
Validation loss: 4.9736167697234555

Epoch: 6| Step: 7
Training loss: 5.4680398534454
Validation loss: 4.967589268771002

Epoch: 6| Step: 8
Training loss: 5.421421350854495
Validation loss: 4.961115315772412

Epoch: 6| Step: 9
Training loss: 5.516955163947398
Validation loss: 4.955169191727793

Epoch: 6| Step: 10
Training loss: 5.7911282661894985
Validation loss: 4.949097962826178

Epoch: 6| Step: 11
Training loss: 4.4718352651263595
Validation loss: 4.942891874881712

Epoch: 6| Step: 12
Training loss: 5.571917844255671
Validation loss: 4.936874671965322

Epoch: 6| Step: 13
Training loss: 4.807754356570747
Validation loss: 4.930679116767885

Epoch: 11| Step: 0
Training loss: 4.767124427920809
Validation loss: 4.924511174246385

Epoch: 6| Step: 1
Training loss: 4.989769578403059
Validation loss: 4.9184580734465415

Epoch: 6| Step: 2
Training loss: 4.6362604751941685
Validation loss: 4.912997293579342

Epoch: 6| Step: 3
Training loss: 5.609658236777644
Validation loss: 4.9068822433100125

Epoch: 6| Step: 4
Training loss: 5.493072134647463
Validation loss: 4.901644122086897

Epoch: 6| Step: 5
Training loss: 4.581409304816774
Validation loss: 4.895457195144846

Epoch: 6| Step: 6
Training loss: 4.776399632985026
Validation loss: 4.889982463646605

Epoch: 6| Step: 7
Training loss: 5.4582443035911785
Validation loss: 4.8847938688291155

Epoch: 6| Step: 8
Training loss: 4.585502434910095
Validation loss: 4.87854321821448

Epoch: 6| Step: 9
Training loss: 5.182473010495723
Validation loss: 4.873083308407974

Epoch: 6| Step: 10
Training loss: 5.1546704271489965
Validation loss: 4.867380529242706

Epoch: 6| Step: 11
Training loss: 4.047020162092451
Validation loss: 4.861774436864292

Epoch: 6| Step: 12
Training loss: 5.3788113942366955
Validation loss: 4.855690625482513

Epoch: 6| Step: 13
Training loss: 5.276744116678427
Validation loss: 4.850192717692035

Epoch: 12| Step: 0
Training loss: 4.730161497814864
Validation loss: 4.844169565713224

Epoch: 6| Step: 1
Training loss: 5.0793688380515105
Validation loss: 4.838107376674311

Epoch: 6| Step: 2
Training loss: 5.128462575416845
Validation loss: 4.831732758965552

Epoch: 6| Step: 3
Training loss: 5.57141393442991
Validation loss: 4.8258708806993384

Epoch: 6| Step: 4
Training loss: 4.254201046876042
Validation loss: 4.819295634752115

Epoch: 6| Step: 5
Training loss: 4.486079407151151
Validation loss: 4.813156710648489

Epoch: 6| Step: 6
Training loss: 5.526953801394933
Validation loss: 4.807106595869909

Epoch: 6| Step: 7
Training loss: 4.93375998705483
Validation loss: 4.800718476247446

Epoch: 6| Step: 8
Training loss: 4.570120522143159
Validation loss: 4.794849643305655

Epoch: 6| Step: 9
Training loss: 5.461002289438178
Validation loss: 4.788331283496312

Epoch: 6| Step: 10
Training loss: 5.184467946254677
Validation loss: 4.782684277262691

Epoch: 6| Step: 11
Training loss: 5.044591428395699
Validation loss: 4.776404691133091

Epoch: 6| Step: 12
Training loss: 4.418307641318119
Validation loss: 4.770631938609265

Epoch: 6| Step: 13
Training loss: 4.393795728377682
Validation loss: 4.764663015526906

Epoch: 13| Step: 0
Training loss: 5.631074804021549
Validation loss: 4.759283029590645

Epoch: 6| Step: 1
Training loss: 5.154666911925579
Validation loss: 4.7525688386065665

Epoch: 6| Step: 2
Training loss: 4.506970199618478
Validation loss: 4.7466883241145075

Epoch: 6| Step: 3
Training loss: 4.682557412124989
Validation loss: 4.741817386602841

Epoch: 6| Step: 4
Training loss: 4.645211672851486
Validation loss: 4.7353813016784585

Epoch: 6| Step: 5
Training loss: 4.961105896502169
Validation loss: 4.729709000376341

Epoch: 6| Step: 6
Training loss: 5.008908346789556
Validation loss: 4.7240317723441

Epoch: 6| Step: 7
Training loss: 4.0879585125604
Validation loss: 4.717875115339836

Epoch: 6| Step: 8
Training loss: 4.384109169262076
Validation loss: 4.711979672200817

Epoch: 6| Step: 9
Training loss: 4.570042476665331
Validation loss: 4.706623487103363

Epoch: 6| Step: 10
Training loss: 4.3024927764956065
Validation loss: 4.701530820030512

Epoch: 6| Step: 11
Training loss: 5.130506023412741
Validation loss: 4.695471703257612

Epoch: 6| Step: 12
Training loss: 5.292444587457077
Validation loss: 4.690209398319378

Epoch: 6| Step: 13
Training loss: 5.266997297185983
Validation loss: 4.684518722219354

Epoch: 14| Step: 0
Training loss: 4.393271520832934
Validation loss: 4.679085108430367

Epoch: 6| Step: 1
Training loss: 5.211016195409333
Validation loss: 4.673082312636867

Epoch: 6| Step: 2
Training loss: 4.735468470632292
Validation loss: 4.667817632338603

Epoch: 6| Step: 3
Training loss: 4.034370338443158
Validation loss: 4.662190379480602

Epoch: 6| Step: 4
Training loss: 4.004008668659593
Validation loss: 4.6570726389081125

Epoch: 6| Step: 5
Training loss: 4.669704992219045
Validation loss: 4.651362095894844

Epoch: 6| Step: 6
Training loss: 4.965327781775212
Validation loss: 4.6461328429882425

Epoch: 6| Step: 7
Training loss: 5.360547351788491
Validation loss: 4.640626318660596

Epoch: 6| Step: 8
Training loss: 4.512585735827449
Validation loss: 4.635131152786061

Epoch: 6| Step: 9
Training loss: 5.263350088726204
Validation loss: 4.6303433662122595

Epoch: 6| Step: 10
Training loss: 5.2425416920559
Validation loss: 4.624755131193276

Epoch: 6| Step: 11
Training loss: 4.834531613595216
Validation loss: 4.62002808296729

Epoch: 6| Step: 12
Training loss: 4.713463455591056
Validation loss: 4.614046236330989

Epoch: 6| Step: 13
Training loss: 4.592968517445563
Validation loss: 4.609374620685454

Epoch: 15| Step: 0
Training loss: 5.961519825340656
Validation loss: 4.602950969858402

Epoch: 6| Step: 1
Training loss: 4.737278013639861
Validation loss: 4.596912497811172

Epoch: 6| Step: 2
Training loss: 4.552712589769842
Validation loss: 4.59196523998365

Epoch: 6| Step: 3
Training loss: 4.623443341549621
Validation loss: 4.586823827819596

Epoch: 6| Step: 4
Training loss: 3.9581645461118313
Validation loss: 4.581350672206849

Epoch: 6| Step: 5
Training loss: 4.424738411795366
Validation loss: 4.57595822525741

Epoch: 6| Step: 6
Training loss: 5.1900837909498225
Validation loss: 4.570984637185452

Epoch: 6| Step: 7
Training loss: 4.679096878813086
Validation loss: 4.565118395414517

Epoch: 6| Step: 8
Training loss: 3.846742039233493
Validation loss: 4.559690751526074

Epoch: 6| Step: 9
Training loss: 4.166701863458113
Validation loss: 4.554385594547213

Epoch: 6| Step: 10
Training loss: 5.155205268214048
Validation loss: 4.549461913517374

Epoch: 6| Step: 11
Training loss: 4.629444358226802
Validation loss: 4.544092049857319

Epoch: 6| Step: 12
Training loss: 4.860372655576342
Validation loss: 4.539044396019099

Epoch: 6| Step: 13
Training loss: 4.579530051162669
Validation loss: 4.533434111279064

Epoch: 16| Step: 0
Training loss: 5.194128191200711
Validation loss: 4.528650489645332

Epoch: 6| Step: 1
Training loss: 3.9861640055326255
Validation loss: 4.522688958005881

Epoch: 6| Step: 2
Training loss: 4.106918703205752
Validation loss: 4.517296188139471

Epoch: 6| Step: 3
Training loss: 5.029138726275604
Validation loss: 4.511979053468984

Epoch: 6| Step: 4
Training loss: 4.618094986035782
Validation loss: 4.507518597855569

Epoch: 6| Step: 5
Training loss: 5.123073494915114
Validation loss: 4.501688004835886

Epoch: 6| Step: 6
Training loss: 4.335474487877213
Validation loss: 4.497021378075917

Epoch: 6| Step: 7
Training loss: 5.3172995036231
Validation loss: 4.491942892740268

Epoch: 6| Step: 8
Training loss: 4.9861276827613255
Validation loss: 4.485925988838382

Epoch: 6| Step: 9
Training loss: 4.3424887163875425
Validation loss: 4.479420795180853

Epoch: 6| Step: 10
Training loss: 4.567010818284872
Validation loss: 4.474940229616996

Epoch: 6| Step: 11
Training loss: 4.362129681016362
Validation loss: 4.468526056542728

Epoch: 6| Step: 12
Training loss: 4.223538090520221
Validation loss: 4.462820106800638

Epoch: 6| Step: 13
Training loss: 4.242458608826658
Validation loss: 4.457649154692205

Epoch: 17| Step: 0
Training loss: 5.212336636917529
Validation loss: 4.451819584337497

Epoch: 6| Step: 1
Training loss: 4.211298033615014
Validation loss: 4.446693067477051

Epoch: 6| Step: 2
Training loss: 4.148668760473757
Validation loss: 4.44089199322106

Epoch: 6| Step: 3
Training loss: 4.5457814792620805
Validation loss: 4.435713699498155

Epoch: 6| Step: 4
Training loss: 5.330461364588904
Validation loss: 4.430310025615046

Epoch: 6| Step: 5
Training loss: 4.469056445731774
Validation loss: 4.424734065223953

Epoch: 6| Step: 6
Training loss: 3.8882749269636023
Validation loss: 4.4188534822986

Epoch: 6| Step: 7
Training loss: 4.295904986391064
Validation loss: 4.413197210340869

Epoch: 6| Step: 8
Training loss: 4.554674518233001
Validation loss: 4.407548176600773

Epoch: 6| Step: 9
Training loss: 4.111911237597294
Validation loss: 4.4033742046745505

Epoch: 6| Step: 10
Training loss: 5.576111673273973
Validation loss: 4.397858260270007

Epoch: 6| Step: 11
Training loss: 3.65888556017819
Validation loss: 4.391043248284959

Epoch: 6| Step: 12
Training loss: 4.749371537243564
Validation loss: 4.386211453117409

Epoch: 6| Step: 13
Training loss: 4.44886785099756
Validation loss: 4.38100036403292

Epoch: 18| Step: 0
Training loss: 4.910264626265184
Validation loss: 4.375739952364281

Epoch: 6| Step: 1
Training loss: 4.451126881765799
Validation loss: 4.369400437323331

Epoch: 6| Step: 2
Training loss: 4.627048760356097
Validation loss: 4.364167326385135

Epoch: 6| Step: 3
Training loss: 3.7399095199982364
Validation loss: 4.359188007459773

Epoch: 6| Step: 4
Training loss: 3.496243777332626
Validation loss: 4.3541316650054585

Epoch: 6| Step: 5
Training loss: 5.514411598282138
Validation loss: 4.348639080946293

Epoch: 6| Step: 6
Training loss: 4.89348423651517
Validation loss: 4.343402546770052

Epoch: 6| Step: 7
Training loss: 4.372431409765677
Validation loss: 4.338056698270466

Epoch: 6| Step: 8
Training loss: 4.709914670523584
Validation loss: 4.333373375243026

Epoch: 6| Step: 9
Training loss: 4.3313410409494075
Validation loss: 4.32902416524636

Epoch: 6| Step: 10
Training loss: 4.040195918478754
Validation loss: 4.3236961795618285

Epoch: 6| Step: 11
Training loss: 3.836410586518926
Validation loss: 4.318284140900119

Epoch: 6| Step: 12
Training loss: 5.0653977754380834
Validation loss: 4.313357834567055

Epoch: 6| Step: 13
Training loss: 4.160712119919935
Validation loss: 4.309248633833726

Epoch: 19| Step: 0
Training loss: 3.8075637128762936
Validation loss: 4.303443059568872

Epoch: 6| Step: 1
Training loss: 4.789013512315723
Validation loss: 4.297827967537293

Epoch: 6| Step: 2
Training loss: 4.25686315749642
Validation loss: 4.292079658759782

Epoch: 6| Step: 3
Training loss: 5.111555375035155
Validation loss: 4.286737011934952

Epoch: 6| Step: 4
Training loss: 4.758753290478365
Validation loss: 4.282440836702449

Epoch: 6| Step: 5
Training loss: 4.77668155001451
Validation loss: 4.2769579755519995

Epoch: 6| Step: 6
Training loss: 4.586662378161296
Validation loss: 4.2713484414694145

Epoch: 6| Step: 7
Training loss: 4.834879375795348
Validation loss: 4.266712706784358

Epoch: 6| Step: 8
Training loss: 4.0806512133422
Validation loss: 4.262032846635412

Epoch: 6| Step: 9
Training loss: 3.37362614678863
Validation loss: 4.256344995544869

Epoch: 6| Step: 10
Training loss: 4.056216030830894
Validation loss: 4.251415970480757

Epoch: 6| Step: 11
Training loss: 4.434781383471958
Validation loss: 4.245842377288341

Epoch: 6| Step: 12
Training loss: 4.541325594259475
Validation loss: 4.240997597187984

Epoch: 6| Step: 13
Training loss: 3.84609318465299
Validation loss: 4.236260176295874

Epoch: 20| Step: 0
Training loss: 4.268499614471136
Validation loss: 4.2309429340894456

Epoch: 6| Step: 1
Training loss: 3.842050067914945
Validation loss: 4.2271003122428965

Epoch: 6| Step: 2
Training loss: 4.4595029966273945
Validation loss: 4.221693373207972

Epoch: 6| Step: 3
Training loss: 4.466854947425301
Validation loss: 4.216210286066216

Epoch: 6| Step: 4
Training loss: 5.03841046986708
Validation loss: 4.21122145299916

Epoch: 6| Step: 5
Training loss: 4.3572691066059726
Validation loss: 4.207399673882642

Epoch: 6| Step: 6
Training loss: 4.2795326519654315
Validation loss: 4.202466513708146

Epoch: 6| Step: 7
Training loss: 4.643778028442079
Validation loss: 4.197349162902777

Epoch: 6| Step: 8
Training loss: 4.042008585411591
Validation loss: 4.193223638044844

Epoch: 6| Step: 9
Training loss: 4.584025775737095
Validation loss: 4.18734422080812

Epoch: 6| Step: 10
Training loss: 4.790901963401548
Validation loss: 4.1819455330949085

Epoch: 6| Step: 11
Training loss: 3.703281576331153
Validation loss: 4.176578227997181

Epoch: 6| Step: 12
Training loss: 4.154891172009818
Validation loss: 4.17133005800241

Epoch: 6| Step: 13
Training loss: 3.777655035406002
Validation loss: 4.167700709143945

Epoch: 21| Step: 0
Training loss: 4.136995387350696
Validation loss: 4.162124344959783

Epoch: 6| Step: 1
Training loss: 4.350103548067132
Validation loss: 4.157019216540013

Epoch: 6| Step: 2
Training loss: 4.018442553303359
Validation loss: 4.152865339112336

Epoch: 6| Step: 3
Training loss: 5.112926124031589
Validation loss: 4.149059682430755

Epoch: 6| Step: 4
Training loss: 4.568815067521974
Validation loss: 4.143275112214639

Epoch: 6| Step: 5
Training loss: 4.894282231918571
Validation loss: 4.139315915249302

Epoch: 6| Step: 6
Training loss: 4.587466555273395
Validation loss: 4.134490049438091

Epoch: 6| Step: 7
Training loss: 4.021144057737929
Validation loss: 4.12900801250222

Epoch: 6| Step: 8
Training loss: 3.5764030744318607
Validation loss: 4.12431401029943

Epoch: 6| Step: 9
Training loss: 3.621307333827146
Validation loss: 4.119252622555033

Epoch: 6| Step: 10
Training loss: 4.311646086696903
Validation loss: 4.115499363909957

Epoch: 6| Step: 11
Training loss: 4.189057928621387
Validation loss: 4.11085120158498

Epoch: 6| Step: 12
Training loss: 4.62441188062863
Validation loss: 4.106175655502916

Epoch: 6| Step: 13
Training loss: 3.2911642793763387
Validation loss: 4.101637252853024

Epoch: 22| Step: 0
Training loss: 3.626802719687038
Validation loss: 4.097616025171468

Epoch: 6| Step: 1
Training loss: 4.213184443712176
Validation loss: 4.09331271333088

Epoch: 6| Step: 2
Training loss: 4.1641211299812415
Validation loss: 4.088432488735197

Epoch: 6| Step: 3
Training loss: 3.4827329589742293
Validation loss: 4.083848252559947

Epoch: 6| Step: 4
Training loss: 5.169625429791852
Validation loss: 4.079094665536125

Epoch: 6| Step: 5
Training loss: 4.069135206419786
Validation loss: 4.075172554060432

Epoch: 6| Step: 6
Training loss: 2.928515716182305
Validation loss: 4.070451496115961

Epoch: 6| Step: 7
Training loss: 4.877920205352395
Validation loss: 4.066504651630962

Epoch: 6| Step: 8
Training loss: 4.299468987967143
Validation loss: 4.062189276134084

Epoch: 6| Step: 9
Training loss: 4.098230603515357
Validation loss: 4.058605302996771

Epoch: 6| Step: 10
Training loss: 3.9086863739915296
Validation loss: 4.054538339408275

Epoch: 6| Step: 11
Training loss: 5.366875118843344
Validation loss: 4.049644573141251

Epoch: 6| Step: 12
Training loss: 3.5762576098662784
Validation loss: 4.045043786294828

Epoch: 6| Step: 13
Training loss: 4.351055999262227
Validation loss: 4.040673255091385

Epoch: 23| Step: 0
Training loss: 4.723204676334785
Validation loss: 4.036088568045511

Epoch: 6| Step: 1
Training loss: 4.9064012249036795
Validation loss: 4.0314011459206895

Epoch: 6| Step: 2
Training loss: 3.316022044146514
Validation loss: 4.026271081518096

Epoch: 6| Step: 3
Training loss: 4.052588240964737
Validation loss: 4.021877601225515

Epoch: 6| Step: 4
Training loss: 4.415363815369047
Validation loss: 4.017489464300331

Epoch: 6| Step: 5
Training loss: 3.5762544098459874
Validation loss: 4.0128306600211605

Epoch: 6| Step: 6
Training loss: 4.512032845533144
Validation loss: 4.00876737426888

Epoch: 6| Step: 7
Training loss: 4.073309031495702
Validation loss: 4.0044976816426665

Epoch: 6| Step: 8
Training loss: 3.3231233793595147
Validation loss: 4.0008536063784215

Epoch: 6| Step: 9
Training loss: 3.942344349731869
Validation loss: 3.9957361940755884

Epoch: 6| Step: 10
Training loss: 4.120953279966778
Validation loss: 3.9917594545818273

Epoch: 6| Step: 11
Training loss: 4.079347390732658
Validation loss: 3.9866907309015334

Epoch: 6| Step: 12
Training loss: 4.471201191060673
Validation loss: 3.982617478043816

Epoch: 6| Step: 13
Training loss: 4.101441357958024
Validation loss: 3.9781300790678906

Epoch: 24| Step: 0
Training loss: 4.59267906109843
Validation loss: 3.974070769486349

Epoch: 6| Step: 1
Training loss: 4.377661631076706
Validation loss: 3.9697599152324803

Epoch: 6| Step: 2
Training loss: 3.6683700390761165
Validation loss: 3.9646534841200824

Epoch: 6| Step: 3
Training loss: 3.8249137020972395
Validation loss: 3.9604771012309357

Epoch: 6| Step: 4
Training loss: 3.5508352344802985
Validation loss: 3.956792404332257

Epoch: 6| Step: 5
Training loss: 3.4734187967789576
Validation loss: 3.9528069650932607

Epoch: 6| Step: 6
Training loss: 3.342632356475453
Validation loss: 3.948189570808913

Epoch: 6| Step: 7
Training loss: 3.4340120132405008
Validation loss: 3.9436991902427003

Epoch: 6| Step: 8
Training loss: 4.650862886496361
Validation loss: 3.9399089811110217

Epoch: 6| Step: 9
Training loss: 4.026747917551321
Validation loss: 3.935992381182846

Epoch: 6| Step: 10
Training loss: 4.276305078655219
Validation loss: 3.931830891608528

Epoch: 6| Step: 11
Training loss: 4.8014061616520625
Validation loss: 3.9275730681021805

Epoch: 6| Step: 12
Training loss: 4.441270757401733
Validation loss: 3.923814271301452

Epoch: 6| Step: 13
Training loss: 4.255683464626879
Validation loss: 3.919365149426652

Epoch: 25| Step: 0
Training loss: 4.379342893665425
Validation loss: 3.9148366521647784

Epoch: 6| Step: 1
Training loss: 3.9388005364365077
Validation loss: 3.90994620862612

Epoch: 6| Step: 2
Training loss: 3.7820771628849172
Validation loss: 3.9055950175161227

Epoch: 6| Step: 3
Training loss: 4.697217710254582
Validation loss: 3.9016344802443554

Epoch: 6| Step: 4
Training loss: 4.093192026099486
Validation loss: 3.8970427378365895

Epoch: 6| Step: 5
Training loss: 4.016598119718012
Validation loss: 3.892555503441334

Epoch: 6| Step: 6
Training loss: 3.0771394497647226
Validation loss: 3.8883427024452644

Epoch: 6| Step: 7
Training loss: 3.918123069150555
Validation loss: 3.883747707137491

Epoch: 6| Step: 8
Training loss: 4.009843635078955
Validation loss: 3.8792549276230286

Epoch: 6| Step: 9
Training loss: 3.9137514641806863
Validation loss: 3.8754352612253204

Epoch: 6| Step: 10
Training loss: 4.25817130440592
Validation loss: 3.871041152242631

Epoch: 6| Step: 11
Training loss: 4.781249002693421
Validation loss: 3.8668398100355055

Epoch: 6| Step: 12
Training loss: 3.372121218935902
Validation loss: 3.8625713090785094

Epoch: 6| Step: 13
Training loss: 3.733048845986808
Validation loss: 3.8581029981130714

Epoch: 26| Step: 0
Training loss: 4.31618154639949
Validation loss: 3.853865857456864

Epoch: 6| Step: 1
Training loss: 4.269493277364304
Validation loss: 3.85010375589046

Epoch: 6| Step: 2
Training loss: 4.028947039315045
Validation loss: 3.845667477079733

Epoch: 6| Step: 3
Training loss: 4.484238466317635
Validation loss: 3.8415493441779804

Epoch: 6| Step: 4
Training loss: 2.9466093329926344
Validation loss: 3.83698742619107

Epoch: 6| Step: 5
Training loss: 3.9542730420954584
Validation loss: 3.832923777442659

Epoch: 6| Step: 6
Training loss: 3.7780625962119787
Validation loss: 3.8287075300162106

Epoch: 6| Step: 7
Training loss: 3.0508059453025775
Validation loss: 3.82430798456017

Epoch: 6| Step: 8
Training loss: 4.324677013178041
Validation loss: 3.8208448875083376

Epoch: 6| Step: 9
Training loss: 3.9376886716175217
Validation loss: 3.816925398762094

Epoch: 6| Step: 10
Training loss: 3.841242274566141
Validation loss: 3.812603037124505

Epoch: 6| Step: 11
Training loss: 3.9737873698898625
Validation loss: 3.8088112793447535

Epoch: 6| Step: 12
Training loss: 4.3117898549836635
Validation loss: 3.8045191169466026

Epoch: 6| Step: 13
Training loss: 3.914955143969963
Validation loss: 3.8005311837285647

Epoch: 27| Step: 0
Training loss: 4.1733603815618
Validation loss: 3.7960619690449184

Epoch: 6| Step: 1
Training loss: 3.943088501407449
Validation loss: 3.791992837200294

Epoch: 6| Step: 2
Training loss: 4.063937358403466
Validation loss: 3.7883881588241386

Epoch: 6| Step: 3
Training loss: 3.9229360414182888
Validation loss: 3.784261486851122

Epoch: 6| Step: 4
Training loss: 4.311241076718169
Validation loss: 3.779744702469164

Epoch: 6| Step: 5
Training loss: 3.592066627649145
Validation loss: 3.7750094070485782

Epoch: 6| Step: 6
Training loss: 4.100025986379752
Validation loss: 3.770849526442574

Epoch: 6| Step: 7
Training loss: 3.7017613729092385
Validation loss: 3.7665458597935886

Epoch: 6| Step: 8
Training loss: 3.344288149871377
Validation loss: 3.7621168412528014

Epoch: 6| Step: 9
Training loss: 3.949131814695953
Validation loss: 3.7583455998346706

Epoch: 6| Step: 10
Training loss: 2.8831320484735947
Validation loss: 3.7541238574185036

Epoch: 6| Step: 11
Training loss: 3.833092281115454
Validation loss: 3.750485007393035

Epoch: 6| Step: 12
Training loss: 4.524557709549191
Validation loss: 3.7465091563836292

Epoch: 6| Step: 13
Training loss: 4.050549580525694
Validation loss: 3.7426876193176826

Epoch: 28| Step: 0
Training loss: 3.9559853801245004
Validation loss: 3.7383251712441825

Epoch: 6| Step: 1
Training loss: 2.9079963605456554
Validation loss: 3.7344587202277553

Epoch: 6| Step: 2
Training loss: 3.3344165631378933
Validation loss: 3.7301714660532754

Epoch: 6| Step: 3
Training loss: 3.8160597644900256
Validation loss: 3.726432941991696

Epoch: 6| Step: 4
Training loss: 3.58142124585461
Validation loss: 3.722372369126064

Epoch: 6| Step: 5
Training loss: 3.753963537503496
Validation loss: 3.7184979115587526

Epoch: 6| Step: 6
Training loss: 4.721367116560713
Validation loss: 3.714986547699879

Epoch: 6| Step: 7
Training loss: 4.345453381166415
Validation loss: 3.710613185698202

Epoch: 6| Step: 8
Training loss: 4.54770382802375
Validation loss: 3.7065971610758903

Epoch: 6| Step: 9
Training loss: 3.1606702916960603
Validation loss: 3.702225673832174

Epoch: 6| Step: 10
Training loss: 2.8482374061366986
Validation loss: 3.698265857954875

Epoch: 6| Step: 11
Training loss: 4.036374169569464
Validation loss: 3.6945026738892857

Epoch: 6| Step: 12
Training loss: 4.65343456788509
Validation loss: 3.6902997439111207

Epoch: 6| Step: 13
Training loss: 3.5672939236205363
Validation loss: 3.6864404610901884

Epoch: 29| Step: 0
Training loss: 3.9014912419654117
Validation loss: 3.682206573294481

Epoch: 6| Step: 1
Training loss: 4.132056240987835
Validation loss: 3.6781977980936036

Epoch: 6| Step: 2
Training loss: 3.0800637273264475
Validation loss: 3.674115064475917

Epoch: 6| Step: 3
Training loss: 3.8644622756354563
Validation loss: 3.6701304302200306

Epoch: 6| Step: 4
Training loss: 4.141792564602114
Validation loss: 3.6659675206134588

Epoch: 6| Step: 5
Training loss: 3.890889966896657
Validation loss: 3.661786031732266

Epoch: 6| Step: 6
Training loss: 4.342858970971547
Validation loss: 3.6578018720630765

Epoch: 6| Step: 7
Training loss: 3.5606072735123377
Validation loss: 3.6535176775591522

Epoch: 6| Step: 8
Training loss: 3.3284877525678445
Validation loss: 3.64930785510064

Epoch: 6| Step: 9
Training loss: 3.6472750329129897
Validation loss: 3.6453149408821997

Epoch: 6| Step: 10
Training loss: 3.5869107390486237
Validation loss: 3.6412490506339545

Epoch: 6| Step: 11
Training loss: 3.5927754283172657
Validation loss: 3.6375750425797637

Epoch: 6| Step: 12
Training loss: 4.18129897381166
Validation loss: 3.6335796462278576

Epoch: 6| Step: 13
Training loss: 3.643435330814403
Validation loss: 3.6297408486610054

Epoch: 30| Step: 0
Training loss: 4.146460455359646
Validation loss: 3.625536100712273

Epoch: 6| Step: 1
Training loss: 4.502424434724616
Validation loss: 3.6213504462970767

Epoch: 6| Step: 2
Training loss: 3.6992521354997567
Validation loss: 3.6167963309417566

Epoch: 6| Step: 3
Training loss: 2.943304130982474
Validation loss: 3.6125780345755896

Epoch: 6| Step: 4
Training loss: 4.260866522259036
Validation loss: 3.6083356013008254

Epoch: 6| Step: 5
Training loss: 2.8027205091392635
Validation loss: 3.60425313210085

Epoch: 6| Step: 6
Training loss: 3.8296371276107615
Validation loss: 3.6002288577839052

Epoch: 6| Step: 7
Training loss: 3.489075095140724
Validation loss: 3.595893640701293

Epoch: 6| Step: 8
Training loss: 3.7020506769191504
Validation loss: 3.5918155937267127

Epoch: 6| Step: 9
Training loss: 3.9177479705522917
Validation loss: 3.5877417718849993

Epoch: 6| Step: 10
Training loss: 3.980386091128377
Validation loss: 3.5840642464561685

Epoch: 6| Step: 11
Training loss: 3.7648013151919577
Validation loss: 3.579549380984224

Epoch: 6| Step: 12
Training loss: 3.571162350132777
Validation loss: 3.575909013044367

Epoch: 6| Step: 13
Training loss: 3.316387270815834
Validation loss: 3.5715620996853996

Epoch: 31| Step: 0
Training loss: 3.7107826602153597
Validation loss: 3.567926011324787

Epoch: 6| Step: 1
Training loss: 3.0186041312979843
Validation loss: 3.5640804733498817

Epoch: 6| Step: 2
Training loss: 3.8180289279167567
Validation loss: 3.560238170371885

Epoch: 6| Step: 3
Training loss: 3.956647426898031
Validation loss: 3.5564853243969043

Epoch: 6| Step: 4
Training loss: 2.968282241110273
Validation loss: 3.5522191011467292

Epoch: 6| Step: 5
Training loss: 3.009031370831719
Validation loss: 3.5485261611242875

Epoch: 6| Step: 6
Training loss: 3.654598156382087
Validation loss: 3.5449054644076075

Epoch: 6| Step: 7
Training loss: 4.2799562601724395
Validation loss: 3.5412194511944244

Epoch: 6| Step: 8
Training loss: 3.626053624113787
Validation loss: 3.537399788415478

Epoch: 6| Step: 9
Training loss: 3.8638874808725667
Validation loss: 3.5335720383486424

Epoch: 6| Step: 10
Training loss: 3.8388302960657414
Validation loss: 3.5298633609871044

Epoch: 6| Step: 11
Training loss: 3.6006297726261005
Validation loss: 3.5259231855507656

Epoch: 6| Step: 12
Training loss: 3.934387551212667
Validation loss: 3.522394345884993

Epoch: 6| Step: 13
Training loss: 3.9672219045438557
Validation loss: 3.5184000323424685

Epoch: 32| Step: 0
Training loss: 3.676133823005299
Validation loss: 3.514593128370841

Epoch: 6| Step: 1
Training loss: 2.9173802365758195
Validation loss: 3.510626793221922

Epoch: 6| Step: 2
Training loss: 4.026607235181501
Validation loss: 3.507195489960373

Epoch: 6| Step: 3
Training loss: 3.66298882669197
Validation loss: 3.503295777213626

Epoch: 6| Step: 4
Training loss: 3.274334404554104
Validation loss: 3.4993594355463307

Epoch: 6| Step: 5
Training loss: 3.6407875384937887
Validation loss: 3.495717494047146

Epoch: 6| Step: 6
Training loss: 3.0380914308552875
Validation loss: 3.4919751449070366

Epoch: 6| Step: 7
Training loss: 3.9092278688402877
Validation loss: 3.4885116335894604

Epoch: 6| Step: 8
Training loss: 3.1494469172220403
Validation loss: 3.4846881218276415

Epoch: 6| Step: 9
Training loss: 4.196218723047605
Validation loss: 3.480877453761313

Epoch: 6| Step: 10
Training loss: 3.6274371668962475
Validation loss: 3.4773549980393605

Epoch: 6| Step: 11
Training loss: 4.0785131744736915
Validation loss: 3.473465952754549

Epoch: 6| Step: 12
Training loss: 3.3994843372422343
Validation loss: 3.4701114079293136

Epoch: 6| Step: 13
Training loss: 3.901118455580114
Validation loss: 3.4663381124349124

Epoch: 33| Step: 0
Training loss: 4.438140393106755
Validation loss: 3.462499353658935

Epoch: 6| Step: 1
Training loss: 2.9991466580128305
Validation loss: 3.4581104038191786

Epoch: 6| Step: 2
Training loss: 3.320704537976849
Validation loss: 3.4540406821129666

Epoch: 6| Step: 3
Training loss: 4.068196689468102
Validation loss: 3.450116326955534

Epoch: 6| Step: 4
Training loss: 3.371163200644314
Validation loss: 3.4462731968972196

Epoch: 6| Step: 5
Training loss: 3.8196058497377807
Validation loss: 3.44252346463911

Epoch: 6| Step: 6
Training loss: 3.479376110846245
Validation loss: 3.438486177416028

Epoch: 6| Step: 7
Training loss: 3.2465605509164006
Validation loss: 3.434302305008143

Epoch: 6| Step: 8
Training loss: 3.910583167917005
Validation loss: 3.430426770640233

Epoch: 6| Step: 9
Training loss: 3.5282294934512795
Validation loss: 3.426353682246198

Epoch: 6| Step: 10
Training loss: 3.3670369621312313
Validation loss: 3.422366799325396

Epoch: 6| Step: 11
Training loss: 3.509050384481545
Validation loss: 3.418354842404886

Epoch: 6| Step: 12
Training loss: 3.7462010532321663
Validation loss: 3.4142998118963637

Epoch: 6| Step: 13
Training loss: 2.9741842225307398
Validation loss: 3.4104108449567363

Epoch: 34| Step: 0
Training loss: 3.3277089033462883
Validation loss: 3.407265981174841

Epoch: 6| Step: 1
Training loss: 3.0060617875724254
Validation loss: 3.4037128763909665

Epoch: 6| Step: 2
Training loss: 3.9397420403708576
Validation loss: 3.4002078301357486

Epoch: 6| Step: 3
Training loss: 3.584491246940024
Validation loss: 3.3961369353395447

Epoch: 6| Step: 4
Training loss: 3.157871698412596
Validation loss: 3.3929521628628825

Epoch: 6| Step: 5
Training loss: 3.8956265454141583
Validation loss: 3.3893520702271345

Epoch: 6| Step: 6
Training loss: 3.0772790666199614
Validation loss: 3.385650654067026

Epoch: 6| Step: 7
Training loss: 3.134933400640696
Validation loss: 3.382346904567135

Epoch: 6| Step: 8
Training loss: 3.4957567105783007
Validation loss: 3.3789789269189017

Epoch: 6| Step: 9
Training loss: 3.8829230248668356
Validation loss: 3.3757480804807796

Epoch: 6| Step: 10
Training loss: 3.534165790548458
Validation loss: 3.3722308537056604

Epoch: 6| Step: 11
Training loss: 3.632800686724744
Validation loss: 3.3687379104312396

Epoch: 6| Step: 12
Training loss: 3.319568505799702
Validation loss: 3.3652327691220294

Epoch: 6| Step: 13
Training loss: 4.112255638770361
Validation loss: 3.3617370108521363

Epoch: 35| Step: 0
Training loss: 3.302373414078975
Validation loss: 3.3578990680747625

Epoch: 6| Step: 1
Training loss: 3.7415536491017263
Validation loss: 3.3546506560170477

Epoch: 6| Step: 2
Training loss: 3.954921269073238
Validation loss: 3.3509351117939863

Epoch: 6| Step: 3
Training loss: 3.0703932579232878
Validation loss: 3.347519814297544

Epoch: 6| Step: 4
Training loss: 3.9910676882401104
Validation loss: 3.3439391489690498

Epoch: 6| Step: 5
Training loss: 3.5559982398407466
Validation loss: 3.340115375144081

Epoch: 6| Step: 6
Training loss: 2.6562751320042692
Validation loss: 3.336484746543591

Epoch: 6| Step: 7
Training loss: 3.0529346168531473
Validation loss: 3.3326992067520207

Epoch: 6| Step: 8
Training loss: 3.0218471711227486
Validation loss: 3.3295958467134685

Epoch: 6| Step: 9
Training loss: 3.2934126911048764
Validation loss: 3.326223603356142

Epoch: 6| Step: 10
Training loss: 3.4959191646352554
Validation loss: 3.3231531057077426

Epoch: 6| Step: 11
Training loss: 3.6103436379917087
Validation loss: 3.3197925115575675

Epoch: 6| Step: 12
Training loss: 3.855095966099536
Validation loss: 3.316235744974341

Epoch: 6| Step: 13
Training loss: 3.753803740023674
Validation loss: 3.312682704565304

Epoch: 36| Step: 0
Training loss: 3.8749301042713378
Validation loss: 3.309704302576834

Epoch: 6| Step: 1
Training loss: 3.4205574739086044
Validation loss: 3.3055260137810447

Epoch: 6| Step: 2
Training loss: 3.306940559713542
Validation loss: 3.3024665217082805

Epoch: 6| Step: 3
Training loss: 3.725214108451834
Validation loss: 3.2990278594232225

Epoch: 6| Step: 4
Training loss: 2.889317232149001
Validation loss: 3.2953128337784574

Epoch: 6| Step: 5
Training loss: 3.7274286635062945
Validation loss: 3.2920536264491362

Epoch: 6| Step: 6
Training loss: 2.273625736374662
Validation loss: 3.2886989752033524

Epoch: 6| Step: 7
Training loss: 3.5224823259677787
Validation loss: 3.285187565748389

Epoch: 6| Step: 8
Training loss: 3.707584062524878
Validation loss: 3.281993793775358

Epoch: 6| Step: 9
Training loss: 3.4941665537572058
Validation loss: 3.2789409566234187

Epoch: 6| Step: 10
Training loss: 2.748152892799924
Validation loss: 3.275469432315696

Epoch: 6| Step: 11
Training loss: 3.2680072764825763
Validation loss: 3.2719785706098925

Epoch: 6| Step: 12
Training loss: 3.3398201924881907
Validation loss: 3.268690164381862

Epoch: 6| Step: 13
Training loss: 4.226614170851553
Validation loss: 3.2658144517180605

Epoch: 37| Step: 0
Training loss: 3.062656943523211
Validation loss: 3.262159269817164

Epoch: 6| Step: 1
Training loss: 3.249864135249812
Validation loss: 3.259119639111432

Epoch: 6| Step: 2
Training loss: 2.984140756411659
Validation loss: 3.255565011383605

Epoch: 6| Step: 3
Training loss: 2.8257485199821217
Validation loss: 3.252715467997645

Epoch: 6| Step: 4
Training loss: 3.489102564853726
Validation loss: 3.2493234076845985

Epoch: 6| Step: 5
Training loss: 3.2499490880646436
Validation loss: 3.2467363550068766

Epoch: 6| Step: 6
Training loss: 3.0875539674559738
Validation loss: 3.243371133110317

Epoch: 6| Step: 7
Training loss: 3.1832739546532176
Validation loss: 3.2407250717833835

Epoch: 6| Step: 8
Training loss: 4.001174277554682
Validation loss: 3.237828412085136

Epoch: 6| Step: 9
Training loss: 4.218853532439095
Validation loss: 3.234977874837425

Epoch: 6| Step: 10
Training loss: 3.6806634147402586
Validation loss: 3.2318802701550178

Epoch: 6| Step: 11
Training loss: 3.434873652681812
Validation loss: 3.228753036751613

Epoch: 6| Step: 12
Training loss: 3.5685234679361346
Validation loss: 3.225620640317694

Epoch: 6| Step: 13
Training loss: 3.0210685024582626
Validation loss: 3.2224676643447956

Epoch: 38| Step: 0
Training loss: 3.3666106612831737
Validation loss: 3.218817108343581

Epoch: 6| Step: 1
Training loss: 3.7752611638353675
Validation loss: 3.2155050074287677

Epoch: 6| Step: 2
Training loss: 2.5679473662523313
Validation loss: 3.212331662548275

Epoch: 6| Step: 3
Training loss: 3.3526885446302526
Validation loss: 3.2089146710791305

Epoch: 6| Step: 4
Training loss: 3.5912369939433795
Validation loss: 3.2057511023920866

Epoch: 6| Step: 5
Training loss: 3.0607291570837267
Validation loss: 3.2024609133191104

Epoch: 6| Step: 6
Training loss: 3.6259798501449545
Validation loss: 3.199376178077262

Epoch: 6| Step: 7
Training loss: 3.1867341262135938
Validation loss: 3.1964814799994654

Epoch: 6| Step: 8
Training loss: 3.3410677981264083
Validation loss: 3.193754430321136

Epoch: 6| Step: 9
Training loss: 3.937027070238968
Validation loss: 3.190405537389626

Epoch: 6| Step: 10
Training loss: 3.044053243143872
Validation loss: 3.187486411670319

Epoch: 6| Step: 11
Training loss: 3.16587766220843
Validation loss: 3.184917999880807

Epoch: 6| Step: 12
Training loss: 3.4452938157178314
Validation loss: 3.181130296694674

Epoch: 6| Step: 13
Training loss: 3.060590031653686
Validation loss: 3.1779228393713472

Epoch: 39| Step: 0
Training loss: 3.1838934447223877
Validation loss: 3.1747471876441606

Epoch: 6| Step: 1
Training loss: 3.584783763243109
Validation loss: 3.171329031623466

Epoch: 6| Step: 2
Training loss: 3.66061414787686
Validation loss: 3.1686549135446698

Epoch: 6| Step: 3
Training loss: 2.8246807390603292
Validation loss: 3.1654846637293867

Epoch: 6| Step: 4
Training loss: 2.6917020195055588
Validation loss: 3.1626399354796755

Epoch: 6| Step: 5
Training loss: 3.5247548552418198
Validation loss: 3.15980383845595

Epoch: 6| Step: 6
Training loss: 3.365450028003864
Validation loss: 3.1567431401419164

Epoch: 6| Step: 7
Training loss: 3.1399143610653173
Validation loss: 3.1526463271609098

Epoch: 6| Step: 8
Training loss: 3.5920098113539836
Validation loss: 3.151231622356094

Epoch: 6| Step: 9
Training loss: 2.7906815987685816
Validation loss: 3.1472837670677554

Epoch: 6| Step: 10
Training loss: 3.6405452342975093
Validation loss: 3.1444877668892803

Epoch: 6| Step: 11
Training loss: 3.378302759509886
Validation loss: 3.1410054724458494

Epoch: 6| Step: 12
Training loss: 3.30431203309932
Validation loss: 3.13831253067823

Epoch: 6| Step: 13
Training loss: 3.2791296511301438
Validation loss: 3.1354435806555605

Epoch: 40| Step: 0
Training loss: 3.084959546385014
Validation loss: 3.1327786083084663

Epoch: 6| Step: 1
Training loss: 3.0890402345911347
Validation loss: 3.1293216069276335

Epoch: 6| Step: 2
Training loss: 2.8597548602489993
Validation loss: 3.127012011997894

Epoch: 6| Step: 3
Training loss: 3.408289027839341
Validation loss: 3.1246324195843416

Epoch: 6| Step: 4
Training loss: 2.996326740859261
Validation loss: 3.121768004881705

Epoch: 6| Step: 5
Training loss: 2.824854355830196
Validation loss: 3.1189366072669937

Epoch: 6| Step: 6
Training loss: 2.387107904802362
Validation loss: 3.115773924976835

Epoch: 6| Step: 7
Training loss: 2.7252435417886134
Validation loss: 3.113621340962

Epoch: 6| Step: 8
Training loss: 3.4507996337345666
Validation loss: 3.1112902188591187

Epoch: 6| Step: 9
Training loss: 3.726119233005597
Validation loss: 3.108855595489564

Epoch: 6| Step: 10
Training loss: 3.7911409006542187
Validation loss: 3.106089608690707

Epoch: 6| Step: 11
Training loss: 3.782339396272332
Validation loss: 3.103243099448265

Epoch: 6| Step: 12
Training loss: 3.781503211756846
Validation loss: 3.100359564099278

Epoch: 6| Step: 13
Training loss: 3.2714700909203085
Validation loss: 3.0971916142097875

Epoch: 41| Step: 0
Training loss: 2.709565092851826
Validation loss: 3.093993129231888

Epoch: 6| Step: 1
Training loss: 3.261539806094398
Validation loss: 3.0918450704205154

Epoch: 6| Step: 2
Training loss: 3.003885613855483
Validation loss: 3.088744793152547

Epoch: 6| Step: 3
Training loss: 4.222941259316624
Validation loss: 3.0864343299580366

Epoch: 6| Step: 4
Training loss: 3.0507593679192833
Validation loss: 3.0835497024156853

Epoch: 6| Step: 5
Training loss: 2.9035527007672535
Validation loss: 3.0806516420999213

Epoch: 6| Step: 6
Training loss: 2.744810148945399
Validation loss: 3.0781765980276736

Epoch: 6| Step: 7
Training loss: 2.9643409513753602
Validation loss: 3.0749461352791805

Epoch: 6| Step: 8
Training loss: 3.6180275256795253
Validation loss: 3.0727787999837473

Epoch: 6| Step: 9
Training loss: 3.3107727153793554
Validation loss: 3.070258621377248

Epoch: 6| Step: 10
Training loss: 3.5356895423893104
Validation loss: 3.067081994113976

Epoch: 6| Step: 11
Training loss: 2.8856874928721155
Validation loss: 3.064293939310748

Epoch: 6| Step: 12
Training loss: 2.6799770009776283
Validation loss: 3.061669658797174

Epoch: 6| Step: 13
Training loss: 3.754870494331225
Validation loss: 3.0584240083132808

Epoch: 42| Step: 0
Training loss: 3.103733484821112
Validation loss: 3.0560075488197005

Epoch: 6| Step: 1
Training loss: 3.309072772842386
Validation loss: 3.0529926668327483

Epoch: 6| Step: 2
Training loss: 3.243521762822522
Validation loss: 3.0503455325904607

Epoch: 6| Step: 3
Training loss: 2.885545050637368
Validation loss: 3.0476532814254584

Epoch: 6| Step: 4
Training loss: 3.2577006734779235
Validation loss: 3.0450129108959105

Epoch: 6| Step: 5
Training loss: 4.070472055189078
Validation loss: 3.0423203031644634

Epoch: 6| Step: 6
Training loss: 3.376159186329997
Validation loss: 3.0394401152251906

Epoch: 6| Step: 7
Training loss: 3.005829234030981
Validation loss: 3.0362390446638665

Epoch: 6| Step: 8
Training loss: 2.9849506242460713
Validation loss: 3.0341756931356807

Epoch: 6| Step: 9
Training loss: 3.0314183139280786
Validation loss: 3.0315932115614617

Epoch: 6| Step: 10
Training loss: 2.721348364913572
Validation loss: 3.0290807978559733

Epoch: 6| Step: 11
Training loss: 2.9821359913325183
Validation loss: 3.0259480727270813

Epoch: 6| Step: 12
Training loss: 3.5537742699254933
Validation loss: 3.0239462806355464

Epoch: 6| Step: 13
Training loss: 2.7933497882561684
Validation loss: 3.0214927129090006

Epoch: 43| Step: 0
Training loss: 3.161184551486149
Validation loss: 3.018412696627731

Epoch: 6| Step: 1
Training loss: 2.944473754289086
Validation loss: 3.016176782702963

Epoch: 6| Step: 2
Training loss: 3.045605986982212
Validation loss: 3.0140912334258414

Epoch: 6| Step: 3
Training loss: 3.2794123272001023
Validation loss: 3.011658136439808

Epoch: 6| Step: 4
Training loss: 3.6335096777255185
Validation loss: 3.0101796005165755

Epoch: 6| Step: 5
Training loss: 2.460600427219515
Validation loss: 3.007430041549369

Epoch: 6| Step: 6
Training loss: 3.3483296343598
Validation loss: 3.0052889984429436

Epoch: 6| Step: 7
Training loss: 3.2173026080518667
Validation loss: 3.0024918432916343

Epoch: 6| Step: 8
Training loss: 3.2150777961015735
Validation loss: 2.9996409201301475

Epoch: 6| Step: 9
Training loss: 3.0197355884732677
Validation loss: 2.9976817551741473

Epoch: 6| Step: 10
Training loss: 3.2029244709048013
Validation loss: 2.995726482058059

Epoch: 6| Step: 11
Training loss: 2.8007274500150094
Validation loss: 2.9930895980193184

Epoch: 6| Step: 12
Training loss: 3.610955755038235
Validation loss: 2.9901487677487637

Epoch: 6| Step: 13
Training loss: 2.9249194598724806
Validation loss: 2.9883180836254586

Epoch: 44| Step: 0
Training loss: 3.6171761629985673
Validation loss: 2.9855736527270857

Epoch: 6| Step: 1
Training loss: 3.2254023278804733
Validation loss: 2.983486942158479

Epoch: 6| Step: 2
Training loss: 3.183776475776068
Validation loss: 2.9808950723410117

Epoch: 6| Step: 3
Training loss: 2.980428432926855
Validation loss: 2.978251687951454

Epoch: 6| Step: 4
Training loss: 2.3726449633930597
Validation loss: 2.975888714160629

Epoch: 6| Step: 5
Training loss: 3.0612304547310147
Validation loss: 2.9733470727263818

Epoch: 6| Step: 6
Training loss: 3.3923166862779777
Validation loss: 2.971130621232684

Epoch: 6| Step: 7
Training loss: 3.3589937215498233
Validation loss: 2.9689234365028683

Epoch: 6| Step: 8
Training loss: 3.18472378573569
Validation loss: 2.966486432640555

Epoch: 6| Step: 9
Training loss: 3.0869074202613604
Validation loss: 2.9642834173687143

Epoch: 6| Step: 10
Training loss: 3.2753495706841225
Validation loss: 2.9716182839874223

Epoch: 6| Step: 11
Training loss: 2.480440683281172
Validation loss: 2.962918305943536

Epoch: 6| Step: 12
Training loss: 3.2095522526096136
Validation loss: 2.9589904046495565

Epoch: 6| Step: 13
Training loss: 2.970976305959253
Validation loss: 2.9610164232564045

Epoch: 45| Step: 0
Training loss: 2.683607787160795
Validation loss: 2.9673951520771826

Epoch: 6| Step: 1
Training loss: 3.343188372353851
Validation loss: 2.985266014889108

Epoch: 6| Step: 2
Training loss: 3.264304154043771
Validation loss: 2.9761439285271334

Epoch: 6| Step: 3
Training loss: 3.3532171544248373
Validation loss: 2.9574916654175376

Epoch: 6| Step: 4
Training loss: 3.7884397643870056
Validation loss: 2.954285637451115

Epoch: 6| Step: 5
Training loss: 2.746955399969462
Validation loss: 2.9488982373825428

Epoch: 6| Step: 6
Training loss: 3.011991693817074
Validation loss: 2.9513030848777286

Epoch: 6| Step: 7
Training loss: 2.6438812403648306
Validation loss: 2.9500887835876397

Epoch: 6| Step: 8
Training loss: 2.912005560167475
Validation loss: 2.9539046427350675

Epoch: 6| Step: 9
Training loss: 3.2620201839568668
Validation loss: 2.9563789000848146

Epoch: 6| Step: 10
Training loss: 3.1139342653445206
Validation loss: 2.944452215780243

Epoch: 6| Step: 11
Training loss: 3.132244410579644
Validation loss: 2.9458385237270814

Epoch: 6| Step: 12
Training loss: 3.1691525055051253
Validation loss: 2.937212327980132

Epoch: 6| Step: 13
Training loss: 2.6620455179371167
Validation loss: 2.935356250698024

Epoch: 46| Step: 0
Training loss: 3.6755133601155885
Validation loss: 2.926719199413705

Epoch: 6| Step: 1
Training loss: 3.123362455473152
Validation loss: 2.923903415672918

Epoch: 6| Step: 2
Training loss: 2.956749684724785
Validation loss: 2.9205880552328387

Epoch: 6| Step: 3
Training loss: 2.7080747236369365
Validation loss: 2.9184672973649675

Epoch: 6| Step: 4
Training loss: 3.3670994156293403
Validation loss: 2.9180452812538875

Epoch: 6| Step: 5
Training loss: 2.3365553227052023
Validation loss: 2.9152017911115493

Epoch: 6| Step: 6
Training loss: 3.166727032002418
Validation loss: 2.914589760050438

Epoch: 6| Step: 7
Training loss: 2.942814017679569
Validation loss: 2.912300020045776

Epoch: 6| Step: 8
Training loss: 3.127645974537562
Validation loss: 2.911757060894872

Epoch: 6| Step: 9
Training loss: 2.752851395104326
Validation loss: 2.9093745673125015

Epoch: 6| Step: 10
Training loss: 3.3570185003466873
Validation loss: 2.9068495702796566

Epoch: 6| Step: 11
Training loss: 2.3846619479600424
Validation loss: 2.9037349715756022

Epoch: 6| Step: 12
Training loss: 3.503086908628488
Validation loss: 2.9009992960512943

Epoch: 6| Step: 13
Training loss: 3.04749812087767
Validation loss: 2.8997307537317276

Epoch: 47| Step: 0
Training loss: 3.042868146102527
Validation loss: 2.896528439605677

Epoch: 6| Step: 1
Training loss: 2.4751729346074747
Validation loss: 2.8947105335031775

Epoch: 6| Step: 2
Training loss: 3.222170891480812
Validation loss: 2.89220728827078

Epoch: 6| Step: 3
Training loss: 3.089332432161325
Validation loss: 2.8904264227215033

Epoch: 6| Step: 4
Training loss: 2.8066222761665345
Validation loss: 2.8891703614228814

Epoch: 6| Step: 5
Training loss: 2.862502258832948
Validation loss: 2.8867543054437745

Epoch: 6| Step: 6
Training loss: 3.310710207530564
Validation loss: 2.8841964170443863

Epoch: 6| Step: 7
Training loss: 2.9174235497193464
Validation loss: 2.8835373598653686

Epoch: 6| Step: 8
Training loss: 2.9795158732875318
Validation loss: 2.8809190715919413

Epoch: 6| Step: 9
Training loss: 2.5143042467722387
Validation loss: 2.8791926123797498

Epoch: 6| Step: 10
Training loss: 3.25275392495551
Validation loss: 2.876081719281373

Epoch: 6| Step: 11
Training loss: 3.1426987515207463
Validation loss: 2.874187686438128

Epoch: 6| Step: 12
Training loss: 3.5359545401762267
Validation loss: 2.8729256458063777

Epoch: 6| Step: 13
Training loss: 3.0343506675553913
Validation loss: 2.870929130280959

Epoch: 48| Step: 0
Training loss: 2.48473696201142
Validation loss: 2.8689931645941855

Epoch: 6| Step: 1
Training loss: 2.7683903721080183
Validation loss: 2.8677692845180305

Epoch: 6| Step: 2
Training loss: 2.7530549160613575
Validation loss: 2.8659847276400052

Epoch: 6| Step: 3
Training loss: 3.142917991643636
Validation loss: 2.8654082249220347

Epoch: 6| Step: 4
Training loss: 2.9990611196651704
Validation loss: 2.8639330779040795

Epoch: 6| Step: 5
Training loss: 3.2324438549573697
Validation loss: 2.859735928184005

Epoch: 6| Step: 6
Training loss: 2.9611864614372756
Validation loss: 2.856572541014501

Epoch: 6| Step: 7
Training loss: 3.3530332810513364
Validation loss: 2.853873221541053

Epoch: 6| Step: 8
Training loss: 2.589796615332768
Validation loss: 2.8539534347592017

Epoch: 6| Step: 9
Training loss: 3.248136132643095
Validation loss: 2.8499321025992286

Epoch: 6| Step: 10
Training loss: 2.4378780169681287
Validation loss: 2.8507882099061423

Epoch: 6| Step: 11
Training loss: 3.440487343843452
Validation loss: 2.8458380386812583

Epoch: 6| Step: 12
Training loss: 3.1154376403121646
Validation loss: 2.8448233622337242

Epoch: 6| Step: 13
Training loss: 3.239226751952003
Validation loss: 2.842534794210048

Epoch: 49| Step: 0
Training loss: 3.1411437559850968
Validation loss: 2.8424726978199755

Epoch: 6| Step: 1
Training loss: 2.9294869723039283
Validation loss: 2.8420132234593685

Epoch: 6| Step: 2
Training loss: 3.0376798725637153
Validation loss: 2.8396844132686034

Epoch: 6| Step: 3
Training loss: 2.7414428047532557
Validation loss: 2.838880484888519

Epoch: 6| Step: 4
Training loss: 3.070956951191165
Validation loss: 2.8377251013423357

Epoch: 6| Step: 5
Training loss: 2.5940573636596844
Validation loss: 2.83593867698624

Epoch: 6| Step: 6
Training loss: 3.135202461774735
Validation loss: 2.8338572541322713

Epoch: 6| Step: 7
Training loss: 2.9260628619478277
Validation loss: 2.8322194986150286

Epoch: 6| Step: 8
Training loss: 3.254121514535046
Validation loss: 2.831893531695463

Epoch: 6| Step: 9
Training loss: 3.1081571254607985
Validation loss: 2.829559355849377

Epoch: 6| Step: 10
Training loss: 2.6095855079758357
Validation loss: 2.8290288896304774

Epoch: 6| Step: 11
Training loss: 2.777977893826527
Validation loss: 2.8267306127227783

Epoch: 6| Step: 12
Training loss: 2.9688878077595784
Validation loss: 2.8258279425493584

Epoch: 6| Step: 13
Training loss: 3.2553426404584678
Validation loss: 2.8227703624316702

Epoch: 50| Step: 0
Training loss: 2.449303633148311
Validation loss: 2.8213195693498174

Epoch: 6| Step: 1
Training loss: 2.666453432458685
Validation loss: 2.8191434316404007

Epoch: 6| Step: 2
Training loss: 3.1064755517134777
Validation loss: 2.8174291579358983

Epoch: 6| Step: 3
Training loss: 3.0994519949117145
Validation loss: 2.8155696083008532

Epoch: 6| Step: 4
Training loss: 2.70472105678675
Validation loss: 2.8138759496838426

Epoch: 6| Step: 5
Training loss: 3.0981994383555524
Validation loss: 2.8129917703836558

Epoch: 6| Step: 6
Training loss: 2.8737113386542767
Validation loss: 2.8089717775056267

Epoch: 6| Step: 7
Training loss: 2.47070534445923
Validation loss: 2.8083404157947314

Epoch: 6| Step: 8
Training loss: 3.1602804303378624
Validation loss: 2.819238953287111

Epoch: 6| Step: 9
Training loss: 2.653700558762916
Validation loss: 2.825798145286219

Epoch: 6| Step: 10
Training loss: 3.165150999110148
Validation loss: 2.8165446268161642

Epoch: 6| Step: 11
Training loss: 2.884704795821091
Validation loss: 2.8078021763106027

Epoch: 6| Step: 12
Training loss: 3.607542291024564
Validation loss: 2.812863714930567

Epoch: 6| Step: 13
Training loss: 3.183023638082322
Validation loss: 2.8019491728439196

Epoch: 51| Step: 0
Training loss: 2.5573118769720473
Validation loss: 2.7938879247836392

Epoch: 6| Step: 1
Training loss: 2.622441089066635
Validation loss: 2.794284523073894

Epoch: 6| Step: 2
Training loss: 3.1391935360086602
Validation loss: 2.793237049936445

Epoch: 6| Step: 3
Training loss: 2.850047756932658
Validation loss: 2.7951382975975867

Epoch: 6| Step: 4
Training loss: 2.8354997953906897
Validation loss: 2.7970421313141705

Epoch: 6| Step: 5
Training loss: 3.230020586544605
Validation loss: 2.7989536850870196

Epoch: 6| Step: 6
Training loss: 2.249368367017085
Validation loss: 2.7993239154201497

Epoch: 6| Step: 7
Training loss: 3.372565627763857
Validation loss: 2.797340382762872

Epoch: 6| Step: 8
Training loss: 2.423797828552598
Validation loss: 2.791851796706435

Epoch: 6| Step: 9
Training loss: 3.469686845615988
Validation loss: 2.788370710929196

Epoch: 6| Step: 10
Training loss: 2.8387810189128437
Validation loss: 2.7894150540508056

Epoch: 6| Step: 11
Training loss: 3.663935352063287
Validation loss: 2.785443405749633

Epoch: 6| Step: 12
Training loss: 2.6793671797435152
Validation loss: 2.781532858991461

Epoch: 6| Step: 13
Training loss: 2.8064365724253215
Validation loss: 2.7815882016408704

Epoch: 52| Step: 0
Training loss: 2.7642848329201186
Validation loss: 2.7831390623338046

Epoch: 6| Step: 1
Training loss: 2.5546363568800854
Validation loss: 2.7834314370902145

Epoch: 6| Step: 2
Training loss: 2.8499369965666634
Validation loss: 2.7818095897971395

Epoch: 6| Step: 3
Training loss: 2.5975645579740685
Validation loss: 2.7808812643494343

Epoch: 6| Step: 4
Training loss: 2.3873701689405777
Validation loss: 2.779299234052824

Epoch: 6| Step: 5
Training loss: 3.2261968594844705
Validation loss: 2.775320168087874

Epoch: 6| Step: 6
Training loss: 3.101918082429015
Validation loss: 2.771133855904637

Epoch: 6| Step: 7
Training loss: 2.8351700009569396
Validation loss: 2.7696228155684253

Epoch: 6| Step: 8
Training loss: 3.049266795845935
Validation loss: 2.766764748991023

Epoch: 6| Step: 9
Training loss: 3.118433805961038
Validation loss: 2.7637504072230725

Epoch: 6| Step: 10
Training loss: 2.9840985714378836
Validation loss: 2.7618106177489343

Epoch: 6| Step: 11
Training loss: 3.3230196339948157
Validation loss: 2.7595072897812307

Epoch: 6| Step: 12
Training loss: 2.9015629207054086
Validation loss: 2.7567726026181374

Epoch: 6| Step: 13
Training loss: 2.915721431335464
Validation loss: 2.754566115375194

Epoch: 53| Step: 0
Training loss: 2.6906122329178626
Validation loss: 2.7523837595274925

Epoch: 6| Step: 1
Training loss: 2.906698540970676
Validation loss: 2.752341155326083

Epoch: 6| Step: 2
Training loss: 2.753560795320821
Validation loss: 2.750971766927988

Epoch: 6| Step: 3
Training loss: 3.259296033712798
Validation loss: 2.749305753062032

Epoch: 6| Step: 4
Training loss: 2.7874931814341264
Validation loss: 2.748087463585256

Epoch: 6| Step: 5
Training loss: 2.979486426063751
Validation loss: 2.7455272859037123

Epoch: 6| Step: 6
Training loss: 3.073409287789141
Validation loss: 2.746373342766248

Epoch: 6| Step: 7
Training loss: 2.3223598708141404
Validation loss: 2.7438816441589653

Epoch: 6| Step: 8
Training loss: 3.0118859389392036
Validation loss: 2.7435208490681546

Epoch: 6| Step: 9
Training loss: 2.9848354443762695
Validation loss: 2.7422211473797065

Epoch: 6| Step: 10
Training loss: 2.881012972600265
Validation loss: 2.739586374452786

Epoch: 6| Step: 11
Training loss: 2.9910615640245783
Validation loss: 2.7376483180308537

Epoch: 6| Step: 12
Training loss: 2.811234422558293
Validation loss: 2.7362897145499976

Epoch: 6| Step: 13
Training loss: 2.876071730174151
Validation loss: 2.733439534341635

Epoch: 54| Step: 0
Training loss: 3.0066927324111106
Validation loss: 2.73538869323915

Epoch: 6| Step: 1
Training loss: 2.70561914645571
Validation loss: 2.7319296083713858

Epoch: 6| Step: 2
Training loss: 2.759622039623308
Validation loss: 2.731777912393761

Epoch: 6| Step: 3
Training loss: 2.469543522650717
Validation loss: 2.7279935941331965

Epoch: 6| Step: 4
Training loss: 2.313476974725586
Validation loss: 2.728020992969235

Epoch: 6| Step: 5
Training loss: 3.2999757765834583
Validation loss: 2.7277707079968208

Epoch: 6| Step: 6
Training loss: 2.7347002108503773
Validation loss: 2.7278783295618125

Epoch: 6| Step: 7
Training loss: 3.075230510724651
Validation loss: 2.727929385681784

Epoch: 6| Step: 8
Training loss: 3.5137693127644556
Validation loss: 2.7391441824833267

Epoch: 6| Step: 9
Training loss: 2.9828544857533212
Validation loss: 2.7253406340920567

Epoch: 6| Step: 10
Training loss: 2.957214430422657
Validation loss: 2.7214183063644843

Epoch: 6| Step: 11
Training loss: 2.693063344862753
Validation loss: 2.72031692133498

Epoch: 6| Step: 12
Training loss: 2.585284839335985
Validation loss: 2.7207008027712405

Epoch: 6| Step: 13
Training loss: 2.8125307717229386
Validation loss: 2.7215804205235226

Epoch: 55| Step: 0
Training loss: 2.659037126354398
Validation loss: 2.7217624534466154

Epoch: 6| Step: 1
Training loss: 2.941223382014728
Validation loss: 2.724897880273928

Epoch: 6| Step: 2
Training loss: 3.0238730735380024
Validation loss: 2.72589139503522

Epoch: 6| Step: 3
Training loss: 2.710023313612089
Validation loss: 2.7250043612337356

Epoch: 6| Step: 4
Training loss: 2.781061487559941
Validation loss: 2.7252642757110808

Epoch: 6| Step: 5
Training loss: 3.1042739201051384
Validation loss: 2.7271989955713005

Epoch: 6| Step: 6
Training loss: 2.599899722879858
Validation loss: 2.724761017985441

Epoch: 6| Step: 7
Training loss: 2.828934190175471
Validation loss: 2.723655353177949

Epoch: 6| Step: 8
Training loss: 1.9838316766838322
Validation loss: 2.722453404901532

Epoch: 6| Step: 9
Training loss: 2.877744939936661
Validation loss: 2.7189487223876343

Epoch: 6| Step: 10
Training loss: 2.9732742368986376
Validation loss: 2.7154085957612724

Epoch: 6| Step: 11
Training loss: 2.84054384692676
Validation loss: 2.710753728700596

Epoch: 6| Step: 12
Training loss: 2.9605155382462134
Validation loss: 2.7108965310877116

Epoch: 6| Step: 13
Training loss: 3.493944379008973
Validation loss: 2.7057591945437105

Epoch: 56| Step: 0
Training loss: 2.1663189633459217
Validation loss: 2.703462627398326

Epoch: 6| Step: 1
Training loss: 2.2403440972408117
Validation loss: 2.702538825481677

Epoch: 6| Step: 2
Training loss: 2.985100942467231
Validation loss: 2.7001171539933417

Epoch: 6| Step: 3
Training loss: 3.0801199243160884
Validation loss: 2.6964467780955075

Epoch: 6| Step: 4
Training loss: 2.9773653004090845
Validation loss: 2.696799475303749

Epoch: 6| Step: 5
Training loss: 2.7268388056183612
Validation loss: 2.6939690231651205

Epoch: 6| Step: 6
Training loss: 2.3793877676482724
Validation loss: 2.6929288339750697

Epoch: 6| Step: 7
Training loss: 3.129783935889435
Validation loss: 2.6920883945696383

Epoch: 6| Step: 8
Training loss: 2.9927735713367944
Validation loss: 2.6903220448823317

Epoch: 6| Step: 9
Training loss: 2.484778989178119
Validation loss: 2.695554388866642

Epoch: 6| Step: 10
Training loss: 2.55335539171669
Validation loss: 2.703822698205129

Epoch: 6| Step: 11
Training loss: 3.150497179304663
Validation loss: 2.7007013969912803

Epoch: 6| Step: 12
Training loss: 3.407816115652455
Validation loss: 2.6900602905201025

Epoch: 6| Step: 13
Training loss: 3.095783528628565
Validation loss: 2.6839209092942746

Epoch: 57| Step: 0
Training loss: 2.919252902045918
Validation loss: 2.6815497004872517

Epoch: 6| Step: 1
Training loss: 2.6231472197857904
Validation loss: 2.679187457378238

Epoch: 6| Step: 2
Training loss: 2.8585067014323737
Validation loss: 2.6792534568417627

Epoch: 6| Step: 3
Training loss: 2.5030302756075304
Validation loss: 2.67905216081111

Epoch: 6| Step: 4
Training loss: 3.565195903986381
Validation loss: 2.6776849290923153

Epoch: 6| Step: 5
Training loss: 2.6646380655743496
Validation loss: 2.678784039248915

Epoch: 6| Step: 6
Training loss: 1.8942059739086419
Validation loss: 2.67642912434946

Epoch: 6| Step: 7
Training loss: 2.3940931109149597
Validation loss: 2.6757880960270164

Epoch: 6| Step: 8
Training loss: 2.9313450714505587
Validation loss: 2.6750154387839604

Epoch: 6| Step: 9
Training loss: 3.3176528870137902
Validation loss: 2.6751071721293007

Epoch: 6| Step: 10
Training loss: 3.1241591275920313
Validation loss: 2.6758015949747382

Epoch: 6| Step: 11
Training loss: 2.589706946624844
Validation loss: 2.6731217804898955

Epoch: 6| Step: 12
Training loss: 3.263959834272421
Validation loss: 2.6738016867044587

Epoch: 6| Step: 13
Training loss: 2.4375477321548398
Validation loss: 2.6717319264317445

Epoch: 58| Step: 0
Training loss: 3.1747919209697946
Validation loss: 2.672389139005823

Epoch: 6| Step: 1
Training loss: 2.3446784659985336
Validation loss: 2.6700915059709813

Epoch: 6| Step: 2
Training loss: 2.4450256374395782
Validation loss: 2.6685278377928605

Epoch: 6| Step: 3
Training loss: 2.5133455741982234
Validation loss: 2.6657740221483994

Epoch: 6| Step: 4
Training loss: 2.9621698638201055
Validation loss: 2.6666821290601037

Epoch: 6| Step: 5
Training loss: 2.623321359777532
Validation loss: 2.663512545115504

Epoch: 6| Step: 6
Training loss: 2.3936921433909464
Validation loss: 2.6613359118310878

Epoch: 6| Step: 7
Training loss: 2.7746380853490047
Validation loss: 2.657583059267139

Epoch: 6| Step: 8
Training loss: 2.726259668360186
Validation loss: 2.660737902535569

Epoch: 6| Step: 9
Training loss: 3.248219369057306
Validation loss: 2.6630178213646487

Epoch: 6| Step: 10
Training loss: 2.54563658391582
Validation loss: 2.665379203504088

Epoch: 6| Step: 11
Training loss: 2.9559533839389314
Validation loss: 2.6729031493830546

Epoch: 6| Step: 12
Training loss: 2.8433374797377886
Validation loss: 2.667318492936154

Epoch: 6| Step: 13
Training loss: 3.527887414411725
Validation loss: 2.659541659842696

Epoch: 59| Step: 0
Training loss: 2.6698101609138063
Validation loss: 2.653968968556642

Epoch: 6| Step: 1
Training loss: 2.9730630162730267
Validation loss: 2.653904017253869

Epoch: 6| Step: 2
Training loss: 2.5924355726780037
Validation loss: 2.6571732356468356

Epoch: 6| Step: 3
Training loss: 2.215315188334832
Validation loss: 2.660469234687037

Epoch: 6| Step: 4
Training loss: 2.8658617161081748
Validation loss: 2.664839004009863

Epoch: 6| Step: 5
Training loss: 2.683912144503628
Validation loss: 2.673815686104307

Epoch: 6| Step: 6
Training loss: 2.7384031434620884
Validation loss: 2.6748150865571554

Epoch: 6| Step: 7
Training loss: 2.580732287197491
Validation loss: 2.6804693062126748

Epoch: 6| Step: 8
Training loss: 2.8647310715927294
Validation loss: 2.6800936140013074

Epoch: 6| Step: 9
Training loss: 2.700392560324961
Validation loss: 2.675188341373268

Epoch: 6| Step: 10
Training loss: 3.1619395728227664
Validation loss: 2.6693054990920984

Epoch: 6| Step: 11
Training loss: 2.7049452105207132
Validation loss: 2.661363907325292

Epoch: 6| Step: 12
Training loss: 2.913085282747999
Validation loss: 2.6573990823430966

Epoch: 6| Step: 13
Training loss: 3.383195040527663
Validation loss: 2.6520704710099854

Epoch: 60| Step: 0
Training loss: 2.4438546316864738
Validation loss: 2.651263609303735

Epoch: 6| Step: 1
Training loss: 3.2118848159678643
Validation loss: 2.6497488985514943

Epoch: 6| Step: 2
Training loss: 2.9508575938607415
Validation loss: 2.646805792289946

Epoch: 6| Step: 3
Training loss: 2.69118761301263
Validation loss: 2.6449419807988597

Epoch: 6| Step: 4
Training loss: 2.7431939606549745
Validation loss: 2.6443510083335107

Epoch: 6| Step: 5
Training loss: 2.8995050073624165
Validation loss: 2.6401155119488044

Epoch: 6| Step: 6
Training loss: 2.7297748344263635
Validation loss: 2.638659451086245

Epoch: 6| Step: 7
Training loss: 2.5956055771385516
Validation loss: 2.636068713275206

Epoch: 6| Step: 8
Training loss: 2.8079576050419006
Validation loss: 2.6350801175102503

Epoch: 6| Step: 9
Training loss: 2.7977032846834238
Validation loss: 2.6314502063011935

Epoch: 6| Step: 10
Training loss: 3.0367146422542644
Validation loss: 2.63501666102972

Epoch: 6| Step: 11
Training loss: 2.736001451965973
Validation loss: 2.6338207906326083

Epoch: 6| Step: 12
Training loss: 2.1728895274070954
Validation loss: 2.6301887939533097

Epoch: 6| Step: 13
Training loss: 2.9634319658317247
Validation loss: 2.6300929330620173

Epoch: 61| Step: 0
Training loss: 2.952667846818408
Validation loss: 2.6343208014786947

Epoch: 6| Step: 1
Training loss: 2.991094723348455
Validation loss: 2.628930434200301

Epoch: 6| Step: 2
Training loss: 2.3897204713678155
Validation loss: 2.6347460490357983

Epoch: 6| Step: 3
Training loss: 1.90101774714502
Validation loss: 2.633654224988065

Epoch: 6| Step: 4
Training loss: 3.0933868503325845
Validation loss: 2.6376784699669757

Epoch: 6| Step: 5
Training loss: 2.610212088989248
Validation loss: 2.6253806852381367

Epoch: 6| Step: 6
Training loss: 2.8268429711378875
Validation loss: 2.6259842798382786

Epoch: 6| Step: 7
Training loss: 2.940921170991221
Validation loss: 2.6240640742878827

Epoch: 6| Step: 8
Training loss: 3.0061851954464296
Validation loss: 2.6233101506967986

Epoch: 6| Step: 9
Training loss: 2.951076220736378
Validation loss: 2.625890989317285

Epoch: 6| Step: 10
Training loss: 2.6064793401207065
Validation loss: 2.6285178363783377

Epoch: 6| Step: 11
Training loss: 2.6791024417407154
Validation loss: 2.6271334712673955

Epoch: 6| Step: 12
Training loss: 3.0308664610168163
Validation loss: 2.627266631864813

Epoch: 6| Step: 13
Training loss: 2.509871828674626
Validation loss: 2.629038005850633

Epoch: 62| Step: 0
Training loss: 2.785773894961265
Validation loss: 2.6275979461949155

Epoch: 6| Step: 1
Training loss: 2.463179472306671
Validation loss: 2.626834183166391

Epoch: 6| Step: 2
Training loss: 3.347210385911485
Validation loss: 2.627306031224722

Epoch: 6| Step: 3
Training loss: 2.1330777516847963
Validation loss: 2.626640564051377

Epoch: 6| Step: 4
Training loss: 2.637469511172268
Validation loss: 2.6230864892289354

Epoch: 6| Step: 5
Training loss: 2.589839515279815
Validation loss: 2.6233749127718116

Epoch: 6| Step: 6
Training loss: 2.7466981312267413
Validation loss: 2.621151039949028

Epoch: 6| Step: 7
Training loss: 2.189901396216868
Validation loss: 2.620620358844568

Epoch: 6| Step: 8
Training loss: 2.9251527404030546
Validation loss: 2.6183388981394775

Epoch: 6| Step: 9
Training loss: 3.1783561449944258
Validation loss: 2.616243706574262

Epoch: 6| Step: 10
Training loss: 2.89922772351919
Validation loss: 2.6148407392709596

Epoch: 6| Step: 11
Training loss: 2.8700763171213888
Validation loss: 2.6142955535531787

Epoch: 6| Step: 12
Training loss: 2.6581850072283926
Validation loss: 2.6111175596775302

Epoch: 6| Step: 13
Training loss: 2.975067323836532
Validation loss: 2.6103044023498176

Epoch: 63| Step: 0
Training loss: 2.643122558448297
Validation loss: 2.612100727045496

Epoch: 6| Step: 1
Training loss: 2.363340670256352
Validation loss: 2.6106018106290487

Epoch: 6| Step: 2
Training loss: 2.8880415635644816
Validation loss: 2.612392683121709

Epoch: 6| Step: 3
Training loss: 2.9014478817981577
Validation loss: 2.609841737102183

Epoch: 6| Step: 4
Training loss: 2.763645562899259
Validation loss: 2.6098315054728767

Epoch: 6| Step: 5
Training loss: 2.9858433172123093
Validation loss: 2.6057531534255345

Epoch: 6| Step: 6
Training loss: 2.985359389045596
Validation loss: 2.60712321996292

Epoch: 6| Step: 7
Training loss: 2.361012679896868
Validation loss: 2.605502195586848

Epoch: 6| Step: 8
Training loss: 2.7485901079429675
Validation loss: 2.607726560547591

Epoch: 6| Step: 9
Training loss: 2.3373504754043726
Validation loss: 2.602058798616026

Epoch: 6| Step: 10
Training loss: 3.2508790221267705
Validation loss: 2.604049883449151

Epoch: 6| Step: 11
Training loss: 2.5101096782050485
Validation loss: 2.599553505755495

Epoch: 6| Step: 12
Training loss: 2.638276449599571
Validation loss: 2.6030570959765247

Epoch: 6| Step: 13
Training loss: 2.8307582335513657
Validation loss: 2.5983262041869697

Epoch: 64| Step: 0
Training loss: 2.793043527735855
Validation loss: 2.5983034785596444

Epoch: 6| Step: 1
Training loss: 3.110364133608819
Validation loss: 2.5976901327041104

Epoch: 6| Step: 2
Training loss: 3.2213915013478345
Validation loss: 2.598174522918381

Epoch: 6| Step: 3
Training loss: 2.583349863635264
Validation loss: 2.596637313743794

Epoch: 6| Step: 4
Training loss: 2.9296429033064
Validation loss: 2.5937361506203422

Epoch: 6| Step: 5
Training loss: 2.6916007759209903
Validation loss: 2.5942441477255413

Epoch: 6| Step: 6
Training loss: 3.0457714723357587
Validation loss: 2.592262025098697

Epoch: 6| Step: 7
Training loss: 2.5044835893485917
Validation loss: 2.593162102313176

Epoch: 6| Step: 8
Training loss: 2.6304033163082257
Validation loss: 2.590767106536652

Epoch: 6| Step: 9
Training loss: 2.2673863371736966
Validation loss: 2.589165477435237

Epoch: 6| Step: 10
Training loss: 2.582335576808328
Validation loss: 2.589604845722321

Epoch: 6| Step: 11
Training loss: 2.5538355722155117
Validation loss: 2.590474937396755

Epoch: 6| Step: 12
Training loss: 2.5116984365066015
Validation loss: 2.584680395751901

Epoch: 6| Step: 13
Training loss: 2.57452733414557
Validation loss: 2.585397377731171

Epoch: 65| Step: 0
Training loss: 2.608323667790681
Validation loss: 2.590007318439724

Epoch: 6| Step: 1
Training loss: 2.6294873347857806
Validation loss: 2.601440319900018

Epoch: 6| Step: 2
Training loss: 2.918857913911954
Validation loss: 2.5923351427447745

Epoch: 6| Step: 3
Training loss: 2.863038431360683
Validation loss: 2.589322182910586

Epoch: 6| Step: 4
Training loss: 3.040505348666329
Validation loss: 2.5883167918803136

Epoch: 6| Step: 5
Training loss: 2.150103890326413
Validation loss: 2.5820048874794748

Epoch: 6| Step: 6
Training loss: 2.2952823436981515
Validation loss: 2.582990105705889

Epoch: 6| Step: 7
Training loss: 2.554478254702427
Validation loss: 2.5810406314401204

Epoch: 6| Step: 8
Training loss: 2.655117736045003
Validation loss: 2.5807674391006814

Epoch: 6| Step: 9
Training loss: 2.843492098002273
Validation loss: 2.580222592386931

Epoch: 6| Step: 10
Training loss: 2.869693502880765
Validation loss: 2.5798682590235567

Epoch: 6| Step: 11
Training loss: 2.4456882370948194
Validation loss: 2.5787037517710703

Epoch: 6| Step: 12
Training loss: 3.0716580846966393
Validation loss: 2.5807981870001213

Epoch: 6| Step: 13
Training loss: 3.094721323757005
Validation loss: 2.580150402056843

Epoch: 66| Step: 0
Training loss: 3.188313099992531
Validation loss: 2.5771122956762196

Epoch: 6| Step: 1
Training loss: 3.0513166868680757
Validation loss: 2.5783581406727984

Epoch: 6| Step: 2
Training loss: 2.8824556951765556
Validation loss: 2.5722680812351837

Epoch: 6| Step: 3
Training loss: 2.655088642027133
Validation loss: 2.5761357811748424

Epoch: 6| Step: 4
Training loss: 2.752350409632608
Validation loss: 2.573880942856364

Epoch: 6| Step: 5
Training loss: 2.334733633658606
Validation loss: 2.5726506846059096

Epoch: 6| Step: 6
Training loss: 2.828922559706419
Validation loss: 2.573492878833556

Epoch: 6| Step: 7
Training loss: 2.646547976922548
Validation loss: 2.5734401793196717

Epoch: 6| Step: 8
Training loss: 2.5857711692400107
Validation loss: 2.573097042499847

Epoch: 6| Step: 9
Training loss: 2.5046213351890794
Validation loss: 2.5707122275475305

Epoch: 6| Step: 10
Training loss: 2.867250530163377
Validation loss: 2.571392122456914

Epoch: 6| Step: 11
Training loss: 2.6157192381878684
Validation loss: 2.5692975514897505

Epoch: 6| Step: 12
Training loss: 2.4328413239463895
Validation loss: 2.570446223497519

Epoch: 6| Step: 13
Training loss: 2.346274173796982
Validation loss: 2.568654121533961

Epoch: 67| Step: 0
Training loss: 2.8079166789992884
Validation loss: 2.5730896761612065

Epoch: 6| Step: 1
Training loss: 2.6534436828663446
Validation loss: 2.5736124253708548

Epoch: 6| Step: 2
Training loss: 2.354545247743061
Validation loss: 2.5701371493524476

Epoch: 6| Step: 3
Training loss: 3.2992887655277165
Validation loss: 2.5742820149251413

Epoch: 6| Step: 4
Training loss: 2.493798766460048
Validation loss: 2.574237582225152

Epoch: 6| Step: 5
Training loss: 2.4563390972877213
Validation loss: 2.5767729479529478

Epoch: 6| Step: 6
Training loss: 2.87944847601081
Validation loss: 2.579212722202781

Epoch: 6| Step: 7
Training loss: 2.7211174139439023
Validation loss: 2.5663410025575875

Epoch: 6| Step: 8
Training loss: 1.9776131472426792
Validation loss: 2.563817654638759

Epoch: 6| Step: 9
Training loss: 2.3404012534913217
Validation loss: 2.56202528983704

Epoch: 6| Step: 10
Training loss: 2.894357282221467
Validation loss: 2.564093466507227

Epoch: 6| Step: 11
Training loss: 2.685073466796528
Validation loss: 2.5620972696809226

Epoch: 6| Step: 12
Training loss: 3.139200523307982
Validation loss: 2.5637891209502155

Epoch: 6| Step: 13
Training loss: 2.8969977985514612
Validation loss: 2.567630810499097

Epoch: 68| Step: 0
Training loss: 2.8780448380530403
Validation loss: 2.565003614181441

Epoch: 6| Step: 1
Training loss: 2.5845724231080327
Validation loss: 2.5665128967329736

Epoch: 6| Step: 2
Training loss: 2.536968600249105
Validation loss: 2.5686316129531965

Epoch: 6| Step: 3
Training loss: 2.554521934440493
Validation loss: 2.569213446695345

Epoch: 6| Step: 4
Training loss: 2.8761116863948777
Validation loss: 2.567853530172829

Epoch: 6| Step: 5
Training loss: 2.777915327057421
Validation loss: 2.565829385909484

Epoch: 6| Step: 6
Training loss: 2.457838644481596
Validation loss: 2.5616746131419634

Epoch: 6| Step: 7
Training loss: 2.493996851278977
Validation loss: 2.5626624141178844

Epoch: 6| Step: 8
Training loss: 2.8989073174653077
Validation loss: 2.5604012431173433

Epoch: 6| Step: 9
Training loss: 2.493027500666527
Validation loss: 2.5607562761498923

Epoch: 6| Step: 10
Training loss: 3.5553959737834417
Validation loss: 2.556476942339767

Epoch: 6| Step: 11
Training loss: 2.6130002359652202
Validation loss: 2.5552735040572285

Epoch: 6| Step: 12
Training loss: 2.6176861188385927
Validation loss: 2.5566598664665388

Epoch: 6| Step: 13
Training loss: 2.131866357003538
Validation loss: 2.5550613129830606

Epoch: 69| Step: 0
Training loss: 2.9152947241844043
Validation loss: 2.552182259231766

Epoch: 6| Step: 1
Training loss: 2.5040123213321657
Validation loss: 2.5509949264097087

Epoch: 6| Step: 2
Training loss: 2.92438354517028
Validation loss: 2.5555594508744925

Epoch: 6| Step: 3
Training loss: 2.453126069086899
Validation loss: 2.5610749694037565

Epoch: 6| Step: 4
Training loss: 2.5836711067959173
Validation loss: 2.553540266763368

Epoch: 6| Step: 5
Training loss: 2.761656160198417
Validation loss: 2.560558126052902

Epoch: 6| Step: 6
Training loss: 3.065738600435257
Validation loss: 2.578484311737432

Epoch: 6| Step: 7
Training loss: 2.0618770699029567
Validation loss: 2.564477250740357

Epoch: 6| Step: 8
Training loss: 2.486500149010217
Validation loss: 2.5662264516585864

Epoch: 6| Step: 9
Training loss: 2.8457265838514885
Validation loss: 2.559861678047286

Epoch: 6| Step: 10
Training loss: 2.8305326719381245
Validation loss: 2.558893410410024

Epoch: 6| Step: 11
Training loss: 3.020484606027487
Validation loss: 2.5603234266081105

Epoch: 6| Step: 12
Training loss: 2.648704942911398
Validation loss: 2.5643253493114275

Epoch: 6| Step: 13
Training loss: 2.35771959853632
Validation loss: 2.555171457971373

Epoch: 70| Step: 0
Training loss: 2.6583825918993167
Validation loss: 2.5541536199123436

Epoch: 6| Step: 1
Training loss: 2.672615350244732
Validation loss: 2.549634970923256

Epoch: 6| Step: 2
Training loss: 2.2568574885383827
Validation loss: 2.5476469496551677

Epoch: 6| Step: 3
Training loss: 2.907178668882457
Validation loss: 2.5486860330663927

Epoch: 6| Step: 4
Training loss: 2.7907487489403113
Validation loss: 2.551865040272836

Epoch: 6| Step: 5
Training loss: 2.9864814075278896
Validation loss: 2.5478277316184603

Epoch: 6| Step: 6
Training loss: 2.4205334300896655
Validation loss: 2.551000518487738

Epoch: 6| Step: 7
Training loss: 2.6938391155185664
Validation loss: 2.5514806126545655

Epoch: 6| Step: 8
Training loss: 2.2201404781400167
Validation loss: 2.5477627258292395

Epoch: 6| Step: 9
Training loss: 3.034493824511115
Validation loss: 2.5485444477404675

Epoch: 6| Step: 10
Training loss: 2.9849638832245984
Validation loss: 2.5454184456841573

Epoch: 6| Step: 11
Training loss: 2.6007645216564557
Validation loss: 2.54838570254272

Epoch: 6| Step: 12
Training loss: 2.7439844053064406
Validation loss: 2.5464640092686346

Epoch: 6| Step: 13
Training loss: 2.4163183640914347
Validation loss: 2.544756704666205

Epoch: 71| Step: 0
Training loss: 2.4851777321331623
Validation loss: 2.5415142566031634

Epoch: 6| Step: 1
Training loss: 3.026341662525466
Validation loss: 2.5420663759042905

Epoch: 6| Step: 2
Training loss: 2.9223580190663774
Validation loss: 2.5441797813488174

Epoch: 6| Step: 3
Training loss: 2.956358093479185
Validation loss: 2.5354380634651497

Epoch: 6| Step: 4
Training loss: 2.572535240740125
Validation loss: 2.5451411174529066

Epoch: 6| Step: 5
Training loss: 3.0451866754145893
Validation loss: 2.54620817539308

Epoch: 6| Step: 6
Training loss: 2.20953281383919
Validation loss: 2.5567315621907785

Epoch: 6| Step: 7
Training loss: 2.4404685699308466
Validation loss: 2.5591078535365224

Epoch: 6| Step: 8
Training loss: 2.5697189619719247
Validation loss: 2.566586624069909

Epoch: 6| Step: 9
Training loss: 2.570024375651498
Validation loss: 2.5710793600546156

Epoch: 6| Step: 10
Training loss: 2.7995946863277985
Validation loss: 2.5617382809273606

Epoch: 6| Step: 11
Training loss: 3.0374359249687912
Validation loss: 2.555643849529193

Epoch: 6| Step: 12
Training loss: 2.5748699562789663
Validation loss: 2.553067112441124

Epoch: 6| Step: 13
Training loss: 2.237647161492611
Validation loss: 2.5484892988992525

Epoch: 72| Step: 0
Training loss: 2.858352561715477
Validation loss: 2.553333860995717

Epoch: 6| Step: 1
Training loss: 2.716325577774177
Validation loss: 2.5509253904656584

Epoch: 6| Step: 2
Training loss: 3.00729785826499
Validation loss: 2.5499077275355106

Epoch: 6| Step: 3
Training loss: 2.578399551106792
Validation loss: 2.550741805842136

Epoch: 6| Step: 4
Training loss: 2.5587959500851887
Validation loss: 2.5482952315993863

Epoch: 6| Step: 5
Training loss: 2.762917610467059
Validation loss: 2.547888150579328

Epoch: 6| Step: 6
Training loss: 2.4778560304853268
Validation loss: 2.544950495315252

Epoch: 6| Step: 7
Training loss: 2.6610974230731705
Validation loss: 2.5499084287919045

Epoch: 6| Step: 8
Training loss: 2.724401891321431
Validation loss: 2.550119373544259

Epoch: 6| Step: 9
Training loss: 1.9958033639758879
Validation loss: 2.5494529922799067

Epoch: 6| Step: 10
Training loss: 2.7073653814464693
Validation loss: 2.546892645839106

Epoch: 6| Step: 11
Training loss: 3.0772790666199614
Validation loss: 2.54710598543706

Epoch: 6| Step: 12
Training loss: 2.790998881925812
Validation loss: 2.547178472681468

Epoch: 6| Step: 13
Training loss: 2.414276508610411
Validation loss: 2.5453863571501354

Epoch: 73| Step: 0
Training loss: 2.9230905544102166
Validation loss: 2.544519798152313

Epoch: 6| Step: 1
Training loss: 2.7481190577762256
Validation loss: 2.5472429941879544

Epoch: 6| Step: 2
Training loss: 2.629377711108573
Validation loss: 2.5472840992761148

Epoch: 6| Step: 3
Training loss: 2.703920368641583
Validation loss: 2.5443603879902104

Epoch: 6| Step: 4
Training loss: 1.9095127137213634
Validation loss: 2.5452287810443774

Epoch: 6| Step: 5
Training loss: 2.6892726286336543
Validation loss: 2.5465485065153906

Epoch: 6| Step: 6
Training loss: 2.5965617921713253
Validation loss: 2.544233157224814

Epoch: 6| Step: 7
Training loss: 2.7862780266058573
Validation loss: 2.545785136372741

Epoch: 6| Step: 8
Training loss: 2.9090615075966455
Validation loss: 2.544328473523986

Epoch: 6| Step: 9
Training loss: 3.068560772750713
Validation loss: 2.5423592629579796

Epoch: 6| Step: 10
Training loss: 2.4035684084726534
Validation loss: 2.5416649573481913

Epoch: 6| Step: 11
Training loss: 2.453035389423711
Validation loss: 2.544037859326085

Epoch: 6| Step: 12
Training loss: 2.574461397303532
Validation loss: 2.54566781858177

Epoch: 6| Step: 13
Training loss: 2.7576967382584723
Validation loss: 2.541114470943863

Epoch: 74| Step: 0
Training loss: 2.314446532163606
Validation loss: 2.543601602385628

Epoch: 6| Step: 1
Training loss: 2.417014579283904
Validation loss: 2.5375722571046246

Epoch: 6| Step: 2
Training loss: 2.75101772896404
Validation loss: 2.53765365248132

Epoch: 6| Step: 3
Training loss: 2.1599277699720845
Validation loss: 2.5395640498976415

Epoch: 6| Step: 4
Training loss: 2.7995256192397204
Validation loss: 2.539139340533989

Epoch: 6| Step: 5
Training loss: 2.6901847381687514
Validation loss: 2.5357453730038046

Epoch: 6| Step: 6
Training loss: 2.975658209298315
Validation loss: 2.5322186692665656

Epoch: 6| Step: 7
Training loss: 2.523561267947243
Validation loss: 2.532562402280887

Epoch: 6| Step: 8
Training loss: 3.0086180561899556
Validation loss: 2.539598566833154

Epoch: 6| Step: 9
Training loss: 2.885849425619541
Validation loss: 2.5351150579882504

Epoch: 6| Step: 10
Training loss: 2.66337894384728
Validation loss: 2.5348482968636183

Epoch: 6| Step: 11
Training loss: 2.755428072286001
Validation loss: 2.5293838152187083

Epoch: 6| Step: 12
Training loss: 2.174888879853284
Validation loss: 2.5277296004635645

Epoch: 6| Step: 13
Training loss: 2.8748712925504107
Validation loss: 2.5218034931871545

Epoch: 75| Step: 0
Training loss: 2.747379007634472
Validation loss: 2.5202699509852575

Epoch: 6| Step: 1
Training loss: 2.217017988697212
Validation loss: 2.5195547176717152

Epoch: 6| Step: 2
Training loss: 2.961823424006758
Validation loss: 2.5198416742916425

Epoch: 6| Step: 3
Training loss: 3.0916980142023816
Validation loss: 2.5171850828399513

Epoch: 6| Step: 4
Training loss: 2.0948676926525067
Validation loss: 2.5178519396742653

Epoch: 6| Step: 5
Training loss: 2.8212198504458246
Validation loss: 2.521439571361767

Epoch: 6| Step: 6
Training loss: 2.830952448082741
Validation loss: 2.520777368055647

Epoch: 6| Step: 7
Training loss: 2.169731564421163
Validation loss: 2.514568304371478

Epoch: 6| Step: 8
Training loss: 2.861887010797813
Validation loss: 2.5220207906476633

Epoch: 6| Step: 9
Training loss: 2.2244631859066812
Validation loss: 2.519545302240973

Epoch: 6| Step: 10
Training loss: 2.7503200691534224
Validation loss: 2.522426753170016

Epoch: 6| Step: 11
Training loss: 2.9361013775819247
Validation loss: 2.5162179220510725

Epoch: 6| Step: 12
Training loss: 2.5504166954508767
Validation loss: 2.5194811438967535

Epoch: 6| Step: 13
Training loss: 2.3983351098487677
Validation loss: 2.521809811795425

Epoch: 76| Step: 0
Training loss: 2.7576910321769144
Validation loss: 2.5194894397824923

Epoch: 6| Step: 1
Training loss: 2.653371530318601
Validation loss: 2.51940494191181

Epoch: 6| Step: 2
Training loss: 3.029006127498319
Validation loss: 2.5211097681312724

Epoch: 6| Step: 3
Training loss: 2.4064854098015824
Validation loss: 2.519899373921616

Epoch: 6| Step: 4
Training loss: 3.009026299830443
Validation loss: 2.521475281958777

Epoch: 6| Step: 5
Training loss: 2.970690123399803
Validation loss: 2.519927852672606

Epoch: 6| Step: 6
Training loss: 2.5573016216345876
Validation loss: 2.514835510208806

Epoch: 6| Step: 7
Training loss: 2.3782393800195
Validation loss: 2.5179556560343577

Epoch: 6| Step: 8
Training loss: 2.599415944596255
Validation loss: 2.5173109103638045

Epoch: 6| Step: 9
Training loss: 2.773665383876117
Validation loss: 2.516161772521463

Epoch: 6| Step: 10
Training loss: 2.6690333017249057
Validation loss: 2.5158624872609843

Epoch: 6| Step: 11
Training loss: 2.0881784809825814
Validation loss: 2.5177935618341367

Epoch: 6| Step: 12
Training loss: 2.4120139902382873
Validation loss: 2.5198729290789315

Epoch: 6| Step: 13
Training loss: 2.3060271943764263
Validation loss: 2.5202934117785705

Epoch: 77| Step: 0
Training loss: 2.566630500274429
Validation loss: 2.5152110436448427

Epoch: 6| Step: 1
Training loss: 2.536878567975287
Validation loss: 2.515937390883199

Epoch: 6| Step: 2
Training loss: 3.0144970617667535
Validation loss: 2.517506971554793

Epoch: 6| Step: 3
Training loss: 2.6166357569073635
Validation loss: 2.509266527871019

Epoch: 6| Step: 4
Training loss: 2.57633021911375
Validation loss: 2.518127286810084

Epoch: 6| Step: 5
Training loss: 2.8954215180016085
Validation loss: 2.5172148393835014

Epoch: 6| Step: 6
Training loss: 2.526664064686156
Validation loss: 2.5181422936893556

Epoch: 6| Step: 7
Training loss: 2.6509657413624645
Validation loss: 2.511233649269447

Epoch: 6| Step: 8
Training loss: 2.567835022520111
Validation loss: 2.513390221731912

Epoch: 6| Step: 9
Training loss: 2.1859781693662454
Validation loss: 2.5066084303415006

Epoch: 6| Step: 10
Training loss: 2.52787442657188
Validation loss: 2.512220982104121

Epoch: 6| Step: 11
Training loss: 2.9260791581059378
Validation loss: 2.5152396781681032

Epoch: 6| Step: 12
Training loss: 2.0856517353121884
Validation loss: 2.5098559649049768

Epoch: 6| Step: 13
Training loss: 2.8943202138718593
Validation loss: 2.512756402263557

Epoch: 78| Step: 0
Training loss: 2.5736988335628097
Validation loss: 2.5092777238093213

Epoch: 6| Step: 1
Training loss: 2.7126670399225965
Validation loss: 2.5082052364992995

Epoch: 6| Step: 2
Training loss: 2.3272173859711005
Validation loss: 2.5114272182271757

Epoch: 6| Step: 3
Training loss: 1.9596842374243728
Validation loss: 2.5090129985480214

Epoch: 6| Step: 4
Training loss: 2.9269495669895296
Validation loss: 2.511646829369401

Epoch: 6| Step: 5
Training loss: 2.3174968037176877
Validation loss: 2.51189300581278

Epoch: 6| Step: 6
Training loss: 2.2770400196457055
Validation loss: 2.512727533858598

Epoch: 6| Step: 7
Training loss: 2.5195699526157767
Validation loss: 2.509493097334694

Epoch: 6| Step: 8
Training loss: 3.2220573839870648
Validation loss: 2.5079770771978676

Epoch: 6| Step: 9
Training loss: 2.7008258545546506
Validation loss: 2.5088535101089002

Epoch: 6| Step: 10
Training loss: 2.5414030115509743
Validation loss: 2.50868569578519

Epoch: 6| Step: 11
Training loss: 2.720510855273264
Validation loss: 2.503350904972801

Epoch: 6| Step: 12
Training loss: 2.979561163829987
Validation loss: 2.5096589734959407

Epoch: 6| Step: 13
Training loss: 2.656808592460634
Validation loss: 2.5104617250654093

Epoch: 79| Step: 0
Training loss: 3.0978946858600884
Validation loss: 2.5082065672752556

Epoch: 6| Step: 1
Training loss: 2.4194022075568897
Validation loss: 2.5075309175440634

Epoch: 6| Step: 2
Training loss: 2.385311529738325
Validation loss: 2.502537599777183

Epoch: 6| Step: 3
Training loss: 2.7509410288462117
Validation loss: 2.5004429345344845

Epoch: 6| Step: 4
Training loss: 2.4778355356031607
Validation loss: 2.50681417366847

Epoch: 6| Step: 5
Training loss: 2.9943914439037074
Validation loss: 2.5037528321809916

Epoch: 6| Step: 6
Training loss: 2.403655498866813
Validation loss: 2.5094544768267197

Epoch: 6| Step: 7
Training loss: 2.52084529232835
Validation loss: 2.5075723329065105

Epoch: 6| Step: 8
Training loss: 2.092773779274062
Validation loss: 2.5028124486737693

Epoch: 6| Step: 9
Training loss: 2.7215856036954245
Validation loss: 2.5044558076234984

Epoch: 6| Step: 10
Training loss: 2.5954799168632245
Validation loss: 2.5061624075660234

Epoch: 6| Step: 11
Training loss: 2.784610561078097
Validation loss: 2.4998709963257446

Epoch: 6| Step: 12
Training loss: 2.9195057448043005
Validation loss: 2.50200490031892

Epoch: 6| Step: 13
Training loss: 2.30526984664636
Validation loss: 2.5065644546562678

Epoch: 80| Step: 0
Training loss: 2.56038494747453
Validation loss: 2.50985924215902

Epoch: 6| Step: 1
Training loss: 2.851967811520533
Validation loss: 2.5056260858388937

Epoch: 6| Step: 2
Training loss: 2.8636149671231363
Validation loss: 2.5079539289831336

Epoch: 6| Step: 3
Training loss: 2.4476080409080465
Validation loss: 2.509657374322214

Epoch: 6| Step: 4
Training loss: 2.7108726823516913
Validation loss: 2.505323305617819

Epoch: 6| Step: 5
Training loss: 2.6961047791062263
Validation loss: 2.5040625624087576

Epoch: 6| Step: 6
Training loss: 2.507697842552698
Validation loss: 2.50964752592294

Epoch: 6| Step: 7
Training loss: 2.7042338131256782
Validation loss: 2.5060635624999126

Epoch: 6| Step: 8
Training loss: 2.4205172763043223
Validation loss: 2.5046995496231976

Epoch: 6| Step: 9
Training loss: 2.3051242220622696
Validation loss: 2.5026223892887525

Epoch: 6| Step: 10
Training loss: 2.713516020455347
Validation loss: 2.4969892651540158

Epoch: 6| Step: 11
Training loss: 2.331553143384213
Validation loss: 2.5102107700949534

Epoch: 6| Step: 12
Training loss: 2.8904752125464945
Validation loss: 2.500416673269231

Epoch: 6| Step: 13
Training loss: 2.613106349685999
Validation loss: 2.501830122557348

Epoch: 81| Step: 0
Training loss: 2.6468020090174793
Validation loss: 2.500622496987822

Epoch: 6| Step: 1
Training loss: 2.7130288623718593
Validation loss: 2.4973837196180946

Epoch: 6| Step: 2
Training loss: 2.5057199845231355
Validation loss: 2.5009846020000452

Epoch: 6| Step: 3
Training loss: 2.5723453355863195
Validation loss: 2.5052740414911825

Epoch: 6| Step: 4
Training loss: 2.324738772904098
Validation loss: 2.5063475611240973

Epoch: 6| Step: 5
Training loss: 3.0242349524176055
Validation loss: 2.516819514334063

Epoch: 6| Step: 6
Training loss: 2.3363689929912894
Validation loss: 2.518927939087555

Epoch: 6| Step: 7
Training loss: 2.393944125359194
Validation loss: 2.5245224752948707

Epoch: 6| Step: 8
Training loss: 3.107398703804637
Validation loss: 2.5343493572024394

Epoch: 6| Step: 9
Training loss: 2.843890176189741
Validation loss: 2.5413137305518716

Epoch: 6| Step: 10
Training loss: 2.79939931829561
Validation loss: 2.5456421097167095

Epoch: 6| Step: 11
Training loss: 2.7644236913571905
Validation loss: 2.5302557228731493

Epoch: 6| Step: 12
Training loss: 2.2141183139439704
Validation loss: 2.5250674437023184

Epoch: 6| Step: 13
Training loss: 2.7079322713611758
Validation loss: 2.5101730946081413

Epoch: 82| Step: 0
Training loss: 3.0253260034859326
Validation loss: 2.509664325178823

Epoch: 6| Step: 1
Training loss: 2.729444145093745
Validation loss: 2.504582591962369

Epoch: 6| Step: 2
Training loss: 2.6754025379238167
Validation loss: 2.502250246763781

Epoch: 6| Step: 3
Training loss: 2.327445936056542
Validation loss: 2.4983855279666405

Epoch: 6| Step: 4
Training loss: 2.5440650838527907
Validation loss: 2.4983815278953965

Epoch: 6| Step: 5
Training loss: 2.7009307246160175
Validation loss: 2.506164976153884

Epoch: 6| Step: 6
Training loss: 2.773524495224506
Validation loss: 2.5014720556495362

Epoch: 6| Step: 7
Training loss: 1.8966363596492102
Validation loss: 2.4981847212524997

Epoch: 6| Step: 8
Training loss: 2.4624481892823455
Validation loss: 2.500600615514961

Epoch: 6| Step: 9
Training loss: 3.070610517253765
Validation loss: 2.500523877885254

Epoch: 6| Step: 10
Training loss: 2.403988456622193
Validation loss: 2.509584001235666

Epoch: 6| Step: 11
Training loss: 2.550010202424826
Validation loss: 2.510043442288134

Epoch: 6| Step: 12
Training loss: 2.6546766221405664
Validation loss: 2.507569559754575

Epoch: 6| Step: 13
Training loss: 2.664294459293175
Validation loss: 2.5073922538998543

Epoch: 83| Step: 0
Training loss: 2.3175713887993603
Validation loss: 2.515803763156948

Epoch: 6| Step: 1
Training loss: 2.4416320208108404
Validation loss: 2.512311344433978

Epoch: 6| Step: 2
Training loss: 2.554382305988852
Validation loss: 2.5183404834106384

Epoch: 6| Step: 3
Training loss: 2.4298957171257283
Validation loss: 2.506799257488353

Epoch: 6| Step: 4
Training loss: 2.5845889352355136
Validation loss: 2.5061661336031094

Epoch: 6| Step: 5
Training loss: 2.9538066420449507
Validation loss: 2.498889231286262

Epoch: 6| Step: 6
Training loss: 2.4035243661152097
Validation loss: 2.4985316414876992

Epoch: 6| Step: 7
Training loss: 2.6910722633278796
Validation loss: 2.4998493387601037

Epoch: 6| Step: 8
Training loss: 3.3834897391962904
Validation loss: 2.4997389657118196

Epoch: 6| Step: 9
Training loss: 2.6601843923460904
Validation loss: 2.494350758072096

Epoch: 6| Step: 10
Training loss: 2.7168865614127964
Validation loss: 2.493299995299781

Epoch: 6| Step: 11
Training loss: 2.585515751401377
Validation loss: 2.497645302339755

Epoch: 6| Step: 12
Training loss: 2.4280839639188434
Validation loss: 2.495578018104179

Epoch: 6| Step: 13
Training loss: 2.127949630972972
Validation loss: 2.4946182498640814

Epoch: 84| Step: 0
Training loss: 2.7023173101256064
Validation loss: 2.5006626999210932

Epoch: 6| Step: 1
Training loss: 1.7843946839965497
Validation loss: 2.499843274608101

Epoch: 6| Step: 2
Training loss: 3.0113924198508983
Validation loss: 2.5066753752621413

Epoch: 6| Step: 3
Training loss: 2.148114655253075
Validation loss: 2.5010484563207607

Epoch: 6| Step: 4
Training loss: 2.4420684648768543
Validation loss: 2.499110985678673

Epoch: 6| Step: 5
Training loss: 2.538809895787923
Validation loss: 2.500582213953836

Epoch: 6| Step: 6
Training loss: 2.4309489909649655
Validation loss: 2.499336822286867

Epoch: 6| Step: 7
Training loss: 3.0052250818130744
Validation loss: 2.4999529675192185

Epoch: 6| Step: 8
Training loss: 2.759801217812765
Validation loss: 2.501664052915722

Epoch: 6| Step: 9
Training loss: 2.6467362512750445
Validation loss: 2.4985670433472285

Epoch: 6| Step: 10
Training loss: 2.779642133251425
Validation loss: 2.4955801835953304

Epoch: 6| Step: 11
Training loss: 3.147279133459359
Validation loss: 2.4980826813987664

Epoch: 6| Step: 12
Training loss: 2.5192136579146345
Validation loss: 2.495581871403307

Epoch: 6| Step: 13
Training loss: 2.2719567579331725
Validation loss: 2.4920052329192677

Epoch: 85| Step: 0
Training loss: 2.240459773357405
Validation loss: 2.4935716155712524

Epoch: 6| Step: 1
Training loss: 1.9749587718668282
Validation loss: 2.4903636624552172

Epoch: 6| Step: 2
Training loss: 3.2079492479433602
Validation loss: 2.486294099145898

Epoch: 6| Step: 3
Training loss: 2.6084929477332355
Validation loss: 2.4945709406953376

Epoch: 6| Step: 4
Training loss: 2.5941332798161523
Validation loss: 2.4961015823551804

Epoch: 6| Step: 5
Training loss: 2.8532913610752275
Validation loss: 2.485099350998321

Epoch: 6| Step: 6
Training loss: 3.080495628260956
Validation loss: 2.4856666230344144

Epoch: 6| Step: 7
Training loss: 2.5890149938061535
Validation loss: 2.4950608736714237

Epoch: 6| Step: 8
Training loss: 2.247147553404097
Validation loss: 2.4984927879261467

Epoch: 6| Step: 9
Training loss: 2.415896610915158
Validation loss: 2.495505194408728

Epoch: 6| Step: 10
Training loss: 2.5295594774994954
Validation loss: 2.4885879080111377

Epoch: 6| Step: 11
Training loss: 2.902501139217551
Validation loss: 2.494340514694426

Epoch: 6| Step: 12
Training loss: 2.560010119060544
Validation loss: 2.5007513665564156

Epoch: 6| Step: 13
Training loss: 2.7179534446765636
Validation loss: 2.5020087119564987

Epoch: 86| Step: 0
Training loss: 2.3447775050757644
Validation loss: 2.508059179546792

Epoch: 6| Step: 1
Training loss: 2.7605001952771167
Validation loss: 2.5101027444122885

Epoch: 6| Step: 2
Training loss: 2.702452471206637
Validation loss: 2.5137489226022947

Epoch: 6| Step: 3
Training loss: 2.6242197784576264
Validation loss: 2.511473940897454

Epoch: 6| Step: 4
Training loss: 2.7875966726740034
Validation loss: 2.516593043932537

Epoch: 6| Step: 5
Training loss: 2.4084686355686813
Validation loss: 2.5134935372576024

Epoch: 6| Step: 6
Training loss: 2.5529771031250577
Validation loss: 2.508477872399506

Epoch: 6| Step: 7
Training loss: 2.3978819560950475
Validation loss: 2.505627544855665

Epoch: 6| Step: 8
Training loss: 2.889640681754969
Validation loss: 2.5081149797249713

Epoch: 6| Step: 9
Training loss: 2.8082616447860005
Validation loss: 2.501988351391765

Epoch: 6| Step: 10
Training loss: 2.801589657619434
Validation loss: 2.495516348585832

Epoch: 6| Step: 11
Training loss: 3.117122333964046
Validation loss: 2.493875137414502

Epoch: 6| Step: 12
Training loss: 2.166727456438257
Validation loss: 2.491981410132231

Epoch: 6| Step: 13
Training loss: 2.2577073227827116
Validation loss: 2.4863686469632347

Epoch: 87| Step: 0
Training loss: 2.316962807295496
Validation loss: 2.486157255851479

Epoch: 6| Step: 1
Training loss: 2.6832479506783073
Validation loss: 2.4881152901631296

Epoch: 6| Step: 2
Training loss: 2.8533204395086047
Validation loss: 2.4887152133198454

Epoch: 6| Step: 3
Training loss: 2.342414068317118
Validation loss: 2.485100981965112

Epoch: 6| Step: 4
Training loss: 2.508912032615401
Validation loss: 2.4845353560608383

Epoch: 6| Step: 5
Training loss: 2.6821886851470222
Validation loss: 2.4866446757771734

Epoch: 6| Step: 6
Training loss: 2.333842789573212
Validation loss: 2.482444012751039

Epoch: 6| Step: 7
Training loss: 2.392016136963421
Validation loss: 2.4820881040675733

Epoch: 6| Step: 8
Training loss: 2.997553463571213
Validation loss: 2.492106277912107

Epoch: 6| Step: 9
Training loss: 2.988540697989579
Validation loss: 2.4948311618766006

Epoch: 6| Step: 10
Training loss: 2.626871077947346
Validation loss: 2.4963653368945047

Epoch: 6| Step: 11
Training loss: 2.2596096819167277
Validation loss: 2.495578018104179

Epoch: 6| Step: 12
Training loss: 2.5792144323146355
Validation loss: 2.4985103142493448

Epoch: 6| Step: 13
Training loss: 2.7271416603730336
Validation loss: 2.4966895278457817

Epoch: 88| Step: 0
Training loss: 2.750496646076731
Validation loss: 2.498526027400104

Epoch: 6| Step: 1
Training loss: 2.6520782023158236
Validation loss: 2.4994085089003364

Epoch: 6| Step: 2
Training loss: 2.010274009057397
Validation loss: 2.4959154935972885

Epoch: 6| Step: 3
Training loss: 2.532328999687578
Validation loss: 2.499545978009053

Epoch: 6| Step: 4
Training loss: 2.750431200380206
Validation loss: 2.4992466824747295

Epoch: 6| Step: 5
Training loss: 2.9143184109731575
Validation loss: 2.5024951245504643

Epoch: 6| Step: 6
Training loss: 2.9766472431444795
Validation loss: 2.5135370755354596

Epoch: 6| Step: 7
Training loss: 2.9835481946353597
Validation loss: 2.500141068293202

Epoch: 6| Step: 8
Training loss: 2.7520576061939654
Validation loss: 2.5076936275715136

Epoch: 6| Step: 9
Training loss: 2.057698295743609
Validation loss: 2.5070063641181695

Epoch: 6| Step: 10
Training loss: 2.481049813523513
Validation loss: 2.4978319781033256

Epoch: 6| Step: 11
Training loss: 2.2805796644284198
Validation loss: 2.497331697331918

Epoch: 6| Step: 12
Training loss: 2.838018153266297
Validation loss: 2.498593316101109

Epoch: 6| Step: 13
Training loss: 2.165581676055305
Validation loss: 2.4904620376937787

Epoch: 89| Step: 0
Training loss: 2.5249702829557363
Validation loss: 2.4907249695463594

Epoch: 6| Step: 1
Training loss: 2.6623302208582276
Validation loss: 2.484401774712001

Epoch: 6| Step: 2
Training loss: 2.919584304535751
Validation loss: 2.488884533819672

Epoch: 6| Step: 3
Training loss: 2.8573668051554217
Validation loss: 2.4851896761649246

Epoch: 6| Step: 4
Training loss: 2.83218867423454
Validation loss: 2.488787301673486

Epoch: 6| Step: 5
Training loss: 2.363745878590219
Validation loss: 2.486278612353544

Epoch: 6| Step: 6
Training loss: 1.770711273773785
Validation loss: 2.4852572300164337

Epoch: 6| Step: 7
Training loss: 2.9299459521415585
Validation loss: 2.4857292722668887

Epoch: 6| Step: 8
Training loss: 2.293070126425664
Validation loss: 2.483228662917698

Epoch: 6| Step: 9
Training loss: 3.053922201228647
Validation loss: 2.4837261368261596

Epoch: 6| Step: 10
Training loss: 2.7788979518145536
Validation loss: 2.4856052511529096

Epoch: 6| Step: 11
Training loss: 2.16889562640073
Validation loss: 2.4887208655054063

Epoch: 6| Step: 12
Training loss: 2.7338225760330137
Validation loss: 2.48667259257363

Epoch: 6| Step: 13
Training loss: 2.141900789201893
Validation loss: 2.4804854905572316

Epoch: 90| Step: 0
Training loss: 3.0830961256455667
Validation loss: 2.4836032396463024

Epoch: 6| Step: 1
Training loss: 2.5989126279146397
Validation loss: 2.4835608165885756

Epoch: 6| Step: 2
Training loss: 2.385815438556438
Validation loss: 2.4835424087719997

Epoch: 6| Step: 3
Training loss: 2.2490512119024246
Validation loss: 2.4905341712155957

Epoch: 6| Step: 4
Training loss: 2.570389581237583
Validation loss: 2.4821585118583225

Epoch: 6| Step: 5
Training loss: 2.547888244154305
Validation loss: 2.489765916032094

Epoch: 6| Step: 6
Training loss: 2.7683136365795717
Validation loss: 2.489222996596584

Epoch: 6| Step: 7
Training loss: 2.747170640053823
Validation loss: 2.484727046822795

Epoch: 6| Step: 8
Training loss: 2.828283737533046
Validation loss: 2.4877006456229553

Epoch: 6| Step: 9
Training loss: 2.385431370141525
Validation loss: 2.485077828532362

Epoch: 6| Step: 10
Training loss: 2.890215870539831
Validation loss: 2.485886791582425

Epoch: 6| Step: 11
Training loss: 2.2246717489472383
Validation loss: 2.4796885787874987

Epoch: 6| Step: 12
Training loss: 2.703900088281453
Validation loss: 2.4760610913220997

Epoch: 6| Step: 13
Training loss: 1.9652202389594828
Validation loss: 2.499310255268532

Epoch: 91| Step: 0
Training loss: 2.699430553997812
Validation loss: 2.4902776178332866

Epoch: 6| Step: 1
Training loss: 2.4586820408981036
Validation loss: 2.4916823541876734

Epoch: 6| Step: 2
Training loss: 2.872889033999114
Validation loss: 2.479509695881982

Epoch: 6| Step: 3
Training loss: 2.7590355254952454
Validation loss: 2.4798200264610513

Epoch: 6| Step: 4
Training loss: 2.669358434712808
Validation loss: 2.48786348661608

Epoch: 6| Step: 5
Training loss: 2.6126987509438577
Validation loss: 2.483527432820573

Epoch: 6| Step: 6
Training loss: 2.5336747976697165
Validation loss: 2.4863443066953663

Epoch: 6| Step: 7
Training loss: 2.2844382176868927
Validation loss: 2.489519786156698

Epoch: 6| Step: 8
Training loss: 2.585932613494958
Validation loss: 2.4877205161493396

Epoch: 6| Step: 9
Training loss: 2.215592515112759
Validation loss: 2.488232686493611

Epoch: 6| Step: 10
Training loss: 2.542135216304848
Validation loss: 2.4863974538338387

Epoch: 6| Step: 11
Training loss: 2.646404284852467
Validation loss: 2.4873025627311875

Epoch: 6| Step: 12
Training loss: 2.731902306917027
Validation loss: 2.4829948398348525

Epoch: 6| Step: 13
Training loss: 2.6177403108156825
Validation loss: 2.491424300187313

Epoch: 92| Step: 0
Training loss: 2.391279941177962
Validation loss: 2.485547458845053

Epoch: 6| Step: 1
Training loss: 2.6038804367438653
Validation loss: 2.488839095427436

Epoch: 6| Step: 2
Training loss: 3.1296596120200317
Validation loss: 2.484043267132775

Epoch: 6| Step: 3
Training loss: 2.657763420248359
Validation loss: 2.479813777125614

Epoch: 6| Step: 4
Training loss: 2.3218144651508
Validation loss: 2.4863201499825047

Epoch: 6| Step: 5
Training loss: 2.3990113009989256
Validation loss: 2.482924159687854

Epoch: 6| Step: 6
Training loss: 2.4669422339397618
Validation loss: 2.4828001745040895

Epoch: 6| Step: 7
Training loss: 2.7338125467841774
Validation loss: 2.490302845132016

Epoch: 6| Step: 8
Training loss: 2.4252515328118043
Validation loss: 2.484852247163063

Epoch: 6| Step: 9
Training loss: 2.1487459828248787
Validation loss: 2.489269641176167

Epoch: 6| Step: 10
Training loss: 3.18541305139277
Validation loss: 2.4808197173681528

Epoch: 6| Step: 11
Training loss: 2.697406077336341
Validation loss: 2.487490853335946

Epoch: 6| Step: 12
Training loss: 2.6318265161009475
Validation loss: 2.4832974702263786

Epoch: 6| Step: 13
Training loss: 2.06469840592913
Validation loss: 2.4833712359443867

Epoch: 93| Step: 0
Training loss: 2.018119274141914
Validation loss: 2.4821521243307596

Epoch: 6| Step: 1
Training loss: 2.3744558413671415
Validation loss: 2.481542608141912

Epoch: 6| Step: 2
Training loss: 2.9294967385811206
Validation loss: 2.487252797889906

Epoch: 6| Step: 3
Training loss: 2.8560411372708208
Validation loss: 2.4866846412830625

Epoch: 6| Step: 4
Training loss: 2.4155988526502177
Validation loss: 2.48422555054093

Epoch: 6| Step: 5
Training loss: 2.9326277563391807
Validation loss: 2.478032202504473

Epoch: 6| Step: 6
Training loss: 2.597342335943225
Validation loss: 2.4794007893349277

Epoch: 6| Step: 7
Training loss: 2.6803308721097054
Validation loss: 2.480111596534571

Epoch: 6| Step: 8
Training loss: 2.5770225248407077
Validation loss: 2.47661254382991

Epoch: 6| Step: 9
Training loss: 2.5300558593674913
Validation loss: 2.47584102001129

Epoch: 6| Step: 10
Training loss: 2.4840401477794254
Validation loss: 2.4865395415369917

Epoch: 6| Step: 11
Training loss: 2.490774202364949
Validation loss: 2.478564266672436

Epoch: 6| Step: 12
Training loss: 3.1917397220972266
Validation loss: 2.4720831312801765

Epoch: 6| Step: 13
Training loss: 1.8244563403395477
Validation loss: 2.474528908769896

Epoch: 94| Step: 0
Training loss: 2.680048704131803
Validation loss: 2.477801521422242

Epoch: 6| Step: 1
Training loss: 2.9527760455929
Validation loss: 2.4821640669127896

Epoch: 6| Step: 2
Training loss: 2.366605277899514
Validation loss: 2.48153589877228

Epoch: 6| Step: 3
Training loss: 2.9388223471877435
Validation loss: 2.4825125056704427

Epoch: 6| Step: 4
Training loss: 2.5462805867593556
Validation loss: 2.480764728819573

Epoch: 6| Step: 5
Training loss: 2.3953969364500525
Validation loss: 2.483935047277162

Epoch: 6| Step: 6
Training loss: 1.8503640718751346
Validation loss: 2.482700111209304

Epoch: 6| Step: 7
Training loss: 2.341643849416684
Validation loss: 2.483384036713555

Epoch: 6| Step: 8
Training loss: 2.170495562594785
Validation loss: 2.4842900515574122

Epoch: 6| Step: 9
Training loss: 2.5243960234183813
Validation loss: 2.4782245566280183

Epoch: 6| Step: 10
Training loss: 3.2671343222130194
Validation loss: 2.4858322188395876

Epoch: 6| Step: 11
Training loss: 2.636155177039402
Validation loss: 2.486511910901006

Epoch: 6| Step: 12
Training loss: 2.7558426778761986
Validation loss: 2.481172877217345

Epoch: 6| Step: 13
Training loss: 2.40625396331857
Validation loss: 2.4823056605738727

Epoch: 95| Step: 0
Training loss: 3.0674824569436785
Validation loss: 2.481101632666953

Epoch: 6| Step: 1
Training loss: 2.2556540127371045
Validation loss: 2.4765570607411433

Epoch: 6| Step: 2
Training loss: 2.90893725780544
Validation loss: 2.4811863939923144

Epoch: 6| Step: 3
Training loss: 2.338633840623417
Validation loss: 2.484432355750481

Epoch: 6| Step: 4
Training loss: 2.167169757047051
Validation loss: 2.483794426407916

Epoch: 6| Step: 5
Training loss: 2.3965404849024283
Validation loss: 2.48221167658155

Epoch: 6| Step: 6
Training loss: 3.2584852809225286
Validation loss: 2.483542088773982

Epoch: 6| Step: 7
Training loss: 2.1784954571487236
Validation loss: 2.480739588731947

Epoch: 6| Step: 8
Training loss: 2.3288997922626735
Validation loss: 2.4767718301867783

Epoch: 6| Step: 9
Training loss: 2.716227534166551
Validation loss: 2.48065051917145

Epoch: 6| Step: 10
Training loss: 2.268205422862205
Validation loss: 2.4780685225950454

Epoch: 6| Step: 11
Training loss: 2.4689162958849833
Validation loss: 2.475790743911434

Epoch: 6| Step: 12
Training loss: 2.573149347530622
Validation loss: 2.4739599502290495

Epoch: 6| Step: 13
Training loss: 2.998898621883697
Validation loss: 2.476564858612959

Epoch: 96| Step: 0
Training loss: 2.4996566536687532
Validation loss: 2.47483370636509

Epoch: 6| Step: 1
Training loss: 2.323612012126368
Validation loss: 2.471663064145914

Epoch: 6| Step: 2
Training loss: 2.7207312544815134
Validation loss: 2.4795726689441775

Epoch: 6| Step: 3
Training loss: 2.793737601779676
Validation loss: 2.470920172243386

Epoch: 6| Step: 4
Training loss: 2.6277728195179497
Validation loss: 2.475253965853346

Epoch: 6| Step: 5
Training loss: 2.6309021491047635
Validation loss: 2.477796084883286

Epoch: 6| Step: 6
Training loss: 2.803844442082247
Validation loss: 2.478842022153216

Epoch: 6| Step: 7
Training loss: 2.2999900403014446
Validation loss: 2.4866627969617965

Epoch: 6| Step: 8
Training loss: 3.100413227227208
Validation loss: 2.483481432405064

Epoch: 6| Step: 9
Training loss: 2.6154691150659786
Validation loss: 2.4846520099512954

Epoch: 6| Step: 10
Training loss: 2.5233772199770916
Validation loss: 2.4842064278470533

Epoch: 6| Step: 11
Training loss: 2.4143484989363913
Validation loss: 2.4748622220155196

Epoch: 6| Step: 12
Training loss: 2.176655400272828
Validation loss: 2.4799581648005207

Epoch: 6| Step: 13
Training loss: 2.566063055261242
Validation loss: 2.477950901299396

Epoch: 97| Step: 0
Training loss: 1.9249666979002267
Validation loss: 2.481035655361906

Epoch: 6| Step: 1
Training loss: 2.906052121224672
Validation loss: 2.485962518469817

Epoch: 6| Step: 2
Training loss: 2.7147713850517325
Validation loss: 2.4839734886615954

Epoch: 6| Step: 3
Training loss: 3.1487232769554883
Validation loss: 2.472312111833636

Epoch: 6| Step: 4
Training loss: 2.5055397644541557
Validation loss: 2.4779257727541673

Epoch: 6| Step: 5
Training loss: 2.7098085542742445
Validation loss: 2.4784306841544805

Epoch: 6| Step: 6
Training loss: 2.9600778907115926
Validation loss: 2.4765669123693526

Epoch: 6| Step: 7
Training loss: 1.8133537649424767
Validation loss: 2.4788756693963405

Epoch: 6| Step: 8
Training loss: 2.427538936785941
Validation loss: 2.478080613138444

Epoch: 6| Step: 9
Training loss: 2.6705515299733804
Validation loss: 2.4760564533755556

Epoch: 6| Step: 10
Training loss: 2.513219975040851
Validation loss: 2.476537341322

Epoch: 6| Step: 11
Training loss: 2.3675026258959604
Validation loss: 2.480581189908688

Epoch: 6| Step: 12
Training loss: 2.6167859125199544
Validation loss: 2.478930339181229

Epoch: 6| Step: 13
Training loss: 2.5285040006660613
Validation loss: 2.4788164698206843

Epoch: 98| Step: 0
Training loss: 2.4759158665131893
Validation loss: 2.4784066827878504

Epoch: 6| Step: 1
Training loss: 1.9587568947793035
Validation loss: 2.478122961645583

Epoch: 6| Step: 2
Training loss: 2.753198064555494
Validation loss: 2.485128932092402

Epoch: 6| Step: 3
Training loss: 2.679504477253551
Validation loss: 2.4773587171378524

Epoch: 6| Step: 4
Training loss: 2.884872734132075
Validation loss: 2.481412052400533

Epoch: 6| Step: 5
Training loss: 2.046117977481014
Validation loss: 2.4794225854508656

Epoch: 6| Step: 6
Training loss: 2.4807050937784973
Validation loss: 2.476857670182643

Epoch: 6| Step: 7
Training loss: 2.5331980426534404
Validation loss: 2.473285275641037

Epoch: 6| Step: 8
Training loss: 2.7965766278740314
Validation loss: 2.471748430473493

Epoch: 6| Step: 9
Training loss: 2.5424729199312988
Validation loss: 2.4866331542145734

Epoch: 6| Step: 10
Training loss: 2.3788917177755535
Validation loss: 2.4833981174834308

Epoch: 6| Step: 11
Training loss: 2.7543196996820543
Validation loss: 2.4865473160937914

Epoch: 6| Step: 12
Training loss: 2.806625759056185
Validation loss: 2.4781865311528426

Epoch: 6| Step: 13
Training loss: 2.8741377491176934
Validation loss: 2.467429238335093

Epoch: 99| Step: 0
Training loss: 2.757984361345575
Validation loss: 2.4670854340810475

Epoch: 6| Step: 1
Training loss: 2.167529032335684
Validation loss: 2.469291112645257

Epoch: 6| Step: 2
Training loss: 2.6533183356520977
Validation loss: 2.4724757011590137

Epoch: 6| Step: 3
Training loss: 1.895621452089254
Validation loss: 2.4793513066325104

Epoch: 6| Step: 4
Training loss: 2.821448184629841
Validation loss: 2.4783235500051095

Epoch: 6| Step: 5
Training loss: 2.553136138704952
Validation loss: 2.4764189733718784

Epoch: 6| Step: 6
Training loss: 2.398236791308114
Validation loss: 2.468110649599751

Epoch: 6| Step: 7
Training loss: 2.711178463827073
Validation loss: 2.4780158302277684

Epoch: 6| Step: 8
Training loss: 1.9788118613255234
Validation loss: 2.4693738897500213

Epoch: 6| Step: 9
Training loss: 2.563585935166766
Validation loss: 2.4709055218328557

Epoch: 6| Step: 10
Training loss: 2.9284828252381545
Validation loss: 2.4758987740729985

Epoch: 6| Step: 11
Training loss: 2.9548123499224777
Validation loss: 2.4732868180009553

Epoch: 6| Step: 12
Training loss: 2.7151939550428024
Validation loss: 2.475374050966784

Epoch: 6| Step: 13
Training loss: 2.6093179845006014
Validation loss: 2.4809872863722595

Epoch: 100| Step: 0
Training loss: 2.60908296515603
Validation loss: 2.479583646397888

Epoch: 6| Step: 1
Training loss: 2.70802242744208
Validation loss: 2.4817439448423437

Epoch: 6| Step: 2
Training loss: 2.5062531468854443
Validation loss: 2.4806759725203227

Epoch: 6| Step: 3
Training loss: 2.7995323471814073
Validation loss: 2.483985694436586

Epoch: 6| Step: 4
Training loss: 2.3497923211390686
Validation loss: 2.4843417471333695

Epoch: 6| Step: 5
Training loss: 2.6546377337878226
Validation loss: 2.480477192381261

Epoch: 6| Step: 6
Training loss: 2.8470861965860843
Validation loss: 2.4878702587816006

Epoch: 6| Step: 7
Training loss: 2.1327490046065876
Validation loss: 2.4792028365715666

Epoch: 6| Step: 8
Training loss: 3.036413769315903
Validation loss: 2.474641265302358

Epoch: 6| Step: 9
Training loss: 2.4774040453023445
Validation loss: 2.471781611617539

Epoch: 6| Step: 10
Training loss: 2.321512136946466
Validation loss: 2.471408732180002

Epoch: 6| Step: 11
Training loss: 2.6620112154041538
Validation loss: 2.4675729255245074

Epoch: 6| Step: 12
Training loss: 2.380162601045519
Validation loss: 2.4715497844254966

Epoch: 6| Step: 13
Training loss: 2.4223094919603705
Validation loss: 2.46496817087873

Epoch: 101| Step: 0
Training loss: 2.4485531135143725
Validation loss: 2.4764468610302117

Epoch: 6| Step: 1
Training loss: 2.2525307939226002
Validation loss: 2.476780188907903

Epoch: 6| Step: 2
Training loss: 2.367535656798469
Validation loss: 2.4781225287035067

Epoch: 6| Step: 3
Training loss: 2.1921518182875444
Validation loss: 2.4772156216198695

Epoch: 6| Step: 4
Training loss: 3.0943749307175152
Validation loss: 2.477936164168162

Epoch: 6| Step: 5
Training loss: 2.4788946007792387
Validation loss: 2.489752597454958

Epoch: 6| Step: 6
Training loss: 2.887849372105768
Validation loss: 2.478673057676506

Epoch: 6| Step: 7
Training loss: 2.6044663727278037
Validation loss: 2.485535292713598

Epoch: 6| Step: 8
Training loss: 2.921911718780393
Validation loss: 2.478655984249492

Epoch: 6| Step: 9
Training loss: 3.0724546613211436
Validation loss: 2.485695877656911

Epoch: 6| Step: 10
Training loss: 2.364978124343963
Validation loss: 2.48674978959325

Epoch: 6| Step: 11
Training loss: 2.445538300152882
Validation loss: 2.4823937823419033

Epoch: 6| Step: 12
Training loss: 2.2908563973200264
Validation loss: 2.4853785505247217

Epoch: 6| Step: 13
Training loss: 2.473094545783734
Validation loss: 2.4843302788697956

Epoch: 102| Step: 0
Training loss: 2.8950758201671682
Validation loss: 2.474803127139504

Epoch: 6| Step: 1
Training loss: 2.758450961029893
Validation loss: 2.4690907721990376

Epoch: 6| Step: 2
Training loss: 2.7642052233535748
Validation loss: 2.4739265894944666

Epoch: 6| Step: 3
Training loss: 2.3611412258346984
Validation loss: 2.472000774426118

Epoch: 6| Step: 4
Training loss: 1.6066055171589269
Validation loss: 2.4695744324943107

Epoch: 6| Step: 5
Training loss: 2.6924601181604384
Validation loss: 2.4742774730764534

Epoch: 6| Step: 6
Training loss: 2.8503234679717164
Validation loss: 2.4793089230111804

Epoch: 6| Step: 7
Training loss: 2.2742731714895483
Validation loss: 2.4778977814677363

Epoch: 6| Step: 8
Training loss: 2.8945707866733024
Validation loss: 2.4861318746039505

Epoch: 6| Step: 9
Training loss: 2.9670720227084906
Validation loss: 2.485805891138932

Epoch: 6| Step: 10
Training loss: 2.49774182375594
Validation loss: 2.4910300027241834

Epoch: 6| Step: 11
Training loss: 1.9588708207601484
Validation loss: 2.491048873640393

Epoch: 6| Step: 12
Training loss: 2.62567511460083
Validation loss: 2.4724036274003542

Epoch: 6| Step: 13
Training loss: 2.3970744580929484
Validation loss: 2.4762882919213642

Epoch: 103| Step: 0
Training loss: 2.593983375437221
Validation loss: 2.476204438102489

Epoch: 6| Step: 1
Training loss: 2.528079272258631
Validation loss: 2.4857995609398156

Epoch: 6| Step: 2
Training loss: 2.1662195795898187
Validation loss: 2.482489200042251

Epoch: 6| Step: 3
Training loss: 2.6951523000681696
Validation loss: 2.4864937246931134

Epoch: 6| Step: 4
Training loss: 2.695938347289807
Validation loss: 2.4904112031274757

Epoch: 6| Step: 5
Training loss: 2.3010802924691993
Validation loss: 2.482020511990202

Epoch: 6| Step: 6
Training loss: 2.709355049103844
Validation loss: 2.4814486753162477

Epoch: 6| Step: 7
Training loss: 2.739182785013062
Validation loss: 2.4779691582223653

Epoch: 6| Step: 8
Training loss: 2.378557051161456
Validation loss: 2.4756325581290843

Epoch: 6| Step: 9
Training loss: 2.5980558389208803
Validation loss: 2.474341181528536

Epoch: 6| Step: 10
Training loss: 2.251661746652434
Validation loss: 2.480973424158493

Epoch: 6| Step: 11
Training loss: 2.607669935677965
Validation loss: 2.480772145056714

Epoch: 6| Step: 12
Training loss: 3.1993770350609796
Validation loss: 2.4864706002103154

Epoch: 6| Step: 13
Training loss: 2.2345478551199767
Validation loss: 2.4827030081719994

Epoch: 104| Step: 0
Training loss: 2.223958952737643
Validation loss: 2.4861736704119988

Epoch: 6| Step: 1
Training loss: 2.982532351782819
Validation loss: 2.4802127175343767

Epoch: 6| Step: 2
Training loss: 2.016842260151136
Validation loss: 2.4777881625898224

Epoch: 6| Step: 3
Training loss: 1.9646614854733733
Validation loss: 2.4826773195174754

Epoch: 6| Step: 4
Training loss: 2.3684201697855416
Validation loss: 2.478440544368003

Epoch: 6| Step: 5
Training loss: 2.844523398061894
Validation loss: 2.475131322285958

Epoch: 6| Step: 6
Training loss: 3.0955477028709333
Validation loss: 2.4682398079774686

Epoch: 6| Step: 7
Training loss: 2.026195634680916
Validation loss: 2.4775335772690066

Epoch: 6| Step: 8
Training loss: 2.5118710010474903
Validation loss: 2.470929226185828

Epoch: 6| Step: 9
Training loss: 3.11582576674952
Validation loss: 2.48009868274235

Epoch: 6| Step: 10
Training loss: 2.1791982887944745
Validation loss: 2.478900066968739

Epoch: 6| Step: 11
Training loss: 3.1096387588350547
Validation loss: 2.474050119939303

Epoch: 6| Step: 12
Training loss: 2.0319453296440715
Validation loss: 2.481105852784429

Epoch: 6| Step: 13
Training loss: 2.779656114234874
Validation loss: 2.483872608754399

Epoch: 105| Step: 0
Training loss: 2.229915516882391
Validation loss: 2.4722376464572138

Epoch: 6| Step: 1
Training loss: 3.1030592681899285
Validation loss: 2.4801186782630475

Epoch: 6| Step: 2
Training loss: 2.8528810561850886
Validation loss: 2.4859238600821247

Epoch: 6| Step: 3
Training loss: 3.089438777190416
Validation loss: 2.4731448927612645

Epoch: 6| Step: 4
Training loss: 2.887629591110422
Validation loss: 2.4789194870723708

Epoch: 6| Step: 5
Training loss: 2.555208298913453
Validation loss: 2.479833005799714

Epoch: 6| Step: 6
Training loss: 2.1790641522288436
Validation loss: 2.473054585605255

Epoch: 6| Step: 7
Training loss: 2.1846396137239217
Validation loss: 2.48192336316564

Epoch: 6| Step: 8
Training loss: 2.244552906435127
Validation loss: 2.4819182238420905

Epoch: 6| Step: 9
Training loss: 1.9626632330975007
Validation loss: 2.4837842754807733

Epoch: 6| Step: 10
Training loss: 2.94642193285702
Validation loss: 2.474518230057364

Epoch: 6| Step: 11
Training loss: 2.4831036847666588
Validation loss: 2.479495977654502

Epoch: 6| Step: 12
Training loss: 2.0307269083072317
Validation loss: 2.4770081256542724

Epoch: 6| Step: 13
Training loss: 2.742077078049655
Validation loss: 2.4838273826387396

Epoch: 106| Step: 0
Training loss: 3.353320392131166
Validation loss: 2.476775488133467

Epoch: 6| Step: 1
Training loss: 2.5838406177532818
Validation loss: 2.4740915577136

Epoch: 6| Step: 2
Training loss: 2.8171070935818157
Validation loss: 2.481023595235186

Epoch: 6| Step: 3
Training loss: 2.1852354044211335
Validation loss: 2.4780435876674076

Epoch: 6| Step: 4
Training loss: 2.9208097913140687
Validation loss: 2.4775128070591377

Epoch: 6| Step: 5
Training loss: 1.9786178095527436
Validation loss: 2.470992594813458

Epoch: 6| Step: 6
Training loss: 2.4875251423700906
Validation loss: 2.4766548372176986

Epoch: 6| Step: 7
Training loss: 2.5845274062693404
Validation loss: 2.4711415742388456

Epoch: 6| Step: 8
Training loss: 2.2675225039945746
Validation loss: 2.4657989762897046

Epoch: 6| Step: 9
Training loss: 2.154918978555385
Validation loss: 2.465020303906948

Epoch: 6| Step: 10
Training loss: 2.567822302300178
Validation loss: 2.4660127973809707

Epoch: 6| Step: 11
Training loss: 2.221236970827856
Validation loss: 2.469355706059313

Epoch: 6| Step: 12
Training loss: 2.5283873583411975
Validation loss: 2.4704161224733516

Epoch: 6| Step: 13
Training loss: 2.769469008936764
Validation loss: 2.4617681645427987

Epoch: 107| Step: 0
Training loss: 2.2859371579027212
Validation loss: 2.466078717380237

Epoch: 6| Step: 1
Training loss: 2.886981379185645
Validation loss: 2.461038415847948

Epoch: 6| Step: 2
Training loss: 2.9284680079099465
Validation loss: 2.4712894593354107

Epoch: 6| Step: 3
Training loss: 2.525613419455014
Validation loss: 2.466577483403573

Epoch: 6| Step: 4
Training loss: 2.8019400823532354
Validation loss: 2.467651130675629

Epoch: 6| Step: 5
Training loss: 2.9038120011251447
Validation loss: 2.4658255256622903

Epoch: 6| Step: 6
Training loss: 2.73688823187139
Validation loss: 2.4650382616582664

Epoch: 6| Step: 7
Training loss: 2.3592507032785663
Validation loss: 2.4648553492317995

Epoch: 6| Step: 8
Training loss: 2.5989161139494654
Validation loss: 2.465648634571278

Epoch: 6| Step: 9
Training loss: 1.5673642546603868
Validation loss: 2.4649070574433645

Epoch: 6| Step: 10
Training loss: 2.51557837022486
Validation loss: 2.465395874155817

Epoch: 6| Step: 11
Training loss: 2.026378482649243
Validation loss: 2.46907488781647

Epoch: 6| Step: 12
Training loss: 2.1995713813439193
Validation loss: 2.4677897167083995

Epoch: 6| Step: 13
Training loss: 2.9081555753962007
Validation loss: 2.4594312468337103

Epoch: 108| Step: 0
Training loss: 2.0898127188116717
Validation loss: 2.46104707019841

Epoch: 6| Step: 1
Training loss: 2.7613565728139675
Validation loss: 2.462732861089635

Epoch: 6| Step: 2
Training loss: 2.135145427566162
Validation loss: 2.4577365301686145

Epoch: 6| Step: 3
Training loss: 2.7037358117580044
Validation loss: 2.472050436411719

Epoch: 6| Step: 4
Training loss: 3.0239076076400644
Validation loss: 2.468295445826487

Epoch: 6| Step: 5
Training loss: 2.247057898535625
Validation loss: 2.4591680149612

Epoch: 6| Step: 6
Training loss: 2.6163346908137477
Validation loss: 2.4643277586897074

Epoch: 6| Step: 7
Training loss: 2.9036476215077642
Validation loss: 2.466820779917658

Epoch: 6| Step: 8
Training loss: 2.1963642899591505
Validation loss: 2.4681815768599997

Epoch: 6| Step: 9
Training loss: 2.136406075371505
Validation loss: 2.47040154949866

Epoch: 6| Step: 10
Training loss: 3.132191280121793
Validation loss: 2.470415012614065

Epoch: 6| Step: 11
Training loss: 2.695629864128212
Validation loss: 2.474685238240117

Epoch: 6| Step: 12
Training loss: 2.432713626525753
Validation loss: 2.4770349559332305

Epoch: 6| Step: 13
Training loss: 2.3884724419121786
Validation loss: 2.4827220224067816

Epoch: 109| Step: 0
Training loss: 2.4988957827521823
Validation loss: 2.4774388027492003

Epoch: 6| Step: 1
Training loss: 3.215383157635001
Validation loss: 2.477301678821094

Epoch: 6| Step: 2
Training loss: 2.5243354829404367
Validation loss: 2.459396735761373

Epoch: 6| Step: 3
Training loss: 1.895077404464457
Validation loss: 2.4544528679880417

Epoch: 6| Step: 4
Training loss: 2.2711325165465013
Validation loss: 2.459806168086642

Epoch: 6| Step: 5
Training loss: 3.158286768856029
Validation loss: 2.457878771205957

Epoch: 6| Step: 6
Training loss: 2.607305379829713
Validation loss: 2.4632131399152537

Epoch: 6| Step: 7
Training loss: 2.6891750172510123
Validation loss: 2.475991906380354

Epoch: 6| Step: 8
Training loss: 2.2382809304441853
Validation loss: 2.4603895435135654

Epoch: 6| Step: 9
Training loss: 2.468900362095506
Validation loss: 2.465178662906038

Epoch: 6| Step: 10
Training loss: 2.9108491008807285
Validation loss: 2.472794097545239

Epoch: 6| Step: 11
Training loss: 2.4868618017068367
Validation loss: 2.455086865102283

Epoch: 6| Step: 12
Training loss: 2.3958302594593617
Validation loss: 2.4645390390224544

Epoch: 6| Step: 13
Training loss: 2.153019129305354
Validation loss: 2.4579329784279067

Epoch: 110| Step: 0
Training loss: 2.3068794818050202
Validation loss: 2.457555410718321

Epoch: 6| Step: 1
Training loss: 2.6171530650136705
Validation loss: 2.4621458124830244

Epoch: 6| Step: 2
Training loss: 3.0504770750051273
Validation loss: 2.461049185342869

Epoch: 6| Step: 3
Training loss: 2.453994305380981
Validation loss: 2.463317575942019

Epoch: 6| Step: 4
Training loss: 2.6391588463369784
Validation loss: 2.454108913586201

Epoch: 6| Step: 5
Training loss: 2.706363039541154
Validation loss: 2.465434677133883

Epoch: 6| Step: 6
Training loss: 2.129861096075098
Validation loss: 2.4647806988776453

Epoch: 6| Step: 7
Training loss: 2.2233368647755607
Validation loss: 2.4720979515255146

Epoch: 6| Step: 8
Training loss: 2.4799533098194164
Validation loss: 2.4738245449364524

Epoch: 6| Step: 9
Training loss: 2.630152414061095
Validation loss: 2.4703217022262156

Epoch: 6| Step: 10
Training loss: 3.0852810318365096
Validation loss: 2.4683128806929706

Epoch: 6| Step: 11
Training loss: 2.328652546144242
Validation loss: 2.4758414132281588

Epoch: 6| Step: 12
Training loss: 2.6119757386347042
Validation loss: 2.471452834983853

Epoch: 6| Step: 13
Training loss: 2.1804921842249994
Validation loss: 2.477258851100226

Epoch: 111| Step: 0
Training loss: 2.6371719083970384
Validation loss: 2.4733409847499335

Epoch: 6| Step: 1
Training loss: 2.979511872323125
Validation loss: 2.470012277709058

Epoch: 6| Step: 2
Training loss: 2.8849603358670923
Validation loss: 2.478354270177917

Epoch: 6| Step: 3
Training loss: 2.042433017486843
Validation loss: 2.476931547471894

Epoch: 6| Step: 4
Training loss: 2.724275870745835
Validation loss: 2.470855925286778

Epoch: 6| Step: 5
Training loss: 1.78143041935105
Validation loss: 2.4780983559842547

Epoch: 6| Step: 6
Training loss: 2.6748745683870867
Validation loss: 2.4743079865301794

Epoch: 6| Step: 7
Training loss: 2.5588809252602287
Validation loss: 2.475747167790654

Epoch: 6| Step: 8
Training loss: 2.702379245089325
Validation loss: 2.4743420969140533

Epoch: 6| Step: 9
Training loss: 2.8274351511567124
Validation loss: 2.469369480619616

Epoch: 6| Step: 10
Training loss: 2.345905076099226
Validation loss: 2.471235319977378

Epoch: 6| Step: 11
Training loss: 2.5770911715940055
Validation loss: 2.4754082911328887

Epoch: 6| Step: 12
Training loss: 2.508625980005021
Validation loss: 2.4737791511831713

Epoch: 6| Step: 13
Training loss: 1.9629297356955577
Validation loss: 2.4768884245792413

Epoch: 112| Step: 0
Training loss: 2.498177913423197
Validation loss: 2.47872544751469

Epoch: 6| Step: 1
Training loss: 2.6402841381852795
Validation loss: 2.470946771120177

Epoch: 6| Step: 2
Training loss: 2.8510716682131294
Validation loss: 2.473844992735083

Epoch: 6| Step: 3
Training loss: 2.0542120437820173
Validation loss: 2.477568252706277

Epoch: 6| Step: 4
Training loss: 2.0834905437916764
Validation loss: 2.4671394148576518

Epoch: 6| Step: 5
Training loss: 2.602068785928866
Validation loss: 2.4709333752282956

Epoch: 6| Step: 6
Training loss: 2.558281566415058
Validation loss: 2.4770664380275114

Epoch: 6| Step: 7
Training loss: 2.2561616240969644
Validation loss: 2.4700440343156913

Epoch: 6| Step: 8
Training loss: 2.60600675550099
Validation loss: 2.4705883054728814

Epoch: 6| Step: 9
Training loss: 2.6752584350384514
Validation loss: 2.465584927141795

Epoch: 6| Step: 10
Training loss: 2.504941158098507
Validation loss: 2.46678841801611

Epoch: 6| Step: 11
Training loss: 2.5788831116367232
Validation loss: 2.468376042818409

Epoch: 6| Step: 12
Training loss: 2.4411720590801647
Validation loss: 2.4657734096586084

Epoch: 6| Step: 13
Training loss: 3.028466588645158
Validation loss: 2.4703110374978787

Epoch: 113| Step: 0
Training loss: 2.8209185596327604
Validation loss: 2.4708616344081213

Epoch: 6| Step: 1
Training loss: 3.3589525533802016
Validation loss: 2.4690050886649453

Epoch: 6| Step: 2
Training loss: 1.7009338843107298
Validation loss: 2.471740778169701

Epoch: 6| Step: 3
Training loss: 2.612603023998219
Validation loss: 2.4703267530769635

Epoch: 6| Step: 4
Training loss: 1.9255649530296768
Validation loss: 2.4659421541937663

Epoch: 6| Step: 5
Training loss: 2.7617180593616535
Validation loss: 2.473585503576709

Epoch: 6| Step: 6
Training loss: 2.3485587062762923
Validation loss: 2.4662407303262275

Epoch: 6| Step: 7
Training loss: 3.005051492513273
Validation loss: 2.4768552075683847

Epoch: 6| Step: 8
Training loss: 2.9439490119416316
Validation loss: 2.472842241135135

Epoch: 6| Step: 9
Training loss: 1.9181956605646
Validation loss: 2.478034319186611

Epoch: 6| Step: 10
Training loss: 2.2923046495577935
Validation loss: 2.4819051593455304

Epoch: 6| Step: 11
Training loss: 2.64986594958712
Validation loss: 2.474664114949059

Epoch: 6| Step: 12
Training loss: 2.06968719828006
Validation loss: 2.4806521050076116

Epoch: 6| Step: 13
Training loss: 2.5399778623442235
Validation loss: 2.476409891362421

Epoch: 114| Step: 0
Training loss: 2.224903653234071
Validation loss: 2.4701017550050732

Epoch: 6| Step: 1
Training loss: 2.5303152736796077
Validation loss: 2.46568222011735

Epoch: 6| Step: 2
Training loss: 3.02303435720693
Validation loss: 2.4641406491759152

Epoch: 6| Step: 3
Training loss: 2.5143324096015824
Validation loss: 2.4750765605606215

Epoch: 6| Step: 4
Training loss: 2.2149665704275474
Validation loss: 2.4688489869951864

Epoch: 6| Step: 5
Training loss: 2.1635919052361894
Validation loss: 2.468461981603399

Epoch: 6| Step: 6
Training loss: 1.9259311083814934
Validation loss: 2.4758961580365293

Epoch: 6| Step: 7
Training loss: 3.0877341919084245
Validation loss: 2.46342657249163

Epoch: 6| Step: 8
Training loss: 3.0435032111975544
Validation loss: 2.4641538239824796

Epoch: 6| Step: 9
Training loss: 2.2050895859561543
Validation loss: 2.4746602290788453

Epoch: 6| Step: 10
Training loss: 2.286474854938944
Validation loss: 2.4847150845748236

Epoch: 6| Step: 11
Training loss: 2.7421209865230645
Validation loss: 2.4888558275812254

Epoch: 6| Step: 12
Training loss: 3.06503315694526
Validation loss: 2.4818433662267947

Epoch: 6| Step: 13
Training loss: 2.1920402276183415
Validation loss: 2.4744900155530507

Epoch: 115| Step: 0
Training loss: 1.9708640237989976
Validation loss: 2.475595744839014

Epoch: 6| Step: 1
Training loss: 2.168788995309769
Validation loss: 2.4803653565331976

Epoch: 6| Step: 2
Training loss: 2.7078174588817836
Validation loss: 2.4825074315928273

Epoch: 6| Step: 3
Training loss: 2.5445105687988416
Validation loss: 2.4884764925593914

Epoch: 6| Step: 4
Training loss: 2.3223243494204535
Validation loss: 2.4932508123566017

Epoch: 6| Step: 5
Training loss: 2.6520851245123924
Validation loss: 2.4918477654960127

Epoch: 6| Step: 6
Training loss: 2.9192914505479215
Validation loss: 2.4991301692278967

Epoch: 6| Step: 7
Training loss: 2.8149202741373966
Validation loss: 2.494142775807241

Epoch: 6| Step: 8
Training loss: 2.6884458784686514
Validation loss: 2.4992092471445395

Epoch: 6| Step: 9
Training loss: 2.7415265539324523
Validation loss: 2.4996026200138988

Epoch: 6| Step: 10
Training loss: 3.0385205096917454
Validation loss: 2.4980861331657493

Epoch: 6| Step: 11
Training loss: 2.3433507960805207
Validation loss: 2.49799053177313

Epoch: 6| Step: 12
Training loss: 2.856408252964723
Validation loss: 2.4975676624957543

Epoch: 6| Step: 13
Training loss: 2.587032766128025
Validation loss: 2.4931232764333036

Epoch: 116| Step: 0
Training loss: 2.6096405076957896
Validation loss: 2.4924417842340096

Epoch: 6| Step: 1
Training loss: 2.38463495319847
Validation loss: 2.491707192498591

Epoch: 6| Step: 2
Training loss: 2.2588771962850767
Validation loss: 2.485342321272521

Epoch: 6| Step: 3
Training loss: 2.9767194891753452
Validation loss: 2.47830754842815

Epoch: 6| Step: 4
Training loss: 2.995089963348314
Validation loss: 2.4728267825812638

Epoch: 6| Step: 5
Training loss: 1.8444285679648396
Validation loss: 2.47327084810272

Epoch: 6| Step: 6
Training loss: 2.493332363713258
Validation loss: 2.4686017857094487

Epoch: 6| Step: 7
Training loss: 2.493889397953252
Validation loss: 2.4723276378954644

Epoch: 6| Step: 8
Training loss: 2.866401918147534
Validation loss: 2.4682244654912076

Epoch: 6| Step: 9
Training loss: 2.5190256957060684
Validation loss: 2.4697102156108537

Epoch: 6| Step: 10
Training loss: 2.796434847332796
Validation loss: 2.4752193302368

Epoch: 6| Step: 11
Training loss: 1.9650721028618265
Validation loss: 2.471507950323603

Epoch: 6| Step: 12
Training loss: 2.518251647112499
Validation loss: 2.470472692466734

Epoch: 6| Step: 13
Training loss: 3.1172046326283565
Validation loss: 2.4803714923364444

Epoch: 117| Step: 0
Training loss: 1.9249647162040064
Validation loss: 2.4868579189176985

Epoch: 6| Step: 1
Training loss: 2.947174697798015
Validation loss: 2.484885589145665

Epoch: 6| Step: 2
Training loss: 2.5300745177320567
Validation loss: 2.4894513583350357

Epoch: 6| Step: 3
Training loss: 2.536525080518689
Validation loss: 2.4776253330004736

Epoch: 6| Step: 4
Training loss: 2.7127574780872346
Validation loss: 2.4834435434229096

Epoch: 6| Step: 5
Training loss: 2.4671946587679154
Validation loss: 2.4852310241367723

Epoch: 6| Step: 6
Training loss: 2.6519117045598892
Validation loss: 2.4847463014432294

Epoch: 6| Step: 7
Training loss: 2.5669407396835955
Validation loss: 2.4748099430720756

Epoch: 6| Step: 8
Training loss: 2.6047419917053727
Validation loss: 2.4722443649881494

Epoch: 6| Step: 9
Training loss: 2.0016386948197242
Validation loss: 2.4834455754902542

Epoch: 6| Step: 10
Training loss: 2.593975838630288
Validation loss: 2.477464481564927

Epoch: 6| Step: 11
Training loss: 3.1923366577135375
Validation loss: 2.4795138866571347

Epoch: 6| Step: 12
Training loss: 2.210496191187599
Validation loss: 2.479106987841286

Epoch: 6| Step: 13
Training loss: 2.614034911817866
Validation loss: 2.4807836698131993

Epoch: 118| Step: 0
Training loss: 2.1409563239754927
Validation loss: 2.4859069643317118

Epoch: 6| Step: 1
Training loss: 2.5577085405124738
Validation loss: 2.467850146895913

Epoch: 6| Step: 2
Training loss: 2.5774141198548306
Validation loss: 2.4670330145000037

Epoch: 6| Step: 3
Training loss: 2.5552746392620236
Validation loss: 2.462270611763004

Epoch: 6| Step: 4
Training loss: 2.8011293075278503
Validation loss: 2.4806336916252807

Epoch: 6| Step: 5
Training loss: 2.5044929186080584
Validation loss: 2.4844777147984236

Epoch: 6| Step: 6
Training loss: 2.831569534021896
Validation loss: 2.4819613554049367

Epoch: 6| Step: 7
Training loss: 2.144400948768012
Validation loss: 2.481996089056675

Epoch: 6| Step: 8
Training loss: 2.76106999181383
Validation loss: 2.4872758272331645

Epoch: 6| Step: 9
Training loss: 2.597260546840661
Validation loss: 2.481410723268373

Epoch: 6| Step: 10
Training loss: 2.62803438191444
Validation loss: 2.487001498190328

Epoch: 6| Step: 11
Training loss: 2.1886510817714315
Validation loss: 2.4873786858348703

Epoch: 6| Step: 12
Training loss: 2.8106872650775454
Validation loss: 2.4806632218508273

Epoch: 6| Step: 13
Training loss: 2.3910813238911257
Validation loss: 2.4773394692587583

Epoch: 119| Step: 0
Training loss: 2.172725922456063
Validation loss: 2.4833362815079907

Epoch: 6| Step: 1
Training loss: 2.670938874379683
Validation loss: 2.4744500457927905

Epoch: 6| Step: 2
Training loss: 3.1982056593810952
Validation loss: 2.470366483931328

Epoch: 6| Step: 3
Training loss: 2.723131179434835
Validation loss: 2.472546165711596

Epoch: 6| Step: 4
Training loss: 2.8236047016535353
Validation loss: 2.463052557256078

Epoch: 6| Step: 5
Training loss: 2.3690907094906524
Validation loss: 2.4650574121501783

Epoch: 6| Step: 6
Training loss: 2.624214236410881
Validation loss: 2.4695702892139404

Epoch: 6| Step: 7
Training loss: 2.4205317556169246
Validation loss: 2.4657576731163062

Epoch: 6| Step: 8
Training loss: 2.161350575407528
Validation loss: 2.4646812582890187

Epoch: 6| Step: 9
Training loss: 2.405418846948313
Validation loss: 2.4698020367436175

Epoch: 6| Step: 10
Training loss: 2.010153507804557
Validation loss: 2.4705745377080732

Epoch: 6| Step: 11
Training loss: 2.6570801279248957
Validation loss: 2.4703670308293186

Epoch: 6| Step: 12
Training loss: 2.39226979040012
Validation loss: 2.4713710761555308

Epoch: 6| Step: 13
Training loss: 2.666809813313147
Validation loss: 2.4647457790501766

Epoch: 120| Step: 0
Training loss: 2.2924333041440867
Validation loss: 2.473817316687548

Epoch: 6| Step: 1
Training loss: 2.7056235524414025
Validation loss: 2.46896454727884

Epoch: 6| Step: 2
Training loss: 2.5871315587835135
Validation loss: 2.4563495153145256

Epoch: 6| Step: 3
Training loss: 2.6072589266148074
Validation loss: 2.464015509190197

Epoch: 6| Step: 4
Training loss: 2.32249897393244
Validation loss: 2.4556823650497135

Epoch: 6| Step: 5
Training loss: 2.3932428923425317
Validation loss: 2.4718614760333133

Epoch: 6| Step: 6
Training loss: 2.5436590754874304
Validation loss: 2.4679558438354774

Epoch: 6| Step: 7
Training loss: 1.8891641316553223
Validation loss: 2.4764110627188685

Epoch: 6| Step: 8
Training loss: 2.445912832845125
Validation loss: 2.472133185418033

Epoch: 6| Step: 9
Training loss: 2.9886453643568354
Validation loss: 2.4832378640054493

Epoch: 6| Step: 10
Training loss: 2.519685867651574
Validation loss: 2.482876371630809

Epoch: 6| Step: 11
Training loss: 2.364032317055235
Validation loss: 2.4748075667302243

Epoch: 6| Step: 12
Training loss: 2.7920858628315113
Validation loss: 2.4753518178814544

Epoch: 6| Step: 13
Training loss: 2.804688690100287
Validation loss: 2.4721718786295224

Epoch: 121| Step: 0
Training loss: 2.438564068282482
Validation loss: 2.4681003858675696

Epoch: 6| Step: 1
Training loss: 2.0428600975304883
Validation loss: 2.4742771518802025

Epoch: 6| Step: 2
Training loss: 2.660443305885654
Validation loss: 2.4718303777667474

Epoch: 6| Step: 3
Training loss: 3.0545935262679014
Validation loss: 2.4662885023753924

Epoch: 6| Step: 4
Training loss: 2.6057814105937864
Validation loss: 2.45981474600133

Epoch: 6| Step: 5
Training loss: 2.373408939071695
Validation loss: 2.4684100178516264

Epoch: 6| Step: 6
Training loss: 1.9975625324606732
Validation loss: 2.4660444121299707

Epoch: 6| Step: 7
Training loss: 1.929619050452862
Validation loss: 2.4725041556122522

Epoch: 6| Step: 8
Training loss: 2.3647123685295144
Validation loss: 2.478547416946048

Epoch: 6| Step: 9
Training loss: 3.0616833902095046
Validation loss: 2.4770339693541286

Epoch: 6| Step: 10
Training loss: 2.635903465535178
Validation loss: 2.480925142047851

Epoch: 6| Step: 11
Training loss: 2.398432330893249
Validation loss: 2.4754686477032832

Epoch: 6| Step: 12
Training loss: 2.7789607538428687
Validation loss: 2.4834345191037484

Epoch: 6| Step: 13
Training loss: 2.730377326711809
Validation loss: 2.4791020590647603

Epoch: 122| Step: 0
Training loss: 2.5702619460679546
Validation loss: 2.4840354767404182

Epoch: 6| Step: 1
Training loss: 2.3468366515662145
Validation loss: 2.486935805230661

Epoch: 6| Step: 2
Training loss: 2.7523961465283873
Validation loss: 2.4848725882243667

Epoch: 6| Step: 3
Training loss: 2.3529692336120656
Validation loss: 2.4833204002384957

Epoch: 6| Step: 4
Training loss: 2.5506512315219623
Validation loss: 2.4773861290675168

Epoch: 6| Step: 5
Training loss: 2.1711254335818433
Validation loss: 2.477048631643722

Epoch: 6| Step: 6
Training loss: 2.320866476903245
Validation loss: 2.4825443424696534

Epoch: 6| Step: 7
Training loss: 2.1820340122051083
Validation loss: 2.474637861120491

Epoch: 6| Step: 8
Training loss: 2.6656410708731184
Validation loss: 2.4786581324618

Epoch: 6| Step: 9
Training loss: 2.095191459374137
Validation loss: 2.4743289763559453

Epoch: 6| Step: 10
Training loss: 2.946857401369525
Validation loss: 2.47227338465305

Epoch: 6| Step: 11
Training loss: 2.579486094606456
Validation loss: 2.4803851897014635

Epoch: 6| Step: 12
Training loss: 2.9848421540051615
Validation loss: 2.4728613151219583

Epoch: 6| Step: 13
Training loss: 2.824739737885951
Validation loss: 2.4668985015159453

Epoch: 123| Step: 0
Training loss: 2.839747536143092
Validation loss: 2.466448624635265

Epoch: 6| Step: 1
Training loss: 2.0987784511325813
Validation loss: 2.4664280591291896

Epoch: 6| Step: 2
Training loss: 2.2745168948482117
Validation loss: 2.466606593904059

Epoch: 6| Step: 3
Training loss: 2.4400858734215958
Validation loss: 2.4689118537479517

Epoch: 6| Step: 4
Training loss: 2.702505139849748
Validation loss: 2.472290019976143

Epoch: 6| Step: 5
Training loss: 2.711315997082442
Validation loss: 2.4757578412023955

Epoch: 6| Step: 6
Training loss: 3.208446120884706
Validation loss: 2.473473902338269

Epoch: 6| Step: 7
Training loss: 1.654356323759342
Validation loss: 2.462776683619058

Epoch: 6| Step: 8
Training loss: 2.868814864079806
Validation loss: 2.459476921557995

Epoch: 6| Step: 9
Training loss: 2.130109590388586
Validation loss: 2.4645315013819182

Epoch: 6| Step: 10
Training loss: 3.142370848994801
Validation loss: 2.462294342760822

Epoch: 6| Step: 11
Training loss: 2.159886486461595
Validation loss: 2.4653281629066996

Epoch: 6| Step: 12
Training loss: 2.240362933593294
Validation loss: 2.4650147988788857

Epoch: 6| Step: 13
Training loss: 2.5080584349022894
Validation loss: 2.468557036379332

Epoch: 124| Step: 0
Training loss: 2.281207358601899
Validation loss: 2.4522233670766918

Epoch: 6| Step: 1
Training loss: 2.395409477445606
Validation loss: 2.4533508261630548

Epoch: 6| Step: 2
Training loss: 2.5691338245405664
Validation loss: 2.4508834203068073

Epoch: 6| Step: 3
Training loss: 2.5389049305074
Validation loss: 2.4576537976497366

Epoch: 6| Step: 4
Training loss: 2.878545150988481
Validation loss: 2.466442728079965

Epoch: 6| Step: 5
Training loss: 2.6096779653132685
Validation loss: 2.458989869289103

Epoch: 6| Step: 6
Training loss: 2.2396877057498683
Validation loss: 2.463620341189251

Epoch: 6| Step: 7
Training loss: 3.0203737808223186
Validation loss: 2.4620889462622055

Epoch: 6| Step: 8
Training loss: 2.75261598486455
Validation loss: 2.4641779641735395

Epoch: 6| Step: 9
Training loss: 2.435754199713785
Validation loss: 2.468020995463463

Epoch: 6| Step: 10
Training loss: 2.5613541250813103
Validation loss: 2.463194442914885

Epoch: 6| Step: 11
Training loss: 2.113647654811796
Validation loss: 2.470215559586874

Epoch: 6| Step: 12
Training loss: 2.392587691307406
Validation loss: 2.467061394820114

Epoch: 6| Step: 13
Training loss: 2.6029515495993714
Validation loss: 2.4566062313014987

Epoch: 125| Step: 0
Training loss: 3.0148282752785347
Validation loss: 2.4648399453755965

Epoch: 6| Step: 1
Training loss: 2.52503184685594
Validation loss: 2.464851085170304

Epoch: 6| Step: 2
Training loss: 1.6226940666717928
Validation loss: 2.479211010790116

Epoch: 6| Step: 3
Training loss: 2.3106057940699447
Validation loss: 2.486467052413

Epoch: 6| Step: 4
Training loss: 3.385544024297144
Validation loss: 2.4868436180576845

Epoch: 6| Step: 5
Training loss: 2.5857270953275853
Validation loss: 2.4790497974022387

Epoch: 6| Step: 6
Training loss: 2.302822379904953
Validation loss: 2.486729591722311

Epoch: 6| Step: 7
Training loss: 2.4200025642003116
Validation loss: 2.490169892317709

Epoch: 6| Step: 8
Training loss: 2.604573566436966
Validation loss: 2.492895968355146

Epoch: 6| Step: 9
Training loss: 2.674691840274256
Validation loss: 2.488896076891185

Epoch: 6| Step: 10
Training loss: 2.3630143952837264
Validation loss: 2.4909955944388322

Epoch: 6| Step: 11
Training loss: 2.1883549790523618
Validation loss: 2.4907217787921985

Epoch: 6| Step: 12
Training loss: 2.557333785964295
Validation loss: 2.487579693947355

Epoch: 6| Step: 13
Training loss: 2.71331770565147
Validation loss: 2.4927489904798823

Epoch: 126| Step: 0
Training loss: 3.272433543510379
Validation loss: 2.4870051730462217

Epoch: 6| Step: 1
Training loss: 2.3553685408954457
Validation loss: 2.4884348551929225

Epoch: 6| Step: 2
Training loss: 2.229665741951313
Validation loss: 2.4926549299752283

Epoch: 6| Step: 3
Training loss: 2.2752139567278413
Validation loss: 2.490699682707469

Epoch: 6| Step: 4
Training loss: 2.7753615032174204
Validation loss: 2.4861269997125133

Epoch: 6| Step: 5
Training loss: 2.2310063504240243
Validation loss: 2.491337550529822

Epoch: 6| Step: 6
Training loss: 2.678281098026338
Validation loss: 2.473786556236583

Epoch: 6| Step: 7
Training loss: 2.682674422623866
Validation loss: 2.470985028615604

Epoch: 6| Step: 8
Training loss: 2.4825651666207182
Validation loss: 2.4811794594475294

Epoch: 6| Step: 9
Training loss: 2.9741980104797987
Validation loss: 2.4792262051482807

Epoch: 6| Step: 10
Training loss: 1.7734705716044932
Validation loss: 2.473982003082013

Epoch: 6| Step: 11
Training loss: 2.326056258934113
Validation loss: 2.476501608500121

Epoch: 6| Step: 12
Training loss: 2.496605762389046
Validation loss: 2.4736843773926167

Epoch: 6| Step: 13
Training loss: 2.942238739264393
Validation loss: 2.471178654882344

Epoch: 127| Step: 0
Training loss: 2.382076962871573
Validation loss: 2.4658562806782656

Epoch: 6| Step: 1
Training loss: 3.0679013634632946
Validation loss: 2.46165672166796

Epoch: 6| Step: 2
Training loss: 2.3438346338885823
Validation loss: 2.467282659923328

Epoch: 6| Step: 3
Training loss: 2.531092415131128
Validation loss: 2.4750264856738786

Epoch: 6| Step: 4
Training loss: 2.86368190569533
Validation loss: 2.4711735414528713

Epoch: 6| Step: 5
Training loss: 2.653080564021193
Validation loss: 2.4760662428027147

Epoch: 6| Step: 6
Training loss: 2.2499575081097776
Validation loss: 2.469386296421437

Epoch: 6| Step: 7
Training loss: 1.9613524222146304
Validation loss: 2.4759502837495315

Epoch: 6| Step: 8
Training loss: 2.7673326812862227
Validation loss: 2.468083915506961

Epoch: 6| Step: 9
Training loss: 2.337587724151337
Validation loss: 2.4649544200848634

Epoch: 6| Step: 10
Training loss: 2.8882636245383737
Validation loss: 2.4598477165776416

Epoch: 6| Step: 11
Training loss: 1.7338563985706135
Validation loss: 2.4738643320528966

Epoch: 6| Step: 12
Training loss: 2.9080325986774467
Validation loss: 2.473796884723085

Epoch: 6| Step: 13
Training loss: 2.236625551659777
Validation loss: 2.4786156808764304

Epoch: 128| Step: 0
Training loss: 2.2436826818031856
Validation loss: 2.484960778871592

Epoch: 6| Step: 1
Training loss: 2.348022838539944
Validation loss: 2.4911957364856607

Epoch: 6| Step: 2
Training loss: 2.468219941612939
Validation loss: 2.4918954851558532

Epoch: 6| Step: 3
Training loss: 2.247687528974006
Validation loss: 2.481436537129472

Epoch: 6| Step: 4
Training loss: 2.42203969087847
Validation loss: 2.4827738306560407

Epoch: 6| Step: 5
Training loss: 2.5481559480944895
Validation loss: 2.4866028719057627

Epoch: 6| Step: 6
Training loss: 1.9506394096020732
Validation loss: 2.4867684373236973

Epoch: 6| Step: 7
Training loss: 2.5752216058574264
Validation loss: 2.484623078889797

Epoch: 6| Step: 8
Training loss: 2.8458529231978296
Validation loss: 2.4841244969142005

Epoch: 6| Step: 9
Training loss: 2.43088455395575
Validation loss: 2.478869081048819

Epoch: 6| Step: 10
Training loss: 3.220125367466638
Validation loss: 2.4722805611612335

Epoch: 6| Step: 11
Training loss: 2.615891685244143
Validation loss: 2.4787076450332344

Epoch: 6| Step: 12
Training loss: 2.646740034641506
Validation loss: 2.472609436652654

Epoch: 6| Step: 13
Training loss: 2.723983375526595
Validation loss: 2.4585579807203657

Epoch: 129| Step: 0
Training loss: 2.865296948873643
Validation loss: 2.467287716995381

Epoch: 6| Step: 1
Training loss: 2.092604138552841
Validation loss: 2.4618917401401483

Epoch: 6| Step: 2
Training loss: 1.8659068548049513
Validation loss: 2.461975460051045

Epoch: 6| Step: 3
Training loss: 2.681163325831747
Validation loss: 2.465445483835869

Epoch: 6| Step: 4
Training loss: 2.280711802918644
Validation loss: 2.469293269004727

Epoch: 6| Step: 5
Training loss: 2.8452246898024462
Validation loss: 2.476984768236084

Epoch: 6| Step: 6
Training loss: 2.523515068255614
Validation loss: 2.4586624043797323

Epoch: 6| Step: 7
Training loss: 2.4099924288428953
Validation loss: 2.463547177674875

Epoch: 6| Step: 8
Training loss: 2.966658005719633
Validation loss: 2.4719568823343003

Epoch: 6| Step: 9
Training loss: 2.4311501372159348
Validation loss: 2.469464307370691

Epoch: 6| Step: 10
Training loss: 2.9491977311957958
Validation loss: 2.467862609532303

Epoch: 6| Step: 11
Training loss: 1.9179207665681854
Validation loss: 2.4839563236891262

Epoch: 6| Step: 12
Training loss: 2.264225178752152
Validation loss: 2.478452568965551

Epoch: 6| Step: 13
Training loss: 2.836280654869337
Validation loss: 2.482595410147807

Epoch: 130| Step: 0
Training loss: 2.2422605495980914
Validation loss: 2.4807003123412477

Epoch: 6| Step: 1
Training loss: 3.0028193259700036
Validation loss: 2.4836114633797886

Epoch: 6| Step: 2
Training loss: 2.5727292094237146
Validation loss: 2.4769171491937167

Epoch: 6| Step: 3
Training loss: 2.442297591194877
Validation loss: 2.4662746139357625

Epoch: 6| Step: 4
Training loss: 2.554741908436052
Validation loss: 2.4700038960846973

Epoch: 6| Step: 5
Training loss: 1.8695997672750502
Validation loss: 2.466059518422745

Epoch: 6| Step: 6
Training loss: 2.5757917538753548
Validation loss: 2.4756016757723143

Epoch: 6| Step: 7
Training loss: 2.4088237918622646
Validation loss: 2.4771323686585003

Epoch: 6| Step: 8
Training loss: 2.5652317280041923
Validation loss: 2.48014349619713

Epoch: 6| Step: 9
Training loss: 2.3763694830267537
Validation loss: 2.4902732776270944

Epoch: 6| Step: 10
Training loss: 2.1170420016022007
Validation loss: 2.4880522777818808

Epoch: 6| Step: 11
Training loss: 2.6626028050020136
Validation loss: 2.488973556177819

Epoch: 6| Step: 12
Training loss: 2.9780961538641018
Validation loss: 2.490154333885228

Epoch: 6| Step: 13
Training loss: 2.7747213481493036
Validation loss: 2.4970297652856144

Epoch: 131| Step: 0
Training loss: 2.0690870580928404
Validation loss: 2.5003716669375566

Epoch: 6| Step: 1
Training loss: 2.6073333610912464
Validation loss: 2.483627382786495

Epoch: 6| Step: 2
Training loss: 2.385359806454783
Validation loss: 2.485986311021937

Epoch: 6| Step: 3
Training loss: 2.2398364138474753
Validation loss: 2.480483007515209

Epoch: 6| Step: 4
Training loss: 2.3130696600267426
Validation loss: 2.4857361941189025

Epoch: 6| Step: 5
Training loss: 2.5319815626392153
Validation loss: 2.474052063354307

Epoch: 6| Step: 6
Training loss: 2.3492897177741936
Validation loss: 2.473763055958091

Epoch: 6| Step: 7
Training loss: 3.179688249817556
Validation loss: 2.4881746677506227

Epoch: 6| Step: 8
Training loss: 2.9119479200505825
Validation loss: 2.4935075219739984

Epoch: 6| Step: 9
Training loss: 2.6132320747253375
Validation loss: 2.4808620031013837

Epoch: 6| Step: 10
Training loss: 2.412366252611129
Validation loss: 2.4862839983799887

Epoch: 6| Step: 11
Training loss: 2.445804924179836
Validation loss: 2.4744349024003935

Epoch: 6| Step: 12
Training loss: 2.819321476760845
Validation loss: 2.4767109919655095

Epoch: 6| Step: 13
Training loss: 2.6672349761330953
Validation loss: 2.475489627687733

Epoch: 132| Step: 0
Training loss: 2.5091821845858693
Validation loss: 2.4676095444912947

Epoch: 6| Step: 1
Training loss: 1.9874942323613
Validation loss: 2.481618155352638

Epoch: 6| Step: 2
Training loss: 2.4889705547584997
Validation loss: 2.480221601373547

Epoch: 6| Step: 3
Training loss: 2.3951468990884233
Validation loss: 2.4805236970517606

Epoch: 6| Step: 4
Training loss: 2.054807246094756
Validation loss: 2.486070034698856

Epoch: 6| Step: 5
Training loss: 3.0061355473864206
Validation loss: 2.4866909053105246

Epoch: 6| Step: 6
Training loss: 2.4631670827689947
Validation loss: 2.491853394629577

Epoch: 6| Step: 7
Training loss: 2.5804849631631424
Validation loss: 2.4884242680927704

Epoch: 6| Step: 8
Training loss: 3.3458497771876052
Validation loss: 2.489591994862406

Epoch: 6| Step: 9
Training loss: 2.7566776696400312
Validation loss: 2.489272211231977

Epoch: 6| Step: 10
Training loss: 2.7242547792328184
Validation loss: 2.4881883381295364

Epoch: 6| Step: 11
Training loss: 2.6428050234895113
Validation loss: 2.4845603217974706

Epoch: 6| Step: 12
Training loss: 2.2466068113071804
Validation loss: 2.493230244801192

Epoch: 6| Step: 13
Training loss: 2.383185685748458
Validation loss: 2.4885832055894914

Epoch: 133| Step: 0
Training loss: 2.473933801362059
Validation loss: 2.4923452010529257

Epoch: 6| Step: 1
Training loss: 2.7648720443670465
Validation loss: 2.4905046543225144

Epoch: 6| Step: 2
Training loss: 2.782606586975097
Validation loss: 2.487258916702568

Epoch: 6| Step: 3
Training loss: 1.8600411383888862
Validation loss: 2.4834515116774614

Epoch: 6| Step: 4
Training loss: 1.8778548441477279
Validation loss: 2.4821752410192777

Epoch: 6| Step: 5
Training loss: 2.8532091376944053
Validation loss: 2.4808891841182916

Epoch: 6| Step: 6
Training loss: 2.5970668496924065
Validation loss: 2.4885240054125917

Epoch: 6| Step: 7
Training loss: 3.3900241583129334
Validation loss: 2.485918529221523

Epoch: 6| Step: 8
Training loss: 2.548138357786638
Validation loss: 2.483442431385352

Epoch: 6| Step: 9
Training loss: 2.6939317787951667
Validation loss: 2.4720609007455776

Epoch: 6| Step: 10
Training loss: 2.0063922772211753
Validation loss: 2.466468899978089

Epoch: 6| Step: 11
Training loss: 2.6218263423801336
Validation loss: 2.464459566140264

Epoch: 6| Step: 12
Training loss: 2.5298343043292064
Validation loss: 2.4728597564276282

Epoch: 6| Step: 13
Training loss: 2.08557845893947
Validation loss: 2.471970280717079

Epoch: 134| Step: 0
Training loss: 2.713797783556133
Validation loss: 2.4841601040905

Epoch: 6| Step: 1
Training loss: 3.127147089549472
Validation loss: 2.500663430877534

Epoch: 6| Step: 2
Training loss: 2.3875283524192876
Validation loss: 2.494836911698418

Epoch: 6| Step: 3
Training loss: 2.026479312598189
Validation loss: 2.480324456130536

Epoch: 6| Step: 4
Training loss: 2.3947271917180686
Validation loss: 2.4742246036121025

Epoch: 6| Step: 5
Training loss: 2.538771674299856
Validation loss: 2.467516917100172

Epoch: 6| Step: 6
Training loss: 1.9853334290013611
Validation loss: 2.474191696136324

Epoch: 6| Step: 7
Training loss: 2.455778205735233
Validation loss: 2.4693113566025557

Epoch: 6| Step: 8
Training loss: 2.6327105312806633
Validation loss: 2.471114744293601

Epoch: 6| Step: 9
Training loss: 2.620677477190416
Validation loss: 2.46630073928262

Epoch: 6| Step: 10
Training loss: 2.433787918304843
Validation loss: 2.471781611617539

Epoch: 6| Step: 11
Training loss: 2.2538673225624537
Validation loss: 2.4777220088468326

Epoch: 6| Step: 12
Training loss: 3.299470142250797
Validation loss: 2.4793719091861717

Epoch: 6| Step: 13
Training loss: 2.484795876606543
Validation loss: 2.474103635569901

Epoch: 135| Step: 0
Training loss: 2.6319116698287504
Validation loss: 2.476280477131812

Epoch: 6| Step: 1
Training loss: 2.796333729458551
Validation loss: 2.4724567447346253

Epoch: 6| Step: 2
Training loss: 2.312154073874453
Validation loss: 2.4734084846753075

Epoch: 6| Step: 3
Training loss: 2.97469144872
Validation loss: 2.4731103641802217

Epoch: 6| Step: 4
Training loss: 2.10251502250539
Validation loss: 2.4702137981452044

Epoch: 6| Step: 5
Training loss: 1.8166774096156726
Validation loss: 2.4738056068795014

Epoch: 6| Step: 6
Training loss: 2.2586451912203915
Validation loss: 2.4720279805411525

Epoch: 6| Step: 7
Training loss: 2.7310448122094932
Validation loss: 2.4657195762477957

Epoch: 6| Step: 8
Training loss: 2.218918914812503
Validation loss: 2.4695719063008927

Epoch: 6| Step: 9
Training loss: 2.235569347939858
Validation loss: 2.4616551800922375

Epoch: 6| Step: 10
Training loss: 2.6347706019168617
Validation loss: 2.4577939497823014

Epoch: 6| Step: 11
Training loss: 2.6599364785088664
Validation loss: 2.4608003043225195

Epoch: 6| Step: 12
Training loss: 2.4271306263868797
Validation loss: 2.461443700651396

Epoch: 6| Step: 13
Training loss: 3.056851686253438
Validation loss: 2.468826920481974

Epoch: 136| Step: 0
Training loss: 2.0918718711024975
Validation loss: 2.4590170819988573

Epoch: 6| Step: 1
Training loss: 2.315413727176382
Validation loss: 2.4631788592841364

Epoch: 6| Step: 2
Training loss: 2.5107720045754776
Validation loss: 2.463219157125048

Epoch: 6| Step: 3
Training loss: 2.4589388042466176
Validation loss: 2.459168927915441

Epoch: 6| Step: 4
Training loss: 2.8707612344651054
Validation loss: 2.4631575647224633

Epoch: 6| Step: 5
Training loss: 2.641624126232192
Validation loss: 2.470991243995561

Epoch: 6| Step: 6
Training loss: 2.1730113178630788
Validation loss: 2.474843364151735

Epoch: 6| Step: 7
Training loss: 2.518287813173714
Validation loss: 2.4628168912333006

Epoch: 6| Step: 8
Training loss: 3.2686849613174367
Validation loss: 2.457983207554228

Epoch: 6| Step: 9
Training loss: 2.3611705086909884
Validation loss: 2.4728299482181475

Epoch: 6| Step: 10
Training loss: 2.5460768309010864
Validation loss: 2.4631067151456754

Epoch: 6| Step: 11
Training loss: 2.744811278145862
Validation loss: 2.464082321187254

Epoch: 6| Step: 12
Training loss: 2.0261325636007146
Validation loss: 2.463701687885395

Epoch: 6| Step: 13
Training loss: 2.4409456596780226
Validation loss: 2.4594330079194524

Epoch: 137| Step: 0
Training loss: 3.1015949391703312
Validation loss: 2.4567364635628364

Epoch: 6| Step: 1
Training loss: 2.080690335009666
Validation loss: 2.465840133738404

Epoch: 6| Step: 2
Training loss: 2.433776750618385
Validation loss: 2.4686617131280952

Epoch: 6| Step: 3
Training loss: 2.7566824264567895
Validation loss: 2.469890845946126

Epoch: 6| Step: 4
Training loss: 2.584848964270605
Validation loss: 2.46053759035211

Epoch: 6| Step: 5
Training loss: 2.3378889933160556
Validation loss: 2.4610883716980365

Epoch: 6| Step: 6
Training loss: 2.215480598511111
Validation loss: 2.472311710019148

Epoch: 6| Step: 7
Training loss: 2.4633484671217736
Validation loss: 2.4663759558574014

Epoch: 6| Step: 8
Training loss: 2.86787310726308
Validation loss: 2.471588498828208

Epoch: 6| Step: 9
Training loss: 1.7629015688278606
Validation loss: 2.4669738850999243

Epoch: 6| Step: 10
Training loss: 2.46474141000647
Validation loss: 2.4680774754533723

Epoch: 6| Step: 11
Training loss: 1.9220708111511458
Validation loss: 2.468137415602494

Epoch: 6| Step: 12
Training loss: 2.675552603426741
Validation loss: 2.4746213379259396

Epoch: 6| Step: 13
Training loss: 3.1077052861703147
Validation loss: 2.4693804953850385

Epoch: 138| Step: 0
Training loss: 2.5542447234315144
Validation loss: 2.4778921927943363

Epoch: 6| Step: 1
Training loss: 2.0577053635962566
Validation loss: 2.470190312136252

Epoch: 6| Step: 2
Training loss: 1.93567633171859
Validation loss: 2.479530313145367

Epoch: 6| Step: 3
Training loss: 2.316873281399522
Validation loss: 2.476581625558708

Epoch: 6| Step: 4
Training loss: 2.8737113386542767
Validation loss: 2.468280514206277

Epoch: 6| Step: 5
Training loss: 2.9315601111632983
Validation loss: 2.469566001112567

Epoch: 6| Step: 6
Training loss: 2.820926588837539
Validation loss: 2.472621553889711

Epoch: 6| Step: 7
Training loss: 2.4704236502014405
Validation loss: 2.473091669700775

Epoch: 6| Step: 8
Training loss: 2.8681589086925947
Validation loss: 2.469128092853849

Epoch: 6| Step: 9
Training loss: 2.368922941391762
Validation loss: 2.4701322235207197

Epoch: 6| Step: 10
Training loss: 2.069617734249001
Validation loss: 2.4669398178039827

Epoch: 6| Step: 11
Training loss: 2.6186174272652347
Validation loss: 2.4701143188894252

Epoch: 6| Step: 12
Training loss: 2.6372852762329035
Validation loss: 2.4629593874120084

Epoch: 6| Step: 13
Training loss: 2.3287461239531155
Validation loss: 2.4761855423182983

Epoch: 139| Step: 0
Training loss: 2.340125472951503
Validation loss: 2.4667182964214107

Epoch: 6| Step: 1
Training loss: 2.5672071069582776
Validation loss: 2.4682697038178616

Epoch: 6| Step: 2
Training loss: 3.010258301966073
Validation loss: 2.4666860137215085

Epoch: 6| Step: 3
Training loss: 2.8884064279659873
Validation loss: 2.474112966958398

Epoch: 6| Step: 4
Training loss: 2.220420101385263
Validation loss: 2.470749290949718

Epoch: 6| Step: 5
Training loss: 2.47083744694162
Validation loss: 2.4720952832449514

Epoch: 6| Step: 6
Training loss: 2.2406773815123944
Validation loss: 2.468485459910034

Epoch: 6| Step: 7
Training loss: 2.475172164015286
Validation loss: 2.4744887790534715

Epoch: 6| Step: 8
Training loss: 2.639392361937248
Validation loss: 2.468984021390184

Epoch: 6| Step: 9
Training loss: 2.6601825998488478
Validation loss: 2.483686627681996

Epoch: 6| Step: 10
Training loss: 2.9764997020114445
Validation loss: 2.467419632050877

Epoch: 6| Step: 11
Training loss: 2.3494992757545683
Validation loss: 2.4627964648146787

Epoch: 6| Step: 12
Training loss: 2.251830627868185
Validation loss: 2.4696415043980084

Epoch: 6| Step: 13
Training loss: 1.9215360513164432
Validation loss: 2.474220002373508

Epoch: 140| Step: 0
Training loss: 1.9845237976515764
Validation loss: 2.478613885325071

Epoch: 6| Step: 1
Training loss: 2.06449943497757
Validation loss: 2.489560407801672

Epoch: 6| Step: 2
Training loss: 2.1232641647586834
Validation loss: 2.4852353571597376

Epoch: 6| Step: 3
Training loss: 2.5580977796368742
Validation loss: 2.4936304011144195

Epoch: 6| Step: 4
Training loss: 2.7381664039809364
Validation loss: 2.484753785757081

Epoch: 6| Step: 5
Training loss: 2.8198951983085045
Validation loss: 2.4944321539924634

Epoch: 6| Step: 6
Training loss: 2.732424667171554
Validation loss: 2.4871089135855513

Epoch: 6| Step: 7
Training loss: 3.0194191264151975
Validation loss: 2.493356253277223

Epoch: 6| Step: 8
Training loss: 2.6379426955274208
Validation loss: 2.4875131616292134

Epoch: 6| Step: 9
Training loss: 1.6426948206540712
Validation loss: 2.4832565541100413

Epoch: 6| Step: 10
Training loss: 2.1580257014882123
Validation loss: 2.4926643274176734

Epoch: 6| Step: 11
Training loss: 3.1265761406108616
Validation loss: 2.487193685869734

Epoch: 6| Step: 12
Training loss: 2.7253974239772494
Validation loss: 2.490842107278995

Epoch: 6| Step: 13
Training loss: 3.058139109529261
Validation loss: 2.485981451829259

Epoch: 141| Step: 0
Training loss: 2.497240737273089
Validation loss: 2.4910115304631795

Epoch: 6| Step: 1
Training loss: 2.523141188098305
Validation loss: 2.48137269057058

Epoch: 6| Step: 2
Training loss: 1.615870727505085
Validation loss: 2.4834736562506343

Epoch: 6| Step: 3
Training loss: 1.834313116378236
Validation loss: 2.479737662160743

Epoch: 6| Step: 4
Training loss: 2.4787318599035237
Validation loss: 2.4779055911566537

Epoch: 6| Step: 5
Training loss: 3.0909802918214653
Validation loss: 2.466833892085431

Epoch: 6| Step: 6
Training loss: 2.8361762500654906
Validation loss: 2.4831863054705323

Epoch: 6| Step: 7
Training loss: 2.6604258306868727
Validation loss: 2.4771125014255877

Epoch: 6| Step: 8
Training loss: 2.05366217845114
Validation loss: 2.4675860336955573

Epoch: 6| Step: 9
Training loss: 2.6120715798447067
Validation loss: 2.4751441656697084

Epoch: 6| Step: 10
Training loss: 2.4474875432477745
Validation loss: 2.46781097129957

Epoch: 6| Step: 11
Training loss: 2.24615244913108
Validation loss: 2.4804857789103374

Epoch: 6| Step: 12
Training loss: 2.851537584169829
Validation loss: 2.4711708882541643

Epoch: 6| Step: 13
Training loss: 3.1797288896645854
Validation loss: 2.469033768195441

Epoch: 142| Step: 0
Training loss: 2.516628373298929
Validation loss: 2.472518716194226

Epoch: 6| Step: 1
Training loss: 2.839403960583875
Validation loss: 2.464371915656183

Epoch: 6| Step: 2
Training loss: 2.14104774922876
Validation loss: 2.467568722521258

Epoch: 6| Step: 3
Training loss: 2.0997438183700416
Validation loss: 2.4660867256297023

Epoch: 6| Step: 4
Training loss: 2.990937691567865
Validation loss: 2.464785696596416

Epoch: 6| Step: 5
Training loss: 2.0616305281427882
Validation loss: 2.472023326990562

Epoch: 6| Step: 6
Training loss: 2.7414022772328903
Validation loss: 2.4668173005100855

Epoch: 6| Step: 7
Training loss: 2.014344510975947
Validation loss: 2.4625630898308777

Epoch: 6| Step: 8
Training loss: 2.237368625641379
Validation loss: 2.4709217482428563

Epoch: 6| Step: 9
Training loss: 3.0207998515060357
Validation loss: 2.4666422606455036

Epoch: 6| Step: 10
Training loss: 2.110100628410366
Validation loss: 2.46585457252396

Epoch: 6| Step: 11
Training loss: 2.803080744059087
Validation loss: 2.4692651396302696

Epoch: 6| Step: 12
Training loss: 2.5672637575215354
Validation loss: 2.4688066323138504

Epoch: 6| Step: 13
Training loss: 2.4538467220262503
Validation loss: 2.4696194691012416

Epoch: 143| Step: 0
Training loss: 2.406081057476091
Validation loss: 2.464976746950484

Epoch: 6| Step: 1
Training loss: 2.4699609418244215
Validation loss: 2.461768890906518

Epoch: 6| Step: 2
Training loss: 2.0050944770757093
Validation loss: 2.4642448040164164

Epoch: 6| Step: 3
Training loss: 2.4108559259049867
Validation loss: 2.4646066752145597

Epoch: 6| Step: 4
Training loss: 2.437965544234177
Validation loss: 2.4634493245298286

Epoch: 6| Step: 5
Training loss: 2.276051070996256
Validation loss: 2.4651240347142123

Epoch: 6| Step: 6
Training loss: 2.622824266748885
Validation loss: 2.4589358065663918

Epoch: 6| Step: 7
Training loss: 3.04798047478497
Validation loss: 2.462564517884858

Epoch: 6| Step: 8
Training loss: 2.3713885505831627
Validation loss: 2.463501231619133

Epoch: 6| Step: 9
Training loss: 2.4163371113537875
Validation loss: 2.457020754000791

Epoch: 6| Step: 10
Training loss: 2.400087466235565
Validation loss: 2.4637477108451056

Epoch: 6| Step: 11
Training loss: 2.9284683335663173
Validation loss: 2.4597514528873203

Epoch: 6| Step: 12
Training loss: 2.974999205004161
Validation loss: 2.471775084741644

Epoch: 6| Step: 13
Training loss: 1.9254042931611566
Validation loss: 2.4662994100625886

Epoch: 144| Step: 0
Training loss: 2.4853185625264964
Validation loss: 2.46134149373907

Epoch: 6| Step: 1
Training loss: 2.5498757500390496
Validation loss: 2.461407498483045

Epoch: 6| Step: 2
Training loss: 2.7317013993847112
Validation loss: 2.462975908174757

Epoch: 6| Step: 3
Training loss: 2.489644250696399
Validation loss: 2.472150159230817

Epoch: 6| Step: 4
Training loss: 2.031681191087627
Validation loss: 2.475343502495704

Epoch: 6| Step: 5
Training loss: 2.1376346389573713
Validation loss: 2.4780124627529374

Epoch: 6| Step: 6
Training loss: 3.070594522273308
Validation loss: 2.473022562366505

Epoch: 6| Step: 7
Training loss: 2.6068925756073718
Validation loss: 2.470665490387775

Epoch: 6| Step: 8
Training loss: 2.571196337461207
Validation loss: 2.47853853512219

Epoch: 6| Step: 9
Training loss: 2.431801026963598
Validation loss: 2.467574584178992

Epoch: 6| Step: 10
Training loss: 2.466499171713321
Validation loss: 2.474858978697965

Epoch: 6| Step: 11
Training loss: 2.7132404670319397
Validation loss: 2.4793475803647333

Epoch: 6| Step: 12
Training loss: 2.1059950133696637
Validation loss: 2.470684629428878

Epoch: 6| Step: 13
Training loss: 2.4727004109035366
Validation loss: 2.4639037244589757

Epoch: 145| Step: 0
Training loss: 2.866375301398831
Validation loss: 2.47330249860553

Epoch: 6| Step: 1
Training loss: 2.6569322495270105
Validation loss: 2.46753358448985

Epoch: 6| Step: 2
Training loss: 1.5343680263135504
Validation loss: 2.4659329288562604

Epoch: 6| Step: 3
Training loss: 2.4997569919735994
Validation loss: 2.4640722261284047

Epoch: 6| Step: 4
Training loss: 2.3229952629261104
Validation loss: 2.457677840003557

Epoch: 6| Step: 5
Training loss: 2.447972030554665
Validation loss: 2.460969632055027

Epoch: 6| Step: 6
Training loss: 2.6325845591412733
Validation loss: 2.4761835363879436

Epoch: 6| Step: 7
Training loss: 2.4988982633998438
Validation loss: 2.4661004539968543

Epoch: 6| Step: 8
Training loss: 2.726206234279375
Validation loss: 2.4705823544624606

Epoch: 6| Step: 9
Training loss: 2.407152477308247
Validation loss: 2.467135855367953

Epoch: 6| Step: 10
Training loss: 3.0925430872142843
Validation loss: 2.4666863359062297

Epoch: 6| Step: 11
Training loss: 2.542382332358601
Validation loss: 2.4581748997556905

Epoch: 6| Step: 12
Training loss: 2.169237030486432
Validation loss: 2.4645363625580803

Epoch: 6| Step: 13
Training loss: 2.5099625447126885
Validation loss: 2.467943872751262

Epoch: 146| Step: 0
Training loss: 2.264773294248416
Validation loss: 2.4571950723427167

Epoch: 6| Step: 1
Training loss: 2.329998107712923
Validation loss: 2.4619663086204295

Epoch: 6| Step: 2
Training loss: 2.369897480932328
Validation loss: 2.466666376483316

Epoch: 6| Step: 3
Training loss: 3.1727618401152955
Validation loss: 2.4603041868369395

Epoch: 6| Step: 4
Training loss: 2.7052901752965712
Validation loss: 2.4791712293395896

Epoch: 6| Step: 5
Training loss: 1.7652819815097995
Validation loss: 2.4681426963194286

Epoch: 6| Step: 6
Training loss: 2.0170719364786995
Validation loss: 2.4630341171666843

Epoch: 6| Step: 7
Training loss: 2.4756767542205385
Validation loss: 2.4650614421169017

Epoch: 6| Step: 8
Training loss: 2.7019703775020254
Validation loss: 2.4594962122904103

Epoch: 6| Step: 9
Training loss: 2.369281509877388
Validation loss: 2.4604772228139415

Epoch: 6| Step: 10
Training loss: 2.9800761152953967
Validation loss: 2.4624369417949956

Epoch: 6| Step: 11
Training loss: 2.446876586289945
Validation loss: 2.4533934233742367

Epoch: 6| Step: 12
Training loss: 2.2462723901446857
Validation loss: 2.4626295136346346

Epoch: 6| Step: 13
Training loss: 2.8424783735031314
Validation loss: 2.457050349692466

Epoch: 147| Step: 0
Training loss: 2.62402843479125
Validation loss: 2.4736042184202374

Epoch: 6| Step: 1
Training loss: 2.572273688857662
Validation loss: 2.4805484949144114

Epoch: 6| Step: 2
Training loss: 2.3019936545555493
Validation loss: 2.4790235579616327

Epoch: 6| Step: 3
Training loss: 2.857890092683823
Validation loss: 2.47556818467295

Epoch: 6| Step: 4
Training loss: 2.2794450909460267
Validation loss: 2.478186394859767

Epoch: 6| Step: 5
Training loss: 2.6474872335931243
Validation loss: 2.475623537438922

Epoch: 6| Step: 6
Training loss: 2.444106514527939
Validation loss: 2.4798098993249376

Epoch: 6| Step: 7
Training loss: 2.4826037732703448
Validation loss: 2.4828502846610103

Epoch: 6| Step: 8
Training loss: 2.2613256241281623
Validation loss: 2.4880927636796315

Epoch: 6| Step: 9
Training loss: 2.1503743267221256
Validation loss: 2.491344113879433

Epoch: 6| Step: 10
Training loss: 2.715928290565159
Validation loss: 2.477338474780942

Epoch: 6| Step: 11
Training loss: 2.1514229301888173
Validation loss: 2.4761739720896676

Epoch: 6| Step: 12
Training loss: 3.0300150449775867
Validation loss: 2.4700862149521567

Epoch: 6| Step: 13
Training loss: 2.440075223107146
Validation loss: 2.46349890082394

Epoch: 148| Step: 0
Training loss: 3.052770613188624
Validation loss: 2.468272641865564

Epoch: 6| Step: 1
Training loss: 2.005626988158841
Validation loss: 2.4672224574222676

Epoch: 6| Step: 2
Training loss: 2.0532443123672133
Validation loss: 2.4727213742004976

Epoch: 6| Step: 3
Training loss: 2.3023902953083195
Validation loss: 2.4687722764438655

Epoch: 6| Step: 4
Training loss: 2.614154572812059
Validation loss: 2.4661878496972824

Epoch: 6| Step: 5
Training loss: 2.2747562948630975
Validation loss: 2.4630747722985418

Epoch: 6| Step: 6
Training loss: 2.3209559514945726
Validation loss: 2.469407947603374

Epoch: 6| Step: 7
Training loss: 2.5200139965698036
Validation loss: 2.476845405216351

Epoch: 6| Step: 8
Training loss: 3.359514100499517
Validation loss: 2.461748802835336

Epoch: 6| Step: 9
Training loss: 1.8928498977460781
Validation loss: 2.4744616883167185

Epoch: 6| Step: 10
Training loss: 2.361915988490749
Validation loss: 2.473802506742714

Epoch: 6| Step: 11
Training loss: 2.7806151447734555
Validation loss: 2.4765423153155988

Epoch: 6| Step: 12
Training loss: 2.1849068666769864
Validation loss: 2.4768232976416953

Epoch: 6| Step: 13
Training loss: 2.7263917186340407
Validation loss: 2.4718753491581067

Epoch: 149| Step: 0
Training loss: 1.9190915428141848
Validation loss: 2.463433992534268

Epoch: 6| Step: 1
Training loss: 2.582383401607505
Validation loss: 2.4656694241427055

Epoch: 6| Step: 2
Training loss: 2.5995028020392783
Validation loss: 2.4656376111925233

Epoch: 6| Step: 3
Training loss: 2.6624633822363206
Validation loss: 2.472252939928742

Epoch: 6| Step: 4
Training loss: 2.1942953013454765
Validation loss: 2.477422875654802

Epoch: 6| Step: 5
Training loss: 3.2793269743909743
Validation loss: 2.485412413046417

Epoch: 6| Step: 6
Training loss: 1.9683843000544394
Validation loss: 2.4857675580197474

Epoch: 6| Step: 7
Training loss: 2.50200534501027
Validation loss: 2.4750622799291118

Epoch: 6| Step: 8
Training loss: 2.63930988857452
Validation loss: 2.4727994165259615

Epoch: 6| Step: 9
Training loss: 2.2886240672743465
Validation loss: 2.4721395506114843

Epoch: 6| Step: 10
Training loss: 2.9465874864403028
Validation loss: 2.4774811381684767

Epoch: 6| Step: 11
Training loss: 2.008522116097015
Validation loss: 2.4720855423890487

Epoch: 6| Step: 12
Training loss: 2.831282902204309
Validation loss: 2.473487396925776

Epoch: 6| Step: 13
Training loss: 2.280270091673134
Validation loss: 2.465031378406392

Epoch: 150| Step: 0
Training loss: 2.7987970322494395
Validation loss: 2.466836678814811

Epoch: 6| Step: 1
Training loss: 2.425029644342506
Validation loss: 2.47949594560248

Epoch: 6| Step: 2
Training loss: 2.638338351683705
Validation loss: 2.4797201794251897

Epoch: 6| Step: 3
Training loss: 2.2653544297286596
Validation loss: 2.471235898842246

Epoch: 6| Step: 4
Training loss: 1.8421061024628067
Validation loss: 2.467605760234504

Epoch: 6| Step: 5
Training loss: 2.423121961936591
Validation loss: 2.466832538990262

Epoch: 6| Step: 6
Training loss: 2.3645950070623756
Validation loss: 2.4752843468700116

Epoch: 6| Step: 7
Training loss: 2.4729840632325057
Validation loss: 2.471349538645349

Epoch: 6| Step: 8
Training loss: 3.273442015724436
Validation loss: 2.4710121413873933

Epoch: 6| Step: 9
Training loss: 2.7601126353459096
Validation loss: 2.4792464962028937

Epoch: 6| Step: 10
Training loss: 1.949906527895452
Validation loss: 2.482892855893718

Epoch: 6| Step: 11
Training loss: 2.691262915438975
Validation loss: 2.478014563416345

Epoch: 6| Step: 12
Training loss: 2.3895137423088024
Validation loss: 2.4729576790892165

Epoch: 6| Step: 13
Training loss: 2.7098204320275965
Validation loss: 2.4702134442480963

Epoch: 151| Step: 0
Training loss: 2.2863622368595067
Validation loss: 2.4669019485933346

Epoch: 6| Step: 1
Training loss: 3.223129848012779
Validation loss: 2.468519288561852

Epoch: 6| Step: 2
Training loss: 2.0387605757822005
Validation loss: 2.4728499864449143

Epoch: 6| Step: 3
Training loss: 3.0231793118421364
Validation loss: 2.4631492081699338

Epoch: 6| Step: 4
Training loss: 2.7136456157862936
Validation loss: 2.47605760885094

Epoch: 6| Step: 5
Training loss: 2.1369918843937716
Validation loss: 2.49940604465744

Epoch: 6| Step: 6
Training loss: 2.6409619359050622
Validation loss: 2.496457689763717

Epoch: 6| Step: 7
Training loss: 2.4005346417969653
Validation loss: 2.5239211840276217

Epoch: 6| Step: 8
Training loss: 2.528424605262548
Validation loss: 2.5323195846778246

Epoch: 6| Step: 9
Training loss: 2.371750465712286
Validation loss: 2.501943595683453

Epoch: 6| Step: 10
Training loss: 1.7416506911036373
Validation loss: 2.503143448271536

Epoch: 6| Step: 11
Training loss: 2.5321312771312754
Validation loss: 2.477548765875961

Epoch: 6| Step: 12
Training loss: 2.322627803706565
Validation loss: 2.4752598895788593

Epoch: 6| Step: 13
Training loss: 2.9194601759248293
Validation loss: 2.468271128570198

Epoch: 152| Step: 0
Training loss: 1.8669465998944104
Validation loss: 2.4775043064597098

Epoch: 6| Step: 1
Training loss: 2.867755220424585
Validation loss: 2.472074194082776

Epoch: 6| Step: 2
Training loss: 2.681349169624464
Validation loss: 2.481486034296877

Epoch: 6| Step: 3
Training loss: 1.947582773841709
Validation loss: 2.487808398197982

Epoch: 6| Step: 4
Training loss: 3.060910182050124
Validation loss: 2.495782895499322

Epoch: 6| Step: 5
Training loss: 2.875296204276892
Validation loss: 2.496056625575678

Epoch: 6| Step: 6
Training loss: 2.2819825132938694
Validation loss: 2.495326219177432

Epoch: 6| Step: 7
Training loss: 2.330309975433312
Validation loss: 2.4994523243232183

Epoch: 6| Step: 8
Training loss: 2.9076344463722514
Validation loss: 2.498785025685248

Epoch: 6| Step: 9
Training loss: 2.194051685945011
Validation loss: 2.4963853612985947

Epoch: 6| Step: 10
Training loss: 2.658133702769542
Validation loss: 2.497312539746605

Epoch: 6| Step: 11
Training loss: 2.8256894578439455
Validation loss: 2.4956189073551465

Epoch: 6| Step: 12
Training loss: 2.3396641020676774
Validation loss: 2.4928375321183043

Epoch: 6| Step: 13
Training loss: 2.9847546081379592
Validation loss: 2.49189286199361

Epoch: 153| Step: 0
Training loss: 2.306437716817612
Validation loss: 2.4907399500824994

Epoch: 6| Step: 1
Training loss: 2.8189554515998028
Validation loss: 2.4868994308924455

Epoch: 6| Step: 2
Training loss: 2.3395033956602123
Validation loss: 2.4847213855521897

Epoch: 6| Step: 3
Training loss: 1.7883293948644172
Validation loss: 2.478486958992521

Epoch: 6| Step: 4
Training loss: 2.3976204440319857
Validation loss: 2.4812807371091807

Epoch: 6| Step: 5
Training loss: 2.8115749957281957
Validation loss: 2.476752208740178

Epoch: 6| Step: 6
Training loss: 2.898234974656602
Validation loss: 2.4731060661495414

Epoch: 6| Step: 7
Training loss: 2.143442568964178
Validation loss: 2.471367024320245

Epoch: 6| Step: 8
Training loss: 3.0546386402642156
Validation loss: 2.4749837791348024

Epoch: 6| Step: 9
Training loss: 2.768520585107428
Validation loss: 2.4727867055892854

Epoch: 6| Step: 10
Training loss: 2.8167934283863776
Validation loss: 2.4674687340226447

Epoch: 6| Step: 11
Training loss: 2.6851799287659315
Validation loss: 2.470487104177257

Epoch: 6| Step: 12
Training loss: 2.5222108298262405
Validation loss: 2.4588584554567907

Epoch: 6| Step: 13
Training loss: 2.066231675156177
Validation loss: 2.4607492687758175

Epoch: 154| Step: 0
Training loss: 3.014342672833926
Validation loss: 2.4619216323649407

Epoch: 6| Step: 1
Training loss: 2.847614889799516
Validation loss: 2.460888348446821

Epoch: 6| Step: 2
Training loss: 3.282906831514458
Validation loss: 2.4548462095861985

Epoch: 6| Step: 3
Training loss: 1.9301874540146349
Validation loss: 2.4523613261435266

Epoch: 6| Step: 4
Training loss: 2.7202649335301423
Validation loss: 2.4505580908726348

Epoch: 6| Step: 5
Training loss: 2.4259533414135515
Validation loss: 2.450222898581132

Epoch: 6| Step: 6
Training loss: 2.4721683062937996
Validation loss: 2.4493596362447883

Epoch: 6| Step: 7
Training loss: 2.3125406210141115
Validation loss: 2.4511194636401554

Epoch: 6| Step: 8
Training loss: 2.032303991497084
Validation loss: 2.4487841482671526

Epoch: 6| Step: 9
Training loss: 2.532902401947084
Validation loss: 2.4541765295930436

Epoch: 6| Step: 10
Training loss: 2.590552323705875
Validation loss: 2.453934108831439

Epoch: 6| Step: 11
Training loss: 1.8449723669117564
Validation loss: 2.456689063797834

Epoch: 6| Step: 12
Training loss: 2.84123487650601
Validation loss: 2.4550414971588594

Epoch: 6| Step: 13
Training loss: 2.044791289407388
Validation loss: 2.456157648293337

Epoch: 155| Step: 0
Training loss: 2.7145591970928695
Validation loss: 2.458873541255403

Epoch: 6| Step: 1
Training loss: 2.781233969652934
Validation loss: 2.455659209327288

Epoch: 6| Step: 2
Training loss: 3.054295351267365
Validation loss: 2.4587034388679547

Epoch: 6| Step: 3
Training loss: 2.2388101588632296
Validation loss: 2.4540454247345056

Epoch: 6| Step: 4
Training loss: 2.505024533789335
Validation loss: 2.456512833139172

Epoch: 6| Step: 5
Training loss: 2.6002308412925634
Validation loss: 2.4538900231318057

Epoch: 6| Step: 6
Training loss: 1.7340251810386007
Validation loss: 2.4607693569325404

Epoch: 6| Step: 7
Training loss: 3.266906778762297
Validation loss: 2.4566784531126404

Epoch: 6| Step: 8
Training loss: 2.620008536754416
Validation loss: 2.4624139302762966

Epoch: 6| Step: 9
Training loss: 1.9436670414433548
Validation loss: 2.4549803308448737

Epoch: 6| Step: 10
Training loss: 2.1111275633232225
Validation loss: 2.4631240173482434

Epoch: 6| Step: 11
Training loss: 2.8785680108927356
Validation loss: 2.4647881148437967

Epoch: 6| Step: 12
Training loss: 2.123091345411665
Validation loss: 2.4579435351978423

Epoch: 6| Step: 13
Training loss: 2.1434799424610698
Validation loss: 2.4672809044404787

Epoch: 156| Step: 0
Training loss: 2.1851714683660157
Validation loss: 2.4646526167851492

Epoch: 6| Step: 1
Training loss: 2.744860701926372
Validation loss: 2.4632286991313546

Epoch: 6| Step: 2
Training loss: 1.922885164090296
Validation loss: 2.471810548298162

Epoch: 6| Step: 3
Training loss: 2.6996153168908887
Validation loss: 2.4745936866188685

Epoch: 6| Step: 4
Training loss: 2.3905076141459567
Validation loss: 2.479054862528005

Epoch: 6| Step: 5
Training loss: 2.592487073698714
Validation loss: 2.480464376610933

Epoch: 6| Step: 6
Training loss: 2.8122170199979086
Validation loss: 2.479614190706779

Epoch: 6| Step: 7
Training loss: 1.7195789765559357
Validation loss: 2.4831381704034134

Epoch: 6| Step: 8
Training loss: 3.2188916221498487
Validation loss: 2.479088731283391

Epoch: 6| Step: 9
Training loss: 2.4810820054228473
Validation loss: 2.4873828873150403

Epoch: 6| Step: 10
Training loss: 3.117610893082083
Validation loss: 2.4773360527445907

Epoch: 6| Step: 11
Training loss: 2.194593209912632
Validation loss: 2.475746469603471

Epoch: 6| Step: 12
Training loss: 2.2354791220703456
Validation loss: 2.4703698457435297

Epoch: 6| Step: 13
Training loss: 2.3934849604796935
Validation loss: 2.4702123503839872

Epoch: 157| Step: 0
Training loss: 2.5818908930270648
Validation loss: 2.4583236133792767

Epoch: 6| Step: 1
Training loss: 2.4723608916273703
Validation loss: 2.461828266380398

Epoch: 6| Step: 2
Training loss: 2.051206126932346
Validation loss: 2.4628634550898583

Epoch: 6| Step: 3
Training loss: 1.7403708938498685
Validation loss: 2.4595372005554084

Epoch: 6| Step: 4
Training loss: 3.2520984330805276
Validation loss: 2.459113802645968

Epoch: 6| Step: 5
Training loss: 2.2812332779780955
Validation loss: 2.464721064025652

Epoch: 6| Step: 6
Training loss: 2.8413951471849686
Validation loss: 2.4633653724180173

Epoch: 6| Step: 7
Training loss: 2.995151734751442
Validation loss: 2.4648617574010814

Epoch: 6| Step: 8
Training loss: 3.011647501893138
Validation loss: 2.460702777951381

Epoch: 6| Step: 9
Training loss: 1.9132298741076512
Validation loss: 2.471875204479339

Epoch: 6| Step: 10
Training loss: 2.569712467362252
Validation loss: 2.46621532134165

Epoch: 6| Step: 11
Training loss: 2.196413354676954
Validation loss: 2.4685769966124083

Epoch: 6| Step: 12
Training loss: 2.0679042412669415
Validation loss: 2.468656610581556

Epoch: 6| Step: 13
Training loss: 2.4627866549104453
Validation loss: 2.466000655727191

Epoch: 158| Step: 0
Training loss: 2.7891555898822737
Validation loss: 2.4617070685161657

Epoch: 6| Step: 1
Training loss: 2.410388706564947
Validation loss: 2.464436855676641

Epoch: 6| Step: 2
Training loss: 1.9002296559926424
Validation loss: 2.461176655769377

Epoch: 6| Step: 3
Training loss: 2.667839348756121
Validation loss: 2.466225681536279

Epoch: 6| Step: 4
Training loss: 3.1062073794843115
Validation loss: 2.4603058019387234

Epoch: 6| Step: 5
Training loss: 1.7807722956911005
Validation loss: 2.462109136462887

Epoch: 6| Step: 6
Training loss: 2.49198266984354
Validation loss: 2.465567521334659

Epoch: 6| Step: 7
Training loss: 2.2232147212419284
Validation loss: 2.465979715866648

Epoch: 6| Step: 8
Training loss: 2.5582640457297092
Validation loss: 2.470013757762612

Epoch: 6| Step: 9
Training loss: 2.656219841280997
Validation loss: 2.4683937910284266

Epoch: 6| Step: 10
Training loss: 2.5515739295829625
Validation loss: 2.468405671391586

Epoch: 6| Step: 11
Training loss: 2.6478106001513178
Validation loss: 2.4690113492642793

Epoch: 6| Step: 12
Training loss: 2.573012027183085
Validation loss: 2.4654546223522615

Epoch: 6| Step: 13
Training loss: 2.204482938385953
Validation loss: 2.469772344476378

Epoch: 159| Step: 0
Training loss: 2.743857198719593
Validation loss: 2.4647734360456903

Epoch: 6| Step: 1
Training loss: 2.288532807708202
Validation loss: 2.4728119345653523

Epoch: 6| Step: 2
Training loss: 2.7807169199777046
Validation loss: 2.4716259264616194

Epoch: 6| Step: 3
Training loss: 2.2336156661888777
Validation loss: 2.470169029758573

Epoch: 6| Step: 4
Training loss: 1.7523870536770052
Validation loss: 2.4726587730422964

Epoch: 6| Step: 5
Training loss: 2.5683455434216436
Validation loss: 2.475448293577513

Epoch: 6| Step: 6
Training loss: 2.7152363664786883
Validation loss: 2.474097436039324

Epoch: 6| Step: 7
Training loss: 2.5019506473811894
Validation loss: 2.4716079201107917

Epoch: 6| Step: 8
Training loss: 2.8448956875039055
Validation loss: 2.471654639888972

Epoch: 6| Step: 9
Training loss: 2.0993007131404244
Validation loss: 2.4670603800923896

Epoch: 6| Step: 10
Training loss: 2.4978300213733178
Validation loss: 2.472302275396186

Epoch: 6| Step: 11
Training loss: 2.7798322857550724
Validation loss: 2.4703324714639923

Epoch: 6| Step: 12
Training loss: 2.5533038484084427
Validation loss: 2.4611220517667602

Epoch: 6| Step: 13
Training loss: 2.289776270902591
Validation loss: 2.4667837626354623

Epoch: 160| Step: 0
Training loss: 2.5690051061179324
Validation loss: 2.4679536058026263

Epoch: 6| Step: 1
Training loss: 2.649861450891978
Validation loss: 2.4619425018294083

Epoch: 6| Step: 2
Training loss: 2.483250201410477
Validation loss: 2.473787375449373

Epoch: 6| Step: 3
Training loss: 2.4069052460502793
Validation loss: 2.466356896160506

Epoch: 6| Step: 4
Training loss: 2.3503053669668468
Validation loss: 2.4689067678131313

Epoch: 6| Step: 5
Training loss: 2.6584635767426246
Validation loss: 2.471311101883262

Epoch: 6| Step: 6
Training loss: 2.855400115935159
Validation loss: 2.470114367150061

Epoch: 6| Step: 7
Training loss: 3.0603318616639643
Validation loss: 2.474298543459444

Epoch: 6| Step: 8
Training loss: 2.0790454862315015
Validation loss: 2.469114912402416

Epoch: 6| Step: 9
Training loss: 1.847738316590496
Validation loss: 2.473553101663036

Epoch: 6| Step: 10
Training loss: 2.4179760465989464
Validation loss: 2.4667686043974597

Epoch: 6| Step: 11
Training loss: 2.4402783527444756
Validation loss: 2.4736427239662353

Epoch: 6| Step: 12
Training loss: 2.6865582257607654
Validation loss: 2.471925254789969

Epoch: 6| Step: 13
Training loss: 2.165809889878486
Validation loss: 2.472547837100937

Epoch: 161| Step: 0
Training loss: 1.8215954888419883
Validation loss: 2.4770972860813334

Epoch: 6| Step: 1
Training loss: 2.2631215964573275
Validation loss: 2.4774156739440603

Epoch: 6| Step: 2
Training loss: 2.7439009918167723
Validation loss: 2.4743684984137637

Epoch: 6| Step: 3
Training loss: 2.4214062637060296
Validation loss: 2.468150810569773

Epoch: 6| Step: 4
Training loss: 2.0412840452234207
Validation loss: 2.461864446220493

Epoch: 6| Step: 5
Training loss: 2.2760956944760906
Validation loss: 2.480792631695936

Epoch: 6| Step: 6
Training loss: 2.066486205661605
Validation loss: 2.476919683938452

Epoch: 6| Step: 7
Training loss: 2.1986104825307375
Validation loss: 2.474544308516294

Epoch: 6| Step: 8
Training loss: 2.6041107985543666
Validation loss: 2.468809231719555

Epoch: 6| Step: 9
Training loss: 2.356941433346839
Validation loss: 2.480931644851625

Epoch: 6| Step: 10
Training loss: 2.9518851447673145
Validation loss: 2.4695601441815875

Epoch: 6| Step: 11
Training loss: 2.766799591119131
Validation loss: 2.4672632931741485

Epoch: 6| Step: 12
Training loss: 3.1175036736094253
Validation loss: 2.4799105278918585

Epoch: 6| Step: 13
Training loss: 2.879154355086757
Validation loss: 2.4725189251202755

Epoch: 162| Step: 0
Training loss: 2.189362741011858
Validation loss: 2.4643788007500023

Epoch: 6| Step: 1
Training loss: 2.519362333091286
Validation loss: 2.462285829967442

Epoch: 6| Step: 2
Training loss: 2.3157040848914523
Validation loss: 2.467263736074477

Epoch: 6| Step: 3
Training loss: 2.043340762167905
Validation loss: 2.484112227836303

Epoch: 6| Step: 4
Training loss: 2.0654989460905733
Validation loss: 2.473945462377429

Epoch: 6| Step: 5
Training loss: 2.709489595130305
Validation loss: 2.4819867953108807

Epoch: 6| Step: 6
Training loss: 2.8774476620101055
Validation loss: 2.486993141867366

Epoch: 6| Step: 7
Training loss: 3.0717769944786997
Validation loss: 2.4911107494625466

Epoch: 6| Step: 8
Training loss: 1.9139375606943327
Validation loss: 2.4895793058184577

Epoch: 6| Step: 9
Training loss: 2.3009084980463337
Validation loss: 2.4840556965172214

Epoch: 6| Step: 10
Training loss: 2.5169173054802045
Validation loss: 2.4809235724030074

Epoch: 6| Step: 11
Training loss: 2.8595769425252695
Validation loss: 2.483210036611347

Epoch: 6| Step: 12
Training loss: 2.4234785124446145
Validation loss: 2.4754350905949276

Epoch: 6| Step: 13
Training loss: 2.9619235608671475
Validation loss: 2.4681911238307532

Epoch: 163| Step: 0
Training loss: 2.8713830503693236
Validation loss: 2.472641336678302

Epoch: 6| Step: 1
Training loss: 1.8719277961940248
Validation loss: 2.4601582257111554

Epoch: 6| Step: 2
Training loss: 2.0991156986838964
Validation loss: 2.4665513851531227

Epoch: 6| Step: 3
Training loss: 2.438824807119063
Validation loss: 2.474884756532753

Epoch: 6| Step: 4
Training loss: 2.2630616518355273
Validation loss: 2.482815763016436

Epoch: 6| Step: 5
Training loss: 2.4493190130369933
Validation loss: 2.471469033683382

Epoch: 6| Step: 6
Training loss: 2.6565115407200857
Validation loss: 2.4669454796117676

Epoch: 6| Step: 7
Training loss: 2.8682485171214225
Validation loss: 2.47760256679746

Epoch: 6| Step: 8
Training loss: 2.5575600435996475
Validation loss: 2.4741504206455414

Epoch: 6| Step: 9
Training loss: 2.4382520640300056
Validation loss: 2.4819133086535374

Epoch: 6| Step: 10
Training loss: 2.3690870865498437
Validation loss: 2.4726724247456136

Epoch: 6| Step: 11
Training loss: 2.3626599212288992
Validation loss: 2.466367706877331

Epoch: 6| Step: 12
Training loss: 2.483505576729393
Validation loss: 2.4825027736764853

Epoch: 6| Step: 13
Training loss: 2.9640346624327014
Validation loss: 2.4780549888133647

Epoch: 164| Step: 0
Training loss: 2.9232969037188954
Validation loss: 2.477603360691117

Epoch: 6| Step: 1
Training loss: 2.4818987711659277
Validation loss: 2.488322897921341

Epoch: 6| Step: 2
Training loss: 2.097248627396081
Validation loss: 2.473841402737108

Epoch: 6| Step: 3
Training loss: 2.524403862406859
Validation loss: 2.4796667369349037

Epoch: 6| Step: 4
Training loss: 2.5621224101927704
Validation loss: 2.482869617852653

Epoch: 6| Step: 5
Training loss: 2.022533789353629
Validation loss: 2.482250192679664

Epoch: 6| Step: 6
Training loss: 2.1740300306686815
Validation loss: 2.4722713514392174

Epoch: 6| Step: 7
Training loss: 2.252072227749422
Validation loss: 2.471893224958453

Epoch: 6| Step: 8
Training loss: 2.346632850233535
Validation loss: 2.46721604733161

Epoch: 6| Step: 9
Training loss: 2.7267856451936194
Validation loss: 2.4747573900604096

Epoch: 6| Step: 10
Training loss: 3.239797276406645
Validation loss: 2.4753173521912792

Epoch: 6| Step: 11
Training loss: 2.1900041688156513
Validation loss: 2.4772955995754695

Epoch: 6| Step: 12
Training loss: 2.5357471594416134
Validation loss: 2.4811553485410895

Epoch: 6| Step: 13
Training loss: 2.515161127954381
Validation loss: 2.4892008313351464

Epoch: 165| Step: 0
Training loss: 2.576556196604109
Validation loss: 2.477242545895037

Epoch: 6| Step: 1
Training loss: 2.8925293294331276
Validation loss: 2.4792004964961962

Epoch: 6| Step: 2
Training loss: 2.630068835093778
Validation loss: 2.4837922986362386

Epoch: 6| Step: 3
Training loss: 2.5330835930381075
Validation loss: 2.4770321405723146

Epoch: 6| Step: 4
Training loss: 2.7070116975416716
Validation loss: 2.4865898000616733

Epoch: 6| Step: 5
Training loss: 1.9891016978007248
Validation loss: 2.4792035738551297

Epoch: 6| Step: 6
Training loss: 2.729929247208283
Validation loss: 2.4851569458633627

Epoch: 6| Step: 7
Training loss: 2.442007445509149
Validation loss: 2.475676441231199

Epoch: 6| Step: 8
Training loss: 2.3498183971604676
Validation loss: 2.483058924736418

Epoch: 6| Step: 9
Training loss: 2.372531009065435
Validation loss: 2.4653451513358218

Epoch: 6| Step: 10
Training loss: 2.5117762723657204
Validation loss: 2.4796993474070366

Epoch: 6| Step: 11
Training loss: 1.7220192075183167
Validation loss: 2.4790333036140213

Epoch: 6| Step: 12
Training loss: 2.115049288921625
Validation loss: 2.4737951017370485

Epoch: 6| Step: 13
Training loss: 2.8887865973563915
Validation loss: 2.473692537719477

Epoch: 166| Step: 0
Training loss: 2.2250474560423705
Validation loss: 2.4724069221547387

Epoch: 6| Step: 1
Training loss: 3.057856562262379
Validation loss: 2.478233583884729

Epoch: 6| Step: 2
Training loss: 2.478989624198691
Validation loss: 2.472075303197159

Epoch: 6| Step: 3
Training loss: 2.1790788135604475
Validation loss: 2.486979209274105

Epoch: 6| Step: 4
Training loss: 3.4839077623422794
Validation loss: 2.4777149363058

Epoch: 6| Step: 5
Training loss: 2.008345596254933
Validation loss: 2.4823925978011863

Epoch: 6| Step: 6
Training loss: 2.271775309856078
Validation loss: 2.4776701190203716

Epoch: 6| Step: 7
Training loss: 2.283931880195647
Validation loss: 2.484362204336807

Epoch: 6| Step: 8
Training loss: 2.5911028118811266
Validation loss: 2.4798895132028322

Epoch: 6| Step: 9
Training loss: 2.4419892858509216
Validation loss: 2.4700213028044473

Epoch: 6| Step: 10
Training loss: 2.066425402720196
Validation loss: 2.4783289934037804

Epoch: 6| Step: 11
Training loss: 2.4078910483111793
Validation loss: 2.47747072078727

Epoch: 6| Step: 12
Training loss: 2.3671474138649002
Validation loss: 2.477651234414183

Epoch: 6| Step: 13
Training loss: 2.472458576900682
Validation loss: 2.4806542995468903

Epoch: 167| Step: 0
Training loss: 1.994977007855313
Validation loss: 2.476017632298914

Epoch: 6| Step: 1
Training loss: 2.493202791910553
Validation loss: 2.4841640550799515

Epoch: 6| Step: 2
Training loss: 2.7038333383697464
Validation loss: 2.4799138767659965

Epoch: 6| Step: 3
Training loss: 3.2225969158837073
Validation loss: 2.4838050652389634

Epoch: 6| Step: 4
Training loss: 2.494029067254784
Validation loss: 2.4808584953350192

Epoch: 6| Step: 5
Training loss: 2.274068738208815
Validation loss: 2.4743566948583835

Epoch: 6| Step: 6
Training loss: 2.89148101503834
Validation loss: 2.48175196658819

Epoch: 6| Step: 7
Training loss: 2.4697130473631788
Validation loss: 2.479577452555893

Epoch: 6| Step: 8
Training loss: 2.6102845211532153
Validation loss: 2.466706907313542

Epoch: 6| Step: 9
Training loss: 2.2644115486954295
Validation loss: 2.476920165218805

Epoch: 6| Step: 10
Training loss: 2.471792157469265
Validation loss: 2.480387744932531

Epoch: 6| Step: 11
Training loss: 1.9003735626803417
Validation loss: 2.4707707452378855

Epoch: 6| Step: 12
Training loss: 2.0880114357149173
Validation loss: 2.485259116701195

Epoch: 6| Step: 13
Training loss: 2.532242191971145
Validation loss: 2.47795875091078

Epoch: 168| Step: 0
Training loss: 2.503588961346876
Validation loss: 2.4729150814403753

Epoch: 6| Step: 1
Training loss: 2.894837809814117
Validation loss: 2.4755814350997642

Epoch: 6| Step: 2
Training loss: 2.7514690463449494
Validation loss: 2.4762406726721187

Epoch: 6| Step: 3
Training loss: 2.843249601835872
Validation loss: 2.4684604040334794

Epoch: 6| Step: 4
Training loss: 1.8502753568328432
Validation loss: 2.4799165045875124

Epoch: 6| Step: 5
Training loss: 2.4275318653596343
Validation loss: 2.4723108903173885

Epoch: 6| Step: 6
Training loss: 2.0111099655307343
Validation loss: 2.4740687991459556

Epoch: 6| Step: 7
Training loss: 2.1981148532506336
Validation loss: 2.4773103725976218

Epoch: 6| Step: 8
Training loss: 1.7980929020525112
Validation loss: 2.4732692736001263

Epoch: 6| Step: 9
Training loss: 2.405364430944778
Validation loss: 2.472058569983806

Epoch: 6| Step: 10
Training loss: 2.353340971864978
Validation loss: 2.4792137836071495

Epoch: 6| Step: 11
Training loss: 2.5948194574016146
Validation loss: 2.4828085609438397

Epoch: 6| Step: 12
Training loss: 2.8562092584087435
Validation loss: 2.4770660610468385

Epoch: 6| Step: 13
Training loss: 2.818416814291458
Validation loss: 2.4693644760861497

Epoch: 169| Step: 0
Training loss: 2.18295469810742
Validation loss: 2.458493927920264

Epoch: 6| Step: 1
Training loss: 2.4727052319151244
Validation loss: 2.4725824378207206

Epoch: 6| Step: 2
Training loss: 2.8248734302355185
Validation loss: 2.4748839617670217

Epoch: 6| Step: 3
Training loss: 2.38257895403888
Validation loss: 2.4714123980646323

Epoch: 6| Step: 4
Training loss: 2.1700324056992026
Validation loss: 2.4782795053351694

Epoch: 6| Step: 5
Training loss: 2.041074731874409
Validation loss: 2.4713340948728146

Epoch: 6| Step: 6
Training loss: 2.7434921421545426
Validation loss: 2.4681670872891455

Epoch: 6| Step: 7
Training loss: 3.010828819352465
Validation loss: 2.475706335547164

Epoch: 6| Step: 8
Training loss: 2.3894536757831024
Validation loss: 2.4717894406306686

Epoch: 6| Step: 9
Training loss: 2.1556080401586533
Validation loss: 2.4676229101177687

Epoch: 6| Step: 10
Training loss: 2.6304225318231387
Validation loss: 2.4753408858724013

Epoch: 6| Step: 11
Training loss: 2.5732124457187755
Validation loss: 2.4613998059581697

Epoch: 6| Step: 12
Training loss: 2.40442955215004
Validation loss: 2.470018358792998

Epoch: 6| Step: 13
Training loss: 2.5591095615559087
Validation loss: 2.4677361285629065

Epoch: 170| Step: 0
Training loss: 2.114717400972083
Validation loss: 2.4911837095943206

Epoch: 6| Step: 1
Training loss: 2.873817034616106
Validation loss: 2.4859007462830216

Epoch: 6| Step: 2
Training loss: 2.6122956519995606
Validation loss: 2.4724019719855184

Epoch: 6| Step: 3
Training loss: 2.849416599459509
Validation loss: 2.4837397756943647

Epoch: 6| Step: 4
Training loss: 2.3791830468713457
Validation loss: 2.485366351590126

Epoch: 6| Step: 5
Training loss: 2.542847614362324
Validation loss: 2.4849876112344482

Epoch: 6| Step: 6
Training loss: 2.4890022610584746
Validation loss: 2.479997709309125

Epoch: 6| Step: 7
Training loss: 2.536784773126892
Validation loss: 2.479792016496249

Epoch: 6| Step: 8
Training loss: 1.8695780880931472
Validation loss: 2.475487540933662

Epoch: 6| Step: 9
Training loss: 2.21766410366644
Validation loss: 2.4861330893295093

Epoch: 6| Step: 10
Training loss: 2.2292032209114696
Validation loss: 2.4739187511824614

Epoch: 6| Step: 11
Training loss: 2.703763059601303
Validation loss: 2.482162081822707

Epoch: 6| Step: 12
Training loss: 2.6453142232602
Validation loss: 2.4864543634027934

Epoch: 6| Step: 13
Training loss: 2.4200647295026863
Validation loss: 2.486390421951695

Epoch: 171| Step: 0
Training loss: 1.5072602362564351
Validation loss: 2.4871304344522662

Epoch: 6| Step: 1
Training loss: 2.75724946669358
Validation loss: 2.477332459785641

Epoch: 6| Step: 2
Training loss: 2.6845074337852632
Validation loss: 2.4818412607987033

Epoch: 6| Step: 3
Training loss: 2.66870107136884
Validation loss: 2.4826682123854784

Epoch: 6| Step: 4
Training loss: 2.601430162151159
Validation loss: 2.4872819859287842

Epoch: 6| Step: 5
Training loss: 2.9132933227910884
Validation loss: 2.478975750814173

Epoch: 6| Step: 6
Training loss: 2.3329022440731655
Validation loss: 2.4860547862666698

Epoch: 6| Step: 7
Training loss: 1.715234803121744
Validation loss: 2.4853119432930053

Epoch: 6| Step: 8
Training loss: 2.6708823696957276
Validation loss: 2.480790677543747

Epoch: 6| Step: 9
Training loss: 2.328379777114251
Validation loss: 2.480559644260243

Epoch: 6| Step: 10
Training loss: 2.097761723372527
Validation loss: 2.479323267331691

Epoch: 6| Step: 11
Training loss: 3.0103679155848404
Validation loss: 2.490957165708526

Epoch: 6| Step: 12
Training loss: 1.9327926054958342
Validation loss: 2.4977868615647454

Epoch: 6| Step: 13
Training loss: 3.120474323017312
Validation loss: 2.474803127139504

Epoch: 172| Step: 0
Training loss: 2.4388520818996944
Validation loss: 2.490542037009692

Epoch: 6| Step: 1
Training loss: 1.9667828738368638
Validation loss: 2.4767559308908096

Epoch: 6| Step: 2
Training loss: 2.0979027629897926
Validation loss: 2.484928253437809

Epoch: 6| Step: 3
Training loss: 2.5315673064103956
Validation loss: 2.4832248304545685

Epoch: 6| Step: 4
Training loss: 2.3038991840677188
Validation loss: 2.4899163176430146

Epoch: 6| Step: 5
Training loss: 2.7155927544227865
Validation loss: 2.4932517207995377

Epoch: 6| Step: 6
Training loss: 3.022960378767661
Validation loss: 2.4944675423483273

Epoch: 6| Step: 7
Training loss: 2.870721702084741
Validation loss: 2.4938133620496026

Epoch: 6| Step: 8
Training loss: 2.8663678153937258
Validation loss: 2.4880914141603205

Epoch: 6| Step: 9
Training loss: 1.88771684676753
Validation loss: 2.5013677034734703

Epoch: 6| Step: 10
Training loss: 2.6206716547242235
Validation loss: 2.491833270019887

Epoch: 6| Step: 11
Training loss: 2.5914780191368463
Validation loss: 2.490956766901658

Epoch: 6| Step: 12
Training loss: 2.648820427412407
Validation loss: 2.494026788888369

Epoch: 6| Step: 13
Training loss: 2.2011062355036715
Validation loss: 2.48110087192395

Epoch: 173| Step: 0
Training loss: 2.3218875766582965
Validation loss: 2.487887604385629

Epoch: 6| Step: 1
Training loss: 3.166681557335895
Validation loss: 2.487363860783501

Epoch: 6| Step: 2
Training loss: 2.5274646853914455
Validation loss: 2.4834058458720523

Epoch: 6| Step: 3
Training loss: 2.517667521686662
Validation loss: 2.4753418410204917

Epoch: 6| Step: 4
Training loss: 2.243113682022941
Validation loss: 2.48973619052982

Epoch: 6| Step: 5
Training loss: 2.335217010738756
Validation loss: 2.479404106844348

Epoch: 6| Step: 6
Training loss: 2.3587878172349117
Validation loss: 2.4837046744555016

Epoch: 6| Step: 7
Training loss: 2.366003968133122
Validation loss: 2.4758125637839177

Epoch: 6| Step: 8
Training loss: 2.4505551234787615
Validation loss: 2.484668386478032

Epoch: 6| Step: 9
Training loss: 2.622571912130467
Validation loss: 2.4782707828904926

Epoch: 6| Step: 10
Training loss: 2.533451206409705
Validation loss: 2.476458823102717

Epoch: 6| Step: 11
Training loss: 2.4638557690852143
Validation loss: 2.4789835651217613

Epoch: 6| Step: 12
Training loss: 2.495644494641421
Validation loss: 2.4763463484563757

Epoch: 6| Step: 13
Training loss: 2.084064800280058
Validation loss: 2.480192394330877

Epoch: 174| Step: 0
Training loss: 2.952601310677907
Validation loss: 2.468279250447752

Epoch: 6| Step: 1
Training loss: 2.058510128979413
Validation loss: 2.473885357767589

Epoch: 6| Step: 2
Training loss: 3.042003316843606
Validation loss: 2.480584289583233

Epoch: 6| Step: 3
Training loss: 1.8029821355805316
Validation loss: 2.481205956350804

Epoch: 6| Step: 4
Training loss: 2.7965259014466786
Validation loss: 2.4831061011772277

Epoch: 6| Step: 5
Training loss: 2.4858773924959494
Validation loss: 2.5114350739621227

Epoch: 6| Step: 6
Training loss: 2.8108297686795036
Validation loss: 2.5068210055980593

Epoch: 6| Step: 7
Training loss: 2.535116938916612
Validation loss: 2.524024257410346

Epoch: 6| Step: 8
Training loss: 2.905782354323572
Validation loss: 2.5077908555599087

Epoch: 6| Step: 9
Training loss: 2.6356376183406556
Validation loss: 2.475202281148131

Epoch: 6| Step: 10
Training loss: 1.7561292260614876
Validation loss: 2.473691654220821

Epoch: 6| Step: 11
Training loss: 2.1798047543506835
Validation loss: 2.4786275282764554

Epoch: 6| Step: 12
Training loss: 2.6227114555996236
Validation loss: 2.4767435290482243

Epoch: 6| Step: 13
Training loss: 2.264952671659697
Validation loss: 2.49063521207202

Epoch: 175| Step: 0
Training loss: 3.042536850567392
Validation loss: 2.4959650220396767

Epoch: 6| Step: 1
Training loss: 2.649038781071928
Validation loss: 2.4776013478895322

Epoch: 6| Step: 2
Training loss: 2.821332160723514
Validation loss: 2.483080512710152

Epoch: 6| Step: 3
Training loss: 2.268718948361937
Validation loss: 2.4742791914756888

Epoch: 6| Step: 4
Training loss: 2.011616587590983
Validation loss: 2.4794245086283673

Epoch: 6| Step: 5
Training loss: 2.550350415705537
Validation loss: 2.4897362144699646

Epoch: 6| Step: 6
Training loss: 2.890418792792749
Validation loss: 2.4851615668260627

Epoch: 6| Step: 7
Training loss: 2.4619949248855804
Validation loss: 2.4841645189608923

Epoch: 6| Step: 8
Training loss: 2.901882047626154
Validation loss: 2.484229061550704

Epoch: 6| Step: 9
Training loss: 2.4218838599258303
Validation loss: 2.493754580819393

Epoch: 6| Step: 10
Training loss: 2.299504338634667
Validation loss: 2.484981790651142

Epoch: 6| Step: 11
Training loss: 2.5532158862294305
Validation loss: 2.4873456967800682

Epoch: 6| Step: 12
Training loss: 2.2490541801388857
Validation loss: 2.4751977941038623

Epoch: 6| Step: 13
Training loss: 2.3916247901396037
Validation loss: 2.480072694733343

Epoch: 176| Step: 0
Training loss: 2.93051567070583
Validation loss: 2.4765729613138343

Epoch: 6| Step: 1
Training loss: 2.4865470364338966
Validation loss: 2.480708153252774

Epoch: 6| Step: 2
Training loss: 1.7637848168389743
Validation loss: 2.4765430694363366

Epoch: 6| Step: 3
Training loss: 2.392568160055779
Validation loss: 2.474253656261351

Epoch: 6| Step: 4
Training loss: 2.751598760397347
Validation loss: 2.4827494391404636

Epoch: 6| Step: 5
Training loss: 3.1879960216463887
Validation loss: 2.479780318877249

Epoch: 6| Step: 6
Training loss: 2.575913469081466
Validation loss: 2.488704755146046

Epoch: 6| Step: 7
Training loss: 1.9552167144037547
Validation loss: 2.489416433403445

Epoch: 6| Step: 8
Training loss: 2.704325150448471
Validation loss: 2.4867731511665787

Epoch: 6| Step: 9
Training loss: 2.3954691955713296
Validation loss: 2.4914976977039704

Epoch: 6| Step: 10
Training loss: 2.0236286087809825
Validation loss: 2.4974830673198727

Epoch: 6| Step: 11
Training loss: 2.6361928005533763
Validation loss: 2.476027726800302

Epoch: 6| Step: 12
Training loss: 2.595267529818567
Validation loss: 2.487927294378198

Epoch: 6| Step: 13
Training loss: 2.5233616300816286
Validation loss: 2.4846818202670327

Epoch: 177| Step: 0
Training loss: 2.71194157983091
Validation loss: 2.48599381557881

Epoch: 6| Step: 1
Training loss: 2.3304099320736618
Validation loss: 2.4894911032049922

Epoch: 6| Step: 2
Training loss: 2.1475459797991667
Validation loss: 2.484270105606692

Epoch: 6| Step: 3
Training loss: 2.4972394961263094
Validation loss: 2.4844673347508617

Epoch: 6| Step: 4
Training loss: 2.5874871626825744
Validation loss: 2.487461659760586

Epoch: 6| Step: 5
Training loss: 2.4866867346205264
Validation loss: 2.472341050341394

Epoch: 6| Step: 6
Training loss: 2.4691946860491836
Validation loss: 2.4800231132788992

Epoch: 6| Step: 7
Training loss: 2.370436047708188
Validation loss: 2.47584154162549

Epoch: 6| Step: 8
Training loss: 2.3092907468218318
Validation loss: 2.4672855186197906

Epoch: 6| Step: 9
Training loss: 2.946018609924997
Validation loss: 2.472654482261825

Epoch: 6| Step: 10
Training loss: 1.785366722070116
Validation loss: 2.4771647718777747

Epoch: 6| Step: 11
Training loss: 2.5606018107069293
Validation loss: 2.474716156118697

Epoch: 6| Step: 12
Training loss: 2.7346475519857294
Validation loss: 2.47533951334803

Epoch: 6| Step: 13
Training loss: 2.421127499310997
Validation loss: 2.476065905790292

Epoch: 178| Step: 0
Training loss: 1.9691746571632032
Validation loss: 2.4805628801242197

Epoch: 6| Step: 1
Training loss: 2.7065630090843174
Validation loss: 2.4866455866335206

Epoch: 6| Step: 2
Training loss: 2.7976449940105352
Validation loss: 2.479947461397214

Epoch: 6| Step: 3
Training loss: 3.0866004714568986
Validation loss: 2.4743193406508466

Epoch: 6| Step: 4
Training loss: 2.168112040415278
Validation loss: 2.4870807939839086

Epoch: 6| Step: 5
Training loss: 2.491111020634461
Validation loss: 2.496458008106203

Epoch: 6| Step: 6
Training loss: 2.727507331901227
Validation loss: 2.4767413791752766

Epoch: 6| Step: 7
Training loss: 2.438872806618667
Validation loss: 2.4770196599024836

Epoch: 6| Step: 8
Training loss: 2.151772535789126
Validation loss: 2.4835200568113045

Epoch: 6| Step: 9
Training loss: 1.9239772061129867
Validation loss: 2.4728451817846504

Epoch: 6| Step: 10
Training loss: 2.4692949104114197
Validation loss: 2.4784424843403543

Epoch: 6| Step: 11
Training loss: 2.660850490327982
Validation loss: 2.477389689869357

Epoch: 6| Step: 12
Training loss: 2.696336811420739
Validation loss: 2.4844189685953366

Epoch: 6| Step: 13
Training loss: 2.0049299038551345
Validation loss: 2.4746110128805254

Epoch: 179| Step: 0
Training loss: 2.7278544253552415
Validation loss: 2.4685516760634423

Epoch: 6| Step: 1
Training loss: 1.8021389359144842
Validation loss: 2.476948985720135

Epoch: 6| Step: 2
Training loss: 2.5116612263168956
Validation loss: 2.4773503924484968

Epoch: 6| Step: 3
Training loss: 2.959498717673672
Validation loss: 2.4764042913081865

Epoch: 6| Step: 4
Training loss: 2.6530196349808173
Validation loss: 2.4750898216466224

Epoch: 6| Step: 5
Training loss: 3.2709077150346872
Validation loss: 2.47801752999904

Epoch: 6| Step: 6
Training loss: 2.647348365655836
Validation loss: 2.4756035778412837

Epoch: 6| Step: 7
Training loss: 2.2048806844595097
Validation loss: 2.4766621534512634

Epoch: 6| Step: 8
Training loss: 2.2478284953457917
Validation loss: 2.4770050295256505

Epoch: 6| Step: 9
Training loss: 2.3229474349329187
Validation loss: 2.477238672089734

Epoch: 6| Step: 10
Training loss: 2.179959406693515
Validation loss: 2.4820630654359266

Epoch: 6| Step: 11
Training loss: 2.176842586463301
Validation loss: 2.4902554061101294

Epoch: 6| Step: 12
Training loss: 2.103963961767642
Validation loss: 2.482451255898592

Epoch: 6| Step: 13
Training loss: 2.3216248984686247
Validation loss: 2.4920860756193184

Epoch: 180| Step: 0
Training loss: 2.9700664613011436
Validation loss: 2.482740124207111

Epoch: 6| Step: 1
Training loss: 2.7295238076768635
Validation loss: 2.4851681864600805

Epoch: 6| Step: 2
Training loss: 2.3549650295763085
Validation loss: 2.483875488351848

Epoch: 6| Step: 3
Training loss: 3.3617216209064256
Validation loss: 2.4963208464869955

Epoch: 6| Step: 4
Training loss: 1.8671968212453658
Validation loss: 2.486907627747801

Epoch: 6| Step: 5
Training loss: 2.2207928776112875
Validation loss: 2.4827770316245497

Epoch: 6| Step: 6
Training loss: 1.7055976486948492
Validation loss: 2.4849363448588555

Epoch: 6| Step: 7
Training loss: 2.539605842555252
Validation loss: 2.5001454549436817

Epoch: 6| Step: 8
Training loss: 2.0373911822695816
Validation loss: 2.485356470888858

Epoch: 6| Step: 9
Training loss: 2.313511395302882
Validation loss: 2.49184452833979

Epoch: 6| Step: 10
Training loss: 2.3426669861053844
Validation loss: 2.487332133598655

Epoch: 6| Step: 11
Training loss: 2.7167496611978534
Validation loss: 2.4878622168329922

Epoch: 6| Step: 12
Training loss: 2.4747818282327585
Validation loss: 2.472416943002675

Epoch: 6| Step: 13
Training loss: 2.415766734792735
Validation loss: 2.4797606891871276

Epoch: 181| Step: 0
Training loss: 2.268940151012034
Validation loss: 2.484983293770115

Epoch: 6| Step: 1
Training loss: 2.471162028157842
Validation loss: 2.4828863262181993

Epoch: 6| Step: 2
Training loss: 2.430530659381578
Validation loss: 2.4786198491156433

Epoch: 6| Step: 3
Training loss: 2.588319355701141
Validation loss: 2.4787640819062995

Epoch: 6| Step: 4
Training loss: 2.4765204296690375
Validation loss: 2.4843124045877487

Epoch: 6| Step: 5
Training loss: 2.063918348501167
Validation loss: 2.485801223417912

Epoch: 6| Step: 6
Training loss: 2.3517646575921893
Validation loss: 2.4821923142524596

Epoch: 6| Step: 7
Training loss: 3.2172347270506125
Validation loss: 2.4773430301276647

Epoch: 6| Step: 8
Training loss: 2.244543240306361
Validation loss: 2.476865555344725

Epoch: 6| Step: 9
Training loss: 2.425553020853227
Validation loss: 2.4894649738177637

Epoch: 6| Step: 10
Training loss: 2.4721989743667203
Validation loss: 2.4832000513174273

Epoch: 6| Step: 11
Training loss: 2.5120346321585743
Validation loss: 2.485812557013001

Epoch: 6| Step: 12
Training loss: 2.612072127498659
Validation loss: 2.484369082013965

Epoch: 6| Step: 13
Training loss: 1.897340685321953
Validation loss: 2.48214964295597

Epoch: 182| Step: 0
Training loss: 2.2618887776452987
Validation loss: 2.4987554313291493

Epoch: 6| Step: 1
Training loss: 2.8020560583514897
Validation loss: 2.482670181065348

Epoch: 6| Step: 2
Training loss: 2.5451431470982513
Validation loss: 2.4852556391243574

Epoch: 6| Step: 3
Training loss: 2.5443426543100487
Validation loss: 2.501572829444999

Epoch: 6| Step: 4
Training loss: 2.1268136755537523
Validation loss: 2.4840614232911857

Epoch: 6| Step: 5
Training loss: 2.112657268019756
Validation loss: 2.499460273337944

Epoch: 6| Step: 6
Training loss: 2.2730748257620523
Validation loss: 2.487746392320377

Epoch: 6| Step: 7
Training loss: 2.936516130322219
Validation loss: 2.489430096963366

Epoch: 6| Step: 8
Training loss: 2.0623107592145327
Validation loss: 2.496720419926002

Epoch: 6| Step: 9
Training loss: 2.7366336758104532
Validation loss: 2.4858816764377303

Epoch: 6| Step: 10
Training loss: 2.4402207082454552
Validation loss: 2.4764482730551918

Epoch: 6| Step: 11
Training loss: 2.430058000288393
Validation loss: 2.4855643090785695

Epoch: 6| Step: 12
Training loss: 2.1567915084450973
Validation loss: 2.4812250861543417

Epoch: 6| Step: 13
Training loss: 2.476550562495875
Validation loss: 2.4814153512073958

Epoch: 183| Step: 0
Training loss: 2.5963244243564807
Validation loss: 2.484647388040919

Epoch: 6| Step: 1
Training loss: 1.8588281035544525
Validation loss: 2.489577829416062

Epoch: 6| Step: 2
Training loss: 2.64164705078672
Validation loss: 2.485597865322896

Epoch: 6| Step: 3
Training loss: 1.9685409677131287
Validation loss: 2.4907704692559647

Epoch: 6| Step: 4
Training loss: 2.310294259225215
Validation loss: 2.489559897042471

Epoch: 6| Step: 5
Training loss: 1.9498287614805254
Validation loss: 2.500011380487606

Epoch: 6| Step: 6
Training loss: 2.550721990063453
Validation loss: 2.4812309315650998

Epoch: 6| Step: 7
Training loss: 2.792994615128267
Validation loss: 2.4800423082849785

Epoch: 6| Step: 8
Training loss: 2.578233936204658
Validation loss: 2.4824240199534238

Epoch: 6| Step: 9
Training loss: 2.3436654647840705
Validation loss: 2.4822075944164226

Epoch: 6| Step: 10
Training loss: 2.995618163239708
Validation loss: 2.4878546699956092

Epoch: 6| Step: 11
Training loss: 2.0405106937471285
Validation loss: 2.496801873872138

Epoch: 6| Step: 12
Training loss: 2.7855847471811064
Validation loss: 2.4899649839607396

Epoch: 6| Step: 13
Training loss: 2.496313524197249
Validation loss: 2.5060905177489587

Epoch: 184| Step: 0
Training loss: 2.8106756439294838
Validation loss: 2.5054191981745375

Epoch: 6| Step: 1
Training loss: 1.7737240328779897
Validation loss: 2.514173306018162

Epoch: 6| Step: 2
Training loss: 2.319285875282079
Validation loss: 2.5080630136703053

Epoch: 6| Step: 3
Training loss: 2.4240419599344705
Validation loss: 2.505021345386437

Epoch: 6| Step: 4
Training loss: 2.3104280004289284
Validation loss: 2.4829139972008147

Epoch: 6| Step: 5
Training loss: 2.8594323658009198
Validation loss: 2.483020981297344

Epoch: 6| Step: 6
Training loss: 3.303154916907521
Validation loss: 2.488082262962721

Epoch: 6| Step: 7
Training loss: 2.41586976779054
Validation loss: 2.4860066747721574

Epoch: 6| Step: 8
Training loss: 2.6401025379381835
Validation loss: 2.4881451867479347

Epoch: 6| Step: 9
Training loss: 2.50039745986021
Validation loss: 2.483547976730911

Epoch: 6| Step: 10
Training loss: 2.467365504409234
Validation loss: 2.4724649814353965

Epoch: 6| Step: 11
Training loss: 2.2552368890541703
Validation loss: 2.483783451566033

Epoch: 6| Step: 12
Training loss: 2.469842306964303
Validation loss: 2.4862210914205924

Epoch: 6| Step: 13
Training loss: 2.0379328028164143
Validation loss: 2.4806728329143177

Epoch: 185| Step: 0
Training loss: 2.800763799168743
Validation loss: 2.4842540303654705

Epoch: 6| Step: 1
Training loss: 2.1343720152626
Validation loss: 2.4904821973168327

Epoch: 6| Step: 2
Training loss: 2.2025961816161446
Validation loss: 2.4931474389511816

Epoch: 6| Step: 3
Training loss: 2.4821905933271045
Validation loss: 2.5007581038209783

Epoch: 6| Step: 4
Training loss: 2.6868091848671036
Validation loss: 2.496919498357419

Epoch: 6| Step: 5
Training loss: 2.666352213757143
Validation loss: 2.4839640663381775

Epoch: 6| Step: 6
Training loss: 2.363259660606449
Validation loss: 2.5005443616121794

Epoch: 6| Step: 7
Training loss: 2.588015916778343
Validation loss: 2.502367035543761

Epoch: 6| Step: 8
Training loss: 2.5606707114528953
Validation loss: 2.5033265075979965

Epoch: 6| Step: 9
Training loss: 1.9222086795092166
Validation loss: 2.495368267050052

Epoch: 6| Step: 10
Training loss: 2.391954040098565
Validation loss: 2.513829967049458

Epoch: 6| Step: 11
Training loss: 2.2291047155975794
Validation loss: 2.512972094338258

Epoch: 6| Step: 12
Training loss: 2.536549800865922
Validation loss: 2.5084074588185596

Epoch: 6| Step: 13
Training loss: 2.834823179298092
Validation loss: 2.506362416575514

Epoch: 186| Step: 0
Training loss: 3.0166818614879123
Validation loss: 2.4944888563622776

Epoch: 6| Step: 1
Training loss: 2.180088894982692
Validation loss: 2.499063777461347

Epoch: 6| Step: 2
Training loss: 2.340172644221093
Validation loss: 2.5015367711920478

Epoch: 6| Step: 3
Training loss: 2.5221772722989977
Validation loss: 2.49673993219187

Epoch: 6| Step: 4
Training loss: 1.8525574662617086
Validation loss: 2.4944145432596163

Epoch: 6| Step: 5
Training loss: 2.2443242010424354
Validation loss: 2.495907151197839

Epoch: 6| Step: 6
Training loss: 2.0849507601844697
Validation loss: 2.4940355996224763

Epoch: 6| Step: 7
Training loss: 2.155348990342891
Validation loss: 2.5022311427162727

Epoch: 6| Step: 8
Training loss: 2.4444310363729334
Validation loss: 2.500855760339251

Epoch: 6| Step: 9
Training loss: 2.3772764840138625
Validation loss: 2.5037368661577597

Epoch: 6| Step: 10
Training loss: 2.7313164744373206
Validation loss: 2.501168693124611

Epoch: 6| Step: 11
Training loss: 2.821933776986841
Validation loss: 2.486761758032721

Epoch: 6| Step: 12
Training loss: 2.9071330708010623
Validation loss: 2.507736490113797

Epoch: 6| Step: 13
Training loss: 2.2992238601073014
Validation loss: 2.513465428266557

Epoch: 187| Step: 0
Training loss: 2.2974927421845375
Validation loss: 2.5188316694828092

Epoch: 6| Step: 1
Training loss: 2.7160053649647105
Validation loss: 2.511646243997262

Epoch: 6| Step: 2
Training loss: 2.2083766381198333
Validation loss: 2.5025219435719

Epoch: 6| Step: 3
Training loss: 2.527693616656069
Validation loss: 2.5026308918987064

Epoch: 6| Step: 4
Training loss: 2.319604014112667
Validation loss: 2.520788276416817

Epoch: 6| Step: 5
Training loss: 2.223806288179938
Validation loss: 2.5052445872347673

Epoch: 6| Step: 6
Training loss: 2.349768578517704
Validation loss: 2.5006548977422973

Epoch: 6| Step: 7
Training loss: 2.8794958372700363
Validation loss: 2.5041936192725553

Epoch: 6| Step: 8
Training loss: 2.1717611598635664
Validation loss: 2.489217760600164

Epoch: 6| Step: 9
Training loss: 2.207847133831876
Validation loss: 2.481265547324924

Epoch: 6| Step: 10
Training loss: 3.095352528451424
Validation loss: 2.4864783989541874

Epoch: 6| Step: 11
Training loss: 2.402758753216741
Validation loss: 2.500876805407393

Epoch: 6| Step: 12
Training loss: 2.476230924052399
Validation loss: 2.4985704387822363

Epoch: 6| Step: 13
Training loss: 2.3424888778308492
Validation loss: 2.4954320580765845

Epoch: 188| Step: 0
Training loss: 1.9550594668112555
Validation loss: 2.489909606898902

Epoch: 6| Step: 1
Training loss: 2.9796499825062526
Validation loss: 2.492863323294054

Epoch: 6| Step: 2
Training loss: 2.239486609447635
Validation loss: 2.500188168755703

Epoch: 6| Step: 3
Training loss: 2.5351473157163933
Validation loss: 2.48826690941176

Epoch: 6| Step: 4
Training loss: 2.9531870033173484
Validation loss: 2.4913031145920077

Epoch: 6| Step: 5
Training loss: 2.810531181413577
Validation loss: 2.4879820767081084

Epoch: 6| Step: 6
Training loss: 2.570250072706697
Validation loss: 2.500534262790279

Epoch: 6| Step: 7
Training loss: 2.3174535947102055
Validation loss: 2.499098774275154

Epoch: 6| Step: 8
Training loss: 1.9086492479635195
Validation loss: 2.493275284418655

Epoch: 6| Step: 9
Training loss: 1.8521045905296127
Validation loss: 2.507324662497932

Epoch: 6| Step: 10
Training loss: 2.663990187572473
Validation loss: 2.510091583815223

Epoch: 6| Step: 11
Training loss: 2.948165523597481
Validation loss: 2.4945563336091

Epoch: 6| Step: 12
Training loss: 2.005495627163343
Validation loss: 2.4830452261175733

Epoch: 6| Step: 13
Training loss: 2.232919285478413
Validation loss: 2.4867756119488043

Epoch: 189| Step: 0
Training loss: 1.4809788451709058
Validation loss: 2.4867784402474453

Epoch: 6| Step: 1
Training loss: 2.3548332103457694
Validation loss: 2.4880462327895376

Epoch: 6| Step: 2
Training loss: 2.4483494044694614
Validation loss: 2.483295534046785

Epoch: 6| Step: 3
Training loss: 2.977997841777237
Validation loss: 2.4917027032812733

Epoch: 6| Step: 4
Training loss: 2.0368358395497097
Validation loss: 2.4912321437968403

Epoch: 6| Step: 5
Training loss: 2.9364128535983056
Validation loss: 2.4858053316522857

Epoch: 6| Step: 6
Training loss: 2.9638692789840233
Validation loss: 2.484366610850759

Epoch: 6| Step: 7
Training loss: 2.4056157849264914
Validation loss: 2.4907592379883585

Epoch: 6| Step: 8
Training loss: 2.296285436831311
Validation loss: 2.488116360185985

Epoch: 6| Step: 9
Training loss: 2.5541353241416793
Validation loss: 2.497797090809069

Epoch: 6| Step: 10
Training loss: 2.1719478896829103
Validation loss: 2.496571112621994

Epoch: 6| Step: 11
Training loss: 2.180933879691324
Validation loss: 2.4938282921658184

Epoch: 6| Step: 12
Training loss: 2.4434678795352136
Validation loss: 2.494027983836049

Epoch: 6| Step: 13
Training loss: 2.5090603679876455
Validation loss: 2.5063703991643194

Epoch: 190| Step: 0
Training loss: 2.3704406743860287
Validation loss: 2.5123178450819075

Epoch: 6| Step: 1
Training loss: 2.4427558769582487
Validation loss: 2.4961401706731032

Epoch: 6| Step: 2
Training loss: 2.814443552502588
Validation loss: 2.5058183991275036

Epoch: 6| Step: 3
Training loss: 2.488953791445745
Validation loss: 2.489201701347329

Epoch: 6| Step: 4
Training loss: 1.9333101315037884
Validation loss: 2.499409963597422

Epoch: 6| Step: 5
Training loss: 2.922194029990749
Validation loss: 2.500050591910577

Epoch: 6| Step: 6
Training loss: 2.360252772873166
Validation loss: 2.495510727714808

Epoch: 6| Step: 7
Training loss: 2.3209331465875866
Validation loss: 2.4995312251235093

Epoch: 6| Step: 8
Training loss: 2.5981431088930282
Validation loss: 2.5030379116292716

Epoch: 6| Step: 9
Training loss: 1.770432669996026
Validation loss: 2.499997552234723

Epoch: 6| Step: 10
Training loss: 2.433140107761282
Validation loss: 2.496629493302521

Epoch: 6| Step: 11
Training loss: 2.2916751052238693
Validation loss: 2.5078339858040852

Epoch: 6| Step: 12
Training loss: 2.2368324477397663
Validation loss: 2.4967277887686343

Epoch: 6| Step: 13
Training loss: 2.8815524854776635
Validation loss: 2.4937592814566765

Epoch: 191| Step: 0
Training loss: 2.665773530245374
Validation loss: 2.494336372725726

Epoch: 6| Step: 1
Training loss: 2.062490521033497
Validation loss: 2.4972924034385096

Epoch: 6| Step: 2
Training loss: 2.459086081997354
Validation loss: 2.5001344326750403

Epoch: 6| Step: 3
Training loss: 2.688707745662078
Validation loss: 2.4933213192944406

Epoch: 6| Step: 4
Training loss: 2.2441489117422067
Validation loss: 2.5017794951584

Epoch: 6| Step: 5
Training loss: 2.083833583535314
Validation loss: 2.50438267881103

Epoch: 6| Step: 6
Training loss: 2.3809953608493717
Validation loss: 2.5000178495405674

Epoch: 6| Step: 7
Training loss: 2.85726617478864
Validation loss: 2.5015098462985796

Epoch: 6| Step: 8
Training loss: 2.273373842167456
Validation loss: 2.5205009546079458

Epoch: 6| Step: 9
Training loss: 2.866806462302149
Validation loss: 2.5141253058706887

Epoch: 6| Step: 10
Training loss: 2.8148456540658455
Validation loss: 2.5132077610416967

Epoch: 6| Step: 11
Training loss: 2.1946167844655613
Validation loss: 2.5009696351630275

Epoch: 6| Step: 12
Training loss: 2.263492080091504
Validation loss: 2.487587233632018

Epoch: 6| Step: 13
Training loss: 2.011200299167535
Validation loss: 2.5016288060731635

Epoch: 192| Step: 0
Training loss: 2.029463466528801
Validation loss: 2.500841380632523

Epoch: 6| Step: 1
Training loss: 2.0326312723970297
Validation loss: 2.498021725907539

Epoch: 6| Step: 2
Training loss: 2.8848292628496157
Validation loss: 2.4982126840577012

Epoch: 6| Step: 3
Training loss: 2.416951053153759
Validation loss: 2.4927135936672524

Epoch: 6| Step: 4
Training loss: 2.1951915123883867
Validation loss: 2.4872746210536376

Epoch: 6| Step: 5
Training loss: 2.3349284668774266
Validation loss: 2.4822431490488515

Epoch: 6| Step: 6
Training loss: 2.486615975641382
Validation loss: 2.485529233606204

Epoch: 6| Step: 7
Training loss: 3.05984974062137
Validation loss: 2.4916960930335903

Epoch: 6| Step: 8
Training loss: 2.0275288462438885
Validation loss: 2.4921183800753623

Epoch: 6| Step: 9
Training loss: 2.2324827491290256
Validation loss: 2.4864028076398634

Epoch: 6| Step: 10
Training loss: 2.308261079265621
Validation loss: 2.4842698336880535

Epoch: 6| Step: 11
Training loss: 1.9787068552312668
Validation loss: 2.4997378211828734

Epoch: 6| Step: 12
Training loss: 2.6161258195256716
Validation loss: 2.501926363410536

Epoch: 6| Step: 13
Training loss: 3.0514263882534816
Validation loss: 2.508339989823373

Epoch: 193| Step: 0
Training loss: 2.1083807968808106
Validation loss: 2.513403502006739

Epoch: 6| Step: 1
Training loss: 2.428651349571836
Validation loss: 2.5080093829391643

Epoch: 6| Step: 2
Training loss: 2.606724563680869
Validation loss: 2.5040005702337

Epoch: 6| Step: 3
Training loss: 2.308650550208081
Validation loss: 2.4994639537231995

Epoch: 6| Step: 4
Training loss: 2.2234989975381647
Validation loss: 2.5021936646931007

Epoch: 6| Step: 5
Training loss: 2.3977560759017846
Validation loss: 2.5162550648567077

Epoch: 6| Step: 6
Training loss: 2.4534159688231956
Validation loss: 2.512439772609969

Epoch: 6| Step: 7
Training loss: 2.4908600623273993
Validation loss: 2.513347297506555

Epoch: 6| Step: 8
Training loss: 2.3857118071387395
Validation loss: 2.509519477381026

Epoch: 6| Step: 9
Training loss: 2.1107758568148354
Validation loss: 2.493459124001434

Epoch: 6| Step: 10
Training loss: 3.128026183679755
Validation loss: 2.500064642388353

Epoch: 6| Step: 11
Training loss: 2.1973549244006625
Validation loss: 2.4956811475340883

Epoch: 6| Step: 12
Training loss: 2.7986660981646443
Validation loss: 2.5068619492314035

Epoch: 6| Step: 13
Training loss: 2.0734600971430774
Validation loss: 2.5052830505860757

Epoch: 194| Step: 0
Training loss: 2.701151927066166
Validation loss: 2.5044233449774667

Epoch: 6| Step: 1
Training loss: 2.4241729663160747
Validation loss: 2.5069495723832773

Epoch: 6| Step: 2
Training loss: 2.7590395869380453
Validation loss: 2.492285109694181

Epoch: 6| Step: 3
Training loss: 2.063194851436751
Validation loss: 2.507839499830318

Epoch: 6| Step: 4
Training loss: 1.96007388121654
Validation loss: 2.5045561757823553

Epoch: 6| Step: 5
Training loss: 2.36853552982223
Validation loss: 2.5082920998345157

Epoch: 6| Step: 6
Training loss: 2.357009914909811
Validation loss: 2.5149022045296276

Epoch: 6| Step: 7
Training loss: 2.54850015101321
Validation loss: 2.501521918853024

Epoch: 6| Step: 8
Training loss: 2.433169895936713
Validation loss: 2.5031841742561167

Epoch: 6| Step: 9
Training loss: 2.194052989935303
Validation loss: 2.5056686031423214

Epoch: 6| Step: 10
Training loss: 2.202781488138318
Validation loss: 2.5006582665068002

Epoch: 6| Step: 11
Training loss: 2.898452470848719
Validation loss: 2.514444330814524

Epoch: 6| Step: 12
Training loss: 2.507269969973625
Validation loss: 2.5085919001899266

Epoch: 6| Step: 13
Training loss: 2.399436717689138
Validation loss: 2.50833972051405

Epoch: 195| Step: 0
Training loss: 2.698663900184847
Validation loss: 2.5317224289322096

Epoch: 6| Step: 1
Training loss: 1.8096684008805675
Validation loss: 2.5286305771173327

Epoch: 6| Step: 2
Training loss: 2.849915914800917
Validation loss: 2.5635592977100154

Epoch: 6| Step: 3
Training loss: 2.46354522597289
Validation loss: 2.550623267180267

Epoch: 6| Step: 4
Training loss: 2.639746706111084
Validation loss: 2.53729515188412

Epoch: 6| Step: 5
Training loss: 2.3390933761648363
Validation loss: 2.5183217302185943

Epoch: 6| Step: 6
Training loss: 2.1921877088159203
Validation loss: 2.5184064932201644

Epoch: 6| Step: 7
Training loss: 2.4838437646024247
Validation loss: 2.5122582789051306

Epoch: 6| Step: 8
Training loss: 2.7419779553462824
Validation loss: 2.526843438603609

Epoch: 6| Step: 9
Training loss: 2.0287419020138002
Validation loss: 2.5094213979445046

Epoch: 6| Step: 10
Training loss: 2.0746553755300123
Validation loss: 2.5065836842054745

Epoch: 6| Step: 11
Training loss: 1.8933457903161175
Validation loss: 2.5132659687134598

Epoch: 6| Step: 12
Training loss: 2.4771134879734125
Validation loss: 2.519437377127208

Epoch: 6| Step: 13
Training loss: 2.895997040509983
Validation loss: 2.5128397716593147

Epoch: 196| Step: 0
Training loss: 2.0819316217515227
Validation loss: 2.500230714960404

Epoch: 6| Step: 1
Training loss: 3.0324858672841857
Validation loss: 2.5116817141383585

Epoch: 6| Step: 2
Training loss: 1.5450823636615774
Validation loss: 2.519963095864025

Epoch: 6| Step: 3
Training loss: 2.3629380158161903
Validation loss: 2.5212350215287267

Epoch: 6| Step: 4
Training loss: 2.3296616366695035
Validation loss: 2.5189233958444

Epoch: 6| Step: 5
Training loss: 2.9296080718399593
Validation loss: 2.519863909069116

Epoch: 6| Step: 6
Training loss: 2.3149042776268733
Validation loss: 2.5148467287565603

Epoch: 6| Step: 7
Training loss: 2.03419281455798
Validation loss: 2.5278691448797845

Epoch: 6| Step: 8
Training loss: 2.2369764429385945
Validation loss: 2.518714287365074

Epoch: 6| Step: 9
Training loss: 2.8182917829353626
Validation loss: 2.5136681284724656

Epoch: 6| Step: 10
Training loss: 1.6909972791057695
Validation loss: 2.5250058413271175

Epoch: 6| Step: 11
Training loss: 2.9926505664243073
Validation loss: 2.5185625762243973

Epoch: 6| Step: 12
Training loss: 1.9486392579780267
Validation loss: 2.525111411881734

Epoch: 6| Step: 13
Training loss: 2.7111462779274422
Validation loss: 2.540885724542731

Epoch: 197| Step: 0
Training loss: 2.0559151466686347
Validation loss: 2.529883969778696

Epoch: 6| Step: 1
Training loss: 2.60654629639987
Validation loss: 2.5233136157479485

Epoch: 6| Step: 2
Training loss: 2.745065510147031
Validation loss: 2.51899854760496

Epoch: 6| Step: 3
Training loss: 2.4450757579339197
Validation loss: 2.5321010524658534

Epoch: 6| Step: 4
Training loss: 1.9155860287061042
Validation loss: 2.5135152432543757

Epoch: 6| Step: 5
Training loss: 2.4042022711256723
Validation loss: 2.51704292537302

Epoch: 6| Step: 6
Training loss: 2.850329490488021
Validation loss: 2.517414806860243

Epoch: 6| Step: 7
Training loss: 2.6626543815162558
Validation loss: 2.5023308061179006

Epoch: 6| Step: 8
Training loss: 2.5263849293926692
Validation loss: 2.509754051251078

Epoch: 6| Step: 9
Training loss: 2.262981582728483
Validation loss: 2.4995368687484136

Epoch: 6| Step: 10
Training loss: 2.2875891621207027
Validation loss: 2.5018285422038367

Epoch: 6| Step: 11
Training loss: 2.343358121535546
Validation loss: 2.497557543682575

Epoch: 6| Step: 12
Training loss: 2.52967917598229
Validation loss: 2.491938723082733

Epoch: 6| Step: 13
Training loss: 1.814991061291082
Validation loss: 2.5102797084398176

Epoch: 198| Step: 0
Training loss: 3.0699670806014456
Validation loss: 2.512866717473445

Epoch: 6| Step: 1
Training loss: 2.466584233461675
Validation loss: 2.5229617084626903

Epoch: 6| Step: 2
Training loss: 2.144212820735262
Validation loss: 2.52767261407471

Epoch: 6| Step: 3
Training loss: 2.0524436389094
Validation loss: 2.5402338935139457

Epoch: 6| Step: 4
Training loss: 2.371403229326892
Validation loss: 2.523942036772252

Epoch: 6| Step: 5
Training loss: 2.437314539969769
Validation loss: 2.5211453100258905

Epoch: 6| Step: 6
Training loss: 2.449781143378253
Validation loss: 2.516648946998648

Epoch: 6| Step: 7
Training loss: 2.315848426490551
Validation loss: 2.5142602634509355

Epoch: 6| Step: 8
Training loss: 2.7411708414361367
Validation loss: 2.5209695658376923

Epoch: 6| Step: 9
Training loss: 1.7295695911665034
Validation loss: 2.522193712392192

Epoch: 6| Step: 10
Training loss: 2.5240343645782195
Validation loss: 2.5166129468611746

Epoch: 6| Step: 11
Training loss: 2.0991362566510103
Validation loss: 2.5109402333505626

Epoch: 6| Step: 12
Training loss: 2.674144650902908
Validation loss: 2.5142184208959075

Epoch: 6| Step: 13
Training loss: 2.1848732572411427
Validation loss: 2.508058577493807

Epoch: 199| Step: 0
Training loss: 2.6560659905818764
Validation loss: 2.530862127028701

Epoch: 6| Step: 1
Training loss: 2.544623754902896
Validation loss: 2.529521603217253

Epoch: 6| Step: 2
Training loss: 2.7588941489941226
Validation loss: 2.515010541504495

Epoch: 6| Step: 3
Training loss: 1.9778993932905808
Validation loss: 2.5193680190407064

Epoch: 6| Step: 4
Training loss: 2.6673359825669665
Validation loss: 2.5083923620162154

Epoch: 6| Step: 5
Training loss: 2.233327126375749
Validation loss: 2.5321793282709795

Epoch: 6| Step: 6
Training loss: 1.8661130742753627
Validation loss: 2.5303545337295246

Epoch: 6| Step: 7
Training loss: 2.724208132277622
Validation loss: 2.533467267494712

Epoch: 6| Step: 8
Training loss: 2.1570833226833255
Validation loss: 2.540253376575608

Epoch: 6| Step: 9
Training loss: 2.1151319146107257
Validation loss: 2.5411278721624915

Epoch: 6| Step: 10
Training loss: 2.189454649517199
Validation loss: 2.5248643523941885

Epoch: 6| Step: 11
Training loss: 2.191747737395584
Validation loss: 2.534324960336129

Epoch: 6| Step: 12
Training loss: 2.2518311572564707
Validation loss: 2.5260336387480495

Epoch: 6| Step: 13
Training loss: 2.7817816922598966
Validation loss: 2.5126977320813992

Epoch: 200| Step: 0
Training loss: 2.3262040578824315
Validation loss: 2.5303450485572716

Epoch: 6| Step: 1
Training loss: 1.7830061704536337
Validation loss: 2.5143925903928843

Epoch: 6| Step: 2
Training loss: 2.538913382039455
Validation loss: 2.5190524176070204

Epoch: 6| Step: 3
Training loss: 2.1748167465005817
Validation loss: 2.518616455551331

Epoch: 6| Step: 4
Training loss: 2.4256222192108954
Validation loss: 2.519725435250447

Epoch: 6| Step: 5
Training loss: 2.313107178853115
Validation loss: 2.517563477782579

Epoch: 6| Step: 6
Training loss: 2.0369031441480314
Validation loss: 2.514478702680766

Epoch: 6| Step: 7
Training loss: 2.052142173065531
Validation loss: 2.522763125732155

Epoch: 6| Step: 8
Training loss: 2.017618184462845
Validation loss: 2.5236902415465536

Epoch: 6| Step: 9
Training loss: 2.208465164376197
Validation loss: 2.5147426155503485

Epoch: 6| Step: 10
Training loss: 2.462847643483991
Validation loss: 2.514962245286168

Epoch: 6| Step: 11
Training loss: 3.1819099326343245
Validation loss: 2.52034391165652

Epoch: 6| Step: 12
Training loss: 2.8260178276844146
Validation loss: 2.5403061075810975

Epoch: 6| Step: 13
Training loss: 2.6661080033503075
Validation loss: 2.5493672196641346

Epoch: 201| Step: 0
Training loss: 2.9204497915849292
Validation loss: 2.550162613738864

Epoch: 6| Step: 1
Training loss: 2.3582289988305405
Validation loss: 2.579507507169353

Epoch: 6| Step: 2
Training loss: 2.1435392270584255
Validation loss: 2.5384261209214944

Epoch: 6| Step: 3
Training loss: 2.7674557935428465
Validation loss: 2.5294469447642216

Epoch: 6| Step: 4
Training loss: 2.3501539098782374
Validation loss: 2.508594996934056

Epoch: 6| Step: 5
Training loss: 2.376315405124616
Validation loss: 2.5144640690149194

Epoch: 6| Step: 6
Training loss: 1.365614809395415
Validation loss: 2.506219359834484

Epoch: 6| Step: 7
Training loss: 3.1302225342151786
Validation loss: 2.510768720599644

Epoch: 6| Step: 8
Training loss: 2.518500538628835
Validation loss: 2.5065781674166705

Epoch: 6| Step: 9
Training loss: 2.761233361307614
Validation loss: 2.4999543662674726

Epoch: 6| Step: 10
Training loss: 2.2442494126155834
Validation loss: 2.497306071641634

Epoch: 6| Step: 11
Training loss: 2.0320350890396504
Validation loss: 2.521410053791884

Epoch: 6| Step: 12
Training loss: 2.62222870360757
Validation loss: 2.505058162468297

Epoch: 6| Step: 13
Training loss: 1.7665563506946058
Validation loss: 2.502180245518664

Epoch: 202| Step: 0
Training loss: 2.0849033035066986
Validation loss: 2.515174604261517

Epoch: 6| Step: 1
Training loss: 2.313013689877197
Validation loss: 2.516803425952991

Epoch: 6| Step: 2
Training loss: 2.6665855832488345
Validation loss: 2.5115609838792743

Epoch: 6| Step: 3
Training loss: 2.7635797384155674
Validation loss: 2.5220578164822793

Epoch: 6| Step: 4
Training loss: 2.4892547475706905
Validation loss: 2.5157362950823066

Epoch: 6| Step: 5
Training loss: 2.0734139873031
Validation loss: 2.5151155639145846

Epoch: 6| Step: 6
Training loss: 3.0302858687406147
Validation loss: 2.508732707102296

Epoch: 6| Step: 7
Training loss: 2.7255496354455
Validation loss: 2.5071670953486977

Epoch: 6| Step: 8
Training loss: 2.220170439457953
Validation loss: 2.496073643658628

Epoch: 6| Step: 9
Training loss: 2.5543307834024938
Validation loss: 2.499982452330994

Epoch: 6| Step: 10
Training loss: 2.1991149986281213
Validation loss: 2.4961128851008367

Epoch: 6| Step: 11
Training loss: 2.2498068196759906
Validation loss: 2.5182254216594653

Epoch: 6| Step: 12
Training loss: 1.5440675323966373
Validation loss: 2.526998630958572

Epoch: 6| Step: 13
Training loss: 2.4187203812079443
Validation loss: 2.5364910387336703

Epoch: 203| Step: 0
Training loss: 2.6409274497995927
Validation loss: 2.5405667040628686

Epoch: 6| Step: 1
Training loss: 2.134104354923882
Validation loss: 2.538602018415057

Epoch: 6| Step: 2
Training loss: 2.4988200264030676
Validation loss: 2.545143381287995

Epoch: 6| Step: 3
Training loss: 2.8220213893293358
Validation loss: 2.5448100450195374

Epoch: 6| Step: 4
Training loss: 2.2721457465664776
Validation loss: 2.5343474129877723

Epoch: 6| Step: 5
Training loss: 2.4502742263535064
Validation loss: 2.515831743357576

Epoch: 6| Step: 6
Training loss: 1.9398145079665177
Validation loss: 2.5168337001274415

Epoch: 6| Step: 7
Training loss: 1.8563607410830865
Validation loss: 2.5033217455582633

Epoch: 6| Step: 8
Training loss: 2.7695958139402244
Validation loss: 2.4911602139215736

Epoch: 6| Step: 9
Training loss: 2.8365948548362345
Validation loss: 2.4915522340717504

Epoch: 6| Step: 10
Training loss: 2.470612704465742
Validation loss: 2.4922518826482447

Epoch: 6| Step: 11
Training loss: 2.210784367626477
Validation loss: 2.501588968124642

Epoch: 6| Step: 12
Training loss: 2.531706592210671
Validation loss: 2.4996243194595937

Epoch: 6| Step: 13
Training loss: 2.515267293388506
Validation loss: 2.502637108074258

Epoch: 204| Step: 0
Training loss: 2.2297471143402543
Validation loss: 2.5130849457832682

Epoch: 6| Step: 1
Training loss: 2.6339267444373347
Validation loss: 2.516495682316328

Epoch: 6| Step: 2
Training loss: 2.1532684942744735
Validation loss: 2.5149832592123245

Epoch: 6| Step: 3
Training loss: 2.709160477924426
Validation loss: 2.5165222337047424

Epoch: 6| Step: 4
Training loss: 2.0175657170404397
Validation loss: 2.5245822636480897

Epoch: 6| Step: 5
Training loss: 1.7952293489620639
Validation loss: 2.5361114410960983

Epoch: 6| Step: 6
Training loss: 2.9108345214188978
Validation loss: 2.526391142171375

Epoch: 6| Step: 7
Training loss: 1.9168998396750074
Validation loss: 2.5393916303105892

Epoch: 6| Step: 8
Training loss: 1.9344982151112982
Validation loss: 2.5368307938114945

Epoch: 6| Step: 9
Training loss: 2.3522123028311737
Validation loss: 2.5452311853104903

Epoch: 6| Step: 10
Training loss: 2.0232492013163976
Validation loss: 2.5562627759395022

Epoch: 6| Step: 11
Training loss: 2.6321040708727277
Validation loss: 2.5476585072329296

Epoch: 6| Step: 12
Training loss: 2.6565445680532487
Validation loss: 2.534905921399184

Epoch: 6| Step: 13
Training loss: 2.868292239698468
Validation loss: 2.5376534176003798

Epoch: 205| Step: 0
Training loss: 1.6040181012737567
Validation loss: 2.531626983324867

Epoch: 6| Step: 1
Training loss: 1.9225358524625507
Validation loss: 2.5342463274495093

Epoch: 6| Step: 2
Training loss: 2.455016554953391
Validation loss: 2.5174725463289525

Epoch: 6| Step: 3
Training loss: 3.460460483580596
Validation loss: 2.529646927066596

Epoch: 6| Step: 4
Training loss: 2.478509660958644
Validation loss: 2.5155836619264256

Epoch: 6| Step: 5
Training loss: 1.9195506609198014
Validation loss: 2.524297750660058

Epoch: 6| Step: 6
Training loss: 2.522562069994048
Validation loss: 2.5236576326801665

Epoch: 6| Step: 7
Training loss: 2.4139004254794023
Validation loss: 2.5089090392104416

Epoch: 6| Step: 8
Training loss: 2.163185685658637
Validation loss: 2.5359934564239284

Epoch: 6| Step: 9
Training loss: 2.2989446955629087
Validation loss: 2.5217660224117875

Epoch: 6| Step: 10
Training loss: 1.7482900439716351
Validation loss: 2.5630975817330324

Epoch: 6| Step: 11
Training loss: 2.457594765963544
Validation loss: 2.543342340219264

Epoch: 6| Step: 12
Training loss: 2.924748277836658
Validation loss: 2.5546592531966046

Epoch: 6| Step: 13
Training loss: 2.377881861524955
Validation loss: 2.550321941684677

Epoch: 206| Step: 0
Training loss: 2.2682189824386274
Validation loss: 2.5631004808455096

Epoch: 6| Step: 1
Training loss: 2.3970303958816452
Validation loss: 2.5461218252679574

Epoch: 6| Step: 2
Training loss: 2.6974865093017595
Validation loss: 2.5178980933508117

Epoch: 6| Step: 3
Training loss: 2.501795696037531
Validation loss: 2.513534198301444

Epoch: 6| Step: 4
Training loss: 1.8709984358878353
Validation loss: 2.518450238459558

Epoch: 6| Step: 5
Training loss: 2.386387478928131
Validation loss: 2.5337312256227733

Epoch: 6| Step: 6
Training loss: 2.459292682593356
Validation loss: 2.5242234493185505

Epoch: 6| Step: 7
Training loss: 2.4173823864324584
Validation loss: 2.527612466495223

Epoch: 6| Step: 8
Training loss: 2.1553794098465877
Validation loss: 2.5268718548180455

Epoch: 6| Step: 9
Training loss: 2.3547923064116394
Validation loss: 2.5263927150243197

Epoch: 6| Step: 10
Training loss: 2.7063861204805724
Validation loss: 2.5194330082944236

Epoch: 6| Step: 11
Training loss: 2.591076495650222
Validation loss: 2.544618593863525

Epoch: 6| Step: 12
Training loss: 1.7140349477189645
Validation loss: 2.5560415181373353

Epoch: 6| Step: 13
Training loss: 2.6613693272189445
Validation loss: 2.5533437665505394

Epoch: 207| Step: 0
Training loss: 2.4077613344889195
Validation loss: 2.565308853477067

Epoch: 6| Step: 1
Training loss: 2.194884886449493
Validation loss: 2.550596159392047

Epoch: 6| Step: 2
Training loss: 1.6889897587557732
Validation loss: 2.5371185686288955

Epoch: 6| Step: 3
Training loss: 2.1699060530476277
Validation loss: 2.5179062366369522

Epoch: 6| Step: 4
Training loss: 2.0672869761457755
Validation loss: 2.521202317863261

Epoch: 6| Step: 5
Training loss: 2.718177822895309
Validation loss: 2.51031201620662

Epoch: 6| Step: 6
Training loss: 2.6675740923329454
Validation loss: 2.5112444250292723

Epoch: 6| Step: 7
Training loss: 3.276793296154809
Validation loss: 2.517000592311627

Epoch: 6| Step: 8
Training loss: 2.5265214811733387
Validation loss: 2.5161418660239927

Epoch: 6| Step: 9
Training loss: 2.383029615172575
Validation loss: 2.526105244154342

Epoch: 6| Step: 10
Training loss: 2.307970921496867
Validation loss: 2.52171722132837

Epoch: 6| Step: 11
Training loss: 2.336944975212123
Validation loss: 2.526638933078204

Epoch: 6| Step: 12
Training loss: 2.1999265571819957
Validation loss: 2.5292497510214553

Epoch: 6| Step: 13
Training loss: 2.30421996466013
Validation loss: 2.54265758604933

Epoch: 208| Step: 0
Training loss: 1.9737084934347002
Validation loss: 2.5574524797168228

Epoch: 6| Step: 1
Training loss: 2.376625508633738
Validation loss: 2.55236032241409

Epoch: 6| Step: 2
Training loss: 2.3076640934319785
Validation loss: 2.5592580694829277

Epoch: 6| Step: 3
Training loss: 2.807482333717914
Validation loss: 2.5491385357358225

Epoch: 6| Step: 4
Training loss: 2.3705252605348335
Validation loss: 2.560443844093581

Epoch: 6| Step: 5
Training loss: 2.318503551290399
Validation loss: 2.5593980762526627

Epoch: 6| Step: 6
Training loss: 2.0372515708326517
Validation loss: 2.553899769946435

Epoch: 6| Step: 7
Training loss: 1.7354066546984401
Validation loss: 2.5677782530224547

Epoch: 6| Step: 8
Training loss: 2.34249437394581
Validation loss: 2.5634765314980155

Epoch: 6| Step: 9
Training loss: 3.061412384598687
Validation loss: 2.569347753223338

Epoch: 6| Step: 10
Training loss: 2.129228424052528
Validation loss: 2.5712909478744352

Epoch: 6| Step: 11
Training loss: 2.567010120432824
Validation loss: 2.5365344015904583

Epoch: 6| Step: 12
Training loss: 2.6336798894573037
Validation loss: 2.5300158957659273

Epoch: 6| Step: 13
Training loss: 1.9496592786421452
Validation loss: 2.522510606348369

Epoch: 209| Step: 0
Training loss: 2.7560839544611273
Validation loss: 2.520025207832446

Epoch: 6| Step: 1
Training loss: 2.827804800211313
Validation loss: 2.5198748529230013

Epoch: 6| Step: 2
Training loss: 1.8339269139527383
Validation loss: 2.5194847161778964

Epoch: 6| Step: 3
Training loss: 1.5033648420501187
Validation loss: 2.5193909598630233

Epoch: 6| Step: 4
Training loss: 2.4121214337375703
Validation loss: 2.5208487759792333

Epoch: 6| Step: 5
Training loss: 2.752322949805425
Validation loss: 2.5232972538164735

Epoch: 6| Step: 6
Training loss: 2.086443778901576
Validation loss: 2.521983953341711

Epoch: 6| Step: 7
Training loss: 2.2172623065912767
Validation loss: 2.526760830051413

Epoch: 6| Step: 8
Training loss: 2.136110655122181
Validation loss: 2.5247240752986086

Epoch: 6| Step: 9
Training loss: 2.7292353691791438
Validation loss: 2.5401078952691285

Epoch: 6| Step: 10
Training loss: 2.1203441103080802
Validation loss: 2.55059461704371

Epoch: 6| Step: 11
Training loss: 2.9290458281667386
Validation loss: 2.5589531798915024

Epoch: 6| Step: 12
Training loss: 2.5223490254162027
Validation loss: 2.54256056611857

Epoch: 6| Step: 13
Training loss: 2.409254798908923
Validation loss: 2.533754318690309

Epoch: 210| Step: 0
Training loss: 2.146704623417916
Validation loss: 2.5305992828491934

Epoch: 6| Step: 1
Training loss: 2.1637601675657447
Validation loss: 2.5280370768507066

Epoch: 6| Step: 2
Training loss: 2.543679227477117
Validation loss: 2.5230616711863183

Epoch: 6| Step: 3
Training loss: 2.171059764199351
Validation loss: 2.5141398624824296

Epoch: 6| Step: 4
Training loss: 2.435556664099213
Validation loss: 2.521460547064989

Epoch: 6| Step: 5
Training loss: 2.1650089989666763
Validation loss: 2.5241621805501495

Epoch: 6| Step: 6
Training loss: 2.666460764406196
Validation loss: 2.517914087939253

Epoch: 6| Step: 7
Training loss: 2.1470295679679774
Validation loss: 2.5207950074195957

Epoch: 6| Step: 8
Training loss: 2.5379930327299545
Validation loss: 2.5157903455018555

Epoch: 6| Step: 9
Training loss: 2.539093862486594
Validation loss: 2.5227761834048152

Epoch: 6| Step: 10
Training loss: 2.40653316268406
Validation loss: 2.5299814287139846

Epoch: 6| Step: 11
Training loss: 2.296134466048436
Validation loss: 2.542144852874301

Epoch: 6| Step: 12
Training loss: 2.4186736575358228
Validation loss: 2.535601497945861

Epoch: 6| Step: 13
Training loss: 2.7958250152721877
Validation loss: 2.546685880726669

Epoch: 211| Step: 0
Training loss: 2.5405411860118043
Validation loss: 2.551931996951211

Epoch: 6| Step: 1
Training loss: 2.599993258247438
Validation loss: 2.539437181264002

Epoch: 6| Step: 2
Training loss: 2.236888618694245
Validation loss: 2.5511576524263186

Epoch: 6| Step: 3
Training loss: 2.0972864830271587
Validation loss: 2.5224686879841247

Epoch: 6| Step: 4
Training loss: 2.542607388699413
Validation loss: 2.549427945041678

Epoch: 6| Step: 5
Training loss: 2.4781065739335064
Validation loss: 2.5195738165362203

Epoch: 6| Step: 6
Training loss: 2.024757691002899
Validation loss: 2.5194405788301784

Epoch: 6| Step: 7
Training loss: 2.2351621295060955
Validation loss: 2.5100695157651693

Epoch: 6| Step: 8
Training loss: 2.282059826226314
Validation loss: 2.5220975516881827

Epoch: 6| Step: 9
Training loss: 1.803130497915788
Validation loss: 2.516251195840035

Epoch: 6| Step: 10
Training loss: 2.363756065905538
Validation loss: 2.5090699494606397

Epoch: 6| Step: 11
Training loss: 2.5602373507857425
Validation loss: 2.521888533078879

Epoch: 6| Step: 12
Training loss: 2.839077642859141
Validation loss: 2.5259012137361494

Epoch: 6| Step: 13
Training loss: 2.421743770858741
Validation loss: 2.5172533566151376

Epoch: 212| Step: 0
Training loss: 3.219086120240328
Validation loss: 2.5130762650828005

Epoch: 6| Step: 1
Training loss: 2.4714892678403046
Validation loss: 2.518945567739921

Epoch: 6| Step: 2
Training loss: 2.0600333057414777
Validation loss: 2.5186006231951983

Epoch: 6| Step: 3
Training loss: 1.768491325738938
Validation loss: 2.5249512249103887

Epoch: 6| Step: 4
Training loss: 1.9139307716350271
Validation loss: 2.52472472059424

Epoch: 6| Step: 5
Training loss: 2.4701708797079758
Validation loss: 2.5248788785683223

Epoch: 6| Step: 6
Training loss: 2.339054439431408
Validation loss: 2.534049366054384

Epoch: 6| Step: 7
Training loss: 2.481043278997426
Validation loss: 2.52113968324935

Epoch: 6| Step: 8
Training loss: 2.6267868499886773
Validation loss: 2.5254867232532647

Epoch: 6| Step: 9
Training loss: 2.450963519842379
Validation loss: 2.5424189835165167

Epoch: 6| Step: 10
Training loss: 2.8430097685494125
Validation loss: 2.5274337367330837

Epoch: 6| Step: 11
Training loss: 1.7406565692442673
Validation loss: 2.5169417447792766

Epoch: 6| Step: 12
Training loss: 1.9412879216996983
Validation loss: 2.5287701425270277

Epoch: 6| Step: 13
Training loss: 2.275708719047804
Validation loss: 2.532274313683775

Epoch: 213| Step: 0
Training loss: 1.8956186221877311
Validation loss: 2.5396660033725538

Epoch: 6| Step: 1
Training loss: 2.1274044794498645
Validation loss: 2.53040791071631

Epoch: 6| Step: 2
Training loss: 2.767114184467564
Validation loss: 2.522334327134285

Epoch: 6| Step: 3
Training loss: 2.244031619619268
Validation loss: 2.5316549063638147

Epoch: 6| Step: 4
Training loss: 2.566317807884373
Validation loss: 2.5224467439703835

Epoch: 6| Step: 5
Training loss: 2.7836552195864273
Validation loss: 2.5267520233455185

Epoch: 6| Step: 6
Training loss: 2.603745927519047
Validation loss: 2.5326908547529254

Epoch: 6| Step: 7
Training loss: 2.1390383889711253
Validation loss: 2.536002904801054

Epoch: 6| Step: 8
Training loss: 2.62343423558044
Validation loss: 2.530495511547792

Epoch: 6| Step: 9
Training loss: 2.2183952585237763
Validation loss: 2.541926438444499

Epoch: 6| Step: 10
Training loss: 2.2236857786977935
Validation loss: 2.527675483075344

Epoch: 6| Step: 11
Training loss: 2.245858088859991
Validation loss: 2.5345056969699082

Epoch: 6| Step: 12
Training loss: 2.361177072039991
Validation loss: 2.535137613362217

Epoch: 6| Step: 13
Training loss: 2.0667146333644952
Validation loss: 2.532411614896957

Epoch: 214| Step: 0
Training loss: 1.8067071356000466
Validation loss: 2.5132952024803594

Epoch: 6| Step: 1
Training loss: 2.141508490909663
Validation loss: 2.5322811083074654

Epoch: 6| Step: 2
Training loss: 2.974842445625305
Validation loss: 2.541040942813397

Epoch: 6| Step: 3
Training loss: 2.2459583009430952
Validation loss: 2.5255673989059617

Epoch: 6| Step: 4
Training loss: 2.509296109110242
Validation loss: 2.5207035304507186

Epoch: 6| Step: 5
Training loss: 2.191771560112118
Validation loss: 2.537787859895361

Epoch: 6| Step: 6
Training loss: 2.134641205703526
Validation loss: 2.5051120150020685

Epoch: 6| Step: 7
Training loss: 2.878430517426527
Validation loss: 2.5324273687543646

Epoch: 6| Step: 8
Training loss: 2.368701815555437
Validation loss: 2.51881205227554

Epoch: 6| Step: 9
Training loss: 2.017297331924728
Validation loss: 2.5247414431369197

Epoch: 6| Step: 10
Training loss: 2.5527115859493485
Validation loss: 2.537873186189809

Epoch: 6| Step: 11
Training loss: 2.2193370633440117
Validation loss: 2.5283968508576415

Epoch: 6| Step: 12
Training loss: 2.364683633657233
Validation loss: 2.530115367761949

Epoch: 6| Step: 13
Training loss: 2.3735215454087992
Validation loss: 2.530194066210167

Epoch: 215| Step: 0
Training loss: 2.2047459476328597
Validation loss: 2.510761923151682

Epoch: 6| Step: 1
Training loss: 1.7008472575256772
Validation loss: 2.5240214944625516

Epoch: 6| Step: 2
Training loss: 2.4052111872780975
Validation loss: 2.518697903443792

Epoch: 6| Step: 3
Training loss: 2.8435534734203913
Validation loss: 2.519998748541829

Epoch: 6| Step: 4
Training loss: 2.302399718578711
Validation loss: 2.5174744562231415

Epoch: 6| Step: 5
Training loss: 2.259314858887932
Validation loss: 2.524376378617426

Epoch: 6| Step: 6
Training loss: 2.087859793168635
Validation loss: 2.5572862851668305

Epoch: 6| Step: 7
Training loss: 2.428599810234087
Validation loss: 2.5637273407840997

Epoch: 6| Step: 8
Training loss: 2.2031795413793978
Validation loss: 2.5804814676280725

Epoch: 6| Step: 9
Training loss: 2.606774227560592
Validation loss: 2.566844947204941

Epoch: 6| Step: 10
Training loss: 2.4484248722726973
Validation loss: 2.5772412567557756

Epoch: 6| Step: 11
Training loss: 2.462678807926592
Validation loss: 2.54740873645631

Epoch: 6| Step: 12
Training loss: 2.303172192031825
Validation loss: 2.5255553940915005

Epoch: 6| Step: 13
Training loss: 2.7699602706759254
Validation loss: 2.512779759256723

Epoch: 216| Step: 0
Training loss: 2.3565852364370397
Validation loss: 2.5235978696586883

Epoch: 6| Step: 1
Training loss: 2.1236916048262913
Validation loss: 2.5069616662934133

Epoch: 6| Step: 2
Training loss: 2.60451516426287
Validation loss: 2.5014646928399857

Epoch: 6| Step: 3
Training loss: 2.1720223136725156
Validation loss: 2.4908948553491097

Epoch: 6| Step: 4
Training loss: 2.6144518774859753
Validation loss: 2.496319604882855

Epoch: 6| Step: 5
Training loss: 2.8956123834932486
Validation loss: 2.5087257378251904

Epoch: 6| Step: 6
Training loss: 2.1319464297980866
Validation loss: 2.5077834716891485

Epoch: 6| Step: 7
Training loss: 1.7151661354760757
Validation loss: 2.508060922330934

Epoch: 6| Step: 8
Training loss: 2.3952684372284994
Validation loss: 2.5242898641171774

Epoch: 6| Step: 9
Training loss: 2.068738576621241
Validation loss: 2.5037091158244187

Epoch: 6| Step: 10
Training loss: 2.6222272488533305
Validation loss: 2.508189853311694

Epoch: 6| Step: 11
Training loss: 1.498543986334566
Validation loss: 2.5334849596658087

Epoch: 6| Step: 12
Training loss: 3.081869413625698
Validation loss: 2.524854893811176

Epoch: 6| Step: 13
Training loss: 2.6194127885135665
Validation loss: 2.532248986681025

Epoch: 217| Step: 0
Training loss: 2.945379524581381
Validation loss: 2.5507849887510883

Epoch: 6| Step: 1
Training loss: 2.8471474945269026
Validation loss: 2.548501959694377

Epoch: 6| Step: 2
Training loss: 2.8843077216769357
Validation loss: 2.559338813994809

Epoch: 6| Step: 3
Training loss: 1.8864582900818416
Validation loss: 2.5600512519812155

Epoch: 6| Step: 4
Training loss: 2.092133196695092
Validation loss: 2.5432584864134413

Epoch: 6| Step: 5
Training loss: 1.8385399088072185
Validation loss: 2.5575552271712385

Epoch: 6| Step: 6
Training loss: 2.0263390670112074
Validation loss: 2.545684590861683

Epoch: 6| Step: 7
Training loss: 3.257076482168228
Validation loss: 2.5447709455256775

Epoch: 6| Step: 8
Training loss: 2.356184058442961
Validation loss: 2.541762605534489

Epoch: 6| Step: 9
Training loss: 2.8253158190251733
Validation loss: 2.5173813432487

Epoch: 6| Step: 10
Training loss: 1.9711652200739291
Validation loss: 2.5096816943194944

Epoch: 6| Step: 11
Training loss: 1.608903538061744
Validation loss: 2.5181198937982967

Epoch: 6| Step: 12
Training loss: 1.293183231139672
Validation loss: 2.50276114255641

Epoch: 6| Step: 13
Training loss: 2.3113128089107207
Validation loss: 2.494510974636367

Epoch: 218| Step: 0
Training loss: 2.7053702847360763
Validation loss: 2.5112692201776676

Epoch: 6| Step: 1
Training loss: 2.006901040610672
Validation loss: 2.5131274475778915

Epoch: 6| Step: 2
Training loss: 2.9094883094627466
Validation loss: 2.509760210202087

Epoch: 6| Step: 3
Training loss: 2.5282898536754046
Validation loss: 2.508192990158843

Epoch: 6| Step: 4
Training loss: 2.635105210145579
Validation loss: 2.5016038359499673

Epoch: 6| Step: 5
Training loss: 2.8529820083601747
Validation loss: 2.493836609651772

Epoch: 6| Step: 6
Training loss: 1.770378735103706
Validation loss: 2.517960232586036

Epoch: 6| Step: 7
Training loss: 2.511747036740505
Validation loss: 2.503822599016468

Epoch: 6| Step: 8
Training loss: 2.048287290278599
Validation loss: 2.512094266910606

Epoch: 6| Step: 9
Training loss: 1.7961170754197795
Validation loss: 2.5138548789583637

Epoch: 6| Step: 10
Training loss: 2.0374840952246616
Validation loss: 2.5098166058578615

Epoch: 6| Step: 11
Training loss: 2.4259941265667218
Validation loss: 2.5091086946638392

Epoch: 6| Step: 12
Training loss: 2.772457153704709
Validation loss: 2.512766428243888

Epoch: 6| Step: 13
Training loss: 2.1764895589180635
Validation loss: 2.5152725699464624

Epoch: 219| Step: 0
Training loss: 2.594415877940771
Validation loss: 2.5230585055770502

Epoch: 6| Step: 1
Training loss: 2.471284748116739
Validation loss: 2.5147817236875185

Epoch: 6| Step: 2
Training loss: 1.9772709718933605
Validation loss: 2.5439608231143036

Epoch: 6| Step: 3
Training loss: 2.9815268781833226
Validation loss: 2.558840177282823

Epoch: 6| Step: 4
Training loss: 2.2818259988255054
Validation loss: 2.558188136906272

Epoch: 6| Step: 5
Training loss: 2.141863722091116
Validation loss: 2.608155001514919

Epoch: 6| Step: 6
Training loss: 2.180549369149905
Validation loss: 2.5836472371850197

Epoch: 6| Step: 7
Training loss: 2.3782729635438264
Validation loss: 2.586372315882405

Epoch: 6| Step: 8
Training loss: 2.3087850062221156
Validation loss: 2.5401577352872335

Epoch: 6| Step: 9
Training loss: 2.0727429213305797
Validation loss: 2.520779543426238

Epoch: 6| Step: 10
Training loss: 2.578447541376945
Validation loss: 2.514656520200906

Epoch: 6| Step: 11
Training loss: 2.618868433202089
Validation loss: 2.506402479878025

Epoch: 6| Step: 12
Training loss: 2.0689349503835195
Validation loss: 2.524385437597117

Epoch: 6| Step: 13
Training loss: 2.6022889552077966
Validation loss: 2.5240371589983326

Epoch: 220| Step: 0
Training loss: 2.852270085583285
Validation loss: 2.5306001543310956

Epoch: 6| Step: 1
Training loss: 2.760827596535457
Validation loss: 2.523349291949618

Epoch: 6| Step: 2
Training loss: 2.5002757874005668
Validation loss: 2.519525730018582

Epoch: 6| Step: 3
Training loss: 2.2877713360396488
Validation loss: 2.510181199634556

Epoch: 6| Step: 4
Training loss: 2.126816365983264
Validation loss: 2.522046141586296

Epoch: 6| Step: 5
Training loss: 2.472598781791695
Validation loss: 2.508145271635704

Epoch: 6| Step: 6
Training loss: 2.82655763135399
Validation loss: 2.493402836471784

Epoch: 6| Step: 7
Training loss: 2.3861013260052197
Validation loss: 2.5109405815075534

Epoch: 6| Step: 8
Training loss: 2.0168153072255954
Validation loss: 2.4915707900399284

Epoch: 6| Step: 9
Training loss: 2.114421431132838
Validation loss: 2.515983161150243

Epoch: 6| Step: 10
Training loss: 2.4294207754648545
Validation loss: 2.5089964641699694

Epoch: 6| Step: 11
Training loss: 2.2518594264101512
Validation loss: 2.5347312880634076

Epoch: 6| Step: 12
Training loss: 2.350205444932918
Validation loss: 2.520865295669914

Epoch: 6| Step: 13
Training loss: 2.400838339934005
Validation loss: 2.512593173992777

Epoch: 221| Step: 0
Training loss: 2.5052023165201645
Validation loss: 2.533995501244538

Epoch: 6| Step: 1
Training loss: 2.5509410767189604
Validation loss: 2.514879989086406

Epoch: 6| Step: 2
Training loss: 2.1845703125
Validation loss: 2.5178333169904263

Epoch: 6| Step: 3
Training loss: 2.623222839406814
Validation loss: 2.5096036430760287

Epoch: 6| Step: 4
Training loss: 1.880730074897518
Validation loss: 2.5226930636274254

Epoch: 6| Step: 5
Training loss: 2.0622213926852595
Validation loss: 2.5293936967421855

Epoch: 6| Step: 6
Training loss: 2.3995175989439215
Validation loss: 2.5240882215613647

Epoch: 6| Step: 7
Training loss: 1.9336570035818712
Validation loss: 2.5134886996246206

Epoch: 6| Step: 8
Training loss: 2.2924338241560576
Validation loss: 2.51934823251225

Epoch: 6| Step: 9
Training loss: 2.2696955452311203
Validation loss: 2.521062168001936

Epoch: 6| Step: 10
Training loss: 2.232457118119119
Validation loss: 2.531380214403047

Epoch: 6| Step: 11
Training loss: 2.665501896474175
Validation loss: 2.5425601128917785

Epoch: 6| Step: 12
Training loss: 2.6758179599443497
Validation loss: 2.535230763833754

Epoch: 6| Step: 13
Training loss: 2.041394767042785
Validation loss: 2.5647541614184752

Epoch: 222| Step: 0
Training loss: 1.5056104639855208
Validation loss: 2.5647901985123562

Epoch: 6| Step: 1
Training loss: 2.413163298505745
Validation loss: 2.569752300709853

Epoch: 6| Step: 2
Training loss: 1.5713723624691833
Validation loss: 2.5492663244308544

Epoch: 6| Step: 3
Training loss: 2.6679730394365224
Validation loss: 2.562964118237512

Epoch: 6| Step: 4
Training loss: 2.1484113102096893
Validation loss: 2.5445354770449216

Epoch: 6| Step: 5
Training loss: 2.1872450543747863
Validation loss: 2.5503063373189723

Epoch: 6| Step: 6
Training loss: 3.5172469403104945
Validation loss: 2.5487243007594684

Epoch: 6| Step: 7
Training loss: 2.1395182846368503
Validation loss: 2.5306891420450484

Epoch: 6| Step: 8
Training loss: 2.4843549427686327
Validation loss: 2.5372182868210706

Epoch: 6| Step: 9
Training loss: 2.2474550053014393
Validation loss: 2.539558338754737

Epoch: 6| Step: 10
Training loss: 1.732509537707741
Validation loss: 2.541143446885542

Epoch: 6| Step: 11
Training loss: 2.685777333861644
Validation loss: 2.545888666861685

Epoch: 6| Step: 12
Training loss: 1.8224511414978928
Validation loss: 2.535988364000431

Epoch: 6| Step: 13
Training loss: 2.8043946349695936
Validation loss: 2.5253564488575906

Epoch: 223| Step: 0
Training loss: 2.779408734792179
Validation loss: 2.5342958437171967

Epoch: 6| Step: 1
Training loss: 3.1137244699994318
Validation loss: 2.5178740815504694

Epoch: 6| Step: 2
Training loss: 1.9958668559317918
Validation loss: 2.5214363800768247

Epoch: 6| Step: 3
Training loss: 3.226906820403012
Validation loss: 2.5184141615118234

Epoch: 6| Step: 4
Training loss: 1.5350930392620097
Validation loss: 2.516122267327208

Epoch: 6| Step: 5
Training loss: 1.8195497936910634
Validation loss: 2.5203038650052596

Epoch: 6| Step: 6
Training loss: 2.6606600784236756
Validation loss: 2.5336793615114073

Epoch: 6| Step: 7
Training loss: 2.1533828691664385
Validation loss: 2.5239742877333677

Epoch: 6| Step: 8
Training loss: 1.4619613568460463
Validation loss: 2.537404196673591

Epoch: 6| Step: 9
Training loss: 2.490679245648827
Validation loss: 2.531246106808027

Epoch: 6| Step: 10
Training loss: 2.181047678311306
Validation loss: 2.541666364409215

Epoch: 6| Step: 11
Training loss: 2.0465259982465462
Validation loss: 2.5328918752091347

Epoch: 6| Step: 12
Training loss: 2.6159532056233785
Validation loss: 2.5377158325308318

Epoch: 6| Step: 13
Training loss: 1.8726740079124526
Validation loss: 2.536570447967498

Epoch: 224| Step: 0
Training loss: 2.551609436463104
Validation loss: 2.5351702704921153

Epoch: 6| Step: 1
Training loss: 2.2437034028296576
Validation loss: 2.540973761700172

Epoch: 6| Step: 2
Training loss: 1.3914988054852253
Validation loss: 2.5203732840517317

Epoch: 6| Step: 3
Training loss: 3.5529383789009876
Validation loss: 2.52340839947907

Epoch: 6| Step: 4
Training loss: 2.260130751380588
Validation loss: 2.5280418787849426

Epoch: 6| Step: 5
Training loss: 1.777746938729363
Validation loss: 2.5123102214492987

Epoch: 6| Step: 6
Training loss: 2.2934434649541546
Validation loss: 2.532084135283803

Epoch: 6| Step: 7
Training loss: 2.1298322151257367
Validation loss: 2.517403710249674

Epoch: 6| Step: 8
Training loss: 3.0181143966238917
Validation loss: 2.5112960562589595

Epoch: 6| Step: 9
Training loss: 2.3439965690613724
Validation loss: 2.5179518843182733

Epoch: 6| Step: 10
Training loss: 2.6455412475681093
Validation loss: 2.500967855660524

Epoch: 6| Step: 11
Training loss: 1.3443924011494681
Validation loss: 2.5348576397771865

Epoch: 6| Step: 12
Training loss: 2.0552738643922392
Validation loss: 2.5640752339129227

Epoch: 6| Step: 13
Training loss: 2.400775676786618
Validation loss: 2.542951936368347

Epoch: 225| Step: 0
Training loss: 2.4415353481492352
Validation loss: 2.5515416459249263

Epoch: 6| Step: 1
Training loss: 2.378080077379892
Validation loss: 2.554737211126783

Epoch: 6| Step: 2
Training loss: 2.3530864656695027
Validation loss: 2.579628415492983

Epoch: 6| Step: 3
Training loss: 2.166079466062106
Validation loss: 2.566159387925243

Epoch: 6| Step: 4
Training loss: 1.8836974917195883
Validation loss: 2.5535791541791544

Epoch: 6| Step: 5
Training loss: 2.480590432854414
Validation loss: 2.5338396867192627

Epoch: 6| Step: 6
Training loss: 2.8535801268591134
Validation loss: 2.5426414736206624

Epoch: 6| Step: 7
Training loss: 2.1257813083209864
Validation loss: 2.5256978433487256

Epoch: 6| Step: 8
Training loss: 2.291899501647722
Validation loss: 2.544536117316371

Epoch: 6| Step: 9
Training loss: 1.9190028368842946
Validation loss: 2.546032381991025

Epoch: 6| Step: 10
Training loss: 1.9840874651348968
Validation loss: 2.558712959909752

Epoch: 6| Step: 11
Training loss: 3.1109198178411974
Validation loss: 2.568582263553203

Epoch: 6| Step: 12
Training loss: 2.45091604896311
Validation loss: 2.5798687442023707

Epoch: 6| Step: 13
Training loss: 2.0498694727211517
Validation loss: 2.5831191732994836

Epoch: 226| Step: 0
Training loss: 2.473884940146271
Validation loss: 2.555186884888926

Epoch: 6| Step: 1
Training loss: 1.659690881466029
Validation loss: 2.537865670639121

Epoch: 6| Step: 2
Training loss: 2.5607092578182655
Validation loss: 2.53010982375582

Epoch: 6| Step: 3
Training loss: 2.716615562504367
Validation loss: 2.509097466297423

Epoch: 6| Step: 4
Training loss: 2.473620860857428
Validation loss: 2.525691031014711

Epoch: 6| Step: 5
Training loss: 2.8972326689552435
Validation loss: 2.525861601294304

Epoch: 6| Step: 6
Training loss: 2.346572803693648
Validation loss: 2.5443033446021404

Epoch: 6| Step: 7
Training loss: 2.1611193532821966
Validation loss: 2.5319254409635827

Epoch: 6| Step: 8
Training loss: 1.9061544425652222
Validation loss: 2.543343808847088

Epoch: 6| Step: 9
Training loss: 2.4324261602973833
Validation loss: 2.5173699544700128

Epoch: 6| Step: 10
Training loss: 2.3265070061249205
Validation loss: 2.512852880897234

Epoch: 6| Step: 11
Training loss: 2.1388107742423443
Validation loss: 2.5201482998010682

Epoch: 6| Step: 12
Training loss: 2.461330031318695
Validation loss: 2.513715947655753

Epoch: 6| Step: 13
Training loss: 2.522450162397137
Validation loss: 2.510708160150026

Epoch: 227| Step: 0
Training loss: 2.4182759769227173
Validation loss: 2.526262479484195

Epoch: 6| Step: 1
Training loss: 2.134235843350093
Validation loss: 2.5316795565478136

Epoch: 6| Step: 2
Training loss: 1.998284319270431
Validation loss: 2.5307360625789688

Epoch: 6| Step: 3
Training loss: 2.3527955532590994
Validation loss: 2.5398781429806823

Epoch: 6| Step: 4
Training loss: 2.1099163349793737
Validation loss: 2.542977438041194

Epoch: 6| Step: 5
Training loss: 2.4671378364420393
Validation loss: 2.5313769964062995

Epoch: 6| Step: 6
Training loss: 1.7023956416967003
Validation loss: 2.5589651211976183

Epoch: 6| Step: 7
Training loss: 2.247623566146893
Validation loss: 2.5554437791410374

Epoch: 6| Step: 8
Training loss: 2.2894592982796187
Validation loss: 2.5271351024066435

Epoch: 6| Step: 9
Training loss: 2.3167345608795435
Validation loss: 2.5271496469760275

Epoch: 6| Step: 10
Training loss: 2.2067054170431137
Validation loss: 2.5329771703350663

Epoch: 6| Step: 11
Training loss: 2.7544297173979078
Validation loss: 2.526363050852858

Epoch: 6| Step: 12
Training loss: 2.018467754084713
Validation loss: 2.5428753985621695

Epoch: 6| Step: 13
Training loss: 3.2462294787734
Validation loss: 2.5483789976364353

Epoch: 228| Step: 0
Training loss: 2.3144259294288294
Validation loss: 2.5625853795660176

Epoch: 6| Step: 1
Training loss: 2.376374198481223
Validation loss: 2.562538720435395

Epoch: 6| Step: 2
Training loss: 1.3205390148993008
Validation loss: 2.5612920689824197

Epoch: 6| Step: 3
Training loss: 1.6785512230187465
Validation loss: 2.5632283330956747

Epoch: 6| Step: 4
Training loss: 2.6432397300371333
Validation loss: 2.594298048220656

Epoch: 6| Step: 5
Training loss: 2.556602576827271
Validation loss: 2.608138509082035

Epoch: 6| Step: 6
Training loss: 3.0076618899995498
Validation loss: 2.6161282193922952

Epoch: 6| Step: 7
Training loss: 2.3433593424424903
Validation loss: 2.6359610516744016

Epoch: 6| Step: 8
Training loss: 2.824280628671401
Validation loss: 2.597982041047017

Epoch: 6| Step: 9
Training loss: 2.048519725880563
Validation loss: 2.5624782437277083

Epoch: 6| Step: 10
Training loss: 2.4998357718885402
Validation loss: 2.55106332338008

Epoch: 6| Step: 11
Training loss: 2.447087822595037
Validation loss: 2.5182003005121234

Epoch: 6| Step: 12
Training loss: 1.6379419094493153
Validation loss: 2.5141334297664613

Epoch: 6| Step: 13
Training loss: 2.741682391909072
Validation loss: 2.511952375005072

Epoch: 229| Step: 0
Training loss: 2.8959463266699412
Validation loss: 2.5174182321199132

Epoch: 6| Step: 1
Training loss: 2.6029071254157414
Validation loss: 2.5201887825235425

Epoch: 6| Step: 2
Training loss: 3.0171587112451963
Validation loss: 2.5149331572986457

Epoch: 6| Step: 3
Training loss: 1.6909198722421064
Validation loss: 2.5196521818724795

Epoch: 6| Step: 4
Training loss: 2.308963029634038
Validation loss: 2.525468306343644

Epoch: 6| Step: 5
Training loss: 2.6259193626975006
Validation loss: 2.5442762007147492

Epoch: 6| Step: 6
Training loss: 2.130008852944759
Validation loss: 2.5563585141753546

Epoch: 6| Step: 7
Training loss: 1.8655320494226562
Validation loss: 2.558615244224283

Epoch: 6| Step: 8
Training loss: 2.4585057429831743
Validation loss: 2.5730686889298253

Epoch: 6| Step: 9
Training loss: 2.2297535299082236
Validation loss: 2.5634024976899683

Epoch: 6| Step: 10
Training loss: 2.027365858953387
Validation loss: 2.5403678160151033

Epoch: 6| Step: 11
Training loss: 2.4539337768759624
Validation loss: 2.5343758861761274

Epoch: 6| Step: 12
Training loss: 1.973095352099942
Validation loss: 2.52461316069415

Epoch: 6| Step: 13
Training loss: 2.325670215440867
Validation loss: 2.5114701357141853

Epoch: 230| Step: 0
Training loss: 2.4597613718239293
Validation loss: 2.5275752469089268

Epoch: 6| Step: 1
Training loss: 2.1897179394938098
Validation loss: 2.521282571113495

Epoch: 6| Step: 2
Training loss: 2.3294297217063966
Validation loss: 2.5332584340751874

Epoch: 6| Step: 3
Training loss: 2.7810490567771673
Validation loss: 2.5250943691886665

Epoch: 6| Step: 4
Training loss: 2.652776084575368
Validation loss: 2.559232225422013

Epoch: 6| Step: 5
Training loss: 2.0556716012703213
Validation loss: 2.5554745129736327

Epoch: 6| Step: 6
Training loss: 2.135313810026821
Validation loss: 2.5476995276321994

Epoch: 6| Step: 7
Training loss: 2.5978706443481023
Validation loss: 2.55842994379127

Epoch: 6| Step: 8
Training loss: 2.310526031116358
Validation loss: 2.5728953331025557

Epoch: 6| Step: 9
Training loss: 2.840531088910211
Validation loss: 2.6060063590525724

Epoch: 6| Step: 10
Training loss: 1.9885472567522846
Validation loss: 2.5890760017369874

Epoch: 6| Step: 11
Training loss: 2.326786552590486
Validation loss: 2.5739993289866607

Epoch: 6| Step: 12
Training loss: 2.2555534915048128
Validation loss: 2.5629308384893337

Epoch: 6| Step: 13
Training loss: 1.501386954915725
Validation loss: 2.5121434447431423

Epoch: 231| Step: 0
Training loss: 2.4383243242863517
Validation loss: 2.519578358606552

Epoch: 6| Step: 1
Training loss: 2.68368401299255
Validation loss: 2.524843940066771

Epoch: 6| Step: 2
Training loss: 3.053132190520176
Validation loss: 2.5226298832039684

Epoch: 6| Step: 3
Training loss: 1.8927504517133096
Validation loss: 2.5340282122961635

Epoch: 6| Step: 4
Training loss: 1.6250143050517816
Validation loss: 2.5264218598122086

Epoch: 6| Step: 5
Training loss: 1.9134114306435719
Validation loss: 2.5277524889797687

Epoch: 6| Step: 6
Training loss: 2.671160864621421
Validation loss: 2.5050365894054014

Epoch: 6| Step: 7
Training loss: 2.309431153312887
Validation loss: 2.5094431233294094

Epoch: 6| Step: 8
Training loss: 2.9133090356763587
Validation loss: 2.499561462086216

Epoch: 6| Step: 9
Training loss: 2.4713176460636057
Validation loss: 2.48662311874623

Epoch: 6| Step: 10
Training loss: 2.6510004566239718
Validation loss: 2.483742255480537

Epoch: 6| Step: 11
Training loss: 2.141833110630122
Validation loss: 2.4869814301858293

Epoch: 6| Step: 12
Training loss: 3.215023216531556
Validation loss: 2.4810599676303893

Epoch: 6| Step: 13
Training loss: 2.281587758600425
Validation loss: 2.4778987677029103

Epoch: 232| Step: 0
Training loss: 3.0993406086710005
Validation loss: 2.480008236245866

Epoch: 6| Step: 1
Training loss: 2.2965882829523543
Validation loss: 2.4684521781168502

Epoch: 6| Step: 2
Training loss: 2.5875997588604083
Validation loss: 2.4739190724252444

Epoch: 6| Step: 3
Training loss: 2.51555732967747
Validation loss: 2.4738013662769083

Epoch: 6| Step: 4
Training loss: 2.767438477174347
Validation loss: 2.471675507556883

Epoch: 6| Step: 5
Training loss: 2.0684437504921895
Validation loss: 2.4697075527953367

Epoch: 6| Step: 6
Training loss: 2.2616027907719647
Validation loss: 2.476809299819143

Epoch: 6| Step: 7
Training loss: 2.4835706644344264
Validation loss: 2.4840382601688296

Epoch: 6| Step: 8
Training loss: 2.880361285066046
Validation loss: 2.4827083539395916

Epoch: 6| Step: 9
Training loss: 2.0507908993448583
Validation loss: 2.4841892164969193

Epoch: 6| Step: 10
Training loss: 2.798552622682194
Validation loss: 2.479610368682426

Epoch: 6| Step: 11
Training loss: 2.6731662418661566
Validation loss: 2.476317352452174

Epoch: 6| Step: 12
Training loss: 2.016250395044618
Validation loss: 2.482639538306186

Epoch: 6| Step: 13
Training loss: 1.8878826081989546
Validation loss: 2.4829617605282412

Epoch: 233| Step: 0
Training loss: 2.174671266640188
Validation loss: 2.4762250668385555

Epoch: 6| Step: 1
Training loss: 2.2582496299105665
Validation loss: 2.4876891608974674

Epoch: 6| Step: 2
Training loss: 3.3619089904757535
Validation loss: 2.487065288124397

Epoch: 6| Step: 3
Training loss: 2.116721577069777
Validation loss: 2.486102321426889

Epoch: 6| Step: 4
Training loss: 2.276294080295917
Validation loss: 2.4766942900721176

Epoch: 6| Step: 5
Training loss: 3.102230893620587
Validation loss: 2.486378387798159

Epoch: 6| Step: 6
Training loss: 2.223676236297841
Validation loss: 2.4834344551013676

Epoch: 6| Step: 7
Training loss: 2.249306147932123
Validation loss: 2.4803556962169067

Epoch: 6| Step: 8
Training loss: 2.065136928867707
Validation loss: 2.4859329393026512

Epoch: 6| Step: 9
Training loss: 2.65367594144373
Validation loss: 2.4729783750792524

Epoch: 6| Step: 10
Training loss: 2.37783704259978
Validation loss: 2.4858722133922972

Epoch: 6| Step: 11
Training loss: 2.2421245499656335
Validation loss: 2.5042719343362916

Epoch: 6| Step: 12
Training loss: 1.8268466620738444
Validation loss: 2.48062386415737

Epoch: 6| Step: 13
Training loss: 2.6951166496439423
Validation loss: 2.491592208574824

Epoch: 234| Step: 0
Training loss: 2.332260146161611
Validation loss: 2.4982360656852554

Epoch: 6| Step: 1
Training loss: 2.6260687151167414
Validation loss: 2.4950701585332657

Epoch: 6| Step: 2
Training loss: 2.792183548252616
Validation loss: 2.502584805977698

Epoch: 6| Step: 3
Training loss: 2.8138677873873608
Validation loss: 2.496811868428879

Epoch: 6| Step: 4
Training loss: 2.278029480908325
Validation loss: 2.5023642963221344

Epoch: 6| Step: 5
Training loss: 2.139110948614442
Validation loss: 2.4988703639225482

Epoch: 6| Step: 6
Training loss: 2.033374555618088
Validation loss: 2.514898562537627

Epoch: 6| Step: 7
Training loss: 2.4629173428616222
Validation loss: 2.522142044292375

Epoch: 6| Step: 8
Training loss: 2.190677732521352
Validation loss: 2.5227460671749777

Epoch: 6| Step: 9
Training loss: 2.4781883510655387
Validation loss: 2.5202937428769134

Epoch: 6| Step: 10
Training loss: 2.2708554631359403
Validation loss: 2.5443038521807058

Epoch: 6| Step: 11
Training loss: 2.7202799208441406
Validation loss: 2.5141348838462036

Epoch: 6| Step: 12
Training loss: 1.84803158453996
Validation loss: 2.5559994811871896

Epoch: 6| Step: 13
Training loss: 2.068691324283547
Validation loss: 2.5262767931388597

Epoch: 235| Step: 0
Training loss: 2.532592605750412
Validation loss: 2.5308858036467523

Epoch: 6| Step: 1
Training loss: 2.4760531795257057
Validation loss: 2.5422886155238937

Epoch: 6| Step: 2
Training loss: 2.6015650660413394
Validation loss: 2.5297231582538036

Epoch: 6| Step: 3
Training loss: 2.3901060451140803
Validation loss: 2.5365303598526197

Epoch: 6| Step: 4
Training loss: 2.451286647586874
Validation loss: 2.546414932479923

Epoch: 6| Step: 5
Training loss: 2.80781291776982
Validation loss: 2.54341564558562

Epoch: 6| Step: 6
Training loss: 2.261649069758611
Validation loss: 2.5486398210793837

Epoch: 6| Step: 7
Training loss: 2.2330286197698914
Validation loss: 2.5334528376182965

Epoch: 6| Step: 8
Training loss: 1.7748940825762007
Validation loss: 2.5162786894172005

Epoch: 6| Step: 9
Training loss: 2.8358428350785085
Validation loss: 2.5191457211953625

Epoch: 6| Step: 10
Training loss: 1.7024637040849966
Validation loss: 2.48950483020141

Epoch: 6| Step: 11
Training loss: 2.026366246234721
Validation loss: 2.5138868404494827

Epoch: 6| Step: 12
Training loss: 2.245319903208209
Validation loss: 2.5132555652681883

Epoch: 6| Step: 13
Training loss: 2.3922629137068356
Validation loss: 2.5040726549355314

Epoch: 236| Step: 0
Training loss: 1.9563256855421562
Validation loss: 2.511661526911623

Epoch: 6| Step: 1
Training loss: 2.6137723133479263
Validation loss: 2.4967032630115886

Epoch: 6| Step: 2
Training loss: 1.9826450767205261
Validation loss: 2.499501854221984

Epoch: 6| Step: 3
Training loss: 2.5048533060518468
Validation loss: 2.4916655612760237

Epoch: 6| Step: 4
Training loss: 2.1623391681465205
Validation loss: 2.508774649070199

Epoch: 6| Step: 5
Training loss: 2.418797463436825
Validation loss: 2.506509571157866

Epoch: 6| Step: 6
Training loss: 2.6960210338813413
Validation loss: 2.5179958899512163

Epoch: 6| Step: 7
Training loss: 2.2595374042397367
Validation loss: 2.52323502554016

Epoch: 6| Step: 8
Training loss: 2.34114255187102
Validation loss: 2.5129674928897585

Epoch: 6| Step: 9
Training loss: 1.9202848849937664
Validation loss: 2.5230905552187752

Epoch: 6| Step: 10
Training loss: 2.4331365801900406
Validation loss: 2.5100460623127905

Epoch: 6| Step: 11
Training loss: 2.4624081047455166
Validation loss: 2.517183243763516

Epoch: 6| Step: 12
Training loss: 2.406280715548176
Validation loss: 2.5349897223169573

Epoch: 6| Step: 13
Training loss: 2.552412974548841
Validation loss: 2.5351867360465143

Epoch: 237| Step: 0
Training loss: 2.0960316538276937
Validation loss: 2.5333465715949184

Epoch: 6| Step: 1
Training loss: 2.836840609257768
Validation loss: 2.5431382239494718

Epoch: 6| Step: 2
Training loss: 2.2413181653270686
Validation loss: 2.5468660132126724

Epoch: 6| Step: 3
Training loss: 2.050720562718134
Validation loss: 2.5633555433983664

Epoch: 6| Step: 4
Training loss: 1.9168084824659373
Validation loss: 2.592361369557207

Epoch: 6| Step: 5
Training loss: 3.1284670098802674
Validation loss: 2.582301215651321

Epoch: 6| Step: 6
Training loss: 1.952603690194063
Validation loss: 2.5734885400042966

Epoch: 6| Step: 7
Training loss: 2.540382018910139
Validation loss: 2.546716790463289

Epoch: 6| Step: 8
Training loss: 2.251972393605228
Validation loss: 2.546768662118668

Epoch: 6| Step: 9
Training loss: 1.8857165848007884
Validation loss: 2.526699874436595

Epoch: 6| Step: 10
Training loss: 1.8273895610205972
Validation loss: 2.509833688963373

Epoch: 6| Step: 11
Training loss: 2.1615054450971365
Validation loss: 2.518932624298476

Epoch: 6| Step: 12
Training loss: 2.3731922497587896
Validation loss: 2.5113864597798767

Epoch: 6| Step: 13
Training loss: 2.8026183420014315
Validation loss: 2.5050842005905185

Epoch: 238| Step: 0
Training loss: 2.553236242926773
Validation loss: 2.503754228806412

Epoch: 6| Step: 1
Training loss: 1.7522873915760484
Validation loss: 2.510189098844103

Epoch: 6| Step: 2
Training loss: 2.2962086028726776
Validation loss: 2.4972344042356296

Epoch: 6| Step: 3
Training loss: 2.207648104994784
Validation loss: 2.5124860415221186

Epoch: 6| Step: 4
Training loss: 2.331961421464238
Validation loss: 2.516445902642557

Epoch: 6| Step: 5
Training loss: 2.267829821907996
Validation loss: 2.4965156035523624

Epoch: 6| Step: 6
Training loss: 2.3310481416173277
Validation loss: 2.511612719349034

Epoch: 6| Step: 7
Training loss: 2.4606385064523466
Validation loss: 2.5148675698413063

Epoch: 6| Step: 8
Training loss: 2.389618904981998
Validation loss: 2.5254452948517656

Epoch: 6| Step: 9
Training loss: 2.297792627670703
Validation loss: 2.5399377184964083

Epoch: 6| Step: 10
Training loss: 2.441739625676163
Validation loss: 2.5418596402896907

Epoch: 6| Step: 11
Training loss: 2.248536587692948
Validation loss: 2.5334300319721073

Epoch: 6| Step: 12
Training loss: 2.6841452308169145
Validation loss: 2.5533657095909064

Epoch: 6| Step: 13
Training loss: 2.4797225670837837
Validation loss: 2.569681710523513

Epoch: 239| Step: 0
Training loss: 2.0254056924463653
Validation loss: 2.571135059829649

Epoch: 6| Step: 1
Training loss: 2.377861607887101
Validation loss: 2.5554432349008533

Epoch: 6| Step: 2
Training loss: 2.4362965082511905
Validation loss: 2.5789577487848647

Epoch: 6| Step: 3
Training loss: 1.2455286161549597
Validation loss: 2.562280312091761

Epoch: 6| Step: 4
Training loss: 2.6632381293604217
Validation loss: 2.5743888061726192

Epoch: 6| Step: 5
Training loss: 2.3620768859455885
Validation loss: 2.5427071416764293

Epoch: 6| Step: 6
Training loss: 2.402834263788716
Validation loss: 2.546550144938449

Epoch: 6| Step: 7
Training loss: 2.4174655273567507
Validation loss: 2.52961038146379

Epoch: 6| Step: 8
Training loss: 2.7601632535723044
Validation loss: 2.5229974447643895

Epoch: 6| Step: 9
Training loss: 1.5802216906686055
Validation loss: 2.541945931981871

Epoch: 6| Step: 10
Training loss: 2.2402162825528134
Validation loss: 2.524277066141865

Epoch: 6| Step: 11
Training loss: 2.5678145030100783
Validation loss: 2.5146946578731613

Epoch: 6| Step: 12
Training loss: 2.5478658796370928
Validation loss: 2.544405889033908

Epoch: 6| Step: 13
Training loss: 2.641590009794516
Validation loss: 2.5495562803135385

Epoch: 240| Step: 0
Training loss: 1.939386864151656
Validation loss: 2.5833940242488245

Epoch: 6| Step: 1
Training loss: 2.61926478604382
Validation loss: 2.5903259488201247

Epoch: 6| Step: 2
Training loss: 2.3136786472853252
Validation loss: 2.6218559115915703

Epoch: 6| Step: 3
Training loss: 2.467156584088776
Validation loss: 2.633440872805258

Epoch: 6| Step: 4
Training loss: 2.2736789011521465
Validation loss: 2.6444420848786043

Epoch: 6| Step: 5
Training loss: 2.337662892097281
Validation loss: 2.610894162609583

Epoch: 6| Step: 6
Training loss: 1.962466977078508
Validation loss: 2.6050635865908296

Epoch: 6| Step: 7
Training loss: 2.305719280429967
Validation loss: 2.552231645491516

Epoch: 6| Step: 8
Training loss: 2.603773489199212
Validation loss: 2.5559358647836388

Epoch: 6| Step: 9
Training loss: 2.3484245985213548
Validation loss: 2.5532381883213104

Epoch: 6| Step: 10
Training loss: 1.6634047376841565
Validation loss: 2.5378599948178615

Epoch: 6| Step: 11
Training loss: 2.682735211387159
Validation loss: 2.533800637495562

Epoch: 6| Step: 12
Training loss: 2.4661266053580433
Validation loss: 2.512332340991716

Epoch: 6| Step: 13
Training loss: 2.2440705051871648
Validation loss: 2.5189309205864223

Epoch: 241| Step: 0
Training loss: 2.853930349846061
Validation loss: 2.5229940743282895

Epoch: 6| Step: 1
Training loss: 2.112262698958541
Validation loss: 2.521789295957207

Epoch: 6| Step: 2
Training loss: 2.413755526978355
Validation loss: 2.511351349391404

Epoch: 6| Step: 3
Training loss: 2.5734459233565943
Validation loss: 2.517697106808396

Epoch: 6| Step: 4
Training loss: 2.7051047423667893
Validation loss: 2.5170342504292553

Epoch: 6| Step: 5
Training loss: 2.5374596803966507
Validation loss: 2.533441230918929

Epoch: 6| Step: 6
Training loss: 2.171046915609571
Validation loss: 2.5172724887258697

Epoch: 6| Step: 7
Training loss: 2.0291323847554357
Validation loss: 2.5327527644153274

Epoch: 6| Step: 8
Training loss: 2.0400197789224435
Validation loss: 2.5294610126117614

Epoch: 6| Step: 9
Training loss: 2.5587067790217706
Validation loss: 2.570254664364625

Epoch: 6| Step: 10
Training loss: 1.9493346399628155
Validation loss: 2.564427581218282

Epoch: 6| Step: 11
Training loss: 2.5808161705792303
Validation loss: 2.5724671520710025

Epoch: 6| Step: 12
Training loss: 1.8300764313876234
Validation loss: 2.5932578190552924

Epoch: 6| Step: 13
Training loss: 2.0339726907252738
Validation loss: 2.5556394959453255

Epoch: 242| Step: 0
Training loss: 2.1324715254426567
Validation loss: 2.5326470181569127

Epoch: 6| Step: 1
Training loss: 2.096494896629376
Validation loss: 2.512472558702003

Epoch: 6| Step: 2
Training loss: 1.889984274501068
Validation loss: 2.511004942245613

Epoch: 6| Step: 3
Training loss: 2.803402407048829
Validation loss: 2.518165143108755

Epoch: 6| Step: 4
Training loss: 2.7302719285397146
Validation loss: 2.5205581346681334

Epoch: 6| Step: 5
Training loss: 2.525296781113586
Validation loss: 2.512170682742386

Epoch: 6| Step: 6
Training loss: 2.303246619896669
Validation loss: 2.4982955765071337

Epoch: 6| Step: 7
Training loss: 2.2674430130061096
Validation loss: 2.530167509094879

Epoch: 6| Step: 8
Training loss: 1.4672191839890032
Validation loss: 2.4965649529667595

Epoch: 6| Step: 9
Training loss: 2.505618648011931
Validation loss: 2.5323288113877265

Epoch: 6| Step: 10
Training loss: 2.3863124470360435
Validation loss: 2.5164662409755882

Epoch: 6| Step: 11
Training loss: 2.5289111222487435
Validation loss: 2.5356297219834003

Epoch: 6| Step: 12
Training loss: 2.5573850615954345
Validation loss: 2.524228722896885

Epoch: 6| Step: 13
Training loss: 2.474818629545508
Validation loss: 2.5672105896109345

Epoch: 243| Step: 0
Training loss: 2.435892602140956
Validation loss: 2.5765702000169997

Epoch: 6| Step: 1
Training loss: 2.2060497160606887
Validation loss: 2.584466229465685

Epoch: 6| Step: 2
Training loss: 2.770701947837847
Validation loss: 2.5715386925939363

Epoch: 6| Step: 3
Training loss: 1.794255611390174
Validation loss: 2.571489290814813

Epoch: 6| Step: 4
Training loss: 1.9968045456565566
Validation loss: 2.5276720166933466

Epoch: 6| Step: 5
Training loss: 2.3668363707326185
Validation loss: 2.5269787862420916

Epoch: 6| Step: 6
Training loss: 2.15441075263529
Validation loss: 2.5328435395064792

Epoch: 6| Step: 7
Training loss: 2.2061413616633003
Validation loss: 2.516241246912703

Epoch: 6| Step: 8
Training loss: 2.7300428677780877
Validation loss: 2.5127131667418934

Epoch: 6| Step: 9
Training loss: 2.367426189814836
Validation loss: 2.527418541329801

Epoch: 6| Step: 10
Training loss: 2.4555545123152247
Validation loss: 2.525042437835708

Epoch: 6| Step: 11
Training loss: 2.397796246918374
Validation loss: 2.517845895208083

Epoch: 6| Step: 12
Training loss: 2.563374811968734
Validation loss: 2.5091512083829346

Epoch: 6| Step: 13
Training loss: 2.3049663827558886
Validation loss: 2.4967884575491555

Epoch: 244| Step: 0
Training loss: 2.396964052378758
Validation loss: 2.521643553067121

Epoch: 6| Step: 1
Training loss: 2.7581473949568265
Validation loss: 2.539600812138864

Epoch: 6| Step: 2
Training loss: 2.1448676396149216
Validation loss: 2.549870451584729

Epoch: 6| Step: 3
Training loss: 2.02581953254538
Validation loss: 2.564508991935477

Epoch: 6| Step: 4
Training loss: 2.3447839109500674
Validation loss: 2.5771094123262963

Epoch: 6| Step: 5
Training loss: 1.978768787210503
Validation loss: 2.580567022183386

Epoch: 6| Step: 6
Training loss: 2.5779265356257723
Validation loss: 2.5810470205677367

Epoch: 6| Step: 7
Training loss: 2.483722913082731
Validation loss: 2.623693156021128

Epoch: 6| Step: 8
Training loss: 2.464112283594416
Validation loss: 2.587365991927714

Epoch: 6| Step: 9
Training loss: 2.101085169021401
Validation loss: 2.562147984710809

Epoch: 6| Step: 10
Training loss: 2.5494457914189486
Validation loss: 2.5526855277281806

Epoch: 6| Step: 11
Training loss: 2.234121454965488
Validation loss: 2.537921480900652

Epoch: 6| Step: 12
Training loss: 1.9901802272749403
Validation loss: 2.535151923929764

Epoch: 6| Step: 13
Training loss: 2.2910695309488296
Validation loss: 2.513503275732361

Epoch: 245| Step: 0
Training loss: 2.779901584831754
Validation loss: 2.5025254924262055

Epoch: 6| Step: 1
Training loss: 2.0151454147990524
Validation loss: 2.5090392094317178

Epoch: 6| Step: 2
Training loss: 1.9304226235684032
Validation loss: 2.4948812215150817

Epoch: 6| Step: 3
Training loss: 1.7245009875340342
Validation loss: 2.497136327621565

Epoch: 6| Step: 4
Training loss: 1.9361513427660366
Validation loss: 2.4899924565906986

Epoch: 6| Step: 5
Training loss: 2.159926666145173
Validation loss: 2.504995822154284

Epoch: 6| Step: 6
Training loss: 1.7976294882322887
Validation loss: 2.504461170424818

Epoch: 6| Step: 7
Training loss: 2.5637129727297805
Validation loss: 2.498160941487593

Epoch: 6| Step: 8
Training loss: 2.547584107332974
Validation loss: 2.5353655853600725

Epoch: 6| Step: 9
Training loss: 2.5520444490753196
Validation loss: 2.531993207417196

Epoch: 6| Step: 10
Training loss: 2.541797186413411
Validation loss: 2.5389018707328397

Epoch: 6| Step: 11
Training loss: 2.7167570329236184
Validation loss: 2.5714720301008493

Epoch: 6| Step: 12
Training loss: 1.9698379780129613
Validation loss: 2.633701132991041

Epoch: 6| Step: 13
Training loss: 2.8440303454704963
Validation loss: 2.614481666888287

Epoch: 246| Step: 0
Training loss: 2.329687221637098
Validation loss: 2.6313033037381737

Epoch: 6| Step: 1
Training loss: 2.503456491910908
Validation loss: 2.6289222115971604

Epoch: 6| Step: 2
Training loss: 2.001635121465664
Validation loss: 2.6336653146042237

Epoch: 6| Step: 3
Training loss: 2.1942031609667962
Validation loss: 2.6319027318363837

Epoch: 6| Step: 4
Training loss: 2.8385408080680086
Validation loss: 2.5886383703782583

Epoch: 6| Step: 5
Training loss: 1.8839101164165053
Validation loss: 2.567834016665598

Epoch: 6| Step: 6
Training loss: 1.7654886108653363
Validation loss: 2.5445163937584825

Epoch: 6| Step: 7
Training loss: 2.447446336946963
Validation loss: 2.4952343499532716

Epoch: 6| Step: 8
Training loss: 2.062082884253978
Validation loss: 2.508187920504932

Epoch: 6| Step: 9
Training loss: 2.6495442736328587
Validation loss: 2.49401076060148

Epoch: 6| Step: 10
Training loss: 2.5028372876648195
Validation loss: 2.4994596453667

Epoch: 6| Step: 11
Training loss: 2.4966288725772747
Validation loss: 2.512755097618065

Epoch: 6| Step: 12
Training loss: 2.0428949929921942
Validation loss: 2.505605342334632

Epoch: 6| Step: 13
Training loss: 2.3717079435479667
Validation loss: 2.512475057576179

Epoch: 247| Step: 0
Training loss: 2.1486862870868193
Validation loss: 2.4938227471597707

Epoch: 6| Step: 1
Training loss: 2.727295173205862
Validation loss: 2.506860269018029

Epoch: 6| Step: 2
Training loss: 2.4922320801385998
Validation loss: 2.4968180433898013

Epoch: 6| Step: 3
Training loss: 2.551541038558415
Validation loss: 2.528623104811776

Epoch: 6| Step: 4
Training loss: 1.4290112840061462
Validation loss: 2.55263361285669

Epoch: 6| Step: 5
Training loss: 2.5418958612715747
Validation loss: 2.5728961825359753

Epoch: 6| Step: 6
Training loss: 2.682965822898615
Validation loss: 2.586068356555847

Epoch: 6| Step: 7
Training loss: 1.699456980875418
Validation loss: 2.553991629331648

Epoch: 6| Step: 8
Training loss: 2.0273466900342965
Validation loss: 2.572684958419692

Epoch: 6| Step: 9
Training loss: 2.0921220286283777
Validation loss: 2.5390893866264763

Epoch: 6| Step: 10
Training loss: 2.6630033921590095
Validation loss: 2.5365466364242724

Epoch: 6| Step: 11
Training loss: 2.0744274774334386
Validation loss: 2.5347594747607363

Epoch: 6| Step: 12
Training loss: 1.9158357463864062
Validation loss: 2.5317282048377105

Epoch: 6| Step: 13
Training loss: 3.064203994962101
Validation loss: 2.5155635534012584

Epoch: 248| Step: 0
Training loss: 2.5781528355800822
Validation loss: 2.5026124814491135

Epoch: 6| Step: 1
Training loss: 2.2239246470083667
Validation loss: 2.5262562821184456

Epoch: 6| Step: 2
Training loss: 1.6725395521838593
Validation loss: 2.5358309168892372

Epoch: 6| Step: 3
Training loss: 3.0287732889915016
Validation loss: 2.563143316012945

Epoch: 6| Step: 4
Training loss: 2.214891867140195
Validation loss: 2.5754871321203465

Epoch: 6| Step: 5
Training loss: 2.0936360114653736
Validation loss: 2.5798537806296538

Epoch: 6| Step: 6
Training loss: 2.102000591463102
Validation loss: 2.61153280007199

Epoch: 6| Step: 7
Training loss: 2.569029421122977
Validation loss: 2.628462241447936

Epoch: 6| Step: 8
Training loss: 2.300523416421131
Validation loss: 2.615843029954172

Epoch: 6| Step: 9
Training loss: 1.554403921363663
Validation loss: 2.5672379863137333

Epoch: 6| Step: 10
Training loss: 2.25136207043207
Validation loss: 2.539831942833286

Epoch: 6| Step: 11
Training loss: 2.333811324978552
Validation loss: 2.5219006971572906

Epoch: 6| Step: 12
Training loss: 2.435138242897911
Validation loss: 2.5113991573096484

Epoch: 6| Step: 13
Training loss: 2.8570810924393473
Validation loss: 2.4978093881188768

Epoch: 249| Step: 0
Training loss: 2.0087389756608167
Validation loss: 2.5076062047290857

Epoch: 6| Step: 1
Training loss: 2.326144098969611
Validation loss: 2.5138147131255058

Epoch: 6| Step: 2
Training loss: 2.85175028143482
Validation loss: 2.508214219223302

Epoch: 6| Step: 3
Training loss: 2.621084108064885
Validation loss: 2.511132068450462

Epoch: 6| Step: 4
Training loss: 2.873615595000415
Validation loss: 2.5208797818362996

Epoch: 6| Step: 5
Training loss: 2.2024065293602924
Validation loss: 2.529467453476204

Epoch: 6| Step: 6
Training loss: 2.045158306980257
Validation loss: 2.5125491211804003

Epoch: 6| Step: 7
Training loss: 2.385440265477707
Validation loss: 2.515294434368054

Epoch: 6| Step: 8
Training loss: 2.2080099720798816
Validation loss: 2.511392875798271

Epoch: 6| Step: 9
Training loss: 2.3487617314539544
Validation loss: 2.516958574287823

Epoch: 6| Step: 10
Training loss: 2.772643413497864
Validation loss: 2.5127158709605597

Epoch: 6| Step: 11
Training loss: 1.9381740382048296
Validation loss: 2.518488074125936

Epoch: 6| Step: 12
Training loss: 2.0893645405600263
Validation loss: 2.5310059417992474

Epoch: 6| Step: 13
Training loss: 1.8363327574859138
Validation loss: 2.5348953873055446

Epoch: 250| Step: 0
Training loss: 2.1981944651361434
Validation loss: 2.538943275195618

Epoch: 6| Step: 1
Training loss: 2.4694893611069397
Validation loss: 2.5185339558144886

Epoch: 6| Step: 2
Training loss: 2.128923272581027
Validation loss: 2.5414029959153472

Epoch: 6| Step: 3
Training loss: 2.283247399859429
Validation loss: 2.5278550288747264

Epoch: 6| Step: 4
Training loss: 1.8171086747710894
Validation loss: 2.5514604989209246

Epoch: 6| Step: 5
Training loss: 2.412109375
Validation loss: 2.5432065041025997

Epoch: 6| Step: 6
Training loss: 2.549221151750037
Validation loss: 2.5524252344627607

Epoch: 6| Step: 7
Training loss: 2.5282867417624484
Validation loss: 2.5556911243079266

Epoch: 6| Step: 8
Training loss: 2.2146885193480217
Validation loss: 2.5277643811798955

Epoch: 6| Step: 9
Training loss: 1.6539374707590326
Validation loss: 2.5442580291415444

Epoch: 6| Step: 10
Training loss: 2.8827572535568393
Validation loss: 2.521619206612437

Epoch: 6| Step: 11
Training loss: 2.6174267104417064
Validation loss: 2.5218789845513525

Epoch: 6| Step: 12
Training loss: 2.304281942600795
Validation loss: 2.527559564997267

Epoch: 6| Step: 13
Training loss: 2.1447900501286505
Validation loss: 2.5236176464864193

Epoch: 251| Step: 0
Training loss: 2.2111659926031066
Validation loss: 2.5128937895027663

Epoch: 6| Step: 1
Training loss: 2.4629322505279996
Validation loss: 2.5243888612690744

Epoch: 6| Step: 2
Training loss: 2.512312609768227
Validation loss: 2.526174472319679

Epoch: 6| Step: 3
Training loss: 3.3318828446856363
Validation loss: 2.524001760157734

Epoch: 6| Step: 4
Training loss: 2.1885052142465695
Validation loss: 2.522874200423097

Epoch: 6| Step: 5
Training loss: 2.0662899453328407
Validation loss: 2.5361288797991666

Epoch: 6| Step: 6
Training loss: 2.0960994463035254
Validation loss: 2.5288816918881714

Epoch: 6| Step: 7
Training loss: 2.202816123142258
Validation loss: 2.569074508452701

Epoch: 6| Step: 8
Training loss: 2.389138451436127
Validation loss: 2.55885177747813

Epoch: 6| Step: 9
Training loss: 1.9668691824507887
Validation loss: 2.595960188613785

Epoch: 6| Step: 10
Training loss: 2.5248805782668766
Validation loss: 2.567721807252353

Epoch: 6| Step: 11
Training loss: 1.8277907758841285
Validation loss: 2.5749763142011814

Epoch: 6| Step: 12
Training loss: 2.4795429574607226
Validation loss: 2.577205871736109

Epoch: 6| Step: 13
Training loss: 1.5753647487869535
Validation loss: 2.565326813976856

Epoch: 252| Step: 0
Training loss: 2.581455091406111
Validation loss: 2.5421255406209076

Epoch: 6| Step: 1
Training loss: 2.180952026651139
Validation loss: 2.531283460796213

Epoch: 6| Step: 2
Training loss: 2.199906399209567
Validation loss: 2.506460821808793

Epoch: 6| Step: 3
Training loss: 1.7117789650950257
Validation loss: 2.523350307662828

Epoch: 6| Step: 4
Training loss: 2.7297834810743034
Validation loss: 2.5162652663986758

Epoch: 6| Step: 5
Training loss: 2.021150806566829
Validation loss: 2.5212498207829817

Epoch: 6| Step: 6
Training loss: 1.8944176079398927
Validation loss: 2.510425525401671

Epoch: 6| Step: 7
Training loss: 2.1398826481381485
Validation loss: 2.532026430835746

Epoch: 6| Step: 8
Training loss: 2.203878828362894
Validation loss: 2.5251949083999308

Epoch: 6| Step: 9
Training loss: 1.8121301997230472
Validation loss: 2.513042443269834

Epoch: 6| Step: 10
Training loss: 2.3335508063559978
Validation loss: 2.517825489109323

Epoch: 6| Step: 11
Training loss: 2.337114936813069
Validation loss: 2.539067813183043

Epoch: 6| Step: 12
Training loss: 2.8230004010796472
Validation loss: 2.5465336904418683

Epoch: 6| Step: 13
Training loss: 2.5778930559726922
Validation loss: 2.535638372486142

Epoch: 253| Step: 0
Training loss: 2.1032658023945667
Validation loss: 2.5567463891067983

Epoch: 6| Step: 1
Training loss: 2.544013164882065
Validation loss: 2.562390891132566

Epoch: 6| Step: 2
Training loss: 2.3613283269359924
Validation loss: 2.564961964236614

Epoch: 6| Step: 3
Training loss: 2.2956676813400962
Validation loss: 2.5589053364663754

Epoch: 6| Step: 4
Training loss: 1.763077780528378
Validation loss: 2.5737918852945323

Epoch: 6| Step: 5
Training loss: 2.085847659801622
Validation loss: 2.573623518946186

Epoch: 6| Step: 6
Training loss: 2.205859712222725
Validation loss: 2.547896587909259

Epoch: 6| Step: 7
Training loss: 2.3055174286944076
Validation loss: 2.5336773069994987

Epoch: 6| Step: 8
Training loss: 2.442494093576433
Validation loss: 2.5323898276527887

Epoch: 6| Step: 9
Training loss: 2.2111146673922586
Validation loss: 2.5238553735564646

Epoch: 6| Step: 10
Training loss: 2.5465849728820924
Validation loss: 2.5346262357702227

Epoch: 6| Step: 11
Training loss: 2.3296765783247095
Validation loss: 2.5310473105827964

Epoch: 6| Step: 12
Training loss: 1.475369895201619
Validation loss: 2.5391939725827553

Epoch: 6| Step: 13
Training loss: 2.9904333804615204
Validation loss: 2.5578761601434477

Epoch: 254| Step: 0
Training loss: 1.9677195198490982
Validation loss: 2.565670889329039

Epoch: 6| Step: 1
Training loss: 2.682420499108838
Validation loss: 2.55623840167734

Epoch: 6| Step: 2
Training loss: 2.0806000390565154
Validation loss: 2.594756264421469

Epoch: 6| Step: 3
Training loss: 2.213272317692607
Validation loss: 2.593595998091123

Epoch: 6| Step: 4
Training loss: 2.470369893999174
Validation loss: 2.6062732314333013

Epoch: 6| Step: 5
Training loss: 2.2133715276218564
Validation loss: 2.574697555137755

Epoch: 6| Step: 6
Training loss: 2.1744109792164097
Validation loss: 2.616588467038916

Epoch: 6| Step: 7
Training loss: 2.224849215766756
Validation loss: 2.592407292664519

Epoch: 6| Step: 8
Training loss: 2.2016331376384675
Validation loss: 2.5564965891644653

Epoch: 6| Step: 9
Training loss: 2.0369178923368683
Validation loss: 2.5382245994501003

Epoch: 6| Step: 10
Training loss: 2.3440222009902874
Validation loss: 2.528705181102408

Epoch: 6| Step: 11
Training loss: 2.2100045220514355
Validation loss: 2.535056309623242

Epoch: 6| Step: 12
Training loss: 2.4245585678871504
Validation loss: 2.527412063799542

Epoch: 6| Step: 13
Training loss: 2.603443828717476
Validation loss: 2.5261502639131606

Epoch: 255| Step: 0
Training loss: 1.9058350908843713
Validation loss: 2.5389932319778277

Epoch: 6| Step: 1
Training loss: 2.72946196455763
Validation loss: 2.5457611924942203

Epoch: 6| Step: 2
Training loss: 2.0316544350226415
Validation loss: 2.537349338161622

Epoch: 6| Step: 3
Training loss: 1.6804405476053756
Validation loss: 2.551911676563569

Epoch: 6| Step: 4
Training loss: 3.0254977991023306
Validation loss: 2.5731556635961383

Epoch: 6| Step: 5
Training loss: 1.9255398798289391
Validation loss: 2.5898433971069155

Epoch: 6| Step: 6
Training loss: 2.26850045673449
Validation loss: 2.5817524600277846

Epoch: 6| Step: 7
Training loss: 1.703592778632181
Validation loss: 2.5719342898166437

Epoch: 6| Step: 8
Training loss: 1.8523581682446093
Validation loss: 2.5621861366404515

Epoch: 6| Step: 9
Training loss: 2.5142928677618146
Validation loss: 2.5464482486224203

Epoch: 6| Step: 10
Training loss: 1.916445373807606
Validation loss: 2.545678214442553

Epoch: 6| Step: 11
Training loss: 3.3086493801587977
Validation loss: 2.5491161665996516

Epoch: 6| Step: 12
Training loss: 2.221087661504032
Validation loss: 2.541096675517476

Epoch: 6| Step: 13
Training loss: 2.1444468664024963
Validation loss: 2.5524208831730695

Epoch: 256| Step: 0
Training loss: 2.5711553519283896
Validation loss: 2.5459852946411874

Epoch: 6| Step: 1
Training loss: 1.8895389180148874
Validation loss: 2.5551225562043443

Epoch: 6| Step: 2
Training loss: 2.4418761266584217
Validation loss: 2.530682221457643

Epoch: 6| Step: 3
Training loss: 1.8372665464575175
Validation loss: 2.5499472001786496

Epoch: 6| Step: 4
Training loss: 1.6594049885656788
Validation loss: 2.553933455216425

Epoch: 6| Step: 5
Training loss: 1.9412733681101915
Validation loss: 2.5438569017546597

Epoch: 6| Step: 6
Training loss: 2.8900901505820213
Validation loss: 2.535461195839689

Epoch: 6| Step: 7
Training loss: 1.9816050382848085
Validation loss: 2.569947097916626

Epoch: 6| Step: 8
Training loss: 2.364891827551118
Validation loss: 2.569966077407515

Epoch: 6| Step: 9
Training loss: 2.319409435513083
Validation loss: 2.5974829288493226

Epoch: 6| Step: 10
Training loss: 2.325379051565459
Validation loss: 2.616397992896857

Epoch: 6| Step: 11
Training loss: 2.507249049886496
Validation loss: 2.6096861724186264

Epoch: 6| Step: 12
Training loss: 1.9412623146781705
Validation loss: 2.5793222672131493

Epoch: 6| Step: 13
Training loss: 2.718658094935478
Validation loss: 2.5827443210213326

Epoch: 257| Step: 0
Training loss: 2.142717661178183
Validation loss: 2.5752501363154003

Epoch: 6| Step: 1
Training loss: 2.8784817055204837
Validation loss: 2.5584281576602725

Epoch: 6| Step: 2
Training loss: 1.954781158179424
Validation loss: 2.5714330269507504

Epoch: 6| Step: 3
Training loss: 1.9950793053106335
Validation loss: 2.5376179894763147

Epoch: 6| Step: 4
Training loss: 2.701490492382331
Validation loss: 2.541642475534184

Epoch: 6| Step: 5
Training loss: 2.074237255868777
Validation loss: 2.5284776379596736

Epoch: 6| Step: 6
Training loss: 2.186069456729867
Validation loss: 2.523144148869769

Epoch: 6| Step: 7
Training loss: 2.5337360559728137
Validation loss: 2.5446671197128126

Epoch: 6| Step: 8
Training loss: 2.1712887199081092
Validation loss: 2.531866375322985

Epoch: 6| Step: 9
Training loss: 1.7490821883889567
Validation loss: 2.56047789332595

Epoch: 6| Step: 10
Training loss: 1.5363226189455268
Validation loss: 2.558819849638392

Epoch: 6| Step: 11
Training loss: 3.339943974647506
Validation loss: 2.5425732876928016

Epoch: 6| Step: 12
Training loss: 2.0131919429512473
Validation loss: 2.5489018650033195

Epoch: 6| Step: 13
Training loss: 1.933138213780034
Validation loss: 2.5306449606583934

Epoch: 258| Step: 0
Training loss: 1.6464183427595187
Validation loss: 2.5586066714050313

Epoch: 6| Step: 1
Training loss: 2.137399512711865
Validation loss: 2.5473701292207567

Epoch: 6| Step: 2
Training loss: 2.2886885510065147
Validation loss: 2.5651812365938556

Epoch: 6| Step: 3
Training loss: 2.1102928142852417
Validation loss: 2.5523591002862958

Epoch: 6| Step: 4
Training loss: 2.084828971599424
Validation loss: 2.558029632890831

Epoch: 6| Step: 5
Training loss: 2.096219783922317
Validation loss: 2.55491946661452

Epoch: 6| Step: 6
Training loss: 2.2059431516459025
Validation loss: 2.5729844371400605

Epoch: 6| Step: 7
Training loss: 1.8506995656903065
Validation loss: 2.5748009879480094

Epoch: 6| Step: 8
Training loss: 2.1953340033838984
Validation loss: 2.5792559214376696

Epoch: 6| Step: 9
Training loss: 2.417723019243172
Validation loss: 2.5756824366851667

Epoch: 6| Step: 10
Training loss: 3.0772242123624034
Validation loss: 2.562883038309236

Epoch: 6| Step: 11
Training loss: 2.7027455322635183
Validation loss: 2.5602347200420277

Epoch: 6| Step: 12
Training loss: 2.696790914451302
Validation loss: 2.5681334034731265

Epoch: 6| Step: 13
Training loss: 1.8158767420619304
Validation loss: 2.565094309108531

Epoch: 259| Step: 0
Training loss: 2.015584900922898
Validation loss: 2.5430597854468893

Epoch: 6| Step: 1
Training loss: 1.6664228578894333
Validation loss: 2.5873775486988766

Epoch: 6| Step: 2
Training loss: 2.9787059685593924
Validation loss: 2.5644676283624532

Epoch: 6| Step: 3
Training loss: 2.081778162018454
Validation loss: 2.5857933134849893

Epoch: 6| Step: 4
Training loss: 1.6001385569183282
Validation loss: 2.5674286871258105

Epoch: 6| Step: 5
Training loss: 2.172208033214818
Validation loss: 2.5709921142247487

Epoch: 6| Step: 6
Training loss: 2.246468633796572
Validation loss: 2.5633152385994027

Epoch: 6| Step: 7
Training loss: 2.093021892515128
Validation loss: 2.570131506146667

Epoch: 6| Step: 8
Training loss: 1.8948896246096036
Validation loss: 2.545225127804509

Epoch: 6| Step: 9
Training loss: 2.7418311776041087
Validation loss: 2.5348542224067545

Epoch: 6| Step: 10
Training loss: 1.6660936880661725
Validation loss: 2.527621348807569

Epoch: 6| Step: 11
Training loss: 1.9940841323068943
Validation loss: 2.547002090996417

Epoch: 6| Step: 12
Training loss: 2.7140810107718276
Validation loss: 2.531036572033753

Epoch: 6| Step: 13
Training loss: 2.8673745907645563
Validation loss: 2.5388241700044394

Epoch: 260| Step: 0
Training loss: 2.57195936507285
Validation loss: 2.5732153643199953

Epoch: 6| Step: 1
Training loss: 1.9935795726103087
Validation loss: 2.6012017016102624

Epoch: 6| Step: 2
Training loss: 1.447503815482848
Validation loss: 2.595667126714283

Epoch: 6| Step: 3
Training loss: 2.0457130220649815
Validation loss: 2.605420708392122

Epoch: 6| Step: 4
Training loss: 2.3962036067827563
Validation loss: 2.5864345230397467

Epoch: 6| Step: 5
Training loss: 2.188129334520385
Validation loss: 2.5716517089224156

Epoch: 6| Step: 6
Training loss: 2.0604944593081536
Validation loss: 2.5729854641466834

Epoch: 6| Step: 7
Training loss: 2.4797715055662115
Validation loss: 2.5403966127713313

Epoch: 6| Step: 8
Training loss: 2.399513127692675
Validation loss: 2.5309523262217364

Epoch: 6| Step: 9
Training loss: 2.1661547520692306
Validation loss: 2.527973487692849

Epoch: 6| Step: 10
Training loss: 2.018144555728093
Validation loss: 2.5261260552746476

Epoch: 6| Step: 11
Training loss: 2.2788584466470785
Validation loss: 2.528894466560856

Epoch: 6| Step: 12
Training loss: 2.6136328399393203
Validation loss: 2.510349982445742

Epoch: 6| Step: 13
Training loss: 2.9870235813411785
Validation loss: 2.518942128782076

Epoch: 261| Step: 0
Training loss: 1.8327310035063462
Validation loss: 2.5075721269010436

Epoch: 6| Step: 1
Training loss: 2.670087428286726
Validation loss: 2.5374116979308954

Epoch: 6| Step: 2
Training loss: 2.009942375989263
Validation loss: 2.5621369577667803

Epoch: 6| Step: 3
Training loss: 1.5333863750212169
Validation loss: 2.5919548318080814

Epoch: 6| Step: 4
Training loss: 2.594561714101488
Validation loss: 2.6213881606311773

Epoch: 6| Step: 5
Training loss: 1.8463479827935128
Validation loss: 2.6395961480154537

Epoch: 6| Step: 6
Training loss: 2.5934536316467955
Validation loss: 2.6402270978486904

Epoch: 6| Step: 7
Training loss: 3.0423903105247208
Validation loss: 2.6675817787054896

Epoch: 6| Step: 8
Training loss: 2.350316931273142
Validation loss: 2.6897686247131314

Epoch: 6| Step: 9
Training loss: 2.127696738375078
Validation loss: 2.7053191553878335

Epoch: 6| Step: 10
Training loss: 2.2927040064238073
Validation loss: 2.6578368290305905

Epoch: 6| Step: 11
Training loss: 2.305947996798807
Validation loss: 2.5984750169594495

Epoch: 6| Step: 12
Training loss: 2.3137996217753565
Validation loss: 2.528587393014977

Epoch: 6| Step: 13
Training loss: 2.1543229932403594
Validation loss: 2.516366237325029

Epoch: 262| Step: 0
Training loss: 1.3490306535381196
Validation loss: 2.4995682820446

Epoch: 6| Step: 1
Training loss: 2.346506049645244
Validation loss: 2.4930391919145958

Epoch: 6| Step: 2
Training loss: 2.3642539804672578
Validation loss: 2.5084321711215787

Epoch: 6| Step: 3
Training loss: 2.5380000782058016
Validation loss: 2.4920715336939363

Epoch: 6| Step: 4
Training loss: 2.7204489825442373
Validation loss: 2.4939682835497345

Epoch: 6| Step: 5
Training loss: 2.08765218031562
Validation loss: 2.5106208422772567

Epoch: 6| Step: 6
Training loss: 1.967964439493375
Validation loss: 2.511072513706606

Epoch: 6| Step: 7
Training loss: 2.797758080217291
Validation loss: 2.5151384566299892

Epoch: 6| Step: 8
Training loss: 1.5405090040756606
Validation loss: 2.5306562347381334

Epoch: 6| Step: 9
Training loss: 1.8528072502896986
Validation loss: 2.54475678274131

Epoch: 6| Step: 10
Training loss: 2.5297587205027994
Validation loss: 2.5496527846813715

Epoch: 6| Step: 11
Training loss: 2.4955876513408426
Validation loss: 2.5507063336200155

Epoch: 6| Step: 12
Training loss: 2.6184837661190405
Validation loss: 2.554525807714548

Epoch: 6| Step: 13
Training loss: 2.3277950181021674
Validation loss: 2.569263278886407

Epoch: 263| Step: 0
Training loss: 1.5138033902039971
Validation loss: 2.583846569351277

Epoch: 6| Step: 1
Training loss: 2.5029439758297785
Validation loss: 2.5702143749920414

Epoch: 6| Step: 2
Training loss: 1.5679779919179473
Validation loss: 2.5630048704176724

Epoch: 6| Step: 3
Training loss: 2.0009267567160443
Validation loss: 2.529167291765801

Epoch: 6| Step: 4
Training loss: 2.274262059178396
Validation loss: 2.528188211588353

Epoch: 6| Step: 5
Training loss: 2.983491936699769
Validation loss: 2.5432052697636993

Epoch: 6| Step: 6
Training loss: 1.887493156269121
Validation loss: 2.5379040388579024

Epoch: 6| Step: 7
Training loss: 2.585905507054029
Validation loss: 2.5352094318472047

Epoch: 6| Step: 8
Training loss: 1.9007877197657246
Validation loss: 2.5299172994292713

Epoch: 6| Step: 9
Training loss: 2.5183941308119167
Validation loss: 2.529537799215725

Epoch: 6| Step: 10
Training loss: 2.087004427990605
Validation loss: 2.5331619326012684

Epoch: 6| Step: 11
Training loss: 2.464788227695283
Validation loss: 2.5265867582441155

Epoch: 6| Step: 12
Training loss: 2.892301825721897
Validation loss: 2.5383210023800493

Epoch: 6| Step: 13
Training loss: 1.913156224780789
Validation loss: 2.5460145038836886

Epoch: 264| Step: 0
Training loss: 2.7698338266649944
Validation loss: 2.5378585934752103

Epoch: 6| Step: 1
Training loss: 1.6210097693325998
Validation loss: 2.5348525607479075

Epoch: 6| Step: 2
Training loss: 3.2554829636756244
Validation loss: 2.586419559044219

Epoch: 6| Step: 3
Training loss: 2.2236752713337684
Validation loss: 2.549719846208356

Epoch: 6| Step: 4
Training loss: 2.5272190352126027
Validation loss: 2.5513902748167365

Epoch: 6| Step: 5
Training loss: 2.4654633095524887
Validation loss: 2.5639459128241837

Epoch: 6| Step: 6
Training loss: 2.059226588457094
Validation loss: 2.5781777964108494

Epoch: 6| Step: 7
Training loss: 2.1511368872847014
Validation loss: 2.5598048248619296

Epoch: 6| Step: 8
Training loss: 1.8274870191287895
Validation loss: 2.561565926737888

Epoch: 6| Step: 9
Training loss: 1.3838676263424798
Validation loss: 2.5878139575661936

Epoch: 6| Step: 10
Training loss: 1.869878704910693
Validation loss: 2.586732048907591

Epoch: 6| Step: 11
Training loss: 2.090225099369428
Validation loss: 2.563159051517176

Epoch: 6| Step: 12
Training loss: 2.1789921570943553
Validation loss: 2.550684570225072

Epoch: 6| Step: 13
Training loss: 2.2895261535816904
Validation loss: 2.5460674355149706

Epoch: 265| Step: 0
Training loss: 2.0218417086801073
Validation loss: 2.538561046674028

Epoch: 6| Step: 1
Training loss: 2.504251869855215
Validation loss: 2.5412611924559974

Epoch: 6| Step: 2
Training loss: 1.7536460496543371
Validation loss: 2.550353516277397

Epoch: 6| Step: 3
Training loss: 2.4887769555663493
Validation loss: 2.5347799012982395

Epoch: 6| Step: 4
Training loss: 2.1335976521342133
Validation loss: 2.5538097277388085

Epoch: 6| Step: 5
Training loss: 2.097868782514746
Validation loss: 2.572436397274115

Epoch: 6| Step: 6
Training loss: 2.659104193807642
Validation loss: 2.5687291796506444

Epoch: 6| Step: 7
Training loss: 1.8351195765728852
Validation loss: 2.6085216931550095

Epoch: 6| Step: 8
Training loss: 2.590324805966007
Validation loss: 2.57029694742833

Epoch: 6| Step: 9
Training loss: 1.867046909545946
Validation loss: 2.5557529821245697

Epoch: 6| Step: 10
Training loss: 2.196801708838402
Validation loss: 2.536266787043993

Epoch: 6| Step: 11
Training loss: 2.6990415567405046
Validation loss: 2.540478120994541

Epoch: 6| Step: 12
Training loss: 2.3678599998096868
Validation loss: 2.540195607415481

Epoch: 6| Step: 13
Training loss: 1.763396688391609
Validation loss: 2.53305049329556

Epoch: 266| Step: 0
Training loss: 2.4616573189274047
Validation loss: 2.5439361123024216

Epoch: 6| Step: 1
Training loss: 2.6495652399966554
Validation loss: 2.521595246004712

Epoch: 6| Step: 2
Training loss: 1.9480813784667483
Validation loss: 2.5287827920539607

Epoch: 6| Step: 3
Training loss: 2.067983216687982
Validation loss: 2.543058840107552

Epoch: 6| Step: 4
Training loss: 2.2493920034585764
Validation loss: 2.5123164374004494

Epoch: 6| Step: 5
Training loss: 2.2495763167853418
Validation loss: 2.5488907807542778

Epoch: 6| Step: 6
Training loss: 2.3498415305092086
Validation loss: 2.5328396487639133

Epoch: 6| Step: 7
Training loss: 2.540029300610807
Validation loss: 2.575060238488526

Epoch: 6| Step: 8
Training loss: 2.667584906874021
Validation loss: 2.5781241831152037

Epoch: 6| Step: 9
Training loss: 2.06524983518069
Validation loss: 2.6122986182026455

Epoch: 6| Step: 10
Training loss: 2.5665158694007215
Validation loss: 2.638922705071152

Epoch: 6| Step: 11
Training loss: 1.95758298607866
Validation loss: 2.6231967848155926

Epoch: 6| Step: 12
Training loss: 1.9799598777443488
Validation loss: 2.6303102882692904

Epoch: 6| Step: 13
Training loss: 1.559699868283294
Validation loss: 2.571786467525922

Epoch: 267| Step: 0
Training loss: 1.8443321989878583
Validation loss: 2.5767404865318615

Epoch: 6| Step: 1
Training loss: 1.887397470278963
Validation loss: 2.572021071101009

Epoch: 6| Step: 2
Training loss: 2.4673861828867585
Validation loss: 2.5563934105623987

Epoch: 6| Step: 3
Training loss: 2.010506095939603
Validation loss: 2.5760919897396186

Epoch: 6| Step: 4
Training loss: 2.5744345405215054
Validation loss: 2.56029626632033

Epoch: 6| Step: 5
Training loss: 2.2065213044722327
Validation loss: 2.545288075204414

Epoch: 6| Step: 6
Training loss: 2.0455148851761735
Validation loss: 2.5440802969726124

Epoch: 6| Step: 7
Training loss: 2.342151147357982
Validation loss: 2.5184182244346696

Epoch: 6| Step: 8
Training loss: 2.5925591734089606
Validation loss: 2.531581966782223

Epoch: 6| Step: 9
Training loss: 2.4823717401875838
Validation loss: 2.5362099611428714

Epoch: 6| Step: 10
Training loss: 1.341020873337567
Validation loss: 2.565555224319722

Epoch: 6| Step: 11
Training loss: 2.530358616739746
Validation loss: 2.5244854305172044

Epoch: 6| Step: 12
Training loss: 2.736262950352484
Validation loss: 2.530049153002503

Epoch: 6| Step: 13
Training loss: 1.8643867843720983
Validation loss: 2.532324551099832

Epoch: 268| Step: 0
Training loss: 2.509052956178478
Validation loss: 2.5353378755921807

Epoch: 6| Step: 1
Training loss: 2.8361535528604285
Validation loss: 2.5410596143436854

Epoch: 6| Step: 2
Training loss: 1.6077540113600437
Validation loss: 2.524323362077481

Epoch: 6| Step: 3
Training loss: 2.324792512228683
Validation loss: 2.5385827966070535

Epoch: 6| Step: 4
Training loss: 1.929126302682712
Validation loss: 2.552306143447921

Epoch: 6| Step: 5
Training loss: 1.675458828157551
Validation loss: 2.536111245242957

Epoch: 6| Step: 6
Training loss: 1.9943914451865514
Validation loss: 2.5303774377612984

Epoch: 6| Step: 7
Training loss: 2.4478643100631534
Validation loss: 2.519759561608299

Epoch: 6| Step: 8
Training loss: 2.4547424815313654
Validation loss: 2.543399491089197

Epoch: 6| Step: 9
Training loss: 2.287452939075759
Validation loss: 2.517509702192171

Epoch: 6| Step: 10
Training loss: 1.8248853751987097
Validation loss: 2.5449248885017095

Epoch: 6| Step: 11
Training loss: 2.4383461290581314
Validation loss: 2.5682346173483053

Epoch: 6| Step: 12
Training loss: 1.97197072420964
Validation loss: 2.529572798555627

Epoch: 6| Step: 13
Training loss: 2.512849971253227
Validation loss: 2.5446626848868097

Epoch: 269| Step: 0
Training loss: 1.9034956748037497
Validation loss: 2.530832750757691

Epoch: 6| Step: 1
Training loss: 1.969135549425615
Validation loss: 2.5269822928871637

Epoch: 6| Step: 2
Training loss: 2.436026298857043
Validation loss: 2.5276529161358514

Epoch: 6| Step: 3
Training loss: 2.0716081128038355
Validation loss: 2.5301430247895302

Epoch: 6| Step: 4
Training loss: 2.238879697994849
Validation loss: 2.5306793166110055

Epoch: 6| Step: 5
Training loss: 2.10158972740262
Validation loss: 2.5507753458777462

Epoch: 6| Step: 6
Training loss: 2.213835956233723
Validation loss: 2.5626099260524255

Epoch: 6| Step: 7
Training loss: 2.574005627528918
Validation loss: 2.5674913996942754

Epoch: 6| Step: 8
Training loss: 1.948910369636257
Validation loss: 2.5849200779791617

Epoch: 6| Step: 9
Training loss: 1.6511893782941232
Validation loss: 2.6264410604693307

Epoch: 6| Step: 10
Training loss: 1.8048234368192477
Validation loss: 2.5994164184831736

Epoch: 6| Step: 11
Training loss: 3.1048549597338497
Validation loss: 2.604006942937046

Epoch: 6| Step: 12
Training loss: 2.1340012364120264
Validation loss: 2.5790326302929247

Epoch: 6| Step: 13
Training loss: 2.8146746387444086
Validation loss: 2.56697352626867

Epoch: 270| Step: 0
Training loss: 2.889801897961251
Validation loss: 2.5774037517876205

Epoch: 6| Step: 1
Training loss: 2.6053902358274135
Validation loss: 2.5163853288073157

Epoch: 6| Step: 2
Training loss: 1.728744853709209
Validation loss: 2.5252485360682413

Epoch: 6| Step: 3
Training loss: 1.8037634130918987
Validation loss: 2.506709187870691

Epoch: 6| Step: 4
Training loss: 1.888726913139375
Validation loss: 2.522494995344104

Epoch: 6| Step: 5
Training loss: 2.956915788903366
Validation loss: 2.516681019055786

Epoch: 6| Step: 6
Training loss: 2.1270007643956084
Validation loss: 2.514325866750168

Epoch: 6| Step: 7
Training loss: 3.048291625301907
Validation loss: 2.509603975584699

Epoch: 6| Step: 8
Training loss: 2.4690020468770193
Validation loss: 2.517214034303929

Epoch: 6| Step: 9
Training loss: 2.260990216550788
Validation loss: 2.511500102365218

Epoch: 6| Step: 10
Training loss: 1.9166506338140004
Validation loss: 2.531632994887654

Epoch: 6| Step: 11
Training loss: 1.3702032343625676
Validation loss: 2.5391755924958943

Epoch: 6| Step: 12
Training loss: 1.9377758075923315
Validation loss: 2.559155079852545

Epoch: 6| Step: 13
Training loss: 1.8368711005160074
Validation loss: 2.5820157680153124

Epoch: 271| Step: 0
Training loss: 2.00842940653394
Validation loss: 2.597313267907739

Epoch: 6| Step: 1
Training loss: 2.633371265556667
Validation loss: 2.6116861094676347

Epoch: 6| Step: 2
Training loss: 2.214350677451404
Validation loss: 2.6214673021988664

Epoch: 6| Step: 3
Training loss: 3.04184044816173
Validation loss: 2.5661584123835177

Epoch: 6| Step: 4
Training loss: 2.035184834402189
Validation loss: 2.5472958924920484

Epoch: 6| Step: 5
Training loss: 1.9682123570272432
Validation loss: 2.524677172881814

Epoch: 6| Step: 6
Training loss: 2.002305132924778
Validation loss: 2.5222275296499435

Epoch: 6| Step: 7
Training loss: 1.8350398040113212
Validation loss: 2.5008734131037382

Epoch: 6| Step: 8
Training loss: 2.3847477292850754
Validation loss: 2.4836268228090965

Epoch: 6| Step: 9
Training loss: 2.4016473520611035
Validation loss: 2.4749918227911576

Epoch: 6| Step: 10
Training loss: 1.8745617036348132
Validation loss: 2.478654926174089

Epoch: 6| Step: 11
Training loss: 2.054511581258284
Validation loss: 2.4809524344892386

Epoch: 6| Step: 12
Training loss: 2.9465256679108895
Validation loss: 2.4659438622874044

Epoch: 6| Step: 13
Training loss: 1.902019621947405
Validation loss: 2.486105086557866

Epoch: 272| Step: 0
Training loss: 2.800513261346487
Validation loss: 2.4894579825240934

Epoch: 6| Step: 1
Training loss: 2.4952668206722213
Validation loss: 2.4651608996079366

Epoch: 6| Step: 2
Training loss: 1.8897134143786634
Validation loss: 2.497470768403292

Epoch: 6| Step: 3
Training loss: 2.31199145524713
Validation loss: 2.502049067313173

Epoch: 6| Step: 4
Training loss: 2.4938628207047904
Validation loss: 2.4930837647929787

Epoch: 6| Step: 5
Training loss: 2.612220172406219
Validation loss: 2.509835525509036

Epoch: 6| Step: 6
Training loss: 1.7627440046945064
Validation loss: 2.5309731916868974

Epoch: 6| Step: 7
Training loss: 2.392401440383077
Validation loss: 2.5301148808950416

Epoch: 6| Step: 8
Training loss: 2.0779111364931153
Validation loss: 2.5535393797685852

Epoch: 6| Step: 9
Training loss: 1.5265553969156491
Validation loss: 2.5879132271025567

Epoch: 6| Step: 10
Training loss: 2.1364070797529906
Validation loss: 2.604441732502669

Epoch: 6| Step: 11
Training loss: 2.3409341809105757
Validation loss: 2.5668340023616114

Epoch: 6| Step: 12
Training loss: 2.5430649418370894
Validation loss: 2.593090111310908

Epoch: 6| Step: 13
Training loss: 2.0338623854259024
Validation loss: 2.595260517320144

Epoch: 273| Step: 0
Training loss: 1.7982675215186907
Validation loss: 2.5651021786341572

Epoch: 6| Step: 1
Training loss: 2.5529064070882135
Validation loss: 2.5507486057967492

Epoch: 6| Step: 2
Training loss: 2.081137058985417
Validation loss: 2.5237110017279747

Epoch: 6| Step: 3
Training loss: 2.3247338501557677
Validation loss: 2.528516070057797

Epoch: 6| Step: 4
Training loss: 2.3406499069375846
Validation loss: 2.5427727767818853

Epoch: 6| Step: 5
Training loss: 2.432439784591607
Validation loss: 2.545334316821314

Epoch: 6| Step: 6
Training loss: 1.6333053794077652
Validation loss: 2.5598721404481326

Epoch: 6| Step: 7
Training loss: 2.211036383368741
Validation loss: 2.5440912069414403

Epoch: 6| Step: 8
Training loss: 2.2805688964767428
Validation loss: 2.544655657857951

Epoch: 6| Step: 9
Training loss: 2.5560273089793166
Validation loss: 2.5439591049240233

Epoch: 6| Step: 10
Training loss: 2.2963376616896176
Validation loss: 2.580855139702952

Epoch: 6| Step: 11
Training loss: 1.9719273192995976
Validation loss: 2.5365972200211964

Epoch: 6| Step: 12
Training loss: 1.8627193091391663
Validation loss: 2.5424348472867018

Epoch: 6| Step: 13
Training loss: 2.504746889587049
Validation loss: 2.519231387093678

Epoch: 274| Step: 0
Training loss: 2.2438882896714483
Validation loss: 2.527964323680368

Epoch: 6| Step: 1
Training loss: 2.8697308893339226
Validation loss: 2.5108831824279196

Epoch: 6| Step: 2
Training loss: 1.3501620230757152
Validation loss: 2.5207478584952114

Epoch: 6| Step: 3
Training loss: 2.6900424907122114
Validation loss: 2.5270477388857024

Epoch: 6| Step: 4
Training loss: 2.1598817399111487
Validation loss: 2.5262714215955446

Epoch: 6| Step: 5
Training loss: 2.0927841463940893
Validation loss: 2.5276779433390475

Epoch: 6| Step: 6
Training loss: 2.890708468495068
Validation loss: 2.53320594852146

Epoch: 6| Step: 7
Training loss: 1.7511837906339534
Validation loss: 2.5578624505300325

Epoch: 6| Step: 8
Training loss: 2.9937179277012134
Validation loss: 2.56037780839834

Epoch: 6| Step: 9
Training loss: 1.9468090627902574
Validation loss: 2.5856181213518545

Epoch: 6| Step: 10
Training loss: 1.8871934502866767
Validation loss: 2.581832531829303

Epoch: 6| Step: 11
Training loss: 1.9830113328541588
Validation loss: 2.580707297182751

Epoch: 6| Step: 12
Training loss: 1.8918763110355086
Validation loss: 2.5458168842972593

Epoch: 6| Step: 13
Training loss: 1.6519756222697375
Validation loss: 2.5661223945040175

Epoch: 275| Step: 0
Training loss: 1.7719170190312987
Validation loss: 2.5245771796862995

Epoch: 6| Step: 1
Training loss: 2.2430862592623804
Validation loss: 2.523398651989291

Epoch: 6| Step: 2
Training loss: 2.5460135284268177
Validation loss: 2.54118393915504

Epoch: 6| Step: 3
Training loss: 2.3380297218698227
Validation loss: 2.53347361975121

Epoch: 6| Step: 4
Training loss: 2.3004867287484947
Validation loss: 2.5382226347209436

Epoch: 6| Step: 5
Training loss: 2.926923175018596
Validation loss: 2.55716644933574

Epoch: 6| Step: 6
Training loss: 1.6938927678258804
Validation loss: 2.5523002739908742

Epoch: 6| Step: 7
Training loss: 1.9707711759071003
Validation loss: 2.571733246331007

Epoch: 6| Step: 8
Training loss: 2.285915046628556
Validation loss: 2.584295775472679

Epoch: 6| Step: 9
Training loss: 1.884505780744302
Validation loss: 2.6160941501934505

Epoch: 6| Step: 10
Training loss: 2.272045745100298
Validation loss: 2.5537378099436583

Epoch: 6| Step: 11
Training loss: 1.873867519426584
Validation loss: 2.540812244530031

Epoch: 6| Step: 12
Training loss: 2.3399530808725233
Validation loss: 2.5492361002861696

Epoch: 6| Step: 13
Training loss: 2.123161642697736
Validation loss: 2.538057928651206

Epoch: 276| Step: 0
Training loss: 1.8593995549479934
Validation loss: 2.5646547856565935

Epoch: 6| Step: 1
Training loss: 1.9951266878100717
Validation loss: 2.559258046193113

Epoch: 6| Step: 2
Training loss: 2.3164303345738855
Validation loss: 2.535457489345366

Epoch: 6| Step: 3
Training loss: 1.4006144878055944
Validation loss: 2.556991828904407

Epoch: 6| Step: 4
Training loss: 1.8889298208638678
Validation loss: 2.5348533288733592

Epoch: 6| Step: 5
Training loss: 2.5364324945678156
Validation loss: 2.56886805922824

Epoch: 6| Step: 6
Training loss: 2.474526130703251
Validation loss: 2.5789538659807105

Epoch: 6| Step: 7
Training loss: 1.3050638900843698
Validation loss: 2.6240445320616947

Epoch: 6| Step: 8
Training loss: 2.3835906212210087
Validation loss: 2.630369749246493

Epoch: 6| Step: 9
Training loss: 2.8102363801953105
Validation loss: 2.633601929651815

Epoch: 6| Step: 10
Training loss: 2.282510383139451
Validation loss: 2.6165629234725176

Epoch: 6| Step: 11
Training loss: 2.031326292512562
Validation loss: 2.662775483900996

Epoch: 6| Step: 12
Training loss: 2.483806041129454
Validation loss: 2.706281638015573

Epoch: 6| Step: 13
Training loss: 2.7135187442175015
Validation loss: 2.62932725003869

Epoch: 277| Step: 0
Training loss: 1.7426026538182013
Validation loss: 2.58152031087363

Epoch: 6| Step: 1
Training loss: 2.3993828615823443
Validation loss: 2.507851391388729

Epoch: 6| Step: 2
Training loss: 2.4367565097066337
Validation loss: 2.5101613248601025

Epoch: 6| Step: 3
Training loss: 2.4031963045135
Validation loss: 2.5099557371656824

Epoch: 6| Step: 4
Training loss: 1.8011787952165232
Validation loss: 2.4954689290558147

Epoch: 6| Step: 5
Training loss: 2.613420650943758
Validation loss: 2.4904345861995116

Epoch: 6| Step: 6
Training loss: 2.2749369811667375
Validation loss: 2.5005902070492674

Epoch: 6| Step: 7
Training loss: 2.4298049554922345
Validation loss: 2.501263617015085

Epoch: 6| Step: 8
Training loss: 2.4904405934834926
Validation loss: 2.4899532064639582

Epoch: 6| Step: 9
Training loss: 2.675331779653803
Validation loss: 2.502792928181512

Epoch: 6| Step: 10
Training loss: 2.2281824476371983
Validation loss: 2.588732957327982

Epoch: 6| Step: 11
Training loss: 1.9244181856052958
Validation loss: 2.674714020864515

Epoch: 6| Step: 12
Training loss: 2.169951760595278
Validation loss: 2.7225802395908816

Epoch: 6| Step: 13
Training loss: 2.3344460513576273
Validation loss: 2.7372698473746047

Epoch: 278| Step: 0
Training loss: 2.1755536438051752
Validation loss: 2.6921638710607145

Epoch: 6| Step: 1
Training loss: 1.8987771817459755
Validation loss: 2.5858685502524628

Epoch: 6| Step: 2
Training loss: 2.499647401740118
Validation loss: 2.5312089798982624

Epoch: 6| Step: 3
Training loss: 1.8116428058296443
Validation loss: 2.5162354828336326

Epoch: 6| Step: 4
Training loss: 2.3206663536211107
Validation loss: 2.502527294638881

Epoch: 6| Step: 5
Training loss: 1.4838076661753725
Validation loss: 2.496317678803415

Epoch: 6| Step: 6
Training loss: 2.134009503952071
Validation loss: 2.4825476557782413

Epoch: 6| Step: 7
Training loss: 2.1479487192578697
Validation loss: 2.489586807525211

Epoch: 6| Step: 8
Training loss: 2.9659711179555317
Validation loss: 2.485276592450437

Epoch: 6| Step: 9
Training loss: 2.198816943686596
Validation loss: 2.49055202477735

Epoch: 6| Step: 10
Training loss: 2.4304242259073203
Validation loss: 2.500827493411852

Epoch: 6| Step: 11
Training loss: 2.2100025801837755
Validation loss: 2.534535320712916

Epoch: 6| Step: 12
Training loss: 2.4551228934176486
Validation loss: 2.541045540338612

Epoch: 6| Step: 13
Training loss: 2.354029378573162
Validation loss: 2.5746682931768783

Epoch: 279| Step: 0
Training loss: 2.1745006689657
Validation loss: 2.6114066888921474

Epoch: 6| Step: 1
Training loss: 2.025632985401509
Validation loss: 2.636691035372285

Epoch: 6| Step: 2
Training loss: 1.7993181950678014
Validation loss: 2.5972963088536125

Epoch: 6| Step: 3
Training loss: 2.31058649849795
Validation loss: 2.580927471980958

Epoch: 6| Step: 4
Training loss: 2.356211176787671
Validation loss: 2.5224306914804924

Epoch: 6| Step: 5
Training loss: 2.115502056116319
Validation loss: 2.5067831840556973

Epoch: 6| Step: 6
Training loss: 2.2841099617938534
Validation loss: 2.5155252235480967

Epoch: 6| Step: 7
Training loss: 2.5453714250332373
Validation loss: 2.5077016613829173

Epoch: 6| Step: 8
Training loss: 2.1622131377893252
Validation loss: 2.5238225149109925

Epoch: 6| Step: 9
Training loss: 2.0732098728272375
Validation loss: 2.5446193043854515

Epoch: 6| Step: 10
Training loss: 2.030069095957769
Validation loss: 2.5081039845580886

Epoch: 6| Step: 11
Training loss: 2.4898835537197286
Validation loss: 2.538483961657654

Epoch: 6| Step: 12
Training loss: 2.6646155177706117
Validation loss: 2.538335122800594

Epoch: 6| Step: 13
Training loss: 2.352886448251742
Validation loss: 2.513587126233177

Epoch: 280| Step: 0
Training loss: 2.7643414983545624
Validation loss: 2.5169927302662103

Epoch: 6| Step: 1
Training loss: 1.8044941455918386
Validation loss: 2.5236630648962355

Epoch: 6| Step: 2
Training loss: 1.7725828691057832
Validation loss: 2.4942743379562033

Epoch: 6| Step: 3
Training loss: 2.0884441502003015
Validation loss: 2.4927076476548224

Epoch: 6| Step: 4
Training loss: 2.8660307585509197
Validation loss: 2.5159166376306095

Epoch: 6| Step: 5
Training loss: 2.325927209038233
Validation loss: 2.5293003470103663

Epoch: 6| Step: 6
Training loss: 2.386419149471465
Validation loss: 2.534686702903259

Epoch: 6| Step: 7
Training loss: 2.0102429356066023
Validation loss: 2.5406747325926666

Epoch: 6| Step: 8
Training loss: 1.9842786990850605
Validation loss: 2.567863155337487

Epoch: 6| Step: 9
Training loss: 1.7689242974661226
Validation loss: 2.601956678433033

Epoch: 6| Step: 10
Training loss: 1.9238965946928963
Validation loss: 2.628388881551931

Epoch: 6| Step: 11
Training loss: 3.251962216109665
Validation loss: 2.5951566443821106

Epoch: 6| Step: 12
Training loss: 1.4601612170580394
Validation loss: 2.600070643993586

Epoch: 6| Step: 13
Training loss: 1.9286544443862488
Validation loss: 2.5757387619980414

Epoch: 281| Step: 0
Training loss: 2.0845220099312205
Validation loss: 2.561051044348159

Epoch: 6| Step: 1
Training loss: 2.1307969403232945
Validation loss: 2.569914967754309

Epoch: 6| Step: 2
Training loss: 2.119330528645411
Validation loss: 2.532236495699159

Epoch: 6| Step: 3
Training loss: 2.3979672645071592
Validation loss: 2.5278950502162942

Epoch: 6| Step: 4
Training loss: 2.544125810835113
Validation loss: 2.5286684726025084

Epoch: 6| Step: 5
Training loss: 1.8530606675198618
Validation loss: 2.5267286303839334

Epoch: 6| Step: 6
Training loss: 2.5460158695226798
Validation loss: 2.5542568112055064

Epoch: 6| Step: 7
Training loss: 1.5916923254584536
Validation loss: 2.511681777420946

Epoch: 6| Step: 8
Training loss: 1.4017617550747032
Validation loss: 2.5070347357282206

Epoch: 6| Step: 9
Training loss: 2.382337178834009
Validation loss: 2.5290116354253698

Epoch: 6| Step: 10
Training loss: 2.6960013131384666
Validation loss: 2.5050410547274176

Epoch: 6| Step: 11
Training loss: 1.4696678378010444
Validation loss: 2.508198376654896

Epoch: 6| Step: 12
Training loss: 2.545183895789263
Validation loss: 2.5179988015393957

Epoch: 6| Step: 13
Training loss: 2.3893241584351905
Validation loss: 2.517226749795328

Epoch: 282| Step: 0
Training loss: 2.245722307092422
Validation loss: 2.5444367483828714

Epoch: 6| Step: 1
Training loss: 2.5519906371013645
Validation loss: 2.5963044284557255

Epoch: 6| Step: 2
Training loss: 1.2448542059134506
Validation loss: 2.5900935555527154

Epoch: 6| Step: 3
Training loss: 2.0766723833367706
Validation loss: 2.5611280319590874

Epoch: 6| Step: 4
Training loss: 2.006354013759245
Validation loss: 2.554273332626468

Epoch: 6| Step: 5
Training loss: 2.628241127523873
Validation loss: 2.545956935681179

Epoch: 6| Step: 6
Training loss: 2.208749827809697
Validation loss: 2.53864002332043

Epoch: 6| Step: 7
Training loss: 2.7307510339207113
Validation loss: 2.562251489886053

Epoch: 6| Step: 8
Training loss: 1.5747163426323543
Validation loss: 2.546880257879965

Epoch: 6| Step: 9
Training loss: 2.054222373387597
Validation loss: 2.557226663191923

Epoch: 6| Step: 10
Training loss: 2.2772405218215477
Validation loss: 2.571605523330889

Epoch: 6| Step: 11
Training loss: 1.9953965016294906
Validation loss: 2.5961127033397013

Epoch: 6| Step: 12
Training loss: 1.7672188915429297
Validation loss: 2.6036053828310926

Epoch: 6| Step: 13
Training loss: 2.3568070944565993
Validation loss: 2.568448288300757

Epoch: 283| Step: 0
Training loss: 1.594630353540206
Validation loss: 2.54964893517463

Epoch: 6| Step: 1
Training loss: 2.569690385566584
Validation loss: 2.517086875857044

Epoch: 6| Step: 2
Training loss: 1.6228184361370375
Validation loss: 2.5140846622897697

Epoch: 6| Step: 3
Training loss: 2.379639561070708
Validation loss: 2.528488850983434

Epoch: 6| Step: 4
Training loss: 2.2955301720412984
Validation loss: 2.56180290106444

Epoch: 6| Step: 5
Training loss: 2.3001009545768025
Validation loss: 2.5390633607520576

Epoch: 6| Step: 6
Training loss: 1.4252688806738913
Validation loss: 2.563604426994634

Epoch: 6| Step: 7
Training loss: 2.3624607143466014
Validation loss: 2.5957709715706736

Epoch: 6| Step: 8
Training loss: 1.7585401597197512
Validation loss: 2.588580376216017

Epoch: 6| Step: 9
Training loss: 2.430161408452198
Validation loss: 2.5620700196309905

Epoch: 6| Step: 10
Training loss: 2.425237278292181
Validation loss: 2.561380079598755

Epoch: 6| Step: 11
Training loss: 2.004199030793948
Validation loss: 2.5709252443582153

Epoch: 6| Step: 12
Training loss: 2.028326424822278
Validation loss: 2.552381581116679

Epoch: 6| Step: 13
Training loss: 2.656649660449318
Validation loss: 2.5608071729087456

Epoch: 284| Step: 0
Training loss: 1.377165562900983
Validation loss: 2.5969130980339985

Epoch: 6| Step: 1
Training loss: 2.3415248226045025
Validation loss: 2.594968050170197

Epoch: 6| Step: 2
Training loss: 2.0374422030062154
Validation loss: 2.590618357172457

Epoch: 6| Step: 3
Training loss: 2.0549409079118957
Validation loss: 2.574804460329265

Epoch: 6| Step: 4
Training loss: 1.615603643456979
Validation loss: 2.554590579186312

Epoch: 6| Step: 5
Training loss: 2.7330877271265774
Validation loss: 2.5441869346401926

Epoch: 6| Step: 6
Training loss: 1.9423822601455663
Validation loss: 2.5429104956045148

Epoch: 6| Step: 7
Training loss: 2.2344031698945392
Validation loss: 2.5392014372543725

Epoch: 6| Step: 8
Training loss: 2.1902130740949666
Validation loss: 2.5414048721899203

Epoch: 6| Step: 9
Training loss: 2.6420195017982135
Validation loss: 2.565781957213786

Epoch: 6| Step: 10
Training loss: 2.406781422775363
Validation loss: 2.544570769816228

Epoch: 6| Step: 11
Training loss: 1.9357132209871428
Validation loss: 2.5734228467649563

Epoch: 6| Step: 12
Training loss: 2.4230215988550468
Validation loss: 2.5642745068865964

Epoch: 6| Step: 13
Training loss: 2.042944709242512
Validation loss: 2.5695309982384735

Epoch: 285| Step: 0
Training loss: 1.58465434062841
Validation loss: 2.599890644267966

Epoch: 6| Step: 1
Training loss: 2.455815583074199
Validation loss: 2.5569658220737317

Epoch: 6| Step: 2
Training loss: 1.9245461610137604
Validation loss: 2.543711845243018

Epoch: 6| Step: 3
Training loss: 1.9666837112313162
Validation loss: 2.551786636440847

Epoch: 6| Step: 4
Training loss: 2.049717683658566
Validation loss: 2.5277427110813084

Epoch: 6| Step: 5
Training loss: 2.0376283710504035
Validation loss: 2.5327470065353888

Epoch: 6| Step: 6
Training loss: 1.9766194934694692
Validation loss: 2.5213530506514266

Epoch: 6| Step: 7
Training loss: 1.8059669352025585
Validation loss: 2.5262983421143574

Epoch: 6| Step: 8
Training loss: 1.9953631054846865
Validation loss: 2.516356509930131

Epoch: 6| Step: 9
Training loss: 2.3918874561153936
Validation loss: 2.5213296469983058

Epoch: 6| Step: 10
Training loss: 2.136101614417418
Validation loss: 2.5393606940030877

Epoch: 6| Step: 11
Training loss: 2.570408410598952
Validation loss: 2.526588197293174

Epoch: 6| Step: 12
Training loss: 3.0818366121010574
Validation loss: 2.530292628205801

Epoch: 6| Step: 13
Training loss: 2.1363531772792834
Validation loss: 2.5593052619745342

Epoch: 286| Step: 0
Training loss: 1.9048983675461355
Validation loss: 2.5952177222957538

Epoch: 6| Step: 1
Training loss: 1.7983837925027901
Validation loss: 2.628443109868189

Epoch: 6| Step: 2
Training loss: 2.4700709804575527
Validation loss: 2.6718379384346322

Epoch: 6| Step: 3
Training loss: 1.8037548875643363
Validation loss: 2.645627627048139

Epoch: 6| Step: 4
Training loss: 1.6944549782569744
Validation loss: 2.596793246981156

Epoch: 6| Step: 5
Training loss: 1.9601483219818063
Validation loss: 2.545260379789204

Epoch: 6| Step: 6
Training loss: 2.3678859775516106
Validation loss: 2.546147482469777

Epoch: 6| Step: 7
Training loss: 2.924590292382148
Validation loss: 2.544444150822866

Epoch: 6| Step: 8
Training loss: 2.5287798850254206
Validation loss: 2.527715625161861

Epoch: 6| Step: 9
Training loss: 2.6091904260834298
Validation loss: 2.5142002217354062

Epoch: 6| Step: 10
Training loss: 1.9608438781031072
Validation loss: 2.5143771502379497

Epoch: 6| Step: 11
Training loss: 1.6397635968716613
Validation loss: 2.5009439752499594

Epoch: 6| Step: 12
Training loss: 2.878498105396882
Validation loss: 2.499198769285515

Epoch: 6| Step: 13
Training loss: 2.010677683065643
Validation loss: 2.5260726507325098

Epoch: 287| Step: 0
Training loss: 1.8840407801059655
Validation loss: 2.5116623654125148

Epoch: 6| Step: 1
Training loss: 1.6460275978008898
Validation loss: 2.528504527131616

Epoch: 6| Step: 2
Training loss: 3.1416569622776973
Validation loss: 2.543128630206702

Epoch: 6| Step: 3
Training loss: 1.7757343089675075
Validation loss: 2.546636870627662

Epoch: 6| Step: 4
Training loss: 2.7136303282522927
Validation loss: 2.5635569493844335

Epoch: 6| Step: 5
Training loss: 2.008125251131253
Validation loss: 2.5585722090030325

Epoch: 6| Step: 6
Training loss: 2.469833522545468
Validation loss: 2.612541903839617

Epoch: 6| Step: 7
Training loss: 2.434927536593127
Validation loss: 2.595752617043885

Epoch: 6| Step: 8
Training loss: 1.9851247017075138
Validation loss: 2.5958551190616808

Epoch: 6| Step: 9
Training loss: 1.9085060902099338
Validation loss: 2.5637498304248285

Epoch: 6| Step: 10
Training loss: 1.5796845538888205
Validation loss: 2.556364545299905

Epoch: 6| Step: 11
Training loss: 2.099091051573955
Validation loss: 2.58879814693831

Epoch: 6| Step: 12
Training loss: 1.8437189649135877
Validation loss: 2.5455454689100594

Epoch: 6| Step: 13
Training loss: 2.354122251468606
Validation loss: 2.5366607261501266

Epoch: 288| Step: 0
Training loss: 1.8788489572906424
Validation loss: 2.5247088714562604

Epoch: 6| Step: 1
Training loss: 2.0258703739614554
Validation loss: 2.536631683337296

Epoch: 6| Step: 2
Training loss: 1.405435029283195
Validation loss: 2.5530960616763916

Epoch: 6| Step: 3
Training loss: 2.292566111369528
Validation loss: 2.543148903586355

Epoch: 6| Step: 4
Training loss: 2.241639605315089
Validation loss: 2.5668087531885884

Epoch: 6| Step: 5
Training loss: 1.7442646046623433
Validation loss: 2.5892466474821196

Epoch: 6| Step: 6
Training loss: 1.955184887877748
Validation loss: 2.587104495623403

Epoch: 6| Step: 7
Training loss: 1.8870800612203618
Validation loss: 2.6044917145366164

Epoch: 6| Step: 8
Training loss: 1.7602335215749285
Validation loss: 2.606083375649519

Epoch: 6| Step: 9
Training loss: 2.1728612183774216
Validation loss: 2.604782235189184

Epoch: 6| Step: 10
Training loss: 2.982194193584977
Validation loss: 2.57715497504539

Epoch: 6| Step: 11
Training loss: 2.55142750520185
Validation loss: 2.590491549954907

Epoch: 6| Step: 12
Training loss: 2.783461645065946
Validation loss: 2.5372775019421456

Epoch: 6| Step: 13
Training loss: 2.010476330545474
Validation loss: 2.5537768032704506

Epoch: 289| Step: 0
Training loss: 2.527512133500343
Validation loss: 2.544669383969587

Epoch: 6| Step: 1
Training loss: 2.0295051710124463
Validation loss: 2.58996468209399

Epoch: 6| Step: 2
Training loss: 1.9663217495330634
Validation loss: 2.6271381147593673

Epoch: 6| Step: 3
Training loss: 1.9076593535969268
Validation loss: 2.572864954090261

Epoch: 6| Step: 4
Training loss: 2.438579320365669
Validation loss: 2.579701999043616

Epoch: 6| Step: 5
Training loss: 1.876685973972088
Validation loss: 2.5676964894318837

Epoch: 6| Step: 6
Training loss: 1.8568812725791928
Validation loss: 2.5561868543217168

Epoch: 6| Step: 7
Training loss: 2.1055534501458038
Validation loss: 2.5566981935443067

Epoch: 6| Step: 8
Training loss: 2.1960543536354225
Validation loss: 2.5525926561815395

Epoch: 6| Step: 9
Training loss: 2.301280979360316
Validation loss: 2.5348309434076066

Epoch: 6| Step: 10
Training loss: 2.197721306915664
Validation loss: 2.539775447030687

Epoch: 6| Step: 11
Training loss: 1.4699671146062014
Validation loss: 2.5742947032260544

Epoch: 6| Step: 12
Training loss: 2.7326765616595226
Validation loss: 2.526811436562812

Epoch: 6| Step: 13
Training loss: 2.137003933636513
Validation loss: 2.5213035481228627

Epoch: 290| Step: 0
Training loss: 2.3579212282465507
Validation loss: 2.5184617091323838

Epoch: 6| Step: 1
Training loss: 2.341551296156926
Validation loss: 2.5191749182778493

Epoch: 6| Step: 2
Training loss: 2.0765176164011625
Validation loss: 2.5190878465616597

Epoch: 6| Step: 3
Training loss: 1.8391986858079488
Validation loss: 2.5238235225614862

Epoch: 6| Step: 4
Training loss: 1.9080175741014112
Validation loss: 2.5459923726262517

Epoch: 6| Step: 5
Training loss: 1.6196005689081543
Validation loss: 2.5601160233501368

Epoch: 6| Step: 6
Training loss: 1.5786804128308278
Validation loss: 2.586331248198679

Epoch: 6| Step: 7
Training loss: 2.4756271569546704
Validation loss: 2.6346686184884898

Epoch: 6| Step: 8
Training loss: 2.3463673536555993
Validation loss: 2.648995444792492

Epoch: 6| Step: 9
Training loss: 2.5173053697282914
Validation loss: 2.685469030003396

Epoch: 6| Step: 10
Training loss: 1.634650040600056
Validation loss: 2.653578098819023

Epoch: 6| Step: 11
Training loss: 2.786138118039551
Validation loss: 2.6964509706520214

Epoch: 6| Step: 12
Training loss: 2.2103005290344346
Validation loss: 2.7928666885330387

Epoch: 6| Step: 13
Training loss: 2.045782365442466
Validation loss: 2.7429845653205844

Epoch: 291| Step: 0
Training loss: 1.9057406385948212
Validation loss: 2.7536565428447943

Epoch: 6| Step: 1
Training loss: 2.3178829741670723
Validation loss: 2.6993719076822087

Epoch: 6| Step: 2
Training loss: 2.0035233457122392
Validation loss: 2.61367466449945

Epoch: 6| Step: 3
Training loss: 2.144411844566862
Validation loss: 2.581673786390751

Epoch: 6| Step: 4
Training loss: 1.586542399385985
Validation loss: 2.5183624474260315

Epoch: 6| Step: 5
Training loss: 1.9657839882115014
Validation loss: 2.52152422955468

Epoch: 6| Step: 6
Training loss: 2.6365010037404897
Validation loss: 2.5137623274425174

Epoch: 6| Step: 7
Training loss: 2.5699039586746277
Validation loss: 2.5165058591973906

Epoch: 6| Step: 8
Training loss: 3.4834103467784225
Validation loss: 2.513051835628203

Epoch: 6| Step: 9
Training loss: 1.7473043388446003
Validation loss: 2.5161998005215147

Epoch: 6| Step: 10
Training loss: 1.5703780886489067
Validation loss: 2.5264709946782853

Epoch: 6| Step: 11
Training loss: 2.442060263962523
Validation loss: 2.5440115248251125

Epoch: 6| Step: 12
Training loss: 1.9181409707993968
Validation loss: 2.53535096253953

Epoch: 6| Step: 13
Training loss: 2.622081769353462
Validation loss: 2.622881155301361

Epoch: 292| Step: 0
Training loss: 2.0251919125640523
Validation loss: 2.6684023652289777

Epoch: 6| Step: 1
Training loss: 2.134563802966959
Validation loss: 2.6659491040474306

Epoch: 6| Step: 2
Training loss: 2.204724319766958
Validation loss: 2.609528679805052

Epoch: 6| Step: 3
Training loss: 2.077853421700273
Validation loss: 2.537655915166595

Epoch: 6| Step: 4
Training loss: 2.23051984364367
Validation loss: 2.5074804052472826

Epoch: 6| Step: 5
Training loss: 1.839640741831333
Validation loss: 2.4952764391856297

Epoch: 6| Step: 6
Training loss: 1.861088516167782
Validation loss: 2.498654734742137

Epoch: 6| Step: 7
Training loss: 1.7881651381114738
Validation loss: 2.494023196075563

Epoch: 6| Step: 8
Training loss: 3.7947238432632826
Validation loss: 2.493003177594382

Epoch: 6| Step: 9
Training loss: 2.4807639119108864
Validation loss: 2.4804055513756302

Epoch: 6| Step: 10
Training loss: 2.4997100661954903
Validation loss: 2.483766893221561

Epoch: 6| Step: 11
Training loss: 2.3741506764480556
Validation loss: 2.4920385748713136

Epoch: 6| Step: 12
Training loss: 2.4032113842264042
Validation loss: 2.5409430166783653

Epoch: 6| Step: 13
Training loss: 2.3145855958265433
Validation loss: 2.5677290187618924

Epoch: 293| Step: 0
Training loss: 1.8349094840444393
Validation loss: 2.6232916101662407

Epoch: 6| Step: 1
Training loss: 2.6518956116201897
Validation loss: 2.634625377650357

Epoch: 6| Step: 2
Training loss: 2.475329070900842
Validation loss: 2.604641868467728

Epoch: 6| Step: 3
Training loss: 2.2251857851451113
Validation loss: 2.6158928852851293

Epoch: 6| Step: 4
Training loss: 2.2009364952551995
Validation loss: 2.6698847267898485

Epoch: 6| Step: 5
Training loss: 2.6757548755543237
Validation loss: 2.598829695602073

Epoch: 6| Step: 6
Training loss: 1.6236449240383406
Validation loss: 2.589842852424017

Epoch: 6| Step: 7
Training loss: 2.260579878251554
Validation loss: 2.538382555567226

Epoch: 6| Step: 8
Training loss: 2.372123984636201
Validation loss: 2.513055092902537

Epoch: 6| Step: 9
Training loss: 2.0361126722625027
Validation loss: 2.497335937757639

Epoch: 6| Step: 10
Training loss: 2.526236195628009
Validation loss: 2.4933506115996398

Epoch: 6| Step: 11
Training loss: 2.3013138211345114
Validation loss: 2.4727233266947706

Epoch: 6| Step: 12
Training loss: 1.7980918412901927
Validation loss: 2.481037144855561

Epoch: 6| Step: 13
Training loss: 2.1480053276265885
Validation loss: 2.497305212408717

Epoch: 294| Step: 0
Training loss: 1.9337148917425746
Validation loss: 2.4669244511250428

Epoch: 6| Step: 1
Training loss: 1.649880884668269
Validation loss: 2.4812826988826555

Epoch: 6| Step: 2
Training loss: 2.5146384822315078
Validation loss: 2.4623261101479366

Epoch: 6| Step: 3
Training loss: 1.6724967157077901
Validation loss: 2.463352846701544

Epoch: 6| Step: 4
Training loss: 1.9209998394451242
Validation loss: 2.4721800077837006

Epoch: 6| Step: 5
Training loss: 2.5922293744145475
Validation loss: 2.5006023952788032

Epoch: 6| Step: 6
Training loss: 2.3793240385457404
Validation loss: 2.553599850321449

Epoch: 6| Step: 7
Training loss: 2.5764117472669383
Validation loss: 2.5656486488457326

Epoch: 6| Step: 8
Training loss: 2.0787189753379787
Validation loss: 2.592105328723534

Epoch: 6| Step: 9
Training loss: 2.5908289627753254
Validation loss: 2.582424055067889

Epoch: 6| Step: 10
Training loss: 2.7803579035564643
Validation loss: 2.5363460309639976

Epoch: 6| Step: 11
Training loss: 2.1198974383035094
Validation loss: 2.490176299172161

Epoch: 6| Step: 12
Training loss: 2.034702477415394
Validation loss: 2.4793943305961244

Epoch: 6| Step: 13
Training loss: 2.4465707095226854
Validation loss: 2.4924673403657094

Epoch: 295| Step: 0
Training loss: 2.0085348173299753
Validation loss: 2.5017876670855452

Epoch: 6| Step: 1
Training loss: 1.7464035407949177
Validation loss: 2.4881225726976512

Epoch: 6| Step: 2
Training loss: 2.5902793368373764
Validation loss: 2.480636775215582

Epoch: 6| Step: 3
Training loss: 2.86797835333621
Validation loss: 2.4821010875552543

Epoch: 6| Step: 4
Training loss: 2.071936664843146
Validation loss: 2.4756407521616763

Epoch: 6| Step: 5
Training loss: 2.705262325914838
Validation loss: 2.5154850606912604

Epoch: 6| Step: 6
Training loss: 1.4191614604652112
Validation loss: 2.5243457777575506

Epoch: 6| Step: 7
Training loss: 1.802137149896576
Validation loss: 2.528101434586023

Epoch: 6| Step: 8
Training loss: 2.282503384674337
Validation loss: 2.5629590561466826

Epoch: 6| Step: 9
Training loss: 2.4883635550739887
Validation loss: 2.590261541684435

Epoch: 6| Step: 10
Training loss: 2.324552008834942
Validation loss: 2.646721928481593

Epoch: 6| Step: 11
Training loss: 2.206151412187594
Validation loss: 2.7463395292250254

Epoch: 6| Step: 12
Training loss: 2.841204499578102
Validation loss: 2.740680900186324

Epoch: 6| Step: 13
Training loss: 2.3088225946749654
Validation loss: 2.6385061427055674

Epoch: 296| Step: 0
Training loss: 1.6590992872708321
Validation loss: 2.5893770605802335

Epoch: 6| Step: 1
Training loss: 1.8685805738316126
Validation loss: 2.568347291712506

Epoch: 6| Step: 2
Training loss: 1.8700704623528037
Validation loss: 2.5385912257321457

Epoch: 6| Step: 3
Training loss: 2.7001810083820943
Validation loss: 2.5339807293848384

Epoch: 6| Step: 4
Training loss: 2.495013700306188
Validation loss: 2.5277943668822545

Epoch: 6| Step: 5
Training loss: 2.3431631752337445
Validation loss: 2.507684135915011

Epoch: 6| Step: 6
Training loss: 1.6767881698393097
Validation loss: 2.5159041524292847

Epoch: 6| Step: 7
Training loss: 1.495614953778485
Validation loss: 2.487645976896742

Epoch: 6| Step: 8
Training loss: 2.4842072436237
Validation loss: 2.5084279415331383

Epoch: 6| Step: 9
Training loss: 2.0258715508309773
Validation loss: 2.521343917736543

Epoch: 6| Step: 10
Training loss: 2.6322473660902506
Validation loss: 2.5557232389400117

Epoch: 6| Step: 11
Training loss: 2.2625388337064054
Validation loss: 2.5758023829736256

Epoch: 6| Step: 12
Training loss: 2.6594588700190953
Validation loss: 2.6328402252699497

Epoch: 6| Step: 13
Training loss: 2.1417945952249404
Validation loss: 2.6293718172330207

Epoch: 297| Step: 0
Training loss: 2.7341111410080385
Validation loss: 2.6005016680443616

Epoch: 6| Step: 1
Training loss: 1.949483176969629
Validation loss: 2.609374010158206

Epoch: 6| Step: 2
Training loss: 2.817049542951172
Validation loss: 2.598786561802633

Epoch: 6| Step: 3
Training loss: 1.4144555488740538
Validation loss: 2.5927567782588232

Epoch: 6| Step: 4
Training loss: 2.4335208594120084
Validation loss: 2.5767443572501016

Epoch: 6| Step: 5
Training loss: 1.6922623579915574
Validation loss: 2.5376729596202487

Epoch: 6| Step: 6
Training loss: 2.9442761770987533
Validation loss: 2.523640422712636

Epoch: 6| Step: 7
Training loss: 1.7773712491433786
Validation loss: 2.4957218758772335

Epoch: 6| Step: 8
Training loss: 2.0100707183088207
Validation loss: 2.4701509645276674

Epoch: 6| Step: 9
Training loss: 2.5352605436764306
Validation loss: 2.476660821770009

Epoch: 6| Step: 10
Training loss: 1.9616260307638438
Validation loss: 2.4964267387217087

Epoch: 6| Step: 11
Training loss: 2.0622965394437247
Validation loss: 2.5156626728151346

Epoch: 6| Step: 12
Training loss: 1.9788661996408279
Validation loss: 2.498933644164164

Epoch: 6| Step: 13
Training loss: 1.9352608324050062
Validation loss: 2.5675678227624816

Epoch: 298| Step: 0
Training loss: 2.243587150083168
Validation loss: 2.602617036702263

Epoch: 6| Step: 1
Training loss: 1.8603038871843869
Validation loss: 2.66508297285895

Epoch: 6| Step: 2
Training loss: 2.232429778050862
Validation loss: 2.6701420746910913

Epoch: 6| Step: 3
Training loss: 2.1663953415616324
Validation loss: 2.753900175335905

Epoch: 6| Step: 4
Training loss: 1.917210508673281
Validation loss: 2.727738353688653

Epoch: 6| Step: 5
Training loss: 2.1309035704843335
Validation loss: 2.648313326254914

Epoch: 6| Step: 6
Training loss: 2.207052747233524
Validation loss: 2.712444637688749

Epoch: 6| Step: 7
Training loss: 3.0773072681458067
Validation loss: 2.638383730561452

Epoch: 6| Step: 8
Training loss: 2.2603378164950776
Validation loss: 2.6141306015297805

Epoch: 6| Step: 9
Training loss: 2.0037199234921323
Validation loss: 2.603162050384226

Epoch: 6| Step: 10
Training loss: 2.1303726045899123
Validation loss: 2.5389592389358966

Epoch: 6| Step: 11
Training loss: 1.8367121583989878
Validation loss: 2.493095129036054

Epoch: 6| Step: 12
Training loss: 1.7054996559323892
Validation loss: 2.492494506421758

Epoch: 6| Step: 13
Training loss: 1.991931554771256
Validation loss: 2.5157577527008343

Epoch: 299| Step: 0
Training loss: 2.730675510769668
Validation loss: 2.4821301680799546

Epoch: 6| Step: 1
Training loss: 2.5355009952543965
Validation loss: 2.510975159586398

Epoch: 6| Step: 2
Training loss: 1.6071713369358944
Validation loss: 2.537686073671799

Epoch: 6| Step: 3
Training loss: 2.3191416448224977
Validation loss: 2.555115822321167

Epoch: 6| Step: 4
Training loss: 2.4428911499932475
Validation loss: 2.6260887945763973

Epoch: 6| Step: 5
Training loss: 2.3786110780996026
Validation loss: 2.764284056673225

Epoch: 6| Step: 6
Training loss: 2.3856708330124525
Validation loss: 2.7816337577864694

Epoch: 6| Step: 7
Training loss: 3.0783598369730383
Validation loss: 2.7261683006935504

Epoch: 6| Step: 8
Training loss: 1.5284973626979728
Validation loss: 2.675857980932029

Epoch: 6| Step: 9
Training loss: 1.4376136900683536
Validation loss: 2.574621490324995

Epoch: 6| Step: 10
Training loss: 2.2096641297386492
Validation loss: 2.5007896606723365

Epoch: 6| Step: 11
Training loss: 2.2088701807215294
Validation loss: 2.471941273568841

Epoch: 6| Step: 12
Training loss: 2.178911843605562
Validation loss: 2.474997474206734

Epoch: 6| Step: 13
Training loss: 1.7982032842106104
Validation loss: 2.486356636676992

Epoch: 300| Step: 0
Training loss: 2.5867635554261446
Validation loss: 2.4771683089361995

Epoch: 6| Step: 1
Training loss: 2.4203190881628376
Validation loss: 2.4772081626536266

Epoch: 6| Step: 2
Training loss: 2.235562949061992
Validation loss: 2.478934995795353

Epoch: 6| Step: 3
Training loss: 2.2250809944069774
Validation loss: 2.4831944345719528

Epoch: 6| Step: 4
Training loss: 1.2518104317173915
Validation loss: 2.491606713427436

Epoch: 6| Step: 5
Training loss: 1.718497379117848
Validation loss: 2.532158708135259

Epoch: 6| Step: 6
Training loss: 2.1548398700530087
Validation loss: 2.538611895362399

Epoch: 6| Step: 7
Training loss: 1.960007101065559
Validation loss: 2.5913449746033894

Epoch: 6| Step: 8
Training loss: 2.8298900849796986
Validation loss: 2.59900307983122

Epoch: 6| Step: 9
Training loss: 2.486363796508642
Validation loss: 2.5981683900250605

Epoch: 6| Step: 10
Training loss: 2.226670968609307
Validation loss: 2.563032831449332

Epoch: 6| Step: 11
Training loss: 2.419697330084895
Validation loss: 2.5577725167509904

Epoch: 6| Step: 12
Training loss: 1.808128873924433
Validation loss: 2.5317916447586453

Epoch: 6| Step: 13
Training loss: 1.9147376290606681
Validation loss: 2.507123763439054

Epoch: 301| Step: 0
Training loss: 2.536441142332711
Validation loss: 2.498503427786744

Epoch: 6| Step: 1
Training loss: 2.6327519169297764
Validation loss: 2.516286995861034

Epoch: 6| Step: 2
Training loss: 1.7554851128868576
Validation loss: 2.5150836022387413

Epoch: 6| Step: 3
Training loss: 2.046043518312087
Validation loss: 2.4957398197017775

Epoch: 6| Step: 4
Training loss: 1.7724325550843953
Validation loss: 2.516123878184757

Epoch: 6| Step: 5
Training loss: 2.2038181377918753
Validation loss: 2.510908724943006

Epoch: 6| Step: 6
Training loss: 1.7721437280718333
Validation loss: 2.5134644480823445

Epoch: 6| Step: 7
Training loss: 2.4741682639480356
Validation loss: 2.523209237717889

Epoch: 6| Step: 8
Training loss: 2.2636538645543762
Validation loss: 2.5176100707906595

Epoch: 6| Step: 9
Training loss: 2.070514021368391
Validation loss: 2.572287947302733

Epoch: 6| Step: 10
Training loss: 1.5315830880497394
Validation loss: 2.5724136900811407

Epoch: 6| Step: 11
Training loss: 2.2921421829247777
Validation loss: 2.615734019375558

Epoch: 6| Step: 12
Training loss: 2.632902058965679
Validation loss: 2.5926649895908893

Epoch: 6| Step: 13
Training loss: 1.8552833223546412
Validation loss: 2.5986860026836887

Epoch: 302| Step: 0
Training loss: 2.1040431700871958
Validation loss: 2.5522639671290017

Epoch: 6| Step: 1
Training loss: 2.2578834601738333
Validation loss: 2.5975614984579436

Epoch: 6| Step: 2
Training loss: 1.6887426392841658
Validation loss: 2.587859493044367

Epoch: 6| Step: 3
Training loss: 1.8755881340779077
Validation loss: 2.602045726478913

Epoch: 6| Step: 4
Training loss: 2.073302445544471
Validation loss: 2.551928415591955

Epoch: 6| Step: 5
Training loss: 2.8911096115101897
Validation loss: 2.60052423694056

Epoch: 6| Step: 6
Training loss: 1.5745890065992996
Validation loss: 2.603808787868481

Epoch: 6| Step: 7
Training loss: 2.118131420117889
Validation loss: 2.6311072950408874

Epoch: 6| Step: 8
Training loss: 2.5994666652930416
Validation loss: 2.6357077989364277

Epoch: 6| Step: 9
Training loss: 1.9266202078016994
Validation loss: 2.6081230220974576

Epoch: 6| Step: 10
Training loss: 1.476847868293608
Validation loss: 2.610401659712058

Epoch: 6| Step: 11
Training loss: 1.8586758493231292
Validation loss: 2.570802280562043

Epoch: 6| Step: 12
Training loss: 2.4343264534532794
Validation loss: 2.5516035186840593

Epoch: 6| Step: 13
Training loss: 2.2025665224661597
Validation loss: 2.5418258731779173

Epoch: 303| Step: 0
Training loss: 2.496379137514527
Validation loss: 2.540248668117554

Epoch: 6| Step: 1
Training loss: 2.402972280265447
Validation loss: 2.5383989768036517

Epoch: 6| Step: 2
Training loss: 1.9573489481401
Validation loss: 2.5325490969498916

Epoch: 6| Step: 3
Training loss: 2.790301392386056
Validation loss: 2.5412680881430054

Epoch: 6| Step: 4
Training loss: 2.4965899098221813
Validation loss: 2.5552381724997115

Epoch: 6| Step: 5
Training loss: 1.888893848144653
Validation loss: 2.5364569964917765

Epoch: 6| Step: 6
Training loss: 1.6465989114873358
Validation loss: 2.526538246870362

Epoch: 6| Step: 7
Training loss: 2.191688125079836
Validation loss: 2.563887181895101

Epoch: 6| Step: 8
Training loss: 1.996809082853616
Validation loss: 2.5539359290824817

Epoch: 6| Step: 9
Training loss: 1.9358715474099228
Validation loss: 2.5429108081316563

Epoch: 6| Step: 10
Training loss: 2.1753628395239133
Validation loss: 2.562554040974757

Epoch: 6| Step: 11
Training loss: 1.9882389806065306
Validation loss: 2.5664942245849454

Epoch: 6| Step: 12
Training loss: 1.8199854217196951
Validation loss: 2.578926770932643

Epoch: 6| Step: 13
Training loss: 2.4600867360028644
Validation loss: 2.5765914209029317

Epoch: 304| Step: 0
Training loss: 2.535839864434306
Validation loss: 2.5951048900988236

Epoch: 6| Step: 1
Training loss: 1.9614824852357144
Validation loss: 2.6467759613400195

Epoch: 6| Step: 2
Training loss: 2.2141275744946802
Validation loss: 2.661362444101422

Epoch: 6| Step: 3
Training loss: 2.3538620563236488
Validation loss: 2.7055192167734314

Epoch: 6| Step: 4
Training loss: 2.410735470310357
Validation loss: 2.695698291240066

Epoch: 6| Step: 5
Training loss: 1.9807210005428773
Validation loss: 2.682105290625903

Epoch: 6| Step: 6
Training loss: 2.1812380946143244
Validation loss: 2.6542965157054574

Epoch: 6| Step: 7
Training loss: 2.452937416631266
Validation loss: 2.622222157207136

Epoch: 6| Step: 8
Training loss: 2.0128850722500067
Validation loss: 2.5930477555174734

Epoch: 6| Step: 9
Training loss: 2.040036725106368
Validation loss: 2.562631588170141

Epoch: 6| Step: 10
Training loss: 2.476440234129492
Validation loss: 2.565143896011464

Epoch: 6| Step: 11
Training loss: 1.399941386971348
Validation loss: 2.538521530036021

Epoch: 6| Step: 12
Training loss: 1.8937040115664463
Validation loss: 2.543665839700219

Epoch: 6| Step: 13
Training loss: 2.3714677745053967
Validation loss: 2.5369593512561943

Epoch: 305| Step: 0
Training loss: 1.7239376500973984
Validation loss: 2.5507941564571266

Epoch: 6| Step: 1
Training loss: 3.049491033142787
Validation loss: 2.542218466306163

Epoch: 6| Step: 2
Training loss: 2.5557557651858125
Validation loss: 2.543560422164286

Epoch: 6| Step: 3
Training loss: 1.9987391431369275
Validation loss: 2.561208034870982

Epoch: 6| Step: 4
Training loss: 2.4795756496882397
Validation loss: 2.5937248136837208

Epoch: 6| Step: 5
Training loss: 2.22055399451849
Validation loss: 2.598737280445858

Epoch: 6| Step: 6
Training loss: 1.7870232566553996
Validation loss: 2.6362955389525604

Epoch: 6| Step: 7
Training loss: 1.6417783044077463
Validation loss: 2.671043697965658

Epoch: 6| Step: 8
Training loss: 2.128649438889669
Validation loss: 2.6820192859211316

Epoch: 6| Step: 9
Training loss: 1.9891282471535785
Validation loss: 2.699030352953811

Epoch: 6| Step: 10
Training loss: 2.933719556119835
Validation loss: 2.6933115806700476

Epoch: 6| Step: 11
Training loss: 1.3357775854581855
Validation loss: 2.690455105771678

Epoch: 6| Step: 12
Training loss: 2.1498066926151274
Validation loss: 2.63921277808027

Epoch: 6| Step: 13
Training loss: 1.3326176669787904
Validation loss: 2.584255466672022

Epoch: 306| Step: 0
Training loss: 1.3884485336095405
Validation loss: 2.542857959246109

Epoch: 6| Step: 1
Training loss: 2.2989911562038925
Validation loss: 2.5549881240085974

Epoch: 6| Step: 2
Training loss: 2.3634716114899903
Validation loss: 2.5617658602442996

Epoch: 6| Step: 3
Training loss: 2.5972312636963197
Validation loss: 2.5230528909418872

Epoch: 6| Step: 4
Training loss: 2.128275422593153
Validation loss: 2.5106096998107317

Epoch: 6| Step: 5
Training loss: 1.6058135393338513
Validation loss: 2.49574683320239

Epoch: 6| Step: 6
Training loss: 2.523726408396131
Validation loss: 2.49894855959021

Epoch: 6| Step: 7
Training loss: 2.2596955680043704
Validation loss: 2.4848257651545027

Epoch: 6| Step: 8
Training loss: 1.9318499475815152
Validation loss: 2.522824200091509

Epoch: 6| Step: 9
Training loss: 2.5130196105216154
Validation loss: 2.5208979485377494

Epoch: 6| Step: 10
Training loss: 2.092882232757412
Validation loss: 2.5460472868208686

Epoch: 6| Step: 11
Training loss: 1.9491843791981578
Validation loss: 2.539615050616669

Epoch: 6| Step: 12
Training loss: 2.2379433475036277
Validation loss: 2.5649398725277397

Epoch: 6| Step: 13
Training loss: 2.618667958142078
Validation loss: 2.5772959907965607

Epoch: 307| Step: 0
Training loss: 2.167176797918781
Validation loss: 2.5452905418615033

Epoch: 6| Step: 1
Training loss: 2.201026295651733
Validation loss: 2.5617895924897027

Epoch: 6| Step: 2
Training loss: 2.015781366951323
Validation loss: 2.5607227737373233

Epoch: 6| Step: 3
Training loss: 2.1647922648788605
Validation loss: 2.5551412725739593

Epoch: 6| Step: 4
Training loss: 2.262592048247857
Validation loss: 2.54833872884558

Epoch: 6| Step: 5
Training loss: 1.4765105061736976
Validation loss: 2.54570645943853

Epoch: 6| Step: 6
Training loss: 1.95744651302376
Validation loss: 2.5456658830114103

Epoch: 6| Step: 7
Training loss: 2.1168097690457772
Validation loss: 2.5195958013422146

Epoch: 6| Step: 8
Training loss: 2.8680638109713863
Validation loss: 2.546373353010524

Epoch: 6| Step: 9
Training loss: 1.7746745764921268
Validation loss: 2.5415422117270206

Epoch: 6| Step: 10
Training loss: 2.2018427803742218
Validation loss: 2.550124827302903

Epoch: 6| Step: 11
Training loss: 1.7809008875261436
Validation loss: 2.5767761246781262

Epoch: 6| Step: 12
Training loss: 1.626995255564763
Validation loss: 2.5877935657653843

Epoch: 6| Step: 13
Training loss: 2.4876673733170422
Validation loss: 2.626001106583497

Epoch: 308| Step: 0
Training loss: 2.7763213302469474
Validation loss: 2.626828102058039

Epoch: 6| Step: 1
Training loss: 1.4607671138525422
Validation loss: 2.625605119864365

Epoch: 6| Step: 2
Training loss: 2.0019889716683967
Validation loss: 2.6205251487258376

Epoch: 6| Step: 3
Training loss: 2.0394849083920277
Validation loss: 2.684381242655259

Epoch: 6| Step: 4
Training loss: 2.2297835759058855
Validation loss: 2.648649006577859

Epoch: 6| Step: 5
Training loss: 1.7921519694177828
Validation loss: 2.627867646077423

Epoch: 6| Step: 6
Training loss: 2.026006886266244
Validation loss: 2.6197777375494953

Epoch: 6| Step: 7
Training loss: 1.834561030818138
Validation loss: 2.608184619072535

Epoch: 6| Step: 8
Training loss: 2.5368808235201237
Validation loss: 2.5764136288926824

Epoch: 6| Step: 9
Training loss: 2.4642097153406404
Validation loss: 2.5548976924491993

Epoch: 6| Step: 10
Training loss: 1.743583564608904
Validation loss: 2.527703520507389

Epoch: 6| Step: 11
Training loss: 2.3002871126842512
Validation loss: 2.5460545129006853

Epoch: 6| Step: 12
Training loss: 2.244937499605775
Validation loss: 2.5478312875494877

Epoch: 6| Step: 13
Training loss: 1.827231033717366
Validation loss: 2.5517754401459323

Epoch: 309| Step: 0
Training loss: 1.624608286081964
Validation loss: 2.5259580041198766

Epoch: 6| Step: 1
Training loss: 1.6142340333529133
Validation loss: 2.5374124339612107

Epoch: 6| Step: 2
Training loss: 1.8676775684223474
Validation loss: 2.5750802141800295

Epoch: 6| Step: 3
Training loss: 2.122789355033491
Validation loss: 2.5871561488441306

Epoch: 6| Step: 4
Training loss: 2.3395883869808394
Validation loss: 2.6062311203819375

Epoch: 6| Step: 5
Training loss: 2.033602364778682
Validation loss: 2.5696818187684376

Epoch: 6| Step: 6
Training loss: 1.9372615052148747
Validation loss: 2.5816227776885046

Epoch: 6| Step: 7
Training loss: 2.1141130146721467
Validation loss: 2.5744354203170796

Epoch: 6| Step: 8
Training loss: 2.3923352674894827
Validation loss: 2.5332173837511918

Epoch: 6| Step: 9
Training loss: 2.738384511527041
Validation loss: 2.5857825256807985

Epoch: 6| Step: 10
Training loss: 2.446274248333388
Validation loss: 2.5633192381039307

Epoch: 6| Step: 11
Training loss: 2.0989121525861156
Validation loss: 2.603873111709702

Epoch: 6| Step: 12
Training loss: 2.5933245574227373
Validation loss: 2.613366354187125

Epoch: 6| Step: 13
Training loss: 1.6051120779531682
Validation loss: 2.5786647809546728

Epoch: 310| Step: 0
Training loss: 2.3343998878306413
Validation loss: 2.626531608259183

Epoch: 6| Step: 1
Training loss: 1.6005859375
Validation loss: 2.628311626568041

Epoch: 6| Step: 2
Training loss: 2.222311465802577
Validation loss: 2.6240434190362953

Epoch: 6| Step: 3
Training loss: 1.9315260804005672
Validation loss: 2.6143997148170457

Epoch: 6| Step: 4
Training loss: 2.390702988094237
Validation loss: 2.6019812811046967

Epoch: 6| Step: 5
Training loss: 2.7216660218978777
Validation loss: 2.6072723079079054

Epoch: 6| Step: 6
Training loss: 2.4409980127435116
Validation loss: 2.615218831273239

Epoch: 6| Step: 7
Training loss: 1.8759239463437265
Validation loss: 2.5884536226728323

Epoch: 6| Step: 8
Training loss: 1.818277818139458
Validation loss: 2.5949382281684175

Epoch: 6| Step: 9
Training loss: 1.4853299733134766
Validation loss: 2.602718550818935

Epoch: 6| Step: 10
Training loss: 1.7431368443690878
Validation loss: 2.6299311098351876

Epoch: 6| Step: 11
Training loss: 2.0611497331595445
Validation loss: 2.57268885068513

Epoch: 6| Step: 12
Training loss: 2.23523764863744
Validation loss: 2.6066674749644685

Epoch: 6| Step: 13
Training loss: 1.8547544369272364
Validation loss: 2.614811288286212

Epoch: 311| Step: 0
Training loss: 1.9032306209626368
Validation loss: 2.625224936399765

Epoch: 6| Step: 1
Training loss: 2.210588083862227
Validation loss: 2.5711288624393127

Epoch: 6| Step: 2
Training loss: 1.453372729114554
Validation loss: 2.595781763788136

Epoch: 6| Step: 3
Training loss: 2.07158716656381
Validation loss: 2.594627396661858

Epoch: 6| Step: 4
Training loss: 1.6021437171830226
Validation loss: 2.6279959460613815

Epoch: 6| Step: 5
Training loss: 2.1679665505337944
Validation loss: 2.6090098142633042

Epoch: 6| Step: 6
Training loss: 2.5442767785795803
Validation loss: 2.662723551575046

Epoch: 6| Step: 7
Training loss: 2.13126079299297
Validation loss: 2.6668645864789533

Epoch: 6| Step: 8
Training loss: 1.701717670185691
Validation loss: 2.5977595946900474

Epoch: 6| Step: 9
Training loss: 2.1918775082354394
Validation loss: 2.5539909992099243

Epoch: 6| Step: 10
Training loss: 1.9507949969166718
Validation loss: 2.5772097263369935

Epoch: 6| Step: 11
Training loss: 1.71749936466122
Validation loss: 2.5133545543607863

Epoch: 6| Step: 12
Training loss: 2.908165085379157
Validation loss: 2.5348002179366493

Epoch: 6| Step: 13
Training loss: 2.4451534719217975
Validation loss: 2.530640061599732

Epoch: 312| Step: 0
Training loss: 2.366241769751147
Validation loss: 2.527460236102951

Epoch: 6| Step: 1
Training loss: 2.5574682191606217
Validation loss: 2.523054174513159

Epoch: 6| Step: 2
Training loss: 1.4564279734032253
Validation loss: 2.558233803626147

Epoch: 6| Step: 3
Training loss: 1.8410136720811703
Validation loss: 2.546222111619933

Epoch: 6| Step: 4
Training loss: 1.3688508297086797
Validation loss: 2.569533209656443

Epoch: 6| Step: 5
Training loss: 1.3105574719701272
Validation loss: 2.5692889137851127

Epoch: 6| Step: 6
Training loss: 1.9222578582265684
Validation loss: 2.579460183627196

Epoch: 6| Step: 7
Training loss: 2.347555098044451
Validation loss: 2.580457399123694

Epoch: 6| Step: 8
Training loss: 2.493274798326631
Validation loss: 2.601695487868567

Epoch: 6| Step: 9
Training loss: 2.634650157889615
Validation loss: 2.578166013449224

Epoch: 6| Step: 10
Training loss: 1.7798535411030594
Validation loss: 2.602579675945615

Epoch: 6| Step: 11
Training loss: 1.9460194233927686
Validation loss: 2.6742645494523463

Epoch: 6| Step: 12
Training loss: 2.4278685209695245
Validation loss: 2.7936506385970037

Epoch: 6| Step: 13
Training loss: 2.3789483428388074
Validation loss: 2.7502119820705944

Epoch: 313| Step: 0
Training loss: 1.9930816438970838
Validation loss: 2.7755091993293646

Epoch: 6| Step: 1
Training loss: 1.9039919878125908
Validation loss: 2.656879485096687

Epoch: 6| Step: 2
Training loss: 2.5169543432399784
Validation loss: 2.5613579957806643

Epoch: 6| Step: 3
Training loss: 1.9839453645112923
Validation loss: 2.5513962320263506

Epoch: 6| Step: 4
Training loss: 2.465492126984521
Validation loss: 2.543759341773423

Epoch: 6| Step: 5
Training loss: 1.9735175037250507
Validation loss: 2.51730944233336

Epoch: 6| Step: 6
Training loss: 2.3028938167076385
Validation loss: 2.531319134556945

Epoch: 6| Step: 7
Training loss: 2.2612194505001746
Validation loss: 2.505854046905871

Epoch: 6| Step: 8
Training loss: 1.4288857301601645
Validation loss: 2.5316528345131553

Epoch: 6| Step: 9
Training loss: 2.1120100728575046
Validation loss: 2.5013104501028622

Epoch: 6| Step: 10
Training loss: 2.0132271158018424
Validation loss: 2.516059537837108

Epoch: 6| Step: 11
Training loss: 2.7915534001236995
Validation loss: 2.55788612578232

Epoch: 6| Step: 12
Training loss: 2.7188066498565506
Validation loss: 2.621731994511787

Epoch: 6| Step: 13
Training loss: 1.6243089527002004
Validation loss: 2.656289373367806

Epoch: 314| Step: 0
Training loss: 2.1044849369074634
Validation loss: 2.666433716573003

Epoch: 6| Step: 1
Training loss: 2.05207409025586
Validation loss: 2.589481855896663

Epoch: 6| Step: 2
Training loss: 1.341138742175074
Validation loss: 2.60050179028671

Epoch: 6| Step: 3
Training loss: 1.8552821657831058
Validation loss: 2.5700193042747537

Epoch: 6| Step: 4
Training loss: 2.1148461490162327
Validation loss: 2.5602895615649475

Epoch: 6| Step: 5
Training loss: 3.110177554738165
Validation loss: 2.516224633695567

Epoch: 6| Step: 6
Training loss: 1.891498017320393
Validation loss: 2.5370200682034185

Epoch: 6| Step: 7
Training loss: 1.6907942371664575
Validation loss: 2.520293600977629

Epoch: 6| Step: 8
Training loss: 2.316178463419423
Validation loss: 2.5420370978482896

Epoch: 6| Step: 9
Training loss: 2.054374525942282
Validation loss: 2.552201798991664

Epoch: 6| Step: 10
Training loss: 2.1639699537408923
Validation loss: 2.5816717700731315

Epoch: 6| Step: 11
Training loss: 1.9745475540520392
Validation loss: 2.6383402343277393

Epoch: 6| Step: 12
Training loss: 2.6213105932098584
Validation loss: 2.6499749806260686

Epoch: 6| Step: 13
Training loss: 2.3051982766225243
Validation loss: 2.6739249740162276

Epoch: 315| Step: 0
Training loss: 2.3072692892971425
Validation loss: 2.6940192321859273

Epoch: 6| Step: 1
Training loss: 1.942322113945233
Validation loss: 2.731800749511601

Epoch: 6| Step: 2
Training loss: 2.6926558075632596
Validation loss: 2.737656562427339

Epoch: 6| Step: 3
Training loss: 2.317030515388333
Validation loss: 2.6973468124689584

Epoch: 6| Step: 4
Training loss: 2.3074504260919824
Validation loss: 2.6384190406019536

Epoch: 6| Step: 5
Training loss: 2.038358369467133
Validation loss: 2.5366342210720636

Epoch: 6| Step: 6
Training loss: 1.2733924717343441
Validation loss: 2.545218289674764

Epoch: 6| Step: 7
Training loss: 1.7415325490366949
Validation loss: 2.5107962504713566

Epoch: 6| Step: 8
Training loss: 2.228678236836715
Validation loss: 2.5223026932423647

Epoch: 6| Step: 9
Training loss: 2.1091970863193388
Validation loss: 2.531977725500508

Epoch: 6| Step: 10
Training loss: 2.4600580490830697
Validation loss: 2.5391456160023824

Epoch: 6| Step: 11
Training loss: 2.1325789662595764
Validation loss: 2.5450556366890233

Epoch: 6| Step: 12
Training loss: 2.1754502981299733
Validation loss: 2.5400353626858347

Epoch: 6| Step: 13
Training loss: 2.1199772883944075
Validation loss: 2.5574513920912643

Epoch: 316| Step: 0
Training loss: 1.851504940635194
Validation loss: 2.544947809734706

Epoch: 6| Step: 1
Training loss: 1.405175031300837
Validation loss: 2.5798087430635928

Epoch: 6| Step: 2
Training loss: 1.9130658104360143
Validation loss: 2.5902880196003824

Epoch: 6| Step: 3
Training loss: 2.3984528084431043
Validation loss: 2.6222961517955907

Epoch: 6| Step: 4
Training loss: 2.1810207869541776
Validation loss: 2.6137939695226198

Epoch: 6| Step: 5
Training loss: 2.8875087126893546
Validation loss: 2.632621343146056

Epoch: 6| Step: 6
Training loss: 1.7714687628515466
Validation loss: 2.6884525148808347

Epoch: 6| Step: 7
Training loss: 2.581699829069168
Validation loss: 2.646831569442928

Epoch: 6| Step: 8
Training loss: 1.8173448988102643
Validation loss: 2.659533845645364

Epoch: 6| Step: 9
Training loss: 1.6432191230801505
Validation loss: 2.6962599116629393

Epoch: 6| Step: 10
Training loss: 2.328967153321665
Validation loss: 2.679018669332014

Epoch: 6| Step: 11
Training loss: 2.3452731460227754
Validation loss: 2.6763350087775586

Epoch: 6| Step: 12
Training loss: 1.0758333591093794
Validation loss: 2.656039809344206

Epoch: 6| Step: 13
Training loss: 1.780526934648433
Validation loss: 2.6257832357756064

Epoch: 317| Step: 0
Training loss: 1.4725989373587292
Validation loss: 2.6334298727793377

Epoch: 6| Step: 1
Training loss: 1.8286325125198684
Validation loss: 2.6506553973051763

Epoch: 6| Step: 2
Training loss: 1.7338635489554777
Validation loss: 2.6559383733122344

Epoch: 6| Step: 3
Training loss: 2.1776592703556985
Validation loss: 2.668289738675635

Epoch: 6| Step: 4
Training loss: 2.7443994366108004
Validation loss: 2.6818798946613613

Epoch: 6| Step: 5
Training loss: 2.351481388758943
Validation loss: 2.701316037104152

Epoch: 6| Step: 6
Training loss: 2.1601758959464905
Validation loss: 2.712528696216025

Epoch: 6| Step: 7
Training loss: 2.2582559645046225
Validation loss: 2.6484492178838686

Epoch: 6| Step: 8
Training loss: 1.5849364179499732
Validation loss: 2.652052506125085

Epoch: 6| Step: 9
Training loss: 2.18721246191966
Validation loss: 2.607123936312624

Epoch: 6| Step: 10
Training loss: 2.1208630852651544
Validation loss: 2.583710478868109

Epoch: 6| Step: 11
Training loss: 2.0068855966331594
Validation loss: 2.5863186189482263

Epoch: 6| Step: 12
Training loss: 1.8627834974775601
Validation loss: 2.5980487039433706

Epoch: 6| Step: 13
Training loss: 1.6896392543332839
Validation loss: 2.540711259804752

Epoch: 318| Step: 0
Training loss: 2.6393606556153246
Validation loss: 2.540393523509746

Epoch: 6| Step: 1
Training loss: 2.3973380187430475
Validation loss: 2.542098545424319

Epoch: 6| Step: 2
Training loss: 1.5771307504329442
Validation loss: 2.5751526160830123

Epoch: 6| Step: 3
Training loss: 2.0464598256484696
Validation loss: 2.566865164855043

Epoch: 6| Step: 4
Training loss: 1.952539096689944
Validation loss: 2.565804111363455

Epoch: 6| Step: 5
Training loss: 1.906584100680623
Validation loss: 2.5828096002438223

Epoch: 6| Step: 6
Training loss: 2.2710168280236287
Validation loss: 2.5843883995314583

Epoch: 6| Step: 7
Training loss: 1.918284838826047
Validation loss: 2.626749590962183

Epoch: 6| Step: 8
Training loss: 1.9560203149282753
Validation loss: 2.5942130230876006

Epoch: 6| Step: 9
Training loss: 1.637005400763512
Validation loss: 2.611506644066988

Epoch: 6| Step: 10
Training loss: 2.163104234191805
Validation loss: 2.6051873965961962

Epoch: 6| Step: 11
Training loss: 1.693458774205644
Validation loss: 2.5920908420316837

Epoch: 6| Step: 12
Training loss: 2.3202425242960083
Validation loss: 2.624381370915233

Epoch: 6| Step: 13
Training loss: 1.8155196456413565
Validation loss: 2.627736527152986

Epoch: 319| Step: 0
Training loss: 1.3152116284670803
Validation loss: 2.605906680857659

Epoch: 6| Step: 1
Training loss: 2.270313751787443
Validation loss: 2.6108280636072374

Epoch: 6| Step: 2
Training loss: 2.9390013084551483
Validation loss: 2.618109879294101

Epoch: 6| Step: 3
Training loss: 1.732132845640394
Validation loss: 2.6411479003352523

Epoch: 6| Step: 4
Training loss: 1.7138155763685505
Validation loss: 2.646935261022012

Epoch: 6| Step: 5
Training loss: 1.628529457039033
Validation loss: 2.6286849088858992

Epoch: 6| Step: 6
Training loss: 2.0516880900516683
Validation loss: 2.605376021275928

Epoch: 6| Step: 7
Training loss: 2.170478426671634
Validation loss: 2.6213144739092833

Epoch: 6| Step: 8
Training loss: 2.4651184412606546
Validation loss: 2.5985999666164514

Epoch: 6| Step: 9
Training loss: 1.935761810286413
Validation loss: 2.595397410725264

Epoch: 6| Step: 10
Training loss: 1.632814836272252
Validation loss: 2.5932831707967767

Epoch: 6| Step: 11
Training loss: 2.1072869032238537
Validation loss: 2.573391725078622

Epoch: 6| Step: 12
Training loss: 1.866736960222867
Validation loss: 2.565049802459019

Epoch: 6| Step: 13
Training loss: 1.4684569695532257
Validation loss: 2.5484811441912574

Epoch: 320| Step: 0
Training loss: 2.4495919413273946
Validation loss: 2.581671123619821

Epoch: 6| Step: 1
Training loss: 2.0019848034841194
Validation loss: 2.580159503924936

Epoch: 6| Step: 2
Training loss: 2.20112833218634
Validation loss: 2.5688316307493704

Epoch: 6| Step: 3
Training loss: 2.41848182472969
Validation loss: 2.6099128016646826

Epoch: 6| Step: 4
Training loss: 2.135146655868264
Validation loss: 2.612250185008734

Epoch: 6| Step: 5
Training loss: 2.2859657353647536
Validation loss: 2.6140040684303276

Epoch: 6| Step: 6
Training loss: 1.7768448014029545
Validation loss: 2.595510796663799

Epoch: 6| Step: 7
Training loss: 1.7173840730459238
Validation loss: 2.637438768577019

Epoch: 6| Step: 8
Training loss: 1.4236279256597855
Validation loss: 2.6390162576644665

Epoch: 6| Step: 9
Training loss: 1.7920299723536894
Validation loss: 2.543333794038397

Epoch: 6| Step: 10
Training loss: 2.2300168730435286
Validation loss: 2.5634530628883203

Epoch: 6| Step: 11
Training loss: 1.739021058115763
Validation loss: 2.5797927856525034

Epoch: 6| Step: 12
Training loss: 1.6123985850061802
Validation loss: 2.5518873074562003

Epoch: 6| Step: 13
Training loss: 1.612043963862202
Validation loss: 2.5748566535135478

Epoch: 321| Step: 0
Training loss: 2.007293752904447
Validation loss: 2.5462819600584736

Epoch: 6| Step: 1
Training loss: 1.4210725972518632
Validation loss: 2.55626637454334

Epoch: 6| Step: 2
Training loss: 2.530159609437902
Validation loss: 2.556282704213301

Epoch: 6| Step: 3
Training loss: 2.035307953611427
Validation loss: 2.541011152524968

Epoch: 6| Step: 4
Training loss: 1.9573044272171443
Validation loss: 2.5273858705103183

Epoch: 6| Step: 5
Training loss: 2.0704976700799835
Validation loss: 2.5842533216695887

Epoch: 6| Step: 6
Training loss: 1.9612111664350083
Validation loss: 2.5976459703743973

Epoch: 6| Step: 7
Training loss: 1.7393580840998528
Validation loss: 2.621437872607454

Epoch: 6| Step: 8
Training loss: 1.8076226612010249
Validation loss: 2.6469236340158795

Epoch: 6| Step: 9
Training loss: 1.477830776102396
Validation loss: 2.6292675085623416

Epoch: 6| Step: 10
Training loss: 1.6418552690532202
Validation loss: 2.6076158849043245

Epoch: 6| Step: 11
Training loss: 2.6093963804910936
Validation loss: 2.608608414969666

Epoch: 6| Step: 12
Training loss: 2.4477145064185164
Validation loss: 2.602852792539825

Epoch: 6| Step: 13
Training loss: 2.098936688206639
Validation loss: 2.6303731029505895

Epoch: 322| Step: 0
Training loss: 1.8026257913110408
Validation loss: 2.7026782833534106

Epoch: 6| Step: 1
Training loss: 2.026516372520405
Validation loss: 2.6840550129440666

Epoch: 6| Step: 2
Training loss: 1.896365821032154
Validation loss: 2.6915567150236126

Epoch: 6| Step: 3
Training loss: 1.6670704908701826
Validation loss: 2.634151416369563

Epoch: 6| Step: 4
Training loss: 2.058146650777927
Validation loss: 2.6294504011541497

Epoch: 6| Step: 5
Training loss: 2.1159956276385126
Validation loss: 2.6042524145632164

Epoch: 6| Step: 6
Training loss: 3.107988057804607
Validation loss: 2.6503065147912555

Epoch: 6| Step: 7
Training loss: 2.3791753306679264
Validation loss: 2.6215955971091933

Epoch: 6| Step: 8
Training loss: 2.165539289267363
Validation loss: 2.621581485582687

Epoch: 6| Step: 9
Training loss: 2.198936756003473
Validation loss: 2.6221365069624083

Epoch: 6| Step: 10
Training loss: 1.808614512379982
Validation loss: 2.622330973838649

Epoch: 6| Step: 11
Training loss: 1.3011991728751002
Validation loss: 2.611423046561937

Epoch: 6| Step: 12
Training loss: 1.3132057109214752
Validation loss: 2.605813487369448

Epoch: 6| Step: 13
Training loss: 1.6942821131355283
Validation loss: 2.58830506275145

Epoch: 323| Step: 0
Training loss: 1.7649674668163966
Validation loss: 2.564404415724594

Epoch: 6| Step: 1
Training loss: 1.8137277851282265
Validation loss: 2.5787924625009064

Epoch: 6| Step: 2
Training loss: 1.411215006932546
Validation loss: 2.562910217697108

Epoch: 6| Step: 3
Training loss: 2.044890162122769
Validation loss: 2.6001030510262892

Epoch: 6| Step: 4
Training loss: 1.7768140737183158
Validation loss: 2.5963283959694126

Epoch: 6| Step: 5
Training loss: 1.890902538263198
Validation loss: 2.6089336760631916

Epoch: 6| Step: 6
Training loss: 2.5334753921063546
Validation loss: 2.658807936567568

Epoch: 6| Step: 7
Training loss: 2.4175906771643563
Validation loss: 2.676973041286106

Epoch: 6| Step: 8
Training loss: 2.561119358944065
Validation loss: 2.5764713725424313

Epoch: 6| Step: 9
Training loss: 1.4421014530719218
Validation loss: 2.542597370990102

Epoch: 6| Step: 10
Training loss: 1.9158481287485183
Validation loss: 2.573579128917802

Epoch: 6| Step: 11
Training loss: 1.765316151301004
Validation loss: 2.532787640885157

Epoch: 6| Step: 12
Training loss: 2.8904686138017563
Validation loss: 2.5359981806168914

Epoch: 6| Step: 13
Training loss: 2.1615676545835423
Validation loss: 2.5259247480777933

Epoch: 324| Step: 0
Training loss: 1.8158561283668957
Validation loss: 2.5211490296807986

Epoch: 6| Step: 1
Training loss: 2.3562965772968103
Validation loss: 2.5222775654408984

Epoch: 6| Step: 2
Training loss: 1.8442270987093128
Validation loss: 2.570923289163175

Epoch: 6| Step: 3
Training loss: 2.339112946215421
Validation loss: 2.5978990943230778

Epoch: 6| Step: 4
Training loss: 1.60690740646867
Validation loss: 2.582756336953095

Epoch: 6| Step: 5
Training loss: 1.324520740564091
Validation loss: 2.6322947067486733

Epoch: 6| Step: 6
Training loss: 2.510720536662775
Validation loss: 2.6890735085893933

Epoch: 6| Step: 7
Training loss: 2.1707468739264884
Validation loss: 2.690920641551741

Epoch: 6| Step: 8
Training loss: 1.53927068706153
Validation loss: 2.677628284804043

Epoch: 6| Step: 9
Training loss: 2.185609381960536
Validation loss: 2.6520156320309693

Epoch: 6| Step: 10
Training loss: 2.510064560717215
Validation loss: 2.562785373087245

Epoch: 6| Step: 11
Training loss: 1.4779848383124552
Validation loss: 2.526059106720697

Epoch: 6| Step: 12
Training loss: 1.927761336643395
Validation loss: 2.518163336307933

Epoch: 6| Step: 13
Training loss: 1.9674176748809802
Validation loss: 2.4947567634025742

Epoch: 325| Step: 0
Training loss: 1.342676354800113
Validation loss: 2.49393142225104

Epoch: 6| Step: 1
Training loss: 2.3011662884788326
Validation loss: 2.5025681021027237

Epoch: 6| Step: 2
Training loss: 2.087357284327262
Validation loss: 2.5122176130273983

Epoch: 6| Step: 3
Training loss: 2.8258285050241687
Validation loss: 2.5137284200138175

Epoch: 6| Step: 4
Training loss: 1.532382935226884
Validation loss: 2.5067553010025145

Epoch: 6| Step: 5
Training loss: 1.4604488922496293
Validation loss: 2.5018594184775913

Epoch: 6| Step: 6
Training loss: 1.7627479270627475
Validation loss: 2.5367611437341906

Epoch: 6| Step: 7
Training loss: 1.253819828085622
Validation loss: 2.545727882969229

Epoch: 6| Step: 8
Training loss: 2.3023317873268283
Validation loss: 2.5605368809198237

Epoch: 6| Step: 9
Training loss: 1.6183129416509243
Validation loss: 2.67139867808852

Epoch: 6| Step: 10
Training loss: 2.1226930999084455
Validation loss: 2.723481296370267

Epoch: 6| Step: 11
Training loss: 2.1073784315494373
Validation loss: 2.7566070083226846

Epoch: 6| Step: 12
Training loss: 2.842560907280032
Validation loss: 2.7795818912771315

Epoch: 6| Step: 13
Training loss: 2.1821194552722445
Validation loss: 2.710500339288719

Epoch: 326| Step: 0
Training loss: 1.9739732028800383
Validation loss: 2.635074281628723

Epoch: 6| Step: 1
Training loss: 1.8178348952630867
Validation loss: 2.606305858644672

Epoch: 6| Step: 2
Training loss: 2.7047682161148807
Validation loss: 2.552384033134332

Epoch: 6| Step: 3
Training loss: 1.5422874781580778
Validation loss: 2.5626545836180017

Epoch: 6| Step: 4
Training loss: 2.115192895484339
Validation loss: 2.542439848651853

Epoch: 6| Step: 5
Training loss: 1.3052197587024896
Validation loss: 2.542432768591416

Epoch: 6| Step: 6
Training loss: 1.4576756583831414
Validation loss: 2.5235829582059974

Epoch: 6| Step: 7
Training loss: 1.909924452121413
Validation loss: 2.582979736944733

Epoch: 6| Step: 8
Training loss: 1.4789936698793584
Validation loss: 2.5940445269309858

Epoch: 6| Step: 9
Training loss: 1.8041047976180802
Validation loss: 2.60357379013683

Epoch: 6| Step: 10
Training loss: 1.858655902710062
Validation loss: 2.6208027328944676

Epoch: 6| Step: 11
Training loss: 2.8187386726101042
Validation loss: 2.5957745766355402

Epoch: 6| Step: 12
Training loss: 1.8709131842594644
Validation loss: 2.6102578046053795

Epoch: 6| Step: 13
Training loss: 2.237254175076333
Validation loss: 2.587556883206659

Epoch: 327| Step: 0
Training loss: 1.4711490274295744
Validation loss: 2.598932657261513

Epoch: 6| Step: 1
Training loss: 1.6568664267371054
Validation loss: 2.629407406972885

Epoch: 6| Step: 2
Training loss: 2.1036067507246536
Validation loss: 2.5910958034471436

Epoch: 6| Step: 3
Training loss: 1.923951740456689
Validation loss: 2.5729188854707323

Epoch: 6| Step: 4
Training loss: 2.4496851816128684
Validation loss: 2.6018784324494457

Epoch: 6| Step: 5
Training loss: 1.9552161047050585
Validation loss: 2.6182998494905516

Epoch: 6| Step: 6
Training loss: 2.034323025697266
Validation loss: 2.6542403903066343

Epoch: 6| Step: 7
Training loss: 2.70658785008397
Validation loss: 2.708949801392382

Epoch: 6| Step: 8
Training loss: 2.2457518209505007
Validation loss: 2.7637612336251216

Epoch: 6| Step: 9
Training loss: 2.408592768052427
Validation loss: 2.7132598354740467

Epoch: 6| Step: 10
Training loss: 1.8911310574784204
Validation loss: 2.5891879916737643

Epoch: 6| Step: 11
Training loss: 1.5737005474147074
Validation loss: 2.5547508675185275

Epoch: 6| Step: 12
Training loss: 2.0178985784353887
Validation loss: 2.5681467720099733

Epoch: 6| Step: 13
Training loss: 2.0646693063254515
Validation loss: 2.5372901873609437

Epoch: 328| Step: 0
Training loss: 1.640037576779911
Validation loss: 2.5602161573133775

Epoch: 6| Step: 1
Training loss: 3.003342991120803
Validation loss: 2.5372509563235135

Epoch: 6| Step: 2
Training loss: 1.7222240364242898
Validation loss: 2.516083203715915

Epoch: 6| Step: 3
Training loss: 1.6585212824654585
Validation loss: 2.605253699720007

Epoch: 6| Step: 4
Training loss: 2.2900278184691976
Validation loss: 2.590691628575217

Epoch: 6| Step: 5
Training loss: 2.2865463853940495
Validation loss: 2.6142814178218075

Epoch: 6| Step: 6
Training loss: 1.8460552222856248
Validation loss: 2.6821185651804713

Epoch: 6| Step: 7
Training loss: 1.8511001073928233
Validation loss: 2.6482452802942227

Epoch: 6| Step: 8
Training loss: 2.4249887446506073
Validation loss: 2.6057079382690045

Epoch: 6| Step: 9
Training loss: 1.7452923260430404
Validation loss: 2.5603629714719776

Epoch: 6| Step: 10
Training loss: 1.7211360668187017
Validation loss: 2.539079965384642

Epoch: 6| Step: 11
Training loss: 1.7330385850065722
Validation loss: 2.526399305267512

Epoch: 6| Step: 12
Training loss: 2.048445121233022
Validation loss: 2.5343858736669636

Epoch: 6| Step: 13
Training loss: 1.9035335008395202
Validation loss: 2.545406987212483

Epoch: 329| Step: 0
Training loss: 2.5815115216574562
Validation loss: 2.5511981181442707

Epoch: 6| Step: 1
Training loss: 1.671750215526103
Validation loss: 2.526323052428636

Epoch: 6| Step: 2
Training loss: 1.9105050796245584
Validation loss: 2.5581757803458487

Epoch: 6| Step: 3
Training loss: 1.8428836662183414
Validation loss: 2.575446508021065

Epoch: 6| Step: 4
Training loss: 1.9491127612208534
Validation loss: 2.6430321204992464

Epoch: 6| Step: 5
Training loss: 2.1323632965455466
Validation loss: 2.67191687954508

Epoch: 6| Step: 6
Training loss: 2.1213002253685547
Validation loss: 2.641116997444734

Epoch: 6| Step: 7
Training loss: 1.711433025350218
Validation loss: 2.6314727513736726

Epoch: 6| Step: 8
Training loss: 1.7008799183041932
Validation loss: 2.6385690785301983

Epoch: 6| Step: 9
Training loss: 2.087000086880779
Validation loss: 2.620443476643262

Epoch: 6| Step: 10
Training loss: 1.904097295230627
Validation loss: 2.6303700060618227

Epoch: 6| Step: 11
Training loss: 2.166617417387111
Validation loss: 2.635626944092759

Epoch: 6| Step: 12
Training loss: 2.0003012191914444
Validation loss: 2.675616880691329

Epoch: 6| Step: 13
Training loss: 1.8833433803639197
Validation loss: 2.687878441594737

Epoch: 330| Step: 0
Training loss: 1.7921664701523352
Validation loss: 2.6918653918702193

Epoch: 6| Step: 1
Training loss: 2.187014498648183
Validation loss: 2.6846933421093326

Epoch: 6| Step: 2
Training loss: 2.2509144937890486
Validation loss: 2.7274576228014347

Epoch: 6| Step: 3
Training loss: 1.3417201124330744
Validation loss: 2.649327551496417

Epoch: 6| Step: 4
Training loss: 1.5133865973611997
Validation loss: 2.5945355861083503

Epoch: 6| Step: 5
Training loss: 2.2914212413340365
Validation loss: 2.5754791400390267

Epoch: 6| Step: 6
Training loss: 2.3178332920178235
Validation loss: 2.5568590335600754

Epoch: 6| Step: 7
Training loss: 2.6881248280060177
Validation loss: 2.574418418600251

Epoch: 6| Step: 8
Training loss: 2.2810088774873334
Validation loss: 2.578877502977638

Epoch: 6| Step: 9
Training loss: 2.0566347127541444
Validation loss: 2.5280082807722155

Epoch: 6| Step: 10
Training loss: 1.5467768165948261
Validation loss: 2.611466154237186

Epoch: 6| Step: 11
Training loss: 2.2614815543124833
Validation loss: 2.5778812023448863

Epoch: 6| Step: 12
Training loss: 1.5624330887772853
Validation loss: 2.6087840890233673

Epoch: 6| Step: 13
Training loss: 1.6670607657201322
Validation loss: 2.5858954265817458

Epoch: 331| Step: 0
Training loss: 2.7046243555553304
Validation loss: 2.6434708558379594

Epoch: 6| Step: 1
Training loss: 1.5289876924946286
Validation loss: 2.6028432509651926

Epoch: 6| Step: 2
Training loss: 2.090641504060066
Validation loss: 2.6582428730448444

Epoch: 6| Step: 3
Training loss: 2.2212872034841755
Validation loss: 2.5839306438200595

Epoch: 6| Step: 4
Training loss: 1.7837295674341358
Validation loss: 2.59058961249748

Epoch: 6| Step: 5
Training loss: 2.1148304787012595
Validation loss: 2.5805657518206164

Epoch: 6| Step: 6
Training loss: 1.9850246537452785
Validation loss: 2.53739558351155

Epoch: 6| Step: 7
Training loss: 1.930050773249229
Validation loss: 2.528842809661338

Epoch: 6| Step: 8
Training loss: 1.6397346623862672
Validation loss: 2.557588180682408

Epoch: 6| Step: 9
Training loss: 2.1577450641588443
Validation loss: 2.6362125466539417

Epoch: 6| Step: 10
Training loss: 1.1113490419480914
Validation loss: 2.608803174376075

Epoch: 6| Step: 11
Training loss: 1.409565471626586
Validation loss: 2.60350236176272

Epoch: 6| Step: 12
Training loss: 2.4147047651386293
Validation loss: 2.610479718720682

Epoch: 6| Step: 13
Training loss: 1.9888821576298774
Validation loss: 2.632977066405711

Epoch: 332| Step: 0
Training loss: 1.890892955612819
Validation loss: 2.602102351570926

Epoch: 6| Step: 1
Training loss: 2.31695457517362
Validation loss: 2.6164914244590176

Epoch: 6| Step: 2
Training loss: 1.4501263431884501
Validation loss: 2.5337252660873073

Epoch: 6| Step: 3
Training loss: 1.946821248152876
Validation loss: 2.53863022474605

Epoch: 6| Step: 4
Training loss: 2.119646621978057
Validation loss: 2.531953392099025

Epoch: 6| Step: 5
Training loss: 1.9806800142726761
Validation loss: 2.5357586929045417

Epoch: 6| Step: 6
Training loss: 1.5082447440474565
Validation loss: 2.5223219445923712

Epoch: 6| Step: 7
Training loss: 1.4241020451961426
Validation loss: 2.5144072481799786

Epoch: 6| Step: 8
Training loss: 2.7909896561073184
Validation loss: 2.504431103683333

Epoch: 6| Step: 9
Training loss: 2.529079212853262
Validation loss: 2.508463678954842

Epoch: 6| Step: 10
Training loss: 1.6966016236574137
Validation loss: 2.527878403552991

Epoch: 6| Step: 11
Training loss: 2.0726860978859953
Validation loss: 2.5755488307705274

Epoch: 6| Step: 12
Training loss: 1.922280183584659
Validation loss: 2.6408584912844106

Epoch: 6| Step: 13
Training loss: 1.9385514636426762
Validation loss: 2.644843754975986

Epoch: 333| Step: 0
Training loss: 1.9171823416021043
Validation loss: 2.657137374755079

Epoch: 6| Step: 1
Training loss: 1.618109104141774
Validation loss: 2.642063674416463

Epoch: 6| Step: 2
Training loss: 1.678947960152181
Validation loss: 2.5441787895699326

Epoch: 6| Step: 3
Training loss: 1.910311327920957
Validation loss: 2.544968123270692

Epoch: 6| Step: 4
Training loss: 2.162322408627478
Validation loss: 2.55020756718187

Epoch: 6| Step: 5
Training loss: 1.7151245026396928
Validation loss: 2.53667903830293

Epoch: 6| Step: 6
Training loss: 2.216965938624782
Validation loss: 2.571904115755416

Epoch: 6| Step: 7
Training loss: 1.8765857348881618
Validation loss: 2.561430273617239

Epoch: 6| Step: 8
Training loss: 2.2493443063484517
Validation loss: 2.573842863927539

Epoch: 6| Step: 9
Training loss: 2.322057100242871
Validation loss: 2.606700905170933

Epoch: 6| Step: 10
Training loss: 1.95707949276242
Validation loss: 2.6308130960186564

Epoch: 6| Step: 11
Training loss: 1.7618709929800596
Validation loss: 2.655000834228423

Epoch: 6| Step: 12
Training loss: 2.2610260688395805
Validation loss: 2.634488561798844

Epoch: 6| Step: 13
Training loss: 1.991799889049954
Validation loss: 2.688274272010569

Epoch: 334| Step: 0
Training loss: 1.7295212745913002
Validation loss: 2.603698540891908

Epoch: 6| Step: 1
Training loss: 1.5335709246094538
Validation loss: 2.6112570304769878

Epoch: 6| Step: 2
Training loss: 2.5101399777048528
Validation loss: 2.577445817360007

Epoch: 6| Step: 3
Training loss: 1.3749682682884172
Validation loss: 2.5805334997951217

Epoch: 6| Step: 4
Training loss: 1.9475515570812558
Validation loss: 2.5957883156372747

Epoch: 6| Step: 5
Training loss: 2.335707433081391
Validation loss: 2.561791298721097

Epoch: 6| Step: 6
Training loss: 1.69965225477755
Validation loss: 2.564467256482389

Epoch: 6| Step: 7
Training loss: 3.1606671235119674
Validation loss: 2.595810389736255

Epoch: 6| Step: 8
Training loss: 2.2131496186975728
Validation loss: 2.619048289303054

Epoch: 6| Step: 9
Training loss: 1.6120470697237357
Validation loss: 2.64085799474046

Epoch: 6| Step: 10
Training loss: 1.7807858849599267
Validation loss: 2.7117625070417524

Epoch: 6| Step: 11
Training loss: 2.7517992549247294
Validation loss: 2.716221609305162

Epoch: 6| Step: 12
Training loss: 1.6901494173439218
Validation loss: 2.7260427043263187

Epoch: 6| Step: 13
Training loss: 1.2435961719254023
Validation loss: 2.736650490134129

Epoch: 335| Step: 0
Training loss: 2.1522211223361625
Validation loss: 2.625259326053788

Epoch: 6| Step: 1
Training loss: 1.5325798954758756
Validation loss: 2.6042084474390896

Epoch: 6| Step: 2
Training loss: 1.9227713998772482
Validation loss: 2.605684590776463

Epoch: 6| Step: 3
Training loss: 1.9741210333639925
Validation loss: 2.5622120439582377

Epoch: 6| Step: 4
Training loss: 2.57563254355511
Validation loss: 2.5416542480248743

Epoch: 6| Step: 5
Training loss: 2.4408560903557803
Validation loss: 2.5588233514710046

Epoch: 6| Step: 6
Training loss: 1.5424681032366807
Validation loss: 2.565632758243058

Epoch: 6| Step: 7
Training loss: 1.4025538720104842
Validation loss: 2.551699408373658

Epoch: 6| Step: 8
Training loss: 2.15186704697858
Validation loss: 2.5840431027936313

Epoch: 6| Step: 9
Training loss: 2.081626752598503
Validation loss: 2.5691223635727045

Epoch: 6| Step: 10
Training loss: 1.572528850248313
Validation loss: 2.6176776483945727

Epoch: 6| Step: 11
Training loss: 1.8726542740589804
Validation loss: 2.6418328015365806

Epoch: 6| Step: 12
Training loss: 1.6060475143871797
Validation loss: 2.6100648588645172

Epoch: 6| Step: 13
Training loss: 1.802982664523197
Validation loss: 2.5816952115921548

Epoch: 336| Step: 0
Training loss: 1.9676661459777616
Validation loss: 2.5565782679760214

Epoch: 6| Step: 1
Training loss: 2.966865985761039
Validation loss: 2.5511790068170472

Epoch: 6| Step: 2
Training loss: 1.7050972814019114
Validation loss: 2.54981319640839

Epoch: 6| Step: 3
Training loss: 1.7861815331740232
Validation loss: 2.544205044247551

Epoch: 6| Step: 4
Training loss: 2.181927586110005
Validation loss: 2.571112171139174

Epoch: 6| Step: 5
Training loss: 2.014395642010593
Validation loss: 2.561250180265694

Epoch: 6| Step: 6
Training loss: 2.0604588205045187
Validation loss: 2.544179195652672

Epoch: 6| Step: 7
Training loss: 2.0811516082692205
Validation loss: 2.6130272894425928

Epoch: 6| Step: 8
Training loss: 1.4695356175278167
Validation loss: 2.660930966996248

Epoch: 6| Step: 9
Training loss: 1.920771274129578
Validation loss: 2.694098305071385

Epoch: 6| Step: 10
Training loss: 2.403872318418867
Validation loss: 2.7417264806219195

Epoch: 6| Step: 11
Training loss: 1.8163652969173638
Validation loss: 2.69318558812533

Epoch: 6| Step: 12
Training loss: 1.432972287385913
Validation loss: 2.670877846888943

Epoch: 6| Step: 13
Training loss: 2.0964672618869042
Validation loss: 2.6513339008375136

Epoch: 337| Step: 0
Training loss: 1.8382683425625264
Validation loss: 2.5849807982527864

Epoch: 6| Step: 1
Training loss: 1.1011302992924576
Validation loss: 2.610956675841255

Epoch: 6| Step: 2
Training loss: 1.672674825566081
Validation loss: 2.618101038370482

Epoch: 6| Step: 3
Training loss: 2.245953311676082
Validation loss: 2.598521657786307

Epoch: 6| Step: 4
Training loss: 2.5426289555527433
Validation loss: 2.6002336531579653

Epoch: 6| Step: 5
Training loss: 2.408659682112315
Validation loss: 2.6129250352551407

Epoch: 6| Step: 6
Training loss: 2.180826853284682
Validation loss: 2.6312032548945954

Epoch: 6| Step: 7
Training loss: 1.5970236871404249
Validation loss: 2.6928322700198852

Epoch: 6| Step: 8
Training loss: 1.403800526471385
Validation loss: 2.697024478946949

Epoch: 6| Step: 9
Training loss: 2.314119545119483
Validation loss: 2.63939641176765

Epoch: 6| Step: 10
Training loss: 1.6422025815959016
Validation loss: 2.681590347207684

Epoch: 6| Step: 11
Training loss: 1.1052985717482586
Validation loss: 2.6611717552578713

Epoch: 6| Step: 12
Training loss: 1.9137645255944704
Validation loss: 2.6211977017554453

Epoch: 6| Step: 13
Training loss: 2.3578502452298924
Validation loss: 2.5981965308627566

Epoch: 338| Step: 0
Training loss: 1.7354637371638926
Validation loss: 2.6086907012980007

Epoch: 6| Step: 1
Training loss: 1.954327205687174
Validation loss: 2.638801245879216

Epoch: 6| Step: 2
Training loss: 1.4375338343080046
Validation loss: 2.6270646195699334

Epoch: 6| Step: 3
Training loss: 1.859478346573176
Validation loss: 2.6911736744500643

Epoch: 6| Step: 4
Training loss: 1.5595621336911794
Validation loss: 2.6891140341969506

Epoch: 6| Step: 5
Training loss: 2.392914118627323
Validation loss: 2.6717900788789732

Epoch: 6| Step: 6
Training loss: 1.536302134014908
Validation loss: 2.631204266728357

Epoch: 6| Step: 7
Training loss: 1.9569027795711358
Validation loss: 2.6064853162519594

Epoch: 6| Step: 8
Training loss: 1.8396714569216515
Validation loss: 2.594262497607777

Epoch: 6| Step: 9
Training loss: 1.9523533631966208
Validation loss: 2.618417676598781

Epoch: 6| Step: 10
Training loss: 1.8671382115454613
Validation loss: 2.618914612214545

Epoch: 6| Step: 11
Training loss: 2.4527850067312476
Validation loss: 2.6145225735680384

Epoch: 6| Step: 12
Training loss: 2.345384155236051
Validation loss: 2.666705672654343

Epoch: 6| Step: 13
Training loss: 2.15525795049941
Validation loss: 2.6397884932476776

Epoch: 339| Step: 0
Training loss: 1.609773382859211
Validation loss: 2.6473365078095874

Epoch: 6| Step: 1
Training loss: 1.8531812842636228
Validation loss: 2.645138000873597

Epoch: 6| Step: 2
Training loss: 1.5661214441147482
Validation loss: 2.683004478379762

Epoch: 6| Step: 3
Training loss: 2.185477711637427
Validation loss: 2.6476392264975908

Epoch: 6| Step: 4
Training loss: 2.286744698656476
Validation loss: 2.659103461574082

Epoch: 6| Step: 5
Training loss: 2.118831545180458
Validation loss: 2.63117026437019

Epoch: 6| Step: 6
Training loss: 1.6215860745254094
Validation loss: 2.625291702169359

Epoch: 6| Step: 7
Training loss: 1.7458267178406328
Validation loss: 2.6477929065114014

Epoch: 6| Step: 8
Training loss: 1.4311572582065484
Validation loss: 2.634281386359657

Epoch: 6| Step: 9
Training loss: 2.1819160034907537
Validation loss: 2.6123352771524813

Epoch: 6| Step: 10
Training loss: 1.765976592309468
Validation loss: 2.6289303586250217

Epoch: 6| Step: 11
Training loss: 2.6072047911153704
Validation loss: 2.6072714087115467

Epoch: 6| Step: 12
Training loss: 1.887407891760809
Validation loss: 2.6176155157871803

Epoch: 6| Step: 13
Training loss: 1.6278243828887378
Validation loss: 2.5975670055843736

Epoch: 340| Step: 0
Training loss: 1.8744230018363603
Validation loss: 2.5958128696163674

Epoch: 6| Step: 1
Training loss: 1.8928888182033363
Validation loss: 2.6766528415520834

Epoch: 6| Step: 2
Training loss: 1.6513157164833019
Validation loss: 2.6190195228671476

Epoch: 6| Step: 3
Training loss: 1.4514338178641735
Validation loss: 2.6322197628931177

Epoch: 6| Step: 4
Training loss: 2.230043708133441
Validation loss: 2.638522949835085

Epoch: 6| Step: 5
Training loss: 2.163456029640422
Validation loss: 2.699234339976799

Epoch: 6| Step: 6
Training loss: 2.30706643640624
Validation loss: 2.652514010748022

Epoch: 6| Step: 7
Training loss: 1.9904466390425986
Validation loss: 2.620538704892783

Epoch: 6| Step: 8
Training loss: 1.6171841091544312
Validation loss: 2.5907998369991647

Epoch: 6| Step: 9
Training loss: 1.5097856804032592
Validation loss: 2.5651939389290113

Epoch: 6| Step: 10
Training loss: 2.2231494108398295
Validation loss: 2.5666948501682683

Epoch: 6| Step: 11
Training loss: 1.2656982777421881
Validation loss: 2.5530639373437323

Epoch: 6| Step: 12
Training loss: 2.8566983728715383
Validation loss: 2.551343356437854

Epoch: 6| Step: 13
Training loss: 1.5502996585731645
Validation loss: 2.573866515694195

Epoch: 341| Step: 0
Training loss: 1.8709672793529943
Validation loss: 2.592145960012973

Epoch: 6| Step: 1
Training loss: 1.6190248823038647
Validation loss: 2.644330030681177

Epoch: 6| Step: 2
Training loss: 1.4922042765847647
Validation loss: 2.564729712921184

Epoch: 6| Step: 3
Training loss: 1.4685790591494936
Validation loss: 2.651512588813501

Epoch: 6| Step: 4
Training loss: 2.2387234715306894
Validation loss: 2.666375924195124

Epoch: 6| Step: 5
Training loss: 1.889992852575926
Validation loss: 2.698637086768685

Epoch: 6| Step: 6
Training loss: 1.2611600506921847
Validation loss: 2.7658463154260446

Epoch: 6| Step: 7
Training loss: 1.4270938213918984
Validation loss: 2.740086387214534

Epoch: 6| Step: 8
Training loss: 2.624010626218958
Validation loss: 2.7131779744881013

Epoch: 6| Step: 9
Training loss: 2.1335007671375386
Validation loss: 2.6785928104697687

Epoch: 6| Step: 10
Training loss: 1.3021015878033564
Validation loss: 2.678715892105258

Epoch: 6| Step: 11
Training loss: 1.4934779474081736
Validation loss: 2.656329658660217

Epoch: 6| Step: 12
Training loss: 2.078052720268505
Validation loss: 2.6342435545311345

Epoch: 6| Step: 13
Training loss: 2.872494310551015
Validation loss: 2.6062958113366563

Epoch: 342| Step: 0
Training loss: 1.9911959705098978
Validation loss: 2.58044949943129

Epoch: 6| Step: 1
Training loss: 1.2861522305238529
Validation loss: 2.6182521950841147

Epoch: 6| Step: 2
Training loss: 1.567760462438133
Validation loss: 2.568247730067096

Epoch: 6| Step: 3
Training loss: 2.223375147188503
Validation loss: 2.5746817049502293

Epoch: 6| Step: 4
Training loss: 1.8077436719236848
Validation loss: 2.5648916914928295

Epoch: 6| Step: 5
Training loss: 1.5705618589182022
Validation loss: 2.6042608218655894

Epoch: 6| Step: 6
Training loss: 2.349140022057264
Validation loss: 2.6193116028174686

Epoch: 6| Step: 7
Training loss: 1.569642792417617
Validation loss: 2.632416058585006

Epoch: 6| Step: 8
Training loss: 2.492430863411605
Validation loss: 2.7009138644683928

Epoch: 6| Step: 9
Training loss: 1.4870557971277885
Validation loss: 2.745288432346335

Epoch: 6| Step: 10
Training loss: 1.471605649628595
Validation loss: 2.717255499473157

Epoch: 6| Step: 11
Training loss: 1.57129308345605
Validation loss: 2.790430739569829

Epoch: 6| Step: 12
Training loss: 2.3525696685560997
Validation loss: 2.75372979069984

Epoch: 6| Step: 13
Training loss: 2.3398411007262756
Validation loss: 2.710468819712912

Epoch: 343| Step: 0
Training loss: 1.8289365352842772
Validation loss: 2.610063580022379

Epoch: 6| Step: 1
Training loss: 1.6446849180357488
Validation loss: 2.6234502456170636

Epoch: 6| Step: 2
Training loss: 1.3907976364817818
Validation loss: 2.5783446247303194

Epoch: 6| Step: 3
Training loss: 1.6755114073562825
Validation loss: 2.5930987693383662

Epoch: 6| Step: 4
Training loss: 2.428127364423821
Validation loss: 2.5700665388139807

Epoch: 6| Step: 5
Training loss: 1.7961039340015488
Validation loss: 2.570916117525948

Epoch: 6| Step: 6
Training loss: 1.929113387600438
Validation loss: 2.5886523698331243

Epoch: 6| Step: 7
Training loss: 2.33775090793612
Validation loss: 2.599608992861503

Epoch: 6| Step: 8
Training loss: 2.1716503877925
Validation loss: 2.6799531736363424

Epoch: 6| Step: 9
Training loss: 2.277088078956045
Validation loss: 2.6432263955288096

Epoch: 6| Step: 10
Training loss: 2.1604364637634546
Validation loss: 2.664818277109584

Epoch: 6| Step: 11
Training loss: 2.2933070698424483
Validation loss: 2.6375896908664758

Epoch: 6| Step: 12
Training loss: 1.5688742508639129
Validation loss: 2.6113105493722997

Epoch: 6| Step: 13
Training loss: 2.0011660037977506
Validation loss: 2.524175939390728

Epoch: 344| Step: 0
Training loss: 2.1855972734219256
Validation loss: 2.5718109802707847

Epoch: 6| Step: 1
Training loss: 2.05315582856094
Validation loss: 2.555648778399121

Epoch: 6| Step: 2
Training loss: 2.4362763487877053
Validation loss: 2.5321636356411026

Epoch: 6| Step: 3
Training loss: 1.8712844273643474
Validation loss: 2.553530198576415

Epoch: 6| Step: 4
Training loss: 1.9277390129242271
Validation loss: 2.5379509786606667

Epoch: 6| Step: 5
Training loss: 1.523816027442927
Validation loss: 2.572092601273911

Epoch: 6| Step: 6
Training loss: 2.9145044395634163
Validation loss: 2.572244105807821

Epoch: 6| Step: 7
Training loss: 1.790418352649023
Validation loss: 2.6589261206226094

Epoch: 6| Step: 8
Training loss: 2.445271452050395
Validation loss: 2.7068830470644696

Epoch: 6| Step: 9
Training loss: 1.9942677725403728
Validation loss: 2.811384912478882

Epoch: 6| Step: 10
Training loss: 1.7042405560928353
Validation loss: 2.824752750098177

Epoch: 6| Step: 11
Training loss: 2.1731069899024735
Validation loss: 2.7682038405017364

Epoch: 6| Step: 12
Training loss: 1.1816862239393944
Validation loss: 2.6088405830901413

Epoch: 6| Step: 13
Training loss: 1.6287842483023036
Validation loss: 2.5978030361683984

Epoch: 345| Step: 0
Training loss: 1.8936211671220708
Validation loss: 2.541375070531714

Epoch: 6| Step: 1
Training loss: 2.3433204765925777
Validation loss: 2.5405985093778725

Epoch: 6| Step: 2
Training loss: 1.8024105884740467
Validation loss: 2.5674678594452676

Epoch: 6| Step: 3
Training loss: 1.1812946412062706
Validation loss: 2.541615115617441

Epoch: 6| Step: 4
Training loss: 1.5298377550654614
Validation loss: 2.5613168450602095

Epoch: 6| Step: 5
Training loss: 1.526645979067856
Validation loss: 2.5584493348810207

Epoch: 6| Step: 6
Training loss: 2.000790916458248
Validation loss: 2.55473681449928

Epoch: 6| Step: 7
Training loss: 1.7427893997311281
Validation loss: 2.532372967319698

Epoch: 6| Step: 8
Training loss: 2.1436837055421067
Validation loss: 2.5351590713461767

Epoch: 6| Step: 9
Training loss: 1.4631707568796752
Validation loss: 2.53404068660564

Epoch: 6| Step: 10
Training loss: 2.59771150229068
Validation loss: 2.5582268760061284

Epoch: 6| Step: 11
Training loss: 1.8514441601241614
Validation loss: 2.631298078639889

Epoch: 6| Step: 12
Training loss: 2.7166531248476735
Validation loss: 2.7121821834053375

Epoch: 6| Step: 13
Training loss: 1.9225723118073916
Validation loss: 2.774561393717121

Epoch: 346| Step: 0
Training loss: 1.8653667942197156
Validation loss: 2.8833762619556675

Epoch: 6| Step: 1
Training loss: 2.5617576081963445
Validation loss: 2.9652999908862014

Epoch: 6| Step: 2
Training loss: 1.2957161931185939
Validation loss: 2.898028020047155

Epoch: 6| Step: 3
Training loss: 2.4945587070673185
Validation loss: 2.8215385723687323

Epoch: 6| Step: 4
Training loss: 1.5228422126712944
Validation loss: 2.691584787412691

Epoch: 6| Step: 5
Training loss: 1.924890463053425
Validation loss: 2.6115683894684216

Epoch: 6| Step: 6
Training loss: 1.8216496742109825
Validation loss: 2.5451537949034644

Epoch: 6| Step: 7
Training loss: 2.111425236983794
Validation loss: 2.5466858885282653

Epoch: 6| Step: 8
Training loss: 1.5438419237452083
Validation loss: 2.5464919568677638

Epoch: 6| Step: 9
Training loss: 2.2677005074371404
Validation loss: 2.5604220781095806

Epoch: 6| Step: 10
Training loss: 2.6841120101478664
Validation loss: 2.565197509513117

Epoch: 6| Step: 11
Training loss: 2.741375664415088
Validation loss: 2.5494255447333694

Epoch: 6| Step: 12
Training loss: 2.075621969007733
Validation loss: 2.5666450687424516

Epoch: 6| Step: 13
Training loss: 1.838188966055111
Validation loss: 2.5566231241542754

Epoch: 347| Step: 0
Training loss: 2.315853882879519
Validation loss: 2.5779323467367417

Epoch: 6| Step: 1
Training loss: 2.3614007198763964
Validation loss: 2.6058520597983175

Epoch: 6| Step: 2
Training loss: 2.5185551608241608
Validation loss: 2.642264464776545

Epoch: 6| Step: 3
Training loss: 1.4834472969652597
Validation loss: 2.70576686055739

Epoch: 6| Step: 4
Training loss: 1.895921083312908
Validation loss: 2.6923339898358676

Epoch: 6| Step: 5
Training loss: 1.438405290898149
Validation loss: 2.7386582750345396

Epoch: 6| Step: 6
Training loss: 2.2970558147234015
Validation loss: 2.8050110611722996

Epoch: 6| Step: 7
Training loss: 1.338055855230952
Validation loss: 2.777880967660698

Epoch: 6| Step: 8
Training loss: 2.2132798582342628
Validation loss: 2.782157349899976

Epoch: 6| Step: 9
Training loss: 1.6581106710551745
Validation loss: 2.686928015469325

Epoch: 6| Step: 10
Training loss: 1.3432114874968248
Validation loss: 2.5651068259804717

Epoch: 6| Step: 11
Training loss: 2.5048413130090563
Validation loss: 2.5775000999739266

Epoch: 6| Step: 12
Training loss: 2.2576242124195898
Validation loss: 2.5291968602028416

Epoch: 6| Step: 13
Training loss: 1.325793295127268
Validation loss: 2.5476316486517265

Epoch: 348| Step: 0
Training loss: 1.5576629536281952
Validation loss: 2.538542489818825

Epoch: 6| Step: 1
Training loss: 1.4609453333680367
Validation loss: 2.522459779651242

Epoch: 6| Step: 2
Training loss: 2.347066135471027
Validation loss: 2.545386645956551

Epoch: 6| Step: 3
Training loss: 1.5934827991966054
Validation loss: 2.556900963133542

Epoch: 6| Step: 4
Training loss: 1.6172657823274614
Validation loss: 2.600557692638561

Epoch: 6| Step: 5
Training loss: 1.5125144421857382
Validation loss: 2.6730148754279184

Epoch: 6| Step: 6
Training loss: 1.7648556814005714
Validation loss: 2.6942342766882925

Epoch: 6| Step: 7
Training loss: 1.9585302402712308
Validation loss: 2.7320973092422203

Epoch: 6| Step: 8
Training loss: 1.1748469496535148
Validation loss: 2.8091343132682494

Epoch: 6| Step: 9
Training loss: 2.429111228384423
Validation loss: 2.7755521064686306

Epoch: 6| Step: 10
Training loss: 2.625617000183544
Validation loss: 2.749497974695381

Epoch: 6| Step: 11
Training loss: 1.4342764494373617
Validation loss: 2.7221077029366834

Epoch: 6| Step: 12
Training loss: 2.209516843912423
Validation loss: 2.782023832987413

Epoch: 6| Step: 13
Training loss: 2.4604045956988725
Validation loss: 2.71138534730998

Epoch: 349| Step: 0
Training loss: 2.0010039670677076
Validation loss: 2.6533471645381312

Epoch: 6| Step: 1
Training loss: 2.5297698414568526
Validation loss: 2.5693406854477145

Epoch: 6| Step: 2
Training loss: 1.7174402968956093
Validation loss: 2.5467066874987747

Epoch: 6| Step: 3
Training loss: 2.616613068811241
Validation loss: 2.557628995215839

Epoch: 6| Step: 4
Training loss: 1.5715965980021103
Validation loss: 2.537468074102898

Epoch: 6| Step: 5
Training loss: 1.1887826517556666
Validation loss: 2.5175840832995138

Epoch: 6| Step: 6
Training loss: 2.1354451123335636
Validation loss: 2.552441324050913

Epoch: 6| Step: 7
Training loss: 2.741524205859484
Validation loss: 2.567306167234281

Epoch: 6| Step: 8
Training loss: 1.609463883695413
Validation loss: 2.6084181045634374

Epoch: 6| Step: 9
Training loss: 1.3598764305917217
Validation loss: 2.5688435570725785

Epoch: 6| Step: 10
Training loss: 2.0765375943839524
Validation loss: 2.589129088978008

Epoch: 6| Step: 11
Training loss: 1.7012156011171469
Validation loss: 2.6123280366703785

Epoch: 6| Step: 12
Training loss: 1.8372586954710168
Validation loss: 2.5752647023115984

Epoch: 6| Step: 13
Training loss: 1.4278096023967661
Validation loss: 2.588058646643579

Epoch: 350| Step: 0
Training loss: 2.0494415266821013
Validation loss: 2.543347136692105

Epoch: 6| Step: 1
Training loss: 1.9132214625259147
Validation loss: 2.5422280947447726

Epoch: 6| Step: 2
Training loss: 2.088730674302685
Validation loss: 2.5345303821399576

Epoch: 6| Step: 3
Training loss: 2.2804396770907163
Validation loss: 2.5015009189247945

Epoch: 6| Step: 4
Training loss: 1.7548586971640563
Validation loss: 2.5351897767940295

Epoch: 6| Step: 5
Training loss: 1.7873012752373243
Validation loss: 2.5154785050411657

Epoch: 6| Step: 6
Training loss: 1.595293008683382
Validation loss: 2.542371563538427

Epoch: 6| Step: 7
Training loss: 1.3950761857643883
Validation loss: 2.566717755028051

Epoch: 6| Step: 8
Training loss: 2.204017187961914
Validation loss: 2.5923298237738295

Epoch: 6| Step: 9
Training loss: 1.652148368232059
Validation loss: 2.631931568831121

Epoch: 6| Step: 10
Training loss: 2.18823186348122
Validation loss: 2.623093048620966

Epoch: 6| Step: 11
Training loss: 1.8532502413494427
Validation loss: 2.6166313377554737

Epoch: 6| Step: 12
Training loss: 1.9753661625082743
Validation loss: 2.608824117838681

Epoch: 6| Step: 13
Training loss: 1.7671384823153877
Validation loss: 2.6202659304049374

Testing loss: 2.1906452753085173
