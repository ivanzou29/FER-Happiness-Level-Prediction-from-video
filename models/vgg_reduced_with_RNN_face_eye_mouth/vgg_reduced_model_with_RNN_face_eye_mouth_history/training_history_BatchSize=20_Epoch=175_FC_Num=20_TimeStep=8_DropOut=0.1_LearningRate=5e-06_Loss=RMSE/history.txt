Epoch: 1| Step: 0
Training loss: 6.41679563846856
Validation loss: 5.905773157048486

Epoch: 5| Step: 1
Training loss: 6.207693728413254
Validation loss: 5.9043108129930975

Epoch: 5| Step: 2
Training loss: 6.3539115812869555
Validation loss: 5.902673671278077

Epoch: 5| Step: 3
Training loss: 5.782496632378336
Validation loss: 5.901131889908265

Epoch: 5| Step: 4
Training loss: 5.995033115680469
Validation loss: 5.899452529711931

Epoch: 5| Step: 5
Training loss: 5.6387807943238535
Validation loss: 5.897885260930107

Epoch: 5| Step: 6
Training loss: 5.9398901696117905
Validation loss: 5.896208797222184

Epoch: 5| Step: 7
Training loss: 6.299906036645042
Validation loss: 5.8945793889740505

Epoch: 5| Step: 8
Training loss: 6.385072119058341
Validation loss: 5.892865174082998

Epoch: 5| Step: 9
Training loss: 5.922678548199516
Validation loss: 5.891089572007736

Epoch: 5| Step: 10
Training loss: 5.344199178455907
Validation loss: 5.88932855507272

Epoch: 5| Step: 11
Training loss: 4.78354166000342
Validation loss: 5.88750948085143

Epoch: 2| Step: 0
Training loss: 7.0275312974382835
Validation loss: 5.885615531689893

Epoch: 5| Step: 1
Training loss: 6.497593947902286
Validation loss: 5.883678532956467

Epoch: 5| Step: 2
Training loss: 5.2317172007060995
Validation loss: 5.881584008813295

Epoch: 5| Step: 3
Training loss: 5.299277871797667
Validation loss: 5.87936507723154

Epoch: 5| Step: 4
Training loss: 5.637804504426076
Validation loss: 5.877249043736175

Epoch: 5| Step: 5
Training loss: 6.153509004233727
Validation loss: 5.874999174834931

Epoch: 5| Step: 6
Training loss: 6.022877628811715
Validation loss: 5.872539532602671

Epoch: 5| Step: 7
Training loss: 5.848990472267649
Validation loss: 5.870051653795573

Epoch: 5| Step: 8
Training loss: 6.591145511799511
Validation loss: 5.867391366883494

Epoch: 5| Step: 9
Training loss: 6.091926810593263
Validation loss: 5.864596821400753

Epoch: 5| Step: 10
Training loss: 5.079680313203832
Validation loss: 5.861707177469147

Epoch: 5| Step: 11
Training loss: 6.497550502814202
Validation loss: 5.8586143983330485

Epoch: 3| Step: 0
Training loss: 5.007175637155953
Validation loss: 5.855236792810517

Epoch: 5| Step: 1
Training loss: 6.134177669513033
Validation loss: 5.851925100611639

Epoch: 5| Step: 2
Training loss: 5.5475337967051574
Validation loss: 5.848347336154516

Epoch: 5| Step: 3
Training loss: 6.600177253886053
Validation loss: 5.844570850241046

Epoch: 5| Step: 4
Training loss: 6.203136684301024
Validation loss: 5.84064088141968

Epoch: 5| Step: 5
Training loss: 5.5853091866912346
Validation loss: 5.836488206677905

Epoch: 5| Step: 6
Training loss: 5.298590548258631
Validation loss: 5.832150920739649

Epoch: 5| Step: 7
Training loss: 5.089735450090141
Validation loss: 5.827547830565117

Epoch: 5| Step: 8
Training loss: 6.299317144292308
Validation loss: 5.823012699797936

Epoch: 5| Step: 9
Training loss: 6.591593746870274
Validation loss: 5.81837136757289

Epoch: 5| Step: 10
Training loss: 6.945083185278594
Validation loss: 5.813229627858105

Epoch: 5| Step: 11
Training loss: 4.758147429906064
Validation loss: 5.807699018711922

Epoch: 4| Step: 0
Training loss: 5.296786237214885
Validation loss: 5.802272213704217

Epoch: 5| Step: 1
Training loss: 5.867825286781416
Validation loss: 5.796721779442668

Epoch: 5| Step: 2
Training loss: 5.735626499907011
Validation loss: 5.790742432195623

Epoch: 5| Step: 3
Training loss: 5.991850404570524
Validation loss: 5.7848207873184805

Epoch: 5| Step: 4
Training loss: 6.456334680553992
Validation loss: 5.778401980957356

Epoch: 5| Step: 5
Training loss: 5.150358220947078
Validation loss: 5.772183603443728

Epoch: 5| Step: 6
Training loss: 5.59233953498975
Validation loss: 5.765176716015248

Epoch: 5| Step: 7
Training loss: 5.876320548479002
Validation loss: 5.7583323105600925

Epoch: 5| Step: 8
Training loss: 6.510914954889572
Validation loss: 5.751478095049752

Epoch: 5| Step: 9
Training loss: 5.985988469157024
Validation loss: 5.744518313874731

Epoch: 5| Step: 10
Training loss: 6.150397137480674
Validation loss: 5.736951458818316

Epoch: 5| Step: 11
Training loss: 5.758871118337098
Validation loss: 5.729490543805425

Epoch: 5| Step: 0
Training loss: 5.317976339263903
Validation loss: 5.722054851989523

Epoch: 5| Step: 1
Training loss: 5.85449601555859
Validation loss: 5.714515062963438

Epoch: 5| Step: 2
Training loss: 6.016569147702205
Validation loss: 5.706657193750172

Epoch: 5| Step: 3
Training loss: 6.274927705751066
Validation loss: 5.6985699164672

Epoch: 5| Step: 4
Training loss: 6.170742268977573
Validation loss: 5.690916537351904

Epoch: 5| Step: 5
Training loss: 6.6101875978012155
Validation loss: 5.682903255716537

Epoch: 5| Step: 6
Training loss: 5.882151694501673
Validation loss: 5.674692398226869

Epoch: 5| Step: 7
Training loss: 5.262526871347573
Validation loss: 5.666330989076795

Epoch: 5| Step: 8
Training loss: 5.723579743638338
Validation loss: 5.658258337985526

Epoch: 5| Step: 9
Training loss: 4.891767179549331
Validation loss: 5.6500246835130055

Epoch: 5| Step: 10
Training loss: 5.414829568620064
Validation loss: 5.642506673907794

Epoch: 5| Step: 11
Training loss: 6.56455569086416
Validation loss: 5.6345607462482485

Epoch: 6| Step: 0
Training loss: 5.5059371461007
Validation loss: 5.626251844343533

Epoch: 5| Step: 1
Training loss: 5.79531913503934
Validation loss: 5.618364439830748

Epoch: 5| Step: 2
Training loss: 5.298707898101602
Validation loss: 5.6103152847998485

Epoch: 5| Step: 3
Training loss: 5.3317230694478335
Validation loss: 5.60255234687768

Epoch: 5| Step: 4
Training loss: 6.144555151832883
Validation loss: 5.594589887820541

Epoch: 5| Step: 5
Training loss: 5.726942853799363
Validation loss: 5.587020655189006

Epoch: 5| Step: 6
Training loss: 5.878866019380619
Validation loss: 5.579602192846446

Epoch: 5| Step: 7
Training loss: 5.731870514902563
Validation loss: 5.57192449085951

Epoch: 5| Step: 8
Training loss: 5.734641419751959
Validation loss: 5.564740719051863

Epoch: 5| Step: 9
Training loss: 5.410265363012962
Validation loss: 5.557627612050384

Epoch: 5| Step: 10
Training loss: 6.334002743864052
Validation loss: 5.550299347717534

Epoch: 5| Step: 11
Training loss: 4.494885611261448
Validation loss: 5.543246921103585

Epoch: 7| Step: 0
Training loss: 6.0438218405397715
Validation loss: 5.5361711123138635

Epoch: 5| Step: 1
Training loss: 5.674475207830002
Validation loss: 5.529032756714136

Epoch: 5| Step: 2
Training loss: 5.612204685385598
Validation loss: 5.521512434836049

Epoch: 5| Step: 3
Training loss: 5.8024467569034375
Validation loss: 5.514487115846606

Epoch: 5| Step: 4
Training loss: 6.01222572890706
Validation loss: 5.506930565171819

Epoch: 5| Step: 5
Training loss: 5.603497244218721
Validation loss: 5.499456024723355

Epoch: 5| Step: 6
Training loss: 5.509129662982592
Validation loss: 5.4917753742362505

Epoch: 5| Step: 7
Training loss: 5.376051334204134
Validation loss: 5.484611281533592

Epoch: 5| Step: 8
Training loss: 4.839668375429339
Validation loss: 5.476939298589047

Epoch: 5| Step: 9
Training loss: 5.062895206048772
Validation loss: 5.469687521364455

Epoch: 5| Step: 10
Training loss: 6.132284387094194
Validation loss: 5.462255119753276

Epoch: 5| Step: 11
Training loss: 5.679547797456568
Validation loss: 5.45494237308151

Epoch: 8| Step: 0
Training loss: 4.590442115251706
Validation loss: 5.447860333338037

Epoch: 5| Step: 1
Training loss: 5.809906411656476
Validation loss: 5.440775180871437

Epoch: 5| Step: 2
Training loss: 5.838480322654804
Validation loss: 5.432585413577763

Epoch: 5| Step: 3
Training loss: 6.251555287443509
Validation loss: 5.42385270458051

Epoch: 5| Step: 4
Training loss: 6.274211831006489
Validation loss: 5.414784451671249

Epoch: 5| Step: 5
Training loss: 5.555337988513928
Validation loss: 5.407319516212068

Epoch: 5| Step: 6
Training loss: 5.031557440990058
Validation loss: 5.400644413444073

Epoch: 5| Step: 7
Training loss: 5.691107978414454
Validation loss: 5.394792628234475

Epoch: 5| Step: 8
Training loss: 5.173551627662741
Validation loss: 5.389403133773822

Epoch: 5| Step: 9
Training loss: 5.821301103645699
Validation loss: 5.383202459773889

Epoch: 5| Step: 10
Training loss: 4.371815421603068
Validation loss: 5.377461365165353

Epoch: 5| Step: 11
Training loss: 5.916999520981798
Validation loss: 5.371769851208787

Epoch: 9| Step: 0
Training loss: 4.912594331801442
Validation loss: 5.365657997511257

Epoch: 5| Step: 1
Training loss: 4.828953940330857
Validation loss: 5.359505283859291

Epoch: 5| Step: 2
Training loss: 5.528216548526067
Validation loss: 5.353522505646174

Epoch: 5| Step: 3
Training loss: 4.58434032590894
Validation loss: 5.347718555430218

Epoch: 5| Step: 4
Training loss: 6.283589548946439
Validation loss: 5.3416650061919695

Epoch: 5| Step: 5
Training loss: 6.09314055696435
Validation loss: 5.3355153085730125

Epoch: 5| Step: 6
Training loss: 6.043477841455697
Validation loss: 5.329382225113144

Epoch: 5| Step: 7
Training loss: 5.5363528749094
Validation loss: 5.3228445800956425

Epoch: 5| Step: 8
Training loss: 6.037202259880729
Validation loss: 5.316849412836717

Epoch: 5| Step: 9
Training loss: 4.944538363208859
Validation loss: 5.310356096491208

Epoch: 5| Step: 10
Training loss: 5.020950294915662
Validation loss: 5.303859625492623

Epoch: 5| Step: 11
Training loss: 4.753855295151118
Validation loss: 5.297370677399821

Epoch: 10| Step: 0
Training loss: 4.484784363460875
Validation loss: 5.2913301491053515

Epoch: 5| Step: 1
Training loss: 5.3626245373045265
Validation loss: 5.285571788495789

Epoch: 5| Step: 2
Training loss: 4.619188523800279
Validation loss: 5.279613150925193

Epoch: 5| Step: 3
Training loss: 6.433086771349726
Validation loss: 5.2737228504731934

Epoch: 5| Step: 4
Training loss: 5.865397295751731
Validation loss: 5.268041989868052

Epoch: 5| Step: 5
Training loss: 5.314236525411949
Validation loss: 5.2621190429308715

Epoch: 5| Step: 6
Training loss: 5.911084976393465
Validation loss: 5.255989760141641

Epoch: 5| Step: 7
Training loss: 5.014003598540954
Validation loss: 5.249941545494058

Epoch: 5| Step: 8
Training loss: 5.083464365453345
Validation loss: 5.244031616820759

Epoch: 5| Step: 9
Training loss: 5.443634606593515
Validation loss: 5.238074836959578

Epoch: 5| Step: 10
Training loss: 4.993146777332931
Validation loss: 5.232680233316229

Epoch: 5| Step: 11
Training loss: 7.028885778736723
Validation loss: 5.226691380818643

Epoch: 11| Step: 0
Training loss: 5.632684163868286
Validation loss: 5.2211355821576735

Epoch: 5| Step: 1
Training loss: 4.217506055754072
Validation loss: 5.215859463531739

Epoch: 5| Step: 2
Training loss: 5.955671591759129
Validation loss: 5.210337286396214

Epoch: 5| Step: 3
Training loss: 5.854691487563694
Validation loss: 5.204590256033617

Epoch: 5| Step: 4
Training loss: 4.621436937475771
Validation loss: 5.199049673906691

Epoch: 5| Step: 5
Training loss: 5.735673388430516
Validation loss: 5.193676255395377

Epoch: 5| Step: 6
Training loss: 5.5749596769645136
Validation loss: 5.188205923743638

Epoch: 5| Step: 7
Training loss: 5.673560530479743
Validation loss: 5.182661680369967

Epoch: 5| Step: 8
Training loss: 5.267697976134683
Validation loss: 5.177473313235044

Epoch: 5| Step: 9
Training loss: 4.546775580823518
Validation loss: 5.171957393731355

Epoch: 5| Step: 10
Training loss: 4.747166039169304
Validation loss: 5.167213444336558

Epoch: 5| Step: 11
Training loss: 6.657604670688391
Validation loss: 5.161720572031965

Epoch: 12| Step: 0
Training loss: 4.670671288806989
Validation loss: 5.157102464279455

Epoch: 5| Step: 1
Training loss: 5.455834707424367
Validation loss: 5.151964984937705

Epoch: 5| Step: 2
Training loss: 4.635990795912999
Validation loss: 5.14669008368681

Epoch: 5| Step: 3
Training loss: 5.628376604267245
Validation loss: 5.14195587492747

Epoch: 5| Step: 4
Training loss: 4.245470887431719
Validation loss: 5.137316093958616

Epoch: 5| Step: 5
Training loss: 5.947496211149749
Validation loss: 5.132570490364649

Epoch: 5| Step: 6
Training loss: 5.198488844860745
Validation loss: 5.128416891738656

Epoch: 5| Step: 7
Training loss: 5.0986439416716784
Validation loss: 5.122897251749603

Epoch: 5| Step: 8
Training loss: 4.805516514163228
Validation loss: 5.118361437919236

Epoch: 5| Step: 9
Training loss: 5.8066146752489445
Validation loss: 5.1135154847265945

Epoch: 5| Step: 10
Training loss: 6.1639102583385785
Validation loss: 5.108615620495257

Epoch: 5| Step: 11
Training loss: 4.046270023328222
Validation loss: 5.10386249128948

Epoch: 13| Step: 0
Training loss: 5.173684716892274
Validation loss: 5.0996351900084065

Epoch: 5| Step: 1
Training loss: 5.197486365274267
Validation loss: 5.094475411714214

Epoch: 5| Step: 2
Training loss: 5.50845467361177
Validation loss: 5.0896022658347935

Epoch: 5| Step: 3
Training loss: 4.604888491196874
Validation loss: 5.085281861094419

Epoch: 5| Step: 4
Training loss: 5.7792021552520145
Validation loss: 5.079820922926683

Epoch: 5| Step: 5
Training loss: 5.248522777721995
Validation loss: 5.074939154900679

Epoch: 5| Step: 6
Training loss: 5.047036372105656
Validation loss: 5.0705607803599415

Epoch: 5| Step: 7
Training loss: 5.8080906704637565
Validation loss: 5.065272266831344

Epoch: 5| Step: 8
Training loss: 5.5788958361498695
Validation loss: 5.060200266989942

Epoch: 5| Step: 9
Training loss: 3.8166497581362817
Validation loss: 5.05511464157182

Epoch: 5| Step: 10
Training loss: 4.81653396177243
Validation loss: 5.049721134782858

Epoch: 5| Step: 11
Training loss: 6.451659103043554
Validation loss: 5.044836981149308

Epoch: 14| Step: 0
Training loss: 5.457669089087972
Validation loss: 5.039831689289835

Epoch: 5| Step: 1
Training loss: 5.108391810088179
Validation loss: 5.035320893864262

Epoch: 5| Step: 2
Training loss: 4.8306739769702265
Validation loss: 5.03020786367817

Epoch: 5| Step: 3
Training loss: 5.0010973679816715
Validation loss: 5.025129081877443

Epoch: 5| Step: 4
Training loss: 5.537266966176718
Validation loss: 5.020395966892762

Epoch: 5| Step: 5
Training loss: 5.532226476307369
Validation loss: 5.015391470125983

Epoch: 5| Step: 6
Training loss: 5.324434585282657
Validation loss: 5.0107455657846485

Epoch: 5| Step: 7
Training loss: 4.784713986258515
Validation loss: 5.006382714781318

Epoch: 5| Step: 8
Training loss: 4.323439282305605
Validation loss: 5.001089033101028

Epoch: 5| Step: 9
Training loss: 5.108633191682312
Validation loss: 4.99648909487171

Epoch: 5| Step: 10
Training loss: 5.069264166891047
Validation loss: 4.99146371767449

Epoch: 5| Step: 11
Training loss: 6.583185057439011
Validation loss: 4.987512236972925

Epoch: 15| Step: 0
Training loss: 4.879475813056673
Validation loss: 4.9835336467369595

Epoch: 5| Step: 1
Training loss: 4.734574820453126
Validation loss: 4.978336267643922

Epoch: 5| Step: 2
Training loss: 5.208997190765074
Validation loss: 4.972989878483796

Epoch: 5| Step: 3
Training loss: 4.924068870242536
Validation loss: 4.968181665573831

Epoch: 5| Step: 4
Training loss: 4.899513236021633
Validation loss: 4.964091606403015

Epoch: 5| Step: 5
Training loss: 5.920422217287973
Validation loss: 4.959056331377397

Epoch: 5| Step: 6
Training loss: 4.405067230993224
Validation loss: 4.954596075383203

Epoch: 5| Step: 7
Training loss: 5.624682099578027
Validation loss: 4.950209777574093

Epoch: 5| Step: 8
Training loss: 5.042261430111478
Validation loss: 4.945714093575706

Epoch: 5| Step: 9
Training loss: 5.372619989119401
Validation loss: 4.940740523896861

Epoch: 5| Step: 10
Training loss: 4.688117838514498
Validation loss: 4.936868989435891

Epoch: 5| Step: 11
Training loss: 5.218350149586688
Validation loss: 4.9322702178435005

Epoch: 16| Step: 0
Training loss: 4.618998164425783
Validation loss: 4.927791539184573

Epoch: 5| Step: 1
Training loss: 5.212949898969865
Validation loss: 4.924009903595419

Epoch: 5| Step: 2
Training loss: 4.842202216166328
Validation loss: 4.918390936148463

Epoch: 5| Step: 3
Training loss: 4.630264585115394
Validation loss: 4.91410731389687

Epoch: 5| Step: 4
Training loss: 4.3899529102206865
Validation loss: 4.9101467329735735

Epoch: 5| Step: 5
Training loss: 5.452296153039938
Validation loss: 4.9060038041142695

Epoch: 5| Step: 6
Training loss: 5.8364332772386085
Validation loss: 4.901289203593704

Epoch: 5| Step: 7
Training loss: 4.553546219443415
Validation loss: 4.896607896392833

Epoch: 5| Step: 8
Training loss: 5.265459278792874
Validation loss: 4.892382613670951

Epoch: 5| Step: 9
Training loss: 5.166420448753266
Validation loss: 4.8877250840699595

Epoch: 5| Step: 10
Training loss: 5.123505164999958
Validation loss: 4.884507445079117

Epoch: 5| Step: 11
Training loss: 5.231925186100629
Validation loss: 4.8792254076559125

Epoch: 17| Step: 0
Training loss: 5.123821402147854
Validation loss: 4.875142413284425

Epoch: 5| Step: 1
Training loss: 5.196431387974046
Validation loss: 4.870464040540131

Epoch: 5| Step: 2
Training loss: 5.421307360921986
Validation loss: 4.865992212046537

Epoch: 5| Step: 3
Training loss: 4.545202412981801
Validation loss: 4.861685127094221

Epoch: 5| Step: 4
Training loss: 5.14822225164133
Validation loss: 4.857490983877095

Epoch: 5| Step: 5
Training loss: 5.777457978290969
Validation loss: 4.852269086916942

Epoch: 5| Step: 6
Training loss: 3.8452842565659493
Validation loss: 4.848753791316544

Epoch: 5| Step: 7
Training loss: 4.435161135390122
Validation loss: 4.844370607385509

Epoch: 5| Step: 8
Training loss: 4.278523934644538
Validation loss: 4.8399888315282125

Epoch: 5| Step: 9
Training loss: 5.154375510069451
Validation loss: 4.835614236227455

Epoch: 5| Step: 10
Training loss: 5.566703665300105
Validation loss: 4.830932558067323

Epoch: 5| Step: 11
Training loss: 4.478173197495557
Validation loss: 4.827113065050431

Epoch: 18| Step: 0
Training loss: 4.396470492259289
Validation loss: 4.822907378460349

Epoch: 5| Step: 1
Training loss: 5.391625176122217
Validation loss: 4.819084988044309

Epoch: 5| Step: 2
Training loss: 5.166193027731375
Validation loss: 4.814566981663235

Epoch: 5| Step: 3
Training loss: 4.80170170501209
Validation loss: 4.810113471999929

Epoch: 5| Step: 4
Training loss: 5.739328848383129
Validation loss: 4.805669867099852

Epoch: 5| Step: 5
Training loss: 5.375923964462266
Validation loss: 4.801117469595836

Epoch: 5| Step: 6
Training loss: 4.598522794958393
Validation loss: 4.7967812594222625

Epoch: 5| Step: 7
Training loss: 4.446453249803212
Validation loss: 4.7924021888904305

Epoch: 5| Step: 8
Training loss: 4.569737168314561
Validation loss: 4.788033080738042

Epoch: 5| Step: 9
Training loss: 4.995142293589155
Validation loss: 4.783764171913273

Epoch: 5| Step: 10
Training loss: 4.222123443273451
Validation loss: 4.779669631370921

Epoch: 5| Step: 11
Training loss: 6.072567475510577
Validation loss: 4.775463662762383

Epoch: 19| Step: 0
Training loss: 5.452495899365058
Validation loss: 4.77060144463352

Epoch: 5| Step: 1
Training loss: 5.004776389874625
Validation loss: 4.766637242277511

Epoch: 5| Step: 2
Training loss: 5.553610567192415
Validation loss: 4.7619595131678345

Epoch: 5| Step: 3
Training loss: 3.9930334221415373
Validation loss: 4.758091630770638

Epoch: 5| Step: 4
Training loss: 4.271201041914804
Validation loss: 4.753294170578555

Epoch: 5| Step: 5
Training loss: 5.569689786754619
Validation loss: 4.749282891535391

Epoch: 5| Step: 6
Training loss: 4.452859435612168
Validation loss: 4.744716541799623

Epoch: 5| Step: 7
Training loss: 4.775599912336154
Validation loss: 4.740526011973089

Epoch: 5| Step: 8
Training loss: 4.858682172148243
Validation loss: 4.7362172452657

Epoch: 5| Step: 9
Training loss: 5.14616267376893
Validation loss: 4.73166327038453

Epoch: 5| Step: 10
Training loss: 4.4811204537749525
Validation loss: 4.727398935505582

Epoch: 5| Step: 11
Training loss: 3.589520826955999
Validation loss: 4.72384927182827

Epoch: 20| Step: 0
Training loss: 4.824925618759578
Validation loss: 4.719386379959234

Epoch: 5| Step: 1
Training loss: 4.775688577105719
Validation loss: 4.715628722172324

Epoch: 5| Step: 2
Training loss: 4.791320965224191
Validation loss: 4.711060302550863

Epoch: 5| Step: 3
Training loss: 4.396666364999972
Validation loss: 4.706850884702963

Epoch: 5| Step: 4
Training loss: 5.190188343254236
Validation loss: 4.7040260947178405

Epoch: 5| Step: 5
Training loss: 5.434826072850783
Validation loss: 4.698800575462478

Epoch: 5| Step: 6
Training loss: 4.042019202728939
Validation loss: 4.694747459192765

Epoch: 5| Step: 7
Training loss: 4.758670522809214
Validation loss: 4.691154606634727

Epoch: 5| Step: 8
Training loss: 4.558699396604105
Validation loss: 4.6870573385822665

Epoch: 5| Step: 9
Training loss: 5.342226937955389
Validation loss: 4.683134182104265

Epoch: 5| Step: 10
Training loss: 4.685878829359801
Validation loss: 4.678809064933416

Epoch: 5| Step: 11
Training loss: 5.316938274146502
Validation loss: 4.674529428309245

Epoch: 21| Step: 0
Training loss: 5.45740906944135
Validation loss: 4.669773781775011

Epoch: 5| Step: 1
Training loss: 3.9594444455482405
Validation loss: 4.665990510843424

Epoch: 5| Step: 2
Training loss: 4.598886744920181
Validation loss: 4.661843995349492

Epoch: 5| Step: 3
Training loss: 4.732057111019808
Validation loss: 4.657821483959571

Epoch: 5| Step: 4
Training loss: 4.64849925280673
Validation loss: 4.653875278764528

Epoch: 5| Step: 5
Training loss: 4.829640172345755
Validation loss: 4.649486040950887

Epoch: 5| Step: 6
Training loss: 4.32670928166058
Validation loss: 4.645613253160454

Epoch: 5| Step: 7
Training loss: 5.2820892570028875
Validation loss: 4.641683053285083

Epoch: 5| Step: 8
Training loss: 5.735654766084089
Validation loss: 4.637406051588953

Epoch: 5| Step: 9
Training loss: 4.656532637447447
Validation loss: 4.633523415821882

Epoch: 5| Step: 10
Training loss: 4.4097752098177345
Validation loss: 4.629189501115784

Epoch: 5| Step: 11
Training loss: 2.1435150907504483
Validation loss: 4.624707891501462

Epoch: 22| Step: 0
Training loss: 5.344353000460418
Validation loss: 4.621100216385656

Epoch: 5| Step: 1
Training loss: 4.079108927041772
Validation loss: 4.617225866271304

Epoch: 5| Step: 2
Training loss: 5.512065657547119
Validation loss: 4.613187861648027

Epoch: 5| Step: 3
Training loss: 4.575200627831758
Validation loss: 4.609017499432926

Epoch: 5| Step: 4
Training loss: 4.9231525034788195
Validation loss: 4.605006390227869

Epoch: 5| Step: 5
Training loss: 4.938773075591498
Validation loss: 4.6009032247262835

Epoch: 5| Step: 6
Training loss: 5.565825421999313
Validation loss: 4.596784674895721

Epoch: 5| Step: 7
Training loss: 4.061351672514572
Validation loss: 4.5925618146662055

Epoch: 5| Step: 8
Training loss: 4.615078362061024
Validation loss: 4.588855462777415

Epoch: 5| Step: 9
Training loss: 3.815102611276702
Validation loss: 4.584245056446472

Epoch: 5| Step: 10
Training loss: 3.976241123125996
Validation loss: 4.580921503756409

Epoch: 5| Step: 11
Training loss: 5.565326272700141
Validation loss: 4.5768946273489135

Epoch: 23| Step: 0
Training loss: 4.679927558664311
Validation loss: 4.572573588832206

Epoch: 5| Step: 1
Training loss: 4.70209844291309
Validation loss: 4.568386347988568

Epoch: 5| Step: 2
Training loss: 4.41858887978941
Validation loss: 4.564359525483416

Epoch: 5| Step: 3
Training loss: 5.387314639697556
Validation loss: 4.560200638735012

Epoch: 5| Step: 4
Training loss: 4.432852446974791
Validation loss: 4.5560579239381385

Epoch: 5| Step: 5
Training loss: 4.07602400755995
Validation loss: 4.551539996067842

Epoch: 5| Step: 6
Training loss: 4.8572732483167425
Validation loss: 4.548101847372448

Epoch: 5| Step: 7
Training loss: 4.350293397326468
Validation loss: 4.543836979162518

Epoch: 5| Step: 8
Training loss: 5.027963453392184
Validation loss: 4.539773278057861

Epoch: 5| Step: 9
Training loss: 4.950145896534026
Validation loss: 4.536016557324066

Epoch: 5| Step: 10
Training loss: 4.813769086484432
Validation loss: 4.5318743045476495

Epoch: 5| Step: 11
Training loss: 2.2915386048572843
Validation loss: 4.528077420199046

Epoch: 24| Step: 0
Training loss: 3.9089340144199616
Validation loss: 4.5237450195914715

Epoch: 5| Step: 1
Training loss: 4.581127028746924
Validation loss: 4.520024225752397

Epoch: 5| Step: 2
Training loss: 4.355229857868372
Validation loss: 4.5163524354153495

Epoch: 5| Step: 3
Training loss: 5.138249831229015
Validation loss: 4.512203887353831

Epoch: 5| Step: 4
Training loss: 4.895827770906359
Validation loss: 4.508877606892988

Epoch: 5| Step: 5
Training loss: 4.503914296257991
Validation loss: 4.504848257092577

Epoch: 5| Step: 6
Training loss: 4.3859984434084165
Validation loss: 4.500803469524861

Epoch: 5| Step: 7
Training loss: 4.593470973668768
Validation loss: 4.496689801956641

Epoch: 5| Step: 8
Training loss: 4.806638045699734
Validation loss: 4.492934145589925

Epoch: 5| Step: 9
Training loss: 4.604066643412367
Validation loss: 4.488949895487222

Epoch: 5| Step: 10
Training loss: 5.002735915295109
Validation loss: 4.485473188205679

Epoch: 5| Step: 11
Training loss: 4.9076007514362905
Validation loss: 4.481158805639278

Epoch: 25| Step: 0
Training loss: 4.397319211122481
Validation loss: 4.477214195477366

Epoch: 5| Step: 1
Training loss: 4.967862991716637
Validation loss: 4.472662842147389

Epoch: 5| Step: 2
Training loss: 4.728026713416836
Validation loss: 4.46843946040377

Epoch: 5| Step: 3
Training loss: 4.862388731166363
Validation loss: 4.464506210513086

Epoch: 5| Step: 4
Training loss: 4.7894444274450025
Validation loss: 4.460617000470572

Epoch: 5| Step: 5
Training loss: 4.798553670099888
Validation loss: 4.456830041630356

Epoch: 5| Step: 6
Training loss: 4.5410746383934235
Validation loss: 4.451725665184358

Epoch: 5| Step: 7
Training loss: 4.740184480320434
Validation loss: 4.447481945630904

Epoch: 5| Step: 8
Training loss: 3.754479720723983
Validation loss: 4.443406888267603

Epoch: 5| Step: 9
Training loss: 4.711284466518965
Validation loss: 4.439659229108986

Epoch: 5| Step: 10
Training loss: 4.459794039910135
Validation loss: 4.435055162215061

Epoch: 5| Step: 11
Training loss: 1.1166210739355398
Validation loss: 4.431125450087695

Epoch: 26| Step: 0
Training loss: 4.816268832310743
Validation loss: 4.427040578598311

Epoch: 5| Step: 1
Training loss: 4.1989110079822005
Validation loss: 4.423460771523484

Epoch: 5| Step: 2
Training loss: 4.617808756850347
Validation loss: 4.41925105770664

Epoch: 5| Step: 3
Training loss: 5.129392648775535
Validation loss: 4.415625785437008

Epoch: 5| Step: 4
Training loss: 4.25815741865549
Validation loss: 4.411408464254229

Epoch: 5| Step: 5
Training loss: 4.8335219160099845
Validation loss: 4.407102403188637

Epoch: 5| Step: 6
Training loss: 4.613975169088138
Validation loss: 4.403125376506182

Epoch: 5| Step: 7
Training loss: 4.173946252203565
Validation loss: 4.398881328588365

Epoch: 5| Step: 8
Training loss: 3.853184232852071
Validation loss: 4.395103975627718

Epoch: 5| Step: 9
Training loss: 4.6989358387147
Validation loss: 4.3909739472182405

Epoch: 5| Step: 10
Training loss: 4.699495150459191
Validation loss: 4.387044974312855

Epoch: 5| Step: 11
Training loss: 3.782397639874466
Validation loss: 4.382601682473835

Epoch: 27| Step: 0
Training loss: 4.725692391502177
Validation loss: 4.3789478655064675

Epoch: 5| Step: 1
Training loss: 4.650464245991691
Validation loss: 4.374410571401399

Epoch: 5| Step: 2
Training loss: 4.78010475554658
Validation loss: 4.370705149504044

Epoch: 5| Step: 3
Training loss: 3.8747357924434893
Validation loss: 4.366444960758332

Epoch: 5| Step: 4
Training loss: 4.562703376313184
Validation loss: 4.361890711860146

Epoch: 5| Step: 5
Training loss: 4.206488982577617
Validation loss: 4.357974512246563

Epoch: 5| Step: 6
Training loss: 4.988163097538661
Validation loss: 4.353887187013181

Epoch: 5| Step: 7
Training loss: 4.257233018551271
Validation loss: 4.34980575010885

Epoch: 5| Step: 8
Training loss: 4.394654946175782
Validation loss: 4.345889902280069

Epoch: 5| Step: 9
Training loss: 5.099799372896823
Validation loss: 4.341646055415476

Epoch: 5| Step: 10
Training loss: 3.689259901181975
Validation loss: 4.337379476978026

Epoch: 5| Step: 11
Training loss: 4.102988963258028
Validation loss: 4.333385332724773

Epoch: 28| Step: 0
Training loss: 5.1300316278326665
Validation loss: 4.329273645268176

Epoch: 5| Step: 1
Training loss: 4.170056350290678
Validation loss: 4.325217471967111

Epoch: 5| Step: 2
Training loss: 4.555957021830388
Validation loss: 4.320719676176749

Epoch: 5| Step: 3
Training loss: 4.518909144468058
Validation loss: 4.316471215589184

Epoch: 5| Step: 4
Training loss: 4.321577166419948
Validation loss: 4.3125242564307

Epoch: 5| Step: 5
Training loss: 4.535691182921952
Validation loss: 4.308540996414166

Epoch: 5| Step: 6
Training loss: 4.512829188969859
Validation loss: 4.304454130203572

Epoch: 5| Step: 7
Training loss: 4.074725023599057
Validation loss: 4.300212003597496

Epoch: 5| Step: 8
Training loss: 4.674126838291774
Validation loss: 4.296266963593393

Epoch: 5| Step: 9
Training loss: 4.385585947763948
Validation loss: 4.291929425217186

Epoch: 5| Step: 10
Training loss: 4.041709165579084
Validation loss: 4.28723481732644

Epoch: 5| Step: 11
Training loss: 3.3537849224830167
Validation loss: 4.283025716739294

Epoch: 29| Step: 0
Training loss: 4.099901309802721
Validation loss: 4.2795561667368585

Epoch: 5| Step: 1
Training loss: 3.994220730973903
Validation loss: 4.2752126741211445

Epoch: 5| Step: 2
Training loss: 3.929138630631801
Validation loss: 4.272376459358271

Epoch: 5| Step: 3
Training loss: 4.9230138036459605
Validation loss: 4.268299875688086

Epoch: 5| Step: 4
Training loss: 4.292555979217603
Validation loss: 4.264101149832447

Epoch: 5| Step: 5
Training loss: 4.6107119932651255
Validation loss: 4.259562281565547

Epoch: 5| Step: 6
Training loss: 4.859360673398797
Validation loss: 4.2554982466749545

Epoch: 5| Step: 7
Training loss: 4.134675210100254
Validation loss: 4.251804053059382

Epoch: 5| Step: 8
Training loss: 4.210105346666435
Validation loss: 4.247549088935173

Epoch: 5| Step: 9
Training loss: 4.315834635864305
Validation loss: 4.243532612681833

Epoch: 5| Step: 10
Training loss: 4.652948425098956
Validation loss: 4.239649407374118

Epoch: 5| Step: 11
Training loss: 4.9894148360798924
Validation loss: 4.235488754512115

Epoch: 30| Step: 0
Training loss: 4.914638855434416
Validation loss: 4.230704021868319

Epoch: 5| Step: 1
Training loss: 4.5642880633130885
Validation loss: 4.226419739066167

Epoch: 5| Step: 2
Training loss: 4.132345883541297
Validation loss: 4.222058983555674

Epoch: 5| Step: 3
Training loss: 3.9467132801018154
Validation loss: 4.217578122361946

Epoch: 5| Step: 4
Training loss: 4.066191888412138
Validation loss: 4.2131307407052

Epoch: 5| Step: 5
Training loss: 4.69580177131794
Validation loss: 4.209394116678043

Epoch: 5| Step: 6
Training loss: 4.306515508032318
Validation loss: 4.2044958835744515

Epoch: 5| Step: 7
Training loss: 4.775223468125049
Validation loss: 4.200362653251001

Epoch: 5| Step: 8
Training loss: 3.1817064178951666
Validation loss: 4.195952581524993

Epoch: 5| Step: 9
Training loss: 4.352838024530415
Validation loss: 4.191907489499604

Epoch: 5| Step: 10
Training loss: 4.611447660325961
Validation loss: 4.187532638308738

Epoch: 5| Step: 11
Training loss: 3.9461316155410797
Validation loss: 4.183309802461584

Epoch: 31| Step: 0
Training loss: 5.081008796550642
Validation loss: 4.179075035784413

Epoch: 5| Step: 1
Training loss: 3.6503503918662985
Validation loss: 4.174556061180658

Epoch: 5| Step: 2
Training loss: 4.270352716462429
Validation loss: 4.17023087487509

Epoch: 5| Step: 3
Training loss: 4.514819433038209
Validation loss: 4.165955438311772

Epoch: 5| Step: 4
Training loss: 3.968971426486356
Validation loss: 4.1614875681028884

Epoch: 5| Step: 5
Training loss: 4.1183353105327
Validation loss: 4.157465749772707

Epoch: 5| Step: 6
Training loss: 4.574688034677777
Validation loss: 4.152840652471822

Epoch: 5| Step: 7
Training loss: 4.336434110778018
Validation loss: 4.148511911073275

Epoch: 5| Step: 8
Training loss: 4.207912058879519
Validation loss: 4.143996146338989

Epoch: 5| Step: 9
Training loss: 4.394475260059988
Validation loss: 4.139703256949457

Epoch: 5| Step: 10
Training loss: 3.7081920868337503
Validation loss: 4.135458994856182

Epoch: 5| Step: 11
Training loss: 5.030120154096564
Validation loss: 4.131207034704693

Epoch: 32| Step: 0
Training loss: 4.858457619771447
Validation loss: 4.126483838199354

Epoch: 5| Step: 1
Training loss: 3.7866880547452277
Validation loss: 4.121865709750812

Epoch: 5| Step: 2
Training loss: 4.358605320298543
Validation loss: 4.117703380753833

Epoch: 5| Step: 3
Training loss: 4.022320460834571
Validation loss: 4.113157279527426

Epoch: 5| Step: 4
Training loss: 4.531235056885382
Validation loss: 4.108911036032036

Epoch: 5| Step: 5
Training loss: 3.517340754284476
Validation loss: 4.104429264026475

Epoch: 5| Step: 6
Training loss: 3.672559828507866
Validation loss: 4.099967539860387

Epoch: 5| Step: 7
Training loss: 4.31195197562402
Validation loss: 4.095686452113415

Epoch: 5| Step: 8
Training loss: 3.9982788436079186
Validation loss: 4.091474638444979

Epoch: 5| Step: 9
Training loss: 4.955285981795294
Validation loss: 4.0871646611335635

Epoch: 5| Step: 10
Training loss: 4.24803407864452
Validation loss: 4.082739040698358

Epoch: 5| Step: 11
Training loss: 4.6392616812531235
Validation loss: 4.078494219673104

Epoch: 33| Step: 0
Training loss: 4.7358742533821205
Validation loss: 4.074094961254124

Epoch: 5| Step: 1
Training loss: 4.457775378147881
Validation loss: 4.069097678100781

Epoch: 5| Step: 2
Training loss: 3.925621644376825
Validation loss: 4.064673121308048

Epoch: 5| Step: 3
Training loss: 3.9002176321880007
Validation loss: 4.060031933447495

Epoch: 5| Step: 4
Training loss: 3.889485510215932
Validation loss: 4.05559875499385

Epoch: 5| Step: 5
Training loss: 4.7619865160690695
Validation loss: 4.050907605124729

Epoch: 5| Step: 6
Training loss: 3.513752349559605
Validation loss: 4.046494597398671

Epoch: 5| Step: 7
Training loss: 4.405170714310263
Validation loss: 4.0422876641272145

Epoch: 5| Step: 8
Training loss: 3.5220619781603686
Validation loss: 4.037765333985999

Epoch: 5| Step: 9
Training loss: 4.4704738039837
Validation loss: 4.0337197971149115

Epoch: 5| Step: 10
Training loss: 4.264844662340762
Validation loss: 4.029316810734873

Epoch: 5| Step: 11
Training loss: 3.914275203567411
Validation loss: 4.024867646191465

Epoch: 34| Step: 0
Training loss: 3.905297002890578
Validation loss: 4.020588870679563

Epoch: 5| Step: 1
Training loss: 4.423698561499494
Validation loss: 4.016203105196428

Epoch: 5| Step: 2
Training loss: 4.712824252278174
Validation loss: 4.011813798104699

Epoch: 5| Step: 3
Training loss: 4.18434320142884
Validation loss: 4.007121144847819

Epoch: 5| Step: 4
Training loss: 3.7244324424578594
Validation loss: 4.002725710623219

Epoch: 5| Step: 5
Training loss: 4.099699632760603
Validation loss: 3.9983419816619428

Epoch: 5| Step: 6
Training loss: 3.879943032977153
Validation loss: 3.9941390481337935

Epoch: 5| Step: 7
Training loss: 4.41299290484064
Validation loss: 3.9894886835622

Epoch: 5| Step: 8
Training loss: 4.098921908548385
Validation loss: 3.985330160504628

Epoch: 5| Step: 9
Training loss: 4.552224489492404
Validation loss: 3.981055433907718

Epoch: 5| Step: 10
Training loss: 3.4707121926759714
Validation loss: 3.976856583048991

Epoch: 5| Step: 11
Training loss: 3.0720576405680697
Validation loss: 3.9720074159092613

Epoch: 35| Step: 0
Training loss: 4.2909362813414305
Validation loss: 3.967929229569562

Epoch: 5| Step: 1
Training loss: 3.5679182376046588
Validation loss: 3.963264012814653

Epoch: 5| Step: 2
Training loss: 4.07981515989286
Validation loss: 3.9593345162304843

Epoch: 5| Step: 3
Training loss: 4.187035150490193
Validation loss: 3.9549849988232513

Epoch: 5| Step: 4
Training loss: 4.311701825124759
Validation loss: 3.950875201223033

Epoch: 5| Step: 5
Training loss: 4.221420686053758
Validation loss: 3.946398615132621

Epoch: 5| Step: 6
Training loss: 3.9342892589725276
Validation loss: 3.9419459366341774

Epoch: 5| Step: 7
Training loss: 4.69935187882911
Validation loss: 3.9376997922234183

Epoch: 5| Step: 8
Training loss: 4.059108550949771
Validation loss: 3.9332425548832397

Epoch: 5| Step: 9
Training loss: 4.118665513140252
Validation loss: 3.928695573744324

Epoch: 5| Step: 10
Training loss: 3.632078166288588
Validation loss: 3.924083113435325

Epoch: 5| Step: 11
Training loss: 1.6579641432801953
Validation loss: 3.9196612175286867

Epoch: 36| Step: 0
Training loss: 3.8140988358732355
Validation loss: 3.9157642870477596

Epoch: 5| Step: 1
Training loss: 4.227431343734776
Validation loss: 3.9119129991816406

Epoch: 5| Step: 2
Training loss: 4.571858045294946
Validation loss: 3.907409500966374

Epoch: 5| Step: 3
Training loss: 3.930390858129565
Validation loss: 3.9029153450416945

Epoch: 5| Step: 4
Training loss: 4.346103387465721
Validation loss: 3.898630095408735

Epoch: 5| Step: 5
Training loss: 3.830312921076326
Validation loss: 3.8943137028730606

Epoch: 5| Step: 6
Training loss: 3.6610193690329704
Validation loss: 3.8899448622462662

Epoch: 5| Step: 7
Training loss: 4.046919774577356
Validation loss: 3.885450473805364

Epoch: 5| Step: 8
Training loss: 4.202273371189225
Validation loss: 3.8813418411798075

Epoch: 5| Step: 9
Training loss: 3.848059494653071
Validation loss: 3.8768087236879993

Epoch: 5| Step: 10
Training loss: 3.4217929220589367
Validation loss: 3.8727384294711307

Epoch: 5| Step: 11
Training loss: 5.280849464170743
Validation loss: 3.868178911637258

Epoch: 37| Step: 0
Training loss: 3.952410486354995
Validation loss: 3.8637450646597555

Epoch: 5| Step: 1
Training loss: 3.7241905869126684
Validation loss: 3.859096779621241

Epoch: 5| Step: 2
Training loss: 3.422274770856187
Validation loss: 3.8546061737755055

Epoch: 5| Step: 3
Training loss: 3.912516823631898
Validation loss: 3.8509459656571754

Epoch: 5| Step: 4
Training loss: 4.340028554585126
Validation loss: 3.846428617541594

Epoch: 5| Step: 5
Training loss: 4.295508260973639
Validation loss: 3.8415636134996163

Epoch: 5| Step: 6
Training loss: 3.9401650265441126
Validation loss: 3.837290269585747

Epoch: 5| Step: 7
Training loss: 3.8518018048518363
Validation loss: 3.833035523138289

Epoch: 5| Step: 8
Training loss: 3.5345948168650363
Validation loss: 3.8284049781607656

Epoch: 5| Step: 9
Training loss: 4.210912361140755
Validation loss: 3.8244326060541214

Epoch: 5| Step: 10
Training loss: 4.323139941719268
Validation loss: 3.819568969931481

Epoch: 5| Step: 11
Training loss: 4.465109455949908
Validation loss: 3.8152082496306576

Epoch: 38| Step: 0
Training loss: 3.769420309855492
Validation loss: 3.810914843540012

Epoch: 5| Step: 1
Training loss: 4.62094061784
Validation loss: 3.8061672990956583

Epoch: 5| Step: 2
Training loss: 3.557731917670337
Validation loss: 3.80174569847332

Epoch: 5| Step: 3
Training loss: 3.4480904864764916
Validation loss: 3.797013927790827

Epoch: 5| Step: 4
Training loss: 4.150946653930799
Validation loss: 3.792872204060927

Epoch: 5| Step: 5
Training loss: 3.4776402549514644
Validation loss: 3.7882144935994995

Epoch: 5| Step: 6
Training loss: 3.610967111569276
Validation loss: 3.78396464862803

Epoch: 5| Step: 7
Training loss: 3.552650622638427
Validation loss: 3.7798448952216392

Epoch: 5| Step: 8
Training loss: 4.320927001958029
Validation loss: 3.7755031052549155

Epoch: 5| Step: 9
Training loss: 4.6809964649926235
Validation loss: 3.7711017348027998

Epoch: 5| Step: 10
Training loss: 3.6587596659374637
Validation loss: 3.7665509448096675

Epoch: 5| Step: 11
Training loss: 4.090656072325169
Validation loss: 3.762091808629936

Epoch: 39| Step: 0
Training loss: 2.5769578545957623
Validation loss: 3.757590268147023

Epoch: 5| Step: 1
Training loss: 4.478902953908716
Validation loss: 3.753859859395583

Epoch: 5| Step: 2
Training loss: 4.31972484489414
Validation loss: 3.749146003968623

Epoch: 5| Step: 3
Training loss: 3.2720562699756126
Validation loss: 3.7447282346288224

Epoch: 5| Step: 4
Training loss: 3.543088530310549
Validation loss: 3.74024715570801

Epoch: 5| Step: 5
Training loss: 4.140519972134953
Validation loss: 3.7359027690222364

Epoch: 5| Step: 6
Training loss: 3.5157740582549857
Validation loss: 3.731513008036732

Epoch: 5| Step: 7
Training loss: 3.603399044311688
Validation loss: 3.7272290234195617

Epoch: 5| Step: 8
Training loss: 4.667988771531331
Validation loss: 3.722909017482784

Epoch: 5| Step: 9
Training loss: 3.9573082784551903
Validation loss: 3.718418282852636

Epoch: 5| Step: 10
Training loss: 3.983682968777453
Validation loss: 3.714071536504515

Epoch: 5| Step: 11
Training loss: 4.128606664494972
Validation loss: 3.709673316184428

Epoch: 40| Step: 0
Training loss: 3.8171271089452508
Validation loss: 3.7051271479930628

Epoch: 5| Step: 1
Training loss: 3.174487912189724
Validation loss: 3.700564758913443

Epoch: 5| Step: 2
Training loss: 3.621885474439192
Validation loss: 3.6965587952603034

Epoch: 5| Step: 3
Training loss: 4.13972803153164
Validation loss: 3.6922477395461035

Epoch: 5| Step: 4
Training loss: 3.9775377437927473
Validation loss: 3.6883398543597696

Epoch: 5| Step: 5
Training loss: 3.98479659897989
Validation loss: 3.6841187087875626

Epoch: 5| Step: 6
Training loss: 3.4023232880950434
Validation loss: 3.6796998214785357

Epoch: 5| Step: 7
Training loss: 4.638103994844466
Validation loss: 3.675587850706297

Epoch: 5| Step: 8
Training loss: 3.823319139351698
Validation loss: 3.670952977422013

Epoch: 5| Step: 9
Training loss: 3.443241110862581
Validation loss: 3.666492114825171

Epoch: 5| Step: 10
Training loss: 3.6052595183229195
Validation loss: 3.662097227627423

Epoch: 5| Step: 11
Training loss: 4.602778068567539
Validation loss: 3.6578846127651508

Epoch: 41| Step: 0
Training loss: 3.830650897580371
Validation loss: 3.6534548560232127

Epoch: 5| Step: 1
Training loss: 4.015780078550396
Validation loss: 3.648714325972111

Epoch: 5| Step: 2
Training loss: 3.669245261145402
Validation loss: 3.6442829359586972

Epoch: 5| Step: 3
Training loss: 3.7561341025043413
Validation loss: 3.6397494353349766

Epoch: 5| Step: 4
Training loss: 3.8112777251539143
Validation loss: 3.635323475004865

Epoch: 5| Step: 5
Training loss: 4.170807548288269
Validation loss: 3.630913613474998

Epoch: 5| Step: 6
Training loss: 2.8826262457828236
Validation loss: 3.626032030150684

Epoch: 5| Step: 7
Training loss: 3.6474234174358715
Validation loss: 3.621975223228673

Epoch: 5| Step: 8
Training loss: 4.186868192920882
Validation loss: 3.617571355172642

Epoch: 5| Step: 9
Training loss: 3.9692244358785618
Validation loss: 3.6131761470320547

Epoch: 5| Step: 10
Training loss: 3.4268013665210915
Validation loss: 3.6087536875696373

Epoch: 5| Step: 11
Training loss: 3.2708873055898975
Validation loss: 3.6046429945931178

Epoch: 42| Step: 0
Training loss: 3.925376271477763
Validation loss: 3.600499441019933

Epoch: 5| Step: 1
Training loss: 3.7379314773181673
Validation loss: 3.596547594146992

Epoch: 5| Step: 2
Training loss: 4.397258485339433
Validation loss: 3.592369527630955

Epoch: 5| Step: 3
Training loss: 3.9546187522576695
Validation loss: 3.5883015006449277

Epoch: 5| Step: 4
Training loss: 4.124518395255118
Validation loss: 3.583779067032602

Epoch: 5| Step: 5
Training loss: 2.957377283770126
Validation loss: 3.579413302845919

Epoch: 5| Step: 6
Training loss: 4.198873986573895
Validation loss: 3.5756344296756066

Epoch: 5| Step: 7
Training loss: 3.357083696928206
Validation loss: 3.5711774884247185

Epoch: 5| Step: 8
Training loss: 3.4237970676090685
Validation loss: 3.5671970957135315

Epoch: 5| Step: 9
Training loss: 3.6095546661181506
Validation loss: 3.5627706770657035

Epoch: 5| Step: 10
Training loss: 2.9416134218002594
Validation loss: 3.558790813507235

Epoch: 5| Step: 11
Training loss: 3.531937118791357
Validation loss: 3.5548769945771532

Epoch: 43| Step: 0
Training loss: 3.4837977183468043
Validation loss: 3.550745466924188

Epoch: 5| Step: 1
Training loss: 4.448754451328247
Validation loss: 3.546565032500052

Epoch: 5| Step: 2
Training loss: 3.7807437778556148
Validation loss: 3.5428146726954863

Epoch: 5| Step: 3
Training loss: 3.593082001011278
Validation loss: 3.5385807430852356

Epoch: 5| Step: 4
Training loss: 3.8944881517173973
Validation loss: 3.534659351813169

Epoch: 5| Step: 5
Training loss: 3.57745248396459
Validation loss: 3.530318894188168

Epoch: 5| Step: 6
Training loss: 4.239528096407029
Validation loss: 3.5263234180405756

Epoch: 5| Step: 7
Training loss: 3.1794764943136578
Validation loss: 3.5221557654206066

Epoch: 5| Step: 8
Training loss: 3.068200391976493
Validation loss: 3.518280699056272

Epoch: 5| Step: 9
Training loss: 3.6243959120850833
Validation loss: 3.5143011468658503

Epoch: 5| Step: 10
Training loss: 3.4388627558879126
Validation loss: 3.510364153815416

Epoch: 5| Step: 11
Training loss: 2.5552617632109302
Validation loss: 3.506554534479698

Epoch: 44| Step: 0
Training loss: 4.283610340665824
Validation loss: 3.502567326045895

Epoch: 5| Step: 1
Training loss: 3.808144629969575
Validation loss: 3.498832854307169

Epoch: 5| Step: 2
Training loss: 3.0889811125449875
Validation loss: 3.4948208898164843

Epoch: 5| Step: 3
Training loss: 3.634055960535583
Validation loss: 3.491161039124764

Epoch: 5| Step: 4
Training loss: 3.974125503217006
Validation loss: 3.4874664870170755

Epoch: 5| Step: 5
Training loss: 3.1750931973933914
Validation loss: 3.4834829251932344

Epoch: 5| Step: 6
Training loss: 3.607210641572086
Validation loss: 3.4796361929998314

Epoch: 5| Step: 7
Training loss: 3.608396983888408
Validation loss: 3.4758438682045916

Epoch: 5| Step: 8
Training loss: 3.0858764642401466
Validation loss: 3.47188170713091

Epoch: 5| Step: 9
Training loss: 3.48304716391862
Validation loss: 3.4681016585297337

Epoch: 5| Step: 10
Training loss: 3.79882825052217
Validation loss: 3.464083442286288

Epoch: 5| Step: 11
Training loss: 4.130602413328723
Validation loss: 3.460281510826538

Epoch: 45| Step: 0
Training loss: 4.041770750193427
Validation loss: 3.45646153585041

Epoch: 5| Step: 1
Training loss: 3.59027090426553
Validation loss: 3.4526345090194104

Epoch: 5| Step: 2
Training loss: 2.911796936835944
Validation loss: 3.4489913410407302

Epoch: 5| Step: 3
Training loss: 3.626107145465438
Validation loss: 3.445166765678768

Epoch: 5| Step: 4
Training loss: 3.247400711573914
Validation loss: 3.4413789768992964

Epoch: 5| Step: 5
Training loss: 3.427510259099586
Validation loss: 3.437752870448777

Epoch: 5| Step: 6
Training loss: 4.072098879979473
Validation loss: 3.4341722333092033

Epoch: 5| Step: 7
Training loss: 2.8803268509406204
Validation loss: 3.430191825566718

Epoch: 5| Step: 8
Training loss: 3.6257235364013276
Validation loss: 3.426498778713663

Epoch: 5| Step: 9
Training loss: 3.831606780175035
Validation loss: 3.4226626588479436

Epoch: 5| Step: 10
Training loss: 3.4171036851718215
Validation loss: 3.4189291049922153

Epoch: 5| Step: 11
Training loss: 5.338008540135595
Validation loss: 3.414907122550295

Epoch: 46| Step: 0
Training loss: 3.707597438074606
Validation loss: 3.410625715301683

Epoch: 5| Step: 1
Training loss: 3.15340514436642
Validation loss: 3.4062918447554877

Epoch: 5| Step: 2
Training loss: 3.5084369333031797
Validation loss: 3.402275029279318

Epoch: 5| Step: 3
Training loss: 3.729113203691959
Validation loss: 3.3982494433757635

Epoch: 5| Step: 4
Training loss: 3.3756100138639002
Validation loss: 3.3940796312080637

Epoch: 5| Step: 5
Training loss: 3.525238050715013
Validation loss: 3.390350526989128

Epoch: 5| Step: 6
Training loss: 3.5593508805821705
Validation loss: 3.3862465775337447

Epoch: 5| Step: 7
Training loss: 3.8090237888225267
Validation loss: 3.382570324129369

Epoch: 5| Step: 8
Training loss: 3.5069406356203316
Validation loss: 3.378543318291943

Epoch: 5| Step: 9
Training loss: 3.086995930779299
Validation loss: 3.3745989266844765

Epoch: 5| Step: 10
Training loss: 3.6965001074988177
Validation loss: 3.3708259355316907

Epoch: 5| Step: 11
Training loss: 3.974344950510025
Validation loss: 3.3670571251077264

Epoch: 47| Step: 0
Training loss: 3.789882547576675
Validation loss: 3.3629426863304217

Epoch: 5| Step: 1
Training loss: 3.0841420805544733
Validation loss: 3.3589104501239238

Epoch: 5| Step: 2
Training loss: 3.322928656832469
Validation loss: 3.355080276756827

Epoch: 5| Step: 3
Training loss: 3.8604529724774475
Validation loss: 3.3513505123175693

Epoch: 5| Step: 4
Training loss: 3.5414727700207354
Validation loss: 3.3473115711677286

Epoch: 5| Step: 5
Training loss: 3.0759988790641497
Validation loss: 3.3435460679086715

Epoch: 5| Step: 6
Training loss: 3.5780511706868743
Validation loss: 3.3395527852343516

Epoch: 5| Step: 7
Training loss: 4.088808994503201
Validation loss: 3.3358189176854207

Epoch: 5| Step: 8
Training loss: 3.565833289091522
Validation loss: 3.33190628538922

Epoch: 5| Step: 9
Training loss: 3.1524263392410647
Validation loss: 3.3278701099581007

Epoch: 5| Step: 10
Training loss: 3.157180497895086
Validation loss: 3.3241013156156756

Epoch: 5| Step: 11
Training loss: 3.1910673636245055
Validation loss: 3.320592477999276

Epoch: 48| Step: 0
Training loss: 3.3742044712196435
Validation loss: 3.3169422892162825

Epoch: 5| Step: 1
Training loss: 2.8406576593282056
Validation loss: 3.3135083001495578

Epoch: 5| Step: 2
Training loss: 3.915760273587064
Validation loss: 3.3100927771025126

Epoch: 5| Step: 3
Training loss: 3.5774579488334153
Validation loss: 3.306752671102609

Epoch: 5| Step: 4
Training loss: 3.784989202728392
Validation loss: 3.3032393051671463

Epoch: 5| Step: 5
Training loss: 3.8550148245480655
Validation loss: 3.2996890817460134

Epoch: 5| Step: 6
Training loss: 3.521937962589503
Validation loss: 3.2964015156662385

Epoch: 5| Step: 7
Training loss: 2.8291335862875155
Validation loss: 3.2926568562000464

Epoch: 5| Step: 8
Training loss: 3.331158898344248
Validation loss: 3.2889022425664693

Epoch: 5| Step: 9
Training loss: 3.535285736578843
Validation loss: 3.285602120507332

Epoch: 5| Step: 10
Training loss: 3.053614279080656
Validation loss: 3.2819287309599137

Epoch: 5| Step: 11
Training loss: 3.4897922434356676
Validation loss: 3.2785154391965583

Epoch: 49| Step: 0
Training loss: 3.4339371684152193
Validation loss: 3.2751521715817886

Epoch: 5| Step: 1
Training loss: 3.052191844135254
Validation loss: 3.271833744657333

Epoch: 5| Step: 2
Training loss: 3.9451730231379103
Validation loss: 3.268695154696386

Epoch: 5| Step: 3
Training loss: 3.469530997118461
Validation loss: 3.265265997176664

Epoch: 5| Step: 4
Training loss: 3.907516640342772
Validation loss: 3.261801630668904

Epoch: 5| Step: 5
Training loss: 3.432437289693821
Validation loss: 3.258220772046961

Epoch: 5| Step: 6
Training loss: 3.037487730150598
Validation loss: 3.2546343162514537

Epoch: 5| Step: 7
Training loss: 2.8725110766111777
Validation loss: 3.251294196255118

Epoch: 5| Step: 8
Training loss: 3.039851304483353
Validation loss: 3.2478634401519018

Epoch: 5| Step: 9
Training loss: 3.8455649952180355
Validation loss: 3.2444917755579232

Epoch: 5| Step: 10
Training loss: 3.2030737896058774
Validation loss: 3.241490729656121

Epoch: 5| Step: 11
Training loss: 3.0926937265244976
Validation loss: 3.237876130498584

Epoch: 50| Step: 0
Training loss: 3.1210619718344668
Validation loss: 3.2347685348742723

Epoch: 5| Step: 1
Training loss: 3.384499778807288
Validation loss: 3.231213358899461

Epoch: 5| Step: 2
Training loss: 3.36753783206886
Validation loss: 3.2278738982186885

Epoch: 5| Step: 3
Training loss: 3.1150009402645646
Validation loss: 3.224763912361864

Epoch: 5| Step: 4
Training loss: 3.8844619409800956
Validation loss: 3.221425484577368

Epoch: 5| Step: 5
Training loss: 3.7575310425227975
Validation loss: 3.217975060219909

Epoch: 5| Step: 6
Training loss: 3.2813613146111122
Validation loss: 3.2146130120190257

Epoch: 5| Step: 7
Training loss: 3.3897374832999203
Validation loss: 3.2108898855424104

Epoch: 5| Step: 8
Training loss: 2.5594031997263604
Validation loss: 3.207530368092287

Epoch: 5| Step: 9
Training loss: 3.3367444386852103
Validation loss: 3.2044022719461096

Epoch: 5| Step: 10
Training loss: 3.571834048005548
Validation loss: 3.2011819699283213

Epoch: 5| Step: 11
Training loss: 3.4122016077617277
Validation loss: 3.1979844814072718

Epoch: 51| Step: 0
Training loss: 3.2970657655024627
Validation loss: 3.1951627066647417

Epoch: 5| Step: 1
Training loss: 3.3555963600771017
Validation loss: 3.191973342844549

Epoch: 5| Step: 2
Training loss: 3.6983837566975386
Validation loss: 3.188988581113327

Epoch: 5| Step: 3
Training loss: 3.398864859533845
Validation loss: 3.185727499264047

Epoch: 5| Step: 4
Training loss: 3.637778810912508
Validation loss: 3.182753419647685

Epoch: 5| Step: 5
Training loss: 3.2167734540168933
Validation loss: 3.1794623342859443

Epoch: 5| Step: 6
Training loss: 2.764583930499643
Validation loss: 3.176161001600705

Epoch: 5| Step: 7
Training loss: 3.66566233896424
Validation loss: 3.1729950391508415

Epoch: 5| Step: 8
Training loss: 3.575103416814396
Validation loss: 3.169942323403677

Epoch: 5| Step: 9
Training loss: 3.1856128865880424
Validation loss: 3.1668500387069938

Epoch: 5| Step: 10
Training loss: 2.735495463096107
Validation loss: 3.163660546661793

Epoch: 5| Step: 11
Training loss: 2.4596585295711852
Validation loss: 3.160734930758701

Epoch: 52| Step: 0
Training loss: 3.190847695823844
Validation loss: 3.1578800159593645

Epoch: 5| Step: 1
Training loss: 3.482904098079776
Validation loss: 3.155110235233061

Epoch: 5| Step: 2
Training loss: 3.229848301635033
Validation loss: 3.1524954014461497

Epoch: 5| Step: 3
Training loss: 3.4046211197690184
Validation loss: 3.1494064733132885

Epoch: 5| Step: 4
Training loss: 3.518473916207941
Validation loss: 3.1462355992297435

Epoch: 5| Step: 5
Training loss: 3.4981818245011946
Validation loss: 3.1435533855175217

Epoch: 5| Step: 6
Training loss: 2.760053982690506
Validation loss: 3.1401879748289327

Epoch: 5| Step: 7
Training loss: 3.259049507778738
Validation loss: 3.1371051175080646

Epoch: 5| Step: 8
Training loss: 3.533143202746427
Validation loss: 3.134270538815549

Epoch: 5| Step: 9
Training loss: 2.9545212124450213
Validation loss: 3.1312227472577443

Epoch: 5| Step: 10
Training loss: 3.028793440698936
Validation loss: 3.128630639874369

Epoch: 5| Step: 11
Training loss: 4.128802309920432
Validation loss: 3.1258542609846893

Epoch: 53| Step: 0
Training loss: 4.040409534961163
Validation loss: 3.1228805634488066

Epoch: 5| Step: 1
Training loss: 3.5465850039332922
Validation loss: 3.119883411228163

Epoch: 5| Step: 2
Training loss: 3.3966024421058227
Validation loss: 3.1167523774347847

Epoch: 5| Step: 3
Training loss: 2.5953339485692295
Validation loss: 3.113449060248281

Epoch: 5| Step: 4
Training loss: 3.045469458710428
Validation loss: 3.1106406979237886

Epoch: 5| Step: 5
Training loss: 3.144560819688222
Validation loss: 3.107721985191997

Epoch: 5| Step: 6
Training loss: 3.074115290954866
Validation loss: 3.1048943906137327

Epoch: 5| Step: 7
Training loss: 2.969705528277613
Validation loss: 3.102075619215092

Epoch: 5| Step: 8
Training loss: 3.727786201117585
Validation loss: 3.099605304704929

Epoch: 5| Step: 9
Training loss: 3.363413809225294
Validation loss: 3.0965311220690026

Epoch: 5| Step: 10
Training loss: 2.485215242915467
Validation loss: 3.0936486712472417

Epoch: 5| Step: 11
Training loss: 3.4778636083550363
Validation loss: 3.090988233362882

Epoch: 54| Step: 0
Training loss: 3.4667989381595974
Validation loss: 3.088271205868718

Epoch: 5| Step: 1
Training loss: 3.1227650088758168
Validation loss: 3.085556521820984

Epoch: 5| Step: 2
Training loss: 3.3178322537852654
Validation loss: 3.082769552873596

Epoch: 5| Step: 3
Training loss: 2.6670376003090777
Validation loss: 3.0799297812278876

Epoch: 5| Step: 4
Training loss: 2.2774031093183225
Validation loss: 3.0776065318770502

Epoch: 5| Step: 5
Training loss: 3.8025282229367434
Validation loss: 3.0754785795913433

Epoch: 5| Step: 6
Training loss: 3.3345359699038366
Validation loss: 3.073115935033928

Epoch: 5| Step: 7
Training loss: 3.1892213848182185
Validation loss: 3.0705469153608806

Epoch: 5| Step: 8
Training loss: 3.1364718633381234
Validation loss: 3.068057807268965

Epoch: 5| Step: 9
Training loss: 3.4152778190773785
Validation loss: 3.065127977372181

Epoch: 5| Step: 10
Training loss: 3.155743548863153
Validation loss: 3.0626239751517716

Epoch: 5| Step: 11
Training loss: 4.225510443376052
Validation loss: 3.0597582208517946

Epoch: 55| Step: 0
Training loss: 3.2766802255913303
Validation loss: 3.0568084313234016

Epoch: 5| Step: 1
Training loss: 2.947042023182121
Validation loss: 3.0540736232825507

Epoch: 5| Step: 2
Training loss: 3.4249849862096795
Validation loss: 3.051263742557903

Epoch: 5| Step: 3
Training loss: 3.0589629007754104
Validation loss: 3.0484149692836184

Epoch: 5| Step: 4
Training loss: 3.4705840065113596
Validation loss: 3.0461914143376685

Epoch: 5| Step: 5
Training loss: 3.0481802467656767
Validation loss: 3.043622352748616

Epoch: 5| Step: 6
Training loss: 2.7072348690105055
Validation loss: 3.0409134864192193

Epoch: 5| Step: 7
Training loss: 2.999147611958343
Validation loss: 3.038432741659377

Epoch: 5| Step: 8
Training loss: 3.709451542541021
Validation loss: 3.0356601311557556

Epoch: 5| Step: 9
Training loss: 3.1439250859369863
Validation loss: 3.0330961543845087

Epoch: 5| Step: 10
Training loss: 3.1274159057435194
Validation loss: 3.0302734997874614

Epoch: 5| Step: 11
Training loss: 3.1763347973814335
Validation loss: 3.027731380461986

Epoch: 56| Step: 0
Training loss: 2.7331023824241383
Validation loss: 3.0248956999912324

Epoch: 5| Step: 1
Training loss: 3.175735304383969
Validation loss: 3.022419185483573

Epoch: 5| Step: 2
Training loss: 3.314195307076405
Validation loss: 3.019476090191

Epoch: 5| Step: 3
Training loss: 3.6433248700470857
Validation loss: 3.016967971825418

Epoch: 5| Step: 4
Training loss: 2.7781102320618625
Validation loss: 3.0139578458824685

Epoch: 5| Step: 5
Training loss: 2.7630973515295367
Validation loss: 3.0119381868777317

Epoch: 5| Step: 6
Training loss: 3.5075762356924383
Validation loss: 3.0097217329696058

Epoch: 5| Step: 7
Training loss: 3.168429001419494
Validation loss: 3.0071396871988445

Epoch: 5| Step: 8
Training loss: 3.042897136663342
Validation loss: 3.004677351525979

Epoch: 5| Step: 9
Training loss: 3.123000153555303
Validation loss: 3.0014838383627302

Epoch: 5| Step: 10
Training loss: 3.436626531426408
Validation loss: 2.998895898937352

Epoch: 5| Step: 11
Training loss: 2.357240835853505
Validation loss: 2.9963719828567927

Epoch: 57| Step: 0
Training loss: 2.6453161159610086
Validation loss: 2.9938662561502336

Epoch: 5| Step: 1
Training loss: 2.4066711651697497
Validation loss: 2.9914888607163963

Epoch: 5| Step: 2
Training loss: 3.0877405235102486
Validation loss: 2.9897804837676394

Epoch: 5| Step: 3
Training loss: 3.1948698525344956
Validation loss: 2.9874653219660385

Epoch: 5| Step: 4
Training loss: 3.411059702328102
Validation loss: 2.9858430111219234

Epoch: 5| Step: 5
Training loss: 3.490874929197732
Validation loss: 2.9831219783873952

Epoch: 5| Step: 6
Training loss: 2.9859712336304995
Validation loss: 2.9809102022708913

Epoch: 5| Step: 7
Training loss: 3.3672832289538905
Validation loss: 2.9784983216497047

Epoch: 5| Step: 8
Training loss: 2.9421053558405625
Validation loss: 2.976432483733778

Epoch: 5| Step: 9
Training loss: 3.32118138332504
Validation loss: 2.973823622254143

Epoch: 5| Step: 10
Training loss: 3.463018820552592
Validation loss: 2.9713847264360185

Epoch: 5| Step: 11
Training loss: 2.29632675997832
Validation loss: 2.968892682980074

Epoch: 58| Step: 0
Training loss: 2.9377025777887855
Validation loss: 2.966794095802973

Epoch: 5| Step: 1
Training loss: 2.8046842697252465
Validation loss: 2.9646353097587257

Epoch: 5| Step: 2
Training loss: 3.5495603369735003
Validation loss: 2.961880851514974

Epoch: 5| Step: 3
Training loss: 2.99755600877729
Validation loss: 2.9605664546654817

Epoch: 5| Step: 4
Training loss: 3.1610981182448903
Validation loss: 2.9604324742180843

Epoch: 5| Step: 5
Training loss: 3.07203234000866
Validation loss: 2.9570430350562233

Epoch: 5| Step: 6
Training loss: 3.2449019134227117
Validation loss: 2.9541589787055424

Epoch: 5| Step: 7
Training loss: 2.907649369867911
Validation loss: 2.951831759840759

Epoch: 5| Step: 8
Training loss: 3.301153796237548
Validation loss: 2.9500293148329937

Epoch: 5| Step: 9
Training loss: 2.7772925005984903
Validation loss: 2.9478459748507704

Epoch: 5| Step: 10
Training loss: 3.0826644343738767
Validation loss: 2.9475939588640405

Epoch: 5| Step: 11
Training loss: 3.8278961736057786
Validation loss: 2.948808728277795

Epoch: 59| Step: 0
Training loss: 3.323351665154201
Validation loss: 2.9430252388424867

Epoch: 5| Step: 1
Training loss: 3.193499286164765
Validation loss: 2.940810266023967

Epoch: 5| Step: 2
Training loss: 2.894926263005209
Validation loss: 2.9389674261744827

Epoch: 5| Step: 3
Training loss: 3.453536755622636
Validation loss: 2.938455487141157

Epoch: 5| Step: 4
Training loss: 3.0228371825088445
Validation loss: 2.9377641085672033

Epoch: 5| Step: 5
Training loss: 2.9831388619686474
Validation loss: 2.9341245290440328

Epoch: 5| Step: 6
Training loss: 3.2853392777956816
Validation loss: 2.930638839543649

Epoch: 5| Step: 7
Training loss: 2.8120130329291295
Validation loss: 2.9272909170011383

Epoch: 5| Step: 8
Training loss: 2.7777604060159655
Validation loss: 2.9248145169627366

Epoch: 5| Step: 9
Training loss: 3.3408124623099087
Validation loss: 2.9234433750220643

Epoch: 5| Step: 10
Training loss: 2.7422623583365366
Validation loss: 2.92081393731099

Epoch: 5| Step: 11
Training loss: 2.5692591030415777
Validation loss: 2.9181096401696833

Epoch: 60| Step: 0
Training loss: 3.1389658326777408
Validation loss: 2.9163083685189624

Epoch: 5| Step: 1
Training loss: 2.9600221532559705
Validation loss: 2.91423874118403

Epoch: 5| Step: 2
Training loss: 3.1323208316062163
Validation loss: 2.911838316759022

Epoch: 5| Step: 3
Training loss: 3.2664916426293193
Validation loss: 2.9100899469046606

Epoch: 5| Step: 4
Training loss: 2.8260637221768725
Validation loss: 2.907765243012349

Epoch: 5| Step: 5
Training loss: 3.2333569974787086
Validation loss: 2.90523632378474

Epoch: 5| Step: 6
Training loss: 2.9507915016907234
Validation loss: 2.9026475921034645

Epoch: 5| Step: 7
Training loss: 3.357152727222717
Validation loss: 2.900926311443537

Epoch: 5| Step: 8
Training loss: 2.9328361985839932
Validation loss: 2.898750648136568

Epoch: 5| Step: 9
Training loss: 3.218307168367908
Validation loss: 2.897098873065113

Epoch: 5| Step: 10
Training loss: 2.4325945472965413
Validation loss: 2.895360072088728

Epoch: 5| Step: 11
Training loss: 2.9874995786275527
Validation loss: 2.895033147201564

Epoch: 61| Step: 0
Training loss: 2.818055240243997
Validation loss: 2.8925552487461497

Epoch: 5| Step: 1
Training loss: 2.825061213412479
Validation loss: 2.889334038118078

Epoch: 5| Step: 2
Training loss: 2.7706228668665918
Validation loss: 2.888002656421382

Epoch: 5| Step: 3
Training loss: 3.2703773196850467
Validation loss: 2.8856598628780845

Epoch: 5| Step: 4
Training loss: 3.247749429686999
Validation loss: 2.883715952355445

Epoch: 5| Step: 5
Training loss: 3.4005401070137635
Validation loss: 2.8814042570701175

Epoch: 5| Step: 6
Training loss: 3.2181973769953585
Validation loss: 2.880017739325215

Epoch: 5| Step: 7
Training loss: 2.550280488239493
Validation loss: 2.878615403893081

Epoch: 5| Step: 8
Training loss: 2.6792630674145497
Validation loss: 2.8769422135121347

Epoch: 5| Step: 9
Training loss: 3.1448175335519766
Validation loss: 2.8747468643425713

Epoch: 5| Step: 10
Training loss: 3.0371878757941686
Validation loss: 2.873424008233882

Epoch: 5| Step: 11
Training loss: 3.7952437801743577
Validation loss: 2.8714420998238124

Epoch: 62| Step: 0
Training loss: 2.7532459522571906
Validation loss: 2.869414491092945

Epoch: 5| Step: 1
Training loss: 2.9461981051588007
Validation loss: 2.8672485206478897

Epoch: 5| Step: 2
Training loss: 3.1528108196422324
Validation loss: 2.8649875228559107

Epoch: 5| Step: 3
Training loss: 3.2489302415154127
Validation loss: 2.8634036403587038

Epoch: 5| Step: 4
Training loss: 2.912852345384287
Validation loss: 2.861145093529828

Epoch: 5| Step: 5
Training loss: 3.0126332676957945
Validation loss: 2.859082007205911

Epoch: 5| Step: 6
Training loss: 2.795210103035384
Validation loss: 2.856674576386355

Epoch: 5| Step: 7
Training loss: 2.9182293838064255
Validation loss: 2.854988019409251

Epoch: 5| Step: 8
Training loss: 2.927805059290997
Validation loss: 2.8530776923478616

Epoch: 5| Step: 9
Training loss: 3.257398254257655
Validation loss: 2.851674123869851

Epoch: 5| Step: 10
Training loss: 3.1500772981393537
Validation loss: 2.8488586601288746

Epoch: 5| Step: 11
Training loss: 2.4064006015168107
Validation loss: 2.8467032150770692

Epoch: 63| Step: 0
Training loss: 2.9385335199801403
Validation loss: 2.8449824670207793

Epoch: 5| Step: 1
Training loss: 3.2484869736229283
Validation loss: 2.8427346970698664

Epoch: 5| Step: 2
Training loss: 2.734145672582009
Validation loss: 2.841084761390047

Epoch: 5| Step: 3
Training loss: 2.8635914882980478
Validation loss: 2.8397346171276365

Epoch: 5| Step: 4
Training loss: 3.124707017515802
Validation loss: 2.837710884844959

Epoch: 5| Step: 5
Training loss: 3.0799942150309345
Validation loss: 2.83665394206019

Epoch: 5| Step: 6
Training loss: 3.4314068978991976
Validation loss: 2.8327881952454024

Epoch: 5| Step: 7
Training loss: 2.7580490227008463
Validation loss: 2.830857848067916

Epoch: 5| Step: 8
Training loss: 2.9615605083868246
Validation loss: 2.8297087799344975

Epoch: 5| Step: 9
Training loss: 2.845106199726071
Validation loss: 2.827659403515041

Epoch: 5| Step: 10
Training loss: 2.8937888486820933
Validation loss: 2.8255643967230855

Epoch: 5| Step: 11
Training loss: 1.8150239011803893
Validation loss: 2.82619121819946

Epoch: 64| Step: 0
Training loss: 2.8630807345802545
Validation loss: 2.8250006916247847

Epoch: 5| Step: 1
Training loss: 2.904282262646075
Validation loss: 2.8227220388418495

Epoch: 5| Step: 2
Training loss: 3.38730103306072
Validation loss: 2.8205684957797468

Epoch: 5| Step: 3
Training loss: 3.5099510691565965
Validation loss: 2.8173309197982683

Epoch: 5| Step: 4
Training loss: 2.8257162890825964
Validation loss: 2.814357155004792

Epoch: 5| Step: 5
Training loss: 2.7939544432249876
Validation loss: 2.8135187776367268

Epoch: 5| Step: 6
Training loss: 3.0289204878296556
Validation loss: 2.8128286911373714

Epoch: 5| Step: 7
Training loss: 1.9983519678251855
Validation loss: 2.812321968095286

Epoch: 5| Step: 8
Training loss: 3.32017534758092
Validation loss: 2.8094010304852897

Epoch: 5| Step: 9
Training loss: 2.8091885887821326
Validation loss: 2.808670934218738

Epoch: 5| Step: 10
Training loss: 2.881395937850121
Validation loss: 2.8077292493487542

Epoch: 5| Step: 11
Training loss: 2.584481373896005
Validation loss: 2.8062149287795615

Epoch: 65| Step: 0
Training loss: 3.3713401448012097
Validation loss: 2.8036695738827877

Epoch: 5| Step: 1
Training loss: 2.648534902396309
Validation loss: 2.8028392652496197

Epoch: 5| Step: 2
Training loss: 2.7023940669214266
Validation loss: 2.801826360091562

Epoch: 5| Step: 3
Training loss: 2.6696322660058374
Validation loss: 2.8009715137560764

Epoch: 5| Step: 4
Training loss: 2.8125565417222322
Validation loss: 2.798381083800339

Epoch: 5| Step: 5
Training loss: 2.884418319426444
Validation loss: 2.7973627201540756

Epoch: 5| Step: 6
Training loss: 3.0957924622361688
Validation loss: 2.793773142258661

Epoch: 5| Step: 7
Training loss: 2.6929334673051755
Validation loss: 2.7931186200104112

Epoch: 5| Step: 8
Training loss: 2.868672913822526
Validation loss: 2.7908540131228077

Epoch: 5| Step: 9
Training loss: 3.1318427889599985
Validation loss: 2.790670745093061

Epoch: 5| Step: 10
Training loss: 3.3595534166375036
Validation loss: 2.788175418662693

Epoch: 5| Step: 11
Training loss: 2.8302856958903155
Validation loss: 2.785983165738258

Epoch: 66| Step: 0
Training loss: 3.0822449043201483
Validation loss: 2.7850390530432905

Epoch: 5| Step: 1
Training loss: 2.995299630692147
Validation loss: 2.784103801062843

Epoch: 5| Step: 2
Training loss: 2.883505471737828
Validation loss: 2.782401435902298

Epoch: 5| Step: 3
Training loss: 3.133948065604354
Validation loss: 2.7817096223270554

Epoch: 5| Step: 4
Training loss: 2.8729867935381685
Validation loss: 2.7803048231566208

Epoch: 5| Step: 5
Training loss: 2.3970510843345463
Validation loss: 2.778010978976389

Epoch: 5| Step: 6
Training loss: 2.878386286204453
Validation loss: 2.77624723640704

Epoch: 5| Step: 7
Training loss: 3.01487730570533
Validation loss: 2.77454280767153

Epoch: 5| Step: 8
Training loss: 2.9369853766093206
Validation loss: 2.7726878912768322

Epoch: 5| Step: 9
Training loss: 2.856406082796854
Validation loss: 2.7722212941043534

Epoch: 5| Step: 10
Training loss: 3.218453402881352
Validation loss: 2.77162358599948

Epoch: 5| Step: 11
Training loss: 1.5180448111553022
Validation loss: 2.770051710888985

Epoch: 67| Step: 0
Training loss: 2.619581715922228
Validation loss: 2.7692185240152845

Epoch: 5| Step: 1
Training loss: 2.876292891665419
Validation loss: 2.766889451911684

Epoch: 5| Step: 2
Training loss: 2.973503884212407
Validation loss: 2.7662147532540473

Epoch: 5| Step: 3
Training loss: 3.03406009002505
Validation loss: 2.7663172162694205

Epoch: 5| Step: 4
Training loss: 3.261916834133006
Validation loss: 2.7644071070529814

Epoch: 5| Step: 5
Training loss: 2.816207984580427
Validation loss: 2.762992388944099

Epoch: 5| Step: 6
Training loss: 2.481874178922542
Validation loss: 2.7623319471171723

Epoch: 5| Step: 7
Training loss: 2.8362260151534473
Validation loss: 2.759189010031547

Epoch: 5| Step: 8
Training loss: 3.1372153529194104
Validation loss: 2.75886334074508

Epoch: 5| Step: 9
Training loss: 3.1430023457065994
Validation loss: 2.7585207144159027

Epoch: 5| Step: 10
Training loss: 2.7893439826719497
Validation loss: 2.756947296124021

Epoch: 5| Step: 11
Training loss: 2.3136713309080483
Validation loss: 2.7555429271076206

Epoch: 68| Step: 0
Training loss: 3.3338469268588313
Validation loss: 2.7544795312126142

Epoch: 5| Step: 1
Training loss: 3.1876207216626855
Validation loss: 2.7520191553811313

Epoch: 5| Step: 2
Training loss: 2.4464050387303797
Validation loss: 2.7519027564567784

Epoch: 5| Step: 3
Training loss: 2.6669045779275637
Validation loss: 2.749335971048538

Epoch: 5| Step: 4
Training loss: 3.0379434206969615
Validation loss: 2.7480521528513715

Epoch: 5| Step: 5
Training loss: 2.939269811040614
Validation loss: 2.7467133793824567

Epoch: 5| Step: 6
Training loss: 2.5090536213417334
Validation loss: 2.7449253575715633

Epoch: 5| Step: 7
Training loss: 3.0141987170124747
Validation loss: 2.742748652295973

Epoch: 5| Step: 8
Training loss: 2.9019226343738236
Validation loss: 2.740843328423126

Epoch: 5| Step: 9
Training loss: 2.8956169944107444
Validation loss: 2.740998143334301

Epoch: 5| Step: 10
Training loss: 2.776620676851211
Validation loss: 2.7396101291540256

Epoch: 5| Step: 11
Training loss: 2.5350781915106197
Validation loss: 2.7379026636479527

Epoch: 69| Step: 0
Training loss: 2.726313451197365
Validation loss: 2.741071135087646

Epoch: 5| Step: 1
Training loss: 2.907731201740826
Validation loss: 2.746255999167755

Epoch: 5| Step: 2
Training loss: 2.4408227818413932
Validation loss: 2.7505828030340016

Epoch: 5| Step: 3
Training loss: 3.1128071767445356
Validation loss: 2.7450861486351386

Epoch: 5| Step: 4
Training loss: 3.4050250169280347
Validation loss: 2.7381660302954156

Epoch: 5| Step: 5
Training loss: 2.3625444761257643
Validation loss: 2.7307355874962447

Epoch: 5| Step: 6
Training loss: 2.8996193011099973
Validation loss: 2.727094578313022

Epoch: 5| Step: 7
Training loss: 2.987576510036239
Validation loss: 2.726622248362029

Epoch: 5| Step: 8
Training loss: 2.929608560134407
Validation loss: 2.7273338050336795

Epoch: 5| Step: 9
Training loss: 2.895897752516443
Validation loss: 2.727969658162468

Epoch: 5| Step: 10
Training loss: 3.0067931194174427
Validation loss: 2.728872328215318

Epoch: 5| Step: 11
Training loss: 1.7478441174091002
Validation loss: 2.7283723976082177

Epoch: 70| Step: 0
Training loss: 2.88124567060497
Validation loss: 2.7252071622677776

Epoch: 5| Step: 1
Training loss: 3.1989155720012357
Validation loss: 2.7212386999624285

Epoch: 5| Step: 2
Training loss: 2.499660278126306
Validation loss: 2.719949928850127

Epoch: 5| Step: 3
Training loss: 2.7629353866284303
Validation loss: 2.7199533145418227

Epoch: 5| Step: 4
Training loss: 3.0182919741204692
Validation loss: 2.714912058750759

Epoch: 5| Step: 5
Training loss: 2.4920415088141756
Validation loss: 2.715230790685912

Epoch: 5| Step: 6
Training loss: 3.2334268995557185
Validation loss: 2.717644784714894

Epoch: 5| Step: 7
Training loss: 3.051311061049689
Validation loss: 2.7128560938513027

Epoch: 5| Step: 8
Training loss: 3.1479475146502485
Validation loss: 2.7115250646054205

Epoch: 5| Step: 9
Training loss: 2.4317858304097606
Validation loss: 2.7114956305966493

Epoch: 5| Step: 10
Training loss: 2.6650238539896756
Validation loss: 2.7098939996190525

Epoch: 5| Step: 11
Training loss: 2.3639528439461053
Validation loss: 2.710656821225608

Epoch: 71| Step: 0
Training loss: 2.9835315730829812
Validation loss: 2.7137119266645318

Epoch: 5| Step: 1
Training loss: 2.985696549926772
Validation loss: 2.7131586896750703

Epoch: 5| Step: 2
Training loss: 3.1073135366681512
Validation loss: 2.721481328788868

Epoch: 5| Step: 3
Training loss: 2.985779277096773
Validation loss: 2.7157522332689923

Epoch: 5| Step: 4
Training loss: 2.904790368190084
Validation loss: 2.7116686762966626

Epoch: 5| Step: 5
Training loss: 2.569802369857124
Validation loss: 2.7068982607719114

Epoch: 5| Step: 6
Training loss: 2.9059398854831793
Validation loss: 2.7094149899345594

Epoch: 5| Step: 7
Training loss: 2.9630338549963433
Validation loss: 2.71051785082024

Epoch: 5| Step: 8
Training loss: 2.6575104359577066
Validation loss: 2.7113133443863604

Epoch: 5| Step: 9
Training loss: 2.7682137307962504
Validation loss: 2.7138854057411566

Epoch: 5| Step: 10
Training loss: 2.6684522511822464
Validation loss: 2.714990643888526

Epoch: 5| Step: 11
Training loss: 1.956338542847883
Validation loss: 2.7028856594137367

Epoch: 72| Step: 0
Training loss: 2.873887385817312
Validation loss: 2.6985418682755546

Epoch: 5| Step: 1
Training loss: 2.4219233354236622
Validation loss: 2.694918978799625

Epoch: 5| Step: 2
Training loss: 2.8354375729618124
Validation loss: 2.6984298112498712

Epoch: 5| Step: 3
Training loss: 2.9285705878758304
Validation loss: 2.7017235402900965

Epoch: 5| Step: 4
Training loss: 2.4513494784387424
Validation loss: 2.701302514878665

Epoch: 5| Step: 5
Training loss: 2.6454348126348513
Validation loss: 2.6931210403903134

Epoch: 5| Step: 6
Training loss: 2.9374879877372413
Validation loss: 2.691176376528745

Epoch: 5| Step: 7
Training loss: 2.9611866224663603
Validation loss: 2.691198081652509

Epoch: 5| Step: 8
Training loss: 3.1406374499325684
Validation loss: 2.6864916735904116

Epoch: 5| Step: 9
Training loss: 2.625115800755599
Validation loss: 2.6871668808766302

Epoch: 5| Step: 10
Training loss: 3.2158115640539218
Validation loss: 2.6876019968594016

Epoch: 5| Step: 11
Training loss: 2.860943473505506
Validation loss: 2.6852373349367844

Epoch: 73| Step: 0
Training loss: 2.452396843594629
Validation loss: 2.6832154408515314

Epoch: 5| Step: 1
Training loss: 3.04434521630194
Validation loss: 2.6820137410787357

Epoch: 5| Step: 2
Training loss: 3.0699120956907797
Validation loss: 2.6802119751090197

Epoch: 5| Step: 3
Training loss: 2.782325279597412
Validation loss: 2.6785774304307575

Epoch: 5| Step: 4
Training loss: 3.1355092150103068
Validation loss: 2.6774808289227128

Epoch: 5| Step: 5
Training loss: 2.505757663532783
Validation loss: 2.6775565168326754

Epoch: 5| Step: 6
Training loss: 2.4353046801566474
Validation loss: 2.6754455912765738

Epoch: 5| Step: 7
Training loss: 3.143718202100231
Validation loss: 2.674708345741048

Epoch: 5| Step: 8
Training loss: 2.664339560143948
Validation loss: 2.674484486313048

Epoch: 5| Step: 9
Training loss: 3.1028226123083718
Validation loss: 2.672544373214367

Epoch: 5| Step: 10
Training loss: 2.576578034492332
Validation loss: 2.672824300585846

Epoch: 5| Step: 11
Training loss: 2.4244794070485804
Validation loss: 2.6699704749728728

Epoch: 74| Step: 0
Training loss: 2.2233025494474195
Validation loss: 2.6735642058866764

Epoch: 5| Step: 1
Training loss: 3.034092779421985
Validation loss: 2.6746885458540866

Epoch: 5| Step: 2
Training loss: 2.7691166275497783
Validation loss: 2.677009074347621

Epoch: 5| Step: 3
Training loss: 2.506791046418275
Validation loss: 2.6695841361919315

Epoch: 5| Step: 4
Training loss: 3.188383241838782
Validation loss: 2.66476058390301

Epoch: 5| Step: 5
Training loss: 2.8145882377515896
Validation loss: 2.6662201743552396

Epoch: 5| Step: 6
Training loss: 2.904358935639045
Validation loss: 2.662305235567079

Epoch: 5| Step: 7
Training loss: 2.708160297050203
Validation loss: 2.662921146432229

Epoch: 5| Step: 8
Training loss: 2.4840250788480764
Validation loss: 2.66182840664634

Epoch: 5| Step: 9
Training loss: 2.8102105040797194
Validation loss: 2.660781376115664

Epoch: 5| Step: 10
Training loss: 3.3028807695046267
Validation loss: 2.6618577330244895

Epoch: 5| Step: 11
Training loss: 2.3833412459271024
Validation loss: 2.659460954364093

Epoch: 75| Step: 0
Training loss: 2.9435816366397076
Validation loss: 2.6607573619414397

Epoch: 5| Step: 1
Training loss: 2.7597397940061916
Validation loss: 2.657254081638719

Epoch: 5| Step: 2
Training loss: 2.6366845700909622
Validation loss: 2.6580758271018126

Epoch: 5| Step: 3
Training loss: 3.1079472469924405
Validation loss: 2.6580580186630365

Epoch: 5| Step: 4
Training loss: 3.044400976231145
Validation loss: 2.6562338473258973

Epoch: 5| Step: 5
Training loss: 2.4923673463223017
Validation loss: 2.6554278541252256

Epoch: 5| Step: 6
Training loss: 2.2104261905657943
Validation loss: 2.654343755035304

Epoch: 5| Step: 7
Training loss: 2.5091233674815965
Validation loss: 2.652999774327504

Epoch: 5| Step: 8
Training loss: 3.0117923712730748
Validation loss: 2.652215728891208

Epoch: 5| Step: 9
Training loss: 3.0339433168511443
Validation loss: 2.652382334904646

Epoch: 5| Step: 10
Training loss: 2.9261414085944
Validation loss: 2.651172362417882

Epoch: 5| Step: 11
Training loss: 2.347743383431375
Validation loss: 2.6488643141029895

Epoch: 76| Step: 0
Training loss: 2.854094752684256
Validation loss: 2.650222248228484

Epoch: 5| Step: 1
Training loss: 2.8760980913945273
Validation loss: 2.6489219147497223

Epoch: 5| Step: 2
Training loss: 3.038917832253206
Validation loss: 2.6470324297209307

Epoch: 5| Step: 3
Training loss: 2.67221834530971
Validation loss: 2.6455794285172365

Epoch: 5| Step: 4
Training loss: 2.918648800126772
Validation loss: 2.6442679082045206

Epoch: 5| Step: 5
Training loss: 2.7238226735826254
Validation loss: 2.645718911217405

Epoch: 5| Step: 6
Training loss: 3.104326913951571
Validation loss: 2.644790490205154

Epoch: 5| Step: 7
Training loss: 2.284029273552033
Validation loss: 2.644354577222698

Epoch: 5| Step: 8
Training loss: 2.962398923284349
Validation loss: 2.6467696220321812

Epoch: 5| Step: 9
Training loss: 3.056540627108296
Validation loss: 2.6452566642298736

Epoch: 5| Step: 10
Training loss: 2.309501972760062
Validation loss: 2.648902765927041

Epoch: 5| Step: 11
Training loss: 0.672771521072037
Validation loss: 2.6415670358560304

Epoch: 77| Step: 0
Training loss: 2.765436888078591
Validation loss: 2.6398075614195573

Epoch: 5| Step: 1
Training loss: 2.784730512226689
Validation loss: 2.638855207518298

Epoch: 5| Step: 2
Training loss: 2.9188716364802723
Validation loss: 2.6365563764143465

Epoch: 5| Step: 3
Training loss: 2.4239936667570463
Validation loss: 2.6372085436617883

Epoch: 5| Step: 4
Training loss: 2.58349521703999
Validation loss: 2.6368564522660454

Epoch: 5| Step: 5
Training loss: 3.1273334183761703
Validation loss: 2.635080524664293

Epoch: 5| Step: 6
Training loss: 2.762088648346476
Validation loss: 2.6363773153138528

Epoch: 5| Step: 7
Training loss: 2.9421398772823695
Validation loss: 2.6335765322417863

Epoch: 5| Step: 8
Training loss: 2.6239082245826957
Validation loss: 2.6334877544306923

Epoch: 5| Step: 9
Training loss: 2.8285651944519747
Validation loss: 2.6317799672513646

Epoch: 5| Step: 10
Training loss: 2.738053468816068
Validation loss: 2.6301314666897224

Epoch: 5| Step: 11
Training loss: 2.522928003421663
Validation loss: 2.63028777855472

Epoch: 78| Step: 0
Training loss: 2.978144187905461
Validation loss: 2.628474868516641

Epoch: 5| Step: 1
Training loss: 2.972921392218281
Validation loss: 2.6277954868699362

Epoch: 5| Step: 2
Training loss: 2.7918751956622803
Validation loss: 2.6275441484556374

Epoch: 5| Step: 3
Training loss: 2.496923747440239
Validation loss: 2.629273693598568

Epoch: 5| Step: 4
Training loss: 2.4812547774953515
Validation loss: 2.6266847532475834

Epoch: 5| Step: 5
Training loss: 2.9505057854982746
Validation loss: 2.6244243830853864

Epoch: 5| Step: 6
Training loss: 2.6118106096723626
Validation loss: 2.623508832127224

Epoch: 5| Step: 7
Training loss: 2.6223069863798654
Validation loss: 2.624253465824674

Epoch: 5| Step: 8
Training loss: 3.0015861768448975
Validation loss: 2.6218998669493483

Epoch: 5| Step: 9
Training loss: 2.7393609501806724
Validation loss: 2.6216554679396995

Epoch: 5| Step: 10
Training loss: 2.7365881110876176
Validation loss: 2.622834125752194

Epoch: 5| Step: 11
Training loss: 2.4582274031580575
Validation loss: 2.6246696900132394

Epoch: 79| Step: 0
Training loss: 3.1592337224899762
Validation loss: 2.6278910043988732

Epoch: 5| Step: 1
Training loss: 3.0045214594739464
Validation loss: 2.623721375214591

Epoch: 5| Step: 2
Training loss: 2.547825173840442
Validation loss: 2.6162112279808505

Epoch: 5| Step: 3
Training loss: 2.8784646429236407
Validation loss: 2.6143612799002134

Epoch: 5| Step: 4
Training loss: 3.1234780229284143
Validation loss: 2.6172285541711635

Epoch: 5| Step: 5
Training loss: 2.569586839825575
Validation loss: 2.6148788670139362

Epoch: 5| Step: 6
Training loss: 2.8234377634610937
Validation loss: 2.6151873636804166

Epoch: 5| Step: 7
Training loss: 2.9497719757402106
Validation loss: 2.6147347567253445

Epoch: 5| Step: 8
Training loss: 2.42394104478608
Validation loss: 2.6144271451847714

Epoch: 5| Step: 9
Training loss: 2.6965525552617318
Validation loss: 2.6122247169113937

Epoch: 5| Step: 10
Training loss: 2.057255405798585
Validation loss: 2.6127518068608544

Epoch: 5| Step: 11
Training loss: 2.2915234145271506
Validation loss: 2.6107921216674708

Epoch: 80| Step: 0
Training loss: 2.9719590360711505
Validation loss: 2.6130736705255346

Epoch: 5| Step: 1
Training loss: 2.545033731293244
Validation loss: 2.61384615568169

Epoch: 5| Step: 2
Training loss: 3.080684159574338
Validation loss: 2.6122104406735653

Epoch: 5| Step: 3
Training loss: 2.8015788497490277
Validation loss: 2.6113889388024543

Epoch: 5| Step: 4
Training loss: 2.832924832085745
Validation loss: 2.605622343752989

Epoch: 5| Step: 5
Training loss: 2.5956959605925394
Validation loss: 2.6071498333653493

Epoch: 5| Step: 6
Training loss: 2.890341585029253
Validation loss: 2.6052080945779132

Epoch: 5| Step: 7
Training loss: 2.673640777511375
Validation loss: 2.604404996774419

Epoch: 5| Step: 8
Training loss: 2.6172335948016374
Validation loss: 2.6022361402538

Epoch: 5| Step: 9
Training loss: 2.5888662665619826
Validation loss: 2.6018089506092443

Epoch: 5| Step: 10
Training loss: 2.4785235129036223
Validation loss: 2.601197725980935

Epoch: 5| Step: 11
Training loss: 2.9483091454801307
Validation loss: 2.600772329085774

Epoch: 81| Step: 0
Training loss: 2.7060550399223877
Validation loss: 2.6033762927689015

Epoch: 5| Step: 1
Training loss: 2.867578131651427
Validation loss: 2.6017809442983286

Epoch: 5| Step: 2
Training loss: 2.4152707529821953
Validation loss: 2.602111536997608

Epoch: 5| Step: 3
Training loss: 2.9205405712108123
Validation loss: 2.60985183166143

Epoch: 5| Step: 4
Training loss: 2.9244821921537016
Validation loss: 2.607168650623963

Epoch: 5| Step: 5
Training loss: 2.743800544707684
Validation loss: 2.606253426211855

Epoch: 5| Step: 6
Training loss: 2.6519462276317913
Validation loss: 2.5988217676603775

Epoch: 5| Step: 7
Training loss: 2.407327187932355
Validation loss: 2.598048768945934

Epoch: 5| Step: 8
Training loss: 2.5299689736555884
Validation loss: 2.592750245569485

Epoch: 5| Step: 9
Training loss: 2.761790143807345
Validation loss: 2.5944765367935063

Epoch: 5| Step: 10
Training loss: 3.194171282012442
Validation loss: 2.5956889071528426

Epoch: 5| Step: 11
Training loss: 2.139445961687216
Validation loss: 2.5986239894147083

Epoch: 82| Step: 0
Training loss: 2.813344616694068
Validation loss: 2.5987940770127387

Epoch: 5| Step: 1
Training loss: 2.655146829744073
Validation loss: 2.6015096092002663

Epoch: 5| Step: 2
Training loss: 3.0214575462407796
Validation loss: 2.601048706151083

Epoch: 5| Step: 3
Training loss: 2.7125121718454404
Validation loss: 2.5959748450497124

Epoch: 5| Step: 4
Training loss: 3.1712510571085213
Validation loss: 2.5946925453805614

Epoch: 5| Step: 5
Training loss: 2.8354562398338463
Validation loss: 2.593426787679143

Epoch: 5| Step: 6
Training loss: 2.6000690927861827
Validation loss: 2.589582630493936

Epoch: 5| Step: 7
Training loss: 2.19351557161027
Validation loss: 2.589782428351108

Epoch: 5| Step: 8
Training loss: 2.8027146395211084
Validation loss: 2.588061433349415

Epoch: 5| Step: 9
Training loss: 2.585702384102399
Validation loss: 2.588023635996832

Epoch: 5| Step: 10
Training loss: 2.514137728782397
Validation loss: 2.5865183328733092

Epoch: 5| Step: 11
Training loss: 2.8214334812087096
Validation loss: 2.586184878776264

Epoch: 83| Step: 0
Training loss: 2.6884512881065428
Validation loss: 2.586767618525541

Epoch: 5| Step: 1
Training loss: 2.458828752242666
Validation loss: 2.584788509930754

Epoch: 5| Step: 2
Training loss: 2.612710978918792
Validation loss: 2.5852331218278577

Epoch: 5| Step: 3
Training loss: 2.697140988419696
Validation loss: 2.5850278016826747

Epoch: 5| Step: 4
Training loss: 3.1144254680588763
Validation loss: 2.5843724050512664

Epoch: 5| Step: 5
Training loss: 2.6017291041459067
Validation loss: 2.5841347018010414

Epoch: 5| Step: 6
Training loss: 2.9229373734480046
Validation loss: 2.5870867439104592

Epoch: 5| Step: 7
Training loss: 2.563472656247024
Validation loss: 2.5815801721822353

Epoch: 5| Step: 8
Training loss: 3.033288486554415
Validation loss: 2.5830946986410748

Epoch: 5| Step: 9
Training loss: 2.266849581499947
Validation loss: 2.583536172153522

Epoch: 5| Step: 10
Training loss: 2.9828800631385324
Validation loss: 2.5824485168483005

Epoch: 5| Step: 11
Training loss: 2.034567837577692
Validation loss: 2.58397725499086

Epoch: 84| Step: 0
Training loss: 3.0273957278803967
Validation loss: 2.581033780430285

Epoch: 5| Step: 1
Training loss: 2.7221691511348327
Validation loss: 2.5819309117014595

Epoch: 5| Step: 2
Training loss: 2.4977856365979973
Validation loss: 2.5792003546709115

Epoch: 5| Step: 3
Training loss: 2.8688594090826465
Validation loss: 2.5786189713861054

Epoch: 5| Step: 4
Training loss: 2.868375028151658
Validation loss: 2.5797593417716467

Epoch: 5| Step: 5
Training loss: 2.560801152247343
Validation loss: 2.579670494850714

Epoch: 5| Step: 6
Training loss: 2.584864828976949
Validation loss: 2.5760910063904614

Epoch: 5| Step: 7
Training loss: 2.6352713221903428
Validation loss: 2.581205700639672

Epoch: 5| Step: 8
Training loss: 2.6170227909925083
Validation loss: 2.5747878989576813

Epoch: 5| Step: 9
Training loss: 2.7686569060439776
Validation loss: 2.576839970626542

Epoch: 5| Step: 10
Training loss: 2.6041108901090637
Validation loss: 2.5715616895169324

Epoch: 5| Step: 11
Training loss: 3.093961920367647
Validation loss: 2.5709373387134633

Epoch: 85| Step: 0
Training loss: 2.7577663342121226
Validation loss: 2.5698576488974485

Epoch: 5| Step: 1
Training loss: 2.6448004401052563
Validation loss: 2.5701818771177734

Epoch: 5| Step: 2
Training loss: 2.5996553229234354
Validation loss: 2.5691433250409577

Epoch: 5| Step: 3
Training loss: 2.7811764482352177
Validation loss: 2.5704277035946252

Epoch: 5| Step: 4
Training loss: 2.3799705692683464
Validation loss: 2.567794296703368

Epoch: 5| Step: 5
Training loss: 2.6333780558526696
Validation loss: 2.568844748154994

Epoch: 5| Step: 6
Training loss: 2.6474915562135735
Validation loss: 2.5691508766956948

Epoch: 5| Step: 7
Training loss: 2.551336207636495
Validation loss: 2.567329585144046

Epoch: 5| Step: 8
Training loss: 3.379823134721264
Validation loss: 2.5666883595177428

Epoch: 5| Step: 9
Training loss: 2.6972161246362973
Validation loss: 2.5659509310070603

Epoch: 5| Step: 10
Training loss: 2.8101500124274845
Validation loss: 2.567941613784607

Epoch: 5| Step: 11
Training loss: 0.42962314817414066
Validation loss: 2.5666826661548416

Epoch: 86| Step: 0
Training loss: 2.9587502163434483
Validation loss: 2.566169410433633

Epoch: 5| Step: 1
Training loss: 2.447844830263821
Validation loss: 2.563957757261391

Epoch: 5| Step: 2
Training loss: 2.5464948124678237
Validation loss: 2.568670585159635

Epoch: 5| Step: 3
Training loss: 2.6195960050793863
Validation loss: 2.563938591873007

Epoch: 5| Step: 4
Training loss: 2.6917052967933093
Validation loss: 2.5670624217827767

Epoch: 5| Step: 5
Training loss: 2.7642900078938353
Validation loss: 2.5687569932927508

Epoch: 5| Step: 6
Training loss: 3.238869166182384
Validation loss: 2.5674931369591953

Epoch: 5| Step: 7
Training loss: 2.323221252270113
Validation loss: 2.5656081613010526

Epoch: 5| Step: 8
Training loss: 2.6790487790510027
Validation loss: 2.5655624186867003

Epoch: 5| Step: 9
Training loss: 2.6826466939585862
Validation loss: 2.566422666113

Epoch: 5| Step: 10
Training loss: 2.516343292614142
Validation loss: 2.562500872262946

Epoch: 5| Step: 11
Training loss: 3.3168772440504353
Validation loss: 2.5646399269914704

Epoch: 87| Step: 0
Training loss: 2.8726744160766375
Validation loss: 2.561187295482794

Epoch: 5| Step: 1
Training loss: 2.3864319374581715
Validation loss: 2.5640135729993854

Epoch: 5| Step: 2
Training loss: 2.950777927565478
Validation loss: 2.562500721070723

Epoch: 5| Step: 3
Training loss: 2.984935767730285
Validation loss: 2.5677565569472796

Epoch: 5| Step: 4
Training loss: 2.529371718547588
Validation loss: 2.568096682189006

Epoch: 5| Step: 5
Training loss: 2.535059475925224
Validation loss: 2.579085631527773

Epoch: 5| Step: 6
Training loss: 2.377201565725577
Validation loss: 2.573581491258601

Epoch: 5| Step: 7
Training loss: 3.024044636331351
Validation loss: 2.566909496836278

Epoch: 5| Step: 8
Training loss: 2.2941080671429734
Validation loss: 2.5623451628077167

Epoch: 5| Step: 9
Training loss: 3.0140259609509226
Validation loss: 2.557032994837816

Epoch: 5| Step: 10
Training loss: 2.584159585630804
Validation loss: 2.555605063500202

Epoch: 5| Step: 11
Training loss: 2.7053201395010427
Validation loss: 2.5556427455854145

Epoch: 88| Step: 0
Training loss: 2.666399962280621
Validation loss: 2.556079158810103

Epoch: 5| Step: 1
Training loss: 2.90951731791622
Validation loss: 2.5562753982339244

Epoch: 5| Step: 2
Training loss: 2.5078699218260514
Validation loss: 2.5575679868024923

Epoch: 5| Step: 3
Training loss: 2.369393909874968
Validation loss: 2.5578517818366846

Epoch: 5| Step: 4
Training loss: 2.5543599049920425
Validation loss: 2.5581230681886082

Epoch: 5| Step: 5
Training loss: 2.70995530686352
Validation loss: 2.558039415408018

Epoch: 5| Step: 6
Training loss: 3.031837956932185
Validation loss: 2.556824343622534

Epoch: 5| Step: 7
Training loss: 2.5821806479211586
Validation loss: 2.555646967001656

Epoch: 5| Step: 8
Training loss: 2.8762461408036333
Validation loss: 2.5566961614154144

Epoch: 5| Step: 9
Training loss: 2.5917362530883636
Validation loss: 2.5554575056176394

Epoch: 5| Step: 10
Training loss: 2.4469710018184183
Validation loss: 2.5554099854931853

Epoch: 5| Step: 11
Training loss: 3.6575206928619526
Validation loss: 2.5539563072684683

Epoch: 89| Step: 0
Training loss: 2.611853513170575
Validation loss: 2.5534405323845144

Epoch: 5| Step: 1
Training loss: 2.444132559800951
Validation loss: 2.5532729522717785

Epoch: 5| Step: 2
Training loss: 2.578462613281333
Validation loss: 2.5511760201724942

Epoch: 5| Step: 3
Training loss: 2.655669204943723
Validation loss: 2.548896911394462

Epoch: 5| Step: 4
Training loss: 2.4197228498412677
Validation loss: 2.551218969887491

Epoch: 5| Step: 5
Training loss: 2.6619343689609933
Validation loss: 2.549734674936741

Epoch: 5| Step: 6
Training loss: 2.663473651501443
Validation loss: 2.5507968592494743

Epoch: 5| Step: 7
Training loss: 2.85541547942145
Validation loss: 2.5520333590123445

Epoch: 5| Step: 8
Training loss: 2.7778674354918844
Validation loss: 2.5508254759587636

Epoch: 5| Step: 9
Training loss: 2.819522482841731
Validation loss: 2.550325077348242

Epoch: 5| Step: 10
Training loss: 3.0386407162321363
Validation loss: 2.545858371401302

Epoch: 5| Step: 11
Training loss: 1.990802477915124
Validation loss: 2.548234296002759

Epoch: 90| Step: 0
Training loss: 2.785486744750706
Validation loss: 2.547746715871567

Epoch: 5| Step: 1
Training loss: 2.8541286679450937
Validation loss: 2.547785828184596

Epoch: 5| Step: 2
Training loss: 2.7786397793866855
Validation loss: 2.5462038095773196

Epoch: 5| Step: 3
Training loss: 2.8083594467201705
Validation loss: 2.5481927501188406

Epoch: 5| Step: 4
Training loss: 2.708439624363449
Validation loss: 2.5441072711410886

Epoch: 5| Step: 5
Training loss: 2.572994977451705
Validation loss: 2.5504367784657442

Epoch: 5| Step: 6
Training loss: 2.806461888663292
Validation loss: 2.5420525497634325

Epoch: 5| Step: 7
Training loss: 2.45239110769073
Validation loss: 2.546179202466811

Epoch: 5| Step: 8
Training loss: 2.3351557517537733
Validation loss: 2.5398471617521747

Epoch: 5| Step: 9
Training loss: 2.9462144517918696
Validation loss: 2.54225303707666

Epoch: 5| Step: 10
Training loss: 2.3594496759382073
Validation loss: 2.5416641365622348

Epoch: 5| Step: 11
Training loss: 2.311133315925218
Validation loss: 2.5421611169447575

Epoch: 91| Step: 0
Training loss: 2.3903117255101027
Validation loss: 2.542132082262628

Epoch: 5| Step: 1
Training loss: 2.501206488357149
Validation loss: 2.541634701439223

Epoch: 5| Step: 2
Training loss: 2.522715273273245
Validation loss: 2.542360439096104

Epoch: 5| Step: 3
Training loss: 2.5541274830569893
Validation loss: 2.5407233885059877

Epoch: 5| Step: 4
Training loss: 2.677256201321997
Validation loss: 2.537697895833321

Epoch: 5| Step: 5
Training loss: 2.704548102829979
Validation loss: 2.5401305197237214

Epoch: 5| Step: 6
Training loss: 2.632603577607589
Validation loss: 2.539290800345638

Epoch: 5| Step: 7
Training loss: 3.016274812092796
Validation loss: 2.5474979130340505

Epoch: 5| Step: 8
Training loss: 2.810807036446379
Validation loss: 2.544887781585734

Epoch: 5| Step: 9
Training loss: 2.8188762019086635
Validation loss: 2.536396990640703

Epoch: 5| Step: 10
Training loss: 2.8050137385883573
Validation loss: 2.5376239281256505

Epoch: 5| Step: 11
Training loss: 2.0007468259710675
Validation loss: 2.5389495002837292

Epoch: 92| Step: 0
Training loss: 3.0037681438709263
Validation loss: 2.540909714364487

Epoch: 5| Step: 1
Training loss: 2.608273484962261
Validation loss: 2.547293809963839

Epoch: 5| Step: 2
Training loss: 2.6846506849839
Validation loss: 2.545853774763372

Epoch: 5| Step: 3
Training loss: 2.837761242641681
Validation loss: 2.548162661384753

Epoch: 5| Step: 4
Training loss: 2.834477492795723
Validation loss: 2.543890993364518

Epoch: 5| Step: 5
Training loss: 2.4512821735019448
Validation loss: 2.5419105285120036

Epoch: 5| Step: 6
Training loss: 2.78670369906969
Validation loss: 2.539965127770642

Epoch: 5| Step: 7
Training loss: 2.670784443265483
Validation loss: 2.5402415995480685

Epoch: 5| Step: 8
Training loss: 2.7510559482244688
Validation loss: 2.5392258342146223

Epoch: 5| Step: 9
Training loss: 2.2703722447766785
Validation loss: 2.532318419567934

Epoch: 5| Step: 10
Training loss: 2.5761257858723106
Validation loss: 2.534047892039891

Epoch: 5| Step: 11
Training loss: 1.4578685655678378
Validation loss: 2.533094891559739

Epoch: 93| Step: 0
Training loss: 2.4893820347400424
Validation loss: 2.5324019216755334

Epoch: 5| Step: 1
Training loss: 2.4632685202751476
Validation loss: 2.5309439109064464

Epoch: 5| Step: 2
Training loss: 2.42643534860844
Validation loss: 2.531443323594177

Epoch: 5| Step: 3
Training loss: 2.5909962571005543
Validation loss: 2.533509788098276

Epoch: 5| Step: 4
Training loss: 2.7109002102532607
Validation loss: 2.5362780126331645

Epoch: 5| Step: 5
Training loss: 2.5555981987237963
Validation loss: 2.5336211209421893

Epoch: 5| Step: 6
Training loss: 2.7705165901892146
Validation loss: 2.53168417499717

Epoch: 5| Step: 7
Training loss: 2.9473193386838297
Validation loss: 2.532742794018205

Epoch: 5| Step: 8
Training loss: 2.9961736437155806
Validation loss: 2.5314711642877388

Epoch: 5| Step: 9
Training loss: 2.7171602534046246
Validation loss: 2.530759245782785

Epoch: 5| Step: 10
Training loss: 2.5879202902191234
Validation loss: 2.5343859442220964

Epoch: 5| Step: 11
Training loss: 2.343637285701162
Validation loss: 2.535719786845252

Epoch: 94| Step: 0
Training loss: 2.9467031904117547
Validation loss: 2.539358616703383

Epoch: 5| Step: 1
Training loss: 2.776591138632992
Validation loss: 2.5449600236384815

Epoch: 5| Step: 2
Training loss: 2.78241610994375
Validation loss: 2.5457040283051673

Epoch: 5| Step: 3
Training loss: 2.721700711369284
Validation loss: 2.5408673645131006

Epoch: 5| Step: 4
Training loss: 2.38704048647863
Validation loss: 2.535056019639942

Epoch: 5| Step: 5
Training loss: 2.576060075047534
Validation loss: 2.5279786630660084

Epoch: 5| Step: 6
Training loss: 2.4540286009659975
Validation loss: 2.5308169869740875

Epoch: 5| Step: 7
Training loss: 2.850890532448226
Validation loss: 2.52670384933478

Epoch: 5| Step: 8
Training loss: 2.3716154577213775
Validation loss: 2.5250055187152443

Epoch: 5| Step: 9
Training loss: 2.5823240359422797
Validation loss: 2.5237789926852194

Epoch: 5| Step: 10
Training loss: 2.8152227150336966
Validation loss: 2.5222782271166224

Epoch: 5| Step: 11
Training loss: 2.3355767727456875
Validation loss: 2.5277108579785614

Epoch: 95| Step: 0
Training loss: 3.1973091733060524
Validation loss: 2.5325923037174993

Epoch: 5| Step: 1
Training loss: 2.636969027473677
Validation loss: 2.533823424123722

Epoch: 5| Step: 2
Training loss: 2.515139515156303
Validation loss: 2.5301117044788075

Epoch: 5| Step: 3
Training loss: 2.5815346106027217
Validation loss: 2.535847985361847

Epoch: 5| Step: 4
Training loss: 3.1860319758724547
Validation loss: 2.5324427733901835

Epoch: 5| Step: 5
Training loss: 2.565647797012803
Validation loss: 2.531712415238729

Epoch: 5| Step: 6
Training loss: 2.5421625081002066
Validation loss: 2.5293528821873785

Epoch: 5| Step: 7
Training loss: 2.403661648638692
Validation loss: 2.5299037328066323

Epoch: 5| Step: 8
Training loss: 2.413896968561231
Validation loss: 2.528741213371083

Epoch: 5| Step: 9
Training loss: 2.252366199308757
Validation loss: 2.5225802482087167

Epoch: 5| Step: 10
Training loss: 2.7916761274794264
Validation loss: 2.521450662030496

Epoch: 5| Step: 11
Training loss: 1.9534344237319679
Validation loss: 2.5203138333699626

Epoch: 96| Step: 0
Training loss: 2.7979795523190143
Validation loss: 2.5224037178688765

Epoch: 5| Step: 1
Training loss: 2.542161007528005
Validation loss: 2.522759849490049

Epoch: 5| Step: 2
Training loss: 2.361083769795804
Validation loss: 2.5204499770254762

Epoch: 5| Step: 3
Training loss: 2.6014600395668928
Validation loss: 2.5200552383176564

Epoch: 5| Step: 4
Training loss: 2.2029818224544426
Validation loss: 2.52202184628537

Epoch: 5| Step: 5
Training loss: 3.26993812572491
Validation loss: 2.518694523310035

Epoch: 5| Step: 6
Training loss: 2.8946823101291628
Validation loss: 2.518792482243438

Epoch: 5| Step: 7
Training loss: 2.0928061336325374
Validation loss: 2.518218356362105

Epoch: 5| Step: 8
Training loss: 2.4737052921921863
Validation loss: 2.5204543046815413

Epoch: 5| Step: 9
Training loss: 2.6596243574454803
Validation loss: 2.5210923240491305

Epoch: 5| Step: 10
Training loss: 2.9000119768092696
Validation loss: 2.5135395773035674

Epoch: 5| Step: 11
Training loss: 2.7660867768892383
Validation loss: 2.5180796105763106

Epoch: 97| Step: 0
Training loss: 2.2912755690259807
Validation loss: 2.5180963575233775

Epoch: 5| Step: 1
Training loss: 2.310599499810157
Validation loss: 2.5188473939011193

Epoch: 5| Step: 2
Training loss: 2.522328608486986
Validation loss: 2.517982136794062

Epoch: 5| Step: 3
Training loss: 2.824001024224417
Validation loss: 2.5183411816231276

Epoch: 5| Step: 4
Training loss: 2.9238943374057613
Validation loss: 2.524932863110902

Epoch: 5| Step: 5
Training loss: 2.497828589618682
Validation loss: 2.5180705486364876

Epoch: 5| Step: 6
Training loss: 2.8129785766328217
Validation loss: 2.522197182364626

Epoch: 5| Step: 7
Training loss: 2.5489086620717165
Validation loss: 2.5242097104145955

Epoch: 5| Step: 8
Training loss: 3.1659665253942584
Validation loss: 2.521152583837459

Epoch: 5| Step: 9
Training loss: 2.409012138066921
Validation loss: 2.5135873870759586

Epoch: 5| Step: 10
Training loss: 2.557575518256635
Validation loss: 2.5159518698870786

Epoch: 5| Step: 11
Training loss: 3.233406548474046
Validation loss: 2.519873490857321

Epoch: 98| Step: 0
Training loss: 3.0328819365219855
Validation loss: 2.5186480213594744

Epoch: 5| Step: 1
Training loss: 2.6065419973461856
Validation loss: 2.5287885471749294

Epoch: 5| Step: 2
Training loss: 2.6450802389568486
Validation loss: 2.5284247113447678

Epoch: 5| Step: 3
Training loss: 2.4356367374535752
Validation loss: 2.5364269604527987

Epoch: 5| Step: 4
Training loss: 2.4122004070942356
Validation loss: 2.5336583732607596

Epoch: 5| Step: 5
Training loss: 2.3836155273082835
Validation loss: 2.5398291931705193

Epoch: 5| Step: 6
Training loss: 2.9830332031448212
Validation loss: 2.534784686539655

Epoch: 5| Step: 7
Training loss: 2.6768557876086283
Validation loss: 2.5332731081889532

Epoch: 5| Step: 8
Training loss: 2.5681932054729075
Validation loss: 2.5255656564020295

Epoch: 5| Step: 9
Training loss: 2.971071319535531
Validation loss: 2.5262303993009576

Epoch: 5| Step: 10
Training loss: 2.386165373686886
Validation loss: 2.5216530000585657

Epoch: 5| Step: 11
Training loss: 2.806782994279668
Validation loss: 2.521417815386057

Epoch: 99| Step: 0
Training loss: 2.8854062370543305
Validation loss: 2.517007406459137

Epoch: 5| Step: 1
Training loss: 2.4426911657796966
Validation loss: 2.5174170048672724

Epoch: 5| Step: 2
Training loss: 2.9410907631896257
Validation loss: 2.5156355634510983

Epoch: 5| Step: 3
Training loss: 3.178383299647023
Validation loss: 2.5152824437152965

Epoch: 5| Step: 4
Training loss: 2.454214643733732
Validation loss: 2.515339926053042

Epoch: 5| Step: 5
Training loss: 2.077125595820871
Validation loss: 2.5133001788273086

Epoch: 5| Step: 6
Training loss: 2.324500520439853
Validation loss: 2.5132406359327693

Epoch: 5| Step: 7
Training loss: 2.6993188246022006
Validation loss: 2.513305028680979

Epoch: 5| Step: 8
Training loss: 2.9014506756542313
Validation loss: 2.5095630291856272

Epoch: 5| Step: 9
Training loss: 2.743996222012424
Validation loss: 2.5109993362646166

Epoch: 5| Step: 10
Training loss: 2.220800177903402
Validation loss: 2.513797052443528

Epoch: 5| Step: 11
Training loss: 1.859194193792551
Validation loss: 2.5076004128779346

Epoch: 100| Step: 0
Training loss: 2.6210983890316157
Validation loss: 2.514881363731903

Epoch: 5| Step: 1
Training loss: 3.131389646785452
Validation loss: 2.511617497311141

Epoch: 5| Step: 2
Training loss: 2.7113323528749813
Validation loss: 2.5157105093692693

Epoch: 5| Step: 3
Training loss: 2.3748113657677608
Validation loss: 2.5305067882562366

Epoch: 5| Step: 4
Training loss: 1.9369315882562397
Validation loss: 2.5262918066598217

Epoch: 5| Step: 5
Training loss: 2.8011117737492848
Validation loss: 2.5287270590206217

Epoch: 5| Step: 6
Training loss: 2.4529009674210944
Validation loss: 2.5229138361450074

Epoch: 5| Step: 7
Training loss: 2.8028157823815394
Validation loss: 2.5185323267764126

Epoch: 5| Step: 8
Training loss: 2.7849656049155693
Validation loss: 2.5140925492347446

Epoch: 5| Step: 9
Training loss: 2.74242302298858
Validation loss: 2.5126340591510012

Epoch: 5| Step: 10
Training loss: 2.5409810960374974
Validation loss: 2.5106575218514604

Epoch: 5| Step: 11
Training loss: 2.3356880386497685
Validation loss: 2.5057185731350815

Epoch: 101| Step: 0
Training loss: 2.610925088392945
Validation loss: 2.5052118651642097

Epoch: 5| Step: 1
Training loss: 2.338633840623417
Validation loss: 2.5052720588515136

Epoch: 5| Step: 2
Training loss: 2.823596004560967
Validation loss: 2.5088307223901847

Epoch: 5| Step: 3
Training loss: 2.52378006726852
Validation loss: 2.5046662730909737

Epoch: 5| Step: 4
Training loss: 2.4217279204961577
Validation loss: 2.5077816494859384

Epoch: 5| Step: 5
Training loss: 2.1011562025567554
Validation loss: 2.505355883487537

Epoch: 5| Step: 6
Training loss: 2.6842330770755827
Validation loss: 2.5067643245884907

Epoch: 5| Step: 7
Training loss: 2.468914461090222
Validation loss: 2.5092480829683907

Epoch: 5| Step: 8
Training loss: 2.7524061946839655
Validation loss: 2.5015075509181495

Epoch: 5| Step: 9
Training loss: 3.0689560706411863
Validation loss: 2.50351589847888

Epoch: 5| Step: 10
Training loss: 2.8616207454894553
Validation loss: 2.499540624533982

Epoch: 5| Step: 11
Training loss: 3.11440342071996
Validation loss: 2.506639114973103

Epoch: 102| Step: 0
Training loss: 2.4014765965443012
Validation loss: 2.505629408272589

Epoch: 5| Step: 1
Training loss: 2.500404515918394
Validation loss: 2.5052026892669184

Epoch: 5| Step: 2
Training loss: 2.879294794951596
Validation loss: 2.5037008866844572

Epoch: 5| Step: 3
Training loss: 2.7041095858889186
Validation loss: 2.5037066558143426

Epoch: 5| Step: 4
Training loss: 2.5965632613049303
Validation loss: 2.508858827873421

Epoch: 5| Step: 5
Training loss: 3.0057521352296335
Validation loss: 2.505047526654257

Epoch: 5| Step: 6
Training loss: 2.443192705771319
Validation loss: 2.5097194800977345

Epoch: 5| Step: 7
Training loss: 2.813872786443725
Validation loss: 2.498724957999484

Epoch: 5| Step: 8
Training loss: 2.8316155069305147
Validation loss: 2.5037766500925223

Epoch: 5| Step: 9
Training loss: 1.9938040962174863
Validation loss: 2.5055807131650605

Epoch: 5| Step: 10
Training loss: 2.4148848531057885
Validation loss: 2.5005989867121206

Epoch: 5| Step: 11
Training loss: 3.0265397117753343
Validation loss: 2.5069104252799805

Epoch: 103| Step: 0
Training loss: 2.7927413314317366
Validation loss: 2.5006797561777945

Epoch: 5| Step: 1
Training loss: 2.3535199810320164
Validation loss: 2.50660262033215

Epoch: 5| Step: 2
Training loss: 2.994639375656838
Validation loss: 2.5069970105302626

Epoch: 5| Step: 3
Training loss: 2.8767159358373373
Validation loss: 2.5016452263348126

Epoch: 5| Step: 4
Training loss: 2.021728972596291
Validation loss: 2.5053069134282318

Epoch: 5| Step: 5
Training loss: 3.1903015989075683
Validation loss: 2.5054226517289937

Epoch: 5| Step: 6
Training loss: 2.6460167728621955
Validation loss: 2.5004578926053957

Epoch: 5| Step: 7
Training loss: 2.9904989154190575
Validation loss: 2.499753574306088

Epoch: 5| Step: 8
Training loss: 2.201593177641234
Validation loss: 2.497495350265375

Epoch: 5| Step: 9
Training loss: 2.048867457096844
Validation loss: 2.500166362949171

Epoch: 5| Step: 10
Training loss: 2.3377594747701145
Validation loss: 2.500474376176717

Epoch: 5| Step: 11
Training loss: 2.9617777012276356
Validation loss: 2.504036656483617

Epoch: 104| Step: 0
Training loss: 2.647615648432788
Validation loss: 2.506073666788269

Epoch: 5| Step: 1
Training loss: 2.6584848314921192
Validation loss: 2.5012070880877406

Epoch: 5| Step: 2
Training loss: 2.187182594159736
Validation loss: 2.5008103607018333

Epoch: 5| Step: 3
Training loss: 2.3681298322268387
Validation loss: 2.4979966560984805

Epoch: 5| Step: 4
Training loss: 2.7057525565219827
Validation loss: 2.500303754631901

Epoch: 5| Step: 5
Training loss: 2.4405202493888476
Validation loss: 2.503356619352831

Epoch: 5| Step: 6
Training loss: 3.0191158981189203
Validation loss: 2.508436163086149

Epoch: 5| Step: 7
Training loss: 2.4554599413469504
Validation loss: 2.5008441652175466

Epoch: 5| Step: 8
Training loss: 2.7091375966322886
Validation loss: 2.507971864511067

Epoch: 5| Step: 9
Training loss: 2.8238992892886463
Validation loss: 2.5068846399272013

Epoch: 5| Step: 10
Training loss: 2.6550804705018054
Validation loss: 2.503098994995871

Epoch: 5| Step: 11
Training loss: 3.1097657231346547
Validation loss: 2.5018978346056486

Epoch: 105| Step: 0
Training loss: 2.708041180234155
Validation loss: 2.5003137828682327

Epoch: 5| Step: 1
Training loss: 2.5010188887476557
Validation loss: 2.497786531460129

Epoch: 5| Step: 2
Training loss: 2.542962280827745
Validation loss: 2.4985465155780577

Epoch: 5| Step: 3
Training loss: 2.9183409835160345
Validation loss: 2.5009780798384496

Epoch: 5| Step: 4
Training loss: 2.4878016418365747
Validation loss: 2.4989316127652956

Epoch: 5| Step: 5
Training loss: 2.725309504859555
Validation loss: 2.499164469492083

Epoch: 5| Step: 6
Training loss: 2.994719785850449
Validation loss: 2.5014385654137206

Epoch: 5| Step: 7
Training loss: 2.3044998351163466
Validation loss: 2.500843485953868

Epoch: 5| Step: 8
Training loss: 2.703553094206015
Validation loss: 2.5023561183382803

Epoch: 5| Step: 9
Training loss: 2.535335023098882
Validation loss: 2.502655284146506

Epoch: 5| Step: 10
Training loss: 2.315790361479539
Validation loss: 2.5022058967240235

Epoch: 5| Step: 11
Training loss: 2.5730135097630833
Validation loss: 2.499822018168837

Epoch: 106| Step: 0
Training loss: 2.455075794300803
Validation loss: 2.4988933259544748

Epoch: 5| Step: 1
Training loss: 2.7497789987713084
Validation loss: 2.4980603879593426

Epoch: 5| Step: 2
Training loss: 1.9671682634087253
Validation loss: 2.4963819071799414

Epoch: 5| Step: 3
Training loss: 2.654298581648412
Validation loss: 2.4944893581474075

Epoch: 5| Step: 4
Training loss: 2.6857480393407633
Validation loss: 2.4976968368400176

Epoch: 5| Step: 5
Training loss: 2.7784233731159653
Validation loss: 2.493636564034653

Epoch: 5| Step: 6
Training loss: 2.881734837846671
Validation loss: 2.5005858847423856

Epoch: 5| Step: 7
Training loss: 2.4282928094600416
Validation loss: 2.4984945294310945

Epoch: 5| Step: 8
Training loss: 2.8054279848141737
Validation loss: 2.4978655007864567

Epoch: 5| Step: 9
Training loss: 2.483235607741869
Validation loss: 2.50394363891173

Epoch: 5| Step: 10
Training loss: 2.4775263598413027
Validation loss: 2.5013340251788803

Epoch: 5| Step: 11
Training loss: 3.281861021280531
Validation loss: 2.5034874274688153

Epoch: 107| Step: 0
Training loss: 3.0448233715124586
Validation loss: 2.502414495059821

Epoch: 5| Step: 1
Training loss: 2.287704950542107
Validation loss: 2.501327853423374

Epoch: 5| Step: 2
Training loss: 3.132831221450841
Validation loss: 2.507929774440928

Epoch: 5| Step: 3
Training loss: 2.4679967962581175
Validation loss: 2.507266934986961

Epoch: 5| Step: 4
Training loss: 2.5770364948807507
Validation loss: 2.5041499939192637

Epoch: 5| Step: 5
Training loss: 2.2644253415674713
Validation loss: 2.510193448147766

Epoch: 5| Step: 6
Training loss: 2.808665310474608
Validation loss: 2.5021763745895873

Epoch: 5| Step: 7
Training loss: 2.5030041764301076
Validation loss: 2.503044444298821

Epoch: 5| Step: 8
Training loss: 2.4476036575078095
Validation loss: 2.496407128503193

Epoch: 5| Step: 9
Training loss: 2.6126182638897055
Validation loss: 2.497053364862927

Epoch: 5| Step: 10
Training loss: 2.3945468821178677
Validation loss: 2.496005228350433

Epoch: 5| Step: 11
Training loss: 1.7049543722541391
Validation loss: 2.4947778041722577

Epoch: 108| Step: 0
Training loss: 2.614177099840842
Validation loss: 2.4962824678991784

Epoch: 5| Step: 1
Training loss: 2.773746097212973
Validation loss: 2.499175545725537

Epoch: 5| Step: 2
Training loss: 2.33897044804021
Validation loss: 2.4975004774226184

Epoch: 5| Step: 3
Training loss: 2.24956020719461
Validation loss: 2.495120770774702

Epoch: 5| Step: 4
Training loss: 2.2496178620395777
Validation loss: 2.496212756962028

Epoch: 5| Step: 5
Training loss: 2.727761952996778
Validation loss: 2.4929781609236747

Epoch: 5| Step: 6
Training loss: 2.603425696179898
Validation loss: 2.4915208712208954

Epoch: 5| Step: 7
Training loss: 2.6690508992218036
Validation loss: 2.498057604247975

Epoch: 5| Step: 8
Training loss: 2.701175582121914
Validation loss: 2.4927293035058464

Epoch: 5| Step: 9
Training loss: 3.0560416807857362
Validation loss: 2.49652937946672

Epoch: 5| Step: 10
Training loss: 2.502909112161821
Validation loss: 2.4959924047489026

Epoch: 5| Step: 11
Training loss: 2.3595046456192823
Validation loss: 2.499111273870255

Epoch: 109| Step: 0
Training loss: 2.6539868755519134
Validation loss: 2.4854374419178353

Epoch: 5| Step: 1
Training loss: 2.4958505526942667
Validation loss: 2.4959341604110863

Epoch: 5| Step: 2
Training loss: 2.5713025073530473
Validation loss: 2.488860086439242

Epoch: 5| Step: 3
Training loss: 2.874123978873399
Validation loss: 2.491216687702126

Epoch: 5| Step: 4
Training loss: 2.019221564331313
Validation loss: 2.4884182319883594

Epoch: 5| Step: 5
Training loss: 2.2043142152760273
Validation loss: 2.485319565802498

Epoch: 5| Step: 6
Training loss: 2.948855588671123
Validation loss: 2.490332069225941

Epoch: 5| Step: 7
Training loss: 2.7463673961274226
Validation loss: 2.487916321795692

Epoch: 5| Step: 8
Training loss: 2.7978055460875515
Validation loss: 2.485996117291394

Epoch: 5| Step: 9
Training loss: 2.260157439900417
Validation loss: 2.4852578815623927

Epoch: 5| Step: 10
Training loss: 2.631273130917759
Validation loss: 2.489182576972713

Epoch: 5| Step: 11
Training loss: 3.2580301408772674
Validation loss: 2.4927960712079114

Epoch: 110| Step: 0
Training loss: 2.085612639658342
Validation loss: 2.484725855398273

Epoch: 5| Step: 1
Training loss: 2.7694437849817115
Validation loss: 2.4898835537197286

Epoch: 5| Step: 2
Training loss: 2.5468618006451966
Validation loss: 2.4883247423587935

Epoch: 5| Step: 3
Training loss: 2.4138978574835193
Validation loss: 2.4896784981025837

Epoch: 5| Step: 4
Training loss: 2.910086939453566
Validation loss: 2.496191067656606

Epoch: 5| Step: 5
Training loss: 3.0023193930144902
Validation loss: 2.5015554099585096

Epoch: 5| Step: 6
Training loss: 2.7880998761418216
Validation loss: 2.503856112910056

Epoch: 5| Step: 7
Training loss: 2.51362995151277
Validation loss: 2.496922490221731

Epoch: 5| Step: 8
Training loss: 2.42558948784742
Validation loss: 2.4894016204874068

Epoch: 5| Step: 9
Training loss: 2.4096549577757904
Validation loss: 2.4927920621675175

Epoch: 5| Step: 10
Training loss: 2.624357871580906
Validation loss: 2.495671399222805

Epoch: 5| Step: 11
Training loss: 2.3829530768278935
Validation loss: 2.4959330380181246

Epoch: 111| Step: 0
Training loss: 2.698642785194083
Validation loss: 2.497635863977339

Epoch: 5| Step: 1
Training loss: 2.814092820855138
Validation loss: 2.49532493925806

Epoch: 5| Step: 2
Training loss: 2.6244324570153346
Validation loss: 2.4952186160738186

Epoch: 5| Step: 3
Training loss: 2.8057932254684186
Validation loss: 2.48729849291518

Epoch: 5| Step: 4
Training loss: 2.49141975463767
Validation loss: 2.4980089404954287

Epoch: 5| Step: 5
Training loss: 2.1444701027968542
Validation loss: 2.4873717605659444

Epoch: 5| Step: 6
Training loss: 2.3699946613493075
Validation loss: 2.4896268255566048

Epoch: 5| Step: 7
Training loss: 2.5179991329394626
Validation loss: 2.4938721618113573

Epoch: 5| Step: 8
Training loss: 2.5816150508750413
Validation loss: 2.4934798749264924

Epoch: 5| Step: 9
Training loss: 2.474802444742394
Validation loss: 2.4915929342181653

Epoch: 5| Step: 10
Training loss: 2.792752429614497
Validation loss: 2.4866741306250013

Epoch: 5| Step: 11
Training loss: 3.055366148039214
Validation loss: 2.492623812152101

Epoch: 112| Step: 0
Training loss: 2.1162254709713797
Validation loss: 2.4906550950833073

Epoch: 5| Step: 1
Training loss: 1.7791482002794874
Validation loss: 2.4946093655254793

Epoch: 5| Step: 2
Training loss: 2.385502431957418
Validation loss: 2.493662072068049

Epoch: 5| Step: 3
Training loss: 2.960638267675801
Validation loss: 2.4969806637644845

Epoch: 5| Step: 4
Training loss: 2.7792218131828443
Validation loss: 2.490050345209338

Epoch: 5| Step: 5
Training loss: 2.970814519094107
Validation loss: 2.4953750865255797

Epoch: 5| Step: 6
Training loss: 2.7415080301910573
Validation loss: 2.487248464387499

Epoch: 5| Step: 7
Training loss: 2.372572109625913
Validation loss: 2.502651390135587

Epoch: 5| Step: 8
Training loss: 2.7426228843288922
Validation loss: 2.487510270268438

Epoch: 5| Step: 9
Training loss: 2.7675900132617817
Validation loss: 2.4882890231072476

Epoch: 5| Step: 10
Training loss: 2.7947262656206164
Validation loss: 2.489971834193237

Epoch: 5| Step: 11
Training loss: 2.229644355810957
Validation loss: 2.487567010612702

Epoch: 113| Step: 0
Training loss: 2.236572039100012
Validation loss: 2.4892001927939016

Epoch: 5| Step: 1
Training loss: 2.6848477428037842
Validation loss: 2.4887352394025206

Epoch: 5| Step: 2
Training loss: 3.0167471423576178
Validation loss: 2.4935985186148177

Epoch: 5| Step: 3
Training loss: 2.9403507116905727
Validation loss: 2.4885118937531012

Epoch: 5| Step: 4
Training loss: 3.0325140136495587
Validation loss: 2.487644024134773

Epoch: 5| Step: 5
Training loss: 2.7232404435127635
Validation loss: 2.489250760762465

Epoch: 5| Step: 6
Training loss: 2.189281283329445
Validation loss: 2.4892787161750416

Epoch: 5| Step: 7
Training loss: 2.3172629510655676
Validation loss: 2.4928277208809546

Epoch: 5| Step: 8
Training loss: 2.7699157706169073
Validation loss: 2.490542503691421

Epoch: 5| Step: 9
Training loss: 2.169329571854125
Validation loss: 2.495356730031505

Epoch: 5| Step: 10
Training loss: 2.3035753573260593
Validation loss: 2.49369249572358

Epoch: 5| Step: 11
Training loss: 2.373867065853519
Validation loss: 2.490446042308887

Epoch: 114| Step: 0
Training loss: 2.650497850401028
Validation loss: 2.4857135022018086

Epoch: 5| Step: 1
Training loss: 2.2940714847298853
Validation loss: 2.4911291412319603

Epoch: 5| Step: 2
Training loss: 2.7020432617541696
Validation loss: 2.4881509480276818

Epoch: 5| Step: 3
Training loss: 2.6692676872917183
Validation loss: 2.48456967788655

Epoch: 5| Step: 4
Training loss: 2.845883920721674
Validation loss: 2.487661876475231

Epoch: 5| Step: 5
Training loss: 2.7831385340641024
Validation loss: 2.48466444428688

Epoch: 5| Step: 6
Training loss: 2.4311824995148483
Validation loss: 2.4882114546332756

Epoch: 5| Step: 7
Training loss: 2.645009841323745
Validation loss: 2.481973755190282

Epoch: 5| Step: 8
Training loss: 2.5286850354933543
Validation loss: 2.4861667098204556

Epoch: 5| Step: 9
Training loss: 2.540161270668825
Validation loss: 2.4870160617721297

Epoch: 5| Step: 10
Training loss: 2.341805630652418
Validation loss: 2.485728996511415

Epoch: 5| Step: 11
Training loss: 2.115643716163058
Validation loss: 2.485626589204099

Epoch: 115| Step: 0
Training loss: 2.2846445407306217
Validation loss: 2.4926013543117103

Epoch: 5| Step: 1
Training loss: 3.6324624169775515
Validation loss: 2.4854761278554522

Epoch: 5| Step: 2
Training loss: 2.8813866704934727
Validation loss: 2.4899786564794395

Epoch: 5| Step: 3
Training loss: 2.6495278963577418
Validation loss: 2.485883366834368

Epoch: 5| Step: 4
Training loss: 2.1965564176632895
Validation loss: 2.4827729463877626

Epoch: 5| Step: 5
Training loss: 1.8625211624888975
Validation loss: 2.489944568799642

Epoch: 5| Step: 6
Training loss: 2.814603315762944
Validation loss: 2.487074351195186

Epoch: 5| Step: 7
Training loss: 2.5138147131255058
Validation loss: 2.4831468857521553

Epoch: 5| Step: 8
Training loss: 2.218754405702327
Validation loss: 2.4849232962300816

Epoch: 5| Step: 9
Training loss: 2.4809452590407823
Validation loss: 2.4828699659447486

Epoch: 5| Step: 10
Training loss: 2.4633084940227956
Validation loss: 2.4880994354048807

Epoch: 5| Step: 11
Training loss: 2.2607316414440843
Validation loss: 2.4811114141996287

Epoch: 116| Step: 0
Training loss: 2.5553259562123727
Validation loss: 2.4853443877610606

Epoch: 5| Step: 1
Training loss: 2.187410298279406
Validation loss: 2.485047247441976

Epoch: 5| Step: 2
Training loss: 2.4640007209652923
Validation loss: 2.4841454757772796

Epoch: 5| Step: 3
Training loss: 2.7335352016741075
Validation loss: 2.484385404425053

Epoch: 5| Step: 4
Training loss: 2.576216112383167
Validation loss: 2.4833815045666388

Epoch: 5| Step: 5
Training loss: 3.0721535634958412
Validation loss: 2.484122997274618

Epoch: 5| Step: 6
Training loss: 2.2659849735916637
Validation loss: 2.4845399341975662

Epoch: 5| Step: 7
Training loss: 2.675670226084007
Validation loss: 2.4824726290632917

Epoch: 5| Step: 8
Training loss: 3.1324975671172686
Validation loss: 2.4869115344266657

Epoch: 5| Step: 9
Training loss: 2.347531942164456
Validation loss: 2.4809760748824234

Epoch: 5| Step: 10
Training loss: 2.320714639565463
Validation loss: 2.4805559558507357

Epoch: 5| Step: 11
Training loss: 1.5368199930357045
Validation loss: 2.4833111394513434

Epoch: 117| Step: 0
Training loss: 2.808015936357971
Validation loss: 2.4799558214321147

Epoch: 5| Step: 1
Training loss: 1.8889462292451233
Validation loss: 2.4774447012015317

Epoch: 5| Step: 2
Training loss: 2.942734943820962
Validation loss: 2.4779494420226285

Epoch: 5| Step: 3
Training loss: 2.6149637824444327
Validation loss: 2.4788111837892766

Epoch: 5| Step: 4
Training loss: 2.5847030413002074
Validation loss: 2.4812722053783367

Epoch: 5| Step: 5
Training loss: 2.4266556347956034
Validation loss: 2.480051409037279

Epoch: 5| Step: 6
Training loss: 2.5395970178057583
Validation loss: 2.47810541540475

Epoch: 5| Step: 7
Training loss: 2.207911709056826
Validation loss: 2.4803795826021204

Epoch: 5| Step: 8
Training loss: 2.9054421563404653
Validation loss: 2.4838824713617975

Epoch: 5| Step: 9
Training loss: 2.85452743440649
Validation loss: 2.48318891382684

Epoch: 5| Step: 10
Training loss: 2.295776312016677
Validation loss: 2.48754485455684

Epoch: 5| Step: 11
Training loss: 3.0174125156820906
Validation loss: 2.491656152092768

Epoch: 118| Step: 0
Training loss: 2.4937163539519256
Validation loss: 2.4920190457261215

Epoch: 5| Step: 1
Training loss: 2.2662590455065663
Validation loss: 2.4936210869888726

Epoch: 5| Step: 2
Training loss: 2.8358979866070455
Validation loss: 2.4905532892003515

Epoch: 5| Step: 3
Training loss: 2.390746468842669
Validation loss: 2.4982805935605543

Epoch: 5| Step: 4
Training loss: 2.9095999166740887
Validation loss: 2.4943734231878714

Epoch: 5| Step: 5
Training loss: 2.1611416381710886
Validation loss: 2.493302465577561

Epoch: 5| Step: 6
Training loss: 2.3907506573133754
Validation loss: 2.489379031817924

Epoch: 5| Step: 7
Training loss: 3.0308845535689724
Validation loss: 2.495723798436034

Epoch: 5| Step: 8
Training loss: 2.6284311667331894
Validation loss: 2.4971182625505226

Epoch: 5| Step: 9
Training loss: 2.4800319497296175
Validation loss: 2.4970048645457448

Epoch: 5| Step: 10
Training loss: 2.3636917136120545
Validation loss: 2.490961018179584

Epoch: 5| Step: 11
Training loss: 3.379865459495687
Validation loss: 2.493092303918753

Epoch: 119| Step: 0
Training loss: 2.4969421759629395
Validation loss: 2.4852205732859987

Epoch: 5| Step: 1
Training loss: 2.631384759564563
Validation loss: 2.4852046381023007

Epoch: 5| Step: 2
Training loss: 2.8418012376469948
Validation loss: 2.490389798369234

Epoch: 5| Step: 3
Training loss: 2.6164515129450203
Validation loss: 2.480321400188139

Epoch: 5| Step: 4
Training loss: 2.5953993551383547
Validation loss: 2.4825470555415063

Epoch: 5| Step: 5
Training loss: 2.262191591265705
Validation loss: 2.4794055652649596

Epoch: 5| Step: 6
Training loss: 2.493614434020753
Validation loss: 2.477761424662373

Epoch: 5| Step: 7
Training loss: 2.7107075970260435
Validation loss: 2.4838116404937125

Epoch: 5| Step: 8
Training loss: 2.807879743158274
Validation loss: 2.485411853471195

Epoch: 5| Step: 9
Training loss: 2.607992571264347
Validation loss: 2.4836397862535096

Epoch: 5| Step: 10
Training loss: 2.365640871506213
Validation loss: 2.487869839514813

Epoch: 5| Step: 11
Training loss: 1.4758678598671422
Validation loss: 2.481421728621336

Epoch: 120| Step: 0
Training loss: 2.8249167269696187
Validation loss: 2.4804805004412254

Epoch: 5| Step: 1
Training loss: 2.3734417873240883
Validation loss: 2.481256603164919

Epoch: 5| Step: 2
Training loss: 2.63837332345999
Validation loss: 2.4816923792881687

Epoch: 5| Step: 3
Training loss: 2.9450097371120134
Validation loss: 2.483391629138594

Epoch: 5| Step: 4
Training loss: 2.674530940063908
Validation loss: 2.481824633457831

Epoch: 5| Step: 5
Training loss: 2.6469333394544763
Validation loss: 2.4781808709752973

Epoch: 5| Step: 6
Training loss: 2.447679732740001
Validation loss: 2.4806814708258575

Epoch: 5| Step: 7
Training loss: 2.475603947019058
Validation loss: 2.4811069058107265

Epoch: 5| Step: 8
Training loss: 2.8953164460370946
Validation loss: 2.482910908436669

Epoch: 5| Step: 9
Training loss: 2.3212932735881555
Validation loss: 2.4856910338825444

Epoch: 5| Step: 10
Training loss: 2.278724735892107
Validation loss: 2.478419783763025

Epoch: 5| Step: 11
Training loss: 1.4172681017984876
Validation loss: 2.4800424324592

Epoch: 121| Step: 0
Training loss: 2.8001998659735334
Validation loss: 2.4793295820118417

Epoch: 5| Step: 1
Training loss: 2.4733755502756583
Validation loss: 2.47942886381857

Epoch: 5| Step: 2
Training loss: 2.2754617704475524
Validation loss: 2.481622458656206

Epoch: 5| Step: 3
Training loss: 2.3378877695523497
Validation loss: 2.475548983065475

Epoch: 5| Step: 4
Training loss: 2.579648764011586
Validation loss: 2.4746819103903785

Epoch: 5| Step: 5
Training loss: 2.583080269098354
Validation loss: 2.481374263934795

Epoch: 5| Step: 6
Training loss: 3.35085433200751
Validation loss: 2.476082088352888

Epoch: 5| Step: 7
Training loss: 2.3073905998242843
Validation loss: 2.4830370365158307

Epoch: 5| Step: 8
Training loss: 2.6036709326332796
Validation loss: 2.4874120418773926

Epoch: 5| Step: 9
Training loss: 2.4206871811503436
Validation loss: 2.487883208101022

Epoch: 5| Step: 10
Training loss: 2.657963996350589
Validation loss: 2.4769360033009113

Epoch: 5| Step: 11
Training loss: 1.840069929017293
Validation loss: 2.4801795730835203

Epoch: 122| Step: 0
Training loss: 2.668752619364612
Validation loss: 2.480275140049762

Epoch: 5| Step: 1
Training loss: 2.091832891700902
Validation loss: 2.482858698939037

Epoch: 5| Step: 2
Training loss: 2.500440749417033
Validation loss: 2.4750054576120024

Epoch: 5| Step: 3
Training loss: 2.2753510172920772
Validation loss: 2.483805561183359

Epoch: 5| Step: 4
Training loss: 2.718711677368872
Validation loss: 2.4815633506278654

Epoch: 5| Step: 5
Training loss: 2.4194575888851744
Validation loss: 2.4750108360605614

Epoch: 5| Step: 6
Training loss: 2.8367642965523827
Validation loss: 2.4744843790369706

Epoch: 5| Step: 7
Training loss: 2.7863074621313872
Validation loss: 2.4805186349252994

Epoch: 5| Step: 8
Training loss: 2.1495878711742997
Validation loss: 2.475549978262166

Epoch: 5| Step: 9
Training loss: 2.898985941941966
Validation loss: 2.4807419513824396

Epoch: 5| Step: 10
Training loss: 2.701321303288421
Validation loss: 2.478078147730702

Epoch: 5| Step: 11
Training loss: 2.833821834264549
Validation loss: 2.477243873253432

Epoch: 123| Step: 0
Training loss: 2.5778277601497224
Validation loss: 2.472320574031597

Epoch: 5| Step: 1
Training loss: 2.676597749084926
Validation loss: 2.4747571130823687

Epoch: 5| Step: 2
Training loss: 2.3467068140793255
Validation loss: 2.4704135287796745

Epoch: 5| Step: 3
Training loss: 2.800576685373996
Validation loss: 2.4710049853169753

Epoch: 5| Step: 4
Training loss: 2.3769688727202767
Validation loss: 2.4730482388347377

Epoch: 5| Step: 5
Training loss: 2.6288100249094093
Validation loss: 2.478194925188374

Epoch: 5| Step: 6
Training loss: 2.3154487367744974
Validation loss: 2.476281016706113

Epoch: 5| Step: 7
Training loss: 2.4576927471149017
Validation loss: 2.4803090562252224

Epoch: 5| Step: 8
Training loss: 3.0410509052324874
Validation loss: 2.4744453446063956

Epoch: 5| Step: 9
Training loss: 2.3044409668525363
Validation loss: 2.479425738659862

Epoch: 5| Step: 10
Training loss: 2.602711833207578
Validation loss: 2.4717523691500336

Epoch: 5| Step: 11
Training loss: 2.471143793304283
Validation loss: 2.4698142280872784

Epoch: 124| Step: 0
Training loss: 2.762493019613017
Validation loss: 2.4688559441026046

Epoch: 5| Step: 1
Training loss: 3.021295937381069
Validation loss: 2.4731784648770234

Epoch: 5| Step: 2
Training loss: 2.6462834693691355
Validation loss: 2.4697688853160953

Epoch: 5| Step: 3
Training loss: 2.599879823254804
Validation loss: 2.4735285951246557

Epoch: 5| Step: 4
Training loss: 2.2179885417274208
Validation loss: 2.4749090730295933

Epoch: 5| Step: 5
Training loss: 1.8623758031412065
Validation loss: 2.4769249419212382

Epoch: 5| Step: 6
Training loss: 2.392025207157066
Validation loss: 2.4820631755007967

Epoch: 5| Step: 7
Training loss: 2.6235492875602344
Validation loss: 2.4759563863594782

Epoch: 5| Step: 8
Training loss: 2.786495876356435
Validation loss: 2.4757406032183233

Epoch: 5| Step: 9
Training loss: 2.6840675968464205
Validation loss: 2.479542396560901

Epoch: 5| Step: 10
Training loss: 2.5111594044515435
Validation loss: 2.478427998642375

Epoch: 5| Step: 11
Training loss: 1.5501389410442368
Validation loss: 2.4786245984950486

Epoch: 125| Step: 0
Training loss: 2.3684684888093637
Validation loss: 2.4778338798081356

Epoch: 5| Step: 1
Training loss: 2.4063307513274097
Validation loss: 2.485211865209438

Epoch: 5| Step: 2
Training loss: 2.517975082649887
Validation loss: 2.4795059858781823

Epoch: 5| Step: 3
Training loss: 2.6949723623412094
Validation loss: 2.4810899372184845

Epoch: 5| Step: 4
Training loss: 3.2446177003780345
Validation loss: 2.4746497315787

Epoch: 5| Step: 5
Training loss: 2.3309974104033513
Validation loss: 2.472335726356437

Epoch: 5| Step: 6
Training loss: 2.0943842823866756
Validation loss: 2.4759144943075584

Epoch: 5| Step: 7
Training loss: 2.4622350753562703
Validation loss: 2.482332029400022

Epoch: 5| Step: 8
Training loss: 2.501425718038369
Validation loss: 2.4799562380311047

Epoch: 5| Step: 9
Training loss: 2.5550662818567735
Validation loss: 2.4786152279807863

Epoch: 5| Step: 10
Training loss: 2.858429966248647
Validation loss: 2.4768134710983216

Epoch: 5| Step: 11
Training loss: 2.0289554253612936
Validation loss: 2.481858792635929

Epoch: 126| Step: 0
Training loss: 2.4491491475170406
Validation loss: 2.4773282212101813

Epoch: 5| Step: 1
Training loss: 2.6102727385042854
Validation loss: 2.4802868713820954

Epoch: 5| Step: 2
Training loss: 2.591122870926574
Validation loss: 2.4811627716182842

Epoch: 5| Step: 3
Training loss: 2.99302530138185
Validation loss: 2.4844371579949476

Epoch: 5| Step: 4
Training loss: 2.3641106781522447
Validation loss: 2.4859588101039294

Epoch: 5| Step: 5
Training loss: 2.616744912145947
Validation loss: 2.486310281062716

Epoch: 5| Step: 6
Training loss: 2.788070545053833
Validation loss: 2.4800722260814827

Epoch: 5| Step: 7
Training loss: 2.6961879027338105
Validation loss: 2.4865903314063087

Epoch: 5| Step: 8
Training loss: 2.192209351608116
Validation loss: 2.4844248904610944

Epoch: 5| Step: 9
Training loss: 2.434758331713868
Validation loss: 2.4805832863944146

Epoch: 5| Step: 10
Training loss: 2.611489541336844
Validation loss: 2.4857415893135144

Epoch: 5| Step: 11
Training loss: 0.9903809327989391
Validation loss: 2.488863213721627

Epoch: 127| Step: 0
Training loss: 2.4619628707726258
Validation loss: 2.488906921422391

Epoch: 5| Step: 1
Training loss: 2.580599250692711
Validation loss: 2.4881229599809624

Epoch: 5| Step: 2
Training loss: 2.714116939159021
Validation loss: 2.4899671104472767

Epoch: 5| Step: 3
Training loss: 2.269948162713737
Validation loss: 2.484902052084319

Epoch: 5| Step: 4
Training loss: 2.5477226110645734
Validation loss: 2.4841405250055097

Epoch: 5| Step: 5
Training loss: 2.7693062974745457
Validation loss: 2.483209684566411

Epoch: 5| Step: 6
Training loss: 2.4655393172196343
Validation loss: 2.4843093495521766

Epoch: 5| Step: 7
Training loss: 2.431242319599955
Validation loss: 2.479579367600542

Epoch: 5| Step: 8
Training loss: 2.2628565217577368
Validation loss: 2.477984564651526

Epoch: 5| Step: 9
Training loss: 2.959930812439492
Validation loss: 2.481804119312523

Epoch: 5| Step: 10
Training loss: 2.5484704011422314
Validation loss: 2.481847192817764

Epoch: 5| Step: 11
Training loss: 2.4562464007868132
Validation loss: 2.482151860184529

Epoch: 128| Step: 0
Training loss: 2.7987134634463877
Validation loss: 2.484925618922998

Epoch: 5| Step: 1
Training loss: 2.4783961490485438
Validation loss: 2.4961627797435284

Epoch: 5| Step: 2
Training loss: 2.5993349545240503
Validation loss: 2.50186998048994

Epoch: 5| Step: 3
Training loss: 2.599741438700338
Validation loss: 2.517789083618699

Epoch: 5| Step: 4
Training loss: 2.565993555990023
Validation loss: 2.5274473441273964

Epoch: 5| Step: 5
Training loss: 2.5539352756086617
Validation loss: 2.511162051003721

Epoch: 5| Step: 6
Training loss: 2.8471612277643787
Validation loss: 2.5116039188569603

Epoch: 5| Step: 7
Training loss: 2.174942813866909
Validation loss: 2.4893578476458167

Epoch: 5| Step: 8
Training loss: 2.822659348212431
Validation loss: 2.4848537383668057

Epoch: 5| Step: 9
Training loss: 2.670432789048014
Validation loss: 2.4761471445172876

Epoch: 5| Step: 10
Training loss: 2.3917976445432476
Validation loss: 2.485446930600069

Epoch: 5| Step: 11
Training loss: 3.2609912175139515
Validation loss: 2.482622720240396

Epoch: 129| Step: 0
Training loss: 2.098272421359019
Validation loss: 2.48050886707455

Epoch: 5| Step: 1
Training loss: 2.4931422590115937
Validation loss: 2.478629977106137

Epoch: 5| Step: 2
Training loss: 2.485802294436866
Validation loss: 2.4797300184867606

Epoch: 5| Step: 3
Training loss: 2.1598248908800772
Validation loss: 2.475616900308712

Epoch: 5| Step: 4
Training loss: 2.4311060061140624
Validation loss: 2.482373472992933

Epoch: 5| Step: 5
Training loss: 2.2499756281910286
Validation loss: 2.480642457821953

Epoch: 5| Step: 6
Training loss: 2.8121500433317808
Validation loss: 2.4798109368775725

Epoch: 5| Step: 7
Training loss: 2.8872862633540053
Validation loss: 2.4811256359908693

Epoch: 5| Step: 8
Training loss: 2.5773742507466517
Validation loss: 2.479048727473241

Epoch: 5| Step: 9
Training loss: 2.7626203174194957
Validation loss: 2.48173479825918

Epoch: 5| Step: 10
Training loss: 2.9487695617156295
Validation loss: 2.471296582423719

Epoch: 5| Step: 11
Training loss: 3.002211232651931
Validation loss: 2.4797272182040744

Epoch: 130| Step: 0
Training loss: 2.639991458532214
Validation loss: 2.478787707101147

Epoch: 5| Step: 1
Training loss: 2.3078284633035304
Validation loss: 2.4786711078650265

Epoch: 5| Step: 2
Training loss: 2.4075331796358204
Validation loss: 2.480573881229213

Epoch: 5| Step: 3
Training loss: 2.3768361673284932
Validation loss: 2.4761250307083547

Epoch: 5| Step: 4
Training loss: 2.8042497638635298
Validation loss: 2.479664986213152

Epoch: 5| Step: 5
Training loss: 2.7084856626269525
Validation loss: 2.4770660810990037

Epoch: 5| Step: 6
Training loss: 2.7853078493267565
Validation loss: 2.477731711506333

Epoch: 5| Step: 7
Training loss: 2.067147077077256
Validation loss: 2.470569491384877

Epoch: 5| Step: 8
Training loss: 3.002516326986956
Validation loss: 2.47040576778853

Epoch: 5| Step: 9
Training loss: 2.44185015495633
Validation loss: 2.4752203054989144

Epoch: 5| Step: 10
Training loss: 2.5797722380299124
Validation loss: 2.4783351783407803

Epoch: 5| Step: 11
Training loss: 0.9530420110875313
Validation loss: 2.479821480631077

Epoch: 131| Step: 0
Training loss: 2.714897144259106
Validation loss: 2.4817603725814648

Epoch: 5| Step: 1
Training loss: 2.4893806939008463
Validation loss: 2.482293034333175

Epoch: 5| Step: 2
Training loss: 1.9880169466090782
Validation loss: 2.4816147607413956

Epoch: 5| Step: 3
Training loss: 2.5731176588701032
Validation loss: 2.4842811502768174

Epoch: 5| Step: 4
Training loss: 2.79461817554211
Validation loss: 2.481762181867722

Epoch: 5| Step: 5
Training loss: 2.506192263273499
Validation loss: 2.482964449138556

Epoch: 5| Step: 6
Training loss: 2.476718644956842
Validation loss: 2.485568769415379

Epoch: 5| Step: 7
Training loss: 2.635781083274048
Validation loss: 2.483267095234986

Epoch: 5| Step: 8
Training loss: 2.5279324301429438
Validation loss: 2.4810192228241665

Epoch: 5| Step: 9
Training loss: 2.263866189116066
Validation loss: 2.4752862210896076

Epoch: 5| Step: 10
Training loss: 2.7875007937306187
Validation loss: 2.4729602178923455

Epoch: 5| Step: 11
Training loss: 3.241775376197691
Validation loss: 2.4740110284647634

Epoch: 132| Step: 0
Training loss: 2.329902226602774
Validation loss: 2.47089346050762

Epoch: 5| Step: 1
Training loss: 2.6581213249721096
Validation loss: 2.4733217417525895

Epoch: 5| Step: 2
Training loss: 2.405801607439635
Validation loss: 2.4743085365718795

Epoch: 5| Step: 3
Training loss: 3.3134685036189944
Validation loss: 2.478176457470947

Epoch: 5| Step: 4
Training loss: 2.516915316224487
Validation loss: 2.483849259895144

Epoch: 5| Step: 5
Training loss: 2.487541627775212
Validation loss: 2.4938723430563625

Epoch: 5| Step: 6
Training loss: 2.494807477567793
Validation loss: 2.5006177099354123

Epoch: 5| Step: 7
Training loss: 2.407449002463581
Validation loss: 2.5063739782413132

Epoch: 5| Step: 8
Training loss: 2.5453965277995745
Validation loss: 2.5094830741111376

Epoch: 5| Step: 9
Training loss: 2.3431022257498113
Validation loss: 2.5150875717966965

Epoch: 5| Step: 10
Training loss: 2.7187970036795313
Validation loss: 2.5095126725906924

Epoch: 5| Step: 11
Training loss: 3.4835910342835343
Validation loss: 2.4994993781477994

Epoch: 133| Step: 0
Training loss: 2.5308385443945194
Validation loss: 2.4989711750543853

Epoch: 5| Step: 1
Training loss: 2.9131191659708127
Validation loss: 2.5100463512277287

Epoch: 5| Step: 2
Training loss: 2.62267863855246
Validation loss: 2.5056026621598564

Epoch: 5| Step: 3
Training loss: 2.350007312844444
Validation loss: 2.517610323324939

Epoch: 5| Step: 4
Training loss: 3.0831323162914597
Validation loss: 2.5292585804518377

Epoch: 5| Step: 5
Training loss: 2.894547723679505
Validation loss: 2.528145699716897

Epoch: 5| Step: 6
Training loss: 2.5631722289587127
Validation loss: 2.513279870210458

Epoch: 5| Step: 7
Training loss: 2.5712448330735964
Validation loss: 2.5024603618121

Epoch: 5| Step: 8
Training loss: 2.6738763641843284
Validation loss: 2.4993065269599994

Epoch: 5| Step: 9
Training loss: 2.135601079157649
Validation loss: 2.4856425156878212

Epoch: 5| Step: 10
Training loss: 2.6323734449377203
Validation loss: 2.4908223095145057

Epoch: 5| Step: 11
Training loss: 2.458940549525066
Validation loss: 2.483476116302122

Epoch: 134| Step: 0
Training loss: 2.4748012886809785
Validation loss: 2.4843264481060814

Epoch: 5| Step: 1
Training loss: 2.5627014267072763
Validation loss: 2.4797898171878474

Epoch: 5| Step: 2
Training loss: 2.4952306075921515
Validation loss: 2.480145150450208

Epoch: 5| Step: 3
Training loss: 2.3658333609772355
Validation loss: 2.478975283958607

Epoch: 5| Step: 4
Training loss: 3.020908924779349
Validation loss: 2.4815602261556435

Epoch: 5| Step: 5
Training loss: 3.0943291632567234
Validation loss: 2.475528525264215

Epoch: 5| Step: 6
Training loss: 2.8153534719132454
Validation loss: 2.475370501311593

Epoch: 5| Step: 7
Training loss: 2.2233584188202355
Validation loss: 2.48168610264392

Epoch: 5| Step: 8
Training loss: 2.696394462694527
Validation loss: 2.4831896699296134

Epoch: 5| Step: 9
Training loss: 2.3687492229691895
Validation loss: 2.4757132773970794

Epoch: 5| Step: 10
Training loss: 2.298320600803101
Validation loss: 2.4736631853156847

Epoch: 5| Step: 11
Training loss: 2.6977901846401204
Validation loss: 2.4756122173893265

Epoch: 135| Step: 0
Training loss: 2.5949331136032594
Validation loss: 2.4785451884769882

Epoch: 5| Step: 1
Training loss: 2.3326242482087207
Validation loss: 2.48150503784028

Epoch: 5| Step: 2
Training loss: 2.890492039277392
Validation loss: 2.478145566729089

Epoch: 5| Step: 3
Training loss: 2.2861993479344913
Validation loss: 2.48196309049806

Epoch: 5| Step: 4
Training loss: 2.799703521018436
Validation loss: 2.4800922618708796

Epoch: 5| Step: 5
Training loss: 2.5125360894339424
Validation loss: 2.4814519940911475

Epoch: 5| Step: 6
Training loss: 2.7958211778205
Validation loss: 2.483766261282556

Epoch: 5| Step: 7
Training loss: 2.555775821794535
Validation loss: 2.4803061644768123

Epoch: 5| Step: 8
Training loss: 2.3889738876046214
Validation loss: 2.481621670051367

Epoch: 5| Step: 9
Training loss: 2.744343749432871
Validation loss: 2.483393957264277

Epoch: 5| Step: 10
Training loss: 2.2289408512952957
Validation loss: 2.478185905808083

Epoch: 5| Step: 11
Training loss: 3.0459839129157755
Validation loss: 2.473619740387976

Epoch: 136| Step: 0
Training loss: 2.3444402059885356
Validation loss: 2.472418724973586

Epoch: 5| Step: 1
Training loss: 3.1401403252413784
Validation loss: 2.4629570359370123

Epoch: 5| Step: 2
Training loss: 3.2287659591298112
Validation loss: 2.4576253289027714

Epoch: 5| Step: 3
Training loss: 2.6534114256186347
Validation loss: 2.459532903039773

Epoch: 5| Step: 4
Training loss: 2.0307455757014963
Validation loss: 2.460144704446587

Epoch: 5| Step: 5
Training loss: 2.534250247391968
Validation loss: 2.467737469085845

Epoch: 5| Step: 6
Training loss: 2.491434587453251
Validation loss: 2.4586175064670144

Epoch: 5| Step: 7
Training loss: 2.617479541483648
Validation loss: 2.462306220277382

Epoch: 5| Step: 8
Training loss: 2.0846928801629394
Validation loss: 2.4599575089646177

Epoch: 5| Step: 9
Training loss: 2.773523893488254
Validation loss: 2.460216626544647

Epoch: 5| Step: 10
Training loss: 1.9482896077209848
Validation loss: 2.4625588500386164

Epoch: 5| Step: 11
Training loss: 2.5722528340015116
Validation loss: 2.4568906015026752

Epoch: 137| Step: 0
Training loss: 2.828116654020187
Validation loss: 2.458887734103555

Epoch: 5| Step: 1
Training loss: 2.428659890270736
Validation loss: 2.4603960036902133

Epoch: 5| Step: 2
Training loss: 2.2448628378174944
Validation loss: 2.464032623587233

Epoch: 5| Step: 3
Training loss: 2.96728929422381
Validation loss: 2.4661382307816933

Epoch: 5| Step: 4
Training loss: 2.5410293238605566
Validation loss: 2.4655223059531313

Epoch: 5| Step: 5
Training loss: 2.7157185633863534
Validation loss: 2.469332276256876

Epoch: 5| Step: 6
Training loss: 2.4312534008639752
Validation loss: 2.4696231778670326

Epoch: 5| Step: 7
Training loss: 2.5097452956983077
Validation loss: 2.469913353423393

Epoch: 5| Step: 8
Training loss: 2.5367951114064886
Validation loss: 2.472388463437593

Epoch: 5| Step: 9
Training loss: 2.6786119621479716
Validation loss: 2.465047135705213

Epoch: 5| Step: 10
Training loss: 2.1441034053519425
Validation loss: 2.469401756398488

Epoch: 5| Step: 11
Training loss: 2.1556898854644424
Validation loss: 2.470229244900255

Epoch: 138| Step: 0
Training loss: 2.3351312477098074
Validation loss: 2.470654280309136

Epoch: 5| Step: 1
Training loss: 2.2391207786583727
Validation loss: 2.467860552557571

Epoch: 5| Step: 2
Training loss: 2.3661669051245084
Validation loss: 2.4645869609476083

Epoch: 5| Step: 3
Training loss: 2.8304396793937374
Validation loss: 2.4674978782943575

Epoch: 5| Step: 4
Training loss: 2.312474018672671
Validation loss: 2.4639212024970507

Epoch: 5| Step: 5
Training loss: 3.043478456639349
Validation loss: 2.471730043201501

Epoch: 5| Step: 6
Training loss: 2.4020202915182622
Validation loss: 2.4618733397781107

Epoch: 5| Step: 7
Training loss: 2.4803152442350775
Validation loss: 2.463492960915491

Epoch: 5| Step: 8
Training loss: 3.017197747314373
Validation loss: 2.4591810992597414

Epoch: 5| Step: 9
Training loss: 2.4868801130504443
Validation loss: 2.46038338614191

Epoch: 5| Step: 10
Training loss: 2.446489044969497
Validation loss: 2.462137109542866

Epoch: 5| Step: 11
Training loss: 1.8323579346465666
Validation loss: 2.4585175095010228

Epoch: 139| Step: 0
Training loss: 2.7869654874276417
Validation loss: 2.459783652937567

Epoch: 5| Step: 1
Training loss: 2.1651498424663433
Validation loss: 2.460360327152853

Epoch: 5| Step: 2
Training loss: 2.5789371945091366
Validation loss: 2.458314137195274

Epoch: 5| Step: 3
Training loss: 1.7925587436728043
Validation loss: 2.4576762070064717

Epoch: 5| Step: 4
Training loss: 2.920883418446007
Validation loss: 2.469873997380463

Epoch: 5| Step: 5
Training loss: 2.5379752780440734
Validation loss: 2.4668786686464963

Epoch: 5| Step: 6
Training loss: 2.5728548688584234
Validation loss: 2.4701943015562557

Epoch: 5| Step: 7
Training loss: 2.6418827830900073
Validation loss: 2.464991045710541

Epoch: 5| Step: 8
Training loss: 2.4065198870815396
Validation loss: 2.4656606792484093

Epoch: 5| Step: 9
Training loss: 2.9357492627130997
Validation loss: 2.4654306034542857

Epoch: 5| Step: 10
Training loss: 2.434124884041663
Validation loss: 2.4625951038591474

Epoch: 5| Step: 11
Training loss: 2.347347601025524
Validation loss: 2.4615962827019833

Epoch: 140| Step: 0
Training loss: 1.6904538757250904
Validation loss: 2.45718566659976

Epoch: 5| Step: 1
Training loss: 2.6624976789437507
Validation loss: 2.4618707935768303

Epoch: 5| Step: 2
Training loss: 3.073634245974518
Validation loss: 2.457211126506389

Epoch: 5| Step: 3
Training loss: 1.993094323903982
Validation loss: 2.465279763777624

Epoch: 5| Step: 4
Training loss: 2.4871342529087945
Validation loss: 2.4558118473884734

Epoch: 5| Step: 5
Training loss: 2.9040931163287627
Validation loss: 2.458754565362873

Epoch: 5| Step: 6
Training loss: 2.3508207348911134
Validation loss: 2.4560202098774964

Epoch: 5| Step: 7
Training loss: 3.110599142668047
Validation loss: 2.457179462792147

Epoch: 5| Step: 8
Training loss: 2.588780986281783
Validation loss: 2.453542570547092

Epoch: 5| Step: 9
Training loss: 2.3127369114945933
Validation loss: 2.4624687436503527

Epoch: 5| Step: 10
Training loss: 2.4270926108339874
Validation loss: 2.4549268677456797

Epoch: 5| Step: 11
Training loss: 2.2438078551417675
Validation loss: 2.4577008069416735

Epoch: 141| Step: 0
Training loss: 3.118921089448566
Validation loss: 2.4529519273160947

Epoch: 5| Step: 1
Training loss: 2.0901827813490956
Validation loss: 2.462806347285601

Epoch: 5| Step: 2
Training loss: 2.588749120574905
Validation loss: 2.4612750028854964

Epoch: 5| Step: 3
Training loss: 2.4177219345014804
Validation loss: 2.4695623807585187

Epoch: 5| Step: 4
Training loss: 2.328550875838011
Validation loss: 2.473534771983994

Epoch: 5| Step: 5
Training loss: 2.660773341546673
Validation loss: 2.474545633307519

Epoch: 5| Step: 6
Training loss: 2.4489950415552113
Validation loss: 2.479193880962952

Epoch: 5| Step: 7
Training loss: 2.773616043576298
Validation loss: 2.483191070119327

Epoch: 5| Step: 8
Training loss: 2.842945362318784
Validation loss: 2.4796766763638

Epoch: 5| Step: 9
Training loss: 2.297986442864569
Validation loss: 2.478151736089178

Epoch: 5| Step: 10
Training loss: 2.4344586692211467
Validation loss: 2.4832372639355484

Epoch: 5| Step: 11
Training loss: 2.7735381631984994
Validation loss: 2.482350202076493

Epoch: 142| Step: 0
Training loss: 2.3572881703358566
Validation loss: 2.473037521592864

Epoch: 5| Step: 1
Training loss: 2.7034447982454988
Validation loss: 2.4655313112213366

Epoch: 5| Step: 2
Training loss: 2.691307298588058
Validation loss: 2.460353378323896

Epoch: 5| Step: 3
Training loss: 3.1240310692701403
Validation loss: 2.4644785961705815

Epoch: 5| Step: 4
Training loss: 2.594488751098689
Validation loss: 2.4691573221448477

Epoch: 5| Step: 5
Training loss: 2.2539784966960346
Validation loss: 2.467494524647243

Epoch: 5| Step: 6
Training loss: 2.5681724103170662
Validation loss: 2.469642723212081

Epoch: 5| Step: 7
Training loss: 2.9364969691919045
Validation loss: 2.470474956365443

Epoch: 5| Step: 8
Training loss: 2.34019444660323
Validation loss: 2.470148165450684

Epoch: 5| Step: 9
Training loss: 2.0451438513715203
Validation loss: 2.4668168857192723

Epoch: 5| Step: 10
Training loss: 2.393351975459581
Validation loss: 2.4656781629625537

Epoch: 5| Step: 11
Training loss: 1.6460526557648565
Validation loss: 2.4650476273635555

Epoch: 143| Step: 0
Training loss: 2.429554632055851
Validation loss: 2.465420719414387

Epoch: 5| Step: 1
Training loss: 2.3513737092639433
Validation loss: 2.4633493986904984

Epoch: 5| Step: 2
Training loss: 2.766331641659754
Validation loss: 2.4659763198701996

Epoch: 5| Step: 3
Training loss: 2.382109291247057
Validation loss: 2.463924887585446

Epoch: 5| Step: 4
Training loss: 2.221783672875556
Validation loss: 2.466080050747521

Epoch: 5| Step: 5
Training loss: 2.7470290000892863
Validation loss: 2.4679354760516254

Epoch: 5| Step: 6
Training loss: 2.345306896632526
Validation loss: 2.4724318335701803

Epoch: 5| Step: 7
Training loss: 3.165009533474562
Validation loss: 2.471059149822406

Epoch: 5| Step: 8
Training loss: 2.701843751880633
Validation loss: 2.4708834978085745

Epoch: 5| Step: 9
Training loss: 2.0009140071892793
Validation loss: 2.468386876888314

Epoch: 5| Step: 10
Training loss: 2.5701364381545933
Validation loss: 2.4724421878056253

Epoch: 5| Step: 11
Training loss: 2.717450587745503
Validation loss: 2.4660208300148807

Epoch: 144| Step: 0
Training loss: 2.507490571176405
Validation loss: 2.4766653944074704

Epoch: 5| Step: 1
Training loss: 2.439662170005032
Validation loss: 2.4707868880998825

Epoch: 5| Step: 2
Training loss: 2.230858015575339
Validation loss: 2.4697287124457503

Epoch: 5| Step: 3
Training loss: 2.862516251563702
Validation loss: 2.4685430138166526

Epoch: 5| Step: 4
Training loss: 2.7557022623092093
Validation loss: 2.470491378616528

Epoch: 5| Step: 5
Training loss: 2.6467181450892494
Validation loss: 2.4688161527244934

Epoch: 5| Step: 6
Training loss: 2.807505177792864
Validation loss: 2.4659661640806725

Epoch: 5| Step: 7
Training loss: 2.3800446991770063
Validation loss: 2.4751687043744814

Epoch: 5| Step: 8
Training loss: 2.6622519507399653
Validation loss: 2.471911385964057

Epoch: 5| Step: 9
Training loss: 2.4286169901348647
Validation loss: 2.480287756536705

Epoch: 5| Step: 10
Training loss: 2.2078927038355807
Validation loss: 2.475859565334821

Epoch: 5| Step: 11
Training loss: 1.878309254168992
Validation loss: 2.472273553417759

Epoch: 145| Step: 0
Training loss: 2.4953721127110473
Validation loss: 2.477560397848052

Epoch: 5| Step: 1
Training loss: 2.4951320938889365
Validation loss: 2.474114669411023

Epoch: 5| Step: 2
Training loss: 2.493871807288122
Validation loss: 2.4749488467250984

Epoch: 5| Step: 3
Training loss: 2.3091917344651605
Validation loss: 2.472653397512774

Epoch: 5| Step: 4
Training loss: 2.6211825269056463
Validation loss: 2.4772622356399427

Epoch: 5| Step: 5
Training loss: 2.9052291225611855
Validation loss: 2.4750397871653402

Epoch: 5| Step: 6
Training loss: 1.8581538959082227
Validation loss: 2.47701201586221

Epoch: 5| Step: 7
Training loss: 2.471008619638474
Validation loss: 2.4768147585782647

Epoch: 5| Step: 8
Training loss: 2.6659975603211237
Validation loss: 2.4721027415641195

Epoch: 5| Step: 9
Training loss: 3.0648368172198865
Validation loss: 2.4664350593148243

Epoch: 5| Step: 10
Training loss: 2.524352389085852
Validation loss: 2.4669498085100914

Epoch: 5| Step: 11
Training loss: 0.6538954457036477
Validation loss: 2.468014406315455

Epoch: 146| Step: 0
Training loss: 2.494358564039279
Validation loss: 2.4743157031624152

Epoch: 5| Step: 1
Training loss: 2.352371634245539
Validation loss: 2.462914418592886

Epoch: 5| Step: 2
Training loss: 2.3997960917953103
Validation loss: 2.4600209744587893

Epoch: 5| Step: 3
Training loss: 2.405566527165664
Validation loss: 2.459234784955008

Epoch: 5| Step: 4
Training loss: 2.5647079445763215
Validation loss: 2.464412959883001

Epoch: 5| Step: 5
Training loss: 2.9543307633192053
Validation loss: 2.4669312847988536

Epoch: 5| Step: 6
Training loss: 2.40200182954844
Validation loss: 2.4590281108171417

Epoch: 5| Step: 7
Training loss: 2.228757291857846
Validation loss: 2.461090478734068

Epoch: 5| Step: 8
Training loss: 2.257608160256143
Validation loss: 2.4678379377986537

Epoch: 5| Step: 9
Training loss: 2.9907015703976065
Validation loss: 2.4594978683135698

Epoch: 5| Step: 10
Training loss: 2.8102098253587267
Validation loss: 2.46090474586286

Epoch: 5| Step: 11
Training loss: 1.2299246417585539
Validation loss: 2.4614333970115334

Epoch: 147| Step: 0
Training loss: 2.3247875895941457
Validation loss: 2.465681478790656

Epoch: 5| Step: 1
Training loss: 2.828829345669149
Validation loss: 2.45743100664832

Epoch: 5| Step: 2
Training loss: 2.8311692182119526
Validation loss: 2.457446448860603

Epoch: 5| Step: 3
Training loss: 2.8113120219172427
Validation loss: 2.463971789328599

Epoch: 5| Step: 4
Training loss: 2.6008796597646797
Validation loss: 2.460516943141144

Epoch: 5| Step: 5
Training loss: 2.6832056556164368
Validation loss: 2.463088594083871

Epoch: 5| Step: 6
Training loss: 2.588352147820209
Validation loss: 2.4563296094034373

Epoch: 5| Step: 7
Training loss: 2.5082262119810386
Validation loss: 2.462054044745451

Epoch: 5| Step: 8
Training loss: 2.3525899372482653
Validation loss: 2.462468267613937

Epoch: 5| Step: 9
Training loss: 2.1966103623641153
Validation loss: 2.4642886117525884

Epoch: 5| Step: 10
Training loss: 2.102881035676417
Validation loss: 2.4598675778653694

Epoch: 5| Step: 11
Training loss: 1.4723308821031547
Validation loss: 2.4639709184713916

Epoch: 148| Step: 0
Training loss: 2.6346596596846026
Validation loss: 2.4670952188387743

Epoch: 5| Step: 1
Training loss: 1.6487912345397808
Validation loss: 2.4647189641238545

Epoch: 5| Step: 2
Training loss: 3.0236161842083624
Validation loss: 2.4562056285872145

Epoch: 5| Step: 3
Training loss: 2.559518149148928
Validation loss: 2.4590700319948593

Epoch: 5| Step: 4
Training loss: 2.428484358148307
Validation loss: 2.4631063561942654

Epoch: 5| Step: 5
Training loss: 2.1201828604234354
Validation loss: 2.4583125046208663

Epoch: 5| Step: 6
Training loss: 2.502748504403498
Validation loss: 2.4618096819384063

Epoch: 5| Step: 7
Training loss: 2.983857754126827
Validation loss: 2.4636231839737515

Epoch: 5| Step: 8
Training loss: 2.488360776483762
Validation loss: 2.4558767326303435

Epoch: 5| Step: 9
Training loss: 2.555012440212594
Validation loss: 2.4591716970732467

Epoch: 5| Step: 10
Training loss: 2.728475254991705
Validation loss: 2.463485960434738

Epoch: 5| Step: 11
Training loss: 1.88151195134471
Validation loss: 2.4643127586856544

Epoch: 149| Step: 0
Training loss: 2.9342329646988645
Validation loss: 2.4654934566397824

Epoch: 5| Step: 1
Training loss: 2.3123393647359634
Validation loss: 2.469023508300664

Epoch: 5| Step: 2
Training loss: 2.214823081914149
Validation loss: 2.4615146081383648

Epoch: 5| Step: 3
Training loss: 2.065371046744381
Validation loss: 2.463801067209486

Epoch: 5| Step: 4
Training loss: 2.5138455370214547
Validation loss: 2.461322391020818

Epoch: 5| Step: 5
Training loss: 2.6836750401341103
Validation loss: 2.4594570571155314

Epoch: 5| Step: 6
Training loss: 2.503851403455472
Validation loss: 2.4562993013127277

Epoch: 5| Step: 7
Training loss: 2.5222738789586856
Validation loss: 2.4612358820632854

Epoch: 5| Step: 8
Training loss: 2.5101547948819407
Validation loss: 2.4621855664123595

Epoch: 5| Step: 9
Training loss: 2.865040320733499
Validation loss: 2.4632505657536483

Epoch: 5| Step: 10
Training loss: 2.5240766820004996
Validation loss: 2.462135556163664

Epoch: 5| Step: 11
Training loss: 2.591413065614153
Validation loss: 2.462007635048959

Epoch: 150| Step: 0
Training loss: 2.390272326416719
Validation loss: 2.4700700393584474

Epoch: 5| Step: 1
Training loss: 2.760195472540099
Validation loss: 2.4664969565244332

Epoch: 5| Step: 2
Training loss: 2.136928178471965
Validation loss: 2.4701808090866395

Epoch: 5| Step: 3
Training loss: 2.929874994000384
Validation loss: 2.4728633920404532

Epoch: 5| Step: 4
Training loss: 2.323000805162084
Validation loss: 2.464107199847821

Epoch: 5| Step: 5
Training loss: 2.587450765979834
Validation loss: 2.4678630764774043

Epoch: 5| Step: 6
Training loss: 2.602729695908624
Validation loss: 2.4719151073663044

Epoch: 5| Step: 7
Training loss: 2.476374766457564
Validation loss: 2.469244975756778

Epoch: 5| Step: 8
Training loss: 2.2953967053656896
Validation loss: 2.4639013295347576

Epoch: 5| Step: 9
Training loss: 2.5951612379076807
Validation loss: 2.46070505083861

Epoch: 5| Step: 10
Training loss: 2.7063947537584734
Validation loss: 2.457660770279926

Epoch: 5| Step: 11
Training loss: 2.0611682406948186
Validation loss: 2.4553364102202493

Epoch: 151| Step: 0
Training loss: 2.833512711924062
Validation loss: 2.457666942556926

Epoch: 5| Step: 1
Training loss: 3.0361515018824097
Validation loss: 2.4616510719092894

Epoch: 5| Step: 2
Training loss: 2.745092434603582
Validation loss: 2.455488868086411

Epoch: 5| Step: 3
Training loss: 2.580943653317825
Validation loss: 2.466161541887074

Epoch: 5| Step: 4
Training loss: 1.913552601685599
Validation loss: 2.465820207753195

Epoch: 5| Step: 5
Training loss: 2.279689516376443
Validation loss: 2.4614587423545142

Epoch: 5| Step: 6
Training loss: 2.6681069021355093
Validation loss: 2.4621356005459405

Epoch: 5| Step: 7
Training loss: 2.3904795882936
Validation loss: 2.4558699935927035

Epoch: 5| Step: 8
Training loss: 2.603067964842609
Validation loss: 2.46152651161398

Epoch: 5| Step: 9
Training loss: 2.167663332759087
Validation loss: 2.4583567857970627

Epoch: 5| Step: 10
Training loss: 2.335685997121282
Validation loss: 2.454183321854747

Epoch: 5| Step: 11
Training loss: 2.7889960785978753
Validation loss: 2.4586381332646887

Epoch: 152| Step: 0
Training loss: 3.074988611711953
Validation loss: 2.455908340330827

Epoch: 5| Step: 1
Training loss: 2.4337504965571526
Validation loss: 2.45507646599559

Epoch: 5| Step: 2
Training loss: 2.307165436632091
Validation loss: 2.4620170566674022

Epoch: 5| Step: 3
Training loss: 2.60423888042779
Validation loss: 2.4556198068798336

Epoch: 5| Step: 4
Training loss: 2.87504063453154
Validation loss: 2.45189535905429

Epoch: 5| Step: 5
Training loss: 2.825631238242395
Validation loss: 2.454591211688271

Epoch: 5| Step: 6
Training loss: 2.394407185114395
Validation loss: 2.457546517703797

Epoch: 5| Step: 7
Training loss: 1.8808466989123729
Validation loss: 2.452152545398354

Epoch: 5| Step: 8
Training loss: 2.2599413909739354
Validation loss: 2.455299215748145

Epoch: 5| Step: 9
Training loss: 2.5526748802064207
Validation loss: 2.4650195623811904

Epoch: 5| Step: 10
Training loss: 2.3648809394142827
Validation loss: 2.4568719291683996

Epoch: 5| Step: 11
Training loss: 2.35401884531987
Validation loss: 2.4566686956090154

Epoch: 153| Step: 0
Training loss: 2.728769365662214
Validation loss: 2.4588508721213533

Epoch: 5| Step: 1
Training loss: 2.0415447224640464
Validation loss: 2.462462430109054

Epoch: 5| Step: 2
Training loss: 2.5195197053393454
Validation loss: 2.4575709653318105

Epoch: 5| Step: 3
Training loss: 2.7136305918311945
Validation loss: 2.454973755254005

Epoch: 5| Step: 4
Training loss: 2.4232037252566903
Validation loss: 2.455840824591692

Epoch: 5| Step: 5
Training loss: 2.514047258234853
Validation loss: 2.4562434038651206

Epoch: 5| Step: 6
Training loss: 2.6407447200925684
Validation loss: 2.4599739045087454

Epoch: 5| Step: 7
Training loss: 2.701046359441476
Validation loss: 2.4677536116622463

Epoch: 5| Step: 8
Training loss: 2.4910930275163796
Validation loss: 2.459445173917703

Epoch: 5| Step: 9
Training loss: 2.523786963484526
Validation loss: 2.4655219433241924

Epoch: 5| Step: 10
Training loss: 2.065728983375498
Validation loss: 2.470762205359892

Epoch: 5| Step: 11
Training loss: 3.4067323675619625
Validation loss: 2.4679216411587026

Epoch: 154| Step: 0
Training loss: 2.425783510560289
Validation loss: 2.4684906231758306

Epoch: 5| Step: 1
Training loss: 2.3242365988679143
Validation loss: 2.471751058937922

Epoch: 5| Step: 2
Training loss: 2.636590889550342
Validation loss: 2.464817669665503

Epoch: 5| Step: 3
Training loss: 2.645262038261638
Validation loss: 2.4711698108938758

Epoch: 5| Step: 4
Training loss: 2.6403548424118406
Validation loss: 2.470683805166507

Epoch: 5| Step: 5
Training loss: 2.637781632559935
Validation loss: 2.476633225322597

Epoch: 5| Step: 6
Training loss: 2.7297670611538267
Validation loss: 2.469714302343284

Epoch: 5| Step: 7
Training loss: 2.034979814433993
Validation loss: 2.4765131812093686

Epoch: 5| Step: 8
Training loss: 2.158899089743104
Validation loss: 2.474433589593983

Epoch: 5| Step: 9
Training loss: 2.8535747796101556
Validation loss: 2.476658727980564

Epoch: 5| Step: 10
Training loss: 2.5303958346445663
Validation loss: 2.4669097105402664

Epoch: 5| Step: 11
Training loss: 1.8104957153598302
Validation loss: 2.4715982496816276

Epoch: 155| Step: 0
Training loss: 2.6075059970044294
Validation loss: 2.477986260435301

Epoch: 5| Step: 1
Training loss: 2.2969237860863725
Validation loss: 2.4738692230773442

Epoch: 5| Step: 2
Training loss: 2.862368158361014
Validation loss: 2.4742104264699405

Epoch: 5| Step: 3
Training loss: 2.8372602924479895
Validation loss: 2.472302456213404

Epoch: 5| Step: 4
Training loss: 2.3342531185172213
Validation loss: 2.478005479236977

Epoch: 5| Step: 5
Training loss: 2.3767367588138617
Validation loss: 2.471983719214021

Epoch: 5| Step: 6
Training loss: 1.9210324184933012
Validation loss: 2.472104156070389

Epoch: 5| Step: 7
Training loss: 2.528607814410028
Validation loss: 2.4666910277164606

Epoch: 5| Step: 8
Training loss: 2.3649865925511664
Validation loss: 2.468008839538341

Epoch: 5| Step: 9
Training loss: 2.532233153252607
Validation loss: 2.457051324080078

Epoch: 5| Step: 10
Training loss: 2.7974141203351777
Validation loss: 2.4766905517846833

Epoch: 5| Step: 11
Training loss: 2.339417585942804
Validation loss: 2.476839044094807

Epoch: 156| Step: 0
Training loss: 2.4972122862149897
Validation loss: 2.476939789345551

Epoch: 5| Step: 1
Training loss: 2.4088693209334693
Validation loss: 2.4742163547014036

Epoch: 5| Step: 2
Training loss: 2.0693746493842435
Validation loss: 2.474729507448792

Epoch: 5| Step: 3
Training loss: 2.62293634586562
Validation loss: 2.4767046746199415

Epoch: 5| Step: 4
Training loss: 2.5141409530395245
Validation loss: 2.4816029115902882

Epoch: 5| Step: 5
Training loss: 2.4118913189013917
Validation loss: 2.480405050746385

Epoch: 5| Step: 6
Training loss: 2.6905856494041935
Validation loss: 2.4751743794671826

Epoch: 5| Step: 7
Training loss: 2.8604147432954736
Validation loss: 2.4745540035629507

Epoch: 5| Step: 8
Training loss: 2.273724095478521
Validation loss: 2.4733855832648293

Epoch: 5| Step: 9
Training loss: 2.6161760339975286
Validation loss: 2.4688739101684405

Epoch: 5| Step: 10
Training loss: 2.755353658169073
Validation loss: 2.46737994634705

Epoch: 5| Step: 11
Training loss: 2.058022233359127
Validation loss: 2.4653014429654956

Epoch: 157| Step: 0
Training loss: 2.4650337158125795
Validation loss: 2.460935041638312

Epoch: 5| Step: 1
Training loss: 2.794602221877333
Validation loss: 2.4612069118713307

Epoch: 5| Step: 2
Training loss: 2.6132102694372836
Validation loss: 2.463317202906476

Epoch: 5| Step: 3
Training loss: 2.239687173491271
Validation loss: 2.4586642205622415

Epoch: 5| Step: 4
Training loss: 2.581905206094061
Validation loss: 2.4626745158932515

Epoch: 5| Step: 5
Training loss: 2.542608138853904
Validation loss: 2.4564385985589317

Epoch: 5| Step: 6
Training loss: 2.3185142458934007
Validation loss: 2.458507066315173

Epoch: 5| Step: 7
Training loss: 2.366194009818732
Validation loss: 2.4594329190573583

Epoch: 5| Step: 8
Training loss: 2.651906669907687
Validation loss: 2.4608023227925617

Epoch: 5| Step: 9
Training loss: 2.626217786690331
Validation loss: 2.454090669412721

Epoch: 5| Step: 10
Training loss: 2.555423268980832
Validation loss: 2.4634711569332555

Epoch: 5| Step: 11
Training loss: 1.361825641369614
Validation loss: 2.4566428722068636

Epoch: 158| Step: 0
Training loss: 3.326974589354853
Validation loss: 2.455582705701739

Epoch: 5| Step: 1
Training loss: 2.3731625124538684
Validation loss: 2.4614061868002834

Epoch: 5| Step: 2
Training loss: 2.526318679774455
Validation loss: 2.4570779477580573

Epoch: 5| Step: 3
Training loss: 2.465746634109646
Validation loss: 2.463641188199411

Epoch: 5| Step: 4
Training loss: 2.167947964955262
Validation loss: 2.459422873580808

Epoch: 5| Step: 5
Training loss: 2.247853526824615
Validation loss: 2.4611080736254434

Epoch: 5| Step: 6
Training loss: 2.398845426679993
Validation loss: 2.4588950628009303

Epoch: 5| Step: 7
Training loss: 2.7491955881099748
Validation loss: 2.4662909755406033

Epoch: 5| Step: 8
Training loss: 2.284227909722383
Validation loss: 2.466670125935251

Epoch: 5| Step: 9
Training loss: 2.5144406012412404
Validation loss: 2.472130428769823

Epoch: 5| Step: 10
Training loss: 2.345631264023379
Validation loss: 2.467989728048908

Epoch: 5| Step: 11
Training loss: 2.5570041989563146
Validation loss: 2.459901585606856

Epoch: 159| Step: 0
Training loss: 2.0835697294265945
Validation loss: 2.4652100264204595

Epoch: 5| Step: 1
Training loss: 2.10901893153586
Validation loss: 2.4657630475637053

Epoch: 5| Step: 2
Training loss: 3.0138541442774756
Validation loss: 2.475189534389298

Epoch: 5| Step: 3
Training loss: 2.4471717079694537
Validation loss: 2.463070660433516

Epoch: 5| Step: 4
Training loss: 2.4025986947102687
Validation loss: 2.4666362638683346

Epoch: 5| Step: 5
Training loss: 2.671542587571962
Validation loss: 2.464829200504202

Epoch: 5| Step: 6
Training loss: 2.429790825808641
Validation loss: 2.455735924968677

Epoch: 5| Step: 7
Training loss: 2.484145147858938
Validation loss: 2.46325111826446

Epoch: 5| Step: 8
Training loss: 2.745701117412394
Validation loss: 2.471415280121428

Epoch: 5| Step: 9
Training loss: 2.4691114523210884
Validation loss: 2.468294576494741

Epoch: 5| Step: 10
Training loss: 2.6379424243859075
Validation loss: 2.4688012202297256

Epoch: 5| Step: 11
Training loss: 2.2243457132219153
Validation loss: 2.459153561153757

Epoch: 160| Step: 0
Training loss: 2.2519398909723347
Validation loss: 2.473512562528311

Epoch: 5| Step: 1
Training loss: 2.418544029120553
Validation loss: 2.46282888723826

Epoch: 5| Step: 2
Training loss: 2.497264032528968
Validation loss: 2.4732396109085903

Epoch: 5| Step: 3
Training loss: 2.6533806955081682
Validation loss: 2.472335879044467

Epoch: 5| Step: 4
Training loss: 2.6571287608908087
Validation loss: 2.4695519380186632

Epoch: 5| Step: 5
Training loss: 2.929022873830514
Validation loss: 2.4716565731298643

Epoch: 5| Step: 6
Training loss: 2.327617718007066
Validation loss: 2.481749556864867

Epoch: 5| Step: 7
Training loss: 2.760485685433348
Validation loss: 2.4782267452998497

Epoch: 5| Step: 8
Training loss: 1.9706512232619695
Validation loss: 2.4798764059715044

Epoch: 5| Step: 9
Training loss: 2.3050533715480026
Validation loss: 2.482344887552853

Epoch: 5| Step: 10
Training loss: 2.5116028469746956
Validation loss: 2.4727120616654505

Epoch: 5| Step: 11
Training loss: 2.5850002284391143
Validation loss: 2.473381225466286

Epoch: 161| Step: 0
Training loss: 1.88503264280028
Validation loss: 2.473605499538468

Epoch: 5| Step: 1
Training loss: 2.574832640459044
Validation loss: 2.480612418752431

Epoch: 5| Step: 2
Training loss: 2.680801026783345
Validation loss: 2.4706930851386817

Epoch: 5| Step: 3
Training loss: 2.4585257201696793
Validation loss: 2.4720731974868193

Epoch: 5| Step: 4
Training loss: 2.5240726203144095
Validation loss: 2.4687459036233776

Epoch: 5| Step: 5
Training loss: 2.144961899283398
Validation loss: 2.478359200441589

Epoch: 5| Step: 6
Training loss: 2.6512454291218406
Validation loss: 2.4729237263639527

Epoch: 5| Step: 7
Training loss: 2.067240151955189
Validation loss: 2.467654355286588

Epoch: 5| Step: 8
Training loss: 2.3089651980480603
Validation loss: 2.467823917188122

Epoch: 5| Step: 9
Training loss: 3.054556216957899
Validation loss: 2.4743144183970114

Epoch: 5| Step: 10
Training loss: 2.741046113704553
Validation loss: 2.4626734872563305

Epoch: 5| Step: 11
Training loss: 3.1649857292636994
Validation loss: 2.4675838194823623

Epoch: 162| Step: 0
Training loss: 2.7285729458903827
Validation loss: 2.4700476057018395

Epoch: 5| Step: 1
Training loss: 2.5032492503213937
Validation loss: 2.4620765915853307

Epoch: 5| Step: 2
Training loss: 1.8351472493060992
Validation loss: 2.4697068569231346

Epoch: 5| Step: 3
Training loss: 2.667726117518821
Validation loss: 2.4662043286925286

Epoch: 5| Step: 4
Training loss: 2.568309896594464
Validation loss: 2.4604062793737453

Epoch: 5| Step: 5
Training loss: 3.030935684110737
Validation loss: 2.470918797263435

Epoch: 5| Step: 6
Training loss: 2.2781157191209167
Validation loss: 2.472765614289141

Epoch: 5| Step: 7
Training loss: 2.5717190775183583
Validation loss: 2.4623276270969874

Epoch: 5| Step: 8
Training loss: 2.40836053412717
Validation loss: 2.470095066842109

Epoch: 5| Step: 9
Training loss: 2.5913351376390406
Validation loss: 2.4807703670839554

Epoch: 5| Step: 10
Training loss: 2.3216599170981955
Validation loss: 2.476191066642095

Epoch: 5| Step: 11
Training loss: 1.9105262943985186
Validation loss: 2.480120452697501

Epoch: 163| Step: 0
Training loss: 2.6839698849962708
Validation loss: 2.477373201068264

Epoch: 5| Step: 1
Training loss: 2.475276480750877
Validation loss: 2.4770516194355245

Epoch: 5| Step: 2
Training loss: 2.1888307066132673
Validation loss: 2.4801649012655353

Epoch: 5| Step: 3
Training loss: 1.9464089853843694
Validation loss: 2.4808885334271262

Epoch: 5| Step: 4
Training loss: 2.7269469594018267
Validation loss: 2.4761516860080306

Epoch: 5| Step: 5
Training loss: 2.654292563462282
Validation loss: 2.475411874845351

Epoch: 5| Step: 6
Training loss: 2.652049614351591
Validation loss: 2.4665766597824508

Epoch: 5| Step: 7
Training loss: 2.7719906753779537
Validation loss: 2.474996235953786

Epoch: 5| Step: 8
Training loss: 2.1204243933347686
Validation loss: 2.466422017526075

Epoch: 5| Step: 9
Training loss: 2.2387289028994757
Validation loss: 2.4722401096527924

Epoch: 5| Step: 10
Training loss: 2.9204896304732295
Validation loss: 2.4714814338568103

Epoch: 5| Step: 11
Training loss: 2.021699490365891
Validation loss: 2.4755222610821583

Epoch: 164| Step: 0
Training loss: 2.712316332808766
Validation loss: 2.481690369803026

Epoch: 5| Step: 1
Training loss: 2.010289664201799
Validation loss: 2.488937646672326

Epoch: 5| Step: 2
Training loss: 2.771125366959777
Validation loss: 2.519210179889338

Epoch: 5| Step: 3
Training loss: 2.369185105273397
Validation loss: 2.488447578017264

Epoch: 5| Step: 4
Training loss: 2.4850124285135764
Validation loss: 2.4797459588053647

Epoch: 5| Step: 5
Training loss: 2.611892490844144
Validation loss: 2.4788784465959797

Epoch: 5| Step: 6
Training loss: 2.5868811599868238
Validation loss: 2.473426578326521

Epoch: 5| Step: 7
Training loss: 2.6153588126493443
Validation loss: 2.4728998844591743

Epoch: 5| Step: 8
Training loss: 2.2857254232407747
Validation loss: 2.4782292506452697

Epoch: 5| Step: 9
Training loss: 2.550194946017914
Validation loss: 2.4737117055467204

Epoch: 5| Step: 10
Training loss: 2.694672173995415
Validation loss: 2.4917135914133803

Epoch: 5| Step: 11
Training loss: 1.8249412265876586
Validation loss: 2.4904221766845276

Epoch: 165| Step: 0
Training loss: 2.4413444328111344
Validation loss: 2.491601964871735

Epoch: 5| Step: 1
Training loss: 2.098069475272754
Validation loss: 2.4787266298001285

Epoch: 5| Step: 2
Training loss: 2.980817341948683
Validation loss: 2.487688845426165

Epoch: 5| Step: 3
Training loss: 2.772930775947319
Validation loss: 2.487394413392452

Epoch: 5| Step: 4
Training loss: 2.6054472457707494
Validation loss: 2.476806905341287

Epoch: 5| Step: 5
Training loss: 2.768485879463505
Validation loss: 2.4668821721294463

Epoch: 5| Step: 6
Training loss: 2.203272496690237
Validation loss: 2.4699069744486972

Epoch: 5| Step: 7
Training loss: 1.8563125137437502
Validation loss: 2.4565327496974163

Epoch: 5| Step: 8
Training loss: 2.2746944557667406
Validation loss: 2.466036166069245

Epoch: 5| Step: 9
Training loss: 2.269776953103454
Validation loss: 2.4809678063762086

Epoch: 5| Step: 10
Training loss: 3.027798289969332
Validation loss: 2.478563052245464

Epoch: 5| Step: 11
Training loss: 2.979803128491933
Validation loss: 2.471131532138821

Epoch: 166| Step: 0
Training loss: 2.48725637651846
Validation loss: 2.4665550079128815

Epoch: 5| Step: 1
Training loss: 2.6652807767010858
Validation loss: 2.464642870697942

Epoch: 5| Step: 2
Training loss: 2.6567221726761923
Validation loss: 2.467923794689465

Epoch: 5| Step: 3
Training loss: 2.2402098969483313
Validation loss: 2.473519339847186

Epoch: 5| Step: 4
Training loss: 2.548038801840988
Validation loss: 2.4712573127271775

Epoch: 5| Step: 5
Training loss: 2.415688470201548
Validation loss: 2.473378118772959

Epoch: 5| Step: 6
Training loss: 2.3390500564600956
Validation loss: 2.461634643144509

Epoch: 5| Step: 7
Training loss: 2.443888289107137
Validation loss: 2.4713228516492314

Epoch: 5| Step: 8
Training loss: 2.5696133761389146
Validation loss: 2.4704930111849848

Epoch: 5| Step: 9
Training loss: 2.8627058130094993
Validation loss: 2.464168756419811

Epoch: 5| Step: 10
Training loss: 2.3546686790640594
Validation loss: 2.4603809110760437

Epoch: 5| Step: 11
Training loss: 1.3781924034468407
Validation loss: 2.4571873221586746

Epoch: 167| Step: 0
Training loss: 2.1068061162369864
Validation loss: 2.4663730961066928

Epoch: 5| Step: 1
Training loss: 2.581624655516172
Validation loss: 2.460152778449405

Epoch: 5| Step: 2
Training loss: 2.4386305510236657
Validation loss: 2.4653730312863638

Epoch: 5| Step: 3
Training loss: 1.7584070853122697
Validation loss: 2.465298902319604

Epoch: 5| Step: 4
Training loss: 2.9216572889520966
Validation loss: 2.4657065508192084

Epoch: 5| Step: 5
Training loss: 2.888318270383351
Validation loss: 2.465932304432606

Epoch: 5| Step: 6
Training loss: 3.0338923941674674
Validation loss: 2.4662168278423287

Epoch: 5| Step: 7
Training loss: 2.5177514228926627
Validation loss: 2.464453398782664

Epoch: 5| Step: 8
Training loss: 2.2847662177160926
Validation loss: 2.4723291929071545

Epoch: 5| Step: 9
Training loss: 2.5667620315009687
Validation loss: 2.465425780305645

Epoch: 5| Step: 10
Training loss: 2.061365682618692
Validation loss: 2.4707979045877457

Epoch: 5| Step: 11
Training loss: 3.0691968914873837
Validation loss: 2.4661064198508944

Epoch: 168| Step: 0
Training loss: 2.2811003335428834
Validation loss: 2.4733246617495075

Epoch: 5| Step: 1
Training loss: 2.3601776172588718
Validation loss: 2.4681830258124067

Epoch: 5| Step: 2
Training loss: 2.3477947682980833
Validation loss: 2.472932945707795

Epoch: 5| Step: 3
Training loss: 3.052903847313233
Validation loss: 2.466948223932842

Epoch: 5| Step: 4
Training loss: 2.414259522925583
Validation loss: 2.4746657407503854

Epoch: 5| Step: 5
Training loss: 2.5926697101426384
Validation loss: 2.4810171807614347

Epoch: 5| Step: 6
Training loss: 2.426397911724144
Validation loss: 2.464528184006612

Epoch: 5| Step: 7
Training loss: 2.7480658752174976
Validation loss: 2.471188142034785

Epoch: 5| Step: 8
Training loss: 2.556530395649423
Validation loss: 2.469745266361992

Epoch: 5| Step: 9
Training loss: 2.305311008746086
Validation loss: 2.4729804398482593

Epoch: 5| Step: 10
Training loss: 2.4756542188869832
Validation loss: 2.465540920833682

Epoch: 5| Step: 11
Training loss: 2.8745423657620766
Validation loss: 2.47790924342059

Epoch: 169| Step: 0
Training loss: 2.257645439118369
Validation loss: 2.4659259695449762

Epoch: 5| Step: 1
Training loss: 2.4819576570709097
Validation loss: 2.4722221961777455

Epoch: 5| Step: 2
Training loss: 2.622604003240386
Validation loss: 2.470394447957213

Epoch: 5| Step: 3
Training loss: 2.217131333180734
Validation loss: 2.475685259088779

Epoch: 5| Step: 4
Training loss: 2.5547636528214004
Validation loss: 2.469625856863586

Epoch: 5| Step: 5
Training loss: 2.2000276693858267
Validation loss: 2.4654782582344716

Epoch: 5| Step: 6
Training loss: 2.674443220858401
Validation loss: 2.463762528813268

Epoch: 5| Step: 7
Training loss: 2.627186636490701
Validation loss: 2.46677514049291

Epoch: 5| Step: 8
Training loss: 2.6713762319725394
Validation loss: 2.4657031786200188

Epoch: 5| Step: 9
Training loss: 2.5711247514439655
Validation loss: 2.4695353486138614

Epoch: 5| Step: 10
Training loss: 2.441453612821835
Validation loss: 2.4709424914381235

Epoch: 5| Step: 11
Training loss: 2.9997547367292854
Validation loss: 2.4700876265914355

Epoch: 170| Step: 0
Training loss: 2.697612544019728
Validation loss: 2.4803949560367315

Epoch: 5| Step: 1
Training loss: 2.480882408913302
Validation loss: 2.4792528070716857

Epoch: 5| Step: 2
Training loss: 1.8682622011353658
Validation loss: 2.470621285069442

Epoch: 5| Step: 3
Training loss: 2.749448027268542
Validation loss: 2.4709514508203925

Epoch: 5| Step: 4
Training loss: 2.1486512233894426
Validation loss: 2.4785286752985

Epoch: 5| Step: 5
Training loss: 2.541405638334973
Validation loss: 2.4806329527644384

Epoch: 5| Step: 6
Training loss: 3.1030354497460015
Validation loss: 2.490460123039653

Epoch: 5| Step: 7
Training loss: 2.61020377697302
Validation loss: 2.475670101182222

Epoch: 5| Step: 8
Training loss: 2.4679587339540343
Validation loss: 2.461087624951117

Epoch: 5| Step: 9
Training loss: 2.6667044954795682
Validation loss: 2.47163080181931

Epoch: 5| Step: 10
Training loss: 2.2853990213923696
Validation loss: 2.4593896387966008

Epoch: 5| Step: 11
Training loss: 1.3841961333927584
Validation loss: 2.463729622722904

Epoch: 171| Step: 0
Training loss: 2.56141109125651
Validation loss: 2.4682366123048256

Epoch: 5| Step: 1
Training loss: 2.0370825731922753
Validation loss: 2.471337853321919

Epoch: 5| Step: 2
Training loss: 2.473360223581123
Validation loss: 2.472977222182189

Epoch: 5| Step: 3
Training loss: 2.8079755206114294
Validation loss: 2.4804368505153853

Epoch: 5| Step: 4
Training loss: 2.5443192278587907
Validation loss: 2.473621776509506

Epoch: 5| Step: 5
Training loss: 2.487937148897949
Validation loss: 2.472375457071112

Epoch: 5| Step: 6
Training loss: 2.835061686818544
Validation loss: 2.4779594564926075

Epoch: 5| Step: 7
Training loss: 2.2583962712075034
Validation loss: 2.4731498976784487

Epoch: 5| Step: 8
Training loss: 2.348764269157621
Validation loss: 2.4685897976366213

Epoch: 5| Step: 9
Training loss: 2.68172410805846
Validation loss: 2.46961721849716

Epoch: 5| Step: 10
Training loss: 2.6362207465178895
Validation loss: 2.4752348741835224

Epoch: 5| Step: 11
Training loss: 1.9394743919166952
Validation loss: 2.468934297724425

Epoch: 172| Step: 0
Training loss: 2.4454293025094342
Validation loss: 2.479287750963005

Epoch: 5| Step: 1
Training loss: 2.432858375895882
Validation loss: 2.477935418489442

Epoch: 5| Step: 2
Training loss: 2.6771121982151356
Validation loss: 2.4741065927886967

Epoch: 5| Step: 3
Training loss: 2.232201646303107
Validation loss: 2.4797821496383854

Epoch: 5| Step: 4
Training loss: 1.992780888764186
Validation loss: 2.4778200640999755

Epoch: 5| Step: 5
Training loss: 2.8973241760254314
Validation loss: 2.4707170247326506

Epoch: 5| Step: 6
Training loss: 2.7279780082823017
Validation loss: 2.477997280997087

Epoch: 5| Step: 7
Training loss: 2.594078410855435
Validation loss: 2.4711916193082324

Epoch: 5| Step: 8
Training loss: 2.399924944657694
Validation loss: 2.464136710427228

Epoch: 5| Step: 9
Training loss: 2.850494268288811
Validation loss: 2.464452145154493

Epoch: 5| Step: 10
Training loss: 2.1411200180730674
Validation loss: 2.4624315520195785

Epoch: 5| Step: 11
Training loss: 1.9490502538842187
Validation loss: 2.4607392327100444

Epoch: 173| Step: 0
Training loss: 2.678302284524437
Validation loss: 2.457895528203749

Epoch: 5| Step: 1
Training loss: 2.595529152900643
Validation loss: 2.4583399996155264

Epoch: 5| Step: 2
Training loss: 2.2004734613560055
Validation loss: 2.484719018689469

Epoch: 5| Step: 3
Training loss: 2.0630097192858
Validation loss: 2.4829229553953027

Epoch: 5| Step: 4
Training loss: 1.9617069148318504
Validation loss: 2.4939354971760923

Epoch: 5| Step: 5
Training loss: 2.575956230016807
Validation loss: 2.4937471195354095

Epoch: 5| Step: 6
Training loss: 2.6631317750226433
Validation loss: 2.4854538212631985

Epoch: 5| Step: 7
Training loss: 2.460482019325794
Validation loss: 2.473710532912068

Epoch: 5| Step: 8
Training loss: 3.1086076719361064
Validation loss: 2.4734962165628285

Epoch: 5| Step: 9
Training loss: 2.4120764602701152
Validation loss: 2.481452558562673

Epoch: 5| Step: 10
Training loss: 2.700968946445758
Validation loss: 2.4765231012044397

Epoch: 5| Step: 11
Training loss: 2.4538061083278047
Validation loss: 2.4907427419722454

Epoch: 174| Step: 0
Training loss: 2.5919553683818224
Validation loss: 2.4904055866898926

Epoch: 5| Step: 1
Training loss: 2.4285148906537914
Validation loss: 2.487810175133957

Epoch: 5| Step: 2
Training loss: 2.455517713572578
Validation loss: 2.485557306813238

Epoch: 5| Step: 3
Training loss: 1.9281019113601907
Validation loss: 2.477097117645265

Epoch: 5| Step: 4
Training loss: 2.0580492258588836
Validation loss: 2.484641678610348

Epoch: 5| Step: 5
Training loss: 2.9940364692622667
Validation loss: 2.480131644022341

Epoch: 5| Step: 6
Training loss: 2.9093645695910135
Validation loss: 2.4783713977916

Epoch: 5| Step: 7
Training loss: 2.5999153123414724
Validation loss: 2.4769730132433057

Epoch: 5| Step: 8
Training loss: 2.6265167214184313
Validation loss: 2.4780301900512183

Epoch: 5| Step: 9
Training loss: 2.546997254602685
Validation loss: 2.4786802196635755

Epoch: 5| Step: 10
Training loss: 2.42384101071187
Validation loss: 2.4793053609589504

Epoch: 5| Step: 11
Training loss: 2.6416295414992397
Validation loss: 2.4748519060031122

Epoch: 175| Step: 0
Training loss: 2.7754267905642
Validation loss: 2.4682010289751215

Epoch: 5| Step: 1
Training loss: 2.2442392140006384
Validation loss: 2.4691343149197995

Epoch: 5| Step: 2
Training loss: 2.5380584139944258
Validation loss: 2.464762404722254

Epoch: 5| Step: 3
Training loss: 2.3896538251497295
Validation loss: 2.4652601636934914

Epoch: 5| Step: 4
Training loss: 2.7502567864951444
Validation loss: 2.471707773319086

Epoch: 5| Step: 5
Training loss: 2.7402269794258274
Validation loss: 2.4733681198931556

Epoch: 5| Step: 6
Training loss: 2.181628385149192
Validation loss: 2.47729282060136

Epoch: 5| Step: 7
Training loss: 2.1392906095201747
Validation loss: 2.482754036575358

Epoch: 5| Step: 8
Training loss: 2.763623995416745
Validation loss: 2.4885188298210803

Epoch: 5| Step: 9
Training loss: 2.602031402028956
Validation loss: 2.4755922777645223

Epoch: 5| Step: 10
Training loss: 2.3904509636852906
Validation loss: 2.472831575225375

Epoch: 5| Step: 11
Training loss: 2.5279411069854776
Validation loss: 2.467131514716326

Testing loss: 2.0020634517601543
