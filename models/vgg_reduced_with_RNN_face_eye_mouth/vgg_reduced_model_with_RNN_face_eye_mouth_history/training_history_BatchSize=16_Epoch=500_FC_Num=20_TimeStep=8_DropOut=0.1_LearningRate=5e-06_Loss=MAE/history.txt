Epoch: 1| Step: 0
Training loss: 5.486702919006348
Validation loss: 5.2666416962941485

Epoch: 6| Step: 1
Training loss: 5.441638946533203
Validation loss: 5.26535964012146

Epoch: 6| Step: 2
Training loss: 6.077589988708496
Validation loss: 5.264099200566609

Epoch: 6| Step: 3
Training loss: 5.3575639724731445
Validation loss: 5.262838125228882

Epoch: 6| Step: 4
Training loss: 6.081729888916016
Validation loss: 5.261546452840169

Epoch: 6| Step: 5
Training loss: 5.923737525939941
Validation loss: 5.260289629300435

Epoch: 6| Step: 6
Training loss: 3.9789371490478516
Validation loss: 5.2589497566223145

Epoch: 6| Step: 7
Training loss: 4.765259265899658
Validation loss: 5.257598638534546

Epoch: 6| Step: 8
Training loss: 6.06306791305542
Validation loss: 5.256249825159709

Epoch: 6| Step: 9
Training loss: 4.487585067749023
Validation loss: 5.254838864008586

Epoch: 6| Step: 10
Training loss: 4.985429286956787
Validation loss: 5.253387530644734

Epoch: 6| Step: 11
Training loss: 5.860578536987305
Validation loss: 5.251955986022949

Epoch: 6| Step: 12
Training loss: 5.0521368980407715
Validation loss: 5.250483433405559

Epoch: 6| Step: 13
Training loss: 5.024594306945801
Validation loss: 5.248983144760132

Epoch: 2| Step: 0
Training loss: 5.948620319366455
Validation loss: 5.247412761052449

Epoch: 6| Step: 1
Training loss: 5.390373229980469
Validation loss: 5.245814085006714

Epoch: 6| Step: 2
Training loss: 5.0365800857543945
Validation loss: 5.244057893753052

Epoch: 6| Step: 3
Training loss: 5.774706840515137
Validation loss: 5.242293993631999

Epoch: 6| Step: 4
Training loss: 4.703872203826904
Validation loss: 5.240457057952881

Epoch: 6| Step: 5
Training loss: 4.573153495788574
Validation loss: 5.238448699315389

Epoch: 6| Step: 6
Training loss: 6.522190093994141
Validation loss: 5.236348708470662

Epoch: 6| Step: 7
Training loss: 5.052384376525879
Validation loss: 5.23421049118042

Epoch: 6| Step: 8
Training loss: 5.477150917053223
Validation loss: 5.231989701588948

Epoch: 6| Step: 9
Training loss: 4.449084281921387
Validation loss: 5.229469060897827

Epoch: 6| Step: 10
Training loss: 5.5384016036987305
Validation loss: 5.2270480791727705

Epoch: 6| Step: 11
Training loss: 3.822786808013916
Validation loss: 5.224445343017578

Epoch: 6| Step: 12
Training loss: 6.233437538146973
Validation loss: 5.221656878789266

Epoch: 6| Step: 13
Training loss: 5.7321367263793945
Validation loss: 5.218832174936931

Epoch: 3| Step: 0
Training loss: 5.7585344314575195
Validation loss: 5.215694427490234

Epoch: 6| Step: 1
Training loss: 5.934516429901123
Validation loss: 5.212627013524373

Epoch: 6| Step: 2
Training loss: 5.8846845626831055
Validation loss: 5.209171454111735

Epoch: 6| Step: 3
Training loss: 5.089909553527832
Validation loss: 5.205604235331218

Epoch: 6| Step: 4
Training loss: 5.026536464691162
Validation loss: 5.20184048016866

Epoch: 6| Step: 5
Training loss: 4.84296989440918
Validation loss: 5.197840849558513

Epoch: 6| Step: 6
Training loss: 4.510947227478027
Validation loss: 5.193837245305379

Epoch: 6| Step: 7
Training loss: 4.956076622009277
Validation loss: 5.189530769983928

Epoch: 6| Step: 8
Training loss: 4.021551132202148
Validation loss: 5.184887886047363

Epoch: 6| Step: 9
Training loss: 5.635104179382324
Validation loss: 5.180205663045247

Epoch: 6| Step: 10
Training loss: 4.82193660736084
Validation loss: 5.175259351730347

Epoch: 6| Step: 11
Training loss: 5.807906150817871
Validation loss: 5.169995148976644

Epoch: 6| Step: 12
Training loss: 6.51222038269043
Validation loss: 5.16457462310791

Epoch: 6| Step: 13
Training loss: 4.844852447509766
Validation loss: 5.158744255701701

Epoch: 4| Step: 0
Training loss: 4.95890998840332
Validation loss: 5.152652025222778

Epoch: 6| Step: 1
Training loss: 5.426448345184326
Validation loss: 5.14646049340566

Epoch: 6| Step: 2
Training loss: 5.764096260070801
Validation loss: 5.139891227086385

Epoch: 6| Step: 3
Training loss: 5.377260208129883
Validation loss: 5.1330543756484985

Epoch: 6| Step: 4
Training loss: 4.883144378662109
Validation loss: 5.126008749008179

Epoch: 6| Step: 5
Training loss: 4.465104103088379
Validation loss: 5.118779222170512

Epoch: 6| Step: 6
Training loss: 5.4572014808654785
Validation loss: 5.111298481623332

Epoch: 6| Step: 7
Training loss: 4.581876754760742
Validation loss: 5.1033988793691

Epoch: 6| Step: 8
Training loss: 4.690291404724121
Validation loss: 5.095290104548137

Epoch: 6| Step: 9
Training loss: 4.674999237060547
Validation loss: 5.0870364507039385

Epoch: 6| Step: 10
Training loss: 5.047130584716797
Validation loss: 5.07852824529012

Epoch: 6| Step: 11
Training loss: 5.734114170074463
Validation loss: 5.070056041081746

Epoch: 6| Step: 12
Training loss: 5.843883514404297
Validation loss: 5.061125199000041

Epoch: 6| Step: 13
Training loss: 5.592907905578613
Validation loss: 5.052266041437785

Epoch: 5| Step: 0
Training loss: 5.489786624908447
Validation loss: 5.042681296666463

Epoch: 6| Step: 1
Training loss: 5.615874290466309
Validation loss: 5.0338451862335205

Epoch: 6| Step: 2
Training loss: 5.633744239807129
Validation loss: 5.023953994115193

Epoch: 6| Step: 3
Training loss: 5.239974498748779
Validation loss: 5.014549175898234

Epoch: 6| Step: 4
Training loss: 4.590557098388672
Validation loss: 5.00466521581014

Epoch: 6| Step: 5
Training loss: 4.731851577758789
Validation loss: 4.9946316083272295

Epoch: 6| Step: 6
Training loss: 6.062409400939941
Validation loss: 4.984947760899861

Epoch: 6| Step: 7
Training loss: 4.186060905456543
Validation loss: 4.974749803543091

Epoch: 6| Step: 8
Training loss: 4.213651657104492
Validation loss: 4.965217590332031

Epoch: 6| Step: 9
Training loss: 4.665672302246094
Validation loss: 4.955169637997945

Epoch: 6| Step: 10
Training loss: 4.240794658660889
Validation loss: 4.945128281911214

Epoch: 6| Step: 11
Training loss: 4.016589164733887
Validation loss: 4.934855620066325

Epoch: 6| Step: 12
Training loss: 5.414006233215332
Validation loss: 4.925020297368367

Epoch: 6| Step: 13
Training loss: 6.7554473876953125
Validation loss: 4.915232340494792

Epoch: 6| Step: 0
Training loss: 4.2837443351745605
Validation loss: 4.905571460723877

Epoch: 6| Step: 1
Training loss: 6.142814636230469
Validation loss: 4.895876010258992

Epoch: 6| Step: 2
Training loss: 5.773385047912598
Validation loss: 4.885694980621338

Epoch: 6| Step: 3
Training loss: 4.904252052307129
Validation loss: 4.875769138336182

Epoch: 6| Step: 4
Training loss: 5.623821258544922
Validation loss: 4.865825335184733

Epoch: 6| Step: 5
Training loss: 4.304629802703857
Validation loss: 4.855832656224568

Epoch: 6| Step: 6
Training loss: 5.689046859741211
Validation loss: 4.846104621887207

Epoch: 6| Step: 7
Training loss: 4.67276668548584
Validation loss: 4.836326599121094

Epoch: 6| Step: 8
Training loss: 4.790034770965576
Validation loss: 4.827383041381836

Epoch: 6| Step: 9
Training loss: 4.803071975708008
Validation loss: 4.817959864934285

Epoch: 6| Step: 10
Training loss: 5.292182445526123
Validation loss: 4.809156894683838

Epoch: 6| Step: 11
Training loss: 4.038723945617676
Validation loss: 4.800010164578755

Epoch: 6| Step: 12
Training loss: 4.713191986083984
Validation loss: 4.791504859924316

Epoch: 6| Step: 13
Training loss: 3.993199348449707
Validation loss: 4.783283869425456

Epoch: 7| Step: 0
Training loss: 3.688861131668091
Validation loss: 4.774457852045695

Epoch: 6| Step: 1
Training loss: 5.629528999328613
Validation loss: 4.765984217325847

Epoch: 6| Step: 2
Training loss: 5.538699626922607
Validation loss: 4.757757107416789

Epoch: 6| Step: 3
Training loss: 5.300706386566162
Validation loss: 4.749484221140544

Epoch: 6| Step: 4
Training loss: 4.95767068862915
Validation loss: 4.741254409154256

Epoch: 6| Step: 5
Training loss: 3.030364990234375
Validation loss: 4.733146905899048

Epoch: 6| Step: 6
Training loss: 4.881137847900391
Validation loss: 4.725560347239177

Epoch: 6| Step: 7
Training loss: 4.823918342590332
Validation loss: 4.718059380849202

Epoch: 6| Step: 8
Training loss: 5.135275840759277
Validation loss: 4.71040407816569

Epoch: 6| Step: 9
Training loss: 4.981294631958008
Validation loss: 4.703798691431682

Epoch: 6| Step: 10
Training loss: 5.348319053649902
Validation loss: 4.696844498316447

Epoch: 6| Step: 11
Training loss: 4.2663116455078125
Validation loss: 4.690199454625447

Epoch: 6| Step: 12
Training loss: 5.131622314453125
Validation loss: 4.683877269426982

Epoch: 6| Step: 13
Training loss: 4.713318347930908
Validation loss: 4.677088101704915

Epoch: 8| Step: 0
Training loss: 5.519303798675537
Validation loss: 4.670366684595744

Epoch: 6| Step: 1
Training loss: 4.840346813201904
Validation loss: 4.66370956103007

Epoch: 6| Step: 2
Training loss: 3.8589906692504883
Validation loss: 4.656855503718059

Epoch: 6| Step: 3
Training loss: 4.940549850463867
Validation loss: 4.64964218934377

Epoch: 6| Step: 4
Training loss: 4.209863662719727
Validation loss: 4.6439510981241865

Epoch: 6| Step: 5
Training loss: 4.789128303527832
Validation loss: 4.637600143750508

Epoch: 6| Step: 6
Training loss: 3.7768054008483887
Validation loss: 4.631717363993327

Epoch: 6| Step: 7
Training loss: 4.20847225189209
Validation loss: 4.625223875045776

Epoch: 6| Step: 8
Training loss: 5.445298194885254
Validation loss: 4.61873984336853

Epoch: 6| Step: 9
Training loss: 5.29334831237793
Validation loss: 4.6124205986658735

Epoch: 6| Step: 10
Training loss: 5.238864898681641
Validation loss: 4.605725208918254

Epoch: 6| Step: 11
Training loss: 4.11677885055542
Validation loss: 4.599160035451253

Epoch: 6| Step: 12
Training loss: 5.347417831420898
Validation loss: 4.592482805252075

Epoch: 6| Step: 13
Training loss: 4.5926384925842285
Validation loss: 4.586510260899861

Epoch: 9| Step: 0
Training loss: 4.937638759613037
Validation loss: 4.580598910649617

Epoch: 6| Step: 1
Training loss: 3.781614303588867
Validation loss: 4.574285507202148

Epoch: 6| Step: 2
Training loss: 4.394303321838379
Validation loss: 4.568546215693156

Epoch: 6| Step: 3
Training loss: 3.958319902420044
Validation loss: 4.562686363855998

Epoch: 6| Step: 4
Training loss: 4.596307754516602
Validation loss: 4.556764841079712

Epoch: 6| Step: 5
Training loss: 4.648995399475098
Validation loss: 4.550390084584554

Epoch: 6| Step: 6
Training loss: 5.544075012207031
Validation loss: 4.543919126192729

Epoch: 6| Step: 7
Training loss: 4.404873371124268
Validation loss: 4.538177053133647

Epoch: 6| Step: 8
Training loss: 5.018359184265137
Validation loss: 4.532281955083211

Epoch: 6| Step: 9
Training loss: 4.440986156463623
Validation loss: 4.526413520177205

Epoch: 6| Step: 10
Training loss: 4.380380153656006
Validation loss: 4.520277976989746

Epoch: 6| Step: 11
Training loss: 4.59196138381958
Validation loss: 4.5143492221832275

Epoch: 6| Step: 12
Training loss: 5.449062347412109
Validation loss: 4.508197943369548

Epoch: 6| Step: 13
Training loss: 4.8502702713012695
Validation loss: 4.5021670659383135

Epoch: 10| Step: 0
Training loss: 4.582278251647949
Validation loss: 4.4963802099227905

Epoch: 6| Step: 1
Training loss: 5.271430969238281
Validation loss: 4.490434010823567

Epoch: 6| Step: 2
Training loss: 3.899260997772217
Validation loss: 4.484277566274007

Epoch: 6| Step: 3
Training loss: 3.444190502166748
Validation loss: 4.4782625039418535

Epoch: 6| Step: 4
Training loss: 5.114562034606934
Validation loss: 4.472844839096069

Epoch: 6| Step: 5
Training loss: 5.358080863952637
Validation loss: 4.467738231023152

Epoch: 6| Step: 6
Training loss: 5.121030807495117
Validation loss: 4.462110757827759

Epoch: 6| Step: 7
Training loss: 4.389828681945801
Validation loss: 4.456804037094116

Epoch: 6| Step: 8
Training loss: 4.036134243011475
Validation loss: 4.451361854871114

Epoch: 6| Step: 9
Training loss: 5.012192249298096
Validation loss: 4.446263233820598

Epoch: 6| Step: 10
Training loss: 5.255229949951172
Validation loss: 4.440338055292766

Epoch: 6| Step: 11
Training loss: 4.784828186035156
Validation loss: 4.434962828954061

Epoch: 6| Step: 12
Training loss: 3.6126255989074707
Validation loss: 4.429634094238281

Epoch: 6| Step: 13
Training loss: 4.082707405090332
Validation loss: 4.424148440361023

Epoch: 11| Step: 0
Training loss: 4.440098762512207
Validation loss: 4.418846845626831

Epoch: 6| Step: 1
Training loss: 3.984734535217285
Validation loss: 4.413763443628947

Epoch: 6| Step: 2
Training loss: 4.7000322341918945
Validation loss: 4.4095867077509565

Epoch: 6| Step: 3
Training loss: 5.058131694793701
Validation loss: 4.40418004989624

Epoch: 6| Step: 4
Training loss: 4.294087886810303
Validation loss: 4.39951769510905

Epoch: 6| Step: 5
Training loss: 4.627041816711426
Validation loss: 4.394060770670573

Epoch: 6| Step: 6
Training loss: 4.861927032470703
Validation loss: 4.389038523038228

Epoch: 6| Step: 7
Training loss: 4.804194450378418
Validation loss: 4.383255441983541

Epoch: 6| Step: 8
Training loss: 3.9024391174316406
Validation loss: 4.378083348274231

Epoch: 6| Step: 9
Training loss: 4.526529312133789
Validation loss: 4.373310883839925

Epoch: 6| Step: 10
Training loss: 4.247486591339111
Validation loss: 4.369053562482198

Epoch: 6| Step: 11
Training loss: 5.743241310119629
Validation loss: 4.36407995223999

Epoch: 6| Step: 12
Training loss: 3.344804525375366
Validation loss: 4.359238107999166

Epoch: 6| Step: 13
Training loss: 4.527215957641602
Validation loss: 4.354649980862935

Epoch: 12| Step: 0
Training loss: 3.887587070465088
Validation loss: 4.3500088055928545

Epoch: 6| Step: 1
Training loss: 4.108159065246582
Validation loss: 4.344648838043213

Epoch: 6| Step: 2
Training loss: 4.681934356689453
Validation loss: 4.340255657831828

Epoch: 6| Step: 3
Training loss: 4.912386894226074
Validation loss: 4.335902372996013

Epoch: 6| Step: 4
Training loss: 4.309382438659668
Validation loss: 4.331449826558431

Epoch: 6| Step: 5
Training loss: 4.687767028808594
Validation loss: 4.327025810877482

Epoch: 6| Step: 6
Training loss: 3.510686159133911
Validation loss: 4.322311083475749

Epoch: 6| Step: 7
Training loss: 4.130704879760742
Validation loss: 4.31780219078064

Epoch: 6| Step: 8
Training loss: 4.830806732177734
Validation loss: 4.31283716360728

Epoch: 6| Step: 9
Training loss: 4.6030120849609375
Validation loss: 4.3082752625147505

Epoch: 6| Step: 10
Training loss: 4.53599739074707
Validation loss: 4.304248332977295

Epoch: 6| Step: 11
Training loss: 4.755187511444092
Validation loss: 4.300338665644328

Epoch: 6| Step: 12
Training loss: 4.24947452545166
Validation loss: 4.295031547546387

Epoch: 6| Step: 13
Training loss: 4.993143081665039
Validation loss: 4.2904079755147295

Epoch: 13| Step: 0
Training loss: 4.3195037841796875
Validation loss: 4.285451650619507

Epoch: 6| Step: 1
Training loss: 3.971499443054199
Validation loss: 4.280908028284709

Epoch: 6| Step: 2
Training loss: 2.570120334625244
Validation loss: 4.2763038873672485

Epoch: 6| Step: 3
Training loss: 3.6628260612487793
Validation loss: 4.272120475769043

Epoch: 6| Step: 4
Training loss: 5.224285125732422
Validation loss: 4.267579873402913

Epoch: 6| Step: 5
Training loss: 4.239602088928223
Validation loss: 4.262678623199463

Epoch: 6| Step: 6
Training loss: 5.377910137176514
Validation loss: 4.257681210835774

Epoch: 6| Step: 7
Training loss: 6.091479301452637
Validation loss: 4.252481142679851

Epoch: 6| Step: 8
Training loss: 4.00838565826416
Validation loss: 4.247258226076762

Epoch: 6| Step: 9
Training loss: 4.108309745788574
Validation loss: 4.2426265478134155

Epoch: 6| Step: 10
Training loss: 4.7094407081604
Validation loss: 4.238045334815979

Epoch: 6| Step: 11
Training loss: 4.420005798339844
Validation loss: 4.232874433199565

Epoch: 6| Step: 12
Training loss: 4.177156448364258
Validation loss: 4.228298942248027

Epoch: 6| Step: 13
Training loss: 4.481156826019287
Validation loss: 4.223186095555623

Epoch: 14| Step: 0
Training loss: 4.64754581451416
Validation loss: 4.218354503313701

Epoch: 6| Step: 1
Training loss: 4.552541255950928
Validation loss: 4.2133034865061445

Epoch: 6| Step: 2
Training loss: 4.317038536071777
Validation loss: 4.20793350537618

Epoch: 6| Step: 3
Training loss: 3.223153591156006
Validation loss: 4.203004757563273

Epoch: 6| Step: 4
Training loss: 4.607980728149414
Validation loss: 4.197891394297282

Epoch: 6| Step: 5
Training loss: 5.033418655395508
Validation loss: 4.192720651626587

Epoch: 6| Step: 6
Training loss: 3.6730356216430664
Validation loss: 4.187198638916016

Epoch: 6| Step: 7
Training loss: 3.5601980686187744
Validation loss: 4.181877692540486

Epoch: 6| Step: 8
Training loss: 4.76635217666626
Validation loss: 4.1772587696711225

Epoch: 6| Step: 9
Training loss: 5.062944412231445
Validation loss: 4.17215096950531

Epoch: 6| Step: 10
Training loss: 4.437506675720215
Validation loss: 4.1682701508204145

Epoch: 6| Step: 11
Training loss: 4.8248138427734375
Validation loss: 4.16274619102478

Epoch: 6| Step: 12
Training loss: 4.367362976074219
Validation loss: 4.158074617385864

Epoch: 6| Step: 13
Training loss: 3.4291608333587646
Validation loss: 4.15354061126709

Epoch: 15| Step: 0
Training loss: 4.364322662353516
Validation loss: 4.14854900042216

Epoch: 6| Step: 1
Training loss: 5.145263671875
Validation loss: 4.143502831459045

Epoch: 6| Step: 2
Training loss: 3.961380958557129
Validation loss: 4.138502558072408

Epoch: 6| Step: 3
Training loss: 4.847247123718262
Validation loss: 4.1336625417073565

Epoch: 6| Step: 4
Training loss: 3.631376266479492
Validation loss: 4.129380106925964

Epoch: 6| Step: 5
Training loss: 4.972764015197754
Validation loss: 4.124552845954895

Epoch: 6| Step: 6
Training loss: 3.768479585647583
Validation loss: 4.119687398274739

Epoch: 6| Step: 7
Training loss: 3.9843711853027344
Validation loss: 4.114439646402995

Epoch: 6| Step: 8
Training loss: 4.655104160308838
Validation loss: 4.110222101211548

Epoch: 6| Step: 9
Training loss: 4.995536804199219
Validation loss: 4.105481187502543

Epoch: 6| Step: 10
Training loss: 2.5420801639556885
Validation loss: 4.0999371608098345

Epoch: 6| Step: 11
Training loss: 3.933040142059326
Validation loss: 4.095388889312744

Epoch: 6| Step: 12
Training loss: 4.438665390014648
Validation loss: 4.090578516324361

Epoch: 6| Step: 13
Training loss: 4.386714935302734
Validation loss: 4.086417396863301

Epoch: 16| Step: 0
Training loss: 5.111638069152832
Validation loss: 4.081281423568726

Epoch: 6| Step: 1
Training loss: 4.716561317443848
Validation loss: 4.0766087373097735

Epoch: 6| Step: 2
Training loss: 3.115328311920166
Validation loss: 4.072057445844014

Epoch: 6| Step: 3
Training loss: 5.056344032287598
Validation loss: 4.067500710487366

Epoch: 6| Step: 4
Training loss: 5.214983940124512
Validation loss: 4.062998374303182

Epoch: 6| Step: 5
Training loss: 3.57458758354187
Validation loss: 4.057745496431987

Epoch: 6| Step: 6
Training loss: 5.012874603271484
Validation loss: 4.05287237962087

Epoch: 6| Step: 7
Training loss: 3.492948532104492
Validation loss: 4.048806230227153

Epoch: 6| Step: 8
Training loss: 3.9822230339050293
Validation loss: 4.044047911961873

Epoch: 6| Step: 9
Training loss: 2.8973336219787598
Validation loss: 4.039435784022014

Epoch: 6| Step: 10
Training loss: 3.894836664199829
Validation loss: 4.0346899429957075

Epoch: 6| Step: 11
Training loss: 4.1736650466918945
Validation loss: 4.030882159868876

Epoch: 6| Step: 12
Training loss: 4.009327411651611
Validation loss: 4.026374300320943

Epoch: 6| Step: 13
Training loss: 4.493423938751221
Validation loss: 4.02185583114624

Epoch: 17| Step: 0
Training loss: 3.3300352096557617
Validation loss: 4.016816139221191

Epoch: 6| Step: 1
Training loss: 4.00007963180542
Validation loss: 4.012050747871399

Epoch: 6| Step: 2
Training loss: 4.8514251708984375
Validation loss: 4.008291443188985

Epoch: 6| Step: 3
Training loss: 3.635388135910034
Validation loss: 4.002890308698018

Epoch: 6| Step: 4
Training loss: 5.19162654876709
Validation loss: 3.998178561528524

Epoch: 6| Step: 5
Training loss: 3.6972908973693848
Validation loss: 3.99349852403005

Epoch: 6| Step: 6
Training loss: 4.515330791473389
Validation loss: 3.98919407526652

Epoch: 6| Step: 7
Training loss: 3.7168643474578857
Validation loss: 3.984492063522339

Epoch: 6| Step: 8
Training loss: 5.071080207824707
Validation loss: 3.98038383324941

Epoch: 6| Step: 9
Training loss: 4.036777496337891
Validation loss: 3.974706292152405

Epoch: 6| Step: 10
Training loss: 4.029881477355957
Validation loss: 3.970018227895101

Epoch: 6| Step: 11
Training loss: 3.443027973175049
Validation loss: 3.9650604327519736

Epoch: 6| Step: 12
Training loss: 4.4666972160339355
Validation loss: 3.9603995084762573

Epoch: 6| Step: 13
Training loss: 3.8851048946380615
Validation loss: 3.9555545250574746

Epoch: 18| Step: 0
Training loss: 2.9678049087524414
Validation loss: 3.9510320822397866

Epoch: 6| Step: 1
Training loss: 4.8024001121521
Validation loss: 3.946565548578898

Epoch: 6| Step: 2
Training loss: 4.190793514251709
Validation loss: 3.942272702852885

Epoch: 6| Step: 3
Training loss: 4.648528099060059
Validation loss: 3.9399263064066568

Epoch: 6| Step: 4
Training loss: 4.2531538009643555
Validation loss: 3.932720422744751

Epoch: 6| Step: 5
Training loss: 3.7020962238311768
Validation loss: 3.928419550259908

Epoch: 6| Step: 6
Training loss: 4.404739856719971
Validation loss: 3.926023006439209

Epoch: 6| Step: 7
Training loss: 3.9773964881896973
Validation loss: 3.920777956644694

Epoch: 6| Step: 8
Training loss: 3.752197027206421
Validation loss: 3.9159391721089682

Epoch: 6| Step: 9
Training loss: 3.9363977909088135
Validation loss: 3.910861849784851

Epoch: 6| Step: 10
Training loss: 3.8676514625549316
Validation loss: 3.9063897927602134

Epoch: 6| Step: 11
Training loss: 3.3482143878936768
Validation loss: 3.9002718925476074

Epoch: 6| Step: 12
Training loss: 4.874391555786133
Validation loss: 3.8949625492095947

Epoch: 6| Step: 13
Training loss: 4.269951820373535
Validation loss: 3.8908427953720093

Epoch: 19| Step: 0
Training loss: 4.214066505432129
Validation loss: 3.884251594543457

Epoch: 6| Step: 1
Training loss: 3.485398530960083
Validation loss: 3.8791321913401284

Epoch: 6| Step: 2
Training loss: 3.979344129562378
Validation loss: 3.873767534891764

Epoch: 6| Step: 3
Training loss: 4.135396957397461
Validation loss: 3.869203289349874

Epoch: 6| Step: 4
Training loss: 3.165614604949951
Validation loss: 3.8648786147435508

Epoch: 6| Step: 5
Training loss: 2.8996896743774414
Validation loss: 3.8613950411478677

Epoch: 6| Step: 6
Training loss: 4.525815486907959
Validation loss: 3.855100154876709

Epoch: 6| Step: 7
Training loss: 4.847177505493164
Validation loss: 3.851086735725403

Epoch: 6| Step: 8
Training loss: 4.27272367477417
Validation loss: 3.8457099199295044

Epoch: 6| Step: 9
Training loss: 4.087461471557617
Validation loss: 3.84077517191569

Epoch: 6| Step: 10
Training loss: 4.237542629241943
Validation loss: 3.8361010948816934

Epoch: 6| Step: 11
Training loss: 4.298839569091797
Validation loss: 3.83066991964976

Epoch: 6| Step: 12
Training loss: 4.1959428787231445
Validation loss: 3.8263301054636636

Epoch: 6| Step: 13
Training loss: 3.722147226333618
Validation loss: 3.821162303288778

Epoch: 20| Step: 0
Training loss: 3.950744867324829
Validation loss: 3.8157147963841758

Epoch: 6| Step: 1
Training loss: 3.4914722442626953
Validation loss: 3.811438004175822

Epoch: 6| Step: 2
Training loss: 3.0768227577209473
Validation loss: 3.807449698448181

Epoch: 6| Step: 3
Training loss: 3.4485955238342285
Validation loss: 3.802672505378723

Epoch: 6| Step: 4
Training loss: 4.173497200012207
Validation loss: 3.798063119252523

Epoch: 6| Step: 5
Training loss: 3.8992178440093994
Validation loss: 3.7922778129577637

Epoch: 6| Step: 6
Training loss: 3.9174578189849854
Validation loss: 3.788195331891378

Epoch: 6| Step: 7
Training loss: 5.125059604644775
Validation loss: 3.7856846253077188

Epoch: 6| Step: 8
Training loss: 4.518148422241211
Validation loss: 3.7832552194595337

Epoch: 6| Step: 9
Training loss: 4.124321460723877
Validation loss: 3.7734384139378867

Epoch: 6| Step: 10
Training loss: 3.911855697631836
Validation loss: 3.770805517832438

Epoch: 6| Step: 11
Training loss: 3.4732067584991455
Validation loss: 3.769295851389567

Epoch: 6| Step: 12
Training loss: 3.6272308826446533
Validation loss: 3.764542818069458

Epoch: 6| Step: 13
Training loss: 4.478087425231934
Validation loss: 3.758748213450114

Epoch: 21| Step: 0
Training loss: 3.7325594425201416
Validation loss: 3.752352158228556

Epoch: 6| Step: 1
Training loss: 2.8005685806274414
Validation loss: 3.7462931076685586

Epoch: 6| Step: 2
Training loss: 3.9847466945648193
Validation loss: 3.741169492403666

Epoch: 6| Step: 3
Training loss: 3.395595073699951
Validation loss: 3.737656037012736

Epoch: 6| Step: 4
Training loss: 3.8829174041748047
Validation loss: 3.7334066232045493

Epoch: 6| Step: 5
Training loss: 3.6805901527404785
Validation loss: 3.7276658614476523

Epoch: 6| Step: 6
Training loss: 4.148196220397949
Validation loss: 3.721466898918152

Epoch: 6| Step: 7
Training loss: 3.636974334716797
Validation loss: 3.717072367668152

Epoch: 6| Step: 8
Training loss: 4.16555643081665
Validation loss: 3.7131715218226113

Epoch: 6| Step: 9
Training loss: 5.088430881500244
Validation loss: 3.709051251411438

Epoch: 6| Step: 10
Training loss: 3.8096020221710205
Validation loss: 3.704119165738424

Epoch: 6| Step: 11
Training loss: 4.200855731964111
Validation loss: 3.6991811196009317

Epoch: 6| Step: 12
Training loss: 4.432353973388672
Validation loss: 3.6944980223973594

Epoch: 6| Step: 13
Training loss: 3.374744415283203
Validation loss: 3.6912928024927774

Epoch: 22| Step: 0
Training loss: 4.124172210693359
Validation loss: 3.6832921902338662

Epoch: 6| Step: 1
Training loss: 3.3400886058807373
Validation loss: 3.6792107025782266

Epoch: 6| Step: 2
Training loss: 3.1261496543884277
Validation loss: 3.6751563946406045

Epoch: 6| Step: 3
Training loss: 4.202298164367676
Validation loss: 3.670636852582296

Epoch: 6| Step: 4
Training loss: 3.9215807914733887
Validation loss: 3.6650941371917725

Epoch: 6| Step: 5
Training loss: 4.111823081970215
Validation loss: 3.659844477971395

Epoch: 6| Step: 6
Training loss: 4.05654239654541
Validation loss: 3.6550221840540567

Epoch: 6| Step: 7
Training loss: 3.252228021621704
Validation loss: 3.650883436203003

Epoch: 6| Step: 8
Training loss: 4.166896820068359
Validation loss: 3.647001028060913

Epoch: 6| Step: 9
Training loss: 3.9716684818267822
Validation loss: 3.64193856716156

Epoch: 6| Step: 10
Training loss: 3.5193843841552734
Validation loss: 3.6364347537358603

Epoch: 6| Step: 11
Training loss: 3.375051259994507
Validation loss: 3.631522615750631

Epoch: 6| Step: 12
Training loss: 4.550045490264893
Validation loss: 3.626551866531372

Epoch: 6| Step: 13
Training loss: 3.712541341781616
Validation loss: 3.6221443017323813

Epoch: 23| Step: 0
Training loss: 3.7553653717041016
Validation loss: 3.617107629776001

Epoch: 6| Step: 1
Training loss: 3.5231680870056152
Validation loss: 3.6124671697616577

Epoch: 6| Step: 2
Training loss: 3.86811900138855
Validation loss: 3.6089022159576416

Epoch: 6| Step: 3
Training loss: 3.4948320388793945
Validation loss: 3.604172110557556

Epoch: 6| Step: 4
Training loss: 3.5845160484313965
Validation loss: 3.5993213256200156

Epoch: 6| Step: 5
Training loss: 3.666797161102295
Validation loss: 3.594396471977234

Epoch: 6| Step: 6
Training loss: 4.0334672927856445
Validation loss: 3.5897078116734824

Epoch: 6| Step: 7
Training loss: 3.9309439659118652
Validation loss: 3.584571043650309

Epoch: 6| Step: 8
Training loss: 3.8813867568969727
Validation loss: 3.579978346824646

Epoch: 6| Step: 9
Training loss: 3.7508320808410645
Validation loss: 3.5754460096359253

Epoch: 6| Step: 10
Training loss: 3.800983428955078
Validation loss: 3.570612589518229

Epoch: 6| Step: 11
Training loss: 3.6770524978637695
Validation loss: 3.5656508207321167

Epoch: 6| Step: 12
Training loss: 3.4684510231018066
Validation loss: 3.5602961778640747

Epoch: 6| Step: 13
Training loss: 4.054134368896484
Validation loss: 3.5553190310796103

Epoch: 24| Step: 0
Training loss: 4.371082305908203
Validation loss: 3.551785707473755

Epoch: 6| Step: 1
Training loss: 2.5035293102264404
Validation loss: 3.5455618699391684

Epoch: 6| Step: 2
Training loss: 3.826620101928711
Validation loss: 3.5400388638178506

Epoch: 6| Step: 3
Training loss: 3.89833402633667
Validation loss: 3.5358405907948813

Epoch: 6| Step: 4
Training loss: 4.000687599182129
Validation loss: 3.5311765670776367

Epoch: 6| Step: 5
Training loss: 4.863862037658691
Validation loss: 3.526640017827352

Epoch: 6| Step: 6
Training loss: 3.453319549560547
Validation loss: 3.5220124324162803

Epoch: 6| Step: 7
Training loss: 3.150846481323242
Validation loss: 3.5165088176727295

Epoch: 6| Step: 8
Training loss: 3.7894127368927
Validation loss: 3.5108877420425415

Epoch: 6| Step: 9
Training loss: 3.967212677001953
Validation loss: 3.506075461705526

Epoch: 6| Step: 10
Training loss: 4.405560493469238
Validation loss: 3.5000935792922974

Epoch: 6| Step: 11
Training loss: 3.1185355186462402
Validation loss: 3.4951432943344116

Epoch: 6| Step: 12
Training loss: 3.205761194229126
Validation loss: 3.48981765906016

Epoch: 6| Step: 13
Training loss: 3.0386502742767334
Validation loss: 3.487565000851949

Epoch: 25| Step: 0
Training loss: 3.520794630050659
Validation loss: 3.4801406462987265

Epoch: 6| Step: 1
Training loss: 3.6882925033569336
Validation loss: 3.4755387703577676

Epoch: 6| Step: 2
Training loss: 3.7492690086364746
Validation loss: 3.4714743296305337

Epoch: 6| Step: 3
Training loss: 3.3240556716918945
Validation loss: 3.4680357376734414

Epoch: 6| Step: 4
Training loss: 3.3209152221679688
Validation loss: 3.462494214375814

Epoch: 6| Step: 5
Training loss: 4.270965576171875
Validation loss: 3.457145571708679

Epoch: 6| Step: 6
Training loss: 3.2803726196289062
Validation loss: 3.4514044920603433

Epoch: 6| Step: 7
Training loss: 3.287562847137451
Validation loss: 3.446141759554545

Epoch: 6| Step: 8
Training loss: 4.829559803009033
Validation loss: 3.4416490395863852

Epoch: 6| Step: 9
Training loss: 2.7242822647094727
Validation loss: 3.4435260693232217

Epoch: 6| Step: 10
Training loss: 4.151971817016602
Validation loss: 3.4318921168645224

Epoch: 6| Step: 11
Training loss: 3.4983177185058594
Validation loss: 3.4284229278564453

Epoch: 6| Step: 12
Training loss: 3.0437512397766113
Validation loss: 3.426139990488688

Epoch: 6| Step: 13
Training loss: 3.955376386642456
Validation loss: 3.424003998438517

Epoch: 26| Step: 0
Training loss: 3.4011738300323486
Validation loss: 3.4180564085642495

Epoch: 6| Step: 1
Training loss: 3.1569056510925293
Validation loss: 3.4124672015508017

Epoch: 6| Step: 2
Training loss: 4.701625823974609
Validation loss: 3.4058024883270264

Epoch: 6| Step: 3
Training loss: 3.6874749660491943
Validation loss: 3.399690826733907

Epoch: 6| Step: 4
Training loss: 3.7564220428466797
Validation loss: 3.394566774368286

Epoch: 6| Step: 5
Training loss: 3.4022650718688965
Validation loss: 3.390020966529846

Epoch: 6| Step: 6
Training loss: 4.082831859588623
Validation loss: 3.384299397468567

Epoch: 6| Step: 7
Training loss: 3.103510856628418
Validation loss: 3.377677838007609

Epoch: 6| Step: 8
Training loss: 4.138465404510498
Validation loss: 3.372087279955546

Epoch: 6| Step: 9
Training loss: 3.129730463027954
Validation loss: 3.3663602670033774

Epoch: 6| Step: 10
Training loss: 3.5802061557769775
Validation loss: 3.3618468840916953

Epoch: 6| Step: 11
Training loss: 3.8231570720672607
Validation loss: 3.356649478276571

Epoch: 6| Step: 12
Training loss: 3.075730800628662
Validation loss: 3.3518694639205933

Epoch: 6| Step: 13
Training loss: 2.718874931335449
Validation loss: 3.3467182715733848

Epoch: 27| Step: 0
Training loss: 3.8866395950317383
Validation loss: 3.3418522675832114

Epoch: 6| Step: 1
Training loss: 4.427773475646973
Validation loss: 3.3379299640655518

Epoch: 6| Step: 2
Training loss: 4.571539878845215
Validation loss: 3.332997481028239

Epoch: 6| Step: 3
Training loss: 3.287313938140869
Validation loss: 3.327043135960897

Epoch: 6| Step: 4
Training loss: 2.8089706897735596
Validation loss: 3.321680267651876

Epoch: 6| Step: 5
Training loss: 3.528822898864746
Validation loss: 3.315865238507589

Epoch: 6| Step: 6
Training loss: 3.448610305786133
Validation loss: 3.3115461667378745

Epoch: 6| Step: 7
Training loss: 3.4277749061584473
Validation loss: 3.3065514167149863

Epoch: 6| Step: 8
Training loss: 3.4030709266662598
Validation loss: 3.3010568618774414

Epoch: 6| Step: 9
Training loss: 3.2774882316589355
Validation loss: 3.2966164350509644

Epoch: 6| Step: 10
Training loss: 3.7047839164733887
Validation loss: 3.2933870951334634

Epoch: 6| Step: 11
Training loss: 2.3150367736816406
Validation loss: 3.28948183854421

Epoch: 6| Step: 12
Training loss: 4.001385688781738
Validation loss: 3.2844264109929404

Epoch: 6| Step: 13
Training loss: 2.705115556716919
Validation loss: 3.2794591585795083

Epoch: 28| Step: 0
Training loss: 4.572268962860107
Validation loss: 3.274399201075236

Epoch: 6| Step: 1
Training loss: 3.475480079650879
Validation loss: 3.2693753242492676

Epoch: 6| Step: 2
Training loss: 3.330455780029297
Validation loss: 3.2644445101420083

Epoch: 6| Step: 3
Training loss: 3.583320140838623
Validation loss: 3.2597296237945557

Epoch: 6| Step: 4
Training loss: 2.1865029335021973
Validation loss: 3.2556053400039673

Epoch: 6| Step: 5
Training loss: 3.8397324085235596
Validation loss: 3.2495705286661782

Epoch: 6| Step: 6
Training loss: 2.624152898788452
Validation loss: 3.245869517326355

Epoch: 6| Step: 7
Training loss: 2.828352451324463
Validation loss: 3.240145524342855

Epoch: 6| Step: 8
Training loss: 3.0596017837524414
Validation loss: 3.2356460889180503

Epoch: 6| Step: 9
Training loss: 4.190817832946777
Validation loss: 3.2314341068267822

Epoch: 6| Step: 10
Training loss: 3.4265918731689453
Validation loss: 3.2262776692708335

Epoch: 6| Step: 11
Training loss: 2.9669687747955322
Validation loss: 3.2214239835739136

Epoch: 6| Step: 12
Training loss: 3.6895291805267334
Validation loss: 3.216961940129598

Epoch: 6| Step: 13
Training loss: 4.114943504333496
Validation loss: 3.212495962778727

Epoch: 29| Step: 0
Training loss: 2.808542013168335
Validation loss: 3.2075778245925903

Epoch: 6| Step: 1
Training loss: 3.891054630279541
Validation loss: 3.2044057846069336

Epoch: 6| Step: 2
Training loss: 3.4761486053466797
Validation loss: 3.1990681091944375

Epoch: 6| Step: 3
Training loss: 3.5485451221466064
Validation loss: 3.1942710081736245

Epoch: 6| Step: 4
Training loss: 2.703078269958496
Validation loss: 3.1896912256876626

Epoch: 6| Step: 5
Training loss: 3.158435344696045
Validation loss: 3.185115396976471

Epoch: 6| Step: 6
Training loss: 3.57139253616333
Validation loss: 3.1813906033833823

Epoch: 6| Step: 7
Training loss: 2.978109121322632
Validation loss: 3.1770779291788735

Epoch: 6| Step: 8
Training loss: 3.1516942977905273
Validation loss: 3.172598878542582

Epoch: 6| Step: 9
Training loss: 3.7199692726135254
Validation loss: 3.167762875556946

Epoch: 6| Step: 10
Training loss: 3.5117533206939697
Validation loss: 3.163539409637451

Epoch: 6| Step: 11
Training loss: 4.308076858520508
Validation loss: 3.159186005592346

Epoch: 6| Step: 12
Training loss: 3.086906909942627
Validation loss: 3.154571990172068

Epoch: 6| Step: 13
Training loss: 3.1318345069885254
Validation loss: 3.1497802734375

Epoch: 30| Step: 0
Training loss: 2.7569031715393066
Validation loss: 3.1458250681559243

Epoch: 6| Step: 1
Training loss: 2.7851943969726562
Validation loss: 3.141484181086222

Epoch: 6| Step: 2
Training loss: 3.462799549102783
Validation loss: 3.140683134396871

Epoch: 6| Step: 3
Training loss: 2.3687164783477783
Validation loss: 3.1329627434412637

Epoch: 6| Step: 4
Training loss: 4.209090709686279
Validation loss: 3.13245956103007

Epoch: 6| Step: 5
Training loss: 4.071285724639893
Validation loss: 3.1253004471460977

Epoch: 6| Step: 6
Training loss: 2.786961555480957
Validation loss: 3.119208574295044

Epoch: 6| Step: 7
Training loss: 3.8081483840942383
Validation loss: 3.1149237155914307

Epoch: 6| Step: 8
Training loss: 2.7979018688201904
Validation loss: 3.1107850074768066

Epoch: 6| Step: 9
Training loss: 2.868724822998047
Validation loss: 3.1063770055770874

Epoch: 6| Step: 10
Training loss: 4.166583061218262
Validation loss: 3.102040727933248

Epoch: 6| Step: 11
Training loss: 3.316286325454712
Validation loss: 3.0982973178227744

Epoch: 6| Step: 12
Training loss: 3.8807156085968018
Validation loss: 3.093464215596517

Epoch: 6| Step: 13
Training loss: 2.9579687118530273
Validation loss: 3.0890052318573

Epoch: 31| Step: 0
Training loss: 3.57621431350708
Validation loss: 3.0849259297053018

Epoch: 6| Step: 1
Training loss: 2.7629597187042236
Validation loss: 3.081487536430359

Epoch: 6| Step: 2
Training loss: 3.6600570678710938
Validation loss: 3.0762333472569785

Epoch: 6| Step: 3
Training loss: 3.246920108795166
Validation loss: 3.074052333831787

Epoch: 6| Step: 4
Training loss: 2.710315465927124
Validation loss: 3.0706631342569985

Epoch: 6| Step: 5
Training loss: 2.8980605602264404
Validation loss: 3.0684109131495156

Epoch: 6| Step: 6
Training loss: 4.028199195861816
Validation loss: 3.0636670192082724

Epoch: 6| Step: 7
Training loss: 3.029289960861206
Validation loss: 3.057777921358744

Epoch: 6| Step: 8
Training loss: 3.6040573120117188
Validation loss: 3.0535921255747476

Epoch: 6| Step: 9
Training loss: 2.1855416297912598
Validation loss: 3.0501734415690103

Epoch: 6| Step: 10
Training loss: 3.7367029190063477
Validation loss: 3.0471450090408325

Epoch: 6| Step: 11
Training loss: 3.6171321868896484
Validation loss: 3.0435698429743447

Epoch: 6| Step: 12
Training loss: 3.236957550048828
Validation loss: 3.0396432081858316

Epoch: 6| Step: 13
Training loss: 3.1959357261657715
Validation loss: 3.035428762435913

Epoch: 32| Step: 0
Training loss: 3.0702621936798096
Validation loss: 3.0295915603637695

Epoch: 6| Step: 1
Training loss: 3.2839412689208984
Validation loss: 3.0264126459757485

Epoch: 6| Step: 2
Training loss: 3.2584002017974854
Validation loss: 3.022311886151632

Epoch: 6| Step: 3
Training loss: 2.769252300262451
Validation loss: 3.0193862120310464

Epoch: 6| Step: 4
Training loss: 2.909043788909912
Validation loss: 3.0169607400894165

Epoch: 6| Step: 5
Training loss: 3.021657943725586
Validation loss: 3.011808435122172

Epoch: 6| Step: 6
Training loss: 2.9461092948913574
Validation loss: 3.009247303009033

Epoch: 6| Step: 7
Training loss: 2.6413180828094482
Validation loss: 3.004292686780294

Epoch: 6| Step: 8
Training loss: 3.343109607696533
Validation loss: 3.000548084576925

Epoch: 6| Step: 9
Training loss: 3.2231013774871826
Validation loss: 2.9959335724512735

Epoch: 6| Step: 10
Training loss: 3.0731310844421387
Validation loss: 2.9920928875605264

Epoch: 6| Step: 11
Training loss: 3.738313674926758
Validation loss: 2.9889456033706665

Epoch: 6| Step: 12
Training loss: 3.5880165100097656
Validation loss: 2.985037326812744

Epoch: 6| Step: 13
Training loss: 3.870673179626465
Validation loss: 2.98140549659729

Epoch: 33| Step: 0
Training loss: 3.656494379043579
Validation loss: 2.9773290157318115

Epoch: 6| Step: 1
Training loss: 2.3519833087921143
Validation loss: 2.973083178202311

Epoch: 6| Step: 2
Training loss: 2.569603204727173
Validation loss: 2.969066301981608

Epoch: 6| Step: 3
Training loss: 3.368356943130493
Validation loss: 2.9650636514027915

Epoch: 6| Step: 4
Training loss: 3.157456398010254
Validation loss: 2.9610599676767984

Epoch: 6| Step: 5
Training loss: 3.9081687927246094
Validation loss: 2.956666588783264

Epoch: 6| Step: 6
Training loss: 3.1510353088378906
Validation loss: 2.952954093615214

Epoch: 6| Step: 7
Training loss: 3.8533599376678467
Validation loss: 2.9487438996632895

Epoch: 6| Step: 8
Training loss: 2.1185200214385986
Validation loss: 2.945194641749064

Epoch: 6| Step: 9
Training loss: 2.8949384689331055
Validation loss: 2.940735658009847

Epoch: 6| Step: 10
Training loss: 3.750864028930664
Validation loss: 2.9375677903493247

Epoch: 6| Step: 11
Training loss: 2.387277364730835
Validation loss: 2.9337087074915567

Epoch: 6| Step: 12
Training loss: 3.408365249633789
Validation loss: 2.9310107231140137

Epoch: 6| Step: 13
Training loss: 3.5145630836486816
Validation loss: 2.9276148875554404

Epoch: 34| Step: 0
Training loss: 3.266977071762085
Validation loss: 2.923813303311666

Epoch: 6| Step: 1
Training loss: 2.746384859085083
Validation loss: 2.9197192986806235

Epoch: 6| Step: 2
Training loss: 3.2998318672180176
Validation loss: 2.9174657265345254

Epoch: 6| Step: 3
Training loss: 2.5011305809020996
Validation loss: 2.914740045865377

Epoch: 6| Step: 4
Training loss: 2.52323055267334
Validation loss: 2.9116198221842446

Epoch: 6| Step: 5
Training loss: 3.0938596725463867
Validation loss: 2.90773344039917

Epoch: 6| Step: 6
Training loss: 3.1112709045410156
Validation loss: 2.9039001862208047

Epoch: 6| Step: 7
Training loss: 2.5196385383605957
Validation loss: 2.9004526933034263

Epoch: 6| Step: 8
Training loss: 3.69779372215271
Validation loss: 2.8966914812723794

Epoch: 6| Step: 9
Training loss: 3.5015547275543213
Validation loss: 2.8930901288986206

Epoch: 6| Step: 10
Training loss: 3.3168277740478516
Validation loss: 2.8886636892954507

Epoch: 6| Step: 11
Training loss: 2.879467010498047
Validation loss: 2.884659687678019

Epoch: 6| Step: 12
Training loss: 3.7260332107543945
Validation loss: 2.8807100852330527

Epoch: 6| Step: 13
Training loss: 3.3065576553344727
Validation loss: 2.87723700205485

Epoch: 35| Step: 0
Training loss: 3.116809368133545
Validation loss: 2.874161124229431

Epoch: 6| Step: 1
Training loss: 3.7138028144836426
Validation loss: 2.8703180948893228

Epoch: 6| Step: 2
Training loss: 2.4668445587158203
Validation loss: 2.867981950441996

Epoch: 6| Step: 3
Training loss: 3.0476229190826416
Validation loss: 2.866224010785421

Epoch: 6| Step: 4
Training loss: 3.4511494636535645
Validation loss: 2.871046702067057

Epoch: 6| Step: 5
Training loss: 3.01328182220459
Validation loss: 2.8575530449549356

Epoch: 6| Step: 6
Training loss: 2.4850268363952637
Validation loss: 2.855414787928263

Epoch: 6| Step: 7
Training loss: 2.2558939456939697
Validation loss: 2.851759592692057

Epoch: 6| Step: 8
Training loss: 2.871471643447876
Validation loss: 2.851107597351074

Epoch: 6| Step: 9
Training loss: 3.5685744285583496
Validation loss: 2.850825826327006

Epoch: 6| Step: 10
Training loss: 3.438199758529663
Validation loss: 2.843967080116272

Epoch: 6| Step: 11
Training loss: 3.80806303024292
Validation loss: 2.8395658334096274

Epoch: 6| Step: 12
Training loss: 2.799649715423584
Validation loss: 2.8357619047164917

Epoch: 6| Step: 13
Training loss: 2.8638930320739746
Validation loss: 2.835452755292257

Epoch: 36| Step: 0
Training loss: 3.0359015464782715
Validation loss: 2.831995646158854

Epoch: 6| Step: 1
Training loss: 2.889390468597412
Validation loss: 2.8259718815485635

Epoch: 6| Step: 2
Training loss: 2.7122597694396973
Validation loss: 2.82171638806661

Epoch: 6| Step: 3
Training loss: 3.470323085784912
Validation loss: 2.8172130584716797

Epoch: 6| Step: 4
Training loss: 3.0116703510284424
Validation loss: 2.814171632130941

Epoch: 6| Step: 5
Training loss: 3.026738166809082
Validation loss: 2.8114963372548423

Epoch: 6| Step: 6
Training loss: 3.0018463134765625
Validation loss: 2.808955510457357

Epoch: 6| Step: 7
Training loss: 3.126206159591675
Validation loss: 2.806511084238688

Epoch: 6| Step: 8
Training loss: 2.6667847633361816
Validation loss: 2.8031179507573447

Epoch: 6| Step: 9
Training loss: 3.024034023284912
Validation loss: 2.8003185987472534

Epoch: 6| Step: 10
Training loss: 3.3638501167297363
Validation loss: 2.7982065280278525

Epoch: 6| Step: 11
Training loss: 2.975344657897949
Validation loss: 2.794733544190725

Epoch: 6| Step: 12
Training loss: 2.186767816543579
Validation loss: 2.791137218475342

Epoch: 6| Step: 13
Training loss: 3.7920517921447754
Validation loss: 2.7884405851364136

Epoch: 37| Step: 0
Training loss: 3.43556809425354
Validation loss: 2.785889466603597

Epoch: 6| Step: 1
Training loss: 2.483952522277832
Validation loss: 2.7816785971323648

Epoch: 6| Step: 2
Training loss: 3.1874213218688965
Validation loss: 2.7783372004826865

Epoch: 6| Step: 3
Training loss: 2.8313379287719727
Validation loss: 2.773884892463684

Epoch: 6| Step: 4
Training loss: 2.8038341999053955
Validation loss: 2.7720592419306436

Epoch: 6| Step: 5
Training loss: 3.555467128753662
Validation loss: 2.770049730936686

Epoch: 6| Step: 6
Training loss: 2.3678171634674072
Validation loss: 2.7670209805170694

Epoch: 6| Step: 7
Training loss: 2.5510621070861816
Validation loss: 2.763443390528361

Epoch: 6| Step: 8
Training loss: 2.280564785003662
Validation loss: 2.761653463045756

Epoch: 6| Step: 9
Training loss: 3.8145718574523926
Validation loss: 2.7590688864390054

Epoch: 6| Step: 10
Training loss: 3.8209028244018555
Validation loss: 2.7564669847488403

Epoch: 6| Step: 11
Training loss: 2.9559807777404785
Validation loss: 2.7538699905077615

Epoch: 6| Step: 12
Training loss: 2.835665225982666
Validation loss: 2.7501872777938843

Epoch: 6| Step: 13
Training loss: 2.736238479614258
Validation loss: 2.747679829597473

Epoch: 38| Step: 0
Training loss: 2.6395809650421143
Validation loss: 2.7435045639673867

Epoch: 6| Step: 1
Training loss: 2.876375675201416
Validation loss: 2.7405553658803306

Epoch: 6| Step: 2
Training loss: 2.7485265731811523
Validation loss: 2.7375670671463013

Epoch: 6| Step: 3
Training loss: 2.8469467163085938
Validation loss: 2.7328776915868125

Epoch: 6| Step: 4
Training loss: 3.460092544555664
Validation loss: 2.729546904563904

Epoch: 6| Step: 5
Training loss: 2.225398063659668
Validation loss: 2.7262505094210305

Epoch: 6| Step: 6
Training loss: 2.976691722869873
Validation loss: 2.7247477769851685

Epoch: 6| Step: 7
Training loss: 3.316467761993408
Validation loss: 2.7194637060165405

Epoch: 6| Step: 8
Training loss: 2.950559139251709
Validation loss: 2.7175767024358115

Epoch: 6| Step: 9
Training loss: 2.6116080284118652
Validation loss: 2.713168978691101

Epoch: 6| Step: 10
Training loss: 3.843017578125
Validation loss: 2.7110490004221597

Epoch: 6| Step: 11
Training loss: 2.5336074829101562
Validation loss: 2.708068370819092

Epoch: 6| Step: 12
Training loss: 3.2409603595733643
Validation loss: 2.7061884800593057

Epoch: 6| Step: 13
Training loss: 2.784611225128174
Validation loss: 2.7035171588261924

Epoch: 39| Step: 0
Training loss: 2.6177656650543213
Validation loss: 2.701281746228536

Epoch: 6| Step: 1
Training loss: 2.0273702144622803
Validation loss: 2.6984310150146484

Epoch: 6| Step: 2
Training loss: 3.4692628383636475
Validation loss: 2.6959701776504517

Epoch: 6| Step: 3
Training loss: 3.594841480255127
Validation loss: 2.693087379137675

Epoch: 6| Step: 4
Training loss: 2.4713175296783447
Validation loss: 2.6901639699935913

Epoch: 6| Step: 5
Training loss: 3.314943313598633
Validation loss: 2.686713178952535

Epoch: 6| Step: 6
Training loss: 3.2047109603881836
Validation loss: 2.6838955084482827

Epoch: 6| Step: 7
Training loss: 3.323155164718628
Validation loss: 2.6795983711878457

Epoch: 6| Step: 8
Training loss: 3.015817165374756
Validation loss: 2.6769667069117227

Epoch: 6| Step: 9
Training loss: 2.8350472450256348
Validation loss: 2.6775693893432617

Epoch: 6| Step: 10
Training loss: 2.6913492679595947
Validation loss: 2.6767192681630454

Epoch: 6| Step: 11
Training loss: 3.031754970550537
Validation loss: 2.671638290087382

Epoch: 6| Step: 12
Training loss: 2.289609670639038
Validation loss: 2.6651041507720947

Epoch: 6| Step: 13
Training loss: 2.516997814178467
Validation loss: 2.6619019905726113

Epoch: 40| Step: 0
Training loss: 2.350674629211426
Validation loss: 2.659728248914083

Epoch: 6| Step: 1
Training loss: 3.0193350315093994
Validation loss: 2.6577365398406982

Epoch: 6| Step: 2
Training loss: 2.982377529144287
Validation loss: 2.653467814127604

Epoch: 6| Step: 3
Training loss: 2.5649614334106445
Validation loss: 2.6498584747314453

Epoch: 6| Step: 4
Training loss: 3.3639988899230957
Validation loss: 2.6467652718226113

Epoch: 6| Step: 5
Training loss: 3.0253257751464844
Validation loss: 2.6436153650283813

Epoch: 6| Step: 6
Training loss: 2.6317806243896484
Validation loss: 2.6393622159957886

Epoch: 6| Step: 7
Training loss: 3.378575325012207
Validation loss: 2.6356126070022583

Epoch: 6| Step: 8
Training loss: 3.181316614151001
Validation loss: 2.6345330476760864

Epoch: 6| Step: 9
Training loss: 2.6798644065856934
Validation loss: 2.6325124502182007

Epoch: 6| Step: 10
Training loss: 2.508082151412964
Validation loss: 2.627646505832672

Epoch: 6| Step: 11
Training loss: 2.5794177055358887
Validation loss: 2.623679439226786

Epoch: 6| Step: 12
Training loss: 2.957406997680664
Validation loss: 2.620757977167765

Epoch: 6| Step: 13
Training loss: 2.589487075805664
Validation loss: 2.6175708373387656

Epoch: 41| Step: 0
Training loss: 3.457684278488159
Validation loss: 2.6139498949050903

Epoch: 6| Step: 1
Training loss: 2.485805034637451
Validation loss: 2.6119112769762673

Epoch: 6| Step: 2
Training loss: 2.9906280040740967
Validation loss: 2.60789155960083

Epoch: 6| Step: 3
Training loss: 3.038539409637451
Validation loss: 2.6056545774141946

Epoch: 6| Step: 4
Training loss: 1.9844226837158203
Validation loss: 2.603165864944458

Epoch: 6| Step: 5
Training loss: 2.2344512939453125
Validation loss: 2.5994757413864136

Epoch: 6| Step: 6
Training loss: 3.03035831451416
Validation loss: 2.5980035066604614

Epoch: 6| Step: 7
Training loss: 2.458390235900879
Validation loss: 2.5956053535143533

Epoch: 6| Step: 8
Training loss: 3.493347406387329
Validation loss: 2.593493183453878

Epoch: 6| Step: 9
Training loss: 2.9813005924224854
Validation loss: 2.590584397315979

Epoch: 6| Step: 10
Training loss: 2.828807830810547
Validation loss: 2.585303544998169

Epoch: 6| Step: 11
Training loss: 3.037525177001953
Validation loss: 2.5841705799102783

Epoch: 6| Step: 12
Training loss: 2.2240662574768066
Validation loss: 2.579962412516276

Epoch: 6| Step: 13
Training loss: 2.9015939235687256
Validation loss: 2.577415188153585

Epoch: 42| Step: 0
Training loss: 2.2609920501708984
Validation loss: 2.575516104698181

Epoch: 6| Step: 1
Training loss: 2.8385682106018066
Validation loss: 2.5697916746139526

Epoch: 6| Step: 2
Training loss: 2.9241340160369873
Validation loss: 2.567737897237142

Epoch: 6| Step: 3
Training loss: 2.6366357803344727
Validation loss: 2.564562757809957

Epoch: 6| Step: 4
Training loss: 2.975515842437744
Validation loss: 2.561885039011637

Epoch: 6| Step: 5
Training loss: 2.5072078704833984
Validation loss: 2.5587333838144937

Epoch: 6| Step: 6
Training loss: 2.206545114517212
Validation loss: 2.556068499883016

Epoch: 6| Step: 7
Training loss: 3.3083391189575195
Validation loss: 2.5534680684407554

Epoch: 6| Step: 8
Training loss: 3.102362632751465
Validation loss: 2.5495193799336753

Epoch: 6| Step: 9
Training loss: 2.2518258094787598
Validation loss: 2.5503066380818686

Epoch: 6| Step: 10
Training loss: 2.605034112930298
Validation loss: 2.5479055841763816

Epoch: 6| Step: 11
Training loss: 2.902174472808838
Validation loss: 2.5488218466440835

Epoch: 6| Step: 12
Training loss: 2.717398166656494
Validation loss: 2.544075687726339

Epoch: 6| Step: 13
Training loss: 3.357503652572632
Validation loss: 2.540119171142578

Epoch: 43| Step: 0
Training loss: 1.875833511352539
Validation loss: 2.5351719856262207

Epoch: 6| Step: 1
Training loss: 2.9484543800354004
Validation loss: 2.5313191016515098

Epoch: 6| Step: 2
Training loss: 3.2589097023010254
Validation loss: 2.5338591734568277

Epoch: 6| Step: 3
Training loss: 1.9566493034362793
Validation loss: 2.527341286341349

Epoch: 6| Step: 4
Training loss: 2.5491671562194824
Validation loss: 2.525843938191732

Epoch: 6| Step: 5
Training loss: 2.911759376525879
Validation loss: 2.524531106154124

Epoch: 6| Step: 6
Training loss: 3.2143843173980713
Validation loss: 2.526020109653473

Epoch: 6| Step: 7
Training loss: 3.093446731567383
Validation loss: 2.5269471804300943

Epoch: 6| Step: 8
Training loss: 2.416621446609497
Validation loss: 2.5285359223683677

Epoch: 6| Step: 9
Training loss: 3.424149751663208
Validation loss: 2.524844169616699

Epoch: 6| Step: 10
Training loss: 2.683964252471924
Validation loss: 2.5193001429239907

Epoch: 6| Step: 11
Training loss: 2.270461082458496
Validation loss: 2.515214463075002

Epoch: 6| Step: 12
Training loss: 2.6832003593444824
Validation loss: 2.5101311604181924

Epoch: 6| Step: 13
Training loss: 2.7484545707702637
Validation loss: 2.5089652935663858

Epoch: 44| Step: 0
Training loss: 3.1682674884796143
Validation loss: 2.5035802324612937

Epoch: 6| Step: 1
Training loss: 1.9756574630737305
Validation loss: 2.5008565187454224

Epoch: 6| Step: 2
Training loss: 2.5789437294006348
Validation loss: 2.494657297929128

Epoch: 6| Step: 3
Training loss: 2.3101649284362793
Validation loss: 2.488249937693278

Epoch: 6| Step: 4
Training loss: 2.567681074142456
Validation loss: 2.4876543283462524

Epoch: 6| Step: 5
Training loss: 1.6410902738571167
Validation loss: 2.4866920113563538

Epoch: 6| Step: 6
Training loss: 2.0950207710266113
Validation loss: 2.4802624384562173

Epoch: 6| Step: 7
Training loss: 3.026681900024414
Validation loss: 2.478028893470764

Epoch: 6| Step: 8
Training loss: 3.349734306335449
Validation loss: 2.4763924280802407

Epoch: 6| Step: 9
Training loss: 3.2430882453918457
Validation loss: 2.4736351569493613

Epoch: 6| Step: 10
Training loss: 3.389892578125
Validation loss: 2.4692788124084473

Epoch: 6| Step: 11
Training loss: 2.6190450191497803
Validation loss: 2.4648706912994385

Epoch: 6| Step: 12
Training loss: 2.8224196434020996
Validation loss: 2.46647971868515

Epoch: 6| Step: 13
Training loss: 2.706855058670044
Validation loss: 2.4670432806015015

Epoch: 45| Step: 0
Training loss: 3.287456512451172
Validation loss: 2.459643622239431

Epoch: 6| Step: 1
Training loss: 2.5951755046844482
Validation loss: 2.453339139620463

Epoch: 6| Step: 2
Training loss: 2.575425624847412
Validation loss: 2.4524606466293335

Epoch: 6| Step: 3
Training loss: 3.047184944152832
Validation loss: 2.4516913096110025

Epoch: 6| Step: 4
Training loss: 3.2533884048461914
Validation loss: 2.4512779911359153

Epoch: 6| Step: 5
Training loss: 1.9242421388626099
Validation loss: 2.4502729177474976

Epoch: 6| Step: 6
Training loss: 2.2117247581481934
Validation loss: 2.4491146008173623

Epoch: 6| Step: 7
Training loss: 2.4200127124786377
Validation loss: 2.446886340777079

Epoch: 6| Step: 8
Training loss: 2.7391769886016846
Validation loss: 2.442795912424723

Epoch: 6| Step: 9
Training loss: 2.636065721511841
Validation loss: 2.44044162829717

Epoch: 6| Step: 10
Training loss: 2.5169219970703125
Validation loss: 2.4352473815282187

Epoch: 6| Step: 11
Training loss: 2.667468309402466
Validation loss: 2.4306265910466514

Epoch: 6| Step: 12
Training loss: 2.886521100997925
Validation loss: 2.4289942582448325

Epoch: 6| Step: 13
Training loss: 2.1723878383636475
Validation loss: 2.4243013064066568

Epoch: 46| Step: 0
Training loss: 2.6116294860839844
Validation loss: 2.4229203859965005

Epoch: 6| Step: 1
Training loss: 2.559878349304199
Validation loss: 2.417393366495768

Epoch: 6| Step: 2
Training loss: 2.4468507766723633
Validation loss: 2.4157705704371133

Epoch: 6| Step: 3
Training loss: 2.4055910110473633
Validation loss: 2.410726626714071

Epoch: 6| Step: 4
Training loss: 2.428283929824829
Validation loss: 2.410778303941091

Epoch: 6| Step: 5
Training loss: 2.9118950366973877
Validation loss: 2.407483220100403

Epoch: 6| Step: 6
Training loss: 2.9818971157073975
Validation loss: 2.4052998622258506

Epoch: 6| Step: 7
Training loss: 2.9644269943237305
Validation loss: 2.404735505580902

Epoch: 6| Step: 8
Training loss: 2.0672478675842285
Validation loss: 2.402549664179484

Epoch: 6| Step: 9
Training loss: 2.5311145782470703
Validation loss: 2.4014941851298013

Epoch: 6| Step: 10
Training loss: 2.1538383960723877
Validation loss: 2.3970701893170676

Epoch: 6| Step: 11
Training loss: 2.7188661098480225
Validation loss: 2.3927421967188516

Epoch: 6| Step: 12
Training loss: 2.7540011405944824
Validation loss: 2.392475684483846

Epoch: 6| Step: 13
Training loss: 2.740349292755127
Validation loss: 2.3908923467000327

Epoch: 47| Step: 0
Training loss: 1.8674324750900269
Validation loss: 2.3893149495124817

Epoch: 6| Step: 1
Training loss: 3.2582244873046875
Validation loss: 2.3821500738461814

Epoch: 6| Step: 2
Training loss: 2.2016608715057373
Validation loss: 2.3786087036132812

Epoch: 6| Step: 3
Training loss: 2.3057785034179688
Validation loss: 2.377976973851522

Epoch: 6| Step: 4
Training loss: 2.421253204345703
Validation loss: 2.3761501709620156

Epoch: 6| Step: 5
Training loss: 2.4884865283966064
Validation loss: 2.3718883991241455

Epoch: 6| Step: 6
Training loss: 2.658066749572754
Validation loss: 2.3770210345586142

Epoch: 6| Step: 7
Training loss: 3.10945463180542
Validation loss: 2.3769472440083823

Epoch: 6| Step: 8
Training loss: 2.713329315185547
Validation loss: 2.3687533140182495

Epoch: 6| Step: 9
Training loss: 2.3411028385162354
Validation loss: 2.3626179297765098

Epoch: 6| Step: 10
Training loss: 2.6164684295654297
Validation loss: 2.3608593940734863

Epoch: 6| Step: 11
Training loss: 2.1521544456481934
Validation loss: 2.3576268355051675

Epoch: 6| Step: 12
Training loss: 3.0212082862854004
Validation loss: 2.3577768405278525

Epoch: 6| Step: 13
Training loss: 2.5769309997558594
Validation loss: 2.3542805115381875

Epoch: 48| Step: 0
Training loss: 2.0111265182495117
Validation loss: 2.3533534606297812

Epoch: 6| Step: 1
Training loss: 2.9337615966796875
Validation loss: 2.350169539451599

Epoch: 6| Step: 2
Training loss: 2.027003765106201
Validation loss: 2.349371075630188

Epoch: 6| Step: 3
Training loss: 2.5240750312805176
Validation loss: 2.3459875782330832

Epoch: 6| Step: 4
Training loss: 2.255481243133545
Validation loss: 2.343103011449178

Epoch: 6| Step: 5
Training loss: 3.0004024505615234
Validation loss: 2.342154343922933

Epoch: 6| Step: 6
Training loss: 2.5367517471313477
Validation loss: 2.3377294540405273

Epoch: 6| Step: 7
Training loss: 2.173830986022949
Validation loss: 2.3367868264516196

Epoch: 6| Step: 8
Training loss: 3.4369773864746094
Validation loss: 2.3333047231038413

Epoch: 6| Step: 9
Training loss: 2.1405282020568848
Validation loss: 2.3320310513178506

Epoch: 6| Step: 10
Training loss: 2.6247496604919434
Validation loss: 2.329413056373596

Epoch: 6| Step: 11
Training loss: 2.2772345542907715
Validation loss: 2.323366324106852

Epoch: 6| Step: 12
Training loss: 2.769106149673462
Validation loss: 2.3212052981058755

Epoch: 6| Step: 13
Training loss: 2.4491591453552246
Validation loss: 2.318487564722697

Epoch: 49| Step: 0
Training loss: 1.2219798564910889
Validation loss: 2.3147146503130593

Epoch: 6| Step: 1
Training loss: 2.6030049324035645
Validation loss: 2.3172916372617087

Epoch: 6| Step: 2
Training loss: 2.1504623889923096
Validation loss: 2.309247454007467

Epoch: 6| Step: 3
Training loss: 2.5535271167755127
Validation loss: 2.3083338538805642

Epoch: 6| Step: 4
Training loss: 2.157121181488037
Validation loss: 2.302395502726237

Epoch: 6| Step: 5
Training loss: 2.009016513824463
Validation loss: 2.3038562337557473

Epoch: 6| Step: 6
Training loss: 2.063075542449951
Validation loss: 2.3028040726979575

Epoch: 6| Step: 7
Training loss: 3.171771764755249
Validation loss: 2.3046834468841553

Epoch: 6| Step: 8
Training loss: 2.069444179534912
Validation loss: 2.3001272678375244

Epoch: 6| Step: 9
Training loss: 2.741825580596924
Validation loss: 2.2993372678756714

Epoch: 6| Step: 10
Training loss: 3.438102960586548
Validation loss: 2.298934519290924

Epoch: 6| Step: 11
Training loss: 2.930292844772339
Validation loss: 2.2988274097442627

Epoch: 6| Step: 12
Training loss: 2.361311435699463
Validation loss: 2.293497900168101

Epoch: 6| Step: 13
Training loss: 3.1567001342773438
Validation loss: 2.28217621644338

Epoch: 50| Step: 0
Training loss: 2.28017258644104
Validation loss: 2.282656113306681

Epoch: 6| Step: 1
Training loss: 2.200188398361206
Validation loss: 2.2815651893615723

Epoch: 6| Step: 2
Training loss: 2.6091113090515137
Validation loss: 2.2846205830574036

Epoch: 6| Step: 3
Training loss: 2.316514492034912
Validation loss: 2.279983480771383

Epoch: 6| Step: 4
Training loss: 2.2155473232269287
Validation loss: 2.2812748154004416

Epoch: 6| Step: 5
Training loss: 2.339472770690918
Validation loss: 2.2787774006525674

Epoch: 6| Step: 6
Training loss: 2.4988608360290527
Validation loss: 2.278380552927653

Epoch: 6| Step: 7
Training loss: 2.323589324951172
Validation loss: 2.2750155131022134

Epoch: 6| Step: 8
Training loss: 2.0654563903808594
Validation loss: 2.276305059591929

Epoch: 6| Step: 9
Training loss: 2.0637621879577637
Validation loss: 2.271105865637461

Epoch: 6| Step: 10
Training loss: 3.220674991607666
Validation loss: 2.270244042078654

Epoch: 6| Step: 11
Training loss: 2.9788646697998047
Validation loss: 2.2662921945254006

Epoch: 6| Step: 12
Training loss: 2.5537266731262207
Validation loss: 2.2614588737487793

Epoch: 6| Step: 13
Training loss: 2.5262293815612793
Validation loss: 2.2585597236951194

Epoch: 51| Step: 0
Training loss: 2.1345930099487305
Validation loss: 2.253679633140564

Epoch: 6| Step: 1
Training loss: 3.0128672122955322
Validation loss: 2.247813085714976

Epoch: 6| Step: 2
Training loss: 2.0021843910217285
Validation loss: 2.249296168486277

Epoch: 6| Step: 3
Training loss: 2.3837361335754395
Validation loss: 2.2554204066594443

Epoch: 6| Step: 4
Training loss: 2.545261859893799
Validation loss: 2.257565975189209

Epoch: 6| Step: 5
Training loss: 2.3503761291503906
Validation loss: 2.2449957132339478

Epoch: 6| Step: 6
Training loss: 2.3531861305236816
Validation loss: 2.2417743603388467

Epoch: 6| Step: 7
Training loss: 2.128955841064453
Validation loss: 2.239265223344167

Epoch: 6| Step: 8
Training loss: 2.27940034866333
Validation loss: 2.2406306862831116

Epoch: 6| Step: 9
Training loss: 2.5281567573547363
Validation loss: 2.2346120874087014

Epoch: 6| Step: 10
Training loss: 2.1936392784118652
Validation loss: 2.2340586384137473

Epoch: 6| Step: 11
Training loss: 2.5734684467315674
Validation loss: 2.2340057094891868

Epoch: 6| Step: 12
Training loss: 2.7799930572509766
Validation loss: 2.2313912510871887

Epoch: 6| Step: 13
Training loss: 2.43074893951416
Validation loss: 2.2303311030069985

Epoch: 52| Step: 0
Training loss: 2.6136932373046875
Validation loss: 2.2272000908851624

Epoch: 6| Step: 1
Training loss: 2.7171835899353027
Validation loss: 2.22650941212972

Epoch: 6| Step: 2
Training loss: 2.1715378761291504
Validation loss: 2.224187990029653

Epoch: 6| Step: 3
Training loss: 2.651111602783203
Validation loss: 2.228407164414724

Epoch: 6| Step: 4
Training loss: 2.471416711807251
Validation loss: 2.224542041619619

Epoch: 6| Step: 5
Training loss: 2.6054165363311768
Validation loss: 2.2263834277788797

Epoch: 6| Step: 6
Training loss: 2.019338369369507
Validation loss: 2.2214524348576865

Epoch: 6| Step: 7
Training loss: 2.8843045234680176
Validation loss: 2.222912053267161

Epoch: 6| Step: 8
Training loss: 2.0845980644226074
Validation loss: 2.215066432952881

Epoch: 6| Step: 9
Training loss: 2.426391363143921
Validation loss: 2.212658246358236

Epoch: 6| Step: 10
Training loss: 1.5175548791885376
Validation loss: 2.2124135494232178

Epoch: 6| Step: 11
Training loss: 2.471797466278076
Validation loss: 2.2111777861913047

Epoch: 6| Step: 12
Training loss: 2.764787197113037
Validation loss: 2.2006011605262756

Epoch: 6| Step: 13
Training loss: 1.9194504022598267
Validation loss: 2.200069864590963

Epoch: 53| Step: 0
Training loss: 2.2816874980926514
Validation loss: 2.1963319182395935

Epoch: 6| Step: 1
Training loss: 1.898140549659729
Validation loss: 2.1938748955726624

Epoch: 6| Step: 2
Training loss: 2.6688895225524902
Validation loss: 2.1885218818982444

Epoch: 6| Step: 3
Training loss: 2.577902317047119
Validation loss: 2.19035009543101

Epoch: 6| Step: 4
Training loss: 2.588921546936035
Validation loss: 2.188575108846029

Epoch: 6| Step: 5
Training loss: 2.8070106506347656
Validation loss: 2.1842815478642783

Epoch: 6| Step: 6
Training loss: 2.269519090652466
Validation loss: 2.189359267552694

Epoch: 6| Step: 7
Training loss: 2.2642576694488525
Validation loss: 2.1855014165242515

Epoch: 6| Step: 8
Training loss: 2.0067014694213867
Validation loss: 2.184035579363505

Epoch: 6| Step: 9
Training loss: 2.0382232666015625
Validation loss: 2.1832087437311807

Epoch: 6| Step: 10
Training loss: 2.5738024711608887
Validation loss: 2.185139238834381

Epoch: 6| Step: 11
Training loss: 2.389695167541504
Validation loss: 2.183677097161611

Epoch: 6| Step: 12
Training loss: 2.337989330291748
Validation loss: 2.179898122946421

Epoch: 6| Step: 13
Training loss: 2.223454475402832
Validation loss: 2.176633139451345

Epoch: 54| Step: 0
Training loss: 2.1786093711853027
Validation loss: 2.1716351310412088

Epoch: 6| Step: 1
Training loss: 1.7666244506835938
Validation loss: 2.176625688870748

Epoch: 6| Step: 2
Training loss: 2.627228260040283
Validation loss: 2.1667003631591797

Epoch: 6| Step: 3
Training loss: 2.588993549346924
Validation loss: 2.1709298690160117

Epoch: 6| Step: 4
Training loss: 2.7844371795654297
Validation loss: 2.178242822488149

Epoch: 6| Step: 5
Training loss: 2.9432015419006348
Validation loss: 2.184011240800222

Epoch: 6| Step: 6
Training loss: 1.9856762886047363
Validation loss: 2.183156132698059

Epoch: 6| Step: 7
Training loss: 2.2954630851745605
Validation loss: 2.173966646194458

Epoch: 6| Step: 8
Training loss: 2.725078582763672
Validation loss: 2.171656926472982

Epoch: 6| Step: 9
Training loss: 1.882622241973877
Validation loss: 2.165680209795634

Epoch: 6| Step: 10
Training loss: 2.076554298400879
Validation loss: 2.168001711368561

Epoch: 6| Step: 11
Training loss: 2.0582163333892822
Validation loss: 2.1647799412409463

Epoch: 6| Step: 12
Training loss: 2.235429525375366
Validation loss: 2.168725868066152

Epoch: 6| Step: 13
Training loss: 2.5315754413604736
Validation loss: 2.168839156627655

Epoch: 55| Step: 0
Training loss: 2.7399964332580566
Validation loss: 2.167491873105367

Epoch: 6| Step: 1
Training loss: 2.5468878746032715
Validation loss: 2.168127636114756

Epoch: 6| Step: 2
Training loss: 2.699744462966919
Validation loss: 2.1664408842722573

Epoch: 6| Step: 3
Training loss: 2.3923091888427734
Validation loss: 2.167949914932251

Epoch: 6| Step: 4
Training loss: 2.5271592140197754
Validation loss: 2.1632694800694785

Epoch: 6| Step: 5
Training loss: 2.4820446968078613
Validation loss: 2.1623501777648926

Epoch: 6| Step: 6
Training loss: 1.9245126247406006
Validation loss: 2.15900727113088

Epoch: 6| Step: 7
Training loss: 2.027650833129883
Validation loss: 2.1561482548713684

Epoch: 6| Step: 8
Training loss: 2.122246742248535
Validation loss: 2.153832276662191

Epoch: 6| Step: 9
Training loss: 2.319263219833374
Validation loss: 2.1488613287607827

Epoch: 6| Step: 10
Training loss: 2.3758046627044678
Validation loss: 2.1468376914660134

Epoch: 6| Step: 11
Training loss: 1.7886829376220703
Validation loss: 2.1396273374557495

Epoch: 6| Step: 12
Training loss: 2.4548654556274414
Validation loss: 2.1403198838233948

Epoch: 6| Step: 13
Training loss: 2.0675268173217773
Validation loss: 2.147243936856588

Epoch: 56| Step: 0
Training loss: 2.428424835205078
Validation loss: 2.1523915926615396

Epoch: 6| Step: 1
Training loss: 2.004254102706909
Validation loss: 2.1340869267781577

Epoch: 6| Step: 2
Training loss: 1.5430610179901123
Validation loss: 2.1320785681406655

Epoch: 6| Step: 3
Training loss: 2.283231258392334
Validation loss: 2.137224038441976

Epoch: 6| Step: 4
Training loss: 2.936399459838867
Validation loss: 2.1441931327184043

Epoch: 6| Step: 5
Training loss: 2.4489645957946777
Validation loss: 2.1577549378077188

Epoch: 6| Step: 6
Training loss: 2.7697877883911133
Validation loss: 2.1513976057370505

Epoch: 6| Step: 7
Training loss: 2.2903313636779785
Validation loss: 2.1549832423528037

Epoch: 6| Step: 8
Training loss: 2.81998872756958
Validation loss: 2.153960963090261

Epoch: 6| Step: 9
Training loss: 2.156445264816284
Validation loss: 2.150906801223755

Epoch: 6| Step: 10
Training loss: 1.8296566009521484
Validation loss: 2.1514506936073303

Epoch: 6| Step: 11
Training loss: 2.4119668006896973
Validation loss: 2.1498302618662515

Epoch: 6| Step: 12
Training loss: 2.235598564147949
Validation loss: 2.1532171765963235

Epoch: 6| Step: 13
Training loss: 2.2705190181732178
Validation loss: 2.154891093571981

Epoch: 57| Step: 0
Training loss: 1.8354971408843994
Validation loss: 2.1589048703511557

Epoch: 6| Step: 1
Training loss: 2.540515661239624
Validation loss: 2.155829985936483

Epoch: 6| Step: 2
Training loss: 2.569673538208008
Validation loss: 2.1518148382504783

Epoch: 6| Step: 3
Training loss: 2.3324153423309326
Validation loss: 2.150885303815206

Epoch: 6| Step: 4
Training loss: 1.5959792137145996
Validation loss: 2.1494610706965127

Epoch: 6| Step: 5
Training loss: 2.2857537269592285
Validation loss: 2.137812634309133

Epoch: 6| Step: 6
Training loss: 2.7775120735168457
Validation loss: 2.12557852268219

Epoch: 6| Step: 7
Training loss: 2.205227851867676
Validation loss: 2.1239076058069863

Epoch: 6| Step: 8
Training loss: 2.1530282497406006
Validation loss: 2.122197429339091

Epoch: 6| Step: 9
Training loss: 2.204355001449585
Validation loss: 2.1134873827298484

Epoch: 6| Step: 10
Training loss: 2.6807150840759277
Validation loss: 2.1071361104647317

Epoch: 6| Step: 11
Training loss: 1.924357533454895
Validation loss: 2.1091278990109763

Epoch: 6| Step: 12
Training loss: 2.9785499572753906
Validation loss: 2.115756372610728

Epoch: 6| Step: 13
Training loss: 2.1856932640075684
Validation loss: 2.1092836062113443

Epoch: 58| Step: 0
Training loss: 2.4029603004455566
Validation loss: 2.108187516530355

Epoch: 6| Step: 1
Training loss: 2.3833045959472656
Validation loss: 2.1073177258173623

Epoch: 6| Step: 2
Training loss: 2.066915988922119
Validation loss: 2.1059979597727456

Epoch: 6| Step: 3
Training loss: 2.406956195831299
Validation loss: 2.1050300200780234

Epoch: 6| Step: 4
Training loss: 2.8564364910125732
Validation loss: 2.1103227138519287

Epoch: 6| Step: 5
Training loss: 2.0460610389709473
Validation loss: 2.1075172424316406

Epoch: 6| Step: 6
Training loss: 2.6020541191101074
Validation loss: 2.1131765842437744

Epoch: 6| Step: 7
Training loss: 2.452181339263916
Validation loss: 2.110928217569987

Epoch: 6| Step: 8
Training loss: 2.037148952484131
Validation loss: 2.1106920639673867

Epoch: 6| Step: 9
Training loss: 1.5525267124176025
Validation loss: 2.114235242207845

Epoch: 6| Step: 10
Training loss: 2.1643714904785156
Validation loss: 2.1140289306640625

Epoch: 6| Step: 11
Training loss: 2.138428211212158
Validation loss: 2.114067316055298

Epoch: 6| Step: 12
Training loss: 2.8053970336914062
Validation loss: 2.114182492097219

Epoch: 6| Step: 13
Training loss: 2.0525929927825928
Validation loss: 2.112604260444641

Epoch: 59| Step: 0
Training loss: 1.8384137153625488
Validation loss: 2.1118234197298684

Epoch: 6| Step: 1
Training loss: 2.7444534301757812
Validation loss: 2.1046442786852517

Epoch: 6| Step: 2
Training loss: 1.9811688661575317
Validation loss: 2.1068628231684365

Epoch: 6| Step: 3
Training loss: 2.2519800662994385
Validation loss: 2.1043155590693154

Epoch: 6| Step: 4
Training loss: 2.260995626449585
Validation loss: 2.1052536964416504

Epoch: 6| Step: 5
Training loss: 2.3678293228149414
Validation loss: 2.1031147042910256

Epoch: 6| Step: 6
Training loss: 2.319495916366577
Validation loss: 2.101352651913961

Epoch: 6| Step: 7
Training loss: 1.700730323791504
Validation loss: 2.1004289984703064

Epoch: 6| Step: 8
Training loss: 2.634119987487793
Validation loss: 2.104971925417582

Epoch: 6| Step: 9
Training loss: 1.9562206268310547
Validation loss: 2.1021430492401123

Epoch: 6| Step: 10
Training loss: 2.7973828315734863
Validation loss: 2.0978432496388755

Epoch: 6| Step: 11
Training loss: 1.9835622310638428
Validation loss: 2.099713365236918

Epoch: 6| Step: 12
Training loss: 2.699974536895752
Validation loss: 2.09446918964386

Epoch: 6| Step: 13
Training loss: 2.255133628845215
Validation loss: 2.0948221484820047

Epoch: 60| Step: 0
Training loss: 2.669480562210083
Validation loss: 2.089427093664805

Epoch: 6| Step: 1
Training loss: 2.123887062072754
Validation loss: 2.08537886540095

Epoch: 6| Step: 2
Training loss: 2.5460917949676514
Validation loss: 2.0844857494036355

Epoch: 6| Step: 3
Training loss: 2.4521889686584473
Validation loss: 2.0851564009984336

Epoch: 6| Step: 4
Training loss: 2.2153878211975098
Validation loss: 2.086196025212606

Epoch: 6| Step: 5
Training loss: 2.565615653991699
Validation loss: 2.083558142185211

Epoch: 6| Step: 6
Training loss: 2.3390417098999023
Validation loss: 2.0952929655710855

Epoch: 6| Step: 7
Training loss: 1.4924290180206299
Validation loss: 2.0816495219866433

Epoch: 6| Step: 8
Training loss: 2.1036477088928223
Validation loss: 2.0782485206921897

Epoch: 6| Step: 9
Training loss: 2.3437108993530273
Validation loss: 2.0803675850232444

Epoch: 6| Step: 10
Training loss: 2.2572553157806396
Validation loss: 2.082847793896993

Epoch: 6| Step: 11
Training loss: 2.648974895477295
Validation loss: 2.0882155100504556

Epoch: 6| Step: 12
Training loss: 1.905826449394226
Validation loss: 2.0858481725056968

Epoch: 6| Step: 13
Training loss: 1.971013069152832
Validation loss: 2.0899678270022073

Epoch: 61| Step: 0
Training loss: 2.4374008178710938
Validation loss: 2.091269632180532

Epoch: 6| Step: 1
Training loss: 1.972076416015625
Validation loss: 2.092046002546946

Epoch: 6| Step: 2
Training loss: 2.95398211479187
Validation loss: 2.0918797055880227

Epoch: 6| Step: 3
Training loss: 1.9668996334075928
Validation loss: 2.089277744293213

Epoch: 6| Step: 4
Training loss: 2.114682912826538
Validation loss: 2.0872218211491904

Epoch: 6| Step: 5
Training loss: 3.0143673419952393
Validation loss: 2.0884389678637185

Epoch: 6| Step: 6
Training loss: 1.8203749656677246
Validation loss: 2.0855835477511087

Epoch: 6| Step: 7
Training loss: 1.9205464124679565
Validation loss: 2.0797464847564697

Epoch: 6| Step: 8
Training loss: 2.6389224529266357
Validation loss: 2.081636885801951

Epoch: 6| Step: 9
Training loss: 1.711245059967041
Validation loss: 2.076487720012665

Epoch: 6| Step: 10
Training loss: 2.295355796813965
Validation loss: 2.075600504875183

Epoch: 6| Step: 11
Training loss: 1.5411434173583984
Validation loss: 2.0817750295003257

Epoch: 6| Step: 12
Training loss: 2.417830228805542
Validation loss: 2.0734804272651672

Epoch: 6| Step: 13
Training loss: 2.8221640586853027
Validation loss: 2.075284719467163

Epoch: 62| Step: 0
Training loss: 2.5716633796691895
Validation loss: 2.0692567427953086

Epoch: 6| Step: 1
Training loss: 2.2239277362823486
Validation loss: 2.0733818411827087

Epoch: 6| Step: 2
Training loss: 1.9399325847625732
Validation loss: 2.0750893155733743

Epoch: 6| Step: 3
Training loss: 2.0363364219665527
Validation loss: 2.072707732518514

Epoch: 6| Step: 4
Training loss: 2.4588396549224854
Validation loss: 2.068034748236338

Epoch: 6| Step: 5
Training loss: 2.076721429824829
Validation loss: 2.072134335835775

Epoch: 6| Step: 6
Training loss: 1.7265526056289673
Validation loss: 2.0664245883623757

Epoch: 6| Step: 7
Training loss: 2.476315498352051
Validation loss: 2.0652897159258523

Epoch: 6| Step: 8
Training loss: 2.254970073699951
Validation loss: 2.0592087507247925

Epoch: 6| Step: 9
Training loss: 2.084707260131836
Validation loss: 2.064247210820516

Epoch: 6| Step: 10
Training loss: 2.13773775100708
Validation loss: 2.0610968470573425

Epoch: 6| Step: 11
Training loss: 2.7814364433288574
Validation loss: 2.0601959029833474

Epoch: 6| Step: 12
Training loss: 2.306626081466675
Validation loss: 2.0555593967437744

Epoch: 6| Step: 13
Training loss: 2.2869505882263184
Validation loss: 2.0625994006792703

Epoch: 63| Step: 0
Training loss: 2.597064971923828
Validation loss: 2.0604949593544006

Epoch: 6| Step: 1
Training loss: 2.757982015609741
Validation loss: 2.057624399662018

Epoch: 6| Step: 2
Training loss: 2.839165210723877
Validation loss: 2.0581703583399453

Epoch: 6| Step: 3
Training loss: 2.1737430095672607
Validation loss: 2.0583835442860923

Epoch: 6| Step: 4
Training loss: 2.469341278076172
Validation loss: 2.0537994305292764

Epoch: 6| Step: 5
Training loss: 2.2650017738342285
Validation loss: 2.058549920717875

Epoch: 6| Step: 6
Training loss: 2.223954677581787
Validation loss: 2.050280193487803

Epoch: 6| Step: 7
Training loss: 2.2683677673339844
Validation loss: 2.0546719233194985

Epoch: 6| Step: 8
Training loss: 1.6000213623046875
Validation loss: 2.0517391363779702

Epoch: 6| Step: 9
Training loss: 2.695244073867798
Validation loss: 2.053410768508911

Epoch: 6| Step: 10
Training loss: 1.0679993629455566
Validation loss: 2.0557692448298135

Epoch: 6| Step: 11
Training loss: 2.0583863258361816
Validation loss: 2.0577152967453003

Epoch: 6| Step: 12
Training loss: 2.5097479820251465
Validation loss: 2.0577783584594727

Epoch: 6| Step: 13
Training loss: 1.7745943069458008
Validation loss: 2.053289790948232

Epoch: 64| Step: 0
Training loss: 1.7964571714401245
Validation loss: 2.0585757891337075

Epoch: 6| Step: 1
Training loss: 2.0008926391601562
Validation loss: 2.048222561677297

Epoch: 6| Step: 2
Training loss: 2.2299466133117676
Validation loss: 2.051541884740194

Epoch: 6| Step: 3
Training loss: 3.209404230117798
Validation loss: 2.0561254819234214

Epoch: 6| Step: 4
Training loss: 2.3648626804351807
Validation loss: 2.0580846865971885

Epoch: 6| Step: 5
Training loss: 1.7978463172912598
Validation loss: 2.0553435484568277

Epoch: 6| Step: 6
Training loss: 1.8771774768829346
Validation loss: 2.0529786149660745

Epoch: 6| Step: 7
Training loss: 1.9040489196777344
Validation loss: 2.0548417965571084

Epoch: 6| Step: 8
Training loss: 2.4850971698760986
Validation loss: 2.0474257866541543

Epoch: 6| Step: 9
Training loss: 3.059680700302124
Validation loss: 2.043057918548584

Epoch: 6| Step: 10
Training loss: 2.301574230194092
Validation loss: 2.0418432553609214

Epoch: 6| Step: 11
Training loss: 2.0410568714141846
Validation loss: 2.0421977043151855

Epoch: 6| Step: 12
Training loss: 2.38265323638916
Validation loss: 2.0467161734898887

Epoch: 6| Step: 13
Training loss: 1.7849184274673462
Validation loss: 2.049895405769348

Epoch: 65| Step: 0
Training loss: 1.5791113376617432
Validation loss: 2.0486658612887063

Epoch: 6| Step: 1
Training loss: 2.120567560195923
Validation loss: 2.049263676007589

Epoch: 6| Step: 2
Training loss: 2.06838321685791
Validation loss: 2.038967728614807

Epoch: 6| Step: 3
Training loss: 2.8675942420959473
Validation loss: 2.0413506627082825

Epoch: 6| Step: 4
Training loss: 2.5508217811584473
Validation loss: 2.0337162613868713

Epoch: 6| Step: 5
Training loss: 1.8835903406143188
Validation loss: 2.0399972597757974

Epoch: 6| Step: 6
Training loss: 1.8499866724014282
Validation loss: 2.0396525661150613

Epoch: 6| Step: 7
Training loss: 2.106659412384033
Validation loss: 2.0427166223526

Epoch: 6| Step: 8
Training loss: 2.6622345447540283
Validation loss: 2.0474654833475747

Epoch: 6| Step: 9
Training loss: 2.1931405067443848
Validation loss: 2.0463940699895224

Epoch: 6| Step: 10
Training loss: 1.9108796119689941
Validation loss: 2.0397233366966248

Epoch: 6| Step: 11
Training loss: 2.1302032470703125
Validation loss: 2.042598227659861

Epoch: 6| Step: 12
Training loss: 2.5072736740112305
Validation loss: 2.0363576809565225

Epoch: 6| Step: 13
Training loss: 2.655618667602539
Validation loss: 2.03178604443868

Epoch: 66| Step: 0
Training loss: 2.289198637008667
Validation loss: 2.0345517992973328

Epoch: 6| Step: 1
Training loss: 2.4656894207000732
Validation loss: 2.0358484983444214

Epoch: 6| Step: 2
Training loss: 1.3341515064239502
Validation loss: 2.0411061445871987

Epoch: 6| Step: 3
Training loss: 2.6412763595581055
Validation loss: 2.048843582471212

Epoch: 6| Step: 4
Training loss: 2.3724281787872314
Validation loss: 2.045669217904409

Epoch: 6| Step: 5
Training loss: 2.1327857971191406
Validation loss: 2.042972127596537

Epoch: 6| Step: 6
Training loss: 2.268256664276123
Validation loss: 2.0319405595461526

Epoch: 6| Step: 7
Training loss: 2.1851155757904053
Validation loss: 2.0251891215642295

Epoch: 6| Step: 8
Training loss: 2.082789897918701
Validation loss: 2.0334393779436746

Epoch: 6| Step: 9
Training loss: 2.118450164794922
Validation loss: 2.0420554876327515

Epoch: 6| Step: 10
Training loss: 2.0765671730041504
Validation loss: 2.05058761437734

Epoch: 6| Step: 11
Training loss: 2.499842882156372
Validation loss: 2.05612051486969

Epoch: 6| Step: 12
Training loss: 2.3285722732543945
Validation loss: 2.0675017635027566

Epoch: 6| Step: 13
Training loss: 2.060861110687256
Validation loss: 2.0606154799461365

Epoch: 67| Step: 0
Training loss: 1.787482500076294
Validation loss: 2.0625746846199036

Epoch: 6| Step: 1
Training loss: 2.9748330116271973
Validation loss: 2.0632184942563376

Epoch: 6| Step: 2
Training loss: 2.3833580017089844
Validation loss: 2.0609552462895713

Epoch: 6| Step: 3
Training loss: 2.213348388671875
Validation loss: 2.061034858226776

Epoch: 6| Step: 4
Training loss: 1.7194421291351318
Validation loss: 2.0648783644040427

Epoch: 6| Step: 5
Training loss: 3.0497472286224365
Validation loss: 2.0641122063001

Epoch: 6| Step: 6
Training loss: 1.5718382596969604
Validation loss: 2.062422533830007

Epoch: 6| Step: 7
Training loss: 2.7010860443115234
Validation loss: 2.0616559783617654

Epoch: 6| Step: 8
Training loss: 2.0271520614624023
Validation loss: 2.058251162370046

Epoch: 6| Step: 9
Training loss: 2.252802610397339
Validation loss: 2.0569249192873635

Epoch: 6| Step: 10
Training loss: 2.2911298274993896
Validation loss: 2.0523212949434915

Epoch: 6| Step: 11
Training loss: 1.5677316188812256
Validation loss: 2.053412437438965

Epoch: 6| Step: 12
Training loss: 2.118816614151001
Validation loss: 2.053333322207133

Epoch: 6| Step: 13
Training loss: 2.5505290031433105
Validation loss: 2.0456746021906533

Epoch: 68| Step: 0
Training loss: 2.1987149715423584
Validation loss: 2.034735381603241

Epoch: 6| Step: 1
Training loss: 2.0554234981536865
Validation loss: 2.0294765631357827

Epoch: 6| Step: 2
Training loss: 1.6077356338500977
Validation loss: 2.027038355668386

Epoch: 6| Step: 3
Training loss: 2.034790515899658
Validation loss: 2.0312419533729553

Epoch: 6| Step: 4
Training loss: 2.4347572326660156
Validation loss: 2.0251481930414834

Epoch: 6| Step: 5
Training loss: 2.2443459033966064
Validation loss: 2.030161678791046

Epoch: 6| Step: 6
Training loss: 1.9422895908355713
Validation loss: 2.027495344479879

Epoch: 6| Step: 7
Training loss: 2.700191020965576
Validation loss: 2.043757994969686

Epoch: 6| Step: 8
Training loss: 1.822263240814209
Validation loss: 2.0543970266977944

Epoch: 6| Step: 9
Training loss: 2.5763096809387207
Validation loss: 2.0632037123044333

Epoch: 6| Step: 10
Training loss: 2.7793760299682617
Validation loss: 2.081008871396383

Epoch: 6| Step: 11
Training loss: 2.0405960083007812
Validation loss: 2.069403807322184

Epoch: 6| Step: 12
Training loss: 2.0363450050354004
Validation loss: 2.0783080061276755

Epoch: 6| Step: 13
Training loss: 2.5997157096862793
Validation loss: 2.063451369603475

Epoch: 69| Step: 0
Training loss: 1.9176125526428223
Validation loss: 2.0427818298339844

Epoch: 6| Step: 1
Training loss: 2.5648250579833984
Validation loss: 2.048503657182058

Epoch: 6| Step: 2
Training loss: 2.453641414642334
Validation loss: 2.026693125565847

Epoch: 6| Step: 3
Training loss: 2.551121234893799
Validation loss: 2.0228736996650696

Epoch: 6| Step: 4
Training loss: 1.7190699577331543
Validation loss: 2.026647408803304

Epoch: 6| Step: 5
Training loss: 2.3583905696868896
Validation loss: 2.0322222312291465

Epoch: 6| Step: 6
Training loss: 2.3767035007476807
Validation loss: 2.0364414850870767

Epoch: 6| Step: 7
Training loss: 2.382406234741211
Validation loss: 2.043509781360626

Epoch: 6| Step: 8
Training loss: 2.2695374488830566
Validation loss: 2.0372339487075806

Epoch: 6| Step: 9
Training loss: 1.9051933288574219
Validation loss: 2.040400425593058

Epoch: 6| Step: 10
Training loss: 2.1878662109375
Validation loss: 2.036620835463206

Epoch: 6| Step: 11
Training loss: 1.9511610269546509
Validation loss: 2.0395216941833496

Epoch: 6| Step: 12
Training loss: 1.9355740547180176
Validation loss: 2.033619244893392

Epoch: 6| Step: 13
Training loss: 2.3806214332580566
Validation loss: 2.0318869153658548

Epoch: 70| Step: 0
Training loss: 1.9813710451126099
Validation loss: 2.0295655330022178

Epoch: 6| Step: 1
Training loss: 2.0661563873291016
Validation loss: 2.021928826967875

Epoch: 6| Step: 2
Training loss: 2.357579469680786
Validation loss: 2.015526612599691

Epoch: 6| Step: 3
Training loss: 2.08048677444458
Validation loss: 2.016309301058451

Epoch: 6| Step: 4
Training loss: 2.4513680934906006
Validation loss: 2.0182246367136636

Epoch: 6| Step: 5
Training loss: 2.1133928298950195
Validation loss: 2.0096680323282876

Epoch: 6| Step: 6
Training loss: 2.236471176147461
Validation loss: 2.0125478903452554

Epoch: 6| Step: 7
Training loss: 1.9100635051727295
Validation loss: 2.0168124636014304

Epoch: 6| Step: 8
Training loss: 1.7496172189712524
Validation loss: 2.0204583406448364

Epoch: 6| Step: 9
Training loss: 2.0820059776306152
Validation loss: 2.02785716454188

Epoch: 6| Step: 10
Training loss: 2.623784303665161
Validation loss: 2.03563400109609

Epoch: 6| Step: 11
Training loss: 2.2510838508605957
Validation loss: 2.0365881522496543

Epoch: 6| Step: 12
Training loss: 2.3205764293670654
Validation loss: 2.0366418759028115

Epoch: 6| Step: 13
Training loss: 2.598257303237915
Validation loss: 2.0267358819643655

Epoch: 71| Step: 0
Training loss: 2.171647310256958
Validation loss: 2.018647849559784

Epoch: 6| Step: 1
Training loss: 2.5394136905670166
Validation loss: 2.014839748541514

Epoch: 6| Step: 2
Training loss: 2.204835891723633
Validation loss: 2.0145265658696494

Epoch: 6| Step: 3
Training loss: 2.205336570739746
Validation loss: 2.0100746750831604

Epoch: 6| Step: 4
Training loss: 2.1061606407165527
Validation loss: 2.013512750466665

Epoch: 6| Step: 5
Training loss: 2.2859654426574707
Validation loss: 2.0200292269388833

Epoch: 6| Step: 6
Training loss: 1.6666882038116455
Validation loss: 2.020856738090515

Epoch: 6| Step: 7
Training loss: 1.7877767086029053
Validation loss: 2.0271959702173867

Epoch: 6| Step: 8
Training loss: 2.0105056762695312
Validation loss: 2.028723180294037

Epoch: 6| Step: 9
Training loss: 2.5616304874420166
Validation loss: 2.033613304297129

Epoch: 6| Step: 10
Training loss: 2.3032543659210205
Validation loss: 2.0357701778411865

Epoch: 6| Step: 11
Training loss: 2.2212672233581543
Validation loss: 2.035421073436737

Epoch: 6| Step: 12
Training loss: 2.4365501403808594
Validation loss: 2.0280991991360984

Epoch: 6| Step: 13
Training loss: 2.1348438262939453
Validation loss: 2.024308224519094

Epoch: 72| Step: 0
Training loss: 2.3235301971435547
Validation loss: 2.020386795202891

Epoch: 6| Step: 1
Training loss: 1.808025598526001
Validation loss: 2.0211485425631204

Epoch: 6| Step: 2
Training loss: 2.1516404151916504
Validation loss: 2.0156227747599282

Epoch: 6| Step: 3
Training loss: 1.8254581689834595
Validation loss: 2.0180235703786216

Epoch: 6| Step: 4
Training loss: 2.3024425506591797
Validation loss: 2.0222023129463196

Epoch: 6| Step: 5
Training loss: 2.5304722785949707
Validation loss: 2.0328922867774963

Epoch: 6| Step: 6
Training loss: 2.5744855403900146
Validation loss: 2.0374711553255715

Epoch: 6| Step: 7
Training loss: 2.290138006210327
Validation loss: 2.0438762108484902

Epoch: 6| Step: 8
Training loss: 2.0692639350891113
Validation loss: 2.0497480630874634

Epoch: 6| Step: 9
Training loss: 2.189899444580078
Validation loss: 2.0491530497868857

Epoch: 6| Step: 10
Training loss: 1.8265842199325562
Validation loss: 2.0476343234380088

Epoch: 6| Step: 11
Training loss: 2.092625141143799
Validation loss: 2.0484888354937234

Epoch: 6| Step: 12
Training loss: 2.516432762145996
Validation loss: 2.0346973141034446

Epoch: 6| Step: 13
Training loss: 2.1426515579223633
Validation loss: 2.023709158102671

Epoch: 73| Step: 0
Training loss: 1.936205267906189
Validation loss: 2.015024562676748

Epoch: 6| Step: 1
Training loss: 2.069204330444336
Validation loss: 2.015529374281565

Epoch: 6| Step: 2
Training loss: 1.9229776859283447
Validation loss: 2.023487309614817

Epoch: 6| Step: 3
Training loss: 2.159804105758667
Validation loss: 2.0324049989382424

Epoch: 6| Step: 4
Training loss: 2.664438486099243
Validation loss: 2.0266897281010947

Epoch: 6| Step: 5
Training loss: 2.4301204681396484
Validation loss: 2.0338706572850547

Epoch: 6| Step: 6
Training loss: 1.8623384237289429
Validation loss: 2.0312976241111755

Epoch: 6| Step: 7
Training loss: 2.0725996494293213
Validation loss: 2.0307870705922446

Epoch: 6| Step: 8
Training loss: 2.787827730178833
Validation loss: 2.0326793789863586

Epoch: 6| Step: 9
Training loss: 2.0752995014190674
Validation loss: 2.0311275124549866

Epoch: 6| Step: 10
Training loss: 1.7503397464752197
Validation loss: 2.026853541533152

Epoch: 6| Step: 11
Training loss: 2.16660213470459
Validation loss: 2.0294072031974792

Epoch: 6| Step: 12
Training loss: 2.240522861480713
Validation loss: 2.0208971897761026

Epoch: 6| Step: 13
Training loss: 2.371873617172241
Validation loss: 2.017777760823568

Epoch: 74| Step: 0
Training loss: 2.311171531677246
Validation loss: 2.017904043197632

Epoch: 6| Step: 1
Training loss: 2.245624542236328
Validation loss: 2.0085789958635965

Epoch: 6| Step: 2
Training loss: 1.9861472845077515
Validation loss: 2.0133804281552634

Epoch: 6| Step: 3
Training loss: 1.7679346799850464
Validation loss: 2.0231298009554544

Epoch: 6| Step: 4
Training loss: 1.9520509243011475
Validation loss: 2.029378513495127

Epoch: 6| Step: 5
Training loss: 3.1717066764831543
Validation loss: 2.0299765865008035

Epoch: 6| Step: 6
Training loss: 1.888725996017456
Validation loss: 2.0314862529436746

Epoch: 6| Step: 7
Training loss: 1.6426417827606201
Validation loss: 2.030613362789154

Epoch: 6| Step: 8
Training loss: 2.542782783508301
Validation loss: 2.0332652727762857

Epoch: 6| Step: 9
Training loss: 2.0063323974609375
Validation loss: 2.0199522574742637

Epoch: 6| Step: 10
Training loss: 2.089690685272217
Validation loss: 2.0176623860994973

Epoch: 6| Step: 11
Training loss: 1.8091514110565186
Validation loss: 2.0246272683143616

Epoch: 6| Step: 12
Training loss: 2.6808040142059326
Validation loss: 2.023862143357595

Epoch: 6| Step: 13
Training loss: 2.095127582550049
Validation loss: 2.0184636314709983

Epoch: 75| Step: 0
Training loss: 2.5915427207946777
Validation loss: 2.0304993192354837

Epoch: 6| Step: 1
Training loss: 2.2285523414611816
Validation loss: 2.0166430473327637

Epoch: 6| Step: 2
Training loss: 1.9260327816009521
Validation loss: 2.0206619103749595

Epoch: 6| Step: 3
Training loss: 1.7208845615386963
Validation loss: 2.027054806550344

Epoch: 6| Step: 4
Training loss: 2.7218949794769287
Validation loss: 2.0321489373842874

Epoch: 6| Step: 5
Training loss: 2.2757046222686768
Validation loss: 2.0322912335395813

Epoch: 6| Step: 6
Training loss: 1.7722978591918945
Validation loss: 2.0378900369008384

Epoch: 6| Step: 7
Training loss: 2.0105249881744385
Validation loss: 2.03022034962972

Epoch: 6| Step: 8
Training loss: 1.9061474800109863
Validation loss: 2.0333784023920694

Epoch: 6| Step: 9
Training loss: 2.0011048316955566
Validation loss: 2.0297725598017373

Epoch: 6| Step: 10
Training loss: 2.344938278198242
Validation loss: 2.0172314445177713

Epoch: 6| Step: 11
Training loss: 2.311414957046509
Validation loss: 2.0203504959742227

Epoch: 6| Step: 12
Training loss: 2.1454505920410156
Validation loss: 2.0161237915356955

Epoch: 6| Step: 13
Training loss: 2.2686493396759033
Validation loss: 2.015876511732737

Epoch: 76| Step: 0
Training loss: 2.145148754119873
Validation loss: 2.0115354855855307

Epoch: 6| Step: 1
Training loss: 1.8769959211349487
Validation loss: 2.012950321038564

Epoch: 6| Step: 2
Training loss: 1.8052501678466797
Validation loss: 2.022234340508779

Epoch: 6| Step: 3
Training loss: 2.4594333171844482
Validation loss: 2.0168697039286294

Epoch: 6| Step: 4
Training loss: 1.7861803770065308
Validation loss: 2.008498469988505

Epoch: 6| Step: 5
Training loss: 2.1506361961364746
Validation loss: 2.013719896475474

Epoch: 6| Step: 6
Training loss: 1.9082491397857666
Validation loss: 2.0035011569658914

Epoch: 6| Step: 7
Training loss: 2.3173251152038574
Validation loss: 2.0113512873649597

Epoch: 6| Step: 8
Training loss: 3.0283079147338867
Validation loss: 2.0120118856430054

Epoch: 6| Step: 9
Training loss: 2.344076156616211
Validation loss: 2.0178928772608438

Epoch: 6| Step: 10
Training loss: 2.4553070068359375
Validation loss: 2.015747547149658

Epoch: 6| Step: 11
Training loss: 2.170119047164917
Validation loss: 2.01340788602829

Epoch: 6| Step: 12
Training loss: 2.0159144401550293
Validation loss: 2.018178701400757

Epoch: 6| Step: 13
Training loss: 1.6991770267486572
Validation loss: 2.0121289690335593

Epoch: 77| Step: 0
Training loss: 2.284747838973999
Validation loss: 2.0171420176823935

Epoch: 6| Step: 1
Training loss: 1.722188115119934
Validation loss: 2.014672060807546

Epoch: 6| Step: 2
Training loss: 1.8877359628677368
Validation loss: 2.0108139514923096

Epoch: 6| Step: 3
Training loss: 2.6176681518554688
Validation loss: 2.010558823744456

Epoch: 6| Step: 4
Training loss: 1.891209602355957
Validation loss: 2.023638884226481

Epoch: 6| Step: 5
Training loss: 2.64801025390625
Validation loss: 2.014565408229828

Epoch: 6| Step: 6
Training loss: 1.9361865520477295
Validation loss: 2.0165641705195108

Epoch: 6| Step: 7
Training loss: 2.7191739082336426
Validation loss: 2.0131877859433494

Epoch: 6| Step: 8
Training loss: 2.267956495285034
Validation loss: 2.011851648489634

Epoch: 6| Step: 9
Training loss: 2.0966219902038574
Validation loss: 2.0238616665204368

Epoch: 6| Step: 10
Training loss: 1.6723556518554688
Validation loss: 2.0207591454188027

Epoch: 6| Step: 11
Training loss: 1.8239604234695435
Validation loss: 2.017996867497762

Epoch: 6| Step: 12
Training loss: 2.27150821685791
Validation loss: 2.0095947980880737

Epoch: 6| Step: 13
Training loss: 2.2065587043762207
Validation loss: 2.006158431371053

Epoch: 78| Step: 0
Training loss: 2.1924946308135986
Validation loss: 2.0129363735516868

Epoch: 6| Step: 1
Training loss: 2.093742847442627
Validation loss: 2.013955593109131

Epoch: 6| Step: 2
Training loss: 2.5375356674194336
Validation loss: 2.006701191266378

Epoch: 6| Step: 3
Training loss: 1.8123302459716797
Validation loss: 2.019878327846527

Epoch: 6| Step: 4
Training loss: 2.420125722885132
Validation loss: 2.01777054866155

Epoch: 6| Step: 5
Training loss: 2.516051769256592
Validation loss: 2.0168707768122354

Epoch: 6| Step: 6
Training loss: 2.1969082355499268
Validation loss: 2.014175852139791

Epoch: 6| Step: 7
Training loss: 2.321054458618164
Validation loss: 2.0120909611384072

Epoch: 6| Step: 8
Training loss: 1.9992692470550537
Validation loss: 2.015896658102671

Epoch: 6| Step: 9
Training loss: 2.307774066925049
Validation loss: 2.0110190510749817

Epoch: 6| Step: 10
Training loss: 1.9532973766326904
Validation loss: 2.0175649722417197

Epoch: 6| Step: 11
Training loss: 1.9593228101730347
Validation loss: 2.013134221235911

Epoch: 6| Step: 12
Training loss: 2.433960437774658
Validation loss: 2.014422595500946

Epoch: 6| Step: 13
Training loss: 1.428856372833252
Validation loss: 2.0188294450441995

Epoch: 79| Step: 0
Training loss: 2.347144603729248
Validation loss: 2.020413815975189

Epoch: 6| Step: 1
Training loss: 2.5753495693206787
Validation loss: 2.022338628768921

Epoch: 6| Step: 2
Training loss: 1.7493255138397217
Validation loss: 2.0210485458374023

Epoch: 6| Step: 3
Training loss: 2.229186534881592
Validation loss: 2.0282066265741983

Epoch: 6| Step: 4
Training loss: 2.056314468383789
Validation loss: 2.0268854101498923

Epoch: 6| Step: 5
Training loss: 2.5894522666931152
Validation loss: 2.0210368235905967

Epoch: 6| Step: 6
Training loss: 1.7110369205474854
Validation loss: 2.0246546864509583

Epoch: 6| Step: 7
Training loss: 1.7881578207015991
Validation loss: 2.0289542078971863

Epoch: 6| Step: 8
Training loss: 1.79304039478302
Validation loss: 2.025919238726298

Epoch: 6| Step: 9
Training loss: 2.3851919174194336
Validation loss: 2.021036426226298

Epoch: 6| Step: 10
Training loss: 2.0132460594177246
Validation loss: 2.0237247943878174

Epoch: 6| Step: 11
Training loss: 2.1355414390563965
Validation loss: 2.0176793734232583

Epoch: 6| Step: 12
Training loss: 1.8346238136291504
Validation loss: 2.023409982522329

Epoch: 6| Step: 13
Training loss: 2.881397247314453
Validation loss: 2.0118872125943503

Epoch: 80| Step: 0
Training loss: 1.3546257019042969
Validation loss: 2.013947526613871

Epoch: 6| Step: 1
Training loss: 2.2594237327575684
Validation loss: 2.0171104868253074

Epoch: 6| Step: 2
Training loss: 2.252530097961426
Validation loss: 2.0178613861401877

Epoch: 6| Step: 3
Training loss: 2.151365280151367
Validation loss: 2.010082423686981

Epoch: 6| Step: 4
Training loss: 2.4187533855438232
Validation loss: 2.0128250122070312

Epoch: 6| Step: 5
Training loss: 2.492604970932007
Validation loss: 2.0119407574335733

Epoch: 6| Step: 6
Training loss: 1.737636923789978
Validation loss: 2.0116658012072244

Epoch: 6| Step: 7
Training loss: 2.4483156204223633
Validation loss: 2.006704807281494

Epoch: 6| Step: 8
Training loss: 2.3995795249938965
Validation loss: 2.015045702457428

Epoch: 6| Step: 9
Training loss: 1.3415899276733398
Validation loss: 2.016137440999349

Epoch: 6| Step: 10
Training loss: 1.9848719835281372
Validation loss: 2.0241756240526834

Epoch: 6| Step: 11
Training loss: 2.587587833404541
Validation loss: 2.0260122418403625

Epoch: 6| Step: 12
Training loss: 2.2598586082458496
Validation loss: 2.0339728196461997

Epoch: 6| Step: 13
Training loss: 2.3060054779052734
Validation loss: 2.0309924880663552

Epoch: 81| Step: 0
Training loss: 2.559187650680542
Validation loss: 2.037366211414337

Epoch: 6| Step: 1
Training loss: 1.3385205268859863
Validation loss: 2.0390798846880593

Epoch: 6| Step: 2
Training loss: 2.375476837158203
Validation loss: 2.034106890360514

Epoch: 6| Step: 3
Training loss: 2.3180813789367676
Validation loss: 2.0434038837750754

Epoch: 6| Step: 4
Training loss: 2.413893699645996
Validation loss: 2.033544401327769

Epoch: 6| Step: 5
Training loss: 1.9262268543243408
Validation loss: 2.0225876768430076

Epoch: 6| Step: 6
Training loss: 1.5166783332824707
Validation loss: 2.020256817340851

Epoch: 6| Step: 7
Training loss: 2.0817923545837402
Validation loss: 2.006347894668579

Epoch: 6| Step: 8
Training loss: 2.345795154571533
Validation loss: 2.013416131337484

Epoch: 6| Step: 9
Training loss: 1.8430993556976318
Validation loss: 2.01695450146993

Epoch: 6| Step: 10
Training loss: 2.517401695251465
Validation loss: 2.015944262345632

Epoch: 6| Step: 11
Training loss: 2.2756919860839844
Validation loss: 2.0118608673413596

Epoch: 6| Step: 12
Training loss: 2.4071860313415527
Validation loss: 2.015819549560547

Epoch: 6| Step: 13
Training loss: 2.2240757942199707
Validation loss: 2.025540749231974

Epoch: 82| Step: 0
Training loss: 1.8378956317901611
Validation loss: 2.0285571416219077

Epoch: 6| Step: 1
Training loss: 2.1843631267547607
Validation loss: 2.0256054401397705

Epoch: 6| Step: 2
Training loss: 2.107043743133545
Validation loss: 2.0316369334856668

Epoch: 6| Step: 3
Training loss: 1.9177281856536865
Validation loss: 2.030156195163727

Epoch: 6| Step: 4
Training loss: 1.8035061359405518
Validation loss: 2.0321666598320007

Epoch: 6| Step: 5
Training loss: 2.542675495147705
Validation loss: 2.0308265686035156

Epoch: 6| Step: 6
Training loss: 2.2943503856658936
Validation loss: 2.03319658835729

Epoch: 6| Step: 7
Training loss: 1.983604073524475
Validation loss: 2.029499034086863

Epoch: 6| Step: 8
Training loss: 1.8960161209106445
Validation loss: 2.0319753885269165

Epoch: 6| Step: 9
Training loss: 1.8576098680496216
Validation loss: 2.030297497908274

Epoch: 6| Step: 10
Training loss: 3.093078136444092
Validation loss: 2.0259264707565308

Epoch: 6| Step: 11
Training loss: 1.9863311052322388
Validation loss: 2.026816109816233

Epoch: 6| Step: 12
Training loss: 2.4780828952789307
Validation loss: 2.0222591757774353

Epoch: 6| Step: 13
Training loss: 1.9530270099639893
Validation loss: 2.0276636282602944

Epoch: 83| Step: 0
Training loss: 2.291900396347046
Validation loss: 2.0193684895833335

Epoch: 6| Step: 1
Training loss: 1.9714000225067139
Validation loss: 2.0276989936828613

Epoch: 6| Step: 2
Training loss: 1.3735312223434448
Validation loss: 2.0249033768971763

Epoch: 6| Step: 3
Training loss: 1.3768560886383057
Validation loss: 2.0241227944691977

Epoch: 6| Step: 4
Training loss: 2.04164981842041
Validation loss: 2.0150359471639

Epoch: 6| Step: 5
Training loss: 1.962831735610962
Validation loss: 2.02049054702123

Epoch: 6| Step: 6
Training loss: 2.6250157356262207
Validation loss: 2.0164058605829873

Epoch: 6| Step: 7
Training loss: 2.65754771232605
Validation loss: 2.0240670442581177

Epoch: 6| Step: 8
Training loss: 2.4991865158081055
Validation loss: 2.026758929093679

Epoch: 6| Step: 9
Training loss: 2.1809606552124023
Validation loss: 2.023014465967814

Epoch: 6| Step: 10
Training loss: 1.7522187232971191
Validation loss: 2.0268306136131287

Epoch: 6| Step: 11
Training loss: 2.319284439086914
Validation loss: 2.0253303249677024

Epoch: 6| Step: 12
Training loss: 2.5688352584838867
Validation loss: 2.0275967518488565

Epoch: 6| Step: 13
Training loss: 2.25268816947937
Validation loss: 2.024280031522115

Epoch: 84| Step: 0
Training loss: 1.8337956666946411
Validation loss: 2.026136358579

Epoch: 6| Step: 1
Training loss: 2.1449437141418457
Validation loss: 2.0200291872024536

Epoch: 6| Step: 2
Training loss: 2.4864559173583984
Validation loss: 2.0107469161351523

Epoch: 6| Step: 3
Training loss: 1.8081867694854736
Validation loss: 2.0133527716000876

Epoch: 6| Step: 4
Training loss: 1.9654536247253418
Validation loss: 2.0191932121912637

Epoch: 6| Step: 5
Training loss: 2.541654109954834
Validation loss: 2.0143784085909524

Epoch: 6| Step: 6
Training loss: 2.041107654571533
Validation loss: 2.014135797818502

Epoch: 6| Step: 7
Training loss: 2.4507083892822266
Validation loss: 2.0248698393503823

Epoch: 6| Step: 8
Training loss: 2.257214307785034
Validation loss: 2.0175541241963706

Epoch: 6| Step: 9
Training loss: 2.199110984802246
Validation loss: 2.0186381737391152

Epoch: 6| Step: 10
Training loss: 2.2957897186279297
Validation loss: 2.0224979718526206

Epoch: 6| Step: 11
Training loss: 1.2367064952850342
Validation loss: 2.020108222961426

Epoch: 6| Step: 12
Training loss: 1.9771347045898438
Validation loss: 2.024561822414398

Epoch: 6| Step: 13
Training loss: 2.5866687297821045
Validation loss: 2.0335798064867654

Epoch: 85| Step: 0
Training loss: 2.967064619064331
Validation loss: 2.034179170926412

Epoch: 6| Step: 1
Training loss: 2.2565245628356934
Validation loss: 2.033268849054972

Epoch: 6| Step: 2
Training loss: 2.511500835418701
Validation loss: 2.0345331827799478

Epoch: 6| Step: 3
Training loss: 1.9799647331237793
Validation loss: 2.032099743684133

Epoch: 6| Step: 4
Training loss: 1.827244520187378
Validation loss: 2.03747296333313

Epoch: 6| Step: 5
Training loss: 2.5286507606506348
Validation loss: 2.0364853938420615

Epoch: 6| Step: 6
Training loss: 2.0978076457977295
Validation loss: 2.036681850751241

Epoch: 6| Step: 7
Training loss: 2.5390379428863525
Validation loss: 2.0246166388193765

Epoch: 6| Step: 8
Training loss: 2.3299930095672607
Validation loss: 2.0230772495269775

Epoch: 6| Step: 9
Training loss: 2.2550103664398193
Validation loss: 2.0213406682014465

Epoch: 6| Step: 10
Training loss: 1.7199339866638184
Validation loss: 2.0211750666300454

Epoch: 6| Step: 11
Training loss: 1.362048625946045
Validation loss: 2.0233510931332908

Epoch: 6| Step: 12
Training loss: 1.5472848415374756
Validation loss: 2.022288143634796

Epoch: 6| Step: 13
Training loss: 1.8495852947235107
Validation loss: 2.0233985582987466

Epoch: 86| Step: 0
Training loss: 1.9509966373443604
Validation loss: 2.027266879876455

Epoch: 6| Step: 1
Training loss: 2.4945223331451416
Validation loss: 2.02724152803421

Epoch: 6| Step: 2
Training loss: 2.3103249073028564
Validation loss: 2.0417786836624146

Epoch: 6| Step: 3
Training loss: 1.7333095073699951
Validation loss: 2.0411773522694907

Epoch: 6| Step: 4
Training loss: 2.129101037979126
Validation loss: 2.038256525993347

Epoch: 6| Step: 5
Training loss: 2.257263660430908
Validation loss: 2.0335575540860495

Epoch: 6| Step: 6
Training loss: 2.3838820457458496
Validation loss: 2.026066780090332

Epoch: 6| Step: 7
Training loss: 2.7209930419921875
Validation loss: 2.0255134105682373

Epoch: 6| Step: 8
Training loss: 1.8698234558105469
Validation loss: 2.014182190100352

Epoch: 6| Step: 9
Training loss: 1.7258925437927246
Validation loss: 2.0148159066836038

Epoch: 6| Step: 10
Training loss: 2.4209203720092773
Validation loss: 2.0094322562217712

Epoch: 6| Step: 11
Training loss: 2.198223114013672
Validation loss: 2.0035959680875144

Epoch: 6| Step: 12
Training loss: 1.9405869245529175
Validation loss: 2.0003244280815125

Epoch: 6| Step: 13
Training loss: 1.7156000137329102
Validation loss: 2.005861481030782

Epoch: 87| Step: 0
Training loss: 2.302771806716919
Validation loss: 2.0080995758374534

Epoch: 6| Step: 1
Training loss: 1.9183659553527832
Validation loss: 2.010097543398539

Epoch: 6| Step: 2
Training loss: 2.7783024311065674
Validation loss: 2.002639671166738

Epoch: 6| Step: 3
Training loss: 2.525608539581299
Validation loss: 2.0084948341051736

Epoch: 6| Step: 4
Training loss: 1.9198211431503296
Validation loss: 2.015151778856913

Epoch: 6| Step: 5
Training loss: 1.8931212425231934
Validation loss: 2.028777599334717

Epoch: 6| Step: 6
Training loss: 2.098419427871704
Validation loss: 2.0302738746007285

Epoch: 6| Step: 7
Training loss: 1.8280115127563477
Validation loss: 2.0241031845410666

Epoch: 6| Step: 8
Training loss: 2.5872459411621094
Validation loss: 2.0308738152186074

Epoch: 6| Step: 9
Training loss: 2.3673195838928223
Validation loss: 2.02908992767334

Epoch: 6| Step: 10
Training loss: 2.266584634780884
Validation loss: 2.0319318771362305

Epoch: 6| Step: 11
Training loss: 2.095973014831543
Validation loss: 2.0441686113675437

Epoch: 6| Step: 12
Training loss: 1.3765641450881958
Validation loss: 2.0434263944625854

Epoch: 6| Step: 13
Training loss: 1.9365484714508057
Validation loss: 2.0416243275006614

Epoch: 88| Step: 0
Training loss: 2.0137243270874023
Validation loss: 2.040852665901184

Epoch: 6| Step: 1
Training loss: 2.4218671321868896
Validation loss: 2.0399794975916543

Epoch: 6| Step: 2
Training loss: 1.3985155820846558
Validation loss: 2.0394790172576904

Epoch: 6| Step: 3
Training loss: 2.0650441646575928
Validation loss: 2.041390677293142

Epoch: 6| Step: 4
Training loss: 2.5862419605255127
Validation loss: 2.032073438167572

Epoch: 6| Step: 5
Training loss: 2.0562684535980225
Validation loss: 2.0348965525627136

Epoch: 6| Step: 6
Training loss: 1.8134803771972656
Validation loss: 2.0373915433883667

Epoch: 6| Step: 7
Training loss: 3.026139259338379
Validation loss: 2.0346684654553733

Epoch: 6| Step: 8
Training loss: 1.8548251390457153
Validation loss: 2.0293126304944358

Epoch: 6| Step: 9
Training loss: 2.749812126159668
Validation loss: 2.050933758417765

Epoch: 6| Step: 10
Training loss: 1.4369059801101685
Validation loss: 2.0290580590566

Epoch: 6| Step: 11
Training loss: 1.552435278892517
Validation loss: 2.0309120615323386

Epoch: 6| Step: 12
Training loss: 2.844022750854492
Validation loss: 2.015413741270701

Epoch: 6| Step: 13
Training loss: 1.9464256763458252
Validation loss: 2.007070243358612

Epoch: 89| Step: 0
Training loss: 1.8834283351898193
Validation loss: 2.011653701464335

Epoch: 6| Step: 1
Training loss: 2.3778469562530518
Validation loss: 2.00843737522761

Epoch: 6| Step: 2
Training loss: 2.423985481262207
Validation loss: 1.993242343266805

Epoch: 6| Step: 3
Training loss: 1.6220217943191528
Validation loss: 1.9977329572041829

Epoch: 6| Step: 4
Training loss: 1.9521071910858154
Validation loss: 1.998233715693156

Epoch: 6| Step: 5
Training loss: 2.216136932373047
Validation loss: 2.002512296040853

Epoch: 6| Step: 6
Training loss: 2.2424230575561523
Validation loss: 1.9964740077654521

Epoch: 6| Step: 7
Training loss: 2.637085199356079
Validation loss: 1.9965434074401855

Epoch: 6| Step: 8
Training loss: 1.5080628395080566
Validation loss: 1.9967052936553955

Epoch: 6| Step: 9
Training loss: 2.2934341430664062
Validation loss: 1.9952935775121052

Epoch: 6| Step: 10
Training loss: 2.8324618339538574
Validation loss: 1.9946844975153606

Epoch: 6| Step: 11
Training loss: 1.5306706428527832
Validation loss: 2.000154495239258

Epoch: 6| Step: 12
Training loss: 2.2703170776367188
Validation loss: 2.007535537083944

Epoch: 6| Step: 13
Training loss: 2.0693955421447754
Validation loss: 2.008428613344828

Epoch: 90| Step: 0
Training loss: 1.7163238525390625
Validation loss: 2.0068636933962503

Epoch: 6| Step: 1
Training loss: 1.8046157360076904
Validation loss: 2.0091400146484375

Epoch: 6| Step: 2
Training loss: 2.471956253051758
Validation loss: 2.0004486640294394

Epoch: 6| Step: 3
Training loss: 2.0793213844299316
Validation loss: 2.0102693239847818

Epoch: 6| Step: 4
Training loss: 1.9395709037780762
Validation loss: 2.0097911755243936

Epoch: 6| Step: 5
Training loss: 1.8218176364898682
Validation loss: 2.01291557153066

Epoch: 6| Step: 6
Training loss: 2.142976999282837
Validation loss: 2.024283548196157

Epoch: 6| Step: 7
Training loss: 2.272643566131592
Validation loss: 2.032219092051188

Epoch: 6| Step: 8
Training loss: 2.329533100128174
Validation loss: 2.0124292174975076

Epoch: 6| Step: 9
Training loss: 2.1098389625549316
Validation loss: 2.008756160736084

Epoch: 6| Step: 10
Training loss: 2.432853937149048
Validation loss: 2.003029008706411

Epoch: 6| Step: 11
Training loss: 2.7123050689697266
Validation loss: 2.0011412501335144

Epoch: 6| Step: 12
Training loss: 2.108025550842285
Validation loss: 2.0076246857643127

Epoch: 6| Step: 13
Training loss: 1.848504662513733
Validation loss: 2.0072606404622397

Epoch: 91| Step: 0
Training loss: 1.7791045904159546
Validation loss: 2.0062149365743003

Epoch: 6| Step: 1
Training loss: 2.49489164352417
Validation loss: 2.003567159175873

Epoch: 6| Step: 2
Training loss: 2.338578224182129
Validation loss: 1.9961899320284526

Epoch: 6| Step: 3
Training loss: 1.545080304145813
Validation loss: 2.006102283795675

Epoch: 6| Step: 4
Training loss: 2.2703957557678223
Validation loss: 2.0091514388720193

Epoch: 6| Step: 5
Training loss: 2.1672773361206055
Validation loss: 2.0157397389411926

Epoch: 6| Step: 6
Training loss: 1.516298532485962
Validation loss: 2.009383976459503

Epoch: 6| Step: 7
Training loss: 1.9832100868225098
Validation loss: 2.008658230304718

Epoch: 6| Step: 8
Training loss: 1.9562315940856934
Validation loss: 2.0077204505602517

Epoch: 6| Step: 9
Training loss: 1.9041881561279297
Validation loss: 2.009283403555552

Epoch: 6| Step: 10
Training loss: 2.9444875717163086
Validation loss: 2.0029465754826865

Epoch: 6| Step: 11
Training loss: 1.9894835948944092
Validation loss: 2.0164095958073935

Epoch: 6| Step: 12
Training loss: 2.5463216304779053
Validation loss: 2.0202375451723733

Epoch: 6| Step: 13
Training loss: 2.336977005004883
Validation loss: 2.021293262640635

Epoch: 92| Step: 0
Training loss: 2.0665950775146484
Validation loss: 2.027202924092611

Epoch: 6| Step: 1
Training loss: 2.606539249420166
Validation loss: 2.040910224119822

Epoch: 6| Step: 2
Training loss: 2.4682812690734863
Validation loss: 2.030362606048584

Epoch: 6| Step: 3
Training loss: 2.060884952545166
Validation loss: 2.023553470770518

Epoch: 6| Step: 4
Training loss: 1.9939217567443848
Validation loss: 2.0324638287226358

Epoch: 6| Step: 5
Training loss: 2.071157932281494
Validation loss: 2.0281463464101157

Epoch: 6| Step: 6
Training loss: 1.8202402591705322
Validation loss: 2.0188057820002236

Epoch: 6| Step: 7
Training loss: 2.1926560401916504
Validation loss: 2.028701444466909

Epoch: 6| Step: 8
Training loss: 1.9141889810562134
Validation loss: 2.0151449839274087

Epoch: 6| Step: 9
Training loss: 2.702238082885742
Validation loss: 2.0144724448521933

Epoch: 6| Step: 10
Training loss: 1.9451195001602173
Validation loss: 2.01662943760554

Epoch: 6| Step: 11
Training loss: 1.898505449295044
Validation loss: 2.0174801349639893

Epoch: 6| Step: 12
Training loss: 2.038048267364502
Validation loss: 2.0114609003067017

Epoch: 6| Step: 13
Training loss: 2.0722577571868896
Validation loss: 2.015516221523285

Epoch: 93| Step: 0
Training loss: 2.4884822368621826
Validation loss: 2.0026467045148215

Epoch: 6| Step: 1
Training loss: 2.7482781410217285
Validation loss: 2.0137270291646323

Epoch: 6| Step: 2
Training loss: 2.007633924484253
Validation loss: 2.015134314695994

Epoch: 6| Step: 3
Training loss: 2.0739212036132812
Validation loss: 2.0171008904774985

Epoch: 6| Step: 4
Training loss: 1.4513635635375977
Validation loss: 2.015262484550476

Epoch: 6| Step: 5
Training loss: 1.859216570854187
Validation loss: 2.0224892497062683

Epoch: 6| Step: 6
Training loss: 2.080110549926758
Validation loss: 2.0187729597091675

Epoch: 6| Step: 7
Training loss: 2.547197103500366
Validation loss: 2.02360866467158

Epoch: 6| Step: 8
Training loss: 1.7223970890045166
Validation loss: 2.0241223772366843

Epoch: 6| Step: 9
Training loss: 2.2426068782806396
Validation loss: 2.018050273259481

Epoch: 6| Step: 10
Training loss: 2.0585455894470215
Validation loss: 2.0102712313334146

Epoch: 6| Step: 11
Training loss: 2.107428789138794
Validation loss: 2.0085360209147134

Epoch: 6| Step: 12
Training loss: 2.152082681655884
Validation loss: 2.0135177969932556

Epoch: 6| Step: 13
Training loss: 2.0995445251464844
Validation loss: 2.008264482021332

Epoch: 94| Step: 0
Training loss: 2.328042984008789
Validation loss: 2.0133665204048157

Epoch: 6| Step: 1
Training loss: 2.0108578205108643
Validation loss: 2.0088709791501365

Epoch: 6| Step: 2
Training loss: 2.2996208667755127
Validation loss: 2.01361475388209

Epoch: 6| Step: 3
Training loss: 1.7349711656570435
Validation loss: 2.0120200514793396

Epoch: 6| Step: 4
Training loss: 2.148709774017334
Validation loss: 2.0097710887591043

Epoch: 6| Step: 5
Training loss: 2.59621524810791
Validation loss: 2.0112337271372476

Epoch: 6| Step: 6
Training loss: 2.4569172859191895
Validation loss: 2.0098517537117004

Epoch: 6| Step: 7
Training loss: 1.7524032592773438
Validation loss: 2.0128145019213357

Epoch: 6| Step: 8
Training loss: 2.2470815181732178
Validation loss: 2.012218475341797

Epoch: 6| Step: 9
Training loss: 2.039898157119751
Validation loss: 2.006935775279999

Epoch: 6| Step: 10
Training loss: 2.0184547901153564
Validation loss: 2.009190102418264

Epoch: 6| Step: 11
Training loss: 1.674994707107544
Validation loss: 2.0122671723365784

Epoch: 6| Step: 12
Training loss: 2.940770149230957
Validation loss: 2.007956882317861

Epoch: 6| Step: 13
Training loss: 1.5066583156585693
Validation loss: 2.0188942352930703

Epoch: 95| Step: 0
Training loss: 2.426398277282715
Validation loss: 2.017149806022644

Epoch: 6| Step: 1
Training loss: 1.755214810371399
Validation loss: 2.0173457264900208

Epoch: 6| Step: 2
Training loss: 1.935340166091919
Validation loss: 2.016198297341665

Epoch: 6| Step: 3
Training loss: 1.9600942134857178
Validation loss: 2.0235973795255027

Epoch: 6| Step: 4
Training loss: 2.0216293334960938
Validation loss: 2.016844650109609

Epoch: 6| Step: 5
Training loss: 2.5939793586730957
Validation loss: 2.028019150098165

Epoch: 6| Step: 6
Training loss: 2.160092830657959
Validation loss: 2.0207961996396384

Epoch: 6| Step: 7
Training loss: 2.4662203788757324
Validation loss: 2.018617828687032

Epoch: 6| Step: 8
Training loss: 1.66056489944458
Validation loss: 2.0270119309425354

Epoch: 6| Step: 9
Training loss: 2.310687303543091
Validation loss: 2.0222343603769937

Epoch: 6| Step: 10
Training loss: 2.408658504486084
Validation loss: 2.018733282883962

Epoch: 6| Step: 11
Training loss: 1.8070454597473145
Validation loss: 2.011423190434774

Epoch: 6| Step: 12
Training loss: 2.3836758136749268
Validation loss: 2.0214664340019226

Epoch: 6| Step: 13
Training loss: 1.975447177886963
Validation loss: 2.0213170647621155

Epoch: 96| Step: 0
Training loss: 1.9111402034759521
Validation loss: 2.021316428979238

Epoch: 6| Step: 1
Training loss: 1.7503085136413574
Validation loss: 2.0192688703536987

Epoch: 6| Step: 2
Training loss: 1.7683346271514893
Validation loss: 2.041338086128235

Epoch: 6| Step: 3
Training loss: 1.7963789701461792
Validation loss: 2.0392409563064575

Epoch: 6| Step: 4
Training loss: 2.484943389892578
Validation loss: 2.035528858502706

Epoch: 6| Step: 5
Training loss: 2.6172585487365723
Validation loss: 2.0395145217577615

Epoch: 6| Step: 6
Training loss: 2.236250400543213
Validation loss: 2.045598804950714

Epoch: 6| Step: 7
Training loss: 1.9071255922317505
Validation loss: 2.0454816023508706

Epoch: 6| Step: 8
Training loss: 2.150650978088379
Validation loss: 2.0473469495773315

Epoch: 6| Step: 9
Training loss: 2.739506483078003
Validation loss: 2.0431668758392334

Epoch: 6| Step: 10
Training loss: 2.3383190631866455
Validation loss: 2.027990182240804

Epoch: 6| Step: 11
Training loss: 1.7519397735595703
Validation loss: 2.0208149353663125

Epoch: 6| Step: 12
Training loss: 2.4885523319244385
Validation loss: 2.012485980987549

Epoch: 6| Step: 13
Training loss: 1.846793293952942
Validation loss: 2.0147526065508523

Epoch: 97| Step: 0
Training loss: 2.1294960975646973
Validation loss: 2.0108786821365356

Epoch: 6| Step: 1
Training loss: 1.9154208898544312
Validation loss: 2.0132036805152893

Epoch: 6| Step: 2
Training loss: 2.5921545028686523
Validation loss: 2.0040219823519387

Epoch: 6| Step: 3
Training loss: 1.8864840269088745
Validation loss: 2.005141089359919

Epoch: 6| Step: 4
Training loss: 1.7690460681915283
Validation loss: 2.003701686859131

Epoch: 6| Step: 5
Training loss: 2.8015801906585693
Validation loss: 2.0084503094355264

Epoch: 6| Step: 6
Training loss: 2.369088888168335
Validation loss: 2.006083091100057

Epoch: 6| Step: 7
Training loss: 1.6870300769805908
Validation loss: 2.0054019490877786

Epoch: 6| Step: 8
Training loss: 2.4775333404541016
Validation loss: 2.0042749842007956

Epoch: 6| Step: 9
Training loss: 2.129770278930664
Validation loss: 2.003967841466268

Epoch: 6| Step: 10
Training loss: 1.4757726192474365
Validation loss: 2.0062506397565207

Epoch: 6| Step: 11
Training loss: 2.132709264755249
Validation loss: 2.0114776889483132

Epoch: 6| Step: 12
Training loss: 2.4527573585510254
Validation loss: 2.00297749042511

Epoch: 6| Step: 13
Training loss: 1.75783371925354
Validation loss: 2.0136334697405496

Epoch: 98| Step: 0
Training loss: 2.8862504959106445
Validation loss: 2.0212674538294473

Epoch: 6| Step: 1
Training loss: 3.0245041847229004
Validation loss: 2.0124611457188926

Epoch: 6| Step: 2
Training loss: 1.6503138542175293
Validation loss: 2.0134975910186768

Epoch: 6| Step: 3
Training loss: 1.4854037761688232
Validation loss: 2.0153661171595254

Epoch: 6| Step: 4
Training loss: 2.2219364643096924
Validation loss: 2.0180607438087463

Epoch: 6| Step: 5
Training loss: 1.8822519779205322
Validation loss: 2.0139761765797934

Epoch: 6| Step: 6
Training loss: 1.736299991607666
Validation loss: 2.024379789829254

Epoch: 6| Step: 7
Training loss: 2.0379233360290527
Validation loss: 2.032196263472239

Epoch: 6| Step: 8
Training loss: 2.079230308532715
Validation loss: 2.0295135577519736

Epoch: 6| Step: 9
Training loss: 2.4213409423828125
Validation loss: 2.0318039854367576

Epoch: 6| Step: 10
Training loss: 1.9854179620742798
Validation loss: 2.030508875846863

Epoch: 6| Step: 11
Training loss: 2.269134044647217
Validation loss: 2.033657948176066

Epoch: 6| Step: 12
Training loss: 1.572122573852539
Validation loss: 2.025509794553121

Epoch: 6| Step: 13
Training loss: 2.201150894165039
Validation loss: 2.0201157927513123

Epoch: 99| Step: 0
Training loss: 1.8988195657730103
Validation loss: 2.018187324206034

Epoch: 6| Step: 1
Training loss: 1.8417472839355469
Validation loss: 2.011014719804128

Epoch: 6| Step: 2
Training loss: 1.8669229745864868
Validation loss: 2.0095993280410767

Epoch: 6| Step: 3
Training loss: 1.4551160335540771
Validation loss: 2.005540986855825

Epoch: 6| Step: 4
Training loss: 2.2609848976135254
Validation loss: 2.006131569544474

Epoch: 6| Step: 5
Training loss: 2.0972938537597656
Validation loss: 2.007350265979767

Epoch: 6| Step: 6
Training loss: 1.6336901187896729
Validation loss: 2.008249501387278

Epoch: 6| Step: 7
Training loss: 2.463515520095825
Validation loss: 2.0041128993034363

Epoch: 6| Step: 8
Training loss: 2.5660781860351562
Validation loss: 2.014118194580078

Epoch: 6| Step: 9
Training loss: 2.7158005237579346
Validation loss: 2.018731693426768

Epoch: 6| Step: 10
Training loss: 2.162153720855713
Validation loss: 2.021917700767517

Epoch: 6| Step: 11
Training loss: 2.0563271045684814
Validation loss: 2.0184266368548074

Epoch: 6| Step: 12
Training loss: 2.575684070587158
Validation loss: 2.017183860143026

Epoch: 6| Step: 13
Training loss: 1.9037257432937622
Validation loss: 2.0202421148618064

Epoch: 100| Step: 0
Training loss: 1.831047534942627
Validation loss: 2.01188192764918

Epoch: 6| Step: 1
Training loss: 1.8555335998535156
Validation loss: 2.009472688039144

Epoch: 6| Step: 2
Training loss: 2.0864739418029785
Validation loss: 2.00802743434906

Epoch: 6| Step: 3
Training loss: 2.167710781097412
Validation loss: 2.005275328954061

Epoch: 6| Step: 4
Training loss: 1.7965030670166016
Validation loss: 1.999741792678833

Epoch: 6| Step: 5
Training loss: 2.565713405609131
Validation loss: 2.0120877027511597

Epoch: 6| Step: 6
Training loss: 2.197422981262207
Validation loss: 2.020622452100118

Epoch: 6| Step: 7
Training loss: 2.3019323348999023
Validation loss: 2.011842966079712

Epoch: 6| Step: 8
Training loss: 2.2010388374328613
Validation loss: 2.0218649903933206

Epoch: 6| Step: 9
Training loss: 1.6662571430206299
Validation loss: 2.0206370751063027

Epoch: 6| Step: 10
Training loss: 2.2569656372070312
Validation loss: 2.0159831444422402

Epoch: 6| Step: 11
Training loss: 2.095222234725952
Validation loss: 2.011885861555735

Epoch: 6| Step: 12
Training loss: 2.2924108505249023
Validation loss: 2.0038437843322754

Epoch: 6| Step: 13
Training loss: 2.170191526412964
Validation loss: 2.0029896100362143

Epoch: 101| Step: 0
Training loss: 1.837576150894165
Validation loss: 2.0034340620040894

Epoch: 6| Step: 1
Training loss: 1.7721788883209229
Validation loss: 2.006829818089803

Epoch: 6| Step: 2
Training loss: 2.416672945022583
Validation loss: 2.005035618940989

Epoch: 6| Step: 3
Training loss: 2.1667754650115967
Validation loss: 2.005338490009308

Epoch: 6| Step: 4
Training loss: 2.1962900161743164
Validation loss: 2.0075019001960754

Epoch: 6| Step: 5
Training loss: 2.604236125946045
Validation loss: 2.013287882010142

Epoch: 6| Step: 6
Training loss: 1.80855131149292
Validation loss: 2.01984566450119

Epoch: 6| Step: 7
Training loss: 2.3389344215393066
Validation loss: 2.0216187040011087

Epoch: 6| Step: 8
Training loss: 2.0293264389038086
Validation loss: 2.0273826320966086

Epoch: 6| Step: 9
Training loss: 1.6262977123260498
Validation loss: 2.0321232676506042

Epoch: 6| Step: 10
Training loss: 2.5826454162597656
Validation loss: 2.045072694619497

Epoch: 6| Step: 11
Training loss: 2.243356227874756
Validation loss: 2.0489203333854675

Epoch: 6| Step: 12
Training loss: 2.5767760276794434
Validation loss: 2.0496957699457803

Epoch: 6| Step: 13
Training loss: 1.5573781728744507
Validation loss: 2.042491396268209

Epoch: 102| Step: 0
Training loss: 1.8994745016098022
Validation loss: 2.0363143483797708

Epoch: 6| Step: 1
Training loss: 2.4398183822631836
Validation loss: 2.0210434198379517

Epoch: 6| Step: 2
Training loss: 2.7991528511047363
Validation loss: 2.0268930395444236

Epoch: 6| Step: 3
Training loss: 1.432328462600708
Validation loss: 2.0161555409431458

Epoch: 6| Step: 4
Training loss: 2.239863872528076
Validation loss: 2.0121209621429443

Epoch: 6| Step: 5
Training loss: 2.072824001312256
Validation loss: 2.0125871102015176

Epoch: 6| Step: 6
Training loss: 2.264805793762207
Validation loss: 2.019452611605326

Epoch: 6| Step: 7
Training loss: 1.981213092803955
Validation loss: 2.0172279675801597

Epoch: 6| Step: 8
Training loss: 1.8617219924926758
Validation loss: 2.0213909347852073

Epoch: 6| Step: 9
Training loss: 1.7250285148620605
Validation loss: 2.018357276916504

Epoch: 6| Step: 10
Training loss: 2.302103042602539
Validation loss: 2.0185699661572776

Epoch: 6| Step: 11
Training loss: 2.4712462425231934
Validation loss: 2.0162070194880166

Epoch: 6| Step: 12
Training loss: 2.324023723602295
Validation loss: 2.0338415106137595

Epoch: 6| Step: 13
Training loss: 1.6215169429779053
Validation loss: 2.0294085343678794

Epoch: 103| Step: 0
Training loss: 2.01409912109375
Validation loss: 2.0117424726486206

Epoch: 6| Step: 1
Training loss: 2.0512845516204834
Validation loss: 2.013618449370066

Epoch: 6| Step: 2
Training loss: 2.317361354827881
Validation loss: 2.0215969483057656

Epoch: 6| Step: 3
Training loss: 2.5344417095184326
Validation loss: 2.0246694882710776

Epoch: 6| Step: 4
Training loss: 2.6042137145996094
Validation loss: 2.027589519818624

Epoch: 6| Step: 5
Training loss: 1.9871490001678467
Validation loss: 2.031795879205068

Epoch: 6| Step: 6
Training loss: 2.210073947906494
Validation loss: 2.0350533922513327

Epoch: 6| Step: 7
Training loss: 2.0624799728393555
Validation loss: 2.0441498160362244

Epoch: 6| Step: 8
Training loss: 1.6332778930664062
Validation loss: 2.0379764238993325

Epoch: 6| Step: 9
Training loss: 2.0755178928375244
Validation loss: 2.038084248701731

Epoch: 6| Step: 10
Training loss: 2.247537136077881
Validation loss: 2.042565484841665

Epoch: 6| Step: 11
Training loss: 1.7699108123779297
Validation loss: 2.04082719484965

Epoch: 6| Step: 12
Training loss: 2.078401803970337
Validation loss: 2.0355656941731772

Epoch: 6| Step: 13
Training loss: 2.0217394828796387
Validation loss: 2.040369927883148

Epoch: 104| Step: 0
Training loss: 1.8711541891098022
Validation loss: 2.028266668319702

Epoch: 6| Step: 1
Training loss: 1.9127196073532104
Validation loss: 2.027341683705648

Epoch: 6| Step: 2
Training loss: 2.374281883239746
Validation loss: 2.026640554269155

Epoch: 6| Step: 3
Training loss: 1.986598253250122
Validation loss: 2.0321417252222695

Epoch: 6| Step: 4
Training loss: 1.438138484954834
Validation loss: 2.0221148331960044

Epoch: 6| Step: 5
Training loss: 2.1787619590759277
Validation loss: 2.0237013498942056

Epoch: 6| Step: 6
Training loss: 2.026369571685791
Validation loss: 2.0294665495554605

Epoch: 6| Step: 7
Training loss: 2.554579734802246
Validation loss: 2.0390143394470215

Epoch: 6| Step: 8
Training loss: 2.30492901802063
Validation loss: 2.035672585169474

Epoch: 6| Step: 9
Training loss: 2.2585573196411133
Validation loss: 2.046516001224518

Epoch: 6| Step: 10
Training loss: 2.434110641479492
Validation loss: 2.0418176651000977

Epoch: 6| Step: 11
Training loss: 1.7150242328643799
Validation loss: 2.046439230442047

Epoch: 6| Step: 12
Training loss: 2.3037185668945312
Validation loss: 2.039254307746887

Epoch: 6| Step: 13
Training loss: 2.552286148071289
Validation loss: 2.0339615742365518

Epoch: 105| Step: 0
Training loss: 2.564896583557129
Validation loss: 2.0319756269454956

Epoch: 6| Step: 1
Training loss: 1.7191935777664185
Validation loss: 2.0194727182388306

Epoch: 6| Step: 2
Training loss: 2.040653944015503
Validation loss: 2.021226723988851

Epoch: 6| Step: 3
Training loss: 2.182267904281616
Validation loss: 2.017248253027598

Epoch: 6| Step: 4
Training loss: 1.8640533685684204
Validation loss: 2.0190311868985495

Epoch: 6| Step: 5
Training loss: 2.193726062774658
Validation loss: 2.0161367654800415

Epoch: 6| Step: 6
Training loss: 1.983093023300171
Validation loss: 2.020684798558553

Epoch: 6| Step: 7
Training loss: 2.1523261070251465
Validation loss: 2.0166063706080117

Epoch: 6| Step: 8
Training loss: 2.1419665813446045
Validation loss: 2.015961746374766

Epoch: 6| Step: 9
Training loss: 2.0077157020568848
Validation loss: 2.0130561192830405

Epoch: 6| Step: 10
Training loss: 2.1025655269622803
Validation loss: 2.034273862838745

Epoch: 6| Step: 11
Training loss: 1.6914446353912354
Validation loss: 2.029674510161082

Epoch: 6| Step: 12
Training loss: 2.303999423980713
Validation loss: 2.0372915267944336

Epoch: 6| Step: 13
Training loss: 2.5646724700927734
Validation loss: 2.033614993095398

Epoch: 106| Step: 0
Training loss: 2.02079439163208
Validation loss: 2.0361568927764893

Epoch: 6| Step: 1
Training loss: 1.9585057497024536
Validation loss: 2.0381078521410623

Epoch: 6| Step: 2
Training loss: 2.4744553565979004
Validation loss: 2.0247170527776084

Epoch: 6| Step: 3
Training loss: 2.51153564453125
Validation loss: 2.0273910760879517

Epoch: 6| Step: 4
Training loss: 2.105177402496338
Validation loss: 2.017647842566172

Epoch: 6| Step: 5
Training loss: 1.7601126432418823
Validation loss: 2.01040518283844

Epoch: 6| Step: 6
Training loss: 1.7008479833602905
Validation loss: 2.0135217706362405

Epoch: 6| Step: 7
Training loss: 1.45751953125
Validation loss: 2.0149779121081033

Epoch: 6| Step: 8
Training loss: 2.7242467403411865
Validation loss: 2.0179660320281982

Epoch: 6| Step: 9
Training loss: 2.670753002166748
Validation loss: 2.017523209253947

Epoch: 6| Step: 10
Training loss: 2.455826997756958
Validation loss: 2.0182619293530784

Epoch: 6| Step: 11
Training loss: 2.3340859413146973
Validation loss: 2.0175938804944358

Epoch: 6| Step: 12
Training loss: 1.7479846477508545
Validation loss: 2.0170680483182273

Epoch: 6| Step: 13
Training loss: 1.9828826189041138
Validation loss: 2.0151151418685913

Epoch: 107| Step: 0
Training loss: 2.0764355659484863
Validation loss: 2.0116353631019592

Epoch: 6| Step: 1
Training loss: 1.8057684898376465
Validation loss: 2.0145238240559897

Epoch: 6| Step: 2
Training loss: 2.7120184898376465
Validation loss: 2.0145296851793923

Epoch: 6| Step: 3
Training loss: 1.3477635383605957
Validation loss: 2.0084524154663086

Epoch: 6| Step: 4
Training loss: 2.3276453018188477
Validation loss: 2.0109474658966064

Epoch: 6| Step: 5
Training loss: 2.45719313621521
Validation loss: 2.0157213608423867

Epoch: 6| Step: 6
Training loss: 1.7489192485809326
Validation loss: 2.016618092854818

Epoch: 6| Step: 7
Training loss: 1.9797935485839844
Validation loss: 2.0187289913495383

Epoch: 6| Step: 8
Training loss: 2.086843967437744
Validation loss: 2.016450504461924

Epoch: 6| Step: 9
Training loss: 2.092855215072632
Validation loss: 2.0252676010131836

Epoch: 6| Step: 10
Training loss: 2.5699691772460938
Validation loss: 2.014603098233541

Epoch: 6| Step: 11
Training loss: 2.1740617752075195
Validation loss: 2.0255773862202964

Epoch: 6| Step: 12
Training loss: 2.3797383308410645
Validation loss: 2.0314382910728455

Epoch: 6| Step: 13
Training loss: 1.7969286441802979
Validation loss: 2.020084341367086

Epoch: 108| Step: 0
Training loss: 2.0461580753326416
Validation loss: 2.0239214499791465

Epoch: 6| Step: 1
Training loss: 1.8042138814926147
Validation loss: 2.020532548427582

Epoch: 6| Step: 2
Training loss: 1.7248377799987793
Validation loss: 2.022931754589081

Epoch: 6| Step: 3
Training loss: 2.7295684814453125
Validation loss: 2.0238454341888428

Epoch: 6| Step: 4
Training loss: 2.1574466228485107
Validation loss: 2.0322934786478677

Epoch: 6| Step: 5
Training loss: 2.0452609062194824
Validation loss: 2.037233273188273

Epoch: 6| Step: 6
Training loss: 2.7418999671936035
Validation loss: 2.0287324587504068

Epoch: 6| Step: 7
Training loss: 2.131890296936035
Validation loss: 2.0204416513442993

Epoch: 6| Step: 8
Training loss: 2.183098316192627
Validation loss: 2.019523819287618

Epoch: 6| Step: 9
Training loss: 1.994863748550415
Validation loss: 2.00527161359787

Epoch: 6| Step: 10
Training loss: 2.12115216255188
Validation loss: 2.0044822096824646

Epoch: 6| Step: 11
Training loss: 1.7344297170639038
Validation loss: 2.0069871147473655

Epoch: 6| Step: 12
Training loss: 1.6226519346237183
Validation loss: 2.008409102757772

Epoch: 6| Step: 13
Training loss: 2.23012113571167
Validation loss: 2.0019100109736123

Epoch: 109| Step: 0
Training loss: 2.470858097076416
Validation loss: 1.9969644943873088

Epoch: 6| Step: 1
Training loss: 1.8544747829437256
Validation loss: 1.9987762570381165

Epoch: 6| Step: 2
Training loss: 2.4693238735198975
Validation loss: 2.001106341679891

Epoch: 6| Step: 3
Training loss: 2.206676483154297
Validation loss: 2.00552499294281

Epoch: 6| Step: 4
Training loss: 1.9023561477661133
Validation loss: 1.9995327790578206

Epoch: 6| Step: 5
Training loss: 2.737165927886963
Validation loss: 1.9987726012865703

Epoch: 6| Step: 6
Training loss: 1.585654616355896
Validation loss: 1.9962460199991863

Epoch: 6| Step: 7
Training loss: 2.352034330368042
Validation loss: 1.9857532382011414

Epoch: 6| Step: 8
Training loss: 2.000964879989624
Validation loss: 1.999112327893575

Epoch: 6| Step: 9
Training loss: 1.6315617561340332
Validation loss: 1.9918099641799927

Epoch: 6| Step: 10
Training loss: 2.341388702392578
Validation loss: 1.9912920594215393

Epoch: 6| Step: 11
Training loss: 1.7994709014892578
Validation loss: 1.9997440179189045

Epoch: 6| Step: 12
Training loss: 1.6855322122573853
Validation loss: 2.002870957056681

Epoch: 6| Step: 13
Training loss: 2.4762470722198486
Validation loss: 2.000730276107788

Epoch: 110| Step: 0
Training loss: 1.4940946102142334
Validation loss: 2.0082819064458213

Epoch: 6| Step: 1
Training loss: 2.024916648864746
Validation loss: 2.0144476294517517

Epoch: 6| Step: 2
Training loss: 1.7716313600540161
Validation loss: 2.003710369269053

Epoch: 6| Step: 3
Training loss: 2.207132339477539
Validation loss: 2.0112476348876953

Epoch: 6| Step: 4
Training loss: 1.7475800514221191
Validation loss: 2.0191267132759094

Epoch: 6| Step: 5
Training loss: 1.9566278457641602
Validation loss: 2.019876182079315

Epoch: 6| Step: 6
Training loss: 1.748145341873169
Validation loss: 2.014904181162516

Epoch: 6| Step: 7
Training loss: 2.0669729709625244
Validation loss: 2.0281973679860434

Epoch: 6| Step: 8
Training loss: 1.699742317199707
Validation loss: 2.0338202118873596

Epoch: 6| Step: 9
Training loss: 2.6493265628814697
Validation loss: 2.0229732990264893

Epoch: 6| Step: 10
Training loss: 2.208096742630005
Validation loss: 2.0358358224232993

Epoch: 6| Step: 11
Training loss: 2.0252685546875
Validation loss: 2.0283012787501016

Epoch: 6| Step: 12
Training loss: 2.8051300048828125
Validation loss: 2.0380219221115112

Epoch: 6| Step: 13
Training loss: 2.836214780807495
Validation loss: 2.0207961599032083

Epoch: 111| Step: 0
Training loss: 1.343094825744629
Validation loss: 2.0202388366063437

Epoch: 6| Step: 1
Training loss: 3.290722608566284
Validation loss: 2.0198862155278525

Epoch: 6| Step: 2
Training loss: 1.784524917602539
Validation loss: 2.0179779529571533

Epoch: 6| Step: 3
Training loss: 2.1886496543884277
Validation loss: 2.0193251768747964

Epoch: 6| Step: 4
Training loss: 1.731866717338562
Validation loss: 2.0218544006347656

Epoch: 6| Step: 5
Training loss: 2.181356430053711
Validation loss: 2.0131447315216064

Epoch: 6| Step: 6
Training loss: 1.9364721775054932
Validation loss: 2.018975635369619

Epoch: 6| Step: 7
Training loss: 2.2373909950256348
Validation loss: 2.016739865144094

Epoch: 6| Step: 8
Training loss: 2.549384117126465
Validation loss: 2.0228448510169983

Epoch: 6| Step: 9
Training loss: 2.2333364486694336
Validation loss: 2.021013100941976

Epoch: 6| Step: 10
Training loss: 2.185253143310547
Validation loss: 2.022238234678904

Epoch: 6| Step: 11
Training loss: 1.7207369804382324
Validation loss: 2.021744350592295

Epoch: 6| Step: 12
Training loss: 2.300126552581787
Validation loss: 2.022760570049286

Epoch: 6| Step: 13
Training loss: 1.7626594305038452
Validation loss: 2.024929463863373

Epoch: 112| Step: 0
Training loss: 1.9514504671096802
Validation loss: 2.0246689518292746

Epoch: 6| Step: 1
Training loss: 2.6124427318573
Validation loss: 2.028317153453827

Epoch: 6| Step: 2
Training loss: 2.096203327178955
Validation loss: 2.042073210080465

Epoch: 6| Step: 3
Training loss: 1.2724177837371826
Validation loss: 2.026610493659973

Epoch: 6| Step: 4
Training loss: 2.8774335384368896
Validation loss: 2.0318075815836587

Epoch: 6| Step: 5
Training loss: 2.1523597240448
Validation loss: 2.0182411869366965

Epoch: 6| Step: 6
Training loss: 1.692173957824707
Validation loss: 2.0171204209327698

Epoch: 6| Step: 7
Training loss: 1.8286726474761963
Validation loss: 2.019000848134359

Epoch: 6| Step: 8
Training loss: 2.0247602462768555
Validation loss: 2.0159082412719727

Epoch: 6| Step: 9
Training loss: 1.913051962852478
Validation loss: 2.0122365951538086

Epoch: 6| Step: 10
Training loss: 2.25811505317688
Validation loss: 2.0178827246030173

Epoch: 6| Step: 11
Training loss: 1.877085566520691
Validation loss: 2.0091646909713745

Epoch: 6| Step: 12
Training loss: 2.446549654006958
Validation loss: 2.0106090108553567

Epoch: 6| Step: 13
Training loss: 2.4257168769836426
Validation loss: 2.0095594922701516

Epoch: 113| Step: 0
Training loss: 2.220141887664795
Validation loss: 2.0158684849739075

Epoch: 6| Step: 1
Training loss: 2.015115737915039
Validation loss: 2.0058918793996177

Epoch: 6| Step: 2
Training loss: 1.9699655771255493
Validation loss: 2.002565085887909

Epoch: 6| Step: 3
Training loss: 2.1718716621398926
Validation loss: 2.0021395087242126

Epoch: 6| Step: 4
Training loss: 1.6344302892684937
Validation loss: 1.9986127614974976

Epoch: 6| Step: 5
Training loss: 1.9672338962554932
Validation loss: 1.9959418177604675

Epoch: 6| Step: 6
Training loss: 2.0380876064300537
Validation loss: 1.9952998757362366

Epoch: 6| Step: 7
Training loss: 2.061067819595337
Validation loss: 2.0055371125539145

Epoch: 6| Step: 8
Training loss: 1.8270928859710693
Validation loss: 2.008417288462321

Epoch: 6| Step: 9
Training loss: 1.674127459526062
Validation loss: 2.0183172623316445

Epoch: 6| Step: 10
Training loss: 1.8996479511260986
Validation loss: 2.021455009778341

Epoch: 6| Step: 11
Training loss: 2.5412979125976562
Validation loss: 2.0197721123695374

Epoch: 6| Step: 12
Training loss: 2.7201547622680664
Validation loss: 2.0244810581207275

Epoch: 6| Step: 13
Training loss: 2.819500207901001
Validation loss: 2.0254499117533364

Epoch: 114| Step: 0
Training loss: 2.4774222373962402
Validation loss: 2.0025370717048645

Epoch: 6| Step: 1
Training loss: 2.1109089851379395
Validation loss: 2.0134601394335427

Epoch: 6| Step: 2
Training loss: 2.3323965072631836
Validation loss: 2.0031529863675437

Epoch: 6| Step: 3
Training loss: 1.9655290842056274
Validation loss: 2.0070072015126548

Epoch: 6| Step: 4
Training loss: 2.0342812538146973
Validation loss: 2.007547934850057

Epoch: 6| Step: 5
Training loss: 2.3143837451934814
Validation loss: 2.006996512413025

Epoch: 6| Step: 6
Training loss: 1.7834012508392334
Validation loss: 2.003291646639506

Epoch: 6| Step: 7
Training loss: 2.8151516914367676
Validation loss: 2.013643483320872

Epoch: 6| Step: 8
Training loss: 1.893092155456543
Validation loss: 2.016683578491211

Epoch: 6| Step: 9
Training loss: 2.1487815380096436
Validation loss: 2.014098604520162

Epoch: 6| Step: 10
Training loss: 1.8749973773956299
Validation loss: 2.0116967956225076

Epoch: 6| Step: 11
Training loss: 2.511035919189453
Validation loss: 2.0185197393099465

Epoch: 6| Step: 12
Training loss: 1.4478631019592285
Validation loss: 2.0142423510551453

Epoch: 6| Step: 13
Training loss: 1.5643556118011475
Validation loss: 2.0185558994611106

Epoch: 115| Step: 0
Training loss: 2.476287364959717
Validation loss: 2.009204387664795

Epoch: 6| Step: 1
Training loss: 2.2151758670806885
Validation loss: 2.010013004144033

Epoch: 6| Step: 2
Training loss: 2.155245304107666
Validation loss: 2.014413813749949

Epoch: 6| Step: 3
Training loss: 1.5572905540466309
Validation loss: 2.0208277106285095

Epoch: 6| Step: 4
Training loss: 2.4466638565063477
Validation loss: 2.023536483446757

Epoch: 6| Step: 5
Training loss: 2.2758870124816895
Validation loss: 2.0179286003112793

Epoch: 6| Step: 6
Training loss: 1.8538756370544434
Validation loss: 2.022326111793518

Epoch: 6| Step: 7
Training loss: 1.7890512943267822
Validation loss: 2.0288655757904053

Epoch: 6| Step: 8
Training loss: 2.2653558254241943
Validation loss: 2.0277194380760193

Epoch: 6| Step: 9
Training loss: 2.207791328430176
Validation loss: 2.0303319295247397

Epoch: 6| Step: 10
Training loss: 2.0613932609558105
Validation loss: 2.0016297698020935

Epoch: 6| Step: 11
Training loss: 1.983794927597046
Validation loss: 2.020946820576986

Epoch: 6| Step: 12
Training loss: 2.2944459915161133
Validation loss: 2.019309083620707

Epoch: 6| Step: 13
Training loss: 1.6764590740203857
Validation loss: 2.0203382770220437

Epoch: 116| Step: 0
Training loss: 1.9472113847732544
Validation loss: 2.0258677204449973

Epoch: 6| Step: 1
Training loss: 2.0489017963409424
Validation loss: 2.023038407166799

Epoch: 6| Step: 2
Training loss: 2.484266996383667
Validation loss: 2.0333502093950906

Epoch: 6| Step: 3
Training loss: 2.027622699737549
Validation loss: 2.034639040629069

Epoch: 6| Step: 4
Training loss: 2.415005683898926
Validation loss: 2.0271704395612082

Epoch: 6| Step: 5
Training loss: 1.5864953994750977
Validation loss: 2.0319551626841226

Epoch: 6| Step: 6
Training loss: 2.2256946563720703
Validation loss: 2.031670312086741

Epoch: 6| Step: 7
Training loss: 2.2449214458465576
Validation loss: 2.0368412335713706

Epoch: 6| Step: 8
Training loss: 2.0250072479248047
Validation loss: 2.0269900957743325

Epoch: 6| Step: 9
Training loss: 1.8607736825942993
Validation loss: 2.0344626704851785

Epoch: 6| Step: 10
Training loss: 2.208376169204712
Validation loss: 2.0347520311673484

Epoch: 6| Step: 11
Training loss: 2.0330018997192383
Validation loss: 2.02090056737264

Epoch: 6| Step: 12
Training loss: 2.192877769470215
Validation loss: 2.0307841897010803

Epoch: 6| Step: 13
Training loss: 1.740456461906433
Validation loss: 2.020221491654714

Epoch: 117| Step: 0
Training loss: 2.4139585494995117
Validation loss: 2.0237892468770347

Epoch: 6| Step: 1
Training loss: 2.304988384246826
Validation loss: 2.0168554186820984

Epoch: 6| Step: 2
Training loss: 2.009550094604492
Validation loss: 2.0287184516588845

Epoch: 6| Step: 3
Training loss: 1.7654509544372559
Validation loss: 2.0152608354886374

Epoch: 6| Step: 4
Training loss: 2.5468287467956543
Validation loss: 2.006954789161682

Epoch: 6| Step: 5
Training loss: 2.3456780910491943
Validation loss: 2.014351487159729

Epoch: 6| Step: 6
Training loss: 1.5337049961090088
Validation loss: 2.0218613346417746

Epoch: 6| Step: 7
Training loss: 2.5005273818969727
Validation loss: 2.01518177986145

Epoch: 6| Step: 8
Training loss: 2.1612250804901123
Validation loss: 2.017461101214091

Epoch: 6| Step: 9
Training loss: 2.03061580657959
Validation loss: 2.0202993949254355

Epoch: 6| Step: 10
Training loss: 1.6291706562042236
Validation loss: 2.0176499088605246

Epoch: 6| Step: 11
Training loss: 1.846367359161377
Validation loss: 2.0132627487182617

Epoch: 6| Step: 12
Training loss: 2.0891032218933105
Validation loss: 2.0254981915156045

Epoch: 6| Step: 13
Training loss: 1.8455995321273804
Validation loss: 2.0148486892382302

Epoch: 118| Step: 0
Training loss: 1.551827073097229
Validation loss: 2.0172847509384155

Epoch: 6| Step: 1
Training loss: 2.4612367153167725
Validation loss: 2.02375719944636

Epoch: 6| Step: 2
Training loss: 1.5316188335418701
Validation loss: 2.0257139603296914

Epoch: 6| Step: 3
Training loss: 2.173245429992676
Validation loss: 2.0327405532201133

Epoch: 6| Step: 4
Training loss: 2.418323278427124
Validation loss: 2.0272184213002524

Epoch: 6| Step: 5
Training loss: 2.338289976119995
Validation loss: 2.0242257118225098

Epoch: 6| Step: 6
Training loss: 1.8386447429656982
Validation loss: 2.0157217979431152

Epoch: 6| Step: 7
Training loss: 1.8140394687652588
Validation loss: 2.0204792420069375

Epoch: 6| Step: 8
Training loss: 1.8976354598999023
Validation loss: 2.0139161745707193

Epoch: 6| Step: 9
Training loss: 1.7160701751708984
Validation loss: 2.016306757926941

Epoch: 6| Step: 10
Training loss: 2.659238576889038
Validation loss: 2.014054318269094

Epoch: 6| Step: 11
Training loss: 1.7698588371276855
Validation loss: 2.0134591261545816

Epoch: 6| Step: 12
Training loss: 3.0221495628356934
Validation loss: 2.017661909262339

Epoch: 6| Step: 13
Training loss: 1.9820101261138916
Validation loss: 2.0131150682767234

Epoch: 119| Step: 0
Training loss: 1.4483544826507568
Validation loss: 2.0149014393488565

Epoch: 6| Step: 1
Training loss: 1.916474461555481
Validation loss: 2.0188161333402

Epoch: 6| Step: 2
Training loss: 1.9599709510803223
Validation loss: 2.025731901327769

Epoch: 6| Step: 3
Training loss: 2.8819048404693604
Validation loss: 2.033013900121053

Epoch: 6| Step: 4
Training loss: 1.8194613456726074
Validation loss: 2.032140294710795

Epoch: 6| Step: 5
Training loss: 2.2699060440063477
Validation loss: 2.020979881286621

Epoch: 6| Step: 6
Training loss: 1.865037441253662
Validation loss: 2.0251784920692444

Epoch: 6| Step: 7
Training loss: 2.5820248126983643
Validation loss: 2.02314954996109

Epoch: 6| Step: 8
Training loss: 2.204441547393799
Validation loss: 2.030092716217041

Epoch: 6| Step: 9
Training loss: 1.598281741142273
Validation loss: 2.0270485083262124

Epoch: 6| Step: 10
Training loss: 2.2452423572540283
Validation loss: 2.029847880204519

Epoch: 6| Step: 11
Training loss: 1.5387167930603027
Validation loss: 2.0290196935335794

Epoch: 6| Step: 12
Training loss: 2.1412603855133057
Validation loss: 2.012119174003601

Epoch: 6| Step: 13
Training loss: 2.670766830444336
Validation loss: 2.012674927711487

Epoch: 120| Step: 0
Training loss: 2.166485071182251
Validation loss: 2.011627952257792

Epoch: 6| Step: 1
Training loss: 2.531062602996826
Validation loss: 2.01302433013916

Epoch: 6| Step: 2
Training loss: 2.8080177307128906
Validation loss: 2.0125417908032737

Epoch: 6| Step: 3
Training loss: 2.5591373443603516
Validation loss: 2.0074195663134256

Epoch: 6| Step: 4
Training loss: 2.420217514038086
Validation loss: 2.012060542901357

Epoch: 6| Step: 5
Training loss: 2.1420257091522217
Validation loss: 2.0092376271883645

Epoch: 6| Step: 6
Training loss: 2.150608777999878
Validation loss: 2.003545661767324

Epoch: 6| Step: 7
Training loss: 1.7962942123413086
Validation loss: 2.016192456086477

Epoch: 6| Step: 8
Training loss: 2.091021776199341
Validation loss: 2.0075297753016152

Epoch: 6| Step: 9
Training loss: 1.9513263702392578
Validation loss: 2.009838104248047

Epoch: 6| Step: 10
Training loss: 1.567739486694336
Validation loss: 2.015214224656423

Epoch: 6| Step: 11
Training loss: 2.245772361755371
Validation loss: 2.019031524658203

Epoch: 6| Step: 12
Training loss: 1.554344654083252
Validation loss: 2.0253902077674866

Epoch: 6| Step: 13
Training loss: 1.2504912614822388
Validation loss: 2.0189244747161865

Epoch: 121| Step: 0
Training loss: 2.4201271533966064
Validation loss: 2.029817740122477

Epoch: 6| Step: 1
Training loss: 1.8542554378509521
Validation loss: 2.0241451064745584

Epoch: 6| Step: 2
Training loss: 1.7432178258895874
Validation loss: 2.0354655583699546

Epoch: 6| Step: 3
Training loss: 1.7498129606246948
Validation loss: 2.023825943470001

Epoch: 6| Step: 4
Training loss: 2.2519469261169434
Validation loss: 2.022867202758789

Epoch: 6| Step: 5
Training loss: 1.7917660474777222
Validation loss: 2.0222683548927307

Epoch: 6| Step: 6
Training loss: 2.2106525897979736
Validation loss: 2.019455075263977

Epoch: 6| Step: 7
Training loss: 2.860227584838867
Validation loss: 2.0263781348864236

Epoch: 6| Step: 8
Training loss: 1.7701135873794556
Validation loss: 2.013666292031606

Epoch: 6| Step: 9
Training loss: 1.6698546409606934
Validation loss: 2.016774594783783

Epoch: 6| Step: 10
Training loss: 2.3494997024536133
Validation loss: 2.0186804135640464

Epoch: 6| Step: 11
Training loss: 2.1754021644592285
Validation loss: 2.0181331038475037

Epoch: 6| Step: 12
Training loss: 2.0900542736053467
Validation loss: 2.0210968653361

Epoch: 6| Step: 13
Training loss: 2.2077388763427734
Validation loss: 2.028053561846415

Epoch: 122| Step: 0
Training loss: 2.4556689262390137
Validation loss: 2.0291372338930764

Epoch: 6| Step: 1
Training loss: 1.849707007408142
Validation loss: 2.022203008333842

Epoch: 6| Step: 2
Training loss: 2.084446907043457
Validation loss: 2.033765494823456

Epoch: 6| Step: 3
Training loss: 1.9999885559082031
Validation loss: 2.0278284152348838

Epoch: 6| Step: 4
Training loss: 2.8817930221557617
Validation loss: 2.029908378918966

Epoch: 6| Step: 5
Training loss: 2.0873122215270996
Validation loss: 2.0259638826052346

Epoch: 6| Step: 6
Training loss: 1.9821107387542725
Validation loss: 2.021853963534037

Epoch: 6| Step: 7
Training loss: 1.9090126752853394
Validation loss: 2.036843995253245

Epoch: 6| Step: 8
Training loss: 1.8733832836151123
Validation loss: 2.025657534599304

Epoch: 6| Step: 9
Training loss: 1.850602626800537
Validation loss: 2.02495014667511

Epoch: 6| Step: 10
Training loss: 2.0561344623565674
Validation loss: 2.0244906346003213

Epoch: 6| Step: 11
Training loss: 1.533022403717041
Validation loss: 2.0013681848843894

Epoch: 6| Step: 12
Training loss: 2.070739269256592
Validation loss: 2.024481773376465

Epoch: 6| Step: 13
Training loss: 2.334073305130005
Validation loss: 2.0216007232666016

Epoch: 123| Step: 0
Training loss: 1.9372657537460327
Validation loss: 2.0175143678983054

Epoch: 6| Step: 1
Training loss: 1.4713382720947266
Validation loss: 2.0306394497553506

Epoch: 6| Step: 2
Training loss: 1.5436177253723145
Validation loss: 2.029545565446218

Epoch: 6| Step: 3
Training loss: 2.7823452949523926
Validation loss: 2.0349305272102356

Epoch: 6| Step: 4
Training loss: 2.4720380306243896
Validation loss: 2.0287708838780723

Epoch: 6| Step: 5
Training loss: 2.1087589263916016
Validation loss: 2.027788539727529

Epoch: 6| Step: 6
Training loss: 1.8128970861434937
Validation loss: 2.0360124905904136

Epoch: 6| Step: 7
Training loss: 2.2158381938934326
Validation loss: 2.0331903100013733

Epoch: 6| Step: 8
Training loss: 2.296781301498413
Validation loss: 2.0424044728279114

Epoch: 6| Step: 9
Training loss: 2.103489398956299
Validation loss: 2.0255138278007507

Epoch: 6| Step: 10
Training loss: 2.2628793716430664
Validation loss: 2.0278705755869546

Epoch: 6| Step: 11
Training loss: 1.871856451034546
Validation loss: 2.0235804120699563

Epoch: 6| Step: 12
Training loss: 2.162607431411743
Validation loss: 2.034025231997172

Epoch: 6| Step: 13
Training loss: 2.3737435340881348
Validation loss: 2.0288663109143577

Epoch: 124| Step: 0
Training loss: 2.284769058227539
Validation loss: 2.027738948663076

Epoch: 6| Step: 1
Training loss: 1.6254266500473022
Validation loss: 2.0230210224787393

Epoch: 6| Step: 2
Training loss: 2.400167942047119
Validation loss: 2.0308337012926736

Epoch: 6| Step: 3
Training loss: 1.9554181098937988
Validation loss: 2.045184055964152

Epoch: 6| Step: 4
Training loss: 2.1308674812316895
Validation loss: 2.0340457955996194

Epoch: 6| Step: 5
Training loss: 2.1832664012908936
Validation loss: 2.03319122393926

Epoch: 6| Step: 6
Training loss: 2.7232608795166016
Validation loss: 2.0318260987599692

Epoch: 6| Step: 7
Training loss: 2.398085117340088
Validation loss: 2.0308557748794556

Epoch: 6| Step: 8
Training loss: 1.9697375297546387
Validation loss: 2.029690901438395

Epoch: 6| Step: 9
Training loss: 1.634359359741211
Validation loss: 2.0234808723131814

Epoch: 6| Step: 10
Training loss: 1.6141839027404785
Validation loss: 2.031048754851023

Epoch: 6| Step: 11
Training loss: 1.89704167842865
Validation loss: 2.016815463701884

Epoch: 6| Step: 12
Training loss: 1.930685043334961
Validation loss: 2.0116209983825684

Epoch: 6| Step: 13
Training loss: 2.1874217987060547
Validation loss: 2.015071471532186

Epoch: 125| Step: 0
Training loss: 2.081366777420044
Validation loss: 2.0313344399134317

Epoch: 6| Step: 1
Training loss: 2.4257590770721436
Validation loss: 2.0285043915112815

Epoch: 6| Step: 2
Training loss: 2.068223237991333
Validation loss: 2.0287922024726868

Epoch: 6| Step: 3
Training loss: 2.2198729515075684
Validation loss: 2.0334970951080322

Epoch: 6| Step: 4
Training loss: 1.5459723472595215
Validation loss: 2.032657186190287

Epoch: 6| Step: 5
Training loss: 2.3515119552612305
Validation loss: 2.03152334690094

Epoch: 6| Step: 6
Training loss: 1.8156673908233643
Validation loss: 2.019610345363617

Epoch: 6| Step: 7
Training loss: 2.100235939025879
Validation loss: 2.02504555384318

Epoch: 6| Step: 8
Training loss: 1.492143154144287
Validation loss: 2.0288588802019754

Epoch: 6| Step: 9
Training loss: 2.74208402633667
Validation loss: 2.016896923383077

Epoch: 6| Step: 10
Training loss: 1.656221628189087
Validation loss: 2.0230676929155984

Epoch: 6| Step: 11
Training loss: 2.3337690830230713
Validation loss: 2.0300265550613403

Epoch: 6| Step: 12
Training loss: 2.1782708168029785
Validation loss: 2.0255921880404153

Epoch: 6| Step: 13
Training loss: 1.7758960723876953
Validation loss: 2.0275739431381226

Epoch: 126| Step: 0
Training loss: 2.024631977081299
Validation loss: 2.021151880423228

Epoch: 6| Step: 1
Training loss: 2.499035358428955
Validation loss: 2.030316412448883

Epoch: 6| Step: 2
Training loss: 2.4148035049438477
Validation loss: 2.0300707817077637

Epoch: 6| Step: 3
Training loss: 1.7590827941894531
Validation loss: 2.020806392033895

Epoch: 6| Step: 4
Training loss: 1.9484858512878418
Validation loss: 2.0188658038775125

Epoch: 6| Step: 5
Training loss: 1.7572779655456543
Validation loss: 2.0162670016288757

Epoch: 6| Step: 6
Training loss: 1.5701024532318115
Validation loss: 2.0206120014190674

Epoch: 6| Step: 7
Training loss: 2.1259424686431885
Validation loss: 2.0078927477200827

Epoch: 6| Step: 8
Training loss: 1.8483742475509644
Validation loss: 2.0156468749046326

Epoch: 6| Step: 9
Training loss: 3.20334529876709
Validation loss: 2.013965924580892

Epoch: 6| Step: 10
Training loss: 1.65068519115448
Validation loss: 2.0108600854873657

Epoch: 6| Step: 11
Training loss: 1.7664794921875
Validation loss: 2.01890895764033

Epoch: 6| Step: 12
Training loss: 1.9844090938568115
Validation loss: 2.013906796773275

Epoch: 6| Step: 13
Training loss: 2.1842212677001953
Validation loss: 2.0190078218777976

Epoch: 127| Step: 0
Training loss: 1.8434510231018066
Validation loss: 2.006300628185272

Epoch: 6| Step: 1
Training loss: 1.996605634689331
Validation loss: 2.025908430417379

Epoch: 6| Step: 2
Training loss: 1.992030143737793
Validation loss: 2.0228551030158997

Epoch: 6| Step: 3
Training loss: 2.20700740814209
Validation loss: 2.0204976201057434

Epoch: 6| Step: 4
Training loss: 1.30758798122406
Validation loss: 2.0235304832458496

Epoch: 6| Step: 5
Training loss: 2.2075376510620117
Validation loss: 2.0169836481412253

Epoch: 6| Step: 6
Training loss: 1.3767521381378174
Validation loss: 2.021094004313151

Epoch: 6| Step: 7
Training loss: 2.3705663681030273
Validation loss: 2.0228524804115295

Epoch: 6| Step: 8
Training loss: 1.79646897315979
Validation loss: 2.023776590824127

Epoch: 6| Step: 9
Training loss: 2.4686145782470703
Validation loss: 2.0293355186780295

Epoch: 6| Step: 10
Training loss: 2.180307388305664
Validation loss: 2.0315356850624084

Epoch: 6| Step: 11
Training loss: 1.8853710889816284
Validation loss: 2.021781543890635

Epoch: 6| Step: 12
Training loss: 2.83499813079834
Validation loss: 2.015595813592275

Epoch: 6| Step: 13
Training loss: 2.3988842964172363
Validation loss: 2.0172119537989297

Epoch: 128| Step: 0
Training loss: 1.456080675125122
Validation loss: 2.00249191125234

Epoch: 6| Step: 1
Training loss: 2.0268547534942627
Validation loss: 2.014501412709554

Epoch: 6| Step: 2
Training loss: 2.034078359603882
Validation loss: 2.0051356156667075

Epoch: 6| Step: 3
Training loss: 2.148467540740967
Validation loss: 2.0082557797431946

Epoch: 6| Step: 4
Training loss: 2.2378602027893066
Validation loss: 2.002454380194346

Epoch: 6| Step: 5
Training loss: 2.0524845123291016
Validation loss: 2.006949226061503

Epoch: 6| Step: 6
Training loss: 1.6583731174468994
Validation loss: 2.0115758776664734

Epoch: 6| Step: 7
Training loss: 2.425550937652588
Validation loss: 2.0164000391960144

Epoch: 6| Step: 8
Training loss: 1.1848891973495483
Validation loss: 2.0123652815818787

Epoch: 6| Step: 9
Training loss: 2.6861073970794678
Validation loss: 2.0034470558166504

Epoch: 6| Step: 10
Training loss: 1.993175745010376
Validation loss: 2.0140116214752197

Epoch: 6| Step: 11
Training loss: 2.347852945327759
Validation loss: 2.0162171920140586

Epoch: 6| Step: 12
Training loss: 2.8276641368865967
Validation loss: 2.028174579143524

Epoch: 6| Step: 13
Training loss: 1.609086513519287
Validation loss: 2.0378547509511313

Epoch: 129| Step: 0
Training loss: 1.904043197631836
Validation loss: 2.032702922821045

Epoch: 6| Step: 1
Training loss: 1.9139404296875
Validation loss: 2.0426703294118247

Epoch: 6| Step: 2
Training loss: 2.224586248397827
Validation loss: 2.0388187567392984

Epoch: 6| Step: 3
Training loss: 1.682572364807129
Validation loss: 2.024260481198629

Epoch: 6| Step: 4
Training loss: 2.0221452713012695
Validation loss: 2.0239126284917197

Epoch: 6| Step: 5
Training loss: 1.7844525575637817
Validation loss: 2.0255409876505532

Epoch: 6| Step: 6
Training loss: 2.4394121170043945
Validation loss: 2.0292601585388184

Epoch: 6| Step: 7
Training loss: 2.5867600440979004
Validation loss: 2.026897609233856

Epoch: 6| Step: 8
Training loss: 2.363678455352783
Validation loss: 2.0218952695528665

Epoch: 6| Step: 9
Training loss: 2.2381033897399902
Validation loss: 2.024768114089966

Epoch: 6| Step: 10
Training loss: 1.7298202514648438
Validation loss: 2.0254034996032715

Epoch: 6| Step: 11
Training loss: 2.187732696533203
Validation loss: 2.0277948578198752

Epoch: 6| Step: 12
Training loss: 1.839751124382019
Validation loss: 2.0309642950693765

Epoch: 6| Step: 13
Training loss: 2.0622873306274414
Validation loss: 2.022305130958557

Epoch: 130| Step: 0
Training loss: 2.4306392669677734
Validation loss: 2.0292442639668784

Epoch: 6| Step: 1
Training loss: 2.310486316680908
Validation loss: 2.026698052883148

Epoch: 6| Step: 2
Training loss: 2.689669609069824
Validation loss: 2.024100343386332

Epoch: 6| Step: 3
Training loss: 1.8946914672851562
Validation loss: 2.0230557322502136

Epoch: 6| Step: 4
Training loss: 2.178823709487915
Validation loss: 2.024499754110972

Epoch: 6| Step: 5
Training loss: 2.3567986488342285
Validation loss: 2.034940997759501

Epoch: 6| Step: 6
Training loss: 1.6654173135757446
Validation loss: 2.0226492484410605

Epoch: 6| Step: 7
Training loss: 1.7831138372421265
Validation loss: 2.037806431452433

Epoch: 6| Step: 8
Training loss: 1.7606091499328613
Validation loss: 2.034681578477224

Epoch: 6| Step: 9
Training loss: 1.879676342010498
Validation loss: 2.0231319665908813

Epoch: 6| Step: 10
Training loss: 1.7436425685882568
Validation loss: 2.016667346159617

Epoch: 6| Step: 11
Training loss: 2.065793514251709
Validation loss: 2.008473575115204

Epoch: 6| Step: 12
Training loss: 2.1428427696228027
Validation loss: 2.0160075426101685

Epoch: 6| Step: 13
Training loss: 2.063845157623291
Validation loss: 2.0180325905481973

Epoch: 131| Step: 0
Training loss: 2.2550032138824463
Validation loss: 2.0247024496396384

Epoch: 6| Step: 1
Training loss: 1.502120018005371
Validation loss: 2.015566090742747

Epoch: 6| Step: 2
Training loss: 1.3966412544250488
Validation loss: 2.0256504813830056

Epoch: 6| Step: 3
Training loss: 1.7421679496765137
Validation loss: 2.0219890673955283

Epoch: 6| Step: 4
Training loss: 2.347032070159912
Validation loss: 2.022324244181315

Epoch: 6| Step: 5
Training loss: 2.2227373123168945
Validation loss: 2.018321931362152

Epoch: 6| Step: 6
Training loss: 2.037101984024048
Validation loss: 2.0304558873176575

Epoch: 6| Step: 7
Training loss: 2.054126024246216
Validation loss: 2.0339640776316323

Epoch: 6| Step: 8
Training loss: 2.167804479598999
Validation loss: 2.032891889413198

Epoch: 6| Step: 9
Training loss: 2.47462797164917
Validation loss: 2.030271530151367

Epoch: 6| Step: 10
Training loss: 1.8448657989501953
Validation loss: 2.0392595132191977

Epoch: 6| Step: 11
Training loss: 2.2018232345581055
Validation loss: 2.0308395822842917

Epoch: 6| Step: 12
Training loss: 2.454641342163086
Validation loss: 2.0447046160697937

Epoch: 6| Step: 13
Training loss: 2.118283748626709
Validation loss: 2.0352651874224343

Epoch: 132| Step: 0
Training loss: 1.9282901287078857
Validation loss: 2.036366860071818

Epoch: 6| Step: 1
Training loss: 2.408862590789795
Validation loss: 2.0305261413256326

Epoch: 6| Step: 2
Training loss: 1.8477319478988647
Validation loss: 2.034032861391703

Epoch: 6| Step: 3
Training loss: 1.7431026697158813
Validation loss: 2.028759936491648

Epoch: 6| Step: 4
Training loss: 2.6553728580474854
Validation loss: 2.0315802097320557

Epoch: 6| Step: 5
Training loss: 2.012328624725342
Validation loss: 2.0255696376164756

Epoch: 6| Step: 6
Training loss: 1.8757023811340332
Validation loss: 2.0259123047192893

Epoch: 6| Step: 7
Training loss: 2.213686466217041
Validation loss: 2.034117877483368

Epoch: 6| Step: 8
Training loss: 1.8652770519256592
Validation loss: 2.0296642184257507

Epoch: 6| Step: 9
Training loss: 1.5641627311706543
Validation loss: 2.0320183634757996

Epoch: 6| Step: 10
Training loss: 2.0277373790740967
Validation loss: 2.0343751509984336

Epoch: 6| Step: 11
Training loss: 2.189117431640625
Validation loss: 2.0310756166776023

Epoch: 6| Step: 12
Training loss: 2.594667434692383
Validation loss: 2.0410969058672586

Epoch: 6| Step: 13
Training loss: 1.7459428310394287
Validation loss: 2.0269007285435996

Epoch: 133| Step: 0
Training loss: 2.2766239643096924
Validation loss: 2.0381776491800943

Epoch: 6| Step: 1
Training loss: 1.7407011985778809
Validation loss: 2.02729868888855

Epoch: 6| Step: 2
Training loss: 1.451634407043457
Validation loss: 2.0345802704493203

Epoch: 6| Step: 3
Training loss: 1.7192254066467285
Validation loss: 2.03505406777064

Epoch: 6| Step: 4
Training loss: 2.693462371826172
Validation loss: 2.0369355281194053

Epoch: 6| Step: 5
Training loss: 1.8538963794708252
Validation loss: 2.059382458527883

Epoch: 6| Step: 6
Training loss: 2.0257277488708496
Validation loss: 2.047310789426168

Epoch: 6| Step: 7
Training loss: 2.363313674926758
Validation loss: 2.0534557104110718

Epoch: 6| Step: 8
Training loss: 1.4271827936172485
Validation loss: 2.045368492603302

Epoch: 6| Step: 9
Training loss: 2.6162383556365967
Validation loss: 2.057582755883535

Epoch: 6| Step: 10
Training loss: 1.7395496368408203
Validation loss: 2.0460748275121055

Epoch: 6| Step: 11
Training loss: 1.9135836362838745
Validation loss: 2.0392701824506125

Epoch: 6| Step: 12
Training loss: 2.347799301147461
Validation loss: 2.0533961057662964

Epoch: 6| Step: 13
Training loss: 2.607771873474121
Validation loss: 2.0492984851201377

Epoch: 134| Step: 0
Training loss: 1.2155296802520752
Validation loss: 2.041005770365397

Epoch: 6| Step: 1
Training loss: 2.6388955116271973
Validation loss: 2.0307167967160544

Epoch: 6| Step: 2
Training loss: 1.9154685735702515
Validation loss: 2.0308204094568887

Epoch: 6| Step: 3
Training loss: 2.063769578933716
Validation loss: 2.02303409576416

Epoch: 6| Step: 4
Training loss: 2.0462851524353027
Validation loss: 2.033908704916636

Epoch: 6| Step: 5
Training loss: 2.1380562782287598
Validation loss: 2.027993639310201

Epoch: 6| Step: 6
Training loss: 1.7429310083389282
Validation loss: 2.0315608382225037

Epoch: 6| Step: 7
Training loss: 2.320523738861084
Validation loss: 2.018585522969564

Epoch: 6| Step: 8
Training loss: 1.8867990970611572
Validation loss: 2.0253619949022927

Epoch: 6| Step: 9
Training loss: 2.3251631259918213
Validation loss: 2.0261645913124084

Epoch: 6| Step: 10
Training loss: 2.1868977546691895
Validation loss: 2.0280696153640747

Epoch: 6| Step: 11
Training loss: 2.1031289100646973
Validation loss: 2.0297309358914695

Epoch: 6| Step: 12
Training loss: 1.866676926612854
Validation loss: 2.021958331267039

Epoch: 6| Step: 13
Training loss: 2.335923433303833
Validation loss: 2.018616795539856

Epoch: 135| Step: 0
Training loss: 2.7218098640441895
Validation loss: 2.0201646288235984

Epoch: 6| Step: 1
Training loss: 1.5386083126068115
Validation loss: 2.0159546534220376

Epoch: 6| Step: 2
Training loss: 1.5253939628601074
Validation loss: 2.0304126342137656

Epoch: 6| Step: 3
Training loss: 2.4229671955108643
Validation loss: 2.0311162074406943

Epoch: 6| Step: 4
Training loss: 1.57881498336792
Validation loss: 2.033692181110382

Epoch: 6| Step: 5
Training loss: 2.4047231674194336
Validation loss: 2.0280078649520874

Epoch: 6| Step: 6
Training loss: 2.1344780921936035
Validation loss: 2.031408707300822

Epoch: 6| Step: 7
Training loss: 2.3792736530303955
Validation loss: 2.034850815931956

Epoch: 6| Step: 8
Training loss: 1.6894298791885376
Validation loss: 2.0353955825169883

Epoch: 6| Step: 9
Training loss: 2.196864128112793
Validation loss: 2.034285287062327

Epoch: 6| Step: 10
Training loss: 2.057541847229004
Validation loss: 2.026394804318746

Epoch: 6| Step: 11
Training loss: 2.109591007232666
Validation loss: 2.0330448945363364

Epoch: 6| Step: 12
Training loss: 2.2453455924987793
Validation loss: 2.035015285015106

Epoch: 6| Step: 13
Training loss: 1.5890992879867554
Validation loss: 2.0416282216707864

Epoch: 136| Step: 0
Training loss: 1.8465814590454102
Validation loss: 2.0396156311035156

Epoch: 6| Step: 1
Training loss: 1.9453389644622803
Validation loss: 2.03725657860438

Epoch: 6| Step: 2
Training loss: 1.9407895803451538
Validation loss: 2.0415080388387046

Epoch: 6| Step: 3
Training loss: 2.260293483734131
Validation loss: 2.030433436234792

Epoch: 6| Step: 4
Training loss: 2.1483607292175293
Validation loss: 2.03965695699056

Epoch: 6| Step: 5
Training loss: 2.205965518951416
Validation loss: 2.030924161275228

Epoch: 6| Step: 6
Training loss: 2.1926193237304688
Validation loss: 2.038592278957367

Epoch: 6| Step: 7
Training loss: 2.079660415649414
Validation loss: 2.0397571523984275

Epoch: 6| Step: 8
Training loss: 1.940009355545044
Validation loss: 2.0405869086583457

Epoch: 6| Step: 9
Training loss: 2.2563066482543945
Validation loss: 2.042874793211619

Epoch: 6| Step: 10
Training loss: 1.5979766845703125
Validation loss: 2.047156274318695

Epoch: 6| Step: 11
Training loss: 1.349851369857788
Validation loss: 2.048242211341858

Epoch: 6| Step: 12
Training loss: 2.2458040714263916
Validation loss: 2.047211011250814

Epoch: 6| Step: 13
Training loss: 2.632521867752075
Validation loss: 2.0493472814559937

Epoch: 137| Step: 0
Training loss: 1.8334944248199463
Validation loss: 2.0393027861913047

Epoch: 6| Step: 1
Training loss: 1.9093382358551025
Validation loss: 2.03990109761556

Epoch: 6| Step: 2
Training loss: 2.4698472023010254
Validation loss: 2.036460002263387

Epoch: 6| Step: 3
Training loss: 1.9020615816116333
Validation loss: 2.0438843170801797

Epoch: 6| Step: 4
Training loss: 1.8105287551879883
Validation loss: 2.0292648673057556

Epoch: 6| Step: 5
Training loss: 2.7153148651123047
Validation loss: 2.030740976333618

Epoch: 6| Step: 6
Training loss: 1.4413906335830688
Validation loss: 2.0307178497314453

Epoch: 6| Step: 7
Training loss: 1.720432162284851
Validation loss: 2.0371715426445007

Epoch: 6| Step: 8
Training loss: 2.0859358310699463
Validation loss: 2.0298153360684714

Epoch: 6| Step: 9
Training loss: 2.2608838081359863
Validation loss: 2.0361852645874023

Epoch: 6| Step: 10
Training loss: 1.8160250186920166
Validation loss: 2.0344350337982178

Epoch: 6| Step: 11
Training loss: 2.801553726196289
Validation loss: 2.0320600668589273

Epoch: 6| Step: 12
Training loss: 2.258456230163574
Validation loss: 2.034291903177897

Epoch: 6| Step: 13
Training loss: 1.7695064544677734
Validation loss: 2.0260669390360513

Epoch: 138| Step: 0
Training loss: 1.8812713623046875
Validation loss: 2.020795245965322

Epoch: 6| Step: 1
Training loss: 2.4796648025512695
Validation loss: 2.0248185992240906

Epoch: 6| Step: 2
Training loss: 1.7334953546524048
Validation loss: 2.018695116043091

Epoch: 6| Step: 3
Training loss: 1.6268315315246582
Validation loss: 2.022853434085846

Epoch: 6| Step: 4
Training loss: 1.8958258628845215
Validation loss: 2.0325230956077576

Epoch: 6| Step: 5
Training loss: 1.965887188911438
Validation loss: 2.0462334950764975

Epoch: 6| Step: 6
Training loss: 2.3811144828796387
Validation loss: 2.0698309938112893

Epoch: 6| Step: 7
Training loss: 1.860060691833496
Validation loss: 2.0811424454053244

Epoch: 6| Step: 8
Training loss: 1.7870668172836304
Validation loss: 2.072665294011434

Epoch: 6| Step: 9
Training loss: 2.408419132232666
Validation loss: 2.0748971501986184

Epoch: 6| Step: 10
Training loss: 2.3469667434692383
Validation loss: 2.081964453061422

Epoch: 6| Step: 11
Training loss: 1.8106193542480469
Validation loss: 2.086992601553599

Epoch: 6| Step: 12
Training loss: 2.367990732192993
Validation loss: 2.051627198855082

Epoch: 6| Step: 13
Training loss: 2.031989574432373
Validation loss: 2.051382919152578

Epoch: 139| Step: 0
Training loss: 2.1291561126708984
Validation loss: 2.047236959139506

Epoch: 6| Step: 1
Training loss: 2.244528293609619
Validation loss: 2.0381665031115213

Epoch: 6| Step: 2
Training loss: 2.756296396255493
Validation loss: 2.04258926709493

Epoch: 6| Step: 3
Training loss: 1.4780800342559814
Validation loss: 2.0391193628311157

Epoch: 6| Step: 4
Training loss: 2.2327096462249756
Validation loss: 2.0391799211502075

Epoch: 6| Step: 5
Training loss: 1.963874340057373
Validation loss: 2.0339508652687073

Epoch: 6| Step: 6
Training loss: 1.8571079969406128
Validation loss: 2.0437735120455423

Epoch: 6| Step: 7
Training loss: 1.6057493686676025
Validation loss: 2.026745080947876

Epoch: 6| Step: 8
Training loss: 1.3561701774597168
Validation loss: 2.0327669183413186

Epoch: 6| Step: 9
Training loss: 1.9448723793029785
Validation loss: 2.037840982278188

Epoch: 6| Step: 10
Training loss: 2.022834539413452
Validation loss: 2.0364250938097634

Epoch: 6| Step: 11
Training loss: 2.771468162536621
Validation loss: 2.0479063391685486

Epoch: 6| Step: 12
Training loss: 2.034177303314209
Validation loss: 2.042263090610504

Epoch: 6| Step: 13
Training loss: 2.2384700775146484
Validation loss: 2.038189431031545

Epoch: 140| Step: 0
Training loss: 1.8709282875061035
Validation loss: 2.031028767426809

Epoch: 6| Step: 1
Training loss: 2.018162965774536
Validation loss: 2.0269997318585715

Epoch: 6| Step: 2
Training loss: 1.9003610610961914
Validation loss: 2.0252968072891235

Epoch: 6| Step: 3
Training loss: 2.1582603454589844
Validation loss: 2.030996779600779

Epoch: 6| Step: 4
Training loss: 2.0853772163391113
Validation loss: 2.041871706644694

Epoch: 6| Step: 5
Training loss: 2.098407745361328
Validation loss: 2.027863641579946

Epoch: 6| Step: 6
Training loss: 2.3322677612304688
Validation loss: 2.0310944318771362

Epoch: 6| Step: 7
Training loss: 1.9225813150405884
Validation loss: 2.0290584365526834

Epoch: 6| Step: 8
Training loss: 2.058842658996582
Validation loss: 2.020996352036794

Epoch: 6| Step: 9
Training loss: 2.2331485748291016
Validation loss: 2.025432745615641

Epoch: 6| Step: 10
Training loss: 1.7681169509887695
Validation loss: 2.0289204319318137

Epoch: 6| Step: 11
Training loss: 1.9199209213256836
Validation loss: 2.0248432556788125

Epoch: 6| Step: 12
Training loss: 1.8963515758514404
Validation loss: 2.041021207968394

Epoch: 6| Step: 13
Training loss: 2.327099323272705
Validation loss: 2.0349931915601096

Epoch: 141| Step: 0
Training loss: 2.155890464782715
Validation loss: 2.0356001257896423

Epoch: 6| Step: 1
Training loss: 1.587090253829956
Validation loss: 2.0430395801862082

Epoch: 6| Step: 2
Training loss: 2.2334799766540527
Validation loss: 2.050866266091665

Epoch: 6| Step: 3
Training loss: 2.2126433849334717
Validation loss: 2.0449798504511514

Epoch: 6| Step: 4
Training loss: 2.051455497741699
Validation loss: 2.0386639833450317

Epoch: 6| Step: 5
Training loss: 2.011779546737671
Validation loss: 2.039186636606852

Epoch: 6| Step: 6
Training loss: 1.293584942817688
Validation loss: 2.032131473223368

Epoch: 6| Step: 7
Training loss: 1.1944656372070312
Validation loss: 2.038887838522593

Epoch: 6| Step: 8
Training loss: 2.055574417114258
Validation loss: 2.028999308745066

Epoch: 6| Step: 9
Training loss: 1.8868763446807861
Validation loss: 2.0266484022140503

Epoch: 6| Step: 10
Training loss: 2.9678499698638916
Validation loss: 2.0319908062616983

Epoch: 6| Step: 11
Training loss: 2.5743675231933594
Validation loss: 2.037050505479177

Epoch: 6| Step: 12
Training loss: 2.161477565765381
Validation loss: 2.0521663626035056

Epoch: 6| Step: 13
Training loss: 2.199256420135498
Validation loss: 2.034643292427063

Epoch: 142| Step: 0
Training loss: 1.8799443244934082
Validation loss: 2.034125884373983

Epoch: 6| Step: 1
Training loss: 2.379627227783203
Validation loss: 2.0396021604537964

Epoch: 6| Step: 2
Training loss: 2.2286059856414795
Validation loss: 2.0382426579793296

Epoch: 6| Step: 3
Training loss: 1.603816032409668
Validation loss: 2.0474594235420227

Epoch: 6| Step: 4
Training loss: 1.4591646194458008
Validation loss: 2.043673495451609

Epoch: 6| Step: 5
Training loss: 2.126448392868042
Validation loss: 2.0444466272989907

Epoch: 6| Step: 6
Training loss: 2.0253772735595703
Validation loss: 2.0614201029141745

Epoch: 6| Step: 7
Training loss: 2.175950288772583
Validation loss: 2.054835557937622

Epoch: 6| Step: 8
Training loss: 1.8328856229782104
Validation loss: 2.054359495639801

Epoch: 6| Step: 9
Training loss: 2.107538938522339
Validation loss: 2.0476123094558716

Epoch: 6| Step: 10
Training loss: 1.8261383771896362
Validation loss: 2.0602531830469766

Epoch: 6| Step: 11
Training loss: 2.346043109893799
Validation loss: 2.0610541701316833

Epoch: 6| Step: 12
Training loss: 2.407573938369751
Validation loss: 2.0507850646972656

Epoch: 6| Step: 13
Training loss: 2.067782402038574
Validation loss: 2.0431845982869468

Epoch: 143| Step: 0
Training loss: 1.429767370223999
Validation loss: 2.050052762031555

Epoch: 6| Step: 1
Training loss: 2.237501621246338
Validation loss: 2.050072113672892

Epoch: 6| Step: 2
Training loss: 2.3122758865356445
Validation loss: 2.042075832684835

Epoch: 6| Step: 3
Training loss: 2.269935131072998
Validation loss: 2.046411097049713

Epoch: 6| Step: 4
Training loss: 2.0730361938476562
Validation loss: 2.0448548396428428

Epoch: 6| Step: 5
Training loss: 2.142138957977295
Validation loss: 2.0448559125264487

Epoch: 6| Step: 6
Training loss: 1.8262859582901
Validation loss: 2.0416518251101174

Epoch: 6| Step: 7
Training loss: 1.7662758827209473
Validation loss: 2.0463279088338218

Epoch: 6| Step: 8
Training loss: 1.8680479526519775
Validation loss: 2.0420366326967874

Epoch: 6| Step: 9
Training loss: 2.687401294708252
Validation loss: 2.0424660642941794

Epoch: 6| Step: 10
Training loss: 1.4922218322753906
Validation loss: 2.0558937390645347

Epoch: 6| Step: 11
Training loss: 2.483999013900757
Validation loss: 2.0470340251922607

Epoch: 6| Step: 12
Training loss: 1.6501049995422363
Validation loss: 2.048196494579315

Epoch: 6| Step: 13
Training loss: 2.1570324897766113
Validation loss: 2.0375410119692483

Epoch: 144| Step: 0
Training loss: 1.7930808067321777
Validation loss: 2.039387802282969

Epoch: 6| Step: 1
Training loss: 2.0805587768554688
Validation loss: 2.0351895093917847

Epoch: 6| Step: 2
Training loss: 2.161360502243042
Validation loss: 2.0474366346995034

Epoch: 6| Step: 3
Training loss: 2.3436479568481445
Validation loss: 2.0486857096354165

Epoch: 6| Step: 4
Training loss: 2.1058082580566406
Validation loss: 2.0386659304300943

Epoch: 6| Step: 5
Training loss: 1.7769980430603027
Validation loss: 2.049628655115763

Epoch: 6| Step: 6
Training loss: 2.5087413787841797
Validation loss: 2.052823483943939

Epoch: 6| Step: 7
Training loss: 2.077393054962158
Validation loss: 2.065789779027303

Epoch: 6| Step: 8
Training loss: 1.7614015340805054
Validation loss: 2.067856033643087

Epoch: 6| Step: 9
Training loss: 2.247260570526123
Validation loss: 2.079753319422404

Epoch: 6| Step: 10
Training loss: 1.4392427206039429
Validation loss: 2.068656305472056

Epoch: 6| Step: 11
Training loss: 2.0028316974639893
Validation loss: 2.0677698850631714

Epoch: 6| Step: 12
Training loss: 2.24465274810791
Validation loss: 2.0684111515680947

Epoch: 6| Step: 13
Training loss: 2.166032314300537
Validation loss: 2.0528766910235086

Epoch: 145| Step: 0
Training loss: 1.8155187368392944
Validation loss: 2.0602100094159446

Epoch: 6| Step: 1
Training loss: 2.389218807220459
Validation loss: 2.049826741218567

Epoch: 6| Step: 2
Training loss: 2.0192856788635254
Validation loss: 2.040036956469218

Epoch: 6| Step: 3
Training loss: 2.088407516479492
Validation loss: 2.0570556124051413

Epoch: 6| Step: 4
Training loss: 3.0469095706939697
Validation loss: 2.049137512842814

Epoch: 6| Step: 5
Training loss: 2.0223498344421387
Validation loss: 2.059183398882548

Epoch: 6| Step: 6
Training loss: 1.9289969205856323
Validation loss: 2.051520665486654

Epoch: 6| Step: 7
Training loss: 2.1739768981933594
Validation loss: 2.0627869764963784

Epoch: 6| Step: 8
Training loss: 1.8611299991607666
Validation loss: 2.054394483566284

Epoch: 6| Step: 9
Training loss: 1.7526600360870361
Validation loss: 2.0557664036750793

Epoch: 6| Step: 10
Training loss: 1.8509151935577393
Validation loss: 2.0507587790489197

Epoch: 6| Step: 11
Training loss: 1.7368563413619995
Validation loss: 2.0453854401906333

Epoch: 6| Step: 12
Training loss: 1.5516340732574463
Validation loss: 2.0411600867907205

Epoch: 6| Step: 13
Training loss: 2.167701244354248
Validation loss: 2.052444795767466

Epoch: 146| Step: 0
Training loss: 2.3467421531677246
Validation loss: 2.04652871688207

Epoch: 6| Step: 1
Training loss: 1.912536859512329
Validation loss: 2.029375731945038

Epoch: 6| Step: 2
Training loss: 2.161569356918335
Validation loss: 2.033309519290924

Epoch: 6| Step: 3
Training loss: 1.8429447412490845
Validation loss: 2.029498895009359

Epoch: 6| Step: 4
Training loss: 1.6975336074829102
Validation loss: 2.030725419521332

Epoch: 6| Step: 5
Training loss: 2.0740957260131836
Validation loss: 2.0335828065872192

Epoch: 6| Step: 6
Training loss: 1.9487296342849731
Validation loss: 2.038294732570648

Epoch: 6| Step: 7
Training loss: 2.06148099899292
Validation loss: 2.0400187770525613

Epoch: 6| Step: 8
Training loss: 2.6703901290893555
Validation loss: 2.0433315436045327

Epoch: 6| Step: 9
Training loss: 2.091937780380249
Validation loss: 2.0344887177149453

Epoch: 6| Step: 10
Training loss: 1.5687649250030518
Validation loss: 2.032697061697642

Epoch: 6| Step: 11
Training loss: 1.9390383958816528
Validation loss: 2.0315187176068625

Epoch: 6| Step: 12
Training loss: 1.66361403465271
Validation loss: 2.0401926835378013

Epoch: 6| Step: 13
Training loss: 2.556121349334717
Validation loss: 2.046244661013285

Epoch: 147| Step: 0
Training loss: 1.878021001815796
Validation loss: 2.0544737378756204

Epoch: 6| Step: 1
Training loss: 2.2498106956481934
Validation loss: 2.0443206628163657

Epoch: 6| Step: 2
Training loss: 2.390202522277832
Validation loss: 2.0594902634620667

Epoch: 6| Step: 3
Training loss: 1.7692909240722656
Validation loss: 2.0450915495554605

Epoch: 6| Step: 4
Training loss: 1.6588771343231201
Validation loss: 2.0543846487998962

Epoch: 6| Step: 5
Training loss: 2.0781922340393066
Validation loss: 2.0552813013394675

Epoch: 6| Step: 6
Training loss: 1.7450722455978394
Validation loss: 2.0528713266054788

Epoch: 6| Step: 7
Training loss: 1.8824281692504883
Validation loss: 2.0392648180325827

Epoch: 6| Step: 8
Training loss: 2.4301397800445557
Validation loss: 2.025288005669912

Epoch: 6| Step: 9
Training loss: 2.294020891189575
Validation loss: 2.03287680943807

Epoch: 6| Step: 10
Training loss: 2.1904537677764893
Validation loss: 2.027270237604777

Epoch: 6| Step: 11
Training loss: 1.8280272483825684
Validation loss: 2.0140838821729026

Epoch: 6| Step: 12
Training loss: 2.157860517501831
Validation loss: 2.0375539461771646

Epoch: 6| Step: 13
Training loss: 2.1153597831726074
Validation loss: 2.037618557612101

Epoch: 148| Step: 0
Training loss: 1.8498942852020264
Validation loss: 2.0610907673835754

Epoch: 6| Step: 1
Training loss: 1.9398472309112549
Validation loss: 2.0583388805389404

Epoch: 6| Step: 2
Training loss: 2.6056885719299316
Validation loss: 2.051811953385671

Epoch: 6| Step: 3
Training loss: 1.7209209203720093
Validation loss: 2.050592382748922

Epoch: 6| Step: 4
Training loss: 1.7968173027038574
Validation loss: 2.04415500164032

Epoch: 6| Step: 5
Training loss: 2.1947789192199707
Validation loss: 2.0368834733963013

Epoch: 6| Step: 6
Training loss: 1.2698380947113037
Validation loss: 2.037756005922953

Epoch: 6| Step: 7
Training loss: 1.8805700540542603
Validation loss: 2.044339875380198

Epoch: 6| Step: 8
Training loss: 2.3867340087890625
Validation loss: 2.044178326924642

Epoch: 6| Step: 9
Training loss: 1.8347809314727783
Validation loss: 2.0581366419792175

Epoch: 6| Step: 10
Training loss: 2.892655849456787
Validation loss: 2.0517764488855996

Epoch: 6| Step: 11
Training loss: 2.0704843997955322
Validation loss: 2.0599302848180137

Epoch: 6| Step: 12
Training loss: 1.7581453323364258
Validation loss: 2.057762404282888

Epoch: 6| Step: 13
Training loss: 2.6935982704162598
Validation loss: 2.057490050792694

Epoch: 149| Step: 0
Training loss: 1.6771769523620605
Validation loss: 2.0508780082066855

Epoch: 6| Step: 1
Training loss: 2.272580623626709
Validation loss: 2.0549540718396506

Epoch: 6| Step: 2
Training loss: 1.2093946933746338
Validation loss: 2.047704497973124

Epoch: 6| Step: 3
Training loss: 1.7956045866012573
Validation loss: 2.0474307537078857

Epoch: 6| Step: 4
Training loss: 2.0191712379455566
Validation loss: 2.0491375724474588

Epoch: 6| Step: 5
Training loss: 2.2102179527282715
Validation loss: 2.046609342098236

Epoch: 6| Step: 6
Training loss: 2.0797629356384277
Validation loss: 2.0488529404004416

Epoch: 6| Step: 7
Training loss: 2.1339921951293945
Validation loss: 2.0540544589360556

Epoch: 6| Step: 8
Training loss: 2.105116367340088
Validation loss: 2.047420005003611

Epoch: 6| Step: 9
Training loss: 1.6704013347625732
Validation loss: 2.055693209171295

Epoch: 6| Step: 10
Training loss: 2.301823377609253
Validation loss: 2.0488646030426025

Epoch: 6| Step: 11
Training loss: 2.250397205352783
Validation loss: 2.0578681429227195

Epoch: 6| Step: 12
Training loss: 2.062404155731201
Validation loss: 2.048967401186625

Epoch: 6| Step: 13
Training loss: 2.397322177886963
Validation loss: 2.060361921787262

Epoch: 150| Step: 0
Training loss: 1.8402605056762695
Validation loss: 2.0517868200937905

Epoch: 6| Step: 1
Training loss: 1.988146185874939
Validation loss: 2.0465656320254006

Epoch: 6| Step: 2
Training loss: 2.2294864654541016
Validation loss: 2.0479408899943032

Epoch: 6| Step: 3
Training loss: 1.9959611892700195
Validation loss: 2.050183653831482

Epoch: 6| Step: 4
Training loss: 2.16613507270813
Validation loss: 2.0558499693870544

Epoch: 6| Step: 5
Training loss: 1.4501549005508423
Validation loss: 2.0561692913373313

Epoch: 6| Step: 6
Training loss: 2.131403923034668
Validation loss: 2.060145457585653

Epoch: 6| Step: 7
Training loss: 2.0044589042663574
Validation loss: 2.054777503013611

Epoch: 6| Step: 8
Training loss: 2.070744037628174
Validation loss: 2.059069554011027

Epoch: 6| Step: 9
Training loss: 2.0945980548858643
Validation loss: 2.0461634596188865

Epoch: 6| Step: 10
Training loss: 2.7938051223754883
Validation loss: 2.0551495949427285

Epoch: 6| Step: 11
Training loss: 1.6466749906539917
Validation loss: 2.0693244338035583

Epoch: 6| Step: 12
Training loss: 1.9826741218566895
Validation loss: 2.0581743319829306

Epoch: 6| Step: 13
Training loss: 1.7514269351959229
Validation loss: 2.0518456300099692

Epoch: 151| Step: 0
Training loss: 1.8537542819976807
Validation loss: 2.048849562803904

Epoch: 6| Step: 1
Training loss: 1.9500514268875122
Validation loss: 2.044389267762502

Epoch: 6| Step: 2
Training loss: 1.8281784057617188
Validation loss: 2.037908057371775

Epoch: 6| Step: 3
Training loss: 1.9259873628616333
Validation loss: 2.0442990263303122

Epoch: 6| Step: 4
Training loss: 1.5967648029327393
Validation loss: 2.0490460197130838

Epoch: 6| Step: 5
Training loss: 1.9891436100006104
Validation loss: 2.0613693992296853

Epoch: 6| Step: 6
Training loss: 1.7941367626190186
Validation loss: 2.048731029033661

Epoch: 6| Step: 7
Training loss: 2.618305206298828
Validation loss: 2.0493249893188477

Epoch: 6| Step: 8
Training loss: 1.7921016216278076
Validation loss: 2.0635092854499817

Epoch: 6| Step: 9
Training loss: 2.2010815143585205
Validation loss: 2.064584493637085

Epoch: 6| Step: 10
Training loss: 2.01619815826416
Validation loss: 2.060628573099772

Epoch: 6| Step: 11
Training loss: 1.810295820236206
Validation loss: 2.0481844743092856

Epoch: 6| Step: 12
Training loss: 2.143670082092285
Validation loss: 2.0557141502698264

Epoch: 6| Step: 13
Training loss: 2.5932364463806152
Validation loss: 2.0483307242393494

Epoch: 152| Step: 0
Training loss: 1.762890338897705
Validation loss: 2.037939270337423

Epoch: 6| Step: 1
Training loss: 1.6276196241378784
Validation loss: 2.0469823678334556

Epoch: 6| Step: 2
Training loss: 2.1090455055236816
Validation loss: 2.043474634488424

Epoch: 6| Step: 3
Training loss: 1.735447883605957
Validation loss: 2.038803199927012

Epoch: 6| Step: 4
Training loss: 2.0672450065612793
Validation loss: 2.0447295109430947

Epoch: 6| Step: 5
Training loss: 2.6839311122894287
Validation loss: 2.0338077743848166

Epoch: 6| Step: 6
Training loss: 2.224198818206787
Validation loss: 2.0486863056818643

Epoch: 6| Step: 7
Training loss: 1.7761282920837402
Validation loss: 2.0551242431004844

Epoch: 6| Step: 8
Training loss: 2.295217990875244
Validation loss: 2.040700892607371

Epoch: 6| Step: 9
Training loss: 2.282376766204834
Validation loss: 2.048289696375529

Epoch: 6| Step: 10
Training loss: 2.0112431049346924
Validation loss: 2.036880075931549

Epoch: 6| Step: 11
Training loss: 2.0608839988708496
Validation loss: 2.0435500343640647

Epoch: 6| Step: 12
Training loss: 1.729578971862793
Validation loss: 2.0333229700724282

Epoch: 6| Step: 13
Training loss: 1.8778778314590454
Validation loss: 2.051161050796509

Epoch: 153| Step: 0
Training loss: 2.0689239501953125
Validation loss: 2.0504886309305825

Epoch: 6| Step: 1
Training loss: 1.9849239587783813
Validation loss: 2.0432843764623008

Epoch: 6| Step: 2
Training loss: 2.0459275245666504
Validation loss: 2.0429214040438333

Epoch: 6| Step: 3
Training loss: 1.9317723512649536
Validation loss: 2.0438785950342813

Epoch: 6| Step: 4
Training loss: 2.0130462646484375
Validation loss: 2.044982691605886

Epoch: 6| Step: 5
Training loss: 2.248633861541748
Validation loss: 2.041677395502726

Epoch: 6| Step: 6
Training loss: 1.9256997108459473
Validation loss: 2.047944446404775

Epoch: 6| Step: 7
Training loss: 1.6614506244659424
Validation loss: 2.0500135024388633

Epoch: 6| Step: 8
Training loss: 2.198373794555664
Validation loss: 2.0434412956237793

Epoch: 6| Step: 9
Training loss: 2.6029911041259766
Validation loss: 2.051365236441294

Epoch: 6| Step: 10
Training loss: 2.0265655517578125
Validation loss: 2.05269455909729

Epoch: 6| Step: 11
Training loss: 1.9462971687316895
Validation loss: 2.05367773771286

Epoch: 6| Step: 12
Training loss: 1.9416303634643555
Validation loss: 2.0562265117963157

Epoch: 6| Step: 13
Training loss: 2.1150240898132324
Validation loss: 2.0630714098612466

Epoch: 154| Step: 0
Training loss: 1.3157474994659424
Validation loss: 2.060887257258097

Epoch: 6| Step: 1
Training loss: 1.9434947967529297
Validation loss: 2.0798703034718833

Epoch: 6| Step: 2
Training loss: 1.587125301361084
Validation loss: 2.0857156912485757

Epoch: 6| Step: 3
Training loss: 1.9729597568511963
Validation loss: 2.097600261370341

Epoch: 6| Step: 4
Training loss: 1.5388669967651367
Validation loss: 2.0830169916152954

Epoch: 6| Step: 5
Training loss: 1.996147632598877
Validation loss: 2.089512288570404

Epoch: 6| Step: 6
Training loss: 1.7289907932281494
Validation loss: 2.0923657218615213

Epoch: 6| Step: 7
Training loss: 2.13520884513855
Validation loss: 2.077329715092977

Epoch: 6| Step: 8
Training loss: 2.562492847442627
Validation loss: 2.0654646952946982

Epoch: 6| Step: 9
Training loss: 2.1151037216186523
Validation loss: 2.0639591813087463

Epoch: 6| Step: 10
Training loss: 1.9954240322113037
Validation loss: 2.0604532758394876

Epoch: 6| Step: 11
Training loss: 2.435202121734619
Validation loss: 2.063014566898346

Epoch: 6| Step: 12
Training loss: 2.7911972999572754
Validation loss: 2.0694767435391745

Epoch: 6| Step: 13
Training loss: 1.935878038406372
Validation loss: 2.054056783517202

Epoch: 155| Step: 0
Training loss: 1.9921152591705322
Validation loss: 2.0568607250849404

Epoch: 6| Step: 1
Training loss: 2.496764659881592
Validation loss: 2.0521857738494873

Epoch: 6| Step: 2
Training loss: 1.7063477039337158
Validation loss: 2.063688417275747

Epoch: 6| Step: 3
Training loss: 1.7155929803848267
Validation loss: 2.066164255142212

Epoch: 6| Step: 4
Training loss: 2.608273983001709
Validation loss: 2.0599646170934043

Epoch: 6| Step: 5
Training loss: 1.8328497409820557
Validation loss: 2.0624410112698874

Epoch: 6| Step: 6
Training loss: 2.1687381267547607
Validation loss: 2.070707122484843

Epoch: 6| Step: 7
Training loss: 1.524465799331665
Validation loss: 2.055437425772349

Epoch: 6| Step: 8
Training loss: 2.241392135620117
Validation loss: 2.0578008890151978

Epoch: 6| Step: 9
Training loss: 1.805445671081543
Validation loss: 2.063575863838196

Epoch: 6| Step: 10
Training loss: 1.850027322769165
Validation loss: 2.0702855785687766

Epoch: 6| Step: 11
Training loss: 2.39857816696167
Validation loss: 2.0777732531229653

Epoch: 6| Step: 12
Training loss: 1.8312337398529053
Validation loss: 2.086225211620331

Epoch: 6| Step: 13
Training loss: 2.2482433319091797
Validation loss: 2.080249806245168

Epoch: 156| Step: 0
Training loss: 1.3924540281295776
Validation loss: 2.0668116410573325

Epoch: 6| Step: 1
Training loss: 2.224027156829834
Validation loss: 2.085611899693807

Epoch: 6| Step: 2
Training loss: 2.1624298095703125
Validation loss: 2.0790218114852905

Epoch: 6| Step: 3
Training loss: 2.2267677783966064
Validation loss: 2.0949012835820517

Epoch: 6| Step: 4
Training loss: 2.005044937133789
Validation loss: 2.0732789436976113

Epoch: 6| Step: 5
Training loss: 2.0097451210021973
Validation loss: 2.09158984820048

Epoch: 6| Step: 6
Training loss: 1.7862988710403442
Validation loss: 2.0874869426091514

Epoch: 6| Step: 7
Training loss: 1.9717457294464111
Validation loss: 2.089971343676249

Epoch: 6| Step: 8
Training loss: 2.102792978286743
Validation loss: 2.0718401273091636

Epoch: 6| Step: 9
Training loss: 1.911492109298706
Validation loss: 2.083564500013987

Epoch: 6| Step: 10
Training loss: 1.9693496227264404
Validation loss: 2.0784049232800803

Epoch: 6| Step: 11
Training loss: 1.6211497783660889
Validation loss: 2.0769317150115967

Epoch: 6| Step: 12
Training loss: 2.529710292816162
Validation loss: 2.0725941260655723

Epoch: 6| Step: 13
Training loss: 2.398972988128662
Validation loss: 2.0673651496569314

Epoch: 157| Step: 0
Training loss: 2.1937735080718994
Validation loss: 2.0598102807998657

Epoch: 6| Step: 1
Training loss: 2.4099068641662598
Validation loss: 2.0733652909596763

Epoch: 6| Step: 2
Training loss: 2.2844200134277344
Validation loss: 2.0696513652801514

Epoch: 6| Step: 3
Training loss: 1.9359016418457031
Validation loss: 2.0636426409085593

Epoch: 6| Step: 4
Training loss: 1.781978726387024
Validation loss: 2.0664052963256836

Epoch: 6| Step: 5
Training loss: 1.9209415912628174
Validation loss: 2.060475508371989

Epoch: 6| Step: 6
Training loss: 2.5200791358947754
Validation loss: 2.064783215522766

Epoch: 6| Step: 7
Training loss: 2.806978225708008
Validation loss: 2.0630775094032288

Epoch: 6| Step: 8
Training loss: 2.2181382179260254
Validation loss: 2.0546924670537314

Epoch: 6| Step: 9
Training loss: 1.5468615293502808
Validation loss: 2.054068903128306

Epoch: 6| Step: 10
Training loss: 1.7015742063522339
Validation loss: 2.061225195725759

Epoch: 6| Step: 11
Training loss: 1.5823017358779907
Validation loss: 2.046397864818573

Epoch: 6| Step: 12
Training loss: 1.492708444595337
Validation loss: 2.0689335068066916

Epoch: 6| Step: 13
Training loss: 2.0370514392852783
Validation loss: 2.067443231741587

Epoch: 158| Step: 0
Training loss: 2.0548059940338135
Validation loss: 2.0674510399500527

Epoch: 6| Step: 1
Training loss: 2.056596040725708
Validation loss: 2.076278289159139

Epoch: 6| Step: 2
Training loss: 2.6152260303497314
Validation loss: 2.0680582523345947

Epoch: 6| Step: 3
Training loss: 1.8617289066314697
Validation loss: 2.062386433283488

Epoch: 6| Step: 4
Training loss: 1.4257763624191284
Validation loss: 2.052068551381429

Epoch: 6| Step: 5
Training loss: 2.061495065689087
Validation loss: 2.0576650500297546

Epoch: 6| Step: 6
Training loss: 2.095428705215454
Validation loss: 2.04902317126592

Epoch: 6| Step: 7
Training loss: 2.0987346172332764
Validation loss: 2.0508214831352234

Epoch: 6| Step: 8
Training loss: 2.030817747116089
Validation loss: 2.053776224454244

Epoch: 6| Step: 9
Training loss: 2.0587360858917236
Validation loss: 2.0533194144566855

Epoch: 6| Step: 10
Training loss: 2.3202147483825684
Validation loss: 2.057305157184601

Epoch: 6| Step: 11
Training loss: 1.8211621046066284
Validation loss: 2.0569791197776794

Epoch: 6| Step: 12
Training loss: 2.1294426918029785
Validation loss: 2.069665253162384

Epoch: 6| Step: 13
Training loss: 1.8554900884628296
Validation loss: 2.0615707437197366

Epoch: 159| Step: 0
Training loss: 1.8220746517181396
Validation loss: 2.0577181776364646

Epoch: 6| Step: 1
Training loss: 2.2695553302764893
Validation loss: 2.074861248334249

Epoch: 6| Step: 2
Training loss: 2.0372772216796875
Validation loss: 2.067501664161682

Epoch: 6| Step: 3
Training loss: 2.1975901126861572
Validation loss: 2.06513520081838

Epoch: 6| Step: 4
Training loss: 2.4435386657714844
Validation loss: 2.08415279785792

Epoch: 6| Step: 5
Training loss: 2.2021474838256836
Validation loss: 2.084939499696096

Epoch: 6| Step: 6
Training loss: 1.4194833040237427
Validation loss: 2.093947490056356

Epoch: 6| Step: 7
Training loss: 1.8904293775558472
Validation loss: 2.065912206967672

Epoch: 6| Step: 8
Training loss: 1.8519116640090942
Validation loss: 2.0950690706570945

Epoch: 6| Step: 9
Training loss: 2.7027182579040527
Validation loss: 2.0881817738215127

Epoch: 6| Step: 10
Training loss: 2.078528642654419
Validation loss: 2.0918984611829123

Epoch: 6| Step: 11
Training loss: 1.6094526052474976
Validation loss: 2.0883435805638633

Epoch: 6| Step: 12
Training loss: 1.7324516773223877
Validation loss: 2.080101033051809

Epoch: 6| Step: 13
Training loss: 1.7700393199920654
Validation loss: 2.079526881376902

Epoch: 160| Step: 0
Training loss: 1.852086067199707
Validation loss: 2.086373209953308

Epoch: 6| Step: 1
Training loss: 1.9531164169311523
Validation loss: 2.068966786066691

Epoch: 6| Step: 2
Training loss: 2.181206703186035
Validation loss: 2.0794142285982766

Epoch: 6| Step: 3
Training loss: 1.9624385833740234
Validation loss: 2.080057760079702

Epoch: 6| Step: 4
Training loss: 1.9234938621520996
Validation loss: 2.0724653601646423

Epoch: 6| Step: 5
Training loss: 2.3873491287231445
Validation loss: 2.0728192130724588

Epoch: 6| Step: 6
Training loss: 1.897892951965332
Validation loss: 2.079310397307078

Epoch: 6| Step: 7
Training loss: 2.0147197246551514
Validation loss: 2.0945249597231546

Epoch: 6| Step: 8
Training loss: 1.9452685117721558
Validation loss: 2.0899407068888345

Epoch: 6| Step: 9
Training loss: 1.4703503847122192
Validation loss: 2.0894153316815696

Epoch: 6| Step: 10
Training loss: 2.062232494354248
Validation loss: 2.0881481965382895

Epoch: 6| Step: 11
Training loss: 2.134890079498291
Validation loss: 2.0642942587534585

Epoch: 6| Step: 12
Training loss: 1.8554792404174805
Validation loss: 2.077645421028137

Epoch: 6| Step: 13
Training loss: 2.114434242248535
Validation loss: 2.079859455426534

Epoch: 161| Step: 0
Training loss: 2.609954595565796
Validation loss: 2.085812211036682

Epoch: 6| Step: 1
Training loss: 1.3410584926605225
Validation loss: 2.0740304589271545

Epoch: 6| Step: 2
Training loss: 1.6511098146438599
Validation loss: 2.0904411673545837

Epoch: 6| Step: 3
Training loss: 1.918570876121521
Validation loss: 2.0613497296969094

Epoch: 6| Step: 4
Training loss: 2.3948259353637695
Validation loss: 2.0747647682825723

Epoch: 6| Step: 5
Training loss: 1.2929507493972778
Validation loss: 2.0589574376742044

Epoch: 6| Step: 6
Training loss: 2.3699262142181396
Validation loss: 2.060336252053579

Epoch: 6| Step: 7
Training loss: 1.8598055839538574
Validation loss: 2.0569433768590293

Epoch: 6| Step: 8
Training loss: 1.9801946878433228
Validation loss: 2.0591230193773904

Epoch: 6| Step: 9
Training loss: 1.8869885206222534
Validation loss: 2.047806759675344

Epoch: 6| Step: 10
Training loss: 2.039820671081543
Validation loss: 2.0528899828592935

Epoch: 6| Step: 11
Training loss: 1.824930191040039
Validation loss: 2.0501754681269326

Epoch: 6| Step: 12
Training loss: 2.337165355682373
Validation loss: 2.040993650754293

Epoch: 6| Step: 13
Training loss: 2.912003993988037
Validation loss: 2.045913358529409

Epoch: 162| Step: 0
Training loss: 2.036703586578369
Validation loss: 2.0467610955238342

Epoch: 6| Step: 1
Training loss: 2.4172935485839844
Validation loss: 2.0581324299176535

Epoch: 6| Step: 2
Training loss: 2.55763840675354
Validation loss: 2.062418818473816

Epoch: 6| Step: 3
Training loss: 1.779521107673645
Validation loss: 2.0654999017715454

Epoch: 6| Step: 4
Training loss: 2.017143964767456
Validation loss: 2.0590862035751343

Epoch: 6| Step: 5
Training loss: 1.9219053983688354
Validation loss: 2.0741882721583047

Epoch: 6| Step: 6
Training loss: 1.369484543800354
Validation loss: 2.072500546773275

Epoch: 6| Step: 7
Training loss: 2.0678551197052
Validation loss: 2.082250734170278

Epoch: 6| Step: 8
Training loss: 2.458618640899658
Validation loss: 2.071178615093231

Epoch: 6| Step: 9
Training loss: 2.1389007568359375
Validation loss: 2.09446789820989

Epoch: 6| Step: 10
Training loss: 1.7306232452392578
Validation loss: 2.093623638153076

Epoch: 6| Step: 11
Training loss: 2.423591136932373
Validation loss: 2.0943719347318015

Epoch: 6| Step: 12
Training loss: 1.7902523279190063
Validation loss: 2.0888622999191284

Epoch: 6| Step: 13
Training loss: 1.8798249959945679
Validation loss: 2.0921189188957214

Epoch: 163| Step: 0
Training loss: 2.223884105682373
Validation loss: 2.088040371735891

Epoch: 6| Step: 1
Training loss: 2.022087812423706
Validation loss: 2.066131830215454

Epoch: 6| Step: 2
Training loss: 2.373281478881836
Validation loss: 2.081402897834778

Epoch: 6| Step: 3
Training loss: 1.4886047840118408
Validation loss: 2.084605554739634

Epoch: 6| Step: 4
Training loss: 1.8967466354370117
Validation loss: 2.0796568791071572

Epoch: 6| Step: 5
Training loss: 1.6541500091552734
Validation loss: 2.0806241631507874

Epoch: 6| Step: 6
Training loss: 1.9353766441345215
Validation loss: 2.0900864601135254

Epoch: 6| Step: 7
Training loss: 2.2806687355041504
Validation loss: 2.0874555706977844

Epoch: 6| Step: 8
Training loss: 1.6808537244796753
Validation loss: 2.0892927845319114

Epoch: 6| Step: 9
Training loss: 1.6342101097106934
Validation loss: 2.1041420896848044

Epoch: 6| Step: 10
Training loss: 3.0617499351501465
Validation loss: 2.120970924695333

Epoch: 6| Step: 11
Training loss: 2.429023504257202
Validation loss: 2.129452129205068

Epoch: 6| Step: 12
Training loss: 2.5125904083251953
Validation loss: 2.1103664437929788

Epoch: 6| Step: 13
Training loss: 1.1415334939956665
Validation loss: 2.119247853755951

Epoch: 164| Step: 0
Training loss: 1.771493673324585
Validation loss: 2.12099281946818

Epoch: 6| Step: 1
Training loss: 2.2149264812469482
Validation loss: 2.1106570959091187

Epoch: 6| Step: 2
Training loss: 2.228346824645996
Validation loss: 2.0925825039545694

Epoch: 6| Step: 3
Training loss: 2.050520181655884
Validation loss: 2.075487414995829

Epoch: 6| Step: 4
Training loss: 1.5972493886947632
Validation loss: 2.0767184694608054

Epoch: 6| Step: 5
Training loss: 2.1457901000976562
Validation loss: 2.0664265354474387

Epoch: 6| Step: 6
Training loss: 1.7008250951766968
Validation loss: 2.0551308592160544

Epoch: 6| Step: 7
Training loss: 2.055718183517456
Validation loss: 2.0486290057500205

Epoch: 6| Step: 8
Training loss: 2.0664620399475098
Validation loss: 2.0425851146380105

Epoch: 6| Step: 9
Training loss: 2.310027599334717
Validation loss: 2.0355266332626343

Epoch: 6| Step: 10
Training loss: 2.050097942352295
Validation loss: 2.039814293384552

Epoch: 6| Step: 11
Training loss: 1.5775219202041626
Validation loss: 2.0646678805351257

Epoch: 6| Step: 12
Training loss: 2.433366298675537
Validation loss: 2.051892896493276

Epoch: 6| Step: 13
Training loss: 2.2719297409057617
Validation loss: 2.07207328081131

Epoch: 165| Step: 0
Training loss: 2.2041149139404297
Validation loss: 2.066898306210836

Epoch: 6| Step: 1
Training loss: 2.0808653831481934
Validation loss: 2.0676421324412027

Epoch: 6| Step: 2
Training loss: 2.066593885421753
Validation loss: 2.0658163825670877

Epoch: 6| Step: 3
Training loss: 2.2980103492736816
Validation loss: 2.05503257115682

Epoch: 6| Step: 4
Training loss: 1.7811756134033203
Validation loss: 2.073109984397888

Epoch: 6| Step: 5
Training loss: 2.418034553527832
Validation loss: 2.0770575801531472

Epoch: 6| Step: 6
Training loss: 1.6575696468353271
Validation loss: 2.071083128452301

Epoch: 6| Step: 7
Training loss: 2.296091318130493
Validation loss: 2.0728477438290915

Epoch: 6| Step: 8
Training loss: 2.205857276916504
Validation loss: 2.07864503065745

Epoch: 6| Step: 9
Training loss: 1.6434897184371948
Validation loss: 2.0696470141410828

Epoch: 6| Step: 10
Training loss: 1.1423803567886353
Validation loss: 2.0793693463007608

Epoch: 6| Step: 11
Training loss: 2.436245918273926
Validation loss: 2.0874192118644714

Epoch: 6| Step: 12
Training loss: 2.0496420860290527
Validation loss: 2.0854833920796714

Epoch: 6| Step: 13
Training loss: 1.8016902208328247
Validation loss: 2.077789545059204

Epoch: 166| Step: 0
Training loss: 2.512551784515381
Validation loss: 2.0872839093208313

Epoch: 6| Step: 1
Training loss: 1.7840543985366821
Validation loss: 2.0823185046513877

Epoch: 6| Step: 2
Training loss: 2.4108986854553223
Validation loss: 2.093574663003286

Epoch: 6| Step: 3
Training loss: 2.373229503631592
Validation loss: 2.0998098055521646

Epoch: 6| Step: 4
Training loss: 1.7020556926727295
Validation loss: 2.08535373210907

Epoch: 6| Step: 5
Training loss: 1.8694005012512207
Validation loss: 2.0937231381734214

Epoch: 6| Step: 6
Training loss: 2.053088426589966
Validation loss: 2.0954330364863076

Epoch: 6| Step: 7
Training loss: 2.247990369796753
Validation loss: 2.106644550959269

Epoch: 6| Step: 8
Training loss: 1.642284870147705
Validation loss: 2.104704042275747

Epoch: 6| Step: 9
Training loss: 2.231161117553711
Validation loss: 2.11101363102595

Epoch: 6| Step: 10
Training loss: 1.8025646209716797
Validation loss: 2.091555178165436

Epoch: 6| Step: 11
Training loss: 1.5675634145736694
Validation loss: 2.112600247065226

Epoch: 6| Step: 12
Training loss: 1.8762454986572266
Validation loss: 2.079303741455078

Epoch: 6| Step: 13
Training loss: 1.9474090337753296
Validation loss: 2.0830573638280234

Epoch: 167| Step: 0
Training loss: 1.9304014444351196
Validation loss: 2.083480636278788

Epoch: 6| Step: 1
Training loss: 1.9722744226455688
Validation loss: 2.092073639233907

Epoch: 6| Step: 2
Training loss: 2.3338229656219482
Validation loss: 2.0864724119504294

Epoch: 6| Step: 3
Training loss: 1.938234806060791
Validation loss: 2.0936467250188193

Epoch: 6| Step: 4
Training loss: 1.5913126468658447
Validation loss: 2.091901501019796

Epoch: 6| Step: 5
Training loss: 1.4353556632995605
Validation loss: 2.0806660254796348

Epoch: 6| Step: 6
Training loss: 2.2518818378448486
Validation loss: 2.0910946329434714

Epoch: 6| Step: 7
Training loss: 1.9474905729293823
Validation loss: 2.0826817552248635

Epoch: 6| Step: 8
Training loss: 2.2659220695495605
Validation loss: 2.0743046402931213

Epoch: 6| Step: 9
Training loss: 2.6230831146240234
Validation loss: 2.08609531323115

Epoch: 6| Step: 10
Training loss: 2.0724973678588867
Validation loss: 2.0769837299982705

Epoch: 6| Step: 11
Training loss: 2.4115962982177734
Validation loss: 2.077297488848368

Epoch: 6| Step: 12
Training loss: 1.6685720682144165
Validation loss: 2.072466333707174

Epoch: 6| Step: 13
Training loss: 1.6535199880599976
Validation loss: 2.069567004839579

Epoch: 168| Step: 0
Training loss: 1.7684520483016968
Validation loss: 2.0713815490404763

Epoch: 6| Step: 1
Training loss: 1.8716967105865479
Validation loss: 2.071273704369863

Epoch: 6| Step: 2
Training loss: 2.4457221031188965
Validation loss: 2.0687254667282104

Epoch: 6| Step: 3
Training loss: 1.7120845317840576
Validation loss: 2.0677380561828613

Epoch: 6| Step: 4
Training loss: 1.5446630716323853
Validation loss: 2.0620054999987283

Epoch: 6| Step: 5
Training loss: 1.8788530826568604
Validation loss: 2.094202776749929

Epoch: 6| Step: 6
Training loss: 2.2055323123931885
Validation loss: 2.087679922580719

Epoch: 6| Step: 7
Training loss: 2.1197123527526855
Validation loss: 2.100318173567454

Epoch: 6| Step: 8
Training loss: 1.5858242511749268
Validation loss: 2.0998446146647134

Epoch: 6| Step: 9
Training loss: 2.261528491973877
Validation loss: 2.0771127144495645

Epoch: 6| Step: 10
Training loss: 2.4234724044799805
Validation loss: 2.088743050893148

Epoch: 6| Step: 11
Training loss: 1.7582433223724365
Validation loss: 2.111420830090841

Epoch: 6| Step: 12
Training loss: 2.297257423400879
Validation loss: 2.103292246659597

Epoch: 6| Step: 13
Training loss: 1.9737789630889893
Validation loss: 2.10029137134552

Epoch: 169| Step: 0
Training loss: 2.3644278049468994
Validation loss: 2.0984708666801453

Epoch: 6| Step: 1
Training loss: 2.4286694526672363
Validation loss: 2.1041795015335083

Epoch: 6| Step: 2
Training loss: 2.4518914222717285
Validation loss: 2.097259839375814

Epoch: 6| Step: 3
Training loss: 2.541736602783203
Validation loss: 2.0965673128763833

Epoch: 6| Step: 4
Training loss: 1.5313103199005127
Validation loss: 2.0951825380325317

Epoch: 6| Step: 5
Training loss: 1.5526944398880005
Validation loss: 2.1072770158449807

Epoch: 6| Step: 6
Training loss: 1.6252079010009766
Validation loss: 2.1106835206349692

Epoch: 6| Step: 7
Training loss: 1.8342024087905884
Validation loss: 2.0978699723879495

Epoch: 6| Step: 8
Training loss: 1.5635265111923218
Validation loss: 2.10874209801356

Epoch: 6| Step: 9
Training loss: 2.4226317405700684
Validation loss: 2.103542228539785

Epoch: 6| Step: 10
Training loss: 2.1474928855895996
Validation loss: 2.1109694043795266

Epoch: 6| Step: 11
Training loss: 1.701113224029541
Validation loss: 2.131094833215078

Epoch: 6| Step: 12
Training loss: 1.6696648597717285
Validation loss: 2.139982581138611

Epoch: 6| Step: 13
Training loss: 1.9314091205596924
Validation loss: 2.1359007159868875

Epoch: 170| Step: 0
Training loss: 2.195786714553833
Validation loss: 2.1338127056757608

Epoch: 6| Step: 1
Training loss: 1.6985952854156494
Validation loss: 2.1490476926167807

Epoch: 6| Step: 2
Training loss: 2.3406453132629395
Validation loss: 2.1496933698654175

Epoch: 6| Step: 3
Training loss: 1.8938179016113281
Validation loss: 2.1408872604370117

Epoch: 6| Step: 4
Training loss: 1.537607192993164
Validation loss: 2.1234413981437683

Epoch: 6| Step: 5
Training loss: 2.404697895050049
Validation loss: 2.1260698239008584

Epoch: 6| Step: 6
Training loss: 2.3675501346588135
Validation loss: 2.1094773411750793

Epoch: 6| Step: 7
Training loss: 2.243227005004883
Validation loss: 2.114425619443258

Epoch: 6| Step: 8
Training loss: 2.9648337364196777
Validation loss: 2.0883201559384665

Epoch: 6| Step: 9
Training loss: 1.3348546028137207
Validation loss: 2.088240166505178

Epoch: 6| Step: 10
Training loss: 1.8238904476165771
Validation loss: 2.069970726966858

Epoch: 6| Step: 11
Training loss: 1.89523184299469
Validation loss: 2.059265395005544

Epoch: 6| Step: 12
Training loss: 1.872101068496704
Validation loss: 2.0616693695386252

Epoch: 6| Step: 13
Training loss: 2.164172649383545
Validation loss: 2.0612696607907615

Epoch: 171| Step: 0
Training loss: 1.927966833114624
Validation loss: 2.0561365286509194

Epoch: 6| Step: 1
Training loss: 1.949027419090271
Validation loss: 2.0619066754976907

Epoch: 6| Step: 2
Training loss: 1.438481330871582
Validation loss: 2.0556798775990806

Epoch: 6| Step: 3
Training loss: 2.124202251434326
Validation loss: 2.05467156569163

Epoch: 6| Step: 4
Training loss: 1.5462090969085693
Validation loss: 2.067707041899363

Epoch: 6| Step: 5
Training loss: 2.0385262966156006
Validation loss: 2.052631219228109

Epoch: 6| Step: 6
Training loss: 2.006883144378662
Validation loss: 2.049012839794159

Epoch: 6| Step: 7
Training loss: 2.5129635334014893
Validation loss: 2.0665565729141235

Epoch: 6| Step: 8
Training loss: 1.9258604049682617
Validation loss: 2.072335402170817

Epoch: 6| Step: 9
Training loss: 2.397031307220459
Validation loss: 2.0611249208450317

Epoch: 6| Step: 10
Training loss: 2.037668466567993
Validation loss: 2.074371854464213

Epoch: 6| Step: 11
Training loss: 2.4213404655456543
Validation loss: 2.0756071408589682

Epoch: 6| Step: 12
Training loss: 2.3267483711242676
Validation loss: 2.083371877670288

Epoch: 6| Step: 13
Training loss: 1.5665035247802734
Validation loss: 2.0890825589497886

Epoch: 172| Step: 0
Training loss: 1.712040662765503
Validation loss: 2.089170197645823

Epoch: 6| Step: 1
Training loss: 2.006439447402954
Validation loss: 2.0817946592966714

Epoch: 6| Step: 2
Training loss: 1.825045108795166
Validation loss: 2.084465185801188

Epoch: 6| Step: 3
Training loss: 2.5456645488739014
Validation loss: 2.0840662121772766

Epoch: 6| Step: 4
Training loss: 1.8116612434387207
Validation loss: 2.0842405756314597

Epoch: 6| Step: 5
Training loss: 1.7151044607162476
Validation loss: 2.094228903452555

Epoch: 6| Step: 6
Training loss: 2.2746596336364746
Validation loss: 2.0993465582529702

Epoch: 6| Step: 7
Training loss: 1.866477131843567
Validation loss: 2.1036787629127502

Epoch: 6| Step: 8
Training loss: 1.4368921518325806
Validation loss: 2.096829831600189

Epoch: 6| Step: 9
Training loss: 2.6821956634521484
Validation loss: 2.1004572113355002

Epoch: 6| Step: 10
Training loss: 2.458167314529419
Validation loss: 2.09258896112442

Epoch: 6| Step: 11
Training loss: 1.6332898139953613
Validation loss: 2.0871897538503013

Epoch: 6| Step: 12
Training loss: 1.8862168788909912
Validation loss: 2.0893513758977256

Epoch: 6| Step: 13
Training loss: 2.08954119682312
Validation loss: 2.0899812380472818

Epoch: 173| Step: 0
Training loss: 1.931321620941162
Validation loss: 2.092748522758484

Epoch: 6| Step: 1
Training loss: 2.4766829013824463
Validation loss: 2.087096850077311

Epoch: 6| Step: 2
Training loss: 1.9113706350326538
Validation loss: 2.117716391881307

Epoch: 6| Step: 3
Training loss: 2.3183770179748535
Validation loss: 2.1022532184918723

Epoch: 6| Step: 4
Training loss: 1.2244936227798462
Validation loss: 2.098884344100952

Epoch: 6| Step: 5
Training loss: 2.2936081886291504
Validation loss: 2.1061063210169473

Epoch: 6| Step: 6
Training loss: 1.7016866207122803
Validation loss: 2.1117517352104187

Epoch: 6| Step: 7
Training loss: 1.8552062511444092
Validation loss: 2.111086587111155

Epoch: 6| Step: 8
Training loss: 1.842881679534912
Validation loss: 2.1231326858202615

Epoch: 6| Step: 9
Training loss: 2.3178820610046387
Validation loss: 2.115680535634359

Epoch: 6| Step: 10
Training loss: 1.7121459245681763
Validation loss: 2.105927069981893

Epoch: 6| Step: 11
Training loss: 2.2737724781036377
Validation loss: 2.109589417775472

Epoch: 6| Step: 12
Training loss: 2.0282747745513916
Validation loss: 2.1037159164746604

Epoch: 6| Step: 13
Training loss: 1.77742338180542
Validation loss: 2.0836700995763144

Epoch: 174| Step: 0
Training loss: 2.04007625579834
Validation loss: 2.087221165498098

Epoch: 6| Step: 1
Training loss: 2.4055938720703125
Validation loss: 2.0810123085975647

Epoch: 6| Step: 2
Training loss: 2.1374943256378174
Validation loss: 2.07513835032781

Epoch: 6| Step: 3
Training loss: 2.291292190551758
Validation loss: 2.0668514172236123

Epoch: 6| Step: 4
Training loss: 1.5598934888839722
Validation loss: 2.060478091239929

Epoch: 6| Step: 5
Training loss: 1.7873460054397583
Validation loss: 2.073787530263265

Epoch: 6| Step: 6
Training loss: 1.8664648532867432
Validation loss: 2.071810523668925

Epoch: 6| Step: 7
Training loss: 2.3865723609924316
Validation loss: 2.085054079691569

Epoch: 6| Step: 8
Training loss: 2.1909828186035156
Validation loss: 2.0875805815060935

Epoch: 6| Step: 9
Training loss: 2.0317318439483643
Validation loss: 2.0712024172147117

Epoch: 6| Step: 10
Training loss: 1.8694541454315186
Validation loss: 2.080708622932434

Epoch: 6| Step: 11
Training loss: 1.9826844930648804
Validation loss: 2.0925934513409934

Epoch: 6| Step: 12
Training loss: 1.1024184226989746
Validation loss: 2.0822821259498596

Epoch: 6| Step: 13
Training loss: 2.1765682697296143
Validation loss: 2.0729974706967673

Epoch: 175| Step: 0
Training loss: 2.626148223876953
Validation loss: 2.0767112572987876

Epoch: 6| Step: 1
Training loss: 1.6442780494689941
Validation loss: 2.075600485006968

Epoch: 6| Step: 2
Training loss: 2.403097152709961
Validation loss: 2.0626824299494424

Epoch: 6| Step: 3
Training loss: 2.1089015007019043
Validation loss: 2.0804316798845925

Epoch: 6| Step: 4
Training loss: 2.0390682220458984
Validation loss: 2.076533794403076

Epoch: 6| Step: 5
Training loss: 1.954239845275879
Validation loss: 2.0677011211713157

Epoch: 6| Step: 6
Training loss: 1.5173834562301636
Validation loss: 2.0724488894144693

Epoch: 6| Step: 7
Training loss: 2.287112236022949
Validation loss: 2.072518209616343

Epoch: 6| Step: 8
Training loss: 1.469496726989746
Validation loss: 2.074781914552053

Epoch: 6| Step: 9
Training loss: 1.9341793060302734
Validation loss: 2.068558613459269

Epoch: 6| Step: 10
Training loss: 1.9919456243515015
Validation loss: 2.057337542374929

Epoch: 6| Step: 11
Training loss: 2.054964542388916
Validation loss: 2.0588011940320334

Epoch: 6| Step: 12
Training loss: 2.363546371459961
Validation loss: 2.061245024204254

Epoch: 6| Step: 13
Training loss: 1.8436357975006104
Validation loss: 2.0580825805664062

Epoch: 176| Step: 0
Training loss: 1.9084573984146118
Validation loss: 2.073401629924774

Epoch: 6| Step: 1
Training loss: 2.2532434463500977
Validation loss: 2.071024775505066

Epoch: 6| Step: 2
Training loss: 1.8911328315734863
Validation loss: 2.058590888977051

Epoch: 6| Step: 3
Training loss: 1.6901453733444214
Validation loss: 2.064302364985148

Epoch: 6| Step: 4
Training loss: 1.9130055904388428
Validation loss: 2.0739441315333047

Epoch: 6| Step: 5
Training loss: 2.1443233489990234
Validation loss: 2.0776667396227517

Epoch: 6| Step: 6
Training loss: 1.8135769367218018
Validation loss: 2.0872660279273987

Epoch: 6| Step: 7
Training loss: 1.5346925258636475
Validation loss: 2.0939644972483316

Epoch: 6| Step: 8
Training loss: 2.5395538806915283
Validation loss: 2.096291244029999

Epoch: 6| Step: 9
Training loss: 1.9357905387878418
Validation loss: 2.1059247652689614

Epoch: 6| Step: 10
Training loss: 1.5980620384216309
Validation loss: 2.110640287399292

Epoch: 6| Step: 11
Training loss: 2.1558752059936523
Validation loss: 2.1057960589726767

Epoch: 6| Step: 12
Training loss: 2.2698974609375
Validation loss: 2.1013709902763367

Epoch: 6| Step: 13
Training loss: 1.8644851446151733
Validation loss: 2.1046451727549234

Epoch: 177| Step: 0
Training loss: 2.810605049133301
Validation loss: 2.098405043284098

Epoch: 6| Step: 1
Training loss: 1.872314214706421
Validation loss: 2.081060528755188

Epoch: 6| Step: 2
Training loss: 1.3610239028930664
Validation loss: 2.0942704478899636

Epoch: 6| Step: 3
Training loss: 2.055485725402832
Validation loss: 2.1015703678131104

Epoch: 6| Step: 4
Training loss: 2.0207955837249756
Validation loss: 2.1069098711013794

Epoch: 6| Step: 5
Training loss: 1.9306775331497192
Validation loss: 2.112242817878723

Epoch: 6| Step: 6
Training loss: 1.831312894821167
Validation loss: 2.092984199523926

Epoch: 6| Step: 7
Training loss: 2.2744054794311523
Validation loss: 2.0798179308573403

Epoch: 6| Step: 8
Training loss: 2.115975856781006
Validation loss: 2.095532317956289

Epoch: 6| Step: 9
Training loss: 2.3729372024536133
Validation loss: 2.0841697454452515

Epoch: 6| Step: 10
Training loss: 1.821800947189331
Validation loss: 2.0789133509000144

Epoch: 6| Step: 11
Training loss: 1.466109275817871
Validation loss: 2.0699374874432883

Epoch: 6| Step: 12
Training loss: 1.9555613994598389
Validation loss: 2.079469402631124

Epoch: 6| Step: 13
Training loss: 1.828789472579956
Validation loss: 2.0711057583491006

Epoch: 178| Step: 0
Training loss: 2.4266695976257324
Validation loss: 2.0715009768803916

Epoch: 6| Step: 1
Training loss: 2.462470531463623
Validation loss: 2.073146959145864

Epoch: 6| Step: 2
Training loss: 2.050124168395996
Validation loss: 2.0709829330444336

Epoch: 6| Step: 3
Training loss: 1.9089336395263672
Validation loss: 2.068336526552836

Epoch: 6| Step: 4
Training loss: 2.181394577026367
Validation loss: 2.0743364890416465

Epoch: 6| Step: 5
Training loss: 1.5964412689208984
Validation loss: 2.07240883509318

Epoch: 6| Step: 6
Training loss: 1.6157065629959106
Validation loss: 2.0797473788261414

Epoch: 6| Step: 7
Training loss: 1.4722187519073486
Validation loss: 2.0869929989178977

Epoch: 6| Step: 8
Training loss: 2.334357261657715
Validation loss: 2.0990396539370217

Epoch: 6| Step: 9
Training loss: 1.768076777458191
Validation loss: 2.084851324558258

Epoch: 6| Step: 10
Training loss: 2.1443095207214355
Validation loss: 2.089746594429016

Epoch: 6| Step: 11
Training loss: 2.1042561531066895
Validation loss: 2.086138586203257

Epoch: 6| Step: 12
Training loss: 1.988038182258606
Validation loss: 2.0896993478139243

Epoch: 6| Step: 13
Training loss: 2.383406639099121
Validation loss: 2.090864439805349

Epoch: 179| Step: 0
Training loss: 2.0307772159576416
Validation loss: 2.07586540778478

Epoch: 6| Step: 1
Training loss: 2.456162929534912
Validation loss: 2.079836924870809

Epoch: 6| Step: 2
Training loss: 1.935177206993103
Validation loss: 2.098229467868805

Epoch: 6| Step: 3
Training loss: 1.3842073678970337
Validation loss: 2.094402631123861

Epoch: 6| Step: 4
Training loss: 2.753753185272217
Validation loss: 2.0955072045326233

Epoch: 6| Step: 5
Training loss: 1.1761876344680786
Validation loss: 2.0950958331425986

Epoch: 6| Step: 6
Training loss: 2.297921657562256
Validation loss: 2.0858176946640015

Epoch: 6| Step: 7
Training loss: 1.7120471000671387
Validation loss: 2.0755028327306113

Epoch: 6| Step: 8
Training loss: 2.3076534271240234
Validation loss: 2.0796493887901306

Epoch: 6| Step: 9
Training loss: 1.8693795204162598
Validation loss: 2.0625383257865906

Epoch: 6| Step: 10
Training loss: 1.9246525764465332
Validation loss: 2.071492552757263

Epoch: 6| Step: 11
Training loss: 2.417064905166626
Validation loss: 2.064870079358419

Epoch: 6| Step: 12
Training loss: 1.883310079574585
Validation loss: 2.0699711243311563

Epoch: 6| Step: 13
Training loss: 1.999480128288269
Validation loss: 2.080275376637777

Epoch: 180| Step: 0
Training loss: 1.82058846950531
Validation loss: 2.085808753967285

Epoch: 6| Step: 1
Training loss: 1.5772979259490967
Validation loss: 2.0875051418940225

Epoch: 6| Step: 2
Training loss: 1.7208843231201172
Validation loss: 2.0841113527615867

Epoch: 6| Step: 3
Training loss: 1.5409317016601562
Validation loss: 2.100633203983307

Epoch: 6| Step: 4
Training loss: 2.4993391036987305
Validation loss: 2.1038455168406167

Epoch: 6| Step: 5
Training loss: 1.7779607772827148
Validation loss: 2.1115241050720215

Epoch: 6| Step: 6
Training loss: 1.6983962059020996
Validation loss: 2.115881641705831

Epoch: 6| Step: 7
Training loss: 1.9001867771148682
Validation loss: 2.109499136606852

Epoch: 6| Step: 8
Training loss: 1.4667888879776
Validation loss: 2.1034337679545083

Epoch: 6| Step: 9
Training loss: 2.3777456283569336
Validation loss: 2.09544305006663

Epoch: 6| Step: 10
Training loss: 2.6718039512634277
Validation loss: 2.0965486566225686

Epoch: 6| Step: 11
Training loss: 2.3976340293884277
Validation loss: 2.0940082470575967

Epoch: 6| Step: 12
Training loss: 2.615415096282959
Validation loss: 2.099294642607371

Epoch: 6| Step: 13
Training loss: 1.693976640701294
Validation loss: 2.100836535294851

Epoch: 181| Step: 0
Training loss: 1.4579194784164429
Validation loss: 2.1038625041643777

Epoch: 6| Step: 1
Training loss: 2.2143373489379883
Validation loss: 2.091369907061259

Epoch: 6| Step: 2
Training loss: 2.339073657989502
Validation loss: 2.0938499768575034

Epoch: 6| Step: 3
Training loss: 1.3373284339904785
Validation loss: 2.0898218750953674

Epoch: 6| Step: 4
Training loss: 1.776917815208435
Validation loss: 2.089849293231964

Epoch: 6| Step: 5
Training loss: 2.2066807746887207
Validation loss: 2.0832895040512085

Epoch: 6| Step: 6
Training loss: 2.2153396606445312
Validation loss: 2.0936118761698403

Epoch: 6| Step: 7
Training loss: 1.8868588209152222
Validation loss: 2.0892730752627053

Epoch: 6| Step: 8
Training loss: 2.4096503257751465
Validation loss: 2.083592673142751

Epoch: 6| Step: 9
Training loss: 2.068701982498169
Validation loss: 2.086984177430471

Epoch: 6| Step: 10
Training loss: 1.8392170667648315
Validation loss: 2.085647781689962

Epoch: 6| Step: 11
Training loss: 2.0200111865997314
Validation loss: 2.0857917070388794

Epoch: 6| Step: 12
Training loss: 2.5389609336853027
Validation loss: 2.078206797440847

Epoch: 6| Step: 13
Training loss: 1.4287055730819702
Validation loss: 2.084241588910421

Epoch: 182| Step: 0
Training loss: 1.897303581237793
Validation loss: 2.0878199140230813

Epoch: 6| Step: 1
Training loss: 1.9244611263275146
Validation loss: 2.08506445089976

Epoch: 6| Step: 2
Training loss: 1.8157401084899902
Validation loss: 2.0960237185160318

Epoch: 6| Step: 3
Training loss: 2.053100109100342
Validation loss: 2.093531390031179

Epoch: 6| Step: 4
Training loss: 2.007007122039795
Validation loss: 2.0954872767130532

Epoch: 6| Step: 5
Training loss: 1.8463540077209473
Validation loss: 2.1021931568781533

Epoch: 6| Step: 6
Training loss: 1.352692723274231
Validation loss: 2.099103013674418

Epoch: 6| Step: 7
Training loss: 2.284193992614746
Validation loss: 2.1103209257125854

Epoch: 6| Step: 8
Training loss: 1.7891782522201538
Validation loss: 2.1218029061953225

Epoch: 6| Step: 9
Training loss: 1.6952260732650757
Validation loss: 2.13197253147761

Epoch: 6| Step: 10
Training loss: 1.6108084917068481
Validation loss: 2.1287730932235718

Epoch: 6| Step: 11
Training loss: 2.7234699726104736
Validation loss: 2.1371033787727356

Epoch: 6| Step: 12
Training loss: 2.2457187175750732
Validation loss: 2.1077202955881753

Epoch: 6| Step: 13
Training loss: 2.2931220531463623
Validation loss: 2.1224852204322815

Epoch: 183| Step: 0
Training loss: 1.732480525970459
Validation loss: 2.117237170537313

Epoch: 6| Step: 1
Training loss: 1.9875755310058594
Validation loss: 2.110128482182821

Epoch: 6| Step: 2
Training loss: 1.8659268617630005
Validation loss: 2.112118422985077

Epoch: 6| Step: 3
Training loss: 1.6659414768218994
Validation loss: 2.098051826159159

Epoch: 6| Step: 4
Training loss: 2.251146078109741
Validation loss: 2.096430321534475

Epoch: 6| Step: 5
Training loss: 2.0516862869262695
Validation loss: 2.0954381028811135

Epoch: 6| Step: 6
Training loss: 1.6804834604263306
Validation loss: 2.099127153555552

Epoch: 6| Step: 7
Training loss: 2.4474315643310547
Validation loss: 2.0986098448435464

Epoch: 6| Step: 8
Training loss: 2.119065046310425
Validation loss: 2.080498973528544

Epoch: 6| Step: 9
Training loss: 1.439988613128662
Validation loss: 2.08277020851771

Epoch: 6| Step: 10
Training loss: 1.9372538328170776
Validation loss: 2.0945565700531006

Epoch: 6| Step: 11
Training loss: 2.126614809036255
Validation loss: 2.077782769997915

Epoch: 6| Step: 12
Training loss: 2.513638496398926
Validation loss: 2.094308773676554

Epoch: 6| Step: 13
Training loss: 1.9289741516113281
Validation loss: 2.09615695476532

Epoch: 184| Step: 0
Training loss: 1.3971292972564697
Validation loss: 2.1099908153216043

Epoch: 6| Step: 1
Training loss: 2.3929829597473145
Validation loss: 2.099314570426941

Epoch: 6| Step: 2
Training loss: 1.399990200996399
Validation loss: 2.104399859905243

Epoch: 6| Step: 3
Training loss: 2.4959373474121094
Validation loss: 2.119832754135132

Epoch: 6| Step: 4
Training loss: 1.7410069704055786
Validation loss: 2.1203026374181113

Epoch: 6| Step: 5
Training loss: 1.564927101135254
Validation loss: 2.113812526067098

Epoch: 6| Step: 6
Training loss: 2.2712182998657227
Validation loss: 2.130811174710592

Epoch: 6| Step: 7
Training loss: 1.9152742624282837
Validation loss: 2.130457798639933

Epoch: 6| Step: 8
Training loss: 2.3108298778533936
Validation loss: 2.128499746322632

Epoch: 6| Step: 9
Training loss: 2.308685779571533
Validation loss: 2.119360605875651

Epoch: 6| Step: 10
Training loss: 2.1814818382263184
Validation loss: 2.104815344015757

Epoch: 6| Step: 11
Training loss: 1.4869301319122314
Validation loss: 2.1180692116419473

Epoch: 6| Step: 12
Training loss: 1.5866453647613525
Validation loss: 2.109489858150482

Epoch: 6| Step: 13
Training loss: 2.354226589202881
Validation loss: 2.108130693435669

Epoch: 185| Step: 0
Training loss: 2.0913476943969727
Validation loss: 2.111341675122579

Epoch: 6| Step: 1
Training loss: 1.9120949506759644
Validation loss: 2.101452946662903

Epoch: 6| Step: 2
Training loss: 2.2563090324401855
Validation loss: 2.107953508694967

Epoch: 6| Step: 3
Training loss: 1.9554588794708252
Validation loss: 2.10387792189916

Epoch: 6| Step: 4
Training loss: 1.7324374914169312
Validation loss: 2.095428168773651

Epoch: 6| Step: 5
Training loss: 1.9001328945159912
Validation loss: 2.093942880630493

Epoch: 6| Step: 6
Training loss: 1.9137187004089355
Validation loss: 2.0803662141164145

Epoch: 6| Step: 7
Training loss: 2.380232572555542
Validation loss: 2.0879655877749124

Epoch: 6| Step: 8
Training loss: 2.156399726867676
Validation loss: 2.0986685752868652

Epoch: 6| Step: 9
Training loss: 1.338839054107666
Validation loss: 2.088570515314738

Epoch: 6| Step: 10
Training loss: 2.1467103958129883
Validation loss: 2.0866153836250305

Epoch: 6| Step: 11
Training loss: 1.8641103506088257
Validation loss: 2.099946359793345

Epoch: 6| Step: 12
Training loss: 1.8237452507019043
Validation loss: 2.1004870533943176

Epoch: 6| Step: 13
Training loss: 1.9355027675628662
Validation loss: 2.105996251106262

Epoch: 186| Step: 0
Training loss: 1.8642339706420898
Validation loss: 2.1217130422592163

Epoch: 6| Step: 1
Training loss: 1.789825201034546
Validation loss: 2.1119468808174133

Epoch: 6| Step: 2
Training loss: 2.0913150310516357
Validation loss: 2.103395422299703

Epoch: 6| Step: 3
Training loss: 2.209144353866577
Validation loss: 2.1266878247261047

Epoch: 6| Step: 4
Training loss: 2.4024546146392822
Validation loss: 2.106667776902517

Epoch: 6| Step: 5
Training loss: 2.255371570587158
Validation loss: 2.1175426642100015

Epoch: 6| Step: 6
Training loss: 1.3028113842010498
Validation loss: 2.1089617013931274

Epoch: 6| Step: 7
Training loss: 1.4953676462173462
Validation loss: 2.109663804372152

Epoch: 6| Step: 8
Training loss: 2.1726646423339844
Validation loss: 2.1044299801190696

Epoch: 6| Step: 9
Training loss: 2.0329630374908447
Validation loss: 2.0935086011886597

Epoch: 6| Step: 10
Training loss: 2.2743470668792725
Validation loss: 2.0852576891581216

Epoch: 6| Step: 11
Training loss: 1.8372758626937866
Validation loss: 2.089646855990092

Epoch: 6| Step: 12
Training loss: 1.772895097732544
Validation loss: 2.0910465717315674

Epoch: 6| Step: 13
Training loss: 2.0013928413391113
Validation loss: 2.085798521836599

Epoch: 187| Step: 0
Training loss: 1.4686472415924072
Validation loss: 2.11242938041687

Epoch: 6| Step: 1
Training loss: 1.9300159215927124
Validation loss: 2.1274659037590027

Epoch: 6| Step: 2
Training loss: 2.996218681335449
Validation loss: 2.127922256787618

Epoch: 6| Step: 3
Training loss: 1.4803433418273926
Validation loss: 2.117235620816549

Epoch: 6| Step: 4
Training loss: 1.9710392951965332
Validation loss: 2.1226951281229653

Epoch: 6| Step: 5
Training loss: 1.725089192390442
Validation loss: 2.1253212292989097

Epoch: 6| Step: 6
Training loss: 2.6868531703948975
Validation loss: 2.1058958967526755

Epoch: 6| Step: 7
Training loss: 2.36610746383667
Validation loss: 2.102535307407379

Epoch: 6| Step: 8
Training loss: 1.463129997253418
Validation loss: 2.108974496523539

Epoch: 6| Step: 9
Training loss: 2.400527238845825
Validation loss: 2.0905678470929465

Epoch: 6| Step: 10
Training loss: 1.809285044670105
Validation loss: 2.0847718318303428

Epoch: 6| Step: 11
Training loss: 1.6317893266677856
Validation loss: 2.0791983405749

Epoch: 6| Step: 12
Training loss: 1.762943983078003
Validation loss: 2.0823017160097756

Epoch: 6| Step: 13
Training loss: 2.1922826766967773
Validation loss: 2.077643016974131

Epoch: 188| Step: 0
Training loss: 2.3004884719848633
Validation loss: 2.0845054189364114

Epoch: 6| Step: 1
Training loss: 1.7137322425842285
Validation loss: 2.0816403230031333

Epoch: 6| Step: 2
Training loss: 1.9725275039672852
Validation loss: 2.089983503023783

Epoch: 6| Step: 3
Training loss: 2.007526397705078
Validation loss: 2.0956053932507834

Epoch: 6| Step: 4
Training loss: 1.8359814882278442
Validation loss: 2.0875019232432046

Epoch: 6| Step: 5
Training loss: 1.7467175722122192
Validation loss: 2.095353821913401

Epoch: 6| Step: 6
Training loss: 2.059147834777832
Validation loss: 2.0955541729927063

Epoch: 6| Step: 7
Training loss: 2.1852478981018066
Validation loss: 2.091592868169149

Epoch: 6| Step: 8
Training loss: 1.9231681823730469
Validation loss: 2.0866695642471313

Epoch: 6| Step: 9
Training loss: 2.039059638977051
Validation loss: 2.081713060537974

Epoch: 6| Step: 10
Training loss: 2.0336039066314697
Validation loss: 2.077422300974528

Epoch: 6| Step: 11
Training loss: 1.8077306747436523
Validation loss: 2.09178896745046

Epoch: 6| Step: 12
Training loss: 2.2353289127349854
Validation loss: 2.0959895253181458

Epoch: 6| Step: 13
Training loss: 1.6151502132415771
Validation loss: 2.114297648270925

Epoch: 189| Step: 0
Training loss: 2.5982654094696045
Validation loss: 2.1249839266141257

Epoch: 6| Step: 1
Training loss: 2.2943241596221924
Validation loss: 2.144218901793162

Epoch: 6| Step: 2
Training loss: 2.483811855316162
Validation loss: 2.129183212916056

Epoch: 6| Step: 3
Training loss: 1.2880175113677979
Validation loss: 2.145197848478953

Epoch: 6| Step: 4
Training loss: 2.0489463806152344
Validation loss: 2.1436381737391152

Epoch: 6| Step: 5
Training loss: 1.4814541339874268
Validation loss: 2.1364939411481223

Epoch: 6| Step: 6
Training loss: 1.9288208484649658
Validation loss: 2.126879036426544

Epoch: 6| Step: 7
Training loss: 1.057735562324524
Validation loss: 2.1285932064056396

Epoch: 6| Step: 8
Training loss: 1.558558464050293
Validation loss: 2.1228345235188804

Epoch: 6| Step: 9
Training loss: 2.624420642852783
Validation loss: 2.1261202096939087

Epoch: 6| Step: 10
Training loss: 2.565084934234619
Validation loss: 2.1330430110295615

Epoch: 6| Step: 11
Training loss: 1.5506230592727661
Validation loss: 2.1279963652292886

Epoch: 6| Step: 12
Training loss: 1.799781322479248
Validation loss: 2.1302207907040915

Epoch: 6| Step: 13
Training loss: 1.8254978656768799
Validation loss: 2.129460175832113

Epoch: 190| Step: 0
Training loss: 2.0560641288757324
Validation loss: 2.1310269832611084

Epoch: 6| Step: 1
Training loss: 1.893183708190918
Validation loss: 2.1140310764312744

Epoch: 6| Step: 2
Training loss: 1.4327099323272705
Validation loss: 2.125175734361013

Epoch: 6| Step: 3
Training loss: 2.1677749156951904
Validation loss: 2.1168137590090432

Epoch: 6| Step: 4
Training loss: 1.7237820625305176
Validation loss: 2.1127254565556846

Epoch: 6| Step: 5
Training loss: 1.635862946510315
Validation loss: 2.104447861512502

Epoch: 6| Step: 6
Training loss: 2.224898338317871
Validation loss: 2.1301135619481406

Epoch: 6| Step: 7
Training loss: 2.7051475048065186
Validation loss: 2.114871303240458

Epoch: 6| Step: 8
Training loss: 1.8696110248565674
Validation loss: 2.1133777300516763

Epoch: 6| Step: 9
Training loss: 1.7539008855819702
Validation loss: 2.108067433039347

Epoch: 6| Step: 10
Training loss: 2.0004055500030518
Validation loss: 2.124729792277018

Epoch: 6| Step: 11
Training loss: 1.6656559705734253
Validation loss: 2.1242183248202005

Epoch: 6| Step: 12
Training loss: 2.061607837677002
Validation loss: 2.1096957127253213

Epoch: 6| Step: 13
Training loss: 1.877068042755127
Validation loss: 2.1179816126823425

Epoch: 191| Step: 0
Training loss: 2.371471405029297
Validation loss: 2.117749253908793

Epoch: 6| Step: 1
Training loss: 1.7280628681182861
Validation loss: 2.1043914159139

Epoch: 6| Step: 2
Training loss: 1.7526774406433105
Validation loss: 2.1024862130482993

Epoch: 6| Step: 3
Training loss: 1.4999340772628784
Validation loss: 2.093062460422516

Epoch: 6| Step: 4
Training loss: 1.9315788745880127
Validation loss: 2.0949612855911255

Epoch: 6| Step: 5
Training loss: 1.3611325025558472
Validation loss: 2.102470854918162

Epoch: 6| Step: 6
Training loss: 2.100259304046631
Validation loss: 2.0982974966367087

Epoch: 6| Step: 7
Training loss: 1.2208130359649658
Validation loss: 2.1002698143323264

Epoch: 6| Step: 8
Training loss: 2.0407652854919434
Validation loss: 2.0975696245829263

Epoch: 6| Step: 9
Training loss: 2.6971001625061035
Validation loss: 2.0937002698580423

Epoch: 6| Step: 10
Training loss: 1.8965916633605957
Validation loss: 2.095973471800486

Epoch: 6| Step: 11
Training loss: 2.6198153495788574
Validation loss: 2.1160248716672263

Epoch: 6| Step: 12
Training loss: 2.0250844955444336
Validation loss: 2.115820129712423

Epoch: 6| Step: 13
Training loss: 1.968653917312622
Validation loss: 2.124619940916697

Epoch: 192| Step: 0
Training loss: 2.4366769790649414
Validation loss: 2.1182981729507446

Epoch: 6| Step: 1
Training loss: 1.7782329320907593
Validation loss: 2.12689745426178

Epoch: 6| Step: 2
Training loss: 1.9563361406326294
Validation loss: 2.106635649998983

Epoch: 6| Step: 3
Training loss: 2.274122953414917
Validation loss: 2.1182412107785544

Epoch: 6| Step: 4
Training loss: 2.126406669616699
Validation loss: 2.110686779022217

Epoch: 6| Step: 5
Training loss: 2.1533312797546387
Validation loss: 2.1063547134399414

Epoch: 6| Step: 6
Training loss: 1.6749067306518555
Validation loss: 2.0872870087623596

Epoch: 6| Step: 7
Training loss: 1.5608919858932495
Validation loss: 2.1001039942105613

Epoch: 6| Step: 8
Training loss: 1.8338130712509155
Validation loss: 2.0834456284840903

Epoch: 6| Step: 9
Training loss: 1.92303466796875
Validation loss: 2.089113493760427

Epoch: 6| Step: 10
Training loss: 1.6848680973052979
Validation loss: 2.078764716784159

Epoch: 6| Step: 11
Training loss: 2.610285758972168
Validation loss: 2.0863019625345864

Epoch: 6| Step: 12
Training loss: 1.571331262588501
Validation loss: 2.090140144030253

Epoch: 6| Step: 13
Training loss: 1.9941507577896118
Validation loss: 2.120933254559835

Epoch: 193| Step: 0
Training loss: 1.2818790674209595
Validation loss: 2.1055088440577188

Epoch: 6| Step: 1
Training loss: 2.214509963989258
Validation loss: 2.109992961088816

Epoch: 6| Step: 2
Training loss: 2.0731661319732666
Validation loss: 2.124693234761556

Epoch: 6| Step: 3
Training loss: 1.867924451828003
Validation loss: 2.1405749917030334

Epoch: 6| Step: 4
Training loss: 2.4818429946899414
Validation loss: 2.13854326804479

Epoch: 6| Step: 5
Training loss: 2.346123695373535
Validation loss: 2.1337652007738748

Epoch: 6| Step: 6
Training loss: 1.9952001571655273
Validation loss: 2.1451021234194436

Epoch: 6| Step: 7
Training loss: 1.6450386047363281
Validation loss: 2.114136815071106

Epoch: 6| Step: 8
Training loss: 2.376466751098633
Validation loss: 2.0925623973210654

Epoch: 6| Step: 9
Training loss: 2.3678886890411377
Validation loss: 2.092396299044291

Epoch: 6| Step: 10
Training loss: 1.6465390920639038
Validation loss: 2.100853602091471

Epoch: 6| Step: 11
Training loss: 2.1687793731689453
Validation loss: 2.0757492184638977

Epoch: 6| Step: 12
Training loss: 1.7808831930160522
Validation loss: 2.0783172845840454

Epoch: 6| Step: 13
Training loss: 1.7784483432769775
Validation loss: 2.0756444732348123

Epoch: 194| Step: 0
Training loss: 1.7855108976364136
Validation loss: 2.0798883636792502

Epoch: 6| Step: 1
Training loss: 2.3932371139526367
Validation loss: 2.0810414950052896

Epoch: 6| Step: 2
Training loss: 1.3657124042510986
Validation loss: 2.070505162080129

Epoch: 6| Step: 3
Training loss: 1.6152347326278687
Validation loss: 2.0829915603001914

Epoch: 6| Step: 4
Training loss: 1.5158464908599854
Validation loss: 2.083077311515808

Epoch: 6| Step: 5
Training loss: 2.133805751800537
Validation loss: 2.079802691936493

Epoch: 6| Step: 6
Training loss: 2.0155231952667236
Validation loss: 2.065213958422343

Epoch: 6| Step: 7
Training loss: 2.4663777351379395
Validation loss: 2.079129238923391

Epoch: 6| Step: 8
Training loss: 1.3612430095672607
Validation loss: 2.0688771406809487

Epoch: 6| Step: 9
Training loss: 2.3925020694732666
Validation loss: 2.07802951335907

Epoch: 6| Step: 10
Training loss: 2.348234176635742
Validation loss: 2.075251658757528

Epoch: 6| Step: 11
Training loss: 1.9234647750854492
Validation loss: 2.082033117612203

Epoch: 6| Step: 12
Training loss: 2.4386954307556152
Validation loss: 2.0782358249028525

Epoch: 6| Step: 13
Training loss: 2.309962272644043
Validation loss: 2.092032790184021

Epoch: 195| Step: 0
Training loss: 1.67720627784729
Validation loss: 2.090889036655426

Epoch: 6| Step: 1
Training loss: 1.5340354442596436
Validation loss: 2.0951056480407715

Epoch: 6| Step: 2
Training loss: 2.202228546142578
Validation loss: 2.088776489098867

Epoch: 6| Step: 3
Training loss: 2.1152381896972656
Validation loss: 2.1029602686564126

Epoch: 6| Step: 4
Training loss: 2.3428783416748047
Validation loss: 2.0970411698023477

Epoch: 6| Step: 5
Training loss: 2.065866470336914
Validation loss: 2.1019171476364136

Epoch: 6| Step: 6
Training loss: 2.4660558700561523
Validation loss: 2.1171784003575644

Epoch: 6| Step: 7
Training loss: 1.3137662410736084
Validation loss: 2.106543183326721

Epoch: 6| Step: 8
Training loss: 1.9648526906967163
Validation loss: 2.113867243131002

Epoch: 6| Step: 9
Training loss: 2.0641229152679443
Validation loss: 2.1196510791778564

Epoch: 6| Step: 10
Training loss: 1.8735995292663574
Validation loss: 2.1359988848368325

Epoch: 6| Step: 11
Training loss: 2.475641965866089
Validation loss: 2.1166924238204956

Epoch: 6| Step: 12
Training loss: 1.2271541357040405
Validation loss: 2.1219398180643716

Epoch: 6| Step: 13
Training loss: 2.025963306427002
Validation loss: 2.126366833845774

Epoch: 196| Step: 0
Training loss: 1.766024112701416
Validation loss: 2.106155514717102

Epoch: 6| Step: 1
Training loss: 1.9289705753326416
Validation loss: 2.119577487309774

Epoch: 6| Step: 2
Training loss: 1.9596956968307495
Validation loss: 2.114973505338033

Epoch: 6| Step: 3
Training loss: 1.8109673261642456
Validation loss: 2.1163938840230307

Epoch: 6| Step: 4
Training loss: 2.217827320098877
Validation loss: 2.1091009775797525

Epoch: 6| Step: 5
Training loss: 2.0437073707580566
Validation loss: 2.129542350769043

Epoch: 6| Step: 6
Training loss: 2.4271633625030518
Validation loss: 2.113767663637797

Epoch: 6| Step: 7
Training loss: 2.21651291847229
Validation loss: 2.1210083762804666

Epoch: 6| Step: 8
Training loss: 1.601599097251892
Validation loss: 2.1229185660680137

Epoch: 6| Step: 9
Training loss: 2.3238143920898438
Validation loss: 2.0999300281206765

Epoch: 6| Step: 10
Training loss: 1.7668466567993164
Validation loss: 2.097304046154022

Epoch: 6| Step: 11
Training loss: 1.8513834476470947
Validation loss: 2.103507856527964

Epoch: 6| Step: 12
Training loss: 1.9260141849517822
Validation loss: 2.1088446378707886

Epoch: 6| Step: 13
Training loss: 1.6160106658935547
Validation loss: 2.09245236714681

Epoch: 197| Step: 0
Training loss: 1.7517335414886475
Validation loss: 2.0909862915674844

Epoch: 6| Step: 1
Training loss: 2.59517502784729
Validation loss: 2.097634514172872

Epoch: 6| Step: 2
Training loss: 2.853046417236328
Validation loss: 2.1043596665064492

Epoch: 6| Step: 3
Training loss: 2.379897117614746
Validation loss: 2.1004596749941506

Epoch: 6| Step: 4
Training loss: 1.7208760976791382
Validation loss: 2.105781098206838

Epoch: 6| Step: 5
Training loss: 2.1434342861175537
Validation loss: 2.1107651193936667

Epoch: 6| Step: 6
Training loss: 2.106901168823242
Validation loss: 2.1055752833684287

Epoch: 6| Step: 7
Training loss: 1.383284568786621
Validation loss: 2.1026664773623147

Epoch: 6| Step: 8
Training loss: 1.7839218378067017
Validation loss: 2.1104785998662314

Epoch: 6| Step: 9
Training loss: 1.8667625188827515
Validation loss: 2.084855377674103

Epoch: 6| Step: 10
Training loss: 1.5218600034713745
Validation loss: 2.101361354192098

Epoch: 6| Step: 11
Training loss: 1.8185135126113892
Validation loss: 2.1088399291038513

Epoch: 6| Step: 12
Training loss: 1.7819756269454956
Validation loss: 2.107535799344381

Epoch: 6| Step: 13
Training loss: 1.5998785495758057
Validation loss: 2.1214750607808432

Epoch: 198| Step: 0
Training loss: 2.1484193801879883
Validation loss: 2.1186077197392783

Epoch: 6| Step: 1
Training loss: 1.1386454105377197
Validation loss: 2.1175964077313743

Epoch: 6| Step: 2
Training loss: 1.6374456882476807
Validation loss: 2.1380282441775003

Epoch: 6| Step: 3
Training loss: 1.4825373888015747
Validation loss: 2.1357293923695884

Epoch: 6| Step: 4
Training loss: 1.3461962938308716
Validation loss: 2.1406219005584717

Epoch: 6| Step: 5
Training loss: 1.7435665130615234
Validation loss: 2.145394504070282

Epoch: 6| Step: 6
Training loss: 1.8378448486328125
Validation loss: 2.1294885873794556

Epoch: 6| Step: 7
Training loss: 3.0190253257751465
Validation loss: 2.1294483741124473

Epoch: 6| Step: 8
Training loss: 1.3994231224060059
Validation loss: 2.1207584341367087

Epoch: 6| Step: 9
Training loss: 2.002539873123169
Validation loss: 2.1217281222343445

Epoch: 6| Step: 10
Training loss: 2.8029632568359375
Validation loss: 2.128532608350118

Epoch: 6| Step: 11
Training loss: 1.3946174383163452
Validation loss: 2.1235675613085427

Epoch: 6| Step: 12
Training loss: 2.3492989540100098
Validation loss: 2.1164215008417764

Epoch: 6| Step: 13
Training loss: 2.6118979454040527
Validation loss: 2.1200480461120605

Epoch: 199| Step: 0
Training loss: 1.4886356592178345
Validation loss: 2.1166855295499167

Epoch: 6| Step: 1
Training loss: 2.6725192070007324
Validation loss: 2.121435066064199

Epoch: 6| Step: 2
Training loss: 1.0667825937271118
Validation loss: 2.131701191266378

Epoch: 6| Step: 3
Training loss: 2.2311220169067383
Validation loss: 2.132923642794291

Epoch: 6| Step: 4
Training loss: 1.6847341060638428
Validation loss: 2.1319594979286194

Epoch: 6| Step: 5
Training loss: 1.9397411346435547
Validation loss: 2.1388861338297525

Epoch: 6| Step: 6
Training loss: 1.8682738542556763
Validation loss: 2.1482011874516806

Epoch: 6| Step: 7
Training loss: 1.8258775472640991
Validation loss: 2.149721006552378

Epoch: 6| Step: 8
Training loss: 1.4710067510604858
Validation loss: 2.1337086160977683

Epoch: 6| Step: 9
Training loss: 2.125237226486206
Validation loss: 2.1280157566070557

Epoch: 6| Step: 10
Training loss: 2.0502829551696777
Validation loss: 2.1220850149790444

Epoch: 6| Step: 11
Training loss: 2.4241676330566406
Validation loss: 2.1180389722188315

Epoch: 6| Step: 12
Training loss: 2.3507580757141113
Validation loss: 2.1186638275782266

Epoch: 6| Step: 13
Training loss: 1.8184860944747925
Validation loss: 2.1309798757235208

Epoch: 200| Step: 0
Training loss: 2.210576057434082
Validation loss: 2.1140268246332803

Epoch: 6| Step: 1
Training loss: 1.7935611009597778
Validation loss: 2.1070563793182373

Epoch: 6| Step: 2
Training loss: 2.1163039207458496
Validation loss: 2.1094807982444763

Epoch: 6| Step: 3
Training loss: 2.077742099761963
Validation loss: 2.111143946647644

Epoch: 6| Step: 4
Training loss: 1.7289685010910034
Validation loss: 2.112267037232717

Epoch: 6| Step: 5
Training loss: 2.2947463989257812
Validation loss: 2.116023302078247

Epoch: 6| Step: 6
Training loss: 2.2121176719665527
Validation loss: 2.114923596382141

Epoch: 6| Step: 7
Training loss: 1.8013744354248047
Validation loss: 2.122502088546753

Epoch: 6| Step: 8
Training loss: 1.598935842514038
Validation loss: 2.124321142832438

Epoch: 6| Step: 9
Training loss: 2.1059021949768066
Validation loss: 2.1173182924588523

Epoch: 6| Step: 10
Training loss: 1.963586688041687
Validation loss: 2.1174220641454062

Epoch: 6| Step: 11
Training loss: 1.8509669303894043
Validation loss: 2.1313204765319824

Epoch: 6| Step: 12
Training loss: 2.189847230911255
Validation loss: 2.1234682401021323

Epoch: 6| Step: 13
Training loss: 1.0698350667953491
Validation loss: 2.1273913184801736

Epoch: 201| Step: 0
Training loss: 1.8295083045959473
Validation loss: 2.1303765773773193

Epoch: 6| Step: 1
Training loss: 2.204063653945923
Validation loss: 2.150600175062815

Epoch: 6| Step: 2
Training loss: 2.2379274368286133
Validation loss: 2.1213479042053223

Epoch: 6| Step: 3
Training loss: 1.7694792747497559
Validation loss: 2.1333364248275757

Epoch: 6| Step: 4
Training loss: 1.7263052463531494
Validation loss: 2.102922280629476

Epoch: 6| Step: 5
Training loss: 2.284320116043091
Validation loss: 2.113552729288737

Epoch: 6| Step: 6
Training loss: 2.986072063446045
Validation loss: 2.1069783767064414

Epoch: 6| Step: 7
Training loss: 2.406961441040039
Validation loss: 2.1144444147745767

Epoch: 6| Step: 8
Training loss: 1.84586501121521
Validation loss: 2.108131170272827

Epoch: 6| Step: 9
Training loss: 1.6810033321380615
Validation loss: 2.1181986331939697

Epoch: 6| Step: 10
Training loss: 1.4626396894454956
Validation loss: 2.1024078130722046

Epoch: 6| Step: 11
Training loss: 2.048743724822998
Validation loss: 2.1246637105941772

Epoch: 6| Step: 12
Training loss: 1.3851556777954102
Validation loss: 2.135136604309082

Epoch: 6| Step: 13
Training loss: 1.3872387409210205
Validation loss: 2.1139726042747498

Epoch: 202| Step: 0
Training loss: 2.20719838142395
Validation loss: 2.128593405087789

Epoch: 6| Step: 1
Training loss: 1.4034194946289062
Validation loss: 2.1211093266805015

Epoch: 6| Step: 2
Training loss: 2.359907627105713
Validation loss: 2.1315547227859497

Epoch: 6| Step: 3
Training loss: 1.8054726123809814
Validation loss: 2.1267240047454834

Epoch: 6| Step: 4
Training loss: 1.5242507457733154
Validation loss: 2.141376495361328

Epoch: 6| Step: 5
Training loss: 2.202890396118164
Validation loss: 2.115015387535095

Epoch: 6| Step: 6
Training loss: 1.5609352588653564
Validation loss: 2.1486560106277466

Epoch: 6| Step: 7
Training loss: 2.5884385108947754
Validation loss: 2.1319481134414673

Epoch: 6| Step: 8
Training loss: 2.07767915725708
Validation loss: 2.1314549446105957

Epoch: 6| Step: 9
Training loss: 1.3679763078689575
Validation loss: 2.1434146563212075

Epoch: 6| Step: 10
Training loss: 1.8527915477752686
Validation loss: 2.156053980191549

Epoch: 6| Step: 11
Training loss: 1.6736586093902588
Validation loss: 2.1424784660339355

Epoch: 6| Step: 12
Training loss: 2.0050806999206543
Validation loss: 2.1479029655456543

Epoch: 6| Step: 13
Training loss: 2.02022123336792
Validation loss: 2.134539842605591

Epoch: 203| Step: 0
Training loss: 1.565053105354309
Validation loss: 2.144975026448568

Epoch: 6| Step: 1
Training loss: 2.006908893585205
Validation loss: 2.1250610947608948

Epoch: 6| Step: 2
Training loss: 1.8394049406051636
Validation loss: 2.1232190330823264

Epoch: 6| Step: 3
Training loss: 2.086254596710205
Validation loss: 2.1318670312563577

Epoch: 6| Step: 4
Training loss: 1.4010238647460938
Validation loss: 2.1350998083750405

Epoch: 6| Step: 5
Training loss: 1.6949794292449951
Validation loss: 2.1319342454274497

Epoch: 6| Step: 6
Training loss: 1.8982679843902588
Validation loss: 2.132248838742574

Epoch: 6| Step: 7
Training loss: 2.3016762733459473
Validation loss: 2.138932685057322

Epoch: 6| Step: 8
Training loss: 1.5306698083877563
Validation loss: 2.150269786516825

Epoch: 6| Step: 9
Training loss: 2.6337099075317383
Validation loss: 2.1403597791989646

Epoch: 6| Step: 10
Training loss: 1.554375171661377
Validation loss: 2.1282028555870056

Epoch: 6| Step: 11
Training loss: 1.8211382627487183
Validation loss: 2.1344135204950967

Epoch: 6| Step: 12
Training loss: 2.016092300415039
Validation loss: 2.131541152795156

Epoch: 6| Step: 13
Training loss: 2.566661834716797
Validation loss: 2.122000972429911

Epoch: 204| Step: 0
Training loss: 1.7547454833984375
Validation loss: 2.111089825630188

Epoch: 6| Step: 1
Training loss: 2.177351236343384
Validation loss: 2.1312381625175476

Epoch: 6| Step: 2
Training loss: 2.2148523330688477
Validation loss: 2.131822427113851

Epoch: 6| Step: 3
Training loss: 2.6367123126983643
Validation loss: 2.109701176484426

Epoch: 6| Step: 4
Training loss: 1.3250353336334229
Validation loss: 2.118160525957743

Epoch: 6| Step: 5
Training loss: 1.7814979553222656
Validation loss: 2.139899571736654

Epoch: 6| Step: 6
Training loss: 2.016139030456543
Validation loss: 2.1395047108332315

Epoch: 6| Step: 7
Training loss: 1.627374291419983
Validation loss: 2.1335941751797995

Epoch: 6| Step: 8
Training loss: 1.8431751728057861
Validation loss: 2.139368454615275

Epoch: 6| Step: 9
Training loss: 2.228405714035034
Validation loss: 2.168320874373118

Epoch: 6| Step: 10
Training loss: 1.9850599765777588
Validation loss: 2.1788235704104104

Epoch: 6| Step: 11
Training loss: 1.529970407485962
Validation loss: 2.167126953601837

Epoch: 6| Step: 12
Training loss: 1.289529800415039
Validation loss: 2.150128483772278

Epoch: 6| Step: 13
Training loss: 2.1447324752807617
Validation loss: 2.1407962242762246

Epoch: 205| Step: 0
Training loss: 1.5814754962921143
Validation loss: 2.139605402946472

Epoch: 6| Step: 1
Training loss: 1.3422385454177856
Validation loss: 2.1253719528516135

Epoch: 6| Step: 2
Training loss: 1.4773449897766113
Validation loss: 2.117453316847483

Epoch: 6| Step: 3
Training loss: 1.825830101966858
Validation loss: 2.1105530858039856

Epoch: 6| Step: 4
Training loss: 2.4136013984680176
Validation loss: 2.1046067078908286

Epoch: 6| Step: 5
Training loss: 2.252779960632324
Validation loss: 2.1019344329833984

Epoch: 6| Step: 6
Training loss: 1.9900970458984375
Validation loss: 2.1183469692866006

Epoch: 6| Step: 7
Training loss: 1.9205329418182373
Validation loss: 2.126670022805532

Epoch: 6| Step: 8
Training loss: 1.9284814596176147
Validation loss: 2.1063368121782937

Epoch: 6| Step: 9
Training loss: 1.8412683010101318
Validation loss: 2.11297873655955

Epoch: 6| Step: 10
Training loss: 2.229842185974121
Validation loss: 2.102160394191742

Epoch: 6| Step: 11
Training loss: 2.535512685775757
Validation loss: 2.094484567642212

Epoch: 6| Step: 12
Training loss: 1.6958940029144287
Validation loss: 2.113703727722168

Epoch: 6| Step: 13
Training loss: 2.507145643234253
Validation loss: 2.099094251791636

Epoch: 206| Step: 0
Training loss: 1.8751537799835205
Validation loss: 2.112486938635508

Epoch: 6| Step: 1
Training loss: 1.9445695877075195
Validation loss: 2.1193796197573342

Epoch: 6| Step: 2
Training loss: 1.7644128799438477
Validation loss: 2.1366395155588784

Epoch: 6| Step: 3
Training loss: 2.7524971961975098
Validation loss: 2.1203234593073526

Epoch: 6| Step: 4
Training loss: 1.6530108451843262
Validation loss: 2.1404240131378174

Epoch: 6| Step: 5
Training loss: 1.3061251640319824
Validation loss: 2.153968870639801

Epoch: 6| Step: 6
Training loss: 2.4566898345947266
Validation loss: 2.167103588581085

Epoch: 6| Step: 7
Training loss: 2.0498547554016113
Validation loss: 2.1626715461413064

Epoch: 6| Step: 8
Training loss: 1.7597925662994385
Validation loss: 2.1540444095929465

Epoch: 6| Step: 9
Training loss: 1.4571579694747925
Validation loss: 2.164367397626241

Epoch: 6| Step: 10
Training loss: 1.1465380191802979
Validation loss: 2.1666046778361

Epoch: 6| Step: 11
Training loss: 2.038760185241699
Validation loss: 2.161782383918762

Epoch: 6| Step: 12
Training loss: 2.5718064308166504
Validation loss: 2.1220033764839172

Epoch: 6| Step: 13
Training loss: 1.8693337440490723
Validation loss: 2.1403778195381165

Epoch: 207| Step: 0
Training loss: 1.9800305366516113
Validation loss: 2.1324005921681723

Epoch: 6| Step: 1
Training loss: 2.0187721252441406
Validation loss: 2.1289296547571817

Epoch: 6| Step: 2
Training loss: 1.7563364505767822
Validation loss: 2.106989800930023

Epoch: 6| Step: 3
Training loss: 1.8948042392730713
Validation loss: 2.1211347381273904

Epoch: 6| Step: 4
Training loss: 2.352234363555908
Validation loss: 2.1210708220799765

Epoch: 6| Step: 5
Training loss: 2.1283411979675293
Validation loss: 2.1202543576558432

Epoch: 6| Step: 6
Training loss: 2.0723764896392822
Validation loss: 2.1289484898249307

Epoch: 6| Step: 7
Training loss: 1.5347727537155151
Validation loss: 2.154861251513163

Epoch: 6| Step: 8
Training loss: 2.393080234527588
Validation loss: 2.139634589354197

Epoch: 6| Step: 9
Training loss: 1.349984884262085
Validation loss: 2.155551294485728

Epoch: 6| Step: 10
Training loss: 1.7751978635787964
Validation loss: 2.128634293874105

Epoch: 6| Step: 11
Training loss: 1.8289908170700073
Validation loss: 2.1584540406862893

Epoch: 6| Step: 12
Training loss: 2.102532386779785
Validation loss: 2.1481194496154785

Epoch: 6| Step: 13
Training loss: 1.5376412868499756
Validation loss: 2.15710711479187

Epoch: 208| Step: 0
Training loss: 1.784916877746582
Validation loss: 2.1805495421091714

Epoch: 6| Step: 1
Training loss: 1.8638590574264526
Validation loss: 2.1864855686823526

Epoch: 6| Step: 2
Training loss: 2.274155616760254
Validation loss: 2.167072852452596

Epoch: 6| Step: 3
Training loss: 1.628179907798767
Validation loss: 2.179810086886088

Epoch: 6| Step: 4
Training loss: 1.9952095746994019
Validation loss: 2.1672542889912925

Epoch: 6| Step: 5
Training loss: 2.270245313644409
Validation loss: 2.171623428662618

Epoch: 6| Step: 6
Training loss: 2.592684507369995
Validation loss: 2.1690465211868286

Epoch: 6| Step: 7
Training loss: 1.2742745876312256
Validation loss: 2.1644835074742637

Epoch: 6| Step: 8
Training loss: 1.9423545598983765
Validation loss: 2.1419370969136557

Epoch: 6| Step: 9
Training loss: 2.524725914001465
Validation loss: 2.1263598601023355

Epoch: 6| Step: 10
Training loss: 2.087662696838379
Validation loss: 2.101114888985952

Epoch: 6| Step: 11
Training loss: 1.9059256315231323
Validation loss: 2.0997068285942078

Epoch: 6| Step: 12
Training loss: 1.561192512512207
Validation loss: 2.105436106522878

Epoch: 6| Step: 13
Training loss: 1.3748722076416016
Validation loss: 2.1024945179621377

Epoch: 209| Step: 0
Training loss: 1.9993349313735962
Validation loss: 2.1073479851086936

Epoch: 6| Step: 1
Training loss: 1.953904628753662
Validation loss: 2.1017849842707315

Epoch: 6| Step: 2
Training loss: 2.2228844165802
Validation loss: 2.110340495904287

Epoch: 6| Step: 3
Training loss: 1.7860966920852661
Validation loss: 2.1034833788871765

Epoch: 6| Step: 4
Training loss: 2.812319278717041
Validation loss: 2.112477123737335

Epoch: 6| Step: 5
Training loss: 1.4102622270584106
Validation loss: 2.1002184549967446

Epoch: 6| Step: 6
Training loss: 2.532223701477051
Validation loss: 2.1252123514811196

Epoch: 6| Step: 7
Training loss: 1.8281840085983276
Validation loss: 2.123883068561554

Epoch: 6| Step: 8
Training loss: 1.3057903051376343
Validation loss: 2.129652818044027

Epoch: 6| Step: 9
Training loss: 1.832633376121521
Validation loss: 2.131573756535848

Epoch: 6| Step: 10
Training loss: 1.5951071977615356
Validation loss: 2.1311089992523193

Epoch: 6| Step: 11
Training loss: 2.150010585784912
Validation loss: 2.162085175514221

Epoch: 6| Step: 12
Training loss: 1.6910526752471924
Validation loss: 2.163518766562144

Epoch: 6| Step: 13
Training loss: 2.3717379570007324
Validation loss: 2.1650821367899575

Epoch: 210| Step: 0
Training loss: 1.310560703277588
Validation loss: 2.154863953590393

Epoch: 6| Step: 1
Training loss: 2.014291286468506
Validation loss: 2.1559378703435264

Epoch: 6| Step: 2
Training loss: 2.2979140281677246
Validation loss: 2.14528093735377

Epoch: 6| Step: 3
Training loss: 1.2466154098510742
Validation loss: 2.141459286212921

Epoch: 6| Step: 4
Training loss: 1.7626813650131226
Validation loss: 2.1348931193351746

Epoch: 6| Step: 5
Training loss: 2.3571176528930664
Validation loss: 2.1455699801445007

Epoch: 6| Step: 6
Training loss: 2.172524929046631
Validation loss: 2.1272313594818115

Epoch: 6| Step: 7
Training loss: 1.9155638217926025
Validation loss: 2.137682874997457

Epoch: 6| Step: 8
Training loss: 2.4254112243652344
Validation loss: 2.134796400864919

Epoch: 6| Step: 9
Training loss: 1.8282427787780762
Validation loss: 2.130593160788218

Epoch: 6| Step: 10
Training loss: 1.9703912734985352
Validation loss: 2.1395955880482993

Epoch: 6| Step: 11
Training loss: 2.592653274536133
Validation loss: 2.116191864013672

Epoch: 6| Step: 12
Training loss: 1.251586675643921
Validation loss: 2.1225814620653787

Epoch: 6| Step: 13
Training loss: 1.2887160778045654
Validation loss: 2.1255436340967813

Epoch: 211| Step: 0
Training loss: 2.235551118850708
Validation loss: 2.1284237106641135

Epoch: 6| Step: 1
Training loss: 1.191854476928711
Validation loss: 2.1254225373268127

Epoch: 6| Step: 2
Training loss: 2.2058892250061035
Validation loss: 2.132604400316874

Epoch: 6| Step: 3
Training loss: 2.562303066253662
Validation loss: 2.143115758895874

Epoch: 6| Step: 4
Training loss: 1.4756057262420654
Validation loss: 2.144050896167755

Epoch: 6| Step: 5
Training loss: 2.030879020690918
Validation loss: 2.1375195185343423

Epoch: 6| Step: 6
Training loss: 2.061908483505249
Validation loss: 2.1396721998850503

Epoch: 6| Step: 7
Training loss: 1.9275835752487183
Validation loss: 2.1213720242182412

Epoch: 6| Step: 8
Training loss: 1.7046515941619873
Validation loss: 2.1371641953786216

Epoch: 6| Step: 9
Training loss: 1.804628610610962
Validation loss: 2.158160408337911

Epoch: 6| Step: 10
Training loss: 1.3566914796829224
Validation loss: 2.1472811897595725

Epoch: 6| Step: 11
Training loss: 1.8266562223434448
Validation loss: 2.156206965446472

Epoch: 6| Step: 12
Training loss: 1.997517704963684
Validation loss: 2.127568324406942

Epoch: 6| Step: 13
Training loss: 2.1352992057800293
Validation loss: 2.1164677143096924

Epoch: 212| Step: 0
Training loss: 1.7288540601730347
Validation loss: 2.122939149538676

Epoch: 6| Step: 1
Training loss: 2.4456615447998047
Validation loss: 2.1328721841176352

Epoch: 6| Step: 2
Training loss: 1.36629056930542
Validation loss: 2.1340185006459556

Epoch: 6| Step: 3
Training loss: 1.591315507888794
Validation loss: 2.118015229701996

Epoch: 6| Step: 4
Training loss: 1.861680269241333
Validation loss: 2.1365426182746887

Epoch: 6| Step: 5
Training loss: 2.0439329147338867
Validation loss: 2.1342681646347046

Epoch: 6| Step: 6
Training loss: 1.2585004568099976
Validation loss: 2.1390586296717324

Epoch: 6| Step: 7
Training loss: 1.8187721967697144
Validation loss: 2.1473251978556314

Epoch: 6| Step: 8
Training loss: 2.0646770000457764
Validation loss: 2.1654080549875894

Epoch: 6| Step: 9
Training loss: 2.637761354446411
Validation loss: 2.1468386054039

Epoch: 6| Step: 10
Training loss: 2.281489372253418
Validation loss: 2.1691485246022544

Epoch: 6| Step: 11
Training loss: 1.6362441778182983
Validation loss: 2.1584496895472207

Epoch: 6| Step: 12
Training loss: 1.610694408416748
Validation loss: 2.172050178050995

Epoch: 6| Step: 13
Training loss: 2.1551618576049805
Validation loss: 2.1496448715527854

Epoch: 213| Step: 0
Training loss: 1.1629655361175537
Validation loss: 2.138058920701345

Epoch: 6| Step: 1
Training loss: 2.305849313735962
Validation loss: 2.1335948506991067

Epoch: 6| Step: 2
Training loss: 1.735180377960205
Validation loss: 2.1287597020467124

Epoch: 6| Step: 3
Training loss: 2.1718602180480957
Validation loss: 2.14253693819046

Epoch: 6| Step: 4
Training loss: 2.293653964996338
Validation loss: 2.13439550002416

Epoch: 6| Step: 5
Training loss: 1.9256170988082886
Validation loss: 2.1160284280776978

Epoch: 6| Step: 6
Training loss: 2.0917446613311768
Validation loss: 2.1176820397377014

Epoch: 6| Step: 7
Training loss: 1.9648890495300293
Validation loss: 2.1085650523503623

Epoch: 6| Step: 8
Training loss: 1.5705927610397339
Validation loss: 2.1274826725323996

Epoch: 6| Step: 9
Training loss: 1.9516801834106445
Validation loss: 2.1309287945429483

Epoch: 6| Step: 10
Training loss: 1.8265734910964966
Validation loss: 2.1242611606915793

Epoch: 6| Step: 11
Training loss: 1.849684476852417
Validation loss: 2.1260692874590554

Epoch: 6| Step: 12
Training loss: 2.0232348442077637
Validation loss: 2.1298327247301736

Epoch: 6| Step: 13
Training loss: 1.6906710863113403
Validation loss: 2.1465874512990317

Epoch: 214| Step: 0
Training loss: 1.4020466804504395
Validation loss: 2.1385615468025208

Epoch: 6| Step: 1
Training loss: 2.13053297996521
Validation loss: 2.1610480348269143

Epoch: 6| Step: 2
Training loss: 1.751140832901001
Validation loss: 2.16223673025767

Epoch: 6| Step: 3
Training loss: 1.5326578617095947
Validation loss: 2.1496503353118896

Epoch: 6| Step: 4
Training loss: 1.953674077987671
Validation loss: 2.148031214872996

Epoch: 6| Step: 5
Training loss: 1.2227063179016113
Validation loss: 2.152092178662618

Epoch: 6| Step: 6
Training loss: 1.791552186012268
Validation loss: 2.162838637828827

Epoch: 6| Step: 7
Training loss: 2.1207170486450195
Validation loss: 2.1472444931666055

Epoch: 6| Step: 8
Training loss: 1.9797357320785522
Validation loss: 2.1383269627889

Epoch: 6| Step: 9
Training loss: 1.8081988096237183
Validation loss: 2.138738671938578

Epoch: 6| Step: 10
Training loss: 2.9828097820281982
Validation loss: 2.1401729186375937

Epoch: 6| Step: 11
Training loss: 1.7624541521072388
Validation loss: 2.122726341088613

Epoch: 6| Step: 12
Training loss: 1.8569328784942627
Validation loss: 2.1309606035550437

Epoch: 6| Step: 13
Training loss: 2.2225749492645264
Validation loss: 2.1206325689951577

Epoch: 215| Step: 0
Training loss: 1.4982647895812988
Validation loss: 2.1384385228157043

Epoch: 6| Step: 1
Training loss: 1.7220208644866943
Validation loss: 2.142800788084666

Epoch: 6| Step: 2
Training loss: 1.7394452095031738
Validation loss: 2.158076743284861

Epoch: 6| Step: 3
Training loss: 1.550077199935913
Validation loss: 2.1393632292747498

Epoch: 6| Step: 4
Training loss: 1.8241454362869263
Validation loss: 2.1408795714378357

Epoch: 6| Step: 5
Training loss: 2.016371726989746
Validation loss: 2.157026469707489

Epoch: 6| Step: 6
Training loss: 2.2565698623657227
Validation loss: 2.174591302871704

Epoch: 6| Step: 7
Training loss: 2.1792540550231934
Validation loss: 2.149307588736216

Epoch: 6| Step: 8
Training loss: 1.7135660648345947
Validation loss: 2.1593404014905295

Epoch: 6| Step: 9
Training loss: 1.897783875465393
Validation loss: 2.1545854012171426

Epoch: 6| Step: 10
Training loss: 2.271688938140869
Validation loss: 2.174923380215963

Epoch: 6| Step: 11
Training loss: 2.119692802429199
Validation loss: 2.160320599873861

Epoch: 6| Step: 12
Training loss: 1.746030330657959
Validation loss: 2.137736976146698

Epoch: 6| Step: 13
Training loss: 2.209120750427246
Validation loss: 2.1545845667521157

Epoch: 216| Step: 0
Training loss: 1.5264477729797363
Validation loss: 2.1621281703313193

Epoch: 6| Step: 1
Training loss: 2.1800224781036377
Validation loss: 2.161014993985494

Epoch: 6| Step: 2
Training loss: 1.2796213626861572
Validation loss: 2.12751696507136

Epoch: 6| Step: 3
Training loss: 2.854576587677002
Validation loss: 2.1344191431999207

Epoch: 6| Step: 4
Training loss: 2.443072557449341
Validation loss: 2.124846637248993

Epoch: 6| Step: 5
Training loss: 1.7199742794036865
Validation loss: 2.125660320123037

Epoch: 6| Step: 6
Training loss: 2.3338088989257812
Validation loss: 2.1239996949831643

Epoch: 6| Step: 7
Training loss: 1.679990530014038
Validation loss: 2.120019515355428

Epoch: 6| Step: 8
Training loss: 1.48099684715271
Validation loss: 2.131960471471151

Epoch: 6| Step: 9
Training loss: 1.731344223022461
Validation loss: 2.1161637902259827

Epoch: 6| Step: 10
Training loss: 1.703078269958496
Validation loss: 2.1281055212020874

Epoch: 6| Step: 11
Training loss: 2.275451421737671
Validation loss: 2.1174391706784568

Epoch: 6| Step: 12
Training loss: 1.499934434890747
Validation loss: 2.1358065406481423

Epoch: 6| Step: 13
Training loss: 1.8328440189361572
Validation loss: 2.158577640851339

Epoch: 217| Step: 0
Training loss: 1.4816498756408691
Validation loss: 2.158782422542572

Epoch: 6| Step: 1
Training loss: 1.7348980903625488
Validation loss: 2.152274509270986

Epoch: 6| Step: 2
Training loss: 1.7479743957519531
Validation loss: 2.167836387952169

Epoch: 6| Step: 3
Training loss: 2.1756930351257324
Validation loss: 2.145691156387329

Epoch: 6| Step: 4
Training loss: 1.420578956604004
Validation loss: 2.1635517279307046

Epoch: 6| Step: 5
Training loss: 1.6008501052856445
Validation loss: 2.1551876266797385

Epoch: 6| Step: 6
Training loss: 1.7889598608016968
Validation loss: 2.1328248580296836

Epoch: 6| Step: 7
Training loss: 1.9377238750457764
Validation loss: 2.148961067199707

Epoch: 6| Step: 8
Training loss: 2.4571585655212402
Validation loss: 2.1351170738538108

Epoch: 6| Step: 9
Training loss: 2.4063522815704346
Validation loss: 2.128471076488495

Epoch: 6| Step: 10
Training loss: 1.5040309429168701
Validation loss: 2.13755863904953

Epoch: 6| Step: 11
Training loss: 2.3061068058013916
Validation loss: 2.139215330282847

Epoch: 6| Step: 12
Training loss: 1.9455243349075317
Validation loss: 2.1529603401819863

Epoch: 6| Step: 13
Training loss: 1.7595150470733643
Validation loss: 2.138023058573405

Epoch: 218| Step: 0
Training loss: 2.241511821746826
Validation loss: 2.1263517340024314

Epoch: 6| Step: 1
Training loss: 1.556679368019104
Validation loss: 2.1312881906827292

Epoch: 6| Step: 2
Training loss: 2.024209976196289
Validation loss: 2.1093848943710327

Epoch: 6| Step: 3
Training loss: 1.8461835384368896
Validation loss: 2.1157009998957315

Epoch: 6| Step: 4
Training loss: 1.4622154235839844
Validation loss: 2.1233644485473633

Epoch: 6| Step: 5
Training loss: 1.9549236297607422
Validation loss: 2.145258108774821

Epoch: 6| Step: 6
Training loss: 1.94684898853302
Validation loss: 2.130389173825582

Epoch: 6| Step: 7
Training loss: 2.4743709564208984
Validation loss: 2.1396940549214682

Epoch: 6| Step: 8
Training loss: 2.0248403549194336
Validation loss: 2.142391085624695

Epoch: 6| Step: 9
Training loss: 2.476203441619873
Validation loss: 2.148308356602987

Epoch: 6| Step: 10
Training loss: 1.4375531673431396
Validation loss: 2.1379602750142417

Epoch: 6| Step: 11
Training loss: 1.702576756477356
Validation loss: 2.1315571665763855

Epoch: 6| Step: 12
Training loss: 1.636972427368164
Validation loss: 2.166592836380005

Epoch: 6| Step: 13
Training loss: 1.8641996383666992
Validation loss: 2.1502156853675842

Epoch: 219| Step: 0
Training loss: 2.592895746231079
Validation loss: 2.1424078146616616

Epoch: 6| Step: 1
Training loss: 2.1674563884735107
Validation loss: 2.135550618171692

Epoch: 6| Step: 2
Training loss: 1.8565438985824585
Validation loss: 2.1400301655133567

Epoch: 6| Step: 3
Training loss: 2.0192391872406006
Validation loss: 2.1390220522880554

Epoch: 6| Step: 4
Training loss: 1.1354495286941528
Validation loss: 2.115887383619944

Epoch: 6| Step: 5
Training loss: 1.9725127220153809
Validation loss: 2.1414026618003845

Epoch: 6| Step: 6
Training loss: 1.6727527379989624
Validation loss: 2.1234830617904663

Epoch: 6| Step: 7
Training loss: 2.173696756362915
Validation loss: 2.1296251813570657

Epoch: 6| Step: 8
Training loss: 2.3862922191619873
Validation loss: 2.1254115104675293

Epoch: 6| Step: 9
Training loss: 1.5868136882781982
Validation loss: 2.125534196694692

Epoch: 6| Step: 10
Training loss: 1.7282953262329102
Validation loss: 2.141579349835714

Epoch: 6| Step: 11
Training loss: 2.119293451309204
Validation loss: 2.144475738207499

Epoch: 6| Step: 12
Training loss: 2.140357494354248
Validation loss: 2.1571670373280845

Epoch: 6| Step: 13
Training loss: 1.157043218612671
Validation loss: 2.1567633152008057

Epoch: 220| Step: 0
Training loss: 2.2016191482543945
Validation loss: 2.161321004231771

Epoch: 6| Step: 1
Training loss: 1.183752417564392
Validation loss: 2.149833599726359

Epoch: 6| Step: 2
Training loss: 1.5155802965164185
Validation loss: 2.1593023339907327

Epoch: 6| Step: 3
Training loss: 1.5191682577133179
Validation loss: 2.1623341043790183

Epoch: 6| Step: 4
Training loss: 1.9957327842712402
Validation loss: 2.140069544315338

Epoch: 6| Step: 5
Training loss: 2.28814959526062
Validation loss: 2.1510525345802307

Epoch: 6| Step: 6
Training loss: 2.594871997833252
Validation loss: 2.1672056516011557

Epoch: 6| Step: 7
Training loss: 1.8685742616653442
Validation loss: 2.158893346786499

Epoch: 6| Step: 8
Training loss: 2.1888561248779297
Validation loss: 2.151030639807383

Epoch: 6| Step: 9
Training loss: 1.6265404224395752
Validation loss: 2.1435388922691345

Epoch: 6| Step: 10
Training loss: 1.360605239868164
Validation loss: 2.148887058099111

Epoch: 6| Step: 11
Training loss: 2.1254053115844727
Validation loss: 2.1579257051150003

Epoch: 6| Step: 12
Training loss: 2.4014554023742676
Validation loss: 2.165935516357422

Epoch: 6| Step: 13
Training loss: 1.5224666595458984
Validation loss: 2.167350788911184

Epoch: 221| Step: 0
Training loss: 2.4542202949523926
Validation loss: 2.1580401261647544

Epoch: 6| Step: 1
Training loss: 1.121546745300293
Validation loss: 2.1685407161712646

Epoch: 6| Step: 2
Training loss: 1.3008646965026855
Validation loss: 2.1741908192634583

Epoch: 6| Step: 3
Training loss: 1.9357293844223022
Validation loss: 2.1585174997647605

Epoch: 6| Step: 4
Training loss: 1.808823823928833
Validation loss: 2.1506075660387673

Epoch: 6| Step: 5
Training loss: 1.8268864154815674
Validation loss: 2.1572846372922263

Epoch: 6| Step: 6
Training loss: 1.7128677368164062
Validation loss: 2.1453789472579956

Epoch: 6| Step: 7
Training loss: 2.131810188293457
Validation loss: 2.1489080786705017

Epoch: 6| Step: 8
Training loss: 1.910593867301941
Validation loss: 2.1394185622533164

Epoch: 6| Step: 9
Training loss: 2.1092495918273926
Validation loss: 2.1646885673205056

Epoch: 6| Step: 10
Training loss: 2.0502877235412598
Validation loss: 2.1648542086283364

Epoch: 6| Step: 11
Training loss: 2.0009021759033203
Validation loss: 2.1709439953168235

Epoch: 6| Step: 12
Training loss: 2.2568137645721436
Validation loss: 2.1782431999842324

Epoch: 6| Step: 13
Training loss: 1.799263834953308
Validation loss: 2.1826868851979575

Epoch: 222| Step: 0
Training loss: 1.8042047023773193
Validation loss: 2.1767439444859824

Epoch: 6| Step: 1
Training loss: 1.848952293395996
Validation loss: 2.1459502975145974

Epoch: 6| Step: 2
Training loss: 1.6315581798553467
Validation loss: 2.1293946703275046

Epoch: 6| Step: 3
Training loss: 1.9521281719207764
Validation loss: 2.1300638914108276

Epoch: 6| Step: 4
Training loss: 1.8819559812545776
Validation loss: 2.1366335352261863

Epoch: 6| Step: 5
Training loss: 2.2257070541381836
Validation loss: 2.1608188152313232

Epoch: 6| Step: 6
Training loss: 1.680675983428955
Validation loss: 2.155133684476217

Epoch: 6| Step: 7
Training loss: 2.117624044418335
Validation loss: 2.1423526207605996

Epoch: 6| Step: 8
Training loss: 1.3630313873291016
Validation loss: 2.149926463762919

Epoch: 6| Step: 9
Training loss: 1.307067632675171
Validation loss: 2.158681352933248

Epoch: 6| Step: 10
Training loss: 2.204540252685547
Validation loss: 2.168123245239258

Epoch: 6| Step: 11
Training loss: 1.7567358016967773
Validation loss: 2.158480962117513

Epoch: 6| Step: 12
Training loss: 2.4678800106048584
Validation loss: 2.1404921611150107

Epoch: 6| Step: 13
Training loss: 2.31819486618042
Validation loss: 2.120946228504181

Epoch: 223| Step: 0
Training loss: 2.1254379749298096
Validation loss: 2.116900940736135

Epoch: 6| Step: 1
Training loss: 1.8798058032989502
Validation loss: 2.1347659826278687

Epoch: 6| Step: 2
Training loss: 2.228949546813965
Validation loss: 2.122763514518738

Epoch: 6| Step: 3
Training loss: 1.8311271667480469
Validation loss: 2.1205779314041138

Epoch: 6| Step: 4
Training loss: 1.7693678140640259
Validation loss: 2.130867878595988

Epoch: 6| Step: 5
Training loss: 2.4522194862365723
Validation loss: 2.1485092838605246

Epoch: 6| Step: 6
Training loss: 1.7520053386688232
Validation loss: 2.144493877887726

Epoch: 6| Step: 7
Training loss: 3.088287830352783
Validation loss: 2.1411251227060952

Epoch: 6| Step: 8
Training loss: 1.6494863033294678
Validation loss: 2.1478770971298218

Epoch: 6| Step: 9
Training loss: 2.2733538150787354
Validation loss: 2.134700338045756

Epoch: 6| Step: 10
Training loss: 1.0435547828674316
Validation loss: 2.136964956919352

Epoch: 6| Step: 11
Training loss: 1.4449429512023926
Validation loss: 2.1429183085759482

Epoch: 6| Step: 12
Training loss: 1.526413917541504
Validation loss: 2.1726461052894592

Epoch: 6| Step: 13
Training loss: 1.2742772102355957
Validation loss: 2.1709097822507224

Epoch: 224| Step: 0
Training loss: 1.540798306465149
Validation loss: 2.173359493414561

Epoch: 6| Step: 1
Training loss: 2.14861798286438
Validation loss: 2.187666594982147

Epoch: 6| Step: 2
Training loss: 2.588416576385498
Validation loss: 2.1694904565811157

Epoch: 6| Step: 3
Training loss: 2.2554450035095215
Validation loss: 2.171856184800466

Epoch: 6| Step: 4
Training loss: 1.7447761297225952
Validation loss: 2.175301949183146

Epoch: 6| Step: 5
Training loss: 1.465369701385498
Validation loss: 2.1607032815615335

Epoch: 6| Step: 6
Training loss: 1.4025481939315796
Validation loss: 2.1760902802149453

Epoch: 6| Step: 7
Training loss: 1.453640103340149
Validation loss: 2.1632035175959268

Epoch: 6| Step: 8
Training loss: 1.3165743350982666
Validation loss: 2.1687846779823303

Epoch: 6| Step: 9
Training loss: 2.383092164993286
Validation loss: 2.175364832083384

Epoch: 6| Step: 10
Training loss: 2.1194663047790527
Validation loss: 2.171276648839315

Epoch: 6| Step: 11
Training loss: 1.771835207939148
Validation loss: 2.1691176096598306

Epoch: 6| Step: 12
Training loss: 1.7820357084274292
Validation loss: 2.151910722255707

Epoch: 6| Step: 13
Training loss: 2.1829230785369873
Validation loss: 2.1195189356803894

Epoch: 225| Step: 0
Training loss: 2.2635698318481445
Validation loss: 2.130045394102732

Epoch: 6| Step: 1
Training loss: 1.4403746128082275
Validation loss: 2.1129492123921714

Epoch: 6| Step: 2
Training loss: 1.4715080261230469
Validation loss: 2.133122285207113

Epoch: 6| Step: 3
Training loss: 2.2146401405334473
Validation loss: 2.137395441532135

Epoch: 6| Step: 4
Training loss: 1.8685302734375
Validation loss: 2.1498148838678994

Epoch: 6| Step: 5
Training loss: 2.2866640090942383
Validation loss: 2.158705155054728

Epoch: 6| Step: 6
Training loss: 1.4989264011383057
Validation loss: 2.168340802192688

Epoch: 6| Step: 7
Training loss: 1.6649072170257568
Validation loss: 2.1682143211364746

Epoch: 6| Step: 8
Training loss: 2.1542110443115234
Validation loss: 2.17991308371226

Epoch: 6| Step: 9
Training loss: 2.12668776512146
Validation loss: 2.1710803707440696

Epoch: 6| Step: 10
Training loss: 1.7984787225723267
Validation loss: 2.1732850074768066

Epoch: 6| Step: 11
Training loss: 1.9306282997131348
Validation loss: 2.1704755822817483

Epoch: 6| Step: 12
Training loss: 1.8958489894866943
Validation loss: 2.1824456453323364

Epoch: 6| Step: 13
Training loss: 1.7624280452728271
Validation loss: 2.169164001941681

Epoch: 226| Step: 0
Training loss: 1.796128511428833
Validation loss: 2.1657097339630127

Epoch: 6| Step: 1
Training loss: 1.325836181640625
Validation loss: 2.163136839866638

Epoch: 6| Step: 2
Training loss: 1.9082705974578857
Validation loss: 2.166233718395233

Epoch: 6| Step: 3
Training loss: 1.9180147647857666
Validation loss: 2.1252692143122354

Epoch: 6| Step: 4
Training loss: 1.969158411026001
Validation loss: 2.154862662156423

Epoch: 6| Step: 5
Training loss: 2.149135112762451
Validation loss: 2.151228646437327

Epoch: 6| Step: 6
Training loss: 2.035804271697998
Validation loss: 2.1482863624890647

Epoch: 6| Step: 7
Training loss: 1.8986482620239258
Validation loss: 2.1181671818097434

Epoch: 6| Step: 8
Training loss: 2.1434590816497803
Validation loss: 2.115473469098409

Epoch: 6| Step: 9
Training loss: 1.5724657773971558
Validation loss: 2.103156566619873

Epoch: 6| Step: 10
Training loss: 2.043701410293579
Validation loss: 2.1261348525683084

Epoch: 6| Step: 11
Training loss: 1.6170623302459717
Validation loss: 2.112595498561859

Epoch: 6| Step: 12
Training loss: 2.462480068206787
Validation loss: 2.1158480842908225

Epoch: 6| Step: 13
Training loss: 2.3084521293640137
Validation loss: 2.112713932991028

Epoch: 227| Step: 0
Training loss: 1.6960549354553223
Validation loss: 2.1266253193219504

Epoch: 6| Step: 1
Training loss: 2.0381221771240234
Validation loss: 2.1513073643048606

Epoch: 6| Step: 2
Training loss: 1.7270408868789673
Validation loss: 2.154401659965515

Epoch: 6| Step: 3
Training loss: 1.765397310256958
Validation loss: 2.1505348285039267

Epoch: 6| Step: 4
Training loss: 1.9970468282699585
Validation loss: 2.147467235724131

Epoch: 6| Step: 5
Training loss: 2.4955711364746094
Validation loss: 2.152074654897054

Epoch: 6| Step: 6
Training loss: 1.6194064617156982
Validation loss: 2.1673120061556497

Epoch: 6| Step: 7
Training loss: 2.793984889984131
Validation loss: 2.166863660017649

Epoch: 6| Step: 8
Training loss: 2.2292966842651367
Validation loss: 2.166231632232666

Epoch: 6| Step: 9
Training loss: 1.6692612171173096
Validation loss: 2.159529983997345

Epoch: 6| Step: 10
Training loss: 2.434330701828003
Validation loss: 2.1605001290639243

Epoch: 6| Step: 11
Training loss: 1.6426715850830078
Validation loss: 2.159087856610616

Epoch: 6| Step: 12
Training loss: 1.2741063833236694
Validation loss: 2.144381582736969

Epoch: 6| Step: 13
Training loss: 1.2118308544158936
Validation loss: 2.1443294088045755

Epoch: 228| Step: 0
Training loss: 2.0760457515716553
Validation loss: 2.136770566304525

Epoch: 6| Step: 1
Training loss: 2.1457977294921875
Validation loss: 2.1230350335439048

Epoch: 6| Step: 2
Training loss: 2.1384472846984863
Validation loss: 2.1070823073387146

Epoch: 6| Step: 3
Training loss: 1.9186644554138184
Validation loss: 2.1186765233675637

Epoch: 6| Step: 4
Training loss: 2.4394407272338867
Validation loss: 2.1215394139289856

Epoch: 6| Step: 5
Training loss: 1.889040231704712
Validation loss: 2.1059828797976174

Epoch: 6| Step: 6
Training loss: 1.5002634525299072
Validation loss: 2.116424878438314

Epoch: 6| Step: 7
Training loss: 1.835051417350769
Validation loss: 2.12679131825765

Epoch: 6| Step: 8
Training loss: 1.3468880653381348
Validation loss: 2.1463247537612915

Epoch: 6| Step: 9
Training loss: 2.2000248432159424
Validation loss: 2.166864514350891

Epoch: 6| Step: 10
Training loss: 1.8974494934082031
Validation loss: 2.1585291624069214

Epoch: 6| Step: 11
Training loss: 1.3372931480407715
Validation loss: 2.173198103904724

Epoch: 6| Step: 12
Training loss: 1.6542056798934937
Validation loss: 2.1730268796284995

Epoch: 6| Step: 13
Training loss: 1.8350790739059448
Validation loss: 2.1565699378649392

Epoch: 229| Step: 0
Training loss: 1.7968711853027344
Validation loss: 2.1675896048545837

Epoch: 6| Step: 1
Training loss: 1.7292017936706543
Validation loss: 2.1481029391288757

Epoch: 6| Step: 2
Training loss: 1.4790478944778442
Validation loss: 2.1399364868799844

Epoch: 6| Step: 3
Training loss: 1.2848316431045532
Validation loss: 2.159525215625763

Epoch: 6| Step: 4
Training loss: 2.1941895484924316
Validation loss: 2.1691361467043557

Epoch: 6| Step: 5
Training loss: 1.618977665901184
Validation loss: 2.172252833843231

Epoch: 6| Step: 6
Training loss: 2.771385669708252
Validation loss: 2.173462927341461

Epoch: 6| Step: 7
Training loss: 1.409250020980835
Validation loss: 2.174185872077942

Epoch: 6| Step: 8
Training loss: 2.168229818344116
Validation loss: 2.16399077574412

Epoch: 6| Step: 9
Training loss: 2.1008596420288086
Validation loss: 2.171710968017578

Epoch: 6| Step: 10
Training loss: 2.0678818225860596
Validation loss: 2.1588990887006125

Epoch: 6| Step: 11
Training loss: 1.885972023010254
Validation loss: 2.1806746125221252

Epoch: 6| Step: 12
Training loss: 1.7034004926681519
Validation loss: 2.153268317381541

Epoch: 6| Step: 13
Training loss: 1.857713222503662
Validation loss: 2.1663021246592202

Epoch: 230| Step: 0
Training loss: 1.1310169696807861
Validation loss: 2.1540953119595847

Epoch: 6| Step: 1
Training loss: 1.6778364181518555
Validation loss: 2.163473109404246

Epoch: 6| Step: 2
Training loss: 1.4521820545196533
Validation loss: 2.1576662063598633

Epoch: 6| Step: 3
Training loss: 1.567340612411499
Validation loss: 2.1504544814427695

Epoch: 6| Step: 4
Training loss: 1.7693232297897339
Validation loss: 2.1551336646080017

Epoch: 6| Step: 5
Training loss: 1.723449468612671
Validation loss: 2.152641554673513

Epoch: 6| Step: 6
Training loss: 1.8421183824539185
Validation loss: 2.1458336114883423

Epoch: 6| Step: 7
Training loss: 2.1669039726257324
Validation loss: 2.1492318709691367

Epoch: 6| Step: 8
Training loss: 2.516979217529297
Validation loss: 2.1548312505086265

Epoch: 6| Step: 9
Training loss: 2.4536542892456055
Validation loss: 2.161054809888204

Epoch: 6| Step: 10
Training loss: 1.84641695022583
Validation loss: 2.14162947734197

Epoch: 6| Step: 11
Training loss: 2.218886375427246
Validation loss: 2.143241743246714

Epoch: 6| Step: 12
Training loss: 1.9305238723754883
Validation loss: 2.1568631529808044

Epoch: 6| Step: 13
Training loss: 2.0139031410217285
Validation loss: 2.157819906870524

Epoch: 231| Step: 0
Training loss: 0.8056477904319763
Validation loss: 2.17402982711792

Epoch: 6| Step: 1
Training loss: 2.2830488681793213
Validation loss: 2.1806474725405374

Epoch: 6| Step: 2
Training loss: 1.8193902969360352
Validation loss: 2.1834000746409097

Epoch: 6| Step: 3
Training loss: 1.445363998413086
Validation loss: 2.1696015993754068

Epoch: 6| Step: 4
Training loss: 2.1509933471679688
Validation loss: 2.1766274770100913

Epoch: 6| Step: 5
Training loss: 1.7814689874649048
Validation loss: 2.130491852760315

Epoch: 6| Step: 6
Training loss: 2.1089000701904297
Validation loss: 2.1493423183759055

Epoch: 6| Step: 7
Training loss: 1.6290404796600342
Validation loss: 2.153605858484904

Epoch: 6| Step: 8
Training loss: 1.3234972953796387
Validation loss: 2.154526174068451

Epoch: 6| Step: 9
Training loss: 2.78127384185791
Validation loss: 2.141138195991516

Epoch: 6| Step: 10
Training loss: 2.0762109756469727
Validation loss: 2.1675134102503457

Epoch: 6| Step: 11
Training loss: 2.193934917449951
Validation loss: 2.155363221963247

Epoch: 6| Step: 12
Training loss: 1.6994266510009766
Validation loss: 2.1568390528361

Epoch: 6| Step: 13
Training loss: 1.5400972366333008
Validation loss: 2.16988468170166

Epoch: 232| Step: 0
Training loss: 1.7244179248809814
Validation loss: 2.1741656064987183

Epoch: 6| Step: 1
Training loss: 1.7852883338928223
Validation loss: 2.1579248309135437

Epoch: 6| Step: 2
Training loss: 1.5311062335968018
Validation loss: 2.1764359871546426

Epoch: 6| Step: 3
Training loss: 1.5012140274047852
Validation loss: 2.1541627645492554

Epoch: 6| Step: 4
Training loss: 2.2602343559265137
Validation loss: 2.16865336894989

Epoch: 6| Step: 5
Training loss: 1.3779263496398926
Validation loss: 2.169392744700114

Epoch: 6| Step: 6
Training loss: 2.385077953338623
Validation loss: 2.1636391083399453

Epoch: 6| Step: 7
Training loss: 2.325500011444092
Validation loss: 2.1755771040916443

Epoch: 6| Step: 8
Training loss: 1.5478309392929077
Validation loss: 2.172855575879415

Epoch: 6| Step: 9
Training loss: 1.6695680618286133
Validation loss: 2.1607172886530557

Epoch: 6| Step: 10
Training loss: 2.049948215484619
Validation loss: 2.17321914434433

Epoch: 6| Step: 11
Training loss: 1.7559762001037598
Validation loss: 2.1644054651260376

Epoch: 6| Step: 12
Training loss: 2.0063562393188477
Validation loss: 2.1684906085332236

Epoch: 6| Step: 13
Training loss: 2.099393367767334
Validation loss: 2.1614617307980857

Epoch: 233| Step: 0
Training loss: 1.897526741027832
Validation loss: 2.1715227564175925

Epoch: 6| Step: 1
Training loss: 2.4560437202453613
Validation loss: 2.1813891927401223

Epoch: 6| Step: 2
Training loss: 1.3757460117340088
Validation loss: 2.191221276919047

Epoch: 6| Step: 3
Training loss: 1.4433445930480957
Validation loss: 2.1691677967707315

Epoch: 6| Step: 4
Training loss: 1.8717572689056396
Validation loss: 2.183017909526825

Epoch: 6| Step: 5
Training loss: 1.5501766204833984
Validation loss: 2.1667758425076804

Epoch: 6| Step: 6
Training loss: 1.4865366220474243
Validation loss: 2.190401077270508

Epoch: 6| Step: 7
Training loss: 1.9202865362167358
Validation loss: 2.1801356871922812

Epoch: 6| Step: 8
Training loss: 1.9187586307525635
Validation loss: 2.1908653179804483

Epoch: 6| Step: 9
Training loss: 2.1855416297912598
Validation loss: 2.190450429916382

Epoch: 6| Step: 10
Training loss: 2.282841205596924
Validation loss: 2.1681076685587564

Epoch: 6| Step: 11
Training loss: 1.7524657249450684
Validation loss: 2.161163628101349

Epoch: 6| Step: 12
Training loss: 2.108628273010254
Validation loss: 2.1765548388163247

Epoch: 6| Step: 13
Training loss: 1.2651015520095825
Validation loss: 2.1563636461893716

Epoch: 234| Step: 0
Training loss: 1.8274576663970947
Validation loss: 2.1412309606870017

Epoch: 6| Step: 1
Training loss: 1.4447596073150635
Validation loss: 2.116534491380056

Epoch: 6| Step: 2
Training loss: 2.1451644897460938
Validation loss: 2.1250762939453125

Epoch: 6| Step: 3
Training loss: 1.6471871137619019
Validation loss: 2.1055140296618142

Epoch: 6| Step: 4
Training loss: 2.204834222793579
Validation loss: 2.1215121944745383

Epoch: 6| Step: 5
Training loss: 2.229569435119629
Validation loss: 2.121975898742676

Epoch: 6| Step: 6
Training loss: 2.8265857696533203
Validation loss: 2.1229043006896973

Epoch: 6| Step: 7
Training loss: 1.5558102130889893
Validation loss: 2.1200055877367654

Epoch: 6| Step: 8
Training loss: 2.2916648387908936
Validation loss: 2.1122838258743286

Epoch: 6| Step: 9
Training loss: 2.5063793659210205
Validation loss: 2.118630111217499

Epoch: 6| Step: 10
Training loss: 1.9220435619354248
Validation loss: 2.1176772713661194

Epoch: 6| Step: 11
Training loss: 1.9185940027236938
Validation loss: 2.1357955733935037

Epoch: 6| Step: 12
Training loss: 1.2793445587158203
Validation loss: 2.1538906693458557

Epoch: 6| Step: 13
Training loss: 1.2987443208694458
Validation loss: 2.158562978108724

Epoch: 235| Step: 0
Training loss: 1.2524257898330688
Validation loss: 2.1712998151779175

Epoch: 6| Step: 1
Training loss: 1.6734442710876465
Validation loss: 2.174965222676595

Epoch: 6| Step: 2
Training loss: 3.033881187438965
Validation loss: 2.163871109485626

Epoch: 6| Step: 3
Training loss: 2.1652536392211914
Validation loss: 2.196599324544271

Epoch: 6| Step: 4
Training loss: 1.8442795276641846
Validation loss: 2.1797879139582315

Epoch: 6| Step: 5
Training loss: 2.4704723358154297
Validation loss: 2.199229637781779

Epoch: 6| Step: 6
Training loss: 1.2291648387908936
Validation loss: 2.1870669523874917

Epoch: 6| Step: 7
Training loss: 1.4359201192855835
Validation loss: 2.1825974782307944

Epoch: 6| Step: 8
Training loss: 1.7872693538665771
Validation loss: 2.169799327850342

Epoch: 6| Step: 9
Training loss: 1.5978659391403198
Validation loss: 2.159243106842041

Epoch: 6| Step: 10
Training loss: 1.9031555652618408
Validation loss: 2.1705983678499856

Epoch: 6| Step: 11
Training loss: 1.8413238525390625
Validation loss: 2.1552155017852783

Epoch: 6| Step: 12
Training loss: 2.2385478019714355
Validation loss: 2.150046706199646

Epoch: 6| Step: 13
Training loss: 2.3457016944885254
Validation loss: 2.1504785815874734

Epoch: 236| Step: 0
Training loss: 2.044233798980713
Validation loss: 2.1440720160802207

Epoch: 6| Step: 1
Training loss: 1.6984522342681885
Validation loss: 2.150785724322001

Epoch: 6| Step: 2
Training loss: 2.3717947006225586
Validation loss: 2.1550989548365274

Epoch: 6| Step: 3
Training loss: 2.0647382736206055
Validation loss: 2.158949633439382

Epoch: 6| Step: 4
Training loss: 1.9240975379943848
Validation loss: 2.16736767689387

Epoch: 6| Step: 5
Training loss: 2.049363613128662
Validation loss: 2.1639479796091714

Epoch: 6| Step: 6
Training loss: 1.2526025772094727
Validation loss: 2.168548266092936

Epoch: 6| Step: 7
Training loss: 1.613797903060913
Validation loss: 2.1819349924723306

Epoch: 6| Step: 8
Training loss: 1.8053735494613647
Validation loss: 2.188529133796692

Epoch: 6| Step: 9
Training loss: 2.2306935787200928
Validation loss: 2.1970247824986777

Epoch: 6| Step: 10
Training loss: 0.9851422309875488
Validation loss: 2.2082146207491555

Epoch: 6| Step: 11
Training loss: 1.7204971313476562
Validation loss: 2.1694878339767456

Epoch: 6| Step: 12
Training loss: 2.2842211723327637
Validation loss: 2.1803078651428223

Epoch: 6| Step: 13
Training loss: 2.3359603881835938
Validation loss: 2.193243940671285

Epoch: 237| Step: 0
Training loss: 1.6394692659378052
Validation loss: 2.17530357837677

Epoch: 6| Step: 1
Training loss: 2.1176257133483887
Validation loss: 2.17619522412618

Epoch: 6| Step: 2
Training loss: 1.7881221771240234
Validation loss: 2.1763731042544046

Epoch: 6| Step: 3
Training loss: 1.7951240539550781
Validation loss: 2.1835163633028665

Epoch: 6| Step: 4
Training loss: 2.5418131351470947
Validation loss: 2.1865269541740417

Epoch: 6| Step: 5
Training loss: 1.6380736827850342
Validation loss: 2.172260026137034

Epoch: 6| Step: 6
Training loss: 1.639304518699646
Validation loss: 2.171261747678121

Epoch: 6| Step: 7
Training loss: 1.6055792570114136
Validation loss: 2.16654771566391

Epoch: 6| Step: 8
Training loss: 1.7304902076721191
Validation loss: 2.1765458583831787

Epoch: 6| Step: 9
Training loss: 1.5071868896484375
Validation loss: 2.167061765988668

Epoch: 6| Step: 10
Training loss: 2.272472381591797
Validation loss: 2.1712493896484375

Epoch: 6| Step: 11
Training loss: 1.3398325443267822
Validation loss: 2.171109159787496

Epoch: 6| Step: 12
Training loss: 1.9876108169555664
Validation loss: 2.182784597078959

Epoch: 6| Step: 13
Training loss: 1.9035050868988037
Validation loss: 2.1754428346951804

Epoch: 238| Step: 0
Training loss: 1.105654001235962
Validation loss: 2.1854196985562644

Epoch: 6| Step: 1
Training loss: 1.7965284585952759
Validation loss: 2.184155523777008

Epoch: 6| Step: 2
Training loss: 2.069091796875
Validation loss: 2.1912242571512857

Epoch: 6| Step: 3
Training loss: 2.7733893394470215
Validation loss: 2.197062055269877

Epoch: 6| Step: 4
Training loss: 1.7085137367248535
Validation loss: 2.153770407040914

Epoch: 6| Step: 5
Training loss: 1.7763561010360718
Validation loss: 2.176420251528422

Epoch: 6| Step: 6
Training loss: 0.8872973918914795
Validation loss: 2.166871170202891

Epoch: 6| Step: 7
Training loss: 2.0042855739593506
Validation loss: 2.179670770963033

Epoch: 6| Step: 8
Training loss: 1.9594173431396484
Validation loss: 2.186920702457428

Epoch: 6| Step: 9
Training loss: 1.7576807737350464
Validation loss: 2.1932472387949624

Epoch: 6| Step: 10
Training loss: 1.533583402633667
Validation loss: 2.1856949726740518

Epoch: 6| Step: 11
Training loss: 2.634568691253662
Validation loss: 2.196342349052429

Epoch: 6| Step: 12
Training loss: 1.3177891969680786
Validation loss: 2.193080464998881

Epoch: 6| Step: 13
Training loss: 2.007373094558716
Validation loss: 2.1774036288261414

Epoch: 239| Step: 0
Training loss: 1.259289264678955
Validation loss: 2.1791392167409263

Epoch: 6| Step: 1
Training loss: 2.123208999633789
Validation loss: 2.1981418132781982

Epoch: 6| Step: 2
Training loss: 3.211033344268799
Validation loss: 2.18535848458608

Epoch: 6| Step: 3
Training loss: 1.544313907623291
Validation loss: 2.1687666177749634

Epoch: 6| Step: 4
Training loss: 1.7858035564422607
Validation loss: 2.2026931047439575

Epoch: 6| Step: 5
Training loss: 1.659761905670166
Validation loss: 2.1958839495976767

Epoch: 6| Step: 6
Training loss: 1.5641579627990723
Validation loss: 2.1723729769388833

Epoch: 6| Step: 7
Training loss: 1.1575593948364258
Validation loss: 2.1861984531084695

Epoch: 6| Step: 8
Training loss: 1.9038975238800049
Validation loss: 2.193159580230713

Epoch: 6| Step: 9
Training loss: 1.7089083194732666
Validation loss: 2.1859856446584067

Epoch: 6| Step: 10
Training loss: 2.0438289642333984
Validation loss: 2.189990242322286

Epoch: 6| Step: 11
Training loss: 1.3406288623809814
Validation loss: 2.167202274004618

Epoch: 6| Step: 12
Training loss: 2.2514688968658447
Validation loss: 2.1767627596855164

Epoch: 6| Step: 13
Training loss: 1.5911059379577637
Validation loss: 2.1708410382270813

Epoch: 240| Step: 0
Training loss: 1.5124536752700806
Validation loss: 2.167900502681732

Epoch: 6| Step: 1
Training loss: 2.332925796508789
Validation loss: 2.154552241166433

Epoch: 6| Step: 2
Training loss: 1.4404501914978027
Validation loss: 2.1507321198781333

Epoch: 6| Step: 3
Training loss: 1.9859684705734253
Validation loss: 2.1767786741256714

Epoch: 6| Step: 4
Training loss: 2.177248954772949
Validation loss: 2.1804577112197876

Epoch: 6| Step: 5
Training loss: 1.428800106048584
Validation loss: 2.1728660066922507

Epoch: 6| Step: 6
Training loss: 1.3965325355529785
Validation loss: 2.1656435330708823

Epoch: 6| Step: 7
Training loss: 1.4640014171600342
Validation loss: 2.176675001780192

Epoch: 6| Step: 8
Training loss: 1.6549967527389526
Validation loss: 2.1460034052530923

Epoch: 6| Step: 9
Training loss: 2.2646470069885254
Validation loss: 2.171394467353821

Epoch: 6| Step: 10
Training loss: 2.017976760864258
Validation loss: 2.174799084663391

Epoch: 6| Step: 11
Training loss: 1.8527624607086182
Validation loss: 2.1973885695139566

Epoch: 6| Step: 12
Training loss: 1.8379827737808228
Validation loss: 2.176332712173462

Epoch: 6| Step: 13
Training loss: 2.1624972820281982
Validation loss: 2.177966058254242

Epoch: 241| Step: 0
Training loss: 1.9154059886932373
Validation loss: 2.189894715944926

Epoch: 6| Step: 1
Training loss: 1.7949467897415161
Validation loss: 2.2047107219696045

Epoch: 6| Step: 2
Training loss: 1.586950421333313
Validation loss: 2.197671135266622

Epoch: 6| Step: 3
Training loss: 2.275618553161621
Validation loss: 2.210035502910614

Epoch: 6| Step: 4
Training loss: 1.5247851610183716
Validation loss: 2.2211370865503945

Epoch: 6| Step: 5
Training loss: 1.5849311351776123
Validation loss: 2.215912183125814

Epoch: 6| Step: 6
Training loss: 1.768308162689209
Validation loss: 2.1871410608291626

Epoch: 6| Step: 7
Training loss: 2.1999528408050537
Validation loss: 2.190509299437205

Epoch: 6| Step: 8
Training loss: 1.3822968006134033
Validation loss: 2.177993655204773

Epoch: 6| Step: 9
Training loss: 2.287135601043701
Validation loss: 2.167216638724009

Epoch: 6| Step: 10
Training loss: 2.358241081237793
Validation loss: 2.1210612654685974

Epoch: 6| Step: 11
Training loss: 1.5168261528015137
Validation loss: 2.123493413130442

Epoch: 6| Step: 12
Training loss: 2.028787136077881
Validation loss: 2.1351704001426697

Epoch: 6| Step: 13
Training loss: 1.9960359334945679
Validation loss: 2.123735189437866

Epoch: 242| Step: 0
Training loss: 2.1096224784851074
Validation loss: 2.139223873615265

Epoch: 6| Step: 1
Training loss: 1.355673909187317
Validation loss: 2.145497679710388

Epoch: 6| Step: 2
Training loss: 1.4327452182769775
Validation loss: 2.1377036372820535

Epoch: 6| Step: 3
Training loss: 1.8444435596466064
Validation loss: 2.1608103116353354

Epoch: 6| Step: 4
Training loss: 1.4827378988265991
Validation loss: 2.183759013811747

Epoch: 6| Step: 5
Training loss: 1.6974499225616455
Validation loss: 2.1920648217201233

Epoch: 6| Step: 6
Training loss: 2.0676651000976562
Validation loss: 2.2057902216911316

Epoch: 6| Step: 7
Training loss: 2.0399200916290283
Validation loss: 2.1991074283917746

Epoch: 6| Step: 8
Training loss: 1.9979546070098877
Validation loss: 2.1993300120035806

Epoch: 6| Step: 9
Training loss: 1.6163389682769775
Validation loss: 2.2030080556869507

Epoch: 6| Step: 10
Training loss: 1.6027348041534424
Validation loss: 2.194432099660238

Epoch: 6| Step: 11
Training loss: 1.9209935665130615
Validation loss: 2.178225656350454

Epoch: 6| Step: 12
Training loss: 2.316498041152954
Validation loss: 2.1856300036112466

Epoch: 6| Step: 13
Training loss: 2.3702845573425293
Validation loss: 2.192801276842753

Epoch: 243| Step: 0
Training loss: 1.8504709005355835
Validation loss: 2.1879164775212607

Epoch: 6| Step: 1
Training loss: 1.54685640335083
Validation loss: 2.180230180422465

Epoch: 6| Step: 2
Training loss: 1.8197581768035889
Validation loss: 2.19578351577123

Epoch: 6| Step: 3
Training loss: 1.3181452751159668
Validation loss: 2.1675270994504294

Epoch: 6| Step: 4
Training loss: 1.5096356868743896
Validation loss: 2.178999404112498

Epoch: 6| Step: 5
Training loss: 1.7723699808120728
Validation loss: 2.1568145553270974

Epoch: 6| Step: 6
Training loss: 1.8723458051681519
Validation loss: 2.180147131284078

Epoch: 6| Step: 7
Training loss: 2.058943748474121
Validation loss: 2.1777562300364175

Epoch: 6| Step: 8
Training loss: 2.6505298614501953
Validation loss: 2.14361443122228

Epoch: 6| Step: 9
Training loss: 1.0555610656738281
Validation loss: 2.170790910720825

Epoch: 6| Step: 10
Training loss: 1.6533924341201782
Validation loss: 2.162961800893148

Epoch: 6| Step: 11
Training loss: 2.2098159790039062
Validation loss: 2.1681719422340393

Epoch: 6| Step: 12
Training loss: 1.9604806900024414
Validation loss: 2.1617230772972107

Epoch: 6| Step: 13
Training loss: 2.1494956016540527
Validation loss: 2.2062722047170005

Epoch: 244| Step: 0
Training loss: 1.493736743927002
Validation loss: 2.1971160173416138

Epoch: 6| Step: 1
Training loss: 1.261132836341858
Validation loss: 2.1958247224489846

Epoch: 6| Step: 2
Training loss: 1.4680894613265991
Validation loss: 2.223757008711497

Epoch: 6| Step: 3
Training loss: 2.234828233718872
Validation loss: 2.2181421319643655

Epoch: 6| Step: 4
Training loss: 2.127439022064209
Validation loss: 2.2170090277989707

Epoch: 6| Step: 5
Training loss: 2.381293773651123
Validation loss: 2.2144182523091636

Epoch: 6| Step: 6
Training loss: 2.218324661254883
Validation loss: 2.204344928264618

Epoch: 6| Step: 7
Training loss: 2.3343560695648193
Validation loss: 2.211932341257731

Epoch: 6| Step: 8
Training loss: 1.5422370433807373
Validation loss: 2.2087262074152627

Epoch: 6| Step: 9
Training loss: 1.78242826461792
Validation loss: 2.2007931073506675

Epoch: 6| Step: 10
Training loss: 1.5009374618530273
Validation loss: 2.212364594141642

Epoch: 6| Step: 11
Training loss: 1.5021159648895264
Validation loss: 2.1962867776552835

Epoch: 6| Step: 12
Training loss: 1.552632451057434
Validation loss: 2.1831620931625366

Epoch: 6| Step: 13
Training loss: 1.8323309421539307
Validation loss: 2.1760218938191733

Epoch: 245| Step: 0
Training loss: 1.811071753501892
Validation loss: 2.183280050754547

Epoch: 6| Step: 1
Training loss: 2.748689889907837
Validation loss: 2.172310988108317

Epoch: 6| Step: 2
Training loss: 1.5379406213760376
Validation loss: 2.165591518084208

Epoch: 6| Step: 3
Training loss: 1.5836241245269775
Validation loss: 2.1707568566004434

Epoch: 6| Step: 4
Training loss: 1.3356103897094727
Validation loss: 2.1705880959828696

Epoch: 6| Step: 5
Training loss: 1.5924246311187744
Validation loss: 2.1851319670677185

Epoch: 6| Step: 6
Training loss: 2.441652774810791
Validation loss: 2.198244293530782

Epoch: 6| Step: 7
Training loss: 1.8972018957138062
Validation loss: 2.209432860215505

Epoch: 6| Step: 8
Training loss: 1.2231316566467285
Validation loss: 2.2122151454289756

Epoch: 6| Step: 9
Training loss: 2.09255051612854
Validation loss: 2.1976624131202698

Epoch: 6| Step: 10
Training loss: 1.4395933151245117
Validation loss: 2.227964719136556

Epoch: 6| Step: 11
Training loss: 1.7948946952819824
Validation loss: 2.221338232358297

Epoch: 6| Step: 12
Training loss: 1.7603737115859985
Validation loss: 2.193696677684784

Epoch: 6| Step: 13
Training loss: 2.1687111854553223
Validation loss: 2.176835815111796

Epoch: 246| Step: 0
Training loss: 1.3474469184875488
Validation loss: 2.184741715590159

Epoch: 6| Step: 1
Training loss: 1.4297181367874146
Validation loss: 2.1720481713612876

Epoch: 6| Step: 2
Training loss: 1.450925588607788
Validation loss: 2.1688705881436667

Epoch: 6| Step: 3
Training loss: 2.288902997970581
Validation loss: 2.168695410092672

Epoch: 6| Step: 4
Training loss: 1.915223479270935
Validation loss: 2.1547226707140603

Epoch: 6| Step: 5
Training loss: 2.128265380859375
Validation loss: 2.168921967347463

Epoch: 6| Step: 6
Training loss: 1.5783592462539673
Validation loss: 2.161789377530416

Epoch: 6| Step: 7
Training loss: 2.2063043117523193
Validation loss: 2.168775757153829

Epoch: 6| Step: 8
Training loss: 1.916680097579956
Validation loss: 2.1728898684183755

Epoch: 6| Step: 9
Training loss: 1.5098267793655396
Validation loss: 2.1781369845072427

Epoch: 6| Step: 10
Training loss: 1.6444655656814575
Validation loss: 2.168704569339752

Epoch: 6| Step: 11
Training loss: 2.6264312267303467
Validation loss: 2.174748400847117

Epoch: 6| Step: 12
Training loss: 1.6259450912475586
Validation loss: 2.176286995410919

Epoch: 6| Step: 13
Training loss: 1.5873522758483887
Validation loss: 2.1906333764394126

Epoch: 247| Step: 0
Training loss: 1.8656370639801025
Validation loss: 2.184852957725525

Epoch: 6| Step: 1
Training loss: 2.4318063259124756
Validation loss: 2.1908056139945984

Epoch: 6| Step: 2
Training loss: 2.4734883308410645
Validation loss: 2.174604872862498

Epoch: 6| Step: 3
Training loss: 1.7021411657333374
Validation loss: 2.1830089489618936

Epoch: 6| Step: 4
Training loss: 1.4573569297790527
Validation loss: 2.1502479712168374

Epoch: 6| Step: 5
Training loss: 1.9786796569824219
Validation loss: 2.1758708357810974

Epoch: 6| Step: 6
Training loss: 1.8345587253570557
Validation loss: 2.155048926671346

Epoch: 6| Step: 7
Training loss: 2.2820639610290527
Validation loss: 2.167397419611613

Epoch: 6| Step: 8
Training loss: 1.8126394748687744
Validation loss: 2.1568817496299744

Epoch: 6| Step: 9
Training loss: 1.8095492124557495
Validation loss: 2.1639471451441445

Epoch: 6| Step: 10
Training loss: 1.1211576461791992
Validation loss: 2.1836403807004294

Epoch: 6| Step: 11
Training loss: 2.044886827468872
Validation loss: 2.1819311579068503

Epoch: 6| Step: 12
Training loss: 1.8239572048187256
Validation loss: 2.176733414332072

Epoch: 6| Step: 13
Training loss: 1.1770504713058472
Validation loss: 2.1717734336853027

Epoch: 248| Step: 0
Training loss: 1.7376514673233032
Validation loss: 2.156866490840912

Epoch: 6| Step: 1
Training loss: 1.6677258014678955
Validation loss: 2.1745177110036216

Epoch: 6| Step: 2
Training loss: 2.2035632133483887
Validation loss: 2.1927186648050943

Epoch: 6| Step: 3
Training loss: 1.9346528053283691
Validation loss: 2.180962304274241

Epoch: 6| Step: 4
Training loss: 1.6520540714263916
Validation loss: 2.2024473945299783

Epoch: 6| Step: 5
Training loss: 2.0709736347198486
Validation loss: 2.195937911669413

Epoch: 6| Step: 6
Training loss: 1.6991231441497803
Validation loss: 2.199848453203837

Epoch: 6| Step: 7
Training loss: 1.52886962890625
Validation loss: 2.200006127357483

Epoch: 6| Step: 8
Training loss: 1.466434121131897
Validation loss: 2.20372066895167

Epoch: 6| Step: 9
Training loss: 1.416257381439209
Validation loss: 2.223628580570221

Epoch: 6| Step: 10
Training loss: 1.7848619222640991
Validation loss: 2.204966048399607

Epoch: 6| Step: 11
Training loss: 1.5070762634277344
Validation loss: 2.198677400747935

Epoch: 6| Step: 12
Training loss: 1.9535443782806396
Validation loss: 2.2074023286501565

Epoch: 6| Step: 13
Training loss: 2.683441638946533
Validation loss: 2.1903649171193442

Epoch: 249| Step: 0
Training loss: 1.5414232015609741
Validation loss: 2.2035741806030273

Epoch: 6| Step: 1
Training loss: 2.297151803970337
Validation loss: 2.2043965657552085

Epoch: 6| Step: 2
Training loss: 2.2179958820343018
Validation loss: 2.1860432624816895

Epoch: 6| Step: 3
Training loss: 1.8461393117904663
Validation loss: 2.209619323412577

Epoch: 6| Step: 4
Training loss: 2.1183531284332275
Validation loss: 2.2070008516311646

Epoch: 6| Step: 5
Training loss: 1.7723875045776367
Validation loss: 2.184642275174459

Epoch: 6| Step: 6
Training loss: 1.4685410261154175
Validation loss: 2.2016082803408303

Epoch: 6| Step: 7
Training loss: 1.5951752662658691
Validation loss: 2.179933269818624

Epoch: 6| Step: 8
Training loss: 1.237732172012329
Validation loss: 2.2075872222582498

Epoch: 6| Step: 9
Training loss: 1.9303861856460571
Validation loss: 2.193218688170115

Epoch: 6| Step: 10
Training loss: 2.1760592460632324
Validation loss: 2.1925774017969766

Epoch: 6| Step: 11
Training loss: 1.3856533765792847
Validation loss: 2.1867640813191733

Epoch: 6| Step: 12
Training loss: 1.6013953685760498
Validation loss: 2.201397697130839

Epoch: 6| Step: 13
Training loss: 1.7140202522277832
Validation loss: 2.2019264300664267

Epoch: 250| Step: 0
Training loss: 1.935117244720459
Validation loss: 2.185007393360138

Epoch: 6| Step: 1
Training loss: 1.6571524143218994
Validation loss: 2.1956812342007956

Epoch: 6| Step: 2
Training loss: 2.2365288734436035
Validation loss: 2.2171167532602944

Epoch: 6| Step: 3
Training loss: 2.318568229675293
Validation loss: 2.187446931997935

Epoch: 6| Step: 4
Training loss: 1.3335585594177246
Validation loss: 2.1889737844467163

Epoch: 6| Step: 5
Training loss: 1.479215145111084
Validation loss: 2.1853252251942954

Epoch: 6| Step: 6
Training loss: 1.8596869707107544
Validation loss: 2.191249907016754

Epoch: 6| Step: 7
Training loss: 1.949601173400879
Validation loss: 2.158062299092611

Epoch: 6| Step: 8
Training loss: 1.567899465560913
Validation loss: 2.195737282435099

Epoch: 6| Step: 9
Training loss: 1.4543678760528564
Validation loss: 2.191899140675863

Epoch: 6| Step: 10
Training loss: 1.5499399900436401
Validation loss: 2.199503719806671

Epoch: 6| Step: 11
Training loss: 1.6222596168518066
Validation loss: 2.212883194287618

Epoch: 6| Step: 12
Training loss: 1.7934656143188477
Validation loss: 2.219760298728943

Epoch: 6| Step: 13
Training loss: 2.2650115489959717
Validation loss: 2.1916688680648804

Epoch: 251| Step: 0
Training loss: 1.7972056865692139
Validation loss: 2.2392377853393555

Epoch: 6| Step: 1
Training loss: 2.0055484771728516
Validation loss: 2.203184127807617

Epoch: 6| Step: 2
Training loss: 1.7810732126235962
Validation loss: 2.2014745076497397

Epoch: 6| Step: 3
Training loss: 1.8218632936477661
Validation loss: 2.1912253896395364

Epoch: 6| Step: 4
Training loss: 1.2298779487609863
Validation loss: 2.198741098244985

Epoch: 6| Step: 5
Training loss: 2.3781392574310303
Validation loss: 2.210240920384725

Epoch: 6| Step: 6
Training loss: 1.6987242698669434
Validation loss: 2.180193463961283

Epoch: 6| Step: 7
Training loss: 1.5680075883865356
Validation loss: 2.1974276304244995

Epoch: 6| Step: 8
Training loss: 1.6479389667510986
Validation loss: 2.190979997316996

Epoch: 6| Step: 9
Training loss: 1.6995960474014282
Validation loss: 2.1795963644981384

Epoch: 6| Step: 10
Training loss: 1.8061286211013794
Validation loss: 2.155904710292816

Epoch: 6| Step: 11
Training loss: 1.5774357318878174
Validation loss: 2.1699947118759155

Epoch: 6| Step: 12
Training loss: 2.433676242828369
Validation loss: 2.18457293510437

Epoch: 6| Step: 13
Training loss: 1.4680767059326172
Validation loss: 2.1770647366841636

Epoch: 252| Step: 0
Training loss: 3.075547218322754
Validation loss: 2.17685200770696

Epoch: 6| Step: 1
Training loss: 1.4749289751052856
Validation loss: 2.1945411761601767

Epoch: 6| Step: 2
Training loss: 1.2941796779632568
Validation loss: 2.1874483227729797

Epoch: 6| Step: 3
Training loss: 2.5486068725585938
Validation loss: 2.203299423058828

Epoch: 6| Step: 4
Training loss: 1.9261627197265625
Validation loss: 2.195734163125356

Epoch: 6| Step: 5
Training loss: 2.070216417312622
Validation loss: 2.174088736375173

Epoch: 6| Step: 6
Training loss: 1.7034611701965332
Validation loss: 2.1917643944422402

Epoch: 6| Step: 7
Training loss: 2.116081953048706
Validation loss: 2.215523878733317

Epoch: 6| Step: 8
Training loss: 1.6488020420074463
Validation loss: 2.234131713708242

Epoch: 6| Step: 9
Training loss: 1.4642919301986694
Validation loss: 2.2213966449101767

Epoch: 6| Step: 10
Training loss: 1.3442234992980957
Validation loss: 2.2201608419418335

Epoch: 6| Step: 11
Training loss: 1.926835298538208
Validation loss: 2.2062420646349588

Epoch: 6| Step: 12
Training loss: 1.1129095554351807
Validation loss: 2.209969242413839

Epoch: 6| Step: 13
Training loss: 1.2082080841064453
Validation loss: 2.194164494673411

Epoch: 253| Step: 0
Training loss: 1.9812521934509277
Validation loss: 2.199331283569336

Epoch: 6| Step: 1
Training loss: 1.6776090860366821
Validation loss: 2.195353925228119

Epoch: 6| Step: 2
Training loss: 1.2868754863739014
Validation loss: 2.165025254090627

Epoch: 6| Step: 3
Training loss: 1.4305903911590576
Validation loss: 2.1878484090169272

Epoch: 6| Step: 4
Training loss: 2.110504150390625
Validation loss: 2.158613920211792

Epoch: 6| Step: 5
Training loss: 1.9406147003173828
Validation loss: 2.1657426357269287

Epoch: 6| Step: 6
Training loss: 2.4997401237487793
Validation loss: 2.1641878286997476

Epoch: 6| Step: 7
Training loss: 1.508651852607727
Validation loss: 2.163259049256643

Epoch: 6| Step: 8
Training loss: 2.2347145080566406
Validation loss: 2.1745699644088745

Epoch: 6| Step: 9
Training loss: 1.8828797340393066
Validation loss: 2.1831085681915283

Epoch: 6| Step: 10
Training loss: 1.4757823944091797
Validation loss: 2.205218235651652

Epoch: 6| Step: 11
Training loss: 1.1846063137054443
Validation loss: 2.210877617200216

Epoch: 6| Step: 12
Training loss: 2.632244110107422
Validation loss: 2.226454178492228

Epoch: 6| Step: 13
Training loss: 1.6202926635742188
Validation loss: 2.2110345164934793

Epoch: 254| Step: 0
Training loss: 1.5795749425888062
Validation loss: 2.2145482301712036

Epoch: 6| Step: 1
Training loss: 1.9400748014450073
Validation loss: 2.217406233151754

Epoch: 6| Step: 2
Training loss: 2.289268732070923
Validation loss: 2.2047789891560874

Epoch: 6| Step: 3
Training loss: 1.4119386672973633
Validation loss: 2.2395172913869223

Epoch: 6| Step: 4
Training loss: 1.837266445159912
Validation loss: 2.255820631980896

Epoch: 6| Step: 5
Training loss: 2.564152240753174
Validation loss: 2.234031399091085

Epoch: 6| Step: 6
Training loss: 1.5346858501434326
Validation loss: 2.233645180861155

Epoch: 6| Step: 7
Training loss: 1.7595000267028809
Validation loss: 2.2014421820640564

Epoch: 6| Step: 8
Training loss: 1.3404390811920166
Validation loss: 2.1858998934427896

Epoch: 6| Step: 9
Training loss: 2.1348791122436523
Validation loss: 2.19577419757843

Epoch: 6| Step: 10
Training loss: 1.183471441268921
Validation loss: 2.176667114098867

Epoch: 6| Step: 11
Training loss: 2.0706470012664795
Validation loss: 2.1717140078544617

Epoch: 6| Step: 12
Training loss: 1.9115524291992188
Validation loss: 2.179914395014445

Epoch: 6| Step: 13
Training loss: 1.621024250984192
Validation loss: 2.182366887728373

Epoch: 255| Step: 0
Training loss: 1.7644745111465454
Validation loss: 2.184105376402537

Epoch: 6| Step: 1
Training loss: 1.4550187587738037
Validation loss: 2.177067458629608

Epoch: 6| Step: 2
Training loss: 2.7938361167907715
Validation loss: 2.1988648970921836

Epoch: 6| Step: 3
Training loss: 1.865967035293579
Validation loss: 2.228548308213552

Epoch: 6| Step: 4
Training loss: 1.534518837928772
Validation loss: 2.225926240285238

Epoch: 6| Step: 5
Training loss: 1.415342926979065
Validation loss: 2.220123211542765

Epoch: 6| Step: 6
Training loss: 1.3595881462097168
Validation loss: 2.2377283573150635

Epoch: 6| Step: 7
Training loss: 1.9705199003219604
Validation loss: 2.2228888471921286

Epoch: 6| Step: 8
Training loss: 1.9029297828674316
Validation loss: 2.2534324328104653

Epoch: 6| Step: 9
Training loss: 2.4016218185424805
Validation loss: 2.197987159093221

Epoch: 6| Step: 10
Training loss: 1.6612634658813477
Validation loss: 2.2179763515790305

Epoch: 6| Step: 11
Training loss: 1.4884108304977417
Validation loss: 2.2123029033342996

Epoch: 6| Step: 12
Training loss: 1.6629266738891602
Validation loss: 2.224993030230204

Epoch: 6| Step: 13
Training loss: 1.5830188989639282
Validation loss: 2.2391324241956077

Epoch: 256| Step: 0
Training loss: 2.068427562713623
Validation loss: 2.265545884768168

Epoch: 6| Step: 1
Training loss: 1.559126377105713
Validation loss: 2.2364335457483926

Epoch: 6| Step: 2
Training loss: 1.943128228187561
Validation loss: 2.238187392552694

Epoch: 6| Step: 3
Training loss: 1.6867448091506958
Validation loss: 2.2331833640734353

Epoch: 6| Step: 4
Training loss: 2.0698530673980713
Validation loss: 2.225941260655721

Epoch: 6| Step: 5
Training loss: 1.9663658142089844
Validation loss: 2.2436245878537497

Epoch: 6| Step: 6
Training loss: 1.1447150707244873
Validation loss: 2.2447787125905356

Epoch: 6| Step: 7
Training loss: 1.696738600730896
Validation loss: 2.2385883728663125

Epoch: 6| Step: 8
Training loss: 1.6144185066223145
Validation loss: 2.2283832828203836

Epoch: 6| Step: 9
Training loss: 1.5029313564300537
Validation loss: 2.2429954210917153

Epoch: 6| Step: 10
Training loss: 1.7923669815063477
Validation loss: 2.2409062584241233

Epoch: 6| Step: 11
Training loss: 2.692579746246338
Validation loss: 2.240441640218099

Epoch: 6| Step: 12
Training loss: 1.5060713291168213
Validation loss: 2.209791620572408

Epoch: 6| Step: 13
Training loss: 1.5962262153625488
Validation loss: 2.2135534087816873

Epoch: 257| Step: 0
Training loss: 1.1195909976959229
Validation loss: 2.2168890039126077

Epoch: 6| Step: 1
Training loss: 1.4516613483428955
Validation loss: 2.1970702012379966

Epoch: 6| Step: 2
Training loss: 1.8214828968048096
Validation loss: 2.2096230189005532

Epoch: 6| Step: 3
Training loss: 2.041766405105591
Validation loss: 2.187004725138346

Epoch: 6| Step: 4
Training loss: 1.5613420009613037
Validation loss: 2.1615243951479592

Epoch: 6| Step: 5
Training loss: 2.985733985900879
Validation loss: 2.177185575167338

Epoch: 6| Step: 6
Training loss: 1.6749094724655151
Validation loss: 2.1619787414868674

Epoch: 6| Step: 7
Training loss: 1.6859009265899658
Validation loss: 2.158583124478658

Epoch: 6| Step: 8
Training loss: 1.2468080520629883
Validation loss: 2.174484968185425

Epoch: 6| Step: 9
Training loss: 1.3262465000152588
Validation loss: 2.1705472270647683

Epoch: 6| Step: 10
Training loss: 2.2722907066345215
Validation loss: 2.1626773476600647

Epoch: 6| Step: 11
Training loss: 1.7358765602111816
Validation loss: 2.1889808972676597

Epoch: 6| Step: 12
Training loss: 2.401829242706299
Validation loss: 2.1817914644877114

Epoch: 6| Step: 13
Training loss: 1.8886783123016357
Validation loss: 2.1894920070966086

Epoch: 258| Step: 0
Training loss: 1.7980289459228516
Validation loss: 2.2080468932787576

Epoch: 6| Step: 1
Training loss: 1.6377992630004883
Validation loss: 2.2121224204699197

Epoch: 6| Step: 2
Training loss: 1.7288317680358887
Validation loss: 2.1997350056966147

Epoch: 6| Step: 3
Training loss: 1.5578699111938477
Validation loss: 2.217354635397593

Epoch: 6| Step: 4
Training loss: 1.7020429372787476
Validation loss: 2.183999458948771

Epoch: 6| Step: 5
Training loss: 2.161195993423462
Validation loss: 2.2078251043955484

Epoch: 6| Step: 6
Training loss: 2.011756420135498
Validation loss: 2.202251593271891

Epoch: 6| Step: 7
Training loss: 1.9637060165405273
Validation loss: 2.220602830251058

Epoch: 6| Step: 8
Training loss: 1.6712737083435059
Validation loss: 2.204588770866394

Epoch: 6| Step: 9
Training loss: 1.706052541732788
Validation loss: 2.169057528177897

Epoch: 6| Step: 10
Training loss: 2.2196359634399414
Validation loss: 2.1557774941126504

Epoch: 6| Step: 11
Training loss: 1.804863452911377
Validation loss: 2.173996011416117

Epoch: 6| Step: 12
Training loss: 1.6449766159057617
Validation loss: 2.1538262963294983

Epoch: 6| Step: 13
Training loss: 1.8223655223846436
Validation loss: 2.161612351735433

Epoch: 259| Step: 0
Training loss: 2.1849207878112793
Validation loss: 2.1671427289644876

Epoch: 6| Step: 1
Training loss: 1.1435909271240234
Validation loss: 2.180607179800669

Epoch: 6| Step: 2
Training loss: 1.4648689031600952
Validation loss: 2.200795034567515

Epoch: 6| Step: 3
Training loss: 1.7605727910995483
Validation loss: 2.1920731465021768

Epoch: 6| Step: 4
Training loss: 1.7797305583953857
Validation loss: 2.201525648434957

Epoch: 6| Step: 5
Training loss: 2.419206142425537
Validation loss: 2.2019551396369934

Epoch: 6| Step: 6
Training loss: 1.7351276874542236
Validation loss: 2.1800260742505393

Epoch: 6| Step: 7
Training loss: 1.9075621366500854
Validation loss: 2.1916971604029336

Epoch: 6| Step: 8
Training loss: 1.952040195465088
Validation loss: 2.175068517525991

Epoch: 6| Step: 9
Training loss: 1.4212234020233154
Validation loss: 2.177864750226339

Epoch: 6| Step: 10
Training loss: 1.2564023733139038
Validation loss: 2.2015830874443054

Epoch: 6| Step: 11
Training loss: 1.77181077003479
Validation loss: 2.209581951300303

Epoch: 6| Step: 12
Training loss: 2.2167763710021973
Validation loss: 2.209524154663086

Epoch: 6| Step: 13
Training loss: 1.729004979133606
Validation loss: 2.2001097202301025

Epoch: 260| Step: 0
Training loss: 1.6369491815567017
Validation loss: 2.221693515777588

Epoch: 6| Step: 1
Training loss: 1.5568770170211792
Validation loss: 2.1951677401860556

Epoch: 6| Step: 2
Training loss: 1.72183358669281
Validation loss: 2.170532703399658

Epoch: 6| Step: 3
Training loss: 2.051074266433716
Validation loss: 2.169737994670868

Epoch: 6| Step: 4
Training loss: 1.3265750408172607
Validation loss: 2.156133313973745

Epoch: 6| Step: 5
Training loss: 2.0571815967559814
Validation loss: 2.1737871170043945

Epoch: 6| Step: 6
Training loss: 2.0264813899993896
Validation loss: 2.181887368361155

Epoch: 6| Step: 7
Training loss: 2.141888380050659
Validation loss: 2.1756842335065207

Epoch: 6| Step: 8
Training loss: 2.1091153621673584
Validation loss: 2.172489047050476

Epoch: 6| Step: 9
Training loss: 1.7593507766723633
Validation loss: 2.191915531953176

Epoch: 6| Step: 10
Training loss: 2.2334346771240234
Validation loss: 2.17943141857783

Epoch: 6| Step: 11
Training loss: 1.653937578201294
Validation loss: 2.2036646405855813

Epoch: 6| Step: 12
Training loss: 1.6931419372558594
Validation loss: 2.208378334840139

Epoch: 6| Step: 13
Training loss: 1.361609697341919
Validation loss: 2.229468047618866

Epoch: 261| Step: 0
Training loss: 1.8557822704315186
Validation loss: 2.225686808427175

Epoch: 6| Step: 1
Training loss: 1.268358826637268
Validation loss: 2.2123488187789917

Epoch: 6| Step: 2
Training loss: 2.4115777015686035
Validation loss: 2.2145957946777344

Epoch: 6| Step: 3
Training loss: 1.4101357460021973
Validation loss: 2.206090529759725

Epoch: 6| Step: 4
Training loss: 1.9955617189407349
Validation loss: 2.1891742944717407

Epoch: 6| Step: 5
Training loss: 1.9910122156143188
Validation loss: 2.1847569147745767

Epoch: 6| Step: 6
Training loss: 2.2903013229370117
Validation loss: 2.1793916821479797

Epoch: 6| Step: 7
Training loss: 1.5022196769714355
Validation loss: 2.177882413069407

Epoch: 6| Step: 8
Training loss: 1.5533599853515625
Validation loss: 2.194042126337687

Epoch: 6| Step: 9
Training loss: 1.1432538032531738
Validation loss: 2.2038223346074424

Epoch: 6| Step: 10
Training loss: 2.7048075199127197
Validation loss: 2.2200613419214883

Epoch: 6| Step: 11
Training loss: 1.2957711219787598
Validation loss: 2.2111173073450723

Epoch: 6| Step: 12
Training loss: 1.3459293842315674
Validation loss: 2.218077222506205

Epoch: 6| Step: 13
Training loss: 2.039287805557251
Validation loss: 2.218562682469686

Epoch: 262| Step: 0
Training loss: 1.2575581073760986
Validation loss: 2.217781682809194

Epoch: 6| Step: 1
Training loss: 1.763948917388916
Validation loss: 2.210875074068705

Epoch: 6| Step: 2
Training loss: 1.9714901447296143
Validation loss: 2.1942431131998696

Epoch: 6| Step: 3
Training loss: 1.7108445167541504
Validation loss: 2.193004329999288

Epoch: 6| Step: 4
Training loss: 1.3850022554397583
Validation loss: 2.1916314363479614

Epoch: 6| Step: 5
Training loss: 2.1330323219299316
Validation loss: 2.1993749936421714

Epoch: 6| Step: 6
Training loss: 1.6854201555252075
Validation loss: 2.2165486415227256

Epoch: 6| Step: 7
Training loss: 2.0278639793395996
Validation loss: 2.2266416549682617

Epoch: 6| Step: 8
Training loss: 1.7281018495559692
Validation loss: 2.2489629983901978

Epoch: 6| Step: 9
Training loss: 1.9165745973587036
Validation loss: 2.2437811493873596

Epoch: 6| Step: 10
Training loss: 1.7388877868652344
Validation loss: 2.2504310607910156

Epoch: 6| Step: 11
Training loss: 1.9530280828475952
Validation loss: 2.2253926197687783

Epoch: 6| Step: 12
Training loss: 1.6250100135803223
Validation loss: 2.2553138931592307

Epoch: 6| Step: 13
Training loss: 1.929734230041504
Validation loss: 2.2579933404922485

Epoch: 263| Step: 0
Training loss: 1.7166564464569092
Validation loss: 2.2711395422617593

Epoch: 6| Step: 1
Training loss: 1.6276171207427979
Validation loss: 2.244583785533905

Epoch: 6| Step: 2
Training loss: 1.7639012336730957
Validation loss: 2.2227935791015625

Epoch: 6| Step: 3
Training loss: 1.6622154712677002
Validation loss: 2.2115697264671326

Epoch: 6| Step: 4
Training loss: 1.4392045736312866
Validation loss: 2.21042807896932

Epoch: 6| Step: 5
Training loss: 1.982618808746338
Validation loss: 2.2392196456591287

Epoch: 6| Step: 6
Training loss: 2.2954745292663574
Validation loss: 2.2314167420069375

Epoch: 6| Step: 7
Training loss: 1.6489720344543457
Validation loss: 2.2136667569478354

Epoch: 6| Step: 8
Training loss: 1.8225479125976562
Validation loss: 2.1999204556147256

Epoch: 6| Step: 9
Training loss: 1.5635336637496948
Validation loss: 2.2128624518712363

Epoch: 6| Step: 10
Training loss: 1.7111399173736572
Validation loss: 2.2219689885775247

Epoch: 6| Step: 11
Training loss: 1.911562204360962
Validation loss: 2.214901785055796

Epoch: 6| Step: 12
Training loss: 1.3958868980407715
Validation loss: 2.2447755336761475

Epoch: 6| Step: 13
Training loss: 1.901322364807129
Validation loss: 2.2251477042833963

Epoch: 264| Step: 0
Training loss: 2.5191650390625
Validation loss: 2.2023498018582663

Epoch: 6| Step: 1
Training loss: 1.5515992641448975
Validation loss: 2.2030173738797507

Epoch: 6| Step: 2
Training loss: 1.155988335609436
Validation loss: 2.2310665448506675

Epoch: 6| Step: 3
Training loss: 2.0525457859039307
Validation loss: 2.215166608492533

Epoch: 6| Step: 4
Training loss: 0.943760871887207
Validation loss: 2.215498924255371

Epoch: 6| Step: 5
Training loss: 1.9322857856750488
Validation loss: 2.2007657289505005

Epoch: 6| Step: 6
Training loss: 1.66965651512146
Validation loss: 2.2400766611099243

Epoch: 6| Step: 7
Training loss: 1.746846079826355
Validation loss: 2.2167519330978394

Epoch: 6| Step: 8
Training loss: 1.4589529037475586
Validation loss: 2.2075630823771157

Epoch: 6| Step: 9
Training loss: 1.8752609491348267
Validation loss: 2.2055084904034934

Epoch: 6| Step: 10
Training loss: 2.0217413902282715
Validation loss: 2.1924338738123574

Epoch: 6| Step: 11
Training loss: 1.61659574508667
Validation loss: 2.1996479829152427

Epoch: 6| Step: 12
Training loss: 2.1698951721191406
Validation loss: 2.2013664841651917

Epoch: 6| Step: 13
Training loss: 1.79762601852417
Validation loss: 2.212113877137502

Epoch: 265| Step: 0
Training loss: 1.595988392829895
Validation loss: 2.183398445447286

Epoch: 6| Step: 1
Training loss: 2.2830066680908203
Validation loss: 2.2236974835395813

Epoch: 6| Step: 2
Training loss: 1.6759259700775146
Validation loss: 2.2142789562543235

Epoch: 6| Step: 3
Training loss: 2.151634454727173
Validation loss: 2.2379899819691977

Epoch: 6| Step: 4
Training loss: 1.6738451719284058
Validation loss: 2.2402536273002625

Epoch: 6| Step: 5
Training loss: 2.0191407203674316
Validation loss: 2.238053818543752

Epoch: 6| Step: 6
Training loss: 1.8005353212356567
Validation loss: 2.246537506580353

Epoch: 6| Step: 7
Training loss: 1.649654507637024
Validation loss: 2.2716269294420877

Epoch: 6| Step: 8
Training loss: 1.72386634349823
Validation loss: 2.25836714108785

Epoch: 6| Step: 9
Training loss: 1.617577314376831
Validation loss: 2.2561581333478293

Epoch: 6| Step: 10
Training loss: 1.5393142700195312
Validation loss: 2.2382322549819946

Epoch: 6| Step: 11
Training loss: 0.9426661133766174
Validation loss: 2.248403310775757

Epoch: 6| Step: 12
Training loss: 1.962362289428711
Validation loss: 2.229343295097351

Epoch: 6| Step: 13
Training loss: 1.7413194179534912
Validation loss: 2.2077054580052695

Epoch: 266| Step: 0
Training loss: 1.8999220132827759
Validation loss: 2.2118937373161316

Epoch: 6| Step: 1
Training loss: 2.118286609649658
Validation loss: 2.23878945906957

Epoch: 6| Step: 2
Training loss: 1.8513476848602295
Validation loss: 2.2138953804969788

Epoch: 6| Step: 3
Training loss: 1.5937039852142334
Validation loss: 2.2140850027402244

Epoch: 6| Step: 4
Training loss: 0.9625034332275391
Validation loss: 2.24160369237264

Epoch: 6| Step: 5
Training loss: 1.541391134262085
Validation loss: 2.2198774019877114

Epoch: 6| Step: 6
Training loss: 2.328599691390991
Validation loss: 2.2356197834014893

Epoch: 6| Step: 7
Training loss: 1.8434690237045288
Validation loss: 2.24019726117452

Epoch: 6| Step: 8
Training loss: 1.384071946144104
Validation loss: 2.25016196568807

Epoch: 6| Step: 9
Training loss: 1.6140437126159668
Validation loss: 2.26613849401474

Epoch: 6| Step: 10
Training loss: 1.8150027990341187
Validation loss: 2.247492492198944

Epoch: 6| Step: 11
Training loss: 1.6707059144973755
Validation loss: 2.277073621749878

Epoch: 6| Step: 12
Training loss: 1.7623779773712158
Validation loss: 2.2515970865885415

Epoch: 6| Step: 13
Training loss: 2.036731719970703
Validation loss: 2.2399449745814004

Epoch: 267| Step: 0
Training loss: 1.4431824684143066
Validation loss: 2.2271462281545005

Epoch: 6| Step: 1
Training loss: 1.2826271057128906
Validation loss: 2.2197968562444053

Epoch: 6| Step: 2
Training loss: 2.2235422134399414
Validation loss: 2.2068932255109153

Epoch: 6| Step: 3
Training loss: 1.983731985092163
Validation loss: 2.192879398663839

Epoch: 6| Step: 4
Training loss: 2.2031164169311523
Validation loss: 2.1822251677513123

Epoch: 6| Step: 5
Training loss: 1.1088683605194092
Validation loss: 2.1891788442929587

Epoch: 6| Step: 6
Training loss: 1.7403135299682617
Validation loss: 2.185887614885966

Epoch: 6| Step: 7
Training loss: 2.1772069931030273
Validation loss: 2.188275774319967

Epoch: 6| Step: 8
Training loss: 2.3785154819488525
Validation loss: 2.192236344019572

Epoch: 6| Step: 9
Training loss: 1.6412861347198486
Validation loss: 2.20706437031428

Epoch: 6| Step: 10
Training loss: 1.5541844367980957
Validation loss: 2.244562804698944

Epoch: 6| Step: 11
Training loss: 1.809615135192871
Validation loss: 2.2329565485318503

Epoch: 6| Step: 12
Training loss: 1.6633813381195068
Validation loss: 2.2410795291264853

Epoch: 6| Step: 13
Training loss: 1.6736712455749512
Validation loss: 2.24560139576594

Epoch: 268| Step: 0
Training loss: 1.5226982831954956
Validation loss: 2.245705703894297

Epoch: 6| Step: 1
Training loss: 1.8035624027252197
Validation loss: 2.236059248447418

Epoch: 6| Step: 2
Training loss: 1.5756430625915527
Validation loss: 2.2219932277997336

Epoch: 6| Step: 3
Training loss: 1.9374666213989258
Validation loss: 2.2319003343582153

Epoch: 6| Step: 4
Training loss: 1.4524619579315186
Validation loss: 2.2227425972620645

Epoch: 6| Step: 5
Training loss: 1.849022388458252
Validation loss: 2.223063826560974

Epoch: 6| Step: 6
Training loss: 2.2349607944488525
Validation loss: 2.208553969860077

Epoch: 6| Step: 7
Training loss: 1.5117297172546387
Validation loss: 2.2289984424908957

Epoch: 6| Step: 8
Training loss: 2.1158485412597656
Validation loss: 2.244517703851064

Epoch: 6| Step: 9
Training loss: 1.7489955425262451
Validation loss: 2.246503988901774

Epoch: 6| Step: 10
Training loss: 1.3202584981918335
Validation loss: 2.2462554772694907

Epoch: 6| Step: 11
Training loss: 1.0803699493408203
Validation loss: 2.230205694834391

Epoch: 6| Step: 12
Training loss: 2.4537739753723145
Validation loss: 2.23664391040802

Epoch: 6| Step: 13
Training loss: 1.700258493423462
Validation loss: 2.2136409680048623

Epoch: 269| Step: 0
Training loss: 1.4311845302581787
Validation loss: 2.2169699668884277

Epoch: 6| Step: 1
Training loss: 1.4922701120376587
Validation loss: 2.2085720698038735

Epoch: 6| Step: 2
Training loss: 1.9130077362060547
Validation loss: 2.171825389067332

Epoch: 6| Step: 3
Training loss: 2.4306607246398926
Validation loss: 2.1956175168355307

Epoch: 6| Step: 4
Training loss: 1.375002145767212
Validation loss: 2.1920672059059143

Epoch: 6| Step: 5
Training loss: 1.545446753501892
Validation loss: 2.1786157687505088

Epoch: 6| Step: 6
Training loss: 1.918161392211914
Validation loss: 2.1841281851132712

Epoch: 6| Step: 7
Training loss: 2.5843496322631836
Validation loss: 2.2018566528956094

Epoch: 6| Step: 8
Training loss: 1.430982232093811
Validation loss: 2.2297285000483194

Epoch: 6| Step: 9
Training loss: 1.599985122680664
Validation loss: 2.2591833074887595

Epoch: 6| Step: 10
Training loss: 2.135495185852051
Validation loss: 2.269898613293966

Epoch: 6| Step: 11
Training loss: 1.3578978776931763
Validation loss: 2.271722356478373

Epoch: 6| Step: 12
Training loss: 1.3668229579925537
Validation loss: 2.2413675586382547

Epoch: 6| Step: 13
Training loss: 1.633070468902588
Validation loss: 2.262791156768799

Epoch: 270| Step: 0
Training loss: 1.0988839864730835
Validation loss: 2.2562415401140847

Epoch: 6| Step: 1
Training loss: 1.0878338813781738
Validation loss: 2.242919683456421

Epoch: 6| Step: 2
Training loss: 1.8610467910766602
Validation loss: 2.280028462409973

Epoch: 6| Step: 3
Training loss: 2.2179653644561768
Validation loss: 2.259034276008606

Epoch: 6| Step: 4
Training loss: 1.8244893550872803
Validation loss: 2.263066907723745

Epoch: 6| Step: 5
Training loss: 2.3710832595825195
Validation loss: 2.252794782320658

Epoch: 6| Step: 6
Training loss: 1.2099626064300537
Validation loss: 2.204386750857035

Epoch: 6| Step: 7
Training loss: 2.6681478023529053
Validation loss: 2.1838992635409036

Epoch: 6| Step: 8
Training loss: 1.309295415878296
Validation loss: 2.198436458905538

Epoch: 6| Step: 9
Training loss: 1.3525043725967407
Validation loss: 2.226492007573446

Epoch: 6| Step: 10
Training loss: 1.736905813217163
Validation loss: 2.227984289328257

Epoch: 6| Step: 11
Training loss: 1.9843406677246094
Validation loss: 2.2648735841115317

Epoch: 6| Step: 12
Training loss: 1.7382880449295044
Validation loss: 2.256215989589691

Epoch: 6| Step: 13
Training loss: 2.0470523834228516
Validation loss: 2.25321896870931

Epoch: 271| Step: 0
Training loss: 2.244845390319824
Validation loss: 2.249788542588552

Epoch: 6| Step: 1
Training loss: 1.8430485725402832
Validation loss: 2.2640171448389688

Epoch: 6| Step: 2
Training loss: 2.252882957458496
Validation loss: 2.2338862816492715

Epoch: 6| Step: 3
Training loss: 1.1908133029937744
Validation loss: 2.2593551675478616

Epoch: 6| Step: 4
Training loss: 1.462859869003296
Validation loss: 2.259923497835795

Epoch: 6| Step: 5
Training loss: 1.2806673049926758
Validation loss: 2.2393284241358438

Epoch: 6| Step: 6
Training loss: 1.3993185758590698
Validation loss: 2.2092266281445823

Epoch: 6| Step: 7
Training loss: 2.2774648666381836
Validation loss: 2.2254308462142944

Epoch: 6| Step: 8
Training loss: 2.217362880706787
Validation loss: 2.233878751595815

Epoch: 6| Step: 9
Training loss: 1.7383527755737305
Validation loss: 2.233010212580363

Epoch: 6| Step: 10
Training loss: 1.7278738021850586
Validation loss: 2.2185617685317993

Epoch: 6| Step: 11
Training loss: 1.4741911888122559
Validation loss: 2.2044445872306824

Epoch: 6| Step: 12
Training loss: 1.4249399900436401
Validation loss: 2.232363243897756

Epoch: 6| Step: 13
Training loss: 1.4708040952682495
Validation loss: 2.2032081683476767

Epoch: 272| Step: 0
Training loss: 2.1611146926879883
Validation loss: 2.2129890521367392

Epoch: 6| Step: 1
Training loss: 1.252383828163147
Validation loss: 2.214911937713623

Epoch: 6| Step: 2
Training loss: 1.7283711433410645
Validation loss: 2.2148099740346274

Epoch: 6| Step: 3
Training loss: 1.9095284938812256
Validation loss: 2.2339874108632407

Epoch: 6| Step: 4
Training loss: 2.2109580039978027
Validation loss: 2.212492843468984

Epoch: 6| Step: 5
Training loss: 2.1360695362091064
Validation loss: 2.225440482298533

Epoch: 6| Step: 6
Training loss: 1.1130530834197998
Validation loss: 2.221353848775228

Epoch: 6| Step: 7
Training loss: 1.8630263805389404
Validation loss: 2.2466686964035034

Epoch: 6| Step: 8
Training loss: 1.4821672439575195
Validation loss: 2.2381210923194885

Epoch: 6| Step: 9
Training loss: 1.7113261222839355
Validation loss: 2.2533483107884726

Epoch: 6| Step: 10
Training loss: 1.3965847492218018
Validation loss: 2.252909481525421

Epoch: 6| Step: 11
Training loss: 1.2579150199890137
Validation loss: 2.2360499501228333

Epoch: 6| Step: 12
Training loss: 1.6423368453979492
Validation loss: 2.222089727719625

Epoch: 6| Step: 13
Training loss: 1.9642084836959839
Validation loss: 2.2078717152277627

Epoch: 273| Step: 0
Training loss: 1.5729992389678955
Validation loss: 2.2239105304082236

Epoch: 6| Step: 1
Training loss: 1.6352952718734741
Validation loss: 2.2032307386398315

Epoch: 6| Step: 2
Training loss: 2.6096835136413574
Validation loss: 2.217271546522776

Epoch: 6| Step: 3
Training loss: 1.9788721799850464
Validation loss: 2.222198764483134

Epoch: 6| Step: 4
Training loss: 1.85606050491333
Validation loss: 2.251425266265869

Epoch: 6| Step: 5
Training loss: 1.1918725967407227
Validation loss: 2.2337517539660134

Epoch: 6| Step: 6
Training loss: 1.512195348739624
Validation loss: 2.255371709664663

Epoch: 6| Step: 7
Training loss: 1.9241611957550049
Validation loss: 2.259279648462931

Epoch: 6| Step: 8
Training loss: 1.4753336906433105
Validation loss: 2.2512000799179077

Epoch: 6| Step: 9
Training loss: 1.4400100708007812
Validation loss: 2.2481223146120706

Epoch: 6| Step: 10
Training loss: 1.3886812925338745
Validation loss: 2.2600157856941223

Epoch: 6| Step: 11
Training loss: 2.047330141067505
Validation loss: 2.2572762171427407

Epoch: 6| Step: 12
Training loss: 1.6850916147232056
Validation loss: 2.2320286631584167

Epoch: 6| Step: 13
Training loss: 1.540940523147583
Validation loss: 2.258355359236399

Epoch: 274| Step: 0
Training loss: 1.4525609016418457
Validation loss: 2.2604869405428567

Epoch: 6| Step: 1
Training loss: 1.5989950895309448
Validation loss: 2.2420753041903176

Epoch: 6| Step: 2
Training loss: 1.4248441457748413
Validation loss: 2.2458359797795615

Epoch: 6| Step: 3
Training loss: 2.5702102184295654
Validation loss: 2.256489415963491

Epoch: 6| Step: 4
Training loss: 2.0913619995117188
Validation loss: 2.2420146465301514

Epoch: 6| Step: 5
Training loss: 1.7731080055236816
Validation loss: 2.2610833247502646

Epoch: 6| Step: 6
Training loss: 1.9114995002746582
Validation loss: 2.259693721930186

Epoch: 6| Step: 7
Training loss: 1.5919179916381836
Validation loss: 2.254418055216471

Epoch: 6| Step: 8
Training loss: 1.368615746498108
Validation loss: 2.2647696336110434

Epoch: 6| Step: 9
Training loss: 1.6762713193893433
Validation loss: 2.2585312922795615

Epoch: 6| Step: 10
Training loss: 1.4629322290420532
Validation loss: 2.250192165374756

Epoch: 6| Step: 11
Training loss: 1.5149223804473877
Validation loss: 2.258173624674479

Epoch: 6| Step: 12
Training loss: 1.8660962581634521
Validation loss: 2.271189570426941

Epoch: 6| Step: 13
Training loss: 1.382907748222351
Validation loss: 2.2724963823954263

Epoch: 275| Step: 0
Training loss: 1.6823798418045044
Validation loss: 2.2729928692181907

Epoch: 6| Step: 1
Training loss: 1.1685065031051636
Validation loss: 2.271092196305593

Epoch: 6| Step: 2
Training loss: 0.8199776411056519
Validation loss: 2.226187606652578

Epoch: 6| Step: 3
Training loss: 1.458202600479126
Validation loss: 2.224951386451721

Epoch: 6| Step: 4
Training loss: 1.4242122173309326
Validation loss: 2.219652076562246

Epoch: 6| Step: 5
Training loss: 2.3540642261505127
Validation loss: 2.2338159481684365

Epoch: 6| Step: 6
Training loss: 2.0128588676452637
Validation loss: 2.1987105210622153

Epoch: 6| Step: 7
Training loss: 1.3789390325546265
Validation loss: 2.229110916455587

Epoch: 6| Step: 8
Training loss: 1.9499740600585938
Validation loss: 2.240342676639557

Epoch: 6| Step: 9
Training loss: 2.2751708030700684
Validation loss: 2.2673106590906777

Epoch: 6| Step: 10
Training loss: 1.9354475736618042
Validation loss: 2.2809715469678244

Epoch: 6| Step: 11
Training loss: 2.464944839477539
Validation loss: 2.2439043720563254

Epoch: 6| Step: 12
Training loss: 1.356537103652954
Validation loss: 2.2575419545173645

Epoch: 6| Step: 13
Training loss: 1.6735384464263916
Validation loss: 2.2608155806859336

Epoch: 276| Step: 0
Training loss: 1.2199063301086426
Validation loss: 2.2468119462331138

Epoch: 6| Step: 1
Training loss: 1.5131034851074219
Validation loss: 2.260215620199839

Epoch: 6| Step: 2
Training loss: 1.2140579223632812
Validation loss: 2.25269623597463

Epoch: 6| Step: 3
Training loss: 1.3363103866577148
Validation loss: 2.256915191809336

Epoch: 6| Step: 4
Training loss: 1.7710773944854736
Validation loss: 2.223639746507009

Epoch: 6| Step: 5
Training loss: 1.5025814771652222
Validation loss: 2.252024253209432

Epoch: 6| Step: 6
Training loss: 2.3638358116149902
Validation loss: 2.2374339501063027

Epoch: 6| Step: 7
Training loss: 2.195096969604492
Validation loss: 2.2252703110376992

Epoch: 6| Step: 8
Training loss: 1.0953084230422974
Validation loss: 2.2221168677012124

Epoch: 6| Step: 9
Training loss: 2.0056185722351074
Validation loss: 2.2414533694585166

Epoch: 6| Step: 10
Training loss: 2.747378349304199
Validation loss: 2.2322184642155967

Epoch: 6| Step: 11
Training loss: 1.3738293647766113
Validation loss: 2.2488682866096497

Epoch: 6| Step: 12
Training loss: 1.639441728591919
Validation loss: 2.2629346450169883

Epoch: 6| Step: 13
Training loss: 1.5280756950378418
Validation loss: 2.252237637837728

Epoch: 277| Step: 0
Training loss: 1.7706787586212158
Validation loss: 2.2609843015670776

Epoch: 6| Step: 1
Training loss: 1.3851330280303955
Validation loss: 2.240159332752228

Epoch: 6| Step: 2
Training loss: 1.998786211013794
Validation loss: 2.258108297983805

Epoch: 6| Step: 3
Training loss: 1.5095219612121582
Validation loss: 2.232330600420634

Epoch: 6| Step: 4
Training loss: 2.0138978958129883
Validation loss: 2.2210450569788613

Epoch: 6| Step: 5
Training loss: 1.7984328269958496
Validation loss: 2.2369144757588706

Epoch: 6| Step: 6
Training loss: 1.3759658336639404
Validation loss: 2.223768393198649

Epoch: 6| Step: 7
Training loss: 1.4978667497634888
Validation loss: 2.209933280944824

Epoch: 6| Step: 8
Training loss: 1.570819616317749
Validation loss: 2.239845414956411

Epoch: 6| Step: 9
Training loss: 1.5760409832000732
Validation loss: 2.206159551938375

Epoch: 6| Step: 10
Training loss: 2.4569597244262695
Validation loss: 2.2300033569335938

Epoch: 6| Step: 11
Training loss: 1.5643994808197021
Validation loss: 2.1951255003611245

Epoch: 6| Step: 12
Training loss: 2.2292821407318115
Validation loss: 2.213717838128408

Epoch: 6| Step: 13
Training loss: 1.3831169605255127
Validation loss: 2.20385471979777

Epoch: 278| Step: 0
Training loss: 1.7390804290771484
Validation loss: 2.2093065977096558

Epoch: 6| Step: 1
Training loss: 1.7767720222473145
Validation loss: 2.1839155157407126

Epoch: 6| Step: 2
Training loss: 1.8852462768554688
Validation loss: 2.1999505360921225

Epoch: 6| Step: 3
Training loss: 1.6982731819152832
Validation loss: 2.2249956329663596

Epoch: 6| Step: 4
Training loss: 2.2259278297424316
Validation loss: 2.224395195643107

Epoch: 6| Step: 5
Training loss: 1.8617959022521973
Validation loss: 2.2190388441085815

Epoch: 6| Step: 6
Training loss: 1.4325697422027588
Validation loss: 2.2508058746655784

Epoch: 6| Step: 7
Training loss: 1.4597551822662354
Validation loss: 2.231085459391276

Epoch: 6| Step: 8
Training loss: 2.319253921508789
Validation loss: 2.266478637854258

Epoch: 6| Step: 9
Training loss: 1.4177708625793457
Validation loss: 2.255581478277842

Epoch: 6| Step: 10
Training loss: 1.3810186386108398
Validation loss: 2.242397407690684

Epoch: 6| Step: 11
Training loss: 1.6355241537094116
Validation loss: 2.2544862826665244

Epoch: 6| Step: 12
Training loss: 1.4059007167816162
Validation loss: 2.2541693647702536

Epoch: 6| Step: 13
Training loss: 1.4613475799560547
Validation loss: 2.245699167251587

Epoch: 279| Step: 0
Training loss: 1.647437334060669
Validation loss: 2.244243860244751

Epoch: 6| Step: 1
Training loss: 1.0918844938278198
Validation loss: 2.2195982535680137

Epoch: 6| Step: 2
Training loss: 1.0272129774093628
Validation loss: 2.2413235108057656

Epoch: 6| Step: 3
Training loss: 1.2850420475006104
Validation loss: 2.2279993494351706

Epoch: 6| Step: 4
Training loss: 1.2321856021881104
Validation loss: 2.222933769226074

Epoch: 6| Step: 5
Training loss: 1.4784475564956665
Validation loss: 2.206263800462087

Epoch: 6| Step: 6
Training loss: 1.4088377952575684
Validation loss: 2.225879987080892

Epoch: 6| Step: 7
Training loss: 1.8133875131607056
Validation loss: 2.2544018228848777

Epoch: 6| Step: 8
Training loss: 2.2866978645324707
Validation loss: 2.233211795488993

Epoch: 6| Step: 9
Training loss: 2.3667356967926025
Validation loss: 2.2363834381103516

Epoch: 6| Step: 10
Training loss: 2.4074277877807617
Validation loss: 2.2111924489339194

Epoch: 6| Step: 11
Training loss: 1.77882981300354
Validation loss: 2.2141391237576804

Epoch: 6| Step: 12
Training loss: 1.4536831378936768
Validation loss: 2.2319979270299277

Epoch: 6| Step: 13
Training loss: 1.9908101558685303
Validation loss: 2.2399850289026895

Epoch: 280| Step: 0
Training loss: 1.507995367050171
Validation loss: 2.2549896438916526

Epoch: 6| Step: 1
Training loss: 1.2338755130767822
Validation loss: 2.209885835647583

Epoch: 6| Step: 2
Training loss: 1.2955833673477173
Validation loss: 2.2676009933153787

Epoch: 6| Step: 3
Training loss: 1.66592276096344
Validation loss: 2.2572636008262634

Epoch: 6| Step: 4
Training loss: 1.3057911396026611
Validation loss: 2.274110654989878

Epoch: 6| Step: 5
Training loss: 1.4931554794311523
Validation loss: 2.2505538066228232

Epoch: 6| Step: 6
Training loss: 1.4145878553390503
Validation loss: 2.2477309306462607

Epoch: 6| Step: 7
Training loss: 1.9329265356063843
Validation loss: 2.239083011945089

Epoch: 6| Step: 8
Training loss: 2.202408790588379
Validation loss: 2.2481154402097068

Epoch: 6| Step: 9
Training loss: 1.8221664428710938
Validation loss: 2.249346971511841

Epoch: 6| Step: 10
Training loss: 1.8226969242095947
Validation loss: 2.2574883699417114

Epoch: 6| Step: 11
Training loss: 1.7591934204101562
Validation loss: 2.2380309104919434

Epoch: 6| Step: 12
Training loss: 2.4973292350769043
Validation loss: 2.197166164716085

Epoch: 6| Step: 13
Training loss: 1.3367791175842285
Validation loss: 2.213818311691284

Epoch: 281| Step: 0
Training loss: 1.6583606004714966
Validation loss: 2.1704081296920776

Epoch: 6| Step: 1
Training loss: 1.7395062446594238
Validation loss: 2.199501951535543

Epoch: 6| Step: 2
Training loss: 2.056968927383423
Validation loss: 2.205512205759684

Epoch: 6| Step: 3
Training loss: 1.196754813194275
Validation loss: 2.202248136202494

Epoch: 6| Step: 4
Training loss: 1.1115005016326904
Validation loss: 2.2052804430325827

Epoch: 6| Step: 5
Training loss: 1.4951848983764648
Validation loss: 2.1896236340204873

Epoch: 6| Step: 6
Training loss: 1.595731258392334
Validation loss: 2.199444075425466

Epoch: 6| Step: 7
Training loss: 2.486396074295044
Validation loss: 2.2314422527949014

Epoch: 6| Step: 8
Training loss: 1.3768540620803833
Validation loss: 2.2048670450846353

Epoch: 6| Step: 9
Training loss: 1.4024370908737183
Validation loss: 2.2136016488075256

Epoch: 6| Step: 10
Training loss: 2.1705942153930664
Validation loss: 2.2326955795288086

Epoch: 6| Step: 11
Training loss: 1.674407720565796
Validation loss: 2.2726020415623984

Epoch: 6| Step: 12
Training loss: 1.8736850023269653
Validation loss: 2.252158761024475

Epoch: 6| Step: 13
Training loss: 1.569439172744751
Validation loss: 2.2491295337677

Epoch: 282| Step: 0
Training loss: 2.0301718711853027
Validation loss: 2.246403376261393

Epoch: 6| Step: 1
Training loss: 1.6083793640136719
Validation loss: 2.223536789417267

Epoch: 6| Step: 2
Training loss: 1.8307743072509766
Validation loss: 2.2503945231437683

Epoch: 6| Step: 3
Training loss: 1.5547469854354858
Validation loss: 2.231557627518972

Epoch: 6| Step: 4
Training loss: 1.7201073169708252
Validation loss: 2.221348245938619

Epoch: 6| Step: 5
Training loss: 2.2330307960510254
Validation loss: 2.244219104448954

Epoch: 6| Step: 6
Training loss: 1.4075710773468018
Validation loss: 2.258200784524282

Epoch: 6| Step: 7
Training loss: 0.9911352396011353
Validation loss: 2.2402862707773843

Epoch: 6| Step: 8
Training loss: 1.0246787071228027
Validation loss: 2.2488096952438354

Epoch: 6| Step: 9
Training loss: 1.864522099494934
Validation loss: 2.23096772034963

Epoch: 6| Step: 10
Training loss: 2.0967957973480225
Validation loss: 2.22269876797994

Epoch: 6| Step: 11
Training loss: 1.8945010900497437
Validation loss: 2.2007559140523276

Epoch: 6| Step: 12
Training loss: 1.5083681344985962
Validation loss: 2.198871910572052

Epoch: 6| Step: 13
Training loss: 1.9648025035858154
Validation loss: 2.2224896947542825

Epoch: 283| Step: 0
Training loss: 1.8036601543426514
Validation loss: 2.184809386730194

Epoch: 6| Step: 1
Training loss: 1.5067791938781738
Validation loss: 2.2114152113596597

Epoch: 6| Step: 2
Training loss: 1.70297372341156
Validation loss: 2.2065823674201965

Epoch: 6| Step: 3
Training loss: 1.3628004789352417
Validation loss: 2.209791620572408

Epoch: 6| Step: 4
Training loss: 2.0678939819335938
Validation loss: 2.2039555311203003

Epoch: 6| Step: 5
Training loss: 1.6120400428771973
Validation loss: 2.248451312383016

Epoch: 6| Step: 6
Training loss: 1.8337706327438354
Validation loss: 2.254466950893402

Epoch: 6| Step: 7
Training loss: 2.1301021575927734
Validation loss: 2.2430171966552734

Epoch: 6| Step: 8
Training loss: 1.6713138818740845
Validation loss: 2.232204556465149

Epoch: 6| Step: 9
Training loss: 1.4582844972610474
Validation loss: 2.2548641363779702

Epoch: 6| Step: 10
Training loss: 2.3038809299468994
Validation loss: 2.276438355445862

Epoch: 6| Step: 11
Training loss: 2.5766139030456543
Validation loss: 2.226602474848429

Epoch: 6| Step: 12
Training loss: 1.9610769748687744
Validation loss: 2.2399025360743203

Epoch: 6| Step: 13
Training loss: 0.7961328029632568
Validation loss: 2.2282404700915017

Epoch: 284| Step: 0
Training loss: 2.681199789047241
Validation loss: 2.2056382497151694

Epoch: 6| Step: 1
Training loss: 2.2362382411956787
Validation loss: 2.215060313542684

Epoch: 6| Step: 2
Training loss: 1.76835298538208
Validation loss: 2.2169363101323447

Epoch: 6| Step: 3
Training loss: 1.949993371963501
Validation loss: 2.2183749278386435

Epoch: 6| Step: 4
Training loss: 1.0869183540344238
Validation loss: 2.2359507083892822

Epoch: 6| Step: 5
Training loss: 2.009885787963867
Validation loss: 2.2360899845759072

Epoch: 6| Step: 6
Training loss: 1.635683298110962
Validation loss: 2.2429423133532205

Epoch: 6| Step: 7
Training loss: 1.1230710744857788
Validation loss: 2.2279620369275412

Epoch: 6| Step: 8
Training loss: 1.7440783977508545
Validation loss: 2.202889343102773

Epoch: 6| Step: 9
Training loss: 1.3614821434020996
Validation loss: 2.2314318418502808

Epoch: 6| Step: 10
Training loss: 0.8515331745147705
Validation loss: 2.2540496587753296

Epoch: 6| Step: 11
Training loss: 2.204594612121582
Validation loss: 2.261305352052053

Epoch: 6| Step: 12
Training loss: 1.2917625904083252
Validation loss: 2.2493476271629333

Epoch: 6| Step: 13
Training loss: 1.7670173645019531
Validation loss: 2.2440295616785684

Epoch: 285| Step: 0
Training loss: 1.8988323211669922
Validation loss: 2.250623802344004

Epoch: 6| Step: 1
Training loss: 1.871948003768921
Validation loss: 2.2207669417063394

Epoch: 6| Step: 2
Training loss: 1.6783336400985718
Validation loss: 2.2361276547114053

Epoch: 6| Step: 3
Training loss: 2.21705961227417
Validation loss: 2.2437746127446494

Epoch: 6| Step: 4
Training loss: 1.1575982570648193
Validation loss: 2.233569403489431

Epoch: 6| Step: 5
Training loss: 1.370103359222412
Validation loss: 2.2255128423372903

Epoch: 6| Step: 6
Training loss: 1.460670828819275
Validation loss: 2.229231059551239

Epoch: 6| Step: 7
Training loss: 1.8858665227890015
Validation loss: 2.237990657488505

Epoch: 6| Step: 8
Training loss: 1.0088955163955688
Validation loss: 2.241420249144236

Epoch: 6| Step: 9
Training loss: 2.075730800628662
Validation loss: 2.2479988733927407

Epoch: 6| Step: 10
Training loss: 1.530040979385376
Validation loss: 2.2323657870292664

Epoch: 6| Step: 11
Training loss: 1.476670503616333
Validation loss: 2.2206004659334817

Epoch: 6| Step: 12
Training loss: 1.9734586477279663
Validation loss: 2.258335769176483

Epoch: 6| Step: 13
Training loss: 1.6794726848602295
Validation loss: 2.2562904755274453

Epoch: 286| Step: 0
Training loss: 2.0904829502105713
Validation loss: 2.2322380741437278

Epoch: 6| Step: 1
Training loss: 2.4694385528564453
Validation loss: 2.2139411767323813

Epoch: 6| Step: 2
Training loss: 1.732541799545288
Validation loss: 2.2478697697321572

Epoch: 6| Step: 3
Training loss: 1.236279010772705
Validation loss: 2.2347302039464316

Epoch: 6| Step: 4
Training loss: 1.3240962028503418
Validation loss: 2.2273632486661277

Epoch: 6| Step: 5
Training loss: 0.8828791379928589
Validation loss: 2.217581033706665

Epoch: 6| Step: 6
Training loss: 0.8995590209960938
Validation loss: 2.2415929238001504

Epoch: 6| Step: 7
Training loss: 1.8210744857788086
Validation loss: 2.2297713359196982

Epoch: 6| Step: 8
Training loss: 1.3731169700622559
Validation loss: 2.2638428807258606

Epoch: 6| Step: 9
Training loss: 2.1790952682495117
Validation loss: 2.2601071198781333

Epoch: 6| Step: 10
Training loss: 1.6930327415466309
Validation loss: 2.2390024264653525

Epoch: 6| Step: 11
Training loss: 1.9324151277542114
Validation loss: 2.2376394073168435

Epoch: 6| Step: 12
Training loss: 1.835080623626709
Validation loss: 2.220907986164093

Epoch: 6| Step: 13
Training loss: 2.0931034088134766
Validation loss: 2.260915478070577

Epoch: 287| Step: 0
Training loss: 1.5133247375488281
Validation loss: 2.2436442375183105

Epoch: 6| Step: 1
Training loss: 1.9066181182861328
Validation loss: 2.2601440151532493

Epoch: 6| Step: 2
Training loss: 2.2446975708007812
Validation loss: 2.2281421422958374

Epoch: 6| Step: 3
Training loss: 0.9805282950401306
Validation loss: 2.2324187954266868

Epoch: 6| Step: 4
Training loss: 2.3985178470611572
Validation loss: 2.2150110006332397

Epoch: 6| Step: 5
Training loss: 1.6735529899597168
Validation loss: 2.1942509015401206

Epoch: 6| Step: 6
Training loss: 1.1114921569824219
Validation loss: 2.164741655190786

Epoch: 6| Step: 7
Training loss: 1.8892556428909302
Validation loss: 2.185684243837992

Epoch: 6| Step: 8
Training loss: 2.516420364379883
Validation loss: 2.1956501603126526

Epoch: 6| Step: 9
Training loss: 2.032423496246338
Validation loss: 2.1851028005282083

Epoch: 6| Step: 10
Training loss: 2.1102371215820312
Validation loss: 2.1778531471888223

Epoch: 6| Step: 11
Training loss: 2.2375974655151367
Validation loss: 2.186743954817454

Epoch: 6| Step: 12
Training loss: 1.4540749788284302
Validation loss: 2.190162718296051

Epoch: 6| Step: 13
Training loss: 2.029747724533081
Validation loss: 2.1850097378094993

Epoch: 288| Step: 0
Training loss: 0.9371737241744995
Validation loss: 2.209190309047699

Epoch: 6| Step: 1
Training loss: 2.4192166328430176
Validation loss: 2.2193145155906677

Epoch: 6| Step: 2
Training loss: 1.622113585472107
Validation loss: 2.2501729329427085

Epoch: 6| Step: 3
Training loss: 1.4220728874206543
Validation loss: 2.222392956415812

Epoch: 6| Step: 4
Training loss: 1.9869866371154785
Validation loss: 2.230000058809916

Epoch: 6| Step: 5
Training loss: 2.2052462100982666
Validation loss: 2.2351208130518594

Epoch: 6| Step: 6
Training loss: 1.1461938619613647
Validation loss: 2.2503289779027305

Epoch: 6| Step: 7
Training loss: 1.581131935119629
Validation loss: 2.2180764079093933

Epoch: 6| Step: 8
Training loss: 1.3518409729003906
Validation loss: 2.2144410212834678

Epoch: 6| Step: 9
Training loss: 1.7435495853424072
Validation loss: 2.2376488049825034

Epoch: 6| Step: 10
Training loss: 1.5000157356262207
Validation loss: 2.2225228349367776

Epoch: 6| Step: 11
Training loss: 1.8173311948776245
Validation loss: 2.216376860936483

Epoch: 6| Step: 12
Training loss: 2.3502931594848633
Validation loss: 2.206889351209005

Epoch: 6| Step: 13
Training loss: 2.3395700454711914
Validation loss: 2.1898571054140725

Epoch: 289| Step: 0
Training loss: 1.7662726640701294
Validation loss: 2.176212946573893

Epoch: 6| Step: 1
Training loss: 1.9376991987228394
Validation loss: 2.1815751791000366

Epoch: 6| Step: 2
Training loss: 2.145658493041992
Validation loss: 2.1672931710879006

Epoch: 6| Step: 3
Training loss: 1.2435818910598755
Validation loss: 2.1910184224446616

Epoch: 6| Step: 4
Training loss: 1.300708293914795
Validation loss: 2.2066595554351807

Epoch: 6| Step: 5
Training loss: 1.80990731716156
Validation loss: 2.1931381821632385

Epoch: 6| Step: 6
Training loss: 2.349083423614502
Validation loss: 2.1975985765457153

Epoch: 6| Step: 7
Training loss: 1.4787441492080688
Validation loss: 2.233824868996938

Epoch: 6| Step: 8
Training loss: 1.4148017168045044
Validation loss: 2.2475417057673135

Epoch: 6| Step: 9
Training loss: 2.0160436630249023
Validation loss: 2.261338929335276

Epoch: 6| Step: 10
Training loss: 1.3397278785705566
Validation loss: 2.2341549595197043

Epoch: 6| Step: 11
Training loss: 1.3191542625427246
Validation loss: 2.2468079129854837

Epoch: 6| Step: 12
Training loss: 1.484262228012085
Validation loss: 2.233392337958018

Epoch: 6| Step: 13
Training loss: 2.002990245819092
Validation loss: 2.247001349925995

Epoch: 290| Step: 0
Training loss: 1.4508020877838135
Validation loss: 2.271349926789602

Epoch: 6| Step: 1
Training loss: 1.8721423149108887
Validation loss: 2.270310123761495

Epoch: 6| Step: 2
Training loss: 1.7042715549468994
Validation loss: 2.262011170387268

Epoch: 6| Step: 3
Training loss: 1.414015293121338
Validation loss: 2.270525813102722

Epoch: 6| Step: 4
Training loss: 1.6526391506195068
Validation loss: 2.272576948006948

Epoch: 6| Step: 5
Training loss: 2.2912020683288574
Validation loss: 2.2780991593996682

Epoch: 6| Step: 6
Training loss: 1.9699251651763916
Validation loss: 2.2654181520144143

Epoch: 6| Step: 7
Training loss: 1.5139895677566528
Validation loss: 2.2866004506746926

Epoch: 6| Step: 8
Training loss: 2.024700880050659
Validation loss: 2.2752801378568015

Epoch: 6| Step: 9
Training loss: 1.689985752105713
Validation loss: 2.268045405546824

Epoch: 6| Step: 10
Training loss: 2.129026412963867
Validation loss: 2.2275835275650024

Epoch: 6| Step: 11
Training loss: 1.7466380596160889
Validation loss: 2.2416651844978333

Epoch: 6| Step: 12
Training loss: 0.7250583171844482
Validation loss: 2.2279247840245566

Epoch: 6| Step: 13
Training loss: 1.334686279296875
Validation loss: 2.2248365680376687

Epoch: 291| Step: 0
Training loss: 1.8039116859436035
Validation loss: 2.2170217037200928

Epoch: 6| Step: 1
Training loss: 2.018975257873535
Validation loss: 2.2168665329615274

Epoch: 6| Step: 2
Training loss: 1.3595061302185059
Validation loss: 2.2243820230166116

Epoch: 6| Step: 3
Training loss: 1.950988531112671
Validation loss: 2.233028292655945

Epoch: 6| Step: 4
Training loss: 1.667108178138733
Validation loss: 2.221051553885142

Epoch: 6| Step: 5
Training loss: 1.7671042680740356
Validation loss: 2.2216124137242637

Epoch: 6| Step: 6
Training loss: 1.4651139974594116
Validation loss: 2.2555012702941895

Epoch: 6| Step: 7
Training loss: 1.367173671722412
Validation loss: 2.2564757466316223

Epoch: 6| Step: 8
Training loss: 1.7844312191009521
Validation loss: 2.247173627217611

Epoch: 6| Step: 9
Training loss: 1.3472259044647217
Validation loss: 2.293941597143809

Epoch: 6| Step: 10
Training loss: 1.8861382007598877
Validation loss: 2.269757866859436

Epoch: 6| Step: 11
Training loss: 1.9755666255950928
Validation loss: 2.257286548614502

Epoch: 6| Step: 12
Training loss: 1.3861687183380127
Validation loss: 2.2709114154179892

Epoch: 6| Step: 13
Training loss: 1.5492277145385742
Validation loss: 2.250231941541036

Epoch: 292| Step: 0
Training loss: 2.027977705001831
Validation loss: 2.2325395147005715

Epoch: 6| Step: 1
Training loss: 1.4818171262741089
Validation loss: 2.2367292642593384

Epoch: 6| Step: 2
Training loss: 1.4761950969696045
Validation loss: 2.232515494028727

Epoch: 6| Step: 3
Training loss: 1.1138347387313843
Validation loss: 2.2272003889083862

Epoch: 6| Step: 4
Training loss: 2.268195629119873
Validation loss: 2.2356626987457275

Epoch: 6| Step: 5
Training loss: 1.6136150360107422
Validation loss: 2.263320207595825

Epoch: 6| Step: 6
Training loss: 1.6091279983520508
Validation loss: 2.2576486468315125

Epoch: 6| Step: 7
Training loss: 1.9033782482147217
Validation loss: 2.2565091848373413

Epoch: 6| Step: 8
Training loss: 1.6196064949035645
Validation loss: 2.2806774775187173

Epoch: 6| Step: 9
Training loss: 1.776097297668457
Validation loss: 2.2786884705225625

Epoch: 6| Step: 10
Training loss: 1.6598924398422241
Validation loss: 2.2683584888776145

Epoch: 6| Step: 11
Training loss: 1.5631120204925537
Validation loss: 2.301444192727407

Epoch: 6| Step: 12
Training loss: 1.5553313493728638
Validation loss: 2.2677361369132996

Epoch: 6| Step: 13
Training loss: 1.29385507106781
Validation loss: 2.2726194262504578

Epoch: 293| Step: 0
Training loss: 1.2463994026184082
Validation loss: 2.235859970251719

Epoch: 6| Step: 1
Training loss: 1.5995936393737793
Validation loss: 2.243315021197001

Epoch: 6| Step: 2
Training loss: 1.653739094734192
Validation loss: 2.2258062958717346

Epoch: 6| Step: 3
Training loss: 1.9669064283370972
Validation loss: 2.2188482085863748

Epoch: 6| Step: 4
Training loss: 2.190577268600464
Validation loss: 2.213200012842814

Epoch: 6| Step: 5
Training loss: 1.3314110040664673
Validation loss: 2.216628313064575

Epoch: 6| Step: 6
Training loss: 1.3502678871154785
Validation loss: 2.21011745929718

Epoch: 6| Step: 7
Training loss: 1.8533408641815186
Validation loss: 2.216800570487976

Epoch: 6| Step: 8
Training loss: 1.6430155038833618
Validation loss: 2.2435540358225503

Epoch: 6| Step: 9
Training loss: 1.3449746370315552
Validation loss: 2.2524763147036233

Epoch: 6| Step: 10
Training loss: 1.7513337135314941
Validation loss: 2.257838785648346

Epoch: 6| Step: 11
Training loss: 1.7160022258758545
Validation loss: 2.2422985434532166

Epoch: 6| Step: 12
Training loss: 2.026259422302246
Validation loss: 2.27700142065684

Epoch: 6| Step: 13
Training loss: 1.9028172492980957
Validation loss: 2.27402663230896

Epoch: 294| Step: 0
Training loss: 1.1257725954055786
Validation loss: 2.2904173533121743

Epoch: 6| Step: 1
Training loss: 1.6481503248214722
Validation loss: 2.2917439341545105

Epoch: 6| Step: 2
Training loss: 1.3592422008514404
Validation loss: 2.335381110509237

Epoch: 6| Step: 3
Training loss: 0.9949333667755127
Validation loss: 2.3246780236562095

Epoch: 6| Step: 4
Training loss: 1.9204118251800537
Validation loss: 2.3147367040316262

Epoch: 6| Step: 5
Training loss: 2.4551663398742676
Validation loss: 2.3142274419466653

Epoch: 6| Step: 6
Training loss: 0.9740622043609619
Validation loss: 2.3010517358779907

Epoch: 6| Step: 7
Training loss: 1.6827712059020996
Validation loss: 2.2464096943537393

Epoch: 6| Step: 8
Training loss: 1.317885160446167
Validation loss: 2.2502018014589944

Epoch: 6| Step: 9
Training loss: 1.7700090408325195
Validation loss: 2.251992702484131

Epoch: 6| Step: 10
Training loss: 2.146519899368286
Validation loss: 2.2422475616137185

Epoch: 6| Step: 11
Training loss: 2.40267276763916
Validation loss: 2.251591960589091

Epoch: 6| Step: 12
Training loss: 1.297304630279541
Validation loss: 2.2396042545636496

Epoch: 6| Step: 13
Training loss: 1.5273942947387695
Validation loss: 2.2525742053985596

Epoch: 295| Step: 0
Training loss: 1.4656316041946411
Validation loss: 2.2508718967437744

Epoch: 6| Step: 1
Training loss: 1.8844329118728638
Validation loss: 2.232077121734619

Epoch: 6| Step: 2
Training loss: 1.4546399116516113
Validation loss: 2.2328540682792664

Epoch: 6| Step: 3
Training loss: 1.6639522314071655
Validation loss: 2.2224934895833335

Epoch: 6| Step: 4
Training loss: 1.8136253356933594
Validation loss: 2.2374509970347085

Epoch: 6| Step: 5
Training loss: 1.2717610597610474
Validation loss: 2.2496745189030967

Epoch: 6| Step: 6
Training loss: 1.8369234800338745
Validation loss: 2.256867289543152

Epoch: 6| Step: 7
Training loss: 1.6822521686553955
Validation loss: 2.2593500216801963

Epoch: 6| Step: 8
Training loss: 1.449804425239563
Validation loss: 2.248154103755951

Epoch: 6| Step: 9
Training loss: 2.228085994720459
Validation loss: 2.2544538180033364

Epoch: 6| Step: 10
Training loss: 2.0694093704223633
Validation loss: 2.2657752633094788

Epoch: 6| Step: 11
Training loss: 1.65838623046875
Validation loss: 2.2476576566696167

Epoch: 6| Step: 12
Training loss: 2.385363817214966
Validation loss: 2.2515597343444824

Epoch: 6| Step: 13
Training loss: 1.3837522268295288
Validation loss: 2.2413076957066855

Epoch: 296| Step: 0
Training loss: 1.7962853908538818
Validation loss: 2.265113631884257

Epoch: 6| Step: 1
Training loss: 1.7172770500183105
Validation loss: 2.2589423259099326

Epoch: 6| Step: 2
Training loss: 1.773018479347229
Validation loss: 2.2459988991419473

Epoch: 6| Step: 3
Training loss: 1.835241436958313
Validation loss: 2.2563191453615823

Epoch: 6| Step: 4
Training loss: 2.225951671600342
Validation loss: 2.238733470439911

Epoch: 6| Step: 5
Training loss: 1.1833312511444092
Validation loss: 2.227793037891388

Epoch: 6| Step: 6
Training loss: 1.8380401134490967
Validation loss: 2.233599066734314

Epoch: 6| Step: 7
Training loss: 1.6088721752166748
Validation loss: 2.2543318271636963

Epoch: 6| Step: 8
Training loss: 1.1407430171966553
Validation loss: 2.2382961312929788

Epoch: 6| Step: 9
Training loss: 0.9777353405952454
Validation loss: 2.2515047788619995

Epoch: 6| Step: 10
Training loss: 1.7794182300567627
Validation loss: 2.2729037006696067

Epoch: 6| Step: 11
Training loss: 1.8436391353607178
Validation loss: 2.256480097770691

Epoch: 6| Step: 12
Training loss: 1.9639091491699219
Validation loss: 2.2648492058118186

Epoch: 6| Step: 13
Training loss: 1.4378780126571655
Validation loss: 2.258210380872091

Epoch: 297| Step: 0
Training loss: 1.654229760169983
Validation loss: 2.245132327079773

Epoch: 6| Step: 1
Training loss: 1.531984806060791
Validation loss: 2.22526886065801

Epoch: 6| Step: 2
Training loss: 1.087573766708374
Validation loss: 2.213654617468516

Epoch: 6| Step: 3
Training loss: 1.838731050491333
Validation loss: 2.219266692797343

Epoch: 6| Step: 4
Training loss: 1.7483155727386475
Validation loss: 2.2015273173650107

Epoch: 6| Step: 5
Training loss: 1.9496347904205322
Validation loss: 2.225174347559611

Epoch: 6| Step: 6
Training loss: 1.4447189569473267
Validation loss: 2.233591397603353

Epoch: 6| Step: 7
Training loss: 1.335585594177246
Validation loss: 2.235390583674113

Epoch: 6| Step: 8
Training loss: 1.9761033058166504
Validation loss: 2.2424856424331665

Epoch: 6| Step: 9
Training loss: 0.7957286834716797
Validation loss: 2.2358357906341553

Epoch: 6| Step: 10
Training loss: 1.4224097728729248
Validation loss: 2.2530285716056824

Epoch: 6| Step: 11
Training loss: 2.0988638401031494
Validation loss: 2.2580673495928445

Epoch: 6| Step: 12
Training loss: 2.0783908367156982
Validation loss: 2.2488391399383545

Epoch: 6| Step: 13
Training loss: 1.8726451396942139
Validation loss: 2.253013471762339

Epoch: 298| Step: 0
Training loss: 1.5617362260818481
Validation loss: 2.25456303358078

Epoch: 6| Step: 1
Training loss: 1.8087410926818848
Validation loss: 2.250611106554667

Epoch: 6| Step: 2
Training loss: 2.044434070587158
Validation loss: 2.2659050027529397

Epoch: 6| Step: 3
Training loss: 0.9661041498184204
Validation loss: 2.241601268450419

Epoch: 6| Step: 4
Training loss: 1.7263612747192383
Validation loss: 2.2453330953915915

Epoch: 6| Step: 5
Training loss: 1.5148780345916748
Validation loss: 2.247124195098877

Epoch: 6| Step: 6
Training loss: 1.2469894886016846
Validation loss: 2.2290218671162925

Epoch: 6| Step: 7
Training loss: 1.773240566253662
Validation loss: 2.241131583849589

Epoch: 6| Step: 8
Training loss: 1.3947151899337769
Validation loss: 2.2239283323287964

Epoch: 6| Step: 9
Training loss: 0.7518543601036072
Validation loss: 2.2300493915875754

Epoch: 6| Step: 10
Training loss: 2.470745086669922
Validation loss: 2.2639787991841636

Epoch: 6| Step: 11
Training loss: 1.8717968463897705
Validation loss: 2.2455081144968667

Epoch: 6| Step: 12
Training loss: 1.391327142715454
Validation loss: 2.2424298524856567

Epoch: 6| Step: 13
Training loss: 1.7425282001495361
Validation loss: 2.2158164978027344

Epoch: 299| Step: 0
Training loss: 1.764703631401062
Validation loss: 2.2151410579681396

Epoch: 6| Step: 1
Training loss: 1.7334038019180298
Validation loss: 2.2361961801846824

Epoch: 6| Step: 2
Training loss: 1.8073352575302124
Validation loss: 2.2276440461476645

Epoch: 6| Step: 3
Training loss: 1.8207347393035889
Validation loss: 2.222238083680471

Epoch: 6| Step: 4
Training loss: 1.715710163116455
Validation loss: 2.2218589584032693

Epoch: 6| Step: 5
Training loss: 1.5002896785736084
Validation loss: 2.2275620698928833

Epoch: 6| Step: 6
Training loss: 1.6740527153015137
Validation loss: 2.2363619605700173

Epoch: 6| Step: 7
Training loss: 1.9116231203079224
Validation loss: 2.2419482668240867

Epoch: 6| Step: 8
Training loss: 1.632167100906372
Validation loss: 2.261856993039449

Epoch: 6| Step: 9
Training loss: 1.0531623363494873
Validation loss: 2.2532386978467307

Epoch: 6| Step: 10
Training loss: 1.437518835067749
Validation loss: 2.2316084702809653

Epoch: 6| Step: 11
Training loss: 2.1328070163726807
Validation loss: 2.2207226554552713

Epoch: 6| Step: 12
Training loss: 1.4873018264770508
Validation loss: 2.2061621149381003

Epoch: 6| Step: 13
Training loss: 1.224214792251587
Validation loss: 2.2009326815605164

Epoch: 300| Step: 0
Training loss: 1.6073018312454224
Validation loss: 2.197561780611674

Epoch: 6| Step: 1
Training loss: 1.9928479194641113
Validation loss: 2.193716843922933

Epoch: 6| Step: 2
Training loss: 1.2107383012771606
Validation loss: 2.213981548945109

Epoch: 6| Step: 3
Training loss: 1.4362260103225708
Validation loss: 2.20365317662557

Epoch: 6| Step: 4
Training loss: 1.6733776330947876
Validation loss: 2.2244548201560974

Epoch: 6| Step: 5
Training loss: 1.53902268409729
Validation loss: 2.20853324731191

Epoch: 6| Step: 6
Training loss: 1.1767112016677856
Validation loss: 2.227691888809204

Epoch: 6| Step: 7
Training loss: 1.326894998550415
Validation loss: 2.2235191067059836

Epoch: 6| Step: 8
Training loss: 1.7166283130645752
Validation loss: 2.256528298060099

Epoch: 6| Step: 9
Training loss: 2.0285935401916504
Validation loss: 2.2383269468943277

Epoch: 6| Step: 10
Training loss: 1.36796236038208
Validation loss: 2.2500237623850503

Epoch: 6| Step: 11
Training loss: 1.9331068992614746
Validation loss: 2.263213892777761

Epoch: 6| Step: 12
Training loss: 1.4571536779403687
Validation loss: 2.2888380885124207

Epoch: 6| Step: 13
Training loss: 1.9388775825500488
Validation loss: 2.244325319925944

Epoch: 301| Step: 0
Training loss: 1.4806324243545532
Validation loss: 2.23424623409907

Epoch: 6| Step: 1
Training loss: 1.2188267707824707
Validation loss: 2.264130930105845

Epoch: 6| Step: 2
Training loss: 1.677943229675293
Validation loss: 2.2426698803901672

Epoch: 6| Step: 3
Training loss: 2.197422981262207
Validation loss: 2.238443930943807

Epoch: 6| Step: 4
Training loss: 1.7531685829162598
Validation loss: 2.2414234280586243

Epoch: 6| Step: 5
Training loss: 1.9007833003997803
Validation loss: 2.227605104446411

Epoch: 6| Step: 6
Training loss: 1.561471939086914
Validation loss: 2.2503175338109336

Epoch: 6| Step: 7
Training loss: 2.048631191253662
Validation loss: 2.258464773495992

Epoch: 6| Step: 8
Training loss: 1.118837833404541
Validation loss: 2.249933362007141

Epoch: 6| Step: 9
Training loss: 1.8290166854858398
Validation loss: 2.2549952467282615

Epoch: 6| Step: 10
Training loss: 0.7887367010116577
Validation loss: 2.24349045753479

Epoch: 6| Step: 11
Training loss: 1.4767303466796875
Validation loss: 2.2252995570500693

Epoch: 6| Step: 12
Training loss: 1.5800635814666748
Validation loss: 2.2066227793693542

Epoch: 6| Step: 13
Training loss: 1.5138764381408691
Validation loss: 2.208055635293325

Epoch: 302| Step: 0
Training loss: 1.5154643058776855
Validation loss: 2.2194844484329224

Epoch: 6| Step: 1
Training loss: 1.6940431594848633
Validation loss: 2.2488431334495544

Epoch: 6| Step: 2
Training loss: 1.6821573972702026
Validation loss: 2.2378242214520774

Epoch: 6| Step: 3
Training loss: 1.2306870222091675
Validation loss: 2.2420168916384378

Epoch: 6| Step: 4
Training loss: 1.9440187215805054
Validation loss: 2.2731350660324097

Epoch: 6| Step: 5
Training loss: 2.0645837783813477
Validation loss: 2.256646156311035

Epoch: 6| Step: 6
Training loss: 2.1075639724731445
Validation loss: 2.279759327570597

Epoch: 6| Step: 7
Training loss: 1.4136309623718262
Validation loss: 2.2806785305341086

Epoch: 6| Step: 8
Training loss: 1.0306549072265625
Validation loss: 2.2679932912190757

Epoch: 6| Step: 9
Training loss: 2.082249402999878
Validation loss: 2.2773567040761313

Epoch: 6| Step: 10
Training loss: 0.8866026401519775
Validation loss: 2.243840456008911

Epoch: 6| Step: 11
Training loss: 1.3660578727722168
Validation loss: 2.2612452109654746

Epoch: 6| Step: 12
Training loss: 2.0737814903259277
Validation loss: 2.2403761943181357

Epoch: 6| Step: 13
Training loss: 1.0631619691848755
Validation loss: 2.2640822728474936

Epoch: 303| Step: 0
Training loss: 1.7474749088287354
Validation loss: 2.2384758591651917

Epoch: 6| Step: 1
Training loss: 2.0510072708129883
Validation loss: 2.2399622797966003

Epoch: 6| Step: 2
Training loss: 1.4176459312438965
Validation loss: 2.2387521664301553

Epoch: 6| Step: 3
Training loss: 1.6530243158340454
Validation loss: 2.2407883405685425

Epoch: 6| Step: 4
Training loss: 1.1682803630828857
Validation loss: 2.2408076524734497

Epoch: 6| Step: 5
Training loss: 1.6022123098373413
Validation loss: 2.2698054909706116

Epoch: 6| Step: 6
Training loss: 1.168211817741394
Validation loss: 2.280329386393229

Epoch: 6| Step: 7
Training loss: 1.5835996866226196
Validation loss: 2.2747598687807717

Epoch: 6| Step: 8
Training loss: 1.6057045459747314
Validation loss: 2.2738982836405435

Epoch: 6| Step: 9
Training loss: 1.6567647457122803
Validation loss: 2.2592910329500833

Epoch: 6| Step: 10
Training loss: 1.1876451969146729
Validation loss: 2.26299786567688

Epoch: 6| Step: 11
Training loss: 1.9160716533660889
Validation loss: 2.270899494489034

Epoch: 6| Step: 12
Training loss: 1.6795356273651123
Validation loss: 2.250166416168213

Epoch: 6| Step: 13
Training loss: 1.7579128742218018
Validation loss: 2.290540357430776

Epoch: 304| Step: 0
Training loss: 1.2054104804992676
Validation loss: 2.2746073404947915

Epoch: 6| Step: 1
Training loss: 1.7455182075500488
Validation loss: 2.310606837272644

Epoch: 6| Step: 2
Training loss: 1.2447144985198975
Validation loss: 2.243422786394755

Epoch: 6| Step: 3
Training loss: 2.396878957748413
Validation loss: 2.253848135471344

Epoch: 6| Step: 4
Training loss: 1.0819048881530762
Validation loss: 2.2528887589772544

Epoch: 6| Step: 5
Training loss: 1.8126376867294312
Validation loss: 2.2428129514058432

Epoch: 6| Step: 6
Training loss: 1.9959924221038818
Validation loss: 2.25051615635554

Epoch: 6| Step: 7
Training loss: 1.9517865180969238
Validation loss: 2.2441243529319763

Epoch: 6| Step: 8
Training loss: 1.8941693305969238
Validation loss: 2.229995310306549

Epoch: 6| Step: 9
Training loss: 1.8152883052825928
Validation loss: 2.248741785685221

Epoch: 6| Step: 10
Training loss: 2.086249828338623
Validation loss: 2.2486987312634787

Epoch: 6| Step: 11
Training loss: 0.845732569694519
Validation loss: 2.253365715344747

Epoch: 6| Step: 12
Training loss: 1.520384669303894
Validation loss: 2.2569817900657654

Epoch: 6| Step: 13
Training loss: 1.6411181688308716
Validation loss: 2.239230771859487

Epoch: 305| Step: 0
Training loss: 1.258368730545044
Validation loss: 2.2535385290781655

Epoch: 6| Step: 1
Training loss: 2.238269329071045
Validation loss: 2.2566943168640137

Epoch: 6| Step: 2
Training loss: 1.238551378250122
Validation loss: 2.262380361557007

Epoch: 6| Step: 3
Training loss: 1.5349606275558472
Validation loss: 2.265436271826426

Epoch: 6| Step: 4
Training loss: 2.0001111030578613
Validation loss: 2.261655271053314

Epoch: 6| Step: 5
Training loss: 1.6051349639892578
Validation loss: 2.2774343689282737

Epoch: 6| Step: 6
Training loss: 1.4080768823623657
Validation loss: 2.2550139824549356

Epoch: 6| Step: 7
Training loss: 1.0708446502685547
Validation loss: 2.2697815696398416

Epoch: 6| Step: 8
Training loss: 1.6592737436294556
Validation loss: 2.255606770515442

Epoch: 6| Step: 9
Training loss: 1.4093377590179443
Validation loss: 2.2551221450169883

Epoch: 6| Step: 10
Training loss: 1.659210443496704
Validation loss: 2.264794866243998

Epoch: 6| Step: 11
Training loss: 1.7994483709335327
Validation loss: 2.259411176045736

Epoch: 6| Step: 12
Training loss: 1.4807627201080322
Validation loss: 2.2568930784861245

Epoch: 6| Step: 13
Training loss: 1.7855963706970215
Validation loss: 2.2609824538230896

Epoch: 306| Step: 0
Training loss: 1.567803144454956
Validation loss: 2.261484146118164

Epoch: 6| Step: 1
Training loss: 1.1800975799560547
Validation loss: 2.233543952306112

Epoch: 6| Step: 2
Training loss: 1.521118402481079
Validation loss: 2.267070750395457

Epoch: 6| Step: 3
Training loss: 1.2971423864364624
Validation loss: 2.258097251256307

Epoch: 6| Step: 4
Training loss: 1.2226277589797974
Validation loss: 2.2588348587354026

Epoch: 6| Step: 5
Training loss: 1.042060136795044
Validation loss: 2.277246872584025

Epoch: 6| Step: 6
Training loss: 1.2297229766845703
Validation loss: 2.272693912188212

Epoch: 6| Step: 7
Training loss: 1.5815601348876953
Validation loss: 2.2803948720296225

Epoch: 6| Step: 8
Training loss: 1.9418044090270996
Validation loss: 2.2694374720255532

Epoch: 6| Step: 9
Training loss: 2.5356602668762207
Validation loss: 2.23389325539271

Epoch: 6| Step: 10
Training loss: 1.4730302095413208
Validation loss: 2.249628027280172

Epoch: 6| Step: 11
Training loss: 2.041787624359131
Validation loss: 2.291967829068502

Epoch: 6| Step: 12
Training loss: 1.8986681699752808
Validation loss: 2.2928526600201926

Epoch: 6| Step: 13
Training loss: 1.4686355590820312
Validation loss: 2.279546638329824

Epoch: 307| Step: 0
Training loss: 1.1606652736663818
Validation loss: 2.2613603671391806

Epoch: 6| Step: 1
Training loss: 1.7814022302627563
Validation loss: 2.28261669476827

Epoch: 6| Step: 2
Training loss: 1.989214301109314
Validation loss: 2.276414771874746

Epoch: 6| Step: 3
Training loss: 1.4200680255889893
Validation loss: 2.293251713116964

Epoch: 6| Step: 4
Training loss: 1.3973884582519531
Validation loss: 2.289110521475474

Epoch: 6| Step: 5
Training loss: 0.909828245639801
Validation loss: 2.2930078506469727

Epoch: 6| Step: 6
Training loss: 1.2192202806472778
Validation loss: 2.268425226211548

Epoch: 6| Step: 7
Training loss: 1.2303698062896729
Validation loss: 2.236350337664286

Epoch: 6| Step: 8
Training loss: 2.1581897735595703
Validation loss: 2.2354625264803567

Epoch: 6| Step: 9
Training loss: 2.533334732055664
Validation loss: 2.216364940007528

Epoch: 6| Step: 10
Training loss: 2.4582056999206543
Validation loss: 2.2513946692148843

Epoch: 6| Step: 11
Training loss: 1.604370355606079
Validation loss: 2.2153799732526145

Epoch: 6| Step: 12
Training loss: 1.33295738697052
Validation loss: 2.2415510217348733

Epoch: 6| Step: 13
Training loss: 1.6986736059188843
Validation loss: 2.2313222686449685

Epoch: 308| Step: 0
Training loss: 1.3042720556259155
Validation loss: 2.2710875272750854

Epoch: 6| Step: 1
Training loss: 1.9383550882339478
Validation loss: 2.2622812390327454

Epoch: 6| Step: 2
Training loss: 1.6572130918502808
Validation loss: 2.285772661368052

Epoch: 6| Step: 3
Training loss: 1.4931902885437012
Validation loss: 2.264812926451365

Epoch: 6| Step: 4
Training loss: 1.5869946479797363
Validation loss: 2.3052873611450195

Epoch: 6| Step: 5
Training loss: 1.5342432260513306
Validation loss: 2.2569286823272705

Epoch: 6| Step: 6
Training loss: 1.707862377166748
Validation loss: 2.2393519282341003

Epoch: 6| Step: 7
Training loss: 2.160489082336426
Validation loss: 2.226313372453054

Epoch: 6| Step: 8
Training loss: 0.9130961298942566
Validation loss: 2.2106611331303916

Epoch: 6| Step: 9
Training loss: 1.82526695728302
Validation loss: 2.1906649669011435

Epoch: 6| Step: 10
Training loss: 1.119047999382019
Validation loss: 2.207257111867269

Epoch: 6| Step: 11
Training loss: 2.1592931747436523
Validation loss: 2.238886217276255

Epoch: 6| Step: 12
Training loss: 1.0480610132217407
Validation loss: 2.2219006021817527

Epoch: 6| Step: 13
Training loss: 1.9067548513412476
Validation loss: 2.2227818965911865

Epoch: 309| Step: 0
Training loss: 2.068441390991211
Validation loss: 2.23228657245636

Epoch: 6| Step: 1
Training loss: 1.9157863855361938
Validation loss: 2.225396732489268

Epoch: 6| Step: 2
Training loss: 1.187329649925232
Validation loss: 2.210836172103882

Epoch: 6| Step: 3
Training loss: 1.6952972412109375
Validation loss: 2.2041849493980408

Epoch: 6| Step: 4
Training loss: 1.6597800254821777
Validation loss: 2.230361044406891

Epoch: 6| Step: 5
Training loss: 1.517153024673462
Validation loss: 2.2156766255696616

Epoch: 6| Step: 6
Training loss: 1.6187679767608643
Validation loss: 2.2285542488098145

Epoch: 6| Step: 7
Training loss: 1.3391809463500977
Validation loss: 2.2718438704808555

Epoch: 6| Step: 8
Training loss: 1.5635857582092285
Validation loss: 2.2837297717730203

Epoch: 6| Step: 9
Training loss: 1.5856091976165771
Validation loss: 2.2990023096402488

Epoch: 6| Step: 10
Training loss: 1.606164574623108
Validation loss: 2.27045069138209

Epoch: 6| Step: 11
Training loss: 1.3099485635757446
Validation loss: 2.2657205065091452

Epoch: 6| Step: 12
Training loss: 1.4370962381362915
Validation loss: 2.277970631917318

Epoch: 6| Step: 13
Training loss: 2.305340051651001
Validation loss: 2.21692564090093

Epoch: 310| Step: 0
Training loss: 1.5410704612731934
Validation loss: 2.2184467713038125

Epoch: 6| Step: 1
Training loss: 2.6191296577453613
Validation loss: 2.197194675604502

Epoch: 6| Step: 2
Training loss: 1.6696100234985352
Validation loss: 2.2090710004170737

Epoch: 6| Step: 3
Training loss: 2.0442800521850586
Validation loss: 2.186149299144745

Epoch: 6| Step: 4
Training loss: 1.1313257217407227
Validation loss: 2.1946557760238647

Epoch: 6| Step: 5
Training loss: 1.3649451732635498
Validation loss: 2.1907502810160318

Epoch: 6| Step: 6
Training loss: 1.6498723030090332
Validation loss: 2.2173974911371865

Epoch: 6| Step: 7
Training loss: 1.1905121803283691
Validation loss: 2.2297614018122354

Epoch: 6| Step: 8
Training loss: 1.3965861797332764
Validation loss: 2.245908260345459

Epoch: 6| Step: 9
Training loss: 1.886879801750183
Validation loss: 2.2628613313039145

Epoch: 6| Step: 10
Training loss: 1.7761356830596924
Validation loss: 2.257386267185211

Epoch: 6| Step: 11
Training loss: 1.3850011825561523
Validation loss: 2.281449238459269

Epoch: 6| Step: 12
Training loss: 1.700203776359558
Validation loss: 2.3252949913342795

Epoch: 6| Step: 13
Training loss: 1.791442632675171
Validation loss: 2.334808905919393

Epoch: 311| Step: 0
Training loss: 1.7277944087982178
Validation loss: 2.3019200960795083

Epoch: 6| Step: 1
Training loss: 1.772092342376709
Validation loss: 2.299741804599762

Epoch: 6| Step: 2
Training loss: 1.7579350471496582
Validation loss: 2.2960402766863504

Epoch: 6| Step: 3
Training loss: 1.107588768005371
Validation loss: 2.252568523089091

Epoch: 6| Step: 4
Training loss: 1.6282460689544678
Validation loss: 2.2608057856559753

Epoch: 6| Step: 5
Training loss: 1.599189043045044
Validation loss: 2.264208277066549

Epoch: 6| Step: 6
Training loss: 1.2452776432037354
Validation loss: 2.273564179738363

Epoch: 6| Step: 7
Training loss: 1.2633464336395264
Validation loss: 2.2537044286727905

Epoch: 6| Step: 8
Training loss: 1.529669165611267
Validation loss: 2.233344336350759

Epoch: 6| Step: 9
Training loss: 1.4682016372680664
Validation loss: 2.251893917719523

Epoch: 6| Step: 10
Training loss: 1.2446893453598022
Validation loss: 2.2237775325775146

Epoch: 6| Step: 11
Training loss: 2.780735969543457
Validation loss: 2.2512486775716147

Epoch: 6| Step: 12
Training loss: 2.0236399173736572
Validation loss: 2.2319264809290567

Epoch: 6| Step: 13
Training loss: 1.6928104162216187
Validation loss: 2.2421695391337075

Epoch: 312| Step: 0
Training loss: 1.2484771013259888
Validation loss: 2.2136420408884683

Epoch: 6| Step: 1
Training loss: 1.239200234413147
Validation loss: 2.2304202715555825

Epoch: 6| Step: 2
Training loss: 1.5311813354492188
Validation loss: 2.2491082549095154

Epoch: 6| Step: 3
Training loss: 1.1818585395812988
Validation loss: 2.2313551704088845

Epoch: 6| Step: 4
Training loss: 2.201523780822754
Validation loss: 2.252528727054596

Epoch: 6| Step: 5
Training loss: 1.7174897193908691
Validation loss: 2.2644001245498657

Epoch: 6| Step: 6
Training loss: 2.2792985439300537
Validation loss: 2.294535001118978

Epoch: 6| Step: 7
Training loss: 1.6804368495941162
Validation loss: 2.264823079109192

Epoch: 6| Step: 8
Training loss: 1.7297232151031494
Validation loss: 2.2673673033714294

Epoch: 6| Step: 9
Training loss: 1.4233897924423218
Validation loss: 2.2422704100608826

Epoch: 6| Step: 10
Training loss: 1.1812384128570557
Validation loss: 2.2428438663482666

Epoch: 6| Step: 11
Training loss: 1.6470699310302734
Validation loss: 2.2276196678479514

Epoch: 6| Step: 12
Training loss: 2.056234836578369
Validation loss: 2.2321507136027017

Epoch: 6| Step: 13
Training loss: 1.2751314640045166
Validation loss: 2.208288590113322

Epoch: 313| Step: 0
Training loss: 1.7140264511108398
Validation loss: 2.2356603741645813

Epoch: 6| Step: 1
Training loss: 2.289362907409668
Validation loss: 2.197001039981842

Epoch: 6| Step: 2
Training loss: 1.5940852165222168
Validation loss: 2.186944286028544

Epoch: 6| Step: 3
Training loss: 2.4140188694000244
Validation loss: 2.1973272562026978

Epoch: 6| Step: 4
Training loss: 1.3734546899795532
Validation loss: 2.1985552310943604

Epoch: 6| Step: 5
Training loss: 1.552459478378296
Validation loss: 2.2203076283137

Epoch: 6| Step: 6
Training loss: 1.7094027996063232
Validation loss: 2.190968374411265

Epoch: 6| Step: 7
Training loss: 1.2171751260757446
Validation loss: 2.195370932420095

Epoch: 6| Step: 8
Training loss: 0.9861792325973511
Validation loss: 2.2336708108584085

Epoch: 6| Step: 9
Training loss: 1.4418762922286987
Validation loss: 2.242065191268921

Epoch: 6| Step: 10
Training loss: 1.7242707014083862
Validation loss: 2.246464113394419

Epoch: 6| Step: 11
Training loss: 1.4254992008209229
Validation loss: 2.239294191201528

Epoch: 6| Step: 12
Training loss: 1.0219924449920654
Validation loss: 2.2421895066897073

Epoch: 6| Step: 13
Training loss: 1.3331897258758545
Validation loss: 2.262112299601237

Epoch: 314| Step: 0
Training loss: 1.5752685070037842
Validation loss: 2.245859126249949

Epoch: 6| Step: 1
Training loss: 1.4098230600357056
Validation loss: 2.2206166783968606

Epoch: 6| Step: 2
Training loss: 1.0087368488311768
Validation loss: 2.1987375617027283

Epoch: 6| Step: 3
Training loss: 1.90728759765625
Validation loss: 2.2354602615038552

Epoch: 6| Step: 4
Training loss: 1.1512141227722168
Validation loss: 2.219254732131958

Epoch: 6| Step: 5
Training loss: 2.2375903129577637
Validation loss: 2.225736975669861

Epoch: 6| Step: 6
Training loss: 1.5773056745529175
Validation loss: 2.2165966828664145

Epoch: 6| Step: 7
Training loss: 1.5666077136993408
Validation loss: 2.243657946586609

Epoch: 6| Step: 8
Training loss: 2.1246228218078613
Validation loss: 2.220490554968516

Epoch: 6| Step: 9
Training loss: 1.1991117000579834
Validation loss: 2.230478207270304

Epoch: 6| Step: 10
Training loss: 1.9129258394241333
Validation loss: 2.2502184311548867

Epoch: 6| Step: 11
Training loss: 1.2653369903564453
Validation loss: 2.256271779537201

Epoch: 6| Step: 12
Training loss: 1.7096832990646362
Validation loss: 2.2761542797088623

Epoch: 6| Step: 13
Training loss: 1.3936388492584229
Validation loss: 2.263333280881246

Epoch: 315| Step: 0
Training loss: 0.9371823072433472
Validation loss: 2.276547829310099

Epoch: 6| Step: 1
Training loss: 2.1324362754821777
Validation loss: 2.2870423992474875

Epoch: 6| Step: 2
Training loss: 1.5921427011489868
Validation loss: 2.288039048512777

Epoch: 6| Step: 3
Training loss: 1.2927749156951904
Validation loss: 2.2459861834843955

Epoch: 6| Step: 4
Training loss: 1.0075105428695679
Validation loss: 2.2324163913726807

Epoch: 6| Step: 5
Training loss: 1.2928032875061035
Validation loss: 2.2353429396947226

Epoch: 6| Step: 6
Training loss: 2.310345411300659
Validation loss: 2.2439075708389282

Epoch: 6| Step: 7
Training loss: 1.4981658458709717
Validation loss: 2.2094971736272178

Epoch: 6| Step: 8
Training loss: 1.7782931327819824
Validation loss: 2.2209524313608804

Epoch: 6| Step: 9
Training loss: 1.6555029153823853
Validation loss: 2.2663568258285522

Epoch: 6| Step: 10
Training loss: 1.0251193046569824
Validation loss: 2.2460781733194985

Epoch: 6| Step: 11
Training loss: 2.1916918754577637
Validation loss: 2.280638893445333

Epoch: 6| Step: 12
Training loss: 1.1373651027679443
Validation loss: 2.2427026430765786

Epoch: 6| Step: 13
Training loss: 1.8088359832763672
Validation loss: 2.2450402975082397

Epoch: 316| Step: 0
Training loss: 2.2618844509124756
Validation loss: 2.248962104320526

Epoch: 6| Step: 1
Training loss: 1.2968502044677734
Validation loss: 2.2469276189804077

Epoch: 6| Step: 2
Training loss: 1.60471510887146
Validation loss: 2.272156278292338

Epoch: 6| Step: 3
Training loss: 1.2477142810821533
Validation loss: 2.2710825204849243

Epoch: 6| Step: 4
Training loss: 1.8142063617706299
Validation loss: 2.2287121613820395

Epoch: 6| Step: 5
Training loss: 1.4105359315872192
Validation loss: 2.252535343170166

Epoch: 6| Step: 6
Training loss: 1.0747588872909546
Validation loss: 2.24050372838974

Epoch: 6| Step: 7
Training loss: 1.1879714727401733
Validation loss: 2.2413529555002847

Epoch: 6| Step: 8
Training loss: 2.477097988128662
Validation loss: 2.219759007294973

Epoch: 6| Step: 9
Training loss: 1.2891987562179565
Validation loss: 2.237168073654175

Epoch: 6| Step: 10
Training loss: 0.9891586899757385
Validation loss: 2.2473523219426474

Epoch: 6| Step: 11
Training loss: 2.1236047744750977
Validation loss: 2.252448638280233

Epoch: 6| Step: 12
Training loss: 1.5987918376922607
Validation loss: 2.218011458714803

Epoch: 6| Step: 13
Training loss: 1.1886800527572632
Validation loss: 2.2326144178708396

Epoch: 317| Step: 0
Training loss: 1.4152183532714844
Validation loss: 2.248902161916097

Epoch: 6| Step: 1
Training loss: 1.1298179626464844
Validation loss: 2.2331324021021524

Epoch: 6| Step: 2
Training loss: 1.6316308975219727
Validation loss: 2.2603732148806253

Epoch: 6| Step: 3
Training loss: 2.0635063648223877
Validation loss: 2.248537600040436

Epoch: 6| Step: 4
Training loss: 1.4582797288894653
Validation loss: 2.23902295033137

Epoch: 6| Step: 5
Training loss: 1.3815076351165771
Validation loss: 2.2437572280565896

Epoch: 6| Step: 6
Training loss: 1.5227259397506714
Validation loss: 2.23840868473053

Epoch: 6| Step: 7
Training loss: 1.221236228942871
Validation loss: 2.2707869609196982

Epoch: 6| Step: 8
Training loss: 1.6344494819641113
Validation loss: 2.2724556724230447

Epoch: 6| Step: 9
Training loss: 1.328243613243103
Validation loss: 2.2609015305836997

Epoch: 6| Step: 10
Training loss: 1.7210782766342163
Validation loss: 2.2820149858792624

Epoch: 6| Step: 11
Training loss: 1.7716999053955078
Validation loss: 2.2481895089149475

Epoch: 6| Step: 12
Training loss: 1.3802392482757568
Validation loss: 2.2814403971036277

Epoch: 6| Step: 13
Training loss: 1.730019450187683
Validation loss: 2.265002687772115

Epoch: 318| Step: 0
Training loss: 2.0241007804870605
Validation loss: 2.264187276363373

Epoch: 6| Step: 1
Training loss: 1.9428529739379883
Validation loss: 2.2597813606262207

Epoch: 6| Step: 2
Training loss: 1.593685269355774
Validation loss: 2.2697543104489646

Epoch: 6| Step: 3
Training loss: 1.2524476051330566
Validation loss: 2.2929734190305076

Epoch: 6| Step: 4
Training loss: 0.9358558654785156
Validation loss: 2.29859725634257

Epoch: 6| Step: 5
Training loss: 2.808074474334717
Validation loss: 2.2584095001220703

Epoch: 6| Step: 6
Training loss: 1.2562867403030396
Validation loss: 2.28489621480306

Epoch: 6| Step: 7
Training loss: 1.3688931465148926
Validation loss: 2.3036247293154397

Epoch: 6| Step: 8
Training loss: 1.5315734148025513
Validation loss: 2.2439653078715005

Epoch: 6| Step: 9
Training loss: 1.0024681091308594
Validation loss: 2.2763328552246094

Epoch: 6| Step: 10
Training loss: 1.7096991539001465
Validation loss: 2.272552569707235

Epoch: 6| Step: 11
Training loss: 2.0321221351623535
Validation loss: 2.270273526509603

Epoch: 6| Step: 12
Training loss: 0.3311654031276703
Validation loss: 2.279441754023234

Epoch: 6| Step: 13
Training loss: 1.6130592823028564
Validation loss: 2.26502126455307

Epoch: 319| Step: 0
Training loss: 1.1295136213302612
Validation loss: 2.2477697928746543

Epoch: 6| Step: 1
Training loss: 2.0875205993652344
Validation loss: 2.27920800447464

Epoch: 6| Step: 2
Training loss: 1.4161478281021118
Validation loss: 2.2612454891204834

Epoch: 6| Step: 3
Training loss: 1.161481261253357
Validation loss: 2.257518490155538

Epoch: 6| Step: 4
Training loss: 1.4996583461761475
Validation loss: 2.2424245278040567

Epoch: 6| Step: 5
Training loss: 1.214177131652832
Validation loss: 2.258580724398295

Epoch: 6| Step: 6
Training loss: 1.5220823287963867
Validation loss: 2.2473039428393045

Epoch: 6| Step: 7
Training loss: 1.8925344944000244
Validation loss: 2.2455742359161377

Epoch: 6| Step: 8
Training loss: 1.9788923263549805
Validation loss: 2.2307555874188743

Epoch: 6| Step: 9
Training loss: 1.9254320859909058
Validation loss: 2.203634281953176

Epoch: 6| Step: 10
Training loss: 1.2205212116241455
Validation loss: 2.2199085553487143

Epoch: 6| Step: 11
Training loss: 1.5287072658538818
Validation loss: 2.2165494163831077

Epoch: 6| Step: 12
Training loss: 1.5132262706756592
Validation loss: 2.2353004614512124

Epoch: 6| Step: 13
Training loss: 1.386998176574707
Validation loss: 2.2433621684710183

Epoch: 320| Step: 0
Training loss: 1.1529659032821655
Validation loss: 2.271979014078776

Epoch: 6| Step: 1
Training loss: 1.4385566711425781
Validation loss: 2.238947610060374

Epoch: 6| Step: 2
Training loss: 2.003556728363037
Validation loss: 2.2567498485247293

Epoch: 6| Step: 3
Training loss: 1.6034184694290161
Validation loss: 2.249032417933146

Epoch: 6| Step: 4
Training loss: 1.4396870136260986
Validation loss: 2.2484891414642334

Epoch: 6| Step: 5
Training loss: 0.8896003365516663
Validation loss: 2.263903498649597

Epoch: 6| Step: 6
Training loss: 2.03743314743042
Validation loss: 2.284249206384023

Epoch: 6| Step: 7
Training loss: 0.8985376954078674
Validation loss: 2.2718812425931296

Epoch: 6| Step: 8
Training loss: 1.1987247467041016
Validation loss: 2.2672994335492453

Epoch: 6| Step: 9
Training loss: 1.1742199659347534
Validation loss: 2.2982248067855835

Epoch: 6| Step: 10
Training loss: 1.0880346298217773
Validation loss: 2.3213821252187095

Epoch: 6| Step: 11
Training loss: 2.8101282119750977
Validation loss: 2.313207467397054

Epoch: 6| Step: 12
Training loss: 1.5152007341384888
Validation loss: 2.289549549420675

Epoch: 6| Step: 13
Training loss: 1.825610876083374
Validation loss: 2.298442264397939

Epoch: 321| Step: 0
Training loss: 1.4667688608169556
Validation loss: 2.301887114842733

Epoch: 6| Step: 1
Training loss: 0.8239965438842773
Validation loss: 2.282360633214315

Epoch: 6| Step: 2
Training loss: 1.2147352695465088
Validation loss: 2.279874245325724

Epoch: 6| Step: 3
Training loss: 2.4961600303649902
Validation loss: 2.2757232586542764

Epoch: 6| Step: 4
Training loss: 1.451138973236084
Validation loss: 2.271633267402649

Epoch: 6| Step: 5
Training loss: 1.4574946165084839
Validation loss: 2.2871612310409546

Epoch: 6| Step: 6
Training loss: 1.6062930822372437
Validation loss: 2.2644590934117637

Epoch: 6| Step: 7
Training loss: 2.0138888359069824
Validation loss: 2.234618663787842

Epoch: 6| Step: 8
Training loss: 1.445298194885254
Validation loss: 2.2782979011535645

Epoch: 6| Step: 9
Training loss: 2.2255361080169678
Validation loss: 2.257232348124186

Epoch: 6| Step: 10
Training loss: 1.374704122543335
Validation loss: 2.2488133907318115

Epoch: 6| Step: 11
Training loss: 1.3709752559661865
Validation loss: 2.2363005677858987

Epoch: 6| Step: 12
Training loss: 1.0617586374282837
Validation loss: 2.2461307843526206

Epoch: 6| Step: 13
Training loss: 1.1164021492004395
Validation loss: 2.2207194566726685

Epoch: 322| Step: 0
Training loss: 1.0831496715545654
Validation loss: 2.2398375868797302

Epoch: 6| Step: 1
Training loss: 1.1200119256973267
Validation loss: 2.206762989362081

Epoch: 6| Step: 2
Training loss: 2.0406274795532227
Validation loss: 2.2364476124445596

Epoch: 6| Step: 3
Training loss: 1.673522710800171
Validation loss: 2.2486868699391684

Epoch: 6| Step: 4
Training loss: 1.2641185522079468
Validation loss: 2.2525209188461304

Epoch: 6| Step: 5
Training loss: 0.9754161834716797
Validation loss: 2.259066859881083

Epoch: 6| Step: 6
Training loss: 1.3046929836273193
Validation loss: 2.280059039592743

Epoch: 6| Step: 7
Training loss: 0.9693905115127563
Validation loss: 2.2384264866511026

Epoch: 6| Step: 8
Training loss: 1.4493168592453003
Validation loss: 2.2613655726114907

Epoch: 6| Step: 9
Training loss: 1.397717833518982
Validation loss: 2.255919416745504

Epoch: 6| Step: 10
Training loss: 1.634027361869812
Validation loss: 2.264575441678365

Epoch: 6| Step: 11
Training loss: 1.380325198173523
Validation loss: 2.2712549368540444

Epoch: 6| Step: 12
Training loss: 1.2614002227783203
Validation loss: 2.254145383834839

Epoch: 6| Step: 13
Training loss: 2.9674429893493652
Validation loss: 2.2486058274904885

Epoch: 323| Step: 0
Training loss: 1.5924890041351318
Validation loss: 2.2907753586769104

Epoch: 6| Step: 1
Training loss: 1.6269209384918213
Validation loss: 2.283219655354818

Epoch: 6| Step: 2
Training loss: 1.1171482801437378
Validation loss: 2.285037318865458

Epoch: 6| Step: 3
Training loss: 1.904067039489746
Validation loss: 2.263039211432139

Epoch: 6| Step: 4
Training loss: 1.3722920417785645
Validation loss: 2.2758934696515403

Epoch: 6| Step: 5
Training loss: 1.6998140811920166
Validation loss: 2.264200270175934

Epoch: 6| Step: 6
Training loss: 1.8204445838928223
Validation loss: 2.2876184384028115

Epoch: 6| Step: 7
Training loss: 1.4912278652191162
Validation loss: 2.270276149113973

Epoch: 6| Step: 8
Training loss: 1.3602615594863892
Validation loss: 2.2236006259918213

Epoch: 6| Step: 9
Training loss: 1.3288977146148682
Validation loss: 2.2659040689468384

Epoch: 6| Step: 10
Training loss: 1.1378974914550781
Validation loss: 2.2498608430226645

Epoch: 6| Step: 11
Training loss: 1.1254050731658936
Validation loss: 2.262490669886271

Epoch: 6| Step: 12
Training loss: 1.1489067077636719
Validation loss: 2.2208473285039267

Epoch: 6| Step: 13
Training loss: 1.7004843950271606
Validation loss: 2.2759238680203757

Epoch: 324| Step: 0
Training loss: 1.6780685186386108
Validation loss: 2.2525446017583213

Epoch: 6| Step: 1
Training loss: 1.9991116523742676
Validation loss: 2.240051567554474

Epoch: 6| Step: 2
Training loss: 1.0309181213378906
Validation loss: 2.254553238550822

Epoch: 6| Step: 3
Training loss: 1.4272695779800415
Validation loss: 2.225305914878845

Epoch: 6| Step: 4
Training loss: 1.2024405002593994
Validation loss: 2.223774174849192

Epoch: 6| Step: 5
Training loss: 1.0552594661712646
Validation loss: 2.2264825900395713

Epoch: 6| Step: 6
Training loss: 1.970955729484558
Validation loss: 2.2336025834083557

Epoch: 6| Step: 7
Training loss: 1.8474613428115845
Validation loss: 2.2357946038246155

Epoch: 6| Step: 8
Training loss: 1.8763554096221924
Validation loss: 2.2515117526054382

Epoch: 6| Step: 9
Training loss: 1.243100643157959
Validation loss: 2.2696227629979453

Epoch: 6| Step: 10
Training loss: 1.4619755744934082
Validation loss: 2.2461249033610025

Epoch: 6| Step: 11
Training loss: 1.025343418121338
Validation loss: 2.3047817746798196

Epoch: 6| Step: 12
Training loss: 1.835176706314087
Validation loss: 2.2505293091138205

Epoch: 6| Step: 13
Training loss: 1.3177002668380737
Validation loss: 2.2786006331443787

Epoch: 325| Step: 0
Training loss: 1.4242382049560547
Validation loss: 2.2787776390711465

Epoch: 6| Step: 1
Training loss: 1.6025116443634033
Validation loss: 2.268665591875712

Epoch: 6| Step: 2
Training loss: 1.468522548675537
Validation loss: 2.2697659929593406

Epoch: 6| Step: 3
Training loss: 1.8814162015914917
Validation loss: 2.280451774597168

Epoch: 6| Step: 4
Training loss: 1.299234390258789
Validation loss: 2.264258086681366

Epoch: 6| Step: 5
Training loss: 1.9674885272979736
Validation loss: 2.291529138882955

Epoch: 6| Step: 6
Training loss: 1.6620193719863892
Validation loss: 2.2439791162808738

Epoch: 6| Step: 7
Training loss: 1.6635735034942627
Validation loss: 2.224673271179199

Epoch: 6| Step: 8
Training loss: 1.3511176109313965
Validation loss: 2.2454766035079956

Epoch: 6| Step: 9
Training loss: 1.4980257749557495
Validation loss: 2.1973310311635337

Epoch: 6| Step: 10
Training loss: 1.185258388519287
Validation loss: 2.2169847885767617

Epoch: 6| Step: 11
Training loss: 1.559234857559204
Validation loss: 2.22882741689682

Epoch: 6| Step: 12
Training loss: 0.9046022891998291
Validation loss: 2.2447574138641357

Epoch: 6| Step: 13
Training loss: 1.0917733907699585
Validation loss: 2.2396466732025146

Epoch: 326| Step: 0
Training loss: 1.318922519683838
Validation loss: 2.228561838467916

Epoch: 6| Step: 1
Training loss: 1.3944048881530762
Validation loss: 2.2478050788243613

Epoch: 6| Step: 2
Training loss: 2.167693614959717
Validation loss: 2.227407435576121

Epoch: 6| Step: 3
Training loss: 1.8581411838531494
Validation loss: 2.2434208393096924

Epoch: 6| Step: 4
Training loss: 1.353811264038086
Validation loss: 2.2346330285072327

Epoch: 6| Step: 5
Training loss: 2.021313428878784
Validation loss: 2.228272875150045

Epoch: 6| Step: 6
Training loss: 1.9935808181762695
Validation loss: 2.2380712827046714

Epoch: 6| Step: 7
Training loss: 1.5796148777008057
Validation loss: 2.235809246699015

Epoch: 6| Step: 8
Training loss: 1.1264358758926392
Validation loss: 2.2504109342892966

Epoch: 6| Step: 9
Training loss: 0.579780638217926
Validation loss: 2.234557588895162

Epoch: 6| Step: 10
Training loss: 1.1328527927398682
Validation loss: 2.2209503253300986

Epoch: 6| Step: 11
Training loss: 1.4670158624649048
Validation loss: 2.2446268796920776

Epoch: 6| Step: 12
Training loss: 1.524049997329712
Validation loss: 2.2430830597877502

Epoch: 6| Step: 13
Training loss: 1.5651195049285889
Validation loss: 2.2467307647069297

Epoch: 327| Step: 0
Training loss: 2.0374131202697754
Validation loss: 2.2284796237945557

Epoch: 6| Step: 1
Training loss: 1.4835827350616455
Validation loss: 2.2007417480150857

Epoch: 6| Step: 2
Training loss: 1.7121355533599854
Validation loss: 2.2398529052734375

Epoch: 6| Step: 3
Training loss: 1.0332010984420776
Validation loss: 2.2270967165629068

Epoch: 6| Step: 4
Training loss: 1.7774384021759033
Validation loss: 2.2777721087137857

Epoch: 6| Step: 5
Training loss: 1.2832345962524414
Validation loss: 2.242411037286123

Epoch: 6| Step: 6
Training loss: 1.3075469732284546
Validation loss: 2.228812038898468

Epoch: 6| Step: 7
Training loss: 1.3343491554260254
Validation loss: 2.233317196369171

Epoch: 6| Step: 8
Training loss: 1.7234716415405273
Validation loss: 2.2559222181638083

Epoch: 6| Step: 9
Training loss: 1.0104609727859497
Validation loss: 2.256134251753489

Epoch: 6| Step: 10
Training loss: 2.296137571334839
Validation loss: 2.257745862007141

Epoch: 6| Step: 11
Training loss: 1.6283878087997437
Validation loss: 2.2378702958424888

Epoch: 6| Step: 12
Training loss: 1.197124719619751
Validation loss: 2.269600292046865

Epoch: 6| Step: 13
Training loss: 0.8622944951057434
Validation loss: 2.244776407877604

Epoch: 328| Step: 0
Training loss: 1.451851725578308
Validation loss: 2.262362619241079

Epoch: 6| Step: 1
Training loss: 1.5446054935455322
Validation loss: 2.2675116062164307

Epoch: 6| Step: 2
Training loss: 1.3619166612625122
Validation loss: 2.2635080218315125

Epoch: 6| Step: 3
Training loss: 1.8884025812149048
Validation loss: 2.2706530491511026

Epoch: 6| Step: 4
Training loss: 1.7519786357879639
Validation loss: 2.2924383083979287

Epoch: 6| Step: 5
Training loss: 1.4403331279754639
Validation loss: 2.2461167176564536

Epoch: 6| Step: 6
Training loss: 1.3005986213684082
Validation loss: 2.2714227040608725

Epoch: 6| Step: 7
Training loss: 1.5120670795440674
Validation loss: 2.248300631841024

Epoch: 6| Step: 8
Training loss: 1.3405394554138184
Validation loss: 2.2600366671880088

Epoch: 6| Step: 9
Training loss: 1.408083200454712
Validation loss: 2.289042115211487

Epoch: 6| Step: 10
Training loss: 1.3815407752990723
Validation loss: 2.246278623739878

Epoch: 6| Step: 11
Training loss: 0.866742730140686
Validation loss: 2.2886851827303567

Epoch: 6| Step: 12
Training loss: 1.0477946996688843
Validation loss: 2.2289976676305137

Epoch: 6| Step: 13
Training loss: 1.7732425928115845
Validation loss: 2.2638691862424216

Epoch: 329| Step: 0
Training loss: 1.4856314659118652
Validation loss: 2.2607381542523703

Epoch: 6| Step: 1
Training loss: 0.7981797456741333
Validation loss: 2.2418223222096763

Epoch: 6| Step: 2
Training loss: 2.410210132598877
Validation loss: 2.2585133711496987

Epoch: 6| Step: 3
Training loss: 1.16038179397583
Validation loss: 2.2733529806137085

Epoch: 6| Step: 4
Training loss: 1.9597413539886475
Validation loss: 2.260976711908976

Epoch: 6| Step: 5
Training loss: 0.9401600956916809
Validation loss: 2.2398993174235025

Epoch: 6| Step: 6
Training loss: 1.6028990745544434
Validation loss: 2.2713354229927063

Epoch: 6| Step: 7
Training loss: 1.0166726112365723
Validation loss: 2.2540387709935508

Epoch: 6| Step: 8
Training loss: 1.5031721591949463
Validation loss: 2.2642393906911216

Epoch: 6| Step: 9
Training loss: 2.244286060333252
Validation loss: 2.244988183180491

Epoch: 6| Step: 10
Training loss: 1.0890929698944092
Validation loss: 2.2199310064315796

Epoch: 6| Step: 11
Training loss: 1.3149477243423462
Validation loss: 2.1975052754084268

Epoch: 6| Step: 12
Training loss: 1.7998298406600952
Validation loss: 2.1887256105740867

Epoch: 6| Step: 13
Training loss: 1.1733042001724243
Validation loss: 2.2125627199808755

Epoch: 330| Step: 0
Training loss: 1.7604758739471436
Validation loss: 2.194451908270518

Epoch: 6| Step: 1
Training loss: 1.1808799505233765
Validation loss: 2.178276300430298

Epoch: 6| Step: 2
Training loss: 1.124516248703003
Validation loss: 2.222269912560781

Epoch: 6| Step: 3
Training loss: 2.002159357070923
Validation loss: 2.2090664505958557

Epoch: 6| Step: 4
Training loss: 1.5389760732650757
Validation loss: 2.217347284158071

Epoch: 6| Step: 5
Training loss: 1.2114092111587524
Validation loss: 2.217489540576935

Epoch: 6| Step: 6
Training loss: 1.200927495956421
Validation loss: 2.216987351576487

Epoch: 6| Step: 7
Training loss: 1.4236088991165161
Validation loss: 2.19636865456899

Epoch: 6| Step: 8
Training loss: 1.8064926862716675
Validation loss: 2.2027417421340942

Epoch: 6| Step: 9
Training loss: 2.150131940841675
Validation loss: 2.2441810766855874

Epoch: 6| Step: 10
Training loss: 2.6423330307006836
Validation loss: 2.2560887734095254

Epoch: 6| Step: 11
Training loss: 1.6350980997085571
Validation loss: 2.2230706810951233

Epoch: 6| Step: 12
Training loss: 1.0060806274414062
Validation loss: 2.216438968976339

Epoch: 6| Step: 13
Training loss: 0.861335813999176
Validation loss: 2.2194308837254844

Epoch: 331| Step: 0
Training loss: 1.306374430656433
Validation loss: 2.233986477057139

Epoch: 6| Step: 1
Training loss: 2.061307668685913
Validation loss: 2.2656277616818747

Epoch: 6| Step: 2
Training loss: 1.9460539817810059
Validation loss: 2.2328933676083884

Epoch: 6| Step: 3
Training loss: 1.0702345371246338
Validation loss: 2.26575897137324

Epoch: 6| Step: 4
Training loss: 1.4318952560424805
Validation loss: 2.229132095972697

Epoch: 6| Step: 5
Training loss: 1.4754868745803833
Validation loss: 2.2611186106999717

Epoch: 6| Step: 6
Training loss: 1.3725881576538086
Validation loss: 2.2687573432922363

Epoch: 6| Step: 7
Training loss: 1.165421962738037
Validation loss: 2.194226384162903

Epoch: 6| Step: 8
Training loss: 1.5023471117019653
Validation loss: 2.247456709543864

Epoch: 6| Step: 9
Training loss: 1.4980995655059814
Validation loss: 2.2294876178105674

Epoch: 6| Step: 10
Training loss: 2.1173627376556396
Validation loss: 2.2518412868181863

Epoch: 6| Step: 11
Training loss: 0.7515342831611633
Validation loss: 2.2471452156702676

Epoch: 6| Step: 12
Training loss: 1.468697428703308
Validation loss: 2.264201899369558

Epoch: 6| Step: 13
Training loss: 1.4666311740875244
Validation loss: 2.225995580355326

Epoch: 332| Step: 0
Training loss: 1.2764310836791992
Validation loss: 2.225209057331085

Epoch: 6| Step: 1
Training loss: 1.4564560651779175
Validation loss: 2.2387368281682334

Epoch: 6| Step: 2
Training loss: 1.7932560443878174
Validation loss: 2.2144691745440164

Epoch: 6| Step: 3
Training loss: 1.8441449403762817
Validation loss: 2.2180978655815125

Epoch: 6| Step: 4
Training loss: 1.0314937829971313
Validation loss: 2.2501617868741355

Epoch: 6| Step: 5
Training loss: 1.424232840538025
Validation loss: 2.227539519468943

Epoch: 6| Step: 6
Training loss: 1.8228822946548462
Validation loss: 2.2389872868855796

Epoch: 6| Step: 7
Training loss: 1.5421478748321533
Validation loss: 2.2854594389597573

Epoch: 6| Step: 8
Training loss: 1.1636717319488525
Validation loss: 2.296968142191569

Epoch: 6| Step: 9
Training loss: 1.0093588829040527
Validation loss: 2.2818985184033713

Epoch: 6| Step: 10
Training loss: 1.6068390607833862
Validation loss: 2.277538537979126

Epoch: 6| Step: 11
Training loss: 1.5406396389007568
Validation loss: 2.2830131451288858

Epoch: 6| Step: 12
Training loss: 1.3684237003326416
Validation loss: 2.2845458587010703

Epoch: 6| Step: 13
Training loss: 1.6266230344772339
Validation loss: 2.2805601358413696

Epoch: 333| Step: 0
Training loss: 1.2194764614105225
Validation loss: 2.26240740219752

Epoch: 6| Step: 1
Training loss: 1.2225579023361206
Validation loss: 2.2661736408869424

Epoch: 6| Step: 2
Training loss: 1.406022071838379
Validation loss: 2.252119719982147

Epoch: 6| Step: 3
Training loss: 1.6874754428863525
Validation loss: 2.239876925945282

Epoch: 6| Step: 4
Training loss: 1.7268726825714111
Validation loss: 2.238987763722738

Epoch: 6| Step: 5
Training loss: 1.486992359161377
Validation loss: 2.253628114859263

Epoch: 6| Step: 6
Training loss: 2.0258898735046387
Validation loss: 2.2556156714757285

Epoch: 6| Step: 7
Training loss: 1.3283398151397705
Validation loss: 2.2507585684458413

Epoch: 6| Step: 8
Training loss: 2.262216567993164
Validation loss: 2.2422063748041787

Epoch: 6| Step: 9
Training loss: 0.9974676370620728
Validation loss: 2.2402856151262918

Epoch: 6| Step: 10
Training loss: 1.5557684898376465
Validation loss: 2.2657781839370728

Epoch: 6| Step: 11
Training loss: 0.8229237794876099
Validation loss: 2.2788301706314087

Epoch: 6| Step: 12
Training loss: 1.0625826120376587
Validation loss: 2.262938380241394

Epoch: 6| Step: 13
Training loss: 1.1410932540893555
Validation loss: 2.2414198319117227

Epoch: 334| Step: 0
Training loss: 1.1200428009033203
Validation loss: 2.2355895042419434

Epoch: 6| Step: 1
Training loss: 0.7085906863212585
Validation loss: 2.223553458849589

Epoch: 6| Step: 2
Training loss: 1.635462760925293
Validation loss: 2.255241791407267

Epoch: 6| Step: 3
Training loss: 1.4877824783325195
Validation loss: 2.224893351395925

Epoch: 6| Step: 4
Training loss: 1.8138935565948486
Validation loss: 2.2197218934694924

Epoch: 6| Step: 5
Training loss: 1.5480728149414062
Validation loss: 2.265152176221212

Epoch: 6| Step: 6
Training loss: 1.2401986122131348
Validation loss: 2.2510540882746377

Epoch: 6| Step: 7
Training loss: 1.7329312562942505
Validation loss: 2.274904727935791

Epoch: 6| Step: 8
Training loss: 1.0395424365997314
Validation loss: 2.218431572119395

Epoch: 6| Step: 9
Training loss: 1.3871428966522217
Validation loss: 2.2107011874516806

Epoch: 6| Step: 10
Training loss: 1.361046314239502
Validation loss: 2.1494943102200827

Epoch: 6| Step: 11
Training loss: 1.9893275499343872
Validation loss: 2.164623955885569

Epoch: 6| Step: 12
Training loss: 1.7526447772979736
Validation loss: 2.1779571374257407

Epoch: 6| Step: 13
Training loss: 1.7877018451690674
Validation loss: 2.158853987852732

Epoch: 335| Step: 0
Training loss: 1.2304743528366089
Validation loss: 2.152700046698252

Epoch: 6| Step: 1
Training loss: 1.3175702095031738
Validation loss: 2.144046723842621

Epoch: 6| Step: 2
Training loss: 1.6052699089050293
Validation loss: 2.180887222290039

Epoch: 6| Step: 3
Training loss: 1.077341914176941
Validation loss: 2.242161989212036

Epoch: 6| Step: 4
Training loss: 2.0318264961242676
Validation loss: 2.207202931245168

Epoch: 6| Step: 5
Training loss: 1.1111952066421509
Validation loss: 2.2503554423650107

Epoch: 6| Step: 6
Training loss: 1.210691213607788
Validation loss: 2.209407468636831

Epoch: 6| Step: 7
Training loss: 2.1137218475341797
Validation loss: 2.248556216557821

Epoch: 6| Step: 8
Training loss: 1.7196165323257446
Validation loss: 2.241929590702057

Epoch: 6| Step: 9
Training loss: 1.388122320175171
Validation loss: 2.204918543497721

Epoch: 6| Step: 10
Training loss: 1.9055371284484863
Validation loss: 2.2448453108469644

Epoch: 6| Step: 11
Training loss: 1.5454167127609253
Validation loss: 2.2530328035354614

Epoch: 6| Step: 12
Training loss: 1.4190864562988281
Validation loss: 2.2348896265029907

Epoch: 6| Step: 13
Training loss: 1.4963737726211548
Validation loss: 2.2671199838320413

Epoch: 336| Step: 0
Training loss: 1.9201232194900513
Validation loss: 2.2066640059153237

Epoch: 6| Step: 1
Training loss: 1.335809588432312
Validation loss: 2.2433413664499917

Epoch: 6| Step: 2
Training loss: 1.1224347352981567
Validation loss: 2.251455465952555

Epoch: 6| Step: 3
Training loss: 1.7296991348266602
Validation loss: 2.2726860443751016

Epoch: 6| Step: 4
Training loss: 1.3276119232177734
Validation loss: 2.2502057949701944

Epoch: 6| Step: 5
Training loss: 1.5803759098052979
Validation loss: 2.296208620071411

Epoch: 6| Step: 6
Training loss: 1.6456413269042969
Validation loss: 2.258174459139506

Epoch: 6| Step: 7
Training loss: 1.2317489385604858
Validation loss: 2.251149912675222

Epoch: 6| Step: 8
Training loss: 1.3710014820098877
Validation loss: 2.3054199616114297

Epoch: 6| Step: 9
Training loss: 1.365033507347107
Validation loss: 2.2673164208730063

Epoch: 6| Step: 10
Training loss: 1.4426724910736084
Validation loss: 2.2404863039652505

Epoch: 6| Step: 11
Training loss: 1.3099260330200195
Validation loss: 2.2834912737210593

Epoch: 6| Step: 12
Training loss: 1.377162218093872
Validation loss: 2.247499664624532

Epoch: 6| Step: 13
Training loss: 1.0339423418045044
Validation loss: 2.2376276652018228

Epoch: 337| Step: 0
Training loss: 1.0877867937088013
Validation loss: 2.223548730214437

Epoch: 6| Step: 1
Training loss: 1.2640421390533447
Validation loss: 2.2289384603500366

Epoch: 6| Step: 2
Training loss: 1.5815693140029907
Validation loss: 2.2479451100031533

Epoch: 6| Step: 3
Training loss: 1.3363170623779297
Validation loss: 2.2697201569875083

Epoch: 6| Step: 4
Training loss: 1.0094215869903564
Validation loss: 2.2644655108451843

Epoch: 6| Step: 5
Training loss: 2.376798629760742
Validation loss: 2.271870215733846

Epoch: 6| Step: 6
Training loss: 1.2110222578048706
Validation loss: 2.232197860876719

Epoch: 6| Step: 7
Training loss: 1.4251708984375
Validation loss: 2.278201679388682

Epoch: 6| Step: 8
Training loss: 1.0924735069274902
Validation loss: 2.2040368715922036

Epoch: 6| Step: 9
Training loss: 1.538020133972168
Validation loss: 2.241410553455353

Epoch: 6| Step: 10
Training loss: 1.5145655870437622
Validation loss: 2.220974842707316

Epoch: 6| Step: 11
Training loss: 1.3204169273376465
Validation loss: 2.246685961882273

Epoch: 6| Step: 12
Training loss: 1.9313145875930786
Validation loss: 2.2561240593592324

Epoch: 6| Step: 13
Training loss: 1.2851178646087646
Validation loss: 2.237473169962565

Epoch: 338| Step: 0
Training loss: 1.1321580410003662
Validation loss: 2.2622310717900596

Epoch: 6| Step: 1
Training loss: 1.834549903869629
Validation loss: 2.2619360287984214

Epoch: 6| Step: 2
Training loss: 1.3777953386306763
Validation loss: 2.2559579809506736

Epoch: 6| Step: 3
Training loss: 1.0801283121109009
Validation loss: 2.2649383346239724

Epoch: 6| Step: 4
Training loss: 1.093275785446167
Validation loss: 2.2684600750605264

Epoch: 6| Step: 5
Training loss: 1.6607366800308228
Validation loss: 2.23013969262441

Epoch: 6| Step: 6
Training loss: 1.8834228515625
Validation loss: 2.2344708840052285

Epoch: 6| Step: 7
Training loss: 1.5050721168518066
Validation loss: 2.23701411485672

Epoch: 6| Step: 8
Training loss: 1.2836077213287354
Validation loss: 2.229621251424154

Epoch: 6| Step: 9
Training loss: 0.6644166707992554
Validation loss: 2.2404306332270303

Epoch: 6| Step: 10
Training loss: 1.7629581689834595
Validation loss: 2.265614608923594

Epoch: 6| Step: 11
Training loss: 1.5425899028778076
Validation loss: 2.2679702639579773

Epoch: 6| Step: 12
Training loss: 1.3969388008117676
Validation loss: 2.259402851263682

Epoch: 6| Step: 13
Training loss: 1.6873773336410522
Validation loss: 2.2576854825019836

Epoch: 339| Step: 0
Training loss: 1.1874748468399048
Validation loss: 2.2762343486150107

Epoch: 6| Step: 1
Training loss: 1.1792795658111572
Validation loss: 2.305191397666931

Epoch: 6| Step: 2
Training loss: 1.1113924980163574
Validation loss: 2.2740965684254966

Epoch: 6| Step: 3
Training loss: 1.4361211061477661
Validation loss: 2.228469987710317

Epoch: 6| Step: 4
Training loss: 1.0923770666122437
Validation loss: 2.2517008980115256

Epoch: 6| Step: 5
Training loss: 1.7554430961608887
Validation loss: 2.2714383204778037

Epoch: 6| Step: 6
Training loss: 1.53693425655365
Validation loss: 2.264437754948934

Epoch: 6| Step: 7
Training loss: 2.2038185596466064
Validation loss: 2.2336902817090354

Epoch: 6| Step: 8
Training loss: 1.6071659326553345
Validation loss: 2.263995905717214

Epoch: 6| Step: 9
Training loss: 1.229405164718628
Validation loss: 2.223543345928192

Epoch: 6| Step: 10
Training loss: 1.4783451557159424
Validation loss: 2.252589205900828

Epoch: 6| Step: 11
Training loss: 1.12861168384552
Validation loss: 2.2738123734792075

Epoch: 6| Step: 12
Training loss: 1.1247681379318237
Validation loss: 2.2258271972338357

Epoch: 6| Step: 13
Training loss: 1.4163000583648682
Validation loss: 2.2235268553098044

Epoch: 340| Step: 0
Training loss: 0.8835902810096741
Validation loss: 2.230174422264099

Epoch: 6| Step: 1
Training loss: 1.072889804840088
Validation loss: 2.2472423116366067

Epoch: 6| Step: 2
Training loss: 0.9348920583724976
Validation loss: 2.2139357328414917

Epoch: 6| Step: 3
Training loss: 1.5439038276672363
Validation loss: 2.236173709233602

Epoch: 6| Step: 4
Training loss: 1.4399144649505615
Validation loss: 2.242940624554952

Epoch: 6| Step: 5
Training loss: 1.202510952949524
Validation loss: 2.2362602949142456

Epoch: 6| Step: 6
Training loss: 1.269985318183899
Validation loss: 2.2513434092203775

Epoch: 6| Step: 7
Training loss: 1.7620664834976196
Validation loss: 2.244272847970327

Epoch: 6| Step: 8
Training loss: 2.136162757873535
Validation loss: 2.25757098197937

Epoch: 6| Step: 9
Training loss: 1.3246469497680664
Validation loss: 2.2477258443832397

Epoch: 6| Step: 10
Training loss: 1.5740004777908325
Validation loss: 2.231320242087046

Epoch: 6| Step: 11
Training loss: 1.5123577117919922
Validation loss: 2.1904293298721313

Epoch: 6| Step: 12
Training loss: 1.1150851249694824
Validation loss: 2.256654421488444

Epoch: 6| Step: 13
Training loss: 1.8060882091522217
Validation loss: 2.2146697839101157

Epoch: 341| Step: 0
Training loss: 0.7298834323883057
Validation loss: 2.286006808280945

Epoch: 6| Step: 1
Training loss: 1.771679401397705
Validation loss: 2.2961184978485107

Epoch: 6| Step: 2
Training loss: 1.1646003723144531
Validation loss: 2.275789260864258

Epoch: 6| Step: 3
Training loss: 0.5706490278244019
Validation loss: 2.266847610473633

Epoch: 6| Step: 4
Training loss: 1.6557588577270508
Validation loss: 2.251188894112905

Epoch: 6| Step: 5
Training loss: 1.523768663406372
Validation loss: 2.265384872754415

Epoch: 6| Step: 6
Training loss: 1.3494956493377686
Validation loss: 2.2936882972717285

Epoch: 6| Step: 7
Training loss: 1.9925442934036255
Validation loss: 2.283221264680227

Epoch: 6| Step: 8
Training loss: 0.9228695631027222
Validation loss: 2.3202319939931235

Epoch: 6| Step: 9
Training loss: 1.422248125076294
Validation loss: 2.3261254032452903

Epoch: 6| Step: 10
Training loss: 2.1467723846435547
Validation loss: 2.277082165082296

Epoch: 6| Step: 11
Training loss: 1.1782617568969727
Validation loss: 2.335875471433004

Epoch: 6| Step: 12
Training loss: 2.1893677711486816
Validation loss: 2.2843721310297647

Epoch: 6| Step: 13
Training loss: 1.4403507709503174
Validation loss: 2.274900476137797

Epoch: 342| Step: 0
Training loss: 1.1048588752746582
Validation loss: 2.298920691013336

Epoch: 6| Step: 1
Training loss: 1.7811062335968018
Validation loss: 2.2805134057998657

Epoch: 6| Step: 2
Training loss: 1.7602676153182983
Validation loss: 2.2229071060816445

Epoch: 6| Step: 3
Training loss: 1.735987901687622
Validation loss: 2.25183512767156

Epoch: 6| Step: 4
Training loss: 1.2734901905059814
Validation loss: 2.2546676794687905

Epoch: 6| Step: 5
Training loss: 1.6667232513427734
Validation loss: 2.2565539677937827

Epoch: 6| Step: 6
Training loss: 1.0064153671264648
Validation loss: 2.2607887983322144

Epoch: 6| Step: 7
Training loss: 1.0172401666641235
Validation loss: 2.2732053995132446

Epoch: 6| Step: 8
Training loss: 1.3902485370635986
Validation loss: 2.251197417577108

Epoch: 6| Step: 9
Training loss: 1.0722640752792358
Validation loss: 2.2480554779370627

Epoch: 6| Step: 10
Training loss: 0.794960081577301
Validation loss: 2.248628338177999

Epoch: 6| Step: 11
Training loss: 2.1317758560180664
Validation loss: 2.2686418692270913

Epoch: 6| Step: 12
Training loss: 1.1583672761917114
Validation loss: 2.257205386956533

Epoch: 6| Step: 13
Training loss: 1.2832157611846924
Validation loss: 2.262858589490255

Epoch: 343| Step: 0
Training loss: 1.463989496231079
Validation loss: 2.277038355668386

Epoch: 6| Step: 1
Training loss: 0.9404186606407166
Validation loss: 2.2615173856417337

Epoch: 6| Step: 2
Training loss: 1.9543100595474243
Validation loss: 2.2688432335853577

Epoch: 6| Step: 3
Training loss: 1.257960319519043
Validation loss: 2.283149321873983

Epoch: 6| Step: 4
Training loss: 1.3021000623703003
Validation loss: 2.2045991818110147

Epoch: 6| Step: 5
Training loss: 2.0418670177459717
Validation loss: 2.238199512163798

Epoch: 6| Step: 6
Training loss: 0.7461831569671631
Validation loss: 2.2254833777745566

Epoch: 6| Step: 7
Training loss: 1.8840340375900269
Validation loss: 2.201067090034485

Epoch: 6| Step: 8
Training loss: 1.3941998481750488
Validation loss: 2.201123813788096

Epoch: 6| Step: 9
Training loss: 1.4721273183822632
Validation loss: 2.2230209509531655

Epoch: 6| Step: 10
Training loss: 1.3221430778503418
Validation loss: 2.2373240987459817

Epoch: 6| Step: 11
Training loss: 1.4528268575668335
Validation loss: 2.237817347049713

Epoch: 6| Step: 12
Training loss: 0.9291360974311829
Validation loss: 2.2572253545125327

Epoch: 6| Step: 13
Training loss: 1.343787670135498
Validation loss: 2.296087066332499

Epoch: 344| Step: 0
Training loss: 1.3846018314361572
Validation loss: 2.249133308728536

Epoch: 6| Step: 1
Training loss: 1.945742130279541
Validation loss: 2.246212283770243

Epoch: 6| Step: 2
Training loss: 1.7602221965789795
Validation loss: 2.1986411412556968

Epoch: 6| Step: 3
Training loss: 0.8659582138061523
Validation loss: 2.22175399462382

Epoch: 6| Step: 4
Training loss: 1.4064981937408447
Validation loss: 2.2002904415130615

Epoch: 6| Step: 5
Training loss: 1.3936723470687866
Validation loss: 2.1443431774775186

Epoch: 6| Step: 6
Training loss: 1.5570201873779297
Validation loss: 2.173931876818339

Epoch: 6| Step: 7
Training loss: 0.9028939604759216
Validation loss: 2.163151423136393

Epoch: 6| Step: 8
Training loss: 1.9351377487182617
Validation loss: 2.178487996260325

Epoch: 6| Step: 9
Training loss: 1.3049018383026123
Validation loss: 2.212172786394755

Epoch: 6| Step: 10
Training loss: 0.686072587966919
Validation loss: 2.2507049242655435

Epoch: 6| Step: 11
Training loss: 1.382535696029663
Validation loss: 2.226280132929484

Epoch: 6| Step: 12
Training loss: 1.7423107624053955
Validation loss: 2.221284568309784

Epoch: 6| Step: 13
Training loss: 1.535758376121521
Validation loss: 2.2256242434183755

Epoch: 345| Step: 0
Training loss: 0.9886150360107422
Validation loss: 2.27126145362854

Epoch: 6| Step: 1
Training loss: 1.3981599807739258
Validation loss: 2.2763758103052774

Epoch: 6| Step: 2
Training loss: 0.7671080827713013
Validation loss: 2.2901232838630676

Epoch: 6| Step: 3
Training loss: 1.616011381149292
Validation loss: 2.2604226072629294

Epoch: 6| Step: 4
Training loss: 1.1126939058303833
Validation loss: 2.2960107922554016

Epoch: 6| Step: 5
Training loss: 1.8698843717575073
Validation loss: 2.302203436692556

Epoch: 6| Step: 6
Training loss: 1.604551076889038
Validation loss: 2.2862985928853354

Epoch: 6| Step: 7
Training loss: 1.6433427333831787
Validation loss: 2.2816768487294516

Epoch: 6| Step: 8
Training loss: 0.9490185379981995
Validation loss: 2.28957869609197

Epoch: 6| Step: 9
Training loss: 2.4806079864501953
Validation loss: 2.303738554318746

Epoch: 6| Step: 10
Training loss: 1.7190027236938477
Validation loss: 2.2968573570251465

Epoch: 6| Step: 11
Training loss: 0.5391532182693481
Validation loss: 2.2938384215037027

Epoch: 6| Step: 12
Training loss: 1.492245078086853
Validation loss: 2.291060447692871

Epoch: 6| Step: 13
Training loss: 1.8892686367034912
Validation loss: 2.2461974223454795

Epoch: 346| Step: 0
Training loss: 0.7960282564163208
Validation loss: 2.3181806405385337

Epoch: 6| Step: 1
Training loss: 1.048837661743164
Validation loss: 2.3340099652608237

Epoch: 6| Step: 2
Training loss: 1.6335402727127075
Validation loss: 2.3090659777323403

Epoch: 6| Step: 3
Training loss: 1.329986333847046
Validation loss: 2.3276135524113974

Epoch: 6| Step: 4
Training loss: 0.9480082392692566
Validation loss: 2.2851099371910095

Epoch: 6| Step: 5
Training loss: 1.3962078094482422
Validation loss: 2.2694401343663535

Epoch: 6| Step: 6
Training loss: 1.5869903564453125
Validation loss: 2.2876374324162803

Epoch: 6| Step: 7
Training loss: 1.9022085666656494
Validation loss: 2.2992982467015586

Epoch: 6| Step: 8
Training loss: 1.4042389392852783
Validation loss: 2.3024850686391196

Epoch: 6| Step: 9
Training loss: 1.5945942401885986
Validation loss: 2.271264672279358

Epoch: 6| Step: 10
Training loss: 1.5674958229064941
Validation loss: 2.2598589857419333

Epoch: 6| Step: 11
Training loss: 1.7320668697357178
Validation loss: 2.2597559293111167

Epoch: 6| Step: 12
Training loss: 1.7975925207138062
Validation loss: 2.276942193508148

Epoch: 6| Step: 13
Training loss: 1.953666090965271
Validation loss: 2.2459398110707602

Epoch: 347| Step: 0
Training loss: 1.8574413061141968
Validation loss: 2.260556618372599

Epoch: 6| Step: 1
Training loss: 1.5595035552978516
Validation loss: 2.275113105773926

Epoch: 6| Step: 2
Training loss: 1.5416452884674072
Validation loss: 2.285583734512329

Epoch: 6| Step: 3
Training loss: 1.7485331296920776
Validation loss: 2.3071130911509194

Epoch: 6| Step: 4
Training loss: 1.0016976594924927
Validation loss: 2.2729700207710266

Epoch: 6| Step: 5
Training loss: 1.7246464490890503
Validation loss: 2.2769881089528403

Epoch: 6| Step: 6
Training loss: 1.4630532264709473
Validation loss: 2.2978466351826987

Epoch: 6| Step: 7
Training loss: 1.0436028242111206
Validation loss: 2.2607457041740417

Epoch: 6| Step: 8
Training loss: 1.3032740354537964
Validation loss: 2.250432769457499

Epoch: 6| Step: 9
Training loss: 1.6039031744003296
Validation loss: 2.2425406177838645

Epoch: 6| Step: 10
Training loss: 1.258715271949768
Validation loss: 2.2402132749557495

Epoch: 6| Step: 11
Training loss: 1.148664951324463
Validation loss: 2.221982796986898

Epoch: 6| Step: 12
Training loss: 1.307893991470337
Validation loss: 2.27825790643692

Epoch: 6| Step: 13
Training loss: 1.4820241928100586
Validation loss: 2.268062114715576

Epoch: 348| Step: 0
Training loss: 1.7655954360961914
Validation loss: 2.2174572944641113

Epoch: 6| Step: 1
Training loss: 2.0081217288970947
Validation loss: 2.2420934637387595

Epoch: 6| Step: 2
Training loss: 1.6354957818984985
Validation loss: 2.2451613346735635

Epoch: 6| Step: 3
Training loss: 1.4326225519180298
Validation loss: 2.224320411682129

Epoch: 6| Step: 4
Training loss: 1.144134521484375
Validation loss: 2.2259115974108377

Epoch: 6| Step: 5
Training loss: 1.9262421131134033
Validation loss: 2.236844480037689

Epoch: 6| Step: 6
Training loss: 1.2732738256454468
Validation loss: 2.2090221842130027

Epoch: 6| Step: 7
Training loss: 1.3835407495498657
Validation loss: 2.1946705977121987

Epoch: 6| Step: 8
Training loss: 1.007149577140808
Validation loss: 2.206602414449056

Epoch: 6| Step: 9
Training loss: 1.8295124769210815
Validation loss: 2.2330663601557412

Epoch: 6| Step: 10
Training loss: 1.1932587623596191
Validation loss: 2.2019865115483603

Epoch: 6| Step: 11
Training loss: 0.7925775051116943
Validation loss: 2.2252146204312644

Epoch: 6| Step: 12
Training loss: 1.214456558227539
Validation loss: 2.229617476463318

Epoch: 6| Step: 13
Training loss: 1.4380990266799927
Validation loss: 2.263934055964152

Epoch: 349| Step: 0
Training loss: 1.1315380334854126
Validation loss: 2.257008969783783

Epoch: 6| Step: 1
Training loss: 1.377946138381958
Validation loss: 2.212986707687378

Epoch: 6| Step: 2
Training loss: 1.865286946296692
Validation loss: 2.2412779927253723

Epoch: 6| Step: 3
Training loss: 1.4280098676681519
Validation loss: 2.2463579575220742

Epoch: 6| Step: 4
Training loss: 1.5163695812225342
Validation loss: 2.2296285231908164

Epoch: 6| Step: 5
Training loss: 1.2969753742218018
Validation loss: 2.221566637357076

Epoch: 6| Step: 6
Training loss: 0.9175707101821899
Validation loss: 2.2239325046539307

Epoch: 6| Step: 7
Training loss: 1.7383021116256714
Validation loss: 2.2626176476478577

Epoch: 6| Step: 8
Training loss: 1.6700868606567383
Validation loss: 2.2627358039220176

Epoch: 6| Step: 9
Training loss: 1.072141408920288
Validation loss: 2.279552777608236

Epoch: 6| Step: 10
Training loss: 1.5127009153366089
Validation loss: 2.2804062366485596

Epoch: 6| Step: 11
Training loss: 0.9309915900230408
Validation loss: 2.284552256266276

Epoch: 6| Step: 12
Training loss: 1.649135708808899
Validation loss: 2.2773127953211465

Epoch: 6| Step: 13
Training loss: 1.4747916460037231
Validation loss: 2.2204041878382363

Epoch: 350| Step: 0
Training loss: 1.129181146621704
Validation loss: 2.267703096071879

Epoch: 6| Step: 1
Training loss: 2.2595362663269043
Validation loss: 2.287031571070353

Epoch: 6| Step: 2
Training loss: 1.576925277709961
Validation loss: 2.2705382704734802

Epoch: 6| Step: 3
Training loss: 1.3424179553985596
Validation loss: 2.2511439323425293

Epoch: 6| Step: 4
Training loss: 0.9767060875892639
Validation loss: 2.2682204246520996

Epoch: 6| Step: 5
Training loss: 1.245415210723877
Validation loss: 2.272417942682902

Epoch: 6| Step: 6
Training loss: 1.3334734439849854
Validation loss: 2.255649745464325

Epoch: 6| Step: 7
Training loss: 0.7130874395370483
Validation loss: 2.253543734550476

Epoch: 6| Step: 8
Training loss: 1.0282199382781982
Validation loss: 2.273974279562632

Epoch: 6| Step: 9
Training loss: 1.755162000656128
Validation loss: 2.25942591826121

Epoch: 6| Step: 10
Training loss: 1.766139030456543
Validation loss: 2.261610766251882

Epoch: 6| Step: 11
Training loss: 1.2551130056381226
Validation loss: 2.253414829572042

Epoch: 6| Step: 12
Training loss: 1.884695291519165
Validation loss: 2.263148228327433

Epoch: 6| Step: 13
Training loss: 1.082668662071228
Validation loss: 2.2486443718274436

Epoch: 351| Step: 0
Training loss: 1.5048556327819824
Validation loss: 2.2695672313372293

Epoch: 6| Step: 1
Training loss: 1.4052729606628418
Validation loss: 2.2408287127812705

Epoch: 6| Step: 2
Training loss: 1.3348015546798706
Validation loss: 2.2433286706606546

Epoch: 6| Step: 3
Training loss: 0.8457640409469604
Validation loss: 2.228053013483683

Epoch: 6| Step: 4
Training loss: 1.2372572422027588
Validation loss: 2.2360411087671914

Epoch: 6| Step: 5
Training loss: 1.9590654373168945
Validation loss: 2.224383811155955

Epoch: 6| Step: 6
Training loss: 1.649928092956543
Validation loss: 2.2268203496932983

Epoch: 6| Step: 7
Training loss: 1.358965277671814
Validation loss: 2.22311141093572

Epoch: 6| Step: 8
Training loss: 0.6141427159309387
Validation loss: 2.257893900076548

Epoch: 6| Step: 9
Training loss: 1.9223805665969849
Validation loss: 2.2293100357055664

Epoch: 6| Step: 10
Training loss: 1.1760045289993286
Validation loss: 2.2169472376505532

Epoch: 6| Step: 11
Training loss: 1.1347745656967163
Validation loss: 2.2367114226023355

Epoch: 6| Step: 12
Training loss: 1.5623481273651123
Validation loss: 2.2730953693389893

Epoch: 6| Step: 13
Training loss: 1.3160980939865112
Validation loss: 2.2445396780967712

Epoch: 352| Step: 0
Training loss: 1.600142478942871
Validation loss: 2.256540576616923

Epoch: 6| Step: 1
Training loss: 0.5392735004425049
Validation loss: 2.2662479082743325

Epoch: 6| Step: 2
Training loss: 1.0681607723236084
Validation loss: 2.2308719952901206

Epoch: 6| Step: 3
Training loss: 1.0518431663513184
Validation loss: 2.228827178478241

Epoch: 6| Step: 4
Training loss: 1.3526278734207153
Validation loss: 2.22265895207723

Epoch: 6| Step: 5
Training loss: 2.111063241958618
Validation loss: 2.1989119251569114

Epoch: 6| Step: 6
Training loss: 1.2885159254074097
Validation loss: 2.208007593949636

Epoch: 6| Step: 7
Training loss: 1.2755711078643799
Validation loss: 2.2606692711512246

Epoch: 6| Step: 8
Training loss: 2.3395347595214844
Validation loss: 2.2520933548609414

Epoch: 6| Step: 9
Training loss: 1.582383155822754
Validation loss: 2.2320860028266907

Epoch: 6| Step: 10
Training loss: 1.3119258880615234
Validation loss: 2.2265886863072715

Epoch: 6| Step: 11
Training loss: 1.3815405368804932
Validation loss: 2.231286883354187

Epoch: 6| Step: 12
Training loss: 1.5365747213363647
Validation loss: 2.200996538003286

Epoch: 6| Step: 13
Training loss: 0.9968580007553101
Validation loss: 2.275959094365438

Epoch: 353| Step: 0
Training loss: 1.5963900089263916
Validation loss: 2.2382381161053977

Epoch: 6| Step: 1
Training loss: 1.2351524829864502
Validation loss: 2.2651756405830383

Epoch: 6| Step: 2
Training loss: 1.6700356006622314
Validation loss: 2.279302179813385

Epoch: 6| Step: 3
Training loss: 1.0265564918518066
Validation loss: 2.2581234773000083

Epoch: 6| Step: 4
Training loss: 1.1255213022232056
Validation loss: 2.297668973604838

Epoch: 6| Step: 5
Training loss: 0.9703161716461182
Validation loss: 2.2888726194699607

Epoch: 6| Step: 6
Training loss: 1.1790404319763184
Validation loss: 2.2857874234517417

Epoch: 6| Step: 7
Training loss: 1.4581704139709473
Validation loss: 2.2343286077181497

Epoch: 6| Step: 8
Training loss: 1.1061136722564697
Validation loss: 2.2564138571421304

Epoch: 6| Step: 9
Training loss: 1.3405622243881226
Validation loss: 2.241865257422129

Epoch: 6| Step: 10
Training loss: 1.5252647399902344
Validation loss: 2.2487541238466897

Epoch: 6| Step: 11
Training loss: 1.593461036682129
Validation loss: 2.218028505643209

Epoch: 6| Step: 12
Training loss: 1.8850774765014648
Validation loss: 2.2861332297325134

Epoch: 6| Step: 13
Training loss: 2.005659818649292
Validation loss: 2.2611626386642456

Epoch: 354| Step: 0
Training loss: 1.400618553161621
Validation loss: 2.263534426689148

Epoch: 6| Step: 1
Training loss: 1.1433653831481934
Validation loss: 2.2519633769989014

Epoch: 6| Step: 2
Training loss: 0.7335491180419922
Validation loss: 2.24979559580485

Epoch: 6| Step: 3
Training loss: 1.157462477684021
Validation loss: 2.2224491437276206

Epoch: 6| Step: 4
Training loss: 1.23320734500885
Validation loss: 2.217778484026591

Epoch: 6| Step: 5
Training loss: 1.2819454669952393
Validation loss: 2.248406151930491

Epoch: 6| Step: 6
Training loss: 1.02689528465271
Validation loss: 2.269795298576355

Epoch: 6| Step: 7
Training loss: 2.0963594913482666
Validation loss: 2.173493444919586

Epoch: 6| Step: 8
Training loss: 1.8744122982025146
Validation loss: 2.214881658554077

Epoch: 6| Step: 9
Training loss: 0.9164271354675293
Validation loss: 2.248898983001709

Epoch: 6| Step: 10
Training loss: 1.5094308853149414
Validation loss: 2.2654364903767905

Epoch: 6| Step: 11
Training loss: 2.1454153060913086
Validation loss: 2.2363064686457315

Epoch: 6| Step: 12
Training loss: 1.2825376987457275
Validation loss: 2.2772165139516196

Epoch: 6| Step: 13
Training loss: 1.16018545627594
Validation loss: 2.2831325928370156

Epoch: 355| Step: 0
Training loss: 1.3559893369674683
Validation loss: 2.2410897811253867

Epoch: 6| Step: 1
Training loss: 1.6177659034729004
Validation loss: 2.2704885403315225

Epoch: 6| Step: 2
Training loss: 1.270714521408081
Validation loss: 2.289673626422882

Epoch: 6| Step: 3
Training loss: 1.553640604019165
Validation loss: 2.322094758351644

Epoch: 6| Step: 4
Training loss: 2.153918743133545
Validation loss: 2.3373337785402932

Epoch: 6| Step: 5
Training loss: 0.9280704259872437
Validation loss: 2.3000064293543496

Epoch: 6| Step: 6
Training loss: 0.9798739552497864
Validation loss: 2.2692745129267373

Epoch: 6| Step: 7
Training loss: 1.4252750873565674
Validation loss: 2.284352699915568

Epoch: 6| Step: 8
Training loss: 1.213850498199463
Validation loss: 2.2906689047813416

Epoch: 6| Step: 9
Training loss: 1.888074278831482
Validation loss: 2.293101151784261

Epoch: 6| Step: 10
Training loss: 1.450287103652954
Validation loss: 2.280194024244944

Epoch: 6| Step: 11
Training loss: 1.3094303607940674
Validation loss: 2.311831474304199

Epoch: 6| Step: 12
Training loss: 0.68270343542099
Validation loss: 2.275712311267853

Epoch: 6| Step: 13
Training loss: 0.9943112134933472
Validation loss: 2.2653094132741294

Epoch: 356| Step: 0
Training loss: 1.384946346282959
Validation loss: 2.304701268672943

Epoch: 6| Step: 1
Training loss: 0.8029674291610718
Validation loss: 2.2495619853337607

Epoch: 6| Step: 2
Training loss: 1.8148143291473389
Validation loss: 2.2355842192967734

Epoch: 6| Step: 3
Training loss: 1.2610526084899902
Validation loss: 2.2816241979599

Epoch: 6| Step: 4
Training loss: 0.8394425511360168
Validation loss: 2.2629308501879373

Epoch: 6| Step: 5
Training loss: 1.2742060422897339
Validation loss: 2.2875524163246155

Epoch: 6| Step: 6
Training loss: 0.8719131350517273
Validation loss: 2.2958587805430093

Epoch: 6| Step: 7
Training loss: 2.1451525688171387
Validation loss: 2.2650878032048545

Epoch: 6| Step: 8
Training loss: 0.7766948342323303
Validation loss: 2.2753012975056968

Epoch: 6| Step: 9
Training loss: 2.594583034515381
Validation loss: 2.2948114474614463

Epoch: 6| Step: 10
Training loss: 1.176845908164978
Validation loss: 2.304161230723063

Epoch: 6| Step: 11
Training loss: 0.9672175645828247
Validation loss: 2.2979719638824463

Epoch: 6| Step: 12
Training loss: 1.2212677001953125
Validation loss: 2.3164854447046914

Epoch: 6| Step: 13
Training loss: 1.6896991729736328
Validation loss: 2.3207412362098694

Epoch: 357| Step: 0
Training loss: 1.2505841255187988
Validation loss: 2.274378697077433

Epoch: 6| Step: 1
Training loss: 0.8533611297607422
Validation loss: 2.269878347714742

Epoch: 6| Step: 2
Training loss: 1.0152778625488281
Validation loss: 2.285120725631714

Epoch: 6| Step: 3
Training loss: 1.461644172668457
Validation loss: 2.253598213195801

Epoch: 6| Step: 4
Training loss: 1.662196397781372
Validation loss: 2.240059773127238

Epoch: 6| Step: 5
Training loss: 2.311903476715088
Validation loss: 2.2888567050298056

Epoch: 6| Step: 6
Training loss: 1.4880807399749756
Validation loss: 2.273949086666107

Epoch: 6| Step: 7
Training loss: 0.7182244658470154
Validation loss: 2.2496095299720764

Epoch: 6| Step: 8
Training loss: 1.0657687187194824
Validation loss: 2.2622464299201965

Epoch: 6| Step: 9
Training loss: 1.2080987691879272
Validation loss: 2.2485111157099404

Epoch: 6| Step: 10
Training loss: 1.6404314041137695
Validation loss: 2.2597699562708535

Epoch: 6| Step: 11
Training loss: 2.3608999252319336
Validation loss: 2.2644107341766357

Epoch: 6| Step: 12
Training loss: 1.7504000663757324
Validation loss: 2.2348241011301675

Epoch: 6| Step: 13
Training loss: 1.0520803928375244
Validation loss: 2.232653240362803

Epoch: 358| Step: 0
Training loss: 1.840964913368225
Validation loss: 2.199789603551229

Epoch: 6| Step: 1
Training loss: 1.8584544658660889
Validation loss: 2.216127316157023

Epoch: 6| Step: 2
Training loss: 1.1603578329086304
Validation loss: 2.251502792040507

Epoch: 6| Step: 3
Training loss: 0.9802548289299011
Validation loss: 2.236052652200063

Epoch: 6| Step: 4
Training loss: 1.3738065958023071
Validation loss: 2.239137887954712

Epoch: 6| Step: 5
Training loss: 1.6352777481079102
Validation loss: 2.224508285522461

Epoch: 6| Step: 6
Training loss: 0.9692121744155884
Validation loss: 2.245128949483236

Epoch: 6| Step: 7
Training loss: 0.9285538196563721
Validation loss: 2.2291509906450906

Epoch: 6| Step: 8
Training loss: 1.6781020164489746
Validation loss: 2.2471969723701477

Epoch: 6| Step: 9
Training loss: 1.3568617105484009
Validation loss: 2.260871708393097

Epoch: 6| Step: 10
Training loss: 2.232060194015503
Validation loss: 2.25136129061381

Epoch: 6| Step: 11
Training loss: 1.8887908458709717
Validation loss: 2.2266355752944946

Epoch: 6| Step: 12
Training loss: 1.3473742008209229
Validation loss: 2.2535526553789773

Epoch: 6| Step: 13
Training loss: 0.6467435359954834
Validation loss: 2.2664953668912253

Epoch: 359| Step: 0
Training loss: 1.5986794233322144
Validation loss: 2.238223433494568

Epoch: 6| Step: 1
Training loss: 1.4763073921203613
Validation loss: 2.2633853753407798

Epoch: 6| Step: 2
Training loss: 2.110157012939453
Validation loss: 2.2335590521494546

Epoch: 6| Step: 3
Training loss: 1.9476239681243896
Validation loss: 2.212105095386505

Epoch: 6| Step: 4
Training loss: 1.0163182020187378
Validation loss: 2.2405812740325928

Epoch: 6| Step: 5
Training loss: 1.1768466234207153
Validation loss: 2.20813657840093

Epoch: 6| Step: 6
Training loss: 1.9319262504577637
Validation loss: 2.2373922864596048

Epoch: 6| Step: 7
Training loss: 0.7570045590400696
Validation loss: 2.2194104393323264

Epoch: 6| Step: 8
Training loss: 0.5924354195594788
Validation loss: 2.2515347599983215

Epoch: 6| Step: 9
Training loss: 1.5216870307922363
Validation loss: 2.2448724508285522

Epoch: 6| Step: 10
Training loss: 1.2882717847824097
Validation loss: 2.2484018802642822

Epoch: 6| Step: 11
Training loss: 0.9096270799636841
Validation loss: 2.242800017197927

Epoch: 6| Step: 12
Training loss: 1.2857493162155151
Validation loss: 2.2783753275871277

Epoch: 6| Step: 13
Training loss: 1.1488127708435059
Validation loss: 2.319023867448171

Epoch: 360| Step: 0
Training loss: 1.4245543479919434
Validation loss: 2.2732409636179605

Epoch: 6| Step: 1
Training loss: 1.638818383216858
Validation loss: 2.2629061937332153

Epoch: 6| Step: 2
Training loss: 2.0514514446258545
Validation loss: 2.3217159509658813

Epoch: 6| Step: 3
Training loss: 1.3495428562164307
Validation loss: 2.2844154636065164

Epoch: 6| Step: 4
Training loss: 1.2996143102645874
Validation loss: 2.28978697458903

Epoch: 6| Step: 5
Training loss: 1.3252060413360596
Validation loss: 2.2893048922220864

Epoch: 6| Step: 6
Training loss: 0.763176679611206
Validation loss: 2.279223879178365

Epoch: 6| Step: 7
Training loss: 1.489952802658081
Validation loss: 2.2375865976015725

Epoch: 6| Step: 8
Training loss: 1.1510155200958252
Validation loss: 2.258162240187327

Epoch: 6| Step: 9
Training loss: 2.072082996368408
Validation loss: 2.3249117533365884

Epoch: 6| Step: 10
Training loss: 0.8882209062576294
Validation loss: 2.298081636428833

Epoch: 6| Step: 11
Training loss: 1.1267290115356445
Validation loss: 2.282031079133352

Epoch: 6| Step: 12
Training loss: 0.9164789915084839
Validation loss: 2.2637004057566323

Epoch: 6| Step: 13
Training loss: 0.7047901749610901
Validation loss: 2.2291577458381653

Epoch: 361| Step: 0
Training loss: 1.1580710411071777
Validation loss: 2.245005249977112

Epoch: 6| Step: 1
Training loss: 1.9517959356307983
Validation loss: 2.263294219970703

Epoch: 6| Step: 2
Training loss: 1.4265961647033691
Validation loss: 2.2874461809794107

Epoch: 6| Step: 3
Training loss: 1.014497995376587
Validation loss: 2.28371795018514

Epoch: 6| Step: 4
Training loss: 1.1298112869262695
Validation loss: 2.2467034260431924

Epoch: 6| Step: 5
Training loss: 1.1887407302856445
Validation loss: 2.2333900928497314

Epoch: 6| Step: 6
Training loss: 1.212328553199768
Validation loss: 2.2589205702145896

Epoch: 6| Step: 7
Training loss: 1.4639915227890015
Validation loss: 2.223384360472361

Epoch: 6| Step: 8
Training loss: 0.9641558527946472
Validation loss: 2.265831549962362

Epoch: 6| Step: 9
Training loss: 1.2764968872070312
Validation loss: 2.2023783524831138

Epoch: 6| Step: 10
Training loss: 0.8657447695732117
Validation loss: 2.2346885402997336

Epoch: 6| Step: 11
Training loss: 1.263237714767456
Validation loss: 2.2470317482948303

Epoch: 6| Step: 12
Training loss: 2.1340250968933105
Validation loss: 2.283344089984894

Epoch: 6| Step: 13
Training loss: 0.7274249792098999
Validation loss: 2.2273099422454834

Epoch: 362| Step: 0
Training loss: 1.032869577407837
Validation loss: 2.255303422609965

Epoch: 6| Step: 1
Training loss: 1.4845271110534668
Validation loss: 2.2521806359291077

Epoch: 6| Step: 2
Training loss: 0.9507576823234558
Validation loss: 2.261283040046692

Epoch: 6| Step: 3
Training loss: 1.2685096263885498
Validation loss: 2.2657313148180642

Epoch: 6| Step: 4
Training loss: 1.1908276081085205
Validation loss: 2.256215433279673

Epoch: 6| Step: 5
Training loss: 1.1737959384918213
Validation loss: 2.2735509872436523

Epoch: 6| Step: 6
Training loss: 1.815528392791748
Validation loss: 2.2649078369140625

Epoch: 6| Step: 7
Training loss: 1.6912460327148438
Validation loss: 2.256847361723582

Epoch: 6| Step: 8
Training loss: 1.013086199760437
Validation loss: 2.264990588029226

Epoch: 6| Step: 9
Training loss: 1.6774029731750488
Validation loss: 2.301722009976705

Epoch: 6| Step: 10
Training loss: 1.6507370471954346
Validation loss: 2.286776900291443

Epoch: 6| Step: 11
Training loss: 0.42785823345184326
Validation loss: 2.3076494336128235

Epoch: 6| Step: 12
Training loss: 1.4172396659851074
Validation loss: 2.289363225301107

Epoch: 6| Step: 13
Training loss: 1.2957414388656616
Validation loss: 2.2687282164891562

Epoch: 363| Step: 0
Training loss: 0.8490825891494751
Validation loss: 2.3151275316874185

Epoch: 6| Step: 1
Training loss: 0.6403893828392029
Validation loss: 2.324267109235128

Epoch: 6| Step: 2
Training loss: 2.277512311935425
Validation loss: 2.2496299147605896

Epoch: 6| Step: 3
Training loss: 1.9485812187194824
Validation loss: 2.273238241672516

Epoch: 6| Step: 4
Training loss: 1.1343512535095215
Validation loss: 2.2684246301651

Epoch: 6| Step: 5
Training loss: 0.7231069803237915
Validation loss: 2.2981302738189697

Epoch: 6| Step: 6
Training loss: 1.5738654136657715
Validation loss: 2.247832397619883

Epoch: 6| Step: 7
Training loss: 1.3456732034683228
Validation loss: 2.2408001025517783

Epoch: 6| Step: 8
Training loss: 1.4253873825073242
Validation loss: 2.288137356440226

Epoch: 6| Step: 9
Training loss: 1.3180290460586548
Validation loss: 2.298407872517904

Epoch: 6| Step: 10
Training loss: 1.0582735538482666
Validation loss: 2.292881886164347

Epoch: 6| Step: 11
Training loss: 1.535476565361023
Validation loss: 2.237172563870748

Epoch: 6| Step: 12
Training loss: 1.416337013244629
Validation loss: 2.274707277615865

Epoch: 6| Step: 13
Training loss: 0.7411761283874512
Validation loss: 2.254723389943441

Epoch: 364| Step: 0
Training loss: 0.6534318923950195
Validation loss: 2.325418790181478

Epoch: 6| Step: 1
Training loss: 0.7725632190704346
Validation loss: 2.3092174728711448

Epoch: 6| Step: 2
Training loss: 0.8866335153579712
Validation loss: 2.278196096420288

Epoch: 6| Step: 3
Training loss: 1.6428258419036865
Validation loss: 2.282605528831482

Epoch: 6| Step: 4
Training loss: 1.7148184776306152
Validation loss: 2.313348650932312

Epoch: 6| Step: 5
Training loss: 1.661637306213379
Validation loss: 2.312090357144674

Epoch: 6| Step: 6
Training loss: 1.0058833360671997
Validation loss: 2.3237975041071572

Epoch: 6| Step: 7
Training loss: 0.9517854452133179
Validation loss: 2.345782995223999

Epoch: 6| Step: 8
Training loss: 1.5539100170135498
Validation loss: 2.3294703165690103

Epoch: 6| Step: 9
Training loss: 2.049837589263916
Validation loss: 2.317116677761078

Epoch: 6| Step: 10
Training loss: 1.339805006980896
Validation loss: 2.331302285194397

Epoch: 6| Step: 11
Training loss: 1.089482069015503
Validation loss: 2.321097711722056

Epoch: 6| Step: 12
Training loss: 1.4294400215148926
Validation loss: 2.3182130654652915

Epoch: 6| Step: 13
Training loss: 2.0068769454956055
Validation loss: 2.2985761562983194

Epoch: 365| Step: 0
Training loss: 1.3765647411346436
Validation loss: 2.2588159640630088

Epoch: 6| Step: 1
Training loss: 1.3199418783187866
Validation loss: 2.2652936776479087

Epoch: 6| Step: 2
Training loss: 1.362127661705017
Validation loss: 2.273155430952708

Epoch: 6| Step: 3
Training loss: 1.570352554321289
Validation loss: 2.292266329129537

Epoch: 6| Step: 4
Training loss: 0.4086683392524719
Validation loss: 2.2401549021402993

Epoch: 6| Step: 5
Training loss: 1.2006011009216309
Validation loss: 2.2461477319399514

Epoch: 6| Step: 6
Training loss: 1.0587258338928223
Validation loss: 2.2257190545399985

Epoch: 6| Step: 7
Training loss: 1.0697532892227173
Validation loss: 2.243819018205007

Epoch: 6| Step: 8
Training loss: 1.2102354764938354
Validation loss: 2.2545103430747986

Epoch: 6| Step: 9
Training loss: 1.7783292531967163
Validation loss: 2.254011332988739

Epoch: 6| Step: 10
Training loss: 1.2569270133972168
Validation loss: 2.2261006037394204

Epoch: 6| Step: 11
Training loss: 1.842900037765503
Validation loss: 2.3239723245302835

Epoch: 6| Step: 12
Training loss: 1.5148730278015137
Validation loss: 2.288771649201711

Epoch: 6| Step: 13
Training loss: 1.542942762374878
Validation loss: 2.2704478104909263

Epoch: 366| Step: 0
Training loss: 1.723382592201233
Validation loss: 2.2159193754196167

Epoch: 6| Step: 1
Training loss: 1.2661948204040527
Validation loss: 2.211359739303589

Epoch: 6| Step: 2
Training loss: 0.8618612289428711
Validation loss: 2.231326719125112

Epoch: 6| Step: 3
Training loss: 1.7318497896194458
Validation loss: 2.2237449288368225

Epoch: 6| Step: 4
Training loss: 0.7581499218940735
Validation loss: 2.2812335093816123

Epoch: 6| Step: 5
Training loss: 1.284715175628662
Validation loss: 2.224233309427897

Epoch: 6| Step: 6
Training loss: 0.9891477227210999
Validation loss: 2.2421905994415283

Epoch: 6| Step: 7
Training loss: 1.4300479888916016
Validation loss: 2.2160796324412027

Epoch: 6| Step: 8
Training loss: 1.218355417251587
Validation loss: 2.233447869618734

Epoch: 6| Step: 9
Training loss: 1.4671165943145752
Validation loss: 2.259425322214762

Epoch: 6| Step: 10
Training loss: 1.2656934261322021
Validation loss: 2.2088252703348794

Epoch: 6| Step: 11
Training loss: 1.229560375213623
Validation loss: 2.246194044748942

Epoch: 6| Step: 12
Training loss: 1.5503110885620117
Validation loss: 2.2674464782079062

Epoch: 6| Step: 13
Training loss: 0.8576695919036865
Validation loss: 2.2611693143844604

Epoch: 367| Step: 0
Training loss: 0.8213719129562378
Validation loss: 2.2529983520507812

Epoch: 6| Step: 1
Training loss: 1.5131853818893433
Validation loss: 2.239341954390208

Epoch: 6| Step: 2
Training loss: 1.809523582458496
Validation loss: 2.227783183256785

Epoch: 6| Step: 3
Training loss: 0.8324313163757324
Validation loss: 2.2228436867396035

Epoch: 6| Step: 4
Training loss: 1.507683277130127
Validation loss: 2.2472816705703735

Epoch: 6| Step: 5
Training loss: 0.7204056978225708
Validation loss: 2.2667075594266257

Epoch: 6| Step: 6
Training loss: 1.900748372077942
Validation loss: 2.2654882868131003

Epoch: 6| Step: 7
Training loss: 1.1990370750427246
Validation loss: 2.256815751393636

Epoch: 6| Step: 8
Training loss: 1.3794242143630981
Validation loss: 2.244483153025309

Epoch: 6| Step: 9
Training loss: 1.7195277214050293
Validation loss: 2.262888471285502

Epoch: 6| Step: 10
Training loss: 1.42877995967865
Validation loss: 2.2467329104741416

Epoch: 6| Step: 11
Training loss: 1.8835926055908203
Validation loss: 2.252707580725352

Epoch: 6| Step: 12
Training loss: 0.6803230047225952
Validation loss: 2.285034457842509

Epoch: 6| Step: 13
Training loss: 1.4910047054290771
Validation loss: 2.2760051091512046

Epoch: 368| Step: 0
Training loss: 0.9412295818328857
Validation loss: 2.2400030891100564

Epoch: 6| Step: 1
Training loss: 1.2541022300720215
Validation loss: 2.2340072790781655

Epoch: 6| Step: 2
Training loss: 1.2196052074432373
Validation loss: 2.228566745917002

Epoch: 6| Step: 3
Training loss: 1.1812236309051514
Validation loss: 2.241561790307363

Epoch: 6| Step: 4
Training loss: 1.420890212059021
Validation loss: 2.2154633601506553

Epoch: 6| Step: 5
Training loss: 1.313785195350647
Validation loss: 2.263811945915222

Epoch: 6| Step: 6
Training loss: 0.9505646228790283
Validation loss: 2.237444043159485

Epoch: 6| Step: 7
Training loss: 1.1888060569763184
Validation loss: 2.231862485408783

Epoch: 6| Step: 8
Training loss: 0.8627163171768188
Validation loss: 2.2474045952161155

Epoch: 6| Step: 9
Training loss: 2.3092331886291504
Validation loss: 2.2140634059906006

Epoch: 6| Step: 10
Training loss: 1.9337308406829834
Validation loss: 2.2325022220611572

Epoch: 6| Step: 11
Training loss: 0.89284348487854
Validation loss: 2.2367480993270874

Epoch: 6| Step: 12
Training loss: 1.3251819610595703
Validation loss: 2.221850593884786

Epoch: 6| Step: 13
Training loss: 0.7218003273010254
Validation loss: 2.263478477795919

Epoch: 369| Step: 0
Training loss: 1.3293383121490479
Validation loss: 2.2922819455464682

Epoch: 6| Step: 1
Training loss: 1.3698170185089111
Validation loss: 2.2831977208455405

Epoch: 6| Step: 2
Training loss: 2.473383903503418
Validation loss: 2.2722885409990945

Epoch: 6| Step: 3
Training loss: 1.7710742950439453
Validation loss: 2.3343350887298584

Epoch: 6| Step: 4
Training loss: 1.5684884786605835
Validation loss: 2.265174627304077

Epoch: 6| Step: 5
Training loss: 0.9927975535392761
Validation loss: 2.3175128698349

Epoch: 6| Step: 6
Training loss: 1.040799617767334
Validation loss: 2.317838509877523

Epoch: 6| Step: 7
Training loss: 1.5295698642730713
Validation loss: 2.299660801887512

Epoch: 6| Step: 8
Training loss: 1.2130663394927979
Validation loss: 2.260870615641276

Epoch: 6| Step: 9
Training loss: 0.7895309925079346
Validation loss: 2.254441241423289

Epoch: 6| Step: 10
Training loss: 1.129054069519043
Validation loss: 2.287211537361145

Epoch: 6| Step: 11
Training loss: 0.8260478973388672
Validation loss: 2.249910374482473

Epoch: 6| Step: 12
Training loss: 0.9629217982292175
Validation loss: 2.250965098539988

Epoch: 6| Step: 13
Training loss: 1.115849494934082
Validation loss: 2.2621661027272544

Epoch: 370| Step: 0
Training loss: 0.9396133422851562
Validation loss: 2.2791723211606345

Epoch: 6| Step: 1
Training loss: 1.151160717010498
Validation loss: 2.2893833915392556

Epoch: 6| Step: 2
Training loss: 1.4732542037963867
Validation loss: 2.2877065539360046

Epoch: 6| Step: 3
Training loss: 1.5962908267974854
Validation loss: 2.294648309548696

Epoch: 6| Step: 4
Training loss: 1.3121232986450195
Validation loss: 2.3389553229014077

Epoch: 6| Step: 5
Training loss: 1.295328974723816
Validation loss: 2.2885703841845193

Epoch: 6| Step: 6
Training loss: 1.329207181930542
Validation loss: 2.2882756193478904

Epoch: 6| Step: 7
Training loss: 1.398589849472046
Validation loss: 2.3484134674072266

Epoch: 6| Step: 8
Training loss: 2.233621120452881
Validation loss: 2.3013305266698203

Epoch: 6| Step: 9
Training loss: 0.8542839288711548
Validation loss: 2.336109975973765

Epoch: 6| Step: 10
Training loss: 0.8724174499511719
Validation loss: 2.3002379536628723

Epoch: 6| Step: 11
Training loss: 1.0934245586395264
Validation loss: 2.237556536992391

Epoch: 6| Step: 12
Training loss: 1.2721643447875977
Validation loss: 2.2416998147964478

Epoch: 6| Step: 13
Training loss: 0.7511507868766785
Validation loss: 2.286500652631124

Epoch: 371| Step: 0
Training loss: 0.7372421026229858
Validation loss: 2.2708608508110046

Epoch: 6| Step: 1
Training loss: 1.340552568435669
Validation loss: 2.286447763442993

Epoch: 6| Step: 2
Training loss: 1.2835586071014404
Validation loss: 2.315747698148092

Epoch: 6| Step: 3
Training loss: 1.5267603397369385
Validation loss: 2.2783284783363342

Epoch: 6| Step: 4
Training loss: 1.118018388748169
Validation loss: 2.267584959665934

Epoch: 6| Step: 5
Training loss: 0.7242563366889954
Validation loss: 2.292141338189443

Epoch: 6| Step: 6
Training loss: 1.3117486238479614
Validation loss: 2.2982341647148132

Epoch: 6| Step: 7
Training loss: 0.7254111170768738
Validation loss: 2.2377186020215354

Epoch: 6| Step: 8
Training loss: 1.5547690391540527
Validation loss: 2.26506636540095

Epoch: 6| Step: 9
Training loss: 0.9147915840148926
Validation loss: 2.2450867096583047

Epoch: 6| Step: 10
Training loss: 0.9691656231880188
Validation loss: 2.2806951800982156

Epoch: 6| Step: 11
Training loss: 1.90353524684906
Validation loss: 2.2610196272532144

Epoch: 6| Step: 12
Training loss: 1.7384953498840332
Validation loss: 2.2863957484563193

Epoch: 6| Step: 13
Training loss: 1.648072361946106
Validation loss: 2.2814874251683555

Epoch: 372| Step: 0
Training loss: 1.1327331066131592
Validation loss: 2.266780654589335

Epoch: 6| Step: 1
Training loss: 1.147040605545044
Validation loss: 2.3197866678237915

Epoch: 6| Step: 2
Training loss: 1.4638936519622803
Validation loss: 2.2813415129979453

Epoch: 6| Step: 3
Training loss: 1.6492459774017334
Validation loss: 2.3000779946645102

Epoch: 6| Step: 4
Training loss: 1.0779571533203125
Validation loss: 2.327327092488607

Epoch: 6| Step: 5
Training loss: 1.6821811199188232
Validation loss: 2.266985535621643

Epoch: 6| Step: 6
Training loss: 1.666710376739502
Validation loss: 2.27503103017807

Epoch: 6| Step: 7
Training loss: 2.5604803562164307
Validation loss: 2.266860862572988

Epoch: 6| Step: 8
Training loss: 1.6844744682312012
Validation loss: 2.2992830872535706

Epoch: 6| Step: 9
Training loss: 1.36299729347229
Validation loss: 2.3078882296880088

Epoch: 6| Step: 10
Training loss: 0.8764798641204834
Validation loss: 2.2720181544621787

Epoch: 6| Step: 11
Training loss: 0.6999994516372681
Validation loss: 2.2818086544672647

Epoch: 6| Step: 12
Training loss: 0.5097277760505676
Validation loss: 2.240987757841746

Epoch: 6| Step: 13
Training loss: 1.506953477859497
Validation loss: 2.2649411956469216

Epoch: 373| Step: 0
Training loss: 0.7890152931213379
Validation loss: 2.234167536099752

Epoch: 6| Step: 1
Training loss: 1.4223321676254272
Validation loss: 2.2749675114949546

Epoch: 6| Step: 2
Training loss: 1.3435485363006592
Validation loss: 2.284563958644867

Epoch: 6| Step: 3
Training loss: 1.1133065223693848
Validation loss: 2.2569095492362976

Epoch: 6| Step: 4
Training loss: 1.4803752899169922
Validation loss: 2.2999465465545654

Epoch: 6| Step: 5
Training loss: 1.9967830181121826
Validation loss: 2.241878648598989

Epoch: 6| Step: 6
Training loss: 1.3876979351043701
Validation loss: 2.2425957520802817

Epoch: 6| Step: 7
Training loss: 0.9237748384475708
Validation loss: 2.247975528240204

Epoch: 6| Step: 8
Training loss: 1.0912078619003296
Validation loss: 2.2373050252596536

Epoch: 6| Step: 9
Training loss: 1.3084897994995117
Validation loss: 2.236270487308502

Epoch: 6| Step: 10
Training loss: 1.2329250574111938
Validation loss: 2.2320381005605063

Epoch: 6| Step: 11
Training loss: 1.0855367183685303
Validation loss: 2.2071871558825173

Epoch: 6| Step: 12
Training loss: 1.3800846338272095
Validation loss: 2.1912068327267966

Epoch: 6| Step: 13
Training loss: 1.5386898517608643
Validation loss: 2.201204558213552

Epoch: 374| Step: 0
Training loss: 1.076775312423706
Validation loss: 2.2594922383626304

Epoch: 6| Step: 1
Training loss: 1.5396097898483276
Validation loss: 2.2066513299942017

Epoch: 6| Step: 2
Training loss: 2.020411968231201
Validation loss: 2.2510735591252646

Epoch: 6| Step: 3
Training loss: 1.2138357162475586
Validation loss: 2.2455637057622275

Epoch: 6| Step: 4
Training loss: 1.676759958267212
Validation loss: 2.2087856332461038

Epoch: 6| Step: 5
Training loss: 0.7375926971435547
Validation loss: 2.2328727642695108

Epoch: 6| Step: 6
Training loss: 0.8253179788589478
Validation loss: 2.234587033589681

Epoch: 6| Step: 7
Training loss: 0.885561466217041
Validation loss: 2.238678296407064

Epoch: 6| Step: 8
Training loss: 1.5461692810058594
Validation loss: 2.2305545012156167

Epoch: 6| Step: 9
Training loss: 1.5602612495422363
Validation loss: 2.218925734361013

Epoch: 6| Step: 10
Training loss: 1.1443110704421997
Validation loss: 2.208717624346415

Epoch: 6| Step: 11
Training loss: 1.3469399213790894
Validation loss: 2.2315699656804404

Epoch: 6| Step: 12
Training loss: 1.3258827924728394
Validation loss: 2.21331650018692

Epoch: 6| Step: 13
Training loss: 0.5463420152664185
Validation loss: 2.2179141839345298

Epoch: 375| Step: 0
Training loss: 0.9764452576637268
Validation loss: 2.199073394139608

Epoch: 6| Step: 1
Training loss: 1.7209405899047852
Validation loss: 2.209702750047048

Epoch: 6| Step: 2
Training loss: 1.3072656393051147
Validation loss: 2.197488764921824

Epoch: 6| Step: 3
Training loss: 1.4666805267333984
Validation loss: 2.2031259735425315

Epoch: 6| Step: 4
Training loss: 1.0625905990600586
Validation loss: 2.173814137776693

Epoch: 6| Step: 5
Training loss: 1.177159309387207
Validation loss: 2.207160472869873

Epoch: 6| Step: 6
Training loss: 1.10123872756958
Validation loss: 2.1821273366610208

Epoch: 6| Step: 7
Training loss: 0.85093092918396
Validation loss: 2.2251638571421304

Epoch: 6| Step: 8
Training loss: 1.352979063987732
Validation loss: 2.2125945687294006

Epoch: 6| Step: 9
Training loss: 1.0728974342346191
Validation loss: 2.1990483601888022

Epoch: 6| Step: 10
Training loss: 0.7154854536056519
Validation loss: 2.229142983754476

Epoch: 6| Step: 11
Training loss: 1.7512750625610352
Validation loss: 2.2830535968144736

Epoch: 6| Step: 12
Training loss: 1.3111408948898315
Validation loss: 2.282879134019216

Epoch: 6| Step: 13
Training loss: 1.6880340576171875
Validation loss: 2.297157029310862

Epoch: 376| Step: 0
Training loss: 1.0225965976715088
Validation loss: 2.28142640988032

Epoch: 6| Step: 1
Training loss: 1.341651201248169
Validation loss: 2.274339576562246

Epoch: 6| Step: 2
Training loss: 1.0769087076187134
Validation loss: 2.265133023262024

Epoch: 6| Step: 3
Training loss: 1.086209774017334
Validation loss: 2.251922329266866

Epoch: 6| Step: 4
Training loss: 1.252071738243103
Validation loss: 2.237494250138601

Epoch: 6| Step: 5
Training loss: 1.6362853050231934
Validation loss: 2.2390072345733643

Epoch: 6| Step: 6
Training loss: 0.9814612865447998
Validation loss: 2.256707787513733

Epoch: 6| Step: 7
Training loss: 1.3953403234481812
Validation loss: 2.294126113255819

Epoch: 6| Step: 8
Training loss: 1.7348277568817139
Validation loss: 2.2446587085723877

Epoch: 6| Step: 9
Training loss: 2.2759079933166504
Validation loss: 2.235905647277832

Epoch: 6| Step: 10
Training loss: 1.3728950023651123
Validation loss: 2.2513816952705383

Epoch: 6| Step: 11
Training loss: 0.5900720357894897
Validation loss: 2.2262885173161826

Epoch: 6| Step: 12
Training loss: 1.02077054977417
Validation loss: 2.2707054118315377

Epoch: 6| Step: 13
Training loss: 0.9344544410705566
Validation loss: 2.218773146470388

Epoch: 377| Step: 0
Training loss: 1.6123521327972412
Validation loss: 2.2435260812441506

Epoch: 6| Step: 1
Training loss: 0.7593081593513489
Validation loss: 2.262438654899597

Epoch: 6| Step: 2
Training loss: 0.6445198655128479
Validation loss: 2.2207316557566323

Epoch: 6| Step: 3
Training loss: 1.3698389530181885
Validation loss: 2.228776673475901

Epoch: 6| Step: 4
Training loss: 1.2867629528045654
Validation loss: 2.200037936369578

Epoch: 6| Step: 5
Training loss: 1.6510331630706787
Validation loss: 2.240372618039449

Epoch: 6| Step: 6
Training loss: 0.7163254618644714
Validation loss: 2.22667133808136

Epoch: 6| Step: 7
Training loss: 1.2118861675262451
Validation loss: 2.2492045760154724

Epoch: 6| Step: 8
Training loss: 1.1333131790161133
Validation loss: 2.208246886730194

Epoch: 6| Step: 9
Training loss: 2.5447678565979004
Validation loss: 2.1973882913589478

Epoch: 6| Step: 10
Training loss: 1.1035914421081543
Validation loss: 2.201044201850891

Epoch: 6| Step: 11
Training loss: 1.4883556365966797
Validation loss: 2.2084251244862876

Epoch: 6| Step: 12
Training loss: 0.7702138423919678
Validation loss: 2.2276963194211326

Epoch: 6| Step: 13
Training loss: 0.8983100652694702
Validation loss: 2.2244879802068076

Epoch: 378| Step: 0
Training loss: 2.5872445106506348
Validation loss: 2.220303535461426

Epoch: 6| Step: 1
Training loss: 0.49869322776794434
Validation loss: 2.2284892400105796

Epoch: 6| Step: 2
Training loss: 1.0484051704406738
Validation loss: 2.226301431655884

Epoch: 6| Step: 3
Training loss: 0.8462837934494019
Validation loss: 2.2071944872538247

Epoch: 6| Step: 4
Training loss: 1.0431187152862549
Validation loss: 2.222637871901194

Epoch: 6| Step: 5
Training loss: 1.0276132822036743
Validation loss: 2.248490850130717

Epoch: 6| Step: 6
Training loss: 0.9344556927680969
Validation loss: 2.2237873673439026

Epoch: 6| Step: 7
Training loss: 1.1419391632080078
Validation loss: 2.242946525414785

Epoch: 6| Step: 8
Training loss: 1.1387910842895508
Validation loss: 2.2623608907063804

Epoch: 6| Step: 9
Training loss: 1.1528300046920776
Validation loss: 2.251556177934011

Epoch: 6| Step: 10
Training loss: 1.3425425291061401
Validation loss: 2.2520319620768228

Epoch: 6| Step: 11
Training loss: 1.9623956680297852
Validation loss: 2.1989072958628335

Epoch: 6| Step: 12
Training loss: 0.809735894203186
Validation loss: 2.2443787654240928

Epoch: 6| Step: 13
Training loss: 2.027585983276367
Validation loss: 2.272004544734955

Epoch: 379| Step: 0
Training loss: 1.389479637145996
Validation loss: 2.232869545618693

Epoch: 6| Step: 1
Training loss: 0.9857903718948364
Validation loss: 2.206853210926056

Epoch: 6| Step: 2
Training loss: 1.1225612163543701
Validation loss: 2.1837754050890603

Epoch: 6| Step: 3
Training loss: 1.4148168563842773
Validation loss: 2.1760209798812866

Epoch: 6| Step: 4
Training loss: 1.0580703020095825
Validation loss: 2.1202199459075928

Epoch: 6| Step: 5
Training loss: 1.2558220624923706
Validation loss: 2.1264999508857727

Epoch: 6| Step: 6
Training loss: 1.2480552196502686
Validation loss: 2.1427773237228394

Epoch: 6| Step: 7
Training loss: 1.3376950025558472
Validation loss: 2.1480838457743325

Epoch: 6| Step: 8
Training loss: 2.1926403045654297
Validation loss: 2.1379850705464682

Epoch: 6| Step: 9
Training loss: 1.3977234363555908
Validation loss: 2.163515826066335

Epoch: 6| Step: 10
Training loss: 1.9699307680130005
Validation loss: 2.213922679424286

Epoch: 6| Step: 11
Training loss: 1.5091975927352905
Validation loss: 2.202404260635376

Epoch: 6| Step: 12
Training loss: 1.9654860496520996
Validation loss: 2.2103070418039956

Epoch: 6| Step: 13
Training loss: 1.503643274307251
Validation loss: 2.208820958932241

Epoch: 380| Step: 0
Training loss: 1.2781054973602295
Validation loss: 2.248923103014628

Epoch: 6| Step: 1
Training loss: 1.357780933380127
Validation loss: 2.2655699650446572

Epoch: 6| Step: 2
Training loss: 1.5562009811401367
Validation loss: 2.2545337677001953

Epoch: 6| Step: 3
Training loss: 1.2000377178192139
Validation loss: 2.2415020863215127

Epoch: 6| Step: 4
Training loss: 1.612870454788208
Validation loss: 2.2448580066363015

Epoch: 6| Step: 5
Training loss: 2.0232906341552734
Validation loss: 2.2506765127182007

Epoch: 6| Step: 6
Training loss: 1.3589451313018799
Validation loss: 2.2670344710350037

Epoch: 6| Step: 7
Training loss: 1.5421284437179565
Validation loss: 2.2878941893577576

Epoch: 6| Step: 8
Training loss: 0.9630001783370972
Validation loss: 2.3092445532480874

Epoch: 6| Step: 9
Training loss: 1.7255892753601074
Validation loss: 2.277867158253988

Epoch: 6| Step: 10
Training loss: 1.1851078271865845
Validation loss: 2.2830071250597634

Epoch: 6| Step: 11
Training loss: 1.404736042022705
Validation loss: 2.2632469137509665

Epoch: 6| Step: 12
Training loss: 1.2033941745758057
Validation loss: 2.2799218893051147

Epoch: 6| Step: 13
Training loss: 1.0074388980865479
Validation loss: 2.2914425134658813

Epoch: 381| Step: 0
Training loss: 1.7172777652740479
Validation loss: 2.290147602558136

Epoch: 6| Step: 1
Training loss: 1.6533520221710205
Validation loss: 2.28982013463974

Epoch: 6| Step: 2
Training loss: 1.2590290307998657
Validation loss: 2.2918866674105325

Epoch: 6| Step: 3
Training loss: 0.9106271266937256
Validation loss: 2.311759034792582

Epoch: 6| Step: 4
Training loss: 1.0051828622817993
Validation loss: 2.2734060287475586

Epoch: 6| Step: 5
Training loss: 1.8244140148162842
Validation loss: 2.2687890926996865

Epoch: 6| Step: 6
Training loss: 1.1351776123046875
Validation loss: 2.292086680730184

Epoch: 6| Step: 7
Training loss: 1.266991376876831
Validation loss: 2.285000999768575

Epoch: 6| Step: 8
Training loss: 1.9828059673309326
Validation loss: 2.302148699760437

Epoch: 6| Step: 9
Training loss: 1.3497518301010132
Validation loss: 2.295592725276947

Epoch: 6| Step: 10
Training loss: 0.9812983870506287
Validation loss: 2.279459615548452

Epoch: 6| Step: 11
Training loss: 1.235514521598816
Validation loss: 2.2284933725992837

Epoch: 6| Step: 12
Training loss: 0.7410886287689209
Validation loss: 2.281390110651652

Epoch: 6| Step: 13
Training loss: 0.8955241441726685
Validation loss: 2.2209985653559365

Epoch: 382| Step: 0
Training loss: 1.5693210363388062
Validation loss: 2.2563817501068115

Epoch: 6| Step: 1
Training loss: 1.3941819667816162
Validation loss: 2.2620918353398642

Epoch: 6| Step: 2
Training loss: 1.281078577041626
Validation loss: 2.2012043793996177

Epoch: 6| Step: 3
Training loss: 1.3409204483032227
Validation loss: 2.219364821910858

Epoch: 6| Step: 4
Training loss: 1.4380767345428467
Validation loss: 2.2199087738990784

Epoch: 6| Step: 5
Training loss: 0.7768968343734741
Validation loss: 2.2101757923762

Epoch: 6| Step: 6
Training loss: 0.9363027811050415
Validation loss: 2.1807397603988647

Epoch: 6| Step: 7
Training loss: 1.3814289569854736
Validation loss: 2.220526119073232

Epoch: 6| Step: 8
Training loss: 0.886366069316864
Validation loss: 2.2204742630322776

Epoch: 6| Step: 9
Training loss: 1.55255126953125
Validation loss: 2.2255048553148904

Epoch: 6| Step: 10
Training loss: 0.8820024728775024
Validation loss: 2.218688507874807

Epoch: 6| Step: 11
Training loss: 0.999679446220398
Validation loss: 2.218881825606028

Epoch: 6| Step: 12
Training loss: 1.6038774251937866
Validation loss: 2.2136257688204446

Epoch: 6| Step: 13
Training loss: 1.125795841217041
Validation loss: 2.262931684652964

Epoch: 383| Step: 0
Training loss: 0.8688147664070129
Validation loss: 2.2454205751419067

Epoch: 6| Step: 1
Training loss: 0.7698826789855957
Validation loss: 2.232634345690409

Epoch: 6| Step: 2
Training loss: 1.2903101444244385
Validation loss: 2.2249722480773926

Epoch: 6| Step: 3
Training loss: 1.3382666110992432
Validation loss: 2.2947476704915366

Epoch: 6| Step: 4
Training loss: 1.4454395771026611
Validation loss: 2.2841676076253257

Epoch: 6| Step: 5
Training loss: 1.8012077808380127
Validation loss: 2.2740708589553833

Epoch: 6| Step: 6
Training loss: 1.4782241582870483
Validation loss: 2.222167650858561

Epoch: 6| Step: 7
Training loss: 1.1682746410369873
Validation loss: 2.2811824679374695

Epoch: 6| Step: 8
Training loss: 0.6955963969230652
Validation loss: 2.243731697400411

Epoch: 6| Step: 9
Training loss: 1.0519942045211792
Validation loss: 2.2911630074183145

Epoch: 6| Step: 10
Training loss: 2.013327121734619
Validation loss: 2.23060135046641

Epoch: 6| Step: 11
Training loss: 0.5903810262680054
Validation loss: 2.2581698894500732

Epoch: 6| Step: 12
Training loss: 1.6307828426361084
Validation loss: 2.269617756207784

Epoch: 6| Step: 13
Training loss: 1.0107402801513672
Validation loss: 2.2669727206230164

Epoch: 384| Step: 0
Training loss: 1.4689686298370361
Validation loss: 2.282044529914856

Epoch: 6| Step: 1
Training loss: 0.444703608751297
Validation loss: 2.2591134309768677

Epoch: 6| Step: 2
Training loss: 0.6982994079589844
Validation loss: 2.287118673324585

Epoch: 6| Step: 3
Training loss: 1.4193227291107178
Validation loss: 2.2303093473116555

Epoch: 6| Step: 4
Training loss: 1.7251335382461548
Validation loss: 2.2666914065678916

Epoch: 6| Step: 5
Training loss: 1.565553903579712
Validation loss: 2.236729542414347

Epoch: 6| Step: 6
Training loss: 0.9103537201881409
Validation loss: 2.2703281243642173

Epoch: 6| Step: 7
Training loss: 1.0367000102996826
Validation loss: 2.2401559154192605

Epoch: 6| Step: 8
Training loss: 1.1871027946472168
Validation loss: 2.2298258741696677

Epoch: 6| Step: 9
Training loss: 1.0217931270599365
Validation loss: 2.2573169271151223

Epoch: 6| Step: 10
Training loss: 1.6040505170822144
Validation loss: 2.2737472653388977

Epoch: 6| Step: 11
Training loss: 1.4699198007583618
Validation loss: 2.291049142678579

Epoch: 6| Step: 12
Training loss: 1.3525075912475586
Validation loss: 2.2886727452278137

Epoch: 6| Step: 13
Training loss: 1.43692147731781
Validation loss: 2.30108908812205

Epoch: 385| Step: 0
Training loss: 1.068814992904663
Validation loss: 2.2581308484077454

Epoch: 6| Step: 1
Training loss: 1.3095694780349731
Validation loss: 2.2849881649017334

Epoch: 6| Step: 2
Training loss: 1.365189552307129
Validation loss: 2.2168893218040466

Epoch: 6| Step: 3
Training loss: 1.5177586078643799
Validation loss: 2.278794765472412

Epoch: 6| Step: 4
Training loss: 1.7265610694885254
Validation loss: 2.2397059202194214

Epoch: 6| Step: 5
Training loss: 1.049738883972168
Validation loss: 2.2343138655026755

Epoch: 6| Step: 6
Training loss: 0.8849513530731201
Validation loss: 2.257811983426412

Epoch: 6| Step: 7
Training loss: 1.1332268714904785
Validation loss: 2.2537617882092795

Epoch: 6| Step: 8
Training loss: 1.1192258596420288
Validation loss: 2.225150386492411

Epoch: 6| Step: 9
Training loss: 1.860854148864746
Validation loss: 2.259043057759603

Epoch: 6| Step: 10
Training loss: 1.6513762474060059
Validation loss: 2.2461949388186135

Epoch: 6| Step: 11
Training loss: 1.7445441484451294
Validation loss: 2.261414130528768

Epoch: 6| Step: 12
Training loss: 1.1520695686340332
Validation loss: 2.2713621258735657

Epoch: 6| Step: 13
Training loss: 0.8539405465126038
Validation loss: 2.270267923672994

Epoch: 386| Step: 0
Training loss: 1.3730193376541138
Validation loss: 2.2476737896601358

Epoch: 6| Step: 1
Training loss: 1.1899771690368652
Validation loss: 2.2622132102648416

Epoch: 6| Step: 2
Training loss: 1.0457600355148315
Validation loss: 2.2551182905832925

Epoch: 6| Step: 3
Training loss: 0.4597199559211731
Validation loss: 2.2698729435602822

Epoch: 6| Step: 4
Training loss: 1.8535568714141846
Validation loss: 2.2878931363423667

Epoch: 6| Step: 5
Training loss: 0.9913725852966309
Validation loss: 2.231122076511383

Epoch: 6| Step: 6
Training loss: 1.5322670936584473
Validation loss: 2.241113305091858

Epoch: 6| Step: 7
Training loss: 1.7305216789245605
Validation loss: 2.2430782318115234

Epoch: 6| Step: 8
Training loss: 1.4437029361724854
Validation loss: 2.2535893519719443

Epoch: 6| Step: 9
Training loss: 0.903586745262146
Validation loss: 2.2764035860697427

Epoch: 6| Step: 10
Training loss: 1.0648698806762695
Validation loss: 2.295196851094564

Epoch: 6| Step: 11
Training loss: 1.556400179862976
Validation loss: 2.313770810763041

Epoch: 6| Step: 12
Training loss: 1.0547294616699219
Validation loss: 2.286817987759908

Epoch: 6| Step: 13
Training loss: 1.1847786903381348
Validation loss: 2.3347067634264627

Epoch: 387| Step: 0
Training loss: 1.4339869022369385
Validation loss: 2.291014571984609

Epoch: 6| Step: 1
Training loss: 1.1105308532714844
Validation loss: 2.2987977067629495

Epoch: 6| Step: 2
Training loss: 1.93654203414917
Validation loss: 2.273643672466278

Epoch: 6| Step: 3
Training loss: 1.0904120206832886
Validation loss: 2.287186642487844

Epoch: 6| Step: 4
Training loss: 0.8694629073143005
Validation loss: 2.291553020477295

Epoch: 6| Step: 5
Training loss: 1.5016005039215088
Validation loss: 2.2905606031417847

Epoch: 6| Step: 6
Training loss: 1.133213758468628
Validation loss: 2.298677702744802

Epoch: 6| Step: 7
Training loss: 1.468254566192627
Validation loss: 2.297754486401876

Epoch: 6| Step: 8
Training loss: 1.0828161239624023
Validation loss: 2.253242572148641

Epoch: 6| Step: 9
Training loss: 1.240823745727539
Validation loss: 2.2484200398127236

Epoch: 6| Step: 10
Training loss: 0.8398463726043701
Validation loss: 2.259561816851298

Epoch: 6| Step: 11
Training loss: 1.5711408853530884
Validation loss: 2.2701878746350608

Epoch: 6| Step: 12
Training loss: 0.8140662312507629
Validation loss: 2.222570816675822

Epoch: 6| Step: 13
Training loss: 1.0204719305038452
Validation loss: 2.236708641052246

Epoch: 388| Step: 0
Training loss: 1.5113966464996338
Validation loss: 2.2862257957458496

Epoch: 6| Step: 1
Training loss: 0.9069108963012695
Validation loss: 2.218381106853485

Epoch: 6| Step: 2
Training loss: 0.9823548197746277
Validation loss: 2.2438466946283975

Epoch: 6| Step: 3
Training loss: 1.6040339469909668
Validation loss: 2.237844785054525

Epoch: 6| Step: 4
Training loss: 2.158557415008545
Validation loss: 2.245433032512665

Epoch: 6| Step: 5
Training loss: 0.9737989902496338
Validation loss: 2.2597883343696594

Epoch: 6| Step: 6
Training loss: 0.9327388405799866
Validation loss: 2.241133371988932

Epoch: 6| Step: 7
Training loss: 1.2433260679244995
Validation loss: 2.233629067738851

Epoch: 6| Step: 8
Training loss: 1.4427919387817383
Validation loss: 2.225005567073822

Epoch: 6| Step: 9
Training loss: 1.3507940769195557
Validation loss: 2.247791886329651

Epoch: 6| Step: 10
Training loss: 0.7516909837722778
Validation loss: 2.23072612285614

Epoch: 6| Step: 11
Training loss: 1.1431752443313599
Validation loss: 2.2229714393615723

Epoch: 6| Step: 12
Training loss: 1.4137238264083862
Validation loss: 2.23095174630483

Epoch: 6| Step: 13
Training loss: 1.1164472103118896
Validation loss: 2.220554828643799

Epoch: 389| Step: 0
Training loss: 0.7067089080810547
Validation loss: 2.240444839000702

Epoch: 6| Step: 1
Training loss: 1.5814908742904663
Validation loss: 2.2313721776008606

Epoch: 6| Step: 2
Training loss: 1.5296311378479004
Validation loss: 2.2463284134864807

Epoch: 6| Step: 3
Training loss: 0.7259849905967712
Validation loss: 2.275269548098246

Epoch: 6| Step: 4
Training loss: 2.4171643257141113
Validation loss: 2.2698081533114114

Epoch: 6| Step: 5
Training loss: 1.683743953704834
Validation loss: 2.2638428807258606

Epoch: 6| Step: 6
Training loss: 1.4400033950805664
Validation loss: 2.28772242863973

Epoch: 6| Step: 7
Training loss: 1.0687206983566284
Validation loss: 2.2646429936091104

Epoch: 6| Step: 8
Training loss: 1.7736692428588867
Validation loss: 2.1776709159215293

Epoch: 6| Step: 9
Training loss: 1.4952483177185059
Validation loss: 2.2141772707303367

Epoch: 6| Step: 10
Training loss: 0.9500646591186523
Validation loss: 2.2336551348368325

Epoch: 6| Step: 11
Training loss: 1.1624644994735718
Validation loss: 2.251793404420217

Epoch: 6| Step: 12
Training loss: 1.5068389177322388
Validation loss: 2.257459024588267

Epoch: 6| Step: 13
Training loss: 0.6770732998847961
Validation loss: 2.2548035184542337

Epoch: 390| Step: 0
Training loss: 1.564220905303955
Validation loss: 2.265004833539327

Epoch: 6| Step: 1
Training loss: 0.939130961894989
Validation loss: 2.234393835067749

Epoch: 6| Step: 2
Training loss: 1.318331003189087
Validation loss: 2.238542397816976

Epoch: 6| Step: 3
Training loss: 0.7880848050117493
Validation loss: 2.2211740811665854

Epoch: 6| Step: 4
Training loss: 2.026165723800659
Validation loss: 2.2049742937088013

Epoch: 6| Step: 5
Training loss: 0.6757239103317261
Validation loss: 2.2384265859921775

Epoch: 6| Step: 6
Training loss: 1.6546880006790161
Validation loss: 2.2214643557866416

Epoch: 6| Step: 7
Training loss: 0.9884915351867676
Validation loss: 2.204910635948181

Epoch: 6| Step: 8
Training loss: 1.0482988357543945
Validation loss: 2.2216260035832724

Epoch: 6| Step: 9
Training loss: 0.41791418194770813
Validation loss: 2.221478223800659

Epoch: 6| Step: 10
Training loss: 1.191826343536377
Validation loss: 2.210826794306437

Epoch: 6| Step: 11
Training loss: 1.7474873065948486
Validation loss: 2.2377857168515525

Epoch: 6| Step: 12
Training loss: 1.5212254524230957
Validation loss: 2.239694913228353

Epoch: 6| Step: 13
Training loss: 0.8592096567153931
Validation loss: 2.2767618695894876

Epoch: 391| Step: 0
Training loss: 0.9599856734275818
Validation loss: 2.2267388105392456

Epoch: 6| Step: 1
Training loss: 1.8242870569229126
Validation loss: 2.2497387727101645

Epoch: 6| Step: 2
Training loss: 1.0358951091766357
Validation loss: 2.248252809047699

Epoch: 6| Step: 3
Training loss: 1.0190188884735107
Validation loss: 2.2874006231625876

Epoch: 6| Step: 4
Training loss: 1.0011149644851685
Validation loss: 2.2917282581329346

Epoch: 6| Step: 5
Training loss: 1.4079453945159912
Validation loss: 2.290466050306956

Epoch: 6| Step: 6
Training loss: 1.352168321609497
Validation loss: 2.287506858507792

Epoch: 6| Step: 7
Training loss: 0.7454520463943481
Validation loss: 2.2981602549552917

Epoch: 6| Step: 8
Training loss: 1.4462519884109497
Validation loss: 2.2756892244021096

Epoch: 6| Step: 9
Training loss: 1.7397432327270508
Validation loss: 2.276552756627401

Epoch: 6| Step: 10
Training loss: 1.9829779863357544
Validation loss: 2.2924762765566506

Epoch: 6| Step: 11
Training loss: 1.1384031772613525
Validation loss: 2.2625295321146646

Epoch: 6| Step: 12
Training loss: 0.5071375370025635
Validation loss: 2.2647955417633057

Epoch: 6| Step: 13
Training loss: 0.6523760557174683
Validation loss: 2.299217939376831

Epoch: 392| Step: 0
Training loss: 0.709635317325592
Validation loss: 2.271023154258728

Epoch: 6| Step: 1
Training loss: 1.3338210582733154
Validation loss: 2.261356016000112

Epoch: 6| Step: 2
Training loss: 1.3752394914627075
Validation loss: 2.2814977963765464

Epoch: 6| Step: 3
Training loss: 1.0620334148406982
Validation loss: 2.2592779994010925

Epoch: 6| Step: 4
Training loss: 1.1503657102584839
Validation loss: 2.28164271513621

Epoch: 6| Step: 5
Training loss: 0.4904981255531311
Validation loss: 2.2791889707247415

Epoch: 6| Step: 6
Training loss: 1.3469212055206299
Validation loss: 2.2698097825050354

Epoch: 6| Step: 7
Training loss: 1.131954550743103
Validation loss: 2.2829939126968384

Epoch: 6| Step: 8
Training loss: 0.8715322017669678
Validation loss: 2.2845638593037925

Epoch: 6| Step: 9
Training loss: 1.3550465106964111
Validation loss: 2.2827033400535583

Epoch: 6| Step: 10
Training loss: 1.6419508457183838
Validation loss: 2.2635252873102822

Epoch: 6| Step: 11
Training loss: 0.9651641845703125
Validation loss: 2.27569709221522

Epoch: 6| Step: 12
Training loss: 1.3010683059692383
Validation loss: 2.2736177245775857

Epoch: 6| Step: 13
Training loss: 1.5824708938598633
Validation loss: 2.3144125938415527

Epoch: 393| Step: 0
Training loss: 1.240925669670105
Validation loss: 2.312368313471476

Epoch: 6| Step: 1
Training loss: 1.0743076801300049
Validation loss: 2.2939815123875937

Epoch: 6| Step: 2
Training loss: 1.5477246046066284
Validation loss: 2.2925482392311096

Epoch: 6| Step: 3
Training loss: 1.2681032419204712
Validation loss: 2.2985677321751914

Epoch: 6| Step: 4
Training loss: 0.7640795707702637
Validation loss: 2.285109758377075

Epoch: 6| Step: 5
Training loss: 1.0621784925460815
Validation loss: 2.252951959768931

Epoch: 6| Step: 6
Training loss: 0.978973925113678
Validation loss: 2.2748491168022156

Epoch: 6| Step: 7
Training loss: 1.4450633525848389
Validation loss: 2.272380610307058

Epoch: 6| Step: 8
Training loss: 1.104536771774292
Validation loss: 2.2422777811686196

Epoch: 6| Step: 9
Training loss: 0.7270146608352661
Validation loss: 2.227575103441874

Epoch: 6| Step: 10
Training loss: 1.0599522590637207
Validation loss: 2.266020178794861

Epoch: 6| Step: 11
Training loss: 1.5383827686309814
Validation loss: 2.211196939150492

Epoch: 6| Step: 12
Training loss: 1.1940252780914307
Validation loss: 2.211042821407318

Epoch: 6| Step: 13
Training loss: 1.6089270114898682
Validation loss: 2.232925295829773

Epoch: 394| Step: 0
Training loss: 0.8532769680023193
Validation loss: 2.2494415442148843

Epoch: 6| Step: 1
Training loss: 1.181566596031189
Validation loss: 2.2182792027791343

Epoch: 6| Step: 2
Training loss: 1.6863141059875488
Validation loss: 2.2078500390052795

Epoch: 6| Step: 3
Training loss: 1.174102544784546
Validation loss: 2.207403520743052

Epoch: 6| Step: 4
Training loss: 1.2686456441879272
Validation loss: 2.259975790977478

Epoch: 6| Step: 5
Training loss: 1.2355281114578247
Validation loss: 2.2131515542666116

Epoch: 6| Step: 6
Training loss: 0.7029179334640503
Validation loss: 2.221705655256907

Epoch: 6| Step: 7
Training loss: 0.9912127256393433
Validation loss: 2.231329401334127

Epoch: 6| Step: 8
Training loss: 0.7321637868881226
Validation loss: 2.224975903828939

Epoch: 6| Step: 9
Training loss: 1.1841604709625244
Validation loss: 2.254752735296885

Epoch: 6| Step: 10
Training loss: 0.9851289987564087
Validation loss: 2.2116831143697104

Epoch: 6| Step: 11
Training loss: 2.4749886989593506
Validation loss: 2.261148691177368

Epoch: 6| Step: 12
Training loss: 0.8808940052986145
Validation loss: 2.2349882324536643

Epoch: 6| Step: 13
Training loss: 0.8163843154907227
Validation loss: 2.2734899123509726

Epoch: 395| Step: 0
Training loss: 1.4600088596343994
Validation loss: 2.210563004016876

Epoch: 6| Step: 1
Training loss: 1.1604722738265991
Validation loss: 2.241091469923655

Epoch: 6| Step: 2
Training loss: 1.5827586650848389
Validation loss: 2.2820843855539956

Epoch: 6| Step: 3
Training loss: 0.9511234164237976
Validation loss: 2.293719450632731

Epoch: 6| Step: 4
Training loss: 1.1464178562164307
Validation loss: 2.298813303311666

Epoch: 6| Step: 5
Training loss: 1.0785465240478516
Validation loss: 2.2514151334762573

Epoch: 6| Step: 6
Training loss: 1.3010870218276978
Validation loss: 2.2277103861172995

Epoch: 6| Step: 7
Training loss: 0.9726861119270325
Validation loss: 2.2457943757375083

Epoch: 6| Step: 8
Training loss: 1.1578896045684814
Validation loss: 2.278607507546743

Epoch: 6| Step: 9
Training loss: 0.9802814722061157
Validation loss: 2.310777703921

Epoch: 6| Step: 10
Training loss: 1.5664559602737427
Validation loss: 2.270351151625315

Epoch: 6| Step: 11
Training loss: 1.2378506660461426
Validation loss: 2.2957242528597512

Epoch: 6| Step: 12
Training loss: 0.7699041366577148
Validation loss: 2.3059505025545755

Epoch: 6| Step: 13
Training loss: 1.5070874691009521
Validation loss: 2.2697817285855613

Epoch: 396| Step: 0
Training loss: 1.6992604732513428
Validation loss: 2.2713545163472495

Epoch: 6| Step: 1
Training loss: 0.7170119285583496
Validation loss: 2.269599755605062

Epoch: 6| Step: 2
Training loss: 1.233583688735962
Validation loss: 2.2864280541737876

Epoch: 6| Step: 3
Training loss: 0.8822214603424072
Validation loss: 2.2587098677953086

Epoch: 6| Step: 4
Training loss: 1.3569090366363525
Validation loss: 2.271285037199656

Epoch: 6| Step: 5
Training loss: 1.17842435836792
Validation loss: 2.249088943004608

Epoch: 6| Step: 6
Training loss: 1.0498679876327515
Validation loss: 2.300960958003998

Epoch: 6| Step: 7
Training loss: 1.337688684463501
Validation loss: 2.2641318241755166

Epoch: 6| Step: 8
Training loss: 1.0107851028442383
Validation loss: 2.2799137036005654

Epoch: 6| Step: 9
Training loss: 1.2481436729431152
Validation loss: 2.2638567686080933

Epoch: 6| Step: 10
Training loss: 1.3658459186553955
Validation loss: 2.2501225670178733

Epoch: 6| Step: 11
Training loss: 1.0414140224456787
Validation loss: 2.275337735811869

Epoch: 6| Step: 12
Training loss: 1.010276436805725
Validation loss: 2.3001139958699546

Epoch: 6| Step: 13
Training loss: 1.4579668045043945
Validation loss: 2.276790897051493

Epoch: 397| Step: 0
Training loss: 0.8504682779312134
Validation loss: 2.277930279572805

Epoch: 6| Step: 1
Training loss: 1.2762928009033203
Validation loss: 2.2520357370376587

Epoch: 6| Step: 2
Training loss: 1.0361946821212769
Validation loss: 2.2749997973442078

Epoch: 6| Step: 3
Training loss: 0.9855790138244629
Validation loss: 2.235055764516195

Epoch: 6| Step: 4
Training loss: 0.6844260096549988
Validation loss: 2.273613393306732

Epoch: 6| Step: 5
Training loss: 1.6482679843902588
Validation loss: 2.287864545981089

Epoch: 6| Step: 6
Training loss: 1.5305719375610352
Validation loss: 2.3142678340276084

Epoch: 6| Step: 7
Training loss: 1.1856499910354614
Validation loss: 2.273469010988871

Epoch: 6| Step: 8
Training loss: 1.1487458944320679
Validation loss: 2.3069719274838767

Epoch: 6| Step: 9
Training loss: 1.8908988237380981
Validation loss: 2.310888727506002

Epoch: 6| Step: 10
Training loss: 1.098128080368042
Validation loss: 2.280679623285929

Epoch: 6| Step: 11
Training loss: 1.1557793617248535
Validation loss: 2.279276112715403

Epoch: 6| Step: 12
Training loss: 1.1487445831298828
Validation loss: 2.2616031964619956

Epoch: 6| Step: 13
Training loss: 1.208319067955017
Validation loss: 2.2540255188941956

Epoch: 398| Step: 0
Training loss: 1.1731213331222534
Validation loss: 2.238890767097473

Epoch: 6| Step: 1
Training loss: 1.3854812383651733
Validation loss: 2.2486841281255088

Epoch: 6| Step: 2
Training loss: 1.2101528644561768
Validation loss: 2.2435280879338584

Epoch: 6| Step: 3
Training loss: 0.9593167304992676
Validation loss: 2.2237688501675925

Epoch: 6| Step: 4
Training loss: 1.4681963920593262
Validation loss: 2.2585548559824624

Epoch: 6| Step: 5
Training loss: 1.1874985694885254
Validation loss: 2.2574309706687927

Epoch: 6| Step: 6
Training loss: 1.5410246849060059
Validation loss: 2.3019259174664817

Epoch: 6| Step: 7
Training loss: 1.1157728433609009
Validation loss: 2.2764694492022195

Epoch: 6| Step: 8
Training loss: 0.892328143119812
Validation loss: 2.2697472174962363

Epoch: 6| Step: 9
Training loss: 1.2070804834365845
Validation loss: 2.264245410760244

Epoch: 6| Step: 10
Training loss: 1.1322119235992432
Validation loss: 2.251025835673014

Epoch: 6| Step: 11
Training loss: 1.7021297216415405
Validation loss: 2.259575883547465

Epoch: 6| Step: 12
Training loss: 0.5333099365234375
Validation loss: 2.225501855214437

Epoch: 6| Step: 13
Training loss: 1.208292007446289
Validation loss: 2.231837888558706

Epoch: 399| Step: 0
Training loss: 1.0415518283843994
Validation loss: 2.200039585431417

Epoch: 6| Step: 1
Training loss: 1.1105005741119385
Validation loss: 2.2362489898999534

Epoch: 6| Step: 2
Training loss: 0.9186748266220093
Validation loss: 2.2487924893697104

Epoch: 6| Step: 3
Training loss: 0.8503643274307251
Validation loss: 2.235811471939087

Epoch: 6| Step: 4
Training loss: 0.6519268751144409
Validation loss: 2.2665191094080606

Epoch: 6| Step: 5
Training loss: 1.670912504196167
Validation loss: 2.291807234287262

Epoch: 6| Step: 6
Training loss: 1.0251935720443726
Validation loss: 2.249917527039846

Epoch: 6| Step: 7
Training loss: 1.4035460948944092
Validation loss: 2.291050136089325

Epoch: 6| Step: 8
Training loss: 1.3908469676971436
Validation loss: 2.271800994873047

Epoch: 6| Step: 9
Training loss: 0.898291826248169
Validation loss: 2.2920982042948403

Epoch: 6| Step: 10
Training loss: 1.5592446327209473
Validation loss: 2.2183698813120523

Epoch: 6| Step: 11
Training loss: 1.4021350145339966
Validation loss: 2.2519675294558206

Epoch: 6| Step: 12
Training loss: 1.2462339401245117
Validation loss: 2.2950869599978128

Epoch: 6| Step: 13
Training loss: 1.714545488357544
Validation loss: 2.244916319847107

Epoch: 400| Step: 0
Training loss: 1.0181759595870972
Validation loss: 2.3088093400001526

Epoch: 6| Step: 1
Training loss: 1.2119977474212646
Validation loss: 2.248118241628011

Epoch: 6| Step: 2
Training loss: 1.7774183750152588
Validation loss: 2.23201451698939

Epoch: 6| Step: 3
Training loss: 0.9798578023910522
Validation loss: 2.2185909748077393

Epoch: 6| Step: 4
Training loss: 1.5567641258239746
Validation loss: 2.237030486265818

Epoch: 6| Step: 5
Training loss: 0.9515905380249023
Validation loss: 2.2290889024734497

Epoch: 6| Step: 6
Training loss: 0.7768211364746094
Validation loss: 2.1929216782251992

Epoch: 6| Step: 7
Training loss: 1.6071197986602783
Validation loss: 2.2312541007995605

Epoch: 6| Step: 8
Training loss: 2.1815123558044434
Validation loss: 2.219069560368856

Epoch: 6| Step: 9
Training loss: 1.9914045333862305
Validation loss: 2.220374584197998

Epoch: 6| Step: 10
Training loss: 1.375632882118225
Validation loss: 2.2267730037371316

Epoch: 6| Step: 11
Training loss: 0.8124377727508545
Validation loss: 2.2346920172373452

Epoch: 6| Step: 12
Training loss: 0.9055427312850952
Validation loss: 2.2466860810915628

Epoch: 6| Step: 13
Training loss: 1.1687809228897095
Validation loss: 2.2395746310551963

Epoch: 401| Step: 0
Training loss: 1.106505274772644
Validation loss: 2.2226915756861367

Epoch: 6| Step: 1
Training loss: 1.5222303867340088
Validation loss: 2.224682847658793

Epoch: 6| Step: 2
Training loss: 0.8743512630462646
Validation loss: 2.2195990284283957

Epoch: 6| Step: 3
Training loss: 0.7350326180458069
Validation loss: 2.2337693770726523

Epoch: 6| Step: 4
Training loss: 0.8637665510177612
Validation loss: 2.272066911061605

Epoch: 6| Step: 5
Training loss: 1.2368342876434326
Validation loss: 2.2861530780792236

Epoch: 6| Step: 6
Training loss: 2.0225915908813477
Validation loss: 2.2843826611836753

Epoch: 6| Step: 7
Training loss: 1.4250720739364624
Validation loss: 2.3124579191207886

Epoch: 6| Step: 8
Training loss: 0.6120877861976624
Validation loss: 2.3314784169197083

Epoch: 6| Step: 9
Training loss: 1.4513496160507202
Validation loss: 2.3238771756490073

Epoch: 6| Step: 10
Training loss: 2.341923236846924
Validation loss: 2.2866702477137246

Epoch: 6| Step: 11
Training loss: 0.8912488222122192
Validation loss: 2.2982928355534873

Epoch: 6| Step: 12
Training loss: 1.3329485654830933
Validation loss: 2.2994783322016397

Epoch: 6| Step: 13
Training loss: 0.8895406126976013
Validation loss: 2.3375948866208396

Epoch: 402| Step: 0
Training loss: 1.523654818534851
Validation loss: 2.2976456681887307

Epoch: 6| Step: 1
Training loss: 1.4971742630004883
Validation loss: 2.3065541982650757

Epoch: 6| Step: 2
Training loss: 1.3786461353302002
Validation loss: 2.3100886146227517

Epoch: 6| Step: 3
Training loss: 0.6521559953689575
Validation loss: 2.2925606767336526

Epoch: 6| Step: 4
Training loss: 1.2853937149047852
Validation loss: 2.2958767811457315

Epoch: 6| Step: 5
Training loss: 1.1131255626678467
Validation loss: 2.2644495169321694

Epoch: 6| Step: 6
Training loss: 1.0678030252456665
Validation loss: 2.1893600622812905

Epoch: 6| Step: 7
Training loss: 1.0739071369171143
Validation loss: 2.20675661166509

Epoch: 6| Step: 8
Training loss: 0.7964618802070618
Validation loss: 2.2531681060791016

Epoch: 6| Step: 9
Training loss: 1.4649813175201416
Validation loss: 2.299301822980245

Epoch: 6| Step: 10
Training loss: 1.038088321685791
Validation loss: 2.2882086833318076

Epoch: 6| Step: 11
Training loss: 0.6464996337890625
Validation loss: 2.273884415626526

Epoch: 6| Step: 12
Training loss: 1.030361533164978
Validation loss: 2.2683099110921225

Epoch: 6| Step: 13
Training loss: 1.6181585788726807
Validation loss: 2.25328661998113

Epoch: 403| Step: 0
Training loss: 1.1752780675888062
Validation loss: 2.2710513869921365

Epoch: 6| Step: 1
Training loss: 0.9441084861755371
Validation loss: 2.2236112356185913

Epoch: 6| Step: 2
Training loss: 0.8426626920700073
Validation loss: 2.2692842284838357

Epoch: 6| Step: 3
Training loss: 1.5395474433898926
Validation loss: 2.245324512322744

Epoch: 6| Step: 4
Training loss: 0.8869898319244385
Validation loss: 2.2161078651746116

Epoch: 6| Step: 5
Training loss: 0.8513340950012207
Validation loss: 2.273479183514913

Epoch: 6| Step: 6
Training loss: 1.973819375038147
Validation loss: 2.22729762395223

Epoch: 6| Step: 7
Training loss: 0.8084242343902588
Validation loss: 2.2391082445780435

Epoch: 6| Step: 8
Training loss: 0.8824859857559204
Validation loss: 2.2323732376098633

Epoch: 6| Step: 9
Training loss: 1.238579511642456
Validation loss: 2.2409340143203735

Epoch: 6| Step: 10
Training loss: 1.4105920791625977
Validation loss: 2.26356569925944

Epoch: 6| Step: 11
Training loss: 1.0963001251220703
Validation loss: 2.2567408084869385

Epoch: 6| Step: 12
Training loss: 1.593178391456604
Validation loss: 2.283417840798696

Epoch: 6| Step: 13
Training loss: 1.6174037456512451
Validation loss: 2.3228556911150613

Epoch: 404| Step: 0
Training loss: 0.7831132411956787
Validation loss: 2.2336907188097634

Epoch: 6| Step: 1
Training loss: 1.5591022968292236
Validation loss: 2.2195993661880493

Epoch: 6| Step: 2
Training loss: 2.0057077407836914
Validation loss: 2.2640347878138223

Epoch: 6| Step: 3
Training loss: 1.0111335515975952
Validation loss: 2.1971896489461265

Epoch: 6| Step: 4
Training loss: 0.7236482501029968
Validation loss: 2.2273703614870706

Epoch: 6| Step: 5
Training loss: 1.297213077545166
Validation loss: 2.2572723229726157

Epoch: 6| Step: 6
Training loss: 1.6099737882614136
Validation loss: 2.2915927171707153

Epoch: 6| Step: 7
Training loss: 1.4065980911254883
Validation loss: 2.268611510594686

Epoch: 6| Step: 8
Training loss: 1.1453958749771118
Validation loss: 2.2200331687927246

Epoch: 6| Step: 9
Training loss: 1.0113465785980225
Validation loss: 2.2448706229527793

Epoch: 6| Step: 10
Training loss: 0.837626039981842
Validation loss: 2.227673888206482

Epoch: 6| Step: 11
Training loss: 0.9705811142921448
Validation loss: 2.258259971936544

Epoch: 6| Step: 12
Training loss: 0.7606035470962524
Validation loss: 2.223593552907308

Epoch: 6| Step: 13
Training loss: 1.0322521924972534
Validation loss: 2.264338513215383

Epoch: 405| Step: 0
Training loss: 0.8136985301971436
Validation loss: 2.2757954597473145

Epoch: 6| Step: 1
Training loss: 0.9227371215820312
Validation loss: 2.195244610309601

Epoch: 6| Step: 2
Training loss: 1.2640912532806396
Validation loss: 2.2220404942830405

Epoch: 6| Step: 3
Training loss: 1.350733995437622
Validation loss: 2.233906110127767

Epoch: 6| Step: 4
Training loss: 0.6167775392532349
Validation loss: 2.210449735323588

Epoch: 6| Step: 5
Training loss: 1.2954379320144653
Validation loss: 2.2332912484804788

Epoch: 6| Step: 6
Training loss: 1.547092318534851
Validation loss: 2.1929433743158975

Epoch: 6| Step: 7
Training loss: 0.9601351022720337
Validation loss: 2.2287747065226235

Epoch: 6| Step: 8
Training loss: 1.2199774980545044
Validation loss: 2.2583141326904297

Epoch: 6| Step: 9
Training loss: 1.645590901374817
Validation loss: 2.3081035216649375

Epoch: 6| Step: 10
Training loss: 1.03041672706604
Validation loss: 2.2346827189127603

Epoch: 6| Step: 11
Training loss: 1.005954623222351
Validation loss: 2.223310351371765

Epoch: 6| Step: 12
Training loss: 0.8544132709503174
Validation loss: 2.246431291103363

Epoch: 6| Step: 13
Training loss: 1.4680368900299072
Validation loss: 2.205287973086039

Epoch: 406| Step: 0
Training loss: 1.174492359161377
Validation loss: 2.218836506207784

Epoch: 6| Step: 1
Training loss: 1.3315752744674683
Validation loss: 2.2459044059117637

Epoch: 6| Step: 2
Training loss: 0.867171049118042
Validation loss: 2.238718787829081

Epoch: 6| Step: 3
Training loss: 0.8243471384048462
Validation loss: 2.240566531817118

Epoch: 6| Step: 4
Training loss: 1.210401177406311
Validation loss: 2.249147613843282

Epoch: 6| Step: 5
Training loss: 0.5832752585411072
Validation loss: 2.232680916786194

Epoch: 6| Step: 6
Training loss: 1.3821349143981934
Validation loss: 2.2214257518450418

Epoch: 6| Step: 7
Training loss: 1.764736533164978
Validation loss: 2.283883015314738

Epoch: 6| Step: 8
Training loss: 1.0062026977539062
Validation loss: 2.2566349307696023

Epoch: 6| Step: 9
Training loss: 1.2221729755401611
Validation loss: 2.2711390256881714

Epoch: 6| Step: 10
Training loss: 1.4259896278381348
Validation loss: 2.2455376784006753

Epoch: 6| Step: 11
Training loss: 1.2119333744049072
Validation loss: 2.240540603796641

Epoch: 6| Step: 12
Training loss: 0.6831034421920776
Validation loss: 2.283537288506826

Epoch: 6| Step: 13
Training loss: 1.2284724712371826
Validation loss: 2.25805934270223

Epoch: 407| Step: 0
Training loss: 1.2750362157821655
Validation loss: 2.246326466401418

Epoch: 6| Step: 1
Training loss: 1.1688692569732666
Validation loss: 2.308378020922343

Epoch: 6| Step: 2
Training loss: 0.900261402130127
Validation loss: 2.2737417618433633

Epoch: 6| Step: 3
Training loss: 0.9788122773170471
Validation loss: 2.234523514906565

Epoch: 6| Step: 4
Training loss: 0.708286464214325
Validation loss: 2.2378438115119934

Epoch: 6| Step: 5
Training loss: 0.7441160678863525
Validation loss: 2.2489925622940063

Epoch: 6| Step: 6
Training loss: 1.1020958423614502
Validation loss: 2.2359206875165305

Epoch: 6| Step: 7
Training loss: 1.373030662536621
Validation loss: 2.278925577799479

Epoch: 6| Step: 8
Training loss: 1.2388218641281128
Validation loss: 2.279732803503672

Epoch: 6| Step: 9
Training loss: 0.8172269463539124
Validation loss: 2.2577460010846457

Epoch: 6| Step: 10
Training loss: 0.7621022462844849
Validation loss: 2.263213316599528

Epoch: 6| Step: 11
Training loss: 1.4575577974319458
Validation loss: 2.27010444800059

Epoch: 6| Step: 12
Training loss: 1.8967682123184204
Validation loss: 2.2728175123532615

Epoch: 6| Step: 13
Training loss: 0.922599196434021
Validation loss: 2.3160769939422607

Epoch: 408| Step: 0
Training loss: 1.1494159698486328
Validation loss: 2.282367706298828

Epoch: 6| Step: 1
Training loss: 1.5798437595367432
Validation loss: 2.259911676247915

Epoch: 6| Step: 2
Training loss: 0.5220871567726135
Validation loss: 2.280583361784617

Epoch: 6| Step: 3
Training loss: 1.1008015871047974
Validation loss: 2.2160184582074485

Epoch: 6| Step: 4
Training loss: 0.9470436573028564
Validation loss: 2.280790388584137

Epoch: 6| Step: 5
Training loss: 1.2778137922286987
Validation loss: 2.309059262275696

Epoch: 6| Step: 6
Training loss: 0.7443419694900513
Validation loss: 2.2813977003097534

Epoch: 6| Step: 7
Training loss: 1.1147799491882324
Validation loss: 2.2563175559043884

Epoch: 6| Step: 8
Training loss: 0.7877568006515503
Validation loss: 2.2246262431144714

Epoch: 6| Step: 9
Training loss: 1.0395396947860718
Validation loss: 2.1891557772954306

Epoch: 6| Step: 10
Training loss: 0.9948743581771851
Validation loss: 2.2814969023068747

Epoch: 6| Step: 11
Training loss: 1.3235338926315308
Validation loss: 2.294641931851705

Epoch: 6| Step: 12
Training loss: 1.9523890018463135
Validation loss: 2.3007285594940186

Epoch: 6| Step: 13
Training loss: 1.1729457378387451
Validation loss: 2.2514405250549316

Epoch: 409| Step: 0
Training loss: 1.233075737953186
Validation loss: 2.2725361982981362

Epoch: 6| Step: 1
Training loss: 1.5325019359588623
Validation loss: 2.24855774641037

Epoch: 6| Step: 2
Training loss: 1.1209014654159546
Validation loss: 2.229248841603597

Epoch: 6| Step: 3
Training loss: 1.7215492725372314
Validation loss: 2.2432960271835327

Epoch: 6| Step: 4
Training loss: 1.2950706481933594
Validation loss: 2.2661552826563516

Epoch: 6| Step: 5
Training loss: 1.4998193979263306
Validation loss: 2.227997283140818

Epoch: 6| Step: 6
Training loss: 0.6632338166236877
Validation loss: 2.2503013213475547

Epoch: 6| Step: 7
Training loss: 0.7929373383522034
Validation loss: 2.2626970410346985

Epoch: 6| Step: 8
Training loss: 1.029057264328003
Validation loss: 2.267265796661377

Epoch: 6| Step: 9
Training loss: 1.25640869140625
Validation loss: 2.2790093421936035

Epoch: 6| Step: 10
Training loss: 1.0796486139297485
Validation loss: 2.2672215898831687

Epoch: 6| Step: 11
Training loss: 1.0069348812103271
Validation loss: 2.2907976706822715

Epoch: 6| Step: 12
Training loss: 0.8364316821098328
Validation loss: 2.29775998989741

Epoch: 6| Step: 13
Training loss: 1.13502836227417
Validation loss: 2.2418773571650186

Epoch: 410| Step: 0
Training loss: 0.8638058304786682
Validation loss: 2.2288382053375244

Epoch: 6| Step: 1
Training loss: 1.1784472465515137
Validation loss: 2.2675843238830566

Epoch: 6| Step: 2
Training loss: 0.8426179885864258
Validation loss: 2.2540312012036643

Epoch: 6| Step: 3
Training loss: 1.0899989604949951
Validation loss: 2.2203814586003623

Epoch: 6| Step: 4
Training loss: 1.0091828107833862
Validation loss: 2.1932118932406106

Epoch: 6| Step: 5
Training loss: 0.8906697034835815
Validation loss: 2.245665887991587

Epoch: 6| Step: 6
Training loss: 1.3333417177200317
Validation loss: 2.228821953137716

Epoch: 6| Step: 7
Training loss: 1.0158718824386597
Validation loss: 2.262385924657186

Epoch: 6| Step: 8
Training loss: 1.5268220901489258
Validation loss: 2.2562005718549094

Epoch: 6| Step: 9
Training loss: 1.0874600410461426
Validation loss: 2.272041837374369

Epoch: 6| Step: 10
Training loss: 1.6119368076324463
Validation loss: 2.2339749733606973

Epoch: 6| Step: 11
Training loss: 0.6193146109580994
Validation loss: 2.2353862524032593

Epoch: 6| Step: 12
Training loss: 1.6296367645263672
Validation loss: 2.1900425950686135

Epoch: 6| Step: 13
Training loss: 0.6990410685539246
Validation loss: 2.270478109518687

Epoch: 411| Step: 0
Training loss: 0.822840690612793
Validation loss: 2.2339754700660706

Epoch: 6| Step: 1
Training loss: 0.9959636926651001
Validation loss: 2.206131180127462

Epoch: 6| Step: 2
Training loss: 1.6986596584320068
Validation loss: 2.2758538524309793

Epoch: 6| Step: 3
Training loss: 1.306725025177002
Validation loss: 2.2430496215820312

Epoch: 6| Step: 4
Training loss: 0.9678624868392944
Validation loss: 2.2351750334103904

Epoch: 6| Step: 5
Training loss: 1.8068463802337646
Validation loss: 2.2941779494285583

Epoch: 6| Step: 6
Training loss: 1.3406020402908325
Validation loss: 2.3106950322786965

Epoch: 6| Step: 7
Training loss: 1.6180217266082764
Validation loss: 2.3648162484169006

Epoch: 6| Step: 8
Training loss: 1.844341516494751
Validation loss: 2.375857949256897

Epoch: 6| Step: 9
Training loss: 1.194986343383789
Validation loss: 2.3779099186261496

Epoch: 6| Step: 10
Training loss: 1.4776561260223389
Validation loss: 2.347141663233439

Epoch: 6| Step: 11
Training loss: 1.1480529308319092
Validation loss: 2.32162352403005

Epoch: 6| Step: 12
Training loss: 0.6515393853187561
Validation loss: 2.305374483267466

Epoch: 6| Step: 13
Training loss: 0.9459861516952515
Validation loss: 2.261053125063578

Epoch: 412| Step: 0
Training loss: 1.0538235902786255
Validation loss: 2.3138774037361145

Epoch: 6| Step: 1
Training loss: 1.410478115081787
Validation loss: 2.3286966482798257

Epoch: 6| Step: 2
Training loss: 1.1744223833084106
Validation loss: 2.311309536298116

Epoch: 6| Step: 3
Training loss: 1.6511759757995605
Validation loss: 2.3027740319569907

Epoch: 6| Step: 4
Training loss: 1.2364764213562012
Validation loss: 2.3461325565973916

Epoch: 6| Step: 5
Training loss: 1.1797491312026978
Validation loss: 2.3349705139795938

Epoch: 6| Step: 6
Training loss: 1.748481273651123
Validation loss: 2.259265919526418

Epoch: 6| Step: 7
Training loss: 1.415287971496582
Validation loss: 2.204400440057119

Epoch: 6| Step: 8
Training loss: 1.046433925628662
Validation loss: 2.2870711286862693

Epoch: 6| Step: 9
Training loss: 1.0422298908233643
Validation loss: 2.248863697052002

Epoch: 6| Step: 10
Training loss: 1.1983129978179932
Validation loss: 2.2777329285939536

Epoch: 6| Step: 11
Training loss: 0.8116337060928345
Validation loss: 2.293895681699117

Epoch: 6| Step: 12
Training loss: 1.380167841911316
Validation loss: 2.293546517690023

Epoch: 6| Step: 13
Training loss: 0.3960808515548706
Validation loss: 2.2922786672910056

Epoch: 413| Step: 0
Training loss: 0.940116822719574
Validation loss: 2.253564973672231

Epoch: 6| Step: 1
Training loss: 1.4827011823654175
Validation loss: 2.2501497666041055

Epoch: 6| Step: 2
Training loss: 0.9690223932266235
Validation loss: 2.238358279069265

Epoch: 6| Step: 3
Training loss: 1.192922592163086
Validation loss: 2.2283668915430703

Epoch: 6| Step: 4
Training loss: 1.1545037031173706
Validation loss: 2.2291895548502603

Epoch: 6| Step: 5
Training loss: 1.3507795333862305
Validation loss: 2.2835538387298584

Epoch: 6| Step: 6
Training loss: 1.060301661491394
Validation loss: 2.2403758764266968

Epoch: 6| Step: 7
Training loss: 1.1224974393844604
Validation loss: 2.2358250419298806

Epoch: 6| Step: 8
Training loss: 1.2053611278533936
Validation loss: 2.2746829986572266

Epoch: 6| Step: 9
Training loss: 0.5415148735046387
Validation loss: 2.2770614624023438

Epoch: 6| Step: 10
Training loss: 0.8229456543922424
Validation loss: 2.2676197290420532

Epoch: 6| Step: 11
Training loss: 1.2851037979125977
Validation loss: 2.3171474933624268

Epoch: 6| Step: 12
Training loss: 0.8280234336853027
Validation loss: 2.3039355079332986

Epoch: 6| Step: 13
Training loss: 1.2708202600479126
Validation loss: 2.2828803062438965

Epoch: 414| Step: 0
Training loss: 1.123014211654663
Validation loss: 2.2745438615481057

Epoch: 6| Step: 1
Training loss: 1.0084327459335327
Validation loss: 2.237687408924103

Epoch: 6| Step: 2
Training loss: 0.9316449165344238
Validation loss: 2.3244624535242715

Epoch: 6| Step: 3
Training loss: 0.6531468629837036
Validation loss: 2.278191089630127

Epoch: 6| Step: 4
Training loss: 1.0885065793991089
Validation loss: 2.3064033587773642

Epoch: 6| Step: 5
Training loss: 1.1526520252227783
Validation loss: 2.282508452733358

Epoch: 6| Step: 6
Training loss: 1.4837517738342285
Validation loss: 2.282145698865255

Epoch: 6| Step: 7
Training loss: 0.6520348787307739
Validation loss: 2.2567567825317383

Epoch: 6| Step: 8
Training loss: 1.4250662326812744
Validation loss: 2.27876087029775

Epoch: 6| Step: 9
Training loss: 1.1134213209152222
Validation loss: 2.270319660504659

Epoch: 6| Step: 10
Training loss: 0.8544847965240479
Validation loss: 2.2507646878560386

Epoch: 6| Step: 11
Training loss: 1.1201748847961426
Validation loss: 2.237879435221354

Epoch: 6| Step: 12
Training loss: 0.9319653511047363
Validation loss: 2.2539692521095276

Epoch: 6| Step: 13
Training loss: 1.5884861946105957
Validation loss: 2.2839492162068686

Epoch: 415| Step: 0
Training loss: 1.2724725008010864
Validation loss: 2.2405047019322715

Epoch: 6| Step: 1
Training loss: 0.907392144203186
Validation loss: 2.2557952801386514

Epoch: 6| Step: 2
Training loss: 1.2167997360229492
Validation loss: 2.2927858233451843

Epoch: 6| Step: 3
Training loss: 1.111643671989441
Validation loss: 2.2572162747383118

Epoch: 6| Step: 4
Training loss: 1.1659650802612305
Validation loss: 2.2523683309555054

Epoch: 6| Step: 5
Training loss: 0.3974648714065552
Validation loss: 2.2571110129356384

Epoch: 6| Step: 6
Training loss: 0.319394052028656
Validation loss: 2.2263654271761575

Epoch: 6| Step: 7
Training loss: 1.905874252319336
Validation loss: 2.2422516345977783

Epoch: 6| Step: 8
Training loss: 0.9748208522796631
Validation loss: 2.2183348139127097

Epoch: 6| Step: 9
Training loss: 0.7481607794761658
Validation loss: 2.2521416544914246

Epoch: 6| Step: 10
Training loss: 1.5549569129943848
Validation loss: 2.222419579823812

Epoch: 6| Step: 11
Training loss: 1.737203598022461
Validation loss: 2.252113322416941

Epoch: 6| Step: 12
Training loss: 0.7807602882385254
Validation loss: 2.244210958480835

Epoch: 6| Step: 13
Training loss: 0.6136426329612732
Validation loss: 2.251106321811676

Epoch: 416| Step: 0
Training loss: 1.270972490310669
Validation loss: 2.2697592973709106

Epoch: 6| Step: 1
Training loss: 1.080186367034912
Validation loss: 2.2714445988337197

Epoch: 6| Step: 2
Training loss: 1.0267107486724854
Validation loss: 2.225325107574463

Epoch: 6| Step: 3
Training loss: 0.6264975070953369
Validation loss: 2.227238893508911

Epoch: 6| Step: 4
Training loss: 0.559687614440918
Validation loss: 2.2706145445505777

Epoch: 6| Step: 5
Training loss: 1.1001249551773071
Validation loss: 2.2260049978892007

Epoch: 6| Step: 6
Training loss: 1.4915218353271484
Validation loss: 2.2571491797765098

Epoch: 6| Step: 7
Training loss: 0.9909800291061401
Validation loss: 2.293290694554647

Epoch: 6| Step: 8
Training loss: 1.59641695022583
Validation loss: 2.309746742248535

Epoch: 6| Step: 9
Training loss: 1.4187287092208862
Validation loss: 2.2762150168418884

Epoch: 6| Step: 10
Training loss: 0.6863041520118713
Validation loss: 2.25895365079244

Epoch: 6| Step: 11
Training loss: 1.150299072265625
Validation loss: 2.2782878081003823

Epoch: 6| Step: 12
Training loss: 1.105438232421875
Validation loss: 2.276308218638102

Epoch: 6| Step: 13
Training loss: 1.110006332397461
Validation loss: 2.2673800587654114

Epoch: 417| Step: 0
Training loss: 1.0511353015899658
Validation loss: 2.248039881388346

Epoch: 6| Step: 1
Training loss: 1.070610761642456
Validation loss: 2.2704786459604898

Epoch: 6| Step: 2
Training loss: 0.6024127006530762
Validation loss: 2.313680092493693

Epoch: 6| Step: 3
Training loss: 0.7122501730918884
Validation loss: 2.279655913511912

Epoch: 6| Step: 4
Training loss: 0.9589325785636902
Validation loss: 2.2556389768918357

Epoch: 6| Step: 5
Training loss: 0.9150339365005493
Validation loss: 2.2686009804407754

Epoch: 6| Step: 6
Training loss: 1.1920278072357178
Validation loss: 2.2580418785413108

Epoch: 6| Step: 7
Training loss: 1.2265028953552246
Validation loss: 2.2448454896608987

Epoch: 6| Step: 8
Training loss: 1.5197890996932983
Validation loss: 2.275672217210134

Epoch: 6| Step: 9
Training loss: 0.8554697036743164
Validation loss: 2.2518378098805747

Epoch: 6| Step: 10
Training loss: 1.0445250272750854
Validation loss: 2.2765763998031616

Epoch: 6| Step: 11
Training loss: 0.692768394947052
Validation loss: 2.2493635217348733

Epoch: 6| Step: 12
Training loss: 1.281798243522644
Validation loss: 2.247950812180837

Epoch: 6| Step: 13
Training loss: 2.0753612518310547
Validation loss: 2.2465447783470154

Epoch: 418| Step: 0
Training loss: 1.2347440719604492
Validation loss: 2.225356916586558

Epoch: 6| Step: 1
Training loss: 0.9484463930130005
Validation loss: 2.23338516553243

Epoch: 6| Step: 2
Training loss: 1.2142517566680908
Validation loss: 2.245987057685852

Epoch: 6| Step: 3
Training loss: 1.1294336318969727
Validation loss: 2.247864822546641

Epoch: 6| Step: 4
Training loss: 0.46575313806533813
Validation loss: 2.218409697214762

Epoch: 6| Step: 5
Training loss: 2.1302599906921387
Validation loss: 2.2503247062365213

Epoch: 6| Step: 6
Training loss: 1.2223827838897705
Validation loss: 2.2479941050211587

Epoch: 6| Step: 7
Training loss: 1.6021840572357178
Validation loss: 2.2581595182418823

Epoch: 6| Step: 8
Training loss: 0.6532514691352844
Validation loss: 2.2033012906710305

Epoch: 6| Step: 9
Training loss: 1.0297781229019165
Validation loss: 2.2212570110956826

Epoch: 6| Step: 10
Training loss: 0.9367720484733582
Validation loss: 2.2614437540372214

Epoch: 6| Step: 11
Training loss: 0.9166879057884216
Validation loss: 2.2650124629338584

Epoch: 6| Step: 12
Training loss: 0.4425326883792877
Validation loss: 2.2844855388005576

Epoch: 6| Step: 13
Training loss: 0.8414928317070007
Validation loss: 2.2133829394976297

Epoch: 419| Step: 0
Training loss: 1.10429048538208
Validation loss: 2.2730219761530557

Epoch: 6| Step: 1
Training loss: 1.0265824794769287
Validation loss: 2.2361731131871543

Epoch: 6| Step: 2
Training loss: 0.8001998662948608
Validation loss: 2.284709711869558

Epoch: 6| Step: 3
Training loss: 0.5497090816497803
Validation loss: 2.2230865756670632

Epoch: 6| Step: 4
Training loss: 1.1574280261993408
Validation loss: 2.2545130252838135

Epoch: 6| Step: 5
Training loss: 1.056549310684204
Validation loss: 2.3156701922416687

Epoch: 6| Step: 6
Training loss: 1.244011640548706
Validation loss: 2.304535746574402

Epoch: 6| Step: 7
Training loss: 1.6351507902145386
Validation loss: 2.3014827370643616

Epoch: 6| Step: 8
Training loss: 0.7223086357116699
Validation loss: 2.2440486351648965

Epoch: 6| Step: 9
Training loss: 0.787243664264679
Validation loss: 2.2600399454434714

Epoch: 6| Step: 10
Training loss: 0.6061640977859497
Validation loss: 2.285926898320516

Epoch: 6| Step: 11
Training loss: 1.4541234970092773
Validation loss: 2.272883574167887

Epoch: 6| Step: 12
Training loss: 1.2222720384597778
Validation loss: 2.2638885577519736

Epoch: 6| Step: 13
Training loss: 1.2211838960647583
Validation loss: 2.2804585695266724

Epoch: 420| Step: 0
Training loss: 0.6185156106948853
Validation loss: 2.2362398902575173

Epoch: 6| Step: 1
Training loss: 0.8557448387145996
Validation loss: 2.300813059012095

Epoch: 6| Step: 2
Training loss: 0.8817999362945557
Validation loss: 2.2677228450775146

Epoch: 6| Step: 3
Training loss: 0.9830019474029541
Validation loss: 2.2860206166903176

Epoch: 6| Step: 4
Training loss: 1.0048167705535889
Validation loss: 2.2636581659317017

Epoch: 6| Step: 5
Training loss: 2.16845703125
Validation loss: 2.3037701845169067

Epoch: 6| Step: 6
Training loss: 0.9568870067596436
Validation loss: 2.3239049116770425

Epoch: 6| Step: 7
Training loss: 1.1423511505126953
Validation loss: 2.3175177574157715

Epoch: 6| Step: 8
Training loss: 0.9616609811782837
Validation loss: 2.296769460042318

Epoch: 6| Step: 9
Training loss: 0.7848857641220093
Validation loss: 2.2915263970692954

Epoch: 6| Step: 10
Training loss: 0.7832472920417786
Validation loss: 2.3290717601776123

Epoch: 6| Step: 11
Training loss: 1.8363147974014282
Validation loss: 2.279355784257253

Epoch: 6| Step: 12
Training loss: 1.0079872608184814
Validation loss: 2.2968449195226035

Epoch: 6| Step: 13
Training loss: 0.7447155117988586
Validation loss: 2.2613393465677896

Epoch: 421| Step: 0
Training loss: 0.8068195581436157
Validation loss: 2.3078453739484153

Epoch: 6| Step: 1
Training loss: 1.3925076723098755
Validation loss: 2.2724504470825195

Epoch: 6| Step: 2
Training loss: 0.8770889639854431
Validation loss: 2.260564088821411

Epoch: 6| Step: 3
Training loss: 0.8950119614601135
Validation loss: 2.2623411417007446

Epoch: 6| Step: 4
Training loss: 0.8271851539611816
Validation loss: 2.2642945845921836

Epoch: 6| Step: 5
Training loss: 0.4447501599788666
Validation loss: 2.2042653958002725

Epoch: 6| Step: 6
Training loss: 1.2699013948440552
Validation loss: 2.2680461009343467

Epoch: 6| Step: 7
Training loss: 1.008911371231079
Validation loss: 2.2943400541941323

Epoch: 6| Step: 8
Training loss: 1.5559216737747192
Validation loss: 2.279857794443766

Epoch: 6| Step: 9
Training loss: 0.8949389457702637
Validation loss: 2.28185365597407

Epoch: 6| Step: 10
Training loss: 0.9904302358627319
Validation loss: 2.2850602865219116

Epoch: 6| Step: 11
Training loss: 0.715979814529419
Validation loss: 2.285400708516439

Epoch: 6| Step: 12
Training loss: 1.1224830150604248
Validation loss: 2.2925223112106323

Epoch: 6| Step: 13
Training loss: 1.7372506856918335
Validation loss: 2.302903493245443

Epoch: 422| Step: 0
Training loss: 1.0029089450836182
Validation loss: 2.3193255265553794

Epoch: 6| Step: 1
Training loss: 0.9871642589569092
Validation loss: 2.3320000966389975

Epoch: 6| Step: 2
Training loss: 1.174112319946289
Validation loss: 2.2848053177197776

Epoch: 6| Step: 3
Training loss: 0.9936155676841736
Validation loss: 2.245599110921224

Epoch: 6| Step: 4
Training loss: 1.1386165618896484
Validation loss: 2.3027676343917847

Epoch: 6| Step: 5
Training loss: 0.8067197799682617
Validation loss: 2.2672744592030845

Epoch: 6| Step: 6
Training loss: 1.2866592407226562
Validation loss: 2.2777748703956604

Epoch: 6| Step: 7
Training loss: 0.7307126522064209
Validation loss: 2.280129094918569

Epoch: 6| Step: 8
Training loss: 1.1326584815979004
Validation loss: 2.2762527465820312

Epoch: 6| Step: 9
Training loss: 0.990705132484436
Validation loss: 2.2627313335736594

Epoch: 6| Step: 10
Training loss: 1.1420214176177979
Validation loss: 2.219160795211792

Epoch: 6| Step: 11
Training loss: 1.123715877532959
Validation loss: 2.266619086265564

Epoch: 6| Step: 12
Training loss: 1.0689221620559692
Validation loss: 2.2436417738596597

Epoch: 6| Step: 13
Training loss: 1.107221007347107
Validation loss: 2.2330636779467263

Epoch: 423| Step: 0
Training loss: 0.6853460073471069
Validation loss: 2.269492189089457

Epoch: 6| Step: 1
Training loss: 1.4944493770599365
Validation loss: 2.255109707514445

Epoch: 6| Step: 2
Training loss: 1.0286964178085327
Validation loss: 2.2513511379559836

Epoch: 6| Step: 3
Training loss: 1.2086899280548096
Validation loss: 2.267834564050039

Epoch: 6| Step: 4
Training loss: 0.6148530840873718
Validation loss: 2.305337448914846

Epoch: 6| Step: 5
Training loss: 1.0674352645874023
Validation loss: 2.2415963808695474

Epoch: 6| Step: 6
Training loss: 1.5773675441741943
Validation loss: 2.2571629087130227

Epoch: 6| Step: 7
Training loss: 0.8855124711990356
Validation loss: 2.3187064131100974

Epoch: 6| Step: 8
Training loss: 1.2861249446868896
Validation loss: 2.2748451630274453

Epoch: 6| Step: 9
Training loss: 1.202997088432312
Validation loss: 2.2432733376820884

Epoch: 6| Step: 10
Training loss: 0.8051724433898926
Validation loss: 2.2282711466153464

Epoch: 6| Step: 11
Training loss: 1.4513843059539795
Validation loss: 2.2895654241243997

Epoch: 6| Step: 12
Training loss: 1.2609353065490723
Validation loss: 2.2116822799046836

Epoch: 6| Step: 13
Training loss: 1.2172269821166992
Validation loss: 2.288626511891683

Epoch: 424| Step: 0
Training loss: 1.6059722900390625
Validation loss: 2.247003416220347

Epoch: 6| Step: 1
Training loss: 0.8946720957756042
Validation loss: 2.2705549001693726

Epoch: 6| Step: 2
Training loss: 1.3647661209106445
Validation loss: 2.2657427191734314

Epoch: 6| Step: 3
Training loss: 0.7298979759216309
Validation loss: 2.260968049367269

Epoch: 6| Step: 4
Training loss: 0.995925784111023
Validation loss: 2.2333495219548545

Epoch: 6| Step: 5
Training loss: 1.1957509517669678
Validation loss: 2.2451222936312356

Epoch: 6| Step: 6
Training loss: 1.0055944919586182
Validation loss: 2.203764100869497

Epoch: 6| Step: 7
Training loss: 1.082415223121643
Validation loss: 2.215767502784729

Epoch: 6| Step: 8
Training loss: 0.7783418893814087
Validation loss: 2.202066163221995

Epoch: 6| Step: 9
Training loss: 0.6790974140167236
Validation loss: 2.2453337709108987

Epoch: 6| Step: 10
Training loss: 1.4118189811706543
Validation loss: 2.2271520098050437

Epoch: 6| Step: 11
Training loss: 0.9839441776275635
Validation loss: 2.1684566537539163

Epoch: 6| Step: 12
Training loss: 0.6138275861740112
Validation loss: 2.2151809136072793

Epoch: 6| Step: 13
Training loss: 1.180546522140503
Validation loss: 2.1874636014302573

Epoch: 425| Step: 0
Training loss: 1.0961401462554932
Validation loss: 2.189921955267588

Epoch: 6| Step: 1
Training loss: 0.6698836088180542
Validation loss: 2.214426835378011

Epoch: 6| Step: 2
Training loss: 0.933014988899231
Validation loss: 2.2229892015457153

Epoch: 6| Step: 3
Training loss: 1.8806047439575195
Validation loss: 2.233917852242788

Epoch: 6| Step: 4
Training loss: 0.5658453702926636
Validation loss: 2.2009243766466775

Epoch: 6| Step: 5
Training loss: 0.5610306262969971
Validation loss: 2.2384336988131204

Epoch: 6| Step: 6
Training loss: 0.8160564303398132
Validation loss: 2.2402091224988303

Epoch: 6| Step: 7
Training loss: 0.7360495328903198
Validation loss: 2.1979010303815207

Epoch: 6| Step: 8
Training loss: 1.2402602434158325
Validation loss: 2.2514127095540366

Epoch: 6| Step: 9
Training loss: 1.8024637699127197
Validation loss: 2.2223801414171853

Epoch: 6| Step: 10
Training loss: 0.9017203450202942
Validation loss: 2.267587880293528

Epoch: 6| Step: 11
Training loss: 1.0839543342590332
Validation loss: 2.226511557896932

Epoch: 6| Step: 12
Training loss: 0.9463039636611938
Validation loss: 2.2844122449556985

Epoch: 6| Step: 13
Training loss: 0.9579179286956787
Validation loss: 2.2702468633651733

Epoch: 426| Step: 0
Training loss: 1.011837124824524
Validation loss: 2.2549275358517966

Epoch: 6| Step: 1
Training loss: 1.405393362045288
Validation loss: 2.3106645345687866

Epoch: 6| Step: 2
Training loss: 1.4345929622650146
Validation loss: 2.2763847510019937

Epoch: 6| Step: 3
Training loss: 1.2680401802062988
Validation loss: 2.317365050315857

Epoch: 6| Step: 4
Training loss: 0.813220739364624
Validation loss: 2.2974708676338196

Epoch: 6| Step: 5
Training loss: 1.0074254274368286
Validation loss: 2.3057465155919394

Epoch: 6| Step: 6
Training loss: 0.5787467956542969
Validation loss: 2.3176700671513877

Epoch: 6| Step: 7
Training loss: 0.4870365858078003
Validation loss: 2.312415063381195

Epoch: 6| Step: 8
Training loss: 1.7652093172073364
Validation loss: 2.2812280456225076

Epoch: 6| Step: 9
Training loss: 1.4500532150268555
Validation loss: 2.248271902402242

Epoch: 6| Step: 10
Training loss: 1.2695757150650024
Validation loss: 2.2650326093037925

Epoch: 6| Step: 11
Training loss: 0.47855693101882935
Validation loss: 2.27932345867157

Epoch: 6| Step: 12
Training loss: 0.8337070941925049
Validation loss: 2.2501362562179565

Epoch: 6| Step: 13
Training loss: 0.8552329540252686
Validation loss: 2.2627592285474143

Epoch: 427| Step: 0
Training loss: 0.4908176362514496
Validation loss: 2.2493784030278525

Epoch: 6| Step: 1
Training loss: 1.5670912265777588
Validation loss: 2.3186440070470176

Epoch: 6| Step: 2
Training loss: 2.271744728088379
Validation loss: 2.267398476600647

Epoch: 6| Step: 3
Training loss: 0.4025889039039612
Validation loss: 2.2616138060887656

Epoch: 6| Step: 4
Training loss: 0.7546191811561584
Validation loss: 2.2582011620203652

Epoch: 6| Step: 5
Training loss: 0.5376925468444824
Validation loss: 2.2717811663945517

Epoch: 6| Step: 6
Training loss: 0.9806685447692871
Validation loss: 2.300764481226603

Epoch: 6| Step: 7
Training loss: 0.9775686264038086
Validation loss: 2.2763076623280845

Epoch: 6| Step: 8
Training loss: 1.471632719039917
Validation loss: 2.2331160505612693

Epoch: 6| Step: 9
Training loss: 0.5826938152313232
Validation loss: 2.266034265359243

Epoch: 6| Step: 10
Training loss: 0.8715945482254028
Validation loss: 2.271436353524526

Epoch: 6| Step: 11
Training loss: 1.3283026218414307
Validation loss: 2.2382086316744485

Epoch: 6| Step: 12
Training loss: 0.9598641395568848
Validation loss: 2.28008234500885

Epoch: 6| Step: 13
Training loss: 0.7848588824272156
Validation loss: 2.201929211616516

Epoch: 428| Step: 0
Training loss: 1.1266295909881592
Validation loss: 2.2666210929552713

Epoch: 6| Step: 1
Training loss: 0.9641729593276978
Validation loss: 2.243055979410807

Epoch: 6| Step: 2
Training loss: 1.354820728302002
Validation loss: 2.29401695728302

Epoch: 6| Step: 3
Training loss: 0.6676961779594421
Validation loss: 2.2508604923884072

Epoch: 6| Step: 4
Training loss: 0.9986922740936279
Validation loss: 2.2461368441581726

Epoch: 6| Step: 5
Training loss: 1.3382090330123901
Validation loss: 2.284400979677836

Epoch: 6| Step: 6
Training loss: 0.8465359210968018
Validation loss: 2.2847203811009726

Epoch: 6| Step: 7
Training loss: 0.3972907066345215
Validation loss: 2.2959880232810974

Epoch: 6| Step: 8
Training loss: 1.7842388153076172
Validation loss: 2.299393812815348

Epoch: 6| Step: 9
Training loss: 1.0601279735565186
Validation loss: 2.2629278699556985

Epoch: 6| Step: 10
Training loss: 0.7260007858276367
Validation loss: 2.2953741947809854

Epoch: 6| Step: 11
Training loss: 0.6810645461082458
Validation loss: 2.279120922088623

Epoch: 6| Step: 12
Training loss: 1.3057231903076172
Validation loss: 2.310018082459768

Epoch: 6| Step: 13
Training loss: 0.506549060344696
Validation loss: 2.291625718275706

Epoch: 429| Step: 0
Training loss: 0.6056084632873535
Validation loss: 2.270885785420736

Epoch: 6| Step: 1
Training loss: 1.4995849132537842
Validation loss: 2.2353426615397134

Epoch: 6| Step: 2
Training loss: 1.0694057941436768
Validation loss: 2.2984304229418435

Epoch: 6| Step: 3
Training loss: 0.744600772857666
Validation loss: 2.2581292589505515

Epoch: 6| Step: 4
Training loss: 1.4387015104293823
Validation loss: 2.240626851717631

Epoch: 6| Step: 5
Training loss: 0.8014837503433228
Validation loss: 2.253415366013845

Epoch: 6| Step: 6
Training loss: 1.3393611907958984
Validation loss: 2.2562121152877808

Epoch: 6| Step: 7
Training loss: 0.5201044678688049
Validation loss: 2.2627638379732766

Epoch: 6| Step: 8
Training loss: 1.217980146408081
Validation loss: 2.2550338904062905

Epoch: 6| Step: 9
Training loss: 1.4900509119033813
Validation loss: 2.2495304544766745

Epoch: 6| Step: 10
Training loss: 1.0396803617477417
Validation loss: 2.2595314979553223

Epoch: 6| Step: 11
Training loss: 0.7092896699905396
Validation loss: 2.267339607079824

Epoch: 6| Step: 12
Training loss: 0.7015194296836853
Validation loss: 2.2506139675776162

Epoch: 6| Step: 13
Training loss: 0.7853684425354004
Validation loss: 2.238373855749766

Epoch: 430| Step: 0
Training loss: 1.2206993103027344
Validation loss: 2.26981920003891

Epoch: 6| Step: 1
Training loss: 0.7698086500167847
Validation loss: 2.2628970543543496

Epoch: 6| Step: 2
Training loss: 1.0932023525238037
Validation loss: 2.278962810834249

Epoch: 6| Step: 3
Training loss: 1.045520544052124
Validation loss: 2.286387821038564

Epoch: 6| Step: 4
Training loss: 0.9870579838752747
Validation loss: 2.2409652272860208

Epoch: 6| Step: 5
Training loss: 0.5310530662536621
Validation loss: 2.2748465538024902

Epoch: 6| Step: 6
Training loss: 0.8464017510414124
Validation loss: 2.2676724990208945

Epoch: 6| Step: 7
Training loss: 0.8694660663604736
Validation loss: 2.277627150217692

Epoch: 6| Step: 8
Training loss: 0.5420571565628052
Validation loss: 2.2334571282068887

Epoch: 6| Step: 9
Training loss: 1.0647004842758179
Validation loss: 2.2907324035962424

Epoch: 6| Step: 10
Training loss: 1.0127475261688232
Validation loss: 2.2641966144243875

Epoch: 6| Step: 11
Training loss: 1.8146815299987793
Validation loss: 2.294504165649414

Epoch: 6| Step: 12
Training loss: 1.3130024671554565
Validation loss: 2.286398470401764

Epoch: 6| Step: 13
Training loss: 1.1811386346817017
Validation loss: 2.3310393492380777

Epoch: 431| Step: 0
Training loss: 1.2560979127883911
Validation loss: 2.3083394368489585

Epoch: 6| Step: 1
Training loss: 1.3236777782440186
Validation loss: 2.319518764813741

Epoch: 6| Step: 2
Training loss: 1.598752737045288
Validation loss: 2.3012139995892844

Epoch: 6| Step: 3
Training loss: 1.1279261112213135
Validation loss: 2.2839338183403015

Epoch: 6| Step: 4
Training loss: 0.8815812468528748
Validation loss: 2.266048312187195

Epoch: 6| Step: 5
Training loss: 0.8107814192771912
Validation loss: 2.2452399333318076

Epoch: 6| Step: 6
Training loss: 1.3286185264587402
Validation loss: 2.2659584085146585

Epoch: 6| Step: 7
Training loss: 1.0617027282714844
Validation loss: 2.2403460343678794

Epoch: 6| Step: 8
Training loss: 0.5858531594276428
Validation loss: 2.2256399591763816

Epoch: 6| Step: 9
Training loss: 2.0532357692718506
Validation loss: 2.1976017554601035

Epoch: 6| Step: 10
Training loss: 0.6818077564239502
Validation loss: 2.240743319193522

Epoch: 6| Step: 11
Training loss: 0.9428125619888306
Validation loss: 2.24314550558726

Epoch: 6| Step: 12
Training loss: 0.8093154430389404
Validation loss: 2.239820202191671

Epoch: 6| Step: 13
Training loss: 0.7432734370231628
Validation loss: 2.2452083826065063

Epoch: 432| Step: 0
Training loss: 0.5450229644775391
Validation loss: 2.245448887348175

Epoch: 6| Step: 1
Training loss: 1.4589974880218506
Validation loss: 2.1838568846384683

Epoch: 6| Step: 2
Training loss: 0.6978252530097961
Validation loss: 2.261779030164083

Epoch: 6| Step: 3
Training loss: 0.9998639822006226
Validation loss: 2.1959905425707498

Epoch: 6| Step: 4
Training loss: 1.3905017375946045
Validation loss: 2.2713730732599893

Epoch: 6| Step: 5
Training loss: 1.1416257619857788
Validation loss: 2.194322109222412

Epoch: 6| Step: 6
Training loss: 0.44872963428497314
Validation loss: 2.221006711324056

Epoch: 6| Step: 7
Training loss: 0.9533358216285706
Validation loss: 2.2208330233891806

Epoch: 6| Step: 8
Training loss: 0.7055314779281616
Validation loss: 2.26264496644338

Epoch: 6| Step: 9
Training loss: 1.211946964263916
Validation loss: 2.238783280054728

Epoch: 6| Step: 10
Training loss: 1.4383485317230225
Validation loss: 2.2392208178838096

Epoch: 6| Step: 11
Training loss: 1.1991355419158936
Validation loss: 2.2444939613342285

Epoch: 6| Step: 12
Training loss: 0.8996309041976929
Validation loss: 2.271525243918101

Epoch: 6| Step: 13
Training loss: 0.8439832925796509
Validation loss: 2.266205310821533

Epoch: 433| Step: 0
Training loss: 1.4763543605804443
Validation loss: 2.229728579521179

Epoch: 6| Step: 1
Training loss: 0.9832711815834045
Validation loss: 2.2691046992937722

Epoch: 6| Step: 2
Training loss: 0.8393629789352417
Validation loss: 2.248206853866577

Epoch: 6| Step: 3
Training loss: 0.8046963214874268
Validation loss: 2.2947471936543784

Epoch: 6| Step: 4
Training loss: 1.026455044746399
Validation loss: 2.2899251580238342

Epoch: 6| Step: 5
Training loss: 1.8010895252227783
Validation loss: 2.2410061359405518

Epoch: 6| Step: 6
Training loss: 0.8337199687957764
Validation loss: 2.2948023875554404

Epoch: 6| Step: 7
Training loss: 0.4422793984413147
Validation loss: 2.229919950167338

Epoch: 6| Step: 8
Training loss: 0.7817078828811646
Validation loss: 2.2472029328346252

Epoch: 6| Step: 9
Training loss: 0.7287527322769165
Validation loss: 2.260978023211161

Epoch: 6| Step: 10
Training loss: 1.268805980682373
Validation loss: 2.2448599338531494

Epoch: 6| Step: 11
Training loss: 0.6590420007705688
Validation loss: 2.2727702458699546

Epoch: 6| Step: 12
Training loss: 1.4266612529754639
Validation loss: 2.272037446498871

Epoch: 6| Step: 13
Training loss: 0.8549513816833496
Validation loss: 2.257822791735331

Epoch: 434| Step: 0
Training loss: 0.5156040191650391
Validation loss: 2.2603166103363037

Epoch: 6| Step: 1
Training loss: 1.659437894821167
Validation loss: 2.2487903237342834

Epoch: 6| Step: 2
Training loss: 0.5907993912696838
Validation loss: 2.2873284618059793

Epoch: 6| Step: 3
Training loss: 0.9235265851020813
Validation loss: 2.234784742196401

Epoch: 6| Step: 4
Training loss: 1.2797203063964844
Validation loss: 2.309030810991923

Epoch: 6| Step: 5
Training loss: 1.351871132850647
Validation loss: 2.2833821773529053

Epoch: 6| Step: 6
Training loss: 0.6319087743759155
Validation loss: 2.2669127186139426

Epoch: 6| Step: 7
Training loss: 1.2907763719558716
Validation loss: 2.2622644305229187

Epoch: 6| Step: 8
Training loss: 1.079176664352417
Validation loss: 2.2630205750465393

Epoch: 6| Step: 9
Training loss: 0.6871746778488159
Validation loss: 2.2495710452397666

Epoch: 6| Step: 10
Training loss: 0.7264934778213501
Validation loss: 2.2279294530550637

Epoch: 6| Step: 11
Training loss: 0.922715961933136
Validation loss: 2.2684319019317627

Epoch: 6| Step: 12
Training loss: 0.9171367883682251
Validation loss: 2.2695963978767395

Epoch: 6| Step: 13
Training loss: 1.083164095878601
Validation loss: 2.3155205249786377

Epoch: 435| Step: 0
Training loss: 1.4450863599777222
Validation loss: 2.2679484486579895

Epoch: 6| Step: 1
Training loss: 1.4986450672149658
Validation loss: 2.2718321482340493

Epoch: 6| Step: 2
Training loss: 0.8751845955848694
Validation loss: 2.3212442795435586

Epoch: 6| Step: 3
Training loss: 0.7140277624130249
Validation loss: 2.297210991382599

Epoch: 6| Step: 4
Training loss: 0.4549412131309509
Validation loss: 2.2581899563471475

Epoch: 6| Step: 5
Training loss: 1.121416449546814
Validation loss: 2.3063732782999673

Epoch: 6| Step: 6
Training loss: 1.2708418369293213
Validation loss: 2.335187037785848

Epoch: 6| Step: 7
Training loss: 1.2783122062683105
Validation loss: 2.30075337489446

Epoch: 6| Step: 8
Training loss: 1.2546372413635254
Validation loss: 2.2466835180918374

Epoch: 6| Step: 9
Training loss: 0.9781020283699036
Validation loss: 2.2938604950904846

Epoch: 6| Step: 10
Training loss: 0.5248162746429443
Validation loss: 2.3046947916348777

Epoch: 6| Step: 11
Training loss: 0.8063095808029175
Validation loss: 2.2831046183904014

Epoch: 6| Step: 12
Training loss: 1.2203571796417236
Validation loss: 2.2473254601160684

Epoch: 6| Step: 13
Training loss: 0.8179807662963867
Validation loss: 2.22276763121287

Epoch: 436| Step: 0
Training loss: 1.5212023258209229
Validation loss: 2.268130819002787

Epoch: 6| Step: 1
Training loss: 1.6843070983886719
Validation loss: 2.233930250008901

Epoch: 6| Step: 2
Training loss: 0.4280964732170105
Validation loss: 2.2784961462020874

Epoch: 6| Step: 3
Training loss: 0.7153834104537964
Validation loss: 2.2602963050206504

Epoch: 6| Step: 4
Training loss: 1.1214330196380615
Validation loss: 2.2329760591189065

Epoch: 6| Step: 5
Training loss: 0.94154953956604
Validation loss: 2.2890105644861856

Epoch: 6| Step: 6
Training loss: 1.055752158164978
Validation loss: 2.2783297896385193

Epoch: 6| Step: 7
Training loss: 1.8247272968292236
Validation loss: 2.2268256346384683

Epoch: 6| Step: 8
Training loss: 0.6508665084838867
Validation loss: 2.224047621091207

Epoch: 6| Step: 9
Training loss: 0.8148638010025024
Validation loss: 2.273233950138092

Epoch: 6| Step: 10
Training loss: 0.6125814914703369
Validation loss: 2.2777769366900125

Epoch: 6| Step: 11
Training loss: 0.7397446036338806
Validation loss: 2.2840343515078225

Epoch: 6| Step: 12
Training loss: 0.5987001061439514
Validation loss: 2.314403235912323

Epoch: 6| Step: 13
Training loss: 1.2391307353973389
Validation loss: 2.285157064596812

Epoch: 437| Step: 0
Training loss: 1.3002973794937134
Validation loss: 2.3058011531829834

Epoch: 6| Step: 1
Training loss: 1.4859520196914673
Validation loss: 2.277167876561483

Epoch: 6| Step: 2
Training loss: 1.1210943460464478
Validation loss: 2.3172014951705933

Epoch: 6| Step: 3
Training loss: 0.6063125133514404
Validation loss: 2.2883364160855613

Epoch: 6| Step: 4
Training loss: 0.7195459008216858
Validation loss: 2.2622790733973184

Epoch: 6| Step: 5
Training loss: 0.8004738092422485
Validation loss: 2.2371644973754883

Epoch: 6| Step: 6
Training loss: 1.3043544292449951
Validation loss: 2.236459573109945

Epoch: 6| Step: 7
Training loss: 0.5975923538208008
Validation loss: 2.295210917790731

Epoch: 6| Step: 8
Training loss: 1.5314563512802124
Validation loss: 2.1881317297617593

Epoch: 6| Step: 9
Training loss: 0.8768985867500305
Validation loss: 2.2638812263806662

Epoch: 6| Step: 10
Training loss: 1.1153370141983032
Validation loss: 2.2364893754323325

Epoch: 6| Step: 11
Training loss: 0.9792819023132324
Validation loss: 2.253529707590739

Epoch: 6| Step: 12
Training loss: 0.7947996854782104
Validation loss: 2.286836862564087

Epoch: 6| Step: 13
Training loss: 0.7595999240875244
Validation loss: 2.240634004275004

Epoch: 438| Step: 0
Training loss: 1.116140604019165
Validation loss: 2.2404472827911377

Epoch: 6| Step: 1
Training loss: 0.6442909836769104
Validation loss: 2.232275148232778

Epoch: 6| Step: 2
Training loss: 0.9099669456481934
Validation loss: 2.273559292157491

Epoch: 6| Step: 3
Training loss: 0.6459715366363525
Validation loss: 2.2125107447306314

Epoch: 6| Step: 4
Training loss: 1.2118570804595947
Validation loss: 2.246149559815725

Epoch: 6| Step: 5
Training loss: 1.5944178104400635
Validation loss: 2.2099372148513794

Epoch: 6| Step: 6
Training loss: 0.948783278465271
Validation loss: 2.2381226420402527

Epoch: 6| Step: 7
Training loss: 0.44905298948287964
Validation loss: 2.2519758145014444

Epoch: 6| Step: 8
Training loss: 0.8746423125267029
Validation loss: 2.2277203798294067

Epoch: 6| Step: 9
Training loss: 1.4970886707305908
Validation loss: 2.236548960208893

Epoch: 6| Step: 10
Training loss: 0.4366835951805115
Validation loss: 2.2760316530863443

Epoch: 6| Step: 11
Training loss: 0.6382495164871216
Validation loss: 2.287706971168518

Epoch: 6| Step: 12
Training loss: 0.8400605916976929
Validation loss: 2.279214878877004

Epoch: 6| Step: 13
Training loss: 1.7849373817443848
Validation loss: 2.28380678097407

Epoch: 439| Step: 0
Training loss: 0.7285101413726807
Validation loss: 2.281891723473867

Epoch: 6| Step: 1
Training loss: 0.6548928022384644
Validation loss: 2.2810797492663064

Epoch: 6| Step: 2
Training loss: 0.9443172812461853
Validation loss: 2.301001707712809

Epoch: 6| Step: 3
Training loss: 0.5881723165512085
Validation loss: 2.2662357091903687

Epoch: 6| Step: 4
Training loss: 0.671085000038147
Validation loss: 2.24004727602005

Epoch: 6| Step: 5
Training loss: 0.7604786157608032
Validation loss: 2.2354756395022073

Epoch: 6| Step: 6
Training loss: 1.5724003314971924
Validation loss: 2.237587829430898

Epoch: 6| Step: 7
Training loss: 0.9839562177658081
Validation loss: 2.26222026348114

Epoch: 6| Step: 8
Training loss: 0.8176703453063965
Validation loss: 2.25294828414917

Epoch: 6| Step: 9
Training loss: 0.7644591331481934
Validation loss: 2.2792131900787354

Epoch: 6| Step: 10
Training loss: 1.101052165031433
Validation loss: 2.2696261207262673

Epoch: 6| Step: 11
Training loss: 0.9839030504226685
Validation loss: 2.2848623792330423

Epoch: 6| Step: 12
Training loss: 1.6569746732711792
Validation loss: 2.239344000816345

Epoch: 6| Step: 13
Training loss: 1.5537950992584229
Validation loss: 2.2774413426717124

Epoch: 440| Step: 0
Training loss: 1.2040505409240723
Validation loss: 2.280721664428711

Epoch: 6| Step: 1
Training loss: 1.3214635848999023
Validation loss: 2.2895480394363403

Epoch: 6| Step: 2
Training loss: 1.2807769775390625
Validation loss: 2.2764140367507935

Epoch: 6| Step: 3
Training loss: 1.0204675197601318
Validation loss: 2.2600924372673035

Epoch: 6| Step: 4
Training loss: 0.8146550059318542
Validation loss: 2.263313909371694

Epoch: 6| Step: 5
Training loss: 0.9416499137878418
Validation loss: 2.2922134002049765

Epoch: 6| Step: 6
Training loss: 0.9381172060966492
Validation loss: 2.2943005760510764

Epoch: 6| Step: 7
Training loss: 0.9875696897506714
Validation loss: 2.320805788040161

Epoch: 6| Step: 8
Training loss: 0.7447829246520996
Validation loss: 2.298727552096049

Epoch: 6| Step: 9
Training loss: 0.7778228521347046
Validation loss: 2.305403927961985

Epoch: 6| Step: 10
Training loss: 1.398627758026123
Validation loss: 2.269326468308767

Epoch: 6| Step: 11
Training loss: 0.3529856204986572
Validation loss: 2.296154578526815

Epoch: 6| Step: 12
Training loss: 1.2552616596221924
Validation loss: 2.2884236574172974

Epoch: 6| Step: 13
Training loss: 1.6993064880371094
Validation loss: 2.3084388971328735

Epoch: 441| Step: 0
Training loss: 0.6305466890335083
Validation loss: 2.2930790980656943

Epoch: 6| Step: 1
Training loss: 1.6163781881332397
Validation loss: 2.3084978063901267

Epoch: 6| Step: 2
Training loss: 1.277968406677246
Validation loss: 2.2340345780054727

Epoch: 6| Step: 3
Training loss: 0.8172425031661987
Validation loss: 2.3247036139170327

Epoch: 6| Step: 4
Training loss: 0.9168878197669983
Validation loss: 2.282949447631836

Epoch: 6| Step: 5
Training loss: 0.725283682346344
Validation loss: 2.2649128834406533

Epoch: 6| Step: 6
Training loss: 1.1122121810913086
Validation loss: 2.2566566467285156

Epoch: 6| Step: 7
Training loss: 0.862049400806427
Validation loss: 2.2387898763020835

Epoch: 6| Step: 8
Training loss: 0.9279161095619202
Validation loss: 2.2756181557973227

Epoch: 6| Step: 9
Training loss: 1.095594048500061
Validation loss: 2.2585112849871316

Epoch: 6| Step: 10
Training loss: 0.6309993267059326
Validation loss: 2.276175638039907

Epoch: 6| Step: 11
Training loss: 1.5849764347076416
Validation loss: 2.284652312596639

Epoch: 6| Step: 12
Training loss: 1.034757375717163
Validation loss: 2.3534099062283835

Epoch: 6| Step: 13
Training loss: 0.884293794631958
Validation loss: 2.3124196529388428

Epoch: 442| Step: 0
Training loss: 0.6308635473251343
Validation loss: 2.2823678255081177

Epoch: 6| Step: 1
Training loss: 0.5422549843788147
Validation loss: 2.3131031592686973

Epoch: 6| Step: 2
Training loss: 0.9183212518692017
Validation loss: 2.2789907852808633

Epoch: 6| Step: 3
Training loss: 1.388751745223999
Validation loss: 2.2830914656321206

Epoch: 6| Step: 4
Training loss: 0.8446998000144958
Validation loss: 2.253366788228353

Epoch: 6| Step: 5
Training loss: 0.6912117004394531
Validation loss: 2.3157235781351724

Epoch: 6| Step: 6
Training loss: 0.9698560833930969
Validation loss: 2.2883636554082236

Epoch: 6| Step: 7
Training loss: 2.1882381439208984
Validation loss: 2.2597363591194153

Epoch: 6| Step: 8
Training loss: 1.7989187240600586
Validation loss: 2.308302919069926

Epoch: 6| Step: 9
Training loss: 0.5048693418502808
Validation loss: 2.2545024951299033

Epoch: 6| Step: 10
Training loss: 0.8422366380691528
Validation loss: 2.2588000694910684

Epoch: 6| Step: 11
Training loss: 0.5796531438827515
Validation loss: 2.249126156171163

Epoch: 6| Step: 12
Training loss: 0.9165738224983215
Validation loss: 2.256670435269674

Epoch: 6| Step: 13
Training loss: 0.5881576538085938
Validation loss: 2.268871823946635

Epoch: 443| Step: 0
Training loss: 0.6115245819091797
Validation loss: 2.2848012248675027

Epoch: 6| Step: 1
Training loss: 0.29719436168670654
Validation loss: 2.2861538926760354

Epoch: 6| Step: 2
Training loss: 0.8950543999671936
Validation loss: 2.274947245915731

Epoch: 6| Step: 3
Training loss: 0.8058319091796875
Validation loss: 2.3830137252807617

Epoch: 6| Step: 4
Training loss: 0.9654810428619385
Validation loss: 2.322680711746216

Epoch: 6| Step: 5
Training loss: 0.7944561839103699
Validation loss: 2.3127466837565103

Epoch: 6| Step: 6
Training loss: 1.342969536781311
Validation loss: 2.2752765814463296

Epoch: 6| Step: 7
Training loss: 1.444474458694458
Validation loss: 2.2954269846280417

Epoch: 6| Step: 8
Training loss: 0.7526090145111084
Validation loss: 2.2918547987937927

Epoch: 6| Step: 9
Training loss: 0.7281025648117065
Validation loss: 2.249869783719381

Epoch: 6| Step: 10
Training loss: 1.282261848449707
Validation loss: 2.3038665453592935

Epoch: 6| Step: 11
Training loss: 1.7582964897155762
Validation loss: 2.2918882767359414

Epoch: 6| Step: 12
Training loss: 1.1343649625778198
Validation loss: 2.2999661763509116

Epoch: 6| Step: 13
Training loss: 1.2157008647918701
Validation loss: 2.359347701072693

Epoch: 444| Step: 0
Training loss: 1.1302447319030762
Validation loss: 2.3531413078308105

Epoch: 6| Step: 1
Training loss: 0.6901313662528992
Validation loss: 2.320011615753174

Epoch: 6| Step: 2
Training loss: 0.843434751033783
Validation loss: 2.357635974884033

Epoch: 6| Step: 3
Training loss: 0.4346975088119507
Validation loss: 2.2854572534561157

Epoch: 6| Step: 4
Training loss: 1.0585004091262817
Validation loss: 2.30591348807017

Epoch: 6| Step: 5
Training loss: 1.9231520891189575
Validation loss: 2.3038416306177774

Epoch: 6| Step: 6
Training loss: 1.0447490215301514
Validation loss: 2.299287716547648

Epoch: 6| Step: 7
Training loss: 1.4057512283325195
Validation loss: 2.3199328581492105

Epoch: 6| Step: 8
Training loss: 1.3881866931915283
Validation loss: 2.27777091662089

Epoch: 6| Step: 9
Training loss: 1.1509090662002563
Validation loss: 2.2903518676757812

Epoch: 6| Step: 10
Training loss: 0.7892744541168213
Validation loss: 2.2338327169418335

Epoch: 6| Step: 11
Training loss: 1.1734592914581299
Validation loss: 2.2553756634394326

Epoch: 6| Step: 12
Training loss: 0.7671585083007812
Validation loss: 2.2680978775024414

Epoch: 6| Step: 13
Training loss: 0.6959708333015442
Validation loss: 2.2602769136428833

Epoch: 445| Step: 0
Training loss: 1.5814647674560547
Validation loss: 2.2459046443303428

Epoch: 6| Step: 1
Training loss: 0.6810521483421326
Validation loss: 2.24691379070282

Epoch: 6| Step: 2
Training loss: 1.1153936386108398
Validation loss: 2.251841445763906

Epoch: 6| Step: 3
Training loss: 1.150686264038086
Validation loss: 2.290467123190562

Epoch: 6| Step: 4
Training loss: 1.2903251647949219
Validation loss: 2.2460009654363

Epoch: 6| Step: 5
Training loss: 0.6762786507606506
Validation loss: 2.2384182612101235

Epoch: 6| Step: 6
Training loss: 0.8563095331192017
Validation loss: 2.23498406012853

Epoch: 6| Step: 7
Training loss: 0.851017951965332
Validation loss: 2.258111913998922

Epoch: 6| Step: 8
Training loss: 0.8745761513710022
Validation loss: 2.264634072780609

Epoch: 6| Step: 9
Training loss: 0.8217654228210449
Validation loss: 2.2955665588378906

Epoch: 6| Step: 10
Training loss: 0.655541181564331
Validation loss: 2.2619916995366416

Epoch: 6| Step: 11
Training loss: 1.0766605138778687
Validation loss: 2.2831042210261026

Epoch: 6| Step: 12
Training loss: 0.8656868934631348
Validation loss: 2.2710824807484946

Epoch: 6| Step: 13
Training loss: 0.8616364598274231
Validation loss: 2.301761507987976

Epoch: 446| Step: 0
Training loss: 1.2449754476547241
Validation loss: 2.259010831514994

Epoch: 6| Step: 1
Training loss: 0.6281747817993164
Validation loss: 2.297059734662374

Epoch: 6| Step: 2
Training loss: 0.7638672590255737
Validation loss: 2.2875356872876487

Epoch: 6| Step: 3
Training loss: 0.9681475758552551
Validation loss: 2.2626877228418985

Epoch: 6| Step: 4
Training loss: 0.6431689858436584
Validation loss: 2.2176498572031655

Epoch: 6| Step: 5
Training loss: 0.9988172650337219
Validation loss: 2.246360103289286

Epoch: 6| Step: 6
Training loss: 1.0306928157806396
Validation loss: 2.2168505986531577

Epoch: 6| Step: 7
Training loss: 0.843315839767456
Validation loss: 2.2626694440841675

Epoch: 6| Step: 8
Training loss: 1.4479509592056274
Validation loss: 2.2469735741615295

Epoch: 6| Step: 9
Training loss: 0.961702823638916
Validation loss: 2.2581551472345986

Epoch: 6| Step: 10
Training loss: 0.701007068157196
Validation loss: 2.272366007169088

Epoch: 6| Step: 11
Training loss: 0.7949705719947815
Validation loss: 2.2759896715482077

Epoch: 6| Step: 12
Training loss: 1.2111737728118896
Validation loss: 2.2291919390360513

Epoch: 6| Step: 13
Training loss: 1.3520516157150269
Validation loss: 2.2769591013590493

Epoch: 447| Step: 0
Training loss: 0.7349390983581543
Validation loss: 2.2532063325246177

Epoch: 6| Step: 1
Training loss: 1.0051493644714355
Validation loss: 2.2709544897079468

Epoch: 6| Step: 2
Training loss: 0.6915192604064941
Validation loss: 2.2781522472699485

Epoch: 6| Step: 3
Training loss: 0.855563759803772
Validation loss: 2.2504553397496543

Epoch: 6| Step: 4
Training loss: 1.4530302286148071
Validation loss: 2.2551539540290833

Epoch: 6| Step: 5
Training loss: 1.4550024271011353
Validation loss: 2.299683153629303

Epoch: 6| Step: 6
Training loss: 0.4412330985069275
Validation loss: 2.3064000606536865

Epoch: 6| Step: 7
Training loss: 1.102622389793396
Validation loss: 2.2728376984596252

Epoch: 6| Step: 8
Training loss: 0.6964906454086304
Validation loss: 2.2650585770606995

Epoch: 6| Step: 9
Training loss: 0.8523227572441101
Validation loss: 2.2423181533813477

Epoch: 6| Step: 10
Training loss: 0.7560607194900513
Validation loss: 2.2468426624933877

Epoch: 6| Step: 11
Training loss: 0.6477924585342407
Validation loss: 2.2674713333447776

Epoch: 6| Step: 12
Training loss: 1.344968318939209
Validation loss: 2.2708779176076255

Epoch: 6| Step: 13
Training loss: 1.802933692932129
Validation loss: 2.2702074448267617

Epoch: 448| Step: 0
Training loss: 0.7685517072677612
Validation loss: 2.24236798286438

Epoch: 6| Step: 1
Training loss: 0.9727959632873535
Validation loss: 2.2704078356424966

Epoch: 6| Step: 2
Training loss: 0.769542396068573
Validation loss: 2.293509523073832

Epoch: 6| Step: 3
Training loss: 0.626985490322113
Validation loss: 2.307809750239054

Epoch: 6| Step: 4
Training loss: 1.319116234779358
Validation loss: 2.3142306407292685

Epoch: 6| Step: 5
Training loss: 1.0054807662963867
Validation loss: 2.305753548940023

Epoch: 6| Step: 6
Training loss: 0.9490265846252441
Validation loss: 2.320046305656433

Epoch: 6| Step: 7
Training loss: 1.1894643306732178
Validation loss: 2.295165459314982

Epoch: 6| Step: 8
Training loss: 1.293644905090332
Validation loss: 2.3025053342183432

Epoch: 6| Step: 9
Training loss: 0.6285268068313599
Validation loss: 2.2827601035435996

Epoch: 6| Step: 10
Training loss: 0.7964854836463928
Validation loss: 2.3503077824910483

Epoch: 6| Step: 11
Training loss: 0.8477247357368469
Validation loss: 2.2796088059743247

Epoch: 6| Step: 12
Training loss: 0.4072956442832947
Validation loss: 2.2955859502156577

Epoch: 6| Step: 13
Training loss: 1.378205418586731
Validation loss: 2.300310969352722

Epoch: 449| Step: 0
Training loss: 0.8682207465171814
Validation loss: 2.2855813105901084

Epoch: 6| Step: 1
Training loss: 1.150214672088623
Validation loss: 2.271992802619934

Epoch: 6| Step: 2
Training loss: 1.4392852783203125
Validation loss: 2.312577406565348

Epoch: 6| Step: 3
Training loss: 1.1446996927261353
Validation loss: 2.2848873138427734

Epoch: 6| Step: 4
Training loss: 1.0878608226776123
Validation loss: 2.2658386826515198

Epoch: 6| Step: 5
Training loss: 1.240483045578003
Validation loss: 2.30562686920166

Epoch: 6| Step: 6
Training loss: 0.8917819261550903
Validation loss: 2.286237875620524

Epoch: 6| Step: 7
Training loss: 1.0120222568511963
Validation loss: 2.290037969748179

Epoch: 6| Step: 8
Training loss: 0.7002114653587341
Validation loss: 2.289024511973063

Epoch: 6| Step: 9
Training loss: 0.6033143997192383
Validation loss: 2.263064165910085

Epoch: 6| Step: 10
Training loss: 0.47520750761032104
Validation loss: 2.288372019926707

Epoch: 6| Step: 11
Training loss: 0.7089962363243103
Validation loss: 2.287022133668264

Epoch: 6| Step: 12
Training loss: 0.848000168800354
Validation loss: 2.2568767070770264

Epoch: 6| Step: 13
Training loss: 0.9502200484275818
Validation loss: 2.2876859108606973

Epoch: 450| Step: 0
Training loss: 0.7054216861724854
Validation loss: 2.2975281476974487

Epoch: 6| Step: 1
Training loss: 0.5267553329467773
Validation loss: 2.3156633774439492

Epoch: 6| Step: 2
Training loss: 0.6638625264167786
Validation loss: 2.3061484495798745

Epoch: 6| Step: 3
Training loss: 1.6320805549621582
Validation loss: 2.285315215587616

Epoch: 6| Step: 4
Training loss: 0.7075037956237793
Validation loss: 2.291299343109131

Epoch: 6| Step: 5
Training loss: 1.1408803462982178
Validation loss: 2.271268367767334

Epoch: 6| Step: 6
Training loss: 0.8569521307945251
Validation loss: 2.2740501364072165

Epoch: 6| Step: 7
Training loss: 0.776546835899353
Validation loss: 2.298360029856364

Epoch: 6| Step: 8
Training loss: 0.50847327709198
Validation loss: 2.264796276887258

Epoch: 6| Step: 9
Training loss: 0.9232257604598999
Validation loss: 2.2501376469930015

Epoch: 6| Step: 10
Training loss: 0.7174093723297119
Validation loss: 2.3018413186073303

Epoch: 6| Step: 11
Training loss: 1.3670188188552856
Validation loss: 2.286846935749054

Epoch: 6| Step: 12
Training loss: 0.9141761064529419
Validation loss: 2.2620488007863364

Epoch: 6| Step: 13
Training loss: 1.4127434492111206
Validation loss: 2.277997533480326

Epoch: 451| Step: 0
Training loss: 0.9201124906539917
Validation loss: 2.2923744122187295

Epoch: 6| Step: 1
Training loss: 0.5587865114212036
Validation loss: 2.2745076616605124

Epoch: 6| Step: 2
Training loss: 0.894091784954071
Validation loss: 2.2909297545750937

Epoch: 6| Step: 3
Training loss: 1.4052588939666748
Validation loss: 2.2804813186327615

Epoch: 6| Step: 4
Training loss: 1.1584827899932861
Validation loss: 2.273217260837555

Epoch: 6| Step: 5
Training loss: 0.34061264991760254
Validation loss: 2.2891528010368347

Epoch: 6| Step: 6
Training loss: 1.1842080354690552
Validation loss: 2.319732387860616

Epoch: 6| Step: 7
Training loss: 0.9524628520011902
Validation loss: 2.2507609526316323

Epoch: 6| Step: 8
Training loss: 1.4817276000976562
Validation loss: 2.262424111366272

Epoch: 6| Step: 9
Training loss: 0.7595539093017578
Validation loss: 2.2736927270889282

Epoch: 6| Step: 10
Training loss: 1.2338063716888428
Validation loss: 2.2949724197387695

Epoch: 6| Step: 11
Training loss: 0.8526915907859802
Validation loss: 2.2746126850446067

Epoch: 6| Step: 12
Training loss: 0.9647420644760132
Validation loss: 2.3098293344179788

Epoch: 6| Step: 13
Training loss: 0.2811935544013977
Validation loss: 2.311652739842733

Epoch: 452| Step: 0
Training loss: 1.435592532157898
Validation loss: 2.3095779418945312

Epoch: 6| Step: 1
Training loss: 0.6535283327102661
Validation loss: 2.285281221071879

Epoch: 6| Step: 2
Training loss: 1.0472936630249023
Validation loss: 2.316669225692749

Epoch: 6| Step: 3
Training loss: 0.9743640422821045
Validation loss: 2.2604755957921348

Epoch: 6| Step: 4
Training loss: 0.7135067582130432
Validation loss: 2.284779369831085

Epoch: 6| Step: 5
Training loss: 1.1999881267547607
Validation loss: 2.324178457260132

Epoch: 6| Step: 6
Training loss: 0.7848691344261169
Validation loss: 2.2977182070414224

Epoch: 6| Step: 7
Training loss: 0.7422769069671631
Validation loss: 2.3064958651860556

Epoch: 6| Step: 8
Training loss: 1.0433461666107178
Validation loss: 2.3512744903564453

Epoch: 6| Step: 9
Training loss: 1.0074044466018677
Validation loss: 2.3516369263331094

Epoch: 6| Step: 10
Training loss: 1.059084177017212
Validation loss: 2.320374766985575

Epoch: 6| Step: 11
Training loss: 0.5936915278434753
Validation loss: 2.3279091119766235

Epoch: 6| Step: 12
Training loss: 0.8185589909553528
Validation loss: 2.345935026804606

Epoch: 6| Step: 13
Training loss: 0.9929748773574829
Validation loss: 2.3151546319325766

Epoch: 453| Step: 0
Training loss: 0.512955904006958
Validation loss: 2.2985878586769104

Epoch: 6| Step: 1
Training loss: 0.676314651966095
Validation loss: 2.2976537148157754

Epoch: 6| Step: 2
Training loss: 1.8269671201705933
Validation loss: 2.322207530339559

Epoch: 6| Step: 3
Training loss: 1.1408313512802124
Validation loss: 2.321276843547821

Epoch: 6| Step: 4
Training loss: 1.1408050060272217
Validation loss: 2.3351685802141824

Epoch: 6| Step: 5
Training loss: 1.037888526916504
Validation loss: 2.2262712121009827

Epoch: 6| Step: 6
Training loss: 0.9374435544013977
Validation loss: 2.287167251110077

Epoch: 6| Step: 7
Training loss: 0.9778279662132263
Validation loss: 2.2555344104766846

Epoch: 6| Step: 8
Training loss: 0.4507037401199341
Validation loss: 2.2884831627209983

Epoch: 6| Step: 9
Training loss: 0.9933661222457886
Validation loss: 2.243818720181783

Epoch: 6| Step: 10
Training loss: 0.8470206260681152
Validation loss: 2.3054631551106772

Epoch: 6| Step: 11
Training loss: 1.4800045490264893
Validation loss: 2.295699199040731

Epoch: 6| Step: 12
Training loss: 0.7018758058547974
Validation loss: 2.277253031730652

Epoch: 6| Step: 13
Training loss: 0.5626572966575623
Validation loss: 2.267658531665802

Epoch: 454| Step: 0
Training loss: 1.3046296834945679
Validation loss: 2.2525484760602317

Epoch: 6| Step: 1
Training loss: 0.9676267504692078
Validation loss: 2.2550970117251077

Epoch: 6| Step: 2
Training loss: 0.7709148526191711
Validation loss: 2.275468091169993

Epoch: 6| Step: 3
Training loss: 0.6048794984817505
Validation loss: 2.30095237493515

Epoch: 6| Step: 4
Training loss: 1.1791719198226929
Validation loss: 2.303675810496012

Epoch: 6| Step: 5
Training loss: 1.45881986618042
Validation loss: 2.3234699964523315

Epoch: 6| Step: 6
Training loss: 0.8996955156326294
Validation loss: 2.2874046564102173

Epoch: 6| Step: 7
Training loss: 0.6638719439506531
Validation loss: 2.298677086830139

Epoch: 6| Step: 8
Training loss: 1.3838552236557007
Validation loss: 2.3176653583844504

Epoch: 6| Step: 9
Training loss: 1.2125182151794434
Validation loss: 2.2953925927480063

Epoch: 6| Step: 10
Training loss: 0.8075921535491943
Validation loss: 2.3110198974609375

Epoch: 6| Step: 11
Training loss: 0.3927328586578369
Validation loss: 2.3042748967806497

Epoch: 6| Step: 12
Training loss: 0.658051609992981
Validation loss: 2.315338969230652

Epoch: 6| Step: 13
Training loss: 1.3335822820663452
Validation loss: 2.2915335496266684

Epoch: 455| Step: 0
Training loss: 0.4790456295013428
Validation loss: 2.269541382789612

Epoch: 6| Step: 1
Training loss: 1.4491629600524902
Validation loss: 2.3208643794059753

Epoch: 6| Step: 2
Training loss: 1.208945631980896
Validation loss: 2.30172199010849

Epoch: 6| Step: 3
Training loss: 0.6677942276000977
Validation loss: 2.271948059399923

Epoch: 6| Step: 4
Training loss: 1.0367870330810547
Validation loss: 2.294025103251139

Epoch: 6| Step: 5
Training loss: 1.0863182544708252
Validation loss: 2.344082474708557

Epoch: 6| Step: 6
Training loss: 1.3248143196105957
Validation loss: 2.2754793564478555

Epoch: 6| Step: 7
Training loss: 0.5855270624160767
Validation loss: 2.2612164417902627

Epoch: 6| Step: 8
Training loss: 0.6700476408004761
Validation loss: 2.328073581059774

Epoch: 6| Step: 9
Training loss: 0.9812371134757996
Validation loss: 2.317289113998413

Epoch: 6| Step: 10
Training loss: 1.2693138122558594
Validation loss: 2.305648922920227

Epoch: 6| Step: 11
Training loss: 1.2112081050872803
Validation loss: 2.2961795926094055

Epoch: 6| Step: 12
Training loss: 0.6334360837936401
Validation loss: 2.319278041521708

Epoch: 6| Step: 13
Training loss: 0.6070520877838135
Validation loss: 2.3068482478459678

Epoch: 456| Step: 0
Training loss: 1.684132695198059
Validation loss: 2.2952773571014404

Epoch: 6| Step: 1
Training loss: 0.9936971664428711
Validation loss: 2.3134629329045615

Epoch: 6| Step: 2
Training loss: 0.9107121229171753
Validation loss: 2.3049389521280923

Epoch: 6| Step: 3
Training loss: 0.6525856256484985
Validation loss: 2.325092693169912

Epoch: 6| Step: 4
Training loss: 1.2583510875701904
Validation loss: 2.339800496896108

Epoch: 6| Step: 5
Training loss: 0.5631039142608643
Validation loss: 2.3338308731714883

Epoch: 6| Step: 6
Training loss: 0.5622373819351196
Validation loss: 2.2872517108917236

Epoch: 6| Step: 7
Training loss: 0.8007312417030334
Validation loss: 2.31807678937912

Epoch: 6| Step: 8
Training loss: 1.2024964094161987
Validation loss: 2.2360538244247437

Epoch: 6| Step: 9
Training loss: 1.0149521827697754
Validation loss: 2.283644219239553

Epoch: 6| Step: 10
Training loss: 0.5033689141273499
Validation loss: 2.310218930244446

Epoch: 6| Step: 11
Training loss: 0.6749224662780762
Validation loss: 2.2922895550727844

Epoch: 6| Step: 12
Training loss: 1.1601874828338623
Validation loss: 2.254258314768473

Epoch: 6| Step: 13
Training loss: 1.1644060611724854
Validation loss: 2.2770744363466897

Epoch: 457| Step: 0
Training loss: 1.1347342729568481
Validation loss: 2.27971617380778

Epoch: 6| Step: 1
Training loss: 0.4975239336490631
Validation loss: 2.2554683883984885

Epoch: 6| Step: 2
Training loss: 0.5479164123535156
Validation loss: 2.3147496382395425

Epoch: 6| Step: 3
Training loss: 1.1922340393066406
Validation loss: 2.286872386932373

Epoch: 6| Step: 4
Training loss: 1.1594789028167725
Validation loss: 2.2770383954048157

Epoch: 6| Step: 5
Training loss: 0.9363516569137573
Validation loss: 2.272239704926809

Epoch: 6| Step: 6
Training loss: 0.9124019742012024
Validation loss: 2.332124431927999

Epoch: 6| Step: 7
Training loss: 0.5624046325683594
Validation loss: 2.294930577278137

Epoch: 6| Step: 8
Training loss: 0.2546193301677704
Validation loss: 2.253784934679667

Epoch: 6| Step: 9
Training loss: 0.928721010684967
Validation loss: 2.295937101046244

Epoch: 6| Step: 10
Training loss: 0.7833374738693237
Validation loss: 2.2594168186187744

Epoch: 6| Step: 11
Training loss: 1.5008842945098877
Validation loss: 2.3190245032310486

Epoch: 6| Step: 12
Training loss: 1.136898398399353
Validation loss: 2.2927759488423667

Epoch: 6| Step: 13
Training loss: 0.9664757251739502
Validation loss: 2.318926771481832

Epoch: 458| Step: 0
Training loss: 0.6337395906448364
Validation loss: 2.2771111726760864

Epoch: 6| Step: 1
Training loss: 0.8266337513923645
Validation loss: 2.2850586970647178

Epoch: 6| Step: 2
Training loss: 0.5692777633666992
Validation loss: 2.2857060631116233

Epoch: 6| Step: 3
Training loss: 0.6575443744659424
Validation loss: 2.287474771340688

Epoch: 6| Step: 4
Training loss: 0.9423747658729553
Validation loss: 2.279636283715566

Epoch: 6| Step: 5
Training loss: 0.4647882878780365
Validation loss: 2.2261133988698325

Epoch: 6| Step: 6
Training loss: 1.080353856086731
Validation loss: 2.2658697168032327

Epoch: 6| Step: 7
Training loss: 1.6403969526290894
Validation loss: 2.2793012857437134

Epoch: 6| Step: 8
Training loss: 1.4077527523040771
Validation loss: 2.2820005814234414

Epoch: 6| Step: 9
Training loss: 0.6974238753318787
Validation loss: 2.2252442638079324

Epoch: 6| Step: 10
Training loss: 0.9395924210548401
Validation loss: 2.237931410471598

Epoch: 6| Step: 11
Training loss: 1.0804191827774048
Validation loss: 2.3314932783444724

Epoch: 6| Step: 12
Training loss: 0.6268355846405029
Validation loss: 2.281213641166687

Epoch: 6| Step: 13
Training loss: 1.1090420484542847
Validation loss: 2.2862228552500405

Epoch: 459| Step: 0
Training loss: 1.4112743139266968
Validation loss: 2.2879526615142822

Epoch: 6| Step: 1
Training loss: 0.6842930316925049
Validation loss: 2.278789142767588

Epoch: 6| Step: 2
Training loss: 0.37588709592819214
Validation loss: 2.3145427107810974

Epoch: 6| Step: 3
Training loss: 1.191612958908081
Validation loss: 2.2700613737106323

Epoch: 6| Step: 4
Training loss: 0.990028977394104
Validation loss: 2.2547053893407187

Epoch: 6| Step: 5
Training loss: 1.10812509059906
Validation loss: 2.313209354877472

Epoch: 6| Step: 6
Training loss: 0.6560643911361694
Validation loss: 2.287855645020803

Epoch: 6| Step: 7
Training loss: 0.7690922021865845
Validation loss: 2.2517693042755127

Epoch: 6| Step: 8
Training loss: 0.9154446125030518
Validation loss: 2.2911434173583984

Epoch: 6| Step: 9
Training loss: 1.0192186832427979
Validation loss: 2.2901095946629844

Epoch: 6| Step: 10
Training loss: 0.7401939630508423
Validation loss: 2.293168385823568

Epoch: 6| Step: 11
Training loss: 1.5657849311828613
Validation loss: 2.2584847609202066

Epoch: 6| Step: 12
Training loss: 0.5754427909851074
Validation loss: 2.3252158562342324

Epoch: 6| Step: 13
Training loss: 0.9680726528167725
Validation loss: 2.3018444379170737

Epoch: 460| Step: 0
Training loss: 0.6354035139083862
Validation loss: 2.3087308605511985

Epoch: 6| Step: 1
Training loss: 1.1994218826293945
Validation loss: 2.2914183735847473

Epoch: 6| Step: 2
Training loss: 0.47553586959838867
Validation loss: 2.2924062609672546

Epoch: 6| Step: 3
Training loss: 0.9197018146514893
Validation loss: 2.2946210702260337

Epoch: 6| Step: 4
Training loss: 0.709743320941925
Validation loss: 2.324842850367228

Epoch: 6| Step: 5
Training loss: 1.6821300983428955
Validation loss: 2.30800324678421

Epoch: 6| Step: 6
Training loss: 1.2329481840133667
Validation loss: 2.2824438214302063

Epoch: 6| Step: 7
Training loss: 0.5673786997795105
Validation loss: 2.287941634654999

Epoch: 6| Step: 8
Training loss: 1.6173641681671143
Validation loss: 2.2880569299062095

Epoch: 6| Step: 9
Training loss: 1.0490241050720215
Validation loss: 2.3472583293914795

Epoch: 6| Step: 10
Training loss: 0.6304380297660828
Validation loss: 2.3424906531969705

Epoch: 6| Step: 11
Training loss: 0.6706752181053162
Validation loss: 2.342061618963877

Epoch: 6| Step: 12
Training loss: 0.9242241382598877
Validation loss: 2.3596189816792807

Epoch: 6| Step: 13
Training loss: 0.8300420045852661
Validation loss: 2.2779390017191568

Epoch: 461| Step: 0
Training loss: 0.9865357875823975
Validation loss: 2.310108760992686

Epoch: 6| Step: 1
Training loss: 0.5073941349983215
Validation loss: 2.333993395169576

Epoch: 6| Step: 2
Training loss: 0.4994165003299713
Validation loss: 2.3390236298243203

Epoch: 6| Step: 3
Training loss: 1.340787649154663
Validation loss: 2.2883188923199973

Epoch: 6| Step: 4
Training loss: 0.8929457664489746
Validation loss: 2.323711395263672

Epoch: 6| Step: 5
Training loss: 1.409314751625061
Validation loss: 2.3164312640825906

Epoch: 6| Step: 6
Training loss: 1.3642578125
Validation loss: 2.287586212158203

Epoch: 6| Step: 7
Training loss: 0.7113957405090332
Validation loss: 2.3525347113609314

Epoch: 6| Step: 8
Training loss: 1.2430932521820068
Validation loss: 2.2881242434183755

Epoch: 6| Step: 9
Training loss: 0.9116975665092468
Validation loss: 2.362411061922709

Epoch: 6| Step: 10
Training loss: 0.7131396532058716
Validation loss: 2.3356430729230246

Epoch: 6| Step: 11
Training loss: 0.639724612236023
Validation loss: 2.3305763800938926

Epoch: 6| Step: 12
Training loss: 0.5240898728370667
Validation loss: 2.2673043807347617

Epoch: 6| Step: 13
Training loss: 0.6448186635971069
Validation loss: 2.3128512700398765

Epoch: 462| Step: 0
Training loss: 0.3597143888473511
Validation loss: 2.281748195489248

Epoch: 6| Step: 1
Training loss: 0.6498833894729614
Validation loss: 2.3414686918258667

Epoch: 6| Step: 2
Training loss: 0.7316287755966187
Validation loss: 2.315533677736918

Epoch: 6| Step: 3
Training loss: 0.8348170518875122
Validation loss: 2.307102620601654

Epoch: 6| Step: 4
Training loss: 1.0431259870529175
Validation loss: 2.2942853768666587

Epoch: 6| Step: 5
Training loss: 0.5018033981323242
Validation loss: 2.2932763497034707

Epoch: 6| Step: 6
Training loss: 1.7914938926696777
Validation loss: 2.2746037244796753

Epoch: 6| Step: 7
Training loss: 1.088571310043335
Validation loss: 2.250657538572947

Epoch: 6| Step: 8
Training loss: 0.8641543388366699
Validation loss: 2.3214720090230307

Epoch: 6| Step: 9
Training loss: 1.1838864088058472
Validation loss: 2.2929683128992715

Epoch: 6| Step: 10
Training loss: 1.52791166305542
Validation loss: 2.3208751877148948

Epoch: 6| Step: 11
Training loss: 0.5536078810691833
Validation loss: 2.2678860823313394

Epoch: 6| Step: 12
Training loss: 0.472148060798645
Validation loss: 2.3368107080459595

Epoch: 6| Step: 13
Training loss: 0.9828639030456543
Validation loss: 2.278630256652832

Epoch: 463| Step: 0
Training loss: 1.034283995628357
Validation loss: 2.3034164110819497

Epoch: 6| Step: 1
Training loss: 0.7953455448150635
Validation loss: 2.297808905442556

Epoch: 6| Step: 2
Training loss: 0.3603818416595459
Validation loss: 2.3004585107167563

Epoch: 6| Step: 3
Training loss: 0.770351767539978
Validation loss: 2.279028375943502

Epoch: 6| Step: 4
Training loss: 0.9275615215301514
Validation loss: 2.2944225072860718

Epoch: 6| Step: 5
Training loss: 0.9383769035339355
Validation loss: 2.2945018808046975

Epoch: 6| Step: 6
Training loss: 1.0091837644577026
Validation loss: 2.312748928864797

Epoch: 6| Step: 7
Training loss: 0.6092955470085144
Validation loss: 2.358963668346405

Epoch: 6| Step: 8
Training loss: 0.610669732093811
Validation loss: 2.29905500014623

Epoch: 6| Step: 9
Training loss: 0.7459520101547241
Validation loss: 2.3071980675061545

Epoch: 6| Step: 10
Training loss: 1.3943307399749756
Validation loss: 2.3027170697848

Epoch: 6| Step: 11
Training loss: 1.6809929609298706
Validation loss: 2.3131370544433594

Epoch: 6| Step: 12
Training loss: 0.35111358761787415
Validation loss: 2.3336862524350486

Epoch: 6| Step: 13
Training loss: 1.2641373872756958
Validation loss: 2.3210196097691855

Epoch: 464| Step: 0
Training loss: 0.3211038112640381
Validation loss: 2.32956200838089

Epoch: 6| Step: 1
Training loss: 1.0963236093521118
Validation loss: 2.3322762648264566

Epoch: 6| Step: 2
Training loss: 0.979864239692688
Validation loss: 2.3265151977539062

Epoch: 6| Step: 3
Training loss: 0.5253981947898865
Validation loss: 2.3249545097351074

Epoch: 6| Step: 4
Training loss: 0.7038090229034424
Validation loss: 2.3409132758776345

Epoch: 6| Step: 5
Training loss: 0.745421290397644
Validation loss: 2.3673960169156394

Epoch: 6| Step: 6
Training loss: 1.594452142715454
Validation loss: 2.280039111773173

Epoch: 6| Step: 7
Training loss: 1.0098296403884888
Validation loss: 2.296754995981852

Epoch: 6| Step: 8
Training loss: 1.5180373191833496
Validation loss: 2.3088573217391968

Epoch: 6| Step: 9
Training loss: 1.2300622463226318
Validation loss: 2.260759631792704

Epoch: 6| Step: 10
Training loss: 1.116922378540039
Validation loss: 2.2598974307378135

Epoch: 6| Step: 11
Training loss: 0.6966296434402466
Validation loss: 2.2641156117121377

Epoch: 6| Step: 12
Training loss: 1.0272470712661743
Validation loss: 2.295168618361155

Epoch: 6| Step: 13
Training loss: 1.0089285373687744
Validation loss: 2.2530741492907205

Epoch: 465| Step: 0
Training loss: 0.7631784677505493
Validation loss: 2.3009016712506614

Epoch: 6| Step: 1
Training loss: 1.02822744846344
Validation loss: 2.3097408215204873

Epoch: 6| Step: 2
Training loss: 1.0914058685302734
Validation loss: 2.2915087938308716

Epoch: 6| Step: 3
Training loss: 1.260402798652649
Validation loss: 2.293731927871704

Epoch: 6| Step: 4
Training loss: 1.213395118713379
Validation loss: 2.335946480433146

Epoch: 6| Step: 5
Training loss: 0.8312793970108032
Validation loss: 2.3454649845759072

Epoch: 6| Step: 6
Training loss: 0.9696452617645264
Validation loss: 2.3554017543792725

Epoch: 6| Step: 7
Training loss: 0.6249455213546753
Validation loss: 2.3161544799804688

Epoch: 6| Step: 8
Training loss: 1.296069622039795
Validation loss: 2.303028643131256

Epoch: 6| Step: 9
Training loss: 0.8180223107337952
Validation loss: 2.3476884365081787

Epoch: 6| Step: 10
Training loss: 0.8037927746772766
Validation loss: 2.371376077334086

Epoch: 6| Step: 11
Training loss: 0.9315534234046936
Validation loss: 2.3464708725611367

Epoch: 6| Step: 12
Training loss: 0.39916282892227173
Validation loss: 2.340201814969381

Epoch: 6| Step: 13
Training loss: 1.13234281539917
Validation loss: 2.3438948591550193

Epoch: 466| Step: 0
Training loss: 1.3359344005584717
Validation loss: 2.3786891301472983

Epoch: 6| Step: 1
Training loss: 0.8964325189590454
Validation loss: 2.3506447275479636

Epoch: 6| Step: 2
Training loss: 0.6712530255317688
Validation loss: 2.3443650801976523

Epoch: 6| Step: 3
Training loss: 0.6902755498886108
Validation loss: 2.314971923828125

Epoch: 6| Step: 4
Training loss: 0.6417576670646667
Validation loss: 2.3328312635421753

Epoch: 6| Step: 5
Training loss: 0.7729661464691162
Validation loss: 2.3379671573638916

Epoch: 6| Step: 6
Training loss: 0.9187721610069275
Validation loss: 2.285812338193258

Epoch: 6| Step: 7
Training loss: 1.3213450908660889
Validation loss: 2.2812276681264243

Epoch: 6| Step: 8
Training loss: 0.9691711664199829
Validation loss: 2.3508704900741577

Epoch: 6| Step: 9
Training loss: 1.1691020727157593
Validation loss: 2.345980405807495

Epoch: 6| Step: 10
Training loss: 0.5821492075920105
Validation loss: 2.3152345617612204

Epoch: 6| Step: 11
Training loss: 1.164281964302063
Validation loss: 2.2879083355267844

Epoch: 6| Step: 12
Training loss: 0.570044994354248
Validation loss: 2.3211912711461387

Epoch: 6| Step: 13
Training loss: 0.9474873542785645
Validation loss: 2.311198353767395

Epoch: 467| Step: 0
Training loss: 0.3562988042831421
Validation loss: 2.3370126684506736

Epoch: 6| Step: 1
Training loss: 0.9583041667938232
Validation loss: 2.331894119580587

Epoch: 6| Step: 2
Training loss: 1.1133133172988892
Validation loss: 2.279192785422007

Epoch: 6| Step: 3
Training loss: 0.4968387484550476
Validation loss: 2.3145851691563926

Epoch: 6| Step: 4
Training loss: 1.151719331741333
Validation loss: 2.303072174390157

Epoch: 6| Step: 5
Training loss: 1.1550441980361938
Validation loss: 2.324496567249298

Epoch: 6| Step: 6
Training loss: 0.8403438925743103
Validation loss: 2.3200161854426065

Epoch: 6| Step: 7
Training loss: 0.8475320935249329
Validation loss: 2.311657746632894

Epoch: 6| Step: 8
Training loss: 0.5975198745727539
Validation loss: 2.2751269340515137

Epoch: 6| Step: 9
Training loss: 1.4577664136886597
Validation loss: 2.292335251967112

Epoch: 6| Step: 10
Training loss: 1.0055830478668213
Validation loss: 2.312518278757731

Epoch: 6| Step: 11
Training loss: 0.7141975164413452
Validation loss: 2.322458485762278

Epoch: 6| Step: 12
Training loss: 0.6587294340133667
Validation loss: 2.3362842798233032

Epoch: 6| Step: 13
Training loss: 0.8682541847229004
Validation loss: 2.2744466066360474

Epoch: 468| Step: 0
Training loss: 0.5692840218544006
Validation loss: 2.2759326100349426

Epoch: 6| Step: 1
Training loss: 1.0403934717178345
Validation loss: 2.320383052031199

Epoch: 6| Step: 2
Training loss: 0.677336573600769
Validation loss: 2.284459332625071

Epoch: 6| Step: 3
Training loss: 1.232757806777954
Validation loss: 2.3023144006729126

Epoch: 6| Step: 4
Training loss: 1.4003863334655762
Validation loss: 2.322557806968689

Epoch: 6| Step: 5
Training loss: 0.92547208070755
Validation loss: 2.302718162536621

Epoch: 6| Step: 6
Training loss: 1.360963225364685
Validation loss: 2.299530784289042

Epoch: 6| Step: 7
Training loss: 0.4416394829750061
Validation loss: 2.335296312967936

Epoch: 6| Step: 8
Training loss: 1.0126423835754395
Validation loss: 2.332301616668701

Epoch: 6| Step: 9
Training loss: 0.48415201902389526
Validation loss: 2.30906750758489

Epoch: 6| Step: 10
Training loss: 1.2043671607971191
Validation loss: 2.3107473651568093

Epoch: 6| Step: 11
Training loss: 1.1111644506454468
Validation loss: 2.324363390604655

Epoch: 6| Step: 12
Training loss: 0.8942071199417114
Validation loss: 2.322481155395508

Epoch: 6| Step: 13
Training loss: 0.2922927141189575
Validation loss: 2.3346245686213174

Epoch: 469| Step: 0
Training loss: 1.0695631504058838
Validation loss: 2.280248204867045

Epoch: 6| Step: 1
Training loss: 0.5887604355812073
Validation loss: 2.3229063351949057

Epoch: 6| Step: 2
Training loss: 1.0454516410827637
Validation loss: 2.335185388724009

Epoch: 6| Step: 3
Training loss: 0.9193993210792542
Validation loss: 2.3286590377489724

Epoch: 6| Step: 4
Training loss: 0.9228048324584961
Validation loss: 2.3272422552108765

Epoch: 6| Step: 5
Training loss: 0.4705749452114105
Validation loss: 2.316103935241699

Epoch: 6| Step: 6
Training loss: 0.463069349527359
Validation loss: 2.311798612276713

Epoch: 6| Step: 7
Training loss: 0.895594596862793
Validation loss: 2.338523725668589

Epoch: 6| Step: 8
Training loss: 1.3875453472137451
Validation loss: 2.344934066136678

Epoch: 6| Step: 9
Training loss: 1.02968168258667
Validation loss: 2.335740327835083

Epoch: 6| Step: 10
Training loss: 1.4882258176803589
Validation loss: 2.3254698514938354

Epoch: 6| Step: 11
Training loss: 1.0661630630493164
Validation loss: 2.341925621032715

Epoch: 6| Step: 12
Training loss: 0.7701854705810547
Validation loss: 2.344590663909912

Epoch: 6| Step: 13
Training loss: 0.5032851696014404
Validation loss: 2.286273101965586

Epoch: 470| Step: 0
Training loss: 1.1162097454071045
Validation loss: 2.3454445004463196

Epoch: 6| Step: 1
Training loss: 0.5967839956283569
Validation loss: 2.2985153198242188

Epoch: 6| Step: 2
Training loss: 0.5111826658248901
Validation loss: 2.332766056060791

Epoch: 6| Step: 3
Training loss: 1.3937160968780518
Validation loss: 2.3034239212671914

Epoch: 6| Step: 4
Training loss: 0.7269576787948608
Validation loss: 2.2639914949735007

Epoch: 6| Step: 5
Training loss: 0.655798077583313
Validation loss: 2.2895891467730203

Epoch: 6| Step: 6
Training loss: 1.1180219650268555
Validation loss: 2.342071771621704

Epoch: 6| Step: 7
Training loss: 0.937519371509552
Validation loss: 2.291898787021637

Epoch: 6| Step: 8
Training loss: 0.9194291830062866
Validation loss: 2.340389529863993

Epoch: 6| Step: 9
Training loss: 1.4133036136627197
Validation loss: 2.3626532554626465

Epoch: 6| Step: 10
Training loss: 0.446681946516037
Validation loss: 2.326665918032328

Epoch: 6| Step: 11
Training loss: 1.3915526866912842
Validation loss: 2.297165791193644

Epoch: 6| Step: 12
Training loss: 0.6788368225097656
Validation loss: 2.2959489822387695

Epoch: 6| Step: 13
Training loss: 0.4214642643928528
Validation loss: 2.3016592860221863

Epoch: 471| Step: 0
Training loss: 1.2562344074249268
Validation loss: 2.313525160153707

Epoch: 6| Step: 1
Training loss: 0.6942734718322754
Validation loss: 2.3397640188535056

Epoch: 6| Step: 2
Training loss: 0.809246301651001
Validation loss: 2.3133311669031777

Epoch: 6| Step: 3
Training loss: 0.3357545733451843
Validation loss: 2.3040648301442466

Epoch: 6| Step: 4
Training loss: 0.49661964178085327
Validation loss: 2.283046305179596

Epoch: 6| Step: 5
Training loss: 0.8736094236373901
Validation loss: 2.3186250925064087

Epoch: 6| Step: 6
Training loss: 0.7814795970916748
Validation loss: 2.3316505948702493

Epoch: 6| Step: 7
Training loss: 1.4009289741516113
Validation loss: 2.312688648700714

Epoch: 6| Step: 8
Training loss: 1.108487844467163
Validation loss: 2.32707671324412

Epoch: 6| Step: 9
Training loss: 0.7381763458251953
Validation loss: 2.323542515436808

Epoch: 6| Step: 10
Training loss: 0.8929293751716614
Validation loss: 2.273645361264547

Epoch: 6| Step: 11
Training loss: 1.4913054704666138
Validation loss: 2.291229764620463

Epoch: 6| Step: 12
Training loss: 0.5942220687866211
Validation loss: 2.311343550682068

Epoch: 6| Step: 13
Training loss: 0.9381138682365417
Validation loss: 2.2762675682703652

Epoch: 472| Step: 0
Training loss: 0.46216899156570435
Validation loss: 2.290022393067678

Epoch: 6| Step: 1
Training loss: 1.308900237083435
Validation loss: 2.2786988417307534

Epoch: 6| Step: 2
Training loss: 0.9707136154174805
Validation loss: 2.2756749987602234

Epoch: 6| Step: 3
Training loss: 1.035264015197754
Validation loss: 2.283017714818319

Epoch: 6| Step: 4
Training loss: 0.4379350244998932
Validation loss: 2.331608235836029

Epoch: 6| Step: 5
Training loss: 1.0957802534103394
Validation loss: 2.3071496884028115

Epoch: 6| Step: 6
Training loss: 0.4031803011894226
Validation loss: 2.2723885774612427

Epoch: 6| Step: 7
Training loss: 0.5262274742126465
Validation loss: 2.3063501516977944

Epoch: 6| Step: 8
Training loss: 0.8313131928443909
Validation loss: 2.3135785857836404

Epoch: 6| Step: 9
Training loss: 0.9350655674934387
Validation loss: 2.327265461285909

Epoch: 6| Step: 10
Training loss: 0.6163360476493835
Validation loss: 2.34678985675176

Epoch: 6| Step: 11
Training loss: 1.2283806800842285
Validation loss: 2.283053437868754

Epoch: 6| Step: 12
Training loss: 0.8974189758300781
Validation loss: 2.3006264170010886

Epoch: 6| Step: 13
Training loss: 1.339254379272461
Validation loss: 2.3297191063563027

Epoch: 473| Step: 0
Training loss: 0.7620002031326294
Validation loss: 2.331541121006012

Epoch: 6| Step: 1
Training loss: 0.8784565329551697
Validation loss: 2.3321349223454795

Epoch: 6| Step: 2
Training loss: 0.6509401798248291
Validation loss: 2.2760059436162314

Epoch: 6| Step: 3
Training loss: 0.8673921227455139
Validation loss: 2.294178863366445

Epoch: 6| Step: 4
Training loss: 0.7215709686279297
Validation loss: 2.293648898601532

Epoch: 6| Step: 5
Training loss: 0.8959774374961853
Validation loss: 2.2815305391947427

Epoch: 6| Step: 6
Training loss: 1.378272294998169
Validation loss: 2.2290934522946677

Epoch: 6| Step: 7
Training loss: 0.9502342343330383
Validation loss: 2.2658637364705405

Epoch: 6| Step: 8
Training loss: 0.7424825429916382
Validation loss: 2.2517619530359902

Epoch: 6| Step: 9
Training loss: 0.7880968451499939
Validation loss: 2.2536047101020813

Epoch: 6| Step: 10
Training loss: 1.1505749225616455
Validation loss: 2.2820038199424744

Epoch: 6| Step: 11
Training loss: 0.6567889451980591
Validation loss: 2.27790359656016

Epoch: 6| Step: 12
Training loss: 0.7687530517578125
Validation loss: 2.2612414956092834

Epoch: 6| Step: 13
Training loss: 1.2866495847702026
Validation loss: 2.308216174443563

Epoch: 474| Step: 0
Training loss: 0.4669888913631439
Validation loss: 2.2863744298617044

Epoch: 6| Step: 1
Training loss: 0.5425803065299988
Validation loss: 2.3050672809282937

Epoch: 6| Step: 2
Training loss: 0.5270057916641235
Validation loss: 2.2405478159586587

Epoch: 6| Step: 3
Training loss: 1.4590767621994019
Validation loss: 2.29945041735967

Epoch: 6| Step: 4
Training loss: 1.660300612449646
Validation loss: 2.275478720664978

Epoch: 6| Step: 5
Training loss: 0.6614630222320557
Validation loss: 2.2561618288358054

Epoch: 6| Step: 6
Training loss: 0.6782581806182861
Validation loss: 2.2849052945772805

Epoch: 6| Step: 7
Training loss: 1.1564931869506836
Validation loss: 2.2666581670443215

Epoch: 6| Step: 8
Training loss: 1.130449891090393
Validation loss: 2.2891058325767517

Epoch: 6| Step: 9
Training loss: 0.5963572263717651
Validation loss: 2.284464200337728

Epoch: 6| Step: 10
Training loss: 0.649507999420166
Validation loss: 2.273296316464742

Epoch: 6| Step: 11
Training loss: 1.1745960712432861
Validation loss: 2.2597405314445496

Epoch: 6| Step: 12
Training loss: 0.6681802272796631
Validation loss: 2.30021999279658

Epoch: 6| Step: 13
Training loss: 0.7236407995223999
Validation loss: 2.32643061876297

Epoch: 475| Step: 0
Training loss: 1.9199230670928955
Validation loss: 2.3593791921933494

Epoch: 6| Step: 1
Training loss: 0.8912763595581055
Validation loss: 2.304396311442057

Epoch: 6| Step: 2
Training loss: 0.6667413115501404
Validation loss: 2.3082765340805054

Epoch: 6| Step: 3
Training loss: 1.2883930206298828
Validation loss: 2.2685212095578513

Epoch: 6| Step: 4
Training loss: 0.5021041631698608
Validation loss: 2.311990737915039

Epoch: 6| Step: 5
Training loss: 0.8736725449562073
Validation loss: 2.279269218444824

Epoch: 6| Step: 6
Training loss: 0.3995388150215149
Validation loss: 2.279015223185221

Epoch: 6| Step: 7
Training loss: 1.3090758323669434
Validation loss: 2.305864771207174

Epoch: 6| Step: 8
Training loss: 0.5569287538528442
Validation loss: 2.354608734448751

Epoch: 6| Step: 9
Training loss: 0.9517298936843872
Validation loss: 2.3231216271718345

Epoch: 6| Step: 10
Training loss: 0.8459150791168213
Validation loss: 2.3284950653711953

Epoch: 6| Step: 11
Training loss: 0.404538631439209
Validation loss: 2.2886601289113364

Epoch: 6| Step: 12
Training loss: 0.956333339214325
Validation loss: 2.334103544553121

Epoch: 6| Step: 13
Training loss: 0.6606435775756836
Validation loss: 2.304527739683787

Epoch: 476| Step: 0
Training loss: 0.9888803958892822
Validation loss: 2.344643553098043

Epoch: 6| Step: 1
Training loss: 0.6734793186187744
Validation loss: 2.3125354448954263

Epoch: 6| Step: 2
Training loss: 1.1862441301345825
Validation loss: 2.291172663370768

Epoch: 6| Step: 3
Training loss: 1.1145941019058228
Validation loss: 2.3112889925638833

Epoch: 6| Step: 4
Training loss: 1.1450986862182617
Validation loss: 2.32324210802714

Epoch: 6| Step: 5
Training loss: 1.0133955478668213
Validation loss: 2.336112380027771

Epoch: 6| Step: 6
Training loss: 0.5644381046295166
Validation loss: 2.3068095048268638

Epoch: 6| Step: 7
Training loss: 0.3797500431537628
Validation loss: 2.303371012210846

Epoch: 6| Step: 8
Training loss: 0.8173911571502686
Validation loss: 2.311414579550425

Epoch: 6| Step: 9
Training loss: 0.6648510694503784
Validation loss: 2.2843567530314126

Epoch: 6| Step: 10
Training loss: 0.8560241460800171
Validation loss: 2.306918203830719

Epoch: 6| Step: 11
Training loss: 1.2280502319335938
Validation loss: 2.278813898563385

Epoch: 6| Step: 12
Training loss: 1.0471583604812622
Validation loss: 2.341509381930033

Epoch: 6| Step: 13
Training loss: 0.681032657623291
Validation loss: 2.3334338466326394

Epoch: 477| Step: 0
Training loss: 0.6640007495880127
Validation loss: 2.2564351757367453

Epoch: 6| Step: 1
Training loss: 0.9156401753425598
Validation loss: 2.3112781842549643

Epoch: 6| Step: 2
Training loss: 1.010323166847229
Validation loss: 2.300204078356425

Epoch: 6| Step: 3
Training loss: 0.9192050099372864
Validation loss: 2.3277575969696045

Epoch: 6| Step: 4
Training loss: 1.1809099912643433
Validation loss: 2.3024275302886963

Epoch: 6| Step: 5
Training loss: 0.8547266125679016
Validation loss: 2.3559369643529258

Epoch: 6| Step: 6
Training loss: 0.6049731969833374
Validation loss: 2.297796905040741

Epoch: 6| Step: 7
Training loss: 0.8228329420089722
Validation loss: 2.2619009415308633

Epoch: 6| Step: 8
Training loss: 0.8748743534088135
Validation loss: 2.281351884206136

Epoch: 6| Step: 9
Training loss: 1.2571196556091309
Validation loss: 2.3080634673436484

Epoch: 6| Step: 10
Training loss: 0.5397072434425354
Validation loss: 2.2801068226496377

Epoch: 6| Step: 11
Training loss: 0.9598710536956787
Validation loss: 2.2916666666666665

Epoch: 6| Step: 12
Training loss: 0.7943993210792542
Validation loss: 2.3008984525998435

Epoch: 6| Step: 13
Training loss: 0.7645810842514038
Validation loss: 2.321018656094869

Epoch: 478| Step: 0
Training loss: 1.3012597560882568
Validation loss: 2.287187695503235

Epoch: 6| Step: 1
Training loss: 1.2575864791870117
Validation loss: 2.2469050089518228

Epoch: 6| Step: 2
Training loss: 0.9202592968940735
Validation loss: 2.245128571987152

Epoch: 6| Step: 3
Training loss: 0.9182601571083069
Validation loss: 2.298516829808553

Epoch: 6| Step: 4
Training loss: 1.6515536308288574
Validation loss: 2.290159304936727

Epoch: 6| Step: 5
Training loss: 0.6108200550079346
Validation loss: 2.3394925793011985

Epoch: 6| Step: 6
Training loss: 0.7316884398460388
Validation loss: 2.3517059485117593

Epoch: 6| Step: 7
Training loss: 1.5389900207519531
Validation loss: 2.328155279159546

Epoch: 6| Step: 8
Training loss: 0.9111151099205017
Validation loss: 2.350501457850138

Epoch: 6| Step: 9
Training loss: 0.851852297782898
Validation loss: 2.3207123478253684

Epoch: 6| Step: 10
Training loss: 0.816493034362793
Validation loss: 2.3446995417277017

Epoch: 6| Step: 11
Training loss: 0.5096035599708557
Validation loss: 2.265103042125702

Epoch: 6| Step: 12
Training loss: 0.8907573819160461
Validation loss: 2.317435344060262

Epoch: 6| Step: 13
Training loss: 0.713257372379303
Validation loss: 2.3071011304855347

Epoch: 479| Step: 0
Training loss: 1.2375664710998535
Validation loss: 2.3056416511535645

Epoch: 6| Step: 1
Training loss: 0.9685776829719543
Validation loss: 2.3645315965016684

Epoch: 6| Step: 2
Training loss: 0.6003120541572571
Validation loss: 2.2857179641723633

Epoch: 6| Step: 3
Training loss: 0.8811742067337036
Validation loss: 2.2964613238970437

Epoch: 6| Step: 4
Training loss: 1.0813254117965698
Validation loss: 2.3300299843152366

Epoch: 6| Step: 5
Training loss: 0.8179569840431213
Validation loss: 2.345289329687754

Epoch: 6| Step: 6
Training loss: 0.5779855251312256
Validation loss: 2.303733309110006

Epoch: 6| Step: 7
Training loss: 0.6003817915916443
Validation loss: 2.341520150502523

Epoch: 6| Step: 8
Training loss: 0.7420542240142822
Validation loss: 2.295399765173594

Epoch: 6| Step: 9
Training loss: 0.7914124727249146
Validation loss: 2.328209638595581

Epoch: 6| Step: 10
Training loss: 1.7315826416015625
Validation loss: 2.3452195723851523

Epoch: 6| Step: 11
Training loss: 0.5371395349502563
Validation loss: 2.3129603068033853

Epoch: 6| Step: 12
Training loss: 0.5978707075119019
Validation loss: 2.265660524368286

Epoch: 6| Step: 13
Training loss: 0.7681994438171387
Validation loss: 2.275900403658549

Epoch: 480| Step: 0
Training loss: 0.9354146718978882
Validation loss: 2.303216020266215

Epoch: 6| Step: 1
Training loss: 1.0368221998214722
Validation loss: 2.2713961402575173

Epoch: 6| Step: 2
Training loss: 0.7762216925621033
Validation loss: 2.2576412757237754

Epoch: 6| Step: 3
Training loss: 0.9594513773918152
Validation loss: 2.3272889057795205

Epoch: 6| Step: 4
Training loss: 1.0209808349609375
Validation loss: 2.295460899670919

Epoch: 6| Step: 5
Training loss: 0.5897598266601562
Validation loss: 2.29015052318573

Epoch: 6| Step: 6
Training loss: 0.9098272323608398
Validation loss: 2.2788896958033242

Epoch: 6| Step: 7
Training loss: 0.689109742641449
Validation loss: 2.3356984853744507

Epoch: 6| Step: 8
Training loss: 0.46387583017349243
Validation loss: 2.3076005975405374

Epoch: 6| Step: 9
Training loss: 0.8083481192588806
Validation loss: 2.3124789198239646

Epoch: 6| Step: 10
Training loss: 0.46392980217933655
Validation loss: 2.339795549710592

Epoch: 6| Step: 11
Training loss: 1.1030642986297607
Validation loss: 2.2976009249687195

Epoch: 6| Step: 12
Training loss: 0.6255514621734619
Validation loss: 2.325260639190674

Epoch: 6| Step: 13
Training loss: 1.3475784063339233
Validation loss: 2.2878490487734475

Epoch: 481| Step: 0
Training loss: 0.7967149019241333
Validation loss: 2.3471702337265015

Epoch: 6| Step: 1
Training loss: 0.423860102891922
Validation loss: 2.309451421101888

Epoch: 6| Step: 2
Training loss: 0.771126389503479
Validation loss: 2.328808844089508

Epoch: 6| Step: 3
Training loss: 0.8752139806747437
Validation loss: 2.339236299196879

Epoch: 6| Step: 4
Training loss: 0.7175025939941406
Validation loss: 2.266765216986338

Epoch: 6| Step: 5
Training loss: 0.7339152693748474
Validation loss: 2.311660369237264

Epoch: 6| Step: 6
Training loss: 1.0153276920318604
Validation loss: 2.3588417967160544

Epoch: 6| Step: 7
Training loss: 1.0504276752471924
Validation loss: 2.2834633588790894

Epoch: 6| Step: 8
Training loss: 0.9964975118637085
Validation loss: 2.339065154393514

Epoch: 6| Step: 9
Training loss: 1.3288829326629639
Validation loss: 2.3271780411402383

Epoch: 6| Step: 10
Training loss: 1.009061336517334
Validation loss: 2.291095952192942

Epoch: 6| Step: 11
Training loss: 0.7227246165275574
Validation loss: 2.3210408290227256

Epoch: 6| Step: 12
Training loss: 0.6629918217658997
Validation loss: 2.30704931418101

Epoch: 6| Step: 13
Training loss: 0.67280113697052
Validation loss: 2.3612132469813027

Epoch: 482| Step: 0
Training loss: 0.6798111200332642
Validation loss: 2.2896295388539634

Epoch: 6| Step: 1
Training loss: 0.3894377648830414
Validation loss: 2.3462446530659995

Epoch: 6| Step: 2
Training loss: 0.5086120963096619
Validation loss: 2.3382697900136313

Epoch: 6| Step: 3
Training loss: 0.9143645167350769
Validation loss: 2.3521135648091636

Epoch: 6| Step: 4
Training loss: 1.2805533409118652
Validation loss: 2.307715098063151

Epoch: 6| Step: 5
Training loss: 0.45052146911621094
Validation loss: 2.325225353240967

Epoch: 6| Step: 6
Training loss: 0.7471001148223877
Validation loss: 2.358985702196757

Epoch: 6| Step: 7
Training loss: 0.3530687987804413
Validation loss: 2.378482143084208

Epoch: 6| Step: 8
Training loss: 0.9203346371650696
Validation loss: 2.343833247820536

Epoch: 6| Step: 9
Training loss: 1.2427256107330322
Validation loss: 2.3337851762771606

Epoch: 6| Step: 10
Training loss: 1.4734135866165161
Validation loss: 2.3592119216918945

Epoch: 6| Step: 11
Training loss: 1.0258991718292236
Validation loss: 2.320777416229248

Epoch: 6| Step: 12
Training loss: 0.3064330220222473
Validation loss: 2.341827472050985

Epoch: 6| Step: 13
Training loss: 1.0986342430114746
Validation loss: 2.3343207836151123

Epoch: 483| Step: 0
Training loss: 1.0436779260635376
Validation loss: 2.3608508706092834

Epoch: 6| Step: 1
Training loss: 0.43023771047592163
Validation loss: 2.3037187258402505

Epoch: 6| Step: 2
Training loss: 0.6006109714508057
Validation loss: 2.2751219669977822

Epoch: 6| Step: 3
Training loss: 1.5701563358306885
Validation loss: 2.3169914285341897

Epoch: 6| Step: 4
Training loss: 1.1455562114715576
Validation loss: 2.290107250213623

Epoch: 6| Step: 5
Training loss: 0.6039369106292725
Validation loss: 2.299529949824015

Epoch: 6| Step: 6
Training loss: 0.7185463905334473
Validation loss: 2.2636350790659585

Epoch: 6| Step: 7
Training loss: 0.9432993531227112
Validation loss: 2.2975457906723022

Epoch: 6| Step: 8
Training loss: 0.6712722778320312
Validation loss: 2.3045706748962402

Epoch: 6| Step: 9
Training loss: 0.4844578802585602
Validation loss: 2.3599087794621787

Epoch: 6| Step: 10
Training loss: 0.8637241125106812
Validation loss: 2.3227920532226562

Epoch: 6| Step: 11
Training loss: 0.7001620531082153
Validation loss: 2.3178911606470742

Epoch: 6| Step: 12
Training loss: 0.6636451482772827
Validation loss: 2.3279675443967185

Epoch: 6| Step: 13
Training loss: 1.0602127313613892
Validation loss: 2.329894721508026

Epoch: 484| Step: 0
Training loss: 0.3249821066856384
Validation loss: 2.3412814140319824

Epoch: 6| Step: 1
Training loss: 0.647011399269104
Validation loss: 2.3451656699180603

Epoch: 6| Step: 2
Training loss: 0.4087737500667572
Validation loss: 2.316731552282969

Epoch: 6| Step: 3
Training loss: 0.9051404595375061
Validation loss: 2.2975100676218667

Epoch: 6| Step: 4
Training loss: 0.7325182557106018
Validation loss: 2.3035550912221274

Epoch: 6| Step: 5
Training loss: 1.0194493532180786
Validation loss: 2.3374393383661904

Epoch: 6| Step: 6
Training loss: 1.2258646488189697
Validation loss: 2.3499647974967957

Epoch: 6| Step: 7
Training loss: 0.8016110062599182
Validation loss: 2.324475586414337

Epoch: 6| Step: 8
Training loss: 0.40914884209632874
Validation loss: 2.319887657960256

Epoch: 6| Step: 9
Training loss: 0.5782978534698486
Validation loss: 2.3226378758748374

Epoch: 6| Step: 10
Training loss: 1.1622756719589233
Validation loss: 2.3159987926483154

Epoch: 6| Step: 11
Training loss: 1.0790457725524902
Validation loss: 2.310416499773661

Epoch: 6| Step: 12
Training loss: 0.7081800103187561
Validation loss: 2.3485481341679892

Epoch: 6| Step: 13
Training loss: 1.3560746908187866
Validation loss: 2.3114953438440957

Epoch: 485| Step: 0
Training loss: 0.572361946105957
Validation loss: 2.3291301131248474

Epoch: 6| Step: 1
Training loss: 0.6020411252975464
Validation loss: 2.336734155813853

Epoch: 6| Step: 2
Training loss: 0.9272462725639343
Validation loss: 2.317138353983561

Epoch: 6| Step: 3
Training loss: 0.7990111112594604
Validation loss: 2.3021392623583474

Epoch: 6| Step: 4
Training loss: 1.5530893802642822
Validation loss: 2.3247191508611045

Epoch: 6| Step: 5
Training loss: 0.33039459586143494
Validation loss: 2.328060567378998

Epoch: 6| Step: 6
Training loss: 1.1808598041534424
Validation loss: 2.380499005317688

Epoch: 6| Step: 7
Training loss: 0.5858452320098877
Validation loss: 2.2455042004585266

Epoch: 6| Step: 8
Training loss: 0.9627078771591187
Validation loss: 2.330585757891337

Epoch: 6| Step: 9
Training loss: 0.9493812322616577
Validation loss: 2.2936623891194663

Epoch: 6| Step: 10
Training loss: 0.6153937578201294
Validation loss: 2.2634952863057456

Epoch: 6| Step: 11
Training loss: 0.8833293318748474
Validation loss: 2.327567378679911

Epoch: 6| Step: 12
Training loss: 1.129711627960205
Validation loss: 2.3247658809026084

Epoch: 6| Step: 13
Training loss: 0.617063045501709
Validation loss: 2.3173383275667825

Epoch: 486| Step: 0
Training loss: 0.6776251792907715
Validation loss: 2.2723481257756553

Epoch: 6| Step: 1
Training loss: 1.6559193134307861
Validation loss: 2.2874236702919006

Epoch: 6| Step: 2
Training loss: 0.44251716136932373
Validation loss: 2.2959957122802734

Epoch: 6| Step: 3
Training loss: 0.5204830765724182
Validation loss: 2.274742046991984

Epoch: 6| Step: 4
Training loss: 0.536279022693634
Validation loss: 2.27186518907547

Epoch: 6| Step: 5
Training loss: 1.2653312683105469
Validation loss: 2.274556597073873

Epoch: 6| Step: 6
Training loss: 0.9940565824508667
Validation loss: 2.3000029921531677

Epoch: 6| Step: 7
Training loss: 0.9670847654342651
Validation loss: 2.265958865483602

Epoch: 6| Step: 8
Training loss: 0.8118551969528198
Validation loss: 2.2724154790242515

Epoch: 6| Step: 9
Training loss: 0.8888980150222778
Validation loss: 2.3077324628829956

Epoch: 6| Step: 10
Training loss: 0.5391114354133606
Validation loss: 2.2819204727808633

Epoch: 6| Step: 11
Training loss: 0.9144074320793152
Validation loss: 2.2431602478027344

Epoch: 6| Step: 12
Training loss: 0.23748765885829926
Validation loss: 2.2877641916275024

Epoch: 6| Step: 13
Training loss: 1.7387884855270386
Validation loss: 2.268686135609945

Epoch: 487| Step: 0
Training loss: 0.6502639055252075
Validation loss: 2.2970327138900757

Epoch: 6| Step: 1
Training loss: 0.5644643306732178
Validation loss: 2.309763411680857

Epoch: 6| Step: 2
Training loss: 0.8612356781959534
Validation loss: 2.2850804527600608

Epoch: 6| Step: 3
Training loss: 0.7542697191238403
Validation loss: 2.3086777925491333

Epoch: 6| Step: 4
Training loss: 0.6027140617370605
Validation loss: 2.3125213583310447

Epoch: 6| Step: 5
Training loss: 0.6090154647827148
Validation loss: 2.2850302855173745

Epoch: 6| Step: 6
Training loss: 0.6121113300323486
Validation loss: 2.235439201196035

Epoch: 6| Step: 7
Training loss: 0.5359273552894592
Validation loss: 2.31439737478892

Epoch: 6| Step: 8
Training loss: 1.0384547710418701
Validation loss: 2.2666135827700296

Epoch: 6| Step: 9
Training loss: 0.9757882356643677
Validation loss: 2.320685029029846

Epoch: 6| Step: 10
Training loss: 1.6166813373565674
Validation loss: 2.296360810597738

Epoch: 6| Step: 11
Training loss: 0.9261605739593506
Validation loss: 2.330455501874288

Epoch: 6| Step: 12
Training loss: 0.9674367904663086
Validation loss: 2.3498059511184692

Epoch: 6| Step: 13
Training loss: 1.277831792831421
Validation loss: 2.330083151658376

Epoch: 488| Step: 0
Training loss: 0.8004860877990723
Validation loss: 2.3160277605056763

Epoch: 6| Step: 1
Training loss: 0.7126350402832031
Validation loss: 2.2975428899129233

Epoch: 6| Step: 2
Training loss: 0.8921283483505249
Validation loss: 2.2875110705693564

Epoch: 6| Step: 3
Training loss: 0.4692852199077606
Validation loss: 2.314315915107727

Epoch: 6| Step: 4
Training loss: 1.1589077711105347
Validation loss: 2.2935109734535217

Epoch: 6| Step: 5
Training loss: 0.5684077739715576
Validation loss: 2.322110931078593

Epoch: 6| Step: 6
Training loss: 1.5385196208953857
Validation loss: 2.2694368958473206

Epoch: 6| Step: 7
Training loss: 0.3634507358074188
Validation loss: 2.314644972483317

Epoch: 6| Step: 8
Training loss: 0.6320078372955322
Validation loss: 2.3418780167897544

Epoch: 6| Step: 9
Training loss: 0.796431303024292
Validation loss: 2.331880728403727

Epoch: 6| Step: 10
Training loss: 0.826507568359375
Validation loss: 2.321360150973002

Epoch: 6| Step: 11
Training loss: 0.8326352834701538
Validation loss: 2.31864204009374

Epoch: 6| Step: 12
Training loss: 1.042644739151001
Validation loss: 2.2792946497599282

Epoch: 6| Step: 13
Training loss: 0.9687807559967041
Validation loss: 2.3163252075513205

Epoch: 489| Step: 0
Training loss: 0.7372919917106628
Validation loss: 2.3564870357513428

Epoch: 6| Step: 1
Training loss: 0.8202285766601562
Validation loss: 2.3534751534461975

Epoch: 6| Step: 2
Training loss: 1.485419750213623
Validation loss: 2.331852396329244

Epoch: 6| Step: 3
Training loss: 0.8015164136886597
Validation loss: 2.3609333833058677

Epoch: 6| Step: 4
Training loss: 0.9900381565093994
Validation loss: 2.345268666744232

Epoch: 6| Step: 5
Training loss: 0.6075395345687866
Validation loss: 2.3335367838541665

Epoch: 6| Step: 6
Training loss: 0.9108669757843018
Validation loss: 2.3453945914904275

Epoch: 6| Step: 7
Training loss: 0.7496901750564575
Validation loss: 2.333045760790507

Epoch: 6| Step: 8
Training loss: 0.897502064704895
Validation loss: 2.344585438569387

Epoch: 6| Step: 9
Training loss: 0.6487162113189697
Validation loss: 2.3567914764086404

Epoch: 6| Step: 10
Training loss: 0.6689428687095642
Validation loss: 2.3218334913253784

Epoch: 6| Step: 11
Training loss: 0.4943709373474121
Validation loss: 2.348218321800232

Epoch: 6| Step: 12
Training loss: 0.7891639471054077
Validation loss: 2.3015565474828086

Epoch: 6| Step: 13
Training loss: 0.8423580527305603
Validation loss: 2.3461287220319114

Epoch: 490| Step: 0
Training loss: 0.9408520460128784
Validation loss: 2.3406722148259482

Epoch: 6| Step: 1
Training loss: 0.9352721571922302
Validation loss: 2.348105549812317

Epoch: 6| Step: 2
Training loss: 0.534469723701477
Validation loss: 2.34883713722229

Epoch: 6| Step: 3
Training loss: 1.0187368392944336
Validation loss: 2.336196800072988

Epoch: 6| Step: 4
Training loss: 0.5722566246986389
Validation loss: 2.305042783419291

Epoch: 6| Step: 5
Training loss: 1.5682127475738525
Validation loss: 2.325697878996531

Epoch: 6| Step: 6
Training loss: 1.2358810901641846
Validation loss: 2.3927409648895264

Epoch: 6| Step: 7
Training loss: 0.8955448865890503
Validation loss: 2.3727259834607444

Epoch: 6| Step: 8
Training loss: 0.6452969312667847
Validation loss: 2.329388598601023

Epoch: 6| Step: 9
Training loss: 0.49468308687210083
Validation loss: 2.328994393348694

Epoch: 6| Step: 10
Training loss: 0.43056413531303406
Validation loss: 2.3590357303619385

Epoch: 6| Step: 11
Training loss: 1.1766223907470703
Validation loss: 2.38163427511851

Epoch: 6| Step: 12
Training loss: 1.2910611629486084
Validation loss: 2.372260570526123

Epoch: 6| Step: 13
Training loss: 0.4401314854621887
Validation loss: 2.342959225177765

Epoch: 491| Step: 0
Training loss: 0.44614842534065247
Validation loss: 2.3763609727223716

Epoch: 6| Step: 1
Training loss: 0.6816642880439758
Validation loss: 2.3472983837127686

Epoch: 6| Step: 2
Training loss: 0.9443625211715698
Validation loss: 2.3497614661852517

Epoch: 6| Step: 3
Training loss: 0.9143825173377991
Validation loss: 2.3753989934921265

Epoch: 6| Step: 4
Training loss: 0.8803883790969849
Validation loss: 2.38592267036438

Epoch: 6| Step: 5
Training loss: 0.5233747959136963
Validation loss: 2.3116482694943747

Epoch: 6| Step: 6
Training loss: 0.7777181267738342
Validation loss: 2.378286918004354

Epoch: 6| Step: 7
Training loss: 1.100623607635498
Validation loss: 2.349311947822571

Epoch: 6| Step: 8
Training loss: 0.6504287123680115
Validation loss: 2.348361372947693

Epoch: 6| Step: 9
Training loss: 0.8265860080718994
Validation loss: 2.3416040738423667

Epoch: 6| Step: 10
Training loss: 1.0382460355758667
Validation loss: 2.3308390378952026

Epoch: 6| Step: 11
Training loss: 0.6719603538513184
Validation loss: 2.3012916445732117

Epoch: 6| Step: 12
Training loss: 1.245368480682373
Validation loss: 2.324865539868673

Epoch: 6| Step: 13
Training loss: 0.7812439799308777
Validation loss: 2.3291054169336953

Epoch: 492| Step: 0
Training loss: 0.6727533340454102
Validation loss: 2.3388187090555825

Epoch: 6| Step: 1
Training loss: 0.9201446771621704
Validation loss: 2.3141955931981406

Epoch: 6| Step: 2
Training loss: 0.8453687429428101
Validation loss: 2.3611910740534463

Epoch: 6| Step: 3
Training loss: 1.505260944366455
Validation loss: 2.3718106746673584

Epoch: 6| Step: 4
Training loss: 1.3092104196548462
Validation loss: 2.3341232538223267

Epoch: 6| Step: 5
Training loss: 0.8081446886062622
Validation loss: 2.313904563585917

Epoch: 6| Step: 6
Training loss: 0.6362165212631226
Validation loss: 2.3043900529543557

Epoch: 6| Step: 7
Training loss: 0.5251283645629883
Validation loss: 2.345187266667684

Epoch: 6| Step: 8
Training loss: 0.4834095239639282
Validation loss: 2.2900568644205728

Epoch: 6| Step: 9
Training loss: 0.779893159866333
Validation loss: 2.2751200199127197

Epoch: 6| Step: 10
Training loss: 1.0922131538391113
Validation loss: 2.2644952535629272

Epoch: 6| Step: 11
Training loss: 1.1281137466430664
Validation loss: 2.3568344910939536

Epoch: 6| Step: 12
Training loss: 0.42600977420806885
Validation loss: 2.342931787172953

Epoch: 6| Step: 13
Training loss: 0.4580526351928711
Validation loss: 2.3129281202952066

Epoch: 493| Step: 0
Training loss: 0.5079638957977295
Validation loss: 2.3039787213007608

Epoch: 6| Step: 1
Training loss: 0.9761810302734375
Validation loss: 2.359002947807312

Epoch: 6| Step: 2
Training loss: 0.609817624092102
Validation loss: 2.389977733294169

Epoch: 6| Step: 3
Training loss: 1.0150820016860962
Validation loss: 2.3277427156766257

Epoch: 6| Step: 4
Training loss: 0.7156725525856018
Validation loss: 2.2957545121510825

Epoch: 6| Step: 5
Training loss: 0.863483726978302
Validation loss: 2.3176302115122476

Epoch: 6| Step: 6
Training loss: 1.1356102228164673
Validation loss: 2.3186362187067666

Epoch: 6| Step: 7
Training loss: 0.587203860282898
Validation loss: 2.32302987575531

Epoch: 6| Step: 8
Training loss: 0.6901777982711792
Validation loss: 2.273698012034098

Epoch: 6| Step: 9
Training loss: 0.7865242958068848
Validation loss: 2.332952618598938

Epoch: 6| Step: 10
Training loss: 0.6243908405303955
Validation loss: 2.308981974919637

Epoch: 6| Step: 11
Training loss: 1.201270580291748
Validation loss: 2.3346649607022605

Epoch: 6| Step: 12
Training loss: 0.9108306169509888
Validation loss: 2.3140821059544883

Epoch: 6| Step: 13
Training loss: 0.6399726867675781
Validation loss: 2.2749290267626443

Epoch: 494| Step: 0
Training loss: 0.3875114321708679
Validation loss: 2.3041504621505737

Epoch: 6| Step: 1
Training loss: 1.3379580974578857
Validation loss: 2.3481212059656777

Epoch: 6| Step: 2
Training loss: 0.7549371123313904
Validation loss: 2.2818578084309897

Epoch: 6| Step: 3
Training loss: 1.0582001209259033
Validation loss: 2.303513685862223

Epoch: 6| Step: 4
Training loss: 0.3785794973373413
Validation loss: 2.352032025655111

Epoch: 6| Step: 5
Training loss: 0.8096550703048706
Validation loss: 2.3215516805648804

Epoch: 6| Step: 6
Training loss: 0.9651849269866943
Validation loss: 2.318560163180033

Epoch: 6| Step: 7
Training loss: 0.7169162034988403
Validation loss: 2.2743168473243713

Epoch: 6| Step: 8
Training loss: 0.5464208722114563
Validation loss: 2.292499085267385

Epoch: 6| Step: 9
Training loss: 1.6468018293380737
Validation loss: 2.3324108719825745

Epoch: 6| Step: 10
Training loss: 0.7771227359771729
Validation loss: 2.3020376761754355

Epoch: 6| Step: 11
Training loss: 0.9228924512863159
Validation loss: 2.3411030173301697

Epoch: 6| Step: 12
Training loss: 0.7310431599617004
Validation loss: 2.336094856262207

Epoch: 6| Step: 13
Training loss: 0.6879051923751831
Validation loss: 2.314831852912903

Epoch: 495| Step: 0
Training loss: 1.0231698751449585
Validation loss: 2.338275690873464

Epoch: 6| Step: 1
Training loss: 0.3071230947971344
Validation loss: 2.343122363090515

Epoch: 6| Step: 2
Training loss: 1.019697666168213
Validation loss: 2.3275957902272544

Epoch: 6| Step: 3
Training loss: 0.8128676414489746
Validation loss: 2.3530908624331155

Epoch: 6| Step: 4
Training loss: 0.5372956991195679
Validation loss: 2.3792487581570945

Epoch: 6| Step: 5
Training loss: 0.6163617968559265
Validation loss: 2.3567124207814536

Epoch: 6| Step: 6
Training loss: 1.2100727558135986
Validation loss: 2.32572603225708

Epoch: 6| Step: 7
Training loss: 0.819381594657898
Validation loss: 2.3403329849243164

Epoch: 6| Step: 8
Training loss: 0.6758561134338379
Validation loss: 2.35053817431132

Epoch: 6| Step: 9
Training loss: 0.5288726687431335
Validation loss: 2.356766939163208

Epoch: 6| Step: 10
Training loss: 0.823661208152771
Validation loss: 2.339698155721029

Epoch: 6| Step: 11
Training loss: 0.9936339259147644
Validation loss: 2.351243774096171

Epoch: 6| Step: 12
Training loss: 1.1231844425201416
Validation loss: 2.370723247528076

Epoch: 6| Step: 13
Training loss: 1.044198751449585
Validation loss: 2.330004652341207

Epoch: 496| Step: 0
Training loss: 0.9171756505966187
Validation loss: 2.347521106402079

Epoch: 6| Step: 1
Training loss: 0.8597493171691895
Validation loss: 2.379722793896993

Epoch: 6| Step: 2
Training loss: 1.1668614149093628
Validation loss: 2.352099378903707

Epoch: 6| Step: 3
Training loss: 0.34908923506736755
Validation loss: 2.316342035929362

Epoch: 6| Step: 4
Training loss: 1.0761032104492188
Validation loss: 2.303415576616923

Epoch: 6| Step: 5
Training loss: 0.42221492528915405
Validation loss: 2.3331530690193176

Epoch: 6| Step: 6
Training loss: 0.987663984298706
Validation loss: 2.3529268503189087

Epoch: 6| Step: 7
Training loss: 0.9439982771873474
Validation loss: 2.372857610384623

Epoch: 6| Step: 8
Training loss: 0.8581007719039917
Validation loss: 2.33201402425766

Epoch: 6| Step: 9
Training loss: 0.3599468767642975
Validation loss: 2.32219926516215

Epoch: 6| Step: 10
Training loss: 0.8180086016654968
Validation loss: 2.2604172627131143

Epoch: 6| Step: 11
Training loss: 0.9106563925743103
Validation loss: 2.3339637517929077

Epoch: 6| Step: 12
Training loss: 0.8584074974060059
Validation loss: 2.291052540143331

Epoch: 6| Step: 13
Training loss: 0.36471864581108093
Validation loss: 2.3428504864374795

Epoch: 497| Step: 0
Training loss: 0.2879082262516022
Validation loss: 2.303739905357361

Epoch: 6| Step: 1
Training loss: 0.9645146131515503
Validation loss: 2.3233646949132285

Epoch: 6| Step: 2
Training loss: 1.5546696186065674
Validation loss: 2.3383440375328064

Epoch: 6| Step: 3
Training loss: 0.8754180669784546
Validation loss: 2.3495121796925864

Epoch: 6| Step: 4
Training loss: 0.7068782448768616
Validation loss: 2.3095411459604898

Epoch: 6| Step: 5
Training loss: 0.5397739410400391
Validation loss: 2.3299792607625327

Epoch: 6| Step: 6
Training loss: 0.7572025656700134
Validation loss: 2.3560364842414856

Epoch: 6| Step: 7
Training loss: 0.6352219581604004
Validation loss: 2.3101203441619873

Epoch: 6| Step: 8
Training loss: 0.5745289325714111
Validation loss: 2.339131752649943

Epoch: 6| Step: 9
Training loss: 1.0411661863327026
Validation loss: 2.316913922627767

Epoch: 6| Step: 10
Training loss: 0.6264480352401733
Validation loss: 2.356915752092997

Epoch: 6| Step: 11
Training loss: 1.004127860069275
Validation loss: 2.3163153926531472

Epoch: 6| Step: 12
Training loss: 0.8920049071311951
Validation loss: 2.3630592226982117

Epoch: 6| Step: 13
Training loss: 0.9537801146507263
Validation loss: 2.320916930834452

Epoch: 498| Step: 0
Training loss: 1.0426188707351685
Validation loss: 2.3817870219548545

Epoch: 6| Step: 1
Training loss: 0.6096607446670532
Validation loss: 2.3524067401885986

Epoch: 6| Step: 2
Training loss: 1.0711541175842285
Validation loss: 2.3633973399798074

Epoch: 6| Step: 3
Training loss: 0.8457845449447632
Validation loss: 2.356649418671926

Epoch: 6| Step: 4
Training loss: 0.9528859257698059
Validation loss: 2.321005384127299

Epoch: 6| Step: 5
Training loss: 1.3615121841430664
Validation loss: 2.3651008009910583

Epoch: 6| Step: 6
Training loss: 1.1355937719345093
Validation loss: 2.3670905431111655

Epoch: 6| Step: 7
Training loss: 0.8907779455184937
Validation loss: 2.3441033562024436

Epoch: 6| Step: 8
Training loss: 0.534281849861145
Validation loss: 2.272679547468821

Epoch: 6| Step: 9
Training loss: 0.673872709274292
Validation loss: 2.3136528730392456

Epoch: 6| Step: 10
Training loss: 0.7485554218292236
Validation loss: 2.2754576603571572

Epoch: 6| Step: 11
Training loss: 0.6066411733627319
Validation loss: 2.316016932328542

Epoch: 6| Step: 12
Training loss: 1.0166703462600708
Validation loss: 2.2551759680112204

Epoch: 6| Step: 13
Training loss: 1.288166880607605
Validation loss: 2.3075937827428183

Epoch: 499| Step: 0
Training loss: 1.4581037759780884
Validation loss: 2.331982692082723

Epoch: 6| Step: 1
Training loss: 1.0243594646453857
Validation loss: 2.3504955768585205

Epoch: 6| Step: 2
Training loss: 0.671603798866272
Validation loss: 2.3205415407816568

Epoch: 6| Step: 3
Training loss: 0.6212792992591858
Validation loss: 2.350186347961426

Epoch: 6| Step: 4
Training loss: 0.4281797409057617
Validation loss: 2.3715142607688904

Epoch: 6| Step: 5
Training loss: 0.5980668067932129
Validation loss: 2.317333698272705

Epoch: 6| Step: 6
Training loss: 0.4768087863922119
Validation loss: 2.296872695287069

Epoch: 6| Step: 7
Training loss: 0.9724289178848267
Validation loss: 2.324680964152018

Epoch: 6| Step: 8
Training loss: 1.0971486568450928
Validation loss: 2.3390047947565713

Epoch: 6| Step: 9
Training loss: 0.5848028659820557
Validation loss: 2.3272570371627808

Epoch: 6| Step: 10
Training loss: 1.5736865997314453
Validation loss: 2.3328936298688254

Epoch: 6| Step: 11
Training loss: 0.7175966501235962
Validation loss: 2.347662707169851

Epoch: 6| Step: 12
Training loss: 0.8839418888092041
Validation loss: 2.3583287398020425

Epoch: 6| Step: 13
Training loss: 0.7958716154098511
Validation loss: 2.3110500971476235

Epoch: 500| Step: 0
Training loss: 1.0672158002853394
Validation loss: 2.3154038985570273

Epoch: 6| Step: 1
Training loss: 0.5839477181434631
Validation loss: 2.318573315938314

Epoch: 6| Step: 2
Training loss: 0.37314218282699585
Validation loss: 2.327359676361084

Epoch: 6| Step: 3
Training loss: 0.387920618057251
Validation loss: 2.323465347290039

Epoch: 6| Step: 4
Training loss: 1.501283884048462
Validation loss: 2.350812236467997

Epoch: 6| Step: 5
Training loss: 0.833621084690094
Validation loss: 2.3069135546684265

Epoch: 6| Step: 6
Training loss: 1.231724500656128
Validation loss: 2.3075349728266397

Epoch: 6| Step: 7
Training loss: 0.423891544342041
Validation loss: 2.347081462542216

Epoch: 6| Step: 8
Training loss: 0.5150099396705627
Validation loss: 2.3080251216888428

Epoch: 6| Step: 9
Training loss: 0.5024226307868958
Validation loss: 2.2899330655733743

Epoch: 6| Step: 10
Training loss: 0.38474851846694946
Validation loss: 2.3169217904408774

Epoch: 6| Step: 11
Training loss: 0.6295715570449829
Validation loss: 2.296002467473348

Epoch: 6| Step: 12
Training loss: 1.9468258619308472
Validation loss: 2.358309825261434

Epoch: 6| Step: 13
Training loss: 0.6955094933509827
Validation loss: 2.4003217816352844

Testing loss: 2.073392042153173
