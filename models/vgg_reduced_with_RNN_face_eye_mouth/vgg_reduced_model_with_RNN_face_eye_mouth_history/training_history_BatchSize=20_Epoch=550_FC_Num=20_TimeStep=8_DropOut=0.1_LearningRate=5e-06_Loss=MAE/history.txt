Epoch: 1| Step: 0
Training loss: 5.58232307434082
Validation loss: 5.338868339856465

Epoch: 5| Step: 1
Training loss: 5.916201591491699
Validation loss: 5.337672054767609

Epoch: 5| Step: 2
Training loss: 6.139864444732666
Validation loss: 5.336585501829783

Epoch: 5| Step: 3
Training loss: 5.179490089416504
Validation loss: 5.335550308227539

Epoch: 5| Step: 4
Training loss: 3.9932494163513184
Validation loss: 5.334573606650035

Epoch: 5| Step: 5
Training loss: 5.457159042358398
Validation loss: 5.333630462487538

Epoch: 5| Step: 6
Training loss: 5.026174068450928
Validation loss: 5.332631190617879

Epoch: 5| Step: 7
Training loss: 5.299638271331787
Validation loss: 5.331703265508016

Epoch: 5| Step: 8
Training loss: 6.219433784484863
Validation loss: 5.330741385618846

Epoch: 5| Step: 9
Training loss: 5.12778377532959
Validation loss: 5.329692085584004

Epoch: 5| Step: 10
Training loss: 5.591713905334473
Validation loss: 5.328678985436757

Epoch: 5| Step: 11
Training loss: 4.868099689483643
Validation loss: 5.327603439490001

Epoch: 2| Step: 0
Training loss: 5.760298728942871
Validation loss: 5.326545377572377

Epoch: 5| Step: 1
Training loss: 5.148896217346191
Validation loss: 5.325440049171448

Epoch: 5| Step: 2
Training loss: 5.297549247741699
Validation loss: 5.324246803919475

Epoch: 5| Step: 3
Training loss: 5.775696754455566
Validation loss: 5.323085784912109

Epoch: 5| Step: 4
Training loss: 6.69933557510376
Validation loss: 5.321671764055888

Epoch: 5| Step: 5
Training loss: 5.459170341491699
Validation loss: 5.320318679014842

Epoch: 5| Step: 6
Training loss: 4.702095031738281
Validation loss: 5.318832218647003

Epoch: 5| Step: 7
Training loss: 5.949828147888184
Validation loss: 5.3172540863355

Epoch: 5| Step: 8
Training loss: 5.010595798492432
Validation loss: 5.315564076105754

Epoch: 5| Step: 9
Training loss: 4.344691276550293
Validation loss: 5.31386677424113

Epoch: 5| Step: 10
Training loss: 4.7709550857543945
Validation loss: 5.311938444773356

Epoch: 5| Step: 11
Training loss: 7.168455600738525
Validation loss: 5.310066719849904

Epoch: 3| Step: 0
Training loss: 4.511578559875488
Validation loss: 5.307975033919017

Epoch: 5| Step: 1
Training loss: 5.645593643188477
Validation loss: 5.305791596571605

Epoch: 5| Step: 2
Training loss: 5.234867095947266
Validation loss: 5.303505440553029

Epoch: 5| Step: 3
Training loss: 4.99862003326416
Validation loss: 5.301049093405406

Epoch: 5| Step: 4
Training loss: 6.196106910705566
Validation loss: 5.298492908477783

Epoch: 5| Step: 5
Training loss: 5.138864040374756
Validation loss: 5.295625785986583

Epoch: 5| Step: 6
Training loss: 4.895559787750244
Validation loss: 5.292922735214233

Epoch: 5| Step: 7
Training loss: 5.2266845703125
Validation loss: 5.289991597334544

Epoch: 5| Step: 8
Training loss: 5.68025541305542
Validation loss: 5.286659419536591

Epoch: 5| Step: 9
Training loss: 6.069927215576172
Validation loss: 5.283372064431508

Epoch: 5| Step: 10
Training loss: 5.267176628112793
Validation loss: 5.279882073402405

Epoch: 5| Step: 11
Training loss: 6.040423393249512
Validation loss: 5.276157597700755

Epoch: 4| Step: 0
Training loss: 6.039820671081543
Validation loss: 5.27220865090688

Epoch: 5| Step: 1
Training loss: 5.825218200683594
Validation loss: 5.268171350161235

Epoch: 5| Step: 2
Training loss: 5.863488674163818
Validation loss: 5.263787666956584

Epoch: 5| Step: 3
Training loss: 4.467120170593262
Validation loss: 5.259260018666585

Epoch: 5| Step: 4
Training loss: 4.503417491912842
Validation loss: 5.254468202590942

Epoch: 5| Step: 5
Training loss: 4.466477394104004
Validation loss: 5.249480267365773

Epoch: 5| Step: 6
Training loss: 5.777853488922119
Validation loss: 5.2444376945495605

Epoch: 5| Step: 7
Training loss: 5.174558639526367
Validation loss: 5.238891422748566

Epoch: 5| Step: 8
Training loss: 5.076287269592285
Validation loss: 5.233370304107666

Epoch: 5| Step: 9
Training loss: 5.281635284423828
Validation loss: 5.227492610613505

Epoch: 5| Step: 10
Training loss: 5.880209922790527
Validation loss: 5.221522311369578

Epoch: 5| Step: 11
Training loss: 5.995426177978516
Validation loss: 5.215182383855184

Epoch: 5| Step: 0
Training loss: 4.359255790710449
Validation loss: 5.208491285641988

Epoch: 5| Step: 1
Training loss: 5.5371809005737305
Validation loss: 5.202069838841756

Epoch: 5| Step: 2
Training loss: 5.948678016662598
Validation loss: 5.194985111554463

Epoch: 5| Step: 3
Training loss: 4.974437713623047
Validation loss: 5.188069085280101

Epoch: 5| Step: 4
Training loss: 5.095808506011963
Validation loss: 5.18069342772166

Epoch: 5| Step: 5
Training loss: 5.429398536682129
Validation loss: 5.173050721486409

Epoch: 5| Step: 6
Training loss: 4.69680118560791
Validation loss: 5.165303508440654

Epoch: 5| Step: 7
Training loss: 5.548826694488525
Validation loss: 5.157122433185577

Epoch: 5| Step: 8
Training loss: 5.730860233306885
Validation loss: 5.148768762747447

Epoch: 5| Step: 9
Training loss: 5.472455024719238
Validation loss: 5.140260477860768

Epoch: 5| Step: 10
Training loss: 4.5093207359313965
Validation loss: 5.131454686323802

Epoch: 5| Step: 11
Training loss: 7.039129257202148
Validation loss: 5.122261146704356

Epoch: 6| Step: 0
Training loss: 5.1284894943237305
Validation loss: 5.113097548484802

Epoch: 5| Step: 1
Training loss: 3.7685744762420654
Validation loss: 5.1037687460581465

Epoch: 5| Step: 2
Training loss: 6.020219326019287
Validation loss: 5.0945338408152265

Epoch: 5| Step: 3
Training loss: 5.026045322418213
Validation loss: 5.085369209448497

Epoch: 5| Step: 4
Training loss: 4.766070365905762
Validation loss: 5.076074461142222

Epoch: 5| Step: 5
Training loss: 4.8741135597229
Validation loss: 5.066921313603719

Epoch: 5| Step: 6
Training loss: 6.179604530334473
Validation loss: 5.05768887201945

Epoch: 5| Step: 7
Training loss: 5.4878249168396
Validation loss: 5.048245191574097

Epoch: 5| Step: 8
Training loss: 4.748045921325684
Validation loss: 5.038712600866954

Epoch: 5| Step: 9
Training loss: 5.283455848693848
Validation loss: 5.029937505722046

Epoch: 5| Step: 10
Training loss: 4.966017723083496
Validation loss: 5.021060645580292

Epoch: 5| Step: 11
Training loss: 6.729231357574463
Validation loss: 5.01227863629659

Epoch: 7| Step: 0
Training loss: 5.195384979248047
Validation loss: 5.004044155279796

Epoch: 5| Step: 1
Training loss: 4.7045793533325195
Validation loss: 4.996064484119415

Epoch: 5| Step: 2
Training loss: 5.10877799987793
Validation loss: 4.9884083072344465

Epoch: 5| Step: 3
Training loss: 5.027340888977051
Validation loss: 4.980428417523702

Epoch: 5| Step: 4
Training loss: 4.359761714935303
Validation loss: 4.972839554150899

Epoch: 5| Step: 5
Training loss: 4.015057563781738
Validation loss: 4.96578053633372

Epoch: 5| Step: 6
Training loss: 5.321051120758057
Validation loss: 4.958652098973592

Epoch: 5| Step: 7
Training loss: 5.74556827545166
Validation loss: 4.9515852729479475

Epoch: 5| Step: 8
Training loss: 4.837855815887451
Validation loss: 4.944175104300181

Epoch: 5| Step: 9
Training loss: 5.899012088775635
Validation loss: 4.937609573205312

Epoch: 5| Step: 10
Training loss: 5.107123374938965
Validation loss: 4.930885225534439

Epoch: 5| Step: 11
Training loss: 6.07869815826416
Validation loss: 4.923909246921539

Epoch: 8| Step: 0
Training loss: 5.0616326332092285
Validation loss: 4.917157967885335

Epoch: 5| Step: 1
Training loss: 4.819118976593018
Validation loss: 4.9104374051094055

Epoch: 5| Step: 2
Training loss: 5.005522727966309
Validation loss: 4.90396120150884

Epoch: 5| Step: 3
Training loss: 5.062895774841309
Validation loss: 4.897209107875824

Epoch: 5| Step: 4
Training loss: 4.055088520050049
Validation loss: 4.890308539072673

Epoch: 5| Step: 5
Training loss: 4.872461795806885
Validation loss: 4.883216102917989

Epoch: 5| Step: 6
Training loss: 4.7984819412231445
Validation loss: 4.876513699690501

Epoch: 5| Step: 7
Training loss: 5.70205020904541
Validation loss: 4.869352420171102

Epoch: 5| Step: 8
Training loss: 5.921515464782715
Validation loss: 4.862467646598816

Epoch: 5| Step: 9
Training loss: 4.508488178253174
Validation loss: 4.855316698551178

Epoch: 5| Step: 10
Training loss: 5.141552448272705
Validation loss: 4.848300973574321

Epoch: 5| Step: 11
Training loss: 3.447080135345459
Validation loss: 4.841096560160319

Epoch: 9| Step: 0
Training loss: 4.886568069458008
Validation loss: 4.83451779683431

Epoch: 5| Step: 1
Training loss: 3.4831032752990723
Validation loss: 4.8279514610767365

Epoch: 5| Step: 2
Training loss: 5.312737941741943
Validation loss: 4.821753740310669

Epoch: 5| Step: 3
Training loss: 5.595779895782471
Validation loss: 4.815351863702138

Epoch: 5| Step: 4
Training loss: 5.4765238761901855
Validation loss: 4.8084747195243835

Epoch: 5| Step: 5
Training loss: 4.324263572692871
Validation loss: 4.802011509736379

Epoch: 5| Step: 6
Training loss: 5.705495357513428
Validation loss: 4.795933087666829

Epoch: 5| Step: 7
Training loss: 4.083562850952148
Validation loss: 4.789696455001831

Epoch: 5| Step: 8
Training loss: 4.792097568511963
Validation loss: 4.782680074373881

Epoch: 5| Step: 9
Training loss: 4.652988433837891
Validation loss: 4.776203076044719

Epoch: 5| Step: 10
Training loss: 5.263042449951172
Validation loss: 4.770146131515503

Epoch: 5| Step: 11
Training loss: 5.9292778968811035
Validation loss: 4.763583441575368

Epoch: 10| Step: 0
Training loss: 5.176746368408203
Validation loss: 4.756640732288361

Epoch: 5| Step: 1
Training loss: 4.654783248901367
Validation loss: 4.7501727143923445

Epoch: 5| Step: 2
Training loss: 5.363041877746582
Validation loss: 4.74317995707194

Epoch: 5| Step: 3
Training loss: 4.959153175354004
Validation loss: 4.736382444699605

Epoch: 5| Step: 4
Training loss: 4.6715803146362305
Validation loss: 4.72968469063441

Epoch: 5| Step: 5
Training loss: 4.010898590087891
Validation loss: 4.724425236384074

Epoch: 5| Step: 6
Training loss: 5.215317249298096
Validation loss: 4.718054533004761

Epoch: 5| Step: 7
Training loss: 4.434601783752441
Validation loss: 4.711395392815272

Epoch: 5| Step: 8
Training loss: 5.276466369628906
Validation loss: 4.70552459359169

Epoch: 5| Step: 9
Training loss: 4.56605339050293
Validation loss: 4.699760754903157

Epoch: 5| Step: 10
Training loss: 4.709312438964844
Validation loss: 4.693766405185063

Epoch: 5| Step: 11
Training loss: 4.490872859954834
Validation loss: 4.687389771143596

Epoch: 11| Step: 0
Training loss: 5.0105390548706055
Validation loss: 4.681015531222026

Epoch: 5| Step: 1
Training loss: 4.694277286529541
Validation loss: 4.674699127674103

Epoch: 5| Step: 2
Training loss: 4.610692501068115
Validation loss: 4.669068614641826

Epoch: 5| Step: 3
Training loss: 4.33817195892334
Validation loss: 4.6628843148549395

Epoch: 5| Step: 4
Training loss: 4.694103240966797
Validation loss: 4.657042006651561

Epoch: 5| Step: 5
Training loss: 4.87271785736084
Validation loss: 4.65140438079834

Epoch: 5| Step: 6
Training loss: 4.640139579772949
Validation loss: 4.644989192485809

Epoch: 5| Step: 7
Training loss: 5.042067050933838
Validation loss: 4.639812270800273

Epoch: 5| Step: 8
Training loss: 4.942381381988525
Validation loss: 4.6343071063359575

Epoch: 5| Step: 9
Training loss: 4.410161018371582
Validation loss: 4.6281217734018965

Epoch: 5| Step: 10
Training loss: 4.88681173324585
Validation loss: 4.622993687788646

Epoch: 5| Step: 11
Training loss: 5.138569355010986
Validation loss: 4.617939213911693

Epoch: 12| Step: 0
Training loss: 4.632802486419678
Validation loss: 4.612854520479838

Epoch: 5| Step: 1
Training loss: 3.879697322845459
Validation loss: 4.607057770093282

Epoch: 5| Step: 2
Training loss: 3.981881618499756
Validation loss: 4.6017919977506

Epoch: 5| Step: 3
Training loss: 4.635743141174316
Validation loss: 4.59660999973615

Epoch: 5| Step: 4
Training loss: 5.3811469078063965
Validation loss: 4.591605007648468

Epoch: 5| Step: 5
Training loss: 4.502303123474121
Validation loss: 4.586927771568298

Epoch: 5| Step: 6
Training loss: 4.811165809631348
Validation loss: 4.581973175207774

Epoch: 5| Step: 7
Training loss: 3.9299988746643066
Validation loss: 4.5766295393308

Epoch: 5| Step: 8
Training loss: 5.037415504455566
Validation loss: 4.57112979888916

Epoch: 5| Step: 9
Training loss: 5.417015552520752
Validation loss: 4.566140900055568

Epoch: 5| Step: 10
Training loss: 5.102935791015625
Validation loss: 4.5611390471458435

Epoch: 5| Step: 11
Training loss: 5.851068496704102
Validation loss: 4.556566536426544

Epoch: 13| Step: 0
Training loss: 5.497476100921631
Validation loss: 4.552114536364873

Epoch: 5| Step: 1
Training loss: 3.9863762855529785
Validation loss: 4.5465185443560285

Epoch: 5| Step: 2
Training loss: 4.668203830718994
Validation loss: 4.5418171882629395

Epoch: 5| Step: 3
Training loss: 4.605441093444824
Validation loss: 4.5366402467091875

Epoch: 5| Step: 4
Training loss: 5.36345911026001
Validation loss: 4.530818819999695

Epoch: 5| Step: 5
Training loss: 3.64673113822937
Validation loss: 4.526035050551097

Epoch: 5| Step: 6
Training loss: 4.47606897354126
Validation loss: 4.5218578179677325

Epoch: 5| Step: 7
Training loss: 4.61033296585083
Validation loss: 4.516346991062164

Epoch: 5| Step: 8
Training loss: 5.028799533843994
Validation loss: 4.511134088039398

Epoch: 5| Step: 9
Training loss: 5.117964744567871
Validation loss: 4.506898581981659

Epoch: 5| Step: 10
Training loss: 3.780346632003784
Validation loss: 4.501968006292979

Epoch: 5| Step: 11
Training loss: 5.395441055297852
Validation loss: 4.4971500635147095

Epoch: 14| Step: 0
Training loss: 4.136767864227295
Validation loss: 4.492276559273402

Epoch: 5| Step: 1
Training loss: 4.476987838745117
Validation loss: 4.487272262573242

Epoch: 5| Step: 2
Training loss: 3.9702486991882324
Validation loss: 4.481742550929387

Epoch: 5| Step: 3
Training loss: 3.661940097808838
Validation loss: 4.477399120728175

Epoch: 5| Step: 4
Training loss: 4.896090507507324
Validation loss: 4.4722667535146075

Epoch: 5| Step: 5
Training loss: 5.859562873840332
Validation loss: 4.4681680003801985

Epoch: 5| Step: 6
Training loss: 4.888114929199219
Validation loss: 4.463330825169881

Epoch: 5| Step: 7
Training loss: 5.179913520812988
Validation loss: 4.458248853683472

Epoch: 5| Step: 8
Training loss: 4.39882755279541
Validation loss: 4.454413264989853

Epoch: 5| Step: 9
Training loss: 4.046402454376221
Validation loss: 4.4498752156893415

Epoch: 5| Step: 10
Training loss: 4.649175643920898
Validation loss: 4.44371019800504

Epoch: 5| Step: 11
Training loss: 5.49665641784668
Validation loss: 4.43866162498792

Epoch: 15| Step: 0
Training loss: 4.011610984802246
Validation loss: 4.4341046412785845

Epoch: 5| Step: 1
Training loss: 6.026006698608398
Validation loss: 4.429486284653346

Epoch: 5| Step: 2
Training loss: 4.900216579437256
Validation loss: 4.42408166329066

Epoch: 5| Step: 3
Training loss: 5.396407604217529
Validation loss: 4.419899096091588

Epoch: 5| Step: 4
Training loss: 4.239683151245117
Validation loss: 4.414364834626515

Epoch: 5| Step: 5
Training loss: 4.789434432983398
Validation loss: 4.409151375293732

Epoch: 5| Step: 6
Training loss: 3.7415688037872314
Validation loss: 4.404492010672887

Epoch: 5| Step: 7
Training loss: 3.64497447013855
Validation loss: 4.399275004863739

Epoch: 5| Step: 8
Training loss: 4.775130271911621
Validation loss: 4.394276420275371

Epoch: 5| Step: 9
Training loss: 4.035265922546387
Validation loss: 4.389656245708466

Epoch: 5| Step: 10
Training loss: 3.998821258544922
Validation loss: 4.384724656740825

Epoch: 5| Step: 11
Training loss: 5.642733573913574
Validation loss: 4.380285799503326

Epoch: 16| Step: 0
Training loss: 3.593783140182495
Validation loss: 4.374989499648412

Epoch: 5| Step: 1
Training loss: 5.628512382507324
Validation loss: 4.371000657478969

Epoch: 5| Step: 2
Training loss: 4.664808750152588
Validation loss: 4.366187175114949

Epoch: 5| Step: 3
Training loss: 5.403983116149902
Validation loss: 4.3612319231033325

Epoch: 5| Step: 4
Training loss: 3.3973019123077393
Validation loss: 4.356018910805385

Epoch: 5| Step: 5
Training loss: 4.999285697937012
Validation loss: 4.351368556420009

Epoch: 5| Step: 6
Training loss: 4.233907222747803
Validation loss: 4.345288435618083

Epoch: 5| Step: 7
Training loss: 4.236215591430664
Validation loss: 4.340163866678874

Epoch: 5| Step: 8
Training loss: 3.7574901580810547
Validation loss: 4.33594074845314

Epoch: 5| Step: 9
Training loss: 5.063823699951172
Validation loss: 4.3314095338185625

Epoch: 5| Step: 10
Training loss: 4.509577751159668
Validation loss: 4.325924754142761

Epoch: 5| Step: 11
Training loss: 3.035371780395508
Validation loss: 4.321261207262675

Epoch: 17| Step: 0
Training loss: 4.5512847900390625
Validation loss: 4.31715386112531

Epoch: 5| Step: 1
Training loss: 4.933136940002441
Validation loss: 4.312997917334239

Epoch: 5| Step: 2
Training loss: 3.515770673751831
Validation loss: 4.307841211557388

Epoch: 5| Step: 3
Training loss: 5.170360565185547
Validation loss: 4.302522957324982

Epoch: 5| Step: 4
Training loss: 4.320765972137451
Validation loss: 4.299614200989406

Epoch: 5| Step: 5
Training loss: 3.6136155128479004
Validation loss: 4.295313835144043

Epoch: 5| Step: 6
Training loss: 4.017210483551025
Validation loss: 4.288508931795756

Epoch: 5| Step: 7
Training loss: 4.667759895324707
Validation loss: 4.284130106369655

Epoch: 5| Step: 8
Training loss: 4.326106548309326
Validation loss: 4.280401815970738

Epoch: 5| Step: 9
Training loss: 4.655051231384277
Validation loss: 4.274507761001587

Epoch: 5| Step: 10
Training loss: 4.810466289520264
Validation loss: 4.268896321455638

Epoch: 5| Step: 11
Training loss: 4.581651210784912
Validation loss: 4.264536569515864

Epoch: 18| Step: 0
Training loss: 4.292935371398926
Validation loss: 4.26025915145874

Epoch: 5| Step: 1
Training loss: 4.400804042816162
Validation loss: 4.254905541737874

Epoch: 5| Step: 2
Training loss: 3.7764346599578857
Validation loss: 4.2503012617429095

Epoch: 5| Step: 3
Training loss: 4.777945041656494
Validation loss: 4.244668324788411

Epoch: 5| Step: 4
Training loss: 4.416343688964844
Validation loss: 4.239270667235057

Epoch: 5| Step: 5
Training loss: 4.458897590637207
Validation loss: 4.233867158492406

Epoch: 5| Step: 6
Training loss: 3.939112424850464
Validation loss: 4.228932797908783

Epoch: 5| Step: 7
Training loss: 4.7233734130859375
Validation loss: 4.2254263659318285

Epoch: 5| Step: 8
Training loss: 4.3322625160217285
Validation loss: 4.220226943492889

Epoch: 5| Step: 9
Training loss: 4.785149574279785
Validation loss: 4.213451564311981

Epoch: 5| Step: 10
Training loss: 3.805621385574341
Validation loss: 4.207811892032623

Epoch: 5| Step: 11
Training loss: 5.832948207855225
Validation loss: 4.2037683228651685

Epoch: 19| Step: 0
Training loss: 4.09908390045166
Validation loss: 4.1997693081696825

Epoch: 5| Step: 1
Training loss: 4.2797136306762695
Validation loss: 4.192997415860494

Epoch: 5| Step: 2
Training loss: 4.666074752807617
Validation loss: 4.188158233960469

Epoch: 5| Step: 3
Training loss: 4.046078681945801
Validation loss: 4.183478703101476

Epoch: 5| Step: 4
Training loss: 4.55471658706665
Validation loss: 4.176837146282196

Epoch: 5| Step: 5
Training loss: 4.130622863769531
Validation loss: 4.172425856192906

Epoch: 5| Step: 6
Training loss: 3.8042328357696533
Validation loss: 4.167642275492351

Epoch: 5| Step: 7
Training loss: 4.217912197113037
Validation loss: 4.162923435370128

Epoch: 5| Step: 8
Training loss: 3.6469969749450684
Validation loss: 4.156957308451335

Epoch: 5| Step: 9
Training loss: 5.3827643394470215
Validation loss: 4.153019974629085

Epoch: 5| Step: 10
Training loss: 4.58392333984375
Validation loss: 4.148667871952057

Epoch: 5| Step: 11
Training loss: 4.239462852478027
Validation loss: 4.1430502732594805

Epoch: 20| Step: 0
Training loss: 3.776005268096924
Validation loss: 4.1380864183108015

Epoch: 5| Step: 1
Training loss: 4.406109809875488
Validation loss: 4.133041540781657

Epoch: 5| Step: 2
Training loss: 4.19069766998291
Validation loss: 4.1268623272577925

Epoch: 5| Step: 3
Training loss: 4.631067276000977
Validation loss: 4.122048993905385

Epoch: 5| Step: 4
Training loss: 5.164462566375732
Validation loss: 4.1161173184712725

Epoch: 5| Step: 5
Training loss: 4.5864362716674805
Validation loss: 4.112583200136821

Epoch: 5| Step: 6
Training loss: 3.3517143726348877
Validation loss: 4.107359747091929

Epoch: 5| Step: 7
Training loss: 4.033477306365967
Validation loss: 4.10166550676028

Epoch: 5| Step: 8
Training loss: 4.521632194519043
Validation loss: 4.096282591422399

Epoch: 5| Step: 9
Training loss: 3.3891689777374268
Validation loss: 4.091077268123627

Epoch: 5| Step: 10
Training loss: 4.490451335906982
Validation loss: 4.086719085772832

Epoch: 5| Step: 11
Training loss: 5.413547515869141
Validation loss: 4.080708543459575

Epoch: 21| Step: 0
Training loss: 3.67875337600708
Validation loss: 4.076420088609059

Epoch: 5| Step: 1
Training loss: 4.497396469116211
Validation loss: 4.072928110758464

Epoch: 5| Step: 2
Training loss: 4.925454139709473
Validation loss: 4.068089514970779

Epoch: 5| Step: 3
Training loss: 3.7853007316589355
Validation loss: 4.061982840299606

Epoch: 5| Step: 4
Training loss: 3.568390369415283
Validation loss: 4.056952804327011

Epoch: 5| Step: 5
Training loss: 4.405158042907715
Validation loss: 4.052717049916585

Epoch: 5| Step: 6
Training loss: 4.877285957336426
Validation loss: 4.046796490748723

Epoch: 5| Step: 7
Training loss: 3.703886032104492
Validation loss: 4.041082302729289

Epoch: 5| Step: 8
Training loss: 3.9812049865722656
Validation loss: 4.037010441223781

Epoch: 5| Step: 9
Training loss: 4.1063232421875
Validation loss: 4.032961487770081

Epoch: 5| Step: 10
Training loss: 4.263620853424072
Validation loss: 4.026990920305252

Epoch: 5| Step: 11
Training loss: 5.976807594299316
Validation loss: 4.022200544675191

Epoch: 22| Step: 0
Training loss: 4.846528053283691
Validation loss: 4.018426229556401

Epoch: 5| Step: 1
Training loss: 4.3048577308654785
Validation loss: 4.01151783267657

Epoch: 5| Step: 2
Training loss: 3.111572265625
Validation loss: 4.005498329798381

Epoch: 5| Step: 3
Training loss: 3.880722761154175
Validation loss: 4.001572320858638

Epoch: 5| Step: 4
Training loss: 3.8790245056152344
Validation loss: 3.9972893496354422

Epoch: 5| Step: 5
Training loss: 4.161596775054932
Validation loss: 3.9915548861026764

Epoch: 5| Step: 6
Training loss: 4.20681095123291
Validation loss: 3.9868589639663696

Epoch: 5| Step: 7
Training loss: 3.468501567840576
Validation loss: 3.9809978107611337

Epoch: 5| Step: 8
Training loss: 4.074524879455566
Validation loss: 3.9759219586849213

Epoch: 5| Step: 9
Training loss: 4.874966621398926
Validation loss: 3.971136490503947

Epoch: 5| Step: 10
Training loss: 4.840920448303223
Validation loss: 3.966127077738444

Epoch: 5| Step: 11
Training loss: 3.471177101135254
Validation loss: 3.960426112016042

Epoch: 23| Step: 0
Training loss: 4.266055583953857
Validation loss: 3.9557185570398965

Epoch: 5| Step: 1
Training loss: 4.558671474456787
Validation loss: 3.9509749909241996

Epoch: 5| Step: 2
Training loss: 3.408207654953003
Validation loss: 3.945425868034363

Epoch: 5| Step: 3
Training loss: 4.7801313400268555
Validation loss: 3.9395710229873657

Epoch: 5| Step: 4
Training loss: 4.0433783531188965
Validation loss: 3.9352397322654724

Epoch: 5| Step: 5
Training loss: 3.57987642288208
Validation loss: 3.9289460480213165

Epoch: 5| Step: 6
Training loss: 3.8793773651123047
Validation loss: 3.9249054292837777

Epoch: 5| Step: 7
Training loss: 3.509899139404297
Validation loss: 3.9204587737719216

Epoch: 5| Step: 8
Training loss: 4.5850958824157715
Validation loss: 3.915555546681086

Epoch: 5| Step: 9
Training loss: 3.8207595348358154
Validation loss: 3.90999898314476

Epoch: 5| Step: 10
Training loss: 4.4511919021606445
Validation loss: 3.9042848447958627

Epoch: 5| Step: 11
Training loss: 3.9788289070129395
Validation loss: 3.8993284900983176

Epoch: 24| Step: 0
Training loss: 3.6866097450256348
Validation loss: 3.89546337723732

Epoch: 5| Step: 1
Training loss: 4.5776047706604
Validation loss: 3.8905730644861856

Epoch: 5| Step: 2
Training loss: 4.28187370300293
Validation loss: 3.8851629495620728

Epoch: 5| Step: 3
Training loss: 3.43498158454895
Validation loss: 3.880597859621048

Epoch: 5| Step: 4
Training loss: 3.6599221229553223
Validation loss: 3.875414957602819

Epoch: 5| Step: 5
Training loss: 2.8424105644226074
Validation loss: 3.870165139436722

Epoch: 5| Step: 6
Training loss: 3.8737072944641113
Validation loss: 3.8664947052796683

Epoch: 5| Step: 7
Training loss: 4.729972839355469
Validation loss: 3.8605813086032867

Epoch: 5| Step: 8
Training loss: 4.213274955749512
Validation loss: 3.85580321153005

Epoch: 5| Step: 9
Training loss: 4.679636001586914
Validation loss: 3.851161609093348

Epoch: 5| Step: 10
Training loss: 4.382226943969727
Validation loss: 3.847063402334849

Epoch: 5| Step: 11
Training loss: 3.4429612159729004
Validation loss: 3.8417888879776

Epoch: 25| Step: 0
Training loss: 3.8938019275665283
Validation loss: 3.8373115062713623

Epoch: 5| Step: 1
Training loss: 4.743590354919434
Validation loss: 3.8317162791887918

Epoch: 5| Step: 2
Training loss: 3.689175844192505
Validation loss: 3.8263688882191977

Epoch: 5| Step: 3
Training loss: 4.296888828277588
Validation loss: 3.8212181627750397

Epoch: 5| Step: 4
Training loss: 3.697359561920166
Validation loss: 3.8164847095807395

Epoch: 5| Step: 5
Training loss: 3.2039763927459717
Validation loss: 3.8109347025553384

Epoch: 5| Step: 6
Training loss: 4.456092834472656
Validation loss: 3.8059224088986716

Epoch: 5| Step: 7
Training loss: 3.965134382247925
Validation loss: 3.8015358547369638

Epoch: 5| Step: 8
Training loss: 4.051883697509766
Validation loss: 3.795933564503988

Epoch: 5| Step: 9
Training loss: 3.095066785812378
Validation loss: 3.790677418311437

Epoch: 5| Step: 10
Training loss: 4.726943016052246
Validation loss: 3.7877114514509835

Epoch: 5| Step: 11
Training loss: 3.0778801441192627
Validation loss: 3.782165835301081

Epoch: 26| Step: 0
Training loss: 4.257809162139893
Validation loss: 3.843287855386734

Epoch: 5| Step: 1
Training loss: 3.409156084060669
Validation loss: 3.7747022112210593

Epoch: 5| Step: 2
Training loss: 3.592798948287964
Validation loss: 3.7726497848828635

Epoch: 5| Step: 3
Training loss: 4.589816093444824
Validation loss: 3.7743880649407706

Epoch: 5| Step: 4
Training loss: 2.9290928840637207
Validation loss: 3.770501971244812

Epoch: 5| Step: 5
Training loss: 3.8643546104431152
Validation loss: 3.7672373950481415

Epoch: 5| Step: 6
Training loss: 3.8354930877685547
Validation loss: 3.7602866689364114

Epoch: 5| Step: 7
Training loss: 4.323141574859619
Validation loss: 3.754639983177185

Epoch: 5| Step: 8
Training loss: 3.548966884613037
Validation loss: 3.75652152299881

Epoch: 5| Step: 9
Training loss: 4.199238300323486
Validation loss: 3.750039974848429

Epoch: 5| Step: 10
Training loss: 4.575085163116455
Validation loss: 3.7419132689634957

Epoch: 5| Step: 11
Training loss: 4.225866317749023
Validation loss: 3.733930289745331

Epoch: 27| Step: 0
Training loss: 4.7194623947143555
Validation loss: 3.7291016777356467

Epoch: 5| Step: 1
Training loss: 4.103973865509033
Validation loss: 3.724390317996343

Epoch: 5| Step: 2
Training loss: 4.088504791259766
Validation loss: 3.7191815972328186

Epoch: 5| Step: 3
Training loss: 3.840311050415039
Validation loss: 3.715478161970774

Epoch: 5| Step: 4
Training loss: 3.900630474090576
Validation loss: 3.7107326686382294

Epoch: 5| Step: 5
Training loss: 3.090242862701416
Validation loss: 3.7058104972044625

Epoch: 5| Step: 6
Training loss: 3.3180861473083496
Validation loss: 3.7014683286348977

Epoch: 5| Step: 7
Training loss: 3.1250452995300293
Validation loss: 3.6973259349664054

Epoch: 5| Step: 8
Training loss: 3.594592332839966
Validation loss: 3.692327469587326

Epoch: 5| Step: 9
Training loss: 4.36810302734375
Validation loss: 3.688724627097448

Epoch: 5| Step: 10
Training loss: 4.341912269592285
Validation loss: 3.6835149228572845

Epoch: 5| Step: 11
Training loss: 4.099460124969482
Validation loss: 3.6780966321627298

Epoch: 28| Step: 0
Training loss: 3.5858757495880127
Validation loss: 3.679851005474726

Epoch: 5| Step: 1
Training loss: 3.852687358856201
Validation loss: 3.6789975464344025

Epoch: 5| Step: 2
Training loss: 4.453494071960449
Validation loss: 3.6679981847604117

Epoch: 5| Step: 3
Training loss: 3.2489266395568848
Validation loss: 3.657574494679769

Epoch: 5| Step: 4
Training loss: 4.08860445022583
Validation loss: 3.655100146929423

Epoch: 5| Step: 5
Training loss: 3.566478729248047
Validation loss: 3.6503552198410034

Epoch: 5| Step: 6
Training loss: 4.7111430168151855
Validation loss: 3.6472889284292855

Epoch: 5| Step: 7
Training loss: 4.450131893157959
Validation loss: 3.6441557705402374

Epoch: 5| Step: 8
Training loss: 3.1097328662872314
Validation loss: 3.6380683978398642

Epoch: 5| Step: 9
Training loss: 3.5083892345428467
Validation loss: 3.632528911034266

Epoch: 5| Step: 10
Training loss: 3.4008877277374268
Validation loss: 3.6275990506013236

Epoch: 5| Step: 11
Training loss: 3.715806722640991
Validation loss: 3.623515635728836

Epoch: 29| Step: 0
Training loss: 3.8531012535095215
Validation loss: 3.6241592864195504

Epoch: 5| Step: 1
Training loss: 4.191891670227051
Validation loss: 3.615053286155065

Epoch: 5| Step: 2
Training loss: 3.5589993000030518
Validation loss: 3.606890877087911

Epoch: 5| Step: 3
Training loss: 3.453933000564575
Validation loss: 3.603280862172445

Epoch: 5| Step: 4
Training loss: 3.7479922771453857
Validation loss: 3.6011896630128226

Epoch: 5| Step: 5
Training loss: 3.995929002761841
Validation loss: 3.5969996750354767

Epoch: 5| Step: 6
Training loss: 3.248358964920044
Validation loss: 3.5927041471004486

Epoch: 5| Step: 7
Training loss: 3.227350950241089
Validation loss: 3.5873975853125253

Epoch: 5| Step: 8
Training loss: 4.339158058166504
Validation loss: 3.583981901407242

Epoch: 5| Step: 9
Training loss: 4.462368488311768
Validation loss: 3.580538183450699

Epoch: 5| Step: 10
Training loss: 3.7283053398132324
Validation loss: 3.578772028287252

Epoch: 5| Step: 11
Training loss: 1.5058579444885254
Validation loss: 3.5707183182239532

Epoch: 30| Step: 0
Training loss: 4.416015625
Validation loss: 3.5644664963086448

Epoch: 5| Step: 1
Training loss: 3.1851375102996826
Validation loss: 3.5586323539415994

Epoch: 5| Step: 2
Training loss: 3.8815689086914062
Validation loss: 3.5545538564523063

Epoch: 5| Step: 3
Training loss: 4.0729217529296875
Validation loss: 3.549213876326879

Epoch: 5| Step: 4
Training loss: 4.2709760665893555
Validation loss: 3.5447638233502707

Epoch: 5| Step: 5
Training loss: 3.3836569786071777
Validation loss: 3.5407968858877816

Epoch: 5| Step: 6
Training loss: 2.9865546226501465
Validation loss: 3.535100152095159

Epoch: 5| Step: 7
Training loss: 4.2308831214904785
Validation loss: 3.5290978252887726

Epoch: 5| Step: 8
Training loss: 3.0387866497039795
Validation loss: 3.5269775092601776

Epoch: 5| Step: 9
Training loss: 3.718395233154297
Validation loss: 3.520894080400467

Epoch: 5| Step: 10
Training loss: 3.705369472503662
Validation loss: 3.5161968171596527

Epoch: 5| Step: 11
Training loss: 3.0289394855499268
Validation loss: 3.5122534732023873

Epoch: 31| Step: 0
Training loss: 4.177923679351807
Validation loss: 3.508579730987549

Epoch: 5| Step: 1
Training loss: 3.818737745285034
Validation loss: 3.504284451405207

Epoch: 5| Step: 2
Training loss: 3.7152152061462402
Validation loss: 3.4987551172574363

Epoch: 5| Step: 3
Training loss: 4.086581230163574
Validation loss: 3.493537962436676

Epoch: 5| Step: 4
Training loss: 3.4679417610168457
Validation loss: 3.4877249002456665

Epoch: 5| Step: 5
Training loss: 3.4201552867889404
Validation loss: 3.4830410381158194

Epoch: 5| Step: 6
Training loss: 4.606686592102051
Validation loss: 3.4776326616605124

Epoch: 5| Step: 7
Training loss: 3.6332924365997314
Validation loss: 3.472380052010218

Epoch: 5| Step: 8
Training loss: 3.790388822555542
Validation loss: 3.466865668694178

Epoch: 5| Step: 9
Training loss: 2.4409542083740234
Validation loss: 3.463634431362152

Epoch: 5| Step: 10
Training loss: 2.8071188926696777
Validation loss: 3.4579570392767587

Epoch: 5| Step: 11
Training loss: 4.6107587814331055
Validation loss: 3.45390447974205

Epoch: 32| Step: 0
Training loss: 3.3305935859680176
Validation loss: 3.4505099058151245

Epoch: 5| Step: 1
Training loss: 3.233999729156494
Validation loss: 3.468299845854441

Epoch: 5| Step: 2
Training loss: 4.092835426330566
Validation loss: 3.441823442776998

Epoch: 5| Step: 3
Training loss: 3.4102749824523926
Validation loss: 3.4357752998669944

Epoch: 5| Step: 4
Training loss: 4.349376678466797
Validation loss: 3.432374894618988

Epoch: 5| Step: 5
Training loss: 3.9520785808563232
Validation loss: 3.43020968635877

Epoch: 5| Step: 6
Training loss: 2.7180066108703613
Validation loss: 3.4295987288157144

Epoch: 5| Step: 7
Training loss: 3.4267570972442627
Validation loss: 3.4260244369506836

Epoch: 5| Step: 8
Training loss: 4.014092445373535
Validation loss: 3.422123392422994

Epoch: 5| Step: 9
Training loss: 3.985806941986084
Validation loss: 3.416553278764089

Epoch: 5| Step: 10
Training loss: 3.4453845024108887
Validation loss: 3.411852687597275

Epoch: 5| Step: 11
Training loss: 1.8315616846084595
Validation loss: 3.407223512729009

Epoch: 33| Step: 0
Training loss: 3.247565746307373
Validation loss: 3.4099281628926597

Epoch: 5| Step: 1
Training loss: 3.8975894451141357
Validation loss: 3.4022861619790397

Epoch: 5| Step: 2
Training loss: 3.533708095550537
Validation loss: 3.3921387592951455

Epoch: 5| Step: 3
Training loss: 3.339254856109619
Validation loss: 3.3870918651421866

Epoch: 5| Step: 4
Training loss: 2.974424362182617
Validation loss: 3.3827484448750815

Epoch: 5| Step: 5
Training loss: 3.9613959789276123
Validation loss: 3.3795977334181466

Epoch: 5| Step: 6
Training loss: 4.3853759765625
Validation loss: 3.3757934272289276

Epoch: 5| Step: 7
Training loss: 3.691880464553833
Validation loss: 3.3730546633402505

Epoch: 5| Step: 8
Training loss: 4.498753547668457
Validation loss: 3.3689514696598053

Epoch: 5| Step: 9
Training loss: 2.9466819763183594
Validation loss: 3.3635083436965942

Epoch: 5| Step: 10
Training loss: 2.664365291595459
Validation loss: 3.358916034301122

Epoch: 5| Step: 11
Training loss: 3.063450813293457
Validation loss: 3.3545551796754203

Epoch: 34| Step: 0
Training loss: 3.4831721782684326
Validation loss: 3.350568652153015

Epoch: 5| Step: 1
Training loss: 3.1842408180236816
Validation loss: 3.3520504534244537

Epoch: 5| Step: 2
Training loss: 2.9564645290374756
Validation loss: 3.343719333410263

Epoch: 5| Step: 3
Training loss: 4.3620500564575195
Validation loss: 3.336672157049179

Epoch: 5| Step: 4
Training loss: 3.550088882446289
Validation loss: 3.3305217921733856

Epoch: 5| Step: 5
Training loss: 3.6142971515655518
Validation loss: 3.325146108865738

Epoch: 5| Step: 6
Training loss: 3.358638048171997
Validation loss: 3.3199939827124276

Epoch: 5| Step: 7
Training loss: 3.4654629230499268
Validation loss: 3.315797080596288

Epoch: 5| Step: 8
Training loss: 3.2767014503479004
Validation loss: 3.3110541005929313

Epoch: 5| Step: 9
Training loss: 3.8168282508850098
Validation loss: 3.3064315219720206

Epoch: 5| Step: 10
Training loss: 3.236825466156006
Validation loss: 3.301426867643992

Epoch: 5| Step: 11
Training loss: 4.426524639129639
Validation loss: 3.298099825779597

Epoch: 35| Step: 0
Training loss: 3.170208692550659
Validation loss: 3.2952582935492196

Epoch: 5| Step: 1
Training loss: 3.0295536518096924
Validation loss: 3.2901864449183145

Epoch: 5| Step: 2
Training loss: 3.4978325366973877
Validation loss: 3.284648229678472

Epoch: 5| Step: 3
Training loss: 3.408809185028076
Validation loss: 3.281002958615621

Epoch: 5| Step: 4
Training loss: 3.733147382736206
Validation loss: 3.2785914838314056

Epoch: 5| Step: 5
Training loss: 2.887899875640869
Validation loss: 3.2725146611531577

Epoch: 5| Step: 6
Training loss: 3.82305908203125
Validation loss: 3.2688586711883545

Epoch: 5| Step: 7
Training loss: 3.6510815620422363
Validation loss: 3.264282693465551

Epoch: 5| Step: 8
Training loss: 3.78010892868042
Validation loss: 3.2588788668314614

Epoch: 5| Step: 9
Training loss: 3.494438886642456
Validation loss: 3.2567430436611176

Epoch: 5| Step: 10
Training loss: 3.4968197345733643
Validation loss: 3.2537530759970346

Epoch: 5| Step: 11
Training loss: 3.0972938537597656
Validation loss: 3.2492839694023132

Epoch: 36| Step: 0
Training loss: 3.676851749420166
Validation loss: 3.246330817540487

Epoch: 5| Step: 1
Training loss: 2.8356997966766357
Validation loss: 3.2428163290023804

Epoch: 5| Step: 2
Training loss: 4.019837856292725
Validation loss: 3.2350671887397766

Epoch: 5| Step: 3
Training loss: 3.6385951042175293
Validation loss: 3.2302182614803314

Epoch: 5| Step: 4
Training loss: 3.4396591186523438
Validation loss: 3.226413438717524

Epoch: 5| Step: 5
Training loss: 2.898343563079834
Validation loss: 3.2203249335289

Epoch: 5| Step: 6
Training loss: 3.3269076347351074
Validation loss: 3.2164055605729422

Epoch: 5| Step: 7
Training loss: 3.99536395072937
Validation loss: 3.21384330590566

Epoch: 5| Step: 8
Training loss: 3.322477340698242
Validation loss: 3.208713948726654

Epoch: 5| Step: 9
Training loss: 3.4372425079345703
Validation loss: 3.2041294078032174

Epoch: 5| Step: 10
Training loss: 2.961258888244629
Validation loss: 3.199943115313848

Epoch: 5| Step: 11
Training loss: 2.6145882606506348
Validation loss: 3.195765266815821

Epoch: 37| Step: 0
Training loss: 2.182465076446533
Validation loss: 3.19176322221756

Epoch: 5| Step: 1
Training loss: 4.405357360839844
Validation loss: 3.1887086232503257

Epoch: 5| Step: 2
Training loss: 4.4217329025268555
Validation loss: 3.188199291626612

Epoch: 5| Step: 3
Training loss: 3.6248672008514404
Validation loss: 3.1839051942030587

Epoch: 5| Step: 4
Training loss: 2.962603807449341
Validation loss: 3.1815782487392426

Epoch: 5| Step: 5
Training loss: 3.102797508239746
Validation loss: 3.1757985055446625

Epoch: 5| Step: 6
Training loss: 3.3268768787384033
Validation loss: 3.1702429354190826

Epoch: 5| Step: 7
Training loss: 3.9894614219665527
Validation loss: 3.1648701230684915

Epoch: 5| Step: 8
Training loss: 2.985058069229126
Validation loss: 3.1594845950603485

Epoch: 5| Step: 9
Training loss: 2.380929470062256
Validation loss: 3.1566762129465737

Epoch: 5| Step: 10
Training loss: 3.1910653114318848
Validation loss: 3.1536973814169564

Epoch: 5| Step: 11
Training loss: 4.97867488861084
Validation loss: 3.154307037591934

Epoch: 38| Step: 0
Training loss: 2.7903876304626465
Validation loss: 3.145413597424825

Epoch: 5| Step: 1
Training loss: 3.6671340465545654
Validation loss: 3.145276963710785

Epoch: 5| Step: 2
Training loss: 3.697350025177002
Validation loss: 3.138672818740209

Epoch: 5| Step: 3
Training loss: 3.432985305786133
Validation loss: 3.130469709634781

Epoch: 5| Step: 4
Training loss: 3.2265915870666504
Validation loss: 3.1267868975798288

Epoch: 5| Step: 5
Training loss: 4.031735897064209
Validation loss: 3.1217337350050607

Epoch: 5| Step: 6
Training loss: 3.6361937522888184
Validation loss: 3.122873236735662

Epoch: 5| Step: 7
Training loss: 3.2179267406463623
Validation loss: 3.121781051158905

Epoch: 5| Step: 8
Training loss: 2.755309581756592
Validation loss: 3.117840568224589

Epoch: 5| Step: 9
Training loss: 3.106177568435669
Validation loss: 3.1072711646556854

Epoch: 5| Step: 10
Training loss: 2.9945645332336426
Validation loss: 3.1025000711282096

Epoch: 5| Step: 11
Training loss: 2.6488540172576904
Validation loss: 3.0957362353801727

Epoch: 39| Step: 0
Training loss: 3.226768970489502
Validation loss: 3.0935782194137573

Epoch: 5| Step: 1
Training loss: 2.550657033920288
Validation loss: 3.090671718120575

Epoch: 5| Step: 2
Training loss: 3.6511127948760986
Validation loss: 3.088842382033666

Epoch: 5| Step: 3
Training loss: 3.503544330596924
Validation loss: 3.0853414237499237

Epoch: 5| Step: 4
Training loss: 2.949016571044922
Validation loss: 3.0799673398335776

Epoch: 5| Step: 5
Training loss: 3.8544833660125732
Validation loss: 3.077251603205999

Epoch: 5| Step: 6
Training loss: 2.917173385620117
Validation loss: 3.0724331537882485

Epoch: 5| Step: 7
Training loss: 3.4106736183166504
Validation loss: 3.070269068082174

Epoch: 5| Step: 8
Training loss: 3.600799083709717
Validation loss: 3.0669098695119223

Epoch: 5| Step: 9
Training loss: 2.8238742351531982
Validation loss: 3.0649122496445975

Epoch: 5| Step: 10
Training loss: 3.609915256500244
Validation loss: 3.0627362430095673

Epoch: 5| Step: 11
Training loss: 2.27836275100708
Validation loss: 3.05731600522995

Epoch: 40| Step: 0
Training loss: 2.881462574005127
Validation loss: 3.054928481578827

Epoch: 5| Step: 1
Training loss: 3.2280685901641846
Validation loss: 3.050710052251816

Epoch: 5| Step: 2
Training loss: 3.7659859657287598
Validation loss: 3.0485578179359436

Epoch: 5| Step: 3
Training loss: 3.7335681915283203
Validation loss: 3.0460936526457467

Epoch: 5| Step: 4
Training loss: 3.6133415699005127
Validation loss: 3.0415037175019584

Epoch: 5| Step: 5
Training loss: 2.8644752502441406
Validation loss: 3.036718189716339

Epoch: 5| Step: 6
Training loss: 3.0196094512939453
Validation loss: 3.034641077121099

Epoch: 5| Step: 7
Training loss: 3.3179805278778076
Validation loss: 3.03005850315094

Epoch: 5| Step: 8
Training loss: 3.0407490730285645
Validation loss: 3.0275457302729287

Epoch: 5| Step: 9
Training loss: 2.9916670322418213
Validation loss: 3.024584839741389

Epoch: 5| Step: 10
Training loss: 3.2178707122802734
Validation loss: 3.0235361556212106

Epoch: 5| Step: 11
Training loss: 2.2065324783325195
Validation loss: 3.020493984222412

Epoch: 41| Step: 0
Training loss: 3.4164633750915527
Validation loss: 3.019961545864741

Epoch: 5| Step: 1
Training loss: 3.24579119682312
Validation loss: 3.0107889771461487

Epoch: 5| Step: 2
Training loss: 3.2962684631347656
Validation loss: 3.0079224606355033

Epoch: 5| Step: 3
Training loss: 3.462364673614502
Validation loss: 3.004109581311544

Epoch: 5| Step: 4
Training loss: 3.1462607383728027
Validation loss: 3.000182569026947

Epoch: 5| Step: 5
Training loss: 3.2968642711639404
Validation loss: 2.9975387851397195

Epoch: 5| Step: 6
Training loss: 2.4336812496185303
Validation loss: 2.9951602121194205

Epoch: 5| Step: 7
Training loss: 3.84334135055542
Validation loss: 2.99390576283137

Epoch: 5| Step: 8
Training loss: 3.5312790870666504
Validation loss: 2.990821490685145

Epoch: 5| Step: 9
Training loss: 2.8070945739746094
Validation loss: 2.9864525397618613

Epoch: 5| Step: 10
Training loss: 2.7596170902252197
Validation loss: 2.9839778939882913

Epoch: 5| Step: 11
Training loss: 2.376098871231079
Validation loss: 2.98103736837705

Epoch: 42| Step: 0
Training loss: 3.689624786376953
Validation loss: 2.9767135679721832

Epoch: 5| Step: 1
Training loss: 2.898780345916748
Validation loss: 2.9731080134709678

Epoch: 5| Step: 2
Training loss: 2.933823585510254
Validation loss: 2.970421423514684

Epoch: 5| Step: 3
Training loss: 3.258373975753784
Validation loss: 2.968572815259298

Epoch: 5| Step: 4
Training loss: 3.5910964012145996
Validation loss: 2.964751293261846

Epoch: 5| Step: 5
Training loss: 3.2782630920410156
Validation loss: 2.9637705087661743

Epoch: 5| Step: 6
Training loss: 2.939985752105713
Validation loss: 2.9569082955519357

Epoch: 5| Step: 7
Training loss: 2.9492805004119873
Validation loss: 2.9517083764076233

Epoch: 5| Step: 8
Training loss: 2.9617810249328613
Validation loss: 2.9505571524302163

Epoch: 5| Step: 9
Training loss: 2.843353748321533
Validation loss: 2.946677088737488

Epoch: 5| Step: 10
Training loss: 3.2457809448242188
Validation loss: 2.9464168747266135

Epoch: 5| Step: 11
Training loss: 3.7958030700683594
Validation loss: 2.9412381649017334

Epoch: 43| Step: 0
Training loss: 3.067422389984131
Validation loss: 2.941351672013601

Epoch: 5| Step: 1
Training loss: 3.0732815265655518
Validation loss: 2.936253398656845

Epoch: 5| Step: 2
Training loss: 3.4845688343048096
Validation loss: 2.933209776878357

Epoch: 5| Step: 3
Training loss: 3.3985495567321777
Validation loss: 2.930826783180237

Epoch: 5| Step: 4
Training loss: 3.116093158721924
Validation loss: 2.9271735350290933

Epoch: 5| Step: 5
Training loss: 2.5700626373291016
Validation loss: 2.9241551657517753

Epoch: 5| Step: 6
Training loss: 2.908583641052246
Validation loss: 2.9232386449972787

Epoch: 5| Step: 7
Training loss: 3.9011292457580566
Validation loss: 2.921778589487076

Epoch: 5| Step: 8
Training loss: 3.0079524517059326
Validation loss: 2.92099795738856

Epoch: 5| Step: 9
Training loss: 2.7953033447265625
Validation loss: 2.918654590845108

Epoch: 5| Step: 10
Training loss: 3.2633118629455566
Validation loss: 2.9166899621486664

Epoch: 5| Step: 11
Training loss: 1.8198010921478271
Validation loss: 2.9137410720189414

Epoch: 44| Step: 0
Training loss: 2.983013153076172
Validation loss: 2.9052729308605194

Epoch: 5| Step: 1
Training loss: 3.899906635284424
Validation loss: 2.9019557336966195

Epoch: 5| Step: 2
Training loss: 3.534900188446045
Validation loss: 2.8976676861445108

Epoch: 5| Step: 3
Training loss: 2.7924208641052246
Validation loss: 2.8923079570134482

Epoch: 5| Step: 4
Training loss: 2.7096164226531982
Validation loss: 2.8912202616532645

Epoch: 5| Step: 5
Training loss: 2.8728368282318115
Validation loss: 2.8870898683865867

Epoch: 5| Step: 6
Training loss: 3.3550899028778076
Validation loss: 2.8838078379631042

Epoch: 5| Step: 7
Training loss: 2.920797109603882
Validation loss: 2.8843387365341187

Epoch: 5| Step: 8
Training loss: 3.277012348175049
Validation loss: 2.880034456650416

Epoch: 5| Step: 9
Training loss: 2.82149338722229
Validation loss: 2.876821905374527

Epoch: 5| Step: 10
Training loss: 2.887104034423828
Validation loss: 2.8714956839879355

Epoch: 5| Step: 11
Training loss: 2.70573091506958
Validation loss: 2.8686316510041556

Epoch: 45| Step: 0
Training loss: 2.9266695976257324
Validation loss: 2.8692738513151803

Epoch: 5| Step: 1
Training loss: 3.5679054260253906
Validation loss: 2.865592141946157

Epoch: 5| Step: 2
Training loss: 3.0843636989593506
Validation loss: 2.8606824477513633

Epoch: 5| Step: 3
Training loss: 3.1128432750701904
Validation loss: 2.856928914785385

Epoch: 5| Step: 4
Training loss: 3.173358201980591
Validation loss: 2.854859540859858

Epoch: 5| Step: 5
Training loss: 2.7324726581573486
Validation loss: 2.8526290158430734

Epoch: 5| Step: 6
Training loss: 3.5315544605255127
Validation loss: 2.8490012685457864

Epoch: 5| Step: 7
Training loss: 2.4635186195373535
Validation loss: 2.846524626016617

Epoch: 5| Step: 8
Training loss: 3.260183334350586
Validation loss: 2.8420535922050476

Epoch: 5| Step: 9
Training loss: 3.645589828491211
Validation loss: 2.8425579766432443

Epoch: 5| Step: 10
Training loss: 2.3280465602874756
Validation loss: 2.8374071021874747

Epoch: 5| Step: 11
Training loss: 1.8642356395721436
Validation loss: 2.8357337713241577

Epoch: 46| Step: 0
Training loss: 4.265659809112549
Validation loss: 2.830370306968689

Epoch: 5| Step: 1
Training loss: 2.799304485321045
Validation loss: 2.827858338753382

Epoch: 5| Step: 2
Training loss: 2.7943012714385986
Validation loss: 2.821909854809443

Epoch: 5| Step: 3
Training loss: 3.0153603553771973
Validation loss: 2.8213755389054618

Epoch: 5| Step: 4
Training loss: 3.024451732635498
Validation loss: 2.818213274081548

Epoch: 5| Step: 5
Training loss: 3.1481471061706543
Validation loss: 2.811718136072159

Epoch: 5| Step: 6
Training loss: 3.343170166015625
Validation loss: 2.81498313943545

Epoch: 5| Step: 7
Training loss: 2.3531064987182617
Validation loss: 2.8108577132225037

Epoch: 5| Step: 8
Training loss: 3.071580410003662
Validation loss: 2.808268348375956

Epoch: 5| Step: 9
Training loss: 2.8621697425842285
Validation loss: 2.8016250332196555

Epoch: 5| Step: 10
Training loss: 2.570035457611084
Validation loss: 2.800280670324961

Epoch: 5| Step: 11
Training loss: 2.808483123779297
Validation loss: 2.7989435891310372

Epoch: 47| Step: 0
Training loss: 2.9254791736602783
Validation loss: 2.7976607382297516

Epoch: 5| Step: 1
Training loss: 3.190908670425415
Validation loss: 2.791132162014643

Epoch: 5| Step: 2
Training loss: 2.848031520843506
Validation loss: 2.7867472966512046

Epoch: 5| Step: 3
Training loss: 2.9462263584136963
Validation loss: 2.7840402722358704

Epoch: 5| Step: 4
Training loss: 3.47920560836792
Validation loss: 2.7761411567529044

Epoch: 5| Step: 5
Training loss: 3.5986714363098145
Validation loss: 2.7761759161949158

Epoch: 5| Step: 6
Training loss: 2.4460673332214355
Validation loss: 2.7726374169190726

Epoch: 5| Step: 7
Training loss: 2.7882163524627686
Validation loss: 2.7693925499916077

Epoch: 5| Step: 8
Training loss: 3.2284016609191895
Validation loss: 2.7680254777272544

Epoch: 5| Step: 9
Training loss: 2.6810684204101562
Validation loss: 2.7643561561902366

Epoch: 5| Step: 10
Training loss: 2.7587971687316895
Validation loss: 2.7626621226469674

Epoch: 5| Step: 11
Training loss: 2.7008750438690186
Validation loss: 2.7597965399424234

Epoch: 48| Step: 0
Training loss: 2.718648910522461
Validation loss: 2.757718861103058

Epoch: 5| Step: 1
Training loss: 2.803743362426758
Validation loss: 2.7549605667591095

Epoch: 5| Step: 2
Training loss: 2.551882266998291
Validation loss: 2.7506766517957053

Epoch: 5| Step: 3
Training loss: 3.059363603591919
Validation loss: 2.754207948843638

Epoch: 5| Step: 4
Training loss: 3.0982697010040283
Validation loss: 2.7488894859949746

Epoch: 5| Step: 5
Training loss: 2.945185899734497
Validation loss: 2.745428204536438

Epoch: 5| Step: 6
Training loss: 2.8114216327667236
Validation loss: 2.7423403362433114

Epoch: 5| Step: 7
Training loss: 2.784409999847412
Validation loss: 2.7375892400741577

Epoch: 5| Step: 8
Training loss: 3.095154047012329
Validation loss: 2.7339603503545127

Epoch: 5| Step: 9
Training loss: 3.0686373710632324
Validation loss: 2.7309474448362985

Epoch: 5| Step: 10
Training loss: 3.706035614013672
Validation loss: 2.7300827403863273

Epoch: 5| Step: 11
Training loss: 1.6582677364349365
Validation loss: 2.725822697083155

Epoch: 49| Step: 0
Training loss: 2.2562193870544434
Validation loss: 2.7236236234505973

Epoch: 5| Step: 1
Training loss: 2.3290512561798096
Validation loss: 2.719522068897883

Epoch: 5| Step: 2
Training loss: 2.8623204231262207
Validation loss: 2.717481623093287

Epoch: 5| Step: 3
Training loss: 3.4156546592712402
Validation loss: 2.715240240097046

Epoch: 5| Step: 4
Training loss: 2.9417243003845215
Validation loss: 2.71450142065684

Epoch: 5| Step: 5
Training loss: 3.2737839221954346
Validation loss: 2.7083065708478293

Epoch: 5| Step: 6
Training loss: 2.8613200187683105
Validation loss: 2.7088544766108194

Epoch: 5| Step: 7
Training loss: 3.5202178955078125
Validation loss: 2.7079632580280304

Epoch: 5| Step: 8
Training loss: 2.788872241973877
Validation loss: 2.7094422578811646

Epoch: 5| Step: 9
Training loss: 2.59975004196167
Validation loss: 2.7058297296365104

Epoch: 5| Step: 10
Training loss: 3.0641655921936035
Validation loss: 2.701102008422216

Epoch: 5| Step: 11
Training loss: 3.282607316970825
Validation loss: 2.6948284904162088

Epoch: 50| Step: 0
Training loss: 3.3080787658691406
Validation loss: 2.6957127451896667

Epoch: 5| Step: 1
Training loss: 2.718090057373047
Validation loss: 2.688247263431549

Epoch: 5| Step: 2
Training loss: 2.8396496772766113
Validation loss: 2.690169264872869

Epoch: 5| Step: 3
Training loss: 2.8474526405334473
Validation loss: 2.683628261089325

Epoch: 5| Step: 4
Training loss: 2.8428421020507812
Validation loss: 2.6784364879131317

Epoch: 5| Step: 5
Training loss: 2.6409912109375
Validation loss: 2.6788987616697946

Epoch: 5| Step: 6
Training loss: 2.902036190032959
Validation loss: 2.6709982256094613

Epoch: 5| Step: 7
Training loss: 2.8113839626312256
Validation loss: 2.668342391649882

Epoch: 5| Step: 8
Training loss: 2.798107147216797
Validation loss: 2.6664450764656067

Epoch: 5| Step: 9
Training loss: 2.7158453464508057
Validation loss: 2.677328517039617

Epoch: 5| Step: 10
Training loss: 3.09382700920105
Validation loss: 2.6648624340693154

Epoch: 5| Step: 11
Training loss: 3.460268974304199
Validation loss: 2.6696043809254966

Epoch: 51| Step: 0
Training loss: 2.5392887592315674
Validation loss: 2.6587887008984885

Epoch: 5| Step: 1
Training loss: 2.925037145614624
Validation loss: 2.6595795353253684

Epoch: 5| Step: 2
Training loss: 3.142369270324707
Validation loss: 2.656095107396444

Epoch: 5| Step: 3
Training loss: 2.4876327514648438
Validation loss: 2.64959787329038

Epoch: 5| Step: 4
Training loss: 2.5485053062438965
Validation loss: 2.646934707959493

Epoch: 5| Step: 5
Training loss: 2.4618115425109863
Validation loss: 2.655055661996206

Epoch: 5| Step: 6
Training loss: 2.732361316680908
Validation loss: 2.646070977052053

Epoch: 5| Step: 7
Training loss: 3.2866508960723877
Validation loss: 2.6414000391960144

Epoch: 5| Step: 8
Training loss: 2.8749380111694336
Validation loss: 2.637459466854731

Epoch: 5| Step: 9
Training loss: 3.317483901977539
Validation loss: 2.634104405840238

Epoch: 5| Step: 10
Training loss: 2.7853522300720215
Validation loss: 2.631799747546514

Epoch: 5| Step: 11
Training loss: 3.5463874340057373
Validation loss: 2.630909929672877

Epoch: 52| Step: 0
Training loss: 2.294137954711914
Validation loss: 2.6269435038169227

Epoch: 5| Step: 1
Training loss: 3.1717183589935303
Validation loss: 2.6300358275572457

Epoch: 5| Step: 2
Training loss: 2.858100175857544
Validation loss: 2.6265861988067627

Epoch: 5| Step: 3
Training loss: 2.862588882446289
Validation loss: 2.62018949786822

Epoch: 5| Step: 4
Training loss: 2.733682155609131
Validation loss: 2.618416448434194

Epoch: 5| Step: 5
Training loss: 2.90584659576416
Validation loss: 2.61466321349144

Epoch: 5| Step: 6
Training loss: 2.927924633026123
Validation loss: 2.6111679673194885

Epoch: 5| Step: 7
Training loss: 3.088270664215088
Validation loss: 2.6108894447485604

Epoch: 5| Step: 8
Training loss: 2.2128653526306152
Validation loss: 2.607019970814387

Epoch: 5| Step: 9
Training loss: 3.020747661590576
Validation loss: 2.6043547093868256

Epoch: 5| Step: 10
Training loss: 3.0235655307769775
Validation loss: 2.600847045580546

Epoch: 5| Step: 11
Training loss: 1.9573243856430054
Validation loss: 2.600477397441864

Epoch: 53| Step: 0
Training loss: 3.0870330333709717
Validation loss: 2.5978931883970895

Epoch: 5| Step: 1
Training loss: 2.507205009460449
Validation loss: 2.591916193564733

Epoch: 5| Step: 2
Training loss: 3.001940965652466
Validation loss: 2.5915997127691903

Epoch: 5| Step: 3
Training loss: 2.9493825435638428
Validation loss: 2.586024651924769

Epoch: 5| Step: 4
Training loss: 2.4976391792297363
Validation loss: 2.5820503334204354

Epoch: 5| Step: 5
Training loss: 2.8180816173553467
Validation loss: 2.5826403299967446

Epoch: 5| Step: 6
Training loss: 3.3173537254333496
Validation loss: 2.580194443464279

Epoch: 5| Step: 7
Training loss: 2.6012394428253174
Validation loss: 2.5777814984321594

Epoch: 5| Step: 8
Training loss: 2.3463244438171387
Validation loss: 2.575066884358724

Epoch: 5| Step: 9
Training loss: 2.474163770675659
Validation loss: 2.574102600415548

Epoch: 5| Step: 10
Training loss: 2.9386355876922607
Validation loss: 2.570239633321762

Epoch: 5| Step: 11
Training loss: 2.9734854698181152
Validation loss: 2.567121068636576

Epoch: 54| Step: 0
Training loss: 2.4620041847229004
Validation loss: 2.5620887080828347

Epoch: 5| Step: 1
Training loss: 3.3043360710144043
Validation loss: 2.5691762963930764

Epoch: 5| Step: 2
Training loss: 3.0131163597106934
Validation loss: 2.569150229295095

Epoch: 5| Step: 3
Training loss: 2.4654030799865723
Validation loss: 2.5601810018221536

Epoch: 5| Step: 4
Training loss: 2.915170192718506
Validation loss: 2.5557883183161416

Epoch: 5| Step: 5
Training loss: 1.9488375186920166
Validation loss: 2.554485330979029

Epoch: 5| Step: 6
Training loss: 2.9386634826660156
Validation loss: 2.5507128834724426

Epoch: 5| Step: 7
Training loss: 2.9323174953460693
Validation loss: 2.552153463164965

Epoch: 5| Step: 8
Training loss: 2.781575918197632
Validation loss: 2.559657076994578

Epoch: 5| Step: 9
Training loss: 2.8473362922668457
Validation loss: 2.5583809514840445

Epoch: 5| Step: 10
Training loss: 2.706651210784912
Validation loss: 2.551240548491478

Epoch: 5| Step: 11
Training loss: 2.2274112701416016
Validation loss: 2.5477131009101868

Epoch: 55| Step: 0
Training loss: 2.3763628005981445
Validation loss: 2.5375286837418876

Epoch: 5| Step: 1
Training loss: 2.3592000007629395
Validation loss: 2.5338138043880463

Epoch: 5| Step: 2
Training loss: 2.545097827911377
Validation loss: 2.5379854639371238

Epoch: 5| Step: 3
Training loss: 2.282501697540283
Validation loss: 2.5381255944569907

Epoch: 5| Step: 4
Training loss: 2.9598629474639893
Validation loss: 2.54245463013649

Epoch: 5| Step: 5
Training loss: 2.79994535446167
Validation loss: 2.555737396081289

Epoch: 5| Step: 6
Training loss: 2.6616499423980713
Validation loss: 2.533839682737986

Epoch: 5| Step: 7
Training loss: 2.5699405670166016
Validation loss: 2.517484118541082

Epoch: 5| Step: 8
Training loss: 3.006746768951416
Validation loss: 2.5186924934387207

Epoch: 5| Step: 9
Training loss: 3.170442581176758
Validation loss: 2.5144960979620614

Epoch: 5| Step: 10
Training loss: 2.9984545707702637
Validation loss: 2.5129383901755014

Epoch: 5| Step: 11
Training loss: 3.9990081787109375
Validation loss: 2.5100445548693338

Epoch: 56| Step: 0
Training loss: 3.0054538249969482
Validation loss: 2.5058255891005197

Epoch: 5| Step: 1
Training loss: 2.845524549484253
Validation loss: 2.5048068861166635

Epoch: 5| Step: 2
Training loss: 2.6436591148376465
Validation loss: 2.5027112563451133

Epoch: 5| Step: 3
Training loss: 2.7211368083953857
Validation loss: 2.5039966901143393

Epoch: 5| Step: 4
Training loss: 2.8148281574249268
Validation loss: 2.500875641902288

Epoch: 5| Step: 5
Training loss: 2.761270523071289
Validation loss: 2.497923413912455

Epoch: 5| Step: 6
Training loss: 2.6162900924682617
Validation loss: 2.4937956432501474

Epoch: 5| Step: 7
Training loss: 2.7307584285736084
Validation loss: 2.4893456796805062

Epoch: 5| Step: 8
Training loss: 3.195302724838257
Validation loss: 2.4879771371682486

Epoch: 5| Step: 9
Training loss: 2.5304856300354004
Validation loss: 2.489782214164734

Epoch: 5| Step: 10
Training loss: 1.7807064056396484
Validation loss: 2.4857573807239532

Epoch: 5| Step: 11
Training loss: 2.2750844955444336
Validation loss: 2.4888339241345725

Epoch: 57| Step: 0
Training loss: 2.423743486404419
Validation loss: 2.4851793497800827

Epoch: 5| Step: 1
Training loss: 2.695218324661255
Validation loss: 2.476591189702352

Epoch: 5| Step: 2
Training loss: 3.216193675994873
Validation loss: 2.4750254253546395

Epoch: 5| Step: 3
Training loss: 2.268507242202759
Validation loss: 2.4719722072283425

Epoch: 5| Step: 4
Training loss: 3.107832431793213
Validation loss: 2.4660436312357583

Epoch: 5| Step: 5
Training loss: 2.305938959121704
Validation loss: 2.467332432667414

Epoch: 5| Step: 6
Training loss: 2.7566535472869873
Validation loss: 2.463624278704325

Epoch: 5| Step: 7
Training loss: 2.409811019897461
Validation loss: 2.4615446031093597

Epoch: 5| Step: 8
Training loss: 3.055586576461792
Validation loss: 2.4578434924284616

Epoch: 5| Step: 9
Training loss: 2.6515588760375977
Validation loss: 2.455214743812879

Epoch: 5| Step: 10
Training loss: 2.3789870738983154
Validation loss: 2.455824136734009

Epoch: 5| Step: 11
Training loss: 2.4832515716552734
Validation loss: 2.4556101262569427

Epoch: 58| Step: 0
Training loss: 2.3187685012817383
Validation loss: 2.450140873591105

Epoch: 5| Step: 1
Training loss: 2.129809617996216
Validation loss: 2.4463818023602166

Epoch: 5| Step: 2
Training loss: 2.481484889984131
Validation loss: 2.446019877990087

Epoch: 5| Step: 3
Training loss: 2.61078143119812
Validation loss: 2.4415319363276162

Epoch: 5| Step: 4
Training loss: 2.060631513595581
Validation loss: 2.4430342068274817

Epoch: 5| Step: 5
Training loss: 3.0352046489715576
Validation loss: 2.440231055021286

Epoch: 5| Step: 6
Training loss: 2.7148818969726562
Validation loss: 2.435209403435389

Epoch: 5| Step: 7
Training loss: 2.9520440101623535
Validation loss: 2.43327804406484

Epoch: 5| Step: 8
Training loss: 2.732516288757324
Validation loss: 2.430893361568451

Epoch: 5| Step: 9
Training loss: 3.1785407066345215
Validation loss: 2.4300612409909568

Epoch: 5| Step: 10
Training loss: 2.718353748321533
Validation loss: 2.427654286225637

Epoch: 5| Step: 11
Training loss: 2.1576244831085205
Validation loss: 2.4258507192134857

Epoch: 59| Step: 0
Training loss: 2.757997989654541
Validation loss: 2.424568126598994

Epoch: 5| Step: 1
Training loss: 2.850903034210205
Validation loss: 2.42230216662089

Epoch: 5| Step: 2
Training loss: 2.6482911109924316
Validation loss: 2.4212249716122947

Epoch: 5| Step: 3
Training loss: 2.273686170578003
Validation loss: 2.421607588728269

Epoch: 5| Step: 4
Training loss: 2.9955618381500244
Validation loss: 2.425217022498449

Epoch: 5| Step: 5
Training loss: 2.471405506134033
Validation loss: 2.4204564491907754

Epoch: 5| Step: 6
Training loss: 2.6088955402374268
Validation loss: 2.4187971452871957

Epoch: 5| Step: 7
Training loss: 2.855945587158203
Validation loss: 2.411350061496099

Epoch: 5| Step: 8
Training loss: 3.082338571548462
Validation loss: 2.408266544342041

Epoch: 5| Step: 9
Training loss: 1.793148398399353
Validation loss: 2.4003442327181497

Epoch: 5| Step: 10
Training loss: 2.136256217956543
Validation loss: 2.401352415482203

Epoch: 5| Step: 11
Training loss: 2.799199104309082
Validation loss: 2.4029962917168937

Epoch: 60| Step: 0
Training loss: 1.793532133102417
Validation loss: 2.4055381417274475

Epoch: 5| Step: 1
Training loss: 1.93910813331604
Validation loss: 2.4076494375864663

Epoch: 5| Step: 2
Training loss: 2.482754707336426
Validation loss: 2.4081306556860604

Epoch: 5| Step: 3
Training loss: 2.8129148483276367
Validation loss: 2.404200663169225

Epoch: 5| Step: 4
Training loss: 2.6944499015808105
Validation loss: 2.3979702293872833

Epoch: 5| Step: 5
Training loss: 2.859616756439209
Validation loss: 2.4000785052776337

Epoch: 5| Step: 6
Training loss: 2.5011303424835205
Validation loss: 2.386982962489128

Epoch: 5| Step: 7
Training loss: 2.480548143386841
Validation loss: 2.3850374122460685

Epoch: 5| Step: 8
Training loss: 2.935253858566284
Validation loss: 2.378173808256785

Epoch: 5| Step: 9
Training loss: 2.5754237174987793
Validation loss: 2.3762155969937644

Epoch: 5| Step: 10
Training loss: 3.0726637840270996
Validation loss: 2.3778229504823685

Epoch: 5| Step: 11
Training loss: 3.134298324584961
Validation loss: 2.3697438736756644

Epoch: 61| Step: 0
Training loss: 2.4608869552612305
Validation loss: 2.369586010773977

Epoch: 5| Step: 1
Training loss: 2.837963819503784
Validation loss: 2.3658868173758187

Epoch: 5| Step: 2
Training loss: 2.725594997406006
Validation loss: 2.366746813058853

Epoch: 5| Step: 3
Training loss: 2.4868617057800293
Validation loss: 2.363929053147634

Epoch: 5| Step: 4
Training loss: 2.253485918045044
Validation loss: 2.372689073284467

Epoch: 5| Step: 5
Training loss: 2.307281017303467
Validation loss: 2.3792755603790283

Epoch: 5| Step: 6
Training loss: 2.3798346519470215
Validation loss: 2.3608188927173615

Epoch: 5| Step: 7
Training loss: 2.8420958518981934
Validation loss: 2.3562483936548233

Epoch: 5| Step: 8
Training loss: 2.482546329498291
Validation loss: 2.3520126243432364

Epoch: 5| Step: 9
Training loss: 2.106220245361328
Validation loss: 2.3530439337094626

Epoch: 5| Step: 10
Training loss: 3.0916075706481934
Validation loss: 2.3615149358908334

Epoch: 5| Step: 11
Training loss: 2.7879676818847656
Validation loss: 2.369647115468979

Epoch: 62| Step: 0
Training loss: 2.7408385276794434
Validation loss: 2.3773545920848846

Epoch: 5| Step: 1
Training loss: 2.919304609298706
Validation loss: 2.3708662589391074

Epoch: 5| Step: 2
Training loss: 1.7797107696533203
Validation loss: 2.3610581854979196

Epoch: 5| Step: 3
Training loss: 2.52329683303833
Validation loss: 2.3527873158454895

Epoch: 5| Step: 4
Training loss: 2.726731777191162
Validation loss: 2.345991830031077

Epoch: 5| Step: 5
Training loss: 2.4064862728118896
Validation loss: 2.3438039670387902

Epoch: 5| Step: 6
Training loss: 2.7144317626953125
Validation loss: 2.3420976797739663

Epoch: 5| Step: 7
Training loss: 2.299868583679199
Validation loss: 2.3383689721425376

Epoch: 5| Step: 8
Training loss: 2.862852096557617
Validation loss: 2.3376464446385703

Epoch: 5| Step: 9
Training loss: 2.66231107711792
Validation loss: 2.3371061583360038

Epoch: 5| Step: 10
Training loss: 2.1368000507354736
Validation loss: 2.333009898662567

Epoch: 5| Step: 11
Training loss: 2.2171151638031006
Validation loss: 2.3320287565390267

Epoch: 63| Step: 0
Training loss: 2.56109881401062
Validation loss: 2.3224759101867676

Epoch: 5| Step: 1
Training loss: 2.7997632026672363
Validation loss: 2.322571257750193

Epoch: 5| Step: 2
Training loss: 2.428783416748047
Validation loss: 2.3216840624809265

Epoch: 5| Step: 3
Training loss: 2.651196002960205
Validation loss: 2.3259716033935547

Epoch: 5| Step: 4
Training loss: 2.6399662494659424
Validation loss: 2.3195639153321586

Epoch: 5| Step: 5
Training loss: 2.5057947635650635
Validation loss: 2.313663065433502

Epoch: 5| Step: 6
Training loss: 2.633798599243164
Validation loss: 2.320392439762751

Epoch: 5| Step: 7
Training loss: 2.3954403400421143
Validation loss: 2.3137864023447037

Epoch: 5| Step: 8
Training loss: 2.3005402088165283
Validation loss: 2.31403457125028

Epoch: 5| Step: 9
Training loss: 2.4147558212280273
Validation loss: 2.314644972483317

Epoch: 5| Step: 10
Training loss: 2.0927109718322754
Validation loss: 2.305920531352361

Epoch: 5| Step: 11
Training loss: 2.1012253761291504
Validation loss: 2.3053917487462363

Epoch: 64| Step: 0
Training loss: 2.6730613708496094
Validation loss: 2.2971885402997336

Epoch: 5| Step: 1
Training loss: 2.6283493041992188
Validation loss: 2.298766473929087

Epoch: 5| Step: 2
Training loss: 2.2498276233673096
Validation loss: 2.29886461297671

Epoch: 5| Step: 3
Training loss: 2.7049624919891357
Validation loss: 2.297379126151403

Epoch: 5| Step: 4
Training loss: 3.054539203643799
Validation loss: 2.2991329431533813

Epoch: 5| Step: 5
Training loss: 2.5305447578430176
Validation loss: 2.2880955636501312

Epoch: 5| Step: 6
Training loss: 2.1404242515563965
Validation loss: 2.292648380001386

Epoch: 5| Step: 7
Training loss: 2.710848331451416
Validation loss: 2.2899185518423715

Epoch: 5| Step: 8
Training loss: 1.9023401737213135
Validation loss: 2.2881943384806314

Epoch: 5| Step: 9
Training loss: 1.7012611627578735
Validation loss: 2.283241723974546

Epoch: 5| Step: 10
Training loss: 2.9786343574523926
Validation loss: 2.2795375188191733

Epoch: 5| Step: 11
Training loss: 1.2067251205444336
Validation loss: 2.278866390387217

Epoch: 65| Step: 0
Training loss: 2.7458972930908203
Validation loss: 2.281468470891317

Epoch: 5| Step: 1
Training loss: 2.040834426879883
Validation loss: 2.2840524315834045

Epoch: 5| Step: 2
Training loss: 2.6391448974609375
Validation loss: 2.274057239294052

Epoch: 5| Step: 3
Training loss: 2.109689235687256
Validation loss: 2.2759472131729126

Epoch: 5| Step: 4
Training loss: 2.376004934310913
Validation loss: 2.2719258864720664

Epoch: 5| Step: 5
Training loss: 2.8026747703552246
Validation loss: 2.269568055868149

Epoch: 5| Step: 6
Training loss: 2.4466233253479004
Validation loss: 2.2697617411613464

Epoch: 5| Step: 7
Training loss: 2.176647186279297
Validation loss: 2.268245756626129

Epoch: 5| Step: 8
Training loss: 2.733333110809326
Validation loss: 2.2648384471734366

Epoch: 5| Step: 9
Training loss: 2.19810152053833
Validation loss: 2.2610151767730713

Epoch: 5| Step: 10
Training loss: 2.435870409011841
Validation loss: 2.262064983447393

Epoch: 5| Step: 11
Training loss: 2.565401554107666
Validation loss: 2.256318842371305

Epoch: 66| Step: 0
Training loss: 2.8808231353759766
Validation loss: 2.2547875493764877

Epoch: 5| Step: 1
Training loss: 2.9802746772766113
Validation loss: 2.253417839606603

Epoch: 5| Step: 2
Training loss: 3.1306769847869873
Validation loss: 2.2463101744651794

Epoch: 5| Step: 3
Training loss: 2.461217164993286
Validation loss: 2.241065969069799

Epoch: 5| Step: 4
Training loss: 3.0740880966186523
Validation loss: 2.2445138543844223

Epoch: 5| Step: 5
Training loss: 1.7870738506317139
Validation loss: 2.247614790995916

Epoch: 5| Step: 6
Training loss: 2.2020435333251953
Validation loss: 2.247028261423111

Epoch: 5| Step: 7
Training loss: 2.234508991241455
Validation loss: 2.238080461819967

Epoch: 5| Step: 8
Training loss: 1.5835756063461304
Validation loss: 2.235260302821795

Epoch: 5| Step: 9
Training loss: 2.550607681274414
Validation loss: 2.2401527961095176

Epoch: 5| Step: 10
Training loss: 1.4744491577148438
Validation loss: 2.230601211388906

Epoch: 5| Step: 11
Training loss: 2.7456889152526855
Validation loss: 2.2254858911037445

Epoch: 67| Step: 0
Training loss: 2.059903621673584
Validation loss: 2.22877066830794

Epoch: 5| Step: 1
Training loss: 2.413644790649414
Validation loss: 2.225354492664337

Epoch: 5| Step: 2
Training loss: 2.6198058128356934
Validation loss: 2.226468543211619

Epoch: 5| Step: 3
Training loss: 2.416761875152588
Validation loss: 2.230087732275327

Epoch: 5| Step: 4
Training loss: 2.5520973205566406
Validation loss: 2.228745470444361

Epoch: 5| Step: 5
Training loss: 2.1371631622314453
Validation loss: 2.2263888319333396

Epoch: 5| Step: 6
Training loss: 2.640556812286377
Validation loss: 2.226222256819407

Epoch: 5| Step: 7
Training loss: 2.7555363178253174
Validation loss: 2.2265034715334573

Epoch: 5| Step: 8
Training loss: 2.2236857414245605
Validation loss: 2.2275212605794272

Epoch: 5| Step: 9
Training loss: 1.7025120258331299
Validation loss: 2.227278639872869

Epoch: 5| Step: 10
Training loss: 2.7256553173065186
Validation loss: 2.2240869998931885

Epoch: 5| Step: 11
Training loss: 1.8248543739318848
Validation loss: 2.220871557792028

Epoch: 68| Step: 0
Training loss: 2.35017466545105
Validation loss: 2.213537022471428

Epoch: 5| Step: 1
Training loss: 2.545762062072754
Validation loss: 2.2195476988951364

Epoch: 5| Step: 2
Training loss: 2.0960142612457275
Validation loss: 2.221046343445778

Epoch: 5| Step: 3
Training loss: 2.39306378364563
Validation loss: 2.214299519856771

Epoch: 5| Step: 4
Training loss: 2.184330463409424
Validation loss: 2.21428515513738

Epoch: 5| Step: 5
Training loss: 2.1463892459869385
Validation loss: 2.2109875281651816

Epoch: 5| Step: 6
Training loss: 2.734530210494995
Validation loss: 2.20931139588356

Epoch: 5| Step: 7
Training loss: 2.861961841583252
Validation loss: 2.2063552935918174

Epoch: 5| Step: 8
Training loss: 2.340376853942871
Validation loss: 2.204857071240743

Epoch: 5| Step: 9
Training loss: 1.9633820056915283
Validation loss: 2.1981901625792184

Epoch: 5| Step: 10
Training loss: 2.489497184753418
Validation loss: 2.206350306669871

Epoch: 5| Step: 11
Training loss: 1.8964629173278809
Validation loss: 2.204322099685669

Epoch: 69| Step: 0
Training loss: 2.2307090759277344
Validation loss: 2.1990185379981995

Epoch: 5| Step: 1
Training loss: 2.4223532676696777
Validation loss: 2.1984313130378723

Epoch: 5| Step: 2
Training loss: 3.2518646717071533
Validation loss: 2.204147865374883

Epoch: 5| Step: 3
Training loss: 2.3748440742492676
Validation loss: 2.206103891134262

Epoch: 5| Step: 4
Training loss: 2.6876838207244873
Validation loss: 2.2026242862145105

Epoch: 5| Step: 5
Training loss: 2.3446874618530273
Validation loss: 2.20401331782341

Epoch: 5| Step: 6
Training loss: 2.0910067558288574
Validation loss: 2.2038263777891793

Epoch: 5| Step: 7
Training loss: 1.9855972528457642
Validation loss: 2.199339061975479

Epoch: 5| Step: 8
Training loss: 1.800432562828064
Validation loss: 2.192733327547709

Epoch: 5| Step: 9
Training loss: 2.4793951511383057
Validation loss: 2.1887033929427466

Epoch: 5| Step: 10
Training loss: 2.168776035308838
Validation loss: 2.1831131329139075

Epoch: 5| Step: 11
Training loss: 2.4905359745025635
Validation loss: 2.179453824957212

Epoch: 70| Step: 0
Training loss: 1.8550201654434204
Validation loss: 2.1867288698752723

Epoch: 5| Step: 1
Training loss: 2.3633103370666504
Validation loss: 2.2173554499944053

Epoch: 5| Step: 2
Training loss: 2.225782871246338
Validation loss: 2.244652584195137

Epoch: 5| Step: 3
Training loss: 1.679886817932129
Validation loss: 2.252922793229421

Epoch: 5| Step: 4
Training loss: 2.934985876083374
Validation loss: 2.23467285434405

Epoch: 5| Step: 5
Training loss: 2.2989163398742676
Validation loss: 2.206230675180753

Epoch: 5| Step: 6
Training loss: 2.8114476203918457
Validation loss: 2.1961104373137155

Epoch: 5| Step: 7
Training loss: 2.4992454051971436
Validation loss: 2.186728835105896

Epoch: 5| Step: 8
Training loss: 2.5158066749572754
Validation loss: 2.187194138765335

Epoch: 5| Step: 9
Training loss: 2.7988297939300537
Validation loss: 2.184758429725965

Epoch: 5| Step: 10
Training loss: 2.054746389389038
Validation loss: 2.1826781233151755

Epoch: 5| Step: 11
Training loss: 2.5613040924072266
Validation loss: 2.180952697992325

Epoch: 71| Step: 0
Training loss: 2.613302707672119
Validation loss: 2.2024671534697213

Epoch: 5| Step: 1
Training loss: 1.9389173984527588
Validation loss: 2.2202291786670685

Epoch: 5| Step: 2
Training loss: 2.1739227771759033
Validation loss: 2.233731394012769

Epoch: 5| Step: 3
Training loss: 2.409864902496338
Validation loss: 2.225126733382543

Epoch: 5| Step: 4
Training loss: 2.8138070106506348
Validation loss: 2.224243611097336

Epoch: 5| Step: 5
Training loss: 2.336862087249756
Validation loss: 2.217704842487971

Epoch: 5| Step: 6
Training loss: 2.3861498832702637
Validation loss: 2.200564826528231

Epoch: 5| Step: 7
Training loss: 2.3702635765075684
Validation loss: 2.1933393279711404

Epoch: 5| Step: 8
Training loss: 1.6976608037948608
Validation loss: 2.183288832505544

Epoch: 5| Step: 9
Training loss: 2.6858649253845215
Validation loss: 2.1727077464262643

Epoch: 5| Step: 10
Training loss: 2.5502572059631348
Validation loss: 2.1639681259791055

Epoch: 5| Step: 11
Training loss: 1.8493461608886719
Validation loss: 2.1593237469593682

Epoch: 72| Step: 0
Training loss: 2.082744836807251
Validation loss: 2.1510977198680243

Epoch: 5| Step: 1
Training loss: 2.0918288230895996
Validation loss: 2.150221675634384

Epoch: 5| Step: 2
Training loss: 2.734531879425049
Validation loss: 2.1496333380540213

Epoch: 5| Step: 3
Training loss: 1.9549976587295532
Validation loss: 2.1414412359396615

Epoch: 5| Step: 4
Training loss: 2.751678466796875
Validation loss: 2.1475482334693274

Epoch: 5| Step: 5
Training loss: 3.094567060470581
Validation loss: 2.14334707458814

Epoch: 5| Step: 6
Training loss: 1.893477439880371
Validation loss: 2.145221640666326

Epoch: 5| Step: 7
Training loss: 2.764364719390869
Validation loss: 2.1331974317630134

Epoch: 5| Step: 8
Training loss: 2.2825875282287598
Validation loss: 2.131513461470604

Epoch: 5| Step: 9
Training loss: 1.6133676767349243
Validation loss: 2.131516029437383

Epoch: 5| Step: 10
Training loss: 2.0603384971618652
Validation loss: 2.127534290154775

Epoch: 5| Step: 11
Training loss: 2.762533664703369
Validation loss: 2.135821208357811

Epoch: 73| Step: 0
Training loss: 2.566633939743042
Validation loss: 2.127541184425354

Epoch: 5| Step: 1
Training loss: 2.8518218994140625
Validation loss: 2.1357380400101342

Epoch: 5| Step: 2
Training loss: 1.8321651220321655
Validation loss: 2.1383222242196402

Epoch: 5| Step: 3
Training loss: 2.327357053756714
Validation loss: 2.1426550845305123

Epoch: 5| Step: 4
Training loss: 2.427082061767578
Validation loss: 2.1378592252731323

Epoch: 5| Step: 5
Training loss: 2.2929093837738037
Validation loss: 2.138123462597529

Epoch: 5| Step: 6
Training loss: 2.229409694671631
Validation loss: 2.14040644466877

Epoch: 5| Step: 7
Training loss: 2.5447516441345215
Validation loss: 2.1399152874946594

Epoch: 5| Step: 8
Training loss: 2.3965907096862793
Validation loss: 2.1345525284608207

Epoch: 5| Step: 9
Training loss: 2.344815969467163
Validation loss: 2.1334688663482666

Epoch: 5| Step: 10
Training loss: 1.693268060684204
Validation loss: 2.1328275899092355

Epoch: 5| Step: 11
Training loss: 0.9523783922195435
Validation loss: 2.126444548368454

Epoch: 74| Step: 0
Training loss: 1.9069411754608154
Validation loss: 2.1289439102013907

Epoch: 5| Step: 1
Training loss: 2.7823805809020996
Validation loss: 2.121083438396454

Epoch: 5| Step: 2
Training loss: 2.3101258277893066
Validation loss: 2.124265030026436

Epoch: 5| Step: 3
Training loss: 1.853926420211792
Validation loss: 2.123912826180458

Epoch: 5| Step: 4
Training loss: 2.7168478965759277
Validation loss: 2.1192722717920938

Epoch: 5| Step: 5
Training loss: 2.767360210418701
Validation loss: 2.120457967122396

Epoch: 5| Step: 6
Training loss: 2.090317487716675
Validation loss: 2.1127479821443558

Epoch: 5| Step: 7
Training loss: 1.9107036590576172
Validation loss: 2.1116940726836524

Epoch: 5| Step: 8
Training loss: 2.064894199371338
Validation loss: 2.111696779727936

Epoch: 5| Step: 9
Training loss: 2.4049623012542725
Validation loss: 2.1077629725138345

Epoch: 5| Step: 10
Training loss: 2.3925223350524902
Validation loss: 2.112798184156418

Epoch: 5| Step: 11
Training loss: 1.3711652755737305
Validation loss: 2.104489346345266

Epoch: 75| Step: 0
Training loss: 2.430708646774292
Validation loss: 2.1074479619661965

Epoch: 5| Step: 1
Training loss: 1.7259712219238281
Validation loss: 2.1067626625299454

Epoch: 5| Step: 2
Training loss: 2.2438066005706787
Validation loss: 2.0960303048292794

Epoch: 5| Step: 3
Training loss: 1.9325649738311768
Validation loss: 2.1062346398830414

Epoch: 5| Step: 4
Training loss: 2.0342164039611816
Validation loss: 2.106062705318133

Epoch: 5| Step: 5
Training loss: 2.753117322921753
Validation loss: 2.09596415857474

Epoch: 5| Step: 6
Training loss: 2.238081455230713
Validation loss: 2.0984348505735397

Epoch: 5| Step: 7
Training loss: 2.0378146171569824
Validation loss: 2.0956693987051644

Epoch: 5| Step: 8
Training loss: 2.1846554279327393
Validation loss: 2.099147548278173

Epoch: 5| Step: 9
Training loss: 2.8135886192321777
Validation loss: 2.087754582365354

Epoch: 5| Step: 10
Training loss: 2.7329726219177246
Validation loss: 2.0948737064997354

Epoch: 5| Step: 11
Training loss: 1.0437957048416138
Validation loss: 2.089925845464071

Epoch: 76| Step: 0
Training loss: 2.583143949508667
Validation loss: 2.0935155103603997

Epoch: 5| Step: 1
Training loss: 1.794563889503479
Validation loss: 2.089278221130371

Epoch: 5| Step: 2
Training loss: 2.6635701656341553
Validation loss: 2.0942129840453467

Epoch: 5| Step: 3
Training loss: 2.1652426719665527
Validation loss: 2.087623024980227

Epoch: 5| Step: 4
Training loss: 2.0158512592315674
Validation loss: 2.0860376556714377

Epoch: 5| Step: 5
Training loss: 2.4254016876220703
Validation loss: 2.0889754394690194

Epoch: 5| Step: 6
Training loss: 2.376499652862549
Validation loss: 2.0909141649802527

Epoch: 5| Step: 7
Training loss: 2.165423631668091
Validation loss: 2.091727465391159

Epoch: 5| Step: 8
Training loss: 2.456167221069336
Validation loss: 2.0870034446318946

Epoch: 5| Step: 9
Training loss: 2.0125577449798584
Validation loss: 2.084610233704249

Epoch: 5| Step: 10
Training loss: 2.317523956298828
Validation loss: 2.0834272702534995

Epoch: 5| Step: 11
Training loss: 1.8064358234405518
Validation loss: 2.0743998289108276

Epoch: 77| Step: 0
Training loss: 1.9497560262680054
Validation loss: 2.085695654153824

Epoch: 5| Step: 1
Training loss: 2.8371827602386475
Validation loss: 2.0900031477212906

Epoch: 5| Step: 2
Training loss: 2.127042770385742
Validation loss: 2.0800637950499854

Epoch: 5| Step: 3
Training loss: 2.3635458946228027
Validation loss: 2.0835951566696167

Epoch: 5| Step: 4
Training loss: 2.210465908050537
Validation loss: 2.081487163901329

Epoch: 5| Step: 5
Training loss: 1.3989137411117554
Validation loss: 2.07135804494222

Epoch: 5| Step: 6
Training loss: 2.172152280807495
Validation loss: 2.0735230396191278

Epoch: 5| Step: 7
Training loss: 2.7463066577911377
Validation loss: 2.079571088155111

Epoch: 5| Step: 8
Training loss: 2.3253188133239746
Validation loss: 2.094048942128817

Epoch: 5| Step: 9
Training loss: 2.34649395942688
Validation loss: 2.0842353900273642

Epoch: 5| Step: 10
Training loss: 2.1840672492980957
Validation loss: 2.0846218218406043

Epoch: 5| Step: 11
Training loss: 3.836704969406128
Validation loss: 2.071667035420736

Epoch: 78| Step: 0
Training loss: 2.040114402770996
Validation loss: 2.073688636223475

Epoch: 5| Step: 1
Training loss: 2.1793859004974365
Validation loss: 2.0695208410422006

Epoch: 5| Step: 2
Training loss: 1.9021799564361572
Validation loss: 2.0655440439780555

Epoch: 5| Step: 3
Training loss: 2.2982208728790283
Validation loss: 2.0728573699792228

Epoch: 5| Step: 4
Training loss: 2.1432743072509766
Validation loss: 2.071901877721151

Epoch: 5| Step: 5
Training loss: 2.615168809890747
Validation loss: 2.075410932302475

Epoch: 5| Step: 6
Training loss: 1.4883874654769897
Validation loss: 2.079350690046946

Epoch: 5| Step: 7
Training loss: 2.723628520965576
Validation loss: 2.0738735795021057

Epoch: 5| Step: 8
Training loss: 2.077296495437622
Validation loss: 2.077445616324743

Epoch: 5| Step: 9
Training loss: 2.5882279872894287
Validation loss: 2.065868546565374

Epoch: 5| Step: 10
Training loss: 2.816633939743042
Validation loss: 2.067608132958412

Epoch: 5| Step: 11
Training loss: 1.5646226406097412
Validation loss: 2.0640700856844583

Epoch: 79| Step: 0
Training loss: 1.851799726486206
Validation loss: 2.062713916103045

Epoch: 5| Step: 1
Training loss: 2.390936851501465
Validation loss: 2.0605864375829697

Epoch: 5| Step: 2
Training loss: 2.8571808338165283
Validation loss: 2.085644245147705

Epoch: 5| Step: 3
Training loss: 2.3961520195007324
Validation loss: 2.091886892914772

Epoch: 5| Step: 4
Training loss: 2.7217442989349365
Validation loss: 2.1080330858627954

Epoch: 5| Step: 5
Training loss: 1.8315856456756592
Validation loss: 2.0857106298208237

Epoch: 5| Step: 6
Training loss: 2.3445963859558105
Validation loss: 2.0858668982982635

Epoch: 5| Step: 7
Training loss: 2.570119857788086
Validation loss: 2.0671561658382416

Epoch: 5| Step: 8
Training loss: 2.1185126304626465
Validation loss: 2.0580610086520514

Epoch: 5| Step: 9
Training loss: 1.9839435815811157
Validation loss: 2.0594731271266937

Epoch: 5| Step: 10
Training loss: 1.757875680923462
Validation loss: 2.061812008420626

Epoch: 5| Step: 11
Training loss: 2.330018997192383
Validation loss: 2.065214122335116

Epoch: 80| Step: 0
Training loss: 1.666166067123413
Validation loss: 2.063477337360382

Epoch: 5| Step: 1
Training loss: 2.193854808807373
Validation loss: 2.0671978245178857

Epoch: 5| Step: 2
Training loss: 1.86639404296875
Validation loss: 2.0655290484428406

Epoch: 5| Step: 3
Training loss: 2.474555492401123
Validation loss: 2.060451880097389

Epoch: 5| Step: 4
Training loss: 2.049753189086914
Validation loss: 2.0563445339600244

Epoch: 5| Step: 5
Training loss: 2.3978493213653564
Validation loss: 2.0531664192676544

Epoch: 5| Step: 6
Training loss: 2.3709535598754883
Validation loss: 2.054132322470347

Epoch: 5| Step: 7
Training loss: 2.170764923095703
Validation loss: 2.0470865219831467

Epoch: 5| Step: 8
Training loss: 2.5727646350860596
Validation loss: 2.0541604856650033

Epoch: 5| Step: 9
Training loss: 2.2932963371276855
Validation loss: 2.0671068280935287

Epoch: 5| Step: 10
Training loss: 2.427786350250244
Validation loss: 2.0626040250062943

Epoch: 5| Step: 11
Training loss: 2.755154609680176
Validation loss: 2.0536243667205176

Epoch: 81| Step: 0
Training loss: 2.5335958003997803
Validation loss: 2.0562493354082108

Epoch: 5| Step: 1
Training loss: 2.100776195526123
Validation loss: 2.0522349874178567

Epoch: 5| Step: 2
Training loss: 2.0666255950927734
Validation loss: 2.0506731470425925

Epoch: 5| Step: 3
Training loss: 2.569739580154419
Validation loss: 2.057216912508011

Epoch: 5| Step: 4
Training loss: 1.7537214756011963
Validation loss: 2.053703566392263

Epoch: 5| Step: 5
Training loss: 1.8247356414794922
Validation loss: 2.044598097602526

Epoch: 5| Step: 6
Training loss: 2.0229105949401855
Validation loss: 2.0478043307860694

Epoch: 5| Step: 7
Training loss: 2.0560030937194824
Validation loss: 2.0509876559178033

Epoch: 5| Step: 8
Training loss: 2.19525408744812
Validation loss: 2.0493027766545615

Epoch: 5| Step: 9
Training loss: 3.0447592735290527
Validation loss: 2.051983262101809

Epoch: 5| Step: 10
Training loss: 2.135448932647705
Validation loss: 2.049379363656044

Epoch: 5| Step: 11
Training loss: 2.5661723613739014
Validation loss: 2.0496065666278205

Epoch: 82| Step: 0
Training loss: 1.7165930271148682
Validation loss: 2.0584309001763663

Epoch: 5| Step: 1
Training loss: 2.511687755584717
Validation loss: 2.0582069555918374

Epoch: 5| Step: 2
Training loss: 2.5254321098327637
Validation loss: 2.0572834561268487

Epoch: 5| Step: 3
Training loss: 2.2532505989074707
Validation loss: 2.0597043335437775

Epoch: 5| Step: 4
Training loss: 1.8832588195800781
Validation loss: 2.059736361106237

Epoch: 5| Step: 5
Training loss: 2.8419153690338135
Validation loss: 2.060433954000473

Epoch: 5| Step: 6
Training loss: 2.112553596496582
Validation loss: 2.052871267000834

Epoch: 5| Step: 7
Training loss: 2.044919967651367
Validation loss: 2.046610951423645

Epoch: 5| Step: 8
Training loss: 2.1483404636383057
Validation loss: 2.0478733827670417

Epoch: 5| Step: 9
Training loss: 2.048654079437256
Validation loss: 2.0394260436296463

Epoch: 5| Step: 10
Training loss: 1.9706547260284424
Validation loss: 2.042966624101003

Epoch: 5| Step: 11
Training loss: 2.851048231124878
Validation loss: 2.0431305517752967

Epoch: 83| Step: 0
Training loss: 2.393711566925049
Validation loss: 2.056048184633255

Epoch: 5| Step: 1
Training loss: 2.2432453632354736
Validation loss: 2.068743199110031

Epoch: 5| Step: 2
Training loss: 1.9576032161712646
Validation loss: 2.0824652910232544

Epoch: 5| Step: 3
Training loss: 2.3727834224700928
Validation loss: 2.101800486445427

Epoch: 5| Step: 4
Training loss: 2.0119435787200928
Validation loss: 2.1270455420017242

Epoch: 5| Step: 5
Training loss: 1.848851203918457
Validation loss: 2.1319586038589478

Epoch: 5| Step: 6
Training loss: 2.8425498008728027
Validation loss: 2.101992686589559

Epoch: 5| Step: 7
Training loss: 2.217456102371216
Validation loss: 2.0867262234290442

Epoch: 5| Step: 8
Training loss: 2.1336793899536133
Validation loss: 2.066315005222956

Epoch: 5| Step: 9
Training loss: 2.4248785972595215
Validation loss: 2.0614088078339896

Epoch: 5| Step: 10
Training loss: 2.0682497024536133
Validation loss: 2.0583964536587396

Epoch: 5| Step: 11
Training loss: 4.086531639099121
Validation loss: 2.0465585390726724

Epoch: 84| Step: 0
Training loss: 2.0125184059143066
Validation loss: 2.0446137487888336

Epoch: 5| Step: 1
Training loss: 1.8347628116607666
Validation loss: 2.0436244755983353

Epoch: 5| Step: 2
Training loss: 2.2236275672912598
Validation loss: 2.0455894668896994

Epoch: 5| Step: 3
Training loss: 2.420980453491211
Validation loss: 2.044616515437762

Epoch: 5| Step: 4
Training loss: 2.79276704788208
Validation loss: 2.058391273021698

Epoch: 5| Step: 5
Training loss: 2.156067371368408
Validation loss: 2.063089574376742

Epoch: 5| Step: 6
Training loss: 1.9703731536865234
Validation loss: 2.0738268544276557

Epoch: 5| Step: 7
Training loss: 2.036726474761963
Validation loss: 2.057874863346418

Epoch: 5| Step: 8
Training loss: 2.0302109718322754
Validation loss: 2.0748169173796973

Epoch: 5| Step: 9
Training loss: 2.246443271636963
Validation loss: 2.052634055415789

Epoch: 5| Step: 10
Training loss: 2.393669843673706
Validation loss: 2.0502747098604837

Epoch: 5| Step: 11
Training loss: 2.9303479194641113
Validation loss: 2.0567205995321274

Epoch: 85| Step: 0
Training loss: 1.869607925415039
Validation loss: 2.0575579355160394

Epoch: 5| Step: 1
Training loss: 2.0849556922912598
Validation loss: 2.054933269818624

Epoch: 5| Step: 2
Training loss: 2.581982374191284
Validation loss: 2.041400815049807

Epoch: 5| Step: 3
Training loss: 2.021134614944458
Validation loss: 2.036739945411682

Epoch: 5| Step: 4
Training loss: 2.190575122833252
Validation loss: 2.0295678675174713

Epoch: 5| Step: 5
Training loss: 2.16339373588562
Validation loss: 2.037124608953794

Epoch: 5| Step: 6
Training loss: 2.016326904296875
Validation loss: 2.0327992141246796

Epoch: 5| Step: 7
Training loss: 2.396890878677368
Validation loss: 2.031439940134684

Epoch: 5| Step: 8
Training loss: 2.150317668914795
Validation loss: 2.042209287484487

Epoch: 5| Step: 9
Training loss: 2.236393451690674
Validation loss: 2.0391880522171655

Epoch: 5| Step: 10
Training loss: 2.2775654792785645
Validation loss: 2.036021480957667

Epoch: 5| Step: 11
Training loss: 3.5228123664855957
Validation loss: 2.0382840236028037

Epoch: 86| Step: 0
Training loss: 2.753187656402588
Validation loss: 2.0385682930548987

Epoch: 5| Step: 1
Training loss: 1.9659059047698975
Validation loss: 2.0346497098604837

Epoch: 5| Step: 2
Training loss: 1.8421010971069336
Validation loss: 2.0369480550289154

Epoch: 5| Step: 3
Training loss: 2.8170642852783203
Validation loss: 2.037155012289683

Epoch: 5| Step: 4
Training loss: 2.4444668292999268
Validation loss: 2.0348198463519416

Epoch: 5| Step: 5
Training loss: 1.9828096628189087
Validation loss: 2.038877988855044

Epoch: 5| Step: 6
Training loss: 1.6499807834625244
Validation loss: 2.040575757622719

Epoch: 5| Step: 7
Training loss: 2.311793565750122
Validation loss: 2.041727438569069

Epoch: 5| Step: 8
Training loss: 1.8497415781021118
Validation loss: 2.035210703810056

Epoch: 5| Step: 9
Training loss: 2.350550413131714
Validation loss: 2.035740226507187

Epoch: 5| Step: 10
Training loss: 2.3013789653778076
Validation loss: 2.040127615133921

Epoch: 5| Step: 11
Training loss: 2.3885269165039062
Validation loss: 2.036573941508929

Epoch: 87| Step: 0
Training loss: 2.6269326210021973
Validation loss: 2.036000723640124

Epoch: 5| Step: 1
Training loss: 1.9971481561660767
Validation loss: 2.0241409142812095

Epoch: 5| Step: 2
Training loss: 2.090817928314209
Validation loss: 2.029161741336187

Epoch: 5| Step: 3
Training loss: 2.099269151687622
Validation loss: 2.0405189941326776

Epoch: 5| Step: 4
Training loss: 2.4955952167510986
Validation loss: 2.0300877491633096

Epoch: 5| Step: 5
Training loss: 2.2509779930114746
Validation loss: 2.0388354559739432

Epoch: 5| Step: 6
Training loss: 2.249941349029541
Validation loss: 2.0378784239292145

Epoch: 5| Step: 7
Training loss: 1.9508922100067139
Validation loss: 2.0314889450867972

Epoch: 5| Step: 8
Training loss: 2.341780424118042
Validation loss: 2.0303834080696106

Epoch: 5| Step: 9
Training loss: 2.284001588821411
Validation loss: 2.036208599805832

Epoch: 5| Step: 10
Training loss: 1.7702596187591553
Validation loss: 2.0359162241220474

Epoch: 5| Step: 11
Training loss: 2.5144472122192383
Validation loss: 2.0337123572826385

Epoch: 88| Step: 0
Training loss: 1.9047142267227173
Validation loss: 2.02888452510039

Epoch: 5| Step: 1
Training loss: 2.2868423461914062
Validation loss: 2.041228632132212

Epoch: 5| Step: 2
Training loss: 1.8037694692611694
Validation loss: 2.053008114298185

Epoch: 5| Step: 3
Training loss: 2.3776321411132812
Validation loss: 2.0690931479136148

Epoch: 5| Step: 4
Training loss: 2.1755385398864746
Validation loss: 2.0820652693510056

Epoch: 5| Step: 5
Training loss: 2.2064855098724365
Validation loss: 2.0911706487337747

Epoch: 5| Step: 6
Training loss: 2.452923059463501
Validation loss: 2.0668197522560754

Epoch: 5| Step: 7
Training loss: 2.357454776763916
Validation loss: 2.0558193375666938

Epoch: 5| Step: 8
Training loss: 3.0986344814300537
Validation loss: 2.041327436765035

Epoch: 5| Step: 9
Training loss: 1.8032060861587524
Validation loss: 2.039666175842285

Epoch: 5| Step: 10
Training loss: 1.6528316736221313
Validation loss: 2.022308826446533

Epoch: 5| Step: 11
Training loss: 1.8408066034317017
Validation loss: 2.0214691857496896

Epoch: 89| Step: 0
Training loss: 2.7729806900024414
Validation loss: 2.0264453838268914

Epoch: 5| Step: 1
Training loss: 2.4473836421966553
Validation loss: 2.036694566408793

Epoch: 5| Step: 2
Training loss: 1.9237792491912842
Validation loss: 2.038037230571111

Epoch: 5| Step: 3
Training loss: 2.3023996353149414
Validation loss: 2.043706734975179

Epoch: 5| Step: 4
Training loss: 1.9710785150527954
Validation loss: 2.041593005259832

Epoch: 5| Step: 5
Training loss: 2.179659843444824
Validation loss: 2.0341010093688965

Epoch: 5| Step: 6
Training loss: 2.427320957183838
Validation loss: 2.043003266056379

Epoch: 5| Step: 7
Training loss: 1.9737132787704468
Validation loss: 2.038188969095548

Epoch: 5| Step: 8
Training loss: 2.138256549835205
Validation loss: 2.027719924847285

Epoch: 5| Step: 9
Training loss: 2.202789783477783
Validation loss: 2.039067586263021

Epoch: 5| Step: 10
Training loss: 1.9148037433624268
Validation loss: 2.033460885286331

Epoch: 5| Step: 11
Training loss: 2.1712093353271484
Validation loss: 2.0192063500483832

Epoch: 90| Step: 0
Training loss: 1.8280913829803467
Validation loss: 2.022502973675728

Epoch: 5| Step: 1
Training loss: 2.344388008117676
Validation loss: 2.0205170710881553

Epoch: 5| Step: 2
Training loss: 1.6974906921386719
Validation loss: 2.013747736811638

Epoch: 5| Step: 3
Training loss: 2.303785800933838
Validation loss: 2.031320706009865

Epoch: 5| Step: 4
Training loss: 1.7733980417251587
Validation loss: 2.041879619161288

Epoch: 5| Step: 5
Training loss: 2.2048306465148926
Validation loss: 2.043558140595754

Epoch: 5| Step: 6
Training loss: 2.4447197914123535
Validation loss: 2.035645008087158

Epoch: 5| Step: 7
Training loss: 2.0416226387023926
Validation loss: 2.0485215534766517

Epoch: 5| Step: 8
Training loss: 2.2675461769104004
Validation loss: 2.0494013677040734

Epoch: 5| Step: 9
Training loss: 2.707866668701172
Validation loss: 2.0368673702081046

Epoch: 5| Step: 10
Training loss: 2.4169764518737793
Validation loss: 2.024723455309868

Epoch: 5| Step: 11
Training loss: 2.1098427772521973
Validation loss: 2.0143983910481134

Epoch: 91| Step: 0
Training loss: 2.328467845916748
Validation loss: 2.0127892196178436

Epoch: 5| Step: 1
Training loss: 2.395512104034424
Validation loss: 2.0240448812643685

Epoch: 5| Step: 2
Training loss: 2.746901512145996
Validation loss: 2.0308939615885415

Epoch: 5| Step: 3
Training loss: 1.9939123392105103
Validation loss: 2.039543256163597

Epoch: 5| Step: 4
Training loss: 2.336634874343872
Validation loss: 2.0355150351921716

Epoch: 5| Step: 5
Training loss: 2.1856319904327393
Validation loss: 2.0365003049373627

Epoch: 5| Step: 6
Training loss: 1.5686899423599243
Validation loss: 2.0407383888959885

Epoch: 5| Step: 7
Training loss: 2.6918399333953857
Validation loss: 2.0406439503033957

Epoch: 5| Step: 8
Training loss: 2.3316359519958496
Validation loss: 2.0383204321066537

Epoch: 5| Step: 9
Training loss: 1.8039013147354126
Validation loss: 2.040946046511332

Epoch: 5| Step: 10
Training loss: 1.8413350582122803
Validation loss: 2.0331023832162223

Epoch: 5| Step: 11
Training loss: 2.0001230239868164
Validation loss: 2.033393695950508

Epoch: 92| Step: 0
Training loss: 2.4460110664367676
Validation loss: 2.020249992609024

Epoch: 5| Step: 1
Training loss: 2.199866533279419
Validation loss: 2.0247776110967

Epoch: 5| Step: 2
Training loss: 1.9503885507583618
Validation loss: 2.0150537341833115

Epoch: 5| Step: 3
Training loss: 2.3002216815948486
Validation loss: 2.022926519314448

Epoch: 5| Step: 4
Training loss: 2.125980854034424
Validation loss: 2.028241833051046

Epoch: 5| Step: 5
Training loss: 2.136820077896118
Validation loss: 2.044560119509697

Epoch: 5| Step: 6
Training loss: 2.3923821449279785
Validation loss: 2.0464057475328445

Epoch: 5| Step: 7
Training loss: 2.542483329772949
Validation loss: 2.0502457320690155

Epoch: 5| Step: 8
Training loss: 1.6218135356903076
Validation loss: 2.0247960637013116

Epoch: 5| Step: 9
Training loss: 2.139935255050659
Validation loss: 2.0274274001518884

Epoch: 5| Step: 10
Training loss: 2.1086783409118652
Validation loss: 2.0357630997896194

Epoch: 5| Step: 11
Training loss: 1.8486311435699463
Validation loss: 2.0232097258170447

Epoch: 93| Step: 0
Training loss: 1.4360520839691162
Validation loss: 2.022349566221237

Epoch: 5| Step: 1
Training loss: 2.449340343475342
Validation loss: 2.0196366757154465

Epoch: 5| Step: 2
Training loss: 2.362854480743408
Validation loss: 2.0346873750289283

Epoch: 5| Step: 3
Training loss: 2.18925404548645
Validation loss: 2.03221462170283

Epoch: 5| Step: 4
Training loss: 1.9901014566421509
Validation loss: 2.02890545129776

Epoch: 5| Step: 5
Training loss: 2.5691909790039062
Validation loss: 2.02989628414313

Epoch: 5| Step: 6
Training loss: 2.0814828872680664
Validation loss: 2.0307552764813104

Epoch: 5| Step: 7
Training loss: 2.2813687324523926
Validation loss: 2.0297711739937463

Epoch: 5| Step: 8
Training loss: 1.8068821430206299
Validation loss: 2.0243137925863266

Epoch: 5| Step: 9
Training loss: 2.4187521934509277
Validation loss: 2.0218108892440796

Epoch: 5| Step: 10
Training loss: 2.433760404586792
Validation loss: 2.0215454697608948

Epoch: 5| Step: 11
Training loss: 2.3858535289764404
Validation loss: 2.0153341740369797

Epoch: 94| Step: 0
Training loss: 1.750474214553833
Validation loss: 2.0246169616778693

Epoch: 5| Step: 1
Training loss: 2.410620927810669
Validation loss: 2.028166597088178

Epoch: 5| Step: 2
Training loss: 2.6912875175476074
Validation loss: 2.0425388167301812

Epoch: 5| Step: 3
Training loss: 1.8635714054107666
Validation loss: 2.050415724515915

Epoch: 5| Step: 4
Training loss: 1.9674911499023438
Validation loss: 2.0452045599619546

Epoch: 5| Step: 5
Training loss: 2.1043448448181152
Validation loss: 2.0609622448682785

Epoch: 5| Step: 6
Training loss: 2.792726516723633
Validation loss: 2.0711994071801505

Epoch: 5| Step: 7
Training loss: 2.4791321754455566
Validation loss: 2.074514170487722

Epoch: 5| Step: 8
Training loss: 2.1686108112335205
Validation loss: 2.0437852342923484

Epoch: 5| Step: 9
Training loss: 2.3577163219451904
Validation loss: 2.026709735393524

Epoch: 5| Step: 10
Training loss: 1.7641699314117432
Validation loss: 2.0258283764123917

Epoch: 5| Step: 11
Training loss: 0.5123084783554077
Validation loss: 2.0163334806760154

Epoch: 95| Step: 0
Training loss: 2.4804587364196777
Validation loss: 2.019864559173584

Epoch: 5| Step: 1
Training loss: 1.7707958221435547
Validation loss: 2.020372211933136

Epoch: 5| Step: 2
Training loss: 2.293325662612915
Validation loss: 2.0300755202770233

Epoch: 5| Step: 3
Training loss: 1.7449582815170288
Validation loss: 2.0279506097237268

Epoch: 5| Step: 4
Training loss: 2.064040422439575
Validation loss: 2.0274026542901993

Epoch: 5| Step: 5
Training loss: 2.399258852005005
Validation loss: 2.0304467578728995

Epoch: 5| Step: 6
Training loss: 2.5349643230438232
Validation loss: 2.0218889017899833

Epoch: 5| Step: 7
Training loss: 1.8656113147735596
Validation loss: 2.0181433111429214

Epoch: 5| Step: 8
Training loss: 2.3154749870300293
Validation loss: 2.01660880446434

Epoch: 5| Step: 9
Training loss: 1.9399192333221436
Validation loss: 2.0167019764582315

Epoch: 5| Step: 10
Training loss: 2.505558967590332
Validation loss: 2.019621138771375

Epoch: 5| Step: 11
Training loss: 2.662998676300049
Validation loss: 2.0148712396621704

Epoch: 96| Step: 0
Training loss: 2.9354095458984375
Validation loss: 2.0163983404636383

Epoch: 5| Step: 1
Training loss: 2.4578516483306885
Validation loss: 2.0294974893331528

Epoch: 5| Step: 2
Training loss: 2.133591413497925
Validation loss: 2.022350703676542

Epoch: 5| Step: 3
Training loss: 2.11767315864563
Validation loss: 2.032749762137731

Epoch: 5| Step: 4
Training loss: 1.7212979793548584
Validation loss: 2.0275625636180243

Epoch: 5| Step: 5
Training loss: 2.080623149871826
Validation loss: 2.027815024058024

Epoch: 5| Step: 6
Training loss: 1.647770881652832
Validation loss: 2.034113665421804

Epoch: 5| Step: 7
Training loss: 1.715888261795044
Validation loss: 2.050173948208491

Epoch: 5| Step: 8
Training loss: 2.292206287384033
Validation loss: 2.0601823925971985

Epoch: 5| Step: 9
Training loss: 2.479565143585205
Validation loss: 2.0679517636696496

Epoch: 5| Step: 10
Training loss: 2.2297258377075195
Validation loss: 2.0629638731479645

Epoch: 5| Step: 11
Training loss: 2.0245635509490967
Validation loss: 2.047151659925779

Epoch: 97| Step: 0
Training loss: 1.9208787679672241
Validation loss: 2.0411234299341836

Epoch: 5| Step: 1
Training loss: 2.0549309253692627
Validation loss: 2.0398737589518228

Epoch: 5| Step: 2
Training loss: 2.2633347511291504
Validation loss: 2.023631369074186

Epoch: 5| Step: 3
Training loss: 3.015244245529175
Validation loss: 2.0259567499160767

Epoch: 5| Step: 4
Training loss: 1.7799183130264282
Validation loss: 2.0259704242149987

Epoch: 5| Step: 5
Training loss: 1.9688665866851807
Validation loss: 2.0291670064131417

Epoch: 5| Step: 6
Training loss: 2.3362607955932617
Validation loss: 2.025401378671328

Epoch: 5| Step: 7
Training loss: 2.1329712867736816
Validation loss: 2.029836744070053

Epoch: 5| Step: 8
Training loss: 1.8969123363494873
Validation loss: 2.0359037021795907

Epoch: 5| Step: 9
Training loss: 2.4497971534729004
Validation loss: 2.034261221686999

Epoch: 5| Step: 10
Training loss: 2.4004414081573486
Validation loss: 2.031016161044439

Epoch: 5| Step: 11
Training loss: 0.8832496404647827
Validation loss: 2.0316342810789743

Epoch: 98| Step: 0
Training loss: 2.5807669162750244
Validation loss: 2.0306451618671417

Epoch: 5| Step: 1
Training loss: 2.140260934829712
Validation loss: 2.0240548898776374

Epoch: 5| Step: 2
Training loss: 1.8698225021362305
Validation loss: 2.019409770766894

Epoch: 5| Step: 3
Training loss: 2.1646180152893066
Validation loss: 2.023150851329168

Epoch: 5| Step: 4
Training loss: 2.239563465118408
Validation loss: 2.0206718494494758

Epoch: 5| Step: 5
Training loss: 1.9877773523330688
Validation loss: 2.0177987068891525

Epoch: 5| Step: 6
Training loss: 1.8014097213745117
Validation loss: 2.0243591368198395

Epoch: 5| Step: 7
Training loss: 1.941641092300415
Validation loss: 2.014705697695414

Epoch: 5| Step: 8
Training loss: 2.0692338943481445
Validation loss: 2.013504902521769

Epoch: 5| Step: 9
Training loss: 2.195162296295166
Validation loss: 2.0233848989009857

Epoch: 5| Step: 10
Training loss: 2.6683478355407715
Validation loss: 2.0344740748405457

Epoch: 5| Step: 11
Training loss: 1.7615067958831787
Validation loss: 2.030353769659996

Epoch: 99| Step: 0
Training loss: 1.7682037353515625
Validation loss: 2.040425255894661

Epoch: 5| Step: 1
Training loss: 2.02140736579895
Validation loss: 2.068487271666527

Epoch: 5| Step: 2
Training loss: 2.4233107566833496
Validation loss: 2.089194963375727

Epoch: 5| Step: 3
Training loss: 2.62888765335083
Validation loss: 2.0838090032339096

Epoch: 5| Step: 4
Training loss: 2.5791358947753906
Validation loss: 2.1020264824231467

Epoch: 5| Step: 5
Training loss: 1.7327232360839844
Validation loss: 2.0591560105482736

Epoch: 5| Step: 6
Training loss: 1.9831047058105469
Validation loss: 2.0372591267029443

Epoch: 5| Step: 7
Training loss: 2.482104778289795
Validation loss: 2.0264781564474106

Epoch: 5| Step: 8
Training loss: 1.9504356384277344
Validation loss: 2.021288221081098

Epoch: 5| Step: 9
Training loss: 2.2783591747283936
Validation loss: 2.034738520781199

Epoch: 5| Step: 10
Training loss: 1.9478756189346313
Validation loss: 2.0270945181449256

Epoch: 5| Step: 11
Training loss: 2.267605781555176
Validation loss: 2.028621499737104

Epoch: 100| Step: 0
Training loss: 2.228803873062134
Validation loss: 2.0289677331844964

Epoch: 5| Step: 1
Training loss: 2.2759957313537598
Validation loss: 2.032506912946701

Epoch: 5| Step: 2
Training loss: 2.1909873485565186
Validation loss: 2.032305176059405

Epoch: 5| Step: 3
Training loss: 2.0312185287475586
Validation loss: 2.0332382122675576

Epoch: 5| Step: 4
Training loss: 2.1247286796569824
Validation loss: 2.032551566759745

Epoch: 5| Step: 5
Training loss: 2.158641815185547
Validation loss: 2.0327408462762833

Epoch: 5| Step: 6
Training loss: 2.1013519763946533
Validation loss: 2.02781742811203

Epoch: 5| Step: 7
Training loss: 2.2117724418640137
Validation loss: 2.024638533592224

Epoch: 5| Step: 8
Training loss: 2.474942445755005
Validation loss: 2.0284350315729776

Epoch: 5| Step: 9
Training loss: 1.9213829040527344
Validation loss: 2.019920359055201

Epoch: 5| Step: 10
Training loss: 2.178041696548462
Validation loss: 2.016175096233686

Epoch: 5| Step: 11
Training loss: 2.9478015899658203
Validation loss: 2.0183673799037933

Epoch: 101| Step: 0
Training loss: 2.1694295406341553
Validation loss: 2.0198806474606195

Epoch: 5| Step: 1
Training loss: 2.0316011905670166
Validation loss: 2.0193123718102775

Epoch: 5| Step: 2
Training loss: 2.567246198654175
Validation loss: 2.0166946748892465

Epoch: 5| Step: 3
Training loss: 1.8610820770263672
Validation loss: 2.022196258107821

Epoch: 5| Step: 4
Training loss: 2.5059664249420166
Validation loss: 2.0253034631411233

Epoch: 5| Step: 5
Training loss: 2.0485100746154785
Validation loss: 2.0192378809054694

Epoch: 5| Step: 6
Training loss: 2.2856483459472656
Validation loss: 2.0180878887573876

Epoch: 5| Step: 7
Training loss: 1.4662513732910156
Validation loss: 2.017569452524185

Epoch: 5| Step: 8
Training loss: 2.0823428630828857
Validation loss: 2.0135045498609543

Epoch: 5| Step: 9
Training loss: 2.320462703704834
Validation loss: 2.01581376294295

Epoch: 5| Step: 10
Training loss: 2.3633861541748047
Validation loss: 2.015580033262571

Epoch: 5| Step: 11
Training loss: 2.205552577972412
Validation loss: 2.024578566352526

Epoch: 102| Step: 0
Training loss: 1.9926135540008545
Validation loss: 2.0309867610534034

Epoch: 5| Step: 1
Training loss: 2.260011911392212
Validation loss: 2.024310906728109

Epoch: 5| Step: 2
Training loss: 2.0901806354522705
Validation loss: 2.036687726775805

Epoch: 5| Step: 3
Training loss: 2.5861573219299316
Validation loss: 2.0231999158859253

Epoch: 5| Step: 4
Training loss: 1.9186925888061523
Validation loss: 2.0314741134643555

Epoch: 5| Step: 5
Training loss: 2.2147605419158936
Validation loss: 2.0273528347412744

Epoch: 5| Step: 6
Training loss: 2.055062770843506
Validation loss: 2.0346671442190805

Epoch: 5| Step: 7
Training loss: 2.0926051139831543
Validation loss: 2.020573521653811

Epoch: 5| Step: 8
Training loss: 1.514216661453247
Validation loss: 2.0223722060521445

Epoch: 5| Step: 9
Training loss: 2.6165008544921875
Validation loss: 2.0199711620807648

Epoch: 5| Step: 10
Training loss: 2.066365957260132
Validation loss: 2.0215917030970254

Epoch: 5| Step: 11
Training loss: 3.1586408615112305
Validation loss: 2.017405077815056

Epoch: 103| Step: 0
Training loss: 2.235696315765381
Validation loss: 2.0182862281799316

Epoch: 5| Step: 1
Training loss: 1.6426689624786377
Validation loss: 2.0231109907229743

Epoch: 5| Step: 2
Training loss: 1.8865337371826172
Validation loss: 2.0156536201635995

Epoch: 5| Step: 3
Training loss: 2.403104305267334
Validation loss: 2.027789314587911

Epoch: 5| Step: 4
Training loss: 2.1934571266174316
Validation loss: 2.0258180846770606

Epoch: 5| Step: 5
Training loss: 2.54935622215271
Validation loss: 2.028782914082209

Epoch: 5| Step: 6
Training loss: 1.6930913925170898
Validation loss: 2.035072217384974

Epoch: 5| Step: 7
Training loss: 2.464346408843994
Validation loss: 2.035661687453588

Epoch: 5| Step: 8
Training loss: 2.4673523902893066
Validation loss: 2.0270876387755075

Epoch: 5| Step: 9
Training loss: 1.6628156900405884
Validation loss: 2.0279184728860855

Epoch: 5| Step: 10
Training loss: 2.3973114490509033
Validation loss: 2.0171535511811576

Epoch: 5| Step: 11
Training loss: 2.183969497680664
Validation loss: 2.013459235429764

Epoch: 104| Step: 0
Training loss: 2.4136900901794434
Validation loss: 2.0168892542521157

Epoch: 5| Step: 1
Training loss: 1.7489923238754272
Validation loss: 2.021183262268702

Epoch: 5| Step: 2
Training loss: 2.2833495140075684
Validation loss: 2.020115410288175

Epoch: 5| Step: 3
Training loss: 2.29555082321167
Validation loss: 2.022493064403534

Epoch: 5| Step: 4
Training loss: 2.4273219108581543
Validation loss: 2.0224270125230155

Epoch: 5| Step: 5
Training loss: 1.892883062362671
Validation loss: 2.0286102145910263

Epoch: 5| Step: 6
Training loss: 1.8911678791046143
Validation loss: 2.0172697405020394

Epoch: 5| Step: 7
Training loss: 1.7986853122711182
Validation loss: 2.019341970483462

Epoch: 5| Step: 8
Training loss: 2.041200637817383
Validation loss: 2.021994188427925

Epoch: 5| Step: 9
Training loss: 2.5805306434631348
Validation loss: 2.0242665708065033

Epoch: 5| Step: 10
Training loss: 2.365891218185425
Validation loss: 2.032834162314733

Epoch: 5| Step: 11
Training loss: 1.765186071395874
Validation loss: 2.037810668349266

Epoch: 105| Step: 0
Training loss: 1.7521562576293945
Validation loss: 2.025242358446121

Epoch: 5| Step: 1
Training loss: 2.453456163406372
Validation loss: 2.0398540993531546

Epoch: 5| Step: 2
Training loss: 2.089986801147461
Validation loss: 2.0386436382929483

Epoch: 5| Step: 3
Training loss: 2.088839054107666
Validation loss: 2.0399158149957657

Epoch: 5| Step: 4
Training loss: 2.3021798133850098
Validation loss: 2.03399125734965

Epoch: 5| Step: 5
Training loss: 1.8168981075286865
Validation loss: 2.0213168561458588

Epoch: 5| Step: 6
Training loss: 2.4538543224334717
Validation loss: 2.029377872745196

Epoch: 5| Step: 7
Training loss: 2.1008219718933105
Validation loss: 2.0305564999580383

Epoch: 5| Step: 8
Training loss: 2.517366647720337
Validation loss: 2.0238195806741714

Epoch: 5| Step: 9
Training loss: 1.6627624034881592
Validation loss: 2.0154922852913537

Epoch: 5| Step: 10
Training loss: 2.0551857948303223
Validation loss: 2.0207393020391464

Epoch: 5| Step: 11
Training loss: 3.1222434043884277
Validation loss: 2.018839677174886

Epoch: 106| Step: 0
Training loss: 2.176041603088379
Validation loss: 2.0199219286441803

Epoch: 5| Step: 1
Training loss: 2.0534191131591797
Validation loss: 2.02141942580541

Epoch: 5| Step: 2
Training loss: 2.687657117843628
Validation loss: 2.008327916264534

Epoch: 5| Step: 3
Training loss: 2.3885319232940674
Validation loss: 2.009461601575216

Epoch: 5| Step: 4
Training loss: 2.2671608924865723
Validation loss: 2.0181602984666824

Epoch: 5| Step: 5
Training loss: 2.155208110809326
Validation loss: 2.01064666112264

Epoch: 5| Step: 6
Training loss: 1.8469257354736328
Validation loss: 2.011378139257431

Epoch: 5| Step: 7
Training loss: 1.9209821224212646
Validation loss: 2.007520670692126

Epoch: 5| Step: 8
Training loss: 2.224608898162842
Validation loss: 2.021020626028379

Epoch: 5| Step: 9
Training loss: 2.027196168899536
Validation loss: 2.0287235577901206

Epoch: 5| Step: 10
Training loss: 1.8953113555908203
Validation loss: 2.029554327329

Epoch: 5| Step: 11
Training loss: 1.3615803718566895
Validation loss: 2.023385470112165

Epoch: 107| Step: 0
Training loss: 1.3761202096939087
Validation loss: 2.0141656746466956

Epoch: 5| Step: 1
Training loss: 2.714116334915161
Validation loss: 2.019783397515615

Epoch: 5| Step: 2
Training loss: 2.5925893783569336
Validation loss: 2.0265153547128043

Epoch: 5| Step: 3
Training loss: 2.170276403427124
Validation loss: 2.0205282966295877

Epoch: 5| Step: 4
Training loss: 2.031625747680664
Validation loss: 2.031246855854988

Epoch: 5| Step: 5
Training loss: 1.5887155532836914
Validation loss: 2.015590245525042

Epoch: 5| Step: 6
Training loss: 2.034374713897705
Validation loss: 2.0327832400798798

Epoch: 5| Step: 7
Training loss: 2.471196174621582
Validation loss: 2.0305453538894653

Epoch: 5| Step: 8
Training loss: 2.375156879425049
Validation loss: 2.0341173509756723

Epoch: 5| Step: 9
Training loss: 1.9905941486358643
Validation loss: 2.0468355218569436

Epoch: 5| Step: 10
Training loss: 1.8998695611953735
Validation loss: 2.0331125209728875

Epoch: 5| Step: 11
Training loss: 2.4288530349731445
Validation loss: 2.0300291577974954

Epoch: 108| Step: 0
Training loss: 2.4456706047058105
Validation loss: 2.025968755284945

Epoch: 5| Step: 1
Training loss: 1.4671423435211182
Validation loss: 2.038047581911087

Epoch: 5| Step: 2
Training loss: 1.7206904888153076
Validation loss: 2.0446592370669046

Epoch: 5| Step: 3
Training loss: 1.880611777305603
Validation loss: 2.036697417497635

Epoch: 5| Step: 4
Training loss: 1.9894113540649414
Validation loss: 2.0414104213317237

Epoch: 5| Step: 5
Training loss: 2.2112321853637695
Validation loss: 2.030320410927137

Epoch: 5| Step: 6
Training loss: 2.2302122116088867
Validation loss: 2.0475288033485413

Epoch: 5| Step: 7
Training loss: 2.6599724292755127
Validation loss: 2.027217666308085

Epoch: 5| Step: 8
Training loss: 2.3318583965301514
Validation loss: 2.0350649058818817

Epoch: 5| Step: 9
Training loss: 1.8658111095428467
Validation loss: 2.0341609170039496

Epoch: 5| Step: 10
Training loss: 2.28007173538208
Validation loss: 2.0311673333247504

Epoch: 5| Step: 11
Training loss: 2.920571804046631
Validation loss: 2.0151017904281616

Epoch: 109| Step: 0
Training loss: 2.471151828765869
Validation loss: 2.0150165458520255

Epoch: 5| Step: 1
Training loss: 2.1544456481933594
Validation loss: 2.0119331379731498

Epoch: 5| Step: 2
Training loss: 1.8264553546905518
Validation loss: 2.010787253578504

Epoch: 5| Step: 3
Training loss: 2.6122756004333496
Validation loss: 2.0170674473047256

Epoch: 5| Step: 4
Training loss: 2.0469491481781006
Validation loss: 2.0203882455825806

Epoch: 5| Step: 5
Training loss: 2.1794826984405518
Validation loss: 2.018709351619085

Epoch: 5| Step: 6
Training loss: 1.6486310958862305
Validation loss: 2.0212203562259674

Epoch: 5| Step: 7
Training loss: 2.040024995803833
Validation loss: 2.0245403200387955

Epoch: 5| Step: 8
Training loss: 1.9324219226837158
Validation loss: 2.0148494094610214

Epoch: 5| Step: 9
Training loss: 2.4444961547851562
Validation loss: 2.0060720294713974

Epoch: 5| Step: 10
Training loss: 2.0303332805633545
Validation loss: 2.012704759836197

Epoch: 5| Step: 11
Training loss: 2.806248664855957
Validation loss: 2.0174116045236588

Epoch: 110| Step: 0
Training loss: 2.040285587310791
Validation loss: 2.018304397662481

Epoch: 5| Step: 1
Training loss: 2.157825469970703
Validation loss: 2.039980505903562

Epoch: 5| Step: 2
Training loss: 2.424898386001587
Validation loss: 2.042137622833252

Epoch: 5| Step: 3
Training loss: 1.557841420173645
Validation loss: 2.042040631175041

Epoch: 5| Step: 4
Training loss: 2.5199573040008545
Validation loss: 2.0378174831469855

Epoch: 5| Step: 5
Training loss: 2.1125259399414062
Validation loss: 2.035483032464981

Epoch: 5| Step: 6
Training loss: 1.8759124279022217
Validation loss: 2.0477437327305474

Epoch: 5| Step: 7
Training loss: 2.404951572418213
Validation loss: 2.0460054775079093

Epoch: 5| Step: 8
Training loss: 2.092597484588623
Validation loss: 2.048545186718305

Epoch: 5| Step: 9
Training loss: 2.152175188064575
Validation loss: 2.0417101681232452

Epoch: 5| Step: 10
Training loss: 1.9897167682647705
Validation loss: 2.0282553285360336

Epoch: 5| Step: 11
Training loss: 2.5875403881073
Validation loss: 2.0220045695702233

Epoch: 111| Step: 0
Training loss: 1.735894799232483
Validation loss: 2.023069272438685

Epoch: 5| Step: 1
Training loss: 2.2519099712371826
Validation loss: 2.016075849533081

Epoch: 5| Step: 2
Training loss: 1.7776836156845093
Validation loss: 2.0235554029544196

Epoch: 5| Step: 3
Training loss: 2.557547092437744
Validation loss: 2.034221827983856

Epoch: 5| Step: 4
Training loss: 1.856814980506897
Validation loss: 2.044816806912422

Epoch: 5| Step: 5
Training loss: 2.4408516883850098
Validation loss: 2.035295695066452

Epoch: 5| Step: 6
Training loss: 2.3298592567443848
Validation loss: 2.030761490265528

Epoch: 5| Step: 7
Training loss: 1.7908828258514404
Validation loss: 2.0229061990976334

Epoch: 5| Step: 8
Training loss: 1.968285322189331
Validation loss: 2.0304422775904336

Epoch: 5| Step: 9
Training loss: 2.388908863067627
Validation loss: 2.0309046457211175

Epoch: 5| Step: 10
Training loss: 2.3497393131256104
Validation loss: 2.0298029830058417

Epoch: 5| Step: 11
Training loss: 1.4674196243286133
Validation loss: 2.0264802277088165

Epoch: 112| Step: 0
Training loss: 2.1026833057403564
Validation loss: 2.0340305268764496

Epoch: 5| Step: 1
Training loss: 2.1067566871643066
Validation loss: 2.0370202511548996

Epoch: 5| Step: 2
Training loss: 1.9004237651824951
Validation loss: 2.049610748887062

Epoch: 5| Step: 3
Training loss: 2.202401638031006
Validation loss: 2.0635316322247186

Epoch: 5| Step: 4
Training loss: 1.9307533502578735
Validation loss: 2.064185937245687

Epoch: 5| Step: 5
Training loss: 2.360612154006958
Validation loss: 2.0469270050525665

Epoch: 5| Step: 6
Training loss: 2.6377623081207275
Validation loss: 2.0310612420241037

Epoch: 5| Step: 7
Training loss: 1.9219691753387451
Validation loss: 2.0156607230504355

Epoch: 5| Step: 8
Training loss: 2.060464382171631
Validation loss: 2.0092915495236716

Epoch: 5| Step: 9
Training loss: 2.6085801124572754
Validation loss: 2.0120579451322556

Epoch: 5| Step: 10
Training loss: 1.8134082555770874
Validation loss: 2.021082897981008

Epoch: 5| Step: 11
Training loss: 2.3228306770324707
Validation loss: 2.026046792666117

Epoch: 113| Step: 0
Training loss: 2.53216814994812
Validation loss: 2.02788216372331

Epoch: 5| Step: 1
Training loss: 2.79815411567688
Validation loss: 2.021580547094345

Epoch: 5| Step: 2
Training loss: 2.2181124687194824
Validation loss: 2.027093152205149

Epoch: 5| Step: 3
Training loss: 2.9136850833892822
Validation loss: 2.023555725812912

Epoch: 5| Step: 4
Training loss: 2.1192355155944824
Validation loss: 2.0165533870458603

Epoch: 5| Step: 5
Training loss: 1.8088725805282593
Validation loss: 2.0181926588217416

Epoch: 5| Step: 6
Training loss: 1.6760956048965454
Validation loss: 2.012445499499639

Epoch: 5| Step: 7
Training loss: 2.133568286895752
Validation loss: 2.012809698780378

Epoch: 5| Step: 8
Training loss: 1.6277908086776733
Validation loss: 2.0208657582600913

Epoch: 5| Step: 9
Training loss: 2.3202362060546875
Validation loss: 2.006667842467626

Epoch: 5| Step: 10
Training loss: 1.8094316720962524
Validation loss: 2.0102420498927436

Epoch: 5| Step: 11
Training loss: 1.3242332935333252
Validation loss: 2.0163406431674957

Epoch: 114| Step: 0
Training loss: 2.1424248218536377
Validation loss: 2.0231720755497613

Epoch: 5| Step: 1
Training loss: 2.650848865509033
Validation loss: 2.0247811625401178

Epoch: 5| Step: 2
Training loss: 1.8057702779769897
Validation loss: 2.0193685044844947

Epoch: 5| Step: 3
Training loss: 2.159184217453003
Validation loss: 2.0223754396041236

Epoch: 5| Step: 4
Training loss: 2.3034849166870117
Validation loss: 2.0318851470947266

Epoch: 5| Step: 5
Training loss: 1.742279291152954
Validation loss: 2.0211972296237946

Epoch: 5| Step: 6
Training loss: 2.1148886680603027
Validation loss: 2.0293550391991935

Epoch: 5| Step: 7
Training loss: 2.169767141342163
Validation loss: 2.0429747104644775

Epoch: 5| Step: 8
Training loss: 2.228189706802368
Validation loss: 2.0415763010581336

Epoch: 5| Step: 9
Training loss: 2.2587969303131104
Validation loss: 2.0409269432226815

Epoch: 5| Step: 10
Training loss: 2.127580404281616
Validation loss: 2.0426718344291053

Epoch: 5| Step: 11
Training loss: 0.6946264505386353
Validation loss: 2.042787805199623

Epoch: 115| Step: 0
Training loss: 2.292515277862549
Validation loss: 2.0292659948269525

Epoch: 5| Step: 1
Training loss: 2.260500192642212
Validation loss: 2.0305631260077157

Epoch: 5| Step: 2
Training loss: 2.1541614532470703
Validation loss: 2.034582167863846

Epoch: 5| Step: 3
Training loss: 1.8611608743667603
Validation loss: 2.0218843122323356

Epoch: 5| Step: 4
Training loss: 2.0125248432159424
Validation loss: 2.0231113930543265

Epoch: 5| Step: 5
Training loss: 2.0002474784851074
Validation loss: 2.0211805750926337

Epoch: 5| Step: 6
Training loss: 2.2569518089294434
Validation loss: 2.0273887614409127

Epoch: 5| Step: 7
Training loss: 1.77603018283844
Validation loss: 2.0265437960624695

Epoch: 5| Step: 8
Training loss: 2.2967472076416016
Validation loss: 2.028995340069135

Epoch: 5| Step: 9
Training loss: 2.458880662918091
Validation loss: 2.0237638105948768

Epoch: 5| Step: 10
Training loss: 1.8462913036346436
Validation loss: 2.0241019825140634

Epoch: 5| Step: 11
Training loss: 2.00278639793396
Validation loss: 2.021610895792643

Epoch: 116| Step: 0
Training loss: 1.696392297744751
Validation loss: 2.0151221603155136

Epoch: 5| Step: 1
Training loss: 2.305729627609253
Validation loss: 1.9992902477582295

Epoch: 5| Step: 2
Training loss: 2.292210102081299
Validation loss: 2.008031040430069

Epoch: 5| Step: 3
Training loss: 2.3468613624572754
Validation loss: 2.014594962199529

Epoch: 5| Step: 4
Training loss: 2.330936908721924
Validation loss: 2.021257867415746

Epoch: 5| Step: 5
Training loss: 1.717781662940979
Validation loss: 2.0220438838005066

Epoch: 5| Step: 6
Training loss: 1.8499990701675415
Validation loss: 2.0192365099986396

Epoch: 5| Step: 7
Training loss: 2.4408955574035645
Validation loss: 2.0214817424615226

Epoch: 5| Step: 8
Training loss: 1.7219276428222656
Validation loss: 2.018708904584249

Epoch: 5| Step: 9
Training loss: 2.1692891120910645
Validation loss: 2.011434723933538

Epoch: 5| Step: 10
Training loss: 2.5779643058776855
Validation loss: 2.0156300365924835

Epoch: 5| Step: 11
Training loss: 2.4742605686187744
Validation loss: 2.0018950204054513

Epoch: 117| Step: 0
Training loss: 1.9247372150421143
Validation loss: 2.0136913508176804

Epoch: 5| Step: 1
Training loss: 2.161050796508789
Validation loss: 2.0186004489660263

Epoch: 5| Step: 2
Training loss: 1.8886066675186157
Validation loss: 2.0174086491266885

Epoch: 5| Step: 3
Training loss: 2.1742587089538574
Validation loss: 2.0259925425052643

Epoch: 5| Step: 4
Training loss: 2.459442615509033
Validation loss: 2.0326988945404687

Epoch: 5| Step: 5
Training loss: 1.3830095529556274
Validation loss: 2.0436623245477676

Epoch: 5| Step: 6
Training loss: 2.0618062019348145
Validation loss: 2.0256621638933816

Epoch: 5| Step: 7
Training loss: 2.2494494915008545
Validation loss: 2.0458308905363083

Epoch: 5| Step: 8
Training loss: 2.2485175132751465
Validation loss: 2.04002017279466

Epoch: 5| Step: 9
Training loss: 2.303253650665283
Validation loss: 2.0283243507146835

Epoch: 5| Step: 10
Training loss: 2.3141767978668213
Validation loss: 2.021105612317721

Epoch: 5| Step: 11
Training loss: 2.826202869415283
Validation loss: 2.013604611158371

Epoch: 118| Step: 0
Training loss: 2.655143976211548
Validation loss: 2.0045188814401627

Epoch: 5| Step: 1
Training loss: 2.485875368118286
Validation loss: 2.0092604060967765

Epoch: 5| Step: 2
Training loss: 1.9447942972183228
Validation loss: 2.0190257281064987

Epoch: 5| Step: 3
Training loss: 2.198110580444336
Validation loss: 2.018338238199552

Epoch: 5| Step: 4
Training loss: 2.7530784606933594
Validation loss: 2.0204602628946304

Epoch: 5| Step: 5
Training loss: 1.6959174871444702
Validation loss: 2.0201982458432517

Epoch: 5| Step: 6
Training loss: 1.8523823022842407
Validation loss: 2.0100295146306357

Epoch: 5| Step: 7
Training loss: 1.3800504207611084
Validation loss: 2.003856082757314

Epoch: 5| Step: 8
Training loss: 2.1988511085510254
Validation loss: 2.004003797968229

Epoch: 5| Step: 9
Training loss: 2.3201775550842285
Validation loss: 2.0059319833914437

Epoch: 5| Step: 10
Training loss: 2.1491806507110596
Validation loss: 2.017597978313764

Epoch: 5| Step: 11
Training loss: 1.676194667816162
Validation loss: 2.0321753720442453

Epoch: 119| Step: 0
Training loss: 2.259211301803589
Validation loss: 2.0138824035724006

Epoch: 5| Step: 1
Training loss: 2.108182668685913
Validation loss: 2.0138507386048636

Epoch: 5| Step: 2
Training loss: 2.005545139312744
Validation loss: 2.007097433010737

Epoch: 5| Step: 3
Training loss: 2.539431095123291
Validation loss: 2.015679955482483

Epoch: 5| Step: 4
Training loss: 1.723479986190796
Validation loss: 2.0082623114188514

Epoch: 5| Step: 5
Training loss: 2.064096212387085
Validation loss: 2.0097749680280685

Epoch: 5| Step: 6
Training loss: 2.3631794452667236
Validation loss: 2.0090521375338235

Epoch: 5| Step: 7
Training loss: 1.9489667415618896
Validation loss: 2.0053343723217645

Epoch: 5| Step: 8
Training loss: 2.178593397140503
Validation loss: 2.0052299896876016

Epoch: 5| Step: 9
Training loss: 1.9932457208633423
Validation loss: 2.0094127853711448

Epoch: 5| Step: 10
Training loss: 2.11942982673645
Validation loss: 2.0183930347363153

Epoch: 5| Step: 11
Training loss: 2.3842287063598633
Validation loss: 2.023186812798182

Epoch: 120| Step: 0
Training loss: 2.0926928520202637
Validation loss: 2.0194945285717645

Epoch: 5| Step: 1
Training loss: 1.7240314483642578
Validation loss: 2.0238111118475595

Epoch: 5| Step: 2
Training loss: 2.3989298343658447
Validation loss: 2.0198823114236197

Epoch: 5| Step: 3
Training loss: 1.9700676202774048
Validation loss: 2.0213261047999063

Epoch: 5| Step: 4
Training loss: 2.3497719764709473
Validation loss: 2.0166774541139603

Epoch: 5| Step: 5
Training loss: 1.8780434131622314
Validation loss: 2.0221286018689475

Epoch: 5| Step: 6
Training loss: 2.203620433807373
Validation loss: 2.0210716128349304

Epoch: 5| Step: 7
Training loss: 2.0022430419921875
Validation loss: 2.0082964350779853

Epoch: 5| Step: 8
Training loss: 2.310607433319092
Validation loss: 2.021279791990916

Epoch: 5| Step: 9
Training loss: 2.430661201477051
Validation loss: 2.022070993979772

Epoch: 5| Step: 10
Training loss: 1.9889570474624634
Validation loss: 2.011239896217982

Epoch: 5| Step: 11
Training loss: 1.1147005558013916
Validation loss: 2.027950237194697

Epoch: 121| Step: 0
Training loss: 2.1947803497314453
Validation loss: 2.0111902405818305

Epoch: 5| Step: 1
Training loss: 2.198129177093506
Validation loss: 2.0171604553858438

Epoch: 5| Step: 2
Training loss: 1.5471258163452148
Validation loss: 2.0147839039564133

Epoch: 5| Step: 3
Training loss: 2.0156314373016357
Validation loss: 2.02181210120519

Epoch: 5| Step: 4
Training loss: 2.130314826965332
Validation loss: 2.0245381544033685

Epoch: 5| Step: 5
Training loss: 2.1399502754211426
Validation loss: 2.0310468524694443

Epoch: 5| Step: 6
Training loss: 2.3784143924713135
Validation loss: 2.028126150369644

Epoch: 5| Step: 7
Training loss: 2.2876224517822266
Validation loss: 2.021913856267929

Epoch: 5| Step: 8
Training loss: 2.5714192390441895
Validation loss: 2.0138467301925025

Epoch: 5| Step: 9
Training loss: 2.1598033905029297
Validation loss: 2.0166127185026803

Epoch: 5| Step: 10
Training loss: 1.5547044277191162
Validation loss: 2.005215585231781

Epoch: 5| Step: 11
Training loss: 2.12093448638916
Validation loss: 2.001523112257322

Epoch: 122| Step: 0
Training loss: 2.0798304080963135
Validation loss: 2.0019545753796897

Epoch: 5| Step: 1
Training loss: 1.8084827661514282
Validation loss: 2.0017549097537994

Epoch: 5| Step: 2
Training loss: 2.24721622467041
Validation loss: 2.0053526957829795

Epoch: 5| Step: 3
Training loss: 2.35831880569458
Validation loss: 2.0122459530830383

Epoch: 5| Step: 4
Training loss: 2.7343175411224365
Validation loss: 2.0199519842863083

Epoch: 5| Step: 5
Training loss: 2.050312042236328
Validation loss: 2.031001935402552

Epoch: 5| Step: 6
Training loss: 1.8330001831054688
Validation loss: 2.0362619509299598

Epoch: 5| Step: 7
Training loss: 1.907231092453003
Validation loss: 2.0425408681233725

Epoch: 5| Step: 8
Training loss: 2.133543014526367
Validation loss: 2.050506422917048

Epoch: 5| Step: 9
Training loss: 2.103886842727661
Validation loss: 2.034224882721901

Epoch: 5| Step: 10
Training loss: 2.0003662109375
Validation loss: 2.0178524057070413

Epoch: 5| Step: 11
Training loss: 2.4558300971984863
Validation loss: 2.0167684902747474

Epoch: 123| Step: 0
Training loss: 1.9357326030731201
Validation loss: 2.0029909759759903

Epoch: 5| Step: 1
Training loss: 2.632366895675659
Validation loss: 2.0125432511170707

Epoch: 5| Step: 2
Training loss: 1.7965562343597412
Validation loss: 2.010250906149546

Epoch: 5| Step: 3
Training loss: 1.8013803958892822
Validation loss: 2.0049652655919394

Epoch: 5| Step: 4
Training loss: 1.801180124282837
Validation loss: 2.006993994116783

Epoch: 5| Step: 5
Training loss: 2.3308498859405518
Validation loss: 2.011207198103269

Epoch: 5| Step: 6
Training loss: 2.1830735206604004
Validation loss: 2.014638418952624

Epoch: 5| Step: 7
Training loss: 2.2081751823425293
Validation loss: 2.0091860592365265

Epoch: 5| Step: 8
Training loss: 2.3452308177948
Validation loss: 2.018395255009333

Epoch: 5| Step: 9
Training loss: 2.0986106395721436
Validation loss: 2.0259856631358466

Epoch: 5| Step: 10
Training loss: 1.9539337158203125
Validation loss: 2.03909037510554

Epoch: 5| Step: 11
Training loss: 2.709700584411621
Validation loss: 2.058322379986445

Epoch: 124| Step: 0
Training loss: 1.9052002429962158
Validation loss: 2.081014712651571

Epoch: 5| Step: 1
Training loss: 1.8655116558074951
Validation loss: 2.07705919444561

Epoch: 5| Step: 2
Training loss: 2.245591640472412
Validation loss: 2.054858018954595

Epoch: 5| Step: 3
Training loss: 1.8571618795394897
Validation loss: 2.042389194170634

Epoch: 5| Step: 4
Training loss: 2.0950725078582764
Validation loss: 2.018488625685374

Epoch: 5| Step: 5
Training loss: 2.1229660511016846
Validation loss: 2.010536735256513

Epoch: 5| Step: 6
Training loss: 2.5324182510375977
Validation loss: 2.006295308470726

Epoch: 5| Step: 7
Training loss: 2.2321271896362305
Validation loss: 2.0192644198735556

Epoch: 5| Step: 8
Training loss: 2.313490390777588
Validation loss: 2.0196751405795417

Epoch: 5| Step: 9
Training loss: 2.3201401233673096
Validation loss: 2.018212174375852

Epoch: 5| Step: 10
Training loss: 2.356858968734741
Validation loss: 2.0264676908651986

Epoch: 5| Step: 11
Training loss: 1.3543492555618286
Validation loss: 2.0309826781352363

Epoch: 125| Step: 0
Training loss: 1.899437665939331
Validation loss: 2.02790230512619

Epoch: 5| Step: 1
Training loss: 1.9787120819091797
Validation loss: 2.028192271788915

Epoch: 5| Step: 2
Training loss: 1.8828208446502686
Validation loss: 2.0297628293434777

Epoch: 5| Step: 3
Training loss: 2.286543369293213
Validation loss: 2.0289940933386483

Epoch: 5| Step: 4
Training loss: 2.009674310684204
Validation loss: 2.030975808699926

Epoch: 5| Step: 5
Training loss: 2.1616568565368652
Validation loss: 2.0192512472470603

Epoch: 5| Step: 6
Training loss: 2.7072722911834717
Validation loss: 2.022108480334282

Epoch: 5| Step: 7
Training loss: 2.540482521057129
Validation loss: 2.015537773569425

Epoch: 5| Step: 8
Training loss: 2.0847156047821045
Validation loss: 2.0088781813780465

Epoch: 5| Step: 9
Training loss: 1.6821777820587158
Validation loss: 2.0089873721202216

Epoch: 5| Step: 10
Training loss: 2.1171162128448486
Validation loss: 2.0043829331795373

Epoch: 5| Step: 11
Training loss: 2.7724852561950684
Validation loss: 1.990530823667844

Epoch: 126| Step: 0
Training loss: 2.168595552444458
Validation loss: 2.0194445848464966

Epoch: 5| Step: 1
Training loss: 2.3664307594299316
Validation loss: 2.033902739485105

Epoch: 5| Step: 2
Training loss: 1.7150919437408447
Validation loss: 2.0495392431815467

Epoch: 5| Step: 3
Training loss: 2.3403685092926025
Validation loss: 2.0572304079929986

Epoch: 5| Step: 4
Training loss: 1.679339051246643
Validation loss: 2.0736633241176605

Epoch: 5| Step: 5
Training loss: 2.3774638175964355
Validation loss: 2.0774612526098886

Epoch: 5| Step: 6
Training loss: 1.9676555395126343
Validation loss: 2.0707919895648956

Epoch: 5| Step: 7
Training loss: 2.436657428741455
Validation loss: 2.0599618206421533

Epoch: 5| Step: 8
Training loss: 2.0834548473358154
Validation loss: 2.0326340943574905

Epoch: 5| Step: 9
Training loss: 1.9253394603729248
Validation loss: 2.032971719900767

Epoch: 5| Step: 10
Training loss: 2.428842782974243
Validation loss: 2.0182383159796395

Epoch: 5| Step: 11
Training loss: 1.5719596147537231
Validation loss: 2.02179088195165

Epoch: 127| Step: 0
Training loss: 2.1374869346618652
Validation loss: 2.0343601405620575

Epoch: 5| Step: 1
Training loss: 2.685617685317993
Validation loss: 2.0373876889546714

Epoch: 5| Step: 2
Training loss: 2.4607253074645996
Validation loss: 2.0391756097475686

Epoch: 5| Step: 3
Training loss: 1.7646758556365967
Validation loss: 2.039071242014567

Epoch: 5| Step: 4
Training loss: 2.220510959625244
Validation loss: 2.050269141793251

Epoch: 5| Step: 5
Training loss: 2.5997488498687744
Validation loss: 2.0428390552600226

Epoch: 5| Step: 6
Training loss: 2.2695870399475098
Validation loss: 2.049923906723658

Epoch: 5| Step: 7
Training loss: 2.1365315914154053
Validation loss: 2.0435292770465217

Epoch: 5| Step: 8
Training loss: 1.7909806966781616
Validation loss: 2.047387570142746

Epoch: 5| Step: 9
Training loss: 1.9151493310928345
Validation loss: 2.0434669156869254

Epoch: 5| Step: 10
Training loss: 2.2097373008728027
Validation loss: 2.0442401319742203

Epoch: 5| Step: 11
Training loss: 1.9876915216445923
Validation loss: 2.0335562030474343

Epoch: 128| Step: 0
Training loss: 2.348125457763672
Validation loss: 2.045810798803965

Epoch: 5| Step: 1
Training loss: 1.976007103919983
Validation loss: 2.0389067927996316

Epoch: 5| Step: 2
Training loss: 2.035703420639038
Validation loss: 2.0339987029631934

Epoch: 5| Step: 3
Training loss: 2.677950859069824
Validation loss: 2.032936712106069

Epoch: 5| Step: 4
Training loss: 2.0225436687469482
Validation loss: 2.0229176580905914

Epoch: 5| Step: 5
Training loss: 1.992945909500122
Validation loss: 2.0199687282244363

Epoch: 5| Step: 6
Training loss: 2.407784938812256
Validation loss: 2.0129509021838508

Epoch: 5| Step: 7
Training loss: 1.8155930042266846
Validation loss: 2.010521893699964

Epoch: 5| Step: 8
Training loss: 2.058816909790039
Validation loss: 1.9938479165236156

Epoch: 5| Step: 9
Training loss: 2.0351200103759766
Validation loss: 2.0047778139511743

Epoch: 5| Step: 10
Training loss: 2.276949405670166
Validation loss: 2.001942311724027

Epoch: 5| Step: 11
Training loss: 1.4678356647491455
Validation loss: 2.017713278532028

Epoch: 129| Step: 0
Training loss: 2.199437141418457
Validation loss: 2.022916873296102

Epoch: 5| Step: 1
Training loss: 2.0214884281158447
Validation loss: 2.029465933640798

Epoch: 5| Step: 2
Training loss: 2.4450266361236572
Validation loss: 2.055654302239418

Epoch: 5| Step: 3
Training loss: 1.7113841772079468
Validation loss: 2.0610507229963937

Epoch: 5| Step: 4
Training loss: 2.62263560295105
Validation loss: 2.0841099868218103

Epoch: 5| Step: 5
Training loss: 2.025662899017334
Validation loss: 2.0586646298567453

Epoch: 5| Step: 6
Training loss: 1.9071305990219116
Validation loss: 2.029644265770912

Epoch: 5| Step: 7
Training loss: 2.5452027320861816
Validation loss: 2.0220935344696045

Epoch: 5| Step: 8
Training loss: 1.92404305934906
Validation loss: 2.0177184641361237

Epoch: 5| Step: 9
Training loss: 2.1151084899902344
Validation loss: 2.020373006661733

Epoch: 5| Step: 10
Training loss: 2.1368603706359863
Validation loss: 2.0118314822514853

Epoch: 5| Step: 11
Training loss: 2.0499444007873535
Validation loss: 2.0126480956872306

Epoch: 130| Step: 0
Training loss: 1.9541314840316772
Validation loss: 2.014303425947825

Epoch: 5| Step: 1
Training loss: 2.2595837116241455
Validation loss: 2.015257105231285

Epoch: 5| Step: 2
Training loss: 2.2452445030212402
Validation loss: 2.0206649700800576

Epoch: 5| Step: 3
Training loss: 2.5471601486206055
Validation loss: 2.011041432619095

Epoch: 5| Step: 4
Training loss: 1.693336844444275
Validation loss: 2.0166046917438507

Epoch: 5| Step: 5
Training loss: 1.7589738368988037
Validation loss: 2.0148931592702866

Epoch: 5| Step: 6
Training loss: 2.521886110305786
Validation loss: 2.024055376648903

Epoch: 5| Step: 7
Training loss: 2.9807560443878174
Validation loss: 2.022736837466558

Epoch: 5| Step: 8
Training loss: 1.811888337135315
Validation loss: 2.0241166253884635

Epoch: 5| Step: 9
Training loss: 1.9219671487808228
Validation loss: 2.0281877666711807

Epoch: 5| Step: 10
Training loss: 1.6829408407211304
Validation loss: 2.0489323884248734

Epoch: 5| Step: 11
Training loss: 0.9601439237594604
Validation loss: 2.053890739878019

Epoch: 131| Step: 0
Training loss: 1.699013113975525
Validation loss: 2.0704130828380585

Epoch: 5| Step: 1
Training loss: 2.223769426345825
Validation loss: 2.0746122300624847

Epoch: 5| Step: 2
Training loss: 1.735811471939087
Validation loss: 2.0738227516412735

Epoch: 5| Step: 3
Training loss: 2.5254783630371094
Validation loss: 2.0749411235253015

Epoch: 5| Step: 4
Training loss: 1.8592020273208618
Validation loss: 2.0782010604937873

Epoch: 5| Step: 5
Training loss: 2.7526562213897705
Validation loss: 2.068451464176178

Epoch: 5| Step: 6
Training loss: 1.608231782913208
Validation loss: 2.0491316318511963

Epoch: 5| Step: 7
Training loss: 1.6947574615478516
Validation loss: 2.0334372222423553

Epoch: 5| Step: 8
Training loss: 2.057842254638672
Validation loss: 2.0391327937444053

Epoch: 5| Step: 9
Training loss: 2.48449969291687
Validation loss: 2.02617214123408

Epoch: 5| Step: 10
Training loss: 2.8035755157470703
Validation loss: 2.0134543081124625

Epoch: 5| Step: 11
Training loss: 1.5705844163894653
Validation loss: 2.004164457321167

Epoch: 132| Step: 0
Training loss: 1.991595983505249
Validation loss: 2.0061921228965125

Epoch: 5| Step: 1
Training loss: 2.1902055740356445
Validation loss: 2.0056341042121253

Epoch: 5| Step: 2
Training loss: 2.174556255340576
Validation loss: 2.01324633260568

Epoch: 5| Step: 3
Training loss: 2.2874412536621094
Validation loss: 2.018347824613253

Epoch: 5| Step: 4
Training loss: 1.8979629278182983
Validation loss: 2.0165856232245765

Epoch: 5| Step: 5
Training loss: 2.0690016746520996
Validation loss: 2.009633685151736

Epoch: 5| Step: 6
Training loss: 2.1798229217529297
Validation loss: 2.008430322011312

Epoch: 5| Step: 7
Training loss: 2.159607410430908
Validation loss: 2.0093707889318466

Epoch: 5| Step: 8
Training loss: 2.2653865814208984
Validation loss: 2.0150288393100104

Epoch: 5| Step: 9
Training loss: 1.6617295742034912
Validation loss: 2.022516757249832

Epoch: 5| Step: 10
Training loss: 2.440142869949341
Validation loss: 2.025838260849317

Epoch: 5| Step: 11
Training loss: 2.2842705249786377
Validation loss: 2.0240686486164727

Epoch: 133| Step: 0
Training loss: 2.0440573692321777
Validation loss: 2.029315193494161

Epoch: 5| Step: 1
Training loss: 2.4954609870910645
Validation loss: 2.0326676666736603

Epoch: 5| Step: 2
Training loss: 2.3135132789611816
Validation loss: 2.0272037784258523

Epoch: 5| Step: 3
Training loss: 2.1577343940734863
Validation loss: 2.0278990467389426

Epoch: 5| Step: 4
Training loss: 1.754774808883667
Validation loss: 2.0164807587862015

Epoch: 5| Step: 5
Training loss: 1.8906348943710327
Validation loss: 2.01155420144399

Epoch: 5| Step: 6
Training loss: 2.199213981628418
Validation loss: 2.0215995609760284

Epoch: 5| Step: 7
Training loss: 1.8338019847869873
Validation loss: 2.0204954197009406

Epoch: 5| Step: 8
Training loss: 2.43699049949646
Validation loss: 2.015396719177564

Epoch: 5| Step: 9
Training loss: 1.6871172189712524
Validation loss: 2.002398024002711

Epoch: 5| Step: 10
Training loss: 2.187039613723755
Validation loss: 2.0135738601287207

Epoch: 5| Step: 11
Training loss: 1.6758999824523926
Validation loss: 2.0173850804567337

Epoch: 134| Step: 0
Training loss: 1.5878047943115234
Validation loss: 2.008517066637675

Epoch: 5| Step: 1
Training loss: 2.544663906097412
Validation loss: 2.0102501710255942

Epoch: 5| Step: 2
Training loss: 1.8393338918685913
Validation loss: 2.0207219620545707

Epoch: 5| Step: 3
Training loss: 2.402660369873047
Validation loss: 2.01210289200147

Epoch: 5| Step: 4
Training loss: 1.9502449035644531
Validation loss: 2.0132065812746682

Epoch: 5| Step: 5
Training loss: 2.3451430797576904
Validation loss: 2.016141136487325

Epoch: 5| Step: 6
Training loss: 1.9930404424667358
Validation loss: 2.021255080898603

Epoch: 5| Step: 7
Training loss: 2.184560775756836
Validation loss: 2.0086857080459595

Epoch: 5| Step: 8
Training loss: 1.9021514654159546
Validation loss: 2.0276372333367667

Epoch: 5| Step: 9
Training loss: 2.081984281539917
Validation loss: 2.0163968255122504

Epoch: 5| Step: 10
Training loss: 2.2616000175476074
Validation loss: 2.0148081531127295

Epoch: 5| Step: 11
Training loss: 1.1432225704193115
Validation loss: 2.0203712483247123

Epoch: 135| Step: 0
Training loss: 2.222093105316162
Validation loss: 2.022229497631391

Epoch: 5| Step: 1
Training loss: 2.009593963623047
Validation loss: 2.0164741575717926

Epoch: 5| Step: 2
Training loss: 1.6627657413482666
Validation loss: 2.02498027185599

Epoch: 5| Step: 3
Training loss: 2.265263080596924
Validation loss: 2.013444314400355

Epoch: 5| Step: 4
Training loss: 1.9938558340072632
Validation loss: 2.0319722443819046

Epoch: 5| Step: 5
Training loss: 2.0371193885803223
Validation loss: 2.0210762520631156

Epoch: 5| Step: 6
Training loss: 2.1581530570983887
Validation loss: 2.022062619527181

Epoch: 5| Step: 7
Training loss: 1.972974181175232
Validation loss: 2.021795173486074

Epoch: 5| Step: 8
Training loss: 2.722627878189087
Validation loss: 2.019552543759346

Epoch: 5| Step: 9
Training loss: 1.826135277748108
Validation loss: 2.011938934524854

Epoch: 5| Step: 10
Training loss: 2.142595052719116
Validation loss: 2.012534643212954

Epoch: 5| Step: 11
Training loss: 1.5056746006011963
Validation loss: 2.012228528658549

Epoch: 136| Step: 0
Training loss: 1.7458159923553467
Validation loss: 2.0120555510123572

Epoch: 5| Step: 1
Training loss: 2.4782662391662598
Validation loss: 2.026974822084109

Epoch: 5| Step: 2
Training loss: 1.7970893383026123
Validation loss: 2.0249418367942176

Epoch: 5| Step: 3
Training loss: 1.6697841882705688
Validation loss: 2.026420180996259

Epoch: 5| Step: 4
Training loss: 1.3635722398757935
Validation loss: 2.0311475694179535

Epoch: 5| Step: 5
Training loss: 2.5147299766540527
Validation loss: 2.0393187950054803

Epoch: 5| Step: 6
Training loss: 1.9423935413360596
Validation loss: 2.0380289802948632

Epoch: 5| Step: 7
Training loss: 2.2529959678649902
Validation loss: 2.0512998402118683

Epoch: 5| Step: 8
Training loss: 2.4988086223602295
Validation loss: 2.055468112230301

Epoch: 5| Step: 9
Training loss: 2.16255521774292
Validation loss: 2.053351273139318

Epoch: 5| Step: 10
Training loss: 2.2394320964813232
Validation loss: 2.0540691167116165

Epoch: 5| Step: 11
Training loss: 2.8478903770446777
Validation loss: 2.0632558266321817

Epoch: 137| Step: 0
Training loss: 2.3822994232177734
Validation loss: 2.0481543143590293

Epoch: 5| Step: 1
Training loss: 1.969900369644165
Validation loss: 2.0418102145195007

Epoch: 5| Step: 2
Training loss: 2.0370869636535645
Validation loss: 2.038066570957502

Epoch: 5| Step: 3
Training loss: 2.096588611602783
Validation loss: 2.022043988108635

Epoch: 5| Step: 4
Training loss: 1.797904372215271
Validation loss: 2.034685716032982

Epoch: 5| Step: 5
Training loss: 2.0947532653808594
Validation loss: 2.027709941069285

Epoch: 5| Step: 6
Training loss: 2.035231590270996
Validation loss: 2.035308758417765

Epoch: 5| Step: 7
Training loss: 2.339595079421997
Validation loss: 2.0306632866462073

Epoch: 5| Step: 8
Training loss: 2.35723614692688
Validation loss: 2.0313971986373267

Epoch: 5| Step: 9
Training loss: 2.247983455657959
Validation loss: 2.0382287402947745

Epoch: 5| Step: 10
Training loss: 1.6593939065933228
Validation loss: 2.029548093676567

Epoch: 5| Step: 11
Training loss: 0.9266649484634399
Validation loss: 2.027970870335897

Epoch: 138| Step: 0
Training loss: 2.116068124771118
Validation loss: 2.0373635043700538

Epoch: 5| Step: 1
Training loss: 1.8469959497451782
Validation loss: 2.0517785449822745

Epoch: 5| Step: 2
Training loss: 2.0690464973449707
Validation loss: 2.0625711431105933

Epoch: 5| Step: 3
Training loss: 2.2530875205993652
Validation loss: 2.0621338983376822

Epoch: 5| Step: 4
Training loss: 2.026494026184082
Validation loss: 2.067424034078916

Epoch: 5| Step: 5
Training loss: 2.6450629234313965
Validation loss: 2.029250164826711

Epoch: 5| Step: 6
Training loss: 1.706132173538208
Validation loss: 2.0459173818429313

Epoch: 5| Step: 7
Training loss: 1.8131024837493896
Validation loss: 2.0391972959041595

Epoch: 5| Step: 8
Training loss: 2.0387773513793945
Validation loss: 2.0332255015770593

Epoch: 5| Step: 9
Training loss: 2.4159469604492188
Validation loss: 2.0322892467180886

Epoch: 5| Step: 10
Training loss: 1.9469082355499268
Validation loss: 2.026113564769427

Epoch: 5| Step: 11
Training loss: 1.9918915033340454
Validation loss: 2.0262403388818107

Epoch: 139| Step: 0
Training loss: 1.9441893100738525
Validation loss: 2.0216146608193717

Epoch: 5| Step: 1
Training loss: 2.602236270904541
Validation loss: 2.01804618537426

Epoch: 5| Step: 2
Training loss: 2.0017285346984863
Validation loss: 2.020329624414444

Epoch: 5| Step: 3
Training loss: 2.0137152671813965
Validation loss: 2.032141695419947

Epoch: 5| Step: 4
Training loss: 2.3585877418518066
Validation loss: 2.0385136008262634

Epoch: 5| Step: 5
Training loss: 1.9067132472991943
Validation loss: 2.037152280410131

Epoch: 5| Step: 6
Training loss: 1.7532575130462646
Validation loss: 2.041966368754705

Epoch: 5| Step: 7
Training loss: 1.7676887512207031
Validation loss: 2.035487080613772

Epoch: 5| Step: 8
Training loss: 2.563070774078369
Validation loss: 2.0309488028287888

Epoch: 5| Step: 9
Training loss: 1.7900346517562866
Validation loss: 2.0292031864325204

Epoch: 5| Step: 10
Training loss: 2.7539615631103516
Validation loss: 2.0366116811831794

Epoch: 5| Step: 11
Training loss: 1.3826470375061035
Validation loss: 2.025812809665998

Epoch: 140| Step: 0
Training loss: 2.255836009979248
Validation loss: 2.0225683798392615

Epoch: 5| Step: 1
Training loss: 2.430569648742676
Validation loss: 2.0334939459959664

Epoch: 5| Step: 2
Training loss: 2.245971202850342
Validation loss: 2.038713961839676

Epoch: 5| Step: 3
Training loss: 2.1386513710021973
Validation loss: 2.0318929702043533

Epoch: 5| Step: 4
Training loss: 1.7636306285858154
Validation loss: 2.048677439490954

Epoch: 5| Step: 5
Training loss: 2.101213216781616
Validation loss: 2.0606590807437897

Epoch: 5| Step: 6
Training loss: 1.9686866998672485
Validation loss: 2.0824701140324273

Epoch: 5| Step: 7
Training loss: 1.6563920974731445
Validation loss: 2.0934026588996253

Epoch: 5| Step: 8
Training loss: 2.469581127166748
Validation loss: 2.081963693102201

Epoch: 5| Step: 9
Training loss: 2.3890252113342285
Validation loss: 2.0650113175312677

Epoch: 5| Step: 10
Training loss: 1.578124761581421
Validation loss: 2.0455167293548584

Epoch: 5| Step: 11
Training loss: 2.536884069442749
Validation loss: 2.0390188843011856

Epoch: 141| Step: 0
Training loss: 2.4623985290527344
Validation loss: 2.03909794986248

Epoch: 5| Step: 1
Training loss: 2.209462881088257
Validation loss: 2.029658551017443

Epoch: 5| Step: 2
Training loss: 1.8875350952148438
Validation loss: 2.0238360861937204

Epoch: 5| Step: 3
Training loss: 1.5484386682510376
Validation loss: 2.021576076745987

Epoch: 5| Step: 4
Training loss: 2.373802661895752
Validation loss: 2.021691158413887

Epoch: 5| Step: 5
Training loss: 1.9627361297607422
Validation loss: 2.0225517402092614

Epoch: 5| Step: 6
Training loss: 2.506533145904541
Validation loss: 2.0304633180300393

Epoch: 5| Step: 7
Training loss: 2.1399784088134766
Validation loss: 2.0240532209475837

Epoch: 5| Step: 8
Training loss: 1.8128814697265625
Validation loss: 2.0299531867106757

Epoch: 5| Step: 9
Training loss: 2.1802680492401123
Validation loss: 2.028347889582316

Epoch: 5| Step: 10
Training loss: 2.239316940307617
Validation loss: 2.0205199470122657

Epoch: 5| Step: 11
Training loss: 2.335486888885498
Validation loss: 2.0274034837881723

Epoch: 142| Step: 0
Training loss: 1.7724659442901611
Validation loss: 2.0062072823445

Epoch: 5| Step: 1
Training loss: 1.83819580078125
Validation loss: 2.019771342476209

Epoch: 5| Step: 2
Training loss: 1.791669487953186
Validation loss: 2.0296825766563416

Epoch: 5| Step: 3
Training loss: 2.0885584354400635
Validation loss: 2.0547052919864655

Epoch: 5| Step: 4
Training loss: 2.4232382774353027
Validation loss: 2.0608816693226495

Epoch: 5| Step: 5
Training loss: 2.526951789855957
Validation loss: 2.069065476457278

Epoch: 5| Step: 6
Training loss: 1.9817650318145752
Validation loss: 2.071893801291784

Epoch: 5| Step: 7
Training loss: 2.2121829986572266
Validation loss: 2.065166791280111

Epoch: 5| Step: 8
Training loss: 1.8610913753509521
Validation loss: 2.057294711470604

Epoch: 5| Step: 9
Training loss: 2.150871992111206
Validation loss: 2.0688828229904175

Epoch: 5| Step: 10
Training loss: 1.9756019115447998
Validation loss: 2.0490102668603263

Epoch: 5| Step: 11
Training loss: 2.722907543182373
Validation loss: 2.041152517000834

Epoch: 143| Step: 0
Training loss: 2.426980972290039
Validation loss: 2.043961822986603

Epoch: 5| Step: 1
Training loss: 2.5713722705841064
Validation loss: 2.034752309322357

Epoch: 5| Step: 2
Training loss: 1.9579908847808838
Validation loss: 2.028811772664388

Epoch: 5| Step: 3
Training loss: 2.1044063568115234
Validation loss: 2.0320663253466287

Epoch: 5| Step: 4
Training loss: 1.8844349384307861
Validation loss: 2.0327530850966773

Epoch: 5| Step: 5
Training loss: 1.9647735357284546
Validation loss: 2.0300044814745584

Epoch: 5| Step: 6
Training loss: 1.9345767498016357
Validation loss: 2.0385521054267883

Epoch: 5| Step: 7
Training loss: 2.104931116104126
Validation loss: 2.0422486662864685

Epoch: 5| Step: 8
Training loss: 2.0914127826690674
Validation loss: 2.042229558030764

Epoch: 5| Step: 9
Training loss: 2.251225709915161
Validation loss: 2.0352682073911033

Epoch: 5| Step: 10
Training loss: 1.8648498058319092
Validation loss: 2.0319159726301828

Epoch: 5| Step: 11
Training loss: 1.0841162204742432
Validation loss: 2.031611775358518

Epoch: 144| Step: 0
Training loss: 2.2309234142303467
Validation loss: 2.040655086437861

Epoch: 5| Step: 1
Training loss: 1.9000076055526733
Validation loss: 2.0222892612218857

Epoch: 5| Step: 2
Training loss: 2.520244598388672
Validation loss: 2.0274590899546943

Epoch: 5| Step: 3
Training loss: 1.8500725030899048
Validation loss: 2.017300362388293

Epoch: 5| Step: 4
Training loss: 2.1879730224609375
Validation loss: 2.0206887274980545

Epoch: 5| Step: 5
Training loss: 2.5642282962799072
Validation loss: 2.0207551618417106

Epoch: 5| Step: 6
Training loss: 2.1475701332092285
Validation loss: 2.024079735080401

Epoch: 5| Step: 7
Training loss: 1.8731714487075806
Validation loss: 2.0183228055636087

Epoch: 5| Step: 8
Training loss: 2.1589431762695312
Validation loss: 2.0217169423898063

Epoch: 5| Step: 9
Training loss: 1.797133445739746
Validation loss: 2.0227249016364417

Epoch: 5| Step: 10
Training loss: 1.9726718664169312
Validation loss: 2.0321724166472754

Epoch: 5| Step: 11
Training loss: 1.046811580657959
Validation loss: 2.022250607609749

Epoch: 145| Step: 0
Training loss: 2.350865125656128
Validation loss: 2.030498206615448

Epoch: 5| Step: 1
Training loss: 2.528897523880005
Validation loss: 2.041680191953977

Epoch: 5| Step: 2
Training loss: 2.4287500381469727
Validation loss: 2.0650418947140374

Epoch: 5| Step: 3
Training loss: 1.5413463115692139
Validation loss: 2.0565922409296036

Epoch: 5| Step: 4
Training loss: 1.9651600122451782
Validation loss: 2.0709882775942483

Epoch: 5| Step: 5
Training loss: 2.0741000175476074
Validation loss: 2.058774381875992

Epoch: 5| Step: 6
Training loss: 2.0867743492126465
Validation loss: 2.0596948713064194

Epoch: 5| Step: 7
Training loss: 1.8853013515472412
Validation loss: 2.0615066091219583

Epoch: 5| Step: 8
Training loss: 1.9260320663452148
Validation loss: 2.0539022932449975

Epoch: 5| Step: 9
Training loss: 1.908409833908081
Validation loss: 2.0580792923768363

Epoch: 5| Step: 10
Training loss: 1.857806921005249
Validation loss: 2.0558670113484063

Epoch: 5| Step: 11
Training loss: 2.0673561096191406
Validation loss: 2.0505894919236503

Epoch: 146| Step: 0
Training loss: 2.0961220264434814
Validation loss: 2.0272563993930817

Epoch: 5| Step: 1
Training loss: 2.5530457496643066
Validation loss: 2.0144834319750466

Epoch: 5| Step: 2
Training loss: 1.6225029230117798
Validation loss: 2.0208595792452493

Epoch: 5| Step: 3
Training loss: 2.5589945316314697
Validation loss: 2.0347976932922998

Epoch: 5| Step: 4
Training loss: 2.331055164337158
Validation loss: 2.03019126256307

Epoch: 5| Step: 5
Training loss: 2.241886615753174
Validation loss: 2.0375101963678994

Epoch: 5| Step: 6
Training loss: 1.8182188272476196
Validation loss: 2.0375230560700097

Epoch: 5| Step: 7
Training loss: 1.4784166812896729
Validation loss: 2.037955328822136

Epoch: 5| Step: 8
Training loss: 2.0744669437408447
Validation loss: 2.0382672399282455

Epoch: 5| Step: 9
Training loss: 1.5163615942001343
Validation loss: 2.0434095164140067

Epoch: 5| Step: 10
Training loss: 2.6684765815734863
Validation loss: 2.0343233992656073

Epoch: 5| Step: 11
Training loss: 3.9486026763916016
Validation loss: 2.035448690255483

Epoch: 147| Step: 0
Training loss: 2.2592761516571045
Validation loss: 2.0357989221811295

Epoch: 5| Step: 1
Training loss: 2.4219250679016113
Validation loss: 2.0252478321393332

Epoch: 5| Step: 2
Training loss: 1.9658453464508057
Validation loss: 2.0328351159890494

Epoch: 5| Step: 3
Training loss: 2.1447911262512207
Validation loss: 2.022423471013705

Epoch: 5| Step: 4
Training loss: 1.955152153968811
Validation loss: 2.0184623996416726

Epoch: 5| Step: 5
Training loss: 1.615443468093872
Validation loss: 2.0134342362483344

Epoch: 5| Step: 6
Training loss: 2.4330124855041504
Validation loss: 2.025915498534838

Epoch: 5| Step: 7
Training loss: 2.316751003265381
Validation loss: 2.0269620766242347

Epoch: 5| Step: 8
Training loss: 1.6818774938583374
Validation loss: 2.0195797979831696

Epoch: 5| Step: 9
Training loss: 1.767073631286621
Validation loss: 2.030078113079071

Epoch: 5| Step: 10
Training loss: 2.591130018234253
Validation loss: 2.0367946475744247

Epoch: 5| Step: 11
Training loss: 2.304588794708252
Validation loss: 2.052845855553945

Epoch: 148| Step: 0
Training loss: 2.3673553466796875
Validation loss: 2.0364750822385154

Epoch: 5| Step: 1
Training loss: 1.728867769241333
Validation loss: 2.0404005448023477

Epoch: 5| Step: 2
Training loss: 1.7357221841812134
Validation loss: 2.034813106060028

Epoch: 5| Step: 3
Training loss: 2.176877975463867
Validation loss: 2.038009991248449

Epoch: 5| Step: 4
Training loss: 2.1394925117492676
Validation loss: 2.0252878268559775

Epoch: 5| Step: 5
Training loss: 2.551187038421631
Validation loss: 2.029730647802353

Epoch: 5| Step: 6
Training loss: 1.7842798233032227
Validation loss: 2.0218012233575187

Epoch: 5| Step: 7
Training loss: 2.0386128425598145
Validation loss: 2.0257683595021567

Epoch: 5| Step: 8
Training loss: 2.1398627758026123
Validation loss: 2.0237025320529938

Epoch: 5| Step: 9
Training loss: 2.1176917552948
Validation loss: 2.0251207600037255

Epoch: 5| Step: 10
Training loss: 2.169661283493042
Validation loss: 2.025567506750425

Epoch: 5| Step: 11
Training loss: 1.8644020557403564
Validation loss: 2.0290496945381165

Epoch: 149| Step: 0
Training loss: 2.5497500896453857
Validation loss: 2.017026975750923

Epoch: 5| Step: 1
Training loss: 1.8077259063720703
Validation loss: 2.028015593687693

Epoch: 5| Step: 2
Training loss: 1.8281978368759155
Validation loss: 2.0350201576948166

Epoch: 5| Step: 3
Training loss: 1.5601071119308472
Validation loss: 2.0331704914569855

Epoch: 5| Step: 4
Training loss: 2.1188902854919434
Validation loss: 2.0332166204849877

Epoch: 5| Step: 5
Training loss: 1.9935060739517212
Validation loss: 2.0413804600636163

Epoch: 5| Step: 6
Training loss: 1.9984012842178345
Validation loss: 2.0485783765713372

Epoch: 5| Step: 7
Training loss: 2.5565736293792725
Validation loss: 2.05650831758976

Epoch: 5| Step: 8
Training loss: 1.7981230020523071
Validation loss: 2.056012362241745

Epoch: 5| Step: 9
Training loss: 2.5771572589874268
Validation loss: 2.0643961479266486

Epoch: 5| Step: 10
Training loss: 1.7321529388427734
Validation loss: 2.0852621694405875

Epoch: 5| Step: 11
Training loss: 2.2282660007476807
Validation loss: 2.079309572776159

Epoch: 150| Step: 0
Training loss: 2.227341890335083
Validation loss: 2.0514649401108422

Epoch: 5| Step: 1
Training loss: 1.7105567455291748
Validation loss: 2.0403555631637573

Epoch: 5| Step: 2
Training loss: 2.1029105186462402
Validation loss: 2.0393962810436883

Epoch: 5| Step: 3
Training loss: 2.071998119354248
Validation loss: 2.0325355331103006

Epoch: 5| Step: 4
Training loss: 1.7633750438690186
Validation loss: 2.044172619779905

Epoch: 5| Step: 5
Training loss: 2.082477331161499
Validation loss: 2.040196791291237

Epoch: 5| Step: 6
Training loss: 2.459947109222412
Validation loss: 2.0541516095399857

Epoch: 5| Step: 7
Training loss: 1.9999186992645264
Validation loss: 2.0538617173830667

Epoch: 5| Step: 8
Training loss: 1.872602105140686
Validation loss: 2.065577487150828

Epoch: 5| Step: 9
Training loss: 2.019415855407715
Validation loss: 2.060451457897822

Epoch: 5| Step: 10
Training loss: 1.9299100637435913
Validation loss: 2.0480734954277673

Epoch: 5| Step: 11
Training loss: 3.588865280151367
Validation loss: 2.048248812556267

Epoch: 151| Step: 0
Training loss: 1.6993287801742554
Validation loss: 2.0419492721557617

Epoch: 5| Step: 1
Training loss: 2.2585573196411133
Validation loss: 2.043274169166883

Epoch: 5| Step: 2
Training loss: 2.2894186973571777
Validation loss: 2.0444318453470864

Epoch: 5| Step: 3
Training loss: 2.2762763500213623
Validation loss: 2.0426628291606903

Epoch: 5| Step: 4
Training loss: 2.065835952758789
Validation loss: 2.043025607864062

Epoch: 5| Step: 5
Training loss: 2.0683815479278564
Validation loss: 2.0363575418790183

Epoch: 5| Step: 6
Training loss: 2.2509663105010986
Validation loss: 2.038891096909841

Epoch: 5| Step: 7
Training loss: 1.5436429977416992
Validation loss: 2.0368386954069138

Epoch: 5| Step: 8
Training loss: 2.1718506813049316
Validation loss: 2.0369494557380676

Epoch: 5| Step: 9
Training loss: 1.9325917959213257
Validation loss: 2.051765968402227

Epoch: 5| Step: 10
Training loss: 1.9502813816070557
Validation loss: 2.0584870874881744

Epoch: 5| Step: 11
Training loss: 2.5108227729797363
Validation loss: 2.0512179136276245

Epoch: 152| Step: 0
Training loss: 1.9876258373260498
Validation loss: 2.043098067243894

Epoch: 5| Step: 1
Training loss: 1.8493095636367798
Validation loss: 2.054883981744448

Epoch: 5| Step: 2
Training loss: 2.153357982635498
Validation loss: 2.051199793815613

Epoch: 5| Step: 3
Training loss: 2.070835828781128
Validation loss: 2.049575924873352

Epoch: 5| Step: 4
Training loss: 2.464381217956543
Validation loss: 2.0534064968427024

Epoch: 5| Step: 5
Training loss: 2.4840145111083984
Validation loss: 2.054601639509201

Epoch: 5| Step: 6
Training loss: 1.5791780948638916
Validation loss: 2.049865201115608

Epoch: 5| Step: 7
Training loss: 2.0378787517547607
Validation loss: 2.053115670879682

Epoch: 5| Step: 8
Training loss: 2.0901691913604736
Validation loss: 2.040359010299047

Epoch: 5| Step: 9
Training loss: 2.155574321746826
Validation loss: 2.035048171877861

Epoch: 5| Step: 10
Training loss: 1.6712802648544312
Validation loss: 2.0416626880566278

Epoch: 5| Step: 11
Training loss: 1.6232861280441284
Validation loss: 2.0365852415561676

Epoch: 153| Step: 0
Training loss: 1.699367880821228
Validation loss: 2.031270811955134

Epoch: 5| Step: 1
Training loss: 1.4859535694122314
Validation loss: 2.04522372285525

Epoch: 5| Step: 2
Training loss: 1.9453125
Validation loss: 2.050948992371559

Epoch: 5| Step: 3
Training loss: 2.920830488204956
Validation loss: 2.0549127558867135

Epoch: 5| Step: 4
Training loss: 2.097632646560669
Validation loss: 2.052208741505941

Epoch: 5| Step: 5
Training loss: 1.8232316970825195
Validation loss: 2.0545289317766824

Epoch: 5| Step: 6
Training loss: 2.569384813308716
Validation loss: 2.0633466194073358

Epoch: 5| Step: 7
Training loss: 1.9641954898834229
Validation loss: 2.056771611173948

Epoch: 5| Step: 8
Training loss: 2.1123785972595215
Validation loss: 2.0478437542915344

Epoch: 5| Step: 9
Training loss: 2.5552306175231934
Validation loss: 2.0476265251636505

Epoch: 5| Step: 10
Training loss: 1.446857213973999
Validation loss: 2.055651550491651

Epoch: 5| Step: 11
Training loss: 1.7303400039672852
Validation loss: 2.056675747036934

Epoch: 154| Step: 0
Training loss: 1.7248432636260986
Validation loss: 2.0441612005233765

Epoch: 5| Step: 1
Training loss: 2.0844192504882812
Validation loss: 2.0487400889396667

Epoch: 5| Step: 2
Training loss: 2.027014970779419
Validation loss: 2.0463276356458664

Epoch: 5| Step: 3
Training loss: 2.396555185317993
Validation loss: 2.0554947356383004

Epoch: 5| Step: 4
Training loss: 1.903296709060669
Validation loss: 2.0557112097740173

Epoch: 5| Step: 5
Training loss: 1.8906952142715454
Validation loss: 2.058846558133761

Epoch: 5| Step: 6
Training loss: 1.8130439519882202
Validation loss: 2.0454329351584115

Epoch: 5| Step: 7
Training loss: 2.4108598232269287
Validation loss: 2.0532498011986413

Epoch: 5| Step: 8
Training loss: 1.9310519695281982
Validation loss: 2.0623965511719384

Epoch: 5| Step: 9
Training loss: 2.3985695838928223
Validation loss: 2.0520979265371957

Epoch: 5| Step: 10
Training loss: 1.8466739654541016
Validation loss: 2.054918110370636

Epoch: 5| Step: 11
Training loss: 1.8712188005447388
Validation loss: 2.0463291058937707

Epoch: 155| Step: 0
Training loss: 1.983453392982483
Validation loss: 2.057365119457245

Epoch: 5| Step: 1
Training loss: 2.4866628646850586
Validation loss: 2.0460103104511895

Epoch: 5| Step: 2
Training loss: 2.9071106910705566
Validation loss: 2.0373649448156357

Epoch: 5| Step: 3
Training loss: 1.831508994102478
Validation loss: 2.0401307890812554

Epoch: 5| Step: 4
Training loss: 1.980966567993164
Validation loss: 2.0460780560970306

Epoch: 5| Step: 5
Training loss: 1.5481219291687012
Validation loss: 2.052508145570755

Epoch: 5| Step: 6
Training loss: 2.229414224624634
Validation loss: 2.0446581294139228

Epoch: 5| Step: 7
Training loss: 2.3343119621276855
Validation loss: 2.052267074584961

Epoch: 5| Step: 8
Training loss: 1.6569652557373047
Validation loss: 2.0435918172200522

Epoch: 5| Step: 9
Training loss: 2.267197847366333
Validation loss: 2.051904171705246

Epoch: 5| Step: 10
Training loss: 1.660801887512207
Validation loss: 2.05024520556132

Epoch: 5| Step: 11
Training loss: 0.2779815196990967
Validation loss: 2.0623461653788886

Epoch: 156| Step: 0
Training loss: 2.4637465476989746
Validation loss: 2.065528223911921

Epoch: 5| Step: 1
Training loss: 1.9000918865203857
Validation loss: 2.0636805593967438

Epoch: 5| Step: 2
Training loss: 2.06318998336792
Validation loss: 2.0594259401162467

Epoch: 5| Step: 3
Training loss: 1.9245656728744507
Validation loss: 2.0620385706424713

Epoch: 5| Step: 4
Training loss: 2.3054163455963135
Validation loss: 2.064653734366099

Epoch: 5| Step: 5
Training loss: 1.783286690711975
Validation loss: 2.0470548321803412

Epoch: 5| Step: 6
Training loss: 2.4854462146759033
Validation loss: 2.059833680589994

Epoch: 5| Step: 7
Training loss: 1.9068365097045898
Validation loss: 2.0618030031522117

Epoch: 5| Step: 8
Training loss: 2.10772442817688
Validation loss: 2.06202199558417

Epoch: 5| Step: 9
Training loss: 1.3076460361480713
Validation loss: 2.053000569343567

Epoch: 5| Step: 10
Training loss: 2.012578010559082
Validation loss: 2.0427818447351456

Epoch: 5| Step: 11
Training loss: 2.3427934646606445
Validation loss: 2.0630099376042685

Epoch: 157| Step: 0
Training loss: 2.3954222202301025
Validation loss: 2.060959761341413

Epoch: 5| Step: 1
Training loss: 1.3181501626968384
Validation loss: 2.0796331812938056

Epoch: 5| Step: 2
Training loss: 2.538443088531494
Validation loss: 2.063388451933861

Epoch: 5| Step: 3
Training loss: 2.1726298332214355
Validation loss: 2.048353999853134

Epoch: 5| Step: 4
Training loss: 2.501812696456909
Validation loss: 2.05166166027387

Epoch: 5| Step: 5
Training loss: 1.67989981174469
Validation loss: 2.052890290816625

Epoch: 5| Step: 6
Training loss: 2.043555498123169
Validation loss: 2.0529950062433877

Epoch: 5| Step: 7
Training loss: 2.1921491622924805
Validation loss: 2.050756807128588

Epoch: 5| Step: 8
Training loss: 1.4109364748001099
Validation loss: 2.0469291508197784

Epoch: 5| Step: 9
Training loss: 1.9204580783843994
Validation loss: 2.0675017684698105

Epoch: 5| Step: 10
Training loss: 2.2802906036376953
Validation loss: 2.0600039263566337

Epoch: 5| Step: 11
Training loss: 1.9759351015090942
Validation loss: 2.056403800845146

Epoch: 158| Step: 0
Training loss: 2.2118098735809326
Validation loss: 2.069344108303388

Epoch: 5| Step: 1
Training loss: 1.6847827434539795
Validation loss: 2.0631062338749566

Epoch: 5| Step: 2
Training loss: 1.7644379138946533
Validation loss: 2.0620776365200677

Epoch: 5| Step: 3
Training loss: 1.9895448684692383
Validation loss: 2.0686875681082406

Epoch: 5| Step: 4
Training loss: 2.182535171508789
Validation loss: 2.0681113253037133

Epoch: 5| Step: 5
Training loss: 1.8662891387939453
Validation loss: 2.0632744630177817

Epoch: 5| Step: 6
Training loss: 2.1405415534973145
Validation loss: 2.06922455628713

Epoch: 5| Step: 7
Training loss: 1.4293816089630127
Validation loss: 2.065146878361702

Epoch: 5| Step: 8
Training loss: 2.938020944595337
Validation loss: 2.0532153099775314

Epoch: 5| Step: 9
Training loss: 1.7926032543182373
Validation loss: 2.05219038327535

Epoch: 5| Step: 10
Training loss: 2.015594005584717
Validation loss: 2.0352275371551514

Epoch: 5| Step: 11
Training loss: 3.273526191711426
Validation loss: 2.0230002949635186

Epoch: 159| Step: 0
Training loss: 1.7435449361801147
Validation loss: 2.026938627163569

Epoch: 5| Step: 1
Training loss: 2.1877987384796143
Validation loss: 2.023405432701111

Epoch: 5| Step: 2
Training loss: 2.1069164276123047
Validation loss: 2.0174449731906257

Epoch: 5| Step: 3
Training loss: 2.257751941680908
Validation loss: 2.021471535166105

Epoch: 5| Step: 4
Training loss: 1.7758877277374268
Validation loss: 2.0304296712080636

Epoch: 5| Step: 5
Training loss: 2.1444687843322754
Validation loss: 2.0256493985652924

Epoch: 5| Step: 6
Training loss: 2.023162364959717
Validation loss: 2.0236543317635856

Epoch: 5| Step: 7
Training loss: 2.4927189350128174
Validation loss: 2.023631662130356

Epoch: 5| Step: 8
Training loss: 1.9749774932861328
Validation loss: 2.026168684164683

Epoch: 5| Step: 9
Training loss: 1.8132822513580322
Validation loss: 2.0293859293063483

Epoch: 5| Step: 10
Training loss: 2.231316328048706
Validation loss: 2.047362431883812

Epoch: 5| Step: 11
Training loss: 3.291717767715454
Validation loss: 2.0592932353417077

Epoch: 160| Step: 0
Training loss: 1.7973695993423462
Validation loss: 2.0673574606577554

Epoch: 5| Step: 1
Training loss: 1.8922998905181885
Validation loss: 2.083732470870018

Epoch: 5| Step: 2
Training loss: 1.9205715656280518
Validation loss: 2.08733406662941

Epoch: 5| Step: 3
Training loss: 2.22943377494812
Validation loss: 2.086883376042048

Epoch: 5| Step: 4
Training loss: 2.435168743133545
Validation loss: 2.088783154884974

Epoch: 5| Step: 5
Training loss: 2.6504290103912354
Validation loss: 2.0927926103274026

Epoch: 5| Step: 6
Training loss: 2.093878984451294
Validation loss: 2.0631538232167563

Epoch: 5| Step: 7
Training loss: 1.4647576808929443
Validation loss: 2.0551923513412476

Epoch: 5| Step: 8
Training loss: 2.249476432800293
Validation loss: 2.0494919617970786

Epoch: 5| Step: 9
Training loss: 1.920650839805603
Validation loss: 2.0511896163225174

Epoch: 5| Step: 10
Training loss: 1.8572721481323242
Validation loss: 2.046493490537008

Epoch: 5| Step: 11
Training loss: 3.058405637741089
Validation loss: 2.0459674298763275

Epoch: 161| Step: 0
Training loss: 2.4031882286071777
Validation loss: 2.046385943889618

Epoch: 5| Step: 1
Training loss: 1.7644870281219482
Validation loss: 2.046124150355657

Epoch: 5| Step: 2
Training loss: 1.8290859460830688
Validation loss: 2.0447319646676383

Epoch: 5| Step: 3
Training loss: 1.788621187210083
Validation loss: 2.044896200299263

Epoch: 5| Step: 4
Training loss: 2.1324515342712402
Validation loss: 2.0384200612703958

Epoch: 5| Step: 5
Training loss: 1.6843359470367432
Validation loss: 2.0542966028054557

Epoch: 5| Step: 6
Training loss: 2.0773935317993164
Validation loss: 2.05886048078537

Epoch: 5| Step: 7
Training loss: 1.9535760879516602
Validation loss: 2.0497039357821145

Epoch: 5| Step: 8
Training loss: 1.8231109380722046
Validation loss: 2.063450038433075

Epoch: 5| Step: 9
Training loss: 2.0273921489715576
Validation loss: 2.070248633623123

Epoch: 5| Step: 10
Training loss: 2.7084155082702637
Validation loss: 2.061624969045321

Epoch: 5| Step: 11
Training loss: 3.1426055431365967
Validation loss: 2.078000028928121

Epoch: 162| Step: 0
Training loss: 2.2127902507781982
Validation loss: 2.085590347647667

Epoch: 5| Step: 1
Training loss: 2.402289390563965
Validation loss: 2.0859166334072747

Epoch: 5| Step: 2
Training loss: 2.063004732131958
Validation loss: 2.0794318119684854

Epoch: 5| Step: 3
Training loss: 2.0710275173187256
Validation loss: 2.0660616805156073

Epoch: 5| Step: 4
Training loss: 2.156691551208496
Validation loss: 2.0610783795515695

Epoch: 5| Step: 5
Training loss: 1.973995566368103
Validation loss: 2.0588553746541343

Epoch: 5| Step: 6
Training loss: 1.827069640159607
Validation loss: 2.064316362142563

Epoch: 5| Step: 7
Training loss: 1.939715027809143
Validation loss: 2.054941092928251

Epoch: 5| Step: 8
Training loss: 2.2096381187438965
Validation loss: 2.0577626327673593

Epoch: 5| Step: 9
Training loss: 1.7742849588394165
Validation loss: 2.0633429487546286

Epoch: 5| Step: 10
Training loss: 2.0947964191436768
Validation loss: 2.072330301006635

Epoch: 5| Step: 11
Training loss: 1.3268063068389893
Validation loss: 2.0765165587266288

Epoch: 163| Step: 0
Training loss: 1.658291220664978
Validation loss: 2.084084317088127

Epoch: 5| Step: 1
Training loss: 2.3116259574890137
Validation loss: 2.100532482067744

Epoch: 5| Step: 2
Training loss: 1.9422998428344727
Validation loss: 2.1042628288269043

Epoch: 5| Step: 3
Training loss: 1.852337121963501
Validation loss: 2.0973168909549713

Epoch: 5| Step: 4
Training loss: 2.3116893768310547
Validation loss: 2.0869625260432563

Epoch: 5| Step: 5
Training loss: 2.239474058151245
Validation loss: 2.0896074374516806

Epoch: 5| Step: 6
Training loss: 2.108276605606079
Validation loss: 2.0677040815353394

Epoch: 5| Step: 7
Training loss: 2.4812331199645996
Validation loss: 2.0696843465169272

Epoch: 5| Step: 8
Training loss: 1.9652044773101807
Validation loss: 2.056788677970568

Epoch: 5| Step: 9
Training loss: 2.1275203227996826
Validation loss: 2.0611441830794015

Epoch: 5| Step: 10
Training loss: 1.500079870223999
Validation loss: 2.05973182618618

Epoch: 5| Step: 11
Training loss: 1.0645320415496826
Validation loss: 2.069840451081594

Epoch: 164| Step: 0
Training loss: 2.0506699085235596
Validation loss: 2.062377000848452

Epoch: 5| Step: 1
Training loss: 2.3029229640960693
Validation loss: 2.060557837287585

Epoch: 5| Step: 2
Training loss: 2.2948436737060547
Validation loss: 2.0831528256336846

Epoch: 5| Step: 3
Training loss: 1.741336464881897
Validation loss: 2.072327102224032

Epoch: 5| Step: 4
Training loss: 2.0797038078308105
Validation loss: 2.0873487343390784

Epoch: 5| Step: 5
Training loss: 2.013002395629883
Validation loss: 2.060683324933052

Epoch: 5| Step: 6
Training loss: 2.304857015609741
Validation loss: 2.0685585786898932

Epoch: 5| Step: 7
Training loss: 2.073441982269287
Validation loss: 2.065882866581281

Epoch: 5| Step: 8
Training loss: 1.7340917587280273
Validation loss: 2.0525237321853638

Epoch: 5| Step: 9
Training loss: 1.679399847984314
Validation loss: 2.0508927553892136

Epoch: 5| Step: 10
Training loss: 2.4456915855407715
Validation loss: 2.056031326452891

Epoch: 5| Step: 11
Training loss: 0.39254462718963623
Validation loss: 2.062497705221176

Epoch: 165| Step: 0
Training loss: 1.7031638622283936
Validation loss: 2.062544271349907

Epoch: 5| Step: 1
Training loss: 1.9311602115631104
Validation loss: 2.085754464070002

Epoch: 5| Step: 2
Training loss: 1.6520570516586304
Validation loss: 2.0778788179159164

Epoch: 5| Step: 3
Training loss: 2.1114039421081543
Validation loss: 2.082566554347674

Epoch: 5| Step: 4
Training loss: 2.372246265411377
Validation loss: 2.080979729692141

Epoch: 5| Step: 5
Training loss: 2.1797566413879395
Validation loss: 2.080930680036545

Epoch: 5| Step: 6
Training loss: 2.096505880355835
Validation loss: 2.070881967743238

Epoch: 5| Step: 7
Training loss: 1.869179129600525
Validation loss: 2.0722440977891288

Epoch: 5| Step: 8
Training loss: 1.639464020729065
Validation loss: 2.061962445576986

Epoch: 5| Step: 9
Training loss: 1.6803295612335205
Validation loss: 2.062294289469719

Epoch: 5| Step: 10
Training loss: 3.0704805850982666
Validation loss: 2.042290916045507

Epoch: 5| Step: 11
Training loss: 2.122107982635498
Validation loss: 2.0528059154748917

Epoch: 166| Step: 0
Training loss: 2.4260709285736084
Validation loss: 2.0644019097089767

Epoch: 5| Step: 1
Training loss: 1.7638542652130127
Validation loss: 2.0574618577957153

Epoch: 5| Step: 2
Training loss: 1.7875592708587646
Validation loss: 2.055385818084081

Epoch: 5| Step: 3
Training loss: 2.5001492500305176
Validation loss: 2.052746598919233

Epoch: 5| Step: 4
Training loss: 1.7438427209854126
Validation loss: 2.067381595571836

Epoch: 5| Step: 5
Training loss: 1.759056806564331
Validation loss: 2.064126506447792

Epoch: 5| Step: 6
Training loss: 2.158407688140869
Validation loss: 2.0657692154248557

Epoch: 5| Step: 7
Training loss: 2.584092617034912
Validation loss: 2.075928976138433

Epoch: 5| Step: 8
Training loss: 2.04268217086792
Validation loss: 2.070473442475001

Epoch: 5| Step: 9
Training loss: 1.9103025197982788
Validation loss: 2.0576671759287515

Epoch: 5| Step: 10
Training loss: 1.6359336376190186
Validation loss: 2.0608929842710495

Epoch: 5| Step: 11
Training loss: 1.381626009941101
Validation loss: 2.0752450227737427

Epoch: 167| Step: 0
Training loss: 1.7122379541397095
Validation loss: 2.0592789302269616

Epoch: 5| Step: 1
Training loss: 2.5928256511688232
Validation loss: 2.0636598269144693

Epoch: 5| Step: 2
Training loss: 2.234619140625
Validation loss: 2.054222827156385

Epoch: 5| Step: 3
Training loss: 1.9989608526229858
Validation loss: 2.0532637536525726

Epoch: 5| Step: 4
Training loss: 2.087697744369507
Validation loss: 2.0564617117245994

Epoch: 5| Step: 5
Training loss: 2.0853333473205566
Validation loss: 2.0552236139774323

Epoch: 5| Step: 6
Training loss: 2.0739846229553223
Validation loss: 2.0676467567682266

Epoch: 5| Step: 7
Training loss: 1.8026783466339111
Validation loss: 2.0526390026013055

Epoch: 5| Step: 8
Training loss: 2.291170597076416
Validation loss: 2.068219011028608

Epoch: 5| Step: 9
Training loss: 1.9779462814331055
Validation loss: 2.0535182307163873

Epoch: 5| Step: 10
Training loss: 1.5098234415054321
Validation loss: 2.0650097131729126

Epoch: 5| Step: 11
Training loss: 1.7478514909744263
Validation loss: 2.0672338157892227

Epoch: 168| Step: 0
Training loss: 2.0887913703918457
Validation loss: 2.0622235238552094

Epoch: 5| Step: 1
Training loss: 2.474442958831787
Validation loss: 2.071595683693886

Epoch: 5| Step: 2
Training loss: 1.7446082830429077
Validation loss: 2.0785946448644004

Epoch: 5| Step: 3
Training loss: 2.7080414295196533
Validation loss: 2.0684925566116967

Epoch: 5| Step: 4
Training loss: 1.8362605571746826
Validation loss: 2.066938723127047

Epoch: 5| Step: 5
Training loss: 1.7809553146362305
Validation loss: 2.0611939380566278

Epoch: 5| Step: 6
Training loss: 2.0649514198303223
Validation loss: 2.0500422616799674

Epoch: 5| Step: 7
Training loss: 2.0088651180267334
Validation loss: 2.054907113313675

Epoch: 5| Step: 8
Training loss: 1.7242482900619507
Validation loss: 2.070802907148997

Epoch: 5| Step: 9
Training loss: 1.9082857370376587
Validation loss: 2.0700928966204324

Epoch: 5| Step: 10
Training loss: 1.9431312084197998
Validation loss: 2.0842373818159103

Epoch: 5| Step: 11
Training loss: 1.8422092199325562
Validation loss: 2.092637225985527

Epoch: 169| Step: 0
Training loss: 2.102022886276245
Validation loss: 2.079414665699005

Epoch: 5| Step: 1
Training loss: 1.501952886581421
Validation loss: 2.083919018507004

Epoch: 5| Step: 2
Training loss: 1.9850174188613892
Validation loss: 2.0620764891306558

Epoch: 5| Step: 3
Training loss: 1.9494991302490234
Validation loss: 2.062419926126798

Epoch: 5| Step: 4
Training loss: 1.4851735830307007
Validation loss: 2.0689553717772164

Epoch: 5| Step: 5
Training loss: 2.2601404190063477
Validation loss: 2.058203270037969

Epoch: 5| Step: 6
Training loss: 2.139303684234619
Validation loss: 2.052448650201162

Epoch: 5| Step: 7
Training loss: 2.2829766273498535
Validation loss: 2.0638185838858285

Epoch: 5| Step: 8
Training loss: 2.4692420959472656
Validation loss: 2.0507535388072333

Epoch: 5| Step: 9
Training loss: 2.1317973136901855
Validation loss: 2.0502940316994986

Epoch: 5| Step: 10
Training loss: 1.9780060052871704
Validation loss: 2.0509704599777856

Epoch: 5| Step: 11
Training loss: 0.9390230774879456
Validation loss: 2.050947606563568

Epoch: 170| Step: 0
Training loss: 1.7978370189666748
Validation loss: 2.0548808028300605

Epoch: 5| Step: 1
Training loss: 2.319049835205078
Validation loss: 2.0582265804211297

Epoch: 5| Step: 2
Training loss: 2.5275213718414307
Validation loss: 2.063758393128713

Epoch: 5| Step: 3
Training loss: 1.6305205821990967
Validation loss: 2.076619878411293

Epoch: 5| Step: 4
Training loss: 1.791608452796936
Validation loss: 2.0756638447443643

Epoch: 5| Step: 5
Training loss: 1.758578896522522
Validation loss: 2.0771397401889167

Epoch: 5| Step: 6
Training loss: 2.0466530323028564
Validation loss: 2.0710375805695853

Epoch: 5| Step: 7
Training loss: 1.8908264636993408
Validation loss: 2.064512401819229

Epoch: 5| Step: 8
Training loss: 2.426305055618286
Validation loss: 2.063620075583458

Epoch: 5| Step: 9
Training loss: 1.6735165119171143
Validation loss: 2.0427229603131614

Epoch: 5| Step: 10
Training loss: 2.248706340789795
Validation loss: 2.0499723901351294

Epoch: 5| Step: 11
Training loss: 2.1047205924987793
Validation loss: 2.0392478307088218

Epoch: 171| Step: 0
Training loss: 2.7423512935638428
Validation loss: 2.0471524596214294

Epoch: 5| Step: 1
Training loss: 1.5096067190170288
Validation loss: 2.0376255214214325

Epoch: 5| Step: 2
Training loss: 1.550169825553894
Validation loss: 2.0434484283129373

Epoch: 5| Step: 3
Training loss: 2.2976062297821045
Validation loss: 2.046496331691742

Epoch: 5| Step: 4
Training loss: 2.1722159385681152
Validation loss: 2.0454683701197305

Epoch: 5| Step: 5
Training loss: 1.716064691543579
Validation loss: 2.043085773785909

Epoch: 5| Step: 6
Training loss: 2.226051092147827
Validation loss: 2.054701939225197

Epoch: 5| Step: 7
Training loss: 2.3834965229034424
Validation loss: 2.053942779699961

Epoch: 5| Step: 8
Training loss: 1.9499439001083374
Validation loss: 2.052098363637924

Epoch: 5| Step: 9
Training loss: 2.01707124710083
Validation loss: 2.0618951519330344

Epoch: 5| Step: 10
Training loss: 1.9963089227676392
Validation loss: 2.0637784401575723

Epoch: 5| Step: 11
Training loss: 2.047194004058838
Validation loss: 2.0648756424585977

Epoch: 172| Step: 0
Training loss: 1.886854887008667
Validation loss: 2.081185147166252

Epoch: 5| Step: 1
Training loss: 2.620400905609131
Validation loss: 2.0820281704266868

Epoch: 5| Step: 2
Training loss: 2.6374051570892334
Validation loss: 2.0733497043450675

Epoch: 5| Step: 3
Training loss: 1.6159422397613525
Validation loss: 2.0713594208161035

Epoch: 5| Step: 4
Training loss: 1.8864505290985107
Validation loss: 2.0642061680555344

Epoch: 5| Step: 5
Training loss: 1.9428074359893799
Validation loss: 2.066365967194239

Epoch: 5| Step: 6
Training loss: 1.877945899963379
Validation loss: 2.0627030730247498

Epoch: 5| Step: 7
Training loss: 1.900822401046753
Validation loss: 2.0720893690983453

Epoch: 5| Step: 8
Training loss: 1.9683700799942017
Validation loss: 2.0497722774744034

Epoch: 5| Step: 9
Training loss: 1.7004127502441406
Validation loss: 2.07420585056146

Epoch: 5| Step: 10
Training loss: 1.787432312965393
Validation loss: 2.059207037091255

Epoch: 5| Step: 11
Training loss: 2.734532356262207
Validation loss: 2.072963679830233

Epoch: 173| Step: 0
Training loss: 1.8534338474273682
Validation loss: 2.0582913359006247

Epoch: 5| Step: 1
Training loss: 2.1097798347473145
Validation loss: 2.064140091339747

Epoch: 5| Step: 2
Training loss: 2.076533555984497
Validation loss: 2.0719850907723107

Epoch: 5| Step: 3
Training loss: 2.7002248764038086
Validation loss: 2.060423493385315

Epoch: 5| Step: 4
Training loss: 2.029745578765869
Validation loss: 2.072689414024353

Epoch: 5| Step: 5
Training loss: 1.6984014511108398
Validation loss: 2.0603713591893515

Epoch: 5| Step: 6
Training loss: 1.9953607320785522
Validation loss: 2.064411982893944

Epoch: 5| Step: 7
Training loss: 1.7167752981185913
Validation loss: 2.05193122724692

Epoch: 5| Step: 8
Training loss: 1.8867660760879517
Validation loss: 2.050941293438276

Epoch: 5| Step: 9
Training loss: 2.308767318725586
Validation loss: 2.055818662047386

Epoch: 5| Step: 10
Training loss: 1.8424571752548218
Validation loss: 2.0467502623796463

Epoch: 5| Step: 11
Training loss: 1.8929316997528076
Validation loss: 2.0577574918667474

Epoch: 174| Step: 0
Training loss: 1.9326517581939697
Validation loss: 2.0708752274513245

Epoch: 5| Step: 1
Training loss: 2.8619885444641113
Validation loss: 2.0869482656319938

Epoch: 5| Step: 2
Training loss: 1.8786576986312866
Validation loss: 2.096483732263247

Epoch: 5| Step: 3
Training loss: 2.325942039489746
Validation loss: 2.1050710876782737

Epoch: 5| Step: 4
Training loss: 2.0066628456115723
Validation loss: 2.091444884737333

Epoch: 5| Step: 5
Training loss: 2.176377773284912
Validation loss: 2.068164676427841

Epoch: 5| Step: 6
Training loss: 2.300112724304199
Validation loss: 2.074090898036957

Epoch: 5| Step: 7
Training loss: 1.6310487985610962
Validation loss: 2.0620980858802795

Epoch: 5| Step: 8
Training loss: 2.0674242973327637
Validation loss: 2.0510544180870056

Epoch: 5| Step: 9
Training loss: 2.087522029876709
Validation loss: 2.0512611915667853

Epoch: 5| Step: 10
Training loss: 1.391608476638794
Validation loss: 2.0574017266432443

Epoch: 5| Step: 11
Training loss: 2.0037407875061035
Validation loss: 2.056107143561045

Epoch: 175| Step: 0
Training loss: 2.260284900665283
Validation loss: 2.0670336137215295

Epoch: 5| Step: 1
Training loss: 1.6419264078140259
Validation loss: 2.0859726617733636

Epoch: 5| Step: 2
Training loss: 2.3545308113098145
Validation loss: 2.0985495845476785

Epoch: 5| Step: 3
Training loss: 1.8700577020645142
Validation loss: 2.117326319217682

Epoch: 5| Step: 4
Training loss: 1.7534748315811157
Validation loss: 2.134473145008087

Epoch: 5| Step: 5
Training loss: 2.1945221424102783
Validation loss: 2.1349081645409265

Epoch: 5| Step: 6
Training loss: 2.288072109222412
Validation loss: 2.127466013034185

Epoch: 5| Step: 7
Training loss: 1.994062066078186
Validation loss: 2.0821192959944406

Epoch: 5| Step: 8
Training loss: 1.9130971431732178
Validation loss: 2.081214110056559

Epoch: 5| Step: 9
Training loss: 1.7588716745376587
Validation loss: 2.051491290330887

Epoch: 5| Step: 10
Training loss: 2.2321040630340576
Validation loss: 2.049433837334315

Epoch: 5| Step: 11
Training loss: 2.5320606231689453
Validation loss: 2.0458944539229074

Epoch: 176| Step: 0
Training loss: 2.2503445148468018
Validation loss: 2.037824804584185

Epoch: 5| Step: 1
Training loss: 2.821840286254883
Validation loss: 2.044605632623037

Epoch: 5| Step: 2
Training loss: 1.7793270349502563
Validation loss: 2.0427250067392984

Epoch: 5| Step: 3
Training loss: 1.9147535562515259
Validation loss: 2.0444605896870294

Epoch: 5| Step: 4
Training loss: 1.7412891387939453
Validation loss: 2.0389427791039147

Epoch: 5| Step: 5
Training loss: 2.1583614349365234
Validation loss: 2.0500329782565436

Epoch: 5| Step: 6
Training loss: 2.45477294921875
Validation loss: 2.0452883193890252

Epoch: 5| Step: 7
Training loss: 2.475454092025757
Validation loss: 2.05867275595665

Epoch: 5| Step: 8
Training loss: 1.900177240371704
Validation loss: 2.0472200214862823

Epoch: 5| Step: 9
Training loss: 1.8132413625717163
Validation loss: 2.050011952718099

Epoch: 5| Step: 10
Training loss: 1.6050631999969482
Validation loss: 2.0623871088027954

Epoch: 5| Step: 11
Training loss: 1.0910465717315674
Validation loss: 2.0560268809398017

Epoch: 177| Step: 0
Training loss: 1.9714053869247437
Validation loss: 2.083172102769216

Epoch: 5| Step: 1
Training loss: 2.3745617866516113
Validation loss: 2.0984085500240326

Epoch: 5| Step: 2
Training loss: 2.5997531414031982
Validation loss: 2.1075588514407477

Epoch: 5| Step: 3
Training loss: 2.003969430923462
Validation loss: 2.097914551695188

Epoch: 5| Step: 4
Training loss: 2.085099220275879
Validation loss: 2.1048130244016647

Epoch: 5| Step: 5
Training loss: 1.5516866445541382
Validation loss: 2.113937238852183

Epoch: 5| Step: 6
Training loss: 1.9064958095550537
Validation loss: 2.0993024657169976

Epoch: 5| Step: 7
Training loss: 1.882655382156372
Validation loss: 2.0822495768467584

Epoch: 5| Step: 8
Training loss: 1.942845344543457
Validation loss: 2.087406595547994

Epoch: 5| Step: 9
Training loss: 2.0154480934143066
Validation loss: 2.0684137046337128

Epoch: 5| Step: 10
Training loss: 2.0710487365722656
Validation loss: 2.0661504367987313

Epoch: 5| Step: 11
Training loss: 2.190959930419922
Validation loss: 2.0711464136838913

Epoch: 178| Step: 0
Training loss: 1.7824885845184326
Validation loss: 2.0554580887158713

Epoch: 5| Step: 1
Training loss: 2.2098004817962646
Validation loss: 2.060188482205073

Epoch: 5| Step: 2
Training loss: 1.6883904933929443
Validation loss: 2.077548250555992

Epoch: 5| Step: 3
Training loss: 1.9669983386993408
Validation loss: 2.057875394821167

Epoch: 5| Step: 4
Training loss: 2.289731025695801
Validation loss: 2.058495153983434

Epoch: 5| Step: 5
Training loss: 2.252711057662964
Validation loss: 2.055345137914022

Epoch: 5| Step: 6
Training loss: 1.982417106628418
Validation loss: 2.0609337786833444

Epoch: 5| Step: 7
Training loss: 2.2734529972076416
Validation loss: 2.0570949415365853

Epoch: 5| Step: 8
Training loss: 1.9760239124298096
Validation loss: 2.070616672436396

Epoch: 5| Step: 9
Training loss: 2.0720419883728027
Validation loss: 2.069885720809301

Epoch: 5| Step: 10
Training loss: 1.435286521911621
Validation loss: 2.0748098641633987

Epoch: 5| Step: 11
Training loss: 1.8066376447677612
Validation loss: 2.0744332720836005

Epoch: 179| Step: 0
Training loss: 1.388768196105957
Validation loss: 2.078822831312815

Epoch: 5| Step: 1
Training loss: 1.8085527420043945
Validation loss: 2.086294104655584

Epoch: 5| Step: 2
Training loss: 1.8120750188827515
Validation loss: 2.078633174300194

Epoch: 5| Step: 3
Training loss: 2.06354022026062
Validation loss: 2.071019937594732

Epoch: 5| Step: 4
Training loss: 2.561495065689087
Validation loss: 2.0519853035608926

Epoch: 5| Step: 5
Training loss: 1.8384497165679932
Validation loss: 2.0563745498657227

Epoch: 5| Step: 6
Training loss: 1.8570743799209595
Validation loss: 2.0558920005957284

Epoch: 5| Step: 7
Training loss: 2.1617496013641357
Validation loss: 2.056920737028122

Epoch: 5| Step: 8
Training loss: 2.511289596557617
Validation loss: 2.0526591390371323

Epoch: 5| Step: 9
Training loss: 2.1252055168151855
Validation loss: 2.053052340944608

Epoch: 5| Step: 10
Training loss: 2.3101983070373535
Validation loss: 2.0570891201496124

Epoch: 5| Step: 11
Training loss: 1.5999703407287598
Validation loss: 2.0490276217460632

Epoch: 180| Step: 0
Training loss: 1.965245246887207
Validation loss: 2.0534268667300544

Epoch: 5| Step: 1
Training loss: 1.8960342407226562
Validation loss: 2.0536322444677353

Epoch: 5| Step: 2
Training loss: 2.2380573749542236
Validation loss: 2.060023933649063

Epoch: 5| Step: 3
Training loss: 1.6097532510757446
Validation loss: 2.0654419660568237

Epoch: 5| Step: 4
Training loss: 2.2386717796325684
Validation loss: 2.081249554951986

Epoch: 5| Step: 5
Training loss: 1.8295406103134155
Validation loss: 2.0896879583597183

Epoch: 5| Step: 6
Training loss: 2.181652784347534
Validation loss: 2.098236938317617

Epoch: 5| Step: 7
Training loss: 2.2110700607299805
Validation loss: 2.103229080637296

Epoch: 5| Step: 8
Training loss: 2.4179584980010986
Validation loss: 2.0875225315491357

Epoch: 5| Step: 9
Training loss: 1.7485615015029907
Validation loss: 2.0991412301858268

Epoch: 5| Step: 10
Training loss: 1.7926199436187744
Validation loss: 2.0921761294205985

Epoch: 5| Step: 11
Training loss: 3.709437847137451
Validation loss: 2.0984155436356864

Epoch: 181| Step: 0
Training loss: 2.564065456390381
Validation loss: 2.098330944776535

Epoch: 5| Step: 1
Training loss: 2.193000078201294
Validation loss: 2.079299529393514

Epoch: 5| Step: 2
Training loss: 2.0433542728424072
Validation loss: 2.061531806985537

Epoch: 5| Step: 3
Training loss: 2.016507863998413
Validation loss: 2.047984406352043

Epoch: 5| Step: 4
Training loss: 2.089115619659424
Validation loss: 2.0504650125900903

Epoch: 5| Step: 5
Training loss: 1.419439673423767
Validation loss: 2.0556268642346063

Epoch: 5| Step: 6
Training loss: 2.1191537380218506
Validation loss: 2.061534951130549

Epoch: 5| Step: 7
Training loss: 2.109185218811035
Validation loss: 2.0545814037323

Epoch: 5| Step: 8
Training loss: 1.579034447669983
Validation loss: 2.048947582642237

Epoch: 5| Step: 9
Training loss: 1.90581476688385
Validation loss: 2.0531542052825293

Epoch: 5| Step: 10
Training loss: 2.1744332313537598
Validation loss: 2.055300439397494

Epoch: 5| Step: 11
Training loss: 1.7384040355682373
Validation loss: 2.0619963506857553

Epoch: 182| Step: 0
Training loss: 1.9964574575424194
Validation loss: 2.0564246575037637

Epoch: 5| Step: 1
Training loss: 2.511864423751831
Validation loss: 2.069636419415474

Epoch: 5| Step: 2
Training loss: 1.502406120300293
Validation loss: 2.0748342921336493

Epoch: 5| Step: 3
Training loss: 2.24763822555542
Validation loss: 2.064025695125262

Epoch: 5| Step: 4
Training loss: 1.9818718433380127
Validation loss: 2.074585974216461

Epoch: 5| Step: 5
Training loss: 1.7984797954559326
Validation loss: 2.0761234760284424

Epoch: 5| Step: 6
Training loss: 2.0975451469421387
Validation loss: 2.0825798710187278

Epoch: 5| Step: 7
Training loss: 1.9166532754898071
Validation loss: 2.087119440237681

Epoch: 5| Step: 8
Training loss: 2.265781879425049
Validation loss: 2.0872347255547843

Epoch: 5| Step: 9
Training loss: 1.7820720672607422
Validation loss: 2.086282104253769

Epoch: 5| Step: 10
Training loss: 1.9863803386688232
Validation loss: 2.0844635665416718

Epoch: 5| Step: 11
Training loss: 1.4565343856811523
Validation loss: 2.081147571404775

Epoch: 183| Step: 0
Training loss: 1.608616590499878
Validation loss: 2.0661988208691278

Epoch: 5| Step: 1
Training loss: 1.6614192724227905
Validation loss: 2.0656992892424264

Epoch: 5| Step: 2
Training loss: 2.3483879566192627
Validation loss: 2.052198032538096

Epoch: 5| Step: 3
Training loss: 2.2814862728118896
Validation loss: 2.051598017414411

Epoch: 5| Step: 4
Training loss: 2.270155906677246
Validation loss: 2.0562934825817742

Epoch: 5| Step: 5
Training loss: 2.0774435997009277
Validation loss: 2.05864380300045

Epoch: 5| Step: 6
Training loss: 1.9592796564102173
Validation loss: 2.051598365108172

Epoch: 5| Step: 7
Training loss: 1.9986398220062256
Validation loss: 2.0591441492239633

Epoch: 5| Step: 8
Training loss: 2.022841215133667
Validation loss: 2.0587296237548194

Epoch: 5| Step: 9
Training loss: 1.6002649068832397
Validation loss: 2.0615828533967337

Epoch: 5| Step: 10
Training loss: 2.4140350818634033
Validation loss: 2.0558378100395203

Epoch: 5| Step: 11
Training loss: 1.1386668682098389
Validation loss: 2.0685280909140906

Epoch: 184| Step: 0
Training loss: 2.291970729827881
Validation loss: 2.0751459499200187

Epoch: 5| Step: 1
Training loss: 2.134342670440674
Validation loss: 2.098121926188469

Epoch: 5| Step: 2
Training loss: 1.9854167699813843
Validation loss: 2.105944370230039

Epoch: 5| Step: 3
Training loss: 2.3222274780273438
Validation loss: 2.1146605710188546

Epoch: 5| Step: 4
Training loss: 2.017324924468994
Validation loss: 2.1111065248648324

Epoch: 5| Step: 5
Training loss: 1.6053664684295654
Validation loss: 2.11303640405337

Epoch: 5| Step: 6
Training loss: 2.266861915588379
Validation loss: 2.1239130844672522

Epoch: 5| Step: 7
Training loss: 2.1092636585235596
Validation loss: 2.1246242026487985

Epoch: 5| Step: 8
Training loss: 2.0546138286590576
Validation loss: 2.1186438649892807

Epoch: 5| Step: 9
Training loss: 1.5275962352752686
Validation loss: 2.11892298857371

Epoch: 5| Step: 10
Training loss: 1.6785469055175781
Validation loss: 2.094143182039261

Epoch: 5| Step: 11
Training loss: 1.3451584577560425
Validation loss: 2.099816312392553

Epoch: 185| Step: 0
Training loss: 2.287583589553833
Validation loss: 2.0977910260359445

Epoch: 5| Step: 1
Training loss: 1.8430168628692627
Validation loss: 2.098121076822281

Epoch: 5| Step: 2
Training loss: 2.547598361968994
Validation loss: 2.1073565085728965

Epoch: 5| Step: 3
Training loss: 2.128955364227295
Validation loss: 2.100339541832606

Epoch: 5| Step: 4
Training loss: 1.8003036975860596
Validation loss: 2.1066236346960068

Epoch: 5| Step: 5
Training loss: 2.503206491470337
Validation loss: 2.097755213578542

Epoch: 5| Step: 6
Training loss: 2.2495436668395996
Validation loss: 2.091335972150167

Epoch: 5| Step: 7
Training loss: 1.4773668050765991
Validation loss: 2.0875150511662164

Epoch: 5| Step: 8
Training loss: 1.7334810495376587
Validation loss: 2.097500572601954

Epoch: 5| Step: 9
Training loss: 1.6339874267578125
Validation loss: 2.096248279015223

Epoch: 5| Step: 10
Training loss: 1.5336006879806519
Validation loss: 2.0857067853212357

Epoch: 5| Step: 11
Training loss: 1.8145828247070312
Validation loss: 2.091130942106247

Epoch: 186| Step: 0
Training loss: 2.269700527191162
Validation loss: 2.0816129744052887

Epoch: 5| Step: 1
Training loss: 2.279282808303833
Validation loss: 2.0736161321401596

Epoch: 5| Step: 2
Training loss: 1.7530075311660767
Validation loss: 2.0724236319462457

Epoch: 5| Step: 3
Training loss: 1.8112480640411377
Validation loss: 2.0663363933563232

Epoch: 5| Step: 4
Training loss: 1.992314100265503
Validation loss: 2.062338630358378

Epoch: 5| Step: 5
Training loss: 2.148113250732422
Validation loss: 2.0610074947277703

Epoch: 5| Step: 6
Training loss: 2.147728681564331
Validation loss: 2.0733985900878906

Epoch: 5| Step: 7
Training loss: 1.8486827611923218
Validation loss: 2.074329599738121

Epoch: 5| Step: 8
Training loss: 1.7160764932632446
Validation loss: 2.0706460624933243

Epoch: 5| Step: 9
Training loss: 1.612775444984436
Validation loss: 2.081459179520607

Epoch: 5| Step: 10
Training loss: 2.202305793762207
Validation loss: 2.0971909761428833

Epoch: 5| Step: 11
Training loss: 3.0349793434143066
Validation loss: 2.0903484225273132

Epoch: 187| Step: 0
Training loss: 2.0911753177642822
Validation loss: 2.0886484583218894

Epoch: 5| Step: 1
Training loss: 2.455099105834961
Validation loss: 2.0876519779364267

Epoch: 5| Step: 2
Training loss: 1.8062652349472046
Validation loss: 2.080615242322286

Epoch: 5| Step: 3
Training loss: 1.3746849298477173
Validation loss: 2.085980072617531

Epoch: 5| Step: 4
Training loss: 1.953974962234497
Validation loss: 2.0843553940455117

Epoch: 5| Step: 5
Training loss: 1.8214218616485596
Validation loss: 2.0661593228578568

Epoch: 5| Step: 6
Training loss: 1.7622677087783813
Validation loss: 2.074378728866577

Epoch: 5| Step: 7
Training loss: 2.096153736114502
Validation loss: 2.058922201395035

Epoch: 5| Step: 8
Training loss: 2.178628444671631
Validation loss: 2.0695239702860513

Epoch: 5| Step: 9
Training loss: 2.008253335952759
Validation loss: 2.067847947279612

Epoch: 5| Step: 10
Training loss: 2.1838390827178955
Validation loss: 2.06166073679924

Epoch: 5| Step: 11
Training loss: 3.045940637588501
Validation loss: 2.0794601837793985

Epoch: 188| Step: 0
Training loss: 2.6500682830810547
Validation loss: 2.072962378462156

Epoch: 5| Step: 1
Training loss: 1.8582632541656494
Validation loss: 2.079955463608106

Epoch: 5| Step: 2
Training loss: 1.7730153799057007
Validation loss: 2.110209117333094

Epoch: 5| Step: 3
Training loss: 2.081698417663574
Validation loss: 2.101474126180013

Epoch: 5| Step: 4
Training loss: 1.6266257762908936
Validation loss: 2.09724268813928

Epoch: 5| Step: 5
Training loss: 2.4051544666290283
Validation loss: 2.0921361645062766

Epoch: 5| Step: 6
Training loss: 1.5261075496673584
Validation loss: 2.092245658238729

Epoch: 5| Step: 7
Training loss: 2.0069680213928223
Validation loss: 2.096366986632347

Epoch: 5| Step: 8
Training loss: 2.2501087188720703
Validation loss: 2.077974403897921

Epoch: 5| Step: 9
Training loss: 1.6961148977279663
Validation loss: 2.0916263858477273

Epoch: 5| Step: 10
Training loss: 2.0047459602355957
Validation loss: 2.0802778402964273

Epoch: 5| Step: 11
Training loss: 1.8850020170211792
Validation loss: 2.0622769445180893

Epoch: 189| Step: 0
Training loss: 2.3322463035583496
Validation loss: 2.069139381249746

Epoch: 5| Step: 1
Training loss: 1.6280266046524048
Validation loss: 2.060893793900808

Epoch: 5| Step: 2
Training loss: 1.9826580286026
Validation loss: 2.052802547812462

Epoch: 5| Step: 3
Training loss: 1.9362709522247314
Validation loss: 2.06548318763574

Epoch: 5| Step: 4
Training loss: 2.175246477127075
Validation loss: 2.065732002258301

Epoch: 5| Step: 5
Training loss: 2.026505947113037
Validation loss: 2.0690555423498154

Epoch: 5| Step: 6
Training loss: 2.29836368560791
Validation loss: 2.0637145737806954

Epoch: 5| Step: 7
Training loss: 1.5182920694351196
Validation loss: 2.0427304953336716

Epoch: 5| Step: 8
Training loss: 1.9089853763580322
Validation loss: 2.0697034001350403

Epoch: 5| Step: 9
Training loss: 1.8053200244903564
Validation loss: 2.0616886913776398

Epoch: 5| Step: 10
Training loss: 2.2659573554992676
Validation loss: 2.07192063331604

Epoch: 5| Step: 11
Training loss: 2.4208714962005615
Validation loss: 2.077605495850245

Epoch: 190| Step: 0
Training loss: 2.2866597175598145
Validation loss: 2.073008343577385

Epoch: 5| Step: 1
Training loss: 1.325134038925171
Validation loss: 2.063024342060089

Epoch: 5| Step: 2
Training loss: 1.8221657276153564
Validation loss: 2.077480932076772

Epoch: 5| Step: 3
Training loss: 2.0957446098327637
Validation loss: 2.0681139479080834

Epoch: 5| Step: 4
Training loss: 2.028754949569702
Validation loss: 2.058517580231031

Epoch: 5| Step: 5
Training loss: 2.0152366161346436
Validation loss: 2.0595325281222663

Epoch: 5| Step: 6
Training loss: 1.9280027151107788
Validation loss: 2.0680362979571023

Epoch: 5| Step: 7
Training loss: 1.9887298345565796
Validation loss: 2.0686287383238473

Epoch: 5| Step: 8
Training loss: 2.4021565914154053
Validation loss: 2.081559325257937

Epoch: 5| Step: 9
Training loss: 2.0041089057922363
Validation loss: 2.0991160770257316

Epoch: 5| Step: 10
Training loss: 1.9341976642608643
Validation loss: 2.1024883637825647

Epoch: 5| Step: 11
Training loss: 2.5880188941955566
Validation loss: 2.1109661857287088

Epoch: 191| Step: 0
Training loss: 1.6221870183944702
Validation loss: 2.1074769844611487

Epoch: 5| Step: 1
Training loss: 2.254812717437744
Validation loss: 2.1050754388173423

Epoch: 5| Step: 2
Training loss: 1.6677051782608032
Validation loss: 2.1146610379219055

Epoch: 5| Step: 3
Training loss: 2.3663601875305176
Validation loss: 2.1189297636349997

Epoch: 5| Step: 4
Training loss: 1.2695014476776123
Validation loss: 2.1108772655328116

Epoch: 5| Step: 5
Training loss: 2.4916229248046875
Validation loss: 2.1197063326835632

Epoch: 5| Step: 6
Training loss: 2.163454532623291
Validation loss: 2.0833347688118615

Epoch: 5| Step: 7
Training loss: 1.5655791759490967
Validation loss: 2.086856002608935

Epoch: 5| Step: 8
Training loss: 1.7515137195587158
Validation loss: 2.0884588807821274

Epoch: 5| Step: 9
Training loss: 2.1306400299072266
Validation loss: 2.0739171653985977

Epoch: 5| Step: 10
Training loss: 2.616804599761963
Validation loss: 2.086934452255567

Epoch: 5| Step: 11
Training loss: 0.7098178863525391
Validation loss: 2.076506028572718

Epoch: 192| Step: 0
Training loss: 2.116117000579834
Validation loss: 2.0836274822553

Epoch: 5| Step: 1
Training loss: 2.282627582550049
Validation loss: 2.0922566652297974

Epoch: 5| Step: 2
Training loss: 2.3292860984802246
Validation loss: 2.0796206494172416

Epoch: 5| Step: 3
Training loss: 2.096966028213501
Validation loss: 2.0886801729599633

Epoch: 5| Step: 4
Training loss: 1.91891610622406
Validation loss: 2.0926210085550943

Epoch: 5| Step: 5
Training loss: 1.3883157968521118
Validation loss: 2.1147749622662864

Epoch: 5| Step: 6
Training loss: 1.7237192392349243
Validation loss: 2.091816266377767

Epoch: 5| Step: 7
Training loss: 2.372849941253662
Validation loss: 2.092041557033857

Epoch: 5| Step: 8
Training loss: 1.6031434535980225
Validation loss: 2.1012755632400513

Epoch: 5| Step: 9
Training loss: 1.6593677997589111
Validation loss: 2.0877771774927774

Epoch: 5| Step: 10
Training loss: 2.084789991378784
Validation loss: 2.0896019488573074

Epoch: 5| Step: 11
Training loss: 2.070723533630371
Validation loss: 2.098495587706566

Epoch: 193| Step: 0
Training loss: 1.550706148147583
Validation loss: 2.0760018875201545

Epoch: 5| Step: 1
Training loss: 1.7308334112167358
Validation loss: 2.0732277929782867

Epoch: 5| Step: 2
Training loss: 2.02577805519104
Validation loss: 2.060290366411209

Epoch: 5| Step: 3
Training loss: 2.087235927581787
Validation loss: 2.062577337026596

Epoch: 5| Step: 4
Training loss: 1.9425901174545288
Validation loss: 2.062781348824501

Epoch: 5| Step: 5
Training loss: 1.9813849925994873
Validation loss: 2.065683742364248

Epoch: 5| Step: 6
Training loss: 3.0081329345703125
Validation loss: 2.0587600072224936

Epoch: 5| Step: 7
Training loss: 1.8735415935516357
Validation loss: 2.06811460852623

Epoch: 5| Step: 8
Training loss: 1.820906400680542
Validation loss: 2.0649092346429825

Epoch: 5| Step: 9
Training loss: 1.897970199584961
Validation loss: 2.069055363535881

Epoch: 5| Step: 10
Training loss: 2.500002145767212
Validation loss: 2.0784128109614053

Epoch: 5| Step: 11
Training loss: 1.363025426864624
Validation loss: 2.0948672890663147

Epoch: 194| Step: 0
Training loss: 2.413778066635132
Validation loss: 2.1184093058109283

Epoch: 5| Step: 1
Training loss: 1.9203859567642212
Validation loss: 2.130829786260923

Epoch: 5| Step: 2
Training loss: 1.9906492233276367
Validation loss: 2.1372750103473663

Epoch: 5| Step: 3
Training loss: 2.6966583728790283
Validation loss: 2.1338550498088202

Epoch: 5| Step: 4
Training loss: 2.0852558612823486
Validation loss: 2.1262020617723465

Epoch: 5| Step: 5
Training loss: 1.4865167140960693
Validation loss: 2.125529537598292

Epoch: 5| Step: 6
Training loss: 2.5660433769226074
Validation loss: 2.1067789793014526

Epoch: 5| Step: 7
Training loss: 2.0379834175109863
Validation loss: 2.0804125567277274

Epoch: 5| Step: 8
Training loss: 1.7537791728973389
Validation loss: 2.099802017211914

Epoch: 5| Step: 9
Training loss: 1.997897744178772
Validation loss: 2.1030389964580536

Epoch: 5| Step: 10
Training loss: 1.8173272609710693
Validation loss: 2.0990785658359528

Epoch: 5| Step: 11
Training loss: 1.012465238571167
Validation loss: 2.0649265348911285

Epoch: 195| Step: 0
Training loss: 1.6197888851165771
Validation loss: 2.063356493910154

Epoch: 5| Step: 1
Training loss: 2.4721689224243164
Validation loss: 2.056847463051478

Epoch: 5| Step: 2
Training loss: 2.519611358642578
Validation loss: 2.065001909931501

Epoch: 5| Step: 3
Training loss: 1.8150007724761963
Validation loss: 2.0605833729108176

Epoch: 5| Step: 4
Training loss: 2.4857192039489746
Validation loss: 2.052226016918818

Epoch: 5| Step: 5
Training loss: 1.9129565954208374
Validation loss: 2.050535569588343

Epoch: 5| Step: 6
Training loss: 2.099113941192627
Validation loss: 2.0515299240748086

Epoch: 5| Step: 7
Training loss: 1.9113008975982666
Validation loss: 2.050194799900055

Epoch: 5| Step: 8
Training loss: 2.2993712425231934
Validation loss: 2.0551889489094415

Epoch: 5| Step: 9
Training loss: 1.3909090757369995
Validation loss: 2.0565508802731833

Epoch: 5| Step: 10
Training loss: 2.080488920211792
Validation loss: 2.060277904073397

Epoch: 5| Step: 11
Training loss: 1.997207760810852
Validation loss: 2.076433743039767

Epoch: 196| Step: 0
Training loss: 1.9220346212387085
Validation loss: 2.0677579094966254

Epoch: 5| Step: 1
Training loss: 1.9329935312271118
Validation loss: 2.071896215279897

Epoch: 5| Step: 2
Training loss: 2.096860647201538
Validation loss: 2.0689565589030585

Epoch: 5| Step: 3
Training loss: 1.9078242778778076
Validation loss: 2.0764488776524863

Epoch: 5| Step: 4
Training loss: 2.2233588695526123
Validation loss: 2.0812802960475287

Epoch: 5| Step: 5
Training loss: 1.6069570779800415
Validation loss: 2.0817819138367972

Epoch: 5| Step: 6
Training loss: 2.069634199142456
Validation loss: 2.0800723830858865

Epoch: 5| Step: 7
Training loss: 2.4289214611053467
Validation loss: 2.0703569104274115

Epoch: 5| Step: 8
Training loss: 1.999444603919983
Validation loss: 2.0936596989631653

Epoch: 5| Step: 9
Training loss: 1.9202903509140015
Validation loss: 2.0914051632086434

Epoch: 5| Step: 10
Training loss: 2.0660736560821533
Validation loss: 2.083769902586937

Epoch: 5| Step: 11
Training loss: 1.4521830081939697
Validation loss: 2.0825508882602057

Epoch: 197| Step: 0
Training loss: 1.6094913482666016
Validation loss: 2.0796228299538293

Epoch: 5| Step: 1
Training loss: 1.7870327234268188
Validation loss: 2.0765405346949897

Epoch: 5| Step: 2
Training loss: 1.7479757070541382
Validation loss: 2.0692256093025208

Epoch: 5| Step: 3
Training loss: 2.0151607990264893
Validation loss: 2.069718877474467

Epoch: 5| Step: 4
Training loss: 2.422574043273926
Validation loss: 2.067683512965838

Epoch: 5| Step: 5
Training loss: 2.359179735183716
Validation loss: 2.0719527701536813

Epoch: 5| Step: 6
Training loss: 2.0759198665618896
Validation loss: 2.085829476515452

Epoch: 5| Step: 7
Training loss: 2.1950647830963135
Validation loss: 2.069959526260694

Epoch: 5| Step: 8
Training loss: 1.5465540885925293
Validation loss: 2.0760072767734528

Epoch: 5| Step: 9
Training loss: 1.9663622379302979
Validation loss: 2.0783578157424927

Epoch: 5| Step: 10
Training loss: 2.1887497901916504
Validation loss: 2.069630409280459

Epoch: 5| Step: 11
Training loss: 2.198955535888672
Validation loss: 2.08391926685969

Epoch: 198| Step: 0
Training loss: 2.3747172355651855
Validation loss: 2.0825536449750266

Epoch: 5| Step: 1
Training loss: 1.9268077611923218
Validation loss: 2.090812007586161

Epoch: 5| Step: 2
Training loss: 1.9172083139419556
Validation loss: 2.1071550150712333

Epoch: 5| Step: 3
Training loss: 2.2456085681915283
Validation loss: 2.0917495290438333

Epoch: 5| Step: 4
Training loss: 2.004307746887207
Validation loss: 2.106594810883204

Epoch: 5| Step: 5
Training loss: 2.5039565563201904
Validation loss: 2.1085167725880942

Epoch: 5| Step: 6
Training loss: 2.4705286026000977
Validation loss: 2.0969905306895575

Epoch: 5| Step: 7
Training loss: 1.607755422592163
Validation loss: 2.107519507408142

Epoch: 5| Step: 8
Training loss: 1.4775382280349731
Validation loss: 2.0913808147112527

Epoch: 5| Step: 9
Training loss: 1.63234543800354
Validation loss: 2.0898743718862534

Epoch: 5| Step: 10
Training loss: 1.8145427703857422
Validation loss: 2.0893306334813437

Epoch: 5| Step: 11
Training loss: 1.4734218120574951
Validation loss: 2.094541092713674

Epoch: 199| Step: 0
Training loss: 2.58567476272583
Validation loss: 2.087640797098478

Epoch: 5| Step: 1
Training loss: 1.7575448751449585
Validation loss: 2.089815596739451

Epoch: 5| Step: 2
Training loss: 2.23907208442688
Validation loss: 2.0846655567487082

Epoch: 5| Step: 3
Training loss: 1.0064523220062256
Validation loss: 2.0830274720986686

Epoch: 5| Step: 4
Training loss: 1.9028384685516357
Validation loss: 2.088463475306829

Epoch: 5| Step: 5
Training loss: 2.042672634124756
Validation loss: 2.1117062071959176

Epoch: 5| Step: 6
Training loss: 2.000478744506836
Validation loss: 2.085454652706782

Epoch: 5| Step: 7
Training loss: 2.1600780487060547
Validation loss: 2.097753788034121

Epoch: 5| Step: 8
Training loss: 1.7730286121368408
Validation loss: 2.096469516555468

Epoch: 5| Step: 9
Training loss: 1.7685436010360718
Validation loss: 2.0999198059240975

Epoch: 5| Step: 10
Training loss: 2.3119165897369385
Validation loss: 2.0903680274883905

Epoch: 5| Step: 11
Training loss: 2.978503704071045
Validation loss: 2.095585803190867

Epoch: 200| Step: 0
Training loss: 2.1584670543670654
Validation loss: 2.089694634079933

Epoch: 5| Step: 1
Training loss: 2.151444673538208
Validation loss: 2.11218923330307

Epoch: 5| Step: 2
Training loss: 2.1773064136505127
Validation loss: 2.0810654312372208

Epoch: 5| Step: 3
Training loss: 1.8219016790390015
Validation loss: 2.081957866748174

Epoch: 5| Step: 4
Training loss: 1.9658806324005127
Validation loss: 2.0870808959007263

Epoch: 5| Step: 5
Training loss: 1.4985226392745972
Validation loss: 2.091857741276423

Epoch: 5| Step: 6
Training loss: 2.154186964035034
Validation loss: 2.095842053492864

Epoch: 5| Step: 7
Training loss: 1.7074817419052124
Validation loss: 2.099160467584928

Epoch: 5| Step: 8
Training loss: 2.243908405303955
Validation loss: 2.0928892393906913

Epoch: 5| Step: 9
Training loss: 1.9124072790145874
Validation loss: 2.1103019267320633

Epoch: 5| Step: 10
Training loss: 1.7543971538543701
Validation loss: 2.101561516523361

Epoch: 5| Step: 11
Training loss: 2.3374195098876953
Validation loss: 2.102491776148478

Epoch: 201| Step: 0
Training loss: 1.5416055917739868
Validation loss: 2.089687615633011

Epoch: 5| Step: 1
Training loss: 1.6851342916488647
Validation loss: 2.0888991405566535

Epoch: 5| Step: 2
Training loss: 2.7532520294189453
Validation loss: 2.084276189406713

Epoch: 5| Step: 3
Training loss: 1.9209661483764648
Validation loss: 2.0721692691246667

Epoch: 5| Step: 4
Training loss: 1.4586220979690552
Validation loss: 2.070255140463511

Epoch: 5| Step: 5
Training loss: 2.3068935871124268
Validation loss: 2.075246344010035

Epoch: 5| Step: 6
Training loss: 2.199763536453247
Validation loss: 2.068809762597084

Epoch: 5| Step: 7
Training loss: 2.0955851078033447
Validation loss: 2.082044005393982

Epoch: 5| Step: 8
Training loss: 2.0174174308776855
Validation loss: 2.085048312942187

Epoch: 5| Step: 9
Training loss: 1.7844173908233643
Validation loss: 2.0785637895266214

Epoch: 5| Step: 10
Training loss: 1.9299644231796265
Validation loss: 2.0771459341049194

Epoch: 5| Step: 11
Training loss: 2.031496524810791
Validation loss: 2.074690322081248

Epoch: 202| Step: 0
Training loss: 2.204033374786377
Validation loss: 2.115349292755127

Epoch: 5| Step: 1
Training loss: 2.1711056232452393
Validation loss: 2.1655688484509787

Epoch: 5| Step: 2
Training loss: 2.8395214080810547
Validation loss: 2.187171846628189

Epoch: 5| Step: 3
Training loss: 2.015455722808838
Validation loss: 2.186057925224304

Epoch: 5| Step: 4
Training loss: 2.0351099967956543
Validation loss: 2.1846983830134072

Epoch: 5| Step: 5
Training loss: 1.4668035507202148
Validation loss: 2.1725091536839805

Epoch: 5| Step: 6
Training loss: 2.1110031604766846
Validation loss: 2.1348743736743927

Epoch: 5| Step: 7
Training loss: 1.6885719299316406
Validation loss: 2.140195886294047

Epoch: 5| Step: 8
Training loss: 2.4530444145202637
Validation loss: 2.119141325354576

Epoch: 5| Step: 9
Training loss: 1.401332139968872
Validation loss: 2.087359368801117

Epoch: 5| Step: 10
Training loss: 2.0550665855407715
Validation loss: 2.0868745297193527

Epoch: 5| Step: 11
Training loss: 1.8018462657928467
Validation loss: 2.092290833592415

Epoch: 203| Step: 0
Training loss: 1.645825982093811
Validation loss: 2.0857461194197335

Epoch: 5| Step: 1
Training loss: 1.9726650714874268
Validation loss: 2.087544788916906

Epoch: 5| Step: 2
Training loss: 1.879355788230896
Validation loss: 2.071671575307846

Epoch: 5| Step: 3
Training loss: 2.2465391159057617
Validation loss: 2.0844322741031647

Epoch: 5| Step: 4
Training loss: 1.7381420135498047
Validation loss: 2.0826189865668616

Epoch: 5| Step: 5
Training loss: 2.1633644104003906
Validation loss: 2.100017155210177

Epoch: 5| Step: 6
Training loss: 2.078345537185669
Validation loss: 2.1099785616000495

Epoch: 5| Step: 7
Training loss: 2.0849242210388184
Validation loss: 2.1237700829903283

Epoch: 5| Step: 8
Training loss: 1.532106637954712
Validation loss: 2.138577848672867

Epoch: 5| Step: 9
Training loss: 2.085265636444092
Validation loss: 2.1282649586598077

Epoch: 5| Step: 10
Training loss: 2.1978626251220703
Validation loss: 2.1422682205835977

Epoch: 5| Step: 11
Training loss: 1.570422887802124
Validation loss: 2.1231880436340966

Epoch: 204| Step: 0
Training loss: 1.4724637269973755
Validation loss: 2.122620329260826

Epoch: 5| Step: 1
Training loss: 2.4447147846221924
Validation loss: 2.1131070653597512

Epoch: 5| Step: 2
Training loss: 2.3272364139556885
Validation loss: 2.10364160935084

Epoch: 5| Step: 3
Training loss: 1.6115649938583374
Validation loss: 2.108910784125328

Epoch: 5| Step: 4
Training loss: 2.1379776000976562
Validation loss: 2.0764940629402795

Epoch: 5| Step: 5
Training loss: 1.7944858074188232
Validation loss: 2.0881768812735877

Epoch: 5| Step: 6
Training loss: 1.8044408559799194
Validation loss: 2.0884034583965936

Epoch: 5| Step: 7
Training loss: 2.163611888885498
Validation loss: 2.0816324055194855

Epoch: 5| Step: 8
Training loss: 1.928858757019043
Validation loss: 2.0911983797947564

Epoch: 5| Step: 9
Training loss: 2.5557861328125
Validation loss: 2.1003888001044593

Epoch: 5| Step: 10
Training loss: 1.4224932193756104
Validation loss: 2.1024162818988166

Epoch: 5| Step: 11
Training loss: 2.0207698345184326
Validation loss: 2.1159812659025192

Epoch: 205| Step: 0
Training loss: 1.7158132791519165
Validation loss: 2.115173409382502

Epoch: 5| Step: 1
Training loss: 2.162914752960205
Validation loss: 2.1071541408697763

Epoch: 5| Step: 2
Training loss: 2.4933643341064453
Validation loss: 2.1177031646172204

Epoch: 5| Step: 3
Training loss: 1.5856653451919556
Validation loss: 2.103822782635689

Epoch: 5| Step: 4
Training loss: 1.8262245655059814
Validation loss: 2.1092378546794257

Epoch: 5| Step: 5
Training loss: 1.7221949100494385
Validation loss: 2.09310045838356

Epoch: 5| Step: 6
Training loss: 2.0243403911590576
Validation loss: 2.096930851538976

Epoch: 5| Step: 7
Training loss: 1.363364815711975
Validation loss: 2.0858540634314218

Epoch: 5| Step: 8
Training loss: 2.212183952331543
Validation loss: 2.099476089080175

Epoch: 5| Step: 9
Training loss: 2.1081533432006836
Validation loss: 2.0906968812147775

Epoch: 5| Step: 10
Training loss: 2.3223233222961426
Validation loss: 2.088322346409162

Epoch: 5| Step: 11
Training loss: 1.867924690246582
Validation loss: 2.0843130399783454

Epoch: 206| Step: 0
Training loss: 2.2160744667053223
Validation loss: 2.085900694131851

Epoch: 5| Step: 1
Training loss: 2.1628875732421875
Validation loss: 2.083964546521505

Epoch: 5| Step: 2
Training loss: 2.227635383605957
Validation loss: 2.080890119075775

Epoch: 5| Step: 3
Training loss: 1.8046443462371826
Validation loss: 2.0680916905403137

Epoch: 5| Step: 4
Training loss: 1.7117936611175537
Validation loss: 2.088256766398748

Epoch: 5| Step: 5
Training loss: 2.467935800552368
Validation loss: 2.0904100984334946

Epoch: 5| Step: 6
Training loss: 1.510250449180603
Validation loss: 2.108533948659897

Epoch: 5| Step: 7
Training loss: 1.5064024925231934
Validation loss: 2.112416923046112

Epoch: 5| Step: 8
Training loss: 1.9914966821670532
Validation loss: 2.1067254741986594

Epoch: 5| Step: 9
Training loss: 1.9180114269256592
Validation loss: 2.0950267910957336

Epoch: 5| Step: 10
Training loss: 2.1154046058654785
Validation loss: 2.0846279859542847

Epoch: 5| Step: 11
Training loss: 2.797466278076172
Validation loss: 2.0782602479060492

Epoch: 207| Step: 0
Training loss: 1.862239122390747
Validation loss: 2.077313393354416

Epoch: 5| Step: 1
Training loss: 1.6188068389892578
Validation loss: 2.067274118463198

Epoch: 5| Step: 2
Training loss: 2.0057713985443115
Validation loss: 2.0667162239551544

Epoch: 5| Step: 3
Training loss: 2.3927316665649414
Validation loss: 2.063500682512919

Epoch: 5| Step: 4
Training loss: 2.624973773956299
Validation loss: 2.0649536103010178

Epoch: 5| Step: 5
Training loss: 2.2853636741638184
Validation loss: 2.073111186424891

Epoch: 5| Step: 6
Training loss: 2.258349895477295
Validation loss: 2.0765557338794074

Epoch: 5| Step: 7
Training loss: 1.6562340259552002
Validation loss: 2.066564048329989

Epoch: 5| Step: 8
Training loss: 1.9946047067642212
Validation loss: 2.092056925098101

Epoch: 5| Step: 9
Training loss: 1.5755635499954224
Validation loss: 2.095175340771675

Epoch: 5| Step: 10
Training loss: 1.6392652988433838
Validation loss: 2.0818758507569632

Epoch: 5| Step: 11
Training loss: 1.4481267929077148
Validation loss: 2.1220856656630835

Epoch: 208| Step: 0
Training loss: 2.2958004474639893
Validation loss: 2.117114245891571

Epoch: 5| Step: 1
Training loss: 2.0465710163116455
Validation loss: 2.1157336086034775

Epoch: 5| Step: 2
Training loss: 2.3489301204681396
Validation loss: 2.1086856524149575

Epoch: 5| Step: 3
Training loss: 1.7753498554229736
Validation loss: 2.1234483222166696

Epoch: 5| Step: 4
Training loss: 1.679072380065918
Validation loss: 2.1081959853569665

Epoch: 5| Step: 5
Training loss: 2.245711326599121
Validation loss: 2.1085919439792633

Epoch: 5| Step: 6
Training loss: 1.5446782112121582
Validation loss: 2.116093561053276

Epoch: 5| Step: 7
Training loss: 2.1908349990844727
Validation loss: 2.1059729953606925

Epoch: 5| Step: 8
Training loss: 1.6918751001358032
Validation loss: 2.0859322349230447

Epoch: 5| Step: 9
Training loss: 1.923898696899414
Validation loss: 2.096511642138163

Epoch: 5| Step: 10
Training loss: 2.0779807567596436
Validation loss: 2.0896832893292108

Epoch: 5| Step: 11
Training loss: 0.8765994310379028
Validation loss: 2.1105132599671683

Epoch: 209| Step: 0
Training loss: 2.120105028152466
Validation loss: 2.125639925400416

Epoch: 5| Step: 1
Training loss: 2.0725936889648438
Validation loss: 2.125573088725408

Epoch: 5| Step: 2
Training loss: 2.1237030029296875
Validation loss: 2.149790793657303

Epoch: 5| Step: 3
Training loss: 2.1273305416107178
Validation loss: 2.15034843981266

Epoch: 5| Step: 4
Training loss: 2.2795639038085938
Validation loss: 2.154667148987452

Epoch: 5| Step: 5
Training loss: 1.8362880945205688
Validation loss: 2.1438106695810952

Epoch: 5| Step: 6
Training loss: 1.9352775812149048
Validation loss: 2.1372410356998444

Epoch: 5| Step: 7
Training loss: 1.7259876728057861
Validation loss: 2.1326094518105188

Epoch: 5| Step: 8
Training loss: 2.274876594543457
Validation loss: 2.133619954188665

Epoch: 5| Step: 9
Training loss: 1.4015566110610962
Validation loss: 2.113323653737704

Epoch: 5| Step: 10
Training loss: 1.6642272472381592
Validation loss: 2.1154066721598306

Epoch: 5| Step: 11
Training loss: 2.534421920776367
Validation loss: 2.1166134625673294

Epoch: 210| Step: 0
Training loss: 2.0978922843933105
Validation loss: 2.1018253515164056

Epoch: 5| Step: 1
Training loss: 2.057406425476074
Validation loss: 2.098758563399315

Epoch: 5| Step: 2
Training loss: 1.9622423648834229
Validation loss: 2.0874145328998566

Epoch: 5| Step: 3
Training loss: 1.7938945293426514
Validation loss: 2.099117582043012

Epoch: 5| Step: 4
Training loss: 1.5670173168182373
Validation loss: 2.0977045943339667

Epoch: 5| Step: 5
Training loss: 2.272408962249756
Validation loss: 2.104941243926684

Epoch: 5| Step: 6
Training loss: 2.4407005310058594
Validation loss: 2.105781043569247

Epoch: 5| Step: 7
Training loss: 2.02028751373291
Validation loss: 2.1328844328721366

Epoch: 5| Step: 8
Training loss: 1.7669093608856201
Validation loss: 2.1186256060997644

Epoch: 5| Step: 9
Training loss: 1.8550646305084229
Validation loss: 2.117206573486328

Epoch: 5| Step: 10
Training loss: 1.5179955959320068
Validation loss: 2.1234405835469565

Epoch: 5| Step: 11
Training loss: 1.6288187503814697
Validation loss: 2.1453756193319955

Epoch: 211| Step: 0
Training loss: 2.2182059288024902
Validation loss: 2.126519630352656

Epoch: 5| Step: 1
Training loss: 2.131934881210327
Validation loss: 2.137866293390592

Epoch: 5| Step: 2
Training loss: 1.8491899967193604
Validation loss: 2.133566662669182

Epoch: 5| Step: 3
Training loss: 1.2524092197418213
Validation loss: 2.1092794289191565

Epoch: 5| Step: 4
Training loss: 2.02351713180542
Validation loss: 2.1250492135683694

Epoch: 5| Step: 5
Training loss: 2.1559224128723145
Validation loss: 2.096551979581515

Epoch: 5| Step: 6
Training loss: 1.9796924591064453
Validation loss: 2.1083958198626838

Epoch: 5| Step: 7
Training loss: 2.052417755126953
Validation loss: 2.094904661178589

Epoch: 5| Step: 8
Training loss: 2.449965715408325
Validation loss: 2.0934065828720727

Epoch: 5| Step: 9
Training loss: 1.4729969501495361
Validation loss: 2.101035177707672

Epoch: 5| Step: 10
Training loss: 1.7531410455703735
Validation loss: 2.100068047642708

Epoch: 5| Step: 11
Training loss: 1.1298222541809082
Validation loss: 2.0879931499560676

Epoch: 212| Step: 0
Training loss: 1.769836664199829
Validation loss: 2.0961098770300546

Epoch: 5| Step: 1
Training loss: 1.800305724143982
Validation loss: 2.088007171948751

Epoch: 5| Step: 2
Training loss: 1.564536213874817
Validation loss: 2.1052507907152176

Epoch: 5| Step: 3
Training loss: 2.347442388534546
Validation loss: 2.1018336017926535

Epoch: 5| Step: 4
Training loss: 1.7404088973999023
Validation loss: 2.1320195893446603

Epoch: 5| Step: 5
Training loss: 2.1025803089141846
Validation loss: 2.1134596864382424

Epoch: 5| Step: 6
Training loss: 1.5592224597930908
Validation loss: 2.142803450425466

Epoch: 5| Step: 7
Training loss: 1.9915844202041626
Validation loss: 2.136234020193418

Epoch: 5| Step: 8
Training loss: 2.0338990688323975
Validation loss: 2.1201614141464233

Epoch: 5| Step: 9
Training loss: 1.5217578411102295
Validation loss: 2.1287377874056497

Epoch: 5| Step: 10
Training loss: 2.7199249267578125
Validation loss: 2.1265328526496887

Epoch: 5| Step: 11
Training loss: 3.016718626022339
Validation loss: 2.132222210367521

Epoch: 213| Step: 0
Training loss: 2.0355308055877686
Validation loss: 2.1303247114022574

Epoch: 5| Step: 1
Training loss: 1.642897605895996
Validation loss: 2.120496983329455

Epoch: 5| Step: 2
Training loss: 2.2901833057403564
Validation loss: 2.123988305528959

Epoch: 5| Step: 3
Training loss: 1.9169422388076782
Validation loss: 2.1264963299036026

Epoch: 5| Step: 4
Training loss: 2.1778366565704346
Validation loss: 2.120897094408671

Epoch: 5| Step: 5
Training loss: 1.9585027694702148
Validation loss: 2.122522165377935

Epoch: 5| Step: 6
Training loss: 1.8401601314544678
Validation loss: 2.107222686211268

Epoch: 5| Step: 7
Training loss: 2.0351779460906982
Validation loss: 2.1298616230487823

Epoch: 5| Step: 8
Training loss: 1.814414381980896
Validation loss: 2.110123574733734

Epoch: 5| Step: 9
Training loss: 1.8908191919326782
Validation loss: 2.1229893416166306

Epoch: 5| Step: 10
Training loss: 1.6886017322540283
Validation loss: 2.108362247546514

Epoch: 5| Step: 11
Training loss: 2.0193796157836914
Validation loss: 2.1261976808309555

Epoch: 214| Step: 0
Training loss: 2.448976993560791
Validation loss: 2.131785199046135

Epoch: 5| Step: 1
Training loss: 2.232130527496338
Validation loss: 2.1446164647738137

Epoch: 5| Step: 2
Training loss: 1.7373650074005127
Validation loss: 2.133809963862101

Epoch: 5| Step: 3
Training loss: 1.651746392250061
Validation loss: 2.121772269407908

Epoch: 5| Step: 4
Training loss: 1.501936435699463
Validation loss: 2.130538687109947

Epoch: 5| Step: 5
Training loss: 2.000704288482666
Validation loss: 2.112670054038366

Epoch: 5| Step: 6
Training loss: 1.7682815790176392
Validation loss: 2.124321848154068

Epoch: 5| Step: 7
Training loss: 1.948473334312439
Validation loss: 2.1146992246309915

Epoch: 5| Step: 8
Training loss: 2.047877550125122
Validation loss: 2.143335059285164

Epoch: 5| Step: 9
Training loss: 1.8027362823486328
Validation loss: 2.132755825916926

Epoch: 5| Step: 10
Training loss: 2.2372891902923584
Validation loss: 2.151011968652407

Epoch: 5| Step: 11
Training loss: 1.4027979373931885
Validation loss: 2.124457448720932

Epoch: 215| Step: 0
Training loss: 1.476231336593628
Validation loss: 2.127987508972486

Epoch: 5| Step: 1
Training loss: 1.7120662927627563
Validation loss: 2.1120992402235665

Epoch: 5| Step: 2
Training loss: 2.322366714477539
Validation loss: 2.098468472560247

Epoch: 5| Step: 3
Training loss: 2.039233684539795
Validation loss: 2.1025604705015817

Epoch: 5| Step: 4
Training loss: 2.194838285446167
Validation loss: 2.1028900345166526

Epoch: 5| Step: 5
Training loss: 2.0892767906188965
Validation loss: 2.1258718222379684

Epoch: 5| Step: 6
Training loss: 1.837273359298706
Validation loss: 2.1150417178869247

Epoch: 5| Step: 7
Training loss: 1.576734185218811
Validation loss: 2.123615155617396

Epoch: 5| Step: 8
Training loss: 2.057326078414917
Validation loss: 2.1181628356377282

Epoch: 5| Step: 9
Training loss: 1.9245471954345703
Validation loss: 2.1336149275302887

Epoch: 5| Step: 10
Training loss: 2.3189921379089355
Validation loss: 2.1347422301769257

Epoch: 5| Step: 11
Training loss: 0.9369429349899292
Validation loss: 2.137858663996061

Epoch: 216| Step: 0
Training loss: 1.8391307592391968
Validation loss: 2.127386917670568

Epoch: 5| Step: 1
Training loss: 2.648314952850342
Validation loss: 2.157418121894201

Epoch: 5| Step: 2
Training loss: 1.9310309886932373
Validation loss: 2.1725917557875314

Epoch: 5| Step: 3
Training loss: 2.0865588188171387
Validation loss: 2.182364602883657

Epoch: 5| Step: 4
Training loss: 1.9207592010498047
Validation loss: 2.1722990572452545

Epoch: 5| Step: 5
Training loss: 2.24908709526062
Validation loss: 2.1531986693541207

Epoch: 5| Step: 6
Training loss: 1.5968806743621826
Validation loss: 2.11426243185997

Epoch: 5| Step: 7
Training loss: 1.5118590593338013
Validation loss: 2.1164859731992087

Epoch: 5| Step: 8
Training loss: 1.9997106790542603
Validation loss: 2.1110917876164117

Epoch: 5| Step: 9
Training loss: 1.8963861465454102
Validation loss: 2.106803372502327

Epoch: 5| Step: 10
Training loss: 1.7702544927597046
Validation loss: 2.100852151711782

Epoch: 5| Step: 11
Training loss: 1.8862625360488892
Validation loss: 2.1272940436999

Epoch: 217| Step: 0
Training loss: 1.6652019023895264
Validation loss: 2.136637727419535

Epoch: 5| Step: 1
Training loss: 2.0158164501190186
Validation loss: 2.150824954112371

Epoch: 5| Step: 2
Training loss: 1.8512986898422241
Validation loss: 2.138941213488579

Epoch: 5| Step: 3
Training loss: 1.6968746185302734
Validation loss: 2.1492838064829507

Epoch: 5| Step: 4
Training loss: 2.353318691253662
Validation loss: 2.1550441086292267

Epoch: 5| Step: 5
Training loss: 1.9233452081680298
Validation loss: 2.1429354349772134

Epoch: 5| Step: 6
Training loss: 1.5266615152359009
Validation loss: 2.146405503153801

Epoch: 5| Step: 7
Training loss: 2.7268662452697754
Validation loss: 2.132997011144956

Epoch: 5| Step: 8
Training loss: 2.1954236030578613
Validation loss: 2.1358045438925424

Epoch: 5| Step: 9
Training loss: 2.2370495796203613
Validation loss: 2.1644715468088784

Epoch: 5| Step: 10
Training loss: 1.2437595129013062
Validation loss: 2.144907370209694

Epoch: 5| Step: 11
Training loss: 1.3576478958129883
Validation loss: 2.1520972549915314

Epoch: 218| Step: 0
Training loss: 1.4586538076400757
Validation loss: 2.1481304615736008

Epoch: 5| Step: 1
Training loss: 2.093052387237549
Validation loss: 2.1415355702241263

Epoch: 5| Step: 2
Training loss: 2.2428348064422607
Validation loss: 2.1513991951942444

Epoch: 5| Step: 3
Training loss: 2.3683042526245117
Validation loss: 2.1565735737482705

Epoch: 5| Step: 4
Training loss: 1.9166761636734009
Validation loss: 2.148273160060247

Epoch: 5| Step: 5
Training loss: 1.5498985052108765
Validation loss: 2.1396593352158866

Epoch: 5| Step: 6
Training loss: 2.0619893074035645
Validation loss: 2.1076156000296273

Epoch: 5| Step: 7
Training loss: 1.9146897792816162
Validation loss: 2.1050542692343392

Epoch: 5| Step: 8
Training loss: 1.4829095602035522
Validation loss: 2.090023006002108

Epoch: 5| Step: 9
Training loss: 1.7752892971038818
Validation loss: 2.100108260909716

Epoch: 5| Step: 10
Training loss: 2.2748658657073975
Validation loss: 2.1128255327542624

Epoch: 5| Step: 11
Training loss: 2.387166976928711
Validation loss: 2.0977849115928016

Epoch: 219| Step: 0
Training loss: 1.9024642705917358
Validation loss: 2.091570481657982

Epoch: 5| Step: 1
Training loss: 2.229296922683716
Validation loss: 2.0917840003967285

Epoch: 5| Step: 2
Training loss: 1.6440136432647705
Validation loss: 2.0948259284098945

Epoch: 5| Step: 3
Training loss: 2.2774758338928223
Validation loss: 2.116897761821747

Epoch: 5| Step: 4
Training loss: 1.7413240671157837
Validation loss: 2.1183432241280875

Epoch: 5| Step: 5
Training loss: 1.4024564027786255
Validation loss: 2.1359391609827676

Epoch: 5| Step: 6
Training loss: 2.147993326187134
Validation loss: 2.135125016172727

Epoch: 5| Step: 7
Training loss: 2.383786201477051
Validation loss: 2.1455799688895545

Epoch: 5| Step: 8
Training loss: 2.1651549339294434
Validation loss: 2.142497311035792

Epoch: 5| Step: 9
Training loss: 2.008826732635498
Validation loss: 2.1533071597417197

Epoch: 5| Step: 10
Training loss: 1.6647822856903076
Validation loss: 2.1391753405332565

Epoch: 5| Step: 11
Training loss: 0.9903243780136108
Validation loss: 2.1336022218068442

Epoch: 220| Step: 0
Training loss: 1.8351871967315674
Validation loss: 2.141524742046992

Epoch: 5| Step: 1
Training loss: 1.7358131408691406
Validation loss: 2.146746610601743

Epoch: 5| Step: 2
Training loss: 1.745216727256775
Validation loss: 2.148940255244573

Epoch: 5| Step: 3
Training loss: 2.159459114074707
Validation loss: 2.1387079656124115

Epoch: 5| Step: 4
Training loss: 2.1916003227233887
Validation loss: 2.1190036684274673

Epoch: 5| Step: 5
Training loss: 1.8074941635131836
Validation loss: 2.1039511462052665

Epoch: 5| Step: 6
Training loss: 1.8427703380584717
Validation loss: 2.1167595982551575

Epoch: 5| Step: 7
Training loss: 1.5617525577545166
Validation loss: 2.1206797709067664

Epoch: 5| Step: 8
Training loss: 2.0499427318573
Validation loss: 2.1072388291358948

Epoch: 5| Step: 9
Training loss: 2.202850818634033
Validation loss: 2.0917091220617294

Epoch: 5| Step: 10
Training loss: 2.1930935382843018
Validation loss: 2.100233127673467

Epoch: 5| Step: 11
Training loss: 0.5253857970237732
Validation loss: 2.10953480998675

Epoch: 221| Step: 0
Training loss: 2.102008104324341
Validation loss: 2.114603266119957

Epoch: 5| Step: 1
Training loss: 2.293562889099121
Validation loss: 2.0995334138472876

Epoch: 5| Step: 2
Training loss: 1.423472285270691
Validation loss: 2.1147760152816772

Epoch: 5| Step: 3
Training loss: 1.7928260564804077
Validation loss: 2.1280804624160132

Epoch: 5| Step: 4
Training loss: 2.3737082481384277
Validation loss: 2.13606296479702

Epoch: 5| Step: 5
Training loss: 1.3939826488494873
Validation loss: 2.125103692213694

Epoch: 5| Step: 6
Training loss: 1.7616841793060303
Validation loss: 2.1320472955703735

Epoch: 5| Step: 7
Training loss: 2.1930718421936035
Validation loss: 2.1339331567287445

Epoch: 5| Step: 8
Training loss: 1.8062912225723267
Validation loss: 2.1377527316411338

Epoch: 5| Step: 9
Training loss: 2.005518674850464
Validation loss: 2.1269004344940186

Epoch: 5| Step: 10
Training loss: 1.8966783285140991
Validation loss: 2.1237074186404548

Epoch: 5| Step: 11
Training loss: 1.4161314964294434
Validation loss: 2.126804212729136

Epoch: 222| Step: 0
Training loss: 1.72678542137146
Validation loss: 2.125893001755079

Epoch: 5| Step: 1
Training loss: 2.189624309539795
Validation loss: 2.1288611690203347

Epoch: 5| Step: 2
Training loss: 1.5809208154678345
Validation loss: 2.1456680297851562

Epoch: 5| Step: 3
Training loss: 2.2013332843780518
Validation loss: 2.1499223113059998

Epoch: 5| Step: 4
Training loss: 2.107332706451416
Validation loss: 2.162083918849627

Epoch: 5| Step: 5
Training loss: 1.932939887046814
Validation loss: 2.1355716486771903

Epoch: 5| Step: 6
Training loss: 1.5565341711044312
Validation loss: 2.114241063594818

Epoch: 5| Step: 7
Training loss: 1.990739107131958
Validation loss: 2.130738765001297

Epoch: 5| Step: 8
Training loss: 1.937294363975525
Validation loss: 2.1386414964993796

Epoch: 5| Step: 9
Training loss: 1.9391753673553467
Validation loss: 2.146313945452372

Epoch: 5| Step: 10
Training loss: 2.019057273864746
Validation loss: 2.1140713542699814

Epoch: 5| Step: 11
Training loss: 0.9815329909324646
Validation loss: 2.122238760193189

Epoch: 223| Step: 0
Training loss: 1.6731328964233398
Validation loss: 2.118853732943535

Epoch: 5| Step: 1
Training loss: 1.9655964374542236
Validation loss: 2.103157033522924

Epoch: 5| Step: 2
Training loss: 1.6457974910736084
Validation loss: 2.1026061475276947

Epoch: 5| Step: 3
Training loss: 2.1495137214660645
Validation loss: 2.1090915302435556

Epoch: 5| Step: 4
Training loss: 2.430877447128296
Validation loss: 2.1134469360113144

Epoch: 5| Step: 5
Training loss: 1.7108697891235352
Validation loss: 2.1125571678082147

Epoch: 5| Step: 6
Training loss: 1.978432297706604
Validation loss: 2.1148135562737784

Epoch: 5| Step: 7
Training loss: 1.6949189901351929
Validation loss: 2.111471563577652

Epoch: 5| Step: 8
Training loss: 1.4928486347198486
Validation loss: 2.113652100165685

Epoch: 5| Step: 9
Training loss: 2.4319732189178467
Validation loss: 2.1182278593381247

Epoch: 5| Step: 10
Training loss: 1.6748253107070923
Validation loss: 2.120828777551651

Epoch: 5| Step: 11
Training loss: 2.6006646156311035
Validation loss: 2.1285802672306695

Epoch: 224| Step: 0
Training loss: 2.1292965412139893
Validation loss: 2.116444577773412

Epoch: 5| Step: 1
Training loss: 1.6389586925506592
Validation loss: 2.133293221394221

Epoch: 5| Step: 2
Training loss: 1.792490005493164
Validation loss: 2.144710356990496

Epoch: 5| Step: 3
Training loss: 1.6880508661270142
Validation loss: 2.144178772966067

Epoch: 5| Step: 4
Training loss: 2.1816792488098145
Validation loss: 2.132267733414968

Epoch: 5| Step: 5
Training loss: 2.2361197471618652
Validation loss: 2.1552566637595496

Epoch: 5| Step: 6
Training loss: 1.9945310354232788
Validation loss: 2.1213225622971854

Epoch: 5| Step: 7
Training loss: 1.6151241064071655
Validation loss: 2.1345226168632507

Epoch: 5| Step: 8
Training loss: 1.6548553705215454
Validation loss: 2.119772652784983

Epoch: 5| Step: 9
Training loss: 1.6498773097991943
Validation loss: 2.1070686827103295

Epoch: 5| Step: 10
Training loss: 2.494771957397461
Validation loss: 2.1048429161310196

Epoch: 5| Step: 11
Training loss: 1.9435677528381348
Validation loss: 2.1102611819903054

Epoch: 225| Step: 0
Training loss: 2.4752235412597656
Validation loss: 2.117528264721235

Epoch: 5| Step: 1
Training loss: 2.0970206260681152
Validation loss: 2.1410667995611825

Epoch: 5| Step: 2
Training loss: 1.5304973125457764
Validation loss: 2.12786133090655

Epoch: 5| Step: 3
Training loss: 2.1145427227020264
Validation loss: 2.156425187985102

Epoch: 5| Step: 4
Training loss: 1.8314635753631592
Validation loss: 2.146391913294792

Epoch: 5| Step: 5
Training loss: 1.4030137062072754
Validation loss: 2.149500608444214

Epoch: 5| Step: 6
Training loss: 2.1969006061553955
Validation loss: 2.1546866446733475

Epoch: 5| Step: 7
Training loss: 1.555355191230774
Validation loss: 2.124669849872589

Epoch: 5| Step: 8
Training loss: 1.9051300287246704
Validation loss: 2.144512509306272

Epoch: 5| Step: 9
Training loss: 1.8536876440048218
Validation loss: 2.135122170050939

Epoch: 5| Step: 10
Training loss: 1.9760735034942627
Validation loss: 2.132474089662234

Epoch: 5| Step: 11
Training loss: 2.0572714805603027
Validation loss: 2.108113999168078

Epoch: 226| Step: 0
Training loss: 2.2199721336364746
Validation loss: 2.1041329006354013

Epoch: 5| Step: 1
Training loss: 1.7027604579925537
Validation loss: 2.0919027626514435

Epoch: 5| Step: 2
Training loss: 1.9796262979507446
Validation loss: 2.093485032518705

Epoch: 5| Step: 3
Training loss: 1.525290846824646
Validation loss: 2.101018870870272

Epoch: 5| Step: 4
Training loss: 1.9310948848724365
Validation loss: 2.113921935359637

Epoch: 5| Step: 5
Training loss: 2.163423538208008
Validation loss: 2.1252836187680564

Epoch: 5| Step: 6
Training loss: 2.327296495437622
Validation loss: 2.144604762395223

Epoch: 5| Step: 7
Training loss: 1.4367940425872803
Validation loss: 2.1563926885525384

Epoch: 5| Step: 8
Training loss: 2.4625627994537354
Validation loss: 2.1613386621077857

Epoch: 5| Step: 9
Training loss: 1.720987319946289
Validation loss: 2.1820406715075173

Epoch: 5| Step: 10
Training loss: 1.7901198863983154
Validation loss: 2.1584461331367493

Epoch: 5| Step: 11
Training loss: 2.887239456176758
Validation loss: 2.156716972589493

Epoch: 227| Step: 0
Training loss: 1.5211360454559326
Validation loss: 2.1607562005519867

Epoch: 5| Step: 1
Training loss: 2.035299777984619
Validation loss: 2.1467788914839425

Epoch: 5| Step: 2
Training loss: 1.9022254943847656
Validation loss: 2.1527838508288064

Epoch: 5| Step: 3
Training loss: 2.0988192558288574
Validation loss: 2.1234979728857675

Epoch: 5| Step: 4
Training loss: 1.866263747215271
Validation loss: 2.1098269522190094

Epoch: 5| Step: 5
Training loss: 2.054683208465576
Validation loss: 2.1203766564528146

Epoch: 5| Step: 6
Training loss: 1.8314836025238037
Validation loss: 2.122865160306295

Epoch: 5| Step: 7
Training loss: 1.7600562572479248
Validation loss: 2.1200767954190574

Epoch: 5| Step: 8
Training loss: 2.300679922103882
Validation loss: 2.1188061833381653

Epoch: 5| Step: 9
Training loss: 1.8323742151260376
Validation loss: 2.1230968882640204

Epoch: 5| Step: 10
Training loss: 1.6292238235473633
Validation loss: 2.1381208300590515

Epoch: 5| Step: 11
Training loss: 2.316828727722168
Validation loss: 2.1263491908709207

Epoch: 228| Step: 0
Training loss: 1.803689956665039
Validation loss: 2.1546084135770798

Epoch: 5| Step: 1
Training loss: 2.1694226264953613
Validation loss: 2.164924611647924

Epoch: 5| Step: 2
Training loss: 1.7858810424804688
Validation loss: 2.186280697584152

Epoch: 5| Step: 3
Training loss: 1.8000319004058838
Validation loss: 2.175424953301748

Epoch: 5| Step: 4
Training loss: 2.014784097671509
Validation loss: 2.164991612235705

Epoch: 5| Step: 5
Training loss: 2.534862756729126
Validation loss: 2.1650062104066214

Epoch: 5| Step: 6
Training loss: 1.7173799276351929
Validation loss: 2.1654999405145645

Epoch: 5| Step: 7
Training loss: 2.056924343109131
Validation loss: 2.1499152382214866

Epoch: 5| Step: 8
Training loss: 1.4298012256622314
Validation loss: 2.1208296616872153

Epoch: 5| Step: 9
Training loss: 1.2880537509918213
Validation loss: 2.110349883635839

Epoch: 5| Step: 10
Training loss: 2.380981206893921
Validation loss: 2.114254350463549

Epoch: 5| Step: 11
Training loss: 2.7395987510681152
Validation loss: 2.1047885368267694

Epoch: 229| Step: 0
Training loss: 2.3664188385009766
Validation loss: 2.098664551973343

Epoch: 5| Step: 1
Training loss: 2.289163112640381
Validation loss: 2.090545246998469

Epoch: 5| Step: 2
Training loss: 1.8598909378051758
Validation loss: 2.0968128542105355

Epoch: 5| Step: 3
Training loss: 2.3961009979248047
Validation loss: 2.0835752487182617

Epoch: 5| Step: 4
Training loss: 1.863364815711975
Validation loss: 2.0961792270342507

Epoch: 5| Step: 5
Training loss: 1.6100457906723022
Validation loss: 2.099100708961487

Epoch: 5| Step: 6
Training loss: 1.5392632484436035
Validation loss: 2.1318290879329047

Epoch: 5| Step: 7
Training loss: 1.6219942569732666
Validation loss: 2.1448879490296044

Epoch: 5| Step: 8
Training loss: 2.0102243423461914
Validation loss: 2.167473077774048

Epoch: 5| Step: 9
Training loss: 1.8302456140518188
Validation loss: 2.1588122298320136

Epoch: 5| Step: 10
Training loss: 1.6748764514923096
Validation loss: 2.1847731669743857

Epoch: 5| Step: 11
Training loss: 1.9092519283294678
Validation loss: 2.1700346867243447

Epoch: 230| Step: 0
Training loss: 1.9957077503204346
Validation loss: 2.1933821042378745

Epoch: 5| Step: 1
Training loss: 1.666830062866211
Validation loss: 2.19937527179718

Epoch: 5| Step: 2
Training loss: 2.170891761779785
Validation loss: 2.180932233730952

Epoch: 5| Step: 3
Training loss: 2.1126160621643066
Validation loss: 2.1546755135059357

Epoch: 5| Step: 4
Training loss: 2.088632106781006
Validation loss: 2.135741571585337

Epoch: 5| Step: 5
Training loss: 1.7280910015106201
Validation loss: 2.112019787232081

Epoch: 5| Step: 6
Training loss: 1.4863741397857666
Validation loss: 2.0852918277184167

Epoch: 5| Step: 7
Training loss: 1.8756214380264282
Validation loss: 2.1045466462771096

Epoch: 5| Step: 8
Training loss: 2.129739999771118
Validation loss: 2.1026772608359656

Epoch: 5| Step: 9
Training loss: 2.299644708633423
Validation loss: 2.0878283381462097

Epoch: 5| Step: 10
Training loss: 2.054271697998047
Validation loss: 2.1209138482809067

Epoch: 5| Step: 11
Training loss: 1.8173946142196655
Validation loss: 2.1081040650606155

Epoch: 231| Step: 0
Training loss: 1.7910953760147095
Validation loss: 2.104399318496386

Epoch: 5| Step: 1
Training loss: 1.6923596858978271
Validation loss: 2.1190030674139657

Epoch: 5| Step: 2
Training loss: 1.753788709640503
Validation loss: 2.121386537949244

Epoch: 5| Step: 3
Training loss: 2.3185534477233887
Validation loss: 2.1490278045336404

Epoch: 5| Step: 4
Training loss: 2.0851712226867676
Validation loss: 2.1384421288967133

Epoch: 5| Step: 5
Training loss: 1.972024917602539
Validation loss: 2.1635283629099527

Epoch: 5| Step: 6
Training loss: 1.724022626876831
Validation loss: 2.142964780330658

Epoch: 5| Step: 7
Training loss: 2.3547511100769043
Validation loss: 2.1222396145264306

Epoch: 5| Step: 8
Training loss: 1.5877048969268799
Validation loss: 2.119589547316233

Epoch: 5| Step: 9
Training loss: 1.7513961791992188
Validation loss: 2.1158315738042197

Epoch: 5| Step: 10
Training loss: 1.713732123374939
Validation loss: 2.114601497848829

Epoch: 5| Step: 11
Training loss: 3.3095855712890625
Validation loss: 2.0990383476018906

Epoch: 232| Step: 0
Training loss: 2.2379372119903564
Validation loss: 2.1133387088775635

Epoch: 5| Step: 1
Training loss: 1.958304762840271
Validation loss: 2.106536398331324

Epoch: 5| Step: 2
Training loss: 1.013641595840454
Validation loss: 2.119927853345871

Epoch: 5| Step: 3
Training loss: 1.3328393697738647
Validation loss: 2.1392122358083725

Epoch: 5| Step: 4
Training loss: 1.9088579416275024
Validation loss: 2.1443345745404563

Epoch: 5| Step: 5
Training loss: 1.940250039100647
Validation loss: 2.151434654990832

Epoch: 5| Step: 6
Training loss: 2.093963146209717
Validation loss: 2.162074089050293

Epoch: 5| Step: 7
Training loss: 1.9891878366470337
Validation loss: 2.1676340798536935

Epoch: 5| Step: 8
Training loss: 2.1951498985290527
Validation loss: 2.164325162768364

Epoch: 5| Step: 9
Training loss: 1.7263950109481812
Validation loss: 2.1951346347729364

Epoch: 5| Step: 10
Training loss: 2.33272647857666
Validation loss: 2.187422345081965

Epoch: 5| Step: 11
Training loss: 2.6638383865356445
Validation loss: 2.189762701590856

Epoch: 233| Step: 0
Training loss: 2.125154972076416
Validation loss: 2.188175414999326

Epoch: 5| Step: 1
Training loss: 1.6012914180755615
Validation loss: 2.1777088145414987

Epoch: 5| Step: 2
Training loss: 2.0464091300964355
Validation loss: 2.200062910715739

Epoch: 5| Step: 3
Training loss: 2.1546993255615234
Validation loss: 2.1738449037075043

Epoch: 5| Step: 4
Training loss: 2.001516819000244
Validation loss: 2.154782752195994

Epoch: 5| Step: 5
Training loss: 1.9331871271133423
Validation loss: 2.157483249902725

Epoch: 5| Step: 6
Training loss: 1.3800939321517944
Validation loss: 2.1539507806301117

Epoch: 5| Step: 7
Training loss: 2.168471574783325
Validation loss: 2.139751066764196

Epoch: 5| Step: 8
Training loss: 2.4108338356018066
Validation loss: 2.140901580452919

Epoch: 5| Step: 9
Training loss: 1.6131446361541748
Validation loss: 2.121707543730736

Epoch: 5| Step: 10
Training loss: 1.3513233661651611
Validation loss: 2.1202986339728036

Epoch: 5| Step: 11
Training loss: 3.356161594390869
Validation loss: 2.1227956314881644

Epoch: 234| Step: 0
Training loss: 1.944382905960083
Validation loss: 2.1169261038303375

Epoch: 5| Step: 1
Training loss: 2.3703856468200684
Validation loss: 2.108581711848577

Epoch: 5| Step: 2
Training loss: 2.107555866241455
Validation loss: 2.1127877632776895

Epoch: 5| Step: 3
Training loss: 1.5605442523956299
Validation loss: 2.113713120420774

Epoch: 5| Step: 4
Training loss: 2.0982062816619873
Validation loss: 2.1240476022164025

Epoch: 5| Step: 5
Training loss: 1.717907190322876
Validation loss: 2.1401897072792053

Epoch: 5| Step: 6
Training loss: 1.7540935277938843
Validation loss: 2.1632605691750846

Epoch: 5| Step: 7
Training loss: 1.7125873565673828
Validation loss: 2.176322877407074

Epoch: 5| Step: 8
Training loss: 1.921459436416626
Validation loss: 2.179263969262441

Epoch: 5| Step: 9
Training loss: 1.7740576267242432
Validation loss: 2.188401371240616

Epoch: 5| Step: 10
Training loss: 1.9198486804962158
Validation loss: 2.174000253280004

Epoch: 5| Step: 11
Training loss: 2.3238799571990967
Validation loss: 2.1669318129618964

Epoch: 235| Step: 0
Training loss: 1.3790562152862549
Validation loss: 2.174377570549647

Epoch: 5| Step: 1
Training loss: 1.561982274055481
Validation loss: 2.1619677742322287

Epoch: 5| Step: 2
Training loss: 1.7207612991333008
Validation loss: 2.1432970066865287

Epoch: 5| Step: 3
Training loss: 2.170997142791748
Validation loss: 2.104290967186292

Epoch: 5| Step: 4
Training loss: 1.7865288257598877
Validation loss: 2.1026875327030816

Epoch: 5| Step: 5
Training loss: 1.8352102041244507
Validation loss: 2.096548398335775

Epoch: 5| Step: 6
Training loss: 2.002000331878662
Validation loss: 2.094687814513842

Epoch: 5| Step: 7
Training loss: 2.3815276622772217
Validation loss: 2.1096981912851334

Epoch: 5| Step: 8
Training loss: 2.411567449569702
Validation loss: 2.1057454645633698

Epoch: 5| Step: 9
Training loss: 1.9926879405975342
Validation loss: 2.118565152088801

Epoch: 5| Step: 10
Training loss: 1.9924424886703491
Validation loss: 2.1275084614753723

Epoch: 5| Step: 11
Training loss: 2.0956928730010986
Validation loss: 2.134688287973404

Epoch: 236| Step: 0
Training loss: 2.1354875564575195
Validation loss: 2.151558796564738

Epoch: 5| Step: 1
Training loss: 1.750115156173706
Validation loss: 2.184148073196411

Epoch: 5| Step: 2
Training loss: 1.6642255783081055
Validation loss: 2.1886367797851562

Epoch: 5| Step: 3
Training loss: 2.036508083343506
Validation loss: 2.182906781633695

Epoch: 5| Step: 4
Training loss: 1.3007551431655884
Validation loss: 2.1728104750315347

Epoch: 5| Step: 5
Training loss: 2.033360242843628
Validation loss: 2.169913868109385

Epoch: 5| Step: 6
Training loss: 1.7503563165664673
Validation loss: 2.1511770486831665

Epoch: 5| Step: 7
Training loss: 2.7646241188049316
Validation loss: 2.125072250763575

Epoch: 5| Step: 8
Training loss: 1.5907660722732544
Validation loss: 2.1305460582176843

Epoch: 5| Step: 9
Training loss: 1.763658881187439
Validation loss: 2.124421536922455

Epoch: 5| Step: 10
Training loss: 2.1882553100585938
Validation loss: 2.1340469221274057

Epoch: 5| Step: 11
Training loss: 2.095358371734619
Validation loss: 2.123988767464956

Epoch: 237| Step: 0
Training loss: 1.3818295001983643
Validation loss: 2.125702758630117

Epoch: 5| Step: 1
Training loss: 2.2381999492645264
Validation loss: 2.1428470760583878

Epoch: 5| Step: 2
Training loss: 1.9189125299453735
Validation loss: 2.148668557405472

Epoch: 5| Step: 3
Training loss: 1.8102874755859375
Validation loss: 2.1287401417891183

Epoch: 5| Step: 4
Training loss: 2.2694499492645264
Validation loss: 2.1402423679828644

Epoch: 5| Step: 5
Training loss: 1.722129464149475
Validation loss: 2.119389389952024

Epoch: 5| Step: 6
Training loss: 1.7461341619491577
Validation loss: 2.1401617179314294

Epoch: 5| Step: 7
Training loss: 1.8923790454864502
Validation loss: 2.171846220890681

Epoch: 5| Step: 8
Training loss: 2.0348076820373535
Validation loss: 2.1923456490039825

Epoch: 5| Step: 9
Training loss: 1.6416221857070923
Validation loss: 2.2000049352645874

Epoch: 5| Step: 10
Training loss: 1.6630289554595947
Validation loss: 2.193404898047447

Epoch: 5| Step: 11
Training loss: 3.4351723194122314
Validation loss: 2.2157889554897943

Epoch: 238| Step: 0
Training loss: 1.7680397033691406
Validation loss: 2.1908314377069473

Epoch: 5| Step: 1
Training loss: 2.1034607887268066
Validation loss: 2.1908698081970215

Epoch: 5| Step: 2
Training loss: 1.5155850648880005
Validation loss: 2.1847008615732193

Epoch: 5| Step: 3
Training loss: 1.6987186670303345
Validation loss: 2.139037092526754

Epoch: 5| Step: 4
Training loss: 2.05804705619812
Validation loss: 2.09912579258283

Epoch: 5| Step: 5
Training loss: 2.017072916030884
Validation loss: 2.102443436781565

Epoch: 5| Step: 6
Training loss: 1.9802392721176147
Validation loss: 2.0987222294012704

Epoch: 5| Step: 7
Training loss: 2.4538166522979736
Validation loss: 2.1038404206434884

Epoch: 5| Step: 8
Training loss: 2.1742191314697266
Validation loss: 2.088686669866244

Epoch: 5| Step: 9
Training loss: 2.021088123321533
Validation loss: 2.0961709717909494

Epoch: 5| Step: 10
Training loss: 1.9856078624725342
Validation loss: 2.0953263491392136

Epoch: 5| Step: 11
Training loss: 0.9969648122787476
Validation loss: 2.113674114147822

Epoch: 239| Step: 0
Training loss: 1.702498435974121
Validation loss: 2.1412719190120697

Epoch: 5| Step: 1
Training loss: 1.5826350450515747
Validation loss: 2.1739413837591806

Epoch: 5| Step: 2
Training loss: 1.9231799840927124
Validation loss: 2.178718184431394

Epoch: 5| Step: 3
Training loss: 1.983666181564331
Validation loss: 2.188477764527003

Epoch: 5| Step: 4
Training loss: 2.0820066928863525
Validation loss: 2.196252793073654

Epoch: 5| Step: 5
Training loss: 1.9028507471084595
Validation loss: 2.185686156153679

Epoch: 5| Step: 6
Training loss: 2.169027805328369
Validation loss: 2.182250181833903

Epoch: 5| Step: 7
Training loss: 1.633565902709961
Validation loss: 2.1855755100647607

Epoch: 5| Step: 8
Training loss: 1.6233234405517578
Validation loss: 2.17141230404377

Epoch: 5| Step: 9
Training loss: 2.0156359672546387
Validation loss: 2.157501513759295

Epoch: 5| Step: 10
Training loss: 2.1347625255584717
Validation loss: 2.1518341998259225

Epoch: 5| Step: 11
Training loss: 1.5705105066299438
Validation loss: 2.148535519838333

Epoch: 240| Step: 0
Training loss: 1.8728386163711548
Validation loss: 2.129747519890467

Epoch: 5| Step: 1
Training loss: 2.36542010307312
Validation loss: 2.133797417084376

Epoch: 5| Step: 2
Training loss: 1.911097764968872
Validation loss: 2.11868845919768

Epoch: 5| Step: 3
Training loss: 1.7373836040496826
Validation loss: 2.1106914430856705

Epoch: 5| Step: 4
Training loss: 1.7538915872573853
Validation loss: 2.116378997762998

Epoch: 5| Step: 5
Training loss: 1.8243036270141602
Validation loss: 2.110529527068138

Epoch: 5| Step: 6
Training loss: 1.6473134756088257
Validation loss: 2.1256281236807504

Epoch: 5| Step: 7
Training loss: 2.0786499977111816
Validation loss: 2.145323554674784

Epoch: 5| Step: 8
Training loss: 1.7926582098007202
Validation loss: 2.145889535546303

Epoch: 5| Step: 9
Training loss: 1.6023094654083252
Validation loss: 2.1542806327342987

Epoch: 5| Step: 10
Training loss: 2.238868236541748
Validation loss: 2.174129456281662

Epoch: 5| Step: 11
Training loss: 1.9035931825637817
Validation loss: 2.1733218878507614

Epoch: 241| Step: 0
Training loss: 1.8302345275878906
Validation loss: 2.182027200857798

Epoch: 5| Step: 1
Training loss: 1.6288414001464844
Validation loss: 2.165409103035927

Epoch: 5| Step: 2
Training loss: 1.983526587486267
Validation loss: 2.1617583284775415

Epoch: 5| Step: 3
Training loss: 1.6559425592422485
Validation loss: 2.1659182061751685

Epoch: 5| Step: 4
Training loss: 1.8757553100585938
Validation loss: 2.158991128206253

Epoch: 5| Step: 5
Training loss: 1.9194923639297485
Validation loss: 2.157676508029302

Epoch: 5| Step: 6
Training loss: 2.038983106613159
Validation loss: 2.159565806388855

Epoch: 5| Step: 7
Training loss: 1.9405391216278076
Validation loss: 2.1700091809034348

Epoch: 5| Step: 8
Training loss: 1.7484420537948608
Validation loss: 2.173398956656456

Epoch: 5| Step: 9
Training loss: 2.0469460487365723
Validation loss: 2.158046747247378

Epoch: 5| Step: 10
Training loss: 1.969057321548462
Validation loss: 2.1793172707160315

Epoch: 5| Step: 11
Training loss: 1.166107177734375
Validation loss: 2.183796321352323

Epoch: 242| Step: 0
Training loss: 2.194671869277954
Validation loss: 2.162885531783104

Epoch: 5| Step: 1
Training loss: 2.0856449604034424
Validation loss: 2.158791313568751

Epoch: 5| Step: 2
Training loss: 1.7069963216781616
Validation loss: 2.1543685297171273

Epoch: 5| Step: 3
Training loss: 1.292352318763733
Validation loss: 2.1453645328680673

Epoch: 5| Step: 4
Training loss: 1.3189961910247803
Validation loss: 2.1457883516947427

Epoch: 5| Step: 5
Training loss: 2.1265196800231934
Validation loss: 2.145245000720024

Epoch: 5| Step: 6
Training loss: 2.000230312347412
Validation loss: 2.124150648713112

Epoch: 5| Step: 7
Training loss: 2.1477956771850586
Validation loss: 2.1381704111893973

Epoch: 5| Step: 8
Training loss: 2.60142183303833
Validation loss: 2.146818379561106

Epoch: 5| Step: 9
Training loss: 1.7523345947265625
Validation loss: 2.1513352443774543

Epoch: 5| Step: 10
Training loss: 1.4445676803588867
Validation loss: 2.1813109864791236

Epoch: 5| Step: 11
Training loss: 2.624094009399414
Validation loss: 2.1847644646962485

Epoch: 243| Step: 0
Training loss: 2.0411853790283203
Validation loss: 2.157665183146795

Epoch: 5| Step: 1
Training loss: 2.0704398155212402
Validation loss: 2.1874532103538513

Epoch: 5| Step: 2
Training loss: 1.5324785709381104
Validation loss: 2.1786371370156608

Epoch: 5| Step: 3
Training loss: 1.7938520908355713
Validation loss: 2.172111377120018

Epoch: 5| Step: 4
Training loss: 2.024876832962036
Validation loss: 2.147829294204712

Epoch: 5| Step: 5
Training loss: 1.989013910293579
Validation loss: 2.1391337861617408

Epoch: 5| Step: 6
Training loss: 2.0706727504730225
Validation loss: 2.1455979446570077

Epoch: 5| Step: 7
Training loss: 1.5083566904067993
Validation loss: 2.1342970629533133

Epoch: 5| Step: 8
Training loss: 1.9613087177276611
Validation loss: 2.1375346928834915

Epoch: 5| Step: 9
Training loss: 1.3100836277008057
Validation loss: 2.15274345378081

Epoch: 5| Step: 10
Training loss: 2.1606945991516113
Validation loss: 2.157834510008494

Epoch: 5| Step: 11
Training loss: 1.741225004196167
Validation loss: 2.143395150701205

Epoch: 244| Step: 0
Training loss: 1.4600279331207275
Validation loss: 2.1494025141000748

Epoch: 5| Step: 1
Training loss: 1.7591266632080078
Validation loss: 2.1627184450626373

Epoch: 5| Step: 2
Training loss: 1.8798354864120483
Validation loss: 2.150480091571808

Epoch: 5| Step: 3
Training loss: 2.399916410446167
Validation loss: 2.150666962067286

Epoch: 5| Step: 4
Training loss: 1.9099922180175781
Validation loss: 2.150123248497645

Epoch: 5| Step: 5
Training loss: 1.7162481546401978
Validation loss: 2.1399321456750235

Epoch: 5| Step: 6
Training loss: 1.8040376901626587
Validation loss: 2.14470711350441

Epoch: 5| Step: 7
Training loss: 1.4646797180175781
Validation loss: 2.133276268839836

Epoch: 5| Step: 8
Training loss: 2.234973192214966
Validation loss: 2.118331323067347

Epoch: 5| Step: 9
Training loss: 2.4421916007995605
Validation loss: 2.143546834588051

Epoch: 5| Step: 10
Training loss: 1.8253190517425537
Validation loss: 2.1628175030152

Epoch: 5| Step: 11
Training loss: 0.8930010199546814
Validation loss: 2.169023106495539

Epoch: 245| Step: 0
Training loss: 1.7699886560440063
Validation loss: 2.172250732779503

Epoch: 5| Step: 1
Training loss: 1.0900923013687134
Validation loss: 2.1843550403912864

Epoch: 5| Step: 2
Training loss: 2.122593641281128
Validation loss: 2.183817664782206

Epoch: 5| Step: 3
Training loss: 2.1718130111694336
Validation loss: 2.180052032073339

Epoch: 5| Step: 4
Training loss: 1.62521493434906
Validation loss: 2.176713913679123

Epoch: 5| Step: 5
Training loss: 1.5623152256011963
Validation loss: 2.184109235803286

Epoch: 5| Step: 6
Training loss: 1.9033641815185547
Validation loss: 2.155591497818629

Epoch: 5| Step: 7
Training loss: 1.7297111749649048
Validation loss: 2.1498785614967346

Epoch: 5| Step: 8
Training loss: 2.4459242820739746
Validation loss: 2.1188844492038093

Epoch: 5| Step: 9
Training loss: 2.0250234603881836
Validation loss: 2.12801264723142

Epoch: 5| Step: 10
Training loss: 2.1733930110931396
Validation loss: 2.1371672650178275

Epoch: 5| Step: 11
Training loss: 1.0087766647338867
Validation loss: 2.1343527734279633

Epoch: 246| Step: 0
Training loss: 2.4501407146453857
Validation loss: 2.1385099490483603

Epoch: 5| Step: 1
Training loss: 1.9393627643585205
Validation loss: 2.143749386072159

Epoch: 5| Step: 2
Training loss: 1.6965278387069702
Validation loss: 2.168252095580101

Epoch: 5| Step: 3
Training loss: 1.3679602146148682
Validation loss: 2.175335263212522

Epoch: 5| Step: 4
Training loss: 1.5618627071380615
Validation loss: 2.1814807107051215

Epoch: 5| Step: 5
Training loss: 1.7409026622772217
Validation loss: 2.1488218307495117

Epoch: 5| Step: 6
Training loss: 1.7501020431518555
Validation loss: 2.1765255630016327

Epoch: 5| Step: 7
Training loss: 1.3333412408828735
Validation loss: 2.1494770298401513

Epoch: 5| Step: 8
Training loss: 1.3447529077529907
Validation loss: 2.171756992737452

Epoch: 5| Step: 9
Training loss: 2.447988748550415
Validation loss: 2.14800027012825

Epoch: 5| Step: 10
Training loss: 2.2511746883392334
Validation loss: 2.1557940542697906

Epoch: 5| Step: 11
Training loss: 3.478008985519409
Validation loss: 2.15740600725015

Epoch: 247| Step: 0
Training loss: 1.9772506952285767
Validation loss: 2.169894516468048

Epoch: 5| Step: 1
Training loss: 2.070657730102539
Validation loss: 2.186202252904574

Epoch: 5| Step: 2
Training loss: 1.9390504360198975
Validation loss: 2.171198219060898

Epoch: 5| Step: 3
Training loss: 1.7906681299209595
Validation loss: 2.1906035244464874

Epoch: 5| Step: 4
Training loss: 1.3835381269454956
Validation loss: 2.1731063624223075

Epoch: 5| Step: 5
Training loss: 1.3941059112548828
Validation loss: 2.1675503899653754

Epoch: 5| Step: 6
Training loss: 2.009160280227661
Validation loss: 2.128693456451098

Epoch: 5| Step: 7
Training loss: 1.7503334283828735
Validation loss: 2.1343142141898475

Epoch: 5| Step: 8
Training loss: 1.948110818862915
Validation loss: 2.137901479999224

Epoch: 5| Step: 9
Training loss: 2.615434408187866
Validation loss: 2.1401109794775643

Epoch: 5| Step: 10
Training loss: 1.7029664516448975
Validation loss: 2.1503299872080484

Epoch: 5| Step: 11
Training loss: 1.6938531398773193
Validation loss: 2.167700633406639

Epoch: 248| Step: 0
Training loss: 1.4968677759170532
Validation loss: 2.1636363118886948

Epoch: 5| Step: 1
Training loss: 2.0286965370178223
Validation loss: 2.196957528591156

Epoch: 5| Step: 2
Training loss: 2.1697781085968018
Validation loss: 2.227318217357

Epoch: 5| Step: 3
Training loss: 2.348686456680298
Validation loss: 2.2132226129372916

Epoch: 5| Step: 4
Training loss: 2.2755789756774902
Validation loss: 2.2188315391540527

Epoch: 5| Step: 5
Training loss: 1.5066916942596436
Validation loss: 2.2282700687646866

Epoch: 5| Step: 6
Training loss: 1.8212718963623047
Validation loss: 2.2251949359973273

Epoch: 5| Step: 7
Training loss: 1.8485053777694702
Validation loss: 2.185850515961647

Epoch: 5| Step: 8
Training loss: 1.5192458629608154
Validation loss: 2.161071260770162

Epoch: 5| Step: 9
Training loss: 1.6583513021469116
Validation loss: 2.1480328341325126

Epoch: 5| Step: 10
Training loss: 1.7781565189361572
Validation loss: 2.138629893461863

Epoch: 5| Step: 11
Training loss: 2.615854263305664
Validation loss: 2.120112250248591

Epoch: 249| Step: 0
Training loss: 1.7342660427093506
Validation loss: 2.130515605211258

Epoch: 5| Step: 1
Training loss: 2.0360748767852783
Validation loss: 2.120395064353943

Epoch: 5| Step: 2
Training loss: 2.016070604324341
Validation loss: 2.1163998544216156

Epoch: 5| Step: 3
Training loss: 1.9556690454483032
Validation loss: 2.1079247842232385

Epoch: 5| Step: 4
Training loss: 2.4230988025665283
Validation loss: 2.1200807044903436

Epoch: 5| Step: 5
Training loss: 1.764865517616272
Validation loss: 2.1471426288286843

Epoch: 5| Step: 6
Training loss: 2.117300510406494
Validation loss: 2.1433594127496085

Epoch: 5| Step: 7
Training loss: 2.072145938873291
Validation loss: 2.169018725554148

Epoch: 5| Step: 8
Training loss: 1.9541759490966797
Validation loss: 2.18849507967631

Epoch: 5| Step: 9
Training loss: 1.7274640798568726
Validation loss: 2.1980650275945663

Epoch: 5| Step: 10
Training loss: 1.6666481494903564
Validation loss: 2.190033733844757

Epoch: 5| Step: 11
Training loss: 1.145945429801941
Validation loss: 2.1960804760456085

Epoch: 250| Step: 0
Training loss: 1.9456695318222046
Validation loss: 2.1612422168254852

Epoch: 5| Step: 1
Training loss: 2.1027865409851074
Validation loss: 2.168401136994362

Epoch: 5| Step: 2
Training loss: 1.8903350830078125
Validation loss: 2.139217252532641

Epoch: 5| Step: 3
Training loss: 1.5724866390228271
Validation loss: 2.1240918934345245

Epoch: 5| Step: 4
Training loss: 2.2168517112731934
Validation loss: 2.11725086470445

Epoch: 5| Step: 5
Training loss: 1.8915350437164307
Validation loss: 2.114913875857989

Epoch: 5| Step: 6
Training loss: 1.968693494796753
Validation loss: 2.1110427578290305

Epoch: 5| Step: 7
Training loss: 1.8591455221176147
Validation loss: 2.117440382639567

Epoch: 5| Step: 8
Training loss: 2.018279552459717
Validation loss: 2.1219549030065536

Epoch: 5| Step: 9
Training loss: 1.4959659576416016
Validation loss: 2.1338036954402924

Epoch: 5| Step: 10
Training loss: 1.9989057779312134
Validation loss: 2.137878566980362

Epoch: 5| Step: 11
Training loss: 1.737823247909546
Validation loss: 2.184467628598213

Epoch: 251| Step: 0
Training loss: 1.2190970182418823
Validation loss: 2.191429932912191

Epoch: 5| Step: 1
Training loss: 1.8547685146331787
Validation loss: 2.1932227512200675

Epoch: 5| Step: 2
Training loss: 2.3044536113739014
Validation loss: 2.2197649280230203

Epoch: 5| Step: 3
Training loss: 1.9205665588378906
Validation loss: 2.2082738280296326

Epoch: 5| Step: 4
Training loss: 1.9594738483428955
Validation loss: 2.221158559123675

Epoch: 5| Step: 5
Training loss: 1.7036056518554688
Validation loss: 2.199262728293737

Epoch: 5| Step: 6
Training loss: 1.8434913158416748
Validation loss: 2.2027194698651633

Epoch: 5| Step: 7
Training loss: 2.2141361236572266
Validation loss: 2.1720217068990073

Epoch: 5| Step: 8
Training loss: 2.445694923400879
Validation loss: 2.1393378376960754

Epoch: 5| Step: 9
Training loss: 1.6141201257705688
Validation loss: 2.1449619034926095

Epoch: 5| Step: 10
Training loss: 1.806517243385315
Validation loss: 2.1392671863238015

Epoch: 5| Step: 11
Training loss: 2.6244516372680664
Validation loss: 2.1339551707108817

Epoch: 252| Step: 0
Training loss: 1.6824064254760742
Validation loss: 2.1426648944616318

Epoch: 5| Step: 1
Training loss: 2.285036087036133
Validation loss: 2.152542213598887

Epoch: 5| Step: 2
Training loss: 1.9769287109375
Validation loss: 2.139966825644175

Epoch: 5| Step: 3
Training loss: 1.6576935052871704
Validation loss: 2.1724703212579093

Epoch: 5| Step: 4
Training loss: 1.4085848331451416
Validation loss: 2.170220673084259

Epoch: 5| Step: 5
Training loss: 2.0276038646698
Validation loss: 2.2079448848962784

Epoch: 5| Step: 6
Training loss: 1.9149881601333618
Validation loss: 2.1999912907679877

Epoch: 5| Step: 7
Training loss: 2.2546021938323975
Validation loss: 2.200904210408529

Epoch: 5| Step: 8
Training loss: 1.8047020435333252
Validation loss: 2.1925889601310096

Epoch: 5| Step: 9
Training loss: 1.5969303846359253
Validation loss: 2.2107446094353995

Epoch: 5| Step: 10
Training loss: 1.6711190938949585
Validation loss: 2.179048846165339

Epoch: 5| Step: 11
Training loss: 2.405146360397339
Validation loss: 2.181472048163414

Epoch: 253| Step: 0
Training loss: 1.6514822244644165
Validation loss: 2.167181134223938

Epoch: 5| Step: 1
Training loss: 2.0658090114593506
Validation loss: 2.177609235048294

Epoch: 5| Step: 2
Training loss: 2.0134894847869873
Validation loss: 2.179581438501676

Epoch: 5| Step: 3
Training loss: 2.731767177581787
Validation loss: 2.1593170662721

Epoch: 5| Step: 4
Training loss: 1.804147720336914
Validation loss: 2.169887820879618

Epoch: 5| Step: 5
Training loss: 1.6190950870513916
Validation loss: 2.189477870861689

Epoch: 5| Step: 6
Training loss: 1.3707619905471802
Validation loss: 2.1832038263479867

Epoch: 5| Step: 7
Training loss: 1.3203729391098022
Validation loss: 2.1735065281391144

Epoch: 5| Step: 8
Training loss: 1.490791916847229
Validation loss: 2.179853076736132

Epoch: 5| Step: 9
Training loss: 2.143794298171997
Validation loss: 2.15632231036822

Epoch: 5| Step: 10
Training loss: 1.706813097000122
Validation loss: 2.1631454477707543

Epoch: 5| Step: 11
Training loss: 3.618924617767334
Validation loss: 2.152075628439585

Epoch: 254| Step: 0
Training loss: 1.86545729637146
Validation loss: 2.165010998646418

Epoch: 5| Step: 1
Training loss: 1.6646173000335693
Validation loss: 2.174910217523575

Epoch: 5| Step: 2
Training loss: 2.1388306617736816
Validation loss: 2.1868324875831604

Epoch: 5| Step: 3
Training loss: 2.2268500328063965
Validation loss: 2.2017013976971307

Epoch: 5| Step: 4
Training loss: 1.6613792181015015
Validation loss: 2.2091616888840995

Epoch: 5| Step: 5
Training loss: 1.862417221069336
Validation loss: 2.213404878973961

Epoch: 5| Step: 6
Training loss: 1.9642975330352783
Validation loss: 2.1982300877571106

Epoch: 5| Step: 7
Training loss: 2.0185558795928955
Validation loss: 2.213206340869268

Epoch: 5| Step: 8
Training loss: 1.639697790145874
Validation loss: 2.2164387802282968

Epoch: 5| Step: 9
Training loss: 1.696451187133789
Validation loss: 2.2152982503175735

Epoch: 5| Step: 10
Training loss: 1.7045879364013672
Validation loss: 2.2198108434677124

Epoch: 5| Step: 11
Training loss: 0.9747804403305054
Validation loss: 2.2042082647482553

Epoch: 255| Step: 0
Training loss: 2.314565896987915
Validation loss: 2.1858441730340323

Epoch: 5| Step: 1
Training loss: 2.5120034217834473
Validation loss: 2.1659390181303024

Epoch: 5| Step: 2
Training loss: 1.378973364830017
Validation loss: 2.15664512415727

Epoch: 5| Step: 3
Training loss: 1.6645866632461548
Validation loss: 2.160952150821686

Epoch: 5| Step: 4
Training loss: 1.5246466398239136
Validation loss: 2.1494214634100595

Epoch: 5| Step: 5
Training loss: 1.8042598962783813
Validation loss: 2.1440371572971344

Epoch: 5| Step: 6
Training loss: 2.242013692855835
Validation loss: 2.14381442964077

Epoch: 5| Step: 7
Training loss: 1.982712745666504
Validation loss: 2.1513524254163108

Epoch: 5| Step: 8
Training loss: 1.6677671670913696
Validation loss: 2.179490273197492

Epoch: 5| Step: 9
Training loss: 1.5571106672286987
Validation loss: 2.183635155359904

Epoch: 5| Step: 10
Training loss: 1.7434810400009155
Validation loss: 2.1973852813243866

Epoch: 5| Step: 11
Training loss: 0.4512783885002136
Validation loss: 2.177680273850759

Epoch: 256| Step: 0
Training loss: 2.901731014251709
Validation loss: 2.2100273172060647

Epoch: 5| Step: 1
Training loss: 1.6524766683578491
Validation loss: 2.2236379384994507

Epoch: 5| Step: 2
Training loss: 2.0796892642974854
Validation loss: 2.2416383773088455

Epoch: 5| Step: 3
Training loss: 1.5164968967437744
Validation loss: 2.202504093448321

Epoch: 5| Step: 4
Training loss: 1.779022216796875
Validation loss: 2.215918411811193

Epoch: 5| Step: 5
Training loss: 1.417710781097412
Validation loss: 2.187604005138079

Epoch: 5| Step: 6
Training loss: 1.52828848361969
Validation loss: 2.1975406308968863

Epoch: 5| Step: 7
Training loss: 1.5990722179412842
Validation loss: 2.1791912764310837

Epoch: 5| Step: 8
Training loss: 1.4533045291900635
Validation loss: 2.2087172170480094

Epoch: 5| Step: 9
Training loss: 1.965691328048706
Validation loss: 2.2032277584075928

Epoch: 5| Step: 10
Training loss: 2.099515914916992
Validation loss: 2.2062488943338394

Epoch: 5| Step: 11
Training loss: 1.4053568840026855
Validation loss: 2.169010559717814

Epoch: 257| Step: 0
Training loss: 2.3024253845214844
Validation loss: 2.1816434462865195

Epoch: 5| Step: 1
Training loss: 2.0176849365234375
Validation loss: 2.174228926499685

Epoch: 5| Step: 2
Training loss: 2.3148601055145264
Validation loss: 2.1911505858103433

Epoch: 5| Step: 3
Training loss: 1.752343773841858
Validation loss: 2.178012177348137

Epoch: 5| Step: 4
Training loss: 2.1744561195373535
Validation loss: 2.1813288182020187

Epoch: 5| Step: 5
Training loss: 1.8072359561920166
Validation loss: 2.185592850049337

Epoch: 5| Step: 6
Training loss: 1.9666637182235718
Validation loss: 2.1935649812221527

Epoch: 5| Step: 7
Training loss: 1.3045293092727661
Validation loss: 2.194361681739489

Epoch: 5| Step: 8
Training loss: 1.6163585186004639
Validation loss: 2.1961556474367776

Epoch: 5| Step: 9
Training loss: 1.483124017715454
Validation loss: 2.182747721672058

Epoch: 5| Step: 10
Training loss: 1.3160912990570068
Validation loss: 2.192417874932289

Epoch: 5| Step: 11
Training loss: 1.2125670909881592
Validation loss: 2.1735810339450836

Epoch: 258| Step: 0
Training loss: 1.20125412940979
Validation loss: 2.175880034764608

Epoch: 5| Step: 1
Training loss: 1.422747015953064
Validation loss: 2.195120468735695

Epoch: 5| Step: 2
Training loss: 2.27833890914917
Validation loss: 2.1805547575155892

Epoch: 5| Step: 3
Training loss: 1.7849334478378296
Validation loss: 2.1793761054674783

Epoch: 5| Step: 4
Training loss: 1.8344618082046509
Validation loss: 2.1709012736876807

Epoch: 5| Step: 5
Training loss: 1.9614044427871704
Validation loss: 2.187228267391523

Epoch: 5| Step: 6
Training loss: 2.288740634918213
Validation loss: 2.1801031877597175

Epoch: 5| Step: 7
Training loss: 1.6468560695648193
Validation loss: 2.178796738386154

Epoch: 5| Step: 8
Training loss: 2.014686107635498
Validation loss: 2.2059205820163093

Epoch: 5| Step: 9
Training loss: 1.594592809677124
Validation loss: 2.168200100461642

Epoch: 5| Step: 10
Training loss: 1.7835668325424194
Validation loss: 2.1719764918088913

Epoch: 5| Step: 11
Training loss: 2.354943037033081
Validation loss: 2.1950806627670922

Epoch: 259| Step: 0
Training loss: 2.135038375854492
Validation loss: 2.1747782776753106

Epoch: 5| Step: 1
Training loss: 2.2439870834350586
Validation loss: 2.1684614767630896

Epoch: 5| Step: 2
Training loss: 2.2837002277374268
Validation loss: 2.1602738897005715

Epoch: 5| Step: 3
Training loss: 1.5095850229263306
Validation loss: 2.1817255268494287

Epoch: 5| Step: 4
Training loss: 1.9069163799285889
Validation loss: 2.1648060232400894

Epoch: 5| Step: 5
Training loss: 1.5382213592529297
Validation loss: 2.164013385772705

Epoch: 5| Step: 6
Training loss: 1.4773057699203491
Validation loss: 2.149986063440641

Epoch: 5| Step: 7
Training loss: 2.169492483139038
Validation loss: 2.1612306386232376

Epoch: 5| Step: 8
Training loss: 1.757754921913147
Validation loss: 2.1478539605935416

Epoch: 5| Step: 9
Training loss: 1.383331537246704
Validation loss: 2.166891321539879

Epoch: 5| Step: 10
Training loss: 1.5982019901275635
Validation loss: 2.17249325911204

Epoch: 5| Step: 11
Training loss: 1.8684351444244385
Validation loss: 2.1815765698750815

Epoch: 260| Step: 0
Training loss: 1.7708027362823486
Validation loss: 2.191294143597285

Epoch: 5| Step: 1
Training loss: 1.675439476966858
Validation loss: 2.182141194740931

Epoch: 5| Step: 2
Training loss: 1.9395687580108643
Validation loss: 2.2017991642157235

Epoch: 5| Step: 3
Training loss: 1.8144687414169312
Validation loss: 2.187213659286499

Epoch: 5| Step: 4
Training loss: 1.7343521118164062
Validation loss: 2.1699143846829734

Epoch: 5| Step: 5
Training loss: 2.317558765411377
Validation loss: 2.1861109187205634

Epoch: 5| Step: 6
Training loss: 1.4377481937408447
Validation loss: 2.1588528951009116

Epoch: 5| Step: 7
Training loss: 1.5792251825332642
Validation loss: 2.161745806535085

Epoch: 5| Step: 8
Training loss: 1.9939050674438477
Validation loss: 2.1838192840417228

Epoch: 5| Step: 9
Training loss: 1.9245471954345703
Validation loss: 2.1555880109469094

Epoch: 5| Step: 10
Training loss: 1.813102126121521
Validation loss: 2.1589800814787545

Epoch: 5| Step: 11
Training loss: 1.4942333698272705
Validation loss: 2.1588285068670907

Epoch: 261| Step: 0
Training loss: 1.975029706954956
Validation loss: 2.186427339911461

Epoch: 5| Step: 1
Training loss: 1.7110973596572876
Validation loss: 2.1717960834503174

Epoch: 5| Step: 2
Training loss: 1.4937869310379028
Validation loss: 2.191082547108332

Epoch: 5| Step: 3
Training loss: 2.6670944690704346
Validation loss: 2.1930108070373535

Epoch: 5| Step: 4
Training loss: 1.8278014659881592
Validation loss: 2.2002280056476593

Epoch: 5| Step: 5
Training loss: 2.1355602741241455
Validation loss: 2.215873956680298

Epoch: 5| Step: 6
Training loss: 1.7317698001861572
Validation loss: 2.217126026749611

Epoch: 5| Step: 7
Training loss: 1.905238151550293
Validation loss: 2.2260321974754333

Epoch: 5| Step: 8
Training loss: 1.9850142002105713
Validation loss: 2.2096135169267654

Epoch: 5| Step: 9
Training loss: 1.271153450012207
Validation loss: 2.207975208759308

Epoch: 5| Step: 10
Training loss: 1.3829954862594604
Validation loss: 2.195026377836863

Epoch: 5| Step: 11
Training loss: 1.2639776468276978
Validation loss: 2.1617706418037415

Epoch: 262| Step: 0
Training loss: 1.8557780981063843
Validation loss: 2.139044404029846

Epoch: 5| Step: 1
Training loss: 1.8567432165145874
Validation loss: 2.1370624005794525

Epoch: 5| Step: 2
Training loss: 2.009181022644043
Validation loss: 2.1466833849747977

Epoch: 5| Step: 3
Training loss: 1.5545690059661865
Validation loss: 2.138959596554438

Epoch: 5| Step: 4
Training loss: 2.1560537815093994
Validation loss: 2.1540226489305496

Epoch: 5| Step: 5
Training loss: 1.852182388305664
Validation loss: 2.19009060660998

Epoch: 5| Step: 6
Training loss: 2.102673053741455
Validation loss: 2.1891810595989227

Epoch: 5| Step: 7
Training loss: 1.6378072500228882
Validation loss: 2.1902008056640625

Epoch: 5| Step: 8
Training loss: 1.741217017173767
Validation loss: 2.214119295279185

Epoch: 5| Step: 9
Training loss: 1.5289676189422607
Validation loss: 2.1939177066087723

Epoch: 5| Step: 10
Training loss: 1.8358211517333984
Validation loss: 2.2050903091828027

Epoch: 5| Step: 11
Training loss: 1.9348690509796143
Validation loss: 2.206597516934077

Epoch: 263| Step: 0
Training loss: 1.3984096050262451
Validation loss: 2.2152824699878693

Epoch: 5| Step: 1
Training loss: 1.7982990741729736
Validation loss: 2.203388055165609

Epoch: 5| Step: 2
Training loss: 1.7644970417022705
Validation loss: 2.1921242276827493

Epoch: 5| Step: 3
Training loss: 1.571796178817749
Validation loss: 2.1656245489915213

Epoch: 5| Step: 4
Training loss: 2.284555196762085
Validation loss: 2.1340904434521994

Epoch: 5| Step: 5
Training loss: 2.1864967346191406
Validation loss: 2.1434749364852905

Epoch: 5| Step: 6
Training loss: 1.8530843257904053
Validation loss: 2.1221147825320563

Epoch: 5| Step: 7
Training loss: 1.579807996749878
Validation loss: 2.116279194752375

Epoch: 5| Step: 8
Training loss: 1.6585566997528076
Validation loss: 2.1262304931879044

Epoch: 5| Step: 9
Training loss: 1.9501861333847046
Validation loss: 2.1514411916335425

Epoch: 5| Step: 10
Training loss: 2.3569960594177246
Validation loss: 2.1596557398637137

Epoch: 5| Step: 11
Training loss: 3.0186736583709717
Validation loss: 2.1452848811944327

Epoch: 264| Step: 0
Training loss: 1.8646812438964844
Validation loss: 2.1639533390601478

Epoch: 5| Step: 1
Training loss: 1.3220583200454712
Validation loss: 2.161581148703893

Epoch: 5| Step: 2
Training loss: 2.209826707839966
Validation loss: 2.158729319771131

Epoch: 5| Step: 3
Training loss: 1.7362709045410156
Validation loss: 2.1679690380891166

Epoch: 5| Step: 4
Training loss: 2.1587460041046143
Validation loss: 2.1690122336149216

Epoch: 5| Step: 5
Training loss: 2.1888108253479004
Validation loss: 2.1864049235979715

Epoch: 5| Step: 6
Training loss: 1.6629860401153564
Validation loss: 2.1552819907665253

Epoch: 5| Step: 7
Training loss: 2.0882797241210938
Validation loss: 2.168039878209432

Epoch: 5| Step: 8
Training loss: 1.5051316022872925
Validation loss: 2.1773054202397666

Epoch: 5| Step: 9
Training loss: 1.714525818824768
Validation loss: 2.16445821026961

Epoch: 5| Step: 10
Training loss: 1.7778123617172241
Validation loss: 2.180853918194771

Epoch: 5| Step: 11
Training loss: 1.6823248863220215
Validation loss: 2.150151158372561

Epoch: 265| Step: 0
Training loss: 1.8636753559112549
Validation loss: 2.1714662412802377

Epoch: 5| Step: 1
Training loss: 2.2341532707214355
Validation loss: 2.1412827521562576

Epoch: 5| Step: 2
Training loss: 1.4775875806808472
Validation loss: 2.1558214177687964

Epoch: 5| Step: 3
Training loss: 1.709170937538147
Validation loss: 2.155648246407509

Epoch: 5| Step: 4
Training loss: 1.497816562652588
Validation loss: 2.159845451513926

Epoch: 5| Step: 5
Training loss: 1.6305347681045532
Validation loss: 2.1693715353806815

Epoch: 5| Step: 6
Training loss: 1.856008768081665
Validation loss: 2.1868378718694053

Epoch: 5| Step: 7
Training loss: 1.4784142971038818
Validation loss: 2.2321111857891083

Epoch: 5| Step: 8
Training loss: 2.4563512802124023
Validation loss: 2.238342593113581

Epoch: 5| Step: 9
Training loss: 2.2736010551452637
Validation loss: 2.232077638308207

Epoch: 5| Step: 10
Training loss: 2.0591320991516113
Validation loss: 2.278009573618571

Epoch: 5| Step: 11
Training loss: 1.9329729080200195
Validation loss: 2.213927149772644

Epoch: 266| Step: 0
Training loss: 1.3380848169326782
Validation loss: 2.1897244652112327

Epoch: 5| Step: 1
Training loss: 1.8993110656738281
Validation loss: 2.1362875600655875

Epoch: 5| Step: 2
Training loss: 2.2581896781921387
Validation loss: 2.109071562687556

Epoch: 5| Step: 3
Training loss: 1.8223869800567627
Validation loss: 2.1076788157224655

Epoch: 5| Step: 4
Training loss: 1.6531708240509033
Validation loss: 2.1083978762229285

Epoch: 5| Step: 5
Training loss: 1.6325397491455078
Validation loss: 2.1083596299091973

Epoch: 5| Step: 6
Training loss: 2.430544376373291
Validation loss: 2.1163460115591683

Epoch: 5| Step: 7
Training loss: 1.868598222732544
Validation loss: 2.0978618065516152

Epoch: 5| Step: 8
Training loss: 2.160858392715454
Validation loss: 2.1199270337820053

Epoch: 5| Step: 9
Training loss: 1.806544303894043
Validation loss: 2.114678993821144

Epoch: 5| Step: 10
Training loss: 1.8555291891098022
Validation loss: 2.1539153357346854

Epoch: 5| Step: 11
Training loss: 3.1377007961273193
Validation loss: 2.1745839019616446

Epoch: 267| Step: 0
Training loss: 1.6059081554412842
Validation loss: 2.1821337391932807

Epoch: 5| Step: 1
Training loss: 1.8243011236190796
Validation loss: 2.2213358332713447

Epoch: 5| Step: 2
Training loss: 2.6935908794403076
Validation loss: 2.224961206316948

Epoch: 5| Step: 3
Training loss: 1.7696033716201782
Validation loss: 2.2199067870775857

Epoch: 5| Step: 4
Training loss: 2.3951992988586426
Validation loss: 2.200183163086573

Epoch: 5| Step: 5
Training loss: 1.5875080823898315
Validation loss: 2.2171794772148132

Epoch: 5| Step: 6
Training loss: 1.4086802005767822
Validation loss: 2.206878383954366

Epoch: 5| Step: 7
Training loss: 2.559407949447632
Validation loss: 2.2080541302760444

Epoch: 5| Step: 8
Training loss: 1.4515551328659058
Validation loss: 2.1841769069433212

Epoch: 5| Step: 9
Training loss: 2.024993896484375
Validation loss: 2.1832572519779205

Epoch: 5| Step: 10
Training loss: 1.2639601230621338
Validation loss: 2.1932078450918198

Epoch: 5| Step: 11
Training loss: 1.2154414653778076
Validation loss: 2.177929346760114

Epoch: 268| Step: 0
Training loss: 1.8507798910140991
Validation loss: 2.152925660212835

Epoch: 5| Step: 1
Training loss: 1.9824540615081787
Validation loss: 2.134880060950915

Epoch: 5| Step: 2
Training loss: 2.2384517192840576
Validation loss: 2.1547347207864127

Epoch: 5| Step: 3
Training loss: 1.664735198020935
Validation loss: 2.153296838204066

Epoch: 5| Step: 4
Training loss: 1.675344705581665
Validation loss: 2.132756153742472

Epoch: 5| Step: 5
Training loss: 1.5981688499450684
Validation loss: 2.150604714949926

Epoch: 5| Step: 6
Training loss: 1.891177773475647
Validation loss: 2.1281741162141166

Epoch: 5| Step: 7
Training loss: 1.2566485404968262
Validation loss: 2.129985436797142

Epoch: 5| Step: 8
Training loss: 2.1009905338287354
Validation loss: 2.152381186683973

Epoch: 5| Step: 9
Training loss: 2.357759952545166
Validation loss: 2.1472150137027106

Epoch: 5| Step: 10
Training loss: 1.6662561893463135
Validation loss: 2.186624730626742

Epoch: 5| Step: 11
Training loss: 1.169419288635254
Validation loss: 2.183890620867411

Epoch: 269| Step: 0
Training loss: 2.1967759132385254
Validation loss: 2.2293529311815896

Epoch: 5| Step: 1
Training loss: 2.671858549118042
Validation loss: 2.2210247864325843

Epoch: 5| Step: 2
Training loss: 1.6792625188827515
Validation loss: 2.2347763230403266

Epoch: 5| Step: 3
Training loss: 1.4019907712936401
Validation loss: 2.2375753968954086

Epoch: 5| Step: 4
Training loss: 1.6521127223968506
Validation loss: 2.2549375891685486

Epoch: 5| Step: 5
Training loss: 1.5935555696487427
Validation loss: 2.258677303791046

Epoch: 5| Step: 6
Training loss: 1.8914587497711182
Validation loss: 2.243468095858892

Epoch: 5| Step: 7
Training loss: 2.4360761642456055
Validation loss: 2.2181952744722366

Epoch: 5| Step: 8
Training loss: 2.0674643516540527
Validation loss: 2.1946396231651306

Epoch: 5| Step: 9
Training loss: 1.5125839710235596
Validation loss: 2.1764862835407257

Epoch: 5| Step: 10
Training loss: 1.6801893711090088
Validation loss: 2.1591828068097434

Epoch: 5| Step: 11
Training loss: 1.602829098701477
Validation loss: 2.1376033574342728

Epoch: 270| Step: 0
Training loss: 2.010399341583252
Validation loss: 2.1477760672569275

Epoch: 5| Step: 1
Training loss: 1.345765471458435
Validation loss: 2.1534662346045175

Epoch: 5| Step: 2
Training loss: 2.3467814922332764
Validation loss: 2.1781743516524634

Epoch: 5| Step: 3
Training loss: 2.1769721508026123
Validation loss: 2.171689584851265

Epoch: 5| Step: 4
Training loss: 1.5332750082015991
Validation loss: 2.1551437079906464

Epoch: 5| Step: 5
Training loss: 1.3165249824523926
Validation loss: 2.193082938591639

Epoch: 5| Step: 6
Training loss: 1.7832469940185547
Validation loss: 2.208400343855222

Epoch: 5| Step: 7
Training loss: 2.238649845123291
Validation loss: 2.209492420156797

Epoch: 5| Step: 8
Training loss: 1.9434741735458374
Validation loss: 2.229491720596949

Epoch: 5| Step: 9
Training loss: 1.935065507888794
Validation loss: 2.2242703388134637

Epoch: 5| Step: 10
Training loss: 1.4050328731536865
Validation loss: 2.219688485066096

Epoch: 5| Step: 11
Training loss: 1.5989209413528442
Validation loss: 2.226465826233228

Epoch: 271| Step: 0
Training loss: 1.5984840393066406
Validation loss: 2.217268317937851

Epoch: 5| Step: 1
Training loss: 1.8668172359466553
Validation loss: 2.2355280021826425

Epoch: 5| Step: 2
Training loss: 1.5444530248641968
Validation loss: 2.211186240116755

Epoch: 5| Step: 3
Training loss: 2.148515462875366
Validation loss: 2.2134764889876046

Epoch: 5| Step: 4
Training loss: 2.2279231548309326
Validation loss: 2.200742930173874

Epoch: 5| Step: 5
Training loss: 1.7288506031036377
Validation loss: 2.210248351097107

Epoch: 5| Step: 6
Training loss: 1.320103645324707
Validation loss: 2.2096047550439835

Epoch: 5| Step: 7
Training loss: 1.6059961318969727
Validation loss: 2.201986794670423

Epoch: 5| Step: 8
Training loss: 1.6011168956756592
Validation loss: 2.2027574578921

Epoch: 5| Step: 9
Training loss: 2.641343593597412
Validation loss: 2.2018172442913055

Epoch: 5| Step: 10
Training loss: 1.580643892288208
Validation loss: 2.1984146734078727

Epoch: 5| Step: 11
Training loss: 1.5114901065826416
Validation loss: 2.205511897802353

Epoch: 272| Step: 0
Training loss: 1.5131070613861084
Validation loss: 2.213291813929876

Epoch: 5| Step: 1
Training loss: 2.0894227027893066
Validation loss: 2.231365919113159

Epoch: 5| Step: 2
Training loss: 1.4170408248901367
Validation loss: 2.2641751170158386

Epoch: 5| Step: 3
Training loss: 1.7492778301239014
Validation loss: 2.250318929553032

Epoch: 5| Step: 4
Training loss: 1.9488166570663452
Validation loss: 2.254690865675608

Epoch: 5| Step: 5
Training loss: 1.6733951568603516
Validation loss: 2.250441163778305

Epoch: 5| Step: 6
Training loss: 1.5178849697113037
Validation loss: 2.256980543335279

Epoch: 5| Step: 7
Training loss: 1.7400825023651123
Validation loss: 2.2566463947296143

Epoch: 5| Step: 8
Training loss: 1.7476726770401
Validation loss: 2.2518358578284583

Epoch: 5| Step: 9
Training loss: 2.1982314586639404
Validation loss: 2.235000799099604

Epoch: 5| Step: 10
Training loss: 1.787825345993042
Validation loss: 2.217567647496859

Epoch: 5| Step: 11
Training loss: 2.6694207191467285
Validation loss: 2.2227356483538947

Epoch: 273| Step: 0
Training loss: 1.6713383197784424
Validation loss: 2.1989425172408423

Epoch: 5| Step: 1
Training loss: 1.5990407466888428
Validation loss: 2.1925612688064575

Epoch: 5| Step: 2
Training loss: 2.0170578956604004
Validation loss: 2.1851815780003867

Epoch: 5| Step: 3
Training loss: 2.149681568145752
Validation loss: 2.178817336757978

Epoch: 5| Step: 4
Training loss: 1.8157329559326172
Validation loss: 2.19951494038105

Epoch: 5| Step: 5
Training loss: 1.426027536392212
Validation loss: 2.2050613164901733

Epoch: 5| Step: 6
Training loss: 1.8154720067977905
Validation loss: 2.1811656256516776

Epoch: 5| Step: 7
Training loss: 1.665785551071167
Validation loss: 2.216613993048668

Epoch: 5| Step: 8
Training loss: 1.1797212362289429
Validation loss: 2.225471576054891

Epoch: 5| Step: 9
Training loss: 1.859967827796936
Validation loss: 2.2393955985705056

Epoch: 5| Step: 10
Training loss: 2.060838460922241
Validation loss: 2.2346499264240265

Epoch: 5| Step: 11
Training loss: 2.9926655292510986
Validation loss: 2.246477802594503

Epoch: 274| Step: 0
Training loss: 1.5522429943084717
Validation loss: 2.2252090672651925

Epoch: 5| Step: 1
Training loss: 2.0407052040100098
Validation loss: 2.2102574507395425

Epoch: 5| Step: 2
Training loss: 1.513118028640747
Validation loss: 2.199341207742691

Epoch: 5| Step: 3
Training loss: 2.1009533405303955
Validation loss: 2.2100298007329306

Epoch: 5| Step: 4
Training loss: 1.9680678844451904
Validation loss: 2.2205863992373147

Epoch: 5| Step: 5
Training loss: 1.5048515796661377
Validation loss: 2.219787130753199

Epoch: 5| Step: 6
Training loss: 1.7551968097686768
Validation loss: 2.1981047491232553

Epoch: 5| Step: 7
Training loss: 1.5697534084320068
Validation loss: 2.183305342992147

Epoch: 5| Step: 8
Training loss: 2.2996013164520264
Validation loss: 2.205744614203771

Epoch: 5| Step: 9
Training loss: 1.627765417098999
Validation loss: 2.197361409664154

Epoch: 5| Step: 10
Training loss: 1.464087963104248
Validation loss: 2.1913644621769586

Epoch: 5| Step: 11
Training loss: 1.586113452911377
Validation loss: 2.1977210541566214

Epoch: 275| Step: 0
Training loss: 1.4965311288833618
Validation loss: 2.1951008339722953

Epoch: 5| Step: 1
Training loss: 1.9647433757781982
Validation loss: 2.1901350915431976

Epoch: 5| Step: 2
Training loss: 1.718427300453186
Validation loss: 2.214080904920896

Epoch: 5| Step: 3
Training loss: 1.6135282516479492
Validation loss: 2.2081164369980493

Epoch: 5| Step: 4
Training loss: 1.957916259765625
Validation loss: 2.204712450504303

Epoch: 5| Step: 5
Training loss: 2.045358896255493
Validation loss: 2.201093236605326

Epoch: 5| Step: 6
Training loss: 1.3857885599136353
Validation loss: 2.1955811281998954

Epoch: 5| Step: 7
Training loss: 1.508201241493225
Validation loss: 2.1923849483331046

Epoch: 5| Step: 8
Training loss: 2.2075493335723877
Validation loss: 2.2049394448598227

Epoch: 5| Step: 9
Training loss: 1.5239225625991821
Validation loss: 2.210852012038231

Epoch: 5| Step: 10
Training loss: 1.9883594512939453
Validation loss: 2.201280896862348

Epoch: 5| Step: 11
Training loss: 2.2264151573181152
Validation loss: 2.193355749050776

Epoch: 276| Step: 0
Training loss: 1.735973596572876
Validation loss: 2.1853389342625937

Epoch: 5| Step: 1
Training loss: 2.2525336742401123
Validation loss: 2.146962270140648

Epoch: 5| Step: 2
Training loss: 1.7323696613311768
Validation loss: 2.135372449954351

Epoch: 5| Step: 3
Training loss: 1.7280887365341187
Validation loss: 2.130572626988093

Epoch: 5| Step: 4
Training loss: 1.4512382745742798
Validation loss: 2.128360023101171

Epoch: 5| Step: 5
Training loss: 1.8667675256729126
Validation loss: 2.1189107994238534

Epoch: 5| Step: 6
Training loss: 1.9429439306259155
Validation loss: 2.112003743648529

Epoch: 5| Step: 7
Training loss: 1.6392271518707275
Validation loss: 2.132595052321752

Epoch: 5| Step: 8
Training loss: 1.7443183660507202
Validation loss: 2.1377114951610565

Epoch: 5| Step: 9
Training loss: 2.3314757347106934
Validation loss: 2.1698072801033654

Epoch: 5| Step: 10
Training loss: 1.7779690027236938
Validation loss: 2.2023773243029914

Epoch: 5| Step: 11
Training loss: 1.3116295337677002
Validation loss: 2.178966964284579

Epoch: 277| Step: 0
Training loss: 1.8318397998809814
Validation loss: 2.216012269258499

Epoch: 5| Step: 1
Training loss: 2.0925559997558594
Validation loss: 2.233974874019623

Epoch: 5| Step: 2
Training loss: 2.2000930309295654
Validation loss: 2.2462091048558555

Epoch: 5| Step: 3
Training loss: 2.325453042984009
Validation loss: 2.239373524983724

Epoch: 5| Step: 4
Training loss: 1.539921760559082
Validation loss: 2.2361672719319663

Epoch: 5| Step: 5
Training loss: 1.837442398071289
Validation loss: 2.2262769639492035

Epoch: 5| Step: 6
Training loss: 1.716831922531128
Validation loss: 2.204783707857132

Epoch: 5| Step: 7
Training loss: 1.7154664993286133
Validation loss: 2.166027784347534

Epoch: 5| Step: 8
Training loss: 1.7781898975372314
Validation loss: 2.135502442717552

Epoch: 5| Step: 9
Training loss: 1.3033668994903564
Validation loss: 2.1319289008776345

Epoch: 5| Step: 10
Training loss: 2.113010883331299
Validation loss: 2.1317036052544913

Epoch: 5| Step: 11
Training loss: 1.9703078269958496
Validation loss: 2.12752436598142

Epoch: 278| Step: 0
Training loss: 1.4291980266571045
Validation loss: 2.1325260450442634

Epoch: 5| Step: 1
Training loss: 2.3126158714294434
Validation loss: 2.1312297930320105

Epoch: 5| Step: 2
Training loss: 1.7811698913574219
Validation loss: 2.1548554996649423

Epoch: 5| Step: 3
Training loss: 1.8120924234390259
Validation loss: 2.170533458391825

Epoch: 5| Step: 4
Training loss: 1.448807954788208
Validation loss: 2.1974488496780396

Epoch: 5| Step: 5
Training loss: 1.5433156490325928
Validation loss: 2.1995889097452164

Epoch: 5| Step: 6
Training loss: 2.0216941833496094
Validation loss: 2.2305710713068643

Epoch: 5| Step: 7
Training loss: 1.915395736694336
Validation loss: 2.2606959293286004

Epoch: 5| Step: 8
Training loss: 1.9283568859100342
Validation loss: 2.2390717466672263

Epoch: 5| Step: 9
Training loss: 2.244676113128662
Validation loss: 2.2773695637782416

Epoch: 5| Step: 10
Training loss: 1.5090166330337524
Validation loss: 2.285216470559438

Epoch: 5| Step: 11
Training loss: 0.8343254923820496
Validation loss: 2.2801988075176873

Epoch: 279| Step: 0
Training loss: 1.8572235107421875
Validation loss: 2.2530973007281623

Epoch: 5| Step: 1
Training loss: 2.0830349922180176
Validation loss: 2.2401467065016427

Epoch: 5| Step: 2
Training loss: 2.0997085571289062
Validation loss: 2.2344492375850677

Epoch: 5| Step: 3
Training loss: 1.627779245376587
Validation loss: 2.2021278937657676

Epoch: 5| Step: 4
Training loss: 2.018087863922119
Validation loss: 2.1736725022395453

Epoch: 5| Step: 5
Training loss: 1.490208387374878
Validation loss: 2.159577657779058

Epoch: 5| Step: 6
Training loss: 1.4400831460952759
Validation loss: 2.1637832125027976

Epoch: 5| Step: 7
Training loss: 1.558138132095337
Validation loss: 2.1416801859935126

Epoch: 5| Step: 8
Training loss: 1.6218894720077515
Validation loss: 2.162808616956075

Epoch: 5| Step: 9
Training loss: 2.058973789215088
Validation loss: 2.151097451647123

Epoch: 5| Step: 10
Training loss: 1.8878679275512695
Validation loss: 2.161719505985578

Epoch: 5| Step: 11
Training loss: 0.8915129899978638
Validation loss: 2.1528566082318625

Epoch: 280| Step: 0
Training loss: 1.5817890167236328
Validation loss: 2.1608648200829825

Epoch: 5| Step: 1
Training loss: 2.82342529296875
Validation loss: 2.175426463286082

Epoch: 5| Step: 2
Training loss: 1.8316497802734375
Validation loss: 2.1694780637820563

Epoch: 5| Step: 3
Training loss: 1.755759835243225
Validation loss: 2.170439913868904

Epoch: 5| Step: 4
Training loss: 1.6600396633148193
Validation loss: 2.168267240126928

Epoch: 5| Step: 5
Training loss: 1.7689111232757568
Validation loss: 2.180643320083618

Epoch: 5| Step: 6
Training loss: 1.6314265727996826
Validation loss: 2.1839290459950766

Epoch: 5| Step: 7
Training loss: 1.5242643356323242
Validation loss: 2.2077419261137643

Epoch: 5| Step: 8
Training loss: 1.429000735282898
Validation loss: 2.202181339263916

Epoch: 5| Step: 9
Training loss: 1.6929748058319092
Validation loss: 2.2023237546284995

Epoch: 5| Step: 10
Training loss: 1.6889522075653076
Validation loss: 2.1999296446641288

Epoch: 5| Step: 11
Training loss: 1.3612675666809082
Validation loss: 2.2168705066045127

Epoch: 281| Step: 0
Training loss: 1.9793851375579834
Validation loss: 2.196533511082331

Epoch: 5| Step: 1
Training loss: 1.397718906402588
Validation loss: 2.2057953774929047

Epoch: 5| Step: 2
Training loss: 1.8921031951904297
Validation loss: 2.172514423727989

Epoch: 5| Step: 3
Training loss: 2.0828099250793457
Validation loss: 2.1916604141394296

Epoch: 5| Step: 4
Training loss: 1.713129997253418
Validation loss: 2.1798510402441025

Epoch: 5| Step: 5
Training loss: 2.0031237602233887
Validation loss: 2.172442783912023

Epoch: 5| Step: 6
Training loss: 1.3542771339416504
Validation loss: 2.1722703526417413

Epoch: 5| Step: 7
Training loss: 1.4115594625473022
Validation loss: 2.157620668411255

Epoch: 5| Step: 8
Training loss: 1.8460867404937744
Validation loss: 2.164114644130071

Epoch: 5| Step: 9
Training loss: 2.159039258956909
Validation loss: 2.189079761505127

Epoch: 5| Step: 10
Training loss: 1.3092912435531616
Validation loss: 2.1938555389642715

Epoch: 5| Step: 11
Training loss: 2.630143165588379
Validation loss: 2.183252384265264

Epoch: 282| Step: 0
Training loss: 2.656726121902466
Validation loss: 2.1910178611675897

Epoch: 5| Step: 1
Training loss: 2.034878969192505
Validation loss: 2.228509118159612

Epoch: 5| Step: 2
Training loss: 2.387363910675049
Validation loss: 2.231713483730952

Epoch: 5| Step: 3
Training loss: 1.500915288925171
Validation loss: 2.215404291947683

Epoch: 5| Step: 4
Training loss: 1.789792776107788
Validation loss: 2.2481127182642617

Epoch: 5| Step: 5
Training loss: 1.397148847579956
Validation loss: 2.2142135401566825

Epoch: 5| Step: 6
Training loss: 1.2783647775650024
Validation loss: 2.1962814976771674

Epoch: 5| Step: 7
Training loss: 1.4125479459762573
Validation loss: 2.2166232764720917

Epoch: 5| Step: 8
Training loss: 2.0030031204223633
Validation loss: 2.179689491788546

Epoch: 5| Step: 9
Training loss: 1.7286670207977295
Validation loss: 2.1723400950431824

Epoch: 5| Step: 10
Training loss: 1.2449519634246826
Validation loss: 2.1699822743733725

Epoch: 5| Step: 11
Training loss: 1.1429102420806885
Validation loss: 2.159743915001551

Epoch: 283| Step: 0
Training loss: 2.069416046142578
Validation loss: 2.1880952566862106

Epoch: 5| Step: 1
Training loss: 1.4067363739013672
Validation loss: 2.1882871886094413

Epoch: 5| Step: 2
Training loss: 2.863579511642456
Validation loss: 2.2434296756982803

Epoch: 5| Step: 3
Training loss: 1.360426664352417
Validation loss: 2.244616001844406

Epoch: 5| Step: 4
Training loss: 1.7765449285507202
Validation loss: 2.2207667330900827

Epoch: 5| Step: 5
Training loss: 1.7216981649398804
Validation loss: 2.236940731604894

Epoch: 5| Step: 6
Training loss: 1.435591220855713
Validation loss: 2.246795172492663

Epoch: 5| Step: 7
Training loss: 2.018082857131958
Validation loss: 2.2078532675902047

Epoch: 5| Step: 8
Training loss: 1.7591211795806885
Validation loss: 2.2096732507149377

Epoch: 5| Step: 9
Training loss: 1.8195228576660156
Validation loss: 2.192327360312144

Epoch: 5| Step: 10
Training loss: 1.2573051452636719
Validation loss: 2.2133527348438897

Epoch: 5| Step: 11
Training loss: 1.1724066734313965
Validation loss: 2.205720439553261

Epoch: 284| Step: 0
Training loss: 2.142043352127075
Validation loss: 2.2142197291056314

Epoch: 5| Step: 1
Training loss: 1.4743626117706299
Validation loss: 2.183672289053599

Epoch: 5| Step: 2
Training loss: 1.5869604349136353
Validation loss: 2.2357865621646247

Epoch: 5| Step: 3
Training loss: 2.4301483631134033
Validation loss: 2.2370663384596505

Epoch: 5| Step: 4
Training loss: 1.6037921905517578
Validation loss: 2.2347458551327386

Epoch: 5| Step: 5
Training loss: 1.5685940980911255
Validation loss: 2.2275183399518332

Epoch: 5| Step: 6
Training loss: 1.6159133911132812
Validation loss: 2.23460291326046

Epoch: 5| Step: 7
Training loss: 1.3073170185089111
Validation loss: 2.2213578124841056

Epoch: 5| Step: 8
Training loss: 2.0820934772491455
Validation loss: 2.2492621342341104

Epoch: 5| Step: 9
Training loss: 1.218868613243103
Validation loss: 2.24260775744915

Epoch: 5| Step: 10
Training loss: 2.257883071899414
Validation loss: 2.2104804615179696

Epoch: 5| Step: 11
Training loss: 1.761857271194458
Validation loss: 2.1958371798197427

Epoch: 285| Step: 0
Training loss: 1.4235143661499023
Validation loss: 2.208436052004496

Epoch: 5| Step: 1
Training loss: 1.8565133810043335
Validation loss: 2.2283992866675058

Epoch: 5| Step: 2
Training loss: 1.5259113311767578
Validation loss: 2.2017058531443277

Epoch: 5| Step: 3
Training loss: 1.6151424646377563
Validation loss: 2.20585065583388

Epoch: 5| Step: 4
Training loss: 1.8980461359024048
Validation loss: 2.2191734512646994

Epoch: 5| Step: 5
Training loss: 2.3101558685302734
Validation loss: 2.221123993396759

Epoch: 5| Step: 6
Training loss: 1.1588528156280518
Validation loss: 2.2038240085045495

Epoch: 5| Step: 7
Training loss: 1.849475622177124
Validation loss: 2.1996349692344666

Epoch: 5| Step: 8
Training loss: 1.752012014389038
Validation loss: 2.19478810330232

Epoch: 5| Step: 9
Training loss: 1.7014095783233643
Validation loss: 2.2072715361913047

Epoch: 5| Step: 10
Training loss: 1.772631049156189
Validation loss: 2.194333463907242

Epoch: 5| Step: 11
Training loss: 2.255012273788452
Validation loss: 2.201073298851649

Epoch: 286| Step: 0
Training loss: 1.4242289066314697
Validation loss: 2.1945312917232513

Epoch: 5| Step: 1
Training loss: 1.7331962585449219
Validation loss: 2.2035528967777886

Epoch: 5| Step: 2
Training loss: 1.5626013278961182
Validation loss: 2.1904973636070886

Epoch: 5| Step: 3
Training loss: 2.151477336883545
Validation loss: 2.198511282602946

Epoch: 5| Step: 4
Training loss: 1.7909595966339111
Validation loss: 2.1771092216173806

Epoch: 5| Step: 5
Training loss: 2.0372753143310547
Validation loss: 2.162932336330414

Epoch: 5| Step: 6
Training loss: 1.80683171749115
Validation loss: 2.1735371351242065

Epoch: 5| Step: 7
Training loss: 1.5128045082092285
Validation loss: 2.1538930783669152

Epoch: 5| Step: 8
Training loss: 1.5177335739135742
Validation loss: 2.1686041802167892

Epoch: 5| Step: 9
Training loss: 1.7609426975250244
Validation loss: 2.187994251648585

Epoch: 5| Step: 10
Training loss: 1.7091872692108154
Validation loss: 2.214195966720581

Epoch: 5| Step: 11
Training loss: 1.942216157913208
Validation loss: 2.227616310119629

Epoch: 287| Step: 0
Training loss: 2.141430616378784
Validation loss: 2.2276873687903085

Epoch: 5| Step: 1
Training loss: 1.661389946937561
Validation loss: 2.250124712785085

Epoch: 5| Step: 2
Training loss: 1.4794509410858154
Validation loss: 2.2514986395835876

Epoch: 5| Step: 3
Training loss: 2.2860450744628906
Validation loss: 2.2429706354935965

Epoch: 5| Step: 4
Training loss: 1.5406122207641602
Validation loss: 2.248697981238365

Epoch: 5| Step: 5
Training loss: 1.6391319036483765
Validation loss: 2.259347508351008

Epoch: 5| Step: 6
Training loss: 1.4862117767333984
Validation loss: 2.2291299800078073

Epoch: 5| Step: 7
Training loss: 1.4832299947738647
Validation loss: 2.2248712331056595

Epoch: 5| Step: 8
Training loss: 1.9942190647125244
Validation loss: 2.1796053101619086

Epoch: 5| Step: 9
Training loss: 1.9918639659881592
Validation loss: 2.1761823693911233

Epoch: 5| Step: 10
Training loss: 1.6121251583099365
Validation loss: 2.1430589109659195

Epoch: 5| Step: 11
Training loss: 1.432963252067566
Validation loss: 2.139735927184423

Epoch: 288| Step: 0
Training loss: 1.9155919551849365
Validation loss: 2.1516042898098626

Epoch: 5| Step: 1
Training loss: 1.7022755146026611
Validation loss: 2.1619109213352203

Epoch: 5| Step: 2
Training loss: 1.6076644659042358
Validation loss: 2.1898245066404343

Epoch: 5| Step: 3
Training loss: 1.4111706018447876
Validation loss: 2.2107280592123666

Epoch: 5| Step: 4
Training loss: 1.513673186302185
Validation loss: 2.2326683898766837

Epoch: 5| Step: 5
Training loss: 1.7500755786895752
Validation loss: 2.2820342431465783

Epoch: 5| Step: 6
Training loss: 1.5211690664291382
Validation loss: 2.238383173942566

Epoch: 5| Step: 7
Training loss: 1.6839700937271118
Validation loss: 2.266283248861631

Epoch: 5| Step: 8
Training loss: 1.5485904216766357
Validation loss: 2.2498796035846076

Epoch: 5| Step: 9
Training loss: 2.019214153289795
Validation loss: 2.277864476044973

Epoch: 5| Step: 10
Training loss: 2.6165413856506348
Validation loss: 2.250821148355802

Epoch: 5| Step: 11
Training loss: 1.0075920820236206
Validation loss: 2.2671231478452682

Epoch: 289| Step: 0
Training loss: 1.8326879739761353
Validation loss: 2.2421983579794564

Epoch: 5| Step: 1
Training loss: 2.2039051055908203
Validation loss: 2.2271594355503717

Epoch: 5| Step: 2
Training loss: 1.5671124458312988
Validation loss: 2.2275647024313607

Epoch: 5| Step: 3
Training loss: 1.650610327720642
Validation loss: 2.186414912343025

Epoch: 5| Step: 4
Training loss: 1.2975636720657349
Validation loss: 2.2140758583943048

Epoch: 5| Step: 5
Training loss: 2.1511943340301514
Validation loss: 2.1645812590916953

Epoch: 5| Step: 6
Training loss: 1.6943258047103882
Validation loss: 2.1722146421670914

Epoch: 5| Step: 7
Training loss: 1.8699105978012085
Validation loss: 2.1995212187369666

Epoch: 5| Step: 8
Training loss: 1.6159498691558838
Validation loss: 2.2016078482071557

Epoch: 5| Step: 9
Training loss: 1.2727277278900146
Validation loss: 2.219782849152883

Epoch: 5| Step: 10
Training loss: 1.954811453819275
Validation loss: 2.243338098128637

Epoch: 5| Step: 11
Training loss: 1.6489289999008179
Validation loss: 2.2432901908953986

Epoch: 290| Step: 0
Training loss: 1.5564382076263428
Validation loss: 2.2314178943634033

Epoch: 5| Step: 1
Training loss: 1.3196001052856445
Validation loss: 2.226029877861341

Epoch: 5| Step: 2
Training loss: 2.3829102516174316
Validation loss: 2.2039599468310676

Epoch: 5| Step: 3
Training loss: 1.2790526151657104
Validation loss: 2.2249125639597573

Epoch: 5| Step: 4
Training loss: 1.505167007446289
Validation loss: 2.250020603338877

Epoch: 5| Step: 5
Training loss: 2.05875563621521
Validation loss: 2.2294260958830514

Epoch: 5| Step: 6
Training loss: 1.6680084466934204
Validation loss: 2.204146072268486

Epoch: 5| Step: 7
Training loss: 1.5522935390472412
Validation loss: 2.1884320278962455

Epoch: 5| Step: 8
Training loss: 1.6971479654312134
Validation loss: 2.181221142411232

Epoch: 5| Step: 9
Training loss: 2.1157422065734863
Validation loss: 2.173966725667318

Epoch: 5| Step: 10
Training loss: 1.686057448387146
Validation loss: 2.1881060252587

Epoch: 5| Step: 11
Training loss: 0.9330451488494873
Validation loss: 2.1925173898537955

Epoch: 291| Step: 0
Training loss: 1.5723943710327148
Validation loss: 2.182763030131658

Epoch: 5| Step: 1
Training loss: 1.3298523426055908
Validation loss: 2.180984228849411

Epoch: 5| Step: 2
Training loss: 1.3345946073532104
Validation loss: 2.21369261542956

Epoch: 5| Step: 3
Training loss: 0.9855012893676758
Validation loss: 2.1923921505610147

Epoch: 5| Step: 4
Training loss: 3.0350253582000732
Validation loss: 2.21853073934714

Epoch: 5| Step: 5
Training loss: 2.167595386505127
Validation loss: 2.2404868602752686

Epoch: 5| Step: 6
Training loss: 1.4769257307052612
Validation loss: 2.2716340174277625

Epoch: 5| Step: 7
Training loss: 2.368229866027832
Validation loss: 2.2843791941801705

Epoch: 5| Step: 8
Training loss: 1.7002874612808228
Validation loss: 2.282393525044123

Epoch: 5| Step: 9
Training loss: 2.0304598808288574
Validation loss: 2.266034891208013

Epoch: 5| Step: 10
Training loss: 1.3923604488372803
Validation loss: 2.2509128550688424

Epoch: 5| Step: 11
Training loss: 1.4030578136444092
Validation loss: 2.239392042160034

Epoch: 292| Step: 0
Training loss: 1.7241909503936768
Validation loss: 2.182221680879593

Epoch: 5| Step: 1
Training loss: 1.742816686630249
Validation loss: 2.1835211912790933

Epoch: 5| Step: 2
Training loss: 1.9274988174438477
Validation loss: 2.205778752764066

Epoch: 5| Step: 3
Training loss: 1.9803005456924438
Validation loss: 2.1814359575510025

Epoch: 5| Step: 4
Training loss: 1.4970682859420776
Validation loss: 2.1843150009711585

Epoch: 5| Step: 5
Training loss: 1.5043084621429443
Validation loss: 2.1933637162049613

Epoch: 5| Step: 6
Training loss: 1.8714511394500732
Validation loss: 2.196841686964035

Epoch: 5| Step: 7
Training loss: 1.5446847677230835
Validation loss: 2.2056942532459893

Epoch: 5| Step: 8
Training loss: 1.2887027263641357
Validation loss: 2.2087975839773812

Epoch: 5| Step: 9
Training loss: 2.0123238563537598
Validation loss: 2.2321467896302543

Epoch: 5| Step: 10
Training loss: 1.7343072891235352
Validation loss: 2.2528366446495056

Epoch: 5| Step: 11
Training loss: 2.37369704246521
Validation loss: 2.239389643073082

Epoch: 293| Step: 0
Training loss: 2.1198618412017822
Validation loss: 2.2502586096525192

Epoch: 5| Step: 1
Training loss: 1.3146419525146484
Validation loss: 2.2236416141192117

Epoch: 5| Step: 2
Training loss: 1.6970274448394775
Validation loss: 2.227222055196762

Epoch: 5| Step: 3
Training loss: 1.5092146396636963
Validation loss: 2.222340375185013

Epoch: 5| Step: 4
Training loss: 2.1371591091156006
Validation loss: 2.2362831830978394

Epoch: 5| Step: 5
Training loss: 1.4589675664901733
Validation loss: 2.244061087568601

Epoch: 5| Step: 6
Training loss: 1.8387409448623657
Validation loss: 2.2264284640550613

Epoch: 5| Step: 7
Training loss: 2.1681950092315674
Validation loss: 2.2171196192502975

Epoch: 5| Step: 8
Training loss: 1.0534428358078003
Validation loss: 2.2329065253337226

Epoch: 5| Step: 9
Training loss: 1.7914308309555054
Validation loss: 2.225180764993032

Epoch: 5| Step: 10
Training loss: 1.7940826416015625
Validation loss: 2.2089670250813165

Epoch: 5| Step: 11
Training loss: 1.4571274518966675
Validation loss: 2.244212140639623

Epoch: 294| Step: 0
Training loss: 1.6792380809783936
Validation loss: 2.244276533524195

Epoch: 5| Step: 1
Training loss: 1.5944430828094482
Validation loss: 2.251619423429171

Epoch: 5| Step: 2
Training loss: 1.7237560749053955
Validation loss: 2.240210389097532

Epoch: 5| Step: 3
Training loss: 1.369158387184143
Validation loss: 2.2751867969830832

Epoch: 5| Step: 4
Training loss: 1.8067430257797241
Validation loss: 2.2820036907990775

Epoch: 5| Step: 5
Training loss: 2.1517324447631836
Validation loss: 2.289580454428991

Epoch: 5| Step: 6
Training loss: 1.6109817028045654
Validation loss: 2.2569908450047174

Epoch: 5| Step: 7
Training loss: 1.9175384044647217
Validation loss: 2.265354702870051

Epoch: 5| Step: 8
Training loss: 1.5630759000778198
Validation loss: 2.285517781972885

Epoch: 5| Step: 9
Training loss: 1.7335666418075562
Validation loss: 2.2519873778025308

Epoch: 5| Step: 10
Training loss: 1.4704101085662842
Validation loss: 2.262394075592359

Epoch: 5| Step: 11
Training loss: 2.2141690254211426
Validation loss: 2.2105714976787567

Epoch: 295| Step: 0
Training loss: 1.5281312465667725
Validation loss: 2.207719544569651

Epoch: 5| Step: 1
Training loss: 1.664419412612915
Validation loss: 2.191928520798683

Epoch: 5| Step: 2
Training loss: 1.4871207475662231
Validation loss: 2.1554069072008133

Epoch: 5| Step: 3
Training loss: 2.157757520675659
Validation loss: 2.184758424758911

Epoch: 5| Step: 4
Training loss: 1.7674669027328491
Validation loss: 2.1856617530186973

Epoch: 5| Step: 5
Training loss: 1.9109725952148438
Validation loss: 2.2202913711468377

Epoch: 5| Step: 6
Training loss: 1.2756030559539795
Validation loss: 2.2422877003749213

Epoch: 5| Step: 7
Training loss: 2.036271333694458
Validation loss: 2.230153222878774

Epoch: 5| Step: 8
Training loss: 1.5757648944854736
Validation loss: 2.25938950975736

Epoch: 5| Step: 9
Training loss: 1.5630850791931152
Validation loss: 2.2460367679595947

Epoch: 5| Step: 10
Training loss: 1.6437021493911743
Validation loss: 2.2736610621213913

Epoch: 5| Step: 11
Training loss: 1.6952389478683472
Validation loss: 2.248311107357343

Epoch: 296| Step: 0
Training loss: 1.6947987079620361
Validation loss: 2.257106522719065

Epoch: 5| Step: 1
Training loss: 1.3297749757766724
Validation loss: 2.2462939421335855

Epoch: 5| Step: 2
Training loss: 1.929305076599121
Validation loss: 2.2443475822607675

Epoch: 5| Step: 3
Training loss: 1.1644225120544434
Validation loss: 2.242107833425204

Epoch: 5| Step: 4
Training loss: 1.4976370334625244
Validation loss: 2.2420672277609506

Epoch: 5| Step: 5
Training loss: 1.0901240110397339
Validation loss: 2.2656726042429605

Epoch: 5| Step: 6
Training loss: 1.6635030508041382
Validation loss: 2.2450169722239175

Epoch: 5| Step: 7
Training loss: 1.9832055568695068
Validation loss: 2.249112288157145

Epoch: 5| Step: 8
Training loss: 2.119131565093994
Validation loss: 2.2360035181045532

Epoch: 5| Step: 9
Training loss: 2.045889377593994
Validation loss: 2.218873287240664

Epoch: 5| Step: 10
Training loss: 1.9506515264511108
Validation loss: 2.2175478786230087

Epoch: 5| Step: 11
Training loss: 2.5351345539093018
Validation loss: 2.208671897649765

Epoch: 297| Step: 0
Training loss: 1.4917157888412476
Validation loss: 2.243693540493647

Epoch: 5| Step: 1
Training loss: 1.7566728591918945
Validation loss: 2.24341111878554

Epoch: 5| Step: 2
Training loss: 1.9837239980697632
Validation loss: 2.269843508799871

Epoch: 5| Step: 3
Training loss: 2.0359671115875244
Validation loss: 2.263617624839147

Epoch: 5| Step: 4
Training loss: 1.9675909280776978
Validation loss: 2.2553138782580695

Epoch: 5| Step: 5
Training loss: 1.7312116622924805
Validation loss: 2.2501626114050546

Epoch: 5| Step: 6
Training loss: 1.7314285039901733
Validation loss: 2.2445730715990067

Epoch: 5| Step: 7
Training loss: 1.6239150762557983
Validation loss: 2.2377415001392365

Epoch: 5| Step: 8
Training loss: 1.3035812377929688
Validation loss: 2.2250137825806937

Epoch: 5| Step: 9
Training loss: 1.47458016872406
Validation loss: 2.2115348825852075

Epoch: 5| Step: 10
Training loss: 1.867069959640503
Validation loss: 2.207256014148394

Epoch: 5| Step: 11
Training loss: 2.0433411598205566
Validation loss: 2.1937604496876397

Epoch: 298| Step: 0
Training loss: 1.9699163436889648
Validation loss: 2.2018828938404718

Epoch: 5| Step: 1
Training loss: 1.9652725458145142
Validation loss: 2.1538742830355964

Epoch: 5| Step: 2
Training loss: 1.897684097290039
Validation loss: 2.1911897361278534

Epoch: 5| Step: 3
Training loss: 1.5574958324432373
Validation loss: 2.191922754049301

Epoch: 5| Step: 4
Training loss: 1.395999550819397
Validation loss: 2.243191490570704

Epoch: 5| Step: 5
Training loss: 2.315507173538208
Validation loss: 2.2606462041536965

Epoch: 5| Step: 6
Training loss: 2.0216732025146484
Validation loss: 2.268038327495257

Epoch: 5| Step: 7
Training loss: 1.4306938648223877
Validation loss: 2.290385882059733

Epoch: 5| Step: 8
Training loss: 1.771063208580017
Validation loss: 2.2989409466584525

Epoch: 5| Step: 9
Training loss: 1.8819061517715454
Validation loss: 2.2868826587994895

Epoch: 5| Step: 10
Training loss: 1.2658523321151733
Validation loss: 2.266447052359581

Epoch: 5| Step: 11
Training loss: 1.048767328262329
Validation loss: 2.2725585599740348

Epoch: 299| Step: 0
Training loss: 1.6667152643203735
Validation loss: 2.240958740313848

Epoch: 5| Step: 1
Training loss: 1.9500482082366943
Validation loss: 2.2526837488015494

Epoch: 5| Step: 2
Training loss: 1.451338529586792
Validation loss: 2.238575508197149

Epoch: 5| Step: 3
Training loss: 1.7303203344345093
Validation loss: 2.185918559630712

Epoch: 5| Step: 4
Training loss: 2.242659330368042
Validation loss: 2.182323088248571

Epoch: 5| Step: 5
Training loss: 1.0883053541183472
Validation loss: 2.188182314236959

Epoch: 5| Step: 6
Training loss: 1.385313630104065
Validation loss: 2.178817391395569

Epoch: 5| Step: 7
Training loss: 1.5146528482437134
Validation loss: 2.1676749338706336

Epoch: 5| Step: 8
Training loss: 1.8352781534194946
Validation loss: 2.1864629785219827

Epoch: 5| Step: 9
Training loss: 2.624532461166382
Validation loss: 2.1783733119567237

Epoch: 5| Step: 10
Training loss: 1.5080904960632324
Validation loss: 2.194549103577932

Epoch: 5| Step: 11
Training loss: 0.9712783098220825
Validation loss: 2.195693408449491

Epoch: 300| Step: 0
Training loss: 1.4180328845977783
Validation loss: 2.2281450877587

Epoch: 5| Step: 1
Training loss: 1.3090845346450806
Validation loss: 2.2239428063233695

Epoch: 5| Step: 2
Training loss: 1.8529365062713623
Validation loss: 2.2362968573967614

Epoch: 5| Step: 3
Training loss: 2.1469919681549072
Validation loss: 2.229032481710116

Epoch: 5| Step: 4
Training loss: 1.7623999118804932
Validation loss: 2.2306063224871955

Epoch: 5| Step: 5
Training loss: 1.2783911228179932
Validation loss: 2.2270218630631766

Epoch: 5| Step: 6
Training loss: 1.7611675262451172
Validation loss: 2.200168510278066

Epoch: 5| Step: 7
Training loss: 1.881344199180603
Validation loss: 2.183650011817614

Epoch: 5| Step: 8
Training loss: 1.8408985137939453
Validation loss: 2.1830439368883767

Epoch: 5| Step: 9
Training loss: 1.4794961214065552
Validation loss: 2.1824362675348916

Epoch: 5| Step: 10
Training loss: 2.3476314544677734
Validation loss: 2.1876544803380966

Epoch: 5| Step: 11
Training loss: 1.4742769002914429
Validation loss: 2.20038540661335

Epoch: 301| Step: 0
Training loss: 1.9160051345825195
Validation loss: 2.1897167563438416

Epoch: 5| Step: 1
Training loss: 1.6140937805175781
Validation loss: 2.189799423019091

Epoch: 5| Step: 2
Training loss: 1.9658044576644897
Validation loss: 2.182188560565313

Epoch: 5| Step: 3
Training loss: 1.8037841320037842
Validation loss: 2.204022169113159

Epoch: 5| Step: 4
Training loss: 1.7248432636260986
Validation loss: 2.242811823884646

Epoch: 5| Step: 5
Training loss: 1.6382644176483154
Validation loss: 2.223988691965739

Epoch: 5| Step: 6
Training loss: 1.6132274866104126
Validation loss: 2.2501166512568793

Epoch: 5| Step: 7
Training loss: 1.8943519592285156
Validation loss: 2.2407087087631226

Epoch: 5| Step: 8
Training loss: 1.1192060708999634
Validation loss: 2.2383287449677787

Epoch: 5| Step: 9
Training loss: 2.3334853649139404
Validation loss: 2.2181150813897452

Epoch: 5| Step: 10
Training loss: 1.9960730075836182
Validation loss: 2.2408300886551538

Epoch: 5| Step: 11
Training loss: 0.5220437049865723
Validation loss: 2.2393402059872947

Epoch: 302| Step: 0
Training loss: 2.1597025394439697
Validation loss: 2.229147886236509

Epoch: 5| Step: 1
Training loss: 1.6866432428359985
Validation loss: 2.2209760497013726

Epoch: 5| Step: 2
Training loss: 1.9100620746612549
Validation loss: 2.2114322235186896

Epoch: 5| Step: 3
Training loss: 1.3168658018112183
Validation loss: 2.207892209291458

Epoch: 5| Step: 4
Training loss: 1.7231476306915283
Validation loss: 2.200344150265058

Epoch: 5| Step: 5
Training loss: 1.7418606281280518
Validation loss: 2.2029663572708764

Epoch: 5| Step: 6
Training loss: 2.0444483757019043
Validation loss: 2.1814657549063363

Epoch: 5| Step: 7
Training loss: 1.6218974590301514
Validation loss: 2.1820575892925262

Epoch: 5| Step: 8
Training loss: 1.5092017650604248
Validation loss: 2.1936380664507547

Epoch: 5| Step: 9
Training loss: 1.6436741352081299
Validation loss: 2.1937675029039383

Epoch: 5| Step: 10
Training loss: 1.3789047002792358
Validation loss: 2.1834129691123962

Epoch: 5| Step: 11
Training loss: 1.280071496963501
Validation loss: 2.1821773648262024

Epoch: 303| Step: 0
Training loss: 1.283785104751587
Validation loss: 2.1767286459604898

Epoch: 5| Step: 1
Training loss: 1.8712966442108154
Validation loss: 2.229959691564242

Epoch: 5| Step: 2
Training loss: 1.8423664569854736
Validation loss: 2.2194844583670297

Epoch: 5| Step: 3
Training loss: 1.5076521635055542
Validation loss: 2.2223758598168692

Epoch: 5| Step: 4
Training loss: 1.839739203453064
Validation loss: 2.224394977092743

Epoch: 5| Step: 5
Training loss: 1.9376217126846313
Validation loss: 2.2203244318564734

Epoch: 5| Step: 6
Training loss: 2.1611647605895996
Validation loss: 2.2350574135780334

Epoch: 5| Step: 7
Training loss: 1.4051239490509033
Validation loss: 2.2428265313307443

Epoch: 5| Step: 8
Training loss: 1.5511656999588013
Validation loss: 2.238578865925471

Epoch: 5| Step: 9
Training loss: 1.6355822086334229
Validation loss: 2.2192172010739646

Epoch: 5| Step: 10
Training loss: 1.0679725408554077
Validation loss: 2.2337209781010947

Epoch: 5| Step: 11
Training loss: 2.2609314918518066
Validation loss: 2.216244359811147

Epoch: 304| Step: 0
Training loss: 2.286780595779419
Validation loss: 2.2267846167087555

Epoch: 5| Step: 1
Training loss: 1.6746432781219482
Validation loss: 2.2580517729123435

Epoch: 5| Step: 2
Training loss: 2.011714220046997
Validation loss: 2.2438511550426483

Epoch: 5| Step: 3
Training loss: 1.6837866306304932
Validation loss: 2.246244966983795

Epoch: 5| Step: 4
Training loss: 1.1972957849502563
Validation loss: 2.2384066432714462

Epoch: 5| Step: 5
Training loss: 1.7922252416610718
Validation loss: 2.238490119576454

Epoch: 5| Step: 6
Training loss: 1.6056060791015625
Validation loss: 2.236623470981916

Epoch: 5| Step: 7
Training loss: 1.273305892944336
Validation loss: 2.2364953011274338

Epoch: 5| Step: 8
Training loss: 1.770634412765503
Validation loss: 2.2382119794686637

Epoch: 5| Step: 9
Training loss: 1.4572513103485107
Validation loss: 2.214761435985565

Epoch: 5| Step: 10
Training loss: 1.4651234149932861
Validation loss: 2.2113142212231955

Epoch: 5| Step: 11
Training loss: 2.4849367141723633
Validation loss: 2.2251165906588235

Epoch: 305| Step: 0
Training loss: 1.5181031227111816
Validation loss: 2.2128820518652597

Epoch: 5| Step: 1
Training loss: 1.6835107803344727
Validation loss: 2.2099655171235404

Epoch: 5| Step: 2
Training loss: 2.008937358856201
Validation loss: 2.179873322447141

Epoch: 5| Step: 3
Training loss: 2.150979518890381
Validation loss: 2.195489823818207

Epoch: 5| Step: 4
Training loss: 2.126748561859131
Validation loss: 2.194617489973704

Epoch: 5| Step: 5
Training loss: 1.498342514038086
Validation loss: 2.199327806631724

Epoch: 5| Step: 6
Training loss: 0.912736713886261
Validation loss: 2.213663026690483

Epoch: 5| Step: 7
Training loss: 1.279902458190918
Validation loss: 2.2266221046447754

Epoch: 5| Step: 8
Training loss: 1.3667140007019043
Validation loss: 2.2298914194107056

Epoch: 5| Step: 9
Training loss: 2.4025990962982178
Validation loss: 2.258406236767769

Epoch: 5| Step: 10
Training loss: 1.2155883312225342
Validation loss: 2.2351931830247245

Epoch: 5| Step: 11
Training loss: 0.9389541149139404
Validation loss: 2.2523913184801736

Epoch: 306| Step: 0
Training loss: 1.1580984592437744
Validation loss: 2.2413148085276284

Epoch: 5| Step: 1
Training loss: 1.3409092426300049
Validation loss: 2.248656620581945

Epoch: 5| Step: 2
Training loss: 1.1956367492675781
Validation loss: 2.2409625252087912

Epoch: 5| Step: 3
Training loss: 2.1710216999053955
Validation loss: 2.215705161293348

Epoch: 5| Step: 4
Training loss: 2.3804824352264404
Validation loss: 2.2222335636615753

Epoch: 5| Step: 5
Training loss: 1.888170599937439
Validation loss: 2.2329227526982627

Epoch: 5| Step: 6
Training loss: 1.7365217208862305
Validation loss: 2.2674519767363868

Epoch: 5| Step: 7
Training loss: 1.3432658910751343
Validation loss: 2.2753492295742035

Epoch: 5| Step: 8
Training loss: 1.7731468677520752
Validation loss: 2.2834566235542297

Epoch: 5| Step: 9
Training loss: 1.9090055227279663
Validation loss: 2.284237345059713

Epoch: 5| Step: 10
Training loss: 1.4108927249908447
Validation loss: 2.2777901788552604

Epoch: 5| Step: 11
Training loss: 0.9046542644500732
Validation loss: 2.29039857784907

Epoch: 307| Step: 0
Training loss: 1.71048903465271
Validation loss: 2.323809653520584

Epoch: 5| Step: 1
Training loss: 1.661877989768982
Validation loss: 2.3025598526000977

Epoch: 5| Step: 2
Training loss: 1.3654025793075562
Validation loss: 2.2837017526229224

Epoch: 5| Step: 3
Training loss: 1.820791244506836
Validation loss: 2.2983362873395285

Epoch: 5| Step: 4
Training loss: 1.1294381618499756
Validation loss: 2.2997313837210336

Epoch: 5| Step: 5
Training loss: 1.811370611190796
Validation loss: 2.269357909758886

Epoch: 5| Step: 6
Training loss: 1.6554651260375977
Validation loss: 2.273479933540026

Epoch: 5| Step: 7
Training loss: 1.2008485794067383
Validation loss: 2.285702556371689

Epoch: 5| Step: 8
Training loss: 1.9490022659301758
Validation loss: 2.279266357421875

Epoch: 5| Step: 9
Training loss: 1.6574630737304688
Validation loss: 2.221623698870341

Epoch: 5| Step: 10
Training loss: 1.9010016918182373
Validation loss: 2.236066445708275

Epoch: 5| Step: 11
Training loss: 1.468205213546753
Validation loss: 2.193062295516332

Epoch: 308| Step: 0
Training loss: 1.1146284341812134
Validation loss: 2.2503959039847055

Epoch: 5| Step: 1
Training loss: 1.9018787145614624
Validation loss: 2.263768116633097

Epoch: 5| Step: 2
Training loss: 1.4333380460739136
Validation loss: 2.2562140375375748

Epoch: 5| Step: 3
Training loss: 2.0752177238464355
Validation loss: 2.2498645236094794

Epoch: 5| Step: 4
Training loss: 1.7464946508407593
Validation loss: 2.2468845347563424

Epoch: 5| Step: 5
Training loss: 2.3304853439331055
Validation loss: 2.256579488515854

Epoch: 5| Step: 6
Training loss: 1.326733946800232
Validation loss: 2.2360806663831077

Epoch: 5| Step: 7
Training loss: 1.899517297744751
Validation loss: 2.2010982086261115

Epoch: 5| Step: 8
Training loss: 1.651411771774292
Validation loss: 2.1720595757166543

Epoch: 5| Step: 9
Training loss: 1.9999821186065674
Validation loss: 2.167647590239843

Epoch: 5| Step: 10
Training loss: 1.2205936908721924
Validation loss: 2.1650709907213845

Epoch: 5| Step: 11
Training loss: 1.5945450067520142
Validation loss: 2.1453675975402198

Epoch: 309| Step: 0
Training loss: 1.5898399353027344
Validation loss: 2.15107170244058

Epoch: 5| Step: 1
Training loss: 1.8892428874969482
Validation loss: 2.1579066266616187

Epoch: 5| Step: 2
Training loss: 1.3593895435333252
Validation loss: 2.1997936566670737

Epoch: 5| Step: 3
Training loss: 1.536804437637329
Validation loss: 2.2555254697799683

Epoch: 5| Step: 4
Training loss: 1.1043115854263306
Validation loss: 2.2627503176530204

Epoch: 5| Step: 5
Training loss: 1.4114067554473877
Validation loss: 2.2973411977291107

Epoch: 5| Step: 6
Training loss: 2.072878837585449
Validation loss: 2.295394857724508

Epoch: 5| Step: 7
Training loss: 1.7407363653182983
Validation loss: 2.2871598998705545

Epoch: 5| Step: 8
Training loss: 2.206340789794922
Validation loss: 2.260001768668493

Epoch: 5| Step: 9
Training loss: 2.2019639015197754
Validation loss: 2.258973091840744

Epoch: 5| Step: 10
Training loss: 1.9417994022369385
Validation loss: 2.2357553293307624

Epoch: 5| Step: 11
Training loss: 2.9364168643951416
Validation loss: 2.1769402225812278

Epoch: 310| Step: 0
Training loss: 1.147517442703247
Validation loss: 2.1524105817079544

Epoch: 5| Step: 1
Training loss: 1.3389686346054077
Validation loss: 2.1521272907654443

Epoch: 5| Step: 2
Training loss: 1.3240973949432373
Validation loss: 2.165298491716385

Epoch: 5| Step: 3
Training loss: 2.0440526008605957
Validation loss: 2.149443214138349

Epoch: 5| Step: 4
Training loss: 2.4179155826568604
Validation loss: 2.157614936431249

Epoch: 5| Step: 5
Training loss: 1.8700511455535889
Validation loss: 2.1548828879992166

Epoch: 5| Step: 6
Training loss: 2.294853448867798
Validation loss: 2.1419682800769806

Epoch: 5| Step: 7
Training loss: 1.2605478763580322
Validation loss: 2.1638491799434028

Epoch: 5| Step: 8
Training loss: 1.5229662656784058
Validation loss: 2.169153700272242

Epoch: 5| Step: 9
Training loss: 1.767041802406311
Validation loss: 2.1755581945180893

Epoch: 5| Step: 10
Training loss: 1.8472919464111328
Validation loss: 2.210208704074224

Epoch: 5| Step: 11
Training loss: 1.8168489933013916
Validation loss: 2.2158914506435394

Epoch: 311| Step: 0
Training loss: 1.376682162284851
Validation loss: 2.22486878434817

Epoch: 5| Step: 1
Training loss: 1.5945149660110474
Validation loss: 2.2646423975626626

Epoch: 5| Step: 2
Training loss: 1.6950981616973877
Validation loss: 2.2407698333263397

Epoch: 5| Step: 3
Training loss: 1.8711246252059937
Validation loss: 2.2464230755964913

Epoch: 5| Step: 4
Training loss: 1.6453742980957031
Validation loss: 2.203334922591845

Epoch: 5| Step: 5
Training loss: 1.7089555263519287
Validation loss: 2.2064923346042633

Epoch: 5| Step: 6
Training loss: 1.9003986120224
Validation loss: 2.182488650083542

Epoch: 5| Step: 7
Training loss: 1.1426293849945068
Validation loss: 2.218533585468928

Epoch: 5| Step: 8
Training loss: 1.8980836868286133
Validation loss: 2.2256639202435813

Epoch: 5| Step: 9
Training loss: 1.6587975025177002
Validation loss: 2.2158097426096597

Epoch: 5| Step: 10
Training loss: 2.021829128265381
Validation loss: 2.2354091703891754

Epoch: 5| Step: 11
Training loss: 1.2659587860107422
Validation loss: 2.2149572372436523

Epoch: 312| Step: 0
Training loss: 1.599137306213379
Validation loss: 2.246579021215439

Epoch: 5| Step: 1
Training loss: 2.7395572662353516
Validation loss: 2.2691979904969535

Epoch: 5| Step: 2
Training loss: 1.5561867952346802
Validation loss: 2.2874399622281394

Epoch: 5| Step: 3
Training loss: 1.6462749242782593
Validation loss: 2.2932916283607483

Epoch: 5| Step: 4
Training loss: 1.7291650772094727
Validation loss: 2.2614735762278237

Epoch: 5| Step: 5
Training loss: 1.6942182779312134
Validation loss: 2.2241068333387375

Epoch: 5| Step: 6
Training loss: 1.8928592205047607
Validation loss: 2.2194765905539193

Epoch: 5| Step: 7
Training loss: 1.7273744344711304
Validation loss: 2.2241909305254617

Epoch: 5| Step: 8
Training loss: 1.5379345417022705
Validation loss: 2.1978739698727927

Epoch: 5| Step: 9
Training loss: 1.4191606044769287
Validation loss: 2.200572296977043

Epoch: 5| Step: 10
Training loss: 1.6045652627944946
Validation loss: 2.1479966839154563

Epoch: 5| Step: 11
Training loss: 3.426528215408325
Validation loss: 2.173118124405543

Epoch: 313| Step: 0
Training loss: 1.4045250415802002
Validation loss: 2.199479122956594

Epoch: 5| Step: 1
Training loss: 1.7348577976226807
Validation loss: 2.186553751428922

Epoch: 5| Step: 2
Training loss: 1.5345933437347412
Validation loss: 2.2014599641164145

Epoch: 5| Step: 3
Training loss: 2.0725035667419434
Validation loss: 2.2175301214059195

Epoch: 5| Step: 4
Training loss: 1.667550802230835
Validation loss: 2.2077424625555673

Epoch: 5| Step: 5
Training loss: 1.423814058303833
Validation loss: 2.223533103863398

Epoch: 5| Step: 6
Training loss: 1.5227409601211548
Validation loss: 2.2441378136475882

Epoch: 5| Step: 7
Training loss: 1.597076416015625
Validation loss: 2.2122275680303574

Epoch: 5| Step: 8
Training loss: 2.1987545490264893
Validation loss: 2.230402464667956

Epoch: 5| Step: 9
Training loss: 1.6402699947357178
Validation loss: 2.2449787855148315

Epoch: 5| Step: 10
Training loss: 1.6099278926849365
Validation loss: 2.2228780488173165

Epoch: 5| Step: 11
Training loss: 0.9765554666519165
Validation loss: 2.242076357205709

Epoch: 314| Step: 0
Training loss: 1.188764214515686
Validation loss: 2.251755212744077

Epoch: 5| Step: 1
Training loss: 1.4104869365692139
Validation loss: 2.2531029731035233

Epoch: 5| Step: 2
Training loss: 2.1521692276000977
Validation loss: 2.232971802353859

Epoch: 5| Step: 3
Training loss: 1.822188138961792
Validation loss: 2.2521927853425345

Epoch: 5| Step: 4
Training loss: 1.53867506980896
Validation loss: 2.2212952772776284

Epoch: 5| Step: 5
Training loss: 2.1432509422302246
Validation loss: 2.2323467234770455

Epoch: 5| Step: 6
Training loss: 1.8794806003570557
Validation loss: 2.203809380531311

Epoch: 5| Step: 7
Training loss: 2.0133414268493652
Validation loss: 2.2107266982396445

Epoch: 5| Step: 8
Training loss: 1.5033248662948608
Validation loss: 2.237782378991445

Epoch: 5| Step: 9
Training loss: 1.4720304012298584
Validation loss: 2.2343008120854697

Epoch: 5| Step: 10
Training loss: 1.3524701595306396
Validation loss: 2.2199206054210663

Epoch: 5| Step: 11
Training loss: 0.8872733116149902
Validation loss: 2.2307517329851785

Epoch: 315| Step: 0
Training loss: 0.998498260974884
Validation loss: 2.219234511256218

Epoch: 5| Step: 1
Training loss: 2.1792960166931152
Validation loss: 2.236182083686193

Epoch: 5| Step: 2
Training loss: 2.0505943298339844
Validation loss: 2.2028825084368386

Epoch: 5| Step: 3
Training loss: 1.2556220293045044
Validation loss: 2.2129896134138107

Epoch: 5| Step: 4
Training loss: 1.253043293952942
Validation loss: 2.2152620603640876

Epoch: 5| Step: 5
Training loss: 1.5625032186508179
Validation loss: 2.236172621448835

Epoch: 5| Step: 6
Training loss: 1.7949692010879517
Validation loss: 2.2356488655010858

Epoch: 5| Step: 7
Training loss: 2.174285650253296
Validation loss: 2.246076002717018

Epoch: 5| Step: 8
Training loss: 1.5651390552520752
Validation loss: 2.2737121284008026

Epoch: 5| Step: 9
Training loss: 1.580784797668457
Validation loss: 2.2631433258454003

Epoch: 5| Step: 10
Training loss: 1.5608292818069458
Validation loss: 2.2680544753869376

Epoch: 5| Step: 11
Training loss: 1.9099308252334595
Validation loss: 2.293658420443535

Epoch: 316| Step: 0
Training loss: 2.053534507751465
Validation loss: 2.260232319434484

Epoch: 5| Step: 1
Training loss: 1.035861849784851
Validation loss: 2.248047411441803

Epoch: 5| Step: 2
Training loss: 1.555138111114502
Validation loss: 2.180303638180097

Epoch: 5| Step: 3
Training loss: 1.5773930549621582
Validation loss: 2.1521696050961814

Epoch: 5| Step: 4
Training loss: 1.7596099376678467
Validation loss: 2.175207073489825

Epoch: 5| Step: 5
Training loss: 1.345818281173706
Validation loss: 2.16941008468469

Epoch: 5| Step: 6
Training loss: 1.7467057704925537
Validation loss: 2.211190010110537

Epoch: 5| Step: 7
Training loss: 1.5823853015899658
Validation loss: 2.207625632484754

Epoch: 5| Step: 8
Training loss: 1.8887596130371094
Validation loss: 2.2451941072940826

Epoch: 5| Step: 9
Training loss: 1.5080878734588623
Validation loss: 2.232921535770098

Epoch: 5| Step: 10
Training loss: 1.9089771509170532
Validation loss: 2.286543836196264

Epoch: 5| Step: 11
Training loss: 1.1237937211990356
Validation loss: 2.2757745484511056

Epoch: 317| Step: 0
Training loss: 1.7936763763427734
Validation loss: 2.2964001893997192

Epoch: 5| Step: 1
Training loss: 1.8675289154052734
Validation loss: 2.2830262184143066

Epoch: 5| Step: 2
Training loss: 1.2774015665054321
Validation loss: 2.2513932089010873

Epoch: 5| Step: 3
Training loss: 1.3757911920547485
Validation loss: 2.2355817457040152

Epoch: 5| Step: 4
Training loss: 1.5979712009429932
Validation loss: 2.2051952679951987

Epoch: 5| Step: 5
Training loss: 1.61286199092865
Validation loss: 2.224322199821472

Epoch: 5| Step: 6
Training loss: 1.7710403203964233
Validation loss: 2.2092722803354263

Epoch: 5| Step: 7
Training loss: 1.3595168590545654
Validation loss: 2.184213697910309

Epoch: 5| Step: 8
Training loss: 1.5819586515426636
Validation loss: 2.195588250954946

Epoch: 5| Step: 9
Training loss: 1.6692702770233154
Validation loss: 2.2224547465642295

Epoch: 5| Step: 10
Training loss: 2.4461238384246826
Validation loss: 2.2235495994488397

Epoch: 5| Step: 11
Training loss: 1.2188122272491455
Validation loss: 2.241143599152565

Epoch: 318| Step: 0
Training loss: 1.6923106908798218
Validation loss: 2.225374316175779

Epoch: 5| Step: 1
Training loss: 1.712938904762268
Validation loss: 2.25012214978536

Epoch: 5| Step: 2
Training loss: 1.2972952127456665
Validation loss: 2.2344526847203574

Epoch: 5| Step: 3
Training loss: 1.369762659072876
Validation loss: 2.2455001870791116

Epoch: 5| Step: 4
Training loss: 1.0845000743865967
Validation loss: 2.2727190951506295

Epoch: 5| Step: 5
Training loss: 1.835228681564331
Validation loss: 2.2519860565662384

Epoch: 5| Step: 6
Training loss: 2.271224021911621
Validation loss: 2.2411176363627114

Epoch: 5| Step: 7
Training loss: 1.3264752626419067
Validation loss: 2.2353346894184747

Epoch: 5| Step: 8
Training loss: 1.818275809288025
Validation loss: 2.2197453677654266

Epoch: 5| Step: 9
Training loss: 1.6314678192138672
Validation loss: 2.216582397619883

Epoch: 5| Step: 10
Training loss: 1.5135266780853271
Validation loss: 2.2017829616864524

Epoch: 5| Step: 11
Training loss: 0.8724985122680664
Validation loss: 2.2131797025601068

Epoch: 319| Step: 0
Training loss: 1.3102530241012573
Validation loss: 2.197601834932963

Epoch: 5| Step: 1
Training loss: 1.2375818490982056
Validation loss: 2.204431171218554

Epoch: 5| Step: 2
Training loss: 1.398805022239685
Validation loss: 2.239075889190038

Epoch: 5| Step: 3
Training loss: 2.028947114944458
Validation loss: 2.2540352046489716

Epoch: 5| Step: 4
Training loss: 2.0754640102386475
Validation loss: 2.2443086008230844

Epoch: 5| Step: 5
Training loss: 1.851880669593811
Validation loss: 2.22573913137118

Epoch: 5| Step: 6
Training loss: 1.446392297744751
Validation loss: 2.269818221529325

Epoch: 5| Step: 7
Training loss: 1.3664509057998657
Validation loss: 2.302497779329618

Epoch: 5| Step: 8
Training loss: 1.8913488388061523
Validation loss: 2.275394171476364

Epoch: 5| Step: 9
Training loss: 1.7188202142715454
Validation loss: 2.289731373389562

Epoch: 5| Step: 10
Training loss: 1.3720213174819946
Validation loss: 2.297635853290558

Epoch: 5| Step: 11
Training loss: 1.2869293689727783
Validation loss: 2.280482346812884

Epoch: 320| Step: 0
Training loss: 1.5238895416259766
Validation loss: 2.255255570014318

Epoch: 5| Step: 1
Training loss: 1.82061767578125
Validation loss: 2.2468477686246238

Epoch: 5| Step: 2
Training loss: 1.5730462074279785
Validation loss: 2.235791246096293

Epoch: 5| Step: 3
Training loss: 1.6971737146377563
Validation loss: 2.242791752020518

Epoch: 5| Step: 4
Training loss: 1.4668607711791992
Validation loss: 2.2108965714772544

Epoch: 5| Step: 5
Training loss: 1.7661113739013672
Validation loss: 2.197621683279673

Epoch: 5| Step: 6
Training loss: 2.1952643394470215
Validation loss: 2.1735048492749534

Epoch: 5| Step: 7
Training loss: 1.4218257665634155
Validation loss: 2.164653946955999

Epoch: 5| Step: 8
Training loss: 1.5876789093017578
Validation loss: 2.161183680097262

Epoch: 5| Step: 9
Training loss: 1.312861442565918
Validation loss: 2.190392479300499

Epoch: 5| Step: 10
Training loss: 1.3527942895889282
Validation loss: 2.2212675511837006

Epoch: 5| Step: 11
Training loss: 0.9964790940284729
Validation loss: 2.225763609011968

Epoch: 321| Step: 0
Training loss: 1.2690918445587158
Validation loss: 2.206315298875173

Epoch: 5| Step: 1
Training loss: 1.5107645988464355
Validation loss: 2.222371111313502

Epoch: 5| Step: 2
Training loss: 1.3166587352752686
Validation loss: 2.2653761903444924

Epoch: 5| Step: 3
Training loss: 1.3615574836730957
Validation loss: 2.2040819823741913

Epoch: 5| Step: 4
Training loss: 1.7920669317245483
Validation loss: 2.194311633706093

Epoch: 5| Step: 5
Training loss: 2.331446409225464
Validation loss: 2.191805119315783

Epoch: 5| Step: 6
Training loss: 1.428547739982605
Validation loss: 2.1711620638767877

Epoch: 5| Step: 7
Training loss: 1.0225446224212646
Validation loss: 2.193967049320539

Epoch: 5| Step: 8
Training loss: 1.9897677898406982
Validation loss: 2.1973988314469657

Epoch: 5| Step: 9
Training loss: 2.0139291286468506
Validation loss: 2.2358483175436654

Epoch: 5| Step: 10
Training loss: 1.553352952003479
Validation loss: 2.2637222905953727

Epoch: 5| Step: 11
Training loss: 1.7267634868621826
Validation loss: 2.304543435573578

Epoch: 322| Step: 0
Training loss: 1.1794250011444092
Validation loss: 2.3384721080462136

Epoch: 5| Step: 1
Training loss: 1.6228363513946533
Validation loss: 2.319208433230718

Epoch: 5| Step: 2
Training loss: 1.9962886571884155
Validation loss: 2.315703441699346

Epoch: 5| Step: 3
Training loss: 1.424140214920044
Validation loss: 2.317882865667343

Epoch: 5| Step: 4
Training loss: 1.8708969354629517
Validation loss: 2.2684176017840705

Epoch: 5| Step: 5
Training loss: 0.8557788729667664
Validation loss: 2.238786071538925

Epoch: 5| Step: 6
Training loss: 2.0692241191864014
Validation loss: 2.180111343661944

Epoch: 5| Step: 7
Training loss: 1.8415863513946533
Validation loss: 2.145621950427691

Epoch: 5| Step: 8
Training loss: 1.7700313329696655
Validation loss: 2.1608266135056815

Epoch: 5| Step: 9
Training loss: 2.1910698413848877
Validation loss: 2.176047613223394

Epoch: 5| Step: 10
Training loss: 1.0212266445159912
Validation loss: 2.16166619459788

Epoch: 5| Step: 11
Training loss: 3.7427446842193604
Validation loss: 2.1720265299081802

Epoch: 323| Step: 0
Training loss: 2.050997257232666
Validation loss: 2.1808975835641227

Epoch: 5| Step: 1
Training loss: 1.0795998573303223
Validation loss: 2.196598927179972

Epoch: 5| Step: 2
Training loss: 1.5809767246246338
Validation loss: 2.2373753786087036

Epoch: 5| Step: 3
Training loss: 1.5906460285186768
Validation loss: 2.2442112267017365

Epoch: 5| Step: 4
Training loss: 1.6156396865844727
Validation loss: 2.263892322778702

Epoch: 5| Step: 5
Training loss: 1.1177666187286377
Validation loss: 2.2648319552342095

Epoch: 5| Step: 6
Training loss: 2.111466407775879
Validation loss: 2.2314748664697013

Epoch: 5| Step: 7
Training loss: 1.4716863632202148
Validation loss: 2.280900225043297

Epoch: 5| Step: 8
Training loss: 1.021530270576477
Validation loss: 2.2490451435248056

Epoch: 5| Step: 9
Training loss: 1.5225976705551147
Validation loss: 2.236038953065872

Epoch: 5| Step: 10
Training loss: 2.328720808029175
Validation loss: 2.232541417082151

Epoch: 5| Step: 11
Training loss: 1.488527536392212
Validation loss: 2.2318901220957437

Epoch: 324| Step: 0
Training loss: 1.4088618755340576
Validation loss: 2.2403312077124915

Epoch: 5| Step: 1
Training loss: 2.1534478664398193
Validation loss: 2.248121460278829

Epoch: 5| Step: 2
Training loss: 1.169694185256958
Validation loss: 2.2815935760736465

Epoch: 5| Step: 3
Training loss: 1.5766746997833252
Validation loss: 2.2468665341536203

Epoch: 5| Step: 4
Training loss: 1.2642618417739868
Validation loss: 2.2549540797869363

Epoch: 5| Step: 5
Training loss: 1.8742389678955078
Validation loss: 2.2462846636772156

Epoch: 5| Step: 6
Training loss: 1.3087894916534424
Validation loss: 2.235256085793177

Epoch: 5| Step: 7
Training loss: 1.5794991254806519
Validation loss: 2.262572238842646

Epoch: 5| Step: 8
Training loss: 1.3857542276382446
Validation loss: 2.2533225814501443

Epoch: 5| Step: 9
Training loss: 2.151793956756592
Validation loss: 2.2154900282621384

Epoch: 5| Step: 10
Training loss: 1.4730803966522217
Validation loss: 2.237529441714287

Epoch: 5| Step: 11
Training loss: 1.273058533668518
Validation loss: 2.24201637506485

Epoch: 325| Step: 0
Training loss: 1.3975908756256104
Validation loss: 2.206923002998034

Epoch: 5| Step: 1
Training loss: 1.138586163520813
Validation loss: 2.2103248635927835

Epoch: 5| Step: 2
Training loss: 0.9421133995056152
Validation loss: 2.2157814502716064

Epoch: 5| Step: 3
Training loss: 1.54058039188385
Validation loss: 2.1943290134270987

Epoch: 5| Step: 4
Training loss: 2.189030408859253
Validation loss: 2.212800701459249

Epoch: 5| Step: 5
Training loss: 1.433133840560913
Validation loss: 2.212732657790184

Epoch: 5| Step: 6
Training loss: 1.1176731586456299
Validation loss: 2.212597226103147

Epoch: 5| Step: 7
Training loss: 2.596430540084839
Validation loss: 2.2405617088079453

Epoch: 5| Step: 8
Training loss: 1.9201873540878296
Validation loss: 2.264196207125982

Epoch: 5| Step: 9
Training loss: 2.2069644927978516
Validation loss: 2.279473384221395

Epoch: 5| Step: 10
Training loss: 1.2800554037094116
Validation loss: 2.2636676033337912

Epoch: 5| Step: 11
Training loss: 1.2005598545074463
Validation loss: 2.2717850307623544

Epoch: 326| Step: 0
Training loss: 1.1894676685333252
Validation loss: 2.2669766545295715

Epoch: 5| Step: 1
Training loss: 1.4151761531829834
Validation loss: 2.2455789893865585

Epoch: 5| Step: 2
Training loss: 1.2748475074768066
Validation loss: 2.2189668069283166

Epoch: 5| Step: 3
Training loss: 1.6293423175811768
Validation loss: 2.1931833922863007

Epoch: 5| Step: 4
Training loss: 2.5705721378326416
Validation loss: 2.1861200531323752

Epoch: 5| Step: 5
Training loss: 1.495202898979187
Validation loss: 2.2040875057379403

Epoch: 5| Step: 6
Training loss: 1.3998782634735107
Validation loss: 2.215317408243815

Epoch: 5| Step: 7
Training loss: 1.1847482919692993
Validation loss: 2.1989428798357644

Epoch: 5| Step: 8
Training loss: 1.9772999286651611
Validation loss: 2.2351419826348624

Epoch: 5| Step: 9
Training loss: 1.7051169872283936
Validation loss: 2.2337951163450875

Epoch: 5| Step: 10
Training loss: 1.914041519165039
Validation loss: 2.2791474759578705

Epoch: 5| Step: 11
Training loss: 0.9465563893318176
Validation loss: 2.2727521558602652

Epoch: 327| Step: 0
Training loss: 1.0605266094207764
Validation loss: 2.270897408326467

Epoch: 5| Step: 1
Training loss: 1.290545105934143
Validation loss: 2.298365796605746

Epoch: 5| Step: 2
Training loss: 2.0327353477478027
Validation loss: 2.2926281541585922

Epoch: 5| Step: 3
Training loss: 2.193817138671875
Validation loss: 2.287980154156685

Epoch: 5| Step: 4
Training loss: 1.8435817956924438
Validation loss: 2.3080539852380753

Epoch: 5| Step: 5
Training loss: 1.5192919969558716
Validation loss: 2.2855265041192374

Epoch: 5| Step: 6
Training loss: 1.385629415512085
Validation loss: 2.2769575119018555

Epoch: 5| Step: 7
Training loss: 0.6643766164779663
Validation loss: 2.254171073436737

Epoch: 5| Step: 8
Training loss: 1.684560775756836
Validation loss: 2.20255978902181

Epoch: 5| Step: 9
Training loss: 2.079786777496338
Validation loss: 2.2009661495685577

Epoch: 5| Step: 10
Training loss: 1.7893657684326172
Validation loss: 2.2260345816612244

Epoch: 5| Step: 11
Training loss: 1.1218196153640747
Validation loss: 2.2053017914295197

Epoch: 328| Step: 0
Training loss: 1.489003300666809
Validation loss: 2.1960260421037674

Epoch: 5| Step: 1
Training loss: 1.299072504043579
Validation loss: 2.236090580622355

Epoch: 5| Step: 2
Training loss: 1.4864675998687744
Validation loss: 2.2395108143488565

Epoch: 5| Step: 3
Training loss: 1.009075403213501
Validation loss: 2.2619725465774536

Epoch: 5| Step: 4
Training loss: 1.4794162511825562
Validation loss: 2.252189209063848

Epoch: 5| Step: 5
Training loss: 1.7609732151031494
Validation loss: 2.271699363986651

Epoch: 5| Step: 6
Training loss: 1.9323017597198486
Validation loss: 2.257757614056269

Epoch: 5| Step: 7
Training loss: 1.3198373317718506
Validation loss: 2.2667055328687034

Epoch: 5| Step: 8
Training loss: 1.883172631263733
Validation loss: 2.2556972404321036

Epoch: 5| Step: 9
Training loss: 1.7341511249542236
Validation loss: 2.287235602736473

Epoch: 5| Step: 10
Training loss: 1.8077037334442139
Validation loss: 2.2616582910219827

Epoch: 5| Step: 11
Training loss: 1.1264913082122803
Validation loss: 2.311194201310476

Epoch: 329| Step: 0
Training loss: 1.7055168151855469
Validation loss: 2.3127950181563697

Epoch: 5| Step: 1
Training loss: 1.6831424236297607
Validation loss: 2.2959563533465066

Epoch: 5| Step: 2
Training loss: 1.1175789833068848
Validation loss: 2.304779758056005

Epoch: 5| Step: 3
Training loss: 1.8783676624298096
Validation loss: 2.274437894423803

Epoch: 5| Step: 4
Training loss: 1.2752792835235596
Validation loss: 2.2679954767227173

Epoch: 5| Step: 5
Training loss: 2.0501883029937744
Validation loss: 2.2229505678017936

Epoch: 5| Step: 6
Training loss: 1.0272483825683594
Validation loss: 2.211341440677643

Epoch: 5| Step: 7
Training loss: 1.649592638015747
Validation loss: 2.185686861475309

Epoch: 5| Step: 8
Training loss: 2.0434088706970215
Validation loss: 2.1950308084487915

Epoch: 5| Step: 9
Training loss: 1.2439212799072266
Validation loss: 2.1976040502389274

Epoch: 5| Step: 10
Training loss: 2.0680899620056152
Validation loss: 2.229591265320778

Epoch: 5| Step: 11
Training loss: 1.3046801090240479
Validation loss: 2.246888130903244

Epoch: 330| Step: 0
Training loss: 2.0138516426086426
Validation loss: 2.269792318344116

Epoch: 5| Step: 1
Training loss: 1.102113962173462
Validation loss: 2.2586073527733483

Epoch: 5| Step: 2
Training loss: 1.563307762145996
Validation loss: 2.2631987631320953

Epoch: 5| Step: 3
Training loss: 1.7489020824432373
Validation loss: 2.282613158226013

Epoch: 5| Step: 4
Training loss: 1.959102988243103
Validation loss: 2.2940481305122375

Epoch: 5| Step: 5
Training loss: 1.8718652725219727
Validation loss: 2.300015161434809

Epoch: 5| Step: 6
Training loss: 1.3818817138671875
Validation loss: 2.302097663283348

Epoch: 5| Step: 7
Training loss: 1.176535964012146
Validation loss: 2.288300851980845

Epoch: 5| Step: 8
Training loss: 1.2684284448623657
Validation loss: 2.2704273660977683

Epoch: 5| Step: 9
Training loss: 1.9603474140167236
Validation loss: 2.270284449060758

Epoch: 5| Step: 10
Training loss: 1.056222677230835
Validation loss: 2.272236242890358

Epoch: 5| Step: 11
Training loss: 1.6749738454818726
Validation loss: 2.2648609032233558

Epoch: 331| Step: 0
Training loss: 2.0574355125427246
Validation loss: 2.24742262562116

Epoch: 5| Step: 1
Training loss: 2.363544225692749
Validation loss: 2.2468852549791336

Epoch: 5| Step: 2
Training loss: 1.5013444423675537
Validation loss: 2.2464313904444375

Epoch: 5| Step: 3
Training loss: 1.7792783975601196
Validation loss: 2.2387648721536

Epoch: 5| Step: 4
Training loss: 1.2231980562210083
Validation loss: 2.2196688652038574

Epoch: 5| Step: 5
Training loss: 1.638110876083374
Validation loss: 2.257760688662529

Epoch: 5| Step: 6
Training loss: 1.0447133779525757
Validation loss: 2.219290797909101

Epoch: 5| Step: 7
Training loss: 1.829697847366333
Validation loss: 2.2345722218354545

Epoch: 5| Step: 8
Training loss: 0.6285195350646973
Validation loss: 2.2157029708226523

Epoch: 5| Step: 9
Training loss: 1.1647365093231201
Validation loss: 2.183557872970899

Epoch: 5| Step: 10
Training loss: 1.8926194906234741
Validation loss: 2.188076992829641

Epoch: 5| Step: 11
Training loss: 2.6042277812957764
Validation loss: 2.229448452591896

Epoch: 332| Step: 0
Training loss: 1.6704771518707275
Validation loss: 2.230211521188418

Epoch: 5| Step: 1
Training loss: 1.4834458827972412
Validation loss: 2.2015440315008163

Epoch: 5| Step: 2
Training loss: 1.0870294570922852
Validation loss: 2.2352874080340066

Epoch: 5| Step: 3
Training loss: 0.978399395942688
Validation loss: 2.2584427495797477

Epoch: 5| Step: 4
Training loss: 2.340881109237671
Validation loss: 2.2419739166895547

Epoch: 5| Step: 5
Training loss: 1.9335625171661377
Validation loss: 2.257488136490186

Epoch: 5| Step: 6
Training loss: 1.5564229488372803
Validation loss: 2.2738968431949615

Epoch: 5| Step: 7
Training loss: 1.793766736984253
Validation loss: 2.3116654753684998

Epoch: 5| Step: 8
Training loss: 1.295461893081665
Validation loss: 2.3074138462543488

Epoch: 5| Step: 9
Training loss: 1.585357427597046
Validation loss: 2.277124911546707

Epoch: 5| Step: 10
Training loss: 1.360392451286316
Validation loss: 2.328179955482483

Epoch: 5| Step: 11
Training loss: 1.66998291015625
Validation loss: 2.3307934502760568

Epoch: 333| Step: 0
Training loss: 1.7554161548614502
Validation loss: 2.3024506668249765

Epoch: 5| Step: 1
Training loss: 1.1633126735687256
Validation loss: 2.302285686135292

Epoch: 5| Step: 2
Training loss: 1.256689429283142
Validation loss: 2.254122724135717

Epoch: 5| Step: 3
Training loss: 1.2671953439712524
Validation loss: 2.2588005314270654

Epoch: 5| Step: 4
Training loss: 1.0727543830871582
Validation loss: 2.2686634808778763

Epoch: 5| Step: 5
Training loss: 1.3304722309112549
Validation loss: 2.2931803415218988

Epoch: 5| Step: 6
Training loss: 1.9241187572479248
Validation loss: 2.328449159860611

Epoch: 5| Step: 7
Training loss: 1.8951513767242432
Validation loss: 2.296670158704122

Epoch: 5| Step: 8
Training loss: 1.3012611865997314
Validation loss: 2.2821453710397086

Epoch: 5| Step: 9
Training loss: 2.2188663482666016
Validation loss: 2.272420962651571

Epoch: 5| Step: 10
Training loss: 1.849527359008789
Validation loss: 2.2915263026952744

Epoch: 5| Step: 11
Training loss: 1.1062736511230469
Validation loss: 2.265347808599472

Epoch: 334| Step: 0
Training loss: 1.652639389038086
Validation loss: 2.2519578337669373

Epoch: 5| Step: 1
Training loss: 1.0840915441513062
Validation loss: 2.2760027945041656

Epoch: 5| Step: 2
Training loss: 1.1769499778747559
Validation loss: 2.2915929555892944

Epoch: 5| Step: 3
Training loss: 0.8195425271987915
Validation loss: 2.278117378552755

Epoch: 5| Step: 4
Training loss: 1.4098937511444092
Validation loss: 2.252889856696129

Epoch: 5| Step: 5
Training loss: 1.833701491355896
Validation loss: 2.2190469851096473

Epoch: 5| Step: 6
Training loss: 2.403425693511963
Validation loss: 2.2675176560878754

Epoch: 5| Step: 7
Training loss: 1.9663903713226318
Validation loss: 2.217622364560763

Epoch: 5| Step: 8
Training loss: 1.5125211477279663
Validation loss: 2.238049710790316

Epoch: 5| Step: 9
Training loss: 1.623722791671753
Validation loss: 2.233618994553884

Epoch: 5| Step: 10
Training loss: 1.168424367904663
Validation loss: 2.2720875839392343

Epoch: 5| Step: 11
Training loss: 2.013620376586914
Validation loss: 2.2912666648626328

Epoch: 335| Step: 0
Training loss: 2.2404725551605225
Validation loss: 2.2719390292962394

Epoch: 5| Step: 1
Training loss: 1.2630691528320312
Validation loss: 2.210559149583181

Epoch: 5| Step: 2
Training loss: 1.0041486024856567
Validation loss: 2.238822042942047

Epoch: 5| Step: 3
Training loss: 1.4597804546356201
Validation loss: 2.1868410805861154

Epoch: 5| Step: 4
Training loss: 1.4102096557617188
Validation loss: 2.2361967464288077

Epoch: 5| Step: 5
Training loss: 1.0291318893432617
Validation loss: 2.209744840860367

Epoch: 5| Step: 6
Training loss: 1.6196264028549194
Validation loss: 2.2573195596536

Epoch: 5| Step: 7
Training loss: 1.4442353248596191
Validation loss: 2.282374292612076

Epoch: 5| Step: 8
Training loss: 2.373302459716797
Validation loss: 2.3234397172927856

Epoch: 5| Step: 9
Training loss: 1.59029221534729
Validation loss: 2.2932268381118774

Epoch: 5| Step: 10
Training loss: 1.5682592391967773
Validation loss: 2.259618729352951

Epoch: 5| Step: 11
Training loss: 1.7923285961151123
Validation loss: 2.294813166062037

Epoch: 336| Step: 0
Training loss: 0.9423408508300781
Validation loss: 2.2654947688182197

Epoch: 5| Step: 1
Training loss: 1.6265437602996826
Validation loss: 2.2429021249214807

Epoch: 5| Step: 2
Training loss: 1.2150027751922607
Validation loss: 2.2544229179620743

Epoch: 5| Step: 3
Training loss: 2.312504768371582
Validation loss: 2.25970126191775

Epoch: 5| Step: 4
Training loss: 0.9497234225273132
Validation loss: 2.2628855854272842

Epoch: 5| Step: 5
Training loss: 2.258363723754883
Validation loss: 2.24808577199777

Epoch: 5| Step: 6
Training loss: 1.4754993915557861
Validation loss: 2.2633870989084244

Epoch: 5| Step: 7
Training loss: 1.7972049713134766
Validation loss: 2.22808205584685

Epoch: 5| Step: 8
Training loss: 1.0160057544708252
Validation loss: 2.224991887807846

Epoch: 5| Step: 9
Training loss: 1.2592986822128296
Validation loss: 2.1826071987549462

Epoch: 5| Step: 10
Training loss: 1.9233405590057373
Validation loss: 2.1930361787478128

Epoch: 5| Step: 11
Training loss: 1.500504732131958
Validation loss: 2.216694007317225

Epoch: 337| Step: 0
Training loss: 1.5427147150039673
Validation loss: 2.234178284804026

Epoch: 5| Step: 1
Training loss: 1.6019115447998047
Validation loss: 2.2411613861719766

Epoch: 5| Step: 2
Training loss: 1.3588885068893433
Validation loss: 2.239591807126999

Epoch: 5| Step: 3
Training loss: 2.021596670150757
Validation loss: 2.240507811307907

Epoch: 5| Step: 4
Training loss: 1.691105604171753
Validation loss: 2.26895339290301

Epoch: 5| Step: 5
Training loss: 1.4637315273284912
Validation loss: 2.2568163176377616

Epoch: 5| Step: 6
Training loss: 1.8645330667495728
Validation loss: 2.2645806670188904

Epoch: 5| Step: 7
Training loss: 1.2028228044509888
Validation loss: 2.260443076491356

Epoch: 5| Step: 8
Training loss: 1.4313809871673584
Validation loss: 2.2544488112131753

Epoch: 5| Step: 9
Training loss: 1.5067726373672485
Validation loss: 2.2581516603628793

Epoch: 5| Step: 10
Training loss: 1.0967729091644287
Validation loss: 2.2605888148148856

Epoch: 5| Step: 11
Training loss: 2.8067455291748047
Validation loss: 2.2583738962809243

Epoch: 338| Step: 0
Training loss: 1.5465158224105835
Validation loss: 2.2969697415828705

Epoch: 5| Step: 1
Training loss: 1.4262996912002563
Validation loss: 2.2986137866973877

Epoch: 5| Step: 2
Training loss: 1.8459522724151611
Validation loss: 2.309395879507065

Epoch: 5| Step: 3
Training loss: 1.2062327861785889
Validation loss: 2.298568765322367

Epoch: 5| Step: 4
Training loss: 0.9065483212471008
Validation loss: 2.2764879018068314

Epoch: 5| Step: 5
Training loss: 1.5573469400405884
Validation loss: 2.2611533850431442

Epoch: 5| Step: 6
Training loss: 1.513106346130371
Validation loss: 2.2176436384518943

Epoch: 5| Step: 7
Training loss: 1.3058501482009888
Validation loss: 2.229122186700503

Epoch: 5| Step: 8
Training loss: 2.289699077606201
Validation loss: 2.2391471415758133

Epoch: 5| Step: 9
Training loss: 1.8815221786499023
Validation loss: 2.2356893569231033

Epoch: 5| Step: 10
Training loss: 1.2447013854980469
Validation loss: 2.296619569261869

Epoch: 5| Step: 11
Training loss: 1.3634307384490967
Validation loss: 2.301284670829773

Epoch: 339| Step: 0
Training loss: 1.1637585163116455
Validation loss: 2.311567505200704

Epoch: 5| Step: 1
Training loss: 1.5589077472686768
Validation loss: 2.352698584397634

Epoch: 5| Step: 2
Training loss: 1.5408780574798584
Validation loss: 2.3408033649126687

Epoch: 5| Step: 3
Training loss: 1.7889324426651
Validation loss: 2.3416161239147186

Epoch: 5| Step: 4
Training loss: 1.8958098888397217
Validation loss: 2.344119002421697

Epoch: 5| Step: 5
Training loss: 1.7959413528442383
Validation loss: 2.3202673395474753

Epoch: 5| Step: 6
Training loss: 1.1840335130691528
Validation loss: 2.269957775870959

Epoch: 5| Step: 7
Training loss: 1.7405517101287842
Validation loss: 2.2296529660622277

Epoch: 5| Step: 8
Training loss: 2.0230748653411865
Validation loss: 2.206592336297035

Epoch: 5| Step: 9
Training loss: 1.6522624492645264
Validation loss: 2.194630871216456

Epoch: 5| Step: 10
Training loss: 1.7289535999298096
Validation loss: 2.211999401450157

Epoch: 5| Step: 11
Training loss: 0.8626279830932617
Validation loss: 2.185061991214752

Epoch: 340| Step: 0
Training loss: 1.414697527885437
Validation loss: 2.2409664640824

Epoch: 5| Step: 1
Training loss: 1.7015804052352905
Validation loss: 2.2096391518910727

Epoch: 5| Step: 2
Training loss: 1.5857117176055908
Validation loss: 2.229689672589302

Epoch: 5| Step: 3
Training loss: 1.7012951374053955
Validation loss: 2.2761295437812805

Epoch: 5| Step: 4
Training loss: 1.1568143367767334
Validation loss: 2.2707831462224326

Epoch: 5| Step: 5
Training loss: 1.8770580291748047
Validation loss: 2.2701784670352936

Epoch: 5| Step: 6
Training loss: 1.2702507972717285
Validation loss: 2.309783786535263

Epoch: 5| Step: 7
Training loss: 1.9897304773330688
Validation loss: 2.2724053661028543

Epoch: 5| Step: 8
Training loss: 1.759685754776001
Validation loss: 2.273085524638494

Epoch: 5| Step: 9
Training loss: 1.177090048789978
Validation loss: 2.283095727364222

Epoch: 5| Step: 10
Training loss: 1.3153356313705444
Validation loss: 2.25943161547184

Epoch: 5| Step: 11
Training loss: 1.0252447128295898
Validation loss: 2.2351586371660233

Epoch: 341| Step: 0
Training loss: 1.299921989440918
Validation loss: 2.208372334639231

Epoch: 5| Step: 1
Training loss: 1.5959285497665405
Validation loss: 2.192486117283503

Epoch: 5| Step: 2
Training loss: 2.0137245655059814
Validation loss: 2.2015918542941413

Epoch: 5| Step: 3
Training loss: 1.3336856365203857
Validation loss: 2.217529743909836

Epoch: 5| Step: 4
Training loss: 1.2690544128417969
Validation loss: 2.209671547015508

Epoch: 5| Step: 5
Training loss: 1.947422742843628
Validation loss: 2.2662452459335327

Epoch: 5| Step: 6
Training loss: 1.180804967880249
Validation loss: 2.2757420539855957

Epoch: 5| Step: 7
Training loss: 1.6893069744110107
Validation loss: 2.2629891534646354

Epoch: 5| Step: 8
Training loss: 1.968120813369751
Validation loss: 2.2548245588938394

Epoch: 5| Step: 9
Training loss: 1.614689588546753
Validation loss: 2.2970617016156516

Epoch: 5| Step: 10
Training loss: 1.6341197490692139
Validation loss: 2.274256413181623

Epoch: 5| Step: 11
Training loss: 1.325212836265564
Validation loss: 2.2699202597141266

Epoch: 342| Step: 0
Training loss: 1.1330008506774902
Validation loss: 2.2504220406214395

Epoch: 5| Step: 1
Training loss: 1.1714287996292114
Validation loss: 2.2552181680997214

Epoch: 5| Step: 2
Training loss: 1.568490982055664
Validation loss: 2.2522757003704705

Epoch: 5| Step: 3
Training loss: 1.199786901473999
Validation loss: 2.2346886098384857

Epoch: 5| Step: 4
Training loss: 2.552016019821167
Validation loss: 2.247371792793274

Epoch: 5| Step: 5
Training loss: 1.6172993183135986
Validation loss: 2.2634487251440683

Epoch: 5| Step: 6
Training loss: 1.713779091835022
Validation loss: 2.240693142016729

Epoch: 5| Step: 7
Training loss: 1.3748877048492432
Validation loss: 2.2567048519849777

Epoch: 5| Step: 8
Training loss: 1.7477123737335205
Validation loss: 2.25064018368721

Epoch: 5| Step: 9
Training loss: 1.403016209602356
Validation loss: 2.2203871260086694

Epoch: 5| Step: 10
Training loss: 1.032856822013855
Validation loss: 2.263748029867808

Epoch: 5| Step: 11
Training loss: 1.3299996852874756
Validation loss: 2.217659463485082

Epoch: 343| Step: 0
Training loss: 1.7313671112060547
Validation loss: 2.2473592857519784

Epoch: 5| Step: 1
Training loss: 1.5848188400268555
Validation loss: 2.220353285471598

Epoch: 5| Step: 2
Training loss: 1.3726041316986084
Validation loss: 2.217284848292669

Epoch: 5| Step: 3
Training loss: 1.068265438079834
Validation loss: 2.2918067375818887

Epoch: 5| Step: 4
Training loss: 1.4914753437042236
Validation loss: 2.2753773579994836

Epoch: 5| Step: 5
Training loss: 1.2075632810592651
Validation loss: 2.2377635637919107

Epoch: 5| Step: 6
Training loss: 1.819652795791626
Validation loss: 2.239069233338038

Epoch: 5| Step: 7
Training loss: 1.6007282733917236
Validation loss: 2.2226189275582633

Epoch: 5| Step: 8
Training loss: 1.7145888805389404
Validation loss: 2.204202945033709

Epoch: 5| Step: 9
Training loss: 1.544557809829712
Validation loss: 2.2516221702098846

Epoch: 5| Step: 10
Training loss: 1.437974452972412
Validation loss: 2.2554611464341483

Epoch: 5| Step: 11
Training loss: 1.4323909282684326
Validation loss: 2.2749964197476706

Epoch: 344| Step: 0
Training loss: 1.314979076385498
Validation loss: 2.2718845307826996

Epoch: 5| Step: 1
Training loss: 2.107604742050171
Validation loss: 2.2690307100613913

Epoch: 5| Step: 2
Training loss: 1.7118953466415405
Validation loss: 2.229450265566508

Epoch: 5| Step: 3
Training loss: 1.672163724899292
Validation loss: 2.2105866273244223

Epoch: 5| Step: 4
Training loss: 1.9084733724594116
Validation loss: 2.220961630344391

Epoch: 5| Step: 5
Training loss: 1.8906786441802979
Validation loss: 2.2119309107462564

Epoch: 5| Step: 6
Training loss: 1.2805016040802002
Validation loss: 2.2371800243854523

Epoch: 5| Step: 7
Training loss: 1.1639901399612427
Validation loss: 2.260403345028559

Epoch: 5| Step: 8
Training loss: 1.470163106918335
Validation loss: 2.292280117670695

Epoch: 5| Step: 9
Training loss: 1.0327316522598267
Validation loss: 2.2691735873619714

Epoch: 5| Step: 10
Training loss: 1.2141057252883911
Validation loss: 2.2625708679358163

Epoch: 5| Step: 11
Training loss: 0.6927931308746338
Validation loss: 2.267314334710439

Epoch: 345| Step: 0
Training loss: 1.204516053199768
Validation loss: 2.2587972780068717

Epoch: 5| Step: 1
Training loss: 1.427644968032837
Validation loss: 2.286246041456858

Epoch: 5| Step: 2
Training loss: 1.827993392944336
Validation loss: 2.249075507124265

Epoch: 5| Step: 3
Training loss: 1.1841034889221191
Validation loss: 2.270952512820562

Epoch: 5| Step: 4
Training loss: 1.9305146932601929
Validation loss: 2.2662689685821533

Epoch: 5| Step: 5
Training loss: 0.6902746558189392
Validation loss: 2.3087574342886605

Epoch: 5| Step: 6
Training loss: 1.2640159130096436
Validation loss: 2.2521234154701233

Epoch: 5| Step: 7
Training loss: 1.900933861732483
Validation loss: 2.3114706774552665

Epoch: 5| Step: 8
Training loss: 1.3376681804656982
Validation loss: 2.289237896601359

Epoch: 5| Step: 9
Training loss: 1.6704351902008057
Validation loss: 2.2670385340849557

Epoch: 5| Step: 10
Training loss: 1.7916568517684937
Validation loss: 2.286801432569822

Epoch: 5| Step: 11
Training loss: 1.5932073593139648
Validation loss: 2.3044684131940207

Epoch: 346| Step: 0
Training loss: 1.0250122547149658
Validation loss: 2.2925725877285004

Epoch: 5| Step: 1
Training loss: 2.1252260208129883
Validation loss: 2.2400932163000107

Epoch: 5| Step: 2
Training loss: 1.3856968879699707
Validation loss: 2.2437958319981894

Epoch: 5| Step: 3
Training loss: 0.9984785318374634
Validation loss: 2.223638638854027

Epoch: 5| Step: 4
Training loss: 1.8457071781158447
Validation loss: 2.246312752366066

Epoch: 5| Step: 5
Training loss: 0.9532309770584106
Validation loss: 2.2694398909807205

Epoch: 5| Step: 6
Training loss: 1.7614929676055908
Validation loss: 2.331227496266365

Epoch: 5| Step: 7
Training loss: 1.5936243534088135
Validation loss: 2.2914241552352905

Epoch: 5| Step: 8
Training loss: 1.4653948545455933
Validation loss: 2.293111870686213

Epoch: 5| Step: 9
Training loss: 1.3341832160949707
Validation loss: 2.316158413887024

Epoch: 5| Step: 10
Training loss: 1.787353277206421
Validation loss: 2.3364231437444687

Epoch: 5| Step: 11
Training loss: 1.266268253326416
Validation loss: 2.3003007074197135

Epoch: 347| Step: 0
Training loss: 1.0196235179901123
Validation loss: 2.2677650252978006

Epoch: 5| Step: 1
Training loss: 1.6936734914779663
Validation loss: 2.2206565141677856

Epoch: 5| Step: 2
Training loss: 1.0026657581329346
Validation loss: 2.1787892132997513

Epoch: 5| Step: 3
Training loss: 1.3899978399276733
Validation loss: 2.2111387054125466

Epoch: 5| Step: 4
Training loss: 1.407219409942627
Validation loss: 2.2249731918176017

Epoch: 5| Step: 5
Training loss: 1.2605822086334229
Validation loss: 2.2292778939008713

Epoch: 5| Step: 6
Training loss: 1.8665359020233154
Validation loss: 2.219017823537191

Epoch: 5| Step: 7
Training loss: 1.5672773122787476
Validation loss: 2.2486628890037537

Epoch: 5| Step: 8
Training loss: 1.845123529434204
Validation loss: 2.2691799054543176

Epoch: 5| Step: 9
Training loss: 1.9547160863876343
Validation loss: 2.2698494593302407

Epoch: 5| Step: 10
Training loss: 1.2131856679916382
Validation loss: 2.256326595942179

Epoch: 5| Step: 11
Training loss: 1.3689885139465332
Validation loss: 2.280883098642031

Epoch: 348| Step: 0
Training loss: 1.7681522369384766
Validation loss: 2.383607655763626

Epoch: 5| Step: 1
Training loss: 1.5032336711883545
Validation loss: 2.4211197992165885

Epoch: 5| Step: 2
Training loss: 1.902475357055664
Validation loss: 2.4198761582374573

Epoch: 5| Step: 3
Training loss: 2.1872470378875732
Validation loss: 2.47137842575709

Epoch: 5| Step: 4
Training loss: 1.8629058599472046
Validation loss: 2.450636694828669

Epoch: 5| Step: 5
Training loss: 1.7464841604232788
Validation loss: 2.4300775229930878

Epoch: 5| Step: 6
Training loss: 1.8488757610321045
Validation loss: 2.403524691859881

Epoch: 5| Step: 7
Training loss: 1.4083211421966553
Validation loss: 2.3556956152121225

Epoch: 5| Step: 8
Training loss: 1.3683993816375732
Validation loss: 2.3616512765487037

Epoch: 5| Step: 9
Training loss: 1.4384888410568237
Validation loss: 2.3217575351397195

Epoch: 5| Step: 10
Training loss: 2.027451515197754
Validation loss: 2.27561587591966

Epoch: 5| Step: 11
Training loss: 0.5519730448722839
Validation loss: 2.264247789978981

Epoch: 349| Step: 0
Training loss: 1.3025814294815063
Validation loss: 2.2650440335273743

Epoch: 5| Step: 1
Training loss: 2.0116591453552246
Validation loss: 2.2619520723819733

Epoch: 5| Step: 2
Training loss: 1.4536858797073364
Validation loss: 2.2696052193641663

Epoch: 5| Step: 3
Training loss: 1.6877368688583374
Validation loss: 2.26474899550279

Epoch: 5| Step: 4
Training loss: 2.635556936264038
Validation loss: 2.2797276775042215

Epoch: 5| Step: 5
Training loss: 1.1797047853469849
Validation loss: 2.2872266123692193

Epoch: 5| Step: 6
Training loss: 1.5898785591125488
Validation loss: 2.2730951060851416

Epoch: 5| Step: 7
Training loss: 2.2146103382110596
Validation loss: 2.293910652399063

Epoch: 5| Step: 8
Training loss: 1.0979734659194946
Validation loss: 2.2947177787621817

Epoch: 5| Step: 9
Training loss: 1.5005022287368774
Validation loss: 2.285918871561686

Epoch: 5| Step: 10
Training loss: 1.695094347000122
Validation loss: 2.247625857591629

Epoch: 5| Step: 11
Training loss: 1.5136687755584717
Validation loss: 2.2668900191783905

Epoch: 350| Step: 0
Training loss: 1.9195572137832642
Validation loss: 2.294644524653753

Epoch: 5| Step: 1
Training loss: 1.7028300762176514
Validation loss: 2.2872333228588104

Epoch: 5| Step: 2
Training loss: 1.8059895038604736
Validation loss: 2.2728423178195953

Epoch: 5| Step: 3
Training loss: 1.6296440362930298
Validation loss: 2.3093713919321694

Epoch: 5| Step: 4
Training loss: 1.2986633777618408
Validation loss: 2.2843120197455087

Epoch: 5| Step: 5
Training loss: 1.122011661529541
Validation loss: 2.2903479784727097

Epoch: 5| Step: 6
Training loss: 1.661137580871582
Validation loss: 2.254705553253492

Epoch: 5| Step: 7
Training loss: 0.8578394055366516
Validation loss: 2.253275672594706

Epoch: 5| Step: 8
Training loss: 1.4697647094726562
Validation loss: 2.231219862898191

Epoch: 5| Step: 9
Training loss: 1.3804107904434204
Validation loss: 2.226145471135775

Epoch: 5| Step: 10
Training loss: 2.1014175415039062
Validation loss: 2.240447317560514

Epoch: 5| Step: 11
Training loss: 1.2763391733169556
Validation loss: 2.229743003845215

Epoch: 351| Step: 0
Training loss: 1.7661006450653076
Validation loss: 2.246720845500628

Epoch: 5| Step: 1
Training loss: 1.4347646236419678
Validation loss: 2.227351819475492

Epoch: 5| Step: 2
Training loss: 1.7418512105941772
Validation loss: 2.2345380385716758

Epoch: 5| Step: 3
Training loss: 1.0834810733795166
Validation loss: 2.2496412793795266

Epoch: 5| Step: 4
Training loss: 1.1061428785324097
Validation loss: 2.233847444256147

Epoch: 5| Step: 5
Training loss: 1.5157917737960815
Validation loss: 2.2188674906889596

Epoch: 5| Step: 6
Training loss: 1.7217477560043335
Validation loss: 2.2352972825368247

Epoch: 5| Step: 7
Training loss: 1.3202861547470093
Validation loss: 2.2434655030568442

Epoch: 5| Step: 8
Training loss: 1.2555347681045532
Validation loss: 2.2332266767819724

Epoch: 5| Step: 9
Training loss: 2.2676641941070557
Validation loss: 2.2486612300078073

Epoch: 5| Step: 10
Training loss: 1.3518494367599487
Validation loss: 2.2388065258661904

Epoch: 5| Step: 11
Training loss: 0.9005771279335022
Validation loss: 2.234354615211487

Epoch: 352| Step: 0
Training loss: 1.3772484064102173
Validation loss: 2.212334762016932

Epoch: 5| Step: 1
Training loss: 1.3896132707595825
Validation loss: 2.2016530483961105

Epoch: 5| Step: 2
Training loss: 1.8244869709014893
Validation loss: 2.1756784518559775

Epoch: 5| Step: 3
Training loss: 1.4582197666168213
Validation loss: 2.197325194875399

Epoch: 5| Step: 4
Training loss: 1.6297489404678345
Validation loss: 2.2027847866217294

Epoch: 5| Step: 5
Training loss: 1.2703876495361328
Validation loss: 2.2419089674949646

Epoch: 5| Step: 6
Training loss: 1.9587455987930298
Validation loss: 2.2951475332180657

Epoch: 5| Step: 7
Training loss: 1.3624694347381592
Validation loss: 2.361672595143318

Epoch: 5| Step: 8
Training loss: 1.8237224817276
Validation loss: 2.3189900517463684

Epoch: 5| Step: 9
Training loss: 1.3061155080795288
Validation loss: 2.353151390949885

Epoch: 5| Step: 10
Training loss: 1.1888469457626343
Validation loss: 2.31285168727239

Epoch: 5| Step: 11
Training loss: 1.298932433128357
Validation loss: 2.3549980421861014

Epoch: 353| Step: 0
Training loss: 0.9656563997268677
Validation loss: 2.336651454369227

Epoch: 5| Step: 1
Training loss: 2.096270799636841
Validation loss: 2.2990943690141044

Epoch: 5| Step: 2
Training loss: 1.6246755123138428
Validation loss: 2.2959555983543396

Epoch: 5| Step: 3
Training loss: 2.1809628009796143
Validation loss: 2.2952712873617807

Epoch: 5| Step: 4
Training loss: 1.2594835758209229
Validation loss: 2.2509832282861075

Epoch: 5| Step: 5
Training loss: 0.8041113018989563
Validation loss: 2.2296634117762246

Epoch: 5| Step: 6
Training loss: 1.0300240516662598
Validation loss: 2.2472800811131797

Epoch: 5| Step: 7
Training loss: 1.7218410968780518
Validation loss: 2.2505333870649338

Epoch: 5| Step: 8
Training loss: 1.8483550548553467
Validation loss: 2.2512473464012146

Epoch: 5| Step: 9
Training loss: 1.1027462482452393
Validation loss: 2.2279284497102103

Epoch: 5| Step: 10
Training loss: 1.6166160106658936
Validation loss: 2.2794840931892395

Epoch: 5| Step: 11
Training loss: 0.2229975461959839
Validation loss: 2.2809457778930664

Epoch: 354| Step: 0
Training loss: 1.9377435445785522
Validation loss: 2.3191019097963967

Epoch: 5| Step: 1
Training loss: 1.9411532878875732
Validation loss: 2.2925495505332947

Epoch: 5| Step: 2
Training loss: 1.3228857517242432
Validation loss: 2.313482349117597

Epoch: 5| Step: 3
Training loss: 1.9605929851531982
Validation loss: 2.3228706816832223

Epoch: 5| Step: 4
Training loss: 1.2814840078353882
Validation loss: 2.295569732785225

Epoch: 5| Step: 5
Training loss: 1.487125039100647
Validation loss: 2.3128884732723236

Epoch: 5| Step: 6
Training loss: 1.176112413406372
Validation loss: 2.2821960697571435

Epoch: 5| Step: 7
Training loss: 1.1977803707122803
Validation loss: 2.2531808614730835

Epoch: 5| Step: 8
Training loss: 1.1775399446487427
Validation loss: 2.239528069893519

Epoch: 5| Step: 9
Training loss: 1.4164884090423584
Validation loss: 2.253707235058149

Epoch: 5| Step: 10
Training loss: 1.4733116626739502
Validation loss: 2.284599930047989

Epoch: 5| Step: 11
Training loss: 1.0854140520095825
Validation loss: 2.267867018779119

Epoch: 355| Step: 0
Training loss: 1.4890574216842651
Validation loss: 2.288004626830419

Epoch: 5| Step: 1
Training loss: 1.4739964008331299
Validation loss: 2.283295134703318

Epoch: 5| Step: 2
Training loss: 1.3323698043823242
Validation loss: 2.301010330518087

Epoch: 5| Step: 3
Training loss: 2.291214942932129
Validation loss: 2.3193134367465973

Epoch: 5| Step: 4
Training loss: 1.2631175518035889
Validation loss: 2.3193062047163644

Epoch: 5| Step: 5
Training loss: 1.2016887664794922
Validation loss: 2.2921315481265387

Epoch: 5| Step: 6
Training loss: 1.4838142395019531
Validation loss: 2.3075567185878754

Epoch: 5| Step: 7
Training loss: 0.9686778783798218
Validation loss: 2.3320741752783456

Epoch: 5| Step: 8
Training loss: 1.3349716663360596
Validation loss: 2.327931225299835

Epoch: 5| Step: 9
Training loss: 1.0694406032562256
Validation loss: 2.325499931971232

Epoch: 5| Step: 10
Training loss: 1.857038140296936
Validation loss: 2.3280646254618964

Epoch: 5| Step: 11
Training loss: 1.1339027881622314
Validation loss: 2.2800076007843018

Epoch: 356| Step: 0
Training loss: 1.2081142663955688
Validation loss: 2.3084346801042557

Epoch: 5| Step: 1
Training loss: 1.645878553390503
Validation loss: 2.3073419084151587

Epoch: 5| Step: 2
Training loss: 1.304070234298706
Validation loss: 2.318934381008148

Epoch: 5| Step: 3
Training loss: 1.4964525699615479
Validation loss: 2.2948869119087854

Epoch: 5| Step: 4
Training loss: 1.7452518939971924
Validation loss: 2.2934280981620154

Epoch: 5| Step: 5
Training loss: 1.3266901969909668
Validation loss: 2.336300661166509

Epoch: 5| Step: 6
Training loss: 1.442939043045044
Validation loss: 2.29905034104983

Epoch: 5| Step: 7
Training loss: 2.1972439289093018
Validation loss: 2.312963386376699

Epoch: 5| Step: 8
Training loss: 1.580298900604248
Validation loss: 2.2922271688779197

Epoch: 5| Step: 9
Training loss: 0.9585960507392883
Validation loss: 2.312387521068255

Epoch: 5| Step: 10
Training loss: 1.1857985258102417
Validation loss: 2.2919221967458725

Epoch: 5| Step: 11
Training loss: 1.0266931056976318
Validation loss: 2.305109957853953

Epoch: 357| Step: 0
Training loss: 1.2405952215194702
Validation loss: 2.285256505012512

Epoch: 5| Step: 1
Training loss: 1.0892243385314941
Validation loss: 2.285151486595472

Epoch: 5| Step: 2
Training loss: 1.272984266281128
Validation loss: 2.30049267411232

Epoch: 5| Step: 3
Training loss: 2.1104896068573
Validation loss: 2.3078754196564355

Epoch: 5| Step: 4
Training loss: 1.6212432384490967
Validation loss: 2.3157603045304618

Epoch: 5| Step: 5
Training loss: 1.097646951675415
Validation loss: 2.300468236207962

Epoch: 5| Step: 6
Training loss: 1.2032734155654907
Validation loss: 2.3118233184019723

Epoch: 5| Step: 7
Training loss: 1.6435810327529907
Validation loss: 2.3461522459983826

Epoch: 5| Step: 8
Training loss: 1.4004732370376587
Validation loss: 2.2799170911312103

Epoch: 5| Step: 9
Training loss: 1.614263892173767
Validation loss: 2.3148489395777383

Epoch: 5| Step: 10
Training loss: 1.519841194152832
Validation loss: 2.3239143987496695

Epoch: 5| Step: 11
Training loss: 1.9063732624053955
Validation loss: 2.3485570549964905

Epoch: 358| Step: 0
Training loss: 1.79812753200531
Validation loss: 2.3081263303756714

Epoch: 5| Step: 1
Training loss: 1.7996673583984375
Validation loss: 2.317381983002027

Epoch: 5| Step: 2
Training loss: 1.6352431774139404
Validation loss: 2.3112025757630668

Epoch: 5| Step: 3
Training loss: 1.4439241886138916
Validation loss: 2.3013053834438324

Epoch: 5| Step: 4
Training loss: 0.9019764065742493
Validation loss: 2.266889661550522

Epoch: 5| Step: 5
Training loss: 1.4946496486663818
Validation loss: 2.2384807964166007

Epoch: 5| Step: 6
Training loss: 1.0094201564788818
Validation loss: 2.241552179058393

Epoch: 5| Step: 7
Training loss: 1.4566491842269897
Validation loss: 2.2497579952081046

Epoch: 5| Step: 8
Training loss: 1.0034288167953491
Validation loss: 2.249431625008583

Epoch: 5| Step: 9
Training loss: 2.001391887664795
Validation loss: 2.274484862883886

Epoch: 5| Step: 10
Training loss: 1.303706407546997
Validation loss: 2.2649408926566443

Epoch: 5| Step: 11
Training loss: 1.2404340505599976
Validation loss: 2.2935404926538467

Epoch: 359| Step: 0
Training loss: 2.282128095626831
Validation loss: 2.317866330345472

Epoch: 5| Step: 1
Training loss: 1.3789780139923096
Validation loss: 2.3112096885840097

Epoch: 5| Step: 2
Training loss: 1.7863140106201172
Validation loss: 2.330764979124069

Epoch: 5| Step: 3
Training loss: 1.8254200220108032
Validation loss: 2.339166969060898

Epoch: 5| Step: 4
Training loss: 1.137960433959961
Validation loss: 2.292797793944677

Epoch: 5| Step: 5
Training loss: 1.748617172241211
Validation loss: 2.272417296965917

Epoch: 5| Step: 6
Training loss: 1.1406660079956055
Validation loss: 2.314050003886223

Epoch: 5| Step: 7
Training loss: 1.5821744203567505
Validation loss: 2.2789528220891953

Epoch: 5| Step: 8
Training loss: 1.0150307416915894
Validation loss: 2.2592177192370095

Epoch: 5| Step: 9
Training loss: 1.1691043376922607
Validation loss: 2.2256064862012863

Epoch: 5| Step: 10
Training loss: 1.2782728672027588
Validation loss: 2.232901801665624

Epoch: 5| Step: 11
Training loss: 1.9780380725860596
Validation loss: 2.247188995281855

Epoch: 360| Step: 0
Training loss: 1.829290747642517
Validation loss: 2.2522658308347068

Epoch: 5| Step: 1
Training loss: 1.6168854236602783
Validation loss: 2.2585895558198295

Epoch: 5| Step: 2
Training loss: 1.5086588859558105
Validation loss: 2.263970211148262

Epoch: 5| Step: 3
Training loss: 1.2798211574554443
Validation loss: 2.244330088297526

Epoch: 5| Step: 4
Training loss: 0.9460235834121704
Validation loss: 2.243436594804128

Epoch: 5| Step: 5
Training loss: 1.3254960775375366
Validation loss: 2.2216363847255707

Epoch: 5| Step: 6
Training loss: 2.4725842475891113
Validation loss: 2.280882408221563

Epoch: 5| Step: 7
Training loss: 1.7864021062850952
Validation loss: 2.2931529531876245

Epoch: 5| Step: 8
Training loss: 0.8918505907058716
Validation loss: 2.288794130086899

Epoch: 5| Step: 9
Training loss: 1.4297702312469482
Validation loss: 2.334921548763911

Epoch: 5| Step: 10
Training loss: 1.30167555809021
Validation loss: 2.2673895408709845

Epoch: 5| Step: 11
Training loss: 0.9970045685768127
Validation loss: 2.2539775570233664

Epoch: 361| Step: 0
Training loss: 1.610314965248108
Validation loss: 2.2254847238461175

Epoch: 5| Step: 1
Training loss: 1.8767837285995483
Validation loss: 2.21343956887722

Epoch: 5| Step: 2
Training loss: 1.3688938617706299
Validation loss: 2.2200815677642822

Epoch: 5| Step: 3
Training loss: 1.7204599380493164
Validation loss: 2.2290369967619577

Epoch: 5| Step: 4
Training loss: 1.4350625276565552
Validation loss: 2.245774800578753

Epoch: 5| Step: 5
Training loss: 1.061450719833374
Validation loss: 2.2574165364106498

Epoch: 5| Step: 6
Training loss: 1.2751274108886719
Validation loss: 2.2822179893652597

Epoch: 5| Step: 7
Training loss: 1.2553410530090332
Validation loss: 2.275134950876236

Epoch: 5| Step: 8
Training loss: 1.5785588026046753
Validation loss: 2.3312593003114066

Epoch: 5| Step: 9
Training loss: 1.3797576427459717
Validation loss: 2.349340791503588

Epoch: 5| Step: 10
Training loss: 1.6787116527557373
Validation loss: 2.316912571589152

Epoch: 5| Step: 11
Training loss: 0.7835371494293213
Validation loss: 2.357307215531667

Epoch: 362| Step: 0
Training loss: 1.96249258518219
Validation loss: 2.3424339840809503

Epoch: 5| Step: 1
Training loss: 1.4416401386260986
Validation loss: 2.348313753803571

Epoch: 5| Step: 2
Training loss: 1.4844847917556763
Validation loss: 2.32029997309049

Epoch: 5| Step: 3
Training loss: 1.279966950416565
Validation loss: 2.2971031020085015

Epoch: 5| Step: 4
Training loss: 2.024095296859741
Validation loss: 2.26872988541921

Epoch: 5| Step: 5
Training loss: 1.528159260749817
Validation loss: 2.2121795018514

Epoch: 5| Step: 6
Training loss: 2.027405261993408
Validation loss: 2.247995654741923

Epoch: 5| Step: 7
Training loss: 1.313620924949646
Validation loss: 2.2569798628489175

Epoch: 5| Step: 8
Training loss: 1.339068055152893
Validation loss: 2.2351834376653037

Epoch: 5| Step: 9
Training loss: 1.2721201181411743
Validation loss: 2.245760311683019

Epoch: 5| Step: 10
Training loss: 0.7389808297157288
Validation loss: 2.2423975517352424

Epoch: 5| Step: 11
Training loss: 3.8658740520477295
Validation loss: 2.2590705205996833

Epoch: 363| Step: 0
Training loss: 1.8034048080444336
Validation loss: 2.2835823148489

Epoch: 5| Step: 1
Training loss: 2.2935070991516113
Validation loss: 2.33222259581089

Epoch: 5| Step: 2
Training loss: 1.4538414478302002
Validation loss: 2.29236630598704

Epoch: 5| Step: 3
Training loss: 1.5803320407867432
Validation loss: 2.31188657383124

Epoch: 5| Step: 4
Training loss: 1.0788825750350952
Validation loss: 2.3396948923667273

Epoch: 5| Step: 5
Training loss: 1.6836354732513428
Validation loss: 2.3599349757035575

Epoch: 5| Step: 6
Training loss: 1.1298491954803467
Validation loss: 2.3268276701370874

Epoch: 5| Step: 7
Training loss: 1.5723451375961304
Validation loss: 2.298358917236328

Epoch: 5| Step: 8
Training loss: 1.5042483806610107
Validation loss: 2.250253438949585

Epoch: 5| Step: 9
Training loss: 1.085193395614624
Validation loss: 2.2457092503706613

Epoch: 5| Step: 10
Training loss: 1.157715082168579
Validation loss: 2.226284792025884

Epoch: 5| Step: 11
Training loss: 1.222199559211731
Validation loss: 2.2062342365582785

Epoch: 364| Step: 0
Training loss: 1.1319143772125244
Validation loss: 2.232124795516332

Epoch: 5| Step: 1
Training loss: 1.6431877613067627
Validation loss: 2.2141131162643433

Epoch: 5| Step: 2
Training loss: 2.75110125541687
Validation loss: 2.224910537401835

Epoch: 5| Step: 3
Training loss: 1.3334259986877441
Validation loss: 2.236580659945806

Epoch: 5| Step: 4
Training loss: 1.3196146488189697
Validation loss: 2.1999395887056985

Epoch: 5| Step: 5
Training loss: 1.0603938102722168
Validation loss: 2.2097418357928595

Epoch: 5| Step: 6
Training loss: 1.296115756034851
Validation loss: 2.260567456483841

Epoch: 5| Step: 7
Training loss: 1.4059486389160156
Validation loss: 2.274346416195234

Epoch: 5| Step: 8
Training loss: 2.1007447242736816
Validation loss: 2.2779577622811

Epoch: 5| Step: 9
Training loss: 1.2613635063171387
Validation loss: 2.2595615486303964

Epoch: 5| Step: 10
Training loss: 0.8624628186225891
Validation loss: 2.2433973203102746

Epoch: 5| Step: 11
Training loss: 0.9328399896621704
Validation loss: 2.2696821043888726

Epoch: 365| Step: 0
Training loss: 1.7582385540008545
Validation loss: 2.2317290604114532

Epoch: 5| Step: 1
Training loss: 0.8935158848762512
Validation loss: 2.224374622106552

Epoch: 5| Step: 2
Training loss: 1.7642250061035156
Validation loss: 2.2211182514826455

Epoch: 5| Step: 3
Training loss: 0.95526123046875
Validation loss: 2.2269829909006753

Epoch: 5| Step: 4
Training loss: 1.6656239032745361
Validation loss: 2.2488633195559182

Epoch: 5| Step: 5
Training loss: 1.4385101795196533
Validation loss: 2.220187187194824

Epoch: 5| Step: 6
Training loss: 1.9173341989517212
Validation loss: 2.232007051507632

Epoch: 5| Step: 7
Training loss: 1.3662643432617188
Validation loss: 2.268297572930654

Epoch: 5| Step: 8
Training loss: 1.298219919204712
Validation loss: 2.30557848016421

Epoch: 5| Step: 9
Training loss: 1.193886637687683
Validation loss: 2.3083117306232452

Epoch: 5| Step: 10
Training loss: 1.2443103790283203
Validation loss: 2.319355587164561

Epoch: 5| Step: 11
Training loss: 2.7857251167297363
Validation loss: 2.297682742277781

Epoch: 366| Step: 0
Training loss: 1.6154861450195312
Validation loss: 2.3006737430890403

Epoch: 5| Step: 1
Training loss: 0.8725148439407349
Validation loss: 2.287314852078756

Epoch: 5| Step: 2
Training loss: 1.8085973262786865
Validation loss: 2.282998338341713

Epoch: 5| Step: 3
Training loss: 1.360824704170227
Validation loss: 2.286355117956797

Epoch: 5| Step: 4
Training loss: 1.7052028179168701
Validation loss: 2.3094617972771325

Epoch: 5| Step: 5
Training loss: 0.8332315683364868
Validation loss: 2.2851321697235107

Epoch: 5| Step: 6
Training loss: 1.4203442335128784
Validation loss: 2.282913774251938

Epoch: 5| Step: 7
Training loss: 1.3153705596923828
Validation loss: 2.3149621884028115

Epoch: 5| Step: 8
Training loss: 1.8493621349334717
Validation loss: 2.285300145546595

Epoch: 5| Step: 9
Training loss: 1.1883604526519775
Validation loss: 2.2933937708536782

Epoch: 5| Step: 10
Training loss: 1.324325442314148
Validation loss: 2.308949420849482

Epoch: 5| Step: 11
Training loss: 1.3463283777236938
Validation loss: 2.2878106037775674

Epoch: 367| Step: 0
Training loss: 1.0555763244628906
Validation loss: 2.300048549969991

Epoch: 5| Step: 1
Training loss: 1.6403367519378662
Validation loss: 2.2563283542792

Epoch: 5| Step: 2
Training loss: 1.3268022537231445
Validation loss: 2.289205387234688

Epoch: 5| Step: 3
Training loss: 1.757333517074585
Validation loss: 2.2717202653487525

Epoch: 5| Step: 4
Training loss: 1.1241763830184937
Validation loss: 2.30592210094134

Epoch: 5| Step: 5
Training loss: 1.4681692123413086
Validation loss: 2.2880250910917916

Epoch: 5| Step: 6
Training loss: 1.26346755027771
Validation loss: 2.3120184242725372

Epoch: 5| Step: 7
Training loss: 1.0842363834381104
Validation loss: 2.3440369963645935

Epoch: 5| Step: 8
Training loss: 1.8113454580307007
Validation loss: 2.3368966380755105

Epoch: 5| Step: 9
Training loss: 1.6260814666748047
Validation loss: 2.3024973968664804

Epoch: 5| Step: 10
Training loss: 1.6507387161254883
Validation loss: 2.2961917221546173

Epoch: 5| Step: 11
Training loss: 0.4265996813774109
Validation loss: 2.30546968181928

Epoch: 368| Step: 0
Training loss: 1.6032135486602783
Validation loss: 2.299191951751709

Epoch: 5| Step: 1
Training loss: 1.2148571014404297
Validation loss: 2.307409256696701

Epoch: 5| Step: 2
Training loss: 1.4934797286987305
Validation loss: 2.288619418938955

Epoch: 5| Step: 3
Training loss: 1.1237266063690186
Validation loss: 2.25206658244133

Epoch: 5| Step: 4
Training loss: 1.08381187915802
Validation loss: 2.2909207393725715

Epoch: 5| Step: 5
Training loss: 1.9344596862792969
Validation loss: 2.272300918896993

Epoch: 5| Step: 6
Training loss: 1.7686131000518799
Validation loss: 2.2433480322360992

Epoch: 5| Step: 7
Training loss: 1.785667061805725
Validation loss: 2.266058847308159

Epoch: 5| Step: 8
Training loss: 0.8395006060600281
Validation loss: 2.279744784037272

Epoch: 5| Step: 9
Training loss: 1.3698030710220337
Validation loss: 2.287636548280716

Epoch: 5| Step: 10
Training loss: 1.1240991353988647
Validation loss: 2.286026507616043

Epoch: 5| Step: 11
Training loss: 0.8759588599205017
Validation loss: 2.30236279964447

Epoch: 369| Step: 0
Training loss: 1.2936252355575562
Validation loss: 2.34775547683239

Epoch: 5| Step: 1
Training loss: 1.790808916091919
Validation loss: 2.3116189440091452

Epoch: 5| Step: 2
Training loss: 1.538849949836731
Validation loss: 2.3212229857842126

Epoch: 5| Step: 3
Training loss: 1.2824680805206299
Validation loss: 2.3210798303286233

Epoch: 5| Step: 4
Training loss: 1.2033367156982422
Validation loss: 2.3353273967901864

Epoch: 5| Step: 5
Training loss: 2.0094330310821533
Validation loss: 2.3425001998742423

Epoch: 5| Step: 6
Training loss: 1.0701346397399902
Validation loss: 2.316625972588857

Epoch: 5| Step: 7
Training loss: 0.8829501271247864
Validation loss: 2.3113759259382882

Epoch: 5| Step: 8
Training loss: 1.0159642696380615
Validation loss: 2.296203871568044

Epoch: 5| Step: 9
Training loss: 2.0038769245147705
Validation loss: 2.284858529766401

Epoch: 5| Step: 10
Training loss: 1.1182136535644531
Validation loss: 2.26518352329731

Epoch: 5| Step: 11
Training loss: 0.8289691805839539
Validation loss: 2.2775709331035614

Epoch: 370| Step: 0
Training loss: 1.452343225479126
Validation loss: 2.283870925505956

Epoch: 5| Step: 1
Training loss: 1.3906716108322144
Validation loss: 2.276106834411621

Epoch: 5| Step: 2
Training loss: 1.7836357355117798
Validation loss: 2.315509617328644

Epoch: 5| Step: 3
Training loss: 0.7662283182144165
Validation loss: 2.3120434284210205

Epoch: 5| Step: 4
Training loss: 1.383262038230896
Validation loss: 2.33628456791242

Epoch: 5| Step: 5
Training loss: 2.131251573562622
Validation loss: 2.30950661500295

Epoch: 5| Step: 6
Training loss: 1.7701278924942017
Validation loss: 2.313616265853246

Epoch: 5| Step: 7
Training loss: 1.3927891254425049
Validation loss: 2.320125346382459

Epoch: 5| Step: 8
Training loss: 0.7184866070747375
Validation loss: 2.2870316207408905

Epoch: 5| Step: 9
Training loss: 1.0845434665679932
Validation loss: 2.2949540615081787

Epoch: 5| Step: 10
Training loss: 1.0299861431121826
Validation loss: 2.301236445705096

Epoch: 5| Step: 11
Training loss: 3.16166353225708
Validation loss: 2.2621580064296722

Epoch: 371| Step: 0
Training loss: 0.9640433192253113
Validation loss: 2.3084390809138617

Epoch: 5| Step: 1
Training loss: 1.5265051126480103
Validation loss: 2.3364179581403732

Epoch: 5| Step: 2
Training loss: 2.160327911376953
Validation loss: 2.327005078395208

Epoch: 5| Step: 3
Training loss: 1.329650640487671
Validation loss: 2.3437629689772925

Epoch: 5| Step: 4
Training loss: 1.3219586610794067
Validation loss: 2.3473997910817466

Epoch: 5| Step: 5
Training loss: 1.4438680410385132
Validation loss: 2.34990501900514

Epoch: 5| Step: 6
Training loss: 1.3008424043655396
Validation loss: 2.3170188665390015

Epoch: 5| Step: 7
Training loss: 1.6414425373077393
Validation loss: 2.303393433491389

Epoch: 5| Step: 8
Training loss: 2.023069143295288
Validation loss: 2.3102996746699014

Epoch: 5| Step: 9
Training loss: 0.9072939157485962
Validation loss: 2.2739812284708023

Epoch: 5| Step: 10
Training loss: 1.0459132194519043
Validation loss: 2.3252400010824203

Epoch: 5| Step: 11
Training loss: 2.362077474594116
Validation loss: 2.2838501731554666

Epoch: 372| Step: 0
Training loss: 0.8448064923286438
Validation loss: 2.2794968485832214

Epoch: 5| Step: 1
Training loss: 1.5480577945709229
Validation loss: 2.2602762480576835

Epoch: 5| Step: 2
Training loss: 1.2721484899520874
Validation loss: 2.2411289115746817

Epoch: 5| Step: 3
Training loss: 1.5270670652389526
Validation loss: 2.228267729282379

Epoch: 5| Step: 4
Training loss: 1.5650103092193604
Validation loss: 2.2609152048826218

Epoch: 5| Step: 5
Training loss: 1.4006484746932983
Validation loss: 2.250877633690834

Epoch: 5| Step: 6
Training loss: 1.594334363937378
Validation loss: 2.2225923935572305

Epoch: 5| Step: 7
Training loss: 1.680283546447754
Validation loss: 2.25659770766894

Epoch: 5| Step: 8
Training loss: 1.2980444431304932
Validation loss: 2.2357534021139145

Epoch: 5| Step: 9
Training loss: 1.1645725965499878
Validation loss: 2.2322677175203958

Epoch: 5| Step: 10
Training loss: 1.4398913383483887
Validation loss: 2.2705321510632834

Epoch: 5| Step: 11
Training loss: 1.1735188961029053
Validation loss: 2.2679707556962967

Epoch: 373| Step: 0
Training loss: 1.1680810451507568
Validation loss: 2.265588770310084

Epoch: 5| Step: 1
Training loss: 1.699366569519043
Validation loss: 2.2535040825605392

Epoch: 5| Step: 2
Training loss: 1.6474624872207642
Validation loss: 2.2516901890436807

Epoch: 5| Step: 3
Training loss: 1.2786026000976562
Validation loss: 2.253701498111089

Epoch: 5| Step: 4
Training loss: 1.256683349609375
Validation loss: 2.263427823781967

Epoch: 5| Step: 5
Training loss: 1.377426028251648
Validation loss: 2.2104256451129913

Epoch: 5| Step: 6
Training loss: 1.0770541429519653
Validation loss: 2.245655963818232

Epoch: 5| Step: 7
Training loss: 1.868035078048706
Validation loss: 2.2261296113332114

Epoch: 5| Step: 8
Training loss: 1.8568217754364014
Validation loss: 2.244645968079567

Epoch: 5| Step: 9
Training loss: 1.0303782224655151
Validation loss: 2.2555440763632455

Epoch: 5| Step: 10
Training loss: 1.149972915649414
Validation loss: 2.2990740090608597

Epoch: 5| Step: 11
Training loss: 0.7629178762435913
Validation loss: 2.2676096707582474

Epoch: 374| Step: 0
Training loss: 1.7286564111709595
Validation loss: 2.289662554860115

Epoch: 5| Step: 1
Training loss: 1.3361079692840576
Validation loss: 2.295898954073588

Epoch: 5| Step: 2
Training loss: 0.8905094861984253
Validation loss: 2.2629829198122025

Epoch: 5| Step: 3
Training loss: 1.442260503768921
Validation loss: 2.2803946981827417

Epoch: 5| Step: 4
Training loss: 1.738800287246704
Validation loss: 2.2769602338473

Epoch: 5| Step: 5
Training loss: 1.4453136920928955
Validation loss: 2.250924145181974

Epoch: 5| Step: 6
Training loss: 1.9498802423477173
Validation loss: 2.248932550350825

Epoch: 5| Step: 7
Training loss: 1.1187564134597778
Validation loss: 2.2630082170168557

Epoch: 5| Step: 8
Training loss: 1.3176604509353638
Validation loss: 2.233186920483907

Epoch: 5| Step: 9
Training loss: 1.3918225765228271
Validation loss: 2.2152398775021234

Epoch: 5| Step: 10
Training loss: 1.4744030237197876
Validation loss: 2.2294338196516037

Epoch: 5| Step: 11
Training loss: 0.5785191655158997
Validation loss: 2.2342761953671775

Epoch: 375| Step: 0
Training loss: 0.9500676393508911
Validation loss: 2.2368501474459968

Epoch: 5| Step: 1
Training loss: 1.4012656211853027
Validation loss: 2.222417563199997

Epoch: 5| Step: 2
Training loss: 1.0256938934326172
Validation loss: 2.2485079566637673

Epoch: 5| Step: 3
Training loss: 1.3757290840148926
Validation loss: 2.2143595119317374

Epoch: 5| Step: 4
Training loss: 1.626833200454712
Validation loss: 2.2502145717541375

Epoch: 5| Step: 5
Training loss: 1.8521897792816162
Validation loss: 2.2214950919151306

Epoch: 5| Step: 6
Training loss: 1.8020683526992798
Validation loss: 2.212378809849421

Epoch: 5| Step: 7
Training loss: 1.2220453023910522
Validation loss: 2.2495618561903634

Epoch: 5| Step: 8
Training loss: 1.3571436405181885
Validation loss: 2.281737665335337

Epoch: 5| Step: 9
Training loss: 1.4540414810180664
Validation loss: 2.2439533174037933

Epoch: 5| Step: 10
Training loss: 1.7293102741241455
Validation loss: 2.2450493474801383

Epoch: 5| Step: 11
Training loss: 1.0765118598937988
Validation loss: 2.233836352825165

Epoch: 376| Step: 0
Training loss: 1.6554632186889648
Validation loss: 2.2360291182994843

Epoch: 5| Step: 1
Training loss: 1.7133716344833374
Validation loss: 2.2482940504948297

Epoch: 5| Step: 2
Training loss: 1.0825588703155518
Validation loss: 2.26933191716671

Epoch: 5| Step: 3
Training loss: 1.3532750606536865
Validation loss: 2.25038214524587

Epoch: 5| Step: 4
Training loss: 2.0255720615386963
Validation loss: 2.2177793135245643

Epoch: 5| Step: 5
Training loss: 1.127185583114624
Validation loss: 2.2173232237497964

Epoch: 5| Step: 6
Training loss: 1.3682878017425537
Validation loss: 2.2752210994561515

Epoch: 5| Step: 7
Training loss: 1.6036903858184814
Validation loss: 2.2552480896313987

Epoch: 5| Step: 8
Training loss: 1.074379324913025
Validation loss: 2.2757366647322974

Epoch: 5| Step: 9
Training loss: 1.1330543756484985
Validation loss: 2.2700916131337485

Epoch: 5| Step: 10
Training loss: 1.9808712005615234
Validation loss: 2.306814730167389

Epoch: 5| Step: 11
Training loss: 0.7296904921531677
Validation loss: 2.2648224532604218

Epoch: 377| Step: 0
Training loss: 0.8192447423934937
Validation loss: 2.249516487121582

Epoch: 5| Step: 1
Training loss: 2.269571542739868
Validation loss: 2.261069347461065

Epoch: 5| Step: 2
Training loss: 1.8439375162124634
Validation loss: 2.223987470070521

Epoch: 5| Step: 3
Training loss: 1.2834694385528564
Validation loss: 2.2307616720596948

Epoch: 5| Step: 4
Training loss: 1.9026588201522827
Validation loss: 2.2223737438519797

Epoch: 5| Step: 5
Training loss: 1.1219652891159058
Validation loss: 2.223255376021067

Epoch: 5| Step: 6
Training loss: 1.5436217784881592
Validation loss: 2.1855297485987344

Epoch: 5| Step: 7
Training loss: 1.5369360446929932
Validation loss: 2.207851847012838

Epoch: 5| Step: 8
Training loss: 1.127875566482544
Validation loss: 2.2409070432186127

Epoch: 5| Step: 9
Training loss: 1.0197696685791016
Validation loss: 2.265116254488627

Epoch: 5| Step: 10
Training loss: 1.0956717729568481
Validation loss: 2.2703268031279245

Epoch: 5| Step: 11
Training loss: 2.3371965885162354
Validation loss: 2.2924594779809317

Epoch: 378| Step: 0
Training loss: 1.446089267730713
Validation loss: 2.347698171933492

Epoch: 5| Step: 1
Training loss: 1.2589730024337769
Validation loss: 2.2847136656443277

Epoch: 5| Step: 2
Training loss: 1.4393476247787476
Validation loss: 2.2982616623242698

Epoch: 5| Step: 3
Training loss: 1.3355741500854492
Validation loss: 2.304615542292595

Epoch: 5| Step: 4
Training loss: 1.6904395818710327
Validation loss: 2.309551323453585

Epoch: 5| Step: 5
Training loss: 1.2676100730895996
Validation loss: 2.2798125545183816

Epoch: 5| Step: 6
Training loss: 0.9786893725395203
Validation loss: 2.2617398500442505

Epoch: 5| Step: 7
Training loss: 1.105004906654358
Validation loss: 2.244697297612826

Epoch: 5| Step: 8
Training loss: 1.2646321058273315
Validation loss: 2.2160122841596603

Epoch: 5| Step: 9
Training loss: 1.9056446552276611
Validation loss: 2.217369313041369

Epoch: 5| Step: 10
Training loss: 1.5887718200683594
Validation loss: 2.2333528300126395

Epoch: 5| Step: 11
Training loss: 1.307855486869812
Validation loss: 2.2122552494208017

Epoch: 379| Step: 0
Training loss: 0.8290268778800964
Validation loss: 2.2288266718387604

Epoch: 5| Step: 1
Training loss: 1.296626091003418
Validation loss: 2.2276578346888223

Epoch: 5| Step: 2
Training loss: 1.3952491283416748
Validation loss: 2.256091912587484

Epoch: 5| Step: 3
Training loss: 1.4595943689346313
Validation loss: 2.2393333862225213

Epoch: 5| Step: 4
Training loss: 1.6137583255767822
Validation loss: 2.2245138933261237

Epoch: 5| Step: 5
Training loss: 1.7920995950698853
Validation loss: 2.220783273379008

Epoch: 5| Step: 6
Training loss: 0.8503971099853516
Validation loss: 2.2343924740950265

Epoch: 5| Step: 7
Training loss: 1.2584365606307983
Validation loss: 2.227493941783905

Epoch: 5| Step: 8
Training loss: 2.185075283050537
Validation loss: 2.1967520167430243

Epoch: 5| Step: 9
Training loss: 1.2149629592895508
Validation loss: 2.22237466275692

Epoch: 5| Step: 10
Training loss: 1.40798020362854
Validation loss: 2.227094898621241

Epoch: 5| Step: 11
Training loss: 2.230410575866699
Validation loss: 2.202134599288305

Epoch: 380| Step: 0
Training loss: 1.4885340929031372
Validation loss: 2.212832714120547

Epoch: 5| Step: 1
Training loss: 1.7800779342651367
Validation loss: 2.2230049272378287

Epoch: 5| Step: 2
Training loss: 0.6907324194908142
Validation loss: 2.216413229703903

Epoch: 5| Step: 3
Training loss: 1.6607224941253662
Validation loss: 2.2072133918603263

Epoch: 5| Step: 4
Training loss: 1.326369285583496
Validation loss: 2.2264722287654877

Epoch: 5| Step: 5
Training loss: 0.7822762727737427
Validation loss: 2.2119480123122535

Epoch: 5| Step: 6
Training loss: 2.052177906036377
Validation loss: 2.2330603847901025

Epoch: 5| Step: 7
Training loss: 1.8952995538711548
Validation loss: 2.2139526506265006

Epoch: 5| Step: 8
Training loss: 1.697222352027893
Validation loss: 2.2189868887265525

Epoch: 5| Step: 9
Training loss: 0.8626658320426941
Validation loss: 2.2252486050128937

Epoch: 5| Step: 10
Training loss: 1.0027265548706055
Validation loss: 2.2496723433335624

Epoch: 5| Step: 11
Training loss: 0.8219386339187622
Validation loss: 2.2446300089359283

Epoch: 381| Step: 0
Training loss: 1.7639859914779663
Validation loss: 2.272232939799627

Epoch: 5| Step: 1
Training loss: 1.569219946861267
Validation loss: 2.2683536460002265

Epoch: 5| Step: 2
Training loss: 1.5592833757400513
Validation loss: 2.2826025088628135

Epoch: 5| Step: 3
Training loss: 0.9826706647872925
Validation loss: 2.266144076983134

Epoch: 5| Step: 4
Training loss: 1.5735708475112915
Validation loss: 2.2631927728652954

Epoch: 5| Step: 5
Training loss: 1.1747678518295288
Validation loss: 2.2561967819929123

Epoch: 5| Step: 6
Training loss: 1.4466487169265747
Validation loss: 2.2920131186644235

Epoch: 5| Step: 7
Training loss: 1.2111084461212158
Validation loss: 2.2477188607056937

Epoch: 5| Step: 8
Training loss: 1.2046797275543213
Validation loss: 2.2404862542947135

Epoch: 5| Step: 9
Training loss: 1.1094290018081665
Validation loss: 2.251502568523089

Epoch: 5| Step: 10
Training loss: 1.2797726392745972
Validation loss: 2.235177213946978

Epoch: 5| Step: 11
Training loss: 0.8831329345703125
Validation loss: 2.2418429603179297

Epoch: 382| Step: 0
Training loss: 1.8739118576049805
Validation loss: 2.2596600502729416

Epoch: 5| Step: 1
Training loss: 1.0539863109588623
Validation loss: 2.2192321866750717

Epoch: 5| Step: 2
Training loss: 1.4221410751342773
Validation loss: 2.21992664039135

Epoch: 5| Step: 3
Training loss: 0.8583841323852539
Validation loss: 2.296371648708979

Epoch: 5| Step: 4
Training loss: 1.4138721227645874
Validation loss: 2.263186146815618

Epoch: 5| Step: 5
Training loss: 1.6363636255264282
Validation loss: 2.277397314707438

Epoch: 5| Step: 6
Training loss: 1.8115043640136719
Validation loss: 2.276423086722692

Epoch: 5| Step: 7
Training loss: 1.1793028116226196
Validation loss: 2.274469534556071

Epoch: 5| Step: 8
Training loss: 0.7142362594604492
Validation loss: 2.2643088002999625

Epoch: 5| Step: 9
Training loss: 1.7584025859832764
Validation loss: 2.284039467573166

Epoch: 5| Step: 10
Training loss: 0.8651443719863892
Validation loss: 2.258623500665029

Epoch: 5| Step: 11
Training loss: 0.35065579414367676
Validation loss: 2.267945239941279

Epoch: 383| Step: 0
Training loss: 1.369879126548767
Validation loss: 2.3016569316387177

Epoch: 5| Step: 1
Training loss: 2.2974884510040283
Validation loss: 2.331023156642914

Epoch: 5| Step: 2
Training loss: 1.6566263437271118
Validation loss: 2.3163810273011527

Epoch: 5| Step: 3
Training loss: 1.1129035949707031
Validation loss: 2.334608882665634

Epoch: 5| Step: 4
Training loss: 0.9135017395019531
Validation loss: 2.3192677895228067

Epoch: 5| Step: 5
Training loss: 1.5798598527908325
Validation loss: 2.3177771270275116

Epoch: 5| Step: 6
Training loss: 1.2276208400726318
Validation loss: 2.310559014479319

Epoch: 5| Step: 7
Training loss: 1.2339527606964111
Validation loss: 2.2929445803165436

Epoch: 5| Step: 8
Training loss: 1.276036024093628
Validation loss: 2.3001168916622796

Epoch: 5| Step: 9
Training loss: 0.8171046376228333
Validation loss: 2.2839532643556595

Epoch: 5| Step: 10
Training loss: 1.6839338541030884
Validation loss: 2.2930252800385156

Epoch: 5| Step: 11
Training loss: 1.302384853363037
Validation loss: 2.287505323688189

Epoch: 384| Step: 0
Training loss: 1.1320922374725342
Validation loss: 2.271226634581884

Epoch: 5| Step: 1
Training loss: 1.4629136323928833
Validation loss: 2.2557527671257653

Epoch: 5| Step: 2
Training loss: 1.5877655744552612
Validation loss: 2.258147567510605

Epoch: 5| Step: 3
Training loss: 1.2134824991226196
Validation loss: 2.2986051042874656

Epoch: 5| Step: 4
Training loss: 0.981738269329071
Validation loss: 2.280606985092163

Epoch: 5| Step: 5
Training loss: 1.6540820598602295
Validation loss: 2.279859115680059

Epoch: 5| Step: 6
Training loss: 2.105008363723755
Validation loss: 2.2818543116251626

Epoch: 5| Step: 7
Training loss: 0.5924032330513
Validation loss: 2.2870266884565353

Epoch: 5| Step: 8
Training loss: 1.321589469909668
Validation loss: 2.275301625331243

Epoch: 5| Step: 9
Training loss: 1.3060853481292725
Validation loss: 2.274671177069346

Epoch: 5| Step: 10
Training loss: 1.3378251791000366
Validation loss: 2.3145814339319863

Epoch: 5| Step: 11
Training loss: 2.5598034858703613
Validation loss: 2.271686241030693

Epoch: 385| Step: 0
Training loss: 1.1872822046279907
Validation loss: 2.2434587478637695

Epoch: 5| Step: 1
Training loss: 0.7401124238967896
Validation loss: 2.237915019194285

Epoch: 5| Step: 2
Training loss: 0.7478830814361572
Validation loss: 2.2287308871746063

Epoch: 5| Step: 3
Training loss: 0.9162557721138
Validation loss: 2.2242576579252877

Epoch: 5| Step: 4
Training loss: 1.500802993774414
Validation loss: 2.2436588406562805

Epoch: 5| Step: 5
Training loss: 1.3107084035873413
Validation loss: 2.280396138628324

Epoch: 5| Step: 6
Training loss: 1.596108078956604
Validation loss: 2.2700143456459045

Epoch: 5| Step: 7
Training loss: 1.1446220874786377
Validation loss: 2.2547165900468826

Epoch: 5| Step: 8
Training loss: 1.0311079025268555
Validation loss: 2.281945606072744

Epoch: 5| Step: 9
Training loss: 1.8707771301269531
Validation loss: 2.236687570810318

Epoch: 5| Step: 10
Training loss: 2.061208486557007
Validation loss: 2.2110274831453958

Epoch: 5| Step: 11
Training loss: 2.1563475131988525
Validation loss: 2.262823740641276

Epoch: 386| Step: 0
Training loss: 1.5149219036102295
Validation loss: 2.227148324251175

Epoch: 5| Step: 1
Training loss: 1.0710526704788208
Validation loss: 2.2591616213321686

Epoch: 5| Step: 2
Training loss: 0.9946969747543335
Validation loss: 2.294673507412275

Epoch: 5| Step: 3
Training loss: 1.6459934711456299
Validation loss: 2.265219673514366

Epoch: 5| Step: 4
Training loss: 1.333113431930542
Validation loss: 2.281760493914286

Epoch: 5| Step: 5
Training loss: 1.2030174732208252
Validation loss: 2.2641522685686746

Epoch: 5| Step: 6
Training loss: 1.6532337665557861
Validation loss: 2.2435269355773926

Epoch: 5| Step: 7
Training loss: 1.0599935054779053
Validation loss: 2.224368244409561

Epoch: 5| Step: 8
Training loss: 1.677674651145935
Validation loss: 2.2439631621042886

Epoch: 5| Step: 9
Training loss: 0.9569129943847656
Validation loss: 2.2654477804899216

Epoch: 5| Step: 10
Training loss: 1.7050873041152954
Validation loss: 2.2308978686730065

Epoch: 5| Step: 11
Training loss: 1.5094325542449951
Validation loss: 2.2522308429082236

Epoch: 387| Step: 0
Training loss: 0.7661657333374023
Validation loss: 2.2853981405496597

Epoch: 5| Step: 1
Training loss: 1.7606298923492432
Validation loss: 2.2338673373063407

Epoch: 5| Step: 2
Training loss: 1.7756704092025757
Validation loss: 2.2550193617741265

Epoch: 5| Step: 3
Training loss: 1.2115347385406494
Validation loss: 2.235089361667633

Epoch: 5| Step: 4
Training loss: 1.3300209045410156
Validation loss: 2.2699782450993857

Epoch: 5| Step: 5
Training loss: 1.2674226760864258
Validation loss: 2.2871081034342446

Epoch: 5| Step: 6
Training loss: 1.108294129371643
Validation loss: 2.2360352873802185

Epoch: 5| Step: 7
Training loss: 1.178964376449585
Validation loss: 2.244807784756025

Epoch: 5| Step: 8
Training loss: 1.3446859121322632
Validation loss: 2.2174795816342034

Epoch: 5| Step: 9
Training loss: 1.2088682651519775
Validation loss: 2.2166412572065988

Epoch: 5| Step: 10
Training loss: 1.578624963760376
Validation loss: 2.2248540421326957

Epoch: 5| Step: 11
Training loss: 0.606963038444519
Validation loss: 2.2432622065146766

Epoch: 388| Step: 0
Training loss: 0.9715851545333862
Validation loss: 2.2452671031157174

Epoch: 5| Step: 1
Training loss: 1.4144315719604492
Validation loss: 2.2311853170394897

Epoch: 5| Step: 2
Training loss: 1.1801931858062744
Validation loss: 2.2370015482107797

Epoch: 5| Step: 3
Training loss: 0.9797593355178833
Validation loss: 2.2444047133127847

Epoch: 5| Step: 4
Training loss: 1.487595796585083
Validation loss: 2.222035119930903

Epoch: 5| Step: 5
Training loss: 0.9118618965148926
Validation loss: 2.219788591066996

Epoch: 5| Step: 6
Training loss: 1.029503345489502
Validation loss: 2.2414701680342355

Epoch: 5| Step: 7
Training loss: 1.484922170639038
Validation loss: 2.226364349325498

Epoch: 5| Step: 8
Training loss: 1.529309868812561
Validation loss: 2.198382173975309

Epoch: 5| Step: 9
Training loss: 1.3159821033477783
Validation loss: 2.210744023323059

Epoch: 5| Step: 10
Training loss: 1.9669075012207031
Validation loss: 2.2137648165225983

Epoch: 5| Step: 11
Training loss: 2.536116361618042
Validation loss: 2.2323298901319504

Epoch: 389| Step: 0
Training loss: 1.8572092056274414
Validation loss: 2.230248341957728

Epoch: 5| Step: 1
Training loss: 0.905066967010498
Validation loss: 2.2300757318735123

Epoch: 5| Step: 2
Training loss: 1.251098871231079
Validation loss: 2.246277297536532

Epoch: 5| Step: 3
Training loss: 1.4601502418518066
Validation loss: 2.2280561923980713

Epoch: 5| Step: 4
Training loss: 1.3208853006362915
Validation loss: 2.303081860144933

Epoch: 5| Step: 5
Training loss: 1.2603775262832642
Validation loss: 2.2952184279759726

Epoch: 5| Step: 6
Training loss: 1.5736076831817627
Validation loss: 2.3843433956305184

Epoch: 5| Step: 7
Training loss: 1.2749305963516235
Validation loss: 2.383861149350802

Epoch: 5| Step: 8
Training loss: 1.1608326435089111
Validation loss: 2.3580647905667624

Epoch: 5| Step: 9
Training loss: 1.0278347730636597
Validation loss: 2.3961008389790854

Epoch: 5| Step: 10
Training loss: 1.8135932683944702
Validation loss: 2.3115426947673163

Epoch: 5| Step: 11
Training loss: 0.41787075996398926
Validation loss: 2.288866564631462

Epoch: 390| Step: 0
Training loss: 1.1824829578399658
Validation loss: 2.2741446495056152

Epoch: 5| Step: 1
Training loss: 1.2554129362106323
Validation loss: 2.2576972246170044

Epoch: 5| Step: 2
Training loss: 1.8696616888046265
Validation loss: 2.29351935784022

Epoch: 5| Step: 3
Training loss: 1.7429344654083252
Validation loss: 2.2591293851534524

Epoch: 5| Step: 4
Training loss: 1.157705545425415
Validation loss: 2.2598224778970084

Epoch: 5| Step: 5
Training loss: 1.197749376296997
Validation loss: 2.2315526455640793

Epoch: 5| Step: 6
Training loss: 0.7306982278823853
Validation loss: 2.241454154253006

Epoch: 5| Step: 7
Training loss: 1.5195566415786743
Validation loss: 2.203446850180626

Epoch: 5| Step: 8
Training loss: 0.6836097240447998
Validation loss: 2.2596452136834464

Epoch: 5| Step: 9
Training loss: 1.5141022205352783
Validation loss: 2.220285321275393

Epoch: 5| Step: 10
Training loss: 1.4019756317138672
Validation loss: 2.298397292693456

Epoch: 5| Step: 11
Training loss: 1.1516984701156616
Validation loss: 2.2351721972227097

Epoch: 391| Step: 0
Training loss: 0.8180514574050903
Validation loss: 2.243758032719294

Epoch: 5| Step: 1
Training loss: 1.0034056901931763
Validation loss: 2.233311891555786

Epoch: 5| Step: 2
Training loss: 1.3782168626785278
Validation loss: 2.2348422706127167

Epoch: 5| Step: 3
Training loss: 1.1919785737991333
Validation loss: 2.2354409794012704

Epoch: 5| Step: 4
Training loss: 1.891988754272461
Validation loss: 2.2142564058303833

Epoch: 5| Step: 5
Training loss: 1.2779639959335327
Validation loss: 2.2196195870637894

Epoch: 5| Step: 6
Training loss: 2.0222816467285156
Validation loss: 2.204906553030014

Epoch: 5| Step: 7
Training loss: 0.8329675793647766
Validation loss: 2.2288522770007453

Epoch: 5| Step: 8
Training loss: 1.054438591003418
Validation loss: 2.2307989299297333

Epoch: 5| Step: 9
Training loss: 1.3054615259170532
Validation loss: 2.246005098025004

Epoch: 5| Step: 10
Training loss: 1.1187796592712402
Validation loss: 2.253315677245458

Epoch: 5| Step: 11
Training loss: 1.8448455333709717
Validation loss: 2.2079393565654755

Epoch: 392| Step: 0
Training loss: 1.3998254537582397
Validation loss: 2.218810493747393

Epoch: 5| Step: 1
Training loss: 1.5835354328155518
Validation loss: 2.2053386519352594

Epoch: 5| Step: 2
Training loss: 1.3321480751037598
Validation loss: 2.2911302944024405

Epoch: 5| Step: 3
Training loss: 1.4691402912139893
Validation loss: 2.2687018314997354

Epoch: 5| Step: 4
Training loss: 1.5986580848693848
Validation loss: 2.224014401435852

Epoch: 5| Step: 5
Training loss: 1.3037164211273193
Validation loss: 2.2717554370562234

Epoch: 5| Step: 6
Training loss: 1.2592285871505737
Validation loss: 2.2679239213466644

Epoch: 5| Step: 7
Training loss: 1.1868730783462524
Validation loss: 2.2723740537961326

Epoch: 5| Step: 8
Training loss: 1.279946208000183
Validation loss: 2.3182841589053473

Epoch: 5| Step: 9
Training loss: 1.2372156381607056
Validation loss: 2.299029678106308

Epoch: 5| Step: 10
Training loss: 0.9583858251571655
Validation loss: 2.270803908507029

Epoch: 5| Step: 11
Training loss: 1.0100456476211548
Validation loss: 2.265145500500997

Epoch: 393| Step: 0
Training loss: 1.1542984247207642
Validation loss: 2.2283667773008347

Epoch: 5| Step: 1
Training loss: 1.4576209783554077
Validation loss: 2.2465626200040183

Epoch: 5| Step: 2
Training loss: 1.331279993057251
Validation loss: 2.1829825192689896

Epoch: 5| Step: 3
Training loss: 1.2630603313446045
Validation loss: 2.23027411599954

Epoch: 5| Step: 4
Training loss: 1.5773276090621948
Validation loss: 2.2247250378131866

Epoch: 5| Step: 5
Training loss: 0.6813918352127075
Validation loss: 2.2120376527309418

Epoch: 5| Step: 6
Training loss: 1.7708072662353516
Validation loss: 2.2428349355856576

Epoch: 5| Step: 7
Training loss: 0.8258807063102722
Validation loss: 2.220917279521624

Epoch: 5| Step: 8
Training loss: 1.4736783504486084
Validation loss: 2.2324331899484

Epoch: 5| Step: 9
Training loss: 1.3847217559814453
Validation loss: 2.2466561992963157

Epoch: 5| Step: 10
Training loss: 1.4437658786773682
Validation loss: 2.262177432576815

Epoch: 5| Step: 11
Training loss: 2.897728443145752
Validation loss: 2.226659541328748

Epoch: 394| Step: 0
Training loss: 1.4686743021011353
Validation loss: 2.2694910963376365

Epoch: 5| Step: 1
Training loss: 1.7492643594741821
Validation loss: 2.281378428141276

Epoch: 5| Step: 2
Training loss: 1.0842912197113037
Validation loss: 2.2806832740704217

Epoch: 5| Step: 3
Training loss: 1.3341144323349
Validation loss: 2.3197420686483383

Epoch: 5| Step: 4
Training loss: 1.6659713983535767
Validation loss: 2.3279680212338767

Epoch: 5| Step: 5
Training loss: 1.3566287755966187
Validation loss: 2.2840857207775116

Epoch: 5| Step: 6
Training loss: 1.208070993423462
Validation loss: 2.302251090606054

Epoch: 5| Step: 7
Training loss: 0.8238686323165894
Validation loss: 2.2919514973958335

Epoch: 5| Step: 8
Training loss: 1.5297479629516602
Validation loss: 2.2969767451286316

Epoch: 5| Step: 9
Training loss: 0.85389643907547
Validation loss: 2.2605591913064322

Epoch: 5| Step: 10
Training loss: 1.2150465250015259
Validation loss: 2.281776746114095

Epoch: 5| Step: 11
Training loss: 2.723243236541748
Validation loss: 2.2400026818116507

Epoch: 395| Step: 0
Training loss: 1.0044660568237305
Validation loss: 2.2537911434968314

Epoch: 5| Step: 1
Training loss: 1.8485727310180664
Validation loss: 2.2617428402105966

Epoch: 5| Step: 2
Training loss: 1.5229568481445312
Validation loss: 2.2516396592060723

Epoch: 5| Step: 3
Training loss: 1.6672790050506592
Validation loss: 2.2575519730647406

Epoch: 5| Step: 4
Training loss: 0.8027222752571106
Validation loss: 2.2543863157431283

Epoch: 5| Step: 5
Training loss: 1.213571310043335
Validation loss: 2.2852998971939087

Epoch: 5| Step: 6
Training loss: 0.9738619923591614
Validation loss: 2.2924981713294983

Epoch: 5| Step: 7
Training loss: 0.993222713470459
Validation loss: 2.2964652677377067

Epoch: 5| Step: 8
Training loss: 1.3268945217132568
Validation loss: 2.2602650970220566

Epoch: 5| Step: 9
Training loss: 1.852992296218872
Validation loss: 2.2190388590097427

Epoch: 5| Step: 10
Training loss: 1.3993595838546753
Validation loss: 2.2324862281481423

Epoch: 5| Step: 11
Training loss: 0.6659262776374817
Validation loss: 2.2368096013863883

Epoch: 396| Step: 0
Training loss: 1.2115240097045898
Validation loss: 2.273281325896581

Epoch: 5| Step: 1
Training loss: 1.1214231252670288
Validation loss: 2.261708880464236

Epoch: 5| Step: 2
Training loss: 1.009516716003418
Validation loss: 2.205078214406967

Epoch: 5| Step: 3
Training loss: 0.9448890686035156
Validation loss: 2.2402510146299996

Epoch: 5| Step: 4
Training loss: 2.040895938873291
Validation loss: 2.2411683996518454

Epoch: 5| Step: 5
Training loss: 1.614328384399414
Validation loss: 2.20497128367424

Epoch: 5| Step: 6
Training loss: 1.804426908493042
Validation loss: 2.269942964116732

Epoch: 5| Step: 7
Training loss: 0.9343395233154297
Validation loss: 2.2533827175696692

Epoch: 5| Step: 8
Training loss: 1.1167185306549072
Validation loss: 2.250666543841362

Epoch: 5| Step: 9
Training loss: 1.499945044517517
Validation loss: 2.2109217445055642

Epoch: 5| Step: 10
Training loss: 1.0371464490890503
Validation loss: 2.234453245997429

Epoch: 5| Step: 11
Training loss: 0.8486872911453247
Validation loss: 2.2471735874811807

Epoch: 397| Step: 0
Training loss: 1.515063762664795
Validation loss: 2.2887346148490906

Epoch: 5| Step: 1
Training loss: 1.1462070941925049
Validation loss: 2.290506919225057

Epoch: 5| Step: 2
Training loss: 1.6935056447982788
Validation loss: 2.2872379968563714

Epoch: 5| Step: 3
Training loss: 1.242336630821228
Validation loss: 2.282327483097712

Epoch: 5| Step: 4
Training loss: 1.0682870149612427
Validation loss: 2.327004536986351

Epoch: 5| Step: 5
Training loss: 1.6127628087997437
Validation loss: 2.2674573163191476

Epoch: 5| Step: 6
Training loss: 1.287513017654419
Validation loss: 2.2682111958662667

Epoch: 5| Step: 7
Training loss: 0.8406232595443726
Validation loss: 2.246780807773272

Epoch: 5| Step: 8
Training loss: 1.4459598064422607
Validation loss: 2.2735516180594764

Epoch: 5| Step: 9
Training loss: 1.1912540197372437
Validation loss: 2.223270853360494

Epoch: 5| Step: 10
Training loss: 1.4055571556091309
Validation loss: 2.2405102849006653

Epoch: 5| Step: 11
Training loss: 0.8697036504745483
Validation loss: 2.241058349609375

Epoch: 398| Step: 0
Training loss: 0.9749413728713989
Validation loss: 2.2376836935679116

Epoch: 5| Step: 1
Training loss: 0.9985160827636719
Validation loss: 2.289847731590271

Epoch: 5| Step: 2
Training loss: 1.6878095865249634
Validation loss: 2.2356502612431846

Epoch: 5| Step: 3
Training loss: 1.5101838111877441
Validation loss: 2.260300412774086

Epoch: 5| Step: 4
Training loss: 1.351976990699768
Validation loss: 2.282306661208471

Epoch: 5| Step: 5
Training loss: 1.2235496044158936
Validation loss: 2.266656627257665

Epoch: 5| Step: 6
Training loss: 1.1866672039031982
Validation loss: 2.3055782119433084

Epoch: 5| Step: 7
Training loss: 1.7160850763320923
Validation loss: 2.2789481530586877

Epoch: 5| Step: 8
Training loss: 1.8692777156829834
Validation loss: 2.2440258165200553

Epoch: 5| Step: 9
Training loss: 1.0841646194458008
Validation loss: 2.244891102115313

Epoch: 5| Step: 10
Training loss: 0.8702985048294067
Validation loss: 2.2236226399739585

Epoch: 5| Step: 11
Training loss: 1.366382360458374
Validation loss: 2.219502458969752

Epoch: 399| Step: 0
Training loss: 1.19992995262146
Validation loss: 2.228890801469485

Epoch: 5| Step: 1
Training loss: 2.3162178993225098
Validation loss: 2.2189343323310218

Epoch: 5| Step: 2
Training loss: 1.6233446598052979
Validation loss: 2.2474901576836905

Epoch: 5| Step: 3
Training loss: 1.6299092769622803
Validation loss: 2.2085747718811035

Epoch: 5| Step: 4
Training loss: 1.9374099969863892
Validation loss: 2.2269360224405923

Epoch: 5| Step: 5
Training loss: 0.8695809245109558
Validation loss: 2.242702146371206

Epoch: 5| Step: 6
Training loss: 1.8104448318481445
Validation loss: 2.295496712128321

Epoch: 5| Step: 7
Training loss: 1.4540674686431885
Validation loss: 2.340662012497584

Epoch: 5| Step: 8
Training loss: 0.9714147448539734
Validation loss: 2.3732768148183823

Epoch: 5| Step: 9
Training loss: 1.011986494064331
Validation loss: 2.3800504257281623

Epoch: 5| Step: 10
Training loss: 1.040881872177124
Validation loss: 2.346956347425779

Epoch: 5| Step: 11
Training loss: 1.1073880195617676
Validation loss: 2.2751547594865165

Epoch: 400| Step: 0
Training loss: 1.4698632955551147
Validation loss: 2.2998829782009125

Epoch: 5| Step: 1
Training loss: 1.210234522819519
Validation loss: 2.2738284170627594

Epoch: 5| Step: 2
Training loss: 1.5549081563949585
Validation loss: 2.254988600810369

Epoch: 5| Step: 3
Training loss: 1.563767671585083
Validation loss: 2.245983978112539

Epoch: 5| Step: 4
Training loss: 0.9495275616645813
Validation loss: 2.2461417814095817

Epoch: 5| Step: 5
Training loss: 1.5089081525802612
Validation loss: 2.2608496646086373

Epoch: 5| Step: 6
Training loss: 1.6745723485946655
Validation loss: 2.226437578598658

Epoch: 5| Step: 7
Training loss: 1.158996343612671
Validation loss: 2.245894024769465

Epoch: 5| Step: 8
Training loss: 1.5456807613372803
Validation loss: 2.3067446798086166

Epoch: 5| Step: 9
Training loss: 0.7844637632369995
Validation loss: 2.2360322872797647

Epoch: 5| Step: 10
Training loss: 1.3357019424438477
Validation loss: 2.26459339261055

Epoch: 5| Step: 11
Training loss: 1.626397967338562
Validation loss: 2.2666625877221427

Epoch: 401| Step: 0
Training loss: 1.1119543313980103
Validation loss: 2.259022424618403

Epoch: 5| Step: 1
Training loss: 1.3775055408477783
Validation loss: 2.2356429050366082

Epoch: 5| Step: 2
Training loss: 1.8102226257324219
Validation loss: 2.2636934320131936

Epoch: 5| Step: 3
Training loss: 1.5845950841903687
Validation loss: 2.253576253851255

Epoch: 5| Step: 4
Training loss: 1.4186375141143799
Validation loss: 2.243252525726954

Epoch: 5| Step: 5
Training loss: 1.4535019397735596
Validation loss: 2.272645483414332

Epoch: 5| Step: 6
Training loss: 1.2495673894882202
Validation loss: 2.256888657808304

Epoch: 5| Step: 7
Training loss: 0.8852226138114929
Validation loss: 2.300037374099096

Epoch: 5| Step: 8
Training loss: 1.7087829113006592
Validation loss: 2.3064238727092743

Epoch: 5| Step: 9
Training loss: 1.1994173526763916
Validation loss: 2.2723638465007148

Epoch: 5| Step: 10
Training loss: 1.2417430877685547
Validation loss: 2.284948095679283

Epoch: 5| Step: 11
Training loss: 0.8868619799613953
Validation loss: 2.26633753379186

Epoch: 402| Step: 0
Training loss: 1.5349019765853882
Validation loss: 2.255956163009008

Epoch: 5| Step: 1
Training loss: 1.1830840110778809
Validation loss: 2.230427732070287

Epoch: 5| Step: 2
Training loss: 0.8796218633651733
Validation loss: 2.2472294767697654

Epoch: 5| Step: 3
Training loss: 1.431452989578247
Validation loss: 2.2568049182494483

Epoch: 5| Step: 4
Training loss: 1.3457043170928955
Validation loss: 2.2303376297156015

Epoch: 5| Step: 5
Training loss: 1.6679490804672241
Validation loss: 2.2492886185646057

Epoch: 5| Step: 6
Training loss: 1.325953722000122
Validation loss: 2.237308075030645

Epoch: 5| Step: 7
Training loss: 1.2208116054534912
Validation loss: 2.195408875743548

Epoch: 5| Step: 8
Training loss: 1.3667855262756348
Validation loss: 2.2107965449492135

Epoch: 5| Step: 9
Training loss: 1.4764134883880615
Validation loss: 2.169861743847529

Epoch: 5| Step: 10
Training loss: 1.189361333847046
Validation loss: 2.21235121289889

Epoch: 5| Step: 11
Training loss: 0.7689992189407349
Validation loss: 2.218546062707901

Epoch: 403| Step: 0
Training loss: 1.3866021633148193
Validation loss: 2.3135396987199783

Epoch: 5| Step: 1
Training loss: 1.7299896478652954
Validation loss: 2.3094208339850106

Epoch: 5| Step: 2
Training loss: 1.644837737083435
Validation loss: 2.291946589946747

Epoch: 5| Step: 3
Training loss: 1.6752811670303345
Validation loss: 2.2893603096405664

Epoch: 5| Step: 4
Training loss: 1.4779967069625854
Validation loss: 2.3017751375834146

Epoch: 5| Step: 5
Training loss: 1.2133523225784302
Validation loss: 2.274883051713308

Epoch: 5| Step: 6
Training loss: 1.4258474111557007
Validation loss: 2.2422941625118256

Epoch: 5| Step: 7
Training loss: 0.7143135070800781
Validation loss: 2.1863429645697274

Epoch: 5| Step: 8
Training loss: 1.2957305908203125
Validation loss: 2.1759991695483527

Epoch: 5| Step: 9
Training loss: 1.6009258031845093
Validation loss: 2.2120965272188187

Epoch: 5| Step: 10
Training loss: 0.800805926322937
Validation loss: 2.207823798060417

Epoch: 5| Step: 11
Training loss: 1.1765727996826172
Validation loss: 2.212886095046997

Epoch: 404| Step: 0
Training loss: 1.3638784885406494
Validation loss: 2.1994408716758094

Epoch: 5| Step: 1
Training loss: 0.6007569432258606
Validation loss: 2.237829993168513

Epoch: 5| Step: 2
Training loss: 1.2666085958480835
Validation loss: 2.2292881458997726

Epoch: 5| Step: 3
Training loss: 1.178752064704895
Validation loss: 2.269801507393519

Epoch: 5| Step: 4
Training loss: 1.2159106731414795
Validation loss: 2.2903485794862113

Epoch: 5| Step: 5
Training loss: 1.4392845630645752
Validation loss: 2.243565022945404

Epoch: 5| Step: 6
Training loss: 1.1213672161102295
Validation loss: 2.2683798422416053

Epoch: 5| Step: 7
Training loss: 1.8622386455535889
Validation loss: 2.276072824994723

Epoch: 5| Step: 8
Training loss: 1.4495596885681152
Validation loss: 2.296827365954717

Epoch: 5| Step: 9
Training loss: 1.215994954109192
Validation loss: 2.295342653989792

Epoch: 5| Step: 10
Training loss: 1.5546122789382935
Validation loss: 2.2460437566041946

Epoch: 5| Step: 11
Training loss: 1.0946811437606812
Validation loss: 2.235694259405136

Epoch: 405| Step: 0
Training loss: 0.9865885972976685
Validation loss: 2.2615628192822137

Epoch: 5| Step: 1
Training loss: 1.259117603302002
Validation loss: 2.2398506899674735

Epoch: 5| Step: 2
Training loss: 1.5213533639907837
Validation loss: 2.248900224765142

Epoch: 5| Step: 3
Training loss: 1.258465051651001
Validation loss: 2.274011045694351

Epoch: 5| Step: 4
Training loss: 1.219350814819336
Validation loss: 2.2791470090548196

Epoch: 5| Step: 5
Training loss: 1.519425630569458
Validation loss: 2.2554564476013184

Epoch: 5| Step: 6
Training loss: 0.8866851925849915
Validation loss: 2.284404625495275

Epoch: 5| Step: 7
Training loss: 1.6208782196044922
Validation loss: 2.277102599541346

Epoch: 5| Step: 8
Training loss: 1.724605917930603
Validation loss: 2.242974321047465

Epoch: 5| Step: 9
Training loss: 0.9518221616744995
Validation loss: 2.2407890061537423

Epoch: 5| Step: 10
Training loss: 0.9970381855964661
Validation loss: 2.238569920261701

Epoch: 5| Step: 11
Training loss: 0.8705657720565796
Validation loss: 2.2777464985847473

Epoch: 406| Step: 0
Training loss: 1.5975492000579834
Validation loss: 2.265518367290497

Epoch: 5| Step: 1
Training loss: 0.9651615023612976
Validation loss: 2.299933061003685

Epoch: 5| Step: 2
Training loss: 1.318282127380371
Validation loss: 2.327703466018041

Epoch: 5| Step: 3
Training loss: 1.1220786571502686
Validation loss: 2.356973866621653

Epoch: 5| Step: 4
Training loss: 1.0648081302642822
Validation loss: 2.3658938705921173

Epoch: 5| Step: 5
Training loss: 1.6065123081207275
Validation loss: 2.3443364997704825

Epoch: 5| Step: 6
Training loss: 1.7074737548828125
Validation loss: 2.295239786307017

Epoch: 5| Step: 7
Training loss: 0.5776011943817139
Validation loss: 2.279270519812902

Epoch: 5| Step: 8
Training loss: 1.824183702468872
Validation loss: 2.2461143831411996

Epoch: 5| Step: 9
Training loss: 1.207762360572815
Validation loss: 2.2655069082975388

Epoch: 5| Step: 10
Training loss: 1.0316988229751587
Validation loss: 2.257522761821747

Epoch: 5| Step: 11
Training loss: 0.8710612058639526
Validation loss: 2.2159687876701355

Epoch: 407| Step: 0
Training loss: 1.7854833602905273
Validation loss: 2.248075559735298

Epoch: 5| Step: 1
Training loss: 1.2672274112701416
Validation loss: 2.2621037513017654

Epoch: 5| Step: 2
Training loss: 0.7646335363388062
Validation loss: 2.2550357977549234

Epoch: 5| Step: 3
Training loss: 0.9253680109977722
Validation loss: 2.271025389432907

Epoch: 5| Step: 4
Training loss: 0.8364086151123047
Validation loss: 2.2813230206569037

Epoch: 5| Step: 5
Training loss: 1.5265320539474487
Validation loss: 2.3121993144353232

Epoch: 5| Step: 6
Training loss: 1.2129018306732178
Validation loss: 2.361083135008812

Epoch: 5| Step: 7
Training loss: 1.3885562419891357
Validation loss: 2.4047478338082633

Epoch: 5| Step: 8
Training loss: 1.34987211227417
Validation loss: 2.3728351394335427

Epoch: 5| Step: 9
Training loss: 1.1320377588272095
Validation loss: 2.360966553290685

Epoch: 5| Step: 10
Training loss: 1.9438018798828125
Validation loss: 2.2670827011267343

Epoch: 5| Step: 11
Training loss: 1.2181377410888672
Validation loss: 2.291685084501902

Epoch: 408| Step: 0
Training loss: 1.1660391092300415
Validation loss: 2.2643316288789115

Epoch: 5| Step: 1
Training loss: 1.483810305595398
Validation loss: 2.2113915532827377

Epoch: 5| Step: 2
Training loss: 1.904693603515625
Validation loss: 2.2390704403320947

Epoch: 5| Step: 3
Training loss: 1.3781288862228394
Validation loss: 2.2450870672861734

Epoch: 5| Step: 4
Training loss: 0.703433632850647
Validation loss: 2.2532375007867813

Epoch: 5| Step: 5
Training loss: 0.9586879014968872
Validation loss: 2.237982233365377

Epoch: 5| Step: 6
Training loss: 1.216801404953003
Validation loss: 2.2567655394474664

Epoch: 5| Step: 7
Training loss: 1.5356833934783936
Validation loss: 2.2611140310764313

Epoch: 5| Step: 8
Training loss: 1.1326771974563599
Validation loss: 2.2696579098701477

Epoch: 5| Step: 9
Training loss: 1.2606101036071777
Validation loss: 2.271114692091942

Epoch: 5| Step: 10
Training loss: 1.240228295326233
Validation loss: 2.2747514694929123

Epoch: 5| Step: 11
Training loss: 0.4872061610221863
Validation loss: 2.2646665424108505

Epoch: 409| Step: 0
Training loss: 1.3371754884719849
Validation loss: 2.238976319630941

Epoch: 5| Step: 1
Training loss: 1.0263887643814087
Validation loss: 2.227350334326426

Epoch: 5| Step: 2
Training loss: 1.3786767721176147
Validation loss: 2.232464849948883

Epoch: 5| Step: 3
Training loss: 1.1988544464111328
Validation loss: 2.2155851225058236

Epoch: 5| Step: 4
Training loss: 1.2139060497283936
Validation loss: 2.245523144801458

Epoch: 5| Step: 5
Training loss: 0.7455975413322449
Validation loss: 2.220383107662201

Epoch: 5| Step: 6
Training loss: 0.9099578857421875
Validation loss: 2.21842730542024

Epoch: 5| Step: 7
Training loss: 1.4212980270385742
Validation loss: 2.187287042538325

Epoch: 5| Step: 8
Training loss: 0.9253674745559692
Validation loss: 2.2329039673010507

Epoch: 5| Step: 9
Training loss: 1.2202539443969727
Validation loss: 2.2293513864278793

Epoch: 5| Step: 10
Training loss: 2.0933265686035156
Validation loss: 2.217896064122518

Epoch: 5| Step: 11
Training loss: 2.0286412239074707
Validation loss: 2.213098128636678

Epoch: 410| Step: 0
Training loss: 1.3077983856201172
Validation loss: 2.2127841214338937

Epoch: 5| Step: 1
Training loss: 1.3324787616729736
Validation loss: 2.2543466091156006

Epoch: 5| Step: 2
Training loss: 1.5702234506607056
Validation loss: 2.2455732375383377

Epoch: 5| Step: 3
Training loss: 1.206344485282898
Validation loss: 2.2504285176595054

Epoch: 5| Step: 4
Training loss: 1.3045705556869507
Validation loss: 2.2554290692011514

Epoch: 5| Step: 5
Training loss: 1.038819432258606
Validation loss: 2.2480802039305368

Epoch: 5| Step: 6
Training loss: 1.0634708404541016
Validation loss: 2.2219713677962623

Epoch: 5| Step: 7
Training loss: 1.0513856410980225
Validation loss: 2.1890257199605307

Epoch: 5| Step: 8
Training loss: 0.8632652163505554
Validation loss: 2.209579572081566

Epoch: 5| Step: 9
Training loss: 1.4310652017593384
Validation loss: 2.225998044013977

Epoch: 5| Step: 10
Training loss: 1.2595545053482056
Validation loss: 2.220112999280294

Epoch: 5| Step: 11
Training loss: 1.5031659603118896
Validation loss: 2.2372925927241645

Epoch: 411| Step: 0
Training loss: 1.3017780780792236
Validation loss: 2.2274603893359504

Epoch: 5| Step: 1
Training loss: 1.328043818473816
Validation loss: 2.2445848286151886

Epoch: 5| Step: 2
Training loss: 0.5506876707077026
Validation loss: 2.226037080089251

Epoch: 5| Step: 3
Training loss: 1.4638797044754028
Validation loss: 2.2369771599769592

Epoch: 5| Step: 4
Training loss: 1.4635112285614014
Validation loss: 2.2168199022610984

Epoch: 5| Step: 5
Training loss: 1.9176057577133179
Validation loss: 2.225464031100273

Epoch: 5| Step: 6
Training loss: 1.0071474313735962
Validation loss: 2.20552089313666

Epoch: 5| Step: 7
Training loss: 1.1250417232513428
Validation loss: 2.197026804089546

Epoch: 5| Step: 8
Training loss: 1.5497992038726807
Validation loss: 2.2361606111129126

Epoch: 5| Step: 9
Training loss: 1.1268787384033203
Validation loss: 2.2475136518478394

Epoch: 5| Step: 10
Training loss: 0.6407479047775269
Validation loss: 2.249685287475586

Epoch: 5| Step: 11
Training loss: 1.0783638954162598
Validation loss: 2.232274522384008

Epoch: 412| Step: 0
Training loss: 1.1764600276947021
Validation loss: 2.1943564315636954

Epoch: 5| Step: 1
Training loss: 1.3005939722061157
Validation loss: 2.215667888522148

Epoch: 5| Step: 2
Training loss: 1.1532973051071167
Validation loss: 2.21183313926061

Epoch: 5| Step: 3
Training loss: 1.2538686990737915
Validation loss: 2.2453181445598602

Epoch: 5| Step: 4
Training loss: 0.9966106414794922
Validation loss: 2.2400114784638085

Epoch: 5| Step: 5
Training loss: 1.1543567180633545
Validation loss: 2.2588623066743216

Epoch: 5| Step: 6
Training loss: 1.0132124423980713
Validation loss: 2.2652699848016105

Epoch: 5| Step: 7
Training loss: 1.4948630332946777
Validation loss: 2.230312019586563

Epoch: 5| Step: 8
Training loss: 1.6089986562728882
Validation loss: 2.274159590403239

Epoch: 5| Step: 9
Training loss: 1.2474557161331177
Validation loss: 2.2270544370015464

Epoch: 5| Step: 10
Training loss: 1.006826639175415
Validation loss: 2.25074569384257

Epoch: 5| Step: 11
Training loss: 0.5954821109771729
Validation loss: 2.2415092140436172

Epoch: 413| Step: 0
Training loss: 0.7033770680427551
Validation loss: 2.2618157962958017

Epoch: 5| Step: 1
Training loss: 1.083852767944336
Validation loss: 2.249384601910909

Epoch: 5| Step: 2
Training loss: 1.9274530410766602
Validation loss: 2.26257885992527

Epoch: 5| Step: 3
Training loss: 1.17842698097229
Validation loss: 2.285206228494644

Epoch: 5| Step: 4
Training loss: 1.210909128189087
Validation loss: 2.2285620868206024

Epoch: 5| Step: 5
Training loss: 1.1967693567276
Validation loss: 2.252416585882505

Epoch: 5| Step: 6
Training loss: 1.0389518737792969
Validation loss: 2.27945085366567

Epoch: 5| Step: 7
Training loss: 1.6909103393554688
Validation loss: 2.241132527589798

Epoch: 5| Step: 8
Training loss: 0.9876071214675903
Validation loss: 2.211666246255239

Epoch: 5| Step: 9
Training loss: 1.6704158782958984
Validation loss: 2.2393460174401603

Epoch: 5| Step: 10
Training loss: 0.8355436325073242
Validation loss: 2.242404783765475

Epoch: 5| Step: 11
Training loss: 0.9607660174369812
Validation loss: 2.2474085787932077

Epoch: 414| Step: 0
Training loss: 1.1297500133514404
Validation loss: 2.2166191935539246

Epoch: 5| Step: 1
Training loss: 1.2254416942596436
Validation loss: 2.2154066214958825

Epoch: 5| Step: 2
Training loss: 1.0551083087921143
Validation loss: 2.2195836255947747

Epoch: 5| Step: 3
Training loss: 1.518705129623413
Validation loss: 2.2758591175079346

Epoch: 5| Step: 4
Training loss: 1.301926851272583
Validation loss: 2.2280194411675134

Epoch: 5| Step: 5
Training loss: 1.4981601238250732
Validation loss: 2.2991472681363425

Epoch: 5| Step: 6
Training loss: 1.1941490173339844
Validation loss: 2.289062316219012

Epoch: 5| Step: 7
Training loss: 1.1081573963165283
Validation loss: 2.3150655130545297

Epoch: 5| Step: 8
Training loss: 1.1349291801452637
Validation loss: 2.3215655436118445

Epoch: 5| Step: 9
Training loss: 0.9099157452583313
Validation loss: 2.3134658137957254

Epoch: 5| Step: 10
Training loss: 1.343154788017273
Validation loss: 2.2987766613562903

Epoch: 5| Step: 11
Training loss: 0.487234503030777
Validation loss: 2.278461774190267

Epoch: 415| Step: 0
Training loss: 1.2888591289520264
Validation loss: 2.2187429070472717

Epoch: 5| Step: 1
Training loss: 0.8016185760498047
Validation loss: 2.222328265508016

Epoch: 5| Step: 2
Training loss: 0.8887211680412292
Validation loss: 2.2489103774229684

Epoch: 5| Step: 3
Training loss: 1.2658483982086182
Validation loss: 2.2164114862680435

Epoch: 5| Step: 4
Training loss: 0.9596979022026062
Validation loss: 2.2296129961808524

Epoch: 5| Step: 5
Training loss: 1.0608071088790894
Validation loss: 2.2336879769961038

Epoch: 5| Step: 6
Training loss: 1.9322235584259033
Validation loss: 2.2776219099760056

Epoch: 5| Step: 7
Training loss: 1.2768586874008179
Validation loss: 2.311898648738861

Epoch: 5| Step: 8
Training loss: 1.2950713634490967
Validation loss: 2.300322105487188

Epoch: 5| Step: 9
Training loss: 1.537489652633667
Validation loss: 2.295897568265597

Epoch: 5| Step: 10
Training loss: 1.1919479370117188
Validation loss: 2.283750901619593

Epoch: 5| Step: 11
Training loss: 0.6154563426971436
Validation loss: 2.281455084681511

Epoch: 416| Step: 0
Training loss: 0.8455747365951538
Validation loss: 2.2142689675092697

Epoch: 5| Step: 1
Training loss: 1.299819827079773
Validation loss: 2.2070654978354773

Epoch: 5| Step: 2
Training loss: 1.1169105768203735
Validation loss: 2.2462349832057953

Epoch: 5| Step: 3
Training loss: 1.9290252923965454
Validation loss: 2.242573748032252

Epoch: 5| Step: 4
Training loss: 1.2687097787857056
Validation loss: 2.234424655636152

Epoch: 5| Step: 5
Training loss: 1.2522519826889038
Validation loss: 2.2310722172260284

Epoch: 5| Step: 6
Training loss: 1.0604274272918701
Validation loss: 2.2443337937196097

Epoch: 5| Step: 7
Training loss: 1.2826578617095947
Validation loss: 2.2433131833871207

Epoch: 5| Step: 8
Training loss: 1.7012968063354492
Validation loss: 2.2503376801808677

Epoch: 5| Step: 9
Training loss: 1.367331862449646
Validation loss: 2.28721817334493

Epoch: 5| Step: 10
Training loss: 0.7078927755355835
Validation loss: 2.2819395711024604

Epoch: 5| Step: 11
Training loss: 0.5258923768997192
Validation loss: 2.2786502639452615

Epoch: 417| Step: 0
Training loss: 1.4973502159118652
Validation loss: 2.2575078705946603

Epoch: 5| Step: 1
Training loss: 1.0244864225387573
Validation loss: 2.2863609542449317

Epoch: 5| Step: 2
Training loss: 1.1704353094100952
Validation loss: 2.2650489509105682

Epoch: 5| Step: 3
Training loss: 1.041560411453247
Validation loss: 2.263560563325882

Epoch: 5| Step: 4
Training loss: 1.375008225440979
Validation loss: 2.280373493830363

Epoch: 5| Step: 5
Training loss: 0.760407567024231
Validation loss: 2.235259532928467

Epoch: 5| Step: 6
Training loss: 1.3075449466705322
Validation loss: 2.240056117375692

Epoch: 5| Step: 7
Training loss: 1.351051688194275
Validation loss: 2.2849206725756326

Epoch: 5| Step: 8
Training loss: 1.1592426300048828
Validation loss: 2.265921582778295

Epoch: 5| Step: 9
Training loss: 1.205610990524292
Validation loss: 2.266009802619616

Epoch: 5| Step: 10
Training loss: 0.923744797706604
Validation loss: 2.280328889687856

Epoch: 5| Step: 11
Training loss: 1.680019736289978
Validation loss: 2.24390018483003

Epoch: 418| Step: 0
Training loss: 0.9200538396835327
Validation loss: 2.2930654883384705

Epoch: 5| Step: 1
Training loss: 1.2204740047454834
Validation loss: 2.3452562739451728

Epoch: 5| Step: 2
Training loss: 1.7441190481185913
Validation loss: 2.3094717413187027

Epoch: 5| Step: 3
Training loss: 1.4619232416152954
Validation loss: 2.311600680152575

Epoch: 5| Step: 4
Training loss: 1.0799880027770996
Validation loss: 2.2896653513113656

Epoch: 5| Step: 5
Training loss: 0.9778682589530945
Validation loss: 2.3068114519119263

Epoch: 5| Step: 6
Training loss: 0.9459723234176636
Validation loss: 2.244472920894623

Epoch: 5| Step: 7
Training loss: 1.7323684692382812
Validation loss: 2.219242369135221

Epoch: 5| Step: 8
Training loss: 1.4362937211990356
Validation loss: 2.206392079591751

Epoch: 5| Step: 9
Training loss: 0.9553510546684265
Validation loss: 2.227230116724968

Epoch: 5| Step: 10
Training loss: 1.09670090675354
Validation loss: 2.23919348915418

Epoch: 5| Step: 11
Training loss: 0.5820143818855286
Validation loss: 2.185571178793907

Epoch: 419| Step: 0
Training loss: 1.3173928260803223
Validation loss: 2.2374167740345

Epoch: 5| Step: 1
Training loss: 1.0102404356002808
Validation loss: 2.219889064629873

Epoch: 5| Step: 2
Training loss: 0.8959644436836243
Validation loss: 2.209065010150274

Epoch: 5| Step: 3
Training loss: 0.9371309280395508
Validation loss: 2.251289298137029

Epoch: 5| Step: 4
Training loss: 1.6957530975341797
Validation loss: 2.2556810478369393

Epoch: 5| Step: 5
Training loss: 1.115868330001831
Validation loss: 2.253807842731476

Epoch: 5| Step: 6
Training loss: 1.867123007774353
Validation loss: 2.2510163336992264

Epoch: 5| Step: 7
Training loss: 0.9988597631454468
Validation loss: 2.2537697354952493

Epoch: 5| Step: 8
Training loss: 0.8442327380180359
Validation loss: 2.2539181063572564

Epoch: 5| Step: 9
Training loss: 2.1031136512756348
Validation loss: 2.22484527528286

Epoch: 5| Step: 10
Training loss: 0.8383127450942993
Validation loss: 2.2223261147737503

Epoch: 5| Step: 11
Training loss: 0.9293431043624878
Validation loss: 2.1928274432818093

Epoch: 420| Step: 0
Training loss: 0.9712855219841003
Validation loss: 2.2063584675391517

Epoch: 5| Step: 1
Training loss: 2.370750904083252
Validation loss: 2.1820091207822165

Epoch: 5| Step: 2
Training loss: 1.3503773212432861
Validation loss: 2.2044663975636163

Epoch: 5| Step: 3
Training loss: 1.8651371002197266
Validation loss: 2.1846832036972046

Epoch: 5| Step: 4
Training loss: 1.1884634494781494
Validation loss: 2.227885593970617

Epoch: 5| Step: 5
Training loss: 1.0942933559417725
Validation loss: 2.2791923880577087

Epoch: 5| Step: 6
Training loss: 1.112882375717163
Validation loss: 2.3082158466180167

Epoch: 5| Step: 7
Training loss: 1.1724306344985962
Validation loss: 2.331059381365776

Epoch: 5| Step: 8
Training loss: 0.8820417523384094
Validation loss: 2.3034368505080542

Epoch: 5| Step: 9
Training loss: 1.2400163412094116
Validation loss: 2.3271989077329636

Epoch: 5| Step: 10
Training loss: 0.7988041639328003
Validation loss: 2.279316027959188

Epoch: 5| Step: 11
Training loss: 0.6238534450531006
Validation loss: 2.2501983841260276

Epoch: 421| Step: 0
Training loss: 1.7544625997543335
Validation loss: 2.2604501644770303

Epoch: 5| Step: 1
Training loss: 0.8908257484436035
Validation loss: 2.237335652112961

Epoch: 5| Step: 2
Training loss: 1.1499024629592896
Validation loss: 2.2384456793467202

Epoch: 5| Step: 3
Training loss: 1.0779715776443481
Validation loss: 2.2631734013557434

Epoch: 5| Step: 4
Training loss: 1.0145851373672485
Validation loss: 2.239792207876841

Epoch: 5| Step: 5
Training loss: 1.4184308052062988
Validation loss: 2.258239448070526

Epoch: 5| Step: 6
Training loss: 1.227405309677124
Validation loss: 2.252437795201937

Epoch: 5| Step: 7
Training loss: 0.9442289471626282
Validation loss: 2.3266153186559677

Epoch: 5| Step: 8
Training loss: 1.2047884464263916
Validation loss: 2.2774078945318856

Epoch: 5| Step: 9
Training loss: 0.8646897077560425
Validation loss: 2.2501482367515564

Epoch: 5| Step: 10
Training loss: 1.3918063640594482
Validation loss: 2.237042407194773

Epoch: 5| Step: 11
Training loss: 2.2310171127319336
Validation loss: 2.245241552591324

Epoch: 422| Step: 0
Training loss: 2.0606136322021484
Validation loss: 2.230776329835256

Epoch: 5| Step: 1
Training loss: 1.1847039461135864
Validation loss: 2.2524491945902505

Epoch: 5| Step: 2
Training loss: 1.1121829748153687
Validation loss: 2.287181094288826

Epoch: 5| Step: 3
Training loss: 0.8455729484558105
Validation loss: 2.2784593403339386

Epoch: 5| Step: 4
Training loss: 1.3145177364349365
Validation loss: 2.270331939061483

Epoch: 5| Step: 5
Training loss: 1.3753976821899414
Validation loss: 2.2726321518421173

Epoch: 5| Step: 6
Training loss: 0.7974992394447327
Validation loss: 2.247167930006981

Epoch: 5| Step: 7
Training loss: 1.0226351022720337
Validation loss: 2.2265971104303994

Epoch: 5| Step: 8
Training loss: 1.3197513818740845
Validation loss: 2.1961930145819983

Epoch: 5| Step: 9
Training loss: 1.8141533136367798
Validation loss: 2.2002214888731637

Epoch: 5| Step: 10
Training loss: 1.1553205251693726
Validation loss: 2.168896680076917

Epoch: 5| Step: 11
Training loss: 1.7390180826187134
Validation loss: 2.156653960545858

Epoch: 423| Step: 0
Training loss: 1.3635179996490479
Validation loss: 2.1776370902856192

Epoch: 5| Step: 1
Training loss: 1.5016205310821533
Validation loss: 2.1537796755631766

Epoch: 5| Step: 2
Training loss: 1.2690789699554443
Validation loss: 2.1620421608289084

Epoch: 5| Step: 3
Training loss: 1.4750568866729736
Validation loss: 2.1851455867290497

Epoch: 5| Step: 4
Training loss: 1.562554121017456
Validation loss: 2.2086822340885797

Epoch: 5| Step: 5
Training loss: 1.7257111072540283
Validation loss: 2.189837709069252

Epoch: 5| Step: 6
Training loss: 1.0587587356567383
Validation loss: 2.183976953228315

Epoch: 5| Step: 7
Training loss: 0.9531059265136719
Validation loss: 2.2553110122680664

Epoch: 5| Step: 8
Training loss: 1.1113134622573853
Validation loss: 2.270588551958402

Epoch: 5| Step: 9
Training loss: 1.3839826583862305
Validation loss: 2.2823275874058404

Epoch: 5| Step: 10
Training loss: 1.0891212224960327
Validation loss: 2.2648544112841287

Epoch: 5| Step: 11
Training loss: 2.131833076477051
Validation loss: 2.2675250669320426

Epoch: 424| Step: 0
Training loss: 0.7672256231307983
Validation loss: 2.275208204984665

Epoch: 5| Step: 1
Training loss: 0.9667993783950806
Validation loss: 2.2525145610173545

Epoch: 5| Step: 2
Training loss: 1.6205251216888428
Validation loss: 2.200365513563156

Epoch: 5| Step: 3
Training loss: 1.0893070697784424
Validation loss: 2.1760750263929367

Epoch: 5| Step: 4
Training loss: 1.5190867185592651
Validation loss: 2.20307324330012

Epoch: 5| Step: 5
Training loss: 1.5178992748260498
Validation loss: 2.250911990801493

Epoch: 5| Step: 6
Training loss: 1.4441839456558228
Validation loss: 2.1950478752454123

Epoch: 5| Step: 7
Training loss: 0.7781141996383667
Validation loss: 2.176269272963206

Epoch: 5| Step: 8
Training loss: 1.0956928730010986
Validation loss: 2.1822380870580673

Epoch: 5| Step: 9
Training loss: 1.1757575273513794
Validation loss: 2.2001953969399133

Epoch: 5| Step: 10
Training loss: 1.205810546875
Validation loss: 2.1956232140461602

Epoch: 5| Step: 11
Training loss: 1.7714370489120483
Validation loss: 2.18919837474823

Epoch: 425| Step: 0
Training loss: 1.17189621925354
Validation loss: 2.1776983042558036

Epoch: 5| Step: 1
Training loss: 1.1026115417480469
Validation loss: 2.199923808375994

Epoch: 5| Step: 2
Training loss: 1.4024279117584229
Validation loss: 2.202735106150309

Epoch: 5| Step: 3
Training loss: 0.9951682090759277
Validation loss: 2.1891343047221503

Epoch: 5| Step: 4
Training loss: 1.2746648788452148
Validation loss: 2.206627666950226

Epoch: 5| Step: 5
Training loss: 1.6713463068008423
Validation loss: 2.237308611472448

Epoch: 5| Step: 6
Training loss: 1.153478980064392
Validation loss: 2.201128820578257

Epoch: 5| Step: 7
Training loss: 0.9648459553718567
Validation loss: 2.2366174856821694

Epoch: 5| Step: 8
Training loss: 1.2185678482055664
Validation loss: 2.1884605338176093

Epoch: 5| Step: 9
Training loss: 1.563175916671753
Validation loss: 2.2319950660069785

Epoch: 5| Step: 10
Training loss: 0.9293543100357056
Validation loss: 2.209655890862147

Epoch: 5| Step: 11
Training loss: 0.46045804023742676
Validation loss: 2.2223940839370093

Epoch: 426| Step: 0
Training loss: 1.2857587337493896
Validation loss: 2.2339351077874503

Epoch: 5| Step: 1
Training loss: 1.164060354232788
Validation loss: 2.201507846514384

Epoch: 5| Step: 2
Training loss: 1.2531108856201172
Validation loss: 2.2044247587521872

Epoch: 5| Step: 3
Training loss: 1.8926258087158203
Validation loss: 2.2244669099648795

Epoch: 5| Step: 4
Training loss: 0.5444632768630981
Validation loss: 2.200784593820572

Epoch: 5| Step: 5
Training loss: 1.193690538406372
Validation loss: 2.1906311064958572

Epoch: 5| Step: 6
Training loss: 1.364705204963684
Validation loss: 2.205698033173879

Epoch: 5| Step: 7
Training loss: 1.3153703212738037
Validation loss: 2.2394601156314216

Epoch: 5| Step: 8
Training loss: 1.5474586486816406
Validation loss: 2.225258022546768

Epoch: 5| Step: 9
Training loss: 0.893528938293457
Validation loss: 2.2297629614671073

Epoch: 5| Step: 10
Training loss: 0.8479403257369995
Validation loss: 2.2507684777180352

Epoch: 5| Step: 11
Training loss: 0.6681609153747559
Validation loss: 2.2178226560354233

Epoch: 427| Step: 0
Training loss: 1.2318943738937378
Validation loss: 2.2464666912953057

Epoch: 5| Step: 1
Training loss: 0.9509873390197754
Validation loss: 2.2525905867417655

Epoch: 5| Step: 2
Training loss: 1.4568421840667725
Validation loss: 2.280143936475118

Epoch: 5| Step: 3
Training loss: 1.4680355787277222
Validation loss: 2.220538765192032

Epoch: 5| Step: 4
Training loss: 0.9735366106033325
Validation loss: 2.1838269432385764

Epoch: 5| Step: 5
Training loss: 0.8020429611206055
Validation loss: 2.238654062151909

Epoch: 5| Step: 6
Training loss: 0.6068274974822998
Validation loss: 2.197554975748062

Epoch: 5| Step: 7
Training loss: 1.1925857067108154
Validation loss: 2.227039227883021

Epoch: 5| Step: 8
Training loss: 1.610041856765747
Validation loss: 2.2208585689465203

Epoch: 5| Step: 9
Training loss: 1.092435359954834
Validation loss: 2.2387378911177316

Epoch: 5| Step: 10
Training loss: 1.5615825653076172
Validation loss: 2.219391350944837

Epoch: 5| Step: 11
Training loss: 1.3042292594909668
Validation loss: 2.204450140396754

Epoch: 428| Step: 0
Training loss: 1.2961786985397339
Validation loss: 2.2241462022066116

Epoch: 5| Step: 1
Training loss: 0.865408718585968
Validation loss: 2.2189017881949744

Epoch: 5| Step: 2
Training loss: 1.140183687210083
Validation loss: 2.2118513733148575

Epoch: 5| Step: 3
Training loss: 1.183788776397705
Validation loss: 2.1787651777267456

Epoch: 5| Step: 4
Training loss: 1.2689577341079712
Validation loss: 2.2596661845842996

Epoch: 5| Step: 5
Training loss: 1.0189390182495117
Validation loss: 2.254709760348002

Epoch: 5| Step: 6
Training loss: 1.0271680355072021
Validation loss: 2.2748043884833655

Epoch: 5| Step: 7
Training loss: 1.3804460763931274
Validation loss: 2.328021764755249

Epoch: 5| Step: 8
Training loss: 1.4471842050552368
Validation loss: 2.2917509178320565

Epoch: 5| Step: 9
Training loss: 1.1355431079864502
Validation loss: 2.3305504520734153

Epoch: 5| Step: 10
Training loss: 1.3797423839569092
Validation loss: 2.2534418205420175

Epoch: 5| Step: 11
Training loss: 2.523956775665283
Validation loss: 2.2715670267740884

Epoch: 429| Step: 0
Training loss: 0.8354673385620117
Validation loss: 2.2386720130840936

Epoch: 5| Step: 1
Training loss: 1.1391758918762207
Validation loss: 2.22964275876681

Epoch: 5| Step: 2
Training loss: 1.2664400339126587
Validation loss: 2.2024834156036377

Epoch: 5| Step: 3
Training loss: 1.2595393657684326
Validation loss: 2.214372922976812

Epoch: 5| Step: 4
Training loss: 1.1731116771697998
Validation loss: 2.201200952132543

Epoch: 5| Step: 5
Training loss: 1.5889750719070435
Validation loss: 2.1837146133184433

Epoch: 5| Step: 6
Training loss: 0.9694957733154297
Validation loss: 2.1883640537659326

Epoch: 5| Step: 7
Training loss: 1.6937415599822998
Validation loss: 2.2268509368101754

Epoch: 5| Step: 8
Training loss: 0.9745141863822937
Validation loss: 2.2116071383158364

Epoch: 5| Step: 9
Training loss: 1.1676377058029175
Validation loss: 2.2558602343002954

Epoch: 5| Step: 10
Training loss: 1.362339735031128
Validation loss: 2.1985841393470764

Epoch: 5| Step: 11
Training loss: 1.9647010564804077
Validation loss: 2.2322654078404107

Epoch: 430| Step: 0
Training loss: 0.8592796325683594
Validation loss: 2.224740579724312

Epoch: 5| Step: 1
Training loss: 1.6381947994232178
Validation loss: 2.156111568212509

Epoch: 5| Step: 2
Training loss: 0.6582688093185425
Validation loss: 2.1742965231339135

Epoch: 5| Step: 3
Training loss: 0.8454021215438843
Validation loss: 2.1869836846987405

Epoch: 5| Step: 4
Training loss: 1.4656285047531128
Validation loss: 2.1856849044561386

Epoch: 5| Step: 5
Training loss: 1.0537655353546143
Validation loss: 2.1692656179269156

Epoch: 5| Step: 6
Training loss: 1.3606032133102417
Validation loss: 2.176947077115377

Epoch: 5| Step: 7
Training loss: 1.4997551441192627
Validation loss: 2.149592195947965

Epoch: 5| Step: 8
Training loss: 1.4669454097747803
Validation loss: 2.1756336241960526

Epoch: 5| Step: 9
Training loss: 0.9298040270805359
Validation loss: 2.1587867786486945

Epoch: 5| Step: 10
Training loss: 1.764801263809204
Validation loss: 2.181228538354238

Epoch: 5| Step: 11
Training loss: 0.6527311205863953
Validation loss: 2.250054106116295

Epoch: 431| Step: 0
Training loss: 0.9091676473617554
Validation loss: 2.1608030746380487

Epoch: 5| Step: 1
Training loss: 1.0430899858474731
Validation loss: 2.168923035264015

Epoch: 5| Step: 2
Training loss: 1.276700735092163
Validation loss: 2.155897875626882

Epoch: 5| Step: 3
Training loss: 1.2902666330337524
Validation loss: 2.178300201892853

Epoch: 5| Step: 4
Training loss: 0.8728607296943665
Validation loss: 2.17167862256368

Epoch: 5| Step: 5
Training loss: 0.6451799273490906
Validation loss: 2.1822184373935065

Epoch: 5| Step: 6
Training loss: 1.4882770776748657
Validation loss: 2.2059018860260644

Epoch: 5| Step: 7
Training loss: 1.3253302574157715
Validation loss: 2.171818658709526

Epoch: 5| Step: 8
Training loss: 1.4113812446594238
Validation loss: 2.1902549465497336

Epoch: 5| Step: 9
Training loss: 1.361019492149353
Validation loss: 2.226433207591375

Epoch: 5| Step: 10
Training loss: 1.133097529411316
Validation loss: 2.223756064971288

Epoch: 5| Step: 11
Training loss: 1.9271321296691895
Validation loss: 2.22965174416701

Epoch: 432| Step: 0
Training loss: 1.7632719278335571
Validation loss: 2.223921393354734

Epoch: 5| Step: 1
Training loss: 1.230168104171753
Validation loss: 2.2177185118198395

Epoch: 5| Step: 2
Training loss: 1.8251829147338867
Validation loss: 2.19892210761706

Epoch: 5| Step: 3
Training loss: 1.0279594659805298
Validation loss: 2.189182162284851

Epoch: 5| Step: 4
Training loss: 0.970904529094696
Validation loss: 2.2083153327306113

Epoch: 5| Step: 5
Training loss: 0.7442609071731567
Validation loss: 2.152661527196566

Epoch: 5| Step: 6
Training loss: 1.073671817779541
Validation loss: 2.182676707704862

Epoch: 5| Step: 7
Training loss: 0.9449517130851746
Validation loss: 2.153211082021395

Epoch: 5| Step: 8
Training loss: 1.4251534938812256
Validation loss: 2.1806136816740036

Epoch: 5| Step: 9
Training loss: 1.2130022048950195
Validation loss: 2.163592129945755

Epoch: 5| Step: 10
Training loss: 0.9503992199897766
Validation loss: 2.1698229064544043

Epoch: 5| Step: 11
Training loss: 1.1475626230239868
Validation loss: 2.188603773713112

Epoch: 433| Step: 0
Training loss: 2.0352606773376465
Validation loss: 2.187102864185969

Epoch: 5| Step: 1
Training loss: 1.3444713354110718
Validation loss: 2.23294006784757

Epoch: 5| Step: 2
Training loss: 1.039638638496399
Validation loss: 2.207119291027387

Epoch: 5| Step: 3
Training loss: 1.3261699676513672
Validation loss: 2.2427060306072235

Epoch: 5| Step: 4
Training loss: 1.2438812255859375
Validation loss: 2.23489548265934

Epoch: 5| Step: 5
Training loss: 1.314683198928833
Validation loss: 2.2562884589036307

Epoch: 5| Step: 6
Training loss: 0.7729769945144653
Validation loss: 2.257647603750229

Epoch: 5| Step: 7
Training loss: 1.0026304721832275
Validation loss: 2.227415213982264

Epoch: 5| Step: 8
Training loss: 0.9358434677124023
Validation loss: 2.2146533032258353

Epoch: 5| Step: 9
Training loss: 0.4741007685661316
Validation loss: 2.245052218437195

Epoch: 5| Step: 10
Training loss: 1.167374849319458
Validation loss: 2.2439588755369186

Epoch: 5| Step: 11
Training loss: 1.1273698806762695
Validation loss: 2.2269075363874435

Epoch: 434| Step: 0
Training loss: 0.8758354187011719
Validation loss: 2.2468930830558143

Epoch: 5| Step: 1
Training loss: 1.607733130455017
Validation loss: 2.271579012274742

Epoch: 5| Step: 2
Training loss: 1.0375158786773682
Validation loss: 2.2765678564707437

Epoch: 5| Step: 3
Training loss: 0.6262261271476746
Validation loss: 2.234412839015325

Epoch: 5| Step: 4
Training loss: 1.5616618394851685
Validation loss: 2.2751079549392066

Epoch: 5| Step: 5
Training loss: 1.041011929512024
Validation loss: 2.238943338394165

Epoch: 5| Step: 6
Training loss: 1.0856118202209473
Validation loss: 2.2112934788068137

Epoch: 5| Step: 7
Training loss: 1.043675422668457
Validation loss: 2.2759943157434464

Epoch: 5| Step: 8
Training loss: 1.713138222694397
Validation loss: 2.2538867791493735

Epoch: 5| Step: 9
Training loss: 1.3350999355316162
Validation loss: 2.251690775156021

Epoch: 5| Step: 10
Training loss: 0.9450985193252563
Validation loss: 2.3073139786720276

Epoch: 5| Step: 11
Training loss: 1.2771165370941162
Validation loss: 2.32635161280632

Epoch: 435| Step: 0
Training loss: 1.1545360088348389
Validation loss: 2.3788332094748816

Epoch: 5| Step: 1
Training loss: 1.7178665399551392
Validation loss: 2.346035917599996

Epoch: 5| Step: 2
Training loss: 1.0705221891403198
Validation loss: 2.3482255140940347

Epoch: 5| Step: 3
Training loss: 1.0654408931732178
Validation loss: 2.339333971341451

Epoch: 5| Step: 4
Training loss: 1.4572904109954834
Validation loss: 2.338309188683828

Epoch: 5| Step: 5
Training loss: 1.2484533786773682
Validation loss: 2.2913736949364343

Epoch: 5| Step: 6
Training loss: 0.8472317457199097
Validation loss: 2.246710235873858

Epoch: 5| Step: 7
Training loss: 0.7417322993278503
Validation loss: 2.272832448283831

Epoch: 5| Step: 8
Training loss: 1.2840120792388916
Validation loss: 2.2473538468281427

Epoch: 5| Step: 9
Training loss: 1.281463623046875
Validation loss: 2.270502065618833

Epoch: 5| Step: 10
Training loss: 1.266075849533081
Validation loss: 2.25163301328818

Epoch: 5| Step: 11
Training loss: 1.825696587562561
Validation loss: 2.2596252113580704

Epoch: 436| Step: 0
Training loss: 1.5694297552108765
Validation loss: 2.261425723632177

Epoch: 5| Step: 1
Training loss: 0.8895518183708191
Validation loss: 2.219572822252909

Epoch: 5| Step: 2
Training loss: 1.4003268480300903
Validation loss: 2.2189216117064157

Epoch: 5| Step: 3
Training loss: 1.0042228698730469
Validation loss: 2.2500353952248893

Epoch: 5| Step: 4
Training loss: 1.2171508073806763
Validation loss: 2.2375857333342233

Epoch: 5| Step: 5
Training loss: 1.597583532333374
Validation loss: 2.268071045478185

Epoch: 5| Step: 6
Training loss: 1.2378945350646973
Validation loss: 2.218365187446276

Epoch: 5| Step: 7
Training loss: 1.0434577465057373
Validation loss: 2.199647312362989

Epoch: 5| Step: 8
Training loss: 1.368815541267395
Validation loss: 2.250145504872004

Epoch: 5| Step: 9
Training loss: 0.9804355502128601
Validation loss: 2.2315487960974374

Epoch: 5| Step: 10
Training loss: 0.6848332285881042
Validation loss: 2.2069503565629325

Epoch: 5| Step: 11
Training loss: 0.39120733737945557
Validation loss: 2.2269119769334793

Epoch: 437| Step: 0
Training loss: 1.0368696451187134
Validation loss: 2.25720743338267

Epoch: 5| Step: 1
Training loss: 0.8065356016159058
Validation loss: 2.224937508503596

Epoch: 5| Step: 2
Training loss: 0.8550950288772583
Validation loss: 2.242243150870005

Epoch: 5| Step: 3
Training loss: 1.2695025205612183
Validation loss: 2.2287136962016425

Epoch: 5| Step: 4
Training loss: 1.5792317390441895
Validation loss: 2.1931628783543906

Epoch: 5| Step: 5
Training loss: 0.8702330589294434
Validation loss: 2.1952742586533227

Epoch: 5| Step: 6
Training loss: 1.6506589651107788
Validation loss: 2.2270559271176658

Epoch: 5| Step: 7
Training loss: 0.8358185887336731
Validation loss: 2.2192243188619614

Epoch: 5| Step: 8
Training loss: 1.0484826564788818
Validation loss: 2.188326060771942

Epoch: 5| Step: 9
Training loss: 0.9144850969314575
Validation loss: 2.221459378798803

Epoch: 5| Step: 10
Training loss: 1.3461068868637085
Validation loss: 2.2079106718301773

Epoch: 5| Step: 11
Training loss: 3.5724213123321533
Validation loss: 2.1964985926946006

Epoch: 438| Step: 0
Training loss: 1.6655457019805908
Validation loss: 2.194706549247106

Epoch: 5| Step: 1
Training loss: 0.988618016242981
Validation loss: 2.210225229461988

Epoch: 5| Step: 2
Training loss: 1.0629692077636719
Validation loss: 2.234792560338974

Epoch: 5| Step: 3
Training loss: 1.4548898935317993
Validation loss: 2.2145392298698425

Epoch: 5| Step: 4
Training loss: 0.78511643409729
Validation loss: 2.2090347508589425

Epoch: 5| Step: 5
Training loss: 0.7668306231498718
Validation loss: 2.2162357171376548

Epoch: 5| Step: 6
Training loss: 1.1271339654922485
Validation loss: 2.1786084473133087

Epoch: 5| Step: 7
Training loss: 1.5811671018600464
Validation loss: 2.204083815217018

Epoch: 5| Step: 8
Training loss: 0.582795262336731
Validation loss: 2.219219813744227

Epoch: 5| Step: 9
Training loss: 0.938134491443634
Validation loss: 2.199354827404022

Epoch: 5| Step: 10
Training loss: 1.290530800819397
Validation loss: 2.2108305394649506

Epoch: 5| Step: 11
Training loss: 1.9546931982040405
Validation loss: 2.2131672898928323

Epoch: 439| Step: 0
Training loss: 1.051055908203125
Validation loss: 2.1938353230555854

Epoch: 5| Step: 1
Training loss: 1.5843828916549683
Validation loss: 2.2288426061471305

Epoch: 5| Step: 2
Training loss: 0.6011478900909424
Validation loss: 2.197230786085129

Epoch: 5| Step: 3
Training loss: 0.5276395082473755
Validation loss: 2.2117736438910165

Epoch: 5| Step: 4
Training loss: 0.901025652885437
Validation loss: 2.1710041761398315

Epoch: 5| Step: 5
Training loss: 1.2841029167175293
Validation loss: 2.210170273979505

Epoch: 5| Step: 6
Training loss: 1.7687431573867798
Validation loss: 2.207974667350451

Epoch: 5| Step: 7
Training loss: 0.9180951118469238
Validation loss: 2.1888042390346527

Epoch: 5| Step: 8
Training loss: 1.2197850942611694
Validation loss: 2.1931834618250527

Epoch: 5| Step: 9
Training loss: 0.9131080508232117
Validation loss: 2.2141513228416443

Epoch: 5| Step: 10
Training loss: 1.4258896112442017
Validation loss: 2.21990630030632

Epoch: 5| Step: 11
Training loss: 1.0540547370910645
Validation loss: 2.1867553095022836

Epoch: 440| Step: 0
Training loss: 1.3764219284057617
Validation loss: 2.1996398816506066

Epoch: 5| Step: 1
Training loss: 1.1798145771026611
Validation loss: 2.240533545613289

Epoch: 5| Step: 2
Training loss: 0.9744888544082642
Validation loss: 2.2175476451714835

Epoch: 5| Step: 3
Training loss: 1.2331520318984985
Validation loss: 2.2069603502750397

Epoch: 5| Step: 4
Training loss: 0.6478752493858337
Validation loss: 2.198421820998192

Epoch: 5| Step: 5
Training loss: 1.0532487630844116
Validation loss: 2.170213277141253

Epoch: 5| Step: 6
Training loss: 0.8877948522567749
Validation loss: 2.1911749690771103

Epoch: 5| Step: 7
Training loss: 0.9596971273422241
Validation loss: 2.2154908875624337

Epoch: 5| Step: 8
Training loss: 1.4413812160491943
Validation loss: 2.173021376132965

Epoch: 5| Step: 9
Training loss: 1.437654733657837
Validation loss: 2.240251819292704

Epoch: 5| Step: 10
Training loss: 0.8183344602584839
Validation loss: 2.225033084551493

Epoch: 5| Step: 11
Training loss: 2.2026185989379883
Validation loss: 2.2167866031328836

Epoch: 441| Step: 0
Training loss: 0.9113063812255859
Validation loss: 2.2341322849194207

Epoch: 5| Step: 1
Training loss: 1.1044161319732666
Validation loss: 2.2334695806105933

Epoch: 5| Step: 2
Training loss: 1.0417612791061401
Validation loss: 2.2731501708428064

Epoch: 5| Step: 3
Training loss: 1.0932514667510986
Validation loss: 2.2969656785329184

Epoch: 5| Step: 4
Training loss: 1.6799278259277344
Validation loss: 2.3423713942368827

Epoch: 5| Step: 5
Training loss: 0.931649386882782
Validation loss: 2.3300325820843377

Epoch: 5| Step: 6
Training loss: 0.9010076522827148
Validation loss: 2.363183250029882

Epoch: 5| Step: 7
Training loss: 1.4205065965652466
Validation loss: 2.3503100872039795

Epoch: 5| Step: 8
Training loss: 1.0784841775894165
Validation loss: 2.3345102965831757

Epoch: 5| Step: 9
Training loss: 1.1082663536071777
Validation loss: 2.305534283320109

Epoch: 5| Step: 10
Training loss: 1.11227548122406
Validation loss: 2.238097349802653

Epoch: 5| Step: 11
Training loss: 1.6715012788772583
Validation loss: 2.257120350996653

Epoch: 442| Step: 0
Training loss: 0.8040984869003296
Validation loss: 2.22469292084376

Epoch: 5| Step: 1
Training loss: 1.2027652263641357
Validation loss: 2.2647306323051453

Epoch: 5| Step: 2
Training loss: 1.347424864768982
Validation loss: 2.266128713885943

Epoch: 5| Step: 3
Training loss: 1.3558787107467651
Validation loss: 2.2780661582946777

Epoch: 5| Step: 4
Training loss: 1.4910913705825806
Validation loss: 2.2468483249346414

Epoch: 5| Step: 5
Training loss: 1.3613941669464111
Validation loss: 2.229373668630918

Epoch: 5| Step: 6
Training loss: 0.9650278091430664
Validation loss: 2.2748120526472726

Epoch: 5| Step: 7
Training loss: 1.2078224420547485
Validation loss: 2.253616208831469

Epoch: 5| Step: 8
Training loss: 1.387451410293579
Validation loss: 2.2728811502456665

Epoch: 5| Step: 9
Training loss: 1.1818857192993164
Validation loss: 2.319417347510656

Epoch: 5| Step: 10
Training loss: 0.6822590827941895
Validation loss: 2.2888601322968802

Epoch: 5| Step: 11
Training loss: 0.6555375456809998
Validation loss: 2.3168152372042337

Epoch: 443| Step: 0
Training loss: 1.542847752571106
Validation loss: 2.2662908881902695

Epoch: 5| Step: 1
Training loss: 1.0427882671356201
Validation loss: 2.245324114958445

Epoch: 5| Step: 2
Training loss: 0.735838770866394
Validation loss: 2.2429830928643546

Epoch: 5| Step: 3
Training loss: 0.9053101539611816
Validation loss: 2.2444233496983848

Epoch: 5| Step: 4
Training loss: 0.8436130285263062
Validation loss: 2.2027961810429892

Epoch: 5| Step: 5
Training loss: 1.4162485599517822
Validation loss: 2.227843761444092

Epoch: 5| Step: 6
Training loss: 0.9261253476142883
Validation loss: 2.232342595855395

Epoch: 5| Step: 7
Training loss: 1.7600338459014893
Validation loss: 2.213820825020472

Epoch: 5| Step: 8
Training loss: 0.9625197649002075
Validation loss: 2.2003570894400277

Epoch: 5| Step: 9
Training loss: 1.1841951608657837
Validation loss: 2.194916680455208

Epoch: 5| Step: 10
Training loss: 1.0563136339187622
Validation loss: 2.1994749903678894

Epoch: 5| Step: 11
Training loss: 0.8468731641769409
Validation loss: 2.1767358084519706

Epoch: 444| Step: 0
Training loss: 1.189430594444275
Validation loss: 2.178386022647222

Epoch: 5| Step: 1
Training loss: 1.2551343441009521
Validation loss: 2.211285188794136

Epoch: 5| Step: 2
Training loss: 0.7947498559951782
Validation loss: 2.202837213873863

Epoch: 5| Step: 3
Training loss: 0.8005563616752625
Validation loss: 2.213557923833529

Epoch: 5| Step: 4
Training loss: 1.0977709293365479
Validation loss: 2.2268758167823157

Epoch: 5| Step: 5
Training loss: 1.0715479850769043
Validation loss: 2.1969549556573233

Epoch: 5| Step: 6
Training loss: 0.834124743938446
Validation loss: 2.1764658788839975

Epoch: 5| Step: 7
Training loss: 1.2148369550704956
Validation loss: 2.1532114992539086

Epoch: 5| Step: 8
Training loss: 1.1554639339447021
Validation loss: 2.2146551261345544

Epoch: 5| Step: 9
Training loss: 1.1258549690246582
Validation loss: 2.1830576807260513

Epoch: 5| Step: 10
Training loss: 1.2910089492797852
Validation loss: 2.203691398104032

Epoch: 5| Step: 11
Training loss: 1.424293041229248
Validation loss: 2.1580340514580407

Epoch: 445| Step: 0
Training loss: 0.8129292726516724
Validation loss: 2.227283865213394

Epoch: 5| Step: 1
Training loss: 1.1671907901763916
Validation loss: 2.2121284107367196

Epoch: 5| Step: 2
Training loss: 1.0683691501617432
Validation loss: 2.1726998339096704

Epoch: 5| Step: 3
Training loss: 1.00492262840271
Validation loss: 2.265676995118459

Epoch: 5| Step: 4
Training loss: 1.3521093130111694
Validation loss: 2.2087417940298715

Epoch: 5| Step: 5
Training loss: 1.6955015659332275
Validation loss: 2.2222170581420264

Epoch: 5| Step: 6
Training loss: 1.6451066732406616
Validation loss: 2.19937826693058

Epoch: 5| Step: 7
Training loss: 0.9074634313583374
Validation loss: 2.220508426427841

Epoch: 5| Step: 8
Training loss: 0.590735912322998
Validation loss: 2.1990034580230713

Epoch: 5| Step: 9
Training loss: 0.6719762086868286
Validation loss: 2.173228239019712

Epoch: 5| Step: 10
Training loss: 0.9698947668075562
Validation loss: 2.217454190055529

Epoch: 5| Step: 11
Training loss: 0.9388406276702881
Validation loss: 2.205311417579651

Epoch: 446| Step: 0
Training loss: 1.1224526166915894
Validation loss: 2.215789496898651

Epoch: 5| Step: 1
Training loss: 0.9527870416641235
Validation loss: 2.2445507993300757

Epoch: 5| Step: 2
Training loss: 1.208111047744751
Validation loss: 2.265587488810221

Epoch: 5| Step: 3
Training loss: 1.1931889057159424
Validation loss: 2.259634723265966

Epoch: 5| Step: 4
Training loss: 1.2463102340698242
Validation loss: 2.2297877073287964

Epoch: 5| Step: 5
Training loss: 1.452677607536316
Validation loss: 2.1784417231877646

Epoch: 5| Step: 6
Training loss: 0.5250357985496521
Validation loss: 2.2004047632217407

Epoch: 5| Step: 7
Training loss: 2.0958313941955566
Validation loss: 2.2069602608680725

Epoch: 5| Step: 8
Training loss: 0.9006220102310181
Validation loss: 2.1883522272109985

Epoch: 5| Step: 9
Training loss: 0.8529378175735474
Validation loss: 2.189965436855952

Epoch: 5| Step: 10
Training loss: 0.4846811294555664
Validation loss: 2.2123381197452545

Epoch: 5| Step: 11
Training loss: 2.09946346282959
Validation loss: 2.184744114677111

Epoch: 447| Step: 0
Training loss: 1.331229329109192
Validation loss: 2.2121366461118064

Epoch: 5| Step: 1
Training loss: 0.8845025300979614
Validation loss: 2.2495134323835373

Epoch: 5| Step: 2
Training loss: 1.4415258169174194
Validation loss: 2.2633874714374542

Epoch: 5| Step: 3
Training loss: 1.1688454151153564
Validation loss: 2.273052453994751

Epoch: 5| Step: 4
Training loss: 0.965070903301239
Validation loss: 2.262323319911957

Epoch: 5| Step: 5
Training loss: 0.9261654019355774
Validation loss: 2.273893266916275

Epoch: 5| Step: 6
Training loss: 1.3595237731933594
Validation loss: 2.2202550023794174

Epoch: 5| Step: 7
Training loss: 0.5924131274223328
Validation loss: 2.23394583662351

Epoch: 5| Step: 8
Training loss: 0.7440392971038818
Validation loss: 2.25646780927976

Epoch: 5| Step: 9
Training loss: 1.4842742681503296
Validation loss: 2.2033051401376724

Epoch: 5| Step: 10
Training loss: 1.0404072999954224
Validation loss: 2.231123963991801

Epoch: 5| Step: 11
Training loss: 0.5558708906173706
Validation loss: 2.2109716335932412

Epoch: 448| Step: 0
Training loss: 1.021368145942688
Validation loss: 2.191395550966263

Epoch: 5| Step: 1
Training loss: 0.616420567035675
Validation loss: 2.196040620406469

Epoch: 5| Step: 2
Training loss: 1.003429651260376
Validation loss: 2.2104507386684418

Epoch: 5| Step: 3
Training loss: 0.8992166519165039
Validation loss: 2.2135420689980188

Epoch: 5| Step: 4
Training loss: 0.7938262820243835
Validation loss: 2.211909979581833

Epoch: 5| Step: 5
Training loss: 2.2888898849487305
Validation loss: 2.2068201700846353

Epoch: 5| Step: 6
Training loss: 1.2391126155853271
Validation loss: 2.2544916570186615

Epoch: 5| Step: 7
Training loss: 0.8496685028076172
Validation loss: 2.2293603122234344

Epoch: 5| Step: 8
Training loss: 1.6150566339492798
Validation loss: 2.2692192991574607

Epoch: 5| Step: 9
Training loss: 0.798835277557373
Validation loss: 2.2260846942663193

Epoch: 5| Step: 10
Training loss: 0.9863899946212769
Validation loss: 2.226250355442365

Epoch: 5| Step: 11
Training loss: 0.6227538585662842
Validation loss: 2.25464661916097

Epoch: 449| Step: 0
Training loss: 0.9029094576835632
Validation loss: 2.2235599358876548

Epoch: 5| Step: 1
Training loss: 1.1397194862365723
Validation loss: 2.192324305574099

Epoch: 5| Step: 2
Training loss: 1.1292067766189575
Validation loss: 2.243591616551081

Epoch: 5| Step: 3
Training loss: 0.8100069165229797
Validation loss: 2.212255304058393

Epoch: 5| Step: 4
Training loss: 1.3307961225509644
Validation loss: 2.2458406190077462

Epoch: 5| Step: 5
Training loss: 1.026727557182312
Validation loss: 2.2302716771761575

Epoch: 5| Step: 6
Training loss: 1.0696055889129639
Validation loss: 2.212686389684677

Epoch: 5| Step: 7
Training loss: 0.7354423403739929
Validation loss: 2.220293382803599

Epoch: 5| Step: 8
Training loss: 0.9537627100944519
Validation loss: 2.245635857184728

Epoch: 5| Step: 9
Training loss: 1.977567434310913
Validation loss: 2.2310018142064414

Epoch: 5| Step: 10
Training loss: 0.9641397595405579
Validation loss: 2.269805997610092

Epoch: 5| Step: 11
Training loss: 1.6628713607788086
Validation loss: 2.2864091197649636

Epoch: 450| Step: 0
Training loss: 1.0310662984848022
Validation loss: 2.270112320780754

Epoch: 5| Step: 1
Training loss: 1.04921555519104
Validation loss: 2.2735687444607415

Epoch: 5| Step: 2
Training loss: 0.749391496181488
Validation loss: 2.216915249824524

Epoch: 5| Step: 3
Training loss: 1.335932970046997
Validation loss: 2.261958306034406

Epoch: 5| Step: 4
Training loss: 1.1333727836608887
Validation loss: 2.2426814238230386

Epoch: 5| Step: 5
Training loss: 1.138857126235962
Validation loss: 2.247617353995641

Epoch: 5| Step: 6
Training loss: 2.0356674194335938
Validation loss: 2.260509749253591

Epoch: 5| Step: 7
Training loss: 0.7094711065292358
Validation loss: 2.2462842563788095

Epoch: 5| Step: 8
Training loss: 0.9749888181686401
Validation loss: 2.216116895278295

Epoch: 5| Step: 9
Training loss: 1.1321324110031128
Validation loss: 2.2553129394849143

Epoch: 5| Step: 10
Training loss: 1.3887345790863037
Validation loss: 2.255217428008715

Epoch: 5| Step: 11
Training loss: 0.9465399384498596
Validation loss: 2.2357040097316108

Epoch: 451| Step: 0
Training loss: 0.7496235370635986
Validation loss: 2.2236715058485665

Epoch: 5| Step: 1
Training loss: 1.0607832670211792
Validation loss: 2.234584932525953

Epoch: 5| Step: 2
Training loss: 1.6743558645248413
Validation loss: 2.241199235121409

Epoch: 5| Step: 3
Training loss: 0.8627845644950867
Validation loss: 2.2561335961023965

Epoch: 5| Step: 4
Training loss: 1.122849464416504
Validation loss: 2.221636012196541

Epoch: 5| Step: 5
Training loss: 1.0426690578460693
Validation loss: 2.2338243375221887

Epoch: 5| Step: 6
Training loss: 1.3220593929290771
Validation loss: 2.2493834694226584

Epoch: 5| Step: 7
Training loss: 1.3479433059692383
Validation loss: 2.2534754276275635

Epoch: 5| Step: 8
Training loss: 0.7695614099502563
Validation loss: 2.243924528360367

Epoch: 5| Step: 9
Training loss: 1.044348955154419
Validation loss: 2.207658588886261

Epoch: 5| Step: 10
Training loss: 0.9454261064529419
Validation loss: 2.2752354641755423

Epoch: 5| Step: 11
Training loss: 1.225691318511963
Validation loss: 2.2294606417417526

Epoch: 452| Step: 0
Training loss: 0.972479522228241
Validation loss: 2.2030601799488068

Epoch: 5| Step: 1
Training loss: 1.1573807001113892
Validation loss: 2.1821490079164505

Epoch: 5| Step: 2
Training loss: 1.433801293373108
Validation loss: 2.1907613476117453

Epoch: 5| Step: 3
Training loss: 0.7377103567123413
Validation loss: 2.195353150367737

Epoch: 5| Step: 4
Training loss: 0.8728232383728027
Validation loss: 2.233492831389109

Epoch: 5| Step: 5
Training loss: 1.1517524719238281
Validation loss: 2.1987597346305847

Epoch: 5| Step: 6
Training loss: 0.5453649759292603
Validation loss: 2.196370671192805

Epoch: 5| Step: 7
Training loss: 0.698843240737915
Validation loss: 2.2290746668974557

Epoch: 5| Step: 8
Training loss: 1.2826801538467407
Validation loss: 2.244223823149999

Epoch: 5| Step: 9
Training loss: 1.2981526851654053
Validation loss: 2.1589574813842773

Epoch: 5| Step: 10
Training loss: 1.6171455383300781
Validation loss: 2.229601100087166

Epoch: 5| Step: 11
Training loss: 0.36211448907852173
Validation loss: 2.225922574599584

Epoch: 453| Step: 0
Training loss: 1.4626556634902954
Validation loss: 2.2324665834506354

Epoch: 5| Step: 1
Training loss: 1.5820602178573608
Validation loss: 2.2577264308929443

Epoch: 5| Step: 2
Training loss: 1.0459957122802734
Validation loss: 2.2214072346687317

Epoch: 5| Step: 3
Training loss: 0.5343865156173706
Validation loss: 2.2196486492951712

Epoch: 5| Step: 4
Training loss: 1.3068530559539795
Validation loss: 2.2174191077550254

Epoch: 5| Step: 5
Training loss: 1.1039221286773682
Validation loss: 2.204820235570272

Epoch: 5| Step: 6
Training loss: 1.2272846698760986
Validation loss: 2.1800622095664344

Epoch: 5| Step: 7
Training loss: 0.7741132974624634
Validation loss: 2.208528677622477

Epoch: 5| Step: 8
Training loss: 0.8833125829696655
Validation loss: 2.1719345649083457

Epoch: 5| Step: 9
Training loss: 0.9040437936782837
Validation loss: 2.22692608833313

Epoch: 5| Step: 10
Training loss: 1.1682988405227661
Validation loss: 2.196622207760811

Epoch: 5| Step: 11
Training loss: 0.47528040409088135
Validation loss: 2.1863534102837243

Epoch: 454| Step: 0
Training loss: 1.015774130821228
Validation loss: 2.1568503131469092

Epoch: 5| Step: 1
Training loss: 0.6280155181884766
Validation loss: 2.1942884425322213

Epoch: 5| Step: 2
Training loss: 0.8128029108047485
Validation loss: 2.176929692427317

Epoch: 5| Step: 3
Training loss: 0.879440188407898
Validation loss: 2.18602861960729

Epoch: 5| Step: 4
Training loss: 1.4918594360351562
Validation loss: 2.2234820326169333

Epoch: 5| Step: 5
Training loss: 0.8693013191223145
Validation loss: 2.2049628545840583

Epoch: 5| Step: 6
Training loss: 0.7771655917167664
Validation loss: 2.2217605809370675

Epoch: 5| Step: 7
Training loss: 1.2001689672470093
Validation loss: 2.1766576170921326

Epoch: 5| Step: 8
Training loss: 1.3185956478118896
Validation loss: 2.1799080272515616

Epoch: 5| Step: 9
Training loss: 1.731925368309021
Validation loss: 2.177877366542816

Epoch: 5| Step: 10
Training loss: 1.266763687133789
Validation loss: 2.2452375988165536

Epoch: 5| Step: 11
Training loss: 1.073679804801941
Validation loss: 2.2037868201732635

Epoch: 455| Step: 0
Training loss: 1.3862640857696533
Validation loss: 2.2411777476469674

Epoch: 5| Step: 1
Training loss: 0.7056158781051636
Validation loss: 2.2244555999835334

Epoch: 5| Step: 2
Training loss: 1.0497602224349976
Validation loss: 2.2071869572003684

Epoch: 5| Step: 3
Training loss: 1.1172044277191162
Validation loss: 2.2390906512737274

Epoch: 5| Step: 4
Training loss: 0.8519346117973328
Validation loss: 2.1841574956973395

Epoch: 5| Step: 5
Training loss: 1.1012859344482422
Validation loss: 2.21688603858153

Epoch: 5| Step: 6
Training loss: 1.1569987535476685
Validation loss: 2.199298992753029

Epoch: 5| Step: 7
Training loss: 1.1526687145233154
Validation loss: 2.1760114232699075

Epoch: 5| Step: 8
Training loss: 0.6841785907745361
Validation loss: 2.157843371232351

Epoch: 5| Step: 9
Training loss: 1.0616453886032104
Validation loss: 2.206356167793274

Epoch: 5| Step: 10
Training loss: 1.8022445440292358
Validation loss: 2.229905237754186

Epoch: 5| Step: 11
Training loss: 0.4194380044937134
Validation loss: 2.204793800910314

Epoch: 456| Step: 0
Training loss: 0.5620819330215454
Validation loss: 2.2230761349201202

Epoch: 5| Step: 1
Training loss: 0.9475107192993164
Validation loss: 2.204248065749804

Epoch: 5| Step: 2
Training loss: 1.03861665725708
Validation loss: 2.1933164447546005

Epoch: 5| Step: 3
Training loss: 1.2300355434417725
Validation loss: 2.211492578188578

Epoch: 5| Step: 4
Training loss: 1.7768123149871826
Validation loss: 2.237180163462957

Epoch: 5| Step: 5
Training loss: 1.4425013065338135
Validation loss: 2.264937420686086

Epoch: 5| Step: 6
Training loss: 0.5611224174499512
Validation loss: 2.2385142693916955

Epoch: 5| Step: 7
Training loss: 0.5838247537612915
Validation loss: 2.2368181198835373

Epoch: 5| Step: 8
Training loss: 0.7070935964584351
Validation loss: 2.1995005110899606

Epoch: 5| Step: 9
Training loss: 1.2691236734390259
Validation loss: 2.222473914424578

Epoch: 5| Step: 10
Training loss: 1.25539231300354
Validation loss: 2.202830448746681

Epoch: 5| Step: 11
Training loss: 0.7998595237731934
Validation loss: 2.202763393521309

Epoch: 457| Step: 0
Training loss: 1.3996202945709229
Validation loss: 2.2039924760659537

Epoch: 5| Step: 1
Training loss: 0.811318576335907
Validation loss: 2.1360760430494943

Epoch: 5| Step: 2
Training loss: 1.6048552989959717
Validation loss: 2.1619164794683456

Epoch: 5| Step: 3
Training loss: 0.8562074899673462
Validation loss: 2.1758501827716827

Epoch: 5| Step: 4
Training loss: 0.962847113609314
Validation loss: 2.1704364021619162

Epoch: 5| Step: 5
Training loss: 0.9082332849502563
Validation loss: 2.201406871279081

Epoch: 5| Step: 6
Training loss: 1.4339191913604736
Validation loss: 2.1700029224157333

Epoch: 5| Step: 7
Training loss: 0.9549036026000977
Validation loss: 2.2113418579101562

Epoch: 5| Step: 8
Training loss: 1.0376166105270386
Validation loss: 2.1620338708162308

Epoch: 5| Step: 9
Training loss: 0.8860155344009399
Validation loss: 2.1129109263420105

Epoch: 5| Step: 10
Training loss: 1.1565673351287842
Validation loss: 2.1582687199115753

Epoch: 5| Step: 11
Training loss: 0.3761719763278961
Validation loss: 2.1783171594142914

Epoch: 458| Step: 0
Training loss: 1.0027590990066528
Validation loss: 2.2082682698965073

Epoch: 5| Step: 1
Training loss: 1.2184978723526
Validation loss: 2.202524190147718

Epoch: 5| Step: 2
Training loss: 0.8823223114013672
Validation loss: 2.217240701119105

Epoch: 5| Step: 3
Training loss: 0.8636748194694519
Validation loss: 2.184716115395228

Epoch: 5| Step: 4
Training loss: 1.7998268604278564
Validation loss: 2.168704887231191

Epoch: 5| Step: 5
Training loss: 0.7069694995880127
Validation loss: 2.2015894452730813

Epoch: 5| Step: 6
Training loss: 0.6546652317047119
Validation loss: 2.2168284505605698

Epoch: 5| Step: 7
Training loss: 1.3223711252212524
Validation loss: 2.206057235598564

Epoch: 5| Step: 8
Training loss: 0.9481633901596069
Validation loss: 2.2354306479295096

Epoch: 5| Step: 9
Training loss: 1.1247732639312744
Validation loss: 2.2303403168916702

Epoch: 5| Step: 10
Training loss: 1.1297805309295654
Validation loss: 2.22438275317351

Epoch: 5| Step: 11
Training loss: 2.1950738430023193
Validation loss: 2.2379284103711448

Epoch: 459| Step: 0
Training loss: 1.2455209493637085
Validation loss: 2.2048138479391732

Epoch: 5| Step: 1
Training loss: 1.4784278869628906
Validation loss: 2.172145719329516

Epoch: 5| Step: 2
Training loss: 1.1092064380645752
Validation loss: 2.1748702774445214

Epoch: 5| Step: 3
Training loss: 0.8983701467514038
Validation loss: 2.1824769427378974

Epoch: 5| Step: 4
Training loss: 1.0350195169448853
Validation loss: 2.1646000991264978

Epoch: 5| Step: 5
Training loss: 1.0586024522781372
Validation loss: 2.1500267336765924

Epoch: 5| Step: 6
Training loss: 0.567211925983429
Validation loss: 2.1548794507980347

Epoch: 5| Step: 7
Training loss: 0.4662397801876068
Validation loss: 2.1485333691040673

Epoch: 5| Step: 8
Training loss: 0.5110135078430176
Validation loss: 2.192825496196747

Epoch: 5| Step: 9
Training loss: 1.0080173015594482
Validation loss: 2.1870577732721963

Epoch: 5| Step: 10
Training loss: 2.0882568359375
Validation loss: 2.1842421193917594

Epoch: 5| Step: 11
Training loss: 0.5329199433326721
Validation loss: 2.1779663463433585

Epoch: 460| Step: 0
Training loss: 0.5350032448768616
Validation loss: 2.215407361586889

Epoch: 5| Step: 1
Training loss: 0.49937134981155396
Validation loss: 2.194570928812027

Epoch: 5| Step: 2
Training loss: 1.4119309186935425
Validation loss: 2.2414628714323044

Epoch: 5| Step: 3
Training loss: 0.8766187429428101
Validation loss: 2.2489661375681558

Epoch: 5| Step: 4
Training loss: 1.2361512184143066
Validation loss: 2.2444692850112915

Epoch: 5| Step: 5
Training loss: 1.0799171924591064
Validation loss: 2.271454930305481

Epoch: 5| Step: 6
Training loss: 1.5813775062561035
Validation loss: 2.203006406625112

Epoch: 5| Step: 7
Training loss: 1.310401201248169
Validation loss: 2.2491882344086966

Epoch: 5| Step: 8
Training loss: 0.8631909489631653
Validation loss: 2.238369027773539

Epoch: 5| Step: 9
Training loss: 0.8388509750366211
Validation loss: 2.2337107211351395

Epoch: 5| Step: 10
Training loss: 0.9430167078971863
Validation loss: 2.205404539903005

Epoch: 5| Step: 11
Training loss: 1.1889944076538086
Validation loss: 2.204476555188497

Epoch: 461| Step: 0
Training loss: 0.8542992472648621
Validation loss: 2.1952951898177466

Epoch: 5| Step: 1
Training loss: 0.6100173592567444
Validation loss: 2.2020466923713684

Epoch: 5| Step: 2
Training loss: 1.1655231714248657
Validation loss: 2.207929790019989

Epoch: 5| Step: 3
Training loss: 0.8954876065254211
Validation loss: 2.203838810324669

Epoch: 5| Step: 4
Training loss: 1.2927213907241821
Validation loss: 2.2205593486626944

Epoch: 5| Step: 5
Training loss: 0.9269648790359497
Validation loss: 2.2103552569945655

Epoch: 5| Step: 6
Training loss: 0.8495516777038574
Validation loss: 2.2242746502161026

Epoch: 5| Step: 7
Training loss: 0.8146656155586243
Validation loss: 2.1876765141884484

Epoch: 5| Step: 8
Training loss: 1.114537000656128
Validation loss: 2.212344542145729

Epoch: 5| Step: 9
Training loss: 1.6406629085540771
Validation loss: 2.1754546215136847

Epoch: 5| Step: 10
Training loss: 0.948832631111145
Validation loss: 2.22737517952919

Epoch: 5| Step: 11
Training loss: 0.3689497709274292
Validation loss: 2.256713400284449

Epoch: 462| Step: 0
Training loss: 1.022674322128296
Validation loss: 2.2354255517323813

Epoch: 5| Step: 1
Training loss: 1.061950922012329
Validation loss: 2.219514628251394

Epoch: 5| Step: 2
Training loss: 1.069786787033081
Validation loss: 2.2285491079092026

Epoch: 5| Step: 3
Training loss: 1.5087769031524658
Validation loss: 2.2446001718441644

Epoch: 5| Step: 4
Training loss: 1.0347694158554077
Validation loss: 2.232375125090281

Epoch: 5| Step: 5
Training loss: 0.7312471866607666
Validation loss: 2.1917811135450997

Epoch: 5| Step: 6
Training loss: 0.7663984298706055
Validation loss: 2.2000944217046103

Epoch: 5| Step: 7
Training loss: 1.3803811073303223
Validation loss: 2.2069816142320633

Epoch: 5| Step: 8
Training loss: 0.8049188852310181
Validation loss: 2.2294078717629113

Epoch: 5| Step: 9
Training loss: 1.2550594806671143
Validation loss: 2.2688292612632117

Epoch: 5| Step: 10
Training loss: 1.0704237222671509
Validation loss: 2.2189962516228356

Epoch: 5| Step: 11
Training loss: 0.8155285120010376
Validation loss: 2.2474812120199203

Epoch: 463| Step: 0
Training loss: 1.7047977447509766
Validation loss: 2.222786749402682

Epoch: 5| Step: 1
Training loss: 0.652563214302063
Validation loss: 2.234963725010554

Epoch: 5| Step: 2
Training loss: 1.261772871017456
Validation loss: 2.2251783510049186

Epoch: 5| Step: 3
Training loss: 1.0094490051269531
Validation loss: 2.2294346392154694

Epoch: 5| Step: 4
Training loss: 0.6505511999130249
Validation loss: 2.22193851073583

Epoch: 5| Step: 5
Training loss: 1.1610654592514038
Validation loss: 2.243586838245392

Epoch: 5| Step: 6
Training loss: 0.6005777716636658
Validation loss: 2.252701759338379

Epoch: 5| Step: 7
Training loss: 0.9711443185806274
Validation loss: 2.2269239326318107

Epoch: 5| Step: 8
Training loss: 1.128668189048767
Validation loss: 2.2199863294760385

Epoch: 5| Step: 9
Training loss: 1.213836431503296
Validation loss: 2.2077943086624146

Epoch: 5| Step: 10
Training loss: 0.9794213175773621
Validation loss: 2.2741968433062234

Epoch: 5| Step: 11
Training loss: 0.4512230455875397
Validation loss: 2.2301133821407952

Epoch: 464| Step: 0
Training loss: 0.8263040781021118
Validation loss: 2.2275726596514382

Epoch: 5| Step: 1
Training loss: 1.1314784288406372
Validation loss: 2.2027564893166223

Epoch: 5| Step: 2
Training loss: 0.8392351865768433
Validation loss: 2.2445286413033805

Epoch: 5| Step: 3
Training loss: 0.8843925595283508
Validation loss: 2.2084372341632843

Epoch: 5| Step: 4
Training loss: 1.22383713722229
Validation loss: 2.1883138169844947

Epoch: 5| Step: 5
Training loss: 1.1569726467132568
Validation loss: 2.1587358812491098

Epoch: 5| Step: 6
Training loss: 0.9583697319030762
Validation loss: 2.174762119849523

Epoch: 5| Step: 7
Training loss: 1.0659289360046387
Validation loss: 2.20506285627683

Epoch: 5| Step: 8
Training loss: 0.5848621129989624
Validation loss: 2.238210067152977

Epoch: 5| Step: 9
Training loss: 1.2192379236221313
Validation loss: 2.2351727982362113

Epoch: 5| Step: 10
Training loss: 1.315014362335205
Validation loss: 2.2243895332018533

Epoch: 5| Step: 11
Training loss: 0.3258037567138672
Validation loss: 2.2471097260713577

Epoch: 465| Step: 0
Training loss: 1.459195852279663
Validation loss: 2.216792161266009

Epoch: 5| Step: 1
Training loss: 0.6424631476402283
Validation loss: 2.2226339479287467

Epoch: 5| Step: 2
Training loss: 0.9514501690864563
Validation loss: 2.2246648569901786

Epoch: 5| Step: 3
Training loss: 1.1445465087890625
Validation loss: 2.226138403018316

Epoch: 5| Step: 4
Training loss: 1.1799269914627075
Validation loss: 2.205272823572159

Epoch: 5| Step: 5
Training loss: 0.7742577791213989
Validation loss: 2.2328277925650277

Epoch: 5| Step: 6
Training loss: 0.9945074915885925
Validation loss: 2.2192414154609046

Epoch: 5| Step: 7
Training loss: 1.3085353374481201
Validation loss: 2.1973224182923636

Epoch: 5| Step: 8
Training loss: 0.6330827474594116
Validation loss: 2.224673499663671

Epoch: 5| Step: 9
Training loss: 1.105588674545288
Validation loss: 2.1984346508979797

Epoch: 5| Step: 10
Training loss: 0.6950775384902954
Validation loss: 2.198176383972168

Epoch: 5| Step: 11
Training loss: 1.5465326309204102
Validation loss: 2.251509760816892

Epoch: 466| Step: 0
Training loss: 0.978329062461853
Validation loss: 2.2307167649269104

Epoch: 5| Step: 1
Training loss: 1.1481460332870483
Validation loss: 2.2222362061341605

Epoch: 5| Step: 2
Training loss: 1.3286230564117432
Validation loss: 2.2008661925792694

Epoch: 5| Step: 3
Training loss: 1.1092742681503296
Validation loss: 2.1975177029768624

Epoch: 5| Step: 4
Training loss: 1.058243989944458
Validation loss: 2.1525429089864097

Epoch: 5| Step: 5
Training loss: 0.9681304693222046
Validation loss: 2.177563468615214

Epoch: 5| Step: 6
Training loss: 0.9797004461288452
Validation loss: 2.165809909502665

Epoch: 5| Step: 7
Training loss: 1.1442348957061768
Validation loss: 2.208348880211512

Epoch: 5| Step: 8
Training loss: 0.971233069896698
Validation loss: 2.2113292465607324

Epoch: 5| Step: 9
Training loss: 1.3588910102844238
Validation loss: 2.234594871600469

Epoch: 5| Step: 10
Training loss: 1.019773006439209
Validation loss: 2.2147144774595895

Epoch: 5| Step: 11
Training loss: 0.6410907506942749
Validation loss: 2.207304726044337

Epoch: 467| Step: 0
Training loss: 1.132799744606018
Validation loss: 2.161823809146881

Epoch: 5| Step: 1
Training loss: 1.0391473770141602
Validation loss: 2.2109116911888123

Epoch: 5| Step: 2
Training loss: 1.4022948741912842
Validation loss: 2.204136162996292

Epoch: 5| Step: 3
Training loss: 1.3266783952713013
Validation loss: 2.22250297665596

Epoch: 5| Step: 4
Training loss: 1.0616499185562134
Validation loss: 2.2131450176239014

Epoch: 5| Step: 5
Training loss: 1.329716444015503
Validation loss: 2.202027608950933

Epoch: 5| Step: 6
Training loss: 0.918450653553009
Validation loss: 2.213730032245318

Epoch: 5| Step: 7
Training loss: 0.9104362726211548
Validation loss: 2.2181010246276855

Epoch: 5| Step: 8
Training loss: 0.7342966198921204
Validation loss: 2.1942817866802216

Epoch: 5| Step: 9
Training loss: 1.3244708776474
Validation loss: 2.225013807415962

Epoch: 5| Step: 10
Training loss: 0.7464680671691895
Validation loss: 2.2291390001773834

Epoch: 5| Step: 11
Training loss: 0.5125850439071655
Validation loss: 2.2306428998708725

Epoch: 468| Step: 0
Training loss: 0.9270952343940735
Validation loss: 2.2023585637410483

Epoch: 5| Step: 1
Training loss: 1.1337484121322632
Validation loss: 2.204878186186155

Epoch: 5| Step: 2
Training loss: 1.0455129146575928
Validation loss: 2.2155247628688812

Epoch: 5| Step: 3
Training loss: 0.9756697416305542
Validation loss: 2.2105720390876136

Epoch: 5| Step: 4
Training loss: 1.5821045637130737
Validation loss: 2.2236352811257043

Epoch: 5| Step: 5
Training loss: 1.2165254354476929
Validation loss: 2.224421739578247

Epoch: 5| Step: 6
Training loss: 0.8225771188735962
Validation loss: 2.2108357002337775

Epoch: 5| Step: 7
Training loss: 1.5704481601715088
Validation loss: 2.2034676571687064

Epoch: 5| Step: 8
Training loss: 0.6231180429458618
Validation loss: 2.279785990715027

Epoch: 5| Step: 9
Training loss: 0.5786818265914917
Validation loss: 2.2061249762773514

Epoch: 5| Step: 10
Training loss: 0.6423712968826294
Validation loss: 2.2089219292004905

Epoch: 5| Step: 11
Training loss: 1.067944884300232
Validation loss: 2.231953019897143

Epoch: 469| Step: 0
Training loss: 1.1824877262115479
Validation loss: 2.232502967119217

Epoch: 5| Step: 1
Training loss: 1.0263652801513672
Validation loss: 2.202526484926542

Epoch: 5| Step: 2
Training loss: 1.1306318044662476
Validation loss: 2.2179698248704276

Epoch: 5| Step: 3
Training loss: 1.0209484100341797
Validation loss: 2.2146947781244912

Epoch: 5| Step: 4
Training loss: 0.6454552412033081
Validation loss: 2.22859318057696

Epoch: 5| Step: 5
Training loss: 0.7594344019889832
Validation loss: 2.265070835749308

Epoch: 5| Step: 6
Training loss: 1.4323028326034546
Validation loss: 2.2259908616542816

Epoch: 5| Step: 7
Training loss: 0.6186370849609375
Validation loss: 2.194308797518412

Epoch: 5| Step: 8
Training loss: 0.9783817529678345
Validation loss: 2.2047727604707084

Epoch: 5| Step: 9
Training loss: 1.216317892074585
Validation loss: 2.1951377987861633

Epoch: 5| Step: 10
Training loss: 1.120275616645813
Validation loss: 2.207828631003698

Epoch: 5| Step: 11
Training loss: 0.6336336135864258
Validation loss: 2.1788049141565957

Epoch: 470| Step: 0
Training loss: 1.3060129880905151
Validation loss: 2.1952830056349435

Epoch: 5| Step: 1
Training loss: 1.2363905906677246
Validation loss: 2.2053293188412986

Epoch: 5| Step: 2
Training loss: 1.00994873046875
Validation loss: 2.187403683861097

Epoch: 5| Step: 3
Training loss: 0.8271127939224243
Validation loss: 2.1949317157268524

Epoch: 5| Step: 4
Training loss: 0.3746110200881958
Validation loss: 2.2203600853681564

Epoch: 5| Step: 5
Training loss: 1.1410763263702393
Validation loss: 2.2141466041405997

Epoch: 5| Step: 6
Training loss: 0.7977615594863892
Validation loss: 2.2442808151245117

Epoch: 5| Step: 7
Training loss: 1.3054659366607666
Validation loss: 2.1802664945522943

Epoch: 5| Step: 8
Training loss: 1.1637442111968994
Validation loss: 2.1809349805116653

Epoch: 5| Step: 9
Training loss: 0.9543501734733582
Validation loss: 2.1700574308633804

Epoch: 5| Step: 10
Training loss: 0.8561531901359558
Validation loss: 2.192881718277931

Epoch: 5| Step: 11
Training loss: 0.4679340124130249
Validation loss: 2.2098103364308677

Epoch: 471| Step: 0
Training loss: 1.3147671222686768
Validation loss: 2.2090574502944946

Epoch: 5| Step: 1
Training loss: 0.7553736567497253
Validation loss: 2.186119168996811

Epoch: 5| Step: 2
Training loss: 0.6470017433166504
Validation loss: 2.1932203620672226

Epoch: 5| Step: 3
Training loss: 1.1547150611877441
Validation loss: 2.191893771290779

Epoch: 5| Step: 4
Training loss: 0.5923777222633362
Validation loss: 2.2243174761533737

Epoch: 5| Step: 5
Training loss: 0.9082395434379578
Validation loss: 2.1971138268709183

Epoch: 5| Step: 6
Training loss: 1.5856494903564453
Validation loss: 2.2086619436740875

Epoch: 5| Step: 7
Training loss: 0.8233238458633423
Validation loss: 2.198160171508789

Epoch: 5| Step: 8
Training loss: 1.0939234495162964
Validation loss: 2.2138290951649346

Epoch: 5| Step: 9
Training loss: 0.5204471349716187
Validation loss: 2.2003156493107476

Epoch: 5| Step: 10
Training loss: 1.1053898334503174
Validation loss: 2.239218160510063

Epoch: 5| Step: 11
Training loss: 0.8618714809417725
Validation loss: 2.179276724656423

Epoch: 472| Step: 0
Training loss: 0.742695689201355
Validation loss: 2.2066410730282464

Epoch: 5| Step: 1
Training loss: 0.9778423309326172
Validation loss: 2.241390109062195

Epoch: 5| Step: 2
Training loss: 1.6127303838729858
Validation loss: 2.2415893971920013

Epoch: 5| Step: 3
Training loss: 0.5581141710281372
Validation loss: 2.217034543553988

Epoch: 5| Step: 4
Training loss: 0.473727285861969
Validation loss: 2.193964739640554

Epoch: 5| Step: 5
Training loss: 0.8112163543701172
Validation loss: 2.198561112085978

Epoch: 5| Step: 6
Training loss: 0.8743909001350403
Validation loss: 2.2263368666172028

Epoch: 5| Step: 7
Training loss: 1.3824485540390015
Validation loss: 2.2186509718497596

Epoch: 5| Step: 8
Training loss: 0.8095544576644897
Validation loss: 2.259402185678482

Epoch: 5| Step: 9
Training loss: 1.2792847156524658
Validation loss: 2.251031925280889

Epoch: 5| Step: 10
Training loss: 1.1450471878051758
Validation loss: 2.197959542274475

Epoch: 5| Step: 11
Training loss: 1.0376743078231812
Validation loss: 2.207838013768196

Epoch: 473| Step: 0
Training loss: 0.6970147490501404
Validation loss: 2.254382148385048

Epoch: 5| Step: 1
Training loss: 1.6862313747406006
Validation loss: 2.2065785030523934

Epoch: 5| Step: 2
Training loss: 0.9480272531509399
Validation loss: 2.259204387664795

Epoch: 5| Step: 3
Training loss: 1.0920841693878174
Validation loss: 2.230404327313105

Epoch: 5| Step: 4
Training loss: 0.6221684217453003
Validation loss: 2.2332278738419213

Epoch: 5| Step: 5
Training loss: 0.8090718984603882
Validation loss: 2.216255029042562

Epoch: 5| Step: 6
Training loss: 0.9506158828735352
Validation loss: 2.1424393902222314

Epoch: 5| Step: 7
Training loss: 1.2449241876602173
Validation loss: 2.1851665526628494

Epoch: 5| Step: 8
Training loss: 1.1320793628692627
Validation loss: 2.1170466442902884

Epoch: 5| Step: 9
Training loss: 1.3616039752960205
Validation loss: 2.1612962931394577

Epoch: 5| Step: 10
Training loss: 0.8535650968551636
Validation loss: 2.1581334322690964

Epoch: 5| Step: 11
Training loss: 0.33120840787887573
Validation loss: 2.160935918490092

Epoch: 474| Step: 0
Training loss: 1.2015533447265625
Validation loss: 2.1460696955521903

Epoch: 5| Step: 1
Training loss: 0.7884303331375122
Validation loss: 2.1594006766875586

Epoch: 5| Step: 2
Training loss: 1.6103723049163818
Validation loss: 2.160273492336273

Epoch: 5| Step: 3
Training loss: 1.1531504392623901
Validation loss: 2.1547491550445557

Epoch: 5| Step: 4
Training loss: 0.4800792634487152
Validation loss: 2.1972771982351937

Epoch: 5| Step: 5
Training loss: 0.7631557583808899
Validation loss: 2.226620743672053

Epoch: 5| Step: 6
Training loss: 1.732733130455017
Validation loss: 2.243992338577906

Epoch: 5| Step: 7
Training loss: 0.864119827747345
Validation loss: 2.213631734251976

Epoch: 5| Step: 8
Training loss: 0.5213757753372192
Validation loss: 2.2277140418688455

Epoch: 5| Step: 9
Training loss: 0.5832756161689758
Validation loss: 2.2129808266957602

Epoch: 5| Step: 10
Training loss: 1.447325348854065
Validation loss: 2.2217688461144767

Epoch: 5| Step: 11
Training loss: 1.3086175918579102
Validation loss: 2.2500389367341995

Epoch: 475| Step: 0
Training loss: 1.3561896085739136
Validation loss: 2.3029355009396872

Epoch: 5| Step: 1
Training loss: 0.820417582988739
Validation loss: 2.2654569894075394

Epoch: 5| Step: 2
Training loss: 0.8206766843795776
Validation loss: 2.192593882481257

Epoch: 5| Step: 3
Training loss: 1.1112862825393677
Validation loss: 2.113481526573499

Epoch: 5| Step: 4
Training loss: 1.1104531288146973
Validation loss: 2.168038308620453

Epoch: 5| Step: 5
Training loss: 1.3417041301727295
Validation loss: 2.1532278458277383

Epoch: 5| Step: 6
Training loss: 1.0871597528457642
Validation loss: 2.1820919513702393

Epoch: 5| Step: 7
Training loss: 1.2064251899719238
Validation loss: 2.169104903936386

Epoch: 5| Step: 8
Training loss: 1.7898709774017334
Validation loss: 2.177427018682162

Epoch: 5| Step: 9
Training loss: 0.8609734773635864
Validation loss: 2.187762518723806

Epoch: 5| Step: 10
Training loss: 1.024524450302124
Validation loss: 2.1707383692264557

Epoch: 5| Step: 11
Training loss: 0.674836277961731
Validation loss: 2.2026778558890023

Epoch: 476| Step: 0
Training loss: 1.5512758493423462
Validation loss: 2.1563746134440103

Epoch: 5| Step: 1
Training loss: 0.5694223642349243
Validation loss: 2.216107572118441

Epoch: 5| Step: 2
Training loss: 1.1202337741851807
Validation loss: 2.2303266127904258

Epoch: 5| Step: 3
Training loss: 0.9389788508415222
Validation loss: 2.1687574485937753

Epoch: 5| Step: 4
Training loss: 0.8271873593330383
Validation loss: 2.173950026432673

Epoch: 5| Step: 5
Training loss: 0.6274590492248535
Validation loss: 2.1807500223318734

Epoch: 5| Step: 6
Training loss: 1.4532294273376465
Validation loss: 2.193410724401474

Epoch: 5| Step: 7
Training loss: 0.9778599739074707
Validation loss: 2.199915736913681

Epoch: 5| Step: 8
Training loss: 0.9998222589492798
Validation loss: 2.17918868859609

Epoch: 5| Step: 9
Training loss: 0.5494914650917053
Validation loss: 2.182250296076139

Epoch: 5| Step: 10
Training loss: 1.7864172458648682
Validation loss: 2.2365309794743857

Epoch: 5| Step: 11
Training loss: 1.0226470232009888
Validation loss: 2.1943145791689553

Epoch: 477| Step: 0
Training loss: 1.181985855102539
Validation loss: 2.204291249314944

Epoch: 5| Step: 1
Training loss: 1.3549247980117798
Validation loss: 2.200115899244944

Epoch: 5| Step: 2
Training loss: 1.1166174411773682
Validation loss: 2.164371599753698

Epoch: 5| Step: 3
Training loss: 0.841846764087677
Validation loss: 2.1520287096500397

Epoch: 5| Step: 4
Training loss: 0.6665470004081726
Validation loss: 2.1873921751976013

Epoch: 5| Step: 5
Training loss: 1.1516978740692139
Validation loss: 2.135566090544065

Epoch: 5| Step: 6
Training loss: 0.7856132388114929
Validation loss: 2.196233337124189

Epoch: 5| Step: 7
Training loss: 0.9618996381759644
Validation loss: 2.176549961169561

Epoch: 5| Step: 8
Training loss: 0.8033348321914673
Validation loss: 2.17885322868824

Epoch: 5| Step: 9
Training loss: 0.7891098260879517
Validation loss: 2.197959154844284

Epoch: 5| Step: 10
Training loss: 1.2338991165161133
Validation loss: 2.191173975666364

Epoch: 5| Step: 11
Training loss: 0.964194118976593
Validation loss: 2.219981794555982

Epoch: 478| Step: 0
Training loss: 0.5833175778388977
Validation loss: 2.1732628792524338

Epoch: 5| Step: 1
Training loss: 1.0443350076675415
Validation loss: 2.1965174873669944

Epoch: 5| Step: 2
Training loss: 0.9413851499557495
Validation loss: 2.223387991388639

Epoch: 5| Step: 3
Training loss: 1.035888910293579
Validation loss: 2.1923194179932275

Epoch: 5| Step: 4
Training loss: 1.5511773824691772
Validation loss: 2.228460599978765

Epoch: 5| Step: 5
Training loss: 1.2481389045715332
Validation loss: 2.1858196556568146

Epoch: 5| Step: 6
Training loss: 0.8824771642684937
Validation loss: 2.2270174523194632

Epoch: 5| Step: 7
Training loss: 0.9864993095397949
Validation loss: 2.2035349110762277

Epoch: 5| Step: 8
Training loss: 1.0544558763504028
Validation loss: 2.195134381453196

Epoch: 5| Step: 9
Training loss: 0.6838610768318176
Validation loss: 2.1797225773334503

Epoch: 5| Step: 10
Training loss: 0.9252975583076477
Validation loss: 2.165778716405233

Epoch: 5| Step: 11
Training loss: 0.25942516326904297
Validation loss: 2.2099397281805673

Epoch: 479| Step: 0
Training loss: 1.5586456060409546
Validation loss: 2.209874947865804

Epoch: 5| Step: 1
Training loss: 1.094551682472229
Validation loss: 2.223250687122345

Epoch: 5| Step: 2
Training loss: 1.358608603477478
Validation loss: 2.255204831560453

Epoch: 5| Step: 3
Training loss: 1.0235650539398193
Validation loss: 2.2474181006352105

Epoch: 5| Step: 4
Training loss: 1.4336845874786377
Validation loss: 2.236035500963529

Epoch: 5| Step: 5
Training loss: 0.8255214691162109
Validation loss: 2.217554733157158

Epoch: 5| Step: 6
Training loss: 0.9401151537895203
Validation loss: 2.1837196300427117

Epoch: 5| Step: 7
Training loss: 0.7216175198554993
Validation loss: 2.2321769694487252

Epoch: 5| Step: 8
Training loss: 0.7160481214523315
Validation loss: 2.2153491278489432

Epoch: 5| Step: 9
Training loss: 0.8542512059211731
Validation loss: 2.2188772509495416

Epoch: 5| Step: 10
Training loss: 0.9226659536361694
Validation loss: 2.206192667285601

Epoch: 5| Step: 11
Training loss: 0.6154403686523438
Validation loss: 2.2014489471912384

Epoch: 480| Step: 0
Training loss: 1.0559463500976562
Validation loss: 2.2239317496617637

Epoch: 5| Step: 1
Training loss: 0.7408570647239685
Validation loss: 2.217734004060427

Epoch: 5| Step: 2
Training loss: 1.7104886770248413
Validation loss: 2.1664861689011254

Epoch: 5| Step: 3
Training loss: 0.9129835963249207
Validation loss: 2.149940182765325

Epoch: 5| Step: 4
Training loss: 0.953177273273468
Validation loss: 2.1569159726301828

Epoch: 5| Step: 5
Training loss: 1.2331150770187378
Validation loss: 2.161179612080256

Epoch: 5| Step: 6
Training loss: 1.1537301540374756
Validation loss: 2.1650174955526986

Epoch: 5| Step: 7
Training loss: 0.696162223815918
Validation loss: 2.141704852382342

Epoch: 5| Step: 8
Training loss: 0.7244571447372437
Validation loss: 2.1840723852316537

Epoch: 5| Step: 9
Training loss: 0.5764161348342896
Validation loss: 2.1743190536896386

Epoch: 5| Step: 10
Training loss: 1.1337206363677979
Validation loss: 2.161079173286756

Epoch: 5| Step: 11
Training loss: 0.3242114782333374
Validation loss: 2.126665845513344

Epoch: 481| Step: 0
Training loss: 0.9648863077163696
Validation loss: 2.2083888947963715

Epoch: 5| Step: 1
Training loss: 0.31018370389938354
Validation loss: 2.169146806001663

Epoch: 5| Step: 2
Training loss: 0.9037551879882812
Validation loss: 2.1611877779165902

Epoch: 5| Step: 3
Training loss: 0.8826079368591309
Validation loss: 2.1776338120301566

Epoch: 5| Step: 4
Training loss: 0.961382269859314
Validation loss: 2.160316581527392

Epoch: 5| Step: 5
Training loss: 1.5116631984710693
Validation loss: 2.148919632037481

Epoch: 5| Step: 6
Training loss: 0.831752598285675
Validation loss: 2.126678536335627

Epoch: 5| Step: 7
Training loss: 1.1437010765075684
Validation loss: 2.164451385537783

Epoch: 5| Step: 8
Training loss: 0.9937040209770203
Validation loss: 2.1952143013477325

Epoch: 5| Step: 9
Training loss: 1.326393723487854
Validation loss: 2.177156796058019

Epoch: 5| Step: 10
Training loss: 0.961919903755188
Validation loss: 2.162234013279279

Epoch: 5| Step: 11
Training loss: 0.5457977056503296
Validation loss: 2.1550754010677338

Epoch: 482| Step: 0
Training loss: 1.0494346618652344
Validation loss: 2.1532502522071204

Epoch: 5| Step: 1
Training loss: 0.9039714932441711
Validation loss: 2.1922256648540497

Epoch: 5| Step: 2
Training loss: 1.041212797164917
Validation loss: 2.1760252912839255

Epoch: 5| Step: 3
Training loss: 0.8178451657295227
Validation loss: 2.218713710705439

Epoch: 5| Step: 4
Training loss: 1.155706763267517
Validation loss: 2.2010059456030526

Epoch: 5| Step: 5
Training loss: 1.158212423324585
Validation loss: 2.161911427974701

Epoch: 5| Step: 6
Training loss: 0.7440763711929321
Validation loss: 2.1818880289793015

Epoch: 5| Step: 7
Training loss: 1.198162317276001
Validation loss: 2.18165951470534

Epoch: 5| Step: 8
Training loss: 0.7319705486297607
Validation loss: 2.2018649578094482

Epoch: 5| Step: 9
Training loss: 0.7902307510375977
Validation loss: 2.21372988820076

Epoch: 5| Step: 10
Training loss: 0.6234696507453918
Validation loss: 2.2100812594095864

Epoch: 5| Step: 11
Training loss: 0.9610620141029358
Validation loss: 2.2488816181818643

Epoch: 483| Step: 0
Training loss: 1.1255245208740234
Validation loss: 2.2512559493382773

Epoch: 5| Step: 1
Training loss: 0.3871627449989319
Validation loss: 2.257478584845861

Epoch: 5| Step: 2
Training loss: 0.9203518033027649
Validation loss: 2.2183570762475333

Epoch: 5| Step: 3
Training loss: 1.6607811450958252
Validation loss: 2.266762852668762

Epoch: 5| Step: 4
Training loss: 0.9254987835884094
Validation loss: 2.260432710250219

Epoch: 5| Step: 5
Training loss: 1.1075599193572998
Validation loss: 2.224299838145574

Epoch: 5| Step: 6
Training loss: 0.6481561660766602
Validation loss: 2.2013760755459466

Epoch: 5| Step: 7
Training loss: 0.764998733997345
Validation loss: 2.258782282471657

Epoch: 5| Step: 8
Training loss: 0.6020972728729248
Validation loss: 2.1938144316275916

Epoch: 5| Step: 9
Training loss: 1.2192846536636353
Validation loss: 2.238823672135671

Epoch: 5| Step: 10
Training loss: 1.0337631702423096
Validation loss: 2.234555870294571

Epoch: 5| Step: 11
Training loss: 0.5844850540161133
Validation loss: 2.1959281116724014

Epoch: 484| Step: 0
Training loss: 1.1355092525482178
Validation loss: 2.2077688376108804

Epoch: 5| Step: 1
Training loss: 1.066636085510254
Validation loss: 2.191099395354589

Epoch: 5| Step: 2
Training loss: 0.7337113618850708
Validation loss: 2.193487599492073

Epoch: 5| Step: 3
Training loss: 0.9546744227409363
Validation loss: 2.2273482332626977

Epoch: 5| Step: 4
Training loss: 1.027742624282837
Validation loss: 2.221803605556488

Epoch: 5| Step: 5
Training loss: 1.1073516607284546
Validation loss: 2.203204393386841

Epoch: 5| Step: 6
Training loss: 0.8797370791435242
Validation loss: 2.2262489845355353

Epoch: 5| Step: 7
Training loss: 0.6548394560813904
Validation loss: 2.208824709057808

Epoch: 5| Step: 8
Training loss: 0.9795118570327759
Validation loss: 2.247206538915634

Epoch: 5| Step: 9
Training loss: 0.774300754070282
Validation loss: 2.233019933104515

Epoch: 5| Step: 10
Training loss: 1.0853431224822998
Validation loss: 2.2122132182121277

Epoch: 5| Step: 11
Training loss: 0.8024981021881104
Validation loss: 2.200712352991104

Epoch: 485| Step: 0
Training loss: 0.8211660385131836
Validation loss: 2.199804430206617

Epoch: 5| Step: 1
Training loss: 1.3778355121612549
Validation loss: 2.231650079290072

Epoch: 5| Step: 2
Training loss: 0.9150808453559875
Validation loss: 2.229280322790146

Epoch: 5| Step: 3
Training loss: 1.7777427434921265
Validation loss: 2.207635447382927

Epoch: 5| Step: 4
Training loss: 0.7066667079925537
Validation loss: 2.208859552939733

Epoch: 5| Step: 5
Training loss: 0.800416111946106
Validation loss: 2.1963371137777963

Epoch: 5| Step: 6
Training loss: 0.9932641983032227
Validation loss: 2.2007541209459305

Epoch: 5| Step: 7
Training loss: 0.8221510648727417
Validation loss: 2.165892720222473

Epoch: 5| Step: 8
Training loss: 0.7739407420158386
Validation loss: 2.155047446489334

Epoch: 5| Step: 9
Training loss: 0.8052467107772827
Validation loss: 2.1261936674515405

Epoch: 5| Step: 10
Training loss: 0.7208395004272461
Validation loss: 2.1397414058446884

Epoch: 5| Step: 11
Training loss: 0.16636979579925537
Validation loss: 2.1827480494976044

Epoch: 486| Step: 0
Training loss: 0.7805696129798889
Validation loss: 2.123819425702095

Epoch: 5| Step: 1
Training loss: 0.6792492866516113
Validation loss: 2.192428842186928

Epoch: 5| Step: 2
Training loss: 1.4221280813217163
Validation loss: 2.2199853907028833

Epoch: 5| Step: 3
Training loss: 1.4827325344085693
Validation loss: 2.220813895265261

Epoch: 5| Step: 4
Training loss: 1.3905532360076904
Validation loss: 2.222729136546453

Epoch: 5| Step: 5
Training loss: 0.4490128457546234
Validation loss: 2.183273434638977

Epoch: 5| Step: 6
Training loss: 0.8751460909843445
Validation loss: 2.135274479786555

Epoch: 5| Step: 7
Training loss: 0.6465648412704468
Validation loss: 2.152734021345774

Epoch: 5| Step: 8
Training loss: 0.7588372826576233
Validation loss: 2.135710825522741

Epoch: 5| Step: 9
Training loss: 1.6877152919769287
Validation loss: 2.148766428232193

Epoch: 5| Step: 10
Training loss: 0.9448364973068237
Validation loss: 2.1868332475423813

Epoch: 5| Step: 11
Training loss: 0.630427360534668
Validation loss: 2.199567755063375

Epoch: 487| Step: 0
Training loss: 0.7981356382369995
Validation loss: 2.1729227801163993

Epoch: 5| Step: 1
Training loss: 0.5359277725219727
Validation loss: 2.187294622262319

Epoch: 5| Step: 2
Training loss: 1.5955419540405273
Validation loss: 2.2245261470476785

Epoch: 5| Step: 3
Training loss: 1.0454317331314087
Validation loss: 2.2753871083259583

Epoch: 5| Step: 4
Training loss: 1.0890119075775146
Validation loss: 2.250663712620735

Epoch: 5| Step: 5
Training loss: 1.7557109594345093
Validation loss: 2.2735837350289025

Epoch: 5| Step: 6
Training loss: 0.9640074968338013
Validation loss: 2.2401671459277472

Epoch: 5| Step: 7
Training loss: 0.8395580053329468
Validation loss: 2.217736075321833

Epoch: 5| Step: 8
Training loss: 0.9671934247016907
Validation loss: 2.242157980799675

Epoch: 5| Step: 9
Training loss: 0.6780902147293091
Validation loss: 2.2029752085606256

Epoch: 5| Step: 10
Training loss: 0.8558513522148132
Validation loss: 2.2036464512348175

Epoch: 5| Step: 11
Training loss: 1.9250906705856323
Validation loss: 2.1986173590024314

Epoch: 488| Step: 0
Training loss: 0.7333873510360718
Validation loss: 2.1975554078817368

Epoch: 5| Step: 1
Training loss: 0.6815561056137085
Validation loss: 2.187360222140948

Epoch: 5| Step: 2
Training loss: 0.8556302189826965
Validation loss: 2.2345463236172995

Epoch: 5| Step: 3
Training loss: 0.7508529424667358
Validation loss: 2.232892870903015

Epoch: 5| Step: 4
Training loss: 0.8107028007507324
Validation loss: 2.2746755282084146

Epoch: 5| Step: 5
Training loss: 1.1821166276931763
Validation loss: 2.262293189764023

Epoch: 5| Step: 6
Training loss: 1.1074684858322144
Validation loss: 2.244530518849691

Epoch: 5| Step: 7
Training loss: 0.6707066297531128
Validation loss: 2.2192862878243127

Epoch: 5| Step: 8
Training loss: 1.055588722229004
Validation loss: 2.2505397498607635

Epoch: 5| Step: 9
Training loss: 1.5920140743255615
Validation loss: 2.230161959926287

Epoch: 5| Step: 10
Training loss: 0.9601980447769165
Validation loss: 2.210358257095019

Epoch: 5| Step: 11
Training loss: 0.33851736783981323
Validation loss: 2.234719177087148

Epoch: 489| Step: 0
Training loss: 1.0532610416412354
Validation loss: 2.270295590162277

Epoch: 5| Step: 1
Training loss: 0.9948307275772095
Validation loss: 2.1936449458201728

Epoch: 5| Step: 2
Training loss: 1.1723216772079468
Validation loss: 2.2096508045991263

Epoch: 5| Step: 3
Training loss: 0.9275776147842407
Validation loss: 2.163577670852343

Epoch: 5| Step: 4
Training loss: 0.856264591217041
Validation loss: 2.2198487520217896

Epoch: 5| Step: 5
Training loss: 0.9852985143661499
Validation loss: 2.195493762691816

Epoch: 5| Step: 6
Training loss: 0.9245058298110962
Validation loss: 2.2089184721310935

Epoch: 5| Step: 7
Training loss: 1.2097760438919067
Validation loss: 2.180677910645803

Epoch: 5| Step: 8
Training loss: 0.7186040282249451
Validation loss: 2.197704474131266

Epoch: 5| Step: 9
Training loss: 0.4358108639717102
Validation loss: 2.2008288304011026

Epoch: 5| Step: 10
Training loss: 0.6970020532608032
Validation loss: 2.14176037410895

Epoch: 5| Step: 11
Training loss: 0.8801579475402832
Validation loss: 2.174042468269666

Epoch: 490| Step: 0
Training loss: 0.6864973306655884
Validation loss: 2.1953972528378167

Epoch: 5| Step: 1
Training loss: 1.644020438194275
Validation loss: 2.189561719695727

Epoch: 5| Step: 2
Training loss: 0.3958803415298462
Validation loss: 2.198134496808052

Epoch: 5| Step: 3
Training loss: 0.8071322441101074
Validation loss: 2.183942904074987

Epoch: 5| Step: 4
Training loss: 0.9480211138725281
Validation loss: 2.1861156274875007

Epoch: 5| Step: 5
Training loss: 0.9808637499809265
Validation loss: 2.1967280209064484

Epoch: 5| Step: 6
Training loss: 1.324965000152588
Validation loss: 2.167390982309977

Epoch: 5| Step: 7
Training loss: 0.8009201884269714
Validation loss: 2.187772666414579

Epoch: 5| Step: 8
Training loss: 1.1327617168426514
Validation loss: 2.2133141309022903

Epoch: 5| Step: 9
Training loss: 0.9114801287651062
Validation loss: 2.1915122667948403

Epoch: 5| Step: 10
Training loss: 0.5854171514511108
Validation loss: 2.2207166800896325

Epoch: 5| Step: 11
Training loss: 0.5684006810188293
Validation loss: 2.198601648211479

Epoch: 491| Step: 0
Training loss: 0.4478536546230316
Validation loss: 2.1832014669974646

Epoch: 5| Step: 1
Training loss: 0.801411509513855
Validation loss: 2.223936304450035

Epoch: 5| Step: 2
Training loss: 1.023317813873291
Validation loss: 2.2541804810365043

Epoch: 5| Step: 3
Training loss: 1.3157106637954712
Validation loss: 2.2737158834934235

Epoch: 5| Step: 4
Training loss: 1.370994210243225
Validation loss: 2.2579867243766785

Epoch: 5| Step: 5
Training loss: 0.9432998895645142
Validation loss: 2.2512870083252587

Epoch: 5| Step: 6
Training loss: 1.0026342868804932
Validation loss: 2.2210088620583215

Epoch: 5| Step: 7
Training loss: 1.244299292564392
Validation loss: 2.217509835958481

Epoch: 5| Step: 8
Training loss: 0.8419471979141235
Validation loss: 2.212302635113398

Epoch: 5| Step: 9
Training loss: 0.653872013092041
Validation loss: 2.254591554403305

Epoch: 5| Step: 10
Training loss: 1.0732715129852295
Validation loss: 2.239278420805931

Epoch: 5| Step: 11
Training loss: 0.39686015248298645
Validation loss: 2.191581755876541

Epoch: 492| Step: 0
Training loss: 1.3419982194900513
Validation loss: 2.1751274913549423

Epoch: 5| Step: 1
Training loss: 0.7533219456672668
Validation loss: 2.22016433874766

Epoch: 5| Step: 2
Training loss: 0.6955345273017883
Validation loss: 2.1816007594267526

Epoch: 5| Step: 3
Training loss: 0.6051121950149536
Validation loss: 2.1973197807868323

Epoch: 5| Step: 4
Training loss: 0.7069956660270691
Validation loss: 2.2285494108994803

Epoch: 5| Step: 5
Training loss: 1.1079870462417603
Validation loss: 2.2173344492912292

Epoch: 5| Step: 6
Training loss: 0.745097279548645
Validation loss: 2.2362908025582633

Epoch: 5| Step: 7
Training loss: 1.162566900253296
Validation loss: 2.2262790699799857

Epoch: 5| Step: 8
Training loss: 0.6816315650939941
Validation loss: 2.2125615378220878

Epoch: 5| Step: 9
Training loss: 0.9433355331420898
Validation loss: 2.2158282101154327

Epoch: 5| Step: 10
Training loss: 1.332237958908081
Validation loss: 2.182305465141932

Epoch: 5| Step: 11
Training loss: 0.5648090839385986
Validation loss: 2.199931969245275

Epoch: 493| Step: 0
Training loss: 1.5976953506469727
Validation loss: 2.218711718916893

Epoch: 5| Step: 1
Training loss: 0.600429356098175
Validation loss: 2.2568975687026978

Epoch: 5| Step: 2
Training loss: 1.2655837535858154
Validation loss: 2.2774642507235208

Epoch: 5| Step: 3
Training loss: 1.1839425563812256
Validation loss: 2.2642585188150406

Epoch: 5| Step: 4
Training loss: 1.104871392250061
Validation loss: 2.2452552219231925

Epoch: 5| Step: 5
Training loss: 0.824724018573761
Validation loss: 2.2066969871520996

Epoch: 5| Step: 6
Training loss: 1.4169633388519287
Validation loss: 2.2172479728857675

Epoch: 5| Step: 7
Training loss: 1.4218404293060303
Validation loss: 2.2088667502005896

Epoch: 5| Step: 8
Training loss: 0.5044817328453064
Validation loss: 2.2426211337248483

Epoch: 5| Step: 9
Training loss: 0.4972921311855316
Validation loss: 2.224635591109594

Epoch: 5| Step: 10
Training loss: 0.955862820148468
Validation loss: 2.26023722688357

Epoch: 5| Step: 11
Training loss: 0.563443660736084
Validation loss: 2.254785880446434

Epoch: 494| Step: 0
Training loss: 0.7181710004806519
Validation loss: 2.202770675222079

Epoch: 5| Step: 1
Training loss: 0.6561900973320007
Validation loss: 2.223533237973849

Epoch: 5| Step: 2
Training loss: 0.7863930463790894
Validation loss: 2.244622270266215

Epoch: 5| Step: 3
Training loss: 1.28298819065094
Validation loss: 2.318049261967341

Epoch: 5| Step: 4
Training loss: 0.7187260389328003
Validation loss: 2.293555329243342

Epoch: 5| Step: 5
Training loss: 1.2096731662750244
Validation loss: 2.3087347745895386

Epoch: 5| Step: 6
Training loss: 1.1339898109436035
Validation loss: 2.224182645479838

Epoch: 5| Step: 7
Training loss: 0.7059357166290283
Validation loss: 2.243484059969584

Epoch: 5| Step: 8
Training loss: 0.6670770049095154
Validation loss: 2.1576767017443976

Epoch: 5| Step: 9
Training loss: 0.9725562334060669
Validation loss: 2.1784227192401886

Epoch: 5| Step: 10
Training loss: 2.1371912956237793
Validation loss: 2.225399206082026

Epoch: 5| Step: 11
Training loss: 0.5075443387031555
Validation loss: 2.226942072312037

Epoch: 495| Step: 0
Training loss: 1.6784770488739014
Validation loss: 2.2020243108272552

Epoch: 5| Step: 1
Training loss: 0.5399931073188782
Validation loss: 2.207724452018738

Epoch: 5| Step: 2
Training loss: 1.097743034362793
Validation loss: 2.2315943042437234

Epoch: 5| Step: 3
Training loss: 0.7369982600212097
Validation loss: 2.2405164937178292

Epoch: 5| Step: 4
Training loss: 1.160414457321167
Validation loss: 2.2211500108242035

Epoch: 5| Step: 5
Training loss: 0.770748496055603
Validation loss: 2.224667181571325

Epoch: 5| Step: 6
Training loss: 0.7357214093208313
Validation loss: 2.2220835089683533

Epoch: 5| Step: 7
Training loss: 0.41441383957862854
Validation loss: 2.2125321477651596

Epoch: 5| Step: 8
Training loss: 1.4229004383087158
Validation loss: 2.2038601487874985

Epoch: 5| Step: 9
Training loss: 0.810342013835907
Validation loss: 2.2003496289253235

Epoch: 5| Step: 10
Training loss: 1.1326830387115479
Validation loss: 2.2143898804982505

Epoch: 5| Step: 11
Training loss: 0.808337926864624
Validation loss: 2.2156556646029153

Epoch: 496| Step: 0
Training loss: 0.6534336805343628
Validation loss: 2.191956107815107

Epoch: 5| Step: 1
Training loss: 1.4951322078704834
Validation loss: 2.208397130171458

Epoch: 5| Step: 2
Training loss: 0.7769904136657715
Validation loss: 2.2029208491245904

Epoch: 5| Step: 3
Training loss: 0.8340345621109009
Validation loss: 2.229315718015035

Epoch: 5| Step: 4
Training loss: 1.526192545890808
Validation loss: 2.222468356291453

Epoch: 5| Step: 5
Training loss: 0.8138583302497864
Validation loss: 2.2382263988256454

Epoch: 5| Step: 6
Training loss: 1.2692015171051025
Validation loss: 2.176590710878372

Epoch: 5| Step: 7
Training loss: 0.8855142593383789
Validation loss: 2.2178091009457908

Epoch: 5| Step: 8
Training loss: 0.6801339387893677
Validation loss: 2.2113013863563538

Epoch: 5| Step: 9
Training loss: 0.5037615895271301
Validation loss: 2.228189026316007

Epoch: 5| Step: 10
Training loss: 0.7511908411979675
Validation loss: 2.21240663031737

Epoch: 5| Step: 11
Training loss: 0.1653137505054474
Validation loss: 2.213569129506747

Epoch: 497| Step: 0
Training loss: 0.8345716595649719
Validation loss: 2.236822177966436

Epoch: 5| Step: 1
Training loss: 0.48220497369766235
Validation loss: 2.223626265923182

Epoch: 5| Step: 2
Training loss: 1.4129455089569092
Validation loss: 2.1910133560498557

Epoch: 5| Step: 3
Training loss: 0.8304710388183594
Validation loss: 2.2485186656316123

Epoch: 5| Step: 4
Training loss: 0.8565943837165833
Validation loss: 2.209964483976364

Epoch: 5| Step: 5
Training loss: 0.8192670941352844
Validation loss: 2.2118157148361206

Epoch: 5| Step: 6
Training loss: 1.3517975807189941
Validation loss: 2.176068440079689

Epoch: 5| Step: 7
Training loss: 0.9696987271308899
Validation loss: 2.2082057942946753

Epoch: 5| Step: 8
Training loss: 0.9479215741157532
Validation loss: 2.1959441900253296

Epoch: 5| Step: 9
Training loss: 1.0766022205352783
Validation loss: 2.1819922675689063

Epoch: 5| Step: 10
Training loss: 0.6992584466934204
Validation loss: 2.1894202530384064

Epoch: 5| Step: 11
Training loss: 0.402074933052063
Validation loss: 2.1989772965510688

Epoch: 498| Step: 0
Training loss: 0.8052405118942261
Validation loss: 2.1981658339500427

Epoch: 5| Step: 1
Training loss: 0.8078632354736328
Validation loss: 2.1843940814336142

Epoch: 5| Step: 2
Training loss: 0.829171359539032
Validation loss: 2.175134306152662

Epoch: 5| Step: 3
Training loss: 0.8950937986373901
Validation loss: 2.139424443244934

Epoch: 5| Step: 4
Training loss: 0.9799005389213562
Validation loss: 2.1727982511123023

Epoch: 5| Step: 5
Training loss: 0.9165693521499634
Validation loss: 2.1517340540885925

Epoch: 5| Step: 6
Training loss: 1.2318519353866577
Validation loss: 2.1644302159547806

Epoch: 5| Step: 7
Training loss: 0.9357696771621704
Validation loss: 2.1900969594717026

Epoch: 5| Step: 8
Training loss: 0.8982561230659485
Validation loss: 2.158418004711469

Epoch: 5| Step: 9
Training loss: 0.8413122892379761
Validation loss: 2.2004344860712686

Epoch: 5| Step: 10
Training loss: 1.080532431602478
Validation loss: 2.1740490943193436

Epoch: 5| Step: 11
Training loss: 0.9663932919502258
Validation loss: 2.203871895869573

Epoch: 499| Step: 0
Training loss: 1.2360610961914062
Validation loss: 2.2228757043679557

Epoch: 5| Step: 1
Training loss: 0.47324761748313904
Validation loss: 2.1868120282888412

Epoch: 5| Step: 2
Training loss: 1.1877018213272095
Validation loss: 2.2103881537914276

Epoch: 5| Step: 3
Training loss: 0.830230712890625
Validation loss: 2.16523448129495

Epoch: 5| Step: 4
Training loss: 0.6855125427246094
Validation loss: 2.147851179043452

Epoch: 5| Step: 5
Training loss: 0.6318343877792358
Validation loss: 2.1747659047444663

Epoch: 5| Step: 6
Training loss: 0.7791866064071655
Validation loss: 2.234337329864502

Epoch: 5| Step: 7
Training loss: 1.4842071533203125
Validation loss: 2.2341827849547067

Epoch: 5| Step: 8
Training loss: 0.8723090887069702
Validation loss: 2.2057502567768097

Epoch: 5| Step: 9
Training loss: 0.9328233003616333
Validation loss: 2.194486603140831

Epoch: 5| Step: 10
Training loss: 0.9786034822463989
Validation loss: 2.2503328025341034

Epoch: 5| Step: 11
Training loss: 0.5058077573776245
Validation loss: 2.2106029788653054

Epoch: 500| Step: 0
Training loss: 0.7570966482162476
Validation loss: 2.210821201403936

Epoch: 5| Step: 1
Training loss: 0.7941768765449524
Validation loss: 2.221256504456202

Epoch: 5| Step: 2
Training loss: 1.6868711709976196
Validation loss: 2.2851883421341577

Epoch: 5| Step: 3
Training loss: 1.224156379699707
Validation loss: 2.296389569838842

Epoch: 5| Step: 4
Training loss: 0.7851139903068542
Validation loss: 2.273924340804418

Epoch: 5| Step: 5
Training loss: 0.7549068927764893
Validation loss: 2.2629856566588082

Epoch: 5| Step: 6
Training loss: 0.49987974762916565
Validation loss: 2.2673386335372925

Epoch: 5| Step: 7
Training loss: 0.9205147624015808
Validation loss: 2.296370113889376

Epoch: 5| Step: 8
Training loss: 1.0104297399520874
Validation loss: 2.2609151899814606

Epoch: 5| Step: 9
Training loss: 0.6967418789863586
Validation loss: 2.3026888271172843

Epoch: 5| Step: 10
Training loss: 0.7788485288619995
Validation loss: 2.215398093064626

Epoch: 5| Step: 11
Training loss: 1.00697922706604
Validation loss: 2.2310018241405487

Epoch: 501| Step: 0
Training loss: 1.0663058757781982
Validation loss: 2.2512086729208627

Epoch: 5| Step: 1
Training loss: 0.9560993313789368
Validation loss: 2.218167250355085

Epoch: 5| Step: 2
Training loss: 0.7922683954238892
Validation loss: 2.1917771200339

Epoch: 5| Step: 3
Training loss: 0.5596938133239746
Validation loss: 2.2239070187012353

Epoch: 5| Step: 4
Training loss: 1.1086939573287964
Validation loss: 2.166038562854131

Epoch: 5| Step: 5
Training loss: 0.6410616040229797
Validation loss: 2.185216118892034

Epoch: 5| Step: 6
Training loss: 0.8500170707702637
Validation loss: 2.162352999051412

Epoch: 5| Step: 7
Training loss: 1.3345236778259277
Validation loss: 2.155828962723414

Epoch: 5| Step: 8
Training loss: 1.0096826553344727
Validation loss: 2.1923391222953796

Epoch: 5| Step: 9
Training loss: 0.5224183797836304
Validation loss: 2.1927433411280313

Epoch: 5| Step: 10
Training loss: 1.0929875373840332
Validation loss: 2.235730528831482

Epoch: 5| Step: 11
Training loss: 0.7757886648178101
Validation loss: 2.230105688174566

Epoch: 502| Step: 0
Training loss: 0.6322027444839478
Validation loss: 2.2357295056184134

Epoch: 5| Step: 1
Training loss: 0.5044144988059998
Validation loss: 2.2354924579461417

Epoch: 5| Step: 2
Training loss: 1.6471846103668213
Validation loss: 2.236249342560768

Epoch: 5| Step: 3
Training loss: 0.8987205624580383
Validation loss: 2.249783327182134

Epoch: 5| Step: 4
Training loss: 1.122664451599121
Validation loss: 2.2378181517124176

Epoch: 5| Step: 5
Training loss: 0.7363622188568115
Validation loss: 2.24078697959582

Epoch: 5| Step: 6
Training loss: 0.5429052710533142
Validation loss: 2.242992361386617

Epoch: 5| Step: 7
Training loss: 1.0784580707550049
Validation loss: 2.2319312194983163

Epoch: 5| Step: 8
Training loss: 1.1059553623199463
Validation loss: 2.1966459850470224

Epoch: 5| Step: 9
Training loss: 0.6788104772567749
Validation loss: 2.20551735162735

Epoch: 5| Step: 10
Training loss: 0.931718647480011
Validation loss: 2.2116912454366684

Epoch: 5| Step: 11
Training loss: 1.3166780471801758
Validation loss: 2.1996369510889053

Epoch: 503| Step: 0
Training loss: 1.1257051229476929
Validation loss: 2.192945291598638

Epoch: 5| Step: 1
Training loss: 1.0127829313278198
Validation loss: 2.2252925684054694

Epoch: 5| Step: 2
Training loss: 1.3044816255569458
Validation loss: 2.217994953195254

Epoch: 5| Step: 3
Training loss: 0.7691375613212585
Validation loss: 2.216404010852178

Epoch: 5| Step: 4
Training loss: 0.7619994282722473
Validation loss: 2.2077243526776633

Epoch: 5| Step: 5
Training loss: 0.9727615118026733
Validation loss: 2.236358553171158

Epoch: 5| Step: 6
Training loss: 0.8816937208175659
Validation loss: 2.1944725712140403

Epoch: 5| Step: 7
Training loss: 0.24213919043540955
Validation loss: 2.1957756876945496

Epoch: 5| Step: 8
Training loss: 0.9621009826660156
Validation loss: 2.187399744987488

Epoch: 5| Step: 9
Training loss: 0.8591121435165405
Validation loss: 2.2130156805117926

Epoch: 5| Step: 10
Training loss: 1.28421151638031
Validation loss: 2.2091485112905502

Epoch: 5| Step: 11
Training loss: 0.49351322650909424
Validation loss: 2.2333156963189444

Epoch: 504| Step: 0
Training loss: 0.9970313310623169
Validation loss: 2.2491942892471948

Epoch: 5| Step: 1
Training loss: 0.8995200991630554
Validation loss: 2.212464138865471

Epoch: 5| Step: 2
Training loss: 0.8071535229682922
Validation loss: 2.240823060274124

Epoch: 5| Step: 3
Training loss: 0.939294159412384
Validation loss: 2.247616653641065

Epoch: 5| Step: 4
Training loss: 0.6374852657318115
Validation loss: 2.223518361647924

Epoch: 5| Step: 5
Training loss: 1.0708560943603516
Validation loss: 2.181313455104828

Epoch: 5| Step: 6
Training loss: 0.394859254360199
Validation loss: 2.1634188294410706

Epoch: 5| Step: 7
Training loss: 1.080609679222107
Validation loss: 2.194053292274475

Epoch: 5| Step: 8
Training loss: 0.7612646818161011
Validation loss: 2.1808531681696572

Epoch: 5| Step: 9
Training loss: 1.3233282566070557
Validation loss: 2.187430053949356

Epoch: 5| Step: 10
Training loss: 1.2945729494094849
Validation loss: 2.181772301594416

Epoch: 5| Step: 11
Training loss: 1.4997844696044922
Validation loss: 2.192584921916326

Epoch: 505| Step: 0
Training loss: 0.5818439722061157
Validation loss: 2.198604871829351

Epoch: 5| Step: 1
Training loss: 0.9423887133598328
Validation loss: 2.174361834923426

Epoch: 5| Step: 2
Training loss: 0.713664710521698
Validation loss: 2.2055069655179977

Epoch: 5| Step: 3
Training loss: 0.378598690032959
Validation loss: 2.248874937494596

Epoch: 5| Step: 4
Training loss: 0.7906263470649719
Validation loss: 2.2239304929971695

Epoch: 5| Step: 5
Training loss: 1.4587703943252563
Validation loss: 2.2374071528514228

Epoch: 5| Step: 6
Training loss: 1.0360546112060547
Validation loss: 2.2498338520526886

Epoch: 5| Step: 7
Training loss: 1.2406352758407593
Validation loss: 2.2489379743734994

Epoch: 5| Step: 8
Training loss: 0.8025070428848267
Validation loss: 2.210717330376307

Epoch: 5| Step: 9
Training loss: 1.0737451314926147
Validation loss: 2.2170267601807914

Epoch: 5| Step: 10
Training loss: 1.0553555488586426
Validation loss: 2.231718788544337

Epoch: 5| Step: 11
Training loss: 1.1736962795257568
Validation loss: 2.243570069471995

Epoch: 506| Step: 0
Training loss: 0.8634490966796875
Validation loss: 2.215312813719114

Epoch: 5| Step: 1
Training loss: 1.5920683145523071
Validation loss: 2.2014065285523734

Epoch: 5| Step: 2
Training loss: 0.9387731552124023
Validation loss: 2.251550311843554

Epoch: 5| Step: 3
Training loss: 0.7001944780349731
Validation loss: 2.2631622751553855

Epoch: 5| Step: 4
Training loss: 1.057908535003662
Validation loss: 2.2431467274824777

Epoch: 5| Step: 5
Training loss: 1.0347760915756226
Validation loss: 2.187613228956858

Epoch: 5| Step: 6
Training loss: 0.5776705741882324
Validation loss: 2.211385985215505

Epoch: 5| Step: 7
Training loss: 0.49853235483169556
Validation loss: 2.2174932261308036

Epoch: 5| Step: 8
Training loss: 0.740003228187561
Validation loss: 2.201972022652626

Epoch: 5| Step: 9
Training loss: 0.6203203201293945
Validation loss: 2.189917733271917

Epoch: 5| Step: 10
Training loss: 1.0539504289627075
Validation loss: 2.1839029093583426

Epoch: 5| Step: 11
Training loss: 0.7272497415542603
Validation loss: 2.2471389174461365

Epoch: 507| Step: 0
Training loss: 1.038772702217102
Validation loss: 2.21432172258695

Epoch: 5| Step: 1
Training loss: 0.9710220098495483
Validation loss: 2.243451247612635

Epoch: 5| Step: 2
Training loss: 1.1260783672332764
Validation loss: 2.2076990654071174

Epoch: 5| Step: 3
Training loss: 0.4391351640224457
Validation loss: 2.180529852708181

Epoch: 5| Step: 4
Training loss: 0.7717582583427429
Validation loss: 2.1420837938785553

Epoch: 5| Step: 5
Training loss: 1.5409820079803467
Validation loss: 2.1662033945322037

Epoch: 5| Step: 6
Training loss: 0.7620996236801147
Validation loss: 2.18408510585626

Epoch: 5| Step: 7
Training loss: 0.6760250926017761
Validation loss: 2.1628294438123703

Epoch: 5| Step: 8
Training loss: 0.6938944458961487
Validation loss: 2.1825080861647925

Epoch: 5| Step: 9
Training loss: 0.6321654915809631
Validation loss: 2.205041761199633

Epoch: 5| Step: 10
Training loss: 1.2945308685302734
Validation loss: 2.2029297252496085

Epoch: 5| Step: 11
Training loss: 0.5390905141830444
Validation loss: 2.227563425898552

Epoch: 508| Step: 0
Training loss: 1.3810811042785645
Validation loss: 2.23974018295606

Epoch: 5| Step: 1
Training loss: 0.8452569246292114
Validation loss: 2.220977778236071

Epoch: 5| Step: 2
Training loss: 1.073277473449707
Validation loss: 2.2500199526548386

Epoch: 5| Step: 3
Training loss: 0.7147349119186401
Validation loss: 2.2643446822961173

Epoch: 5| Step: 4
Training loss: 0.8145820498466492
Validation loss: 2.2409869730472565

Epoch: 5| Step: 5
Training loss: 0.547954261302948
Validation loss: 2.269324019551277

Epoch: 5| Step: 6
Training loss: 0.7903554439544678
Validation loss: 2.261019622286161

Epoch: 5| Step: 7
Training loss: 1.0965158939361572
Validation loss: 2.202399174372355

Epoch: 5| Step: 8
Training loss: 1.117782473564148
Validation loss: 2.2250949343045554

Epoch: 5| Step: 9
Training loss: 1.0575014352798462
Validation loss: 2.245528111855189

Epoch: 5| Step: 10
Training loss: 0.9767481088638306
Validation loss: 2.20488503575325

Epoch: 5| Step: 11
Training loss: 1.0269701480865479
Validation loss: 2.214857349793116

Epoch: 509| Step: 0
Training loss: 1.2219576835632324
Validation loss: 2.2318692902723947

Epoch: 5| Step: 1
Training loss: 0.5933396816253662
Validation loss: 2.225836997230848

Epoch: 5| Step: 2
Training loss: 0.6979047060012817
Validation loss: 2.212524230281512

Epoch: 5| Step: 3
Training loss: 1.0423314571380615
Validation loss: 2.243893618384997

Epoch: 5| Step: 4
Training loss: 1.2200157642364502
Validation loss: 2.2239060203234353

Epoch: 5| Step: 5
Training loss: 0.4282529354095459
Validation loss: 2.227388987938563

Epoch: 5| Step: 6
Training loss: 1.3098801374435425
Validation loss: 2.223052809635798

Epoch: 5| Step: 7
Training loss: 0.7803839445114136
Validation loss: 2.1780299693346024

Epoch: 5| Step: 8
Training loss: 0.4698026180267334
Validation loss: 2.145313705007235

Epoch: 5| Step: 9
Training loss: 0.5677738189697266
Validation loss: 2.140874976913134

Epoch: 5| Step: 10
Training loss: 0.6019984483718872
Validation loss: 2.129371071855227

Epoch: 5| Step: 11
Training loss: 1.8560125827789307
Validation loss: 2.1762226621309915

Epoch: 510| Step: 0
Training loss: 0.7625048756599426
Validation loss: 2.176042690873146

Epoch: 5| Step: 1
Training loss: 0.5910128355026245
Validation loss: 2.1795407036940255

Epoch: 5| Step: 2
Training loss: 0.670067548751831
Validation loss: 2.1936346342166266

Epoch: 5| Step: 3
Training loss: 1.0694366693496704
Validation loss: 2.198141564925512

Epoch: 5| Step: 4
Training loss: 0.9369535446166992
Validation loss: 2.1858727633953094

Epoch: 5| Step: 5
Training loss: 0.9168537855148315
Validation loss: 2.1905642996231713

Epoch: 5| Step: 6
Training loss: 1.1853095293045044
Validation loss: 2.2005635797977448

Epoch: 5| Step: 7
Training loss: 0.5391513705253601
Validation loss: 2.2107275227705636

Epoch: 5| Step: 8
Training loss: 1.101173996925354
Validation loss: 2.202610303958257

Epoch: 5| Step: 9
Training loss: 0.6064221262931824
Validation loss: 2.217660744984945

Epoch: 5| Step: 10
Training loss: 1.0277667045593262
Validation loss: 2.2099210073550544

Epoch: 5| Step: 11
Training loss: 0.12431079149246216
Validation loss: 2.2332140654325485

Epoch: 511| Step: 0
Training loss: 0.7102105021476746
Validation loss: 2.2089323500792184

Epoch: 5| Step: 1
Training loss: 0.4561891555786133
Validation loss: 2.2108147342999778

Epoch: 5| Step: 2
Training loss: 0.9569129943847656
Validation loss: 2.179400771856308

Epoch: 5| Step: 3
Training loss: 0.823958694934845
Validation loss: 2.193739801645279

Epoch: 5| Step: 4
Training loss: 0.7786615490913391
Validation loss: 2.2098362048467

Epoch: 5| Step: 5
Training loss: 0.4461238980293274
Validation loss: 2.1842767000198364

Epoch: 5| Step: 6
Training loss: 0.8647516369819641
Validation loss: 2.1925943245490394

Epoch: 5| Step: 7
Training loss: 1.0525180101394653
Validation loss: 2.2015327612559

Epoch: 5| Step: 8
Training loss: 0.7106230854988098
Validation loss: 2.1634107679128647

Epoch: 5| Step: 9
Training loss: 1.59553861618042
Validation loss: 2.165104697148005

Epoch: 5| Step: 10
Training loss: 0.45134496688842773
Validation loss: 2.162629619240761

Epoch: 5| Step: 11
Training loss: 2.567234754562378
Validation loss: 2.1877222657203674

Epoch: 512| Step: 0
Training loss: 1.1864826679229736
Validation loss: 2.2184364199638367

Epoch: 5| Step: 1
Training loss: 0.9615912437438965
Validation loss: 2.2256054083506265

Epoch: 5| Step: 2
Training loss: 0.8978735208511353
Validation loss: 2.233643114566803

Epoch: 5| Step: 3
Training loss: 0.7164093255996704
Validation loss: 2.2226717472076416

Epoch: 5| Step: 4
Training loss: 0.7975350618362427
Validation loss: 2.242248992125193

Epoch: 5| Step: 5
Training loss: 0.6952657103538513
Validation loss: 2.2307546138763428

Epoch: 5| Step: 6
Training loss: 0.9600821733474731
Validation loss: 2.242508048812548

Epoch: 5| Step: 7
Training loss: 0.6675304174423218
Validation loss: 2.2135013987620673

Epoch: 5| Step: 8
Training loss: 0.986488938331604
Validation loss: 2.219565769036611

Epoch: 5| Step: 9
Training loss: 0.796273410320282
Validation loss: 2.2413896719614663

Epoch: 5| Step: 10
Training loss: 0.5669580698013306
Validation loss: 2.2414407084385553

Epoch: 5| Step: 11
Training loss: 1.1807855367660522
Validation loss: 2.241679231325785

Epoch: 513| Step: 0
Training loss: 0.797997772693634
Validation loss: 2.197370395064354

Epoch: 5| Step: 1
Training loss: 1.157094955444336
Validation loss: 2.1735313832759857

Epoch: 5| Step: 2
Training loss: 1.6524696350097656
Validation loss: 2.16226760049661

Epoch: 5| Step: 3
Training loss: 0.9085588455200195
Validation loss: 2.186552877227465

Epoch: 5| Step: 4
Training loss: 0.9202756881713867
Validation loss: 2.215438038110733

Epoch: 5| Step: 5
Training loss: 0.7364789843559265
Validation loss: 2.160848672191302

Epoch: 5| Step: 6
Training loss: 0.9003442525863647
Validation loss: 2.18544872601827

Epoch: 5| Step: 7
Training loss: 0.6056785583496094
Validation loss: 2.188810000816981

Epoch: 5| Step: 8
Training loss: 0.4933527112007141
Validation loss: 2.162083382407824

Epoch: 5| Step: 9
Training loss: 0.6178776025772095
Validation loss: 2.1466958423455558

Epoch: 5| Step: 10
Training loss: 0.5603076219558716
Validation loss: 2.234830617904663

Epoch: 5| Step: 11
Training loss: 0.849886417388916
Validation loss: 2.2053381353616714

Epoch: 514| Step: 0
Training loss: 0.7771067023277283
Validation loss: 2.218572755654653

Epoch: 5| Step: 1
Training loss: 1.1854634284973145
Validation loss: 2.1997216641902924

Epoch: 5| Step: 2
Training loss: 0.6393970251083374
Validation loss: 2.207163691520691

Epoch: 5| Step: 3
Training loss: 0.399665892124176
Validation loss: 2.2009981920321784

Epoch: 5| Step: 4
Training loss: 0.7325614094734192
Validation loss: 2.1658293306827545

Epoch: 5| Step: 5
Training loss: 0.7065126299858093
Validation loss: 2.183285892009735

Epoch: 5| Step: 6
Training loss: 1.082107424736023
Validation loss: 2.2020972867806754

Epoch: 5| Step: 7
Training loss: 0.8057147264480591
Validation loss: 2.1679446399211884

Epoch: 5| Step: 8
Training loss: 1.3726341724395752
Validation loss: 2.188383231560389

Epoch: 5| Step: 9
Training loss: 0.7226357460021973
Validation loss: 2.109753797451655

Epoch: 5| Step: 10
Training loss: 0.6762363314628601
Validation loss: 2.172817140817642

Epoch: 5| Step: 11
Training loss: 1.5866833925247192
Validation loss: 2.135470693310102

Epoch: 515| Step: 0
Training loss: 0.47825542092323303
Validation loss: 2.1858856827020645

Epoch: 5| Step: 1
Training loss: 0.8965764045715332
Validation loss: 2.1328039318323135

Epoch: 5| Step: 2
Training loss: 0.5273233652114868
Validation loss: 2.1571940233310065

Epoch: 5| Step: 3
Training loss: 0.8186651468276978
Validation loss: 2.172801891962687

Epoch: 5| Step: 4
Training loss: 1.0485713481903076
Validation loss: 2.1902851313352585

Epoch: 5| Step: 5
Training loss: 0.7235987186431885
Validation loss: 2.213127995530764

Epoch: 5| Step: 6
Training loss: 1.3487956523895264
Validation loss: 2.192759503920873

Epoch: 5| Step: 7
Training loss: 0.7243579626083374
Validation loss: 2.227772742509842

Epoch: 5| Step: 8
Training loss: 1.1450021266937256
Validation loss: 2.2388531416654587

Epoch: 5| Step: 9
Training loss: 0.4842900335788727
Validation loss: 2.250301788250605

Epoch: 5| Step: 10
Training loss: 0.42631974816322327
Validation loss: 2.244266907374064

Epoch: 5| Step: 11
Training loss: 1.606295108795166
Validation loss: 2.2419030169645944

Epoch: 516| Step: 0
Training loss: 0.8752926588058472
Validation loss: 2.248301694790522

Epoch: 5| Step: 1
Training loss: 0.8066365122795105
Validation loss: 2.2350286841392517

Epoch: 5| Step: 2
Training loss: 1.3870006799697876
Validation loss: 2.2022096614042916

Epoch: 5| Step: 3
Training loss: 0.5066255331039429
Validation loss: 2.2086307456096015

Epoch: 5| Step: 4
Training loss: 0.8971544504165649
Validation loss: 2.200425237417221

Epoch: 5| Step: 5
Training loss: 0.3366616666316986
Validation loss: 2.2233258535464606

Epoch: 5| Step: 6
Training loss: 0.8958969116210938
Validation loss: 2.1879069258769355

Epoch: 5| Step: 7
Training loss: 1.113397240638733
Validation loss: 2.2091997265815735

Epoch: 5| Step: 8
Training loss: 0.5065184831619263
Validation loss: 2.2017257312933602

Epoch: 5| Step: 9
Training loss: 1.0462853908538818
Validation loss: 2.261352320512136

Epoch: 5| Step: 10
Training loss: 0.5769028067588806
Validation loss: 2.207194228967031

Epoch: 5| Step: 11
Training loss: 0.9783821105957031
Validation loss: 2.215855618317922

Epoch: 517| Step: 0
Training loss: 1.1235830783843994
Validation loss: 2.1898649434248605

Epoch: 5| Step: 1
Training loss: 1.044440746307373
Validation loss: 2.183289726575216

Epoch: 5| Step: 2
Training loss: 0.9499324560165405
Validation loss: 2.1869864761829376

Epoch: 5| Step: 3
Training loss: 0.6450622081756592
Validation loss: 2.194789762298266

Epoch: 5| Step: 4
Training loss: 1.394850254058838
Validation loss: 2.159787674744924

Epoch: 5| Step: 5
Training loss: 0.5088152885437012
Validation loss: 2.158152381579081

Epoch: 5| Step: 6
Training loss: 0.7259718179702759
Validation loss: 2.170281062523524

Epoch: 5| Step: 7
Training loss: 0.9280717968940735
Validation loss: 2.1821571389834085

Epoch: 5| Step: 8
Training loss: 0.5456287264823914
Validation loss: 2.1813708394765854

Epoch: 5| Step: 9
Training loss: 0.8107227087020874
Validation loss: 2.161550005276998

Epoch: 5| Step: 10
Training loss: 0.5295166969299316
Validation loss: 2.2150023728609085

Epoch: 5| Step: 11
Training loss: 0.3583377003669739
Validation loss: 2.152405639489492

Epoch: 518| Step: 0
Training loss: 0.994665801525116
Validation loss: 2.1988881876071296

Epoch: 5| Step: 1
Training loss: 0.5082812905311584
Validation loss: 2.2220236013333

Epoch: 5| Step: 2
Training loss: 0.886640727519989
Validation loss: 2.239773457249006

Epoch: 5| Step: 3
Training loss: 0.5498033165931702
Validation loss: 2.202139526605606

Epoch: 5| Step: 4
Training loss: 1.1156976222991943
Validation loss: 2.2146576742331185

Epoch: 5| Step: 5
Training loss: 0.9673976898193359
Validation loss: 2.179354573289553

Epoch: 5| Step: 6
Training loss: 0.6627716422080994
Validation loss: 2.1666233787933984

Epoch: 5| Step: 7
Training loss: 0.6796682476997375
Validation loss: 2.1998932311932244

Epoch: 5| Step: 8
Training loss: 0.6216729283332825
Validation loss: 2.2130528688430786

Epoch: 5| Step: 9
Training loss: 1.4380756616592407
Validation loss: 2.15745976070563

Epoch: 5| Step: 10
Training loss: 0.5018251538276672
Validation loss: 2.161844660838445

Epoch: 5| Step: 11
Training loss: 1.006494402885437
Validation loss: 2.186850289503733

Epoch: 519| Step: 0
Training loss: 0.8971031904220581
Validation loss: 2.193562775850296

Epoch: 5| Step: 1
Training loss: 0.8729947209358215
Validation loss: 2.238513300816218

Epoch: 5| Step: 2
Training loss: 0.6027888655662537
Validation loss: 2.2372486541668573

Epoch: 5| Step: 3
Training loss: 0.7652953863143921
Validation loss: 2.2176466286182404

Epoch: 5| Step: 4
Training loss: 0.40504342317581177
Validation loss: 2.2222735633452735

Epoch: 5| Step: 5
Training loss: 1.1414906978607178
Validation loss: 2.2469223539034524

Epoch: 5| Step: 6
Training loss: 0.8432339429855347
Validation loss: 2.2234366635481515

Epoch: 5| Step: 7
Training loss: 0.6737891435623169
Validation loss: 2.2528353532155356

Epoch: 5| Step: 8
Training loss: 0.9225174188613892
Validation loss: 2.203675071398417

Epoch: 5| Step: 9
Training loss: 0.7828927636146545
Validation loss: 2.2086478024721146

Epoch: 5| Step: 10
Training loss: 0.9191144108772278
Validation loss: 2.204936370253563

Epoch: 5| Step: 11
Training loss: 0.638593316078186
Validation loss: 2.217699055870374

Epoch: 520| Step: 0
Training loss: 0.9552465677261353
Validation loss: 2.177622805039088

Epoch: 5| Step: 1
Training loss: 0.2803778052330017
Validation loss: 2.153508315483729

Epoch: 5| Step: 2
Training loss: 0.9489547610282898
Validation loss: 2.168559948603312

Epoch: 5| Step: 3
Training loss: 0.723598837852478
Validation loss: 2.189294864734014

Epoch: 5| Step: 4
Training loss: 0.8134208917617798
Validation loss: 2.204738070567449

Epoch: 5| Step: 5
Training loss: 0.905795693397522
Validation loss: 2.1850953102111816

Epoch: 5| Step: 6
Training loss: 0.9436750411987305
Validation loss: 2.165482302506765

Epoch: 5| Step: 7
Training loss: 1.0540484189987183
Validation loss: 2.1836532950401306

Epoch: 5| Step: 8
Training loss: 0.36017680168151855
Validation loss: 2.2087710152069726

Epoch: 5| Step: 9
Training loss: 0.5608028173446655
Validation loss: 2.1773775120576224

Epoch: 5| Step: 10
Training loss: 1.1736304759979248
Validation loss: 2.198509727915128

Epoch: 5| Step: 11
Training loss: 0.49778318405151367
Validation loss: 2.2028956562280655

Epoch: 521| Step: 0
Training loss: 0.4057624936103821
Validation loss: 2.1751992056767144

Epoch: 5| Step: 1
Training loss: 0.6593087315559387
Validation loss: 2.1912795205911

Epoch: 5| Step: 2
Training loss: 0.6125270128250122
Validation loss: 2.191066324710846

Epoch: 5| Step: 3
Training loss: 0.453035831451416
Validation loss: 2.2001138826211295

Epoch: 5| Step: 4
Training loss: 0.7169891595840454
Validation loss: 2.216410835584005

Epoch: 5| Step: 5
Training loss: 1.36156165599823
Validation loss: 2.1834188103675842

Epoch: 5| Step: 6
Training loss: 0.47160038352012634
Validation loss: 2.1996773729721704

Epoch: 5| Step: 7
Training loss: 1.1473850011825562
Validation loss: 2.157762055595716

Epoch: 5| Step: 8
Training loss: 0.6823412179946899
Validation loss: 2.1841043333212533

Epoch: 5| Step: 9
Training loss: 0.6109574437141418
Validation loss: 2.1824279725551605

Epoch: 5| Step: 10
Training loss: 1.2438342571258545
Validation loss: 2.2177289724349976

Epoch: 5| Step: 11
Training loss: 1.2056022882461548
Validation loss: 2.178222507238388

Epoch: 522| Step: 0
Training loss: 0.6873065829277039
Validation loss: 2.2145116378863654

Epoch: 5| Step: 1
Training loss: 0.9585763216018677
Validation loss: 2.18176398674647

Epoch: 5| Step: 2
Training loss: 0.4883074164390564
Validation loss: 2.15398242076238

Epoch: 5| Step: 3
Training loss: 0.6312106251716614
Validation loss: 2.1415842125813165

Epoch: 5| Step: 4
Training loss: 0.8701160550117493
Validation loss: 2.15825263162454

Epoch: 5| Step: 5
Training loss: 0.5237637758255005
Validation loss: 2.1592101653416953

Epoch: 5| Step: 6
Training loss: 1.3460843563079834
Validation loss: 2.195635919769605

Epoch: 5| Step: 7
Training loss: 0.8236331939697266
Validation loss: 2.137165213624636

Epoch: 5| Step: 8
Training loss: 0.8653548359870911
Validation loss: 2.1788222094376883

Epoch: 5| Step: 9
Training loss: 0.8173414468765259
Validation loss: 2.226127256949743

Epoch: 5| Step: 10
Training loss: 0.7038413882255554
Validation loss: 2.210131123661995

Epoch: 5| Step: 11
Training loss: 0.3069090247154236
Validation loss: 2.228970835606257

Epoch: 523| Step: 0
Training loss: 0.9727309942245483
Validation loss: 2.2145359267791114

Epoch: 5| Step: 1
Training loss: 1.2318066358566284
Validation loss: 2.2488847573598227

Epoch: 5| Step: 2
Training loss: 0.6520649194717407
Validation loss: 2.2824095686276755

Epoch: 5| Step: 3
Training loss: 0.889327347278595
Validation loss: 2.3007940351963043

Epoch: 5| Step: 4
Training loss: 0.8895347714424133
Validation loss: 2.2369320591290793

Epoch: 5| Step: 5
Training loss: 1.185550332069397
Validation loss: 2.309982548157374

Epoch: 5| Step: 6
Training loss: 0.5494122505187988
Validation loss: 2.2692044973373413

Epoch: 5| Step: 7
Training loss: 1.0028293132781982
Validation loss: 2.232551872730255

Epoch: 5| Step: 8
Training loss: 0.8149261474609375
Validation loss: 2.166884849468867

Epoch: 5| Step: 9
Training loss: 0.6486173868179321
Validation loss: 2.2377692560354867

Epoch: 5| Step: 10
Training loss: 1.0243808031082153
Validation loss: 2.191616808374723

Epoch: 5| Step: 11
Training loss: 0.31871509552001953
Validation loss: 2.2788618405659995

Epoch: 524| Step: 0
Training loss: 1.0422008037567139
Validation loss: 2.262910857796669

Epoch: 5| Step: 1
Training loss: 0.9511985778808594
Validation loss: 2.254206677277883

Epoch: 5| Step: 2
Training loss: 0.7120696306228638
Validation loss: 2.220086932182312

Epoch: 5| Step: 3
Training loss: 0.40800029039382935
Validation loss: 2.250787451863289

Epoch: 5| Step: 4
Training loss: 0.6266460418701172
Validation loss: 2.2631335457166037

Epoch: 5| Step: 5
Training loss: 1.2547197341918945
Validation loss: 2.2527723809083304

Epoch: 5| Step: 6
Training loss: 0.6798961162567139
Validation loss: 2.2773682872454324

Epoch: 5| Step: 7
Training loss: 0.7217091917991638
Validation loss: 2.240335131684939

Epoch: 5| Step: 8
Training loss: 1.185300588607788
Validation loss: 2.2109316488107047

Epoch: 5| Step: 9
Training loss: 0.853201687335968
Validation loss: 2.1847830365101495

Epoch: 5| Step: 10
Training loss: 1.1156635284423828
Validation loss: 2.213793471455574

Epoch: 5| Step: 11
Training loss: 0.2629304528236389
Validation loss: 2.198892598350843

Epoch: 525| Step: 0
Training loss: 0.5300697088241577
Validation loss: 2.178766369819641

Epoch: 5| Step: 1
Training loss: 0.8954756855964661
Validation loss: 2.1565612256526947

Epoch: 5| Step: 2
Training loss: 0.5516360402107239
Validation loss: 2.1809985041618347

Epoch: 5| Step: 3
Training loss: 1.3164446353912354
Validation loss: 2.176332021752993

Epoch: 5| Step: 4
Training loss: 0.4501633644104004
Validation loss: 2.177796641985575

Epoch: 5| Step: 5
Training loss: 0.5158350467681885
Validation loss: 2.169031028946241

Epoch: 5| Step: 6
Training loss: 1.2895129919052124
Validation loss: 2.1888438165187836

Epoch: 5| Step: 7
Training loss: 0.7191510200500488
Validation loss: 2.198654428124428

Epoch: 5| Step: 8
Training loss: 0.9429537057876587
Validation loss: 2.226992299159368

Epoch: 5| Step: 9
Training loss: 0.5421355962753296
Validation loss: 2.168218652407328

Epoch: 5| Step: 10
Training loss: 0.6537328958511353
Validation loss: 2.2031196653842926

Epoch: 5| Step: 11
Training loss: 0.30656367540359497
Validation loss: 2.2397278050581613

Epoch: 526| Step: 0
Training loss: 0.36179500818252563
Validation loss: 2.1977696865797043

Epoch: 5| Step: 1
Training loss: 0.5429989695549011
Validation loss: 2.203119218349457

Epoch: 5| Step: 2
Training loss: 0.8713833093643188
Validation loss: 2.20593232413133

Epoch: 5| Step: 3
Training loss: 0.6946097612380981
Validation loss: 2.1554114570220313

Epoch: 5| Step: 4
Training loss: 0.7874128222465515
Validation loss: 2.1745046377182007

Epoch: 5| Step: 5
Training loss: 0.8033517003059387
Validation loss: 2.1434124062458673

Epoch: 5| Step: 6
Training loss: 0.5861509442329407
Validation loss: 2.155054986476898

Epoch: 5| Step: 7
Training loss: 0.5238352417945862
Validation loss: 2.1715428829193115

Epoch: 5| Step: 8
Training loss: 0.7698720693588257
Validation loss: 2.1425002813339233

Epoch: 5| Step: 9
Training loss: 0.6030357480049133
Validation loss: 2.1751247396071753

Epoch: 5| Step: 10
Training loss: 1.7136895656585693
Validation loss: 2.1603749841451645

Epoch: 5| Step: 11
Training loss: 0.1886758804321289
Validation loss: 2.1952599386374154

Epoch: 527| Step: 0
Training loss: 0.9876769781112671
Validation loss: 2.1844963133335114

Epoch: 5| Step: 1
Training loss: 0.8225347399711609
Validation loss: 2.178962176044782

Epoch: 5| Step: 2
Training loss: 0.8062936067581177
Validation loss: 2.2069605042537055

Epoch: 5| Step: 3
Training loss: 0.8855247497558594
Validation loss: 2.1856327752272287

Epoch: 5| Step: 4
Training loss: 0.444802850484848
Validation loss: 2.1812987476587296

Epoch: 5| Step: 5
Training loss: 0.2778646945953369
Validation loss: 2.1777607748905816

Epoch: 5| Step: 6
Training loss: 1.243714690208435
Validation loss: 2.1882440745830536

Epoch: 5| Step: 7
Training loss: 0.820382297039032
Validation loss: 2.1761532574892044

Epoch: 5| Step: 8
Training loss: 0.5756539106369019
Validation loss: 2.2112697263558707

Epoch: 5| Step: 9
Training loss: 0.9152438044548035
Validation loss: 2.182368983825048

Epoch: 5| Step: 10
Training loss: 0.7303773164749146
Validation loss: 2.193107157945633

Epoch: 5| Step: 11
Training loss: 0.3512990474700928
Validation loss: 2.165571461121241

Epoch: 528| Step: 0
Training loss: 0.6428712606430054
Validation loss: 2.1991724520921707

Epoch: 5| Step: 1
Training loss: 0.5633613467216492
Validation loss: 2.1603870491186776

Epoch: 5| Step: 2
Training loss: 0.7677321434020996
Validation loss: 2.2065492471059165

Epoch: 5| Step: 3
Training loss: 1.0486633777618408
Validation loss: 2.2080754935741425

Epoch: 5| Step: 4
Training loss: 0.5048192143440247
Validation loss: 2.2124684552351632

Epoch: 5| Step: 5
Training loss: 0.3534846603870392
Validation loss: 2.1976882815361023

Epoch: 5| Step: 6
Training loss: 0.4719044268131256
Validation loss: 2.171417325735092

Epoch: 5| Step: 7
Training loss: 1.022193193435669
Validation loss: 2.1814103772242865

Epoch: 5| Step: 8
Training loss: 0.7402958869934082
Validation loss: 2.1745326220989227

Epoch: 5| Step: 9
Training loss: 1.0156022310256958
Validation loss: 2.2040847837924957

Epoch: 5| Step: 10
Training loss: 0.8011543154716492
Validation loss: 2.2217308630545936

Epoch: 5| Step: 11
Training loss: 0.708573043346405
Validation loss: 2.1976810296376548

Epoch: 529| Step: 0
Training loss: 1.2268507480621338
Validation loss: 2.180110995968183

Epoch: 5| Step: 1
Training loss: 0.7186756134033203
Validation loss: 2.17052985727787

Epoch: 5| Step: 2
Training loss: 0.6732310056686401
Validation loss: 2.2537364065647125

Epoch: 5| Step: 3
Training loss: 1.345452070236206
Validation loss: 2.1985138952732086

Epoch: 5| Step: 4
Training loss: 0.5490792989730835
Validation loss: 2.1895168920358024

Epoch: 5| Step: 5
Training loss: 0.9636399149894714
Validation loss: 2.206228569149971

Epoch: 5| Step: 6
Training loss: 0.4459780752658844
Validation loss: 2.225375711917877

Epoch: 5| Step: 7
Training loss: 0.45068997144699097
Validation loss: 2.2140783816576004

Epoch: 5| Step: 8
Training loss: 0.8779112100601196
Validation loss: 2.240655173858007

Epoch: 5| Step: 9
Training loss: 0.9434496164321899
Validation loss: 2.193506528933843

Epoch: 5| Step: 10
Training loss: 0.48634177446365356
Validation loss: 2.19229494035244

Epoch: 5| Step: 11
Training loss: 0.469880610704422
Validation loss: 2.1658736368020377

Epoch: 530| Step: 0
Training loss: 1.0403434038162231
Validation loss: 2.119401122132937

Epoch: 5| Step: 1
Training loss: 0.5821242928504944
Validation loss: 2.1776451021432877

Epoch: 5| Step: 2
Training loss: 0.8106021881103516
Validation loss: 2.1263619512319565

Epoch: 5| Step: 3
Training loss: 0.9959211349487305
Validation loss: 2.1654568016529083

Epoch: 5| Step: 4
Training loss: 0.647506833076477
Validation loss: 2.1401772995789847

Epoch: 5| Step: 5
Training loss: 0.8801557421684265
Validation loss: 2.1605265935262046

Epoch: 5| Step: 6
Training loss: 0.5562041997909546
Validation loss: 2.130268012483915

Epoch: 5| Step: 7
Training loss: 1.2069066762924194
Validation loss: 2.1084569642941156

Epoch: 5| Step: 8
Training loss: 0.5124718546867371
Validation loss: 2.137360249956449

Epoch: 5| Step: 9
Training loss: 0.3589826226234436
Validation loss: 2.1472891370455423

Epoch: 5| Step: 10
Training loss: 0.6458269357681274
Validation loss: 2.204020773371061

Epoch: 5| Step: 11
Training loss: 0.2013634443283081
Validation loss: 2.1741423159837723

Epoch: 531| Step: 0
Training loss: 0.6974914073944092
Validation loss: 2.1927706748247147

Epoch: 5| Step: 1
Training loss: 0.9546998143196106
Validation loss: 2.2095029205083847

Epoch: 5| Step: 2
Training loss: 0.9656011462211609
Validation loss: 2.1780679722627005

Epoch: 5| Step: 3
Training loss: 0.6153566241264343
Validation loss: 2.103307028611501

Epoch: 5| Step: 4
Training loss: 0.6682270765304565
Validation loss: 2.1232145925362906

Epoch: 5| Step: 5
Training loss: 0.365785151720047
Validation loss: 2.1464188545942307

Epoch: 5| Step: 6
Training loss: 1.1574430465698242
Validation loss: 2.162011136611303

Epoch: 5| Step: 7
Training loss: 0.6345319747924805
Validation loss: 2.1272777716318765

Epoch: 5| Step: 8
Training loss: 0.5128264427185059
Validation loss: 2.2033521831035614

Epoch: 5| Step: 9
Training loss: 1.0324549674987793
Validation loss: 2.184598128000895

Epoch: 5| Step: 10
Training loss: 0.6973721385002136
Validation loss: 2.2204787929852805

Epoch: 5| Step: 11
Training loss: 0.319982647895813
Validation loss: 2.1865346133708954

Epoch: 532| Step: 0
Training loss: 0.7970174551010132
Validation loss: 2.199344793955485

Epoch: 5| Step: 1
Training loss: 0.3938574194908142
Validation loss: 2.2120301524798074

Epoch: 5| Step: 2
Training loss: 0.9439435005187988
Validation loss: 2.183887784679731

Epoch: 5| Step: 3
Training loss: 0.6771975755691528
Validation loss: 2.170862853527069

Epoch: 5| Step: 4
Training loss: 0.7325074672698975
Validation loss: 2.170836771527926

Epoch: 5| Step: 5
Training loss: 0.9143327474594116
Validation loss: 2.166670868794123

Epoch: 5| Step: 6
Training loss: 0.769821047782898
Validation loss: 2.1880594988663993

Epoch: 5| Step: 7
Training loss: 0.8215198516845703
Validation loss: 2.1963336964448295

Epoch: 5| Step: 8
Training loss: 0.36078470945358276
Validation loss: 2.1953380505243936

Epoch: 5| Step: 9
Training loss: 0.789221465587616
Validation loss: 2.239080568154653

Epoch: 5| Step: 10
Training loss: 0.7682713270187378
Validation loss: 2.19405626753966

Epoch: 5| Step: 11
Training loss: 0.6962318420410156
Validation loss: 2.1673880765835443

Epoch: 533| Step: 0
Training loss: 0.3895936906337738
Validation loss: 2.177868068218231

Epoch: 5| Step: 1
Training loss: 0.9978839755058289
Validation loss: 2.2058955828348794

Epoch: 5| Step: 2
Training loss: 0.5378433465957642
Validation loss: 2.1234016021092734

Epoch: 5| Step: 3
Training loss: 1.1295053958892822
Validation loss: 2.1701562901337943

Epoch: 5| Step: 4
Training loss: 0.43976956605911255
Validation loss: 2.166094645857811

Epoch: 5| Step: 5
Training loss: 0.7540107369422913
Validation loss: 2.1436588168144226

Epoch: 5| Step: 6
Training loss: 0.759303867816925
Validation loss: 2.181890274087588

Epoch: 5| Step: 7
Training loss: 0.8384024500846863
Validation loss: 2.1609667291243873

Epoch: 5| Step: 8
Training loss: 0.4591330587863922
Validation loss: 2.1698928823073707

Epoch: 5| Step: 9
Training loss: 0.8781055212020874
Validation loss: 2.2256379822889962

Epoch: 5| Step: 10
Training loss: 0.698156476020813
Validation loss: 2.186877489089966

Epoch: 5| Step: 11
Training loss: 1.4968180656433105
Validation loss: 2.1802151203155518

Epoch: 534| Step: 0
Training loss: 0.7818789482116699
Validation loss: 2.122917741537094

Epoch: 5| Step: 1
Training loss: 0.8352346420288086
Validation loss: 2.1542008270819983

Epoch: 5| Step: 2
Training loss: 0.48819828033447266
Validation loss: 2.1708106199900308

Epoch: 5| Step: 3
Training loss: 0.7061141133308411
Validation loss: 2.1376910905043283

Epoch: 5| Step: 4
Training loss: 0.6975387930870056
Validation loss: 2.162644699215889

Epoch: 5| Step: 5
Training loss: 0.6049267053604126
Validation loss: 2.1978580156962075

Epoch: 5| Step: 6
Training loss: 0.8645514249801636
Validation loss: 2.215333248178164

Epoch: 5| Step: 7
Training loss: 0.38716182112693787
Validation loss: 2.2119979510704675

Epoch: 5| Step: 8
Training loss: 1.2354767322540283
Validation loss: 2.2235764215389886

Epoch: 5| Step: 9
Training loss: 1.228238821029663
Validation loss: 2.202502300341924

Epoch: 5| Step: 10
Training loss: 0.3420037031173706
Validation loss: 2.189512843887011

Epoch: 5| Step: 11
Training loss: 0.5089070796966553
Validation loss: 2.2043256362279258

Epoch: 535| Step: 0
Training loss: 0.22003698348999023
Validation loss: 2.195373366276423

Epoch: 5| Step: 1
Training loss: 0.9187244176864624
Validation loss: 2.1593643128871918

Epoch: 5| Step: 2
Training loss: 0.9111276865005493
Validation loss: 2.2015870610872903

Epoch: 5| Step: 3
Training loss: 0.5030282139778137
Validation loss: 2.15717721482118

Epoch: 5| Step: 4
Training loss: 0.7591997981071472
Validation loss: 2.186445891857147

Epoch: 5| Step: 5
Training loss: 0.939923882484436
Validation loss: 2.130778059363365

Epoch: 5| Step: 6
Training loss: 0.7118844985961914
Validation loss: 2.153224989771843

Epoch: 5| Step: 7
Training loss: 0.3972548842430115
Validation loss: 2.197546049952507

Epoch: 5| Step: 8
Training loss: 0.9120446443557739
Validation loss: 2.181267634034157

Epoch: 5| Step: 9
Training loss: 0.8935196995735168
Validation loss: 2.1504078060388565

Epoch: 5| Step: 10
Training loss: 0.7087898850440979
Validation loss: 2.1726443568865457

Epoch: 5| Step: 11
Training loss: 0.28676772117614746
Validation loss: 2.1697878390550613

Epoch: 536| Step: 0
Training loss: 0.9872873425483704
Validation loss: 2.221802572409312

Epoch: 5| Step: 1
Training loss: 0.5044341087341309
Validation loss: 2.161464363336563

Epoch: 5| Step: 2
Training loss: 0.28204020857810974
Validation loss: 2.18955667813619

Epoch: 5| Step: 3
Training loss: 1.017690896987915
Validation loss: 2.1882219115893045

Epoch: 5| Step: 4
Training loss: 0.6392389535903931
Validation loss: 2.19362536072731

Epoch: 5| Step: 5
Training loss: 0.4371764063835144
Validation loss: 2.2017234563827515

Epoch: 5| Step: 6
Training loss: 0.79783695936203
Validation loss: 2.179361561934153

Epoch: 5| Step: 7
Training loss: 0.6608330011367798
Validation loss: 2.1657350659370422

Epoch: 5| Step: 8
Training loss: 0.6172738075256348
Validation loss: 2.1855461398760476

Epoch: 5| Step: 9
Training loss: 0.8784451484680176
Validation loss: 2.180369625488917

Epoch: 5| Step: 10
Training loss: 1.0209035873413086
Validation loss: 2.186686168114344

Epoch: 5| Step: 11
Training loss: 1.773967981338501
Validation loss: 2.2071297566095986

Epoch: 537| Step: 0
Training loss: 0.9901787638664246
Validation loss: 2.180993696053823

Epoch: 5| Step: 1
Training loss: 0.895054042339325
Validation loss: 2.20367161432902

Epoch: 5| Step: 2
Training loss: 0.5612514019012451
Validation loss: 2.1940872420867286

Epoch: 5| Step: 3
Training loss: 0.5950822830200195
Validation loss: 2.1837316999832788

Epoch: 5| Step: 4
Training loss: 0.6478558778762817
Validation loss: 2.194855680068334

Epoch: 5| Step: 5
Training loss: 0.6252479553222656
Validation loss: 2.208399698138237

Epoch: 5| Step: 6
Training loss: 0.948062539100647
Validation loss: 2.2160654067993164

Epoch: 5| Step: 7
Training loss: 0.5721939206123352
Validation loss: 2.1984456380208335

Epoch: 5| Step: 8
Training loss: 1.0055170059204102
Validation loss: 2.2216144104798636

Epoch: 5| Step: 9
Training loss: 0.3186299800872803
Validation loss: 2.197805717587471

Epoch: 5| Step: 10
Training loss: 0.7466788291931152
Validation loss: 2.228002905845642

Epoch: 5| Step: 11
Training loss: 0.4493861198425293
Validation loss: 2.2166604499022164

Epoch: 538| Step: 0
Training loss: 0.7597991228103638
Validation loss: 2.1999050875504813

Epoch: 5| Step: 1
Training loss: 0.8011916279792786
Validation loss: 2.1769105394681296

Epoch: 5| Step: 2
Training loss: 1.014925241470337
Validation loss: 2.2218882193168006

Epoch: 5| Step: 3
Training loss: 0.6755188703536987
Validation loss: 2.1771298895279565

Epoch: 5| Step: 4
Training loss: 0.5659065246582031
Validation loss: 2.2134989897410073

Epoch: 5| Step: 5
Training loss: 0.3263798654079437
Validation loss: 2.1622865349054337

Epoch: 5| Step: 6
Training loss: 1.0796841382980347
Validation loss: 2.218441297610601

Epoch: 5| Step: 7
Training loss: 0.9852913022041321
Validation loss: 2.1624278724193573

Epoch: 5| Step: 8
Training loss: 0.34771063923835754
Validation loss: 2.1868809213240943

Epoch: 5| Step: 9
Training loss: 0.5810868144035339
Validation loss: 2.1872144838174186

Epoch: 5| Step: 10
Training loss: 0.42654603719711304
Validation loss: 2.2014003843069077

Epoch: 5| Step: 11
Training loss: 0.25627464056015015
Validation loss: 2.2186307658751807

Epoch: 539| Step: 0
Training loss: 0.6954060792922974
Validation loss: 2.1982077807188034

Epoch: 5| Step: 1
Training loss: 0.5099800825119019
Validation loss: 2.1963123132785163

Epoch: 5| Step: 2
Training loss: 0.910565972328186
Validation loss: 2.175316244363785

Epoch: 5| Step: 3
Training loss: 0.532689094543457
Validation loss: 2.1902860899766288

Epoch: 5| Step: 4
Training loss: 0.8020512461662292
Validation loss: 2.161504050095876

Epoch: 5| Step: 5
Training loss: 0.4917762875556946
Validation loss: 2.177756736675898

Epoch: 5| Step: 6
Training loss: 0.731270432472229
Validation loss: 2.1715240329504013

Epoch: 5| Step: 7
Training loss: 0.36206942796707153
Validation loss: 2.19797512392203

Epoch: 5| Step: 8
Training loss: 0.9173271059989929
Validation loss: 2.163421352704366

Epoch: 5| Step: 9
Training loss: 0.6278679966926575
Validation loss: 2.177776868144671

Epoch: 5| Step: 10
Training loss: 1.05268132686615
Validation loss: 2.174893776575724

Epoch: 5| Step: 11
Training loss: 0.49148017168045044
Validation loss: 2.1790072520573935

Epoch: 540| Step: 0
Training loss: 0.5820890665054321
Validation loss: 2.185175508260727

Epoch: 5| Step: 1
Training loss: 0.5323007106781006
Validation loss: 2.1777174025774

Epoch: 5| Step: 2
Training loss: 0.818385124206543
Validation loss: 2.2137270172437034

Epoch: 5| Step: 3
Training loss: 1.1041162014007568
Validation loss: 2.1697089225053787

Epoch: 5| Step: 4
Training loss: 0.45324668288230896
Validation loss: 2.209366942445437

Epoch: 5| Step: 5
Training loss: 0.945335865020752
Validation loss: 2.2025501181681952

Epoch: 5| Step: 6
Training loss: 0.4205567240715027
Validation loss: 2.2109860281149545

Epoch: 5| Step: 7
Training loss: 0.6830645799636841
Validation loss: 2.2080291161934533

Epoch: 5| Step: 8
Training loss: 0.351778119802475
Validation loss: 2.200060168902079

Epoch: 5| Step: 9
Training loss: 0.6290281414985657
Validation loss: 2.1806262681881585

Epoch: 5| Step: 10
Training loss: 1.2927627563476562
Validation loss: 2.1283952494462333

Epoch: 5| Step: 11
Training loss: 0.27094796299934387
Validation loss: 2.165336718161901

Epoch: 541| Step: 0
Training loss: 0.6113125085830688
Validation loss: 2.1520848820606866

Epoch: 5| Step: 1
Training loss: 1.0034466981887817
Validation loss: 2.0743823746840158

Epoch: 5| Step: 2
Training loss: 0.9518827199935913
Validation loss: 2.1039779682954154

Epoch: 5| Step: 3
Training loss: 0.8496421575546265
Validation loss: 2.121233602364858

Epoch: 5| Step: 4
Training loss: 0.40616244077682495
Validation loss: 2.1105769524971643

Epoch: 5| Step: 5
Training loss: 1.2360095977783203
Validation loss: 2.10896889368693

Epoch: 5| Step: 6
Training loss: 1.061740517616272
Validation loss: 2.1565718750158944

Epoch: 5| Step: 7
Training loss: 1.375738501548767
Validation loss: 2.165897250175476

Epoch: 5| Step: 8
Training loss: 0.5492603778839111
Validation loss: 2.1808288991451263

Epoch: 5| Step: 9
Training loss: 0.6640071868896484
Validation loss: 2.139032711585363

Epoch: 5| Step: 10
Training loss: 0.669208288192749
Validation loss: 2.174193521340688

Epoch: 5| Step: 11
Training loss: 0.27103710174560547
Validation loss: 2.1155827393134436

Epoch: 542| Step: 0
Training loss: 0.5536624789237976
Validation loss: 2.133909652630488

Epoch: 5| Step: 1
Training loss: 0.44976741075515747
Validation loss: 2.11079873641332

Epoch: 5| Step: 2
Training loss: 2.2232227325439453
Validation loss: 2.1398483167092004

Epoch: 5| Step: 3
Training loss: 0.5050923228263855
Validation loss: 2.1554051637649536

Epoch: 5| Step: 4
Training loss: 0.4683605134487152
Validation loss: 2.1748025317986808

Epoch: 5| Step: 5
Training loss: 0.6932634115219116
Validation loss: 2.1668157974878945

Epoch: 5| Step: 6
Training loss: 1.0334932804107666
Validation loss: 2.1994512528181076

Epoch: 5| Step: 7
Training loss: 0.8264314532279968
Validation loss: 2.1958394100268683

Epoch: 5| Step: 8
Training loss: 0.5545690655708313
Validation loss: 2.199976106484731

Epoch: 5| Step: 9
Training loss: 0.3870845139026642
Validation loss: 2.209564213951429

Epoch: 5| Step: 10
Training loss: 0.5959514379501343
Validation loss: 2.1923199196656546

Epoch: 5| Step: 11
Training loss: 0.35299253463745117
Validation loss: 2.159266764918963

Epoch: 543| Step: 0
Training loss: 0.9592059850692749
Validation loss: 2.1953705499569574

Epoch: 5| Step: 1
Training loss: 0.7661402225494385
Validation loss: 2.1614244878292084

Epoch: 5| Step: 2
Training loss: 0.8632596731185913
Validation loss: 2.1644557615121207

Epoch: 5| Step: 3
Training loss: 1.051113486289978
Validation loss: 2.162092169125875

Epoch: 5| Step: 4
Training loss: 0.665301501750946
Validation loss: 2.147159993648529

Epoch: 5| Step: 5
Training loss: 0.5284281969070435
Validation loss: 2.153653532266617

Epoch: 5| Step: 6
Training loss: 0.466052383184433
Validation loss: 2.2146461407343545

Epoch: 5| Step: 7
Training loss: 1.1518559455871582
Validation loss: 2.2255284786224365

Epoch: 5| Step: 8
Training loss: 0.7989329099655151
Validation loss: 2.208292086919149

Epoch: 5| Step: 9
Training loss: 0.7272281646728516
Validation loss: 2.228546291589737

Epoch: 5| Step: 10
Training loss: 0.614505410194397
Validation loss: 2.1563730984926224

Epoch: 5| Step: 11
Training loss: 0.3332989811897278
Validation loss: 2.195900241533915

Epoch: 544| Step: 0
Training loss: 0.7016338109970093
Validation loss: 2.15188060204188

Epoch: 5| Step: 1
Training loss: 0.6385971307754517
Validation loss: 2.1863382359345755

Epoch: 5| Step: 2
Training loss: 0.7490308880805969
Validation loss: 2.2226422826449075

Epoch: 5| Step: 3
Training loss: 1.0491210222244263
Validation loss: 2.1940868347883224

Epoch: 5| Step: 4
Training loss: 0.6742638349533081
Validation loss: 2.1636643509070077

Epoch: 5| Step: 5
Training loss: 0.6665588617324829
Validation loss: 2.127167592446009

Epoch: 5| Step: 6
Training loss: 0.5575661063194275
Validation loss: 2.182490328947703

Epoch: 5| Step: 7
Training loss: 0.7753913998603821
Validation loss: 2.199352969725927

Epoch: 5| Step: 8
Training loss: 0.6463371515274048
Validation loss: 2.22829540570577

Epoch: 5| Step: 9
Training loss: 1.3344688415527344
Validation loss: 2.205610821644465

Epoch: 5| Step: 10
Training loss: 1.1031602621078491
Validation loss: 2.224841753641764

Epoch: 5| Step: 11
Training loss: 0.7890056371688843
Validation loss: 2.224809388319651

Epoch: 545| Step: 0
Training loss: 0.648880124092102
Validation loss: 2.1880296568075814

Epoch: 5| Step: 1
Training loss: 0.7603394389152527
Validation loss: 2.1443489293257394

Epoch: 5| Step: 2
Training loss: 0.7542260885238647
Validation loss: 2.137609819571177

Epoch: 5| Step: 3
Training loss: 0.6200495958328247
Validation loss: 2.1639604220787683

Epoch: 5| Step: 4
Training loss: 1.018334984779358
Validation loss: 2.164472167690595

Epoch: 5| Step: 5
Training loss: 1.163952112197876
Validation loss: 2.1627801209688187

Epoch: 5| Step: 6
Training loss: 0.6725068688392639
Validation loss: 2.20076622068882

Epoch: 5| Step: 7
Training loss: 1.1445097923278809
Validation loss: 2.168683812022209

Epoch: 5| Step: 8
Training loss: 0.7411133646965027
Validation loss: 2.1630987922350564

Epoch: 5| Step: 9
Training loss: 0.5677440762519836
Validation loss: 2.1936467786629996

Epoch: 5| Step: 10
Training loss: 0.5487031936645508
Validation loss: 2.1784015893936157

Epoch: 5| Step: 11
Training loss: 0.21193307638168335
Validation loss: 2.2227966487407684

Epoch: 546| Step: 0
Training loss: 0.3824293315410614
Validation loss: 2.172987381617228

Epoch: 5| Step: 1
Training loss: 0.49453192949295044
Validation loss: 2.2045540511608124

Epoch: 5| Step: 2
Training loss: 0.8238666653633118
Validation loss: 2.2000067879756293

Epoch: 5| Step: 3
Training loss: 0.626849353313446
Validation loss: 2.14279842376709

Epoch: 5| Step: 4
Training loss: 0.5012950301170349
Validation loss: 2.1513677587111792

Epoch: 5| Step: 5
Training loss: 1.281453251838684
Validation loss: 2.1106055229902267

Epoch: 5| Step: 6
Training loss: 0.9388351440429688
Validation loss: 2.100282073020935

Epoch: 5| Step: 7
Training loss: 0.569983959197998
Validation loss: 2.1050786077976227

Epoch: 5| Step: 8
Training loss: 1.1255279779434204
Validation loss: 2.1458666225274405

Epoch: 5| Step: 9
Training loss: 0.5222413539886475
Validation loss: 2.1738783617814383

Epoch: 5| Step: 10
Training loss: 0.8832769393920898
Validation loss: 2.2036546617746353

Epoch: 5| Step: 11
Training loss: 0.23708124458789825
Validation loss: 2.186737904946009

Epoch: 547| Step: 0
Training loss: 0.8307029008865356
Validation loss: 2.170173784097036

Epoch: 5| Step: 1
Training loss: 0.5826343297958374
Validation loss: 2.168785899877548

Epoch: 5| Step: 2
Training loss: 0.42795252799987793
Validation loss: 2.166614462931951

Epoch: 5| Step: 3
Training loss: 0.4972480833530426
Validation loss: 2.183084547519684

Epoch: 5| Step: 4
Training loss: 1.0617388486862183
Validation loss: 2.1735997051000595

Epoch: 5| Step: 5
Training loss: 0.5968297123908997
Validation loss: 2.1882656266291938

Epoch: 5| Step: 6
Training loss: 1.2017018795013428
Validation loss: 2.1807590425014496

Epoch: 5| Step: 7
Training loss: 0.8529216647148132
Validation loss: 2.2084583143393197

Epoch: 5| Step: 8
Training loss: 0.5192888975143433
Validation loss: 2.1589186638593674

Epoch: 5| Step: 9
Training loss: 0.48405295610427856
Validation loss: 2.1733501851558685

Epoch: 5| Step: 10
Training loss: 0.8560886383056641
Validation loss: 2.1834634989500046

Epoch: 5| Step: 11
Training loss: 2.2215542793273926
Validation loss: 2.254515210787455

Epoch: 548| Step: 0
Training loss: 0.5047272443771362
Validation loss: 2.207181637485822

Epoch: 5| Step: 1
Training loss: 1.2734087705612183
Validation loss: 2.2021219382683435

Epoch: 5| Step: 2
Training loss: 0.7428463697433472
Validation loss: 2.1430363953113556

Epoch: 5| Step: 3
Training loss: 0.9724633097648621
Validation loss: 2.1699018528064093

Epoch: 5| Step: 4
Training loss: 0.8024554252624512
Validation loss: 2.1383296251296997

Epoch: 5| Step: 5
Training loss: 0.5840668678283691
Validation loss: 2.1094066898028054

Epoch: 5| Step: 6
Training loss: 0.48698145151138306
Validation loss: 2.14815587302049

Epoch: 5| Step: 7
Training loss: 0.7293885350227356
Validation loss: 2.16664649049441

Epoch: 5| Step: 8
Training loss: 0.5806428790092468
Validation loss: 2.153781866033872

Epoch: 5| Step: 9
Training loss: 0.7832663059234619
Validation loss: 2.1749098002910614

Epoch: 5| Step: 10
Training loss: 0.787981390953064
Validation loss: 2.2271708548069

Epoch: 5| Step: 11
Training loss: 0.21933713555335999
Validation loss: 2.200673441092173

Epoch: 549| Step: 0
Training loss: 0.37359970808029175
Validation loss: 2.212722435593605

Epoch: 5| Step: 1
Training loss: 0.6463032364845276
Validation loss: 2.161173552274704

Epoch: 5| Step: 2
Training loss: 0.8443151712417603
Validation loss: 2.218124568462372

Epoch: 5| Step: 3
Training loss: 0.6719679832458496
Validation loss: 2.128592163324356

Epoch: 5| Step: 4
Training loss: 1.1278975009918213
Validation loss: 2.1381208300590515

Epoch: 5| Step: 5
Training loss: 1.0364768505096436
Validation loss: 2.182384009162585

Epoch: 5| Step: 6
Training loss: 0.6377625465393066
Validation loss: 2.132748102148374

Epoch: 5| Step: 7
Training loss: 0.283733069896698
Validation loss: 2.1389571925004325

Epoch: 5| Step: 8
Training loss: 1.0262097120285034
Validation loss: 2.1460001319646835

Epoch: 5| Step: 9
Training loss: 0.3751150667667389
Validation loss: 2.1277266641457877

Epoch: 5| Step: 10
Training loss: 0.7603510618209839
Validation loss: 2.1564223815997443

Epoch: 5| Step: 11
Training loss: 0.5973605513572693
Validation loss: 2.0856018364429474

Epoch: 550| Step: 0
Training loss: 0.8502200245857239
Validation loss: 2.1289883653322854

Epoch: 5| Step: 1
Training loss: 0.7738825082778931
Validation loss: 2.0934206942717233

Epoch: 5| Step: 2
Training loss: 0.5523513555526733
Validation loss: 2.129176398118337

Epoch: 5| Step: 3
Training loss: 0.6980513334274292
Validation loss: 2.148271153370539

Epoch: 5| Step: 4
Training loss: 0.9946818351745605
Validation loss: 2.1051728228727975

Epoch: 5| Step: 5
Training loss: 0.4895244538784027
Validation loss: 2.151491994659106

Epoch: 5| Step: 6
Training loss: 0.5010238885879517
Validation loss: 2.1055421233177185

Epoch: 5| Step: 7
Training loss: 0.5916343331336975
Validation loss: 2.0973581025997796

Epoch: 5| Step: 8
Training loss: 0.9333602786064148
Validation loss: 2.11097814142704

Epoch: 5| Step: 9
Training loss: 0.8545106649398804
Validation loss: 2.0906609843174615

Epoch: 5| Step: 10
Training loss: 0.42783278226852417
Validation loss: 2.0947600404421487

Epoch: 5| Step: 11
Training loss: 0.34728753566741943
Validation loss: 2.0830466051896415

Testing loss: 1.8325120553695897
