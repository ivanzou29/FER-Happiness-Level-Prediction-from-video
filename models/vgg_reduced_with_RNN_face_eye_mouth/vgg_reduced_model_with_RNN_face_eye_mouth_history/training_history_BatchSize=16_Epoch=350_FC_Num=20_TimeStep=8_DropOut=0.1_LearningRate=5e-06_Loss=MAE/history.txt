Epoch: 1| Step: 0
Training loss: 6.179544448852539
Validation loss: 5.35948379834493

Epoch: 6| Step: 1
Training loss: 5.920795440673828
Validation loss: 5.357239246368408

Epoch: 6| Step: 2
Training loss: 6.193357467651367
Validation loss: 5.35505731900533

Epoch: 6| Step: 3
Training loss: 6.0605878829956055
Validation loss: 5.352935791015625

Epoch: 6| Step: 4
Training loss: 4.670234203338623
Validation loss: 5.350884437561035

Epoch: 6| Step: 5
Training loss: 4.344187259674072
Validation loss: 5.348927458127339

Epoch: 6| Step: 6
Training loss: 5.14395809173584
Validation loss: 5.347079515457153

Epoch: 6| Step: 7
Training loss: 6.141319274902344
Validation loss: 5.345115343729655

Epoch: 6| Step: 8
Training loss: 5.037199974060059
Validation loss: 5.343270937601726

Epoch: 6| Step: 9
Training loss: 6.105513572692871
Validation loss: 5.341312567392985

Epoch: 6| Step: 10
Training loss: 4.496294021606445
Validation loss: 5.339366515477498

Epoch: 6| Step: 11
Training loss: 5.507518768310547
Validation loss: 5.337329864501953

Epoch: 6| Step: 12
Training loss: 4.900769233703613
Validation loss: 5.3352828820546465

Epoch: 6| Step: 13
Training loss: 5.114001750946045
Validation loss: 5.333167552947998

Epoch: 2| Step: 0
Training loss: 5.6252641677856445
Validation loss: 5.3309281667073565

Epoch: 6| Step: 1
Training loss: 6.501890182495117
Validation loss: 5.3286519050598145

Epoch: 6| Step: 2
Training loss: 4.6233320236206055
Validation loss: 5.326241731643677

Epoch: 6| Step: 3
Training loss: 5.25560188293457
Validation loss: 5.323884169260661

Epoch: 6| Step: 4
Training loss: 4.685454845428467
Validation loss: 5.3212784131368

Epoch: 6| Step: 5
Training loss: 5.492466926574707
Validation loss: 5.318679571151733

Epoch: 6| Step: 6
Training loss: 5.078306674957275
Validation loss: 5.315944353739421

Epoch: 6| Step: 7
Training loss: 5.444847583770752
Validation loss: 5.313040256500244

Epoch: 6| Step: 8
Training loss: 5.487819671630859
Validation loss: 5.310284058252971

Epoch: 6| Step: 9
Training loss: 5.429317474365234
Validation loss: 5.307111183802287

Epoch: 6| Step: 10
Training loss: 5.842673301696777
Validation loss: 5.303972482681274

Epoch: 6| Step: 11
Training loss: 4.553406238555908
Validation loss: 5.300637602806091

Epoch: 6| Step: 12
Training loss: 5.930617332458496
Validation loss: 5.297288417816162

Epoch: 6| Step: 13
Training loss: 5.412939071655273
Validation loss: 5.293805996576945

Epoch: 3| Step: 0
Training loss: 5.778220176696777
Validation loss: 5.290025075276692

Epoch: 6| Step: 1
Training loss: 5.756791114807129
Validation loss: 5.286419073740642

Epoch: 6| Step: 2
Training loss: 5.813864707946777
Validation loss: 5.282467842102051

Epoch: 6| Step: 3
Training loss: 4.822330474853516
Validation loss: 5.2782448927561445

Epoch: 6| Step: 4
Training loss: 4.076828956604004
Validation loss: 5.27404002348582

Epoch: 6| Step: 5
Training loss: 4.815025329589844
Validation loss: 5.269712607065837

Epoch: 6| Step: 6
Training loss: 4.913231372833252
Validation loss: 5.265355666478475

Epoch: 6| Step: 7
Training loss: 5.995256423950195
Validation loss: 5.260767300923665

Epoch: 6| Step: 8
Training loss: 6.13360071182251
Validation loss: 5.255956093470256

Epoch: 6| Step: 9
Training loss: 6.740993499755859
Validation loss: 5.251006841659546

Epoch: 6| Step: 10
Training loss: 5.366579055786133
Validation loss: 5.24612283706665

Epoch: 6| Step: 11
Training loss: 4.463683605194092
Validation loss: 5.241078774134318

Epoch: 6| Step: 12
Training loss: 4.468501091003418
Validation loss: 5.23581075668335

Epoch: 6| Step: 13
Training loss: 5.511687278747559
Validation loss: 5.230712652206421

Epoch: 4| Step: 0
Training loss: 4.739150047302246
Validation loss: 5.225355863571167

Epoch: 6| Step: 1
Training loss: 5.576207160949707
Validation loss: 5.2198920249938965

Epoch: 6| Step: 2
Training loss: 5.383627891540527
Validation loss: 5.214471975962321

Epoch: 6| Step: 3
Training loss: 4.44185733795166
Validation loss: 5.208732684453328

Epoch: 6| Step: 4
Training loss: 5.114111423492432
Validation loss: 5.203137477238973

Epoch: 6| Step: 5
Training loss: 4.446280002593994
Validation loss: 5.197484731674194

Epoch: 6| Step: 6
Training loss: 6.2899489402771
Validation loss: 5.19152847925822

Epoch: 6| Step: 7
Training loss: 5.775125026702881
Validation loss: 5.185809214909871

Epoch: 6| Step: 8
Training loss: 4.234699726104736
Validation loss: 5.179664055506389

Epoch: 6| Step: 9
Training loss: 5.131754398345947
Validation loss: 5.173643986384074

Epoch: 6| Step: 10
Training loss: 6.614006996154785
Validation loss: 5.167762398719788

Epoch: 6| Step: 11
Training loss: 5.57362174987793
Validation loss: 5.161676406860352

Epoch: 6| Step: 12
Training loss: 4.989176273345947
Validation loss: 5.155390659968059

Epoch: 6| Step: 13
Training loss: 5.344695091247559
Validation loss: 5.149245262145996

Epoch: 5| Step: 0
Training loss: 6.318260669708252
Validation loss: 5.142685969670613

Epoch: 6| Step: 1
Training loss: 5.146280288696289
Validation loss: 5.136270364125569

Epoch: 6| Step: 2
Training loss: 5.86881160736084
Validation loss: 5.130003611246745

Epoch: 6| Step: 3
Training loss: 6.012938499450684
Validation loss: 5.123432954152425

Epoch: 6| Step: 4
Training loss: 4.9338860511779785
Validation loss: 5.116593798001607

Epoch: 6| Step: 5
Training loss: 4.557306289672852
Validation loss: 5.109788020451863

Epoch: 6| Step: 6
Training loss: 5.381635665893555
Validation loss: 5.103162248929341

Epoch: 6| Step: 7
Training loss: 4.4343156814575195
Validation loss: 5.096080223719279

Epoch: 6| Step: 8
Training loss: 4.937317371368408
Validation loss: 5.089760859807332

Epoch: 6| Step: 9
Training loss: 6.161358833312988
Validation loss: 5.082770665486653

Epoch: 6| Step: 10
Training loss: 4.336986064910889
Validation loss: 5.075965404510498

Epoch: 6| Step: 11
Training loss: 4.6095685958862305
Validation loss: 5.069320281346639

Epoch: 6| Step: 12
Training loss: 5.0803985595703125
Validation loss: 5.062627871831258

Epoch: 6| Step: 13
Training loss: 4.69280481338501
Validation loss: 5.0560862223307295

Epoch: 6| Step: 0
Training loss: 4.500480651855469
Validation loss: 5.04936150709788

Epoch: 6| Step: 1
Training loss: 4.738574028015137
Validation loss: 5.043222427368164

Epoch: 6| Step: 2
Training loss: 4.665034294128418
Validation loss: 5.037084738413493

Epoch: 6| Step: 3
Training loss: 5.70377254486084
Validation loss: 5.030329545338948

Epoch: 6| Step: 4
Training loss: 5.938726425170898
Validation loss: 5.0240921179453535

Epoch: 6| Step: 5
Training loss: 4.400913238525391
Validation loss: 5.017627199490865

Epoch: 6| Step: 6
Training loss: 5.257082939147949
Validation loss: 5.011419773101807

Epoch: 6| Step: 7
Training loss: 4.826145172119141
Validation loss: 5.005247990290324

Epoch: 6| Step: 8
Training loss: 3.80356502532959
Validation loss: 4.998671531677246

Epoch: 6| Step: 9
Training loss: 5.433821678161621
Validation loss: 4.992264032363892

Epoch: 6| Step: 10
Training loss: 5.298716068267822
Validation loss: 4.986117045084636

Epoch: 6| Step: 11
Training loss: 6.186184883117676
Validation loss: 4.9798227945963545

Epoch: 6| Step: 12
Training loss: 4.821341514587402
Validation loss: 4.97351876894633

Epoch: 6| Step: 13
Training loss: 5.6823835372924805
Validation loss: 4.967422246932983

Epoch: 7| Step: 0
Training loss: 3.7125325202941895
Validation loss: 4.961558898289998

Epoch: 6| Step: 1
Training loss: 4.618809223175049
Validation loss: 4.955778797467549

Epoch: 6| Step: 2
Training loss: 5.496795177459717
Validation loss: 4.950084368387858

Epoch: 6| Step: 3
Training loss: 5.214570999145508
Validation loss: 4.944415012995402

Epoch: 6| Step: 4
Training loss: 4.776209831237793
Validation loss: 4.938718795776367

Epoch: 6| Step: 5
Training loss: 5.550047874450684
Validation loss: 4.9331010182698565

Epoch: 6| Step: 6
Training loss: 5.338846206665039
Validation loss: 4.927401701609294

Epoch: 6| Step: 7
Training loss: 4.776921272277832
Validation loss: 4.922009865442912

Epoch: 6| Step: 8
Training loss: 5.032607078552246
Validation loss: 4.916438976923625

Epoch: 6| Step: 9
Training loss: 5.202651023864746
Validation loss: 4.911180814107259

Epoch: 6| Step: 10
Training loss: 5.893274784088135
Validation loss: 4.905773282051086

Epoch: 6| Step: 11
Training loss: 3.459521770477295
Validation loss: 4.900695244471232

Epoch: 6| Step: 12
Training loss: 5.795502185821533
Validation loss: 4.895445744196574

Epoch: 6| Step: 13
Training loss: 5.26132869720459
Validation loss: 4.890280405680339

Epoch: 8| Step: 0
Training loss: 4.691776752471924
Validation loss: 4.885368267695109

Epoch: 6| Step: 1
Training loss: 4.943248748779297
Validation loss: 4.880339980125427

Epoch: 6| Step: 2
Training loss: 4.419558525085449
Validation loss: 4.875305414199829

Epoch: 6| Step: 3
Training loss: 6.031731605529785
Validation loss: 4.869983911514282

Epoch: 6| Step: 4
Training loss: 4.927525520324707
Validation loss: 4.864914735158284

Epoch: 6| Step: 5
Training loss: 5.776355266571045
Validation loss: 4.859785636266072

Epoch: 6| Step: 6
Training loss: 5.424473762512207
Validation loss: 4.854514916737874

Epoch: 6| Step: 7
Training loss: 4.798567771911621
Validation loss: 4.849220832188924

Epoch: 6| Step: 8
Training loss: 4.009817123413086
Validation loss: 4.844314018885295

Epoch: 6| Step: 9
Training loss: 5.087224006652832
Validation loss: 4.839224179585774

Epoch: 6| Step: 10
Training loss: 4.354401588439941
Validation loss: 4.833808461825053

Epoch: 6| Step: 11
Training loss: 4.524161338806152
Validation loss: 4.82904593149821

Epoch: 6| Step: 12
Training loss: 5.191769599914551
Validation loss: 4.823472499847412

Epoch: 6| Step: 13
Training loss: 4.976650238037109
Validation loss: 4.818236827850342

Epoch: 9| Step: 0
Training loss: 3.793731689453125
Validation loss: 4.8136301438013716

Epoch: 6| Step: 1
Training loss: 4.641452312469482
Validation loss: 4.808499972025554

Epoch: 6| Step: 2
Training loss: 5.0397443771362305
Validation loss: 4.803602457046509

Epoch: 6| Step: 3
Training loss: 5.824660778045654
Validation loss: 4.798591057459514

Epoch: 6| Step: 4
Training loss: 5.31633186340332
Validation loss: 4.793613115946452

Epoch: 6| Step: 5
Training loss: 5.132157802581787
Validation loss: 4.788383523623149

Epoch: 6| Step: 6
Training loss: 4.742225646972656
Validation loss: 4.783729592959086

Epoch: 6| Step: 7
Training loss: 4.1333513259887695
Validation loss: 4.778621355692546

Epoch: 6| Step: 8
Training loss: 4.879787921905518
Validation loss: 4.7744191487630205

Epoch: 6| Step: 9
Training loss: 4.898898601531982
Validation loss: 4.769646962483724

Epoch: 6| Step: 10
Training loss: 4.86665153503418
Validation loss: 4.764942804972331

Epoch: 6| Step: 11
Training loss: 5.867665767669678
Validation loss: 4.760293006896973

Epoch: 6| Step: 12
Training loss: 4.527872562408447
Validation loss: 4.75528089205424

Epoch: 6| Step: 13
Training loss: 4.557204246520996
Validation loss: 4.750988165537517

Epoch: 10| Step: 0
Training loss: 4.597626686096191
Validation loss: 4.746254523595174

Epoch: 6| Step: 1
Training loss: 5.171196460723877
Validation loss: 4.742082277933757

Epoch: 6| Step: 2
Training loss: 6.255406379699707
Validation loss: 4.737655242284139

Epoch: 6| Step: 3
Training loss: 4.152154445648193
Validation loss: 4.733386913935344

Epoch: 6| Step: 4
Training loss: 4.816164970397949
Validation loss: 4.729116241137187

Epoch: 6| Step: 5
Training loss: 3.7634096145629883
Validation loss: 4.725234349568685

Epoch: 6| Step: 6
Training loss: 3.0484442710876465
Validation loss: 4.72052788734436

Epoch: 6| Step: 7
Training loss: 4.840231895446777
Validation loss: 4.716429233551025

Epoch: 6| Step: 8
Training loss: 5.17495059967041
Validation loss: 4.712770462036133

Epoch: 6| Step: 9
Training loss: 5.035058975219727
Validation loss: 4.708505153656006

Epoch: 6| Step: 10
Training loss: 5.164333820343018
Validation loss: 4.704034407933553

Epoch: 6| Step: 11
Training loss: 5.102637767791748
Validation loss: 4.699086666107178

Epoch: 6| Step: 12
Training loss: 5.2827630043029785
Validation loss: 4.69487448533376

Epoch: 6| Step: 13
Training loss: 4.94696569442749
Validation loss: 4.690367062886556

Epoch: 11| Step: 0
Training loss: 4.170041084289551
Validation loss: 4.685471574465434

Epoch: 6| Step: 1
Training loss: 4.3095574378967285
Validation loss: 4.680438200632731

Epoch: 6| Step: 2
Training loss: 4.234818458557129
Validation loss: 4.676077365875244

Epoch: 6| Step: 3
Training loss: 3.919199228286743
Validation loss: 4.671343922615051

Epoch: 6| Step: 4
Training loss: 4.727105140686035
Validation loss: 4.6666295528411865

Epoch: 6| Step: 5
Training loss: 5.0806732177734375
Validation loss: 4.661969820658366

Epoch: 6| Step: 6
Training loss: 4.637184143066406
Validation loss: 4.657142519950867

Epoch: 6| Step: 7
Training loss: 5.4677886962890625
Validation loss: 4.652156114578247

Epoch: 6| Step: 8
Training loss: 5.168531894683838
Validation loss: 4.648456414540608

Epoch: 6| Step: 9
Training loss: 5.862844467163086
Validation loss: 4.642357150713603

Epoch: 6| Step: 10
Training loss: 4.271651744842529
Validation loss: 4.6380618413289385

Epoch: 6| Step: 11
Training loss: 4.783565521240234
Validation loss: 4.633087714513143

Epoch: 6| Step: 12
Training loss: 5.270011901855469
Validation loss: 4.628479719161987

Epoch: 6| Step: 13
Training loss: 4.592288017272949
Validation loss: 4.623101234436035

Epoch: 12| Step: 0
Training loss: 4.050579071044922
Validation loss: 4.617382804552714

Epoch: 6| Step: 1
Training loss: 5.168867588043213
Validation loss: 4.612479488054912

Epoch: 6| Step: 2
Training loss: 2.702284336090088
Validation loss: 4.6084113121032715

Epoch: 6| Step: 3
Training loss: 5.1054229736328125
Validation loss: 4.60263713200887

Epoch: 6| Step: 4
Training loss: 4.936283588409424
Validation loss: 4.59761913617452

Epoch: 6| Step: 5
Training loss: 5.723023414611816
Validation loss: 4.592791398366292

Epoch: 6| Step: 6
Training loss: 4.288286209106445
Validation loss: 4.587633530298869

Epoch: 6| Step: 7
Training loss: 5.148980140686035
Validation loss: 4.583028793334961

Epoch: 6| Step: 8
Training loss: 4.93278694152832
Validation loss: 4.576949278513591

Epoch: 6| Step: 9
Training loss: 4.9819512367248535
Validation loss: 4.571881214777629

Epoch: 6| Step: 10
Training loss: 4.505977153778076
Validation loss: 4.56742004553477

Epoch: 6| Step: 11
Training loss: 4.619473457336426
Validation loss: 4.562257409095764

Epoch: 6| Step: 12
Training loss: 5.020449638366699
Validation loss: 4.557172218958537

Epoch: 6| Step: 13
Training loss: 4.397716999053955
Validation loss: 4.552233894666036

Epoch: 13| Step: 0
Training loss: 5.301830291748047
Validation loss: 4.547139008839925

Epoch: 6| Step: 1
Training loss: 3.0523314476013184
Validation loss: 4.542445023854573

Epoch: 6| Step: 2
Training loss: 5.641330718994141
Validation loss: 4.536694367726644

Epoch: 6| Step: 3
Training loss: 4.989124298095703
Validation loss: 4.532494942347209

Epoch: 6| Step: 4
Training loss: 5.793698310852051
Validation loss: 4.5275799036026

Epoch: 6| Step: 5
Training loss: 4.570662498474121
Validation loss: 4.5221695105234785

Epoch: 6| Step: 6
Training loss: 4.6123504638671875
Validation loss: 4.517595807711284

Epoch: 6| Step: 7
Training loss: 5.020769119262695
Validation loss: 4.512152512868245

Epoch: 6| Step: 8
Training loss: 4.162485122680664
Validation loss: 4.5074204206466675

Epoch: 6| Step: 9
Training loss: 3.9669454097747803
Validation loss: 4.502212842305501

Epoch: 6| Step: 10
Training loss: 4.25986385345459
Validation loss: 4.497206012407939

Epoch: 6| Step: 11
Training loss: 4.26618766784668
Validation loss: 4.491856972376506

Epoch: 6| Step: 12
Training loss: 4.076998233795166
Validation loss: 4.486899058024089

Epoch: 6| Step: 13
Training loss: 4.968033790588379
Validation loss: 4.482281883557637

Epoch: 14| Step: 0
Training loss: 4.427582740783691
Validation loss: 4.477172613143921

Epoch: 6| Step: 1
Training loss: 4.825224876403809
Validation loss: 4.471887032190959

Epoch: 6| Step: 2
Training loss: 4.430143356323242
Validation loss: 4.46693476041158

Epoch: 6| Step: 3
Training loss: 4.047906875610352
Validation loss: 4.461141069730123

Epoch: 6| Step: 4
Training loss: 3.982813835144043
Validation loss: 4.45539927482605

Epoch: 6| Step: 5
Training loss: 5.3064727783203125
Validation loss: 4.450084567070007

Epoch: 6| Step: 6
Training loss: 5.412519931793213
Validation loss: 4.4446784655253095

Epoch: 6| Step: 7
Training loss: 5.130025863647461
Validation loss: 4.438621123631795

Epoch: 6| Step: 8
Training loss: 5.182772636413574
Validation loss: 4.432093858718872

Epoch: 6| Step: 9
Training loss: 4.854076385498047
Validation loss: 4.426032900810242

Epoch: 6| Step: 10
Training loss: 4.8200154304504395
Validation loss: 4.419076959292094

Epoch: 6| Step: 11
Training loss: 3.4397342205047607
Validation loss: 4.413319667180379

Epoch: 6| Step: 12
Training loss: 3.833829641342163
Validation loss: 4.4062773784001665

Epoch: 6| Step: 13
Training loss: 4.046334266662598
Validation loss: 4.399357716242473

Epoch: 15| Step: 0
Training loss: 3.7636213302612305
Validation loss: 4.393793265024821

Epoch: 6| Step: 1
Training loss: 4.131067752838135
Validation loss: 4.386574745178223

Epoch: 6| Step: 2
Training loss: 5.450186252593994
Validation loss: 4.379847804705302

Epoch: 6| Step: 3
Training loss: 4.650943756103516
Validation loss: 4.371849576632182

Epoch: 6| Step: 4
Training loss: 3.360515594482422
Validation loss: 4.365941206614177

Epoch: 6| Step: 5
Training loss: 5.5720109939575195
Validation loss: 4.35893193880717

Epoch: 6| Step: 6
Training loss: 3.0328593254089355
Validation loss: 4.351873397827148

Epoch: 6| Step: 7
Training loss: 3.3248772621154785
Validation loss: 4.345041433970134

Epoch: 6| Step: 8
Training loss: 4.629829406738281
Validation loss: 4.338899930318196

Epoch: 6| Step: 9
Training loss: 4.330629348754883
Validation loss: 4.33085298538208

Epoch: 6| Step: 10
Training loss: 6.252250671386719
Validation loss: 4.323736866315206

Epoch: 6| Step: 11
Training loss: 4.31611967086792
Validation loss: 4.318598747253418

Epoch: 6| Step: 12
Training loss: 4.2930908203125
Validation loss: 4.30981969833374

Epoch: 6| Step: 13
Training loss: 5.441004276275635
Validation loss: 4.302355130513509

Epoch: 16| Step: 0
Training loss: 5.484091758728027
Validation loss: 4.297980348269145

Epoch: 6| Step: 1
Training loss: 4.783932209014893
Validation loss: 4.289770285288493

Epoch: 6| Step: 2
Training loss: 3.526503562927246
Validation loss: 4.2812091906865435

Epoch: 6| Step: 3
Training loss: 4.486267566680908
Validation loss: 4.275776306788127

Epoch: 6| Step: 4
Training loss: 5.220487594604492
Validation loss: 4.268125096956889

Epoch: 6| Step: 5
Training loss: 3.5434422492980957
Validation loss: 4.26289431254069

Epoch: 6| Step: 6
Training loss: 3.350656270980835
Validation loss: 4.256929238637288

Epoch: 6| Step: 7
Training loss: 4.308989524841309
Validation loss: 4.250259002049764

Epoch: 6| Step: 8
Training loss: 3.8397090435028076
Validation loss: 4.244579315185547

Epoch: 6| Step: 9
Training loss: 4.87339973449707
Validation loss: 4.237568656603496

Epoch: 6| Step: 10
Training loss: 4.94977331161499
Validation loss: 4.23082168896993

Epoch: 6| Step: 11
Training loss: 4.199881076812744
Validation loss: 4.224581917126973

Epoch: 6| Step: 12
Training loss: 4.329370498657227
Validation loss: 4.219810922940572

Epoch: 6| Step: 13
Training loss: 4.46074914932251
Validation loss: 4.2125381628672285

Epoch: 17| Step: 0
Training loss: 4.41364049911499
Validation loss: 4.207332054773967

Epoch: 6| Step: 1
Training loss: 4.2669525146484375
Validation loss: 4.200039227803548

Epoch: 6| Step: 2
Training loss: 4.237677574157715
Validation loss: 4.1931255261103315

Epoch: 6| Step: 3
Training loss: 4.303791522979736
Validation loss: 4.187590320905049

Epoch: 6| Step: 4
Training loss: 4.978265762329102
Validation loss: 4.182339906692505

Epoch: 6| Step: 5
Training loss: 4.331159591674805
Validation loss: 4.175716876983643

Epoch: 6| Step: 6
Training loss: 3.169872283935547
Validation loss: 4.168958425521851

Epoch: 6| Step: 7
Training loss: 4.329887390136719
Validation loss: 4.162095030148824

Epoch: 6| Step: 8
Training loss: 4.33767032623291
Validation loss: 4.156549175580342

Epoch: 6| Step: 9
Training loss: 4.193253517150879
Validation loss: 4.150912443796794

Epoch: 6| Step: 10
Training loss: 4.073866844177246
Validation loss: 4.143863598505656

Epoch: 6| Step: 11
Training loss: 5.435641288757324
Validation loss: 4.137782255808513

Epoch: 6| Step: 12
Training loss: 3.6292691230773926
Validation loss: 4.132546106974284

Epoch: 6| Step: 13
Training loss: 4.543360233306885
Validation loss: 4.126672863960266

Epoch: 18| Step: 0
Training loss: 5.405233860015869
Validation loss: 4.1207477649052935

Epoch: 6| Step: 1
Training loss: 4.786431312561035
Validation loss: 4.114904165267944

Epoch: 6| Step: 2
Training loss: 3.0716617107391357
Validation loss: 4.109490593274434

Epoch: 6| Step: 3
Training loss: 4.552071571350098
Validation loss: 4.104343255360921

Epoch: 6| Step: 4
Training loss: 4.260436058044434
Validation loss: 4.098249157269795

Epoch: 6| Step: 5
Training loss: 5.351902008056641
Validation loss: 4.092350244522095

Epoch: 6| Step: 6
Training loss: 3.5964362621307373
Validation loss: 4.08681845664978

Epoch: 6| Step: 7
Training loss: 3.571615219116211
Validation loss: 4.081255515416463

Epoch: 6| Step: 8
Training loss: 3.5749902725219727
Validation loss: 4.074994444847107

Epoch: 6| Step: 9
Training loss: 4.408519268035889
Validation loss: 4.070587118466695

Epoch: 6| Step: 10
Training loss: 4.380437850952148
Validation loss: 4.064801136652629

Epoch: 6| Step: 11
Training loss: 4.028122901916504
Validation loss: 4.059454758961995

Epoch: 6| Step: 12
Training loss: 3.2952122688293457
Validation loss: 4.054585496584575

Epoch: 6| Step: 13
Training loss: 4.889962196350098
Validation loss: 4.049559076627095

Epoch: 19| Step: 0
Training loss: 4.183361053466797
Validation loss: 4.044083674748738

Epoch: 6| Step: 1
Training loss: 5.170123100280762
Validation loss: 4.038593769073486

Epoch: 6| Step: 2
Training loss: 4.5012078285217285
Validation loss: 4.033915042877197

Epoch: 6| Step: 3
Training loss: 3.4519593715667725
Validation loss: 4.028228958447774

Epoch: 6| Step: 4
Training loss: 4.3237810134887695
Validation loss: 4.0227365891138716

Epoch: 6| Step: 5
Training loss: 5.536272048950195
Validation loss: 4.017855207125346

Epoch: 6| Step: 6
Training loss: 3.8009207248687744
Validation loss: 4.0126246611277265

Epoch: 6| Step: 7
Training loss: 3.874234676361084
Validation loss: 4.007661541302999

Epoch: 6| Step: 8
Training loss: 4.687049388885498
Validation loss: 4.001399993896484

Epoch: 6| Step: 9
Training loss: 3.8599395751953125
Validation loss: 3.9962077538172402

Epoch: 6| Step: 10
Training loss: 3.9952235221862793
Validation loss: 3.9907690286636353

Epoch: 6| Step: 11
Training loss: 3.972928047180176
Validation loss: 3.98599910736084

Epoch: 6| Step: 12
Training loss: 3.0154333114624023
Validation loss: 3.980669379234314

Epoch: 6| Step: 13
Training loss: 3.803706645965576
Validation loss: 3.975376605987549

Epoch: 20| Step: 0
Training loss: 4.105097770690918
Validation loss: 3.9709366957346597

Epoch: 6| Step: 1
Training loss: 4.161389350891113
Validation loss: 3.9661253690719604

Epoch: 6| Step: 2
Training loss: 3.87825608253479
Validation loss: 3.962122837702433

Epoch: 6| Step: 3
Training loss: 3.838153600692749
Validation loss: 3.9567221800486245

Epoch: 6| Step: 4
Training loss: 3.8592491149902344
Validation loss: 3.9524377584457397

Epoch: 6| Step: 5
Training loss: 3.52545166015625
Validation loss: 3.9466594060262046

Epoch: 6| Step: 6
Training loss: 3.906737804412842
Validation loss: 3.940567413965861

Epoch: 6| Step: 7
Training loss: 4.077158451080322
Validation loss: 3.935568372408549

Epoch: 6| Step: 8
Training loss: 4.064084529876709
Validation loss: 3.9306538899739585

Epoch: 6| Step: 9
Training loss: 4.815776824951172
Validation loss: 3.9251875082651773

Epoch: 6| Step: 10
Training loss: 3.7069716453552246
Validation loss: 3.918123642603556

Epoch: 6| Step: 11
Training loss: 4.146669387817383
Validation loss: 3.914682626724243

Epoch: 6| Step: 12
Training loss: 4.324478626251221
Validation loss: 3.9078545570373535

Epoch: 6| Step: 13
Training loss: 4.786238670349121
Validation loss: 3.9026521841684976

Epoch: 21| Step: 0
Training loss: 5.024194717407227
Validation loss: 3.8971099058787027

Epoch: 6| Step: 1
Training loss: 4.145035743713379
Validation loss: 3.8926616112391152

Epoch: 6| Step: 2
Training loss: 3.966430902481079
Validation loss: 3.887577454249064

Epoch: 6| Step: 3
Training loss: 4.182139873504639
Validation loss: 3.8828434546788535

Epoch: 6| Step: 4
Training loss: 2.9216980934143066
Validation loss: 3.877245863278707

Epoch: 6| Step: 5
Training loss: 3.729027509689331
Validation loss: 3.8719611167907715

Epoch: 6| Step: 6
Training loss: 3.555601119995117
Validation loss: 3.866417566935221

Epoch: 6| Step: 7
Training loss: 4.773878574371338
Validation loss: 3.8610368967056274

Epoch: 6| Step: 8
Training loss: 4.04625129699707
Validation loss: 3.8553788661956787

Epoch: 6| Step: 9
Training loss: 4.2530927658081055
Validation loss: 3.84908918539683

Epoch: 6| Step: 10
Training loss: 4.231420040130615
Validation loss: 3.844095468521118

Epoch: 6| Step: 11
Training loss: 4.136897087097168
Validation loss: 3.8405954440434775

Epoch: 6| Step: 12
Training loss: 4.118366241455078
Validation loss: 3.833717385927836

Epoch: 6| Step: 13
Training loss: 3.1423850059509277
Validation loss: 3.8300728003184

Epoch: 22| Step: 0
Training loss: 4.036139488220215
Validation loss: 3.82530148824056

Epoch: 6| Step: 1
Training loss: 4.180578231811523
Validation loss: 3.820274551709493

Epoch: 6| Step: 2
Training loss: 3.2022719383239746
Validation loss: 3.8148217598597207

Epoch: 6| Step: 3
Training loss: 3.3222150802612305
Validation loss: 3.8101061979929605

Epoch: 6| Step: 4
Training loss: 3.5551328659057617
Validation loss: 3.804934859275818

Epoch: 6| Step: 5
Training loss: 3.516812801361084
Validation loss: 3.800351699193319

Epoch: 6| Step: 6
Training loss: 3.614149808883667
Validation loss: 3.794997453689575

Epoch: 6| Step: 7
Training loss: 4.613102436065674
Validation loss: 3.791224718093872

Epoch: 6| Step: 8
Training loss: 4.663235664367676
Validation loss: 3.784492572148641

Epoch: 6| Step: 9
Training loss: 5.029467582702637
Validation loss: 3.78030796845754

Epoch: 6| Step: 10
Training loss: 2.51518177986145
Validation loss: 3.7749500274658203

Epoch: 6| Step: 11
Training loss: 4.503396987915039
Validation loss: 3.7697007258733115

Epoch: 6| Step: 12
Training loss: 4.748892784118652
Validation loss: 3.7632842461268106

Epoch: 6| Step: 13
Training loss: 3.756459951400757
Validation loss: 3.7586096922556558

Epoch: 23| Step: 0
Training loss: 3.3701257705688477
Validation loss: 3.753019173940023

Epoch: 6| Step: 1
Training loss: 4.0245041847229
Validation loss: 3.748385508855184

Epoch: 6| Step: 2
Training loss: 2.829918384552002
Validation loss: 3.7424516677856445

Epoch: 6| Step: 3
Training loss: 3.9757232666015625
Validation loss: 3.7391486962636313

Epoch: 6| Step: 4
Training loss: 3.4793295860290527
Validation loss: 3.7339375019073486

Epoch: 6| Step: 5
Training loss: 4.006056308746338
Validation loss: 3.7290470202763877

Epoch: 6| Step: 6
Training loss: 3.780029535293579
Validation loss: 3.7245174249013266

Epoch: 6| Step: 7
Training loss: 3.751349687576294
Validation loss: 3.7195162773132324

Epoch: 6| Step: 8
Training loss: 4.133991718292236
Validation loss: 3.7146881024042764

Epoch: 6| Step: 9
Training loss: 3.3880202770233154
Validation loss: 3.7103766600290933

Epoch: 6| Step: 10
Training loss: 5.226040363311768
Validation loss: 3.706020951271057

Epoch: 6| Step: 11
Training loss: 3.5157089233398438
Validation loss: 3.7007903258005777

Epoch: 6| Step: 12
Training loss: 4.719259738922119
Validation loss: 3.696726640065511

Epoch: 6| Step: 13
Training loss: 4.128415107727051
Validation loss: 3.6913519303003945

Epoch: 24| Step: 0
Training loss: 4.288942813873291
Validation loss: 3.6860703229904175

Epoch: 6| Step: 1
Training loss: 3.511061668395996
Validation loss: 3.682603597640991

Epoch: 6| Step: 2
Training loss: 3.944871425628662
Validation loss: 3.676792780558268

Epoch: 6| Step: 3
Training loss: 3.991039276123047
Validation loss: 3.6714391311009726

Epoch: 6| Step: 4
Training loss: 3.2414660453796387
Validation loss: 3.666328271230062

Epoch: 6| Step: 5
Training loss: 4.190080165863037
Validation loss: 3.661454121271769

Epoch: 6| Step: 6
Training loss: 3.9831244945526123
Validation loss: 3.656040986378988

Epoch: 6| Step: 7
Training loss: 3.303312063217163
Validation loss: 3.652026812235514

Epoch: 6| Step: 8
Training loss: 4.813235282897949
Validation loss: 3.646314104398092

Epoch: 6| Step: 9
Training loss: 4.004890441894531
Validation loss: 3.6412317752838135

Epoch: 6| Step: 10
Training loss: 4.217897415161133
Validation loss: 3.636632521947225

Epoch: 6| Step: 11
Training loss: 3.462520122528076
Validation loss: 3.6317484776178994

Epoch: 6| Step: 12
Training loss: 2.967801094055176
Validation loss: 3.626495679219564

Epoch: 6| Step: 13
Training loss: 3.534297466278076
Validation loss: 3.623059074083964

Epoch: 25| Step: 0
Training loss: 3.8632450103759766
Validation loss: 3.6178630193074546

Epoch: 6| Step: 1
Training loss: 4.1555376052856445
Validation loss: 3.613248586654663

Epoch: 6| Step: 2
Training loss: 4.713043212890625
Validation loss: 3.6091276009877524

Epoch: 6| Step: 3
Training loss: 3.731635332107544
Validation loss: 3.604623794555664

Epoch: 6| Step: 4
Training loss: 3.836726665496826
Validation loss: 3.600219408671061

Epoch: 6| Step: 5
Training loss: 3.678635597229004
Validation loss: 3.594942092895508

Epoch: 6| Step: 6
Training loss: 2.9353322982788086
Validation loss: 3.5904506047566733

Epoch: 6| Step: 7
Training loss: 3.181608200073242
Validation loss: 3.5871121486028037

Epoch: 6| Step: 8
Training loss: 4.389748573303223
Validation loss: 3.5815035502115884

Epoch: 6| Step: 9
Training loss: 3.615403175354004
Validation loss: 3.577540636062622

Epoch: 6| Step: 10
Training loss: 3.1540369987487793
Validation loss: 3.571254253387451

Epoch: 6| Step: 11
Training loss: 2.479783296585083
Validation loss: 3.5667225122451782

Epoch: 6| Step: 12
Training loss: 4.427908897399902
Validation loss: 3.5626238584518433

Epoch: 6| Step: 13
Training loss: 4.339611053466797
Validation loss: 3.557687759399414

Epoch: 26| Step: 0
Training loss: 3.1722230911254883
Validation loss: 3.5523573557535806

Epoch: 6| Step: 1
Training loss: 4.531946182250977
Validation loss: 3.547498265902201

Epoch: 6| Step: 2
Training loss: 3.4209046363830566
Validation loss: 3.54237699508667

Epoch: 6| Step: 3
Training loss: 3.099975109100342
Validation loss: 3.5361852645874023

Epoch: 6| Step: 4
Training loss: 3.4320077896118164
Validation loss: 3.5316152969996133

Epoch: 6| Step: 5
Training loss: 4.114483833312988
Validation loss: 3.5274113019307456

Epoch: 6| Step: 6
Training loss: 3.942826509475708
Validation loss: 3.522363026936849

Epoch: 6| Step: 7
Training loss: 3.0890493392944336
Validation loss: 3.517235358556112

Epoch: 6| Step: 8
Training loss: 3.3262362480163574
Validation loss: 3.512062390645345

Epoch: 6| Step: 9
Training loss: 3.7775232791900635
Validation loss: 3.507192095120748

Epoch: 6| Step: 10
Training loss: 4.120377540588379
Validation loss: 3.5023457209269204

Epoch: 6| Step: 11
Training loss: 3.525556802749634
Validation loss: 3.4975611368815103

Epoch: 6| Step: 12
Training loss: 3.7052087783813477
Validation loss: 3.493417580922445

Epoch: 6| Step: 13
Training loss: 4.340055465698242
Validation loss: 3.4870897928873696

Epoch: 27| Step: 0
Training loss: 3.8866124153137207
Validation loss: 3.4820624589920044

Epoch: 6| Step: 1
Training loss: 4.426017761230469
Validation loss: 3.477364977200826

Epoch: 6| Step: 2
Training loss: 4.198548316955566
Validation loss: 3.4728192885716758

Epoch: 6| Step: 3
Training loss: 3.3208327293395996
Validation loss: 3.4677297671635947

Epoch: 6| Step: 4
Training loss: 3.2970309257507324
Validation loss: 3.4628092447916665

Epoch: 6| Step: 5
Training loss: 3.043342113494873
Validation loss: 3.4570727348327637

Epoch: 6| Step: 6
Training loss: 2.20808744430542
Validation loss: 3.4519200722376504

Epoch: 6| Step: 7
Training loss: 3.635072946548462
Validation loss: 3.4479697148005166

Epoch: 6| Step: 8
Training loss: 4.096657752990723
Validation loss: 3.442119757334391

Epoch: 6| Step: 9
Training loss: 4.005147933959961
Validation loss: 3.4384095271428428

Epoch: 6| Step: 10
Training loss: 3.1111679077148438
Validation loss: 3.4319968223571777

Epoch: 6| Step: 11
Training loss: 3.9957590103149414
Validation loss: 3.428372025489807

Epoch: 6| Step: 12
Training loss: 4.1595869064331055
Validation loss: 3.4237715800603232

Epoch: 6| Step: 13
Training loss: 3.2773399353027344
Validation loss: 3.4186981916427612

Epoch: 28| Step: 0
Training loss: 3.686074733734131
Validation loss: 3.4153936306635537

Epoch: 6| Step: 1
Training loss: 3.8993418216705322
Validation loss: 3.4099873304367065

Epoch: 6| Step: 2
Training loss: 3.455439567565918
Validation loss: 3.4035998582839966

Epoch: 6| Step: 3
Training loss: 3.4524972438812256
Validation loss: 3.399372378985087

Epoch: 6| Step: 4
Training loss: 3.084312915802002
Validation loss: 3.395308335622152

Epoch: 6| Step: 5
Training loss: 3.8039066791534424
Validation loss: 3.390259265899658

Epoch: 6| Step: 6
Training loss: 2.872335910797119
Validation loss: 3.3859100341796875

Epoch: 6| Step: 7
Training loss: 3.601022481918335
Validation loss: 3.3812463680903115

Epoch: 6| Step: 8
Training loss: 3.2026185989379883
Validation loss: 3.377363999684652

Epoch: 6| Step: 9
Training loss: 2.9409356117248535
Validation loss: 3.371583580970764

Epoch: 6| Step: 10
Training loss: 4.175754547119141
Validation loss: 3.3690956830978394

Epoch: 6| Step: 11
Training loss: 2.680337905883789
Validation loss: 3.3661998510360718

Epoch: 6| Step: 12
Training loss: 4.878060340881348
Validation loss: 3.358994960784912

Epoch: 6| Step: 13
Training loss: 4.014355659484863
Validation loss: 3.3535139560699463

Epoch: 29| Step: 0
Training loss: 3.446220874786377
Validation loss: 3.3503679037094116

Epoch: 6| Step: 1
Training loss: 3.8406150341033936
Validation loss: 3.3461461067199707

Epoch: 6| Step: 2
Training loss: 2.5968422889709473
Validation loss: 3.340817093849182

Epoch: 6| Step: 3
Training loss: 4.1171674728393555
Validation loss: 3.335473418235779

Epoch: 6| Step: 4
Training loss: 3.6321568489074707
Validation loss: 3.3307555119196572

Epoch: 6| Step: 5
Training loss: 4.095630645751953
Validation loss: 3.3257182041803994

Epoch: 6| Step: 6
Training loss: 3.655129909515381
Validation loss: 3.3220014572143555

Epoch: 6| Step: 7
Training loss: 2.9929051399230957
Validation loss: 3.317919929822286

Epoch: 6| Step: 8
Training loss: 3.3285439014434814
Validation loss: 3.31231423219045

Epoch: 6| Step: 9
Training loss: 4.097774505615234
Validation loss: 3.3070939779281616

Epoch: 6| Step: 10
Training loss: 3.5273218154907227
Validation loss: 3.3023109436035156

Epoch: 6| Step: 11
Training loss: 3.2973904609680176
Validation loss: 3.297765930493673

Epoch: 6| Step: 12
Training loss: 3.389599323272705
Validation loss: 3.2942633628845215

Epoch: 6| Step: 13
Training loss: 2.911381244659424
Validation loss: 3.289334853490194

Epoch: 30| Step: 0
Training loss: 2.6897552013397217
Validation loss: 3.2855858405431113

Epoch: 6| Step: 1
Training loss: 2.4540462493896484
Validation loss: 3.281299591064453

Epoch: 6| Step: 2
Training loss: 2.8459291458129883
Validation loss: 3.276863177617391

Epoch: 6| Step: 3
Training loss: 3.352447509765625
Validation loss: 3.2725557486216226

Epoch: 6| Step: 4
Training loss: 3.6971216201782227
Validation loss: 3.2681055068969727

Epoch: 6| Step: 5
Training loss: 3.724419593811035
Validation loss: 3.263495922088623

Epoch: 6| Step: 6
Training loss: 4.403076171875
Validation loss: 3.260233441988627

Epoch: 6| Step: 7
Training loss: 4.243614673614502
Validation loss: 3.2549463907877603

Epoch: 6| Step: 8
Training loss: 2.375622034072876
Validation loss: 3.251351753870646

Epoch: 6| Step: 9
Training loss: 4.071932315826416
Validation loss: 3.246760090192159

Epoch: 6| Step: 10
Training loss: 3.504640579223633
Validation loss: 3.2426305611928306

Epoch: 6| Step: 11
Training loss: 3.517212390899658
Validation loss: 3.2385366360346475

Epoch: 6| Step: 12
Training loss: 3.974562883377075
Validation loss: 3.2334571282068887

Epoch: 6| Step: 13
Training loss: 3.2145142555236816
Validation loss: 3.2290059328079224

Epoch: 31| Step: 0
Training loss: 3.593303680419922
Validation loss: 3.2246301571528115

Epoch: 6| Step: 1
Training loss: 3.303785800933838
Validation loss: 3.219965100288391

Epoch: 6| Step: 2
Training loss: 3.280298948287964
Validation loss: 3.216153144836426

Epoch: 6| Step: 3
Training loss: 3.2823662757873535
Validation loss: 3.2116056283315024

Epoch: 6| Step: 4
Training loss: 3.6986429691314697
Validation loss: 3.2066867351531982

Epoch: 6| Step: 5
Training loss: 3.6569719314575195
Validation loss: 3.203882098197937

Epoch: 6| Step: 6
Training loss: 4.18343448638916
Validation loss: 3.198855439821879

Epoch: 6| Step: 7
Training loss: 2.7857918739318848
Validation loss: 3.1933629910151162

Epoch: 6| Step: 8
Training loss: 2.903421640396118
Validation loss: 3.1893639961878457

Epoch: 6| Step: 9
Training loss: 2.8240320682525635
Validation loss: 3.1849018732706704

Epoch: 6| Step: 10
Training loss: 2.817387819290161
Validation loss: 3.1797446409861245

Epoch: 6| Step: 11
Training loss: 3.322984457015991
Validation loss: 3.175717910130819

Epoch: 6| Step: 12
Training loss: 4.1232686042785645
Validation loss: 3.170677065849304

Epoch: 6| Step: 13
Training loss: 3.5152688026428223
Validation loss: 3.1672882636388144

Epoch: 32| Step: 0
Training loss: 2.0470387935638428
Validation loss: 3.1632145643234253

Epoch: 6| Step: 1
Training loss: 3.306972026824951
Validation loss: 3.1589160760243735

Epoch: 6| Step: 2
Training loss: 3.7966742515563965
Validation loss: 3.1554715236028037

Epoch: 6| Step: 3
Training loss: 3.659966230392456
Validation loss: 3.151335517565409

Epoch: 6| Step: 4
Training loss: 4.437457084655762
Validation loss: 3.1464588244756064

Epoch: 6| Step: 5
Training loss: 3.536983013153076
Validation loss: 3.1424824396769204

Epoch: 6| Step: 6
Training loss: 3.3621504306793213
Validation loss: 3.1384549538294473

Epoch: 6| Step: 7
Training loss: 3.2176334857940674
Validation loss: 3.134456197420756

Epoch: 6| Step: 8
Training loss: 3.6793477535247803
Validation loss: 3.1305349667867026

Epoch: 6| Step: 9
Training loss: 3.2706079483032227
Validation loss: 3.125627795855204

Epoch: 6| Step: 10
Training loss: 2.7077040672302246
Validation loss: 3.1216416358947754

Epoch: 6| Step: 11
Training loss: 3.0356738567352295
Validation loss: 3.1176517407099404

Epoch: 6| Step: 12
Training loss: 3.379945755004883
Validation loss: 3.1128269831339517

Epoch: 6| Step: 13
Training loss: 3.0645766258239746
Validation loss: 3.1100517908732095

Epoch: 33| Step: 0
Training loss: 3.777578115463257
Validation loss: 3.105371634165446

Epoch: 6| Step: 1
Training loss: 3.9561941623687744
Validation loss: 3.104861934979757

Epoch: 6| Step: 2
Training loss: 2.8694872856140137
Validation loss: 3.0972681840260825

Epoch: 6| Step: 3
Training loss: 3.442681312561035
Validation loss: 3.0915279388427734

Epoch: 6| Step: 4
Training loss: 2.7280657291412354
Validation loss: 3.087721586227417

Epoch: 6| Step: 5
Training loss: 3.0495643615722656
Validation loss: 3.0839539766311646

Epoch: 6| Step: 6
Training loss: 2.937291383743286
Validation loss: 3.0801674524943032

Epoch: 6| Step: 7
Training loss: 3.9743900299072266
Validation loss: 3.0769485235214233

Epoch: 6| Step: 8
Training loss: 3.0564794540405273
Validation loss: 3.072998563448588

Epoch: 6| Step: 9
Training loss: 3.3241803646087646
Validation loss: 3.068161129951477

Epoch: 6| Step: 10
Training loss: 2.8682494163513184
Validation loss: 3.063918153444926

Epoch: 6| Step: 11
Training loss: 3.2149858474731445
Validation loss: 3.0605199337005615

Epoch: 6| Step: 12
Training loss: 3.353261709213257
Validation loss: 3.0570515791575112

Epoch: 6| Step: 13
Training loss: 3.1990408897399902
Validation loss: 3.051797111829122

Epoch: 34| Step: 0
Training loss: 3.103646755218506
Validation loss: 3.0485483407974243

Epoch: 6| Step: 1
Training loss: 3.2600345611572266
Validation loss: 3.0455307563145957

Epoch: 6| Step: 2
Training loss: 4.440370082855225
Validation loss: 3.0408939123153687

Epoch: 6| Step: 3
Training loss: 2.1404476165771484
Validation loss: 3.0372267166773477

Epoch: 6| Step: 4
Training loss: 3.2015600204467773
Validation loss: 3.0332305828730264

Epoch: 6| Step: 5
Training loss: 3.694929599761963
Validation loss: 3.0286481380462646

Epoch: 6| Step: 6
Training loss: 3.644815444946289
Validation loss: 3.026716113090515

Epoch: 6| Step: 7
Training loss: 3.1285743713378906
Validation loss: 3.0206923484802246

Epoch: 6| Step: 8
Training loss: 3.4551777839660645
Validation loss: 3.0180227359135947

Epoch: 6| Step: 9
Training loss: 2.9344687461853027
Validation loss: 3.0137608448664346

Epoch: 6| Step: 10
Training loss: 2.8912036418914795
Validation loss: 3.008411169052124

Epoch: 6| Step: 11
Training loss: 3.6805567741394043
Validation loss: 3.0047199726104736

Epoch: 6| Step: 12
Training loss: 2.961188316345215
Validation loss: 2.9985220034917197

Epoch: 6| Step: 13
Training loss: 2.4755587577819824
Validation loss: 2.997290054957072

Epoch: 35| Step: 0
Training loss: 3.7444028854370117
Validation loss: 2.9932570854822793

Epoch: 6| Step: 1
Training loss: 2.667325973510742
Validation loss: 2.993035872777303

Epoch: 6| Step: 2
Training loss: 3.178590774536133
Validation loss: 2.9888879458109536

Epoch: 6| Step: 3
Training loss: 3.3976683616638184
Validation loss: 2.98339315255483

Epoch: 6| Step: 4
Training loss: 3.001614570617676
Validation loss: 2.978295167287191

Epoch: 6| Step: 5
Training loss: 3.768381357192993
Validation loss: 2.9735323786735535

Epoch: 6| Step: 6
Training loss: 2.539323568344116
Validation loss: 2.9684036572774253

Epoch: 6| Step: 7
Training loss: 2.1972250938415527
Validation loss: 2.9658976395924888

Epoch: 6| Step: 8
Training loss: 3.3718342781066895
Validation loss: 2.962620178858439

Epoch: 6| Step: 9
Training loss: 2.9380316734313965
Validation loss: 2.9615967671076455

Epoch: 6| Step: 10
Training loss: 2.8881256580352783
Validation loss: 2.976059635480245

Epoch: 6| Step: 11
Training loss: 3.845909595489502
Validation loss: 2.987579902013143

Epoch: 6| Step: 12
Training loss: 3.153921365737915
Validation loss: 2.950260798136393

Epoch: 6| Step: 13
Training loss: 3.659099578857422
Validation loss: 2.9479953845342

Epoch: 36| Step: 0
Training loss: 3.269899368286133
Validation loss: 2.9536829789479575

Epoch: 6| Step: 1
Training loss: 3.8449387550354004
Validation loss: 2.9624444246292114

Epoch: 6| Step: 2
Training loss: 2.931018114089966
Validation loss: 2.954013546307882

Epoch: 6| Step: 3
Training loss: 4.117684841156006
Validation loss: 2.94128688176473

Epoch: 6| Step: 4
Training loss: 1.84176504611969
Validation loss: 2.9307283957799277

Epoch: 6| Step: 5
Training loss: 3.11734676361084
Validation loss: 2.924867033958435

Epoch: 6| Step: 6
Training loss: 2.2808213233947754
Validation loss: 2.9187567234039307

Epoch: 6| Step: 7
Training loss: 2.9064979553222656
Validation loss: 2.9172092278798423

Epoch: 6| Step: 8
Training loss: 3.044362783432007
Validation loss: 2.9131245613098145

Epoch: 6| Step: 9
Training loss: 3.43192195892334
Validation loss: 2.911126891771952

Epoch: 6| Step: 10
Training loss: 4.079406261444092
Validation loss: 2.9076868693033853

Epoch: 6| Step: 11
Training loss: 3.2019870281219482
Validation loss: 2.9045775334040322

Epoch: 6| Step: 12
Training loss: 3.084613084793091
Validation loss: 2.900208671887716

Epoch: 6| Step: 13
Training loss: 2.6153717041015625
Validation loss: 2.8986838261286416

Epoch: 37| Step: 0
Training loss: 3.8036704063415527
Validation loss: 2.891870101292928

Epoch: 6| Step: 1
Training loss: 2.5775327682495117
Validation loss: 2.888618270556132

Epoch: 6| Step: 2
Training loss: 2.421579360961914
Validation loss: 2.884661634763082

Epoch: 6| Step: 3
Training loss: 3.483374834060669
Validation loss: 2.8848647276560464

Epoch: 6| Step: 4
Training loss: 2.893730640411377
Validation loss: 2.8897976875305176

Epoch: 6| Step: 5
Training loss: 3.582444190979004
Validation loss: 2.8769514163335166

Epoch: 6| Step: 6
Training loss: 3.555905818939209
Validation loss: 2.8718560139338174

Epoch: 6| Step: 7
Training loss: 3.1023387908935547
Validation loss: 2.8670026461283364

Epoch: 6| Step: 8
Training loss: 2.414003372192383
Validation loss: 2.8633522590001426

Epoch: 6| Step: 9
Training loss: 3.8422975540161133
Validation loss: 2.8608757654825845

Epoch: 6| Step: 10
Training loss: 2.223557472229004
Validation loss: 2.8569238583246865

Epoch: 6| Step: 11
Training loss: 2.9722986221313477
Validation loss: 2.8527920246124268

Epoch: 6| Step: 12
Training loss: 2.637331008911133
Validation loss: 2.8502933184305825

Epoch: 6| Step: 13
Training loss: 3.4978244304656982
Validation loss: 2.842893640200297

Epoch: 38| Step: 0
Training loss: 2.8637046813964844
Validation loss: 2.8412906726201377

Epoch: 6| Step: 1
Training loss: 3.2514452934265137
Validation loss: 2.8406523068745932

Epoch: 6| Step: 2
Training loss: 2.476841449737549
Validation loss: 2.83347495396932

Epoch: 6| Step: 3
Training loss: 3.011653423309326
Validation loss: 2.831051508585612

Epoch: 6| Step: 4
Training loss: 2.7661633491516113
Validation loss: 2.826501409212748

Epoch: 6| Step: 5
Training loss: 2.690711736679077
Validation loss: 2.8221959273020425

Epoch: 6| Step: 6
Training loss: 3.0264506340026855
Validation loss: 2.818447709083557

Epoch: 6| Step: 7
Training loss: 2.298917770385742
Validation loss: 2.8177583614985147

Epoch: 6| Step: 8
Training loss: 3.3140459060668945
Validation loss: 2.8136887152989707

Epoch: 6| Step: 9
Training loss: 2.831486940383911
Validation loss: 2.809040625890096

Epoch: 6| Step: 10
Training loss: 3.4603161811828613
Validation loss: 2.809856414794922

Epoch: 6| Step: 11
Training loss: 2.8563525676727295
Validation loss: 2.806440075238546

Epoch: 6| Step: 12
Training loss: 3.892671823501587
Validation loss: 2.80260161558787

Epoch: 6| Step: 13
Training loss: 3.6326680183410645
Validation loss: 2.797448515892029

Epoch: 39| Step: 0
Training loss: 3.421557664871216
Validation loss: 2.7940669854482016

Epoch: 6| Step: 1
Training loss: 2.2252004146575928
Validation loss: 2.78842560450236

Epoch: 6| Step: 2
Training loss: 3.0058228969573975
Validation loss: 2.787965973218282

Epoch: 6| Step: 3
Training loss: 2.7785611152648926
Validation loss: 2.7836390336354575

Epoch: 6| Step: 4
Training loss: 2.736286163330078
Validation loss: 2.7790496746699014

Epoch: 6| Step: 5
Training loss: 2.024229049682617
Validation loss: 2.7785441478093467

Epoch: 6| Step: 6
Training loss: 3.016862154006958
Validation loss: 2.773534337679545

Epoch: 6| Step: 7
Training loss: 3.8811047077178955
Validation loss: 2.772927244504293

Epoch: 6| Step: 8
Training loss: 2.693182945251465
Validation loss: 2.7687312364578247

Epoch: 6| Step: 9
Training loss: 3.5663833618164062
Validation loss: 2.764749050140381

Epoch: 6| Step: 10
Training loss: 3.306698799133301
Validation loss: 2.7620275020599365

Epoch: 6| Step: 11
Training loss: 3.4028334617614746
Validation loss: 2.7598816951115928

Epoch: 6| Step: 12
Training loss: 2.6259212493896484
Validation loss: 2.755855600039164

Epoch: 6| Step: 13
Training loss: 2.9955544471740723
Validation loss: 2.7535581588745117

Epoch: 40| Step: 0
Training loss: 3.2175183296203613
Validation loss: 2.751185635725657

Epoch: 6| Step: 1
Training loss: 2.4911773204803467
Validation loss: 2.750479221343994

Epoch: 6| Step: 2
Training loss: 2.2044026851654053
Validation loss: 2.7502272526423135

Epoch: 6| Step: 3
Training loss: 2.89987850189209
Validation loss: 2.739923675855001

Epoch: 6| Step: 4
Training loss: 3.63076114654541
Validation loss: 2.7363690535227456

Epoch: 6| Step: 5
Training loss: 2.882230520248413
Validation loss: 2.7352838118871055

Epoch: 6| Step: 6
Training loss: 3.8446438312530518
Validation loss: 2.7361401319503784

Epoch: 6| Step: 7
Training loss: 3.2500624656677246
Validation loss: 2.731783310572306

Epoch: 6| Step: 8
Training loss: 2.631131887435913
Validation loss: 2.7265659968058267

Epoch: 6| Step: 9
Training loss: 3.4900460243225098
Validation loss: 2.7224531173706055

Epoch: 6| Step: 10
Training loss: 2.7632884979248047
Validation loss: 2.7205934127171836

Epoch: 6| Step: 11
Training loss: 3.395512342453003
Validation loss: 2.7191069523493447

Epoch: 6| Step: 12
Training loss: 2.5158281326293945
Validation loss: 2.7150171995162964

Epoch: 6| Step: 13
Training loss: 1.9036369323730469
Validation loss: 2.709549903869629

Epoch: 41| Step: 0
Training loss: 2.868530750274658
Validation loss: 2.707162539164225

Epoch: 6| Step: 1
Training loss: 2.531390428543091
Validation loss: 2.705847462018331

Epoch: 6| Step: 2
Training loss: 3.4906983375549316
Validation loss: 2.7018374601999917

Epoch: 6| Step: 3
Training loss: 2.6350059509277344
Validation loss: 2.6997965971628823

Epoch: 6| Step: 4
Training loss: 3.379108190536499
Validation loss: 2.696409205595652

Epoch: 6| Step: 5
Training loss: 2.6828136444091797
Validation loss: 2.69425896803538

Epoch: 6| Step: 6
Training loss: 2.7058358192443848
Validation loss: 2.6910594701766968

Epoch: 6| Step: 7
Training loss: 2.0348289012908936
Validation loss: 2.6867485841115317

Epoch: 6| Step: 8
Training loss: 3.53074049949646
Validation loss: 2.6840729316075644

Epoch: 6| Step: 9
Training loss: 3.3649492263793945
Validation loss: 2.677767038345337

Epoch: 6| Step: 10
Training loss: 2.545670986175537
Validation loss: 2.675320585568746

Epoch: 6| Step: 11
Training loss: 2.74245023727417
Validation loss: 2.6713717381159463

Epoch: 6| Step: 12
Training loss: 3.374187469482422
Validation loss: 2.6677751938501992

Epoch: 6| Step: 13
Training loss: 2.6171178817749023
Validation loss: 2.6608837048212686

Epoch: 42| Step: 0
Training loss: 2.1210827827453613
Validation loss: 2.661470333735148

Epoch: 6| Step: 1
Training loss: 3.3593547344207764
Validation loss: 2.658334652582804

Epoch: 6| Step: 2
Training loss: 2.9558310508728027
Validation loss: 2.655385216077169

Epoch: 6| Step: 3
Training loss: 2.5052363872528076
Validation loss: 2.650997837384542

Epoch: 6| Step: 4
Training loss: 2.788039207458496
Validation loss: 2.646839698155721

Epoch: 6| Step: 5
Training loss: 3.0656137466430664
Validation loss: 2.643376588821411

Epoch: 6| Step: 6
Training loss: 2.887935161590576
Validation loss: 2.6392802000045776

Epoch: 6| Step: 7
Training loss: 3.0652384757995605
Validation loss: 2.636932293574015

Epoch: 6| Step: 8
Training loss: 2.59602689743042
Validation loss: 2.6336395343144736

Epoch: 6| Step: 9
Training loss: 2.9912121295928955
Validation loss: 2.6325084368387857

Epoch: 6| Step: 10
Training loss: 3.131161689758301
Validation loss: 2.627283970514933

Epoch: 6| Step: 11
Training loss: 2.567232131958008
Validation loss: 2.6232639153798423

Epoch: 6| Step: 12
Training loss: 2.5412979125976562
Validation loss: 2.618703027566274

Epoch: 6| Step: 13
Training loss: 3.2400424480438232
Validation loss: 2.6144989331563315

Epoch: 43| Step: 0
Training loss: 2.8737149238586426
Validation loss: 2.6144162019093833

Epoch: 6| Step: 1
Training loss: 2.861482620239258
Validation loss: 2.6098407904307046

Epoch: 6| Step: 2
Training loss: 2.9185025691986084
Validation loss: 2.6087525288263955

Epoch: 6| Step: 3
Training loss: 3.1298959255218506
Validation loss: 2.6088063716888428

Epoch: 6| Step: 4
Training loss: 2.5431394577026367
Validation loss: 2.602194627126058

Epoch: 6| Step: 5
Training loss: 2.254073143005371
Validation loss: 2.604963779449463

Epoch: 6| Step: 6
Training loss: 2.682114362716675
Validation loss: 2.5958927075068154

Epoch: 6| Step: 7
Training loss: 3.171426296234131
Validation loss: 2.593587040901184

Epoch: 6| Step: 8
Training loss: 2.552713394165039
Validation loss: 2.590984662373861

Epoch: 6| Step: 9
Training loss: 3.064556121826172
Validation loss: 2.585407773653666

Epoch: 6| Step: 10
Training loss: 2.4605491161346436
Validation loss: 2.5826141436894736

Epoch: 6| Step: 11
Training loss: 2.712698221206665
Validation loss: 2.580753445625305

Epoch: 6| Step: 12
Training loss: 2.4813144207000732
Validation loss: 2.577387491861979

Epoch: 6| Step: 13
Training loss: 3.3859968185424805
Validation loss: 2.5762911637624106

Epoch: 44| Step: 0
Training loss: 2.685251474380493
Validation loss: 2.574413776397705

Epoch: 6| Step: 1
Training loss: 2.260240077972412
Validation loss: 2.567185719807943

Epoch: 6| Step: 2
Training loss: 3.0066046714782715
Validation loss: 2.561323086420695

Epoch: 6| Step: 3
Training loss: 2.6368894577026367
Validation loss: 2.5623183647791543

Epoch: 6| Step: 4
Training loss: 2.5908031463623047
Validation loss: 2.558944344520569

Epoch: 6| Step: 5
Training loss: 3.1616196632385254
Validation loss: 2.559848189353943

Epoch: 6| Step: 6
Training loss: 2.4799070358276367
Validation loss: 2.551839212576548

Epoch: 6| Step: 7
Training loss: 3.078742027282715
Validation loss: 2.5497421423594155

Epoch: 6| Step: 8
Training loss: 2.778219699859619
Validation loss: 2.5532077153523765

Epoch: 6| Step: 9
Training loss: 2.3354365825653076
Validation loss: 2.5457367499669394

Epoch: 6| Step: 10
Training loss: 2.9934592247009277
Validation loss: 2.5443268616994223

Epoch: 6| Step: 11
Training loss: 2.7481651306152344
Validation loss: 2.535713036855062

Epoch: 6| Step: 12
Training loss: 2.707005023956299
Validation loss: 2.5369801123936973

Epoch: 6| Step: 13
Training loss: 2.9715044498443604
Validation loss: 2.5355023940404258

Epoch: 45| Step: 0
Training loss: 2.911876678466797
Validation loss: 2.5305920044581094

Epoch: 6| Step: 1
Training loss: 3.0793275833129883
Validation loss: 2.5265886386235556

Epoch: 6| Step: 2
Training loss: 2.778209924697876
Validation loss: 2.5219563643137612

Epoch: 6| Step: 3
Training loss: 2.9079716205596924
Validation loss: 2.5230201482772827

Epoch: 6| Step: 4
Training loss: 2.479005813598633
Validation loss: 2.522446314493815

Epoch: 6| Step: 5
Training loss: 2.387260913848877
Validation loss: 2.521983285744985

Epoch: 6| Step: 6
Training loss: 3.3170154094696045
Validation loss: 2.5166096289952598

Epoch: 6| Step: 7
Training loss: 2.892723321914673
Validation loss: 2.513472636540731

Epoch: 6| Step: 8
Training loss: 3.045759916305542
Validation loss: 2.5092583100001016

Epoch: 6| Step: 9
Training loss: 2.0941622257232666
Validation loss: 2.506342053413391

Epoch: 6| Step: 10
Training loss: 2.661564826965332
Validation loss: 2.504482706387838

Epoch: 6| Step: 11
Training loss: 2.834920883178711
Validation loss: 2.4981863498687744

Epoch: 6| Step: 12
Training loss: 2.088409423828125
Validation loss: 2.493244449297587

Epoch: 6| Step: 13
Training loss: 2.455519437789917
Validation loss: 2.4906871716181436

Epoch: 46| Step: 0
Training loss: 2.4610233306884766
Validation loss: 2.4863833586374917

Epoch: 6| Step: 1
Training loss: 2.687685489654541
Validation loss: 2.4869781732559204

Epoch: 6| Step: 2
Training loss: 2.8534088134765625
Validation loss: 2.480918824672699

Epoch: 6| Step: 3
Training loss: 2.6798012256622314
Validation loss: 2.481667677561442

Epoch: 6| Step: 4
Training loss: 2.333728075027466
Validation loss: 2.4809968868891397

Epoch: 6| Step: 5
Training loss: 2.7124667167663574
Validation loss: 2.4758463303248086

Epoch: 6| Step: 6
Training loss: 1.9106333255767822
Validation loss: 2.471258004506429

Epoch: 6| Step: 7
Training loss: 3.1621131896972656
Validation loss: 2.4697118997573853

Epoch: 6| Step: 8
Training loss: 1.940992832183838
Validation loss: 2.473549763361613

Epoch: 6| Step: 9
Training loss: 2.2958436012268066
Validation loss: 2.470418612162272

Epoch: 6| Step: 10
Training loss: 3.1391751766204834
Validation loss: 2.468445618947347

Epoch: 6| Step: 11
Training loss: 3.4979336261749268
Validation loss: 2.4611034790674844

Epoch: 6| Step: 12
Training loss: 2.976445436477661
Validation loss: 2.4565603335698447

Epoch: 6| Step: 13
Training loss: 2.6306426525115967
Validation loss: 2.4559550285339355

Epoch: 47| Step: 0
Training loss: 2.6441690921783447
Validation loss: 2.450953960418701

Epoch: 6| Step: 1
Training loss: 3.074920654296875
Validation loss: 2.454169968763987

Epoch: 6| Step: 2
Training loss: 1.5978466272354126
Validation loss: 2.4498908519744873

Epoch: 6| Step: 3
Training loss: 2.6835405826568604
Validation loss: 2.445975104967753

Epoch: 6| Step: 4
Training loss: 3.091963768005371
Validation loss: 2.4441685676574707

Epoch: 6| Step: 5
Training loss: 2.5919852256774902
Validation loss: 2.4378955960273743

Epoch: 6| Step: 6
Training loss: 3.123483419418335
Validation loss: 2.434313694636027

Epoch: 6| Step: 7
Training loss: 2.238313674926758
Validation loss: 2.439988593260447

Epoch: 6| Step: 8
Training loss: 2.524320125579834
Validation loss: 2.4316522081693015

Epoch: 6| Step: 9
Training loss: 2.691423177719116
Validation loss: 2.4296273787816367

Epoch: 6| Step: 10
Training loss: 2.9523191452026367
Validation loss: 2.427842934926351

Epoch: 6| Step: 11
Training loss: 2.660489797592163
Validation loss: 2.4226227601369223

Epoch: 6| Step: 12
Training loss: 2.379786729812622
Validation loss: 2.420914888381958

Epoch: 6| Step: 13
Training loss: 2.4300200939178467
Validation loss: 2.4161545038223267

Epoch: 48| Step: 0
Training loss: 2.8593456745147705
Validation loss: 2.4126424392064414

Epoch: 6| Step: 1
Training loss: 2.6020469665527344
Validation loss: 2.4094952742258706

Epoch: 6| Step: 2
Training loss: 2.074601888656616
Validation loss: 2.406972587108612

Epoch: 6| Step: 3
Training loss: 2.9447882175445557
Validation loss: 2.406966249148051

Epoch: 6| Step: 4
Training loss: 2.2657389640808105
Validation loss: 2.402949055035909

Epoch: 6| Step: 5
Training loss: 2.5737926959991455
Validation loss: 2.3975494305292764

Epoch: 6| Step: 6
Training loss: 1.765956997871399
Validation loss: 2.400648077329

Epoch: 6| Step: 7
Training loss: 3.0063252449035645
Validation loss: 2.3970323403676352

Epoch: 6| Step: 8
Training loss: 2.4149856567382812
Validation loss: 2.3927293618520102

Epoch: 6| Step: 9
Training loss: 2.921298027038574
Validation loss: 2.3933711647987366

Epoch: 6| Step: 10
Training loss: 2.097689151763916
Validation loss: 2.389847218990326

Epoch: 6| Step: 11
Training loss: 2.6783015727996826
Validation loss: 2.3870264689127603

Epoch: 6| Step: 12
Training loss: 2.4531407356262207
Validation loss: 2.3841418822606406

Epoch: 6| Step: 13
Training loss: 3.42962646484375
Validation loss: 2.381902356942495

Epoch: 49| Step: 0
Training loss: 2.6255736351013184
Validation loss: 2.3829797506332397

Epoch: 6| Step: 1
Training loss: 2.556903839111328
Validation loss: 2.377194801966349

Epoch: 6| Step: 2
Training loss: 2.2395150661468506
Validation loss: 2.3738056818644204

Epoch: 6| Step: 3
Training loss: 2.1240596771240234
Validation loss: 2.3745601574579873

Epoch: 6| Step: 4
Training loss: 3.1327834129333496
Validation loss: 2.37304425239563

Epoch: 6| Step: 5
Training loss: 2.351140260696411
Validation loss: 2.3694961269696555

Epoch: 6| Step: 6
Training loss: 2.628037214279175
Validation loss: 2.363759477933248

Epoch: 6| Step: 7
Training loss: 1.8423593044281006
Validation loss: 2.36282217502594

Epoch: 6| Step: 8
Training loss: 1.8026484251022339
Validation loss: 2.362242877483368

Epoch: 6| Step: 9
Training loss: 2.845080614089966
Validation loss: 2.3592852354049683

Epoch: 6| Step: 10
Training loss: 2.4157843589782715
Validation loss: 2.3532740672429404

Epoch: 6| Step: 11
Training loss: 3.2373335361480713
Validation loss: 2.357252518335978

Epoch: 6| Step: 12
Training loss: 3.140576124191284
Validation loss: 2.3538708686828613

Epoch: 6| Step: 13
Training loss: 2.6269607543945312
Validation loss: 2.3521515130996704

Epoch: 50| Step: 0
Training loss: 2.5075509548187256
Validation loss: 2.3510939280192056

Epoch: 6| Step: 1
Training loss: 2.643000602722168
Validation loss: 2.3493075569470725

Epoch: 6| Step: 2
Training loss: 2.5663700103759766
Validation loss: 2.345665713151296

Epoch: 6| Step: 3
Training loss: 2.5151278972625732
Validation loss: 2.343859394391378

Epoch: 6| Step: 4
Training loss: 2.9161062240600586
Validation loss: 2.3418569366137185

Epoch: 6| Step: 5
Training loss: 2.5651822090148926
Validation loss: 2.3395399252573648

Epoch: 6| Step: 6
Training loss: 2.439821720123291
Validation loss: 2.3358554442723594

Epoch: 6| Step: 7
Training loss: 2.954758405685425
Validation loss: 2.3316129247347512

Epoch: 6| Step: 8
Training loss: 2.592942714691162
Validation loss: 2.3298405408859253

Epoch: 6| Step: 9
Training loss: 2.8738958835601807
Validation loss: 2.324283182621002

Epoch: 6| Step: 10
Training loss: 1.955603837966919
Validation loss: 2.3183241287867227

Epoch: 6| Step: 11
Training loss: 3.008937358856201
Validation loss: 2.3149306774139404

Epoch: 6| Step: 12
Training loss: 1.8776153326034546
Validation loss: 2.3145635525385537

Epoch: 6| Step: 13
Training loss: 1.5578632354736328
Validation loss: 2.3162753582000732

Epoch: 51| Step: 0
Training loss: 2.6701648235321045
Validation loss: 2.314510782559713

Epoch: 6| Step: 1
Training loss: 2.049093008041382
Validation loss: 2.315869688987732

Epoch: 6| Step: 2
Training loss: 2.6171634197235107
Validation loss: 2.325283467769623

Epoch: 6| Step: 3
Training loss: 1.6226649284362793
Validation loss: 2.3285128275553384

Epoch: 6| Step: 4
Training loss: 2.959012508392334
Validation loss: 2.332083741823832

Epoch: 6| Step: 5
Training loss: 2.533771514892578
Validation loss: 2.3129908641179404

Epoch: 6| Step: 6
Training loss: 2.1451187133789062
Validation loss: 2.2999327778816223

Epoch: 6| Step: 7
Training loss: 3.248420238494873
Validation loss: 2.2995773553848267

Epoch: 6| Step: 8
Training loss: 2.2366037368774414
Validation loss: 2.2921903133392334

Epoch: 6| Step: 9
Training loss: 2.486727237701416
Validation loss: 2.3038258949915567

Epoch: 6| Step: 10
Training loss: 2.70043683052063
Validation loss: 2.305987596511841

Epoch: 6| Step: 11
Training loss: 2.3879473209381104
Validation loss: 2.3095144629478455

Epoch: 6| Step: 12
Training loss: 2.71951961517334
Validation loss: 2.3089704116185508

Epoch: 6| Step: 13
Training loss: 2.203190803527832
Validation loss: 2.302622218926748

Epoch: 52| Step: 0
Training loss: 2.283785343170166
Validation loss: 2.296838919321696

Epoch: 6| Step: 1
Training loss: 2.929098129272461
Validation loss: 2.2953344782193503

Epoch: 6| Step: 2
Training loss: 2.700054407119751
Validation loss: 2.287478486696879

Epoch: 6| Step: 3
Training loss: 2.2033450603485107
Validation loss: 2.2862406571706138

Epoch: 6| Step: 4
Training loss: 2.4148037433624268
Validation loss: 2.2837294737497964

Epoch: 6| Step: 5
Training loss: 1.9117218255996704
Validation loss: 2.274982233842214

Epoch: 6| Step: 6
Training loss: 2.312199592590332
Validation loss: 2.2750518520673118

Epoch: 6| Step: 7
Training loss: 2.4444668292999268
Validation loss: 2.272061268488566

Epoch: 6| Step: 8
Training loss: 2.6712427139282227
Validation loss: 2.262014369169871

Epoch: 6| Step: 9
Training loss: 2.587594985961914
Validation loss: 2.259082635243734

Epoch: 6| Step: 10
Training loss: 2.426642894744873
Validation loss: 2.257622241973877

Epoch: 6| Step: 11
Training loss: 2.4107985496520996
Validation loss: 2.2617196440696716

Epoch: 6| Step: 12
Training loss: 2.1758673191070557
Validation loss: 2.2595372597376504

Epoch: 6| Step: 13
Training loss: 2.6751961708068848
Validation loss: 2.258585751056671

Epoch: 53| Step: 0
Training loss: 2.9195311069488525
Validation loss: 2.2541146675745645

Epoch: 6| Step: 1
Training loss: 2.373692035675049
Validation loss: 2.2482683261235556

Epoch: 6| Step: 2
Training loss: 2.559903621673584
Validation loss: 2.244242231051127

Epoch: 6| Step: 3
Training loss: 2.577768087387085
Validation loss: 2.2455506920814514

Epoch: 6| Step: 4
Training loss: 1.966304063796997
Validation loss: 2.241289814313253

Epoch: 6| Step: 5
Training loss: 2.2925548553466797
Validation loss: 2.240866243839264

Epoch: 6| Step: 6
Training loss: 1.8287158012390137
Validation loss: 2.2401810685793557

Epoch: 6| Step: 7
Training loss: 2.724087715148926
Validation loss: 2.236716349919637

Epoch: 6| Step: 8
Training loss: 2.3531603813171387
Validation loss: 2.233209490776062

Epoch: 6| Step: 9
Training loss: 2.145969867706299
Validation loss: 2.2284080386161804

Epoch: 6| Step: 10
Training loss: 2.7604329586029053
Validation loss: 2.2254883845647178

Epoch: 6| Step: 11
Training loss: 2.2507524490356445
Validation loss: 2.227048178513845

Epoch: 6| Step: 12
Training loss: 2.5669851303100586
Validation loss: 2.2262178460756936

Epoch: 6| Step: 13
Training loss: 2.1632189750671387
Validation loss: 2.223650415738424

Epoch: 54| Step: 0
Training loss: 2.891794204711914
Validation loss: 2.2242700854937234

Epoch: 6| Step: 1
Training loss: 2.279052257537842
Validation loss: 2.2312088012695312

Epoch: 6| Step: 2
Training loss: 2.9289307594299316
Validation loss: 2.225173234939575

Epoch: 6| Step: 3
Training loss: 2.3998782634735107
Validation loss: 2.2137098908424377

Epoch: 6| Step: 4
Training loss: 2.4542617797851562
Validation loss: 2.2171742916107178

Epoch: 6| Step: 5
Training loss: 2.2029497623443604
Validation loss: 2.2176836729049683

Epoch: 6| Step: 6
Training loss: 2.235682964324951
Validation loss: 2.210097829500834

Epoch: 6| Step: 7
Training loss: 2.1064634323120117
Validation loss: 2.206308921178182

Epoch: 6| Step: 8
Training loss: 2.638864517211914
Validation loss: 2.2132455507914224

Epoch: 6| Step: 9
Training loss: 2.3190455436706543
Validation loss: 2.2164169748624167

Epoch: 6| Step: 10
Training loss: 2.193270206451416
Validation loss: 2.2118686040242515

Epoch: 6| Step: 11
Training loss: 1.8416485786437988
Validation loss: 2.204290429751078

Epoch: 6| Step: 12
Training loss: 1.8965907096862793
Validation loss: 2.1997708479563394

Epoch: 6| Step: 13
Training loss: 2.734971523284912
Validation loss: 2.2084886034329734

Epoch: 55| Step: 0
Training loss: 2.497741222381592
Validation loss: 2.195505062739054

Epoch: 6| Step: 1
Training loss: 2.423551321029663
Validation loss: 2.1886675556500754

Epoch: 6| Step: 2
Training loss: 2.6769373416900635
Validation loss: 2.189576268196106

Epoch: 6| Step: 3
Training loss: 2.8873863220214844
Validation loss: 2.1929969986279807

Epoch: 6| Step: 4
Training loss: 2.4059767723083496
Validation loss: 2.1919596989949546

Epoch: 6| Step: 5
Training loss: 3.0267910957336426
Validation loss: 2.1875511606534324

Epoch: 6| Step: 6
Training loss: 2.0727686882019043
Validation loss: 2.1947840650876365

Epoch: 6| Step: 7
Training loss: 1.5307624340057373
Validation loss: 2.1874125003814697

Epoch: 6| Step: 8
Training loss: 1.8244361877441406
Validation loss: 2.1929962436358132

Epoch: 6| Step: 9
Training loss: 2.597313404083252
Validation loss: 2.188749631245931

Epoch: 6| Step: 10
Training loss: 2.208197593688965
Validation loss: 2.180606484413147

Epoch: 6| Step: 11
Training loss: 1.9743133783340454
Validation loss: 2.184782306353251

Epoch: 6| Step: 12
Training loss: 2.1067991256713867
Validation loss: 2.1834221879641214

Epoch: 6| Step: 13
Training loss: 2.644636392593384
Validation loss: 2.1854533553123474

Epoch: 56| Step: 0
Training loss: 2.6658260822296143
Validation loss: 2.181974689165751

Epoch: 6| Step: 1
Training loss: 2.467434883117676
Validation loss: 2.1738274097442627

Epoch: 6| Step: 2
Training loss: 2.6876258850097656
Validation loss: 2.1728784640630088

Epoch: 6| Step: 3
Training loss: 3.051837921142578
Validation loss: 2.1767979661623635

Epoch: 6| Step: 4
Training loss: 2.5469648838043213
Validation loss: 2.1736137866973877

Epoch: 6| Step: 5
Training loss: 2.034858226776123
Validation loss: 2.181897521018982

Epoch: 6| Step: 6
Training loss: 2.240157127380371
Validation loss: 2.18174817164739

Epoch: 6| Step: 7
Training loss: 2.005765914916992
Validation loss: 2.1819244027137756

Epoch: 6| Step: 8
Training loss: 2.3588485717773438
Validation loss: 2.1799403031667075

Epoch: 6| Step: 9
Training loss: 2.1077022552490234
Validation loss: 2.1702094674110413

Epoch: 6| Step: 10
Training loss: 2.007826089859009
Validation loss: 2.1620245774586997

Epoch: 6| Step: 11
Training loss: 2.7624051570892334
Validation loss: 2.1639561454455056

Epoch: 6| Step: 12
Training loss: 1.9960777759552002
Validation loss: 2.1661643385887146

Epoch: 6| Step: 13
Training loss: 1.693340539932251
Validation loss: 2.1692957878112793

Epoch: 57| Step: 0
Training loss: 2.6326169967651367
Validation loss: 2.160665591557821

Epoch: 6| Step: 1
Training loss: 2.2341551780700684
Validation loss: 2.158160368601481

Epoch: 6| Step: 2
Training loss: 2.2785158157348633
Validation loss: 2.1527721087137857

Epoch: 6| Step: 3
Training loss: 2.075113296508789
Validation loss: 2.1520100831985474

Epoch: 6| Step: 4
Training loss: 2.50758695602417
Validation loss: 2.1568210124969482

Epoch: 6| Step: 5
Training loss: 1.9375619888305664
Validation loss: 2.1549889047940574

Epoch: 6| Step: 6
Training loss: 2.506260395050049
Validation loss: 2.1518730521202087

Epoch: 6| Step: 7
Training loss: 2.039836883544922
Validation loss: 2.150438408056895

Epoch: 6| Step: 8
Training loss: 1.9581749439239502
Validation loss: 2.1682864228884378

Epoch: 6| Step: 9
Training loss: 2.232306957244873
Validation loss: 2.14517072836558

Epoch: 6| Step: 10
Training loss: 2.4899935722351074
Validation loss: 2.1438024441401162

Epoch: 6| Step: 11
Training loss: 2.538193702697754
Validation loss: 2.1509936253229776

Epoch: 6| Step: 12
Training loss: 2.3922386169433594
Validation loss: 2.150994618733724

Epoch: 6| Step: 13
Training loss: 2.422147035598755
Validation loss: 2.1581438183784485

Epoch: 58| Step: 0
Training loss: 1.991267204284668
Validation loss: 2.159122586250305

Epoch: 6| Step: 1
Training loss: 2.064387083053589
Validation loss: 2.1681652466456094

Epoch: 6| Step: 2
Training loss: 2.1782617568969727
Validation loss: 2.1711965203285217

Epoch: 6| Step: 3
Training loss: 2.2248947620391846
Validation loss: 2.1754987637201944

Epoch: 6| Step: 4
Training loss: 2.203810691833496
Validation loss: 2.160086234410604

Epoch: 6| Step: 5
Training loss: 2.114635944366455
Validation loss: 2.1565027236938477

Epoch: 6| Step: 6
Training loss: 2.2860376834869385
Validation loss: 2.146315594514211

Epoch: 6| Step: 7
Training loss: 2.6481502056121826
Validation loss: 2.1474153796831765

Epoch: 6| Step: 8
Training loss: 1.8741834163665771
Validation loss: 2.1426063776016235

Epoch: 6| Step: 9
Training loss: 2.5964865684509277
Validation loss: 2.145704746246338

Epoch: 6| Step: 10
Training loss: 2.2283363342285156
Validation loss: 2.1353853146235147

Epoch: 6| Step: 11
Training loss: 2.5006754398345947
Validation loss: 2.1320797403653464

Epoch: 6| Step: 12
Training loss: 2.8788158893585205
Validation loss: 2.1290882229804993

Epoch: 6| Step: 13
Training loss: 2.425673007965088
Validation loss: 2.1379657785097756

Epoch: 59| Step: 0
Training loss: 2.3888182640075684
Validation loss: 2.1390084624290466

Epoch: 6| Step: 1
Training loss: 2.2086291313171387
Validation loss: 2.1666540106137595

Epoch: 6| Step: 2
Training loss: 2.2534432411193848
Validation loss: 2.161375125249227

Epoch: 6| Step: 3
Training loss: 2.2917933464050293
Validation loss: 2.189173936843872

Epoch: 6| Step: 4
Training loss: 2.19893217086792
Validation loss: 2.2171671787897744

Epoch: 6| Step: 5
Training loss: 2.3798255920410156
Validation loss: 2.260353128115336

Epoch: 6| Step: 6
Training loss: 2.2163233757019043
Validation loss: 2.172257204850515

Epoch: 6| Step: 7
Training loss: 2.78369402885437
Validation loss: 2.139853358268738

Epoch: 6| Step: 8
Training loss: 2.5406486988067627
Validation loss: 2.124520242214203

Epoch: 6| Step: 9
Training loss: 2.4148659706115723
Validation loss: 2.12832248210907

Epoch: 6| Step: 10
Training loss: 2.1651337146759033
Validation loss: 2.151140252749125

Epoch: 6| Step: 11
Training loss: 1.9493179321289062
Validation loss: 2.1740453441937766

Epoch: 6| Step: 12
Training loss: 1.9467629194259644
Validation loss: 2.2009005149205527

Epoch: 6| Step: 13
Training loss: 2.536917209625244
Validation loss: 2.2191419998804727

Epoch: 60| Step: 0
Training loss: 2.595688819885254
Validation loss: 2.210288643836975

Epoch: 6| Step: 1
Training loss: 1.9440867900848389
Validation loss: 2.2043269276618958

Epoch: 6| Step: 2
Training loss: 2.176588535308838
Validation loss: 2.1750969886779785

Epoch: 6| Step: 3
Training loss: 2.061800718307495
Validation loss: 2.1501107613245645

Epoch: 6| Step: 4
Training loss: 2.062955141067505
Validation loss: 2.1364293098449707

Epoch: 6| Step: 5
Training loss: 3.0193228721618652
Validation loss: 2.1364526748657227

Epoch: 6| Step: 6
Training loss: 1.6411266326904297
Validation loss: 2.133701761563619

Epoch: 6| Step: 7
Training loss: 2.353073835372925
Validation loss: 2.128724197546641

Epoch: 6| Step: 8
Training loss: 2.0909769535064697
Validation loss: 2.126655101776123

Epoch: 6| Step: 9
Training loss: 2.3070921897888184
Validation loss: 2.124476909637451

Epoch: 6| Step: 10
Training loss: 2.110275983810425
Validation loss: 2.1148333748181662

Epoch: 6| Step: 11
Training loss: 2.5950684547424316
Validation loss: 2.1069753170013428

Epoch: 6| Step: 12
Training loss: 2.785158157348633
Validation loss: 2.105946203072866

Epoch: 6| Step: 13
Training loss: 2.5972657203674316
Validation loss: 2.0974259773890176

Epoch: 61| Step: 0
Training loss: 2.8953967094421387
Validation loss: 2.101218362649282

Epoch: 6| Step: 1
Training loss: 1.4403842687606812
Validation loss: 2.0958962440490723

Epoch: 6| Step: 2
Training loss: 2.16454815864563
Validation loss: 2.130257864793142

Epoch: 6| Step: 3
Training loss: 2.408170223236084
Validation loss: 2.1511264642079673

Epoch: 6| Step: 4
Training loss: 2.6008362770080566
Validation loss: 2.134851038455963

Epoch: 6| Step: 5
Training loss: 2.319619655609131
Validation loss: 2.11545991897583

Epoch: 6| Step: 6
Training loss: 1.9345682859420776
Validation loss: 2.1085435152053833

Epoch: 6| Step: 7
Training loss: 2.5657005310058594
Validation loss: 2.099695344765981

Epoch: 6| Step: 8
Training loss: 1.9605278968811035
Validation loss: 2.0936880111694336

Epoch: 6| Step: 9
Training loss: 2.3560338020324707
Validation loss: 2.0985257625579834

Epoch: 6| Step: 10
Training loss: 1.9661988019943237
Validation loss: 2.100962440172831

Epoch: 6| Step: 11
Training loss: 2.0948057174682617
Validation loss: 2.1008793910344443

Epoch: 6| Step: 12
Training loss: 2.6280479431152344
Validation loss: 2.1021520495414734

Epoch: 6| Step: 13
Training loss: 2.590975761413574
Validation loss: 2.104775150616964

Epoch: 62| Step: 0
Training loss: 2.5776453018188477
Validation loss: 2.104106346766154

Epoch: 6| Step: 1
Training loss: 2.1895389556884766
Validation loss: 2.106681982676188

Epoch: 6| Step: 2
Training loss: 1.9960194826126099
Validation loss: 2.1002785364786782

Epoch: 6| Step: 3
Training loss: 1.7849777936935425
Validation loss: 2.0957345763842263

Epoch: 6| Step: 4
Training loss: 2.5951149463653564
Validation loss: 2.094928781191508

Epoch: 6| Step: 5
Training loss: 2.5859909057617188
Validation loss: 2.0839704275131226

Epoch: 6| Step: 6
Training loss: 2.3426876068115234
Validation loss: 2.0806758602460227

Epoch: 6| Step: 7
Training loss: 2.358675003051758
Validation loss: 2.086459199587504

Epoch: 6| Step: 8
Training loss: 1.9419242143630981
Validation loss: 2.088625888029734

Epoch: 6| Step: 9
Training loss: 2.5421879291534424
Validation loss: 2.0886215368906655

Epoch: 6| Step: 10
Training loss: 2.850269317626953
Validation loss: 2.0765355030695596

Epoch: 6| Step: 11
Training loss: 1.5246002674102783
Validation loss: 2.082931121190389

Epoch: 6| Step: 12
Training loss: 2.336617946624756
Validation loss: 2.0820987025896707

Epoch: 6| Step: 13
Training loss: 2.079380512237549
Validation loss: 2.0854425628980002

Epoch: 63| Step: 0
Training loss: 2.0317108631134033
Validation loss: 2.086521863937378

Epoch: 6| Step: 1
Training loss: 2.3595499992370605
Validation loss: 2.0782955090204873

Epoch: 6| Step: 2
Training loss: 2.099429130554199
Validation loss: 2.080385684967041

Epoch: 6| Step: 3
Training loss: 2.748889207839966
Validation loss: 2.0758927265803018

Epoch: 6| Step: 4
Training loss: 2.6655168533325195
Validation loss: 2.0740610559781394

Epoch: 6| Step: 5
Training loss: 1.992820382118225
Validation loss: 2.0636562506357827

Epoch: 6| Step: 6
Training loss: 1.6400072574615479
Validation loss: 2.0735004345575967

Epoch: 6| Step: 7
Training loss: 1.922108769416809
Validation loss: 2.0683989922205606

Epoch: 6| Step: 8
Training loss: 2.848504066467285
Validation loss: 2.0760809183120728

Epoch: 6| Step: 9
Training loss: 2.0811736583709717
Validation loss: 2.0698166886965432

Epoch: 6| Step: 10
Training loss: 1.9561606645584106
Validation loss: 2.0703361431757608

Epoch: 6| Step: 11
Training loss: 1.627235770225525
Validation loss: 2.0648484428723655

Epoch: 6| Step: 12
Training loss: 2.618055820465088
Validation loss: 2.065678298473358

Epoch: 6| Step: 13
Training loss: 2.731356620788574
Validation loss: 2.060277581214905

Epoch: 64| Step: 0
Training loss: 1.9691860675811768
Validation loss: 2.064064641793569

Epoch: 6| Step: 1
Training loss: 2.9662139415740967
Validation loss: 2.0618830919265747

Epoch: 6| Step: 2
Training loss: 1.964341640472412
Validation loss: 2.0631579558054605

Epoch: 6| Step: 3
Training loss: 2.552076816558838
Validation loss: 2.056252380212148

Epoch: 6| Step: 4
Training loss: 1.8948023319244385
Validation loss: 2.0597198804219565

Epoch: 6| Step: 5
Training loss: 1.8540723323822021
Validation loss: 2.0666234294573465

Epoch: 6| Step: 6
Training loss: 2.2799205780029297
Validation loss: 2.065837105115255

Epoch: 6| Step: 7
Training loss: 2.390796184539795
Validation loss: 2.0682979424794516

Epoch: 6| Step: 8
Training loss: 2.6962056159973145
Validation loss: 2.0701810320218406

Epoch: 6| Step: 9
Training loss: 1.843409776687622
Validation loss: 2.0509559512138367

Epoch: 6| Step: 10
Training loss: 1.638641595840454
Validation loss: 2.055289109547933

Epoch: 6| Step: 11
Training loss: 2.4164576530456543
Validation loss: 2.073047935962677

Epoch: 6| Step: 12
Training loss: 2.6040844917297363
Validation loss: 2.0649789770444236

Epoch: 6| Step: 13
Training loss: 2.0183041095733643
Validation loss: 2.0723437468210855

Epoch: 65| Step: 0
Training loss: 2.0075156688690186
Validation loss: 2.0486597617467246

Epoch: 6| Step: 1
Training loss: 1.575786828994751
Validation loss: 2.050481597582499

Epoch: 6| Step: 2
Training loss: 2.1388378143310547
Validation loss: 2.0432477394739785

Epoch: 6| Step: 3
Training loss: 2.1682071685791016
Validation loss: 2.0498724381128945

Epoch: 6| Step: 4
Training loss: 2.282763957977295
Validation loss: 2.0528753995895386

Epoch: 6| Step: 5
Training loss: 1.7833812236785889
Validation loss: 2.054516077041626

Epoch: 6| Step: 6
Training loss: 2.5375185012817383
Validation loss: 2.0517505009969077

Epoch: 6| Step: 7
Training loss: 2.1515936851501465
Validation loss: 2.044433077176412

Epoch: 6| Step: 8
Training loss: 2.2609169483184814
Validation loss: 2.052838146686554

Epoch: 6| Step: 9
Training loss: 1.9632433652877808
Validation loss: 2.0534430742263794

Epoch: 6| Step: 10
Training loss: 2.632709264755249
Validation loss: 2.0552047888437905

Epoch: 6| Step: 11
Training loss: 2.611570119857788
Validation loss: 2.04727566242218

Epoch: 6| Step: 12
Training loss: 2.3182458877563477
Validation loss: 2.051076650619507

Epoch: 6| Step: 13
Training loss: 2.55501651763916
Validation loss: 2.0570053458213806

Epoch: 66| Step: 0
Training loss: 2.265270471572876
Validation loss: 2.0601029793421426

Epoch: 6| Step: 1
Training loss: 1.886474847793579
Validation loss: 2.0542346636454263

Epoch: 6| Step: 2
Training loss: 1.8488444089889526
Validation loss: 2.0572914679845176

Epoch: 6| Step: 3
Training loss: 2.1416072845458984
Validation loss: 2.049483815828959

Epoch: 6| Step: 4
Training loss: 1.975831389427185
Validation loss: 2.048673470815023

Epoch: 6| Step: 5
Training loss: 1.7171580791473389
Validation loss: 2.048719068368276

Epoch: 6| Step: 6
Training loss: 2.145747423171997
Validation loss: 2.0507882634798684

Epoch: 6| Step: 7
Training loss: 2.668884515762329
Validation loss: 2.0412110884984336

Epoch: 6| Step: 8
Training loss: 1.922929048538208
Validation loss: 2.0490638812383017

Epoch: 6| Step: 9
Training loss: 1.7310495376586914
Validation loss: 2.0501052935918174

Epoch: 6| Step: 10
Training loss: 3.1462438106536865
Validation loss: 2.0514267086982727

Epoch: 6| Step: 11
Training loss: 2.272869348526001
Validation loss: 2.0417685310045877

Epoch: 6| Step: 12
Training loss: 2.7453513145446777
Validation loss: 2.04020627339681

Epoch: 6| Step: 13
Training loss: 2.631279945373535
Validation loss: 2.045754690965017

Epoch: 67| Step: 0
Training loss: 2.2694344520568848
Validation loss: 2.045209447542826

Epoch: 6| Step: 1
Training loss: 2.492096424102783
Validation loss: 2.041137715180715

Epoch: 6| Step: 2
Training loss: 1.7966421842575073
Validation loss: 2.038748621940613

Epoch: 6| Step: 3
Training loss: 1.903902530670166
Validation loss: 2.0366228818893433

Epoch: 6| Step: 4
Training loss: 2.8000950813293457
Validation loss: 2.0466580192248025

Epoch: 6| Step: 5
Training loss: 2.448925733566284
Validation loss: 2.040976047515869

Epoch: 6| Step: 6
Training loss: 2.4115188121795654
Validation loss: 2.0462171832720437

Epoch: 6| Step: 7
Training loss: 2.2914421558380127
Validation loss: 2.0343648195266724

Epoch: 6| Step: 8
Training loss: 1.366934061050415
Validation loss: 2.0431623657544455

Epoch: 6| Step: 9
Training loss: 2.064420461654663
Validation loss: 2.040222724278768

Epoch: 6| Step: 10
Training loss: 2.351121425628662
Validation loss: 2.0443632205327353

Epoch: 6| Step: 11
Training loss: 2.0921132564544678
Validation loss: 2.047245184580485

Epoch: 6| Step: 12
Training loss: 2.1942338943481445
Validation loss: 2.0426682035128274

Epoch: 6| Step: 13
Training loss: 2.353285789489746
Validation loss: 2.035162885983785

Epoch: 68| Step: 0
Training loss: 2.5037264823913574
Validation loss: 2.039712150891622

Epoch: 6| Step: 1
Training loss: 2.234988212585449
Validation loss: 2.0418761173884072

Epoch: 6| Step: 2
Training loss: 2.8233914375305176
Validation loss: 2.039655069510142

Epoch: 6| Step: 3
Training loss: 1.8888447284698486
Validation loss: 2.0361945629119873

Epoch: 6| Step: 4
Training loss: 1.6617213487625122
Validation loss: 2.0399546027183533

Epoch: 6| Step: 5
Training loss: 2.0211362838745117
Validation loss: 2.0406166712443032

Epoch: 6| Step: 6
Training loss: 2.8271732330322266
Validation loss: 2.050667186578115

Epoch: 6| Step: 7
Training loss: 2.517509937286377
Validation loss: 2.0499222675959268

Epoch: 6| Step: 8
Training loss: 2.2820541858673096
Validation loss: 2.051198720932007

Epoch: 6| Step: 9
Training loss: 1.8787338733673096
Validation loss: 2.0663491686185202

Epoch: 6| Step: 10
Training loss: 1.8749765157699585
Validation loss: 2.0474419792493186

Epoch: 6| Step: 11
Training loss: 1.636598825454712
Validation loss: 2.069158752759298

Epoch: 6| Step: 12
Training loss: 2.717770576477051
Validation loss: 2.0675973296165466

Epoch: 6| Step: 13
Training loss: 1.942746877670288
Validation loss: 2.052500228087107

Epoch: 69| Step: 0
Training loss: 2.190182685852051
Validation loss: 2.0407843589782715

Epoch: 6| Step: 1
Training loss: 2.697953939437866
Validation loss: 2.0531134009361267

Epoch: 6| Step: 2
Training loss: 1.9231598377227783
Validation loss: 2.0500712990760803

Epoch: 6| Step: 3
Training loss: 2.582620620727539
Validation loss: 2.0370744864145913

Epoch: 6| Step: 4
Training loss: 2.66233491897583
Validation loss: 2.0287466645240784

Epoch: 6| Step: 5
Training loss: 2.534231662750244
Validation loss: 2.0415481527646384

Epoch: 6| Step: 6
Training loss: 1.9220244884490967
Validation loss: 2.0351192553838096

Epoch: 6| Step: 7
Training loss: 2.0212769508361816
Validation loss: 2.044831116994222

Epoch: 6| Step: 8
Training loss: 2.3989486694335938
Validation loss: 2.037464718023936

Epoch: 6| Step: 9
Training loss: 1.7221341133117676
Validation loss: 2.0279870430628457

Epoch: 6| Step: 10
Training loss: 2.389186382293701
Validation loss: 2.0218860507011414

Epoch: 6| Step: 11
Training loss: 1.7237417697906494
Validation loss: 2.029771625995636

Epoch: 6| Step: 12
Training loss: 1.7908923625946045
Validation loss: 2.04130482673645

Epoch: 6| Step: 13
Training loss: 2.325134515762329
Validation loss: 2.0431010127067566

Epoch: 70| Step: 0
Training loss: 1.4686579704284668
Validation loss: 2.0521938800811768

Epoch: 6| Step: 1
Training loss: 1.7475095987319946
Validation loss: 2.059915562470754

Epoch: 6| Step: 2
Training loss: 2.184666156768799
Validation loss: 2.073128958543142

Epoch: 6| Step: 3
Training loss: 3.157968044281006
Validation loss: 2.108655889829

Epoch: 6| Step: 4
Training loss: 2.314730644226074
Validation loss: 2.0969446301460266

Epoch: 6| Step: 5
Training loss: 1.9119247198104858
Validation loss: 2.0818932056427

Epoch: 6| Step: 6
Training loss: 1.811408519744873
Validation loss: 2.0646981398264566

Epoch: 6| Step: 7
Training loss: 2.408839702606201
Validation loss: 2.0298524498939514

Epoch: 6| Step: 8
Training loss: 2.2279269695281982
Validation loss: 2.040643870830536

Epoch: 6| Step: 9
Training loss: 2.4052531719207764
Validation loss: 2.028852939605713

Epoch: 6| Step: 10
Training loss: 2.776398181915283
Validation loss: 2.047552208105723

Epoch: 6| Step: 11
Training loss: 2.6429810523986816
Validation loss: 2.0596407651901245

Epoch: 6| Step: 12
Training loss: 2.180065393447876
Validation loss: 2.07023819287618

Epoch: 6| Step: 13
Training loss: 2.270308017730713
Validation loss: 2.0725136200586953

Epoch: 71| Step: 0
Training loss: 2.6534383296966553
Validation loss: 2.075310389200846

Epoch: 6| Step: 1
Training loss: 2.241689920425415
Validation loss: 2.06427925825119

Epoch: 6| Step: 2
Training loss: 2.642033338546753
Validation loss: 2.0612216194470725

Epoch: 6| Step: 3
Training loss: 1.9241490364074707
Validation loss: 2.059206783771515

Epoch: 6| Step: 4
Training loss: 2.3287758827209473
Validation loss: 2.052896579106649

Epoch: 6| Step: 5
Training loss: 2.422254800796509
Validation loss: 2.044270118077596

Epoch: 6| Step: 6
Training loss: 1.9292666912078857
Validation loss: 2.0466109116872153

Epoch: 6| Step: 7
Training loss: 2.331575393676758
Validation loss: 2.041674256324768

Epoch: 6| Step: 8
Training loss: 1.9276719093322754
Validation loss: 2.045678655306498

Epoch: 6| Step: 9
Training loss: 2.3019027709960938
Validation loss: 2.0373572508494058

Epoch: 6| Step: 10
Training loss: 2.1031129360198975
Validation loss: 2.040281116962433

Epoch: 6| Step: 11
Training loss: 2.1080238819122314
Validation loss: 2.029138922691345

Epoch: 6| Step: 12
Training loss: 2.191763401031494
Validation loss: 2.018982211748759

Epoch: 6| Step: 13
Training loss: 2.007845401763916
Validation loss: 2.0207545161247253

Epoch: 72| Step: 0
Training loss: 2.024188756942749
Validation loss: 2.0348599950472512

Epoch: 6| Step: 1
Training loss: 2.211103916168213
Validation loss: 2.0384276111920676

Epoch: 6| Step: 2
Training loss: 1.7329750061035156
Validation loss: 2.039103349049886

Epoch: 6| Step: 3
Training loss: 1.71049165725708
Validation loss: 2.050216476122538

Epoch: 6| Step: 4
Training loss: 1.8054563999176025
Validation loss: 2.0537202954292297

Epoch: 6| Step: 5
Training loss: 2.489910125732422
Validation loss: 2.056539793809255

Epoch: 6| Step: 6
Training loss: 2.1281776428222656
Validation loss: 2.05240797996521

Epoch: 6| Step: 7
Training loss: 2.065248489379883
Validation loss: 2.055371046066284

Epoch: 6| Step: 8
Training loss: 2.678018808364868
Validation loss: 2.0477436979611716

Epoch: 6| Step: 9
Training loss: 1.7325024604797363
Validation loss: 2.0437647302945456

Epoch: 6| Step: 10
Training loss: 2.675776720046997
Validation loss: 2.0396740635236106

Epoch: 6| Step: 11
Training loss: 2.2883057594299316
Validation loss: 2.0286606748898826

Epoch: 6| Step: 12
Training loss: 2.6334640979766846
Validation loss: 2.0322840015093484

Epoch: 6| Step: 13
Training loss: 2.4054458141326904
Validation loss: 2.0363353292147317

Epoch: 73| Step: 0
Training loss: 2.216196060180664
Validation loss: 2.0328445037206015

Epoch: 6| Step: 1
Training loss: 2.4898571968078613
Validation loss: 2.031785806020101

Epoch: 6| Step: 2
Training loss: 2.3954243659973145
Validation loss: 2.0344958504041037

Epoch: 6| Step: 3
Training loss: 2.2360522747039795
Validation loss: 2.0348702867825827

Epoch: 6| Step: 4
Training loss: 2.4073028564453125
Validation loss: 2.036657234032949

Epoch: 6| Step: 5
Training loss: 2.4176065921783447
Validation loss: 2.035727103551229

Epoch: 6| Step: 6
Training loss: 1.6691769361495972
Validation loss: 2.037212630112966

Epoch: 6| Step: 7
Training loss: 1.8064944744110107
Validation loss: 2.030060609181722

Epoch: 6| Step: 8
Training loss: 2.1979751586914062
Validation loss: 2.031229535738627

Epoch: 6| Step: 9
Training loss: 2.4533324241638184
Validation loss: 2.023664573828379

Epoch: 6| Step: 10
Training loss: 2.34910249710083
Validation loss: 2.0335290233294168

Epoch: 6| Step: 11
Training loss: 2.0505568981170654
Validation loss: 2.0352455973625183

Epoch: 6| Step: 12
Training loss: 2.516540765762329
Validation loss: 2.0412455598513284

Epoch: 6| Step: 13
Training loss: 1.437506914138794
Validation loss: 2.046962340672811

Epoch: 74| Step: 0
Training loss: 2.7259624004364014
Validation loss: 2.0536720554033914

Epoch: 6| Step: 1
Training loss: 2.506143569946289
Validation loss: 2.0671591560045877

Epoch: 6| Step: 2
Training loss: 2.287928581237793
Validation loss: 2.06870444615682

Epoch: 6| Step: 3
Training loss: 2.212872266769409
Validation loss: 2.0633997917175293

Epoch: 6| Step: 4
Training loss: 2.6011853218078613
Validation loss: 2.0462217728296914

Epoch: 6| Step: 5
Training loss: 2.582775592803955
Validation loss: 2.0313510497411094

Epoch: 6| Step: 6
Training loss: 2.682591676712036
Validation loss: 2.0215769012769065

Epoch: 6| Step: 7
Training loss: 2.644420862197876
Validation loss: 2.0165550112724304

Epoch: 6| Step: 8
Training loss: 2.304896354675293
Validation loss: 2.0271750688552856

Epoch: 6| Step: 9
Training loss: 1.7310031652450562
Validation loss: 2.0215761264165244

Epoch: 6| Step: 10
Training loss: 1.656247854232788
Validation loss: 2.02395236492157

Epoch: 6| Step: 11
Training loss: 1.2210566997528076
Validation loss: 2.0277485052744546

Epoch: 6| Step: 12
Training loss: 1.6956202983856201
Validation loss: 2.0238737066586814

Epoch: 6| Step: 13
Training loss: 1.9644606113433838
Validation loss: 2.0246138175328574

Epoch: 75| Step: 0
Training loss: 2.3683810234069824
Validation loss: 2.02811735868454

Epoch: 6| Step: 1
Training loss: 2.0923686027526855
Validation loss: 2.014628787835439

Epoch: 6| Step: 2
Training loss: 2.2570905685424805
Validation loss: 2.019675135612488

Epoch: 6| Step: 3
Training loss: 1.3516297340393066
Validation loss: 2.0234521627426147

Epoch: 6| Step: 4
Training loss: 1.3488588333129883
Validation loss: 2.034624457359314

Epoch: 6| Step: 5
Training loss: 1.8857742547988892
Validation loss: 2.030023753643036

Epoch: 6| Step: 6
Training loss: 2.5224180221557617
Validation loss: 2.0322461326917014

Epoch: 6| Step: 7
Training loss: 2.4578282833099365
Validation loss: 2.0467004776000977

Epoch: 6| Step: 8
Training loss: 2.505585193634033
Validation loss: 2.0449122985204062

Epoch: 6| Step: 9
Training loss: 2.4714174270629883
Validation loss: 2.047179698944092

Epoch: 6| Step: 10
Training loss: 2.257396697998047
Validation loss: 2.0478352904319763

Epoch: 6| Step: 11
Training loss: 2.361473560333252
Validation loss: 2.0320427616437278

Epoch: 6| Step: 12
Training loss: 2.054049491882324
Validation loss: 2.0263951619466147

Epoch: 6| Step: 13
Training loss: 2.5861291885375977
Validation loss: 2.0318334102630615

Epoch: 76| Step: 0
Training loss: 2.280569076538086
Validation loss: 2.0212102929751077

Epoch: 6| Step: 1
Training loss: 2.6679654121398926
Validation loss: 2.0200887521107993

Epoch: 6| Step: 2
Training loss: 1.9677515029907227
Validation loss: 2.0223199327786765

Epoch: 6| Step: 3
Training loss: 2.1803674697875977
Validation loss: 2.024694800376892

Epoch: 6| Step: 4
Training loss: 1.800032615661621
Validation loss: 2.0271036426226297

Epoch: 6| Step: 5
Training loss: 1.9747737646102905
Validation loss: 2.0269469817479453

Epoch: 6| Step: 6
Training loss: 1.7031614780426025
Validation loss: 2.032915016015371

Epoch: 6| Step: 7
Training loss: 2.230971574783325
Validation loss: 2.04083784421285

Epoch: 6| Step: 8
Training loss: 1.6501646041870117
Validation loss: 2.034542461236318

Epoch: 6| Step: 9
Training loss: 2.578824281692505
Validation loss: 2.0492273966471353

Epoch: 6| Step: 10
Training loss: 2.0286247730255127
Validation loss: 2.0540969371795654

Epoch: 6| Step: 11
Training loss: 2.1942291259765625
Validation loss: 2.043516238530477

Epoch: 6| Step: 12
Training loss: 2.792044162750244
Validation loss: 2.0509883761405945

Epoch: 6| Step: 13
Training loss: 2.3379316329956055
Validation loss: 2.0554271936416626

Epoch: 77| Step: 0
Training loss: 2.4315409660339355
Validation loss: 2.0336193641026816

Epoch: 6| Step: 1
Training loss: 1.3771332502365112
Validation loss: 2.0390902956326804

Epoch: 6| Step: 2
Training loss: 1.8398890495300293
Validation loss: 2.0393925507863364

Epoch: 6| Step: 3
Training loss: 2.2468807697296143
Validation loss: 2.0412697990735373

Epoch: 6| Step: 4
Training loss: 2.0323777198791504
Validation loss: 2.041084110736847

Epoch: 6| Step: 5
Training loss: 2.161707878112793
Validation loss: 2.041860659917196

Epoch: 6| Step: 6
Training loss: 2.103428363800049
Validation loss: 2.026871085166931

Epoch: 6| Step: 7
Training loss: 1.6798125505447388
Validation loss: 2.0266348123550415

Epoch: 6| Step: 8
Training loss: 2.736633777618408
Validation loss: 2.0391146341959634

Epoch: 6| Step: 9
Training loss: 2.299213409423828
Validation loss: 2.02862556775411

Epoch: 6| Step: 10
Training loss: 2.2668426036834717
Validation loss: 2.0360966523488364

Epoch: 6| Step: 11
Training loss: 2.393702983856201
Validation loss: 2.0417145689328513

Epoch: 6| Step: 12
Training loss: 2.009941577911377
Validation loss: 2.0320933858553567

Epoch: 6| Step: 13
Training loss: 2.7480220794677734
Validation loss: 2.037936786810557

Epoch: 78| Step: 0
Training loss: 2.862748861312866
Validation loss: 2.0444992184638977

Epoch: 6| Step: 1
Training loss: 1.9977589845657349
Validation loss: 2.0258347193400064

Epoch: 6| Step: 2
Training loss: 2.1932530403137207
Validation loss: 2.033507843812307

Epoch: 6| Step: 3
Training loss: 1.5393805503845215
Validation loss: 2.0290106534957886

Epoch: 6| Step: 4
Training loss: 2.4465603828430176
Validation loss: 2.020505905151367

Epoch: 6| Step: 5
Training loss: 1.862871766090393
Validation loss: 2.0240937868754068

Epoch: 6| Step: 6
Training loss: 2.464160203933716
Validation loss: 2.0262301166852317

Epoch: 6| Step: 7
Training loss: 2.588059186935425
Validation loss: 2.029182255268097

Epoch: 6| Step: 8
Training loss: 2.5679757595062256
Validation loss: 2.0342471599578857

Epoch: 6| Step: 9
Training loss: 2.5332837104797363
Validation loss: 2.0478963057200112

Epoch: 6| Step: 10
Training loss: 1.536875605583191
Validation loss: 2.044126331806183

Epoch: 6| Step: 11
Training loss: 1.8136887550354004
Validation loss: 2.0476141770680747

Epoch: 6| Step: 12
Training loss: 1.6029458045959473
Validation loss: 2.0324986378351846

Epoch: 6| Step: 13
Training loss: 2.3613715171813965
Validation loss: 2.028855820496877

Epoch: 79| Step: 0
Training loss: 2.01613187789917
Validation loss: 2.0387816031773887

Epoch: 6| Step: 1
Training loss: 1.8819690942764282
Validation loss: 2.0273189147313437

Epoch: 6| Step: 2
Training loss: 2.638977527618408
Validation loss: 2.04039067029953

Epoch: 6| Step: 3
Training loss: 2.724304437637329
Validation loss: 2.0470757683118186

Epoch: 6| Step: 4
Training loss: 2.4642128944396973
Validation loss: 2.0473538835843406

Epoch: 6| Step: 5
Training loss: 1.7410262823104858
Validation loss: 2.0497695207595825

Epoch: 6| Step: 6
Training loss: 1.4749057292938232
Validation loss: 2.058693766593933

Epoch: 6| Step: 7
Training loss: 2.334109306335449
Validation loss: 2.0579561988512673

Epoch: 6| Step: 8
Training loss: 2.0860650539398193
Validation loss: 2.0499099493026733

Epoch: 6| Step: 9
Training loss: 1.766039252281189
Validation loss: 2.031923691431681

Epoch: 6| Step: 10
Training loss: 2.3867273330688477
Validation loss: 2.05227792263031

Epoch: 6| Step: 11
Training loss: 2.293182134628296
Validation loss: 2.0342715779940286

Epoch: 6| Step: 12
Training loss: 2.0708444118499756
Validation loss: 2.0278477867444358

Epoch: 6| Step: 13
Training loss: 2.3581647872924805
Validation loss: 2.018309791882833

Epoch: 80| Step: 0
Training loss: 1.8501631021499634
Validation loss: 2.0173486471176147

Epoch: 6| Step: 1
Training loss: 2.2917213439941406
Validation loss: 2.0133185585339866

Epoch: 6| Step: 2
Training loss: 1.8762249946594238
Validation loss: 2.025835156440735

Epoch: 6| Step: 3
Training loss: 2.440659999847412
Validation loss: 2.0204750696818032

Epoch: 6| Step: 4
Training loss: 2.1191139221191406
Validation loss: 2.0258028507232666

Epoch: 6| Step: 5
Training loss: 2.0161471366882324
Validation loss: 2.0278718074162803

Epoch: 6| Step: 6
Training loss: 2.250885009765625
Validation loss: 2.033215959866842

Epoch: 6| Step: 7
Training loss: 2.2915430068969727
Validation loss: 2.037324289480845

Epoch: 6| Step: 8
Training loss: 2.4166259765625
Validation loss: 2.0236124197642007

Epoch: 6| Step: 9
Training loss: 2.1031653881073
Validation loss: 2.0317147175470986

Epoch: 6| Step: 10
Training loss: 2.233941078186035
Validation loss: 2.0312265952428183

Epoch: 6| Step: 11
Training loss: 2.538806438446045
Validation loss: 2.028513014316559

Epoch: 6| Step: 12
Training loss: 2.2054762840270996
Validation loss: 2.02986611922582

Epoch: 6| Step: 13
Training loss: 2.0023655891418457
Validation loss: 2.013315955797831

Epoch: 81| Step: 0
Training loss: 2.7147648334503174
Validation loss: 2.0114047527313232

Epoch: 6| Step: 1
Training loss: 1.583397626876831
Validation loss: 2.0120740135510764

Epoch: 6| Step: 2
Training loss: 2.127680778503418
Validation loss: 2.037216544151306

Epoch: 6| Step: 3
Training loss: 2.431575298309326
Validation loss: 2.051851987838745

Epoch: 6| Step: 4
Training loss: 1.946811318397522
Validation loss: 2.058414419492086

Epoch: 6| Step: 5
Training loss: 2.003178119659424
Validation loss: 2.061606526374817

Epoch: 6| Step: 6
Training loss: 2.0759506225585938
Validation loss: 2.0699840784072876

Epoch: 6| Step: 7
Training loss: 2.819063663482666
Validation loss: 2.057004710038503

Epoch: 6| Step: 8
Training loss: 2.1373720169067383
Validation loss: 2.03688116868337

Epoch: 6| Step: 9
Training loss: 2.620671033859253
Validation loss: 2.0228166778882346

Epoch: 6| Step: 10
Training loss: 1.5101912021636963
Validation loss: 2.024514118830363

Epoch: 6| Step: 11
Training loss: 1.8874895572662354
Validation loss: 2.021472156047821

Epoch: 6| Step: 12
Training loss: 2.5806937217712402
Validation loss: 2.0200020472208657

Epoch: 6| Step: 13
Training loss: 1.902454137802124
Validation loss: 2.0326476097106934

Epoch: 82| Step: 0
Training loss: 2.1554348468780518
Validation loss: 2.035584251085917

Epoch: 6| Step: 1
Training loss: 1.9922888278961182
Validation loss: 2.041944404443105

Epoch: 6| Step: 2
Training loss: 2.884636402130127
Validation loss: 2.045871913433075

Epoch: 6| Step: 3
Training loss: 2.297919273376465
Validation loss: 2.0434754292170205

Epoch: 6| Step: 4
Training loss: 1.8687710762023926
Validation loss: 2.039995789527893

Epoch: 6| Step: 5
Training loss: 2.15080189704895
Validation loss: 2.040941834449768

Epoch: 6| Step: 6
Training loss: 2.178224563598633
Validation loss: 2.040016154448191

Epoch: 6| Step: 7
Training loss: 2.0588502883911133
Validation loss: 2.0311822295188904

Epoch: 6| Step: 8
Training loss: 2.3989694118499756
Validation loss: 2.035619934399923

Epoch: 6| Step: 9
Training loss: 1.9278217554092407
Validation loss: 2.0333094398180642

Epoch: 6| Step: 10
Training loss: 2.0845823287963867
Validation loss: 2.0347494880358377

Epoch: 6| Step: 11
Training loss: 2.881990909576416
Validation loss: 2.0294505755106607

Epoch: 6| Step: 12
Training loss: 2.177171230316162
Validation loss: 2.0284504294395447

Epoch: 6| Step: 13
Training loss: 1.7233994007110596
Validation loss: 2.023217737674713

Epoch: 83| Step: 0
Training loss: 2.4286274909973145
Validation loss: 2.019698361555735

Epoch: 6| Step: 1
Training loss: 1.8383045196533203
Validation loss: 2.0183936754862466

Epoch: 6| Step: 2
Training loss: 1.4638644456863403
Validation loss: 2.0271213054656982

Epoch: 6| Step: 3
Training loss: 2.352395534515381
Validation loss: 2.021249016125997

Epoch: 6| Step: 4
Training loss: 1.994670033454895
Validation loss: 2.0156615177790322

Epoch: 6| Step: 5
Training loss: 2.2110047340393066
Validation loss: 2.0270668864250183

Epoch: 6| Step: 6
Training loss: 2.639315128326416
Validation loss: 2.0208725333213806

Epoch: 6| Step: 7
Training loss: 2.2355339527130127
Validation loss: 2.0246946016947427

Epoch: 6| Step: 8
Training loss: 2.2265756130218506
Validation loss: 2.0215362310409546

Epoch: 6| Step: 9
Training loss: 1.9067704677581787
Validation loss: 2.0332718888918557

Epoch: 6| Step: 10
Training loss: 2.390472888946533
Validation loss: 2.0470025142033896

Epoch: 6| Step: 11
Training loss: 2.595705509185791
Validation loss: 2.045048177242279

Epoch: 6| Step: 12
Training loss: 1.950421690940857
Validation loss: 2.0368204712867737

Epoch: 6| Step: 13
Training loss: 1.9315509796142578
Validation loss: 2.040143609046936

Epoch: 84| Step: 0
Training loss: 2.630598545074463
Validation loss: 2.04512753089269

Epoch: 6| Step: 1
Training loss: 1.9699076414108276
Validation loss: 2.0388421614964805

Epoch: 6| Step: 2
Training loss: 2.6436405181884766
Validation loss: 2.063011964162191

Epoch: 6| Step: 3
Training loss: 2.4609992504119873
Validation loss: 2.0557228525479636

Epoch: 6| Step: 4
Training loss: 1.6666431427001953
Validation loss: 2.065140893061956

Epoch: 6| Step: 5
Training loss: 2.0655057430267334
Validation loss: 2.067261020342509

Epoch: 6| Step: 6
Training loss: 2.3096961975097656
Validation loss: 2.0715762178103128

Epoch: 6| Step: 7
Training loss: 2.1460976600646973
Validation loss: 2.0699331760406494

Epoch: 6| Step: 8
Training loss: 2.8510427474975586
Validation loss: 2.0649576584498086

Epoch: 6| Step: 9
Training loss: 1.6271007061004639
Validation loss: 2.0531235138575235

Epoch: 6| Step: 10
Training loss: 1.6624257564544678
Validation loss: 2.02561084429423

Epoch: 6| Step: 11
Training loss: 2.230863094329834
Validation loss: 2.0203449527422586

Epoch: 6| Step: 12
Training loss: 2.2358264923095703
Validation loss: 2.0179538130760193

Epoch: 6| Step: 13
Training loss: 1.8846501111984253
Validation loss: 2.021812637646993

Epoch: 85| Step: 0
Training loss: 2.738499641418457
Validation loss: 2.024785876274109

Epoch: 6| Step: 1
Training loss: 1.9155384302139282
Validation loss: 2.013782282670339

Epoch: 6| Step: 2
Training loss: 2.3803977966308594
Validation loss: 2.02883243560791

Epoch: 6| Step: 3
Training loss: 2.2917752265930176
Validation loss: 2.0363022685050964

Epoch: 6| Step: 4
Training loss: 1.4419610500335693
Validation loss: 2.037626584370931

Epoch: 6| Step: 5
Training loss: 2.0404140949249268
Validation loss: 2.030616303284963

Epoch: 6| Step: 6
Training loss: 2.1504690647125244
Validation loss: 2.0401559670766196

Epoch: 6| Step: 7
Training loss: 2.493439197540283
Validation loss: 2.032542606194814

Epoch: 6| Step: 8
Training loss: 2.2720954418182373
Validation loss: 2.0394020080566406

Epoch: 6| Step: 9
Training loss: 2.153670310974121
Validation loss: 2.03128190835317

Epoch: 6| Step: 10
Training loss: 1.8929673433303833
Validation loss: 2.039372742176056

Epoch: 6| Step: 11
Training loss: 2.529470682144165
Validation loss: 2.0239503582318625

Epoch: 6| Step: 12
Training loss: 2.545708656311035
Validation loss: 2.0228785077730813

Epoch: 6| Step: 13
Training loss: 1.7898845672607422
Validation loss: 2.018057425816854

Epoch: 86| Step: 0
Training loss: 2.310811996459961
Validation loss: 2.014836331208547

Epoch: 6| Step: 1
Training loss: 1.7639319896697998
Validation loss: 2.0049924651781716

Epoch: 6| Step: 2
Training loss: 2.141512155532837
Validation loss: 2.018533448378245

Epoch: 6| Step: 3
Training loss: 1.8463226556777954
Validation loss: 2.026915709177653

Epoch: 6| Step: 4
Training loss: 2.841546058654785
Validation loss: 2.0242095788319907

Epoch: 6| Step: 5
Training loss: 2.0765340328216553
Validation loss: 2.036830723285675

Epoch: 6| Step: 6
Training loss: 1.5170605182647705
Validation loss: 2.044516901175181

Epoch: 6| Step: 7
Training loss: 1.8946696519851685
Validation loss: 2.0472482442855835

Epoch: 6| Step: 8
Training loss: 2.103036880493164
Validation loss: 2.047577162583669

Epoch: 6| Step: 9
Training loss: 2.4197843074798584
Validation loss: 2.059268812338511

Epoch: 6| Step: 10
Training loss: 2.1743602752685547
Validation loss: 2.049403488636017

Epoch: 6| Step: 11
Training loss: 2.3948192596435547
Validation loss: 2.0399776299794516

Epoch: 6| Step: 12
Training loss: 2.103830337524414
Validation loss: 2.0313446521759033

Epoch: 6| Step: 13
Training loss: 2.6179471015930176
Validation loss: 2.0153470635414124

Epoch: 87| Step: 0
Training loss: 1.9882038831710815
Validation loss: 2.011643330256144

Epoch: 6| Step: 1
Training loss: 2.91463303565979
Validation loss: 2.010852058728536

Epoch: 6| Step: 2
Training loss: 2.2843823432922363
Validation loss: 2.0215770999590554

Epoch: 6| Step: 3
Training loss: 1.7773902416229248
Validation loss: 2.025890668233236

Epoch: 6| Step: 4
Training loss: 1.9808725118637085
Validation loss: 2.021361827850342

Epoch: 6| Step: 5
Training loss: 2.1643319129943848
Validation loss: 2.025295833746592

Epoch: 6| Step: 6
Training loss: 2.2734665870666504
Validation loss: 2.0249364376068115

Epoch: 6| Step: 7
Training loss: 2.108269691467285
Validation loss: 2.023460845152537

Epoch: 6| Step: 8
Training loss: 2.6576690673828125
Validation loss: 2.029651701450348

Epoch: 6| Step: 9
Training loss: 1.7558600902557373
Validation loss: 2.0317824681599936

Epoch: 6| Step: 10
Training loss: 2.221285820007324
Validation loss: 2.0189253290494285

Epoch: 6| Step: 11
Training loss: 2.266112804412842
Validation loss: 2.023694952329

Epoch: 6| Step: 12
Training loss: 1.7502963542938232
Validation loss: 2.023227353890737

Epoch: 6| Step: 13
Training loss: 2.1895265579223633
Validation loss: 2.022946079572042

Epoch: 88| Step: 0
Training loss: 1.796181082725525
Validation loss: 2.016108592351278

Epoch: 6| Step: 1
Training loss: 2.4257302284240723
Validation loss: 2.013026316960653

Epoch: 6| Step: 2
Training loss: 2.3713464736938477
Validation loss: 2.0055064956347146

Epoch: 6| Step: 3
Training loss: 1.9316818714141846
Validation loss: 1.9954353769620259

Epoch: 6| Step: 4
Training loss: 1.5885462760925293
Validation loss: 2.007372816403707

Epoch: 6| Step: 5
Training loss: 2.672102928161621
Validation loss: 2.0044560035069785

Epoch: 6| Step: 6
Training loss: 2.006648302078247
Validation loss: 2.0026050209999084

Epoch: 6| Step: 7
Training loss: 1.5418106317520142
Validation loss: 2.0255324840545654

Epoch: 6| Step: 8
Training loss: 2.0503153800964355
Validation loss: 2.0130293369293213

Epoch: 6| Step: 9
Training loss: 2.2798550128936768
Validation loss: 2.0244888067245483

Epoch: 6| Step: 10
Training loss: 1.8731342554092407
Validation loss: 2.011601150035858

Epoch: 6| Step: 11
Training loss: 3.1797075271606445
Validation loss: 2.015520612398783

Epoch: 6| Step: 12
Training loss: 2.2126996517181396
Validation loss: 2.0164612929026284

Epoch: 6| Step: 13
Training loss: 1.9358351230621338
Validation loss: 2.0132295290629068

Epoch: 89| Step: 0
Training loss: 2.021376609802246
Validation loss: 2.0175697008768716

Epoch: 6| Step: 1
Training loss: 1.7766320705413818
Validation loss: 2.0195050040880838

Epoch: 6| Step: 2
Training loss: 2.3885984420776367
Validation loss: 2.0078320701917014

Epoch: 6| Step: 3
Training loss: 2.023890733718872
Validation loss: 2.016375501950582

Epoch: 6| Step: 4
Training loss: 2.1249637603759766
Validation loss: 2.026610473791758

Epoch: 6| Step: 5
Training loss: 2.2027111053466797
Validation loss: 2.031866451104482

Epoch: 6| Step: 6
Training loss: 1.6463184356689453
Validation loss: 2.0276583433151245

Epoch: 6| Step: 7
Training loss: 1.9848556518554688
Validation loss: 2.035910507043203

Epoch: 6| Step: 8
Training loss: 2.2874808311462402
Validation loss: 2.0332116882006326

Epoch: 6| Step: 9
Training loss: 2.2932329177856445
Validation loss: 2.0317707657814026

Epoch: 6| Step: 10
Training loss: 2.764767646789551
Validation loss: 2.034667730331421

Epoch: 6| Step: 11
Training loss: 2.070341110229492
Validation loss: 2.0243833859761557

Epoch: 6| Step: 12
Training loss: 1.8053460121154785
Validation loss: 2.020589749018351

Epoch: 6| Step: 13
Training loss: 2.525298833847046
Validation loss: 2.016350050767263

Epoch: 90| Step: 0
Training loss: 2.233551502227783
Validation loss: 2.0026724537213645

Epoch: 6| Step: 1
Training loss: 1.6486531496047974
Validation loss: 2.007716635862986

Epoch: 6| Step: 2
Training loss: 1.7511121034622192
Validation loss: 2.0118393699328103

Epoch: 6| Step: 3
Training loss: 1.7666490077972412
Validation loss: 2.0044777592023215

Epoch: 6| Step: 4
Training loss: 2.22163462638855
Validation loss: 2.0116626818974814

Epoch: 6| Step: 5
Training loss: 1.9302897453308105
Validation loss: 2.0060475865999856

Epoch: 6| Step: 6
Training loss: 2.8597793579101562
Validation loss: 2.014427602291107

Epoch: 6| Step: 7
Training loss: 2.206082820892334
Validation loss: 2.0192773739496865

Epoch: 6| Step: 8
Training loss: 2.6248772144317627
Validation loss: 2.02598903576533

Epoch: 6| Step: 9
Training loss: 1.9973267316818237
Validation loss: 2.0198373198509216

Epoch: 6| Step: 10
Training loss: 2.7499468326568604
Validation loss: 2.0294803182284036

Epoch: 6| Step: 11
Training loss: 2.7320876121520996
Validation loss: 2.0240127046902976

Epoch: 6| Step: 12
Training loss: 1.2919901609420776
Validation loss: 2.0157899856567383

Epoch: 6| Step: 13
Training loss: 2.0172085762023926
Validation loss: 2.0183460315068564

Epoch: 91| Step: 0
Training loss: 1.7692515850067139
Validation loss: 2.02087539434433

Epoch: 6| Step: 1
Training loss: 2.1073055267333984
Validation loss: 2.020654877026876

Epoch: 6| Step: 2
Training loss: 2.369227886199951
Validation loss: 2.0230889121691384

Epoch: 6| Step: 3
Training loss: 2.1206531524658203
Validation loss: 2.0214594999949136

Epoch: 6| Step: 4
Training loss: 2.2323594093322754
Validation loss: 2.0225202242533364

Epoch: 6| Step: 5
Training loss: 2.121567726135254
Validation loss: 2.0240215261777244

Epoch: 6| Step: 6
Training loss: 2.539691686630249
Validation loss: 2.038064181804657

Epoch: 6| Step: 7
Training loss: 2.196739673614502
Validation loss: 2.0194703936576843

Epoch: 6| Step: 8
Training loss: 2.1604671478271484
Validation loss: 2.0125037829081216

Epoch: 6| Step: 9
Training loss: 2.470658302307129
Validation loss: 2.021489063898722

Epoch: 6| Step: 10
Training loss: 2.147852897644043
Validation loss: 2.023069898287455

Epoch: 6| Step: 11
Training loss: 1.579350471496582
Validation loss: 2.02233225107193

Epoch: 6| Step: 12
Training loss: 2.35408616065979
Validation loss: 2.0283954540888467

Epoch: 6| Step: 13
Training loss: 1.7303766012191772
Validation loss: 2.018641630808512

Epoch: 92| Step: 0
Training loss: 2.0331034660339355
Validation loss: 2.0223457415898642

Epoch: 6| Step: 1
Training loss: 2.189448356628418
Validation loss: 2.0251368284225464

Epoch: 6| Step: 2
Training loss: 2.289745807647705
Validation loss: 2.015693803628286

Epoch: 6| Step: 3
Training loss: 2.1639111042022705
Validation loss: 2.0177000761032104

Epoch: 6| Step: 4
Training loss: 2.537350654602051
Validation loss: 2.0164074103037515

Epoch: 6| Step: 5
Training loss: 2.2953648567199707
Validation loss: 2.0166983008384705

Epoch: 6| Step: 6
Training loss: 2.060792922973633
Validation loss: 2.017901341120402

Epoch: 6| Step: 7
Training loss: 2.3997974395751953
Validation loss: 2.0201719403266907

Epoch: 6| Step: 8
Training loss: 2.0686779022216797
Validation loss: 2.02256186803182

Epoch: 6| Step: 9
Training loss: 1.6130175590515137
Validation loss: 2.0269686381022134

Epoch: 6| Step: 10
Training loss: 1.830371379852295
Validation loss: 2.030276278654734

Epoch: 6| Step: 11
Training loss: 2.467010498046875
Validation loss: 2.023507237434387

Epoch: 6| Step: 12
Training loss: 1.6228208541870117
Validation loss: 2.0246952970822654

Epoch: 6| Step: 13
Training loss: 2.2878074645996094
Validation loss: 2.022647182146708

Epoch: 93| Step: 0
Training loss: 2.210266351699829
Validation loss: 2.023185114065806

Epoch: 6| Step: 1
Training loss: 2.514742374420166
Validation loss: 2.024696667989095

Epoch: 6| Step: 2
Training loss: 2.177415370941162
Validation loss: 2.0227227807044983

Epoch: 6| Step: 3
Training loss: 2.1255483627319336
Validation loss: 2.0304155945777893

Epoch: 6| Step: 4
Training loss: 2.6099605560302734
Validation loss: 2.029597024122874

Epoch: 6| Step: 5
Training loss: 1.9542447328567505
Validation loss: 2.019719878832499

Epoch: 6| Step: 6
Training loss: 1.897571086883545
Validation loss: 2.0196522076924643

Epoch: 6| Step: 7
Training loss: 2.165576457977295
Validation loss: 2.0267263650894165

Epoch: 6| Step: 8
Training loss: 2.3443613052368164
Validation loss: 2.0228792826334634

Epoch: 6| Step: 9
Training loss: 2.671360492706299
Validation loss: 2.0105179150899253

Epoch: 6| Step: 10
Training loss: 1.8675236701965332
Validation loss: 2.012357930342356

Epoch: 6| Step: 11
Training loss: 1.6937495470046997
Validation loss: 2.012593924999237

Epoch: 6| Step: 12
Training loss: 1.7660729885101318
Validation loss: 2.007760306199392

Epoch: 6| Step: 13
Training loss: 1.932344913482666
Validation loss: 2.011591653029124

Epoch: 94| Step: 0
Training loss: 1.9152758121490479
Validation loss: 2.022365311781565

Epoch: 6| Step: 1
Training loss: 2.6234960556030273
Validation loss: 2.0181986490885415

Epoch: 6| Step: 2
Training loss: 1.7712922096252441
Validation loss: 2.0329235792160034

Epoch: 6| Step: 3
Training loss: 1.8053058385849
Validation loss: 2.0404794613520303

Epoch: 6| Step: 4
Training loss: 2.1819827556610107
Validation loss: 2.0286311705907187

Epoch: 6| Step: 5
Training loss: 2.4962291717529297
Validation loss: 2.0194729367891946

Epoch: 6| Step: 6
Training loss: 2.0655431747436523
Validation loss: 2.032132863998413

Epoch: 6| Step: 7
Training loss: 2.4584603309631348
Validation loss: 2.0251196225484214

Epoch: 6| Step: 8
Training loss: 1.8512178659439087
Validation loss: 2.0282361110051474

Epoch: 6| Step: 9
Training loss: 2.0548250675201416
Validation loss: 2.020739436149597

Epoch: 6| Step: 10
Training loss: 1.5948376655578613
Validation loss: 2.014484226703644

Epoch: 6| Step: 11
Training loss: 2.539341688156128
Validation loss: 2.0217366218566895

Epoch: 6| Step: 12
Training loss: 2.5609726905822754
Validation loss: 2.016522149244944

Epoch: 6| Step: 13
Training loss: 1.814857840538025
Validation loss: 2.015472133954366

Epoch: 95| Step: 0
Training loss: 2.3781864643096924
Validation loss: 2.012186805407206

Epoch: 6| Step: 1
Training loss: 2.0099828243255615
Validation loss: 2.0082728068033853

Epoch: 6| Step: 2
Training loss: 2.2659952640533447
Validation loss: 2.01689213514328

Epoch: 6| Step: 3
Training loss: 1.9079952239990234
Validation loss: 2.023263851801554

Epoch: 6| Step: 4
Training loss: 2.1769285202026367
Validation loss: 2.017892281214396

Epoch: 6| Step: 5
Training loss: 2.095041275024414
Validation loss: 2.021978199481964

Epoch: 6| Step: 6
Training loss: 2.281363010406494
Validation loss: 2.0188312927881875

Epoch: 6| Step: 7
Training loss: 2.1946544647216797
Validation loss: 2.025098125139872

Epoch: 6| Step: 8
Training loss: 2.112372398376465
Validation loss: 2.0176373720169067

Epoch: 6| Step: 9
Training loss: 2.010314702987671
Validation loss: 2.012158989906311

Epoch: 6| Step: 10
Training loss: 2.5152668952941895
Validation loss: 2.0057694911956787

Epoch: 6| Step: 11
Training loss: 1.844252109527588
Validation loss: 2.0048941175142923

Epoch: 6| Step: 12
Training loss: 1.9158340692520142
Validation loss: 2.018150210380554

Epoch: 6| Step: 13
Training loss: 2.1082725524902344
Validation loss: 2.0110175212224326

Epoch: 96| Step: 0
Training loss: 2.0100576877593994
Validation loss: 2.0191970070203147

Epoch: 6| Step: 1
Training loss: 2.375361680984497
Validation loss: 2.014184594154358

Epoch: 6| Step: 2
Training loss: 2.5473275184631348
Validation loss: 2.016672730445862

Epoch: 6| Step: 3
Training loss: 1.7573717832565308
Validation loss: 2.0193177660306296

Epoch: 6| Step: 4
Training loss: 1.9015674591064453
Validation loss: 2.017380118370056

Epoch: 6| Step: 5
Training loss: 2.1512866020202637
Validation loss: 2.013527790705363

Epoch: 6| Step: 6
Training loss: 1.809436321258545
Validation loss: 2.0098223884900412

Epoch: 6| Step: 7
Training loss: 2.5392470359802246
Validation loss: 2.0093053579330444

Epoch: 6| Step: 8
Training loss: 2.3534483909606934
Validation loss: 2.01571919520696

Epoch: 6| Step: 9
Training loss: 2.233351469039917
Validation loss: 2.0107406179110208

Epoch: 6| Step: 10
Training loss: 1.8932626247406006
Validation loss: 2.0049113829930625

Epoch: 6| Step: 11
Training loss: 2.109071969985962
Validation loss: 2.006962696711222

Epoch: 6| Step: 12
Training loss: 2.3289451599121094
Validation loss: 2.003717521826426

Epoch: 6| Step: 13
Training loss: 2.1416103839874268
Validation loss: 2.0035558541615806

Epoch: 97| Step: 0
Training loss: 2.265474319458008
Validation loss: 2.0059867699941

Epoch: 6| Step: 1
Training loss: 2.1180737018585205
Validation loss: 2.016430219014486

Epoch: 6| Step: 2
Training loss: 1.9891695976257324
Validation loss: 2.0212039748827615

Epoch: 6| Step: 3
Training loss: 2.3894593715667725
Validation loss: 2.0413577556610107

Epoch: 6| Step: 4
Training loss: 2.2820382118225098
Validation loss: 2.037011524041494

Epoch: 6| Step: 5
Training loss: 3.035191059112549
Validation loss: 2.0569024880727134

Epoch: 6| Step: 6
Training loss: 1.7571523189544678
Validation loss: 2.045890967051188

Epoch: 6| Step: 7
Training loss: 2.1853580474853516
Validation loss: 2.0623974005381265

Epoch: 6| Step: 8
Training loss: 2.301598310470581
Validation loss: 2.049607833226522

Epoch: 6| Step: 9
Training loss: 2.1176400184631348
Validation loss: 2.0236288706461587

Epoch: 6| Step: 10
Training loss: 1.6881301403045654
Validation loss: 2.018190244833628

Epoch: 6| Step: 11
Training loss: 2.1846632957458496
Validation loss: 2.023657282193502

Epoch: 6| Step: 12
Training loss: 1.497822642326355
Validation loss: 2.0101347168286643

Epoch: 6| Step: 13
Training loss: 2.1773154735565186
Validation loss: 2.0188019474347434

Epoch: 98| Step: 0
Training loss: 2.2992801666259766
Validation loss: 2.0047841469446817

Epoch: 6| Step: 1
Training loss: 2.248404026031494
Validation loss: 2.0026585459709167

Epoch: 6| Step: 2
Training loss: 2.0151140689849854
Validation loss: 2.0089621345202127

Epoch: 6| Step: 3
Training loss: 2.4282467365264893
Validation loss: 2.0126552979151406

Epoch: 6| Step: 4
Training loss: 2.6666371822357178
Validation loss: 2.0039172967274985

Epoch: 6| Step: 5
Training loss: 1.5484888553619385
Validation loss: 2.0029051701227822

Epoch: 6| Step: 6
Training loss: 1.48954176902771
Validation loss: 2.0088505347569785

Epoch: 6| Step: 7
Training loss: 2.39925479888916
Validation loss: 2.0105360945065818

Epoch: 6| Step: 8
Training loss: 2.5880675315856934
Validation loss: 2.0014023582140603

Epoch: 6| Step: 9
Training loss: 2.1173837184906006
Validation loss: 2.010837972164154

Epoch: 6| Step: 10
Training loss: 1.593458652496338
Validation loss: 2.0084168712298074

Epoch: 6| Step: 11
Training loss: 1.9552066326141357
Validation loss: 2.017699718475342

Epoch: 6| Step: 12
Training loss: 2.257343292236328
Validation loss: 2.017976442972819

Epoch: 6| Step: 13
Training loss: 2.080174684524536
Validation loss: 2.0321222941080728

Epoch: 99| Step: 0
Training loss: 2.0532708168029785
Validation loss: 2.031712611516317

Epoch: 6| Step: 1
Training loss: 1.927617073059082
Validation loss: 2.0259007811546326

Epoch: 6| Step: 2
Training loss: 1.7701890468597412
Validation loss: 2.031705101331075

Epoch: 6| Step: 3
Training loss: 2.1653082370758057
Validation loss: 2.0341208775838218

Epoch: 6| Step: 4
Training loss: 2.632575035095215
Validation loss: 2.036261816819509

Epoch: 6| Step: 5
Training loss: 1.9442226886749268
Validation loss: 2.033452093601227

Epoch: 6| Step: 6
Training loss: 2.107543468475342
Validation loss: 2.028964718182882

Epoch: 6| Step: 7
Training loss: 2.2116408348083496
Validation loss: 2.0248774687449136

Epoch: 6| Step: 8
Training loss: 2.704625368118286
Validation loss: 2.014879902203878

Epoch: 6| Step: 9
Training loss: 2.2977633476257324
Validation loss: 2.0143073995908103

Epoch: 6| Step: 10
Training loss: 2.0056750774383545
Validation loss: 2.0107134580612183

Epoch: 6| Step: 11
Training loss: 2.02085280418396
Validation loss: 2.017067313194275

Epoch: 6| Step: 12
Training loss: 2.2147841453552246
Validation loss: 2.024234195550283

Epoch: 6| Step: 13
Training loss: 1.6877541542053223
Validation loss: 2.0123597979545593

Epoch: 100| Step: 0
Training loss: 1.9788172245025635
Validation loss: 2.0278868476549783

Epoch: 6| Step: 1
Training loss: 2.073352813720703
Validation loss: 2.0260496934254966

Epoch: 6| Step: 2
Training loss: 2.6257858276367188
Validation loss: 2.026711642742157

Epoch: 6| Step: 3
Training loss: 1.5318107604980469
Validation loss: 2.030692378679911

Epoch: 6| Step: 4
Training loss: 2.0318922996520996
Validation loss: 2.0365522305170694

Epoch: 6| Step: 5
Training loss: 2.0074002742767334
Validation loss: 2.0251000920931497

Epoch: 6| Step: 6
Training loss: 2.2662713527679443
Validation loss: 2.027939716974894

Epoch: 6| Step: 7
Training loss: 2.217803478240967
Validation loss: 2.0289489030838013

Epoch: 6| Step: 8
Training loss: 1.7378809452056885
Validation loss: 2.0253518422444663

Epoch: 6| Step: 9
Training loss: 1.8880550861358643
Validation loss: 2.0084455609321594

Epoch: 6| Step: 10
Training loss: 2.1648001670837402
Validation loss: 2.0031345089276633

Epoch: 6| Step: 11
Training loss: 1.9829338788986206
Validation loss: 2.004652976989746

Epoch: 6| Step: 12
Training loss: 2.6519429683685303
Validation loss: 2.011416574319204

Epoch: 6| Step: 13
Training loss: 2.6351585388183594
Validation loss: 2.0103541215260825

Epoch: 101| Step: 0
Training loss: 2.4845547676086426
Validation loss: 2.011647423108419

Epoch: 6| Step: 1
Training loss: 1.7287201881408691
Validation loss: 2.012336532274882

Epoch: 6| Step: 2
Training loss: 3.0494544506073
Validation loss: 2.0121518969535828

Epoch: 6| Step: 3
Training loss: 1.826608419418335
Validation loss: 2.0112515687942505

Epoch: 6| Step: 4
Training loss: 1.7088133096694946
Validation loss: 2.0020985205968223

Epoch: 6| Step: 5
Training loss: 2.200500965118408
Validation loss: 2.0045183102289834

Epoch: 6| Step: 6
Training loss: 2.4004626274108887
Validation loss: 1.99757581949234

Epoch: 6| Step: 7
Training loss: 1.9034240245819092
Validation loss: 2.0002784927686057

Epoch: 6| Step: 8
Training loss: 2.5130724906921387
Validation loss: 2.021447022755941

Epoch: 6| Step: 9
Training loss: 1.8382210731506348
Validation loss: 2.0240816871325173

Epoch: 6| Step: 10
Training loss: 2.4004483222961426
Validation loss: 2.015819013118744

Epoch: 6| Step: 11
Training loss: 2.1278367042541504
Validation loss: 2.031791090965271

Epoch: 6| Step: 12
Training loss: 2.095411777496338
Validation loss: 2.0285147627194724

Epoch: 6| Step: 13
Training loss: 1.9119335412979126
Validation loss: 2.0523231625556946

Epoch: 102| Step: 0
Training loss: 1.8406312465667725
Validation loss: 2.043458183606466

Epoch: 6| Step: 1
Training loss: 2.699580430984497
Validation loss: 2.039215306440989

Epoch: 6| Step: 2
Training loss: 2.0373053550720215
Validation loss: 2.029210408528646

Epoch: 6| Step: 3
Training loss: 2.2971432209014893
Validation loss: 2.0224222342173257

Epoch: 6| Step: 4
Training loss: 2.446751356124878
Validation loss: 2.0040480891863504

Epoch: 6| Step: 5
Training loss: 2.256211042404175
Validation loss: 2.0101855993270874

Epoch: 6| Step: 6
Training loss: 2.126965045928955
Validation loss: 2.0203258196512857

Epoch: 6| Step: 7
Training loss: 2.1866650581359863
Validation loss: 2.0122836232185364

Epoch: 6| Step: 8
Training loss: 1.9677332639694214
Validation loss: 2.017533322175344

Epoch: 6| Step: 9
Training loss: 2.380948781967163
Validation loss: 2.011231700579325

Epoch: 6| Step: 10
Training loss: 2.0836284160614014
Validation loss: 2.013282517592112

Epoch: 6| Step: 11
Training loss: 1.854219675064087
Validation loss: 2.007323404153188

Epoch: 6| Step: 12
Training loss: 1.8126697540283203
Validation loss: 2.017114579677582

Epoch: 6| Step: 13
Training loss: 2.2863898277282715
Validation loss: 2.016269564628601

Epoch: 103| Step: 0
Training loss: 2.010200023651123
Validation loss: 2.0214678843816123

Epoch: 6| Step: 1
Training loss: 2.9706506729125977
Validation loss: 2.0209516286849976

Epoch: 6| Step: 2
Training loss: 1.6294145584106445
Validation loss: 2.0401792327562966

Epoch: 6| Step: 3
Training loss: 1.3932862281799316
Validation loss: 2.0223864118258157

Epoch: 6| Step: 4
Training loss: 2.0699057579040527
Validation loss: 2.028770089149475

Epoch: 6| Step: 5
Training loss: 2.290041446685791
Validation loss: 2.0221304297447205

Epoch: 6| Step: 6
Training loss: 1.4863171577453613
Validation loss: 2.0131998459498086

Epoch: 6| Step: 7
Training loss: 2.0995805263519287
Validation loss: 2.0203214486440024

Epoch: 6| Step: 8
Training loss: 2.1266930103302
Validation loss: 2.0294942061106362

Epoch: 6| Step: 9
Training loss: 2.7617573738098145
Validation loss: 2.034235179424286

Epoch: 6| Step: 10
Training loss: 1.7980716228485107
Validation loss: 2.0320947567621865

Epoch: 6| Step: 11
Training loss: 2.3399412631988525
Validation loss: 2.0521461566289267

Epoch: 6| Step: 12
Training loss: 2.360185146331787
Validation loss: 2.0516554713249207

Epoch: 6| Step: 13
Training loss: 2.1880764961242676
Validation loss: 2.0495391289393106

Epoch: 104| Step: 0
Training loss: 1.5381245613098145
Validation loss: 2.04274054368337

Epoch: 6| Step: 1
Training loss: 1.9232360124588013
Validation loss: 2.017947554588318

Epoch: 6| Step: 2
Training loss: 2.1305439472198486
Validation loss: 2.028725246588389

Epoch: 6| Step: 3
Training loss: 1.9484541416168213
Validation loss: 2.016302684942881

Epoch: 6| Step: 4
Training loss: 1.9475510120391846
Validation loss: 2.019279738267263

Epoch: 6| Step: 5
Training loss: 2.066927909851074
Validation loss: 2.025596797466278

Epoch: 6| Step: 6
Training loss: 2.3438963890075684
Validation loss: 2.037610491116842

Epoch: 6| Step: 7
Training loss: 2.3185763359069824
Validation loss: 2.043368617693583

Epoch: 6| Step: 8
Training loss: 2.681144952774048
Validation loss: 2.0352263847986856

Epoch: 6| Step: 9
Training loss: 2.326364517211914
Validation loss: 2.0408907334009805

Epoch: 6| Step: 10
Training loss: 2.575742244720459
Validation loss: 2.037807822227478

Epoch: 6| Step: 11
Training loss: 2.2475779056549072
Validation loss: 2.03342338403066

Epoch: 6| Step: 12
Training loss: 1.6571986675262451
Validation loss: 2.0392070611317954

Epoch: 6| Step: 13
Training loss: 2.6046183109283447
Validation loss: 2.0400527119636536

Epoch: 105| Step: 0
Training loss: 1.9026527404785156
Validation loss: 2.033045212427775

Epoch: 6| Step: 1
Training loss: 2.1184582710266113
Validation loss: 2.0321810046831765

Epoch: 6| Step: 2
Training loss: 2.500741481781006
Validation loss: 2.0255261262257895

Epoch: 6| Step: 3
Training loss: 1.5850985050201416
Validation loss: 2.021003703276316

Epoch: 6| Step: 4
Training loss: 2.300936222076416
Validation loss: 2.0146735509236655

Epoch: 6| Step: 5
Training loss: 2.847618818283081
Validation loss: 2.0115608175595603

Epoch: 6| Step: 6
Training loss: 2.624352216720581
Validation loss: 2.0110339522361755

Epoch: 6| Step: 7
Training loss: 1.3760700225830078
Validation loss: 2.0136844714482627

Epoch: 6| Step: 8
Training loss: 2.114841938018799
Validation loss: 2.014934778213501

Epoch: 6| Step: 9
Training loss: 1.5909531116485596
Validation loss: 2.0131253004074097

Epoch: 6| Step: 10
Training loss: 2.1766576766967773
Validation loss: 2.022779862085978

Epoch: 6| Step: 11
Training loss: 2.3196420669555664
Validation loss: 2.034131666024526

Epoch: 6| Step: 12
Training loss: 2.3911402225494385
Validation loss: 2.035857001940409

Epoch: 6| Step: 13
Training loss: 2.158297538757324
Validation loss: 2.0400933424631753

Epoch: 106| Step: 0
Training loss: 1.6554229259490967
Validation loss: 2.038532813390096

Epoch: 6| Step: 1
Training loss: 2.371168613433838
Validation loss: 2.0323731303215027

Epoch: 6| Step: 2
Training loss: 1.8664255142211914
Validation loss: 2.02187313636144

Epoch: 6| Step: 3
Training loss: 1.6336266994476318
Validation loss: 2.0201608538627625

Epoch: 6| Step: 4
Training loss: 2.552175521850586
Validation loss: 2.0191763838132224

Epoch: 6| Step: 5
Training loss: 1.790381669998169
Validation loss: 2.008507033189138

Epoch: 6| Step: 6
Training loss: 2.845895767211914
Validation loss: 2.0057902137438455

Epoch: 6| Step: 7
Training loss: 2.6170969009399414
Validation loss: 2.0050170620282493

Epoch: 6| Step: 8
Training loss: 1.6747581958770752
Validation loss: 2.022404432296753

Epoch: 6| Step: 9
Training loss: 2.274322032928467
Validation loss: 2.0160007874170938

Epoch: 6| Step: 10
Training loss: 2.368037462234497
Validation loss: 2.011185268561045

Epoch: 6| Step: 11
Training loss: 2.1873135566711426
Validation loss: 2.0039714773495994

Epoch: 6| Step: 12
Training loss: 2.6790542602539062
Validation loss: 2.013014634450277

Epoch: 6| Step: 13
Training loss: 1.357421875
Validation loss: 2.0087205171585083

Epoch: 107| Step: 0
Training loss: 1.5816234350204468
Validation loss: 2.009463648001353

Epoch: 6| Step: 1
Training loss: 1.5681806802749634
Validation loss: 2.0108185609181723

Epoch: 6| Step: 2
Training loss: 1.9712557792663574
Validation loss: 2.0149683753649392

Epoch: 6| Step: 3
Training loss: 2.7078676223754883
Validation loss: 2.009337623914083

Epoch: 6| Step: 4
Training loss: 1.7995884418487549
Validation loss: 2.028596818447113

Epoch: 6| Step: 5
Training loss: 2.329224109649658
Validation loss: 2.018814265727997

Epoch: 6| Step: 6
Training loss: 1.5502426624298096
Validation loss: 2.0349854628245034

Epoch: 6| Step: 7
Training loss: 2.420560121536255
Validation loss: 2.0403894186019897

Epoch: 6| Step: 8
Training loss: 1.9039708375930786
Validation loss: 2.043971578280131

Epoch: 6| Step: 9
Training loss: 2.1851930618286133
Validation loss: 2.045190989971161

Epoch: 6| Step: 10
Training loss: 2.709730386734009
Validation loss: 2.036777118841807

Epoch: 6| Step: 11
Training loss: 2.5799453258514404
Validation loss: 2.029306252797445

Epoch: 6| Step: 12
Training loss: 2.358696222305298
Validation loss: 2.011666774749756

Epoch: 6| Step: 13
Training loss: 2.127225399017334
Validation loss: 2.0213064750035605

Epoch: 108| Step: 0
Training loss: 1.7475221157073975
Validation loss: 2.0110048055648804

Epoch: 6| Step: 1
Training loss: 1.9648274183273315
Validation loss: 2.0072544614473977

Epoch: 6| Step: 2
Training loss: 2.216010808944702
Validation loss: 2.012373904387156

Epoch: 6| Step: 3
Training loss: 1.5796104669570923
Validation loss: 2.0055901606877646

Epoch: 6| Step: 4
Training loss: 2.322154998779297
Validation loss: 2.013044834136963

Epoch: 6| Step: 5
Training loss: 2.3297863006591797
Validation loss: 2.0097662210464478

Epoch: 6| Step: 6
Training loss: 2.425340175628662
Validation loss: 2.0279686053593955

Epoch: 6| Step: 7
Training loss: 1.8950297832489014
Validation loss: 2.0225223700205484

Epoch: 6| Step: 8
Training loss: 1.484705924987793
Validation loss: 2.027206857999166

Epoch: 6| Step: 9
Training loss: 3.1939687728881836
Validation loss: 2.026833256085714

Epoch: 6| Step: 10
Training loss: 2.3528900146484375
Validation loss: 2.027908762296041

Epoch: 6| Step: 11
Training loss: 1.9442660808563232
Validation loss: 2.0317832628885903

Epoch: 6| Step: 12
Training loss: 2.2970364093780518
Validation loss: 2.0303574601809182

Epoch: 6| Step: 13
Training loss: 1.9802665710449219
Validation loss: 2.036185880502065

Epoch: 109| Step: 0
Training loss: 1.463498830795288
Validation loss: 2.0526506900787354

Epoch: 6| Step: 1
Training loss: 1.430833339691162
Validation loss: 2.0405300060908

Epoch: 6| Step: 2
Training loss: 2.697986125946045
Validation loss: 2.039594570795695

Epoch: 6| Step: 3
Training loss: 2.156343936920166
Validation loss: 2.0538752476374307

Epoch: 6| Step: 4
Training loss: 2.3502893447875977
Validation loss: 2.0528031388918557

Epoch: 6| Step: 5
Training loss: 2.289304256439209
Validation loss: 2.044120669364929

Epoch: 6| Step: 6
Training loss: 2.1817171573638916
Validation loss: 2.0306643644968667

Epoch: 6| Step: 7
Training loss: 2.691310405731201
Validation loss: 2.0388488173484802

Epoch: 6| Step: 8
Training loss: 2.324875831604004
Validation loss: 2.0386680364608765

Epoch: 6| Step: 9
Training loss: 1.6477675437927246
Validation loss: 2.0481542348861694

Epoch: 6| Step: 10
Training loss: 1.756845235824585
Validation loss: 2.049976408481598

Epoch: 6| Step: 11
Training loss: 1.948197841644287
Validation loss: 2.040074904759725

Epoch: 6| Step: 12
Training loss: 1.96023690700531
Validation loss: 2.0443394581476846

Epoch: 6| Step: 13
Training loss: 2.545611619949341
Validation loss: 2.0516359408696494

Epoch: 110| Step: 0
Training loss: 2.0531938076019287
Validation loss: 2.0461694995562234

Epoch: 6| Step: 1
Training loss: 1.8715500831604004
Validation loss: 2.030287504196167

Epoch: 6| Step: 2
Training loss: 2.228533983230591
Validation loss: 2.0381298462549844

Epoch: 6| Step: 3
Training loss: 2.548379898071289
Validation loss: 2.0219279130299888

Epoch: 6| Step: 4
Training loss: 2.5400328636169434
Validation loss: 2.01085764169693

Epoch: 6| Step: 5
Training loss: 1.8878371715545654
Validation loss: 2.0203694701194763

Epoch: 6| Step: 6
Training loss: 1.5983989238739014
Validation loss: 2.01941309372584

Epoch: 6| Step: 7
Training loss: 2.8247287273406982
Validation loss: 2.012623608112335

Epoch: 6| Step: 8
Training loss: 1.9827781915664673
Validation loss: 2.0150870084762573

Epoch: 6| Step: 9
Training loss: 1.7378793954849243
Validation loss: 2.019208610057831

Epoch: 6| Step: 10
Training loss: 2.058448553085327
Validation loss: 2.0150149861971536

Epoch: 6| Step: 11
Training loss: 2.123812198638916
Validation loss: 2.01622074842453

Epoch: 6| Step: 12
Training loss: 1.7036309242248535
Validation loss: 2.0209972858428955

Epoch: 6| Step: 13
Training loss: 2.3418197631835938
Validation loss: 2.0231342116991677

Epoch: 111| Step: 0
Training loss: 1.6792608499526978
Validation loss: 2.026386082172394

Epoch: 6| Step: 1
Training loss: 1.8399146795272827
Validation loss: 2.033952752749125

Epoch: 6| Step: 2
Training loss: 2.0169849395751953
Validation loss: 2.053660750389099

Epoch: 6| Step: 3
Training loss: 2.2033514976501465
Validation loss: 2.046187162399292

Epoch: 6| Step: 4
Training loss: 2.595799446105957
Validation loss: 2.063781499862671

Epoch: 6| Step: 5
Training loss: 2.6259524822235107
Validation loss: 2.043704549471537

Epoch: 6| Step: 6
Training loss: 2.007899284362793
Validation loss: 2.043501079082489

Epoch: 6| Step: 7
Training loss: 2.060945987701416
Validation loss: 2.030794342358907

Epoch: 6| Step: 8
Training loss: 1.9862573146820068
Validation loss: 2.026310125986735

Epoch: 6| Step: 9
Training loss: 1.8039898872375488
Validation loss: 2.023273785909017

Epoch: 6| Step: 10
Training loss: 1.679797887802124
Validation loss: 2.022304634253184

Epoch: 6| Step: 11
Training loss: 2.7568795680999756
Validation loss: 2.0166098872820535

Epoch: 6| Step: 12
Training loss: 2.572432518005371
Validation loss: 2.021324574947357

Epoch: 6| Step: 13
Training loss: 1.9466406106948853
Validation loss: 2.026512563228607

Epoch: 112| Step: 0
Training loss: 2.2315566539764404
Validation loss: 2.0243141849835715

Epoch: 6| Step: 1
Training loss: 1.8336412906646729
Validation loss: 2.0211823185284934

Epoch: 6| Step: 2
Training loss: 2.3224048614501953
Validation loss: 2.0248879392941794

Epoch: 6| Step: 3
Training loss: 2.5756564140319824
Validation loss: 2.0386215647061667

Epoch: 6| Step: 4
Training loss: 1.3559818267822266
Validation loss: 2.025549610455831

Epoch: 6| Step: 5
Training loss: 2.288442373275757
Validation loss: 2.0288125475247702

Epoch: 6| Step: 6
Training loss: 1.8229022026062012
Validation loss: 2.0254081885019937

Epoch: 6| Step: 7
Training loss: 2.3377773761749268
Validation loss: 2.0268982648849487

Epoch: 6| Step: 8
Training loss: 1.6075241565704346
Validation loss: 2.024865706761678

Epoch: 6| Step: 9
Training loss: 2.621269941329956
Validation loss: 2.0201865235964456

Epoch: 6| Step: 10
Training loss: 1.7301818132400513
Validation loss: 2.022417982419332

Epoch: 6| Step: 11
Training loss: 2.0396671295166016
Validation loss: 2.019145687421163

Epoch: 6| Step: 12
Training loss: 2.1256933212280273
Validation loss: 2.017181317011515

Epoch: 6| Step: 13
Training loss: 2.444995880126953
Validation loss: 2.0293264985084534

Epoch: 113| Step: 0
Training loss: 1.7852108478546143
Validation loss: 2.0271416703859964

Epoch: 6| Step: 1
Training loss: 2.1113271713256836
Validation loss: 2.041127840677897

Epoch: 6| Step: 2
Training loss: 2.244353771209717
Validation loss: 2.0432696541150412

Epoch: 6| Step: 3
Training loss: 2.1447813510894775
Validation loss: 2.044173002243042

Epoch: 6| Step: 4
Training loss: 1.838208794593811
Validation loss: 2.035467286904653

Epoch: 6| Step: 5
Training loss: 1.784158706665039
Validation loss: 2.0400113264719644

Epoch: 6| Step: 6
Training loss: 2.0228171348571777
Validation loss: 2.0395781993865967

Epoch: 6| Step: 7
Training loss: 2.3196659088134766
Validation loss: 2.030839224656423

Epoch: 6| Step: 8
Training loss: 2.126185655593872
Validation loss: 2.0381060043970742

Epoch: 6| Step: 9
Training loss: 2.470179796218872
Validation loss: 2.013725697994232

Epoch: 6| Step: 10
Training loss: 1.6895976066589355
Validation loss: 2.028348207473755

Epoch: 6| Step: 11
Training loss: 1.9919832944869995
Validation loss: 2.0253533323605857

Epoch: 6| Step: 12
Training loss: 2.451420307159424
Validation loss: 2.0214372475941977

Epoch: 6| Step: 13
Training loss: 2.2784547805786133
Validation loss: 2.0183314085006714

Epoch: 114| Step: 0
Training loss: 2.2637224197387695
Validation loss: 2.0179506738980613

Epoch: 6| Step: 1
Training loss: 2.284269094467163
Validation loss: 2.0237553119659424

Epoch: 6| Step: 2
Training loss: 1.8641324043273926
Validation loss: 2.0191579262415567

Epoch: 6| Step: 3
Training loss: 2.38691782951355
Validation loss: 2.0117639899253845

Epoch: 6| Step: 4
Training loss: 2.3554015159606934
Validation loss: 2.013688385486603

Epoch: 6| Step: 5
Training loss: 2.1673989295959473
Validation loss: 2.014917771021525

Epoch: 6| Step: 6
Training loss: 1.6999260187149048
Validation loss: 2.021384517351786

Epoch: 6| Step: 7
Training loss: 2.1276164054870605
Validation loss: 2.016374429066976

Epoch: 6| Step: 8
Training loss: 2.1656906604766846
Validation loss: 2.0178552667299905

Epoch: 6| Step: 9
Training loss: 1.9128376245498657
Validation loss: 2.0253689686457315

Epoch: 6| Step: 10
Training loss: 1.8346282243728638
Validation loss: 2.0320640405019126

Epoch: 6| Step: 11
Training loss: 2.6098945140838623
Validation loss: 2.0194573203722634

Epoch: 6| Step: 12
Training loss: 1.8707363605499268
Validation loss: 2.0207013686498008

Epoch: 6| Step: 13
Training loss: 1.9769896268844604
Validation loss: 2.0103225310643515

Epoch: 115| Step: 0
Training loss: 2.031059741973877
Validation loss: 2.013910174369812

Epoch: 6| Step: 1
Training loss: 1.3225523233413696
Validation loss: 2.0166439016660056

Epoch: 6| Step: 2
Training loss: 2.6739437580108643
Validation loss: 2.0181082288424173

Epoch: 6| Step: 3
Training loss: 2.507366418838501
Validation loss: 2.015692889690399

Epoch: 6| Step: 4
Training loss: 1.3111512660980225
Validation loss: 2.0155691504478455

Epoch: 6| Step: 5
Training loss: 2.0215444564819336
Validation loss: 2.0142791469891868

Epoch: 6| Step: 6
Training loss: 2.2380239963531494
Validation loss: 2.029520889123281

Epoch: 6| Step: 7
Training loss: 2.220789909362793
Validation loss: 2.0260939598083496

Epoch: 6| Step: 8
Training loss: 1.9899208545684814
Validation loss: 2.019667645295461

Epoch: 6| Step: 9
Training loss: 2.0481653213500977
Validation loss: 2.0264620184898376

Epoch: 6| Step: 10
Training loss: 2.168853282928467
Validation loss: 2.0098209778467813

Epoch: 6| Step: 11
Training loss: 2.532118320465088
Validation loss: 2.022915025552114

Epoch: 6| Step: 12
Training loss: 1.7164194583892822
Validation loss: 2.0119199554125466

Epoch: 6| Step: 13
Training loss: 2.4901328086853027
Validation loss: 2.0193108717600503

Epoch: 116| Step: 0
Training loss: 2.6525793075561523
Validation loss: 2.0114362438519797

Epoch: 6| Step: 1
Training loss: 1.9804786443710327
Validation loss: 2.0226835211118064

Epoch: 6| Step: 2
Training loss: 2.251502275466919
Validation loss: 2.0231662591298423

Epoch: 6| Step: 3
Training loss: 2.147334575653076
Validation loss: 2.016739805539449

Epoch: 6| Step: 4
Training loss: 2.640160083770752
Validation loss: 2.0201417009035745

Epoch: 6| Step: 5
Training loss: 2.1822755336761475
Validation loss: 2.013386348883311

Epoch: 6| Step: 6
Training loss: 1.2974512577056885
Validation loss: 2.0255122979482016

Epoch: 6| Step: 7
Training loss: 1.8101274967193604
Validation loss: 2.032443900903066

Epoch: 6| Step: 8
Training loss: 2.3858728408813477
Validation loss: 2.031952122847239

Epoch: 6| Step: 9
Training loss: 1.591536045074463
Validation loss: 2.023801545302073

Epoch: 6| Step: 10
Training loss: 2.0988030433654785
Validation loss: 2.0341282884279885

Epoch: 6| Step: 11
Training loss: 1.9766544103622437
Validation loss: 2.0259505907694497

Epoch: 6| Step: 12
Training loss: 2.5383167266845703
Validation loss: 2.037150720755259

Epoch: 6| Step: 13
Training loss: 1.5117580890655518
Validation loss: 2.0353793104489646

Epoch: 117| Step: 0
Training loss: 2.2160329818725586
Validation loss: 2.0257747173309326

Epoch: 6| Step: 1
Training loss: 2.1583633422851562
Validation loss: 2.018334607283274

Epoch: 6| Step: 2
Training loss: 2.506791114807129
Validation loss: 2.022310654322306

Epoch: 6| Step: 3
Training loss: 1.7916805744171143
Validation loss: 2.027389168739319

Epoch: 6| Step: 4
Training loss: 1.837357759475708
Validation loss: 2.006966789563497

Epoch: 6| Step: 5
Training loss: 1.8392701148986816
Validation loss: 2.0131096045176187

Epoch: 6| Step: 6
Training loss: 2.356973886489868
Validation loss: 2.0190900564193726

Epoch: 6| Step: 7
Training loss: 3.0426223278045654
Validation loss: 2.0224669774373374

Epoch: 6| Step: 8
Training loss: 1.9859132766723633
Validation loss: 2.013850510120392

Epoch: 6| Step: 9
Training loss: 1.6219006776809692
Validation loss: 2.0282128055890403

Epoch: 6| Step: 10
Training loss: 1.905198097229004
Validation loss: 2.0266091028849282

Epoch: 6| Step: 11
Training loss: 2.087628126144409
Validation loss: 2.0303969383239746

Epoch: 6| Step: 12
Training loss: 1.6636039018630981
Validation loss: 2.0401405890782676

Epoch: 6| Step: 13
Training loss: 2.4114012718200684
Validation loss: 2.0377302964528403

Epoch: 118| Step: 0
Training loss: 2.3055763244628906
Validation loss: 2.041370411713918

Epoch: 6| Step: 1
Training loss: 1.897831916809082
Validation loss: 2.04608420530955

Epoch: 6| Step: 2
Training loss: 2.414026975631714
Validation loss: 2.0492856899897256

Epoch: 6| Step: 3
Training loss: 2.1173219680786133
Validation loss: 2.0490524967511496

Epoch: 6| Step: 4
Training loss: 1.8116388320922852
Validation loss: 2.03584490219752

Epoch: 6| Step: 5
Training loss: 1.8796783685684204
Validation loss: 2.0382072925567627

Epoch: 6| Step: 6
Training loss: 1.5193746089935303
Validation loss: 2.0321189562479653

Epoch: 6| Step: 7
Training loss: 2.1521658897399902
Validation loss: 2.0246726671854653

Epoch: 6| Step: 8
Training loss: 2.1067590713500977
Validation loss: 2.0253761212031045

Epoch: 6| Step: 9
Training loss: 2.555805206298828
Validation loss: 2.0257893006006875

Epoch: 6| Step: 10
Training loss: 1.7536541223526
Validation loss: 2.037766615549723

Epoch: 6| Step: 11
Training loss: 2.447800397872925
Validation loss: 2.0199759205182395

Epoch: 6| Step: 12
Training loss: 1.9733914136886597
Validation loss: 2.028051217397054

Epoch: 6| Step: 13
Training loss: 2.079068183898926
Validation loss: 2.0323254068692527

Epoch: 119| Step: 0
Training loss: 2.1832756996154785
Validation loss: 2.0323228438695273

Epoch: 6| Step: 1
Training loss: 1.5032434463500977
Validation loss: 2.033608853816986

Epoch: 6| Step: 2
Training loss: 1.5163298845291138
Validation loss: 2.0374958316485086

Epoch: 6| Step: 3
Training loss: 2.030061721801758
Validation loss: 2.0269439816474915

Epoch: 6| Step: 4
Training loss: 2.0953617095947266
Validation loss: 2.0278521180152893

Epoch: 6| Step: 5
Training loss: 2.3221583366394043
Validation loss: 2.034697651863098

Epoch: 6| Step: 6
Training loss: 2.5874147415161133
Validation loss: 2.0309011737505593

Epoch: 6| Step: 7
Training loss: 2.1795926094055176
Validation loss: 2.0291057229042053

Epoch: 6| Step: 8
Training loss: 1.6358702182769775
Validation loss: 2.0339460968971252

Epoch: 6| Step: 9
Training loss: 2.5431323051452637
Validation loss: 2.0374181667963662

Epoch: 6| Step: 10
Training loss: 2.3425211906433105
Validation loss: 2.0288788874944053

Epoch: 6| Step: 11
Training loss: 2.3785431385040283
Validation loss: 2.031014641125997

Epoch: 6| Step: 12
Training loss: 1.4584808349609375
Validation loss: 2.0308067202568054

Epoch: 6| Step: 13
Training loss: 2.122901201248169
Validation loss: 2.015301465988159

Epoch: 120| Step: 0
Training loss: 2.1118111610412598
Validation loss: 2.0246074398358664

Epoch: 6| Step: 1
Training loss: 2.1519556045532227
Validation loss: 2.021622439225515

Epoch: 6| Step: 2
Training loss: 2.193668842315674
Validation loss: 2.0300562977790833

Epoch: 6| Step: 3
Training loss: 2.219407320022583
Validation loss: 2.026810050010681

Epoch: 6| Step: 4
Training loss: 1.6027923822402954
Validation loss: 2.034838914871216

Epoch: 6| Step: 5
Training loss: 1.7389583587646484
Validation loss: 2.038620352745056

Epoch: 6| Step: 6
Training loss: 2.175011157989502
Validation loss: 2.0392372608184814

Epoch: 6| Step: 7
Training loss: 2.156160354614258
Validation loss: 2.044919431209564

Epoch: 6| Step: 8
Training loss: 2.1567537784576416
Validation loss: 2.040088494618734

Epoch: 6| Step: 9
Training loss: 1.27213454246521
Validation loss: 2.0332157214482627

Epoch: 6| Step: 10
Training loss: 2.099343776702881
Validation loss: 2.043437659740448

Epoch: 6| Step: 11
Training loss: 2.262578010559082
Validation loss: 2.042123635609945

Epoch: 6| Step: 12
Training loss: 2.789073944091797
Validation loss: 2.035454789797465

Epoch: 6| Step: 13
Training loss: 2.3603503704071045
Validation loss: 2.035848875840505

Epoch: 121| Step: 0
Training loss: 1.955253005027771
Validation loss: 2.0285707910855613

Epoch: 6| Step: 1
Training loss: 2.262608766555786
Validation loss: 2.0209202766418457

Epoch: 6| Step: 2
Training loss: 2.737509250640869
Validation loss: 2.033436675866445

Epoch: 6| Step: 3
Training loss: 1.725149154663086
Validation loss: 2.025376300017039

Epoch: 6| Step: 4
Training loss: 1.8864799737930298
Validation loss: 2.0449381271998086

Epoch: 6| Step: 5
Training loss: 2.1025142669677734
Validation loss: 2.050956964492798

Epoch: 6| Step: 6
Training loss: 2.651388168334961
Validation loss: 2.047670364379883

Epoch: 6| Step: 7
Training loss: 2.7509944438934326
Validation loss: 2.0409825841585794

Epoch: 6| Step: 8
Training loss: 2.158756971359253
Validation loss: 2.0452550649642944

Epoch: 6| Step: 9
Training loss: 1.9996683597564697
Validation loss: 2.0516690413157144

Epoch: 6| Step: 10
Training loss: 2.1145734786987305
Validation loss: 2.04522442817688

Epoch: 6| Step: 11
Training loss: 1.499950885772705
Validation loss: 2.050349454085032

Epoch: 6| Step: 12
Training loss: 2.0535922050476074
Validation loss: 2.0451268553733826

Epoch: 6| Step: 13
Training loss: 2.2969391345977783
Validation loss: 2.040692985057831

Epoch: 122| Step: 0
Training loss: 2.1482062339782715
Validation loss: 2.0475686391194663

Epoch: 6| Step: 1
Training loss: 2.1110639572143555
Validation loss: 2.053301473458608

Epoch: 6| Step: 2
Training loss: 1.797095537185669
Validation loss: 2.0526338617006936

Epoch: 6| Step: 3
Training loss: 1.9206726551055908
Validation loss: 2.0523895819981894

Epoch: 6| Step: 4
Training loss: 1.6266642808914185
Validation loss: 2.0423249204953513

Epoch: 6| Step: 5
Training loss: 2.4583404064178467
Validation loss: 2.03764146566391

Epoch: 6| Step: 6
Training loss: 2.6550583839416504
Validation loss: 2.0325968861579895

Epoch: 6| Step: 7
Training loss: 2.135683536529541
Validation loss: 2.0283291141192117

Epoch: 6| Step: 8
Training loss: 2.175386428833008
Validation loss: 2.025715251763662

Epoch: 6| Step: 9
Training loss: 1.8556711673736572
Validation loss: 2.034774343172709

Epoch: 6| Step: 10
Training loss: 1.9403740167617798
Validation loss: 2.0324410994847617

Epoch: 6| Step: 11
Training loss: 2.201695203781128
Validation loss: 2.035107652346293

Epoch: 6| Step: 12
Training loss: 2.116717576980591
Validation loss: 2.036869208017985

Epoch: 6| Step: 13
Training loss: 2.640204906463623
Validation loss: 2.0341171423594155

Epoch: 123| Step: 0
Training loss: 2.5095434188842773
Validation loss: 2.0202576716740928

Epoch: 6| Step: 1
Training loss: 2.2937722206115723
Validation loss: 2.0286030769348145

Epoch: 6| Step: 2
Training loss: 2.6238155364990234
Validation loss: 2.0331474343935647

Epoch: 6| Step: 3
Training loss: 2.3748135566711426
Validation loss: 2.0340932806332908

Epoch: 6| Step: 4
Training loss: 2.3531723022460938
Validation loss: 2.0315114855766296

Epoch: 6| Step: 5
Training loss: 1.6428004503250122
Validation loss: 2.029552459716797

Epoch: 6| Step: 6
Training loss: 2.0400028228759766
Validation loss: 2.0340631008148193

Epoch: 6| Step: 7
Training loss: 1.7323399782180786
Validation loss: 2.0274727940559387

Epoch: 6| Step: 8
Training loss: 1.4800812005996704
Validation loss: 2.034721533457438

Epoch: 6| Step: 9
Training loss: 1.8159549236297607
Validation loss: 2.027142326037089

Epoch: 6| Step: 10
Training loss: 2.122945547103882
Validation loss: 2.031031866868337

Epoch: 6| Step: 11
Training loss: 2.1188673973083496
Validation loss: 2.0301528573036194

Epoch: 6| Step: 12
Training loss: 1.9851688146591187
Validation loss: 2.02457324663798

Epoch: 6| Step: 13
Training loss: 2.045027732849121
Validation loss: 2.022533575693766

Epoch: 124| Step: 0
Training loss: 2.850034236907959
Validation loss: 2.025030235449473

Epoch: 6| Step: 1
Training loss: 1.656097173690796
Validation loss: 2.0400224328041077

Epoch: 6| Step: 2
Training loss: 1.8517124652862549
Validation loss: 2.0353697141011557

Epoch: 6| Step: 3
Training loss: 1.8408174514770508
Validation loss: 2.032761732737223

Epoch: 6| Step: 4
Training loss: 1.8861534595489502
Validation loss: 2.0308267871538797

Epoch: 6| Step: 5
Training loss: 2.244940757751465
Validation loss: 2.039669076601664

Epoch: 6| Step: 6
Training loss: 2.059925079345703
Validation loss: 2.0352925062179565

Epoch: 6| Step: 7
Training loss: 1.853715419769287
Validation loss: 2.0366517504056296

Epoch: 6| Step: 8
Training loss: 2.3699631690979004
Validation loss: 2.0347727139790854

Epoch: 6| Step: 9
Training loss: 1.7683067321777344
Validation loss: 2.0492700338363647

Epoch: 6| Step: 10
Training loss: 2.1070656776428223
Validation loss: 2.0400659441947937

Epoch: 6| Step: 11
Training loss: 2.2001986503601074
Validation loss: 2.0409759084383645

Epoch: 6| Step: 12
Training loss: 1.888351321220398
Validation loss: 2.0286333759625754

Epoch: 6| Step: 13
Training loss: 2.5537161827087402
Validation loss: 2.043610632419586

Epoch: 125| Step: 0
Training loss: 2.1466636657714844
Validation loss: 2.0371557076772056

Epoch: 6| Step: 1
Training loss: 1.4409570693969727
Validation loss: 2.0247735182444253

Epoch: 6| Step: 2
Training loss: 2.531791925430298
Validation loss: 2.039638419946035

Epoch: 6| Step: 3
Training loss: 2.965614080429077
Validation loss: 2.022910416126251

Epoch: 6| Step: 4
Training loss: 1.7145252227783203
Validation loss: 2.0404566526412964

Epoch: 6| Step: 5
Training loss: 1.9441930055618286
Validation loss: 2.0270607670148215

Epoch: 6| Step: 6
Training loss: 2.253492832183838
Validation loss: 2.032183806101481

Epoch: 6| Step: 7
Training loss: 2.0968570709228516
Validation loss: 2.0367865562438965

Epoch: 6| Step: 8
Training loss: 1.7489286661148071
Validation loss: 2.036370038986206

Epoch: 6| Step: 9
Training loss: 2.1963255405426025
Validation loss: 2.0310670932133994

Epoch: 6| Step: 10
Training loss: 2.224282741546631
Validation loss: 2.036652624607086

Epoch: 6| Step: 11
Training loss: 2.4226949214935303
Validation loss: 2.0293803612391152

Epoch: 6| Step: 12
Training loss: 1.5355539321899414
Validation loss: 2.0313496192296348

Epoch: 6| Step: 13
Training loss: 2.0487818717956543
Validation loss: 2.0312580466270447

Epoch: 126| Step: 0
Training loss: 2.242488145828247
Validation loss: 2.027271548906962

Epoch: 6| Step: 1
Training loss: 2.3769888877868652
Validation loss: 2.0389073689778647

Epoch: 6| Step: 2
Training loss: 2.3875527381896973
Validation loss: 2.048932751019796

Epoch: 6| Step: 3
Training loss: 2.060490608215332
Validation loss: 2.0563112696011863

Epoch: 6| Step: 4
Training loss: 1.7733699083328247
Validation loss: 2.034521500269572

Epoch: 6| Step: 5
Training loss: 1.5656421184539795
Validation loss: 2.040755867958069

Epoch: 6| Step: 6
Training loss: 2.0870907306671143
Validation loss: 2.0437939167022705

Epoch: 6| Step: 7
Training loss: 3.0663681030273438
Validation loss: 2.041538715362549

Epoch: 6| Step: 8
Training loss: 2.238396644592285
Validation loss: 2.02749756971995

Epoch: 6| Step: 9
Training loss: 2.180208683013916
Validation loss: 2.0356605648994446

Epoch: 6| Step: 10
Training loss: 1.6549081802368164
Validation loss: 2.035913427670797

Epoch: 6| Step: 11
Training loss: 2.0205719470977783
Validation loss: 2.029241760571798

Epoch: 6| Step: 12
Training loss: 1.6772706508636475
Validation loss: 2.0223461786905923

Epoch: 6| Step: 13
Training loss: 1.603060007095337
Validation loss: 2.03399387995402

Epoch: 127| Step: 0
Training loss: 2.098747730255127
Validation loss: 2.025318920612335

Epoch: 6| Step: 1
Training loss: 1.8730664253234863
Validation loss: 2.0289336244265237

Epoch: 6| Step: 2
Training loss: 2.28871488571167
Validation loss: 2.033112903436025

Epoch: 6| Step: 3
Training loss: 1.5058718919754028
Validation loss: 2.027162273724874

Epoch: 6| Step: 4
Training loss: 2.490967273712158
Validation loss: 2.0307482481002808

Epoch: 6| Step: 5
Training loss: 1.7859058380126953
Validation loss: 2.0338040788968406

Epoch: 6| Step: 6
Training loss: 2.162553310394287
Validation loss: 2.0323413014411926

Epoch: 6| Step: 7
Training loss: 2.6028127670288086
Validation loss: 2.036976675192515

Epoch: 6| Step: 8
Training loss: 1.931911587715149
Validation loss: 2.032427430152893

Epoch: 6| Step: 9
Training loss: 2.2115750312805176
Validation loss: 2.0358109871546426

Epoch: 6| Step: 10
Training loss: 2.141310214996338
Validation loss: 2.030427893002828

Epoch: 6| Step: 11
Training loss: 2.2998898029327393
Validation loss: 2.0324905117352805

Epoch: 6| Step: 12
Training loss: 1.4819929599761963
Validation loss: 2.0418411095937095

Epoch: 6| Step: 13
Training loss: 2.0454654693603516
Validation loss: 2.046521842479706

Epoch: 128| Step: 0
Training loss: 1.8667677640914917
Validation loss: 2.0452744166056314

Epoch: 6| Step: 1
Training loss: 1.7880979776382446
Validation loss: 2.0387016336123147

Epoch: 6| Step: 2
Training loss: 1.8655941486358643
Validation loss: 2.055916666984558

Epoch: 6| Step: 3
Training loss: 2.406351089477539
Validation loss: 2.0427295366923013

Epoch: 6| Step: 4
Training loss: 2.23766827583313
Validation loss: 2.0425370732943215

Epoch: 6| Step: 5
Training loss: 1.772054672241211
Validation loss: 2.045749386151632

Epoch: 6| Step: 6
Training loss: 1.744525671005249
Validation loss: 2.045260767141978

Epoch: 6| Step: 7
Training loss: 2.306288719177246
Validation loss: 2.034039835135142

Epoch: 6| Step: 8
Training loss: 2.0846986770629883
Validation loss: 2.0529595216115317

Epoch: 6| Step: 9
Training loss: 2.4542057514190674
Validation loss: 2.0445291797320047

Epoch: 6| Step: 10
Training loss: 2.0368735790252686
Validation loss: 2.03801562388738

Epoch: 6| Step: 11
Training loss: 1.84162175655365
Validation loss: 2.0435218612353006

Epoch: 6| Step: 12
Training loss: 1.8291138410568237
Validation loss: 2.042332669099172

Epoch: 6| Step: 13
Training loss: 2.433039665222168
Validation loss: 2.0522632201512656

Epoch: 129| Step: 0
Training loss: 2.347470760345459
Validation loss: 2.0463456312815347

Epoch: 6| Step: 1
Training loss: 1.5584502220153809
Validation loss: 2.0324322978655496

Epoch: 6| Step: 2
Training loss: 1.9713313579559326
Validation loss: 2.0488378604253135

Epoch: 6| Step: 3
Training loss: 1.9505056142807007
Validation loss: 2.041883707046509

Epoch: 6| Step: 4
Training loss: 2.4134321212768555
Validation loss: 2.046915431817373

Epoch: 6| Step: 5
Training loss: 1.9025006294250488
Validation loss: 2.0380125840504966

Epoch: 6| Step: 6
Training loss: 2.749267816543579
Validation loss: 2.026012738545736

Epoch: 6| Step: 7
Training loss: 1.9643058776855469
Validation loss: 2.0415959556897483

Epoch: 6| Step: 8
Training loss: 2.6861064434051514
Validation loss: 2.046282251675924

Epoch: 6| Step: 9
Training loss: 1.448483943939209
Validation loss: 2.0315948923428855

Epoch: 6| Step: 10
Training loss: 2.0065367221832275
Validation loss: 2.0422069231669107

Epoch: 6| Step: 11
Training loss: 1.6457223892211914
Validation loss: 2.0458475947380066

Epoch: 6| Step: 12
Training loss: 2.131819009780884
Validation loss: 2.048792322476705

Epoch: 6| Step: 13
Training loss: 1.9212639331817627
Validation loss: 2.0543455481529236

Epoch: 130| Step: 0
Training loss: 2.1553709506988525
Validation loss: 2.0503862500190735

Epoch: 6| Step: 1
Training loss: 2.074342727661133
Validation loss: 2.0578975478808084

Epoch: 6| Step: 2
Training loss: 2.500852584838867
Validation loss: 2.0452717940012612

Epoch: 6| Step: 3
Training loss: 1.7102770805358887
Validation loss: 2.051694095134735

Epoch: 6| Step: 4
Training loss: 2.0124588012695312
Validation loss: 2.044533054033915

Epoch: 6| Step: 5
Training loss: 1.9958021640777588
Validation loss: 2.0567521850268045

Epoch: 6| Step: 6
Training loss: 2.116820812225342
Validation loss: 2.04537171125412

Epoch: 6| Step: 7
Training loss: 2.1445505619049072
Validation loss: 2.035232404867808

Epoch: 6| Step: 8
Training loss: 2.0224857330322266
Validation loss: 2.0384981830914817

Epoch: 6| Step: 9
Training loss: 1.6643011569976807
Validation loss: 2.045758684476217

Epoch: 6| Step: 10
Training loss: 2.677490234375
Validation loss: 2.038961033026377

Epoch: 6| Step: 11
Training loss: 1.761633276939392
Validation loss: 2.0371079643567405

Epoch: 6| Step: 12
Training loss: 2.009169340133667
Validation loss: 2.0342050790786743

Epoch: 6| Step: 13
Training loss: 2.149613857269287
Validation loss: 2.0353506008783975

Epoch: 131| Step: 0
Training loss: 2.5864362716674805
Validation loss: 2.0511306325594583

Epoch: 6| Step: 1
Training loss: 2.1104543209075928
Validation loss: 2.0468032161394754

Epoch: 6| Step: 2
Training loss: 1.9173083305358887
Validation loss: 2.0438656012217202

Epoch: 6| Step: 3
Training loss: 1.9767576456069946
Validation loss: 2.0589648683865867

Epoch: 6| Step: 4
Training loss: 1.9449822902679443
Validation loss: 2.085314710934957

Epoch: 6| Step: 5
Training loss: 2.149369955062866
Validation loss: 2.047106663386027

Epoch: 6| Step: 6
Training loss: 2.184293031692505
Validation loss: 2.0545783837636313

Epoch: 6| Step: 7
Training loss: 2.2085189819335938
Validation loss: 2.0574745337168374

Epoch: 6| Step: 8
Training loss: 1.744117259979248
Validation loss: 2.053593893845876

Epoch: 6| Step: 9
Training loss: 2.3210015296936035
Validation loss: 2.049350321292877

Epoch: 6| Step: 10
Training loss: 2.4582552909851074
Validation loss: 2.030286729335785

Epoch: 6| Step: 11
Training loss: 1.8404381275177002
Validation loss: 2.038521329561869

Epoch: 6| Step: 12
Training loss: 1.5408101081848145
Validation loss: 2.0302785833676658

Epoch: 6| Step: 13
Training loss: 1.9440791606903076
Validation loss: 2.029496113459269

Epoch: 132| Step: 0
Training loss: 1.5562199354171753
Validation loss: 2.0539039174715676

Epoch: 6| Step: 1
Training loss: 2.047360897064209
Validation loss: 2.0552178621292114

Epoch: 6| Step: 2
Training loss: 2.0335841178894043
Validation loss: 2.0677776535352073

Epoch: 6| Step: 3
Training loss: 1.664008378982544
Validation loss: 2.0613726377487183

Epoch: 6| Step: 4
Training loss: 2.4606127738952637
Validation loss: 2.064376095930735

Epoch: 6| Step: 5
Training loss: 2.626478672027588
Validation loss: 2.0611273447672525

Epoch: 6| Step: 6
Training loss: 1.7274086475372314
Validation loss: 2.057939608891805

Epoch: 6| Step: 7
Training loss: 1.9608547687530518
Validation loss: 2.073000510533651

Epoch: 6| Step: 8
Training loss: 1.7746260166168213
Validation loss: 2.057717780272166

Epoch: 6| Step: 9
Training loss: 2.5516600608825684
Validation loss: 2.0629642407099404

Epoch: 6| Step: 10
Training loss: 2.0005767345428467
Validation loss: 2.0742449164390564

Epoch: 6| Step: 11
Training loss: 2.3297462463378906
Validation loss: 2.0668320258458457

Epoch: 6| Step: 12
Training loss: 2.268256664276123
Validation loss: 2.071918328603109

Epoch: 6| Step: 13
Training loss: 1.9516724348068237
Validation loss: 2.0560030738512673

Epoch: 133| Step: 0
Training loss: 2.7371726036071777
Validation loss: 2.0461577574412027

Epoch: 6| Step: 1
Training loss: 2.2439424991607666
Validation loss: 2.043331563472748

Epoch: 6| Step: 2
Training loss: 2.3195526599884033
Validation loss: 2.046120842297872

Epoch: 6| Step: 3
Training loss: 2.0701210498809814
Validation loss: 2.0522906382878623

Epoch: 6| Step: 4
Training loss: 2.396352767944336
Validation loss: 2.05768491824468

Epoch: 6| Step: 5
Training loss: 2.012789249420166
Validation loss: 2.0417855978012085

Epoch: 6| Step: 6
Training loss: 1.455733299255371
Validation loss: 2.0475274125734964

Epoch: 6| Step: 7
Training loss: 2.1209375858306885
Validation loss: 2.043254256248474

Epoch: 6| Step: 8
Training loss: 1.6538374423980713
Validation loss: 2.0356069803237915

Epoch: 6| Step: 9
Training loss: 1.971421718597412
Validation loss: 2.0335227251052856

Epoch: 6| Step: 10
Training loss: 1.951240062713623
Validation loss: 2.028403321901957

Epoch: 6| Step: 11
Training loss: 2.5460729598999023
Validation loss: 2.0426815350850425

Epoch: 6| Step: 12
Training loss: 2.078235149383545
Validation loss: 2.0433741211891174

Epoch: 6| Step: 13
Training loss: 2.0827035903930664
Validation loss: 2.049597680568695

Epoch: 134| Step: 0
Training loss: 1.4564135074615479
Validation loss: 2.059339761734009

Epoch: 6| Step: 1
Training loss: 2.6594510078430176
Validation loss: 2.0532129804293313

Epoch: 6| Step: 2
Training loss: 1.685570478439331
Validation loss: 2.0516568422317505

Epoch: 6| Step: 3
Training loss: 1.9675791263580322
Validation loss: 2.0446298718452454

Epoch: 6| Step: 4
Training loss: 2.954150676727295
Validation loss: 2.0615488290786743

Epoch: 6| Step: 5
Training loss: 1.6023706197738647
Validation loss: 2.0659088492393494

Epoch: 6| Step: 6
Training loss: 2.3220629692077637
Validation loss: 2.0642948945363364

Epoch: 6| Step: 7
Training loss: 1.4000946283340454
Validation loss: 2.0649123589197793

Epoch: 6| Step: 8
Training loss: 2.7628414630889893
Validation loss: 2.0632056991259256

Epoch: 6| Step: 9
Training loss: 2.244669198989868
Validation loss: 2.050917307535807

Epoch: 6| Step: 10
Training loss: 2.1075587272644043
Validation loss: 2.0305923024813333

Epoch: 6| Step: 11
Training loss: 2.040269374847412
Validation loss: 2.0513002276420593

Epoch: 6| Step: 12
Training loss: 1.8210562467575073
Validation loss: 2.033771554629008

Epoch: 6| Step: 13
Training loss: 2.00993275642395
Validation loss: 2.0309484203656516

Epoch: 135| Step: 0
Training loss: 1.7182981967926025
Validation loss: 2.0425294240315757

Epoch: 6| Step: 1
Training loss: 1.6553401947021484
Validation loss: 2.042454779148102

Epoch: 6| Step: 2
Training loss: 1.9585620164871216
Validation loss: 2.037846585114797

Epoch: 6| Step: 3
Training loss: 2.456284999847412
Validation loss: 2.042131245136261

Epoch: 6| Step: 4
Training loss: 2.385549545288086
Validation loss: 2.053489089012146

Epoch: 6| Step: 5
Training loss: 2.545927047729492
Validation loss: 2.0479663213094077

Epoch: 6| Step: 6
Training loss: 2.193214178085327
Validation loss: 2.0447027484575906

Epoch: 6| Step: 7
Training loss: 2.086268663406372
Validation loss: 2.04617440700531

Epoch: 6| Step: 8
Training loss: 2.065062999725342
Validation loss: 2.0511238177617392

Epoch: 6| Step: 9
Training loss: 1.9168245792388916
Validation loss: 2.0429298480351767

Epoch: 6| Step: 10
Training loss: 1.7282443046569824
Validation loss: 2.062110722064972

Epoch: 6| Step: 11
Training loss: 2.0161795616149902
Validation loss: 2.084514339764913

Epoch: 6| Step: 12
Training loss: 2.092226028442383
Validation loss: 2.077829420566559

Epoch: 6| Step: 13
Training loss: 2.134592294692993
Validation loss: 2.0915668408075967

Epoch: 136| Step: 0
Training loss: 2.0264840126037598
Validation loss: 2.084949254989624

Epoch: 6| Step: 1
Training loss: 1.8295422792434692
Validation loss: 2.0841157635053

Epoch: 6| Step: 2
Training loss: 2.5227818489074707
Validation loss: 2.075429995854696

Epoch: 6| Step: 3
Training loss: 1.8970369100570679
Validation loss: 2.091543515523275

Epoch: 6| Step: 4
Training loss: 1.9740222692489624
Validation loss: 2.0694159468015036

Epoch: 6| Step: 5
Training loss: 2.2541885375976562
Validation loss: 2.0542393128077188

Epoch: 6| Step: 6
Training loss: 1.553961992263794
Validation loss: 2.049870570500692

Epoch: 6| Step: 7
Training loss: 1.7722684144973755
Validation loss: 2.0471754670143127

Epoch: 6| Step: 8
Training loss: 2.6700785160064697
Validation loss: 2.0432421962420144

Epoch: 6| Step: 9
Training loss: 1.970207691192627
Validation loss: 2.0505777994791665

Epoch: 6| Step: 10
Training loss: 1.955801010131836
Validation loss: 2.0370440681775412

Epoch: 6| Step: 11
Training loss: 2.53236985206604
Validation loss: 2.033788720766703

Epoch: 6| Step: 12
Training loss: 2.196190118789673
Validation loss: 2.037809908390045

Epoch: 6| Step: 13
Training loss: 1.4368568658828735
Validation loss: 2.041556239128113

Epoch: 137| Step: 0
Training loss: 2.014558792114258
Validation loss: 2.041509489218394

Epoch: 6| Step: 1
Training loss: 2.111483335494995
Validation loss: 2.0420797864596048

Epoch: 6| Step: 2
Training loss: 2.1126298904418945
Validation loss: 2.043547292550405

Epoch: 6| Step: 3
Training loss: 1.7690136432647705
Validation loss: 2.0506720542907715

Epoch: 6| Step: 4
Training loss: 1.8479435443878174
Validation loss: 2.053528050581614

Epoch: 6| Step: 5
Training loss: 1.7475831508636475
Validation loss: 2.049706200758616

Epoch: 6| Step: 6
Training loss: 2.387619733810425
Validation loss: 2.072859048843384

Epoch: 6| Step: 7
Training loss: 2.1792540550231934
Validation loss: 2.091440995534261

Epoch: 6| Step: 8
Training loss: 1.4536519050598145
Validation loss: 2.0842310190200806

Epoch: 6| Step: 9
Training loss: 1.9211450815200806
Validation loss: 2.070215662320455

Epoch: 6| Step: 10
Training loss: 2.698198080062866
Validation loss: 2.084319611390432

Epoch: 6| Step: 11
Training loss: 1.8760418891906738
Validation loss: 2.0995722810427346

Epoch: 6| Step: 12
Training loss: 2.390772819519043
Validation loss: 2.074499468008677

Epoch: 6| Step: 13
Training loss: 2.2782726287841797
Validation loss: 2.0480339527130127

Epoch: 138| Step: 0
Training loss: 2.2385377883911133
Validation loss: 2.0519478718439736

Epoch: 6| Step: 1
Training loss: 2.4827194213867188
Validation loss: 2.053166925907135

Epoch: 6| Step: 2
Training loss: 2.149851083755493
Validation loss: 2.0351038177808127

Epoch: 6| Step: 3
Training loss: 1.9572418928146362
Validation loss: 2.0437578757603965

Epoch: 6| Step: 4
Training loss: 2.097594976425171
Validation loss: 2.039190133412679

Epoch: 6| Step: 5
Training loss: 2.282318353652954
Validation loss: 2.0347434480985007

Epoch: 6| Step: 6
Training loss: 2.209702491760254
Validation loss: 2.0378214915593467

Epoch: 6| Step: 7
Training loss: 1.7474455833435059
Validation loss: 2.0492147405942283

Epoch: 6| Step: 8
Training loss: 2.237131118774414
Validation loss: 2.0401746034622192

Epoch: 6| Step: 9
Training loss: 2.434659481048584
Validation loss: 2.0316076278686523

Epoch: 6| Step: 10
Training loss: 1.7583305835723877
Validation loss: 2.0380061070124307

Epoch: 6| Step: 11
Training loss: 1.991257905960083
Validation loss: 2.0397149324417114

Epoch: 6| Step: 12
Training loss: 1.6189496517181396
Validation loss: 2.030712644259135

Epoch: 6| Step: 13
Training loss: 2.4218225479125977
Validation loss: 2.0347171624501548

Epoch: 139| Step: 0
Training loss: 1.7586941719055176
Validation loss: 2.0321155786514282

Epoch: 6| Step: 1
Training loss: 1.7881040573120117
Validation loss: 2.028482715288798

Epoch: 6| Step: 2
Training loss: 2.2052013874053955
Validation loss: 2.0352213978767395

Epoch: 6| Step: 3
Training loss: 2.1757164001464844
Validation loss: 2.046556055545807

Epoch: 6| Step: 4
Training loss: 1.9851628541946411
Validation loss: 2.046244184176127

Epoch: 6| Step: 5
Training loss: 2.5346603393554688
Validation loss: 2.057134290536245

Epoch: 6| Step: 6
Training loss: 1.8340625762939453
Validation loss: 2.0573004682858786

Epoch: 6| Step: 7
Training loss: 2.4875335693359375
Validation loss: 2.0613886515299478

Epoch: 6| Step: 8
Training loss: 1.3810538053512573
Validation loss: 2.05749919017156

Epoch: 6| Step: 9
Training loss: 1.7969045639038086
Validation loss: 2.064066489537557

Epoch: 6| Step: 10
Training loss: 2.3839502334594727
Validation loss: 2.0653946002324424

Epoch: 6| Step: 11
Training loss: 2.235447406768799
Validation loss: 2.086673080921173

Epoch: 6| Step: 12
Training loss: 1.7242010831832886
Validation loss: 2.067039887110392

Epoch: 6| Step: 13
Training loss: 2.3180794715881348
Validation loss: 2.0560473601023355

Epoch: 140| Step: 0
Training loss: 2.1737892627716064
Validation loss: 2.063262164592743

Epoch: 6| Step: 1
Training loss: 1.664305329322815
Validation loss: 2.0551928679148355

Epoch: 6| Step: 2
Training loss: 2.2805514335632324
Validation loss: 2.0637572209040322

Epoch: 6| Step: 3
Training loss: 2.4333009719848633
Validation loss: 2.065824866294861

Epoch: 6| Step: 4
Training loss: 1.8525471687316895
Validation loss: 2.0651132663091025

Epoch: 6| Step: 5
Training loss: 2.0930919647216797
Validation loss: 2.060542345046997

Epoch: 6| Step: 6
Training loss: 2.3740415573120117
Validation loss: 2.058794935544332

Epoch: 6| Step: 7
Training loss: 2.7456412315368652
Validation loss: 2.060016671816508

Epoch: 6| Step: 8
Training loss: 1.3471555709838867
Validation loss: 2.063668648401896

Epoch: 6| Step: 9
Training loss: 1.8083703517913818
Validation loss: 2.057563006877899

Epoch: 6| Step: 10
Training loss: 1.7604341506958008
Validation loss: 2.067933718363444

Epoch: 6| Step: 11
Training loss: 1.556670904159546
Validation loss: 2.058079719543457

Epoch: 6| Step: 12
Training loss: 2.1445775032043457
Validation loss: 2.048584997653961

Epoch: 6| Step: 13
Training loss: 2.6894783973693848
Validation loss: 2.064752678076426

Epoch: 141| Step: 0
Training loss: 2.9161882400512695
Validation loss: 2.0554014245669046

Epoch: 6| Step: 1
Training loss: 1.9949638843536377
Validation loss: 2.0686829487482705

Epoch: 6| Step: 2
Training loss: 1.4841365814208984
Validation loss: 2.07247128089269

Epoch: 6| Step: 3
Training loss: 2.0583279132843018
Validation loss: 2.0587997436523438

Epoch: 6| Step: 4
Training loss: 2.382413625717163
Validation loss: 2.055392543474833

Epoch: 6| Step: 5
Training loss: 2.388946056365967
Validation loss: 2.0815458496411643

Epoch: 6| Step: 6
Training loss: 1.9973698854446411
Validation loss: 2.063544233640035

Epoch: 6| Step: 7
Training loss: 2.2220497131347656
Validation loss: 2.0647860566775003

Epoch: 6| Step: 8
Training loss: 1.8575749397277832
Validation loss: 2.055353363355001

Epoch: 6| Step: 9
Training loss: 1.9524885416030884
Validation loss: 2.058532257874807

Epoch: 6| Step: 10
Training loss: 1.6512782573699951
Validation loss: 2.0544877449671426

Epoch: 6| Step: 11
Training loss: 1.6551916599273682
Validation loss: 2.0527997612953186

Epoch: 6| Step: 12
Training loss: 1.6599174737930298
Validation loss: 2.058731118837992

Epoch: 6| Step: 13
Training loss: 2.4670181274414062
Validation loss: 2.049004912376404

Epoch: 142| Step: 0
Training loss: 1.540554165840149
Validation loss: 2.04492578903834

Epoch: 6| Step: 1
Training loss: 2.547656297683716
Validation loss: 2.0318337281545005

Epoch: 6| Step: 2
Training loss: 1.5338908433914185
Validation loss: 2.0321470896402993

Epoch: 6| Step: 3
Training loss: 2.2150511741638184
Validation loss: 2.0294644832611084

Epoch: 6| Step: 4
Training loss: 2.167466402053833
Validation loss: 2.045020043849945

Epoch: 6| Step: 5
Training loss: 2.298689126968384
Validation loss: 2.0426421960194907

Epoch: 6| Step: 6
Training loss: 1.7393933534622192
Validation loss: 2.0524632136027017

Epoch: 6| Step: 7
Training loss: 1.514772891998291
Validation loss: 2.0517242153485618

Epoch: 6| Step: 8
Training loss: 2.1171374320983887
Validation loss: 2.059032758076986

Epoch: 6| Step: 9
Training loss: 2.8661510944366455
Validation loss: 2.0655338764190674

Epoch: 6| Step: 10
Training loss: 1.743323564529419
Validation loss: 2.0423171122868857

Epoch: 6| Step: 11
Training loss: 2.650601863861084
Validation loss: 2.0257873932520547

Epoch: 6| Step: 12
Training loss: 1.9854111671447754
Validation loss: 2.027664919694265

Epoch: 6| Step: 13
Training loss: 2.159231185913086
Validation loss: 2.0437471667925515

Epoch: 143| Step: 0
Training loss: 1.1323070526123047
Validation loss: 2.034711559613546

Epoch: 6| Step: 1
Training loss: 1.512366533279419
Validation loss: 2.0321742494901023

Epoch: 6| Step: 2
Training loss: 2.2696402072906494
Validation loss: 2.0315305987993875

Epoch: 6| Step: 3
Training loss: 2.1330714225769043
Validation loss: 2.0346469283103943

Epoch: 6| Step: 4
Training loss: 1.9652928113937378
Validation loss: 2.0408729712168374

Epoch: 6| Step: 5
Training loss: 1.9256855249404907
Validation loss: 2.0397881269454956

Epoch: 6| Step: 6
Training loss: 1.8069994449615479
Validation loss: 2.0369314153989158

Epoch: 6| Step: 7
Training loss: 2.6262946128845215
Validation loss: 2.0260514616966248

Epoch: 6| Step: 8
Training loss: 2.0163345336914062
Validation loss: 2.0287384390830994

Epoch: 6| Step: 9
Training loss: 2.3176045417785645
Validation loss: 2.031638483206431

Epoch: 6| Step: 10
Training loss: 2.4503493309020996
Validation loss: 2.0217833320299783

Epoch: 6| Step: 11
Training loss: 2.247908115386963
Validation loss: 2.0226935346921286

Epoch: 6| Step: 12
Training loss: 2.4475717544555664
Validation loss: 2.041147987047831

Epoch: 6| Step: 13
Training loss: 2.258204936981201
Validation loss: 2.0423508485158286

Epoch: 144| Step: 0
Training loss: 1.819249153137207
Validation loss: 2.0521010756492615

Epoch: 6| Step: 1
Training loss: 1.6480154991149902
Validation loss: 2.0597304701805115

Epoch: 6| Step: 2
Training loss: 2.159261703491211
Validation loss: 2.067152500152588

Epoch: 6| Step: 3
Training loss: 2.289914846420288
Validation loss: 2.0779787500699363

Epoch: 6| Step: 4
Training loss: 1.8126208782196045
Validation loss: 2.0870469013849893

Epoch: 6| Step: 5
Training loss: 2.3005990982055664
Validation loss: 2.091606914997101

Epoch: 6| Step: 6
Training loss: 1.8014047145843506
Validation loss: 2.0829168955485025

Epoch: 6| Step: 7
Training loss: 1.7447528839111328
Validation loss: 2.069053868452708

Epoch: 6| Step: 8
Training loss: 2.8042521476745605
Validation loss: 2.0677197178204856

Epoch: 6| Step: 9
Training loss: 2.114471673965454
Validation loss: 2.0556264917055764

Epoch: 6| Step: 10
Training loss: 2.132981777191162
Validation loss: 2.04760080575943

Epoch: 6| Step: 11
Training loss: 2.059396743774414
Validation loss: 2.0410038828849792

Epoch: 6| Step: 12
Training loss: 1.7802696228027344
Validation loss: 2.057505786418915

Epoch: 6| Step: 13
Training loss: 2.058405876159668
Validation loss: 2.043755531311035

Epoch: 145| Step: 0
Training loss: 1.7344841957092285
Validation loss: 2.038171331087748

Epoch: 6| Step: 1
Training loss: 2.029759407043457
Validation loss: 2.041717827320099

Epoch: 6| Step: 2
Training loss: 1.7585357427597046
Validation loss: 2.048328677813212

Epoch: 6| Step: 3
Training loss: 2.616415500640869
Validation loss: 2.043987810611725

Epoch: 6| Step: 4
Training loss: 2.3759188652038574
Validation loss: 2.0399664839108786

Epoch: 6| Step: 5
Training loss: 1.550689458847046
Validation loss: 2.0490559538205466

Epoch: 6| Step: 6
Training loss: 1.5088623762130737
Validation loss: 2.0512777964274087

Epoch: 6| Step: 7
Training loss: 2.214895009994507
Validation loss: 2.0523337523142495

Epoch: 6| Step: 8
Training loss: 2.280512809753418
Validation loss: 2.044930895169576

Epoch: 6| Step: 9
Training loss: 2.3625497817993164
Validation loss: 2.049140671888987

Epoch: 6| Step: 10
Training loss: 1.8217713832855225
Validation loss: 2.046768287817637

Epoch: 6| Step: 11
Training loss: 1.8081563711166382
Validation loss: 2.044408142566681

Epoch: 6| Step: 12
Training loss: 2.056119680404663
Validation loss: 2.0783031980196633

Epoch: 6| Step: 13
Training loss: 2.2076597213745117
Validation loss: 2.086394747098287

Epoch: 146| Step: 0
Training loss: 1.5928421020507812
Validation loss: 2.0980425477027893

Epoch: 6| Step: 1
Training loss: 2.06984281539917
Validation loss: 2.0996533234914145

Epoch: 6| Step: 2
Training loss: 2.0887763500213623
Validation loss: 2.1254387497901917

Epoch: 6| Step: 3
Training loss: 1.6025142669677734
Validation loss: 2.09984815120697

Epoch: 6| Step: 4
Training loss: 2.6464648246765137
Validation loss: 2.1044949491818747

Epoch: 6| Step: 5
Training loss: 1.6023237705230713
Validation loss: 2.0918206771214805

Epoch: 6| Step: 6
Training loss: 2.0839309692382812
Validation loss: 2.061334212621053

Epoch: 6| Step: 7
Training loss: 2.6153173446655273
Validation loss: 2.0686296621958413

Epoch: 6| Step: 8
Training loss: 1.980362057685852
Validation loss: 2.0481406847635903

Epoch: 6| Step: 9
Training loss: 1.8486943244934082
Validation loss: 2.051527261734009

Epoch: 6| Step: 10
Training loss: 1.751641035079956
Validation loss: 2.042829970518748

Epoch: 6| Step: 11
Training loss: 1.8219428062438965
Validation loss: 2.036572496096293

Epoch: 6| Step: 12
Training loss: 2.338167190551758
Validation loss: 2.027008831501007

Epoch: 6| Step: 13
Training loss: 2.4629979133605957
Validation loss: 2.035124639670054

Epoch: 147| Step: 0
Training loss: 2.371412515640259
Validation loss: 2.0428251028060913

Epoch: 6| Step: 1
Training loss: 2.8385672569274902
Validation loss: 2.051352580388387

Epoch: 6| Step: 2
Training loss: 2.0631914138793945
Validation loss: 2.0392072399457297

Epoch: 6| Step: 3
Training loss: 2.8675520420074463
Validation loss: 2.0370368162790933

Epoch: 6| Step: 4
Training loss: 2.1321563720703125
Validation loss: 2.0462632377942405

Epoch: 6| Step: 5
Training loss: 1.5824346542358398
Validation loss: 2.0459430615107217

Epoch: 6| Step: 6
Training loss: 2.43989896774292
Validation loss: 2.056325991948446

Epoch: 6| Step: 7
Training loss: 2.088017463684082
Validation loss: 2.045362412929535

Epoch: 6| Step: 8
Training loss: 2.0370380878448486
Validation loss: 2.047195533911387

Epoch: 6| Step: 9
Training loss: 1.5622820854187012
Validation loss: 2.0536211729049683

Epoch: 6| Step: 10
Training loss: 2.344475269317627
Validation loss: 2.0616885224978128

Epoch: 6| Step: 11
Training loss: 1.304189920425415
Validation loss: 2.069422662258148

Epoch: 6| Step: 12
Training loss: 1.6903278827667236
Validation loss: 2.0692748626073203

Epoch: 6| Step: 13
Training loss: 1.6755783557891846
Validation loss: 2.0584802627563477

Epoch: 148| Step: 0
Training loss: 2.748206615447998
Validation loss: 2.079781254132589

Epoch: 6| Step: 1
Training loss: 2.2088208198547363
Validation loss: 2.0678207079569497

Epoch: 6| Step: 2
Training loss: 2.221083402633667
Validation loss: 2.098103721936544

Epoch: 6| Step: 3
Training loss: 2.4896719455718994
Validation loss: 2.077339251836141

Epoch: 6| Step: 4
Training loss: 1.6408430337905884
Validation loss: 2.0840530395507812

Epoch: 6| Step: 5
Training loss: 2.0814244747161865
Validation loss: 2.0768343607584634

Epoch: 6| Step: 6
Training loss: 1.7436246871948242
Validation loss: 2.0623353918393454

Epoch: 6| Step: 7
Training loss: 2.0885977745056152
Validation loss: 2.0677462816238403

Epoch: 6| Step: 8
Training loss: 1.8345353603363037
Validation loss: 2.064809739589691

Epoch: 6| Step: 9
Training loss: 1.582665205001831
Validation loss: 2.0588845014572144

Epoch: 6| Step: 10
Training loss: 1.918810486793518
Validation loss: 2.053265690803528

Epoch: 6| Step: 11
Training loss: 2.0565948486328125
Validation loss: 2.0596953630447388

Epoch: 6| Step: 12
Training loss: 2.15621280670166
Validation loss: 2.047394355138143

Epoch: 6| Step: 13
Training loss: 1.7773232460021973
Validation loss: 2.0535043478012085

Epoch: 149| Step: 0
Training loss: 1.7547234296798706
Validation loss: 2.048823873202006

Epoch: 6| Step: 1
Training loss: 1.9324489831924438
Validation loss: 2.0596781969070435

Epoch: 6| Step: 2
Training loss: 2.296140670776367
Validation loss: 2.0650605956713357

Epoch: 6| Step: 3
Training loss: 2.29184627532959
Validation loss: 2.066499491532644

Epoch: 6| Step: 4
Training loss: 1.6902449131011963
Validation loss: 2.0618750055631003

Epoch: 6| Step: 5
Training loss: 2.367307186126709
Validation loss: 2.054766575495402

Epoch: 6| Step: 6
Training loss: 2.4329280853271484
Validation loss: 2.065407911936442

Epoch: 6| Step: 7
Training loss: 2.05869197845459
Validation loss: 2.080622454484304

Epoch: 6| Step: 8
Training loss: 2.3911240100860596
Validation loss: 2.087976117928823

Epoch: 6| Step: 9
Training loss: 1.9215900897979736
Validation loss: 2.075457056363424

Epoch: 6| Step: 10
Training loss: 1.9453558921813965
Validation loss: 2.088577449321747

Epoch: 6| Step: 11
Training loss: 1.3832743167877197
Validation loss: 2.09389462073644

Epoch: 6| Step: 12
Training loss: 2.2354049682617188
Validation loss: 2.0901960134506226

Epoch: 6| Step: 13
Training loss: 1.8988215923309326
Validation loss: 2.0862317085266113

Epoch: 150| Step: 0
Training loss: 2.024993896484375
Validation loss: 2.0866942405700684

Epoch: 6| Step: 1
Training loss: 2.3031630516052246
Validation loss: 2.087036391099294

Epoch: 6| Step: 2
Training loss: 1.6534996032714844
Validation loss: 2.076157569885254

Epoch: 6| Step: 3
Training loss: 2.025183916091919
Validation loss: 2.071966807047526

Epoch: 6| Step: 4
Training loss: 1.791874885559082
Validation loss: 2.0607244968414307

Epoch: 6| Step: 5
Training loss: 1.7093491554260254
Validation loss: 2.0752814213434854

Epoch: 6| Step: 6
Training loss: 2.3275952339172363
Validation loss: 2.085538864135742

Epoch: 6| Step: 7
Training loss: 1.9407472610473633
Validation loss: 2.063455065091451

Epoch: 6| Step: 8
Training loss: 2.089477062225342
Validation loss: 2.075555423895518

Epoch: 6| Step: 9
Training loss: 1.9317748546600342
Validation loss: 2.0671032269795737

Epoch: 6| Step: 10
Training loss: 1.789850115776062
Validation loss: 2.061689337094625

Epoch: 6| Step: 11
Training loss: 1.884004831314087
Validation loss: 2.063266634941101

Epoch: 6| Step: 12
Training loss: 2.694319009780884
Validation loss: 2.0819097558657327

Epoch: 6| Step: 13
Training loss: 2.0337953567504883
Validation loss: 2.0733715693155923

Epoch: 151| Step: 0
Training loss: 1.9306793212890625
Validation loss: 2.07479190826416

Epoch: 6| Step: 1
Training loss: 2.1918792724609375
Validation loss: 2.07981546719869

Epoch: 6| Step: 2
Training loss: 2.0130956172943115
Validation loss: 2.078636089960734

Epoch: 6| Step: 3
Training loss: 1.9450504779815674
Validation loss: 2.0718199412027993

Epoch: 6| Step: 4
Training loss: 1.8807330131530762
Validation loss: 2.0756322542826333

Epoch: 6| Step: 5
Training loss: 1.5340311527252197
Validation loss: 2.0741313695907593

Epoch: 6| Step: 6
Training loss: 1.9288829565048218
Validation loss: 2.070778489112854

Epoch: 6| Step: 7
Training loss: 1.7413582801818848
Validation loss: 2.064862767855326

Epoch: 6| Step: 8
Training loss: 2.5305542945861816
Validation loss: 2.0678196946779885

Epoch: 6| Step: 9
Training loss: 1.9365568161010742
Validation loss: 2.0624569853146872

Epoch: 6| Step: 10
Training loss: 2.1652779579162598
Validation loss: 2.0541433294614158

Epoch: 6| Step: 11
Training loss: 1.8981283903121948
Validation loss: 2.055270274480184

Epoch: 6| Step: 12
Training loss: 2.678100109100342
Validation loss: 2.0669321616490683

Epoch: 6| Step: 13
Training loss: 1.8914494514465332
Validation loss: 2.0670743187268577

Epoch: 152| Step: 0
Training loss: 1.8597168922424316
Validation loss: 2.069629708925883

Epoch: 6| Step: 1
Training loss: 1.9701389074325562
Validation loss: 2.054350515206655

Epoch: 6| Step: 2
Training loss: 2.3485217094421387
Validation loss: 2.065050403277079

Epoch: 6| Step: 3
Training loss: 2.2762396335601807
Validation loss: 2.0592129031817117

Epoch: 6| Step: 4
Training loss: 1.931009292602539
Validation loss: 2.056155522664388

Epoch: 6| Step: 5
Training loss: 2.0889363288879395
Validation loss: 2.0660917361577353

Epoch: 6| Step: 6
Training loss: 2.2096219062805176
Validation loss: 2.0645864407221475

Epoch: 6| Step: 7
Training loss: 1.6189223527908325
Validation loss: 2.0575371384620667

Epoch: 6| Step: 8
Training loss: 1.3809709548950195
Validation loss: 2.057305912176768

Epoch: 6| Step: 9
Training loss: 2.003687858581543
Validation loss: 2.0740205446879068

Epoch: 6| Step: 10
Training loss: 2.1820526123046875
Validation loss: 2.06601220369339

Epoch: 6| Step: 11
Training loss: 1.7988581657409668
Validation loss: 2.0791468818982444

Epoch: 6| Step: 12
Training loss: 2.0587244033813477
Validation loss: 2.080257693926493

Epoch: 6| Step: 13
Training loss: 2.3070144653320312
Validation loss: 2.085394322872162

Epoch: 153| Step: 0
Training loss: 1.68766188621521
Validation loss: 2.0772833824157715

Epoch: 6| Step: 1
Training loss: 2.1073036193847656
Validation loss: 2.0858490069707236

Epoch: 6| Step: 2
Training loss: 3.1567130088806152
Validation loss: 2.0915427605311074

Epoch: 6| Step: 3
Training loss: 2.3435778617858887
Validation loss: 2.0718839367230735

Epoch: 6| Step: 4
Training loss: 2.0545737743377686
Validation loss: 2.0897974371910095

Epoch: 6| Step: 5
Training loss: 1.820568561553955
Validation loss: 2.0812211632728577

Epoch: 6| Step: 6
Training loss: 1.7935945987701416
Validation loss: 2.074181377887726

Epoch: 6| Step: 7
Training loss: 2.2287659645080566
Validation loss: 2.068397581577301

Epoch: 6| Step: 8
Training loss: 2.1965317726135254
Validation loss: 2.092253784338633

Epoch: 6| Step: 9
Training loss: 1.3830758333206177
Validation loss: 2.0766585866610208

Epoch: 6| Step: 10
Training loss: 2.0348010063171387
Validation loss: 2.0726844867070517

Epoch: 6| Step: 11
Training loss: 1.9884490966796875
Validation loss: 2.081210116545359

Epoch: 6| Step: 12
Training loss: 1.5887092351913452
Validation loss: 2.0887569189071655

Epoch: 6| Step: 13
Training loss: 2.0062155723571777
Validation loss: 2.094399909178416

Epoch: 154| Step: 0
Training loss: 2.669326066970825
Validation loss: 2.07501357793808

Epoch: 6| Step: 1
Training loss: 2.5331263542175293
Validation loss: 2.0810676415761313

Epoch: 6| Step: 2
Training loss: 1.7189340591430664
Validation loss: 2.0918434460957847

Epoch: 6| Step: 3
Training loss: 1.5825495719909668
Validation loss: 2.077275296052297

Epoch: 6| Step: 4
Training loss: 1.896789789199829
Validation loss: 2.079532821973165

Epoch: 6| Step: 5
Training loss: 2.6681294441223145
Validation loss: 2.073433995246887

Epoch: 6| Step: 6
Training loss: 1.9948245286941528
Validation loss: 2.070793410142263

Epoch: 6| Step: 7
Training loss: 1.8375024795532227
Validation loss: 2.077006379763285

Epoch: 6| Step: 8
Training loss: 1.929624080657959
Validation loss: 2.0802364548047385

Epoch: 6| Step: 9
Training loss: 1.326662302017212
Validation loss: 2.0886055628458657

Epoch: 6| Step: 10
Training loss: 2.4447877407073975
Validation loss: 2.091046770413717

Epoch: 6| Step: 11
Training loss: 1.444526195526123
Validation loss: 2.093188484509786

Epoch: 6| Step: 12
Training loss: 1.7106108665466309
Validation loss: 2.0856409470240274

Epoch: 6| Step: 13
Training loss: 2.247823715209961
Validation loss: 2.083925942579905

Epoch: 155| Step: 0
Training loss: 1.580200433731079
Validation loss: 2.082403282324473

Epoch: 6| Step: 1
Training loss: 2.116990089416504
Validation loss: 2.0890960097312927

Epoch: 6| Step: 2
Training loss: 1.9834563732147217
Validation loss: 2.069672922293345

Epoch: 6| Step: 3
Training loss: 2.3394839763641357
Validation loss: 2.079560120900472

Epoch: 6| Step: 4
Training loss: 2.072550058364868
Validation loss: 2.082671801249186

Epoch: 6| Step: 5
Training loss: 2.554673671722412
Validation loss: 2.079348107179006

Epoch: 6| Step: 6
Training loss: 2.048823356628418
Validation loss: 2.0592505733172097

Epoch: 6| Step: 7
Training loss: 1.681639313697815
Validation loss: 2.0666001439094543

Epoch: 6| Step: 8
Training loss: 2.183231830596924
Validation loss: 2.073296288649241

Epoch: 6| Step: 9
Training loss: 1.4919981956481934
Validation loss: 2.068098465601603

Epoch: 6| Step: 10
Training loss: 2.113849639892578
Validation loss: 2.0826682845751443

Epoch: 6| Step: 11
Training loss: 1.6373540163040161
Validation loss: 2.064182678858439

Epoch: 6| Step: 12
Training loss: 2.1419599056243896
Validation loss: 2.0632619659105935

Epoch: 6| Step: 13
Training loss: 2.024738073348999
Validation loss: 2.071062902609507

Epoch: 156| Step: 0
Training loss: 2.422797679901123
Validation loss: 2.080956518650055

Epoch: 6| Step: 1
Training loss: 1.6356794834136963
Validation loss: 2.079526642958323

Epoch: 6| Step: 2
Training loss: 2.373767375946045
Validation loss: 2.070567786693573

Epoch: 6| Step: 3
Training loss: 1.8369617462158203
Validation loss: 2.0788626670837402

Epoch: 6| Step: 4
Training loss: 2.090695381164551
Validation loss: 2.077361543973287

Epoch: 6| Step: 5
Training loss: 2.329319953918457
Validation loss: 2.061193505922953

Epoch: 6| Step: 6
Training loss: 2.085017681121826
Validation loss: 2.076811929543813

Epoch: 6| Step: 7
Training loss: 1.873633623123169
Validation loss: 2.074877381324768

Epoch: 6| Step: 8
Training loss: 1.645796298980713
Validation loss: 2.064372996489207

Epoch: 6| Step: 9
Training loss: 1.8820030689239502
Validation loss: 2.05895201365153

Epoch: 6| Step: 10
Training loss: 1.6058800220489502
Validation loss: 2.082083066304525

Epoch: 6| Step: 11
Training loss: 1.9146426916122437
Validation loss: 2.079294522603353

Epoch: 6| Step: 12
Training loss: 2.403639078140259
Validation loss: 2.075737734635671

Epoch: 6| Step: 13
Training loss: 1.9643723964691162
Validation loss: 2.0926038225491843

Epoch: 157| Step: 0
Training loss: 2.331812858581543
Validation loss: 2.1023929715156555

Epoch: 6| Step: 1
Training loss: 1.4956424236297607
Validation loss: 2.090841809908549

Epoch: 6| Step: 2
Training loss: 2.1760377883911133
Validation loss: 2.121764381726583

Epoch: 6| Step: 3
Training loss: 2.056551456451416
Validation loss: 2.112616697947184

Epoch: 6| Step: 4
Training loss: 2.1966183185577393
Validation loss: 2.119612435499827

Epoch: 6| Step: 5
Training loss: 1.7505671977996826
Validation loss: 2.1101667483647666

Epoch: 6| Step: 6
Training loss: 1.9608159065246582
Validation loss: 2.0986487865448

Epoch: 6| Step: 7
Training loss: 2.9585180282592773
Validation loss: 2.0831154584884644

Epoch: 6| Step: 8
Training loss: 2.9918270111083984
Validation loss: 2.0750367045402527

Epoch: 6| Step: 9
Training loss: 1.4917093515396118
Validation loss: 2.0772552490234375

Epoch: 6| Step: 10
Training loss: 1.4978715181350708
Validation loss: 2.061709006627401

Epoch: 6| Step: 11
Training loss: 1.4978358745574951
Validation loss: 2.0499493877092996

Epoch: 6| Step: 12
Training loss: 1.711342692375183
Validation loss: 2.054998834927877

Epoch: 6| Step: 13
Training loss: 1.9044018983840942
Validation loss: 2.0578662355740867

Epoch: 158| Step: 0
Training loss: 2.027106285095215
Validation loss: 2.0496427416801453

Epoch: 6| Step: 1
Training loss: 2.045038938522339
Validation loss: 2.053878883520762

Epoch: 6| Step: 2
Training loss: 2.094615936279297
Validation loss: 2.058770179748535

Epoch: 6| Step: 3
Training loss: 1.5886677503585815
Validation loss: 2.0624940991401672

Epoch: 6| Step: 4
Training loss: 2.250340700149536
Validation loss: 2.0651931365331015

Epoch: 6| Step: 5
Training loss: 3.000197410583496
Validation loss: 2.0732277234395347

Epoch: 6| Step: 6
Training loss: 2.401212215423584
Validation loss: 2.0638263821601868

Epoch: 6| Step: 7
Training loss: 1.5651741027832031
Validation loss: 2.0740365584691367

Epoch: 6| Step: 8
Training loss: 1.9427450895309448
Validation loss: 2.092724541823069

Epoch: 6| Step: 9
Training loss: 1.332685947418213
Validation loss: 2.083907882372538

Epoch: 6| Step: 10
Training loss: 2.100480556488037
Validation loss: 2.093495766321818

Epoch: 6| Step: 11
Training loss: 1.4981873035430908
Validation loss: 2.093550364176432

Epoch: 6| Step: 12
Training loss: 2.279715061187744
Validation loss: 2.0727956891059875

Epoch: 6| Step: 13
Training loss: 2.1762948036193848
Validation loss: 2.0678292910257974

Epoch: 159| Step: 0
Training loss: 1.7000559568405151
Validation loss: 2.0690927306811013

Epoch: 6| Step: 1
Training loss: 1.912104845046997
Validation loss: 2.0679500699043274

Epoch: 6| Step: 2
Training loss: 2.5129473209381104
Validation loss: 2.0750158230463662

Epoch: 6| Step: 3
Training loss: 1.373707890510559
Validation loss: 2.0659895737965903

Epoch: 6| Step: 4
Training loss: 2.1800012588500977
Validation loss: 2.079761544863383

Epoch: 6| Step: 5
Training loss: 2.611929178237915
Validation loss: 2.0795822143554688

Epoch: 6| Step: 6
Training loss: 1.1221916675567627
Validation loss: 2.0765073895454407

Epoch: 6| Step: 7
Training loss: 2.0992298126220703
Validation loss: 2.081234256426493

Epoch: 6| Step: 8
Training loss: 2.5078125
Validation loss: 2.085828204949697

Epoch: 6| Step: 9
Training loss: 2.192213773727417
Validation loss: 2.079283058643341

Epoch: 6| Step: 10
Training loss: 1.8026490211486816
Validation loss: 2.0816538532574973

Epoch: 6| Step: 11
Training loss: 1.7345854043960571
Validation loss: 2.0977396766344705

Epoch: 6| Step: 12
Training loss: 1.9281421899795532
Validation loss: 2.0793230334917703

Epoch: 6| Step: 13
Training loss: 2.232618808746338
Validation loss: 2.074779431025187

Epoch: 160| Step: 0
Training loss: 1.9611716270446777
Validation loss: 2.0793567101160684

Epoch: 6| Step: 1
Training loss: 2.111475944519043
Validation loss: 2.06932669878006

Epoch: 6| Step: 2
Training loss: 1.8273530006408691
Validation loss: 2.0650283296902976

Epoch: 6| Step: 3
Training loss: 1.6058404445648193
Validation loss: 2.062176545461019

Epoch: 6| Step: 4
Training loss: 1.886568546295166
Validation loss: 2.067739029725393

Epoch: 6| Step: 5
Training loss: 2.4838814735412598
Validation loss: 2.0652072429656982

Epoch: 6| Step: 6
Training loss: 2.1495349407196045
Validation loss: 2.069502611955007

Epoch: 6| Step: 7
Training loss: 2.0910120010375977
Validation loss: 2.064003507296244

Epoch: 6| Step: 8
Training loss: 1.8363182544708252
Validation loss: 2.063666880130768

Epoch: 6| Step: 9
Training loss: 1.6753883361816406
Validation loss: 2.049556016921997

Epoch: 6| Step: 10
Training loss: 2.2994532585144043
Validation loss: 2.0613034764925637

Epoch: 6| Step: 11
Training loss: 2.060137987136841
Validation loss: 2.0581753849983215

Epoch: 6| Step: 12
Training loss: 1.7861130237579346
Validation loss: 2.0653119484583535

Epoch: 6| Step: 13
Training loss: 2.186666965484619
Validation loss: 2.0659456849098206

Epoch: 161| Step: 0
Training loss: 2.0101747512817383
Validation loss: 2.0717691779136658

Epoch: 6| Step: 1
Training loss: 2.8829264640808105
Validation loss: 2.0819403727849326

Epoch: 6| Step: 2
Training loss: 1.8095662593841553
Validation loss: 2.0880804856618247

Epoch: 6| Step: 3
Training loss: 1.6791951656341553
Validation loss: 2.0778130094210305

Epoch: 6| Step: 4
Training loss: 2.6957755088806152
Validation loss: 2.0795664191246033

Epoch: 6| Step: 5
Training loss: 1.6459014415740967
Validation loss: 2.0781065622965493

Epoch: 6| Step: 6
Training loss: 1.6859424114227295
Validation loss: 2.07121072212855

Epoch: 6| Step: 7
Training loss: 2.1218326091766357
Validation loss: 2.0710148215293884

Epoch: 6| Step: 8
Training loss: 2.513749599456787
Validation loss: 2.0807429552078247

Epoch: 6| Step: 9
Training loss: 1.8626705408096313
Validation loss: 2.0798779129981995

Epoch: 6| Step: 10
Training loss: 1.6585688591003418
Validation loss: 2.0780890186627707

Epoch: 6| Step: 11
Training loss: 1.660426378250122
Validation loss: 2.0734607776006064

Epoch: 6| Step: 12
Training loss: 2.005406618118286
Validation loss: 2.0984380642573037

Epoch: 6| Step: 13
Training loss: 1.7792060375213623
Validation loss: 2.093669573465983

Epoch: 162| Step: 0
Training loss: 1.9593979120254517
Validation loss: 2.100952168305715

Epoch: 6| Step: 1
Training loss: 2.1244759559631348
Validation loss: 2.0906421740849814

Epoch: 6| Step: 2
Training loss: 2.192986488342285
Validation loss: 2.085136373837789

Epoch: 6| Step: 3
Training loss: 1.7762938737869263
Validation loss: 2.090118865172068

Epoch: 6| Step: 4
Training loss: 2.0534963607788086
Validation loss: 2.080779035886129

Epoch: 6| Step: 5
Training loss: 1.9309895038604736
Validation loss: 2.099319279193878

Epoch: 6| Step: 6
Training loss: 2.42370867729187
Validation loss: 2.089369614919027

Epoch: 6| Step: 7
Training loss: 1.9581449031829834
Validation loss: 2.0893893043200173

Epoch: 6| Step: 8
Training loss: 2.906527519226074
Validation loss: 2.0863664944966636

Epoch: 6| Step: 9
Training loss: 1.744659185409546
Validation loss: 2.0789119402567544

Epoch: 6| Step: 10
Training loss: 1.7118664979934692
Validation loss: 2.0919607083002725

Epoch: 6| Step: 11
Training loss: 1.755141019821167
Validation loss: 2.0886038541793823

Epoch: 6| Step: 12
Training loss: 1.7213904857635498
Validation loss: 2.085780163606008

Epoch: 6| Step: 13
Training loss: 1.7306184768676758
Validation loss: 2.0725177526474

Epoch: 163| Step: 0
Training loss: 1.5848697423934937
Validation loss: 2.0816997488339744

Epoch: 6| Step: 1
Training loss: 2.0376787185668945
Validation loss: 2.0959497491518655

Epoch: 6| Step: 2
Training loss: 1.799748420715332
Validation loss: 2.0846217473347983

Epoch: 6| Step: 3
Training loss: 2.173159122467041
Validation loss: 2.091684877872467

Epoch: 6| Step: 4
Training loss: 1.9483081102371216
Validation loss: 2.0771432320276895

Epoch: 6| Step: 5
Training loss: 1.820725917816162
Validation loss: 2.088244875272115

Epoch: 6| Step: 6
Training loss: 1.6933097839355469
Validation loss: 2.091395378112793

Epoch: 6| Step: 7
Training loss: 2.7520809173583984
Validation loss: 2.090447187423706

Epoch: 6| Step: 8
Training loss: 1.8859013319015503
Validation loss: 2.089972456296285

Epoch: 6| Step: 9
Training loss: 1.7612409591674805
Validation loss: 2.0797760089238486

Epoch: 6| Step: 10
Training loss: 2.3340649604797363
Validation loss: 2.077795227368673

Epoch: 6| Step: 11
Training loss: 1.8029091358184814
Validation loss: 2.073338766892751

Epoch: 6| Step: 12
Training loss: 1.881640911102295
Validation loss: 2.0764872630437217

Epoch: 6| Step: 13
Training loss: 2.591867446899414
Validation loss: 2.06447962919871

Epoch: 164| Step: 0
Training loss: 1.6021068096160889
Validation loss: 2.0703958670298257

Epoch: 6| Step: 1
Training loss: 2.2900209426879883
Validation loss: 2.080422103404999

Epoch: 6| Step: 2
Training loss: 1.7602765560150146
Validation loss: 2.0825833280881247

Epoch: 6| Step: 3
Training loss: 2.113607406616211
Validation loss: 2.0741511583328247

Epoch: 6| Step: 4
Training loss: 1.794811725616455
Validation loss: 2.0919928749402366

Epoch: 6| Step: 5
Training loss: 1.7292420864105225
Validation loss: 2.1016863783200583

Epoch: 6| Step: 6
Training loss: 2.1104025840759277
Validation loss: 2.1045971314112344

Epoch: 6| Step: 7
Training loss: 2.136598825454712
Validation loss: 2.1077987353006997

Epoch: 6| Step: 8
Training loss: 2.181344985961914
Validation loss: 2.099696477254232

Epoch: 6| Step: 9
Training loss: 1.8449552059173584
Validation loss: 2.1094163060188293

Epoch: 6| Step: 10
Training loss: 2.3112552165985107
Validation loss: 2.0952131946881614

Epoch: 6| Step: 11
Training loss: 1.797527551651001
Validation loss: 2.1084998647371926

Epoch: 6| Step: 12
Training loss: 2.206401824951172
Validation loss: 2.1084371209144592

Epoch: 6| Step: 13
Training loss: 1.8903088569641113
Validation loss: 2.0911527474721274

Epoch: 165| Step: 0
Training loss: 2.0373973846435547
Validation loss: 2.097192406654358

Epoch: 6| Step: 1
Training loss: 2.1118667125701904
Validation loss: 2.0980290373166404

Epoch: 6| Step: 2
Training loss: 2.3103537559509277
Validation loss: 2.0870006879170737

Epoch: 6| Step: 3
Training loss: 1.7754710912704468
Validation loss: 2.0879321893056235

Epoch: 6| Step: 4
Training loss: 1.4544146060943604
Validation loss: 2.094967305660248

Epoch: 6| Step: 5
Training loss: 1.694810152053833
Validation loss: 2.0875495870908103

Epoch: 6| Step: 6
Training loss: 2.3446898460388184
Validation loss: 2.094033161799113

Epoch: 6| Step: 7
Training loss: 1.5964248180389404
Validation loss: 2.1021991968154907

Epoch: 6| Step: 8
Training loss: 1.715345859527588
Validation loss: 2.092571179072062

Epoch: 6| Step: 9
Training loss: 1.9708607196807861
Validation loss: 2.085717499256134

Epoch: 6| Step: 10
Training loss: 2.3911526203155518
Validation loss: 2.0831915934880576

Epoch: 6| Step: 11
Training loss: 1.9524307250976562
Validation loss: 2.0738171339035034

Epoch: 6| Step: 12
Training loss: 1.6928589344024658
Validation loss: 2.084590435028076

Epoch: 6| Step: 13
Training loss: 2.6074376106262207
Validation loss: 2.090636352698008

Epoch: 166| Step: 0
Training loss: 1.7688443660736084
Validation loss: 2.1001742482185364

Epoch: 6| Step: 1
Training loss: 2.9043421745300293
Validation loss: 2.093855102856954

Epoch: 6| Step: 2
Training loss: 1.6884427070617676
Validation loss: 2.09113617738088

Epoch: 6| Step: 3
Training loss: 2.180800437927246
Validation loss: 2.1133580803871155

Epoch: 6| Step: 4
Training loss: 2.1370673179626465
Validation loss: 2.0812012950579324

Epoch: 6| Step: 5
Training loss: 1.4601929187774658
Validation loss: 2.085567593574524

Epoch: 6| Step: 6
Training loss: 2.552950382232666
Validation loss: 2.090060750643412

Epoch: 6| Step: 7
Training loss: 2.113987445831299
Validation loss: 2.1102450489997864

Epoch: 6| Step: 8
Training loss: 1.643248200416565
Validation loss: 2.1001861294110618

Epoch: 6| Step: 9
Training loss: 1.6821011304855347
Validation loss: 2.091342508792877

Epoch: 6| Step: 10
Training loss: 1.7503358125686646
Validation loss: 2.089128792285919

Epoch: 6| Step: 11
Training loss: 1.9162324666976929
Validation loss: 2.082783798376719

Epoch: 6| Step: 12
Training loss: 1.9778506755828857
Validation loss: 2.089784344037374

Epoch: 6| Step: 13
Training loss: 2.0406599044799805
Validation loss: 2.0948322812716165

Epoch: 167| Step: 0
Training loss: 1.5815584659576416
Validation loss: 2.081802189350128

Epoch: 6| Step: 1
Training loss: 1.9285073280334473
Validation loss: 2.0709888537724814

Epoch: 6| Step: 2
Training loss: 2.1898698806762695
Validation loss: 2.0700184305508933

Epoch: 6| Step: 3
Training loss: 1.6809711456298828
Validation loss: 2.0668094555536904

Epoch: 6| Step: 4
Training loss: 1.9923672676086426
Validation loss: 2.0723164876302085

Epoch: 6| Step: 5
Training loss: 2.6468639373779297
Validation loss: 2.068295200665792

Epoch: 6| Step: 6
Training loss: 2.60300350189209
Validation loss: 2.084865669409434

Epoch: 6| Step: 7
Training loss: 1.746827244758606
Validation loss: 2.0840758879979453

Epoch: 6| Step: 8
Training loss: 2.285320281982422
Validation loss: 2.08862566947937

Epoch: 6| Step: 9
Training loss: 2.3066859245300293
Validation loss: 2.0906460682551065

Epoch: 6| Step: 10
Training loss: 1.7068647146224976
Validation loss: 2.098271449406942

Epoch: 6| Step: 11
Training loss: 1.8997080326080322
Validation loss: 2.0995375911394754

Epoch: 6| Step: 12
Training loss: 1.730668067932129
Validation loss: 2.0932985146840415

Epoch: 6| Step: 13
Training loss: 1.80857253074646
Validation loss: 2.0876451333363852

Epoch: 168| Step: 0
Training loss: 1.9478108882904053
Validation loss: 2.0894739627838135

Epoch: 6| Step: 1
Training loss: 2.1885697841644287
Validation loss: 2.084327439467112

Epoch: 6| Step: 2
Training loss: 1.770512580871582
Validation loss: 2.0802741050720215

Epoch: 6| Step: 3
Training loss: 2.0093159675598145
Validation loss: 2.0795615116755166

Epoch: 6| Step: 4
Training loss: 1.9774754047393799
Validation loss: 2.0812241037686667

Epoch: 6| Step: 5
Training loss: 1.5531901121139526
Validation loss: 2.0866821805636087

Epoch: 6| Step: 6
Training loss: 2.0665488243103027
Validation loss: 2.078256825606028

Epoch: 6| Step: 7
Training loss: 1.5858328342437744
Validation loss: 2.0728360414505005

Epoch: 6| Step: 8
Training loss: 2.447950839996338
Validation loss: 2.0743077596028647

Epoch: 6| Step: 9
Training loss: 2.2734861373901367
Validation loss: 2.078373114267985

Epoch: 6| Step: 10
Training loss: 2.332672595977783
Validation loss: 2.082576096057892

Epoch: 6| Step: 11
Training loss: 1.801391839981079
Validation loss: 2.0696740547815957

Epoch: 6| Step: 12
Training loss: 2.122023582458496
Validation loss: 2.0691254138946533

Epoch: 6| Step: 13
Training loss: 1.659735918045044
Validation loss: 2.0614137252171836

Epoch: 169| Step: 0
Training loss: 2.871274709701538
Validation loss: 2.087501267592112

Epoch: 6| Step: 1
Training loss: 1.6046507358551025
Validation loss: 2.0837549567222595

Epoch: 6| Step: 2
Training loss: 2.56791353225708
Validation loss: 2.070743183294932

Epoch: 6| Step: 3
Training loss: 1.8393595218658447
Validation loss: 2.0724841753641763

Epoch: 6| Step: 4
Training loss: 1.0847299098968506
Validation loss: 2.0915207266807556

Epoch: 6| Step: 5
Training loss: 1.2282071113586426
Validation loss: 2.0880195697148642

Epoch: 6| Step: 6
Training loss: 2.1741487979888916
Validation loss: 2.0899027387301126

Epoch: 6| Step: 7
Training loss: 1.1694302558898926
Validation loss: 2.1091275811195374

Epoch: 6| Step: 8
Training loss: 2.118408203125
Validation loss: 2.0876258611679077

Epoch: 6| Step: 9
Training loss: 2.689302682876587
Validation loss: 2.1082434256871543

Epoch: 6| Step: 10
Training loss: 2.516408681869507
Validation loss: 2.099643051624298

Epoch: 6| Step: 11
Training loss: 1.9028899669647217
Validation loss: 2.0840848684310913

Epoch: 6| Step: 12
Training loss: 2.3331525325775146
Validation loss: 2.0764176845550537

Epoch: 6| Step: 13
Training loss: 1.500058650970459
Validation loss: 2.0806888540585837

Epoch: 170| Step: 0
Training loss: 2.477111339569092
Validation loss: 2.0914828379948935

Epoch: 6| Step: 1
Training loss: 1.895090937614441
Validation loss: 2.0966731707255044

Epoch: 6| Step: 2
Training loss: 1.4031474590301514
Validation loss: 2.072238564491272

Epoch: 6| Step: 3
Training loss: 1.645421028137207
Validation loss: 2.0903161565462747

Epoch: 6| Step: 4
Training loss: 2.531449556350708
Validation loss: 2.0988752047220864

Epoch: 6| Step: 5
Training loss: 2.0963079929351807
Validation loss: 2.0914027293523154

Epoch: 6| Step: 6
Training loss: 1.862623929977417
Validation loss: 2.0827064911524453

Epoch: 6| Step: 7
Training loss: 2.0979418754577637
Validation loss: 2.0786503156026206

Epoch: 6| Step: 8
Training loss: 2.3053102493286133
Validation loss: 2.0759191115697226

Epoch: 6| Step: 9
Training loss: 1.5127465724945068
Validation loss: 2.0896344979604087

Epoch: 6| Step: 10
Training loss: 1.596265435218811
Validation loss: 2.088545799255371

Epoch: 6| Step: 11
Training loss: 2.4791481494903564
Validation loss: 2.101589540640513

Epoch: 6| Step: 12
Training loss: 1.8047528266906738
Validation loss: 2.0940361618995667

Epoch: 6| Step: 13
Training loss: 1.7766485214233398
Validation loss: 2.1007988452911377

Epoch: 171| Step: 0
Training loss: 2.079981565475464
Validation loss: 2.0942914883295694

Epoch: 6| Step: 1
Training loss: 1.8484617471694946
Validation loss: 2.1039279301961265

Epoch: 6| Step: 2
Training loss: 2.15834641456604
Validation loss: 2.1025710105895996

Epoch: 6| Step: 3
Training loss: 1.8213773965835571
Validation loss: 2.107334613800049

Epoch: 6| Step: 4
Training loss: 1.4684053659439087
Validation loss: 2.096176564693451

Epoch: 6| Step: 5
Training loss: 2.196227550506592
Validation loss: 2.0959277351697287

Epoch: 6| Step: 6
Training loss: 1.8182963132858276
Validation loss: 2.1002891063690186

Epoch: 6| Step: 7
Training loss: 1.6534737348556519
Validation loss: 2.0907289187113443

Epoch: 6| Step: 8
Training loss: 2.3940370082855225
Validation loss: 2.1030782659848533

Epoch: 6| Step: 9
Training loss: 1.952736258506775
Validation loss: 2.0889166792233786

Epoch: 6| Step: 10
Training loss: 1.9330627918243408
Validation loss: 2.086369792620341

Epoch: 6| Step: 11
Training loss: 1.8999810218811035
Validation loss: 2.0949673851331077

Epoch: 6| Step: 12
Training loss: 2.256460666656494
Validation loss: 2.0853696862856546

Epoch: 6| Step: 13
Training loss: 1.9981147050857544
Validation loss: 2.0999873876571655

Epoch: 172| Step: 0
Training loss: 1.9631617069244385
Validation loss: 2.098657548427582

Epoch: 6| Step: 1
Training loss: 2.07596492767334
Validation loss: 2.0994762579600015

Epoch: 6| Step: 2
Training loss: 1.5589910745620728
Validation loss: 2.103072683016459

Epoch: 6| Step: 3
Training loss: 2.435404062271118
Validation loss: 2.112779955069224

Epoch: 6| Step: 4
Training loss: 2.1432275772094727
Validation loss: 2.112882216771444

Epoch: 6| Step: 5
Training loss: 2.21435546875
Validation loss: 2.110871434211731

Epoch: 6| Step: 6
Training loss: 2.279409408569336
Validation loss: 2.1017451882362366

Epoch: 6| Step: 7
Training loss: 2.189396858215332
Validation loss: 2.0963946183522544

Epoch: 6| Step: 8
Training loss: 1.476096510887146
Validation loss: 2.0889743765195212

Epoch: 6| Step: 9
Training loss: 1.6880038976669312
Validation loss: 2.088784654935201

Epoch: 6| Step: 10
Training loss: 2.6252284049987793
Validation loss: 2.083160698413849

Epoch: 6| Step: 11
Training loss: 1.4890397787094116
Validation loss: 2.071165144443512

Epoch: 6| Step: 12
Training loss: 2.0506248474121094
Validation loss: 2.080550253391266

Epoch: 6| Step: 13
Training loss: 1.3676396608352661
Validation loss: 2.1072877645492554

Epoch: 173| Step: 0
Training loss: 2.2573695182800293
Validation loss: 2.116952379544576

Epoch: 6| Step: 1
Training loss: 1.3233344554901123
Validation loss: 2.1141895055770874

Epoch: 6| Step: 2
Training loss: 2.6276237964630127
Validation loss: 2.1291222969690957

Epoch: 6| Step: 3
Training loss: 1.7548547983169556
Validation loss: 2.128459374109904

Epoch: 6| Step: 4
Training loss: 1.8132967948913574
Validation loss: 2.1224215626716614

Epoch: 6| Step: 5
Training loss: 1.9517438411712646
Validation loss: 2.102404614289602

Epoch: 6| Step: 6
Training loss: 2.467839002609253
Validation loss: 2.1035945216814675

Epoch: 6| Step: 7
Training loss: 2.0005388259887695
Validation loss: 2.101533889770508

Epoch: 6| Step: 8
Training loss: 1.8813915252685547
Validation loss: 2.091316521167755

Epoch: 6| Step: 9
Training loss: 2.2016396522521973
Validation loss: 2.087864418824514

Epoch: 6| Step: 10
Training loss: 2.133857488632202
Validation loss: 2.0789615909258523

Epoch: 6| Step: 11
Training loss: 2.290006637573242
Validation loss: 2.0814533829689026

Epoch: 6| Step: 12
Training loss: 1.630295753479004
Validation loss: 2.0824320713678994

Epoch: 6| Step: 13
Training loss: 1.5454168319702148
Validation loss: 2.0814114014307656

Epoch: 174| Step: 0
Training loss: 2.4177680015563965
Validation loss: 2.0651438434918723

Epoch: 6| Step: 1
Training loss: 1.7535170316696167
Validation loss: 2.0767955780029297

Epoch: 6| Step: 2
Training loss: 1.906654953956604
Validation loss: 2.079661548137665

Epoch: 6| Step: 3
Training loss: 1.6510859727859497
Validation loss: 2.083192308743795

Epoch: 6| Step: 4
Training loss: 1.9998747110366821
Validation loss: 2.0921409924825034

Epoch: 6| Step: 5
Training loss: 1.9184544086456299
Validation loss: 2.088272988796234

Epoch: 6| Step: 6
Training loss: 1.854182481765747
Validation loss: 2.0988449255625405

Epoch: 6| Step: 7
Training loss: 2.0674757957458496
Validation loss: 2.085501233736674

Epoch: 6| Step: 8
Training loss: 1.7827200889587402
Validation loss: 2.0897203286488852

Epoch: 6| Step: 9
Training loss: 2.4184513092041016
Validation loss: 2.083514849344889

Epoch: 6| Step: 10
Training loss: 1.6152094602584839
Validation loss: 2.0954415996869407

Epoch: 6| Step: 11
Training loss: 2.0927906036376953
Validation loss: 2.0957335432370505

Epoch: 6| Step: 12
Training loss: 2.1138789653778076
Validation loss: 2.097192962964376

Epoch: 6| Step: 13
Training loss: 1.943627119064331
Validation loss: 2.1018357475598655

Epoch: 175| Step: 0
Training loss: 1.4483592510223389
Validation loss: 2.092912197113037

Epoch: 6| Step: 1
Training loss: 1.6989082098007202
Validation loss: 2.1097883184750876

Epoch: 6| Step: 2
Training loss: 1.7260534763336182
Validation loss: 2.1032268603642783

Epoch: 6| Step: 3
Training loss: 1.8032243251800537
Validation loss: 2.0976965626080832

Epoch: 6| Step: 4
Training loss: 1.9863502979278564
Validation loss: 2.1128497322400412

Epoch: 6| Step: 5
Training loss: 2.4177331924438477
Validation loss: 2.101614832878113

Epoch: 6| Step: 6
Training loss: 1.6390941143035889
Validation loss: 2.1205214063326516

Epoch: 6| Step: 7
Training loss: 2.1994383335113525
Validation loss: 2.110562026500702

Epoch: 6| Step: 8
Training loss: 2.7108428478240967
Validation loss: 2.11851437886556

Epoch: 6| Step: 9
Training loss: 2.4361188411712646
Validation loss: 2.1018250385920205

Epoch: 6| Step: 10
Training loss: 2.190657138824463
Validation loss: 2.1165019075075784

Epoch: 6| Step: 11
Training loss: 1.9020224809646606
Validation loss: 2.1025563677152

Epoch: 6| Step: 12
Training loss: 1.9289829730987549
Validation loss: 2.1171682675679526

Epoch: 6| Step: 13
Training loss: 1.6046096086502075
Validation loss: 2.1142751375834146

Epoch: 176| Step: 0
Training loss: 1.7698848247528076
Validation loss: 2.1198025345802307

Epoch: 6| Step: 1
Training loss: 1.873354434967041
Validation loss: 2.1116228898366294

Epoch: 6| Step: 2
Training loss: 2.784907579421997
Validation loss: 2.096968710422516

Epoch: 6| Step: 3
Training loss: 1.8808560371398926
Validation loss: 2.0890689492225647

Epoch: 6| Step: 4
Training loss: 1.9448083639144897
Validation loss: 2.075213611125946

Epoch: 6| Step: 5
Training loss: 1.5827019214630127
Validation loss: 2.083070079485575

Epoch: 6| Step: 6
Training loss: 1.9343173503875732
Validation loss: 2.086979409058889

Epoch: 6| Step: 7
Training loss: 2.278221607208252
Validation loss: 2.0815571546554565

Epoch: 6| Step: 8
Training loss: 2.0621628761291504
Validation loss: 2.091128349304199

Epoch: 6| Step: 9
Training loss: 1.8379367589950562
Validation loss: 2.1087007323900857

Epoch: 6| Step: 10
Training loss: 1.572587251663208
Validation loss: 2.0975844264030457

Epoch: 6| Step: 11
Training loss: 1.7847050428390503
Validation loss: 2.1011712153752646

Epoch: 6| Step: 12
Training loss: 1.7999520301818848
Validation loss: 2.0997071663538613

Epoch: 6| Step: 13
Training loss: 2.0687437057495117
Validation loss: 2.1159077485402427

Epoch: 177| Step: 0
Training loss: 2.3854660987854004
Validation loss: 2.1138075788815818

Epoch: 6| Step: 1
Training loss: 2.2365822792053223
Validation loss: 2.1310545802116394

Epoch: 6| Step: 2
Training loss: 1.9444518089294434
Validation loss: 2.123100757598877

Epoch: 6| Step: 3
Training loss: 1.4600036144256592
Validation loss: 2.1498655478159585

Epoch: 6| Step: 4
Training loss: 1.5878537893295288
Validation loss: 2.1309834520022073

Epoch: 6| Step: 5
Training loss: 2.361876964569092
Validation loss: 2.1603817542394004

Epoch: 6| Step: 6
Training loss: 2.1075663566589355
Validation loss: 2.1495481729507446

Epoch: 6| Step: 7
Training loss: 2.2915472984313965
Validation loss: 2.127006749312083

Epoch: 6| Step: 8
Training loss: 1.6563783884048462
Validation loss: 2.1094181537628174

Epoch: 6| Step: 9
Training loss: 1.784165859222412
Validation loss: 2.0961780548095703

Epoch: 6| Step: 10
Training loss: 1.8317196369171143
Validation loss: 2.1064655582110086

Epoch: 6| Step: 11
Training loss: 1.7748210430145264
Validation loss: 2.106354296207428

Epoch: 6| Step: 12
Training loss: 1.8239691257476807
Validation loss: 2.098290125528971

Epoch: 6| Step: 13
Training loss: 2.291543960571289
Validation loss: 2.086975355943044

Epoch: 178| Step: 0
Training loss: 1.32149338722229
Validation loss: 2.0763240257898965

Epoch: 6| Step: 1
Training loss: 2.3308300971984863
Validation loss: 2.077553848425547

Epoch: 6| Step: 2
Training loss: 2.2381551265716553
Validation loss: 2.086020608743032

Epoch: 6| Step: 3
Training loss: 1.635467529296875
Validation loss: 2.099174658457438

Epoch: 6| Step: 4
Training loss: 1.3282802104949951
Validation loss: 2.089577933152517

Epoch: 6| Step: 5
Training loss: 1.5901951789855957
Validation loss: 2.10444168249766

Epoch: 6| Step: 6
Training loss: 2.425931692123413
Validation loss: 2.1051348447799683

Epoch: 6| Step: 7
Training loss: 2.4806385040283203
Validation loss: 2.1181683937708535

Epoch: 6| Step: 8
Training loss: 1.3379358053207397
Validation loss: 2.1009975473086038

Epoch: 6| Step: 9
Training loss: 1.8768863677978516
Validation loss: 2.1314645806948342

Epoch: 6| Step: 10
Training loss: 1.9926443099975586
Validation loss: 2.0934590895970664

Epoch: 6| Step: 11
Training loss: 2.3881921768188477
Validation loss: 2.095879554748535

Epoch: 6| Step: 12
Training loss: 3.0678770542144775
Validation loss: 2.0914520819981894

Epoch: 6| Step: 13
Training loss: 1.7407175302505493
Validation loss: 2.0965055028597512

Epoch: 179| Step: 0
Training loss: 1.7760848999023438
Validation loss: 2.092310984929403

Epoch: 6| Step: 1
Training loss: 1.910517930984497
Validation loss: 2.095900595188141

Epoch: 6| Step: 2
Training loss: 1.7996069192886353
Validation loss: 2.091843326886495

Epoch: 6| Step: 3
Training loss: 2.2608137130737305
Validation loss: 2.094953954219818

Epoch: 6| Step: 4
Training loss: 1.885493516921997
Validation loss: 2.0929364363352456

Epoch: 6| Step: 5
Training loss: 1.9624130725860596
Validation loss: 2.0833208362261453

Epoch: 6| Step: 6
Training loss: 2.169025421142578
Validation loss: 2.0917334159215293

Epoch: 6| Step: 7
Training loss: 1.9534862041473389
Validation loss: 2.093514402707418

Epoch: 6| Step: 8
Training loss: 1.801435947418213
Validation loss: 2.0942464470863342

Epoch: 6| Step: 9
Training loss: 2.220933675765991
Validation loss: 2.08635280529658

Epoch: 6| Step: 10
Training loss: 1.6637625694274902
Validation loss: 2.094198167324066

Epoch: 6| Step: 11
Training loss: 1.9750232696533203
Validation loss: 2.081612288951874

Epoch: 6| Step: 12
Training loss: 1.7248389720916748
Validation loss: 2.0990609725316367

Epoch: 6| Step: 13
Training loss: 2.0505940914154053
Validation loss: 2.108456552028656

Epoch: 180| Step: 0
Training loss: 1.7793294191360474
Validation loss: 2.103629469871521

Epoch: 6| Step: 1
Training loss: 2.145941734313965
Validation loss: 2.092069605986277

Epoch: 6| Step: 2
Training loss: 2.221067428588867
Validation loss: 2.0917464892069497

Epoch: 6| Step: 3
Training loss: 2.1289455890655518
Validation loss: 2.101345698038737

Epoch: 6| Step: 4
Training loss: 1.9313900470733643
Validation loss: 2.091479321320852

Epoch: 6| Step: 5
Training loss: 1.851433277130127
Validation loss: 2.1021272341410318

Epoch: 6| Step: 6
Training loss: 1.878507137298584
Validation loss: 2.0999573270479837

Epoch: 6| Step: 7
Training loss: 1.7377829551696777
Validation loss: 2.1057589054107666

Epoch: 6| Step: 8
Training loss: 1.964926838874817
Validation loss: 2.105631391207377

Epoch: 6| Step: 9
Training loss: 1.8118171691894531
Validation loss: 2.098825732866923

Epoch: 6| Step: 10
Training loss: 1.7012652158737183
Validation loss: 2.100823680559794

Epoch: 6| Step: 11
Training loss: 2.0630860328674316
Validation loss: 2.0892417629559836

Epoch: 6| Step: 12
Training loss: 1.9484798908233643
Validation loss: 2.093536297480265

Epoch: 6| Step: 13
Training loss: 2.0718841552734375
Validation loss: 2.0889391700426736

Epoch: 181| Step: 0
Training loss: 2.008115291595459
Validation loss: 2.0863900184631348

Epoch: 6| Step: 1
Training loss: 1.829272747039795
Validation loss: 2.088341772556305

Epoch: 6| Step: 2
Training loss: 2.202817440032959
Validation loss: 2.092385788758596

Epoch: 6| Step: 3
Training loss: 2.1649010181427
Validation loss: 2.081804315249125

Epoch: 6| Step: 4
Training loss: 2.207387685775757
Validation loss: 2.1072261730829873

Epoch: 6| Step: 5
Training loss: 1.7034072875976562
Validation loss: 2.102536420027415

Epoch: 6| Step: 6
Training loss: 2.231405258178711
Validation loss: 2.1131651600201926

Epoch: 6| Step: 7
Training loss: 2.3034329414367676
Validation loss: 2.1092206637064614

Epoch: 6| Step: 8
Training loss: 1.9283748865127563
Validation loss: 2.1275379260381064

Epoch: 6| Step: 9
Training loss: 1.8654446601867676
Validation loss: 2.1255439718564353

Epoch: 6| Step: 10
Training loss: 1.2461872100830078
Validation loss: 2.1328835487365723

Epoch: 6| Step: 11
Training loss: 2.3759121894836426
Validation loss: 2.132315933704376

Epoch: 6| Step: 12
Training loss: 1.939943552017212
Validation loss: 2.134649674097697

Epoch: 6| Step: 13
Training loss: 1.6860824823379517
Validation loss: 2.1169173320134482

Epoch: 182| Step: 0
Training loss: 1.4322247505187988
Validation loss: 2.1151552200317383

Epoch: 6| Step: 1
Training loss: 1.7531609535217285
Validation loss: 2.1120781103769937

Epoch: 6| Step: 2
Training loss: 1.4427986145019531
Validation loss: 2.0978547732035318

Epoch: 6| Step: 3
Training loss: 1.8252071142196655
Validation loss: 2.0859158436457315

Epoch: 6| Step: 4
Training loss: 1.772770881652832
Validation loss: 2.0938225189844766

Epoch: 6| Step: 5
Training loss: 2.188755750656128
Validation loss: 2.0781673590342202

Epoch: 6| Step: 6
Training loss: 2.82609486579895
Validation loss: 2.0793203711509705

Epoch: 6| Step: 7
Training loss: 2.091703414916992
Validation loss: 2.0747055212656655

Epoch: 6| Step: 8
Training loss: 2.220614433288574
Validation loss: 2.0731239318847656

Epoch: 6| Step: 9
Training loss: 1.7112430334091187
Validation loss: 2.0870408415794373

Epoch: 6| Step: 10
Training loss: 2.179307460784912
Validation loss: 2.0874616503715515

Epoch: 6| Step: 11
Training loss: 2.044320821762085
Validation loss: 2.0921448270479837

Epoch: 6| Step: 12
Training loss: 2.5624661445617676
Validation loss: 2.1040682395299277

Epoch: 6| Step: 13
Training loss: 1.70676851272583
Validation loss: 2.0970573822657266

Epoch: 183| Step: 0
Training loss: 1.8567748069763184
Validation loss: 2.1141648292541504

Epoch: 6| Step: 1
Training loss: 2.2889482975006104
Validation loss: 2.138051430384318

Epoch: 6| Step: 2
Training loss: 1.5782859325408936
Validation loss: 2.133906106154124

Epoch: 6| Step: 3
Training loss: 2.016540288925171
Validation loss: 2.1373637517293296

Epoch: 6| Step: 4
Training loss: 1.8566689491271973
Validation loss: 2.1262611746788025

Epoch: 6| Step: 5
Training loss: 1.7287731170654297
Validation loss: 2.114902218182882

Epoch: 6| Step: 6
Training loss: 2.868706226348877
Validation loss: 2.119288225968679

Epoch: 6| Step: 7
Training loss: 2.0592691898345947
Validation loss: 2.0992732445398965

Epoch: 6| Step: 8
Training loss: 2.110698699951172
Validation loss: 2.094603935877482

Epoch: 6| Step: 9
Training loss: 1.671771764755249
Validation loss: 2.1072028080622354

Epoch: 6| Step: 10
Training loss: 2.276710271835327
Validation loss: 2.097314476966858

Epoch: 6| Step: 11
Training loss: 1.4830505847930908
Validation loss: 2.095134973526001

Epoch: 6| Step: 12
Training loss: 2.0030484199523926
Validation loss: 2.0887069503466287

Epoch: 6| Step: 13
Training loss: 1.6736723184585571
Validation loss: 2.096942881743113

Epoch: 184| Step: 0
Training loss: 2.701204776763916
Validation loss: 2.1108644803365073

Epoch: 6| Step: 1
Training loss: 1.382718801498413
Validation loss: 2.1018579800923667

Epoch: 6| Step: 2
Training loss: 2.0241427421569824
Validation loss: 2.1082118153572083

Epoch: 6| Step: 3
Training loss: 1.788785457611084
Validation loss: 2.0977601408958435

Epoch: 6| Step: 4
Training loss: 1.615653395652771
Validation loss: 2.1150028109550476

Epoch: 6| Step: 5
Training loss: 2.010042190551758
Validation loss: 2.1085439920425415

Epoch: 6| Step: 6
Training loss: 2.4450035095214844
Validation loss: 2.0968942840894065

Epoch: 6| Step: 7
Training loss: 1.705031156539917
Validation loss: 2.1110683480898538

Epoch: 6| Step: 8
Training loss: 1.6483619213104248
Validation loss: 2.1030386288960776

Epoch: 6| Step: 9
Training loss: 1.8658933639526367
Validation loss: 2.1099496682484946

Epoch: 6| Step: 10
Training loss: 1.9328205585479736
Validation loss: 2.0921491980552673

Epoch: 6| Step: 11
Training loss: 1.779274582862854
Validation loss: 2.1022077600161233

Epoch: 6| Step: 12
Training loss: 2.0365474224090576
Validation loss: 2.0882519086201987

Epoch: 6| Step: 13
Training loss: 1.9819990396499634
Validation loss: 2.1172181963920593

Epoch: 185| Step: 0
Training loss: 2.09354567527771
Validation loss: 2.112190326054891

Epoch: 6| Step: 1
Training loss: 1.6337976455688477
Validation loss: 2.125523825486501

Epoch: 6| Step: 2
Training loss: 1.8289334774017334
Validation loss: 2.1208359797795615

Epoch: 6| Step: 3
Training loss: 2.467174768447876
Validation loss: 2.1229745149612427

Epoch: 6| Step: 4
Training loss: 1.8016517162322998
Validation loss: 2.1315307219823203

Epoch: 6| Step: 5
Training loss: 2.168199062347412
Validation loss: 2.1343358755111694

Epoch: 6| Step: 6
Training loss: 2.241581439971924
Validation loss: 2.1281612714131675

Epoch: 6| Step: 7
Training loss: 1.6388376951217651
Validation loss: 2.1216670870780945

Epoch: 6| Step: 8
Training loss: 1.9980955123901367
Validation loss: 2.1095610658327737

Epoch: 6| Step: 9
Training loss: 1.9239156246185303
Validation loss: 2.126113216082255

Epoch: 6| Step: 10
Training loss: 2.405571937561035
Validation loss: 2.1021660963694253

Epoch: 6| Step: 11
Training loss: 2.0673906803131104
Validation loss: 2.1033072471618652

Epoch: 6| Step: 12
Training loss: 1.4963399171829224
Validation loss: 2.1068822542826333

Epoch: 6| Step: 13
Training loss: 1.488713026046753
Validation loss: 2.0987473924954734

Epoch: 186| Step: 0
Training loss: 2.2000958919525146
Validation loss: 2.122239649295807

Epoch: 6| Step: 1
Training loss: 2.1332406997680664
Validation loss: 2.120252807935079

Epoch: 6| Step: 2
Training loss: 1.98912513256073
Validation loss: 2.1436374187469482

Epoch: 6| Step: 3
Training loss: 1.9782028198242188
Validation loss: 2.1239449183146157

Epoch: 6| Step: 4
Training loss: 1.8516018390655518
Validation loss: 2.1397428711255393

Epoch: 6| Step: 5
Training loss: 1.504799246788025
Validation loss: 2.1385908722877502

Epoch: 6| Step: 6
Training loss: 1.6160626411437988
Validation loss: 2.130380630493164

Epoch: 6| Step: 7
Training loss: 2.31882381439209
Validation loss: 2.130165417989095

Epoch: 6| Step: 8
Training loss: 1.5706307888031006
Validation loss: 2.125842253367106

Epoch: 6| Step: 9
Training loss: 1.4771511554718018
Validation loss: 2.102006494998932

Epoch: 6| Step: 10
Training loss: 1.9896972179412842
Validation loss: 2.101113796234131

Epoch: 6| Step: 11
Training loss: 1.8841384649276733
Validation loss: 2.099462906519572

Epoch: 6| Step: 12
Training loss: 2.3581786155700684
Validation loss: 2.0981368819872537

Epoch: 6| Step: 13
Training loss: 2.179159164428711
Validation loss: 2.1051249305407205

Epoch: 187| Step: 0
Training loss: 2.467867851257324
Validation loss: 2.107961336771647

Epoch: 6| Step: 1
Training loss: 1.6906404495239258
Validation loss: 2.1170902649561563

Epoch: 6| Step: 2
Training loss: 1.959112286567688
Validation loss: 2.1173634926478067

Epoch: 6| Step: 3
Training loss: 2.121206045150757
Validation loss: 2.1186559001604715

Epoch: 6| Step: 4
Training loss: 1.2896513938903809
Validation loss: 2.1244295835494995

Epoch: 6| Step: 5
Training loss: 2.3284201622009277
Validation loss: 2.112526814142863

Epoch: 6| Step: 6
Training loss: 1.7148483991622925
Validation loss: 2.1215703090031943

Epoch: 6| Step: 7
Training loss: 1.8838235139846802
Validation loss: 2.1119181513786316

Epoch: 6| Step: 8
Training loss: 1.246628761291504
Validation loss: 2.1050922870635986

Epoch: 6| Step: 9
Training loss: 2.160550355911255
Validation loss: 2.0917888879776

Epoch: 6| Step: 10
Training loss: 2.1484646797180176
Validation loss: 2.1026702523231506

Epoch: 6| Step: 11
Training loss: 2.488157033920288
Validation loss: 2.1126819451649985

Epoch: 6| Step: 12
Training loss: 1.5986957550048828
Validation loss: 2.0958807468414307

Epoch: 6| Step: 13
Training loss: 1.7971844673156738
Validation loss: 2.1032077074050903

Epoch: 188| Step: 0
Training loss: 1.3814914226531982
Validation loss: 2.1135210593541465

Epoch: 6| Step: 1
Training loss: 1.8529378175735474
Validation loss: 2.1044448018074036

Epoch: 6| Step: 2
Training loss: 1.8502824306488037
Validation loss: 2.119400362173716

Epoch: 6| Step: 3
Training loss: 1.8802417516708374
Validation loss: 2.1118730107943215

Epoch: 6| Step: 4
Training loss: 1.5258216857910156
Validation loss: 2.1237537264823914

Epoch: 6| Step: 5
Training loss: 1.9640159606933594
Validation loss: 2.112658063570658

Epoch: 6| Step: 6
Training loss: 1.9321644306182861
Validation loss: 2.1363333264986673

Epoch: 6| Step: 7
Training loss: 1.9065653085708618
Validation loss: 2.119736909866333

Epoch: 6| Step: 8
Training loss: 2.040706157684326
Validation loss: 2.128294368584951

Epoch: 6| Step: 9
Training loss: 1.9951894283294678
Validation loss: 2.133403956890106

Epoch: 6| Step: 10
Training loss: 2.0206711292266846
Validation loss: 2.103963335355123

Epoch: 6| Step: 11
Training loss: 2.213813304901123
Validation loss: 2.0976414680480957

Epoch: 6| Step: 12
Training loss: 1.897721529006958
Validation loss: 2.113837500413259

Epoch: 6| Step: 13
Training loss: 2.4065284729003906
Validation loss: 2.1106894810994468

Epoch: 189| Step: 0
Training loss: 2.0860955715179443
Validation loss: 2.0960126320521035

Epoch: 6| Step: 1
Training loss: 1.3569705486297607
Validation loss: 2.1127821803092957

Epoch: 6| Step: 2
Training loss: 2.392587184906006
Validation loss: 2.1066633661588035

Epoch: 6| Step: 3
Training loss: 2.3281116485595703
Validation loss: 2.103658656279246

Epoch: 6| Step: 4
Training loss: 2.0610337257385254
Validation loss: 2.107408106327057

Epoch: 6| Step: 5
Training loss: 2.1230368614196777
Validation loss: 2.1150317390759787

Epoch: 6| Step: 6
Training loss: 1.9801400899887085
Validation loss: 2.1236286560694375

Epoch: 6| Step: 7
Training loss: 1.144592046737671
Validation loss: 2.1222519874572754

Epoch: 6| Step: 8
Training loss: 1.7633278369903564
Validation loss: 2.1525467236836753

Epoch: 6| Step: 9
Training loss: 2.256704092025757
Validation loss: 2.144779066244761

Epoch: 6| Step: 10
Training loss: 1.872385859489441
Validation loss: 2.1578893264134726

Epoch: 6| Step: 11
Training loss: 2.296415328979492
Validation loss: 2.142261783281962

Epoch: 6| Step: 12
Training loss: 2.1412415504455566
Validation loss: 2.1387497782707214

Epoch: 6| Step: 13
Training loss: 1.670607328414917
Validation loss: 2.1334885954856873

Epoch: 190| Step: 0
Training loss: 1.3138766288757324
Validation loss: 2.1216221253077188

Epoch: 6| Step: 1
Training loss: 2.675178050994873
Validation loss: 2.116147736708323

Epoch: 6| Step: 2
Training loss: 2.1936917304992676
Validation loss: 2.0943989157676697

Epoch: 6| Step: 3
Training loss: 1.9437733888626099
Validation loss: 2.0951577027638755

Epoch: 6| Step: 4
Training loss: 1.9506629705429077
Validation loss: 2.09696102142334

Epoch: 6| Step: 5
Training loss: 1.8955529928207397
Validation loss: 2.1067870259284973

Epoch: 6| Step: 6
Training loss: 2.094273567199707
Validation loss: 2.0966270565986633

Epoch: 6| Step: 7
Training loss: 1.6505118608474731
Validation loss: 2.1074877977371216

Epoch: 6| Step: 8
Training loss: 1.8781073093414307
Validation loss: 2.1035083134969077

Epoch: 6| Step: 9
Training loss: 2.1777772903442383
Validation loss: 2.107868174711863

Epoch: 6| Step: 10
Training loss: 2.3111720085144043
Validation loss: 2.118521968523661

Epoch: 6| Step: 11
Training loss: 1.8891372680664062
Validation loss: 2.1105413834253945

Epoch: 6| Step: 12
Training loss: 1.8190999031066895
Validation loss: 2.115909218788147

Epoch: 6| Step: 13
Training loss: 2.217648983001709
Validation loss: 2.1218915383021035

Epoch: 191| Step: 0
Training loss: 1.8131885528564453
Validation loss: 2.1135008335113525

Epoch: 6| Step: 1
Training loss: 2.1208181381225586
Validation loss: 2.112302601337433

Epoch: 6| Step: 2
Training loss: 2.804041624069214
Validation loss: 2.1263082226117453

Epoch: 6| Step: 3
Training loss: 1.6732131242752075
Validation loss: 2.1140859127044678

Epoch: 6| Step: 4
Training loss: 1.5371869802474976
Validation loss: 2.108514746030172

Epoch: 6| Step: 5
Training loss: 1.4238080978393555
Validation loss: 2.1116694808006287

Epoch: 6| Step: 6
Training loss: 2.254434108734131
Validation loss: 2.0929051637649536

Epoch: 6| Step: 7
Training loss: 1.8857728242874146
Validation loss: 2.108361303806305

Epoch: 6| Step: 8
Training loss: 1.919831395149231
Validation loss: 2.1191862424214682

Epoch: 6| Step: 9
Training loss: 1.8815865516662598
Validation loss: 2.1119571328163147

Epoch: 6| Step: 10
Training loss: 2.2453784942626953
Validation loss: 2.128759721914927

Epoch: 6| Step: 11
Training loss: 1.5015151500701904
Validation loss: 2.115711212158203

Epoch: 6| Step: 12
Training loss: 1.780752420425415
Validation loss: 2.1189513007799783

Epoch: 6| Step: 13
Training loss: 1.89769446849823
Validation loss: 2.127764324347178

Epoch: 192| Step: 0
Training loss: 2.1382651329040527
Validation loss: 2.1167116363843284

Epoch: 6| Step: 1
Training loss: 1.7797415256500244
Validation loss: 2.113016208012899

Epoch: 6| Step: 2
Training loss: 2.0330629348754883
Validation loss: 2.1059876680374146

Epoch: 6| Step: 3
Training loss: 2.229001998901367
Validation loss: 2.119644025961558

Epoch: 6| Step: 4
Training loss: 2.495713710784912
Validation loss: 2.1070438226064048

Epoch: 6| Step: 5
Training loss: 1.4467227458953857
Validation loss: 2.104177256425222

Epoch: 6| Step: 6
Training loss: 2.084012746810913
Validation loss: 2.0913637479146323

Epoch: 6| Step: 7
Training loss: 1.5474815368652344
Validation loss: 2.1065202951431274

Epoch: 6| Step: 8
Training loss: 1.6692789793014526
Validation loss: 2.096469263235728

Epoch: 6| Step: 9
Training loss: 2.139702796936035
Validation loss: 2.0997242530186973

Epoch: 6| Step: 10
Training loss: 2.001948118209839
Validation loss: 2.103246569633484

Epoch: 6| Step: 11
Training loss: 2.0429420471191406
Validation loss: 2.119628667831421

Epoch: 6| Step: 12
Training loss: 1.5777866840362549
Validation loss: 2.127846042315165

Epoch: 6| Step: 13
Training loss: 2.0493626594543457
Validation loss: 2.121775050957998

Epoch: 193| Step: 0
Training loss: 2.4120969772338867
Validation loss: 2.1239864428838096

Epoch: 6| Step: 1
Training loss: 1.5045080184936523
Validation loss: 2.1317270000775657

Epoch: 6| Step: 2
Training loss: 1.8481485843658447
Validation loss: 2.131153921286265

Epoch: 6| Step: 3
Training loss: 1.5712944269180298
Validation loss: 2.142460902531942

Epoch: 6| Step: 4
Training loss: 2.3674097061157227
Validation loss: 2.1522621711095176

Epoch: 6| Step: 5
Training loss: 1.696484923362732
Validation loss: 2.1336954832077026

Epoch: 6| Step: 6
Training loss: 1.8189961910247803
Validation loss: 2.137211004892985

Epoch: 6| Step: 7
Training loss: 2.2816505432128906
Validation loss: 2.1431586742401123

Epoch: 6| Step: 8
Training loss: 1.271831750869751
Validation loss: 2.130735715230306

Epoch: 6| Step: 9
Training loss: 1.7280004024505615
Validation loss: 2.1204868157704673

Epoch: 6| Step: 10
Training loss: 1.7282055616378784
Validation loss: 2.132383147875468

Epoch: 6| Step: 11
Training loss: 2.1434977054595947
Validation loss: 2.1192272901535034

Epoch: 6| Step: 12
Training loss: 2.476165771484375
Validation loss: 2.1103729605674744

Epoch: 6| Step: 13
Training loss: 1.7084661722183228
Validation loss: 2.1216952403386435

Epoch: 194| Step: 0
Training loss: 1.8354434967041016
Validation loss: 2.1131747364997864

Epoch: 6| Step: 1
Training loss: 1.861009120941162
Validation loss: 2.1016363501548767

Epoch: 6| Step: 2
Training loss: 2.248487949371338
Validation loss: 2.104327976703644

Epoch: 6| Step: 3
Training loss: 2.0389018058776855
Validation loss: 2.096255362033844

Epoch: 6| Step: 4
Training loss: 2.126049041748047
Validation loss: 2.104784071445465

Epoch: 6| Step: 5
Training loss: 1.9999696016311646
Validation loss: 2.103274424870809

Epoch: 6| Step: 6
Training loss: 1.565040111541748
Validation loss: 2.106671392917633

Epoch: 6| Step: 7
Training loss: 2.194772720336914
Validation loss: 2.10443651676178

Epoch: 6| Step: 8
Training loss: 1.5811067819595337
Validation loss: 2.105448325475057

Epoch: 6| Step: 9
Training loss: 3.064927339553833
Validation loss: 2.1322161753972373

Epoch: 6| Step: 10
Training loss: 1.7870827913284302
Validation loss: 2.1091293692588806

Epoch: 6| Step: 11
Training loss: 1.63986074924469
Validation loss: 2.120659033457438

Epoch: 6| Step: 12
Training loss: 1.798103928565979
Validation loss: 2.1406262715657554

Epoch: 6| Step: 13
Training loss: 1.3543123006820679
Validation loss: 2.1262786388397217

Epoch: 195| Step: 0
Training loss: 2.43196964263916
Validation loss: 2.120643377304077

Epoch: 6| Step: 1
Training loss: 2.080669403076172
Validation loss: 2.1069724361101785

Epoch: 6| Step: 2
Training loss: 1.5385195016860962
Validation loss: 2.1098618706067405

Epoch: 6| Step: 3
Training loss: 2.1136348247528076
Validation loss: 2.106270710627238

Epoch: 6| Step: 4
Training loss: 2.1865668296813965
Validation loss: 2.103075603644053

Epoch: 6| Step: 5
Training loss: 1.290501356124878
Validation loss: 2.1029357512791953

Epoch: 6| Step: 6
Training loss: 1.6916348934173584
Validation loss: 2.123268206914266

Epoch: 6| Step: 7
Training loss: 1.5965970754623413
Validation loss: 2.1251227657000222

Epoch: 6| Step: 8
Training loss: 1.2632743120193481
Validation loss: 2.1265418330828347

Epoch: 6| Step: 9
Training loss: 2.374793291091919
Validation loss: 2.13244237502416

Epoch: 6| Step: 10
Training loss: 1.6612966060638428
Validation loss: 2.1211361487706504

Epoch: 6| Step: 11
Training loss: 2.398676872253418
Validation loss: 2.160831789175669

Epoch: 6| Step: 12
Training loss: 1.7174324989318848
Validation loss: 2.1560285290082297

Epoch: 6| Step: 13
Training loss: 2.17789888381958
Validation loss: 2.1568609873453775

Epoch: 196| Step: 0
Training loss: 1.2239919900894165
Validation loss: 2.165605306625366

Epoch: 6| Step: 1
Training loss: 2.1425552368164062
Validation loss: 2.1638947327931723

Epoch: 6| Step: 2
Training loss: 1.7302333116531372
Validation loss: 2.1671292384465537

Epoch: 6| Step: 3
Training loss: 1.7558165788650513
Validation loss: 2.1613266269365945

Epoch: 6| Step: 4
Training loss: 2.4384818077087402
Validation loss: 2.155041813850403

Epoch: 6| Step: 5
Training loss: 2.2510263919830322
Validation loss: 2.1658464272816977

Epoch: 6| Step: 6
Training loss: 1.775838851928711
Validation loss: 2.157147785027822

Epoch: 6| Step: 7
Training loss: 2.4150333404541016
Validation loss: 2.1542120377222695

Epoch: 6| Step: 8
Training loss: 1.5420632362365723
Validation loss: 2.1329668164253235

Epoch: 6| Step: 9
Training loss: 2.06302547454834
Validation loss: 2.1304994225502014

Epoch: 6| Step: 10
Training loss: 2.000053644180298
Validation loss: 2.1147236029307046

Epoch: 6| Step: 11
Training loss: 1.9835703372955322
Validation loss: 2.116477608680725

Epoch: 6| Step: 12
Training loss: 2.7975986003875732
Validation loss: 2.11589245001475

Epoch: 6| Step: 13
Training loss: 0.9385794997215271
Validation loss: 2.1291861732800803

Epoch: 197| Step: 0
Training loss: 2.4280078411102295
Validation loss: 2.1110066771507263

Epoch: 6| Step: 1
Training loss: 1.529937744140625
Validation loss: 2.111415922641754

Epoch: 6| Step: 2
Training loss: 1.9116239547729492
Validation loss: 2.146373132864634

Epoch: 6| Step: 3
Training loss: 2.1360955238342285
Validation loss: 2.137436846892039

Epoch: 6| Step: 4
Training loss: 1.9644172191619873
Validation loss: 2.140024205048879

Epoch: 6| Step: 5
Training loss: 2.239969253540039
Validation loss: 2.1549962560335794

Epoch: 6| Step: 6
Training loss: 2.051053285598755
Validation loss: 2.16161314646403

Epoch: 6| Step: 7
Training loss: 1.8291641473770142
Validation loss: 2.165843188762665

Epoch: 6| Step: 8
Training loss: 1.7836205959320068
Validation loss: 2.167308727900187

Epoch: 6| Step: 9
Training loss: 1.8782991170883179
Validation loss: 2.170018037160238

Epoch: 6| Step: 10
Training loss: 2.2256879806518555
Validation loss: 2.14770499865214

Epoch: 6| Step: 11
Training loss: 2.3192572593688965
Validation loss: 2.1559122602144876

Epoch: 6| Step: 12
Training loss: 1.318723440170288
Validation loss: 2.138945996761322

Epoch: 6| Step: 13
Training loss: 1.5956002473831177
Validation loss: 2.128806988398234

Epoch: 198| Step: 0
Training loss: 1.9413344860076904
Validation loss: 2.0930248300234475

Epoch: 6| Step: 1
Training loss: 1.940670371055603
Validation loss: 2.0973642071088157

Epoch: 6| Step: 2
Training loss: 2.1160244941711426
Validation loss: 2.088272988796234

Epoch: 6| Step: 3
Training loss: 1.7690167427062988
Validation loss: 2.0998093088467917

Epoch: 6| Step: 4
Training loss: 1.6252307891845703
Validation loss: 2.090386946996053

Epoch: 6| Step: 5
Training loss: 1.919299602508545
Validation loss: 2.0843112468719482

Epoch: 6| Step: 6
Training loss: 1.5103601217269897
Validation loss: 2.0953142642974854

Epoch: 6| Step: 7
Training loss: 1.8251276016235352
Validation loss: 2.0977604587872825

Epoch: 6| Step: 8
Training loss: 2.2621188163757324
Validation loss: 2.112725615501404

Epoch: 6| Step: 9
Training loss: 1.8831528425216675
Validation loss: 2.1320771177609763

Epoch: 6| Step: 10
Training loss: 1.4869657754898071
Validation loss: 2.1269736091295877

Epoch: 6| Step: 11
Training loss: 1.996497392654419
Validation loss: 2.1112181544303894

Epoch: 6| Step: 12
Training loss: 2.198582410812378
Validation loss: 2.1088448762893677

Epoch: 6| Step: 13
Training loss: 2.20060133934021
Validation loss: 2.1155894994735718

Epoch: 199| Step: 0
Training loss: 2.0565643310546875
Validation loss: 2.105140209197998

Epoch: 6| Step: 1
Training loss: 1.3296048641204834
Validation loss: 2.1039408445358276

Epoch: 6| Step: 2
Training loss: 2.0843563079833984
Validation loss: 2.0990763505299888

Epoch: 6| Step: 3
Training loss: 1.5179001092910767
Validation loss: 2.110945463180542

Epoch: 6| Step: 4
Training loss: 1.8885143995285034
Validation loss: 2.0971598823865256

Epoch: 6| Step: 5
Training loss: 2.091655731201172
Validation loss: 2.1096901496251426

Epoch: 6| Step: 6
Training loss: 1.5126063823699951
Validation loss: 2.1065635879834494

Epoch: 6| Step: 7
Training loss: 2.2067272663116455
Validation loss: 2.1021342476209006

Epoch: 6| Step: 8
Training loss: 1.9146264791488647
Validation loss: 2.100382129351298

Epoch: 6| Step: 9
Training loss: 1.9926047325134277
Validation loss: 2.099146584669749

Epoch: 6| Step: 10
Training loss: 1.7109143733978271
Validation loss: 2.112982928752899

Epoch: 6| Step: 11
Training loss: 2.1322884559631348
Validation loss: 2.1256702740987143

Epoch: 6| Step: 12
Training loss: 2.0315780639648438
Validation loss: 2.097865362962087

Epoch: 6| Step: 13
Training loss: 2.106231212615967
Validation loss: 2.1044968167940774

Epoch: 200| Step: 0
Training loss: 1.811279535293579
Validation loss: 2.10526837905248

Epoch: 6| Step: 1
Training loss: 1.4724793434143066
Validation loss: 2.1150726079940796

Epoch: 6| Step: 2
Training loss: 2.5679659843444824
Validation loss: 2.11182709534963

Epoch: 6| Step: 3
Training loss: 1.8897368907928467
Validation loss: 2.110924164454142

Epoch: 6| Step: 4
Training loss: 2.1212940216064453
Validation loss: 2.116950273513794

Epoch: 6| Step: 5
Training loss: 1.5540695190429688
Validation loss: 2.1281577746073403

Epoch: 6| Step: 6
Training loss: 1.8337490558624268
Validation loss: 2.1090961694717407

Epoch: 6| Step: 7
Training loss: 2.2973995208740234
Validation loss: 2.1173604329427085

Epoch: 6| Step: 8
Training loss: 2.438734292984009
Validation loss: 2.113933483759562

Epoch: 6| Step: 9
Training loss: 1.4880726337432861
Validation loss: 2.1241918206214905

Epoch: 6| Step: 10
Training loss: 1.8263568878173828
Validation loss: 2.1209529042243958

Epoch: 6| Step: 11
Training loss: 1.5036616325378418
Validation loss: 2.1150447130203247

Epoch: 6| Step: 12
Training loss: 1.7336068153381348
Validation loss: 2.102836767832438

Epoch: 6| Step: 13
Training loss: 2.020296573638916
Validation loss: 2.1201552351315818

Epoch: 201| Step: 0
Training loss: 1.9866304397583008
Validation loss: 2.1023547053337097

Epoch: 6| Step: 1
Training loss: 2.247483730316162
Validation loss: 2.092531681060791

Epoch: 6| Step: 2
Training loss: 1.6734375953674316
Validation loss: 2.1204097469647727

Epoch: 6| Step: 3
Training loss: 1.6319129467010498
Validation loss: 2.108393371105194

Epoch: 6| Step: 4
Training loss: 1.4254348278045654
Validation loss: 2.11104021469752

Epoch: 6| Step: 5
Training loss: 1.5094538927078247
Validation loss: 2.1149174571037292

Epoch: 6| Step: 6
Training loss: 1.8947556018829346
Validation loss: 2.1439870794614158

Epoch: 6| Step: 7
Training loss: 2.1607184410095215
Validation loss: 2.1600780884424844

Epoch: 6| Step: 8
Training loss: 1.665319800376892
Validation loss: 2.1954113245010376

Epoch: 6| Step: 9
Training loss: 1.1849747896194458
Validation loss: 2.162488838036855

Epoch: 6| Step: 10
Training loss: 2.4047770500183105
Validation loss: 2.166614810625712

Epoch: 6| Step: 11
Training loss: 2.134420394897461
Validation loss: 2.164638896783193

Epoch: 6| Step: 12
Training loss: 2.5591037273406982
Validation loss: 2.1703592936197915

Epoch: 6| Step: 13
Training loss: 2.339925765991211
Validation loss: 2.1633487542470298

Epoch: 202| Step: 0
Training loss: 2.3382115364074707
Validation loss: 2.1732394099235535

Epoch: 6| Step: 1
Training loss: 2.354208469390869
Validation loss: 2.165497879187266

Epoch: 6| Step: 2
Training loss: 2.3610851764678955
Validation loss: 2.1431405941645303

Epoch: 6| Step: 3
Training loss: 1.5887532234191895
Validation loss: 2.1515344381332397

Epoch: 6| Step: 4
Training loss: 1.5752081871032715
Validation loss: 2.13393505414327

Epoch: 6| Step: 5
Training loss: 1.2763264179229736
Validation loss: 2.1285834312438965

Epoch: 6| Step: 6
Training loss: 1.610508680343628
Validation loss: 2.1173324386278787

Epoch: 6| Step: 7
Training loss: 2.239701271057129
Validation loss: 2.1297563711802163

Epoch: 6| Step: 8
Training loss: 2.1400656700134277
Validation loss: 2.1144511699676514

Epoch: 6| Step: 9
Training loss: 1.272918939590454
Validation loss: 2.13410751024882

Epoch: 6| Step: 10
Training loss: 1.9355409145355225
Validation loss: 2.1406774719556174

Epoch: 6| Step: 11
Training loss: 1.5887315273284912
Validation loss: 2.1445385615030923

Epoch: 6| Step: 12
Training loss: 2.0985612869262695
Validation loss: 2.12179434299469

Epoch: 6| Step: 13
Training loss: 1.7562487125396729
Validation loss: 2.128403663635254

Epoch: 203| Step: 0
Training loss: 1.9719290733337402
Validation loss: 2.1227921644846597

Epoch: 6| Step: 1
Training loss: 1.825493574142456
Validation loss: 2.1372217535972595

Epoch: 6| Step: 2
Training loss: 1.6642767190933228
Validation loss: 2.142638882001241

Epoch: 6| Step: 3
Training loss: 1.6266893148422241
Validation loss: 2.137364705403646

Epoch: 6| Step: 4
Training loss: 2.2567715644836426
Validation loss: 2.1227832436561584

Epoch: 6| Step: 5
Training loss: 1.6600151062011719
Validation loss: 2.1187880436579385

Epoch: 6| Step: 6
Training loss: 1.5028433799743652
Validation loss: 2.1215829451878867

Epoch: 6| Step: 7
Training loss: 2.0078561305999756
Validation loss: 2.1168567736943564

Epoch: 6| Step: 8
Training loss: 2.522892951965332
Validation loss: 2.110670884450277

Epoch: 6| Step: 9
Training loss: 1.6930221319198608
Validation loss: 2.116935928662618

Epoch: 6| Step: 10
Training loss: 2.076866865158081
Validation loss: 2.120513657728831

Epoch: 6| Step: 11
Training loss: 1.4733920097351074
Validation loss: 2.115719219048818

Epoch: 6| Step: 12
Training loss: 1.8437986373901367
Validation loss: 2.0932456056276956

Epoch: 6| Step: 13
Training loss: 2.3397860527038574
Validation loss: 2.1173534393310547

Epoch: 204| Step: 0
Training loss: 1.759735345840454
Validation loss: 2.1090786457061768

Epoch: 6| Step: 1
Training loss: 2.307149887084961
Validation loss: 2.120876908302307

Epoch: 6| Step: 2
Training loss: 1.4399604797363281
Validation loss: 2.1281775633494058

Epoch: 6| Step: 3
Training loss: 1.4666829109191895
Validation loss: 2.1212673783302307

Epoch: 6| Step: 4
Training loss: 1.9101464748382568
Validation loss: 2.1314433415730796

Epoch: 6| Step: 5
Training loss: 1.4380502700805664
Validation loss: 2.1381185054779053

Epoch: 6| Step: 6
Training loss: 1.8054622411727905
Validation loss: 2.143980065981547

Epoch: 6| Step: 7
Training loss: 1.6187254190444946
Validation loss: 2.1283699671427407

Epoch: 6| Step: 8
Training loss: 2.727539539337158
Validation loss: 2.1417150298754373

Epoch: 6| Step: 9
Training loss: 2.1072309017181396
Validation loss: 2.127462903658549

Epoch: 6| Step: 10
Training loss: 1.9873571395874023
Validation loss: 2.122333804766337

Epoch: 6| Step: 11
Training loss: 1.9548664093017578
Validation loss: 2.1532140175501504

Epoch: 6| Step: 12
Training loss: 1.868300199508667
Validation loss: 2.1262718439102173

Epoch: 6| Step: 13
Training loss: 1.9663857221603394
Validation loss: 2.136813163757324

Epoch: 205| Step: 0
Training loss: 1.4732682704925537
Validation loss: 2.138293206691742

Epoch: 6| Step: 1
Training loss: 1.5983624458312988
Validation loss: 2.1086905201276145

Epoch: 6| Step: 2
Training loss: 1.8199825286865234
Validation loss: 2.1252786119778952

Epoch: 6| Step: 3
Training loss: 2.1068837642669678
Validation loss: 2.1098886132240295

Epoch: 6| Step: 4
Training loss: 1.452573299407959
Validation loss: 2.103143314520518

Epoch: 6| Step: 5
Training loss: 1.9223804473876953
Validation loss: 2.1175127824147544

Epoch: 6| Step: 6
Training loss: 2.0119004249572754
Validation loss: 2.1171760161717734

Epoch: 6| Step: 7
Training loss: 2.466355800628662
Validation loss: 2.1133094827334085

Epoch: 6| Step: 8
Training loss: 1.4226428270339966
Validation loss: 2.104860862096151

Epoch: 6| Step: 9
Training loss: 2.416747570037842
Validation loss: 2.137462596098582

Epoch: 6| Step: 10
Training loss: 1.9514516592025757
Validation loss: 2.1347362399101257

Epoch: 6| Step: 11
Training loss: 1.836986780166626
Validation loss: 2.163677136103312

Epoch: 6| Step: 12
Training loss: 2.1445059776306152
Validation loss: 2.155137300491333

Epoch: 6| Step: 13
Training loss: 1.9124083518981934
Validation loss: 2.1650492548942566

Epoch: 206| Step: 0
Training loss: 1.6989116668701172
Validation loss: 2.1520379980405173

Epoch: 6| Step: 1
Training loss: 1.726564884185791
Validation loss: 2.141078154246012

Epoch: 6| Step: 2
Training loss: 2.062460422515869
Validation loss: 2.1506611903508506

Epoch: 6| Step: 3
Training loss: 1.9292668104171753
Validation loss: 2.144394357999166

Epoch: 6| Step: 4
Training loss: 1.5780885219573975
Validation loss: 2.124399185180664

Epoch: 6| Step: 5
Training loss: 2.1853437423706055
Validation loss: 2.1305585304896035

Epoch: 6| Step: 6
Training loss: 2.0164411067962646
Validation loss: 2.145370582739512

Epoch: 6| Step: 7
Training loss: 1.8003935813903809
Validation loss: 2.1241701443990073

Epoch: 6| Step: 8
Training loss: 1.8572986125946045
Validation loss: 2.1184918880462646

Epoch: 6| Step: 9
Training loss: 2.452353000640869
Validation loss: 2.1210785508155823

Epoch: 6| Step: 10
Training loss: 1.8014966249465942
Validation loss: 2.1046868761380515

Epoch: 6| Step: 11
Training loss: 1.710754632949829
Validation loss: 2.1020119190216064

Epoch: 6| Step: 12
Training loss: 2.3671674728393555
Validation loss: 2.0950628519058228

Epoch: 6| Step: 13
Training loss: 1.6322591304779053
Validation loss: 2.1144330501556396

Epoch: 207| Step: 0
Training loss: 1.5234956741333008
Validation loss: 2.097315728664398

Epoch: 6| Step: 1
Training loss: 1.7775636911392212
Validation loss: 2.1064599752426147

Epoch: 6| Step: 2
Training loss: 1.7372831106185913
Validation loss: 2.10502419869105

Epoch: 6| Step: 3
Training loss: 2.0892112255096436
Validation loss: 2.1079797546068826

Epoch: 6| Step: 4
Training loss: 1.4851897954940796
Validation loss: 2.1057093342145285

Epoch: 6| Step: 5
Training loss: 1.8277416229248047
Validation loss: 2.105130394299825

Epoch: 6| Step: 6
Training loss: 2.254568099975586
Validation loss: 2.1119117538134256

Epoch: 6| Step: 7
Training loss: 1.504860520362854
Validation loss: 2.113373359044393

Epoch: 6| Step: 8
Training loss: 1.8133918046951294
Validation loss: 2.112476646900177

Epoch: 6| Step: 9
Training loss: 1.7799715995788574
Validation loss: 2.1133936444918313

Epoch: 6| Step: 10
Training loss: 2.601579189300537
Validation loss: 2.1035964290301004

Epoch: 6| Step: 11
Training loss: 2.422865390777588
Validation loss: 2.0917102893193564

Epoch: 6| Step: 12
Training loss: 2.3734776973724365
Validation loss: 2.113683521747589

Epoch: 6| Step: 13
Training loss: 2.108814001083374
Validation loss: 2.1122883955637612

Epoch: 208| Step: 0
Training loss: 2.289193868637085
Validation loss: 2.0982967615127563

Epoch: 6| Step: 1
Training loss: 2.035256862640381
Validation loss: 2.106711208820343

Epoch: 6| Step: 2
Training loss: 2.0576140880584717
Validation loss: 2.1171439488728843

Epoch: 6| Step: 3
Training loss: 1.441542625427246
Validation loss: 2.1018155415852866

Epoch: 6| Step: 4
Training loss: 2.506845474243164
Validation loss: 2.1044121583302817

Epoch: 6| Step: 5
Training loss: 2.0027499198913574
Validation loss: 2.126029849052429

Epoch: 6| Step: 6
Training loss: 1.3182510137557983
Validation loss: 2.120758831501007

Epoch: 6| Step: 7
Training loss: 1.4277514219284058
Validation loss: 2.129500766595205

Epoch: 6| Step: 8
Training loss: 2.489513635635376
Validation loss: 2.1244194904963174

Epoch: 6| Step: 9
Training loss: 1.5031440258026123
Validation loss: 2.12653915087382

Epoch: 6| Step: 10
Training loss: 2.018108367919922
Validation loss: 2.1180423895517984

Epoch: 6| Step: 11
Training loss: 1.3311183452606201
Validation loss: 2.112645745277405

Epoch: 6| Step: 12
Training loss: 2.2888710498809814
Validation loss: 2.137370546658834

Epoch: 6| Step: 13
Training loss: 1.787096619606018
Validation loss: 2.142107685407003

Epoch: 209| Step: 0
Training loss: 1.6213935613632202
Validation loss: 2.1444815595944724

Epoch: 6| Step: 1
Training loss: 2.057699203491211
Validation loss: 2.1399360497792563

Epoch: 6| Step: 2
Training loss: 1.5630402565002441
Validation loss: 2.14115047454834

Epoch: 6| Step: 3
Training loss: 2.1591930389404297
Validation loss: 2.15564093987147

Epoch: 6| Step: 4
Training loss: 1.4844927787780762
Validation loss: 2.1558614373207092

Epoch: 6| Step: 5
Training loss: 1.8690239191055298
Validation loss: 2.146976590156555

Epoch: 6| Step: 6
Training loss: 1.8747236728668213
Validation loss: 2.1557619174321494

Epoch: 6| Step: 7
Training loss: 2.4393513202667236
Validation loss: 2.1404343843460083

Epoch: 6| Step: 8
Training loss: 2.0653305053710938
Validation loss: 2.130379617214203

Epoch: 6| Step: 9
Training loss: 1.8584117889404297
Validation loss: 2.1562660932540894

Epoch: 6| Step: 10
Training loss: 2.4436023235321045
Validation loss: 2.152923047542572

Epoch: 6| Step: 11
Training loss: 1.577776551246643
Validation loss: 2.142155647277832

Epoch: 6| Step: 12
Training loss: 1.6928794384002686
Validation loss: 2.1364398201306662

Epoch: 6| Step: 13
Training loss: 1.6157995462417603
Validation loss: 2.122681180636088

Epoch: 210| Step: 0
Training loss: 1.4169960021972656
Validation loss: 2.1215700109799704

Epoch: 6| Step: 1
Training loss: 1.886489748954773
Validation loss: 2.1253892381985984

Epoch: 6| Step: 2
Training loss: 1.9058194160461426
Validation loss: 2.127478241920471

Epoch: 6| Step: 3
Training loss: 2.153958559036255
Validation loss: 2.113390266895294

Epoch: 6| Step: 4
Training loss: 1.8443320989608765
Validation loss: 2.142484128475189

Epoch: 6| Step: 5
Training loss: 1.6179633140563965
Validation loss: 2.1382811466852822

Epoch: 6| Step: 6
Training loss: 1.8935800790786743
Validation loss: 2.1313366095225015

Epoch: 6| Step: 7
Training loss: 1.832908272743225
Validation loss: 2.1527543663978577

Epoch: 6| Step: 8
Training loss: 1.6110303401947021
Validation loss: 2.1248724460601807

Epoch: 6| Step: 9
Training loss: 1.7182995080947876
Validation loss: 2.1229119896888733

Epoch: 6| Step: 10
Training loss: 1.224555492401123
Validation loss: 2.1185353994369507

Epoch: 6| Step: 11
Training loss: 2.515911817550659
Validation loss: 2.126802444458008

Epoch: 6| Step: 12
Training loss: 2.0245938301086426
Validation loss: 2.123113493124644

Epoch: 6| Step: 13
Training loss: 2.3489785194396973
Validation loss: 2.1149888237317405

Epoch: 211| Step: 0
Training loss: 2.000535726547241
Validation loss: 2.1190538009007773

Epoch: 6| Step: 1
Training loss: 1.9656519889831543
Validation loss: 2.117825170358022

Epoch: 6| Step: 2
Training loss: 1.4550436735153198
Validation loss: 2.109571913878123

Epoch: 6| Step: 3
Training loss: 1.9493300914764404
Validation loss: 2.119910697142283

Epoch: 6| Step: 4
Training loss: 1.4267343282699585
Validation loss: 2.1014457543691

Epoch: 6| Step: 5
Training loss: 1.2158033847808838
Validation loss: 2.107729117075602

Epoch: 6| Step: 6
Training loss: 2.5393435955047607
Validation loss: 2.120249887307485

Epoch: 6| Step: 7
Training loss: 2.033740520477295
Validation loss: 2.130305290222168

Epoch: 6| Step: 8
Training loss: 2.2126388549804688
Validation loss: 2.1120556791623435

Epoch: 6| Step: 9
Training loss: 1.2490572929382324
Validation loss: 2.12269119421641

Epoch: 6| Step: 10
Training loss: 2.5550570487976074
Validation loss: 2.1284050345420837

Epoch: 6| Step: 11
Training loss: 1.537671685218811
Validation loss: 2.134588301181793

Epoch: 6| Step: 12
Training loss: 2.4254767894744873
Validation loss: 2.1264302730560303

Epoch: 6| Step: 13
Training loss: 1.5144988298416138
Validation loss: 2.1403375267982483

Epoch: 212| Step: 0
Training loss: 2.1027109622955322
Validation loss: 2.133254647254944

Epoch: 6| Step: 1
Training loss: 2.023369073867798
Validation loss: 2.1239355007807412

Epoch: 6| Step: 2
Training loss: 1.6753616333007812
Validation loss: 2.1344196796417236

Epoch: 6| Step: 3
Training loss: 2.249540328979492
Validation loss: 2.147276997566223

Epoch: 6| Step: 4
Training loss: 2.115074634552002
Validation loss: 2.1517244974772134

Epoch: 6| Step: 5
Training loss: 1.8737993240356445
Validation loss: 2.1635080774625144

Epoch: 6| Step: 6
Training loss: 1.3836497068405151
Validation loss: 2.1554459730784097

Epoch: 6| Step: 7
Training loss: 1.7617182731628418
Validation loss: 2.1524630387624106

Epoch: 6| Step: 8
Training loss: 1.791480541229248
Validation loss: 2.159584085146586

Epoch: 6| Step: 9
Training loss: 1.409975528717041
Validation loss: 2.146089474360148

Epoch: 6| Step: 10
Training loss: 1.572312355041504
Validation loss: 2.1571277578671775

Epoch: 6| Step: 11
Training loss: 2.0773067474365234
Validation loss: 2.144120534261068

Epoch: 6| Step: 12
Training loss: 1.7395694255828857
Validation loss: 2.12660417954127

Epoch: 6| Step: 13
Training loss: 2.3923087120056152
Validation loss: 2.1265587210655212

Epoch: 213| Step: 0
Training loss: 1.9081358909606934
Validation loss: 2.118009944756826

Epoch: 6| Step: 1
Training loss: 2.1989786624908447
Validation loss: 2.1090617974599204

Epoch: 6| Step: 2
Training loss: 2.1419835090637207
Validation loss: 2.1260976592699685

Epoch: 6| Step: 3
Training loss: 1.0508713722229004
Validation loss: 2.1168280839920044

Epoch: 6| Step: 4
Training loss: 1.696732521057129
Validation loss: 2.1129061381022134

Epoch: 6| Step: 5
Training loss: 2.1357221603393555
Validation loss: 2.1215147177378335

Epoch: 6| Step: 6
Training loss: 1.985398769378662
Validation loss: 2.110921323299408

Epoch: 6| Step: 7
Training loss: 1.6519227027893066
Validation loss: 2.1173922618230185

Epoch: 6| Step: 8
Training loss: 1.9143356084823608
Validation loss: 2.109077493349711

Epoch: 6| Step: 9
Training loss: 2.5984814167022705
Validation loss: 2.1307128270467124

Epoch: 6| Step: 10
Training loss: 1.469684362411499
Validation loss: 2.1122167507807412

Epoch: 6| Step: 11
Training loss: 1.6994071006774902
Validation loss: 2.1193705797195435

Epoch: 6| Step: 12
Training loss: 1.8936114311218262
Validation loss: 2.140782674153646

Epoch: 6| Step: 13
Training loss: 1.9027780294418335
Validation loss: 2.1229864954948425

Epoch: 214| Step: 0
Training loss: 1.486700177192688
Validation loss: 2.126439332962036

Epoch: 6| Step: 1
Training loss: 1.8526384830474854
Validation loss: 2.137108246485392

Epoch: 6| Step: 2
Training loss: 2.2769229412078857
Validation loss: 2.1482867201169333

Epoch: 6| Step: 3
Training loss: 2.1153886318206787
Validation loss: 2.1507034301757812

Epoch: 6| Step: 4
Training loss: 1.5704654455184937
Validation loss: 2.181173006693522

Epoch: 6| Step: 5
Training loss: 2.149172782897949
Validation loss: 2.1705744862556458

Epoch: 6| Step: 6
Training loss: 1.8919402360916138
Validation loss: 2.1611998677253723

Epoch: 6| Step: 7
Training loss: 1.9432475566864014
Validation loss: 2.1550041834513345

Epoch: 6| Step: 8
Training loss: 1.843078374862671
Validation loss: 2.151727537314097

Epoch: 6| Step: 9
Training loss: 2.1324892044067383
Validation loss: 2.123902221520742

Epoch: 6| Step: 10
Training loss: 1.8750016689300537
Validation loss: 2.1252829829851785

Epoch: 6| Step: 11
Training loss: 1.539855718612671
Validation loss: 2.125702977180481

Epoch: 6| Step: 12
Training loss: 1.2293134927749634
Validation loss: 2.1282269954681396

Epoch: 6| Step: 13
Training loss: 2.030764102935791
Validation loss: 2.123668611049652

Epoch: 215| Step: 0
Training loss: 1.785423994064331
Validation loss: 2.1378246545791626

Epoch: 6| Step: 1
Training loss: 1.5766311883926392
Validation loss: 2.136822243531545

Epoch: 6| Step: 2
Training loss: 1.649902105331421
Validation loss: 2.1508613427480063

Epoch: 6| Step: 3
Training loss: 1.7652459144592285
Validation loss: 2.1693439881006875

Epoch: 6| Step: 4
Training loss: 2.5426478385925293
Validation loss: 2.1778990825017295

Epoch: 6| Step: 5
Training loss: 1.894872784614563
Validation loss: 2.164681553840637

Epoch: 6| Step: 6
Training loss: 1.496065616607666
Validation loss: 2.1644822557767234

Epoch: 6| Step: 7
Training loss: 1.9991226196289062
Validation loss: 2.172801971435547

Epoch: 6| Step: 8
Training loss: 1.7001004219055176
Validation loss: 2.1636447310447693

Epoch: 6| Step: 9
Training loss: 2.1963887214660645
Validation loss: 2.1722036798795066

Epoch: 6| Step: 10
Training loss: 1.911611795425415
Validation loss: 2.1555571953455606

Epoch: 6| Step: 11
Training loss: 1.27003812789917
Validation loss: 2.1222919821739197

Epoch: 6| Step: 12
Training loss: 1.5012781620025635
Validation loss: 2.1421881318092346

Epoch: 6| Step: 13
Training loss: 2.6402134895324707
Validation loss: 2.1213648120562234

Epoch: 216| Step: 0
Training loss: 1.6716866493225098
Validation loss: 2.1098493138949075

Epoch: 6| Step: 1
Training loss: 1.7220606803894043
Validation loss: 2.1358712712923684

Epoch: 6| Step: 2
Training loss: 1.7547831535339355
Validation loss: 2.1394986510276794

Epoch: 6| Step: 3
Training loss: 1.7644274234771729
Validation loss: 2.13182665904363

Epoch: 6| Step: 4
Training loss: 1.7752931118011475
Validation loss: 2.13450292746226

Epoch: 6| Step: 5
Training loss: 2.1632609367370605
Validation loss: 2.1576265692710876

Epoch: 6| Step: 6
Training loss: 1.7834285497665405
Validation loss: 2.1464398900667825

Epoch: 6| Step: 7
Training loss: 2.4021451473236084
Validation loss: 2.1571754217147827

Epoch: 6| Step: 8
Training loss: 1.4490225315093994
Validation loss: 2.115646024545034

Epoch: 6| Step: 9
Training loss: 1.986830711364746
Validation loss: 2.123893598715464

Epoch: 6| Step: 10
Training loss: 2.525583505630493
Validation loss: 2.1166502237319946

Epoch: 6| Step: 11
Training loss: 1.5322511196136475
Validation loss: 2.127361297607422

Epoch: 6| Step: 12
Training loss: 1.3880767822265625
Validation loss: 2.1274014115333557

Epoch: 6| Step: 13
Training loss: 1.895376443862915
Validation loss: 2.137186328570048

Epoch: 217| Step: 0
Training loss: 2.125574827194214
Validation loss: 2.1268142660458884

Epoch: 6| Step: 1
Training loss: 2.2201879024505615
Validation loss: 2.132389545440674

Epoch: 6| Step: 2
Training loss: 1.6207892894744873
Validation loss: 2.1588168342908225

Epoch: 6| Step: 3
Training loss: 1.4925262928009033
Validation loss: 2.1595412294069924

Epoch: 6| Step: 4
Training loss: 1.629723310470581
Validation loss: 2.1668097575505576

Epoch: 6| Step: 5
Training loss: 1.4557626247406006
Validation loss: 2.1437726616859436

Epoch: 6| Step: 6
Training loss: 1.6706502437591553
Validation loss: 2.139515479405721

Epoch: 6| Step: 7
Training loss: 1.7213517427444458
Validation loss: 2.1265107790629068

Epoch: 6| Step: 8
Training loss: 2.1011292934417725
Validation loss: 2.14327480395635

Epoch: 6| Step: 9
Training loss: 2.396493434906006
Validation loss: 2.134530166784922

Epoch: 6| Step: 10
Training loss: 1.7971893548965454
Validation loss: 2.1396135290463767

Epoch: 6| Step: 11
Training loss: 1.7774741649627686
Validation loss: 2.1326403617858887

Epoch: 6| Step: 12
Training loss: 1.8388311862945557
Validation loss: 2.122913360595703

Epoch: 6| Step: 13
Training loss: 1.825976848602295
Validation loss: 2.1365507443745932

Epoch: 218| Step: 0
Training loss: 2.1279916763305664
Validation loss: 2.1289899150530496

Epoch: 6| Step: 1
Training loss: 1.8481582403182983
Validation loss: 2.1526865363121033

Epoch: 6| Step: 2
Training loss: 2.4060306549072266
Validation loss: 2.127388616402944

Epoch: 6| Step: 3
Training loss: 1.1451598405838013
Validation loss: 2.1555585861206055

Epoch: 6| Step: 4
Training loss: 1.856507420539856
Validation loss: 2.1523310343424478

Epoch: 6| Step: 5
Training loss: 1.6208555698394775
Validation loss: 2.14992884794871

Epoch: 6| Step: 6
Training loss: 1.7985177040100098
Validation loss: 2.149685581525167

Epoch: 6| Step: 7
Training loss: 1.730660080909729
Validation loss: 2.1310999393463135

Epoch: 6| Step: 8
Training loss: 2.2424943447113037
Validation loss: 2.1145957112312317

Epoch: 6| Step: 9
Training loss: 1.811850666999817
Validation loss: 2.1109800140062966

Epoch: 6| Step: 10
Training loss: 2.014174222946167
Validation loss: 2.100381910800934

Epoch: 6| Step: 11
Training loss: 2.2313127517700195
Validation loss: 2.1152763764063516

Epoch: 6| Step: 12
Training loss: 1.5794990062713623
Validation loss: 2.098538815975189

Epoch: 6| Step: 13
Training loss: 1.869020700454712
Validation loss: 2.1051757534344993

Epoch: 219| Step: 0
Training loss: 2.1088740825653076
Validation loss: 2.1258048017819724

Epoch: 6| Step: 1
Training loss: 1.4476165771484375
Validation loss: 2.1401021480560303

Epoch: 6| Step: 2
Training loss: 1.714667797088623
Validation loss: 2.151122788588206

Epoch: 6| Step: 3
Training loss: 1.6730546951293945
Validation loss: 2.1570443709691367

Epoch: 6| Step: 4
Training loss: 2.1997971534729004
Validation loss: 2.1852882703145347

Epoch: 6| Step: 5
Training loss: 1.4571633338928223
Validation loss: 2.1535377303759256

Epoch: 6| Step: 6
Training loss: 1.6208581924438477
Validation loss: 2.166095038255056

Epoch: 6| Step: 7
Training loss: 2.5143818855285645
Validation loss: 2.172182778517405

Epoch: 6| Step: 8
Training loss: 2.23496150970459
Validation loss: 2.1731456518173218

Epoch: 6| Step: 9
Training loss: 1.3144242763519287
Validation loss: 2.150365670522054

Epoch: 6| Step: 10
Training loss: 1.9171967506408691
Validation loss: 2.115131378173828

Epoch: 6| Step: 11
Training loss: 2.158287525177002
Validation loss: 2.1254263321558633

Epoch: 6| Step: 12
Training loss: 2.189793109893799
Validation loss: 2.107958118120829

Epoch: 6| Step: 13
Training loss: 1.5233694314956665
Validation loss: 2.111521522204081

Epoch: 220| Step: 0
Training loss: 1.6653170585632324
Validation loss: 2.0947203040122986

Epoch: 6| Step: 1
Training loss: 1.6803950071334839
Validation loss: 2.0795801281929016

Epoch: 6| Step: 2
Training loss: 2.0277140140533447
Validation loss: 2.096183975537618

Epoch: 6| Step: 3
Training loss: 2.1191225051879883
Validation loss: 2.0988550384839377

Epoch: 6| Step: 4
Training loss: 1.668205738067627
Validation loss: 2.092598040898641

Epoch: 6| Step: 5
Training loss: 2.4878182411193848
Validation loss: 2.1114028096199036

Epoch: 6| Step: 6
Training loss: 2.3291125297546387
Validation loss: 2.1065953175226846

Epoch: 6| Step: 7
Training loss: 1.6922588348388672
Validation loss: 2.109172542889913

Epoch: 6| Step: 8
Training loss: 1.9115819931030273
Validation loss: 2.1144596536954245

Epoch: 6| Step: 9
Training loss: 1.4158517122268677
Validation loss: 2.110249181588491

Epoch: 6| Step: 10
Training loss: 1.945613145828247
Validation loss: 2.1004718939463296

Epoch: 6| Step: 11
Training loss: 1.5471079349517822
Validation loss: 2.1197288632392883

Epoch: 6| Step: 12
Training loss: 2.201418161392212
Validation loss: 2.13966304063797

Epoch: 6| Step: 13
Training loss: 2.0504884719848633
Validation loss: 2.1525936325391135

Epoch: 221| Step: 0
Training loss: 2.0738067626953125
Validation loss: 2.1529967387517295

Epoch: 6| Step: 1
Training loss: 2.266550302505493
Validation loss: 2.168524165948232

Epoch: 6| Step: 2
Training loss: 2.0792746543884277
Validation loss: 2.1635668873786926

Epoch: 6| Step: 3
Training loss: 1.3660078048706055
Validation loss: 2.152990400791168

Epoch: 6| Step: 4
Training loss: 2.0574936866760254
Validation loss: 2.169608771800995

Epoch: 6| Step: 5
Training loss: 1.978977918624878
Validation loss: 2.1678734620412192

Epoch: 6| Step: 6
Training loss: 1.407342791557312
Validation loss: 2.144498368104299

Epoch: 6| Step: 7
Training loss: 2.1484122276306152
Validation loss: 2.133631467819214

Epoch: 6| Step: 8
Training loss: 1.9863625764846802
Validation loss: 2.1301251451174417

Epoch: 6| Step: 9
Training loss: 1.9181556701660156
Validation loss: 2.125761071840922

Epoch: 6| Step: 10
Training loss: 2.428006649017334
Validation loss: 2.1191741228103638

Epoch: 6| Step: 11
Training loss: 1.6384884119033813
Validation loss: 2.1291941006978354

Epoch: 6| Step: 12
Training loss: 1.456005573272705
Validation loss: 2.1286402344703674

Epoch: 6| Step: 13
Training loss: 2.047950267791748
Validation loss: 2.111325820287069

Epoch: 222| Step: 0
Training loss: 1.2003111839294434
Validation loss: 2.122807721296946

Epoch: 6| Step: 1
Training loss: 2.353294610977173
Validation loss: 2.1136953830718994

Epoch: 6| Step: 2
Training loss: 1.5698206424713135
Validation loss: 2.1368351181348166

Epoch: 6| Step: 3
Training loss: 1.8799046277999878
Validation loss: 2.1215708255767822

Epoch: 6| Step: 4
Training loss: 1.9157289266586304
Validation loss: 2.126614530881246

Epoch: 6| Step: 5
Training loss: 1.6142796277999878
Validation loss: 2.1449214220046997

Epoch: 6| Step: 6
Training loss: 1.8673454523086548
Validation loss: 2.146860102812449

Epoch: 6| Step: 7
Training loss: 2.3873157501220703
Validation loss: 2.1542179584503174

Epoch: 6| Step: 8
Training loss: 1.8644795417785645
Validation loss: 2.1377329428990683

Epoch: 6| Step: 9
Training loss: 1.8154276609420776
Validation loss: 2.1518051425615945

Epoch: 6| Step: 10
Training loss: 2.0581250190734863
Validation loss: 2.139126181602478

Epoch: 6| Step: 11
Training loss: 1.6781044006347656
Validation loss: 2.147336264451345

Epoch: 6| Step: 12
Training loss: 1.5179485082626343
Validation loss: 2.1566260059674582

Epoch: 6| Step: 13
Training loss: 1.923654556274414
Validation loss: 2.1628369291623435

Epoch: 223| Step: 0
Training loss: 1.4544734954833984
Validation loss: 2.1565174659093223

Epoch: 6| Step: 1
Training loss: 1.3764504194259644
Validation loss: 2.1642441749572754

Epoch: 6| Step: 2
Training loss: 1.6850969791412354
Validation loss: 2.161497096220652

Epoch: 6| Step: 3
Training loss: 2.4895482063293457
Validation loss: 2.1443698008855185

Epoch: 6| Step: 4
Training loss: 2.1686904430389404
Validation loss: 2.1460912426312766

Epoch: 6| Step: 5
Training loss: 1.978020429611206
Validation loss: 2.149700959523519

Epoch: 6| Step: 6
Training loss: 1.4412310123443604
Validation loss: 2.153839866320292

Epoch: 6| Step: 7
Training loss: 1.6319332122802734
Validation loss: 2.152251879374186

Epoch: 6| Step: 8
Training loss: 1.9346565008163452
Validation loss: 2.129169782002767

Epoch: 6| Step: 9
Training loss: 2.0588126182556152
Validation loss: 2.1537148356437683

Epoch: 6| Step: 10
Training loss: 1.1725143194198608
Validation loss: 2.1268898049990335

Epoch: 6| Step: 11
Training loss: 2.1801364421844482
Validation loss: 2.1381721099217734

Epoch: 6| Step: 12
Training loss: 1.9051640033721924
Validation loss: 2.1387779116630554

Epoch: 6| Step: 13
Training loss: 1.893408179283142
Validation loss: 2.115164816379547

Epoch: 224| Step: 0
Training loss: 2.365339756011963
Validation loss: 2.122406860192617

Epoch: 6| Step: 1
Training loss: 1.6697359085083008
Validation loss: 2.148231645425161

Epoch: 6| Step: 2
Training loss: 1.4648091793060303
Validation loss: 2.1230740944544473

Epoch: 6| Step: 3
Training loss: 2.087064027786255
Validation loss: 2.1229966481526694

Epoch: 6| Step: 4
Training loss: 1.0644298791885376
Validation loss: 2.11442502339681

Epoch: 6| Step: 5
Training loss: 1.9707012176513672
Validation loss: 2.124977687994639

Epoch: 6| Step: 6
Training loss: 2.451545000076294
Validation loss: 2.1577125191688538

Epoch: 6| Step: 7
Training loss: 1.5712339878082275
Validation loss: 2.149084508419037

Epoch: 6| Step: 8
Training loss: 2.5228419303894043
Validation loss: 2.158275922139486

Epoch: 6| Step: 9
Training loss: 2.2314155101776123
Validation loss: 2.158791263898214

Epoch: 6| Step: 10
Training loss: 1.2668620347976685
Validation loss: 2.1657036741574607

Epoch: 6| Step: 11
Training loss: 1.0374319553375244
Validation loss: 2.140249749024709

Epoch: 6| Step: 12
Training loss: 1.5167515277862549
Validation loss: 2.1432294845581055

Epoch: 6| Step: 13
Training loss: 2.0091567039489746
Validation loss: 2.1216655572255454

Epoch: 225| Step: 0
Training loss: 1.248066782951355
Validation loss: 2.141808867454529

Epoch: 6| Step: 1
Training loss: 2.2909739017486572
Validation loss: 2.1115935643514

Epoch: 6| Step: 2
Training loss: 1.7959860563278198
Validation loss: 2.1160555879275003

Epoch: 6| Step: 3
Training loss: 1.7487215995788574
Validation loss: 2.112536668777466

Epoch: 6| Step: 4
Training loss: 1.9119796752929688
Validation loss: 2.1398442586263022

Epoch: 6| Step: 5
Training loss: 1.7929296493530273
Validation loss: 2.1362329721450806

Epoch: 6| Step: 6
Training loss: 1.5624380111694336
Validation loss: 2.1474865476290383

Epoch: 6| Step: 7
Training loss: 1.5030887126922607
Validation loss: 2.1291468342145285

Epoch: 6| Step: 8
Training loss: 2.0772218704223633
Validation loss: 2.1440319418907166

Epoch: 6| Step: 9
Training loss: 2.0569281578063965
Validation loss: 2.1575109561284385

Epoch: 6| Step: 10
Training loss: 1.7064387798309326
Validation loss: 2.160350501537323

Epoch: 6| Step: 11
Training loss: 1.5479097366333008
Validation loss: 2.1371235052744546

Epoch: 6| Step: 12
Training loss: 2.241293430328369
Validation loss: 2.13815567890803

Epoch: 6| Step: 13
Training loss: 1.5255330801010132
Validation loss: 2.144759198029836

Epoch: 226| Step: 0
Training loss: 2.1700592041015625
Validation loss: 2.1170421640078225

Epoch: 6| Step: 1
Training loss: 1.825393795967102
Validation loss: 2.1256433924039206

Epoch: 6| Step: 2
Training loss: 1.991804838180542
Validation loss: 2.1168154875437417

Epoch: 6| Step: 3
Training loss: 1.4438810348510742
Validation loss: 2.1223997672398887

Epoch: 6| Step: 4
Training loss: 1.8523359298706055
Validation loss: 2.1288350423177085

Epoch: 6| Step: 5
Training loss: 1.5846258401870728
Validation loss: 2.100383202234904

Epoch: 6| Step: 6
Training loss: 1.7984986305236816
Validation loss: 2.113505482673645

Epoch: 6| Step: 7
Training loss: 1.4895683526992798
Validation loss: 2.1005505522092185

Epoch: 6| Step: 8
Training loss: 2.2563724517822266
Validation loss: 2.1038742065429688

Epoch: 6| Step: 9
Training loss: 1.2822942733764648
Validation loss: 2.103573759396871

Epoch: 6| Step: 10
Training loss: 1.580148696899414
Validation loss: 2.1218063036600747

Epoch: 6| Step: 11
Training loss: 1.9608361721038818
Validation loss: 2.1146554152170816

Epoch: 6| Step: 12
Training loss: 1.8683665990829468
Validation loss: 2.117810229460398

Epoch: 6| Step: 13
Training loss: 2.1784820556640625
Validation loss: 2.1310513814290366

Epoch: 227| Step: 0
Training loss: 2.6873908042907715
Validation loss: 2.1300926407178244

Epoch: 6| Step: 1
Training loss: 1.4835044145584106
Validation loss: 2.125083267688751

Epoch: 6| Step: 2
Training loss: 2.057929515838623
Validation loss: 2.1197525461514792

Epoch: 6| Step: 3
Training loss: 1.2834560871124268
Validation loss: 2.118075966835022

Epoch: 6| Step: 4
Training loss: 1.7516939640045166
Validation loss: 2.1314309438069663

Epoch: 6| Step: 5
Training loss: 2.578874111175537
Validation loss: 2.120768109957377

Epoch: 6| Step: 6
Training loss: 1.35477614402771
Validation loss: 2.122562130292257

Epoch: 6| Step: 7
Training loss: 1.7653275728225708
Validation loss: 2.1208781599998474

Epoch: 6| Step: 8
Training loss: 1.4130219221115112
Validation loss: 2.1184167861938477

Epoch: 6| Step: 9
Training loss: 1.880807876586914
Validation loss: 2.1060200929641724

Epoch: 6| Step: 10
Training loss: 1.5415127277374268
Validation loss: 2.1274505654970803

Epoch: 6| Step: 11
Training loss: 1.587030291557312
Validation loss: 2.1297810475031533

Epoch: 6| Step: 12
Training loss: 1.624167561531067
Validation loss: 2.1178001165390015

Epoch: 6| Step: 13
Training loss: 2.0559096336364746
Validation loss: 2.12559445699056

Epoch: 228| Step: 0
Training loss: 2.1127800941467285
Validation loss: 2.1182005802790322

Epoch: 6| Step: 1
Training loss: 2.065976858139038
Validation loss: 2.134637395540873

Epoch: 6| Step: 2
Training loss: 1.7501883506774902
Validation loss: 2.137947062651316

Epoch: 6| Step: 3
Training loss: 1.7544037103652954
Validation loss: 2.1387948195139566

Epoch: 6| Step: 4
Training loss: 1.4352314472198486
Validation loss: 2.1052269538243613

Epoch: 6| Step: 5
Training loss: 2.464374542236328
Validation loss: 2.1167616844177246

Epoch: 6| Step: 6
Training loss: 1.2510398626327515
Validation loss: 2.128382980823517

Epoch: 6| Step: 7
Training loss: 1.7150437831878662
Validation loss: 2.12481822570165

Epoch: 6| Step: 8
Training loss: 2.157947540283203
Validation loss: 2.115183154741923

Epoch: 6| Step: 9
Training loss: 1.7103394269943237
Validation loss: 2.127380927403768

Epoch: 6| Step: 10
Training loss: 1.582262396812439
Validation loss: 2.1180056730906167

Epoch: 6| Step: 11
Training loss: 1.945157527923584
Validation loss: 2.1434390942255654

Epoch: 6| Step: 12
Training loss: 1.5550873279571533
Validation loss: 2.117532471815745

Epoch: 6| Step: 13
Training loss: 1.6947637796401978
Validation loss: 2.1382469137509665

Epoch: 229| Step: 0
Training loss: 1.6327062845230103
Validation loss: 2.1583629846572876

Epoch: 6| Step: 1
Training loss: 1.8540788888931274
Validation loss: 2.155406415462494

Epoch: 6| Step: 2
Training loss: 1.943145990371704
Validation loss: 2.170499642690023

Epoch: 6| Step: 3
Training loss: 1.2807884216308594
Validation loss: 2.1747872034708657

Epoch: 6| Step: 4
Training loss: 1.8755378723144531
Validation loss: 2.1532869140307107

Epoch: 6| Step: 5
Training loss: 1.457524299621582
Validation loss: 2.1457163294156394

Epoch: 6| Step: 6
Training loss: 1.4342155456542969
Validation loss: 2.1515366633733115

Epoch: 6| Step: 7
Training loss: 1.9538556337356567
Validation loss: 2.1404104431470237

Epoch: 6| Step: 8
Training loss: 1.5935611724853516
Validation loss: 2.1332318981488547

Epoch: 6| Step: 9
Training loss: 2.9685497283935547
Validation loss: 2.1282254656155906

Epoch: 6| Step: 10
Training loss: 2.189021587371826
Validation loss: 2.1516517400741577

Epoch: 6| Step: 11
Training loss: 1.7150007486343384
Validation loss: 2.1314677000045776

Epoch: 6| Step: 12
Training loss: 1.7526490688323975
Validation loss: 2.1410248478253684

Epoch: 6| Step: 13
Training loss: 1.8767929077148438
Validation loss: 2.1299850742022195

Epoch: 230| Step: 0
Training loss: 1.5641419887542725
Validation loss: 2.141686201095581

Epoch: 6| Step: 1
Training loss: 1.9000539779663086
Validation loss: 2.13704381386439

Epoch: 6| Step: 2
Training loss: 2.237729072570801
Validation loss: 2.159811715284983

Epoch: 6| Step: 3
Training loss: 2.501112222671509
Validation loss: 2.1509638826052346

Epoch: 6| Step: 4
Training loss: 1.873067021369934
Validation loss: 2.1716349124908447

Epoch: 6| Step: 5
Training loss: 1.9463725090026855
Validation loss: 2.1742449601491294

Epoch: 6| Step: 6
Training loss: 1.1559338569641113
Validation loss: 2.1715839902559915

Epoch: 6| Step: 7
Training loss: 1.7532564401626587
Validation loss: 2.1541385650634766

Epoch: 6| Step: 8
Training loss: 0.9740365743637085
Validation loss: 2.125411073366801

Epoch: 6| Step: 9
Training loss: 2.268887519836426
Validation loss: 2.1330443223317466

Epoch: 6| Step: 10
Training loss: 2.228147506713867
Validation loss: 2.0971603790918985

Epoch: 6| Step: 11
Training loss: 1.4558165073394775
Validation loss: 2.107597589492798

Epoch: 6| Step: 12
Training loss: 2.0272350311279297
Validation loss: 2.103522559007009

Epoch: 6| Step: 13
Training loss: 1.6473333835601807
Validation loss: 2.113958696524302

Epoch: 231| Step: 0
Training loss: 2.162832260131836
Validation loss: 2.097962280114492

Epoch: 6| Step: 1
Training loss: 1.6879183053970337
Validation loss: 2.1024845838546753

Epoch: 6| Step: 2
Training loss: 1.5490115880966187
Validation loss: 2.1000447273254395

Epoch: 6| Step: 3
Training loss: 1.65488862991333
Validation loss: 2.1119433442751565

Epoch: 6| Step: 4
Training loss: 1.458716869354248
Validation loss: 2.1275871992111206

Epoch: 6| Step: 5
Training loss: 1.9869478940963745
Validation loss: 2.130006512006124

Epoch: 6| Step: 6
Training loss: 1.5018889904022217
Validation loss: 2.158446451028188

Epoch: 6| Step: 7
Training loss: 1.9581103324890137
Validation loss: 2.172620177268982

Epoch: 6| Step: 8
Training loss: 1.7036411762237549
Validation loss: 2.1715561548868814

Epoch: 6| Step: 9
Training loss: 2.4109339714050293
Validation loss: 2.142816424369812

Epoch: 6| Step: 10
Training loss: 1.345249056816101
Validation loss: 2.1237272222836814

Epoch: 6| Step: 11
Training loss: 2.8881025314331055
Validation loss: 2.1389249761899314

Epoch: 6| Step: 12
Training loss: 1.7694787979125977
Validation loss: 2.1149794459342957

Epoch: 6| Step: 13
Training loss: 1.9800810813903809
Validation loss: 2.1034842332204184

Epoch: 232| Step: 0
Training loss: 1.5750007629394531
Validation loss: 2.1162590980529785

Epoch: 6| Step: 1
Training loss: 1.820065975189209
Validation loss: 2.130811333656311

Epoch: 6| Step: 2
Training loss: 1.4927220344543457
Validation loss: 2.128561099370321

Epoch: 6| Step: 3
Training loss: 1.1344025135040283
Validation loss: 2.1286497116088867

Epoch: 6| Step: 4
Training loss: 2.4417786598205566
Validation loss: 2.1373204390207925

Epoch: 6| Step: 5
Training loss: 2.813842296600342
Validation loss: 2.128419498602549

Epoch: 6| Step: 6
Training loss: 1.8236236572265625
Validation loss: 2.1196823517481485

Epoch: 6| Step: 7
Training loss: 1.3742928504943848
Validation loss: 2.1232253313064575

Epoch: 6| Step: 8
Training loss: 1.6984813213348389
Validation loss: 2.1139806310335794

Epoch: 6| Step: 9
Training loss: 1.16896390914917
Validation loss: 2.1178794503211975

Epoch: 6| Step: 10
Training loss: 1.301435947418213
Validation loss: 2.131528993447622

Epoch: 6| Step: 11
Training loss: 2.017634391784668
Validation loss: 2.128846208254496

Epoch: 6| Step: 12
Training loss: 2.260420560836792
Validation loss: 2.1395798921585083

Epoch: 6| Step: 13
Training loss: 2.1190309524536133
Validation loss: 2.134376049041748

Epoch: 233| Step: 0
Training loss: 1.1271955966949463
Validation loss: 2.1476688782374063

Epoch: 6| Step: 1
Training loss: 1.9990289211273193
Validation loss: 2.1202319661776223

Epoch: 6| Step: 2
Training loss: 1.5181480646133423
Validation loss: 2.130429685115814

Epoch: 6| Step: 3
Training loss: 1.7122538089752197
Validation loss: 2.1220392982165017

Epoch: 6| Step: 4
Training loss: 1.8873748779296875
Validation loss: 2.1119988163312278

Epoch: 6| Step: 5
Training loss: 2.278918743133545
Validation loss: 2.135787089665731

Epoch: 6| Step: 6
Training loss: 1.2506682872772217
Validation loss: 2.127607266108195

Epoch: 6| Step: 7
Training loss: 2.1933753490448
Validation loss: 2.1484032471974692

Epoch: 6| Step: 8
Training loss: 1.5985832214355469
Validation loss: 2.137886941432953

Epoch: 6| Step: 9
Training loss: 1.4924055337905884
Validation loss: 2.141627331574758

Epoch: 6| Step: 10
Training loss: 1.9228248596191406
Validation loss: 2.1493095755577087

Epoch: 6| Step: 11
Training loss: 2.542994499206543
Validation loss: 2.1729111671447754

Epoch: 6| Step: 12
Training loss: 1.466686487197876
Validation loss: 2.1516526142756143

Epoch: 6| Step: 13
Training loss: 1.7765755653381348
Validation loss: 2.1463884512583413

Epoch: 234| Step: 0
Training loss: 1.5077747106552124
Validation loss: 2.1739822228749595

Epoch: 6| Step: 1
Training loss: 1.5354087352752686
Validation loss: 2.1860945423444114

Epoch: 6| Step: 2
Training loss: 1.8332891464233398
Validation loss: 2.1697123845418296

Epoch: 6| Step: 3
Training loss: 1.6008479595184326
Validation loss: 2.177027483781179

Epoch: 6| Step: 4
Training loss: 2.349215507507324
Validation loss: 2.1779887278874717

Epoch: 6| Step: 5
Training loss: 2.250950336456299
Validation loss: 2.194206794102987

Epoch: 6| Step: 6
Training loss: 1.2208168506622314
Validation loss: 2.173896392186483

Epoch: 6| Step: 7
Training loss: 1.0796833038330078
Validation loss: 2.1827552119890847

Epoch: 6| Step: 8
Training loss: 1.8185392618179321
Validation loss: 2.171197215716044

Epoch: 6| Step: 9
Training loss: 2.1088242530822754
Validation loss: 2.1414748231569924

Epoch: 6| Step: 10
Training loss: 1.409641146659851
Validation loss: 2.1489458282788596

Epoch: 6| Step: 11
Training loss: 1.966198444366455
Validation loss: 2.149950683116913

Epoch: 6| Step: 12
Training loss: 2.1327905654907227
Validation loss: 2.1538376013437905

Epoch: 6| Step: 13
Training loss: 1.8568296432495117
Validation loss: 2.1468452413876853

Epoch: 235| Step: 0
Training loss: 1.7273226976394653
Validation loss: 2.137849966684977

Epoch: 6| Step: 1
Training loss: 1.633486032485962
Validation loss: 2.142502725124359

Epoch: 6| Step: 2
Training loss: 1.7286248207092285
Validation loss: 2.1509360472361245

Epoch: 6| Step: 3
Training loss: 1.9067010879516602
Validation loss: 2.126068035761515

Epoch: 6| Step: 4
Training loss: 1.4311683177947998
Validation loss: 2.1522973775863647

Epoch: 6| Step: 5
Training loss: 2.1948752403259277
Validation loss: 2.1768642465273538

Epoch: 6| Step: 6
Training loss: 1.8014018535614014
Validation loss: 2.1626460949579873

Epoch: 6| Step: 7
Training loss: 1.7757186889648438
Validation loss: 2.175376534461975

Epoch: 6| Step: 8
Training loss: 1.8845266103744507
Validation loss: 2.1706067323684692

Epoch: 6| Step: 9
Training loss: 1.9143562316894531
Validation loss: 2.1446481545766196

Epoch: 6| Step: 10
Training loss: 1.8083256483078003
Validation loss: 2.1660985549290976

Epoch: 6| Step: 11
Training loss: 1.629987359046936
Validation loss: 2.1252909898757935

Epoch: 6| Step: 12
Training loss: 1.5219810009002686
Validation loss: 2.130602320035299

Epoch: 6| Step: 13
Training loss: 1.6317851543426514
Validation loss: 2.1425673564275107

Epoch: 236| Step: 0
Training loss: 1.7344149351119995
Validation loss: 2.114718437194824

Epoch: 6| Step: 1
Training loss: 1.7436518669128418
Validation loss: 2.1427921851476035

Epoch: 6| Step: 2
Training loss: 1.4175782203674316
Validation loss: 2.1384360988934836

Epoch: 6| Step: 3
Training loss: 1.216764211654663
Validation loss: 2.171297311782837

Epoch: 6| Step: 4
Training loss: 1.0663697719573975
Validation loss: 2.1416715383529663

Epoch: 6| Step: 5
Training loss: 1.9602887630462646
Validation loss: 2.148680051167806

Epoch: 6| Step: 6
Training loss: 1.7190455198287964
Validation loss: 2.1463879148165383

Epoch: 6| Step: 7
Training loss: 1.8215715885162354
Validation loss: 2.139664590358734

Epoch: 6| Step: 8
Training loss: 2.200179100036621
Validation loss: 2.1444687843322754

Epoch: 6| Step: 9
Training loss: 2.2303950786590576
Validation loss: 2.1360214948654175

Epoch: 6| Step: 10
Training loss: 1.4720330238342285
Validation loss: 2.100462257862091

Epoch: 6| Step: 11
Training loss: 1.9218132495880127
Validation loss: 2.119203488032023

Epoch: 6| Step: 12
Training loss: 1.9172698259353638
Validation loss: 2.1249837478001914

Epoch: 6| Step: 13
Training loss: 2.128897190093994
Validation loss: 2.129606783390045

Epoch: 237| Step: 0
Training loss: 1.7121641635894775
Validation loss: 2.1239568988482156

Epoch: 6| Step: 1
Training loss: 1.0384339094161987
Validation loss: 2.1350468595822654

Epoch: 6| Step: 2
Training loss: 2.105947494506836
Validation loss: 2.107608358065287

Epoch: 6| Step: 3
Training loss: 1.1133711338043213
Validation loss: 2.1324103673299155

Epoch: 6| Step: 4
Training loss: 1.4236063957214355
Validation loss: 2.130046526590983

Epoch: 6| Step: 5
Training loss: 2.396669387817383
Validation loss: 2.1392275293668113

Epoch: 6| Step: 6
Training loss: 1.8223731517791748
Validation loss: 2.1357895930608115

Epoch: 6| Step: 7
Training loss: 1.8397876024246216
Validation loss: 2.12566214799881

Epoch: 6| Step: 8
Training loss: 1.1347864866256714
Validation loss: 2.117055078347524

Epoch: 6| Step: 9
Training loss: 3.078531265258789
Validation loss: 2.130896429220835

Epoch: 6| Step: 10
Training loss: 1.5790225267410278
Validation loss: 2.1434481342633567

Epoch: 6| Step: 11
Training loss: 1.3144631385803223
Validation loss: 2.1445513367652893

Epoch: 6| Step: 12
Training loss: 2.104015350341797
Validation loss: 2.1613194942474365

Epoch: 6| Step: 13
Training loss: 1.7587108612060547
Validation loss: 2.1589993834495544

Epoch: 238| Step: 0
Training loss: 1.3887975215911865
Validation loss: 2.1644545793533325

Epoch: 6| Step: 1
Training loss: 2.2474985122680664
Validation loss: 2.1503833731015525

Epoch: 6| Step: 2
Training loss: 1.4403990507125854
Validation loss: 2.1453600327173867

Epoch: 6| Step: 3
Training loss: 1.5127339363098145
Validation loss: 2.1320045789082847

Epoch: 6| Step: 4
Training loss: 1.9091368913650513
Validation loss: 2.128824750582377

Epoch: 6| Step: 5
Training loss: 1.8559677600860596
Validation loss: 2.138800402482351

Epoch: 6| Step: 6
Training loss: 1.1333587169647217
Validation loss: 2.120083967844645

Epoch: 6| Step: 7
Training loss: 1.8233150243759155
Validation loss: 2.115657647450765

Epoch: 6| Step: 8
Training loss: 1.4818260669708252
Validation loss: 2.125565489133199

Epoch: 6| Step: 9
Training loss: 1.6850688457489014
Validation loss: 2.1263086795806885

Epoch: 6| Step: 10
Training loss: 1.5304341316223145
Validation loss: 2.134924610455831

Epoch: 6| Step: 11
Training loss: 2.4488778114318848
Validation loss: 2.139101227124532

Epoch: 6| Step: 12
Training loss: 1.7272560596466064
Validation loss: 2.149872879187266

Epoch: 6| Step: 13
Training loss: 2.1371946334838867
Validation loss: 2.1457207401593528

Epoch: 239| Step: 0
Training loss: 1.8088239431381226
Validation loss: 2.1505564053853354

Epoch: 6| Step: 1
Training loss: 2.257582664489746
Validation loss: 2.15438441435496

Epoch: 6| Step: 2
Training loss: 1.2141692638397217
Validation loss: 2.159223477045695

Epoch: 6| Step: 3
Training loss: 1.5947043895721436
Validation loss: 2.15723184744517

Epoch: 6| Step: 4
Training loss: 1.8620675802230835
Validation loss: 2.148535172144572

Epoch: 6| Step: 5
Training loss: 1.4712409973144531
Validation loss: 2.152947505315145

Epoch: 6| Step: 6
Training loss: 1.485594630241394
Validation loss: 2.152344803015391

Epoch: 6| Step: 7
Training loss: 2.1859753131866455
Validation loss: 2.1311453382174173

Epoch: 6| Step: 8
Training loss: 1.758180022239685
Validation loss: 2.1158371766408286

Epoch: 6| Step: 9
Training loss: 1.8313980102539062
Validation loss: 2.129374325275421

Epoch: 6| Step: 10
Training loss: 1.1606478691101074
Validation loss: 2.132082720597585

Epoch: 6| Step: 11
Training loss: 2.4713597297668457
Validation loss: 2.1380030512809753

Epoch: 6| Step: 12
Training loss: 1.6778955459594727
Validation loss: 2.1116172671318054

Epoch: 6| Step: 13
Training loss: 1.571207046508789
Validation loss: 2.1217527190844216

Epoch: 240| Step: 0
Training loss: 1.5279803276062012
Validation loss: 2.1306219696998596

Epoch: 6| Step: 1
Training loss: 1.2837047576904297
Validation loss: 2.135450005531311

Epoch: 6| Step: 2
Training loss: 1.9280452728271484
Validation loss: 2.162156820297241

Epoch: 6| Step: 3
Training loss: 1.817448616027832
Validation loss: 2.1696550250053406

Epoch: 6| Step: 4
Training loss: 2.1565449237823486
Validation loss: 2.1748246351877847

Epoch: 6| Step: 5
Training loss: 1.8664954900741577
Validation loss: 2.185419778029124

Epoch: 6| Step: 6
Training loss: 1.5594701766967773
Validation loss: 2.194935222466787

Epoch: 6| Step: 7
Training loss: 1.8871086835861206
Validation loss: 2.1791300177574158

Epoch: 6| Step: 8
Training loss: 1.6560752391815186
Validation loss: 2.1633055806159973

Epoch: 6| Step: 9
Training loss: 2.274409770965576
Validation loss: 2.1405457655588784

Epoch: 6| Step: 10
Training loss: 1.2021762132644653
Validation loss: 2.1459572513898215

Epoch: 6| Step: 11
Training loss: 1.6298880577087402
Validation loss: 2.1441120704015098

Epoch: 6| Step: 12
Training loss: 1.6493098735809326
Validation loss: 2.119052290916443

Epoch: 6| Step: 13
Training loss: 2.3602678775787354
Validation loss: 2.136987884839376

Epoch: 241| Step: 0
Training loss: 1.8920528888702393
Validation loss: 2.1247859795888266

Epoch: 6| Step: 1
Training loss: 2.181795597076416
Validation loss: 2.13652241230011

Epoch: 6| Step: 2
Training loss: 2.280186653137207
Validation loss: 2.1327146689097085

Epoch: 6| Step: 3
Training loss: 1.1080979108810425
Validation loss: 2.127256532510122

Epoch: 6| Step: 4
Training loss: 0.8659906387329102
Validation loss: 2.1178991198539734

Epoch: 6| Step: 5
Training loss: 1.8990334272384644
Validation loss: 2.1361483534177146

Epoch: 6| Step: 6
Training loss: 1.7305241823196411
Validation loss: 2.145864486694336

Epoch: 6| Step: 7
Training loss: 1.2881388664245605
Validation loss: 2.1531567176183066

Epoch: 6| Step: 8
Training loss: 1.3721202611923218
Validation loss: 2.1596726775169373

Epoch: 6| Step: 9
Training loss: 1.9049043655395508
Validation loss: 2.1669600009918213

Epoch: 6| Step: 10
Training loss: 2.358062982559204
Validation loss: 2.1588809291521707

Epoch: 6| Step: 11
Training loss: 1.5779228210449219
Validation loss: 2.1540350914001465

Epoch: 6| Step: 12
Training loss: 2.151597499847412
Validation loss: 2.171917716662089

Epoch: 6| Step: 13
Training loss: 2.060715675354004
Validation loss: 2.173671464125315

Epoch: 242| Step: 0
Training loss: 1.3300087451934814
Validation loss: 2.175989270210266

Epoch: 6| Step: 1
Training loss: 1.7544912099838257
Validation loss: 2.1685680747032166

Epoch: 6| Step: 2
Training loss: 1.9136641025543213
Validation loss: 2.1553731759389243

Epoch: 6| Step: 3
Training loss: 1.5103315114974976
Validation loss: 2.149967054526011

Epoch: 6| Step: 4
Training loss: 1.4850064516067505
Validation loss: 2.1658320228258767

Epoch: 6| Step: 5
Training loss: 2.2539093494415283
Validation loss: 2.1427509983380637

Epoch: 6| Step: 6
Training loss: 1.7900099754333496
Validation loss: 2.1545825203259787

Epoch: 6| Step: 7
Training loss: 2.1780223846435547
Validation loss: 2.1737571557362876

Epoch: 6| Step: 8
Training loss: 1.2893166542053223
Validation loss: 2.198242167631785

Epoch: 6| Step: 9
Training loss: 1.9039233922958374
Validation loss: 2.189494331677755

Epoch: 6| Step: 10
Training loss: 0.9918774366378784
Validation loss: 2.183028598626455

Epoch: 6| Step: 11
Training loss: 2.2430312633514404
Validation loss: 2.20473575592041

Epoch: 6| Step: 12
Training loss: 1.9884967803955078
Validation loss: 2.1718448996543884

Epoch: 6| Step: 13
Training loss: 1.9606738090515137
Validation loss: 2.1652592023213706

Epoch: 243| Step: 0
Training loss: 1.610114336013794
Validation loss: 2.143281082312266

Epoch: 6| Step: 1
Training loss: 1.8049893379211426
Validation loss: 2.1302297910054526

Epoch: 6| Step: 2
Training loss: 1.2690492868423462
Validation loss: 2.132239818572998

Epoch: 6| Step: 3
Training loss: 1.5310218334197998
Validation loss: 2.1495548486709595

Epoch: 6| Step: 4
Training loss: 1.7972021102905273
Validation loss: 2.099877178668976

Epoch: 6| Step: 5
Training loss: 1.414101004600525
Validation loss: 2.136630952358246

Epoch: 6| Step: 6
Training loss: 1.8564574718475342
Validation loss: 2.1389941374460855

Epoch: 6| Step: 7
Training loss: 1.9598753452301025
Validation loss: 2.136630038420359

Epoch: 6| Step: 8
Training loss: 1.5644934177398682
Validation loss: 2.128473083178202

Epoch: 6| Step: 9
Training loss: 2.400391101837158
Validation loss: 2.1214957237243652

Epoch: 6| Step: 10
Training loss: 1.527964472770691
Validation loss: 2.1362263361612954

Epoch: 6| Step: 11
Training loss: 2.0690560340881348
Validation loss: 2.1355706652005515

Epoch: 6| Step: 12
Training loss: 1.6494252681732178
Validation loss: 2.1375239888827005

Epoch: 6| Step: 13
Training loss: 1.8192098140716553
Validation loss: 2.130370557308197

Epoch: 244| Step: 0
Training loss: 2.279134511947632
Validation loss: 2.1323439876238504

Epoch: 6| Step: 1
Training loss: 1.6927223205566406
Validation loss: 2.1357120275497437

Epoch: 6| Step: 2
Training loss: 1.071372151374817
Validation loss: 2.129187842210134

Epoch: 6| Step: 3
Training loss: 1.6880419254302979
Validation loss: 2.116788903872172

Epoch: 6| Step: 4
Training loss: 1.910715937614441
Validation loss: 2.1345911423365274

Epoch: 6| Step: 5
Training loss: 1.6500015258789062
Validation loss: 2.1235222816467285

Epoch: 6| Step: 6
Training loss: 1.5923417806625366
Validation loss: 2.1118383208910623

Epoch: 6| Step: 7
Training loss: 1.3133635520935059
Validation loss: 2.132745305697123

Epoch: 6| Step: 8
Training loss: 2.0630645751953125
Validation loss: 2.1490896145502725

Epoch: 6| Step: 9
Training loss: 1.9931132793426514
Validation loss: 2.144537111123403

Epoch: 6| Step: 10
Training loss: 1.658984899520874
Validation loss: 2.1492820580800376

Epoch: 6| Step: 11
Training loss: 1.7469611167907715
Validation loss: 2.159161647160848

Epoch: 6| Step: 12
Training loss: 1.7444826364517212
Validation loss: 2.166102965672811

Epoch: 6| Step: 13
Training loss: 1.750150442123413
Validation loss: 2.15389221906662

Epoch: 245| Step: 0
Training loss: 1.4494774341583252
Validation loss: 2.1706300576527915

Epoch: 6| Step: 1
Training loss: 1.8961608409881592
Validation loss: 2.170245806376139

Epoch: 6| Step: 2
Training loss: 1.3714380264282227
Validation loss: 2.16486257314682

Epoch: 6| Step: 3
Training loss: 1.527904987335205
Validation loss: 2.1610272924105325

Epoch: 6| Step: 4
Training loss: 1.962624192237854
Validation loss: 2.1505767504374185

Epoch: 6| Step: 5
Training loss: 1.9561526775360107
Validation loss: 2.1441255807876587

Epoch: 6| Step: 6
Training loss: 2.1802825927734375
Validation loss: 2.1666549841562905

Epoch: 6| Step: 7
Training loss: 1.4051017761230469
Validation loss: 2.1787041425704956

Epoch: 6| Step: 8
Training loss: 1.581176996231079
Validation loss: 2.1595707535743713

Epoch: 6| Step: 9
Training loss: 1.1395835876464844
Validation loss: 2.1651210387547812

Epoch: 6| Step: 10
Training loss: 1.436601996421814
Validation loss: 2.172804534435272

Epoch: 6| Step: 11
Training loss: 1.7614964246749878
Validation loss: 2.144895772139231

Epoch: 6| Step: 12
Training loss: 1.6866304874420166
Validation loss: 2.1443405946095786

Epoch: 6| Step: 13
Training loss: 2.553128242492676
Validation loss: 2.1610127488772073

Epoch: 246| Step: 0
Training loss: 1.0120866298675537
Validation loss: 2.129144867261251

Epoch: 6| Step: 1
Training loss: 1.6170144081115723
Validation loss: 2.1458972692489624

Epoch: 6| Step: 2
Training loss: 1.7446682453155518
Validation loss: 2.149578352769216

Epoch: 6| Step: 3
Training loss: 1.596506953239441
Validation loss: 2.1425047318140664

Epoch: 6| Step: 4
Training loss: 1.7185148000717163
Validation loss: 2.140488783518473

Epoch: 6| Step: 5
Training loss: 2.7696213722229004
Validation loss: 2.1424656907717385

Epoch: 6| Step: 6
Training loss: 1.2486848831176758
Validation loss: 2.133502105871836

Epoch: 6| Step: 7
Training loss: 1.683376669883728
Validation loss: 2.137038469314575

Epoch: 6| Step: 8
Training loss: 1.5114545822143555
Validation loss: 2.1391422947247825

Epoch: 6| Step: 9
Training loss: 1.3289833068847656
Validation loss: 2.126344641049703

Epoch: 6| Step: 10
Training loss: 1.8050806522369385
Validation loss: 2.150311748186747

Epoch: 6| Step: 11
Training loss: 1.4367698431015015
Validation loss: 2.1319650610287986

Epoch: 6| Step: 12
Training loss: 2.3682668209075928
Validation loss: 2.1483752727508545

Epoch: 6| Step: 13
Training loss: 1.7967499494552612
Validation loss: 2.1469682455062866

Epoch: 247| Step: 0
Training loss: 1.6559760570526123
Validation loss: 2.1356412370999656

Epoch: 6| Step: 1
Training loss: 2.1490225791931152
Validation loss: 2.1478764017422995

Epoch: 6| Step: 2
Training loss: 1.1604273319244385
Validation loss: 2.162468433380127

Epoch: 6| Step: 3
Training loss: 1.4497990608215332
Validation loss: 2.1618812878926597

Epoch: 6| Step: 4
Training loss: 2.2072033882141113
Validation loss: 2.162599245707194

Epoch: 6| Step: 5
Training loss: 1.4672036170959473
Validation loss: 2.150841554005941

Epoch: 6| Step: 6
Training loss: 1.207500696182251
Validation loss: 2.165396789709727

Epoch: 6| Step: 7
Training loss: 2.4845871925354004
Validation loss: 2.2125733494758606

Epoch: 6| Step: 8
Training loss: 2.4226434230804443
Validation loss: 2.192146639029185

Epoch: 6| Step: 9
Training loss: 1.3536911010742188
Validation loss: 2.1753050088882446

Epoch: 6| Step: 10
Training loss: 2.035994052886963
Validation loss: 2.2188517451286316

Epoch: 6| Step: 11
Training loss: 1.4937587976455688
Validation loss: 2.1770851810773215

Epoch: 6| Step: 12
Training loss: 1.6846356391906738
Validation loss: 2.1912930011749268

Epoch: 6| Step: 13
Training loss: 1.3989572525024414
Validation loss: 2.172318756580353

Epoch: 248| Step: 0
Training loss: 2.0808157920837402
Validation loss: 2.1736921270688376

Epoch: 6| Step: 1
Training loss: 1.668874740600586
Validation loss: 2.149152398109436

Epoch: 6| Step: 2
Training loss: 2.2960352897644043
Validation loss: 2.131694793701172

Epoch: 6| Step: 3
Training loss: 0.783571183681488
Validation loss: 2.1588489611943564

Epoch: 6| Step: 4
Training loss: 1.793337345123291
Validation loss: 2.145632525285085

Epoch: 6| Step: 5
Training loss: 1.5187922716140747
Validation loss: 2.159376621246338

Epoch: 6| Step: 6
Training loss: 1.492225170135498
Validation loss: 2.1485092639923096

Epoch: 6| Step: 7
Training loss: 1.8812696933746338
Validation loss: 2.157754381497701

Epoch: 6| Step: 8
Training loss: 1.1365113258361816
Validation loss: 2.183864692846934

Epoch: 6| Step: 9
Training loss: 1.6575143337249756
Validation loss: 2.193162977695465

Epoch: 6| Step: 10
Training loss: 1.2077221870422363
Validation loss: 2.167086978753408

Epoch: 6| Step: 11
Training loss: 2.5701632499694824
Validation loss: 2.1611162225405374

Epoch: 6| Step: 12
Training loss: 1.2326247692108154
Validation loss: 2.1827525695165

Epoch: 6| Step: 13
Training loss: 2.677243709564209
Validation loss: 2.16665381193161

Epoch: 249| Step: 0
Training loss: 1.1309032440185547
Validation loss: 2.1497464179992676

Epoch: 6| Step: 1
Training loss: 1.8531478643417358
Validation loss: 2.1552359660466514

Epoch: 6| Step: 2
Training loss: 2.3133888244628906
Validation loss: 2.1593870719273887

Epoch: 6| Step: 3
Training loss: 1.0117967128753662
Validation loss: 2.168333967526754

Epoch: 6| Step: 4
Training loss: 1.2676876783370972
Validation loss: 2.1456589500109353

Epoch: 6| Step: 5
Training loss: 1.8677878379821777
Validation loss: 2.1514450709025064

Epoch: 6| Step: 6
Training loss: 1.6938393115997314
Validation loss: 2.1589628060658774

Epoch: 6| Step: 7
Training loss: 1.7686035633087158
Validation loss: 2.1781314611434937

Epoch: 6| Step: 8
Training loss: 1.4106365442276
Validation loss: 2.1710390051205954

Epoch: 6| Step: 9
Training loss: 2.4485113620758057
Validation loss: 2.1400222380956015

Epoch: 6| Step: 10
Training loss: 1.6625295877456665
Validation loss: 2.1444641749064126

Epoch: 6| Step: 11
Training loss: 1.6907368898391724
Validation loss: 2.1677029132843018

Epoch: 6| Step: 12
Training loss: 1.5870088338851929
Validation loss: 2.1817023158073425

Epoch: 6| Step: 13
Training loss: 1.9595402479171753
Validation loss: 2.152443766593933

Epoch: 250| Step: 0
Training loss: 1.6355485916137695
Validation loss: 2.1508780121803284

Epoch: 6| Step: 1
Training loss: 1.9932422637939453
Validation loss: 2.16189181804657

Epoch: 6| Step: 2
Training loss: 1.8280556201934814
Validation loss: 2.1472246448198953

Epoch: 6| Step: 3
Training loss: 1.6570672988891602
Validation loss: 2.1674875219662986

Epoch: 6| Step: 4
Training loss: 2.1972150802612305
Validation loss: 2.1550456285476685

Epoch: 6| Step: 5
Training loss: 1.2559964656829834
Validation loss: 2.1515660881996155

Epoch: 6| Step: 6
Training loss: 1.6790380477905273
Validation loss: 2.1487960815429688

Epoch: 6| Step: 7
Training loss: 1.2552032470703125
Validation loss: 2.162594517072042

Epoch: 6| Step: 8
Training loss: 1.4564306735992432
Validation loss: 2.1652504603068032

Epoch: 6| Step: 9
Training loss: 1.7905099391937256
Validation loss: 2.174210329850515

Epoch: 6| Step: 10
Training loss: 1.171100378036499
Validation loss: 2.1748281717300415

Epoch: 6| Step: 11
Training loss: 1.7847785949707031
Validation loss: 2.186795234680176

Epoch: 6| Step: 12
Training loss: 1.699948787689209
Validation loss: 2.17325222492218

Epoch: 6| Step: 13
Training loss: 1.8034889698028564
Validation loss: 2.1722535689671836

Epoch: 251| Step: 0
Training loss: 1.5089240074157715
Validation loss: 2.173563996950785

Epoch: 6| Step: 1
Training loss: 1.6932417154312134
Validation loss: 2.1561482151349387

Epoch: 6| Step: 2
Training loss: 0.8698020577430725
Validation loss: 2.1763290564219155

Epoch: 6| Step: 3
Training loss: 2.2141971588134766
Validation loss: 2.1579823096593223

Epoch: 6| Step: 4
Training loss: 1.7274510860443115
Validation loss: 2.1522201100985208

Epoch: 6| Step: 5
Training loss: 1.8315784931182861
Validation loss: 2.1594606836636863

Epoch: 6| Step: 6
Training loss: 1.6298707723617554
Validation loss: 2.1598455905914307

Epoch: 6| Step: 7
Training loss: 1.5452498197555542
Validation loss: 2.1469962994257608

Epoch: 6| Step: 8
Training loss: 1.7196013927459717
Validation loss: 2.160713175932566

Epoch: 6| Step: 9
Training loss: 2.169261932373047
Validation loss: 2.1506317257881165

Epoch: 6| Step: 10
Training loss: 1.1374921798706055
Validation loss: 2.1494192481040955

Epoch: 6| Step: 11
Training loss: 1.4093014001846313
Validation loss: 2.1625577211380005

Epoch: 6| Step: 12
Training loss: 2.087891101837158
Validation loss: 2.1715206305185952

Epoch: 6| Step: 13
Training loss: 1.8775869607925415
Validation loss: 2.1757949590682983

Epoch: 252| Step: 0
Training loss: 1.039452075958252
Validation loss: 2.177685638268789

Epoch: 6| Step: 1
Training loss: 1.6129454374313354
Validation loss: 2.1843579411506653

Epoch: 6| Step: 2
Training loss: 1.7166025638580322
Validation loss: 2.1878100633621216

Epoch: 6| Step: 3
Training loss: 2.2087438106536865
Validation loss: 2.1941346724828086

Epoch: 6| Step: 4
Training loss: 1.9260283708572388
Validation loss: 2.191257953643799

Epoch: 6| Step: 5
Training loss: 1.8063576221466064
Validation loss: 2.1824561953544617

Epoch: 6| Step: 6
Training loss: 1.5883049964904785
Validation loss: 2.179849406083425

Epoch: 6| Step: 7
Training loss: 1.3380776643753052
Validation loss: 2.177664816379547

Epoch: 6| Step: 8
Training loss: 2.1007437705993652
Validation loss: 2.174868861834208

Epoch: 6| Step: 9
Training loss: 1.5788309574127197
Validation loss: 2.179086685180664

Epoch: 6| Step: 10
Training loss: 2.2718145847320557
Validation loss: 2.1898272037506104

Epoch: 6| Step: 11
Training loss: 1.2319927215576172
Validation loss: 2.1814692417780557

Epoch: 6| Step: 12
Training loss: 1.5276246070861816
Validation loss: 2.1610870162645974

Epoch: 6| Step: 13
Training loss: 1.5990495681762695
Validation loss: 2.1906062165896096

Epoch: 253| Step: 0
Training loss: 1.928525686264038
Validation loss: 2.1906837224960327

Epoch: 6| Step: 1
Training loss: 1.3826196193695068
Validation loss: 2.1652079621950784

Epoch: 6| Step: 2
Training loss: 1.224688172340393
Validation loss: 2.1796406706174216

Epoch: 6| Step: 3
Training loss: 1.9350769519805908
Validation loss: 2.1551433006922402

Epoch: 6| Step: 4
Training loss: 1.8820478916168213
Validation loss: 2.1581008434295654

Epoch: 6| Step: 5
Training loss: 1.2459726333618164
Validation loss: 2.1447819073994956

Epoch: 6| Step: 6
Training loss: 1.3675837516784668
Validation loss: 2.181148588657379

Epoch: 6| Step: 7
Training loss: 1.6578025817871094
Validation loss: 2.135925809542338

Epoch: 6| Step: 8
Training loss: 1.7454768419265747
Validation loss: 2.1748653054237366

Epoch: 6| Step: 9
Training loss: 1.560685157775879
Validation loss: 2.1785792907079062

Epoch: 6| Step: 10
Training loss: 2.58508563041687
Validation loss: 2.1691462993621826

Epoch: 6| Step: 11
Training loss: 1.8563878536224365
Validation loss: 2.1879835724830627

Epoch: 6| Step: 12
Training loss: 1.4123008251190186
Validation loss: 2.151849865913391

Epoch: 6| Step: 13
Training loss: 1.7035982608795166
Validation loss: 2.1689496437708535

Epoch: 254| Step: 0
Training loss: 1.6972100734710693
Validation loss: 2.150749405225118

Epoch: 6| Step: 1
Training loss: 1.7058333158493042
Validation loss: 2.144607126712799

Epoch: 6| Step: 2
Training loss: 1.7479842901229858
Validation loss: 2.1563732028007507

Epoch: 6| Step: 3
Training loss: 1.8583799600601196
Validation loss: 2.1359214981396994

Epoch: 6| Step: 4
Training loss: 2.1171483993530273
Validation loss: 2.136977732181549

Epoch: 6| Step: 5
Training loss: 1.1972672939300537
Validation loss: 2.126140773296356

Epoch: 6| Step: 6
Training loss: 1.2554831504821777
Validation loss: 2.143832484881083

Epoch: 6| Step: 7
Training loss: 1.926923394203186
Validation loss: 2.1538733641306558

Epoch: 6| Step: 8
Training loss: 1.7411696910858154
Validation loss: 2.1478949189186096

Epoch: 6| Step: 9
Training loss: 1.344441533088684
Validation loss: 2.1613084077835083

Epoch: 6| Step: 10
Training loss: 1.8673551082611084
Validation loss: 2.1494624813397727

Epoch: 6| Step: 11
Training loss: 1.9519041776657104
Validation loss: 2.159816404183706

Epoch: 6| Step: 12
Training loss: 0.996343731880188
Validation loss: 2.162218987941742

Epoch: 6| Step: 13
Training loss: 1.6566506624221802
Validation loss: 2.138673464457194

Epoch: 255| Step: 0
Training loss: 1.3345226049423218
Validation loss: 2.13746577501297

Epoch: 6| Step: 1
Training loss: 0.9556450247764587
Validation loss: 2.158796787261963

Epoch: 6| Step: 2
Training loss: 1.5222599506378174
Validation loss: 2.1468263268470764

Epoch: 6| Step: 3
Training loss: 2.1498637199401855
Validation loss: 2.1552849809328714

Epoch: 6| Step: 4
Training loss: 1.5802314281463623
Validation loss: 2.1798014839490256

Epoch: 6| Step: 5
Training loss: 1.9141199588775635
Validation loss: 2.1477839152018228

Epoch: 6| Step: 6
Training loss: 1.8967981338500977
Validation loss: 2.1691829562187195

Epoch: 6| Step: 7
Training loss: 1.9336559772491455
Validation loss: 2.1683980226516724

Epoch: 6| Step: 8
Training loss: 1.1305923461914062
Validation loss: 2.1770078341166177

Epoch: 6| Step: 9
Training loss: 2.308759927749634
Validation loss: 2.1847081383069358

Epoch: 6| Step: 10
Training loss: 1.6879141330718994
Validation loss: 2.1741461157798767

Epoch: 6| Step: 11
Training loss: 1.4396793842315674
Validation loss: 2.1977736552556357

Epoch: 6| Step: 12
Training loss: 1.6276006698608398
Validation loss: 2.1457050442695618

Epoch: 6| Step: 13
Training loss: 1.265002965927124
Validation loss: 2.1617253621419272

Epoch: 256| Step: 0
Training loss: 1.09004807472229
Validation loss: 2.160448729991913

Epoch: 6| Step: 1
Training loss: 1.7082774639129639
Validation loss: 2.124699354171753

Epoch: 6| Step: 2
Training loss: 1.9490671157836914
Validation loss: 2.1539600491523743

Epoch: 6| Step: 3
Training loss: 1.484109878540039
Validation loss: 2.1573319832483926

Epoch: 6| Step: 4
Training loss: 1.8950743675231934
Validation loss: 2.1437276005744934

Epoch: 6| Step: 5
Training loss: 1.3412163257598877
Validation loss: 2.145562171936035

Epoch: 6| Step: 6
Training loss: 1.896397590637207
Validation loss: 2.170011500517527

Epoch: 6| Step: 7
Training loss: 2.5134172439575195
Validation loss: 2.149339218934377

Epoch: 6| Step: 8
Training loss: 1.3831217288970947
Validation loss: 2.1572721799214682

Epoch: 6| Step: 9
Training loss: 1.6746571063995361
Validation loss: 2.184782644112905

Epoch: 6| Step: 10
Training loss: 1.8947207927703857
Validation loss: 2.1861326694488525

Epoch: 6| Step: 11
Training loss: 1.5473344326019287
Validation loss: 2.1939452091852822

Epoch: 6| Step: 12
Training loss: 1.8527767658233643
Validation loss: 2.1986964344978333

Epoch: 6| Step: 13
Training loss: 1.0823771953582764
Validation loss: 2.193310101826986

Epoch: 257| Step: 0
Training loss: 1.686913251876831
Validation loss: 2.1827710270881653

Epoch: 6| Step: 1
Training loss: 1.8803200721740723
Validation loss: 2.1557461619377136

Epoch: 6| Step: 2
Training loss: 1.4180728197097778
Validation loss: 2.164977471033732

Epoch: 6| Step: 3
Training loss: 1.2354694604873657
Validation loss: 2.143433471520742

Epoch: 6| Step: 4
Training loss: 1.3619176149368286
Validation loss: 2.1367037892341614

Epoch: 6| Step: 5
Training loss: 1.6965135335922241
Validation loss: 2.134181241194407

Epoch: 6| Step: 6
Training loss: 1.569275975227356
Validation loss: 2.118952473004659

Epoch: 6| Step: 7
Training loss: 1.9528905153274536
Validation loss: 2.120613217353821

Epoch: 6| Step: 8
Training loss: 1.6056478023529053
Validation loss: 2.1339675982793174

Epoch: 6| Step: 9
Training loss: 1.5310113430023193
Validation loss: 2.136943201224009

Epoch: 6| Step: 10
Training loss: 1.5559847354888916
Validation loss: 2.1210606694221497

Epoch: 6| Step: 11
Training loss: 1.5746197700500488
Validation loss: 2.1410640875498452

Epoch: 6| Step: 12
Training loss: 1.3479931354522705
Validation loss: 2.1394405166308084

Epoch: 6| Step: 13
Training loss: 2.365717649459839
Validation loss: 2.1467634638150535

Epoch: 258| Step: 0
Training loss: 1.6452360153198242
Validation loss: 2.1620063185691833

Epoch: 6| Step: 1
Training loss: 1.7678501605987549
Validation loss: 2.1323235233624778

Epoch: 6| Step: 2
Training loss: 1.3386790752410889
Validation loss: 2.160292307535807

Epoch: 6| Step: 3
Training loss: 1.937495231628418
Validation loss: 2.1520851055781045

Epoch: 6| Step: 4
Training loss: 1.5213334560394287
Validation loss: 2.144162356853485

Epoch: 6| Step: 5
Training loss: 1.5894222259521484
Validation loss: 2.1560747822125754

Epoch: 6| Step: 6
Training loss: 2.007810115814209
Validation loss: 2.1426047682762146

Epoch: 6| Step: 7
Training loss: 1.7896430492401123
Validation loss: 2.145141065120697

Epoch: 6| Step: 8
Training loss: 1.8185045719146729
Validation loss: 2.1265487670898438

Epoch: 6| Step: 9
Training loss: 1.4597148895263672
Validation loss: 2.146931231021881

Epoch: 6| Step: 10
Training loss: 1.3554456233978271
Validation loss: 2.144360661506653

Epoch: 6| Step: 11
Training loss: 1.4017904996871948
Validation loss: 2.1423689921696982

Epoch: 6| Step: 12
Training loss: 1.0739209651947021
Validation loss: 2.1459546089172363

Epoch: 6| Step: 13
Training loss: 2.113978862762451
Validation loss: 2.1494176586469016

Epoch: 259| Step: 0
Training loss: 1.0010067224502563
Validation loss: 2.139503022034963

Epoch: 6| Step: 1
Training loss: 1.685896873474121
Validation loss: 2.170744776725769

Epoch: 6| Step: 2
Training loss: 0.8541683554649353
Validation loss: 2.1904558340708413

Epoch: 6| Step: 3
Training loss: 1.444997787475586
Validation loss: 2.144807597001394

Epoch: 6| Step: 4
Training loss: 1.83830988407135
Validation loss: 2.1735795537630715

Epoch: 6| Step: 5
Training loss: 1.568757176399231
Validation loss: 2.1538459062576294

Epoch: 6| Step: 6
Training loss: 2.227128744125366
Validation loss: 2.1707505782445273

Epoch: 6| Step: 7
Training loss: 1.585433006286621
Validation loss: 2.1703749299049377

Epoch: 6| Step: 8
Training loss: 1.4226830005645752
Validation loss: 2.165947417418162

Epoch: 6| Step: 9
Training loss: 2.364872455596924
Validation loss: 2.151750326156616

Epoch: 6| Step: 10
Training loss: 1.8105013370513916
Validation loss: 2.166701058546702

Epoch: 6| Step: 11
Training loss: 2.237654685974121
Validation loss: 2.1415234804153442

Epoch: 6| Step: 12
Training loss: 1.6043064594268799
Validation loss: 2.146483302116394

Epoch: 6| Step: 13
Training loss: 1.5462204217910767
Validation loss: 2.146104951699575

Epoch: 260| Step: 0
Training loss: 1.82231605052948
Validation loss: 2.141835371653239

Epoch: 6| Step: 1
Training loss: 1.243720293045044
Validation loss: 2.1430725852648416

Epoch: 6| Step: 2
Training loss: 1.1123037338256836
Validation loss: 2.1403579910596213

Epoch: 6| Step: 3
Training loss: 1.4957904815673828
Validation loss: 2.16107569138209

Epoch: 6| Step: 4
Training loss: 1.8861351013183594
Validation loss: 2.1499674717585244

Epoch: 6| Step: 5
Training loss: 0.9326362609863281
Validation loss: 2.126326104005178

Epoch: 6| Step: 6
Training loss: 1.680525302886963
Validation loss: 2.148615578810374

Epoch: 6| Step: 7
Training loss: 1.7858808040618896
Validation loss: 2.157974660396576

Epoch: 6| Step: 8
Training loss: 1.8192085027694702
Validation loss: 2.152773857116699

Epoch: 6| Step: 9
Training loss: 2.0345664024353027
Validation loss: 2.1319499214490256

Epoch: 6| Step: 10
Training loss: 1.9377379417419434
Validation loss: 2.1328782041867576

Epoch: 6| Step: 11
Training loss: 1.5570011138916016
Validation loss: 2.1421355406443277

Epoch: 6| Step: 12
Training loss: 1.3648924827575684
Validation loss: 2.1253491242726645

Epoch: 6| Step: 13
Training loss: 2.0229592323303223
Validation loss: 2.1204867561658225

Epoch: 261| Step: 0
Training loss: 1.3616262674331665
Validation loss: 2.1263563434282937

Epoch: 6| Step: 1
Training loss: 2.085451602935791
Validation loss: 2.16156413157781

Epoch: 6| Step: 2
Training loss: 1.6558399200439453
Validation loss: 2.179149846235911

Epoch: 6| Step: 3
Training loss: 2.483283042907715
Validation loss: 2.174398442109426

Epoch: 6| Step: 4
Training loss: 1.2543513774871826
Validation loss: 2.1787486473719277

Epoch: 6| Step: 5
Training loss: 1.0692059993743896
Validation loss: 2.1654181480407715

Epoch: 6| Step: 6
Training loss: 1.6026806831359863
Validation loss: 2.136533737182617

Epoch: 6| Step: 7
Training loss: 1.4582973718643188
Validation loss: 2.1336100101470947

Epoch: 6| Step: 8
Training loss: 1.2116124629974365
Validation loss: 2.139495333035787

Epoch: 6| Step: 9
Training loss: 2.8609249591827393
Validation loss: 2.141224205493927

Epoch: 6| Step: 10
Training loss: 1.401184320449829
Validation loss: 2.129163463910421

Epoch: 6| Step: 11
Training loss: 2.027860403060913
Validation loss: 2.139615515867869

Epoch: 6| Step: 12
Training loss: 1.412597417831421
Validation loss: 2.141870677471161

Epoch: 6| Step: 13
Training loss: 1.110593318939209
Validation loss: 2.1585126717885337

Epoch: 262| Step: 0
Training loss: 1.9091757535934448
Validation loss: 2.1585890650749207

Epoch: 6| Step: 1
Training loss: 1.580318570137024
Validation loss: 2.1829630931218467

Epoch: 6| Step: 2
Training loss: 1.671148419380188
Validation loss: 2.1535057425498962

Epoch: 6| Step: 3
Training loss: 1.658767580986023
Validation loss: 2.1398709217707315

Epoch: 6| Step: 4
Training loss: 1.1282964944839478
Validation loss: 2.1447131435076394

Epoch: 6| Step: 5
Training loss: 1.1629332304000854
Validation loss: 2.1650248765945435

Epoch: 6| Step: 6
Training loss: 1.6914433240890503
Validation loss: 2.1867148876190186

Epoch: 6| Step: 7
Training loss: 1.5532760620117188
Validation loss: 2.1669050256411233

Epoch: 6| Step: 8
Training loss: 1.815004825592041
Validation loss: 2.1623454888661704

Epoch: 6| Step: 9
Training loss: 2.275392532348633
Validation loss: 2.1517256100972495

Epoch: 6| Step: 10
Training loss: 1.9491660594940186
Validation loss: 2.1479045152664185

Epoch: 6| Step: 11
Training loss: 1.6626232862472534
Validation loss: 2.135600507259369

Epoch: 6| Step: 12
Training loss: 1.1414854526519775
Validation loss: 2.1351154247919717

Epoch: 6| Step: 13
Training loss: 1.935893177986145
Validation loss: 2.1462559898694358

Epoch: 263| Step: 0
Training loss: 1.5391165018081665
Validation loss: 2.141426424185435

Epoch: 6| Step: 1
Training loss: 1.4962340593338013
Validation loss: 2.1345949371655784

Epoch: 6| Step: 2
Training loss: 0.835313081741333
Validation loss: 2.134041408697764

Epoch: 6| Step: 3
Training loss: 1.7998878955841064
Validation loss: 2.133100966612498

Epoch: 6| Step: 4
Training loss: 1.85709547996521
Validation loss: 2.125333229700724

Epoch: 6| Step: 5
Training loss: 2.625293731689453
Validation loss: 2.1582783659299216

Epoch: 6| Step: 6
Training loss: 1.9372292757034302
Validation loss: 2.125896692276001

Epoch: 6| Step: 7
Training loss: 1.4199869632720947
Validation loss: 2.117411176363627

Epoch: 6| Step: 8
Training loss: 1.0458544492721558
Validation loss: 2.1409313082695007

Epoch: 6| Step: 9
Training loss: 1.7023957967758179
Validation loss: 2.1286354660987854

Epoch: 6| Step: 10
Training loss: 2.4095327854156494
Validation loss: 2.130169669787089

Epoch: 6| Step: 11
Training loss: 1.496854543685913
Validation loss: 2.1363288164138794

Epoch: 6| Step: 12
Training loss: 1.4340744018554688
Validation loss: 2.129913071791331

Epoch: 6| Step: 13
Training loss: 1.243905782699585
Validation loss: 2.147833247979482

Epoch: 264| Step: 0
Training loss: 1.6131343841552734
Validation loss: 2.1506936152776084

Epoch: 6| Step: 1
Training loss: 1.608996868133545
Validation loss: 2.144702653090159

Epoch: 6| Step: 2
Training loss: 1.8736259937286377
Validation loss: 2.1393532951672873

Epoch: 6| Step: 3
Training loss: 1.6769301891326904
Validation loss: 2.1251513759295144

Epoch: 6| Step: 4
Training loss: 1.4205070734024048
Validation loss: 2.1479993065198264

Epoch: 6| Step: 5
Training loss: 1.1581263542175293
Validation loss: 2.125289261341095

Epoch: 6| Step: 6
Training loss: 2.2669968605041504
Validation loss: 2.1279021302858987

Epoch: 6| Step: 7
Training loss: 1.8707610368728638
Validation loss: 2.147297283013662

Epoch: 6| Step: 8
Training loss: 1.765608787536621
Validation loss: 2.137940545876821

Epoch: 6| Step: 9
Training loss: 2.157773494720459
Validation loss: 2.1455393632253013

Epoch: 6| Step: 10
Training loss: 1.4656524658203125
Validation loss: 2.1683064897855124

Epoch: 6| Step: 11
Training loss: 1.2214503288269043
Validation loss: 2.1558020313580832

Epoch: 6| Step: 12
Training loss: 1.3250951766967773
Validation loss: 2.17805145184199

Epoch: 6| Step: 13
Training loss: 1.4705127477645874
Validation loss: 2.182403842608134

Epoch: 265| Step: 0
Training loss: 1.058656930923462
Validation loss: 2.150055766105652

Epoch: 6| Step: 1
Training loss: 1.623328447341919
Validation loss: 2.130926032861074

Epoch: 6| Step: 2
Training loss: 2.118102788925171
Validation loss: 2.129597306251526

Epoch: 6| Step: 3
Training loss: 2.3404688835144043
Validation loss: 2.15579092502594

Epoch: 6| Step: 4
Training loss: 1.0837035179138184
Validation loss: 2.1316258311271667

Epoch: 6| Step: 5
Training loss: 0.9888908863067627
Validation loss: 2.1336089173952737

Epoch: 6| Step: 6
Training loss: 1.8056267499923706
Validation loss: 2.1354694763819375

Epoch: 6| Step: 7
Training loss: 1.336315393447876
Validation loss: 2.1379936933517456

Epoch: 6| Step: 8
Training loss: 1.82239830493927
Validation loss: 2.1380057334899902

Epoch: 6| Step: 9
Training loss: 1.5916438102722168
Validation loss: 2.1448801557223

Epoch: 6| Step: 10
Training loss: 1.5061166286468506
Validation loss: 2.1379552086194358

Epoch: 6| Step: 11
Training loss: 1.6403748989105225
Validation loss: 2.1329431931177774

Epoch: 6| Step: 12
Training loss: 2.0099246501922607
Validation loss: 2.1480833888053894

Epoch: 6| Step: 13
Training loss: 1.376171350479126
Validation loss: 2.159810721874237

Epoch: 266| Step: 0
Training loss: 1.8136405944824219
Validation loss: 2.1278497179349265

Epoch: 6| Step: 1
Training loss: 1.4220222234725952
Validation loss: 2.1485053300857544

Epoch: 6| Step: 2
Training loss: 2.1258182525634766
Validation loss: 2.173230528831482

Epoch: 6| Step: 3
Training loss: 1.6673502922058105
Validation loss: 2.152281562487284

Epoch: 6| Step: 4
Training loss: 2.1304776668548584
Validation loss: 2.151639382044474

Epoch: 6| Step: 5
Training loss: 1.7625460624694824
Validation loss: 2.1439912915229797

Epoch: 6| Step: 6
Training loss: 0.9920403957366943
Validation loss: 2.154534180959066

Epoch: 6| Step: 7
Training loss: 1.3559019565582275
Validation loss: 2.154147962729136

Epoch: 6| Step: 8
Training loss: 1.3473176956176758
Validation loss: 2.157449245452881

Epoch: 6| Step: 9
Training loss: 1.7725319862365723
Validation loss: 2.1649903059005737

Epoch: 6| Step: 10
Training loss: 1.7530200481414795
Validation loss: 2.1681902209917703

Epoch: 6| Step: 11
Training loss: 1.3691836595535278
Validation loss: 2.1597318251927695

Epoch: 6| Step: 12
Training loss: 1.5452626943588257
Validation loss: 2.158202648162842

Epoch: 6| Step: 13
Training loss: 1.176222324371338
Validation loss: 2.1463300387064614

Epoch: 267| Step: 0
Training loss: 1.4535157680511475
Validation loss: 2.175575017929077

Epoch: 6| Step: 1
Training loss: 1.8844339847564697
Validation loss: 2.2013657093048096

Epoch: 6| Step: 2
Training loss: 1.5949783325195312
Validation loss: 2.1643572648366294

Epoch: 6| Step: 3
Training loss: 2.001132011413574
Validation loss: 2.1942519744237265

Epoch: 6| Step: 4
Training loss: 1.1726360321044922
Validation loss: 2.192397932211558

Epoch: 6| Step: 5
Training loss: 1.131571650505066
Validation loss: 2.1711944142977395

Epoch: 6| Step: 6
Training loss: 1.1349568367004395
Validation loss: 2.1438481211662292

Epoch: 6| Step: 7
Training loss: 1.2088755369186401
Validation loss: 2.156392753124237

Epoch: 6| Step: 8
Training loss: 1.9239383935928345
Validation loss: 2.176764488220215

Epoch: 6| Step: 9
Training loss: 1.6464775800704956
Validation loss: 2.178006172180176

Epoch: 6| Step: 10
Training loss: 2.6036453247070312
Validation loss: 2.151470959186554

Epoch: 6| Step: 11
Training loss: 1.8389180898666382
Validation loss: 2.175516049067179

Epoch: 6| Step: 12
Training loss: 1.382380485534668
Validation loss: 2.174629330635071

Epoch: 6| Step: 13
Training loss: 1.2210829257965088
Validation loss: 2.182407637437185

Epoch: 268| Step: 0
Training loss: 1.3722283840179443
Validation loss: 2.1825541257858276

Epoch: 6| Step: 1
Training loss: 1.403738260269165
Validation loss: 2.154027581214905

Epoch: 6| Step: 2
Training loss: 1.2441282272338867
Validation loss: 2.190492848555247

Epoch: 6| Step: 3
Training loss: 1.6761517524719238
Validation loss: 2.1803942124048867

Epoch: 6| Step: 4
Training loss: 1.314934253692627
Validation loss: 2.1935781637827554

Epoch: 6| Step: 5
Training loss: 1.842893362045288
Validation loss: 2.1698201298713684

Epoch: 6| Step: 6
Training loss: 1.8269292116165161
Validation loss: 2.1706848541895547

Epoch: 6| Step: 7
Training loss: 1.2001240253448486
Validation loss: 2.1770296494166055

Epoch: 6| Step: 8
Training loss: 1.7331812381744385
Validation loss: 2.2084021170934043

Epoch: 6| Step: 9
Training loss: 1.5209555625915527
Validation loss: 2.2071406841278076

Epoch: 6| Step: 10
Training loss: 2.3310089111328125
Validation loss: 2.204222559928894

Epoch: 6| Step: 11
Training loss: 1.417368769645691
Validation loss: 2.2012081940968833

Epoch: 6| Step: 12
Training loss: 1.914334774017334
Validation loss: 2.2047935724258423

Epoch: 6| Step: 13
Training loss: 1.8242775201797485
Validation loss: 2.1636577248573303

Epoch: 269| Step: 0
Training loss: 1.7494678497314453
Validation loss: 2.1488725344340005

Epoch: 6| Step: 1
Training loss: 1.180907964706421
Validation loss: 2.1314187049865723

Epoch: 6| Step: 2
Training loss: 1.1875412464141846
Validation loss: 2.1308398644129434

Epoch: 6| Step: 3
Training loss: 1.60282564163208
Validation loss: 2.136297424634298

Epoch: 6| Step: 4
Training loss: 2.2534525394439697
Validation loss: 2.1454174319903054

Epoch: 6| Step: 5
Training loss: 3.066410541534424
Validation loss: 2.1599653164545694

Epoch: 6| Step: 6
Training loss: 1.1501938104629517
Validation loss: 2.14881024758021

Epoch: 6| Step: 7
Training loss: 1.6009714603424072
Validation loss: 2.144410789012909

Epoch: 6| Step: 8
Training loss: 1.3162686824798584
Validation loss: 2.1684574484825134

Epoch: 6| Step: 9
Training loss: 1.9551489353179932
Validation loss: 2.1458436449368796

Epoch: 6| Step: 10
Training loss: 1.3176939487457275
Validation loss: 2.169605851173401

Epoch: 6| Step: 11
Training loss: 1.2589390277862549
Validation loss: 2.187691311041514

Epoch: 6| Step: 12
Training loss: 1.8919546604156494
Validation loss: 2.1774332523345947

Epoch: 6| Step: 13
Training loss: 1.6194438934326172
Validation loss: 2.182976941267649

Epoch: 270| Step: 0
Training loss: 1.039848804473877
Validation loss: 2.240152597427368

Epoch: 6| Step: 1
Training loss: 2.1064672470092773
Validation loss: 2.209511121114095

Epoch: 6| Step: 2
Training loss: 1.1875466108322144
Validation loss: 2.1845418214797974

Epoch: 6| Step: 3
Training loss: 1.2334892749786377
Validation loss: 2.1798872152964273

Epoch: 6| Step: 4
Training loss: 1.3055109977722168
Validation loss: 2.169345180193583

Epoch: 6| Step: 5
Training loss: 1.117638349533081
Validation loss: 2.1705751021703086

Epoch: 6| Step: 6
Training loss: 1.844028353691101
Validation loss: 2.157284220059713

Epoch: 6| Step: 7
Training loss: 2.0746731758117676
Validation loss: 2.1474375327428183

Epoch: 6| Step: 8
Training loss: 1.6776773929595947
Validation loss: 2.161356528600057

Epoch: 6| Step: 9
Training loss: 2.3106775283813477
Validation loss: 2.131001889705658

Epoch: 6| Step: 10
Training loss: 1.4617050886154175
Validation loss: 2.123906056086222

Epoch: 6| Step: 11
Training loss: 1.5903184413909912
Validation loss: 2.130754033724467

Epoch: 6| Step: 12
Training loss: 1.8032689094543457
Validation loss: 2.1318925817807517

Epoch: 6| Step: 13
Training loss: 1.620032548904419
Validation loss: 2.130720376968384

Epoch: 271| Step: 0
Training loss: 1.9886720180511475
Validation loss: 2.1248748501141868

Epoch: 6| Step: 1
Training loss: 1.7598830461502075
Validation loss: 2.1400734583536782

Epoch: 6| Step: 2
Training loss: 1.926310420036316
Validation loss: 2.142443219820658

Epoch: 6| Step: 3
Training loss: 1.5762710571289062
Validation loss: 2.1658557256062827

Epoch: 6| Step: 4
Training loss: 1.2872776985168457
Validation loss: 2.159778118133545

Epoch: 6| Step: 5
Training loss: 1.074852466583252
Validation loss: 2.181890547275543

Epoch: 6| Step: 6
Training loss: 1.9922271966934204
Validation loss: 2.151571750640869

Epoch: 6| Step: 7
Training loss: 1.2888209819793701
Validation loss: 2.12557723124822

Epoch: 6| Step: 8
Training loss: 0.9105136394500732
Validation loss: 2.124918262163798

Epoch: 6| Step: 9
Training loss: 1.3152391910552979
Validation loss: 2.1380610267321267

Epoch: 6| Step: 10
Training loss: 1.5454492568969727
Validation loss: 2.1636773347854614

Epoch: 6| Step: 11
Training loss: 1.7210769653320312
Validation loss: 2.129749814669291

Epoch: 6| Step: 12
Training loss: 1.5199792385101318
Validation loss: 2.1505450208981833

Epoch: 6| Step: 13
Training loss: 1.8877298831939697
Validation loss: 2.1561657985051474

Epoch: 272| Step: 0
Training loss: 1.668421745300293
Validation loss: 2.162620484828949

Epoch: 6| Step: 1
Training loss: 1.9321260452270508
Validation loss: 2.160875141620636

Epoch: 6| Step: 2
Training loss: 1.5119972229003906
Validation loss: 2.1715973814328513

Epoch: 6| Step: 3
Training loss: 2.069596290588379
Validation loss: 2.172598361968994

Epoch: 6| Step: 4
Training loss: 1.6286561489105225
Validation loss: 2.19484810034434

Epoch: 6| Step: 5
Training loss: 1.9293185472488403
Validation loss: 2.2009538809458413

Epoch: 6| Step: 6
Training loss: 1.6180669069290161
Validation loss: 2.2216229240099588

Epoch: 6| Step: 7
Training loss: 1.9469237327575684
Validation loss: 2.202761928240458

Epoch: 6| Step: 8
Training loss: 1.4565138816833496
Validation loss: 2.213687459627787

Epoch: 6| Step: 9
Training loss: 1.3744105100631714
Validation loss: 2.172856549421946

Epoch: 6| Step: 10
Training loss: 1.5439726114273071
Validation loss: 2.139440377553304

Epoch: 6| Step: 11
Training loss: 1.58400297164917
Validation loss: 2.1402219931284585

Epoch: 6| Step: 12
Training loss: 1.380826473236084
Validation loss: 2.1523072123527527

Epoch: 6| Step: 13
Training loss: 1.6932580471038818
Validation loss: 2.14134273926417

Epoch: 273| Step: 0
Training loss: 1.6447131633758545
Validation loss: 2.137286643187205

Epoch: 6| Step: 1
Training loss: 1.4699523448944092
Validation loss: 2.145160754521688

Epoch: 6| Step: 2
Training loss: 1.707622766494751
Validation loss: 2.137736896673838

Epoch: 6| Step: 3
Training loss: 1.6503028869628906
Validation loss: 2.159486730893453

Epoch: 6| Step: 4
Training loss: 1.8235478401184082
Validation loss: 2.1715833147366843

Epoch: 6| Step: 5
Training loss: 1.880698323249817
Validation loss: 2.186131159464518

Epoch: 6| Step: 6
Training loss: 2.0000205039978027
Validation loss: 2.2220657070477805

Epoch: 6| Step: 7
Training loss: 1.7707796096801758
Validation loss: 2.2243559161822

Epoch: 6| Step: 8
Training loss: 1.4340271949768066
Validation loss: 2.1803128520647683

Epoch: 6| Step: 9
Training loss: 1.4579439163208008
Validation loss: 2.227005104223887

Epoch: 6| Step: 10
Training loss: 1.4454525709152222
Validation loss: 2.1859169403711953

Epoch: 6| Step: 11
Training loss: 1.2605960369110107
Validation loss: 2.1881908575693765

Epoch: 6| Step: 12
Training loss: 1.554248332977295
Validation loss: 2.1718228260676065

Epoch: 6| Step: 13
Training loss: 1.499690055847168
Validation loss: 2.1426436503728232

Epoch: 274| Step: 0
Training loss: 1.4900758266448975
Validation loss: 2.118569314479828

Epoch: 6| Step: 1
Training loss: 1.2653822898864746
Validation loss: 2.140960216522217

Epoch: 6| Step: 2
Training loss: 1.3419688940048218
Validation loss: 2.1558690468470254

Epoch: 6| Step: 3
Training loss: 2.0254087448120117
Validation loss: 2.134268860022227

Epoch: 6| Step: 4
Training loss: 1.8730621337890625
Validation loss: 2.1331509153048196

Epoch: 6| Step: 5
Training loss: 1.096015453338623
Validation loss: 2.151200771331787

Epoch: 6| Step: 6
Training loss: 1.196993350982666
Validation loss: 2.1570945580800376

Epoch: 6| Step: 7
Training loss: 1.8856645822525024
Validation loss: 2.13434370358785

Epoch: 6| Step: 8
Training loss: 1.564192771911621
Validation loss: 2.1617671052614846

Epoch: 6| Step: 9
Training loss: 1.3722920417785645
Validation loss: 2.1408520142237344

Epoch: 6| Step: 10
Training loss: 2.4589877128601074
Validation loss: 2.1512855092684426

Epoch: 6| Step: 11
Training loss: 0.9499194622039795
Validation loss: 2.1413306991259256

Epoch: 6| Step: 12
Training loss: 2.454679489135742
Validation loss: 2.1211636066436768

Epoch: 6| Step: 13
Training loss: 1.0030426979064941
Validation loss: 2.152993361155192

Epoch: 275| Step: 0
Training loss: 1.7015572786331177
Validation loss: 2.1569476326306662

Epoch: 6| Step: 1
Training loss: 1.5741140842437744
Validation loss: 2.122330625851949

Epoch: 6| Step: 2
Training loss: 1.4801456928253174
Validation loss: 2.129728615283966

Epoch: 6| Step: 3
Training loss: 1.0653687715530396
Validation loss: 2.126117169857025

Epoch: 6| Step: 4
Training loss: 1.6811838150024414
Validation loss: 2.1512797673543296

Epoch: 6| Step: 5
Training loss: 1.6143935918807983
Validation loss: 2.134524643421173

Epoch: 6| Step: 6
Training loss: 1.5680525302886963
Validation loss: 2.148158331712087

Epoch: 6| Step: 7
Training loss: 1.8978636264801025
Validation loss: 2.1192423899968467

Epoch: 6| Step: 8
Training loss: 1.878253698348999
Validation loss: 2.1348572770754495

Epoch: 6| Step: 9
Training loss: 1.1009154319763184
Validation loss: 2.1544734040896096

Epoch: 6| Step: 10
Training loss: 1.1845396757125854
Validation loss: 2.147430956363678

Epoch: 6| Step: 11
Training loss: 1.8102351427078247
Validation loss: 2.1704157988230386

Epoch: 6| Step: 12
Training loss: 1.3948063850402832
Validation loss: 2.151382486025492

Epoch: 6| Step: 13
Training loss: 1.477283239364624
Validation loss: 2.167335053284963

Epoch: 276| Step: 0
Training loss: 1.6497396230697632
Validation loss: 2.163173278172811

Epoch: 6| Step: 1
Training loss: 1.580082893371582
Validation loss: 2.197096327940623

Epoch: 6| Step: 2
Training loss: 1.263916254043579
Validation loss: 2.1920865376790366

Epoch: 6| Step: 3
Training loss: 1.457108497619629
Validation loss: 2.207120954990387

Epoch: 6| Step: 4
Training loss: 1.2613892555236816
Validation loss: 2.1811416149139404

Epoch: 6| Step: 5
Training loss: 2.0067591667175293
Validation loss: 2.1812036832173667

Epoch: 6| Step: 6
Training loss: 1.3150279521942139
Validation loss: 2.1629866560300193

Epoch: 6| Step: 7
Training loss: 1.5421146154403687
Validation loss: 2.1618096232414246

Epoch: 6| Step: 8
Training loss: 1.5377843379974365
Validation loss: 2.1639842987060547

Epoch: 6| Step: 9
Training loss: 0.929028332233429
Validation loss: 2.152170717716217

Epoch: 6| Step: 10
Training loss: 1.6112642288208008
Validation loss: 2.140140970547994

Epoch: 6| Step: 11
Training loss: 2.4307339191436768
Validation loss: 2.144771099090576

Epoch: 6| Step: 12
Training loss: 2.194178581237793
Validation loss: 2.1358526746431985

Epoch: 6| Step: 13
Training loss: 1.3738195896148682
Validation loss: 2.1210027933120728

Epoch: 277| Step: 0
Training loss: 1.8968076705932617
Validation loss: 2.142814497152964

Epoch: 6| Step: 1
Training loss: 1.1576284170150757
Validation loss: 2.113010505835215

Epoch: 6| Step: 2
Training loss: 1.9688992500305176
Validation loss: 2.16531765460968

Epoch: 6| Step: 3
Training loss: 1.789017677307129
Validation loss: 2.1930508414904275

Epoch: 6| Step: 4
Training loss: 1.3579087257385254
Validation loss: 2.169459422429403

Epoch: 6| Step: 5
Training loss: 1.7297747135162354
Validation loss: 2.195890565713247

Epoch: 6| Step: 6
Training loss: 1.084149956703186
Validation loss: 2.164588729540507

Epoch: 6| Step: 7
Training loss: 1.6677789688110352
Validation loss: 2.1466329097747803

Epoch: 6| Step: 8
Training loss: 1.1093798875808716
Validation loss: 2.1328113675117493

Epoch: 6| Step: 9
Training loss: 1.4682459831237793
Validation loss: 2.1416650811831155

Epoch: 6| Step: 10
Training loss: 2.185590982437134
Validation loss: 2.164525588353475

Epoch: 6| Step: 11
Training loss: 1.544211745262146
Validation loss: 2.1355687379837036

Epoch: 6| Step: 12
Training loss: 1.3606419563293457
Validation loss: 2.152680257956187

Epoch: 6| Step: 13
Training loss: 1.7983593940734863
Validation loss: 2.1535770297050476

Epoch: 278| Step: 0
Training loss: 1.604889154434204
Validation loss: 2.153225084145864

Epoch: 6| Step: 1
Training loss: 0.8355889916419983
Validation loss: 2.1746005018552146

Epoch: 6| Step: 2
Training loss: 1.513106346130371
Validation loss: 2.1673446893692017

Epoch: 6| Step: 3
Training loss: 1.6519097089767456
Validation loss: 2.1480581760406494

Epoch: 6| Step: 4
Training loss: 1.4019410610198975
Validation loss: 2.1791704495747886

Epoch: 6| Step: 5
Training loss: 1.19231379032135
Validation loss: 2.1572032372156777

Epoch: 6| Step: 6
Training loss: 1.7981820106506348
Validation loss: 2.155044754346212

Epoch: 6| Step: 7
Training loss: 1.7135536670684814
Validation loss: 2.170879582564036

Epoch: 6| Step: 8
Training loss: 1.9929475784301758
Validation loss: 2.1665388147036233

Epoch: 6| Step: 9
Training loss: 1.351083755493164
Validation loss: 2.1815545360247293

Epoch: 6| Step: 10
Training loss: 1.2848637104034424
Validation loss: 2.1748076677322388

Epoch: 6| Step: 11
Training loss: 1.888474941253662
Validation loss: 2.157420734564463

Epoch: 6| Step: 12
Training loss: 1.7665380239486694
Validation loss: 2.1517301201820374

Epoch: 6| Step: 13
Training loss: 1.3132882118225098
Validation loss: 2.1753501494725547

Epoch: 279| Step: 0
Training loss: 0.7971633076667786
Validation loss: 2.1851266423861184

Epoch: 6| Step: 1
Training loss: 1.4509857892990112
Validation loss: 2.1757004062334695

Epoch: 6| Step: 2
Training loss: 1.125218391418457
Validation loss: 2.1868669390678406

Epoch: 6| Step: 3
Training loss: 1.9213991165161133
Validation loss: 2.188452879587809

Epoch: 6| Step: 4
Training loss: 0.9911105632781982
Validation loss: 2.179104765256246

Epoch: 6| Step: 5
Training loss: 1.5026304721832275
Validation loss: 2.2016026775042215

Epoch: 6| Step: 6
Training loss: 0.9870785474777222
Validation loss: 2.19368577003479

Epoch: 6| Step: 7
Training loss: 1.4554474353790283
Validation loss: 2.2008502880732217

Epoch: 6| Step: 8
Training loss: 1.6284418106079102
Validation loss: 2.204943060874939

Epoch: 6| Step: 9
Training loss: 2.654646873474121
Validation loss: 2.1873476107915244

Epoch: 6| Step: 10
Training loss: 1.4981436729431152
Validation loss: 2.199764132499695

Epoch: 6| Step: 11
Training loss: 1.8748868703842163
Validation loss: 2.1966955264409385

Epoch: 6| Step: 12
Training loss: 1.9451510906219482
Validation loss: 2.190460284550985

Epoch: 6| Step: 13
Training loss: 1.5756148099899292
Validation loss: 2.198342223962148

Epoch: 280| Step: 0
Training loss: 1.4527442455291748
Validation loss: 2.156455953915914

Epoch: 6| Step: 1
Training loss: 1.7024918794631958
Validation loss: 2.156820774078369

Epoch: 6| Step: 2
Training loss: 2.038461685180664
Validation loss: 2.1410093307495117

Epoch: 6| Step: 3
Training loss: 1.572485327720642
Validation loss: 2.1284318963686624

Epoch: 6| Step: 4
Training loss: 1.21147882938385
Validation loss: 2.119605839252472

Epoch: 6| Step: 5
Training loss: 1.674195408821106
Validation loss: 2.1348379651705423

Epoch: 6| Step: 6
Training loss: 1.6629356145858765
Validation loss: 2.1229761242866516

Epoch: 6| Step: 7
Training loss: 1.4039583206176758
Validation loss: 2.134058117866516

Epoch: 6| Step: 8
Training loss: 1.0745429992675781
Validation loss: 2.1472156842549643

Epoch: 6| Step: 9
Training loss: 1.6658564805984497
Validation loss: 2.1550872127215066

Epoch: 6| Step: 10
Training loss: 1.6899774074554443
Validation loss: 2.1807005206743875

Epoch: 6| Step: 11
Training loss: 1.7293179035186768
Validation loss: 2.196946839491526

Epoch: 6| Step: 12
Training loss: 1.7991007566452026
Validation loss: 2.193266212940216

Epoch: 6| Step: 13
Training loss: 1.0998172760009766
Validation loss: 2.1772290468215942

Epoch: 281| Step: 0
Training loss: 1.0174198150634766
Validation loss: 2.1768349607785544

Epoch: 6| Step: 1
Training loss: 1.3572533130645752
Validation loss: 2.157789925734202

Epoch: 6| Step: 2
Training loss: 1.6286935806274414
Validation loss: 2.166958491007487

Epoch: 6| Step: 3
Training loss: 1.6686933040618896
Validation loss: 2.1707292397816977

Epoch: 6| Step: 4
Training loss: 1.5883457660675049
Validation loss: 2.135277529557546

Epoch: 6| Step: 5
Training loss: 1.997092604637146
Validation loss: 2.1697255770365396

Epoch: 6| Step: 6
Training loss: 1.523934006690979
Validation loss: 2.155461053053538

Epoch: 6| Step: 7
Training loss: 2.114011526107788
Validation loss: 2.155789335568746

Epoch: 6| Step: 8
Training loss: 0.6330034732818604
Validation loss: 2.133268117904663

Epoch: 6| Step: 9
Training loss: 1.6313304901123047
Validation loss: 2.157632887363434

Epoch: 6| Step: 10
Training loss: 1.184084415435791
Validation loss: 2.14514168103536

Epoch: 6| Step: 11
Training loss: 2.0521163940429688
Validation loss: 2.1314639846483865

Epoch: 6| Step: 12
Training loss: 1.6656118631362915
Validation loss: 2.1216042240460715

Epoch: 6| Step: 13
Training loss: 1.1547510623931885
Validation loss: 2.1716164549191794

Epoch: 282| Step: 0
Training loss: 1.6088204383850098
Validation loss: 2.1990387439727783

Epoch: 6| Step: 1
Training loss: 2.139954090118408
Validation loss: 2.2085429430007935

Epoch: 6| Step: 2
Training loss: 2.033843517303467
Validation loss: 2.1852777202924094

Epoch: 6| Step: 3
Training loss: 2.2296018600463867
Validation loss: 2.178278942902883

Epoch: 6| Step: 4
Training loss: 1.2545506954193115
Validation loss: 2.1453205148379006

Epoch: 6| Step: 5
Training loss: 0.7283680438995361
Validation loss: 2.181800643603007

Epoch: 6| Step: 6
Training loss: 0.8808146715164185
Validation loss: 2.1693088014920554

Epoch: 6| Step: 7
Training loss: 1.4292526245117188
Validation loss: 2.1415319244066873

Epoch: 6| Step: 8
Training loss: 1.4092168807983398
Validation loss: 2.157193382581075

Epoch: 6| Step: 9
Training loss: 1.6833897829055786
Validation loss: 2.1780030727386475

Epoch: 6| Step: 10
Training loss: 1.3844914436340332
Validation loss: 2.1575282216072083

Epoch: 6| Step: 11
Training loss: 1.1329723596572876
Validation loss: 2.157176375389099

Epoch: 6| Step: 12
Training loss: 2.2662343978881836
Validation loss: 2.173914929231008

Epoch: 6| Step: 13
Training loss: 1.0525578260421753
Validation loss: 2.1867857774098716

Epoch: 283| Step: 0
Training loss: 1.660034418106079
Validation loss: 2.197603166103363

Epoch: 6| Step: 1
Training loss: 1.6151442527770996
Validation loss: 2.177047828833262

Epoch: 6| Step: 2
Training loss: 1.3686659336090088
Validation loss: 2.1521615584691367

Epoch: 6| Step: 3
Training loss: 1.6115930080413818
Validation loss: 2.1450607577959695

Epoch: 6| Step: 4
Training loss: 1.2561631202697754
Validation loss: 2.175599197546641

Epoch: 6| Step: 5
Training loss: 1.75580632686615
Validation loss: 2.160001218318939

Epoch: 6| Step: 6
Training loss: 1.5762975215911865
Validation loss: 2.200547218322754

Epoch: 6| Step: 7
Training loss: 1.5711205005645752
Validation loss: 2.2092703183492026

Epoch: 6| Step: 8
Training loss: 1.8491308689117432
Validation loss: 2.203624705473582

Epoch: 6| Step: 9
Training loss: 1.4704539775848389
Validation loss: 2.1813702980677285

Epoch: 6| Step: 10
Training loss: 1.610968828201294
Validation loss: 2.15594075123469

Epoch: 6| Step: 11
Training loss: 1.7188372611999512
Validation loss: 2.194662928581238

Epoch: 6| Step: 12
Training loss: 1.2281663417816162
Validation loss: 2.1943045457204184

Epoch: 6| Step: 13
Training loss: 1.7867250442504883
Validation loss: 2.212694227695465

Epoch: 284| Step: 0
Training loss: 1.0799944400787354
Validation loss: 2.2273534337679544

Epoch: 6| Step: 1
Training loss: 1.6192562580108643
Validation loss: 2.2248421907424927

Epoch: 6| Step: 2
Training loss: 1.4505829811096191
Validation loss: 2.2356115778287253

Epoch: 6| Step: 3
Training loss: 1.359395980834961
Validation loss: 2.1875247160593667

Epoch: 6| Step: 4
Training loss: 1.888551950454712
Validation loss: 2.1666574279467263

Epoch: 6| Step: 5
Training loss: 2.1754698753356934
Validation loss: 2.148054083188375

Epoch: 6| Step: 6
Training loss: 1.9601777791976929
Validation loss: 2.149209956328074

Epoch: 6| Step: 7
Training loss: 1.3061127662658691
Validation loss: 2.153415242830912

Epoch: 6| Step: 8
Training loss: 1.5952703952789307
Validation loss: 2.150310297807058

Epoch: 6| Step: 9
Training loss: 1.1397393941879272
Validation loss: 2.148041288057963

Epoch: 6| Step: 10
Training loss: 1.8100478649139404
Validation loss: 2.1436752676963806

Epoch: 6| Step: 11
Training loss: 1.991758942604065
Validation loss: 2.1376304229100547

Epoch: 6| Step: 12
Training loss: 1.3981682062149048
Validation loss: 2.1293168663978577

Epoch: 6| Step: 13
Training loss: 0.9426387548446655
Validation loss: 2.1360116203626

Epoch: 285| Step: 0
Training loss: 1.4671196937561035
Validation loss: 2.1145673592885337

Epoch: 6| Step: 1
Training loss: 1.9792529344558716
Validation loss: 2.1462738513946533

Epoch: 6| Step: 2
Training loss: 1.4614043235778809
Validation loss: 2.122262398401896

Epoch: 6| Step: 3
Training loss: 1.163179636001587
Validation loss: 2.105513572692871

Epoch: 6| Step: 4
Training loss: 0.7652489542961121
Validation loss: 2.1355128486951194

Epoch: 6| Step: 5
Training loss: 1.7518768310546875
Validation loss: 2.1486672163009644

Epoch: 6| Step: 6
Training loss: 1.6732453107833862
Validation loss: 2.1356157859166465

Epoch: 6| Step: 7
Training loss: 1.7468396425247192
Validation loss: 2.1539233724276223

Epoch: 6| Step: 8
Training loss: 1.8687824010849
Validation loss: 2.1779287258783975

Epoch: 6| Step: 9
Training loss: 1.3403443098068237
Validation loss: 2.1713198026021323

Epoch: 6| Step: 10
Training loss: 1.2466647624969482
Validation loss: 2.1780285636583963

Epoch: 6| Step: 11
Training loss: 1.6023039817810059
Validation loss: 2.173153340816498

Epoch: 6| Step: 12
Training loss: 1.707812786102295
Validation loss: 2.1414765119552612

Epoch: 6| Step: 13
Training loss: 1.140366554260254
Validation loss: 2.137496908505758

Epoch: 286| Step: 0
Training loss: 0.8623360395431519
Validation loss: 2.15714023510615

Epoch: 6| Step: 1
Training loss: 1.8253428936004639
Validation loss: 2.114346206188202

Epoch: 6| Step: 2
Training loss: 1.7471630573272705
Validation loss: 2.1336143811543784

Epoch: 6| Step: 3
Training loss: 1.8196779489517212
Validation loss: 2.1227309703826904

Epoch: 6| Step: 4
Training loss: 1.1810016632080078
Validation loss: 2.1361369291941323

Epoch: 6| Step: 5
Training loss: 1.4101178646087646
Validation loss: 2.123797873655955

Epoch: 6| Step: 6
Training loss: 2.185598373413086
Validation loss: 2.146995564301809

Epoch: 6| Step: 7
Training loss: 1.193073034286499
Validation loss: 2.129101037979126

Epoch: 6| Step: 8
Training loss: 1.3655980825424194
Validation loss: 2.163620193799337

Epoch: 6| Step: 9
Training loss: 1.3072576522827148
Validation loss: 2.1867065032323203

Epoch: 6| Step: 10
Training loss: 1.6824613809585571
Validation loss: 2.2002812027931213

Epoch: 6| Step: 11
Training loss: 1.7853548526763916
Validation loss: 2.1923423608144126

Epoch: 6| Step: 12
Training loss: 1.398878812789917
Validation loss: 2.174881875514984

Epoch: 6| Step: 13
Training loss: 1.5470768213272095
Validation loss: 2.1543979247411094

Epoch: 287| Step: 0
Training loss: 1.745910406112671
Validation loss: 2.1568437814712524

Epoch: 6| Step: 1
Training loss: 1.9176609516143799
Validation loss: 2.1784802675247192

Epoch: 6| Step: 2
Training loss: 0.9257164001464844
Validation loss: 2.1288066506385803

Epoch: 6| Step: 3
Training loss: 1.4348030090332031
Validation loss: 2.144731362660726

Epoch: 6| Step: 4
Training loss: 1.4756801128387451
Validation loss: 2.166193147500356

Epoch: 6| Step: 5
Training loss: 1.5076611042022705
Validation loss: 2.1634226640065513

Epoch: 6| Step: 6
Training loss: 1.6546679735183716
Validation loss: 2.151276191075643

Epoch: 6| Step: 7
Training loss: 1.1476566791534424
Validation loss: 2.1470007499059043

Epoch: 6| Step: 8
Training loss: 1.4427189826965332
Validation loss: 2.1818413734436035

Epoch: 6| Step: 9
Training loss: 1.4206185340881348
Validation loss: 2.175187349319458

Epoch: 6| Step: 10
Training loss: 1.251481533050537
Validation loss: 2.160213132699331

Epoch: 6| Step: 11
Training loss: 1.415783166885376
Validation loss: 2.180909812450409

Epoch: 6| Step: 12
Training loss: 1.2116798162460327
Validation loss: 2.170180022716522

Epoch: 6| Step: 13
Training loss: 1.9581118822097778
Validation loss: 2.158780892690023

Epoch: 288| Step: 0
Training loss: 1.4532921314239502
Validation loss: 2.142137885093689

Epoch: 6| Step: 1
Training loss: 1.2310818433761597
Validation loss: 2.1439179182052612

Epoch: 6| Step: 2
Training loss: 1.1048601865768433
Validation loss: 2.1489481925964355

Epoch: 6| Step: 3
Training loss: 1.133829951286316
Validation loss: 2.134864032268524

Epoch: 6| Step: 4
Training loss: 1.4103963375091553
Validation loss: 2.136696755886078

Epoch: 6| Step: 5
Training loss: 0.9650198221206665
Validation loss: 2.140792806943258

Epoch: 6| Step: 6
Training loss: 1.2997758388519287
Validation loss: 2.1347519556681314

Epoch: 6| Step: 7
Training loss: 1.4475821256637573
Validation loss: 2.113401174545288

Epoch: 6| Step: 8
Training loss: 2.4240946769714355
Validation loss: 2.154977301756541

Epoch: 6| Step: 9
Training loss: 1.246019959449768
Validation loss: 2.1280768712361655

Epoch: 6| Step: 10
Training loss: 1.5538301467895508
Validation loss: 2.137198885281881

Epoch: 6| Step: 11
Training loss: 1.4235692024230957
Validation loss: 2.131364425023397

Epoch: 6| Step: 12
Training loss: 1.5575683116912842
Validation loss: 2.1547898054122925

Epoch: 6| Step: 13
Training loss: 2.1366405487060547
Validation loss: 2.1287298997243247

Epoch: 289| Step: 0
Training loss: 1.117968201637268
Validation loss: 2.160368343194326

Epoch: 6| Step: 1
Training loss: 1.3453361988067627
Validation loss: 2.1614280144373574

Epoch: 6| Step: 2
Training loss: 1.2500743865966797
Validation loss: 2.164664149284363

Epoch: 6| Step: 3
Training loss: 1.1337658166885376
Validation loss: 2.185209413369497

Epoch: 6| Step: 4
Training loss: 1.4554524421691895
Validation loss: 2.183296581109365

Epoch: 6| Step: 5
Training loss: 1.7155845165252686
Validation loss: 2.1841201782226562

Epoch: 6| Step: 6
Training loss: 2.234675168991089
Validation loss: 2.1798877318700156

Epoch: 6| Step: 7
Training loss: 1.2834696769714355
Validation loss: 2.184436639149984

Epoch: 6| Step: 8
Training loss: 1.1107277870178223
Validation loss: 2.1711628437042236

Epoch: 6| Step: 9
Training loss: 2.2820286750793457
Validation loss: 2.1906891663869223

Epoch: 6| Step: 10
Training loss: 1.647061824798584
Validation loss: 2.1858405669530234

Epoch: 6| Step: 11
Training loss: 1.898841381072998
Validation loss: 2.1881273984909058

Epoch: 6| Step: 12
Training loss: 1.607953667640686
Validation loss: 2.2075829903284707

Epoch: 6| Step: 13
Training loss: 0.8151805996894836
Validation loss: 2.168920954068502

Epoch: 290| Step: 0
Training loss: 0.9561403393745422
Validation loss: 2.1840930382410684

Epoch: 6| Step: 1
Training loss: 1.5727696418762207
Validation loss: 2.1856895287831626

Epoch: 6| Step: 2
Training loss: 1.3029989004135132
Validation loss: 2.1871106227238974

Epoch: 6| Step: 3
Training loss: 1.5443947315216064
Validation loss: 2.187087972958883

Epoch: 6| Step: 4
Training loss: 1.2347359657287598
Validation loss: 2.190419058005015

Epoch: 6| Step: 5
Training loss: 1.9694488048553467
Validation loss: 2.1861340403556824

Epoch: 6| Step: 6
Training loss: 1.1000235080718994
Validation loss: 2.183832108974457

Epoch: 6| Step: 7
Training loss: 1.6928339004516602
Validation loss: 2.1647180318832397

Epoch: 6| Step: 8
Training loss: 1.5257656574249268
Validation loss: 2.1676068107287088

Epoch: 6| Step: 9
Training loss: 1.9715631008148193
Validation loss: 2.15378600358963

Epoch: 6| Step: 10
Training loss: 1.5236607789993286
Validation loss: 2.146252989768982

Epoch: 6| Step: 11
Training loss: 1.2243525981903076
Validation loss: 2.159994920094808

Epoch: 6| Step: 12
Training loss: 1.4585424661636353
Validation loss: 2.127220551172892

Epoch: 6| Step: 13
Training loss: 1.2671983242034912
Validation loss: 2.1213414867719016

Epoch: 291| Step: 0
Training loss: 1.3276933431625366
Validation loss: 2.1636374394098916

Epoch: 6| Step: 1
Training loss: 1.4740960597991943
Validation loss: 2.1673428813616433

Epoch: 6| Step: 2
Training loss: 1.9353423118591309
Validation loss: 2.1295898159344993

Epoch: 6| Step: 3
Training loss: 1.285477638244629
Validation loss: 2.1457950671513877

Epoch: 6| Step: 4
Training loss: 1.6745028495788574
Validation loss: 2.1545594731966653

Epoch: 6| Step: 5
Training loss: 1.4463872909545898
Validation loss: 2.184157152970632

Epoch: 6| Step: 6
Training loss: 1.3997739553451538
Validation loss: 2.2297848661740622

Epoch: 6| Step: 7
Training loss: 1.2756891250610352
Validation loss: 2.204833447933197

Epoch: 6| Step: 8
Training loss: 1.6309314966201782
Validation loss: 2.187619944413503

Epoch: 6| Step: 9
Training loss: 1.1150742769241333
Validation loss: 2.171107232570648

Epoch: 6| Step: 10
Training loss: 1.576828956604004
Validation loss: 2.1637515226999917

Epoch: 6| Step: 11
Training loss: 1.0249685049057007
Validation loss: 2.1269450187683105

Epoch: 6| Step: 12
Training loss: 2.06268310546875
Validation loss: 2.1333158810933432

Epoch: 6| Step: 13
Training loss: 1.6340241432189941
Validation loss: 2.1392436424891152

Epoch: 292| Step: 0
Training loss: 3.015194892883301
Validation loss: 2.1354547142982483

Epoch: 6| Step: 1
Training loss: 1.821008563041687
Validation loss: 2.1244009534517923

Epoch: 6| Step: 2
Training loss: 1.272377610206604
Validation loss: 2.184881051381429

Epoch: 6| Step: 3
Training loss: 0.83457350730896
Validation loss: 2.1694551507631936

Epoch: 6| Step: 4
Training loss: 1.2214864492416382
Validation loss: 2.1879517237345376

Epoch: 6| Step: 5
Training loss: 2.228250503540039
Validation loss: 2.1864108443260193

Epoch: 6| Step: 6
Training loss: 1.8806520700454712
Validation loss: 2.2016788125038147

Epoch: 6| Step: 7
Training loss: 1.3582457304000854
Validation loss: 2.214505434036255

Epoch: 6| Step: 8
Training loss: 1.3545198440551758
Validation loss: 2.190743406613668

Epoch: 6| Step: 9
Training loss: 0.9598689675331116
Validation loss: 2.1926139195760093

Epoch: 6| Step: 10
Training loss: 0.9253181219100952
Validation loss: 2.1836370825767517

Epoch: 6| Step: 11
Training loss: 1.1544435024261475
Validation loss: 2.151781360308329

Epoch: 6| Step: 12
Training loss: 1.1052510738372803
Validation loss: 2.206048011779785

Epoch: 6| Step: 13
Training loss: 0.9861934781074524
Validation loss: 2.1626992424329123

Epoch: 293| Step: 0
Training loss: 0.9019758701324463
Validation loss: 2.1899588902791343

Epoch: 6| Step: 1
Training loss: 1.6055388450622559
Validation loss: 2.1771342555681863

Epoch: 6| Step: 2
Training loss: 1.1929303407669067
Validation loss: 2.1495241125424704

Epoch: 6| Step: 3
Training loss: 1.0485912561416626
Validation loss: 2.1607906421025596

Epoch: 6| Step: 4
Training loss: 0.8092249631881714
Validation loss: 2.1456297437349954

Epoch: 6| Step: 5
Training loss: 1.9128079414367676
Validation loss: 2.154386361440023

Epoch: 6| Step: 6
Training loss: 1.888720154762268
Validation loss: 2.12732203801473

Epoch: 6| Step: 7
Training loss: 1.551556944847107
Validation loss: 2.1479589541753135

Epoch: 6| Step: 8
Training loss: 2.3243954181671143
Validation loss: 2.1373003323872886

Epoch: 6| Step: 9
Training loss: 1.4874849319458008
Validation loss: 2.1022819876670837

Epoch: 6| Step: 10
Training loss: 1.2991127967834473
Validation loss: 2.139580508073171

Epoch: 6| Step: 11
Training loss: 1.7020493745803833
Validation loss: 2.127812067667643

Epoch: 6| Step: 12
Training loss: 0.7845675945281982
Validation loss: 2.10631787776947

Epoch: 6| Step: 13
Training loss: 1.1468861103057861
Validation loss: 2.132436533768972

Epoch: 294| Step: 0
Training loss: 1.3174784183502197
Validation loss: 2.1482683221499124

Epoch: 6| Step: 1
Training loss: 1.5618078708648682
Validation loss: 2.1672666668891907

Epoch: 6| Step: 2
Training loss: 1.4456778764724731
Validation loss: 2.131264865398407

Epoch: 6| Step: 3
Training loss: 1.080206274986267
Validation loss: 2.1397001345952353

Epoch: 6| Step: 4
Training loss: 1.3306032419204712
Validation loss: 2.140638589859009

Epoch: 6| Step: 5
Training loss: 1.1634609699249268
Validation loss: 2.1399194399515786

Epoch: 6| Step: 6
Training loss: 1.2664289474487305
Validation loss: 2.152520020802816

Epoch: 6| Step: 7
Training loss: 2.5027382373809814
Validation loss: 2.1331650217374167

Epoch: 6| Step: 8
Training loss: 1.730063796043396
Validation loss: 2.192730645338694

Epoch: 6| Step: 9
Training loss: 1.3666832447052002
Validation loss: 2.1475441654523215

Epoch: 6| Step: 10
Training loss: 0.966031551361084
Validation loss: 2.1552652517954507

Epoch: 6| Step: 11
Training loss: 1.5192376375198364
Validation loss: 2.1633358001708984

Epoch: 6| Step: 12
Training loss: 1.6326725482940674
Validation loss: 2.144687990347544

Epoch: 6| Step: 13
Training loss: 1.077897071838379
Validation loss: 2.152978797753652

Epoch: 295| Step: 0
Training loss: 1.4321675300598145
Validation loss: 2.1460516452789307

Epoch: 6| Step: 1
Training loss: 0.8484454154968262
Validation loss: 2.1584124167760215

Epoch: 6| Step: 2
Training loss: 1.5494272708892822
Validation loss: 2.1418129404385886

Epoch: 6| Step: 3
Training loss: 1.0961034297943115
Validation loss: 2.1542617281277976

Epoch: 6| Step: 4
Training loss: 1.398775577545166
Validation loss: 2.1672115127245584

Epoch: 6| Step: 5
Training loss: 2.161193370819092
Validation loss: 2.1859157482783

Epoch: 6| Step: 6
Training loss: 1.1060917377471924
Validation loss: 2.163766086101532

Epoch: 6| Step: 7
Training loss: 1.1920146942138672
Validation loss: 2.168847978115082

Epoch: 6| Step: 8
Training loss: 1.7034509181976318
Validation loss: 2.181864301363627

Epoch: 6| Step: 9
Training loss: 0.9932481050491333
Validation loss: 2.13505220413208

Epoch: 6| Step: 10
Training loss: 1.212958574295044
Validation loss: 2.1561959783236184

Epoch: 6| Step: 11
Training loss: 2.1285769939422607
Validation loss: 2.1298828522364297

Epoch: 6| Step: 12
Training loss: 1.475915551185608
Validation loss: 2.161340296268463

Epoch: 6| Step: 13
Training loss: 1.5702996253967285
Validation loss: 2.162904699643453

Epoch: 296| Step: 0
Training loss: 1.2602603435516357
Validation loss: 2.1607450445493064

Epoch: 6| Step: 1
Training loss: 0.8985198140144348
Validation loss: 2.158903439839681

Epoch: 6| Step: 2
Training loss: 0.9901708960533142
Validation loss: 2.1521878441174827

Epoch: 6| Step: 3
Training loss: 1.3786592483520508
Validation loss: 2.1569316387176514

Epoch: 6| Step: 4
Training loss: 1.762101650238037
Validation loss: 2.148169000943502

Epoch: 6| Step: 5
Training loss: 1.3953553438186646
Validation loss: 2.1590760151545205

Epoch: 6| Step: 6
Training loss: 1.8213682174682617
Validation loss: 2.1383098363876343

Epoch: 6| Step: 7
Training loss: 1.699951410293579
Validation loss: 2.135108311971029

Epoch: 6| Step: 8
Training loss: 1.7115671634674072
Validation loss: 2.146219571431478

Epoch: 6| Step: 9
Training loss: 1.4064602851867676
Validation loss: 2.128184119860331

Epoch: 6| Step: 10
Training loss: 1.104557752609253
Validation loss: 2.1290146112442017

Epoch: 6| Step: 11
Training loss: 1.2589106559753418
Validation loss: 2.1432663202285767

Epoch: 6| Step: 12
Training loss: 1.8556848764419556
Validation loss: 2.159374475479126

Epoch: 6| Step: 13
Training loss: 0.8158624172210693
Validation loss: 2.155283749103546

Epoch: 297| Step: 0
Training loss: 1.6723538637161255
Validation loss: 2.168525815010071

Epoch: 6| Step: 1
Training loss: 1.1361362934112549
Validation loss: 2.1659582058588662

Epoch: 6| Step: 2
Training loss: 1.456554889678955
Validation loss: 2.1413559118906655

Epoch: 6| Step: 3
Training loss: 1.8092525005340576
Validation loss: 2.13768462340037

Epoch: 6| Step: 4
Training loss: 1.6099718809127808
Validation loss: 2.1574889421463013

Epoch: 6| Step: 5
Training loss: 1.5436697006225586
Validation loss: 2.166898508866628

Epoch: 6| Step: 6
Training loss: 1.096364140510559
Validation loss: 2.1682905356089273

Epoch: 6| Step: 7
Training loss: 2.0745880603790283
Validation loss: 2.1742863059043884

Epoch: 6| Step: 8
Training loss: 1.705354928970337
Validation loss: 2.157104750474294

Epoch: 6| Step: 9
Training loss: 1.4489409923553467
Validation loss: 2.1558335026105246

Epoch: 6| Step: 10
Training loss: 1.1698023080825806
Validation loss: 2.1641974250475564

Epoch: 6| Step: 11
Training loss: 1.271860122680664
Validation loss: 2.155467430750529

Epoch: 6| Step: 12
Training loss: 0.8531814217567444
Validation loss: 2.1630659103393555

Epoch: 6| Step: 13
Training loss: 0.9790358543395996
Validation loss: 2.16060209274292

Epoch: 298| Step: 0
Training loss: 1.9122912883758545
Validation loss: 2.1371494134267173

Epoch: 6| Step: 1
Training loss: 1.1711204051971436
Validation loss: 2.15877099831899

Epoch: 6| Step: 2
Training loss: 1.45602285861969
Validation loss: 2.174793561299642

Epoch: 6| Step: 3
Training loss: 1.2637732028961182
Validation loss: 2.1699628631273904

Epoch: 6| Step: 4
Training loss: 1.7925336360931396
Validation loss: 2.141524612903595

Epoch: 6| Step: 5
Training loss: 1.4576539993286133
Validation loss: 2.154887855052948

Epoch: 6| Step: 6
Training loss: 0.9379056096076965
Validation loss: 2.136130392551422

Epoch: 6| Step: 7
Training loss: 1.246890902519226
Validation loss: 2.152170499165853

Epoch: 6| Step: 8
Training loss: 1.1519067287445068
Validation loss: 2.1646787524223328

Epoch: 6| Step: 9
Training loss: 1.5812923908233643
Validation loss: 2.1607930262883506

Epoch: 6| Step: 10
Training loss: 1.3383290767669678
Validation loss: 2.186083217461904

Epoch: 6| Step: 11
Training loss: 0.9996961951255798
Validation loss: 2.2147469321886697

Epoch: 6| Step: 12
Training loss: 1.7971975803375244
Validation loss: 2.1799835562705994

Epoch: 6| Step: 13
Training loss: 1.0549622774124146
Validation loss: 2.181528468926748

Epoch: 299| Step: 0
Training loss: 1.4831769466400146
Validation loss: 2.196150024731954

Epoch: 6| Step: 1
Training loss: 1.432643175125122
Validation loss: 2.1933157046635947

Epoch: 6| Step: 2
Training loss: 1.958704948425293
Validation loss: 2.17902143796285

Epoch: 6| Step: 3
Training loss: 1.2119054794311523
Validation loss: 2.2008460760116577

Epoch: 6| Step: 4
Training loss: 1.3077194690704346
Validation loss: 2.1848572889963784

Epoch: 6| Step: 5
Training loss: 1.062915325164795
Validation loss: 2.196017344792684

Epoch: 6| Step: 6
Training loss: 1.5575629472732544
Validation loss: 2.179124355316162

Epoch: 6| Step: 7
Training loss: 1.3877589702606201
Validation loss: 2.1334343949953714

Epoch: 6| Step: 8
Training loss: 1.3657957315444946
Validation loss: 2.1691729029019675

Epoch: 6| Step: 9
Training loss: 1.089735984802246
Validation loss: 2.1601619720458984

Epoch: 6| Step: 10
Training loss: 1.5601727962493896
Validation loss: 2.1487134099006653

Epoch: 6| Step: 11
Training loss: 1.4359077215194702
Validation loss: 2.1506075263023376

Epoch: 6| Step: 12
Training loss: 1.241495966911316
Validation loss: 2.133627394835154

Epoch: 6| Step: 13
Training loss: 1.245190143585205
Validation loss: 2.1636623541514077

Epoch: 300| Step: 0
Training loss: 1.2445250749588013
Validation loss: 2.1324128111203513

Epoch: 6| Step: 1
Training loss: 1.1293981075286865
Validation loss: 2.1310331424077353

Epoch: 6| Step: 2
Training loss: 1.039179801940918
Validation loss: 2.16951992114385

Epoch: 6| Step: 3
Training loss: 1.0549390316009521
Validation loss: 2.17439212401708

Epoch: 6| Step: 4
Training loss: 1.5428521633148193
Validation loss: 2.156223773956299

Epoch: 6| Step: 5
Training loss: 1.4724798202514648
Validation loss: 2.143784284591675

Epoch: 6| Step: 6
Training loss: 1.3479759693145752
Validation loss: 2.1485277016957602

Epoch: 6| Step: 7
Training loss: 1.9102782011032104
Validation loss: 2.173926373322805

Epoch: 6| Step: 8
Training loss: 1.7237733602523804
Validation loss: 2.147933622201284

Epoch: 6| Step: 9
Training loss: 0.6794434785842896
Validation loss: 2.1876667737960815

Epoch: 6| Step: 10
Training loss: 1.6494462490081787
Validation loss: 2.20102330048879

Epoch: 6| Step: 11
Training loss: 1.2506269216537476
Validation loss: 2.200572987397512

Epoch: 6| Step: 12
Training loss: 1.2200099229812622
Validation loss: 2.2009340723355613

Epoch: 6| Step: 13
Training loss: 1.6481343507766724
Validation loss: 2.2002132336298623

Epoch: 301| Step: 0
Training loss: 0.9165170788764954
Validation loss: 2.1730098128318787

Epoch: 6| Step: 1
Training loss: 1.2880215644836426
Validation loss: 2.1743177572886148

Epoch: 6| Step: 2
Training loss: 0.9140831828117371
Validation loss: 2.177055239677429

Epoch: 6| Step: 3
Training loss: 1.1554841995239258
Validation loss: 2.184380610783895

Epoch: 6| Step: 4
Training loss: 1.3359346389770508
Validation loss: 2.1796829104423523

Epoch: 6| Step: 5
Training loss: 1.7063336372375488
Validation loss: 2.1691162983576455

Epoch: 6| Step: 6
Training loss: 2.0458498001098633
Validation loss: 2.216956933339437

Epoch: 6| Step: 7
Training loss: 1.5214817523956299
Validation loss: 2.1986430486043296

Epoch: 6| Step: 8
Training loss: 0.9033641219139099
Validation loss: 2.1994272073109946

Epoch: 6| Step: 9
Training loss: 1.4909861087799072
Validation loss: 2.170691808064779

Epoch: 6| Step: 10
Training loss: 2.4871575832366943
Validation loss: 2.1416062315305076

Epoch: 6| Step: 11
Training loss: 0.8176237344741821
Validation loss: 2.1435528993606567

Epoch: 6| Step: 12
Training loss: 1.2261892557144165
Validation loss: 2.1278825402259827

Epoch: 6| Step: 13
Training loss: 1.7405555248260498
Validation loss: 2.1530954837799072

Epoch: 302| Step: 0
Training loss: 1.093695878982544
Validation loss: 2.1171346505482993

Epoch: 6| Step: 1
Training loss: 1.8768095970153809
Validation loss: 2.161599636077881

Epoch: 6| Step: 2
Training loss: 0.8631632328033447
Validation loss: 2.1562891006469727

Epoch: 6| Step: 3
Training loss: 0.9418999552726746
Validation loss: 2.1760200659434

Epoch: 6| Step: 4
Training loss: 1.8431205749511719
Validation loss: 2.169792135556539

Epoch: 6| Step: 5
Training loss: 1.5314757823944092
Validation loss: 2.1784865458806357

Epoch: 6| Step: 6
Training loss: 1.0688730478286743
Validation loss: 2.1521641413370767

Epoch: 6| Step: 7
Training loss: 1.1040778160095215
Validation loss: 2.1509587367375693

Epoch: 6| Step: 8
Training loss: 1.6230223178863525
Validation loss: 2.169895271460215

Epoch: 6| Step: 9
Training loss: 0.9159662127494812
Validation loss: 2.1326757868131003

Epoch: 6| Step: 10
Training loss: 1.2861706018447876
Validation loss: 2.1612916588783264

Epoch: 6| Step: 11
Training loss: 2.1327385902404785
Validation loss: 2.1517407099405923

Epoch: 6| Step: 12
Training loss: 1.6714681386947632
Validation loss: 2.171545843283335

Epoch: 6| Step: 13
Training loss: 1.1826599836349487
Validation loss: 2.1439809997876487

Epoch: 303| Step: 0
Training loss: 1.131625771522522
Validation loss: 2.1669360200564065

Epoch: 6| Step: 1
Training loss: 1.2063193321228027
Validation loss: 2.1760250329971313

Epoch: 6| Step: 2
Training loss: 1.48074209690094
Validation loss: 2.1623862783114114

Epoch: 6| Step: 3
Training loss: 1.2872428894042969
Validation loss: 2.196939388910929

Epoch: 6| Step: 4
Training loss: 1.1684634685516357
Validation loss: 2.177935540676117

Epoch: 6| Step: 5
Training loss: 1.6974270343780518
Validation loss: 2.2021066347757974

Epoch: 6| Step: 6
Training loss: 1.1870992183685303
Validation loss: 2.2006889979044595

Epoch: 6| Step: 7
Training loss: 1.2811777591705322
Validation loss: 2.182202617327372

Epoch: 6| Step: 8
Training loss: 1.9085471630096436
Validation loss: 2.2098498344421387

Epoch: 6| Step: 9
Training loss: 1.368070363998413
Validation loss: 2.204592744509379

Epoch: 6| Step: 10
Training loss: 1.4387859106063843
Validation loss: 2.199948271115621

Epoch: 6| Step: 11
Training loss: 0.8946470022201538
Validation loss: 2.1870917280515036

Epoch: 6| Step: 12
Training loss: 1.6239804029464722
Validation loss: 2.1840978860855103

Epoch: 6| Step: 13
Training loss: 0.9807930588722229
Validation loss: 2.2049068411191306

Epoch: 304| Step: 0
Training loss: 1.2485343217849731
Validation loss: 2.1768383383750916

Epoch: 6| Step: 1
Training loss: 1.7162940502166748
Validation loss: 2.131741940975189

Epoch: 6| Step: 2
Training loss: 1.2746262550354004
Validation loss: 2.191930035750071

Epoch: 6| Step: 3
Training loss: 1.0387169122695923
Validation loss: 2.1438461343447366

Epoch: 6| Step: 4
Training loss: 1.5901265144348145
Validation loss: 2.169865449269613

Epoch: 6| Step: 5
Training loss: 1.0693974494934082
Validation loss: 2.1810967723528543

Epoch: 6| Step: 6
Training loss: 0.9070565104484558
Validation loss: 2.1745144526163735

Epoch: 6| Step: 7
Training loss: 1.1415660381317139
Validation loss: 2.145611345767975

Epoch: 6| Step: 8
Training loss: 1.474444031715393
Validation loss: 2.1863768895467124

Epoch: 6| Step: 9
Training loss: 1.178037405014038
Validation loss: 2.1611960530281067

Epoch: 6| Step: 10
Training loss: 1.7230275869369507
Validation loss: 2.172204593817393

Epoch: 6| Step: 11
Training loss: 1.3164080381393433
Validation loss: 2.1802452206611633

Epoch: 6| Step: 12
Training loss: 1.882345199584961
Validation loss: 2.1940545638402305

Epoch: 6| Step: 13
Training loss: 1.1438220739364624
Validation loss: 2.201450228691101

Epoch: 305| Step: 0
Training loss: 1.2773499488830566
Validation loss: 2.2358510494232178

Epoch: 6| Step: 1
Training loss: 1.1403703689575195
Validation loss: 2.236414313316345

Epoch: 6| Step: 2
Training loss: 1.1480257511138916
Validation loss: 2.2207318345705667

Epoch: 6| Step: 3
Training loss: 1.0440467596054077
Validation loss: 2.2285497188568115

Epoch: 6| Step: 4
Training loss: 1.3570396900177002
Validation loss: 2.1929160356521606

Epoch: 6| Step: 5
Training loss: 1.1769912242889404
Validation loss: 2.143187622229258

Epoch: 6| Step: 6
Training loss: 2.1224560737609863
Validation loss: 2.1667163372039795

Epoch: 6| Step: 7
Training loss: 1.109641194343567
Validation loss: 2.172179321448008

Epoch: 6| Step: 8
Training loss: 1.8665692806243896
Validation loss: 2.1727043191591897

Epoch: 6| Step: 9
Training loss: 2.231902837753296
Validation loss: 2.1851770281791687

Epoch: 6| Step: 10
Training loss: 0.9990212321281433
Validation loss: 2.1629868348439536

Epoch: 6| Step: 11
Training loss: 0.9793989658355713
Validation loss: 2.156233767668406

Epoch: 6| Step: 12
Training loss: 1.7779074907302856
Validation loss: 2.1709353725115457

Epoch: 6| Step: 13
Training loss: 1.2688517570495605
Validation loss: 2.1601521372795105

Epoch: 306| Step: 0
Training loss: 0.993569016456604
Validation loss: 2.170674661795298

Epoch: 6| Step: 1
Training loss: 1.5204964876174927
Validation loss: 2.1827319860458374

Epoch: 6| Step: 2
Training loss: 1.692711591720581
Validation loss: 2.176314572493235

Epoch: 6| Step: 3
Training loss: 0.9693498611450195
Validation loss: 2.162548025449117

Epoch: 6| Step: 4
Training loss: 1.4242184162139893
Validation loss: 2.1697776317596436

Epoch: 6| Step: 5
Training loss: 0.941638708114624
Validation loss: 2.1707917849222818

Epoch: 6| Step: 6
Training loss: 0.9812768697738647
Validation loss: 2.154264052708944

Epoch: 6| Step: 7
Training loss: 1.457413673400879
Validation loss: 2.1588467359542847

Epoch: 6| Step: 8
Training loss: 0.9602560997009277
Validation loss: 2.1850129763285318

Epoch: 6| Step: 9
Training loss: 1.245915174484253
Validation loss: 2.183770775794983

Epoch: 6| Step: 10
Training loss: 1.8531134128570557
Validation loss: 2.1675899426142373

Epoch: 6| Step: 11
Training loss: 1.5015990734100342
Validation loss: 2.177371541659037

Epoch: 6| Step: 12
Training loss: 1.7188498973846436
Validation loss: 2.1517717242240906

Epoch: 6| Step: 13
Training loss: 1.5739036798477173
Validation loss: 2.138213813304901

Epoch: 307| Step: 0
Training loss: 1.3374921083450317
Validation loss: 2.184166649977366

Epoch: 6| Step: 1
Training loss: 1.7431137561798096
Validation loss: 2.1383580565452576

Epoch: 6| Step: 2
Training loss: 1.2493958473205566
Validation loss: 2.1410219271977744

Epoch: 6| Step: 3
Training loss: 0.6191756129264832
Validation loss: 2.146256963411967

Epoch: 6| Step: 4
Training loss: 1.2733207941055298
Validation loss: 2.1364741921424866

Epoch: 6| Step: 5
Training loss: 1.7461618185043335
Validation loss: 2.130144933859507

Epoch: 6| Step: 6
Training loss: 1.3935792446136475
Validation loss: 2.142455279827118

Epoch: 6| Step: 7
Training loss: 1.0971777439117432
Validation loss: 2.14397124449412

Epoch: 6| Step: 8
Training loss: 1.5113329887390137
Validation loss: 2.154489358266195

Epoch: 6| Step: 9
Training loss: 0.8020917773246765
Validation loss: 2.150280753771464

Epoch: 6| Step: 10
Training loss: 1.680454134941101
Validation loss: 2.1627416213353476

Epoch: 6| Step: 11
Training loss: 1.230400562286377
Validation loss: 2.152980705102285

Epoch: 6| Step: 12
Training loss: 1.1751693487167358
Validation loss: 2.1692050894101462

Epoch: 6| Step: 13
Training loss: 1.8213207721710205
Validation loss: 2.1893643339474997

Epoch: 308| Step: 0
Training loss: 1.4087164402008057
Validation loss: 2.172641475995382

Epoch: 6| Step: 1
Training loss: 1.1252617835998535
Validation loss: 2.1714368065198264

Epoch: 6| Step: 2
Training loss: 0.7932404279708862
Validation loss: 2.16183610757192

Epoch: 6| Step: 3
Training loss: 1.1105196475982666
Validation loss: 2.1576159795125327

Epoch: 6| Step: 4
Training loss: 1.617159366607666
Validation loss: 2.18305234114329

Epoch: 6| Step: 5
Training loss: 0.846244215965271
Validation loss: 2.20285834868749

Epoch: 6| Step: 6
Training loss: 0.7041448354721069
Validation loss: 2.1634445587793985

Epoch: 6| Step: 7
Training loss: 1.768119215965271
Validation loss: 2.174289027849833

Epoch: 6| Step: 8
Training loss: 1.456249713897705
Validation loss: 2.1951411167780557

Epoch: 6| Step: 9
Training loss: 1.7642139196395874
Validation loss: 2.1495563983917236

Epoch: 6| Step: 10
Training loss: 1.733122706413269
Validation loss: 2.1498529513676963

Epoch: 6| Step: 11
Training loss: 1.6012920141220093
Validation loss: 2.1429635286331177

Epoch: 6| Step: 12
Training loss: 1.191787600517273
Validation loss: 2.1499746839205423

Epoch: 6| Step: 13
Training loss: 1.6321241855621338
Validation loss: 2.139252265294393

Epoch: 309| Step: 0
Training loss: 1.6505405902862549
Validation loss: 2.107612450917562

Epoch: 6| Step: 1
Training loss: 0.9614725708961487
Validation loss: 2.139509995778402

Epoch: 6| Step: 2
Training loss: 1.5403722524642944
Validation loss: 2.154030919075012

Epoch: 6| Step: 3
Training loss: 1.5676276683807373
Validation loss: 2.184385577837626

Epoch: 6| Step: 4
Training loss: 1.3420754671096802
Validation loss: 2.1827223102251687

Epoch: 6| Step: 5
Training loss: 1.572953462600708
Validation loss: 2.1948020656903586

Epoch: 6| Step: 6
Training loss: 1.4414583444595337
Validation loss: 2.2073862552642822

Epoch: 6| Step: 7
Training loss: 0.7542643547058105
Validation loss: 2.1886865893999734

Epoch: 6| Step: 8
Training loss: 1.4188624620437622
Validation loss: 2.1934118270874023

Epoch: 6| Step: 9
Training loss: 1.6097221374511719
Validation loss: 2.2307044665018716

Epoch: 6| Step: 10
Training loss: 1.020167350769043
Validation loss: 2.22215074300766

Epoch: 6| Step: 11
Training loss: 1.2339012622833252
Validation loss: 2.2147671778996787

Epoch: 6| Step: 12
Training loss: 0.9328948855400085
Validation loss: 2.244941234588623

Epoch: 6| Step: 13
Training loss: 1.2146939039230347
Validation loss: 2.214513063430786

Epoch: 310| Step: 0
Training loss: 1.708378791809082
Validation loss: 2.2047173976898193

Epoch: 6| Step: 1
Training loss: 1.564485788345337
Validation loss: 2.2142476638158164

Epoch: 6| Step: 2
Training loss: 1.3958171606063843
Validation loss: 2.16984361410141

Epoch: 6| Step: 3
Training loss: 1.409250259399414
Validation loss: 2.1312106053034463

Epoch: 6| Step: 4
Training loss: 0.9214293360710144
Validation loss: 2.1705650885899863

Epoch: 6| Step: 5
Training loss: 1.5492849349975586
Validation loss: 2.1424102981885276

Epoch: 6| Step: 6
Training loss: 1.4292010068893433
Validation loss: 2.190335472424825

Epoch: 6| Step: 7
Training loss: 1.6278800964355469
Validation loss: 2.1701815327008567

Epoch: 6| Step: 8
Training loss: 1.3303537368774414
Validation loss: 2.163474957148234

Epoch: 6| Step: 9
Training loss: 0.8251552581787109
Validation loss: 2.155600984891256

Epoch: 6| Step: 10
Training loss: 1.1312751770019531
Validation loss: 2.145178953806559

Epoch: 6| Step: 11
Training loss: 1.4282265901565552
Validation loss: 2.14115838209788

Epoch: 6| Step: 12
Training loss: 1.3630043268203735
Validation loss: 2.1573900977770486

Epoch: 6| Step: 13
Training loss: 0.827911376953125
Validation loss: 2.1556440591812134

Epoch: 311| Step: 0
Training loss: 1.5210753679275513
Validation loss: 2.148231347401937

Epoch: 6| Step: 1
Training loss: 0.8294991254806519
Validation loss: 2.1546725829442344

Epoch: 6| Step: 2
Training loss: 1.3456114530563354
Validation loss: 2.1891602675120034

Epoch: 6| Step: 3
Training loss: 1.7205145359039307
Validation loss: 2.2054385940233865

Epoch: 6| Step: 4
Training loss: 0.8741706609725952
Validation loss: 2.1996750235557556

Epoch: 6| Step: 5
Training loss: 1.5955243110656738
Validation loss: 2.235020120938619

Epoch: 6| Step: 6
Training loss: 1.4713172912597656
Validation loss: 2.2072951197624207

Epoch: 6| Step: 7
Training loss: 1.2774786949157715
Validation loss: 2.2049858967463174

Epoch: 6| Step: 8
Training loss: 1.5094826221466064
Validation loss: 2.2039880951245627

Epoch: 6| Step: 9
Training loss: 1.478118658065796
Validation loss: 2.1996421217918396

Epoch: 6| Step: 10
Training loss: 1.2787584066390991
Validation loss: 2.205286145210266

Epoch: 6| Step: 11
Training loss: 1.2163066864013672
Validation loss: 2.1770805517832437

Epoch: 6| Step: 12
Training loss: 1.0830457210540771
Validation loss: 2.139767050743103

Epoch: 6| Step: 13
Training loss: 1.1591219902038574
Validation loss: 2.159205913543701

Epoch: 312| Step: 0
Training loss: 1.3628058433532715
Validation loss: 2.183919986089071

Epoch: 6| Step: 1
Training loss: 1.564164400100708
Validation loss: 2.1671854853630066

Epoch: 6| Step: 2
Training loss: 1.1701126098632812
Validation loss: 2.1652052998542786

Epoch: 6| Step: 3
Training loss: 1.0674710273742676
Validation loss: 2.1628729701042175

Epoch: 6| Step: 4
Training loss: 1.4368336200714111
Validation loss: 2.1442468762397766

Epoch: 6| Step: 5
Training loss: 1.9021917581558228
Validation loss: 2.141831378142039

Epoch: 6| Step: 6
Training loss: 1.2627851963043213
Validation loss: 2.161725719769796

Epoch: 6| Step: 7
Training loss: 1.531874656677246
Validation loss: 2.1739341815312705

Epoch: 6| Step: 8
Training loss: 1.317281723022461
Validation loss: 2.1747619907061257

Epoch: 6| Step: 9
Training loss: 1.490190863609314
Validation loss: 2.1796491543451944

Epoch: 6| Step: 10
Training loss: 0.6826683878898621
Validation loss: 2.1725862423578897

Epoch: 6| Step: 11
Training loss: 1.4064267873764038
Validation loss: 2.186155398686727

Epoch: 6| Step: 12
Training loss: 0.5101042985916138
Validation loss: 2.1747276981671653

Epoch: 6| Step: 13
Training loss: 1.2846767902374268
Validation loss: 2.197430352369944

Epoch: 313| Step: 0
Training loss: 1.1584246158599854
Validation loss: 2.1988117893536887

Epoch: 6| Step: 1
Training loss: 1.275141954421997
Validation loss: 2.1918264627456665

Epoch: 6| Step: 2
Training loss: 1.720841407775879
Validation loss: 2.176325519879659

Epoch: 6| Step: 3
Training loss: 0.8881464600563049
Validation loss: 2.1719795862833657

Epoch: 6| Step: 4
Training loss: 0.8168462514877319
Validation loss: 2.19329841931661

Epoch: 6| Step: 5
Training loss: 1.6063565015792847
Validation loss: 2.206627289454142

Epoch: 6| Step: 6
Training loss: 1.9358431100845337
Validation loss: 2.1736778020858765

Epoch: 6| Step: 7
Training loss: 1.1542181968688965
Validation loss: 2.1530479192733765

Epoch: 6| Step: 8
Training loss: 1.7357265949249268
Validation loss: 2.175373454888662

Epoch: 6| Step: 9
Training loss: 1.8270528316497803
Validation loss: 2.169106125831604

Epoch: 6| Step: 10
Training loss: 1.0008260011672974
Validation loss: 2.174883246421814

Epoch: 6| Step: 11
Training loss: 0.5407813787460327
Validation loss: 2.2074749867121377

Epoch: 6| Step: 12
Training loss: 1.2096319198608398
Validation loss: 2.1867334047953286

Epoch: 6| Step: 13
Training loss: 0.8759307861328125
Validation loss: 2.161957859992981

Epoch: 314| Step: 0
Training loss: 1.7209092378616333
Validation loss: 2.1751030882199607

Epoch: 6| Step: 1
Training loss: 1.1863174438476562
Validation loss: 2.201637864112854

Epoch: 6| Step: 2
Training loss: 1.107452392578125
Validation loss: 2.1891730626424155

Epoch: 6| Step: 3
Training loss: 1.5256836414337158
Validation loss: 2.2053717374801636

Epoch: 6| Step: 4
Training loss: 0.9499944448471069
Validation loss: 2.202984174092611

Epoch: 6| Step: 5
Training loss: 0.9101253151893616
Validation loss: 2.1976955930391946

Epoch: 6| Step: 6
Training loss: 1.3794333934783936
Validation loss: 2.18909345070521

Epoch: 6| Step: 7
Training loss: 1.2933859825134277
Validation loss: 2.172327935695648

Epoch: 6| Step: 8
Training loss: 1.6121841669082642
Validation loss: 2.202665468056997

Epoch: 6| Step: 9
Training loss: 1.8023159503936768
Validation loss: 2.2038551767667136

Epoch: 6| Step: 10
Training loss: 0.9700257778167725
Validation loss: 2.2101722955703735

Epoch: 6| Step: 11
Training loss: 1.5221004486083984
Validation loss: 2.167144497235616

Epoch: 6| Step: 12
Training loss: 1.4145417213439941
Validation loss: 2.1917460759480796

Epoch: 6| Step: 13
Training loss: 0.6894266605377197
Validation loss: 2.1652312676111856

Epoch: 315| Step: 0
Training loss: 0.7724512815475464
Validation loss: 2.179117997487386

Epoch: 6| Step: 1
Training loss: 1.3537603616714478
Validation loss: 2.1564650932947793

Epoch: 6| Step: 2
Training loss: 1.3605024814605713
Validation loss: 2.1664170622825623

Epoch: 6| Step: 3
Training loss: 1.887184739112854
Validation loss: 2.162860174973806

Epoch: 6| Step: 4
Training loss: 1.2227023839950562
Validation loss: 2.1770511666933694

Epoch: 6| Step: 5
Training loss: 1.027916431427002
Validation loss: 2.146761496861776

Epoch: 6| Step: 6
Training loss: 1.5575084686279297
Validation loss: 2.185797095298767

Epoch: 6| Step: 7
Training loss: 1.565638780593872
Validation loss: 2.1920848886171975

Epoch: 6| Step: 8
Training loss: 0.8489425778388977
Validation loss: 2.1953084468841553

Epoch: 6| Step: 9
Training loss: 1.3828513622283936
Validation loss: 2.246118903160095

Epoch: 6| Step: 10
Training loss: 0.920595109462738
Validation loss: 2.2277647852897644

Epoch: 6| Step: 11
Training loss: 1.1769436597824097
Validation loss: 2.2239390214284263

Epoch: 6| Step: 12
Training loss: 1.258596658706665
Validation loss: 2.2097833156585693

Epoch: 6| Step: 13
Training loss: 1.9700710773468018
Validation loss: 2.1854278246561685

Epoch: 316| Step: 0
Training loss: 0.8301382064819336
Validation loss: 2.205036540826162

Epoch: 6| Step: 1
Training loss: 1.555066466331482
Validation loss: 2.162274976571401

Epoch: 6| Step: 2
Training loss: 0.7579028606414795
Validation loss: 2.1614458163579306

Epoch: 6| Step: 3
Training loss: 1.910535216331482
Validation loss: 2.1675907373428345

Epoch: 6| Step: 4
Training loss: 0.9052395820617676
Validation loss: 2.1585676670074463

Epoch: 6| Step: 5
Training loss: 1.1828641891479492
Validation loss: 2.1808237632115683

Epoch: 6| Step: 6
Training loss: 0.8675834536552429
Validation loss: 2.13120706876119

Epoch: 6| Step: 7
Training loss: 2.104323387145996
Validation loss: 2.1607143680254617

Epoch: 6| Step: 8
Training loss: 1.0436434745788574
Validation loss: 2.1799315810203552

Epoch: 6| Step: 9
Training loss: 1.1727961301803589
Validation loss: 2.138266642888387

Epoch: 6| Step: 10
Training loss: 1.0382403135299683
Validation loss: 2.168325920899709

Epoch: 6| Step: 11
Training loss: 2.0123794078826904
Validation loss: 2.1926357547442117

Epoch: 6| Step: 12
Training loss: 1.0392704010009766
Validation loss: 2.196446160475413

Epoch: 6| Step: 13
Training loss: 1.9892592430114746
Validation loss: 2.194104174772898

Epoch: 317| Step: 0
Training loss: 1.3483014106750488
Validation loss: 2.1727861563364663

Epoch: 6| Step: 1
Training loss: 1.353057622909546
Validation loss: 2.168286085128784

Epoch: 6| Step: 2
Training loss: 1.0327415466308594
Validation loss: 2.176698168118795

Epoch: 6| Step: 3
Training loss: 0.9893596768379211
Validation loss: 2.179599126180013

Epoch: 6| Step: 4
Training loss: 1.575537919998169
Validation loss: 2.181981305281321

Epoch: 6| Step: 5
Training loss: 1.1994848251342773
Validation loss: 2.1876779397328696

Epoch: 6| Step: 6
Training loss: 1.460148572921753
Validation loss: 2.190718491872152

Epoch: 6| Step: 7
Training loss: 1.8743834495544434
Validation loss: 2.2109505335489907

Epoch: 6| Step: 8
Training loss: 0.8763150572776794
Validation loss: 2.128840446472168

Epoch: 6| Step: 9
Training loss: 0.9618661403656006
Validation loss: 2.200223763783773

Epoch: 6| Step: 10
Training loss: 0.7915850281715393
Validation loss: 2.1495139598846436

Epoch: 6| Step: 11
Training loss: 1.7339699268341064
Validation loss: 2.183481136957804

Epoch: 6| Step: 12
Training loss: 1.257959246635437
Validation loss: 2.1521244049072266

Epoch: 6| Step: 13
Training loss: 1.302889108657837
Validation loss: 2.155229945977529

Epoch: 318| Step: 0
Training loss: 1.2712132930755615
Validation loss: 2.1489655574162803

Epoch: 6| Step: 1
Training loss: 1.6189852952957153
Validation loss: 2.1590439279874167

Epoch: 6| Step: 2
Training loss: 1.752120852470398
Validation loss: 2.135804057121277

Epoch: 6| Step: 3
Training loss: 1.1076292991638184
Validation loss: 2.1624963084856668

Epoch: 6| Step: 4
Training loss: 0.6738637685775757
Validation loss: 2.1157071590423584

Epoch: 6| Step: 5
Training loss: 1.4769376516342163
Validation loss: 2.136758248011271

Epoch: 6| Step: 6
Training loss: 1.4422396421432495
Validation loss: 2.1581457455952964

Epoch: 6| Step: 7
Training loss: 1.839963436126709
Validation loss: 2.1233921448389688

Epoch: 6| Step: 8
Training loss: 0.5875622034072876
Validation loss: 2.1075093746185303

Epoch: 6| Step: 9
Training loss: 1.3715202808380127
Validation loss: 2.1238685647646585

Epoch: 6| Step: 10
Training loss: 1.2893519401550293
Validation loss: 2.1617985566457114

Epoch: 6| Step: 11
Training loss: 0.9246392250061035
Validation loss: 2.121985693772634

Epoch: 6| Step: 12
Training loss: 1.2325317859649658
Validation loss: 2.148223340511322

Epoch: 6| Step: 13
Training loss: 1.4489480257034302
Validation loss: 2.17575337489446

Epoch: 319| Step: 0
Training loss: 2.0367085933685303
Validation loss: 2.172139823436737

Epoch: 6| Step: 1
Training loss: 1.5321235656738281
Validation loss: 2.130950669447581

Epoch: 6| Step: 2
Training loss: 0.6720061302185059
Validation loss: 2.1652414798736572

Epoch: 6| Step: 3
Training loss: 0.9849874973297119
Validation loss: 2.144474466641744

Epoch: 6| Step: 4
Training loss: 1.2076084613800049
Validation loss: 2.1319174766540527

Epoch: 6| Step: 5
Training loss: 1.4601850509643555
Validation loss: 2.1487043698628745

Epoch: 6| Step: 6
Training loss: 1.9414074420928955
Validation loss: 2.158125956853231

Epoch: 6| Step: 7
Training loss: 0.7147241234779358
Validation loss: 2.1567445198694863

Epoch: 6| Step: 8
Training loss: 0.6417946219444275
Validation loss: 2.138273378213247

Epoch: 6| Step: 9
Training loss: 1.0685728788375854
Validation loss: 2.1440407832463584

Epoch: 6| Step: 10
Training loss: 1.1048390865325928
Validation loss: 2.1268978118896484

Epoch: 6| Step: 11
Training loss: 1.6140005588531494
Validation loss: 2.187058707078298

Epoch: 6| Step: 12
Training loss: 0.9895672798156738
Validation loss: 2.1880751053492227

Epoch: 6| Step: 13
Training loss: 1.6330039501190186
Validation loss: 2.1824828386306763

Epoch: 320| Step: 0
Training loss: 1.3948683738708496
Validation loss: 2.1763636668523154

Epoch: 6| Step: 1
Training loss: 1.292834758758545
Validation loss: 2.182651937007904

Epoch: 6| Step: 2
Training loss: 1.7501362562179565
Validation loss: 2.2149704694747925

Epoch: 6| Step: 3
Training loss: 0.9842287302017212
Validation loss: 2.1812785466512046

Epoch: 6| Step: 4
Training loss: 1.2779481410980225
Validation loss: 2.2116803328196206

Epoch: 6| Step: 5
Training loss: 1.3280737400054932
Validation loss: 2.205868422985077

Epoch: 6| Step: 6
Training loss: 1.2399743795394897
Validation loss: 2.2330474654833474

Epoch: 6| Step: 7
Training loss: 0.9594203233718872
Validation loss: 2.170624832312266

Epoch: 6| Step: 8
Training loss: 0.8903801441192627
Validation loss: 2.1495026548703513

Epoch: 6| Step: 9
Training loss: 1.2406386137008667
Validation loss: 2.1535335183143616

Epoch: 6| Step: 10
Training loss: 0.8140479326248169
Validation loss: 2.1604997714360556

Epoch: 6| Step: 11
Training loss: 1.6495656967163086
Validation loss: 2.173667073249817

Epoch: 6| Step: 12
Training loss: 1.6350657939910889
Validation loss: 2.121572494506836

Epoch: 6| Step: 13
Training loss: 0.75664883852005
Validation loss: 2.1259620785713196

Epoch: 321| Step: 0
Training loss: 0.904242992401123
Validation loss: 2.1381854017575583

Epoch: 6| Step: 1
Training loss: 1.131026268005371
Validation loss: 2.1385290026664734

Epoch: 6| Step: 2
Training loss: 2.0811927318573
Validation loss: 2.1637158195177713

Epoch: 6| Step: 3
Training loss: 1.1969106197357178
Validation loss: 2.1822738647460938

Epoch: 6| Step: 4
Training loss: 1.4191895723342896
Validation loss: 2.1725401480992637

Epoch: 6| Step: 5
Training loss: 0.5078539848327637
Validation loss: 2.179868678251902

Epoch: 6| Step: 6
Training loss: 0.8046653270721436
Validation loss: 2.214572032292684

Epoch: 6| Step: 7
Training loss: 1.5946992635726929
Validation loss: 2.2162925004959106

Epoch: 6| Step: 8
Training loss: 1.8321247100830078
Validation loss: 2.188392400741577

Epoch: 6| Step: 9
Training loss: 0.9470721483230591
Validation loss: 2.196248769760132

Epoch: 6| Step: 10
Training loss: 1.154355764389038
Validation loss: 2.2265111605326333

Epoch: 6| Step: 11
Training loss: 1.37055504322052
Validation loss: 2.2225481271743774

Epoch: 6| Step: 12
Training loss: 1.4012281894683838
Validation loss: 2.201477070649465

Epoch: 6| Step: 13
Training loss: 0.9113161563873291
Validation loss: 2.213880737622579

Epoch: 322| Step: 0
Training loss: 1.2961852550506592
Validation loss: 2.2024136185646057

Epoch: 6| Step: 1
Training loss: 1.0459632873535156
Validation loss: 2.1738013426462808

Epoch: 6| Step: 2
Training loss: 1.5988142490386963
Validation loss: 2.1861552794774375

Epoch: 6| Step: 3
Training loss: 1.6303608417510986
Validation loss: 2.207888642946879

Epoch: 6| Step: 4
Training loss: 1.3231582641601562
Validation loss: 2.205561796824137

Epoch: 6| Step: 5
Training loss: 0.8727585673332214
Validation loss: 2.195571700731913

Epoch: 6| Step: 6
Training loss: 1.3805100917816162
Validation loss: 2.1828957398732505

Epoch: 6| Step: 7
Training loss: 0.8677520155906677
Validation loss: 2.1929179628690085

Epoch: 6| Step: 8
Training loss: 1.0155037641525269
Validation loss: 2.21088707447052

Epoch: 6| Step: 9
Training loss: 1.3388416767120361
Validation loss: 2.191396435101827

Epoch: 6| Step: 10
Training loss: 1.6089242696762085
Validation loss: 2.183411419391632

Epoch: 6| Step: 11
Training loss: 1.0114233493804932
Validation loss: 2.194294889767965

Epoch: 6| Step: 12
Training loss: 1.0270044803619385
Validation loss: 2.1769447525342307

Epoch: 6| Step: 13
Training loss: 0.7859677076339722
Validation loss: 2.1757819056510925

Epoch: 323| Step: 0
Training loss: 1.3805437088012695
Validation loss: 2.186106046040853

Epoch: 6| Step: 1
Training loss: 0.8416591882705688
Validation loss: 2.160334845383962

Epoch: 6| Step: 2
Training loss: 1.4248290061950684
Validation loss: 2.1819496552149453

Epoch: 6| Step: 3
Training loss: 0.6654274463653564
Validation loss: 2.156581699848175

Epoch: 6| Step: 4
Training loss: 2.149570941925049
Validation loss: 2.160636087258657

Epoch: 6| Step: 5
Training loss: 0.9803272485733032
Validation loss: 2.16877673069636

Epoch: 6| Step: 6
Training loss: 1.3856902122497559
Validation loss: 2.16620941956838

Epoch: 6| Step: 7
Training loss: 1.3186200857162476
Validation loss: 2.1420345306396484

Epoch: 6| Step: 8
Training loss: 1.1887459754943848
Validation loss: 2.141869227091471

Epoch: 6| Step: 9
Training loss: 0.9648191928863525
Validation loss: 2.157212177912394

Epoch: 6| Step: 10
Training loss: 1.3649849891662598
Validation loss: 2.1295567750930786

Epoch: 6| Step: 11
Training loss: 1.2288830280303955
Validation loss: 2.1853264768918357

Epoch: 6| Step: 12
Training loss: 1.4410958290100098
Validation loss: 2.153712491194407

Epoch: 6| Step: 13
Training loss: 0.8018302321434021
Validation loss: 2.176855762799581

Epoch: 324| Step: 0
Training loss: 0.7434219121932983
Validation loss: 2.1706456343332925

Epoch: 6| Step: 1
Training loss: 1.3093326091766357
Validation loss: 2.1902323762575784

Epoch: 6| Step: 2
Training loss: 1.9919061660766602
Validation loss: 2.17477023601532

Epoch: 6| Step: 3
Training loss: 1.0934522151947021
Validation loss: 2.1679765780766806

Epoch: 6| Step: 4
Training loss: 0.7237715721130371
Validation loss: 2.1578034361203513

Epoch: 6| Step: 5
Training loss: 1.3020721673965454
Validation loss: 2.1413525144259133

Epoch: 6| Step: 6
Training loss: 1.5837795734405518
Validation loss: 2.1667091647783914

Epoch: 6| Step: 7
Training loss: 1.135206937789917
Validation loss: 2.170713027318319

Epoch: 6| Step: 8
Training loss: 0.8862093091011047
Validation loss: 2.179675062497457

Epoch: 6| Step: 9
Training loss: 1.2277997732162476
Validation loss: 2.1543444395065308

Epoch: 6| Step: 10
Training loss: 0.9297735691070557
Validation loss: 2.2058156530062356

Epoch: 6| Step: 11
Training loss: 0.9165511727333069
Validation loss: 2.1712116797765098

Epoch: 6| Step: 12
Training loss: 2.2678143978118896
Validation loss: 2.1799872318903604

Epoch: 6| Step: 13
Training loss: 0.7120834589004517
Validation loss: 2.182148893674215

Epoch: 325| Step: 0
Training loss: 0.7183876037597656
Validation loss: 2.1948698361714682

Epoch: 6| Step: 1
Training loss: 1.3635166883468628
Validation loss: 2.2083028753598533

Epoch: 6| Step: 2
Training loss: 1.5294800996780396
Validation loss: 2.2212218046188354

Epoch: 6| Step: 3
Training loss: 1.1577256917953491
Validation loss: 2.224731127421061

Epoch: 6| Step: 4
Training loss: 1.61879301071167
Validation loss: 2.2347753047943115

Epoch: 6| Step: 5
Training loss: 1.1447957754135132
Validation loss: 2.2460979223251343

Epoch: 6| Step: 6
Training loss: 1.3059943914413452
Validation loss: 2.23011181751887

Epoch: 6| Step: 7
Training loss: 1.1385152339935303
Validation loss: 2.2324783404668174

Epoch: 6| Step: 8
Training loss: 1.3385334014892578
Validation loss: 2.198898752530416

Epoch: 6| Step: 9
Training loss: 1.2661938667297363
Validation loss: 2.1890193621317544

Epoch: 6| Step: 10
Training loss: 1.0837498903274536
Validation loss: 2.1991531451543174

Epoch: 6| Step: 11
Training loss: 0.6308472156524658
Validation loss: 2.1972909569740295

Epoch: 6| Step: 12
Training loss: 1.4929016828536987
Validation loss: 2.211217145125071

Epoch: 6| Step: 13
Training loss: 0.8780865669250488
Validation loss: 2.1831071774164834

Epoch: 326| Step: 0
Training loss: 1.1787326335906982
Validation loss: 2.1541751821835837

Epoch: 6| Step: 1
Training loss: 1.135215163230896
Validation loss: 2.183740278085073

Epoch: 6| Step: 2
Training loss: 1.061845064163208
Validation loss: 2.1733538111050925

Epoch: 6| Step: 3
Training loss: 1.3319419622421265
Validation loss: 2.1752399802207947

Epoch: 6| Step: 4
Training loss: 1.3463376760482788
Validation loss: 2.192055583000183

Epoch: 6| Step: 5
Training loss: 1.083228349685669
Validation loss: 2.157085955142975

Epoch: 6| Step: 6
Training loss: 0.8943005800247192
Validation loss: 2.206581731637319

Epoch: 6| Step: 7
Training loss: 1.0052554607391357
Validation loss: 2.1864821712176004

Epoch: 6| Step: 8
Training loss: 0.9672662019729614
Validation loss: 2.195766886075338

Epoch: 6| Step: 9
Training loss: 1.455153226852417
Validation loss: 2.1837328672409058

Epoch: 6| Step: 10
Training loss: 1.7545937299728394
Validation loss: 2.1810807585716248

Epoch: 6| Step: 11
Training loss: 0.9237488508224487
Validation loss: 2.1919628381729126

Epoch: 6| Step: 12
Training loss: 1.2127087116241455
Validation loss: 2.181390106678009

Epoch: 6| Step: 13
Training loss: 1.427659273147583
Validation loss: 2.1740169127782187

Epoch: 327| Step: 0
Training loss: 0.8957723379135132
Validation loss: 2.190807561079661

Epoch: 6| Step: 1
Training loss: 0.8474478721618652
Validation loss: 2.1614962816238403

Epoch: 6| Step: 2
Training loss: 1.2018488645553589
Validation loss: 2.169506072998047

Epoch: 6| Step: 3
Training loss: 1.0810678005218506
Validation loss: 2.158435662587484

Epoch: 6| Step: 4
Training loss: 1.605313777923584
Validation loss: 2.146922687689463

Epoch: 6| Step: 5
Training loss: 1.5138274431228638
Validation loss: 2.1681140661239624

Epoch: 6| Step: 6
Training loss: 1.3291306495666504
Validation loss: 2.154955585797628

Epoch: 6| Step: 7
Training loss: 0.7335858345031738
Validation loss: 2.1367016434669495

Epoch: 6| Step: 8
Training loss: 1.3196923732757568
Validation loss: 2.195656140645345

Epoch: 6| Step: 9
Training loss: 1.849658727645874
Validation loss: 2.176066517829895

Epoch: 6| Step: 10
Training loss: 0.9629110097885132
Validation loss: 2.178941011428833

Epoch: 6| Step: 11
Training loss: 1.6806776523590088
Validation loss: 2.1467377742131553

Epoch: 6| Step: 12
Training loss: 1.0476523637771606
Validation loss: 2.1595643758773804

Epoch: 6| Step: 13
Training loss: 1.0435290336608887
Validation loss: 2.194394588470459

Epoch: 328| Step: 0
Training loss: 2.456386089324951
Validation loss: 2.1309618949890137

Epoch: 6| Step: 1
Training loss: 1.9676761627197266
Validation loss: 2.149469534556071

Epoch: 6| Step: 2
Training loss: 1.4934743642807007
Validation loss: 2.2024409572283425

Epoch: 6| Step: 3
Training loss: 1.5144625902175903
Validation loss: 2.201126754283905

Epoch: 6| Step: 4
Training loss: 1.2654757499694824
Validation loss: 2.1920586625734964

Epoch: 6| Step: 5
Training loss: 1.1857846975326538
Validation loss: 2.2115527788798013

Epoch: 6| Step: 6
Training loss: 0.7466628551483154
Validation loss: 2.2189824183781943

Epoch: 6| Step: 7
Training loss: 0.859286367893219
Validation loss: 2.2394909858703613

Epoch: 6| Step: 8
Training loss: 0.7261608839035034
Validation loss: 2.250592847665151

Epoch: 6| Step: 9
Training loss: 0.958463191986084
Validation loss: 2.217443307240804

Epoch: 6| Step: 10
Training loss: 1.065285325050354
Validation loss: 2.195494373639425

Epoch: 6| Step: 11
Training loss: 1.2895228862762451
Validation loss: 2.18044775724411

Epoch: 6| Step: 12
Training loss: 0.6255828142166138
Validation loss: 2.177330811818441

Epoch: 6| Step: 13
Training loss: 1.035757064819336
Validation loss: 2.1725767850875854

Epoch: 329| Step: 0
Training loss: 1.8379210233688354
Validation loss: 2.2018457452456155

Epoch: 6| Step: 1
Training loss: 1.160355806350708
Validation loss: 2.1849781274795532

Epoch: 6| Step: 2
Training loss: 1.3758717775344849
Validation loss: 2.1747618317604065

Epoch: 6| Step: 3
Training loss: 0.7947086691856384
Validation loss: 2.1651274959246316

Epoch: 6| Step: 4
Training loss: 1.0516459941864014
Validation loss: 2.155602594216665

Epoch: 6| Step: 5
Training loss: 1.4367263317108154
Validation loss: 2.1439348459243774

Epoch: 6| Step: 6
Training loss: 0.6134669780731201
Validation loss: 2.142035722732544

Epoch: 6| Step: 7
Training loss: 1.3062620162963867
Validation loss: 2.153306166330973

Epoch: 6| Step: 8
Training loss: 1.0569208860397339
Validation loss: 2.1476380427678428

Epoch: 6| Step: 9
Training loss: 0.66801917552948
Validation loss: 2.144936740398407

Epoch: 6| Step: 10
Training loss: 2.0608339309692383
Validation loss: 2.114351491133372

Epoch: 6| Step: 11
Training loss: 1.0799763202667236
Validation loss: 2.144544243812561

Epoch: 6| Step: 12
Training loss: 0.9585590958595276
Validation loss: 2.1434171199798584

Epoch: 6| Step: 13
Training loss: 1.6762380599975586
Validation loss: 2.14370459318161

Epoch: 330| Step: 0
Training loss: 1.4010206460952759
Validation loss: 2.1296979983647666

Epoch: 6| Step: 1
Training loss: 0.8816012740135193
Validation loss: 2.1208038330078125

Epoch: 6| Step: 2
Training loss: 1.1498408317565918
Validation loss: 2.1361926396687827

Epoch: 6| Step: 3
Training loss: 1.1051719188690186
Validation loss: 2.1572087009747825

Epoch: 6| Step: 4
Training loss: 0.6437634229660034
Validation loss: 2.187750299771627

Epoch: 6| Step: 5
Training loss: 0.894161581993103
Validation loss: 2.126424511273702

Epoch: 6| Step: 6
Training loss: 1.4042167663574219
Validation loss: 2.191600183645884

Epoch: 6| Step: 7
Training loss: 1.0485049486160278
Validation loss: 2.1882717609405518

Epoch: 6| Step: 8
Training loss: 1.1096553802490234
Validation loss: 2.199558913707733

Epoch: 6| Step: 9
Training loss: 1.0932406187057495
Validation loss: 2.180575668811798

Epoch: 6| Step: 10
Training loss: 1.3017545938491821
Validation loss: 2.212616185347239

Epoch: 6| Step: 11
Training loss: 2.258481979370117
Validation loss: 2.207438071568807

Epoch: 6| Step: 12
Training loss: 0.8278517723083496
Validation loss: 2.1948421001434326

Epoch: 6| Step: 13
Training loss: 1.5141123533248901
Validation loss: 2.216779907544454

Epoch: 331| Step: 0
Training loss: 1.2719014883041382
Validation loss: 2.223298887411753

Epoch: 6| Step: 1
Training loss: 1.3590087890625
Validation loss: 2.2212088902791343

Epoch: 6| Step: 2
Training loss: 1.1949121952056885
Validation loss: 2.230980694293976

Epoch: 6| Step: 3
Training loss: 1.1910157203674316
Validation loss: 2.15916113058726

Epoch: 6| Step: 4
Training loss: 0.4749438464641571
Validation loss: 2.197374939918518

Epoch: 6| Step: 5
Training loss: 0.9849051237106323
Validation loss: 2.1997245152791343

Epoch: 6| Step: 6
Training loss: 1.1976401805877686
Validation loss: 2.19099227587382

Epoch: 6| Step: 7
Training loss: 1.6809132099151611
Validation loss: 2.255536198616028

Epoch: 6| Step: 8
Training loss: 0.6967483162879944
Validation loss: 2.213460385799408

Epoch: 6| Step: 9
Training loss: 2.2134923934936523
Validation loss: 2.2085677782694497

Epoch: 6| Step: 10
Training loss: 1.6434177160263062
Validation loss: 2.192724565664927

Epoch: 6| Step: 11
Training loss: 0.8378610014915466
Validation loss: 2.195232093334198

Epoch: 6| Step: 12
Training loss: 0.9354381561279297
Validation loss: 2.224099099636078

Epoch: 6| Step: 13
Training loss: 1.0829099416732788
Validation loss: 2.2228571573893228

Epoch: 332| Step: 0
Training loss: 1.1531741619110107
Validation loss: 2.2651427189509072

Epoch: 6| Step: 1
Training loss: 1.2954261302947998
Validation loss: 2.23811928431193

Epoch: 6| Step: 2
Training loss: 1.319946527481079
Validation loss: 2.280407945315043

Epoch: 6| Step: 3
Training loss: 1.1545078754425049
Validation loss: 2.226394752661387

Epoch: 6| Step: 4
Training loss: 1.038548231124878
Validation loss: 2.274469276269277

Epoch: 6| Step: 5
Training loss: 1.5126936435699463
Validation loss: 2.1872947812080383

Epoch: 6| Step: 6
Training loss: 0.7010926008224487
Validation loss: 2.232906937599182

Epoch: 6| Step: 7
Training loss: 1.059863805770874
Validation loss: 2.2053842544555664

Epoch: 6| Step: 8
Training loss: 1.1270394325256348
Validation loss: 2.2177265087763467

Epoch: 6| Step: 9
Training loss: 1.2903497219085693
Validation loss: 2.1970237096150718

Epoch: 6| Step: 10
Training loss: 2.47231388092041
Validation loss: 2.188573877016703

Epoch: 6| Step: 11
Training loss: 0.7890923619270325
Validation loss: 2.1862436532974243

Epoch: 6| Step: 12
Training loss: 0.950407862663269
Validation loss: 2.1973705291748047

Epoch: 6| Step: 13
Training loss: 0.9753289818763733
Validation loss: 2.176245391368866

Epoch: 333| Step: 0
Training loss: 1.5163336992263794
Validation loss: 2.1824578245480857

Epoch: 6| Step: 1
Training loss: 1.3860034942626953
Validation loss: 2.1555152336756387

Epoch: 6| Step: 2
Training loss: 0.5813186168670654
Validation loss: 2.155151923497518

Epoch: 6| Step: 3
Training loss: 0.8321092128753662
Validation loss: 2.1596879959106445

Epoch: 6| Step: 4
Training loss: 0.8312815427780151
Validation loss: 2.12628444035848

Epoch: 6| Step: 5
Training loss: 0.6675021052360535
Validation loss: 2.0921223759651184

Epoch: 6| Step: 6
Training loss: 1.431029200553894
Validation loss: 2.1262992223103843

Epoch: 6| Step: 7
Training loss: 1.1966984272003174
Validation loss: 2.133789082368215

Epoch: 6| Step: 8
Training loss: 0.9081377387046814
Validation loss: 2.144979556401571

Epoch: 6| Step: 9
Training loss: 1.5103965997695923
Validation loss: 2.108423411846161

Epoch: 6| Step: 10
Training loss: 1.1718628406524658
Validation loss: 2.1129462321599326

Epoch: 6| Step: 11
Training loss: 1.3363802433013916
Validation loss: 2.111525019009908

Epoch: 6| Step: 12
Training loss: 1.633690357208252
Validation loss: 2.0667455991109214

Epoch: 6| Step: 13
Training loss: 1.1258606910705566
Validation loss: 2.1057018438975015

Epoch: 334| Step: 0
Training loss: 0.8323529958724976
Validation loss: 2.0903929074605307

Epoch: 6| Step: 1
Training loss: 1.106501579284668
Validation loss: 2.14471842845281

Epoch: 6| Step: 2
Training loss: 1.6457750797271729
Validation loss: 2.15095853805542

Epoch: 6| Step: 3
Training loss: 1.4220867156982422
Validation loss: 2.1400723854700723

Epoch: 6| Step: 4
Training loss: 1.0791043043136597
Validation loss: 2.1484711170196533

Epoch: 6| Step: 5
Training loss: 1.2940723896026611
Validation loss: 2.139833231767019

Epoch: 6| Step: 6
Training loss: 1.2417666912078857
Validation loss: 2.1664061347643533

Epoch: 6| Step: 7
Training loss: 1.15379798412323
Validation loss: 2.156774659951528

Epoch: 6| Step: 8
Training loss: 0.727557361125946
Validation loss: 2.1460022727648416

Epoch: 6| Step: 9
Training loss: 1.2337353229522705
Validation loss: 2.183802823225657

Epoch: 6| Step: 10
Training loss: 1.579787015914917
Validation loss: 2.158094306786855

Epoch: 6| Step: 11
Training loss: 1.0749765634536743
Validation loss: 2.1341270208358765

Epoch: 6| Step: 12
Training loss: 0.806122362613678
Validation loss: 2.196972072124481

Epoch: 6| Step: 13
Training loss: 1.1121678352355957
Validation loss: 2.1891659696896872

Epoch: 335| Step: 0
Training loss: 0.8303751945495605
Validation loss: 2.23393706480662

Epoch: 6| Step: 1
Training loss: 0.9027420282363892
Validation loss: 2.2176398634910583

Epoch: 6| Step: 2
Training loss: 0.9883661866188049
Validation loss: 2.2158868114153543

Epoch: 6| Step: 3
Training loss: 0.7955114841461182
Validation loss: 2.1855120062828064

Epoch: 6| Step: 4
Training loss: 1.0167744159698486
Validation loss: 2.1884069442749023

Epoch: 6| Step: 5
Training loss: 0.8571778535842896
Validation loss: 2.208317458629608

Epoch: 6| Step: 6
Training loss: 1.2018499374389648
Validation loss: 2.207037111123403

Epoch: 6| Step: 7
Training loss: 1.3980375528335571
Validation loss: 2.1822394132614136

Epoch: 6| Step: 8
Training loss: 1.3460619449615479
Validation loss: 2.185533086458842

Epoch: 6| Step: 9
Training loss: 0.8724266290664673
Validation loss: 2.1856157978375754

Epoch: 6| Step: 10
Training loss: 0.9805487394332886
Validation loss: 2.1667842666308084

Epoch: 6| Step: 11
Training loss: 1.7373287677764893
Validation loss: 2.1630433797836304

Epoch: 6| Step: 12
Training loss: 1.7977756261825562
Validation loss: 2.1848315397898355

Epoch: 6| Step: 13
Training loss: 1.3543658256530762
Validation loss: 2.1584446827570596

Epoch: 336| Step: 0
Training loss: 0.9980860352516174
Validation loss: 2.1632123986879983

Epoch: 6| Step: 1
Training loss: 0.7644676566123962
Validation loss: 2.1866794427235923

Epoch: 6| Step: 2
Training loss: 0.644904375076294
Validation loss: 2.1759986877441406

Epoch: 6| Step: 3
Training loss: 1.4606058597564697
Validation loss: 2.2129228115081787

Epoch: 6| Step: 4
Training loss: 1.3086646795272827
Validation loss: 2.1761167645454407

Epoch: 6| Step: 5
Training loss: 1.1213243007659912
Validation loss: 2.163819114367167

Epoch: 6| Step: 6
Training loss: 1.463325023651123
Validation loss: 2.1617983182271323

Epoch: 6| Step: 7
Training loss: 0.9366649985313416
Validation loss: 2.1973323623339334

Epoch: 6| Step: 8
Training loss: 1.5763964653015137
Validation loss: 2.2132029136021933

Epoch: 6| Step: 9
Training loss: 1.4419645071029663
Validation loss: 2.2345725496610007

Epoch: 6| Step: 10
Training loss: 1.0987859964370728
Validation loss: 2.203635275363922

Epoch: 6| Step: 11
Training loss: 1.3009953498840332
Validation loss: 2.2357308665911355

Epoch: 6| Step: 12
Training loss: 0.7713810801506042
Validation loss: 2.2313873370488486

Epoch: 6| Step: 13
Training loss: 1.2214584350585938
Validation loss: 2.2172198494275412

Epoch: 337| Step: 0
Training loss: 1.410876989364624
Validation loss: 2.2850550413131714

Epoch: 6| Step: 1
Training loss: 1.1656897068023682
Validation loss: 2.275819698969523

Epoch: 6| Step: 2
Training loss: 1.0329864025115967
Validation loss: 2.2502488096555076

Epoch: 6| Step: 3
Training loss: 1.2325060367584229
Validation loss: 2.2636749347050986

Epoch: 6| Step: 4
Training loss: 1.4635263681411743
Validation loss: 2.2507912516593933

Epoch: 6| Step: 5
Training loss: 1.1858259439468384
Validation loss: 2.2482260862986245

Epoch: 6| Step: 6
Training loss: 1.4203928709030151
Validation loss: 2.239104231198629

Epoch: 6| Step: 7
Training loss: 0.7369615435600281
Validation loss: 2.213163912296295

Epoch: 6| Step: 8
Training loss: 0.9793538451194763
Validation loss: 2.2277453740437827

Epoch: 6| Step: 9
Training loss: 1.1218793392181396
Validation loss: 2.2204816738764444

Epoch: 6| Step: 10
Training loss: 1.3847761154174805
Validation loss: 2.241615335146586

Epoch: 6| Step: 11
Training loss: 1.2326794862747192
Validation loss: 2.2057496706644693

Epoch: 6| Step: 12
Training loss: 0.7833479642868042
Validation loss: 2.221807897090912

Epoch: 6| Step: 13
Training loss: 1.2674202919006348
Validation loss: 2.234624723593394

Epoch: 338| Step: 0
Training loss: 0.6752158403396606
Validation loss: 2.2278898557027182

Epoch: 6| Step: 1
Training loss: 0.6053085327148438
Validation loss: 2.2135979930559793

Epoch: 6| Step: 2
Training loss: 1.426927924156189
Validation loss: 2.2221568624178567

Epoch: 6| Step: 3
Training loss: 1.4798635244369507
Validation loss: 2.2088637153307595

Epoch: 6| Step: 4
Training loss: 0.7745365500450134
Validation loss: 2.195245683193207

Epoch: 6| Step: 5
Training loss: 0.7933180332183838
Validation loss: 2.2255197167396545

Epoch: 6| Step: 6
Training loss: 0.8860023021697998
Validation loss: 2.2295209169387817

Epoch: 6| Step: 7
Training loss: 0.8600528240203857
Validation loss: 2.236312131086985

Epoch: 6| Step: 8
Training loss: 1.9819707870483398
Validation loss: 2.2307281692822776

Epoch: 6| Step: 9
Training loss: 1.1244397163391113
Validation loss: 2.2513370315233865

Epoch: 6| Step: 10
Training loss: 0.7149040699005127
Validation loss: 2.2382582227389016

Epoch: 6| Step: 11
Training loss: 1.4178873300552368
Validation loss: 2.233121077219645

Epoch: 6| Step: 12
Training loss: 1.5825456380844116
Validation loss: 2.2245933612187705

Epoch: 6| Step: 13
Training loss: 1.4791576862335205
Validation loss: 2.210459609826406

Epoch: 339| Step: 0
Training loss: 1.21964430809021
Validation loss: 2.2202481428782144

Epoch: 6| Step: 1
Training loss: 1.9506604671478271
Validation loss: 2.217722555001577

Epoch: 6| Step: 2
Training loss: 1.6485328674316406
Validation loss: 2.1767571369806924

Epoch: 6| Step: 3
Training loss: 0.6633580327033997
Validation loss: 2.181996206442515

Epoch: 6| Step: 4
Training loss: 1.1242144107818604
Validation loss: 2.2286670009295144

Epoch: 6| Step: 5
Training loss: 1.6470649242401123
Validation loss: 2.170193314552307

Epoch: 6| Step: 6
Training loss: 0.6269657015800476
Validation loss: 2.1671834786732993

Epoch: 6| Step: 7
Training loss: 0.6455397605895996
Validation loss: 2.2134809494018555

Epoch: 6| Step: 8
Training loss: 1.146693229675293
Validation loss: 2.180620869000753

Epoch: 6| Step: 9
Training loss: 1.0693342685699463
Validation loss: 2.190951923529307

Epoch: 6| Step: 10
Training loss: 1.2617597579956055
Validation loss: 2.1798011660575867

Epoch: 6| Step: 11
Training loss: 1.4930899143218994
Validation loss: 2.16081694761912

Epoch: 6| Step: 12
Training loss: 0.7729033827781677
Validation loss: 2.1666349172592163

Epoch: 6| Step: 13
Training loss: 0.6929600238800049
Validation loss: 2.171881635983785

Epoch: 340| Step: 0
Training loss: 1.5200146436691284
Validation loss: 2.1512545545895896

Epoch: 6| Step: 1
Training loss: 1.6792147159576416
Validation loss: 2.1551056106885276

Epoch: 6| Step: 2
Training loss: 1.210405945777893
Validation loss: 2.136787752310435

Epoch: 6| Step: 3
Training loss: 1.1842578649520874
Validation loss: 2.1626025438308716

Epoch: 6| Step: 4
Training loss: 0.9128910303115845
Validation loss: 2.1468297441800437

Epoch: 6| Step: 5
Training loss: 1.181205153465271
Validation loss: 2.1045292615890503

Epoch: 6| Step: 6
Training loss: 0.8347480297088623
Validation loss: 2.1699349681536355

Epoch: 6| Step: 7
Training loss: 1.025546669960022
Validation loss: 2.1842790047327676

Epoch: 6| Step: 8
Training loss: 1.4016282558441162
Validation loss: 2.1724947690963745

Epoch: 6| Step: 9
Training loss: 0.8586025238037109
Validation loss: 2.2005238135655723

Epoch: 6| Step: 10
Training loss: 0.9889379739761353
Validation loss: 2.1715548435846963

Epoch: 6| Step: 11
Training loss: 0.470401406288147
Validation loss: 2.195536176363627

Epoch: 6| Step: 12
Training loss: 0.9781694412231445
Validation loss: 2.2037477095921836

Epoch: 6| Step: 13
Training loss: 1.4657361507415771
Validation loss: 2.2515106995900473

Epoch: 341| Step: 0
Training loss: 0.6907258629798889
Validation loss: 2.2359913984934487

Epoch: 6| Step: 1
Training loss: 0.5319861769676208
Validation loss: 2.2601853410402932

Epoch: 6| Step: 2
Training loss: 0.7169710397720337
Validation loss: 2.1882282892862954

Epoch: 6| Step: 3
Training loss: 1.5114288330078125
Validation loss: 2.2223448355992637

Epoch: 6| Step: 4
Training loss: 1.4425690174102783
Validation loss: 2.2117599646250405

Epoch: 6| Step: 5
Training loss: 1.210629940032959
Validation loss: 2.2155312498410544

Epoch: 6| Step: 6
Training loss: 1.3620645999908447
Validation loss: 2.223611374696096

Epoch: 6| Step: 7
Training loss: 0.97757887840271
Validation loss: 2.2242574095726013

Epoch: 6| Step: 8
Training loss: 1.1983458995819092
Validation loss: 2.2076154947280884

Epoch: 6| Step: 9
Training loss: 1.4906823635101318
Validation loss: 2.1608731349309287

Epoch: 6| Step: 10
Training loss: 1.296255111694336
Validation loss: 2.1782954931259155

Epoch: 6| Step: 11
Training loss: 0.8902422785758972
Validation loss: 2.1813936034838357

Epoch: 6| Step: 12
Training loss: 1.7742899656295776
Validation loss: 2.197874883810679

Epoch: 6| Step: 13
Training loss: 1.200749158859253
Validation loss: 2.1920275688171387

Epoch: 342| Step: 0
Training loss: 1.3490419387817383
Validation loss: 2.1905813614527383

Epoch: 6| Step: 1
Training loss: 1.2807021141052246
Validation loss: 2.187856117884318

Epoch: 6| Step: 2
Training loss: 1.3068113327026367
Validation loss: 2.1780446767807007

Epoch: 6| Step: 3
Training loss: 0.582061767578125
Validation loss: 2.1781482299168906

Epoch: 6| Step: 4
Training loss: 1.4634153842926025
Validation loss: 2.2371709744135537

Epoch: 6| Step: 5
Training loss: 0.9976761341094971
Validation loss: 2.216882844765981

Epoch: 6| Step: 6
Training loss: 1.3939244747161865
Validation loss: 2.225736161073049

Epoch: 6| Step: 7
Training loss: 1.3825373649597168
Validation loss: 2.198147257169088

Epoch: 6| Step: 8
Training loss: 1.1160197257995605
Validation loss: 2.200055162111918

Epoch: 6| Step: 9
Training loss: 0.7368330955505371
Validation loss: 2.208282252152761

Epoch: 6| Step: 10
Training loss: 1.233781337738037
Validation loss: 2.1735393603642783

Epoch: 6| Step: 11
Training loss: 1.2992973327636719
Validation loss: 2.1981650590896606

Epoch: 6| Step: 12
Training loss: 1.5262153148651123
Validation loss: 2.1631503899892173

Epoch: 6| Step: 13
Training loss: 0.8535475730895996
Validation loss: 2.1804459492365518

Epoch: 343| Step: 0
Training loss: 1.7204972505569458
Validation loss: 2.1520955562591553

Epoch: 6| Step: 1
Training loss: 1.3253703117370605
Validation loss: 2.1289677023887634

Epoch: 6| Step: 2
Training loss: 0.4921424686908722
Validation loss: 2.164549926916758

Epoch: 6| Step: 3
Training loss: 0.6967388391494751
Validation loss: 2.1415576934814453

Epoch: 6| Step: 4
Training loss: 1.1932499408721924
Validation loss: 2.1489535570144653

Epoch: 6| Step: 5
Training loss: 1.300653338432312
Validation loss: 2.1672176321347556

Epoch: 6| Step: 6
Training loss: 1.0773371458053589
Validation loss: 2.146972378094991

Epoch: 6| Step: 7
Training loss: 1.1854161024093628
Validation loss: 2.1516449650128684

Epoch: 6| Step: 8
Training loss: 1.2050039768218994
Validation loss: 2.1526308059692383

Epoch: 6| Step: 9
Training loss: 1.0134117603302002
Validation loss: 2.1954437096913657

Epoch: 6| Step: 10
Training loss: 0.9651772379875183
Validation loss: 2.174022058645884

Epoch: 6| Step: 11
Training loss: 0.6659170389175415
Validation loss: 2.2147353092829385

Epoch: 6| Step: 12
Training loss: 1.0235822200775146
Validation loss: 2.1904059847195945

Epoch: 6| Step: 13
Training loss: 1.2551558017730713
Validation loss: 2.1982948780059814

Epoch: 344| Step: 0
Training loss: 0.5486777424812317
Validation loss: 2.1890257199605307

Epoch: 6| Step: 1
Training loss: 0.8677511811256409
Validation loss: 2.186510662237803

Epoch: 6| Step: 2
Training loss: 2.1422221660614014
Validation loss: 2.1546194156010947

Epoch: 6| Step: 3
Training loss: 1.4174689054489136
Validation loss: 2.195643345514933

Epoch: 6| Step: 4
Training loss: 1.199639916419983
Validation loss: 2.166730761528015

Epoch: 6| Step: 5
Training loss: 1.5375183820724487
Validation loss: 2.168919324874878

Epoch: 6| Step: 6
Training loss: 1.0344057083129883
Validation loss: 2.186170240243276

Epoch: 6| Step: 7
Training loss: 1.1136536598205566
Validation loss: 2.1507051984469094

Epoch: 6| Step: 8
Training loss: 1.274686336517334
Validation loss: 2.161694288253784

Epoch: 6| Step: 9
Training loss: 0.9623657464981079
Validation loss: 2.1846828063329062

Epoch: 6| Step: 10
Training loss: 0.5730752944946289
Validation loss: 2.1544110576311746

Epoch: 6| Step: 11
Training loss: 0.8213962316513062
Validation loss: 2.176280895868937

Epoch: 6| Step: 12
Training loss: 1.5623719692230225
Validation loss: 2.13677316904068

Epoch: 6| Step: 13
Training loss: 0.6800596714019775
Validation loss: 2.1740474303563437

Epoch: 345| Step: 0
Training loss: 0.7295747399330139
Validation loss: 2.152067164580027

Epoch: 6| Step: 1
Training loss: 1.2076363563537598
Validation loss: 2.1765965024630227

Epoch: 6| Step: 2
Training loss: 0.711767315864563
Validation loss: 2.1554606755574546

Epoch: 6| Step: 3
Training loss: 1.2933921813964844
Validation loss: 2.1522868076960244

Epoch: 6| Step: 4
Training loss: 0.88386070728302
Validation loss: 2.1183567444483438

Epoch: 6| Step: 5
Training loss: 1.1988091468811035
Validation loss: 2.1166420777638755

Epoch: 6| Step: 6
Training loss: 1.925605297088623
Validation loss: 2.110677798589071

Epoch: 6| Step: 7
Training loss: 1.5924479961395264
Validation loss: 2.15519787867864

Epoch: 6| Step: 8
Training loss: 1.1762675046920776
Validation loss: 2.16152153412501

Epoch: 6| Step: 9
Training loss: 0.6301276683807373
Validation loss: 2.1455618341763816

Epoch: 6| Step: 10
Training loss: 0.8617330193519592
Validation loss: 2.165355642636617

Epoch: 6| Step: 11
Training loss: 1.2645463943481445
Validation loss: 2.159345249334971

Epoch: 6| Step: 12
Training loss: 0.7466726303100586
Validation loss: 2.22313916683197

Epoch: 6| Step: 13
Training loss: 0.7464592456817627
Validation loss: 2.1582599878311157

Epoch: 346| Step: 0
Training loss: 1.2981278896331787
Validation loss: 2.1764857371648154

Epoch: 6| Step: 1
Training loss: 0.5115606784820557
Validation loss: 2.1762545108795166

Epoch: 6| Step: 2
Training loss: 0.9328203201293945
Validation loss: 2.1566784183184304

Epoch: 6| Step: 3
Training loss: 1.1354026794433594
Validation loss: 2.147714376449585

Epoch: 6| Step: 4
Training loss: 0.8981752395629883
Validation loss: 2.2104419271151223

Epoch: 6| Step: 5
Training loss: 1.373380184173584
Validation loss: 2.174332618713379

Epoch: 6| Step: 6
Training loss: 1.3460274934768677
Validation loss: 2.145081023375193

Epoch: 6| Step: 7
Training loss: 1.3820500373840332
Validation loss: 2.179883897304535

Epoch: 6| Step: 8
Training loss: 0.9394254684448242
Validation loss: 2.172189255555471

Epoch: 6| Step: 9
Training loss: 1.0664088726043701
Validation loss: 2.1500217517217

Epoch: 6| Step: 10
Training loss: 0.5273607969284058
Validation loss: 2.17444908618927

Epoch: 6| Step: 11
Training loss: 0.9342103004455566
Validation loss: 2.157981554667155

Epoch: 6| Step: 12
Training loss: 1.1702150106430054
Validation loss: 2.2046815752983093

Epoch: 6| Step: 13
Training loss: 1.4628509283065796
Validation loss: 2.1866007645924888

Epoch: 347| Step: 0
Training loss: 0.9265017509460449
Validation loss: 2.2363423903783164

Epoch: 6| Step: 1
Training loss: 1.7587182521820068
Validation loss: 2.2034815351168313

Epoch: 6| Step: 2
Training loss: 1.2709734439849854
Validation loss: 2.24241840839386

Epoch: 6| Step: 3
Training loss: 0.6306860446929932
Validation loss: 2.214745501677195

Epoch: 6| Step: 4
Training loss: 0.8984771966934204
Validation loss: 2.2447511156400046

Epoch: 6| Step: 5
Training loss: 0.9601588249206543
Validation loss: 2.231522500514984

Epoch: 6| Step: 6
Training loss: 1.484161615371704
Validation loss: 2.168096045653025

Epoch: 6| Step: 7
Training loss: 0.8837699890136719
Validation loss: 2.157340188821157

Epoch: 6| Step: 8
Training loss: 1.225230097770691
Validation loss: 2.214971661567688

Epoch: 6| Step: 9
Training loss: 0.7358947992324829
Validation loss: 2.1933117508888245

Epoch: 6| Step: 10
Training loss: 1.7294182777404785
Validation loss: 2.1943189899126687

Epoch: 6| Step: 11
Training loss: 1.5576269626617432
Validation loss: 2.1877732475598655

Epoch: 6| Step: 12
Training loss: 0.6819970607757568
Validation loss: 2.1775439182917276

Epoch: 6| Step: 13
Training loss: 0.7532451152801514
Validation loss: 2.183455983797709

Epoch: 348| Step: 0
Training loss: 0.8614648580551147
Validation loss: 2.1580923199653625

Epoch: 6| Step: 1
Training loss: 0.6884689331054688
Validation loss: 2.16566135485967

Epoch: 6| Step: 2
Training loss: 0.9306991696357727
Validation loss: 2.17513906955719

Epoch: 6| Step: 3
Training loss: 1.311652421951294
Validation loss: 2.206970969835917

Epoch: 6| Step: 4
Training loss: 0.960407555103302
Validation loss: 2.1813544034957886

Epoch: 6| Step: 5
Training loss: 2.1017138957977295
Validation loss: 2.1721846659978232

Epoch: 6| Step: 6
Training loss: 1.4472945928573608
Validation loss: 2.1703794399897256

Epoch: 6| Step: 7
Training loss: 0.7662200927734375
Validation loss: 2.1583165526390076

Epoch: 6| Step: 8
Training loss: 0.703009843826294
Validation loss: 2.172058324019114

Epoch: 6| Step: 9
Training loss: 1.1728161573410034
Validation loss: 2.194605608781179

Epoch: 6| Step: 10
Training loss: 1.6966896057128906
Validation loss: 2.187087873617808

Epoch: 6| Step: 11
Training loss: 0.940615713596344
Validation loss: 2.188964287439982

Epoch: 6| Step: 12
Training loss: 1.3115692138671875
Validation loss: 2.1962910890579224

Epoch: 6| Step: 13
Training loss: 0.7358766794204712
Validation loss: 2.1904556353886924

Epoch: 349| Step: 0
Training loss: 1.0115642547607422
Validation loss: 2.1592755119005838

Epoch: 6| Step: 1
Training loss: 1.8681025505065918
Validation loss: 2.1630184253056846

Epoch: 6| Step: 2
Training loss: 0.7080607414245605
Validation loss: 2.151556889216105

Epoch: 6| Step: 3
Training loss: 1.4307293891906738
Validation loss: 2.1257599194844565

Epoch: 6| Step: 4
Training loss: 0.7437800765037537
Validation loss: 2.1503681341807046

Epoch: 6| Step: 5
Training loss: 0.9420536756515503
Validation loss: 2.162192940711975

Epoch: 6| Step: 6
Training loss: 1.7279202938079834
Validation loss: 2.1355350414911904

Epoch: 6| Step: 7
Training loss: 0.9546119570732117
Validation loss: 2.1620783607165017

Epoch: 6| Step: 8
Training loss: 1.678225040435791
Validation loss: 2.169145405292511

Epoch: 6| Step: 9
Training loss: 0.8306776881217957
Validation loss: 2.176119089126587

Epoch: 6| Step: 10
Training loss: 0.7056688070297241
Validation loss: 2.1965348720550537

Epoch: 6| Step: 11
Training loss: 1.1193339824676514
Validation loss: 2.176079789797465

Epoch: 6| Step: 12
Training loss: 0.9377033710479736
Validation loss: 2.239032804965973

Epoch: 6| Step: 13
Training loss: 1.1601004600524902
Validation loss: 2.1981868942578635

Epoch: 350| Step: 0
Training loss: 0.6340885162353516
Validation loss: 2.226653575897217

Epoch: 6| Step: 1
Training loss: 1.1843198537826538
Validation loss: 2.190422018369039

Epoch: 6| Step: 2
Training loss: 1.5023419857025146
Validation loss: 2.2265066305796304

Epoch: 6| Step: 3
Training loss: 1.4684782028198242
Validation loss: 2.2019497553507485

Epoch: 6| Step: 4
Training loss: 1.0021460056304932
Validation loss: 2.1764301856358848

Epoch: 6| Step: 5
Training loss: 1.4809467792510986
Validation loss: 2.203673481941223

Epoch: 6| Step: 6
Training loss: 0.996861457824707
Validation loss: 2.1888710061709085

Epoch: 6| Step: 7
Training loss: 0.6916677951812744
Validation loss: 2.1804069677988687

Epoch: 6| Step: 8
Training loss: 0.6788980960845947
Validation loss: 2.147056301434835

Epoch: 6| Step: 9
Training loss: 1.0691300630569458
Validation loss: 2.167976498603821

Epoch: 6| Step: 10
Training loss: 1.0368597507476807
Validation loss: 2.1593820254007974

Epoch: 6| Step: 11
Training loss: 1.389225721359253
Validation loss: 2.1775739789009094

Epoch: 6| Step: 12
Training loss: 1.190284013748169
Validation loss: 2.136790414651235

Epoch: 6| Step: 13
Training loss: 1.1530637741088867
Validation loss: 2.159087359905243

Testing loss: 1.8628751819939922
