Epoch: 1| Step: 0
Training loss: 4.571844577789307
Validation loss: 5.289573669433594

Epoch: 6| Step: 1
Training loss: 5.820682525634766
Validation loss: 5.288088798522949

Epoch: 6| Step: 2
Training loss: 4.806291580200195
Validation loss: 5.286686499913533

Epoch: 6| Step: 3
Training loss: 4.624273300170898
Validation loss: 5.28529938062032

Epoch: 6| Step: 4
Training loss: 5.200798034667969
Validation loss: 5.283875783284505

Epoch: 6| Step: 5
Training loss: 6.332764148712158
Validation loss: 5.2824437618255615

Epoch: 6| Step: 6
Training loss: 5.988917350769043
Validation loss: 5.281071503957112

Epoch: 6| Step: 7
Training loss: 5.7428107261657715
Validation loss: 5.279559373855591

Epoch: 6| Step: 8
Training loss: 6.37208890914917
Validation loss: 5.278046210606893

Epoch: 6| Step: 9
Training loss: 4.235400199890137
Validation loss: 5.276547908782959

Epoch: 6| Step: 10
Training loss: 5.100534439086914
Validation loss: 5.274938980738322

Epoch: 6| Step: 11
Training loss: 4.892816543579102
Validation loss: 5.273263851801555

Epoch: 6| Step: 12
Training loss: 5.865509986877441
Validation loss: 5.2715699672698975

Epoch: 6| Step: 13
Training loss: 5.334535598754883
Validation loss: 5.2697538534800215

Epoch: 2| Step: 0
Training loss: 3.9943435192108154
Validation loss: 5.267847061157227

Epoch: 6| Step: 1
Training loss: 4.64167594909668
Validation loss: 5.265801429748535

Epoch: 6| Step: 2
Training loss: 5.942413806915283
Validation loss: 5.263723611831665

Epoch: 6| Step: 3
Training loss: 4.5223493576049805
Validation loss: 5.261453310648601

Epoch: 6| Step: 4
Training loss: 4.953067779541016
Validation loss: 5.25913421312968

Epoch: 6| Step: 5
Training loss: 4.647375106811523
Validation loss: 5.256754636764526

Epoch: 6| Step: 6
Training loss: 4.968202114105225
Validation loss: 5.254110654195149

Epoch: 6| Step: 7
Training loss: 6.015510559082031
Validation loss: 5.251407702763875

Epoch: 6| Step: 8
Training loss: 5.821463584899902
Validation loss: 5.248606046040853

Epoch: 6| Step: 9
Training loss: 6.070321083068848
Validation loss: 5.245524485905965

Epoch: 6| Step: 10
Training loss: 6.604447841644287
Validation loss: 5.242438713709514

Epoch: 6| Step: 11
Training loss: 5.630512237548828
Validation loss: 5.239185055096944

Epoch: 6| Step: 12
Training loss: 5.355853080749512
Validation loss: 5.235735495885213

Epoch: 6| Step: 13
Training loss: 5.3259196281433105
Validation loss: 5.232129335403442

Epoch: 3| Step: 0
Training loss: 4.692597389221191
Validation loss: 5.2283116181691485

Epoch: 6| Step: 1
Training loss: 6.239956855773926
Validation loss: 5.224347273508708

Epoch: 6| Step: 2
Training loss: 5.241584777832031
Validation loss: 5.220056931177775

Epoch: 6| Step: 3
Training loss: 5.228171348571777
Validation loss: 5.215635458628337

Epoch: 6| Step: 4
Training loss: 4.468900680541992
Validation loss: 5.21101442972819

Epoch: 6| Step: 5
Training loss: 5.508600234985352
Validation loss: 5.206278244654338

Epoch: 6| Step: 6
Training loss: 4.538887023925781
Validation loss: 5.201484044392903

Epoch: 6| Step: 7
Training loss: 6.309117317199707
Validation loss: 5.1959574619929

Epoch: 6| Step: 8
Training loss: 4.619731903076172
Validation loss: 5.190608421961467

Epoch: 6| Step: 9
Training loss: 4.778722763061523
Validation loss: 5.185026407241821

Epoch: 6| Step: 10
Training loss: 6.628202438354492
Validation loss: 5.1789664427439375

Epoch: 6| Step: 11
Training loss: 5.006058692932129
Validation loss: 5.172774791717529

Epoch: 6| Step: 12
Training loss: 5.166959762573242
Validation loss: 5.166316032409668

Epoch: 6| Step: 13
Training loss: 5.318648338317871
Validation loss: 5.159552335739136

Epoch: 4| Step: 0
Training loss: 5.161301612854004
Validation loss: 5.152377128601074

Epoch: 6| Step: 1
Training loss: 4.723427772521973
Validation loss: 5.145005861918132

Epoch: 6| Step: 2
Training loss: 5.5449395179748535
Validation loss: 5.137627363204956

Epoch: 6| Step: 3
Training loss: 4.6105546951293945
Validation loss: 5.1296132405598955

Epoch: 6| Step: 4
Training loss: 5.389105796813965
Validation loss: 5.121466398239136

Epoch: 6| Step: 5
Training loss: 6.295757293701172
Validation loss: 5.113117138544719

Epoch: 6| Step: 6
Training loss: 5.220379829406738
Validation loss: 5.104099194208781

Epoch: 6| Step: 7
Training loss: 4.049084663391113
Validation loss: 5.094989697138469

Epoch: 6| Step: 8
Training loss: 5.6740641593933105
Validation loss: 5.085754474004109

Epoch: 6| Step: 9
Training loss: 4.127399921417236
Validation loss: 5.076415141423543

Epoch: 6| Step: 10
Training loss: 5.095685958862305
Validation loss: 5.067191044489543

Epoch: 6| Step: 11
Training loss: 6.310046195983887
Validation loss: 5.05737288792928

Epoch: 6| Step: 12
Training loss: 5.431597709655762
Validation loss: 5.048005978266398

Epoch: 6| Step: 13
Training loss: 4.789487838745117
Validation loss: 5.038179715474446

Epoch: 5| Step: 0
Training loss: 6.197176933288574
Validation loss: 5.028728008270264

Epoch: 6| Step: 1
Training loss: 7.2584662437438965
Validation loss: 5.0191168785095215

Epoch: 6| Step: 2
Training loss: 4.3211822509765625
Validation loss: 5.009576241175334

Epoch: 6| Step: 3
Training loss: 5.6075849533081055
Validation loss: 4.999997456868489

Epoch: 6| Step: 4
Training loss: 4.962610721588135
Validation loss: 4.990770260492961

Epoch: 6| Step: 5
Training loss: 4.062699317932129
Validation loss: 4.9818220138549805

Epoch: 6| Step: 6
Training loss: 5.55256986618042
Validation loss: 4.972371141115825

Epoch: 6| Step: 7
Training loss: 4.731618881225586
Validation loss: 4.963267246882121

Epoch: 6| Step: 8
Training loss: 5.15137243270874
Validation loss: 4.9541042645772295

Epoch: 6| Step: 9
Training loss: 4.4645466804504395
Validation loss: 4.944897890090942

Epoch: 6| Step: 10
Training loss: 4.164877891540527
Validation loss: 4.935616572697957

Epoch: 6| Step: 11
Training loss: 4.597947120666504
Validation loss: 4.92642609278361

Epoch: 6| Step: 12
Training loss: 5.521371364593506
Validation loss: 4.917191823323567

Epoch: 6| Step: 13
Training loss: 4.116857051849365
Validation loss: 4.9076963265736895

Epoch: 6| Step: 0
Training loss: 4.956178665161133
Validation loss: 4.897639274597168

Epoch: 6| Step: 1
Training loss: 4.871667861938477
Validation loss: 4.88689398765564

Epoch: 6| Step: 2
Training loss: 5.721994400024414
Validation loss: 4.874215364456177

Epoch: 6| Step: 3
Training loss: 5.135348320007324
Validation loss: 4.859933614730835

Epoch: 6| Step: 4
Training loss: 4.295297145843506
Validation loss: 4.848755915959676

Epoch: 6| Step: 5
Training loss: 5.227894306182861
Validation loss: 4.839313904444377

Epoch: 6| Step: 6
Training loss: 4.491063117980957
Validation loss: 4.831412315368652

Epoch: 6| Step: 7
Training loss: 5.165162086486816
Validation loss: 4.8242982228597

Epoch: 6| Step: 8
Training loss: 4.655714988708496
Validation loss: 4.81677492459615

Epoch: 6| Step: 9
Training loss: 4.670490741729736
Validation loss: 4.8090775807698565

Epoch: 6| Step: 10
Training loss: 4.1831183433532715
Validation loss: 4.8017386595408125

Epoch: 6| Step: 11
Training loss: 4.462471961975098
Validation loss: 4.793886423110962

Epoch: 6| Step: 12
Training loss: 5.23486328125
Validation loss: 4.786162694295247

Epoch: 6| Step: 13
Training loss: 5.80148983001709
Validation loss: 4.778332908948262

Epoch: 7| Step: 0
Training loss: 4.590465068817139
Validation loss: 4.770449837048848

Epoch: 6| Step: 1
Training loss: 3.2204208374023438
Validation loss: 4.762712240219116

Epoch: 6| Step: 2
Training loss: 4.181884288787842
Validation loss: 4.755052367846171

Epoch: 6| Step: 3
Training loss: 4.853912353515625
Validation loss: 4.7476277351379395

Epoch: 6| Step: 4
Training loss: 5.786826133728027
Validation loss: 4.740094701449077

Epoch: 6| Step: 5
Training loss: 5.08515739440918
Validation loss: 4.732935746510823

Epoch: 6| Step: 6
Training loss: 4.758108615875244
Validation loss: 4.725747386614482

Epoch: 6| Step: 7
Training loss: 5.935725212097168
Validation loss: 4.718836863835652

Epoch: 6| Step: 8
Training loss: 5.04530668258667
Validation loss: 4.711952845255534

Epoch: 6| Step: 9
Training loss: 5.052345275878906
Validation loss: 4.705381313959758

Epoch: 6| Step: 10
Training loss: 5.429275989532471
Validation loss: 4.698298096656799

Epoch: 6| Step: 11
Training loss: 4.373196601867676
Validation loss: 4.691323558489482

Epoch: 6| Step: 12
Training loss: 5.615028381347656
Validation loss: 4.685201327006022

Epoch: 6| Step: 13
Training loss: 3.496887683868408
Validation loss: 4.679146448771159

Epoch: 8| Step: 0
Training loss: 4.18397331237793
Validation loss: 4.67306915918986

Epoch: 6| Step: 1
Training loss: 3.5352678298950195
Validation loss: 4.667023579279582

Epoch: 6| Step: 2
Training loss: 4.519707679748535
Validation loss: 4.660254756609599

Epoch: 6| Step: 3
Training loss: 5.575544357299805
Validation loss: 4.6542288064956665

Epoch: 6| Step: 4
Training loss: 4.3902764320373535
Validation loss: 4.647588014602661

Epoch: 6| Step: 5
Training loss: 4.743330955505371
Validation loss: 4.641385714213054

Epoch: 6| Step: 6
Training loss: 5.735267639160156
Validation loss: 4.635046641031901

Epoch: 6| Step: 7
Training loss: 5.659111976623535
Validation loss: 4.6285022894541425

Epoch: 6| Step: 8
Training loss: 3.8643360137939453
Validation loss: 4.622472047805786

Epoch: 6| Step: 9
Training loss: 4.293656349182129
Validation loss: 4.616661151250203

Epoch: 6| Step: 10
Training loss: 4.2880778312683105
Validation loss: 4.610180894533793

Epoch: 6| Step: 11
Training loss: 5.29530143737793
Validation loss: 4.604815403620402

Epoch: 6| Step: 12
Training loss: 4.201953887939453
Validation loss: 4.599114457766215

Epoch: 6| Step: 13
Training loss: 5.943598747253418
Validation loss: 4.593417406082153

Epoch: 9| Step: 0
Training loss: 4.855527877807617
Validation loss: 4.588010470072429

Epoch: 6| Step: 1
Training loss: 4.149430274963379
Validation loss: 4.5820689996083575

Epoch: 6| Step: 2
Training loss: 4.46328067779541
Validation loss: 4.5763877630233765

Epoch: 6| Step: 3
Training loss: 4.149806976318359
Validation loss: 4.57131560643514

Epoch: 6| Step: 4
Training loss: 3.8077454566955566
Validation loss: 4.56502370039622

Epoch: 6| Step: 5
Training loss: 4.422921180725098
Validation loss: 4.559499065081279

Epoch: 6| Step: 6
Training loss: 6.175046920776367
Validation loss: 4.554112990697225

Epoch: 6| Step: 7
Training loss: 5.126882076263428
Validation loss: 4.548772811889648

Epoch: 6| Step: 8
Training loss: 4.3969197273254395
Validation loss: 4.542926629384358

Epoch: 6| Step: 9
Training loss: 4.408348083496094
Validation loss: 4.536768555641174

Epoch: 6| Step: 10
Training loss: 4.6502227783203125
Validation loss: 4.530514558156331

Epoch: 6| Step: 11
Training loss: 4.49954891204834
Validation loss: 4.5247204303741455

Epoch: 6| Step: 12
Training loss: 4.425687789916992
Validation loss: 4.519476254781087

Epoch: 6| Step: 13
Training loss: 5.60184383392334
Validation loss: 4.512696862220764

Epoch: 10| Step: 0
Training loss: 5.010538101196289
Validation loss: 4.506420016288757

Epoch: 6| Step: 1
Training loss: 5.049701690673828
Validation loss: 4.499342083930969

Epoch: 6| Step: 2
Training loss: 4.905727386474609
Validation loss: 4.490419467290242

Epoch: 6| Step: 3
Training loss: 5.097240447998047
Validation loss: 4.4816412925720215

Epoch: 6| Step: 4
Training loss: 4.7674970626831055
Validation loss: 4.4760531187057495

Epoch: 6| Step: 5
Training loss: 4.147891521453857
Validation loss: 4.472046613693237

Epoch: 6| Step: 6
Training loss: 5.34583854675293
Validation loss: 4.465569774309794

Epoch: 6| Step: 7
Training loss: 3.638789176940918
Validation loss: 4.459406693776448

Epoch: 6| Step: 8
Training loss: 3.9901862144470215
Validation loss: 4.4528047641118365

Epoch: 6| Step: 9
Training loss: 4.7298479080200195
Validation loss: 4.446235299110413

Epoch: 6| Step: 10
Training loss: 5.28626012802124
Validation loss: 4.440653324127197

Epoch: 6| Step: 11
Training loss: 3.593034267425537
Validation loss: 4.433988571166992

Epoch: 6| Step: 12
Training loss: 4.918692588806152
Validation loss: 4.427172422409058

Epoch: 6| Step: 13
Training loss: 3.5532970428466797
Validation loss: 4.421563982963562

Epoch: 11| Step: 0
Training loss: 3.628953456878662
Validation loss: 4.4150469700495405

Epoch: 6| Step: 1
Training loss: 4.95253849029541
Validation loss: 4.408764203389485

Epoch: 6| Step: 2
Training loss: 5.179538726806641
Validation loss: 4.401583870251973

Epoch: 6| Step: 3
Training loss: 4.57276725769043
Validation loss: 4.395665009816487

Epoch: 6| Step: 4
Training loss: 5.086307048797607
Validation loss: 4.389924128850301

Epoch: 6| Step: 5
Training loss: 4.8354644775390625
Validation loss: 4.382821321487427

Epoch: 6| Step: 6
Training loss: 4.315883636474609
Validation loss: 4.375804543495178

Epoch: 6| Step: 7
Training loss: 3.976357936859131
Validation loss: 4.368470072746277

Epoch: 6| Step: 8
Training loss: 4.440042972564697
Validation loss: 4.362079421679179

Epoch: 6| Step: 9
Training loss: 3.9045605659484863
Validation loss: 4.354806105295817

Epoch: 6| Step: 10
Training loss: 5.056862831115723
Validation loss: 4.34915550549825

Epoch: 6| Step: 11
Training loss: 4.190018653869629
Validation loss: 4.3413558801015215

Epoch: 6| Step: 12
Training loss: 4.003933429718018
Validation loss: 4.333237330118815

Epoch: 6| Step: 13
Training loss: 4.724922180175781
Validation loss: 4.325758457183838

Epoch: 12| Step: 0
Training loss: 3.946343183517456
Validation loss: 4.319812059402466

Epoch: 6| Step: 1
Training loss: 4.8252363204956055
Validation loss: 4.313228050867717

Epoch: 6| Step: 2
Training loss: 4.31635856628418
Validation loss: 4.305852969487508

Epoch: 6| Step: 3
Training loss: 4.128626823425293
Validation loss: 4.297594467798869

Epoch: 6| Step: 4
Training loss: 3.750440835952759
Validation loss: 4.290738781293233

Epoch: 6| Step: 5
Training loss: 5.152201175689697
Validation loss: 4.284054120381673

Epoch: 6| Step: 6
Training loss: 2.8736233711242676
Validation loss: 4.276493589083354

Epoch: 6| Step: 7
Training loss: 5.1721673011779785
Validation loss: 4.269802212715149

Epoch: 6| Step: 8
Training loss: 3.985968589782715
Validation loss: 4.2625337441762285

Epoch: 6| Step: 9
Training loss: 4.894941806793213
Validation loss: 4.256029963493347

Epoch: 6| Step: 10
Training loss: 3.9782180786132812
Validation loss: 4.249854286511739

Epoch: 6| Step: 11
Training loss: 5.3748579025268555
Validation loss: 4.243014097213745

Epoch: 6| Step: 12
Training loss: 4.457188129425049
Validation loss: 4.236767053604126

Epoch: 6| Step: 13
Training loss: 4.739928245544434
Validation loss: 4.230989336967468

Epoch: 13| Step: 0
Training loss: 4.192028522491455
Validation loss: 4.223301887512207

Epoch: 6| Step: 1
Training loss: 4.173089981079102
Validation loss: 4.217953642209371

Epoch: 6| Step: 2
Training loss: 3.3808112144470215
Validation loss: 4.212016661961873

Epoch: 6| Step: 3
Training loss: 4.015460968017578
Validation loss: 4.206219871838887

Epoch: 6| Step: 4
Training loss: 5.78931999206543
Validation loss: 4.200767834981282

Epoch: 6| Step: 5
Training loss: 3.945396900177002
Validation loss: 4.193885048230489

Epoch: 6| Step: 6
Training loss: 3.8974814414978027
Validation loss: 4.188245574633281

Epoch: 6| Step: 7
Training loss: 5.06744384765625
Validation loss: 4.182706832885742

Epoch: 6| Step: 8
Training loss: 4.273289203643799
Validation loss: 4.176099419593811

Epoch: 6| Step: 9
Training loss: 3.9563755989074707
Validation loss: 4.169376214345296

Epoch: 6| Step: 10
Training loss: 4.739974498748779
Validation loss: 4.164058168729146

Epoch: 6| Step: 11
Training loss: 3.8378865718841553
Validation loss: 4.157873551050822

Epoch: 6| Step: 12
Training loss: 3.6659116744995117
Validation loss: 4.15046238899231

Epoch: 6| Step: 13
Training loss: 5.515286922454834
Validation loss: 4.143558502197266

Epoch: 14| Step: 0
Training loss: 4.457613468170166
Validation loss: 4.137531717618306

Epoch: 6| Step: 1
Training loss: 4.605049133300781
Validation loss: 4.13025160630544

Epoch: 6| Step: 2
Training loss: 4.550683498382568
Validation loss: 4.12503198782603

Epoch: 6| Step: 3
Training loss: 5.263355255126953
Validation loss: 4.1181842883427935

Epoch: 6| Step: 4
Training loss: 3.2734899520874023
Validation loss: 4.111091375350952

Epoch: 6| Step: 5
Training loss: 4.140249729156494
Validation loss: 4.105482578277588

Epoch: 6| Step: 6
Training loss: 3.837585926055908
Validation loss: 4.1002488533655805

Epoch: 6| Step: 7
Training loss: 4.135505676269531
Validation loss: 4.093897740046184

Epoch: 6| Step: 8
Training loss: 4.137114524841309
Validation loss: 4.087188482284546

Epoch: 6| Step: 9
Training loss: 3.643476724624634
Validation loss: 4.081988294919332

Epoch: 6| Step: 10
Training loss: 3.702371835708618
Validation loss: 4.07564640045166

Epoch: 6| Step: 11
Training loss: 4.16055965423584
Validation loss: 4.069387753804524

Epoch: 6| Step: 12
Training loss: 4.695046424865723
Validation loss: 4.063607970873515

Epoch: 6| Step: 13
Training loss: 4.738651275634766
Validation loss: 4.057214260101318

Epoch: 15| Step: 0
Training loss: 4.134355068206787
Validation loss: 4.05327570438385

Epoch: 6| Step: 1
Training loss: 4.412579536437988
Validation loss: 4.047720233599345

Epoch: 6| Step: 2
Training loss: 4.814258098602295
Validation loss: 4.042148033777873

Epoch: 6| Step: 3
Training loss: 3.7946059703826904
Validation loss: 4.036660234133403

Epoch: 6| Step: 4
Training loss: 3.9934945106506348
Validation loss: 4.031264225641887

Epoch: 6| Step: 5
Training loss: 3.971970558166504
Validation loss: 4.024910728136699

Epoch: 6| Step: 6
Training loss: 3.543196678161621
Validation loss: 4.020872433980306

Epoch: 6| Step: 7
Training loss: 3.6628005504608154
Validation loss: 4.013232310612996

Epoch: 6| Step: 8
Training loss: 4.763419151306152
Validation loss: 4.0092413028081255

Epoch: 6| Step: 9
Training loss: 4.238247394561768
Validation loss: 4.002998987833659

Epoch: 6| Step: 10
Training loss: 4.026760101318359
Validation loss: 3.997018575668335

Epoch: 6| Step: 11
Training loss: 4.117827415466309
Validation loss: 3.9916218916575112

Epoch: 6| Step: 12
Training loss: 4.574277400970459
Validation loss: 3.986649672190348

Epoch: 6| Step: 13
Training loss: 4.226672649383545
Validation loss: 3.9807129303614297

Epoch: 16| Step: 0
Training loss: 4.762245178222656
Validation loss: 3.9758370320002236

Epoch: 6| Step: 1
Training loss: 4.118405342102051
Validation loss: 3.971726139386495

Epoch: 6| Step: 2
Training loss: 3.906217336654663
Validation loss: 3.9657605489095054

Epoch: 6| Step: 3
Training loss: 5.206861972808838
Validation loss: 3.9602301120758057

Epoch: 6| Step: 4
Training loss: 4.261190414428711
Validation loss: 3.9552008310953775

Epoch: 6| Step: 5
Training loss: 4.064208030700684
Validation loss: 3.949432373046875

Epoch: 6| Step: 6
Training loss: 3.024036407470703
Validation loss: 3.944585601488749

Epoch: 6| Step: 7
Training loss: 4.381388187408447
Validation loss: 3.941227356592814

Epoch: 6| Step: 8
Training loss: 3.8192319869995117
Validation loss: 3.9343899488449097

Epoch: 6| Step: 9
Training loss: 3.107391119003296
Validation loss: 3.928359627723694

Epoch: 6| Step: 10
Training loss: 4.848073959350586
Validation loss: 3.9238421519597373

Epoch: 6| Step: 11
Training loss: 4.1999006271362305
Validation loss: 3.91892679532369

Epoch: 6| Step: 12
Training loss: 4.151000499725342
Validation loss: 3.914869785308838

Epoch: 6| Step: 13
Training loss: 3.4009785652160645
Validation loss: 3.90906023979187

Epoch: 17| Step: 0
Training loss: 3.4337987899780273
Validation loss: 3.903367757797241

Epoch: 6| Step: 1
Training loss: 4.118112564086914
Validation loss: 3.898068904876709

Epoch: 6| Step: 2
Training loss: 3.0401997566223145
Validation loss: 3.893676996231079

Epoch: 6| Step: 3
Training loss: 4.691619396209717
Validation loss: 3.887581785519918

Epoch: 6| Step: 4
Training loss: 3.356497287750244
Validation loss: 3.883116364479065

Epoch: 6| Step: 5
Training loss: 4.592177867889404
Validation loss: 3.8775399923324585

Epoch: 6| Step: 6
Training loss: 4.180629253387451
Validation loss: 3.8728436628977456

Epoch: 6| Step: 7
Training loss: 4.311969757080078
Validation loss: 3.868783791859945

Epoch: 6| Step: 8
Training loss: 4.62592887878418
Validation loss: 3.86329452196757

Epoch: 6| Step: 9
Training loss: 4.06411075592041
Validation loss: 3.8584813674290976

Epoch: 6| Step: 10
Training loss: 3.697544813156128
Validation loss: 3.8548292318979898

Epoch: 6| Step: 11
Training loss: 3.8415961265563965
Validation loss: 3.8514793713887534

Epoch: 6| Step: 12
Training loss: 3.724309206008911
Validation loss: 3.843483567237854

Epoch: 6| Step: 13
Training loss: 4.6248779296875
Validation loss: 3.839570681254069

Epoch: 18| Step: 0
Training loss: 5.17886209487915
Validation loss: 3.8351528644561768

Epoch: 6| Step: 1
Training loss: 4.014919281005859
Validation loss: 3.8303151528040567

Epoch: 6| Step: 2
Training loss: 4.0035319328308105
Validation loss: 3.8232397635777793

Epoch: 6| Step: 3
Training loss: 4.081130027770996
Validation loss: 3.818660298983256

Epoch: 6| Step: 4
Training loss: 3.4440178871154785
Validation loss: 3.8141311009724936

Epoch: 6| Step: 5
Training loss: 2.3784430027008057
Validation loss: 3.809291362762451

Epoch: 6| Step: 6
Training loss: 3.8882086277008057
Validation loss: 3.8045602242151895

Epoch: 6| Step: 7
Training loss: 3.4187302589416504
Validation loss: 3.799856265385946

Epoch: 6| Step: 8
Training loss: 4.500524520874023
Validation loss: 3.7941855589548745

Epoch: 6| Step: 9
Training loss: 3.5360164642333984
Validation loss: 3.7897512515385947

Epoch: 6| Step: 10
Training loss: 4.707000255584717
Validation loss: 3.7861274878184

Epoch: 6| Step: 11
Training loss: 3.515946626663208
Validation loss: 3.782299598058065

Epoch: 6| Step: 12
Training loss: 4.632510185241699
Validation loss: 3.775768995285034

Epoch: 6| Step: 13
Training loss: 4.112422943115234
Validation loss: 3.770649552345276

Epoch: 19| Step: 0
Training loss: 5.408715724945068
Validation loss: 3.76715624332428

Epoch: 6| Step: 1
Training loss: 4.105144023895264
Validation loss: 3.7633383671442666

Epoch: 6| Step: 2
Training loss: 3.8923239707946777
Validation loss: 3.7584245999654136

Epoch: 6| Step: 3
Training loss: 3.5553107261657715
Validation loss: 3.7520545721054077

Epoch: 6| Step: 4
Training loss: 3.898963212966919
Validation loss: 3.746787746747335

Epoch: 6| Step: 5
Training loss: 3.7036800384521484
Validation loss: 3.7427927255630493

Epoch: 6| Step: 6
Training loss: 4.370948314666748
Validation loss: 3.7375928163528442

Epoch: 6| Step: 7
Training loss: 3.921499729156494
Validation loss: 3.7324013312657676

Epoch: 6| Step: 8
Training loss: 4.321935176849365
Validation loss: 3.7278382778167725

Epoch: 6| Step: 9
Training loss: 3.0446677207946777
Validation loss: 3.725010951360067

Epoch: 6| Step: 10
Training loss: 2.363381862640381
Validation loss: 3.7182911237080893

Epoch: 6| Step: 11
Training loss: 4.04779052734375
Validation loss: 3.7133489847183228

Epoch: 6| Step: 12
Training loss: 4.031116008758545
Validation loss: 3.7104936838150024

Epoch: 6| Step: 13
Training loss: 3.8877882957458496
Validation loss: 3.707946022351583

Epoch: 20| Step: 0
Training loss: 3.50380802154541
Validation loss: 3.704070965449015

Epoch: 6| Step: 1
Training loss: 3.4773101806640625
Validation loss: 3.6979772249857583

Epoch: 6| Step: 2
Training loss: 4.134505271911621
Validation loss: 3.692004998524984

Epoch: 6| Step: 3
Training loss: 3.9990105628967285
Validation loss: 3.6877265771230063

Epoch: 6| Step: 4
Training loss: 4.267211437225342
Validation loss: 3.6840017636617026

Epoch: 6| Step: 5
Training loss: 3.495025157928467
Validation loss: 3.678807179133097

Epoch: 6| Step: 6
Training loss: 3.5641136169433594
Validation loss: 3.6747482220331826

Epoch: 6| Step: 7
Training loss: 3.5072059631347656
Validation loss: 3.670740564664205

Epoch: 6| Step: 8
Training loss: 3.986440896987915
Validation loss: 3.665204564730326

Epoch: 6| Step: 9
Training loss: 3.29642915725708
Validation loss: 3.6602959632873535

Epoch: 6| Step: 10
Training loss: 3.6669363975524902
Validation loss: 3.65670116742452

Epoch: 6| Step: 11
Training loss: 4.050703525543213
Validation loss: 3.651789387067159

Epoch: 6| Step: 12
Training loss: 3.71710467338562
Validation loss: 3.6479386488596597

Epoch: 6| Step: 13
Training loss: 5.032405376434326
Validation loss: 3.644077936808268

Epoch: 21| Step: 0
Training loss: 3.699082136154175
Validation loss: 3.6386822859446206

Epoch: 6| Step: 1
Training loss: 3.15553617477417
Validation loss: 3.6342377265294394

Epoch: 6| Step: 2
Training loss: 3.7636168003082275
Validation loss: 3.6300763289133706

Epoch: 6| Step: 3
Training loss: 3.0427587032318115
Validation loss: 3.62580943107605

Epoch: 6| Step: 4
Training loss: 3.701838970184326
Validation loss: 3.6221115986506143

Epoch: 6| Step: 5
Training loss: 4.381044864654541
Validation loss: 3.6170524756113687

Epoch: 6| Step: 6
Training loss: 4.329818248748779
Validation loss: 3.612257440884908

Epoch: 6| Step: 7
Training loss: 4.0572919845581055
Validation loss: 3.6071229378382363

Epoch: 6| Step: 8
Training loss: 4.666667938232422
Validation loss: 3.6042526165644326

Epoch: 6| Step: 9
Training loss: 3.891310214996338
Validation loss: 3.599419871966044

Epoch: 6| Step: 10
Training loss: 3.4528822898864746
Validation loss: 3.5952436129252114

Epoch: 6| Step: 11
Training loss: 4.357499122619629
Validation loss: 3.590287923812866

Epoch: 6| Step: 12
Training loss: 3.798539638519287
Validation loss: 3.5854381322860718

Epoch: 6| Step: 13
Training loss: 2.515504837036133
Validation loss: 3.5811678965886435

Epoch: 22| Step: 0
Training loss: 3.5941505432128906
Validation loss: 3.5765403509140015

Epoch: 6| Step: 1
Training loss: 3.3722567558288574
Validation loss: 3.5722179810206094

Epoch: 6| Step: 2
Training loss: 3.4256248474121094
Validation loss: 3.567830721537272

Epoch: 6| Step: 3
Training loss: 3.797427177429199
Validation loss: 3.563322067260742

Epoch: 6| Step: 4
Training loss: 3.5741519927978516
Validation loss: 3.5581063826878867

Epoch: 6| Step: 5
Training loss: 4.416653633117676
Validation loss: 3.5538383324941

Epoch: 6| Step: 6
Training loss: 3.7187371253967285
Validation loss: 3.5496529738108316

Epoch: 6| Step: 7
Training loss: 3.1779356002807617
Validation loss: 3.5443111658096313

Epoch: 6| Step: 8
Training loss: 3.3133797645568848
Validation loss: 3.540425499280294

Epoch: 6| Step: 9
Training loss: 3.148074150085449
Validation loss: 3.53585422039032

Epoch: 6| Step: 10
Training loss: 3.313382863998413
Validation loss: 3.5312029918034873

Epoch: 6| Step: 11
Training loss: 5.236307144165039
Validation loss: 3.5269894202550254

Epoch: 6| Step: 12
Training loss: 4.596507549285889
Validation loss: 3.5220757722854614

Epoch: 6| Step: 13
Training loss: 3.272360324859619
Validation loss: 3.517450531323751

Epoch: 23| Step: 0
Training loss: 4.15323543548584
Validation loss: 3.5127575397491455

Epoch: 6| Step: 1
Training loss: 4.220149993896484
Validation loss: 3.5089468161265054

Epoch: 6| Step: 2
Training loss: 3.415464162826538
Validation loss: 3.5038395722707114

Epoch: 6| Step: 3
Training loss: 3.8563313484191895
Validation loss: 3.4996613264083862

Epoch: 6| Step: 4
Training loss: 4.010065078735352
Validation loss: 3.4959820906321206

Epoch: 6| Step: 5
Training loss: 3.5768439769744873
Validation loss: 3.491104006767273

Epoch: 6| Step: 6
Training loss: 2.9227335453033447
Validation loss: 3.4867610534032187

Epoch: 6| Step: 7
Training loss: 3.969888925552368
Validation loss: 3.481810688972473

Epoch: 6| Step: 8
Training loss: 3.8035852909088135
Validation loss: 3.4772810141245523

Epoch: 6| Step: 9
Training loss: 4.303220748901367
Validation loss: 3.472870707511902

Epoch: 6| Step: 10
Training loss: 2.6964755058288574
Validation loss: 3.4679126739501953

Epoch: 6| Step: 11
Training loss: 3.993663787841797
Validation loss: 3.463984568913778

Epoch: 6| Step: 12
Training loss: 2.9426355361938477
Validation loss: 3.45925772190094

Epoch: 6| Step: 13
Training loss: 3.241061210632324
Validation loss: 3.4547811349232993

Epoch: 24| Step: 0
Training loss: 4.3348917961120605
Validation loss: 3.449587345123291

Epoch: 6| Step: 1
Training loss: 3.2949862480163574
Validation loss: 3.444976051648458

Epoch: 6| Step: 2
Training loss: 2.6284377574920654
Validation loss: 3.4407848517100015

Epoch: 6| Step: 3
Training loss: 4.521547317504883
Validation loss: 3.435899019241333

Epoch: 6| Step: 4
Training loss: 2.259265661239624
Validation loss: 3.431600054105123

Epoch: 6| Step: 5
Training loss: 3.586884021759033
Validation loss: 3.4273512760798135

Epoch: 6| Step: 6
Training loss: 3.8767337799072266
Validation loss: 3.42313814163208

Epoch: 6| Step: 7
Training loss: 3.654207706451416
Validation loss: 3.418192744255066

Epoch: 6| Step: 8
Training loss: 4.1601409912109375
Validation loss: 3.4140493869781494

Epoch: 6| Step: 9
Training loss: 2.4784188270568848
Validation loss: 3.4094256162643433

Epoch: 6| Step: 10
Training loss: 3.7396607398986816
Validation loss: 3.4054592847824097

Epoch: 6| Step: 11
Training loss: 3.9488108158111572
Validation loss: 3.4011804262797036

Epoch: 6| Step: 12
Training loss: 4.113532543182373
Validation loss: 3.3968347708384194

Epoch: 6| Step: 13
Training loss: 3.6519980430603027
Validation loss: 3.3925681114196777

Epoch: 25| Step: 0
Training loss: 4.386382579803467
Validation loss: 3.388356645901998

Epoch: 6| Step: 1
Training loss: 4.289406776428223
Validation loss: 3.3837135235468545

Epoch: 6| Step: 2
Training loss: 4.419610977172852
Validation loss: 3.379392464955648

Epoch: 6| Step: 3
Training loss: 2.5590994358062744
Validation loss: 3.37525204817454

Epoch: 6| Step: 4
Training loss: 3.0301549434661865
Validation loss: 3.370827039082845

Epoch: 6| Step: 5
Training loss: 2.727983236312866
Validation loss: 3.366499940554301

Epoch: 6| Step: 6
Training loss: 3.4034571647644043
Validation loss: 3.3615235884984336

Epoch: 6| Step: 7
Training loss: 4.086391925811768
Validation loss: 3.3574976126352944

Epoch: 6| Step: 8
Training loss: 3.278273105621338
Validation loss: 3.3532246748606362

Epoch: 6| Step: 9
Training loss: 3.9009904861450195
Validation loss: 3.34955624739329

Epoch: 6| Step: 10
Training loss: 4.051025390625
Validation loss: 3.344902237256368

Epoch: 6| Step: 11
Training loss: 3.254380226135254
Validation loss: 3.3402740557988486

Epoch: 6| Step: 12
Training loss: 2.751596212387085
Validation loss: 3.3353998263676963

Epoch: 6| Step: 13
Training loss: 3.302021026611328
Validation loss: 3.331614057223002

Epoch: 26| Step: 0
Training loss: 4.175025939941406
Validation loss: 3.3277063369750977

Epoch: 6| Step: 1
Training loss: 3.3219552040100098
Validation loss: 3.3236255248387656

Epoch: 6| Step: 2
Training loss: 3.7661006450653076
Validation loss: 3.3193229039510093

Epoch: 6| Step: 3
Training loss: 2.302211284637451
Validation loss: 3.3148266871770224

Epoch: 6| Step: 4
Training loss: 4.623711109161377
Validation loss: 3.3110586404800415

Epoch: 6| Step: 5
Training loss: 2.8275508880615234
Validation loss: 3.3060746590296426

Epoch: 6| Step: 6
Training loss: 3.830838680267334
Validation loss: 3.30156679948171

Epoch: 6| Step: 7
Training loss: 2.5801496505737305
Validation loss: 3.297219673792521

Epoch: 6| Step: 8
Training loss: 3.1291263103485107
Validation loss: 3.2932563622792563

Epoch: 6| Step: 9
Training loss: 3.796812057495117
Validation loss: 3.289397438367208

Epoch: 6| Step: 10
Training loss: 3.895894765853882
Validation loss: 3.2855094273885093

Epoch: 6| Step: 11
Training loss: 3.687579393386841
Validation loss: 3.2812567551930747

Epoch: 6| Step: 12
Training loss: 3.0962886810302734
Validation loss: 3.2771912018458047

Epoch: 6| Step: 13
Training loss: 3.6418652534484863
Validation loss: 3.2738068103790283

Epoch: 27| Step: 0
Training loss: 3.4132843017578125
Validation loss: 3.2700643142064414

Epoch: 6| Step: 1
Training loss: 4.004643440246582
Validation loss: 3.2659217913945517

Epoch: 6| Step: 2
Training loss: 3.8925576210021973
Validation loss: 3.2616599400838218

Epoch: 6| Step: 3
Training loss: 3.6705093383789062
Validation loss: 3.2575645446777344

Epoch: 6| Step: 4
Training loss: 2.7717041969299316
Validation loss: 3.2535614569981894

Epoch: 6| Step: 5
Training loss: 2.344364643096924
Validation loss: 3.2497963905334473

Epoch: 6| Step: 6
Training loss: 4.150609493255615
Validation loss: 3.246126373608907

Epoch: 6| Step: 7
Training loss: 3.895003080368042
Validation loss: 3.242128054300944

Epoch: 6| Step: 8
Training loss: 3.102139711380005
Validation loss: 3.237556298573812

Epoch: 6| Step: 9
Training loss: 2.857064723968506
Validation loss: 3.233861525853475

Epoch: 6| Step: 10
Training loss: 3.343069076538086
Validation loss: 3.2295451164245605

Epoch: 6| Step: 11
Training loss: 3.970963954925537
Validation loss: 3.225249489148458

Epoch: 6| Step: 12
Training loss: 3.546412467956543
Validation loss: 3.221619804700216

Epoch: 6| Step: 13
Training loss: 2.9725122451782227
Validation loss: 3.2172855138778687

Epoch: 28| Step: 0
Training loss: 2.68403959274292
Validation loss: 3.2134049336115518

Epoch: 6| Step: 1
Training loss: 3.9251668453216553
Validation loss: 3.2096352577209473

Epoch: 6| Step: 2
Training loss: 3.025486707687378
Validation loss: 3.205507198969523

Epoch: 6| Step: 3
Training loss: 3.2639288902282715
Validation loss: 3.202046275138855

Epoch: 6| Step: 4
Training loss: 4.0434346199035645
Validation loss: 3.1983039379119873

Epoch: 6| Step: 5
Training loss: 2.4629929065704346
Validation loss: 3.1939842303593955

Epoch: 6| Step: 6
Training loss: 3.162973642349243
Validation loss: 3.1906495491663613

Epoch: 6| Step: 7
Training loss: 3.252830982208252
Validation loss: 3.186408360799154

Epoch: 6| Step: 8
Training loss: 4.090311050415039
Validation loss: 3.182661692301432

Epoch: 6| Step: 9
Training loss: 3.9236438274383545
Validation loss: 3.1782410542170205

Epoch: 6| Step: 10
Training loss: 3.1022567749023438
Validation loss: 3.17372719446818

Epoch: 6| Step: 11
Training loss: 3.355046510696411
Validation loss: 3.1700188318888345

Epoch: 6| Step: 12
Training loss: 3.649082660675049
Validation loss: 3.1661234696706138

Epoch: 6| Step: 13
Training loss: 3.251582145690918
Validation loss: 3.1624563535054526

Epoch: 29| Step: 0
Training loss: 3.80110239982605
Validation loss: 3.1585596799850464

Epoch: 6| Step: 1
Training loss: 3.42016863822937
Validation loss: 3.154153267542521

Epoch: 6| Step: 2
Training loss: 1.960859775543213
Validation loss: 3.150348663330078

Epoch: 6| Step: 3
Training loss: 4.074068546295166
Validation loss: 3.1465706825256348

Epoch: 6| Step: 4
Training loss: 3.23649525642395
Validation loss: 3.1425376733144126

Epoch: 6| Step: 5
Training loss: 3.9218785762786865
Validation loss: 3.138885180155436

Epoch: 6| Step: 6
Training loss: 2.8353805541992188
Validation loss: 3.1344013611475625

Epoch: 6| Step: 7
Training loss: 2.5256528854370117
Validation loss: 3.130494753519694

Epoch: 6| Step: 8
Training loss: 3.4635515213012695
Validation loss: 3.1267945369084678

Epoch: 6| Step: 9
Training loss: 3.107205390930176
Validation loss: 3.1226302782694497

Epoch: 6| Step: 10
Training loss: 3.3625378608703613
Validation loss: 3.1187535921732583

Epoch: 6| Step: 11
Training loss: 3.4090898036956787
Validation loss: 3.114753246307373

Epoch: 6| Step: 12
Training loss: 3.4223244190216064
Validation loss: 3.1110264460245767

Epoch: 6| Step: 13
Training loss: 3.949770212173462
Validation loss: 3.106711268424988

Epoch: 30| Step: 0
Training loss: 3.6765904426574707
Validation loss: 3.1029287576675415

Epoch: 6| Step: 1
Training loss: 3.6756339073181152
Validation loss: 3.0992725690205893

Epoch: 6| Step: 2
Training loss: 2.8821120262145996
Validation loss: 3.0951157410939536

Epoch: 6| Step: 3
Training loss: 3.4163546562194824
Validation loss: 3.0910704533259072

Epoch: 6| Step: 4
Training loss: 2.713639259338379
Validation loss: 3.0872427225112915

Epoch: 6| Step: 5
Training loss: 2.4670543670654297
Validation loss: 3.0833067496617637

Epoch: 6| Step: 6
Training loss: 3.430490255355835
Validation loss: 3.079610904057821

Epoch: 6| Step: 7
Training loss: 2.9060683250427246
Validation loss: 3.07576584815979

Epoch: 6| Step: 8
Training loss: 3.214096784591675
Validation loss: 3.071580648422241

Epoch: 6| Step: 9
Training loss: 2.9474637508392334
Validation loss: 3.0670796632766724

Epoch: 6| Step: 10
Training loss: 3.899181842803955
Validation loss: 3.0635812679926553

Epoch: 6| Step: 11
Training loss: 3.679631233215332
Validation loss: 3.0593345165252686

Epoch: 6| Step: 12
Training loss: 3.1542351245880127
Validation loss: 3.055030425389608

Epoch: 6| Step: 13
Training loss: 3.682569980621338
Validation loss: 3.051097353299459

Epoch: 31| Step: 0
Training loss: 3.329253673553467
Validation loss: 3.0469786723454795

Epoch: 6| Step: 1
Training loss: 3.4480128288269043
Validation loss: 3.043754061063131

Epoch: 6| Step: 2
Training loss: 3.4787683486938477
Validation loss: 3.039685845375061

Epoch: 6| Step: 3
Training loss: 2.758328437805176
Validation loss: 3.0359318256378174

Epoch: 6| Step: 4
Training loss: 3.374140501022339
Validation loss: 3.03184982140859

Epoch: 6| Step: 5
Training loss: 3.6548914909362793
Validation loss: 3.0278896490732827

Epoch: 6| Step: 6
Training loss: 3.103252410888672
Validation loss: 3.0242382287979126

Epoch: 6| Step: 7
Training loss: 2.6993346214294434
Validation loss: 3.020020524660746

Epoch: 6| Step: 8
Training loss: 2.399106025695801
Validation loss: 3.0174574851989746

Epoch: 6| Step: 9
Training loss: 3.072559356689453
Validation loss: 3.0137850840886435

Epoch: 6| Step: 10
Training loss: 3.7644126415252686
Validation loss: 3.010595122973124

Epoch: 6| Step: 11
Training loss: 2.909327507019043
Validation loss: 3.0073372522989907

Epoch: 6| Step: 12
Training loss: 3.5761146545410156
Validation loss: 3.003374139467875

Epoch: 6| Step: 13
Training loss: 3.4311602115631104
Validation loss: 2.9991345405578613

Epoch: 32| Step: 0
Training loss: 2.5110111236572266
Validation loss: 2.9961053927739463

Epoch: 6| Step: 1
Training loss: 2.2566680908203125
Validation loss: 2.992360234260559

Epoch: 6| Step: 2
Training loss: 2.680654525756836
Validation loss: 2.988611896832784

Epoch: 6| Step: 3
Training loss: 2.657064914703369
Validation loss: 2.98511536916097

Epoch: 6| Step: 4
Training loss: 2.7148540019989014
Validation loss: 2.981831510861715

Epoch: 6| Step: 5
Training loss: 3.491154670715332
Validation loss: 2.978634317715963

Epoch: 6| Step: 6
Training loss: 3.6557955741882324
Validation loss: 2.9750978549321494

Epoch: 6| Step: 7
Training loss: 3.1370630264282227
Validation loss: 2.9718503952026367

Epoch: 6| Step: 8
Training loss: 3.2753138542175293
Validation loss: 2.968678832054138

Epoch: 6| Step: 9
Training loss: 4.4116106033325195
Validation loss: 2.9652617375055947

Epoch: 6| Step: 10
Training loss: 2.923536777496338
Validation loss: 2.9624406894048056

Epoch: 6| Step: 11
Training loss: 3.7008657455444336
Validation loss: 2.95870308081309

Epoch: 6| Step: 12
Training loss: 3.335831880569458
Validation loss: 2.955138405164083

Epoch: 6| Step: 13
Training loss: 3.6003146171569824
Validation loss: 2.9507898886998496

Epoch: 33| Step: 0
Training loss: 2.8471412658691406
Validation loss: 2.9468713998794556

Epoch: 6| Step: 1
Training loss: 3.2651870250701904
Validation loss: 2.943401654561361

Epoch: 6| Step: 2
Training loss: 3.293867349624634
Validation loss: 2.939771811167399

Epoch: 6| Step: 3
Training loss: 3.5053162574768066
Validation loss: 2.9360200564066568

Epoch: 6| Step: 4
Training loss: 3.8624768257141113
Validation loss: 2.932002862294515

Epoch: 6| Step: 5
Training loss: 3.179208993911743
Validation loss: 2.9281384547551474

Epoch: 6| Step: 6
Training loss: 3.3263516426086426
Validation loss: 2.923959414164225

Epoch: 6| Step: 7
Training loss: 2.318427562713623
Validation loss: 2.9202178716659546

Epoch: 6| Step: 8
Training loss: 2.5404977798461914
Validation loss: 2.9160850842793784

Epoch: 6| Step: 9
Training loss: 3.211313247680664
Validation loss: 2.913017471631368

Epoch: 6| Step: 10
Training loss: 3.0552978515625
Validation loss: 2.909575343132019

Epoch: 6| Step: 11
Training loss: 3.198513984680176
Validation loss: 2.9065680503845215

Epoch: 6| Step: 12
Training loss: 3.2524662017822266
Validation loss: 2.9033759435017905

Epoch: 6| Step: 13
Training loss: 2.942833662033081
Validation loss: 2.8996794621149697

Epoch: 34| Step: 0
Training loss: 2.785614490509033
Validation loss: 2.8967631260553994

Epoch: 6| Step: 1
Training loss: 3.8255226612091064
Validation loss: 2.8932480414708457

Epoch: 6| Step: 2
Training loss: 3.373544692993164
Validation loss: 2.88977058728536

Epoch: 6| Step: 3
Training loss: 2.762275218963623
Validation loss: 2.886554559071859

Epoch: 6| Step: 4
Training loss: 3.487121105194092
Validation loss: 2.883182922999064

Epoch: 6| Step: 5
Training loss: 2.2129156589508057
Validation loss: 2.880046804745992

Epoch: 6| Step: 6
Training loss: 3.0390098094940186
Validation loss: 2.877427121003469

Epoch: 6| Step: 7
Training loss: 3.1949431896209717
Validation loss: 2.874013980229696

Epoch: 6| Step: 8
Training loss: 3.4686508178710938
Validation loss: 2.871246576309204

Epoch: 6| Step: 9
Training loss: 3.187887191772461
Validation loss: 2.868149479230245

Epoch: 6| Step: 10
Training loss: 3.209681987762451
Validation loss: 2.8650283416112265

Epoch: 6| Step: 11
Training loss: 3.2839951515197754
Validation loss: 2.861857811609904

Epoch: 6| Step: 12
Training loss: 2.4743387699127197
Validation loss: 2.858810544013977

Epoch: 6| Step: 13
Training loss: 2.8790464401245117
Validation loss: 2.8553126653035483

Epoch: 35| Step: 0
Training loss: 3.08579421043396
Validation loss: 2.852411985397339

Epoch: 6| Step: 1
Training loss: 3.7521772384643555
Validation loss: 2.8487254778544107

Epoch: 6| Step: 2
Training loss: 2.7084455490112305
Validation loss: 2.8454810778299966

Epoch: 6| Step: 3
Training loss: 3.1220736503601074
Validation loss: 2.8423847754796348

Epoch: 6| Step: 4
Training loss: 3.600721597671509
Validation loss: 2.838781793912252

Epoch: 6| Step: 5
Training loss: 3.594230890274048
Validation loss: 2.8358315229415894

Epoch: 6| Step: 6
Training loss: 3.029557466506958
Validation loss: 2.832180301348368

Epoch: 6| Step: 7
Training loss: 2.3446156978607178
Validation loss: 2.829217473665873

Epoch: 6| Step: 8
Training loss: 3.070042133331299
Validation loss: 2.8264379103978476

Epoch: 6| Step: 9
Training loss: 3.5164270401000977
Validation loss: 2.8231393496195474

Epoch: 6| Step: 10
Training loss: 2.850342273712158
Validation loss: 2.820291837056478

Epoch: 6| Step: 11
Training loss: 2.447005271911621
Validation loss: 2.8174591859181723

Epoch: 6| Step: 12
Training loss: 2.496912956237793
Validation loss: 2.814198056856791

Epoch: 6| Step: 13
Training loss: 3.0146045684814453
Validation loss: 2.8115965127944946

Epoch: 36| Step: 0
Training loss: 2.795713186264038
Validation loss: 2.809469223022461

Epoch: 6| Step: 1
Training loss: 2.9973511695861816
Validation loss: 2.806474963823954

Epoch: 6| Step: 2
Training loss: 3.175748586654663
Validation loss: 2.803755283355713

Epoch: 6| Step: 3
Training loss: 3.0083975791931152
Validation loss: 2.800109585126241

Epoch: 6| Step: 4
Training loss: 2.9132604598999023
Validation loss: 2.7975300947825112

Epoch: 6| Step: 5
Training loss: 2.722740650177002
Validation loss: 2.7946560780207315

Epoch: 6| Step: 6
Training loss: 2.614077568054199
Validation loss: 2.792068123817444

Epoch: 6| Step: 7
Training loss: 2.9331326484680176
Validation loss: 2.7902925411860147

Epoch: 6| Step: 8
Training loss: 2.491786241531372
Validation loss: 2.786767601966858

Epoch: 6| Step: 9
Training loss: 3.366334915161133
Validation loss: 2.7844552596410117

Epoch: 6| Step: 10
Training loss: 3.4639315605163574
Validation loss: 2.782670338948568

Epoch: 6| Step: 11
Training loss: 3.134464979171753
Validation loss: 2.7786357005437217

Epoch: 6| Step: 12
Training loss: 2.6091678142547607
Validation loss: 2.777379631996155

Epoch: 6| Step: 13
Training loss: 3.818166732788086
Validation loss: 2.7746115922927856

Epoch: 37| Step: 0
Training loss: 3.4315593242645264
Validation loss: 2.77219287554423

Epoch: 6| Step: 1
Training loss: 2.121706485748291
Validation loss: 2.768772006034851

Epoch: 6| Step: 2
Training loss: 3.6245017051696777
Validation loss: 2.7667267322540283

Epoch: 6| Step: 3
Training loss: 3.1899282932281494
Validation loss: 2.764288624127706

Epoch: 6| Step: 4
Training loss: 2.950700283050537
Validation loss: 2.7611864805221558

Epoch: 6| Step: 5
Training loss: 2.9029252529144287
Validation loss: 2.7577629884084067

Epoch: 6| Step: 6
Training loss: 3.196990966796875
Validation loss: 2.7542421420415244

Epoch: 6| Step: 7
Training loss: 3.269239664077759
Validation loss: 2.7507539987564087

Epoch: 6| Step: 8
Training loss: 3.2192635536193848
Validation loss: 2.7471547524134317

Epoch: 6| Step: 9
Training loss: 2.1713333129882812
Validation loss: 2.7439018885294595

Epoch: 6| Step: 10
Training loss: 2.6613879203796387
Validation loss: 2.740293502807617

Epoch: 6| Step: 11
Training loss: 3.3610119819641113
Validation loss: 2.7367857694625854

Epoch: 6| Step: 12
Training loss: 2.234793186187744
Validation loss: 2.7347993652025857

Epoch: 6| Step: 13
Training loss: 3.1872129440307617
Validation loss: 2.7318400939305625

Epoch: 38| Step: 0
Training loss: 2.3354392051696777
Validation loss: 2.7353491385777793

Epoch: 6| Step: 1
Training loss: 3.14382004737854
Validation loss: 2.771743059158325

Epoch: 6| Step: 2
Training loss: 2.9764227867126465
Validation loss: 2.7280099789301553

Epoch: 6| Step: 3
Training loss: 3.2573065757751465
Validation loss: 2.7233097155888877

Epoch: 6| Step: 4
Training loss: 2.5088436603546143
Validation loss: 2.7220086654027305

Epoch: 6| Step: 5
Training loss: 3.319542646408081
Validation loss: 2.723479151725769

Epoch: 6| Step: 6
Training loss: 2.7638444900512695
Validation loss: 2.7231287956237793

Epoch: 6| Step: 7
Training loss: 2.9001779556274414
Validation loss: 2.7281276981035867

Epoch: 6| Step: 8
Training loss: 3.212505578994751
Validation loss: 2.7233781019846597

Epoch: 6| Step: 9
Training loss: 3.010340452194214
Validation loss: 2.715413729349772

Epoch: 6| Step: 10
Training loss: 2.2511143684387207
Validation loss: 2.710924506187439

Epoch: 6| Step: 11
Training loss: 3.1927661895751953
Validation loss: 2.7076361179351807

Epoch: 6| Step: 12
Training loss: 2.7943670749664307
Validation loss: 2.707817792892456

Epoch: 6| Step: 13
Training loss: 3.402021646499634
Validation loss: 2.7044831116994223

Epoch: 39| Step: 0
Training loss: 3.3947229385375977
Validation loss: 2.699656287829081

Epoch: 6| Step: 1
Training loss: 2.6813530921936035
Validation loss: 2.6952038606007895

Epoch: 6| Step: 2
Training loss: 3.1220669746398926
Validation loss: 2.691301782925924

Epoch: 6| Step: 3
Training loss: 2.698961019515991
Validation loss: 2.6873621543248496

Epoch: 6| Step: 4
Training loss: 2.828239679336548
Validation loss: 2.6836818854014077

Epoch: 6| Step: 5
Training loss: 2.737337827682495
Validation loss: 2.68104495604833

Epoch: 6| Step: 6
Training loss: 2.8921196460723877
Validation loss: 2.678371866544088

Epoch: 6| Step: 7
Training loss: 3.069211959838867
Validation loss: 2.6758922338485718

Epoch: 6| Step: 8
Training loss: 2.738985776901245
Validation loss: 2.672671635945638

Epoch: 6| Step: 9
Training loss: 3.4927854537963867
Validation loss: 2.669402519861857

Epoch: 6| Step: 10
Training loss: 2.3963561058044434
Validation loss: 2.667779246966044

Epoch: 6| Step: 11
Training loss: 2.2401041984558105
Validation loss: 2.6639297008514404

Epoch: 6| Step: 12
Training loss: 2.9309186935424805
Validation loss: 2.6610986391703286

Epoch: 6| Step: 13
Training loss: 3.1716129779815674
Validation loss: 2.65803333123525

Epoch: 40| Step: 0
Training loss: 3.01336669921875
Validation loss: 2.6552244822184243

Epoch: 6| Step: 1
Training loss: 3.011333465576172
Validation loss: 2.651775677998861

Epoch: 6| Step: 2
Training loss: 3.566819906234741
Validation loss: 2.6485824386278787

Epoch: 6| Step: 3
Training loss: 2.7477316856384277
Validation loss: 2.645039916038513

Epoch: 6| Step: 4
Training loss: 2.435197353363037
Validation loss: 2.6426545778910318

Epoch: 6| Step: 5
Training loss: 2.669543743133545
Validation loss: 2.6394547621409097

Epoch: 6| Step: 6
Training loss: 3.1132354736328125
Validation loss: 2.6362226009368896

Epoch: 6| Step: 7
Training loss: 2.5708746910095215
Validation loss: 2.632689118385315

Epoch: 6| Step: 8
Training loss: 2.926997184753418
Validation loss: 2.6302630503972373

Epoch: 6| Step: 9
Training loss: 2.0511386394500732
Validation loss: 2.626164277394613

Epoch: 6| Step: 10
Training loss: 2.758273124694824
Validation loss: 2.624508817990621

Epoch: 6| Step: 11
Training loss: 2.8952009677886963
Validation loss: 2.620129863421122

Epoch: 6| Step: 12
Training loss: 3.4376165866851807
Validation loss: 2.6178763707478843

Epoch: 6| Step: 13
Training loss: 2.549131393432617
Validation loss: 2.6140369176864624

Epoch: 41| Step: 0
Training loss: 3.482745885848999
Validation loss: 2.6098385651906333

Epoch: 6| Step: 1
Training loss: 2.720010280609131
Validation loss: 2.606313645839691

Epoch: 6| Step: 2
Training loss: 2.2183837890625
Validation loss: 2.6046341260274253

Epoch: 6| Step: 3
Training loss: 2.457078695297241
Validation loss: 2.599840601285299

Epoch: 6| Step: 4
Training loss: 2.7728159427642822
Validation loss: 2.598410884539286

Epoch: 6| Step: 5
Training loss: 3.3848490715026855
Validation loss: 2.595633029937744

Epoch: 6| Step: 6
Training loss: 1.8886233568191528
Validation loss: 2.5903091033299765

Epoch: 6| Step: 7
Training loss: 3.2788023948669434
Validation loss: 2.5901883045832315

Epoch: 6| Step: 8
Training loss: 2.777869701385498
Validation loss: 2.5895790656407676

Epoch: 6| Step: 9
Training loss: 3.038546562194824
Validation loss: 2.587269345919291

Epoch: 6| Step: 10
Training loss: 3.3185172080993652
Validation loss: 2.580143928527832

Epoch: 6| Step: 11
Training loss: 3.0846028327941895
Validation loss: 2.5786136786142984

Epoch: 6| Step: 12
Training loss: 2.5566115379333496
Validation loss: 2.577793061733246

Epoch: 6| Step: 13
Training loss: 2.183896064758301
Validation loss: 2.5777623653411865

Epoch: 42| Step: 0
Training loss: 2.6517324447631836
Validation loss: 2.5767436623573303

Epoch: 6| Step: 1
Training loss: 2.8816678524017334
Validation loss: 2.577812373638153

Epoch: 6| Step: 2
Training loss: 2.6228203773498535
Validation loss: 2.5759050846099854

Epoch: 6| Step: 3
Training loss: 3.844430446624756
Validation loss: 2.569712519645691

Epoch: 6| Step: 4
Training loss: 2.0745370388031006
Validation loss: 2.5651334524154663

Epoch: 6| Step: 5
Training loss: 3.0767314434051514
Validation loss: 2.561647137006124

Epoch: 6| Step: 6
Training loss: 1.9333457946777344
Validation loss: 2.5586628119150796

Epoch: 6| Step: 7
Training loss: 2.7831506729125977
Validation loss: 2.5550238688786826

Epoch: 6| Step: 8
Training loss: 3.1200053691864014
Validation loss: 2.549787918726603

Epoch: 6| Step: 9
Training loss: 3.049950122833252
Validation loss: 2.5486052433649697

Epoch: 6| Step: 10
Training loss: 2.585817575454712
Validation loss: 2.546714186668396

Epoch: 6| Step: 11
Training loss: 3.117379665374756
Validation loss: 2.543064912160238

Epoch: 6| Step: 12
Training loss: 2.2228100299835205
Validation loss: 2.540399650732676

Epoch: 6| Step: 13
Training loss: 2.6744284629821777
Validation loss: 2.5379643042882285

Epoch: 43| Step: 0
Training loss: 2.3842086791992188
Validation loss: 2.534576932589213

Epoch: 6| Step: 1
Training loss: 3.0339772701263428
Validation loss: 2.5339279969533286

Epoch: 6| Step: 2
Training loss: 2.877305030822754
Validation loss: 2.533468743165334

Epoch: 6| Step: 3
Training loss: 3.494929313659668
Validation loss: 2.529012441635132

Epoch: 6| Step: 4
Training loss: 1.7039902210235596
Validation loss: 2.5244614680608115

Epoch: 6| Step: 5
Training loss: 2.9651598930358887
Validation loss: 2.5217538674672446

Epoch: 6| Step: 6
Training loss: 2.690218448638916
Validation loss: 2.520214835802714

Epoch: 6| Step: 7
Training loss: 2.0987095832824707
Validation loss: 2.518721063931783

Epoch: 6| Step: 8
Training loss: 2.321110486984253
Validation loss: 2.5139122009277344

Epoch: 6| Step: 9
Training loss: 2.833498477935791
Validation loss: 2.5121679306030273

Epoch: 6| Step: 10
Training loss: 2.4520959854125977
Validation loss: 2.509554624557495

Epoch: 6| Step: 11
Training loss: 2.9876742362976074
Validation loss: 2.507496198018392

Epoch: 6| Step: 12
Training loss: 3.0201308727264404
Validation loss: 2.5071598291397095

Epoch: 6| Step: 13
Training loss: 3.1799302101135254
Validation loss: 2.50220263004303

Epoch: 44| Step: 0
Training loss: 2.2895898818969727
Validation loss: 2.5018036365509033

Epoch: 6| Step: 1
Training loss: 2.927720308303833
Validation loss: 2.499647577603658

Epoch: 6| Step: 2
Training loss: 2.166806221008301
Validation loss: 2.4991524616877236

Epoch: 6| Step: 3
Training loss: 3.164590358734131
Validation loss: 2.4952515363693237

Epoch: 6| Step: 4
Training loss: 1.9167232513427734
Validation loss: 2.488078316052755

Epoch: 6| Step: 5
Training loss: 2.474385976791382
Validation loss: 2.4865058263142905

Epoch: 6| Step: 6
Training loss: 2.031877040863037
Validation loss: 2.4845532178878784

Epoch: 6| Step: 7
Training loss: 2.8532984256744385
Validation loss: 2.4851052363713584

Epoch: 6| Step: 8
Training loss: 3.0779168605804443
Validation loss: 2.4813774625460305

Epoch: 6| Step: 9
Training loss: 2.6449570655822754
Validation loss: 2.475141723950704

Epoch: 6| Step: 10
Training loss: 3.2821574211120605
Validation loss: 2.4748944441477456

Epoch: 6| Step: 11
Training loss: 2.615394115447998
Validation loss: 2.4742533365885415

Epoch: 6| Step: 12
Training loss: 3.290004253387451
Validation loss: 2.473129391670227

Epoch: 6| Step: 13
Training loss: 2.8317198753356934
Validation loss: 2.4718871116638184

Epoch: 45| Step: 0
Training loss: 3.1108484268188477
Validation loss: 2.4714814821879068

Epoch: 6| Step: 1
Training loss: 2.9826931953430176
Validation loss: 2.4683858354886374

Epoch: 6| Step: 2
Training loss: 3.085691213607788
Validation loss: 2.467385411262512

Epoch: 6| Step: 3
Training loss: 2.33001708984375
Validation loss: 2.4660609563191733

Epoch: 6| Step: 4
Training loss: 2.880129814147949
Validation loss: 2.464192887147268

Epoch: 6| Step: 5
Training loss: 1.8931232690811157
Validation loss: 2.4588928818702698

Epoch: 6| Step: 6
Training loss: 2.8162670135498047
Validation loss: 2.4538129568099976

Epoch: 6| Step: 7
Training loss: 2.8338918685913086
Validation loss: 2.4497915705045066

Epoch: 6| Step: 8
Training loss: 2.40633225440979
Validation loss: 2.4463791449864707

Epoch: 6| Step: 9
Training loss: 2.4636759757995605
Validation loss: 2.442459285259247

Epoch: 6| Step: 10
Training loss: 2.9365344047546387
Validation loss: 2.43624347448349

Epoch: 6| Step: 11
Training loss: 2.4950132369995117
Validation loss: 2.4405611952145896

Epoch: 6| Step: 12
Training loss: 2.634556293487549
Validation loss: 2.4448880155881247

Epoch: 6| Step: 13
Training loss: 2.198438882827759
Validation loss: 2.4531469345092773

Epoch: 46| Step: 0
Training loss: 2.5686302185058594
Validation loss: 2.4372678796450296

Epoch: 6| Step: 1
Training loss: 3.0659615993499756
Validation loss: 2.4269110759099326

Epoch: 6| Step: 2
Training loss: 2.2746119499206543
Validation loss: 2.4229522943496704

Epoch: 6| Step: 3
Training loss: 2.698713541030884
Validation loss: 2.422795613606771

Epoch: 6| Step: 4
Training loss: 2.091534376144409
Validation loss: 2.4242597421010337

Epoch: 6| Step: 5
Training loss: 2.004927158355713
Validation loss: 2.4264270663261414

Epoch: 6| Step: 6
Training loss: 2.5325069427490234
Validation loss: 2.4263583421707153

Epoch: 6| Step: 7
Training loss: 3.0456161499023438
Validation loss: 2.426314393679301

Epoch: 6| Step: 8
Training loss: 2.2256836891174316
Validation loss: 2.424422025680542

Epoch: 6| Step: 9
Training loss: 2.8042519092559814
Validation loss: 2.4311643838882446

Epoch: 6| Step: 10
Training loss: 2.696730136871338
Validation loss: 2.4294397234916687

Epoch: 6| Step: 11
Training loss: 2.7181456089019775
Validation loss: 2.424878239631653

Epoch: 6| Step: 12
Training loss: 3.270265579223633
Validation loss: 2.4077667395273843

Epoch: 6| Step: 13
Training loss: 2.5617237091064453
Validation loss: 2.3997371594111123

Epoch: 47| Step: 0
Training loss: 2.596792221069336
Validation loss: 2.397269129753113

Epoch: 6| Step: 1
Training loss: 2.8645894527435303
Validation loss: 2.393005927403768

Epoch: 6| Step: 2
Training loss: 2.211367607116699
Validation loss: 2.3919944763183594

Epoch: 6| Step: 3
Training loss: 1.841737985610962
Validation loss: 2.388176520665487

Epoch: 6| Step: 4
Training loss: 2.6203088760375977
Validation loss: 2.3857383131980896

Epoch: 6| Step: 5
Training loss: 3.044276237487793
Validation loss: 2.387061357498169

Epoch: 6| Step: 6
Training loss: 2.3270394802093506
Validation loss: 2.385384460290273

Epoch: 6| Step: 7
Training loss: 2.417865037918091
Validation loss: 2.3789541323979697

Epoch: 6| Step: 8
Training loss: 2.3012185096740723
Validation loss: 2.3814531564712524

Epoch: 6| Step: 9
Training loss: 3.0818095207214355
Validation loss: 2.378490765889486

Epoch: 6| Step: 10
Training loss: 3.028637409210205
Validation loss: 2.374628404776255

Epoch: 6| Step: 11
Training loss: 2.8805220127105713
Validation loss: 2.372231205304464

Epoch: 6| Step: 12
Training loss: 2.142953395843506
Validation loss: 2.366707762082418

Epoch: 6| Step: 13
Training loss: 2.516767978668213
Validation loss: 2.367331067721049

Epoch: 48| Step: 0
Training loss: 3.0738918781280518
Validation loss: 2.362771431605021

Epoch: 6| Step: 1
Training loss: 2.8867993354797363
Validation loss: 2.3621381521224976

Epoch: 6| Step: 2
Training loss: 1.5334683656692505
Validation loss: 2.3545095721880593

Epoch: 6| Step: 3
Training loss: 2.5239992141723633
Validation loss: 2.354027350743612

Epoch: 6| Step: 4
Training loss: 2.493227958679199
Validation loss: 2.3527401884396872

Epoch: 6| Step: 5
Training loss: 2.65425705909729
Validation loss: 2.3512001434961953

Epoch: 6| Step: 6
Training loss: 3.1677639484405518
Validation loss: 2.3481703201929727

Epoch: 6| Step: 7
Training loss: 2.783078908920288
Validation loss: 2.34529447555542

Epoch: 6| Step: 8
Training loss: 2.380514144897461
Validation loss: 2.3417475620905557

Epoch: 6| Step: 9
Training loss: 2.4887914657592773
Validation loss: 2.340776522954305

Epoch: 6| Step: 10
Training loss: 1.6463580131530762
Validation loss: 2.339699069658915

Epoch: 6| Step: 11
Training loss: 2.453711748123169
Validation loss: 2.337923049926758

Epoch: 6| Step: 12
Training loss: 2.760591983795166
Validation loss: 2.33452836672465

Epoch: 6| Step: 13
Training loss: 2.551605701446533
Validation loss: 2.331509987513224

Epoch: 49| Step: 0
Training loss: 3.3350608348846436
Validation loss: 2.3285438617070517

Epoch: 6| Step: 1
Training loss: 2.4408442974090576
Validation loss: 2.3310283025105796

Epoch: 6| Step: 2
Training loss: 2.5281636714935303
Validation loss: 2.3261119723320007

Epoch: 6| Step: 3
Training loss: 2.218050479888916
Validation loss: 2.32168177763621

Epoch: 6| Step: 4
Training loss: 2.6743550300598145
Validation loss: 2.319796840349833

Epoch: 6| Step: 5
Training loss: 2.6500587463378906
Validation loss: 2.3208123048146567

Epoch: 6| Step: 6
Training loss: 2.555732488632202
Validation loss: 2.3191162745157876

Epoch: 6| Step: 7
Training loss: 2.3110482692718506
Validation loss: 2.3143261671066284

Epoch: 6| Step: 8
Training loss: 2.266935110092163
Validation loss: 2.312611142794291

Epoch: 6| Step: 9
Training loss: 1.6761648654937744
Validation loss: 2.312253932158152

Epoch: 6| Step: 10
Training loss: 2.806663751602173
Validation loss: 2.305940349896749

Epoch: 6| Step: 11
Training loss: 2.1960198879241943
Validation loss: 2.3057719071706138

Epoch: 6| Step: 12
Training loss: 2.3737435340881348
Validation loss: 2.302950143814087

Epoch: 6| Step: 13
Training loss: 2.742523670196533
Validation loss: 2.3080679178237915

Epoch: 50| Step: 0
Training loss: 3.0076897144317627
Validation loss: 2.299692233403524

Epoch: 6| Step: 1
Training loss: 2.5009188652038574
Validation loss: 2.2997719049453735

Epoch: 6| Step: 2
Training loss: 2.5324535369873047
Validation loss: 2.29251758257548

Epoch: 6| Step: 3
Training loss: 2.0755252838134766
Validation loss: 2.2903826236724854

Epoch: 6| Step: 4
Training loss: 2.591796398162842
Validation loss: 2.2938163677851358

Epoch: 6| Step: 5
Training loss: 2.9788870811462402
Validation loss: 2.295918822288513

Epoch: 6| Step: 6
Training loss: 2.219639301300049
Validation loss: 2.30477237701416

Epoch: 6| Step: 7
Training loss: 2.7130391597747803
Validation loss: 2.3024734258651733

Epoch: 6| Step: 8
Training loss: 1.9460835456848145
Validation loss: 2.2986236015955606

Epoch: 6| Step: 9
Training loss: 1.994999647140503
Validation loss: 2.2913887103398642

Epoch: 6| Step: 10
Training loss: 1.7986339330673218
Validation loss: 2.2839596470197043

Epoch: 6| Step: 11
Training loss: 2.6570727825164795
Validation loss: 2.2812766234079995

Epoch: 6| Step: 12
Training loss: 3.083872079849243
Validation loss: 2.2774956425031028

Epoch: 6| Step: 13
Training loss: 2.5366923809051514
Validation loss: 2.27254056930542

Epoch: 51| Step: 0
Training loss: 2.954094409942627
Validation loss: 2.2680946588516235

Epoch: 6| Step: 1
Training loss: 2.3227734565734863
Validation loss: 2.2669745286305747

Epoch: 6| Step: 2
Training loss: 1.9735407829284668
Validation loss: 2.2656187613805137

Epoch: 6| Step: 3
Training loss: 2.343050003051758
Validation loss: 2.27476171652476

Epoch: 6| Step: 4
Training loss: 3.09602952003479
Validation loss: 2.298876484235128

Epoch: 6| Step: 5
Training loss: 2.1579880714416504
Validation loss: 2.313737710316976

Epoch: 6| Step: 6
Training loss: 2.199793577194214
Validation loss: 2.279930373032888

Epoch: 6| Step: 7
Training loss: 2.321544647216797
Validation loss: 2.270573874314626

Epoch: 6| Step: 8
Training loss: 2.2441558837890625
Validation loss: 2.2761894861857095

Epoch: 6| Step: 9
Training loss: 2.6373748779296875
Validation loss: 2.262469013532003

Epoch: 6| Step: 10
Training loss: 2.2587101459503174
Validation loss: 2.257618029912313

Epoch: 6| Step: 11
Training loss: 2.361330270767212
Validation loss: 2.2568412820498147

Epoch: 6| Step: 12
Training loss: 2.8301241397857666
Validation loss: 2.256997505823771

Epoch: 6| Step: 13
Training loss: 2.3864188194274902
Validation loss: 2.2573644121487937

Epoch: 52| Step: 0
Training loss: 2.3797988891601562
Validation loss: 2.2635165055592856

Epoch: 6| Step: 1
Training loss: 2.401170253753662
Validation loss: 2.2669565876324973

Epoch: 6| Step: 2
Training loss: 2.805441379547119
Validation loss: 2.2692488630612693

Epoch: 6| Step: 3
Training loss: 2.2512919902801514
Validation loss: 2.279766877492269

Epoch: 6| Step: 4
Training loss: 2.7744827270507812
Validation loss: 2.2867359717686973

Epoch: 6| Step: 5
Training loss: 2.4919071197509766
Validation loss: 2.2893837491671243

Epoch: 6| Step: 6
Training loss: 2.6931729316711426
Validation loss: 2.2733914653460183

Epoch: 6| Step: 7
Training loss: 1.5733091831207275
Validation loss: 2.2600000301996865

Epoch: 6| Step: 8
Training loss: 2.891364574432373
Validation loss: 2.253332734107971

Epoch: 6| Step: 9
Training loss: 2.3306198120117188
Validation loss: 2.247407078742981

Epoch: 6| Step: 10
Training loss: 1.9724953174591064
Validation loss: 2.2426234086354575

Epoch: 6| Step: 11
Training loss: 2.3025355339050293
Validation loss: 2.2355435689290366

Epoch: 6| Step: 12
Training loss: 2.922872543334961
Validation loss: 2.231886108716329

Epoch: 6| Step: 13
Training loss: 2.0371251106262207
Validation loss: 2.227979381879171

Epoch: 53| Step: 0
Training loss: 2.5238378047943115
Validation loss: 2.2233079274495444

Epoch: 6| Step: 1
Training loss: 3.0083932876586914
Validation loss: 2.2220542430877686

Epoch: 6| Step: 2
Training loss: 2.586064338684082
Validation loss: 2.218920906384786

Epoch: 6| Step: 3
Training loss: 2.4188385009765625
Validation loss: 2.2161275347073874

Epoch: 6| Step: 4
Training loss: 2.403627395629883
Validation loss: 2.215874433517456

Epoch: 6| Step: 5
Training loss: 2.387503147125244
Validation loss: 2.2163371245066323

Epoch: 6| Step: 6
Training loss: 1.93330717086792
Validation loss: 2.220985253651937

Epoch: 6| Step: 7
Training loss: 1.4409841299057007
Validation loss: 2.228654980659485

Epoch: 6| Step: 8
Training loss: 3.285968065261841
Validation loss: 2.225414454936981

Epoch: 6| Step: 9
Training loss: 2.0250868797302246
Validation loss: 2.21552840868632

Epoch: 6| Step: 10
Training loss: 2.760690689086914
Validation loss: 2.2037604053815207

Epoch: 6| Step: 11
Training loss: 2.1113088130950928
Validation loss: 2.20211931069692

Epoch: 6| Step: 12
Training loss: 2.1726062297821045
Validation loss: 2.1996132930119834

Epoch: 6| Step: 13
Training loss: 2.1775765419006348
Validation loss: 2.1966403126716614

Epoch: 54| Step: 0
Training loss: 2.0880942344665527
Validation loss: 2.1974690357844033

Epoch: 6| Step: 1
Training loss: 2.5237605571746826
Validation loss: 2.1964682936668396

Epoch: 6| Step: 2
Training loss: 2.4841103553771973
Validation loss: 2.197283923625946

Epoch: 6| Step: 3
Training loss: 2.0734810829162598
Validation loss: 2.19202729066213

Epoch: 6| Step: 4
Training loss: 2.634925127029419
Validation loss: 2.192265431086222

Epoch: 6| Step: 5
Training loss: 2.0848419666290283
Validation loss: 2.1907512744267783

Epoch: 6| Step: 6
Training loss: 2.2823596000671387
Validation loss: 2.1883705854415894

Epoch: 6| Step: 7
Training loss: 1.9479618072509766
Validation loss: 2.186173697312673

Epoch: 6| Step: 8
Training loss: 2.676886558532715
Validation loss: 2.1860509713490806

Epoch: 6| Step: 9
Training loss: 2.5398778915405273
Validation loss: 2.1828951636950173

Epoch: 6| Step: 10
Training loss: 2.7227237224578857
Validation loss: 2.177717169125875

Epoch: 6| Step: 11
Training loss: 1.7376720905303955
Validation loss: 2.1797467470169067

Epoch: 6| Step: 12
Training loss: 2.1965394020080566
Validation loss: 2.177608013153076

Epoch: 6| Step: 13
Training loss: 2.8696370124816895
Validation loss: 2.1743470827738443

Epoch: 55| Step: 0
Training loss: 1.9913487434387207
Validation loss: 2.1745635072390237

Epoch: 6| Step: 1
Training loss: 1.9046411514282227
Validation loss: 2.1702247063318887

Epoch: 6| Step: 2
Training loss: 1.9808626174926758
Validation loss: 2.1657413442929587

Epoch: 6| Step: 3
Training loss: 2.0177133083343506
Validation loss: 2.1666935682296753

Epoch: 6| Step: 4
Training loss: 2.39323091506958
Validation loss: 2.1743311484654746

Epoch: 6| Step: 5
Training loss: 1.8625155687332153
Validation loss: 2.170817951361338

Epoch: 6| Step: 6
Training loss: 2.5081753730773926
Validation loss: 2.16473380724589

Epoch: 6| Step: 7
Training loss: 1.8680026531219482
Validation loss: 2.158891280492147

Epoch: 6| Step: 8
Training loss: 2.6804652214050293
Validation loss: 2.16416605313619

Epoch: 6| Step: 9
Training loss: 2.839254379272461
Validation loss: 2.1644901831944785

Epoch: 6| Step: 10
Training loss: 2.8206281661987305
Validation loss: 2.161483625570933

Epoch: 6| Step: 11
Training loss: 2.591609477996826
Validation loss: 2.1590143044789634

Epoch: 6| Step: 12
Training loss: 2.9102487564086914
Validation loss: 2.158328056335449

Epoch: 6| Step: 13
Training loss: 2.1571924686431885
Validation loss: 2.1584499875704446

Epoch: 56| Step: 0
Training loss: 1.939921498298645
Validation loss: 2.1595510641733804

Epoch: 6| Step: 1
Training loss: 2.3141791820526123
Validation loss: 2.1541877388954163

Epoch: 6| Step: 2
Training loss: 2.4080286026000977
Validation loss: 2.150820871194204

Epoch: 6| Step: 3
Training loss: 1.9996708631515503
Validation loss: 2.1499449213345847

Epoch: 6| Step: 4
Training loss: 2.6423449516296387
Validation loss: 2.1506188114484153

Epoch: 6| Step: 5
Training loss: 2.2850396633148193
Validation loss: 2.1514225006103516

Epoch: 6| Step: 6
Training loss: 2.1259474754333496
Validation loss: 2.1513639092445374

Epoch: 6| Step: 7
Training loss: 1.8425756692886353
Validation loss: 2.142866869767507

Epoch: 6| Step: 8
Training loss: 2.700683116912842
Validation loss: 2.1395004789034524

Epoch: 6| Step: 9
Training loss: 3.641524314880371
Validation loss: 2.1434634725252786

Epoch: 6| Step: 10
Training loss: 1.6026922464370728
Validation loss: 2.1390190521876016

Epoch: 6| Step: 11
Training loss: 2.23185396194458
Validation loss: 2.1365913550059

Epoch: 6| Step: 12
Training loss: 2.0844671726226807
Validation loss: 2.132116655508677

Epoch: 6| Step: 13
Training loss: 2.5683460235595703
Validation loss: 2.135420878728231

Epoch: 57| Step: 0
Training loss: 2.8916234970092773
Validation loss: 2.1313669681549072

Epoch: 6| Step: 1
Training loss: 2.931299924850464
Validation loss: 2.1286567846934

Epoch: 6| Step: 2
Training loss: 1.5951511859893799
Validation loss: 2.129209736982981

Epoch: 6| Step: 3
Training loss: 2.681769371032715
Validation loss: 2.134471873442332

Epoch: 6| Step: 4
Training loss: 2.5913026332855225
Validation loss: 2.1373603145281472

Epoch: 6| Step: 5
Training loss: 2.2230114936828613
Validation loss: 2.1327048341433206

Epoch: 6| Step: 6
Training loss: 2.010201930999756
Validation loss: 2.130068600177765

Epoch: 6| Step: 7
Training loss: 1.9206910133361816
Validation loss: 2.1315635442733765

Epoch: 6| Step: 8
Training loss: 2.8712804317474365
Validation loss: 2.127306322256724

Epoch: 6| Step: 9
Training loss: 2.2653794288635254
Validation loss: 2.125769337018331

Epoch: 6| Step: 10
Training loss: 2.005824565887451
Validation loss: 2.1272836724917092

Epoch: 6| Step: 11
Training loss: 2.1889891624450684
Validation loss: 2.1221910516421

Epoch: 6| Step: 12
Training loss: 1.9658632278442383
Validation loss: 2.120298445224762

Epoch: 6| Step: 13
Training loss: 1.990973949432373
Validation loss: 2.1112950245539346

Epoch: 58| Step: 0
Training loss: 2.719160795211792
Validation loss: 2.1208602587381997

Epoch: 6| Step: 1
Training loss: 2.256957530975342
Validation loss: 2.1203830440839133

Epoch: 6| Step: 2
Training loss: 2.504061698913574
Validation loss: 2.1144782304763794

Epoch: 6| Step: 3
Training loss: 2.2070319652557373
Validation loss: 2.128435810407003

Epoch: 6| Step: 4
Training loss: 2.7992005348205566
Validation loss: 2.13441934188207

Epoch: 6| Step: 5
Training loss: 2.0267720222473145
Validation loss: 2.1536832451820374

Epoch: 6| Step: 6
Training loss: 2.5673680305480957
Validation loss: 2.1851225097974143

Epoch: 6| Step: 7
Training loss: 1.5342636108398438
Validation loss: 2.180062691370646

Epoch: 6| Step: 8
Training loss: 2.867103099822998
Validation loss: 2.1357266108194985

Epoch: 6| Step: 9
Training loss: 2.100019931793213
Validation loss: 2.107709606488546

Epoch: 6| Step: 10
Training loss: 1.8703447580337524
Validation loss: 2.108685831228892

Epoch: 6| Step: 11
Training loss: 2.331178665161133
Validation loss: 2.118153770764669

Epoch: 6| Step: 12
Training loss: 1.7667794227600098
Validation loss: 2.122428774833679

Epoch: 6| Step: 13
Training loss: 2.372432231903076
Validation loss: 2.125249743461609

Epoch: 59| Step: 0
Training loss: 2.470433235168457
Validation loss: 2.138733128706614

Epoch: 6| Step: 1
Training loss: 2.8118906021118164
Validation loss: 2.14630655447642

Epoch: 6| Step: 2
Training loss: 2.472682476043701
Validation loss: 2.156548857688904

Epoch: 6| Step: 3
Training loss: 2.513415813446045
Validation loss: 2.1690480510393777

Epoch: 6| Step: 4
Training loss: 2.1394379138946533
Validation loss: 2.165464202562968

Epoch: 6| Step: 5
Training loss: 2.106755018234253
Validation loss: 2.1640779177347818

Epoch: 6| Step: 6
Training loss: 2.1125712394714355
Validation loss: 2.159979462623596

Epoch: 6| Step: 7
Training loss: 1.6568074226379395
Validation loss: 2.1491530736287436

Epoch: 6| Step: 8
Training loss: 2.2140302658081055
Validation loss: 2.1399860779444375

Epoch: 6| Step: 9
Training loss: 2.281703233718872
Validation loss: 2.1388352711995444

Epoch: 6| Step: 10
Training loss: 2.588865041732788
Validation loss: 2.1282981435457864

Epoch: 6| Step: 11
Training loss: 1.7684246301651
Validation loss: 2.1220698157946267

Epoch: 6| Step: 12
Training loss: 2.6649608612060547
Validation loss: 2.1188997427622476

Epoch: 6| Step: 13
Training loss: 2.649054765701294
Validation loss: 2.1208136677742004

Epoch: 60| Step: 0
Training loss: 2.016327142715454
Validation loss: 2.114308933417002

Epoch: 6| Step: 1
Training loss: 2.5097835063934326
Validation loss: 2.113734543323517

Epoch: 6| Step: 2
Training loss: 1.9081169366836548
Validation loss: 2.1118656595547995

Epoch: 6| Step: 3
Training loss: 1.820560336112976
Validation loss: 2.109960357348124

Epoch: 6| Step: 4
Training loss: 2.284802198410034
Validation loss: 2.110951562722524

Epoch: 6| Step: 5
Training loss: 2.1567418575286865
Validation loss: 2.1051193873087564

Epoch: 6| Step: 6
Training loss: 2.316171646118164
Validation loss: 2.1033764680226645

Epoch: 6| Step: 7
Training loss: 2.3311595916748047
Validation loss: 2.099325954914093

Epoch: 6| Step: 8
Training loss: 2.338088035583496
Validation loss: 2.0965509613355002

Epoch: 6| Step: 9
Training loss: 2.4914515018463135
Validation loss: 2.09265128771464

Epoch: 6| Step: 10
Training loss: 2.1495118141174316
Validation loss: 2.0887144804000854

Epoch: 6| Step: 11
Training loss: 2.516653537750244
Validation loss: 2.083456496397654

Epoch: 6| Step: 12
Training loss: 2.4642505645751953
Validation loss: 2.080570697784424

Epoch: 6| Step: 13
Training loss: 2.4570908546447754
Validation loss: 2.075732946395874

Epoch: 61| Step: 0
Training loss: 1.9288305044174194
Validation loss: 2.0775102774302163

Epoch: 6| Step: 1
Training loss: 2.497047185897827
Validation loss: 2.0892632007598877

Epoch: 6| Step: 2
Training loss: 2.6133222579956055
Validation loss: 2.1019328435262046

Epoch: 6| Step: 3
Training loss: 2.4875435829162598
Validation loss: 2.125625789165497

Epoch: 6| Step: 4
Training loss: 1.958343744277954
Validation loss: 2.1339357097943625

Epoch: 6| Step: 5
Training loss: 2.356226921081543
Validation loss: 2.139568348725637

Epoch: 6| Step: 6
Training loss: 2.1934447288513184
Validation loss: 2.109297255674998

Epoch: 6| Step: 7
Training loss: 2.404822826385498
Validation loss: 2.092017889022827

Epoch: 6| Step: 8
Training loss: 1.6044583320617676
Validation loss: 2.074599107106527

Epoch: 6| Step: 9
Training loss: 2.2854127883911133
Validation loss: 2.0676130056381226

Epoch: 6| Step: 10
Training loss: 2.6243228912353516
Validation loss: 2.0775486628214517

Epoch: 6| Step: 11
Training loss: 2.218722343444824
Validation loss: 2.079222639401754

Epoch: 6| Step: 12
Training loss: 2.1165096759796143
Validation loss: 2.083913266658783

Epoch: 6| Step: 13
Training loss: 2.442701816558838
Validation loss: 2.083733379840851

Epoch: 62| Step: 0
Training loss: 2.949273109436035
Validation loss: 2.0870403250058494

Epoch: 6| Step: 1
Training loss: 2.7398836612701416
Validation loss: 2.086429933706919

Epoch: 6| Step: 2
Training loss: 2.4628093242645264
Validation loss: 2.084885835647583

Epoch: 6| Step: 3
Training loss: 1.751854658126831
Validation loss: 2.0855874021848044

Epoch: 6| Step: 4
Training loss: 2.052032947540283
Validation loss: 2.084017793337504

Epoch: 6| Step: 5
Training loss: 2.396395206451416
Validation loss: 2.080262303352356

Epoch: 6| Step: 6
Training loss: 2.266836166381836
Validation loss: 2.0744085113207498

Epoch: 6| Step: 7
Training loss: 2.1042981147766113
Validation loss: 2.0782277385393777

Epoch: 6| Step: 8
Training loss: 2.329801559448242
Validation loss: 2.0709084272384644

Epoch: 6| Step: 9
Training loss: 2.326620101928711
Validation loss: 2.067543307940165

Epoch: 6| Step: 10
Training loss: 2.0467822551727295
Validation loss: 2.0706546902656555

Epoch: 6| Step: 11
Training loss: 1.5950229167938232
Validation loss: 2.066754380861918

Epoch: 6| Step: 12
Training loss: 2.1807641983032227
Validation loss: 2.0557551781336465

Epoch: 6| Step: 13
Training loss: 2.453994035720825
Validation loss: 2.0568777521451316

Epoch: 63| Step: 0
Training loss: 2.0831689834594727
Validation loss: 2.054366866747538

Epoch: 6| Step: 1
Training loss: 1.831171989440918
Validation loss: 2.0517955223719277

Epoch: 6| Step: 2
Training loss: 2.1235055923461914
Validation loss: 2.0599451859792075

Epoch: 6| Step: 3
Training loss: 1.8788249492645264
Validation loss: 2.0712193648020425

Epoch: 6| Step: 4
Training loss: 2.3024051189422607
Validation loss: 2.0814462701479592

Epoch: 6| Step: 5
Training loss: 2.2723286151885986
Validation loss: 2.0807208816210427

Epoch: 6| Step: 6
Training loss: 2.288346767425537
Validation loss: 2.0825819969177246

Epoch: 6| Step: 7
Training loss: 2.588186025619507
Validation loss: 2.071013788382212

Epoch: 6| Step: 8
Training loss: 2.5185294151306152
Validation loss: 2.0698267221450806

Epoch: 6| Step: 9
Training loss: 2.074613094329834
Validation loss: 2.047071178754171

Epoch: 6| Step: 10
Training loss: 2.370129108428955
Validation loss: 2.0513267517089844

Epoch: 6| Step: 11
Training loss: 1.92850661277771
Validation loss: 2.054282546043396

Epoch: 6| Step: 12
Training loss: 2.250432014465332
Validation loss: 2.052424649397532

Epoch: 6| Step: 13
Training loss: 2.548646926879883
Validation loss: 2.054315229256948

Epoch: 64| Step: 0
Training loss: 2.1767940521240234
Validation loss: 2.0566803018252053

Epoch: 6| Step: 1
Training loss: 2.4179203510284424
Validation loss: 2.0593170324961343

Epoch: 6| Step: 2
Training loss: 1.9682204723358154
Validation loss: 2.066536784172058

Epoch: 6| Step: 3
Training loss: 2.4925899505615234
Validation loss: 2.0628154476483664

Epoch: 6| Step: 4
Training loss: 2.225839376449585
Validation loss: 2.0656309127807617

Epoch: 6| Step: 5
Training loss: 2.4071693420410156
Validation loss: 2.0674806237220764

Epoch: 6| Step: 6
Training loss: 1.9957661628723145
Validation loss: 2.0633761485417685

Epoch: 6| Step: 7
Training loss: 1.8005702495574951
Validation loss: 2.0704795320828757

Epoch: 6| Step: 8
Training loss: 2.2420759201049805
Validation loss: 2.0633892019589744

Epoch: 6| Step: 9
Training loss: 2.3267288208007812
Validation loss: 2.0654016733169556

Epoch: 6| Step: 10
Training loss: 2.3272666931152344
Validation loss: 2.065787653128306

Epoch: 6| Step: 11
Training loss: 2.8058762550354004
Validation loss: 2.0600695411364236

Epoch: 6| Step: 12
Training loss: 2.304393768310547
Validation loss: 2.0620397130648294

Epoch: 6| Step: 13
Training loss: 2.1192290782928467
Validation loss: 2.059479812781016

Epoch: 65| Step: 0
Training loss: 2.0045080184936523
Validation loss: 2.060416877269745

Epoch: 6| Step: 1
Training loss: 2.518037796020508
Validation loss: 2.0521193941434226

Epoch: 6| Step: 2
Training loss: 2.591798782348633
Validation loss: 2.047649304072062

Epoch: 6| Step: 3
Training loss: 1.520162582397461
Validation loss: 2.0422911643981934

Epoch: 6| Step: 4
Training loss: 2.2689759731292725
Validation loss: 2.0411200523376465

Epoch: 6| Step: 5
Training loss: 3.3048057556152344
Validation loss: 2.0466694037119546

Epoch: 6| Step: 6
Training loss: 2.172534227371216
Validation loss: 2.047892411549886

Epoch: 6| Step: 7
Training loss: 1.861729621887207
Validation loss: 2.043939471244812

Epoch: 6| Step: 8
Training loss: 1.9785337448120117
Validation loss: 2.050192356109619

Epoch: 6| Step: 9
Training loss: 2.0874180793762207
Validation loss: 2.0691330432891846

Epoch: 6| Step: 10
Training loss: 1.5533409118652344
Validation loss: 2.0663852294286094

Epoch: 6| Step: 11
Training loss: 2.1418113708496094
Validation loss: 2.0578559041023254

Epoch: 6| Step: 12
Training loss: 2.5311665534973145
Validation loss: 2.0604254007339478

Epoch: 6| Step: 13
Training loss: 2.4454283714294434
Validation loss: 2.0540589888890586

Epoch: 66| Step: 0
Training loss: 2.939258575439453
Validation loss: 2.052112360795339

Epoch: 6| Step: 1
Training loss: 1.774778127670288
Validation loss: 2.0466451247533164

Epoch: 6| Step: 2
Training loss: 2.525635004043579
Validation loss: 2.033216873804728

Epoch: 6| Step: 3
Training loss: 2.395461082458496
Validation loss: 2.033945918083191

Epoch: 6| Step: 4
Training loss: 3.1199114322662354
Validation loss: 2.036602278550466

Epoch: 6| Step: 5
Training loss: 1.9304721355438232
Validation loss: 2.037350038687388

Epoch: 6| Step: 6
Training loss: 1.666457176208496
Validation loss: 2.031312108039856

Epoch: 6| Step: 7
Training loss: 1.992051601409912
Validation loss: 2.042344073454539

Epoch: 6| Step: 8
Training loss: 1.5184433460235596
Validation loss: 2.0390183528264365

Epoch: 6| Step: 9
Training loss: 2.7842040061950684
Validation loss: 2.035844544569651

Epoch: 6| Step: 10
Training loss: 2.0698232650756836
Validation loss: 2.0363998810450235

Epoch: 6| Step: 11
Training loss: 1.8341870307922363
Validation loss: 2.0360642472902932

Epoch: 6| Step: 12
Training loss: 2.393692970275879
Validation loss: 2.042288621266683

Epoch: 6| Step: 13
Training loss: 1.8781174421310425
Validation loss: 2.027086098988851

Epoch: 67| Step: 0
Training loss: 1.2914848327636719
Validation loss: 2.0305680632591248

Epoch: 6| Step: 1
Training loss: 1.8107601404190063
Validation loss: 2.0377496679623923

Epoch: 6| Step: 2
Training loss: 2.1578876972198486
Validation loss: 2.0303478042284646

Epoch: 6| Step: 3
Training loss: 2.1736443042755127
Validation loss: 2.037683626015981

Epoch: 6| Step: 4
Training loss: 2.715649366378784
Validation loss: 2.038454751173655

Epoch: 6| Step: 5
Training loss: 2.4918203353881836
Validation loss: 2.03874009847641

Epoch: 6| Step: 6
Training loss: 1.5542047023773193
Validation loss: 2.0330472787221274

Epoch: 6| Step: 7
Training loss: 2.511749029159546
Validation loss: 2.0331780314445496

Epoch: 6| Step: 8
Training loss: 1.9381873607635498
Validation loss: 2.0369813442230225

Epoch: 6| Step: 9
Training loss: 2.6810264587402344
Validation loss: 2.032313128312429

Epoch: 6| Step: 10
Training loss: 1.913705825805664
Validation loss: 2.043112496534983

Epoch: 6| Step: 11
Training loss: 2.5731077194213867
Validation loss: 2.0559397538503013

Epoch: 6| Step: 12
Training loss: 2.6896815299987793
Validation loss: 2.0484717885653176

Epoch: 6| Step: 13
Training loss: 2.4235305786132812
Validation loss: 2.051722844441732

Epoch: 68| Step: 0
Training loss: 2.158414840698242
Validation loss: 2.0328646302223206

Epoch: 6| Step: 1
Training loss: 2.4641618728637695
Validation loss: 2.036960462729136

Epoch: 6| Step: 2
Training loss: 2.4916632175445557
Validation loss: 2.02638179063797

Epoch: 6| Step: 3
Training loss: 2.4659628868103027
Validation loss: 2.027315616607666

Epoch: 6| Step: 4
Training loss: 2.5620548725128174
Validation loss: 2.0448020696640015

Epoch: 6| Step: 5
Training loss: 2.0654563903808594
Validation loss: 2.0424573024113974

Epoch: 6| Step: 6
Training loss: 2.195559024810791
Validation loss: 2.0471577843030295

Epoch: 6| Step: 7
Training loss: 2.5884809494018555
Validation loss: 2.050540347894033

Epoch: 6| Step: 8
Training loss: 1.9544668197631836
Validation loss: 2.047166188557943

Epoch: 6| Step: 9
Training loss: 2.611147165298462
Validation loss: 2.041145702203115

Epoch: 6| Step: 10
Training loss: 1.7295057773590088
Validation loss: 2.044168452421824

Epoch: 6| Step: 11
Training loss: 1.70292329788208
Validation loss: 2.0370594461758933

Epoch: 6| Step: 12
Training loss: 1.5168520212173462
Validation loss: 2.0354711612065635

Epoch: 6| Step: 13
Training loss: 2.6980831623077393
Validation loss: 2.034739077091217

Epoch: 69| Step: 0
Training loss: 2.3209660053253174
Validation loss: 2.0275624791781106

Epoch: 6| Step: 1
Training loss: 1.8461740016937256
Validation loss: 2.017202357451121

Epoch: 6| Step: 2
Training loss: 2.0322747230529785
Validation loss: 2.032251556714376

Epoch: 6| Step: 3
Training loss: 1.7102899551391602
Validation loss: 2.0533230900764465

Epoch: 6| Step: 4
Training loss: 2.8851230144500732
Validation loss: 2.0624775091807046

Epoch: 6| Step: 5
Training loss: 1.6816811561584473
Validation loss: 2.0684755643208823

Epoch: 6| Step: 6
Training loss: 2.7305333614349365
Validation loss: 2.0513802766799927

Epoch: 6| Step: 7
Training loss: 2.6077847480773926
Validation loss: 2.0334550738334656

Epoch: 6| Step: 8
Training loss: 2.0406084060668945
Validation loss: 2.0281008084615073

Epoch: 6| Step: 9
Training loss: 2.174748182296753
Validation loss: 2.0288206537564597

Epoch: 6| Step: 10
Training loss: 2.2806012630462646
Validation loss: 2.0417628089586892

Epoch: 6| Step: 11
Training loss: 2.0371365547180176
Validation loss: 2.047185798486074

Epoch: 6| Step: 12
Training loss: 2.5698742866516113
Validation loss: 2.0454369386037192

Epoch: 6| Step: 13
Training loss: 2.4635977745056152
Validation loss: 2.0532197753588357

Epoch: 70| Step: 0
Training loss: 2.1537857055664062
Validation loss: 2.0520921548207602

Epoch: 6| Step: 1
Training loss: 2.6325249671936035
Validation loss: 2.0618794759114585

Epoch: 6| Step: 2
Training loss: 2.8096578121185303
Validation loss: 2.0705536603927612

Epoch: 6| Step: 3
Training loss: 2.4269821643829346
Validation loss: 2.0714191595713296

Epoch: 6| Step: 4
Training loss: 2.592829704284668
Validation loss: 2.080465038617452

Epoch: 6| Step: 5
Training loss: 2.2058186531066895
Validation loss: 2.074847380320231

Epoch: 6| Step: 6
Training loss: 2.4941515922546387
Validation loss: 2.073411782582601

Epoch: 6| Step: 7
Training loss: 2.366185426712036
Validation loss: 2.067193329334259

Epoch: 6| Step: 8
Training loss: 1.5685334205627441
Validation loss: 2.052435517311096

Epoch: 6| Step: 9
Training loss: 2.2954068183898926
Validation loss: 2.0509615540504456

Epoch: 6| Step: 10
Training loss: 2.451880693435669
Validation loss: 2.047985076904297

Epoch: 6| Step: 11
Training loss: 1.8533647060394287
Validation loss: 2.044964551925659

Epoch: 6| Step: 12
Training loss: 1.9355077743530273
Validation loss: 2.044406314690908

Epoch: 6| Step: 13
Training loss: 1.7931647300720215
Validation loss: 2.039275646209717

Epoch: 71| Step: 0
Training loss: 1.9668076038360596
Validation loss: 2.044041931629181

Epoch: 6| Step: 1
Training loss: 2.359157085418701
Validation loss: 2.037636081377665

Epoch: 6| Step: 2
Training loss: 2.5267086029052734
Validation loss: 2.0294567147890725

Epoch: 6| Step: 3
Training loss: 1.7972726821899414
Validation loss: 2.0270530780156455

Epoch: 6| Step: 4
Training loss: 1.852975606918335
Validation loss: 2.024441361427307

Epoch: 6| Step: 5
Training loss: 1.7993927001953125
Validation loss: 2.0290485421816506

Epoch: 6| Step: 6
Training loss: 2.2725844383239746
Validation loss: 2.052654286225637

Epoch: 6| Step: 7
Training loss: 2.1849377155303955
Validation loss: 2.0741971135139465

Epoch: 6| Step: 8
Training loss: 2.849883556365967
Validation loss: 2.087615708510081

Epoch: 6| Step: 9
Training loss: 1.9730148315429688
Validation loss: 2.093993087609609

Epoch: 6| Step: 10
Training loss: 1.7991929054260254
Validation loss: 2.0889912645022073

Epoch: 6| Step: 11
Training loss: 2.4707260131835938
Validation loss: 2.097619334856669

Epoch: 6| Step: 12
Training loss: 2.4913742542266846
Validation loss: 2.105484882990519

Epoch: 6| Step: 13
Training loss: 2.9681503772735596
Validation loss: 2.078749497731527

Epoch: 72| Step: 0
Training loss: 2.224468946456909
Validation loss: 2.0563488205273948

Epoch: 6| Step: 1
Training loss: 2.8025965690612793
Validation loss: 2.0447083115577698

Epoch: 6| Step: 2
Training loss: 2.2755703926086426
Validation loss: 2.0250274340311685

Epoch: 6| Step: 3
Training loss: 2.487945079803467
Validation loss: 2.024077892303467

Epoch: 6| Step: 4
Training loss: 2.2873058319091797
Validation loss: 2.0225387612978616

Epoch: 6| Step: 5
Training loss: 1.9926321506500244
Validation loss: 2.024500052134196

Epoch: 6| Step: 6
Training loss: 1.8073883056640625
Validation loss: 2.026477893193563

Epoch: 6| Step: 7
Training loss: 2.7043368816375732
Validation loss: 2.026011645793915

Epoch: 6| Step: 8
Training loss: 2.1644914150238037
Validation loss: 2.026296317577362

Epoch: 6| Step: 9
Training loss: 2.2887344360351562
Validation loss: 2.0347410837809243

Epoch: 6| Step: 10
Training loss: 2.1908183097839355
Validation loss: 2.0374085307121277

Epoch: 6| Step: 11
Training loss: 1.9330614805221558
Validation loss: 2.0330147544542947

Epoch: 6| Step: 12
Training loss: 1.588904619216919
Validation loss: 2.028364678223928

Epoch: 6| Step: 13
Training loss: 1.7049567699432373
Validation loss: 2.032476544380188

Epoch: 73| Step: 0
Training loss: 1.3002455234527588
Validation loss: 2.0368661085764566

Epoch: 6| Step: 1
Training loss: 1.792701005935669
Validation loss: 2.0324296951293945

Epoch: 6| Step: 2
Training loss: 2.080430746078491
Validation loss: 2.0362782080968223

Epoch: 6| Step: 3
Training loss: 2.0531630516052246
Validation loss: 2.0266406337420144

Epoch: 6| Step: 4
Training loss: 2.246792793273926
Validation loss: 2.0241514841715493

Epoch: 6| Step: 5
Training loss: 2.0933837890625
Validation loss: 2.021887242794037

Epoch: 6| Step: 6
Training loss: 2.9463672637939453
Validation loss: 2.0213403900464377

Epoch: 6| Step: 7
Training loss: 2.062002658843994
Validation loss: 2.0324419935544333

Epoch: 6| Step: 8
Training loss: 3.013810634613037
Validation loss: 2.031008243560791

Epoch: 6| Step: 9
Training loss: 2.3668973445892334
Validation loss: 2.026673158009847

Epoch: 6| Step: 10
Training loss: 1.7833808660507202
Validation loss: 2.044591546058655

Epoch: 6| Step: 11
Training loss: 2.3240718841552734
Validation loss: 2.04286789894104

Epoch: 6| Step: 12
Training loss: 2.291059970855713
Validation loss: 2.042857050895691

Epoch: 6| Step: 13
Training loss: 2.3075642585754395
Validation loss: 2.0344822804133096

Epoch: 74| Step: 0
Training loss: 2.1915860176086426
Validation loss: 2.0493163069089255

Epoch: 6| Step: 1
Training loss: 2.2561588287353516
Validation loss: 2.046607712904612

Epoch: 6| Step: 2
Training loss: 2.1062257289886475
Validation loss: 2.0565532644589744

Epoch: 6| Step: 3
Training loss: 2.3969693183898926
Validation loss: 2.0489362875620523

Epoch: 6| Step: 4
Training loss: 2.2602837085723877
Validation loss: 2.046667496363322

Epoch: 6| Step: 5
Training loss: 2.452329397201538
Validation loss: 2.031435549259186

Epoch: 6| Step: 6
Training loss: 2.1400656700134277
Validation loss: 2.0256927013397217

Epoch: 6| Step: 7
Training loss: 1.6822214126586914
Validation loss: 2.024707833925883

Epoch: 6| Step: 8
Training loss: 2.936432123184204
Validation loss: 2.01472145318985

Epoch: 6| Step: 9
Training loss: 1.8289698362350464
Validation loss: 2.0173398653666177

Epoch: 6| Step: 10
Training loss: 3.0064857006073
Validation loss: 2.018410940965017

Epoch: 6| Step: 11
Training loss: 1.7003514766693115
Validation loss: 2.026961366335551

Epoch: 6| Step: 12
Training loss: 1.7264454364776611
Validation loss: 2.0313682158788047

Epoch: 6| Step: 13
Training loss: 2.1414883136749268
Validation loss: 2.0353771448135376

Epoch: 75| Step: 0
Training loss: 2.217529296875
Validation loss: 2.035776158173879

Epoch: 6| Step: 1
Training loss: 2.3994126319885254
Validation loss: 2.0306374231974282

Epoch: 6| Step: 2
Training loss: 2.6106033325195312
Validation loss: 2.027493437131246

Epoch: 6| Step: 3
Training loss: 2.7862472534179688
Validation loss: 2.0220353404680886

Epoch: 6| Step: 4
Training loss: 1.9121034145355225
Validation loss: 2.023878594239553

Epoch: 6| Step: 5
Training loss: 2.0925192832946777
Validation loss: 2.018964926401774

Epoch: 6| Step: 6
Training loss: 2.2174642086029053
Validation loss: 2.0136663913726807

Epoch: 6| Step: 7
Training loss: 2.1925599575042725
Validation loss: 2.0259336034456887

Epoch: 6| Step: 8
Training loss: 2.147998332977295
Validation loss: 2.02614963054657

Epoch: 6| Step: 9
Training loss: 1.8097264766693115
Validation loss: 2.0201081236203513

Epoch: 6| Step: 10
Training loss: 1.8343567848205566
Validation loss: 2.027929345766703

Epoch: 6| Step: 11
Training loss: 2.120105266571045
Validation loss: 2.027458747227987

Epoch: 6| Step: 12
Training loss: 1.9685726165771484
Validation loss: 2.0445600946744285

Epoch: 6| Step: 13
Training loss: 2.1525869369506836
Validation loss: 2.042458792527517

Epoch: 76| Step: 0
Training loss: 2.984555959701538
Validation loss: 2.033572514851888

Epoch: 6| Step: 1
Training loss: 1.949162244796753
Validation loss: 2.031009296576182

Epoch: 6| Step: 2
Training loss: 1.5534751415252686
Validation loss: 2.019168814023336

Epoch: 6| Step: 3
Training loss: 2.0358128547668457
Validation loss: 2.016735076904297

Epoch: 6| Step: 4
Training loss: 2.828359603881836
Validation loss: 2.015309731165568

Epoch: 6| Step: 5
Training loss: 2.528965950012207
Validation loss: 2.0157207250595093

Epoch: 6| Step: 6
Training loss: 2.4064507484436035
Validation loss: 2.0120225747426352

Epoch: 6| Step: 7
Training loss: 2.2037041187286377
Validation loss: 2.0117106239000955

Epoch: 6| Step: 8
Training loss: 1.985776424407959
Validation loss: 2.020930806795756

Epoch: 6| Step: 9
Training loss: 2.395716428756714
Validation loss: 2.0189502835273743

Epoch: 6| Step: 10
Training loss: 1.265700101852417
Validation loss: 2.0206338763237

Epoch: 6| Step: 11
Training loss: 1.8535230159759521
Validation loss: 2.018495261669159

Epoch: 6| Step: 12
Training loss: 2.0758132934570312
Validation loss: 2.0312543312708535

Epoch: 6| Step: 13
Training loss: 2.401639699935913
Validation loss: 2.0183926026026406

Epoch: 77| Step: 0
Training loss: 2.3256986141204834
Validation loss: 2.0176029801368713

Epoch: 6| Step: 1
Training loss: 2.6358237266540527
Validation loss: 2.0255321860313416

Epoch: 6| Step: 2
Training loss: 2.2705912590026855
Validation loss: 2.029021978378296

Epoch: 6| Step: 3
Training loss: 2.179100513458252
Validation loss: 2.023964782555898

Epoch: 6| Step: 4
Training loss: 1.796891212463379
Validation loss: 2.0210734407107034

Epoch: 6| Step: 5
Training loss: 1.7798717021942139
Validation loss: 2.0173994302749634

Epoch: 6| Step: 6
Training loss: 3.077578544616699
Validation loss: 2.0122984250386557

Epoch: 6| Step: 7
Training loss: 1.8080031871795654
Validation loss: 2.016380727291107

Epoch: 6| Step: 8
Training loss: 2.0869905948638916
Validation loss: 2.00751123825709

Epoch: 6| Step: 9
Training loss: 2.490208148956299
Validation loss: 2.0112273693084717

Epoch: 6| Step: 10
Training loss: 2.3515052795410156
Validation loss: 2.0104273160298667

Epoch: 6| Step: 11
Training loss: 2.1297080516815186
Validation loss: 2.009370485941569

Epoch: 6| Step: 12
Training loss: 1.221006155014038
Validation loss: 2.0130138198534646

Epoch: 6| Step: 13
Training loss: 2.175041675567627
Validation loss: 2.014379878838857

Epoch: 78| Step: 0
Training loss: 1.9286354780197144
Validation loss: 2.00982803106308

Epoch: 6| Step: 1
Training loss: 2.089967966079712
Validation loss: 2.0087218483289084

Epoch: 6| Step: 2
Training loss: 2.2262072563171387
Validation loss: 2.013352076212565

Epoch: 6| Step: 3
Training loss: 2.430410861968994
Validation loss: 2.0209814310073853

Epoch: 6| Step: 4
Training loss: 2.926912784576416
Validation loss: 2.032560726006826

Epoch: 6| Step: 5
Training loss: 2.309434413909912
Validation loss: 2.0206658045450845

Epoch: 6| Step: 6
Training loss: 2.2606732845306396
Validation loss: 2.0306421717007956

Epoch: 6| Step: 7
Training loss: 1.6243623495101929
Validation loss: 2.0232849717140198

Epoch: 6| Step: 8
Training loss: 2.011087417602539
Validation loss: 2.029190023740133

Epoch: 6| Step: 9
Training loss: 2.069392681121826
Validation loss: 2.0429727435112

Epoch: 6| Step: 10
Training loss: 2.200143814086914
Validation loss: 2.05084357659022

Epoch: 6| Step: 11
Training loss: 2.9477145671844482
Validation loss: 2.0543601910273233

Epoch: 6| Step: 12
Training loss: 1.6519408226013184
Validation loss: 2.0617963075637817

Epoch: 6| Step: 13
Training loss: 1.7705276012420654
Validation loss: 2.0512020190556846

Epoch: 79| Step: 0
Training loss: 2.515902042388916
Validation loss: 2.0349162817001343

Epoch: 6| Step: 1
Training loss: 2.221423625946045
Validation loss: 2.0222682555516562

Epoch: 6| Step: 2
Training loss: 2.393751621246338
Validation loss: 2.0183301170667014

Epoch: 6| Step: 3
Training loss: 2.040858745574951
Validation loss: 2.0238499840100608

Epoch: 6| Step: 4
Training loss: 2.1017956733703613
Validation loss: 2.030683914820353

Epoch: 6| Step: 5
Training loss: 2.340010166168213
Validation loss: 2.039445618788401

Epoch: 6| Step: 6
Training loss: 2.1116647720336914
Validation loss: 2.043077846368154

Epoch: 6| Step: 7
Training loss: 1.9226607084274292
Validation loss: 2.038425346215566

Epoch: 6| Step: 8
Training loss: 2.4099245071411133
Validation loss: 2.045709808667501

Epoch: 6| Step: 9
Training loss: 2.053955078125
Validation loss: 2.0447097222010293

Epoch: 6| Step: 10
Training loss: 1.557275414466858
Validation loss: 2.046150326728821

Epoch: 6| Step: 11
Training loss: 1.9300113916397095
Validation loss: 2.0484232703844705

Epoch: 6| Step: 12
Training loss: 2.7155137062072754
Validation loss: 2.043450971444448

Epoch: 6| Step: 13
Training loss: 2.3653082847595215
Validation loss: 2.0406600634256997

Epoch: 80| Step: 0
Training loss: 1.9304821491241455
Validation loss: 2.0333486994107566

Epoch: 6| Step: 1
Training loss: 1.5466574430465698
Validation loss: 2.039263606071472

Epoch: 6| Step: 2
Training loss: 3.1281919479370117
Validation loss: 2.035688638687134

Epoch: 6| Step: 3
Training loss: 2.514803647994995
Validation loss: 2.03244278828303

Epoch: 6| Step: 4
Training loss: 1.7985732555389404
Validation loss: 2.0291945338249207

Epoch: 6| Step: 5
Training loss: 2.139399290084839
Validation loss: 2.0296860734621682

Epoch: 6| Step: 6
Training loss: 2.278352737426758
Validation loss: 2.0242914954821267

Epoch: 6| Step: 7
Training loss: 2.389402389526367
Validation loss: 2.0103232065836587

Epoch: 6| Step: 8
Training loss: 2.026370048522949
Validation loss: 2.013130704561869

Epoch: 6| Step: 9
Training loss: 1.94375479221344
Validation loss: 2.0139702955881753

Epoch: 6| Step: 10
Training loss: 2.3262853622436523
Validation loss: 2.0246670842170715

Epoch: 6| Step: 11
Training loss: 1.9702130556106567
Validation loss: 2.0252007246017456

Epoch: 6| Step: 12
Training loss: 2.2237422466278076
Validation loss: 2.053216814994812

Epoch: 6| Step: 13
Training loss: 2.4397919178009033
Validation loss: 2.0544895927111306

Epoch: 81| Step: 0
Training loss: 2.1943299770355225
Validation loss: 2.053523361682892

Epoch: 6| Step: 1
Training loss: 2.3172874450683594
Validation loss: 2.04375167687734

Epoch: 6| Step: 2
Training loss: 2.375077962875366
Validation loss: 2.038664758205414

Epoch: 6| Step: 3
Training loss: 2.0766379833221436
Validation loss: 2.035553594430288

Epoch: 6| Step: 4
Training loss: 1.3478975296020508
Validation loss: 2.0262686212857566

Epoch: 6| Step: 5
Training loss: 2.0276975631713867
Validation loss: 2.0164031783739724

Epoch: 6| Step: 6
Training loss: 2.1951355934143066
Validation loss: 2.0145603815714517

Epoch: 6| Step: 7
Training loss: 2.1494994163513184
Validation loss: 2.0206268231074014

Epoch: 6| Step: 8
Training loss: 2.250636577606201
Validation loss: 2.0220567186673484

Epoch: 6| Step: 9
Training loss: 2.3868017196655273
Validation loss: 2.021950046221415

Epoch: 6| Step: 10
Training loss: 2.6817898750305176
Validation loss: 2.02129328250885

Epoch: 6| Step: 11
Training loss: 2.2488625049591064
Validation loss: 2.025064845879873

Epoch: 6| Step: 12
Training loss: 2.276510238647461
Validation loss: 2.0196349223454795

Epoch: 6| Step: 13
Training loss: 1.937186360359192
Validation loss: 2.0260813236236572

Epoch: 82| Step: 0
Training loss: 2.1945624351501465
Validation loss: 2.0215221842130027

Epoch: 6| Step: 1
Training loss: 2.036904811859131
Validation loss: 2.023574411869049

Epoch: 6| Step: 2
Training loss: 2.028360366821289
Validation loss: 2.0213856299718223

Epoch: 6| Step: 3
Training loss: 2.6229758262634277
Validation loss: 2.0210747122764587

Epoch: 6| Step: 4
Training loss: 1.5909576416015625
Validation loss: 2.028835197289785

Epoch: 6| Step: 5
Training loss: 1.8704862594604492
Validation loss: 2.0246620972951255

Epoch: 6| Step: 6
Training loss: 2.0861892700195312
Validation loss: 2.029825766881307

Epoch: 6| Step: 7
Training loss: 1.6431169509887695
Validation loss: 2.034278174241384

Epoch: 6| Step: 8
Training loss: 2.8054769039154053
Validation loss: 2.0358469684918723

Epoch: 6| Step: 9
Training loss: 2.334771156311035
Validation loss: 2.0338696440060935

Epoch: 6| Step: 10
Training loss: 2.0329055786132812
Validation loss: 2.0242116848627725

Epoch: 6| Step: 11
Training loss: 2.132612705230713
Validation loss: 2.0221530199050903

Epoch: 6| Step: 12
Training loss: 2.2699813842773438
Validation loss: 2.0269498229026794

Epoch: 6| Step: 13
Training loss: 2.4975757598876953
Validation loss: 2.021402815977732

Epoch: 83| Step: 0
Training loss: 2.461289405822754
Validation loss: 2.0117657581965127

Epoch: 6| Step: 1
Training loss: 2.4133427143096924
Validation loss: 2.0028762022654214

Epoch: 6| Step: 2
Training loss: 1.4879224300384521
Validation loss: 2.006895124912262

Epoch: 6| Step: 3
Training loss: 1.74424409866333
Validation loss: 2.0053425828615823

Epoch: 6| Step: 4
Training loss: 2.4439806938171387
Validation loss: 2.009346862634023

Epoch: 6| Step: 5
Training loss: 2.1717329025268555
Validation loss: 2.0076218247413635

Epoch: 6| Step: 6
Training loss: 1.8039419651031494
Validation loss: 2.007154961427053

Epoch: 6| Step: 7
Training loss: 1.9328267574310303
Validation loss: 2.005221883455912

Epoch: 6| Step: 8
Training loss: 2.8827195167541504
Validation loss: 1.997498134771983

Epoch: 6| Step: 9
Training loss: 2.1862001419067383
Validation loss: 2.008238653341929

Epoch: 6| Step: 10
Training loss: 2.147757053375244
Validation loss: 2.000540554523468

Epoch: 6| Step: 11
Training loss: 2.2111144065856934
Validation loss: 2.0045345425605774

Epoch: 6| Step: 12
Training loss: 2.378608226776123
Validation loss: 2.0048588116963706

Epoch: 6| Step: 13
Training loss: 1.9107569456100464
Validation loss: 2.003117104371389

Epoch: 84| Step: 0
Training loss: 2.213409423828125
Validation loss: 2.011206408341726

Epoch: 6| Step: 1
Training loss: 1.5612986087799072
Validation loss: 2.021498143672943

Epoch: 6| Step: 2
Training loss: 1.7194201946258545
Validation loss: 2.0264089107513428

Epoch: 6| Step: 3
Training loss: 1.9058055877685547
Validation loss: 2.0271966457366943

Epoch: 6| Step: 4
Training loss: 2.632213830947876
Validation loss: 2.0412267645200095

Epoch: 6| Step: 5
Training loss: 2.397170305252075
Validation loss: 2.0438987414042153

Epoch: 6| Step: 6
Training loss: 2.2669901847839355
Validation loss: 2.047812263170878

Epoch: 6| Step: 7
Training loss: 2.168461322784424
Validation loss: 2.0493220885594687

Epoch: 6| Step: 8
Training loss: 2.8398430347442627
Validation loss: 2.053956687450409

Epoch: 6| Step: 9
Training loss: 1.3474063873291016
Validation loss: 2.0437289079030356

Epoch: 6| Step: 10
Training loss: 2.125999927520752
Validation loss: 2.046342372894287

Epoch: 6| Step: 11
Training loss: 2.1524276733398438
Validation loss: 2.033375879128774

Epoch: 6| Step: 12
Training loss: 2.700610876083374
Validation loss: 2.03819876909256

Epoch: 6| Step: 13
Training loss: 2.0748815536499023
Validation loss: 2.035616179307302

Epoch: 85| Step: 0
Training loss: 2.4934520721435547
Validation loss: 2.0405219992001853

Epoch: 6| Step: 1
Training loss: 1.4265745878219604
Validation loss: 2.0349266131718955

Epoch: 6| Step: 2
Training loss: 2.6900782585144043
Validation loss: 2.0387280782063804

Epoch: 6| Step: 3
Training loss: 1.8305431604385376
Validation loss: 2.033038854598999

Epoch: 6| Step: 4
Training loss: 2.192582130432129
Validation loss: 2.0268830259641013

Epoch: 6| Step: 5
Training loss: 2.2482309341430664
Validation loss: 2.016471207141876

Epoch: 6| Step: 6
Training loss: 2.4824447631835938
Validation loss: 2.0134483575820923

Epoch: 6| Step: 7
Training loss: 1.6906013488769531
Validation loss: 2.0131094257036843

Epoch: 6| Step: 8
Training loss: 2.4439826011657715
Validation loss: 2.0096293091773987

Epoch: 6| Step: 9
Training loss: 1.7015407085418701
Validation loss: 2.0112454891204834

Epoch: 6| Step: 10
Training loss: 2.069852590560913
Validation loss: 2.0025153954823813

Epoch: 6| Step: 11
Training loss: 1.9068961143493652
Validation loss: 2.003477374712626

Epoch: 6| Step: 12
Training loss: 2.3883631229400635
Validation loss: 2.0025179783503213

Epoch: 6| Step: 13
Training loss: 2.3712897300720215
Validation loss: 2.0126511454582214

Epoch: 86| Step: 0
Training loss: 2.2754621505737305
Validation loss: 1.999359409014384

Epoch: 6| Step: 1
Training loss: 1.7315142154693604
Validation loss: 2.0082716743151345

Epoch: 6| Step: 2
Training loss: 2.0317790508270264
Validation loss: 2.0071388483047485

Epoch: 6| Step: 3
Training loss: 2.080394983291626
Validation loss: 2.0090496142705283

Epoch: 6| Step: 4
Training loss: 2.501725673675537
Validation loss: 2.0081944664319358

Epoch: 6| Step: 5
Training loss: 1.7738981246948242
Validation loss: 2.0181051095326743

Epoch: 6| Step: 6
Training loss: 2.680549144744873
Validation loss: 2.0202932755152383

Epoch: 6| Step: 7
Training loss: 2.2988953590393066
Validation loss: 2.027893284956614

Epoch: 6| Step: 8
Training loss: 2.3003084659576416
Validation loss: 2.0478931665420532

Epoch: 6| Step: 9
Training loss: 1.852767825126648
Validation loss: 2.037392795085907

Epoch: 6| Step: 10
Training loss: 1.935433268547058
Validation loss: 2.042874832948049

Epoch: 6| Step: 11
Training loss: 2.765995740890503
Validation loss: 2.0337375601132712

Epoch: 6| Step: 12
Training loss: 1.3748716115951538
Validation loss: 2.015709857145945

Epoch: 6| Step: 13
Training loss: 2.458012580871582
Validation loss: 2.0109373331069946

Epoch: 87| Step: 0
Training loss: 2.1609275341033936
Validation loss: 2.0036658445994058

Epoch: 6| Step: 1
Training loss: 2.6697826385498047
Validation loss: 2.0051389336586

Epoch: 6| Step: 2
Training loss: 2.4205636978149414
Validation loss: 2.005610545476278

Epoch: 6| Step: 3
Training loss: 1.9436653852462769
Validation loss: 2.0162912607192993

Epoch: 6| Step: 4
Training loss: 1.4777177572250366
Validation loss: 2.018634041150411

Epoch: 6| Step: 5
Training loss: 1.9199804067611694
Validation loss: 2.0232420365015664

Epoch: 6| Step: 6
Training loss: 2.355497360229492
Validation loss: 2.0268580317497253

Epoch: 6| Step: 7
Training loss: 3.025148868560791
Validation loss: 2.0239470799764

Epoch: 6| Step: 8
Training loss: 2.204096794128418
Validation loss: 2.0253867308298745

Epoch: 6| Step: 9
Training loss: 2.434034824371338
Validation loss: 2.024127185344696

Epoch: 6| Step: 10
Training loss: 1.392951250076294
Validation loss: 2.0263429284095764

Epoch: 6| Step: 11
Training loss: 2.146824836730957
Validation loss: 2.0240062872568765

Epoch: 6| Step: 12
Training loss: 1.8777244091033936
Validation loss: 2.0101316372553506

Epoch: 6| Step: 13
Training loss: 2.28165340423584
Validation loss: 2.0211186011632285

Epoch: 88| Step: 0
Training loss: 2.288045883178711
Validation loss: 2.0099552273750305

Epoch: 6| Step: 1
Training loss: 2.286599636077881
Validation loss: 2.0049155553181968

Epoch: 6| Step: 2
Training loss: 2.280639171600342
Validation loss: 2.001983960469564

Epoch: 6| Step: 3
Training loss: 2.3448586463928223
Validation loss: 2.004905025164286

Epoch: 6| Step: 4
Training loss: 2.5643696784973145
Validation loss: 2.0080086986223855

Epoch: 6| Step: 5
Training loss: 2.0299606323242188
Validation loss: 2.004928231239319

Epoch: 6| Step: 6
Training loss: 2.5935440063476562
Validation loss: 2.0088618993759155

Epoch: 6| Step: 7
Training loss: 1.99785315990448
Validation loss: 2.001405656337738

Epoch: 6| Step: 8
Training loss: 1.9968945980072021
Validation loss: 2.0075984398523965

Epoch: 6| Step: 9
Training loss: 1.932873249053955
Validation loss: 2.0323464075724282

Epoch: 6| Step: 10
Training loss: 2.1097612380981445
Validation loss: 2.0377705891927085

Epoch: 6| Step: 11
Training loss: 1.9819536209106445
Validation loss: 2.03694740931193

Epoch: 6| Step: 12
Training loss: 1.643118143081665
Validation loss: 2.0424894094467163

Epoch: 6| Step: 13
Training loss: 1.7772094011306763
Validation loss: 2.0392228762308755

Epoch: 89| Step: 0
Training loss: 2.5454673767089844
Validation loss: 2.0350085298220315

Epoch: 6| Step: 1
Training loss: 1.485889196395874
Validation loss: 2.0409383376439414

Epoch: 6| Step: 2
Training loss: 2.645172595977783
Validation loss: 2.0311027566591897

Epoch: 6| Step: 3
Training loss: 2.087747097015381
Validation loss: 2.028039733568827

Epoch: 6| Step: 4
Training loss: 2.437631130218506
Validation loss: 2.02635266383489

Epoch: 6| Step: 5
Training loss: 2.156730890274048
Validation loss: 2.0405214627583823

Epoch: 6| Step: 6
Training loss: 2.3854000568389893
Validation loss: 2.0331637461980185

Epoch: 6| Step: 7
Training loss: 1.9722189903259277
Validation loss: 2.032620628674825

Epoch: 6| Step: 8
Training loss: 2.5853140354156494
Validation loss: 2.0404167970021567

Epoch: 6| Step: 9
Training loss: 1.881965160369873
Validation loss: 2.033506373564402

Epoch: 6| Step: 10
Training loss: 1.995779275894165
Validation loss: 2.0383658409118652

Epoch: 6| Step: 11
Training loss: 1.9253294467926025
Validation loss: 2.034525136152903

Epoch: 6| Step: 12
Training loss: 2.278557777404785
Validation loss: 2.0466906428337097

Epoch: 6| Step: 13
Training loss: 1.5962773561477661
Validation loss: 2.034807781378428

Epoch: 90| Step: 0
Training loss: 2.225956439971924
Validation loss: 2.0242035587628684

Epoch: 6| Step: 1
Training loss: 2.3078079223632812
Validation loss: 2.0197705030441284

Epoch: 6| Step: 2
Training loss: 1.457992672920227
Validation loss: 2.0151815017064414

Epoch: 6| Step: 3
Training loss: 2.517324447631836
Validation loss: 2.0057647029558816

Epoch: 6| Step: 4
Training loss: 2.1313061714172363
Validation loss: 2.011811137199402

Epoch: 6| Step: 5
Training loss: 2.500073194503784
Validation loss: 2.0106041034062705

Epoch: 6| Step: 6
Training loss: 2.0922484397888184
Validation loss: 1.9983965555826824

Epoch: 6| Step: 7
Training loss: 2.222238302230835
Validation loss: 2.009888549645742

Epoch: 6| Step: 8
Training loss: 2.173224687576294
Validation loss: 2.0134376088778176

Epoch: 6| Step: 9
Training loss: 2.042431354522705
Validation loss: 2.0112319191296897

Epoch: 6| Step: 10
Training loss: 2.4203848838806152
Validation loss: 2.006077150503794

Epoch: 6| Step: 11
Training loss: 1.767552137374878
Validation loss: 2.0144340793291726

Epoch: 6| Step: 12
Training loss: 1.692991018295288
Validation loss: 2.01918093363444

Epoch: 6| Step: 13
Training loss: 2.418254852294922
Validation loss: 2.01010529200236

Epoch: 91| Step: 0
Training loss: 1.691360592842102
Validation loss: 2.021929303805033

Epoch: 6| Step: 1
Training loss: 2.447065830230713
Validation loss: 2.0315096378326416

Epoch: 6| Step: 2
Training loss: 1.9357945919036865
Validation loss: 2.042635222276052

Epoch: 6| Step: 3
Training loss: 2.014284133911133
Validation loss: 2.040434936682383

Epoch: 6| Step: 4
Training loss: 2.012155294418335
Validation loss: 2.0399362047513327

Epoch: 6| Step: 5
Training loss: 3.082855701446533
Validation loss: 2.0420870383580527

Epoch: 6| Step: 6
Training loss: 2.5505523681640625
Validation loss: 2.0240631898244223

Epoch: 6| Step: 7
Training loss: 2.609135150909424
Validation loss: 2.005862295627594

Epoch: 6| Step: 8
Training loss: 1.705175518989563
Validation loss: 2.003380537033081

Epoch: 6| Step: 9
Training loss: 2.724825859069824
Validation loss: 2.004303256670634

Epoch: 6| Step: 10
Training loss: 1.857840657234192
Validation loss: 2.0009947220484414

Epoch: 6| Step: 11
Training loss: 1.8099802732467651
Validation loss: 2.0071296095848083

Epoch: 6| Step: 12
Training loss: 1.6145843267440796
Validation loss: 2.0071340203285217

Epoch: 6| Step: 13
Training loss: 1.9496192932128906
Validation loss: 2.01182230313619

Epoch: 92| Step: 0
Training loss: 2.279691219329834
Validation loss: 2.001425325870514

Epoch: 6| Step: 1
Training loss: 2.3643434047698975
Validation loss: 2.006011346975962

Epoch: 6| Step: 2
Training loss: 2.28316068649292
Validation loss: 2.007382412751516

Epoch: 6| Step: 3
Training loss: 2.700882911682129
Validation loss: 2.0000129540761313

Epoch: 6| Step: 4
Training loss: 1.9567992687225342
Validation loss: 2.002475599447886

Epoch: 6| Step: 5
Training loss: 1.8850988149642944
Validation loss: 2.0058730642000833

Epoch: 6| Step: 6
Training loss: 1.6543986797332764
Validation loss: 2.003094812234243

Epoch: 6| Step: 7
Training loss: 1.8248023986816406
Validation loss: 2.008001466592153

Epoch: 6| Step: 8
Training loss: 2.1420955657958984
Validation loss: 2.005572239557902

Epoch: 6| Step: 9
Training loss: 2.036682605743408
Validation loss: 2.013898332913717

Epoch: 6| Step: 10
Training loss: 2.338205575942993
Validation loss: 2.017034888267517

Epoch: 6| Step: 11
Training loss: 2.341061592102051
Validation loss: 2.0198108156522117

Epoch: 6| Step: 12
Training loss: 2.035008668899536
Validation loss: 2.017916520436605

Epoch: 6| Step: 13
Training loss: 1.8550095558166504
Validation loss: 2.0222167372703552

Epoch: 93| Step: 0
Training loss: 1.930802583694458
Validation loss: 2.030749579270681

Epoch: 6| Step: 1
Training loss: 1.9382927417755127
Validation loss: 2.011906941731771

Epoch: 6| Step: 2
Training loss: 2.2773914337158203
Validation loss: 2.0127519766489663

Epoch: 6| Step: 3
Training loss: 2.2872209548950195
Validation loss: 2.035155196984609

Epoch: 6| Step: 4
Training loss: 2.0171804428100586
Validation loss: 2.0342915256818137

Epoch: 6| Step: 5
Training loss: 1.9700958728790283
Validation loss: 2.024159530798594

Epoch: 6| Step: 6
Training loss: 1.3709092140197754
Validation loss: 2.0169695615768433

Epoch: 6| Step: 7
Training loss: 2.4789631366729736
Validation loss: 2.016283472379049

Epoch: 6| Step: 8
Training loss: 1.525924801826477
Validation loss: 2.0116475423177085

Epoch: 6| Step: 9
Training loss: 1.8378586769104004
Validation loss: 1.9999104738235474

Epoch: 6| Step: 10
Training loss: 2.5516695976257324
Validation loss: 2.005132536093394

Epoch: 6| Step: 11
Training loss: 2.4854249954223633
Validation loss: 1.9969995816548665

Epoch: 6| Step: 12
Training loss: 2.110624074935913
Validation loss: 2.0044214526812234

Epoch: 6| Step: 13
Training loss: 2.895125389099121
Validation loss: 2.0059043169021606

Epoch: 94| Step: 0
Training loss: 1.9700199365615845
Validation loss: 2.0002284049987793

Epoch: 6| Step: 1
Training loss: 2.738516330718994
Validation loss: 2.0078357060750327

Epoch: 6| Step: 2
Training loss: 2.363510847091675
Validation loss: 2.0161888798077903

Epoch: 6| Step: 3
Training loss: 1.8444913625717163
Validation loss: 2.0070969065030417

Epoch: 6| Step: 4
Training loss: 2.192645311355591
Validation loss: 2.0041080514589944

Epoch: 6| Step: 5
Training loss: 1.7020254135131836
Validation loss: 2.008750398953756

Epoch: 6| Step: 6
Training loss: 2.2725605964660645
Validation loss: 2.011017322540283

Epoch: 6| Step: 7
Training loss: 2.272716522216797
Validation loss: 2.0065994461377463

Epoch: 6| Step: 8
Training loss: 2.131840705871582
Validation loss: 2.007516086101532

Epoch: 6| Step: 9
Training loss: 2.2824130058288574
Validation loss: 2.0229972998301187

Epoch: 6| Step: 10
Training loss: 1.9732651710510254
Validation loss: 2.018550713857015

Epoch: 6| Step: 11
Training loss: 2.440138339996338
Validation loss: 2.022225300470988

Epoch: 6| Step: 12
Training loss: 2.329730987548828
Validation loss: 2.01350329319636

Epoch: 6| Step: 13
Training loss: 1.1734095811843872
Validation loss: 2.0119143525759378

Epoch: 95| Step: 0
Training loss: 2.073443651199341
Validation loss: 2.020601511001587

Epoch: 6| Step: 1
Training loss: 2.3516154289245605
Validation loss: 2.0195361773173013

Epoch: 6| Step: 2
Training loss: 2.5928587913513184
Validation loss: 2.0141306718190513

Epoch: 6| Step: 3
Training loss: 2.0223569869995117
Validation loss: 2.0222562551498413

Epoch: 6| Step: 4
Training loss: 1.5195653438568115
Validation loss: 2.0131343603134155

Epoch: 6| Step: 5
Training loss: 2.0271012783050537
Validation loss: 2.02759317557017

Epoch: 6| Step: 6
Training loss: 2.460418939590454
Validation loss: 2.0237653454144797

Epoch: 6| Step: 7
Training loss: 2.168318748474121
Validation loss: 2.024676044782003

Epoch: 6| Step: 8
Training loss: 2.2504618167877197
Validation loss: 2.0194596449534097

Epoch: 6| Step: 9
Training loss: 1.6487033367156982
Validation loss: 2.0354084769884744

Epoch: 6| Step: 10
Training loss: 2.0602774620056152
Validation loss: 2.0244083801905313

Epoch: 6| Step: 11
Training loss: 1.9314323663711548
Validation loss: 2.0115098357200623

Epoch: 6| Step: 12
Training loss: 2.3310799598693848
Validation loss: 2.0165346463521323

Epoch: 6| Step: 13
Training loss: 2.2004590034484863
Validation loss: 2.017083783944448

Epoch: 96| Step: 0
Training loss: 2.197523593902588
Validation loss: 2.007928808530172

Epoch: 6| Step: 1
Training loss: 2.8932483196258545
Validation loss: 2.0053319334983826

Epoch: 6| Step: 2
Training loss: 2.3380837440490723
Validation loss: 2.008653541405996

Epoch: 6| Step: 3
Training loss: 2.251581907272339
Validation loss: 2.0093206763267517

Epoch: 6| Step: 4
Training loss: 2.2016592025756836
Validation loss: 2.0047457218170166

Epoch: 6| Step: 5
Training loss: 2.631636142730713
Validation loss: 2.0068745811780295

Epoch: 6| Step: 6
Training loss: 2.241579294204712
Validation loss: 2.0067794720331826

Epoch: 6| Step: 7
Training loss: 1.7542893886566162
Validation loss: 2.022918144861857

Epoch: 6| Step: 8
Training loss: 1.8181334733963013
Validation loss: 2.0155638058980307

Epoch: 6| Step: 9
Training loss: 1.8965250253677368
Validation loss: 2.0213425358136496

Epoch: 6| Step: 10
Training loss: 1.3749300241470337
Validation loss: 2.0215998888015747

Epoch: 6| Step: 11
Training loss: 2.0131990909576416
Validation loss: 2.0288076798121133

Epoch: 6| Step: 12
Training loss: 1.8222072124481201
Validation loss: 2.0438985029856362

Epoch: 6| Step: 13
Training loss: 2.2194035053253174
Validation loss: 2.040534794330597

Epoch: 97| Step: 0
Training loss: 2.2749404907226562
Validation loss: 2.0362173517545066

Epoch: 6| Step: 1
Training loss: 2.4069390296936035
Validation loss: 2.0330763459205627

Epoch: 6| Step: 2
Training loss: 2.3230581283569336
Validation loss: 2.0314801136652627

Epoch: 6| Step: 3
Training loss: 2.022360324859619
Validation loss: 2.0363576213518777

Epoch: 6| Step: 4
Training loss: 2.277498245239258
Validation loss: 2.022887428601583

Epoch: 6| Step: 5
Training loss: 2.5048885345458984
Validation loss: 2.0111308693885803

Epoch: 6| Step: 6
Training loss: 2.188210964202881
Validation loss: 2.005194067955017

Epoch: 6| Step: 7
Training loss: 2.2683753967285156
Validation loss: 2.008254607518514

Epoch: 6| Step: 8
Training loss: 2.0655908584594727
Validation loss: 2.009649376074473

Epoch: 6| Step: 9
Training loss: 2.440840721130371
Validation loss: 2.009360154469808

Epoch: 6| Step: 10
Training loss: 1.9046703577041626
Validation loss: 2.0130682786305747

Epoch: 6| Step: 11
Training loss: 1.7809141874313354
Validation loss: 2.0078184803326926

Epoch: 6| Step: 12
Training loss: 1.7188935279846191
Validation loss: 1.9959583481152852

Epoch: 6| Step: 13
Training loss: 1.618269681930542
Validation loss: 2.005886733531952

Epoch: 98| Step: 0
Training loss: 1.7268548011779785
Validation loss: 2.0040143926938376

Epoch: 6| Step: 1
Training loss: 2.5316338539123535
Validation loss: 1.9928661783536274

Epoch: 6| Step: 2
Training loss: 2.107607841491699
Validation loss: 2.0025338331858316

Epoch: 6| Step: 3
Training loss: 2.289578437805176
Validation loss: 1.9991806944211323

Epoch: 6| Step: 4
Training loss: 2.314772129058838
Validation loss: 2.00727113087972

Epoch: 6| Step: 5
Training loss: 1.7875699996948242
Validation loss: 2.0144256154696145

Epoch: 6| Step: 6
Training loss: 2.5106821060180664
Validation loss: 2.0250194470087686

Epoch: 6| Step: 7
Training loss: 2.1449265480041504
Validation loss: 2.0520270466804504

Epoch: 6| Step: 8
Training loss: 2.1755943298339844
Validation loss: 2.0491988261540732

Epoch: 6| Step: 9
Training loss: 2.009406089782715
Validation loss: 2.0351185401280723

Epoch: 6| Step: 10
Training loss: 2.642975330352783
Validation loss: 2.0288673837979636

Epoch: 6| Step: 11
Training loss: 1.6797609329223633
Validation loss: 2.014880955219269

Epoch: 6| Step: 12
Training loss: 2.3249688148498535
Validation loss: 2.0144450267155967

Epoch: 6| Step: 13
Training loss: 1.5952903032302856
Validation loss: 2.0076722701390586

Epoch: 99| Step: 0
Training loss: 2.046269178390503
Validation loss: 2.0116282304128013

Epoch: 6| Step: 1
Training loss: 1.7345584630966187
Validation loss: 2.008202870686849

Epoch: 6| Step: 2
Training loss: 2.5469486713409424
Validation loss: 2.0091507037480674

Epoch: 6| Step: 3
Training loss: 2.380552291870117
Validation loss: 2.0216429034868875

Epoch: 6| Step: 4
Training loss: 2.04052734375
Validation loss: 2.0205100178718567

Epoch: 6| Step: 5
Training loss: 1.6538411378860474
Validation loss: 2.0233403046925864

Epoch: 6| Step: 6
Training loss: 1.9151389598846436
Validation loss: 2.0205119450887046

Epoch: 6| Step: 7
Training loss: 2.1690406799316406
Validation loss: 2.018990993499756

Epoch: 6| Step: 8
Training loss: 2.1815409660339355
Validation loss: 2.029121001561483

Epoch: 6| Step: 9
Training loss: 2.071524143218994
Validation loss: 2.031120320161184

Epoch: 6| Step: 10
Training loss: 2.4317638874053955
Validation loss: 2.0385910868644714

Epoch: 6| Step: 11
Training loss: 1.5080291032791138
Validation loss: 2.0322434306144714

Epoch: 6| Step: 12
Training loss: 2.7436132431030273
Validation loss: 2.036229650179545

Epoch: 6| Step: 13
Training loss: 2.1338679790496826
Validation loss: 2.035306771596273

Epoch: 100| Step: 0
Training loss: 1.3907270431518555
Validation loss: 2.01908540725708

Epoch: 6| Step: 1
Training loss: 1.825308918952942
Validation loss: 2.0184813141822815

Epoch: 6| Step: 2
Training loss: 2.098649501800537
Validation loss: 2.0269195437431335

Epoch: 6| Step: 3
Training loss: 2.0304481983184814
Validation loss: 2.0340757369995117

Epoch: 6| Step: 4
Training loss: 2.479520082473755
Validation loss: 2.0181708534558616

Epoch: 6| Step: 5
Training loss: 2.0128626823425293
Validation loss: 2.027540922164917

Epoch: 6| Step: 6
Training loss: 1.9466426372528076
Validation loss: 2.0163856546084085

Epoch: 6| Step: 7
Training loss: 2.568671464920044
Validation loss: 2.0177278916041055

Epoch: 6| Step: 8
Training loss: 1.8224914073944092
Validation loss: 2.0190935532251992

Epoch: 6| Step: 9
Training loss: 2.2715325355529785
Validation loss: 2.0174927512804666

Epoch: 6| Step: 10
Training loss: 1.8665969371795654
Validation loss: 2.0171930392583213

Epoch: 6| Step: 11
Training loss: 2.5721054077148438
Validation loss: 2.01255730787913

Epoch: 6| Step: 12
Training loss: 2.187588691711426
Validation loss: 2.016554117202759

Epoch: 6| Step: 13
Training loss: 2.297029495239258
Validation loss: 2.0178470810254416

Epoch: 101| Step: 0
Training loss: 1.592853307723999
Validation loss: 2.027010122934977

Epoch: 6| Step: 1
Training loss: 1.7386295795440674
Validation loss: 2.0303277571996055

Epoch: 6| Step: 2
Training loss: 2.2490947246551514
Validation loss: 2.03050963083903

Epoch: 6| Step: 3
Training loss: 2.023573398590088
Validation loss: 2.046423335870107

Epoch: 6| Step: 4
Training loss: 1.5482577085494995
Validation loss: 2.0368964870770774

Epoch: 6| Step: 5
Training loss: 2.4102649688720703
Validation loss: 2.036380410194397

Epoch: 6| Step: 6
Training loss: 1.719768762588501
Validation loss: 2.042913258075714

Epoch: 6| Step: 7
Training loss: 1.9522874355316162
Validation loss: 2.029758930206299

Epoch: 6| Step: 8
Training loss: 2.079763174057007
Validation loss: 2.027726729710897

Epoch: 6| Step: 9
Training loss: 2.319521427154541
Validation loss: 2.0273918310801187

Epoch: 6| Step: 10
Training loss: 1.9587873220443726
Validation loss: 2.022086262702942

Epoch: 6| Step: 11
Training loss: 2.2759766578674316
Validation loss: 2.014045476913452

Epoch: 6| Step: 12
Training loss: 3.3263564109802246
Validation loss: 2.0127787987391152

Epoch: 6| Step: 13
Training loss: 2.2197494506835938
Validation loss: 2.0082802176475525

Epoch: 102| Step: 0
Training loss: 2.0594916343688965
Validation loss: 2.00463475783666

Epoch: 6| Step: 1
Training loss: 1.8746405839920044
Validation loss: 2.0103655656178794

Epoch: 6| Step: 2
Training loss: 2.4846529960632324
Validation loss: 2.01236100991567

Epoch: 6| Step: 3
Training loss: 1.6167802810668945
Validation loss: 2.0148276686668396

Epoch: 6| Step: 4
Training loss: 1.742824673652649
Validation loss: 2.0141532023747764

Epoch: 6| Step: 5
Training loss: 2.6140694618225098
Validation loss: 2.006702244281769

Epoch: 6| Step: 6
Training loss: 1.9820115566253662
Validation loss: 2.008076806863149

Epoch: 6| Step: 7
Training loss: 1.8317234516143799
Validation loss: 2.0224570830663047

Epoch: 6| Step: 8
Training loss: 1.8941700458526611
Validation loss: 2.030638575553894

Epoch: 6| Step: 9
Training loss: 1.9159049987792969
Validation loss: 2.0532960891723633

Epoch: 6| Step: 10
Training loss: 2.529336929321289
Validation loss: 2.0621321201324463

Epoch: 6| Step: 11
Training loss: 2.691709041595459
Validation loss: 2.079480250676473

Epoch: 6| Step: 12
Training loss: 2.2089991569519043
Validation loss: 2.0904260873794556

Epoch: 6| Step: 13
Training loss: 2.2138233184814453
Validation loss: 2.0640706618626914

Epoch: 103| Step: 0
Training loss: 1.3921918869018555
Validation loss: 2.052731513977051

Epoch: 6| Step: 1
Training loss: 2.1504554748535156
Validation loss: 2.0468337138493857

Epoch: 6| Step: 2
Training loss: 2.0031702518463135
Validation loss: 2.027004619439443

Epoch: 6| Step: 3
Training loss: 1.8985306024551392
Validation loss: 2.030324180920919

Epoch: 6| Step: 4
Training loss: 2.075622320175171
Validation loss: 2.0180338819821677

Epoch: 6| Step: 5
Training loss: 1.7827636003494263
Validation loss: 2.0230408906936646

Epoch: 6| Step: 6
Training loss: 2.5801286697387695
Validation loss: 2.0366632541020713

Epoch: 6| Step: 7
Training loss: 2.745279550552368
Validation loss: 2.031378229459127

Epoch: 6| Step: 8
Training loss: 2.0607762336730957
Validation loss: 2.021892031033834

Epoch: 6| Step: 9
Training loss: 2.587646007537842
Validation loss: 2.0196531812349954

Epoch: 6| Step: 10
Training loss: 1.8076419830322266
Validation loss: 2.0225701928138733

Epoch: 6| Step: 11
Training loss: 2.5980687141418457
Validation loss: 2.023468832174937

Epoch: 6| Step: 12
Training loss: 2.126696825027466
Validation loss: 2.0173351764678955

Epoch: 6| Step: 13
Training loss: 2.1150288581848145
Validation loss: 2.0162752866744995

Epoch: 104| Step: 0
Training loss: 2.615081310272217
Validation loss: 2.024465044339498

Epoch: 6| Step: 1
Training loss: 2.006910800933838
Validation loss: 2.0476903120676675

Epoch: 6| Step: 2
Training loss: 2.283886432647705
Validation loss: 2.050783336162567

Epoch: 6| Step: 3
Training loss: 1.9980485439300537
Validation loss: 2.0708247423171997

Epoch: 6| Step: 4
Training loss: 2.295767307281494
Validation loss: 2.081784268220266

Epoch: 6| Step: 5
Training loss: 1.7056591510772705
Validation loss: 2.0927183826764426

Epoch: 6| Step: 6
Training loss: 2.126708507537842
Validation loss: 2.0841928720474243

Epoch: 6| Step: 7
Training loss: 2.087040662765503
Validation loss: 2.087015748023987

Epoch: 6| Step: 8
Training loss: 2.276294231414795
Validation loss: 2.074318250020345

Epoch: 6| Step: 9
Training loss: 2.2149744033813477
Validation loss: 2.05047337214152

Epoch: 6| Step: 10
Training loss: 2.098949432373047
Validation loss: 2.0393603642781577

Epoch: 6| Step: 11
Training loss: 2.3049683570861816
Validation loss: 2.01903235912323

Epoch: 6| Step: 12
Training loss: 1.9865421056747437
Validation loss: 2.016101876894633

Epoch: 6| Step: 13
Training loss: 1.6747654676437378
Validation loss: 2.0281127095222473

Epoch: 105| Step: 0
Training loss: 2.22886323928833
Validation loss: 2.0380573868751526

Epoch: 6| Step: 1
Training loss: 2.0171749591827393
Validation loss: 2.0437217156092324

Epoch: 6| Step: 2
Training loss: 1.7250210046768188
Validation loss: 2.042616307735443

Epoch: 6| Step: 3
Training loss: 2.0108256340026855
Validation loss: 2.0474879145622253

Epoch: 6| Step: 4
Training loss: 2.472900867462158
Validation loss: 2.041204591592153

Epoch: 6| Step: 5
Training loss: 1.8730323314666748
Validation loss: 2.048947254816691

Epoch: 6| Step: 6
Training loss: 2.4739537239074707
Validation loss: 2.0443984071413674

Epoch: 6| Step: 7
Training loss: 2.0397262573242188
Validation loss: 2.0457807977994285

Epoch: 6| Step: 8
Training loss: 2.149184226989746
Validation loss: 2.051603118578593

Epoch: 6| Step: 9
Training loss: 2.26897931098938
Validation loss: 2.049107631047567

Epoch: 6| Step: 10
Training loss: 2.7177562713623047
Validation loss: 2.0485438307126365

Epoch: 6| Step: 11
Training loss: 2.6954967975616455
Validation loss: 2.037050485610962

Epoch: 6| Step: 12
Training loss: 1.848414659500122
Validation loss: 2.040871818860372

Epoch: 6| Step: 13
Training loss: 2.089693069458008
Validation loss: 2.0433061917622886

Epoch: 106| Step: 0
Training loss: 2.363630771636963
Validation loss: 2.034194509188334

Epoch: 6| Step: 1
Training loss: 2.521942615509033
Validation loss: 2.026703198750814

Epoch: 6| Step: 2
Training loss: 1.5985110998153687
Validation loss: 2.028869390487671

Epoch: 6| Step: 3
Training loss: 2.1489615440368652
Validation loss: 2.0214796662330627

Epoch: 6| Step: 4
Training loss: 2.759744167327881
Validation loss: 2.0261497298876443

Epoch: 6| Step: 5
Training loss: 2.4979326725006104
Validation loss: 2.0248199701309204

Epoch: 6| Step: 6
Training loss: 2.277142286300659
Validation loss: 2.0266537268956504

Epoch: 6| Step: 7
Training loss: 2.029111385345459
Validation loss: 2.025368948777517

Epoch: 6| Step: 8
Training loss: 1.8953442573547363
Validation loss: 2.030171891053518

Epoch: 6| Step: 9
Training loss: 2.0987160205841064
Validation loss: 2.0257498224576316

Epoch: 6| Step: 10
Training loss: 2.298585891723633
Validation loss: 2.028167426586151

Epoch: 6| Step: 11
Training loss: 2.1486401557922363
Validation loss: 2.0274287263552346

Epoch: 6| Step: 12
Training loss: 1.7884931564331055
Validation loss: 2.016068994998932

Epoch: 6| Step: 13
Training loss: 1.663780927658081
Validation loss: 2.027316232522329

Epoch: 107| Step: 0
Training loss: 1.8642216920852661
Validation loss: 2.02793159087499

Epoch: 6| Step: 1
Training loss: 2.4351024627685547
Validation loss: 2.0504630406697593

Epoch: 6| Step: 2
Training loss: 1.5231127738952637
Validation loss: 2.0468676686286926

Epoch: 6| Step: 3
Training loss: 2.318024158477783
Validation loss: 2.0510624051094055

Epoch: 6| Step: 4
Training loss: 1.8170198202133179
Validation loss: 2.037033498287201

Epoch: 6| Step: 5
Training loss: 2.048218011856079
Validation loss: 2.0419166882832847

Epoch: 6| Step: 6
Training loss: 1.8344413042068481
Validation loss: 2.038808008035024

Epoch: 6| Step: 7
Training loss: 2.469817638397217
Validation loss: 2.0408462285995483

Epoch: 6| Step: 8
Training loss: 2.5941758155822754
Validation loss: 2.049703677495321

Epoch: 6| Step: 9
Training loss: 2.209578514099121
Validation loss: 2.052071988582611

Epoch: 6| Step: 10
Training loss: 1.6324915885925293
Validation loss: 2.048391819000244

Epoch: 6| Step: 11
Training loss: 2.394317150115967
Validation loss: 2.0506039460500083

Epoch: 6| Step: 12
Training loss: 2.2079038619995117
Validation loss: 2.0497477451960244

Epoch: 6| Step: 13
Training loss: 2.3108999729156494
Validation loss: 2.05266801516215

Epoch: 108| Step: 0
Training loss: 2.135500431060791
Validation loss: 2.0474554697672525

Epoch: 6| Step: 1
Training loss: 1.9993211030960083
Validation loss: 2.0437341928482056

Epoch: 6| Step: 2
Training loss: 2.135179042816162
Validation loss: 2.0267554918924966

Epoch: 6| Step: 3
Training loss: 2.673090934753418
Validation loss: 2.030482769012451

Epoch: 6| Step: 4
Training loss: 1.6760538816452026
Validation loss: 2.039340933163961

Epoch: 6| Step: 5
Training loss: 1.8429876565933228
Validation loss: 2.028938432534536

Epoch: 6| Step: 6
Training loss: 1.6750519275665283
Validation loss: 2.0372997721036277

Epoch: 6| Step: 7
Training loss: 2.2343227863311768
Validation loss: 2.043270746866862

Epoch: 6| Step: 8
Training loss: 2.556145191192627
Validation loss: 2.0439146359761557

Epoch: 6| Step: 9
Training loss: 1.592888355255127
Validation loss: 2.041375776131948

Epoch: 6| Step: 10
Training loss: 2.3056161403656006
Validation loss: 2.0473339955012

Epoch: 6| Step: 11
Training loss: 2.4700560569763184
Validation loss: 2.0551443099975586

Epoch: 6| Step: 12
Training loss: 1.4739965200424194
Validation loss: 2.046095927556356

Epoch: 6| Step: 13
Training loss: 2.5422158241271973
Validation loss: 2.0537935892740884

Epoch: 109| Step: 0
Training loss: 2.153982162475586
Validation loss: 2.041599969069163

Epoch: 6| Step: 1
Training loss: 1.8365817070007324
Validation loss: 2.032307724157969

Epoch: 6| Step: 2
Training loss: 2.5281214714050293
Validation loss: 2.0343758265177407

Epoch: 6| Step: 3
Training loss: 1.8429169654846191
Validation loss: 2.0332905848821006

Epoch: 6| Step: 4
Training loss: 2.4267144203186035
Validation loss: 2.0288661122322083

Epoch: 6| Step: 5
Training loss: 2.3617382049560547
Validation loss: 2.031420191129049

Epoch: 6| Step: 6
Training loss: 2.070488452911377
Validation loss: 2.0211751659711203

Epoch: 6| Step: 7
Training loss: 2.4913997650146484
Validation loss: 2.0280320048332214

Epoch: 6| Step: 8
Training loss: 1.6766126155853271
Validation loss: 2.0240753094355264

Epoch: 6| Step: 9
Training loss: 1.4934284687042236
Validation loss: 2.024908939997355

Epoch: 6| Step: 10
Training loss: 2.2412943840026855
Validation loss: 2.035867989063263

Epoch: 6| Step: 11
Training loss: 2.5810985565185547
Validation loss: 2.036343197027842

Epoch: 6| Step: 12
Training loss: 2.1482057571411133
Validation loss: 2.0329822301864624

Epoch: 6| Step: 13
Training loss: 1.6516764163970947
Validation loss: 2.0299008091290793

Epoch: 110| Step: 0
Training loss: 2.0114684104919434
Validation loss: 2.0347419579823813

Epoch: 6| Step: 1
Training loss: 1.7083909511566162
Validation loss: 2.053470770517985

Epoch: 6| Step: 2
Training loss: 1.6156606674194336
Validation loss: 2.0536710619926453

Epoch: 6| Step: 3
Training loss: 1.8917510509490967
Validation loss: 2.0551353295644126

Epoch: 6| Step: 4
Training loss: 2.603848934173584
Validation loss: 2.0635703802108765

Epoch: 6| Step: 5
Training loss: 1.990875244140625
Validation loss: 2.0534900029500327

Epoch: 6| Step: 6
Training loss: 2.4086732864379883
Validation loss: 2.058257520198822

Epoch: 6| Step: 7
Training loss: 1.9689295291900635
Validation loss: 2.04964687426885

Epoch: 6| Step: 8
Training loss: 2.5667777061462402
Validation loss: 2.0495785673459372

Epoch: 6| Step: 9
Training loss: 2.0294151306152344
Validation loss: 2.029480596383413

Epoch: 6| Step: 10
Training loss: 1.8493425846099854
Validation loss: 2.015347500642141

Epoch: 6| Step: 11
Training loss: 2.0299580097198486
Validation loss: 2.0197621981302896

Epoch: 6| Step: 12
Training loss: 2.3585104942321777
Validation loss: 2.0286723971366882

Epoch: 6| Step: 13
Training loss: 2.403000831604004
Validation loss: 2.010767916838328

Epoch: 111| Step: 0
Training loss: 2.3443236351013184
Validation loss: 2.0253214836120605

Epoch: 6| Step: 1
Training loss: 1.9546773433685303
Validation loss: 2.0165280302365622

Epoch: 6| Step: 2
Training loss: 2.2103476524353027
Validation loss: 2.019645094871521

Epoch: 6| Step: 3
Training loss: 2.3998918533325195
Validation loss: 2.015168388684591

Epoch: 6| Step: 4
Training loss: 1.9331119060516357
Validation loss: 2.0210132400194802

Epoch: 6| Step: 5
Training loss: 2.1419901847839355
Validation loss: 2.0090071757634482

Epoch: 6| Step: 6
Training loss: 2.2017109394073486
Validation loss: 2.0162815054257712

Epoch: 6| Step: 7
Training loss: 2.305753707885742
Validation loss: 2.01059220234553

Epoch: 6| Step: 8
Training loss: 2.403787612915039
Validation loss: 2.0153409838676453

Epoch: 6| Step: 9
Training loss: 2.1646180152893066
Validation loss: 2.0144548614819846

Epoch: 6| Step: 10
Training loss: 1.8973811864852905
Validation loss: 2.010475198427836

Epoch: 6| Step: 11
Training loss: 1.8076823949813843
Validation loss: 2.00661563873291

Epoch: 6| Step: 12
Training loss: 2.0332422256469727
Validation loss: 2.0117138028144836

Epoch: 6| Step: 13
Training loss: 2.0561046600341797
Validation loss: 2.007125675678253

Epoch: 112| Step: 0
Training loss: 1.99614417552948
Validation loss: 2.0099809567133584

Epoch: 6| Step: 1
Training loss: 2.3241610527038574
Validation loss: 2.0100587407747903

Epoch: 6| Step: 2
Training loss: 1.7719991207122803
Validation loss: 2.0135332147280374

Epoch: 6| Step: 3
Training loss: 2.0269038677215576
Validation loss: 2.0242322285970054

Epoch: 6| Step: 4
Training loss: 2.311837673187256
Validation loss: 2.0330835779507956

Epoch: 6| Step: 5
Training loss: 2.0418567657470703
Validation loss: 2.04598202308019

Epoch: 6| Step: 6
Training loss: 1.387261986732483
Validation loss: 2.0452393094698587

Epoch: 6| Step: 7
Training loss: 1.9976953268051147
Validation loss: 2.049799601236979

Epoch: 6| Step: 8
Training loss: 2.4765679836273193
Validation loss: 2.0542240937550864

Epoch: 6| Step: 9
Training loss: 2.9303016662597656
Validation loss: 2.0458333094914756

Epoch: 6| Step: 10
Training loss: 2.1990742683410645
Validation loss: 2.0394334197044373

Epoch: 6| Step: 11
Training loss: 2.3434786796569824
Validation loss: 2.0289769371350608

Epoch: 6| Step: 12
Training loss: 2.049224853515625
Validation loss: 2.017243981361389

Epoch: 6| Step: 13
Training loss: 1.8781299591064453
Validation loss: 2.017949958642324

Epoch: 113| Step: 0
Training loss: 2.2609951496124268
Validation loss: 2.023569166660309

Epoch: 6| Step: 1
Training loss: 2.2856550216674805
Validation loss: 2.0197631319363913

Epoch: 6| Step: 2
Training loss: 2.443990707397461
Validation loss: 2.030620892842611

Epoch: 6| Step: 3
Training loss: 1.863183617591858
Validation loss: 2.0313777327537537

Epoch: 6| Step: 4
Training loss: 1.2490876913070679
Validation loss: 2.0319988330205283

Epoch: 6| Step: 5
Training loss: 2.0415396690368652
Validation loss: 2.031238834063212

Epoch: 6| Step: 6
Training loss: 2.218557834625244
Validation loss: 2.0307069619496665

Epoch: 6| Step: 7
Training loss: 1.9931310415267944
Validation loss: 2.035551687081655

Epoch: 6| Step: 8
Training loss: 2.619203567504883
Validation loss: 2.027315616607666

Epoch: 6| Step: 9
Training loss: 2.287458896636963
Validation loss: 2.0223845640818277

Epoch: 6| Step: 10
Training loss: 2.299609661102295
Validation loss: 2.02900097767512

Epoch: 6| Step: 11
Training loss: 1.4854521751403809
Validation loss: 2.0151239037513733

Epoch: 6| Step: 12
Training loss: 2.2240822315216064
Validation loss: 2.0236207644144693

Epoch: 6| Step: 13
Training loss: 2.596487045288086
Validation loss: 2.0199962059656777

Epoch: 114| Step: 0
Training loss: 2.434446334838867
Validation loss: 2.0309510032335916

Epoch: 6| Step: 1
Training loss: 2.5748395919799805
Validation loss: 2.037909130255381

Epoch: 6| Step: 2
Training loss: 2.3470892906188965
Validation loss: 2.044188459714254

Epoch: 6| Step: 3
Training loss: 2.3849456310272217
Validation loss: 2.038078526655833

Epoch: 6| Step: 4
Training loss: 1.3587716817855835
Validation loss: 2.0418253938357034

Epoch: 6| Step: 5
Training loss: 1.7476465702056885
Validation loss: 2.032805542151133

Epoch: 6| Step: 6
Training loss: 2.076423406600952
Validation loss: 2.047216455141703

Epoch: 6| Step: 7
Training loss: 2.0978946685791016
Validation loss: 2.043582856655121

Epoch: 6| Step: 8
Training loss: 1.30653715133667
Validation loss: 2.051425337791443

Epoch: 6| Step: 9
Training loss: 2.0585272312164307
Validation loss: 2.0561675230662027

Epoch: 6| Step: 10
Training loss: 2.1296472549438477
Validation loss: 2.041502912839254

Epoch: 6| Step: 11
Training loss: 2.001842975616455
Validation loss: 2.051678737004598

Epoch: 6| Step: 12
Training loss: 2.4546027183532715
Validation loss: 2.0237381855646768

Epoch: 6| Step: 13
Training loss: 2.5661213397979736
Validation loss: 2.0143360694249473

Epoch: 115| Step: 0
Training loss: 2.7717936038970947
Validation loss: 2.0170478423436484

Epoch: 6| Step: 1
Training loss: 1.8235275745391846
Validation loss: 2.012786547342936

Epoch: 6| Step: 2
Training loss: 2.696566343307495
Validation loss: 2.0246365865071616

Epoch: 6| Step: 3
Training loss: 1.669577717781067
Validation loss: 2.02877684434255

Epoch: 6| Step: 4
Training loss: 2.484768867492676
Validation loss: 2.037993093331655

Epoch: 6| Step: 5
Training loss: 2.089956521987915
Validation loss: 2.038313706715902

Epoch: 6| Step: 6
Training loss: 1.9169707298278809
Validation loss: 2.03691703081131

Epoch: 6| Step: 7
Training loss: 2.159791946411133
Validation loss: 2.043445110321045

Epoch: 6| Step: 8
Training loss: 2.8023014068603516
Validation loss: 2.0413655638694763

Epoch: 6| Step: 9
Training loss: 2.6615397930145264
Validation loss: 2.042643884817759

Epoch: 6| Step: 10
Training loss: 1.684504747390747
Validation loss: 2.0481534401575723

Epoch: 6| Step: 11
Training loss: 1.8575897216796875
Validation loss: 2.0454870661099753

Epoch: 6| Step: 12
Training loss: 2.035294532775879
Validation loss: 2.04315839211146

Epoch: 6| Step: 13
Training loss: 1.6739611625671387
Validation loss: 2.0370952486991882

Epoch: 116| Step: 0
Training loss: 2.1973602771759033
Validation loss: 2.026384969552358

Epoch: 6| Step: 1
Training loss: 1.9282176494598389
Validation loss: 2.0273495515187583

Epoch: 6| Step: 2
Training loss: 1.5529557466506958
Validation loss: 2.0089832743008933

Epoch: 6| Step: 3
Training loss: 2.2206599712371826
Validation loss: 2.007745862007141

Epoch: 6| Step: 4
Training loss: 2.0702602863311768
Validation loss: 2.004805306593577

Epoch: 6| Step: 5
Training loss: 2.3949193954467773
Validation loss: 2.009311060110728

Epoch: 6| Step: 6
Training loss: 2.233154296875
Validation loss: 2.007445275783539

Epoch: 6| Step: 7
Training loss: 2.195504903793335
Validation loss: 2.019532004992167

Epoch: 6| Step: 8
Training loss: 1.5838901996612549
Validation loss: 2.0237302780151367

Epoch: 6| Step: 9
Training loss: 1.835750937461853
Validation loss: 2.0455586115519204

Epoch: 6| Step: 10
Training loss: 2.7999186515808105
Validation loss: 2.057184418042501

Epoch: 6| Step: 11
Training loss: 2.4236655235290527
Validation loss: 2.06281570593516

Epoch: 6| Step: 12
Training loss: 2.279292106628418
Validation loss: 2.06216033299764

Epoch: 6| Step: 13
Training loss: 2.1558661460876465
Validation loss: 2.054081439971924

Epoch: 117| Step: 0
Training loss: 2.6823816299438477
Validation loss: 2.0446227391560874

Epoch: 6| Step: 1
Training loss: 2.1162972450256348
Validation loss: 2.039225975672404

Epoch: 6| Step: 2
Training loss: 2.2567951679229736
Validation loss: 2.0321343143781028

Epoch: 6| Step: 3
Training loss: 2.307072401046753
Validation loss: 2.0258777737617493

Epoch: 6| Step: 4
Training loss: 2.018545150756836
Validation loss: 2.0206030209859214

Epoch: 6| Step: 5
Training loss: 1.7456817626953125
Validation loss: 2.0150094628334045

Epoch: 6| Step: 6
Training loss: 2.5790505409240723
Validation loss: 2.026629706223806

Epoch: 6| Step: 7
Training loss: 2.2214772701263428
Validation loss: 2.0186360279719033

Epoch: 6| Step: 8
Training loss: 1.8152239322662354
Validation loss: 2.0172424912452698

Epoch: 6| Step: 9
Training loss: 1.3522080183029175
Validation loss: 2.0136711994806924

Epoch: 6| Step: 10
Training loss: 2.5577187538146973
Validation loss: 2.009490172068278

Epoch: 6| Step: 11
Training loss: 2.2562761306762695
Validation loss: 2.0242845018704734

Epoch: 6| Step: 12
Training loss: 1.6101689338684082
Validation loss: 2.0245121916135154

Epoch: 6| Step: 13
Training loss: 1.9409881830215454
Validation loss: 2.0297372142473855

Epoch: 118| Step: 0
Training loss: 1.8874677419662476
Validation loss: 2.027619163195292

Epoch: 6| Step: 1
Training loss: 2.4917263984680176
Validation loss: 2.031623661518097

Epoch: 6| Step: 2
Training loss: 2.20160174369812
Validation loss: 2.0472543636957803

Epoch: 6| Step: 3
Training loss: 2.248382568359375
Validation loss: 2.044530510902405

Epoch: 6| Step: 4
Training loss: 2.0025365352630615
Validation loss: 2.047410269578298

Epoch: 6| Step: 5
Training loss: 1.8168381452560425
Validation loss: 2.0485717256863913

Epoch: 6| Step: 6
Training loss: 2.0992603302001953
Validation loss: 2.0394833087921143

Epoch: 6| Step: 7
Training loss: 1.7997219562530518
Validation loss: 2.0291810433069863

Epoch: 6| Step: 8
Training loss: 1.843780517578125
Validation loss: 2.0255847771962485

Epoch: 6| Step: 9
Training loss: 2.4648098945617676
Validation loss: 2.0255109667778015

Epoch: 6| Step: 10
Training loss: 1.753513216972351
Validation loss: 2.0236896276474

Epoch: 6| Step: 11
Training loss: 3.2523791790008545
Validation loss: 2.037918269634247

Epoch: 6| Step: 12
Training loss: 1.1848976612091064
Validation loss: 2.0304690400759378

Epoch: 6| Step: 13
Training loss: 1.9430588483810425
Validation loss: 2.0329753955205283

Epoch: 119| Step: 0
Training loss: 2.5309576988220215
Validation loss: 2.05561093489329

Epoch: 6| Step: 1
Training loss: 2.3702566623687744
Validation loss: 2.035162329673767

Epoch: 6| Step: 2
Training loss: 2.0195369720458984
Validation loss: 2.045639753341675

Epoch: 6| Step: 3
Training loss: 1.869913101196289
Validation loss: 2.0532169342041016

Epoch: 6| Step: 4
Training loss: 2.199035167694092
Validation loss: 2.037720203399658

Epoch: 6| Step: 5
Training loss: 1.9954032897949219
Validation loss: 2.0436301628748574

Epoch: 6| Step: 6
Training loss: 2.801131248474121
Validation loss: 2.0389678478240967

Epoch: 6| Step: 7
Training loss: 1.735666036605835
Validation loss: 2.0451535979906716

Epoch: 6| Step: 8
Training loss: 1.4262058734893799
Validation loss: 2.0391503175099692

Epoch: 6| Step: 9
Training loss: 1.9594919681549072
Validation loss: 2.0368337829907737

Epoch: 6| Step: 10
Training loss: 2.0803565979003906
Validation loss: 2.035739262898763

Epoch: 6| Step: 11
Training loss: 2.0142059326171875
Validation loss: 2.0404595732688904

Epoch: 6| Step: 12
Training loss: 2.0596866607666016
Validation loss: 2.0373316605885825

Epoch: 6| Step: 13
Training loss: 1.9002948999404907
Validation loss: 2.038350999355316

Epoch: 120| Step: 0
Training loss: 1.5918514728546143
Validation loss: 2.0404673417409263

Epoch: 6| Step: 1
Training loss: 2.43253231048584
Validation loss: 2.0356394052505493

Epoch: 6| Step: 2
Training loss: 2.4499664306640625
Validation loss: 2.0367202162742615

Epoch: 6| Step: 3
Training loss: 2.1149399280548096
Validation loss: 2.0340956846872964

Epoch: 6| Step: 4
Training loss: 1.5468405485153198
Validation loss: 2.0286380449930825

Epoch: 6| Step: 5
Training loss: 1.998416781425476
Validation loss: 2.039826214313507

Epoch: 6| Step: 6
Training loss: 2.3733930587768555
Validation loss: 2.030736565589905

Epoch: 6| Step: 7
Training loss: 1.7763477563858032
Validation loss: 2.0405569473902383

Epoch: 6| Step: 8
Training loss: 1.8042409420013428
Validation loss: 2.04090823729833

Epoch: 6| Step: 9
Training loss: 1.9504668712615967
Validation loss: 2.031866411368052

Epoch: 6| Step: 10
Training loss: 2.060375213623047
Validation loss: 2.0335710048675537

Epoch: 6| Step: 11
Training loss: 1.9599870443344116
Validation loss: 2.0411206086476645

Epoch: 6| Step: 12
Training loss: 2.5035171508789062
Validation loss: 2.033421834309896

Epoch: 6| Step: 13
Training loss: 2.230071544647217
Validation loss: 2.042016784350077

Epoch: 121| Step: 0
Training loss: 1.9941895008087158
Validation loss: 2.0418413082758584

Epoch: 6| Step: 1
Training loss: 1.833194375038147
Validation loss: 2.0380776723225913

Epoch: 6| Step: 2
Training loss: 1.658202886581421
Validation loss: 2.0491923491160073

Epoch: 6| Step: 3
Training loss: 1.948859691619873
Validation loss: 2.0447438756624856

Epoch: 6| Step: 4
Training loss: 2.087541341781616
Validation loss: 2.040577491124471

Epoch: 6| Step: 5
Training loss: 3.0276646614074707
Validation loss: 2.052723546822866

Epoch: 6| Step: 6
Training loss: 1.437417984008789
Validation loss: 2.04240091641744

Epoch: 6| Step: 7
Training loss: 2.183908224105835
Validation loss: 2.038057486216227

Epoch: 6| Step: 8
Training loss: 1.5155562162399292
Validation loss: 2.0332805116971335

Epoch: 6| Step: 9
Training loss: 2.370844602584839
Validation loss: 2.041034678618113

Epoch: 6| Step: 10
Training loss: 1.923957109451294
Validation loss: 2.0414686600367227

Epoch: 6| Step: 11
Training loss: 2.492175579071045
Validation loss: 2.039449373881022

Epoch: 6| Step: 12
Training loss: 2.6336796283721924
Validation loss: 2.0518364111582437

Epoch: 6| Step: 13
Training loss: 1.8717812299728394
Validation loss: 2.036112626393636

Epoch: 122| Step: 0
Training loss: 2.6756744384765625
Validation loss: 2.0415728290875754

Epoch: 6| Step: 1
Training loss: 2.0909788608551025
Validation loss: 2.0435060262680054

Epoch: 6| Step: 2
Training loss: 1.3847064971923828
Validation loss: 2.0431050459543862

Epoch: 6| Step: 3
Training loss: 1.4977233409881592
Validation loss: 2.041393280029297

Epoch: 6| Step: 4
Training loss: 2.3008828163146973
Validation loss: 2.0415180325508118

Epoch: 6| Step: 5
Training loss: 2.13409423828125
Validation loss: 2.0397639075915017

Epoch: 6| Step: 6
Training loss: 1.8744754791259766
Validation loss: 2.0361322363217673

Epoch: 6| Step: 7
Training loss: 2.4092278480529785
Validation loss: 2.0410467982292175

Epoch: 6| Step: 8
Training loss: 2.655013084411621
Validation loss: 2.0417479872703552

Epoch: 6| Step: 9
Training loss: 1.7322124242782593
Validation loss: 2.028744618097941

Epoch: 6| Step: 10
Training loss: 2.5990304946899414
Validation loss: 2.0349416534105935

Epoch: 6| Step: 11
Training loss: 1.589605689048767
Validation loss: 2.0319114923477173

Epoch: 6| Step: 12
Training loss: 2.2669074535369873
Validation loss: 2.0255284110705056

Epoch: 6| Step: 13
Training loss: 1.492619514465332
Validation loss: 2.030842940012614

Epoch: 123| Step: 0
Training loss: 1.7649717330932617
Validation loss: 2.0318574706713357

Epoch: 6| Step: 1
Training loss: 2.47186279296875
Validation loss: 2.0298590064048767

Epoch: 6| Step: 2
Training loss: 2.5359444618225098
Validation loss: 2.026312748591105

Epoch: 6| Step: 3
Training loss: 1.7289884090423584
Validation loss: 2.028150121370951

Epoch: 6| Step: 4
Training loss: 2.161292791366577
Validation loss: 2.016730546951294

Epoch: 6| Step: 5
Training loss: 1.91460382938385
Validation loss: 2.018673062324524

Epoch: 6| Step: 6
Training loss: 1.6415807008743286
Validation loss: 2.0261647701263428

Epoch: 6| Step: 7
Training loss: 2.673344612121582
Validation loss: 2.0185409585634866

Epoch: 6| Step: 8
Training loss: 2.238603115081787
Validation loss: 2.0334493120511374

Epoch: 6| Step: 9
Training loss: 1.8852007389068604
Validation loss: 2.0281677842140198

Epoch: 6| Step: 10
Training loss: 2.1085197925567627
Validation loss: 2.038798749446869

Epoch: 6| Step: 11
Training loss: 1.7816715240478516
Validation loss: 2.0348899960517883

Epoch: 6| Step: 12
Training loss: 1.8894959688186646
Validation loss: 2.0314851800600686

Epoch: 6| Step: 13
Training loss: 2.0996487140655518
Validation loss: 2.0365551710128784

Epoch: 124| Step: 0
Training loss: 2.276278018951416
Validation loss: 2.0345133940378823

Epoch: 6| Step: 1
Training loss: 1.4498958587646484
Validation loss: 2.0331095655759177

Epoch: 6| Step: 2
Training loss: 3.2079310417175293
Validation loss: 2.0354759097099304

Epoch: 6| Step: 3
Training loss: 2.0693178176879883
Validation loss: 2.032082219918569

Epoch: 6| Step: 4
Training loss: 2.584604263305664
Validation loss: 2.025079687436422

Epoch: 6| Step: 5
Training loss: 1.6422350406646729
Validation loss: 2.024127185344696

Epoch: 6| Step: 6
Training loss: 2.386093854904175
Validation loss: 2.0372772018114724

Epoch: 6| Step: 7
Training loss: 1.1562535762786865
Validation loss: 2.0337616999944053

Epoch: 6| Step: 8
Training loss: 1.8454082012176514
Validation loss: 2.0285691817601523

Epoch: 6| Step: 9
Training loss: 1.7613990306854248
Validation loss: 2.037526309490204

Epoch: 6| Step: 10
Training loss: 2.028045415878296
Validation loss: 2.0353925426801047

Epoch: 6| Step: 11
Training loss: 2.248201370239258
Validation loss: 2.028627574443817

Epoch: 6| Step: 12
Training loss: 1.927664041519165
Validation loss: 2.0383419394493103

Epoch: 6| Step: 13
Training loss: 2.745734691619873
Validation loss: 2.0330129663149514

Epoch: 125| Step: 0
Training loss: 1.6878947019577026
Validation loss: 2.0432482957839966

Epoch: 6| Step: 1
Training loss: 2.498960256576538
Validation loss: 2.043983002503713

Epoch: 6| Step: 2
Training loss: 2.0374269485473633
Validation loss: 2.0426774819691977

Epoch: 6| Step: 3
Training loss: 2.4828925132751465
Validation loss: 2.0372233589490256

Epoch: 6| Step: 4
Training loss: 2.484527587890625
Validation loss: 2.049684544404348

Epoch: 6| Step: 5
Training loss: 2.375664710998535
Validation loss: 2.0531683762868247

Epoch: 6| Step: 6
Training loss: 2.0545542240142822
Validation loss: 2.048714359601339

Epoch: 6| Step: 7
Training loss: 2.104665994644165
Validation loss: 2.0434215863545737

Epoch: 6| Step: 8
Training loss: 1.7689636945724487
Validation loss: 2.043287992477417

Epoch: 6| Step: 9
Training loss: 1.6883379220962524
Validation loss: 2.0497177243232727

Epoch: 6| Step: 10
Training loss: 2.4341554641723633
Validation loss: 2.0386667251586914

Epoch: 6| Step: 11
Training loss: 1.7133417129516602
Validation loss: 2.039707660675049

Epoch: 6| Step: 12
Training loss: 1.5778594017028809
Validation loss: 2.0366411805152893

Epoch: 6| Step: 13
Training loss: 2.2290093898773193
Validation loss: 2.0409125288327536

Epoch: 126| Step: 0
Training loss: 2.321145534515381
Validation loss: 2.0481335719426474

Epoch: 6| Step: 1
Training loss: 1.6896347999572754
Validation loss: 2.0453715125719705

Epoch: 6| Step: 2
Training loss: 2.083012580871582
Validation loss: 2.0535945892333984

Epoch: 6| Step: 3
Training loss: 1.6642792224884033
Validation loss: 2.0449538826942444

Epoch: 6| Step: 4
Training loss: 2.1814332008361816
Validation loss: 2.0349969466527305

Epoch: 6| Step: 5
Training loss: 2.1497440338134766
Validation loss: 2.02836412191391

Epoch: 6| Step: 6
Training loss: 2.0692596435546875
Validation loss: 2.0573261976242065

Epoch: 6| Step: 7
Training loss: 1.9311703443527222
Validation loss: 2.0420451362927756

Epoch: 6| Step: 8
Training loss: 2.4528985023498535
Validation loss: 2.046117146809896

Epoch: 6| Step: 9
Training loss: 2.2297041416168213
Validation loss: 2.0559110045433044

Epoch: 6| Step: 10
Training loss: 2.0254907608032227
Validation loss: 2.048633098602295

Epoch: 6| Step: 11
Training loss: 2.1653289794921875
Validation loss: 2.044536054134369

Epoch: 6| Step: 12
Training loss: 1.8482940196990967
Validation loss: 2.048257132371267

Epoch: 6| Step: 13
Training loss: 2.2103118896484375
Validation loss: 2.055327296257019

Epoch: 127| Step: 0
Training loss: 1.8829362392425537
Validation loss: 2.0451438426971436

Epoch: 6| Step: 1
Training loss: 1.9758245944976807
Validation loss: 2.0443646907806396

Epoch: 6| Step: 2
Training loss: 1.9531830549240112
Validation loss: 2.041653275489807

Epoch: 6| Step: 3
Training loss: 2.1555325984954834
Validation loss: 2.0500847498575845

Epoch: 6| Step: 4
Training loss: 2.1815476417541504
Validation loss: 2.0565481384595237

Epoch: 6| Step: 5
Training loss: 2.0096702575683594
Validation loss: 2.052553037802378

Epoch: 6| Step: 6
Training loss: 1.413458228111267
Validation loss: 2.064012070496877

Epoch: 6| Step: 7
Training loss: 1.9895470142364502
Validation loss: 2.0450485150019326

Epoch: 6| Step: 8
Training loss: 1.8093196153640747
Validation loss: 2.0511343677838645

Epoch: 6| Step: 9
Training loss: 2.604071617126465
Validation loss: 2.0332034826278687

Epoch: 6| Step: 10
Training loss: 2.0432493686676025
Validation loss: 2.0357859333356223

Epoch: 6| Step: 11
Training loss: 2.096130132675171
Validation loss: 2.019381066163381

Epoch: 6| Step: 12
Training loss: 2.6087584495544434
Validation loss: 2.0198699235916138

Epoch: 6| Step: 13
Training loss: 2.0568742752075195
Validation loss: 2.019757350285848

Epoch: 128| Step: 0
Training loss: 1.7831404209136963
Validation loss: 2.032186190287272

Epoch: 6| Step: 1
Training loss: 1.8835593461990356
Validation loss: 2.034738222757975

Epoch: 6| Step: 2
Training loss: 1.7012250423431396
Validation loss: 2.0337255597114563

Epoch: 6| Step: 3
Training loss: 2.1826138496398926
Validation loss: 2.027000347773234

Epoch: 6| Step: 4
Training loss: 2.248232841491699
Validation loss: 2.0324796636899314

Epoch: 6| Step: 5
Training loss: 2.3212597370147705
Validation loss: 2.0420307318369546

Epoch: 6| Step: 6
Training loss: 1.3559248447418213
Validation loss: 2.0320408741633096

Epoch: 6| Step: 7
Training loss: 1.8486582040786743
Validation loss: 2.045352836449941

Epoch: 6| Step: 8
Training loss: 2.7312653064727783
Validation loss: 2.035998582839966

Epoch: 6| Step: 9
Training loss: 2.27632212638855
Validation loss: 2.0431371529897056

Epoch: 6| Step: 10
Training loss: 1.9039621353149414
Validation loss: 2.0370143055915833

Epoch: 6| Step: 11
Training loss: 2.452752113342285
Validation loss: 2.045374115308126

Epoch: 6| Step: 12
Training loss: 1.8964486122131348
Validation loss: 2.0320642789204917

Epoch: 6| Step: 13
Training loss: 2.047210693359375
Validation loss: 2.04347958167394

Epoch: 129| Step: 0
Training loss: 1.7649831771850586
Validation loss: 2.0498077273368835

Epoch: 6| Step: 1
Training loss: 2.4728891849517822
Validation loss: 2.0640505154927573

Epoch: 6| Step: 2
Training loss: 2.5518288612365723
Validation loss: 2.0714690486590066

Epoch: 6| Step: 3
Training loss: 1.2983641624450684
Validation loss: 2.07317723830541

Epoch: 6| Step: 4
Training loss: 2.6422524452209473
Validation loss: 2.086933116118113

Epoch: 6| Step: 5
Training loss: 2.0426812171936035
Validation loss: 2.057011365890503

Epoch: 6| Step: 6
Training loss: 2.0533924102783203
Validation loss: 2.0442563692728677

Epoch: 6| Step: 7
Training loss: 2.5618672370910645
Validation loss: 2.021892229715983

Epoch: 6| Step: 8
Training loss: 1.6033751964569092
Validation loss: 2.020684599876404

Epoch: 6| Step: 9
Training loss: 2.7954182624816895
Validation loss: 2.0143115520477295

Epoch: 6| Step: 10
Training loss: 2.2688708305358887
Validation loss: 2.0229506691296897

Epoch: 6| Step: 11
Training loss: 1.5803439617156982
Validation loss: 2.012770930926005

Epoch: 6| Step: 12
Training loss: 1.8261888027191162
Validation loss: 2.0161003867785134

Epoch: 6| Step: 13
Training loss: 1.6695313453674316
Validation loss: 2.008731782436371

Epoch: 130| Step: 0
Training loss: 1.8525203466415405
Validation loss: 2.025879899660746

Epoch: 6| Step: 1
Training loss: 2.6604294776916504
Validation loss: 2.02460914850235

Epoch: 6| Step: 2
Training loss: 2.429370880126953
Validation loss: 2.026425321896871

Epoch: 6| Step: 3
Training loss: 2.180893898010254
Validation loss: 2.0246869325637817

Epoch: 6| Step: 4
Training loss: 2.141226291656494
Validation loss: 2.0320709943771362

Epoch: 6| Step: 5
Training loss: 2.1316277980804443
Validation loss: 2.046700179576874

Epoch: 6| Step: 6
Training loss: 2.077061891555786
Validation loss: 2.047584116458893

Epoch: 6| Step: 7
Training loss: 2.078714370727539
Validation loss: 2.064878841241201

Epoch: 6| Step: 8
Training loss: 2.2392666339874268
Validation loss: 2.0664729674657187

Epoch: 6| Step: 9
Training loss: 1.695570707321167
Validation loss: 2.0703488985697427

Epoch: 6| Step: 10
Training loss: 1.8167979717254639
Validation loss: 2.073004643122355

Epoch: 6| Step: 11
Training loss: 2.2544052600860596
Validation loss: 2.0731401244799295

Epoch: 6| Step: 12
Training loss: 1.8996193408966064
Validation loss: 2.058303475379944

Epoch: 6| Step: 13
Training loss: 1.6089262962341309
Validation loss: 2.0656718214352927

Epoch: 131| Step: 0
Training loss: 1.7044881582260132
Validation loss: 2.068560262521108

Epoch: 6| Step: 1
Training loss: 2.8946869373321533
Validation loss: 2.0514087478319802

Epoch: 6| Step: 2
Training loss: 2.0535030364990234
Validation loss: 2.042550524075826

Epoch: 6| Step: 3
Training loss: 1.827472448348999
Validation loss: 2.053771118323008

Epoch: 6| Step: 4
Training loss: 1.3782765865325928
Validation loss: 2.041938225428263

Epoch: 6| Step: 5
Training loss: 1.7825181484222412
Validation loss: 2.0434542496999106

Epoch: 6| Step: 6
Training loss: 1.8005971908569336
Validation loss: 2.03302131096522

Epoch: 6| Step: 7
Training loss: 2.4904367923736572
Validation loss: 2.0394080877304077

Epoch: 6| Step: 8
Training loss: 2.424633026123047
Validation loss: 2.0254233678181968

Epoch: 6| Step: 9
Training loss: 1.378306269645691
Validation loss: 2.0286187330881753

Epoch: 6| Step: 10
Training loss: 2.4485955238342285
Validation loss: 2.035118599732717

Epoch: 6| Step: 11
Training loss: 1.924697756767273
Validation loss: 2.02712873617808

Epoch: 6| Step: 12
Training loss: 2.5586791038513184
Validation loss: 2.0371615290641785

Epoch: 6| Step: 13
Training loss: 1.9825501441955566
Validation loss: 2.029188573360443

Epoch: 132| Step: 0
Training loss: 1.9923624992370605
Validation loss: 2.0316730737686157

Epoch: 6| Step: 1
Training loss: 2.6517534255981445
Validation loss: 2.034790555636088

Epoch: 6| Step: 2
Training loss: 2.0283031463623047
Validation loss: 2.031943619251251

Epoch: 6| Step: 3
Training loss: 1.7551655769348145
Validation loss: 2.037847181161245

Epoch: 6| Step: 4
Training loss: 2.384502410888672
Validation loss: 2.036753535270691

Epoch: 6| Step: 5
Training loss: 1.8473082780838013
Validation loss: 2.037753164768219

Epoch: 6| Step: 6
Training loss: 1.9694488048553467
Validation loss: 2.033576190471649

Epoch: 6| Step: 7
Training loss: 2.1385724544525146
Validation loss: 2.0282695492108664

Epoch: 6| Step: 8
Training loss: 1.5992519855499268
Validation loss: 2.0410561760266623

Epoch: 6| Step: 9
Training loss: 2.1475508213043213
Validation loss: 2.045320371786753

Epoch: 6| Step: 10
Training loss: 1.842793583869934
Validation loss: 2.0632877151171365

Epoch: 6| Step: 11
Training loss: 2.6019375324249268
Validation loss: 2.061225096384684

Epoch: 6| Step: 12
Training loss: 2.4218363761901855
Validation loss: 2.0548579891522727

Epoch: 6| Step: 13
Training loss: 1.9543921947479248
Validation loss: 2.04669984181722

Epoch: 133| Step: 0
Training loss: 3.103875160217285
Validation loss: 2.046960413455963

Epoch: 6| Step: 1
Training loss: 1.7758023738861084
Validation loss: 2.0248921513557434

Epoch: 6| Step: 2
Training loss: 1.7612417936325073
Validation loss: 2.0359940926233926

Epoch: 6| Step: 3
Training loss: 1.7430771589279175
Validation loss: 2.0325875679651895

Epoch: 6| Step: 4
Training loss: 2.3268682956695557
Validation loss: 2.0401143232981362

Epoch: 6| Step: 5
Training loss: 1.8246933221817017
Validation loss: 2.0318303306897483

Epoch: 6| Step: 6
Training loss: 1.2874417304992676
Validation loss: 2.032182196776072

Epoch: 6| Step: 7
Training loss: 1.7471225261688232
Validation loss: 2.045505940914154

Epoch: 6| Step: 8
Training loss: 2.31301212310791
Validation loss: 2.0486638943354287

Epoch: 6| Step: 9
Training loss: 2.279313564300537
Validation loss: 2.0424473683039346

Epoch: 6| Step: 10
Training loss: 1.1589927673339844
Validation loss: 2.0440770983695984

Epoch: 6| Step: 11
Training loss: 1.9337925910949707
Validation loss: 2.042060832182566

Epoch: 6| Step: 12
Training loss: 2.357301712036133
Validation loss: 2.050831059614817

Epoch: 6| Step: 13
Training loss: 2.9047422409057617
Validation loss: 2.0594825744628906

Epoch: 134| Step: 0
Training loss: 1.7069406509399414
Validation loss: 2.0516177217165628

Epoch: 6| Step: 1
Training loss: 1.8153812885284424
Validation loss: 2.064988613128662

Epoch: 6| Step: 2
Training loss: 1.6495146751403809
Validation loss: 2.056495110193888

Epoch: 6| Step: 3
Training loss: 2.0345160961151123
Validation loss: 2.052483320236206

Epoch: 6| Step: 4
Training loss: 2.1543397903442383
Validation loss: 2.0565375089645386

Epoch: 6| Step: 5
Training loss: 1.962493658065796
Validation loss: 2.0576425790786743

Epoch: 6| Step: 6
Training loss: 1.4356496334075928
Validation loss: 2.0450223286946616

Epoch: 6| Step: 7
Training loss: 2.142670154571533
Validation loss: 2.050250152746836

Epoch: 6| Step: 8
Training loss: 2.1107702255249023
Validation loss: 2.047555605570475

Epoch: 6| Step: 9
Training loss: 2.4348134994506836
Validation loss: 2.0463886658350625

Epoch: 6| Step: 10
Training loss: 2.3895742893218994
Validation loss: 2.0536649425824485

Epoch: 6| Step: 11
Training loss: 2.0050621032714844
Validation loss: 2.039916674296061

Epoch: 6| Step: 12
Training loss: 2.3275985717773438
Validation loss: 2.0501177112261453

Epoch: 6| Step: 13
Training loss: 2.18060302734375
Validation loss: 2.043221970399221

Epoch: 135| Step: 0
Training loss: 1.9333657026290894
Validation loss: 2.0503109296162925

Epoch: 6| Step: 1
Training loss: 2.1190249919891357
Validation loss: 2.043980836868286

Epoch: 6| Step: 2
Training loss: 2.1404483318328857
Validation loss: 2.0481920639673867

Epoch: 6| Step: 3
Training loss: 2.187044620513916
Validation loss: 2.0653637846310935

Epoch: 6| Step: 4
Training loss: 2.3223235607147217
Validation loss: 2.0599167148272195

Epoch: 6| Step: 5
Training loss: 1.9621250629425049
Validation loss: 2.0566516717274985

Epoch: 6| Step: 6
Training loss: 1.898893117904663
Validation loss: 2.0494717359542847

Epoch: 6| Step: 7
Training loss: 1.6930489540100098
Validation loss: 2.064154624938965

Epoch: 6| Step: 8
Training loss: 2.122483968734741
Validation loss: 2.0628990133603415

Epoch: 6| Step: 9
Training loss: 2.015981674194336
Validation loss: 2.0636096795399985

Epoch: 6| Step: 10
Training loss: 1.998826026916504
Validation loss: 2.0712145964304605

Epoch: 6| Step: 11
Training loss: 2.219796657562256
Validation loss: 2.0639572938283286

Epoch: 6| Step: 12
Training loss: 1.9236717224121094
Validation loss: 2.0552712082862854

Epoch: 6| Step: 13
Training loss: 1.9961761236190796
Validation loss: 2.0464544097582498

Epoch: 136| Step: 0
Training loss: 2.541403293609619
Validation loss: 2.057175954182943

Epoch: 6| Step: 1
Training loss: 2.8375966548919678
Validation loss: 2.059782783190409

Epoch: 6| Step: 2
Training loss: 1.6946799755096436
Validation loss: 2.0483368635177612

Epoch: 6| Step: 3
Training loss: 1.726505994796753
Validation loss: 2.050182600816091

Epoch: 6| Step: 4
Training loss: 1.6912422180175781
Validation loss: 2.051946481068929

Epoch: 6| Step: 5
Training loss: 2.4196114540100098
Validation loss: 2.053552766640981

Epoch: 6| Step: 6
Training loss: 1.836562991142273
Validation loss: 2.0471925338109336

Epoch: 6| Step: 7
Training loss: 1.7205274105072021
Validation loss: 2.0649850765864053

Epoch: 6| Step: 8
Training loss: 2.019688129425049
Validation loss: 2.0649869441986084

Epoch: 6| Step: 9
Training loss: 2.0495641231536865
Validation loss: 2.0732967058817544

Epoch: 6| Step: 10
Training loss: 1.9116839170455933
Validation loss: 2.0824790795644126

Epoch: 6| Step: 11
Training loss: 1.8572942018508911
Validation loss: 2.0718235969543457

Epoch: 6| Step: 12
Training loss: 2.0240602493286133
Validation loss: 2.074126442273458

Epoch: 6| Step: 13
Training loss: 2.1662511825561523
Validation loss: 2.073114017645518

Epoch: 137| Step: 0
Training loss: 1.9584027528762817
Validation loss: 2.058894455432892

Epoch: 6| Step: 1
Training loss: 1.4836680889129639
Validation loss: 2.066062311331431

Epoch: 6| Step: 2
Training loss: 2.095364570617676
Validation loss: 2.053443272908529

Epoch: 6| Step: 3
Training loss: 2.3782734870910645
Validation loss: 2.0524053970972695

Epoch: 6| Step: 4
Training loss: 2.011558771133423
Validation loss: 2.0447703202565513

Epoch: 6| Step: 5
Training loss: 1.3691821098327637
Validation loss: 2.0498912731806436

Epoch: 6| Step: 6
Training loss: 1.365964651107788
Validation loss: 2.0628950794537864

Epoch: 6| Step: 7
Training loss: 2.011955738067627
Validation loss: 2.0591241916020713

Epoch: 6| Step: 8
Training loss: 2.03208589553833
Validation loss: 2.0578924814860025

Epoch: 6| Step: 9
Training loss: 2.2500853538513184
Validation loss: 2.0669955809911094

Epoch: 6| Step: 10
Training loss: 1.7575515508651733
Validation loss: 2.072960356871287

Epoch: 6| Step: 11
Training loss: 2.7237448692321777
Validation loss: 2.078014890352885

Epoch: 6| Step: 12
Training loss: 2.8012397289276123
Validation loss: 2.0688685178756714

Epoch: 6| Step: 13
Training loss: 1.99092698097229
Validation loss: 2.077956517537435

Epoch: 138| Step: 0
Training loss: 2.061221122741699
Validation loss: 2.0751381516456604

Epoch: 6| Step: 1
Training loss: 1.6899325847625732
Validation loss: 2.0587412118911743

Epoch: 6| Step: 2
Training loss: 1.7287249565124512
Validation loss: 2.054526925086975

Epoch: 6| Step: 3
Training loss: 2.05656099319458
Validation loss: 2.0625762740770974

Epoch: 6| Step: 4
Training loss: 2.0078985691070557
Validation loss: 2.05430014928182

Epoch: 6| Step: 5
Training loss: 2.4799633026123047
Validation loss: 2.0447487433751426

Epoch: 6| Step: 6
Training loss: 1.7615082263946533
Validation loss: 2.062649051348368

Epoch: 6| Step: 7
Training loss: 1.8465070724487305
Validation loss: 2.058026969432831

Epoch: 6| Step: 8
Training loss: 2.55654239654541
Validation loss: 2.053498367468516

Epoch: 6| Step: 9
Training loss: 2.178135395050049
Validation loss: 2.072408616542816

Epoch: 6| Step: 10
Training loss: 1.8625425100326538
Validation loss: 2.053592344125112

Epoch: 6| Step: 11
Training loss: 2.7144217491149902
Validation loss: 2.0540147026379905

Epoch: 6| Step: 12
Training loss: 2.100339651107788
Validation loss: 2.0528660813967385

Epoch: 6| Step: 13
Training loss: 1.3728092908859253
Validation loss: 2.048835496107737

Epoch: 139| Step: 0
Training loss: 1.9676892757415771
Validation loss: 2.045551518599192

Epoch: 6| Step: 1
Training loss: 2.1202852725982666
Validation loss: 2.05063929160436

Epoch: 6| Step: 2
Training loss: 2.2547781467437744
Validation loss: 2.060554246107737

Epoch: 6| Step: 3
Training loss: 2.267791271209717
Validation loss: 2.0557064215342202

Epoch: 6| Step: 4
Training loss: 2.0343666076660156
Validation loss: 2.0601205229759216

Epoch: 6| Step: 5
Training loss: 2.510601043701172
Validation loss: 2.0626712838808694

Epoch: 6| Step: 6
Training loss: 1.1841776371002197
Validation loss: 2.062703231970469

Epoch: 6| Step: 7
Training loss: 2.076366662979126
Validation loss: 2.0711929202079773

Epoch: 6| Step: 8
Training loss: 1.6798765659332275
Validation loss: 2.080169916152954

Epoch: 6| Step: 9
Training loss: 1.9805020093917847
Validation loss: 2.0730329553286233

Epoch: 6| Step: 10
Training loss: 2.02761173248291
Validation loss: 2.074311455090841

Epoch: 6| Step: 11
Training loss: 2.021231174468994
Validation loss: 2.0776294271151223

Epoch: 6| Step: 12
Training loss: 1.8732166290283203
Validation loss: 2.0643226901690164

Epoch: 6| Step: 13
Training loss: 2.238835573196411
Validation loss: 2.0645137230555215

Epoch: 140| Step: 0
Training loss: 1.793592929840088
Validation loss: 2.0531630317370095

Epoch: 6| Step: 1
Training loss: 2.2547881603240967
Validation loss: 2.0484055280685425

Epoch: 6| Step: 2
Training loss: 2.114321231842041
Validation loss: 2.0534698963165283

Epoch: 6| Step: 3
Training loss: 2.2456765174865723
Validation loss: 2.0536802808443704

Epoch: 6| Step: 4
Training loss: 2.168149471282959
Validation loss: 2.0402178366978965

Epoch: 6| Step: 5
Training loss: 1.53770112991333
Validation loss: 2.0411445697148642

Epoch: 6| Step: 6
Training loss: 2.2137081623077393
Validation loss: 2.054489254951477

Epoch: 6| Step: 7
Training loss: 2.167149782180786
Validation loss: 2.047838886578878

Epoch: 6| Step: 8
Training loss: 2.391524076461792
Validation loss: 2.0721393624941506

Epoch: 6| Step: 9
Training loss: 2.1464219093322754
Validation loss: 2.064423759778341

Epoch: 6| Step: 10
Training loss: 1.9293665885925293
Validation loss: 2.076820651690165

Epoch: 6| Step: 11
Training loss: 1.5475223064422607
Validation loss: 2.0898043711980185

Epoch: 6| Step: 12
Training loss: 1.7516944408416748
Validation loss: 2.1021170616149902

Epoch: 6| Step: 13
Training loss: 1.7950446605682373
Validation loss: 2.0983497699101767

Epoch: 141| Step: 0
Training loss: 2.10672664642334
Validation loss: 2.1033950646718345

Epoch: 6| Step: 1
Training loss: 2.242274761199951
Validation loss: 2.086470603942871

Epoch: 6| Step: 2
Training loss: 1.706317663192749
Validation loss: 2.074362277984619

Epoch: 6| Step: 3
Training loss: 1.7195111513137817
Validation loss: 2.0836674769719443

Epoch: 6| Step: 4
Training loss: 2.1245546340942383
Validation loss: 2.0780643224716187

Epoch: 6| Step: 5
Training loss: 1.8298166990280151
Validation loss: 2.065178632736206

Epoch: 6| Step: 6
Training loss: 1.416804552078247
Validation loss: 2.07024218638738

Epoch: 6| Step: 7
Training loss: 2.4078543186187744
Validation loss: 2.0630101561546326

Epoch: 6| Step: 8
Training loss: 2.229048013687134
Validation loss: 2.079358537991842

Epoch: 6| Step: 9
Training loss: 2.39749813079834
Validation loss: 2.075051744778951

Epoch: 6| Step: 10
Training loss: 2.1754469871520996
Validation loss: 2.064829170703888

Epoch: 6| Step: 11
Training loss: 2.079493999481201
Validation loss: 2.075776000817617

Epoch: 6| Step: 12
Training loss: 1.642204999923706
Validation loss: 2.074250102043152

Epoch: 6| Step: 13
Training loss: 2.0491881370544434
Validation loss: 2.0687620043754578

Epoch: 142| Step: 0
Training loss: 2.146968126296997
Validation loss: 2.071813702583313

Epoch: 6| Step: 1
Training loss: 2.3231983184814453
Validation loss: 2.056978702545166

Epoch: 6| Step: 2
Training loss: 2.160179853439331
Validation loss: 2.0658161838849387

Epoch: 6| Step: 3
Training loss: 2.2478384971618652
Validation loss: 2.0650688211123147

Epoch: 6| Step: 4
Training loss: 2.249483108520508
Validation loss: 2.0479745268821716

Epoch: 6| Step: 5
Training loss: 1.9980192184448242
Validation loss: 2.0604698260625205

Epoch: 6| Step: 6
Training loss: 1.4301769733428955
Validation loss: 2.0524113972981772

Epoch: 6| Step: 7
Training loss: 1.7991389036178589
Validation loss: 2.0622262358665466

Epoch: 6| Step: 8
Training loss: 1.6650145053863525
Validation loss: 2.074588119983673

Epoch: 6| Step: 9
Training loss: 2.0466599464416504
Validation loss: 2.07560803492864

Epoch: 6| Step: 10
Training loss: 1.7545181512832642
Validation loss: 2.0800559322039285

Epoch: 6| Step: 11
Training loss: 2.1934759616851807
Validation loss: 2.0902430017789206

Epoch: 6| Step: 12
Training loss: 2.0345230102539062
Validation loss: 2.126326640446981

Epoch: 6| Step: 13
Training loss: 1.860837459564209
Validation loss: 2.148740768432617

Epoch: 143| Step: 0
Training loss: 1.7363789081573486
Validation loss: 2.1423669854799905

Epoch: 6| Step: 1
Training loss: 2.640242338180542
Validation loss: 2.14166522026062

Epoch: 6| Step: 2
Training loss: 2.035780668258667
Validation loss: 2.1378581523895264

Epoch: 6| Step: 3
Training loss: 1.658510684967041
Validation loss: 2.122467577457428

Epoch: 6| Step: 4
Training loss: 2.4411492347717285
Validation loss: 2.0958021680514016

Epoch: 6| Step: 5
Training loss: 1.492613434791565
Validation loss: 2.089232087135315

Epoch: 6| Step: 6
Training loss: 2.053954601287842
Validation loss: 2.070512135823568

Epoch: 6| Step: 7
Training loss: 1.8542615175247192
Validation loss: 2.065378427505493

Epoch: 6| Step: 8
Training loss: 1.803626298904419
Validation loss: 2.056260863939921

Epoch: 6| Step: 9
Training loss: 1.8794437646865845
Validation loss: 2.0496756037076316

Epoch: 6| Step: 10
Training loss: 1.7033624649047852
Validation loss: 2.0540247162183127

Epoch: 6| Step: 11
Training loss: 2.212080717086792
Validation loss: 2.0503985484441123

Epoch: 6| Step: 12
Training loss: 2.5328681468963623
Validation loss: 2.0479760567347207

Epoch: 6| Step: 13
Training loss: 2.4216644763946533
Validation loss: 2.0608361959457397

Epoch: 144| Step: 0
Training loss: 2.171576499938965
Validation loss: 2.0560091932614646

Epoch: 6| Step: 1
Training loss: 2.676776170730591
Validation loss: 2.0556854804356894

Epoch: 6| Step: 2
Training loss: 2.3980321884155273
Validation loss: 2.0490411122639975

Epoch: 6| Step: 3
Training loss: 1.3647499084472656
Validation loss: 2.0545584758122764

Epoch: 6| Step: 4
Training loss: 1.9646828174591064
Validation loss: 2.062036414941152

Epoch: 6| Step: 5
Training loss: 2.0291428565979004
Validation loss: 2.0611450473467507

Epoch: 6| Step: 6
Training loss: 2.00065279006958
Validation loss: 2.064280390739441

Epoch: 6| Step: 7
Training loss: 1.6212596893310547
Validation loss: 2.074229657649994

Epoch: 6| Step: 8
Training loss: 1.842649221420288
Validation loss: 2.095811585585276

Epoch: 6| Step: 9
Training loss: 1.74557363986969
Validation loss: 2.110528528690338

Epoch: 6| Step: 10
Training loss: 2.0136451721191406
Validation loss: 2.1193573673566184

Epoch: 6| Step: 11
Training loss: 2.7261343002319336
Validation loss: 2.1330820123354592

Epoch: 6| Step: 12
Training loss: 2.2282800674438477
Validation loss: 2.1192949612935386

Epoch: 6| Step: 13
Training loss: 1.7462074756622314
Validation loss: 2.078351398309072

Epoch: 145| Step: 0
Training loss: 1.610957384109497
Validation loss: 2.0572232007980347

Epoch: 6| Step: 1
Training loss: 2.0173041820526123
Validation loss: 2.070763031641642

Epoch: 6| Step: 2
Training loss: 1.6246142387390137
Validation loss: 2.061869184176127

Epoch: 6| Step: 3
Training loss: 2.1608986854553223
Validation loss: 2.068988005320231

Epoch: 6| Step: 4
Training loss: 2.048917770385742
Validation loss: 2.055738846460978

Epoch: 6| Step: 5
Training loss: 1.7849359512329102
Validation loss: 2.0490987300872803

Epoch: 6| Step: 6
Training loss: 1.631212592124939
Validation loss: 2.0457657178243003

Epoch: 6| Step: 7
Training loss: 2.34867262840271
Validation loss: 2.0513285597165427

Epoch: 6| Step: 8
Training loss: 1.6716378927230835
Validation loss: 2.04877499739329

Epoch: 6| Step: 9
Training loss: 2.6982760429382324
Validation loss: 2.05656898021698

Epoch: 6| Step: 10
Training loss: 2.1909241676330566
Validation loss: 2.0629694859186807

Epoch: 6| Step: 11
Training loss: 1.8395590782165527
Validation loss: 2.060758054256439

Epoch: 6| Step: 12
Training loss: 2.0545310974121094
Validation loss: 2.0728883345921836

Epoch: 6| Step: 13
Training loss: 2.365001916885376
Validation loss: 2.080524226029714

Epoch: 146| Step: 0
Training loss: 2.3582301139831543
Validation loss: 2.1052778561909995

Epoch: 6| Step: 1
Training loss: 2.6587038040161133
Validation loss: 2.146231174468994

Epoch: 6| Step: 2
Training loss: 2.578253746032715
Validation loss: 2.138655662536621

Epoch: 6| Step: 3
Training loss: 1.573211669921875
Validation loss: 2.1492716670036316

Epoch: 6| Step: 4
Training loss: 1.918647050857544
Validation loss: 2.1388230522473655

Epoch: 6| Step: 5
Training loss: 1.6722030639648438
Validation loss: 2.108835736910502

Epoch: 6| Step: 6
Training loss: 2.0826351642608643
Validation loss: 2.1088958779970803

Epoch: 6| Step: 7
Training loss: 1.6886663436889648
Validation loss: 2.086076021194458

Epoch: 6| Step: 8
Training loss: 1.8088176250457764
Validation loss: 2.0828614632288613

Epoch: 6| Step: 9
Training loss: 1.559476375579834
Validation loss: 2.0784798661867776

Epoch: 6| Step: 10
Training loss: 2.654463291168213
Validation loss: 2.0637863079706826

Epoch: 6| Step: 11
Training loss: 1.916791558265686
Validation loss: 2.051981727282206

Epoch: 6| Step: 12
Training loss: 2.3521978855133057
Validation loss: 2.0622715751330056

Epoch: 6| Step: 13
Training loss: 1.785563349723816
Validation loss: 2.0496262907981873

Epoch: 147| Step: 0
Training loss: 2.4679527282714844
Validation loss: 2.048238297303518

Epoch: 6| Step: 1
Training loss: 1.5344254970550537
Validation loss: 2.046593447526296

Epoch: 6| Step: 2
Training loss: 2.1553397178649902
Validation loss: 2.050933539867401

Epoch: 6| Step: 3
Training loss: 2.059730052947998
Validation loss: 2.0466394424438477

Epoch: 6| Step: 4
Training loss: 1.7297275066375732
Validation loss: 2.051123837629954

Epoch: 6| Step: 5
Training loss: 1.8706867694854736
Validation loss: 2.051617602507273

Epoch: 6| Step: 6
Training loss: 1.8043079376220703
Validation loss: 2.058109005292257

Epoch: 6| Step: 7
Training loss: 1.5522102117538452
Validation loss: 2.0678496758143106

Epoch: 6| Step: 8
Training loss: 2.337132215499878
Validation loss: 2.0678593516349792

Epoch: 6| Step: 9
Training loss: 2.39298939704895
Validation loss: 2.0935160915056863

Epoch: 6| Step: 10
Training loss: 2.1305718421936035
Validation loss: 2.07945716381073

Epoch: 6| Step: 11
Training loss: 2.4266929626464844
Validation loss: 2.10398797194163

Epoch: 6| Step: 12
Training loss: 2.0011730194091797
Validation loss: 2.1108777125676474

Epoch: 6| Step: 13
Training loss: 2.145157814025879
Validation loss: 2.1198029120763144

Epoch: 148| Step: 0
Training loss: 2.4083850383758545
Validation loss: 2.1154311299324036

Epoch: 6| Step: 1
Training loss: 1.8458908796310425
Validation loss: 2.0972504218419394

Epoch: 6| Step: 2
Training loss: 2.024876594543457
Validation loss: 2.11125777165095

Epoch: 6| Step: 3
Training loss: 2.0799484252929688
Validation loss: 2.0714887181917825

Epoch: 6| Step: 4
Training loss: 1.853529691696167
Validation loss: 2.066167096296946

Epoch: 6| Step: 5
Training loss: 2.0218143463134766
Validation loss: 2.0779234369595847

Epoch: 6| Step: 6
Training loss: 1.7044488191604614
Validation loss: 2.075776914755503

Epoch: 6| Step: 7
Training loss: 1.28395676612854
Validation loss: 2.0736097494761148

Epoch: 6| Step: 8
Training loss: 1.5764341354370117
Validation loss: 2.0714816451072693

Epoch: 6| Step: 9
Training loss: 2.1755895614624023
Validation loss: 2.0688188870747886

Epoch: 6| Step: 10
Training loss: 2.621108293533325
Validation loss: 2.0792659918467202

Epoch: 6| Step: 11
Training loss: 2.2916393280029297
Validation loss: 2.0718239744504294

Epoch: 6| Step: 12
Training loss: 1.636427402496338
Validation loss: 2.066612720489502

Epoch: 6| Step: 13
Training loss: 2.3768608570098877
Validation loss: 2.072330812613169

Epoch: 149| Step: 0
Training loss: 1.8668360710144043
Validation loss: 2.0725173354148865

Epoch: 6| Step: 1
Training loss: 1.6082054376602173
Validation loss: 2.0727075338363647

Epoch: 6| Step: 2
Training loss: 2.46805739402771
Validation loss: 2.0799179871877036

Epoch: 6| Step: 3
Training loss: 2.151897430419922
Validation loss: 2.06941686073939

Epoch: 6| Step: 4
Training loss: 1.7665116786956787
Validation loss: 2.0749173363049827

Epoch: 6| Step: 5
Training loss: 2.3672678470611572
Validation loss: 2.062453806400299

Epoch: 6| Step: 6
Training loss: 2.0349504947662354
Validation loss: 2.0626692374547324

Epoch: 6| Step: 7
Training loss: 2.0566978454589844
Validation loss: 2.0707298119862876

Epoch: 6| Step: 8
Training loss: 2.2330386638641357
Validation loss: 2.071087956428528

Epoch: 6| Step: 9
Training loss: 1.2974722385406494
Validation loss: 2.0816811323165894

Epoch: 6| Step: 10
Training loss: 1.8376550674438477
Validation loss: 2.0862980683644614

Epoch: 6| Step: 11
Training loss: 1.8186593055725098
Validation loss: 2.0940269231796265

Epoch: 6| Step: 12
Training loss: 2.391732931137085
Validation loss: 2.0952217976252236

Epoch: 6| Step: 13
Training loss: 2.0161666870117188
Validation loss: 2.119479537010193

Epoch: 150| Step: 0
Training loss: 1.6569985151290894
Validation loss: 2.124857803185781

Epoch: 6| Step: 1
Training loss: 1.7764230966567993
Validation loss: 2.11277308066686

Epoch: 6| Step: 2
Training loss: 1.859622836112976
Validation loss: 2.09333074092865

Epoch: 6| Step: 3
Training loss: 1.869706630706787
Validation loss: 2.0910393993059793

Epoch: 6| Step: 4
Training loss: 1.916123390197754
Validation loss: 2.0774924755096436

Epoch: 6| Step: 5
Training loss: 2.3851399421691895
Validation loss: 2.0656935771306357

Epoch: 6| Step: 6
Training loss: 1.7919706106185913
Validation loss: 2.06855845451355

Epoch: 6| Step: 7
Training loss: 1.971478819847107
Validation loss: 2.057047426700592

Epoch: 6| Step: 8
Training loss: 2.096996307373047
Validation loss: 2.0777154167493186

Epoch: 6| Step: 9
Training loss: 2.576338529586792
Validation loss: 2.072732090950012

Epoch: 6| Step: 10
Training loss: 2.404200553894043
Validation loss: 2.07522443930308

Epoch: 6| Step: 11
Training loss: 1.8940017223358154
Validation loss: 2.0668394764264426

Epoch: 6| Step: 12
Training loss: 2.1928982734680176
Validation loss: 2.074309766292572

Epoch: 6| Step: 13
Training loss: 1.6978518962860107
Validation loss: 2.075912435849508

Epoch: 151| Step: 0
Training loss: 1.9805171489715576
Validation loss: 2.080457111199697

Epoch: 6| Step: 1
Training loss: 1.6229701042175293
Validation loss: 2.089558800061544

Epoch: 6| Step: 2
Training loss: 1.7527523040771484
Validation loss: 2.07953151067098

Epoch: 6| Step: 3
Training loss: 1.9167485237121582
Validation loss: 2.0886115233103433

Epoch: 6| Step: 4
Training loss: 2.0857455730438232
Validation loss: 2.096993307272593

Epoch: 6| Step: 5
Training loss: 1.9176169633865356
Validation loss: 2.1171316107114158

Epoch: 6| Step: 6
Training loss: 1.9322737455368042
Validation loss: 2.1133671005566916

Epoch: 6| Step: 7
Training loss: 2.2046163082122803
Validation loss: 2.115195711453756

Epoch: 6| Step: 8
Training loss: 2.477233409881592
Validation loss: 2.1041329503059387

Epoch: 6| Step: 9
Training loss: 2.427842140197754
Validation loss: 2.102804680665334

Epoch: 6| Step: 10
Training loss: 1.9920849800109863
Validation loss: 2.1060919562975564

Epoch: 6| Step: 11
Training loss: 2.2656607627868652
Validation loss: 2.102595269680023

Epoch: 6| Step: 12
Training loss: 1.5416815280914307
Validation loss: 2.082017441590627

Epoch: 6| Step: 13
Training loss: 1.6294476985931396
Validation loss: 2.086247364679972

Epoch: 152| Step: 0
Training loss: 2.0975570678710938
Validation loss: 2.07306170463562

Epoch: 6| Step: 1
Training loss: 2.3501200675964355
Validation loss: 2.0775018334388733

Epoch: 6| Step: 2
Training loss: 2.260593891143799
Validation loss: 2.0652006467183432

Epoch: 6| Step: 3
Training loss: 1.9432041645050049
Validation loss: 2.0700515508651733

Epoch: 6| Step: 4
Training loss: 2.5208396911621094
Validation loss: 2.0630237658818564

Epoch: 6| Step: 5
Training loss: 2.0028786659240723
Validation loss: 2.0753486355145774

Epoch: 6| Step: 6
Training loss: 1.8893520832061768
Validation loss: 2.079382280508677

Epoch: 6| Step: 7
Training loss: 1.949711799621582
Validation loss: 2.0853864351908364

Epoch: 6| Step: 8
Training loss: 1.0530428886413574
Validation loss: 2.0856464505195618

Epoch: 6| Step: 9
Training loss: 2.187894105911255
Validation loss: 2.0879388650258384

Epoch: 6| Step: 10
Training loss: 1.494747281074524
Validation loss: 2.110769788424174

Epoch: 6| Step: 11
Training loss: 2.74112868309021
Validation loss: 2.1065892775853476

Epoch: 6| Step: 12
Training loss: 1.5800139904022217
Validation loss: 2.107298711935679

Epoch: 6| Step: 13
Training loss: 1.9266422986984253
Validation loss: 2.092892130215963

Epoch: 153| Step: 0
Training loss: 1.618584394454956
Validation loss: 2.0967470606168113

Epoch: 6| Step: 1
Training loss: 1.2946375608444214
Validation loss: 2.0850737492243447

Epoch: 6| Step: 2
Training loss: 2.292254686355591
Validation loss: 2.076734244823456

Epoch: 6| Step: 3
Training loss: 1.8413124084472656
Validation loss: 2.087319533030192

Epoch: 6| Step: 4
Training loss: 2.266920566558838
Validation loss: 2.0731579462687173

Epoch: 6| Step: 5
Training loss: 2.439291477203369
Validation loss: 2.0699561834335327

Epoch: 6| Step: 6
Training loss: 2.0707507133483887
Validation loss: 2.077342212200165

Epoch: 6| Step: 7
Training loss: 1.816791296005249
Validation loss: 2.073417067527771

Epoch: 6| Step: 8
Training loss: 2.352492332458496
Validation loss: 2.0844398538271585

Epoch: 6| Step: 9
Training loss: 2.6886308193206787
Validation loss: 2.0674393574396768

Epoch: 6| Step: 10
Training loss: 1.9253168106079102
Validation loss: 2.0774182081222534

Epoch: 6| Step: 11
Training loss: 1.961442232131958
Validation loss: 2.075201948483785

Epoch: 6| Step: 12
Training loss: 1.5054547786712646
Validation loss: 2.070278743902842

Epoch: 6| Step: 13
Training loss: 1.5612434148788452
Validation loss: 2.0814961393674216

Epoch: 154| Step: 0
Training loss: 2.5342049598693848
Validation loss: 2.084981838862101

Epoch: 6| Step: 1
Training loss: 1.9367382526397705
Validation loss: 2.074109752972921

Epoch: 6| Step: 2
Training loss: 2.4177064895629883
Validation loss: 2.0865718523661294

Epoch: 6| Step: 3
Training loss: 2.1585042476654053
Validation loss: 2.0929967761039734

Epoch: 6| Step: 4
Training loss: 2.566617488861084
Validation loss: 2.0863391757011414

Epoch: 6| Step: 5
Training loss: 1.6620005369186401
Validation loss: 2.0873557130495706

Epoch: 6| Step: 6
Training loss: 1.9608415365219116
Validation loss: 2.0908226370811462

Epoch: 6| Step: 7
Training loss: 1.9980919361114502
Validation loss: 2.0888691743214927

Epoch: 6| Step: 8
Training loss: 1.1442680358886719
Validation loss: 2.088079591592153

Epoch: 6| Step: 9
Training loss: 1.9997397661209106
Validation loss: 2.0980821450551352

Epoch: 6| Step: 10
Training loss: 2.134793996810913
Validation loss: 2.0897082090377808

Epoch: 6| Step: 11
Training loss: 2.1092607975006104
Validation loss: 2.099705775578817

Epoch: 6| Step: 12
Training loss: 1.7846323251724243
Validation loss: 2.1085540850957236

Epoch: 6| Step: 13
Training loss: 1.328437328338623
Validation loss: 2.1123790939648948

Epoch: 155| Step: 0
Training loss: 1.8634419441223145
Validation loss: 2.1083816289901733

Epoch: 6| Step: 1
Training loss: 1.44402277469635
Validation loss: 2.1229166189829507

Epoch: 6| Step: 2
Training loss: 2.7363409996032715
Validation loss: 2.112700343132019

Epoch: 6| Step: 3
Training loss: 2.076855182647705
Validation loss: 2.1058366894721985

Epoch: 6| Step: 4
Training loss: 2.323993682861328
Validation loss: 2.09485391775767

Epoch: 6| Step: 5
Training loss: 1.643768072128296
Validation loss: 2.097988247871399

Epoch: 6| Step: 6
Training loss: 1.8591537475585938
Validation loss: 2.080228348573049

Epoch: 6| Step: 7
Training loss: 1.828368902206421
Validation loss: 2.0736571550369263

Epoch: 6| Step: 8
Training loss: 1.8323768377304077
Validation loss: 2.0768299102783203

Epoch: 6| Step: 9
Training loss: 2.2409303188323975
Validation loss: 2.066502034664154

Epoch: 6| Step: 10
Training loss: 1.8243937492370605
Validation loss: 2.070047616958618

Epoch: 6| Step: 11
Training loss: 2.0817666053771973
Validation loss: 2.062973380088806

Epoch: 6| Step: 12
Training loss: 2.0081076622009277
Validation loss: 2.077053666114807

Epoch: 6| Step: 13
Training loss: 2.062938690185547
Validation loss: 2.0838407278060913

Epoch: 156| Step: 0
Training loss: 1.9654912948608398
Validation loss: 2.0836390058199563

Epoch: 6| Step: 1
Training loss: 1.991834282875061
Validation loss: 2.098948657512665

Epoch: 6| Step: 2
Training loss: 2.1540987491607666
Validation loss: 2.1068482597668967

Epoch: 6| Step: 3
Training loss: 1.6541544198989868
Validation loss: 2.092912952105204

Epoch: 6| Step: 4
Training loss: 1.5476200580596924
Validation loss: 2.0949582060178122

Epoch: 6| Step: 5
Training loss: 1.8354617357254028
Validation loss: 2.1026306549708047

Epoch: 6| Step: 6
Training loss: 1.8500230312347412
Validation loss: 2.1063162088394165

Epoch: 6| Step: 7
Training loss: 1.8245604038238525
Validation loss: 2.0990418990453086

Epoch: 6| Step: 8
Training loss: 2.105613946914673
Validation loss: 2.090423127015432

Epoch: 6| Step: 9
Training loss: 1.907198429107666
Validation loss: 2.067691445350647

Epoch: 6| Step: 10
Training loss: 2.241619348526001
Validation loss: 2.0747914910316467

Epoch: 6| Step: 11
Training loss: 2.065089225769043
Validation loss: 2.070649782816569

Epoch: 6| Step: 12
Training loss: 2.128765106201172
Validation loss: 2.077786147594452

Epoch: 6| Step: 13
Training loss: 2.2861099243164062
Validation loss: 2.063385864098867

Epoch: 157| Step: 0
Training loss: 1.7247157096862793
Validation loss: 2.064925193786621

Epoch: 6| Step: 1
Training loss: 2.24428129196167
Validation loss: 2.076178332169851

Epoch: 6| Step: 2
Training loss: 1.8820537328720093
Validation loss: 2.0852672855059304

Epoch: 6| Step: 3
Training loss: 1.6673239469528198
Validation loss: 2.0915671785672507

Epoch: 6| Step: 4
Training loss: 1.7758632898330688
Validation loss: 2.0915934840838113

Epoch: 6| Step: 5
Training loss: 1.7292317152023315
Validation loss: 2.1130065520604453

Epoch: 6| Step: 6
Training loss: 1.8185317516326904
Validation loss: 2.0942296783129373

Epoch: 6| Step: 7
Training loss: 2.0294957160949707
Validation loss: 2.0987605849901834

Epoch: 6| Step: 8
Training loss: 2.6989545822143555
Validation loss: 2.0865673224131265

Epoch: 6| Step: 9
Training loss: 1.5292686223983765
Validation loss: 2.0705235600471497

Epoch: 6| Step: 10
Training loss: 2.1049320697784424
Validation loss: 2.0836731791496277

Epoch: 6| Step: 11
Training loss: 1.6574676036834717
Validation loss: 2.0711551308631897

Epoch: 6| Step: 12
Training loss: 2.7136576175689697
Validation loss: 2.0706783533096313

Epoch: 6| Step: 13
Training loss: 2.1415560245513916
Validation loss: 2.0767149925231934

Epoch: 158| Step: 0
Training loss: 2.1380538940429688
Validation loss: 2.0728500485420227

Epoch: 6| Step: 1
Training loss: 2.1200242042541504
Validation loss: 2.063584327697754

Epoch: 6| Step: 2
Training loss: 2.2855167388916016
Validation loss: 2.0765074491500854

Epoch: 6| Step: 3
Training loss: 2.0401906967163086
Validation loss: 2.073277731736501

Epoch: 6| Step: 4
Training loss: 2.1603808403015137
Validation loss: 2.076310873031616

Epoch: 6| Step: 5
Training loss: 1.7628086805343628
Validation loss: 2.0678837498029075

Epoch: 6| Step: 6
Training loss: 2.034362554550171
Validation loss: 2.0781042178471885

Epoch: 6| Step: 7
Training loss: 2.2466542720794678
Validation loss: 2.079500595728556

Epoch: 6| Step: 8
Training loss: 1.4712079763412476
Validation loss: 2.0786689718564353

Epoch: 6| Step: 9
Training loss: 2.3735551834106445
Validation loss: 2.0861430764198303

Epoch: 6| Step: 10
Training loss: 1.7301342487335205
Validation loss: 2.086678663889567

Epoch: 6| Step: 11
Training loss: 2.076038360595703
Validation loss: 2.1040204564730325

Epoch: 6| Step: 12
Training loss: 1.6970605850219727
Validation loss: 2.110109885533651

Epoch: 6| Step: 13
Training loss: 1.5231428146362305
Validation loss: 2.0979408025741577

Epoch: 159| Step: 0
Training loss: 1.3361397981643677
Validation loss: 2.110694090525309

Epoch: 6| Step: 1
Training loss: 2.0615410804748535
Validation loss: 2.1104220350583396

Epoch: 6| Step: 2
Training loss: 1.8064582347869873
Validation loss: 2.137705445289612

Epoch: 6| Step: 3
Training loss: 1.8271009922027588
Validation loss: 2.1430675387382507

Epoch: 6| Step: 4
Training loss: 2.2160470485687256
Validation loss: 2.1401251554489136

Epoch: 6| Step: 5
Training loss: 1.561191439628601
Validation loss: 2.149252772331238

Epoch: 6| Step: 6
Training loss: 2.472856044769287
Validation loss: 2.150644620259603

Epoch: 6| Step: 7
Training loss: 2.3729708194732666
Validation loss: 2.126009782155355

Epoch: 6| Step: 8
Training loss: 2.1654062271118164
Validation loss: 2.1171718637148538

Epoch: 6| Step: 9
Training loss: 1.705016016960144
Validation loss: 2.0958768129348755

Epoch: 6| Step: 10
Training loss: 1.8322454690933228
Validation loss: 2.0881439248720803

Epoch: 6| Step: 11
Training loss: 2.18861722946167
Validation loss: 2.068043132623037

Epoch: 6| Step: 12
Training loss: 2.0134124755859375
Validation loss: 2.0634479324022927

Epoch: 6| Step: 13
Training loss: 2.206005096435547
Validation loss: 2.0683053731918335

Epoch: 160| Step: 0
Training loss: 1.8335767984390259
Validation loss: 2.063466489315033

Epoch: 6| Step: 1
Training loss: 2.5674517154693604
Validation loss: 2.069313168525696

Epoch: 6| Step: 2
Training loss: 1.6670353412628174
Validation loss: 2.0685081481933594

Epoch: 6| Step: 3
Training loss: 1.7176319360733032
Validation loss: 2.073223570982615

Epoch: 6| Step: 4
Training loss: 1.9412360191345215
Validation loss: 2.065932055314382

Epoch: 6| Step: 5
Training loss: 2.356410503387451
Validation loss: 2.0604864358901978

Epoch: 6| Step: 6
Training loss: 2.0242080688476562
Validation loss: 2.0597324768702188

Epoch: 6| Step: 7
Training loss: 2.511298179626465
Validation loss: 2.0650704900423684

Epoch: 6| Step: 8
Training loss: 1.7234808206558228
Validation loss: 2.0715678930282593

Epoch: 6| Step: 9
Training loss: 2.7085838317871094
Validation loss: 2.0592370430628457

Epoch: 6| Step: 10
Training loss: 1.3670034408569336
Validation loss: 2.075034240881602

Epoch: 6| Step: 11
Training loss: 1.9836777448654175
Validation loss: 2.0759134888648987

Epoch: 6| Step: 12
Training loss: 1.9522058963775635
Validation loss: 2.100698014100393

Epoch: 6| Step: 13
Training loss: 2.1455929279327393
Validation loss: 2.1083730856577554

Epoch: 161| Step: 0
Training loss: 2.285539150238037
Validation loss: 2.093460222085317

Epoch: 6| Step: 1
Training loss: 1.4278788566589355
Validation loss: 2.106451670328776

Epoch: 6| Step: 2
Training loss: 1.9975647926330566
Validation loss: 2.1062920689582825

Epoch: 6| Step: 3
Training loss: 2.1553239822387695
Validation loss: 2.1133174498875937

Epoch: 6| Step: 4
Training loss: 2.625891923904419
Validation loss: 2.0973581274350486

Epoch: 6| Step: 5
Training loss: 1.7336786985397339
Validation loss: 2.0903942386309304

Epoch: 6| Step: 6
Training loss: 2.3793516159057617
Validation loss: 2.0808346470197043

Epoch: 6| Step: 7
Training loss: 1.9507193565368652
Validation loss: 2.090600848197937

Epoch: 6| Step: 8
Training loss: 2.1648943424224854
Validation loss: 2.0824968616167703

Epoch: 6| Step: 9
Training loss: 1.7288322448730469
Validation loss: 2.063418130079905

Epoch: 6| Step: 10
Training loss: 1.6610840559005737
Validation loss: 2.0804460446039834

Epoch: 6| Step: 11
Training loss: 2.3254759311676025
Validation loss: 2.087118148803711

Epoch: 6| Step: 12
Training loss: 1.9662878513336182
Validation loss: 2.0959779024124146

Epoch: 6| Step: 13
Training loss: 1.7929327487945557
Validation loss: 2.0928810834884644

Epoch: 162| Step: 0
Training loss: 2.048732280731201
Validation loss: 2.114283243815104

Epoch: 6| Step: 1
Training loss: 2.6840102672576904
Validation loss: 2.097565313180288

Epoch: 6| Step: 2
Training loss: 1.9359594583511353
Validation loss: 2.1046804984410605

Epoch: 6| Step: 3
Training loss: 1.1216093301773071
Validation loss: 2.108853757381439

Epoch: 6| Step: 4
Training loss: 1.9862260818481445
Validation loss: 2.082176983356476

Epoch: 6| Step: 5
Training loss: 1.3898612260818481
Validation loss: 2.0903664429982505

Epoch: 6| Step: 6
Training loss: 2.2557597160339355
Validation loss: 2.077477296193441

Epoch: 6| Step: 7
Training loss: 2.313153028488159
Validation loss: 2.069440801938375

Epoch: 6| Step: 8
Training loss: 2.2895798683166504
Validation loss: 2.0763132770856223

Epoch: 6| Step: 9
Training loss: 2.0276224613189697
Validation loss: 2.0674219131469727

Epoch: 6| Step: 10
Training loss: 2.217287540435791
Validation loss: 2.072723865509033

Epoch: 6| Step: 11
Training loss: 2.628382921218872
Validation loss: 2.0824149449666343

Epoch: 6| Step: 12
Training loss: 2.1736297607421875
Validation loss: 2.0630285938580832

Epoch: 6| Step: 13
Training loss: 1.7086186408996582
Validation loss: 2.068705995877584

Epoch: 163| Step: 0
Training loss: 2.1083977222442627
Validation loss: 2.0831722219785056

Epoch: 6| Step: 1
Training loss: 1.9498770236968994
Validation loss: 2.0771386424700418

Epoch: 6| Step: 2
Training loss: 2.11846923828125
Validation loss: 2.100339194138845

Epoch: 6| Step: 3
Training loss: 2.6718931198120117
Validation loss: 2.1029747327168784

Epoch: 6| Step: 4
Training loss: 1.5958889722824097
Validation loss: 2.113418678442637

Epoch: 6| Step: 5
Training loss: 1.7135611772537231
Validation loss: 2.1088294188181558

Epoch: 6| Step: 6
Training loss: 1.795829176902771
Validation loss: 2.1149657169977822

Epoch: 6| Step: 7
Training loss: 1.9319669008255005
Validation loss: 2.134140451749166

Epoch: 6| Step: 8
Training loss: 1.8384687900543213
Validation loss: 2.109408438205719

Epoch: 6| Step: 9
Training loss: 1.6148343086242676
Validation loss: 2.1224393447240195

Epoch: 6| Step: 10
Training loss: 2.1827564239501953
Validation loss: 2.109607140223185

Epoch: 6| Step: 11
Training loss: 2.195171594619751
Validation loss: 2.1130749185880027

Epoch: 6| Step: 12
Training loss: 1.7105480432510376
Validation loss: 2.0931821862856546

Epoch: 6| Step: 13
Training loss: 2.360119104385376
Validation loss: 2.0829546451568604

Epoch: 164| Step: 0
Training loss: 2.057812213897705
Validation loss: 2.0805225570996604

Epoch: 6| Step: 1
Training loss: 2.117140293121338
Validation loss: 2.077209194501241

Epoch: 6| Step: 2
Training loss: 1.6284040212631226
Validation loss: 2.077335238456726

Epoch: 6| Step: 3
Training loss: 1.9526729583740234
Validation loss: 2.061901410420736

Epoch: 6| Step: 4
Training loss: 1.3950148820877075
Validation loss: 2.0739667812983194

Epoch: 6| Step: 5
Training loss: 1.9785652160644531
Validation loss: 2.078296105066935

Epoch: 6| Step: 6
Training loss: 1.9358973503112793
Validation loss: 2.0943907697995505

Epoch: 6| Step: 7
Training loss: 1.9893102645874023
Validation loss: 2.085917373498281

Epoch: 6| Step: 8
Training loss: 1.385535717010498
Validation loss: 2.096526563167572

Epoch: 6| Step: 9
Training loss: 2.8344614505767822
Validation loss: 2.093186696370443

Epoch: 6| Step: 10
Training loss: 1.9146841764450073
Validation loss: 2.0821456710497537

Epoch: 6| Step: 11
Training loss: 1.9872249364852905
Validation loss: 2.0882264773050943

Epoch: 6| Step: 12
Training loss: 2.240723133087158
Validation loss: 2.087573071320852

Epoch: 6| Step: 13
Training loss: 2.097139596939087
Validation loss: 2.074653208255768

Epoch: 165| Step: 0
Training loss: 1.609660267829895
Validation loss: 2.0891136129697165

Epoch: 6| Step: 1
Training loss: 1.742842435836792
Validation loss: 2.1092841625213623

Epoch: 6| Step: 2
Training loss: 1.4200327396392822
Validation loss: 2.0798057119051614

Epoch: 6| Step: 3
Training loss: 2.0140907764434814
Validation loss: 2.0774266521135965

Epoch: 6| Step: 4
Training loss: 2.359252691268921
Validation loss: 2.0798154870669046

Epoch: 6| Step: 5
Training loss: 2.162052869796753
Validation loss: 2.0868151585261026

Epoch: 6| Step: 6
Training loss: 2.1758322715759277
Validation loss: 2.079196512699127

Epoch: 6| Step: 7
Training loss: 1.8034298419952393
Validation loss: 2.0780157446861267

Epoch: 6| Step: 8
Training loss: 2.5023279190063477
Validation loss: 2.088866174221039

Epoch: 6| Step: 9
Training loss: 1.6347577571868896
Validation loss: 2.0934993624687195

Epoch: 6| Step: 10
Training loss: 1.4757215976715088
Validation loss: 2.0868966579437256

Epoch: 6| Step: 11
Training loss: 2.2451272010803223
Validation loss: 2.0967884063720703

Epoch: 6| Step: 12
Training loss: 1.8742681741714478
Validation loss: 2.0760854880015054

Epoch: 6| Step: 13
Training loss: 2.2153172492980957
Validation loss: 2.103741923967997

Epoch: 166| Step: 0
Training loss: 1.7999649047851562
Validation loss: 2.0942989190419516

Epoch: 6| Step: 1
Training loss: 1.8629341125488281
Validation loss: 2.081976075967153

Epoch: 6| Step: 2
Training loss: 2.3229660987854004
Validation loss: 2.080381751060486

Epoch: 6| Step: 3
Training loss: 2.304490089416504
Validation loss: 2.0979302128156028

Epoch: 6| Step: 4
Training loss: 2.249433994293213
Validation loss: 2.0873891711235046

Epoch: 6| Step: 5
Training loss: 1.7472913265228271
Validation loss: 2.0862576365470886

Epoch: 6| Step: 6
Training loss: 1.6895043849945068
Validation loss: 2.1075644890467324

Epoch: 6| Step: 7
Training loss: 2.1347544193267822
Validation loss: 2.108643372853597

Epoch: 6| Step: 8
Training loss: 1.8902111053466797
Validation loss: 2.092840393384298

Epoch: 6| Step: 9
Training loss: 1.8671132326126099
Validation loss: 2.1183666586875916

Epoch: 6| Step: 10
Training loss: 1.2895970344543457
Validation loss: 2.116769293944041

Epoch: 6| Step: 11
Training loss: 2.308285713195801
Validation loss: 2.1256962418556213

Epoch: 6| Step: 12
Training loss: 2.348906993865967
Validation loss: 2.131055474281311

Epoch: 6| Step: 13
Training loss: 1.3551476001739502
Validation loss: 2.1423587997754416

Epoch: 167| Step: 0
Training loss: 2.4072635173797607
Validation loss: 2.1303434570630393

Epoch: 6| Step: 1
Training loss: 1.9010663032531738
Validation loss: 2.1228595773379006

Epoch: 6| Step: 2
Training loss: 2.0606014728546143
Validation loss: 2.1197840770085654

Epoch: 6| Step: 3
Training loss: 1.6399686336517334
Validation loss: 2.100357929865519

Epoch: 6| Step: 4
Training loss: 2.2411129474639893
Validation loss: 2.0727192759513855

Epoch: 6| Step: 5
Training loss: 1.8407156467437744
Validation loss: 2.077330549558004

Epoch: 6| Step: 6
Training loss: 2.3429059982299805
Validation loss: 2.0683854818344116

Epoch: 6| Step: 7
Training loss: 1.4798256158828735
Validation loss: 2.0717087388038635

Epoch: 6| Step: 8
Training loss: 1.7680917978286743
Validation loss: 2.078027307987213

Epoch: 6| Step: 9
Training loss: 2.0341038703918457
Validation loss: 2.0712778568267822

Epoch: 6| Step: 10
Training loss: 2.0379536151885986
Validation loss: 2.0773452321688333

Epoch: 6| Step: 11
Training loss: 1.6992793083190918
Validation loss: 2.073871632417043

Epoch: 6| Step: 12
Training loss: 2.6595325469970703
Validation loss: 2.0769712924957275

Epoch: 6| Step: 13
Training loss: 2.4337925910949707
Validation loss: 2.084529399871826

Epoch: 168| Step: 0
Training loss: 2.1296911239624023
Validation loss: 2.0861210227012634

Epoch: 6| Step: 1
Training loss: 1.592980146408081
Validation loss: 2.0868710478146872

Epoch: 6| Step: 2
Training loss: 2.3963558673858643
Validation loss: 2.0996383825937905

Epoch: 6| Step: 3
Training loss: 2.5582377910614014
Validation loss: 2.0991573532422385

Epoch: 6| Step: 4
Training loss: 2.019331216812134
Validation loss: 2.132425526777903

Epoch: 6| Step: 5
Training loss: 2.5807926654815674
Validation loss: 2.1147649685541787

Epoch: 6| Step: 6
Training loss: 1.674511432647705
Validation loss: 2.1119322180747986

Epoch: 6| Step: 7
Training loss: 1.9171373844146729
Validation loss: 2.1061415870984397

Epoch: 6| Step: 8
Training loss: 1.5264164209365845
Validation loss: 2.085716942946116

Epoch: 6| Step: 9
Training loss: 2.1836118698120117
Validation loss: 2.107105235258738

Epoch: 6| Step: 10
Training loss: 1.5938732624053955
Validation loss: 2.1083970069885254

Epoch: 6| Step: 11
Training loss: 2.2286882400512695
Validation loss: 2.0897816022237143

Epoch: 6| Step: 12
Training loss: 1.4350006580352783
Validation loss: 2.0879918734232583

Epoch: 6| Step: 13
Training loss: 1.419670581817627
Validation loss: 2.1031026442845664

Epoch: 169| Step: 0
Training loss: 2.003480911254883
Validation loss: 2.099249243736267

Epoch: 6| Step: 1
Training loss: 1.9376909732818604
Validation loss: 2.0975038210550943

Epoch: 6| Step: 2
Training loss: 2.2742059230804443
Validation loss: 2.099776009718577

Epoch: 6| Step: 3
Training loss: 1.5176626443862915
Validation loss: 2.1032166481018066

Epoch: 6| Step: 4
Training loss: 1.3619083166122437
Validation loss: 2.094303826491038

Epoch: 6| Step: 5
Training loss: 1.8700741529464722
Validation loss: 2.091388384501139

Epoch: 6| Step: 6
Training loss: 1.8188786506652832
Validation loss: 2.093300461769104

Epoch: 6| Step: 7
Training loss: 2.002514600753784
Validation loss: 2.0862399538358054

Epoch: 6| Step: 8
Training loss: 2.008873224258423
Validation loss: 2.0974353154500327

Epoch: 6| Step: 9
Training loss: 1.5183970928192139
Validation loss: 2.0969780683517456

Epoch: 6| Step: 10
Training loss: 1.8554129600524902
Validation loss: 2.087809602419535

Epoch: 6| Step: 11
Training loss: 2.59627103805542
Validation loss: 2.101652363936106

Epoch: 6| Step: 12
Training loss: 2.1303882598876953
Validation loss: 2.083765168984731

Epoch: 6| Step: 13
Training loss: 2.1395883560180664
Validation loss: 2.0877588589986167

Epoch: 170| Step: 0
Training loss: 2.015547275543213
Validation loss: 2.0937039057413735

Epoch: 6| Step: 1
Training loss: 2.0243148803710938
Validation loss: 2.1020418405532837

Epoch: 6| Step: 2
Training loss: 1.9030369520187378
Validation loss: 2.1040836572647095

Epoch: 6| Step: 3
Training loss: 2.1720409393310547
Validation loss: 2.1098098158836365

Epoch: 6| Step: 4
Training loss: 1.46700918674469
Validation loss: 2.12509814898173

Epoch: 6| Step: 5
Training loss: 1.9371941089630127
Validation loss: 2.1267165541648865

Epoch: 6| Step: 6
Training loss: 1.7451144456863403
Validation loss: 2.1160595218340554

Epoch: 6| Step: 7
Training loss: 1.6115527153015137
Validation loss: 2.102103054523468

Epoch: 6| Step: 8
Training loss: 2.1656463146209717
Validation loss: 2.1038884123166404

Epoch: 6| Step: 9
Training loss: 2.347100257873535
Validation loss: 2.109870115915934

Epoch: 6| Step: 10
Training loss: 2.057343006134033
Validation loss: 2.103121757507324

Epoch: 6| Step: 11
Training loss: 2.0976874828338623
Validation loss: 2.097046176592509

Epoch: 6| Step: 12
Training loss: 2.3450751304626465
Validation loss: 2.0980226596196494

Epoch: 6| Step: 13
Training loss: 1.3337234258651733
Validation loss: 2.095019519329071

Epoch: 171| Step: 0
Training loss: 1.8942160606384277
Validation loss: 2.0979551474253335

Epoch: 6| Step: 1
Training loss: 2.149775981903076
Validation loss: 2.096510092417399

Epoch: 6| Step: 2
Training loss: 2.5107338428497314
Validation loss: 2.10499115784963

Epoch: 6| Step: 3
Training loss: 1.7248268127441406
Validation loss: 2.102165182431539

Epoch: 6| Step: 4
Training loss: 1.4112249612808228
Validation loss: 2.0997243920962014

Epoch: 6| Step: 5
Training loss: 1.9882632493972778
Validation loss: 2.09677791595459

Epoch: 6| Step: 6
Training loss: 2.819793224334717
Validation loss: 2.136782924334208

Epoch: 6| Step: 7
Training loss: 1.8089416027069092
Validation loss: 2.1284353931744895

Epoch: 6| Step: 8
Training loss: 2.4724111557006836
Validation loss: 2.133080244064331

Epoch: 6| Step: 9
Training loss: 1.5170727968215942
Validation loss: 2.1175150275230408

Epoch: 6| Step: 10
Training loss: 1.7770206928253174
Validation loss: 2.1074865460395813

Epoch: 6| Step: 11
Training loss: 1.7637635469436646
Validation loss: 2.0960442423820496

Epoch: 6| Step: 12
Training loss: 1.9044698476791382
Validation loss: 2.1105986833572388

Epoch: 6| Step: 13
Training loss: 1.5277854204177856
Validation loss: 2.0859124859174094

Epoch: 172| Step: 0
Training loss: 1.4352452754974365
Validation loss: 2.0945398012797036

Epoch: 6| Step: 1
Training loss: 1.857710361480713
Validation loss: 2.108937621116638

Epoch: 6| Step: 2
Training loss: 2.81807804107666
Validation loss: 2.0970668395360312

Epoch: 6| Step: 3
Training loss: 1.8713388442993164
Validation loss: 2.106774866580963

Epoch: 6| Step: 4
Training loss: 2.0100879669189453
Validation loss: 2.112613578637441

Epoch: 6| Step: 5
Training loss: 1.8498203754425049
Validation loss: 2.1199573079744973

Epoch: 6| Step: 6
Training loss: 2.5791265964508057
Validation loss: 2.1097596089045205

Epoch: 6| Step: 7
Training loss: 1.2268450260162354
Validation loss: 2.112114210923513

Epoch: 6| Step: 8
Training loss: 2.487597942352295
Validation loss: 2.1183494528134665

Epoch: 6| Step: 9
Training loss: 2.0654330253601074
Validation loss: 2.1090527375539145

Epoch: 6| Step: 10
Training loss: 2.302701950073242
Validation loss: 2.117239534854889

Epoch: 6| Step: 11
Training loss: 1.3144500255584717
Validation loss: 2.121489485104879

Epoch: 6| Step: 12
Training loss: 1.3349113464355469
Validation loss: 2.1309671998023987

Epoch: 6| Step: 13
Training loss: 1.8896170854568481
Validation loss: 2.114629407723745

Epoch: 173| Step: 0
Training loss: 1.9686429500579834
Validation loss: 2.1044018069903054

Epoch: 6| Step: 1
Training loss: 1.2103803157806396
Validation loss: 2.104811191558838

Epoch: 6| Step: 2
Training loss: 1.7508009672164917
Validation loss: 2.094220757484436

Epoch: 6| Step: 3
Training loss: 1.63344144821167
Validation loss: 2.1194227933883667

Epoch: 6| Step: 4
Training loss: 1.9263204336166382
Validation loss: 2.1087010502815247

Epoch: 6| Step: 5
Training loss: 2.205364227294922
Validation loss: 2.0996643702189126

Epoch: 6| Step: 6
Training loss: 2.167933702468872
Validation loss: 2.107419192790985

Epoch: 6| Step: 7
Training loss: 2.027827262878418
Validation loss: 2.1075169444084167

Epoch: 6| Step: 8
Training loss: 1.6766905784606934
Validation loss: 2.099203189214071

Epoch: 6| Step: 9
Training loss: 1.9645506143569946
Validation loss: 2.109876573085785

Epoch: 6| Step: 10
Training loss: 1.5845301151275635
Validation loss: 2.110596855481466

Epoch: 6| Step: 11
Training loss: 2.4293618202209473
Validation loss: 2.0923288464546204

Epoch: 6| Step: 12
Training loss: 2.9550256729125977
Validation loss: 2.1140756408373513

Epoch: 6| Step: 13
Training loss: 1.447587490081787
Validation loss: 2.1091554164886475

Epoch: 174| Step: 0
Training loss: 2.297173023223877
Validation loss: 2.105685611565908

Epoch: 6| Step: 1
Training loss: 2.439117908477783
Validation loss: 2.108003854751587

Epoch: 6| Step: 2
Training loss: 1.6648285388946533
Validation loss: 2.091234028339386

Epoch: 6| Step: 3
Training loss: 2.4995670318603516
Validation loss: 2.0959871212641397

Epoch: 6| Step: 4
Training loss: 1.499067783355713
Validation loss: 2.1020676692326865

Epoch: 6| Step: 5
Training loss: 1.9131410121917725
Validation loss: 2.11583677927653

Epoch: 6| Step: 6
Training loss: 2.2413597106933594
Validation loss: 2.1099423368771872

Epoch: 6| Step: 7
Training loss: 2.0445213317871094
Validation loss: 2.1043126980463662

Epoch: 6| Step: 8
Training loss: 1.7299525737762451
Validation loss: 2.1136008898417153

Epoch: 6| Step: 9
Training loss: 1.8678042888641357
Validation loss: 2.111414829889933

Epoch: 6| Step: 10
Training loss: 1.308051586151123
Validation loss: 2.1049289107322693

Epoch: 6| Step: 11
Training loss: 1.4561171531677246
Validation loss: 2.1159090399742126

Epoch: 6| Step: 12
Training loss: 1.965047836303711
Validation loss: 2.1162936290105185

Epoch: 6| Step: 13
Training loss: 1.8653773069381714
Validation loss: 2.100383480389913

Epoch: 175| Step: 0
Training loss: 1.8319071531295776
Validation loss: 2.1172958811124167

Epoch: 6| Step: 1
Training loss: 2.07694673538208
Validation loss: 2.0995407104492188

Epoch: 6| Step: 2
Training loss: 1.7210159301757812
Validation loss: 2.113791346549988

Epoch: 6| Step: 3
Training loss: 1.8018522262573242
Validation loss: 2.101678450902303

Epoch: 6| Step: 4
Training loss: 2.347783327102661
Validation loss: 2.09673144419988

Epoch: 6| Step: 5
Training loss: 1.8036115169525146
Validation loss: 2.11934757232666

Epoch: 6| Step: 6
Training loss: 1.7431845664978027
Validation loss: 2.124281128247579

Epoch: 6| Step: 7
Training loss: 1.6460237503051758
Validation loss: 2.1192057728767395

Epoch: 6| Step: 8
Training loss: 2.2237019538879395
Validation loss: 2.138812839984894

Epoch: 6| Step: 9
Training loss: 2.11147403717041
Validation loss: 2.120091497898102

Epoch: 6| Step: 10
Training loss: 1.5345702171325684
Validation loss: 2.121689736843109

Epoch: 6| Step: 11
Training loss: 1.7841085195541382
Validation loss: 2.1230158607165017

Epoch: 6| Step: 12
Training loss: 2.2886857986450195
Validation loss: 2.0875491897265115

Epoch: 6| Step: 13
Training loss: 1.9972243309020996
Validation loss: 2.115454057852427

Epoch: 176| Step: 0
Training loss: 2.018216609954834
Validation loss: 2.1130110224088035

Epoch: 6| Step: 1
Training loss: 1.9144941568374634
Validation loss: 2.112572272618612

Epoch: 6| Step: 2
Training loss: 1.8984614610671997
Validation loss: 2.101348956425985

Epoch: 6| Step: 3
Training loss: 2.113095998764038
Validation loss: 2.0958996017773948

Epoch: 6| Step: 4
Training loss: 1.6171151399612427
Validation loss: 2.0798391302426658

Epoch: 6| Step: 5
Training loss: 2.2516822814941406
Validation loss: 2.09102471669515

Epoch: 6| Step: 6
Training loss: 1.9325884580612183
Validation loss: 2.081095894177755

Epoch: 6| Step: 7
Training loss: 1.7159197330474854
Validation loss: 2.084046185016632

Epoch: 6| Step: 8
Training loss: 1.4354579448699951
Validation loss: 2.0900802612304688

Epoch: 6| Step: 9
Training loss: 1.954064130783081
Validation loss: 2.106006383895874

Epoch: 6| Step: 10
Training loss: 1.7934634685516357
Validation loss: 2.108685572942098

Epoch: 6| Step: 11
Training loss: 2.067046642303467
Validation loss: 2.1122796734174094

Epoch: 6| Step: 12
Training loss: 2.203601837158203
Validation loss: 2.1047356128692627

Epoch: 6| Step: 13
Training loss: 1.9608328342437744
Validation loss: 2.1067203283309937

Epoch: 177| Step: 0
Training loss: 2.887409210205078
Validation loss: 2.1227760513623557

Epoch: 6| Step: 1
Training loss: 1.4107683897018433
Validation loss: 2.1105544169743857

Epoch: 6| Step: 2
Training loss: 1.9007898569107056
Validation loss: 2.1404189666112265

Epoch: 6| Step: 3
Training loss: 1.8529750108718872
Validation loss: 2.142124891281128

Epoch: 6| Step: 4
Training loss: 2.405759334564209
Validation loss: 2.1237438917160034

Epoch: 6| Step: 5
Training loss: 1.5581039190292358
Validation loss: 2.12010927995046

Epoch: 6| Step: 6
Training loss: 1.773496389389038
Validation loss: 2.112473448117574

Epoch: 6| Step: 7
Training loss: 1.9352266788482666
Validation loss: 2.1174635887145996

Epoch: 6| Step: 8
Training loss: 1.6065874099731445
Validation loss: 2.106742004553477

Epoch: 6| Step: 9
Training loss: 1.6171367168426514
Validation loss: 2.1057081619898477

Epoch: 6| Step: 10
Training loss: 1.6627705097198486
Validation loss: 2.1034427881240845

Epoch: 6| Step: 11
Training loss: 1.4681568145751953
Validation loss: 2.1028579473495483

Epoch: 6| Step: 12
Training loss: 2.0837504863739014
Validation loss: 2.103144387404124

Epoch: 6| Step: 13
Training loss: 2.434877872467041
Validation loss: 2.100960652033488

Epoch: 178| Step: 0
Training loss: 1.9187555313110352
Validation loss: 2.1092792749404907

Epoch: 6| Step: 1
Training loss: 1.8260698318481445
Validation loss: 2.102602024873098

Epoch: 6| Step: 2
Training loss: 1.7752357721328735
Validation loss: 2.120731790860494

Epoch: 6| Step: 3
Training loss: 1.904181957244873
Validation loss: 2.113070865472158

Epoch: 6| Step: 4
Training loss: 1.5626962184906006
Validation loss: 2.1188851396242776

Epoch: 6| Step: 5
Training loss: 2.281883478164673
Validation loss: 2.10589861869812

Epoch: 6| Step: 6
Training loss: 1.6598454713821411
Validation loss: 2.111700634161631

Epoch: 6| Step: 7
Training loss: 1.9994782209396362
Validation loss: 2.11305437485377

Epoch: 6| Step: 8
Training loss: 1.7783832550048828
Validation loss: 2.125250518321991

Epoch: 6| Step: 9
Training loss: 1.8397133350372314
Validation loss: 2.127441942691803

Epoch: 6| Step: 10
Training loss: 1.9694576263427734
Validation loss: 2.130469779173533

Epoch: 6| Step: 11
Training loss: 1.6477127075195312
Validation loss: 2.1395519177118936

Epoch: 6| Step: 12
Training loss: 2.574869155883789
Validation loss: 2.1686232884724936

Epoch: 6| Step: 13
Training loss: 1.997255802154541
Validation loss: 2.168100376923879

Epoch: 179| Step: 0
Training loss: 2.092909336090088
Validation loss: 2.168718854586283

Epoch: 6| Step: 1
Training loss: 1.9559271335601807
Validation loss: 2.1538928548494973

Epoch: 6| Step: 2
Training loss: 1.8566724061965942
Validation loss: 2.1436620553334556

Epoch: 6| Step: 3
Training loss: 1.8034961223602295
Validation loss: 2.141924520333608

Epoch: 6| Step: 4
Training loss: 1.8024585247039795
Validation loss: 2.1226099332173667

Epoch: 6| Step: 5
Training loss: 2.0709049701690674
Validation loss: 2.1118016044298806

Epoch: 6| Step: 6
Training loss: 2.435227870941162
Validation loss: 2.118031919002533

Epoch: 6| Step: 7
Training loss: 2.168562412261963
Validation loss: 2.0978932976722717

Epoch: 6| Step: 8
Training loss: 2.015838146209717
Validation loss: 2.106556534767151

Epoch: 6| Step: 9
Training loss: 1.6348167657852173
Validation loss: 2.1022912859916687

Epoch: 6| Step: 10
Training loss: 2.053734302520752
Validation loss: 2.1061198314030967

Epoch: 6| Step: 11
Training loss: 1.5633677244186401
Validation loss: 2.105500817298889

Epoch: 6| Step: 12
Training loss: 1.310761570930481
Validation loss: 2.101730386416117

Epoch: 6| Step: 13
Training loss: 2.113570213317871
Validation loss: 2.1191085974375405

Epoch: 180| Step: 0
Training loss: 1.6036791801452637
Validation loss: 2.1127697030703225

Epoch: 6| Step: 1
Training loss: 1.6670022010803223
Validation loss: 2.1185162464777627

Epoch: 6| Step: 2
Training loss: 1.6602693796157837
Validation loss: 2.125959893067678

Epoch: 6| Step: 3
Training loss: 2.1093220710754395
Validation loss: 2.1192009250322976

Epoch: 6| Step: 4
Training loss: 1.9612231254577637
Validation loss: 2.1321279605229697

Epoch: 6| Step: 5
Training loss: 1.65946364402771
Validation loss: 2.1055986086527505

Epoch: 6| Step: 6
Training loss: 2.0281357765197754
Validation loss: 2.1115994254748025

Epoch: 6| Step: 7
Training loss: 1.6025182008743286
Validation loss: 2.0940852959950766

Epoch: 6| Step: 8
Training loss: 1.915269136428833
Validation loss: 2.1051724553108215

Epoch: 6| Step: 9
Training loss: 1.7167690992355347
Validation loss: 2.1042660077412925

Epoch: 6| Step: 10
Training loss: 1.7491824626922607
Validation loss: 2.1360881328582764

Epoch: 6| Step: 11
Training loss: 2.718691110610962
Validation loss: 2.1179563403129578

Epoch: 6| Step: 12
Training loss: 2.270350217819214
Validation loss: 2.113201399644216

Epoch: 6| Step: 13
Training loss: 2.285078763961792
Validation loss: 2.12621408700943

Epoch: 181| Step: 0
Training loss: 2.5874276161193848
Validation loss: 2.1041775345802307

Epoch: 6| Step: 1
Training loss: 1.9830060005187988
Validation loss: 2.100689093271891

Epoch: 6| Step: 2
Training loss: 2.016364812850952
Validation loss: 2.097050050894419

Epoch: 6| Step: 3
Training loss: 2.1081767082214355
Validation loss: 2.108854134877523

Epoch: 6| Step: 4
Training loss: 1.709395170211792
Validation loss: 2.0978243549664817

Epoch: 6| Step: 5
Training loss: 1.70278799533844
Validation loss: 2.1152511636416116

Epoch: 6| Step: 6
Training loss: 1.979069471359253
Validation loss: 2.10610165198644

Epoch: 6| Step: 7
Training loss: 1.5774970054626465
Validation loss: 2.1062356432278952

Epoch: 6| Step: 8
Training loss: 1.478008508682251
Validation loss: 2.115934213002523

Epoch: 6| Step: 9
Training loss: 2.328251838684082
Validation loss: 2.125182489554087

Epoch: 6| Step: 10
Training loss: 1.738695502281189
Validation loss: 2.140894889831543

Epoch: 6| Step: 11
Training loss: 1.800498127937317
Validation loss: 2.1380614638328552

Epoch: 6| Step: 12
Training loss: 1.7366373538970947
Validation loss: 2.140009641647339

Epoch: 6| Step: 13
Training loss: 2.2510719299316406
Validation loss: 2.1274489561716714

Epoch: 182| Step: 0
Training loss: 2.83030104637146
Validation loss: 2.129118104775747

Epoch: 6| Step: 1
Training loss: 2.040292978286743
Validation loss: 2.121757706006368

Epoch: 6| Step: 2
Training loss: 2.8316402435302734
Validation loss: 2.11765589316686

Epoch: 6| Step: 3
Training loss: 1.6394824981689453
Validation loss: 2.1031409899393716

Epoch: 6| Step: 4
Training loss: 1.5990644693374634
Validation loss: 2.0900115172068277

Epoch: 6| Step: 5
Training loss: 1.8961704969406128
Validation loss: 2.1114150484402976

Epoch: 6| Step: 6
Training loss: 1.8962352275848389
Validation loss: 2.0912845532099404

Epoch: 6| Step: 7
Training loss: 1.952502727508545
Validation loss: 2.108181377251943

Epoch: 6| Step: 8
Training loss: 1.8420302867889404
Validation loss: 2.107066293557485

Epoch: 6| Step: 9
Training loss: 1.5909169912338257
Validation loss: 2.1281455953915915

Epoch: 6| Step: 10
Training loss: 1.541471242904663
Validation loss: 2.124496340751648

Epoch: 6| Step: 11
Training loss: 1.213944673538208
Validation loss: 2.1181333462397256

Epoch: 6| Step: 12
Training loss: 1.4961557388305664
Validation loss: 2.1241151690483093

Epoch: 6| Step: 13
Training loss: 2.6028380393981934
Validation loss: 2.113982141017914

Epoch: 183| Step: 0
Training loss: 2.1736111640930176
Validation loss: 2.1059966882069907

Epoch: 6| Step: 1
Training loss: 1.4270803928375244
Validation loss: 2.10829226175944

Epoch: 6| Step: 2
Training loss: 2.1521835327148438
Validation loss: 2.1044433315594993

Epoch: 6| Step: 3
Training loss: 2.4063544273376465
Validation loss: 2.1161583264668784

Epoch: 6| Step: 4
Training loss: 1.598731279373169
Validation loss: 2.106774846712748

Epoch: 6| Step: 5
Training loss: 2.449197292327881
Validation loss: 2.1184794505437217

Epoch: 6| Step: 6
Training loss: 2.385410785675049
Validation loss: 2.1113597551981607

Epoch: 6| Step: 7
Training loss: 1.8880908489227295
Validation loss: 2.1165290673573813

Epoch: 6| Step: 8
Training loss: 1.4610987901687622
Validation loss: 2.1165600021680198

Epoch: 6| Step: 9
Training loss: 1.9380195140838623
Validation loss: 2.1241167783737183

Epoch: 6| Step: 10
Training loss: 1.095695972442627
Validation loss: 2.114055355389913

Epoch: 6| Step: 11
Training loss: 1.4216079711914062
Validation loss: 2.1109390457471213

Epoch: 6| Step: 12
Training loss: 2.0890607833862305
Validation loss: 2.1040674646695456

Epoch: 6| Step: 13
Training loss: 2.077841281890869
Validation loss: 2.115155498186747

Epoch: 184| Step: 0
Training loss: 2.255199909210205
Validation loss: 2.1077157656351724

Epoch: 6| Step: 1
Training loss: 2.036731719970703
Validation loss: 2.1317257285118103

Epoch: 6| Step: 2
Training loss: 1.6394107341766357
Validation loss: 2.134405036767324

Epoch: 6| Step: 3
Training loss: 1.90748131275177
Validation loss: 2.125651796658834

Epoch: 6| Step: 4
Training loss: 2.166839361190796
Validation loss: 2.1225008368492126

Epoch: 6| Step: 5
Training loss: 2.0502989292144775
Validation loss: 2.135162830352783

Epoch: 6| Step: 6
Training loss: 1.6694815158843994
Validation loss: 2.1240641872088113

Epoch: 6| Step: 7
Training loss: 1.8558135032653809
Validation loss: 2.1135666966438293

Epoch: 6| Step: 8
Training loss: 2.120920419692993
Validation loss: 2.115048428376516

Epoch: 6| Step: 9
Training loss: 1.7371819019317627
Validation loss: 2.112503230571747

Epoch: 6| Step: 10
Training loss: 1.5429067611694336
Validation loss: 2.122347414493561

Epoch: 6| Step: 11
Training loss: 1.314810872077942
Validation loss: 2.1288466254870095

Epoch: 6| Step: 12
Training loss: 2.047553539276123
Validation loss: 2.1034807761510215

Epoch: 6| Step: 13
Training loss: 2.189897298812866
Validation loss: 2.1155337492624917

Epoch: 185| Step: 0
Training loss: 2.068173885345459
Validation loss: 2.1244629422823587

Epoch: 6| Step: 1
Training loss: 1.3887176513671875
Validation loss: 2.1127156416575112

Epoch: 6| Step: 2
Training loss: 2.1002087593078613
Validation loss: 2.098626891771952

Epoch: 6| Step: 3
Training loss: 1.8122968673706055
Validation loss: 2.1166611115137735

Epoch: 6| Step: 4
Training loss: 1.7921745777130127
Validation loss: 2.1240070263544717

Epoch: 6| Step: 5
Training loss: 2.07962703704834
Validation loss: 2.1423699259757996

Epoch: 6| Step: 6
Training loss: 1.7513267993927002
Validation loss: 2.140599091847738

Epoch: 6| Step: 7
Training loss: 1.5717589855194092
Validation loss: 2.1456944743792215

Epoch: 6| Step: 8
Training loss: 2.014932155609131
Validation loss: 2.1486258506774902

Epoch: 6| Step: 9
Training loss: 2.659741163253784
Validation loss: 2.137618084748586

Epoch: 6| Step: 10
Training loss: 2.1834380626678467
Validation loss: 2.1366211970647178

Epoch: 6| Step: 11
Training loss: 2.3518898487091064
Validation loss: 2.141975998878479

Epoch: 6| Step: 12
Training loss: 1.608241081237793
Validation loss: 2.1276857058207193

Epoch: 6| Step: 13
Training loss: 1.3446598052978516
Validation loss: 2.1109730005264282

Epoch: 186| Step: 0
Training loss: 1.5458365678787231
Validation loss: 2.11628387371699

Epoch: 6| Step: 1
Training loss: 2.182734966278076
Validation loss: 2.1227020422617593

Epoch: 6| Step: 2
Training loss: 2.3979108333587646
Validation loss: 2.1098584731419883

Epoch: 6| Step: 3
Training loss: 1.6950594186782837
Validation loss: 2.1217583616574607

Epoch: 6| Step: 4
Training loss: 1.620597243309021
Validation loss: 2.1251697142918906

Epoch: 6| Step: 5
Training loss: 1.5606553554534912
Validation loss: 2.1390905578931174

Epoch: 6| Step: 6
Training loss: 2.0292227268218994
Validation loss: 2.1160769859949746

Epoch: 6| Step: 7
Training loss: 1.8191825151443481
Validation loss: 2.1167134046554565

Epoch: 6| Step: 8
Training loss: 2.2132225036621094
Validation loss: 2.1195552150408425

Epoch: 6| Step: 9
Training loss: 1.8417330980300903
Validation loss: 2.1209458311398826

Epoch: 6| Step: 10
Training loss: 1.6455925703048706
Validation loss: 2.1440542936325073

Epoch: 6| Step: 11
Training loss: 1.7609212398529053
Validation loss: 2.127832849820455

Epoch: 6| Step: 12
Training loss: 2.158916473388672
Validation loss: 2.129615823427836

Epoch: 6| Step: 13
Training loss: 1.9993709325790405
Validation loss: 2.1361942887306213

Epoch: 187| Step: 0
Training loss: 2.003988027572632
Validation loss: 2.1272741158803306

Epoch: 6| Step: 1
Training loss: 1.197914481163025
Validation loss: 2.14927872021993

Epoch: 6| Step: 2
Training loss: 1.4799456596374512
Validation loss: 2.1493465105692544

Epoch: 6| Step: 3
Training loss: 1.552915334701538
Validation loss: 2.147006034851074

Epoch: 6| Step: 4
Training loss: 1.8047027587890625
Validation loss: 2.1359689831733704

Epoch: 6| Step: 5
Training loss: 2.243570327758789
Validation loss: 2.125024398167928

Epoch: 6| Step: 6
Training loss: 2.715625047683716
Validation loss: 2.1352319916089377

Epoch: 6| Step: 7
Training loss: 2.704486846923828
Validation loss: 2.107397715250651

Epoch: 6| Step: 8
Training loss: 2.0802414417266846
Validation loss: 2.1183237632115683

Epoch: 6| Step: 9
Training loss: 1.7118628025054932
Validation loss: 2.126101811726888

Epoch: 6| Step: 10
Training loss: 2.187744140625
Validation loss: 2.142907738685608

Epoch: 6| Step: 11
Training loss: 2.000392198562622
Validation loss: 2.109090248743693

Epoch: 6| Step: 12
Training loss: 1.502233862876892
Validation loss: 2.1150855223337808

Epoch: 6| Step: 13
Training loss: 1.756422519683838
Validation loss: 2.1093148787816367

Epoch: 188| Step: 0
Training loss: 1.3901405334472656
Validation loss: 2.1071576873461404

Epoch: 6| Step: 1
Training loss: 1.9655532836914062
Validation loss: 2.0965322454770408

Epoch: 6| Step: 2
Training loss: 2.0165319442749023
Validation loss: 2.110250771045685

Epoch: 6| Step: 3
Training loss: 2.4374642372131348
Validation loss: 2.1089964310328164

Epoch: 6| Step: 4
Training loss: 2.021693229675293
Validation loss: 2.11178066333135

Epoch: 6| Step: 5
Training loss: 2.061861515045166
Validation loss: 2.124864339828491

Epoch: 6| Step: 6
Training loss: 1.9004185199737549
Validation loss: 2.1306050221125283

Epoch: 6| Step: 7
Training loss: 1.8588266372680664
Validation loss: 2.113782783349355

Epoch: 6| Step: 8
Training loss: 1.6524019241333008
Validation loss: 2.129976987838745

Epoch: 6| Step: 9
Training loss: 1.5018250942230225
Validation loss: 2.1393168369928994

Epoch: 6| Step: 10
Training loss: 1.9754102230072021
Validation loss: 2.1514044205347695

Epoch: 6| Step: 11
Training loss: 1.765775203704834
Validation loss: 2.1505141854286194

Epoch: 6| Step: 12
Training loss: 2.160963535308838
Validation loss: 2.152898907661438

Epoch: 6| Step: 13
Training loss: 2.316850423812866
Validation loss: 2.1645057002703347

Epoch: 189| Step: 0
Training loss: 2.1008756160736084
Validation loss: 2.142788589000702

Epoch: 6| Step: 1
Training loss: 2.351104497909546
Validation loss: 2.156737724939982

Epoch: 6| Step: 2
Training loss: 2.3000526428222656
Validation loss: 2.1239672899246216

Epoch: 6| Step: 3
Training loss: 1.5431828498840332
Validation loss: 2.1389384269714355

Epoch: 6| Step: 4
Training loss: 1.7499115467071533
Validation loss: 2.1284331480662027

Epoch: 6| Step: 5
Training loss: 1.6810669898986816
Validation loss: 2.140222152074178

Epoch: 6| Step: 6
Training loss: 1.7739287614822388
Validation loss: 2.12632683912913

Epoch: 6| Step: 7
Training loss: 1.9596651792526245
Validation loss: 2.1210742195447287

Epoch: 6| Step: 8
Training loss: 1.1454479694366455
Validation loss: 2.1301612655321756

Epoch: 6| Step: 9
Training loss: 1.288650393486023
Validation loss: 2.110517700513204

Epoch: 6| Step: 10
Training loss: 2.2896080017089844
Validation loss: 2.1169284184773765

Epoch: 6| Step: 11
Training loss: 2.2719593048095703
Validation loss: 2.1219170888264975

Epoch: 6| Step: 12
Training loss: 1.2688283920288086
Validation loss: 2.1289430260658264

Epoch: 6| Step: 13
Training loss: 2.660349130630493
Validation loss: 2.13699601093928

Epoch: 190| Step: 0
Training loss: 1.72275710105896
Validation loss: 2.1311834255854287

Epoch: 6| Step: 1
Training loss: 1.2397968769073486
Validation loss: 2.126683493455251

Epoch: 6| Step: 2
Training loss: 2.2379026412963867
Validation loss: 2.134478986263275

Epoch: 6| Step: 3
Training loss: 1.576096773147583
Validation loss: 2.134160856405894

Epoch: 6| Step: 4
Training loss: 2.0669212341308594
Validation loss: 2.1292222142219543

Epoch: 6| Step: 5
Training loss: 1.4225257635116577
Validation loss: 2.1472617189089456

Epoch: 6| Step: 6
Training loss: 1.5540034770965576
Validation loss: 2.1539998054504395

Epoch: 6| Step: 7
Training loss: 1.5149056911468506
Validation loss: 2.149835924307505

Epoch: 6| Step: 8
Training loss: 2.0378763675689697
Validation loss: 2.1584413051605225

Epoch: 6| Step: 9
Training loss: 2.266861915588379
Validation loss: 2.139395534992218

Epoch: 6| Step: 10
Training loss: 1.8387155532836914
Validation loss: 2.1239532629648843

Epoch: 6| Step: 11
Training loss: 1.6740386486053467
Validation loss: 2.128953536351522

Epoch: 6| Step: 12
Training loss: 2.671130418777466
Validation loss: 2.127102335294088

Epoch: 6| Step: 13
Training loss: 2.5183568000793457
Validation loss: 2.139680325984955

Epoch: 191| Step: 0
Training loss: 1.6215457916259766
Validation loss: 2.1198682387669883

Epoch: 6| Step: 1
Training loss: 1.761339545249939
Validation loss: 2.1338204741477966

Epoch: 6| Step: 2
Training loss: 2.302244186401367
Validation loss: 2.141981621583303

Epoch: 6| Step: 3
Training loss: 1.9602442979812622
Validation loss: 2.145900865395864

Epoch: 6| Step: 4
Training loss: 2.4226088523864746
Validation loss: 2.14192004998525

Epoch: 6| Step: 5
Training loss: 1.8895443677902222
Validation loss: 2.143736402193705

Epoch: 6| Step: 6
Training loss: 1.7801294326782227
Validation loss: 2.125842571258545

Epoch: 6| Step: 7
Training loss: 1.7401140928268433
Validation loss: 2.1382375160853067

Epoch: 6| Step: 8
Training loss: 1.7997368574142456
Validation loss: 2.1285803516705832

Epoch: 6| Step: 9
Training loss: 1.9971880912780762
Validation loss: 2.1205389499664307

Epoch: 6| Step: 10
Training loss: 1.5746490955352783
Validation loss: 2.126064340273539

Epoch: 6| Step: 11
Training loss: 2.2635903358459473
Validation loss: 2.122574269771576

Epoch: 6| Step: 12
Training loss: 1.8205801248550415
Validation loss: 2.1250835259755454

Epoch: 6| Step: 13
Training loss: 1.6295863389968872
Validation loss: 2.1159427165985107

Epoch: 192| Step: 0
Training loss: 2.1540207862854004
Validation loss: 2.130440413951874

Epoch: 6| Step: 1
Training loss: 1.761526346206665
Validation loss: 2.129312594731649

Epoch: 6| Step: 2
Training loss: 1.6549248695373535
Validation loss: 2.1510854959487915

Epoch: 6| Step: 3
Training loss: 2.2234714031219482
Validation loss: 2.159925162792206

Epoch: 6| Step: 4
Training loss: 1.652906894683838
Validation loss: 2.159186760584513

Epoch: 6| Step: 5
Training loss: 2.1678707599639893
Validation loss: 2.16357284784317

Epoch: 6| Step: 6
Training loss: 1.6925628185272217
Validation loss: 2.1616159280141196

Epoch: 6| Step: 7
Training loss: 1.6710032224655151
Validation loss: 2.1695712208747864

Epoch: 6| Step: 8
Training loss: 1.309753656387329
Validation loss: 2.163547853628794

Epoch: 6| Step: 9
Training loss: 2.400966167449951
Validation loss: 2.153676450252533

Epoch: 6| Step: 10
Training loss: 2.036630153656006
Validation loss: 2.154568155606588

Epoch: 6| Step: 11
Training loss: 2.179431915283203
Validation loss: 2.184389591217041

Epoch: 6| Step: 12
Training loss: 1.7377400398254395
Validation loss: 2.1823620001475015

Epoch: 6| Step: 13
Training loss: 1.909110426902771
Validation loss: 2.1826038559277854

Epoch: 193| Step: 0
Training loss: 2.5100715160369873
Validation loss: 2.1638682087262473

Epoch: 6| Step: 1
Training loss: 1.6652567386627197
Validation loss: 2.159341017405192

Epoch: 6| Step: 2
Training loss: 1.9058802127838135
Validation loss: 2.170280913511912

Epoch: 6| Step: 3
Training loss: 1.974146842956543
Validation loss: 2.162261446317037

Epoch: 6| Step: 4
Training loss: 1.71394944190979
Validation loss: 2.1586714585622153

Epoch: 6| Step: 5
Training loss: 2.041670322418213
Validation loss: 2.1485707561175027

Epoch: 6| Step: 6
Training loss: 2.358156681060791
Validation loss: 2.132025142510732

Epoch: 6| Step: 7
Training loss: 1.358982801437378
Validation loss: 2.1354774832725525

Epoch: 6| Step: 8
Training loss: 1.359442949295044
Validation loss: 2.1248931090037027

Epoch: 6| Step: 9
Training loss: 2.0317721366882324
Validation loss: 2.1328148245811462

Epoch: 6| Step: 10
Training loss: 1.916518211364746
Validation loss: 2.1294772227605185

Epoch: 6| Step: 11
Training loss: 1.8856308460235596
Validation loss: 2.1468650301297507

Epoch: 6| Step: 12
Training loss: 1.72287118434906
Validation loss: 2.144823412100474

Epoch: 6| Step: 13
Training loss: 1.9309258460998535
Validation loss: 2.145770172278086

Epoch: 194| Step: 0
Training loss: 1.3408514261245728
Validation loss: 2.1466208497683206

Epoch: 6| Step: 1
Training loss: 2.30387282371521
Validation loss: 2.1811159451802573

Epoch: 6| Step: 2
Training loss: 1.7390309572219849
Validation loss: 2.18440580368042

Epoch: 6| Step: 3
Training loss: 2.515925407409668
Validation loss: 2.169203241666158

Epoch: 6| Step: 4
Training loss: 2.1351215839385986
Validation loss: 2.1584612131118774

Epoch: 6| Step: 5
Training loss: 1.7623165845870972
Validation loss: 2.1594396432240806

Epoch: 6| Step: 6
Training loss: 2.317261219024658
Validation loss: 2.1555342276891074

Epoch: 6| Step: 7
Training loss: 1.6659729480743408
Validation loss: 2.158976395924886

Epoch: 6| Step: 8
Training loss: 2.0870511531829834
Validation loss: 2.1514043609301248

Epoch: 6| Step: 9
Training loss: 1.5478851795196533
Validation loss: 2.1355225841204324

Epoch: 6| Step: 10
Training loss: 1.8641221523284912
Validation loss: 2.1339951554934182

Epoch: 6| Step: 11
Training loss: 1.4568231105804443
Validation loss: 2.1450284123420715

Epoch: 6| Step: 12
Training loss: 2.2602410316467285
Validation loss: 2.1375664273897805

Epoch: 6| Step: 13
Training loss: 1.7252871990203857
Validation loss: 2.1290528575579324

Epoch: 195| Step: 0
Training loss: 1.5399819612503052
Validation loss: 2.1498992641766868

Epoch: 6| Step: 1
Training loss: 2.0649056434631348
Validation loss: 2.148147384325663

Epoch: 6| Step: 2
Training loss: 1.8605890274047852
Validation loss: 2.145163277784983

Epoch: 6| Step: 3
Training loss: 1.3096938133239746
Validation loss: 2.148785650730133

Epoch: 6| Step: 4
Training loss: 2.0690927505493164
Validation loss: 2.17400731643041

Epoch: 6| Step: 5
Training loss: 1.9792500734329224
Validation loss: 2.170499245325724

Epoch: 6| Step: 6
Training loss: 1.991836667060852
Validation loss: 2.1805717945098877

Epoch: 6| Step: 7
Training loss: 2.4141252040863037
Validation loss: 2.161794741948446

Epoch: 6| Step: 8
Training loss: 1.8805943727493286
Validation loss: 2.165804624557495

Epoch: 6| Step: 9
Training loss: 1.5920219421386719
Validation loss: 2.146876335144043

Epoch: 6| Step: 10
Training loss: 1.7300820350646973
Validation loss: 2.144593119621277

Epoch: 6| Step: 11
Training loss: 2.16685152053833
Validation loss: 2.1352942188580832

Epoch: 6| Step: 12
Training loss: 1.9118821620941162
Validation loss: 2.131495396296183

Epoch: 6| Step: 13
Training loss: 2.0032005310058594
Validation loss: 2.1426671544710794

Epoch: 196| Step: 0
Training loss: 1.4791624546051025
Validation loss: 2.1200761198997498

Epoch: 6| Step: 1
Training loss: 1.8234925270080566
Validation loss: 2.1414232651392617

Epoch: 6| Step: 2
Training loss: 2.2024502754211426
Validation loss: 2.128357787926992

Epoch: 6| Step: 3
Training loss: 2.1685571670532227
Validation loss: 2.144386967023214

Epoch: 6| Step: 4
Training loss: 1.7386831045150757
Validation loss: 2.1513407826423645

Epoch: 6| Step: 5
Training loss: 1.6841320991516113
Validation loss: 2.1475968956947327

Epoch: 6| Step: 6
Training loss: 2.0031471252441406
Validation loss: 2.1374887824058533

Epoch: 6| Step: 7
Training loss: 1.1393097639083862
Validation loss: 2.1354976892471313

Epoch: 6| Step: 8
Training loss: 2.143120288848877
Validation loss: 2.1330246329307556

Epoch: 6| Step: 9
Training loss: 1.5542341470718384
Validation loss: 2.123161276181539

Epoch: 6| Step: 10
Training loss: 1.9512507915496826
Validation loss: 2.1288381218910217

Epoch: 6| Step: 11
Training loss: 1.9939374923706055
Validation loss: 2.120778799057007

Epoch: 6| Step: 12
Training loss: 2.1100716590881348
Validation loss: 2.1380377809206643

Epoch: 6| Step: 13
Training loss: 2.3122401237487793
Validation loss: 2.1189237038294473

Epoch: 197| Step: 0
Training loss: 1.9484362602233887
Validation loss: 2.1234130263328552

Epoch: 6| Step: 1
Training loss: 1.9309086799621582
Validation loss: 2.1247542103131614

Epoch: 6| Step: 2
Training loss: 1.543715000152588
Validation loss: 2.128411332766215

Epoch: 6| Step: 3
Training loss: 1.6767393350601196
Validation loss: 2.127599775791168

Epoch: 6| Step: 4
Training loss: 2.0455830097198486
Validation loss: 2.1198734442392984

Epoch: 6| Step: 5
Training loss: 1.5568053722381592
Validation loss: 2.1084792613983154

Epoch: 6| Step: 6
Training loss: 2.2026844024658203
Validation loss: 2.1184512178103128

Epoch: 6| Step: 7
Training loss: 1.4734933376312256
Validation loss: 2.120934764544169

Epoch: 6| Step: 8
Training loss: 2.111572027206421
Validation loss: 2.1177898248036704

Epoch: 6| Step: 9
Training loss: 2.422262191772461
Validation loss: 2.1530985633532205

Epoch: 6| Step: 10
Training loss: 1.8437163829803467
Validation loss: 2.1604175766309104

Epoch: 6| Step: 11
Training loss: 2.1632180213928223
Validation loss: 2.1618759632110596

Epoch: 6| Step: 12
Training loss: 1.4747098684310913
Validation loss: 2.202538708845774

Epoch: 6| Step: 13
Training loss: 1.9586410522460938
Validation loss: 2.194914400577545

Epoch: 198| Step: 0
Training loss: 1.439233660697937
Validation loss: 2.185025215148926

Epoch: 6| Step: 1
Training loss: 2.093698024749756
Validation loss: 2.175068974494934

Epoch: 6| Step: 2
Training loss: 2.032588481903076
Validation loss: 2.1667429010073342

Epoch: 6| Step: 3
Training loss: 2.203723430633545
Validation loss: 2.1488002141316733

Epoch: 6| Step: 4
Training loss: 1.5423954725265503
Validation loss: 2.138352950414022

Epoch: 6| Step: 5
Training loss: 1.2689180374145508
Validation loss: 2.1411187052726746

Epoch: 6| Step: 6
Training loss: 2.205596923828125
Validation loss: 2.1505722800890603

Epoch: 6| Step: 7
Training loss: 1.5129919052124023
Validation loss: 2.127748131752014

Epoch: 6| Step: 8
Training loss: 1.7648063898086548
Validation loss: 2.1303747296333313

Epoch: 6| Step: 9
Training loss: 1.6616886854171753
Validation loss: 2.118229349454244

Epoch: 6| Step: 10
Training loss: 2.390981674194336
Validation loss: 2.130259176095327

Epoch: 6| Step: 11
Training loss: 2.561546802520752
Validation loss: 2.1222481727600098

Epoch: 6| Step: 12
Training loss: 2.472585439682007
Validation loss: 2.123875061670939

Epoch: 6| Step: 13
Training loss: 1.5764955282211304
Validation loss: 2.1230879624684653

Epoch: 199| Step: 0
Training loss: 2.86570405960083
Validation loss: 2.1365166505177817

Epoch: 6| Step: 1
Training loss: 2.202373504638672
Validation loss: 2.1457384626070657

Epoch: 6| Step: 2
Training loss: 1.4124271869659424
Validation loss: 2.139702558517456

Epoch: 6| Step: 3
Training loss: 2.195343017578125
Validation loss: 2.1646780371665955

Epoch: 6| Step: 4
Training loss: 1.2939066886901855
Validation loss: 2.172182639439901

Epoch: 6| Step: 5
Training loss: 2.3803181648254395
Validation loss: 2.1762203772862754

Epoch: 6| Step: 6
Training loss: 1.6128419637680054
Validation loss: 2.2139001886049905

Epoch: 6| Step: 7
Training loss: 2.564351797103882
Validation loss: 2.1835597157478333

Epoch: 6| Step: 8
Training loss: 1.9206926822662354
Validation loss: 2.1967103083928428

Epoch: 6| Step: 9
Training loss: 1.582726001739502
Validation loss: 2.1874189972877502

Epoch: 6| Step: 10
Training loss: 1.297980546951294
Validation loss: 2.169497867425283

Epoch: 6| Step: 11
Training loss: 1.9554966688156128
Validation loss: 2.1578683853149414

Epoch: 6| Step: 12
Training loss: 1.2744929790496826
Validation loss: 2.1426937182744346

Epoch: 6| Step: 13
Training loss: 1.8896842002868652
Validation loss: 2.151041845480601

Epoch: 200| Step: 0
Training loss: 1.8211684226989746
Validation loss: 2.1415521701176963

Epoch: 6| Step: 1
Training loss: 1.7662725448608398
Validation loss: 2.1381401419639587

Epoch: 6| Step: 2
Training loss: 1.8144359588623047
Validation loss: 2.135991096496582

Epoch: 6| Step: 3
Training loss: 1.7291024923324585
Validation loss: 2.136914292971293

Epoch: 6| Step: 4
Training loss: 2.26532244682312
Validation loss: 2.1500839392344155

Epoch: 6| Step: 5
Training loss: 1.4739142656326294
Validation loss: 2.1439412434895835

Epoch: 6| Step: 6
Training loss: 2.2336158752441406
Validation loss: 2.1465922395388284

Epoch: 6| Step: 7
Training loss: 1.7350908517837524
Validation loss: 2.150845209757487

Epoch: 6| Step: 8
Training loss: 1.7992960214614868
Validation loss: 2.149998128414154

Epoch: 6| Step: 9
Training loss: 1.7504466772079468
Validation loss: 2.15861839056015

Epoch: 6| Step: 10
Training loss: 2.088968515396118
Validation loss: 2.1551236708958945

Epoch: 6| Step: 11
Training loss: 1.9673287868499756
Validation loss: 2.149324099222819

Epoch: 6| Step: 12
Training loss: 2.121554374694824
Validation loss: 2.1518396933873496

Epoch: 6| Step: 13
Training loss: 1.4016717672348022
Validation loss: 2.1768946846326194

Epoch: 201| Step: 0
Training loss: 1.5947248935699463
Validation loss: 2.174724042415619

Epoch: 6| Step: 1
Training loss: 1.625370740890503
Validation loss: 2.16968963543574

Epoch: 6| Step: 2
Training loss: 1.2806251049041748
Validation loss: 2.170089840888977

Epoch: 6| Step: 3
Training loss: 1.339142918586731
Validation loss: 2.178717772165934

Epoch: 6| Step: 4
Training loss: 1.6126967668533325
Validation loss: 2.1771969000498452

Epoch: 6| Step: 5
Training loss: 2.101778507232666
Validation loss: 2.1679346760114035

Epoch: 6| Step: 6
Training loss: 2.815992832183838
Validation loss: 2.162408928076426

Epoch: 6| Step: 7
Training loss: 1.9116158485412598
Validation loss: 2.154296656449636

Epoch: 6| Step: 8
Training loss: 2.30387544631958
Validation loss: 2.1452972491582236

Epoch: 6| Step: 9
Training loss: 2.4948270320892334
Validation loss: 2.162162264188131

Epoch: 6| Step: 10
Training loss: 1.6533541679382324
Validation loss: 2.1396308143933616

Epoch: 6| Step: 11
Training loss: 1.5155987739562988
Validation loss: 2.1404877503712973

Epoch: 6| Step: 12
Training loss: 1.9217050075531006
Validation loss: 2.1453203360239663

Epoch: 6| Step: 13
Training loss: 1.7928597927093506
Validation loss: 2.137951930363973

Epoch: 202| Step: 0
Training loss: 1.670986533164978
Validation loss: 2.1488780975341797

Epoch: 6| Step: 1
Training loss: 2.368720054626465
Validation loss: 2.137413740158081

Epoch: 6| Step: 2
Training loss: 1.8093056678771973
Validation loss: 2.1468202273050943

Epoch: 6| Step: 3
Training loss: 1.552567720413208
Validation loss: 2.1418451269467673

Epoch: 6| Step: 4
Training loss: 1.28413724899292
Validation loss: 2.1698980728785195

Epoch: 6| Step: 5
Training loss: 1.3779839277267456
Validation loss: 2.16520623366038

Epoch: 6| Step: 6
Training loss: 2.20898699760437
Validation loss: 2.1673622330029807

Epoch: 6| Step: 7
Training loss: 2.5203731060028076
Validation loss: 2.1784401734670005

Epoch: 6| Step: 8
Training loss: 1.8230018615722656
Validation loss: 2.1658541758855185

Epoch: 6| Step: 9
Training loss: 2.2268476486206055
Validation loss: 2.1479063034057617

Epoch: 6| Step: 10
Training loss: 2.1623098850250244
Validation loss: 2.1619936426480613

Epoch: 6| Step: 11
Training loss: 1.6790586709976196
Validation loss: 2.1564637422561646

Epoch: 6| Step: 12
Training loss: 1.7471933364868164
Validation loss: 2.1588527957598367

Epoch: 6| Step: 13
Training loss: 1.6994494199752808
Validation loss: 2.1541395584742227

Epoch: 203| Step: 0
Training loss: 2.4132723808288574
Validation loss: 2.1425826152165732

Epoch: 6| Step: 1
Training loss: 1.40944504737854
Validation loss: 2.1553619305292764

Epoch: 6| Step: 2
Training loss: 1.4557292461395264
Validation loss: 2.1696004470189414

Epoch: 6| Step: 3
Training loss: 1.2777185440063477
Validation loss: 2.165064493815104

Epoch: 6| Step: 4
Training loss: 2.036668300628662
Validation loss: 2.1626774271329245

Epoch: 6| Step: 5
Training loss: 2.09808087348938
Validation loss: 2.1676494081815085

Epoch: 6| Step: 6
Training loss: 2.187103033065796
Validation loss: 2.1592424511909485

Epoch: 6| Step: 7
Training loss: 1.308597445487976
Validation loss: 2.150524298350016

Epoch: 6| Step: 8
Training loss: 2.1759114265441895
Validation loss: 2.154615600903829

Epoch: 6| Step: 9
Training loss: 1.584220290184021
Validation loss: 2.1498860716819763

Epoch: 6| Step: 10
Training loss: 1.4995992183685303
Validation loss: 2.1619678735733032

Epoch: 6| Step: 11
Training loss: 2.265871047973633
Validation loss: 2.1671804984410605

Epoch: 6| Step: 12
Training loss: 1.339638352394104
Validation loss: 2.1468268632888794

Epoch: 6| Step: 13
Training loss: 2.8512487411499023
Validation loss: 2.1455835700035095

Epoch: 204| Step: 0
Training loss: 1.9817020893096924
Validation loss: 2.141882618268331

Epoch: 6| Step: 1
Training loss: 2.3463473320007324
Validation loss: 2.142943342526754

Epoch: 6| Step: 2
Training loss: 1.7388396263122559
Validation loss: 2.141563634077708

Epoch: 6| Step: 3
Training loss: 1.7897669076919556
Validation loss: 2.13983146349589

Epoch: 6| Step: 4
Training loss: 1.7181495428085327
Validation loss: 2.1339083711306253

Epoch: 6| Step: 5
Training loss: 1.4215686321258545
Validation loss: 2.1387998461723328

Epoch: 6| Step: 6
Training loss: 2.0202388763427734
Validation loss: 2.1527519822120667

Epoch: 6| Step: 7
Training loss: 1.6607816219329834
Validation loss: 2.1495702862739563

Epoch: 6| Step: 8
Training loss: 1.7854704856872559
Validation loss: 2.168904185295105

Epoch: 6| Step: 9
Training loss: 2.6095967292785645
Validation loss: 2.178167204062144

Epoch: 6| Step: 10
Training loss: 1.4597673416137695
Validation loss: 2.172027508417765

Epoch: 6| Step: 11
Training loss: 2.3146109580993652
Validation loss: 2.1712886095046997

Epoch: 6| Step: 12
Training loss: 1.3784124851226807
Validation loss: 2.1730948289235434

Epoch: 6| Step: 13
Training loss: 1.4801428318023682
Validation loss: 2.1600451866785684

Epoch: 205| Step: 0
Training loss: 2.142298936843872
Validation loss: 2.179280161857605

Epoch: 6| Step: 1
Training loss: 2.56333065032959
Validation loss: 2.1700443029403687

Epoch: 6| Step: 2
Training loss: 1.756721019744873
Validation loss: 2.1784512996673584

Epoch: 6| Step: 3
Training loss: 1.3291914463043213
Validation loss: 2.1702021757761636

Epoch: 6| Step: 4
Training loss: 1.4093282222747803
Validation loss: 2.1947280168533325

Epoch: 6| Step: 5
Training loss: 1.9047877788543701
Validation loss: 2.198362092177073

Epoch: 6| Step: 6
Training loss: 1.0911790132522583
Validation loss: 2.1852927009264627

Epoch: 6| Step: 7
Training loss: 2.3729166984558105
Validation loss: 2.1855861147244773

Epoch: 6| Step: 8
Training loss: 1.9984852075576782
Validation loss: 2.183672845363617

Epoch: 6| Step: 9
Training loss: 2.0590429306030273
Validation loss: 2.1653309067090354

Epoch: 6| Step: 10
Training loss: 1.546858787536621
Validation loss: 2.15180504322052

Epoch: 6| Step: 11
Training loss: 1.4816714525222778
Validation loss: 2.1458860437075296

Epoch: 6| Step: 12
Training loss: 2.1773245334625244
Validation loss: 2.1455010771751404

Epoch: 6| Step: 13
Training loss: 1.7838133573532104
Validation loss: 2.1294424335161843

Epoch: 206| Step: 0
Training loss: 1.9745570421218872
Validation loss: 2.1451677083969116

Epoch: 6| Step: 1
Training loss: 2.236319065093994
Validation loss: 2.145747264226278

Epoch: 6| Step: 2
Training loss: 1.7854211330413818
Validation loss: 2.1437822182973227

Epoch: 6| Step: 3
Training loss: 1.2768497467041016
Validation loss: 2.156000554561615

Epoch: 6| Step: 4
Training loss: 1.538709044456482
Validation loss: 2.1509610414505005

Epoch: 6| Step: 5
Training loss: 2.440842628479004
Validation loss: 2.1595224340756736

Epoch: 6| Step: 6
Training loss: 1.6949517726898193
Validation loss: 2.149950941403707

Epoch: 6| Step: 7
Training loss: 2.217787265777588
Validation loss: 2.1542638540267944

Epoch: 6| Step: 8
Training loss: 2.387683868408203
Validation loss: 2.1639687617619834

Epoch: 6| Step: 9
Training loss: 1.3252006769180298
Validation loss: 2.155973811944326

Epoch: 6| Step: 10
Training loss: 1.41873300075531
Validation loss: 2.154137134552002

Epoch: 6| Step: 11
Training loss: 1.6671249866485596
Validation loss: 2.1530120174090066

Epoch: 6| Step: 12
Training loss: 1.7696881294250488
Validation loss: 2.1529343724250793

Epoch: 6| Step: 13
Training loss: 1.8603252172470093
Validation loss: 2.17558487256368

Epoch: 207| Step: 0
Training loss: 1.707092046737671
Validation loss: 2.1702862779299417

Epoch: 6| Step: 1
Training loss: 1.3560938835144043
Validation loss: 2.1676304737726846

Epoch: 6| Step: 2
Training loss: 2.0353212356567383
Validation loss: 2.177671412626902

Epoch: 6| Step: 3
Training loss: 1.7201564311981201
Validation loss: 2.1672451496124268

Epoch: 6| Step: 4
Training loss: 1.882590413093567
Validation loss: 2.1691372195879617

Epoch: 6| Step: 5
Training loss: 1.146379828453064
Validation loss: 2.1776954730351767

Epoch: 6| Step: 6
Training loss: 2.0556368827819824
Validation loss: 2.157998184363047

Epoch: 6| Step: 7
Training loss: 1.9128159284591675
Validation loss: 2.1661916772524514

Epoch: 6| Step: 8
Training loss: 1.906381368637085
Validation loss: 2.150120039780935

Epoch: 6| Step: 9
Training loss: 1.2870324850082397
Validation loss: 2.1511332392692566

Epoch: 6| Step: 10
Training loss: 2.171298027038574
Validation loss: 2.1585307319959006

Epoch: 6| Step: 11
Training loss: 2.3653855323791504
Validation loss: 2.146089951197306

Epoch: 6| Step: 12
Training loss: 2.1491312980651855
Validation loss: 2.1490365068117776

Epoch: 6| Step: 13
Training loss: 1.9279365539550781
Validation loss: 2.1893559098243713

Epoch: 208| Step: 0
Training loss: 1.9638230800628662
Validation loss: 2.163623571395874

Epoch: 6| Step: 1
Training loss: 2.5702693462371826
Validation loss: 2.1944494048754373

Epoch: 6| Step: 2
Training loss: 0.9738250970840454
Validation loss: 2.2156404654184976

Epoch: 6| Step: 3
Training loss: 1.6034001111984253
Validation loss: 2.235391139984131

Epoch: 6| Step: 4
Training loss: 1.7167840003967285
Validation loss: 2.2207768758138022

Epoch: 6| Step: 5
Training loss: 2.251312494277954
Validation loss: 2.2245403130849204

Epoch: 6| Step: 6
Training loss: 1.2698254585266113
Validation loss: 2.1942700346310935

Epoch: 6| Step: 7
Training loss: 1.491471529006958
Validation loss: 2.1776129404703775

Epoch: 6| Step: 8
Training loss: 2.197066307067871
Validation loss: 2.175928791364034

Epoch: 6| Step: 9
Training loss: 2.914231300354004
Validation loss: 2.152398645877838

Epoch: 6| Step: 10
Training loss: 1.6776361465454102
Validation loss: 2.1558727423350015

Epoch: 6| Step: 11
Training loss: 1.5046403408050537
Validation loss: 2.1438483198483786

Epoch: 6| Step: 12
Training loss: 1.6202609539031982
Validation loss: 2.1381488839785256

Epoch: 6| Step: 13
Training loss: 2.2719357013702393
Validation loss: 2.140418291091919

Epoch: 209| Step: 0
Training loss: 1.5454528331756592
Validation loss: 2.134860038757324

Epoch: 6| Step: 1
Training loss: 1.3363549709320068
Validation loss: 2.1397496859232583

Epoch: 6| Step: 2
Training loss: 1.9891083240509033
Validation loss: 2.151551286379496

Epoch: 6| Step: 3
Training loss: 1.5461851358413696
Validation loss: 2.136675536632538

Epoch: 6| Step: 4
Training loss: 2.033651351928711
Validation loss: 2.151703119277954

Epoch: 6| Step: 5
Training loss: 1.9297617673873901
Validation loss: 2.141172548135122

Epoch: 6| Step: 6
Training loss: 2.220613718032837
Validation loss: 2.1925082405408225

Epoch: 6| Step: 7
Training loss: 1.6607732772827148
Validation loss: 2.1851235826810202

Epoch: 6| Step: 8
Training loss: 2.4023213386535645
Validation loss: 2.212701757748922

Epoch: 6| Step: 9
Training loss: 1.563289761543274
Validation loss: 2.2030324935913086

Epoch: 6| Step: 10
Training loss: 2.4327807426452637
Validation loss: 2.172171692053477

Epoch: 6| Step: 11
Training loss: 2.3563811779022217
Validation loss: 2.1704058249791465

Epoch: 6| Step: 12
Training loss: 1.577063798904419
Validation loss: 2.1421696543693542

Epoch: 6| Step: 13
Training loss: 1.759778380393982
Validation loss: 2.1515765388806662

Epoch: 210| Step: 0
Training loss: 2.478975772857666
Validation loss: 2.154786388079325

Epoch: 6| Step: 1
Training loss: 2.019723892211914
Validation loss: 2.1806283990542092

Epoch: 6| Step: 2
Training loss: 1.6721454858779907
Validation loss: 2.172514180342356

Epoch: 6| Step: 3
Training loss: 1.929884910583496
Validation loss: 2.177144726117452

Epoch: 6| Step: 4
Training loss: 1.9580754041671753
Validation loss: 2.181723634401957

Epoch: 6| Step: 5
Training loss: 1.6651854515075684
Validation loss: 2.1756171385447183

Epoch: 6| Step: 6
Training loss: 1.6134941577911377
Validation loss: 2.191840410232544

Epoch: 6| Step: 7
Training loss: 1.5189892053604126
Validation loss: 2.182685891787211

Epoch: 6| Step: 8
Training loss: 1.8780570030212402
Validation loss: 2.1850949128468833

Epoch: 6| Step: 9
Training loss: 2.3995022773742676
Validation loss: 2.1717702746391296

Epoch: 6| Step: 10
Training loss: 2.003582715988159
Validation loss: 2.206718365351359

Epoch: 6| Step: 11
Training loss: 1.2228243350982666
Validation loss: 2.207672437032064

Epoch: 6| Step: 12
Training loss: 1.9984773397445679
Validation loss: 2.222644646962484

Epoch: 6| Step: 13
Training loss: 1.494822382926941
Validation loss: 2.212976336479187

Epoch: 211| Step: 0
Training loss: 1.8310003280639648
Validation loss: 2.179536203543345

Epoch: 6| Step: 1
Training loss: 2.0091981887817383
Validation loss: 2.1776591142018638

Epoch: 6| Step: 2
Training loss: 1.2534101009368896
Validation loss: 2.1749304930369058

Epoch: 6| Step: 3
Training loss: 1.2824015617370605
Validation loss: 2.1743371287981668

Epoch: 6| Step: 4
Training loss: 2.1355342864990234
Validation loss: 2.1501662731170654

Epoch: 6| Step: 5
Training loss: 2.473358631134033
Validation loss: 2.157956143220266

Epoch: 6| Step: 6
Training loss: 1.5390965938568115
Validation loss: 2.158672293027242

Epoch: 6| Step: 7
Training loss: 1.8658950328826904
Validation loss: 2.1446171601613364

Epoch: 6| Step: 8
Training loss: 1.753575325012207
Validation loss: 2.1404003898302713

Epoch: 6| Step: 9
Training loss: 1.7561404705047607
Validation loss: 2.1536102294921875

Epoch: 6| Step: 10
Training loss: 1.541853427886963
Validation loss: 2.1306744813919067

Epoch: 6| Step: 11
Training loss: 2.452423334121704
Validation loss: 2.1636193792025247

Epoch: 6| Step: 12
Training loss: 1.443489670753479
Validation loss: 2.1489195028940835

Epoch: 6| Step: 13
Training loss: 1.8711917400360107
Validation loss: 2.1760160724322

Epoch: 212| Step: 0
Training loss: 1.649614930152893
Validation loss: 2.1821658611297607

Epoch: 6| Step: 1
Training loss: 1.97030508518219
Validation loss: 2.181239426136017

Epoch: 6| Step: 2
Training loss: 2.0610265731811523
Validation loss: 2.2027501265207925

Epoch: 6| Step: 3
Training loss: 1.527571678161621
Validation loss: 2.209454039732615

Epoch: 6| Step: 4
Training loss: 1.9422928094863892
Validation loss: 2.2379109462102256

Epoch: 6| Step: 5
Training loss: 1.076934814453125
Validation loss: 2.2174145778020224

Epoch: 6| Step: 6
Training loss: 1.6408240795135498
Validation loss: 2.1797699332237244

Epoch: 6| Step: 7
Training loss: 2.0800209045410156
Validation loss: 2.184740444024404

Epoch: 6| Step: 8
Training loss: 2.006157398223877
Validation loss: 2.1611449321111045

Epoch: 6| Step: 9
Training loss: 2.089994430541992
Validation loss: 2.1421902775764465

Epoch: 6| Step: 10
Training loss: 2.206084728240967
Validation loss: 2.123659829298655

Epoch: 6| Step: 11
Training loss: 2.057802677154541
Validation loss: 2.1277108192443848

Epoch: 6| Step: 12
Training loss: 1.8747634887695312
Validation loss: 2.1373214522997537

Epoch: 6| Step: 13
Training loss: 1.870323896408081
Validation loss: 2.144632120927175

Epoch: 213| Step: 0
Training loss: 1.865560531616211
Validation loss: 2.1369486252466836

Epoch: 6| Step: 1
Training loss: 2.3066201210021973
Validation loss: 2.167293151219686

Epoch: 6| Step: 2
Training loss: 1.8048663139343262
Validation loss: 2.169150233268738

Epoch: 6| Step: 3
Training loss: 1.8211864233016968
Validation loss: 2.170126815636953

Epoch: 6| Step: 4
Training loss: 2.5396389961242676
Validation loss: 2.191204071044922

Epoch: 6| Step: 5
Training loss: 1.5927259922027588
Validation loss: 2.213786780834198

Epoch: 6| Step: 6
Training loss: 1.4206255674362183
Validation loss: 2.232143839200338

Epoch: 6| Step: 7
Training loss: 1.7848708629608154
Validation loss: 2.2528358697891235

Epoch: 6| Step: 8
Training loss: 1.97736394405365
Validation loss: 2.245235562324524

Epoch: 6| Step: 9
Training loss: 1.507000207901001
Validation loss: 2.220719575881958

Epoch: 6| Step: 10
Training loss: 1.9554846286773682
Validation loss: 2.211883783340454

Epoch: 6| Step: 11
Training loss: 2.001866579055786
Validation loss: 2.165130376815796

Epoch: 6| Step: 12
Training loss: 1.825138807296753
Validation loss: 2.1396508614222207

Epoch: 6| Step: 13
Training loss: 1.9620063304901123
Validation loss: 2.1564362247784934

Epoch: 214| Step: 0
Training loss: 2.0355868339538574
Validation loss: 2.132637004057566

Epoch: 6| Step: 1
Training loss: 2.2834248542785645
Validation loss: 2.1326563159624734

Epoch: 6| Step: 2
Training loss: 1.29642653465271
Validation loss: 2.1385150949160256

Epoch: 6| Step: 3
Training loss: 2.4363725185394287
Validation loss: 2.1393756667772927

Epoch: 6| Step: 4
Training loss: 1.7593376636505127
Validation loss: 2.129979054133097

Epoch: 6| Step: 5
Training loss: 2.060788154602051
Validation loss: 2.145765006542206

Epoch: 6| Step: 6
Training loss: 2.3154959678649902
Validation loss: 2.145682374636332

Epoch: 6| Step: 7
Training loss: 2.383566379547119
Validation loss: 2.1441875100135803

Epoch: 6| Step: 8
Training loss: 1.7508111000061035
Validation loss: 2.156639337539673

Epoch: 6| Step: 9
Training loss: 1.3224290609359741
Validation loss: 2.1490925947825112

Epoch: 6| Step: 10
Training loss: 1.3362597227096558
Validation loss: 2.1603550712267556

Epoch: 6| Step: 11
Training loss: 1.7101469039916992
Validation loss: 2.195411483446757

Epoch: 6| Step: 12
Training loss: 1.5393855571746826
Validation loss: 2.213248054186503

Epoch: 6| Step: 13
Training loss: 2.051802396774292
Validation loss: 2.239296555519104

Epoch: 215| Step: 0
Training loss: 2.46832275390625
Validation loss: 2.250091552734375

Epoch: 6| Step: 1
Training loss: 2.115251064300537
Validation loss: 2.2408601442972818

Epoch: 6| Step: 2
Training loss: 2.1813108921051025
Validation loss: 2.2171597878138223

Epoch: 6| Step: 3
Training loss: 1.6104917526245117
Validation loss: 2.2462552388509116

Epoch: 6| Step: 4
Training loss: 1.3420369625091553
Validation loss: 2.20876944065094

Epoch: 6| Step: 5
Training loss: 1.9551464319229126
Validation loss: 2.208371718724569

Epoch: 6| Step: 6
Training loss: 1.6900959014892578
Validation loss: 2.1886401573816934

Epoch: 6| Step: 7
Training loss: 1.7079575061798096
Validation loss: 2.206843058268229

Epoch: 6| Step: 8
Training loss: 1.5370395183563232
Validation loss: 2.2049612402915955

Epoch: 6| Step: 9
Training loss: 2.7500076293945312
Validation loss: 2.191885550816854

Epoch: 6| Step: 10
Training loss: 1.788069486618042
Validation loss: 2.176343341668447

Epoch: 6| Step: 11
Training loss: 1.6377168893814087
Validation loss: 2.1738153298695884

Epoch: 6| Step: 12
Training loss: 1.3754844665527344
Validation loss: 2.182053724924723

Epoch: 6| Step: 13
Training loss: 1.231886386871338
Validation loss: 2.162182946999868

Epoch: 216| Step: 0
Training loss: 1.864736557006836
Validation loss: 2.163220544656118

Epoch: 6| Step: 1
Training loss: 1.5292444229125977
Validation loss: 2.1960425972938538

Epoch: 6| Step: 2
Training loss: 1.9580504894256592
Validation loss: 2.151674727598826

Epoch: 6| Step: 3
Training loss: 2.0071065425872803
Validation loss: 2.1787986954053244

Epoch: 6| Step: 4
Training loss: 1.4125325679779053
Validation loss: 2.1647472977638245

Epoch: 6| Step: 5
Training loss: 2.2015268802642822
Validation loss: 2.186752955118815

Epoch: 6| Step: 6
Training loss: 1.488759994506836
Validation loss: 2.193415363629659

Epoch: 6| Step: 7
Training loss: 1.9224512577056885
Validation loss: 2.1719592809677124

Epoch: 6| Step: 8
Training loss: 2.111903667449951
Validation loss: 2.2157238721847534

Epoch: 6| Step: 9
Training loss: 2.4386215209960938
Validation loss: 2.2421807448069253

Epoch: 6| Step: 10
Training loss: 1.2827751636505127
Validation loss: 2.2567228078842163

Epoch: 6| Step: 11
Training loss: 1.679356575012207
Validation loss: 2.242991884549459

Epoch: 6| Step: 12
Training loss: 1.8646478652954102
Validation loss: 2.2049341996510825

Epoch: 6| Step: 13
Training loss: 2.4375545978546143
Validation loss: 2.2112462719281516

Epoch: 217| Step: 0
Training loss: 2.7122278213500977
Validation loss: 2.174847960472107

Epoch: 6| Step: 1
Training loss: 1.8337684869766235
Validation loss: 2.17309977610906

Epoch: 6| Step: 2
Training loss: 1.70125150680542
Validation loss: 2.140184541543325

Epoch: 6| Step: 3
Training loss: 1.6636360883712769
Validation loss: 2.1502486864725747

Epoch: 6| Step: 4
Training loss: 1.2969896793365479
Validation loss: 2.146541953086853

Epoch: 6| Step: 5
Training loss: 2.474674940109253
Validation loss: 2.1311963200569153

Epoch: 6| Step: 6
Training loss: 2.357543706893921
Validation loss: 2.1339731415112815

Epoch: 6| Step: 7
Training loss: 2.3084299564361572
Validation loss: 2.155343929926554

Epoch: 6| Step: 8
Training loss: 1.5117069482803345
Validation loss: 2.1468149423599243

Epoch: 6| Step: 9
Training loss: 1.7349520921707153
Validation loss: 2.1435478727022805

Epoch: 6| Step: 10
Training loss: 1.0971276760101318
Validation loss: 2.147804538408915

Epoch: 6| Step: 11
Training loss: 2.1689329147338867
Validation loss: 2.1446454723676047

Epoch: 6| Step: 12
Training loss: 1.8103644847869873
Validation loss: 2.1581942240397134

Epoch: 6| Step: 13
Training loss: 1.3791413307189941
Validation loss: 2.1677474975585938

Epoch: 218| Step: 0
Training loss: 1.6725198030471802
Validation loss: 2.1604108214378357

Epoch: 6| Step: 1
Training loss: 1.7493629455566406
Validation loss: 2.181577662626902

Epoch: 6| Step: 2
Training loss: 2.1901464462280273
Validation loss: 2.1735695799191794

Epoch: 6| Step: 3
Training loss: 2.1130053997039795
Validation loss: 2.1986325780550637

Epoch: 6| Step: 4
Training loss: 2.1525163650512695
Validation loss: 2.173172414302826

Epoch: 6| Step: 5
Training loss: 1.531984567642212
Validation loss: 2.1767341693242392

Epoch: 6| Step: 6
Training loss: 1.3348485231399536
Validation loss: 2.1794541279474893

Epoch: 6| Step: 7
Training loss: 1.6307295560836792
Validation loss: 2.1607395013173423

Epoch: 6| Step: 8
Training loss: 2.4940109252929688
Validation loss: 2.177384336789449

Epoch: 6| Step: 9
Training loss: 1.944376826286316
Validation loss: 2.17265385389328

Epoch: 6| Step: 10
Training loss: 1.0893669128417969
Validation loss: 2.181973159313202

Epoch: 6| Step: 11
Training loss: 1.911996841430664
Validation loss: 2.181074639161428

Epoch: 6| Step: 12
Training loss: 1.4048271179199219
Validation loss: 2.1931662956873574

Epoch: 6| Step: 13
Training loss: 2.004638910293579
Validation loss: 2.175754209359487

Epoch: 219| Step: 0
Training loss: 1.6511032581329346
Validation loss: 2.1963001489639282

Epoch: 6| Step: 1
Training loss: 1.2478032112121582
Validation loss: 2.1885743538538613

Epoch: 6| Step: 2
Training loss: 1.835831880569458
Validation loss: 2.218996544679006

Epoch: 6| Step: 3
Training loss: 1.7953088283538818
Validation loss: 2.2191723187764487

Epoch: 6| Step: 4
Training loss: 1.757865071296692
Validation loss: 2.188459793726603

Epoch: 6| Step: 5
Training loss: 1.4651079177856445
Validation loss: 2.2415488560994468

Epoch: 6| Step: 6
Training loss: 1.8746682405471802
Validation loss: 2.230452040831248

Epoch: 6| Step: 7
Training loss: 1.7341188192367554
Validation loss: 2.238602101802826

Epoch: 6| Step: 8
Training loss: 1.9453058242797852
Validation loss: 2.198572039604187

Epoch: 6| Step: 9
Training loss: 1.9449139833450317
Validation loss: 2.203316648801168

Epoch: 6| Step: 10
Training loss: 1.662032961845398
Validation loss: 2.2151558001836142

Epoch: 6| Step: 11
Training loss: 2.175649404525757
Validation loss: 2.1968029141426086

Epoch: 6| Step: 12
Training loss: 2.1070785522460938
Validation loss: 2.184650401274363

Epoch: 6| Step: 13
Training loss: 1.9365453720092773
Validation loss: 2.152786592642466

Epoch: 220| Step: 0
Training loss: 2.8601768016815186
Validation loss: 2.1465880076090493

Epoch: 6| Step: 1
Training loss: 1.264104962348938
Validation loss: 2.1402315894762673

Epoch: 6| Step: 2
Training loss: 1.5287096500396729
Validation loss: 2.1378374099731445

Epoch: 6| Step: 3
Training loss: 1.700520634651184
Validation loss: 2.1394198536872864

Epoch: 6| Step: 4
Training loss: 1.529738187789917
Validation loss: 2.139875908692678

Epoch: 6| Step: 5
Training loss: 2.473173141479492
Validation loss: 2.141593853632609

Epoch: 6| Step: 6
Training loss: 1.846030354499817
Validation loss: 2.1332958539326987

Epoch: 6| Step: 7
Training loss: 2.3040285110473633
Validation loss: 2.147001008192698

Epoch: 6| Step: 8
Training loss: 2.5431907176971436
Validation loss: 2.159801483154297

Epoch: 6| Step: 9
Training loss: 1.1699634790420532
Validation loss: 2.16337251663208

Epoch: 6| Step: 10
Training loss: 1.3513214588165283
Validation loss: 2.166166444619497

Epoch: 6| Step: 11
Training loss: 1.4755438566207886
Validation loss: 2.163484752178192

Epoch: 6| Step: 12
Training loss: 1.9289121627807617
Validation loss: 2.175489823023478

Epoch: 6| Step: 13
Training loss: 1.67559814453125
Validation loss: 2.161835551261902

Epoch: 221| Step: 0
Training loss: 1.8057829141616821
Validation loss: 2.1484148502349854

Epoch: 6| Step: 1
Training loss: 2.172316551208496
Validation loss: 2.155160884062449

Epoch: 6| Step: 2
Training loss: 2.0020132064819336
Validation loss: 2.1694742242495217

Epoch: 6| Step: 3
Training loss: 1.8739420175552368
Validation loss: 2.176431099573771

Epoch: 6| Step: 4
Training loss: 1.7602739334106445
Validation loss: 2.192403415838877

Epoch: 6| Step: 5
Training loss: 1.758845567703247
Validation loss: 2.1852197448412576

Epoch: 6| Step: 6
Training loss: 1.6586308479309082
Validation loss: 2.195594867070516

Epoch: 6| Step: 7
Training loss: 1.6205016374588013
Validation loss: 2.201910138130188

Epoch: 6| Step: 8
Training loss: 1.9338130950927734
Validation loss: 2.189096132914225

Epoch: 6| Step: 9
Training loss: 1.4465363025665283
Validation loss: 2.216200848420461

Epoch: 6| Step: 10
Training loss: 1.7772791385650635
Validation loss: 2.1867308219273887

Epoch: 6| Step: 11
Training loss: 1.796372652053833
Validation loss: 2.1728148261706033

Epoch: 6| Step: 12
Training loss: 1.9436798095703125
Validation loss: 2.1692210833231607

Epoch: 6| Step: 13
Training loss: 1.6523911952972412
Validation loss: 2.1742035945256553

Epoch: 222| Step: 0
Training loss: 1.0766243934631348
Validation loss: 2.169690728187561

Epoch: 6| Step: 1
Training loss: 1.6752097606658936
Validation loss: 2.16742076476415

Epoch: 6| Step: 2
Training loss: 2.668156147003174
Validation loss: 2.178672134876251

Epoch: 6| Step: 3
Training loss: 2.024259567260742
Validation loss: 2.1634848515192666

Epoch: 6| Step: 4
Training loss: 1.808222770690918
Validation loss: 2.1696647008260093

Epoch: 6| Step: 5
Training loss: 1.7613863945007324
Validation loss: 2.1481580336888633

Epoch: 6| Step: 6
Training loss: 2.0653109550476074
Validation loss: 2.162532329559326

Epoch: 6| Step: 7
Training loss: 1.7971479892730713
Validation loss: 2.167789955933889

Epoch: 6| Step: 8
Training loss: 1.772594690322876
Validation loss: 2.162718137105306

Epoch: 6| Step: 9
Training loss: 1.5869836807250977
Validation loss: 2.153999308745066

Epoch: 6| Step: 10
Training loss: 1.266542911529541
Validation loss: 2.160853862762451

Epoch: 6| Step: 11
Training loss: 1.7144005298614502
Validation loss: 2.173837502797445

Epoch: 6| Step: 12
Training loss: 1.6548290252685547
Validation loss: 2.163578192392985

Epoch: 6| Step: 13
Training loss: 2.094991683959961
Validation loss: 2.1700894435246787

Epoch: 223| Step: 0
Training loss: 1.5240118503570557
Validation loss: 2.1892238656679788

Epoch: 6| Step: 1
Training loss: 2.2540712356567383
Validation loss: 2.197380701700846

Epoch: 6| Step: 2
Training loss: 2.487536907196045
Validation loss: 2.1638230681419373

Epoch: 6| Step: 3
Training loss: 1.9972834587097168
Validation loss: 2.158494293689728

Epoch: 6| Step: 4
Training loss: 1.670572280883789
Validation loss: 2.164438088734945

Epoch: 6| Step: 5
Training loss: 1.6338133811950684
Validation loss: 2.1743539373079934

Epoch: 6| Step: 6
Training loss: 1.9916934967041016
Validation loss: 2.174900849660238

Epoch: 6| Step: 7
Training loss: 1.5859215259552002
Validation loss: 2.167300740877787

Epoch: 6| Step: 8
Training loss: 1.456972360610962
Validation loss: 2.17331991593043

Epoch: 6| Step: 9
Training loss: 1.5452125072479248
Validation loss: 2.172359585762024

Epoch: 6| Step: 10
Training loss: 1.3280236721038818
Validation loss: 2.1894330978393555

Epoch: 6| Step: 11
Training loss: 2.279353141784668
Validation loss: 2.166702071825663

Epoch: 6| Step: 12
Training loss: 1.7714858055114746
Validation loss: 2.1555630366007485

Epoch: 6| Step: 13
Training loss: 1.0878300666809082
Validation loss: 2.173535247643789

Epoch: 224| Step: 0
Training loss: 1.6431608200073242
Validation loss: 2.193023423353831

Epoch: 6| Step: 1
Training loss: 1.0443124771118164
Validation loss: 2.2085172533988953

Epoch: 6| Step: 2
Training loss: 2.75585675239563
Validation loss: 2.2179781198501587

Epoch: 6| Step: 3
Training loss: 2.4618916511535645
Validation loss: 2.1945923964182534

Epoch: 6| Step: 4
Training loss: 1.3521509170532227
Validation loss: 2.214103043079376

Epoch: 6| Step: 5
Training loss: 1.8867855072021484
Validation loss: 2.1912419199943542

Epoch: 6| Step: 6
Training loss: 1.6057379245758057
Validation loss: 2.175717016061147

Epoch: 6| Step: 7
Training loss: 1.3956533670425415
Validation loss: 2.190726081530253

Epoch: 6| Step: 8
Training loss: 1.7972102165222168
Validation loss: 2.181963086128235

Epoch: 6| Step: 9
Training loss: 2.2807250022888184
Validation loss: 2.1696465015411377

Epoch: 6| Step: 10
Training loss: 1.785097599029541
Validation loss: 2.183824598789215

Epoch: 6| Step: 11
Training loss: 2.219714641571045
Validation loss: 2.1610281467437744

Epoch: 6| Step: 12
Training loss: 1.1325533390045166
Validation loss: 2.163031538327535

Epoch: 6| Step: 13
Training loss: 1.7123206853866577
Validation loss: 2.1764787435531616

Epoch: 225| Step: 0
Training loss: 2.453411102294922
Validation loss: 2.169408400853475

Epoch: 6| Step: 1
Training loss: 1.717422366142273
Validation loss: 2.1848576267560325

Epoch: 6| Step: 2
Training loss: 2.054699420928955
Validation loss: 2.1801568269729614

Epoch: 6| Step: 3
Training loss: 1.6779156923294067
Validation loss: 2.1752460598945618

Epoch: 6| Step: 4
Training loss: 1.9925029277801514
Validation loss: 2.1799885829289756

Epoch: 6| Step: 5
Training loss: 2.0132713317871094
Validation loss: 2.2107117772102356

Epoch: 6| Step: 6
Training loss: 1.4639509916305542
Validation loss: 2.2098044753074646

Epoch: 6| Step: 7
Training loss: 1.784115195274353
Validation loss: 2.184863030910492

Epoch: 6| Step: 8
Training loss: 1.3468353748321533
Validation loss: 2.1770623524983725

Epoch: 6| Step: 9
Training loss: 1.7131783962249756
Validation loss: 2.183088719844818

Epoch: 6| Step: 10
Training loss: 1.8291239738464355
Validation loss: 2.1820040742556253

Epoch: 6| Step: 11
Training loss: 1.1061573028564453
Validation loss: 2.1828840176264444

Epoch: 6| Step: 12
Training loss: 1.7830899953842163
Validation loss: 2.1773733099301658

Epoch: 6| Step: 13
Training loss: 1.833037257194519
Validation loss: 2.1684539715449014

Epoch: 226| Step: 0
Training loss: 2.4579644203186035
Validation loss: 2.1623321374257407

Epoch: 6| Step: 1
Training loss: 1.8570338487625122
Validation loss: 2.1632862091064453

Epoch: 6| Step: 2
Training loss: 1.054861068725586
Validation loss: 2.164785921573639

Epoch: 6| Step: 3
Training loss: 2.263568878173828
Validation loss: 2.1654265324274697

Epoch: 6| Step: 4
Training loss: 1.9847763776779175
Validation loss: 2.1602074106534324

Epoch: 6| Step: 5
Training loss: 1.9997875690460205
Validation loss: 2.1538628935813904

Epoch: 6| Step: 6
Training loss: 1.9202451705932617
Validation loss: 2.1568260391553244

Epoch: 6| Step: 7
Training loss: 1.377954363822937
Validation loss: 2.15954327583313

Epoch: 6| Step: 8
Training loss: 1.6401031017303467
Validation loss: 2.1670304338137307

Epoch: 6| Step: 9
Training loss: 2.2724788188934326
Validation loss: 2.1684157053629556

Epoch: 6| Step: 10
Training loss: 2.2679738998413086
Validation loss: 2.172007441520691

Epoch: 6| Step: 11
Training loss: 1.2488036155700684
Validation loss: 2.1719403862953186

Epoch: 6| Step: 12
Training loss: 1.181193232536316
Validation loss: 2.179964601993561

Epoch: 6| Step: 13
Training loss: 1.9590944051742554
Validation loss: 2.1638843019803367

Epoch: 227| Step: 0
Training loss: 1.1808571815490723
Validation loss: 2.1589186986287436

Epoch: 6| Step: 1
Training loss: 2.2289955615997314
Validation loss: 2.1553160150845847

Epoch: 6| Step: 2
Training loss: 1.770196557044983
Validation loss: 2.1414528290430703

Epoch: 6| Step: 3
Training loss: 1.7564659118652344
Validation loss: 2.1608951489130654

Epoch: 6| Step: 4
Training loss: 1.9975776672363281
Validation loss: 2.1641294360160828

Epoch: 6| Step: 5
Training loss: 1.809086799621582
Validation loss: 2.1653207341829934

Epoch: 6| Step: 6
Training loss: 1.4206653833389282
Validation loss: 2.1490607261657715

Epoch: 6| Step: 7
Training loss: 2.1295669078826904
Validation loss: 2.1533674001693726

Epoch: 6| Step: 8
Training loss: 2.3620591163635254
Validation loss: 2.1601959665616355

Epoch: 6| Step: 9
Training loss: 1.8387649059295654
Validation loss: 2.13629416624705

Epoch: 6| Step: 10
Training loss: 1.0994980335235596
Validation loss: 2.1611303091049194

Epoch: 6| Step: 11
Training loss: 2.228215456008911
Validation loss: 2.1668249567349753

Epoch: 6| Step: 12
Training loss: 1.459119439125061
Validation loss: 2.186100443204244

Epoch: 6| Step: 13
Training loss: 1.6221988201141357
Validation loss: 2.1832618713378906

Epoch: 228| Step: 0
Training loss: 1.4963794946670532
Validation loss: 2.1665442188580832

Epoch: 6| Step: 1
Training loss: 1.518702507019043
Validation loss: 2.1627937157948813

Epoch: 6| Step: 2
Training loss: 2.2386555671691895
Validation loss: 2.184209406375885

Epoch: 6| Step: 3
Training loss: 1.3086003065109253
Validation loss: 2.201439062754313

Epoch: 6| Step: 4
Training loss: 2.1467978954315186
Validation loss: 2.170796513557434

Epoch: 6| Step: 5
Training loss: 1.4993343353271484
Validation loss: 2.1678935289382935

Epoch: 6| Step: 6
Training loss: 1.6124106645584106
Validation loss: 2.1671413580576577

Epoch: 6| Step: 7
Training loss: 2.3289341926574707
Validation loss: 2.2023709217707315

Epoch: 6| Step: 8
Training loss: 1.9864968061447144
Validation loss: 2.1914702653884888

Epoch: 6| Step: 9
Training loss: 1.5627423524856567
Validation loss: 2.153649389743805

Epoch: 6| Step: 10
Training loss: 2.090177059173584
Validation loss: 2.1919607122739158

Epoch: 6| Step: 11
Training loss: 1.3606618642807007
Validation loss: 2.192229429880778

Epoch: 6| Step: 12
Training loss: 1.7187308073043823
Validation loss: 2.1796083648999534

Epoch: 6| Step: 13
Training loss: 1.9761219024658203
Validation loss: 2.1665442188580832

Epoch: 229| Step: 0
Training loss: 1.5521743297576904
Validation loss: 2.1640573740005493

Epoch: 6| Step: 1
Training loss: 1.437462329864502
Validation loss: 2.1546552578608194

Epoch: 6| Step: 2
Training loss: 1.580235242843628
Validation loss: 2.181624114513397

Epoch: 6| Step: 3
Training loss: 1.9718040227890015
Validation loss: 2.1833184957504272

Epoch: 6| Step: 4
Training loss: 1.6324970722198486
Validation loss: 2.173517386118571

Epoch: 6| Step: 5
Training loss: 1.7557084560394287
Validation loss: 2.1701062321662903

Epoch: 6| Step: 6
Training loss: 1.984113335609436
Validation loss: 2.1687893072764077

Epoch: 6| Step: 7
Training loss: 2.018277883529663
Validation loss: 2.167648990948995

Epoch: 6| Step: 8
Training loss: 1.7168047428131104
Validation loss: 2.1653892596562705

Epoch: 6| Step: 9
Training loss: 1.8733731508255005
Validation loss: 2.1460351943969727

Epoch: 6| Step: 10
Training loss: 1.4773555994033813
Validation loss: 2.1725101272265115

Epoch: 6| Step: 11
Training loss: 1.5277595520019531
Validation loss: 2.1747488379478455

Epoch: 6| Step: 12
Training loss: 2.471156597137451
Validation loss: 2.191879709561666

Epoch: 6| Step: 13
Training loss: 1.533210277557373
Validation loss: 2.2005840142567954

Epoch: 230| Step: 0
Training loss: 1.7819058895111084
Validation loss: 2.22435196240743

Epoch: 6| Step: 1
Training loss: 1.8257864713668823
Validation loss: 2.213457147280375

Epoch: 6| Step: 2
Training loss: 2.2727596759796143
Validation loss: 2.208649516105652

Epoch: 6| Step: 3
Training loss: 2.021721601486206
Validation loss: 2.220271269480387

Epoch: 6| Step: 4
Training loss: 1.1378198862075806
Validation loss: 2.210670232772827

Epoch: 6| Step: 5
Training loss: 1.346925973892212
Validation loss: 2.1887933015823364

Epoch: 6| Step: 6
Training loss: 1.6031320095062256
Validation loss: 2.201353351275126

Epoch: 6| Step: 7
Training loss: 1.7813458442687988
Validation loss: 2.1791368325551352

Epoch: 6| Step: 8
Training loss: 1.837913990020752
Validation loss: 2.1749953826268515

Epoch: 6| Step: 9
Training loss: 1.4912450313568115
Validation loss: 2.1710360844930015

Epoch: 6| Step: 10
Training loss: 1.8960928916931152
Validation loss: 2.1657333374023438

Epoch: 6| Step: 11
Training loss: 1.8548961877822876
Validation loss: 2.166253407796224

Epoch: 6| Step: 12
Training loss: 2.139777183532715
Validation loss: 2.1875670154889426

Epoch: 6| Step: 13
Training loss: 1.9449858665466309
Validation loss: 2.1833482782046

Epoch: 231| Step: 0
Training loss: 1.5185202360153198
Validation loss: 2.193710764249166

Epoch: 6| Step: 1
Training loss: 2.12017822265625
Validation loss: 2.174664080142975

Epoch: 6| Step: 2
Training loss: 1.7985104322433472
Validation loss: 2.1798980832099915

Epoch: 6| Step: 3
Training loss: 1.5341377258300781
Validation loss: 2.1746839682261148

Epoch: 6| Step: 4
Training loss: 1.7707912921905518
Validation loss: 2.1891228953997293

Epoch: 6| Step: 5
Training loss: 0.9493623971939087
Validation loss: 2.181348701318105

Epoch: 6| Step: 6
Training loss: 1.3153835535049438
Validation loss: 2.1770781874656677

Epoch: 6| Step: 7
Training loss: 1.3779258728027344
Validation loss: 2.181666831175486

Epoch: 6| Step: 8
Training loss: 2.660654067993164
Validation loss: 2.1750316619873047

Epoch: 6| Step: 9
Training loss: 2.0084609985351562
Validation loss: 2.1680585145950317

Epoch: 6| Step: 10
Training loss: 2.1405768394470215
Validation loss: 2.1744956572850547

Epoch: 6| Step: 11
Training loss: 1.693234920501709
Validation loss: 2.171895225842794

Epoch: 6| Step: 12
Training loss: 2.066286325454712
Validation loss: 2.188904106616974

Epoch: 6| Step: 13
Training loss: 1.72906494140625
Validation loss: 2.1975929737091064

Epoch: 232| Step: 0
Training loss: 2.0425779819488525
Validation loss: 2.1734653313954673

Epoch: 6| Step: 1
Training loss: 2.1999709606170654
Validation loss: 2.17985200881958

Epoch: 6| Step: 2
Training loss: 1.1907668113708496
Validation loss: 2.1936370134353638

Epoch: 6| Step: 3
Training loss: 1.8111672401428223
Validation loss: 2.162205080191294

Epoch: 6| Step: 4
Training loss: 1.129840612411499
Validation loss: 2.1594382325808206

Epoch: 6| Step: 5
Training loss: 1.976094365119934
Validation loss: 2.1708372831344604

Epoch: 6| Step: 6
Training loss: 1.8415406942367554
Validation loss: 2.1466737389564514

Epoch: 6| Step: 7
Training loss: 1.4733710289001465
Validation loss: 2.144188622633616

Epoch: 6| Step: 8
Training loss: 1.7449069023132324
Validation loss: 2.172809580961863

Epoch: 6| Step: 9
Training loss: 1.8767809867858887
Validation loss: 2.147975484530131

Epoch: 6| Step: 10
Training loss: 1.9200398921966553
Validation loss: 2.154159128665924

Epoch: 6| Step: 11
Training loss: 1.8987603187561035
Validation loss: 2.148053467273712

Epoch: 6| Step: 12
Training loss: 1.6833691596984863
Validation loss: 2.1584128538767495

Epoch: 6| Step: 13
Training loss: 1.624354362487793
Validation loss: 2.1535207629203796

Epoch: 233| Step: 0
Training loss: 1.8686598539352417
Validation loss: 2.1847285429636636

Epoch: 6| Step: 1
Training loss: 1.4956598281860352
Validation loss: 2.1768656770388284

Epoch: 6| Step: 2
Training loss: 1.8386826515197754
Validation loss: 2.208380480607351

Epoch: 6| Step: 3
Training loss: 1.5543925762176514
Validation loss: 2.175541579723358

Epoch: 6| Step: 4
Training loss: 2.0370028018951416
Validation loss: 2.183373967806498

Epoch: 6| Step: 5
Training loss: 1.289109230041504
Validation loss: 2.182677070299784

Epoch: 6| Step: 6
Training loss: 2.0467560291290283
Validation loss: 2.1808420618375144

Epoch: 6| Step: 7
Training loss: 1.522038459777832
Validation loss: 2.177659193674723

Epoch: 6| Step: 8
Training loss: 1.2394843101501465
Validation loss: 2.1817601124445596

Epoch: 6| Step: 9
Training loss: 2.3061647415161133
Validation loss: 2.1654550035794577

Epoch: 6| Step: 10
Training loss: 1.805410385131836
Validation loss: 2.184576233228048

Epoch: 6| Step: 11
Training loss: 1.6683833599090576
Validation loss: 2.1802948713302612

Epoch: 6| Step: 12
Training loss: 1.767305612564087
Validation loss: 2.193385680516561

Epoch: 6| Step: 13
Training loss: 2.269641876220703
Validation loss: 2.1712184151013694

Epoch: 234| Step: 0
Training loss: 1.9471070766448975
Validation loss: 2.1776407758394876

Epoch: 6| Step: 1
Training loss: 2.241518497467041
Validation loss: 2.1782894333203635

Epoch: 6| Step: 2
Training loss: 1.6168409585952759
Validation loss: 2.1827728748321533

Epoch: 6| Step: 3
Training loss: 1.740360975265503
Validation loss: 2.1624359687169394

Epoch: 6| Step: 4
Training loss: 1.6889309883117676
Validation loss: 2.1576792200406394

Epoch: 6| Step: 5
Training loss: 1.649642825126648
Validation loss: 2.194571554660797

Epoch: 6| Step: 6
Training loss: 1.696415662765503
Validation loss: 2.180143674214681

Epoch: 6| Step: 7
Training loss: 1.7365998029708862
Validation loss: 2.143408238887787

Epoch: 6| Step: 8
Training loss: 1.1986004114151
Validation loss: 2.1454413731892905

Epoch: 6| Step: 9
Training loss: 1.9618550539016724
Validation loss: 2.1417155265808105

Epoch: 6| Step: 10
Training loss: 1.7128245830535889
Validation loss: 2.1629441181818643

Epoch: 6| Step: 11
Training loss: 1.9010958671569824
Validation loss: 2.139838755130768

Epoch: 6| Step: 12
Training loss: 2.3660993576049805
Validation loss: 2.133705258369446

Epoch: 6| Step: 13
Training loss: 1.6992518901824951
Validation loss: 2.1617196798324585

Epoch: 235| Step: 0
Training loss: 1.3391165733337402
Validation loss: 2.1550031304359436

Epoch: 6| Step: 1
Training loss: 1.32780122756958
Validation loss: 2.1430026491483054

Epoch: 6| Step: 2
Training loss: 1.6918009519577026
Validation loss: 2.1755270957946777

Epoch: 6| Step: 3
Training loss: 2.0896735191345215
Validation loss: 2.163622816403707

Epoch: 6| Step: 4
Training loss: 2.2957370281219482
Validation loss: 2.1875665386517844

Epoch: 6| Step: 5
Training loss: 1.979729175567627
Validation loss: 2.1835755904515586

Epoch: 6| Step: 6
Training loss: 1.2364217042922974
Validation loss: 2.197365085283915

Epoch: 6| Step: 7
Training loss: 1.7305887937545776
Validation loss: 2.1868223746617637

Epoch: 6| Step: 8
Training loss: 2.358339309692383
Validation loss: 2.2049671014149985

Epoch: 6| Step: 9
Training loss: 1.353981375694275
Validation loss: 2.188870628674825

Epoch: 6| Step: 10
Training loss: 2.470400810241699
Validation loss: 2.2100791136423745

Epoch: 6| Step: 11
Training loss: 1.4667177200317383
Validation loss: 2.215337077776591

Epoch: 6| Step: 12
Training loss: 1.5982990264892578
Validation loss: 2.2049487829208374

Epoch: 6| Step: 13
Training loss: 1.2329185009002686
Validation loss: 2.2248476147651672

Epoch: 236| Step: 0
Training loss: 2.0964508056640625
Validation loss: 2.1800766388575235

Epoch: 6| Step: 1
Training loss: 1.5098075866699219
Validation loss: 2.213095724582672

Epoch: 6| Step: 2
Training loss: 2.1939480304718018
Validation loss: 2.209649403889974

Epoch: 6| Step: 3
Training loss: 1.392020583152771
Validation loss: 2.1952575047810874

Epoch: 6| Step: 4
Training loss: 1.3890643119812012
Validation loss: 2.1970468560854592

Epoch: 6| Step: 5
Training loss: 2.124460458755493
Validation loss: 2.182673931121826

Epoch: 6| Step: 6
Training loss: 2.4640979766845703
Validation loss: 2.1581252018610635

Epoch: 6| Step: 7
Training loss: 1.8572704792022705
Validation loss: 2.1617807149887085

Epoch: 6| Step: 8
Training loss: 1.7904542684555054
Validation loss: 2.1761639515558877

Epoch: 6| Step: 9
Training loss: 1.471780776977539
Validation loss: 2.175432006518046

Epoch: 6| Step: 10
Training loss: 2.0804197788238525
Validation loss: 2.180578291416168

Epoch: 6| Step: 11
Training loss: 0.9684886932373047
Validation loss: 2.1650776068369546

Epoch: 6| Step: 12
Training loss: 1.262570858001709
Validation loss: 2.2013337214787803

Epoch: 6| Step: 13
Training loss: 2.0731868743896484
Validation loss: 2.18808122475942

Epoch: 237| Step: 0
Training loss: 1.8671481609344482
Validation loss: 2.1970330675443015

Epoch: 6| Step: 1
Training loss: 1.3222241401672363
Validation loss: 2.1989691654841104

Epoch: 6| Step: 2
Training loss: 2.063412666320801
Validation loss: 2.1925190885861716

Epoch: 6| Step: 3
Training loss: 1.096923828125
Validation loss: 2.2078193028767905

Epoch: 6| Step: 4
Training loss: 1.34848153591156
Validation loss: 2.193138082822164

Epoch: 6| Step: 5
Training loss: 1.8340604305267334
Validation loss: 2.181423564751943

Epoch: 6| Step: 6
Training loss: 1.9276950359344482
Validation loss: 2.169006566206614

Epoch: 6| Step: 7
Training loss: 2.231455087661743
Validation loss: 2.158103267351786

Epoch: 6| Step: 8
Training loss: 2.234273910522461
Validation loss: 2.1749784549077353

Epoch: 6| Step: 9
Training loss: 1.7564765214920044
Validation loss: 2.1679947773615518

Epoch: 6| Step: 10
Training loss: 2.0738844871520996
Validation loss: 2.1765282352765403

Epoch: 6| Step: 11
Training loss: 1.4441089630126953
Validation loss: 2.1597065925598145

Epoch: 6| Step: 12
Training loss: 1.57035231590271
Validation loss: 2.184453248977661

Epoch: 6| Step: 13
Training loss: 1.9410711526870728
Validation loss: 2.1777232885360718

Epoch: 238| Step: 0
Training loss: 1.296026587486267
Validation loss: 2.209112524986267

Epoch: 6| Step: 1
Training loss: 1.5652439594268799
Validation loss: 2.217358628908793

Epoch: 6| Step: 2
Training loss: 1.7269368171691895
Validation loss: 2.239944895108541

Epoch: 6| Step: 3
Training loss: 2.047055244445801
Validation loss: 2.25264843304952

Epoch: 6| Step: 4
Training loss: 1.473660945892334
Validation loss: 2.23583447933197

Epoch: 6| Step: 5
Training loss: 1.5853512287139893
Validation loss: 2.225036938985189

Epoch: 6| Step: 6
Training loss: 1.6089521646499634
Validation loss: 2.1989919940630593

Epoch: 6| Step: 7
Training loss: 2.3640880584716797
Validation loss: 2.1935144662857056

Epoch: 6| Step: 8
Training loss: 1.4089558124542236
Validation loss: 2.200746695200602

Epoch: 6| Step: 9
Training loss: 2.312966823577881
Validation loss: 2.1687041521072388

Epoch: 6| Step: 10
Training loss: 1.2746458053588867
Validation loss: 2.18681792418162

Epoch: 6| Step: 11
Training loss: 1.8130829334259033
Validation loss: 2.1681936184565225

Epoch: 6| Step: 12
Training loss: 2.320970058441162
Validation loss: 2.1712926626205444

Epoch: 6| Step: 13
Training loss: 1.7688745260238647
Validation loss: 2.158632218837738

Epoch: 239| Step: 0
Training loss: 1.5073456764221191
Validation loss: 2.1539544264475503

Epoch: 6| Step: 1
Training loss: 2.0952327251434326
Validation loss: 2.1575734615325928

Epoch: 6| Step: 2
Training loss: 1.9328515529632568
Validation loss: 2.1599483291308084

Epoch: 6| Step: 3
Training loss: 1.717248797416687
Validation loss: 2.1513102054595947

Epoch: 6| Step: 4
Training loss: 2.7826786041259766
Validation loss: 2.1465763250986734

Epoch: 6| Step: 5
Training loss: 1.6275581121444702
Validation loss: 2.1771182815233865

Epoch: 6| Step: 6
Training loss: 1.8670440912246704
Validation loss: 2.1777661641438804

Epoch: 6| Step: 7
Training loss: 1.641785979270935
Validation loss: 2.1669004559516907

Epoch: 6| Step: 8
Training loss: 1.500857949256897
Validation loss: 2.176751136779785

Epoch: 6| Step: 9
Training loss: 1.833165168762207
Validation loss: 2.1717143853505454

Epoch: 6| Step: 10
Training loss: 1.3390902280807495
Validation loss: 2.1719749371210733

Epoch: 6| Step: 11
Training loss: 1.4841411113739014
Validation loss: 2.1741926272710166

Epoch: 6| Step: 12
Training loss: 1.452523946762085
Validation loss: 2.1771277586619058

Epoch: 6| Step: 13
Training loss: 1.9352853298187256
Validation loss: 2.1865654389063516

Epoch: 240| Step: 0
Training loss: 1.7651879787445068
Validation loss: 2.1692950328191123

Epoch: 6| Step: 1
Training loss: 1.7061643600463867
Validation loss: 2.174136221408844

Epoch: 6| Step: 2
Training loss: 1.68767511844635
Validation loss: 2.1982587973276773

Epoch: 6| Step: 3
Training loss: 1.8386282920837402
Validation loss: 2.186575770378113

Epoch: 6| Step: 4
Training loss: 1.7448556423187256
Validation loss: 2.1740883588790894

Epoch: 6| Step: 5
Training loss: 2.075831651687622
Validation loss: 2.1770965854326882

Epoch: 6| Step: 6
Training loss: 1.0658657550811768
Validation loss: 2.2032305002212524

Epoch: 6| Step: 7
Training loss: 2.106433629989624
Validation loss: 2.227383772532145

Epoch: 6| Step: 8
Training loss: 2.0759079456329346
Validation loss: 2.231748342514038

Epoch: 6| Step: 9
Training loss: 1.480787992477417
Validation loss: 2.185132145881653

Epoch: 6| Step: 10
Training loss: 1.8894829750061035
Validation loss: 2.176274379094442

Epoch: 6| Step: 11
Training loss: 1.6704649925231934
Validation loss: 2.1546940207481384

Epoch: 6| Step: 12
Training loss: 1.5178545713424683
Validation loss: 2.1577874024709067

Epoch: 6| Step: 13
Training loss: 1.991933822631836
Validation loss: 2.1343666315078735

Epoch: 241| Step: 0
Training loss: 2.2009501457214355
Validation loss: 2.1408663193384805

Epoch: 6| Step: 1
Training loss: 1.5698835849761963
Validation loss: 2.139812409877777

Epoch: 6| Step: 2
Training loss: 2.068589687347412
Validation loss: 2.1269242564837136

Epoch: 6| Step: 3
Training loss: 1.9497332572937012
Validation loss: 2.144540846347809

Epoch: 6| Step: 4
Training loss: 1.851409912109375
Validation loss: 2.152432143688202

Epoch: 6| Step: 5
Training loss: 1.262103796005249
Validation loss: 2.1545215845108032

Epoch: 6| Step: 6
Training loss: 2.0703012943267822
Validation loss: 2.1490677992502847

Epoch: 6| Step: 7
Training loss: 1.6704609394073486
Validation loss: 2.1581971844037375

Epoch: 6| Step: 8
Training loss: 1.5452017784118652
Validation loss: 2.1671682794888816

Epoch: 6| Step: 9
Training loss: 1.7565152645111084
Validation loss: 2.1612347761789956

Epoch: 6| Step: 10
Training loss: 2.701050281524658
Validation loss: 2.1611369848251343

Epoch: 6| Step: 11
Training loss: 1.8553712368011475
Validation loss: 2.1902524630228677

Epoch: 6| Step: 12
Training loss: 1.5947353839874268
Validation loss: 2.1596210598945618

Epoch: 6| Step: 13
Training loss: 1.2014391422271729
Validation loss: 2.164659063021342

Epoch: 242| Step: 0
Training loss: 1.6594127416610718
Validation loss: 2.1469608743985495

Epoch: 6| Step: 1
Training loss: 1.5164413452148438
Validation loss: 2.1608652075131736

Epoch: 6| Step: 2
Training loss: 1.676943302154541
Validation loss: 2.1615076859792075

Epoch: 6| Step: 3
Training loss: 2.159396171569824
Validation loss: 2.1757009625434875

Epoch: 6| Step: 4
Training loss: 1.541133165359497
Validation loss: 2.174075980981191

Epoch: 6| Step: 5
Training loss: 1.8849103450775146
Validation loss: 2.162551164627075

Epoch: 6| Step: 6
Training loss: 1.429295301437378
Validation loss: 2.1996851166089377

Epoch: 6| Step: 7
Training loss: 1.9498083591461182
Validation loss: 2.1914386550585427

Epoch: 6| Step: 8
Training loss: 2.0351011753082275
Validation loss: 2.203346232573191

Epoch: 6| Step: 9
Training loss: 1.310213327407837
Validation loss: 2.1670894821484885

Epoch: 6| Step: 10
Training loss: 1.154211401939392
Validation loss: 2.1638007958730063

Epoch: 6| Step: 11
Training loss: 2.223146677017212
Validation loss: 2.1827391187349954

Epoch: 6| Step: 12
Training loss: 2.054074287414551
Validation loss: 2.1664308110872903

Epoch: 6| Step: 13
Training loss: 1.8212509155273438
Validation loss: 2.1824546257654824

Epoch: 243| Step: 0
Training loss: 0.911288857460022
Validation loss: 2.1846742232640586

Epoch: 6| Step: 1
Training loss: 1.5664706230163574
Validation loss: 2.18056591351827

Epoch: 6| Step: 2
Training loss: 2.1809778213500977
Validation loss: 2.202312628428141

Epoch: 6| Step: 3
Training loss: 2.409026622772217
Validation loss: 2.1877042055130005

Epoch: 6| Step: 4
Training loss: 1.4550228118896484
Validation loss: 2.2205730279286704

Epoch: 6| Step: 5
Training loss: 2.261943817138672
Validation loss: 2.1840439240137735

Epoch: 6| Step: 6
Training loss: 1.8310272693634033
Validation loss: 2.1978593667348227

Epoch: 6| Step: 7
Training loss: 1.6802079677581787
Validation loss: 2.2075593868891397

Epoch: 6| Step: 8
Training loss: 1.0493335723876953
Validation loss: 2.220363179842631

Epoch: 6| Step: 9
Training loss: 1.4582219123840332
Validation loss: 2.2167332569758096

Epoch: 6| Step: 10
Training loss: 2.4425201416015625
Validation loss: 2.2335532506306968

Epoch: 6| Step: 11
Training loss: 1.2233085632324219
Validation loss: 2.235181748867035

Epoch: 6| Step: 12
Training loss: 1.681466817855835
Validation loss: 2.2087907791137695

Epoch: 6| Step: 13
Training loss: 1.8441746234893799
Validation loss: 2.2202059030532837

Epoch: 244| Step: 0
Training loss: 1.3092750310897827
Validation loss: 2.2285563151041665

Epoch: 6| Step: 1
Training loss: 1.9444661140441895
Validation loss: 2.2312580943107605

Epoch: 6| Step: 2
Training loss: 2.346068859100342
Validation loss: 2.2404865821202598

Epoch: 6| Step: 3
Training loss: 1.6899629831314087
Validation loss: 2.2144466439882913

Epoch: 6| Step: 4
Training loss: 1.594165325164795
Validation loss: 2.221752683321635

Epoch: 6| Step: 5
Training loss: 1.787477970123291
Validation loss: 2.2131906549135842

Epoch: 6| Step: 6
Training loss: 2.764997959136963
Validation loss: 2.2219561338424683

Epoch: 6| Step: 7
Training loss: 1.352183222770691
Validation loss: 2.186046580473582

Epoch: 6| Step: 8
Training loss: 1.5973780155181885
Validation loss: 2.222467005252838

Epoch: 6| Step: 9
Training loss: 1.5953563451766968
Validation loss: 2.1983069578806558

Epoch: 6| Step: 10
Training loss: 1.272359848022461
Validation loss: 2.190358559290568

Epoch: 6| Step: 11
Training loss: 1.6229805946350098
Validation loss: 2.213612894217173

Epoch: 6| Step: 12
Training loss: 1.1492335796356201
Validation loss: 2.2106924255688987

Epoch: 6| Step: 13
Training loss: 1.563184142112732
Validation loss: 2.189212679862976

Epoch: 245| Step: 0
Training loss: 1.9826580286026
Validation loss: 2.207915723323822

Epoch: 6| Step: 1
Training loss: 2.19826078414917
Validation loss: 2.2089820305506387

Epoch: 6| Step: 2
Training loss: 1.2347931861877441
Validation loss: 2.2003437280654907

Epoch: 6| Step: 3
Training loss: 1.614497423171997
Validation loss: 2.1769770781199136

Epoch: 6| Step: 4
Training loss: 1.3997312784194946
Validation loss: 2.2080037196477256

Epoch: 6| Step: 5
Training loss: 1.8763453960418701
Validation loss: 2.200372358163198

Epoch: 6| Step: 6
Training loss: 1.512000560760498
Validation loss: 2.2180993358294168

Epoch: 6| Step: 7
Training loss: 1.9043313264846802
Validation loss: 2.203046898047129

Epoch: 6| Step: 8
Training loss: 1.8068451881408691
Validation loss: 2.1652013063430786

Epoch: 6| Step: 9
Training loss: 2.26007080078125
Validation loss: 2.198853055636088

Epoch: 6| Step: 10
Training loss: 2.2304978370666504
Validation loss: 2.175132075945536

Epoch: 6| Step: 11
Training loss: 1.4270974397659302
Validation loss: 2.1672356724739075

Epoch: 6| Step: 12
Training loss: 1.785433053970337
Validation loss: 2.161190688610077

Epoch: 6| Step: 13
Training loss: 1.1642205715179443
Validation loss: 2.1727773944536843

Epoch: 246| Step: 0
Training loss: 1.430541753768921
Validation loss: 2.166849195957184

Epoch: 6| Step: 1
Training loss: 1.3757145404815674
Validation loss: 2.1565340558687844

Epoch: 6| Step: 2
Training loss: 2.5096964836120605
Validation loss: 2.168537457784017

Epoch: 6| Step: 3
Training loss: 1.295616626739502
Validation loss: 2.1594241857528687

Epoch: 6| Step: 4
Training loss: 1.7495181560516357
Validation loss: 2.163617650667826

Epoch: 6| Step: 5
Training loss: 1.1309152841567993
Validation loss: 2.16791961590449

Epoch: 6| Step: 6
Training loss: 2.3412911891937256
Validation loss: 2.1717003186543784

Epoch: 6| Step: 7
Training loss: 1.7586774826049805
Validation loss: 2.1796613136927285

Epoch: 6| Step: 8
Training loss: 1.475757122039795
Validation loss: 2.1672717134157815

Epoch: 6| Step: 9
Training loss: 1.5227419137954712
Validation loss: 2.1798332134882608

Epoch: 6| Step: 10
Training loss: 2.2217674255371094
Validation loss: 2.156156599521637

Epoch: 6| Step: 11
Training loss: 2.0056238174438477
Validation loss: 2.1865743001302085

Epoch: 6| Step: 12
Training loss: 1.204384207725525
Validation loss: 2.1391042470932007

Epoch: 6| Step: 13
Training loss: 1.9564900398254395
Validation loss: 2.172368665536245

Epoch: 247| Step: 0
Training loss: 1.5093131065368652
Validation loss: 2.1701470613479614

Epoch: 6| Step: 1
Training loss: 2.276966094970703
Validation loss: 2.1776341001192727

Epoch: 6| Step: 2
Training loss: 2.0166189670562744
Validation loss: 2.191457529862722

Epoch: 6| Step: 3
Training loss: 2.096654176712036
Validation loss: 2.2085569302241006

Epoch: 6| Step: 4
Training loss: 1.4539449214935303
Validation loss: 2.1907799442609153

Epoch: 6| Step: 5
Training loss: 1.7099822759628296
Validation loss: 2.179068863391876

Epoch: 6| Step: 6
Training loss: 1.5710515975952148
Validation loss: 2.183650096257528

Epoch: 6| Step: 7
Training loss: 1.35951566696167
Validation loss: 2.173810303211212

Epoch: 6| Step: 8
Training loss: 1.780618667602539
Validation loss: 2.1692628065745034

Epoch: 6| Step: 9
Training loss: 1.4977388381958008
Validation loss: 2.2007561127344766

Epoch: 6| Step: 10
Training loss: 1.6304491758346558
Validation loss: 2.179381271203359

Epoch: 6| Step: 11
Training loss: 1.2557674646377563
Validation loss: 2.1506158113479614

Epoch: 6| Step: 12
Training loss: 2.243412494659424
Validation loss: 2.16300505399704

Epoch: 6| Step: 13
Training loss: 1.2378902435302734
Validation loss: 2.1584046284357705

Epoch: 248| Step: 0
Training loss: 2.257080554962158
Validation loss: 2.172223369280497

Epoch: 6| Step: 1
Training loss: 1.46510648727417
Validation loss: 2.191063086191813

Epoch: 6| Step: 2
Training loss: 1.8073830604553223
Validation loss: 2.184214433034261

Epoch: 6| Step: 3
Training loss: 1.8332817554473877
Validation loss: 2.175064126650492

Epoch: 6| Step: 4
Training loss: 1.372717022895813
Validation loss: 2.181360383828481

Epoch: 6| Step: 5
Training loss: 2.101438045501709
Validation loss: 2.177430192629496

Epoch: 6| Step: 6
Training loss: 1.4452555179595947
Validation loss: 2.1858258644739785

Epoch: 6| Step: 7
Training loss: 2.237847328186035
Validation loss: 2.1832669576009116

Epoch: 6| Step: 8
Training loss: 1.4712741374969482
Validation loss: 2.2130261858304343

Epoch: 6| Step: 9
Training loss: 1.8546382188796997
Validation loss: 2.2214444080988565

Epoch: 6| Step: 10
Training loss: 1.5029044151306152
Validation loss: 2.235992709795634

Epoch: 6| Step: 11
Training loss: 1.412597417831421
Validation loss: 2.25636621316274

Epoch: 6| Step: 12
Training loss: 1.5193135738372803
Validation loss: 2.2575198809305825

Epoch: 6| Step: 13
Training loss: 1.957296371459961
Validation loss: 2.2437634468078613

Epoch: 249| Step: 0
Training loss: 1.9039623737335205
Validation loss: 2.2294944326082864

Epoch: 6| Step: 1
Training loss: 1.5892577171325684
Validation loss: 2.202040513356527

Epoch: 6| Step: 2
Training loss: 1.4466924667358398
Validation loss: 2.204555948575338

Epoch: 6| Step: 3
Training loss: 2.1999807357788086
Validation loss: 2.1932663520177207

Epoch: 6| Step: 4
Training loss: 1.5578949451446533
Validation loss: 2.1983032623926797

Epoch: 6| Step: 5
Training loss: 1.0266180038452148
Validation loss: 2.17897899945577

Epoch: 6| Step: 6
Training loss: 1.6772147417068481
Validation loss: 2.1779067715009055

Epoch: 6| Step: 7
Training loss: 1.91123366355896
Validation loss: 2.1539767185846963

Epoch: 6| Step: 8
Training loss: 1.9053459167480469
Validation loss: 2.176567554473877

Epoch: 6| Step: 9
Training loss: 1.8959420919418335
Validation loss: 2.1635901927948

Epoch: 6| Step: 10
Training loss: 1.5802085399627686
Validation loss: 2.149580438931783

Epoch: 6| Step: 11
Training loss: 1.571617603302002
Validation loss: 2.153579751650492

Epoch: 6| Step: 12
Training loss: 1.738060474395752
Validation loss: 2.1437701980272927

Epoch: 6| Step: 13
Training loss: 2.295457363128662
Validation loss: 2.1642202138900757

Epoch: 250| Step: 0
Training loss: 2.1210227012634277
Validation loss: 2.168858011563619

Epoch: 6| Step: 1
Training loss: 1.4705085754394531
Validation loss: 2.166625122229258

Epoch: 6| Step: 2
Training loss: 1.220372200012207
Validation loss: 2.1787563363711038

Epoch: 6| Step: 3
Training loss: 2.296154260635376
Validation loss: 2.165375848611196

Epoch: 6| Step: 4
Training loss: 2.1566193103790283
Validation loss: 2.152889867623647

Epoch: 6| Step: 5
Training loss: 1.7885668277740479
Validation loss: 2.1463247537612915

Epoch: 6| Step: 6
Training loss: 1.0674281120300293
Validation loss: 2.158406456311544

Epoch: 6| Step: 7
Training loss: 1.759230613708496
Validation loss: 2.1594768365224204

Epoch: 6| Step: 8
Training loss: 1.600438117980957
Validation loss: 2.1755663553873696

Epoch: 6| Step: 9
Training loss: 2.0460848808288574
Validation loss: 2.1683756907780967

Epoch: 6| Step: 10
Training loss: 1.6124143600463867
Validation loss: 2.1762386560440063

Epoch: 6| Step: 11
Training loss: 1.8823188543319702
Validation loss: 2.188909113407135

Epoch: 6| Step: 12
Training loss: 1.9515739679336548
Validation loss: 2.1963220636049905

Epoch: 6| Step: 13
Training loss: 1.0293670892715454
Validation loss: 2.2051005959510803

Epoch: 251| Step: 0
Training loss: 1.8298988342285156
Validation loss: 2.1966871420542398

Epoch: 6| Step: 1
Training loss: 1.6198532581329346
Validation loss: 2.202643096446991

Epoch: 6| Step: 2
Training loss: 1.7625617980957031
Validation loss: 2.181332548459371

Epoch: 6| Step: 3
Training loss: 1.899564266204834
Validation loss: 2.214742422103882

Epoch: 6| Step: 4
Training loss: 1.4791984558105469
Validation loss: 2.1868607004483542

Epoch: 6| Step: 5
Training loss: 1.6911503076553345
Validation loss: 2.1902068058649697

Epoch: 6| Step: 6
Training loss: 1.8917181491851807
Validation loss: 2.1994227965672812

Epoch: 6| Step: 7
Training loss: 3.089958906173706
Validation loss: 2.1982606848080954

Epoch: 6| Step: 8
Training loss: 1.324737787246704
Validation loss: 2.2116270065307617

Epoch: 6| Step: 9
Training loss: 1.3907455205917358
Validation loss: 2.204814374446869

Epoch: 6| Step: 10
Training loss: 1.6607928276062012
Validation loss: 2.188219348589579

Epoch: 6| Step: 11
Training loss: 1.7367202043533325
Validation loss: 2.200044552485148

Epoch: 6| Step: 12
Training loss: 1.1100213527679443
Validation loss: 2.193379839261373

Epoch: 6| Step: 13
Training loss: 1.3792450428009033
Validation loss: 2.166379531224569

Epoch: 252| Step: 0
Training loss: 1.5726722478866577
Validation loss: 2.187187393506368

Epoch: 6| Step: 1
Training loss: 1.6106456518173218
Validation loss: 2.1546910206476846

Epoch: 6| Step: 2
Training loss: 1.819044589996338
Validation loss: 2.1571419835090637

Epoch: 6| Step: 3
Training loss: 1.4278877973556519
Validation loss: 2.1655442913373313

Epoch: 6| Step: 4
Training loss: 1.26340651512146
Validation loss: 2.1342098712921143

Epoch: 6| Step: 5
Training loss: 1.4695440530776978
Validation loss: 2.1670747995376587

Epoch: 6| Step: 6
Training loss: 1.4430129528045654
Validation loss: 2.1918081442515054

Epoch: 6| Step: 7
Training loss: 2.2162976264953613
Validation loss: 2.1801626086235046

Epoch: 6| Step: 8
Training loss: 2.038348913192749
Validation loss: 2.1923362612724304

Epoch: 6| Step: 9
Training loss: 2.240461826324463
Validation loss: 2.1704342365264893

Epoch: 6| Step: 10
Training loss: 1.7270101308822632
Validation loss: 2.180882970492045

Epoch: 6| Step: 11
Training loss: 1.4379692077636719
Validation loss: 2.167270998160044

Epoch: 6| Step: 12
Training loss: 1.3362383842468262
Validation loss: 2.1763526797294617

Epoch: 6| Step: 13
Training loss: 2.110175132751465
Validation loss: 2.1464043855667114

Epoch: 253| Step: 0
Training loss: 1.6422758102416992
Validation loss: 2.1589874029159546

Epoch: 6| Step: 1
Training loss: 1.5220065116882324
Validation loss: 2.169325053691864

Epoch: 6| Step: 2
Training loss: 1.970524787902832
Validation loss: 2.161435842514038

Epoch: 6| Step: 3
Training loss: 1.5350327491760254
Validation loss: 2.158094028631846

Epoch: 6| Step: 4
Training loss: 1.6751363277435303
Validation loss: 2.181321064631144

Epoch: 6| Step: 5
Training loss: 1.821203351020813
Validation loss: 2.1942983667055764

Epoch: 6| Step: 6
Training loss: 1.5441031455993652
Validation loss: 2.185759345690409

Epoch: 6| Step: 7
Training loss: 1.6588916778564453
Validation loss: 2.176863193511963

Epoch: 6| Step: 8
Training loss: 1.539715051651001
Validation loss: 2.168104887008667

Epoch: 6| Step: 9
Training loss: 1.6808967590332031
Validation loss: 2.1660437981287637

Epoch: 6| Step: 10
Training loss: 1.4104931354522705
Validation loss: 2.19300905863444

Epoch: 6| Step: 11
Training loss: 2.118377447128296
Validation loss: 2.164505879084269

Epoch: 6| Step: 12
Training loss: 1.554584264755249
Validation loss: 2.182832419872284

Epoch: 6| Step: 13
Training loss: 1.9617564678192139
Validation loss: 2.2061224778493247

Epoch: 254| Step: 0
Training loss: 1.5997189283370972
Validation loss: 2.205229183038076

Epoch: 6| Step: 1
Training loss: 1.0929309129714966
Validation loss: 2.2053317626317344

Epoch: 6| Step: 2
Training loss: 1.6703975200653076
Validation loss: 2.206939955552419

Epoch: 6| Step: 3
Training loss: 1.6075053215026855
Validation loss: 2.2147634426752725

Epoch: 6| Step: 4
Training loss: 1.4584441184997559
Validation loss: 2.2048692305882773

Epoch: 6| Step: 5
Training loss: 1.1031780242919922
Validation loss: 2.2104185024897256

Epoch: 6| Step: 6
Training loss: 1.8646645545959473
Validation loss: 2.2337989807128906

Epoch: 6| Step: 7
Training loss: 2.4831228256225586
Validation loss: 2.2061155239741006

Epoch: 6| Step: 8
Training loss: 1.6861610412597656
Validation loss: 2.2073540091514587

Epoch: 6| Step: 9
Training loss: 1.9406588077545166
Validation loss: 2.21683661142985

Epoch: 6| Step: 10
Training loss: 1.8854191303253174
Validation loss: 2.1673782666524253

Epoch: 6| Step: 11
Training loss: 1.430687427520752
Validation loss: 2.168690005938212

Epoch: 6| Step: 12
Training loss: 1.3106213808059692
Validation loss: 2.2076727747917175

Epoch: 6| Step: 13
Training loss: 2.100818634033203
Validation loss: 2.189597467581431

Epoch: 255| Step: 0
Training loss: 1.0652189254760742
Validation loss: 2.202678402264913

Epoch: 6| Step: 1
Training loss: 2.3659400939941406
Validation loss: 2.218295176823934

Epoch: 6| Step: 2
Training loss: 2.7077231407165527
Validation loss: 2.1924115220705667

Epoch: 6| Step: 3
Training loss: 2.066331148147583
Validation loss: 2.2059070269266763

Epoch: 6| Step: 4
Training loss: 1.9469996690750122
Validation loss: 2.2220863699913025

Epoch: 6| Step: 5
Training loss: 1.695417881011963
Validation loss: 2.2185094753901162

Epoch: 6| Step: 6
Training loss: 1.1615495681762695
Validation loss: 2.218110501766205

Epoch: 6| Step: 7
Training loss: 1.7571654319763184
Validation loss: 2.190139134724935

Epoch: 6| Step: 8
Training loss: 1.874396562576294
Validation loss: 2.2013366421063743

Epoch: 6| Step: 9
Training loss: 1.1184425354003906
Validation loss: 2.2034659186999

Epoch: 6| Step: 10
Training loss: 1.7093406915664673
Validation loss: 2.197713037331899

Epoch: 6| Step: 11
Training loss: 1.4739950895309448
Validation loss: 2.22109983364741

Epoch: 6| Step: 12
Training loss: 1.1517521142959595
Validation loss: 2.2165461778640747

Epoch: 6| Step: 13
Training loss: 1.502840518951416
Validation loss: 2.1919418970743814

Epoch: 256| Step: 0
Training loss: 1.2039490938186646
Validation loss: 2.212583839893341

Epoch: 6| Step: 1
Training loss: 2.097323417663574
Validation loss: 2.1830008029937744

Epoch: 6| Step: 2
Training loss: 1.8134690523147583
Validation loss: 2.2058152556419373

Epoch: 6| Step: 3
Training loss: 1.3841755390167236
Validation loss: 2.1842500368754068

Epoch: 6| Step: 4
Training loss: 1.8095974922180176
Validation loss: 2.1815900405248008

Epoch: 6| Step: 5
Training loss: 1.6213771104812622
Validation loss: 2.1971559127171836

Epoch: 6| Step: 6
Training loss: 2.185192108154297
Validation loss: 2.1940455436706543

Epoch: 6| Step: 7
Training loss: 1.4368324279785156
Validation loss: 2.2028491298357644

Epoch: 6| Step: 8
Training loss: 1.8960795402526855
Validation loss: 2.18801212310791

Epoch: 6| Step: 9
Training loss: 1.420602560043335
Validation loss: 2.2046376864115396

Epoch: 6| Step: 10
Training loss: 1.4679244756698608
Validation loss: 2.203278124332428

Epoch: 6| Step: 11
Training loss: 2.139155864715576
Validation loss: 2.196674088637034

Epoch: 6| Step: 12
Training loss: 1.1218839883804321
Validation loss: 2.176391124725342

Epoch: 6| Step: 13
Training loss: 1.4828369617462158
Validation loss: 2.200241287549337

Epoch: 257| Step: 0
Training loss: 1.852173089981079
Validation loss: 2.1991170048713684

Epoch: 6| Step: 1
Training loss: 1.8875313997268677
Validation loss: 2.195925990740458

Epoch: 6| Step: 2
Training loss: 2.0256776809692383
Validation loss: 2.182668407758077

Epoch: 6| Step: 3
Training loss: 1.7576817274093628
Validation loss: 2.175071954727173

Epoch: 6| Step: 4
Training loss: 1.6274524927139282
Validation loss: 2.1897069613138833

Epoch: 6| Step: 5
Training loss: 1.6202731132507324
Validation loss: 2.1694467862447104

Epoch: 6| Step: 6
Training loss: 1.5683951377868652
Validation loss: 2.188420216242472

Epoch: 6| Step: 7
Training loss: 1.758857011795044
Validation loss: 2.1827359000841775

Epoch: 6| Step: 8
Training loss: 1.586320400238037
Validation loss: 2.174323836962382

Epoch: 6| Step: 9
Training loss: 0.8202654719352722
Validation loss: 2.1685946583747864

Epoch: 6| Step: 10
Training loss: 1.3088691234588623
Validation loss: 2.1756437619527182

Epoch: 6| Step: 11
Training loss: 1.80450439453125
Validation loss: 2.1637819608052573

Epoch: 6| Step: 12
Training loss: 1.7520952224731445
Validation loss: 2.1835121313730874

Epoch: 6| Step: 13
Training loss: 1.710550308227539
Validation loss: 2.1957271297772727

Epoch: 258| Step: 0
Training loss: 2.1635007858276367
Validation loss: 2.1988228956858316

Epoch: 6| Step: 1
Training loss: 1.7368838787078857
Validation loss: 2.181534747282664

Epoch: 6| Step: 2
Training loss: 1.024751901626587
Validation loss: 2.1793190836906433

Epoch: 6| Step: 3
Training loss: 1.9731183052062988
Validation loss: 2.2055057684580484

Epoch: 6| Step: 4
Training loss: 1.8062244653701782
Validation loss: 2.17855167388916

Epoch: 6| Step: 5
Training loss: 1.6034373044967651
Validation loss: 2.162857969601949

Epoch: 6| Step: 6
Training loss: 1.6407051086425781
Validation loss: 2.180855472882589

Epoch: 6| Step: 7
Training loss: 0.8869798183441162
Validation loss: 2.1890342434247336

Epoch: 6| Step: 8
Training loss: 1.607438087463379
Validation loss: 2.1779319643974304

Epoch: 6| Step: 9
Training loss: 1.7467120885849
Validation loss: 2.168728510538737

Epoch: 6| Step: 10
Training loss: 1.8814613819122314
Validation loss: 2.1746050318082175

Epoch: 6| Step: 11
Training loss: 1.6150858402252197
Validation loss: 2.174481769402822

Epoch: 6| Step: 12
Training loss: 1.591869831085205
Validation loss: 2.1939065059026084

Epoch: 6| Step: 13
Training loss: 1.6786489486694336
Validation loss: 2.1867779890696206

Epoch: 259| Step: 0
Training loss: 2.1003336906433105
Validation loss: 2.1759957671165466

Epoch: 6| Step: 1
Training loss: 1.6498627662658691
Validation loss: 2.153681755065918

Epoch: 6| Step: 2
Training loss: 2.7406229972839355
Validation loss: 2.1742056012153625

Epoch: 6| Step: 3
Training loss: 1.7620797157287598
Validation loss: 2.1714141567548118

Epoch: 6| Step: 4
Training loss: 1.5056105852127075
Validation loss: 2.1821228861808777

Epoch: 6| Step: 5
Training loss: 1.2688062191009521
Validation loss: 2.171556830406189

Epoch: 6| Step: 6
Training loss: 1.3900059461593628
Validation loss: 2.164304256439209

Epoch: 6| Step: 7
Training loss: 1.0064432621002197
Validation loss: 2.1656845808029175

Epoch: 6| Step: 8
Training loss: 1.8505486249923706
Validation loss: 2.1565508246421814

Epoch: 6| Step: 9
Training loss: 0.9647260904312134
Validation loss: 2.180555522441864

Epoch: 6| Step: 10
Training loss: 1.9949926137924194
Validation loss: 2.201610803604126

Epoch: 6| Step: 11
Training loss: 1.233502984046936
Validation loss: 2.24378236134847

Epoch: 6| Step: 12
Training loss: 1.7153186798095703
Validation loss: 2.234063446521759

Epoch: 6| Step: 13
Training loss: 2.010676622390747
Validation loss: 2.2173262238502502

Epoch: 260| Step: 0
Training loss: 2.0955569744110107
Validation loss: 2.237128218015035

Epoch: 6| Step: 1
Training loss: 1.8758594989776611
Validation loss: 2.231872280438741

Epoch: 6| Step: 2
Training loss: 2.206259250640869
Validation loss: 2.2575042247772217

Epoch: 6| Step: 3
Training loss: 2.2312049865722656
Validation loss: 2.234210252761841

Epoch: 6| Step: 4
Training loss: 2.285000801086426
Validation loss: 2.2181106408437095

Epoch: 6| Step: 5
Training loss: 2.0229742527008057
Validation loss: 2.2153395414352417

Epoch: 6| Step: 6
Training loss: 1.5404505729675293
Validation loss: 2.197085519631704

Epoch: 6| Step: 7
Training loss: 1.417839765548706
Validation loss: 2.215281367301941

Epoch: 6| Step: 8
Training loss: 1.5668165683746338
Validation loss: 2.17426464955012

Epoch: 6| Step: 9
Training loss: 1.1201395988464355
Validation loss: 2.1952559550603232

Epoch: 6| Step: 10
Training loss: 1.9390864372253418
Validation loss: 2.1934195359547934

Epoch: 6| Step: 11
Training loss: 1.2791610956192017
Validation loss: 2.1721168557802835

Epoch: 6| Step: 12
Training loss: 1.0235025882720947
Validation loss: 2.2038546204566956

Epoch: 6| Step: 13
Training loss: 1.3031775951385498
Validation loss: 2.1529336969057717

Epoch: 261| Step: 0
Training loss: 1.6329092979431152
Validation loss: 2.184789518515269

Epoch: 6| Step: 1
Training loss: 1.585280418395996
Validation loss: 2.1741613348325095

Epoch: 6| Step: 2
Training loss: 1.8965721130371094
Validation loss: 2.1772695779800415

Epoch: 6| Step: 3
Training loss: 1.5490778684616089
Validation loss: 2.1967210173606873

Epoch: 6| Step: 4
Training loss: 1.5417072772979736
Validation loss: 2.1947062015533447

Epoch: 6| Step: 5
Training loss: 1.1734111309051514
Validation loss: 2.2029733061790466

Epoch: 6| Step: 6
Training loss: 2.50742769241333
Validation loss: 2.190018614133199

Epoch: 6| Step: 7
Training loss: 1.1600033044815063
Validation loss: 2.20974991718928

Epoch: 6| Step: 8
Training loss: 1.9510234594345093
Validation loss: 2.216386079788208

Epoch: 6| Step: 9
Training loss: 1.4845294952392578
Validation loss: 2.2044668992360434

Epoch: 6| Step: 10
Training loss: 0.7867051362991333
Validation loss: 2.1856773296991983

Epoch: 6| Step: 11
Training loss: 2.4414024353027344
Validation loss: 2.1942528088887534

Epoch: 6| Step: 12
Training loss: 1.8749510049819946
Validation loss: 2.170846402645111

Epoch: 6| Step: 13
Training loss: 1.637709617614746
Validation loss: 2.2134591738382974

Epoch: 262| Step: 0
Training loss: 1.8292205333709717
Validation loss: 2.1740201512972512

Epoch: 6| Step: 1
Training loss: 1.8600637912750244
Validation loss: 2.1619028051694236

Epoch: 6| Step: 2
Training loss: 1.6362353563308716
Validation loss: 2.1654212474823

Epoch: 6| Step: 3
Training loss: 1.7363046407699585
Validation loss: 2.183490256468455

Epoch: 6| Step: 4
Training loss: 2.0478265285491943
Validation loss: 2.1759796738624573

Epoch: 6| Step: 5
Training loss: 2.3761682510375977
Validation loss: 2.1927685340245566

Epoch: 6| Step: 6
Training loss: 1.8159610033035278
Validation loss: 2.2114632725715637

Epoch: 6| Step: 7
Training loss: 1.573560118675232
Validation loss: 2.180074989795685

Epoch: 6| Step: 8
Training loss: 1.2888951301574707
Validation loss: 2.2004332343737283

Epoch: 6| Step: 9
Training loss: 1.4037775993347168
Validation loss: 2.156077027320862

Epoch: 6| Step: 10
Training loss: 1.6240968704223633
Validation loss: 2.1788576443990073

Epoch: 6| Step: 11
Training loss: 1.2705390453338623
Validation loss: 2.1570428212483725

Epoch: 6| Step: 12
Training loss: 1.8509926795959473
Validation loss: 2.2046538591384888

Epoch: 6| Step: 13
Training loss: 0.9515683650970459
Validation loss: 2.1644477049509683

Epoch: 263| Step: 0
Training loss: 1.5812649726867676
Validation loss: 2.177546481291453

Epoch: 6| Step: 1
Training loss: 1.474377155303955
Validation loss: 2.155122776826223

Epoch: 6| Step: 2
Training loss: 1.2202551364898682
Validation loss: 2.1725157697995505

Epoch: 6| Step: 3
Training loss: 1.502914547920227
Validation loss: 2.174980580806732

Epoch: 6| Step: 4
Training loss: 1.8515031337738037
Validation loss: 2.202486296494802

Epoch: 6| Step: 5
Training loss: 1.996193289756775
Validation loss: 2.160915732383728

Epoch: 6| Step: 6
Training loss: 1.6305044889450073
Validation loss: 2.1853549679120383

Epoch: 6| Step: 7
Training loss: 1.7986259460449219
Validation loss: 2.1715696652730307

Epoch: 6| Step: 8
Training loss: 1.8586740493774414
Validation loss: 2.1960397164026895

Epoch: 6| Step: 9
Training loss: 2.0864014625549316
Validation loss: 2.196690638860067

Epoch: 6| Step: 10
Training loss: 1.308068037033081
Validation loss: 2.175912082195282

Epoch: 6| Step: 11
Training loss: 2.3185503482818604
Validation loss: 2.199875553448995

Epoch: 6| Step: 12
Training loss: 1.3012747764587402
Validation loss: 2.187212506930033

Epoch: 6| Step: 13
Training loss: 1.1380945444107056
Validation loss: 2.1950435439745584

Epoch: 264| Step: 0
Training loss: 2.127570390701294
Validation loss: 2.202348053455353

Epoch: 6| Step: 1
Training loss: 1.1798930168151855
Validation loss: 2.1843964060147605

Epoch: 6| Step: 2
Training loss: 1.6536320447921753
Validation loss: 2.205495536327362

Epoch: 6| Step: 3
Training loss: 1.8610739707946777
Validation loss: 2.1922985514005027

Epoch: 6| Step: 4
Training loss: 1.9463977813720703
Validation loss: 2.207455297311147

Epoch: 6| Step: 5
Training loss: 1.0677410364151
Validation loss: 2.233871877193451

Epoch: 6| Step: 6
Training loss: 1.5528706312179565
Validation loss: 2.212425470352173

Epoch: 6| Step: 7
Training loss: 1.4217134714126587
Validation loss: 2.204423467318217

Epoch: 6| Step: 8
Training loss: 2.072582721710205
Validation loss: 2.2218337059020996

Epoch: 6| Step: 9
Training loss: 1.816568374633789
Validation loss: 2.1951180696487427

Epoch: 6| Step: 10
Training loss: 1.4182946681976318
Validation loss: 2.2323182622591653

Epoch: 6| Step: 11
Training loss: 2.337817430496216
Validation loss: 2.2330907185872397

Epoch: 6| Step: 12
Training loss: 1.299644112586975
Validation loss: 2.228218197822571

Epoch: 6| Step: 13
Training loss: 0.9992444515228271
Validation loss: 2.21790345509847

Epoch: 265| Step: 0
Training loss: 1.1384215354919434
Validation loss: 2.2223924001057944

Epoch: 6| Step: 1
Training loss: 1.4345829486846924
Validation loss: 2.216045300165812

Epoch: 6| Step: 2
Training loss: 1.3245420455932617
Validation loss: 2.213464856147766

Epoch: 6| Step: 3
Training loss: 1.6584913730621338
Validation loss: 2.2386029163996377

Epoch: 6| Step: 4
Training loss: 2.0643041133880615
Validation loss: 2.227955241998037

Epoch: 6| Step: 5
Training loss: 1.2064831256866455
Validation loss: 2.231779932975769

Epoch: 6| Step: 6
Training loss: 1.5533413887023926
Validation loss: 2.2020315527915955

Epoch: 6| Step: 7
Training loss: 1.6446127891540527
Validation loss: 2.207288940747579

Epoch: 6| Step: 8
Training loss: 1.0829734802246094
Validation loss: 2.186355928579966

Epoch: 6| Step: 9
Training loss: 2.37141489982605
Validation loss: 2.218243360519409

Epoch: 6| Step: 10
Training loss: 1.782074213027954
Validation loss: 2.195128401120504

Epoch: 6| Step: 11
Training loss: 1.8085107803344727
Validation loss: 2.20730451742808

Epoch: 6| Step: 12
Training loss: 2.0505423545837402
Validation loss: 2.182316521803538

Epoch: 6| Step: 13
Training loss: 1.810400128364563
Validation loss: 2.1762778560320535

Epoch: 266| Step: 0
Training loss: 1.3094794750213623
Validation loss: 2.160939633846283

Epoch: 6| Step: 1
Training loss: 2.214668035507202
Validation loss: 2.1573710640271506

Epoch: 6| Step: 2
Training loss: 1.5909411907196045
Validation loss: 2.1648743947347007

Epoch: 6| Step: 3
Training loss: 1.3390390872955322
Validation loss: 2.186667581399282

Epoch: 6| Step: 4
Training loss: 2.501046895980835
Validation loss: 2.201861083507538

Epoch: 6| Step: 5
Training loss: 0.8648326396942139
Validation loss: 2.2046268781026206

Epoch: 6| Step: 6
Training loss: 1.5336835384368896
Validation loss: 2.177324970563253

Epoch: 6| Step: 7
Training loss: 1.6869046688079834
Validation loss: 2.1996235450108848

Epoch: 6| Step: 8
Training loss: 1.2090280055999756
Validation loss: 2.2041757702827454

Epoch: 6| Step: 9
Training loss: 2.182098865509033
Validation loss: 2.169333517551422

Epoch: 6| Step: 10
Training loss: 0.9165173172950745
Validation loss: 2.193524956703186

Epoch: 6| Step: 11
Training loss: 1.501791000366211
Validation loss: 2.1752368410428367

Epoch: 6| Step: 12
Training loss: 1.855652928352356
Validation loss: 2.202861805756887

Epoch: 6| Step: 13
Training loss: 1.8896541595458984
Validation loss: 2.2209463715553284

Epoch: 267| Step: 0
Training loss: 2.2964725494384766
Validation loss: 2.1937219699223838

Epoch: 6| Step: 1
Training loss: 1.5782690048217773
Validation loss: 2.2178389628728232

Epoch: 6| Step: 2
Training loss: 1.824093222618103
Validation loss: 2.194850444793701

Epoch: 6| Step: 3
Training loss: 1.5485643148422241
Validation loss: 2.2057812213897705

Epoch: 6| Step: 4
Training loss: 1.2308896780014038
Validation loss: 2.189391851425171

Epoch: 6| Step: 5
Training loss: 1.9083136320114136
Validation loss: 2.188799182573954

Epoch: 6| Step: 6
Training loss: 1.2432823181152344
Validation loss: 2.1890955766042075

Epoch: 6| Step: 7
Training loss: 1.0927672386169434
Validation loss: 2.1683965921401978

Epoch: 6| Step: 8
Training loss: 2.113891124725342
Validation loss: 2.1501943667729697

Epoch: 6| Step: 9
Training loss: 1.6405665874481201
Validation loss: 2.14996991554896

Epoch: 6| Step: 10
Training loss: 1.6491791009902954
Validation loss: 2.181954801082611

Epoch: 6| Step: 11
Training loss: 1.2912838459014893
Validation loss: 2.184264143308004

Epoch: 6| Step: 12
Training loss: 1.2683851718902588
Validation loss: 2.1571140686670938

Epoch: 6| Step: 13
Training loss: 2.2707977294921875
Validation loss: 2.1929155786832175

Epoch: 268| Step: 0
Training loss: 0.9572150707244873
Validation loss: 2.2252090771993003

Epoch: 6| Step: 1
Training loss: 1.3923518657684326
Validation loss: 2.2236068646113076

Epoch: 6| Step: 2
Training loss: 2.1750681400299072
Validation loss: 2.24220601717631

Epoch: 6| Step: 3
Training loss: 1.274658203125
Validation loss: 2.2623285055160522

Epoch: 6| Step: 4
Training loss: 1.8906171321868896
Validation loss: 2.2273107369740806

Epoch: 6| Step: 5
Training loss: 2.190382957458496
Validation loss: 2.227155248324076

Epoch: 6| Step: 6
Training loss: 1.5619111061096191
Validation loss: 2.2376222014427185

Epoch: 6| Step: 7
Training loss: 1.8352746963500977
Validation loss: 2.1676616271336875

Epoch: 6| Step: 8
Training loss: 1.7335273027420044
Validation loss: 2.180972456932068

Epoch: 6| Step: 9
Training loss: 1.5631511211395264
Validation loss: 2.215900719165802

Epoch: 6| Step: 10
Training loss: 1.3202872276306152
Validation loss: 2.1982892950375876

Epoch: 6| Step: 11
Training loss: 1.9692379236221313
Validation loss: 2.225092093149821

Epoch: 6| Step: 12
Training loss: 1.9177634716033936
Validation loss: 2.1931116382280984

Epoch: 6| Step: 13
Training loss: 1.7408976554870605
Validation loss: 2.1930227279663086

Epoch: 269| Step: 0
Training loss: 2.197152853012085
Validation loss: 2.173271894454956

Epoch: 6| Step: 1
Training loss: 0.65763920545578
Validation loss: 2.20490034421285

Epoch: 6| Step: 2
Training loss: 1.2381443977355957
Validation loss: 2.171518564224243

Epoch: 6| Step: 3
Training loss: 1.877549409866333
Validation loss: 2.1562752723693848

Epoch: 6| Step: 4
Training loss: 1.2258296012878418
Validation loss: 2.198078374067942

Epoch: 6| Step: 5
Training loss: 2.615272045135498
Validation loss: 2.1819239457448325

Epoch: 6| Step: 6
Training loss: 1.5792440176010132
Validation loss: 2.20440810918808

Epoch: 6| Step: 7
Training loss: 2.0836474895477295
Validation loss: 2.2143004536628723

Epoch: 6| Step: 8
Training loss: 1.8799471855163574
Validation loss: 2.227283696333567

Epoch: 6| Step: 9
Training loss: 1.9991633892059326
Validation loss: 2.2435433864593506

Epoch: 6| Step: 10
Training loss: 1.6918907165527344
Validation loss: 2.251474996407827

Epoch: 6| Step: 11
Training loss: 1.3182114362716675
Validation loss: 2.229131817817688

Epoch: 6| Step: 12
Training loss: 2.043771266937256
Validation loss: 2.2333367268244424

Epoch: 6| Step: 13
Training loss: 1.1624293327331543
Validation loss: 2.1905792951583862

Epoch: 270| Step: 0
Training loss: 2.03633451461792
Validation loss: 2.2327585419019065

Epoch: 6| Step: 1
Training loss: 1.8619084358215332
Validation loss: 2.188139816125234

Epoch: 6| Step: 2
Training loss: 1.603946328163147
Validation loss: 2.163330892721812

Epoch: 6| Step: 3
Training loss: 1.2626597881317139
Validation loss: 2.17954428990682

Epoch: 6| Step: 4
Training loss: 1.6675132513046265
Validation loss: 2.174728433291117

Epoch: 6| Step: 5
Training loss: 1.5241787433624268
Validation loss: 2.1609472036361694

Epoch: 6| Step: 6
Training loss: 1.0146489143371582
Validation loss: 2.169489324092865

Epoch: 6| Step: 7
Training loss: 1.7153198719024658
Validation loss: 2.1581918597221375

Epoch: 6| Step: 8
Training loss: 1.5472396612167358
Validation loss: 2.1906341115633645

Epoch: 6| Step: 9
Training loss: 2.086081027984619
Validation loss: 2.180557429790497

Epoch: 6| Step: 10
Training loss: 1.9916406869888306
Validation loss: 2.1536516149838767

Epoch: 6| Step: 11
Training loss: 1.2080552577972412
Validation loss: 2.177745441595713

Epoch: 6| Step: 12
Training loss: 2.041395902633667
Validation loss: 2.205198645591736

Epoch: 6| Step: 13
Training loss: 1.869224190711975
Validation loss: 2.186425348122915

Epoch: 271| Step: 0
Training loss: 1.4100725650787354
Validation loss: 2.209260861078898

Epoch: 6| Step: 1
Training loss: 1.9896836280822754
Validation loss: 2.1703290740648904

Epoch: 6| Step: 2
Training loss: 1.329556941986084
Validation loss: 2.1886239647865295

Epoch: 6| Step: 3
Training loss: 1.9482556581497192
Validation loss: 2.1808777848879495

Epoch: 6| Step: 4
Training loss: 1.6647565364837646
Validation loss: 2.1761678059895835

Epoch: 6| Step: 5
Training loss: 1.7893154621124268
Validation loss: 2.145681937535604

Epoch: 6| Step: 6
Training loss: 1.674642562866211
Validation loss: 2.159386157989502

Epoch: 6| Step: 7
Training loss: 1.6997828483581543
Validation loss: 2.1729215184847512

Epoch: 6| Step: 8
Training loss: 1.7780674695968628
Validation loss: 2.1765044927597046

Epoch: 6| Step: 9
Training loss: 1.843284010887146
Validation loss: 2.162001371383667

Epoch: 6| Step: 10
Training loss: 1.3147951364517212
Validation loss: 2.162274440129598

Epoch: 6| Step: 11
Training loss: 1.6964902877807617
Validation loss: 2.1775077184041343

Epoch: 6| Step: 12
Training loss: 2.1655712127685547
Validation loss: 2.1987098852793374

Epoch: 6| Step: 13
Training loss: 1.4529006481170654
Validation loss: 2.2051525910695395

Epoch: 272| Step: 0
Training loss: 1.463826060295105
Validation loss: 2.2194000283877053

Epoch: 6| Step: 1
Training loss: 1.4632561206817627
Validation loss: 2.2310253977775574

Epoch: 6| Step: 2
Training loss: 1.6332828998565674
Validation loss: 2.2228691776593528

Epoch: 6| Step: 3
Training loss: 1.1885418891906738
Validation loss: 2.2257200876871743

Epoch: 6| Step: 4
Training loss: 1.855055332183838
Validation loss: 2.251602053642273

Epoch: 6| Step: 5
Training loss: 1.6484453678131104
Validation loss: 2.248034358024597

Epoch: 6| Step: 6
Training loss: 2.0661189556121826
Validation loss: 2.233222266038259

Epoch: 6| Step: 7
Training loss: 1.6071808338165283
Validation loss: 2.197671592235565

Epoch: 6| Step: 8
Training loss: 2.1515846252441406
Validation loss: 2.18914524714152

Epoch: 6| Step: 9
Training loss: 1.813664197921753
Validation loss: 2.1769485473632812

Epoch: 6| Step: 10
Training loss: 1.4878780841827393
Validation loss: 2.179872155189514

Epoch: 6| Step: 11
Training loss: 1.6580842733383179
Validation loss: 2.155479669570923

Epoch: 6| Step: 12
Training loss: 1.5171546936035156
Validation loss: 2.1574059327443442

Epoch: 6| Step: 13
Training loss: 1.40659499168396
Validation loss: 2.150984466075897

Epoch: 273| Step: 0
Training loss: 1.2852957248687744
Validation loss: 2.161672214667002

Epoch: 6| Step: 1
Training loss: 2.08921217918396
Validation loss: 2.1661711732546487

Epoch: 6| Step: 2
Training loss: 1.7431455850601196
Validation loss: 2.187612016995748

Epoch: 6| Step: 3
Training loss: 1.7853175401687622
Validation loss: 2.1715184450149536

Epoch: 6| Step: 4
Training loss: 1.6072688102722168
Validation loss: 2.1689246694246926

Epoch: 6| Step: 5
Training loss: 1.7338980436325073
Validation loss: 2.173986554145813

Epoch: 6| Step: 6
Training loss: 1.3911240100860596
Validation loss: 2.191991368929545

Epoch: 6| Step: 7
Training loss: 1.2249047756195068
Validation loss: 2.2021204233169556

Epoch: 6| Step: 8
Training loss: 2.8064839839935303
Validation loss: 2.2040728529294333

Epoch: 6| Step: 9
Training loss: 1.5773353576660156
Validation loss: 2.2229421138763428

Epoch: 6| Step: 10
Training loss: 1.5500967502593994
Validation loss: 2.215875188509623

Epoch: 6| Step: 11
Training loss: 1.904313325881958
Validation loss: 2.2395804723103843

Epoch: 6| Step: 12
Training loss: 0.9045705795288086
Validation loss: 2.202615479628245

Epoch: 6| Step: 13
Training loss: 1.8854084014892578
Validation loss: 2.23298043012619

Epoch: 274| Step: 0
Training loss: 1.4770877361297607
Validation loss: 2.216973880926768

Epoch: 6| Step: 1
Training loss: 1.6068055629730225
Validation loss: 2.1965730587641397

Epoch: 6| Step: 2
Training loss: 1.9821659326553345
Validation loss: 2.1810523867607117

Epoch: 6| Step: 3
Training loss: 2.528287887573242
Validation loss: 2.1737632354100547

Epoch: 6| Step: 4
Training loss: 1.384488821029663
Validation loss: 2.164537807305654

Epoch: 6| Step: 5
Training loss: 1.527604579925537
Validation loss: 2.1839518348375955

Epoch: 6| Step: 6
Training loss: 2.133021354675293
Validation loss: 2.1759580969810486

Epoch: 6| Step: 7
Training loss: 1.0595000982284546
Validation loss: 2.168132762114207

Epoch: 6| Step: 8
Training loss: 1.9065946340560913
Validation loss: 2.1615422566731772

Epoch: 6| Step: 9
Training loss: 1.2141655683517456
Validation loss: 2.1379562815030417

Epoch: 6| Step: 10
Training loss: 1.451451063156128
Validation loss: 2.1755645473798118

Epoch: 6| Step: 11
Training loss: 1.4666194915771484
Validation loss: 2.2100486358006797

Epoch: 6| Step: 12
Training loss: 1.1012442111968994
Validation loss: 2.1957728266716003

Epoch: 6| Step: 13
Training loss: 1.6651933193206787
Validation loss: 2.1954732735951743

Epoch: 275| Step: 0
Training loss: 1.190887451171875
Validation loss: 2.211710592110952

Epoch: 6| Step: 1
Training loss: 1.8307275772094727
Validation loss: 2.2342201670010886

Epoch: 6| Step: 2
Training loss: 2.0186705589294434
Validation loss: 2.221203605333964

Epoch: 6| Step: 3
Training loss: 1.5006732940673828
Validation loss: 2.2166796922683716

Epoch: 6| Step: 4
Training loss: 1.0175175666809082
Validation loss: 2.20473841826121

Epoch: 6| Step: 5
Training loss: 1.3260679244995117
Validation loss: 2.184253692626953

Epoch: 6| Step: 6
Training loss: 1.698270320892334
Validation loss: 2.2064623832702637

Epoch: 6| Step: 7
Training loss: 1.076049566268921
Validation loss: 2.203054924805959

Epoch: 6| Step: 8
Training loss: 1.8595091104507446
Validation loss: 2.1948182582855225

Epoch: 6| Step: 9
Training loss: 1.2124429941177368
Validation loss: 2.208010117212931

Epoch: 6| Step: 10
Training loss: 1.536928653717041
Validation loss: 2.206756134827932

Epoch: 6| Step: 11
Training loss: 2.2518601417541504
Validation loss: 2.206590930620829

Epoch: 6| Step: 12
Training loss: 2.184999942779541
Validation loss: 2.2123756408691406

Epoch: 6| Step: 13
Training loss: 1.987147331237793
Validation loss: 2.21319043636322

Epoch: 276| Step: 0
Training loss: 1.5339456796646118
Validation loss: 2.213876962661743

Epoch: 6| Step: 1
Training loss: 1.1733137369155884
Validation loss: 2.232711613178253

Epoch: 6| Step: 2
Training loss: 1.2189159393310547
Validation loss: 2.1823951403299966

Epoch: 6| Step: 3
Training loss: 1.8066240549087524
Validation loss: 2.183059016863505

Epoch: 6| Step: 4
Training loss: 1.2821661233901978
Validation loss: 2.189288318157196

Epoch: 6| Step: 5
Training loss: 1.2472530603408813
Validation loss: 2.1883193055788674

Epoch: 6| Step: 6
Training loss: 0.814586877822876
Validation loss: 2.1927006244659424

Epoch: 6| Step: 7
Training loss: 2.166105270385742
Validation loss: 2.211373805999756

Epoch: 6| Step: 8
Training loss: 1.5677673816680908
Validation loss: 2.2039204438527427

Epoch: 6| Step: 9
Training loss: 1.9537925720214844
Validation loss: 2.2264294226964316

Epoch: 6| Step: 10
Training loss: 1.5864200592041016
Validation loss: 2.2138420939445496

Epoch: 6| Step: 11
Training loss: 1.2061558961868286
Validation loss: 2.197008192539215

Epoch: 6| Step: 12
Training loss: 1.4772863388061523
Validation loss: 2.2278361916542053

Epoch: 6| Step: 13
Training loss: 3.300983428955078
Validation loss: 2.2083125511805215

Epoch: 277| Step: 0
Training loss: 1.772453784942627
Validation loss: 2.183294097582499

Epoch: 6| Step: 1
Training loss: 1.6096069812774658
Validation loss: 2.2306318084398904

Epoch: 6| Step: 2
Training loss: 0.8219597935676575
Validation loss: 2.192520280679067

Epoch: 6| Step: 3
Training loss: 1.508737325668335
Validation loss: 2.2106740872065225

Epoch: 6| Step: 4
Training loss: 1.4669355154037476
Validation loss: 2.2108625372250876

Epoch: 6| Step: 5
Training loss: 1.3306511640548706
Validation loss: 2.2174549102783203

Epoch: 6| Step: 6
Training loss: 2.1877832412719727
Validation loss: 2.1912700136502585

Epoch: 6| Step: 7
Training loss: 1.4442623853683472
Validation loss: 2.224528749783834

Epoch: 6| Step: 8
Training loss: 1.5720690488815308
Validation loss: 2.2143699725468955

Epoch: 6| Step: 9
Training loss: 1.6883739233016968
Validation loss: 2.1605742971102395

Epoch: 6| Step: 10
Training loss: 1.583064317703247
Validation loss: 2.1774895588556924

Epoch: 6| Step: 11
Training loss: 1.9327867031097412
Validation loss: 2.194922765096029

Epoch: 6| Step: 12
Training loss: 1.584416389465332
Validation loss: 2.195117990175883

Epoch: 6| Step: 13
Training loss: 1.8498378992080688
Validation loss: 2.1890517671902976

Epoch: 278| Step: 0
Training loss: 1.9132680892944336
Validation loss: 2.203295628229777

Epoch: 6| Step: 1
Training loss: 1.5109933614730835
Validation loss: 2.1615600188573203

Epoch: 6| Step: 2
Training loss: 1.4211468696594238
Validation loss: 2.182882785797119

Epoch: 6| Step: 3
Training loss: 1.310631513595581
Validation loss: 2.1900521516799927

Epoch: 6| Step: 4
Training loss: 1.4111862182617188
Validation loss: 2.182425538698832

Epoch: 6| Step: 5
Training loss: 1.5504580736160278
Validation loss: 2.1803977489471436

Epoch: 6| Step: 6
Training loss: 1.562599778175354
Validation loss: 2.193740169207255

Epoch: 6| Step: 7
Training loss: 1.9238128662109375
Validation loss: 2.2053687969843545

Epoch: 6| Step: 8
Training loss: 2.2655928134918213
Validation loss: 2.1796693007151284

Epoch: 6| Step: 9
Training loss: 1.0868345499038696
Validation loss: 2.182353953520457

Epoch: 6| Step: 10
Training loss: 2.1112847328186035
Validation loss: 2.1812921365102134

Epoch: 6| Step: 11
Training loss: 1.8149229288101196
Validation loss: 2.168972055117289

Epoch: 6| Step: 12
Training loss: 0.9818726181983948
Validation loss: 2.224695007006327

Epoch: 6| Step: 13
Training loss: 1.8724396228790283
Validation loss: 2.2031401991844177

Epoch: 279| Step: 0
Training loss: 1.4341317415237427
Validation loss: 2.202881375948588

Epoch: 6| Step: 1
Training loss: 1.7779014110565186
Validation loss: 2.2152475118637085

Epoch: 6| Step: 2
Training loss: 1.945096731185913
Validation loss: 2.2129644552866616

Epoch: 6| Step: 3
Training loss: 1.5971691608428955
Validation loss: 2.2308658758799234

Epoch: 6| Step: 4
Training loss: 1.1572625637054443
Validation loss: 2.2076024413108826

Epoch: 6| Step: 5
Training loss: 1.3466637134552002
Validation loss: 2.1982763210932412

Epoch: 6| Step: 6
Training loss: 1.695194125175476
Validation loss: 2.1840142607688904

Epoch: 6| Step: 7
Training loss: 1.467870831489563
Validation loss: 2.2102420330047607

Epoch: 6| Step: 8
Training loss: 2.273427724838257
Validation loss: 2.195998807748159

Epoch: 6| Step: 9
Training loss: 2.045358419418335
Validation loss: 2.2099063793818154

Epoch: 6| Step: 10
Training loss: 1.7268421649932861
Validation loss: 2.2239842812220254

Epoch: 6| Step: 11
Training loss: 1.8802061080932617
Validation loss: 2.2214001019795737

Epoch: 6| Step: 12
Training loss: 1.8614866733551025
Validation loss: 2.255954702695211

Epoch: 6| Step: 13
Training loss: 1.1241778135299683
Validation loss: 2.2704883217811584

Epoch: 280| Step: 0
Training loss: 1.2134740352630615
Validation loss: 2.252848664919535

Epoch: 6| Step: 1
Training loss: 1.9057152271270752
Validation loss: 2.2882068951924643

Epoch: 6| Step: 2
Training loss: 2.1625208854675293
Validation loss: 2.2549802660942078

Epoch: 6| Step: 3
Training loss: 1.358878493309021
Validation loss: 2.218521555264791

Epoch: 6| Step: 4
Training loss: 1.5167748928070068
Validation loss: 2.213601986567179

Epoch: 6| Step: 5
Training loss: 1.6406444311141968
Validation loss: 2.1846347649892173

Epoch: 6| Step: 6
Training loss: 1.7169873714447021
Validation loss: 2.201076646645864

Epoch: 6| Step: 7
Training loss: 1.4609129428863525
Validation loss: 2.2117920915285745

Epoch: 6| Step: 8
Training loss: 1.5785229206085205
Validation loss: 2.2201072176297507

Epoch: 6| Step: 9
Training loss: 1.6490418910980225
Validation loss: 2.197902023792267

Epoch: 6| Step: 10
Training loss: 2.279883861541748
Validation loss: 2.211498181025187

Epoch: 6| Step: 11
Training loss: 1.5521976947784424
Validation loss: 2.2004764874776206

Epoch: 6| Step: 12
Training loss: 1.313025951385498
Validation loss: 2.2136882742245994

Epoch: 6| Step: 13
Training loss: 1.5981025695800781
Validation loss: 2.1935701767603555

Epoch: 281| Step: 0
Training loss: 1.3557488918304443
Validation loss: 2.2162126898765564

Epoch: 6| Step: 1
Training loss: 1.7399088144302368
Validation loss: 2.232328712940216

Epoch: 6| Step: 2
Training loss: 1.3840526342391968
Validation loss: 2.2488701740900674

Epoch: 6| Step: 3
Training loss: 0.9061240553855896
Validation loss: 2.2491992314656577

Epoch: 6| Step: 4
Training loss: 2.1042556762695312
Validation loss: 2.2331892251968384

Epoch: 6| Step: 5
Training loss: 1.4769777059555054
Validation loss: 2.243575135866801

Epoch: 6| Step: 6
Training loss: 1.3072186708450317
Validation loss: 2.2192330757776895

Epoch: 6| Step: 7
Training loss: 1.697400689125061
Validation loss: 2.2171823978424072

Epoch: 6| Step: 8
Training loss: 1.2425436973571777
Validation loss: 2.208704193433126

Epoch: 6| Step: 9
Training loss: 1.7636053562164307
Validation loss: 2.21513032913208

Epoch: 6| Step: 10
Training loss: 2.177973747253418
Validation loss: 2.237315853436788

Epoch: 6| Step: 11
Training loss: 1.8064967393875122
Validation loss: 2.2033519546190896

Epoch: 6| Step: 12
Training loss: 1.648378849029541
Validation loss: 2.2264973322550454

Epoch: 6| Step: 13
Training loss: 2.068492889404297
Validation loss: 2.216672420501709

Epoch: 282| Step: 0
Training loss: 1.4350628852844238
Validation loss: 2.1986583471298218

Epoch: 6| Step: 1
Training loss: 1.60260009765625
Validation loss: 2.217540701230367

Epoch: 6| Step: 2
Training loss: 1.7945525646209717
Validation loss: 2.2157427867253623

Epoch: 6| Step: 3
Training loss: 1.2871458530426025
Validation loss: 2.21600733200709

Epoch: 6| Step: 4
Training loss: 2.133997917175293
Validation loss: 2.221083184083303

Epoch: 6| Step: 5
Training loss: 1.8877480030059814
Validation loss: 2.2413962682088218

Epoch: 6| Step: 6
Training loss: 1.6074950695037842
Validation loss: 2.2883450984954834

Epoch: 6| Step: 7
Training loss: 1.400191068649292
Validation loss: 2.2669355273246765

Epoch: 6| Step: 8
Training loss: 0.922295868396759
Validation loss: 2.24549134572347

Epoch: 6| Step: 9
Training loss: 2.306847095489502
Validation loss: 2.247008045514425

Epoch: 6| Step: 10
Training loss: 1.6389353275299072
Validation loss: 2.250711520512899

Epoch: 6| Step: 11
Training loss: 1.1292860507965088
Validation loss: 2.200082461039225

Epoch: 6| Step: 12
Training loss: 2.3883285522460938
Validation loss: 2.199006140232086

Epoch: 6| Step: 13
Training loss: 1.1967248916625977
Validation loss: 2.1973808209101358

Epoch: 283| Step: 0
Training loss: 2.2824254035949707
Validation loss: 2.1942941347757974

Epoch: 6| Step: 1
Training loss: 1.7495100498199463
Validation loss: 2.21756374835968

Epoch: 6| Step: 2
Training loss: 0.8064424991607666
Validation loss: 2.1977599064509072

Epoch: 6| Step: 3
Training loss: 1.6184885501861572
Validation loss: 2.207710921764374

Epoch: 6| Step: 4
Training loss: 1.2897312641143799
Validation loss: 2.226654907067617

Epoch: 6| Step: 5
Training loss: 2.223417282104492
Validation loss: 2.1941430966059365

Epoch: 6| Step: 6
Training loss: 2.143825054168701
Validation loss: 2.221295396486918

Epoch: 6| Step: 7
Training loss: 1.943677306175232
Validation loss: 2.2106309731801352

Epoch: 6| Step: 8
Training loss: 1.2023122310638428
Validation loss: 2.209894319375356

Epoch: 6| Step: 9
Training loss: 1.0979992151260376
Validation loss: 2.203244765599569

Epoch: 6| Step: 10
Training loss: 1.1614081859588623
Validation loss: 2.2461365262667337

Epoch: 6| Step: 11
Training loss: 1.2951698303222656
Validation loss: 2.258195618788401

Epoch: 6| Step: 12
Training loss: 1.8683247566223145
Validation loss: 2.282843907674154

Epoch: 6| Step: 13
Training loss: 1.6792759895324707
Validation loss: 2.267400542894999

Epoch: 284| Step: 0
Training loss: 1.7274404764175415
Validation loss: 2.229732632637024

Epoch: 6| Step: 1
Training loss: 1.5090988874435425
Validation loss: 2.226193924744924

Epoch: 6| Step: 2
Training loss: 1.8169801235198975
Validation loss: 2.242319385210673

Epoch: 6| Step: 3
Training loss: 1.2743918895721436
Validation loss: 2.2420337994893393

Epoch: 6| Step: 4
Training loss: 2.3474183082580566
Validation loss: 2.2066627542177835

Epoch: 6| Step: 5
Training loss: 1.8217769861221313
Validation loss: 2.2104268670082092

Epoch: 6| Step: 6
Training loss: 0.8123102784156799
Validation loss: 2.172553539276123

Epoch: 6| Step: 7
Training loss: 1.692128300666809
Validation loss: 2.195421894391378

Epoch: 6| Step: 8
Training loss: 1.641958475112915
Validation loss: 2.200806717077891

Epoch: 6| Step: 9
Training loss: 1.607776165008545
Validation loss: 2.19689804315567

Epoch: 6| Step: 10
Training loss: 1.664672613143921
Validation loss: 2.2118929028511047

Epoch: 6| Step: 11
Training loss: 0.9146062135696411
Validation loss: 2.2024803161621094

Epoch: 6| Step: 12
Training loss: 2.2928109169006348
Validation loss: 2.190186699231466

Epoch: 6| Step: 13
Training loss: 1.1680183410644531
Validation loss: 2.2109381755193076

Epoch: 285| Step: 0
Training loss: 2.3735318183898926
Validation loss: 2.2034494280815125

Epoch: 6| Step: 1
Training loss: 1.2911385297775269
Validation loss: 2.2165308396021524

Epoch: 6| Step: 2
Training loss: 1.3178648948669434
Validation loss: 2.2133107781410217

Epoch: 6| Step: 3
Training loss: 1.6510226726531982
Validation loss: 2.2316605846087136

Epoch: 6| Step: 4
Training loss: 1.3112339973449707
Validation loss: 2.237742781639099

Epoch: 6| Step: 5
Training loss: 1.6826997995376587
Validation loss: 2.227471172809601

Epoch: 6| Step: 6
Training loss: 1.3797112703323364
Validation loss: 2.237951715787252

Epoch: 6| Step: 7
Training loss: 1.8254483938217163
Validation loss: 2.217550575733185

Epoch: 6| Step: 8
Training loss: 1.0320141315460205
Validation loss: 2.197156230608622

Epoch: 6| Step: 9
Training loss: 1.7213867902755737
Validation loss: 2.189968148867289

Epoch: 6| Step: 10
Training loss: 1.7679061889648438
Validation loss: 2.177786866823832

Epoch: 6| Step: 11
Training loss: 1.561527132987976
Validation loss: 2.14370850721995

Epoch: 6| Step: 12
Training loss: 1.758914828300476
Validation loss: 2.1592562794685364

Epoch: 6| Step: 13
Training loss: 1.7942333221435547
Validation loss: 2.1771695812543235

Epoch: 286| Step: 0
Training loss: 1.0817264318466187
Validation loss: 2.2010757525761924

Epoch: 6| Step: 1
Training loss: 1.8761160373687744
Validation loss: 2.183119793732961

Epoch: 6| Step: 2
Training loss: 2.003998279571533
Validation loss: 2.1795501510302224

Epoch: 6| Step: 3
Training loss: 1.5636483430862427
Validation loss: 2.1739419301350913

Epoch: 6| Step: 4
Training loss: 1.4473341703414917
Validation loss: 2.1837339202562966

Epoch: 6| Step: 5
Training loss: 1.8563843965530396
Validation loss: 2.222123165925344

Epoch: 6| Step: 6
Training loss: 1.479499101638794
Validation loss: 2.2274044156074524

Epoch: 6| Step: 7
Training loss: 1.2475439310073853
Validation loss: 2.2141265273094177

Epoch: 6| Step: 8
Training loss: 1.5725879669189453
Validation loss: 2.1899410088857016

Epoch: 6| Step: 9
Training loss: 1.5977802276611328
Validation loss: 2.1975432435671487

Epoch: 6| Step: 10
Training loss: 1.1142083406448364
Validation loss: 2.2064165671666465

Epoch: 6| Step: 11
Training loss: 1.3919057846069336
Validation loss: 2.187471171220144

Epoch: 6| Step: 12
Training loss: 1.5591142177581787
Validation loss: 2.2138906915982566

Epoch: 6| Step: 13
Training loss: 2.0235087871551514
Validation loss: 2.1775333086649575

Epoch: 287| Step: 0
Training loss: 1.621146321296692
Validation loss: 2.1979408860206604

Epoch: 6| Step: 1
Training loss: 1.576786756515503
Validation loss: 2.213093717892965

Epoch: 6| Step: 2
Training loss: 1.5758881568908691
Validation loss: 2.197550137837728

Epoch: 6| Step: 3
Training loss: 1.5677714347839355
Validation loss: 2.1796836256980896

Epoch: 6| Step: 4
Training loss: 1.2063071727752686
Validation loss: 2.1913683811823526

Epoch: 6| Step: 5
Training loss: 1.8000423908233643
Validation loss: 2.183395346005758

Epoch: 6| Step: 6
Training loss: 1.448127031326294
Validation loss: 2.1731870770454407

Epoch: 6| Step: 7
Training loss: 1.647745966911316
Validation loss: 2.1744412581125894

Epoch: 6| Step: 8
Training loss: 1.8278886079788208
Validation loss: 2.188774049282074

Epoch: 6| Step: 9
Training loss: 1.6997474431991577
Validation loss: 2.17577197154363

Epoch: 6| Step: 10
Training loss: 1.341437578201294
Validation loss: 2.1927151481310525

Epoch: 6| Step: 11
Training loss: 1.8371754884719849
Validation loss: 2.1952831943829856

Epoch: 6| Step: 12
Training loss: 1.4671735763549805
Validation loss: 2.1799358328183494

Epoch: 6| Step: 13
Training loss: 1.6860429048538208
Validation loss: 2.1776451667149863

Epoch: 288| Step: 0
Training loss: 1.6377700567245483
Validation loss: 2.2376983563105264

Epoch: 6| Step: 1
Training loss: 2.033949851989746
Validation loss: 2.271638035774231

Epoch: 6| Step: 2
Training loss: 1.4613807201385498
Validation loss: 2.2426611185073853

Epoch: 6| Step: 3
Training loss: 1.2871356010437012
Validation loss: 2.2372488578160605

Epoch: 6| Step: 4
Training loss: 0.8892272710800171
Validation loss: 2.212081948916117

Epoch: 6| Step: 5
Training loss: 1.305312991142273
Validation loss: 2.199869533379873

Epoch: 6| Step: 6
Training loss: 2.218322277069092
Validation loss: 2.1903897523880005

Epoch: 6| Step: 7
Training loss: 1.9407685995101929
Validation loss: 2.1700831850369773

Epoch: 6| Step: 8
Training loss: 1.421026587486267
Validation loss: 2.1695587237675986

Epoch: 6| Step: 9
Training loss: 1.6871435642242432
Validation loss: 2.1868160565694175

Epoch: 6| Step: 10
Training loss: 2.3615641593933105
Validation loss: 2.182764768600464

Epoch: 6| Step: 11
Training loss: 1.2300081253051758
Validation loss: 2.184064527352651

Epoch: 6| Step: 12
Training loss: 1.4055380821228027
Validation loss: 2.1841067473093667

Epoch: 6| Step: 13
Training loss: 1.719283103942871
Validation loss: 2.1842257579167685

Epoch: 289| Step: 0
Training loss: 1.257230281829834
Validation loss: 2.1793057521184287

Epoch: 6| Step: 1
Training loss: 1.6104848384857178
Validation loss: 2.1814973751703897

Epoch: 6| Step: 2
Training loss: 1.9709559679031372
Validation loss: 2.1720133423805237

Epoch: 6| Step: 3
Training loss: 1.3726669549942017
Validation loss: 2.183392584323883

Epoch: 6| Step: 4
Training loss: 1.6068062782287598
Validation loss: 2.2022659381230674

Epoch: 6| Step: 5
Training loss: 1.2122222185134888
Validation loss: 2.18306040763855

Epoch: 6| Step: 6
Training loss: 1.186996579170227
Validation loss: 2.204363922278086

Epoch: 6| Step: 7
Training loss: 1.293663501739502
Validation loss: 2.2097554802894592

Epoch: 6| Step: 8
Training loss: 1.7302439212799072
Validation loss: 2.2237181266148887

Epoch: 6| Step: 9
Training loss: 1.4315205812454224
Validation loss: 2.237811823685964

Epoch: 6| Step: 10
Training loss: 1.172252893447876
Validation loss: 2.197207768758138

Epoch: 6| Step: 11
Training loss: 2.1660118103027344
Validation loss: 2.1780635714530945

Epoch: 6| Step: 12
Training loss: 1.897146224975586
Validation loss: 2.169563094774882

Epoch: 6| Step: 13
Training loss: 1.526163101196289
Validation loss: 2.1843008597691855

Epoch: 290| Step: 0
Training loss: 1.2539079189300537
Validation loss: 2.1686509251594543

Epoch: 6| Step: 1
Training loss: 1.6507749557495117
Validation loss: 2.192895313103994

Epoch: 6| Step: 2
Training loss: 1.8062729835510254
Validation loss: 2.187938690185547

Epoch: 6| Step: 3
Training loss: 0.7843379974365234
Validation loss: 2.1972539822260537

Epoch: 6| Step: 4
Training loss: 1.2688589096069336
Validation loss: 2.2084891200065613

Epoch: 6| Step: 5
Training loss: 1.469934344291687
Validation loss: 2.163293202718099

Epoch: 6| Step: 6
Training loss: 1.8807874917984009
Validation loss: 2.183494965235392

Epoch: 6| Step: 7
Training loss: 2.16253399848938
Validation loss: 2.1700584491093955

Epoch: 6| Step: 8
Training loss: 1.5981712341308594
Validation loss: 2.15406342347463

Epoch: 6| Step: 9
Training loss: 1.2594740390777588
Validation loss: 2.1524465878804526

Epoch: 6| Step: 10
Training loss: 1.9064313173294067
Validation loss: 2.1861522595087686

Epoch: 6| Step: 11
Training loss: 2.222175359725952
Validation loss: 2.1586639881134033

Epoch: 6| Step: 12
Training loss: 1.3258914947509766
Validation loss: 2.212543706099192

Epoch: 6| Step: 13
Training loss: 0.9858196973800659
Validation loss: 2.208749790986379

Epoch: 291| Step: 0
Training loss: 1.8322060108184814
Validation loss: 2.219488481680552

Epoch: 6| Step: 1
Training loss: 1.2019519805908203
Validation loss: 2.2485408584276834

Epoch: 6| Step: 2
Training loss: 1.299584984779358
Validation loss: 2.240295151869456

Epoch: 6| Step: 3
Training loss: 1.6261780261993408
Validation loss: 2.290431797504425

Epoch: 6| Step: 4
Training loss: 0.8168405294418335
Validation loss: 2.259724418322245

Epoch: 6| Step: 5
Training loss: 1.8365187644958496
Validation loss: 2.228191355864207

Epoch: 6| Step: 6
Training loss: 1.7375940084457397
Validation loss: 2.181577126185099

Epoch: 6| Step: 7
Training loss: 1.9772167205810547
Validation loss: 2.1851978103319802

Epoch: 6| Step: 8
Training loss: 1.785912036895752
Validation loss: 2.1720743974049888

Epoch: 6| Step: 9
Training loss: 1.9319628477096558
Validation loss: 2.21161687374115

Epoch: 6| Step: 10
Training loss: 1.5887666940689087
Validation loss: 2.178739388783773

Epoch: 6| Step: 11
Training loss: 2.1979544162750244
Validation loss: 2.1972522735595703

Epoch: 6| Step: 12
Training loss: 0.8004636168479919
Validation loss: 2.1869117816289267

Epoch: 6| Step: 13
Training loss: 1.475106954574585
Validation loss: 2.183193266391754

Epoch: 292| Step: 0
Training loss: 1.3653247356414795
Validation loss: 2.1467182437578836

Epoch: 6| Step: 1
Training loss: 1.679865837097168
Validation loss: 2.1691072583198547

Epoch: 6| Step: 2
Training loss: 1.2177244424819946
Validation loss: 2.1761262814203897

Epoch: 6| Step: 3
Training loss: 1.9058341979980469
Validation loss: 2.1492055654525757

Epoch: 6| Step: 4
Training loss: 1.5246747732162476
Validation loss: 2.210861086845398

Epoch: 6| Step: 5
Training loss: 1.9105618000030518
Validation loss: 2.1910725831985474

Epoch: 6| Step: 6
Training loss: 1.3909071683883667
Validation loss: 2.2024222215016684

Epoch: 6| Step: 7
Training loss: 2.546760082244873
Validation loss: 2.2267892758051553

Epoch: 6| Step: 8
Training loss: 2.162075996398926
Validation loss: 2.1960849165916443

Epoch: 6| Step: 9
Training loss: 1.552736759185791
Validation loss: 2.2078721125920615

Epoch: 6| Step: 10
Training loss: 1.1176681518554688
Validation loss: 2.179691473642985

Epoch: 6| Step: 11
Training loss: 0.9693774580955505
Validation loss: 2.1851070324579873

Epoch: 6| Step: 12
Training loss: 1.3518104553222656
Validation loss: 2.188224812348684

Epoch: 6| Step: 13
Training loss: 0.8585947155952454
Validation loss: 2.1981528600056968

Epoch: 293| Step: 0
Training loss: 2.2886574268341064
Validation loss: 2.173300564289093

Epoch: 6| Step: 1
Training loss: 1.8057174682617188
Validation loss: 2.1773940324783325

Epoch: 6| Step: 2
Training loss: 1.4804964065551758
Validation loss: 2.1901923418045044

Epoch: 6| Step: 3
Training loss: 2.312117576599121
Validation loss: 2.1912564436594644

Epoch: 6| Step: 4
Training loss: 1.738144874572754
Validation loss: 2.1848214070002236

Epoch: 6| Step: 5
Training loss: 1.4465880393981934
Validation loss: 2.190359592437744

Epoch: 6| Step: 6
Training loss: 1.1523511409759521
Validation loss: 2.2127007444699607

Epoch: 6| Step: 7
Training loss: 1.0379694700241089
Validation loss: 2.190827568372091

Epoch: 6| Step: 8
Training loss: 1.7505266666412354
Validation loss: 2.2051595052083335

Epoch: 6| Step: 9
Training loss: 1.0625030994415283
Validation loss: 2.225477655728658

Epoch: 6| Step: 10
Training loss: 1.3512673377990723
Validation loss: 2.229046583175659

Epoch: 6| Step: 11
Training loss: 1.3324220180511475
Validation loss: 2.2233195304870605

Epoch: 6| Step: 12
Training loss: 1.3879252672195435
Validation loss: 2.2338364919026694

Epoch: 6| Step: 13
Training loss: 1.6055110692977905
Validation loss: 2.242271900177002

Epoch: 294| Step: 0
Training loss: 1.7535810470581055
Validation loss: 2.1971428990364075

Epoch: 6| Step: 1
Training loss: 1.3762428760528564
Validation loss: 2.1916383504867554

Epoch: 6| Step: 2
Training loss: 1.0408202409744263
Validation loss: 2.198979993661245

Epoch: 6| Step: 3
Training loss: 1.937147617340088
Validation loss: 2.1543355782826743

Epoch: 6| Step: 4
Training loss: 1.0360220670700073
Validation loss: 2.1847572724024453

Epoch: 6| Step: 5
Training loss: 1.345194935798645
Validation loss: 2.152386744817098

Epoch: 6| Step: 6
Training loss: 1.060526728630066
Validation loss: 2.1548380057017007

Epoch: 6| Step: 7
Training loss: 1.2934911251068115
Validation loss: 2.130619843800863

Epoch: 6| Step: 8
Training loss: 1.4900989532470703
Validation loss: 2.166199346383413

Epoch: 6| Step: 9
Training loss: 1.6851615905761719
Validation loss: 2.1739646792411804

Epoch: 6| Step: 10
Training loss: 1.7191858291625977
Validation loss: 2.2201379537582397

Epoch: 6| Step: 11
Training loss: 2.4546573162078857
Validation loss: 2.2184842228889465

Epoch: 6| Step: 12
Training loss: 2.2550039291381836
Validation loss: 2.239685376485189

Epoch: 6| Step: 13
Training loss: 1.218635082244873
Validation loss: 2.245217800140381

Epoch: 295| Step: 0
Training loss: 1.6783232688903809
Validation loss: 2.230667511622111

Epoch: 6| Step: 1
Training loss: 1.1962575912475586
Validation loss: 2.1984076301256814

Epoch: 6| Step: 2
Training loss: 1.320540428161621
Validation loss: 2.1796972155570984

Epoch: 6| Step: 3
Training loss: 2.4339513778686523
Validation loss: 2.1573974887530007

Epoch: 6| Step: 4
Training loss: 1.8926148414611816
Validation loss: 2.1743359367052713

Epoch: 6| Step: 5
Training loss: 0.9563630819320679
Validation loss: 2.156770666440328

Epoch: 6| Step: 6
Training loss: 1.3861794471740723
Validation loss: 2.179592470328013

Epoch: 6| Step: 7
Training loss: 1.4773190021514893
Validation loss: 2.1911157170931497

Epoch: 6| Step: 8
Training loss: 1.5806519985198975
Validation loss: 2.1724663972854614

Epoch: 6| Step: 9
Training loss: 1.4883490800857544
Validation loss: 2.1634109814961753

Epoch: 6| Step: 10
Training loss: 1.1084431409835815
Validation loss: 2.166867991288503

Epoch: 6| Step: 11
Training loss: 1.896390438079834
Validation loss: 2.1608241399129233

Epoch: 6| Step: 12
Training loss: 1.539609432220459
Validation loss: 2.2130826512972512

Epoch: 6| Step: 13
Training loss: 1.8429094552993774
Validation loss: 2.2041675647099814

Epoch: 296| Step: 0
Training loss: 1.8453476428985596
Validation loss: 2.2188554604848227

Epoch: 6| Step: 1
Training loss: 1.3988368511199951
Validation loss: 2.2065513730049133

Epoch: 6| Step: 2
Training loss: 1.7341206073760986
Validation loss: 2.209452430407206

Epoch: 6| Step: 3
Training loss: 1.3676865100860596
Validation loss: 2.185606519381205

Epoch: 6| Step: 4
Training loss: 1.9888811111450195
Validation loss: 2.202058990796407

Epoch: 6| Step: 5
Training loss: 0.901278018951416
Validation loss: 2.2175110578536987

Epoch: 6| Step: 6
Training loss: 1.3720812797546387
Validation loss: 2.1636091470718384

Epoch: 6| Step: 7
Training loss: 1.162868618965149
Validation loss: 2.188011189301809

Epoch: 6| Step: 8
Training loss: 1.859269142150879
Validation loss: 2.186018784840902

Epoch: 6| Step: 9
Training loss: 1.8656072616577148
Validation loss: 2.179919441541036

Epoch: 6| Step: 10
Training loss: 1.0417301654815674
Validation loss: 2.215322216351827

Epoch: 6| Step: 11
Training loss: 1.5151185989379883
Validation loss: 2.179893175760905

Epoch: 6| Step: 12
Training loss: 1.2910288572311401
Validation loss: 2.2172470092773438

Epoch: 6| Step: 13
Training loss: 1.9828875064849854
Validation loss: 2.241446236769358

Epoch: 297| Step: 0
Training loss: 1.9324922561645508
Validation loss: 2.215157151222229

Epoch: 6| Step: 1
Training loss: 0.8373752236366272
Validation loss: 2.214809020360311

Epoch: 6| Step: 2
Training loss: 1.306213140487671
Validation loss: 2.2321564356486

Epoch: 6| Step: 3
Training loss: 1.1589688062667847
Validation loss: 2.248393932978312

Epoch: 6| Step: 4
Training loss: 1.3649847507476807
Validation loss: 2.240447004636129

Epoch: 6| Step: 5
Training loss: 1.5861756801605225
Validation loss: 2.2105289300282798

Epoch: 6| Step: 6
Training loss: 1.0133600234985352
Validation loss: 2.2115519046783447

Epoch: 6| Step: 7
Training loss: 1.5485880374908447
Validation loss: 2.205903728802999

Epoch: 6| Step: 8
Training loss: 2.6538429260253906
Validation loss: 2.195518950621287

Epoch: 6| Step: 9
Training loss: 1.854955792427063
Validation loss: 2.187542200088501

Epoch: 6| Step: 10
Training loss: 1.9470093250274658
Validation loss: 2.181065042813619

Epoch: 6| Step: 11
Training loss: 1.3974788188934326
Validation loss: 2.206531743208567

Epoch: 6| Step: 12
Training loss: 1.5452616214752197
Validation loss: 2.235730210940043

Epoch: 6| Step: 13
Training loss: 1.2377318143844604
Validation loss: 2.195716361204783

Epoch: 298| Step: 0
Training loss: 1.5451695919036865
Validation loss: 2.2480696638425193

Epoch: 6| Step: 1
Training loss: 1.4088947772979736
Validation loss: 2.232760965824127

Epoch: 6| Step: 2
Training loss: 0.9646301865577698
Validation loss: 2.2083014647165933

Epoch: 6| Step: 3
Training loss: 1.9695184230804443
Validation loss: 2.231467127799988

Epoch: 6| Step: 4
Training loss: 1.501649260520935
Validation loss: 2.187535266081492

Epoch: 6| Step: 5
Training loss: 1.4651390314102173
Validation loss: 2.2023112575213113

Epoch: 6| Step: 6
Training loss: 1.2760075330734253
Validation loss: 2.2111931244532266

Epoch: 6| Step: 7
Training loss: 1.3602728843688965
Validation loss: 2.197707494099935

Epoch: 6| Step: 8
Training loss: 1.2242567539215088
Validation loss: 2.225500305493673

Epoch: 6| Step: 9
Training loss: 1.4088940620422363
Validation loss: 2.1970943013827005

Epoch: 6| Step: 10
Training loss: 2.720806121826172
Validation loss: 2.1996530095736184

Epoch: 6| Step: 11
Training loss: 0.9743140935897827
Validation loss: 2.2033780415852866

Epoch: 6| Step: 12
Training loss: 2.299687385559082
Validation loss: 2.1950055360794067

Epoch: 6| Step: 13
Training loss: 2.213285207748413
Validation loss: 2.2065685391426086

Epoch: 299| Step: 0
Training loss: 1.1918206214904785
Validation loss: 2.2004948059717813

Epoch: 6| Step: 1
Training loss: 1.128273844718933
Validation loss: 2.2150689562161765

Epoch: 6| Step: 2
Training loss: 1.9880709648132324
Validation loss: 2.219347616036733

Epoch: 6| Step: 3
Training loss: 1.2107232809066772
Validation loss: 2.2248401443163552

Epoch: 6| Step: 4
Training loss: 1.2889094352722168
Validation loss: 2.2314505577087402

Epoch: 6| Step: 5
Training loss: 1.9174145460128784
Validation loss: 2.1863968769709268

Epoch: 6| Step: 6
Training loss: 1.3822730779647827
Validation loss: 2.255878130594889

Epoch: 6| Step: 7
Training loss: 1.3890899419784546
Validation loss: 2.198330303033193

Epoch: 6| Step: 8
Training loss: 1.2409648895263672
Validation loss: 2.1962236563364663

Epoch: 6| Step: 9
Training loss: 1.8214448690414429
Validation loss: 2.1917796532313027

Epoch: 6| Step: 10
Training loss: 1.6892638206481934
Validation loss: 2.145879030227661

Epoch: 6| Step: 11
Training loss: 1.2530958652496338
Validation loss: 2.168322225411733

Epoch: 6| Step: 12
Training loss: 2.15889310836792
Validation loss: 2.2036794821421304

Epoch: 6| Step: 13
Training loss: 1.151825189590454
Validation loss: 2.1939707597096763

Epoch: 300| Step: 0
Training loss: 2.2353131771087646
Validation loss: 2.1966729164123535

Epoch: 6| Step: 1
Training loss: 1.4147279262542725
Validation loss: 2.2385350267092385

Epoch: 6| Step: 2
Training loss: 1.2975358963012695
Validation loss: 2.2389748891194663

Epoch: 6| Step: 3
Training loss: 1.38450026512146
Validation loss: 2.2307591239611306

Epoch: 6| Step: 4
Training loss: 2.4378764629364014
Validation loss: 2.2179791927337646

Epoch: 6| Step: 5
Training loss: 1.2754580974578857
Validation loss: 2.2355334957440696

Epoch: 6| Step: 6
Training loss: 2.3805196285247803
Validation loss: 2.21429709593455

Epoch: 6| Step: 7
Training loss: 0.9133819341659546
Validation loss: 2.2072561780611673

Epoch: 6| Step: 8
Training loss: 1.1566495895385742
Validation loss: 2.1912051240603128

Epoch: 6| Step: 9
Training loss: 1.1366591453552246
Validation loss: 2.21363898118337

Epoch: 6| Step: 10
Training loss: 1.5796116590499878
Validation loss: 2.1879664262135825

Epoch: 6| Step: 11
Training loss: 2.091038703918457
Validation loss: 2.1896448532740274

Epoch: 6| Step: 12
Training loss: 1.0999746322631836
Validation loss: 2.175770322481791

Epoch: 6| Step: 13
Training loss: 1.104567050933838
Validation loss: 2.20293656984965

Epoch: 301| Step: 0
Training loss: 1.1031522750854492
Validation loss: 2.182534178098043

Epoch: 6| Step: 1
Training loss: 1.103384017944336
Validation loss: 2.2272942662239075

Epoch: 6| Step: 2
Training loss: 1.6150903701782227
Validation loss: 2.202674925327301

Epoch: 6| Step: 3
Training loss: 1.4397871494293213
Validation loss: 2.1960007150967917

Epoch: 6| Step: 4
Training loss: 1.5792624950408936
Validation loss: 2.198401470979055

Epoch: 6| Step: 5
Training loss: 1.4741640090942383
Validation loss: 2.189167936642965

Epoch: 6| Step: 6
Training loss: 1.4178646802902222
Validation loss: 2.195562163988749

Epoch: 6| Step: 7
Training loss: 1.1000217199325562
Validation loss: 2.175406575202942

Epoch: 6| Step: 8
Training loss: 0.9371333122253418
Validation loss: 2.201985994974772

Epoch: 6| Step: 9
Training loss: 2.0994129180908203
Validation loss: 2.168386161327362

Epoch: 6| Step: 10
Training loss: 1.632006049156189
Validation loss: 2.1894924441973367

Epoch: 6| Step: 11
Training loss: 2.020279884338379
Validation loss: 2.222290356953939

Epoch: 6| Step: 12
Training loss: 1.8788745403289795
Validation loss: 2.200043042500814

Epoch: 6| Step: 13
Training loss: 1.1201591491699219
Validation loss: 2.218736191590627

Epoch: 302| Step: 0
Training loss: 1.3242669105529785
Validation loss: 2.220736304918925

Epoch: 6| Step: 1
Training loss: 1.5382304191589355
Validation loss: 2.224264125029246

Epoch: 6| Step: 2
Training loss: 1.9908859729766846
Validation loss: 2.2293941179911294

Epoch: 6| Step: 3
Training loss: 1.6071982383728027
Validation loss: 2.1907427112261453

Epoch: 6| Step: 4
Training loss: 1.2866246700286865
Validation loss: 2.188013811906179

Epoch: 6| Step: 5
Training loss: 0.9564329385757446
Validation loss: 2.2191389004389444

Epoch: 6| Step: 6
Training loss: 1.520456314086914
Validation loss: 2.215188682079315

Epoch: 6| Step: 7
Training loss: 1.6410868167877197
Validation loss: 2.20278791586558

Epoch: 6| Step: 8
Training loss: 1.2339591979980469
Validation loss: 2.204173664251963

Epoch: 6| Step: 9
Training loss: 1.3317290544509888
Validation loss: 2.191507359345754

Epoch: 6| Step: 10
Training loss: 1.9357227087020874
Validation loss: 2.215009331703186

Epoch: 6| Step: 11
Training loss: 1.4664907455444336
Validation loss: 2.2004796663920083

Epoch: 6| Step: 12
Training loss: 1.9389053583145142
Validation loss: 2.220703601837158

Epoch: 6| Step: 13
Training loss: 1.4937946796417236
Validation loss: 2.2243599891662598

Epoch: 303| Step: 0
Training loss: 2.0129024982452393
Validation loss: 2.225672205289205

Epoch: 6| Step: 1
Training loss: 1.7132670879364014
Validation loss: 2.2309824426968894

Epoch: 6| Step: 2
Training loss: 1.4375088214874268
Validation loss: 2.2650185028711953

Epoch: 6| Step: 3
Training loss: 1.8058290481567383
Validation loss: 2.2546651363372803

Epoch: 6| Step: 4
Training loss: 1.4580001831054688
Validation loss: 2.264489233493805

Epoch: 6| Step: 5
Training loss: 1.85513436794281
Validation loss: 2.276313285032908

Epoch: 6| Step: 6
Training loss: 1.0164707899093628
Validation loss: 2.284844080607096

Epoch: 6| Step: 7
Training loss: 1.646960973739624
Validation loss: 2.260942975680033

Epoch: 6| Step: 8
Training loss: 1.1677539348602295
Validation loss: 2.20602415005366

Epoch: 6| Step: 9
Training loss: 1.8540468215942383
Validation loss: 2.2156572341918945

Epoch: 6| Step: 10
Training loss: 1.7617050409317017
Validation loss: 2.1932095686594644

Epoch: 6| Step: 11
Training loss: 1.3728303909301758
Validation loss: 2.205356220404307

Epoch: 6| Step: 12
Training loss: 1.4015735387802124
Validation loss: 2.2197327613830566

Epoch: 6| Step: 13
Training loss: 1.125600814819336
Validation loss: 2.1956470012664795

Epoch: 304| Step: 0
Training loss: 2.0502586364746094
Validation loss: 2.21765673160553

Epoch: 6| Step: 1
Training loss: 1.544195294380188
Validation loss: 2.2050998210906982

Epoch: 6| Step: 2
Training loss: 1.5745948553085327
Validation loss: 2.2222385803858438

Epoch: 6| Step: 3
Training loss: 1.4994745254516602
Validation loss: 2.2325421571731567

Epoch: 6| Step: 4
Training loss: 1.4595534801483154
Validation loss: 2.2181939284006753

Epoch: 6| Step: 5
Training loss: 1.6405436992645264
Validation loss: 2.1941725413004556

Epoch: 6| Step: 6
Training loss: 1.6224160194396973
Validation loss: 2.2389108141263327

Epoch: 6| Step: 7
Training loss: 0.975010097026825
Validation loss: 2.255005896091461

Epoch: 6| Step: 8
Training loss: 0.9490184187889099
Validation loss: 2.23812605937322

Epoch: 6| Step: 9
Training loss: 1.9052790403366089
Validation loss: 2.2877086400985718

Epoch: 6| Step: 10
Training loss: 1.6770590543746948
Validation loss: 2.2622978687286377

Epoch: 6| Step: 11
Training loss: 1.4976906776428223
Validation loss: 2.2529653112093606

Epoch: 6| Step: 12
Training loss: 1.0802874565124512
Validation loss: 2.229975422223409

Epoch: 6| Step: 13
Training loss: 1.5123331546783447
Validation loss: 2.244269609451294

Epoch: 305| Step: 0
Training loss: 1.4533170461654663
Validation loss: 2.2256412506103516

Epoch: 6| Step: 1
Training loss: 1.840144395828247
Validation loss: 2.225405514240265

Epoch: 6| Step: 2
Training loss: 1.0758311748504639
Validation loss: 2.2129069169362388

Epoch: 6| Step: 3
Training loss: 1.2248653173446655
Validation loss: 2.2232919335365295

Epoch: 6| Step: 4
Training loss: 1.2621614933013916
Validation loss: 2.2012763818105063

Epoch: 6| Step: 5
Training loss: 1.1780903339385986
Validation loss: 2.2061190207799277

Epoch: 6| Step: 6
Training loss: 1.281611680984497
Validation loss: 2.190678040186564

Epoch: 6| Step: 7
Training loss: 1.8506807088851929
Validation loss: 2.225355585416158

Epoch: 6| Step: 8
Training loss: 2.2802538871765137
Validation loss: 2.2372618118921914

Epoch: 6| Step: 9
Training loss: 1.7780752182006836
Validation loss: 2.21915735801061

Epoch: 6| Step: 10
Training loss: 0.9497300982475281
Validation loss: 2.220933735370636

Epoch: 6| Step: 11
Training loss: 1.276869535446167
Validation loss: 2.223243991533915

Epoch: 6| Step: 12
Training loss: 1.5070586204528809
Validation loss: 2.2625726461410522

Epoch: 6| Step: 13
Training loss: 1.6067320108413696
Validation loss: 2.2680316964785256

Epoch: 306| Step: 0
Training loss: 1.8914731740951538
Validation loss: 2.2861953179041543

Epoch: 6| Step: 1
Training loss: 1.6959803104400635
Validation loss: 2.28253573179245

Epoch: 6| Step: 2
Training loss: 1.5808484554290771
Validation loss: 2.2974138259887695

Epoch: 6| Step: 3
Training loss: 1.2230744361877441
Validation loss: 2.347558399041494

Epoch: 6| Step: 4
Training loss: 1.6103689670562744
Validation loss: 2.2973596254984536

Epoch: 6| Step: 5
Training loss: 1.9584987163543701
Validation loss: 2.262090265750885

Epoch: 6| Step: 6
Training loss: 1.7754583358764648
Validation loss: 2.2631324529647827

Epoch: 6| Step: 7
Training loss: 1.5500646829605103
Validation loss: 2.289945642153422

Epoch: 6| Step: 8
Training loss: 1.1627068519592285
Validation loss: 2.2603259881337485

Epoch: 6| Step: 9
Training loss: 1.3335751295089722
Validation loss: 2.2746967871983848

Epoch: 6| Step: 10
Training loss: 1.3813118934631348
Validation loss: 2.2591241796811423

Epoch: 6| Step: 11
Training loss: 1.6850624084472656
Validation loss: 2.2274491786956787

Epoch: 6| Step: 12
Training loss: 1.8333204984664917
Validation loss: 2.214081962903341

Epoch: 6| Step: 13
Training loss: 0.9700671434402466
Validation loss: 2.2583563725153604

Epoch: 307| Step: 0
Training loss: 1.9612646102905273
Validation loss: 2.234321097532908

Epoch: 6| Step: 1
Training loss: 1.56553316116333
Validation loss: 2.192151725292206

Epoch: 6| Step: 2
Training loss: 0.6024173498153687
Validation loss: 2.1953794161478677

Epoch: 6| Step: 3
Training loss: 1.0015352964401245
Validation loss: 2.183610995610555

Epoch: 6| Step: 4
Training loss: 0.990853488445282
Validation loss: 2.1782636245091758

Epoch: 6| Step: 5
Training loss: 1.6611605882644653
Validation loss: 2.184158464272817

Epoch: 6| Step: 6
Training loss: 1.8144757747650146
Validation loss: 2.1778770089149475

Epoch: 6| Step: 7
Training loss: 1.5779839754104614
Validation loss: 2.178097645441691

Epoch: 6| Step: 8
Training loss: 1.670175552368164
Validation loss: 2.2150373061498008

Epoch: 6| Step: 9
Training loss: 1.1207454204559326
Validation loss: 2.1920743385950723

Epoch: 6| Step: 10
Training loss: 1.0281791687011719
Validation loss: 2.221947173277537

Epoch: 6| Step: 11
Training loss: 1.0869497060775757
Validation loss: 2.212737739086151

Epoch: 6| Step: 12
Training loss: 2.103288412094116
Validation loss: 2.2156116167704263

Epoch: 6| Step: 13
Training loss: 2.386432647705078
Validation loss: 2.1715293327967324

Epoch: 308| Step: 0
Training loss: 0.8109169006347656
Validation loss: 2.1811835567156472

Epoch: 6| Step: 1
Training loss: 1.8640820980072021
Validation loss: 2.157101313273112

Epoch: 6| Step: 2
Training loss: 1.82541823387146
Validation loss: 2.207447648048401

Epoch: 6| Step: 3
Training loss: 1.662087082862854
Validation loss: 2.1781052549680076

Epoch: 6| Step: 4
Training loss: 1.5903910398483276
Validation loss: 2.2070826292037964

Epoch: 6| Step: 5
Training loss: 2.367295742034912
Validation loss: 2.151044805844625

Epoch: 6| Step: 6
Training loss: 1.6495537757873535
Validation loss: 2.1695051193237305

Epoch: 6| Step: 7
Training loss: 1.2620701789855957
Validation loss: 2.1957656939824424

Epoch: 6| Step: 8
Training loss: 1.5589125156402588
Validation loss: 2.2241090536117554

Epoch: 6| Step: 9
Training loss: 1.8180283308029175
Validation loss: 2.1930291255315146

Epoch: 6| Step: 10
Training loss: 1.115222692489624
Validation loss: 2.182492812474569

Epoch: 6| Step: 11
Training loss: 0.8992308378219604
Validation loss: 2.19660751024882

Epoch: 6| Step: 12
Training loss: 1.6289432048797607
Validation loss: 2.1807111700375876

Epoch: 6| Step: 13
Training loss: 1.0544191598892212
Validation loss: 2.2140637238820395

Epoch: 309| Step: 0
Training loss: 1.5960968732833862
Validation loss: 2.2225815852483115

Epoch: 6| Step: 1
Training loss: 2.042050361633301
Validation loss: 2.2290072639783225

Epoch: 6| Step: 2
Training loss: 1.2646300792694092
Validation loss: 2.195245345433553

Epoch: 6| Step: 3
Training loss: 1.136063814163208
Validation loss: 2.2255666653315225

Epoch: 6| Step: 4
Training loss: 2.2068939208984375
Validation loss: 2.229033430417379

Epoch: 6| Step: 5
Training loss: 1.526299238204956
Validation loss: 2.1872858802477517

Epoch: 6| Step: 6
Training loss: 1.5871928930282593
Validation loss: 2.1852245330810547

Epoch: 6| Step: 7
Training loss: 1.2849853038787842
Validation loss: 2.1766361395517984

Epoch: 6| Step: 8
Training loss: 1.5689198970794678
Validation loss: 2.174653967221578

Epoch: 6| Step: 9
Training loss: 1.170881748199463
Validation loss: 2.1845572193463645

Epoch: 6| Step: 10
Training loss: 0.9730503559112549
Validation loss: 2.1848251024881997

Epoch: 6| Step: 11
Training loss: 1.5206811428070068
Validation loss: 2.149528920650482

Epoch: 6| Step: 12
Training loss: 1.1586105823516846
Validation loss: 2.171090006828308

Epoch: 6| Step: 13
Training loss: 1.8417911529541016
Validation loss: 2.172001679738363

Epoch: 310| Step: 0
Training loss: 0.9856440424919128
Validation loss: 2.178272565205892

Epoch: 6| Step: 1
Training loss: 1.418022871017456
Validation loss: 2.2026300032933555

Epoch: 6| Step: 2
Training loss: 1.0257172584533691
Validation loss: 2.175987124443054

Epoch: 6| Step: 3
Training loss: 1.501670002937317
Validation loss: 2.209649384021759

Epoch: 6| Step: 4
Training loss: 1.1065328121185303
Validation loss: 2.211857279141744

Epoch: 6| Step: 5
Training loss: 1.2576606273651123
Validation loss: 2.2036969661712646

Epoch: 6| Step: 6
Training loss: 1.781291127204895
Validation loss: 2.2088585694630942

Epoch: 6| Step: 7
Training loss: 1.2779145240783691
Validation loss: 2.2085037231445312

Epoch: 6| Step: 8
Training loss: 1.4172338247299194
Validation loss: 2.2299444675445557

Epoch: 6| Step: 9
Training loss: 1.2071874141693115
Validation loss: 2.221040586630503

Epoch: 6| Step: 10
Training loss: 1.3095262050628662
Validation loss: 2.2112523714701333

Epoch: 6| Step: 11
Training loss: 2.39907169342041
Validation loss: 2.2145400444666543

Epoch: 6| Step: 12
Training loss: 1.8280200958251953
Validation loss: 2.203398366769155

Epoch: 6| Step: 13
Training loss: 1.8451646566390991
Validation loss: 2.1993601322174072

Epoch: 311| Step: 0
Training loss: 0.8862069249153137
Validation loss: 2.1933951377868652

Epoch: 6| Step: 1
Training loss: 1.218407392501831
Validation loss: 2.181517740090688

Epoch: 6| Step: 2
Training loss: 1.5356024503707886
Validation loss: 2.1765645146369934

Epoch: 6| Step: 3
Training loss: 2.933058500289917
Validation loss: 2.199815034866333

Epoch: 6| Step: 4
Training loss: 1.0177605152130127
Validation loss: 2.1861021518707275

Epoch: 6| Step: 5
Training loss: 1.2237954139709473
Validation loss: 2.1992374062538147

Epoch: 6| Step: 6
Training loss: 1.1567542552947998
Validation loss: 2.1802860498428345

Epoch: 6| Step: 7
Training loss: 1.0600621700286865
Validation loss: 2.218229333559672

Epoch: 6| Step: 8
Training loss: 1.5730308294296265
Validation loss: 2.191754778226217

Epoch: 6| Step: 9
Training loss: 1.548872709274292
Validation loss: 2.201531946659088

Epoch: 6| Step: 10
Training loss: 1.3683456182479858
Validation loss: 2.191284716129303

Epoch: 6| Step: 11
Training loss: 1.8534643650054932
Validation loss: 2.1956142584482827

Epoch: 6| Step: 12
Training loss: 1.237305760383606
Validation loss: 2.173155943552653

Epoch: 6| Step: 13
Training loss: 1.6934714317321777
Validation loss: 2.175296942392985

Epoch: 312| Step: 0
Training loss: 1.1943446397781372
Validation loss: 2.2340726057688394

Epoch: 6| Step: 1
Training loss: 1.154874324798584
Validation loss: 2.212238391240438

Epoch: 6| Step: 2
Training loss: 1.3436886072158813
Validation loss: 2.2004559437433877

Epoch: 6| Step: 3
Training loss: 1.2012674808502197
Validation loss: 2.1908652782440186

Epoch: 6| Step: 4
Training loss: 1.3395963907241821
Validation loss: 2.1991150180498757

Epoch: 6| Step: 5
Training loss: 1.489108681678772
Validation loss: 2.2093079686164856

Epoch: 6| Step: 6
Training loss: 1.6827540397644043
Validation loss: 2.186589320500692

Epoch: 6| Step: 7
Training loss: 1.1446459293365479
Validation loss: 2.1690938075383506

Epoch: 6| Step: 8
Training loss: 1.843348503112793
Validation loss: 2.1694140235582986

Epoch: 6| Step: 9
Training loss: 1.5873544216156006
Validation loss: 2.1799458662668862

Epoch: 6| Step: 10
Training loss: 1.458630084991455
Validation loss: 2.170093556245168

Epoch: 6| Step: 11
Training loss: 1.9003009796142578
Validation loss: 2.1993958155314126

Epoch: 6| Step: 12
Training loss: 1.297390103340149
Validation loss: 2.189169685045878

Epoch: 6| Step: 13
Training loss: 1.2807817459106445
Validation loss: 2.188454747200012

Epoch: 313| Step: 0
Training loss: 1.366312026977539
Validation loss: 2.2053739428520203

Epoch: 6| Step: 1
Training loss: 1.2861377000808716
Validation loss: 2.2082080443700156

Epoch: 6| Step: 2
Training loss: 1.316565752029419
Validation loss: 2.2225781679153442

Epoch: 6| Step: 3
Training loss: 1.1736177206039429
Validation loss: 2.22216933965683

Epoch: 6| Step: 4
Training loss: 1.9804394245147705
Validation loss: 2.200759689013163

Epoch: 6| Step: 5
Training loss: 1.8138070106506348
Validation loss: 2.2355414430300393

Epoch: 6| Step: 6
Training loss: 1.1567918062210083
Validation loss: 2.2452152172724404

Epoch: 6| Step: 7
Training loss: 1.8684136867523193
Validation loss: 2.2269940773646035

Epoch: 6| Step: 8
Training loss: 2.004183769226074
Validation loss: 2.229259649912516

Epoch: 6| Step: 9
Training loss: 1.635608434677124
Validation loss: 2.2407840490341187

Epoch: 6| Step: 10
Training loss: 1.5783798694610596
Validation loss: 2.2676769495010376

Epoch: 6| Step: 11
Training loss: 1.1907923221588135
Validation loss: 2.245522697766622

Epoch: 6| Step: 12
Training loss: 1.5084567070007324
Validation loss: 2.229337990283966

Epoch: 6| Step: 13
Training loss: 0.7778743505477905
Validation loss: 2.2520106434822083

Epoch: 314| Step: 0
Training loss: 1.3212659358978271
Validation loss: 2.2270784775416055

Epoch: 6| Step: 1
Training loss: 1.153048038482666
Validation loss: 2.2033711075782776

Epoch: 6| Step: 2
Training loss: 1.5174106359481812
Validation loss: 2.249054173628489

Epoch: 6| Step: 3
Training loss: 1.4876182079315186
Validation loss: 2.215885043144226

Epoch: 6| Step: 4
Training loss: 1.2262296676635742
Validation loss: 2.1981170972188315

Epoch: 6| Step: 5
Training loss: 1.5943354368209839
Validation loss: 2.218208690484365

Epoch: 6| Step: 6
Training loss: 1.9790196418762207
Validation loss: 2.223474701245626

Epoch: 6| Step: 7
Training loss: 1.781421184539795
Validation loss: 2.2047423124313354

Epoch: 6| Step: 8
Training loss: 1.1928880214691162
Validation loss: 2.2254606088002524

Epoch: 6| Step: 9
Training loss: 1.3936035633087158
Validation loss: 2.208481192588806

Epoch: 6| Step: 10
Training loss: 1.3983674049377441
Validation loss: 2.1963905493418374

Epoch: 6| Step: 11
Training loss: 1.653591513633728
Validation loss: 2.2029348015785217

Epoch: 6| Step: 12
Training loss: 1.0386658906936646
Validation loss: 2.236738125483195

Epoch: 6| Step: 13
Training loss: 1.1145641803741455
Validation loss: 2.2140654722849527

Epoch: 315| Step: 0
Training loss: 0.9421837329864502
Validation loss: 2.2028247912724814

Epoch: 6| Step: 1
Training loss: 1.1433355808258057
Validation loss: 2.1985965172449746

Epoch: 6| Step: 2
Training loss: 1.445846438407898
Validation loss: 2.236876289049784

Epoch: 6| Step: 3
Training loss: 0.9409099817276001
Validation loss: 2.2173537413279214

Epoch: 6| Step: 4
Training loss: 1.5718071460723877
Validation loss: 2.2041025161743164

Epoch: 6| Step: 5
Training loss: 1.6291396617889404
Validation loss: 2.20210333665212

Epoch: 6| Step: 6
Training loss: 1.9265216588974
Validation loss: 2.1958754857381186

Epoch: 6| Step: 7
Training loss: 1.48489511013031
Validation loss: 2.2003709077835083

Epoch: 6| Step: 8
Training loss: 1.7107895612716675
Validation loss: 2.2082444230715432

Epoch: 6| Step: 9
Training loss: 1.7114818096160889
Validation loss: 2.2106115023295083

Epoch: 6| Step: 10
Training loss: 1.1950840950012207
Validation loss: 2.218958795070648

Epoch: 6| Step: 11
Training loss: 0.9259827136993408
Validation loss: 2.2074593901634216

Epoch: 6| Step: 12
Training loss: 1.7363660335540771
Validation loss: 2.224486847718557

Epoch: 6| Step: 13
Training loss: 1.316865086555481
Validation loss: 2.235902567704519

Epoch: 316| Step: 0
Training loss: 1.8575464487075806
Validation loss: 2.269225796063741

Epoch: 6| Step: 1
Training loss: 1.77970290184021
Validation loss: 2.288292149702708

Epoch: 6| Step: 2
Training loss: 1.2421834468841553
Validation loss: 2.263292074203491

Epoch: 6| Step: 3
Training loss: 1.7421236038208008
Validation loss: 2.2493396600087485

Epoch: 6| Step: 4
Training loss: 0.8437172174453735
Validation loss: 2.2219794591267905

Epoch: 6| Step: 5
Training loss: 1.2864576578140259
Validation loss: 2.1693478425343833

Epoch: 6| Step: 6
Training loss: 1.8089230060577393
Validation loss: 2.1925616463025412

Epoch: 6| Step: 7
Training loss: 1.2703139781951904
Validation loss: 2.1701738238334656

Epoch: 6| Step: 8
Training loss: 0.9274817109107971
Validation loss: 2.1863139470418296

Epoch: 6| Step: 9
Training loss: 1.1941794157028198
Validation loss: 2.1728204091389975

Epoch: 6| Step: 10
Training loss: 1.3008875846862793
Validation loss: 2.2181026140848794

Epoch: 6| Step: 11
Training loss: 1.6614389419555664
Validation loss: 2.1619999607404075

Epoch: 6| Step: 12
Training loss: 1.9013361930847168
Validation loss: 2.2020813624064126

Epoch: 6| Step: 13
Training loss: 1.5960719585418701
Validation loss: 2.1910988092422485

Epoch: 317| Step: 0
Training loss: 1.3730641603469849
Validation loss: 2.210147738456726

Epoch: 6| Step: 1
Training loss: 1.2904173135757446
Validation loss: 2.2159764766693115

Epoch: 6| Step: 2
Training loss: 1.843312382698059
Validation loss: 2.2342061201731362

Epoch: 6| Step: 3
Training loss: 1.4714267253875732
Validation loss: 2.2132952213287354

Epoch: 6| Step: 4
Training loss: 1.236783742904663
Validation loss: 2.224701484044393

Epoch: 6| Step: 5
Training loss: 1.5130226612091064
Validation loss: 2.225315888722738

Epoch: 6| Step: 6
Training loss: 0.95853590965271
Validation loss: 2.2081018487612405

Epoch: 6| Step: 7
Training loss: 1.3331860303878784
Validation loss: 2.2227535247802734

Epoch: 6| Step: 8
Training loss: 1.3717546463012695
Validation loss: 2.226750592390696

Epoch: 6| Step: 9
Training loss: 1.5924489498138428
Validation loss: 2.2063229282697043

Epoch: 6| Step: 10
Training loss: 1.6729117631912231
Validation loss: 2.18941068649292

Epoch: 6| Step: 11
Training loss: 1.2705895900726318
Validation loss: 2.2414096792538962

Epoch: 6| Step: 12
Training loss: 1.2307746410369873
Validation loss: 2.2153087854385376

Epoch: 6| Step: 13
Training loss: 1.435948371887207
Validation loss: 2.2185907562573752

Epoch: 318| Step: 0
Training loss: 1.0082359313964844
Validation loss: 2.2078542908032737

Epoch: 6| Step: 1
Training loss: 1.4079375267028809
Validation loss: 2.2108044425646463

Epoch: 6| Step: 2
Training loss: 0.8001313209533691
Validation loss: 2.2124252915382385

Epoch: 6| Step: 3
Training loss: 1.0568324327468872
Validation loss: 2.2056585351626077

Epoch: 6| Step: 4
Training loss: 1.2411941289901733
Validation loss: 2.1676472822825112

Epoch: 6| Step: 5
Training loss: 1.4130752086639404
Validation loss: 2.15171217918396

Epoch: 6| Step: 6
Training loss: 1.8495277166366577
Validation loss: 2.2032531102498374

Epoch: 6| Step: 7
Training loss: 2.3569154739379883
Validation loss: 2.231461544831594

Epoch: 6| Step: 8
Training loss: 1.7139859199523926
Validation loss: 2.2195458014806113

Epoch: 6| Step: 9
Training loss: 1.5316526889801025
Validation loss: 2.215890884399414

Epoch: 6| Step: 10
Training loss: 0.8923776149749756
Validation loss: 2.2413993875185647

Epoch: 6| Step: 11
Training loss: 1.666360855102539
Validation loss: 2.225507219632467

Epoch: 6| Step: 12
Training loss: 1.366920828819275
Validation loss: 2.1731635530789695

Epoch: 6| Step: 13
Training loss: 1.5133817195892334
Validation loss: 2.1974712212880454

Epoch: 319| Step: 0
Training loss: 1.4949133396148682
Validation loss: 2.2215084632237754

Epoch: 6| Step: 1
Training loss: 1.1878595352172852
Validation loss: 2.17268176873525

Epoch: 6| Step: 2
Training loss: 1.7678375244140625
Validation loss: 2.1957940260569253

Epoch: 6| Step: 3
Training loss: 1.0697574615478516
Validation loss: 2.1983494559923806

Epoch: 6| Step: 4
Training loss: 1.7199780941009521
Validation loss: 2.2080837885538735

Epoch: 6| Step: 5
Training loss: 1.2478560209274292
Validation loss: 2.2122835715611777

Epoch: 6| Step: 6
Training loss: 1.0392920970916748
Validation loss: 2.192936440308889

Epoch: 6| Step: 7
Training loss: 1.7919564247131348
Validation loss: 2.225199739138285

Epoch: 6| Step: 8
Training loss: 1.3097145557403564
Validation loss: 2.194375157356262

Epoch: 6| Step: 9
Training loss: 1.0911903381347656
Validation loss: 2.225838541984558

Epoch: 6| Step: 10
Training loss: 1.3168785572052002
Validation loss: 2.2770605087280273

Epoch: 6| Step: 11
Training loss: 2.0192971229553223
Validation loss: 2.2170116901397705

Epoch: 6| Step: 12
Training loss: 2.015700340270996
Validation loss: 2.2216612100601196

Epoch: 6| Step: 13
Training loss: 0.7845808267593384
Validation loss: 2.1954973936080933

Epoch: 320| Step: 0
Training loss: 2.0179290771484375
Validation loss: 2.1977305014928183

Epoch: 6| Step: 1
Training loss: 1.341794729232788
Validation loss: 2.18272872765859

Epoch: 6| Step: 2
Training loss: 1.1625243425369263
Validation loss: 2.2065818508466086

Epoch: 6| Step: 3
Training loss: 1.0589582920074463
Validation loss: 2.1932937105496726

Epoch: 6| Step: 4
Training loss: 1.395567536354065
Validation loss: 2.233918865521749

Epoch: 6| Step: 5
Training loss: 0.9970231056213379
Validation loss: 2.2312602599461875

Epoch: 6| Step: 6
Training loss: 1.872132658958435
Validation loss: 2.242816070715586

Epoch: 6| Step: 7
Training loss: 1.5806748867034912
Validation loss: 2.2428450187047324

Epoch: 6| Step: 8
Training loss: 1.2117044925689697
Validation loss: 2.227662205696106

Epoch: 6| Step: 9
Training loss: 1.5678578615188599
Validation loss: 2.1880341172218323

Epoch: 6| Step: 10
Training loss: 1.353529930114746
Validation loss: 2.1954740285873413

Epoch: 6| Step: 11
Training loss: 1.584825038909912
Validation loss: 2.1995604236920676

Epoch: 6| Step: 12
Training loss: 0.7309247255325317
Validation loss: 2.198098878065745

Epoch: 6| Step: 13
Training loss: 1.6294442415237427
Validation loss: 2.2194810708363852

Epoch: 321| Step: 0
Training loss: 1.06742525100708
Validation loss: 2.2437663078308105

Epoch: 6| Step: 1
Training loss: 1.0820051431655884
Validation loss: 2.218244115511576

Epoch: 6| Step: 2
Training loss: 1.4703550338745117
Validation loss: 2.216154853502909

Epoch: 6| Step: 3
Training loss: 1.6896698474884033
Validation loss: 2.186474402745565

Epoch: 6| Step: 4
Training loss: 1.9172418117523193
Validation loss: 2.1515870690345764

Epoch: 6| Step: 5
Training loss: 0.868932843208313
Validation loss: 2.179201304912567

Epoch: 6| Step: 6
Training loss: 1.2115391492843628
Validation loss: 2.1699068943659463

Epoch: 6| Step: 7
Training loss: 1.2446072101593018
Validation loss: 2.177071670691172

Epoch: 6| Step: 8
Training loss: 1.8084163665771484
Validation loss: 2.1802923480669656

Epoch: 6| Step: 9
Training loss: 1.1377354860305786
Validation loss: 2.199985225995382

Epoch: 6| Step: 10
Training loss: 0.9558618068695068
Validation loss: 2.1872011025746665

Epoch: 6| Step: 11
Training loss: 1.9514460563659668
Validation loss: 2.2055237889289856

Epoch: 6| Step: 12
Training loss: 1.7584539651870728
Validation loss: 2.1953326066335044

Epoch: 6| Step: 13
Training loss: 1.2441426515579224
Validation loss: 2.24633659919103

Epoch: 322| Step: 0
Training loss: 1.7741549015045166
Validation loss: 2.223521331946055

Epoch: 6| Step: 1
Training loss: 1.5208148956298828
Validation loss: 2.24330464998881

Epoch: 6| Step: 2
Training loss: 1.5061193704605103
Validation loss: 2.2342742681503296

Epoch: 6| Step: 3
Training loss: 1.1614421606063843
Validation loss: 2.2100820938746133

Epoch: 6| Step: 4
Training loss: 1.4085534811019897
Validation loss: 2.183737655480703

Epoch: 6| Step: 5
Training loss: 1.4992947578430176
Validation loss: 2.197279612223307

Epoch: 6| Step: 6
Training loss: 1.2054816484451294
Validation loss: 2.220353980859121

Epoch: 6| Step: 7
Training loss: 1.0653984546661377
Validation loss: 2.2373542388280234

Epoch: 6| Step: 8
Training loss: 1.6996006965637207
Validation loss: 2.204749365647634

Epoch: 6| Step: 9
Training loss: 2.664816379547119
Validation loss: 2.2231265703837075

Epoch: 6| Step: 10
Training loss: 0.8420892953872681
Validation loss: 2.2237819830576577

Epoch: 6| Step: 11
Training loss: 0.6148214340209961
Validation loss: 2.193824847539266

Epoch: 6| Step: 12
Training loss: 1.4734594821929932
Validation loss: 2.189307471116384

Epoch: 6| Step: 13
Training loss: 1.4352443218231201
Validation loss: 2.2047025561332703

Epoch: 323| Step: 0
Training loss: 0.7341726422309875
Validation loss: 2.184263904889425

Epoch: 6| Step: 1
Training loss: 1.9490848779678345
Validation loss: 2.2221750815709433

Epoch: 6| Step: 2
Training loss: 1.4331504106521606
Validation loss: 2.2067575256029763

Epoch: 6| Step: 3
Training loss: 1.259174108505249
Validation loss: 2.223464568456014

Epoch: 6| Step: 4
Training loss: 1.1413263082504272
Validation loss: 2.1981250842412314

Epoch: 6| Step: 5
Training loss: 1.1835466623306274
Validation loss: 2.228955109914144

Epoch: 6| Step: 6
Training loss: 1.0516319274902344
Validation loss: 2.1954118609428406

Epoch: 6| Step: 7
Training loss: 1.3002511262893677
Validation loss: 2.2306277751922607

Epoch: 6| Step: 8
Training loss: 1.9272748231887817
Validation loss: 2.2120691339174905

Epoch: 6| Step: 9
Training loss: 1.1543995141983032
Validation loss: 2.220840275287628

Epoch: 6| Step: 10
Training loss: 2.450108051300049
Validation loss: 2.2483379443486533

Epoch: 6| Step: 11
Training loss: 0.984703540802002
Validation loss: 2.222706615924835

Epoch: 6| Step: 12
Training loss: 0.7752876281738281
Validation loss: 2.2561477422714233

Epoch: 6| Step: 13
Training loss: 2.0260169506073
Validation loss: 2.2522226770718894

Epoch: 324| Step: 0
Training loss: 1.222703456878662
Validation loss: 2.2731241385142007

Epoch: 6| Step: 1
Training loss: 1.5097053050994873
Validation loss: 2.2241151531537375

Epoch: 6| Step: 2
Training loss: 1.4719650745391846
Validation loss: 2.230566402276357

Epoch: 6| Step: 3
Training loss: 1.3638315200805664
Validation loss: 2.2318147818247476

Epoch: 6| Step: 4
Training loss: 1.2775588035583496
Validation loss: 2.241608500480652

Epoch: 6| Step: 5
Training loss: 1.0880954265594482
Validation loss: 2.2718594471613565

Epoch: 6| Step: 6
Training loss: 1.038103461265564
Validation loss: 2.2423418362935386

Epoch: 6| Step: 7
Training loss: 1.3443617820739746
Validation loss: 2.2191438476244607

Epoch: 6| Step: 8
Training loss: 1.5065412521362305
Validation loss: 2.237297236919403

Epoch: 6| Step: 9
Training loss: 1.056410551071167
Validation loss: 2.204556465148926

Epoch: 6| Step: 10
Training loss: 1.5494399070739746
Validation loss: 2.21695347627004

Epoch: 6| Step: 11
Training loss: 1.7418944835662842
Validation loss: 2.250802199045817

Epoch: 6| Step: 12
Training loss: 1.1847138404846191
Validation loss: 2.23472261428833

Epoch: 6| Step: 13
Training loss: 1.704742431640625
Validation loss: 2.2740416328112283

Epoch: 325| Step: 0
Training loss: 2.7039356231689453
Validation loss: 2.2494371136029563

Epoch: 6| Step: 1
Training loss: 0.810285747051239
Validation loss: 2.221240679423014

Epoch: 6| Step: 2
Training loss: 1.7471963167190552
Validation loss: 2.267324149608612

Epoch: 6| Step: 3
Training loss: 1.1491469144821167
Validation loss: 2.1987364888191223

Epoch: 6| Step: 4
Training loss: 1.1330362558364868
Validation loss: 2.2284172574679055

Epoch: 6| Step: 5
Training loss: 0.8027230501174927
Validation loss: 2.206203798453013

Epoch: 6| Step: 6
Training loss: 1.908632516860962
Validation loss: 2.220353901386261

Epoch: 6| Step: 7
Training loss: 1.5314737558364868
Validation loss: 2.2256805896759033

Epoch: 6| Step: 8
Training loss: 1.1987972259521484
Validation loss: 2.214144289493561

Epoch: 6| Step: 9
Training loss: 1.0587353706359863
Validation loss: 2.195331633090973

Epoch: 6| Step: 10
Training loss: 1.110605001449585
Validation loss: 2.208991209665934

Epoch: 6| Step: 11
Training loss: 1.271139144897461
Validation loss: 2.249084929625193

Epoch: 6| Step: 12
Training loss: 1.9088428020477295
Validation loss: 2.250170588493347

Epoch: 6| Step: 13
Training loss: 1.0640859603881836
Validation loss: 2.251466433207194

Epoch: 326| Step: 0
Training loss: 1.390122890472412
Validation loss: 2.236710170904795

Epoch: 6| Step: 1
Training loss: 1.1517294645309448
Validation loss: 2.2334546049435935

Epoch: 6| Step: 2
Training loss: 1.5196471214294434
Validation loss: 2.236987749735514

Epoch: 6| Step: 3
Training loss: 1.09591543674469
Validation loss: 2.180345356464386

Epoch: 6| Step: 4
Training loss: 2.1162004470825195
Validation loss: 2.209011952082316

Epoch: 6| Step: 5
Training loss: 1.5216975212097168
Validation loss: 2.173189322153727

Epoch: 6| Step: 6
Training loss: 1.6382192373275757
Validation loss: 2.2166767517725625

Epoch: 6| Step: 7
Training loss: 1.3340998888015747
Validation loss: 2.2076570192972818

Epoch: 6| Step: 8
Training loss: 1.0387442111968994
Validation loss: 2.202094395955404

Epoch: 6| Step: 9
Training loss: 0.954066276550293
Validation loss: 2.1935866276423135

Epoch: 6| Step: 10
Training loss: 1.2668405771255493
Validation loss: 2.2108629743258157

Epoch: 6| Step: 11
Training loss: 1.6466971635818481
Validation loss: 2.1934642990430198

Epoch: 6| Step: 12
Training loss: 1.9886815547943115
Validation loss: 2.2033211390177407

Epoch: 6| Step: 13
Training loss: 1.034624695777893
Validation loss: 2.1535003383954368

Epoch: 327| Step: 0
Training loss: 1.7582920789718628
Validation loss: 2.1804576317469277

Epoch: 6| Step: 1
Training loss: 1.0862128734588623
Validation loss: 2.1782647172609964

Epoch: 6| Step: 2
Training loss: 0.8820537328720093
Validation loss: 2.213905115922292

Epoch: 6| Step: 3
Training loss: 1.3963689804077148
Validation loss: 2.2013057669003806

Epoch: 6| Step: 4
Training loss: 1.2674086093902588
Validation loss: 2.2029855648676553

Epoch: 6| Step: 5
Training loss: 1.1648149490356445
Validation loss: 2.2102562189102173

Epoch: 6| Step: 6
Training loss: 1.3042043447494507
Validation loss: 2.1874709725379944

Epoch: 6| Step: 7
Training loss: 0.9862589836120605
Validation loss: 2.2174633344014487

Epoch: 6| Step: 8
Training loss: 1.368637204170227
Validation loss: 2.2017213106155396

Epoch: 6| Step: 9
Training loss: 2.1842353343963623
Validation loss: 2.183997313181559

Epoch: 6| Step: 10
Training loss: 2.1968631744384766
Validation loss: 2.207570234934489

Epoch: 6| Step: 11
Training loss: 1.11600923538208
Validation loss: 2.1751192013422647

Epoch: 6| Step: 12
Training loss: 1.2376303672790527
Validation loss: 2.2009292443593345

Epoch: 6| Step: 13
Training loss: 1.2746577262878418
Validation loss: 2.1957903802394867

Epoch: 328| Step: 0
Training loss: 0.69901442527771
Validation loss: 2.1996457974116006

Epoch: 6| Step: 1
Training loss: 1.4666463136672974
Validation loss: 2.2010250091552734

Epoch: 6| Step: 2
Training loss: 2.2483339309692383
Validation loss: 2.260822514692942

Epoch: 6| Step: 3
Training loss: 1.8892250061035156
Validation loss: 2.217028478781382

Epoch: 6| Step: 4
Training loss: 1.2711741924285889
Validation loss: 2.2422972122828164

Epoch: 6| Step: 5
Training loss: 1.8275315761566162
Validation loss: 2.228200137615204

Epoch: 6| Step: 6
Training loss: 0.8546442985534668
Validation loss: 2.238553742567698

Epoch: 6| Step: 7
Training loss: 1.4671993255615234
Validation loss: 2.2125292221705117

Epoch: 6| Step: 8
Training loss: 1.6363329887390137
Validation loss: 2.2679829200108848

Epoch: 6| Step: 9
Training loss: 1.2011526823043823
Validation loss: 2.204927464326223

Epoch: 6| Step: 10
Training loss: 1.397723913192749
Validation loss: 2.2353489001592

Epoch: 6| Step: 11
Training loss: 1.4424641132354736
Validation loss: 2.1983460585276284

Epoch: 6| Step: 12
Training loss: 0.8158081769943237
Validation loss: 2.18424383799235

Epoch: 6| Step: 13
Training loss: 1.2053935527801514
Validation loss: 2.2414886951446533

Epoch: 329| Step: 0
Training loss: 0.7220768332481384
Validation loss: 2.2003121972084045

Epoch: 6| Step: 1
Training loss: 1.9688926935195923
Validation loss: 2.2130720814069114

Epoch: 6| Step: 2
Training loss: 0.9757639169692993
Validation loss: 2.181105454762777

Epoch: 6| Step: 3
Training loss: 2.130652904510498
Validation loss: 2.2075182596842446

Epoch: 6| Step: 4
Training loss: 2.0036778450012207
Validation loss: 2.1829564968744912

Epoch: 6| Step: 5
Training loss: 0.69343501329422
Validation loss: 2.214250326156616

Epoch: 6| Step: 6
Training loss: 1.526281714439392
Validation loss: 2.2060501972834268

Epoch: 6| Step: 7
Training loss: 1.7356081008911133
Validation loss: 2.198559582233429

Epoch: 6| Step: 8
Training loss: 0.8724209070205688
Validation loss: 2.186560014883677

Epoch: 6| Step: 9
Training loss: 1.4221785068511963
Validation loss: 2.2253569761912027

Epoch: 6| Step: 10
Training loss: 1.0508354902267456
Validation loss: 2.213648796081543

Epoch: 6| Step: 11
Training loss: 1.2387480735778809
Validation loss: 2.2088635563850403

Epoch: 6| Step: 12
Training loss: 1.0609872341156006
Validation loss: 2.190136273701986

Epoch: 6| Step: 13
Training loss: 1.6616172790527344
Validation loss: 2.2213115294774375

Epoch: 330| Step: 0
Training loss: 1.101576328277588
Validation loss: 2.209640900293986

Epoch: 6| Step: 1
Training loss: 0.6929168701171875
Validation loss: 2.2065707246462503

Epoch: 6| Step: 2
Training loss: 1.3804128170013428
Validation loss: 2.1909476121266684

Epoch: 6| Step: 3
Training loss: 1.7476873397827148
Validation loss: 2.2136141459147134

Epoch: 6| Step: 4
Training loss: 1.7622458934783936
Validation loss: 2.209712545077006

Epoch: 6| Step: 5
Training loss: 1.451561689376831
Validation loss: 2.21596227089564

Epoch: 6| Step: 6
Training loss: 1.30739164352417
Validation loss: 2.231131633122762

Epoch: 6| Step: 7
Training loss: 1.4641621112823486
Validation loss: 2.214727799097697

Epoch: 6| Step: 8
Training loss: 1.0940110683441162
Validation loss: 2.2513092756271362

Epoch: 6| Step: 9
Training loss: 1.3696415424346924
Validation loss: 2.2118261456489563

Epoch: 6| Step: 10
Training loss: 1.7033605575561523
Validation loss: 2.227491776148478

Epoch: 6| Step: 11
Training loss: 1.4380388259887695
Validation loss: 2.232830266157786

Epoch: 6| Step: 12
Training loss: 0.6918483972549438
Validation loss: 2.2473031481107077

Epoch: 6| Step: 13
Training loss: 1.5535919666290283
Validation loss: 2.2329062620798745

Epoch: 331| Step: 0
Training loss: 0.8193129897117615
Validation loss: 2.2403764526049295

Epoch: 6| Step: 1
Training loss: 2.0099294185638428
Validation loss: 2.241724212964376

Epoch: 6| Step: 2
Training loss: 0.45770567655563354
Validation loss: 2.2211988965670266

Epoch: 6| Step: 3
Training loss: 0.9734822511672974
Validation loss: 2.201088825861613

Epoch: 6| Step: 4
Training loss: 1.6289618015289307
Validation loss: 2.2075440486272178

Epoch: 6| Step: 5
Training loss: 0.8750662207603455
Validation loss: 2.200121800104777

Epoch: 6| Step: 6
Training loss: 1.4452872276306152
Validation loss: 2.2028112610181174

Epoch: 6| Step: 7
Training loss: 1.8426345586776733
Validation loss: 2.2446440855662027

Epoch: 6| Step: 8
Training loss: 0.9563100337982178
Validation loss: 2.2191738287607827

Epoch: 6| Step: 9
Training loss: 2.104180335998535
Validation loss: 2.2031176884969077

Epoch: 6| Step: 10
Training loss: 1.6901628971099854
Validation loss: 2.1810819506645203

Epoch: 6| Step: 11
Training loss: 1.5744069814682007
Validation loss: 2.2114747365315757

Epoch: 6| Step: 12
Training loss: 1.074202537536621
Validation loss: 2.1896261175473533

Epoch: 6| Step: 13
Training loss: 1.2622848749160767
Validation loss: 2.1728054086367288

Epoch: 332| Step: 0
Training loss: 1.442114233970642
Validation loss: 2.1988547444343567

Epoch: 6| Step: 1
Training loss: 1.9762293100357056
Validation loss: 2.218434830506643

Epoch: 6| Step: 2
Training loss: 1.7691853046417236
Validation loss: 2.243364453315735

Epoch: 6| Step: 3
Training loss: 1.3116369247436523
Validation loss: 2.2510257164637246

Epoch: 6| Step: 4
Training loss: 0.9462099075317383
Validation loss: 2.2183907429377236

Epoch: 6| Step: 5
Training loss: 1.2798974514007568
Validation loss: 2.221280296643575

Epoch: 6| Step: 6
Training loss: 1.7411998510360718
Validation loss: 2.2814010779062905

Epoch: 6| Step: 7
Training loss: 1.9643844366073608
Validation loss: 2.235322813193003

Epoch: 6| Step: 8
Training loss: 0.8133313655853271
Validation loss: 2.247336427370707

Epoch: 6| Step: 9
Training loss: 0.7315881252288818
Validation loss: 2.2600395679473877

Epoch: 6| Step: 10
Training loss: 1.0272178649902344
Validation loss: 2.2498090068499246

Epoch: 6| Step: 11
Training loss: 1.7573354244232178
Validation loss: 2.2428917288780212

Epoch: 6| Step: 12
Training loss: 1.172210454940796
Validation loss: 2.2176946004231772

Epoch: 6| Step: 13
Training loss: 1.621990442276001
Validation loss: 2.197181781133016

Epoch: 333| Step: 0
Training loss: 1.0326741933822632
Validation loss: 2.207205812136332

Epoch: 6| Step: 1
Training loss: 2.088747262954712
Validation loss: 2.163281778494517

Epoch: 6| Step: 2
Training loss: 2.05492901802063
Validation loss: 2.1796080668767295

Epoch: 6| Step: 3
Training loss: 1.6167571544647217
Validation loss: 2.173473079999288

Epoch: 6| Step: 4
Training loss: 0.7866091728210449
Validation loss: 2.1650236447652182

Epoch: 6| Step: 5
Training loss: 0.7252928018569946
Validation loss: 2.1676857074101767

Epoch: 6| Step: 6
Training loss: 1.4967790842056274
Validation loss: 2.1981224020322165

Epoch: 6| Step: 7
Training loss: 1.8845728635787964
Validation loss: 2.194274922211965

Epoch: 6| Step: 8
Training loss: 1.2386627197265625
Validation loss: 2.20189501841863

Epoch: 6| Step: 9
Training loss: 1.2455850839614868
Validation loss: 2.229467233022054

Epoch: 6| Step: 10
Training loss: 1.3502321243286133
Validation loss: 2.229812959829966

Epoch: 6| Step: 11
Training loss: 1.3377978801727295
Validation loss: 2.2439163525899253

Epoch: 6| Step: 12
Training loss: 1.446297526359558
Validation loss: 2.240747570991516

Epoch: 6| Step: 13
Training loss: 1.4255428314208984
Validation loss: 2.2308963934580484

Epoch: 334| Step: 0
Training loss: 0.8565101623535156
Validation loss: 2.224487284819285

Epoch: 6| Step: 1
Training loss: 1.0526152849197388
Validation loss: 2.2241084575653076

Epoch: 6| Step: 2
Training loss: 1.2069653272628784
Validation loss: 2.1896166801452637

Epoch: 6| Step: 3
Training loss: 1.7396860122680664
Validation loss: 2.170668681462606

Epoch: 6| Step: 4
Training loss: 1.4017226696014404
Validation loss: 2.1655955712000527

Epoch: 6| Step: 5
Training loss: 1.698617696762085
Validation loss: 2.156651755174001

Epoch: 6| Step: 6
Training loss: 2.3842575550079346
Validation loss: 2.1596022049585977

Epoch: 6| Step: 7
Training loss: 1.2160600423812866
Validation loss: 2.214091102282206

Epoch: 6| Step: 8
Training loss: 1.9661275148391724
Validation loss: 2.221405307451884

Epoch: 6| Step: 9
Training loss: 1.9760133028030396
Validation loss: 2.213861266771952

Epoch: 6| Step: 10
Training loss: 0.8464550971984863
Validation loss: 2.2594090501467385

Epoch: 6| Step: 11
Training loss: 0.8035853505134583
Validation loss: 2.227310359477997

Epoch: 6| Step: 12
Training loss: 1.0498175621032715
Validation loss: 2.308311700820923

Epoch: 6| Step: 13
Training loss: 1.212695598602295
Validation loss: 2.2973368565241494

Epoch: 335| Step: 0
Training loss: 1.280198574066162
Validation loss: 2.288405259450277

Epoch: 6| Step: 1
Training loss: 1.569019079208374
Validation loss: 2.2733811140060425

Epoch: 6| Step: 2
Training loss: 1.824193000793457
Validation loss: 2.2430635690689087

Epoch: 6| Step: 3
Training loss: 1.3498351573944092
Validation loss: 2.217880129814148

Epoch: 6| Step: 4
Training loss: 1.4043490886688232
Validation loss: 2.2109557390213013

Epoch: 6| Step: 5
Training loss: 2.208494186401367
Validation loss: 2.208544890085856

Epoch: 6| Step: 6
Training loss: 1.5949211120605469
Validation loss: 2.218092123667399

Epoch: 6| Step: 7
Training loss: 0.9565673470497131
Validation loss: 2.1947092612584433

Epoch: 6| Step: 8
Training loss: 1.2462973594665527
Validation loss: 2.2181829611460366

Epoch: 6| Step: 9
Training loss: 1.1785187721252441
Validation loss: 2.1985894242922464

Epoch: 6| Step: 10
Training loss: 1.505899429321289
Validation loss: 2.2215267618497214

Epoch: 6| Step: 11
Training loss: 0.7159954905509949
Validation loss: 2.1712743242581687

Epoch: 6| Step: 12
Training loss: 0.9212030172348022
Validation loss: 2.170147975285848

Epoch: 6| Step: 13
Training loss: 0.8453353643417358
Validation loss: 2.181795080502828

Epoch: 336| Step: 0
Training loss: 0.9985798001289368
Validation loss: 2.122101982434591

Epoch: 6| Step: 1
Training loss: 2.140141010284424
Validation loss: 2.166602869828542

Epoch: 6| Step: 2
Training loss: 1.5855255126953125
Validation loss: 2.144203861554464

Epoch: 6| Step: 3
Training loss: 1.932394027709961
Validation loss: 2.1659003297487893

Epoch: 6| Step: 4
Training loss: 1.0972963571548462
Validation loss: 2.2095547119776406

Epoch: 6| Step: 5
Training loss: 1.5378351211547852
Validation loss: 2.196983595689138

Epoch: 6| Step: 6
Training loss: 1.074670672416687
Validation loss: 2.1791775623957315

Epoch: 6| Step: 7
Training loss: 1.06169593334198
Validation loss: 2.214569369951884

Epoch: 6| Step: 8
Training loss: 1.1345576047897339
Validation loss: 2.2169198195139566

Epoch: 6| Step: 9
Training loss: 1.2585161924362183
Validation loss: 2.2308059136072793

Epoch: 6| Step: 10
Training loss: 1.0105249881744385
Validation loss: 2.234058757623037

Epoch: 6| Step: 11
Training loss: 1.067542552947998
Validation loss: 2.2586767077445984

Epoch: 6| Step: 12
Training loss: 1.2086869478225708
Validation loss: 2.2709563771883645

Epoch: 6| Step: 13
Training loss: 1.594739317893982
Validation loss: 2.2706027825673423

Epoch: 337| Step: 0
Training loss: 1.7042438983917236
Validation loss: 2.2337092955907187

Epoch: 6| Step: 1
Training loss: 1.0202836990356445
Validation loss: 2.2867798805236816

Epoch: 6| Step: 2
Training loss: 1.4202024936676025
Validation loss: 2.260791758696238

Epoch: 6| Step: 3
Training loss: 1.4786450862884521
Validation loss: 2.2661200364430747

Epoch: 6| Step: 4
Training loss: 1.4183824062347412
Validation loss: 2.286147673924764

Epoch: 6| Step: 5
Training loss: 1.700885534286499
Validation loss: 2.247931718826294

Epoch: 6| Step: 6
Training loss: 1.4632973670959473
Validation loss: 2.2367409467697144

Epoch: 6| Step: 7
Training loss: 0.9237711429595947
Validation loss: 2.276792506376902

Epoch: 6| Step: 8
Training loss: 0.9911850690841675
Validation loss: 2.239116112391154

Epoch: 6| Step: 9
Training loss: 0.936355710029602
Validation loss: 2.248097022374471

Epoch: 6| Step: 10
Training loss: 1.0784059762954712
Validation loss: 2.263612767060598

Epoch: 6| Step: 11
Training loss: 1.3284556865692139
Validation loss: 2.1979732513427734

Epoch: 6| Step: 12
Training loss: 2.346457004547119
Validation loss: 2.202722489833832

Epoch: 6| Step: 13
Training loss: 0.6767947673797607
Validation loss: 2.206037720044454

Epoch: 338| Step: 0
Training loss: 0.8682783842086792
Validation loss: 2.2520313262939453

Epoch: 6| Step: 1
Training loss: 1.7317421436309814
Validation loss: 2.227693716684977

Epoch: 6| Step: 2
Training loss: 1.2136528491973877
Validation loss: 2.2008835077285767

Epoch: 6| Step: 3
Training loss: 1.2403918504714966
Validation loss: 2.2170472145080566

Epoch: 6| Step: 4
Training loss: 1.4904141426086426
Validation loss: 2.2241239150365195

Epoch: 6| Step: 5
Training loss: 1.324586272239685
Validation loss: 2.1882399916648865

Epoch: 6| Step: 6
Training loss: 1.3717817068099976
Validation loss: 2.196633776028951

Epoch: 6| Step: 7
Training loss: 1.1360392570495605
Validation loss: 2.216891646385193

Epoch: 6| Step: 8
Training loss: 1.613865613937378
Validation loss: 2.2163201173146567

Epoch: 6| Step: 9
Training loss: 1.6701126098632812
Validation loss: 2.2138681411743164

Epoch: 6| Step: 10
Training loss: 1.829662561416626
Validation loss: 2.2069506843884787

Epoch: 6| Step: 11
Training loss: 1.5462342500686646
Validation loss: 2.2355132500330606

Epoch: 6| Step: 12
Training loss: 1.4741506576538086
Validation loss: 2.18956728776296

Epoch: 6| Step: 13
Training loss: 0.9583609104156494
Validation loss: 2.2723850210507712

Epoch: 339| Step: 0
Training loss: 0.9106840491294861
Validation loss: 2.2655551036198935

Epoch: 6| Step: 1
Training loss: 2.206252098083496
Validation loss: 2.2744088570276895

Epoch: 6| Step: 2
Training loss: 1.7542434930801392
Validation loss: 2.2614044149716697

Epoch: 6| Step: 3
Training loss: 1.1499674320220947
Validation loss: 2.3042798240979514

Epoch: 6| Step: 4
Training loss: 1.4249588251113892
Validation loss: 2.307017982006073

Epoch: 6| Step: 5
Training loss: 0.9307193756103516
Validation loss: 2.2718990047772727

Epoch: 6| Step: 6
Training loss: 1.2934114933013916
Validation loss: 2.2678926984469094

Epoch: 6| Step: 7
Training loss: 1.3681528568267822
Validation loss: 2.2667917807896933

Epoch: 6| Step: 8
Training loss: 0.8212890625
Validation loss: 2.2579323848088584

Epoch: 6| Step: 9
Training loss: 1.703242301940918
Validation loss: 2.2790652314821878

Epoch: 6| Step: 10
Training loss: 1.8171669244766235
Validation loss: 2.2321929931640625

Epoch: 6| Step: 11
Training loss: 1.1707487106323242
Validation loss: 2.260834018389384

Epoch: 6| Step: 12
Training loss: 1.3072726726531982
Validation loss: 2.247415244579315

Epoch: 6| Step: 13
Training loss: 1.0637433528900146
Validation loss: 2.2543140848477683

Epoch: 340| Step: 0
Training loss: 1.6624536514282227
Validation loss: 2.257370889186859

Epoch: 6| Step: 1
Training loss: 1.2846242189407349
Validation loss: 2.3086241086324057

Epoch: 6| Step: 2
Training loss: 1.8036651611328125
Validation loss: 2.306665301322937

Epoch: 6| Step: 3
Training loss: 1.1906226873397827
Validation loss: 2.3031619985898337

Epoch: 6| Step: 4
Training loss: 1.272688627243042
Validation loss: 2.252078195412954

Epoch: 6| Step: 5
Training loss: 1.518473505973816
Validation loss: 2.2419066230456033

Epoch: 6| Step: 6
Training loss: 0.6941184401512146
Validation loss: 2.27134637037913

Epoch: 6| Step: 7
Training loss: 1.3163061141967773
Validation loss: 2.216018537680308

Epoch: 6| Step: 8
Training loss: 0.8442890048027039
Validation loss: 2.2243396242459617

Epoch: 6| Step: 9
Training loss: 1.9826890230178833
Validation loss: 2.2127296328544617

Epoch: 6| Step: 10
Training loss: 0.9656549096107483
Validation loss: 2.2187929352124534

Epoch: 6| Step: 11
Training loss: 1.7400879859924316
Validation loss: 2.194025178750356

Epoch: 6| Step: 12
Training loss: 1.642329454421997
Validation loss: 2.1978339155515036

Epoch: 6| Step: 13
Training loss: 1.1360889673233032
Validation loss: 2.222151239713033

Epoch: 341| Step: 0
Training loss: 1.746244192123413
Validation loss: 2.2216609716415405

Epoch: 6| Step: 1
Training loss: 1.6122000217437744
Validation loss: 2.2536648909250894

Epoch: 6| Step: 2
Training loss: 1.1187584400177002
Validation loss: 2.255901336669922

Epoch: 6| Step: 3
Training loss: 1.4217768907546997
Validation loss: 2.248186548550924

Epoch: 6| Step: 4
Training loss: 0.8757870197296143
Validation loss: 2.2194932103157043

Epoch: 6| Step: 5
Training loss: 1.5276148319244385
Validation loss: 2.2531954844792685

Epoch: 6| Step: 6
Training loss: 0.7796223759651184
Validation loss: 2.219426234563192

Epoch: 6| Step: 7
Training loss: 1.5148913860321045
Validation loss: 2.2224960923194885

Epoch: 6| Step: 8
Training loss: 1.5083762407302856
Validation loss: 2.227119823296865

Epoch: 6| Step: 9
Training loss: 0.8065196871757507
Validation loss: 2.238872508207957

Epoch: 6| Step: 10
Training loss: 0.9657309055328369
Validation loss: 2.2573227882385254

Epoch: 6| Step: 11
Training loss: 1.7448230981826782
Validation loss: 2.232774019241333

Epoch: 6| Step: 12
Training loss: 1.5772979259490967
Validation loss: 2.2174750367800393

Epoch: 6| Step: 13
Training loss: 1.07186758518219
Validation loss: 2.238818049430847

Epoch: 342| Step: 0
Training loss: 0.6388535499572754
Validation loss: 2.264730374018351

Epoch: 6| Step: 1
Training loss: 1.2448277473449707
Validation loss: 2.240077237288157

Epoch: 6| Step: 2
Training loss: 1.465801477432251
Validation loss: 2.2031017541885376

Epoch: 6| Step: 3
Training loss: 2.4343185424804688
Validation loss: 2.242078443368276

Epoch: 6| Step: 4
Training loss: 1.6427104473114014
Validation loss: 2.219023287296295

Epoch: 6| Step: 5
Training loss: 0.88942551612854
Validation loss: 2.2089751958847046

Epoch: 6| Step: 6
Training loss: 1.2297290563583374
Validation loss: 2.2115897138913474

Epoch: 6| Step: 7
Training loss: 0.8848799467086792
Validation loss: 2.2231144309043884

Epoch: 6| Step: 8
Training loss: 1.3745057582855225
Validation loss: 2.214243551095327

Epoch: 6| Step: 9
Training loss: 1.7015290260314941
Validation loss: 2.236162463823954

Epoch: 6| Step: 10
Training loss: 0.7717632055282593
Validation loss: 2.235726237297058

Epoch: 6| Step: 11
Training loss: 1.5039358139038086
Validation loss: 2.1960375706354776

Epoch: 6| Step: 12
Training loss: 1.5189718008041382
Validation loss: 2.2182292143503823

Epoch: 6| Step: 13
Training loss: 0.8157117962837219
Validation loss: 2.206390917301178

Epoch: 343| Step: 0
Training loss: 1.2195998430252075
Validation loss: 2.1903767585754395

Epoch: 6| Step: 1
Training loss: 0.6947950124740601
Validation loss: 2.189044773578644

Epoch: 6| Step: 2
Training loss: 1.8437132835388184
Validation loss: 2.206604818503062

Epoch: 6| Step: 3
Training loss: 1.8623355627059937
Validation loss: 2.196481625239054

Epoch: 6| Step: 4
Training loss: 1.157634973526001
Validation loss: 2.219273885091146

Epoch: 6| Step: 5
Training loss: 1.5558686256408691
Validation loss: 2.2031168142954507

Epoch: 6| Step: 6
Training loss: 1.1476449966430664
Validation loss: 2.2359728614489236

Epoch: 6| Step: 7
Training loss: 0.8775194883346558
Validation loss: 2.1720067461331687

Epoch: 6| Step: 8
Training loss: 0.5353966355323792
Validation loss: 2.1929266850153604

Epoch: 6| Step: 9
Training loss: 1.3376213312149048
Validation loss: 2.2248465021451316

Epoch: 6| Step: 10
Training loss: 1.2179701328277588
Validation loss: 2.2202393213907876

Epoch: 6| Step: 11
Training loss: 1.0875904560089111
Validation loss: 2.2211689551671348

Epoch: 6| Step: 12
Training loss: 1.1514393091201782
Validation loss: 2.221722503503164

Epoch: 6| Step: 13
Training loss: 2.0151374340057373
Validation loss: 2.230297644933065

Epoch: 344| Step: 0
Training loss: 1.8729552030563354
Validation loss: 2.2666498819986978

Epoch: 6| Step: 1
Training loss: 1.632983922958374
Validation loss: 2.236325224240621

Epoch: 6| Step: 2
Training loss: 0.9936994910240173
Validation loss: 2.200058897336324

Epoch: 6| Step: 3
Training loss: 1.2386703491210938
Validation loss: 2.2035736242930093

Epoch: 6| Step: 4
Training loss: 1.4276880025863647
Validation loss: 2.242872476577759

Epoch: 6| Step: 5
Training loss: 0.7607959508895874
Validation loss: 2.215441584587097

Epoch: 6| Step: 6
Training loss: 1.5175193548202515
Validation loss: 2.2309281826019287

Epoch: 6| Step: 7
Training loss: 1.455585241317749
Validation loss: 2.2105813026428223

Epoch: 6| Step: 8
Training loss: 1.0896068811416626
Validation loss: 2.2475333213806152

Epoch: 6| Step: 9
Training loss: 0.7045199275016785
Validation loss: 2.2541574239730835

Epoch: 6| Step: 10
Training loss: 1.1127474308013916
Validation loss: 2.216160535812378

Epoch: 6| Step: 11
Training loss: 0.8705296516418457
Validation loss: 2.2518699963887534

Epoch: 6| Step: 12
Training loss: 1.435637354850769
Validation loss: 2.2138773798942566

Epoch: 6| Step: 13
Training loss: 2.101740837097168
Validation loss: 2.2346367041269937

Epoch: 345| Step: 0
Training loss: 0.8098037242889404
Validation loss: 2.228092829386393

Epoch: 6| Step: 1
Training loss: 1.0313671827316284
Validation loss: 2.1941400369008384

Epoch: 6| Step: 2
Training loss: 1.7713066339492798
Validation loss: 2.188610831896464

Epoch: 6| Step: 3
Training loss: 1.1471850872039795
Validation loss: 2.2092315355936685

Epoch: 6| Step: 4
Training loss: 1.2842434644699097
Validation loss: 2.189996898174286

Epoch: 6| Step: 5
Training loss: 1.6466015577316284
Validation loss: 2.166901926199595

Epoch: 6| Step: 6
Training loss: 1.2231483459472656
Validation loss: 2.179027338822683

Epoch: 6| Step: 7
Training loss: 1.783639669418335
Validation loss: 2.185626963774363

Epoch: 6| Step: 8
Training loss: 1.560131549835205
Validation loss: 2.2017951806386313

Epoch: 6| Step: 9
Training loss: 1.396730899810791
Validation loss: 2.209586441516876

Epoch: 6| Step: 10
Training loss: 2.1914174556732178
Validation loss: 2.225048323472341

Epoch: 6| Step: 11
Training loss: 1.0533790588378906
Validation loss: 2.1622540752092996

Epoch: 6| Step: 12
Training loss: 0.9658697843551636
Validation loss: 2.2112252910931907

Epoch: 6| Step: 13
Training loss: 0.8188073635101318
Validation loss: 2.1755576928456626

Epoch: 346| Step: 0
Training loss: 1.9389007091522217
Validation loss: 2.236609955628713

Epoch: 6| Step: 1
Training loss: 1.170740008354187
Validation loss: 2.2564285596211753

Epoch: 6| Step: 2
Training loss: 0.9543558359146118
Validation loss: 2.259212334950765

Epoch: 6| Step: 3
Training loss: 1.3193920850753784
Validation loss: 2.243018468221029

Epoch: 6| Step: 4
Training loss: 1.0893224477767944
Validation loss: 2.2694894274075827

Epoch: 6| Step: 5
Training loss: 1.1393505334854126
Validation loss: 2.2603030800819397

Epoch: 6| Step: 6
Training loss: 1.4109582901000977
Validation loss: 2.228359818458557

Epoch: 6| Step: 7
Training loss: 1.5265896320343018
Validation loss: 2.2576437989870706

Epoch: 6| Step: 8
Training loss: 0.9159737825393677
Validation loss: 2.239932656288147

Epoch: 6| Step: 9
Training loss: 1.3465454578399658
Validation loss: 2.245862523714701

Epoch: 6| Step: 10
Training loss: 1.0334502458572388
Validation loss: 2.2072253624598184

Epoch: 6| Step: 11
Training loss: 1.3496501445770264
Validation loss: 2.2202515999476113

Epoch: 6| Step: 12
Training loss: 2.128122568130493
Validation loss: 2.2316086093584695

Epoch: 6| Step: 13
Training loss: 1.078137993812561
Validation loss: 2.247189919153849

Epoch: 347| Step: 0
Training loss: 1.1952770948410034
Validation loss: 2.290672024091085

Epoch: 6| Step: 1
Training loss: 2.217754364013672
Validation loss: 2.3113691012064614

Epoch: 6| Step: 2
Training loss: 0.8125685453414917
Validation loss: 2.2916391690572104

Epoch: 6| Step: 3
Training loss: 1.207956075668335
Validation loss: 2.290693203608195

Epoch: 6| Step: 4
Training loss: 1.501099944114685
Validation loss: 2.3097097873687744

Epoch: 6| Step: 5
Training loss: 1.3781988620758057
Validation loss: 2.285464425881704

Epoch: 6| Step: 6
Training loss: 1.8486194610595703
Validation loss: 2.2365246216456094

Epoch: 6| Step: 7
Training loss: 1.233818531036377
Validation loss: 2.2841507395108542

Epoch: 6| Step: 8
Training loss: 1.2689764499664307
Validation loss: 2.2541311780611673

Epoch: 6| Step: 9
Training loss: 1.436397671699524
Validation loss: 2.2713856299718223

Epoch: 6| Step: 10
Training loss: 0.6897608637809753
Validation loss: 2.273423969745636

Epoch: 6| Step: 11
Training loss: 1.509101152420044
Validation loss: 2.224361519018809

Epoch: 6| Step: 12
Training loss: 1.0552551746368408
Validation loss: 2.2462326288223267

Epoch: 6| Step: 13
Training loss: 0.7061418890953064
Validation loss: 2.2313284079233804

Epoch: 348| Step: 0
Training loss: 1.8032362461090088
Validation loss: 2.243091424306234

Epoch: 6| Step: 1
Training loss: 0.6589733958244324
Validation loss: 2.2295580307642617

Epoch: 6| Step: 2
Training loss: 1.678046464920044
Validation loss: 2.2229193449020386

Epoch: 6| Step: 3
Training loss: 0.9053443670272827
Validation loss: 2.226992885271708

Epoch: 6| Step: 4
Training loss: 1.191521167755127
Validation loss: 2.252082367738088

Epoch: 6| Step: 5
Training loss: 2.5757336616516113
Validation loss: 2.221813122431437

Epoch: 6| Step: 6
Training loss: 0.5783993005752563
Validation loss: 2.2142677704493203

Epoch: 6| Step: 7
Training loss: 0.8524472713470459
Validation loss: 2.2541228334108987

Epoch: 6| Step: 8
Training loss: 1.6139129400253296
Validation loss: 2.225130319595337

Epoch: 6| Step: 9
Training loss: 1.4280714988708496
Validation loss: 2.26494566599528

Epoch: 6| Step: 10
Training loss: 1.4454623460769653
Validation loss: 2.2316143910090127

Epoch: 6| Step: 11
Training loss: 0.9394119381904602
Validation loss: 2.2700095176696777

Epoch: 6| Step: 12
Training loss: 1.4073857069015503
Validation loss: 2.159875512123108

Epoch: 6| Step: 13
Training loss: 0.5860862731933594
Validation loss: 2.181118905544281

Epoch: 349| Step: 0
Training loss: 1.3573954105377197
Validation loss: 2.195570250352224

Epoch: 6| Step: 1
Training loss: 1.1467410326004028
Validation loss: 2.2072430650393167

Epoch: 6| Step: 2
Training loss: 1.4396177530288696
Validation loss: 2.173809011777242

Epoch: 6| Step: 3
Training loss: 1.4990346431732178
Validation loss: 2.2117023865381875

Epoch: 6| Step: 4
Training loss: 1.2275352478027344
Validation loss: 2.1724929014841714

Epoch: 6| Step: 5
Training loss: 1.3033673763275146
Validation loss: 2.192528863747915

Epoch: 6| Step: 6
Training loss: 1.2622203826904297
Validation loss: 2.1685595512390137

Epoch: 6| Step: 7
Training loss: 1.7190452814102173
Validation loss: 2.1916805505752563

Epoch: 6| Step: 8
Training loss: 0.6960009336471558
Validation loss: 2.2518319686253867

Epoch: 6| Step: 9
Training loss: 1.5340780019760132
Validation loss: 2.2623303731282554

Epoch: 6| Step: 10
Training loss: 1.1353912353515625
Validation loss: 2.2661107977231345

Epoch: 6| Step: 11
Training loss: 1.4362348318099976
Validation loss: 2.261249601840973

Epoch: 6| Step: 12
Training loss: 0.9916549921035767
Validation loss: 2.293257713317871

Epoch: 6| Step: 13
Training loss: 1.7302155494689941
Validation loss: 2.2618261178334556

Epoch: 350| Step: 0
Training loss: 0.9513788223266602
Validation loss: 2.274393697579702

Epoch: 6| Step: 1
Training loss: 1.657253384590149
Validation loss: 2.2363710006078086

Epoch: 6| Step: 2
Training loss: 1.0942327976226807
Validation loss: 2.2695285876592

Epoch: 6| Step: 3
Training loss: 1.5620265007019043
Validation loss: 2.284634550412496

Epoch: 6| Step: 4
Training loss: 0.9692308306694031
Validation loss: 2.310625155766805

Epoch: 6| Step: 5
Training loss: 1.9533298015594482
Validation loss: 2.2250776489575705

Epoch: 6| Step: 6
Training loss: 1.4966216087341309
Validation loss: 2.2279892762502036

Epoch: 6| Step: 7
Training loss: 1.229048728942871
Validation loss: 2.2781919638315835

Epoch: 6| Step: 8
Training loss: 1.1029281616210938
Validation loss: 2.2469225923220315

Epoch: 6| Step: 9
Training loss: 1.5634409189224243
Validation loss: 2.257782439390818

Epoch: 6| Step: 10
Training loss: 1.072861909866333
Validation loss: 2.266214688618978

Epoch: 6| Step: 11
Training loss: 1.325674295425415
Validation loss: 2.2199469010035195

Epoch: 6| Step: 12
Training loss: 1.9990798234939575
Validation loss: 2.223528206348419

Epoch: 6| Step: 13
Training loss: 0.9310988187789917
Validation loss: 2.242761969566345

Epoch: 351| Step: 0
Training loss: 1.9021786451339722
Validation loss: 2.2620134949684143

Epoch: 6| Step: 1
Training loss: 0.9858534932136536
Validation loss: 2.249090075492859

Epoch: 6| Step: 2
Training loss: 1.2654139995574951
Validation loss: 2.261122485001882

Epoch: 6| Step: 3
Training loss: 1.1608155965805054
Validation loss: 2.2638617356618247

Epoch: 6| Step: 4
Training loss: 1.2151124477386475
Validation loss: 2.273681362469991

Epoch: 6| Step: 5
Training loss: 1.2172456979751587
Validation loss: 2.246932069460551

Epoch: 6| Step: 6
Training loss: 0.6116830110549927
Validation loss: 2.239038825035095

Epoch: 6| Step: 7
Training loss: 1.4283726215362549
Validation loss: 2.220840553442637

Epoch: 6| Step: 8
Training loss: 1.4077363014221191
Validation loss: 2.2399089535077414

Epoch: 6| Step: 9
Training loss: 1.6426547765731812
Validation loss: 2.2594836552937827

Epoch: 6| Step: 10
Training loss: 1.5946221351623535
Validation loss: 2.2192457914352417

Epoch: 6| Step: 11
Training loss: 1.2257087230682373
Validation loss: 2.2638132572174072

Epoch: 6| Step: 12
Training loss: 1.341284990310669
Validation loss: 2.19224605957667

Epoch: 6| Step: 13
Training loss: 1.2995631694793701
Validation loss: 2.228720506032308

Epoch: 352| Step: 0
Training loss: 2.0242934226989746
Validation loss: 2.192015826702118

Epoch: 6| Step: 1
Training loss: 1.1944053173065186
Validation loss: 2.1965545614560447

Epoch: 6| Step: 2
Training loss: 0.7986552715301514
Validation loss: 2.194048523902893

Epoch: 6| Step: 3
Training loss: 0.887089729309082
Validation loss: 2.209185759226481

Epoch: 6| Step: 4
Training loss: 1.1049383878707886
Validation loss: 2.2191877563794455

Epoch: 6| Step: 5
Training loss: 1.3912794589996338
Validation loss: 2.1601423819859824

Epoch: 6| Step: 6
Training loss: 0.46538692712783813
Validation loss: 2.191256523132324

Epoch: 6| Step: 7
Training loss: 1.3256688117980957
Validation loss: 2.1555861433347068

Epoch: 6| Step: 8
Training loss: 0.9774014949798584
Validation loss: 2.2245789766311646

Epoch: 6| Step: 9
Training loss: 1.6689122915267944
Validation loss: 2.221053719520569

Epoch: 6| Step: 10
Training loss: 1.4041078090667725
Validation loss: 2.1951770385106406

Epoch: 6| Step: 11
Training loss: 1.9173444509506226
Validation loss: 2.2493322690327964

Epoch: 6| Step: 12
Training loss: 1.6842745542526245
Validation loss: 2.255884329477946

Epoch: 6| Step: 13
Training loss: 1.414750099182129
Validation loss: 2.2087888717651367

Epoch: 353| Step: 0
Training loss: 1.3389973640441895
Validation loss: 2.2033102909723916

Epoch: 6| Step: 1
Training loss: 1.1955054998397827
Validation loss: 2.20236865679423

Epoch: 6| Step: 2
Training loss: 1.114828109741211
Validation loss: 2.1736018856366477

Epoch: 6| Step: 3
Training loss: 1.2737200260162354
Validation loss: 2.204253673553467

Epoch: 6| Step: 4
Training loss: 1.3370733261108398
Validation loss: 2.2007517417271933

Epoch: 6| Step: 5
Training loss: 1.1873254776000977
Validation loss: 2.1825095415115356

Epoch: 6| Step: 6
Training loss: 1.429680585861206
Validation loss: 2.1859154303868613

Epoch: 6| Step: 7
Training loss: 1.232590675354004
Validation loss: 2.1714370449384055

Epoch: 6| Step: 8
Training loss: 1.5754177570343018
Validation loss: 2.2420969009399414

Epoch: 6| Step: 9
Training loss: 1.2975120544433594
Validation loss: 2.1841540336608887

Epoch: 6| Step: 10
Training loss: 1.0203056335449219
Validation loss: 2.168109099070231

Epoch: 6| Step: 11
Training loss: 1.2075978517532349
Validation loss: 2.206394890944163

Epoch: 6| Step: 12
Training loss: 1.3693492412567139
Validation loss: 2.2231817841529846

Epoch: 6| Step: 13
Training loss: 1.2868196964263916
Validation loss: 2.2158822615941367

Epoch: 354| Step: 0
Training loss: 1.1073740720748901
Validation loss: 2.188360273838043

Epoch: 6| Step: 1
Training loss: 0.8224853277206421
Validation loss: 2.2462945183118186

Epoch: 6| Step: 2
Training loss: 1.4170029163360596
Validation loss: 2.2061137159665427

Epoch: 6| Step: 3
Training loss: 1.4597851037979126
Validation loss: 2.1890427668889365

Epoch: 6| Step: 4
Training loss: 0.9174073934555054
Validation loss: 2.2336760759353638

Epoch: 6| Step: 5
Training loss: 1.5505870580673218
Validation loss: 2.2281565070152283

Epoch: 6| Step: 6
Training loss: 1.3377119302749634
Validation loss: 2.2219709555308023

Epoch: 6| Step: 7
Training loss: 0.9155918955802917
Validation loss: 2.1984853545824685

Epoch: 6| Step: 8
Training loss: 0.9244218468666077
Validation loss: 2.215984880924225

Epoch: 6| Step: 9
Training loss: 1.3046410083770752
Validation loss: 2.225082198778788

Epoch: 6| Step: 10
Training loss: 1.8849499225616455
Validation loss: 2.225992818673452

Epoch: 6| Step: 11
Training loss: 0.995990514755249
Validation loss: 2.2279039223988852

Epoch: 6| Step: 12
Training loss: 1.727351188659668
Validation loss: 2.2650626500447593

Epoch: 6| Step: 13
Training loss: 1.2975353002548218
Validation loss: 2.248213807741801

Epoch: 355| Step: 0
Training loss: 0.884369969367981
Validation loss: 2.2943522532780967

Epoch: 6| Step: 1
Training loss: 0.9688345193862915
Validation loss: 2.299000104268392

Epoch: 6| Step: 2
Training loss: 0.98222815990448
Validation loss: 2.216872811317444

Epoch: 6| Step: 3
Training loss: 1.3238394260406494
Validation loss: 2.2464220921198526

Epoch: 6| Step: 4
Training loss: 1.4580371379852295
Validation loss: 2.247699578603109

Epoch: 6| Step: 5
Training loss: 1.2151057720184326
Validation loss: 2.2696314652760825

Epoch: 6| Step: 6
Training loss: 0.8920412063598633
Validation loss: 2.277749021848043

Epoch: 6| Step: 7
Training loss: 1.3991460800170898
Validation loss: 2.261408746242523

Epoch: 6| Step: 8
Training loss: 1.6552449464797974
Validation loss: 2.2450563510258994

Epoch: 6| Step: 9
Training loss: 2.0001890659332275
Validation loss: 2.219819267590841

Epoch: 6| Step: 10
Training loss: 1.0552139282226562
Validation loss: 2.234220107396444

Epoch: 6| Step: 11
Training loss: 1.1724299192428589
Validation loss: 2.223681847254435

Epoch: 6| Step: 12
Training loss: 1.621929407119751
Validation loss: 2.236946960290273

Epoch: 6| Step: 13
Training loss: 0.9426893591880798
Validation loss: 2.2627753416697183

Epoch: 356| Step: 0
Training loss: 2.326493501663208
Validation loss: 2.2216986219088235

Epoch: 6| Step: 1
Training loss: 1.5606434345245361
Validation loss: 2.2505837082862854

Epoch: 6| Step: 2
Training loss: 1.0766839981079102
Validation loss: 2.222012440363566

Epoch: 6| Step: 3
Training loss: 1.1577532291412354
Validation loss: 2.2357585032780967

Epoch: 6| Step: 4
Training loss: 0.7314776182174683
Validation loss: 2.2796842455863953

Epoch: 6| Step: 5
Training loss: 1.481156349182129
Validation loss: 2.249944011370341

Epoch: 6| Step: 6
Training loss: 0.8044580221176147
Validation loss: 2.2463276187578836

Epoch: 6| Step: 7
Training loss: 1.2263561487197876
Validation loss: 2.242876390616099

Epoch: 6| Step: 8
Training loss: 1.458465814590454
Validation loss: 2.262494742870331

Epoch: 6| Step: 9
Training loss: 1.2033281326293945
Validation loss: 2.218211611111959

Epoch: 6| Step: 10
Training loss: 1.8403247594833374
Validation loss: 2.2248644630114236

Epoch: 6| Step: 11
Training loss: 0.39468467235565186
Validation loss: 2.212268610795339

Epoch: 6| Step: 12
Training loss: 1.104097604751587
Validation loss: 2.224914570649465

Epoch: 6| Step: 13
Training loss: 0.9077417850494385
Validation loss: 2.2877763708432517

Epoch: 357| Step: 0
Training loss: 0.7367056012153625
Validation loss: 2.2431047757466636

Epoch: 6| Step: 1
Training loss: 1.4846141338348389
Validation loss: 2.272027333577474

Epoch: 6| Step: 2
Training loss: 1.3353197574615479
Validation loss: 2.276655356089274

Epoch: 6| Step: 3
Training loss: 1.1277458667755127
Validation loss: 2.3000579277674356

Epoch: 6| Step: 4
Training loss: 0.9124095439910889
Validation loss: 2.303680102030436

Epoch: 6| Step: 5
Training loss: 1.099043607711792
Validation loss: 2.2568862040837607

Epoch: 6| Step: 6
Training loss: 1.3058545589447021
Validation loss: 2.296771248181661

Epoch: 6| Step: 7
Training loss: 1.3382540941238403
Validation loss: 2.2283350825309753

Epoch: 6| Step: 8
Training loss: 1.1813654899597168
Validation loss: 2.243378241856893

Epoch: 6| Step: 9
Training loss: 1.6547374725341797
Validation loss: 2.257336139678955

Epoch: 6| Step: 10
Training loss: 2.6046605110168457
Validation loss: 2.2602574030558267

Epoch: 6| Step: 11
Training loss: 1.1039079427719116
Validation loss: 2.2364537914594016

Epoch: 6| Step: 12
Training loss: 1.041269063949585
Validation loss: 2.244761606057485

Epoch: 6| Step: 13
Training loss: 1.0498498678207397
Validation loss: 2.2559200525283813

Epoch: 358| Step: 0
Training loss: 1.8305692672729492
Validation loss: 2.291567881902059

Epoch: 6| Step: 1
Training loss: 0.8559036254882812
Validation loss: 2.2648040850957236

Epoch: 6| Step: 2
Training loss: 0.7393019199371338
Validation loss: 2.273452083269755

Epoch: 6| Step: 3
Training loss: 0.8818677067756653
Validation loss: 2.2839665015538535

Epoch: 6| Step: 4
Training loss: 1.1391804218292236
Validation loss: 2.2829130490620932

Epoch: 6| Step: 5
Training loss: 2.228259801864624
Validation loss: 2.2607821226119995

Epoch: 6| Step: 6
Training loss: 1.6363362073898315
Validation loss: 2.276856621106466

Epoch: 6| Step: 7
Training loss: 1.1729891300201416
Validation loss: 2.2493472695350647

Epoch: 6| Step: 8
Training loss: 0.5987458229064941
Validation loss: 2.2519118785858154

Epoch: 6| Step: 9
Training loss: 0.861279308795929
Validation loss: 2.235677659511566

Epoch: 6| Step: 10
Training loss: 1.2596161365509033
Validation loss: 2.198207120100657

Epoch: 6| Step: 11
Training loss: 1.012090802192688
Validation loss: 2.217056711514791

Epoch: 6| Step: 12
Training loss: 1.6453187465667725
Validation loss: 2.194046219189962

Epoch: 6| Step: 13
Training loss: 1.544304609298706
Validation loss: 2.2582915822664895

Epoch: 359| Step: 0
Training loss: 1.3269439935684204
Validation loss: 2.2145716746648154

Epoch: 6| Step: 1
Training loss: 1.3009655475616455
Validation loss: 2.233251452445984

Epoch: 6| Step: 2
Training loss: 1.1291420459747314
Validation loss: 2.2313979665438333

Epoch: 6| Step: 3
Training loss: 1.0551793575286865
Validation loss: 2.2823961973190308

Epoch: 6| Step: 4
Training loss: 0.8933636546134949
Validation loss: 2.260123531023661

Epoch: 6| Step: 5
Training loss: 1.4329043626785278
Validation loss: 2.190529147783915

Epoch: 6| Step: 6
Training loss: 1.5086077451705933
Validation loss: 2.1932832400004068

Epoch: 6| Step: 7
Training loss: 1.3819036483764648
Validation loss: 2.219254732131958

Epoch: 6| Step: 8
Training loss: 0.8780567646026611
Validation loss: 2.1977619528770447

Epoch: 6| Step: 9
Training loss: 1.498742938041687
Validation loss: 2.20701140165329

Epoch: 6| Step: 10
Training loss: 2.033764123916626
Validation loss: 2.2154290676116943

Epoch: 6| Step: 11
Training loss: 1.4632006883621216
Validation loss: 2.2717527747154236

Epoch: 6| Step: 12
Training loss: 1.4145021438598633
Validation loss: 2.2250563303629556

Epoch: 6| Step: 13
Training loss: 1.4737389087677002
Validation loss: 2.2263260881106057

Epoch: 360| Step: 0
Training loss: 1.355363130569458
Validation loss: 2.230843464533488

Epoch: 6| Step: 1
Training loss: 1.24298095703125
Validation loss: 2.212669610977173

Epoch: 6| Step: 2
Training loss: 1.067200779914856
Validation loss: 2.195169150829315

Epoch: 6| Step: 3
Training loss: 1.5511295795440674
Validation loss: 2.235376318295797

Epoch: 6| Step: 4
Training loss: 0.9375376105308533
Validation loss: 2.194585661093394

Epoch: 6| Step: 5
Training loss: 0.9247568845748901
Validation loss: 2.196288744608561

Epoch: 6| Step: 6
Training loss: 1.1531614065170288
Validation loss: 2.1208449602127075

Epoch: 6| Step: 7
Training loss: 0.8561620712280273
Validation loss: 2.1756310065587363

Epoch: 6| Step: 8
Training loss: 1.43950355052948
Validation loss: 2.100582003593445

Epoch: 6| Step: 9
Training loss: 1.5803507566452026
Validation loss: 2.148806114991506

Epoch: 6| Step: 10
Training loss: 1.7768751382827759
Validation loss: 2.14805402358373

Epoch: 6| Step: 11
Training loss: 2.0284478664398193
Validation loss: 2.155234456062317

Epoch: 6| Step: 12
Training loss: 1.5452582836151123
Validation loss: 2.1549803018569946

Epoch: 6| Step: 13
Training loss: 1.5675413608551025
Validation loss: 2.153167506059011

Epoch: 361| Step: 0
Training loss: 0.9966855645179749
Validation loss: 2.1661421855290732

Epoch: 6| Step: 1
Training loss: 1.577246904373169
Validation loss: 2.206075370311737

Epoch: 6| Step: 2
Training loss: 1.3939239978790283
Validation loss: 2.1862157583236694

Epoch: 6| Step: 3
Training loss: 1.3009233474731445
Validation loss: 2.2200635274251304

Epoch: 6| Step: 4
Training loss: 2.2188358306884766
Validation loss: 2.214677552382151

Epoch: 6| Step: 5
Training loss: 0.9704928398132324
Validation loss: 2.206983963648478

Epoch: 6| Step: 6
Training loss: 1.1589782238006592
Validation loss: 2.2295236190160117

Epoch: 6| Step: 7
Training loss: 1.6781400442123413
Validation loss: 2.2648422718048096

Epoch: 6| Step: 8
Training loss: 1.3370836973190308
Validation loss: 2.2487208048502603

Epoch: 6| Step: 9
Training loss: 1.5027507543563843
Validation loss: 2.2957605918248496

Epoch: 6| Step: 10
Training loss: 0.9656567573547363
Validation loss: 2.2592881123224893

Epoch: 6| Step: 11
Training loss: 1.1979881525039673
Validation loss: 2.2381211320559182

Epoch: 6| Step: 12
Training loss: 0.9914021492004395
Validation loss: 2.237572133541107

Epoch: 6| Step: 13
Training loss: 1.2732949256896973
Validation loss: 2.232085724671682

Epoch: 362| Step: 0
Training loss: 0.8117769956588745
Validation loss: 2.257592042287191

Epoch: 6| Step: 1
Training loss: 0.9845862984657288
Validation loss: 2.2206284006436667

Epoch: 6| Step: 2
Training loss: 1.1115739345550537
Validation loss: 2.214219590028127

Epoch: 6| Step: 3
Training loss: 1.0109949111938477
Validation loss: 2.2302860220273337

Epoch: 6| Step: 4
Training loss: 1.3540292978286743
Validation loss: 2.179334044456482

Epoch: 6| Step: 5
Training loss: 1.498618245124817
Validation loss: 2.1971088647842407

Epoch: 6| Step: 6
Training loss: 1.284579873085022
Validation loss: 2.2098704973856607

Epoch: 6| Step: 7
Training loss: 1.3511946201324463
Validation loss: 2.164791782697042

Epoch: 6| Step: 8
Training loss: 0.9407644867897034
Validation loss: 2.226575513680776

Epoch: 6| Step: 9
Training loss: 1.1274774074554443
Validation loss: 2.225629289944967

Epoch: 6| Step: 10
Training loss: 1.4346644878387451
Validation loss: 2.251351058483124

Epoch: 6| Step: 11
Training loss: 1.784511923789978
Validation loss: 2.2306087414423623

Epoch: 6| Step: 12
Training loss: 1.8646752834320068
Validation loss: 2.2469096183776855

Epoch: 6| Step: 13
Training loss: 1.3500277996063232
Validation loss: 2.2613696654637656

Epoch: 363| Step: 0
Training loss: 1.4903379678726196
Validation loss: 2.254793167114258

Epoch: 6| Step: 1
Training loss: 1.6317346096038818
Validation loss: 2.2138825257619223

Epoch: 6| Step: 2
Training loss: 1.0434095859527588
Validation loss: 2.2062964042027793

Epoch: 6| Step: 3
Training loss: 1.1057329177856445
Validation loss: 2.227938453356425

Epoch: 6| Step: 4
Training loss: 1.2688162326812744
Validation loss: 2.2512823343276978

Epoch: 6| Step: 5
Training loss: 0.7065950036048889
Validation loss: 2.171321074167887

Epoch: 6| Step: 6
Training loss: 1.0394375324249268
Validation loss: 2.213980714480082

Epoch: 6| Step: 7
Training loss: 1.235158920288086
Validation loss: 2.1810466647148132

Epoch: 6| Step: 8
Training loss: 1.3652464151382446
Validation loss: 2.2256596883138022

Epoch: 6| Step: 9
Training loss: 1.8364044427871704
Validation loss: 2.195751667022705

Epoch: 6| Step: 10
Training loss: 0.9919397234916687
Validation loss: 2.1571995417277017

Epoch: 6| Step: 11
Training loss: 1.4528965950012207
Validation loss: 2.2305704752604165

Epoch: 6| Step: 12
Training loss: 0.4675384759902954
Validation loss: 2.2501664956410727

Epoch: 6| Step: 13
Training loss: 1.556993007659912
Validation loss: 2.2107545932133994

Epoch: 364| Step: 0
Training loss: 1.3222490549087524
Validation loss: 2.239895780881246

Epoch: 6| Step: 1
Training loss: 0.6999460458755493
Validation loss: 2.243403355280558

Epoch: 6| Step: 2
Training loss: 1.756640911102295
Validation loss: 2.257425844669342

Epoch: 6| Step: 3
Training loss: 1.0172793865203857
Validation loss: 2.2492236693700156

Epoch: 6| Step: 4
Training loss: 1.7824944257736206
Validation loss: 2.25431497891744

Epoch: 6| Step: 5
Training loss: 1.293574571609497
Validation loss: 2.268139958381653

Epoch: 6| Step: 6
Training loss: 1.2776371240615845
Validation loss: 2.245759586493174

Epoch: 6| Step: 7
Training loss: 1.2058466672897339
Validation loss: 2.268410861492157

Epoch: 6| Step: 8
Training loss: 0.8221410512924194
Validation loss: 2.239954431851705

Epoch: 6| Step: 9
Training loss: 0.8301689028739929
Validation loss: 2.205487608909607

Epoch: 6| Step: 10
Training loss: 1.1064505577087402
Validation loss: 2.1974443594614663

Epoch: 6| Step: 11
Training loss: 1.1786493062973022
Validation loss: 2.231990019480387

Epoch: 6| Step: 12
Training loss: 1.630990982055664
Validation loss: 2.2358385920524597

Epoch: 6| Step: 13
Training loss: 1.7787872552871704
Validation loss: 2.2053638696670532

Epoch: 365| Step: 0
Training loss: 0.8727817535400391
Validation loss: 2.2201934258143106

Epoch: 6| Step: 1
Training loss: 0.9827879071235657
Validation loss: 2.1681801875432334

Epoch: 6| Step: 2
Training loss: 1.6272144317626953
Validation loss: 2.161144951979319

Epoch: 6| Step: 3
Training loss: 1.112743854522705
Validation loss: 2.193471074104309

Epoch: 6| Step: 4
Training loss: 1.389466404914856
Validation loss: 2.2291073401769004

Epoch: 6| Step: 5
Training loss: 0.7556338310241699
Validation loss: 2.2480210860570273

Epoch: 6| Step: 6
Training loss: 2.0135374069213867
Validation loss: 2.300125221411387

Epoch: 6| Step: 7
Training loss: 0.8268275260925293
Validation loss: 2.283409357070923

Epoch: 6| Step: 8
Training loss: 1.310666799545288
Validation loss: 2.2725286881128945

Epoch: 6| Step: 9
Training loss: 1.6378440856933594
Validation loss: 2.2363470594088235

Epoch: 6| Step: 10
Training loss: 0.8361945152282715
Validation loss: 2.269634246826172

Epoch: 6| Step: 11
Training loss: 1.0802102088928223
Validation loss: 2.257920503616333

Epoch: 6| Step: 12
Training loss: 1.3441479206085205
Validation loss: 2.270226220289866

Epoch: 6| Step: 13
Training loss: 1.5442333221435547
Validation loss: 2.227832853794098

Epoch: 366| Step: 0
Training loss: 1.478655219078064
Validation loss: 2.2693607012430825

Epoch: 6| Step: 1
Training loss: 0.9086170196533203
Validation loss: 2.2311521569887796

Epoch: 6| Step: 2
Training loss: 0.8425160646438599
Validation loss: 2.2683945894241333

Epoch: 6| Step: 3
Training loss: 1.9337067604064941
Validation loss: 2.2438053290049234

Epoch: 6| Step: 4
Training loss: 1.5751867294311523
Validation loss: 2.1986917853355408

Epoch: 6| Step: 5
Training loss: 0.610039472579956
Validation loss: 2.1662044525146484

Epoch: 6| Step: 6
Training loss: 1.1232366561889648
Validation loss: 2.1775532960891724

Epoch: 6| Step: 7
Training loss: 0.9633821249008179
Validation loss: 2.2070563236872354

Epoch: 6| Step: 8
Training loss: 0.7657881379127502
Validation loss: 2.2180991967519126

Epoch: 6| Step: 9
Training loss: 1.1308619976043701
Validation loss: 2.2551045616467795

Epoch: 6| Step: 10
Training loss: 1.4819563627243042
Validation loss: 2.305374880631765

Epoch: 6| Step: 11
Training loss: 1.7890139818191528
Validation loss: 2.3054305712381997

Epoch: 6| Step: 12
Training loss: 1.979797124862671
Validation loss: 2.3013355334599814

Epoch: 6| Step: 13
Training loss: 2.144415855407715
Validation loss: 2.283464014530182

Epoch: 367| Step: 0
Training loss: 1.2579799890518188
Validation loss: 2.253288447856903

Epoch: 6| Step: 1
Training loss: 1.8512359857559204
Validation loss: 2.228876829147339

Epoch: 6| Step: 2
Training loss: 1.5632097721099854
Validation loss: 2.186657269795736

Epoch: 6| Step: 3
Training loss: 1.251722812652588
Validation loss: 2.1889803210894265

Epoch: 6| Step: 4
Training loss: 1.0903964042663574
Validation loss: 2.2361149191856384

Epoch: 6| Step: 5
Training loss: 0.9111542701721191
Validation loss: 2.206232786178589

Epoch: 6| Step: 6
Training loss: 0.7702257633209229
Validation loss: 2.210680603981018

Epoch: 6| Step: 7
Training loss: 2.013601779937744
Validation loss: 2.2835334142049155

Epoch: 6| Step: 8
Training loss: 1.0718843936920166
Validation loss: 2.2823529044787088

Epoch: 6| Step: 9
Training loss: 1.3004789352416992
Validation loss: 2.244355082511902

Epoch: 6| Step: 10
Training loss: 1.1759099960327148
Validation loss: 2.2668399810791016

Epoch: 6| Step: 11
Training loss: 1.2449830770492554
Validation loss: 2.2350124518076577

Epoch: 6| Step: 12
Training loss: 1.911238431930542
Validation loss: 2.2439589897791543

Epoch: 6| Step: 13
Training loss: 0.9957861304283142
Validation loss: 2.2539560993512473

Epoch: 368| Step: 0
Training loss: 1.1053537130355835
Validation loss: 2.2887631257375083

Epoch: 6| Step: 1
Training loss: 1.8393409252166748
Validation loss: 2.2953408559163413

Epoch: 6| Step: 2
Training loss: 0.6435467004776001
Validation loss: 2.2764209508895874

Epoch: 6| Step: 3
Training loss: 0.9379655122756958
Validation loss: 2.2582469979921975

Epoch: 6| Step: 4
Training loss: 1.7372854948043823
Validation loss: 2.2480299274126687

Epoch: 6| Step: 5
Training loss: 0.9590330123901367
Validation loss: 2.2156550884246826

Epoch: 6| Step: 6
Training loss: 1.3803281784057617
Validation loss: 2.2396074533462524

Epoch: 6| Step: 7
Training loss: 1.2791025638580322
Validation loss: 2.2714914282162986

Epoch: 6| Step: 8
Training loss: 0.7214881181716919
Validation loss: 2.273101886113485

Epoch: 6| Step: 9
Training loss: 1.4388591051101685
Validation loss: 2.2257229487101235

Epoch: 6| Step: 10
Training loss: 1.183239221572876
Validation loss: 2.274261236190796

Epoch: 6| Step: 11
Training loss: 1.5464816093444824
Validation loss: 2.246820648511251

Epoch: 6| Step: 12
Training loss: 1.4015002250671387
Validation loss: 2.2372197111447654

Epoch: 6| Step: 13
Training loss: 1.375135898590088
Validation loss: 2.2227683663368225

Epoch: 369| Step: 0
Training loss: 2.260610580444336
Validation loss: 2.223556717236837

Epoch: 6| Step: 1
Training loss: 1.2860007286071777
Validation loss: 2.22762397925059

Epoch: 6| Step: 2
Training loss: 0.7709360718727112
Validation loss: 2.2124276161193848

Epoch: 6| Step: 3
Training loss: 1.1264680624008179
Validation loss: 2.2060060501098633

Epoch: 6| Step: 4
Training loss: 1.3108012676239014
Validation loss: 2.2328234910964966

Epoch: 6| Step: 5
Training loss: 1.1340928077697754
Validation loss: 2.235620101292928

Epoch: 6| Step: 6
Training loss: 0.6246078610420227
Validation loss: 2.194700598716736

Epoch: 6| Step: 7
Training loss: 0.8811376094818115
Validation loss: 2.2020782232284546

Epoch: 6| Step: 8
Training loss: 0.8953263759613037
Validation loss: 2.2385257482528687

Epoch: 6| Step: 9
Training loss: 1.061847448348999
Validation loss: 2.264634827772776

Epoch: 6| Step: 10
Training loss: 1.4959909915924072
Validation loss: 2.267284393310547

Epoch: 6| Step: 11
Training loss: 1.6305917501449585
Validation loss: 2.2674952348073325

Epoch: 6| Step: 12
Training loss: 0.6374309062957764
Validation loss: 2.285042921702067

Epoch: 6| Step: 13
Training loss: 1.541275978088379
Validation loss: 2.295809725920359

Epoch: 370| Step: 0
Training loss: 1.119065761566162
Validation loss: 2.2503551046053567

Epoch: 6| Step: 1
Training loss: 0.7673614025115967
Validation loss: 2.270065208276113

Epoch: 6| Step: 2
Training loss: 1.2769086360931396
Validation loss: 2.2552546858787537

Epoch: 6| Step: 3
Training loss: 1.1044106483459473
Validation loss: 2.2415557503700256

Epoch: 6| Step: 4
Training loss: 1.274760127067566
Validation loss: 2.2669045527776084

Epoch: 6| Step: 5
Training loss: 1.2867929935455322
Validation loss: 2.2363359928131104

Epoch: 6| Step: 6
Training loss: 0.8418861031532288
Validation loss: 2.207153797149658

Epoch: 6| Step: 7
Training loss: 1.822533369064331
Validation loss: 2.1855167547861734

Epoch: 6| Step: 8
Training loss: 1.4076876640319824
Validation loss: 2.189141273498535

Epoch: 6| Step: 9
Training loss: 0.9266980886459351
Validation loss: 2.207415819168091

Epoch: 6| Step: 10
Training loss: 1.640252947807312
Validation loss: 2.158467451731364

Epoch: 6| Step: 11
Training loss: 1.5859065055847168
Validation loss: 2.236611485481262

Epoch: 6| Step: 12
Training loss: 0.7471437454223633
Validation loss: 2.179700175921122

Epoch: 6| Step: 13
Training loss: 0.9222734570503235
Validation loss: 2.212479809919993

Epoch: 371| Step: 0
Training loss: 1.3549830913543701
Validation loss: 2.221103608608246

Epoch: 6| Step: 1
Training loss: 1.0077943801879883
Validation loss: 2.2478421926498413

Epoch: 6| Step: 2
Training loss: 1.3236809968948364
Validation loss: 2.255789558092753

Epoch: 6| Step: 3
Training loss: 0.6188135147094727
Validation loss: 2.227204362551371

Epoch: 6| Step: 4
Training loss: 0.9472512602806091
Validation loss: 2.2083698908487954

Epoch: 6| Step: 5
Training loss: 0.9808511137962341
Validation loss: 2.269292632738749

Epoch: 6| Step: 6
Training loss: 0.5687065124511719
Validation loss: 2.2365346550941467

Epoch: 6| Step: 7
Training loss: 1.655325174331665
Validation loss: 2.2460664908091226

Epoch: 6| Step: 8
Training loss: 1.3137439489364624
Validation loss: 2.2309961915016174

Epoch: 6| Step: 9
Training loss: 1.74066162109375
Validation loss: 2.2176580826441445

Epoch: 6| Step: 10
Training loss: 1.2055974006652832
Validation loss: 2.224976062774658

Epoch: 6| Step: 11
Training loss: 1.1411652565002441
Validation loss: 2.2451964815457663

Epoch: 6| Step: 12
Training loss: 1.2809157371520996
Validation loss: 2.241888165473938

Epoch: 6| Step: 13
Training loss: 1.274362325668335
Validation loss: 2.289547304312388

Epoch: 372| Step: 0
Training loss: 1.4866496324539185
Validation loss: 2.27211066087087

Epoch: 6| Step: 1
Training loss: 1.6854336261749268
Validation loss: 2.267995516459147

Epoch: 6| Step: 2
Training loss: 0.9455893635749817
Validation loss: 2.31944473584493

Epoch: 6| Step: 3
Training loss: 1.4639348983764648
Validation loss: 2.315525392691294

Epoch: 6| Step: 4
Training loss: 0.9225771427154541
Validation loss: 2.2798526684443154

Epoch: 6| Step: 5
Training loss: 0.5202399492263794
Validation loss: 2.283251623312632

Epoch: 6| Step: 6
Training loss: 1.4677046537399292
Validation loss: 2.2408129374186196

Epoch: 6| Step: 7
Training loss: 1.5422245264053345
Validation loss: 2.227250317732493

Epoch: 6| Step: 8
Training loss: 0.81080162525177
Validation loss: 2.2572644551595054

Epoch: 6| Step: 9
Training loss: 1.2681925296783447
Validation loss: 2.2198355197906494

Epoch: 6| Step: 10
Training loss: 0.9721748232841492
Validation loss: 2.2092701196670532

Epoch: 6| Step: 11
Training loss: 1.6653138399124146
Validation loss: 2.219070295492808

Epoch: 6| Step: 12
Training loss: 1.074840784072876
Validation loss: 2.2052585085233054

Epoch: 6| Step: 13
Training loss: 1.5091452598571777
Validation loss: 2.2364837527275085

Epoch: 373| Step: 0
Training loss: 1.445457935333252
Validation loss: 2.1972655256589255

Epoch: 6| Step: 1
Training loss: 0.7590073347091675
Validation loss: 2.17623641093572

Epoch: 6| Step: 2
Training loss: 0.9810255765914917
Validation loss: 2.240383783976237

Epoch: 6| Step: 3
Training loss: 2.277233600616455
Validation loss: 2.199796219666799

Epoch: 6| Step: 4
Training loss: 0.7916765213012695
Validation loss: 2.1738189856211343

Epoch: 6| Step: 5
Training loss: 0.8875132203102112
Validation loss: 2.1792060335477195

Epoch: 6| Step: 6
Training loss: 0.7138447761535645
Validation loss: 2.2030889987945557

Epoch: 6| Step: 7
Training loss: 1.0778772830963135
Validation loss: 2.1647758881251016

Epoch: 6| Step: 8
Training loss: 1.2867974042892456
Validation loss: 2.1590354641278586

Epoch: 6| Step: 9
Training loss: 1.3367226123809814
Validation loss: 2.182819426059723

Epoch: 6| Step: 10
Training loss: 1.4732441902160645
Validation loss: 2.211644152800242

Epoch: 6| Step: 11
Training loss: 1.2501544952392578
Validation loss: 2.2196144262949624

Epoch: 6| Step: 12
Training loss: 0.7437763214111328
Validation loss: 2.226271867752075

Epoch: 6| Step: 13
Training loss: 0.9234097599983215
Validation loss: 2.1664644678433738

Epoch: 374| Step: 0
Training loss: 1.3930362462997437
Validation loss: 2.1834874550501504

Epoch: 6| Step: 1
Training loss: 1.5892152786254883
Validation loss: 2.2017460664113364

Epoch: 6| Step: 2
Training loss: 0.8985876441001892
Validation loss: 2.241636494795481

Epoch: 6| Step: 3
Training loss: 1.1282460689544678
Validation loss: 2.230737090110779

Epoch: 6| Step: 4
Training loss: 1.669418454170227
Validation loss: 2.20961731672287

Epoch: 6| Step: 5
Training loss: 0.8502604961395264
Validation loss: 2.30492240190506

Epoch: 6| Step: 6
Training loss: 1.122298002243042
Validation loss: 2.2646316289901733

Epoch: 6| Step: 7
Training loss: 0.9703043699264526
Validation loss: 2.293502151966095

Epoch: 6| Step: 8
Training loss: 1.621027946472168
Validation loss: 2.282046675682068

Epoch: 6| Step: 9
Training loss: 0.9247645139694214
Validation loss: 2.2907461325327554

Epoch: 6| Step: 10
Training loss: 0.7112562656402588
Validation loss: 2.203204353650411

Epoch: 6| Step: 11
Training loss: 1.3359298706054688
Validation loss: 2.264477550983429

Epoch: 6| Step: 12
Training loss: 1.3962821960449219
Validation loss: 2.228380878766378

Epoch: 6| Step: 13
Training loss: 1.1106112003326416
Validation loss: 2.2105777661005654

Epoch: 375| Step: 0
Training loss: 1.2804142236709595
Validation loss: 2.221925218900045

Epoch: 6| Step: 1
Training loss: 1.1618143320083618
Validation loss: 2.2210668524106345

Epoch: 6| Step: 2
Training loss: 1.6649413108825684
Validation loss: 2.1712101101875305

Epoch: 6| Step: 3
Training loss: 0.7225930690765381
Validation loss: 2.159794489542643

Epoch: 6| Step: 4
Training loss: 1.2981210947036743
Validation loss: 2.219188610712687

Epoch: 6| Step: 5
Training loss: 1.11348557472229
Validation loss: 2.2267541885375977

Epoch: 6| Step: 6
Training loss: 1.2870869636535645
Validation loss: 2.2562504212061563

Epoch: 6| Step: 7
Training loss: 1.8271209001541138
Validation loss: 2.2128573258717856

Epoch: 6| Step: 8
Training loss: 2.489069938659668
Validation loss: 2.197115739186605

Epoch: 6| Step: 9
Training loss: 1.0301146507263184
Validation loss: 2.16685289144516

Epoch: 6| Step: 10
Training loss: 1.2855530977249146
Validation loss: 2.142425298690796

Epoch: 6| Step: 11
Training loss: 0.5650368928909302
Validation loss: 2.1767322222391763

Epoch: 6| Step: 12
Training loss: 1.0549609661102295
Validation loss: 2.1524961590766907

Epoch: 6| Step: 13
Training loss: 1.1972100734710693
Validation loss: 2.1830934882164

Epoch: 376| Step: 0
Training loss: 1.0106087923049927
Validation loss: 2.1547346711158752

Epoch: 6| Step: 1
Training loss: 0.8922960162162781
Validation loss: 2.167892336845398

Epoch: 6| Step: 2
Training loss: 0.7142707705497742
Validation loss: 2.168161153793335

Epoch: 6| Step: 3
Training loss: 2.1588058471679688
Validation loss: 2.1988983750343323

Epoch: 6| Step: 4
Training loss: 1.3961344957351685
Validation loss: 2.172058343887329

Epoch: 6| Step: 5
Training loss: 1.0271512269973755
Validation loss: 2.174836734930674

Epoch: 6| Step: 6
Training loss: 0.8509793281555176
Validation loss: 2.170577804247538

Epoch: 6| Step: 7
Training loss: 0.8479288220405579
Validation loss: 2.2771912813186646

Epoch: 6| Step: 8
Training loss: 0.9334064722061157
Validation loss: 2.2670729557673135

Epoch: 6| Step: 9
Training loss: 1.6402782201766968
Validation loss: 2.266950090726217

Epoch: 6| Step: 10
Training loss: 1.4658782482147217
Validation loss: 2.2780699928601584

Epoch: 6| Step: 11
Training loss: 1.7417672872543335
Validation loss: 2.286811808745066

Epoch: 6| Step: 12
Training loss: 0.6243613362312317
Validation loss: 2.293775757153829

Epoch: 6| Step: 13
Training loss: 0.8247501254081726
Validation loss: 2.2840667168299356

Epoch: 377| Step: 0
Training loss: 0.950853168964386
Validation loss: 2.318485955397288

Epoch: 6| Step: 1
Training loss: 0.8980493545532227
Validation loss: 2.309397260348002

Epoch: 6| Step: 2
Training loss: 0.9065546989440918
Validation loss: 2.2665360967318215

Epoch: 6| Step: 3
Training loss: 2.2184600830078125
Validation loss: 2.3198137482007346

Epoch: 6| Step: 4
Training loss: 1.0009487867355347
Validation loss: 2.299688696861267

Epoch: 6| Step: 5
Training loss: 1.0825408697128296
Validation loss: 2.2815410494804382

Epoch: 6| Step: 6
Training loss: 0.9386085271835327
Validation loss: 2.280473073323568

Epoch: 6| Step: 7
Training loss: 1.0210344791412354
Validation loss: 2.300270656744639

Epoch: 6| Step: 8
Training loss: 1.207330584526062
Validation loss: 2.307662606239319

Epoch: 6| Step: 9
Training loss: 1.6636863946914673
Validation loss: 2.290878971417745

Epoch: 6| Step: 10
Training loss: 1.4263033866882324
Validation loss: 2.261011322339376

Epoch: 6| Step: 11
Training loss: 1.5728800296783447
Validation loss: 2.2664937178293862

Epoch: 6| Step: 12
Training loss: 1.547971487045288
Validation loss: 2.2850689689318338

Epoch: 6| Step: 13
Training loss: 0.6731307506561279
Validation loss: 2.240166445573171

Epoch: 378| Step: 0
Training loss: 1.5347684621810913
Validation loss: 2.2334837516148887

Epoch: 6| Step: 1
Training loss: 1.8255990743637085
Validation loss: 2.204043984413147

Epoch: 6| Step: 2
Training loss: 0.6751004457473755
Validation loss: 2.1989838083585105

Epoch: 6| Step: 3
Training loss: 0.7839194536209106
Validation loss: 2.156829516092936

Epoch: 6| Step: 4
Training loss: 0.9686630964279175
Validation loss: 2.1842169761657715

Epoch: 6| Step: 5
Training loss: 0.5030381083488464
Validation loss: 2.1991136272748313

Epoch: 6| Step: 6
Training loss: 0.9613670706748962
Validation loss: 2.1698943972587585

Epoch: 6| Step: 7
Training loss: 1.01686429977417
Validation loss: 2.190249423185984

Epoch: 6| Step: 8
Training loss: 1.4659503698349
Validation loss: 2.2113334933916726

Epoch: 6| Step: 9
Training loss: 1.4467475414276123
Validation loss: 2.214717904726664

Epoch: 6| Step: 10
Training loss: 1.7734401226043701
Validation loss: 2.2119373281796775

Epoch: 6| Step: 11
Training loss: 1.3331794738769531
Validation loss: 2.230690121650696

Epoch: 6| Step: 12
Training loss: 1.1409456729888916
Validation loss: 2.2538283864657083

Epoch: 6| Step: 13
Training loss: 1.037300944328308
Validation loss: 2.2856915394465127

Epoch: 379| Step: 0
Training loss: 1.178750991821289
Validation loss: 2.2763992746671042

Epoch: 6| Step: 1
Training loss: 0.8186020255088806
Validation loss: 2.2795437773068747

Epoch: 6| Step: 2
Training loss: 1.4850157499313354
Validation loss: 2.288392265637716

Epoch: 6| Step: 3
Training loss: 0.7490894198417664
Validation loss: 2.2977423667907715

Epoch: 6| Step: 4
Training loss: 1.7228080034255981
Validation loss: 2.3173919518788657

Epoch: 6| Step: 5
Training loss: 1.673766016960144
Validation loss: 2.25430428981781

Epoch: 6| Step: 6
Training loss: 0.8050129413604736
Validation loss: 2.231455643971761

Epoch: 6| Step: 7
Training loss: 1.3582887649536133
Validation loss: 2.2505534291267395

Epoch: 6| Step: 8
Training loss: 1.599955439567566
Validation loss: 2.2217323978741965

Epoch: 6| Step: 9
Training loss: 1.2007582187652588
Validation loss: 2.2345911463101706

Epoch: 6| Step: 10
Training loss: 0.8309396505355835
Validation loss: 2.201522946357727

Epoch: 6| Step: 11
Training loss: 1.1857705116271973
Validation loss: 2.203497350215912

Epoch: 6| Step: 12
Training loss: 0.9684420824050903
Validation loss: 2.206684668858846

Epoch: 6| Step: 13
Training loss: 1.3039205074310303
Validation loss: 2.241100271542867

Epoch: 380| Step: 0
Training loss: 1.4019410610198975
Validation loss: 2.181329071521759

Epoch: 6| Step: 1
Training loss: 1.5086443424224854
Validation loss: 2.2107338110605874

Epoch: 6| Step: 2
Training loss: 1.0422213077545166
Validation loss: 2.2291794617970786

Epoch: 6| Step: 3
Training loss: 0.641635000705719
Validation loss: 2.1997152169545493

Epoch: 6| Step: 4
Training loss: 0.8780182003974915
Validation loss: 2.23951248327891

Epoch: 6| Step: 5
Training loss: 1.0399671792984009
Validation loss: 2.196195403734843

Epoch: 6| Step: 6
Training loss: 0.799521803855896
Validation loss: 2.21276984612147

Epoch: 6| Step: 7
Training loss: 1.2870699167251587
Validation loss: 2.218829393386841

Epoch: 6| Step: 8
Training loss: 1.514324426651001
Validation loss: 2.223236560821533

Epoch: 6| Step: 9
Training loss: 0.7930582761764526
Validation loss: 2.2704543272654214

Epoch: 6| Step: 10
Training loss: 1.2379481792449951
Validation loss: 2.306246201197306

Epoch: 6| Step: 11
Training loss: 1.2665756940841675
Validation loss: 2.264849046866099

Epoch: 6| Step: 12
Training loss: 1.6687963008880615
Validation loss: 2.2606961131095886

Epoch: 6| Step: 13
Training loss: 1.4251182079315186
Validation loss: 2.213591535886129

Epoch: 381| Step: 0
Training loss: 0.9224393367767334
Validation loss: 2.2096222043037415

Epoch: 6| Step: 1
Training loss: 1.4132243394851685
Validation loss: 2.246761699517568

Epoch: 6| Step: 2
Training loss: 1.4746413230895996
Validation loss: 2.2358838319778442

Epoch: 6| Step: 3
Training loss: 0.7445796728134155
Validation loss: 2.24049973487854

Epoch: 6| Step: 4
Training loss: 1.8687427043914795
Validation loss: 2.2350218892097473

Epoch: 6| Step: 5
Training loss: 0.907565176486969
Validation loss: 2.2520720958709717

Epoch: 6| Step: 6
Training loss: 1.3216197490692139
Validation loss: 2.256444195906321

Epoch: 6| Step: 7
Training loss: 1.3698716163635254
Validation loss: 2.2477051417032876

Epoch: 6| Step: 8
Training loss: 1.0726006031036377
Validation loss: 2.26000448067983

Epoch: 6| Step: 9
Training loss: 0.8371151089668274
Validation loss: 2.2409462134043374

Epoch: 6| Step: 10
Training loss: 2.043203830718994
Validation loss: 2.2430635690689087

Epoch: 6| Step: 11
Training loss: 0.5103507041931152
Validation loss: 2.2295779387156167

Epoch: 6| Step: 12
Training loss: 0.7260656356811523
Validation loss: 2.2655377785364785

Epoch: 6| Step: 13
Training loss: 1.5568087100982666
Validation loss: 2.2379742662111917

Epoch: 382| Step: 0
Training loss: 1.6246423721313477
Validation loss: 2.1802021265029907

Epoch: 6| Step: 1
Training loss: 1.1985247135162354
Validation loss: 2.2695248325665793

Epoch: 6| Step: 2
Training loss: 1.0737836360931396
Validation loss: 2.241815427939097

Epoch: 6| Step: 3
Training loss: 0.5733073949813843
Validation loss: 2.2053954799969993

Epoch: 6| Step: 4
Training loss: 0.8275948166847229
Validation loss: 2.2045222520828247

Epoch: 6| Step: 5
Training loss: 0.9512012004852295
Validation loss: 2.209370493888855

Epoch: 6| Step: 6
Training loss: 1.491234302520752
Validation loss: 2.2470783591270447

Epoch: 6| Step: 7
Training loss: 1.7374355792999268
Validation loss: 2.190672298272451

Epoch: 6| Step: 8
Training loss: 1.1199641227722168
Validation loss: 2.213605443636576

Epoch: 6| Step: 9
Training loss: 1.0747191905975342
Validation loss: 2.2033708691596985

Epoch: 6| Step: 10
Training loss: 1.2517740726470947
Validation loss: 2.131454070409139

Epoch: 6| Step: 11
Training loss: 0.8552153706550598
Validation loss: 2.1609556476275125

Epoch: 6| Step: 12
Training loss: 1.2778213024139404
Validation loss: 2.1852271358172097

Epoch: 6| Step: 13
Training loss: 1.530472993850708
Validation loss: 2.212951203187307

Epoch: 383| Step: 0
Training loss: 2.006617784500122
Validation loss: 2.2111698587735495

Epoch: 6| Step: 1
Training loss: 0.7958487272262573
Validation loss: 2.2304410139719644

Epoch: 6| Step: 2
Training loss: 1.2164249420166016
Validation loss: 2.2053176760673523

Epoch: 6| Step: 3
Training loss: 1.2723065614700317
Validation loss: 2.256472627321879

Epoch: 6| Step: 4
Training loss: 0.8572692275047302
Validation loss: 2.1879896918932595

Epoch: 6| Step: 5
Training loss: 1.0212481021881104
Validation loss: 2.207028408845266

Epoch: 6| Step: 6
Training loss: 1.2127116918563843
Validation loss: 2.2316417892773948

Epoch: 6| Step: 7
Training loss: 1.4674789905548096
Validation loss: 2.239229162534078

Epoch: 6| Step: 8
Training loss: 1.0496547222137451
Validation loss: 2.2753210067749023

Epoch: 6| Step: 9
Training loss: 2.3243181705474854
Validation loss: 2.263651490211487

Epoch: 6| Step: 10
Training loss: 1.5011723041534424
Validation loss: 2.2789188424746194

Epoch: 6| Step: 11
Training loss: 1.4190044403076172
Validation loss: 2.224571386973063

Epoch: 6| Step: 12
Training loss: 0.5993492603302002
Validation loss: 2.2042636275291443

Epoch: 6| Step: 13
Training loss: 0.6106203198432922
Validation loss: 2.224065144856771

Epoch: 384| Step: 0
Training loss: 1.409543514251709
Validation loss: 2.1955273946126304

Epoch: 6| Step: 1
Training loss: 1.0056908130645752
Validation loss: 2.2059494256973267

Epoch: 6| Step: 2
Training loss: 2.601325511932373
Validation loss: 2.1599597334861755

Epoch: 6| Step: 3
Training loss: 1.0152829885482788
Validation loss: 2.2021355430285134

Epoch: 6| Step: 4
Training loss: 0.8890170454978943
Validation loss: 2.1995702981948853

Epoch: 6| Step: 5
Training loss: 1.0515636205673218
Validation loss: 2.1620925267537436

Epoch: 6| Step: 6
Training loss: 1.7147152423858643
Validation loss: 2.1917264262835183

Epoch: 6| Step: 7
Training loss: 0.9308122396469116
Validation loss: 2.2233691612879434

Epoch: 6| Step: 8
Training loss: 0.8540258407592773
Validation loss: 2.289180040359497

Epoch: 6| Step: 9
Training loss: 0.7724090814590454
Validation loss: 2.33042573928833

Epoch: 6| Step: 10
Training loss: 1.2834291458129883
Validation loss: 2.2903507550557456

Epoch: 6| Step: 11
Training loss: 1.453700065612793
Validation loss: 2.331490079561869

Epoch: 6| Step: 12
Training loss: 1.7674615383148193
Validation loss: 2.3264777263005576

Epoch: 6| Step: 13
Training loss: 0.8935321569442749
Validation loss: 2.2934376200040183

Epoch: 385| Step: 0
Training loss: 1.2233688831329346
Validation loss: 2.2587023973464966

Epoch: 6| Step: 1
Training loss: 1.2775487899780273
Validation loss: 2.2740487257639566

Epoch: 6| Step: 2
Training loss: 0.7960527539253235
Validation loss: 2.203040838241577

Epoch: 6| Step: 3
Training loss: 1.3872311115264893
Validation loss: 2.2297980388005576

Epoch: 6| Step: 4
Training loss: 1.164210319519043
Validation loss: 2.209199051062266

Epoch: 6| Step: 5
Training loss: 0.7711999416351318
Validation loss: 2.204583783944448

Epoch: 6| Step: 6
Training loss: 1.099349021911621
Validation loss: 2.189030090967814

Epoch: 6| Step: 7
Training loss: 0.7512961626052856
Validation loss: 2.2102094888687134

Epoch: 6| Step: 8
Training loss: 1.1781679391860962
Validation loss: 2.2012510299682617

Epoch: 6| Step: 9
Training loss: 1.6392263174057007
Validation loss: 2.2121349573135376

Epoch: 6| Step: 10
Training loss: 2.034759998321533
Validation loss: 2.2091184258461

Epoch: 6| Step: 11
Training loss: 0.6887267827987671
Validation loss: 2.212040344874064

Epoch: 6| Step: 12
Training loss: 1.03425133228302
Validation loss: 2.2278680404027305

Epoch: 6| Step: 13
Training loss: 1.2738724946975708
Validation loss: 2.270037293434143

Epoch: 386| Step: 0
Training loss: 1.5580713748931885
Validation loss: 2.284629245599111

Epoch: 6| Step: 1
Training loss: 1.7401111125946045
Validation loss: 2.267119566599528

Epoch: 6| Step: 2
Training loss: 1.0127609968185425
Validation loss: 2.2587173779805503

Epoch: 6| Step: 3
Training loss: 1.4015811681747437
Validation loss: 2.2634976704915366

Epoch: 6| Step: 4
Training loss: 0.8092116713523865
Validation loss: 2.2183510661125183

Epoch: 6| Step: 5
Training loss: 1.284805417060852
Validation loss: 2.2399205565452576

Epoch: 6| Step: 6
Training loss: 1.4862473011016846
Validation loss: 2.2170549233754477

Epoch: 6| Step: 7
Training loss: 1.1717791557312012
Validation loss: 2.1627372900644937

Epoch: 6| Step: 8
Training loss: 1.2017804384231567
Validation loss: 2.182648519674937

Epoch: 6| Step: 9
Training loss: 1.490417242050171
Validation loss: 2.1835521856943765

Epoch: 6| Step: 10
Training loss: 1.0214550495147705
Validation loss: 2.1716599663098655

Epoch: 6| Step: 11
Training loss: 1.4375462532043457
Validation loss: 2.1811267932256064

Epoch: 6| Step: 12
Training loss: 1.1091890335083008
Validation loss: 2.177445630232493

Epoch: 6| Step: 13
Training loss: 1.1325241327285767
Validation loss: 2.1944138010342917

Epoch: 387| Step: 0
Training loss: 2.1568727493286133
Validation loss: 2.1964240074157715

Epoch: 6| Step: 1
Training loss: 0.8011318445205688
Validation loss: 2.1960432132085166

Epoch: 6| Step: 2
Training loss: 1.4071882963180542
Validation loss: 2.2024232149124146

Epoch: 6| Step: 3
Training loss: 1.3635696172714233
Validation loss: 2.1793504556020102

Epoch: 6| Step: 4
Training loss: 1.3660651445388794
Validation loss: 2.215677261352539

Epoch: 6| Step: 5
Training loss: 0.9525505304336548
Validation loss: 2.212934950987498

Epoch: 6| Step: 6
Training loss: 1.0298043489456177
Validation loss: 2.1859414180119834

Epoch: 6| Step: 7
Training loss: 1.59189772605896
Validation loss: 2.183696230252584

Epoch: 6| Step: 8
Training loss: 0.5858062505722046
Validation loss: 2.2322955330212912

Epoch: 6| Step: 9
Training loss: 0.8555179238319397
Validation loss: 2.2168002327283225

Epoch: 6| Step: 10
Training loss: 1.5930330753326416
Validation loss: 2.206325570742289

Epoch: 6| Step: 11
Training loss: 1.065859079360962
Validation loss: 2.1684776544570923

Epoch: 6| Step: 12
Training loss: 1.3471825122833252
Validation loss: 2.200126131375631

Epoch: 6| Step: 13
Training loss: 1.039875864982605
Validation loss: 2.2668526570002236

Epoch: 388| Step: 0
Training loss: 1.5044312477111816
Validation loss: 2.2216918071111045

Epoch: 6| Step: 1
Training loss: 0.6817253232002258
Validation loss: 2.2226521372795105

Epoch: 6| Step: 2
Training loss: 0.8968485593795776
Validation loss: 2.2839362621307373

Epoch: 6| Step: 3
Training loss: 1.6385773420333862
Validation loss: 2.269038120905558

Epoch: 6| Step: 4
Training loss: 0.8157981634140015
Validation loss: 2.2566730777422586

Epoch: 6| Step: 5
Training loss: 1.139796257019043
Validation loss: 2.205089588960012

Epoch: 6| Step: 6
Training loss: 0.9430816173553467
Validation loss: 2.1619609594345093

Epoch: 6| Step: 7
Training loss: 1.059615969657898
Validation loss: 2.1987614035606384

Epoch: 6| Step: 8
Training loss: 0.7104285359382629
Validation loss: 2.167980889479319

Epoch: 6| Step: 9
Training loss: 0.7720668315887451
Validation loss: 2.2296701073646545

Epoch: 6| Step: 10
Training loss: 1.3810023069381714
Validation loss: 2.217614014943441

Epoch: 6| Step: 11
Training loss: 1.9600603580474854
Validation loss: 2.138211270173391

Epoch: 6| Step: 12
Training loss: 1.2713348865509033
Validation loss: 2.1798209150632224

Epoch: 6| Step: 13
Training loss: 1.1441707611083984
Validation loss: 2.1575735211372375

Epoch: 389| Step: 0
Training loss: 0.6056022047996521
Validation loss: 2.1911933024724326

Epoch: 6| Step: 1
Training loss: 0.5257066488265991
Validation loss: 2.1877876917521157

Epoch: 6| Step: 2
Training loss: 0.7844034433364868
Validation loss: 2.2018120288848877

Epoch: 6| Step: 3
Training loss: 1.2148547172546387
Validation loss: 2.2053473591804504

Epoch: 6| Step: 4
Training loss: 0.6006603240966797
Validation loss: 2.185141702493032

Epoch: 6| Step: 5
Training loss: 1.3264507055282593
Validation loss: 2.1984113454818726

Epoch: 6| Step: 6
Training loss: 1.1581640243530273
Validation loss: 2.2454460660616555

Epoch: 6| Step: 7
Training loss: 0.8890615105628967
Validation loss: 2.2445545196533203

Epoch: 6| Step: 8
Training loss: 1.62998366355896
Validation loss: 2.2288608153661094

Epoch: 6| Step: 9
Training loss: 1.2052927017211914
Validation loss: 2.206876198450724

Epoch: 6| Step: 10
Training loss: 1.571835994720459
Validation loss: 2.2588183482488

Epoch: 6| Step: 11
Training loss: 1.4356045722961426
Validation loss: 2.254397730032603

Epoch: 6| Step: 12
Training loss: 1.0633327960968018
Validation loss: 2.244213819503784

Epoch: 6| Step: 13
Training loss: 1.3936017751693726
Validation loss: 2.230444153149923

Epoch: 390| Step: 0
Training loss: 0.5271326303482056
Validation loss: 2.2372607986132302

Epoch: 6| Step: 1
Training loss: 1.6464157104492188
Validation loss: 2.245485027631124

Epoch: 6| Step: 2
Training loss: 0.6784701347351074
Validation loss: 2.2278037865956626

Epoch: 6| Step: 3
Training loss: 1.209484338760376
Validation loss: 2.1932610074679055

Epoch: 6| Step: 4
Training loss: 0.7231835722923279
Validation loss: 2.2260080774625144

Epoch: 6| Step: 5
Training loss: 1.1346116065979004
Validation loss: 2.186420261859894

Epoch: 6| Step: 6
Training loss: 1.6699403524398804
Validation loss: 2.162312150001526

Epoch: 6| Step: 7
Training loss: 0.934057354927063
Validation loss: 2.1622852087020874

Epoch: 6| Step: 8
Training loss: 0.8340853452682495
Validation loss: 2.2278841535250344

Epoch: 6| Step: 9
Training loss: 1.1676747798919678
Validation loss: 2.197685440381368

Epoch: 6| Step: 10
Training loss: 1.0221424102783203
Validation loss: 2.196549574534098

Epoch: 6| Step: 11
Training loss: 0.8771877884864807
Validation loss: 2.182053327560425

Epoch: 6| Step: 12
Training loss: 2.145846366882324
Validation loss: 2.209832191467285

Epoch: 6| Step: 13
Training loss: 0.8019817471504211
Validation loss: 2.18828550974528

Epoch: 391| Step: 0
Training loss: 1.405953288078308
Validation loss: 2.1477702061335244

Epoch: 6| Step: 1
Training loss: 1.2657097578048706
Validation loss: 2.173998177051544

Epoch: 6| Step: 2
Training loss: 0.8006701469421387
Validation loss: 2.2352154652277627

Epoch: 6| Step: 3
Training loss: 1.092254638671875
Validation loss: 2.2316317160924277

Epoch: 6| Step: 4
Training loss: 1.0997755527496338
Validation loss: 2.257327755292257

Epoch: 6| Step: 5
Training loss: 1.1934947967529297
Validation loss: 2.236622174580892

Epoch: 6| Step: 6
Training loss: 0.89113849401474
Validation loss: 2.2777926921844482

Epoch: 6| Step: 7
Training loss: 0.7796868085861206
Validation loss: 2.2546788454055786

Epoch: 6| Step: 8
Training loss: 1.3569992780685425
Validation loss: 2.316341539223989

Epoch: 6| Step: 9
Training loss: 1.028708577156067
Validation loss: 2.2703351775805154

Epoch: 6| Step: 10
Training loss: 0.6292293667793274
Validation loss: 2.2712706128756204

Epoch: 6| Step: 11
Training loss: 1.1903772354125977
Validation loss: 2.2761301596959433

Epoch: 6| Step: 12
Training loss: 1.7968382835388184
Validation loss: 2.2058500051498413

Epoch: 6| Step: 13
Training loss: 0.657107949256897
Validation loss: 2.2432252168655396

Epoch: 392| Step: 0
Training loss: 1.1673873662948608
Validation loss: 2.2377916177113852

Epoch: 6| Step: 1
Training loss: 1.1069550514221191
Validation loss: 2.2193124691645303

Epoch: 6| Step: 2
Training loss: 1.208861231803894
Validation loss: 2.2244556148846946

Epoch: 6| Step: 3
Training loss: 1.2685787677764893
Validation loss: 2.2089125514030457

Epoch: 6| Step: 4
Training loss: 0.5463901162147522
Validation loss: 2.251271406809489

Epoch: 6| Step: 5
Training loss: 0.8664380311965942
Validation loss: 2.2380324403444924

Epoch: 6| Step: 6
Training loss: 1.5059561729431152
Validation loss: 2.220941960811615

Epoch: 6| Step: 7
Training loss: 1.098610758781433
Validation loss: 2.2112390597661338

Epoch: 6| Step: 8
Training loss: 0.5720812082290649
Validation loss: 2.2061434586842856

Epoch: 6| Step: 9
Training loss: 1.3268297910690308
Validation loss: 2.2053884863853455

Epoch: 6| Step: 10
Training loss: 1.4955925941467285
Validation loss: 2.195578475793203

Epoch: 6| Step: 11
Training loss: 0.8887195587158203
Validation loss: 2.228222409884135

Epoch: 6| Step: 12
Training loss: 1.2218581438064575
Validation loss: 2.1934611201286316

Epoch: 6| Step: 13
Training loss: 1.2329474687576294
Validation loss: 2.1638184189796448

Epoch: 393| Step: 0
Training loss: 1.194915771484375
Validation loss: 2.2234186927477517

Epoch: 6| Step: 1
Training loss: 0.9916764497756958
Validation loss: 2.210135062535604

Epoch: 6| Step: 2
Training loss: 1.021760106086731
Validation loss: 2.2236982186635337

Epoch: 6| Step: 3
Training loss: 1.2096583843231201
Validation loss: 2.2449434995651245

Epoch: 6| Step: 4
Training loss: 1.2375950813293457
Validation loss: 2.2914257844289145

Epoch: 6| Step: 5
Training loss: 0.7544413805007935
Validation loss: 2.23831969499588

Epoch: 6| Step: 6
Training loss: 1.1058944463729858
Validation loss: 2.2553900678952536

Epoch: 6| Step: 7
Training loss: 1.3884408473968506
Validation loss: 2.3015974958737693

Epoch: 6| Step: 8
Training loss: 1.288557767868042
Validation loss: 2.292846977710724

Epoch: 6| Step: 9
Training loss: 1.0299177169799805
Validation loss: 2.273168206214905

Epoch: 6| Step: 10
Training loss: 1.400932788848877
Validation loss: 2.2428587873776755

Epoch: 6| Step: 11
Training loss: 1.3022820949554443
Validation loss: 2.2418527801831565

Epoch: 6| Step: 12
Training loss: 0.8616554737091064
Validation loss: 2.2140019734700522

Epoch: 6| Step: 13
Training loss: 1.7695701122283936
Validation loss: 2.183738648891449

Epoch: 394| Step: 0
Training loss: 1.0350897312164307
Validation loss: 2.198537846406301

Epoch: 6| Step: 1
Training loss: 1.3175839185714722
Validation loss: 2.180420398712158

Epoch: 6| Step: 2
Training loss: 1.1103724241256714
Validation loss: 2.177062749862671

Epoch: 6| Step: 3
Training loss: 2.1573376655578613
Validation loss: 2.1856267849604287

Epoch: 6| Step: 4
Training loss: 1.171778678894043
Validation loss: 2.22237761815389

Epoch: 6| Step: 5
Training loss: 1.0522363185882568
Validation loss: 2.1925220290819802

Epoch: 6| Step: 6
Training loss: 1.2606163024902344
Validation loss: 2.2276188135147095

Epoch: 6| Step: 7
Training loss: 0.9796841144561768
Validation loss: 2.19100554784139

Epoch: 6| Step: 8
Training loss: 1.3451725244522095
Validation loss: 2.1856507857640586

Epoch: 6| Step: 9
Training loss: 0.611383855342865
Validation loss: 2.192491094271342

Epoch: 6| Step: 10
Training loss: 1.18662691116333
Validation loss: 2.223044296105703

Epoch: 6| Step: 11
Training loss: 0.6729161143302917
Validation loss: 2.2401214043299356

Epoch: 6| Step: 12
Training loss: 0.7692004442214966
Validation loss: 2.2395686705907187

Epoch: 6| Step: 13
Training loss: 0.9639191031455994
Validation loss: 2.2043938636779785

Epoch: 395| Step: 0
Training loss: 0.9215751886367798
Validation loss: 2.214681704839071

Epoch: 6| Step: 1
Training loss: 1.4730807542800903
Validation loss: 2.255512555440267

Epoch: 6| Step: 2
Training loss: 0.8907080292701721
Validation loss: 2.2667065461476645

Epoch: 6| Step: 3
Training loss: 1.1421051025390625
Validation loss: 2.2515764236450195

Epoch: 6| Step: 4
Training loss: 0.6681146621704102
Validation loss: 2.288720746835073

Epoch: 6| Step: 5
Training loss: 0.9050300121307373
Validation loss: 2.2485203544298806

Epoch: 6| Step: 6
Training loss: 1.6955163478851318
Validation loss: 2.2535836895306907

Epoch: 6| Step: 7
Training loss: 1.0118882656097412
Validation loss: 2.2515904704729715

Epoch: 6| Step: 8
Training loss: 1.141187071800232
Validation loss: 2.249213377634684

Epoch: 6| Step: 9
Training loss: 1.5220067501068115
Validation loss: 2.2387407620747886

Epoch: 6| Step: 10
Training loss: 1.456763505935669
Validation loss: 2.2823659380277

Epoch: 6| Step: 11
Training loss: 0.7877401113510132
Validation loss: 2.248502572377523

Epoch: 6| Step: 12
Training loss: 0.7075918912887573
Validation loss: 2.2954124013582864

Epoch: 6| Step: 13
Training loss: 0.9373995661735535
Validation loss: 2.2144919435183206

Epoch: 396| Step: 0
Training loss: 0.7633658051490784
Validation loss: 2.2596923311551413

Epoch: 6| Step: 1
Training loss: 0.6938294768333435
Validation loss: 2.2446744044621787

Epoch: 6| Step: 2
Training loss: 1.0986132621765137
Validation loss: 2.2077810366948447

Epoch: 6| Step: 3
Training loss: 0.9820098280906677
Validation loss: 2.2415830294291177

Epoch: 6| Step: 4
Training loss: 1.1950254440307617
Validation loss: 2.252462387084961

Epoch: 6| Step: 5
Training loss: 1.1701123714447021
Validation loss: 2.239919741948446

Epoch: 6| Step: 6
Training loss: 1.537007451057434
Validation loss: 2.239614963531494

Epoch: 6| Step: 7
Training loss: 0.6807204484939575
Validation loss: 2.207196513811747

Epoch: 6| Step: 8
Training loss: 1.3455283641815186
Validation loss: 2.208593428134918

Epoch: 6| Step: 9
Training loss: 0.563080906867981
Validation loss: 2.179858406384786

Epoch: 6| Step: 10
Training loss: 1.8344672918319702
Validation loss: 2.173556387424469

Epoch: 6| Step: 11
Training loss: 1.1098558902740479
Validation loss: 2.155070682366689

Epoch: 6| Step: 12
Training loss: 1.056642770767212
Validation loss: 2.2066744565963745

Epoch: 6| Step: 13
Training loss: 1.1526648998260498
Validation loss: 2.186164359251658

Epoch: 397| Step: 0
Training loss: 0.8887114524841309
Validation loss: 2.1961750189463296

Epoch: 6| Step: 1
Training loss: 0.7197132110595703
Validation loss: 2.1539998253186545

Epoch: 6| Step: 2
Training loss: 0.9926856160163879
Validation loss: 2.214904268582662

Epoch: 6| Step: 3
Training loss: 1.4786641597747803
Validation loss: 2.1869975924491882

Epoch: 6| Step: 4
Training loss: 0.8178176879882812
Validation loss: 2.227267245451609

Epoch: 6| Step: 5
Training loss: 1.1541789770126343
Validation loss: 2.2314834594726562

Epoch: 6| Step: 6
Training loss: 1.4275176525115967
Validation loss: 2.190681060155233

Epoch: 6| Step: 7
Training loss: 0.908293604850769
Validation loss: 2.2516154448191323

Epoch: 6| Step: 8
Training loss: 0.825652003288269
Validation loss: 2.229048232237498

Epoch: 6| Step: 9
Training loss: 0.6895995140075684
Validation loss: 2.212705592314402

Epoch: 6| Step: 10
Training loss: 0.7785576581954956
Validation loss: 2.220429241657257

Epoch: 6| Step: 11
Training loss: 1.571913480758667
Validation loss: 2.180642386277517

Epoch: 6| Step: 12
Training loss: 0.7826836705207825
Validation loss: 2.1768638690312705

Epoch: 6| Step: 13
Training loss: 1.2642356157302856
Validation loss: 2.1953232487042746

Epoch: 398| Step: 0
Training loss: 0.6414113640785217
Validation loss: 2.1837661067644754

Epoch: 6| Step: 1
Training loss: 0.7148263454437256
Validation loss: 2.199679712454478

Epoch: 6| Step: 2
Training loss: 1.5144402980804443
Validation loss: 2.2287169098854065

Epoch: 6| Step: 3
Training loss: 1.0547430515289307
Validation loss: 2.1741551955540976

Epoch: 6| Step: 4
Training loss: 2.0378525257110596
Validation loss: 2.2263036966323853

Epoch: 6| Step: 5
Training loss: 0.49238690733909607
Validation loss: 2.1999805768330893

Epoch: 6| Step: 6
Training loss: 1.0471196174621582
Validation loss: 2.245599687099457

Epoch: 6| Step: 7
Training loss: 1.1809041500091553
Validation loss: 2.2320680816968284

Epoch: 6| Step: 8
Training loss: 0.6555286049842834
Validation loss: 2.2433890302975974

Epoch: 6| Step: 9
Training loss: 1.4072074890136719
Validation loss: 2.260843197504679

Epoch: 6| Step: 10
Training loss: 0.9886910915374756
Validation loss: 2.200043479601542

Epoch: 6| Step: 11
Training loss: 0.5555448532104492
Validation loss: 2.2214174469312034

Epoch: 6| Step: 12
Training loss: 1.7086880207061768
Validation loss: 2.2100430130958557

Epoch: 6| Step: 13
Training loss: 0.8911908268928528
Validation loss: 2.19170210758845

Epoch: 399| Step: 0
Training loss: 0.6156806349754333
Validation loss: 2.201688269774119

Epoch: 6| Step: 1
Training loss: 0.27347511053085327
Validation loss: 2.2093118031819663

Epoch: 6| Step: 2
Training loss: 0.5891868472099304
Validation loss: 2.1882009307543435

Epoch: 6| Step: 3
Training loss: 1.2360438108444214
Validation loss: 2.2166914343833923

Epoch: 6| Step: 4
Training loss: 1.24534273147583
Validation loss: 2.266058405240377

Epoch: 6| Step: 5
Training loss: 1.2665071487426758
Validation loss: 2.230689545472463

Epoch: 6| Step: 6
Training loss: 1.4307146072387695
Validation loss: 2.2260818680127463

Epoch: 6| Step: 7
Training loss: 1.5475893020629883
Validation loss: 2.2457568645477295

Epoch: 6| Step: 8
Training loss: 1.1079645156860352
Validation loss: 2.252731283505758

Epoch: 6| Step: 9
Training loss: 0.7364872097969055
Validation loss: 2.1735641956329346

Epoch: 6| Step: 10
Training loss: 1.2853164672851562
Validation loss: 2.1996172865231833

Epoch: 6| Step: 11
Training loss: 1.430553913116455
Validation loss: 2.176684101422628

Epoch: 6| Step: 12
Training loss: 1.3181877136230469
Validation loss: 2.2435156106948853

Epoch: 6| Step: 13
Training loss: 1.1399035453796387
Validation loss: 2.238298773765564

Epoch: 400| Step: 0
Training loss: 1.3571053743362427
Validation loss: 2.215808709462484

Epoch: 6| Step: 1
Training loss: 0.9469890594482422
Validation loss: 2.220658242702484

Epoch: 6| Step: 2
Training loss: 1.0555967092514038
Validation loss: 2.224511126677195

Epoch: 6| Step: 3
Training loss: 0.959618091583252
Validation loss: 2.24479474623998

Epoch: 6| Step: 4
Training loss: 0.7894194722175598
Validation loss: 2.191798905531565

Epoch: 6| Step: 5
Training loss: 0.8317752480506897
Validation loss: 2.2152427633603415

Epoch: 6| Step: 6
Training loss: 0.9884325265884399
Validation loss: 2.201496720314026

Epoch: 6| Step: 7
Training loss: 1.5985875129699707
Validation loss: 2.205538193384806

Epoch: 6| Step: 8
Training loss: 1.0225857496261597
Validation loss: 2.202933410803477

Epoch: 6| Step: 9
Training loss: 0.8637948036193848
Validation loss: 2.1866204738616943

Epoch: 6| Step: 10
Training loss: 1.4325321912765503
Validation loss: 2.1773093342781067

Epoch: 6| Step: 11
Training loss: 1.1671984195709229
Validation loss: 2.172330101331075

Epoch: 6| Step: 12
Training loss: 1.2681212425231934
Validation loss: 2.1444828708966575

Epoch: 6| Step: 13
Training loss: 1.0791071653366089
Validation loss: 2.1450318892796836

Epoch: 401| Step: 0
Training loss: 0.9076680541038513
Validation loss: 2.13523938258489

Epoch: 6| Step: 1
Training loss: 0.6779928207397461
Validation loss: 2.1515667835871377

Epoch: 6| Step: 2
Training loss: 0.4676194190979004
Validation loss: 2.180077016353607

Epoch: 6| Step: 3
Training loss: 0.7027143239974976
Validation loss: 2.2103030681610107

Epoch: 6| Step: 4
Training loss: 0.9961157441139221
Validation loss: 2.2416191498438516

Epoch: 6| Step: 5
Training loss: 1.3879964351654053
Validation loss: 2.2592286268870034

Epoch: 6| Step: 6
Training loss: 1.7168300151824951
Validation loss: 2.233432650566101

Epoch: 6| Step: 7
Training loss: 1.6708917617797852
Validation loss: 2.224304517110189

Epoch: 6| Step: 8
Training loss: 1.349362850189209
Validation loss: 2.239905059337616

Epoch: 6| Step: 9
Training loss: 1.0016144514083862
Validation loss: 2.2578443686167398

Epoch: 6| Step: 10
Training loss: 1.1542434692382812
Validation loss: 2.2525404691696167

Epoch: 6| Step: 11
Training loss: 0.9718618392944336
Validation loss: 2.25687837600708

Epoch: 6| Step: 12
Training loss: 1.5279803276062012
Validation loss: 2.2036546071370444

Epoch: 6| Step: 13
Training loss: 0.797537088394165
Validation loss: 2.226020336151123

Epoch: 402| Step: 0
Training loss: 1.1193325519561768
Validation loss: 2.220127205053965

Epoch: 6| Step: 1
Training loss: 0.8297964334487915
Validation loss: 2.2364383339881897

Epoch: 6| Step: 2
Training loss: 1.5565073490142822
Validation loss: 2.24371067682902

Epoch: 6| Step: 3
Training loss: 0.9407638311386108
Validation loss: 2.281426707903544

Epoch: 6| Step: 4
Training loss: 0.8945761919021606
Validation loss: 2.2919362982114158

Epoch: 6| Step: 5
Training loss: 0.9342498183250427
Validation loss: 2.340614080429077

Epoch: 6| Step: 6
Training loss: 1.4705027341842651
Validation loss: 2.363017201423645

Epoch: 6| Step: 7
Training loss: 1.7307472229003906
Validation loss: 2.371156315008799

Epoch: 6| Step: 8
Training loss: 0.8664182424545288
Validation loss: 2.3710418939590454

Epoch: 6| Step: 9
Training loss: 1.0033032894134521
Validation loss: 2.355767627557119

Epoch: 6| Step: 10
Training loss: 1.4025286436080933
Validation loss: 2.353107531865438

Epoch: 6| Step: 11
Training loss: 1.7662768363952637
Validation loss: 2.283180812994639

Epoch: 6| Step: 12
Training loss: 1.1860032081604004
Validation loss: 2.2455230156580606

Epoch: 6| Step: 13
Training loss: 0.9400908350944519
Validation loss: 2.269148329893748

Epoch: 403| Step: 0
Training loss: 1.3293659687042236
Validation loss: 2.2143187522888184

Epoch: 6| Step: 1
Training loss: 1.0997662544250488
Validation loss: 2.2427337567011514

Epoch: 6| Step: 2
Training loss: 0.9489933252334595
Validation loss: 2.176373064517975

Epoch: 6| Step: 3
Training loss: 1.2671306133270264
Validation loss: 2.1509487628936768

Epoch: 6| Step: 4
Training loss: 0.5204719305038452
Validation loss: 2.1788031856218972

Epoch: 6| Step: 5
Training loss: 1.8743128776550293
Validation loss: 2.1344115932782493

Epoch: 6| Step: 6
Training loss: 2.0034241676330566
Validation loss: 2.1894362370173135

Epoch: 6| Step: 7
Training loss: 1.1553467512130737
Validation loss: 2.131792346636454

Epoch: 6| Step: 8
Training loss: 0.9925516247749329
Validation loss: 2.1674060821533203

Epoch: 6| Step: 9
Training loss: 0.8176244497299194
Validation loss: 2.185386379559835

Epoch: 6| Step: 10
Training loss: 1.151861548423767
Validation loss: 2.1426995992660522

Epoch: 6| Step: 11
Training loss: 0.615495502948761
Validation loss: 2.1461657683054605

Epoch: 6| Step: 12
Training loss: 0.6477656364440918
Validation loss: 2.1663373708724976

Epoch: 6| Step: 13
Training loss: 0.48589348793029785
Validation loss: 2.168394446372986

Epoch: 404| Step: 0
Training loss: 0.5257749557495117
Validation loss: 2.189457595348358

Epoch: 6| Step: 1
Training loss: 0.873937726020813
Validation loss: 2.2266220251719155

Epoch: 6| Step: 2
Training loss: 0.8655589818954468
Validation loss: 2.2398651838302612

Epoch: 6| Step: 3
Training loss: 0.7875305414199829
Validation loss: 2.229094942410787

Epoch: 6| Step: 4
Training loss: 0.8802602887153625
Validation loss: 2.196165978908539

Epoch: 6| Step: 5
Training loss: 1.130857229232788
Validation loss: 2.2072834968566895

Epoch: 6| Step: 6
Training loss: 2.141385078430176
Validation loss: 2.186670939127604

Epoch: 6| Step: 7
Training loss: 1.4074993133544922
Validation loss: 2.156114141146342

Epoch: 6| Step: 8
Training loss: 2.3763091564178467
Validation loss: 2.1719884872436523

Epoch: 6| Step: 9
Training loss: 0.6943791508674622
Validation loss: 2.16953182220459

Epoch: 6| Step: 10
Training loss: 1.0750758647918701
Validation loss: 2.165910998980204

Epoch: 6| Step: 11
Training loss: 0.7994840145111084
Validation loss: 2.1756937901178994

Epoch: 6| Step: 12
Training loss: 0.5868277549743652
Validation loss: 2.24491947889328

Epoch: 6| Step: 13
Training loss: 1.2097980976104736
Validation loss: 2.2270572980244956

Epoch: 405| Step: 0
Training loss: 1.0972697734832764
Validation loss: 2.2025366028149924

Epoch: 6| Step: 1
Training loss: 0.8609369993209839
Validation loss: 2.1949879924456277

Epoch: 6| Step: 2
Training loss: 0.9342696666717529
Validation loss: 2.2090314626693726

Epoch: 6| Step: 3
Training loss: 1.850714087486267
Validation loss: 2.2244739135106406

Epoch: 6| Step: 4
Training loss: 1.2163264751434326
Validation loss: 2.226282477378845

Epoch: 6| Step: 5
Training loss: 0.7803372144699097
Validation loss: 2.221991320451101

Epoch: 6| Step: 6
Training loss: 2.043217420578003
Validation loss: 2.248513102531433

Epoch: 6| Step: 7
Training loss: 0.9118527770042419
Validation loss: 2.2288080851236978

Epoch: 6| Step: 8
Training loss: 0.7563563585281372
Validation loss: 2.2223944465319314

Epoch: 6| Step: 9
Training loss: 0.9495804309844971
Validation loss: 2.1658085783322654

Epoch: 6| Step: 10
Training loss: 0.3774893879890442
Validation loss: 2.18756240606308

Epoch: 6| Step: 11
Training loss: 1.0598200559616089
Validation loss: 2.17413059870402

Epoch: 6| Step: 12
Training loss: 0.9876539707183838
Validation loss: 2.1689997712771096

Epoch: 6| Step: 13
Training loss: 0.9299023747444153
Validation loss: 2.16279673576355

Epoch: 406| Step: 0
Training loss: 1.023577332496643
Validation loss: 2.1513382395108542

Epoch: 6| Step: 1
Training loss: 0.927759051322937
Validation loss: 2.1346694231033325

Epoch: 6| Step: 2
Training loss: 1.8393880128860474
Validation loss: 2.1384146014849343

Epoch: 6| Step: 3
Training loss: 0.937415361404419
Validation loss: 2.2222549319267273

Epoch: 6| Step: 4
Training loss: 1.3170502185821533
Validation loss: 2.1567788322766623

Epoch: 6| Step: 5
Training loss: 1.579808235168457
Validation loss: 2.2148019472757974

Epoch: 6| Step: 6
Training loss: 0.593765139579773
Validation loss: 2.1825642784436545

Epoch: 6| Step: 7
Training loss: 1.116457223892212
Validation loss: 2.230575462182363

Epoch: 6| Step: 8
Training loss: 0.8432316184043884
Validation loss: 2.230607807636261

Epoch: 6| Step: 9
Training loss: 0.8098928928375244
Validation loss: 2.2414071957270303

Epoch: 6| Step: 10
Training loss: 0.8344485759735107
Validation loss: 2.2156944274902344

Epoch: 6| Step: 11
Training loss: 0.8587061166763306
Validation loss: 2.267880698045095

Epoch: 6| Step: 12
Training loss: 0.9269617795944214
Validation loss: 2.2536054452260337

Epoch: 6| Step: 13
Training loss: 1.2679872512817383
Validation loss: 2.2404468059539795

Epoch: 407| Step: 0
Training loss: 0.6273247003555298
Validation loss: 2.2182101806004844

Epoch: 6| Step: 1
Training loss: 0.9509241580963135
Validation loss: 2.2049304246902466

Epoch: 6| Step: 2
Training loss: 0.5951845645904541
Validation loss: 2.249395767847697

Epoch: 6| Step: 3
Training loss: 1.1922767162322998
Validation loss: 2.1940402388572693

Epoch: 6| Step: 4
Training loss: 0.8751100301742554
Validation loss: 2.2152183453241983

Epoch: 6| Step: 5
Training loss: 1.306919813156128
Validation loss: 2.1930603981018066

Epoch: 6| Step: 6
Training loss: 1.474010705947876
Validation loss: 2.189258793989817

Epoch: 6| Step: 7
Training loss: 1.750016689300537
Validation loss: 2.1782877445220947

Epoch: 6| Step: 8
Training loss: 1.1495792865753174
Validation loss: 2.159120341142019

Epoch: 6| Step: 9
Training loss: 1.0429534912109375
Validation loss: 2.178481380144755

Epoch: 6| Step: 10
Training loss: 0.9077110290527344
Validation loss: 2.166396180788676

Epoch: 6| Step: 11
Training loss: 1.190281629562378
Validation loss: 2.17991171280543

Epoch: 6| Step: 12
Training loss: 0.7548844814300537
Validation loss: 2.1757511297861734

Epoch: 6| Step: 13
Training loss: 0.9648369550704956
Validation loss: 2.20055091381073

Epoch: 408| Step: 0
Training loss: 1.6913137435913086
Validation loss: 2.1766978899637857

Epoch: 6| Step: 1
Training loss: 0.9002925753593445
Validation loss: 2.196908473968506

Epoch: 6| Step: 2
Training loss: 0.6733644008636475
Validation loss: 2.185408333937327

Epoch: 6| Step: 3
Training loss: 1.1000677347183228
Validation loss: 2.180466036001841

Epoch: 6| Step: 4
Training loss: 0.572066068649292
Validation loss: 2.225350777308146

Epoch: 6| Step: 5
Training loss: 1.5056395530700684
Validation loss: 2.232213258743286

Epoch: 6| Step: 6
Training loss: 1.6433182954788208
Validation loss: 2.231050690015157

Epoch: 6| Step: 7
Training loss: 1.0961641073226929
Validation loss: 2.240412871042887

Epoch: 6| Step: 8
Training loss: 1.044407844543457
Validation loss: 2.2366917729377747

Epoch: 6| Step: 9
Training loss: 1.111712098121643
Validation loss: 2.195265293121338

Epoch: 6| Step: 10
Training loss: 0.9441467523574829
Validation loss: 2.1828718185424805

Epoch: 6| Step: 11
Training loss: 0.9935439825057983
Validation loss: 2.174042801062266

Epoch: 6| Step: 12
Training loss: 0.6465874314308167
Validation loss: 2.19575564066569

Epoch: 6| Step: 13
Training loss: 1.1010737419128418
Validation loss: 2.1991658409436545

Epoch: 409| Step: 0
Training loss: 0.7172732949256897
Validation loss: 2.163068155447642

Epoch: 6| Step: 1
Training loss: 1.1279242038726807
Validation loss: 2.185263514518738

Epoch: 6| Step: 2
Training loss: 1.7547428607940674
Validation loss: 2.156581699848175

Epoch: 6| Step: 3
Training loss: 1.1203868389129639
Validation loss: 2.158609608809153

Epoch: 6| Step: 4
Training loss: 0.9759124517440796
Validation loss: 2.18127433458964

Epoch: 6| Step: 5
Training loss: 1.4940139055252075
Validation loss: 2.2105425794919333

Epoch: 6| Step: 6
Training loss: 1.1619147062301636
Validation loss: 2.1846638917922974

Epoch: 6| Step: 7
Training loss: 0.929930567741394
Validation loss: 2.1927711367607117

Epoch: 6| Step: 8
Training loss: 0.46529242396354675
Validation loss: 2.242215633392334

Epoch: 6| Step: 9
Training loss: 1.3571157455444336
Validation loss: 2.2333741982777915

Epoch: 6| Step: 10
Training loss: 1.2172027826309204
Validation loss: 2.261002699534098

Epoch: 6| Step: 11
Training loss: 0.8600271344184875
Validation loss: 2.250387688477834

Epoch: 6| Step: 12
Training loss: 1.1565439701080322
Validation loss: 2.276013453801473

Epoch: 6| Step: 13
Training loss: 0.9420560598373413
Validation loss: 2.3151621222496033

Epoch: 410| Step: 0
Training loss: 1.2541587352752686
Validation loss: 2.294077157974243

Epoch: 6| Step: 1
Training loss: 0.5228255987167358
Validation loss: 2.2578774094581604

Epoch: 6| Step: 2
Training loss: 1.1255985498428345
Validation loss: 2.2108927567799888

Epoch: 6| Step: 3
Training loss: 0.8842450380325317
Validation loss: 2.214734594027201

Epoch: 6| Step: 4
Training loss: 0.7833088040351868
Validation loss: 2.1827139457066855

Epoch: 6| Step: 5
Training loss: 1.01738440990448
Validation loss: 2.195423642794291

Epoch: 6| Step: 6
Training loss: 0.8960259556770325
Validation loss: 2.188006639480591

Epoch: 6| Step: 7
Training loss: 1.422654390335083
Validation loss: 2.16540265083313

Epoch: 6| Step: 8
Training loss: 1.968593716621399
Validation loss: 2.182298223177592

Epoch: 6| Step: 9
Training loss: 0.6428167819976807
Validation loss: 2.1492350896199546

Epoch: 6| Step: 10
Training loss: 0.944110631942749
Validation loss: 2.1717164119084678

Epoch: 6| Step: 11
Training loss: 0.35344767570495605
Validation loss: 2.1736941933631897

Epoch: 6| Step: 12
Training loss: 1.0741811990737915
Validation loss: 2.155943274497986

Epoch: 6| Step: 13
Training loss: 1.6769213676452637
Validation loss: 2.1863456765810647

Epoch: 411| Step: 0
Training loss: 1.0214041471481323
Validation loss: 2.1651452779769897

Epoch: 6| Step: 1
Training loss: 1.1711080074310303
Validation loss: 2.1831948359807334

Epoch: 6| Step: 2
Training loss: 1.536792278289795
Validation loss: 2.2348437309265137

Epoch: 6| Step: 3
Training loss: 0.7498047351837158
Validation loss: 2.2214781840642295

Epoch: 6| Step: 4
Training loss: 1.007861852645874
Validation loss: 2.193281968434652

Epoch: 6| Step: 5
Training loss: 0.8998128175735474
Validation loss: 2.22761207818985

Epoch: 6| Step: 6
Training loss: 1.5744028091430664
Validation loss: 2.2525807817777

Epoch: 6| Step: 7
Training loss: 1.238791823387146
Validation loss: 2.235552887121836

Epoch: 6| Step: 8
Training loss: 0.6057891845703125
Validation loss: 2.2151201367378235

Epoch: 6| Step: 9
Training loss: 0.5963698029518127
Validation loss: 2.205387532711029

Epoch: 6| Step: 10
Training loss: 0.7450162172317505
Validation loss: 2.2024592558542886

Epoch: 6| Step: 11
Training loss: 0.8908362984657288
Validation loss: 2.198927879333496

Epoch: 6| Step: 12
Training loss: 1.38313889503479
Validation loss: 2.2042460441589355

Epoch: 6| Step: 13
Training loss: 0.9329045414924622
Validation loss: 2.2037220199902854

Epoch: 412| Step: 0
Training loss: 1.3346961736679077
Validation loss: 2.2217886050542197

Epoch: 6| Step: 1
Training loss: 0.9790747165679932
Validation loss: 2.1761231819788613

Epoch: 6| Step: 2
Training loss: 0.8262693881988525
Validation loss: 2.196763356526693

Epoch: 6| Step: 3
Training loss: 1.2053200006484985
Validation loss: 2.171776831150055

Epoch: 6| Step: 4
Training loss: 1.5173101425170898
Validation loss: 2.1607685883839927

Epoch: 6| Step: 5
Training loss: 1.2811558246612549
Validation loss: 2.141445815563202

Epoch: 6| Step: 6
Training loss: 0.7618972659111023
Validation loss: 2.1535855333010354

Epoch: 6| Step: 7
Training loss: 1.254701018333435
Validation loss: 2.18440047899882

Epoch: 6| Step: 8
Training loss: 1.3258249759674072
Validation loss: 2.171786348025004

Epoch: 6| Step: 9
Training loss: 1.0026895999908447
Validation loss: 2.166607062021891

Epoch: 6| Step: 10
Training loss: 0.8829984664916992
Validation loss: 2.141052722930908

Epoch: 6| Step: 11
Training loss: 1.0135475397109985
Validation loss: 2.1931803623835244

Epoch: 6| Step: 12
Training loss: 0.42644691467285156
Validation loss: 2.2109063069025674

Epoch: 6| Step: 13
Training loss: 0.5626532435417175
Validation loss: 2.234610895315806

Epoch: 413| Step: 0
Training loss: 0.6987130641937256
Validation loss: 2.2007724245389304

Epoch: 6| Step: 1
Training loss: 0.7919614315032959
Validation loss: 2.245457410812378

Epoch: 6| Step: 2
Training loss: 1.4166959524154663
Validation loss: 2.27964194615682

Epoch: 6| Step: 3
Training loss: 0.9225171804428101
Validation loss: 2.282053073247274

Epoch: 6| Step: 4
Training loss: 1.0091222524642944
Validation loss: 2.2222599387168884

Epoch: 6| Step: 5
Training loss: 0.9419121146202087
Validation loss: 2.211757560571035

Epoch: 6| Step: 6
Training loss: 1.2202740907669067
Validation loss: 2.224066217740377

Epoch: 6| Step: 7
Training loss: 0.9124832153320312
Validation loss: 2.171393314997355

Epoch: 6| Step: 8
Training loss: 1.1899733543395996
Validation loss: 2.1845925052960715

Epoch: 6| Step: 9
Training loss: 1.475501298904419
Validation loss: 2.1443909406661987

Epoch: 6| Step: 10
Training loss: 1.4199693202972412
Validation loss: 2.1626185973485312

Epoch: 6| Step: 11
Training loss: 1.1811392307281494
Validation loss: 2.158235510190328

Epoch: 6| Step: 12
Training loss: 1.2096118927001953
Validation loss: 2.190907041231791

Epoch: 6| Step: 13
Training loss: 0.38783520460128784
Validation loss: 2.244904418786367

Epoch: 414| Step: 0
Training loss: 1.231229305267334
Validation loss: 2.2492884000142417

Epoch: 6| Step: 1
Training loss: 0.9248894453048706
Validation loss: 2.2361683448155723

Epoch: 6| Step: 2
Training loss: 1.2233266830444336
Validation loss: 2.2215041518211365

Epoch: 6| Step: 3
Training loss: 0.526120662689209
Validation loss: 2.235957702000936

Epoch: 6| Step: 4
Training loss: 0.9411415457725525
Validation loss: 2.229285717010498

Epoch: 6| Step: 5
Training loss: 1.279588222503662
Validation loss: 2.133445620536804

Epoch: 6| Step: 6
Training loss: 1.3119194507598877
Validation loss: 2.1194279392560325

Epoch: 6| Step: 7
Training loss: 1.3053234815597534
Validation loss: 2.098817527294159

Epoch: 6| Step: 8
Training loss: 1.6615625619888306
Validation loss: 2.1002389788627625

Epoch: 6| Step: 9
Training loss: 1.271468162536621
Validation loss: 2.129023293654124

Epoch: 6| Step: 10
Training loss: 1.8159918785095215
Validation loss: 2.1665446758270264

Epoch: 6| Step: 11
Training loss: 1.1367733478546143
Validation loss: 2.136604050795237

Epoch: 6| Step: 12
Training loss: 0.7009276151657104
Validation loss: 2.166451891263326

Epoch: 6| Step: 13
Training loss: 0.90629643201828
Validation loss: 2.130660037199656

Epoch: 415| Step: 0
Training loss: 1.074084758758545
Validation loss: 2.122793734073639

Epoch: 6| Step: 1
Training loss: 1.031379222869873
Validation loss: 2.10664963722229

Epoch: 6| Step: 2
Training loss: 1.157808780670166
Validation loss: 2.1234070857365928

Epoch: 6| Step: 3
Training loss: 1.285943865776062
Validation loss: 2.201369047164917

Epoch: 6| Step: 4
Training loss: 1.3353474140167236
Validation loss: 2.1930365562438965

Epoch: 6| Step: 5
Training loss: 0.6966079473495483
Validation loss: 2.19937926530838

Epoch: 6| Step: 6
Training loss: 1.4121458530426025
Validation loss: 2.1637862722078958

Epoch: 6| Step: 7
Training loss: 0.9942864179611206
Validation loss: 2.180569569269816

Epoch: 6| Step: 8
Training loss: 0.9907361268997192
Validation loss: 2.1605498790740967

Epoch: 6| Step: 9
Training loss: 1.6693254709243774
Validation loss: 2.1314481298128762

Epoch: 6| Step: 10
Training loss: 0.8959014415740967
Validation loss: 2.1226003766059875

Epoch: 6| Step: 11
Training loss: 1.246293067932129
Validation loss: 2.1529888113339744

Epoch: 6| Step: 12
Training loss: 1.038848638534546
Validation loss: 2.2057549158732095

Epoch: 6| Step: 13
Training loss: 1.0748754739761353
Validation loss: 2.197553833325704

Epoch: 416| Step: 0
Training loss: 1.0806750059127808
Validation loss: 2.2317129174868264

Epoch: 6| Step: 1
Training loss: 1.1580042839050293
Validation loss: 2.201342304547628

Epoch: 6| Step: 2
Training loss: 0.8159988522529602
Validation loss: 2.2041104237238565

Epoch: 6| Step: 3
Training loss: 0.6175358295440674
Validation loss: 2.152417222658793

Epoch: 6| Step: 4
Training loss: 1.2551403045654297
Validation loss: 2.175783395767212

Epoch: 6| Step: 5
Training loss: 1.159121036529541
Validation loss: 2.1496485074361167

Epoch: 6| Step: 6
Training loss: 1.1945445537567139
Validation loss: 2.1583534479141235

Epoch: 6| Step: 7
Training loss: 0.713286280632019
Validation loss: 2.1834758520126343

Epoch: 6| Step: 8
Training loss: 1.087044358253479
Validation loss: 2.1975388328234353

Epoch: 6| Step: 9
Training loss: 1.0590062141418457
Validation loss: 2.1907057762145996

Epoch: 6| Step: 10
Training loss: 0.9182283282279968
Validation loss: 2.1493128736813865

Epoch: 6| Step: 11
Training loss: 0.633375346660614
Validation loss: 2.1769434412320456

Epoch: 6| Step: 12
Training loss: 1.2666995525360107
Validation loss: 2.1913684209187827

Epoch: 6| Step: 13
Training loss: 1.1571459770202637
Validation loss: 2.1755810181299844

Epoch: 417| Step: 0
Training loss: 1.0765488147735596
Validation loss: 2.1823495030403137

Epoch: 6| Step: 1
Training loss: 1.1202014684677124
Validation loss: 2.1784183382987976

Epoch: 6| Step: 2
Training loss: 0.7362346649169922
Validation loss: 2.134709040323893

Epoch: 6| Step: 3
Training loss: 0.8398213386535645
Validation loss: 2.1938703457514444

Epoch: 6| Step: 4
Training loss: 1.4163260459899902
Validation loss: 2.149999459584554

Epoch: 6| Step: 5
Training loss: 1.4219342470169067
Validation loss: 2.1713098287582397

Epoch: 6| Step: 6
Training loss: 0.6989809274673462
Validation loss: 2.171384592851003

Epoch: 6| Step: 7
Training loss: 0.7694458365440369
Validation loss: 2.192706743876139

Epoch: 6| Step: 8
Training loss: 0.7502068281173706
Validation loss: 2.1892940600713096

Epoch: 6| Step: 9
Training loss: 1.114814281463623
Validation loss: 2.2214284936587014

Epoch: 6| Step: 10
Training loss: 1.2684166431427002
Validation loss: 2.2091421286265054

Epoch: 6| Step: 11
Training loss: 0.7685830593109131
Validation loss: 2.206478754679362

Epoch: 6| Step: 12
Training loss: 1.419059157371521
Validation loss: 2.2050744692484536

Epoch: 6| Step: 13
Training loss: 1.04407799243927
Validation loss: 2.193289120992025

Epoch: 418| Step: 0
Training loss: 0.7486642599105835
Validation loss: 2.1902534564336142

Epoch: 6| Step: 1
Training loss: 1.449617862701416
Validation loss: 2.1628165245056152

Epoch: 6| Step: 2
Training loss: 0.6581470370292664
Validation loss: 2.1836713353792825

Epoch: 6| Step: 3
Training loss: 1.2567808628082275
Validation loss: 2.2219708363215127

Epoch: 6| Step: 4
Training loss: 1.2756967544555664
Validation loss: 2.163433392842611

Epoch: 6| Step: 5
Training loss: 1.2469326257705688
Validation loss: 2.195539395014445

Epoch: 6| Step: 6
Training loss: 1.3619887828826904
Validation loss: 2.1816022992134094

Epoch: 6| Step: 7
Training loss: 1.4504382610321045
Validation loss: 2.18784236907959

Epoch: 6| Step: 8
Training loss: 0.7994911670684814
Validation loss: 2.1342520515124

Epoch: 6| Step: 9
Training loss: 1.1007696390151978
Validation loss: 2.0856147607167563

Epoch: 6| Step: 10
Training loss: 0.955512285232544
Validation loss: 2.159725467363993

Epoch: 6| Step: 11
Training loss: 0.8106735944747925
Validation loss: 2.1855088273684182

Epoch: 6| Step: 12
Training loss: 0.8123875856399536
Validation loss: 2.2008651296297708

Epoch: 6| Step: 13
Training loss: 1.3797402381896973
Validation loss: 2.197054167588552

Epoch: 419| Step: 0
Training loss: 1.0094883441925049
Validation loss: 2.263247032960256

Epoch: 6| Step: 1
Training loss: 0.8623862862586975
Validation loss: 2.2355597416559854

Epoch: 6| Step: 2
Training loss: 1.13917875289917
Validation loss: 2.216372569402059

Epoch: 6| Step: 3
Training loss: 0.5558850765228271
Validation loss: 2.228924016157786

Epoch: 6| Step: 4
Training loss: 1.2306549549102783
Validation loss: 2.240671753883362

Epoch: 6| Step: 5
Training loss: 0.5255246162414551
Validation loss: 2.2058895230293274

Epoch: 6| Step: 6
Training loss: 0.4586421251296997
Validation loss: 2.157097280025482

Epoch: 6| Step: 7
Training loss: 2.273569107055664
Validation loss: 2.238766153653463

Epoch: 6| Step: 8
Training loss: 1.22068452835083
Validation loss: 2.1806931098302207

Epoch: 6| Step: 9
Training loss: 1.186443567276001
Validation loss: 2.233567158381144

Epoch: 6| Step: 10
Training loss: 0.8339009284973145
Validation loss: 2.1791344483693442

Epoch: 6| Step: 11
Training loss: 1.7092297077178955
Validation loss: 2.187459389368693

Epoch: 6| Step: 12
Training loss: 0.8341152667999268
Validation loss: 2.2192590037981668

Epoch: 6| Step: 13
Training loss: 1.2505643367767334
Validation loss: 2.2431723276774087

Epoch: 420| Step: 0
Training loss: 1.3081064224243164
Validation loss: 2.1996227900187173

Epoch: 6| Step: 1
Training loss: 1.1410702466964722
Validation loss: 2.175578753153483

Epoch: 6| Step: 2
Training loss: 1.1457023620605469
Validation loss: 2.209480881690979

Epoch: 6| Step: 3
Training loss: 0.7977460622787476
Validation loss: 2.1793657541275024

Epoch: 6| Step: 4
Training loss: 1.4211691617965698
Validation loss: 2.2272786498069763

Epoch: 6| Step: 5
Training loss: 0.6900511384010315
Validation loss: 2.2071063121159873

Epoch: 6| Step: 6
Training loss: 1.0034329891204834
Validation loss: 2.2238341569900513

Epoch: 6| Step: 7
Training loss: 0.788682222366333
Validation loss: 2.2007774909337363

Epoch: 6| Step: 8
Training loss: 1.7754483222961426
Validation loss: 2.194463570912679

Epoch: 6| Step: 9
Training loss: 0.8587352633476257
Validation loss: 2.1864888668060303

Epoch: 6| Step: 10
Training loss: 0.6754990220069885
Validation loss: 2.1926655371983848

Epoch: 6| Step: 11
Training loss: 0.9195874929428101
Validation loss: 2.196373780568441

Epoch: 6| Step: 12
Training loss: 0.808078944683075
Validation loss: 2.1609089374542236

Epoch: 6| Step: 13
Training loss: 0.9866811037063599
Validation loss: 2.1629316210746765

Epoch: 421| Step: 0
Training loss: 0.6796497702598572
Validation loss: 2.130052924156189

Epoch: 6| Step: 1
Training loss: 1.3731542825698853
Validation loss: 2.131108363469442

Epoch: 6| Step: 2
Training loss: 1.780282735824585
Validation loss: 2.1171375711758933

Epoch: 6| Step: 3
Training loss: 1.444331169128418
Validation loss: 2.1238736311594644

Epoch: 6| Step: 4
Training loss: 0.8458331823348999
Validation loss: 2.1520909667015076

Epoch: 6| Step: 5
Training loss: 1.3692653179168701
Validation loss: 2.1515431801478067

Epoch: 6| Step: 6
Training loss: 0.6494777202606201
Validation loss: 2.1987451116243997

Epoch: 6| Step: 7
Training loss: 0.8861468434333801
Validation loss: 2.1716422041257224

Epoch: 6| Step: 8
Training loss: 1.0297749042510986
Validation loss: 2.173392573992411

Epoch: 6| Step: 9
Training loss: 1.0593726634979248
Validation loss: 2.215494155883789

Epoch: 6| Step: 10
Training loss: 0.6273905634880066
Validation loss: 2.200546900431315

Epoch: 6| Step: 11
Training loss: 0.7088831663131714
Validation loss: 2.204063673814138

Epoch: 6| Step: 12
Training loss: 1.3920918703079224
Validation loss: 2.214387834072113

Epoch: 6| Step: 13
Training loss: 0.4926922917366028
Validation loss: 2.2159424821535745

Epoch: 422| Step: 0
Training loss: 0.9101642966270447
Validation loss: 2.2260446349779763

Epoch: 6| Step: 1
Training loss: 1.4217073917388916
Validation loss: 2.171665827433268

Epoch: 6| Step: 2
Training loss: 1.3827941417694092
Validation loss: 2.1713828245798745

Epoch: 6| Step: 3
Training loss: 1.0979959964752197
Validation loss: 2.21621572971344

Epoch: 6| Step: 4
Training loss: 0.8672084808349609
Validation loss: 2.2322853207588196

Epoch: 6| Step: 5
Training loss: 0.7807800769805908
Validation loss: 2.1788190404574075

Epoch: 6| Step: 6
Training loss: 1.240964412689209
Validation loss: 2.1758895913759866

Epoch: 6| Step: 7
Training loss: 0.9896835684776306
Validation loss: 2.158283233642578

Epoch: 6| Step: 8
Training loss: 1.1960930824279785
Validation loss: 2.1503114104270935

Epoch: 6| Step: 9
Training loss: 0.6171009540557861
Validation loss: 2.1688506603240967

Epoch: 6| Step: 10
Training loss: 1.4413466453552246
Validation loss: 2.1017778317133584

Epoch: 6| Step: 11
Training loss: 0.617501974105835
Validation loss: 2.18203471104304

Epoch: 6| Step: 12
Training loss: 0.9657449722290039
Validation loss: 2.1674468517303467

Epoch: 6| Step: 13
Training loss: 1.1338369846343994
Validation loss: 2.1542908747990928

Epoch: 423| Step: 0
Training loss: 0.9897053837776184
Validation loss: 2.1647169391314187

Epoch: 6| Step: 1
Training loss: 1.190778374671936
Validation loss: 2.156258781750997

Epoch: 6| Step: 2
Training loss: 0.8509626388549805
Validation loss: 2.172452469666799

Epoch: 6| Step: 3
Training loss: 1.503763198852539
Validation loss: 2.164199153582255

Epoch: 6| Step: 4
Training loss: 1.1249759197235107
Validation loss: 2.1607473293940225

Epoch: 6| Step: 5
Training loss: 1.0887291431427002
Validation loss: 2.1427136858304343

Epoch: 6| Step: 6
Training loss: 1.064772605895996
Validation loss: 2.1481135884920755

Epoch: 6| Step: 7
Training loss: 0.5095887184143066
Validation loss: 2.1683878103892007

Epoch: 6| Step: 8
Training loss: 1.2685742378234863
Validation loss: 2.1442472338676453

Epoch: 6| Step: 9
Training loss: 0.7468249201774597
Validation loss: 2.159528295199076

Epoch: 6| Step: 10
Training loss: 0.9961702227592468
Validation loss: 2.1393901109695435

Epoch: 6| Step: 11
Training loss: 0.7095597982406616
Validation loss: 2.1503410935401917

Epoch: 6| Step: 12
Training loss: 1.3694430589675903
Validation loss: 2.1779170433680215

Epoch: 6| Step: 13
Training loss: 0.63191819190979
Validation loss: 2.127425750096639

Epoch: 424| Step: 0
Training loss: 1.332818627357483
Validation loss: 2.1096336444218955

Epoch: 6| Step: 1
Training loss: 1.2111871242523193
Validation loss: 2.139637013276418

Epoch: 6| Step: 2
Training loss: 0.6607884168624878
Validation loss: 2.1365906993548074

Epoch: 6| Step: 3
Training loss: 0.5188080072402954
Validation loss: 2.1508841117223105

Epoch: 6| Step: 4
Training loss: 1.2456284761428833
Validation loss: 2.1384277939796448

Epoch: 6| Step: 5
Training loss: 1.4457769393920898
Validation loss: 2.208984692891439

Epoch: 6| Step: 6
Training loss: 1.097442388534546
Validation loss: 2.1342333356539407

Epoch: 6| Step: 7
Training loss: 1.366206407546997
Validation loss: 2.1629435618718467

Epoch: 6| Step: 8
Training loss: 0.9052456617355347
Validation loss: 2.1347378293673196

Epoch: 6| Step: 9
Training loss: 0.6567484140396118
Validation loss: 2.1731095910072327

Epoch: 6| Step: 10
Training loss: 0.621940016746521
Validation loss: 2.153824508190155

Epoch: 6| Step: 11
Training loss: 0.868796169757843
Validation loss: 2.1964263717333474

Epoch: 6| Step: 12
Training loss: 0.667205810546875
Validation loss: 2.1871825655301413

Epoch: 6| Step: 13
Training loss: 1.064476728439331
Validation loss: 2.1818222403526306

Epoch: 425| Step: 0
Training loss: 1.5756298303604126
Validation loss: 2.18478653828303

Epoch: 6| Step: 1
Training loss: 0.9849281311035156
Validation loss: 2.142336368560791

Epoch: 6| Step: 2
Training loss: 0.7712950110435486
Validation loss: 2.1689002315203347

Epoch: 6| Step: 3
Training loss: 0.9393832087516785
Validation loss: 2.1835779746373496

Epoch: 6| Step: 4
Training loss: 1.2192449569702148
Validation loss: 2.2089072664578757

Epoch: 6| Step: 5
Training loss: 0.8101837635040283
Validation loss: 2.1447399655977883

Epoch: 6| Step: 6
Training loss: 0.6115410327911377
Validation loss: 2.1551466385523477

Epoch: 6| Step: 7
Training loss: 0.6160234212875366
Validation loss: 2.122267504533132

Epoch: 6| Step: 8
Training loss: 1.158013939857483
Validation loss: 2.159055987993876

Epoch: 6| Step: 9
Training loss: 0.9489942193031311
Validation loss: 2.160097519556681

Epoch: 6| Step: 10
Training loss: 1.7131346464157104
Validation loss: 2.176717519760132

Epoch: 6| Step: 11
Training loss: 0.9728708863258362
Validation loss: 2.211265484491984

Epoch: 6| Step: 12
Training loss: 0.7434118986129761
Validation loss: 2.21039346853892

Epoch: 6| Step: 13
Training loss: 0.6694504022598267
Validation loss: 2.1710331439971924

Epoch: 426| Step: 0
Training loss: 0.807715654373169
Validation loss: 2.2011158068974814

Epoch: 6| Step: 1
Training loss: 1.069969892501831
Validation loss: 2.1943562626838684

Epoch: 6| Step: 2
Training loss: 0.5268363356590271
Validation loss: 2.1516799132029214

Epoch: 6| Step: 3
Training loss: 0.4877973794937134
Validation loss: 2.142282168070475

Epoch: 6| Step: 4
Training loss: 1.15553879737854
Validation loss: 2.1530858675638833

Epoch: 6| Step: 5
Training loss: 1.1787309646606445
Validation loss: 2.185399134953817

Epoch: 6| Step: 6
Training loss: 0.8533188700675964
Validation loss: 2.146088461081187

Epoch: 6| Step: 7
Training loss: 1.196454644203186
Validation loss: 2.1227275927861533

Epoch: 6| Step: 8
Training loss: 1.0881818532943726
Validation loss: 2.1325061519940696

Epoch: 6| Step: 9
Training loss: 1.11830735206604
Validation loss: 2.107040365537008

Epoch: 6| Step: 10
Training loss: 0.690592885017395
Validation loss: 2.1493524312973022

Epoch: 6| Step: 11
Training loss: 0.9871915578842163
Validation loss: 2.158439556757609

Epoch: 6| Step: 12
Training loss: 0.8588211536407471
Validation loss: 2.1122126976648965

Epoch: 6| Step: 13
Training loss: 1.517878532409668
Validation loss: 2.113486965497335

Epoch: 427| Step: 0
Training loss: 0.7772204279899597
Validation loss: 2.144813676675161

Epoch: 6| Step: 1
Training loss: 1.6345899105072021
Validation loss: 2.131252924601237

Epoch: 6| Step: 2
Training loss: 0.8467855453491211
Validation loss: 2.1528140902519226

Epoch: 6| Step: 3
Training loss: 1.1237703561782837
Validation loss: 2.142540176709493

Epoch: 6| Step: 4
Training loss: 0.40474629402160645
Validation loss: 2.1986320416132608

Epoch: 6| Step: 5
Training loss: 1.4403976202011108
Validation loss: 2.1580289204915366

Epoch: 6| Step: 6
Training loss: 1.3627040386199951
Validation loss: 2.1684343814849854

Epoch: 6| Step: 7
Training loss: 1.3640708923339844
Validation loss: 2.2337359189987183

Epoch: 6| Step: 8
Training loss: 0.8743717670440674
Validation loss: 2.2153461376825967

Epoch: 6| Step: 9
Training loss: 0.8347119092941284
Validation loss: 2.209408779939016

Epoch: 6| Step: 10
Training loss: 0.8274235725402832
Validation loss: 2.211149593194326

Epoch: 6| Step: 11
Training loss: 0.7318387031555176
Validation loss: 2.194608767827352

Epoch: 6| Step: 12
Training loss: 0.7806134223937988
Validation loss: 2.1850452423095703

Epoch: 6| Step: 13
Training loss: 0.7296316623687744
Validation loss: 2.2313560048739114

Epoch: 428| Step: 0
Training loss: 1.058078408241272
Validation loss: 2.2554535071055093

Epoch: 6| Step: 1
Training loss: 0.4224470853805542
Validation loss: 2.243484099706014

Epoch: 6| Step: 2
Training loss: 1.1574373245239258
Validation loss: 2.20263942082723

Epoch: 6| Step: 3
Training loss: 0.32460707426071167
Validation loss: 2.1970874071121216

Epoch: 6| Step: 4
Training loss: 0.8696754574775696
Validation loss: 2.2052663365999856

Epoch: 6| Step: 5
Training loss: 1.3032933473587036
Validation loss: 2.1961813966433206

Epoch: 6| Step: 6
Training loss: 1.2391231060028076
Validation loss: 2.164016286532084

Epoch: 6| Step: 7
Training loss: 0.9596846103668213
Validation loss: 2.1661071379979453

Epoch: 6| Step: 8
Training loss: 0.9738188982009888
Validation loss: 2.1682485739390054

Epoch: 6| Step: 9
Training loss: 0.8425372242927551
Validation loss: 2.1397833625475564

Epoch: 6| Step: 10
Training loss: 0.8743590116500854
Validation loss: 2.149038314819336

Epoch: 6| Step: 11
Training loss: 1.6557163000106812
Validation loss: 2.155280113220215

Epoch: 6| Step: 12
Training loss: 0.9272211790084839
Validation loss: 2.1661099592844644

Epoch: 6| Step: 13
Training loss: 0.7709903717041016
Validation loss: 2.1549623608589172

Epoch: 429| Step: 0
Training loss: 0.9513746500015259
Validation loss: 2.1995710531870523

Epoch: 6| Step: 1
Training loss: 1.0662516355514526
Validation loss: 2.1795869867006936

Epoch: 6| Step: 2
Training loss: 0.9035098552703857
Validation loss: 2.2012480099995932

Epoch: 6| Step: 3
Training loss: 0.6566003561019897
Validation loss: 2.2115209499994912

Epoch: 6| Step: 4
Training loss: 0.7655156850814819
Validation loss: 2.190557320912679

Epoch: 6| Step: 5
Training loss: 1.2749534845352173
Validation loss: 2.1600421667099

Epoch: 6| Step: 6
Training loss: 0.5755216479301453
Validation loss: 2.1848371624946594

Epoch: 6| Step: 7
Training loss: 1.0079102516174316
Validation loss: 2.1591702898343406

Epoch: 6| Step: 8
Training loss: 1.2949278354644775
Validation loss: 2.200518627961477

Epoch: 6| Step: 9
Training loss: 1.4177072048187256
Validation loss: 2.1922996640205383

Epoch: 6| Step: 10
Training loss: 1.0525925159454346
Validation loss: 2.1970903277397156

Epoch: 6| Step: 11
Training loss: 1.3245823383331299
Validation loss: 2.111550589402517

Epoch: 6| Step: 12
Training loss: 0.829072117805481
Validation loss: 2.232895255088806

Epoch: 6| Step: 13
Training loss: 0.7593522071838379
Validation loss: 2.1918681065241494

Epoch: 430| Step: 0
Training loss: 1.0820565223693848
Validation loss: 2.251650591691335

Epoch: 6| Step: 1
Training loss: 0.5704004764556885
Validation loss: 2.253503402074178

Epoch: 6| Step: 2
Training loss: 1.6897786855697632
Validation loss: 2.239143133163452

Epoch: 6| Step: 3
Training loss: 1.5296121835708618
Validation loss: 2.2068375945091248

Epoch: 6| Step: 4
Training loss: 0.4987347722053528
Validation loss: 2.186895191669464

Epoch: 6| Step: 5
Training loss: 0.8365049362182617
Validation loss: 2.225775102774302

Epoch: 6| Step: 6
Training loss: 1.3380154371261597
Validation loss: 2.1626418431599936

Epoch: 6| Step: 7
Training loss: 0.6900966167449951
Validation loss: 2.2144686182339988

Epoch: 6| Step: 8
Training loss: 0.8675792217254639
Validation loss: 2.1686517198880515

Epoch: 6| Step: 9
Training loss: 0.6062246561050415
Validation loss: 2.198158880074819

Epoch: 6| Step: 10
Training loss: 0.8257386088371277
Validation loss: 2.193868180116018

Epoch: 6| Step: 11
Training loss: 1.081254243850708
Validation loss: 2.20916094382604

Epoch: 6| Step: 12
Training loss: 1.1730436086654663
Validation loss: 2.189878245194753

Epoch: 6| Step: 13
Training loss: 1.2236642837524414
Validation loss: 2.154178202152252

Epoch: 431| Step: 0
Training loss: 0.8679832220077515
Validation loss: 2.1604793866475425

Epoch: 6| Step: 1
Training loss: 0.598465085029602
Validation loss: 2.183651407559713

Epoch: 6| Step: 2
Training loss: 1.0723652839660645
Validation loss: 2.149263302485148

Epoch: 6| Step: 3
Training loss: 0.8911616802215576
Validation loss: 2.1303093234697976

Epoch: 6| Step: 4
Training loss: 0.47087419033050537
Validation loss: 2.1672255396842957

Epoch: 6| Step: 5
Training loss: 0.62457674741745
Validation loss: 2.1717395385106406

Epoch: 6| Step: 6
Training loss: 0.623591959476471
Validation loss: 2.1660934487978616

Epoch: 6| Step: 7
Training loss: 1.7712593078613281
Validation loss: 2.1407224535942078

Epoch: 6| Step: 8
Training loss: 1.2077637910842896
Validation loss: 2.110963145891825

Epoch: 6| Step: 9
Training loss: 1.5369418859481812
Validation loss: 2.1284428437550864

Epoch: 6| Step: 10
Training loss: 0.9912692904472351
Validation loss: 2.1707369287808738

Epoch: 6| Step: 11
Training loss: 0.8936765789985657
Validation loss: 2.1366790334383645

Epoch: 6| Step: 12
Training loss: 1.1900708675384521
Validation loss: 2.1346887747446694

Epoch: 6| Step: 13
Training loss: 0.5866941213607788
Validation loss: 2.1600715120633445

Epoch: 432| Step: 0
Training loss: 0.8162160515785217
Validation loss: 2.153468211491903

Epoch: 6| Step: 1
Training loss: 1.0586352348327637
Validation loss: 2.137365917364756

Epoch: 6| Step: 2
Training loss: 1.3251980543136597
Validation loss: 2.1581785877545676

Epoch: 6| Step: 3
Training loss: 1.0025935173034668
Validation loss: 2.1960026025772095

Epoch: 6| Step: 4
Training loss: 1.7188374996185303
Validation loss: 2.2015791535377502

Epoch: 6| Step: 5
Training loss: 0.45678287744522095
Validation loss: 2.1961893836657205

Epoch: 6| Step: 6
Training loss: 0.8955879211425781
Validation loss: 2.1755024592081704

Epoch: 6| Step: 7
Training loss: 0.8904117345809937
Validation loss: 2.182257135709127

Epoch: 6| Step: 8
Training loss: 1.0131888389587402
Validation loss: 2.181388000647227

Epoch: 6| Step: 9
Training loss: 0.5445114970207214
Validation loss: 2.1933159033457437

Epoch: 6| Step: 10
Training loss: 0.6973204612731934
Validation loss: 2.0802393158276877

Epoch: 6| Step: 11
Training loss: 0.9164526462554932
Validation loss: 2.1556259195009866

Epoch: 6| Step: 12
Training loss: 1.045517921447754
Validation loss: 2.150937875111898

Epoch: 6| Step: 13
Training loss: 0.8336745500564575
Validation loss: 2.1865627765655518

Epoch: 433| Step: 0
Training loss: 1.1256290674209595
Validation loss: 2.1200255950291953

Epoch: 6| Step: 1
Training loss: 1.0299935340881348
Validation loss: 2.1850423415501914

Epoch: 6| Step: 2
Training loss: 1.1454548835754395
Validation loss: 2.166857600212097

Epoch: 6| Step: 3
Training loss: 0.6597179174423218
Validation loss: 2.1587746143341064

Epoch: 6| Step: 4
Training loss: 1.2493891716003418
Validation loss: 2.1874829729398093

Epoch: 6| Step: 5
Training loss: 1.471181035041809
Validation loss: 2.1426878372828164

Epoch: 6| Step: 6
Training loss: 0.4725022315979004
Validation loss: 2.1707172791163125

Epoch: 6| Step: 7
Training loss: 0.4970148205757141
Validation loss: 2.140709857145945

Epoch: 6| Step: 8
Training loss: 1.0867341756820679
Validation loss: 2.1734264294306436

Epoch: 6| Step: 9
Training loss: 1.0763766765594482
Validation loss: 2.2423549691836038

Epoch: 6| Step: 10
Training loss: 0.6307765245437622
Validation loss: 2.181550840536753

Epoch: 6| Step: 11
Training loss: 1.1291629076004028
Validation loss: 2.1715815464655557

Epoch: 6| Step: 12
Training loss: 0.5583581924438477
Validation loss: 2.148883322874705

Epoch: 6| Step: 13
Training loss: 0.8523002862930298
Validation loss: 2.148665189743042

Epoch: 434| Step: 0
Training loss: 0.7301846742630005
Validation loss: 2.135800580183665

Epoch: 6| Step: 1
Training loss: 1.3508409261703491
Validation loss: 2.1209235986073813

Epoch: 6| Step: 2
Training loss: 0.8907929062843323
Validation loss: 2.1648515661557517

Epoch: 6| Step: 3
Training loss: 0.8266952037811279
Validation loss: 2.1249968806902566

Epoch: 6| Step: 4
Training loss: 0.699015736579895
Validation loss: 2.124860922495524

Epoch: 6| Step: 5
Training loss: 1.1661815643310547
Validation loss: 2.148424744606018

Epoch: 6| Step: 6
Training loss: 0.9648287296295166
Validation loss: 2.143468995889028

Epoch: 6| Step: 7
Training loss: 0.6376122832298279
Validation loss: 2.141637702782949

Epoch: 6| Step: 8
Training loss: 1.7412149906158447
Validation loss: 2.129868447780609

Epoch: 6| Step: 9
Training loss: 0.7724424600601196
Validation loss: 2.156683405240377

Epoch: 6| Step: 10
Training loss: 1.3037114143371582
Validation loss: 2.178050696849823

Epoch: 6| Step: 11
Training loss: 0.7295727729797363
Validation loss: 2.183217386404673

Epoch: 6| Step: 12
Training loss: 0.7269248366355896
Validation loss: 2.196316401163737

Epoch: 6| Step: 13
Training loss: 0.8134884834289551
Validation loss: 2.14692223072052

Epoch: 435| Step: 0
Training loss: 0.8866704106330872
Validation loss: 2.169735928376516

Epoch: 6| Step: 1
Training loss: 1.2624642848968506
Validation loss: 2.158443729082743

Epoch: 6| Step: 2
Training loss: 0.8934070467948914
Validation loss: 2.147440512975057

Epoch: 6| Step: 3
Training loss: 1.1080212593078613
Validation loss: 2.1238913933436074

Epoch: 6| Step: 4
Training loss: 0.7252124547958374
Validation loss: 2.1442461808522544

Epoch: 6| Step: 5
Training loss: 0.933829665184021
Validation loss: 2.1499642928441367

Epoch: 6| Step: 6
Training loss: 0.9281517267227173
Validation loss: 2.1005348761876426

Epoch: 6| Step: 7
Training loss: 0.8385845422744751
Validation loss: 2.1323729356129966

Epoch: 6| Step: 8
Training loss: 0.3478226065635681
Validation loss: 2.084643085797628

Epoch: 6| Step: 9
Training loss: 0.8439770936965942
Validation loss: 2.1429805755615234

Epoch: 6| Step: 10
Training loss: 1.4973140954971313
Validation loss: 2.220727483431498

Epoch: 6| Step: 11
Training loss: 0.7932827472686768
Validation loss: 2.217375715573629

Epoch: 6| Step: 12
Training loss: 0.7904461622238159
Validation loss: 2.2011979818344116

Epoch: 6| Step: 13
Training loss: 2.0198144912719727
Validation loss: 2.2318636377652488

Epoch: 436| Step: 0
Training loss: 0.986170768737793
Validation loss: 2.2058984438578286

Epoch: 6| Step: 1
Training loss: 0.8732070922851562
Validation loss: 2.198519984881083

Epoch: 6| Step: 2
Training loss: 0.7678862810134888
Validation loss: 2.0924794673919678

Epoch: 6| Step: 3
Training loss: 1.082653284072876
Validation loss: 2.1678338050842285

Epoch: 6| Step: 4
Training loss: 0.8000353574752808
Validation loss: 2.136699378490448

Epoch: 6| Step: 5
Training loss: 0.6331800222396851
Validation loss: 2.1511614123980203

Epoch: 6| Step: 6
Training loss: 0.7197016477584839
Validation loss: 2.1630442341168723

Epoch: 6| Step: 7
Training loss: 0.8527520895004272
Validation loss: 2.1029247442881265

Epoch: 6| Step: 8
Training loss: 1.041982650756836
Validation loss: 2.2000157634417215

Epoch: 6| Step: 9
Training loss: 0.904481828212738
Validation loss: 2.1247583429018655

Epoch: 6| Step: 10
Training loss: 1.40378737449646
Validation loss: 2.172527233759562

Epoch: 6| Step: 11
Training loss: 0.8055721521377563
Validation loss: 2.198880672454834

Epoch: 6| Step: 12
Training loss: 0.8783637881278992
Validation loss: 2.1330666144688926

Epoch: 6| Step: 13
Training loss: 1.6943690776824951
Validation loss: 2.1887102325757346

Epoch: 437| Step: 0
Training loss: 0.43433094024658203
Validation loss: 2.1983686884244285

Epoch: 6| Step: 1
Training loss: 1.1722757816314697
Validation loss: 2.169047713279724

Epoch: 6| Step: 2
Training loss: 0.9103274345397949
Validation loss: 2.1720781723658242

Epoch: 6| Step: 3
Training loss: 1.4506324529647827
Validation loss: 2.170133868853251

Epoch: 6| Step: 4
Training loss: 0.7389732003211975
Validation loss: 2.1498213609059653

Epoch: 6| Step: 5
Training loss: 0.6286317110061646
Validation loss: 2.2162778774897256

Epoch: 6| Step: 6
Training loss: 0.32697105407714844
Validation loss: 2.2056477069854736

Epoch: 6| Step: 7
Training loss: 1.2238444089889526
Validation loss: 2.205642501513163

Epoch: 6| Step: 8
Training loss: 1.380012035369873
Validation loss: 2.1506349643071494

Epoch: 6| Step: 9
Training loss: 1.147219181060791
Validation loss: 2.151495397090912

Epoch: 6| Step: 10
Training loss: 1.0184366703033447
Validation loss: 2.192902406056722

Epoch: 6| Step: 11
Training loss: 0.7357385754585266
Validation loss: 2.161278784275055

Epoch: 6| Step: 12
Training loss: 1.462912917137146
Validation loss: 2.1645262638727822

Epoch: 6| Step: 13
Training loss: 1.2641383409500122
Validation loss: 2.2092687487602234

Epoch: 438| Step: 0
Training loss: 1.6204564571380615
Validation loss: 2.2284828623135886

Epoch: 6| Step: 1
Training loss: 0.9889660477638245
Validation loss: 2.1630669832229614

Epoch: 6| Step: 2
Training loss: 1.051109790802002
Validation loss: 2.157277981440226

Epoch: 6| Step: 3
Training loss: 0.8000898957252502
Validation loss: 2.1568691730499268

Epoch: 6| Step: 4
Training loss: 1.122860312461853
Validation loss: 2.1483537753423056

Epoch: 6| Step: 5
Training loss: 0.5347609519958496
Validation loss: 2.1698633432388306

Epoch: 6| Step: 6
Training loss: 1.1936376094818115
Validation loss: 2.202689528465271

Epoch: 6| Step: 7
Training loss: 1.0427249670028687
Validation loss: 2.1575324336687722

Epoch: 6| Step: 8
Training loss: 1.0811865329742432
Validation loss: 2.1802878975868225

Epoch: 6| Step: 9
Training loss: 0.7755353450775146
Validation loss: 2.177684942881266

Epoch: 6| Step: 10
Training loss: 0.5922878980636597
Validation loss: 2.17968088388443

Epoch: 6| Step: 11
Training loss: 0.9434312582015991
Validation loss: 2.1821757753690085

Epoch: 6| Step: 12
Training loss: 0.4904996454715729
Validation loss: 2.1954033374786377

Epoch: 6| Step: 13
Training loss: 1.7455627918243408
Validation loss: 2.1792322595914206

Epoch: 439| Step: 0
Training loss: 0.9433184862136841
Validation loss: 2.1932154496510825

Epoch: 6| Step: 1
Training loss: 2.0397307872772217
Validation loss: 2.18507981300354

Epoch: 6| Step: 2
Training loss: 1.0059775114059448
Validation loss: 2.1693283319473267

Epoch: 6| Step: 3
Training loss: 1.3189339637756348
Validation loss: 2.1902058521906533

Epoch: 6| Step: 4
Training loss: 0.8611409068107605
Validation loss: 2.1805189847946167

Epoch: 6| Step: 5
Training loss: 0.6476557850837708
Validation loss: 2.1636809508005777

Epoch: 6| Step: 6
Training loss: 0.5255237817764282
Validation loss: 2.187091867129008

Epoch: 6| Step: 7
Training loss: 0.8284924030303955
Validation loss: 2.157151540120443

Epoch: 6| Step: 8
Training loss: 0.7181653380393982
Validation loss: 2.159300963083903

Epoch: 6| Step: 9
Training loss: 0.7361387014389038
Validation loss: 2.1627091566721597

Epoch: 6| Step: 10
Training loss: 0.7068010568618774
Validation loss: 2.1490405797958374

Epoch: 6| Step: 11
Training loss: 0.7947805523872375
Validation loss: 2.186128874619802

Epoch: 6| Step: 12
Training loss: 0.5802032947540283
Validation loss: 2.1556456486384072

Epoch: 6| Step: 13
Training loss: 1.4951460361480713
Validation loss: 2.1174264748891196

Epoch: 440| Step: 0
Training loss: 0.9642619490623474
Validation loss: 2.1273858547210693

Epoch: 6| Step: 1
Training loss: 0.9332267045974731
Validation loss: 2.128821015357971

Epoch: 6| Step: 2
Training loss: 0.466205894947052
Validation loss: 2.131706158320109

Epoch: 6| Step: 3
Training loss: 1.1322739124298096
Validation loss: 2.1424834529558816

Epoch: 6| Step: 4
Training loss: 1.3028180599212646
Validation loss: 2.145681301752726

Epoch: 6| Step: 5
Training loss: 1.6908575296401978
Validation loss: 2.2099013725916543

Epoch: 6| Step: 6
Training loss: 1.1239733695983887
Validation loss: 2.1421690781911216

Epoch: 6| Step: 7
Training loss: 0.3724554777145386
Validation loss: 2.1426514983177185

Epoch: 6| Step: 8
Training loss: 0.46063700318336487
Validation loss: 2.214853564898173

Epoch: 6| Step: 9
Training loss: 0.8171600103378296
Validation loss: 2.2133133014043174

Epoch: 6| Step: 10
Training loss: 0.9418753981590271
Validation loss: 2.1953845620155334

Epoch: 6| Step: 11
Training loss: 0.8710370063781738
Validation loss: 2.1581151286760965

Epoch: 6| Step: 12
Training loss: 0.5860551595687866
Validation loss: 2.2177403966585794

Epoch: 6| Step: 13
Training loss: 1.1019150018692017
Validation loss: 2.147462169329325

Epoch: 441| Step: 0
Training loss: 0.8305013179779053
Validation loss: 2.1173022389411926

Epoch: 6| Step: 1
Training loss: 1.5989207029342651
Validation loss: 2.17934779326121

Epoch: 6| Step: 2
Training loss: 1.0735489130020142
Validation loss: 2.1487671732902527

Epoch: 6| Step: 3
Training loss: 1.149819016456604
Validation loss: 2.1164246002833047

Epoch: 6| Step: 4
Training loss: 1.4792120456695557
Validation loss: 2.1575470765431723

Epoch: 6| Step: 5
Training loss: 0.9712469577789307
Validation loss: 2.14312752087911

Epoch: 6| Step: 6
Training loss: 1.0870859622955322
Validation loss: 2.118983586629232

Epoch: 6| Step: 7
Training loss: 0.7417941093444824
Validation loss: 2.144917090733846

Epoch: 6| Step: 8
Training loss: 0.7448328137397766
Validation loss: 2.164418935775757

Epoch: 6| Step: 9
Training loss: 1.0160094499588013
Validation loss: 2.1796974738438926

Epoch: 6| Step: 10
Training loss: 0.7647245526313782
Validation loss: 2.152043640613556

Epoch: 6| Step: 11
Training loss: 0.7307710647583008
Validation loss: 2.1351091464360556

Epoch: 6| Step: 12
Training loss: 0.6580913662910461
Validation loss: 2.1238576769828796

Epoch: 6| Step: 13
Training loss: 0.8218092918395996
Validation loss: 2.143192768096924

Epoch: 442| Step: 0
Training loss: 1.2635890245437622
Validation loss: 2.187052766482035

Epoch: 6| Step: 1
Training loss: 0.62013840675354
Validation loss: 2.194327394167582

Epoch: 6| Step: 2
Training loss: 0.7630220651626587
Validation loss: 2.211920698483785

Epoch: 6| Step: 3
Training loss: 0.4776378273963928
Validation loss: 2.2112538814544678

Epoch: 6| Step: 4
Training loss: 0.9596877098083496
Validation loss: 2.1956497629483542

Epoch: 6| Step: 5
Training loss: 1.069386601448059
Validation loss: 2.1836277842521667

Epoch: 6| Step: 6
Training loss: 1.0982234477996826
Validation loss: 2.1406915187835693

Epoch: 6| Step: 7
Training loss: 0.9424401521682739
Validation loss: 2.156729578971863

Epoch: 6| Step: 8
Training loss: 0.5496329665184021
Validation loss: 2.157957454522451

Epoch: 6| Step: 9
Training loss: 1.7128522396087646
Validation loss: 2.1615626215934753

Epoch: 6| Step: 10
Training loss: 1.3906813859939575
Validation loss: 2.21528826157252

Epoch: 6| Step: 11
Training loss: 0.8356746435165405
Validation loss: 2.1246881087621055

Epoch: 6| Step: 12
Training loss: 1.189262866973877
Validation loss: 2.176513413588206

Epoch: 6| Step: 13
Training loss: 0.8014782667160034
Validation loss: 2.144169489542643

Epoch: 443| Step: 0
Training loss: 1.5238540172576904
Validation loss: 2.1418604254722595

Epoch: 6| Step: 1
Training loss: 0.9290254712104797
Validation loss: 2.1425636410713196

Epoch: 6| Step: 2
Training loss: 0.5799090266227722
Validation loss: 2.207656999429067

Epoch: 6| Step: 3
Training loss: 0.9447602033615112
Validation loss: 2.174398104349772

Epoch: 6| Step: 4
Training loss: 1.081817388534546
Validation loss: 2.153567930062612

Epoch: 6| Step: 5
Training loss: 1.3692188262939453
Validation loss: 2.1465569535891214

Epoch: 6| Step: 6
Training loss: 0.8082408905029297
Validation loss: 2.154171586036682

Epoch: 6| Step: 7
Training loss: 0.7960283160209656
Validation loss: 2.168126364549001

Epoch: 6| Step: 8
Training loss: 0.7595424652099609
Validation loss: 2.159287174542745

Epoch: 6| Step: 9
Training loss: 1.043316125869751
Validation loss: 2.150172213713328

Epoch: 6| Step: 10
Training loss: 1.0290322303771973
Validation loss: 2.1872029900550842

Epoch: 6| Step: 11
Training loss: 0.5723162889480591
Validation loss: 2.1912291248639426

Epoch: 6| Step: 12
Training loss: 0.6234580874443054
Validation loss: 2.1869741678237915

Epoch: 6| Step: 13
Training loss: 0.8036915063858032
Validation loss: 2.224097410837809

Epoch: 444| Step: 0
Training loss: 0.7829110622406006
Validation loss: 2.1375121474266052

Epoch: 6| Step: 1
Training loss: 1.1870096921920776
Validation loss: 2.238895138104757

Epoch: 6| Step: 2
Training loss: 0.552370548248291
Validation loss: 2.185355226198832

Epoch: 6| Step: 3
Training loss: 0.9677227735519409
Validation loss: 2.199396292368571

Epoch: 6| Step: 4
Training loss: 0.8131531476974487
Validation loss: 2.1916382710138955

Epoch: 6| Step: 5
Training loss: 0.32019513845443726
Validation loss: 2.15632027387619

Epoch: 6| Step: 6
Training loss: 1.0255850553512573
Validation loss: 2.1518393953641257

Epoch: 6| Step: 7
Training loss: 1.2693170309066772
Validation loss: 2.2184398770332336

Epoch: 6| Step: 8
Training loss: 0.551361620426178
Validation loss: 2.125321010748545

Epoch: 6| Step: 9
Training loss: 1.0086169242858887
Validation loss: 2.1653480728467307

Epoch: 6| Step: 10
Training loss: 1.4524513483047485
Validation loss: 2.1898622115453086

Epoch: 6| Step: 11
Training loss: 1.4103062152862549
Validation loss: 2.155491610368093

Epoch: 6| Step: 12
Training loss: 0.9754476547241211
Validation loss: 2.163396636644999

Epoch: 6| Step: 13
Training loss: 0.5318952202796936
Validation loss: 2.178840180238088

Epoch: 445| Step: 0
Training loss: 0.8352132439613342
Validation loss: 2.2214491168657937

Epoch: 6| Step: 1
Training loss: 1.8470752239227295
Validation loss: 2.2043935855229697

Epoch: 6| Step: 2
Training loss: 0.47989678382873535
Validation loss: 2.1843047738075256

Epoch: 6| Step: 3
Training loss: 0.8308954834938049
Validation loss: 2.1697643200556436

Epoch: 6| Step: 4
Training loss: 0.8893983960151672
Validation loss: 2.163797616958618

Epoch: 6| Step: 5
Training loss: 0.925502359867096
Validation loss: 2.11251437664032

Epoch: 6| Step: 6
Training loss: 0.5684875249862671
Validation loss: 2.1320900917053223

Epoch: 6| Step: 7
Training loss: 0.9515718221664429
Validation loss: 2.098881959915161

Epoch: 6| Step: 8
Training loss: 0.9158276319503784
Validation loss: 2.15517391761144

Epoch: 6| Step: 9
Training loss: 0.33722272515296936
Validation loss: 2.105162183443705

Epoch: 6| Step: 10
Training loss: 1.604314923286438
Validation loss: 2.1281723181406655

Epoch: 6| Step: 11
Training loss: 0.7537524700164795
Validation loss: 2.0823949376742044

Epoch: 6| Step: 12
Training loss: 1.0956315994262695
Validation loss: 2.058181623617808

Epoch: 6| Step: 13
Training loss: 1.0623492002487183
Validation loss: 2.1219736138979592

Epoch: 446| Step: 0
Training loss: 1.6897706985473633
Validation loss: 2.062297821044922

Epoch: 6| Step: 1
Training loss: 0.773086667060852
Validation loss: 2.1082937717437744

Epoch: 6| Step: 2
Training loss: 0.9373688697814941
Validation loss: 2.111981987953186

Epoch: 6| Step: 3
Training loss: 0.963516354560852
Validation loss: 2.136915107568105

Epoch: 6| Step: 4
Training loss: 0.8786860704421997
Validation loss: 2.118511736392975

Epoch: 6| Step: 5
Training loss: 0.4837263822555542
Validation loss: 2.146435876687368

Epoch: 6| Step: 6
Training loss: 0.7704893350601196
Validation loss: 2.1091597080230713

Epoch: 6| Step: 7
Training loss: 1.087498426437378
Validation loss: 2.154796322186788

Epoch: 6| Step: 8
Training loss: 0.9117100238800049
Validation loss: 2.20714004834493

Epoch: 6| Step: 9
Training loss: 1.7922039031982422
Validation loss: 2.1748777429262796

Epoch: 6| Step: 10
Training loss: 1.126176357269287
Validation loss: 2.16197661558787

Epoch: 6| Step: 11
Training loss: 0.9007245302200317
Validation loss: 2.1102208495140076

Epoch: 6| Step: 12
Training loss: 0.5745080709457397
Validation loss: 2.086587051550547

Epoch: 6| Step: 13
Training loss: 0.46670782566070557
Validation loss: 2.1014556090037027

Epoch: 447| Step: 0
Training loss: 0.5144591927528381
Validation loss: 2.0767341256141663

Epoch: 6| Step: 1
Training loss: 1.0377343893051147
Validation loss: 2.1270572741826377

Epoch: 6| Step: 2
Training loss: 0.9038177728652954
Validation loss: 2.1121864716211953

Epoch: 6| Step: 3
Training loss: 1.3724188804626465
Validation loss: 2.135688285032908

Epoch: 6| Step: 4
Training loss: 0.9213525652885437
Validation loss: 2.1791711250940957

Epoch: 6| Step: 5
Training loss: 0.5895793437957764
Validation loss: 2.1552617152531943

Epoch: 6| Step: 6
Training loss: 1.3534822463989258
Validation loss: 2.22480575243632

Epoch: 6| Step: 7
Training loss: 0.6520599126815796
Validation loss: 2.192424952983856

Epoch: 6| Step: 8
Training loss: 1.2571460008621216
Validation loss: 2.177741269270579

Epoch: 6| Step: 9
Training loss: 1.135998010635376
Validation loss: 2.2032331625620523

Epoch: 6| Step: 10
Training loss: 0.7495627403259277
Validation loss: 2.2027008533477783

Epoch: 6| Step: 11
Training loss: 0.789841890335083
Validation loss: 2.148603061834971

Epoch: 6| Step: 12
Training loss: 0.7901082038879395
Validation loss: 2.1608283519744873

Epoch: 6| Step: 13
Training loss: 0.5675746202468872
Validation loss: 2.1498621304829917

Epoch: 448| Step: 0
Training loss: 0.9241716265678406
Validation loss: 2.1029454469680786

Epoch: 6| Step: 1
Training loss: 1.8880841732025146
Validation loss: 2.1240800817807517

Epoch: 6| Step: 2
Training loss: 0.7910703420639038
Validation loss: 2.087653954823812

Epoch: 6| Step: 3
Training loss: 0.699582040309906
Validation loss: 2.104682683944702

Epoch: 6| Step: 4
Training loss: 1.165736198425293
Validation loss: 2.1077942649523416

Epoch: 6| Step: 5
Training loss: 1.0615431070327759
Validation loss: 2.11436398824056

Epoch: 6| Step: 6
Training loss: 0.8839626312255859
Validation loss: 2.114694873491923

Epoch: 6| Step: 7
Training loss: 1.229103922843933
Validation loss: 2.126109540462494

Epoch: 6| Step: 8
Training loss: 0.7240765690803528
Validation loss: 2.11299592256546

Epoch: 6| Step: 9
Training loss: 0.8301661014556885
Validation loss: 2.1816185315450034

Epoch: 6| Step: 10
Training loss: 0.8731399178504944
Validation loss: 2.1471063693364463

Epoch: 6| Step: 11
Training loss: 0.3860059976577759
Validation loss: 2.177066226800283

Epoch: 6| Step: 12
Training loss: 0.7031457424163818
Validation loss: 2.1698849201202393

Epoch: 6| Step: 13
Training loss: 0.670910120010376
Validation loss: 2.1858733097712197

Epoch: 449| Step: 0
Training loss: 1.3062294721603394
Validation loss: 2.216023325920105

Epoch: 6| Step: 1
Training loss: 0.8725510835647583
Validation loss: 2.217356244723002

Epoch: 6| Step: 2
Training loss: 0.927412748336792
Validation loss: 2.216784656047821

Epoch: 6| Step: 3
Training loss: 1.0868873596191406
Validation loss: 2.21747358640035

Epoch: 6| Step: 4
Training loss: 0.7780376672744751
Validation loss: 2.1602505842844644

Epoch: 6| Step: 5
Training loss: 0.7402001619338989
Validation loss: 2.169816017150879

Epoch: 6| Step: 6
Training loss: 0.7404395341873169
Validation loss: 2.1738674640655518

Epoch: 6| Step: 7
Training loss: 0.7013510465621948
Validation loss: 2.1858147382736206

Epoch: 6| Step: 8
Training loss: 0.42662644386291504
Validation loss: 2.223117729028066

Epoch: 6| Step: 9
Training loss: 1.4875530004501343
Validation loss: 2.180595636367798

Epoch: 6| Step: 10
Training loss: 0.6651167869567871
Validation loss: 2.1692726016044617

Epoch: 6| Step: 11
Training loss: 0.9966745376586914
Validation loss: 2.1940070390701294

Epoch: 6| Step: 12
Training loss: 1.1995524168014526
Validation loss: 2.114729086558024

Epoch: 6| Step: 13
Training loss: 0.7626934051513672
Validation loss: 2.1248063246409097

Epoch: 450| Step: 0
Training loss: 0.5644935369491577
Validation loss: 2.165429949760437

Epoch: 6| Step: 1
Training loss: 0.876470685005188
Validation loss: 2.1352672576904297

Epoch: 6| Step: 2
Training loss: 0.6891323328018188
Validation loss: 2.1514840722084045

Epoch: 6| Step: 3
Training loss: 0.9139487743377686
Validation loss: 2.1236449082692466

Epoch: 6| Step: 4
Training loss: 0.9572591781616211
Validation loss: 2.1321523984273276

Epoch: 6| Step: 5
Training loss: 1.2390453815460205
Validation loss: 2.082698424657186

Epoch: 6| Step: 6
Training loss: 0.67972731590271
Validation loss: 2.092261632283529

Epoch: 6| Step: 7
Training loss: 1.150684118270874
Validation loss: 2.1464935342470803

Epoch: 6| Step: 8
Training loss: 1.8015239238739014
Validation loss: 2.1514949003855386

Epoch: 6| Step: 9
Training loss: 0.815162181854248
Validation loss: 2.1573679049809775

Epoch: 6| Step: 10
Training loss: 1.0342516899108887
Validation loss: 2.1880129973093667

Epoch: 6| Step: 11
Training loss: 0.7466456890106201
Validation loss: 2.182245969772339

Epoch: 6| Step: 12
Training loss: 0.7843828797340393
Validation loss: 2.174038271109263

Epoch: 6| Step: 13
Training loss: 0.952425479888916
Validation loss: 2.1407238642374673

Epoch: 451| Step: 0
Training loss: 1.3486220836639404
Validation loss: 2.167690694332123

Epoch: 6| Step: 1
Training loss: 1.142114520072937
Validation loss: 2.1460585991541543

Epoch: 6| Step: 2
Training loss: 1.4454036951065063
Validation loss: 2.153108378251394

Epoch: 6| Step: 3
Training loss: 1.1988160610198975
Validation loss: 2.153622309366862

Epoch: 6| Step: 4
Training loss: 1.1935138702392578
Validation loss: 2.1730809211730957

Epoch: 6| Step: 5
Training loss: 1.0504164695739746
Validation loss: 2.2293506264686584

Epoch: 6| Step: 6
Training loss: 0.5564901828765869
Validation loss: 2.2247061729431152

Epoch: 6| Step: 7
Training loss: 0.6870790719985962
Validation loss: 2.1590925653775535

Epoch: 6| Step: 8
Training loss: 0.7532163858413696
Validation loss: 2.162782867749532

Epoch: 6| Step: 9
Training loss: 0.9255124926567078
Validation loss: 2.1348605155944824

Epoch: 6| Step: 10
Training loss: 0.6218740940093994
Validation loss: 2.1469077269236245

Epoch: 6| Step: 11
Training loss: 1.7590774297714233
Validation loss: 2.1601080894470215

Epoch: 6| Step: 12
Training loss: 0.6167582273483276
Validation loss: 2.193317095438639

Epoch: 6| Step: 13
Training loss: 0.7284789085388184
Validation loss: 2.1557361682256064

Epoch: 452| Step: 0
Training loss: 0.9067102670669556
Validation loss: 2.1602885723114014

Epoch: 6| Step: 1
Training loss: 0.6141574382781982
Validation loss: 2.1431497732798257

Epoch: 6| Step: 2
Training loss: 1.264313817024231
Validation loss: 2.0887652238210044

Epoch: 6| Step: 3
Training loss: 0.4339480698108673
Validation loss: 2.1274545192718506

Epoch: 6| Step: 4
Training loss: 1.2249505519866943
Validation loss: 2.1332596937815347

Epoch: 6| Step: 5
Training loss: 0.8293775320053101
Validation loss: 2.119460880756378

Epoch: 6| Step: 6
Training loss: 0.731694221496582
Validation loss: 2.135147134462992

Epoch: 6| Step: 7
Training loss: 0.7324748039245605
Validation loss: 2.1855836709340415

Epoch: 6| Step: 8
Training loss: 1.269364595413208
Validation loss: 2.1962687770525613

Epoch: 6| Step: 9
Training loss: 0.6863828301429749
Validation loss: 2.2178273598353067

Epoch: 6| Step: 10
Training loss: 0.7732292413711548
Validation loss: 2.19911523660024

Epoch: 6| Step: 11
Training loss: 0.4008565843105316
Validation loss: 2.1492771903673806

Epoch: 6| Step: 12
Training loss: 1.5268405675888062
Validation loss: 2.2165423234303794

Epoch: 6| Step: 13
Training loss: 0.8937487006187439
Validation loss: 2.195077975591024

Epoch: 453| Step: 0
Training loss: 0.813525915145874
Validation loss: 2.2187267541885376

Epoch: 6| Step: 1
Training loss: 0.9324887990951538
Validation loss: 2.199280261993408

Epoch: 6| Step: 2
Training loss: 0.8169181942939758
Validation loss: 2.208758314450582

Epoch: 6| Step: 3
Training loss: 1.103990912437439
Validation loss: 2.1254358688990274

Epoch: 6| Step: 4
Training loss: 0.45587435364723206
Validation loss: 2.1430854201316833

Epoch: 6| Step: 5
Training loss: 0.8582621216773987
Validation loss: 2.1166805028915405

Epoch: 6| Step: 6
Training loss: 1.3201618194580078
Validation loss: 2.112896184126536

Epoch: 6| Step: 7
Training loss: 0.5343185663223267
Validation loss: 2.103247582912445

Epoch: 6| Step: 8
Training loss: 1.3228240013122559
Validation loss: 2.112417976061503

Epoch: 6| Step: 9
Training loss: 0.8415053486824036
Validation loss: 2.1351803143819175

Epoch: 6| Step: 10
Training loss: 0.9123574495315552
Validation loss: 2.1210328737894693

Epoch: 6| Step: 11
Training loss: 0.6593453288078308
Validation loss: 2.132573962211609

Epoch: 6| Step: 12
Training loss: 1.4103386402130127
Validation loss: 2.135898470878601

Epoch: 6| Step: 13
Training loss: 1.570282220840454
Validation loss: 2.18135404586792

Epoch: 454| Step: 0
Training loss: 1.0428740978240967
Validation loss: 2.127691407998403

Epoch: 6| Step: 1
Training loss: 1.0275702476501465
Validation loss: 2.153290271759033

Epoch: 6| Step: 2
Training loss: 0.6602543592453003
Validation loss: 2.151952008406321

Epoch: 6| Step: 3
Training loss: 0.9231701493263245
Validation loss: 2.2031442523002625

Epoch: 6| Step: 4
Training loss: 1.170687198638916
Validation loss: 2.146404981613159

Epoch: 6| Step: 5
Training loss: 1.1900070905685425
Validation loss: 2.1532620588938394

Epoch: 6| Step: 6
Training loss: 1.4137849807739258
Validation loss: 2.2097948590914407

Epoch: 6| Step: 7
Training loss: 1.4281185865402222
Validation loss: 2.1721832156181335

Epoch: 6| Step: 8
Training loss: 0.9051811099052429
Validation loss: 2.1745818654696145

Epoch: 6| Step: 9
Training loss: 0.5329208374023438
Validation loss: 2.1702199379603067

Epoch: 6| Step: 10
Training loss: 0.42432066798210144
Validation loss: 2.1519503196080527

Epoch: 6| Step: 11
Training loss: 0.8823056221008301
Validation loss: 2.1760226488113403

Epoch: 6| Step: 12
Training loss: 0.6563600301742554
Validation loss: 2.1742244760195413

Epoch: 6| Step: 13
Training loss: 0.5980305671691895
Validation loss: 2.201959013938904

Epoch: 455| Step: 0
Training loss: 0.8336277604103088
Validation loss: 2.171605110168457

Epoch: 6| Step: 1
Training loss: 0.5531007647514343
Validation loss: 2.1972176233927407

Epoch: 6| Step: 2
Training loss: 1.218117594718933
Validation loss: 2.177801767985026

Epoch: 6| Step: 3
Training loss: 0.5041122436523438
Validation loss: 2.158070226510366

Epoch: 6| Step: 4
Training loss: 0.5406960844993591
Validation loss: 2.166381299495697

Epoch: 6| Step: 5
Training loss: 0.9948265552520752
Validation loss: 2.1571369568506875

Epoch: 6| Step: 6
Training loss: 1.5871264934539795
Validation loss: 2.2210389177004495

Epoch: 6| Step: 7
Training loss: 0.838868260383606
Validation loss: 2.2169572512308755

Epoch: 6| Step: 8
Training loss: 0.5170738697052002
Validation loss: 2.1916335225105286

Epoch: 6| Step: 9
Training loss: 0.8071494102478027
Validation loss: 2.1843135754267373

Epoch: 6| Step: 10
Training loss: 0.6650855541229248
Validation loss: 2.184437870979309

Epoch: 6| Step: 11
Training loss: 1.336463212966919
Validation loss: 2.1378067334493003

Epoch: 6| Step: 12
Training loss: 1.123329758644104
Validation loss: 2.1538569927215576

Epoch: 6| Step: 13
Training loss: 1.0060168504714966
Validation loss: 2.122691531976064

Epoch: 456| Step: 0
Training loss: 1.027336597442627
Validation loss: 2.1452150344848633

Epoch: 6| Step: 1
Training loss: 0.8474645614624023
Validation loss: 2.1615765492121377

Epoch: 6| Step: 2
Training loss: 1.265493392944336
Validation loss: 2.1002627412478128

Epoch: 6| Step: 3
Training loss: 1.1264843940734863
Validation loss: 2.123458524545034

Epoch: 6| Step: 4
Training loss: 1.1116790771484375
Validation loss: 2.1499709288279214

Epoch: 6| Step: 5
Training loss: 1.3952710628509521
Validation loss: 2.120753010114034

Epoch: 6| Step: 6
Training loss: 0.6445041298866272
Validation loss: 2.1164729793866477

Epoch: 6| Step: 7
Training loss: 0.7191283702850342
Validation loss: 2.1042750080426535

Epoch: 6| Step: 8
Training loss: 0.8959436416625977
Validation loss: 2.1168397863705954

Epoch: 6| Step: 9
Training loss: 0.7081305384635925
Validation loss: 2.1049044132232666

Epoch: 6| Step: 10
Training loss: 0.45325756072998047
Validation loss: 2.142886996269226

Epoch: 6| Step: 11
Training loss: 0.4796537756919861
Validation loss: 2.1221881906191506

Epoch: 6| Step: 12
Training loss: 0.29025378823280334
Validation loss: 2.1120632688204446

Epoch: 6| Step: 13
Training loss: 1.119260549545288
Validation loss: 2.117330531279246

Epoch: 457| Step: 0
Training loss: 0.6168116331100464
Validation loss: 2.1170968810717263

Epoch: 6| Step: 1
Training loss: 1.3026227951049805
Validation loss: 2.0989394585291543

Epoch: 6| Step: 2
Training loss: 0.5015316009521484
Validation loss: 2.100001355012258

Epoch: 6| Step: 3
Training loss: 1.292549967765808
Validation loss: 2.143032670021057

Epoch: 6| Step: 4
Training loss: 0.9719886183738708
Validation loss: 2.1146446069081626

Epoch: 6| Step: 5
Training loss: 0.7102165222167969
Validation loss: 2.165714204311371

Epoch: 6| Step: 6
Training loss: 1.0650794506072998
Validation loss: 2.1188777685165405

Epoch: 6| Step: 7
Training loss: 0.5992711782455444
Validation loss: 2.15563170115153

Epoch: 6| Step: 8
Training loss: 1.0865920782089233
Validation loss: 2.1004871924718223

Epoch: 6| Step: 9
Training loss: 0.6628390550613403
Validation loss: 2.1321851015090942

Epoch: 6| Step: 10
Training loss: 0.9279170036315918
Validation loss: 2.132490257422129

Epoch: 6| Step: 11
Training loss: 0.4479496479034424
Validation loss: 2.1601807673772178

Epoch: 6| Step: 12
Training loss: 1.2443804740905762
Validation loss: 2.129553278287252

Epoch: 6| Step: 13
Training loss: 1.01325523853302
Validation loss: 2.181278864542643

Epoch: 458| Step: 0
Training loss: 0.8793892860412598
Validation loss: 2.1539740562438965

Epoch: 6| Step: 1
Training loss: 0.457170695066452
Validation loss: 2.152807831764221

Epoch: 6| Step: 2
Training loss: 1.416757583618164
Validation loss: 2.14459494749705

Epoch: 6| Step: 3
Training loss: 1.025830864906311
Validation loss: 2.139452576637268

Epoch: 6| Step: 4
Training loss: 0.6541152596473694
Validation loss: 2.077280600865682

Epoch: 6| Step: 5
Training loss: 1.1967428922653198
Validation loss: 2.114775558312734

Epoch: 6| Step: 6
Training loss: 1.0609875917434692
Validation loss: 2.116381069024404

Epoch: 6| Step: 7
Training loss: 1.261475682258606
Validation loss: 2.089775482813517

Epoch: 6| Step: 8
Training loss: 0.7348899841308594
Validation loss: 2.104542334874471

Epoch: 6| Step: 9
Training loss: 0.5011663436889648
Validation loss: 2.173330863316854

Epoch: 6| Step: 10
Training loss: 0.9235471487045288
Validation loss: 2.1645474433898926

Epoch: 6| Step: 11
Training loss: 0.611630380153656
Validation loss: 2.2150688767433167

Epoch: 6| Step: 12
Training loss: 0.9235469102859497
Validation loss: 2.190483490626017

Epoch: 6| Step: 13
Training loss: 0.4659898579120636
Validation loss: 2.1557289958000183

Epoch: 459| Step: 0
Training loss: 1.005460262298584
Validation loss: 2.1903761426607766

Epoch: 6| Step: 1
Training loss: 1.1377114057540894
Validation loss: 2.210312565167745

Epoch: 6| Step: 2
Training loss: 0.9907037019729614
Validation loss: 2.1850106914838157

Epoch: 6| Step: 3
Training loss: 0.4100113809108734
Validation loss: 2.164487838745117

Epoch: 6| Step: 4
Training loss: 0.975635290145874
Validation loss: 2.1492991844813027

Epoch: 6| Step: 5
Training loss: 0.3915955126285553
Validation loss: 2.1699354449907937

Epoch: 6| Step: 6
Training loss: 0.7134107351303101
Validation loss: 2.169347067674001

Epoch: 6| Step: 7
Training loss: 1.105153203010559
Validation loss: 2.1598481933275857

Epoch: 6| Step: 8
Training loss: 1.3744663000106812
Validation loss: 2.167074759801229

Epoch: 6| Step: 9
Training loss: 0.6244173049926758
Validation loss: 2.122169295946757

Epoch: 6| Step: 10
Training loss: 0.4767993688583374
Validation loss: 2.178945998350779

Epoch: 6| Step: 11
Training loss: 0.9538716077804565
Validation loss: 2.139258066813151

Epoch: 6| Step: 12
Training loss: 0.7818015217781067
Validation loss: 2.1439706285794577

Epoch: 6| Step: 13
Training loss: 0.8147569894790649
Validation loss: 2.1704354087511697

Epoch: 460| Step: 0
Training loss: 0.7689534425735474
Validation loss: 2.1334089438120523

Epoch: 6| Step: 1
Training loss: 0.6086333990097046
Validation loss: 2.170546054840088

Epoch: 6| Step: 2
Training loss: 0.9649147987365723
Validation loss: 2.181843558947245

Epoch: 6| Step: 3
Training loss: 0.565048336982727
Validation loss: 2.1111063957214355

Epoch: 6| Step: 4
Training loss: 0.6444077491760254
Validation loss: 2.156903088092804

Epoch: 6| Step: 5
Training loss: 0.9008735418319702
Validation loss: 2.1371246576309204

Epoch: 6| Step: 6
Training loss: 1.1864314079284668
Validation loss: 2.1552072763442993

Epoch: 6| Step: 7
Training loss: 0.6247549653053284
Validation loss: 2.1834524075190225

Epoch: 6| Step: 8
Training loss: 1.1720422506332397
Validation loss: 2.1534328858057656

Epoch: 6| Step: 9
Training loss: 1.3236603736877441
Validation loss: 2.190812369187673

Epoch: 6| Step: 10
Training loss: 1.613036870956421
Validation loss: 2.2092321316401162

Epoch: 6| Step: 11
Training loss: 0.5657479166984558
Validation loss: 2.208199461301168

Epoch: 6| Step: 12
Training loss: 0.3572620749473572
Validation loss: 2.1871336301167807

Epoch: 6| Step: 13
Training loss: 0.6154898405075073
Validation loss: 2.2188045382499695

Epoch: 461| Step: 0
Training loss: 1.0278425216674805
Validation loss: 2.167116641998291

Epoch: 6| Step: 1
Training loss: 0.4784329831600189
Validation loss: 2.186159908771515

Epoch: 6| Step: 2
Training loss: 1.2220338582992554
Validation loss: 2.1715434193611145

Epoch: 6| Step: 3
Training loss: 0.354727566242218
Validation loss: 2.1536646087964377

Epoch: 6| Step: 4
Training loss: 0.7607626914978027
Validation loss: 2.1242125630378723

Epoch: 6| Step: 5
Training loss: 0.7630748152732849
Validation loss: 2.1281657814979553

Epoch: 6| Step: 6
Training loss: 1.2310187816619873
Validation loss: 2.1229905684789023

Epoch: 6| Step: 7
Training loss: 0.7851032018661499
Validation loss: 2.126835604508718

Epoch: 6| Step: 8
Training loss: 0.9770349264144897
Validation loss: 2.174270828564962

Epoch: 6| Step: 9
Training loss: 0.9387004375457764
Validation loss: 2.13911110162735

Epoch: 6| Step: 10
Training loss: 0.583882212638855
Validation loss: 2.149096349875132

Epoch: 6| Step: 11
Training loss: 1.2940647602081299
Validation loss: 2.1273043553034463

Epoch: 6| Step: 12
Training loss: 0.8473477959632874
Validation loss: 2.151303211847941

Epoch: 6| Step: 13
Training loss: 0.7935691475868225
Validation loss: 2.1547458171844482

Epoch: 462| Step: 0
Training loss: 0.5709863901138306
Validation loss: 2.0923272172609964

Epoch: 6| Step: 1
Training loss: 0.45671385526657104
Validation loss: 2.149347941080729

Epoch: 6| Step: 2
Training loss: 1.0562682151794434
Validation loss: 2.2077298959096274

Epoch: 6| Step: 3
Training loss: 0.5117158889770508
Validation loss: 2.1329516172409058

Epoch: 6| Step: 4
Training loss: 0.6051839590072632
Validation loss: 2.183680991331736

Epoch: 6| Step: 5
Training loss: 0.8493792414665222
Validation loss: 2.1563103596369424

Epoch: 6| Step: 6
Training loss: 1.1675703525543213
Validation loss: 2.201517383257548

Epoch: 6| Step: 7
Training loss: 0.9862849712371826
Validation loss: 2.172843058904012

Epoch: 6| Step: 8
Training loss: 1.1911416053771973
Validation loss: 2.1573694547017417

Epoch: 6| Step: 9
Training loss: 1.6298766136169434
Validation loss: 2.2136417428652444

Epoch: 6| Step: 10
Training loss: 0.47438210248947144
Validation loss: 2.213116725285848

Epoch: 6| Step: 11
Training loss: 0.5849877595901489
Validation loss: 2.1646511554718018

Epoch: 6| Step: 12
Training loss: 0.29192477464675903
Validation loss: 2.1555604139963784

Epoch: 6| Step: 13
Training loss: 1.1315668821334839
Validation loss: 2.1989004611968994

Epoch: 463| Step: 0
Training loss: 0.7911403179168701
Validation loss: 2.155169506867727

Epoch: 6| Step: 1
Training loss: 0.5470468997955322
Validation loss: 2.19457217057546

Epoch: 6| Step: 2
Training loss: 0.22608759999275208
Validation loss: 2.133360048135122

Epoch: 6| Step: 3
Training loss: 0.6339536309242249
Validation loss: 2.1391846934954324

Epoch: 6| Step: 4
Training loss: 1.0029771327972412
Validation loss: 2.208538055419922

Epoch: 6| Step: 5
Training loss: 1.1079816818237305
Validation loss: 2.1268434127171836

Epoch: 6| Step: 6
Training loss: 0.8896377086639404
Validation loss: 2.1674912770589194

Epoch: 6| Step: 7
Training loss: 0.4778382480144501
Validation loss: 2.165074110031128

Epoch: 6| Step: 8
Training loss: 0.40888217091560364
Validation loss: 2.148039758205414

Epoch: 6| Step: 9
Training loss: 1.6452078819274902
Validation loss: 2.1752400398254395

Epoch: 6| Step: 10
Training loss: 0.9382515549659729
Validation loss: 2.1574549674987793

Epoch: 6| Step: 11
Training loss: 0.8844569325447083
Validation loss: 2.1671895186106362

Epoch: 6| Step: 12
Training loss: 1.2427823543548584
Validation loss: 2.1629454096158347

Epoch: 6| Step: 13
Training loss: 0.9145834445953369
Validation loss: 2.184650103251139

Epoch: 464| Step: 0
Training loss: 1.435734510421753
Validation loss: 2.1764095028241477

Epoch: 6| Step: 1
Training loss: 0.5634140968322754
Validation loss: 2.170680562655131

Epoch: 6| Step: 2
Training loss: 0.9483011364936829
Validation loss: 2.1285417477289834

Epoch: 6| Step: 3
Training loss: 0.38870275020599365
Validation loss: 2.157133400440216

Epoch: 6| Step: 4
Training loss: 0.6766024827957153
Validation loss: 2.117429773012797

Epoch: 6| Step: 5
Training loss: 1.2490119934082031
Validation loss: 2.1263772447903952

Epoch: 6| Step: 6
Training loss: 0.5115569233894348
Validation loss: 2.1146117448806763

Epoch: 6| Step: 7
Training loss: 1.1099493503570557
Validation loss: 2.1389233469963074

Epoch: 6| Step: 8
Training loss: 0.6372342109680176
Validation loss: 2.103404939174652

Epoch: 6| Step: 9
Training loss: 1.1042897701263428
Validation loss: 2.1203606923421225

Epoch: 6| Step: 10
Training loss: 0.4543471932411194
Validation loss: 2.095293919245402

Epoch: 6| Step: 11
Training loss: 0.5741653442382812
Validation loss: 2.1033459305763245

Epoch: 6| Step: 12
Training loss: 1.4698500633239746
Validation loss: 2.09771329164505

Epoch: 6| Step: 13
Training loss: 0.9340184926986694
Validation loss: 2.141641934712728

Epoch: 465| Step: 0
Training loss: 0.778150737285614
Validation loss: 2.1437326471010842

Epoch: 6| Step: 1
Training loss: 0.9778735637664795
Validation loss: 2.1340967814127603

Epoch: 6| Step: 2
Training loss: 0.7513357400894165
Validation loss: 2.1179544925689697

Epoch: 6| Step: 3
Training loss: 0.764306902885437
Validation loss: 2.090453584988912

Epoch: 6| Step: 4
Training loss: 0.5851693153381348
Validation loss: 2.126362164815267

Epoch: 6| Step: 5
Training loss: 0.8521566390991211
Validation loss: 2.1353973547617593

Epoch: 6| Step: 6
Training loss: 0.5067712664604187
Validation loss: 2.1252036690711975

Epoch: 6| Step: 7
Training loss: 0.922539472579956
Validation loss: 2.1196104685465493

Epoch: 6| Step: 8
Training loss: 1.1577216386795044
Validation loss: 2.1443856358528137

Epoch: 6| Step: 9
Training loss: 0.9166030883789062
Validation loss: 2.1043235460917153

Epoch: 6| Step: 10
Training loss: 0.7262219190597534
Validation loss: 2.1821998755137124

Epoch: 6| Step: 11
Training loss: 1.2067933082580566
Validation loss: 2.1561756332715354

Epoch: 6| Step: 12
Training loss: 1.229653000831604
Validation loss: 2.178364932537079

Epoch: 6| Step: 13
Training loss: 0.8237448334693909
Validation loss: 2.169388214747111

Epoch: 466| Step: 0
Training loss: 0.8132489919662476
Validation loss: 2.201047639052073

Epoch: 6| Step: 1
Training loss: 0.9970295429229736
Validation loss: 2.205271601676941

Epoch: 6| Step: 2
Training loss: 1.0508273839950562
Validation loss: 2.1849995851516724

Epoch: 6| Step: 3
Training loss: 1.2841485738754272
Validation loss: 2.178679426511129

Epoch: 6| Step: 4
Training loss: 0.5515810251235962
Validation loss: 2.201061467329661

Epoch: 6| Step: 5
Training loss: 0.5102860927581787
Validation loss: 2.137960910797119

Epoch: 6| Step: 6
Training loss: 0.744391679763794
Validation loss: 2.1508595744768777

Epoch: 6| Step: 7
Training loss: 1.159744381904602
Validation loss: 2.160940190156301

Epoch: 6| Step: 8
Training loss: 0.7896344065666199
Validation loss: 2.1662570436795554

Epoch: 6| Step: 9
Training loss: 0.8905597925186157
Validation loss: 2.155993620554606

Epoch: 6| Step: 10
Training loss: 1.6834453344345093
Validation loss: 2.158490478992462

Epoch: 6| Step: 11
Training loss: 0.8769848346710205
Validation loss: 2.0766839186350503

Epoch: 6| Step: 12
Training loss: 0.6350095868110657
Validation loss: 2.135521332422892

Epoch: 6| Step: 13
Training loss: 0.4859783947467804
Validation loss: 2.1165722608566284

Epoch: 467| Step: 0
Training loss: 0.7185931205749512
Validation loss: 2.081289609273275

Epoch: 6| Step: 1
Training loss: 0.5809448957443237
Validation loss: 2.0873239437739053

Epoch: 6| Step: 2
Training loss: 0.49047404527664185
Validation loss: 2.1345510880152383

Epoch: 6| Step: 3
Training loss: 1.333773136138916
Validation loss: 2.161698281764984

Epoch: 6| Step: 4
Training loss: 0.8995980024337769
Validation loss: 2.122433602809906

Epoch: 6| Step: 5
Training loss: 1.2678861618041992
Validation loss: 2.140736758708954

Epoch: 6| Step: 6
Training loss: 0.8745783567428589
Validation loss: 2.1663819948832193

Epoch: 6| Step: 7
Training loss: 0.9683701992034912
Validation loss: 2.123601039250692

Epoch: 6| Step: 8
Training loss: 0.26324158906936646
Validation loss: 2.143072525660197

Epoch: 6| Step: 9
Training loss: 0.8388983011245728
Validation loss: 2.1803847551345825

Epoch: 6| Step: 10
Training loss: 1.181623101234436
Validation loss: 2.123314102490743

Epoch: 6| Step: 11
Training loss: 1.3383859395980835
Validation loss: 2.172799289226532

Epoch: 6| Step: 12
Training loss: 0.5308931469917297
Validation loss: 2.1622390151023865

Epoch: 6| Step: 13
Training loss: 0.642612099647522
Validation loss: 2.12884122133255

Epoch: 468| Step: 0
Training loss: 0.9854564666748047
Validation loss: 2.1904401977856955

Epoch: 6| Step: 1
Training loss: 0.3484795093536377
Validation loss: 2.1241533160209656

Epoch: 6| Step: 2
Training loss: 0.9801979064941406
Validation loss: 2.154535969098409

Epoch: 6| Step: 3
Training loss: 0.8642102479934692
Validation loss: 2.155517896016439

Epoch: 6| Step: 4
Training loss: 0.7293679714202881
Validation loss: 2.1280202865600586

Epoch: 6| Step: 5
Training loss: 0.7024330496788025
Validation loss: 2.139609714349111

Epoch: 6| Step: 6
Training loss: 1.2861437797546387
Validation loss: 2.068056265513102

Epoch: 6| Step: 7
Training loss: 0.7236378192901611
Validation loss: 2.1051791508992515

Epoch: 6| Step: 8
Training loss: 0.8356378674507141
Validation loss: 2.139062682787577

Epoch: 6| Step: 9
Training loss: 0.9502447247505188
Validation loss: 2.0742462873458862

Epoch: 6| Step: 10
Training loss: 1.2466374635696411
Validation loss: 2.148681422074636

Epoch: 6| Step: 11
Training loss: 0.5465080738067627
Validation loss: 2.1485126614570618

Epoch: 6| Step: 12
Training loss: 0.8349224328994751
Validation loss: 2.104676147301992

Epoch: 6| Step: 13
Training loss: 0.9991805553436279
Validation loss: 2.158558189868927

Epoch: 469| Step: 0
Training loss: 1.1931884288787842
Validation loss: 2.1404534578323364

Epoch: 6| Step: 1
Training loss: 0.5210208892822266
Validation loss: 2.1317274371782937

Epoch: 6| Step: 2
Training loss: 0.38870537281036377
Validation loss: 2.1530919869740806

Epoch: 6| Step: 3
Training loss: 1.2115705013275146
Validation loss: 2.195229649543762

Epoch: 6| Step: 4
Training loss: 0.729346752166748
Validation loss: 2.188619871934255

Epoch: 6| Step: 5
Training loss: 0.8324831128120422
Validation loss: 2.190301497777303

Epoch: 6| Step: 6
Training loss: 1.328774094581604
Validation loss: 2.175775945186615

Epoch: 6| Step: 7
Training loss: 0.7345246076583862
Validation loss: 2.135153869787852

Epoch: 6| Step: 8
Training loss: 0.7533072233200073
Validation loss: 2.1526227792104087

Epoch: 6| Step: 9
Training loss: 1.1957387924194336
Validation loss: 2.1335744659105935

Epoch: 6| Step: 10
Training loss: 0.4090765118598938
Validation loss: 2.149954617023468

Epoch: 6| Step: 11
Training loss: 0.49127230048179626
Validation loss: 2.1368114948272705

Epoch: 6| Step: 12
Training loss: 0.6560752391815186
Validation loss: 2.1395182410875955

Epoch: 6| Step: 13
Training loss: 1.2692537307739258
Validation loss: 2.1835298339525857

Epoch: 470| Step: 0
Training loss: 0.33194953203201294
Validation loss: 2.1517667174339294

Epoch: 6| Step: 1
Training loss: 1.2217042446136475
Validation loss: 2.140297253926595

Epoch: 6| Step: 2
Training loss: 0.772542417049408
Validation loss: 2.127212385336558

Epoch: 6| Step: 3
Training loss: 0.746783435344696
Validation loss: 2.1175657908121743

Epoch: 6| Step: 4
Training loss: 1.0736397504806519
Validation loss: 2.1001395185788474

Epoch: 6| Step: 5
Training loss: 0.4626838266849518
Validation loss: 2.0962170362472534

Epoch: 6| Step: 6
Training loss: 1.288853645324707
Validation loss: 2.111067791779836

Epoch: 6| Step: 7
Training loss: 0.6158603429794312
Validation loss: 2.12299636999766

Epoch: 6| Step: 8
Training loss: 1.1788395643234253
Validation loss: 2.140169163544973

Epoch: 6| Step: 9
Training loss: 0.7475173473358154
Validation loss: 2.13141135374705

Epoch: 6| Step: 10
Training loss: 0.9524750709533691
Validation loss: 2.1836844086647034

Epoch: 6| Step: 11
Training loss: 0.8081934452056885
Validation loss: 2.1666124065717063

Epoch: 6| Step: 12
Training loss: 0.788332462310791
Validation loss: 2.1815430323282876

Epoch: 6| Step: 13
Training loss: 0.9486038684844971
Validation loss: 2.209728558858236

Epoch: 471| Step: 0
Training loss: 0.9632977247238159
Validation loss: 2.2277707854906716

Epoch: 6| Step: 1
Training loss: 0.7943544983863831
Validation loss: 2.149043301741282

Epoch: 6| Step: 2
Training loss: 1.0397117137908936
Validation loss: 2.1661478877067566

Epoch: 6| Step: 3
Training loss: 0.8129748106002808
Validation loss: 2.1529475847880044

Epoch: 6| Step: 4
Training loss: 0.8320149183273315
Validation loss: 2.16375861565272

Epoch: 6| Step: 5
Training loss: 0.8405711650848389
Validation loss: 2.1641942858695984

Epoch: 6| Step: 6
Training loss: 0.4801890254020691
Validation loss: 2.1900848150253296

Epoch: 6| Step: 7
Training loss: 1.1798834800720215
Validation loss: 2.158077299594879

Epoch: 6| Step: 8
Training loss: 0.6307500600814819
Validation loss: 2.1723684271176658

Epoch: 6| Step: 9
Training loss: 0.7076683044433594
Validation loss: 2.203887482484182

Epoch: 6| Step: 10
Training loss: 1.394111156463623
Validation loss: 2.207223137219747

Epoch: 6| Step: 11
Training loss: 1.2828458547592163
Validation loss: 2.1386066675186157

Epoch: 6| Step: 12
Training loss: 0.6100901365280151
Validation loss: 2.1841453909873962

Epoch: 6| Step: 13
Training loss: 0.41800808906555176
Validation loss: 2.1165371934572854

Epoch: 472| Step: 0
Training loss: 0.652880072593689
Validation loss: 2.132134040196737

Epoch: 6| Step: 1
Training loss: 0.5743579864501953
Validation loss: 2.1564180652300515

Epoch: 6| Step: 2
Training loss: 0.7462332248687744
Validation loss: 2.1468884150187173

Epoch: 6| Step: 3
Training loss: 0.6837409734725952
Validation loss: 2.146766265233358

Epoch: 6| Step: 4
Training loss: 0.7553766965866089
Validation loss: 2.124328315258026

Epoch: 6| Step: 5
Training loss: 1.30706787109375
Validation loss: 2.1473175684611

Epoch: 6| Step: 6
Training loss: 0.7948524355888367
Validation loss: 2.190129041671753

Epoch: 6| Step: 7
Training loss: 0.9051641821861267
Validation loss: 2.1450875798861184

Epoch: 6| Step: 8
Training loss: 0.7215695381164551
Validation loss: 2.160318593184153

Epoch: 6| Step: 9
Training loss: 0.7916367053985596
Validation loss: 2.132964332898458

Epoch: 6| Step: 10
Training loss: 0.7976059913635254
Validation loss: 2.1565040946006775

Epoch: 6| Step: 11
Training loss: 0.7915350198745728
Validation loss: 2.1522436141967773

Epoch: 6| Step: 12
Training loss: 0.4320327937602997
Validation loss: 2.1519946654637656

Epoch: 6| Step: 13
Training loss: 1.4543192386627197
Validation loss: 2.1889065504074097

Epoch: 473| Step: 0
Training loss: 0.45024827122688293
Validation loss: 2.156940201918284

Epoch: 6| Step: 1
Training loss: 0.7988980412483215
Validation loss: 2.168877283732096

Epoch: 6| Step: 2
Training loss: 0.9201151728630066
Validation loss: 2.1641589601834617

Epoch: 6| Step: 3
Training loss: 0.6760594844818115
Validation loss: 2.1952199737230935

Epoch: 6| Step: 4
Training loss: 1.3863255977630615
Validation loss: 2.151282807191213

Epoch: 6| Step: 5
Training loss: 0.3578624427318573
Validation loss: 2.1707919438680015

Epoch: 6| Step: 6
Training loss: 0.5934555530548096
Validation loss: 2.1784733732541404

Epoch: 6| Step: 7
Training loss: 1.0164353847503662
Validation loss: 2.1419740319252014

Epoch: 6| Step: 8
Training loss: 0.5248926877975464
Validation loss: 2.143610159556071

Epoch: 6| Step: 9
Training loss: 1.3837480545043945
Validation loss: 2.1736284295717874

Epoch: 6| Step: 10
Training loss: 0.5018922090530396
Validation loss: 2.1432109673817954

Epoch: 6| Step: 11
Training loss: 0.5838589668273926
Validation loss: 2.1343703468640647

Epoch: 6| Step: 12
Training loss: 0.6865742206573486
Validation loss: 2.129043618837992

Epoch: 6| Step: 13
Training loss: 1.2589658498764038
Validation loss: 2.16776442527771

Epoch: 474| Step: 0
Training loss: 0.579853892326355
Validation loss: 2.1244168480237327

Epoch: 6| Step: 1
Training loss: 0.7773675322532654
Validation loss: 2.1559844811757407

Epoch: 6| Step: 2
Training loss: 0.7432631850242615
Validation loss: 2.1221428712209067

Epoch: 6| Step: 3
Training loss: 0.5123974680900574
Validation loss: 2.108307957649231

Epoch: 6| Step: 4
Training loss: 0.6526703238487244
Validation loss: 2.1145079731941223

Epoch: 6| Step: 5
Training loss: 0.9080774784088135
Validation loss: 2.0446444948514304

Epoch: 6| Step: 6
Training loss: 0.5836774110794067
Validation loss: 2.0945260922114053

Epoch: 6| Step: 7
Training loss: 0.5914447903633118
Validation loss: 2.0597467621167502

Epoch: 6| Step: 8
Training loss: 0.6943193674087524
Validation loss: 2.1488790114720664

Epoch: 6| Step: 9
Training loss: 0.5441111922264099
Validation loss: 2.1616219679514566

Epoch: 6| Step: 10
Training loss: 1.0723122358322144
Validation loss: 2.143317441145579

Epoch: 6| Step: 11
Training loss: 1.1199877262115479
Validation loss: 2.1544199784596763

Epoch: 6| Step: 12
Training loss: 1.1433014869689941
Validation loss: 2.109007100264231

Epoch: 6| Step: 13
Training loss: 1.4060957431793213
Validation loss: 2.1004083156585693

Epoch: 475| Step: 0
Training loss: 1.1662908792495728
Validation loss: 2.0916731556256614

Epoch: 6| Step: 1
Training loss: 1.281267523765564
Validation loss: 2.1475146611531577

Epoch: 6| Step: 2
Training loss: 1.252314805984497
Validation loss: 2.134980400403341

Epoch: 6| Step: 3
Training loss: 0.7951104640960693
Validation loss: 2.1224565505981445

Epoch: 6| Step: 4
Training loss: 0.6881967186927795
Validation loss: 2.116502106189728

Epoch: 6| Step: 5
Training loss: 1.1745790243148804
Validation loss: 2.1014760533968606

Epoch: 6| Step: 6
Training loss: 0.8849344849586487
Validation loss: 2.1038392186164856

Epoch: 6| Step: 7
Training loss: 0.9984213709831238
Validation loss: 2.0922805666923523

Epoch: 6| Step: 8
Training loss: 0.4151448905467987
Validation loss: 2.1318054795265198

Epoch: 6| Step: 9
Training loss: 0.5913411378860474
Validation loss: 2.077370047569275

Epoch: 6| Step: 10
Training loss: 0.6109894514083862
Validation loss: 2.144336740175883

Epoch: 6| Step: 11
Training loss: 0.400606632232666
Validation loss: 2.162586430708567

Epoch: 6| Step: 12
Training loss: 0.5902040004730225
Validation loss: 2.173477609952291

Epoch: 6| Step: 13
Training loss: 0.9764443635940552
Validation loss: 2.1361518502235413

Epoch: 476| Step: 0
Training loss: 0.46472734212875366
Validation loss: 2.0970520774523416

Epoch: 6| Step: 1
Training loss: 0.6762781143188477
Validation loss: 2.11090624332428

Epoch: 6| Step: 2
Training loss: 0.6931346654891968
Validation loss: 2.1110345125198364

Epoch: 6| Step: 3
Training loss: 0.7163230776786804
Validation loss: 2.183414419492086

Epoch: 6| Step: 4
Training loss: 0.5184121131896973
Validation loss: 2.181506872177124

Epoch: 6| Step: 5
Training loss: 0.534641444683075
Validation loss: 2.1407163540522256

Epoch: 6| Step: 6
Training loss: 0.7678658962249756
Validation loss: 2.1308677792549133

Epoch: 6| Step: 7
Training loss: 0.9116707444190979
Validation loss: 2.1270315249760947

Epoch: 6| Step: 8
Training loss: 0.8691349625587463
Validation loss: 2.1574743588765464

Epoch: 6| Step: 9
Training loss: 1.0728970766067505
Validation loss: 2.1407965222994485

Epoch: 6| Step: 10
Training loss: 1.2194137573242188
Validation loss: 2.154530386130015

Epoch: 6| Step: 11
Training loss: 0.3165006935596466
Validation loss: 2.1719384590784707

Epoch: 6| Step: 12
Training loss: 1.4409453868865967
Validation loss: 2.1656505266825357

Epoch: 6| Step: 13
Training loss: 1.1427671909332275
Validation loss: 2.202203412850698

Epoch: 477| Step: 0
Training loss: 0.7466147541999817
Validation loss: 2.162474830945333

Epoch: 6| Step: 1
Training loss: 0.37668347358703613
Validation loss: 2.1583191553751626

Epoch: 6| Step: 2
Training loss: 0.42888128757476807
Validation loss: 2.128216564655304

Epoch: 6| Step: 3
Training loss: 0.4472101032733917
Validation loss: 2.163674235343933

Epoch: 6| Step: 4
Training loss: 0.8462534546852112
Validation loss: 2.14244278271993

Epoch: 6| Step: 5
Training loss: 0.5825787782669067
Validation loss: 2.20336651802063

Epoch: 6| Step: 6
Training loss: 0.7622586488723755
Validation loss: 2.1583880186080933

Epoch: 6| Step: 7
Training loss: 0.43007493019104004
Validation loss: 2.154126683870951

Epoch: 6| Step: 8
Training loss: 0.953824520111084
Validation loss: 2.1977377931276956

Epoch: 6| Step: 9
Training loss: 1.3468356132507324
Validation loss: 2.2041401465733848

Epoch: 6| Step: 10
Training loss: 1.0949275493621826
Validation loss: 2.1710146069526672

Epoch: 6| Step: 11
Training loss: 0.621417224407196
Validation loss: 2.1490970849990845

Epoch: 6| Step: 12
Training loss: 0.9897124767303467
Validation loss: 2.1474718848864236

Epoch: 6| Step: 13
Training loss: 1.3983454704284668
Validation loss: 2.2010098894437156

Epoch: 478| Step: 0
Training loss: 0.9965362548828125
Validation loss: 2.172759751478831

Epoch: 6| Step: 1
Training loss: 0.5422255992889404
Validation loss: 2.163142760594686

Epoch: 6| Step: 2
Training loss: 0.3891063928604126
Validation loss: 2.1371808846791587

Epoch: 6| Step: 3
Training loss: 0.8475275039672852
Validation loss: 2.127378741900126

Epoch: 6| Step: 4
Training loss: 0.6717923283576965
Validation loss: 2.0899529457092285

Epoch: 6| Step: 5
Training loss: 0.9095918536186218
Validation loss: 2.1195149024327598

Epoch: 6| Step: 6
Training loss: 0.5465090870857239
Validation loss: 2.110684076944987

Epoch: 6| Step: 7
Training loss: 0.7938172817230225
Validation loss: 2.1247307459513345

Epoch: 6| Step: 8
Training loss: 1.0121498107910156
Validation loss: 2.1710317730903625

Epoch: 6| Step: 9
Training loss: 0.8298218250274658
Validation loss: 2.151102066040039

Epoch: 6| Step: 10
Training loss: 1.3796638250350952
Validation loss: 2.1682922641436257

Epoch: 6| Step: 11
Training loss: 0.6053141355514526
Validation loss: 2.18172287940979

Epoch: 6| Step: 12
Training loss: 1.0438947677612305
Validation loss: 2.1187902291615806

Epoch: 6| Step: 13
Training loss: 1.284508228302002
Validation loss: 2.1816603938738504

Epoch: 479| Step: 0
Training loss: 0.9476366639137268
Validation loss: 2.176541566848755

Epoch: 6| Step: 1
Training loss: 1.0096088647842407
Validation loss: 2.2137708266576133

Epoch: 6| Step: 2
Training loss: 0.8483842611312866
Validation loss: 2.1361057360967

Epoch: 6| Step: 3
Training loss: 0.7526249289512634
Validation loss: 2.1615899999936423

Epoch: 6| Step: 4
Training loss: 1.2213127613067627
Validation loss: 2.1956648429234824

Epoch: 6| Step: 5
Training loss: 1.0085196495056152
Validation loss: 2.2017677625020347

Epoch: 6| Step: 6
Training loss: 0.9252662658691406
Validation loss: 2.1884565552075705

Epoch: 6| Step: 7
Training loss: 0.6683058142662048
Validation loss: 2.1442889173825583

Epoch: 6| Step: 8
Training loss: 0.9722253084182739
Validation loss: 2.2154098749160767

Epoch: 6| Step: 9
Training loss: 0.572659969329834
Validation loss: 2.181203047434489

Epoch: 6| Step: 10
Training loss: 0.4300450086593628
Validation loss: 2.1216533184051514

Epoch: 6| Step: 11
Training loss: 0.8760734796524048
Validation loss: 2.147799034913381

Epoch: 6| Step: 12
Training loss: 0.5814000368118286
Validation loss: 2.1914488077163696

Epoch: 6| Step: 13
Training loss: 1.2567558288574219
Validation loss: 2.132733643054962

Epoch: 480| Step: 0
Training loss: 1.0515174865722656
Validation loss: 2.1055840849876404

Epoch: 6| Step: 1
Training loss: 1.1282565593719482
Validation loss: 2.0849584142367044

Epoch: 6| Step: 2
Training loss: 0.4817054271697998
Validation loss: 2.109686295191447

Epoch: 6| Step: 3
Training loss: 0.9002237319946289
Validation loss: 2.102605720361074

Epoch: 6| Step: 4
Training loss: 0.8406983613967896
Validation loss: 2.133750299612681

Epoch: 6| Step: 5
Training loss: 0.7861388325691223
Validation loss: 2.153712749481201

Epoch: 6| Step: 6
Training loss: 0.3298342227935791
Validation loss: 2.1350526014963784

Epoch: 6| Step: 7
Training loss: 0.431667685508728
Validation loss: 2.1914258003234863

Epoch: 6| Step: 8
Training loss: 0.8065913319587708
Validation loss: 2.1400336424509683

Epoch: 6| Step: 9
Training loss: 0.9055837392807007
Validation loss: 2.169018805027008

Epoch: 6| Step: 10
Training loss: 1.0782334804534912
Validation loss: 2.1320263147354126

Epoch: 6| Step: 11
Training loss: 0.8605724573135376
Validation loss: 2.1594083309173584

Epoch: 6| Step: 12
Training loss: 0.6028625965118408
Validation loss: 2.1914158860842385

Epoch: 6| Step: 13
Training loss: 0.9866838455200195
Validation loss: 2.1374942660331726

Epoch: 481| Step: 0
Training loss: 1.0558264255523682
Validation loss: 2.155471444129944

Epoch: 6| Step: 1
Training loss: 1.207606554031372
Validation loss: 2.162592649459839

Epoch: 6| Step: 2
Training loss: 0.8985446095466614
Validation loss: 2.157895803451538

Epoch: 6| Step: 3
Training loss: 0.35455983877182007
Validation loss: 2.17870040734609

Epoch: 6| Step: 4
Training loss: 0.9822007417678833
Validation loss: 2.2203274965286255

Epoch: 6| Step: 5
Training loss: 0.5844836235046387
Validation loss: 2.1704156200091043

Epoch: 6| Step: 6
Training loss: 0.7421327829360962
Validation loss: 2.1892709136009216

Epoch: 6| Step: 7
Training loss: 1.2726399898529053
Validation loss: 2.1980177561442056

Epoch: 6| Step: 8
Training loss: 0.9777712225914001
Validation loss: 2.1839183568954468

Epoch: 6| Step: 9
Training loss: 0.46558648347854614
Validation loss: 2.179453273614248

Epoch: 6| Step: 10
Training loss: 0.6210919618606567
Validation loss: 2.2155852715174356

Epoch: 6| Step: 11
Training loss: 0.8008217811584473
Validation loss: 2.152586261431376

Epoch: 6| Step: 12
Training loss: 0.46782439947128296
Validation loss: 2.20442263285319

Epoch: 6| Step: 13
Training loss: 0.5590430498123169
Validation loss: 2.125831127166748

Epoch: 482| Step: 0
Training loss: 0.9730372428894043
Validation loss: 2.178402543067932

Epoch: 6| Step: 1
Training loss: 0.6835534572601318
Validation loss: 2.1488053798675537

Epoch: 6| Step: 2
Training loss: 1.1189333200454712
Validation loss: 2.1496737599372864

Epoch: 6| Step: 3
Training loss: 0.48803001642227173
Validation loss: 2.168922404448191

Epoch: 6| Step: 4
Training loss: 1.0489425659179688
Validation loss: 2.1107577284177146

Epoch: 6| Step: 5
Training loss: 0.8661677837371826
Validation loss: 2.187447448571523

Epoch: 6| Step: 6
Training loss: 0.5505005717277527
Validation loss: 2.1110498110453286

Epoch: 6| Step: 7
Training loss: 0.778191328048706
Validation loss: 2.1639981667200723

Epoch: 6| Step: 8
Training loss: 0.48707932233810425
Validation loss: 2.144136905670166

Epoch: 6| Step: 9
Training loss: 0.4687036871910095
Validation loss: 2.143146197001139

Epoch: 6| Step: 10
Training loss: 0.9906524419784546
Validation loss: 2.1457502841949463

Epoch: 6| Step: 11
Training loss: 0.6523777842521667
Validation loss: 2.1827708880106607

Epoch: 6| Step: 12
Training loss: 0.8244370818138123
Validation loss: 2.1653926769892373

Epoch: 6| Step: 13
Training loss: 0.9651756882667542
Validation loss: 2.124278426170349

Epoch: 483| Step: 0
Training loss: 0.5714596509933472
Validation loss: 2.1588635643323264

Epoch: 6| Step: 1
Training loss: 0.8608863353729248
Validation loss: 2.2152424653371177

Epoch: 6| Step: 2
Training loss: 0.9693285226821899
Validation loss: 2.1381911436716714

Epoch: 6| Step: 3
Training loss: 0.7701782584190369
Validation loss: 2.115369439125061

Epoch: 6| Step: 4
Training loss: 1.3455013036727905
Validation loss: 2.109469989935557

Epoch: 6| Step: 5
Training loss: 1.1198207139968872
Validation loss: 2.1587960720062256

Epoch: 6| Step: 6
Training loss: 0.9778743982315063
Validation loss: 2.2331042687098184

Epoch: 6| Step: 7
Training loss: 0.9793662428855896
Validation loss: 2.2050136725107827

Epoch: 6| Step: 8
Training loss: 0.6882582306861877
Validation loss: 2.118727723757426

Epoch: 6| Step: 9
Training loss: 0.44962358474731445
Validation loss: 2.120252867539724

Epoch: 6| Step: 10
Training loss: 0.3888758718967438
Validation loss: 2.1335041324297586

Epoch: 6| Step: 11
Training loss: 0.642565131187439
Validation loss: 2.0697584748268127

Epoch: 6| Step: 12
Training loss: 0.6405196189880371
Validation loss: 2.1132246454556785

Epoch: 6| Step: 13
Training loss: 1.2607600688934326
Validation loss: 2.157048443953196

Epoch: 484| Step: 0
Training loss: 0.6326838731765747
Validation loss: 2.190636614958445

Epoch: 6| Step: 1
Training loss: 1.0580558776855469
Validation loss: 2.173769195874532

Epoch: 6| Step: 2
Training loss: 0.5183697938919067
Validation loss: 2.135102947552999

Epoch: 6| Step: 3
Training loss: 0.8479872345924377
Validation loss: 2.141130745410919

Epoch: 6| Step: 4
Training loss: 0.7218669652938843
Validation loss: 2.1496417125066123

Epoch: 6| Step: 5
Training loss: 0.43426576256752014
Validation loss: 2.1223605275154114

Epoch: 6| Step: 6
Training loss: 0.7994670867919922
Validation loss: 2.088454286257426

Epoch: 6| Step: 7
Training loss: 1.3833379745483398
Validation loss: 2.1768542925516763

Epoch: 6| Step: 8
Training loss: 1.1013895273208618
Validation loss: 2.1241937279701233

Epoch: 6| Step: 9
Training loss: 1.1171085834503174
Validation loss: 2.2289153337478638

Epoch: 6| Step: 10
Training loss: 0.4041232168674469
Validation loss: 2.132227818171183

Epoch: 6| Step: 11
Training loss: 0.6780136823654175
Validation loss: 2.13659397761027

Epoch: 6| Step: 12
Training loss: 1.096156358718872
Validation loss: 2.134009818236033

Epoch: 6| Step: 13
Training loss: 0.4286368787288666
Validation loss: 2.1464027961095176

Epoch: 485| Step: 0
Training loss: 0.8515847325325012
Validation loss: 2.181085785230001

Epoch: 6| Step: 1
Training loss: 0.8792961239814758
Validation loss: 2.1672775745391846

Epoch: 6| Step: 2
Training loss: 0.6368839740753174
Validation loss: 2.1395644744237265

Epoch: 6| Step: 3
Training loss: 0.5722817182540894
Validation loss: 2.1615892251332602

Epoch: 6| Step: 4
Training loss: 0.5670411586761475
Validation loss: 2.189005891482035

Epoch: 6| Step: 5
Training loss: 1.3226933479309082
Validation loss: 2.187911033630371

Epoch: 6| Step: 6
Training loss: 1.0405683517456055
Validation loss: 2.10265984137853

Epoch: 6| Step: 7
Training loss: 0.74965500831604
Validation loss: 2.1627511183420816

Epoch: 6| Step: 8
Training loss: 1.07182776927948
Validation loss: 2.0862202644348145

Epoch: 6| Step: 9
Training loss: 0.7796424627304077
Validation loss: 2.1601057251294455

Epoch: 6| Step: 10
Training loss: 0.5614551305770874
Validation loss: 2.1574392120043435

Epoch: 6| Step: 11
Training loss: 0.32339924573898315
Validation loss: 2.1805049777030945

Epoch: 6| Step: 12
Training loss: 1.3858602046966553
Validation loss: 2.1699469685554504

Epoch: 6| Step: 13
Training loss: 0.5610158443450928
Validation loss: 2.2022186517715454

Epoch: 486| Step: 0
Training loss: 0.9327856302261353
Validation loss: 2.1438910961151123

Epoch: 6| Step: 1
Training loss: 1.0184476375579834
Validation loss: 2.1669184962908425

Epoch: 6| Step: 2
Training loss: 0.6367846727371216
Validation loss: 2.1730870405832925

Epoch: 6| Step: 3
Training loss: 0.40806472301483154
Validation loss: 2.1216429471969604

Epoch: 6| Step: 4
Training loss: 1.15966796875
Validation loss: 2.1608469088872275

Epoch: 6| Step: 5
Training loss: 0.7456318140029907
Validation loss: 2.120633920033773

Epoch: 6| Step: 6
Training loss: 0.6365292072296143
Validation loss: 2.137907346089681

Epoch: 6| Step: 7
Training loss: 0.46344608068466187
Validation loss: 2.1366846164067588

Epoch: 6| Step: 8
Training loss: 1.488783836364746
Validation loss: 2.14669277270635

Epoch: 6| Step: 9
Training loss: 1.2026710510253906
Validation loss: 2.1674528320630393

Epoch: 6| Step: 10
Training loss: 0.40762996673583984
Validation loss: 2.145546078681946

Epoch: 6| Step: 11
Training loss: 0.8371138572692871
Validation loss: 2.1156842907269797

Epoch: 6| Step: 12
Training loss: 0.6483009457588196
Validation loss: 2.207998355229696

Epoch: 6| Step: 13
Training loss: 0.4908735156059265
Validation loss: 2.179900070031484

Epoch: 487| Step: 0
Training loss: 0.7016611695289612
Validation loss: 2.2352662285168967

Epoch: 6| Step: 1
Training loss: 0.7509185075759888
Validation loss: 2.2496890823046365

Epoch: 6| Step: 2
Training loss: 1.1822857856750488
Validation loss: 2.235530515511831

Epoch: 6| Step: 3
Training loss: 0.8383851647377014
Validation loss: 2.228345354398092

Epoch: 6| Step: 4
Training loss: 0.4908669590950012
Validation loss: 2.294111410776774

Epoch: 6| Step: 5
Training loss: 1.100232481956482
Validation loss: 2.22897599140803

Epoch: 6| Step: 6
Training loss: 0.9334253668785095
Validation loss: 2.238298853238424

Epoch: 6| Step: 7
Training loss: 0.6553020477294922
Validation loss: 2.2153602639834085

Epoch: 6| Step: 8
Training loss: 0.790069580078125
Validation loss: 2.190068085988363

Epoch: 6| Step: 9
Training loss: 0.5864349007606506
Validation loss: 2.1767250696818032

Epoch: 6| Step: 10
Training loss: 0.5039580464363098
Validation loss: 2.1725841760635376

Epoch: 6| Step: 11
Training loss: 0.5490132570266724
Validation loss: 2.137252926826477

Epoch: 6| Step: 12
Training loss: 0.8282550573348999
Validation loss: 2.117139458656311

Epoch: 6| Step: 13
Training loss: 1.4322396516799927
Validation loss: 2.211771249771118

Epoch: 488| Step: 0
Training loss: 0.6880712509155273
Validation loss: 2.1343213319778442

Epoch: 6| Step: 1
Training loss: 0.8377132415771484
Validation loss: 2.134840408960978

Epoch: 6| Step: 2
Training loss: 0.4236741065979004
Validation loss: 2.1327102979024253

Epoch: 6| Step: 3
Training loss: 0.7502299547195435
Validation loss: 2.2097492019335427

Epoch: 6| Step: 4
Training loss: 1.197333574295044
Validation loss: 2.165216783682505

Epoch: 6| Step: 5
Training loss: 0.9165670275688171
Validation loss: 2.1175421277681985

Epoch: 6| Step: 6
Training loss: 0.7939574718475342
Validation loss: 2.1417378981908164

Epoch: 6| Step: 7
Training loss: 0.8814753293991089
Validation loss: 2.1085742314656577

Epoch: 6| Step: 8
Training loss: 0.9813233613967896
Validation loss: 2.1411977211634317

Epoch: 6| Step: 9
Training loss: 0.5224471092224121
Validation loss: 2.175475279490153

Epoch: 6| Step: 10
Training loss: 0.38459908962249756
Validation loss: 2.1317325035730996

Epoch: 6| Step: 11
Training loss: 0.9001237750053406
Validation loss: 2.222769021987915

Epoch: 6| Step: 12
Training loss: 0.40541404485702515
Validation loss: 2.2317348519961038

Epoch: 6| Step: 13
Training loss: 1.070622444152832
Validation loss: 2.179805119832357

Epoch: 489| Step: 0
Training loss: 1.011888861656189
Validation loss: 2.220707277456919

Epoch: 6| Step: 1
Training loss: 0.5073438286781311
Validation loss: 2.1686936418215432

Epoch: 6| Step: 2
Training loss: 0.849210798740387
Validation loss: 2.177595635255178

Epoch: 6| Step: 3
Training loss: 0.6452093720436096
Validation loss: 2.19053848584493

Epoch: 6| Step: 4
Training loss: 0.39498448371887207
Validation loss: 2.197069466114044

Epoch: 6| Step: 5
Training loss: 0.6501692533493042
Validation loss: 2.162683884302775

Epoch: 6| Step: 6
Training loss: 0.5416637659072876
Validation loss: 2.168183167775472

Epoch: 6| Step: 7
Training loss: 1.3487982749938965
Validation loss: 2.156945745150248

Epoch: 6| Step: 8
Training loss: 0.7137444615364075
Validation loss: 2.17890336116155

Epoch: 6| Step: 9
Training loss: 0.713647186756134
Validation loss: 2.077519655227661

Epoch: 6| Step: 10
Training loss: 0.5419373512268066
Validation loss: 2.1418819626172385

Epoch: 6| Step: 11
Training loss: 0.4839150309562683
Validation loss: 2.1491394440333047

Epoch: 6| Step: 12
Training loss: 0.9927732944488525
Validation loss: 2.1445135871569314

Epoch: 6| Step: 13
Training loss: 0.9477881789207458
Validation loss: 2.139261841773987

Epoch: 490| Step: 0
Training loss: 1.0537869930267334
Validation loss: 2.1444286108016968

Epoch: 6| Step: 1
Training loss: 0.8785401582717896
Validation loss: 2.116801460584005

Epoch: 6| Step: 2
Training loss: 1.3150765895843506
Validation loss: 2.1184128522872925

Epoch: 6| Step: 3
Training loss: 0.42957863211631775
Validation loss: 2.159178078174591

Epoch: 6| Step: 4
Training loss: 0.8050181269645691
Validation loss: 2.1404767632484436

Epoch: 6| Step: 5
Training loss: 1.0515859127044678
Validation loss: 2.1124685804049173

Epoch: 6| Step: 6
Training loss: 0.8191777467727661
Validation loss: 2.167476216952006

Epoch: 6| Step: 7
Training loss: 0.7631099224090576
Validation loss: 2.138846755027771

Epoch: 6| Step: 8
Training loss: 0.7650144100189209
Validation loss: 2.1487218936284385

Epoch: 6| Step: 9
Training loss: 0.30497467517852783
Validation loss: 2.148041089375814

Epoch: 6| Step: 10
Training loss: 0.37601953744888306
Validation loss: 2.172471523284912

Epoch: 6| Step: 11
Training loss: 0.9889334440231323
Validation loss: 2.1434248288472495

Epoch: 6| Step: 12
Training loss: 0.6877880096435547
Validation loss: 2.11931973695755

Epoch: 6| Step: 13
Training loss: 0.33120739459991455
Validation loss: 2.186616897583008

Epoch: 491| Step: 0
Training loss: 0.9167605638504028
Validation loss: 2.137770394484202

Epoch: 6| Step: 1
Training loss: 0.3646106719970703
Validation loss: 2.166923681894938

Epoch: 6| Step: 2
Training loss: 1.3436256647109985
Validation loss: 2.1945390701293945

Epoch: 6| Step: 3
Training loss: 0.6088348627090454
Validation loss: 2.2163033286730447

Epoch: 6| Step: 4
Training loss: 0.7702795267105103
Validation loss: 2.2018217047055564

Epoch: 6| Step: 5
Training loss: 0.6795961856842041
Validation loss: 2.1336522499720254

Epoch: 6| Step: 6
Training loss: 1.0487574338912964
Validation loss: 2.1871207555135093

Epoch: 6| Step: 7
Training loss: 1.1981627941131592
Validation loss: 2.1526693304379783

Epoch: 6| Step: 8
Training loss: 0.7352197766304016
Validation loss: 2.185137609640757

Epoch: 6| Step: 9
Training loss: 0.5569354295730591
Validation loss: 2.147908945878347

Epoch: 6| Step: 10
Training loss: 0.46284952759742737
Validation loss: 2.1833901007970176

Epoch: 6| Step: 11
Training loss: 0.37061068415641785
Validation loss: 2.167226870854696

Epoch: 6| Step: 12
Training loss: 0.7171745300292969
Validation loss: 2.154160976409912

Epoch: 6| Step: 13
Training loss: 1.4687433242797852
Validation loss: 2.130078156789144

Epoch: 492| Step: 0
Training loss: 1.007841944694519
Validation loss: 2.137869735558828

Epoch: 6| Step: 1
Training loss: 0.83059161901474
Validation loss: 2.184105416138967

Epoch: 6| Step: 2
Training loss: 0.6654776334762573
Validation loss: 2.1420337359110513

Epoch: 6| Step: 3
Training loss: 0.6911095380783081
Validation loss: 2.1365174055099487

Epoch: 6| Step: 4
Training loss: 0.4951738715171814
Validation loss: 2.1680091420809426

Epoch: 6| Step: 5
Training loss: 0.592517614364624
Validation loss: 2.199967165788015

Epoch: 6| Step: 6
Training loss: 1.0826432704925537
Validation loss: 2.1691040992736816

Epoch: 6| Step: 7
Training loss: 0.3486916422843933
Validation loss: 2.1038089593251548

Epoch: 6| Step: 8
Training loss: 0.4685841202735901
Validation loss: 2.181689361731211

Epoch: 6| Step: 9
Training loss: 1.0810036659240723
Validation loss: 2.1469953258832297

Epoch: 6| Step: 10
Training loss: 0.5886050462722778
Validation loss: 2.1546902656555176

Epoch: 6| Step: 11
Training loss: 0.9940640330314636
Validation loss: 2.1712292234102883

Epoch: 6| Step: 12
Training loss: 0.6147786378860474
Validation loss: 2.1880701382954917

Epoch: 6| Step: 13
Training loss: 1.0887582302093506
Validation loss: 2.151445209980011

Epoch: 493| Step: 0
Training loss: 0.7721240520477295
Validation loss: 2.174274285634359

Epoch: 6| Step: 1
Training loss: 1.1006548404693604
Validation loss: 2.1442643801371255

Epoch: 6| Step: 2
Training loss: 0.7742775082588196
Validation loss: 2.1571701566378274

Epoch: 6| Step: 3
Training loss: 0.8947387337684631
Validation loss: 2.1867358684539795

Epoch: 6| Step: 4
Training loss: 0.5315356850624084
Validation loss: 2.1168522040049234

Epoch: 6| Step: 5
Training loss: 0.3527548015117645
Validation loss: 2.177705446879069

Epoch: 6| Step: 6
Training loss: 1.084945797920227
Validation loss: 2.1693394780158997

Epoch: 6| Step: 7
Training loss: 1.7401777505874634
Validation loss: 2.1133304039637246

Epoch: 6| Step: 8
Training loss: 0.6221217513084412
Validation loss: 2.1607155799865723

Epoch: 6| Step: 9
Training loss: 0.4476533532142639
Validation loss: 2.166505992412567

Epoch: 6| Step: 10
Training loss: 0.42048922181129456
Validation loss: 2.1852362553278604

Epoch: 6| Step: 11
Training loss: 0.6612550616264343
Validation loss: 2.2007458806037903

Epoch: 6| Step: 12
Training loss: 0.5456879138946533
Validation loss: 2.161359747250875

Epoch: 6| Step: 13
Training loss: 0.6013445854187012
Validation loss: 2.1988155444463096

Epoch: 494| Step: 0
Training loss: 0.7134354114532471
Validation loss: 2.197045624256134

Epoch: 6| Step: 1
Training loss: 0.4219540059566498
Validation loss: 2.15552427371343

Epoch: 6| Step: 2
Training loss: 0.5862405300140381
Validation loss: 2.149005730946859

Epoch: 6| Step: 3
Training loss: 1.00556480884552
Validation loss: 2.1908832788467407

Epoch: 6| Step: 4
Training loss: 0.9161800146102905
Validation loss: 2.1708627144495645

Epoch: 6| Step: 5
Training loss: 0.5935261249542236
Validation loss: 2.1167892018953958

Epoch: 6| Step: 6
Training loss: 1.0780237913131714
Validation loss: 2.148724913597107

Epoch: 6| Step: 7
Training loss: 1.259803295135498
Validation loss: 2.167268693447113

Epoch: 6| Step: 8
Training loss: 0.6649055480957031
Validation loss: 2.1274908582369485

Epoch: 6| Step: 9
Training loss: 0.7236015796661377
Validation loss: 2.1551836927731833

Epoch: 6| Step: 10
Training loss: 1.2788596153259277
Validation loss: 2.1495704849561057

Epoch: 6| Step: 11
Training loss: 0.9580810070037842
Validation loss: 2.1790409088134766

Epoch: 6| Step: 12
Training loss: 0.6412174701690674
Validation loss: 2.228144645690918

Epoch: 6| Step: 13
Training loss: 1.1047343015670776
Validation loss: 2.187391698360443

Epoch: 495| Step: 0
Training loss: 0.5741532444953918
Validation loss: 2.2086398204167685

Epoch: 6| Step: 1
Training loss: 0.607354462146759
Validation loss: 2.165455162525177

Epoch: 6| Step: 2
Training loss: 0.49607619643211365
Validation loss: 2.1458964943885803

Epoch: 6| Step: 3
Training loss: 0.8171365857124329
Validation loss: 2.1816904544830322

Epoch: 6| Step: 4
Training loss: 1.0011671781539917
Validation loss: 2.1699782013893127

Epoch: 6| Step: 5
Training loss: 0.920708417892456
Validation loss: 2.2004165649414062

Epoch: 6| Step: 6
Training loss: 0.29635053873062134
Validation loss: 2.165266672770182

Epoch: 6| Step: 7
Training loss: 0.3945426344871521
Validation loss: 2.20571231842041

Epoch: 6| Step: 8
Training loss: 0.9636658430099487
Validation loss: 2.1413357059160867

Epoch: 6| Step: 9
Training loss: 1.582506775856018
Validation loss: 2.1573702295621238

Epoch: 6| Step: 10
Training loss: 1.1228654384613037
Validation loss: 2.155220886071523

Epoch: 6| Step: 11
Training loss: 0.5911399722099304
Validation loss: 2.145641028881073

Epoch: 6| Step: 12
Training loss: 0.6528829336166382
Validation loss: 2.1385615269343057

Epoch: 6| Step: 13
Training loss: 0.6580437421798706
Validation loss: 2.1130990783373513

Epoch: 496| Step: 0
Training loss: 0.8618484735488892
Validation loss: 2.1592477560043335

Epoch: 6| Step: 1
Training loss: 0.5429115891456604
Validation loss: 2.1286482413609824

Epoch: 6| Step: 2
Training loss: 0.9359053373336792
Validation loss: 2.0867971976598105

Epoch: 6| Step: 3
Training loss: 0.7040606737136841
Validation loss: 2.1013612945874534

Epoch: 6| Step: 4
Training loss: 1.048356533050537
Validation loss: 2.0794584353764853

Epoch: 6| Step: 5
Training loss: 0.5842273235321045
Validation loss: 2.096330205599467

Epoch: 6| Step: 6
Training loss: 0.7913164496421814
Validation loss: 2.111372470855713

Epoch: 6| Step: 7
Training loss: 0.7679109573364258
Validation loss: 2.090088884035746

Epoch: 6| Step: 8
Training loss: 1.0813473463058472
Validation loss: 2.1507275501887

Epoch: 6| Step: 9
Training loss: 0.8262941241264343
Validation loss: 2.083021342754364

Epoch: 6| Step: 10
Training loss: 0.5467094779014587
Validation loss: 2.151181221008301

Epoch: 6| Step: 11
Training loss: 0.34033316373825073
Validation loss: 2.1781378785769143

Epoch: 6| Step: 12
Training loss: 0.6324816942214966
Validation loss: 2.132120927174886

Epoch: 6| Step: 13
Training loss: 1.141140341758728
Validation loss: 2.1607989072799683

Epoch: 497| Step: 0
Training loss: 0.6149171590805054
Validation loss: 2.177306135495504

Epoch: 6| Step: 1
Training loss: 0.5725104212760925
Validation loss: 2.1144285798072815

Epoch: 6| Step: 2
Training loss: 0.690268874168396
Validation loss: 2.19305012623469

Epoch: 6| Step: 3
Training loss: 1.4629383087158203
Validation loss: 2.146528422832489

Epoch: 6| Step: 4
Training loss: 0.31285780668258667
Validation loss: 2.1861623922983804

Epoch: 6| Step: 5
Training loss: 0.6745361685752869
Validation loss: 2.1434955398241677

Epoch: 6| Step: 6
Training loss: 0.3534677028656006
Validation loss: 2.1828768054644265

Epoch: 6| Step: 7
Training loss: 0.5087476372718811
Validation loss: 2.1531293392181396

Epoch: 6| Step: 8
Training loss: 0.39729687571525574
Validation loss: 2.1917285124460855

Epoch: 6| Step: 9
Training loss: 0.6019942760467529
Validation loss: 2.1675527493158975

Epoch: 6| Step: 10
Training loss: 1.1216602325439453
Validation loss: 2.150950769583384

Epoch: 6| Step: 11
Training loss: 0.7786508202552795
Validation loss: 2.1639785170555115

Epoch: 6| Step: 12
Training loss: 0.9018600583076477
Validation loss: 2.151400903860728

Epoch: 6| Step: 13
Training loss: 1.3322703838348389
Validation loss: 2.1739808122316995

Epoch: 498| Step: 0
Training loss: 0.6539015769958496
Validation loss: 2.1536821126937866

Epoch: 6| Step: 1
Training loss: 0.8261343836784363
Validation loss: 2.1215399503707886

Epoch: 6| Step: 2
Training loss: 0.4914076328277588
Validation loss: 2.138727287451426

Epoch: 6| Step: 3
Training loss: 0.40650513768196106
Validation loss: 2.0952778855959573

Epoch: 6| Step: 4
Training loss: 0.9169793725013733
Validation loss: 2.1243478258450827

Epoch: 6| Step: 5
Training loss: 1.0072355270385742
Validation loss: 2.1446746587753296

Epoch: 6| Step: 6
Training loss: 1.1185877323150635
Validation loss: 2.179211219151815

Epoch: 6| Step: 7
Training loss: 1.3099372386932373
Validation loss: 2.1605194211006165

Epoch: 6| Step: 8
Training loss: 0.6460185050964355
Validation loss: 2.1576110124588013

Epoch: 6| Step: 9
Training loss: 0.4067837595939636
Validation loss: 2.1788617769877114

Epoch: 6| Step: 10
Training loss: 0.3707994818687439
Validation loss: 2.1947968204816184

Epoch: 6| Step: 11
Training loss: 0.740007758140564
Validation loss: 2.1890253027280173

Epoch: 6| Step: 12
Training loss: 0.833991289138794
Validation loss: 2.102026879787445

Epoch: 6| Step: 13
Training loss: 0.7580878734588623
Validation loss: 2.2140076955159507

Epoch: 499| Step: 0
Training loss: 1.1323310136795044
Validation loss: 2.2000094850858054

Epoch: 6| Step: 1
Training loss: 0.5239233374595642
Validation loss: 2.1385132670402527

Epoch: 6| Step: 2
Training loss: 0.2090531587600708
Validation loss: 2.169567088286082

Epoch: 6| Step: 3
Training loss: 1.1242436170578003
Validation loss: 2.2013450860977173

Epoch: 6| Step: 4
Training loss: 0.8221431374549866
Validation loss: 2.2382949590682983

Epoch: 6| Step: 5
Training loss: 0.799528956413269
Validation loss: 2.227738380432129

Epoch: 6| Step: 6
Training loss: 0.7532487511634827
Validation loss: 2.136220475037893

Epoch: 6| Step: 7
Training loss: 0.3736087679862976
Validation loss: 2.175703763961792

Epoch: 6| Step: 8
Training loss: 1.3796874284744263
Validation loss: 2.1903879841168723

Epoch: 6| Step: 9
Training loss: 0.5709108114242554
Validation loss: 2.1668427189191184

Epoch: 6| Step: 10
Training loss: 0.533214807510376
Validation loss: 2.1275749802589417

Epoch: 6| Step: 11
Training loss: 0.5190126895904541
Validation loss: 2.248095452785492

Epoch: 6| Step: 12
Training loss: 1.3248472213745117
Validation loss: 2.182690660158793

Epoch: 6| Step: 13
Training loss: 0.4826478362083435
Validation loss: 2.202567478020986

Epoch: 500| Step: 0
Training loss: 0.8336231708526611
Validation loss: 2.171813408533732

Epoch: 6| Step: 1
Training loss: 0.8515012264251709
Validation loss: 2.194609781106313

Epoch: 6| Step: 2
Training loss: 0.4550165832042694
Validation loss: 2.210293412208557

Epoch: 6| Step: 3
Training loss: 0.471011221408844
Validation loss: 2.189941962560018

Epoch: 6| Step: 4
Training loss: 0.4869026243686676
Validation loss: 2.1908822456995645

Epoch: 6| Step: 5
Training loss: 1.0308234691619873
Validation loss: 2.149619142214457

Epoch: 6| Step: 6
Training loss: 0.9616113305091858
Validation loss: 2.1769643227259317

Epoch: 6| Step: 7
Training loss: 0.9097870588302612
Validation loss: 2.189459760983785

Epoch: 6| Step: 8
Training loss: 0.3709586262702942
Validation loss: 2.154854973157247

Epoch: 6| Step: 9
Training loss: 1.3775932788848877
Validation loss: 2.176215092341105

Epoch: 6| Step: 10
Training loss: 0.6521667242050171
Validation loss: 2.1197150349617004

Epoch: 6| Step: 11
Training loss: 0.5376586318016052
Validation loss: 2.1259333888689675

Epoch: 6| Step: 12
Training loss: 0.5545529127120972
Validation loss: 2.1786234974861145

Epoch: 6| Step: 13
Training loss: 0.9866931438446045
Validation loss: 2.181406398614248

Epoch: 501| Step: 0
Training loss: 0.399988055229187
Validation loss: 2.1520434617996216

Epoch: 6| Step: 1
Training loss: 0.7286221981048584
Validation loss: 2.158632000287374

Epoch: 6| Step: 2
Training loss: 0.6707381010055542
Validation loss: 2.176970064640045

Epoch: 6| Step: 3
Training loss: 0.7193410396575928
Validation loss: 2.0901951789855957

Epoch: 6| Step: 4
Training loss: 0.4511813521385193
Validation loss: 2.1864595810572305

Epoch: 6| Step: 5
Training loss: 0.4426683783531189
Validation loss: 2.1021389762560525

Epoch: 6| Step: 6
Training loss: 0.6877890825271606
Validation loss: 2.1440505981445312

Epoch: 6| Step: 7
Training loss: 0.4945618510246277
Validation loss: 2.1911883552869162

Epoch: 6| Step: 8
Training loss: 1.1587148904800415
Validation loss: 2.1869725982348123

Epoch: 6| Step: 9
Training loss: 1.1395421028137207
Validation loss: 2.17370597521464

Epoch: 6| Step: 10
Training loss: 0.882889986038208
Validation loss: 2.1142098108927407

Epoch: 6| Step: 11
Training loss: 0.7409049272537231
Validation loss: 2.1895524859428406

Epoch: 6| Step: 12
Training loss: 0.6324781179428101
Validation loss: 2.1320777336756387

Epoch: 6| Step: 13
Training loss: 1.034196376800537
Validation loss: 2.178815245628357

Epoch: 502| Step: 0
Training loss: 0.6862413883209229
Validation loss: 2.1812974015871682

Epoch: 6| Step: 1
Training loss: 0.42996305227279663
Validation loss: 2.156676014264425

Epoch: 6| Step: 2
Training loss: 1.3660637140274048
Validation loss: 2.202920079231262

Epoch: 6| Step: 3
Training loss: 0.43718016147613525
Validation loss: 2.2156840165456138

Epoch: 6| Step: 4
Training loss: 0.6408421993255615
Validation loss: 2.1942973732948303

Epoch: 6| Step: 5
Training loss: 0.9667963981628418
Validation loss: 2.1525460481643677

Epoch: 6| Step: 6
Training loss: 0.8520569205284119
Validation loss: 2.1934908827145896

Epoch: 6| Step: 7
Training loss: 0.5465967655181885
Validation loss: 2.216019550959269

Epoch: 6| Step: 8
Training loss: 0.7405014634132385
Validation loss: 2.1690919995307922

Epoch: 6| Step: 9
Training loss: 1.1303763389587402
Validation loss: 2.1452659964561462

Epoch: 6| Step: 10
Training loss: 0.9369407296180725
Validation loss: 2.1326261361440024

Epoch: 6| Step: 11
Training loss: 0.5223620533943176
Validation loss: 2.1277217666308084

Epoch: 6| Step: 12
Training loss: 0.8062736988067627
Validation loss: 2.1254799564679465

Epoch: 6| Step: 13
Training loss: 0.3730737566947937
Validation loss: 2.138859192530314

Epoch: 503| Step: 0
Training loss: 0.38547971844673157
Validation loss: 2.1332790652910867

Epoch: 6| Step: 1
Training loss: 0.5711381435394287
Validation loss: 2.160017748673757

Epoch: 6| Step: 2
Training loss: 1.8216755390167236
Validation loss: 2.183571219444275

Epoch: 6| Step: 3
Training loss: 0.6358814835548401
Validation loss: 2.1545875867207847

Epoch: 6| Step: 4
Training loss: 0.8429630994796753
Validation loss: 2.1733872493108115

Epoch: 6| Step: 5
Training loss: 0.7035731077194214
Validation loss: 2.1527252991994223

Epoch: 6| Step: 6
Training loss: 0.5898240804672241
Validation loss: 2.1527985533078513

Epoch: 6| Step: 7
Training loss: 1.1824054718017578
Validation loss: 2.1804007291793823

Epoch: 6| Step: 8
Training loss: 0.7056282162666321
Validation loss: 2.14294296503067

Epoch: 6| Step: 9
Training loss: 0.47238388657569885
Validation loss: 2.1703749299049377

Epoch: 6| Step: 10
Training loss: 1.305163860321045
Validation loss: 2.17012091477712

Epoch: 6| Step: 11
Training loss: 0.9727405309677124
Validation loss: 2.1773972312609353

Epoch: 6| Step: 12
Training loss: 0.9289397597312927
Validation loss: 2.1177615920702615

Epoch: 6| Step: 13
Training loss: 0.7385430335998535
Validation loss: 2.0945245027542114

Epoch: 504| Step: 0
Training loss: 0.7253420352935791
Validation loss: 2.1975871523221335

Epoch: 6| Step: 1
Training loss: 1.621490240097046
Validation loss: 2.197878619035085

Epoch: 6| Step: 2
Training loss: 0.9458609819412231
Validation loss: 2.2310936053593955

Epoch: 6| Step: 3
Training loss: 0.5260601043701172
Validation loss: 2.226977268854777

Epoch: 6| Step: 4
Training loss: 0.8389961123466492
Validation loss: 2.247526208559672

Epoch: 6| Step: 5
Training loss: 1.0249407291412354
Validation loss: 2.1890454093615213

Epoch: 6| Step: 6
Training loss: 0.6170181632041931
Validation loss: 2.193675180276235

Epoch: 6| Step: 7
Training loss: 0.40414777398109436
Validation loss: 2.2423030138015747

Epoch: 6| Step: 8
Training loss: 0.9826033711433411
Validation loss: 2.192162831624349

Epoch: 6| Step: 9
Training loss: 0.5310686826705933
Validation loss: 2.1096958120663962

Epoch: 6| Step: 10
Training loss: 1.2816287279129028
Validation loss: 2.177658518155416

Epoch: 6| Step: 11
Training loss: 0.4386279582977295
Validation loss: 2.1803457140922546

Epoch: 6| Step: 12
Training loss: 0.9253172874450684
Validation loss: 2.0993027885754905

Epoch: 6| Step: 13
Training loss: 0.6241325736045837
Validation loss: 2.1134968996047974

Epoch: 505| Step: 0
Training loss: 0.4868812561035156
Validation loss: 2.101028541723887

Epoch: 6| Step: 1
Training loss: 0.6066805720329285
Validation loss: 2.1265270709991455

Epoch: 6| Step: 2
Training loss: 0.7847496271133423
Validation loss: 2.0865850249926248

Epoch: 6| Step: 3
Training loss: 0.3920702636241913
Validation loss: 2.1401500701904297

Epoch: 6| Step: 4
Training loss: 0.5880320072174072
Validation loss: 2.1046416759490967

Epoch: 6| Step: 5
Training loss: 0.8161261081695557
Validation loss: 2.083901902039846

Epoch: 6| Step: 6
Training loss: 0.7948727011680603
Validation loss: 2.1159339348475137

Epoch: 6| Step: 7
Training loss: 1.168285846710205
Validation loss: 2.1266473730405173

Epoch: 6| Step: 8
Training loss: 0.6066716909408569
Validation loss: 2.082886834939321

Epoch: 6| Step: 9
Training loss: 0.8571408987045288
Validation loss: 2.136915624141693

Epoch: 6| Step: 10
Training loss: 0.7302639484405518
Validation loss: 2.0921720067660012

Epoch: 6| Step: 11
Training loss: 1.0688278675079346
Validation loss: 2.1193296909332275

Epoch: 6| Step: 12
Training loss: 1.084435224533081
Validation loss: 2.091609001159668

Epoch: 6| Step: 13
Training loss: 0.46129658818244934
Validation loss: 2.127617359161377

Epoch: 506| Step: 0
Training loss: 0.7849816083908081
Validation loss: 2.1552364826202393

Epoch: 6| Step: 1
Training loss: 0.558260977268219
Validation loss: 2.14263379573822

Epoch: 6| Step: 2
Training loss: 0.9777204990386963
Validation loss: 2.1298138896624246

Epoch: 6| Step: 3
Training loss: 0.8120635747909546
Validation loss: 2.12850687901179

Epoch: 6| Step: 4
Training loss: 1.281867265701294
Validation loss: 2.14602263768514

Epoch: 6| Step: 5
Training loss: 0.5430380702018738
Validation loss: 2.1611182490984597

Epoch: 6| Step: 6
Training loss: 0.34858885407447815
Validation loss: 2.1406901677449546

Epoch: 6| Step: 7
Training loss: 0.3293468654155731
Validation loss: 2.149782379468282

Epoch: 6| Step: 8
Training loss: 0.7592633366584778
Validation loss: 2.0743499994277954

Epoch: 6| Step: 9
Training loss: 0.8556439876556396
Validation loss: 2.1412168542544046

Epoch: 6| Step: 10
Training loss: 0.7439587116241455
Validation loss: 2.1656227707862854

Epoch: 6| Step: 11
Training loss: 0.5327627658843994
Validation loss: 2.158368726571401

Epoch: 6| Step: 12
Training loss: 0.5899131894111633
Validation loss: 2.17875345547994

Epoch: 6| Step: 13
Training loss: 0.7911220192909241
Validation loss: 2.16557647784551

Epoch: 507| Step: 0
Training loss: 0.48600393533706665
Validation loss: 2.2224008242289224

Epoch: 6| Step: 1
Training loss: 0.6232228875160217
Validation loss: 2.1621439854303994

Epoch: 6| Step: 2
Training loss: 0.5750390887260437
Validation loss: 2.2062682112058005

Epoch: 6| Step: 3
Training loss: 0.6772937774658203
Validation loss: 2.1496222615242004

Epoch: 6| Step: 4
Training loss: 0.6186025738716125
Validation loss: 2.1918713450431824

Epoch: 6| Step: 5
Training loss: 1.0221532583236694
Validation loss: 2.1339848240216575

Epoch: 6| Step: 6
Training loss: 1.0269076824188232
Validation loss: 2.1368364095687866

Epoch: 6| Step: 7
Training loss: 0.2867623567581177
Validation loss: 2.1836910049120584

Epoch: 6| Step: 8
Training loss: 1.0248652696609497
Validation loss: 2.138726810614268

Epoch: 6| Step: 9
Training loss: 1.142971158027649
Validation loss: 2.130660434563955

Epoch: 6| Step: 10
Training loss: 1.0440837144851685
Validation loss: 2.129587014516195

Epoch: 6| Step: 11
Training loss: 0.7142876386642456
Validation loss: 2.168429692586263

Epoch: 6| Step: 12
Training loss: 0.6312386989593506
Validation loss: 2.1346038778622947

Epoch: 6| Step: 13
Training loss: 0.4363378882408142
Validation loss: 2.1307057539621987

Epoch: 508| Step: 0
Training loss: 0.9249013662338257
Validation loss: 2.1392419735590615

Epoch: 6| Step: 1
Training loss: 0.9380487203598022
Validation loss: 2.1624467372894287

Epoch: 6| Step: 2
Training loss: 0.9580651521682739
Validation loss: 2.1679450472195945

Epoch: 6| Step: 3
Training loss: 1.240707278251648
Validation loss: 2.191697080930074

Epoch: 6| Step: 4
Training loss: 0.42908746004104614
Validation loss: 2.1673731406529746

Epoch: 6| Step: 5
Training loss: 0.17559167742729187
Validation loss: 2.175897558530172

Epoch: 6| Step: 6
Training loss: 0.5912303924560547
Validation loss: 2.1950397888819375

Epoch: 6| Step: 7
Training loss: 0.5473893880844116
Validation loss: 2.2109394868214927

Epoch: 6| Step: 8
Training loss: 0.4964268207550049
Validation loss: 2.1735745072364807

Epoch: 6| Step: 9
Training loss: 0.6948032975196838
Validation loss: 2.179198662439982

Epoch: 6| Step: 10
Training loss: 0.48690885305404663
Validation loss: 2.1757121880849204

Epoch: 6| Step: 11
Training loss: 1.0988929271697998
Validation loss: 2.191897432009379

Epoch: 6| Step: 12
Training loss: 0.41054949164390564
Validation loss: 2.126851419607798

Epoch: 6| Step: 13
Training loss: 0.6539446115493774
Validation loss: 2.1387587785720825

Epoch: 509| Step: 0
Training loss: 0.6587276458740234
Validation loss: 2.1444997787475586

Epoch: 6| Step: 1
Training loss: 0.8981713652610779
Validation loss: 2.1390852133433023

Epoch: 6| Step: 2
Training loss: 0.5788376927375793
Validation loss: 2.0998725096384683

Epoch: 6| Step: 3
Training loss: 0.5540388822555542
Validation loss: 2.1699384252230325

Epoch: 6| Step: 4
Training loss: 0.6577621698379517
Validation loss: 2.103943645954132

Epoch: 6| Step: 5
Training loss: 0.45352843403816223
Validation loss: 2.130719006061554

Epoch: 6| Step: 6
Training loss: 0.6698504686355591
Validation loss: 2.1175363063812256

Epoch: 6| Step: 7
Training loss: 1.1617070436477661
Validation loss: 2.164552470048269

Epoch: 6| Step: 8
Training loss: 0.8640817403793335
Validation loss: 2.137387235959371

Epoch: 6| Step: 9
Training loss: 0.5560464859008789
Validation loss: 2.123161514600118

Epoch: 6| Step: 10
Training loss: 0.4966755509376526
Validation loss: 2.0914566914240518

Epoch: 6| Step: 11
Training loss: 0.5644775032997131
Validation loss: 2.1421542962392173

Epoch: 6| Step: 12
Training loss: 1.4238333702087402
Validation loss: 2.1403764486312866

Epoch: 6| Step: 13
Training loss: 0.4916130304336548
Validation loss: 2.137222150961558

Epoch: 510| Step: 0
Training loss: 1.203973412513733
Validation loss: 2.1284024318059287

Epoch: 6| Step: 1
Training loss: 0.5675678849220276
Validation loss: 2.0936833222707114

Epoch: 6| Step: 2
Training loss: 0.9511806964874268
Validation loss: 2.1197781364123025

Epoch: 6| Step: 3
Training loss: 0.6898888349533081
Validation loss: 2.144350985685984

Epoch: 6| Step: 4
Training loss: 0.8605009913444519
Validation loss: 2.124589681625366

Epoch: 6| Step: 5
Training loss: 0.40313720703125
Validation loss: 2.1064869364102683

Epoch: 6| Step: 6
Training loss: 0.39595991373062134
Validation loss: 2.1154986222585044

Epoch: 6| Step: 7
Training loss: 1.0244507789611816
Validation loss: 2.1404468019803367

Epoch: 6| Step: 8
Training loss: 0.6902377605438232
Validation loss: 2.105125447114309

Epoch: 6| Step: 9
Training loss: 0.37200236320495605
Validation loss: 2.1179115772247314

Epoch: 6| Step: 10
Training loss: 0.6497652530670166
Validation loss: 2.127574324607849

Epoch: 6| Step: 11
Training loss: 0.8348698019981384
Validation loss: 2.0971024433771768

Epoch: 6| Step: 12
Training loss: 0.8024958968162537
Validation loss: 2.159230589866638

Epoch: 6| Step: 13
Training loss: 0.6112173795700073
Validation loss: 2.0643670360247293

Epoch: 511| Step: 0
Training loss: 0.7188341617584229
Validation loss: 2.147331873575846

Epoch: 6| Step: 1
Training loss: 1.0086479187011719
Validation loss: 2.1178110440572104

Epoch: 6| Step: 2
Training loss: 0.33908921480178833
Validation loss: 2.1275015672047934

Epoch: 6| Step: 3
Training loss: 0.5836257934570312
Validation loss: 2.1324693163235984

Epoch: 6| Step: 4
Training loss: 0.4577696621417999
Validation loss: 2.1059210300445557

Epoch: 6| Step: 5
Training loss: 0.9259886741638184
Validation loss: 2.142320454120636

Epoch: 6| Step: 6
Training loss: 0.7562370300292969
Validation loss: 2.1255125602086387

Epoch: 6| Step: 7
Training loss: 0.7392328977584839
Validation loss: 2.133039951324463

Epoch: 6| Step: 8
Training loss: 0.6915960311889648
Validation loss: 2.174341162045797

Epoch: 6| Step: 9
Training loss: 0.5102888941764832
Validation loss: 2.151173750559489

Epoch: 6| Step: 10
Training loss: 0.6087747812271118
Validation loss: 2.160320440928141

Epoch: 6| Step: 11
Training loss: 0.48044896125793457
Validation loss: 2.1642282009124756

Epoch: 6| Step: 12
Training loss: 1.0185492038726807
Validation loss: 2.136432925860087

Epoch: 6| Step: 13
Training loss: 0.8185552358627319
Validation loss: 2.1911885142326355

Epoch: 512| Step: 0
Training loss: 0.491030752658844
Validation loss: 2.1212926308314004

Epoch: 6| Step: 1
Training loss: 1.0576179027557373
Validation loss: 2.177839994430542

Epoch: 6| Step: 2
Training loss: 1.3767850399017334
Validation loss: 2.169043997923533

Epoch: 6| Step: 3
Training loss: 0.4891246259212494
Validation loss: 2.1582560936609902

Epoch: 6| Step: 4
Training loss: 0.9403004050254822
Validation loss: 2.143623193105062

Epoch: 6| Step: 5
Training loss: 0.3824160695075989
Validation loss: 2.0960652828216553

Epoch: 6| Step: 6
Training loss: 0.6546095013618469
Validation loss: 2.0947973132133484

Epoch: 6| Step: 7
Training loss: 0.41057172417640686
Validation loss: 2.060368299484253

Epoch: 6| Step: 8
Training loss: 0.5942961573600769
Validation loss: 2.075741151968638

Epoch: 6| Step: 9
Training loss: 0.7208802700042725
Validation loss: 2.100639979044596

Epoch: 6| Step: 10
Training loss: 0.908234179019928
Validation loss: 2.095140298207601

Epoch: 6| Step: 11
Training loss: 0.9955717325210571
Validation loss: 2.1354923248291016

Epoch: 6| Step: 12
Training loss: 0.4878060221672058
Validation loss: 2.119460860888163

Epoch: 6| Step: 13
Training loss: 0.5247587561607361
Validation loss: 2.0823975801467896

Epoch: 513| Step: 0
Training loss: 1.2163922786712646
Validation loss: 2.1662245194117227

Epoch: 6| Step: 1
Training loss: 0.36463862657546997
Validation loss: 2.1291489203770957

Epoch: 6| Step: 2
Training loss: 0.4560510814189911
Validation loss: 2.1557137767473855

Epoch: 6| Step: 3
Training loss: 0.5027703046798706
Validation loss: 2.1793483893076577

Epoch: 6| Step: 4
Training loss: 0.5447128415107727
Validation loss: 2.141843060652415

Epoch: 6| Step: 5
Training loss: 0.9427355527877808
Validation loss: 2.110003491242727

Epoch: 6| Step: 6
Training loss: 0.42631205916404724
Validation loss: 2.1619508862495422

Epoch: 6| Step: 7
Training loss: 0.7983661890029907
Validation loss: 2.162027736504873

Epoch: 6| Step: 8
Training loss: 1.036973476409912
Validation loss: 2.1382739345232644

Epoch: 6| Step: 9
Training loss: 0.8550913333892822
Validation loss: 2.2132924596468606

Epoch: 6| Step: 10
Training loss: 0.33552610874176025
Validation loss: 2.1879776318868003

Epoch: 6| Step: 11
Training loss: 0.5186810493469238
Validation loss: 2.13747767607371

Epoch: 6| Step: 12
Training loss: 0.6809296011924744
Validation loss: 2.1880162954330444

Epoch: 6| Step: 13
Training loss: 0.9802521467208862
Validation loss: 2.1387886206309

Epoch: 514| Step: 0
Training loss: 0.6740971803665161
Validation loss: 2.154872934023539

Epoch: 6| Step: 1
Training loss: 0.33122768998146057
Validation loss: 2.2085496187210083

Epoch: 6| Step: 2
Training loss: 0.8208669424057007
Validation loss: 2.134623646736145

Epoch: 6| Step: 3
Training loss: 0.33851659297943115
Validation loss: 2.130949298540751

Epoch: 6| Step: 4
Training loss: 0.7656144499778748
Validation loss: 2.1123902996381125

Epoch: 6| Step: 5
Training loss: 0.6073942184448242
Validation loss: 2.1482245524724326

Epoch: 6| Step: 6
Training loss: 1.1209626197814941
Validation loss: 2.190376619497935

Epoch: 6| Step: 7
Training loss: 0.4427270293235779
Validation loss: 2.0954825282096863

Epoch: 6| Step: 8
Training loss: 0.9965271353721619
Validation loss: 2.186225434144338

Epoch: 6| Step: 9
Training loss: 0.4241199791431427
Validation loss: 2.191614886124929

Epoch: 6| Step: 10
Training loss: 0.8977386355400085
Validation loss: 2.1863669753074646

Epoch: 6| Step: 11
Training loss: 0.8401815891265869
Validation loss: 2.1290650765101113

Epoch: 6| Step: 12
Training loss: 0.6365704536437988
Validation loss: 2.144110163052877

Epoch: 6| Step: 13
Training loss: 0.5046118497848511
Validation loss: 2.179742693901062

Epoch: 515| Step: 0
Training loss: 0.4638882875442505
Validation loss: 2.211312492688497

Epoch: 6| Step: 1
Training loss: 0.7364915013313293
Validation loss: 2.165074606736501

Epoch: 6| Step: 2
Training loss: 0.27147409319877625
Validation loss: 2.1635491649309793

Epoch: 6| Step: 3
Training loss: 0.5869696736335754
Validation loss: 2.12624462445577

Epoch: 6| Step: 4
Training loss: 0.7217321395874023
Validation loss: 2.116595188776652

Epoch: 6| Step: 5
Training loss: 0.401139497756958
Validation loss: 2.067924161752065

Epoch: 6| Step: 6
Training loss: 1.1556057929992676
Validation loss: 2.0697266856829324

Epoch: 6| Step: 7
Training loss: 1.1886491775512695
Validation loss: 2.1458659966786704

Epoch: 6| Step: 8
Training loss: 0.39837828278541565
Validation loss: 2.0969671408335366

Epoch: 6| Step: 9
Training loss: 0.8242558240890503
Validation loss: 2.2141538858413696

Epoch: 6| Step: 10
Training loss: 0.9005708694458008
Validation loss: 2.1821111838022866

Epoch: 6| Step: 11
Training loss: 0.6745132207870483
Validation loss: 2.162662843863169

Epoch: 6| Step: 12
Training loss: 0.8696143627166748
Validation loss: 2.1725452740987143

Epoch: 6| Step: 13
Training loss: 1.1197524070739746
Validation loss: 2.2070847153663635

Epoch: 516| Step: 0
Training loss: 0.8509573936462402
Validation loss: 2.2262166937192283

Epoch: 6| Step: 1
Training loss: 0.4474472105503082
Validation loss: 2.1456172267595925

Epoch: 6| Step: 2
Training loss: 0.8865363001823425
Validation loss: 2.196956157684326

Epoch: 6| Step: 3
Training loss: 0.7616525888442993
Validation loss: 2.159135321776072

Epoch: 6| Step: 4
Training loss: 1.167798399925232
Validation loss: 2.1350054343541465

Epoch: 6| Step: 5
Training loss: 0.48224321007728577
Validation loss: 2.132316509882609

Epoch: 6| Step: 6
Training loss: 0.9166138172149658
Validation loss: 2.161103367805481

Epoch: 6| Step: 7
Training loss: 0.33076775074005127
Validation loss: 2.1414401531219482

Epoch: 6| Step: 8
Training loss: 0.764347493648529
Validation loss: 2.0837937394777932

Epoch: 6| Step: 9
Training loss: 0.5987904071807861
Validation loss: 2.0971412460009256

Epoch: 6| Step: 10
Training loss: 0.5026993751525879
Validation loss: 2.0963160395622253

Epoch: 6| Step: 11
Training loss: 0.4455452561378479
Validation loss: 2.101891656716665

Epoch: 6| Step: 12
Training loss: 1.0127003192901611
Validation loss: 2.13528702656428

Epoch: 6| Step: 13
Training loss: 1.3323514461517334
Validation loss: 2.196911553541819

Epoch: 517| Step: 0
Training loss: 1.0656391382217407
Validation loss: 2.237918277581533

Epoch: 6| Step: 1
Training loss: 0.6011790037155151
Validation loss: 2.134627103805542

Epoch: 6| Step: 2
Training loss: 0.7761892080307007
Validation loss: 2.1963594953219094

Epoch: 6| Step: 3
Training loss: 0.5301984548568726
Validation loss: 2.1215089559555054

Epoch: 6| Step: 4
Training loss: 1.0330619812011719
Validation loss: 2.1672919591267905

Epoch: 6| Step: 5
Training loss: 0.8168522715568542
Validation loss: 2.1097830533981323

Epoch: 6| Step: 6
Training loss: 0.5083814859390259
Validation loss: 2.1806582609812417

Epoch: 6| Step: 7
Training loss: 0.8605552911758423
Validation loss: 2.149364471435547

Epoch: 6| Step: 8
Training loss: 0.6128631830215454
Validation loss: 2.12656040986379

Epoch: 6| Step: 9
Training loss: 0.8990978002548218
Validation loss: 2.1750510931015015

Epoch: 6| Step: 10
Training loss: 0.432717889547348
Validation loss: 2.1474502285321555

Epoch: 6| Step: 11
Training loss: 0.495708167552948
Validation loss: 2.0920066833496094

Epoch: 6| Step: 12
Training loss: 1.0225465297698975
Validation loss: 2.1212497552235923

Epoch: 6| Step: 13
Training loss: 0.792304515838623
Validation loss: 2.1410929958025613

Epoch: 518| Step: 0
Training loss: 0.6710930466651917
Validation loss: 2.1850417455037436

Epoch: 6| Step: 1
Training loss: 0.977922797203064
Validation loss: 2.182170490423838

Epoch: 6| Step: 2
Training loss: 1.1437567472457886
Validation loss: 2.1671282251675925

Epoch: 6| Step: 3
Training loss: 1.3246866464614868
Validation loss: 2.140761435031891

Epoch: 6| Step: 4
Training loss: 0.6743570566177368
Validation loss: 2.147485355536143

Epoch: 6| Step: 5
Training loss: 0.8380306363105774
Validation loss: 2.1151171724001565

Epoch: 6| Step: 6
Training loss: 1.0073177814483643
Validation loss: 2.112721641858419

Epoch: 6| Step: 7
Training loss: 0.4483676254749298
Validation loss: 2.136033554871877

Epoch: 6| Step: 8
Training loss: 0.5652686357498169
Validation loss: 2.12263947725296

Epoch: 6| Step: 9
Training loss: 0.4079509973526001
Validation loss: 2.1629109978675842

Epoch: 6| Step: 10
Training loss: 0.5027862787246704
Validation loss: 2.137360910574595

Epoch: 6| Step: 11
Training loss: 0.5929309725761414
Validation loss: 2.166534205277761

Epoch: 6| Step: 12
Training loss: 0.5500966310501099
Validation loss: 2.1646928191184998

Epoch: 6| Step: 13
Training loss: 0.7224193215370178
Validation loss: 2.170868933200836

Epoch: 519| Step: 0
Training loss: 0.738791823387146
Validation loss: 2.170554995536804

Epoch: 6| Step: 1
Training loss: 0.9204570055007935
Validation loss: 2.124940037727356

Epoch: 6| Step: 2
Training loss: 0.40792015194892883
Validation loss: 2.1588815251986184

Epoch: 6| Step: 3
Training loss: 0.5333377122879028
Validation loss: 2.1796031395594277

Epoch: 6| Step: 4
Training loss: 0.8648788928985596
Validation loss: 2.20634659131368

Epoch: 6| Step: 5
Training loss: 1.0733976364135742
Validation loss: 2.1535874207814536

Epoch: 6| Step: 6
Training loss: 0.8578517436981201
Validation loss: 2.1472518841425576

Epoch: 6| Step: 7
Training loss: 0.5147705674171448
Validation loss: 2.1535905599594116

Epoch: 6| Step: 8
Training loss: 0.5135592818260193
Validation loss: 2.1439239780108132

Epoch: 6| Step: 9
Training loss: 1.0060131549835205
Validation loss: 2.1420645713806152

Epoch: 6| Step: 10
Training loss: 0.28765931725502014
Validation loss: 2.158327877521515

Epoch: 6| Step: 11
Training loss: 0.6071619391441345
Validation loss: 2.127986192703247

Epoch: 6| Step: 12
Training loss: 1.506617546081543
Validation loss: 2.14292577902476

Epoch: 6| Step: 13
Training loss: 0.3612985610961914
Validation loss: 2.1708996295928955

Epoch: 520| Step: 0
Training loss: 1.1382315158843994
Validation loss: 2.1634402871131897

Epoch: 6| Step: 1
Training loss: 0.5211092233657837
Validation loss: 2.157291054725647

Epoch: 6| Step: 2
Training loss: 0.4369054436683655
Validation loss: 2.1395655075709024

Epoch: 6| Step: 3
Training loss: 0.7315654158592224
Validation loss: 2.1712549726168313

Epoch: 6| Step: 4
Training loss: 0.3260948657989502
Validation loss: 2.1832720836003623

Epoch: 6| Step: 5
Training loss: 0.791333794593811
Validation loss: 2.12336128950119

Epoch: 6| Step: 6
Training loss: 0.7050364017486572
Validation loss: 2.1373762289683023

Epoch: 6| Step: 7
Training loss: 0.23730218410491943
Validation loss: 2.2036180098851523

Epoch: 6| Step: 8
Training loss: 1.1061478853225708
Validation loss: 2.15316375096639

Epoch: 6| Step: 9
Training loss: 0.5732318162918091
Validation loss: 2.127361019452413

Epoch: 6| Step: 10
Training loss: 0.8666493892669678
Validation loss: 2.129758278528849

Epoch: 6| Step: 11
Training loss: 0.8438729047775269
Validation loss: 2.155064662297567

Epoch: 6| Step: 12
Training loss: 0.5579308271408081
Validation loss: 2.135036567846934

Epoch: 6| Step: 13
Training loss: 0.9499279856681824
Validation loss: 2.1377365787823996

Epoch: 521| Step: 0
Training loss: 0.5255306959152222
Validation loss: 2.131903032461802

Epoch: 6| Step: 1
Training loss: 0.5295286178588867
Validation loss: 2.0924156308174133

Epoch: 6| Step: 2
Training loss: 0.4004990756511688
Validation loss: 2.1658016443252563

Epoch: 6| Step: 3
Training loss: 0.6519993543624878
Validation loss: 2.1413453221321106

Epoch: 6| Step: 4
Training loss: 1.2037537097930908
Validation loss: 2.1545315186182656

Epoch: 6| Step: 5
Training loss: 0.5426861047744751
Validation loss: 2.113824506600698

Epoch: 6| Step: 6
Training loss: 1.5972591638565063
Validation loss: 2.0932643016179404

Epoch: 6| Step: 7
Training loss: 0.6410937905311584
Validation loss: 2.130517323811849

Epoch: 6| Step: 8
Training loss: 0.8246373534202576
Validation loss: 2.105077544848124

Epoch: 6| Step: 9
Training loss: 0.7384947538375854
Validation loss: 2.099691907564799

Epoch: 6| Step: 10
Training loss: 0.6205726861953735
Validation loss: 2.1539392868677774

Epoch: 6| Step: 11
Training loss: 0.3140692710876465
Validation loss: 2.143583516279856

Epoch: 6| Step: 12
Training loss: 0.45631110668182373
Validation loss: 2.186007559299469

Epoch: 6| Step: 13
Training loss: 0.6271682381629944
Validation loss: 2.1143243312835693

Epoch: 522| Step: 0
Training loss: 0.5107603669166565
Validation loss: 2.126860499382019

Epoch: 6| Step: 1
Training loss: 0.8460982441902161
Validation loss: 2.1533409357070923

Epoch: 6| Step: 2
Training loss: 0.5457757115364075
Validation loss: 2.165179491043091

Epoch: 6| Step: 3
Training loss: 0.6605385541915894
Validation loss: 2.1628661354382834

Epoch: 6| Step: 4
Training loss: 0.4777929186820984
Validation loss: 2.1359592278798423

Epoch: 6| Step: 5
Training loss: 0.9092600345611572
Validation loss: 2.149687111377716

Epoch: 6| Step: 6
Training loss: 0.539000928401947
Validation loss: 2.159583787123362

Epoch: 6| Step: 7
Training loss: 0.45015057921409607
Validation loss: 2.1758212645848594

Epoch: 6| Step: 8
Training loss: 0.6240299940109253
Validation loss: 2.130433718363444

Epoch: 6| Step: 9
Training loss: 1.126295804977417
Validation loss: 2.1569277246793113

Epoch: 6| Step: 10
Training loss: 0.946438729763031
Validation loss: 2.190436085065206

Epoch: 6| Step: 11
Training loss: 0.8198522329330444
Validation loss: 2.2147197127342224

Epoch: 6| Step: 12
Training loss: 0.693968653678894
Validation loss: 2.2421481808026633

Epoch: 6| Step: 13
Training loss: 0.5793651342391968
Validation loss: 2.1846905946731567

Epoch: 523| Step: 0
Training loss: 0.5169854164123535
Validation loss: 2.2166561285654702

Epoch: 6| Step: 1
Training loss: 1.0098936557769775
Validation loss: 2.1887049873669944

Epoch: 6| Step: 2
Training loss: 0.8898981213569641
Validation loss: 2.1593238711357117

Epoch: 6| Step: 3
Training loss: 0.9221194386482239
Validation loss: 2.1470778783162436

Epoch: 6| Step: 4
Training loss: 0.9288634061813354
Validation loss: 2.1338435212771096

Epoch: 6| Step: 5
Training loss: 0.7665845155715942
Validation loss: 2.160458286603292

Epoch: 6| Step: 6
Training loss: 0.7073072195053101
Validation loss: 2.1039183934529624

Epoch: 6| Step: 7
Training loss: 0.5059641003608704
Validation loss: 2.1302122275034585

Epoch: 6| Step: 8
Training loss: 0.7473452687263489
Validation loss: 2.1117431918780007

Epoch: 6| Step: 9
Training loss: 0.3796306252479553
Validation loss: 2.0987242658933005

Epoch: 6| Step: 10
Training loss: 0.6355343461036682
Validation loss: 2.080324371655782

Epoch: 6| Step: 11
Training loss: 0.7122134566307068
Validation loss: 2.0933077136675515

Epoch: 6| Step: 12
Training loss: 0.6078503131866455
Validation loss: 2.1147388021151223

Epoch: 6| Step: 13
Training loss: 0.5763819217681885
Validation loss: 2.0759446024894714

Epoch: 524| Step: 0
Training loss: 0.7160952091217041
Validation loss: 2.1115328868230185

Epoch: 6| Step: 1
Training loss: 0.572696328163147
Validation loss: 2.100747287273407

Epoch: 6| Step: 2
Training loss: 0.7602335810661316
Validation loss: 2.0912371476491294

Epoch: 6| Step: 3
Training loss: 0.7195004224777222
Validation loss: 2.129271705945333

Epoch: 6| Step: 4
Training loss: 0.5097941160202026
Validation loss: 2.1641382972399392

Epoch: 6| Step: 5
Training loss: 0.4911994934082031
Validation loss: 2.164474129676819

Epoch: 6| Step: 6
Training loss: 1.0531668663024902
Validation loss: 2.1533287167549133

Epoch: 6| Step: 7
Training loss: 1.1762163639068604
Validation loss: 2.1834904750188193

Epoch: 6| Step: 8
Training loss: 0.9586092829704285
Validation loss: 2.1592409014701843

Epoch: 6| Step: 9
Training loss: 0.7767902612686157
Validation loss: 2.1519757310549417

Epoch: 6| Step: 10
Training loss: 0.4813293516635895
Validation loss: 2.1967214743296304

Epoch: 6| Step: 11
Training loss: 0.6809941530227661
Validation loss: 2.1301887035369873

Epoch: 6| Step: 12
Training loss: 0.671719491481781
Validation loss: 2.1343456308046975

Epoch: 6| Step: 13
Training loss: 0.7604069709777832
Validation loss: 2.191574056943258

Epoch: 525| Step: 0
Training loss: 0.3794400990009308
Validation loss: 2.2060702244440713

Epoch: 6| Step: 1
Training loss: 0.6615573167800903
Validation loss: 2.141757071018219

Epoch: 6| Step: 2
Training loss: 0.890103816986084
Validation loss: 2.1865744392077127

Epoch: 6| Step: 3
Training loss: 0.5347381830215454
Validation loss: 2.2349396546681723

Epoch: 6| Step: 4
Training loss: 1.0730689764022827
Validation loss: 2.182438770929972

Epoch: 6| Step: 5
Training loss: 0.5396064519882202
Validation loss: 2.227274477481842

Epoch: 6| Step: 6
Training loss: 0.5799720287322998
Validation loss: 2.2246472438176474

Epoch: 6| Step: 7
Training loss: 0.5366086363792419
Validation loss: 2.2055959502855935

Epoch: 6| Step: 8
Training loss: 1.00018310546875
Validation loss: 2.231325328350067

Epoch: 6| Step: 9
Training loss: 0.47928112745285034
Validation loss: 2.199533979098002

Epoch: 6| Step: 10
Training loss: 0.7728268504142761
Validation loss: 2.215661863485972

Epoch: 6| Step: 11
Training loss: 0.6803014874458313
Validation loss: 2.2088207403818765

Epoch: 6| Step: 12
Training loss: 0.5796228647232056
Validation loss: 2.199731787045797

Epoch: 6| Step: 13
Training loss: 0.9947417974472046
Validation loss: 2.173158506552378

Epoch: 526| Step: 0
Training loss: 0.5418413877487183
Validation loss: 2.1762973070144653

Epoch: 6| Step: 1
Training loss: 0.8704002499580383
Validation loss: 2.1399114529291787

Epoch: 6| Step: 2
Training loss: 1.0609409809112549
Validation loss: 2.174146036307017

Epoch: 6| Step: 3
Training loss: 0.847403347492218
Validation loss: 2.133369565010071

Epoch: 6| Step: 4
Training loss: 0.7565833330154419
Validation loss: 2.137275815010071

Epoch: 6| Step: 5
Training loss: 0.4904872477054596
Validation loss: 2.1773205399513245

Epoch: 6| Step: 6
Training loss: 0.447654128074646
Validation loss: 2.089074969291687

Epoch: 6| Step: 7
Training loss: 0.5563855171203613
Validation loss: 2.1239944895108542

Epoch: 6| Step: 8
Training loss: 0.45650699734687805
Validation loss: 2.124369462331136

Epoch: 6| Step: 9
Training loss: 0.5577284693717957
Validation loss: 2.149061898390452

Epoch: 6| Step: 10
Training loss: 0.44108012318611145
Validation loss: 2.1276849706967673

Epoch: 6| Step: 11
Training loss: 0.5777648091316223
Validation loss: 2.1188624501228333

Epoch: 6| Step: 12
Training loss: 1.297058343887329
Validation loss: 2.152958790461222

Epoch: 6| Step: 13
Training loss: 0.7275243997573853
Validation loss: 2.151219666004181

Epoch: 527| Step: 0
Training loss: 0.5169684886932373
Validation loss: 2.153213620185852

Epoch: 6| Step: 1
Training loss: 0.6105070114135742
Validation loss: 2.0719212690989175

Epoch: 6| Step: 2
Training loss: 0.9746605753898621
Validation loss: 2.0623265504837036

Epoch: 6| Step: 3
Training loss: 0.46058031916618347
Validation loss: 2.0918026169141135

Epoch: 6| Step: 4
Training loss: 0.2515665888786316
Validation loss: 2.120816628138224

Epoch: 6| Step: 5
Training loss: 0.41642144322395325
Validation loss: 2.1374482909838357

Epoch: 6| Step: 6
Training loss: 0.5004758238792419
Validation loss: 2.1394548416137695

Epoch: 6| Step: 7
Training loss: 0.7134658098220825
Validation loss: 2.136724352836609

Epoch: 6| Step: 8
Training loss: 0.8726014494895935
Validation loss: 2.1562082966168723

Epoch: 6| Step: 9
Training loss: 0.6344321966171265
Validation loss: 2.231711228688558

Epoch: 6| Step: 10
Training loss: 1.075404167175293
Validation loss: 2.1545050541559854

Epoch: 6| Step: 11
Training loss: 0.824001133441925
Validation loss: 2.2330432335535684

Epoch: 6| Step: 12
Training loss: 1.2550957202911377
Validation loss: 2.145440101623535

Epoch: 6| Step: 13
Training loss: 0.6481561064720154
Validation loss: 2.222861627737681

Epoch: 528| Step: 0
Training loss: 0.5179860591888428
Validation loss: 2.189864714940389

Epoch: 6| Step: 1
Training loss: 0.5837184190750122
Validation loss: 2.1954421599706015

Epoch: 6| Step: 2
Training loss: 0.9010789394378662
Validation loss: 2.20270965496699

Epoch: 6| Step: 3
Training loss: 0.8770520687103271
Validation loss: 2.141999622186025

Epoch: 6| Step: 4
Training loss: 0.4189024269580841
Validation loss: 2.1609934171040854

Epoch: 6| Step: 5
Training loss: 0.7776629328727722
Validation loss: 2.1653138399124146

Epoch: 6| Step: 6
Training loss: 0.8070541620254517
Validation loss: 2.1681012312571206

Epoch: 6| Step: 7
Training loss: 0.3827797770500183
Validation loss: 2.1560657819112143

Epoch: 6| Step: 8
Training loss: 0.9705969095230103
Validation loss: 2.1517512996991477

Epoch: 6| Step: 9
Training loss: 0.7000185251235962
Validation loss: 2.1420982480049133

Epoch: 6| Step: 10
Training loss: 0.28151628375053406
Validation loss: 2.0622784892717996

Epoch: 6| Step: 11
Training loss: 0.7069035768508911
Validation loss: 2.102200965086619

Epoch: 6| Step: 12
Training loss: 0.6313364505767822
Validation loss: 2.097103933493296

Epoch: 6| Step: 13
Training loss: 1.2413190603256226
Validation loss: 2.108691394329071

Epoch: 529| Step: 0
Training loss: 0.37023022770881653
Validation loss: 2.134162962436676

Epoch: 6| Step: 1
Training loss: 0.5023701786994934
Validation loss: 2.1638156374295554

Epoch: 6| Step: 2
Training loss: 0.4163062572479248
Validation loss: 2.1513084173202515

Epoch: 6| Step: 3
Training loss: 0.3044852316379547
Validation loss: 2.129146416982015

Epoch: 6| Step: 4
Training loss: 1.0179046392440796
Validation loss: 2.0985779762268066

Epoch: 6| Step: 5
Training loss: 0.8663988709449768
Validation loss: 2.0990203221639

Epoch: 6| Step: 6
Training loss: 0.5571527481079102
Validation loss: 2.1580713589986167

Epoch: 6| Step: 7
Training loss: 0.8870367407798767
Validation loss: 2.087265729904175

Epoch: 6| Step: 8
Training loss: 0.5688362121582031
Validation loss: 2.121125280857086

Epoch: 6| Step: 9
Training loss: 1.078526258468628
Validation loss: 2.0982319513956704

Epoch: 6| Step: 10
Training loss: 0.6484482288360596
Validation loss: 2.094448765118917

Epoch: 6| Step: 11
Training loss: 0.3755537271499634
Validation loss: 2.124746084213257

Epoch: 6| Step: 12
Training loss: 0.3424808084964752
Validation loss: 2.1683586041132608

Epoch: 6| Step: 13
Training loss: 1.185451865196228
Validation loss: 2.147918085257212

Epoch: 530| Step: 0
Training loss: 0.5059359073638916
Validation loss: 2.122859080632528

Epoch: 6| Step: 1
Training loss: 0.4250788986682892
Validation loss: 2.1615397135416665

Epoch: 6| Step: 2
Training loss: 0.7770981788635254
Validation loss: 2.151465972264608

Epoch: 6| Step: 3
Training loss: 1.0908726453781128
Validation loss: 2.178478797276815

Epoch: 6| Step: 4
Training loss: 0.6779650449752808
Validation loss: 2.0874772469202676

Epoch: 6| Step: 5
Training loss: 0.4232163429260254
Validation loss: 2.1343889435132346

Epoch: 6| Step: 6
Training loss: 0.6588085293769836
Validation loss: 2.1505384842554727

Epoch: 6| Step: 7
Training loss: 0.8961211442947388
Validation loss: 2.141606251398722

Epoch: 6| Step: 8
Training loss: 0.5042936205863953
Validation loss: 2.133980135122935

Epoch: 6| Step: 9
Training loss: 1.041725993156433
Validation loss: 2.1324771642684937

Epoch: 6| Step: 10
Training loss: 0.3388504981994629
Validation loss: 2.0721705754597983

Epoch: 6| Step: 11
Training loss: 0.428519070148468
Validation loss: 2.134449541568756

Epoch: 6| Step: 12
Training loss: 0.4618055522441864
Validation loss: 2.098346749941508

Epoch: 6| Step: 13
Training loss: 0.6094760894775391
Validation loss: 2.1157821218172708

Epoch: 531| Step: 0
Training loss: 0.4999336004257202
Validation loss: 2.1097556948661804

Epoch: 6| Step: 1
Training loss: 0.6545385122299194
Validation loss: 2.146891633669535

Epoch: 6| Step: 2
Training loss: 0.5427917838096619
Validation loss: 2.1481377879778543

Epoch: 6| Step: 3
Training loss: 1.3567206859588623
Validation loss: 2.1711127956708274

Epoch: 6| Step: 4
Training loss: 0.8432749509811401
Validation loss: 2.169049600760142

Epoch: 6| Step: 5
Training loss: 0.8885570764541626
Validation loss: 2.1916282971700034

Epoch: 6| Step: 6
Training loss: 0.39622098207473755
Validation loss: 2.15792985757192

Epoch: 6| Step: 7
Training loss: 0.6162590384483337
Validation loss: 2.2214527130126953

Epoch: 6| Step: 8
Training loss: 0.38893163204193115
Validation loss: 2.199145793914795

Epoch: 6| Step: 9
Training loss: 0.4874439239501953
Validation loss: 2.1970045963923135

Epoch: 6| Step: 10
Training loss: 0.5724430084228516
Validation loss: 2.1171810030937195

Epoch: 6| Step: 11
Training loss: 0.24215421080589294
Validation loss: 2.150968531767527

Epoch: 6| Step: 12
Training loss: 0.5445497632026672
Validation loss: 2.1365238428115845

Epoch: 6| Step: 13
Training loss: 0.5384492874145508
Validation loss: 2.141441504160563

Epoch: 532| Step: 0
Training loss: 0.44702357053756714
Validation loss: 2.1434473395347595

Epoch: 6| Step: 1
Training loss: 0.5999398231506348
Validation loss: 2.158674975236257

Epoch: 6| Step: 2
Training loss: 1.332834243774414
Validation loss: 2.1269306937853494

Epoch: 6| Step: 3
Training loss: 1.0640151500701904
Validation loss: 2.156152089436849

Epoch: 6| Step: 4
Training loss: 0.7565457820892334
Validation loss: 2.1283321181933084

Epoch: 6| Step: 5
Training loss: 1.0842198133468628
Validation loss: 2.1787563959757485

Epoch: 6| Step: 6
Training loss: 0.4335470497608185
Validation loss: 2.106642166773478

Epoch: 6| Step: 7
Training loss: 0.39642173051834106
Validation loss: 2.090446650981903

Epoch: 6| Step: 8
Training loss: 0.4947443902492523
Validation loss: 2.1529831687609353

Epoch: 6| Step: 9
Training loss: 0.43151652812957764
Validation loss: 2.0944570302963257

Epoch: 6| Step: 10
Training loss: 0.4200979471206665
Validation loss: 2.1688966155052185

Epoch: 6| Step: 11
Training loss: 0.6618479490280151
Validation loss: 2.147718071937561

Epoch: 6| Step: 12
Training loss: 0.7635304927825928
Validation loss: 2.149169703324636

Epoch: 6| Step: 13
Training loss: 0.9106552600860596
Validation loss: 2.1999302307764688

Epoch: 533| Step: 0
Training loss: 0.7080914974212646
Validation loss: 2.185121218363444

Epoch: 6| Step: 1
Training loss: 0.6636291146278381
Validation loss: 2.1070445775985718

Epoch: 6| Step: 2
Training loss: 0.38071227073669434
Validation loss: 2.1416634718577066

Epoch: 6| Step: 3
Training loss: 0.9542545676231384
Validation loss: 2.1316221157709756

Epoch: 6| Step: 4
Training loss: 0.4641173481941223
Validation loss: 2.1325865387916565

Epoch: 6| Step: 5
Training loss: 0.7055689692497253
Validation loss: 2.114478886127472

Epoch: 6| Step: 6
Training loss: 1.0741199254989624
Validation loss: 2.12614643573761

Epoch: 6| Step: 7
Training loss: 0.5629678964614868
Validation loss: 2.0777749021848044

Epoch: 6| Step: 8
Training loss: 0.5024181008338928
Validation loss: 2.0580785473187766

Epoch: 6| Step: 9
Training loss: 0.7784476280212402
Validation loss: 2.102197547753652

Epoch: 6| Step: 10
Training loss: 0.8537919521331787
Validation loss: 2.0926289359728494

Epoch: 6| Step: 11
Training loss: 0.5875687599182129
Validation loss: 2.098590393861135

Epoch: 6| Step: 12
Training loss: 0.5107577443122864
Validation loss: 2.081856290499369

Epoch: 6| Step: 13
Training loss: 1.2683155536651611
Validation loss: 2.1588669419288635

Epoch: 534| Step: 0
Training loss: 0.49815189838409424
Validation loss: 2.1252521276474

Epoch: 6| Step: 1
Training loss: 0.5091493129730225
Validation loss: 2.1186478535334268

Epoch: 6| Step: 2
Training loss: 0.8099992275238037
Validation loss: 2.0965742270151773

Epoch: 6| Step: 3
Training loss: 0.44904595613479614
Validation loss: 2.0942653814951577

Epoch: 6| Step: 4
Training loss: 0.6826823949813843
Validation loss: 2.1477052172025046

Epoch: 6| Step: 5
Training loss: 1.2827606201171875
Validation loss: 2.112472573916117

Epoch: 6| Step: 6
Training loss: 0.6544264554977417
Validation loss: 2.072268863519033

Epoch: 6| Step: 7
Training loss: 0.4822220802307129
Validation loss: 2.09696501493454

Epoch: 6| Step: 8
Training loss: 0.7699614763259888
Validation loss: 2.1219242413838706

Epoch: 6| Step: 9
Training loss: 0.8071413040161133
Validation loss: 2.136261781056722

Epoch: 6| Step: 10
Training loss: 0.6578400135040283
Validation loss: 2.15125165383021

Epoch: 6| Step: 11
Training loss: 0.8624950647354126
Validation loss: 2.1345516045888266

Epoch: 6| Step: 12
Training loss: 0.7154554724693298
Validation loss: 2.087812523047129

Epoch: 6| Step: 13
Training loss: 0.5322826504707336
Validation loss: 2.1347915728886924

Epoch: 535| Step: 0
Training loss: 1.1148430109024048
Validation loss: 2.156279186407725

Epoch: 6| Step: 1
Training loss: 0.4575803875923157
Validation loss: 2.119348088900248

Epoch: 6| Step: 2
Training loss: 0.4279034435749054
Validation loss: 2.1177035768826804

Epoch: 6| Step: 3
Training loss: 0.7237285375595093
Validation loss: 2.087199330329895

Epoch: 6| Step: 4
Training loss: 0.7559680938720703
Validation loss: 2.099149783452352

Epoch: 6| Step: 5
Training loss: 0.3616418242454529
Validation loss: 2.140587488810221

Epoch: 6| Step: 6
Training loss: 0.520356297492981
Validation loss: 2.1137587825457254

Epoch: 6| Step: 7
Training loss: 0.46639925241470337
Validation loss: 2.1876015663146973

Epoch: 6| Step: 8
Training loss: 0.3975532650947571
Validation loss: 2.1985694567362466

Epoch: 6| Step: 9
Training loss: 0.8741228580474854
Validation loss: 2.1256396373113

Epoch: 6| Step: 10
Training loss: 0.6272956132888794
Validation loss: 2.139206349849701

Epoch: 6| Step: 11
Training loss: 0.4504612386226654
Validation loss: 2.1868111292521157

Epoch: 6| Step: 12
Training loss: 0.41206979751586914
Validation loss: 2.1494945685068765

Epoch: 6| Step: 13
Training loss: 0.8200957179069519
Validation loss: 2.1155605713526406

Epoch: 536| Step: 0
Training loss: 0.46390604972839355
Validation loss: 2.141852935155233

Epoch: 6| Step: 1
Training loss: 0.637377917766571
Validation loss: 2.1180970668792725

Epoch: 6| Step: 2
Training loss: 1.061380386352539
Validation loss: 2.1583881179491677

Epoch: 6| Step: 3
Training loss: 0.6281835436820984
Validation loss: 2.1717936197916665

Epoch: 6| Step: 4
Training loss: 1.182525634765625
Validation loss: 2.1545212070147195

Epoch: 6| Step: 5
Training loss: 0.5823132991790771
Validation loss: 2.1803171038627625

Epoch: 6| Step: 6
Training loss: 0.4811810255050659
Validation loss: 2.0950525403022766

Epoch: 6| Step: 7
Training loss: 0.6338475942611694
Validation loss: 2.1438148617744446

Epoch: 6| Step: 8
Training loss: 0.36277955770492554
Validation loss: 2.1570387482643127

Epoch: 6| Step: 9
Training loss: 0.4263622760772705
Validation loss: 2.0896933674812317

Epoch: 6| Step: 10
Training loss: 0.7536977529525757
Validation loss: 2.1087926427523294

Epoch: 6| Step: 11
Training loss: 0.32887810468673706
Validation loss: 2.1209293405214944

Epoch: 6| Step: 12
Training loss: 0.6070036888122559
Validation loss: 2.119871656099955

Epoch: 6| Step: 13
Training loss: 0.4824475646018982
Validation loss: 2.1341294646263123

Epoch: 537| Step: 0
Training loss: 0.9146177768707275
Validation loss: 2.1346768140792847

Epoch: 6| Step: 1
Training loss: 0.7433531284332275
Validation loss: 2.1342896620432534

Epoch: 6| Step: 2
Training loss: 0.5422857999801636
Validation loss: 2.139223019282023

Epoch: 6| Step: 3
Training loss: 0.5300694704055786
Validation loss: 2.1795438726743064

Epoch: 6| Step: 4
Training loss: 0.46925708651542664
Validation loss: 2.1634294390678406

Epoch: 6| Step: 5
Training loss: 0.511435866355896
Validation loss: 2.1619001428286233

Epoch: 6| Step: 6
Training loss: 1.0440387725830078
Validation loss: 2.1882490515708923

Epoch: 6| Step: 7
Training loss: 0.463272362947464
Validation loss: 2.165146211783091

Epoch: 6| Step: 8
Training loss: 0.427067369222641
Validation loss: 2.199084460735321

Epoch: 6| Step: 9
Training loss: 0.7094377279281616
Validation loss: 2.154871424039205

Epoch: 6| Step: 10
Training loss: 0.6945716142654419
Validation loss: 2.1533085306485495

Epoch: 6| Step: 11
Training loss: 0.9406048059463501
Validation loss: 2.1787670254707336

Epoch: 6| Step: 12
Training loss: 0.6782152652740479
Validation loss: 2.0922463138898215

Epoch: 6| Step: 13
Training loss: 0.32144251465797424
Validation loss: 2.1317936778068542

Epoch: 538| Step: 0
Training loss: 0.3838683068752289
Validation loss: 2.0767592191696167

Epoch: 6| Step: 1
Training loss: 0.393964558839798
Validation loss: 2.135032375653585

Epoch: 6| Step: 2
Training loss: 1.1499125957489014
Validation loss: 2.1083850264549255

Epoch: 6| Step: 3
Training loss: 0.5302548408508301
Validation loss: 2.0937907298405967

Epoch: 6| Step: 4
Training loss: 0.28252315521240234
Validation loss: 2.10657807191213

Epoch: 6| Step: 5
Training loss: 0.5454975962638855
Validation loss: 2.108549952507019

Epoch: 6| Step: 6
Training loss: 0.25751620531082153
Validation loss: 2.0993821819623313

Epoch: 6| Step: 7
Training loss: 0.922092616558075
Validation loss: 2.1177412470181785

Epoch: 6| Step: 8
Training loss: 0.688692569732666
Validation loss: 2.094768206278483

Epoch: 6| Step: 9
Training loss: 0.8858400583267212
Validation loss: 2.1020847161610923

Epoch: 6| Step: 10
Training loss: 0.5788158178329468
Validation loss: 2.140541136264801

Epoch: 6| Step: 11
Training loss: 0.9202218055725098
Validation loss: 2.142378091812134

Epoch: 6| Step: 12
Training loss: 0.42562729120254517
Validation loss: 2.1390838623046875

Epoch: 6| Step: 13
Training loss: 0.38112199306488037
Validation loss: 2.1573543151219687

Epoch: 539| Step: 0
Training loss: 0.6493272185325623
Validation loss: 2.1479557355244956

Epoch: 6| Step: 1
Training loss: 0.4457938075065613
Validation loss: 2.1908514897028604

Epoch: 6| Step: 2
Training loss: 0.601055383682251
Validation loss: 2.1386407812436423

Epoch: 6| Step: 3
Training loss: 0.4822666049003601
Validation loss: 2.159624139467875

Epoch: 6| Step: 4
Training loss: 0.5139179229736328
Validation loss: 2.1677178541819253

Epoch: 6| Step: 5
Training loss: 1.2900665998458862
Validation loss: 2.1032488346099854

Epoch: 6| Step: 6
Training loss: 0.5853146910667419
Validation loss: 2.142111361026764

Epoch: 6| Step: 7
Training loss: 0.8324030041694641
Validation loss: 2.153831422328949

Epoch: 6| Step: 8
Training loss: 0.4176762104034424
Validation loss: 2.143907825152079

Epoch: 6| Step: 9
Training loss: 0.5577484965324402
Validation loss: 2.172169009844462

Epoch: 6| Step: 10
Training loss: 0.7838504910469055
Validation loss: 2.156616528828939

Epoch: 6| Step: 11
Training loss: 0.41529178619384766
Validation loss: 2.17627606789271

Epoch: 6| Step: 12
Training loss: 0.4395758807659149
Validation loss: 2.171489953994751

Epoch: 6| Step: 13
Training loss: 0.40057456493377686
Validation loss: 2.1259610851605735

Epoch: 540| Step: 0
Training loss: 0.3005189299583435
Validation loss: 2.1220322052637735

Epoch: 6| Step: 1
Training loss: 1.0120434761047363
Validation loss: 2.129603862762451

Epoch: 6| Step: 2
Training loss: 0.6397743225097656
Validation loss: 2.108577072620392

Epoch: 6| Step: 3
Training loss: 0.9812883734703064
Validation loss: 2.16440478960673

Epoch: 6| Step: 4
Training loss: 0.5506709218025208
Validation loss: 2.133205831050873

Epoch: 6| Step: 5
Training loss: 0.6869864463806152
Validation loss: 2.1768999497095742

Epoch: 6| Step: 6
Training loss: 0.5704530477523804
Validation loss: 2.1333848237991333

Epoch: 6| Step: 7
Training loss: 0.5142232179641724
Validation loss: 2.1286086241404214

Epoch: 6| Step: 8
Training loss: 0.9904113411903381
Validation loss: 2.1110790173212686

Epoch: 6| Step: 9
Training loss: 0.8216888308525085
Validation loss: 2.1677486300468445

Epoch: 6| Step: 10
Training loss: 0.36214232444763184
Validation loss: 2.128464659055074

Epoch: 6| Step: 11
Training loss: 0.37076398730278015
Validation loss: 2.109073499838511

Epoch: 6| Step: 12
Training loss: 0.6494910717010498
Validation loss: 2.1344104607899985

Epoch: 6| Step: 13
Training loss: 0.34436315298080444
Validation loss: 2.155383586883545

Epoch: 541| Step: 0
Training loss: 0.5942130088806152
Validation loss: 2.1768422524134317

Epoch: 6| Step: 1
Training loss: 0.5238568782806396
Validation loss: 2.1468616724014282

Epoch: 6| Step: 2
Training loss: 1.106114149093628
Validation loss: 2.142870545387268

Epoch: 6| Step: 3
Training loss: 0.7207763195037842
Validation loss: 2.095377584298452

Epoch: 6| Step: 4
Training loss: 0.36692214012145996
Validation loss: 2.103934586048126

Epoch: 6| Step: 5
Training loss: 0.40479373931884766
Validation loss: 2.1823121507962546

Epoch: 6| Step: 6
Training loss: 0.4873645603656769
Validation loss: 2.1129123767217

Epoch: 6| Step: 7
Training loss: 0.4856811463832855
Validation loss: 2.1249465545018515

Epoch: 6| Step: 8
Training loss: 0.7752010822296143
Validation loss: 2.1643191377321878

Epoch: 6| Step: 9
Training loss: 1.1650218963623047
Validation loss: 2.153950870037079

Epoch: 6| Step: 10
Training loss: 0.44486233592033386
Validation loss: 2.1335222125053406

Epoch: 6| Step: 11
Training loss: 0.5332664251327515
Validation loss: 2.1579713424046836

Epoch: 6| Step: 12
Training loss: 0.8446265459060669
Validation loss: 2.1270339290301004

Epoch: 6| Step: 13
Training loss: 0.43458905816078186
Validation loss: 2.0951431592305503

Epoch: 542| Step: 0
Training loss: 0.4172590672969818
Validation loss: 2.128680964310964

Epoch: 6| Step: 1
Training loss: 0.8552690148353577
Validation loss: 2.1245577136675515

Epoch: 6| Step: 2
Training loss: 0.9279403686523438
Validation loss: 2.112774670124054

Epoch: 6| Step: 3
Training loss: 0.36744970083236694
Validation loss: 2.1030893524487815

Epoch: 6| Step: 4
Training loss: 0.5981032848358154
Validation loss: 2.1121648152669272

Epoch: 6| Step: 5
Training loss: 0.33186835050582886
Validation loss: 2.105997463067373

Epoch: 6| Step: 6
Training loss: 0.7763136029243469
Validation loss: 2.11880757411321

Epoch: 6| Step: 7
Training loss: 0.4758368730545044
Validation loss: 2.103916108608246

Epoch: 6| Step: 8
Training loss: 0.35382792353630066
Validation loss: 2.0990888277689614

Epoch: 6| Step: 9
Training loss: 0.7130360007286072
Validation loss: 2.129667500654856

Epoch: 6| Step: 10
Training loss: 0.3838440179824829
Validation loss: 2.125133732954661

Epoch: 6| Step: 11
Training loss: 0.566476047039032
Validation loss: 2.1747486193974814

Epoch: 6| Step: 12
Training loss: 0.8098141551017761
Validation loss: 2.0842355489730835

Epoch: 6| Step: 13
Training loss: 0.9294232726097107
Validation loss: 2.0915043354034424

Epoch: 543| Step: 0
Training loss: 0.34849822521209717
Validation loss: 2.1342076659202576

Epoch: 6| Step: 1
Training loss: 0.5643196105957031
Validation loss: 2.0944854815800986

Epoch: 6| Step: 2
Training loss: 0.3183639645576477
Validation loss: 2.124726156393687

Epoch: 6| Step: 3
Training loss: 0.6097047328948975
Validation loss: 2.1156452695528665

Epoch: 6| Step: 4
Training loss: 0.49801361560821533
Validation loss: 2.1140179435412088

Epoch: 6| Step: 5
Training loss: 0.6794545650482178
Validation loss: 2.140552262465159

Epoch: 6| Step: 6
Training loss: 0.9726148843765259
Validation loss: 2.157538890838623

Epoch: 6| Step: 7
Training loss: 0.2694756090641022
Validation loss: 2.2190927267074585

Epoch: 6| Step: 8
Training loss: 0.9632967710494995
Validation loss: 2.150473634401957

Epoch: 6| Step: 9
Training loss: 0.9312720894813538
Validation loss: 2.1466365257898965

Epoch: 6| Step: 10
Training loss: 0.5829298496246338
Validation loss: 2.1299335757891336

Epoch: 6| Step: 11
Training loss: 0.4655761122703552
Validation loss: 2.1048830151557922

Epoch: 6| Step: 12
Training loss: 0.7028422355651855
Validation loss: 2.131736636161804

Epoch: 6| Step: 13
Training loss: 0.42161303758621216
Validation loss: 2.138981262842814

Epoch: 544| Step: 0
Training loss: 0.3784492313861847
Validation loss: 2.166159192721049

Epoch: 6| Step: 1
Training loss: 0.39541858434677124
Validation loss: 2.182644804318746

Epoch: 6| Step: 2
Training loss: 0.5681965351104736
Validation loss: 2.160120129585266

Epoch: 6| Step: 3
Training loss: 0.7472900152206421
Validation loss: 2.1595155000686646

Epoch: 6| Step: 4
Training loss: 0.706794261932373
Validation loss: 2.193994482358297

Epoch: 6| Step: 5
Training loss: 0.2936602234840393
Validation loss: 2.190180321534475

Epoch: 6| Step: 6
Training loss: 0.9556673765182495
Validation loss: 2.201962967713674

Epoch: 6| Step: 7
Training loss: 1.2554136514663696
Validation loss: 2.19794499874115

Epoch: 6| Step: 8
Training loss: 0.5552558898925781
Validation loss: 2.175738533337911

Epoch: 6| Step: 9
Training loss: 0.28591737151145935
Validation loss: 2.200447897116343

Epoch: 6| Step: 10
Training loss: 0.3694206178188324
Validation loss: 2.1421202619870505

Epoch: 6| Step: 11
Training loss: 0.31613409519195557
Validation loss: 2.099905570348104

Epoch: 6| Step: 12
Training loss: 0.9171177744865417
Validation loss: 2.1205169359842935

Epoch: 6| Step: 13
Training loss: 0.5135259032249451
Validation loss: 2.1453521649042764

Epoch: 545| Step: 0
Training loss: 0.3322080373764038
Validation loss: 2.1193395058314004

Epoch: 6| Step: 1
Training loss: 0.5019978284835815
Validation loss: 2.1005264123280845

Epoch: 6| Step: 2
Training loss: 0.30528128147125244
Validation loss: 2.151252826054891

Epoch: 6| Step: 3
Training loss: 0.7701205015182495
Validation loss: 2.1350714961687722

Epoch: 6| Step: 4
Training loss: 0.7385868430137634
Validation loss: 2.1163777112960815

Epoch: 6| Step: 5
Training loss: 0.6286463141441345
Validation loss: 2.120379408200582

Epoch: 6| Step: 6
Training loss: 0.580413281917572
Validation loss: 2.1643184820810952

Epoch: 6| Step: 7
Training loss: 0.588202953338623
Validation loss: 2.1764888167381287

Epoch: 6| Step: 8
Training loss: 0.5207952857017517
Validation loss: 2.1297674576441445

Epoch: 6| Step: 9
Training loss: 0.6182795166969299
Validation loss: 2.1266541878382363

Epoch: 6| Step: 10
Training loss: 0.9439244866371155
Validation loss: 2.15706596771876

Epoch: 6| Step: 11
Training loss: 0.43735596537590027
Validation loss: 2.094728171825409

Epoch: 6| Step: 12
Training loss: 0.6426152586936951
Validation loss: 2.159109115600586

Epoch: 6| Step: 13
Training loss: 0.8041613101959229
Validation loss: 2.2037160396575928

Epoch: 546| Step: 0
Training loss: 0.45960068702697754
Validation loss: 2.1231042544047036

Epoch: 6| Step: 1
Training loss: 0.8212490081787109
Validation loss: 2.1369264920552573

Epoch: 6| Step: 2
Training loss: 0.9123108386993408
Validation loss: 2.1486153602600098

Epoch: 6| Step: 3
Training loss: 0.1538514792919159
Validation loss: 2.1460928519566855

Epoch: 6| Step: 4
Training loss: 0.35171234607696533
Validation loss: 2.1369040807088218

Epoch: 6| Step: 5
Training loss: 0.29265785217285156
Validation loss: 2.143748184045156

Epoch: 6| Step: 6
Training loss: 1.0502020120620728
Validation loss: 2.153672675291697

Epoch: 6| Step: 7
Training loss: 0.4871046543121338
Validation loss: 2.1738189856211343

Epoch: 6| Step: 8
Training loss: 0.4384678602218628
Validation loss: 2.1433890660603843

Epoch: 6| Step: 9
Training loss: 1.2230112552642822
Validation loss: 2.102960725625356

Epoch: 6| Step: 10
Training loss: 0.4095766842365265
Validation loss: 2.1034178535143533

Epoch: 6| Step: 11
Training loss: 0.657367467880249
Validation loss: 2.0972530047098794

Epoch: 6| Step: 12
Training loss: 0.5382606387138367
Validation loss: 2.0921059250831604

Epoch: 6| Step: 13
Training loss: 0.40825724601745605
Validation loss: 2.1373008688290915

Epoch: 547| Step: 0
Training loss: 0.4995571970939636
Validation loss: 2.078870117664337

Epoch: 6| Step: 1
Training loss: 0.9834384322166443
Validation loss: 2.140501399834951

Epoch: 6| Step: 2
Training loss: 0.9235866069793701
Validation loss: 2.11968602736791

Epoch: 6| Step: 3
Training loss: 0.4697044789791107
Validation loss: 2.081004321575165

Epoch: 6| Step: 4
Training loss: 0.49725210666656494
Validation loss: 2.1009079217910767

Epoch: 6| Step: 5
Training loss: 0.6390907168388367
Validation loss: 2.17082808415095

Epoch: 6| Step: 6
Training loss: 0.35162749886512756
Validation loss: 2.1188480059305825

Epoch: 6| Step: 7
Training loss: 0.6410295963287354
Validation loss: 2.1257392366727195

Epoch: 6| Step: 8
Training loss: 0.4938336908817291
Validation loss: 2.140964905420939

Epoch: 6| Step: 9
Training loss: 0.5337759852409363
Validation loss: 2.1372135082880654

Epoch: 6| Step: 10
Training loss: 0.7384426593780518
Validation loss: 2.096481204032898

Epoch: 6| Step: 11
Training loss: 0.6587659120559692
Validation loss: 2.1423797408739724

Epoch: 6| Step: 12
Training loss: 0.9119859337806702
Validation loss: 2.1330086390177407

Epoch: 6| Step: 13
Training loss: 0.2530556321144104
Validation loss: 2.163449009259542

Epoch: 548| Step: 0
Training loss: 0.4366229772567749
Validation loss: 2.1447572708129883

Epoch: 6| Step: 1
Training loss: 0.7533456087112427
Validation loss: 2.1348921855290732

Epoch: 6| Step: 2
Training loss: 0.7982959151268005
Validation loss: 2.167355199654897

Epoch: 6| Step: 3
Training loss: 0.4088760018348694
Validation loss: 2.1834651827812195

Epoch: 6| Step: 4
Training loss: 0.6061198711395264
Validation loss: 2.1380309661229453

Epoch: 6| Step: 5
Training loss: 0.927420973777771
Validation loss: 2.2013314167658486

Epoch: 6| Step: 6
Training loss: 0.2637150287628174
Validation loss: 2.193215807278951

Epoch: 6| Step: 7
Training loss: 0.25750893354415894
Validation loss: 2.164437929789225

Epoch: 6| Step: 8
Training loss: 0.6884812712669373
Validation loss: 2.1422356764475503

Epoch: 6| Step: 9
Training loss: 0.7157043218612671
Validation loss: 2.206721623738607

Epoch: 6| Step: 10
Training loss: 0.7368170619010925
Validation loss: 2.2023558815320334

Epoch: 6| Step: 11
Training loss: 0.447664737701416
Validation loss: 2.2080581386884055

Epoch: 6| Step: 12
Training loss: 0.6257278919219971
Validation loss: 2.2494004567464194

Epoch: 6| Step: 13
Training loss: 0.5166351795196533
Validation loss: 2.2155579725901284

Epoch: 549| Step: 0
Training loss: 0.49245262145996094
Validation loss: 2.2172516187032065

Epoch: 6| Step: 1
Training loss: 0.3546479344367981
Validation loss: 2.238169312477112

Epoch: 6| Step: 2
Training loss: 0.5876461267471313
Validation loss: 2.198044538497925

Epoch: 6| Step: 3
Training loss: 0.5326352119445801
Validation loss: 2.1706631978352866

Epoch: 6| Step: 4
Training loss: 0.3640422224998474
Validation loss: 2.180704176425934

Epoch: 6| Step: 5
Training loss: 0.2758675217628479
Validation loss: 2.1362855235735574

Epoch: 6| Step: 6
Training loss: 0.3913036286830902
Validation loss: 2.110998531182607

Epoch: 6| Step: 7
Training loss: 0.8735840320587158
Validation loss: 2.1475375096003213

Epoch: 6| Step: 8
Training loss: 0.7872118353843689
Validation loss: 2.1377752820650735

Epoch: 6| Step: 9
Training loss: 0.4007086753845215
Validation loss: 2.109561880429586

Epoch: 6| Step: 10
Training loss: 0.5673873424530029
Validation loss: 2.1403377254803977

Epoch: 6| Step: 11
Training loss: 0.7763553261756897
Validation loss: 2.130103588104248

Epoch: 6| Step: 12
Training loss: 1.1933032274246216
Validation loss: 2.0941019654273987

Epoch: 6| Step: 13
Training loss: 0.8466806411743164
Validation loss: 2.1500523885091147

Epoch: 550| Step: 0
Training loss: 0.8413949608802795
Validation loss: 2.0860135753949485

Epoch: 6| Step: 1
Training loss: 0.5383507013320923
Validation loss: 2.079037348429362

Epoch: 6| Step: 2
Training loss: 0.48101210594177246
Validation loss: 2.1221073071161904

Epoch: 6| Step: 3
Training loss: 1.4459750652313232
Validation loss: 2.1302598317464194

Epoch: 6| Step: 4
Training loss: 0.43728744983673096
Validation loss: 2.164042274157206

Epoch: 6| Step: 5
Training loss: 0.5159163475036621
Validation loss: 2.1168860594431558

Epoch: 6| Step: 6
Training loss: 0.365517258644104
Validation loss: 2.1621391773223877

Epoch: 6| Step: 7
Training loss: 0.2697819471359253
Validation loss: 2.081338365872701

Epoch: 6| Step: 8
Training loss: 0.4931052625179291
Validation loss: 2.1460127035776773

Epoch: 6| Step: 9
Training loss: 0.5703667998313904
Validation loss: 2.163801670074463

Epoch: 6| Step: 10
Training loss: 0.3713562488555908
Validation loss: 2.1488150556882224

Epoch: 6| Step: 11
Training loss: 0.6359214186668396
Validation loss: 2.1461406151453652

Epoch: 6| Step: 12
Training loss: 1.2330659627914429
Validation loss: 2.09574826558431

Epoch: 6| Step: 13
Training loss: 0.639904797077179
Validation loss: 2.12701823314031

Testing loss: 1.892127781463184
